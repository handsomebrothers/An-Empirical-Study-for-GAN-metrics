{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*-coding:utf-8-*-\n",
    "import util\n",
    "import tensorflow as tf\n",
    "MNIST_CLASSIFIER_FROZEN_GRAPH = './classify_mnist_graph_def.pb'\n",
    "INPUT_TENSOR = 'inputs:0'\n",
    "OUTPUT_TENSOR = 'logits:0'\n",
    "def EuclideanDistances(A, B):\n",
    "\n",
    "    BT = B.transpose()\n",
    "    # vecProd = A * BT\n",
    "    vecProd = np.dot(A, BT)\n",
    "    # print(vecProd)\n",
    "    SqA = A ** 2\n",
    "    # print(SqA)\n",
    "    sumSqA = np.matrix(np.sum(SqA, axis=1))\n",
    "    sumSqAEx = np.tile(sumSqA.transpose(), (1, vecProd.shape[1]))\n",
    "    # print(sumSqAEx)\n",
    "\n",
    "    SqB = B ** 2\n",
    "    sumSqB = np.sum(SqB, axis=1)\n",
    "    sumSqBEx = np.tile(sumSqB, (vecProd.shape[0], 1))\n",
    "    SqED = sumSqBEx + sumSqAEx - 2 * vecProd\n",
    "    SqED[SqED < 0] = 0.0\n",
    "    ED = np.sqrt(SqED)\n",
    "    return np.divide(ED.sum(),ED.shape[0]*ED.shape[1])\n",
    "def cal_distance_image_real(images,labels):\n",
    "    eval_images=tf.convert_to_tensor(images)\n",
    "    y_logits=util.mnist_logits(eval_images, MNIST_CLASSIFIER_FROZEN_GRAPH, INPUT_TENSOR, OUTPUT_TENSOR)\n",
    "    y_logits=tf.Session().run(y_logits)\n",
    "    dict={}\n",
    "    all_dis=[]\n",
    "    for i in range(10):\n",
    "        dict[i]=[]\n",
    "    for i in range(len(labels)):\n",
    "        dict[labels[i]].append(y_logits[i])\n",
    "    for i in range(10):\n",
    "        dict[i]=np.array(dict[i])\n",
    "        if len(dict[i]):\n",
    "            dis = EuclideanDistances(dict[i], dict[i])  # 生成图片的紧度\n",
    "        else:\n",
    "            dis = -1\n",
    "        all_dis.append(dis)\n",
    "    return np.array(all_dis)\n",
    "def cal_distance_image_fake(images):\n",
    "    eval_images=tf.convert_to_tensor(images)\n",
    "    y_logits=util.mnist_logits(eval_images, MNIST_CLASSIFIER_FROZEN_GRAPH, INPUT_TENSOR, OUTPUT_TENSOR)\n",
    "    y_logits=tf.Session().run(y_logits)\n",
    "    labels = tf.Session().run(tf.argmax(y_logits, 1))\n",
    "    dict={}\n",
    "    all_dis=[]\n",
    "    for i in range(10):\n",
    "        dict[i]=[]\n",
    "    for i in range(len(labels)):\n",
    "        dict[labels[i]].append(y_logits[i])\n",
    "    for i in range(10):\n",
    "        dict[i]=np.array(dict[i])\n",
    "        if len(dict[i]):\n",
    "            dis = EuclideanDistances(dict[i], dict[i])  # 生成图片的紧度\n",
    "        else:\n",
    "            dis = -1\n",
    "        all_dis.append(dis)\n",
    "    return np.array(all_dis)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_15 (Conv2D)           (None, 14, 14, 32)        320       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 14, 14, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 7, 7, 64)          18496     \n",
      "_________________________________________________________________\n",
      "zero_padding2d_3 (ZeroPaddin (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 4, 4, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 393,729\n",
      "Trainable params: 392,833\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 6272)              633472    \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_5 (UpSampling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 14, 14, 128)       147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 14, 14, 128)       512       \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_6 (UpSampling2 (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 28, 28, 64)        73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 28, 28, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 28, 28, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 856,193\n",
      "Trainable params: 855,809\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n",
      "epoch:0 step:1 [D loss: 1.099858, acc.: 28.12%] [G loss: 0.658647]\n",
      "epoch:0 step:2 [D loss: 0.906247, acc.: 50.00%] [G loss: 0.783317]\n",
      "epoch:0 step:3 [D loss: 0.572987, acc.: 71.88%] [G loss: 1.289762]\n",
      "epoch:0 step:4 [D loss: 0.597646, acc.: 70.31%] [G loss: 1.391321]\n",
      "epoch:0 step:5 [D loss: 0.455221, acc.: 78.91%] [G loss: 1.305255]\n",
      "epoch:0 step:6 [D loss: 0.288067, acc.: 89.06%] [G loss: 1.119186]\n",
      "epoch:0 step:7 [D loss: 0.274931, acc.: 89.84%] [G loss: 0.854499]\n",
      "epoch:0 step:8 [D loss: 0.408904, acc.: 80.47%] [G loss: 0.760088]\n",
      "epoch:0 step:9 [D loss: 0.617959, acc.: 67.19%] [G loss: 1.126284]\n",
      "epoch:0 step:10 [D loss: 0.977512, acc.: 48.44%] [G loss: 1.530834]\n",
      "epoch:0 step:11 [D loss: 0.884597, acc.: 48.44%] [G loss: 1.677225]\n",
      "epoch:0 step:12 [D loss: 0.873970, acc.: 50.00%] [G loss: 1.259697]\n",
      "epoch:0 step:13 [D loss: 0.606761, acc.: 67.97%] [G loss: 1.519199]\n",
      "epoch:0 step:14 [D loss: 0.774229, acc.: 57.03%] [G loss: 1.780699]\n",
      "epoch:0 step:15 [D loss: 0.597947, acc.: 67.97%] [G loss: 1.269269]\n",
      "epoch:0 step:16 [D loss: 0.506964, acc.: 75.78%] [G loss: 0.565731]\n",
      "epoch:0 step:17 [D loss: 0.351082, acc.: 88.28%] [G loss: 0.375700]\n",
      "epoch:0 step:18 [D loss: 0.345005, acc.: 82.81%] [G loss: 0.339335]\n",
      "epoch:0 step:19 [D loss: 0.398966, acc.: 80.47%] [G loss: 0.681728]\n",
      "epoch:0 step:20 [D loss: 0.982995, acc.: 54.69%] [G loss: 1.634879]\n",
      "epoch:0 step:21 [D loss: 1.179716, acc.: 34.38%] [G loss: 1.585014]\n",
      "epoch:0 step:22 [D loss: 0.958509, acc.: 47.66%] [G loss: 1.062156]\n",
      "epoch:0 step:23 [D loss: 0.643102, acc.: 71.88%] [G loss: 0.529535]\n",
      "epoch:0 step:24 [D loss: 0.588945, acc.: 73.44%] [G loss: 0.556409]\n",
      "epoch:0 step:25 [D loss: 0.766962, acc.: 62.50%] [G loss: 0.989661]\n",
      "epoch:0 step:26 [D loss: 1.321475, acc.: 37.50%] [G loss: 1.284461]\n",
      "epoch:0 step:27 [D loss: 1.067425, acc.: 42.19%] [G loss: 1.368819]\n",
      "epoch:0 step:28 [D loss: 0.985948, acc.: 44.53%] [G loss: 0.913035]\n",
      "epoch:0 step:29 [D loss: 0.872608, acc.: 47.66%] [G loss: 1.066396]\n",
      "epoch:0 step:30 [D loss: 0.850928, acc.: 43.75%] [G loss: 1.572437]\n",
      "epoch:0 step:31 [D loss: 0.858437, acc.: 46.09%] [G loss: 1.712039]\n",
      "epoch:0 step:32 [D loss: 0.962618, acc.: 42.19%] [G loss: 1.031810]\n",
      "epoch:0 step:33 [D loss: 0.597313, acc.: 67.97%] [G loss: 0.800232]\n",
      "epoch:0 step:34 [D loss: 0.466922, acc.: 78.12%] [G loss: 0.500688]\n",
      "epoch:0 step:35 [D loss: 0.477239, acc.: 75.00%] [G loss: 0.491254]\n",
      "epoch:0 step:36 [D loss: 0.717494, acc.: 66.41%] [G loss: 0.941034]\n",
      "epoch:0 step:37 [D loss: 1.115345, acc.: 39.06%] [G loss: 1.401056]\n",
      "epoch:0 step:38 [D loss: 1.356582, acc.: 28.91%] [G loss: 1.437387]\n",
      "epoch:0 step:39 [D loss: 0.983167, acc.: 40.62%] [G loss: 1.328464]\n",
      "epoch:0 step:40 [D loss: 0.752368, acc.: 56.25%] [G loss: 1.273880]\n",
      "epoch:0 step:41 [D loss: 0.866065, acc.: 49.22%] [G loss: 1.452796]\n",
      "epoch:0 step:42 [D loss: 0.875641, acc.: 50.00%] [G loss: 1.688408]\n",
      "epoch:0 step:43 [D loss: 0.865643, acc.: 47.66%] [G loss: 1.489109]\n",
      "epoch:0 step:44 [D loss: 0.918055, acc.: 50.78%] [G loss: 1.248550]\n",
      "epoch:0 step:45 [D loss: 0.815340, acc.: 55.47%] [G loss: 1.017520]\n",
      "epoch:0 step:46 [D loss: 0.838703, acc.: 44.53%] [G loss: 0.990734]\n",
      "epoch:0 step:47 [D loss: 0.811016, acc.: 53.91%] [G loss: 1.193191]\n",
      "epoch:0 step:48 [D loss: 0.889640, acc.: 46.09%] [G loss: 1.547421]\n",
      "epoch:0 step:49 [D loss: 0.855953, acc.: 47.66%] [G loss: 1.315688]\n",
      "epoch:0 step:50 [D loss: 0.893729, acc.: 46.88%] [G loss: 1.219796]\n",
      "epoch:0 step:51 [D loss: 0.796241, acc.: 56.25%] [G loss: 1.377127]\n",
      "epoch:0 step:52 [D loss: 0.866980, acc.: 50.78%] [G loss: 1.503561]\n",
      "epoch:0 step:53 [D loss: 0.761571, acc.: 52.34%] [G loss: 1.317651]\n",
      "epoch:0 step:54 [D loss: 0.756534, acc.: 53.12%] [G loss: 1.079999]\n",
      "epoch:0 step:55 [D loss: 0.603543, acc.: 67.97%] [G loss: 1.263057]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:56 [D loss: 0.793782, acc.: 54.69%] [G loss: 1.136590]\n",
      "epoch:0 step:57 [D loss: 0.900310, acc.: 49.22%] [G loss: 1.087780]\n",
      "epoch:0 step:58 [D loss: 0.974866, acc.: 42.19%] [G loss: 1.188643]\n",
      "epoch:0 step:59 [D loss: 0.800961, acc.: 49.22%] [G loss: 1.388608]\n",
      "epoch:0 step:60 [D loss: 1.013465, acc.: 42.97%] [G loss: 1.213990]\n",
      "epoch:0 step:61 [D loss: 0.865639, acc.: 45.31%] [G loss: 1.268679]\n",
      "epoch:0 step:62 [D loss: 0.893454, acc.: 46.09%] [G loss: 0.991829]\n",
      "epoch:0 step:63 [D loss: 0.780858, acc.: 51.56%] [G loss: 1.332237]\n",
      "epoch:0 step:64 [D loss: 0.874093, acc.: 45.31%] [G loss: 1.238858]\n",
      "epoch:0 step:65 [D loss: 0.845127, acc.: 47.66%] [G loss: 1.088136]\n",
      "epoch:0 step:66 [D loss: 0.845404, acc.: 51.56%] [G loss: 1.069645]\n",
      "epoch:0 step:67 [D loss: 0.776089, acc.: 53.91%] [G loss: 1.079013]\n",
      "epoch:0 step:68 [D loss: 0.823574, acc.: 46.88%] [G loss: 1.359123]\n",
      "epoch:0 step:69 [D loss: 0.915007, acc.: 43.75%] [G loss: 1.346519]\n",
      "epoch:0 step:70 [D loss: 0.813153, acc.: 51.56%] [G loss: 1.247913]\n",
      "epoch:0 step:71 [D loss: 0.848864, acc.: 46.88%] [G loss: 1.368507]\n",
      "epoch:0 step:72 [D loss: 0.903349, acc.: 45.31%] [G loss: 1.306559]\n",
      "epoch:0 step:73 [D loss: 0.913954, acc.: 47.66%] [G loss: 0.977368]\n",
      "epoch:0 step:74 [D loss: 0.815745, acc.: 45.31%] [G loss: 1.202901]\n",
      "epoch:0 step:75 [D loss: 0.911631, acc.: 46.09%] [G loss: 1.087127]\n",
      "epoch:0 step:76 [D loss: 0.840368, acc.: 49.22%] [G loss: 1.298655]\n",
      "epoch:0 step:77 [D loss: 0.794646, acc.: 52.34%] [G loss: 1.211508]\n",
      "epoch:0 step:78 [D loss: 1.002868, acc.: 35.16%] [G loss: 1.038100]\n",
      "epoch:0 step:79 [D loss: 0.904114, acc.: 40.62%] [G loss: 1.058169]\n",
      "epoch:0 step:80 [D loss: 0.908720, acc.: 44.53%] [G loss: 1.095024]\n",
      "epoch:0 step:81 [D loss: 0.835262, acc.: 47.66%] [G loss: 1.197863]\n",
      "epoch:0 step:82 [D loss: 0.954666, acc.: 39.06%] [G loss: 1.204786]\n",
      "epoch:0 step:83 [D loss: 0.728022, acc.: 58.59%] [G loss: 1.159026]\n",
      "epoch:0 step:84 [D loss: 0.946626, acc.: 45.31%] [G loss: 1.248243]\n",
      "epoch:0 step:85 [D loss: 0.851552, acc.: 42.97%] [G loss: 1.019211]\n",
      "epoch:0 step:86 [D loss: 0.745460, acc.: 55.47%] [G loss: 1.276964]\n",
      "epoch:0 step:87 [D loss: 0.863158, acc.: 42.97%] [G loss: 1.137757]\n",
      "epoch:0 step:88 [D loss: 0.892625, acc.: 41.41%] [G loss: 1.152967]\n",
      "epoch:0 step:89 [D loss: 0.819862, acc.: 46.88%] [G loss: 1.285857]\n",
      "epoch:0 step:90 [D loss: 0.742763, acc.: 57.03%] [G loss: 1.023832]\n",
      "epoch:0 step:91 [D loss: 0.830440, acc.: 48.44%] [G loss: 1.191487]\n",
      "epoch:0 step:92 [D loss: 0.813389, acc.: 52.34%] [G loss: 1.153304]\n",
      "epoch:0 step:93 [D loss: 0.844196, acc.: 50.00%] [G loss: 1.152822]\n",
      "epoch:0 step:94 [D loss: 1.061129, acc.: 35.94%] [G loss: 1.003991]\n",
      "epoch:0 step:95 [D loss: 0.792844, acc.: 47.66%] [G loss: 1.112796]\n",
      "epoch:0 step:96 [D loss: 0.833050, acc.: 43.75%] [G loss: 1.199345]\n",
      "epoch:0 step:97 [D loss: 1.013708, acc.: 35.94%] [G loss: 1.033180]\n",
      "epoch:0 step:98 [D loss: 0.787488, acc.: 52.34%] [G loss: 1.301621]\n",
      "epoch:0 step:99 [D loss: 0.832043, acc.: 42.19%] [G loss: 1.304345]\n",
      "epoch:0 step:100 [D loss: 0.703215, acc.: 57.81%] [G loss: 1.110919]\n",
      "epoch:0 step:101 [D loss: 0.758057, acc.: 58.59%] [G loss: 1.026144]\n",
      "epoch:0 step:102 [D loss: 0.798382, acc.: 54.69%] [G loss: 0.959173]\n",
      "epoch:0 step:103 [D loss: 0.717821, acc.: 55.47%] [G loss: 1.222760]\n",
      "epoch:0 step:104 [D loss: 0.772583, acc.: 53.91%] [G loss: 1.237936]\n",
      "epoch:0 step:105 [D loss: 0.726328, acc.: 59.38%] [G loss: 1.426508]\n",
      "epoch:0 step:106 [D loss: 0.859982, acc.: 42.97%] [G loss: 1.209454]\n",
      "epoch:0 step:107 [D loss: 0.837845, acc.: 53.12%] [G loss: 1.279936]\n",
      "epoch:0 step:108 [D loss: 0.858282, acc.: 47.66%] [G loss: 1.039915]\n",
      "epoch:0 step:109 [D loss: 0.785848, acc.: 49.22%] [G loss: 1.025066]\n",
      "epoch:0 step:110 [D loss: 0.761917, acc.: 55.47%] [G loss: 1.158547]\n",
      "epoch:0 step:111 [D loss: 0.763070, acc.: 50.78%] [G loss: 0.984549]\n",
      "epoch:0 step:112 [D loss: 0.925042, acc.: 36.72%] [G loss: 1.197974]\n",
      "epoch:0 step:113 [D loss: 0.949876, acc.: 39.06%] [G loss: 1.248390]\n",
      "epoch:0 step:114 [D loss: 1.010345, acc.: 32.81%] [G loss: 1.082431]\n",
      "epoch:0 step:115 [D loss: 0.916038, acc.: 42.97%] [G loss: 1.212351]\n",
      "epoch:0 step:116 [D loss: 0.889512, acc.: 48.44%] [G loss: 1.091718]\n",
      "epoch:0 step:117 [D loss: 0.674676, acc.: 57.81%] [G loss: 1.273959]\n",
      "epoch:0 step:118 [D loss: 0.828221, acc.: 53.12%] [G loss: 1.258773]\n",
      "epoch:0 step:119 [D loss: 0.941239, acc.: 42.19%] [G loss: 1.209401]\n",
      "epoch:0 step:120 [D loss: 0.991090, acc.: 39.84%] [G loss: 1.046495]\n",
      "epoch:0 step:121 [D loss: 0.818586, acc.: 50.78%] [G loss: 1.097974]\n",
      "epoch:0 step:122 [D loss: 0.797016, acc.: 45.31%] [G loss: 0.940016]\n",
      "epoch:0 step:123 [D loss: 0.830510, acc.: 50.00%] [G loss: 1.039602]\n",
      "epoch:0 step:124 [D loss: 0.839010, acc.: 47.66%] [G loss: 1.175594]\n",
      "epoch:0 step:125 [D loss: 0.894436, acc.: 45.31%] [G loss: 1.201954]\n",
      "epoch:0 step:126 [D loss: 0.811189, acc.: 46.88%] [G loss: 1.132802]\n",
      "epoch:0 step:127 [D loss: 0.903537, acc.: 42.19%] [G loss: 1.038154]\n",
      "epoch:0 step:128 [D loss: 0.925738, acc.: 42.19%] [G loss: 1.163828]\n",
      "epoch:0 step:129 [D loss: 0.921705, acc.: 38.28%] [G loss: 1.233186]\n",
      "epoch:0 step:130 [D loss: 0.719890, acc.: 65.62%] [G loss: 0.949453]\n",
      "epoch:0 step:131 [D loss: 0.791646, acc.: 52.34%] [G loss: 1.075152]\n",
      "epoch:0 step:132 [D loss: 0.834747, acc.: 48.44%] [G loss: 1.045611]\n",
      "epoch:0 step:133 [D loss: 0.867646, acc.: 47.66%] [G loss: 1.044641]\n",
      "epoch:0 step:134 [D loss: 0.836635, acc.: 47.66%] [G loss: 1.128354]\n",
      "epoch:0 step:135 [D loss: 0.958527, acc.: 34.38%] [G loss: 1.008498]\n",
      "epoch:0 step:136 [D loss: 0.934879, acc.: 42.19%] [G loss: 1.116303]\n",
      "epoch:0 step:137 [D loss: 0.951806, acc.: 41.41%] [G loss: 0.993553]\n",
      "epoch:0 step:138 [D loss: 0.962941, acc.: 41.41%] [G loss: 1.003240]\n",
      "epoch:0 step:139 [D loss: 0.973397, acc.: 39.84%] [G loss: 0.910641]\n",
      "epoch:0 step:140 [D loss: 0.842278, acc.: 43.75%] [G loss: 0.998260]\n",
      "epoch:0 step:141 [D loss: 0.771025, acc.: 51.56%] [G loss: 1.097495]\n",
      "epoch:0 step:142 [D loss: 0.801591, acc.: 50.78%] [G loss: 0.948117]\n",
      "epoch:0 step:143 [D loss: 0.822127, acc.: 39.84%] [G loss: 1.057082]\n",
      "epoch:0 step:144 [D loss: 0.852869, acc.: 46.09%] [G loss: 1.127320]\n",
      "epoch:0 step:145 [D loss: 0.771490, acc.: 50.78%] [G loss: 1.255126]\n",
      "epoch:0 step:146 [D loss: 0.892458, acc.: 42.19%] [G loss: 0.959148]\n",
      "epoch:0 step:147 [D loss: 0.876152, acc.: 47.66%] [G loss: 0.925877]\n",
      "epoch:0 step:148 [D loss: 0.794260, acc.: 52.34%] [G loss: 0.926027]\n",
      "epoch:0 step:149 [D loss: 0.797727, acc.: 44.53%] [G loss: 1.168017]\n",
      "epoch:0 step:150 [D loss: 0.899416, acc.: 45.31%] [G loss: 0.943612]\n",
      "epoch:0 step:151 [D loss: 0.909591, acc.: 42.19%] [G loss: 0.980032]\n",
      "epoch:0 step:152 [D loss: 0.798351, acc.: 47.66%] [G loss: 1.126536]\n",
      "epoch:0 step:153 [D loss: 0.856646, acc.: 51.56%] [G loss: 1.196821]\n",
      "epoch:0 step:154 [D loss: 0.835750, acc.: 45.31%] [G loss: 0.963447]\n",
      "epoch:0 step:155 [D loss: 0.894350, acc.: 40.62%] [G loss: 1.024670]\n",
      "epoch:0 step:156 [D loss: 0.884262, acc.: 39.06%] [G loss: 1.054859]\n",
      "epoch:0 step:157 [D loss: 0.757944, acc.: 51.56%] [G loss: 1.152604]\n",
      "epoch:0 step:158 [D loss: 0.833235, acc.: 47.66%] [G loss: 1.008090]\n",
      "epoch:0 step:159 [D loss: 0.859693, acc.: 40.62%] [G loss: 1.093326]\n",
      "epoch:0 step:160 [D loss: 0.872523, acc.: 41.41%] [G loss: 0.914945]\n",
      "epoch:0 step:161 [D loss: 0.922844, acc.: 36.72%] [G loss: 0.968025]\n",
      "epoch:0 step:162 [D loss: 0.796359, acc.: 53.12%] [G loss: 1.147137]\n",
      "epoch:0 step:163 [D loss: 0.744577, acc.: 46.88%] [G loss: 1.006769]\n",
      "epoch:0 step:164 [D loss: 0.795945, acc.: 51.56%] [G loss: 1.154211]\n",
      "epoch:0 step:165 [D loss: 0.756561, acc.: 52.34%] [G loss: 1.351142]\n",
      "epoch:0 step:166 [D loss: 0.735365, acc.: 57.03%] [G loss: 1.134306]\n",
      "epoch:0 step:167 [D loss: 0.765459, acc.: 48.44%] [G loss: 1.175522]\n",
      "epoch:0 step:168 [D loss: 0.750568, acc.: 57.03%] [G loss: 1.136407]\n",
      "epoch:0 step:169 [D loss: 0.820008, acc.: 47.66%] [G loss: 1.136696]\n",
      "epoch:0 step:170 [D loss: 0.847570, acc.: 50.00%] [G loss: 1.051845]\n",
      "epoch:0 step:171 [D loss: 0.776295, acc.: 57.03%] [G loss: 1.018757]\n",
      "epoch:0 step:172 [D loss: 0.905186, acc.: 45.31%] [G loss: 1.078457]\n",
      "epoch:0 step:173 [D loss: 0.847362, acc.: 48.44%] [G loss: 0.994543]\n",
      "epoch:0 step:174 [D loss: 0.872870, acc.: 46.88%] [G loss: 1.061018]\n",
      "epoch:0 step:175 [D loss: 0.847795, acc.: 44.53%] [G loss: 1.068680]\n",
      "epoch:0 step:176 [D loss: 0.811995, acc.: 49.22%] [G loss: 1.140395]\n",
      "epoch:0 step:177 [D loss: 0.847962, acc.: 47.66%] [G loss: 1.022325]\n",
      "epoch:0 step:178 [D loss: 0.781246, acc.: 53.12%] [G loss: 1.051137]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:179 [D loss: 0.879297, acc.: 39.06%] [G loss: 1.206634]\n",
      "epoch:0 step:180 [D loss: 1.012597, acc.: 38.28%] [G loss: 1.074492]\n",
      "epoch:0 step:181 [D loss: 0.823548, acc.: 43.75%] [G loss: 1.181467]\n",
      "epoch:0 step:182 [D loss: 0.868376, acc.: 41.41%] [G loss: 1.057033]\n",
      "epoch:0 step:183 [D loss: 0.870114, acc.: 39.84%] [G loss: 0.955756]\n",
      "epoch:0 step:184 [D loss: 0.831612, acc.: 43.75%] [G loss: 0.936626]\n",
      "epoch:0 step:185 [D loss: 0.798696, acc.: 50.00%] [G loss: 1.013512]\n",
      "epoch:0 step:186 [D loss: 0.789430, acc.: 48.44%] [G loss: 1.017732]\n",
      "epoch:0 step:187 [D loss: 0.750968, acc.: 57.03%] [G loss: 0.997275]\n",
      "epoch:0 step:188 [D loss: 0.968811, acc.: 34.38%] [G loss: 1.008533]\n",
      "epoch:0 step:189 [D loss: 0.795639, acc.: 50.78%] [G loss: 0.974146]\n",
      "epoch:0 step:190 [D loss: 0.851629, acc.: 46.88%] [G loss: 1.038645]\n",
      "epoch:0 step:191 [D loss: 0.824703, acc.: 48.44%] [G loss: 1.184436]\n",
      "epoch:0 step:192 [D loss: 0.807741, acc.: 46.88%] [G loss: 1.189656]\n",
      "epoch:0 step:193 [D loss: 0.834006, acc.: 51.56%] [G loss: 1.008613]\n",
      "epoch:0 step:194 [D loss: 0.836183, acc.: 46.88%] [G loss: 1.178647]\n",
      "epoch:0 step:195 [D loss: 0.810896, acc.: 42.19%] [G loss: 1.035266]\n",
      "epoch:0 step:196 [D loss: 0.827657, acc.: 43.75%] [G loss: 1.005057]\n",
      "epoch:0 step:197 [D loss: 0.802900, acc.: 45.31%] [G loss: 1.000708]\n",
      "epoch:0 step:198 [D loss: 0.845901, acc.: 47.66%] [G loss: 1.027426]\n",
      "epoch:0 step:199 [D loss: 0.860969, acc.: 46.88%] [G loss: 1.031092]\n",
      "epoch:0 step:200 [D loss: 0.853547, acc.: 44.53%] [G loss: 0.986110]\n",
      "WARNING:tensorflow:From /home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/contrib/gan/python/eval/python/classifier_metrics_impl.py:185: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      "##############\n",
      "[3.07453461 1.79916086 7.06757449 5.6664598  4.3109555  6.20632565\n",
      " 5.1991401  5.3216167  5.67971484 3.91102663]\n",
      "##########\n",
      "epoch:0 step:201 [D loss: 0.734785, acc.: 56.25%] [G loss: 1.106969]\n",
      "epoch:0 step:202 [D loss: 0.866156, acc.: 38.28%] [G loss: 1.076536]\n",
      "epoch:0 step:203 [D loss: 0.960728, acc.: 38.28%] [G loss: 0.990704]\n",
      "epoch:0 step:204 [D loss: 0.915403, acc.: 42.19%] [G loss: 0.954932]\n",
      "epoch:0 step:205 [D loss: 0.787736, acc.: 48.44%] [G loss: 0.934281]\n",
      "epoch:0 step:206 [D loss: 0.819146, acc.: 42.97%] [G loss: 0.956696]\n",
      "epoch:0 step:207 [D loss: 0.755464, acc.: 51.56%] [G loss: 1.172749]\n",
      "epoch:0 step:208 [D loss: 0.784693, acc.: 46.88%] [G loss: 1.043224]\n",
      "epoch:0 step:209 [D loss: 0.792848, acc.: 52.34%] [G loss: 1.070654]\n",
      "epoch:0 step:210 [D loss: 0.850806, acc.: 45.31%] [G loss: 1.026734]\n",
      "epoch:0 step:211 [D loss: 0.869629, acc.: 40.62%] [G loss: 1.029298]\n",
      "epoch:0 step:212 [D loss: 0.867239, acc.: 44.53%] [G loss: 1.014015]\n",
      "epoch:0 step:213 [D loss: 0.795054, acc.: 47.66%] [G loss: 1.074002]\n",
      "epoch:0 step:214 [D loss: 0.823836, acc.: 42.97%] [G loss: 0.911005]\n",
      "epoch:0 step:215 [D loss: 0.795899, acc.: 45.31%] [G loss: 0.922910]\n",
      "epoch:0 step:216 [D loss: 0.762154, acc.: 53.12%] [G loss: 0.864100]\n",
      "epoch:0 step:217 [D loss: 0.717502, acc.: 52.34%] [G loss: 0.951380]\n",
      "epoch:0 step:218 [D loss: 0.856242, acc.: 44.53%] [G loss: 1.103951]\n",
      "epoch:0 step:219 [D loss: 0.813044, acc.: 47.66%] [G loss: 1.064352]\n",
      "epoch:0 step:220 [D loss: 1.019472, acc.: 28.12%] [G loss: 1.022534]\n",
      "epoch:0 step:221 [D loss: 0.804809, acc.: 46.88%] [G loss: 1.016989]\n",
      "epoch:0 step:222 [D loss: 0.775426, acc.: 56.25%] [G loss: 1.006192]\n",
      "epoch:0 step:223 [D loss: 0.852881, acc.: 44.53%] [G loss: 0.917992]\n",
      "epoch:0 step:224 [D loss: 0.800319, acc.: 50.00%] [G loss: 0.981137]\n",
      "epoch:0 step:225 [D loss: 0.821897, acc.: 42.97%] [G loss: 0.992219]\n",
      "epoch:0 step:226 [D loss: 0.728031, acc.: 55.47%] [G loss: 1.025596]\n",
      "epoch:0 step:227 [D loss: 0.831146, acc.: 46.09%] [G loss: 1.047228]\n",
      "epoch:0 step:228 [D loss: 0.696586, acc.: 58.59%] [G loss: 1.037787]\n",
      "epoch:0 step:229 [D loss: 0.706331, acc.: 55.47%] [G loss: 1.029582]\n",
      "epoch:0 step:230 [D loss: 0.659944, acc.: 59.38%] [G loss: 1.076023]\n",
      "epoch:0 step:231 [D loss: 0.648270, acc.: 62.50%] [G loss: 1.209591]\n",
      "epoch:0 step:232 [D loss: 0.660306, acc.: 59.38%] [G loss: 1.266789]\n",
      "epoch:0 step:233 [D loss: 0.845933, acc.: 46.88%] [G loss: 1.114186]\n",
      "epoch:0 step:234 [D loss: 0.902715, acc.: 39.84%] [G loss: 0.902507]\n",
      "epoch:0 step:235 [D loss: 0.755877, acc.: 53.12%] [G loss: 1.178848]\n",
      "epoch:0 step:236 [D loss: 0.744880, acc.: 57.03%] [G loss: 1.185376]\n",
      "epoch:0 step:237 [D loss: 0.818528, acc.: 44.53%] [G loss: 0.894221]\n",
      "epoch:0 step:238 [D loss: 0.849898, acc.: 46.88%] [G loss: 0.935471]\n",
      "epoch:0 step:239 [D loss: 0.785579, acc.: 55.47%] [G loss: 1.030988]\n",
      "epoch:0 step:240 [D loss: 0.817367, acc.: 48.44%] [G loss: 1.028717]\n",
      "epoch:0 step:241 [D loss: 0.780215, acc.: 52.34%] [G loss: 1.039359]\n",
      "epoch:0 step:242 [D loss: 0.920076, acc.: 38.28%] [G loss: 0.905555]\n",
      "epoch:0 step:243 [D loss: 0.739212, acc.: 53.12%] [G loss: 0.952828]\n",
      "epoch:0 step:244 [D loss: 0.676863, acc.: 53.91%] [G loss: 0.963246]\n",
      "epoch:0 step:245 [D loss: 0.758757, acc.: 53.12%] [G loss: 0.944541]\n",
      "epoch:0 step:246 [D loss: 0.820468, acc.: 44.53%] [G loss: 1.017596]\n",
      "epoch:0 step:247 [D loss: 0.808363, acc.: 50.00%] [G loss: 1.001192]\n",
      "epoch:0 step:248 [D loss: 0.793370, acc.: 46.09%] [G loss: 1.012170]\n",
      "epoch:0 step:249 [D loss: 0.792804, acc.: 51.56%] [G loss: 1.175827]\n",
      "epoch:0 step:250 [D loss: 0.798659, acc.: 48.44%] [G loss: 1.084254]\n",
      "epoch:0 step:251 [D loss: 0.812655, acc.: 46.88%] [G loss: 1.076677]\n",
      "epoch:0 step:252 [D loss: 0.791030, acc.: 49.22%] [G loss: 1.007307]\n",
      "epoch:0 step:253 [D loss: 0.700493, acc.: 61.72%] [G loss: 0.979459]\n",
      "epoch:0 step:254 [D loss: 0.703106, acc.: 57.03%] [G loss: 1.007338]\n",
      "epoch:0 step:255 [D loss: 0.670936, acc.: 64.06%] [G loss: 1.054054]\n",
      "epoch:0 step:256 [D loss: 0.708792, acc.: 57.03%] [G loss: 0.934106]\n",
      "epoch:0 step:257 [D loss: 0.797233, acc.: 49.22%] [G loss: 0.915130]\n",
      "epoch:0 step:258 [D loss: 0.735254, acc.: 53.12%] [G loss: 0.995731]\n",
      "epoch:0 step:259 [D loss: 0.773511, acc.: 48.44%] [G loss: 1.016369]\n",
      "epoch:0 step:260 [D loss: 0.730968, acc.: 55.47%] [G loss: 0.962833]\n",
      "epoch:0 step:261 [D loss: 0.781760, acc.: 52.34%] [G loss: 1.129036]\n",
      "epoch:0 step:262 [D loss: 0.835123, acc.: 42.19%] [G loss: 1.045260]\n",
      "epoch:0 step:263 [D loss: 0.844289, acc.: 45.31%] [G loss: 1.074855]\n",
      "epoch:0 step:264 [D loss: 0.714007, acc.: 52.34%] [G loss: 1.020188]\n",
      "epoch:0 step:265 [D loss: 0.786947, acc.: 50.00%] [G loss: 0.888129]\n",
      "epoch:0 step:266 [D loss: 0.866832, acc.: 37.50%] [G loss: 0.873293]\n",
      "epoch:0 step:267 [D loss: 0.777602, acc.: 50.00%] [G loss: 1.047782]\n",
      "epoch:0 step:268 [D loss: 0.838589, acc.: 46.09%] [G loss: 1.029466]\n",
      "epoch:0 step:269 [D loss: 0.887021, acc.: 39.06%] [G loss: 1.027827]\n",
      "epoch:0 step:270 [D loss: 0.702028, acc.: 65.62%] [G loss: 1.056638]\n",
      "epoch:0 step:271 [D loss: 0.731528, acc.: 53.12%] [G loss: 1.054308]\n",
      "epoch:0 step:272 [D loss: 0.839914, acc.: 42.97%] [G loss: 0.964240]\n",
      "epoch:0 step:273 [D loss: 0.803575, acc.: 49.22%] [G loss: 1.021277]\n",
      "epoch:0 step:274 [D loss: 0.864033, acc.: 41.41%] [G loss: 1.060173]\n",
      "epoch:0 step:275 [D loss: 0.781072, acc.: 47.66%] [G loss: 1.044660]\n",
      "epoch:0 step:276 [D loss: 0.762378, acc.: 50.00%] [G loss: 1.104926]\n",
      "epoch:0 step:277 [D loss: 0.729312, acc.: 57.81%] [G loss: 1.124268]\n",
      "epoch:0 step:278 [D loss: 0.744276, acc.: 52.34%] [G loss: 0.930717]\n",
      "epoch:0 step:279 [D loss: 0.745099, acc.: 53.91%] [G loss: 0.925362]\n",
      "epoch:0 step:280 [D loss: 0.728033, acc.: 54.69%] [G loss: 0.949806]\n",
      "epoch:0 step:281 [D loss: 0.881979, acc.: 39.06%] [G loss: 0.973366]\n",
      "epoch:0 step:282 [D loss: 0.837336, acc.: 46.88%] [G loss: 1.037321]\n",
      "epoch:0 step:283 [D loss: 0.825140, acc.: 42.19%] [G loss: 1.095818]\n",
      "epoch:0 step:284 [D loss: 0.720617, acc.: 55.47%] [G loss: 0.890935]\n",
      "epoch:0 step:285 [D loss: 0.786810, acc.: 52.34%] [G loss: 0.905760]\n",
      "epoch:0 step:286 [D loss: 0.764020, acc.: 54.69%] [G loss: 0.999152]\n",
      "epoch:0 step:287 [D loss: 0.734910, acc.: 53.12%] [G loss: 0.899567]\n",
      "epoch:0 step:288 [D loss: 0.750996, acc.: 54.69%] [G loss: 0.996375]\n",
      "epoch:0 step:289 [D loss: 0.756577, acc.: 49.22%] [G loss: 1.036741]\n",
      "epoch:0 step:290 [D loss: 0.812929, acc.: 44.53%] [G loss: 0.996667]\n",
      "epoch:0 step:291 [D loss: 0.715297, acc.: 54.69%] [G loss: 1.069726]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:292 [D loss: 0.680974, acc.: 62.50%] [G loss: 1.124110]\n",
      "epoch:0 step:293 [D loss: 0.748121, acc.: 46.88%] [G loss: 0.988115]\n",
      "epoch:0 step:294 [D loss: 0.771419, acc.: 50.00%] [G loss: 1.129985]\n",
      "epoch:0 step:295 [D loss: 0.772048, acc.: 51.56%] [G loss: 0.978776]\n",
      "epoch:0 step:296 [D loss: 0.731627, acc.: 52.34%] [G loss: 1.027727]\n",
      "epoch:0 step:297 [D loss: 0.785997, acc.: 43.75%] [G loss: 0.951421]\n",
      "epoch:0 step:298 [D loss: 0.749509, acc.: 53.12%] [G loss: 1.138070]\n",
      "epoch:0 step:299 [D loss: 0.746011, acc.: 50.78%] [G loss: 1.106012]\n",
      "epoch:0 step:300 [D loss: 0.763755, acc.: 56.25%] [G loss: 1.039539]\n",
      "epoch:0 step:301 [D loss: 0.901095, acc.: 39.06%] [G loss: 0.941761]\n",
      "epoch:0 step:302 [D loss: 0.746578, acc.: 53.91%] [G loss: 1.003380]\n",
      "epoch:0 step:303 [D loss: 0.807285, acc.: 50.78%] [G loss: 0.993046]\n",
      "epoch:0 step:304 [D loss: 0.796305, acc.: 52.34%] [G loss: 0.974527]\n",
      "epoch:0 step:305 [D loss: 0.754809, acc.: 50.00%] [G loss: 0.820766]\n",
      "epoch:0 step:306 [D loss: 0.866145, acc.: 36.72%] [G loss: 0.904358]\n",
      "epoch:0 step:307 [D loss: 0.756568, acc.: 53.91%] [G loss: 0.992834]\n",
      "epoch:0 step:308 [D loss: 0.829386, acc.: 47.66%] [G loss: 0.925420]\n",
      "epoch:0 step:309 [D loss: 0.767681, acc.: 51.56%] [G loss: 1.059405]\n",
      "epoch:0 step:310 [D loss: 0.756627, acc.: 55.47%] [G loss: 1.096050]\n",
      "epoch:0 step:311 [D loss: 0.784224, acc.: 50.00%] [G loss: 1.106011]\n",
      "epoch:0 step:312 [D loss: 0.734897, acc.: 53.12%] [G loss: 1.138216]\n",
      "epoch:0 step:313 [D loss: 0.738414, acc.: 48.44%] [G loss: 1.046284]\n",
      "epoch:0 step:314 [D loss: 0.709726, acc.: 57.81%] [G loss: 1.004712]\n",
      "epoch:0 step:315 [D loss: 0.771501, acc.: 53.12%] [G loss: 1.145955]\n",
      "epoch:0 step:316 [D loss: 0.856028, acc.: 41.41%] [G loss: 1.024525]\n",
      "epoch:0 step:317 [D loss: 0.821378, acc.: 43.75%] [G loss: 0.985160]\n",
      "epoch:0 step:318 [D loss: 0.895871, acc.: 35.94%] [G loss: 0.884730]\n",
      "epoch:0 step:319 [D loss: 0.835541, acc.: 46.88%] [G loss: 0.895562]\n",
      "epoch:0 step:320 [D loss: 0.805201, acc.: 50.00%] [G loss: 0.885558]\n",
      "epoch:0 step:321 [D loss: 0.723392, acc.: 56.25%] [G loss: 0.940108]\n",
      "epoch:0 step:322 [D loss: 0.667805, acc.: 60.16%] [G loss: 0.878403]\n",
      "epoch:0 step:323 [D loss: 0.685847, acc.: 59.38%] [G loss: 1.030341]\n",
      "epoch:0 step:324 [D loss: 0.746811, acc.: 59.38%] [G loss: 0.963335]\n",
      "epoch:0 step:325 [D loss: 0.696627, acc.: 60.16%] [G loss: 0.877899]\n",
      "epoch:0 step:326 [D loss: 0.706187, acc.: 56.25%] [G loss: 0.876389]\n",
      "epoch:0 step:327 [D loss: 0.741800, acc.: 50.78%] [G loss: 1.048200]\n",
      "epoch:0 step:328 [D loss: 0.766211, acc.: 53.12%] [G loss: 1.075539]\n",
      "epoch:0 step:329 [D loss: 0.780835, acc.: 51.56%] [G loss: 1.090458]\n",
      "epoch:0 step:330 [D loss: 0.733602, acc.: 50.78%] [G loss: 1.049409]\n",
      "epoch:0 step:331 [D loss: 0.719711, acc.: 57.03%] [G loss: 1.012884]\n",
      "epoch:0 step:332 [D loss: 0.733885, acc.: 48.44%] [G loss: 1.031496]\n",
      "epoch:0 step:333 [D loss: 0.707582, acc.: 58.59%] [G loss: 1.016526]\n",
      "epoch:0 step:334 [D loss: 0.744486, acc.: 50.00%] [G loss: 1.045047]\n",
      "epoch:0 step:335 [D loss: 0.721709, acc.: 55.47%] [G loss: 1.120685]\n",
      "epoch:0 step:336 [D loss: 0.785595, acc.: 50.00%] [G loss: 1.065493]\n",
      "epoch:0 step:337 [D loss: 0.693612, acc.: 57.03%] [G loss: 1.043659]\n",
      "epoch:0 step:338 [D loss: 0.755821, acc.: 54.69%] [G loss: 1.102974]\n",
      "epoch:0 step:339 [D loss: 0.682057, acc.: 60.16%] [G loss: 1.061116]\n",
      "epoch:0 step:340 [D loss: 0.797151, acc.: 52.34%] [G loss: 1.002387]\n",
      "epoch:0 step:341 [D loss: 0.785684, acc.: 49.22%] [G loss: 0.985781]\n",
      "epoch:0 step:342 [D loss: 0.756484, acc.: 52.34%] [G loss: 0.848634]\n",
      "epoch:0 step:343 [D loss: 0.732851, acc.: 53.91%] [G loss: 0.897460]\n",
      "epoch:0 step:344 [D loss: 0.673311, acc.: 60.16%] [G loss: 1.018135]\n",
      "epoch:0 step:345 [D loss: 0.791515, acc.: 48.44%] [G loss: 1.063251]\n",
      "epoch:0 step:346 [D loss: 0.768870, acc.: 53.91%] [G loss: 1.011505]\n",
      "epoch:0 step:347 [D loss: 0.692062, acc.: 59.38%] [G loss: 1.133857]\n",
      "epoch:0 step:348 [D loss: 0.865418, acc.: 42.97%] [G loss: 0.915171]\n",
      "epoch:0 step:349 [D loss: 0.944471, acc.: 42.19%] [G loss: 0.856891]\n",
      "epoch:0 step:350 [D loss: 0.818734, acc.: 41.41%] [G loss: 0.932907]\n",
      "epoch:0 step:351 [D loss: 0.805948, acc.: 46.88%] [G loss: 1.070184]\n",
      "epoch:0 step:352 [D loss: 0.807745, acc.: 36.72%] [G loss: 0.918439]\n",
      "epoch:0 step:353 [D loss: 0.748911, acc.: 54.69%] [G loss: 1.001475]\n",
      "epoch:0 step:354 [D loss: 0.849000, acc.: 42.97%] [G loss: 1.032630]\n",
      "epoch:0 step:355 [D loss: 0.755081, acc.: 50.00%] [G loss: 0.921200]\n",
      "epoch:0 step:356 [D loss: 0.737744, acc.: 52.34%] [G loss: 0.943687]\n",
      "epoch:0 step:357 [D loss: 0.760415, acc.: 47.66%] [G loss: 1.151071]\n",
      "epoch:0 step:358 [D loss: 0.749654, acc.: 57.81%] [G loss: 1.068170]\n",
      "epoch:0 step:359 [D loss: 0.759613, acc.: 50.00%] [G loss: 1.029375]\n",
      "epoch:0 step:360 [D loss: 0.646900, acc.: 63.28%] [G loss: 1.050759]\n",
      "epoch:0 step:361 [D loss: 0.765453, acc.: 51.56%] [G loss: 1.110829]\n",
      "epoch:0 step:362 [D loss: 0.785620, acc.: 46.88%] [G loss: 0.963530]\n",
      "epoch:0 step:363 [D loss: 0.772836, acc.: 47.66%] [G loss: 0.922812]\n",
      "epoch:0 step:364 [D loss: 0.752090, acc.: 51.56%] [G loss: 0.979547]\n",
      "epoch:0 step:365 [D loss: 0.802344, acc.: 45.31%] [G loss: 0.974978]\n",
      "epoch:0 step:366 [D loss: 0.753852, acc.: 51.56%] [G loss: 1.087419]\n",
      "epoch:0 step:367 [D loss: 0.763291, acc.: 48.44%] [G loss: 0.978291]\n",
      "epoch:0 step:368 [D loss: 0.695209, acc.: 58.59%] [G loss: 1.078618]\n",
      "epoch:0 step:369 [D loss: 0.724529, acc.: 55.47%] [G loss: 1.055644]\n",
      "epoch:0 step:370 [D loss: 0.850943, acc.: 42.97%] [G loss: 1.011301]\n",
      "epoch:0 step:371 [D loss: 0.696251, acc.: 57.81%] [G loss: 1.003115]\n",
      "epoch:0 step:372 [D loss: 0.758960, acc.: 47.66%] [G loss: 1.044359]\n",
      "epoch:0 step:373 [D loss: 0.718348, acc.: 58.59%] [G loss: 1.066120]\n",
      "epoch:0 step:374 [D loss: 0.744757, acc.: 51.56%] [G loss: 1.056986]\n",
      "epoch:0 step:375 [D loss: 0.890279, acc.: 38.28%] [G loss: 0.976158]\n",
      "epoch:0 step:376 [D loss: 0.775106, acc.: 46.88%] [G loss: 1.017982]\n",
      "epoch:0 step:377 [D loss: 0.705372, acc.: 60.16%] [G loss: 0.936077]\n",
      "epoch:0 step:378 [D loss: 0.739891, acc.: 54.69%] [G loss: 0.871824]\n",
      "epoch:0 step:379 [D loss: 0.749953, acc.: 50.00%] [G loss: 0.950697]\n",
      "epoch:0 step:380 [D loss: 0.716932, acc.: 53.91%] [G loss: 1.110047]\n",
      "epoch:0 step:381 [D loss: 0.787502, acc.: 48.44%] [G loss: 0.997085]\n",
      "epoch:0 step:382 [D loss: 0.850558, acc.: 37.50%] [G loss: 1.031451]\n",
      "epoch:0 step:383 [D loss: 0.777505, acc.: 45.31%] [G loss: 1.064156]\n",
      "epoch:0 step:384 [D loss: 0.766214, acc.: 48.44%] [G loss: 1.083496]\n",
      "epoch:0 step:385 [D loss: 0.810494, acc.: 46.09%] [G loss: 1.037024]\n",
      "epoch:0 step:386 [D loss: 0.755767, acc.: 50.00%] [G loss: 0.893421]\n",
      "epoch:0 step:387 [D loss: 0.783035, acc.: 53.91%] [G loss: 0.998869]\n",
      "epoch:0 step:388 [D loss: 0.642934, acc.: 65.62%] [G loss: 0.866288]\n",
      "epoch:0 step:389 [D loss: 0.737816, acc.: 50.00%] [G loss: 1.135106]\n",
      "epoch:0 step:390 [D loss: 0.758877, acc.: 43.75%] [G loss: 1.026230]\n",
      "epoch:0 step:391 [D loss: 0.666612, acc.: 63.28%] [G loss: 1.007672]\n",
      "epoch:0 step:392 [D loss: 0.691514, acc.: 54.69%] [G loss: 1.156047]\n",
      "epoch:0 step:393 [D loss: 0.732956, acc.: 52.34%] [G loss: 1.033722]\n",
      "epoch:0 step:394 [D loss: 0.680442, acc.: 60.94%] [G loss: 1.156281]\n",
      "epoch:0 step:395 [D loss: 0.684539, acc.: 61.72%] [G loss: 1.116550]\n",
      "epoch:0 step:396 [D loss: 0.756623, acc.: 50.00%] [G loss: 1.136803]\n",
      "epoch:0 step:397 [D loss: 0.751755, acc.: 43.75%] [G loss: 0.975907]\n",
      "epoch:0 step:398 [D loss: 0.781822, acc.: 53.91%] [G loss: 0.883666]\n",
      "epoch:0 step:399 [D loss: 0.660385, acc.: 62.50%] [G loss: 1.258812]\n",
      "epoch:0 step:400 [D loss: 0.749436, acc.: 53.91%] [G loss: 1.079464]\n",
      "##############\n",
      "[2.72826207 1.45788109 6.79818948 5.4747496  3.97511526 6.01344313\n",
      " 5.01148117 5.1616143  5.43920161 3.76143586]\n",
      "##########\n",
      "epoch:0 step:401 [D loss: 0.728596, acc.: 56.25%] [G loss: 1.118357]\n",
      "epoch:0 step:402 [D loss: 0.691107, acc.: 54.69%] [G loss: 1.001977]\n",
      "epoch:0 step:403 [D loss: 0.739828, acc.: 52.34%] [G loss: 1.001662]\n",
      "epoch:0 step:404 [D loss: 0.717710, acc.: 55.47%] [G loss: 0.930941]\n",
      "epoch:0 step:405 [D loss: 0.689309, acc.: 56.25%] [G loss: 0.990090]\n",
      "epoch:0 step:406 [D loss: 0.734141, acc.: 48.44%] [G loss: 1.157921]\n",
      "epoch:0 step:407 [D loss: 0.729014, acc.: 51.56%] [G loss: 1.132304]\n",
      "epoch:0 step:408 [D loss: 0.752232, acc.: 50.00%] [G loss: 1.053082]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:409 [D loss: 0.824496, acc.: 46.09%] [G loss: 1.093808]\n",
      "epoch:0 step:410 [D loss: 0.795154, acc.: 47.66%] [G loss: 1.092709]\n",
      "epoch:0 step:411 [D loss: 0.811240, acc.: 46.09%] [G loss: 1.080116]\n",
      "epoch:0 step:412 [D loss: 0.765280, acc.: 52.34%] [G loss: 1.045914]\n",
      "epoch:0 step:413 [D loss: 0.741008, acc.: 50.00%] [G loss: 1.031773]\n",
      "epoch:0 step:414 [D loss: 0.718126, acc.: 55.47%] [G loss: 1.003462]\n",
      "epoch:0 step:415 [D loss: 0.684526, acc.: 57.81%] [G loss: 0.961490]\n",
      "epoch:0 step:416 [D loss: 0.826328, acc.: 48.44%] [G loss: 1.002316]\n",
      "epoch:0 step:417 [D loss: 0.824065, acc.: 50.78%] [G loss: 1.026494]\n",
      "epoch:0 step:418 [D loss: 0.746421, acc.: 49.22%] [G loss: 1.059024]\n",
      "epoch:0 step:419 [D loss: 0.761283, acc.: 56.25%] [G loss: 0.957641]\n",
      "epoch:0 step:420 [D loss: 0.625644, acc.: 62.50%] [G loss: 1.184703]\n",
      "epoch:0 step:421 [D loss: 0.778185, acc.: 51.56%] [G loss: 0.983758]\n",
      "epoch:0 step:422 [D loss: 0.751223, acc.: 47.66%] [G loss: 1.048155]\n",
      "epoch:0 step:423 [D loss: 0.761098, acc.: 51.56%] [G loss: 0.924114]\n",
      "epoch:0 step:424 [D loss: 0.744803, acc.: 57.03%] [G loss: 1.073636]\n",
      "epoch:0 step:425 [D loss: 0.701478, acc.: 52.34%] [G loss: 1.135114]\n",
      "epoch:0 step:426 [D loss: 0.738776, acc.: 50.78%] [G loss: 1.118359]\n",
      "epoch:0 step:427 [D loss: 0.698232, acc.: 53.91%] [G loss: 1.132913]\n",
      "epoch:0 step:428 [D loss: 0.657854, acc.: 60.94%] [G loss: 1.131551]\n",
      "epoch:0 step:429 [D loss: 0.589027, acc.: 66.41%] [G loss: 1.079484]\n",
      "epoch:0 step:430 [D loss: 0.621800, acc.: 66.41%] [G loss: 1.200586]\n",
      "epoch:0 step:431 [D loss: 0.768629, acc.: 50.00%] [G loss: 1.084513]\n",
      "epoch:0 step:432 [D loss: 0.804257, acc.: 50.00%] [G loss: 1.173733]\n",
      "epoch:0 step:433 [D loss: 0.722131, acc.: 56.25%] [G loss: 1.092461]\n",
      "epoch:0 step:434 [D loss: 0.715773, acc.: 58.59%] [G loss: 1.114162]\n",
      "epoch:0 step:435 [D loss: 0.601551, acc.: 67.97%] [G loss: 1.157248]\n",
      "epoch:0 step:436 [D loss: 0.705239, acc.: 50.78%] [G loss: 1.102905]\n",
      "epoch:0 step:437 [D loss: 0.801713, acc.: 48.44%] [G loss: 0.878907]\n",
      "epoch:0 step:438 [D loss: 0.739480, acc.: 51.56%] [G loss: 0.913078]\n",
      "epoch:0 step:439 [D loss: 0.795661, acc.: 46.09%] [G loss: 0.867123]\n",
      "epoch:0 step:440 [D loss: 0.729693, acc.: 51.56%] [G loss: 1.105580]\n",
      "epoch:0 step:441 [D loss: 0.645446, acc.: 64.06%] [G loss: 0.987329]\n",
      "epoch:0 step:442 [D loss: 0.782078, acc.: 46.09%] [G loss: 1.008715]\n",
      "epoch:0 step:443 [D loss: 0.685128, acc.: 57.03%] [G loss: 0.932026]\n",
      "epoch:0 step:444 [D loss: 0.821758, acc.: 48.44%] [G loss: 1.005341]\n",
      "epoch:0 step:445 [D loss: 0.705155, acc.: 53.91%] [G loss: 0.934983]\n",
      "epoch:0 step:446 [D loss: 0.734860, acc.: 50.00%] [G loss: 0.842600]\n",
      "epoch:0 step:447 [D loss: 0.737751, acc.: 51.56%] [G loss: 0.974253]\n",
      "epoch:0 step:448 [D loss: 0.780166, acc.: 49.22%] [G loss: 0.959222]\n",
      "epoch:0 step:449 [D loss: 0.726299, acc.: 58.59%] [G loss: 1.013695]\n",
      "epoch:0 step:450 [D loss: 0.656725, acc.: 57.03%] [G loss: 1.011350]\n",
      "epoch:0 step:451 [D loss: 0.685638, acc.: 57.03%] [G loss: 1.141553]\n",
      "epoch:0 step:452 [D loss: 0.704464, acc.: 59.38%] [G loss: 1.040735]\n",
      "epoch:0 step:453 [D loss: 0.733420, acc.: 58.59%] [G loss: 0.973244]\n",
      "epoch:0 step:454 [D loss: 0.747517, acc.: 48.44%] [G loss: 0.930880]\n",
      "epoch:0 step:455 [D loss: 0.753851, acc.: 56.25%] [G loss: 1.074335]\n",
      "epoch:0 step:456 [D loss: 0.708449, acc.: 52.34%] [G loss: 1.094742]\n",
      "epoch:0 step:457 [D loss: 0.727869, acc.: 59.38%] [G loss: 1.074346]\n",
      "epoch:0 step:458 [D loss: 0.736370, acc.: 54.69%] [G loss: 1.011442]\n",
      "epoch:0 step:459 [D loss: 0.754306, acc.: 50.78%] [G loss: 0.978055]\n",
      "epoch:0 step:460 [D loss: 0.718483, acc.: 60.94%] [G loss: 0.884897]\n",
      "epoch:0 step:461 [D loss: 0.692521, acc.: 54.69%] [G loss: 1.108858]\n",
      "epoch:0 step:462 [D loss: 0.732000, acc.: 55.47%] [G loss: 0.963971]\n",
      "epoch:0 step:463 [D loss: 0.668863, acc.: 56.25%] [G loss: 1.048345]\n",
      "epoch:0 step:464 [D loss: 0.732860, acc.: 50.78%] [G loss: 0.962782]\n",
      "epoch:0 step:465 [D loss: 0.774762, acc.: 53.12%] [G loss: 1.104574]\n",
      "epoch:0 step:466 [D loss: 0.721059, acc.: 55.47%] [G loss: 1.096671]\n",
      "epoch:0 step:467 [D loss: 0.758465, acc.: 51.56%] [G loss: 1.088337]\n",
      "epoch:0 step:468 [D loss: 0.818240, acc.: 42.19%] [G loss: 1.106854]\n",
      "epoch:0 step:469 [D loss: 0.756329, acc.: 49.22%] [G loss: 0.974714]\n",
      "epoch:0 step:470 [D loss: 0.779486, acc.: 46.09%] [G loss: 1.044861]\n",
      "epoch:0 step:471 [D loss: 0.779245, acc.: 46.88%] [G loss: 0.955832]\n",
      "epoch:0 step:472 [D loss: 0.719678, acc.: 55.47%] [G loss: 1.017856]\n",
      "epoch:0 step:473 [D loss: 0.727028, acc.: 51.56%] [G loss: 0.845885]\n",
      "epoch:0 step:474 [D loss: 0.631486, acc.: 64.84%] [G loss: 1.025662]\n",
      "epoch:0 step:475 [D loss: 0.672459, acc.: 60.94%] [G loss: 1.084525]\n",
      "epoch:0 step:476 [D loss: 0.682251, acc.: 57.03%] [G loss: 1.145792]\n",
      "epoch:0 step:477 [D loss: 0.774150, acc.: 46.09%] [G loss: 1.075092]\n",
      "epoch:0 step:478 [D loss: 0.721355, acc.: 55.47%] [G loss: 0.826116]\n",
      "epoch:0 step:479 [D loss: 0.733451, acc.: 53.91%] [G loss: 1.054847]\n",
      "epoch:0 step:480 [D loss: 0.715157, acc.: 57.03%] [G loss: 1.057130]\n",
      "epoch:0 step:481 [D loss: 0.802281, acc.: 46.09%] [G loss: 0.873455]\n",
      "epoch:0 step:482 [D loss: 0.705171, acc.: 58.59%] [G loss: 1.101072]\n",
      "epoch:0 step:483 [D loss: 0.707257, acc.: 49.22%] [G loss: 1.069336]\n",
      "epoch:0 step:484 [D loss: 0.756292, acc.: 50.78%] [G loss: 1.100199]\n",
      "epoch:0 step:485 [D loss: 0.641053, acc.: 61.72%] [G loss: 1.053694]\n",
      "epoch:0 step:486 [D loss: 0.666977, acc.: 59.38%] [G loss: 1.159451]\n",
      "epoch:0 step:487 [D loss: 0.641782, acc.: 62.50%] [G loss: 1.141978]\n",
      "epoch:0 step:488 [D loss: 0.700253, acc.: 61.72%] [G loss: 1.101770]\n",
      "epoch:0 step:489 [D loss: 0.792121, acc.: 49.22%] [G loss: 1.078797]\n",
      "epoch:0 step:490 [D loss: 0.824865, acc.: 46.88%] [G loss: 1.022967]\n",
      "epoch:0 step:491 [D loss: 0.695300, acc.: 57.81%] [G loss: 0.992058]\n",
      "epoch:0 step:492 [D loss: 0.735031, acc.: 53.12%] [G loss: 0.984806]\n",
      "epoch:0 step:493 [D loss: 0.684965, acc.: 62.50%] [G loss: 1.013860]\n",
      "epoch:0 step:494 [D loss: 0.726302, acc.: 57.81%] [G loss: 0.963764]\n",
      "epoch:0 step:495 [D loss: 0.745064, acc.: 53.12%] [G loss: 1.089036]\n",
      "epoch:0 step:496 [D loss: 0.645303, acc.: 63.28%] [G loss: 1.109446]\n",
      "epoch:0 step:497 [D loss: 0.739190, acc.: 53.12%] [G loss: 1.013392]\n",
      "epoch:0 step:498 [D loss: 0.623701, acc.: 63.28%] [G loss: 1.277948]\n",
      "epoch:0 step:499 [D loss: 0.638334, acc.: 63.28%] [G loss: 1.094712]\n",
      "epoch:0 step:500 [D loss: 0.788710, acc.: 49.22%] [G loss: 0.905614]\n",
      "epoch:0 step:501 [D loss: 0.860363, acc.: 49.22%] [G loss: 1.031029]\n",
      "epoch:0 step:502 [D loss: 0.675549, acc.: 58.59%] [G loss: 1.039800]\n",
      "epoch:0 step:503 [D loss: 0.691009, acc.: 60.16%] [G loss: 0.925728]\n",
      "epoch:0 step:504 [D loss: 0.757748, acc.: 49.22%] [G loss: 1.046004]\n",
      "epoch:0 step:505 [D loss: 0.810615, acc.: 47.66%] [G loss: 0.960936]\n",
      "epoch:0 step:506 [D loss: 0.654420, acc.: 60.94%] [G loss: 1.036342]\n",
      "epoch:0 step:507 [D loss: 0.659036, acc.: 60.16%] [G loss: 1.051734]\n",
      "epoch:0 step:508 [D loss: 0.658944, acc.: 60.94%] [G loss: 1.267276]\n",
      "epoch:0 step:509 [D loss: 0.687072, acc.: 53.12%] [G loss: 1.065446]\n",
      "epoch:0 step:510 [D loss: 0.670140, acc.: 67.19%] [G loss: 1.150091]\n",
      "epoch:0 step:511 [D loss: 0.761636, acc.: 47.66%] [G loss: 0.972845]\n",
      "epoch:0 step:512 [D loss: 0.747868, acc.: 54.69%] [G loss: 1.015459]\n",
      "epoch:0 step:513 [D loss: 0.619732, acc.: 71.09%] [G loss: 1.091548]\n",
      "epoch:0 step:514 [D loss: 0.598571, acc.: 72.66%] [G loss: 1.141398]\n",
      "epoch:0 step:515 [D loss: 0.689657, acc.: 63.28%] [G loss: 1.025845]\n",
      "epoch:0 step:516 [D loss: 0.702542, acc.: 57.81%] [G loss: 0.999395]\n",
      "epoch:0 step:517 [D loss: 0.794883, acc.: 46.09%] [G loss: 0.980895]\n",
      "epoch:0 step:518 [D loss: 0.713604, acc.: 56.25%] [G loss: 1.033550]\n",
      "epoch:0 step:519 [D loss: 0.706397, acc.: 53.91%] [G loss: 1.086948]\n",
      "epoch:0 step:520 [D loss: 0.708404, acc.: 58.59%] [G loss: 1.046119]\n",
      "epoch:0 step:521 [D loss: 0.667811, acc.: 60.16%] [G loss: 1.126420]\n",
      "epoch:0 step:522 [D loss: 0.699165, acc.: 60.94%] [G loss: 1.050253]\n",
      "epoch:0 step:523 [D loss: 0.729827, acc.: 56.25%] [G loss: 1.041590]\n",
      "epoch:0 step:524 [D loss: 0.709669, acc.: 52.34%] [G loss: 1.106959]\n",
      "epoch:0 step:525 [D loss: 0.680572, acc.: 57.03%] [G loss: 1.070567]\n",
      "epoch:0 step:526 [D loss: 0.705563, acc.: 57.81%] [G loss: 0.909470]\n",
      "epoch:0 step:527 [D loss: 0.707733, acc.: 54.69%] [G loss: 0.977220]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:528 [D loss: 0.653253, acc.: 63.28%] [G loss: 1.102423]\n",
      "epoch:0 step:529 [D loss: 0.783822, acc.: 51.56%] [G loss: 1.005393]\n",
      "epoch:0 step:530 [D loss: 0.698908, acc.: 58.59%] [G loss: 1.047570]\n",
      "epoch:0 step:531 [D loss: 0.742539, acc.: 53.91%] [G loss: 1.016666]\n",
      "epoch:0 step:532 [D loss: 0.702574, acc.: 53.12%] [G loss: 0.903633]\n",
      "epoch:0 step:533 [D loss: 0.793969, acc.: 46.09%] [G loss: 0.986337]\n",
      "epoch:0 step:534 [D loss: 0.752057, acc.: 50.78%] [G loss: 1.005375]\n",
      "epoch:0 step:535 [D loss: 0.694666, acc.: 57.03%] [G loss: 1.123720]\n",
      "epoch:0 step:536 [D loss: 0.713295, acc.: 57.81%] [G loss: 0.958445]\n",
      "epoch:0 step:537 [D loss: 0.705912, acc.: 52.34%] [G loss: 1.048229]\n",
      "epoch:0 step:538 [D loss: 0.778665, acc.: 51.56%] [G loss: 1.055656]\n",
      "epoch:0 step:539 [D loss: 0.711676, acc.: 51.56%] [G loss: 1.020207]\n",
      "epoch:0 step:540 [D loss: 0.656541, acc.: 66.41%] [G loss: 1.079431]\n",
      "epoch:0 step:541 [D loss: 0.640650, acc.: 62.50%] [G loss: 1.092942]\n",
      "epoch:0 step:542 [D loss: 0.768736, acc.: 48.44%] [G loss: 1.162420]\n",
      "epoch:0 step:543 [D loss: 0.765796, acc.: 47.66%] [G loss: 1.049694]\n",
      "epoch:0 step:544 [D loss: 0.698519, acc.: 60.16%] [G loss: 1.000336]\n",
      "epoch:0 step:545 [D loss: 0.795721, acc.: 47.66%] [G loss: 1.118262]\n",
      "epoch:0 step:546 [D loss: 0.657279, acc.: 65.62%] [G loss: 1.087769]\n",
      "epoch:0 step:547 [D loss: 0.710415, acc.: 53.91%] [G loss: 1.132002]\n",
      "epoch:0 step:548 [D loss: 0.740596, acc.: 56.25%] [G loss: 1.105931]\n",
      "epoch:0 step:549 [D loss: 0.766179, acc.: 45.31%] [G loss: 1.058744]\n",
      "epoch:0 step:550 [D loss: 0.742834, acc.: 53.91%] [G loss: 1.246169]\n",
      "epoch:0 step:551 [D loss: 0.628468, acc.: 66.41%] [G loss: 1.162168]\n",
      "epoch:0 step:552 [D loss: 0.611051, acc.: 64.84%] [G loss: 1.189081]\n",
      "epoch:0 step:553 [D loss: 0.806083, acc.: 51.56%] [G loss: 1.055454]\n",
      "epoch:0 step:554 [D loss: 0.653824, acc.: 60.16%] [G loss: 1.047323]\n",
      "epoch:0 step:555 [D loss: 0.706246, acc.: 57.81%] [G loss: 1.029702]\n",
      "epoch:0 step:556 [D loss: 0.717258, acc.: 55.47%] [G loss: 1.032817]\n",
      "epoch:0 step:557 [D loss: 0.601396, acc.: 70.31%] [G loss: 1.093475]\n",
      "epoch:0 step:558 [D loss: 0.704313, acc.: 58.59%] [G loss: 1.160424]\n",
      "epoch:0 step:559 [D loss: 0.709043, acc.: 58.59%] [G loss: 1.171903]\n",
      "epoch:0 step:560 [D loss: 0.784635, acc.: 45.31%] [G loss: 1.094632]\n",
      "epoch:0 step:561 [D loss: 0.726551, acc.: 57.03%] [G loss: 0.973202]\n",
      "epoch:0 step:562 [D loss: 0.763385, acc.: 48.44%] [G loss: 1.019010]\n",
      "epoch:0 step:563 [D loss: 0.715012, acc.: 54.69%] [G loss: 1.110369]\n",
      "epoch:0 step:564 [D loss: 0.693764, acc.: 56.25%] [G loss: 1.078082]\n",
      "epoch:0 step:565 [D loss: 0.729828, acc.: 55.47%] [G loss: 0.955169]\n",
      "epoch:0 step:566 [D loss: 0.828828, acc.: 45.31%] [G loss: 1.051378]\n",
      "epoch:0 step:567 [D loss: 0.692286, acc.: 60.16%] [G loss: 1.093978]\n",
      "epoch:0 step:568 [D loss: 0.613303, acc.: 70.31%] [G loss: 1.219886]\n",
      "epoch:0 step:569 [D loss: 0.810327, acc.: 46.09%] [G loss: 0.818301]\n",
      "epoch:0 step:570 [D loss: 0.776553, acc.: 53.91%] [G loss: 0.941469]\n",
      "epoch:0 step:571 [D loss: 0.669686, acc.: 60.94%] [G loss: 1.113309]\n",
      "epoch:0 step:572 [D loss: 0.867925, acc.: 40.62%] [G loss: 0.936779]\n",
      "epoch:0 step:573 [D loss: 0.769100, acc.: 53.12%] [G loss: 1.009081]\n",
      "epoch:0 step:574 [D loss: 0.687787, acc.: 58.59%] [G loss: 1.016731]\n",
      "epoch:0 step:575 [D loss: 0.666194, acc.: 57.03%] [G loss: 1.081830]\n",
      "epoch:0 step:576 [D loss: 0.799492, acc.: 53.12%] [G loss: 1.169561]\n",
      "epoch:0 step:577 [D loss: 0.765268, acc.: 53.91%] [G loss: 1.038102]\n",
      "epoch:0 step:578 [D loss: 0.716220, acc.: 54.69%] [G loss: 1.120366]\n",
      "epoch:0 step:579 [D loss: 0.677355, acc.: 61.72%] [G loss: 1.041312]\n",
      "epoch:0 step:580 [D loss: 0.778481, acc.: 47.66%] [G loss: 1.095238]\n",
      "epoch:0 step:581 [D loss: 0.753392, acc.: 50.78%] [G loss: 1.042598]\n",
      "epoch:0 step:582 [D loss: 0.709507, acc.: 53.12%] [G loss: 1.077789]\n",
      "epoch:0 step:583 [D loss: 0.748513, acc.: 54.69%] [G loss: 1.084037]\n",
      "epoch:0 step:584 [D loss: 0.724536, acc.: 59.38%] [G loss: 1.000458]\n",
      "epoch:0 step:585 [D loss: 0.715206, acc.: 60.16%] [G loss: 1.018672]\n",
      "epoch:0 step:586 [D loss: 0.636941, acc.: 64.06%] [G loss: 1.118278]\n",
      "epoch:0 step:587 [D loss: 0.647395, acc.: 61.72%] [G loss: 1.170962]\n",
      "epoch:0 step:588 [D loss: 0.624166, acc.: 66.41%] [G loss: 1.137116]\n",
      "epoch:0 step:589 [D loss: 0.690508, acc.: 57.81%] [G loss: 1.112339]\n",
      "epoch:0 step:590 [D loss: 0.739222, acc.: 47.66%] [G loss: 1.195334]\n",
      "epoch:0 step:591 [D loss: 0.815559, acc.: 46.09%] [G loss: 0.963607]\n",
      "epoch:0 step:592 [D loss: 0.759361, acc.: 42.97%] [G loss: 0.883375]\n",
      "epoch:0 step:593 [D loss: 0.765971, acc.: 53.12%] [G loss: 0.970792]\n",
      "epoch:0 step:594 [D loss: 0.706998, acc.: 62.50%] [G loss: 0.959605]\n",
      "epoch:0 step:595 [D loss: 0.699789, acc.: 59.38%] [G loss: 0.997430]\n",
      "epoch:0 step:596 [D loss: 0.737591, acc.: 58.59%] [G loss: 1.042744]\n",
      "epoch:0 step:597 [D loss: 0.710967, acc.: 52.34%] [G loss: 1.067141]\n",
      "epoch:0 step:598 [D loss: 0.681510, acc.: 57.03%] [G loss: 0.976340]\n",
      "epoch:0 step:599 [D loss: 0.766682, acc.: 53.91%] [G loss: 0.987953]\n",
      "epoch:0 step:600 [D loss: 0.744103, acc.: 50.78%] [G loss: 1.035842]\n",
      "##############\n",
      "[2.97951246 1.1099681  6.53653606 5.16761229 3.99631137 5.87452852\n",
      " 4.7837716  4.67345253 5.15931271 3.71929906]\n",
      "##########\n",
      "epoch:0 step:601 [D loss: 0.700897, acc.: 53.91%] [G loss: 1.026929]\n",
      "epoch:0 step:602 [D loss: 0.669910, acc.: 57.03%] [G loss: 1.112251]\n",
      "epoch:0 step:603 [D loss: 0.724281, acc.: 50.78%] [G loss: 1.063722]\n",
      "epoch:0 step:604 [D loss: 0.718172, acc.: 56.25%] [G loss: 1.072683]\n",
      "epoch:0 step:605 [D loss: 0.644811, acc.: 62.50%] [G loss: 1.192613]\n",
      "epoch:0 step:606 [D loss: 0.692773, acc.: 57.81%] [G loss: 0.994959]\n",
      "epoch:0 step:607 [D loss: 0.788971, acc.: 48.44%] [G loss: 1.050517]\n",
      "epoch:0 step:608 [D loss: 0.641801, acc.: 63.28%] [G loss: 1.078244]\n",
      "epoch:0 step:609 [D loss: 0.685417, acc.: 58.59%] [G loss: 1.087379]\n",
      "epoch:0 step:610 [D loss: 0.682262, acc.: 57.81%] [G loss: 1.039352]\n",
      "epoch:0 step:611 [D loss: 0.715843, acc.: 55.47%] [G loss: 0.931537]\n",
      "epoch:0 step:612 [D loss: 0.692470, acc.: 60.94%] [G loss: 0.999989]\n",
      "epoch:0 step:613 [D loss: 0.638268, acc.: 62.50%] [G loss: 0.998905]\n",
      "epoch:0 step:614 [D loss: 0.772814, acc.: 51.56%] [G loss: 1.006001]\n",
      "epoch:0 step:615 [D loss: 0.710471, acc.: 57.81%] [G loss: 1.102350]\n",
      "epoch:0 step:616 [D loss: 0.738971, acc.: 46.88%] [G loss: 0.988978]\n",
      "epoch:0 step:617 [D loss: 0.773584, acc.: 49.22%] [G loss: 1.029225]\n",
      "epoch:0 step:618 [D loss: 0.745074, acc.: 50.00%] [G loss: 0.900518]\n",
      "epoch:0 step:619 [D loss: 0.713907, acc.: 53.91%] [G loss: 1.057384]\n",
      "epoch:0 step:620 [D loss: 0.719764, acc.: 56.25%] [G loss: 1.088273]\n",
      "epoch:0 step:621 [D loss: 0.634204, acc.: 60.16%] [G loss: 1.125409]\n",
      "epoch:0 step:622 [D loss: 0.777853, acc.: 45.31%] [G loss: 1.151540]\n",
      "epoch:0 step:623 [D loss: 0.738606, acc.: 58.59%] [G loss: 1.083018]\n",
      "epoch:0 step:624 [D loss: 0.753944, acc.: 51.56%] [G loss: 1.030776]\n",
      "epoch:0 step:625 [D loss: 0.685437, acc.: 59.38%] [G loss: 1.035710]\n",
      "epoch:0 step:626 [D loss: 0.778916, acc.: 46.09%] [G loss: 1.202753]\n",
      "epoch:0 step:627 [D loss: 0.696712, acc.: 57.03%] [G loss: 1.184555]\n",
      "epoch:0 step:628 [D loss: 0.664708, acc.: 59.38%] [G loss: 1.096067]\n",
      "epoch:0 step:629 [D loss: 0.659834, acc.: 60.94%] [G loss: 1.076926]\n",
      "epoch:0 step:630 [D loss: 0.648937, acc.: 65.62%] [G loss: 1.029787]\n",
      "epoch:0 step:631 [D loss: 0.684101, acc.: 61.72%] [G loss: 1.032813]\n",
      "epoch:0 step:632 [D loss: 0.739703, acc.: 57.03%] [G loss: 1.101159]\n",
      "epoch:0 step:633 [D loss: 0.698211, acc.: 57.81%] [G loss: 1.004210]\n",
      "epoch:0 step:634 [D loss: 0.662238, acc.: 60.16%] [G loss: 1.046061]\n",
      "epoch:0 step:635 [D loss: 0.706891, acc.: 58.59%] [G loss: 1.052824]\n",
      "epoch:0 step:636 [D loss: 0.848171, acc.: 46.88%] [G loss: 0.920190]\n",
      "epoch:0 step:637 [D loss: 0.672844, acc.: 60.16%] [G loss: 1.057195]\n",
      "epoch:0 step:638 [D loss: 0.720714, acc.: 50.00%] [G loss: 1.064152]\n",
      "epoch:0 step:639 [D loss: 0.692245, acc.: 57.81%] [G loss: 1.115870]\n",
      "epoch:0 step:640 [D loss: 0.710982, acc.: 53.91%] [G loss: 0.895253]\n",
      "epoch:0 step:641 [D loss: 0.672366, acc.: 58.59%] [G loss: 1.051282]\n",
      "epoch:0 step:642 [D loss: 0.658062, acc.: 60.94%] [G loss: 1.024823]\n",
      "epoch:0 step:643 [D loss: 0.668441, acc.: 61.72%] [G loss: 1.191067]\n",
      "epoch:0 step:644 [D loss: 0.695901, acc.: 55.47%] [G loss: 1.005719]\n",
      "epoch:0 step:645 [D loss: 0.775459, acc.: 48.44%] [G loss: 0.930786]\n",
      "epoch:0 step:646 [D loss: 0.842677, acc.: 44.53%] [G loss: 1.086200]\n",
      "epoch:0 step:647 [D loss: 0.760388, acc.: 50.78%] [G loss: 1.096144]\n",
      "epoch:0 step:648 [D loss: 0.635063, acc.: 63.28%] [G loss: 1.029752]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:649 [D loss: 0.730603, acc.: 54.69%] [G loss: 1.016426]\n",
      "epoch:0 step:650 [D loss: 0.679846, acc.: 57.81%] [G loss: 1.048333]\n",
      "epoch:0 step:651 [D loss: 0.685084, acc.: 57.81%] [G loss: 1.033846]\n",
      "epoch:0 step:652 [D loss: 0.821955, acc.: 46.09%] [G loss: 0.931715]\n",
      "epoch:0 step:653 [D loss: 0.703234, acc.: 53.91%] [G loss: 1.080786]\n",
      "epoch:0 step:654 [D loss: 0.715069, acc.: 57.03%] [G loss: 0.897327]\n",
      "epoch:0 step:655 [D loss: 0.749357, acc.: 52.34%] [G loss: 1.019691]\n",
      "epoch:0 step:656 [D loss: 0.667505, acc.: 54.69%] [G loss: 0.968832]\n",
      "epoch:0 step:657 [D loss: 0.825283, acc.: 49.22%] [G loss: 1.041031]\n",
      "epoch:0 step:658 [D loss: 0.703202, acc.: 60.16%] [G loss: 1.040963]\n",
      "epoch:0 step:659 [D loss: 0.712564, acc.: 56.25%] [G loss: 0.906048]\n",
      "epoch:0 step:660 [D loss: 0.734155, acc.: 53.12%] [G loss: 0.918823]\n",
      "epoch:0 step:661 [D loss: 0.620933, acc.: 68.75%] [G loss: 1.076673]\n",
      "epoch:0 step:662 [D loss: 0.810656, acc.: 49.22%] [G loss: 1.023744]\n",
      "epoch:0 step:663 [D loss: 0.736974, acc.: 53.91%] [G loss: 1.001114]\n",
      "epoch:0 step:664 [D loss: 0.730492, acc.: 59.38%] [G loss: 1.070099]\n",
      "epoch:0 step:665 [D loss: 0.644352, acc.: 59.38%] [G loss: 1.025481]\n",
      "epoch:0 step:666 [D loss: 0.659201, acc.: 60.94%] [G loss: 1.123377]\n",
      "epoch:0 step:667 [D loss: 0.667462, acc.: 56.25%] [G loss: 1.054501]\n",
      "epoch:0 step:668 [D loss: 0.694357, acc.: 59.38%] [G loss: 1.237025]\n",
      "epoch:0 step:669 [D loss: 0.740286, acc.: 54.69%] [G loss: 1.103791]\n",
      "epoch:0 step:670 [D loss: 0.793303, acc.: 53.12%] [G loss: 0.987006]\n",
      "epoch:0 step:671 [D loss: 0.727178, acc.: 50.78%] [G loss: 0.890774]\n",
      "epoch:0 step:672 [D loss: 0.689104, acc.: 60.94%] [G loss: 0.954749]\n",
      "epoch:0 step:673 [D loss: 0.745519, acc.: 49.22%] [G loss: 0.955683]\n",
      "epoch:0 step:674 [D loss: 0.760160, acc.: 52.34%] [G loss: 0.767965]\n",
      "epoch:0 step:675 [D loss: 0.738605, acc.: 56.25%] [G loss: 0.991686]\n",
      "epoch:0 step:676 [D loss: 0.803868, acc.: 48.44%] [G loss: 0.970114]\n",
      "epoch:0 step:677 [D loss: 0.627160, acc.: 64.06%] [G loss: 1.035512]\n",
      "epoch:0 step:678 [D loss: 0.670979, acc.: 60.94%] [G loss: 1.012704]\n",
      "epoch:0 step:679 [D loss: 0.775731, acc.: 50.00%] [G loss: 0.846804]\n",
      "epoch:0 step:680 [D loss: 0.690948, acc.: 61.72%] [G loss: 0.921526]\n",
      "epoch:0 step:681 [D loss: 0.721321, acc.: 49.22%] [G loss: 0.950623]\n",
      "epoch:0 step:682 [D loss: 0.751181, acc.: 50.78%] [G loss: 1.077617]\n",
      "epoch:0 step:683 [D loss: 0.810902, acc.: 49.22%] [G loss: 0.880334]\n",
      "epoch:0 step:684 [D loss: 0.735386, acc.: 51.56%] [G loss: 1.049560]\n",
      "epoch:0 step:685 [D loss: 0.701331, acc.: 58.59%] [G loss: 0.939071]\n",
      "epoch:0 step:686 [D loss: 0.634448, acc.: 60.94%] [G loss: 0.927512]\n",
      "epoch:0 step:687 [D loss: 0.743257, acc.: 54.69%] [G loss: 0.917416]\n",
      "epoch:0 step:688 [D loss: 0.671838, acc.: 61.72%] [G loss: 1.030819]\n",
      "epoch:0 step:689 [D loss: 0.702470, acc.: 58.59%] [G loss: 1.021215]\n",
      "epoch:0 step:690 [D loss: 0.709086, acc.: 56.25%] [G loss: 0.915421]\n",
      "epoch:0 step:691 [D loss: 0.670009, acc.: 60.16%] [G loss: 1.017128]\n",
      "epoch:0 step:692 [D loss: 0.683804, acc.: 58.59%] [G loss: 1.018553]\n",
      "epoch:0 step:693 [D loss: 0.685731, acc.: 57.03%] [G loss: 0.884542]\n",
      "epoch:0 step:694 [D loss: 0.717791, acc.: 53.91%] [G loss: 1.140233]\n",
      "epoch:0 step:695 [D loss: 0.623773, acc.: 64.06%] [G loss: 1.003926]\n",
      "epoch:0 step:696 [D loss: 0.718621, acc.: 54.69%] [G loss: 1.032665]\n",
      "epoch:0 step:697 [D loss: 0.688430, acc.: 56.25%] [G loss: 1.178105]\n",
      "epoch:0 step:698 [D loss: 0.776866, acc.: 50.78%] [G loss: 1.024680]\n",
      "epoch:0 step:699 [D loss: 0.744678, acc.: 52.34%] [G loss: 0.989132]\n",
      "epoch:0 step:700 [D loss: 0.739109, acc.: 47.66%] [G loss: 0.921195]\n",
      "epoch:0 step:701 [D loss: 0.708250, acc.: 56.25%] [G loss: 1.086080]\n",
      "epoch:0 step:702 [D loss: 0.684075, acc.: 59.38%] [G loss: 0.889973]\n",
      "epoch:0 step:703 [D loss: 0.756667, acc.: 49.22%] [G loss: 1.057046]\n",
      "epoch:0 step:704 [D loss: 0.850424, acc.: 40.62%] [G loss: 0.853438]\n",
      "epoch:0 step:705 [D loss: 0.738191, acc.: 51.56%] [G loss: 1.052293]\n",
      "epoch:0 step:706 [D loss: 0.672261, acc.: 61.72%] [G loss: 0.990022]\n",
      "epoch:0 step:707 [D loss: 0.637239, acc.: 61.72%] [G loss: 1.080212]\n",
      "epoch:0 step:708 [D loss: 0.699899, acc.: 58.59%] [G loss: 1.017449]\n",
      "epoch:0 step:709 [D loss: 0.723181, acc.: 52.34%] [G loss: 1.199712]\n",
      "epoch:0 step:710 [D loss: 0.721271, acc.: 57.81%] [G loss: 1.020193]\n",
      "epoch:0 step:711 [D loss: 0.760526, acc.: 49.22%] [G loss: 0.870895]\n",
      "epoch:0 step:712 [D loss: 0.602864, acc.: 71.09%] [G loss: 1.065743]\n",
      "epoch:0 step:713 [D loss: 0.669155, acc.: 60.94%] [G loss: 0.960268]\n",
      "epoch:0 step:714 [D loss: 0.651987, acc.: 60.94%] [G loss: 1.013898]\n",
      "epoch:0 step:715 [D loss: 0.682111, acc.: 60.16%] [G loss: 1.008658]\n",
      "epoch:0 step:716 [D loss: 0.778287, acc.: 52.34%] [G loss: 0.983688]\n",
      "epoch:0 step:717 [D loss: 0.719089, acc.: 59.38%] [G loss: 0.873654]\n",
      "epoch:0 step:718 [D loss: 0.700155, acc.: 56.25%] [G loss: 0.948448]\n",
      "epoch:0 step:719 [D loss: 0.773047, acc.: 46.09%] [G loss: 0.952322]\n",
      "epoch:0 step:720 [D loss: 0.686359, acc.: 58.59%] [G loss: 1.058085]\n",
      "epoch:0 step:721 [D loss: 0.697684, acc.: 54.69%] [G loss: 0.983931]\n",
      "epoch:0 step:722 [D loss: 0.755314, acc.: 52.34%] [G loss: 0.940651]\n",
      "epoch:0 step:723 [D loss: 0.718743, acc.: 53.91%] [G loss: 0.987904]\n",
      "epoch:0 step:724 [D loss: 0.663529, acc.: 57.03%] [G loss: 0.998689]\n",
      "epoch:0 step:725 [D loss: 0.730201, acc.: 55.47%] [G loss: 0.974640]\n",
      "epoch:0 step:726 [D loss: 0.754161, acc.: 51.56%] [G loss: 0.946017]\n",
      "epoch:0 step:727 [D loss: 0.775444, acc.: 50.78%] [G loss: 1.013322]\n",
      "epoch:0 step:728 [D loss: 0.666236, acc.: 62.50%] [G loss: 0.989994]\n",
      "epoch:0 step:729 [D loss: 0.674153, acc.: 60.16%] [G loss: 1.011261]\n",
      "epoch:0 step:730 [D loss: 0.836745, acc.: 36.72%] [G loss: 0.806921]\n",
      "epoch:0 step:731 [D loss: 0.731813, acc.: 54.69%] [G loss: 1.085981]\n",
      "epoch:0 step:732 [D loss: 0.805045, acc.: 48.44%] [G loss: 0.844456]\n",
      "epoch:0 step:733 [D loss: 0.708590, acc.: 53.12%] [G loss: 1.098546]\n",
      "epoch:0 step:734 [D loss: 0.688314, acc.: 55.47%] [G loss: 0.995415]\n",
      "epoch:0 step:735 [D loss: 0.826898, acc.: 44.53%] [G loss: 0.924187]\n",
      "epoch:0 step:736 [D loss: 0.715034, acc.: 51.56%] [G loss: 1.032711]\n",
      "epoch:0 step:737 [D loss: 0.729338, acc.: 51.56%] [G loss: 1.101872]\n",
      "epoch:0 step:738 [D loss: 0.683743, acc.: 57.81%] [G loss: 1.055025]\n",
      "epoch:0 step:739 [D loss: 0.729403, acc.: 54.69%] [G loss: 1.053198]\n",
      "epoch:0 step:740 [D loss: 0.764537, acc.: 49.22%] [G loss: 0.847606]\n",
      "epoch:0 step:741 [D loss: 0.738677, acc.: 54.69%] [G loss: 0.951120]\n",
      "epoch:0 step:742 [D loss: 0.753371, acc.: 51.56%] [G loss: 0.908931]\n",
      "epoch:0 step:743 [D loss: 0.669385, acc.: 62.50%] [G loss: 0.944122]\n",
      "epoch:0 step:744 [D loss: 0.714967, acc.: 57.03%] [G loss: 0.909910]\n",
      "epoch:0 step:745 [D loss: 0.712767, acc.: 54.69%] [G loss: 0.883052]\n",
      "epoch:0 step:746 [D loss: 0.712451, acc.: 57.03%] [G loss: 1.003508]\n",
      "epoch:0 step:747 [D loss: 0.678288, acc.: 56.25%] [G loss: 1.025956]\n",
      "epoch:0 step:748 [D loss: 0.742988, acc.: 50.00%] [G loss: 0.945431]\n",
      "epoch:0 step:749 [D loss: 0.688182, acc.: 59.38%] [G loss: 1.008305]\n",
      "epoch:0 step:750 [D loss: 0.649277, acc.: 61.72%] [G loss: 1.038297]\n",
      "epoch:0 step:751 [D loss: 0.699457, acc.: 55.47%] [G loss: 0.998001]\n",
      "epoch:0 step:752 [D loss: 0.796605, acc.: 47.66%] [G loss: 0.932494]\n",
      "epoch:0 step:753 [D loss: 0.714941, acc.: 57.03%] [G loss: 0.930960]\n",
      "epoch:0 step:754 [D loss: 0.702187, acc.: 57.81%] [G loss: 1.005320]\n",
      "epoch:0 step:755 [D loss: 0.710684, acc.: 54.69%] [G loss: 0.925781]\n",
      "epoch:0 step:756 [D loss: 0.726124, acc.: 52.34%] [G loss: 0.904736]\n",
      "epoch:0 step:757 [D loss: 0.668235, acc.: 63.28%] [G loss: 0.943425]\n",
      "epoch:0 step:758 [D loss: 0.702532, acc.: 56.25%] [G loss: 1.002361]\n",
      "epoch:0 step:759 [D loss: 0.745379, acc.: 48.44%] [G loss: 0.911497]\n",
      "epoch:0 step:760 [D loss: 0.788918, acc.: 44.53%] [G loss: 0.957282]\n",
      "epoch:0 step:761 [D loss: 0.724381, acc.: 52.34%] [G loss: 0.991538]\n",
      "epoch:0 step:762 [D loss: 0.757412, acc.: 46.88%] [G loss: 0.997145]\n",
      "epoch:0 step:763 [D loss: 0.730419, acc.: 53.12%] [G loss: 0.946267]\n",
      "epoch:0 step:764 [D loss: 0.800472, acc.: 42.97%] [G loss: 0.969887]\n",
      "epoch:0 step:765 [D loss: 0.753067, acc.: 43.75%] [G loss: 0.841088]\n",
      "epoch:0 step:766 [D loss: 0.754963, acc.: 50.78%] [G loss: 1.066967]\n",
      "epoch:0 step:767 [D loss: 0.772031, acc.: 52.34%] [G loss: 0.999948]\n",
      "epoch:0 step:768 [D loss: 0.753727, acc.: 50.78%] [G loss: 0.995098]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:769 [D loss: 0.726518, acc.: 52.34%] [G loss: 1.005868]\n",
      "epoch:0 step:770 [D loss: 0.709460, acc.: 55.47%] [G loss: 0.898218]\n",
      "epoch:0 step:771 [D loss: 0.700719, acc.: 50.78%] [G loss: 1.006663]\n",
      "epoch:0 step:772 [D loss: 0.690331, acc.: 56.25%] [G loss: 0.987978]\n",
      "epoch:0 step:773 [D loss: 0.728733, acc.: 52.34%] [G loss: 0.900362]\n",
      "epoch:0 step:774 [D loss: 0.739135, acc.: 60.16%] [G loss: 0.940438]\n",
      "epoch:0 step:775 [D loss: 0.683965, acc.: 62.50%] [G loss: 1.051083]\n",
      "epoch:0 step:776 [D loss: 0.719777, acc.: 56.25%] [G loss: 1.069081]\n",
      "epoch:0 step:777 [D loss: 0.612741, acc.: 66.41%] [G loss: 0.951228]\n",
      "epoch:0 step:778 [D loss: 0.816186, acc.: 41.41%] [G loss: 0.901785]\n",
      "epoch:0 step:779 [D loss: 0.723160, acc.: 53.12%] [G loss: 1.009073]\n",
      "epoch:0 step:780 [D loss: 0.720072, acc.: 54.69%] [G loss: 0.908363]\n",
      "epoch:0 step:781 [D loss: 0.739805, acc.: 50.00%] [G loss: 0.939778]\n",
      "epoch:0 step:782 [D loss: 0.686173, acc.: 62.50%] [G loss: 1.019036]\n",
      "epoch:0 step:783 [D loss: 0.678543, acc.: 57.03%] [G loss: 1.020001]\n",
      "epoch:0 step:784 [D loss: 0.682256, acc.: 58.59%] [G loss: 0.973894]\n",
      "epoch:0 step:785 [D loss: 0.692213, acc.: 54.69%] [G loss: 0.970611]\n",
      "epoch:0 step:786 [D loss: 0.655000, acc.: 61.72%] [G loss: 0.923331]\n",
      "epoch:0 step:787 [D loss: 0.745991, acc.: 56.25%] [G loss: 1.037141]\n",
      "epoch:0 step:788 [D loss: 0.742559, acc.: 53.91%] [G loss: 0.970173]\n",
      "epoch:0 step:789 [D loss: 0.681414, acc.: 54.69%] [G loss: 1.097718]\n",
      "epoch:0 step:790 [D loss: 0.704085, acc.: 57.03%] [G loss: 1.053026]\n",
      "epoch:0 step:791 [D loss: 0.721639, acc.: 54.69%] [G loss: 0.999630]\n",
      "epoch:0 step:792 [D loss: 0.741089, acc.: 53.91%] [G loss: 1.040713]\n",
      "epoch:0 step:793 [D loss: 0.704881, acc.: 56.25%] [G loss: 1.001721]\n",
      "epoch:0 step:794 [D loss: 0.840715, acc.: 47.66%] [G loss: 0.891136]\n",
      "epoch:0 step:795 [D loss: 0.750039, acc.: 49.22%] [G loss: 1.067769]\n",
      "epoch:0 step:796 [D loss: 0.693127, acc.: 56.25%] [G loss: 1.046965]\n",
      "epoch:0 step:797 [D loss: 0.711613, acc.: 57.03%] [G loss: 1.194165]\n",
      "epoch:0 step:798 [D loss: 0.643488, acc.: 59.38%] [G loss: 1.047536]\n",
      "epoch:0 step:799 [D loss: 0.715457, acc.: 57.03%] [G loss: 0.992909]\n",
      "epoch:0 step:800 [D loss: 0.751405, acc.: 56.25%] [G loss: 1.002714]\n",
      "##############\n",
      "[2.51935224 0.099035   5.94351776 4.5845924  3.56731939 5.27069557\n",
      " 4.28652648 4.11559393 4.49846216 3.08951279]\n",
      "##########\n",
      "epoch:0 step:801 [D loss: 0.807704, acc.: 46.88%] [G loss: 0.849516]\n",
      "epoch:0 step:802 [D loss: 0.711073, acc.: 57.81%] [G loss: 0.995478]\n",
      "epoch:0 step:803 [D loss: 0.712311, acc.: 58.59%] [G loss: 1.031025]\n",
      "epoch:0 step:804 [D loss: 0.745740, acc.: 50.78%] [G loss: 0.993675]\n",
      "epoch:0 step:805 [D loss: 0.761384, acc.: 50.78%] [G loss: 0.961436]\n",
      "epoch:0 step:806 [D loss: 0.739731, acc.: 53.91%] [G loss: 0.990895]\n",
      "epoch:0 step:807 [D loss: 0.729209, acc.: 57.03%] [G loss: 1.078978]\n",
      "epoch:0 step:808 [D loss: 0.731169, acc.: 57.03%] [G loss: 0.995610]\n",
      "epoch:0 step:809 [D loss: 0.701998, acc.: 57.03%] [G loss: 1.082756]\n",
      "epoch:0 step:810 [D loss: 0.713566, acc.: 54.69%] [G loss: 0.929596]\n",
      "epoch:0 step:811 [D loss: 0.675388, acc.: 55.47%] [G loss: 0.944271]\n",
      "epoch:0 step:812 [D loss: 0.796683, acc.: 45.31%] [G loss: 0.989927]\n",
      "epoch:0 step:813 [D loss: 0.780607, acc.: 48.44%] [G loss: 1.027439]\n",
      "epoch:0 step:814 [D loss: 0.715681, acc.: 50.78%] [G loss: 0.962115]\n",
      "epoch:0 step:815 [D loss: 0.642838, acc.: 59.38%] [G loss: 1.069026]\n",
      "epoch:0 step:816 [D loss: 0.651376, acc.: 60.16%] [G loss: 1.073490]\n",
      "epoch:0 step:817 [D loss: 0.728180, acc.: 52.34%] [G loss: 1.016420]\n",
      "epoch:0 step:818 [D loss: 0.794094, acc.: 46.09%] [G loss: 0.957100]\n",
      "epoch:0 step:819 [D loss: 0.677525, acc.: 61.72%] [G loss: 0.913260]\n",
      "epoch:0 step:820 [D loss: 0.742629, acc.: 51.56%] [G loss: 0.898206]\n",
      "epoch:0 step:821 [D loss: 0.738785, acc.: 50.00%] [G loss: 0.953823]\n",
      "epoch:0 step:822 [D loss: 0.710434, acc.: 53.91%] [G loss: 1.057054]\n",
      "epoch:0 step:823 [D loss: 0.691832, acc.: 59.38%] [G loss: 1.026476]\n",
      "epoch:0 step:824 [D loss: 0.764117, acc.: 49.22%] [G loss: 1.125379]\n",
      "epoch:0 step:825 [D loss: 0.702179, acc.: 52.34%] [G loss: 1.040290]\n",
      "epoch:0 step:826 [D loss: 0.775345, acc.: 46.09%] [G loss: 0.864059]\n",
      "epoch:0 step:827 [D loss: 0.703989, acc.: 57.03%] [G loss: 0.987657]\n",
      "epoch:0 step:828 [D loss: 0.746889, acc.: 47.66%] [G loss: 0.973212]\n",
      "epoch:0 step:829 [D loss: 0.761441, acc.: 52.34%] [G loss: 0.904534]\n",
      "epoch:0 step:830 [D loss: 0.619074, acc.: 63.28%] [G loss: 1.084541]\n",
      "epoch:0 step:831 [D loss: 0.721321, acc.: 54.69%] [G loss: 1.020206]\n",
      "epoch:0 step:832 [D loss: 0.721073, acc.: 57.81%] [G loss: 0.887995]\n",
      "epoch:0 step:833 [D loss: 0.722788, acc.: 59.38%] [G loss: 1.046332]\n",
      "epoch:0 step:834 [D loss: 0.703706, acc.: 57.81%] [G loss: 0.957839]\n",
      "epoch:0 step:835 [D loss: 0.671486, acc.: 66.41%] [G loss: 0.946326]\n",
      "epoch:0 step:836 [D loss: 0.717002, acc.: 53.12%] [G loss: 1.008897]\n",
      "epoch:0 step:837 [D loss: 0.724932, acc.: 58.59%] [G loss: 1.095357]\n",
      "epoch:0 step:838 [D loss: 0.700671, acc.: 52.34%] [G loss: 0.992529]\n",
      "epoch:0 step:839 [D loss: 0.691763, acc.: 55.47%] [G loss: 1.023711]\n",
      "epoch:0 step:840 [D loss: 0.778016, acc.: 51.56%] [G loss: 1.026405]\n",
      "epoch:0 step:841 [D loss: 0.642069, acc.: 63.28%] [G loss: 0.958153]\n",
      "epoch:0 step:842 [D loss: 0.664339, acc.: 59.38%] [G loss: 1.066537]\n",
      "epoch:0 step:843 [D loss: 0.671173, acc.: 60.94%] [G loss: 1.024910]\n",
      "epoch:0 step:844 [D loss: 0.663875, acc.: 59.38%] [G loss: 0.990507]\n",
      "epoch:0 step:845 [D loss: 0.738040, acc.: 53.91%] [G loss: 1.067830]\n",
      "epoch:0 step:846 [D loss: 0.680665, acc.: 63.28%] [G loss: 0.954297]\n",
      "epoch:0 step:847 [D loss: 0.751807, acc.: 51.56%] [G loss: 0.967003]\n",
      "epoch:0 step:848 [D loss: 0.729399, acc.: 52.34%] [G loss: 0.972345]\n",
      "epoch:0 step:849 [D loss: 0.758041, acc.: 43.75%] [G loss: 0.950016]\n",
      "epoch:0 step:850 [D loss: 0.759608, acc.: 52.34%] [G loss: 0.857579]\n",
      "epoch:0 step:851 [D loss: 0.757556, acc.: 50.78%] [G loss: 0.943425]\n",
      "epoch:0 step:852 [D loss: 0.725471, acc.: 50.00%] [G loss: 0.970098]\n",
      "epoch:0 step:853 [D loss: 0.707473, acc.: 54.69%] [G loss: 1.003466]\n",
      "epoch:0 step:854 [D loss: 0.693825, acc.: 58.59%] [G loss: 1.083130]\n",
      "epoch:0 step:855 [D loss: 0.796200, acc.: 50.00%] [G loss: 0.904107]\n",
      "epoch:0 step:856 [D loss: 0.708558, acc.: 53.12%] [G loss: 0.906682]\n",
      "epoch:0 step:857 [D loss: 0.695240, acc.: 60.16%] [G loss: 0.922311]\n",
      "epoch:0 step:858 [D loss: 0.731079, acc.: 50.78%] [G loss: 0.946169]\n",
      "epoch:0 step:859 [D loss: 0.784179, acc.: 52.34%] [G loss: 0.988727]\n",
      "epoch:0 step:860 [D loss: 0.782683, acc.: 48.44%] [G loss: 0.948941]\n",
      "epoch:0 step:861 [D loss: 0.774904, acc.: 48.44%] [G loss: 0.934044]\n",
      "epoch:0 step:862 [D loss: 0.670870, acc.: 62.50%] [G loss: 0.999984]\n",
      "epoch:0 step:863 [D loss: 0.734634, acc.: 55.47%] [G loss: 0.972857]\n",
      "epoch:0 step:864 [D loss: 0.724342, acc.: 51.56%] [G loss: 0.922851]\n",
      "epoch:0 step:865 [D loss: 0.769868, acc.: 49.22%] [G loss: 0.866158]\n",
      "epoch:0 step:866 [D loss: 0.683763, acc.: 58.59%] [G loss: 1.114702]\n",
      "epoch:0 step:867 [D loss: 0.786701, acc.: 47.66%] [G loss: 0.865441]\n",
      "epoch:0 step:868 [D loss: 0.713220, acc.: 56.25%] [G loss: 1.028583]\n",
      "epoch:0 step:869 [D loss: 0.730150, acc.: 51.56%] [G loss: 0.932952]\n",
      "epoch:0 step:870 [D loss: 0.713983, acc.: 57.81%] [G loss: 0.941212]\n",
      "epoch:0 step:871 [D loss: 0.703381, acc.: 51.56%] [G loss: 0.924380]\n",
      "epoch:0 step:872 [D loss: 0.742208, acc.: 51.56%] [G loss: 0.916520]\n",
      "epoch:0 step:873 [D loss: 0.671336, acc.: 58.59%] [G loss: 0.991641]\n",
      "epoch:0 step:874 [D loss: 0.755226, acc.: 53.91%] [G loss: 0.926373]\n",
      "epoch:0 step:875 [D loss: 0.671923, acc.: 60.16%] [G loss: 0.899725]\n",
      "epoch:0 step:876 [D loss: 0.665501, acc.: 56.25%] [G loss: 0.915979]\n",
      "epoch:0 step:877 [D loss: 0.678359, acc.: 59.38%] [G loss: 0.876571]\n",
      "epoch:0 step:878 [D loss: 0.678810, acc.: 60.94%] [G loss: 0.911333]\n",
      "epoch:0 step:879 [D loss: 0.736156, acc.: 53.91%] [G loss: 1.043451]\n",
      "epoch:0 step:880 [D loss: 0.738811, acc.: 50.00%] [G loss: 1.016748]\n",
      "epoch:0 step:881 [D loss: 0.703776, acc.: 56.25%] [G loss: 1.058268]\n",
      "epoch:0 step:882 [D loss: 0.774879, acc.: 52.34%] [G loss: 0.918843]\n",
      "epoch:0 step:883 [D loss: 0.800625, acc.: 46.88%] [G loss: 0.954628]\n",
      "epoch:0 step:884 [D loss: 0.737830, acc.: 57.03%] [G loss: 0.994012]\n",
      "epoch:0 step:885 [D loss: 0.684772, acc.: 61.72%] [G loss: 1.028392]\n",
      "epoch:0 step:886 [D loss: 0.718115, acc.: 53.12%] [G loss: 1.066403]\n",
      "epoch:0 step:887 [D loss: 0.745161, acc.: 53.12%] [G loss: 0.972748]\n",
      "epoch:0 step:888 [D loss: 0.714299, acc.: 57.03%] [G loss: 1.070338]\n",
      "epoch:0 step:889 [D loss: 0.738203, acc.: 51.56%] [G loss: 1.090094]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:890 [D loss: 0.636264, acc.: 59.38%] [G loss: 0.987487]\n",
      "epoch:0 step:891 [D loss: 0.743879, acc.: 50.00%] [G loss: 0.945593]\n",
      "epoch:0 step:892 [D loss: 0.823176, acc.: 50.00%] [G loss: 0.936638]\n",
      "epoch:0 step:893 [D loss: 0.755386, acc.: 52.34%] [G loss: 0.865424]\n",
      "epoch:0 step:894 [D loss: 0.690800, acc.: 57.03%] [G loss: 0.959598]\n",
      "epoch:0 step:895 [D loss: 0.745552, acc.: 50.00%] [G loss: 0.981826]\n",
      "epoch:0 step:896 [D loss: 0.678375, acc.: 59.38%] [G loss: 0.836030]\n",
      "epoch:0 step:897 [D loss: 0.641133, acc.: 67.97%] [G loss: 1.021728]\n",
      "epoch:0 step:898 [D loss: 0.740156, acc.: 53.12%] [G loss: 0.976984]\n",
      "epoch:0 step:899 [D loss: 0.794198, acc.: 46.09%] [G loss: 0.975548]\n",
      "epoch:0 step:900 [D loss: 0.697034, acc.: 57.03%] [G loss: 1.006030]\n",
      "epoch:0 step:901 [D loss: 0.721352, acc.: 56.25%] [G loss: 1.030323]\n",
      "epoch:0 step:902 [D loss: 0.698471, acc.: 61.72%] [G loss: 1.005135]\n",
      "epoch:0 step:903 [D loss: 0.728133, acc.: 47.66%] [G loss: 1.117518]\n",
      "epoch:0 step:904 [D loss: 0.686491, acc.: 56.25%] [G loss: 0.909022]\n",
      "epoch:0 step:905 [D loss: 0.745903, acc.: 46.09%] [G loss: 1.038304]\n",
      "epoch:0 step:906 [D loss: 0.676439, acc.: 63.28%] [G loss: 0.964168]\n",
      "epoch:0 step:907 [D loss: 0.703280, acc.: 56.25%] [G loss: 1.035542]\n",
      "epoch:0 step:908 [D loss: 0.698212, acc.: 56.25%] [G loss: 0.898737]\n",
      "epoch:0 step:909 [D loss: 0.657797, acc.: 67.97%] [G loss: 1.021080]\n",
      "epoch:0 step:910 [D loss: 0.736629, acc.: 57.03%] [G loss: 0.918548]\n",
      "epoch:0 step:911 [D loss: 0.667603, acc.: 60.16%] [G loss: 1.020966]\n",
      "epoch:0 step:912 [D loss: 0.652122, acc.: 60.94%] [G loss: 1.043332]\n",
      "epoch:0 step:913 [D loss: 0.764286, acc.: 52.34%] [G loss: 1.001060]\n",
      "epoch:0 step:914 [D loss: 0.672137, acc.: 64.06%] [G loss: 0.921569]\n",
      "epoch:0 step:915 [D loss: 0.767905, acc.: 47.66%] [G loss: 1.061643]\n",
      "epoch:0 step:916 [D loss: 0.676970, acc.: 53.91%] [G loss: 1.084805]\n",
      "epoch:0 step:917 [D loss: 0.780616, acc.: 46.88%] [G loss: 0.962042]\n",
      "epoch:0 step:918 [D loss: 0.596893, acc.: 64.84%] [G loss: 1.008981]\n",
      "epoch:0 step:919 [D loss: 0.715309, acc.: 51.56%] [G loss: 0.911651]\n",
      "epoch:0 step:920 [D loss: 0.755638, acc.: 47.66%] [G loss: 1.074165]\n",
      "epoch:0 step:921 [D loss: 0.619767, acc.: 62.50%] [G loss: 1.089416]\n",
      "epoch:0 step:922 [D loss: 0.705818, acc.: 56.25%] [G loss: 0.949905]\n",
      "epoch:0 step:923 [D loss: 0.649990, acc.: 64.06%] [G loss: 0.950239]\n",
      "epoch:0 step:924 [D loss: 0.625676, acc.: 61.72%] [G loss: 1.027219]\n",
      "epoch:0 step:925 [D loss: 0.661638, acc.: 62.50%] [G loss: 1.088408]\n",
      "epoch:0 step:926 [D loss: 0.644680, acc.: 65.62%] [G loss: 1.077541]\n",
      "epoch:0 step:927 [D loss: 0.645986, acc.: 63.28%] [G loss: 1.072099]\n",
      "epoch:0 step:928 [D loss: 0.830755, acc.: 50.78%] [G loss: 1.284965]\n",
      "epoch:0 step:929 [D loss: 0.930204, acc.: 31.25%] [G loss: 0.861833]\n",
      "epoch:0 step:930 [D loss: 0.600706, acc.: 65.62%] [G loss: 1.049672]\n",
      "epoch:0 step:931 [D loss: 0.698908, acc.: 54.69%] [G loss: 1.181817]\n",
      "epoch:0 step:932 [D loss: 0.784119, acc.: 52.34%] [G loss: 1.052750]\n",
      "epoch:0 step:933 [D loss: 0.699596, acc.: 57.81%] [G loss: 1.022039]\n",
      "epoch:0 step:934 [D loss: 0.723949, acc.: 52.34%] [G loss: 0.990182]\n",
      "epoch:0 step:935 [D loss: 0.784661, acc.: 49.22%] [G loss: 0.897068]\n",
      "epoch:0 step:936 [D loss: 0.648399, acc.: 59.38%] [G loss: 0.984438]\n",
      "epoch:0 step:937 [D loss: 0.676352, acc.: 59.38%] [G loss: 0.999288]\n",
      "epoch:1 step:938 [D loss: 0.730576, acc.: 59.38%] [G loss: 1.048151]\n",
      "epoch:1 step:939 [D loss: 0.689844, acc.: 64.84%] [G loss: 0.962367]\n",
      "epoch:1 step:940 [D loss: 0.754237, acc.: 52.34%] [G loss: 1.026366]\n",
      "epoch:1 step:941 [D loss: 0.724109, acc.: 54.69%] [G loss: 1.021081]\n",
      "epoch:1 step:942 [D loss: 0.670183, acc.: 65.62%] [G loss: 1.033645]\n",
      "epoch:1 step:943 [D loss: 0.742525, acc.: 51.56%] [G loss: 1.178651]\n",
      "epoch:1 step:944 [D loss: 0.753935, acc.: 53.12%] [G loss: 1.051185]\n",
      "epoch:1 step:945 [D loss: 0.726753, acc.: 50.00%] [G loss: 0.982989]\n",
      "epoch:1 step:946 [D loss: 0.655963, acc.: 62.50%] [G loss: 1.023942]\n",
      "epoch:1 step:947 [D loss: 0.672672, acc.: 58.59%] [G loss: 0.995042]\n",
      "epoch:1 step:948 [D loss: 0.757171, acc.: 52.34%] [G loss: 0.943887]\n",
      "epoch:1 step:949 [D loss: 0.663088, acc.: 63.28%] [G loss: 0.990462]\n",
      "epoch:1 step:950 [D loss: 0.701791, acc.: 52.34%] [G loss: 0.935328]\n",
      "epoch:1 step:951 [D loss: 0.696902, acc.: 55.47%] [G loss: 1.079536]\n",
      "epoch:1 step:952 [D loss: 0.671134, acc.: 64.06%] [G loss: 1.007763]\n",
      "epoch:1 step:953 [D loss: 0.711356, acc.: 61.72%] [G loss: 0.984341]\n",
      "epoch:1 step:954 [D loss: 0.747740, acc.: 53.91%] [G loss: 0.959051]\n",
      "epoch:1 step:955 [D loss: 0.712460, acc.: 53.12%] [G loss: 0.967649]\n",
      "epoch:1 step:956 [D loss: 0.702609, acc.: 55.47%] [G loss: 1.085053]\n",
      "epoch:1 step:957 [D loss: 0.874574, acc.: 35.94%] [G loss: 0.938798]\n",
      "epoch:1 step:958 [D loss: 0.710076, acc.: 53.12%] [G loss: 0.964497]\n",
      "epoch:1 step:959 [D loss: 0.733689, acc.: 55.47%] [G loss: 0.936064]\n",
      "epoch:1 step:960 [D loss: 0.744723, acc.: 50.78%] [G loss: 0.936003]\n",
      "epoch:1 step:961 [D loss: 0.708656, acc.: 58.59%] [G loss: 1.082380]\n",
      "epoch:1 step:962 [D loss: 0.718816, acc.: 52.34%] [G loss: 0.998103]\n",
      "epoch:1 step:963 [D loss: 0.755963, acc.: 51.56%] [G loss: 0.968492]\n",
      "epoch:1 step:964 [D loss: 0.736290, acc.: 53.91%] [G loss: 0.979650]\n",
      "epoch:1 step:965 [D loss: 0.713557, acc.: 52.34%] [G loss: 0.989919]\n",
      "epoch:1 step:966 [D loss: 0.721954, acc.: 55.47%] [G loss: 1.081395]\n",
      "epoch:1 step:967 [D loss: 0.783930, acc.: 47.66%] [G loss: 0.905615]\n",
      "epoch:1 step:968 [D loss: 0.762444, acc.: 50.78%] [G loss: 0.902071]\n",
      "epoch:1 step:969 [D loss: 0.793680, acc.: 46.88%] [G loss: 1.005894]\n",
      "epoch:1 step:970 [D loss: 0.665390, acc.: 61.72%] [G loss: 0.936614]\n",
      "epoch:1 step:971 [D loss: 0.684113, acc.: 58.59%] [G loss: 1.065449]\n",
      "epoch:1 step:972 [D loss: 0.641302, acc.: 63.28%] [G loss: 0.905405]\n",
      "epoch:1 step:973 [D loss: 0.702766, acc.: 60.16%] [G loss: 0.994432]\n",
      "epoch:1 step:974 [D loss: 0.654277, acc.: 57.03%] [G loss: 1.009076]\n",
      "epoch:1 step:975 [D loss: 0.794316, acc.: 45.31%] [G loss: 0.938122]\n",
      "epoch:1 step:976 [D loss: 0.676372, acc.: 60.94%] [G loss: 1.066129]\n",
      "epoch:1 step:977 [D loss: 0.736717, acc.: 53.12%] [G loss: 0.887150]\n",
      "epoch:1 step:978 [D loss: 0.720565, acc.: 57.03%] [G loss: 1.002156]\n",
      "epoch:1 step:979 [D loss: 0.640263, acc.: 62.50%] [G loss: 1.020667]\n",
      "epoch:1 step:980 [D loss: 0.716043, acc.: 53.91%] [G loss: 1.082937]\n",
      "epoch:1 step:981 [D loss: 0.773886, acc.: 48.44%] [G loss: 0.907354]\n",
      "epoch:1 step:982 [D loss: 0.755531, acc.: 48.44%] [G loss: 0.975543]\n",
      "epoch:1 step:983 [D loss: 0.727037, acc.: 53.12%] [G loss: 0.896584]\n",
      "epoch:1 step:984 [D loss: 0.750802, acc.: 50.00%] [G loss: 1.008884]\n",
      "epoch:1 step:985 [D loss: 0.702458, acc.: 53.12%] [G loss: 1.141285]\n",
      "epoch:1 step:986 [D loss: 0.682826, acc.: 59.38%] [G loss: 1.068405]\n",
      "epoch:1 step:987 [D loss: 0.694467, acc.: 56.25%] [G loss: 1.043329]\n",
      "epoch:1 step:988 [D loss: 0.761752, acc.: 53.91%] [G loss: 1.069261]\n",
      "epoch:1 step:989 [D loss: 0.684967, acc.: 58.59%] [G loss: 0.983327]\n",
      "epoch:1 step:990 [D loss: 0.747941, acc.: 52.34%] [G loss: 0.947555]\n",
      "epoch:1 step:991 [D loss: 0.703436, acc.: 58.59%] [G loss: 0.900670]\n",
      "epoch:1 step:992 [D loss: 0.649608, acc.: 63.28%] [G loss: 0.970180]\n",
      "epoch:1 step:993 [D loss: 0.774440, acc.: 51.56%] [G loss: 1.000424]\n",
      "epoch:1 step:994 [D loss: 0.717763, acc.: 55.47%] [G loss: 1.010647]\n",
      "epoch:1 step:995 [D loss: 0.694590, acc.: 57.03%] [G loss: 0.937397]\n",
      "epoch:1 step:996 [D loss: 0.681230, acc.: 60.94%] [G loss: 0.919110]\n",
      "epoch:1 step:997 [D loss: 0.747527, acc.: 52.34%] [G loss: 1.000655]\n",
      "epoch:1 step:998 [D loss: 0.713421, acc.: 53.12%] [G loss: 1.017933]\n",
      "epoch:1 step:999 [D loss: 0.744837, acc.: 45.31%] [G loss: 0.967160]\n",
      "epoch:1 step:1000 [D loss: 0.680086, acc.: 50.00%] [G loss: 0.972384]\n",
      "##############\n",
      "[2.16702452 0.34813593 5.67050338 4.12937489 2.82861514 4.89449986\n",
      " 3.78088195 3.8792639  4.09589934 2.51347784]\n",
      "##########\n",
      "epoch:1 step:1001 [D loss: 0.684692, acc.: 57.03%] [G loss: 0.924175]\n",
      "epoch:1 step:1002 [D loss: 0.745735, acc.: 49.22%] [G loss: 0.939085]\n",
      "epoch:1 step:1003 [D loss: 0.708937, acc.: 54.69%] [G loss: 0.952663]\n",
      "epoch:1 step:1004 [D loss: 0.739129, acc.: 48.44%] [G loss: 0.913634]\n",
      "epoch:1 step:1005 [D loss: 0.678194, acc.: 56.25%] [G loss: 0.917074]\n",
      "epoch:1 step:1006 [D loss: 0.814933, acc.: 39.84%] [G loss: 0.965056]\n",
      "epoch:1 step:1007 [D loss: 0.714258, acc.: 52.34%] [G loss: 0.962062]\n",
      "epoch:1 step:1008 [D loss: 0.667877, acc.: 60.94%] [G loss: 0.916374]\n",
      "epoch:1 step:1009 [D loss: 0.649193, acc.: 60.94%] [G loss: 0.983849]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1010 [D loss: 0.693254, acc.: 57.03%] [G loss: 0.977625]\n",
      "epoch:1 step:1011 [D loss: 0.690533, acc.: 53.91%] [G loss: 1.000050]\n",
      "epoch:1 step:1012 [D loss: 0.636649, acc.: 60.94%] [G loss: 1.030138]\n",
      "epoch:1 step:1013 [D loss: 0.626380, acc.: 64.84%] [G loss: 1.106517]\n",
      "epoch:1 step:1014 [D loss: 0.615532, acc.: 65.62%] [G loss: 1.121918]\n",
      "epoch:1 step:1015 [D loss: 0.792248, acc.: 53.12%] [G loss: 0.999149]\n",
      "epoch:1 step:1016 [D loss: 0.800716, acc.: 47.66%] [G loss: 0.873006]\n",
      "epoch:1 step:1017 [D loss: 0.751050, acc.: 51.56%] [G loss: 0.845044]\n",
      "epoch:1 step:1018 [D loss: 0.837166, acc.: 42.97%] [G loss: 0.943357]\n",
      "epoch:1 step:1019 [D loss: 0.726115, acc.: 57.81%] [G loss: 0.862887]\n",
      "epoch:1 step:1020 [D loss: 0.659361, acc.: 61.72%] [G loss: 1.036782]\n",
      "epoch:1 step:1021 [D loss: 0.689562, acc.: 57.03%] [G loss: 0.980969]\n",
      "epoch:1 step:1022 [D loss: 0.661846, acc.: 59.38%] [G loss: 1.040858]\n",
      "epoch:1 step:1023 [D loss: 0.660661, acc.: 62.50%] [G loss: 1.030852]\n",
      "epoch:1 step:1024 [D loss: 0.652475, acc.: 57.81%] [G loss: 1.103637]\n",
      "epoch:1 step:1025 [D loss: 0.682678, acc.: 57.81%] [G loss: 0.936614]\n",
      "epoch:1 step:1026 [D loss: 0.702004, acc.: 56.25%] [G loss: 1.055825]\n",
      "epoch:1 step:1027 [D loss: 0.658213, acc.: 59.38%] [G loss: 0.970079]\n",
      "epoch:1 step:1028 [D loss: 0.677360, acc.: 57.03%] [G loss: 0.996465]\n",
      "epoch:1 step:1029 [D loss: 0.699715, acc.: 55.47%] [G loss: 0.973314]\n",
      "epoch:1 step:1030 [D loss: 0.655491, acc.: 60.94%] [G loss: 1.050897]\n",
      "epoch:1 step:1031 [D loss: 0.707742, acc.: 59.38%] [G loss: 0.970942]\n",
      "epoch:1 step:1032 [D loss: 0.762510, acc.: 50.78%] [G loss: 0.979951]\n",
      "epoch:1 step:1033 [D loss: 0.764268, acc.: 49.22%] [G loss: 1.006055]\n",
      "epoch:1 step:1034 [D loss: 0.664598, acc.: 64.84%] [G loss: 1.077593]\n",
      "epoch:1 step:1035 [D loss: 0.667142, acc.: 56.25%] [G loss: 1.042073]\n",
      "epoch:1 step:1036 [D loss: 0.675406, acc.: 64.84%] [G loss: 0.939414]\n",
      "epoch:1 step:1037 [D loss: 0.720040, acc.: 52.34%] [G loss: 0.851104]\n",
      "epoch:1 step:1038 [D loss: 0.718582, acc.: 52.34%] [G loss: 0.929117]\n",
      "epoch:1 step:1039 [D loss: 0.671074, acc.: 58.59%] [G loss: 1.064719]\n",
      "epoch:1 step:1040 [D loss: 0.605850, acc.: 64.06%] [G loss: 1.082603]\n",
      "epoch:1 step:1041 [D loss: 0.660215, acc.: 60.94%] [G loss: 1.032528]\n",
      "epoch:1 step:1042 [D loss: 0.763814, acc.: 50.00%] [G loss: 0.973325]\n",
      "epoch:1 step:1043 [D loss: 0.755457, acc.: 46.09%] [G loss: 1.044001]\n",
      "epoch:1 step:1044 [D loss: 0.701962, acc.: 59.38%] [G loss: 1.029280]\n",
      "epoch:1 step:1045 [D loss: 0.716320, acc.: 51.56%] [G loss: 1.016081]\n",
      "epoch:1 step:1046 [D loss: 0.761057, acc.: 47.66%] [G loss: 0.857878]\n",
      "epoch:1 step:1047 [D loss: 0.757434, acc.: 55.47%] [G loss: 0.999056]\n",
      "epoch:1 step:1048 [D loss: 0.620643, acc.: 64.06%] [G loss: 0.987868]\n",
      "epoch:1 step:1049 [D loss: 0.727933, acc.: 52.34%] [G loss: 0.915803]\n",
      "epoch:1 step:1050 [D loss: 0.750259, acc.: 48.44%] [G loss: 1.028722]\n",
      "epoch:1 step:1051 [D loss: 0.710131, acc.: 56.25%] [G loss: 1.050321]\n",
      "epoch:1 step:1052 [D loss: 0.697568, acc.: 55.47%] [G loss: 0.921044]\n",
      "epoch:1 step:1053 [D loss: 0.706339, acc.: 54.69%] [G loss: 1.073064]\n",
      "epoch:1 step:1054 [D loss: 0.738976, acc.: 46.09%] [G loss: 0.892305]\n",
      "epoch:1 step:1055 [D loss: 0.653195, acc.: 62.50%] [G loss: 0.905062]\n",
      "epoch:1 step:1056 [D loss: 0.677529, acc.: 52.34%] [G loss: 1.000686]\n",
      "epoch:1 step:1057 [D loss: 0.800467, acc.: 47.66%] [G loss: 1.013407]\n",
      "epoch:1 step:1058 [D loss: 0.744868, acc.: 52.34%] [G loss: 0.905187]\n",
      "epoch:1 step:1059 [D loss: 0.741106, acc.: 51.56%] [G loss: 0.939857]\n",
      "epoch:1 step:1060 [D loss: 0.763397, acc.: 49.22%] [G loss: 0.871278]\n",
      "epoch:1 step:1061 [D loss: 0.678324, acc.: 57.81%] [G loss: 1.066644]\n",
      "epoch:1 step:1062 [D loss: 0.718537, acc.: 50.78%] [G loss: 0.987285]\n",
      "epoch:1 step:1063 [D loss: 0.721625, acc.: 48.44%] [G loss: 0.901465]\n",
      "epoch:1 step:1064 [D loss: 0.686494, acc.: 57.03%] [G loss: 1.002462]\n",
      "epoch:1 step:1065 [D loss: 0.684721, acc.: 51.56%] [G loss: 0.903376]\n",
      "epoch:1 step:1066 [D loss: 0.795476, acc.: 44.53%] [G loss: 0.926555]\n",
      "epoch:1 step:1067 [D loss: 0.690564, acc.: 57.81%] [G loss: 0.879100]\n",
      "epoch:1 step:1068 [D loss: 0.692339, acc.: 58.59%] [G loss: 0.991949]\n",
      "epoch:1 step:1069 [D loss: 0.721948, acc.: 53.91%] [G loss: 0.927448]\n",
      "epoch:1 step:1070 [D loss: 0.797228, acc.: 45.31%] [G loss: 0.887204]\n",
      "epoch:1 step:1071 [D loss: 0.710188, acc.: 53.12%] [G loss: 1.049415]\n",
      "epoch:1 step:1072 [D loss: 0.723435, acc.: 46.88%] [G loss: 0.908131]\n",
      "epoch:1 step:1073 [D loss: 0.736656, acc.: 55.47%] [G loss: 0.973632]\n",
      "epoch:1 step:1074 [D loss: 0.721254, acc.: 56.25%] [G loss: 0.904665]\n",
      "epoch:1 step:1075 [D loss: 0.767731, acc.: 50.78%] [G loss: 0.965331]\n",
      "epoch:1 step:1076 [D loss: 0.727183, acc.: 57.03%] [G loss: 0.900502]\n",
      "epoch:1 step:1077 [D loss: 0.693968, acc.: 57.03%] [G loss: 0.968274]\n",
      "epoch:1 step:1078 [D loss: 0.686955, acc.: 57.81%] [G loss: 1.084743]\n",
      "epoch:1 step:1079 [D loss: 0.702214, acc.: 52.34%] [G loss: 0.882272]\n",
      "epoch:1 step:1080 [D loss: 0.787106, acc.: 45.31%] [G loss: 0.968752]\n",
      "epoch:1 step:1081 [D loss: 0.667245, acc.: 56.25%] [G loss: 0.964334]\n",
      "epoch:1 step:1082 [D loss: 0.682994, acc.: 59.38%] [G loss: 0.947522]\n",
      "epoch:1 step:1083 [D loss: 0.735480, acc.: 53.12%] [G loss: 0.953083]\n",
      "epoch:1 step:1084 [D loss: 0.679132, acc.: 59.38%] [G loss: 1.041974]\n",
      "epoch:1 step:1085 [D loss: 0.748285, acc.: 51.56%] [G loss: 1.027904]\n",
      "epoch:1 step:1086 [D loss: 0.724307, acc.: 56.25%] [G loss: 1.060116]\n",
      "epoch:1 step:1087 [D loss: 0.686373, acc.: 58.59%] [G loss: 0.927234]\n",
      "epoch:1 step:1088 [D loss: 0.597986, acc.: 64.84%] [G loss: 1.130516]\n",
      "epoch:1 step:1089 [D loss: 0.698594, acc.: 61.72%] [G loss: 0.956811]\n",
      "epoch:1 step:1090 [D loss: 0.684122, acc.: 61.72%] [G loss: 1.096683]\n",
      "epoch:1 step:1091 [D loss: 0.632204, acc.: 64.84%] [G loss: 1.009908]\n",
      "epoch:1 step:1092 [D loss: 0.723074, acc.: 56.25%] [G loss: 0.893883]\n",
      "epoch:1 step:1093 [D loss: 0.694131, acc.: 61.72%] [G loss: 0.930496]\n",
      "epoch:1 step:1094 [D loss: 0.684407, acc.: 57.81%] [G loss: 1.009512]\n",
      "epoch:1 step:1095 [D loss: 0.753781, acc.: 56.25%] [G loss: 0.898193]\n",
      "epoch:1 step:1096 [D loss: 0.670812, acc.: 58.59%] [G loss: 1.054990]\n",
      "epoch:1 step:1097 [D loss: 0.719624, acc.: 53.12%] [G loss: 0.997663]\n",
      "epoch:1 step:1098 [D loss: 0.738792, acc.: 48.44%] [G loss: 0.893321]\n",
      "epoch:1 step:1099 [D loss: 0.647141, acc.: 64.84%] [G loss: 0.971405]\n",
      "epoch:1 step:1100 [D loss: 0.681559, acc.: 60.94%] [G loss: 0.974783]\n",
      "epoch:1 step:1101 [D loss: 0.653305, acc.: 57.03%] [G loss: 0.962653]\n",
      "epoch:1 step:1102 [D loss: 0.667779, acc.: 57.81%] [G loss: 1.110860]\n",
      "epoch:1 step:1103 [D loss: 0.738882, acc.: 46.09%] [G loss: 0.987203]\n",
      "epoch:1 step:1104 [D loss: 0.738692, acc.: 51.56%] [G loss: 0.954250]\n",
      "epoch:1 step:1105 [D loss: 0.664710, acc.: 60.94%] [G loss: 0.929385]\n",
      "epoch:1 step:1106 [D loss: 0.687225, acc.: 56.25%] [G loss: 0.958024]\n",
      "epoch:1 step:1107 [D loss: 0.733797, acc.: 48.44%] [G loss: 0.906620]\n",
      "epoch:1 step:1108 [D loss: 0.673580, acc.: 57.81%] [G loss: 1.007067]\n",
      "epoch:1 step:1109 [D loss: 0.698864, acc.: 58.59%] [G loss: 1.014251]\n",
      "epoch:1 step:1110 [D loss: 0.718853, acc.: 56.25%] [G loss: 1.004040]\n",
      "epoch:1 step:1111 [D loss: 0.730030, acc.: 55.47%] [G loss: 0.986625]\n",
      "epoch:1 step:1112 [D loss: 0.700859, acc.: 56.25%] [G loss: 1.053151]\n",
      "epoch:1 step:1113 [D loss: 0.695141, acc.: 53.12%] [G loss: 1.123957]\n",
      "epoch:1 step:1114 [D loss: 0.651990, acc.: 61.72%] [G loss: 1.002501]\n",
      "epoch:1 step:1115 [D loss: 0.635767, acc.: 60.94%] [G loss: 1.104463]\n",
      "epoch:1 step:1116 [D loss: 0.689145, acc.: 60.94%] [G loss: 0.900535]\n",
      "epoch:1 step:1117 [D loss: 0.654062, acc.: 63.28%] [G loss: 0.870624]\n",
      "epoch:1 step:1118 [D loss: 0.668834, acc.: 57.81%] [G loss: 0.962726]\n",
      "epoch:1 step:1119 [D loss: 0.739179, acc.: 50.78%] [G loss: 0.861543]\n",
      "epoch:1 step:1120 [D loss: 0.694657, acc.: 54.69%] [G loss: 1.011343]\n",
      "epoch:1 step:1121 [D loss: 0.653310, acc.: 60.16%] [G loss: 0.952698]\n",
      "epoch:1 step:1122 [D loss: 0.741182, acc.: 45.31%] [G loss: 0.883856]\n",
      "epoch:1 step:1123 [D loss: 0.725121, acc.: 55.47%] [G loss: 0.967860]\n",
      "epoch:1 step:1124 [D loss: 0.733347, acc.: 56.25%] [G loss: 0.909730]\n",
      "epoch:1 step:1125 [D loss: 0.706387, acc.: 58.59%] [G loss: 0.945834]\n",
      "epoch:1 step:1126 [D loss: 0.688154, acc.: 56.25%] [G loss: 0.954000]\n",
      "epoch:1 step:1127 [D loss: 0.690644, acc.: 60.94%] [G loss: 0.998286]\n",
      "epoch:1 step:1128 [D loss: 0.726816, acc.: 54.69%] [G loss: 0.946937]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1129 [D loss: 0.722317, acc.: 49.22%] [G loss: 1.127216]\n",
      "epoch:1 step:1130 [D loss: 0.724418, acc.: 48.44%] [G loss: 0.962657]\n",
      "epoch:1 step:1131 [D loss: 0.752136, acc.: 51.56%] [G loss: 0.985009]\n",
      "epoch:1 step:1132 [D loss: 0.653361, acc.: 62.50%] [G loss: 1.184811]\n",
      "epoch:1 step:1133 [D loss: 0.789830, acc.: 46.88%] [G loss: 0.944810]\n",
      "epoch:1 step:1134 [D loss: 0.638630, acc.: 65.62%] [G loss: 0.965883]\n",
      "epoch:1 step:1135 [D loss: 0.695352, acc.: 51.56%] [G loss: 1.001192]\n",
      "epoch:1 step:1136 [D loss: 0.732744, acc.: 50.00%] [G loss: 1.012835]\n",
      "epoch:1 step:1137 [D loss: 0.781616, acc.: 42.97%] [G loss: 0.917630]\n",
      "epoch:1 step:1138 [D loss: 0.673363, acc.: 57.81%] [G loss: 0.962169]\n",
      "epoch:1 step:1139 [D loss: 0.692954, acc.: 55.47%] [G loss: 0.909485]\n",
      "epoch:1 step:1140 [D loss: 0.705555, acc.: 55.47%] [G loss: 0.946261]\n",
      "epoch:1 step:1141 [D loss: 0.687054, acc.: 56.25%] [G loss: 1.014804]\n",
      "epoch:1 step:1142 [D loss: 0.774976, acc.: 44.53%] [G loss: 0.941197]\n",
      "epoch:1 step:1143 [D loss: 0.712985, acc.: 51.56%] [G loss: 0.981332]\n",
      "epoch:1 step:1144 [D loss: 0.654778, acc.: 60.94%] [G loss: 1.001900]\n",
      "epoch:1 step:1145 [D loss: 0.597603, acc.: 70.31%] [G loss: 1.233435]\n",
      "epoch:1 step:1146 [D loss: 0.662992, acc.: 60.94%] [G loss: 1.031089]\n",
      "epoch:1 step:1147 [D loss: 0.678889, acc.: 57.03%] [G loss: 0.974536]\n",
      "epoch:1 step:1148 [D loss: 0.701010, acc.: 59.38%] [G loss: 0.958419]\n",
      "epoch:1 step:1149 [D loss: 0.720135, acc.: 57.03%] [G loss: 0.886980]\n",
      "epoch:1 step:1150 [D loss: 0.744317, acc.: 53.91%] [G loss: 0.950908]\n",
      "epoch:1 step:1151 [D loss: 0.733449, acc.: 52.34%] [G loss: 0.870980]\n",
      "epoch:1 step:1152 [D loss: 0.752344, acc.: 50.00%] [G loss: 0.926404]\n",
      "epoch:1 step:1153 [D loss: 0.761150, acc.: 49.22%] [G loss: 0.900798]\n",
      "epoch:1 step:1154 [D loss: 0.665985, acc.: 58.59%] [G loss: 0.912669]\n",
      "epoch:1 step:1155 [D loss: 0.721262, acc.: 53.91%] [G loss: 0.840980]\n",
      "epoch:1 step:1156 [D loss: 0.706106, acc.: 47.66%] [G loss: 1.031957]\n",
      "epoch:1 step:1157 [D loss: 0.834821, acc.: 37.50%] [G loss: 1.011195]\n",
      "epoch:1 step:1158 [D loss: 0.695026, acc.: 57.81%] [G loss: 1.053222]\n",
      "epoch:1 step:1159 [D loss: 0.681152, acc.: 53.12%] [G loss: 1.120255]\n",
      "epoch:1 step:1160 [D loss: 0.665972, acc.: 60.16%] [G loss: 0.908592]\n",
      "epoch:1 step:1161 [D loss: 0.732055, acc.: 57.03%] [G loss: 0.963451]\n",
      "epoch:1 step:1162 [D loss: 0.719364, acc.: 55.47%] [G loss: 0.996616]\n",
      "epoch:1 step:1163 [D loss: 0.680416, acc.: 56.25%] [G loss: 0.958943]\n",
      "epoch:1 step:1164 [D loss: 0.752256, acc.: 50.78%] [G loss: 0.922800]\n",
      "epoch:1 step:1165 [D loss: 0.743158, acc.: 50.78%] [G loss: 0.863435]\n",
      "epoch:1 step:1166 [D loss: 0.665945, acc.: 60.16%] [G loss: 0.979255]\n",
      "epoch:1 step:1167 [D loss: 0.673403, acc.: 56.25%] [G loss: 1.118014]\n",
      "epoch:1 step:1168 [D loss: 0.617655, acc.: 62.50%] [G loss: 1.244068]\n",
      "epoch:1 step:1169 [D loss: 0.605667, acc.: 66.41%] [G loss: 1.171288]\n",
      "epoch:1 step:1170 [D loss: 0.734742, acc.: 56.25%] [G loss: 1.071068]\n",
      "epoch:1 step:1171 [D loss: 0.739735, acc.: 56.25%] [G loss: 1.040776]\n",
      "epoch:1 step:1172 [D loss: 0.728742, acc.: 50.78%] [G loss: 0.979494]\n",
      "epoch:1 step:1173 [D loss: 0.733860, acc.: 57.03%] [G loss: 0.925145]\n",
      "epoch:1 step:1174 [D loss: 0.670939, acc.: 57.81%] [G loss: 0.920929]\n",
      "epoch:1 step:1175 [D loss: 0.652126, acc.: 61.72%] [G loss: 1.047871]\n",
      "epoch:1 step:1176 [D loss: 0.711981, acc.: 54.69%] [G loss: 0.941357]\n",
      "epoch:1 step:1177 [D loss: 0.702816, acc.: 57.03%] [G loss: 0.943822]\n",
      "epoch:1 step:1178 [D loss: 0.670855, acc.: 58.59%] [G loss: 1.039277]\n",
      "epoch:1 step:1179 [D loss: 0.669907, acc.: 61.72%] [G loss: 0.882107]\n",
      "epoch:1 step:1180 [D loss: 0.719612, acc.: 57.03%] [G loss: 0.863922]\n",
      "epoch:1 step:1181 [D loss: 0.681476, acc.: 60.16%] [G loss: 0.958748]\n",
      "epoch:1 step:1182 [D loss: 0.687718, acc.: 60.94%] [G loss: 0.998767]\n",
      "epoch:1 step:1183 [D loss: 0.665664, acc.: 57.03%] [G loss: 0.949388]\n",
      "epoch:1 step:1184 [D loss: 0.713941, acc.: 54.69%] [G loss: 0.995056]\n",
      "epoch:1 step:1185 [D loss: 0.713853, acc.: 57.03%] [G loss: 0.954107]\n",
      "epoch:1 step:1186 [D loss: 0.707401, acc.: 50.78%] [G loss: 1.102070]\n",
      "epoch:1 step:1187 [D loss: 0.823306, acc.: 43.75%] [G loss: 0.905683]\n",
      "epoch:1 step:1188 [D loss: 0.783161, acc.: 49.22%] [G loss: 0.821458]\n",
      "epoch:1 step:1189 [D loss: 0.735189, acc.: 53.91%] [G loss: 0.910776]\n",
      "epoch:1 step:1190 [D loss: 0.666712, acc.: 60.94%] [G loss: 0.958709]\n",
      "epoch:1 step:1191 [D loss: 0.718343, acc.: 53.12%] [G loss: 1.046188]\n",
      "epoch:1 step:1192 [D loss: 0.630175, acc.: 66.41%] [G loss: 1.020001]\n",
      "epoch:1 step:1193 [D loss: 0.698417, acc.: 56.25%] [G loss: 1.067004]\n",
      "epoch:1 step:1194 [D loss: 0.659192, acc.: 62.50%] [G loss: 0.966128]\n",
      "epoch:1 step:1195 [D loss: 0.671969, acc.: 57.81%] [G loss: 1.046636]\n",
      "epoch:1 step:1196 [D loss: 0.626814, acc.: 64.06%] [G loss: 1.064730]\n",
      "epoch:1 step:1197 [D loss: 0.714924, acc.: 54.69%] [G loss: 0.973959]\n",
      "epoch:1 step:1198 [D loss: 0.729631, acc.: 49.22%] [G loss: 0.981266]\n",
      "epoch:1 step:1199 [D loss: 0.703122, acc.: 55.47%] [G loss: 0.923522]\n",
      "epoch:1 step:1200 [D loss: 0.732593, acc.: 53.91%] [G loss: 1.023741]\n",
      "##############\n",
      "[2.07776304 0.25087542 5.52824731 4.00401487 2.85278607 4.86385619\n",
      " 3.5686942  3.86349848 4.09231023 2.66794796]\n",
      "##########\n",
      "epoch:1 step:1201 [D loss: 0.712034, acc.: 50.78%] [G loss: 0.940695]\n",
      "epoch:1 step:1202 [D loss: 0.746567, acc.: 47.66%] [G loss: 0.824438]\n",
      "epoch:1 step:1203 [D loss: 0.722258, acc.: 50.78%] [G loss: 0.881622]\n",
      "epoch:1 step:1204 [D loss: 0.720586, acc.: 53.91%] [G loss: 0.967708]\n",
      "epoch:1 step:1205 [D loss: 0.678714, acc.: 58.59%] [G loss: 1.040467]\n",
      "epoch:1 step:1206 [D loss: 0.793284, acc.: 46.88%] [G loss: 0.912176]\n",
      "epoch:1 step:1207 [D loss: 0.685394, acc.: 60.16%] [G loss: 0.982239]\n",
      "epoch:1 step:1208 [D loss: 0.661983, acc.: 59.38%] [G loss: 0.953040]\n",
      "epoch:1 step:1209 [D loss: 0.690991, acc.: 57.03%] [G loss: 1.007437]\n",
      "epoch:1 step:1210 [D loss: 0.646309, acc.: 62.50%] [G loss: 1.073531]\n",
      "epoch:1 step:1211 [D loss: 0.727464, acc.: 53.12%] [G loss: 0.916015]\n",
      "epoch:1 step:1212 [D loss: 0.737372, acc.: 53.91%] [G loss: 0.922438]\n",
      "epoch:1 step:1213 [D loss: 0.737297, acc.: 50.78%] [G loss: 0.974367]\n",
      "epoch:1 step:1214 [D loss: 0.721484, acc.: 50.00%] [G loss: 0.996080]\n",
      "epoch:1 step:1215 [D loss: 0.732316, acc.: 50.78%] [G loss: 0.989953]\n",
      "epoch:1 step:1216 [D loss: 0.642890, acc.: 60.16%] [G loss: 0.952246]\n",
      "epoch:1 step:1217 [D loss: 0.708993, acc.: 57.03%] [G loss: 0.850085]\n",
      "epoch:1 step:1218 [D loss: 0.670789, acc.: 56.25%] [G loss: 0.964278]\n",
      "epoch:1 step:1219 [D loss: 0.690014, acc.: 55.47%] [G loss: 0.993525]\n",
      "epoch:1 step:1220 [D loss: 0.702891, acc.: 61.72%] [G loss: 0.908832]\n",
      "epoch:1 step:1221 [D loss: 0.709924, acc.: 55.47%] [G loss: 0.937870]\n",
      "epoch:1 step:1222 [D loss: 0.672073, acc.: 64.06%] [G loss: 1.027450]\n",
      "epoch:1 step:1223 [D loss: 0.686044, acc.: 60.94%] [G loss: 0.975991]\n",
      "epoch:1 step:1224 [D loss: 0.684551, acc.: 54.69%] [G loss: 0.969445]\n",
      "epoch:1 step:1225 [D loss: 0.700803, acc.: 58.59%] [G loss: 0.976065]\n",
      "epoch:1 step:1226 [D loss: 0.687123, acc.: 57.81%] [G loss: 0.945305]\n",
      "epoch:1 step:1227 [D loss: 0.726403, acc.: 53.91%] [G loss: 0.965026]\n",
      "epoch:1 step:1228 [D loss: 0.707185, acc.: 60.16%] [G loss: 0.941444]\n",
      "epoch:1 step:1229 [D loss: 0.766787, acc.: 52.34%] [G loss: 0.830256]\n",
      "epoch:1 step:1230 [D loss: 0.695538, acc.: 55.47%] [G loss: 0.909552]\n",
      "epoch:1 step:1231 [D loss: 0.707585, acc.: 56.25%] [G loss: 0.978993]\n",
      "epoch:1 step:1232 [D loss: 0.702844, acc.: 53.12%] [G loss: 1.150675]\n",
      "epoch:1 step:1233 [D loss: 0.624090, acc.: 64.84%] [G loss: 0.996259]\n",
      "epoch:1 step:1234 [D loss: 0.685457, acc.: 58.59%] [G loss: 0.980721]\n",
      "epoch:1 step:1235 [D loss: 0.696679, acc.: 53.91%] [G loss: 0.998601]\n",
      "epoch:1 step:1236 [D loss: 0.717499, acc.: 54.69%] [G loss: 0.983094]\n",
      "epoch:1 step:1237 [D loss: 0.670789, acc.: 60.16%] [G loss: 0.970240]\n",
      "epoch:1 step:1238 [D loss: 0.737261, acc.: 51.56%] [G loss: 0.896617]\n",
      "epoch:1 step:1239 [D loss: 0.699967, acc.: 56.25%] [G loss: 0.910521]\n",
      "epoch:1 step:1240 [D loss: 0.681872, acc.: 54.69%] [G loss: 0.982027]\n",
      "epoch:1 step:1241 [D loss: 0.729978, acc.: 53.91%] [G loss: 1.014309]\n",
      "epoch:1 step:1242 [D loss: 0.711256, acc.: 50.78%] [G loss: 0.930949]\n",
      "epoch:1 step:1243 [D loss: 0.672168, acc.: 57.81%] [G loss: 0.983247]\n",
      "epoch:1 step:1244 [D loss: 0.697800, acc.: 59.38%] [G loss: 0.918161]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1245 [D loss: 0.780540, acc.: 45.31%] [G loss: 0.928043]\n",
      "epoch:1 step:1246 [D loss: 0.778789, acc.: 45.31%] [G loss: 0.968843]\n",
      "epoch:1 step:1247 [D loss: 0.722366, acc.: 53.12%] [G loss: 0.994772]\n",
      "epoch:1 step:1248 [D loss: 0.693170, acc.: 57.03%] [G loss: 0.983157]\n",
      "epoch:1 step:1249 [D loss: 0.719292, acc.: 50.78%] [G loss: 0.993273]\n",
      "epoch:1 step:1250 [D loss: 0.654553, acc.: 64.84%] [G loss: 1.070010]\n",
      "epoch:1 step:1251 [D loss: 0.636527, acc.: 66.41%] [G loss: 1.028047]\n",
      "epoch:1 step:1252 [D loss: 0.596060, acc.: 68.75%] [G loss: 1.018556]\n",
      "epoch:1 step:1253 [D loss: 0.856356, acc.: 44.53%] [G loss: 0.869361]\n",
      "epoch:1 step:1254 [D loss: 0.706767, acc.: 56.25%] [G loss: 1.054973]\n",
      "epoch:1 step:1255 [D loss: 0.675830, acc.: 60.94%] [G loss: 1.009396]\n",
      "epoch:1 step:1256 [D loss: 0.721475, acc.: 54.69%] [G loss: 1.044908]\n",
      "epoch:1 step:1257 [D loss: 0.731179, acc.: 51.56%] [G loss: 1.007800]\n",
      "epoch:1 step:1258 [D loss: 0.719186, acc.: 53.12%] [G loss: 0.875262]\n",
      "epoch:1 step:1259 [D loss: 0.723243, acc.: 56.25%] [G loss: 0.990793]\n",
      "epoch:1 step:1260 [D loss: 0.763175, acc.: 50.78%] [G loss: 0.868157]\n",
      "epoch:1 step:1261 [D loss: 0.712260, acc.: 55.47%] [G loss: 0.865632]\n",
      "epoch:1 step:1262 [D loss: 0.697646, acc.: 57.03%] [G loss: 0.907944]\n",
      "epoch:1 step:1263 [D loss: 0.650349, acc.: 59.38%] [G loss: 0.981074]\n",
      "epoch:1 step:1264 [D loss: 0.666904, acc.: 64.84%] [G loss: 0.883868]\n",
      "epoch:1 step:1265 [D loss: 0.682015, acc.: 62.50%] [G loss: 1.028147]\n",
      "epoch:1 step:1266 [D loss: 0.728290, acc.: 57.03%] [G loss: 0.936908]\n",
      "epoch:1 step:1267 [D loss: 0.679911, acc.: 60.16%] [G loss: 1.007333]\n",
      "epoch:1 step:1268 [D loss: 0.703584, acc.: 60.16%] [G loss: 0.948632]\n",
      "epoch:1 step:1269 [D loss: 0.632490, acc.: 68.75%] [G loss: 0.973730]\n",
      "epoch:1 step:1270 [D loss: 0.687160, acc.: 58.59%] [G loss: 1.030341]\n",
      "epoch:1 step:1271 [D loss: 0.666758, acc.: 63.28%] [G loss: 0.978330]\n",
      "epoch:1 step:1272 [D loss: 0.661430, acc.: 59.38%] [G loss: 0.993414]\n",
      "epoch:1 step:1273 [D loss: 0.660028, acc.: 60.16%] [G loss: 0.943104]\n",
      "epoch:1 step:1274 [D loss: 0.629382, acc.: 67.19%] [G loss: 0.976450]\n",
      "epoch:1 step:1275 [D loss: 0.686780, acc.: 53.12%] [G loss: 1.007575]\n",
      "epoch:1 step:1276 [D loss: 0.706266, acc.: 54.69%] [G loss: 0.937768]\n",
      "epoch:1 step:1277 [D loss: 0.699429, acc.: 57.03%] [G loss: 0.961955]\n",
      "epoch:1 step:1278 [D loss: 0.735079, acc.: 55.47%] [G loss: 0.960432]\n",
      "epoch:1 step:1279 [D loss: 0.695225, acc.: 56.25%] [G loss: 0.939015]\n",
      "epoch:1 step:1280 [D loss: 0.734205, acc.: 56.25%] [G loss: 0.884512]\n",
      "epoch:1 step:1281 [D loss: 0.716799, acc.: 59.38%] [G loss: 0.957203]\n",
      "epoch:1 step:1282 [D loss: 0.648439, acc.: 61.72%] [G loss: 1.092938]\n",
      "epoch:1 step:1283 [D loss: 0.642102, acc.: 65.62%] [G loss: 1.042428]\n",
      "epoch:1 step:1284 [D loss: 0.694832, acc.: 56.25%] [G loss: 1.107638]\n",
      "epoch:1 step:1285 [D loss: 0.771606, acc.: 46.88%] [G loss: 1.059908]\n",
      "epoch:1 step:1286 [D loss: 0.736294, acc.: 57.03%] [G loss: 0.963672]\n",
      "epoch:1 step:1287 [D loss: 0.681021, acc.: 58.59%] [G loss: 1.026849]\n",
      "epoch:1 step:1288 [D loss: 0.774471, acc.: 47.66%] [G loss: 0.954125]\n",
      "epoch:1 step:1289 [D loss: 0.798376, acc.: 41.41%] [G loss: 0.901913]\n",
      "epoch:1 step:1290 [D loss: 0.775555, acc.: 45.31%] [G loss: 0.938828]\n",
      "epoch:1 step:1291 [D loss: 0.696690, acc.: 56.25%] [G loss: 0.916017]\n",
      "epoch:1 step:1292 [D loss: 0.719037, acc.: 56.25%] [G loss: 0.880823]\n",
      "epoch:1 step:1293 [D loss: 0.739210, acc.: 50.78%] [G loss: 0.969252]\n",
      "epoch:1 step:1294 [D loss: 0.660714, acc.: 57.81%] [G loss: 0.978689]\n",
      "epoch:1 step:1295 [D loss: 0.646963, acc.: 61.72%] [G loss: 1.091412]\n",
      "epoch:1 step:1296 [D loss: 0.652951, acc.: 64.84%] [G loss: 1.033520]\n",
      "epoch:1 step:1297 [D loss: 0.617437, acc.: 64.84%] [G loss: 1.046898]\n",
      "epoch:1 step:1298 [D loss: 0.721500, acc.: 55.47%] [G loss: 1.017533]\n",
      "epoch:1 step:1299 [D loss: 0.785880, acc.: 49.22%] [G loss: 1.059791]\n",
      "epoch:1 step:1300 [D loss: 0.637694, acc.: 66.41%] [G loss: 0.967429]\n",
      "epoch:1 step:1301 [D loss: 0.681350, acc.: 60.16%] [G loss: 0.990067]\n",
      "epoch:1 step:1302 [D loss: 0.725873, acc.: 54.69%] [G loss: 1.088580]\n",
      "epoch:1 step:1303 [D loss: 0.682055, acc.: 60.16%] [G loss: 0.971569]\n",
      "epoch:1 step:1304 [D loss: 0.680075, acc.: 56.25%] [G loss: 0.998784]\n",
      "epoch:1 step:1305 [D loss: 0.670288, acc.: 54.69%] [G loss: 0.892399]\n",
      "epoch:1 step:1306 [D loss: 0.631968, acc.: 67.97%] [G loss: 1.027547]\n",
      "epoch:1 step:1307 [D loss: 0.683965, acc.: 58.59%] [G loss: 0.934930]\n",
      "epoch:1 step:1308 [D loss: 0.666966, acc.: 66.41%] [G loss: 0.982846]\n",
      "epoch:1 step:1309 [D loss: 0.632871, acc.: 60.94%] [G loss: 0.984424]\n",
      "epoch:1 step:1310 [D loss: 0.719435, acc.: 51.56%] [G loss: 0.995493]\n",
      "epoch:1 step:1311 [D loss: 0.636974, acc.: 66.41%] [G loss: 0.977122]\n",
      "epoch:1 step:1312 [D loss: 0.721247, acc.: 53.12%] [G loss: 0.869718]\n",
      "epoch:1 step:1313 [D loss: 0.693788, acc.: 58.59%] [G loss: 0.944173]\n",
      "epoch:1 step:1314 [D loss: 0.741715, acc.: 50.78%] [G loss: 0.900605]\n",
      "epoch:1 step:1315 [D loss: 0.687475, acc.: 56.25%] [G loss: 0.992219]\n",
      "epoch:1 step:1316 [D loss: 0.621324, acc.: 65.62%] [G loss: 0.993741]\n",
      "epoch:1 step:1317 [D loss: 0.805314, acc.: 49.22%] [G loss: 0.970038]\n",
      "epoch:1 step:1318 [D loss: 0.637502, acc.: 61.72%] [G loss: 1.080911]\n",
      "epoch:1 step:1319 [D loss: 0.797895, acc.: 52.34%] [G loss: 0.960067]\n",
      "epoch:1 step:1320 [D loss: 0.728938, acc.: 49.22%] [G loss: 0.897109]\n",
      "epoch:1 step:1321 [D loss: 0.755414, acc.: 52.34%] [G loss: 0.935512]\n",
      "epoch:1 step:1322 [D loss: 0.746723, acc.: 50.78%] [G loss: 0.903960]\n",
      "epoch:1 step:1323 [D loss: 0.713909, acc.: 54.69%] [G loss: 0.936058]\n",
      "epoch:1 step:1324 [D loss: 0.667429, acc.: 57.81%] [G loss: 1.040766]\n",
      "epoch:1 step:1325 [D loss: 0.700119, acc.: 60.94%] [G loss: 0.991135]\n",
      "epoch:1 step:1326 [D loss: 0.707480, acc.: 60.16%] [G loss: 0.887409]\n",
      "epoch:1 step:1327 [D loss: 0.726624, acc.: 56.25%] [G loss: 1.046684]\n",
      "epoch:1 step:1328 [D loss: 0.713229, acc.: 54.69%] [G loss: 0.932529]\n",
      "epoch:1 step:1329 [D loss: 0.685596, acc.: 55.47%] [G loss: 1.040787]\n",
      "epoch:1 step:1330 [D loss: 0.637907, acc.: 62.50%] [G loss: 1.058651]\n",
      "epoch:1 step:1331 [D loss: 0.765226, acc.: 46.88%] [G loss: 0.911632]\n",
      "epoch:1 step:1332 [D loss: 0.624931, acc.: 63.28%] [G loss: 0.978932]\n",
      "epoch:1 step:1333 [D loss: 0.807299, acc.: 41.41%] [G loss: 1.022703]\n",
      "epoch:1 step:1334 [D loss: 0.664432, acc.: 59.38%] [G loss: 0.923699]\n",
      "epoch:1 step:1335 [D loss: 0.681961, acc.: 56.25%] [G loss: 0.962265]\n",
      "epoch:1 step:1336 [D loss: 0.673656, acc.: 58.59%] [G loss: 0.870055]\n",
      "epoch:1 step:1337 [D loss: 0.719313, acc.: 53.91%] [G loss: 1.016176]\n",
      "epoch:1 step:1338 [D loss: 0.678325, acc.: 57.03%] [G loss: 0.971850]\n",
      "epoch:1 step:1339 [D loss: 0.692102, acc.: 53.12%] [G loss: 1.028518]\n",
      "epoch:1 step:1340 [D loss: 0.750477, acc.: 57.81%] [G loss: 1.038656]\n",
      "epoch:1 step:1341 [D loss: 0.732421, acc.: 50.00%] [G loss: 0.973394]\n",
      "epoch:1 step:1342 [D loss: 0.671808, acc.: 60.94%] [G loss: 1.009719]\n",
      "epoch:1 step:1343 [D loss: 0.700310, acc.: 63.28%] [G loss: 1.035691]\n",
      "epoch:1 step:1344 [D loss: 0.703113, acc.: 57.03%] [G loss: 1.122866]\n",
      "epoch:1 step:1345 [D loss: 0.734111, acc.: 49.22%] [G loss: 0.959593]\n",
      "epoch:1 step:1346 [D loss: 0.606673, acc.: 66.41%] [G loss: 1.092811]\n",
      "epoch:1 step:1347 [D loss: 0.732480, acc.: 50.78%] [G loss: 1.009877]\n",
      "epoch:1 step:1348 [D loss: 0.679434, acc.: 59.38%] [G loss: 0.967914]\n",
      "epoch:1 step:1349 [D loss: 0.729963, acc.: 50.78%] [G loss: 1.005537]\n",
      "epoch:1 step:1350 [D loss: 0.705524, acc.: 57.03%] [G loss: 0.925876]\n",
      "epoch:1 step:1351 [D loss: 0.664111, acc.: 57.81%] [G loss: 0.968243]\n",
      "epoch:1 step:1352 [D loss: 0.758338, acc.: 46.09%] [G loss: 0.964510]\n",
      "epoch:1 step:1353 [D loss: 0.654702, acc.: 64.06%] [G loss: 0.977614]\n",
      "epoch:1 step:1354 [D loss: 0.769183, acc.: 49.22%] [G loss: 0.930509]\n",
      "epoch:1 step:1355 [D loss: 0.760246, acc.: 46.09%] [G loss: 0.920686]\n",
      "epoch:1 step:1356 [D loss: 0.684665, acc.: 60.94%] [G loss: 0.970416]\n",
      "epoch:1 step:1357 [D loss: 0.698907, acc.: 57.81%] [G loss: 0.926831]\n",
      "epoch:1 step:1358 [D loss: 0.746702, acc.: 50.00%] [G loss: 1.003854]\n",
      "epoch:1 step:1359 [D loss: 0.684454, acc.: 60.16%] [G loss: 0.978832]\n",
      "epoch:1 step:1360 [D loss: 0.703421, acc.: 55.47%] [G loss: 1.026878]\n",
      "epoch:1 step:1361 [D loss: 0.759028, acc.: 48.44%] [G loss: 0.855662]\n",
      "epoch:1 step:1362 [D loss: 0.809724, acc.: 41.41%] [G loss: 0.927125]\n",
      "epoch:1 step:1363 [D loss: 0.737702, acc.: 46.88%] [G loss: 0.906362]\n",
      "epoch:1 step:1364 [D loss: 0.689873, acc.: 60.16%] [G loss: 1.011189]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1365 [D loss: 0.644799, acc.: 64.06%] [G loss: 0.918234]\n",
      "epoch:1 step:1366 [D loss: 0.738662, acc.: 48.44%] [G loss: 0.926840]\n",
      "epoch:1 step:1367 [D loss: 0.655654, acc.: 66.41%] [G loss: 1.011444]\n",
      "epoch:1 step:1368 [D loss: 0.750659, acc.: 46.88%] [G loss: 1.022226]\n",
      "epoch:1 step:1369 [D loss: 0.734020, acc.: 51.56%] [G loss: 0.827084]\n",
      "epoch:1 step:1370 [D loss: 0.684910, acc.: 57.81%] [G loss: 1.021810]\n",
      "epoch:1 step:1371 [D loss: 0.727521, acc.: 54.69%] [G loss: 0.875605]\n",
      "epoch:1 step:1372 [D loss: 0.738173, acc.: 53.91%] [G loss: 0.887441]\n",
      "epoch:1 step:1373 [D loss: 0.751260, acc.: 47.66%] [G loss: 0.940961]\n",
      "epoch:1 step:1374 [D loss: 0.728638, acc.: 53.12%] [G loss: 0.904637]\n",
      "epoch:1 step:1375 [D loss: 0.604291, acc.: 64.06%] [G loss: 1.061755]\n",
      "epoch:1 step:1376 [D loss: 0.667100, acc.: 65.62%] [G loss: 0.910624]\n",
      "epoch:1 step:1377 [D loss: 0.702404, acc.: 52.34%] [G loss: 0.893950]\n",
      "epoch:1 step:1378 [D loss: 0.742230, acc.: 50.00%] [G loss: 0.982477]\n",
      "epoch:1 step:1379 [D loss: 0.729004, acc.: 51.56%] [G loss: 0.960135]\n",
      "epoch:1 step:1380 [D loss: 0.683853, acc.: 56.25%] [G loss: 1.000672]\n",
      "epoch:1 step:1381 [D loss: 0.732544, acc.: 53.12%] [G loss: 0.971733]\n",
      "epoch:1 step:1382 [D loss: 0.696607, acc.: 60.94%] [G loss: 1.013554]\n",
      "epoch:1 step:1383 [D loss: 0.750661, acc.: 51.56%] [G loss: 0.952535]\n",
      "epoch:1 step:1384 [D loss: 0.623229, acc.: 62.50%] [G loss: 0.997391]\n",
      "epoch:1 step:1385 [D loss: 0.739985, acc.: 55.47%] [G loss: 0.971986]\n",
      "epoch:1 step:1386 [D loss: 0.778517, acc.: 47.66%] [G loss: 1.082630]\n",
      "epoch:1 step:1387 [D loss: 0.670745, acc.: 63.28%] [G loss: 0.996336]\n",
      "epoch:1 step:1388 [D loss: 0.717358, acc.: 50.78%] [G loss: 1.010472]\n",
      "epoch:1 step:1389 [D loss: 0.706365, acc.: 53.91%] [G loss: 1.009233]\n",
      "epoch:1 step:1390 [D loss: 0.640685, acc.: 62.50%] [G loss: 1.109499]\n",
      "epoch:1 step:1391 [D loss: 0.711819, acc.: 58.59%] [G loss: 1.073394]\n",
      "epoch:1 step:1392 [D loss: 0.609336, acc.: 65.62%] [G loss: 1.108979]\n",
      "epoch:1 step:1393 [D loss: 0.643556, acc.: 63.28%] [G loss: 0.982554]\n",
      "epoch:1 step:1394 [D loss: 0.637525, acc.: 63.28%] [G loss: 1.044933]\n",
      "epoch:1 step:1395 [D loss: 0.683244, acc.: 54.69%] [G loss: 1.026730]\n",
      "epoch:1 step:1396 [D loss: 0.723883, acc.: 53.12%] [G loss: 0.928246]\n",
      "epoch:1 step:1397 [D loss: 0.715568, acc.: 56.25%] [G loss: 0.901241]\n",
      "epoch:1 step:1398 [D loss: 0.690343, acc.: 57.81%] [G loss: 0.947203]\n",
      "epoch:1 step:1399 [D loss: 0.761211, acc.: 47.66%] [G loss: 0.879730]\n",
      "epoch:1 step:1400 [D loss: 0.774304, acc.: 46.88%] [G loss: 0.870519]\n",
      "##############\n",
      "[1.93916221 0.9681767  5.74815581 4.24168993 3.25802479 4.96071193\n",
      " 3.8903322  4.24344202 3.9928706  2.70834012]\n",
      "##########\n",
      "epoch:1 step:1401 [D loss: 0.673846, acc.: 53.91%] [G loss: 0.905774]\n",
      "epoch:1 step:1402 [D loss: 0.748207, acc.: 47.66%] [G loss: 0.784034]\n",
      "epoch:1 step:1403 [D loss: 0.716847, acc.: 50.78%] [G loss: 1.044374]\n",
      "epoch:1 step:1404 [D loss: 0.749407, acc.: 47.66%] [G loss: 0.901488]\n",
      "epoch:1 step:1405 [D loss: 0.715544, acc.: 53.91%] [G loss: 0.979719]\n",
      "epoch:1 step:1406 [D loss: 0.631634, acc.: 61.72%] [G loss: 0.870370]\n",
      "epoch:1 step:1407 [D loss: 0.650710, acc.: 60.94%] [G loss: 0.997839]\n",
      "epoch:1 step:1408 [D loss: 0.676774, acc.: 57.03%] [G loss: 0.959910]\n",
      "epoch:1 step:1409 [D loss: 0.704442, acc.: 57.81%] [G loss: 1.021919]\n",
      "epoch:1 step:1410 [D loss: 0.747652, acc.: 51.56%] [G loss: 0.878692]\n",
      "epoch:1 step:1411 [D loss: 0.696559, acc.: 53.12%] [G loss: 0.892953]\n",
      "epoch:1 step:1412 [D loss: 0.776795, acc.: 52.34%] [G loss: 0.829489]\n",
      "epoch:1 step:1413 [D loss: 0.692109, acc.: 56.25%] [G loss: 0.909365]\n",
      "epoch:1 step:1414 [D loss: 0.758445, acc.: 45.31%] [G loss: 0.982047]\n",
      "epoch:1 step:1415 [D loss: 0.646170, acc.: 61.72%] [G loss: 0.927624]\n",
      "epoch:1 step:1416 [D loss: 0.752651, acc.: 53.12%] [G loss: 0.959926]\n",
      "epoch:1 step:1417 [D loss: 0.731349, acc.: 57.03%] [G loss: 0.970426]\n",
      "epoch:1 step:1418 [D loss: 0.633631, acc.: 64.84%] [G loss: 1.036187]\n",
      "epoch:1 step:1419 [D loss: 0.702745, acc.: 53.91%] [G loss: 0.927916]\n",
      "epoch:1 step:1420 [D loss: 0.719554, acc.: 54.69%] [G loss: 0.923209]\n",
      "epoch:1 step:1421 [D loss: 0.683379, acc.: 62.50%] [G loss: 0.895835]\n",
      "epoch:1 step:1422 [D loss: 0.674880, acc.: 62.50%] [G loss: 0.954029]\n",
      "epoch:1 step:1423 [D loss: 0.717737, acc.: 50.78%] [G loss: 0.997825]\n",
      "epoch:1 step:1424 [D loss: 0.783672, acc.: 43.75%] [G loss: 0.920103]\n",
      "epoch:1 step:1425 [D loss: 0.638729, acc.: 67.19%] [G loss: 1.055651]\n",
      "epoch:1 step:1426 [D loss: 0.666737, acc.: 58.59%] [G loss: 0.961207]\n",
      "epoch:1 step:1427 [D loss: 0.705408, acc.: 54.69%] [G loss: 0.940645]\n",
      "epoch:1 step:1428 [D loss: 0.661320, acc.: 60.94%] [G loss: 0.929793]\n",
      "epoch:1 step:1429 [D loss: 0.747724, acc.: 49.22%] [G loss: 0.928867]\n",
      "epoch:1 step:1430 [D loss: 0.681011, acc.: 60.16%] [G loss: 0.864119]\n",
      "epoch:1 step:1431 [D loss: 0.661824, acc.: 60.94%] [G loss: 1.013541]\n",
      "epoch:1 step:1432 [D loss: 0.685172, acc.: 55.47%] [G loss: 0.905864]\n",
      "epoch:1 step:1433 [D loss: 0.668917, acc.: 62.50%] [G loss: 0.934371]\n",
      "epoch:1 step:1434 [D loss: 0.700277, acc.: 53.12%] [G loss: 0.923531]\n",
      "epoch:1 step:1435 [D loss: 0.658454, acc.: 57.81%] [G loss: 0.986594]\n",
      "epoch:1 step:1436 [D loss: 0.694196, acc.: 57.03%] [G loss: 0.904227]\n",
      "epoch:1 step:1437 [D loss: 0.714570, acc.: 53.91%] [G loss: 0.984914]\n",
      "epoch:1 step:1438 [D loss: 0.727339, acc.: 57.03%] [G loss: 0.914794]\n",
      "epoch:1 step:1439 [D loss: 0.751491, acc.: 51.56%] [G loss: 0.897137]\n",
      "epoch:1 step:1440 [D loss: 0.721453, acc.: 50.78%] [G loss: 0.869501]\n",
      "epoch:1 step:1441 [D loss: 0.721718, acc.: 56.25%] [G loss: 0.929886]\n",
      "epoch:1 step:1442 [D loss: 0.660564, acc.: 59.38%] [G loss: 0.982820]\n",
      "epoch:1 step:1443 [D loss: 0.724903, acc.: 52.34%] [G loss: 0.986520]\n",
      "epoch:1 step:1444 [D loss: 0.699762, acc.: 53.91%] [G loss: 0.991273]\n",
      "epoch:1 step:1445 [D loss: 0.698330, acc.: 57.03%] [G loss: 0.981290]\n",
      "epoch:1 step:1446 [D loss: 0.774198, acc.: 49.22%] [G loss: 0.915380]\n",
      "epoch:1 step:1447 [D loss: 0.738362, acc.: 55.47%] [G loss: 0.871738]\n",
      "epoch:1 step:1448 [D loss: 0.760706, acc.: 46.88%] [G loss: 0.975511]\n",
      "epoch:1 step:1449 [D loss: 0.714404, acc.: 54.69%] [G loss: 0.889518]\n",
      "epoch:1 step:1450 [D loss: 0.728836, acc.: 52.34%] [G loss: 0.942120]\n",
      "epoch:1 step:1451 [D loss: 0.721089, acc.: 52.34%] [G loss: 0.971840]\n",
      "epoch:1 step:1452 [D loss: 0.680595, acc.: 56.25%] [G loss: 0.934240]\n",
      "epoch:1 step:1453 [D loss: 0.697404, acc.: 57.03%] [G loss: 0.939372]\n",
      "epoch:1 step:1454 [D loss: 0.766876, acc.: 50.00%] [G loss: 0.993569]\n",
      "epoch:1 step:1455 [D loss: 0.735856, acc.: 54.69%] [G loss: 0.913126]\n",
      "epoch:1 step:1456 [D loss: 0.707424, acc.: 60.94%] [G loss: 0.935516]\n",
      "epoch:1 step:1457 [D loss: 0.611283, acc.: 64.06%] [G loss: 0.958451]\n",
      "epoch:1 step:1458 [D loss: 0.665777, acc.: 59.38%] [G loss: 0.951051]\n",
      "epoch:1 step:1459 [D loss: 0.647351, acc.: 60.16%] [G loss: 0.848354]\n",
      "epoch:1 step:1460 [D loss: 0.686701, acc.: 57.03%] [G loss: 1.026603]\n",
      "epoch:1 step:1461 [D loss: 0.716871, acc.: 57.03%] [G loss: 0.963306]\n",
      "epoch:1 step:1462 [D loss: 0.659243, acc.: 60.16%] [G loss: 0.997784]\n",
      "epoch:1 step:1463 [D loss: 0.668004, acc.: 60.94%] [G loss: 0.954470]\n",
      "epoch:1 step:1464 [D loss: 0.664738, acc.: 60.94%] [G loss: 0.916588]\n",
      "epoch:1 step:1465 [D loss: 0.706269, acc.: 57.03%] [G loss: 0.949806]\n",
      "epoch:1 step:1466 [D loss: 0.589083, acc.: 71.88%] [G loss: 0.954813]\n",
      "epoch:1 step:1467 [D loss: 0.704379, acc.: 56.25%] [G loss: 1.011171]\n",
      "epoch:1 step:1468 [D loss: 0.686449, acc.: 57.03%] [G loss: 0.828610]\n",
      "epoch:1 step:1469 [D loss: 0.668393, acc.: 62.50%] [G loss: 0.918384]\n",
      "epoch:1 step:1470 [D loss: 0.706253, acc.: 54.69%] [G loss: 0.943115]\n",
      "epoch:1 step:1471 [D loss: 0.663276, acc.: 64.06%] [G loss: 0.998963]\n",
      "epoch:1 step:1472 [D loss: 0.658575, acc.: 58.59%] [G loss: 1.016972]\n",
      "epoch:1 step:1473 [D loss: 0.643143, acc.: 58.59%] [G loss: 1.045244]\n",
      "epoch:1 step:1474 [D loss: 0.700122, acc.: 60.16%] [G loss: 0.980483]\n",
      "epoch:1 step:1475 [D loss: 0.699016, acc.: 57.03%] [G loss: 0.968707]\n",
      "epoch:1 step:1476 [D loss: 0.805390, acc.: 45.31%] [G loss: 0.941946]\n",
      "epoch:1 step:1477 [D loss: 0.718987, acc.: 48.44%] [G loss: 0.840555]\n",
      "epoch:1 step:1478 [D loss: 0.689330, acc.: 57.03%] [G loss: 0.856023]\n",
      "epoch:1 step:1479 [D loss: 0.726321, acc.: 49.22%] [G loss: 0.874943]\n",
      "epoch:1 step:1480 [D loss: 0.754171, acc.: 46.09%] [G loss: 0.920002]\n",
      "epoch:1 step:1481 [D loss: 0.721743, acc.: 52.34%] [G loss: 1.096414]\n",
      "epoch:1 step:1482 [D loss: 0.678891, acc.: 56.25%] [G loss: 0.866241]\n",
      "epoch:1 step:1483 [D loss: 0.620282, acc.: 69.53%] [G loss: 1.093815]\n",
      "epoch:1 step:1484 [D loss: 0.635748, acc.: 62.50%] [G loss: 0.966092]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1485 [D loss: 0.633446, acc.: 64.06%] [G loss: 0.987285]\n",
      "epoch:1 step:1486 [D loss: 0.673282, acc.: 57.81%] [G loss: 0.964047]\n",
      "epoch:1 step:1487 [D loss: 0.640070, acc.: 60.94%] [G loss: 0.858898]\n",
      "epoch:1 step:1488 [D loss: 0.644964, acc.: 67.19%] [G loss: 1.020366]\n",
      "epoch:1 step:1489 [D loss: 0.660013, acc.: 56.25%] [G loss: 0.991462]\n",
      "epoch:1 step:1490 [D loss: 0.634428, acc.: 60.94%] [G loss: 1.105450]\n",
      "epoch:1 step:1491 [D loss: 0.615288, acc.: 71.09%] [G loss: 1.067952]\n",
      "epoch:1 step:1492 [D loss: 0.629722, acc.: 64.06%] [G loss: 1.063843]\n",
      "epoch:1 step:1493 [D loss: 0.615530, acc.: 67.97%] [G loss: 1.157817]\n",
      "epoch:1 step:1494 [D loss: 0.637312, acc.: 60.94%] [G loss: 1.135213]\n",
      "epoch:1 step:1495 [D loss: 0.692476, acc.: 56.25%] [G loss: 1.002905]\n",
      "epoch:1 step:1496 [D loss: 0.759479, acc.: 53.91%] [G loss: 0.903102]\n",
      "epoch:1 step:1497 [D loss: 0.787584, acc.: 45.31%] [G loss: 0.830023]\n",
      "epoch:1 step:1498 [D loss: 0.662295, acc.: 58.59%] [G loss: 0.960511]\n",
      "epoch:1 step:1499 [D loss: 0.664184, acc.: 60.94%] [G loss: 0.905241]\n",
      "epoch:1 step:1500 [D loss: 0.668270, acc.: 57.81%] [G loss: 0.971824]\n",
      "epoch:1 step:1501 [D loss: 0.636401, acc.: 61.72%] [G loss: 1.060032]\n",
      "epoch:1 step:1502 [D loss: 0.724905, acc.: 50.00%] [G loss: 0.964110]\n",
      "epoch:1 step:1503 [D loss: 0.824497, acc.: 43.75%] [G loss: 0.940045]\n",
      "epoch:1 step:1504 [D loss: 0.627927, acc.: 65.62%] [G loss: 0.938804]\n",
      "epoch:1 step:1505 [D loss: 0.745161, acc.: 50.78%] [G loss: 0.851572]\n",
      "epoch:1 step:1506 [D loss: 0.656025, acc.: 58.59%] [G loss: 0.955357]\n",
      "epoch:1 step:1507 [D loss: 0.705908, acc.: 53.91%] [G loss: 0.940784]\n",
      "epoch:1 step:1508 [D loss: 0.705196, acc.: 57.81%] [G loss: 0.977968]\n",
      "epoch:1 step:1509 [D loss: 0.743794, acc.: 50.78%] [G loss: 0.809732]\n",
      "epoch:1 step:1510 [D loss: 0.682913, acc.: 52.34%] [G loss: 0.883471]\n",
      "epoch:1 step:1511 [D loss: 0.680780, acc.: 57.81%] [G loss: 0.863789]\n",
      "epoch:1 step:1512 [D loss: 0.610672, acc.: 64.84%] [G loss: 0.955595]\n",
      "epoch:1 step:1513 [D loss: 0.691925, acc.: 56.25%] [G loss: 1.005560]\n",
      "epoch:1 step:1514 [D loss: 0.702729, acc.: 58.59%] [G loss: 0.896720]\n",
      "epoch:1 step:1515 [D loss: 0.641083, acc.: 68.75%] [G loss: 0.861092]\n",
      "epoch:1 step:1516 [D loss: 0.703281, acc.: 52.34%] [G loss: 1.010137]\n",
      "epoch:1 step:1517 [D loss: 0.748908, acc.: 46.88%] [G loss: 0.983568]\n",
      "epoch:1 step:1518 [D loss: 0.676853, acc.: 56.25%] [G loss: 0.954919]\n",
      "epoch:1 step:1519 [D loss: 0.717911, acc.: 50.78%] [G loss: 0.873177]\n",
      "epoch:1 step:1520 [D loss: 0.674194, acc.: 59.38%] [G loss: 0.903378]\n",
      "epoch:1 step:1521 [D loss: 0.720164, acc.: 53.12%] [G loss: 1.007271]\n",
      "epoch:1 step:1522 [D loss: 0.705863, acc.: 57.81%] [G loss: 0.880960]\n",
      "epoch:1 step:1523 [D loss: 0.746762, acc.: 52.34%] [G loss: 0.952391]\n",
      "epoch:1 step:1524 [D loss: 0.656896, acc.: 59.38%] [G loss: 0.945060]\n",
      "epoch:1 step:1525 [D loss: 0.666352, acc.: 64.06%] [G loss: 0.934994]\n",
      "epoch:1 step:1526 [D loss: 0.643858, acc.: 67.97%] [G loss: 1.015856]\n",
      "epoch:1 step:1527 [D loss: 0.725562, acc.: 50.00%] [G loss: 0.947427]\n",
      "epoch:1 step:1528 [D loss: 0.752407, acc.: 51.56%] [G loss: 0.819345]\n",
      "epoch:1 step:1529 [D loss: 0.698067, acc.: 57.03%] [G loss: 0.957804]\n",
      "epoch:1 step:1530 [D loss: 0.733672, acc.: 51.56%] [G loss: 0.962996]\n",
      "epoch:1 step:1531 [D loss: 0.700519, acc.: 53.91%] [G loss: 0.984085]\n",
      "epoch:1 step:1532 [D loss: 0.729707, acc.: 48.44%] [G loss: 0.885867]\n",
      "epoch:1 step:1533 [D loss: 0.703923, acc.: 57.81%] [G loss: 0.871512]\n",
      "epoch:1 step:1534 [D loss: 0.749093, acc.: 46.09%] [G loss: 0.883822]\n",
      "epoch:1 step:1535 [D loss: 0.725467, acc.: 48.44%] [G loss: 0.918276]\n",
      "epoch:1 step:1536 [D loss: 0.736473, acc.: 53.12%] [G loss: 0.940163]\n",
      "epoch:1 step:1537 [D loss: 0.749499, acc.: 47.66%] [G loss: 0.871812]\n",
      "epoch:1 step:1538 [D loss: 0.742702, acc.: 50.78%] [G loss: 0.887160]\n",
      "epoch:1 step:1539 [D loss: 0.680847, acc.: 59.38%] [G loss: 0.933769]\n",
      "epoch:1 step:1540 [D loss: 0.610871, acc.: 67.97%] [G loss: 0.961661]\n",
      "epoch:1 step:1541 [D loss: 0.720716, acc.: 53.12%] [G loss: 0.882434]\n",
      "epoch:1 step:1542 [D loss: 0.696261, acc.: 61.72%] [G loss: 0.869258]\n",
      "epoch:1 step:1543 [D loss: 0.638645, acc.: 62.50%] [G loss: 1.007241]\n",
      "epoch:1 step:1544 [D loss: 0.687481, acc.: 63.28%] [G loss: 0.958306]\n",
      "epoch:1 step:1545 [D loss: 0.668108, acc.: 60.94%] [G loss: 0.991305]\n",
      "epoch:1 step:1546 [D loss: 0.677263, acc.: 53.91%] [G loss: 1.022253]\n",
      "epoch:1 step:1547 [D loss: 0.733491, acc.: 51.56%] [G loss: 1.073009]\n",
      "epoch:1 step:1548 [D loss: 0.697805, acc.: 57.03%] [G loss: 0.949444]\n",
      "epoch:1 step:1549 [D loss: 0.653408, acc.: 63.28%] [G loss: 1.021936]\n",
      "epoch:1 step:1550 [D loss: 0.747730, acc.: 48.44%] [G loss: 0.887431]\n",
      "epoch:1 step:1551 [D loss: 0.688119, acc.: 57.03%] [G loss: 0.938109]\n",
      "epoch:1 step:1552 [D loss: 0.754917, acc.: 48.44%] [G loss: 1.022608]\n",
      "epoch:1 step:1553 [D loss: 0.702872, acc.: 57.03%] [G loss: 0.966156]\n",
      "epoch:1 step:1554 [D loss: 0.698416, acc.: 53.12%] [G loss: 0.878651]\n",
      "epoch:1 step:1555 [D loss: 0.696939, acc.: 56.25%] [G loss: 0.907741]\n",
      "epoch:1 step:1556 [D loss: 0.656551, acc.: 60.94%] [G loss: 0.950245]\n",
      "epoch:1 step:1557 [D loss: 0.732302, acc.: 53.12%] [G loss: 0.989635]\n",
      "epoch:1 step:1558 [D loss: 0.743208, acc.: 49.22%] [G loss: 0.913336]\n",
      "epoch:1 step:1559 [D loss: 0.732629, acc.: 49.22%] [G loss: 0.864868]\n",
      "epoch:1 step:1560 [D loss: 0.730693, acc.: 49.22%] [G loss: 0.862062]\n",
      "epoch:1 step:1561 [D loss: 0.659621, acc.: 59.38%] [G loss: 0.978916]\n",
      "epoch:1 step:1562 [D loss: 0.713966, acc.: 50.78%] [G loss: 0.960692]\n",
      "epoch:1 step:1563 [D loss: 0.682889, acc.: 62.50%] [G loss: 0.901081]\n",
      "epoch:1 step:1564 [D loss: 0.696898, acc.: 55.47%] [G loss: 0.933722]\n",
      "epoch:1 step:1565 [D loss: 0.678000, acc.: 59.38%] [G loss: 0.989209]\n",
      "epoch:1 step:1566 [D loss: 0.670200, acc.: 61.72%] [G loss: 0.916771]\n",
      "epoch:1 step:1567 [D loss: 0.672092, acc.: 58.59%] [G loss: 1.027505]\n",
      "epoch:1 step:1568 [D loss: 0.584856, acc.: 67.97%] [G loss: 1.051860]\n",
      "epoch:1 step:1569 [D loss: 0.685876, acc.: 57.03%] [G loss: 0.939515]\n",
      "epoch:1 step:1570 [D loss: 0.641736, acc.: 62.50%] [G loss: 1.014239]\n",
      "epoch:1 step:1571 [D loss: 0.650659, acc.: 60.16%] [G loss: 1.071974]\n",
      "epoch:1 step:1572 [D loss: 0.682047, acc.: 55.47%] [G loss: 0.949048]\n",
      "epoch:1 step:1573 [D loss: 0.728979, acc.: 50.00%] [G loss: 0.886511]\n",
      "epoch:1 step:1574 [D loss: 0.672585, acc.: 64.06%] [G loss: 0.949106]\n",
      "epoch:1 step:1575 [D loss: 0.693003, acc.: 60.16%] [G loss: 0.907146]\n",
      "epoch:1 step:1576 [D loss: 0.633170, acc.: 64.06%] [G loss: 1.047309]\n",
      "epoch:1 step:1577 [D loss: 0.666297, acc.: 60.16%] [G loss: 0.899355]\n",
      "epoch:1 step:1578 [D loss: 0.706953, acc.: 60.16%] [G loss: 0.862388]\n",
      "epoch:1 step:1579 [D loss: 0.697589, acc.: 53.12%] [G loss: 0.870538]\n",
      "epoch:1 step:1580 [D loss: 0.674456, acc.: 54.69%] [G loss: 1.029170]\n",
      "epoch:1 step:1581 [D loss: 0.664325, acc.: 61.72%] [G loss: 1.000952]\n",
      "epoch:1 step:1582 [D loss: 0.639712, acc.: 66.41%] [G loss: 0.996698]\n",
      "epoch:1 step:1583 [D loss: 0.630627, acc.: 60.16%] [G loss: 0.908388]\n",
      "epoch:1 step:1584 [D loss: 0.683753, acc.: 55.47%] [G loss: 1.016311]\n",
      "epoch:1 step:1585 [D loss: 0.677215, acc.: 57.03%] [G loss: 0.950410]\n",
      "epoch:1 step:1586 [D loss: 0.655786, acc.: 60.94%] [G loss: 0.998080]\n",
      "epoch:1 step:1587 [D loss: 0.669054, acc.: 60.94%] [G loss: 1.055622]\n",
      "epoch:1 step:1588 [D loss: 0.667531, acc.: 60.94%] [G loss: 0.990868]\n",
      "epoch:1 step:1589 [D loss: 0.669105, acc.: 60.16%] [G loss: 1.003302]\n",
      "epoch:1 step:1590 [D loss: 0.722195, acc.: 53.91%] [G loss: 0.898893]\n",
      "epoch:1 step:1591 [D loss: 0.645725, acc.: 60.94%] [G loss: 0.906276]\n",
      "epoch:1 step:1592 [D loss: 0.679918, acc.: 53.12%] [G loss: 1.018384]\n",
      "epoch:1 step:1593 [D loss: 0.735467, acc.: 51.56%] [G loss: 1.040789]\n",
      "epoch:1 step:1594 [D loss: 0.697957, acc.: 57.03%] [G loss: 1.022271]\n",
      "epoch:1 step:1595 [D loss: 0.680150, acc.: 60.94%] [G loss: 1.025459]\n",
      "epoch:1 step:1596 [D loss: 0.664166, acc.: 60.94%] [G loss: 1.008293]\n",
      "epoch:1 step:1597 [D loss: 0.680717, acc.: 55.47%] [G loss: 0.986722]\n",
      "epoch:1 step:1598 [D loss: 0.680785, acc.: 61.72%] [G loss: 0.894193]\n",
      "epoch:1 step:1599 [D loss: 0.692258, acc.: 60.16%] [G loss: 1.035659]\n",
      "epoch:1 step:1600 [D loss: 0.739385, acc.: 54.69%] [G loss: 0.949925]\n",
      "##############\n",
      "[2.06142909 0.27496485 5.48619101 3.70821123 2.71582079 4.84616099\n",
      " 3.46718032 3.77245007 3.93418856 2.86420265]\n",
      "##########\n",
      "epoch:1 step:1601 [D loss: 0.743855, acc.: 50.78%] [G loss: 0.906920]\n",
      "epoch:1 step:1602 [D loss: 0.667891, acc.: 58.59%] [G loss: 0.971571]\n",
      "epoch:1 step:1603 [D loss: 0.625545, acc.: 62.50%] [G loss: 0.991436]\n",
      "epoch:1 step:1604 [D loss: 0.673317, acc.: 56.25%] [G loss: 0.956317]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1605 [D loss: 0.733227, acc.: 55.47%] [G loss: 0.903829]\n",
      "epoch:1 step:1606 [D loss: 0.699363, acc.: 53.91%] [G loss: 0.954211]\n",
      "epoch:1 step:1607 [D loss: 0.692918, acc.: 52.34%] [G loss: 0.851356]\n",
      "epoch:1 step:1608 [D loss: 0.696060, acc.: 53.91%] [G loss: 0.872381]\n",
      "epoch:1 step:1609 [D loss: 0.741353, acc.: 52.34%] [G loss: 0.918321]\n",
      "epoch:1 step:1610 [D loss: 0.719784, acc.: 55.47%] [G loss: 0.987764]\n",
      "epoch:1 step:1611 [D loss: 0.670586, acc.: 58.59%] [G loss: 0.983624]\n",
      "epoch:1 step:1612 [D loss: 0.646992, acc.: 64.06%] [G loss: 0.955011]\n",
      "epoch:1 step:1613 [D loss: 0.716300, acc.: 53.91%] [G loss: 0.946006]\n",
      "epoch:1 step:1614 [D loss: 0.686770, acc.: 61.72%] [G loss: 0.952776]\n",
      "epoch:1 step:1615 [D loss: 0.624370, acc.: 62.50%] [G loss: 1.025426]\n",
      "epoch:1 step:1616 [D loss: 0.672096, acc.: 59.38%] [G loss: 0.930904]\n",
      "epoch:1 step:1617 [D loss: 0.687370, acc.: 56.25%] [G loss: 0.922641]\n",
      "epoch:1 step:1618 [D loss: 0.666708, acc.: 57.81%] [G loss: 0.876235]\n",
      "epoch:1 step:1619 [D loss: 0.694702, acc.: 59.38%] [G loss: 0.847973]\n",
      "epoch:1 step:1620 [D loss: 0.682875, acc.: 55.47%] [G loss: 0.991490]\n",
      "epoch:1 step:1621 [D loss: 0.670227, acc.: 56.25%] [G loss: 0.953406]\n",
      "epoch:1 step:1622 [D loss: 0.726837, acc.: 53.91%] [G loss: 0.965799]\n",
      "epoch:1 step:1623 [D loss: 0.655964, acc.: 55.47%] [G loss: 0.860930]\n",
      "epoch:1 step:1624 [D loss: 0.649833, acc.: 57.81%] [G loss: 0.923804]\n",
      "epoch:1 step:1625 [D loss: 0.616841, acc.: 62.50%] [G loss: 0.997651]\n",
      "epoch:1 step:1626 [D loss: 0.724968, acc.: 51.56%] [G loss: 0.910075]\n",
      "epoch:1 step:1627 [D loss: 0.693834, acc.: 52.34%] [G loss: 0.919869]\n",
      "epoch:1 step:1628 [D loss: 0.723293, acc.: 60.94%] [G loss: 0.941355]\n",
      "epoch:1 step:1629 [D loss: 0.715105, acc.: 54.69%] [G loss: 0.973837]\n",
      "epoch:1 step:1630 [D loss: 0.689572, acc.: 57.03%] [G loss: 0.909391]\n",
      "epoch:1 step:1631 [D loss: 0.644697, acc.: 59.38%] [G loss: 0.923455]\n",
      "epoch:1 step:1632 [D loss: 0.654770, acc.: 64.84%] [G loss: 1.013575]\n",
      "epoch:1 step:1633 [D loss: 0.737685, acc.: 52.34%] [G loss: 0.882873]\n",
      "epoch:1 step:1634 [D loss: 0.682670, acc.: 62.50%] [G loss: 0.910358]\n",
      "epoch:1 step:1635 [D loss: 0.661023, acc.: 60.94%] [G loss: 0.951412]\n",
      "epoch:1 step:1636 [D loss: 0.712542, acc.: 53.91%] [G loss: 0.928724]\n",
      "epoch:1 step:1637 [D loss: 0.670363, acc.: 60.94%] [G loss: 0.946883]\n",
      "epoch:1 step:1638 [D loss: 0.644850, acc.: 65.62%] [G loss: 0.914824]\n",
      "epoch:1 step:1639 [D loss: 0.677667, acc.: 59.38%] [G loss: 0.931000]\n",
      "epoch:1 step:1640 [D loss: 0.671461, acc.: 57.03%] [G loss: 0.935170]\n",
      "epoch:1 step:1641 [D loss: 0.690753, acc.: 59.38%] [G loss: 1.024597]\n",
      "epoch:1 step:1642 [D loss: 0.632951, acc.: 60.16%] [G loss: 0.853345]\n",
      "epoch:1 step:1643 [D loss: 0.662822, acc.: 64.84%] [G loss: 0.996135]\n",
      "epoch:1 step:1644 [D loss: 0.599608, acc.: 63.28%] [G loss: 0.971899]\n",
      "epoch:1 step:1645 [D loss: 0.662786, acc.: 59.38%] [G loss: 0.939877]\n",
      "epoch:1 step:1646 [D loss: 0.576274, acc.: 75.78%] [G loss: 1.042911]\n",
      "epoch:1 step:1647 [D loss: 0.788044, acc.: 48.44%] [G loss: 1.006249]\n",
      "epoch:1 step:1648 [D loss: 0.770402, acc.: 49.22%] [G loss: 0.802366]\n",
      "epoch:1 step:1649 [D loss: 0.668479, acc.: 58.59%] [G loss: 1.009059]\n",
      "epoch:1 step:1650 [D loss: 0.666819, acc.: 56.25%] [G loss: 0.828004]\n",
      "epoch:1 step:1651 [D loss: 0.753922, acc.: 46.09%] [G loss: 0.839601]\n",
      "epoch:1 step:1652 [D loss: 0.732548, acc.: 55.47%] [G loss: 0.945869]\n",
      "epoch:1 step:1653 [D loss: 0.691846, acc.: 53.91%] [G loss: 0.971438]\n",
      "epoch:1 step:1654 [D loss: 0.718190, acc.: 54.69%] [G loss: 0.990404]\n",
      "epoch:1 step:1655 [D loss: 0.715673, acc.: 53.91%] [G loss: 0.897654]\n",
      "epoch:1 step:1656 [D loss: 0.759280, acc.: 50.00%] [G loss: 0.913072]\n",
      "epoch:1 step:1657 [D loss: 0.698654, acc.: 55.47%] [G loss: 0.886164]\n",
      "epoch:1 step:1658 [D loss: 0.754315, acc.: 53.12%] [G loss: 0.917863]\n",
      "epoch:1 step:1659 [D loss: 0.672195, acc.: 64.06%] [G loss: 0.881207]\n",
      "epoch:1 step:1660 [D loss: 0.747602, acc.: 50.00%] [G loss: 0.839882]\n",
      "epoch:1 step:1661 [D loss: 0.687199, acc.: 53.12%] [G loss: 0.923993]\n",
      "epoch:1 step:1662 [D loss: 0.664874, acc.: 61.72%] [G loss: 0.939059]\n",
      "epoch:1 step:1663 [D loss: 0.631656, acc.: 60.16%] [G loss: 0.951575]\n",
      "epoch:1 step:1664 [D loss: 0.673481, acc.: 58.59%] [G loss: 0.924248]\n",
      "epoch:1 step:1665 [D loss: 0.734365, acc.: 46.88%] [G loss: 0.950015]\n",
      "epoch:1 step:1666 [D loss: 0.667214, acc.: 57.03%] [G loss: 0.972960]\n",
      "epoch:1 step:1667 [D loss: 0.701649, acc.: 57.03%] [G loss: 0.929368]\n",
      "epoch:1 step:1668 [D loss: 0.649318, acc.: 59.38%] [G loss: 0.980651]\n",
      "epoch:1 step:1669 [D loss: 0.698471, acc.: 56.25%] [G loss: 0.951754]\n",
      "epoch:1 step:1670 [D loss: 0.647311, acc.: 58.59%] [G loss: 0.994639]\n",
      "epoch:1 step:1671 [D loss: 0.726708, acc.: 53.91%] [G loss: 0.935591]\n",
      "epoch:1 step:1672 [D loss: 0.673277, acc.: 59.38%] [G loss: 1.005480]\n",
      "epoch:1 step:1673 [D loss: 0.731664, acc.: 52.34%] [G loss: 0.873802]\n",
      "epoch:1 step:1674 [D loss: 0.672265, acc.: 61.72%] [G loss: 0.992472]\n",
      "epoch:1 step:1675 [D loss: 0.722956, acc.: 52.34%] [G loss: 0.886766]\n",
      "epoch:1 step:1676 [D loss: 0.721026, acc.: 56.25%] [G loss: 0.952338]\n",
      "epoch:1 step:1677 [D loss: 0.653517, acc.: 64.06%] [G loss: 1.052289]\n",
      "epoch:1 step:1678 [D loss: 0.688381, acc.: 57.03%] [G loss: 0.937897]\n",
      "epoch:1 step:1679 [D loss: 0.711934, acc.: 57.03%] [G loss: 0.861772]\n",
      "epoch:1 step:1680 [D loss: 0.660733, acc.: 67.19%] [G loss: 0.951459]\n",
      "epoch:1 step:1681 [D loss: 0.793797, acc.: 43.75%] [G loss: 0.885912]\n",
      "epoch:1 step:1682 [D loss: 0.751204, acc.: 50.78%] [G loss: 0.961828]\n",
      "epoch:1 step:1683 [D loss: 0.709314, acc.: 53.12%] [G loss: 0.916937]\n",
      "epoch:1 step:1684 [D loss: 0.658401, acc.: 64.06%] [G loss: 1.074061]\n",
      "epoch:1 step:1685 [D loss: 0.674055, acc.: 60.16%] [G loss: 0.937475]\n",
      "epoch:1 step:1686 [D loss: 0.664211, acc.: 59.38%] [G loss: 0.926183]\n",
      "epoch:1 step:1687 [D loss: 0.660200, acc.: 63.28%] [G loss: 1.029008]\n",
      "epoch:1 step:1688 [D loss: 0.681018, acc.: 57.81%] [G loss: 1.031911]\n",
      "epoch:1 step:1689 [D loss: 0.654321, acc.: 57.81%] [G loss: 0.909786]\n",
      "epoch:1 step:1690 [D loss: 0.676794, acc.: 56.25%] [G loss: 0.949283]\n",
      "epoch:1 step:1691 [D loss: 0.651252, acc.: 61.72%] [G loss: 1.010142]\n",
      "epoch:1 step:1692 [D loss: 0.659412, acc.: 53.91%] [G loss: 0.916980]\n",
      "epoch:1 step:1693 [D loss: 0.690424, acc.: 57.81%] [G loss: 0.929697]\n",
      "epoch:1 step:1694 [D loss: 0.702348, acc.: 52.34%] [G loss: 0.896175]\n",
      "epoch:1 step:1695 [D loss: 0.718585, acc.: 55.47%] [G loss: 0.970025]\n",
      "epoch:1 step:1696 [D loss: 0.686847, acc.: 57.03%] [G loss: 0.897387]\n",
      "epoch:1 step:1697 [D loss: 0.688408, acc.: 56.25%] [G loss: 0.975318]\n",
      "epoch:1 step:1698 [D loss: 0.647630, acc.: 65.62%] [G loss: 0.976139]\n",
      "epoch:1 step:1699 [D loss: 0.663168, acc.: 63.28%] [G loss: 1.026851]\n",
      "epoch:1 step:1700 [D loss: 0.658555, acc.: 62.50%] [G loss: 1.022456]\n",
      "epoch:1 step:1701 [D loss: 0.672512, acc.: 53.91%] [G loss: 0.867872]\n",
      "epoch:1 step:1702 [D loss: 0.726619, acc.: 50.78%] [G loss: 0.986282]\n",
      "epoch:1 step:1703 [D loss: 0.691888, acc.: 59.38%] [G loss: 0.921889]\n",
      "epoch:1 step:1704 [D loss: 0.681088, acc.: 57.03%] [G loss: 0.950971]\n",
      "epoch:1 step:1705 [D loss: 0.693695, acc.: 51.56%] [G loss: 1.000170]\n",
      "epoch:1 step:1706 [D loss: 0.697675, acc.: 58.59%] [G loss: 1.084453]\n",
      "epoch:1 step:1707 [D loss: 0.669132, acc.: 60.94%] [G loss: 0.991776]\n",
      "epoch:1 step:1708 [D loss: 0.705794, acc.: 56.25%] [G loss: 1.006310]\n",
      "epoch:1 step:1709 [D loss: 0.731407, acc.: 54.69%] [G loss: 0.966460]\n",
      "epoch:1 step:1710 [D loss: 0.670942, acc.: 58.59%] [G loss: 0.852465]\n",
      "epoch:1 step:1711 [D loss: 0.700593, acc.: 55.47%] [G loss: 0.950137]\n",
      "epoch:1 step:1712 [D loss: 0.670294, acc.: 59.38%] [G loss: 0.927904]\n",
      "epoch:1 step:1713 [D loss: 0.666438, acc.: 55.47%] [G loss: 0.973582]\n",
      "epoch:1 step:1714 [D loss: 0.685355, acc.: 56.25%] [G loss: 1.042932]\n",
      "epoch:1 step:1715 [D loss: 0.721000, acc.: 50.78%] [G loss: 0.912588]\n",
      "epoch:1 step:1716 [D loss: 0.705478, acc.: 54.69%] [G loss: 0.920873]\n",
      "epoch:1 step:1717 [D loss: 0.719090, acc.: 55.47%] [G loss: 0.933515]\n",
      "epoch:1 step:1718 [D loss: 0.702313, acc.: 57.03%] [G loss: 0.987423]\n",
      "epoch:1 step:1719 [D loss: 0.651812, acc.: 60.94%] [G loss: 0.806220]\n",
      "epoch:1 step:1720 [D loss: 0.681362, acc.: 60.16%] [G loss: 0.834288]\n",
      "epoch:1 step:1721 [D loss: 0.691603, acc.: 56.25%] [G loss: 0.920145]\n",
      "epoch:1 step:1722 [D loss: 0.657140, acc.: 58.59%] [G loss: 1.076098]\n",
      "epoch:1 step:1723 [D loss: 0.711560, acc.: 53.12%] [G loss: 0.934406]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1724 [D loss: 0.693747, acc.: 55.47%] [G loss: 0.852213]\n",
      "epoch:1 step:1725 [D loss: 0.680619, acc.: 57.03%] [G loss: 0.963042]\n",
      "epoch:1 step:1726 [D loss: 0.644625, acc.: 63.28%] [G loss: 1.005483]\n",
      "epoch:1 step:1727 [D loss: 0.670879, acc.: 61.72%] [G loss: 0.944786]\n",
      "epoch:1 step:1728 [D loss: 0.674862, acc.: 56.25%] [G loss: 0.901361]\n",
      "epoch:1 step:1729 [D loss: 0.675354, acc.: 59.38%] [G loss: 1.134727]\n",
      "epoch:1 step:1730 [D loss: 0.691628, acc.: 52.34%] [G loss: 1.048626]\n",
      "epoch:1 step:1731 [D loss: 0.689097, acc.: 59.38%] [G loss: 0.916111]\n",
      "epoch:1 step:1732 [D loss: 0.683082, acc.: 57.03%] [G loss: 0.893643]\n",
      "epoch:1 step:1733 [D loss: 0.697210, acc.: 60.94%] [G loss: 0.871817]\n",
      "epoch:1 step:1734 [D loss: 0.707150, acc.: 57.81%] [G loss: 0.886482]\n",
      "epoch:1 step:1735 [D loss: 0.673485, acc.: 63.28%] [G loss: 0.952369]\n",
      "epoch:1 step:1736 [D loss: 0.687879, acc.: 60.94%] [G loss: 0.949328]\n",
      "epoch:1 step:1737 [D loss: 0.724270, acc.: 53.91%] [G loss: 0.883103]\n",
      "epoch:1 step:1738 [D loss: 0.778548, acc.: 42.19%] [G loss: 0.905615]\n",
      "epoch:1 step:1739 [D loss: 0.713663, acc.: 53.12%] [G loss: 0.882955]\n",
      "epoch:1 step:1740 [D loss: 0.683921, acc.: 62.50%] [G loss: 1.010073]\n",
      "epoch:1 step:1741 [D loss: 0.734152, acc.: 47.66%] [G loss: 1.084842]\n",
      "epoch:1 step:1742 [D loss: 0.676510, acc.: 57.03%] [G loss: 1.055409]\n",
      "epoch:1 step:1743 [D loss: 0.616532, acc.: 66.41%] [G loss: 0.901788]\n",
      "epoch:1 step:1744 [D loss: 0.629465, acc.: 67.19%] [G loss: 0.939156]\n",
      "epoch:1 step:1745 [D loss: 0.740637, acc.: 46.88%] [G loss: 0.900986]\n",
      "epoch:1 step:1746 [D loss: 0.696144, acc.: 61.72%] [G loss: 0.954240]\n",
      "epoch:1 step:1747 [D loss: 0.636754, acc.: 64.06%] [G loss: 1.055488]\n",
      "epoch:1 step:1748 [D loss: 0.669664, acc.: 54.69%] [G loss: 1.053198]\n",
      "epoch:1 step:1749 [D loss: 0.717201, acc.: 54.69%] [G loss: 1.018765]\n",
      "epoch:1 step:1750 [D loss: 0.699017, acc.: 56.25%] [G loss: 0.954907]\n",
      "epoch:1 step:1751 [D loss: 0.684342, acc.: 56.25%] [G loss: 0.952844]\n",
      "epoch:1 step:1752 [D loss: 0.724653, acc.: 49.22%] [G loss: 1.022999]\n",
      "epoch:1 step:1753 [D loss: 0.670261, acc.: 60.94%] [G loss: 0.918951]\n",
      "epoch:1 step:1754 [D loss: 0.658424, acc.: 59.38%] [G loss: 0.941254]\n",
      "epoch:1 step:1755 [D loss: 0.661668, acc.: 64.06%] [G loss: 0.906672]\n",
      "epoch:1 step:1756 [D loss: 0.608646, acc.: 67.19%] [G loss: 1.034272]\n",
      "epoch:1 step:1757 [D loss: 0.709216, acc.: 53.91%] [G loss: 0.943229]\n",
      "epoch:1 step:1758 [D loss: 0.649760, acc.: 59.38%] [G loss: 0.996575]\n",
      "epoch:1 step:1759 [D loss: 0.659126, acc.: 61.72%] [G loss: 0.899200]\n",
      "epoch:1 step:1760 [D loss: 0.712740, acc.: 56.25%] [G loss: 0.861814]\n",
      "epoch:1 step:1761 [D loss: 0.694707, acc.: 51.56%] [G loss: 0.985875]\n",
      "epoch:1 step:1762 [D loss: 0.616058, acc.: 65.62%] [G loss: 1.045676]\n",
      "epoch:1 step:1763 [D loss: 0.710383, acc.: 53.91%] [G loss: 0.930456]\n",
      "epoch:1 step:1764 [D loss: 0.661842, acc.: 60.94%] [G loss: 0.976190]\n",
      "epoch:1 step:1765 [D loss: 0.708297, acc.: 51.56%] [G loss: 0.971947]\n",
      "epoch:1 step:1766 [D loss: 0.699781, acc.: 56.25%] [G loss: 0.924330]\n",
      "epoch:1 step:1767 [D loss: 0.668569, acc.: 60.94%] [G loss: 0.975093]\n",
      "epoch:1 step:1768 [D loss: 0.694593, acc.: 58.59%] [G loss: 1.008721]\n",
      "epoch:1 step:1769 [D loss: 0.602324, acc.: 68.75%] [G loss: 1.100278]\n",
      "epoch:1 step:1770 [D loss: 0.649747, acc.: 59.38%] [G loss: 1.018562]\n",
      "epoch:1 step:1771 [D loss: 0.716246, acc.: 51.56%] [G loss: 0.830230]\n",
      "epoch:1 step:1772 [D loss: 0.688347, acc.: 56.25%] [G loss: 1.004770]\n",
      "epoch:1 step:1773 [D loss: 0.716969, acc.: 54.69%] [G loss: 0.934848]\n",
      "epoch:1 step:1774 [D loss: 0.678389, acc.: 57.03%] [G loss: 0.925581]\n",
      "epoch:1 step:1775 [D loss: 0.631951, acc.: 64.06%] [G loss: 0.995019]\n",
      "epoch:1 step:1776 [D loss: 0.623893, acc.: 63.28%] [G loss: 0.853865]\n",
      "epoch:1 step:1777 [D loss: 0.706497, acc.: 57.03%] [G loss: 1.000905]\n",
      "epoch:1 step:1778 [D loss: 0.617431, acc.: 65.62%] [G loss: 0.985895]\n",
      "epoch:1 step:1779 [D loss: 0.592579, acc.: 71.88%] [G loss: 0.943510]\n",
      "epoch:1 step:1780 [D loss: 0.662800, acc.: 60.94%] [G loss: 0.982172]\n",
      "epoch:1 step:1781 [D loss: 0.676428, acc.: 57.81%] [G loss: 0.987684]\n",
      "epoch:1 step:1782 [D loss: 0.695506, acc.: 60.16%] [G loss: 0.960390]\n",
      "epoch:1 step:1783 [D loss: 0.681694, acc.: 57.03%] [G loss: 0.919985]\n",
      "epoch:1 step:1784 [D loss: 0.612659, acc.: 64.06%] [G loss: 0.970512]\n",
      "epoch:1 step:1785 [D loss: 0.645817, acc.: 66.41%] [G loss: 0.967961]\n",
      "epoch:1 step:1786 [D loss: 0.686579, acc.: 53.12%] [G loss: 1.017496]\n",
      "epoch:1 step:1787 [D loss: 0.670772, acc.: 59.38%] [G loss: 0.966885]\n",
      "epoch:1 step:1788 [D loss: 0.713892, acc.: 56.25%] [G loss: 0.907620]\n",
      "epoch:1 step:1789 [D loss: 0.621505, acc.: 63.28%] [G loss: 1.003158]\n",
      "epoch:1 step:1790 [D loss: 0.734860, acc.: 50.00%] [G loss: 0.899318]\n",
      "epoch:1 step:1791 [D loss: 0.668858, acc.: 60.16%] [G loss: 0.870236]\n",
      "epoch:1 step:1792 [D loss: 0.719189, acc.: 56.25%] [G loss: 1.030329]\n",
      "epoch:1 step:1793 [D loss: 0.664861, acc.: 62.50%] [G loss: 0.923998]\n",
      "epoch:1 step:1794 [D loss: 0.658983, acc.: 59.38%] [G loss: 0.829077]\n",
      "epoch:1 step:1795 [D loss: 0.694856, acc.: 56.25%] [G loss: 0.926214]\n",
      "epoch:1 step:1796 [D loss: 0.669442, acc.: 62.50%] [G loss: 1.021360]\n",
      "epoch:1 step:1797 [D loss: 0.648711, acc.: 64.84%] [G loss: 1.053995]\n",
      "epoch:1 step:1798 [D loss: 0.667423, acc.: 60.16%] [G loss: 1.051747]\n",
      "epoch:1 step:1799 [D loss: 0.702784, acc.: 51.56%] [G loss: 0.956767]\n",
      "epoch:1 step:1800 [D loss: 0.649901, acc.: 64.06%] [G loss: 0.996677]\n",
      "##############\n",
      "[1.96875208 0.42974035 5.19853664 3.8624566  2.92002029 4.66680902\n",
      " 3.4655974  3.78666957 3.57487868 2.76000482]\n",
      "##########\n",
      "epoch:1 step:1801 [D loss: 0.652110, acc.: 59.38%] [G loss: 1.061357]\n",
      "epoch:1 step:1802 [D loss: 0.713114, acc.: 57.03%] [G loss: 0.932762]\n",
      "epoch:1 step:1803 [D loss: 0.675568, acc.: 54.69%] [G loss: 0.988896]\n",
      "epoch:1 step:1804 [D loss: 0.825836, acc.: 40.62%] [G loss: 0.942294]\n",
      "epoch:1 step:1805 [D loss: 0.686823, acc.: 57.81%] [G loss: 0.919549]\n",
      "epoch:1 step:1806 [D loss: 0.751829, acc.: 50.78%] [G loss: 0.931582]\n",
      "epoch:1 step:1807 [D loss: 0.744840, acc.: 55.47%] [G loss: 0.892467]\n",
      "epoch:1 step:1808 [D loss: 0.689526, acc.: 58.59%] [G loss: 0.901874]\n",
      "epoch:1 step:1809 [D loss: 0.701476, acc.: 53.91%] [G loss: 0.880702]\n",
      "epoch:1 step:1810 [D loss: 0.695866, acc.: 56.25%] [G loss: 0.933138]\n",
      "epoch:1 step:1811 [D loss: 0.723819, acc.: 51.56%] [G loss: 0.905123]\n",
      "epoch:1 step:1812 [D loss: 0.655418, acc.: 56.25%] [G loss: 0.990180]\n",
      "epoch:1 step:1813 [D loss: 0.697219, acc.: 54.69%] [G loss: 1.008914]\n",
      "epoch:1 step:1814 [D loss: 0.655103, acc.: 61.72%] [G loss: 0.989333]\n",
      "epoch:1 step:1815 [D loss: 0.712481, acc.: 53.91%] [G loss: 0.933720]\n",
      "epoch:1 step:1816 [D loss: 0.631624, acc.: 64.84%] [G loss: 0.930190]\n",
      "epoch:1 step:1817 [D loss: 0.663430, acc.: 61.72%] [G loss: 0.991300]\n",
      "epoch:1 step:1818 [D loss: 0.657976, acc.: 58.59%] [G loss: 0.914998]\n",
      "epoch:1 step:1819 [D loss: 0.723540, acc.: 51.56%] [G loss: 0.948425]\n",
      "epoch:1 step:1820 [D loss: 0.640714, acc.: 60.94%] [G loss: 0.960119]\n",
      "epoch:1 step:1821 [D loss: 0.712101, acc.: 52.34%] [G loss: 0.948202]\n",
      "epoch:1 step:1822 [D loss: 0.677057, acc.: 56.25%] [G loss: 0.883604]\n",
      "epoch:1 step:1823 [D loss: 0.626138, acc.: 65.62%] [G loss: 1.027076]\n",
      "epoch:1 step:1824 [D loss: 0.705190, acc.: 53.91%] [G loss: 0.997893]\n",
      "epoch:1 step:1825 [D loss: 0.571690, acc.: 72.66%] [G loss: 1.036802]\n",
      "epoch:1 step:1826 [D loss: 0.626807, acc.: 67.97%] [G loss: 1.047758]\n",
      "epoch:1 step:1827 [D loss: 0.652432, acc.: 60.94%] [G loss: 0.977426]\n",
      "epoch:1 step:1828 [D loss: 0.726577, acc.: 51.56%] [G loss: 0.959407]\n",
      "epoch:1 step:1829 [D loss: 0.800023, acc.: 46.88%] [G loss: 0.963623]\n",
      "epoch:1 step:1830 [D loss: 0.729411, acc.: 51.56%] [G loss: 0.900097]\n",
      "epoch:1 step:1831 [D loss: 0.665952, acc.: 62.50%] [G loss: 0.972962]\n",
      "epoch:1 step:1832 [D loss: 0.674317, acc.: 59.38%] [G loss: 0.948315]\n",
      "epoch:1 step:1833 [D loss: 0.682530, acc.: 59.38%] [G loss: 0.963338]\n",
      "epoch:1 step:1834 [D loss: 0.697063, acc.: 60.94%] [G loss: 0.912997]\n",
      "epoch:1 step:1835 [D loss: 0.699110, acc.: 54.69%] [G loss: 0.925051]\n",
      "epoch:1 step:1836 [D loss: 0.642690, acc.: 63.28%] [G loss: 0.951641]\n",
      "epoch:1 step:1837 [D loss: 0.680011, acc.: 54.69%] [G loss: 0.884048]\n",
      "epoch:1 step:1838 [D loss: 0.713444, acc.: 51.56%] [G loss: 0.898401]\n",
      "epoch:1 step:1839 [D loss: 0.702648, acc.: 50.78%] [G loss: 0.999572]\n",
      "epoch:1 step:1840 [D loss: 0.648018, acc.: 61.72%] [G loss: 1.046078]\n",
      "epoch:1 step:1841 [D loss: 0.741415, acc.: 46.88%] [G loss: 0.917274]\n",
      "epoch:1 step:1842 [D loss: 0.699212, acc.: 55.47%] [G loss: 0.865589]\n",
      "epoch:1 step:1843 [D loss: 0.671336, acc.: 60.16%] [G loss: 0.833073]\n",
      "epoch:1 step:1844 [D loss: 0.656064, acc.: 60.16%] [G loss: 0.920198]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1845 [D loss: 0.726445, acc.: 53.12%] [G loss: 0.953361]\n",
      "epoch:1 step:1846 [D loss: 0.663526, acc.: 62.50%] [G loss: 0.916276]\n",
      "epoch:1 step:1847 [D loss: 0.649301, acc.: 60.16%] [G loss: 1.041768]\n",
      "epoch:1 step:1848 [D loss: 0.659379, acc.: 54.69%] [G loss: 1.127272]\n",
      "epoch:1 step:1849 [D loss: 0.618400, acc.: 67.97%] [G loss: 1.090158]\n",
      "epoch:1 step:1850 [D loss: 0.681629, acc.: 64.06%] [G loss: 0.964290]\n",
      "epoch:1 step:1851 [D loss: 0.655203, acc.: 60.16%] [G loss: 0.939943]\n",
      "epoch:1 step:1852 [D loss: 0.693500, acc.: 53.91%] [G loss: 0.985422]\n",
      "epoch:1 step:1853 [D loss: 0.682661, acc.: 60.16%] [G loss: 0.893247]\n",
      "epoch:1 step:1854 [D loss: 0.723906, acc.: 53.12%] [G loss: 0.967377]\n",
      "epoch:1 step:1855 [D loss: 0.622929, acc.: 71.09%] [G loss: 0.926256]\n",
      "epoch:1 step:1856 [D loss: 0.633709, acc.: 68.75%] [G loss: 0.997311]\n",
      "epoch:1 step:1857 [D loss: 0.797801, acc.: 48.44%] [G loss: 0.912990]\n",
      "epoch:1 step:1858 [D loss: 0.666780, acc.: 58.59%] [G loss: 0.911855]\n",
      "epoch:1 step:1859 [D loss: 0.621680, acc.: 64.06%] [G loss: 1.033498]\n",
      "epoch:1 step:1860 [D loss: 0.530417, acc.: 78.91%] [G loss: 1.060707]\n",
      "epoch:1 step:1861 [D loss: 0.535509, acc.: 79.69%] [G loss: 1.121379]\n",
      "epoch:1 step:1862 [D loss: 0.597305, acc.: 66.41%] [G loss: 1.108064]\n",
      "epoch:1 step:1863 [D loss: 0.602026, acc.: 67.19%] [G loss: 1.211044]\n",
      "epoch:1 step:1864 [D loss: 0.618851, acc.: 67.19%] [G loss: 1.033665]\n",
      "epoch:1 step:1865 [D loss: 0.860715, acc.: 44.53%] [G loss: 0.960057]\n",
      "epoch:1 step:1866 [D loss: 0.784169, acc.: 51.56%] [G loss: 0.925490]\n",
      "epoch:1 step:1867 [D loss: 0.613028, acc.: 72.66%] [G loss: 1.024371]\n",
      "epoch:1 step:1868 [D loss: 0.672607, acc.: 64.06%] [G loss: 0.905727]\n",
      "epoch:1 step:1869 [D loss: 0.706113, acc.: 54.69%] [G loss: 1.037451]\n",
      "epoch:1 step:1870 [D loss: 0.725788, acc.: 52.34%] [G loss: 0.973550]\n",
      "epoch:1 step:1871 [D loss: 0.688315, acc.: 60.16%] [G loss: 0.979105]\n",
      "epoch:1 step:1872 [D loss: 0.616583, acc.: 62.50%] [G loss: 0.921913]\n",
      "epoch:1 step:1873 [D loss: 0.657298, acc.: 63.28%] [G loss: 1.054774]\n",
      "epoch:1 step:1874 [D loss: 0.672600, acc.: 66.41%] [G loss: 0.990240]\n",
      "epoch:2 step:1875 [D loss: 0.627898, acc.: 60.94%] [G loss: 1.126508]\n",
      "epoch:2 step:1876 [D loss: 0.652610, acc.: 60.16%] [G loss: 1.091213]\n",
      "epoch:2 step:1877 [D loss: 0.655755, acc.: 61.72%] [G loss: 1.144921]\n",
      "epoch:2 step:1878 [D loss: 0.657509, acc.: 62.50%] [G loss: 0.964361]\n",
      "epoch:2 step:1879 [D loss: 0.608590, acc.: 65.62%] [G loss: 1.009311]\n",
      "epoch:2 step:1880 [D loss: 0.693901, acc.: 60.16%] [G loss: 0.995910]\n",
      "epoch:2 step:1881 [D loss: 0.717635, acc.: 50.00%] [G loss: 1.013359]\n",
      "epoch:2 step:1882 [D loss: 0.697391, acc.: 58.59%] [G loss: 1.018575]\n",
      "epoch:2 step:1883 [D loss: 0.670927, acc.: 53.12%] [G loss: 0.887903]\n",
      "epoch:2 step:1884 [D loss: 0.683228, acc.: 58.59%] [G loss: 1.123353]\n",
      "epoch:2 step:1885 [D loss: 0.752815, acc.: 47.66%] [G loss: 0.870975]\n",
      "epoch:2 step:1886 [D loss: 0.723564, acc.: 55.47%] [G loss: 1.063260]\n",
      "epoch:2 step:1887 [D loss: 0.641659, acc.: 63.28%] [G loss: 1.032866]\n",
      "epoch:2 step:1888 [D loss: 0.700363, acc.: 60.16%] [G loss: 1.028321]\n",
      "epoch:2 step:1889 [D loss: 0.623381, acc.: 64.06%] [G loss: 1.038211]\n",
      "epoch:2 step:1890 [D loss: 0.666026, acc.: 57.03%] [G loss: 0.916307]\n",
      "epoch:2 step:1891 [D loss: 0.721482, acc.: 55.47%] [G loss: 1.040511]\n",
      "epoch:2 step:1892 [D loss: 0.720970, acc.: 50.78%] [G loss: 0.901983]\n",
      "epoch:2 step:1893 [D loss: 0.680101, acc.: 57.81%] [G loss: 0.871474]\n",
      "epoch:2 step:1894 [D loss: 0.770576, acc.: 46.88%] [G loss: 0.970987]\n",
      "epoch:2 step:1895 [D loss: 0.721103, acc.: 50.00%] [G loss: 0.821156]\n",
      "epoch:2 step:1896 [D loss: 0.698389, acc.: 56.25%] [G loss: 0.830748]\n",
      "epoch:2 step:1897 [D loss: 0.611211, acc.: 66.41%] [G loss: 0.893160]\n",
      "epoch:2 step:1898 [D loss: 0.632982, acc.: 68.75%] [G loss: 0.971796]\n",
      "epoch:2 step:1899 [D loss: 0.619971, acc.: 67.97%] [G loss: 0.927428]\n",
      "epoch:2 step:1900 [D loss: 0.684362, acc.: 63.28%] [G loss: 0.997004]\n",
      "epoch:2 step:1901 [D loss: 0.706039, acc.: 53.91%] [G loss: 0.997685]\n",
      "epoch:2 step:1902 [D loss: 0.664248, acc.: 57.81%] [G loss: 0.936502]\n",
      "epoch:2 step:1903 [D loss: 0.671915, acc.: 60.16%] [G loss: 0.885347]\n",
      "epoch:2 step:1904 [D loss: 0.685125, acc.: 60.16%] [G loss: 0.947943]\n",
      "epoch:2 step:1905 [D loss: 0.692643, acc.: 57.03%] [G loss: 0.894655]\n",
      "epoch:2 step:1906 [D loss: 0.788579, acc.: 45.31%] [G loss: 0.900564]\n",
      "epoch:2 step:1907 [D loss: 0.695974, acc.: 57.03%] [G loss: 0.882383]\n",
      "epoch:2 step:1908 [D loss: 0.691361, acc.: 54.69%] [G loss: 0.870846]\n",
      "epoch:2 step:1909 [D loss: 0.617352, acc.: 67.19%] [G loss: 1.062742]\n",
      "epoch:2 step:1910 [D loss: 0.651834, acc.: 61.72%] [G loss: 1.033665]\n",
      "epoch:2 step:1911 [D loss: 0.606457, acc.: 65.62%] [G loss: 1.125314]\n",
      "epoch:2 step:1912 [D loss: 0.676583, acc.: 63.28%] [G loss: 0.989923]\n",
      "epoch:2 step:1913 [D loss: 0.682716, acc.: 60.16%] [G loss: 0.931807]\n",
      "epoch:2 step:1914 [D loss: 0.696427, acc.: 59.38%] [G loss: 0.934927]\n",
      "epoch:2 step:1915 [D loss: 0.745000, acc.: 48.44%] [G loss: 0.876573]\n",
      "epoch:2 step:1916 [D loss: 0.609664, acc.: 63.28%] [G loss: 0.984682]\n",
      "epoch:2 step:1917 [D loss: 0.662564, acc.: 57.81%] [G loss: 0.987814]\n",
      "epoch:2 step:1918 [D loss: 0.712197, acc.: 53.91%] [G loss: 0.998686]\n",
      "epoch:2 step:1919 [D loss: 0.718094, acc.: 52.34%] [G loss: 0.975102]\n",
      "epoch:2 step:1920 [D loss: 0.714454, acc.: 53.91%] [G loss: 0.949486]\n",
      "epoch:2 step:1921 [D loss: 0.655320, acc.: 63.28%] [G loss: 0.996392]\n",
      "epoch:2 step:1922 [D loss: 0.618084, acc.: 61.72%] [G loss: 0.989135]\n",
      "epoch:2 step:1923 [D loss: 0.678434, acc.: 58.59%] [G loss: 0.994133]\n",
      "epoch:2 step:1924 [D loss: 0.618784, acc.: 67.19%] [G loss: 1.060022]\n",
      "epoch:2 step:1925 [D loss: 0.674120, acc.: 60.16%] [G loss: 0.949281]\n",
      "epoch:2 step:1926 [D loss: 0.706228, acc.: 54.69%] [G loss: 1.013419]\n",
      "epoch:2 step:1927 [D loss: 0.688495, acc.: 57.03%] [G loss: 0.924144]\n",
      "epoch:2 step:1928 [D loss: 0.627306, acc.: 64.84%] [G loss: 0.987341]\n",
      "epoch:2 step:1929 [D loss: 0.604245, acc.: 67.97%] [G loss: 0.921746]\n",
      "epoch:2 step:1930 [D loss: 0.623032, acc.: 67.97%] [G loss: 0.945833]\n",
      "epoch:2 step:1931 [D loss: 0.682919, acc.: 56.25%] [G loss: 1.047407]\n",
      "epoch:2 step:1932 [D loss: 0.693634, acc.: 55.47%] [G loss: 0.893495]\n",
      "epoch:2 step:1933 [D loss: 0.639836, acc.: 68.75%] [G loss: 1.056063]\n",
      "epoch:2 step:1934 [D loss: 0.650491, acc.: 58.59%] [G loss: 0.900602]\n",
      "epoch:2 step:1935 [D loss: 0.673858, acc.: 57.03%] [G loss: 0.955589]\n",
      "epoch:2 step:1936 [D loss: 0.686943, acc.: 57.81%] [G loss: 0.926808]\n",
      "epoch:2 step:1937 [D loss: 0.635475, acc.: 63.28%] [G loss: 0.897214]\n",
      "epoch:2 step:1938 [D loss: 0.682534, acc.: 57.03%] [G loss: 0.881346]\n",
      "epoch:2 step:1939 [D loss: 0.692408, acc.: 58.59%] [G loss: 0.911695]\n",
      "epoch:2 step:1940 [D loss: 0.671274, acc.: 57.03%] [G loss: 0.859756]\n",
      "epoch:2 step:1941 [D loss: 0.667286, acc.: 60.94%] [G loss: 0.952380]\n",
      "epoch:2 step:1942 [D loss: 0.667957, acc.: 61.72%] [G loss: 0.965600]\n",
      "epoch:2 step:1943 [D loss: 0.666392, acc.: 61.72%] [G loss: 0.914508]\n",
      "epoch:2 step:1944 [D loss: 0.660239, acc.: 57.03%] [G loss: 0.907002]\n",
      "epoch:2 step:1945 [D loss: 0.655831, acc.: 55.47%] [G loss: 0.963225]\n",
      "epoch:2 step:1946 [D loss: 0.643775, acc.: 63.28%] [G loss: 0.983062]\n",
      "epoch:2 step:1947 [D loss: 0.682691, acc.: 57.03%] [G loss: 0.901823]\n",
      "epoch:2 step:1948 [D loss: 0.669492, acc.: 58.59%] [G loss: 0.945457]\n",
      "epoch:2 step:1949 [D loss: 0.578332, acc.: 74.22%] [G loss: 0.930531]\n",
      "epoch:2 step:1950 [D loss: 0.625039, acc.: 64.06%] [G loss: 1.034293]\n",
      "epoch:2 step:1951 [D loss: 0.592166, acc.: 67.19%] [G loss: 1.004833]\n",
      "epoch:2 step:1952 [D loss: 0.705619, acc.: 55.47%] [G loss: 0.996005]\n",
      "epoch:2 step:1953 [D loss: 0.729032, acc.: 50.78%] [G loss: 0.935195]\n",
      "epoch:2 step:1954 [D loss: 0.722866, acc.: 50.78%] [G loss: 1.055704]\n",
      "epoch:2 step:1955 [D loss: 0.720922, acc.: 54.69%] [G loss: 0.963997]\n",
      "epoch:2 step:1956 [D loss: 0.671853, acc.: 61.72%] [G loss: 0.869169]\n",
      "epoch:2 step:1957 [D loss: 0.737247, acc.: 48.44%] [G loss: 0.931097]\n",
      "epoch:2 step:1958 [D loss: 0.616577, acc.: 64.84%] [G loss: 0.971664]\n",
      "epoch:2 step:1959 [D loss: 0.638331, acc.: 67.19%] [G loss: 1.010951]\n",
      "epoch:2 step:1960 [D loss: 0.686418, acc.: 60.94%] [G loss: 0.933771]\n",
      "epoch:2 step:1961 [D loss: 0.713559, acc.: 56.25%] [G loss: 0.888233]\n",
      "epoch:2 step:1962 [D loss: 0.669574, acc.: 62.50%] [G loss: 0.976846]\n",
      "epoch:2 step:1963 [D loss: 0.662220, acc.: 60.16%] [G loss: 1.002955]\n",
      "epoch:2 step:1964 [D loss: 0.662598, acc.: 57.81%] [G loss: 0.932131]\n",
      "epoch:2 step:1965 [D loss: 0.711505, acc.: 51.56%] [G loss: 0.911772]\n",
      "epoch:2 step:1966 [D loss: 0.700843, acc.: 57.81%] [G loss: 0.926240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:1967 [D loss: 0.647625, acc.: 64.06%] [G loss: 0.909072]\n",
      "epoch:2 step:1968 [D loss: 0.709542, acc.: 49.22%] [G loss: 0.900168]\n",
      "epoch:2 step:1969 [D loss: 0.731831, acc.: 52.34%] [G loss: 0.866704]\n",
      "epoch:2 step:1970 [D loss: 0.652259, acc.: 64.06%] [G loss: 0.936261]\n",
      "epoch:2 step:1971 [D loss: 0.683500, acc.: 55.47%] [G loss: 0.918624]\n",
      "epoch:2 step:1972 [D loss: 0.685829, acc.: 51.56%] [G loss: 0.952687]\n",
      "epoch:2 step:1973 [D loss: 0.677993, acc.: 58.59%] [G loss: 1.012689]\n",
      "epoch:2 step:1974 [D loss: 0.684008, acc.: 54.69%] [G loss: 0.986977]\n",
      "epoch:2 step:1975 [D loss: 0.686476, acc.: 63.28%] [G loss: 0.957554]\n",
      "epoch:2 step:1976 [D loss: 0.683263, acc.: 57.81%] [G loss: 1.030780]\n",
      "epoch:2 step:1977 [D loss: 0.579599, acc.: 71.88%] [G loss: 1.030535]\n",
      "epoch:2 step:1978 [D loss: 0.690670, acc.: 60.16%] [G loss: 0.957798]\n",
      "epoch:2 step:1979 [D loss: 0.678809, acc.: 57.03%] [G loss: 1.054170]\n",
      "epoch:2 step:1980 [D loss: 0.647263, acc.: 64.06%] [G loss: 0.941448]\n",
      "epoch:2 step:1981 [D loss: 0.755650, acc.: 49.22%] [G loss: 0.987912]\n",
      "epoch:2 step:1982 [D loss: 0.725236, acc.: 50.00%] [G loss: 0.942364]\n",
      "epoch:2 step:1983 [D loss: 0.717405, acc.: 49.22%] [G loss: 0.927200]\n",
      "epoch:2 step:1984 [D loss: 0.660967, acc.: 60.16%] [G loss: 0.990412]\n",
      "epoch:2 step:1985 [D loss: 0.656405, acc.: 58.59%] [G loss: 0.962363]\n",
      "epoch:2 step:1986 [D loss: 0.656249, acc.: 64.06%] [G loss: 0.870785]\n",
      "epoch:2 step:1987 [D loss: 0.685965, acc.: 58.59%] [G loss: 0.925229]\n",
      "epoch:2 step:1988 [D loss: 0.770351, acc.: 50.00%] [G loss: 0.883138]\n",
      "epoch:2 step:1989 [D loss: 0.688187, acc.: 52.34%] [G loss: 1.029256]\n",
      "epoch:2 step:1990 [D loss: 0.670157, acc.: 53.91%] [G loss: 0.957563]\n",
      "epoch:2 step:1991 [D loss: 0.717035, acc.: 52.34%] [G loss: 1.010135]\n",
      "epoch:2 step:1992 [D loss: 0.713752, acc.: 51.56%] [G loss: 0.854267]\n",
      "epoch:2 step:1993 [D loss: 0.675883, acc.: 57.03%] [G loss: 0.912781]\n",
      "epoch:2 step:1994 [D loss: 0.693895, acc.: 56.25%] [G loss: 0.992267]\n",
      "epoch:2 step:1995 [D loss: 0.763813, acc.: 46.88%] [G loss: 0.848505]\n",
      "epoch:2 step:1996 [D loss: 0.721631, acc.: 57.03%] [G loss: 0.874711]\n",
      "epoch:2 step:1997 [D loss: 0.689722, acc.: 52.34%] [G loss: 0.920582]\n",
      "epoch:2 step:1998 [D loss: 0.771277, acc.: 54.69%] [G loss: 0.908881]\n",
      "epoch:2 step:1999 [D loss: 0.645787, acc.: 59.38%] [G loss: 0.996842]\n",
      "epoch:2 step:2000 [D loss: 0.721360, acc.: 52.34%] [G loss: 0.944830]\n",
      "##############\n",
      "[1.89125639 0.18438969 4.8076477  3.87994261 2.57187629 4.69961974\n",
      " 3.54755462 3.5978742  3.69668462 2.57715548]\n",
      "##########\n",
      "epoch:2 step:2001 [D loss: 0.646362, acc.: 64.84%] [G loss: 0.996207]\n",
      "epoch:2 step:2002 [D loss: 0.620466, acc.: 64.06%] [G loss: 0.914355]\n",
      "epoch:2 step:2003 [D loss: 0.708103, acc.: 54.69%] [G loss: 0.899892]\n",
      "epoch:2 step:2004 [D loss: 0.664466, acc.: 64.84%] [G loss: 1.036106]\n",
      "epoch:2 step:2005 [D loss: 0.576188, acc.: 73.44%] [G loss: 1.032811]\n",
      "epoch:2 step:2006 [D loss: 0.639972, acc.: 64.06%] [G loss: 0.941029]\n",
      "epoch:2 step:2007 [D loss: 0.759963, acc.: 50.78%] [G loss: 0.936781]\n",
      "epoch:2 step:2008 [D loss: 0.723099, acc.: 49.22%] [G loss: 0.787670]\n",
      "epoch:2 step:2009 [D loss: 0.698603, acc.: 58.59%] [G loss: 0.861717]\n",
      "epoch:2 step:2010 [D loss: 0.671951, acc.: 61.72%] [G loss: 0.969904]\n",
      "epoch:2 step:2011 [D loss: 0.700823, acc.: 57.03%] [G loss: 1.013696]\n",
      "epoch:2 step:2012 [D loss: 0.685088, acc.: 55.47%] [G loss: 0.966828]\n",
      "epoch:2 step:2013 [D loss: 0.697869, acc.: 53.12%] [G loss: 0.965116]\n",
      "epoch:2 step:2014 [D loss: 0.680627, acc.: 57.81%] [G loss: 1.009992]\n",
      "epoch:2 step:2015 [D loss: 0.610121, acc.: 66.41%] [G loss: 1.047215]\n",
      "epoch:2 step:2016 [D loss: 0.685842, acc.: 56.25%] [G loss: 1.019730]\n",
      "epoch:2 step:2017 [D loss: 0.646221, acc.: 60.94%] [G loss: 0.914715]\n",
      "epoch:2 step:2018 [D loss: 0.684993, acc.: 50.78%] [G loss: 0.996480]\n",
      "epoch:2 step:2019 [D loss: 0.625603, acc.: 64.06%] [G loss: 1.015024]\n",
      "epoch:2 step:2020 [D loss: 0.689465, acc.: 58.59%] [G loss: 0.965768]\n",
      "epoch:2 step:2021 [D loss: 0.696728, acc.: 54.69%] [G loss: 0.875405]\n",
      "epoch:2 step:2022 [D loss: 0.662752, acc.: 59.38%] [G loss: 0.971314]\n",
      "epoch:2 step:2023 [D loss: 0.674019, acc.: 64.06%] [G loss: 0.986359]\n",
      "epoch:2 step:2024 [D loss: 0.681005, acc.: 59.38%] [G loss: 0.907843]\n",
      "epoch:2 step:2025 [D loss: 0.640122, acc.: 62.50%] [G loss: 1.021704]\n",
      "epoch:2 step:2026 [D loss: 0.606730, acc.: 66.41%] [G loss: 1.030913]\n",
      "epoch:2 step:2027 [D loss: 0.694476, acc.: 55.47%] [G loss: 0.997361]\n",
      "epoch:2 step:2028 [D loss: 0.716083, acc.: 52.34%] [G loss: 0.897076]\n",
      "epoch:2 step:2029 [D loss: 0.718860, acc.: 53.12%] [G loss: 0.971758]\n",
      "epoch:2 step:2030 [D loss: 0.679248, acc.: 60.94%] [G loss: 0.881535]\n",
      "epoch:2 step:2031 [D loss: 0.699817, acc.: 56.25%] [G loss: 0.956797]\n",
      "epoch:2 step:2032 [D loss: 0.648884, acc.: 60.16%] [G loss: 0.941138]\n",
      "epoch:2 step:2033 [D loss: 0.703443, acc.: 56.25%] [G loss: 0.901545]\n",
      "epoch:2 step:2034 [D loss: 0.735736, acc.: 52.34%] [G loss: 0.899060]\n",
      "epoch:2 step:2035 [D loss: 0.722774, acc.: 47.66%] [G loss: 0.954327]\n",
      "epoch:2 step:2036 [D loss: 0.684933, acc.: 54.69%] [G loss: 0.880508]\n",
      "epoch:2 step:2037 [D loss: 0.635271, acc.: 63.28%] [G loss: 1.037261]\n",
      "epoch:2 step:2038 [D loss: 0.749508, acc.: 49.22%] [G loss: 0.958256]\n",
      "epoch:2 step:2039 [D loss: 0.653766, acc.: 59.38%] [G loss: 0.998916]\n",
      "epoch:2 step:2040 [D loss: 0.629012, acc.: 63.28%] [G loss: 1.003252]\n",
      "epoch:2 step:2041 [D loss: 0.564847, acc.: 75.00%] [G loss: 1.108195]\n",
      "epoch:2 step:2042 [D loss: 0.724408, acc.: 50.00%] [G loss: 1.032380]\n",
      "epoch:2 step:2043 [D loss: 0.661281, acc.: 62.50%] [G loss: 1.031895]\n",
      "epoch:2 step:2044 [D loss: 0.665016, acc.: 60.94%] [G loss: 0.959717]\n",
      "epoch:2 step:2045 [D loss: 0.672750, acc.: 57.81%] [G loss: 1.027478]\n",
      "epoch:2 step:2046 [D loss: 0.687982, acc.: 58.59%] [G loss: 0.927562]\n",
      "epoch:2 step:2047 [D loss: 0.607691, acc.: 67.97%] [G loss: 0.990153]\n",
      "epoch:2 step:2048 [D loss: 0.717075, acc.: 54.69%] [G loss: 0.861216]\n",
      "epoch:2 step:2049 [D loss: 0.689032, acc.: 59.38%] [G loss: 0.915544]\n",
      "epoch:2 step:2050 [D loss: 0.678713, acc.: 57.81%] [G loss: 1.059309]\n",
      "epoch:2 step:2051 [D loss: 0.598213, acc.: 70.31%] [G loss: 1.033244]\n",
      "epoch:2 step:2052 [D loss: 0.640270, acc.: 64.84%] [G loss: 1.019291]\n",
      "epoch:2 step:2053 [D loss: 0.668742, acc.: 60.94%] [G loss: 0.981972]\n",
      "epoch:2 step:2054 [D loss: 0.673831, acc.: 55.47%] [G loss: 1.008713]\n",
      "epoch:2 step:2055 [D loss: 0.675860, acc.: 57.81%] [G loss: 0.911793]\n",
      "epoch:2 step:2056 [D loss: 0.682935, acc.: 56.25%] [G loss: 0.942072]\n",
      "epoch:2 step:2057 [D loss: 0.712414, acc.: 55.47%] [G loss: 0.909976]\n",
      "epoch:2 step:2058 [D loss: 0.662227, acc.: 57.81%] [G loss: 1.013299]\n",
      "epoch:2 step:2059 [D loss: 0.693500, acc.: 58.59%] [G loss: 0.853358]\n",
      "epoch:2 step:2060 [D loss: 0.665564, acc.: 60.16%] [G loss: 0.991263]\n",
      "epoch:2 step:2061 [D loss: 0.688675, acc.: 57.03%] [G loss: 1.055495]\n",
      "epoch:2 step:2062 [D loss: 0.647113, acc.: 62.50%] [G loss: 0.985210]\n",
      "epoch:2 step:2063 [D loss: 0.710606, acc.: 56.25%] [G loss: 0.944426]\n",
      "epoch:2 step:2064 [D loss: 0.690531, acc.: 57.81%] [G loss: 1.010180]\n",
      "epoch:2 step:2065 [D loss: 0.638108, acc.: 61.72%] [G loss: 1.016109]\n",
      "epoch:2 step:2066 [D loss: 0.697900, acc.: 53.91%] [G loss: 0.982494]\n",
      "epoch:2 step:2067 [D loss: 0.716819, acc.: 53.12%] [G loss: 0.944802]\n",
      "epoch:2 step:2068 [D loss: 0.579161, acc.: 71.09%] [G loss: 0.899596]\n",
      "epoch:2 step:2069 [D loss: 0.639601, acc.: 65.62%] [G loss: 1.066486]\n",
      "epoch:2 step:2070 [D loss: 0.798212, acc.: 40.62%] [G loss: 0.913220]\n",
      "epoch:2 step:2071 [D loss: 0.669409, acc.: 58.59%] [G loss: 0.939772]\n",
      "epoch:2 step:2072 [D loss: 0.695053, acc.: 55.47%] [G loss: 0.916607]\n",
      "epoch:2 step:2073 [D loss: 0.721390, acc.: 54.69%] [G loss: 0.927864]\n",
      "epoch:2 step:2074 [D loss: 0.785502, acc.: 48.44%] [G loss: 0.828823]\n",
      "epoch:2 step:2075 [D loss: 0.689339, acc.: 54.69%] [G loss: 1.013868]\n",
      "epoch:2 step:2076 [D loss: 0.645871, acc.: 58.59%] [G loss: 0.913889]\n",
      "epoch:2 step:2077 [D loss: 0.783044, acc.: 42.97%] [G loss: 0.831283]\n",
      "epoch:2 step:2078 [D loss: 0.666416, acc.: 61.72%] [G loss: 0.976898]\n",
      "epoch:2 step:2079 [D loss: 0.714688, acc.: 55.47%] [G loss: 1.011815]\n",
      "epoch:2 step:2080 [D loss: 0.614790, acc.: 67.19%] [G loss: 1.055849]\n",
      "epoch:2 step:2081 [D loss: 0.636848, acc.: 60.16%] [G loss: 1.041966]\n",
      "epoch:2 step:2082 [D loss: 0.688386, acc.: 59.38%] [G loss: 1.005715]\n",
      "epoch:2 step:2083 [D loss: 0.615813, acc.: 71.09%] [G loss: 1.032321]\n",
      "epoch:2 step:2084 [D loss: 0.758071, acc.: 53.91%] [G loss: 1.006932]\n",
      "epoch:2 step:2085 [D loss: 0.697836, acc.: 53.12%] [G loss: 0.945882]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2086 [D loss: 0.656355, acc.: 61.72%] [G loss: 1.040009]\n",
      "epoch:2 step:2087 [D loss: 0.684060, acc.: 59.38%] [G loss: 0.974116]\n",
      "epoch:2 step:2088 [D loss: 0.719778, acc.: 48.44%] [G loss: 0.898972]\n",
      "epoch:2 step:2089 [D loss: 0.711563, acc.: 53.12%] [G loss: 1.002972]\n",
      "epoch:2 step:2090 [D loss: 0.663702, acc.: 60.94%] [G loss: 0.976202]\n",
      "epoch:2 step:2091 [D loss: 0.640256, acc.: 67.97%] [G loss: 0.929811]\n",
      "epoch:2 step:2092 [D loss: 0.679929, acc.: 54.69%] [G loss: 0.853279]\n",
      "epoch:2 step:2093 [D loss: 0.610922, acc.: 70.31%] [G loss: 1.070010]\n",
      "epoch:2 step:2094 [D loss: 0.751003, acc.: 51.56%] [G loss: 0.949125]\n",
      "epoch:2 step:2095 [D loss: 0.704773, acc.: 50.78%] [G loss: 0.963683]\n",
      "epoch:2 step:2096 [D loss: 0.577812, acc.: 67.97%] [G loss: 1.076582]\n",
      "epoch:2 step:2097 [D loss: 0.713653, acc.: 57.03%] [G loss: 1.022643]\n",
      "epoch:2 step:2098 [D loss: 0.766041, acc.: 51.56%] [G loss: 0.980764]\n",
      "epoch:2 step:2099 [D loss: 0.740436, acc.: 51.56%] [G loss: 1.014490]\n",
      "epoch:2 step:2100 [D loss: 0.743487, acc.: 51.56%] [G loss: 0.988555]\n",
      "epoch:2 step:2101 [D loss: 0.763502, acc.: 53.91%] [G loss: 0.903755]\n",
      "epoch:2 step:2102 [D loss: 0.749593, acc.: 50.78%] [G loss: 0.897369]\n",
      "epoch:2 step:2103 [D loss: 0.687873, acc.: 56.25%] [G loss: 0.916701]\n",
      "epoch:2 step:2104 [D loss: 0.592964, acc.: 71.09%] [G loss: 1.148912]\n",
      "epoch:2 step:2105 [D loss: 0.659413, acc.: 62.50%] [G loss: 1.037038]\n",
      "epoch:2 step:2106 [D loss: 0.583221, acc.: 71.09%] [G loss: 1.114388]\n",
      "epoch:2 step:2107 [D loss: 0.687128, acc.: 59.38%] [G loss: 1.039416]\n",
      "epoch:2 step:2108 [D loss: 0.674131, acc.: 60.16%] [G loss: 1.045157]\n",
      "epoch:2 step:2109 [D loss: 0.704767, acc.: 57.81%] [G loss: 0.985622]\n",
      "epoch:2 step:2110 [D loss: 0.680809, acc.: 58.59%] [G loss: 1.022035]\n",
      "epoch:2 step:2111 [D loss: 0.736768, acc.: 47.66%] [G loss: 0.919062]\n",
      "epoch:2 step:2112 [D loss: 0.695131, acc.: 62.50%] [G loss: 0.993799]\n",
      "epoch:2 step:2113 [D loss: 0.724355, acc.: 53.91%] [G loss: 0.953023]\n",
      "epoch:2 step:2114 [D loss: 0.677724, acc.: 61.72%] [G loss: 0.888873]\n",
      "epoch:2 step:2115 [D loss: 0.745241, acc.: 51.56%] [G loss: 1.061422]\n",
      "epoch:2 step:2116 [D loss: 0.716912, acc.: 49.22%] [G loss: 1.001177]\n",
      "epoch:2 step:2117 [D loss: 0.668808, acc.: 62.50%] [G loss: 1.087533]\n",
      "epoch:2 step:2118 [D loss: 0.659938, acc.: 57.81%] [G loss: 0.840100]\n",
      "epoch:2 step:2119 [D loss: 0.636578, acc.: 60.94%] [G loss: 0.997005]\n",
      "epoch:2 step:2120 [D loss: 0.690393, acc.: 57.03%] [G loss: 0.865929]\n",
      "epoch:2 step:2121 [D loss: 0.682169, acc.: 57.03%] [G loss: 0.988958]\n",
      "epoch:2 step:2122 [D loss: 0.690173, acc.: 57.03%] [G loss: 0.996357]\n",
      "epoch:2 step:2123 [D loss: 0.731914, acc.: 55.47%] [G loss: 0.886739]\n",
      "epoch:2 step:2124 [D loss: 0.690672, acc.: 55.47%] [G loss: 0.864535]\n",
      "epoch:2 step:2125 [D loss: 0.686716, acc.: 53.91%] [G loss: 1.002522]\n",
      "epoch:2 step:2126 [D loss: 0.736176, acc.: 50.78%] [G loss: 0.798283]\n",
      "epoch:2 step:2127 [D loss: 0.685516, acc.: 53.12%] [G loss: 0.993694]\n",
      "epoch:2 step:2128 [D loss: 0.638535, acc.: 60.94%] [G loss: 0.927230]\n",
      "epoch:2 step:2129 [D loss: 0.708202, acc.: 51.56%] [G loss: 0.969878]\n",
      "epoch:2 step:2130 [D loss: 0.746884, acc.: 52.34%] [G loss: 0.998080]\n",
      "epoch:2 step:2131 [D loss: 0.654631, acc.: 62.50%] [G loss: 0.948856]\n",
      "epoch:2 step:2132 [D loss: 0.697744, acc.: 55.47%] [G loss: 0.948431]\n",
      "epoch:2 step:2133 [D loss: 0.677450, acc.: 61.72%] [G loss: 0.887422]\n",
      "epoch:2 step:2134 [D loss: 0.630412, acc.: 67.97%] [G loss: 1.074287]\n",
      "epoch:2 step:2135 [D loss: 0.610977, acc.: 70.31%] [G loss: 1.040905]\n",
      "epoch:2 step:2136 [D loss: 0.637427, acc.: 63.28%] [G loss: 1.080468]\n",
      "epoch:2 step:2137 [D loss: 0.730177, acc.: 53.12%] [G loss: 1.047097]\n",
      "epoch:2 step:2138 [D loss: 0.653947, acc.: 60.16%] [G loss: 0.955120]\n",
      "epoch:2 step:2139 [D loss: 0.703411, acc.: 61.72%] [G loss: 0.864152]\n",
      "epoch:2 step:2140 [D loss: 0.769937, acc.: 49.22%] [G loss: 0.840444]\n",
      "epoch:2 step:2141 [D loss: 0.666531, acc.: 60.16%] [G loss: 1.008745]\n",
      "epoch:2 step:2142 [D loss: 0.696272, acc.: 54.69%] [G loss: 0.940046]\n",
      "epoch:2 step:2143 [D loss: 0.732760, acc.: 52.34%] [G loss: 0.959746]\n",
      "epoch:2 step:2144 [D loss: 0.687051, acc.: 54.69%] [G loss: 0.829489]\n",
      "epoch:2 step:2145 [D loss: 0.717497, acc.: 53.91%] [G loss: 0.890932]\n",
      "epoch:2 step:2146 [D loss: 0.734789, acc.: 51.56%] [G loss: 0.979976]\n",
      "epoch:2 step:2147 [D loss: 0.702551, acc.: 54.69%] [G loss: 0.973965]\n",
      "epoch:2 step:2148 [D loss: 0.694790, acc.: 50.00%] [G loss: 1.058770]\n",
      "epoch:2 step:2149 [D loss: 0.751195, acc.: 47.66%] [G loss: 0.902477]\n",
      "epoch:2 step:2150 [D loss: 0.707755, acc.: 48.44%] [G loss: 0.953755]\n",
      "epoch:2 step:2151 [D loss: 0.718994, acc.: 55.47%] [G loss: 0.955194]\n",
      "epoch:2 step:2152 [D loss: 0.725612, acc.: 51.56%] [G loss: 0.884213]\n",
      "epoch:2 step:2153 [D loss: 0.739684, acc.: 53.12%] [G loss: 0.962049]\n",
      "epoch:2 step:2154 [D loss: 0.650937, acc.: 67.97%] [G loss: 0.832458]\n",
      "epoch:2 step:2155 [D loss: 0.670815, acc.: 62.50%] [G loss: 1.053961]\n",
      "epoch:2 step:2156 [D loss: 0.664608, acc.: 56.25%] [G loss: 0.899909]\n",
      "epoch:2 step:2157 [D loss: 0.735461, acc.: 54.69%] [G loss: 0.834243]\n",
      "epoch:2 step:2158 [D loss: 0.740487, acc.: 45.31%] [G loss: 0.829428]\n",
      "epoch:2 step:2159 [D loss: 0.668125, acc.: 55.47%] [G loss: 0.904347]\n",
      "epoch:2 step:2160 [D loss: 0.724820, acc.: 51.56%] [G loss: 0.966806]\n",
      "epoch:2 step:2161 [D loss: 0.692242, acc.: 54.69%] [G loss: 0.936976]\n",
      "epoch:2 step:2162 [D loss: 0.674058, acc.: 60.16%] [G loss: 1.003229]\n",
      "epoch:2 step:2163 [D loss: 0.666054, acc.: 59.38%] [G loss: 0.923635]\n",
      "epoch:2 step:2164 [D loss: 0.720247, acc.: 56.25%] [G loss: 0.995828]\n",
      "epoch:2 step:2165 [D loss: 0.720125, acc.: 57.03%] [G loss: 0.906495]\n",
      "epoch:2 step:2166 [D loss: 0.703646, acc.: 54.69%] [G loss: 0.921196]\n",
      "epoch:2 step:2167 [D loss: 0.710584, acc.: 53.91%] [G loss: 1.016448]\n",
      "epoch:2 step:2168 [D loss: 0.665142, acc.: 61.72%] [G loss: 0.937644]\n",
      "epoch:2 step:2169 [D loss: 0.654939, acc.: 57.81%] [G loss: 1.002202]\n",
      "epoch:2 step:2170 [D loss: 0.658983, acc.: 57.03%] [G loss: 1.040388]\n",
      "epoch:2 step:2171 [D loss: 0.645144, acc.: 60.94%] [G loss: 0.905377]\n",
      "epoch:2 step:2172 [D loss: 0.669548, acc.: 59.38%] [G loss: 0.967818]\n",
      "epoch:2 step:2173 [D loss: 0.660489, acc.: 58.59%] [G loss: 0.914085]\n",
      "epoch:2 step:2174 [D loss: 0.706796, acc.: 54.69%] [G loss: 0.859414]\n",
      "epoch:2 step:2175 [D loss: 0.724533, acc.: 51.56%] [G loss: 0.989509]\n",
      "epoch:2 step:2176 [D loss: 0.681502, acc.: 55.47%] [G loss: 0.981557]\n",
      "epoch:2 step:2177 [D loss: 0.731734, acc.: 52.34%] [G loss: 0.945468]\n",
      "epoch:2 step:2178 [D loss: 0.708165, acc.: 52.34%] [G loss: 0.978490]\n",
      "epoch:2 step:2179 [D loss: 0.675587, acc.: 60.16%] [G loss: 0.906749]\n",
      "epoch:2 step:2180 [D loss: 0.625523, acc.: 64.84%] [G loss: 0.924366]\n",
      "epoch:2 step:2181 [D loss: 0.650772, acc.: 61.72%] [G loss: 0.962664]\n",
      "epoch:2 step:2182 [D loss: 0.688166, acc.: 57.81%] [G loss: 0.934472]\n",
      "epoch:2 step:2183 [D loss: 0.681854, acc.: 57.03%] [G loss: 0.956383]\n",
      "epoch:2 step:2184 [D loss: 0.715149, acc.: 56.25%] [G loss: 0.770030]\n",
      "epoch:2 step:2185 [D loss: 0.657201, acc.: 57.03%] [G loss: 0.941364]\n",
      "epoch:2 step:2186 [D loss: 0.702659, acc.: 51.56%] [G loss: 0.953137]\n",
      "epoch:2 step:2187 [D loss: 0.668239, acc.: 59.38%] [G loss: 0.953660]\n",
      "epoch:2 step:2188 [D loss: 0.579693, acc.: 69.53%] [G loss: 1.115177]\n",
      "epoch:2 step:2189 [D loss: 0.550970, acc.: 74.22%] [G loss: 1.101151]\n",
      "epoch:2 step:2190 [D loss: 0.797435, acc.: 46.88%] [G loss: 0.961910]\n",
      "epoch:2 step:2191 [D loss: 0.682175, acc.: 53.12%] [G loss: 1.062547]\n",
      "epoch:2 step:2192 [D loss: 0.721201, acc.: 56.25%] [G loss: 0.932649]\n",
      "epoch:2 step:2193 [D loss: 0.649219, acc.: 59.38%] [G loss: 0.985539]\n",
      "epoch:2 step:2194 [D loss: 0.639698, acc.: 60.94%] [G loss: 0.947579]\n",
      "epoch:2 step:2195 [D loss: 0.648441, acc.: 64.06%] [G loss: 0.975680]\n",
      "epoch:2 step:2196 [D loss: 0.650902, acc.: 57.03%] [G loss: 0.935560]\n",
      "epoch:2 step:2197 [D loss: 0.667484, acc.: 62.50%] [G loss: 0.949509]\n",
      "epoch:2 step:2198 [D loss: 0.639620, acc.: 63.28%] [G loss: 0.943962]\n",
      "epoch:2 step:2199 [D loss: 0.685598, acc.: 55.47%] [G loss: 0.854596]\n",
      "epoch:2 step:2200 [D loss: 0.690208, acc.: 60.16%] [G loss: 0.904672]\n",
      "##############\n",
      "[1.85883325 0.14686004 4.99333435 3.90066737 2.35695589 4.47394428\n",
      " 3.30007203 3.82559075 3.28813368 2.57192307]\n",
      "##########\n",
      "epoch:2 step:2201 [D loss: 0.713666, acc.: 53.91%] [G loss: 0.921491]\n",
      "epoch:2 step:2202 [D loss: 0.659225, acc.: 61.72%] [G loss: 0.991666]\n",
      "epoch:2 step:2203 [D loss: 0.661892, acc.: 59.38%] [G loss: 0.906977]\n",
      "epoch:2 step:2204 [D loss: 0.715565, acc.: 57.03%] [G loss: 0.805140]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2205 [D loss: 0.652339, acc.: 61.72%] [G loss: 0.890223]\n",
      "epoch:2 step:2206 [D loss: 0.668250, acc.: 56.25%] [G loss: 0.889189]\n",
      "epoch:2 step:2207 [D loss: 0.669432, acc.: 52.34%] [G loss: 1.043363]\n",
      "epoch:2 step:2208 [D loss: 0.723937, acc.: 53.12%] [G loss: 0.963006]\n",
      "epoch:2 step:2209 [D loss: 0.721189, acc.: 55.47%] [G loss: 0.867039]\n",
      "epoch:2 step:2210 [D loss: 0.668603, acc.: 60.94%] [G loss: 0.917212]\n",
      "epoch:2 step:2211 [D loss: 0.580045, acc.: 71.09%] [G loss: 1.042818]\n",
      "epoch:2 step:2212 [D loss: 0.682228, acc.: 58.59%] [G loss: 1.019514]\n",
      "epoch:2 step:2213 [D loss: 0.708512, acc.: 50.78%] [G loss: 0.957208]\n",
      "epoch:2 step:2214 [D loss: 0.581946, acc.: 69.53%] [G loss: 1.064809]\n",
      "epoch:2 step:2215 [D loss: 0.706695, acc.: 56.25%] [G loss: 0.949000]\n",
      "epoch:2 step:2216 [D loss: 0.729521, acc.: 50.00%] [G loss: 0.871579]\n",
      "epoch:2 step:2217 [D loss: 0.680254, acc.: 59.38%] [G loss: 0.882774]\n",
      "epoch:2 step:2218 [D loss: 0.650606, acc.: 60.94%] [G loss: 0.915208]\n",
      "epoch:2 step:2219 [D loss: 0.679453, acc.: 58.59%] [G loss: 0.975476]\n",
      "epoch:2 step:2220 [D loss: 0.644357, acc.: 65.62%] [G loss: 0.996600]\n",
      "epoch:2 step:2221 [D loss: 0.657478, acc.: 64.06%] [G loss: 1.103674]\n",
      "epoch:2 step:2222 [D loss: 0.705531, acc.: 54.69%] [G loss: 0.922334]\n",
      "epoch:2 step:2223 [D loss: 0.768054, acc.: 50.00%] [G loss: 0.836314]\n",
      "epoch:2 step:2224 [D loss: 0.670167, acc.: 60.16%] [G loss: 1.114897]\n",
      "epoch:2 step:2225 [D loss: 0.707504, acc.: 55.47%] [G loss: 0.979666]\n",
      "epoch:2 step:2226 [D loss: 0.743141, acc.: 41.41%] [G loss: 0.912122]\n",
      "epoch:2 step:2227 [D loss: 0.700893, acc.: 54.69%] [G loss: 0.922089]\n",
      "epoch:2 step:2228 [D loss: 0.665044, acc.: 57.03%] [G loss: 0.975144]\n",
      "epoch:2 step:2229 [D loss: 0.701747, acc.: 60.16%] [G loss: 0.870471]\n",
      "epoch:2 step:2230 [D loss: 0.683488, acc.: 55.47%] [G loss: 1.021736]\n",
      "epoch:2 step:2231 [D loss: 0.702530, acc.: 53.12%] [G loss: 0.960836]\n",
      "epoch:2 step:2232 [D loss: 0.633954, acc.: 60.16%] [G loss: 0.952108]\n",
      "epoch:2 step:2233 [D loss: 0.609999, acc.: 64.84%] [G loss: 1.014925]\n",
      "epoch:2 step:2234 [D loss: 0.671467, acc.: 59.38%] [G loss: 0.996124]\n",
      "epoch:2 step:2235 [D loss: 0.705658, acc.: 53.12%] [G loss: 0.919959]\n",
      "epoch:2 step:2236 [D loss: 0.654852, acc.: 67.19%] [G loss: 0.966567]\n",
      "epoch:2 step:2237 [D loss: 0.673099, acc.: 58.59%] [G loss: 0.985206]\n",
      "epoch:2 step:2238 [D loss: 0.662784, acc.: 58.59%] [G loss: 0.880766]\n",
      "epoch:2 step:2239 [D loss: 0.710554, acc.: 52.34%] [G loss: 0.867774]\n",
      "epoch:2 step:2240 [D loss: 0.672153, acc.: 58.59%] [G loss: 0.887360]\n",
      "epoch:2 step:2241 [D loss: 0.671975, acc.: 60.16%] [G loss: 0.981583]\n",
      "epoch:2 step:2242 [D loss: 0.672143, acc.: 60.94%] [G loss: 1.020243]\n",
      "epoch:2 step:2243 [D loss: 0.650888, acc.: 67.19%] [G loss: 0.887913]\n",
      "epoch:2 step:2244 [D loss: 0.649920, acc.: 61.72%] [G loss: 0.964060]\n",
      "epoch:2 step:2245 [D loss: 0.663776, acc.: 66.41%] [G loss: 1.080924]\n",
      "epoch:2 step:2246 [D loss: 0.702457, acc.: 60.16%] [G loss: 0.952941]\n",
      "epoch:2 step:2247 [D loss: 0.664758, acc.: 63.28%] [G loss: 0.968451]\n",
      "epoch:2 step:2248 [D loss: 0.676549, acc.: 60.16%] [G loss: 0.930720]\n",
      "epoch:2 step:2249 [D loss: 0.697947, acc.: 56.25%] [G loss: 1.015974]\n",
      "epoch:2 step:2250 [D loss: 0.692670, acc.: 57.81%] [G loss: 1.016598]\n",
      "epoch:2 step:2251 [D loss: 0.717185, acc.: 52.34%] [G loss: 0.961296]\n",
      "epoch:2 step:2252 [D loss: 0.656074, acc.: 58.59%] [G loss: 0.869839]\n",
      "epoch:2 step:2253 [D loss: 0.703505, acc.: 55.47%] [G loss: 0.882143]\n",
      "epoch:2 step:2254 [D loss: 0.614346, acc.: 65.62%] [G loss: 0.988321]\n",
      "epoch:2 step:2255 [D loss: 0.635013, acc.: 63.28%] [G loss: 1.015496]\n",
      "epoch:2 step:2256 [D loss: 0.745099, acc.: 51.56%] [G loss: 0.948982]\n",
      "epoch:2 step:2257 [D loss: 0.662132, acc.: 61.72%] [G loss: 0.929430]\n",
      "epoch:2 step:2258 [D loss: 0.671525, acc.: 53.12%] [G loss: 0.985657]\n",
      "epoch:2 step:2259 [D loss: 0.680645, acc.: 60.94%] [G loss: 0.982046]\n",
      "epoch:2 step:2260 [D loss: 0.705983, acc.: 56.25%] [G loss: 0.970486]\n",
      "epoch:2 step:2261 [D loss: 0.681529, acc.: 57.81%] [G loss: 0.901604]\n",
      "epoch:2 step:2262 [D loss: 0.706561, acc.: 54.69%] [G loss: 0.973159]\n",
      "epoch:2 step:2263 [D loss: 0.644566, acc.: 61.72%] [G loss: 0.982193]\n",
      "epoch:2 step:2264 [D loss: 0.655891, acc.: 57.81%] [G loss: 0.990638]\n",
      "epoch:2 step:2265 [D loss: 0.701773, acc.: 53.91%] [G loss: 0.976299]\n",
      "epoch:2 step:2266 [D loss: 0.683299, acc.: 56.25%] [G loss: 0.930430]\n",
      "epoch:2 step:2267 [D loss: 0.644832, acc.: 64.06%] [G loss: 0.937510]\n",
      "epoch:2 step:2268 [D loss: 0.738204, acc.: 50.00%] [G loss: 0.884014]\n",
      "epoch:2 step:2269 [D loss: 0.650468, acc.: 61.72%] [G loss: 0.926969]\n",
      "epoch:2 step:2270 [D loss: 0.722455, acc.: 53.91%] [G loss: 0.905945]\n",
      "epoch:2 step:2271 [D loss: 0.669834, acc.: 58.59%] [G loss: 0.963082]\n",
      "epoch:2 step:2272 [D loss: 0.680717, acc.: 53.12%] [G loss: 0.908623]\n",
      "epoch:2 step:2273 [D loss: 0.615135, acc.: 65.62%] [G loss: 0.940555]\n",
      "epoch:2 step:2274 [D loss: 0.671995, acc.: 55.47%] [G loss: 0.871240]\n",
      "epoch:2 step:2275 [D loss: 0.726651, acc.: 50.00%] [G loss: 0.956933]\n",
      "epoch:2 step:2276 [D loss: 0.656442, acc.: 54.69%] [G loss: 1.008372]\n",
      "epoch:2 step:2277 [D loss: 0.641192, acc.: 62.50%] [G loss: 1.022624]\n",
      "epoch:2 step:2278 [D loss: 0.647547, acc.: 59.38%] [G loss: 1.015971]\n",
      "epoch:2 step:2279 [D loss: 0.648551, acc.: 63.28%] [G loss: 1.026926]\n",
      "epoch:2 step:2280 [D loss: 0.687586, acc.: 57.03%] [G loss: 0.901248]\n",
      "epoch:2 step:2281 [D loss: 0.649920, acc.: 62.50%] [G loss: 1.031192]\n",
      "epoch:2 step:2282 [D loss: 0.718645, acc.: 56.25%] [G loss: 1.026031]\n",
      "epoch:2 step:2283 [D loss: 0.635652, acc.: 67.97%] [G loss: 0.988041]\n",
      "epoch:2 step:2284 [D loss: 0.718819, acc.: 48.44%] [G loss: 0.834841]\n",
      "epoch:2 step:2285 [D loss: 0.697990, acc.: 57.03%] [G loss: 0.938427]\n",
      "epoch:2 step:2286 [D loss: 0.692062, acc.: 57.03%] [G loss: 0.996081]\n",
      "epoch:2 step:2287 [D loss: 0.664746, acc.: 58.59%] [G loss: 0.980685]\n",
      "epoch:2 step:2288 [D loss: 0.650946, acc.: 59.38%] [G loss: 0.983142]\n",
      "epoch:2 step:2289 [D loss: 0.701135, acc.: 55.47%] [G loss: 0.990996]\n",
      "epoch:2 step:2290 [D loss: 0.711152, acc.: 53.12%] [G loss: 0.903683]\n",
      "epoch:2 step:2291 [D loss: 0.662768, acc.: 56.25%] [G loss: 1.019035]\n",
      "epoch:2 step:2292 [D loss: 0.675108, acc.: 59.38%] [G loss: 0.880062]\n",
      "epoch:2 step:2293 [D loss: 0.631408, acc.: 67.19%] [G loss: 0.856469]\n",
      "epoch:2 step:2294 [D loss: 0.599745, acc.: 68.75%] [G loss: 0.888584]\n",
      "epoch:2 step:2295 [D loss: 0.704657, acc.: 53.12%] [G loss: 1.001829]\n",
      "epoch:2 step:2296 [D loss: 0.742746, acc.: 52.34%] [G loss: 0.902586]\n",
      "epoch:2 step:2297 [D loss: 0.692357, acc.: 57.81%] [G loss: 0.946951]\n",
      "epoch:2 step:2298 [D loss: 0.695077, acc.: 53.91%] [G loss: 0.933372]\n",
      "epoch:2 step:2299 [D loss: 0.748696, acc.: 54.69%] [G loss: 0.917232]\n",
      "epoch:2 step:2300 [D loss: 0.734908, acc.: 52.34%] [G loss: 0.860184]\n",
      "epoch:2 step:2301 [D loss: 0.636715, acc.: 65.62%] [G loss: 0.985626]\n",
      "epoch:2 step:2302 [D loss: 0.596050, acc.: 67.97%] [G loss: 1.044467]\n",
      "epoch:2 step:2303 [D loss: 0.649459, acc.: 61.72%] [G loss: 0.980397]\n",
      "epoch:2 step:2304 [D loss: 0.658023, acc.: 53.12%] [G loss: 1.140527]\n",
      "epoch:2 step:2305 [D loss: 0.648776, acc.: 60.16%] [G loss: 1.106108]\n",
      "epoch:2 step:2306 [D loss: 0.727950, acc.: 50.00%] [G loss: 0.974121]\n",
      "epoch:2 step:2307 [D loss: 0.725209, acc.: 53.91%] [G loss: 0.889114]\n",
      "epoch:2 step:2308 [D loss: 0.718806, acc.: 53.91%] [G loss: 0.874655]\n",
      "epoch:2 step:2309 [D loss: 0.754703, acc.: 46.88%] [G loss: 0.860796]\n",
      "epoch:2 step:2310 [D loss: 0.629369, acc.: 61.72%] [G loss: 0.973252]\n",
      "epoch:2 step:2311 [D loss: 0.638158, acc.: 57.81%] [G loss: 1.019194]\n",
      "epoch:2 step:2312 [D loss: 0.649581, acc.: 61.72%] [G loss: 0.988681]\n",
      "epoch:2 step:2313 [D loss: 0.658020, acc.: 59.38%] [G loss: 0.845466]\n",
      "epoch:2 step:2314 [D loss: 0.740162, acc.: 51.56%] [G loss: 0.851877]\n",
      "epoch:2 step:2315 [D loss: 0.667782, acc.: 57.03%] [G loss: 0.999526]\n",
      "epoch:2 step:2316 [D loss: 0.698711, acc.: 56.25%] [G loss: 0.876150]\n",
      "epoch:2 step:2317 [D loss: 0.682662, acc.: 57.81%] [G loss: 0.892326]\n",
      "epoch:2 step:2318 [D loss: 0.723652, acc.: 50.78%] [G loss: 0.910956]\n",
      "epoch:2 step:2319 [D loss: 0.663141, acc.: 63.28%] [G loss: 0.939332]\n",
      "epoch:2 step:2320 [D loss: 0.631695, acc.: 61.72%] [G loss: 1.086096]\n",
      "epoch:2 step:2321 [D loss: 0.653300, acc.: 63.28%] [G loss: 1.035720]\n",
      "epoch:2 step:2322 [D loss: 0.771346, acc.: 46.88%] [G loss: 0.940755]\n",
      "epoch:2 step:2323 [D loss: 0.680791, acc.: 54.69%] [G loss: 1.030678]\n",
      "epoch:2 step:2324 [D loss: 0.714717, acc.: 54.69%] [G loss: 1.043586]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2325 [D loss: 0.652270, acc.: 61.72%] [G loss: 0.982607]\n",
      "epoch:2 step:2326 [D loss: 0.650428, acc.: 61.72%] [G loss: 1.056216]\n",
      "epoch:2 step:2327 [D loss: 0.602873, acc.: 68.75%] [G loss: 1.055636]\n",
      "epoch:2 step:2328 [D loss: 0.661297, acc.: 63.28%] [G loss: 1.022962]\n",
      "epoch:2 step:2329 [D loss: 0.689882, acc.: 54.69%] [G loss: 0.904662]\n",
      "epoch:2 step:2330 [D loss: 0.640499, acc.: 63.28%] [G loss: 0.948999]\n",
      "epoch:2 step:2331 [D loss: 0.561810, acc.: 72.66%] [G loss: 0.988393]\n",
      "epoch:2 step:2332 [D loss: 0.756149, acc.: 46.88%] [G loss: 0.951527]\n",
      "epoch:2 step:2333 [D loss: 0.734059, acc.: 56.25%] [G loss: 0.928821]\n",
      "epoch:2 step:2334 [D loss: 0.644471, acc.: 60.94%] [G loss: 1.029537]\n",
      "epoch:2 step:2335 [D loss: 0.659244, acc.: 63.28%] [G loss: 1.027661]\n",
      "epoch:2 step:2336 [D loss: 0.707257, acc.: 58.59%] [G loss: 0.882503]\n",
      "epoch:2 step:2337 [D loss: 0.735834, acc.: 53.12%] [G loss: 0.912984]\n",
      "epoch:2 step:2338 [D loss: 0.647776, acc.: 62.50%] [G loss: 0.922248]\n",
      "epoch:2 step:2339 [D loss: 0.731579, acc.: 49.22%] [G loss: 0.936147]\n",
      "epoch:2 step:2340 [D loss: 0.682495, acc.: 57.03%] [G loss: 1.008808]\n",
      "epoch:2 step:2341 [D loss: 0.703044, acc.: 62.50%] [G loss: 0.857595]\n",
      "epoch:2 step:2342 [D loss: 0.661153, acc.: 60.94%] [G loss: 0.984584]\n",
      "epoch:2 step:2343 [D loss: 0.642864, acc.: 61.72%] [G loss: 1.048176]\n",
      "epoch:2 step:2344 [D loss: 0.648614, acc.: 68.75%] [G loss: 1.028842]\n",
      "epoch:2 step:2345 [D loss: 0.647979, acc.: 59.38%] [G loss: 1.017994]\n",
      "epoch:2 step:2346 [D loss: 0.697889, acc.: 60.94%] [G loss: 0.913674]\n",
      "epoch:2 step:2347 [D loss: 0.787554, acc.: 46.88%] [G loss: 0.916009]\n",
      "epoch:2 step:2348 [D loss: 0.713208, acc.: 55.47%] [G loss: 0.933403]\n",
      "epoch:2 step:2349 [D loss: 0.718491, acc.: 51.56%] [G loss: 0.871357]\n",
      "epoch:2 step:2350 [D loss: 0.618135, acc.: 70.31%] [G loss: 0.944807]\n",
      "epoch:2 step:2351 [D loss: 0.752242, acc.: 51.56%] [G loss: 0.923866]\n",
      "epoch:2 step:2352 [D loss: 0.680415, acc.: 56.25%] [G loss: 0.897162]\n",
      "epoch:2 step:2353 [D loss: 0.725600, acc.: 51.56%] [G loss: 0.855719]\n",
      "epoch:2 step:2354 [D loss: 0.677561, acc.: 57.03%] [G loss: 0.882573]\n",
      "epoch:2 step:2355 [D loss: 0.671680, acc.: 54.69%] [G loss: 1.045486]\n",
      "epoch:2 step:2356 [D loss: 0.751308, acc.: 45.31%] [G loss: 0.943039]\n",
      "epoch:2 step:2357 [D loss: 0.721322, acc.: 53.91%] [G loss: 0.898136]\n",
      "epoch:2 step:2358 [D loss: 0.666126, acc.: 60.94%] [G loss: 0.938503]\n",
      "epoch:2 step:2359 [D loss: 0.701456, acc.: 54.69%] [G loss: 0.919015]\n",
      "epoch:2 step:2360 [D loss: 0.734928, acc.: 50.00%] [G loss: 1.005462]\n",
      "epoch:2 step:2361 [D loss: 0.664827, acc.: 61.72%] [G loss: 0.928923]\n",
      "epoch:2 step:2362 [D loss: 0.586858, acc.: 72.66%] [G loss: 0.968920]\n",
      "epoch:2 step:2363 [D loss: 0.724617, acc.: 53.91%] [G loss: 0.880723]\n",
      "epoch:2 step:2364 [D loss: 0.671338, acc.: 57.81%] [G loss: 0.988179]\n",
      "epoch:2 step:2365 [D loss: 0.670607, acc.: 62.50%] [G loss: 0.888794]\n",
      "epoch:2 step:2366 [D loss: 0.632667, acc.: 63.28%] [G loss: 0.928496]\n",
      "epoch:2 step:2367 [D loss: 0.766640, acc.: 46.09%] [G loss: 0.869854]\n",
      "epoch:2 step:2368 [D loss: 0.678341, acc.: 60.16%] [G loss: 0.868436]\n",
      "epoch:2 step:2369 [D loss: 0.695122, acc.: 53.12%] [G loss: 0.881190]\n",
      "epoch:2 step:2370 [D loss: 0.671231, acc.: 63.28%] [G loss: 0.917679]\n",
      "epoch:2 step:2371 [D loss: 0.741853, acc.: 47.66%] [G loss: 0.799553]\n",
      "epoch:2 step:2372 [D loss: 0.679519, acc.: 60.16%] [G loss: 1.037418]\n",
      "epoch:2 step:2373 [D loss: 0.627424, acc.: 65.62%] [G loss: 1.024301]\n",
      "epoch:2 step:2374 [D loss: 0.729472, acc.: 46.09%] [G loss: 0.859671]\n",
      "epoch:2 step:2375 [D loss: 0.686951, acc.: 51.56%] [G loss: 1.008305]\n",
      "epoch:2 step:2376 [D loss: 0.715995, acc.: 52.34%] [G loss: 0.866874]\n",
      "epoch:2 step:2377 [D loss: 0.707154, acc.: 53.12%] [G loss: 0.906154]\n",
      "epoch:2 step:2378 [D loss: 0.686097, acc.: 55.47%] [G loss: 0.941649]\n",
      "epoch:2 step:2379 [D loss: 0.629617, acc.: 69.53%] [G loss: 0.961873]\n",
      "epoch:2 step:2380 [D loss: 0.691035, acc.: 58.59%] [G loss: 0.949016]\n",
      "epoch:2 step:2381 [D loss: 0.692235, acc.: 57.81%] [G loss: 0.903987]\n",
      "epoch:2 step:2382 [D loss: 0.684830, acc.: 53.91%] [G loss: 0.897245]\n",
      "epoch:2 step:2383 [D loss: 0.678195, acc.: 62.50%] [G loss: 0.986444]\n",
      "epoch:2 step:2384 [D loss: 0.682378, acc.: 60.16%] [G loss: 0.879949]\n",
      "epoch:2 step:2385 [D loss: 0.779136, acc.: 53.12%] [G loss: 0.921340]\n",
      "epoch:2 step:2386 [D loss: 0.704665, acc.: 56.25%] [G loss: 0.916783]\n",
      "epoch:2 step:2387 [D loss: 0.609447, acc.: 65.62%] [G loss: 0.963851]\n",
      "epoch:2 step:2388 [D loss: 0.670254, acc.: 60.94%] [G loss: 0.922799]\n",
      "epoch:2 step:2389 [D loss: 0.636727, acc.: 70.31%] [G loss: 0.897899]\n",
      "epoch:2 step:2390 [D loss: 0.625313, acc.: 66.41%] [G loss: 0.928523]\n",
      "epoch:2 step:2391 [D loss: 0.722832, acc.: 52.34%] [G loss: 0.988817]\n",
      "epoch:2 step:2392 [D loss: 0.688058, acc.: 60.16%] [G loss: 0.978774]\n",
      "epoch:2 step:2393 [D loss: 0.669253, acc.: 59.38%] [G loss: 0.846632]\n",
      "epoch:2 step:2394 [D loss: 0.670572, acc.: 69.53%] [G loss: 0.902500]\n",
      "epoch:2 step:2395 [D loss: 0.665221, acc.: 57.81%] [G loss: 0.905016]\n",
      "epoch:2 step:2396 [D loss: 0.659433, acc.: 54.69%] [G loss: 0.976169]\n",
      "epoch:2 step:2397 [D loss: 0.644489, acc.: 61.72%] [G loss: 0.994404]\n",
      "epoch:2 step:2398 [D loss: 0.650949, acc.: 58.59%] [G loss: 0.944828]\n",
      "epoch:2 step:2399 [D loss: 0.675680, acc.: 58.59%] [G loss: 0.826966]\n",
      "epoch:2 step:2400 [D loss: 0.640165, acc.: 63.28%] [G loss: 0.945789]\n",
      "##############\n",
      "[1.5784252  0.37627115 5.02328773 3.8211785  2.5117256  4.51944699\n",
      " 3.4109033  3.85634985 3.46658646 2.64998423]\n",
      "##########\n",
      "epoch:2 step:2401 [D loss: 0.637675, acc.: 66.41%] [G loss: 0.913211]\n",
      "epoch:2 step:2402 [D loss: 0.725225, acc.: 56.25%] [G loss: 0.864530]\n",
      "epoch:2 step:2403 [D loss: 0.672129, acc.: 53.12%] [G loss: 0.837457]\n",
      "epoch:2 step:2404 [D loss: 0.644487, acc.: 67.19%] [G loss: 0.880366]\n",
      "epoch:2 step:2405 [D loss: 0.697299, acc.: 55.47%] [G loss: 0.874967]\n",
      "epoch:2 step:2406 [D loss: 0.654607, acc.: 62.50%] [G loss: 0.974273]\n",
      "epoch:2 step:2407 [D loss: 0.705700, acc.: 55.47%] [G loss: 0.895101]\n",
      "epoch:2 step:2408 [D loss: 0.687852, acc.: 56.25%] [G loss: 0.890739]\n",
      "epoch:2 step:2409 [D loss: 0.634112, acc.: 60.94%] [G loss: 0.915655]\n",
      "epoch:2 step:2410 [D loss: 0.684634, acc.: 53.91%] [G loss: 0.960184]\n",
      "epoch:2 step:2411 [D loss: 0.635690, acc.: 63.28%] [G loss: 0.993808]\n",
      "epoch:2 step:2412 [D loss: 0.650344, acc.: 63.28%] [G loss: 0.942798]\n",
      "epoch:2 step:2413 [D loss: 0.776030, acc.: 49.22%] [G loss: 0.949308]\n",
      "epoch:2 step:2414 [D loss: 0.698673, acc.: 58.59%] [G loss: 0.966168]\n",
      "epoch:2 step:2415 [D loss: 0.622227, acc.: 62.50%] [G loss: 0.945655]\n",
      "epoch:2 step:2416 [D loss: 0.753870, acc.: 46.09%] [G loss: 0.855553]\n",
      "epoch:2 step:2417 [D loss: 0.713714, acc.: 54.69%] [G loss: 0.876682]\n",
      "epoch:2 step:2418 [D loss: 0.695493, acc.: 50.00%] [G loss: 0.843956]\n",
      "epoch:2 step:2419 [D loss: 0.630914, acc.: 66.41%] [G loss: 0.871828]\n",
      "epoch:2 step:2420 [D loss: 0.703159, acc.: 57.03%] [G loss: 0.907332]\n",
      "epoch:2 step:2421 [D loss: 0.635261, acc.: 63.28%] [G loss: 0.938758]\n",
      "epoch:2 step:2422 [D loss: 0.665904, acc.: 62.50%] [G loss: 0.967148]\n",
      "epoch:2 step:2423 [D loss: 0.658016, acc.: 60.94%] [G loss: 0.952880]\n",
      "epoch:2 step:2424 [D loss: 0.622162, acc.: 64.84%] [G loss: 1.006740]\n",
      "epoch:2 step:2425 [D loss: 0.601178, acc.: 67.97%] [G loss: 0.962671]\n",
      "epoch:2 step:2426 [D loss: 0.611017, acc.: 67.19%] [G loss: 1.097340]\n",
      "epoch:2 step:2427 [D loss: 0.673216, acc.: 60.94%] [G loss: 1.130269]\n",
      "epoch:2 step:2428 [D loss: 0.679888, acc.: 53.91%] [G loss: 1.052771]\n",
      "epoch:2 step:2429 [D loss: 0.675121, acc.: 59.38%] [G loss: 0.991565]\n",
      "epoch:2 step:2430 [D loss: 0.634451, acc.: 64.06%] [G loss: 0.994911]\n",
      "epoch:2 step:2431 [D loss: 0.607414, acc.: 67.19%] [G loss: 0.987906]\n",
      "epoch:2 step:2432 [D loss: 0.621944, acc.: 67.97%] [G loss: 0.997264]\n",
      "epoch:2 step:2433 [D loss: 0.797992, acc.: 47.66%] [G loss: 0.973580]\n",
      "epoch:2 step:2434 [D loss: 0.730628, acc.: 49.22%] [G loss: 0.979030]\n",
      "epoch:2 step:2435 [D loss: 0.640877, acc.: 66.41%] [G loss: 0.968615]\n",
      "epoch:2 step:2436 [D loss: 0.653836, acc.: 60.94%] [G loss: 0.892531]\n",
      "epoch:2 step:2437 [D loss: 0.690295, acc.: 57.03%] [G loss: 0.882992]\n",
      "epoch:2 step:2438 [D loss: 0.744229, acc.: 48.44%] [G loss: 0.875466]\n",
      "epoch:2 step:2439 [D loss: 0.710964, acc.: 48.44%] [G loss: 0.915696]\n",
      "epoch:2 step:2440 [D loss: 0.714284, acc.: 47.66%] [G loss: 1.003069]\n",
      "epoch:2 step:2441 [D loss: 0.718265, acc.: 47.66%] [G loss: 0.974744]\n",
      "epoch:2 step:2442 [D loss: 0.651487, acc.: 64.84%] [G loss: 1.000009]\n",
      "epoch:2 step:2443 [D loss: 0.618873, acc.: 67.19%] [G loss: 0.980670]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2444 [D loss: 0.687978, acc.: 55.47%] [G loss: 0.981877]\n",
      "epoch:2 step:2445 [D loss: 0.679250, acc.: 54.69%] [G loss: 0.949858]\n",
      "epoch:2 step:2446 [D loss: 0.762507, acc.: 48.44%] [G loss: 0.873445]\n",
      "epoch:2 step:2447 [D loss: 0.728538, acc.: 50.78%] [G loss: 0.992789]\n",
      "epoch:2 step:2448 [D loss: 0.720202, acc.: 54.69%] [G loss: 0.865571]\n",
      "epoch:2 step:2449 [D loss: 0.689701, acc.: 58.59%] [G loss: 0.997273]\n",
      "epoch:2 step:2450 [D loss: 0.750519, acc.: 46.09%] [G loss: 1.040217]\n",
      "epoch:2 step:2451 [D loss: 0.754076, acc.: 51.56%] [G loss: 0.941164]\n",
      "epoch:2 step:2452 [D loss: 0.654334, acc.: 65.62%] [G loss: 1.047944]\n",
      "epoch:2 step:2453 [D loss: 0.687662, acc.: 53.12%] [G loss: 0.963102]\n",
      "epoch:2 step:2454 [D loss: 0.739028, acc.: 49.22%] [G loss: 0.872364]\n",
      "epoch:2 step:2455 [D loss: 0.704997, acc.: 49.22%] [G loss: 0.932847]\n",
      "epoch:2 step:2456 [D loss: 0.650375, acc.: 63.28%] [G loss: 0.929035]\n",
      "epoch:2 step:2457 [D loss: 0.732920, acc.: 53.91%] [G loss: 0.840453]\n",
      "epoch:2 step:2458 [D loss: 0.711962, acc.: 54.69%] [G loss: 0.896570]\n",
      "epoch:2 step:2459 [D loss: 0.640666, acc.: 63.28%] [G loss: 0.945276]\n",
      "epoch:2 step:2460 [D loss: 0.633441, acc.: 61.72%] [G loss: 0.977494]\n",
      "epoch:2 step:2461 [D loss: 0.687499, acc.: 57.03%] [G loss: 0.817100]\n",
      "epoch:2 step:2462 [D loss: 0.687023, acc.: 57.81%] [G loss: 0.919358]\n",
      "epoch:2 step:2463 [D loss: 0.631849, acc.: 64.84%] [G loss: 0.993782]\n",
      "epoch:2 step:2464 [D loss: 0.713519, acc.: 51.56%] [G loss: 0.880066]\n",
      "epoch:2 step:2465 [D loss: 0.654665, acc.: 57.03%] [G loss: 1.012163]\n",
      "epoch:2 step:2466 [D loss: 0.706746, acc.: 55.47%] [G loss: 0.910933]\n",
      "epoch:2 step:2467 [D loss: 0.724696, acc.: 47.66%] [G loss: 0.921321]\n",
      "epoch:2 step:2468 [D loss: 0.625648, acc.: 65.62%] [G loss: 0.938494]\n",
      "epoch:2 step:2469 [D loss: 0.644581, acc.: 63.28%] [G loss: 0.972364]\n",
      "epoch:2 step:2470 [D loss: 0.718117, acc.: 50.00%] [G loss: 0.798028]\n",
      "epoch:2 step:2471 [D loss: 0.676853, acc.: 60.94%] [G loss: 0.940023]\n",
      "epoch:2 step:2472 [D loss: 0.692375, acc.: 53.91%] [G loss: 0.938276]\n",
      "epoch:2 step:2473 [D loss: 0.715748, acc.: 51.56%] [G loss: 0.941467]\n",
      "epoch:2 step:2474 [D loss: 0.758522, acc.: 51.56%] [G loss: 0.963130]\n",
      "epoch:2 step:2475 [D loss: 0.694474, acc.: 51.56%] [G loss: 0.924236]\n",
      "epoch:2 step:2476 [D loss: 0.659459, acc.: 61.72%] [G loss: 0.886155]\n",
      "epoch:2 step:2477 [D loss: 0.663389, acc.: 64.06%] [G loss: 0.905419]\n",
      "epoch:2 step:2478 [D loss: 0.710076, acc.: 52.34%] [G loss: 1.018623]\n",
      "epoch:2 step:2479 [D loss: 0.645341, acc.: 59.38%] [G loss: 0.960571]\n",
      "epoch:2 step:2480 [D loss: 0.633699, acc.: 62.50%] [G loss: 0.973092]\n",
      "epoch:2 step:2481 [D loss: 0.730851, acc.: 46.88%] [G loss: 0.949434]\n",
      "epoch:2 step:2482 [D loss: 0.658417, acc.: 57.81%] [G loss: 1.004070]\n",
      "epoch:2 step:2483 [D loss: 0.711546, acc.: 53.91%] [G loss: 0.898079]\n",
      "epoch:2 step:2484 [D loss: 0.664475, acc.: 57.81%] [G loss: 0.930918]\n",
      "epoch:2 step:2485 [D loss: 0.676739, acc.: 57.03%] [G loss: 0.957115]\n",
      "epoch:2 step:2486 [D loss: 0.662440, acc.: 59.38%] [G loss: 1.028738]\n",
      "epoch:2 step:2487 [D loss: 0.660774, acc.: 63.28%] [G loss: 0.902305]\n",
      "epoch:2 step:2488 [D loss: 0.669610, acc.: 57.81%] [G loss: 0.913888]\n",
      "epoch:2 step:2489 [D loss: 0.787681, acc.: 42.19%] [G loss: 0.921628]\n",
      "epoch:2 step:2490 [D loss: 0.614479, acc.: 66.41%] [G loss: 0.938855]\n",
      "epoch:2 step:2491 [D loss: 0.735526, acc.: 46.09%] [G loss: 0.908846]\n",
      "epoch:2 step:2492 [D loss: 0.648554, acc.: 63.28%] [G loss: 0.862878]\n",
      "epoch:2 step:2493 [D loss: 0.676794, acc.: 60.94%] [G loss: 0.925053]\n",
      "epoch:2 step:2494 [D loss: 0.708431, acc.: 57.03%] [G loss: 0.879386]\n",
      "epoch:2 step:2495 [D loss: 0.699259, acc.: 55.47%] [G loss: 0.870952]\n",
      "epoch:2 step:2496 [D loss: 0.741130, acc.: 50.00%] [G loss: 0.973306]\n",
      "epoch:2 step:2497 [D loss: 0.733382, acc.: 48.44%] [G loss: 0.913448]\n",
      "epoch:2 step:2498 [D loss: 0.642010, acc.: 66.41%] [G loss: 0.951105]\n",
      "epoch:2 step:2499 [D loss: 0.703057, acc.: 54.69%] [G loss: 0.971541]\n",
      "epoch:2 step:2500 [D loss: 0.709086, acc.: 52.34%] [G loss: 1.001382]\n",
      "epoch:2 step:2501 [D loss: 0.697916, acc.: 59.38%] [G loss: 0.976217]\n",
      "epoch:2 step:2502 [D loss: 0.697988, acc.: 51.56%] [G loss: 0.920612]\n",
      "epoch:2 step:2503 [D loss: 0.725909, acc.: 50.00%] [G loss: 0.920269]\n",
      "epoch:2 step:2504 [D loss: 0.697072, acc.: 53.91%] [G loss: 0.973592]\n",
      "epoch:2 step:2505 [D loss: 0.664168, acc.: 61.72%] [G loss: 0.947425]\n",
      "epoch:2 step:2506 [D loss: 0.663899, acc.: 60.94%] [G loss: 0.973545]\n",
      "epoch:2 step:2507 [D loss: 0.636482, acc.: 64.06%] [G loss: 0.873657]\n",
      "epoch:2 step:2508 [D loss: 0.629479, acc.: 60.94%] [G loss: 0.986414]\n",
      "epoch:2 step:2509 [D loss: 0.567280, acc.: 75.78%] [G loss: 1.032182]\n",
      "epoch:2 step:2510 [D loss: 0.687528, acc.: 57.03%] [G loss: 1.020358]\n",
      "epoch:2 step:2511 [D loss: 0.624450, acc.: 61.72%] [G loss: 0.939589]\n",
      "epoch:2 step:2512 [D loss: 0.694956, acc.: 57.81%] [G loss: 0.838876]\n",
      "epoch:2 step:2513 [D loss: 0.668784, acc.: 64.06%] [G loss: 1.003761]\n",
      "epoch:2 step:2514 [D loss: 0.637123, acc.: 69.53%] [G loss: 0.918392]\n",
      "epoch:2 step:2515 [D loss: 0.618156, acc.: 75.00%] [G loss: 1.122324]\n",
      "epoch:2 step:2516 [D loss: 0.621602, acc.: 62.50%] [G loss: 1.036376]\n",
      "epoch:2 step:2517 [D loss: 0.652729, acc.: 61.72%] [G loss: 1.059859]\n",
      "epoch:2 step:2518 [D loss: 0.654196, acc.: 60.94%] [G loss: 1.044915]\n",
      "epoch:2 step:2519 [D loss: 0.658054, acc.: 60.94%] [G loss: 0.878478]\n",
      "epoch:2 step:2520 [D loss: 0.714019, acc.: 55.47%] [G loss: 0.807711]\n",
      "epoch:2 step:2521 [D loss: 0.646414, acc.: 60.16%] [G loss: 0.946307]\n",
      "epoch:2 step:2522 [D loss: 0.650300, acc.: 67.19%] [G loss: 0.915300]\n",
      "epoch:2 step:2523 [D loss: 0.624104, acc.: 63.28%] [G loss: 0.950947]\n",
      "epoch:2 step:2524 [D loss: 0.692462, acc.: 57.03%] [G loss: 0.911208]\n",
      "epoch:2 step:2525 [D loss: 0.700175, acc.: 55.47%] [G loss: 0.942667]\n",
      "epoch:2 step:2526 [D loss: 0.694061, acc.: 57.81%] [G loss: 0.910931]\n",
      "epoch:2 step:2527 [D loss: 0.719971, acc.: 57.81%] [G loss: 0.914076]\n",
      "epoch:2 step:2528 [D loss: 0.588003, acc.: 66.41%] [G loss: 0.917724]\n",
      "epoch:2 step:2529 [D loss: 0.696235, acc.: 50.00%] [G loss: 0.879885]\n",
      "epoch:2 step:2530 [D loss: 0.693834, acc.: 52.34%] [G loss: 0.997673]\n",
      "epoch:2 step:2531 [D loss: 0.630031, acc.: 67.97%] [G loss: 0.922374]\n",
      "epoch:2 step:2532 [D loss: 0.674007, acc.: 65.62%] [G loss: 0.877192]\n",
      "epoch:2 step:2533 [D loss: 0.679659, acc.: 59.38%] [G loss: 0.914814]\n",
      "epoch:2 step:2534 [D loss: 0.691311, acc.: 57.03%] [G loss: 0.860671]\n",
      "epoch:2 step:2535 [D loss: 0.615113, acc.: 64.84%] [G loss: 0.999876]\n",
      "epoch:2 step:2536 [D loss: 0.664800, acc.: 60.16%] [G loss: 0.950726]\n",
      "epoch:2 step:2537 [D loss: 0.647772, acc.: 62.50%] [G loss: 0.975558]\n",
      "epoch:2 step:2538 [D loss: 0.697163, acc.: 58.59%] [G loss: 0.969276]\n",
      "epoch:2 step:2539 [D loss: 0.634137, acc.: 64.06%] [G loss: 0.989350]\n",
      "epoch:2 step:2540 [D loss: 0.745900, acc.: 50.78%] [G loss: 0.908675]\n",
      "epoch:2 step:2541 [D loss: 0.709419, acc.: 53.12%] [G loss: 0.906895]\n",
      "epoch:2 step:2542 [D loss: 0.702668, acc.: 57.03%] [G loss: 0.855583]\n",
      "epoch:2 step:2543 [D loss: 0.699740, acc.: 55.47%] [G loss: 0.839262]\n",
      "epoch:2 step:2544 [D loss: 0.693727, acc.: 56.25%] [G loss: 0.889054]\n",
      "epoch:2 step:2545 [D loss: 0.654799, acc.: 60.16%] [G loss: 0.971074]\n",
      "epoch:2 step:2546 [D loss: 0.705101, acc.: 53.91%] [G loss: 0.818415]\n",
      "epoch:2 step:2547 [D loss: 0.709301, acc.: 50.00%] [G loss: 0.955401]\n",
      "epoch:2 step:2548 [D loss: 0.661253, acc.: 62.50%] [G loss: 0.893099]\n",
      "epoch:2 step:2549 [D loss: 0.703472, acc.: 59.38%] [G loss: 0.906380]\n",
      "epoch:2 step:2550 [D loss: 0.673417, acc.: 61.72%] [G loss: 0.914654]\n",
      "epoch:2 step:2551 [D loss: 0.619350, acc.: 64.06%] [G loss: 0.930252]\n",
      "epoch:2 step:2552 [D loss: 0.617636, acc.: 64.84%] [G loss: 1.062026]\n",
      "epoch:2 step:2553 [D loss: 0.625255, acc.: 65.62%] [G loss: 0.968402]\n",
      "epoch:2 step:2554 [D loss: 0.614182, acc.: 69.53%] [G loss: 0.949556]\n",
      "epoch:2 step:2555 [D loss: 0.622706, acc.: 66.41%] [G loss: 1.029249]\n",
      "epoch:2 step:2556 [D loss: 0.665605, acc.: 60.16%] [G loss: 1.042877]\n",
      "epoch:2 step:2557 [D loss: 0.694296, acc.: 55.47%] [G loss: 0.953935]\n",
      "epoch:2 step:2558 [D loss: 0.733229, acc.: 57.81%] [G loss: 0.768988]\n",
      "epoch:2 step:2559 [D loss: 0.676484, acc.: 60.16%] [G loss: 0.929158]\n",
      "epoch:2 step:2560 [D loss: 0.629479, acc.: 64.84%] [G loss: 0.983577]\n",
      "epoch:2 step:2561 [D loss: 0.661952, acc.: 55.47%] [G loss: 0.980757]\n",
      "epoch:2 step:2562 [D loss: 0.748183, acc.: 46.09%] [G loss: 0.978230]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2563 [D loss: 0.658007, acc.: 64.84%] [G loss: 0.922709]\n",
      "epoch:2 step:2564 [D loss: 0.635224, acc.: 61.72%] [G loss: 0.962717]\n",
      "epoch:2 step:2565 [D loss: 0.690171, acc.: 59.38%] [G loss: 0.837229]\n",
      "epoch:2 step:2566 [D loss: 0.697602, acc.: 54.69%] [G loss: 0.882874]\n",
      "epoch:2 step:2567 [D loss: 0.693470, acc.: 57.03%] [G loss: 1.027706]\n",
      "epoch:2 step:2568 [D loss: 0.664891, acc.: 60.16%] [G loss: 0.986065]\n",
      "epoch:2 step:2569 [D loss: 0.659678, acc.: 61.72%] [G loss: 0.918957]\n",
      "epoch:2 step:2570 [D loss: 0.671127, acc.: 63.28%] [G loss: 0.946194]\n",
      "epoch:2 step:2571 [D loss: 0.693052, acc.: 53.12%] [G loss: 0.866938]\n",
      "epoch:2 step:2572 [D loss: 0.676832, acc.: 57.03%] [G loss: 1.004687]\n",
      "epoch:2 step:2573 [D loss: 0.620287, acc.: 65.62%] [G loss: 0.953181]\n",
      "epoch:2 step:2574 [D loss: 0.615500, acc.: 70.31%] [G loss: 1.150437]\n",
      "epoch:2 step:2575 [D loss: 0.643357, acc.: 56.25%] [G loss: 0.896174]\n",
      "epoch:2 step:2576 [D loss: 0.710338, acc.: 52.34%] [G loss: 0.978763]\n",
      "epoch:2 step:2577 [D loss: 0.691662, acc.: 60.94%] [G loss: 0.938864]\n",
      "epoch:2 step:2578 [D loss: 0.628840, acc.: 63.28%] [G loss: 1.037176]\n",
      "epoch:2 step:2579 [D loss: 0.622889, acc.: 60.16%] [G loss: 0.976099]\n",
      "epoch:2 step:2580 [D loss: 0.629977, acc.: 63.28%] [G loss: 0.964473]\n",
      "epoch:2 step:2581 [D loss: 0.695144, acc.: 56.25%] [G loss: 0.987465]\n",
      "epoch:2 step:2582 [D loss: 0.644250, acc.: 64.06%] [G loss: 1.027973]\n",
      "epoch:2 step:2583 [D loss: 0.630372, acc.: 62.50%] [G loss: 1.028001]\n",
      "epoch:2 step:2584 [D loss: 0.693335, acc.: 54.69%] [G loss: 0.961301]\n",
      "epoch:2 step:2585 [D loss: 0.705281, acc.: 52.34%] [G loss: 0.951632]\n",
      "epoch:2 step:2586 [D loss: 0.642302, acc.: 62.50%] [G loss: 0.959567]\n",
      "epoch:2 step:2587 [D loss: 0.621943, acc.: 69.53%] [G loss: 1.007358]\n",
      "epoch:2 step:2588 [D loss: 0.635659, acc.: 63.28%] [G loss: 1.014084]\n",
      "epoch:2 step:2589 [D loss: 0.681099, acc.: 53.12%] [G loss: 0.942878]\n",
      "epoch:2 step:2590 [D loss: 0.739142, acc.: 53.12%] [G loss: 0.943216]\n",
      "epoch:2 step:2591 [D loss: 0.711032, acc.: 57.81%] [G loss: 0.969127]\n",
      "epoch:2 step:2592 [D loss: 0.750054, acc.: 53.91%] [G loss: 0.871621]\n",
      "epoch:2 step:2593 [D loss: 0.716638, acc.: 54.69%] [G loss: 0.937939]\n",
      "epoch:2 step:2594 [D loss: 0.696927, acc.: 53.12%] [G loss: 0.927434]\n",
      "epoch:2 step:2595 [D loss: 0.708574, acc.: 50.00%] [G loss: 0.986269]\n",
      "epoch:2 step:2596 [D loss: 0.713345, acc.: 49.22%] [G loss: 1.007107]\n",
      "epoch:2 step:2597 [D loss: 0.648745, acc.: 62.50%] [G loss: 0.916053]\n",
      "epoch:2 step:2598 [D loss: 0.580404, acc.: 65.62%] [G loss: 0.970672]\n",
      "epoch:2 step:2599 [D loss: 0.672980, acc.: 57.03%] [G loss: 0.990681]\n",
      "epoch:2 step:2600 [D loss: 0.690664, acc.: 54.69%] [G loss: 0.971558]\n",
      "##############\n",
      "[1.9016807  0.75188187 4.91076218 4.00591348 2.67360646 4.5701332\n",
      " 3.5871703  4.10483832 3.74050383 2.63727595]\n",
      "##########\n",
      "epoch:2 step:2601 [D loss: 0.729573, acc.: 53.12%] [G loss: 0.976168]\n",
      "epoch:2 step:2602 [D loss: 0.708011, acc.: 57.03%] [G loss: 0.900997]\n",
      "epoch:2 step:2603 [D loss: 0.644748, acc.: 59.38%] [G loss: 0.962881]\n",
      "epoch:2 step:2604 [D loss: 0.681173, acc.: 63.28%] [G loss: 0.924431]\n",
      "epoch:2 step:2605 [D loss: 0.600922, acc.: 67.97%] [G loss: 0.925662]\n",
      "epoch:2 step:2606 [D loss: 0.602169, acc.: 64.84%] [G loss: 1.007286]\n",
      "epoch:2 step:2607 [D loss: 0.626391, acc.: 62.50%] [G loss: 1.066271]\n",
      "epoch:2 step:2608 [D loss: 0.724682, acc.: 57.03%] [G loss: 1.037268]\n",
      "epoch:2 step:2609 [D loss: 0.711298, acc.: 53.91%] [G loss: 0.971338]\n",
      "epoch:2 step:2610 [D loss: 0.726607, acc.: 48.44%] [G loss: 1.032820]\n",
      "epoch:2 step:2611 [D loss: 0.672406, acc.: 61.72%] [G loss: 0.938976]\n",
      "epoch:2 step:2612 [D loss: 0.700889, acc.: 53.12%] [G loss: 0.993570]\n",
      "epoch:2 step:2613 [D loss: 0.716001, acc.: 49.22%] [G loss: 0.917956]\n",
      "epoch:2 step:2614 [D loss: 0.674827, acc.: 56.25%] [G loss: 0.919727]\n",
      "epoch:2 step:2615 [D loss: 0.755244, acc.: 48.44%] [G loss: 0.867255]\n",
      "epoch:2 step:2616 [D loss: 0.653094, acc.: 59.38%] [G loss: 1.009219]\n",
      "epoch:2 step:2617 [D loss: 0.651499, acc.: 64.06%] [G loss: 1.015413]\n",
      "epoch:2 step:2618 [D loss: 0.795291, acc.: 43.75%] [G loss: 0.845097]\n",
      "epoch:2 step:2619 [D loss: 0.634808, acc.: 59.38%] [G loss: 1.007563]\n",
      "epoch:2 step:2620 [D loss: 0.617013, acc.: 62.50%] [G loss: 1.018137]\n",
      "epoch:2 step:2621 [D loss: 0.656436, acc.: 57.81%] [G loss: 0.984360]\n",
      "epoch:2 step:2622 [D loss: 0.649397, acc.: 64.06%] [G loss: 0.970437]\n",
      "epoch:2 step:2623 [D loss: 0.730710, acc.: 50.78%] [G loss: 0.984935]\n",
      "epoch:2 step:2624 [D loss: 0.653390, acc.: 61.72%] [G loss: 0.943414]\n",
      "epoch:2 step:2625 [D loss: 0.707427, acc.: 54.69%] [G loss: 1.022254]\n",
      "epoch:2 step:2626 [D loss: 0.748274, acc.: 49.22%] [G loss: 0.836062]\n",
      "epoch:2 step:2627 [D loss: 0.675231, acc.: 57.81%] [G loss: 0.821857]\n",
      "epoch:2 step:2628 [D loss: 0.659420, acc.: 60.16%] [G loss: 0.912925]\n",
      "epoch:2 step:2629 [D loss: 0.691734, acc.: 53.12%] [G loss: 0.903657]\n",
      "epoch:2 step:2630 [D loss: 0.655207, acc.: 63.28%] [G loss: 0.845197]\n",
      "epoch:2 step:2631 [D loss: 0.688942, acc.: 52.34%] [G loss: 0.897306]\n",
      "epoch:2 step:2632 [D loss: 0.671383, acc.: 55.47%] [G loss: 0.974307]\n",
      "epoch:2 step:2633 [D loss: 0.724374, acc.: 49.22%] [G loss: 0.893072]\n",
      "epoch:2 step:2634 [D loss: 0.647057, acc.: 59.38%] [G loss: 0.953165]\n",
      "epoch:2 step:2635 [D loss: 0.670938, acc.: 57.81%] [G loss: 0.938426]\n",
      "epoch:2 step:2636 [D loss: 0.689812, acc.: 52.34%] [G loss: 0.852947]\n",
      "epoch:2 step:2637 [D loss: 0.686275, acc.: 57.03%] [G loss: 0.901345]\n",
      "epoch:2 step:2638 [D loss: 0.663580, acc.: 60.94%] [G loss: 0.872576]\n",
      "epoch:2 step:2639 [D loss: 0.681010, acc.: 53.12%] [G loss: 0.963645]\n",
      "epoch:2 step:2640 [D loss: 0.704393, acc.: 50.78%] [G loss: 0.868573]\n",
      "epoch:2 step:2641 [D loss: 0.701077, acc.: 55.47%] [G loss: 0.962724]\n",
      "epoch:2 step:2642 [D loss: 0.684282, acc.: 60.16%] [G loss: 0.867541]\n",
      "epoch:2 step:2643 [D loss: 0.720250, acc.: 50.78%] [G loss: 0.863805]\n",
      "epoch:2 step:2644 [D loss: 0.749016, acc.: 51.56%] [G loss: 0.849296]\n",
      "epoch:2 step:2645 [D loss: 0.648456, acc.: 60.94%] [G loss: 0.943596]\n",
      "epoch:2 step:2646 [D loss: 0.600559, acc.: 66.41%] [G loss: 0.973027]\n",
      "epoch:2 step:2647 [D loss: 0.672921, acc.: 59.38%] [G loss: 1.023387]\n",
      "epoch:2 step:2648 [D loss: 0.702653, acc.: 59.38%] [G loss: 0.986618]\n",
      "epoch:2 step:2649 [D loss: 0.680623, acc.: 55.47%] [G loss: 0.829785]\n",
      "epoch:2 step:2650 [D loss: 0.691458, acc.: 57.81%] [G loss: 0.946205]\n",
      "epoch:2 step:2651 [D loss: 0.791098, acc.: 50.78%] [G loss: 0.886886]\n",
      "epoch:2 step:2652 [D loss: 0.663974, acc.: 60.94%] [G loss: 0.990857]\n",
      "epoch:2 step:2653 [D loss: 0.692214, acc.: 53.91%] [G loss: 1.017171]\n",
      "epoch:2 step:2654 [D loss: 0.739185, acc.: 53.12%] [G loss: 0.928501]\n",
      "epoch:2 step:2655 [D loss: 0.690398, acc.: 59.38%] [G loss: 0.921319]\n",
      "epoch:2 step:2656 [D loss: 0.683974, acc.: 53.91%] [G loss: 0.984417]\n",
      "epoch:2 step:2657 [D loss: 0.621992, acc.: 63.28%] [G loss: 0.837204]\n",
      "epoch:2 step:2658 [D loss: 0.644283, acc.: 64.06%] [G loss: 1.026065]\n",
      "epoch:2 step:2659 [D loss: 0.643552, acc.: 64.84%] [G loss: 0.936971]\n",
      "epoch:2 step:2660 [D loss: 0.600671, acc.: 69.53%] [G loss: 0.996696]\n",
      "epoch:2 step:2661 [D loss: 0.686372, acc.: 58.59%] [G loss: 0.936070]\n",
      "epoch:2 step:2662 [D loss: 0.750235, acc.: 51.56%] [G loss: 0.948366]\n",
      "epoch:2 step:2663 [D loss: 0.647079, acc.: 63.28%] [G loss: 0.901097]\n",
      "epoch:2 step:2664 [D loss: 0.648868, acc.: 65.62%] [G loss: 0.893177]\n",
      "epoch:2 step:2665 [D loss: 0.708665, acc.: 52.34%] [G loss: 0.971921]\n",
      "epoch:2 step:2666 [D loss: 0.651503, acc.: 64.06%] [G loss: 1.009038]\n",
      "epoch:2 step:2667 [D loss: 0.632724, acc.: 63.28%] [G loss: 1.095927]\n",
      "epoch:2 step:2668 [D loss: 0.719062, acc.: 57.81%] [G loss: 0.938224]\n",
      "epoch:2 step:2669 [D loss: 0.620929, acc.: 67.97%] [G loss: 1.001239]\n",
      "epoch:2 step:2670 [D loss: 0.663180, acc.: 59.38%] [G loss: 1.026504]\n",
      "epoch:2 step:2671 [D loss: 0.760595, acc.: 46.88%] [G loss: 0.900858]\n",
      "epoch:2 step:2672 [D loss: 0.625277, acc.: 64.84%] [G loss: 0.893919]\n",
      "epoch:2 step:2673 [D loss: 0.673225, acc.: 63.28%] [G loss: 0.939727]\n",
      "epoch:2 step:2674 [D loss: 0.703598, acc.: 49.22%] [G loss: 0.962015]\n",
      "epoch:2 step:2675 [D loss: 0.757372, acc.: 46.88%] [G loss: 0.951901]\n",
      "epoch:2 step:2676 [D loss: 0.622345, acc.: 62.50%] [G loss: 0.862586]\n",
      "epoch:2 step:2677 [D loss: 0.697950, acc.: 56.25%] [G loss: 0.971817]\n",
      "epoch:2 step:2678 [D loss: 0.646176, acc.: 66.41%] [G loss: 0.943691]\n",
      "epoch:2 step:2679 [D loss: 0.609779, acc.: 62.50%] [G loss: 1.005172]\n",
      "epoch:2 step:2680 [D loss: 0.694388, acc.: 58.59%] [G loss: 0.919961]\n",
      "epoch:2 step:2681 [D loss: 0.644957, acc.: 62.50%] [G loss: 0.948476]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2682 [D loss: 0.605609, acc.: 68.75%] [G loss: 1.083665]\n",
      "epoch:2 step:2683 [D loss: 0.697098, acc.: 57.03%] [G loss: 0.895243]\n",
      "epoch:2 step:2684 [D loss: 0.667033, acc.: 58.59%] [G loss: 0.926076]\n",
      "epoch:2 step:2685 [D loss: 0.606780, acc.: 69.53%] [G loss: 0.963973]\n",
      "epoch:2 step:2686 [D loss: 0.716562, acc.: 53.12%] [G loss: 0.975315]\n",
      "epoch:2 step:2687 [D loss: 0.689671, acc.: 53.12%] [G loss: 0.825112]\n",
      "epoch:2 step:2688 [D loss: 0.634569, acc.: 63.28%] [G loss: 0.855209]\n",
      "epoch:2 step:2689 [D loss: 0.689452, acc.: 54.69%] [G loss: 0.979189]\n",
      "epoch:2 step:2690 [D loss: 0.665438, acc.: 57.81%] [G loss: 0.987922]\n",
      "epoch:2 step:2691 [D loss: 0.714935, acc.: 51.56%] [G loss: 1.092311]\n",
      "epoch:2 step:2692 [D loss: 0.713325, acc.: 56.25%] [G loss: 1.015850]\n",
      "epoch:2 step:2693 [D loss: 0.676421, acc.: 61.72%] [G loss: 0.984240]\n",
      "epoch:2 step:2694 [D loss: 0.691506, acc.: 58.59%] [G loss: 0.934233]\n",
      "epoch:2 step:2695 [D loss: 0.673771, acc.: 56.25%] [G loss: 1.015734]\n",
      "epoch:2 step:2696 [D loss: 0.676128, acc.: 57.81%] [G loss: 0.863336]\n",
      "epoch:2 step:2697 [D loss: 0.628421, acc.: 61.72%] [G loss: 0.999314]\n",
      "epoch:2 step:2698 [D loss: 0.676435, acc.: 56.25%] [G loss: 1.020960]\n",
      "epoch:2 step:2699 [D loss: 0.656175, acc.: 57.81%] [G loss: 0.902317]\n",
      "epoch:2 step:2700 [D loss: 0.726271, acc.: 50.78%] [G loss: 0.971408]\n",
      "epoch:2 step:2701 [D loss: 0.724937, acc.: 51.56%] [G loss: 0.881943]\n",
      "epoch:2 step:2702 [D loss: 0.694048, acc.: 58.59%] [G loss: 0.874077]\n",
      "epoch:2 step:2703 [D loss: 0.585323, acc.: 68.75%] [G loss: 1.015535]\n",
      "epoch:2 step:2704 [D loss: 0.627714, acc.: 64.84%] [G loss: 1.008195]\n",
      "epoch:2 step:2705 [D loss: 0.669945, acc.: 60.94%] [G loss: 0.933793]\n",
      "epoch:2 step:2706 [D loss: 0.628651, acc.: 62.50%] [G loss: 0.945125]\n",
      "epoch:2 step:2707 [D loss: 0.628776, acc.: 64.84%] [G loss: 1.009159]\n",
      "epoch:2 step:2708 [D loss: 0.655655, acc.: 62.50%] [G loss: 0.977546]\n",
      "epoch:2 step:2709 [D loss: 0.603512, acc.: 65.62%] [G loss: 1.037707]\n",
      "epoch:2 step:2710 [D loss: 0.683843, acc.: 59.38%] [G loss: 1.030914]\n",
      "epoch:2 step:2711 [D loss: 0.635755, acc.: 66.41%] [G loss: 0.975729]\n",
      "epoch:2 step:2712 [D loss: 0.647956, acc.: 64.06%] [G loss: 0.996616]\n",
      "epoch:2 step:2713 [D loss: 0.720616, acc.: 56.25%] [G loss: 0.969252]\n",
      "epoch:2 step:2714 [D loss: 0.577017, acc.: 67.97%] [G loss: 1.050368]\n",
      "epoch:2 step:2715 [D loss: 0.652628, acc.: 62.50%] [G loss: 1.016944]\n",
      "epoch:2 step:2716 [D loss: 0.635787, acc.: 63.28%] [G loss: 0.950187]\n",
      "epoch:2 step:2717 [D loss: 0.649697, acc.: 62.50%] [G loss: 0.935989]\n",
      "epoch:2 step:2718 [D loss: 0.729102, acc.: 49.22%] [G loss: 0.973148]\n",
      "epoch:2 step:2719 [D loss: 0.649519, acc.: 61.72%] [G loss: 0.969607]\n",
      "epoch:2 step:2720 [D loss: 0.676304, acc.: 59.38%] [G loss: 0.886460]\n",
      "epoch:2 step:2721 [D loss: 0.652176, acc.: 60.94%] [G loss: 0.992889]\n",
      "epoch:2 step:2722 [D loss: 0.672278, acc.: 62.50%] [G loss: 0.892802]\n",
      "epoch:2 step:2723 [D loss: 0.709358, acc.: 53.91%] [G loss: 0.906449]\n",
      "epoch:2 step:2724 [D loss: 0.712530, acc.: 47.66%] [G loss: 0.850447]\n",
      "epoch:2 step:2725 [D loss: 0.712673, acc.: 53.12%] [G loss: 0.919898]\n",
      "epoch:2 step:2726 [D loss: 0.660228, acc.: 64.84%] [G loss: 0.914294]\n",
      "epoch:2 step:2727 [D loss: 0.618748, acc.: 66.41%] [G loss: 0.996877]\n",
      "epoch:2 step:2728 [D loss: 0.674949, acc.: 61.72%] [G loss: 1.002894]\n",
      "epoch:2 step:2729 [D loss: 0.715778, acc.: 50.78%] [G loss: 1.008699]\n",
      "epoch:2 step:2730 [D loss: 0.685599, acc.: 60.16%] [G loss: 0.912300]\n",
      "epoch:2 step:2731 [D loss: 0.697517, acc.: 57.03%] [G loss: 0.920427]\n",
      "epoch:2 step:2732 [D loss: 0.743350, acc.: 56.25%] [G loss: 0.975028]\n",
      "epoch:2 step:2733 [D loss: 0.769543, acc.: 42.19%] [G loss: 0.906414]\n",
      "epoch:2 step:2734 [D loss: 0.610677, acc.: 65.62%] [G loss: 1.033654]\n",
      "epoch:2 step:2735 [D loss: 0.698514, acc.: 60.16%] [G loss: 0.759976]\n",
      "epoch:2 step:2736 [D loss: 0.612537, acc.: 65.62%] [G loss: 0.931078]\n",
      "epoch:2 step:2737 [D loss: 0.673507, acc.: 59.38%] [G loss: 0.863615]\n",
      "epoch:2 step:2738 [D loss: 0.670218, acc.: 57.03%] [G loss: 0.977487]\n",
      "epoch:2 step:2739 [D loss: 0.690848, acc.: 58.59%] [G loss: 0.923899]\n",
      "epoch:2 step:2740 [D loss: 0.655007, acc.: 61.72%] [G loss: 0.958885]\n",
      "epoch:2 step:2741 [D loss: 0.764919, acc.: 46.88%] [G loss: 0.996670]\n",
      "epoch:2 step:2742 [D loss: 0.679231, acc.: 57.03%] [G loss: 0.970904]\n",
      "epoch:2 step:2743 [D loss: 0.643577, acc.: 60.94%] [G loss: 0.879830]\n",
      "epoch:2 step:2744 [D loss: 0.659216, acc.: 59.38%] [G loss: 0.968007]\n",
      "epoch:2 step:2745 [D loss: 0.663810, acc.: 61.72%] [G loss: 0.914927]\n",
      "epoch:2 step:2746 [D loss: 0.658521, acc.: 63.28%] [G loss: 0.861232]\n",
      "epoch:2 step:2747 [D loss: 0.643135, acc.: 64.06%] [G loss: 1.010647]\n",
      "epoch:2 step:2748 [D loss: 0.607764, acc.: 64.06%] [G loss: 0.907912]\n",
      "epoch:2 step:2749 [D loss: 0.668027, acc.: 60.94%] [G loss: 0.887253]\n",
      "epoch:2 step:2750 [D loss: 0.670391, acc.: 60.94%] [G loss: 1.028050]\n",
      "epoch:2 step:2751 [D loss: 0.683945, acc.: 57.03%] [G loss: 1.016184]\n",
      "epoch:2 step:2752 [D loss: 0.653254, acc.: 59.38%] [G loss: 0.928447]\n",
      "epoch:2 step:2753 [D loss: 0.719190, acc.: 55.47%] [G loss: 0.991911]\n",
      "epoch:2 step:2754 [D loss: 0.689752, acc.: 55.47%] [G loss: 0.994989]\n",
      "epoch:2 step:2755 [D loss: 0.669188, acc.: 57.03%] [G loss: 0.959435]\n",
      "epoch:2 step:2756 [D loss: 0.648318, acc.: 59.38%] [G loss: 0.937364]\n",
      "epoch:2 step:2757 [D loss: 0.739333, acc.: 51.56%] [G loss: 0.906475]\n",
      "epoch:2 step:2758 [D loss: 0.712677, acc.: 50.00%] [G loss: 0.912381]\n",
      "epoch:2 step:2759 [D loss: 0.645252, acc.: 66.41%] [G loss: 1.141886]\n",
      "epoch:2 step:2760 [D loss: 0.607425, acc.: 71.09%] [G loss: 1.177796]\n",
      "epoch:2 step:2761 [D loss: 0.670497, acc.: 62.50%] [G loss: 0.990276]\n",
      "epoch:2 step:2762 [D loss: 0.652489, acc.: 64.06%] [G loss: 0.988017]\n",
      "epoch:2 step:2763 [D loss: 0.616201, acc.: 65.62%] [G loss: 1.023496]\n",
      "epoch:2 step:2764 [D loss: 0.601156, acc.: 71.09%] [G loss: 0.948270]\n",
      "epoch:2 step:2765 [D loss: 0.665468, acc.: 58.59%] [G loss: 1.012309]\n",
      "epoch:2 step:2766 [D loss: 0.780106, acc.: 47.66%] [G loss: 0.879346]\n",
      "epoch:2 step:2767 [D loss: 0.728159, acc.: 51.56%] [G loss: 0.872343]\n",
      "epoch:2 step:2768 [D loss: 0.670266, acc.: 58.59%] [G loss: 1.005497]\n",
      "epoch:2 step:2769 [D loss: 0.638639, acc.: 58.59%] [G loss: 0.986891]\n",
      "epoch:2 step:2770 [D loss: 0.633719, acc.: 63.28%] [G loss: 0.958156]\n",
      "epoch:2 step:2771 [D loss: 0.656184, acc.: 59.38%] [G loss: 0.958216]\n",
      "epoch:2 step:2772 [D loss: 0.615357, acc.: 67.19%] [G loss: 0.936404]\n",
      "epoch:2 step:2773 [D loss: 0.636602, acc.: 59.38%] [G loss: 1.039046]\n",
      "epoch:2 step:2774 [D loss: 0.642190, acc.: 64.84%] [G loss: 1.006938]\n",
      "epoch:2 step:2775 [D loss: 0.636358, acc.: 62.50%] [G loss: 1.013100]\n",
      "epoch:2 step:2776 [D loss: 0.658007, acc.: 67.19%] [G loss: 0.930291]\n",
      "epoch:2 step:2777 [D loss: 0.748916, acc.: 50.00%] [G loss: 0.911909]\n",
      "epoch:2 step:2778 [D loss: 0.696507, acc.: 60.16%] [G loss: 0.887169]\n",
      "epoch:2 step:2779 [D loss: 0.651567, acc.: 64.84%] [G loss: 0.866435]\n",
      "epoch:2 step:2780 [D loss: 0.665300, acc.: 62.50%] [G loss: 0.980837]\n",
      "epoch:2 step:2781 [D loss: 0.660003, acc.: 60.16%] [G loss: 0.982065]\n",
      "epoch:2 step:2782 [D loss: 0.638391, acc.: 65.62%] [G loss: 1.014943]\n",
      "epoch:2 step:2783 [D loss: 0.599417, acc.: 68.75%] [G loss: 0.962817]\n",
      "epoch:2 step:2784 [D loss: 0.626864, acc.: 64.06%] [G loss: 0.956312]\n",
      "epoch:2 step:2785 [D loss: 0.589956, acc.: 71.09%] [G loss: 0.932599]\n",
      "epoch:2 step:2786 [D loss: 0.543757, acc.: 76.56%] [G loss: 1.111205]\n",
      "epoch:2 step:2787 [D loss: 0.725799, acc.: 53.91%] [G loss: 0.916196]\n",
      "epoch:2 step:2788 [D loss: 0.628455, acc.: 64.84%] [G loss: 1.037398]\n",
      "epoch:2 step:2789 [D loss: 0.673835, acc.: 57.03%] [G loss: 0.915957]\n",
      "epoch:2 step:2790 [D loss: 0.630286, acc.: 66.41%] [G loss: 0.927271]\n",
      "epoch:2 step:2791 [D loss: 0.656625, acc.: 63.28%] [G loss: 0.894747]\n",
      "epoch:2 step:2792 [D loss: 0.582795, acc.: 72.66%] [G loss: 0.937783]\n",
      "epoch:2 step:2793 [D loss: 0.607596, acc.: 65.62%] [G loss: 1.028773]\n",
      "epoch:2 step:2794 [D loss: 0.789835, acc.: 46.09%] [G loss: 0.978585]\n",
      "epoch:2 step:2795 [D loss: 0.662336, acc.: 65.62%] [G loss: 0.891753]\n",
      "epoch:2 step:2796 [D loss: 0.559932, acc.: 75.78%] [G loss: 0.949522]\n",
      "epoch:2 step:2797 [D loss: 0.555040, acc.: 71.09%] [G loss: 1.029595]\n",
      "epoch:2 step:2798 [D loss: 0.527083, acc.: 77.34%] [G loss: 1.038051]\n",
      "epoch:2 step:2799 [D loss: 0.594709, acc.: 68.75%] [G loss: 1.071264]\n",
      "epoch:2 step:2800 [D loss: 0.611176, acc.: 64.06%] [G loss: 1.133755]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[1.73915856 0.87707445 4.89604535 3.88235959 2.35325785 4.6325913\n",
      " 3.39399288 3.96017303 3.57323912 2.49506118]\n",
      "##########\n",
      "epoch:2 step:2801 [D loss: 0.704610, acc.: 55.47%] [G loss: 0.959099]\n",
      "epoch:2 step:2802 [D loss: 0.911309, acc.: 48.44%] [G loss: 0.962674]\n",
      "epoch:2 step:2803 [D loss: 0.835638, acc.: 42.19%] [G loss: 0.830461]\n",
      "epoch:2 step:2804 [D loss: 0.582896, acc.: 64.84%] [G loss: 1.006129]\n",
      "epoch:2 step:2805 [D loss: 0.645163, acc.: 61.72%] [G loss: 1.007781]\n",
      "epoch:2 step:2806 [D loss: 0.597654, acc.: 64.84%] [G loss: 1.142122]\n",
      "epoch:2 step:2807 [D loss: 0.627781, acc.: 64.06%] [G loss: 0.929067]\n",
      "epoch:2 step:2808 [D loss: 0.697164, acc.: 53.12%] [G loss: 0.952934]\n",
      "epoch:2 step:2809 [D loss: 0.679610, acc.: 53.91%] [G loss: 0.912953]\n",
      "epoch:2 step:2810 [D loss: 0.590950, acc.: 66.41%] [G loss: 0.849753]\n",
      "epoch:2 step:2811 [D loss: 0.559774, acc.: 74.22%] [G loss: 1.199122]\n",
      "epoch:3 step:2812 [D loss: 0.699571, acc.: 60.16%] [G loss: 1.094037]\n",
      "epoch:3 step:2813 [D loss: 0.653193, acc.: 62.50%] [G loss: 1.105213]\n",
      "epoch:3 step:2814 [D loss: 0.751988, acc.: 53.12%] [G loss: 1.013891]\n",
      "epoch:3 step:2815 [D loss: 0.738538, acc.: 50.78%] [G loss: 0.878046]\n",
      "epoch:3 step:2816 [D loss: 0.623990, acc.: 66.41%] [G loss: 0.970754]\n",
      "epoch:3 step:2817 [D loss: 0.677348, acc.: 58.59%] [G loss: 0.989490]\n",
      "epoch:3 step:2818 [D loss: 0.682819, acc.: 57.03%] [G loss: 0.944367]\n",
      "epoch:3 step:2819 [D loss: 0.672855, acc.: 60.16%] [G loss: 1.051605]\n",
      "epoch:3 step:2820 [D loss: 0.683392, acc.: 60.16%] [G loss: 1.000207]\n",
      "epoch:3 step:2821 [D loss: 0.657083, acc.: 61.72%] [G loss: 0.981735]\n",
      "epoch:3 step:2822 [D loss: 0.623872, acc.: 65.62%] [G loss: 1.058017]\n",
      "epoch:3 step:2823 [D loss: 0.635378, acc.: 65.62%] [G loss: 1.013049]\n",
      "epoch:3 step:2824 [D loss: 0.643226, acc.: 64.84%] [G loss: 1.024229]\n",
      "epoch:3 step:2825 [D loss: 0.601072, acc.: 66.41%] [G loss: 1.033553]\n",
      "epoch:3 step:2826 [D loss: 0.552167, acc.: 67.97%] [G loss: 1.047768]\n",
      "epoch:3 step:2827 [D loss: 0.681568, acc.: 57.03%] [G loss: 1.036816]\n",
      "epoch:3 step:2828 [D loss: 0.739207, acc.: 50.78%] [G loss: 1.029933]\n",
      "epoch:3 step:2829 [D loss: 0.697338, acc.: 56.25%] [G loss: 0.926685]\n",
      "epoch:3 step:2830 [D loss: 0.658998, acc.: 64.06%] [G loss: 0.765753]\n",
      "epoch:3 step:2831 [D loss: 0.815300, acc.: 42.19%] [G loss: 0.891384]\n",
      "epoch:3 step:2832 [D loss: 0.647356, acc.: 62.50%] [G loss: 0.928520]\n",
      "epoch:3 step:2833 [D loss: 0.639340, acc.: 63.28%] [G loss: 0.854170]\n",
      "epoch:3 step:2834 [D loss: 0.659213, acc.: 61.72%] [G loss: 0.988888]\n",
      "epoch:3 step:2835 [D loss: 0.733403, acc.: 54.69%] [G loss: 1.031458]\n",
      "epoch:3 step:2836 [D loss: 0.618994, acc.: 65.62%] [G loss: 1.009240]\n",
      "epoch:3 step:2837 [D loss: 0.690016, acc.: 56.25%] [G loss: 0.856396]\n",
      "epoch:3 step:2838 [D loss: 0.650548, acc.: 65.62%] [G loss: 1.024065]\n",
      "epoch:3 step:2839 [D loss: 0.665468, acc.: 61.72%] [G loss: 0.953398]\n",
      "epoch:3 step:2840 [D loss: 0.675362, acc.: 60.94%] [G loss: 1.077858]\n",
      "epoch:3 step:2841 [D loss: 0.704808, acc.: 54.69%] [G loss: 0.955140]\n",
      "epoch:3 step:2842 [D loss: 0.710589, acc.: 50.78%] [G loss: 0.964067]\n",
      "epoch:3 step:2843 [D loss: 0.622175, acc.: 67.19%] [G loss: 0.969199]\n",
      "epoch:3 step:2844 [D loss: 0.651020, acc.: 64.84%] [G loss: 0.962740]\n",
      "epoch:3 step:2845 [D loss: 0.613486, acc.: 64.06%] [G loss: 1.129534]\n",
      "epoch:3 step:2846 [D loss: 0.651854, acc.: 60.94%] [G loss: 1.017300]\n",
      "epoch:3 step:2847 [D loss: 0.621153, acc.: 66.41%] [G loss: 0.984318]\n",
      "epoch:3 step:2848 [D loss: 0.664255, acc.: 55.47%] [G loss: 1.087568]\n",
      "epoch:3 step:2849 [D loss: 0.645072, acc.: 65.62%] [G loss: 1.013712]\n",
      "epoch:3 step:2850 [D loss: 0.708772, acc.: 53.12%] [G loss: 1.015359]\n",
      "epoch:3 step:2851 [D loss: 0.660461, acc.: 60.94%] [G loss: 0.934978]\n",
      "epoch:3 step:2852 [D loss: 0.695557, acc.: 57.03%] [G loss: 0.924477]\n",
      "epoch:3 step:2853 [D loss: 0.651162, acc.: 57.03%] [G loss: 0.999043]\n",
      "epoch:3 step:2854 [D loss: 0.753275, acc.: 51.56%] [G loss: 0.922187]\n",
      "epoch:3 step:2855 [D loss: 0.635651, acc.: 66.41%] [G loss: 1.080545]\n",
      "epoch:3 step:2856 [D loss: 0.809688, acc.: 45.31%] [G loss: 0.946547]\n",
      "epoch:3 step:2857 [D loss: 0.656160, acc.: 57.81%] [G loss: 0.899689]\n",
      "epoch:3 step:2858 [D loss: 0.670220, acc.: 60.16%] [G loss: 0.863633]\n",
      "epoch:3 step:2859 [D loss: 0.666651, acc.: 62.50%] [G loss: 0.937045]\n",
      "epoch:3 step:2860 [D loss: 0.660223, acc.: 57.81%] [G loss: 0.890104]\n",
      "epoch:3 step:2861 [D loss: 0.592760, acc.: 71.09%] [G loss: 1.003603]\n",
      "epoch:3 step:2862 [D loss: 0.720677, acc.: 50.00%] [G loss: 0.942578]\n",
      "epoch:3 step:2863 [D loss: 0.636801, acc.: 61.72%] [G loss: 0.883041]\n",
      "epoch:3 step:2864 [D loss: 0.632020, acc.: 64.06%] [G loss: 1.101155]\n",
      "epoch:3 step:2865 [D loss: 0.646648, acc.: 61.72%] [G loss: 1.052469]\n",
      "epoch:3 step:2866 [D loss: 0.614156, acc.: 66.41%] [G loss: 1.070004]\n",
      "epoch:3 step:2867 [D loss: 0.683847, acc.: 54.69%] [G loss: 0.979985]\n",
      "epoch:3 step:2868 [D loss: 0.710014, acc.: 58.59%] [G loss: 1.096992]\n",
      "epoch:3 step:2869 [D loss: 0.717831, acc.: 51.56%] [G loss: 0.998656]\n",
      "epoch:3 step:2870 [D loss: 0.676557, acc.: 54.69%] [G loss: 0.928865]\n",
      "epoch:3 step:2871 [D loss: 0.691510, acc.: 59.38%] [G loss: 0.901967]\n",
      "epoch:3 step:2872 [D loss: 0.654685, acc.: 60.16%] [G loss: 1.074929]\n",
      "epoch:3 step:2873 [D loss: 0.656998, acc.: 59.38%] [G loss: 1.138688]\n",
      "epoch:3 step:2874 [D loss: 0.636005, acc.: 63.28%] [G loss: 0.982211]\n",
      "epoch:3 step:2875 [D loss: 0.710618, acc.: 49.22%] [G loss: 0.858175]\n",
      "epoch:3 step:2876 [D loss: 0.661510, acc.: 63.28%] [G loss: 0.980050]\n",
      "epoch:3 step:2877 [D loss: 0.618606, acc.: 61.72%] [G loss: 0.953857]\n",
      "epoch:3 step:2878 [D loss: 0.687016, acc.: 55.47%] [G loss: 0.973931]\n",
      "epoch:3 step:2879 [D loss: 0.676075, acc.: 58.59%] [G loss: 0.954268]\n",
      "epoch:3 step:2880 [D loss: 0.702308, acc.: 53.91%] [G loss: 0.913093]\n",
      "epoch:3 step:2881 [D loss: 0.699220, acc.: 53.91%] [G loss: 0.865286]\n",
      "epoch:3 step:2882 [D loss: 0.635552, acc.: 63.28%] [G loss: 0.990341]\n",
      "epoch:3 step:2883 [D loss: 0.610718, acc.: 71.09%] [G loss: 1.056257]\n",
      "epoch:3 step:2884 [D loss: 0.669575, acc.: 65.62%] [G loss: 1.027979]\n",
      "epoch:3 step:2885 [D loss: 0.635776, acc.: 64.06%] [G loss: 0.949548]\n",
      "epoch:3 step:2886 [D loss: 0.634671, acc.: 68.75%] [G loss: 0.973608]\n",
      "epoch:3 step:2887 [D loss: 0.651046, acc.: 64.84%] [G loss: 1.203745]\n",
      "epoch:3 step:2888 [D loss: 0.599751, acc.: 67.19%] [G loss: 1.189752]\n",
      "epoch:3 step:2889 [D loss: 0.692307, acc.: 57.81%] [G loss: 1.117750]\n",
      "epoch:3 step:2890 [D loss: 0.663644, acc.: 59.38%] [G loss: 1.032911]\n",
      "epoch:3 step:2891 [D loss: 0.668676, acc.: 58.59%] [G loss: 0.915593]\n",
      "epoch:3 step:2892 [D loss: 0.740898, acc.: 53.12%] [G loss: 0.828384]\n",
      "epoch:3 step:2893 [D loss: 0.644573, acc.: 63.28%] [G loss: 0.892053]\n",
      "epoch:3 step:2894 [D loss: 0.641710, acc.: 64.06%] [G loss: 0.933569]\n",
      "epoch:3 step:2895 [D loss: 0.690161, acc.: 57.03%] [G loss: 0.971048]\n",
      "epoch:3 step:2896 [D loss: 0.730819, acc.: 53.91%] [G loss: 0.881989]\n",
      "epoch:3 step:2897 [D loss: 0.717620, acc.: 57.03%] [G loss: 0.999058]\n",
      "epoch:3 step:2898 [D loss: 0.701068, acc.: 51.56%] [G loss: 1.002444]\n",
      "epoch:3 step:2899 [D loss: 0.675770, acc.: 60.94%] [G loss: 0.906001]\n",
      "epoch:3 step:2900 [D loss: 0.675545, acc.: 58.59%] [G loss: 0.900452]\n",
      "epoch:3 step:2901 [D loss: 0.637275, acc.: 64.06%] [G loss: 0.875192]\n",
      "epoch:3 step:2902 [D loss: 0.655531, acc.: 64.84%] [G loss: 0.908429]\n",
      "epoch:3 step:2903 [D loss: 0.673454, acc.: 60.94%] [G loss: 1.002732]\n",
      "epoch:3 step:2904 [D loss: 0.611159, acc.: 64.06%] [G loss: 0.949196]\n",
      "epoch:3 step:2905 [D loss: 0.692985, acc.: 53.91%] [G loss: 1.096598]\n",
      "epoch:3 step:2906 [D loss: 0.688582, acc.: 54.69%] [G loss: 0.916104]\n",
      "epoch:3 step:2907 [D loss: 0.656098, acc.: 59.38%] [G loss: 0.942029]\n",
      "epoch:3 step:2908 [D loss: 0.679861, acc.: 56.25%] [G loss: 0.872316]\n",
      "epoch:3 step:2909 [D loss: 0.660698, acc.: 60.94%] [G loss: 0.982903]\n",
      "epoch:3 step:2910 [D loss: 0.673636, acc.: 60.94%] [G loss: 0.808338]\n",
      "epoch:3 step:2911 [D loss: 0.634814, acc.: 64.06%] [G loss: 0.854757]\n",
      "epoch:3 step:2912 [D loss: 0.649601, acc.: 60.16%] [G loss: 0.919834]\n",
      "epoch:3 step:2913 [D loss: 0.627431, acc.: 69.53%] [G loss: 1.061489]\n",
      "epoch:3 step:2914 [D loss: 0.612602, acc.: 67.19%] [G loss: 0.964787]\n",
      "epoch:3 step:2915 [D loss: 0.734249, acc.: 61.72%] [G loss: 1.073712]\n",
      "epoch:3 step:2916 [D loss: 0.666103, acc.: 64.06%] [G loss: 1.016679]\n",
      "epoch:3 step:2917 [D loss: 0.684058, acc.: 63.28%] [G loss: 0.949567]\n",
      "epoch:3 step:2918 [D loss: 0.706469, acc.: 54.69%] [G loss: 1.058671]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2919 [D loss: 0.740870, acc.: 48.44%] [G loss: 0.936963]\n",
      "epoch:3 step:2920 [D loss: 0.664400, acc.: 64.06%] [G loss: 1.030631]\n",
      "epoch:3 step:2921 [D loss: 0.698890, acc.: 60.94%] [G loss: 0.886617]\n",
      "epoch:3 step:2922 [D loss: 0.639662, acc.: 60.94%] [G loss: 0.902092]\n",
      "epoch:3 step:2923 [D loss: 0.684131, acc.: 59.38%] [G loss: 0.936095]\n",
      "epoch:3 step:2924 [D loss: 0.682994, acc.: 56.25%] [G loss: 0.952520]\n",
      "epoch:3 step:2925 [D loss: 0.717651, acc.: 53.12%] [G loss: 0.884155]\n",
      "epoch:3 step:2926 [D loss: 0.690608, acc.: 54.69%] [G loss: 0.886260]\n",
      "epoch:3 step:2927 [D loss: 0.640870, acc.: 64.06%] [G loss: 0.937060]\n",
      "epoch:3 step:2928 [D loss: 0.664926, acc.: 60.16%] [G loss: 0.884863]\n",
      "epoch:3 step:2929 [D loss: 0.596350, acc.: 67.97%] [G loss: 0.828704]\n",
      "epoch:3 step:2930 [D loss: 0.622289, acc.: 67.97%] [G loss: 0.965061]\n",
      "epoch:3 step:2931 [D loss: 0.790620, acc.: 43.75%] [G loss: 0.857618]\n",
      "epoch:3 step:2932 [D loss: 0.704924, acc.: 55.47%] [G loss: 0.898366]\n",
      "epoch:3 step:2933 [D loss: 0.686429, acc.: 59.38%] [G loss: 0.853618]\n",
      "epoch:3 step:2934 [D loss: 0.628669, acc.: 66.41%] [G loss: 1.021999]\n",
      "epoch:3 step:2935 [D loss: 0.684231, acc.: 61.72%] [G loss: 0.934926]\n",
      "epoch:3 step:2936 [D loss: 0.707089, acc.: 54.69%] [G loss: 0.978226]\n",
      "epoch:3 step:2937 [D loss: 0.724948, acc.: 46.88%] [G loss: 0.868064]\n",
      "epoch:3 step:2938 [D loss: 0.700707, acc.: 51.56%] [G loss: 0.928325]\n",
      "epoch:3 step:2939 [D loss: 0.717579, acc.: 60.16%] [G loss: 0.839887]\n",
      "epoch:3 step:2940 [D loss: 0.702922, acc.: 46.09%] [G loss: 0.962431]\n",
      "epoch:3 step:2941 [D loss: 0.670386, acc.: 57.81%] [G loss: 0.962686]\n",
      "epoch:3 step:2942 [D loss: 0.614081, acc.: 68.75%] [G loss: 0.958945]\n",
      "epoch:3 step:2943 [D loss: 0.686277, acc.: 56.25%] [G loss: 0.908623]\n",
      "epoch:3 step:2944 [D loss: 0.774952, acc.: 45.31%] [G loss: 0.857605]\n",
      "epoch:3 step:2945 [D loss: 0.634498, acc.: 62.50%] [G loss: 0.960546]\n",
      "epoch:3 step:2946 [D loss: 0.656582, acc.: 60.94%] [G loss: 0.908383]\n",
      "epoch:3 step:2947 [D loss: 0.693936, acc.: 51.56%] [G loss: 0.932464]\n",
      "epoch:3 step:2948 [D loss: 0.702858, acc.: 48.44%] [G loss: 0.971675]\n",
      "epoch:3 step:2949 [D loss: 0.635160, acc.: 64.84%] [G loss: 1.073192]\n",
      "epoch:3 step:2950 [D loss: 0.714968, acc.: 54.69%] [G loss: 0.922549]\n",
      "epoch:3 step:2951 [D loss: 0.704741, acc.: 56.25%] [G loss: 0.978984]\n",
      "epoch:3 step:2952 [D loss: 0.646872, acc.: 62.50%] [G loss: 1.042403]\n",
      "epoch:3 step:2953 [D loss: 0.614714, acc.: 67.19%] [G loss: 0.970455]\n",
      "epoch:3 step:2954 [D loss: 0.685433, acc.: 58.59%] [G loss: 0.944034]\n",
      "epoch:3 step:2955 [D loss: 0.646613, acc.: 62.50%] [G loss: 0.852951]\n",
      "epoch:3 step:2956 [D loss: 0.624182, acc.: 63.28%] [G loss: 0.979130]\n",
      "epoch:3 step:2957 [D loss: 0.629367, acc.: 66.41%] [G loss: 0.898845]\n",
      "epoch:3 step:2958 [D loss: 0.688986, acc.: 55.47%] [G loss: 0.955287]\n",
      "epoch:3 step:2959 [D loss: 0.657128, acc.: 63.28%] [G loss: 1.013454]\n",
      "epoch:3 step:2960 [D loss: 0.629834, acc.: 62.50%] [G loss: 0.952863]\n",
      "epoch:3 step:2961 [D loss: 0.651120, acc.: 64.06%] [G loss: 0.936313]\n",
      "epoch:3 step:2962 [D loss: 0.597919, acc.: 68.75%] [G loss: 1.107058]\n",
      "epoch:3 step:2963 [D loss: 0.662303, acc.: 59.38%] [G loss: 1.076169]\n",
      "epoch:3 step:2964 [D loss: 0.701250, acc.: 56.25%] [G loss: 0.984531]\n",
      "epoch:3 step:2965 [D loss: 0.616391, acc.: 69.53%] [G loss: 0.991337]\n",
      "epoch:3 step:2966 [D loss: 0.666039, acc.: 63.28%] [G loss: 0.954850]\n",
      "epoch:3 step:2967 [D loss: 0.662678, acc.: 66.41%] [G loss: 0.960507]\n",
      "epoch:3 step:2968 [D loss: 0.677356, acc.: 59.38%] [G loss: 0.916645]\n",
      "epoch:3 step:2969 [D loss: 0.716135, acc.: 54.69%] [G loss: 0.906728]\n",
      "epoch:3 step:2970 [D loss: 0.731945, acc.: 52.34%] [G loss: 0.947744]\n",
      "epoch:3 step:2971 [D loss: 0.790371, acc.: 44.53%] [G loss: 0.868121]\n",
      "epoch:3 step:2972 [D loss: 0.672656, acc.: 57.81%] [G loss: 0.918092]\n",
      "epoch:3 step:2973 [D loss: 0.668929, acc.: 56.25%] [G loss: 0.863746]\n",
      "epoch:3 step:2974 [D loss: 0.627048, acc.: 64.84%] [G loss: 0.916716]\n",
      "epoch:3 step:2975 [D loss: 0.643664, acc.: 61.72%] [G loss: 0.849629]\n",
      "epoch:3 step:2976 [D loss: 0.635887, acc.: 70.31%] [G loss: 0.928400]\n",
      "epoch:3 step:2977 [D loss: 0.659707, acc.: 62.50%] [G loss: 0.938173]\n",
      "epoch:3 step:2978 [D loss: 0.768378, acc.: 47.66%] [G loss: 0.921589]\n",
      "epoch:3 step:2979 [D loss: 0.647041, acc.: 66.41%] [G loss: 1.026845]\n",
      "epoch:3 step:2980 [D loss: 0.659957, acc.: 62.50%] [G loss: 0.972302]\n",
      "epoch:3 step:2981 [D loss: 0.725465, acc.: 53.12%] [G loss: 1.004674]\n",
      "epoch:3 step:2982 [D loss: 0.604416, acc.: 65.62%] [G loss: 1.023615]\n",
      "epoch:3 step:2983 [D loss: 0.668441, acc.: 57.81%] [G loss: 0.827197]\n",
      "epoch:3 step:2984 [D loss: 0.655656, acc.: 56.25%] [G loss: 0.928105]\n",
      "epoch:3 step:2985 [D loss: 0.667242, acc.: 58.59%] [G loss: 0.919732]\n",
      "epoch:3 step:2986 [D loss: 0.689404, acc.: 61.72%] [G loss: 0.909426]\n",
      "epoch:3 step:2987 [D loss: 0.661226, acc.: 57.81%] [G loss: 0.966414]\n",
      "epoch:3 step:2988 [D loss: 0.691500, acc.: 54.69%] [G loss: 0.886135]\n",
      "epoch:3 step:2989 [D loss: 0.743577, acc.: 53.91%] [G loss: 0.964847]\n",
      "epoch:3 step:2990 [D loss: 0.696907, acc.: 54.69%] [G loss: 0.952546]\n",
      "epoch:3 step:2991 [D loss: 0.741575, acc.: 50.00%] [G loss: 0.947969]\n",
      "epoch:3 step:2992 [D loss: 0.672168, acc.: 64.06%] [G loss: 0.909271]\n",
      "epoch:3 step:2993 [D loss: 0.719772, acc.: 57.03%] [G loss: 0.955421]\n",
      "epoch:3 step:2994 [D loss: 0.691867, acc.: 58.59%] [G loss: 0.990834]\n",
      "epoch:3 step:2995 [D loss: 0.699500, acc.: 56.25%] [G loss: 0.885925]\n",
      "epoch:3 step:2996 [D loss: 0.675338, acc.: 57.81%] [G loss: 0.931512]\n",
      "epoch:3 step:2997 [D loss: 0.658152, acc.: 62.50%] [G loss: 0.925046]\n",
      "epoch:3 step:2998 [D loss: 0.696042, acc.: 54.69%] [G loss: 0.847508]\n",
      "epoch:3 step:2999 [D loss: 0.669749, acc.: 62.50%] [G loss: 0.970581]\n",
      "epoch:3 step:3000 [D loss: 0.701072, acc.: 57.81%] [G loss: 0.891374]\n",
      "##############\n",
      "[1.75662646 0.65139612 5.19809147 3.77007116 2.27848217 4.82347971\n",
      " 3.58360132 3.93885196 3.46841352 2.79252601]\n",
      "##########\n",
      "epoch:3 step:3001 [D loss: 0.610368, acc.: 61.72%] [G loss: 0.945537]\n",
      "epoch:3 step:3002 [D loss: 0.706476, acc.: 58.59%] [G loss: 0.990870]\n",
      "epoch:3 step:3003 [D loss: 0.617300, acc.: 66.41%] [G loss: 1.025126]\n",
      "epoch:3 step:3004 [D loss: 0.717017, acc.: 55.47%] [G loss: 0.915678]\n",
      "epoch:3 step:3005 [D loss: 0.613318, acc.: 69.53%] [G loss: 1.008849]\n",
      "epoch:3 step:3006 [D loss: 0.665149, acc.: 67.19%] [G loss: 1.078888]\n",
      "epoch:3 step:3007 [D loss: 0.749461, acc.: 48.44%] [G loss: 0.972448]\n",
      "epoch:3 step:3008 [D loss: 0.656715, acc.: 60.16%] [G loss: 0.943786]\n",
      "epoch:3 step:3009 [D loss: 0.624589, acc.: 63.28%] [G loss: 1.010581]\n",
      "epoch:3 step:3010 [D loss: 0.675080, acc.: 57.81%] [G loss: 0.862087]\n",
      "epoch:3 step:3011 [D loss: 0.736411, acc.: 50.00%] [G loss: 1.019023]\n",
      "epoch:3 step:3012 [D loss: 0.671313, acc.: 62.50%] [G loss: 0.964744]\n",
      "epoch:3 step:3013 [D loss: 0.674468, acc.: 63.28%] [G loss: 0.916349]\n",
      "epoch:3 step:3014 [D loss: 0.736267, acc.: 48.44%] [G loss: 0.887542]\n",
      "epoch:3 step:3015 [D loss: 0.644259, acc.: 61.72%] [G loss: 0.920889]\n",
      "epoch:3 step:3016 [D loss: 0.682337, acc.: 60.16%] [G loss: 0.892924]\n",
      "epoch:3 step:3017 [D loss: 0.637573, acc.: 60.94%] [G loss: 0.989891]\n",
      "epoch:3 step:3018 [D loss: 0.584608, acc.: 69.53%] [G loss: 1.001635]\n",
      "epoch:3 step:3019 [D loss: 0.569190, acc.: 68.75%] [G loss: 1.018054]\n",
      "epoch:3 step:3020 [D loss: 0.537820, acc.: 76.56%] [G loss: 1.087780]\n",
      "epoch:3 step:3021 [D loss: 0.723424, acc.: 55.47%] [G loss: 0.975277]\n",
      "epoch:3 step:3022 [D loss: 0.710570, acc.: 53.12%] [G loss: 0.961827]\n",
      "epoch:3 step:3023 [D loss: 0.714061, acc.: 54.69%] [G loss: 0.864060]\n",
      "epoch:3 step:3024 [D loss: 0.683601, acc.: 55.47%] [G loss: 0.862925]\n",
      "epoch:3 step:3025 [D loss: 0.734761, acc.: 48.44%] [G loss: 0.962892]\n",
      "epoch:3 step:3026 [D loss: 0.673454, acc.: 57.03%] [G loss: 0.901329]\n",
      "epoch:3 step:3027 [D loss: 0.637530, acc.: 64.06%] [G loss: 0.876814]\n",
      "epoch:3 step:3028 [D loss: 0.671293, acc.: 56.25%] [G loss: 1.008530]\n",
      "epoch:3 step:3029 [D loss: 0.607863, acc.: 66.41%] [G loss: 0.968498]\n",
      "epoch:3 step:3030 [D loss: 0.632318, acc.: 64.06%] [G loss: 0.987568]\n",
      "epoch:3 step:3031 [D loss: 0.816039, acc.: 43.75%] [G loss: 0.864662]\n",
      "epoch:3 step:3032 [D loss: 0.723832, acc.: 53.12%] [G loss: 0.914623]\n",
      "epoch:3 step:3033 [D loss: 0.669682, acc.: 60.16%] [G loss: 1.027588]\n",
      "epoch:3 step:3034 [D loss: 0.650964, acc.: 56.25%] [G loss: 1.045342]\n",
      "epoch:3 step:3035 [D loss: 0.639870, acc.: 61.72%] [G loss: 0.995222]\n",
      "epoch:3 step:3036 [D loss: 0.674419, acc.: 57.03%] [G loss: 0.892681]\n",
      "epoch:3 step:3037 [D loss: 0.614233, acc.: 64.84%] [G loss: 1.054781]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3038 [D loss: 0.745189, acc.: 53.91%] [G loss: 0.919998]\n",
      "epoch:3 step:3039 [D loss: 0.676970, acc.: 57.81%] [G loss: 1.087396]\n",
      "epoch:3 step:3040 [D loss: 0.671192, acc.: 57.03%] [G loss: 0.809788]\n",
      "epoch:3 step:3041 [D loss: 0.624961, acc.: 63.28%] [G loss: 0.998679]\n",
      "epoch:3 step:3042 [D loss: 0.615456, acc.: 67.19%] [G loss: 1.037466]\n",
      "epoch:3 step:3043 [D loss: 0.550191, acc.: 74.22%] [G loss: 1.077743]\n",
      "epoch:3 step:3044 [D loss: 0.783708, acc.: 53.12%] [G loss: 0.980184]\n",
      "epoch:3 step:3045 [D loss: 0.670241, acc.: 64.84%] [G loss: 1.020514]\n",
      "epoch:3 step:3046 [D loss: 0.661994, acc.: 53.12%] [G loss: 0.976776]\n",
      "epoch:3 step:3047 [D loss: 0.637151, acc.: 63.28%] [G loss: 0.995280]\n",
      "epoch:3 step:3048 [D loss: 0.695192, acc.: 57.03%] [G loss: 1.139850]\n",
      "epoch:3 step:3049 [D loss: 0.679276, acc.: 57.81%] [G loss: 0.980601]\n",
      "epoch:3 step:3050 [D loss: 0.650068, acc.: 65.62%] [G loss: 0.957330]\n",
      "epoch:3 step:3051 [D loss: 0.680162, acc.: 62.50%] [G loss: 0.875611]\n",
      "epoch:3 step:3052 [D loss: 0.694883, acc.: 53.91%] [G loss: 1.048965]\n",
      "epoch:3 step:3053 [D loss: 0.753160, acc.: 50.00%] [G loss: 0.879837]\n",
      "epoch:3 step:3054 [D loss: 0.649849, acc.: 62.50%] [G loss: 0.886048]\n",
      "epoch:3 step:3055 [D loss: 0.672307, acc.: 58.59%] [G loss: 0.887988]\n",
      "epoch:3 step:3056 [D loss: 0.664004, acc.: 54.69%] [G loss: 0.915222]\n",
      "epoch:3 step:3057 [D loss: 0.686598, acc.: 57.81%] [G loss: 0.895396]\n",
      "epoch:3 step:3058 [D loss: 0.685117, acc.: 55.47%] [G loss: 0.869451]\n",
      "epoch:3 step:3059 [D loss: 0.621182, acc.: 66.41%] [G loss: 0.949831]\n",
      "epoch:3 step:3060 [D loss: 0.735016, acc.: 53.91%] [G loss: 0.852540]\n",
      "epoch:3 step:3061 [D loss: 0.737224, acc.: 50.78%] [G loss: 0.894444]\n",
      "epoch:3 step:3062 [D loss: 0.717929, acc.: 51.56%] [G loss: 0.841349]\n",
      "epoch:3 step:3063 [D loss: 0.651346, acc.: 60.94%] [G loss: 0.998992]\n",
      "epoch:3 step:3064 [D loss: 0.653929, acc.: 63.28%] [G loss: 0.992623]\n",
      "epoch:3 step:3065 [D loss: 0.630847, acc.: 61.72%] [G loss: 0.979658]\n",
      "epoch:3 step:3066 [D loss: 0.613269, acc.: 67.19%] [G loss: 0.944118]\n",
      "epoch:3 step:3067 [D loss: 0.655864, acc.: 64.06%] [G loss: 0.914385]\n",
      "epoch:3 step:3068 [D loss: 0.688318, acc.: 58.59%] [G loss: 0.983065]\n",
      "epoch:3 step:3069 [D loss: 0.677350, acc.: 60.16%] [G loss: 0.922934]\n",
      "epoch:3 step:3070 [D loss: 0.610963, acc.: 68.75%] [G loss: 0.969521]\n",
      "epoch:3 step:3071 [D loss: 0.712034, acc.: 58.59%] [G loss: 0.964843]\n",
      "epoch:3 step:3072 [D loss: 0.681777, acc.: 61.72%] [G loss: 1.050434]\n",
      "epoch:3 step:3073 [D loss: 0.733013, acc.: 57.81%] [G loss: 1.007582]\n",
      "epoch:3 step:3074 [D loss: 0.821062, acc.: 41.41%] [G loss: 0.883217]\n",
      "epoch:3 step:3075 [D loss: 0.697491, acc.: 57.03%] [G loss: 0.938383]\n",
      "epoch:3 step:3076 [D loss: 0.709090, acc.: 53.91%] [G loss: 1.001381]\n",
      "epoch:3 step:3077 [D loss: 0.726724, acc.: 46.09%] [G loss: 0.939839]\n",
      "epoch:3 step:3078 [D loss: 0.667139, acc.: 66.41%] [G loss: 1.006451]\n",
      "epoch:3 step:3079 [D loss: 0.607525, acc.: 64.84%] [G loss: 0.932789]\n",
      "epoch:3 step:3080 [D loss: 0.696870, acc.: 50.00%] [G loss: 1.032469]\n",
      "epoch:3 step:3081 [D loss: 0.664597, acc.: 57.03%] [G loss: 0.933976]\n",
      "epoch:3 step:3082 [D loss: 0.712756, acc.: 54.69%] [G loss: 0.849854]\n",
      "epoch:3 step:3083 [D loss: 0.675352, acc.: 57.03%] [G loss: 0.963343]\n",
      "epoch:3 step:3084 [D loss: 0.670280, acc.: 60.16%] [G loss: 0.930846]\n",
      "epoch:3 step:3085 [D loss: 0.657382, acc.: 61.72%] [G loss: 0.876138]\n",
      "epoch:3 step:3086 [D loss: 0.706417, acc.: 59.38%] [G loss: 0.937377]\n",
      "epoch:3 step:3087 [D loss: 0.659666, acc.: 57.03%] [G loss: 0.999144]\n",
      "epoch:3 step:3088 [D loss: 0.717140, acc.: 54.69%] [G loss: 0.888137]\n",
      "epoch:3 step:3089 [D loss: 0.676092, acc.: 62.50%] [G loss: 0.979972]\n",
      "epoch:3 step:3090 [D loss: 0.667355, acc.: 61.72%] [G loss: 0.834560]\n",
      "epoch:3 step:3091 [D loss: 0.734347, acc.: 50.78%] [G loss: 0.930800]\n",
      "epoch:3 step:3092 [D loss: 0.730280, acc.: 47.66%] [G loss: 0.957635]\n",
      "epoch:3 step:3093 [D loss: 0.614132, acc.: 65.62%] [G loss: 0.941116]\n",
      "epoch:3 step:3094 [D loss: 0.639354, acc.: 65.62%] [G loss: 0.986025]\n",
      "epoch:3 step:3095 [D loss: 0.672904, acc.: 62.50%] [G loss: 0.976955]\n",
      "epoch:3 step:3096 [D loss: 0.619272, acc.: 65.62%] [G loss: 1.023004]\n",
      "epoch:3 step:3097 [D loss: 0.661368, acc.: 62.50%] [G loss: 0.955836]\n",
      "epoch:3 step:3098 [D loss: 0.679117, acc.: 57.03%] [G loss: 0.941309]\n",
      "epoch:3 step:3099 [D loss: 0.722942, acc.: 50.00%] [G loss: 0.873321]\n",
      "epoch:3 step:3100 [D loss: 0.621277, acc.: 64.84%] [G loss: 0.899286]\n",
      "epoch:3 step:3101 [D loss: 0.704548, acc.: 57.03%] [G loss: 0.859453]\n",
      "epoch:3 step:3102 [D loss: 0.745298, acc.: 46.88%] [G loss: 0.884387]\n",
      "epoch:3 step:3103 [D loss: 0.636970, acc.: 62.50%] [G loss: 1.039511]\n",
      "epoch:3 step:3104 [D loss: 0.677529, acc.: 59.38%] [G loss: 1.000594]\n",
      "epoch:3 step:3105 [D loss: 0.654806, acc.: 60.16%] [G loss: 1.019115]\n",
      "epoch:3 step:3106 [D loss: 0.683375, acc.: 53.91%] [G loss: 1.029390]\n",
      "epoch:3 step:3107 [D loss: 0.647920, acc.: 61.72%] [G loss: 1.069097]\n",
      "epoch:3 step:3108 [D loss: 0.708026, acc.: 53.91%] [G loss: 0.943574]\n",
      "epoch:3 step:3109 [D loss: 0.672874, acc.: 54.69%] [G loss: 0.894927]\n",
      "epoch:3 step:3110 [D loss: 0.652670, acc.: 60.94%] [G loss: 0.984353]\n",
      "epoch:3 step:3111 [D loss: 0.690626, acc.: 64.84%] [G loss: 0.970891]\n",
      "epoch:3 step:3112 [D loss: 0.640191, acc.: 67.19%] [G loss: 0.870011]\n",
      "epoch:3 step:3113 [D loss: 0.629216, acc.: 67.19%] [G loss: 0.943996]\n",
      "epoch:3 step:3114 [D loss: 0.699849, acc.: 54.69%] [G loss: 0.921626]\n",
      "epoch:3 step:3115 [D loss: 0.698788, acc.: 56.25%] [G loss: 0.871288]\n",
      "epoch:3 step:3116 [D loss: 0.744118, acc.: 49.22%] [G loss: 0.948928]\n",
      "epoch:3 step:3117 [D loss: 0.699589, acc.: 55.47%] [G loss: 0.946367]\n",
      "epoch:3 step:3118 [D loss: 0.615637, acc.: 67.97%] [G loss: 1.053164]\n",
      "epoch:3 step:3119 [D loss: 0.732410, acc.: 51.56%] [G loss: 0.992505]\n",
      "epoch:3 step:3120 [D loss: 0.639926, acc.: 58.59%] [G loss: 0.927971]\n",
      "epoch:3 step:3121 [D loss: 0.654854, acc.: 60.16%] [G loss: 0.996080]\n",
      "epoch:3 step:3122 [D loss: 0.697644, acc.: 59.38%] [G loss: 0.990321]\n",
      "epoch:3 step:3123 [D loss: 0.706618, acc.: 53.91%] [G loss: 0.937310]\n",
      "epoch:3 step:3124 [D loss: 0.613924, acc.: 67.19%] [G loss: 0.941378]\n",
      "epoch:3 step:3125 [D loss: 0.609823, acc.: 69.53%] [G loss: 1.001060]\n",
      "epoch:3 step:3126 [D loss: 0.573259, acc.: 69.53%] [G loss: 1.028017]\n",
      "epoch:3 step:3127 [D loss: 0.733726, acc.: 48.44%] [G loss: 0.980704]\n",
      "epoch:3 step:3128 [D loss: 0.719678, acc.: 51.56%] [G loss: 1.046040]\n",
      "epoch:3 step:3129 [D loss: 0.617101, acc.: 69.53%] [G loss: 1.026332]\n",
      "epoch:3 step:3130 [D loss: 0.661162, acc.: 56.25%] [G loss: 0.927457]\n",
      "epoch:3 step:3131 [D loss: 0.648753, acc.: 61.72%] [G loss: 1.066105]\n",
      "epoch:3 step:3132 [D loss: 0.643402, acc.: 61.72%] [G loss: 0.952178]\n",
      "epoch:3 step:3133 [D loss: 0.647956, acc.: 60.94%] [G loss: 0.962969]\n",
      "epoch:3 step:3134 [D loss: 0.679529, acc.: 60.16%] [G loss: 0.910378]\n",
      "epoch:3 step:3135 [D loss: 0.675068, acc.: 60.94%] [G loss: 0.923075]\n",
      "epoch:3 step:3136 [D loss: 0.718986, acc.: 49.22%] [G loss: 0.910767]\n",
      "epoch:3 step:3137 [D loss: 0.723473, acc.: 53.12%] [G loss: 0.923844]\n",
      "epoch:3 step:3138 [D loss: 0.651572, acc.: 64.06%] [G loss: 0.894825]\n",
      "epoch:3 step:3139 [D loss: 0.637178, acc.: 57.81%] [G loss: 0.949889]\n",
      "epoch:3 step:3140 [D loss: 0.647323, acc.: 61.72%] [G loss: 0.856402]\n",
      "epoch:3 step:3141 [D loss: 0.677457, acc.: 61.72%] [G loss: 0.941297]\n",
      "epoch:3 step:3142 [D loss: 0.634880, acc.: 60.16%] [G loss: 0.861963]\n",
      "epoch:3 step:3143 [D loss: 0.629345, acc.: 64.84%] [G loss: 0.894887]\n",
      "epoch:3 step:3144 [D loss: 0.623302, acc.: 68.75%] [G loss: 0.881763]\n",
      "epoch:3 step:3145 [D loss: 0.637791, acc.: 57.81%] [G loss: 1.043475]\n",
      "epoch:3 step:3146 [D loss: 0.634394, acc.: 64.84%] [G loss: 1.054004]\n",
      "epoch:3 step:3147 [D loss: 0.620075, acc.: 67.19%] [G loss: 0.945548]\n",
      "epoch:3 step:3148 [D loss: 0.602785, acc.: 67.97%] [G loss: 0.908121]\n",
      "epoch:3 step:3149 [D loss: 0.649251, acc.: 60.16%] [G loss: 0.965405]\n",
      "epoch:3 step:3150 [D loss: 0.622278, acc.: 60.94%] [G loss: 0.943661]\n",
      "epoch:3 step:3151 [D loss: 0.643113, acc.: 60.16%] [G loss: 0.997487]\n",
      "epoch:3 step:3152 [D loss: 0.673150, acc.: 56.25%] [G loss: 0.937692]\n",
      "epoch:3 step:3153 [D loss: 0.707752, acc.: 53.12%] [G loss: 0.919375]\n",
      "epoch:3 step:3154 [D loss: 0.676751, acc.: 55.47%] [G loss: 0.851719]\n",
      "epoch:3 step:3155 [D loss: 0.625899, acc.: 61.72%] [G loss: 1.001867]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3156 [D loss: 0.669019, acc.: 56.25%] [G loss: 1.091097]\n",
      "epoch:3 step:3157 [D loss: 0.651461, acc.: 63.28%] [G loss: 0.956452]\n",
      "epoch:3 step:3158 [D loss: 0.764301, acc.: 50.00%] [G loss: 0.861658]\n",
      "epoch:3 step:3159 [D loss: 0.691104, acc.: 56.25%] [G loss: 0.972267]\n",
      "epoch:3 step:3160 [D loss: 0.753845, acc.: 48.44%] [G loss: 0.872980]\n",
      "epoch:3 step:3161 [D loss: 0.670721, acc.: 60.16%] [G loss: 1.013013]\n",
      "epoch:3 step:3162 [D loss: 0.730982, acc.: 53.91%] [G loss: 0.868575]\n",
      "epoch:3 step:3163 [D loss: 0.645053, acc.: 62.50%] [G loss: 1.097373]\n",
      "epoch:3 step:3164 [D loss: 0.646030, acc.: 64.06%] [G loss: 0.979218]\n",
      "epoch:3 step:3165 [D loss: 0.631428, acc.: 67.19%] [G loss: 1.077511]\n",
      "epoch:3 step:3166 [D loss: 0.626020, acc.: 68.75%] [G loss: 1.019714]\n",
      "epoch:3 step:3167 [D loss: 0.598371, acc.: 71.09%] [G loss: 1.011115]\n",
      "epoch:3 step:3168 [D loss: 0.667758, acc.: 64.84%] [G loss: 0.927780]\n",
      "epoch:3 step:3169 [D loss: 0.680383, acc.: 56.25%] [G loss: 1.048973]\n",
      "epoch:3 step:3170 [D loss: 0.578473, acc.: 72.66%] [G loss: 1.026583]\n",
      "epoch:3 step:3171 [D loss: 0.659760, acc.: 60.16%] [G loss: 1.005605]\n",
      "epoch:3 step:3172 [D loss: 0.734315, acc.: 60.94%] [G loss: 0.919010]\n",
      "epoch:3 step:3173 [D loss: 0.634903, acc.: 60.16%] [G loss: 1.018261]\n",
      "epoch:3 step:3174 [D loss: 0.676575, acc.: 62.50%] [G loss: 0.947568]\n",
      "epoch:3 step:3175 [D loss: 0.609715, acc.: 64.84%] [G loss: 0.965329]\n",
      "epoch:3 step:3176 [D loss: 0.672724, acc.: 60.94%] [G loss: 1.101180]\n",
      "epoch:3 step:3177 [D loss: 0.663804, acc.: 60.94%] [G loss: 0.951586]\n",
      "epoch:3 step:3178 [D loss: 0.657113, acc.: 64.06%] [G loss: 0.975712]\n",
      "epoch:3 step:3179 [D loss: 0.659870, acc.: 59.38%] [G loss: 0.937559]\n",
      "epoch:3 step:3180 [D loss: 0.694913, acc.: 62.50%] [G loss: 0.939557]\n",
      "epoch:3 step:3181 [D loss: 0.629394, acc.: 69.53%] [G loss: 1.052500]\n",
      "epoch:3 step:3182 [D loss: 0.651144, acc.: 67.19%] [G loss: 1.026923]\n",
      "epoch:3 step:3183 [D loss: 0.670935, acc.: 60.16%] [G loss: 0.947053]\n",
      "epoch:3 step:3184 [D loss: 0.708514, acc.: 50.00%] [G loss: 0.977797]\n",
      "epoch:3 step:3185 [D loss: 0.711568, acc.: 53.91%] [G loss: 0.932246]\n",
      "epoch:3 step:3186 [D loss: 0.613063, acc.: 68.75%] [G loss: 0.998467]\n",
      "epoch:3 step:3187 [D loss: 0.755246, acc.: 41.41%] [G loss: 0.937696]\n",
      "epoch:3 step:3188 [D loss: 0.752287, acc.: 48.44%] [G loss: 0.885073]\n",
      "epoch:3 step:3189 [D loss: 0.666367, acc.: 64.84%] [G loss: 0.955207]\n",
      "epoch:3 step:3190 [D loss: 0.669822, acc.: 60.94%] [G loss: 0.997540]\n",
      "epoch:3 step:3191 [D loss: 0.616122, acc.: 68.75%] [G loss: 1.063896]\n",
      "epoch:3 step:3192 [D loss: 0.699141, acc.: 50.78%] [G loss: 0.973882]\n",
      "epoch:3 step:3193 [D loss: 0.662456, acc.: 61.72%] [G loss: 1.052306]\n",
      "epoch:3 step:3194 [D loss: 0.686487, acc.: 60.94%] [G loss: 1.008631]\n",
      "epoch:3 step:3195 [D loss: 0.650397, acc.: 60.94%] [G loss: 0.979773]\n",
      "epoch:3 step:3196 [D loss: 0.664701, acc.: 58.59%] [G loss: 0.935233]\n",
      "epoch:3 step:3197 [D loss: 0.739560, acc.: 51.56%] [G loss: 0.967172]\n",
      "epoch:3 step:3198 [D loss: 0.638368, acc.: 57.81%] [G loss: 1.032655]\n",
      "epoch:3 step:3199 [D loss: 0.662522, acc.: 60.94%] [G loss: 0.980539]\n",
      "epoch:3 step:3200 [D loss: 0.672372, acc.: 57.81%] [G loss: 0.946065]\n",
      "##############\n",
      "[2.02045965 0.74401563 5.06829296 4.08206561 2.50323939 4.7547417\n",
      " 3.32339424 4.03819789 3.61252552 2.81883752]\n",
      "##########\n",
      "epoch:3 step:3201 [D loss: 0.668540, acc.: 64.06%] [G loss: 1.022468]\n",
      "epoch:3 step:3202 [D loss: 0.670334, acc.: 61.72%] [G loss: 0.810267]\n",
      "epoch:3 step:3203 [D loss: 0.664090, acc.: 58.59%] [G loss: 0.953567]\n",
      "epoch:3 step:3204 [D loss: 0.647498, acc.: 62.50%] [G loss: 0.918303]\n",
      "epoch:3 step:3205 [D loss: 0.690709, acc.: 57.81%] [G loss: 0.948179]\n",
      "epoch:3 step:3206 [D loss: 0.657636, acc.: 59.38%] [G loss: 0.808103]\n",
      "epoch:3 step:3207 [D loss: 0.709721, acc.: 50.00%] [G loss: 0.998901]\n",
      "epoch:3 step:3208 [D loss: 0.677942, acc.: 59.38%] [G loss: 0.991572]\n",
      "epoch:3 step:3209 [D loss: 0.682518, acc.: 59.38%] [G loss: 0.982209]\n",
      "epoch:3 step:3210 [D loss: 0.646235, acc.: 60.94%] [G loss: 0.970207]\n",
      "epoch:3 step:3211 [D loss: 0.745399, acc.: 48.44%] [G loss: 0.970595]\n",
      "epoch:3 step:3212 [D loss: 0.598417, acc.: 69.53%] [G loss: 1.085135]\n",
      "epoch:3 step:3213 [D loss: 0.750298, acc.: 55.47%] [G loss: 0.890757]\n",
      "epoch:3 step:3214 [D loss: 0.631202, acc.: 67.97%] [G loss: 1.033285]\n",
      "epoch:3 step:3215 [D loss: 0.675969, acc.: 57.03%] [G loss: 0.917338]\n",
      "epoch:3 step:3216 [D loss: 0.702590, acc.: 53.12%] [G loss: 1.036283]\n",
      "epoch:3 step:3217 [D loss: 0.589055, acc.: 70.31%] [G loss: 1.127470]\n",
      "epoch:3 step:3218 [D loss: 0.688794, acc.: 55.47%] [G loss: 1.030667]\n",
      "epoch:3 step:3219 [D loss: 0.661372, acc.: 59.38%] [G loss: 0.949652]\n",
      "epoch:3 step:3220 [D loss: 0.569902, acc.: 69.53%] [G loss: 1.103849]\n",
      "epoch:3 step:3221 [D loss: 0.691483, acc.: 57.81%] [G loss: 0.877816]\n",
      "epoch:3 step:3222 [D loss: 0.604710, acc.: 72.66%] [G loss: 0.966257]\n",
      "epoch:3 step:3223 [D loss: 0.665461, acc.: 62.50%] [G loss: 1.035463]\n",
      "epoch:3 step:3224 [D loss: 0.660309, acc.: 53.91%] [G loss: 0.967391]\n",
      "epoch:3 step:3225 [D loss: 0.658269, acc.: 56.25%] [G loss: 0.884106]\n",
      "epoch:3 step:3226 [D loss: 0.652801, acc.: 64.84%] [G loss: 0.891323]\n",
      "epoch:3 step:3227 [D loss: 0.695911, acc.: 55.47%] [G loss: 0.930935]\n",
      "epoch:3 step:3228 [D loss: 0.690559, acc.: 57.81%] [G loss: 1.037772]\n",
      "epoch:3 step:3229 [D loss: 0.696001, acc.: 61.72%] [G loss: 0.976161]\n",
      "epoch:3 step:3230 [D loss: 0.570184, acc.: 71.09%] [G loss: 1.046255]\n",
      "epoch:3 step:3231 [D loss: 0.594440, acc.: 65.62%] [G loss: 0.991392]\n",
      "epoch:3 step:3232 [D loss: 0.768995, acc.: 47.66%] [G loss: 0.827263]\n",
      "epoch:3 step:3233 [D loss: 0.701021, acc.: 53.91%] [G loss: 0.932154]\n",
      "epoch:3 step:3234 [D loss: 0.710170, acc.: 51.56%] [G loss: 0.850005]\n",
      "epoch:3 step:3235 [D loss: 0.689091, acc.: 57.03%] [G loss: 0.889162]\n",
      "epoch:3 step:3236 [D loss: 0.794813, acc.: 42.19%] [G loss: 0.877159]\n",
      "epoch:3 step:3237 [D loss: 0.698992, acc.: 57.81%] [G loss: 0.927191]\n",
      "epoch:3 step:3238 [D loss: 0.671223, acc.: 57.81%] [G loss: 0.905317]\n",
      "epoch:3 step:3239 [D loss: 0.616128, acc.: 68.75%] [G loss: 0.982690]\n",
      "epoch:3 step:3240 [D loss: 0.599141, acc.: 68.75%] [G loss: 1.009163]\n",
      "epoch:3 step:3241 [D loss: 0.589744, acc.: 67.19%] [G loss: 1.099605]\n",
      "epoch:3 step:3242 [D loss: 0.716995, acc.: 54.69%] [G loss: 0.848719]\n",
      "epoch:3 step:3243 [D loss: 0.678689, acc.: 59.38%] [G loss: 0.954555]\n",
      "epoch:3 step:3244 [D loss: 0.644782, acc.: 59.38%] [G loss: 0.956795]\n",
      "epoch:3 step:3245 [D loss: 0.615655, acc.: 64.84%] [G loss: 0.946369]\n",
      "epoch:3 step:3246 [D loss: 0.629796, acc.: 64.06%] [G loss: 0.970536]\n",
      "epoch:3 step:3247 [D loss: 0.708781, acc.: 55.47%] [G loss: 0.980761]\n",
      "epoch:3 step:3248 [D loss: 0.775060, acc.: 48.44%] [G loss: 0.841499]\n",
      "epoch:3 step:3249 [D loss: 0.683614, acc.: 53.12%] [G loss: 0.952391]\n",
      "epoch:3 step:3250 [D loss: 0.684528, acc.: 59.38%] [G loss: 1.051532]\n",
      "epoch:3 step:3251 [D loss: 0.650620, acc.: 67.97%] [G loss: 1.027753]\n",
      "epoch:3 step:3252 [D loss: 0.702339, acc.: 53.12%] [G loss: 0.898670]\n",
      "epoch:3 step:3253 [D loss: 0.686918, acc.: 57.03%] [G loss: 0.946744]\n",
      "epoch:3 step:3254 [D loss: 0.646677, acc.: 63.28%] [G loss: 0.946434]\n",
      "epoch:3 step:3255 [D loss: 0.680757, acc.: 57.81%] [G loss: 0.899603]\n",
      "epoch:3 step:3256 [D loss: 0.717526, acc.: 53.91%] [G loss: 0.923334]\n",
      "epoch:3 step:3257 [D loss: 0.730090, acc.: 52.34%] [G loss: 0.861883]\n",
      "epoch:3 step:3258 [D loss: 0.640006, acc.: 62.50%] [G loss: 1.011491]\n",
      "epoch:3 step:3259 [D loss: 0.727345, acc.: 53.91%] [G loss: 0.946154]\n",
      "epoch:3 step:3260 [D loss: 0.671300, acc.: 60.94%] [G loss: 1.048962]\n",
      "epoch:3 step:3261 [D loss: 0.674317, acc.: 57.03%] [G loss: 0.904272]\n",
      "epoch:3 step:3262 [D loss: 0.603122, acc.: 72.66%] [G loss: 1.001080]\n",
      "epoch:3 step:3263 [D loss: 0.705924, acc.: 57.03%] [G loss: 1.057292]\n",
      "epoch:3 step:3264 [D loss: 0.580520, acc.: 71.88%] [G loss: 1.007153]\n",
      "epoch:3 step:3265 [D loss: 0.673618, acc.: 57.81%] [G loss: 0.950998]\n",
      "epoch:3 step:3266 [D loss: 0.640436, acc.: 65.62%] [G loss: 1.008147]\n",
      "epoch:3 step:3267 [D loss: 0.666008, acc.: 64.06%] [G loss: 0.989676]\n",
      "epoch:3 step:3268 [D loss: 0.668929, acc.: 57.03%] [G loss: 0.909956]\n",
      "epoch:3 step:3269 [D loss: 0.769277, acc.: 47.66%] [G loss: 0.911979]\n",
      "epoch:3 step:3270 [D loss: 0.689151, acc.: 53.91%] [G loss: 0.948657]\n",
      "epoch:3 step:3271 [D loss: 0.606260, acc.: 66.41%] [G loss: 0.989173]\n",
      "epoch:3 step:3272 [D loss: 0.623742, acc.: 65.62%] [G loss: 0.893106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3273 [D loss: 0.706380, acc.: 58.59%] [G loss: 1.006866]\n",
      "epoch:3 step:3274 [D loss: 0.729247, acc.: 56.25%] [G loss: 0.929862]\n",
      "epoch:3 step:3275 [D loss: 0.634263, acc.: 66.41%] [G loss: 0.936305]\n",
      "epoch:3 step:3276 [D loss: 0.713844, acc.: 56.25%] [G loss: 0.923390]\n",
      "epoch:3 step:3277 [D loss: 0.728970, acc.: 50.78%] [G loss: 0.935243]\n",
      "epoch:3 step:3278 [D loss: 0.616657, acc.: 66.41%] [G loss: 1.115788]\n",
      "epoch:3 step:3279 [D loss: 0.651839, acc.: 60.94%] [G loss: 0.963409]\n",
      "epoch:3 step:3280 [D loss: 0.609177, acc.: 65.62%] [G loss: 1.033986]\n",
      "epoch:3 step:3281 [D loss: 0.591418, acc.: 61.72%] [G loss: 1.074198]\n",
      "epoch:3 step:3282 [D loss: 0.616889, acc.: 60.94%] [G loss: 1.007135]\n",
      "epoch:3 step:3283 [D loss: 0.721151, acc.: 55.47%] [G loss: 0.923616]\n",
      "epoch:3 step:3284 [D loss: 0.781630, acc.: 42.97%] [G loss: 0.894914]\n",
      "epoch:3 step:3285 [D loss: 0.744433, acc.: 46.09%] [G loss: 0.962367]\n",
      "epoch:3 step:3286 [D loss: 0.759239, acc.: 46.09%] [G loss: 0.836639]\n",
      "epoch:3 step:3287 [D loss: 0.656612, acc.: 60.16%] [G loss: 0.893295]\n",
      "epoch:3 step:3288 [D loss: 0.722430, acc.: 53.12%] [G loss: 0.885942]\n",
      "epoch:3 step:3289 [D loss: 0.654282, acc.: 66.41%] [G loss: 1.014578]\n",
      "epoch:3 step:3290 [D loss: 0.674483, acc.: 57.03%] [G loss: 0.896447]\n",
      "epoch:3 step:3291 [D loss: 0.677725, acc.: 64.06%] [G loss: 0.986549]\n",
      "epoch:3 step:3292 [D loss: 0.657408, acc.: 65.62%] [G loss: 0.994548]\n",
      "epoch:3 step:3293 [D loss: 0.689582, acc.: 54.69%] [G loss: 0.858110]\n",
      "epoch:3 step:3294 [D loss: 0.703450, acc.: 54.69%] [G loss: 0.853791]\n",
      "epoch:3 step:3295 [D loss: 0.667047, acc.: 59.38%] [G loss: 0.920430]\n",
      "epoch:3 step:3296 [D loss: 0.682910, acc.: 50.78%] [G loss: 1.055237]\n",
      "epoch:3 step:3297 [D loss: 0.670162, acc.: 57.03%] [G loss: 0.877372]\n",
      "epoch:3 step:3298 [D loss: 0.684148, acc.: 57.81%] [G loss: 0.901114]\n",
      "epoch:3 step:3299 [D loss: 0.621992, acc.: 62.50%] [G loss: 0.974483]\n",
      "epoch:3 step:3300 [D loss: 0.663677, acc.: 62.50%] [G loss: 0.872963]\n",
      "epoch:3 step:3301 [D loss: 0.683776, acc.: 60.94%] [G loss: 0.934293]\n",
      "epoch:3 step:3302 [D loss: 0.708723, acc.: 55.47%] [G loss: 0.814313]\n",
      "epoch:3 step:3303 [D loss: 0.692172, acc.: 59.38%] [G loss: 0.966065]\n",
      "epoch:3 step:3304 [D loss: 0.715821, acc.: 53.12%] [G loss: 1.011953]\n",
      "epoch:3 step:3305 [D loss: 0.662859, acc.: 58.59%] [G loss: 0.992491]\n",
      "epoch:3 step:3306 [D loss: 0.640917, acc.: 62.50%] [G loss: 1.114936]\n",
      "epoch:3 step:3307 [D loss: 0.697011, acc.: 54.69%] [G loss: 1.029345]\n",
      "epoch:3 step:3308 [D loss: 0.681744, acc.: 60.94%] [G loss: 1.011001]\n",
      "epoch:3 step:3309 [D loss: 0.674891, acc.: 55.47%] [G loss: 0.901098]\n",
      "epoch:3 step:3310 [D loss: 0.593979, acc.: 71.09%] [G loss: 1.118055]\n",
      "epoch:3 step:3311 [D loss: 0.691371, acc.: 52.34%] [G loss: 1.051045]\n",
      "epoch:3 step:3312 [D loss: 0.730992, acc.: 50.00%] [G loss: 0.956795]\n",
      "epoch:3 step:3313 [D loss: 0.711343, acc.: 50.00%] [G loss: 0.900086]\n",
      "epoch:3 step:3314 [D loss: 0.668887, acc.: 59.38%] [G loss: 0.904180]\n",
      "epoch:3 step:3315 [D loss: 0.628677, acc.: 63.28%] [G loss: 1.009724]\n",
      "epoch:3 step:3316 [D loss: 0.675829, acc.: 61.72%] [G loss: 0.948054]\n",
      "epoch:3 step:3317 [D loss: 0.696245, acc.: 55.47%] [G loss: 0.903996]\n",
      "epoch:3 step:3318 [D loss: 0.723763, acc.: 53.91%] [G loss: 0.928799]\n",
      "epoch:3 step:3319 [D loss: 0.583843, acc.: 67.97%] [G loss: 1.059960]\n",
      "epoch:3 step:3320 [D loss: 0.699503, acc.: 53.12%] [G loss: 0.957886]\n",
      "epoch:3 step:3321 [D loss: 0.715709, acc.: 57.81%] [G loss: 0.979026]\n",
      "epoch:3 step:3322 [D loss: 0.746192, acc.: 47.66%] [G loss: 0.849257]\n",
      "epoch:3 step:3323 [D loss: 0.661983, acc.: 61.72%] [G loss: 0.928990]\n",
      "epoch:3 step:3324 [D loss: 0.590640, acc.: 68.75%] [G loss: 1.014911]\n",
      "epoch:3 step:3325 [D loss: 0.658564, acc.: 57.81%] [G loss: 0.887444]\n",
      "epoch:3 step:3326 [D loss: 0.679038, acc.: 56.25%] [G loss: 0.918742]\n",
      "epoch:3 step:3327 [D loss: 0.632285, acc.: 67.19%] [G loss: 0.968247]\n",
      "epoch:3 step:3328 [D loss: 0.737283, acc.: 48.44%] [G loss: 1.012246]\n",
      "epoch:3 step:3329 [D loss: 0.660463, acc.: 56.25%] [G loss: 0.893761]\n",
      "epoch:3 step:3330 [D loss: 0.658567, acc.: 57.03%] [G loss: 0.991400]\n",
      "epoch:3 step:3331 [D loss: 0.617724, acc.: 68.75%] [G loss: 1.020697]\n",
      "epoch:3 step:3332 [D loss: 0.614728, acc.: 64.06%] [G loss: 1.097505]\n",
      "epoch:3 step:3333 [D loss: 0.667008, acc.: 60.94%] [G loss: 0.983795]\n",
      "epoch:3 step:3334 [D loss: 0.646604, acc.: 60.94%] [G loss: 0.871661]\n",
      "epoch:3 step:3335 [D loss: 0.656042, acc.: 60.94%] [G loss: 0.999792]\n",
      "epoch:3 step:3336 [D loss: 0.675731, acc.: 62.50%] [G loss: 0.949846]\n",
      "epoch:3 step:3337 [D loss: 0.644258, acc.: 60.94%] [G loss: 0.987328]\n",
      "epoch:3 step:3338 [D loss: 0.668652, acc.: 57.81%] [G loss: 0.931974]\n",
      "epoch:3 step:3339 [D loss: 0.726320, acc.: 56.25%] [G loss: 0.890460]\n",
      "epoch:3 step:3340 [D loss: 0.681721, acc.: 57.81%] [G loss: 0.833591]\n",
      "epoch:3 step:3341 [D loss: 0.654065, acc.: 61.72%] [G loss: 0.942811]\n",
      "epoch:3 step:3342 [D loss: 0.639214, acc.: 58.59%] [G loss: 0.957885]\n",
      "epoch:3 step:3343 [D loss: 0.612735, acc.: 67.97%] [G loss: 0.976136]\n",
      "epoch:3 step:3344 [D loss: 0.679443, acc.: 57.81%] [G loss: 1.011345]\n",
      "epoch:3 step:3345 [D loss: 0.688255, acc.: 58.59%] [G loss: 0.911865]\n",
      "epoch:3 step:3346 [D loss: 0.618363, acc.: 65.62%] [G loss: 0.962248]\n",
      "epoch:3 step:3347 [D loss: 0.658984, acc.: 67.19%] [G loss: 0.976067]\n",
      "epoch:3 step:3348 [D loss: 0.658466, acc.: 61.72%] [G loss: 0.991275]\n",
      "epoch:3 step:3349 [D loss: 0.679842, acc.: 59.38%] [G loss: 0.889557]\n",
      "epoch:3 step:3350 [D loss: 0.688627, acc.: 54.69%] [G loss: 0.957828]\n",
      "epoch:3 step:3351 [D loss: 0.690597, acc.: 57.03%] [G loss: 1.035187]\n",
      "epoch:3 step:3352 [D loss: 0.614824, acc.: 67.97%] [G loss: 0.972104]\n",
      "epoch:3 step:3353 [D loss: 0.791598, acc.: 43.75%] [G loss: 0.881142]\n",
      "epoch:3 step:3354 [D loss: 0.757607, acc.: 45.31%] [G loss: 0.825253]\n",
      "epoch:3 step:3355 [D loss: 0.736827, acc.: 46.09%] [G loss: 0.918199]\n",
      "epoch:3 step:3356 [D loss: 0.702095, acc.: 55.47%] [G loss: 0.935106]\n",
      "epoch:3 step:3357 [D loss: 0.708311, acc.: 53.12%] [G loss: 0.991211]\n",
      "epoch:3 step:3358 [D loss: 0.603719, acc.: 67.19%] [G loss: 1.059118]\n",
      "epoch:3 step:3359 [D loss: 0.692943, acc.: 58.59%] [G loss: 0.860046]\n",
      "epoch:3 step:3360 [D loss: 0.684904, acc.: 57.81%] [G loss: 0.976332]\n",
      "epoch:3 step:3361 [D loss: 0.600492, acc.: 69.53%] [G loss: 0.974059]\n",
      "epoch:3 step:3362 [D loss: 0.590519, acc.: 70.31%] [G loss: 1.145043]\n",
      "epoch:3 step:3363 [D loss: 0.654330, acc.: 62.50%] [G loss: 0.963335]\n",
      "epoch:3 step:3364 [D loss: 0.632159, acc.: 62.50%] [G loss: 0.903847]\n",
      "epoch:3 step:3365 [D loss: 0.636614, acc.: 59.38%] [G loss: 1.037316]\n",
      "epoch:3 step:3366 [D loss: 0.572338, acc.: 70.31%] [G loss: 1.015831]\n",
      "epoch:3 step:3367 [D loss: 0.623904, acc.: 63.28%] [G loss: 0.942654]\n",
      "epoch:3 step:3368 [D loss: 0.667799, acc.: 57.81%] [G loss: 0.959435]\n",
      "epoch:3 step:3369 [D loss: 0.636774, acc.: 67.97%] [G loss: 1.136541]\n",
      "epoch:3 step:3370 [D loss: 0.742734, acc.: 50.00%] [G loss: 0.975709]\n",
      "epoch:3 step:3371 [D loss: 0.686978, acc.: 54.69%] [G loss: 0.959928]\n",
      "epoch:3 step:3372 [D loss: 0.718066, acc.: 52.34%] [G loss: 0.984308]\n",
      "epoch:3 step:3373 [D loss: 0.677396, acc.: 58.59%] [G loss: 0.980918]\n",
      "epoch:3 step:3374 [D loss: 0.636098, acc.: 68.75%] [G loss: 0.936563]\n",
      "epoch:3 step:3375 [D loss: 0.713667, acc.: 54.69%] [G loss: 0.959050]\n",
      "epoch:3 step:3376 [D loss: 0.693167, acc.: 56.25%] [G loss: 1.067529]\n",
      "epoch:3 step:3377 [D loss: 0.706818, acc.: 53.91%] [G loss: 0.896058]\n",
      "epoch:3 step:3378 [D loss: 0.667786, acc.: 56.25%] [G loss: 0.957745]\n",
      "epoch:3 step:3379 [D loss: 0.703803, acc.: 55.47%] [G loss: 0.926338]\n",
      "epoch:3 step:3380 [D loss: 0.668033, acc.: 60.16%] [G loss: 1.072511]\n",
      "epoch:3 step:3381 [D loss: 0.601938, acc.: 71.09%] [G loss: 0.904293]\n",
      "epoch:3 step:3382 [D loss: 0.655041, acc.: 63.28%] [G loss: 0.922165]\n",
      "epoch:3 step:3383 [D loss: 0.648040, acc.: 60.16%] [G loss: 0.977661]\n",
      "epoch:3 step:3384 [D loss: 0.717896, acc.: 55.47%] [G loss: 0.894264]\n",
      "epoch:3 step:3385 [D loss: 0.668947, acc.: 60.16%] [G loss: 0.989622]\n",
      "epoch:3 step:3386 [D loss: 0.666610, acc.: 61.72%] [G loss: 0.956835]\n",
      "epoch:3 step:3387 [D loss: 0.689163, acc.: 58.59%] [G loss: 0.973641]\n",
      "epoch:3 step:3388 [D loss: 0.662989, acc.: 63.28%] [G loss: 0.992166]\n",
      "epoch:3 step:3389 [D loss: 0.654084, acc.: 60.94%] [G loss: 1.014022]\n",
      "epoch:3 step:3390 [D loss: 0.734080, acc.: 45.31%] [G loss: 0.977062]\n",
      "epoch:3 step:3391 [D loss: 0.650597, acc.: 60.94%] [G loss: 1.042596]\n",
      "epoch:3 step:3392 [D loss: 0.715752, acc.: 54.69%] [G loss: 0.868356]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3393 [D loss: 0.656606, acc.: 60.94%] [G loss: 0.933037]\n",
      "epoch:3 step:3394 [D loss: 0.671100, acc.: 57.03%] [G loss: 0.875686]\n",
      "epoch:3 step:3395 [D loss: 0.728325, acc.: 57.03%] [G loss: 0.894139]\n",
      "epoch:3 step:3396 [D loss: 0.626234, acc.: 66.41%] [G loss: 0.985217]\n",
      "epoch:3 step:3397 [D loss: 0.707467, acc.: 55.47%] [G loss: 1.094943]\n",
      "epoch:3 step:3398 [D loss: 0.614489, acc.: 64.06%] [G loss: 0.956908]\n",
      "epoch:3 step:3399 [D loss: 0.636880, acc.: 64.84%] [G loss: 0.838255]\n",
      "epoch:3 step:3400 [D loss: 0.602816, acc.: 72.66%] [G loss: 0.971771]\n",
      "##############\n",
      "[2.14171433 1.1617221  5.27733186 4.23406114 2.92001658 5.17347256\n",
      " 3.79529853 4.27056223 3.72741783 3.06026728]\n",
      "##########\n",
      "epoch:3 step:3401 [D loss: 0.723610, acc.: 53.12%] [G loss: 1.023974]\n",
      "epoch:3 step:3402 [D loss: 0.716476, acc.: 59.38%] [G loss: 0.883708]\n",
      "epoch:3 step:3403 [D loss: 0.635212, acc.: 60.16%] [G loss: 0.970264]\n",
      "epoch:3 step:3404 [D loss: 0.671652, acc.: 58.59%] [G loss: 0.899930]\n",
      "epoch:3 step:3405 [D loss: 0.679964, acc.: 57.81%] [G loss: 1.002515]\n",
      "epoch:3 step:3406 [D loss: 0.648506, acc.: 59.38%] [G loss: 0.979089]\n",
      "epoch:3 step:3407 [D loss: 0.660768, acc.: 59.38%] [G loss: 0.956084]\n",
      "epoch:3 step:3408 [D loss: 0.631072, acc.: 62.50%] [G loss: 0.899041]\n",
      "epoch:3 step:3409 [D loss: 0.636615, acc.: 65.62%] [G loss: 0.968436]\n",
      "epoch:3 step:3410 [D loss: 0.682921, acc.: 50.00%] [G loss: 0.974457]\n",
      "epoch:3 step:3411 [D loss: 0.730318, acc.: 50.78%] [G loss: 0.948995]\n",
      "epoch:3 step:3412 [D loss: 0.680252, acc.: 60.16%] [G loss: 0.926286]\n",
      "epoch:3 step:3413 [D loss: 0.761549, acc.: 46.09%] [G loss: 0.921174]\n",
      "epoch:3 step:3414 [D loss: 0.642708, acc.: 64.06%] [G loss: 0.906485]\n",
      "epoch:3 step:3415 [D loss: 0.647705, acc.: 65.62%] [G loss: 1.012667]\n",
      "epoch:3 step:3416 [D loss: 0.665385, acc.: 59.38%] [G loss: 1.061158]\n",
      "epoch:3 step:3417 [D loss: 0.642883, acc.: 59.38%] [G loss: 0.889167]\n",
      "epoch:3 step:3418 [D loss: 0.669000, acc.: 59.38%] [G loss: 0.908445]\n",
      "epoch:3 step:3419 [D loss: 0.689855, acc.: 56.25%] [G loss: 0.944499]\n",
      "epoch:3 step:3420 [D loss: 0.604453, acc.: 71.88%] [G loss: 1.051972]\n",
      "epoch:3 step:3421 [D loss: 0.674440, acc.: 58.59%] [G loss: 1.024067]\n",
      "epoch:3 step:3422 [D loss: 0.670128, acc.: 60.94%] [G loss: 1.041613]\n",
      "epoch:3 step:3423 [D loss: 0.665317, acc.: 61.72%] [G loss: 1.022735]\n",
      "epoch:3 step:3424 [D loss: 0.649484, acc.: 63.28%] [G loss: 0.825482]\n",
      "epoch:3 step:3425 [D loss: 0.682207, acc.: 56.25%] [G loss: 0.999783]\n",
      "epoch:3 step:3426 [D loss: 0.737766, acc.: 49.22%] [G loss: 0.926498]\n",
      "epoch:3 step:3427 [D loss: 0.668458, acc.: 57.03%] [G loss: 0.990846]\n",
      "epoch:3 step:3428 [D loss: 0.655728, acc.: 64.06%] [G loss: 0.914001]\n",
      "epoch:3 step:3429 [D loss: 0.689689, acc.: 57.81%] [G loss: 0.858086]\n",
      "epoch:3 step:3430 [D loss: 0.666406, acc.: 60.94%] [G loss: 0.958671]\n",
      "epoch:3 step:3431 [D loss: 0.649660, acc.: 62.50%] [G loss: 0.968165]\n",
      "epoch:3 step:3432 [D loss: 0.663076, acc.: 59.38%] [G loss: 1.044594]\n",
      "epoch:3 step:3433 [D loss: 0.755401, acc.: 46.09%] [G loss: 0.875617]\n",
      "epoch:3 step:3434 [D loss: 0.679955, acc.: 59.38%] [G loss: 0.993563]\n",
      "epoch:3 step:3435 [D loss: 0.656680, acc.: 57.81%] [G loss: 0.860842]\n",
      "epoch:3 step:3436 [D loss: 0.699102, acc.: 53.91%] [G loss: 0.852263]\n",
      "epoch:3 step:3437 [D loss: 0.589957, acc.: 71.88%] [G loss: 1.034679]\n",
      "epoch:3 step:3438 [D loss: 0.703786, acc.: 52.34%] [G loss: 0.937235]\n",
      "epoch:3 step:3439 [D loss: 0.702568, acc.: 57.03%] [G loss: 0.895002]\n",
      "epoch:3 step:3440 [D loss: 0.677868, acc.: 57.81%] [G loss: 0.904236]\n",
      "epoch:3 step:3441 [D loss: 0.643200, acc.: 64.06%] [G loss: 0.962645]\n",
      "epoch:3 step:3442 [D loss: 0.591652, acc.: 71.88%] [G loss: 0.981279]\n",
      "epoch:3 step:3443 [D loss: 0.654947, acc.: 58.59%] [G loss: 1.018864]\n",
      "epoch:3 step:3444 [D loss: 0.674562, acc.: 57.03%] [G loss: 0.925199]\n",
      "epoch:3 step:3445 [D loss: 0.637477, acc.: 64.06%] [G loss: 1.000588]\n",
      "epoch:3 step:3446 [D loss: 0.568397, acc.: 74.22%] [G loss: 1.039197]\n",
      "epoch:3 step:3447 [D loss: 0.782109, acc.: 43.75%] [G loss: 0.942666]\n",
      "epoch:3 step:3448 [D loss: 0.695994, acc.: 55.47%] [G loss: 1.005587]\n",
      "epoch:3 step:3449 [D loss: 0.675926, acc.: 62.50%] [G loss: 1.042330]\n",
      "epoch:3 step:3450 [D loss: 0.637629, acc.: 64.06%] [G loss: 0.956671]\n",
      "epoch:3 step:3451 [D loss: 0.661696, acc.: 64.06%] [G loss: 0.900112]\n",
      "epoch:3 step:3452 [D loss: 0.671486, acc.: 53.91%] [G loss: 0.971315]\n",
      "epoch:3 step:3453 [D loss: 0.608282, acc.: 65.62%] [G loss: 1.064453]\n",
      "epoch:3 step:3454 [D loss: 0.651522, acc.: 67.19%] [G loss: 0.995514]\n",
      "epoch:3 step:3455 [D loss: 0.690413, acc.: 57.03%] [G loss: 1.009619]\n",
      "epoch:3 step:3456 [D loss: 0.677846, acc.: 54.69%] [G loss: 1.048089]\n",
      "epoch:3 step:3457 [D loss: 0.662387, acc.: 59.38%] [G loss: 1.041732]\n",
      "epoch:3 step:3458 [D loss: 0.669778, acc.: 60.16%] [G loss: 0.931570]\n",
      "epoch:3 step:3459 [D loss: 0.622601, acc.: 62.50%] [G loss: 0.912222]\n",
      "epoch:3 step:3460 [D loss: 0.584131, acc.: 72.66%] [G loss: 1.068305]\n",
      "epoch:3 step:3461 [D loss: 0.639528, acc.: 61.72%] [G loss: 1.109026]\n",
      "epoch:3 step:3462 [D loss: 0.627836, acc.: 64.84%] [G loss: 0.947356]\n",
      "epoch:3 step:3463 [D loss: 0.658131, acc.: 64.06%] [G loss: 0.967742]\n",
      "epoch:3 step:3464 [D loss: 0.699584, acc.: 58.59%] [G loss: 0.945495]\n",
      "epoch:3 step:3465 [D loss: 0.630613, acc.: 64.84%] [G loss: 0.990529]\n",
      "epoch:3 step:3466 [D loss: 0.661956, acc.: 62.50%] [G loss: 1.075015]\n",
      "epoch:3 step:3467 [D loss: 0.646362, acc.: 60.16%] [G loss: 0.925476]\n",
      "epoch:3 step:3468 [D loss: 0.695639, acc.: 60.94%] [G loss: 0.959612]\n",
      "epoch:3 step:3469 [D loss: 0.720729, acc.: 54.69%] [G loss: 0.965846]\n",
      "epoch:3 step:3470 [D loss: 0.637060, acc.: 62.50%] [G loss: 0.871638]\n",
      "epoch:3 step:3471 [D loss: 0.656844, acc.: 63.28%] [G loss: 0.869447]\n",
      "epoch:3 step:3472 [D loss: 0.595137, acc.: 66.41%] [G loss: 0.992730]\n",
      "epoch:3 step:3473 [D loss: 0.678150, acc.: 55.47%] [G loss: 0.950378]\n",
      "epoch:3 step:3474 [D loss: 0.711186, acc.: 53.91%] [G loss: 0.910046]\n",
      "epoch:3 step:3475 [D loss: 0.669679, acc.: 57.03%] [G loss: 0.978546]\n",
      "epoch:3 step:3476 [D loss: 0.717601, acc.: 51.56%] [G loss: 0.919227]\n",
      "epoch:3 step:3477 [D loss: 0.639872, acc.: 64.84%] [G loss: 1.055911]\n",
      "epoch:3 step:3478 [D loss: 0.696443, acc.: 59.38%] [G loss: 1.014967]\n",
      "epoch:3 step:3479 [D loss: 0.721281, acc.: 53.91%] [G loss: 0.843611]\n",
      "epoch:3 step:3480 [D loss: 0.735853, acc.: 51.56%] [G loss: 0.950844]\n",
      "epoch:3 step:3481 [D loss: 0.695616, acc.: 58.59%] [G loss: 0.978270]\n",
      "epoch:3 step:3482 [D loss: 0.618305, acc.: 66.41%] [G loss: 1.104750]\n",
      "epoch:3 step:3483 [D loss: 0.704918, acc.: 49.22%] [G loss: 0.873559]\n",
      "epoch:3 step:3484 [D loss: 0.730906, acc.: 52.34%] [G loss: 0.830038]\n",
      "epoch:3 step:3485 [D loss: 0.680399, acc.: 53.12%] [G loss: 0.906013]\n",
      "epoch:3 step:3486 [D loss: 0.678773, acc.: 55.47%] [G loss: 0.952261]\n",
      "epoch:3 step:3487 [D loss: 0.678476, acc.: 59.38%] [G loss: 0.987541]\n",
      "epoch:3 step:3488 [D loss: 0.652085, acc.: 58.59%] [G loss: 0.962418]\n",
      "epoch:3 step:3489 [D loss: 0.683456, acc.: 57.81%] [G loss: 1.078802]\n",
      "epoch:3 step:3490 [D loss: 0.688811, acc.: 56.25%] [G loss: 0.862188]\n",
      "epoch:3 step:3491 [D loss: 0.615048, acc.: 64.06%] [G loss: 0.820758]\n",
      "epoch:3 step:3492 [D loss: 0.699537, acc.: 56.25%] [G loss: 0.922173]\n",
      "epoch:3 step:3493 [D loss: 0.613791, acc.: 66.41%] [G loss: 0.944117]\n",
      "epoch:3 step:3494 [D loss: 0.665915, acc.: 57.03%] [G loss: 0.935713]\n",
      "epoch:3 step:3495 [D loss: 0.657987, acc.: 61.72%] [G loss: 0.818514]\n",
      "epoch:3 step:3496 [D loss: 0.706225, acc.: 56.25%] [G loss: 0.824105]\n",
      "epoch:3 step:3497 [D loss: 0.656762, acc.: 64.06%] [G loss: 0.931585]\n",
      "epoch:3 step:3498 [D loss: 0.652973, acc.: 63.28%] [G loss: 0.940935]\n",
      "epoch:3 step:3499 [D loss: 0.646160, acc.: 64.84%] [G loss: 0.923915]\n",
      "epoch:3 step:3500 [D loss: 0.632241, acc.: 64.84%] [G loss: 0.903546]\n",
      "epoch:3 step:3501 [D loss: 0.587691, acc.: 69.53%] [G loss: 1.094609]\n",
      "epoch:3 step:3502 [D loss: 0.653500, acc.: 62.50%] [G loss: 0.947437]\n",
      "epoch:3 step:3503 [D loss: 0.652028, acc.: 60.16%] [G loss: 1.004872]\n",
      "epoch:3 step:3504 [D loss: 0.617331, acc.: 65.62%] [G loss: 0.997517]\n",
      "epoch:3 step:3505 [D loss: 0.676119, acc.: 56.25%] [G loss: 0.827675]\n",
      "epoch:3 step:3506 [D loss: 0.653302, acc.: 59.38%] [G loss: 0.996905]\n",
      "epoch:3 step:3507 [D loss: 0.660564, acc.: 63.28%] [G loss: 0.956315]\n",
      "epoch:3 step:3508 [D loss: 0.670078, acc.: 60.94%] [G loss: 1.002701]\n",
      "epoch:3 step:3509 [D loss: 0.678285, acc.: 58.59%] [G loss: 0.971214]\n",
      "epoch:3 step:3510 [D loss: 0.604218, acc.: 66.41%] [G loss: 1.071815]\n",
      "epoch:3 step:3511 [D loss: 0.716866, acc.: 57.03%] [G loss: 1.022512]\n",
      "epoch:3 step:3512 [D loss: 0.726263, acc.: 46.88%] [G loss: 0.887650]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3513 [D loss: 0.712146, acc.: 52.34%] [G loss: 0.972819]\n",
      "epoch:3 step:3514 [D loss: 0.678745, acc.: 57.81%] [G loss: 0.949277]\n",
      "epoch:3 step:3515 [D loss: 0.750621, acc.: 49.22%] [G loss: 0.929395]\n",
      "epoch:3 step:3516 [D loss: 0.648710, acc.: 63.28%] [G loss: 0.905914]\n",
      "epoch:3 step:3517 [D loss: 0.695939, acc.: 53.91%] [G loss: 0.947909]\n",
      "epoch:3 step:3518 [D loss: 0.623536, acc.: 67.19%] [G loss: 0.942032]\n",
      "epoch:3 step:3519 [D loss: 0.627127, acc.: 65.62%] [G loss: 0.986819]\n",
      "epoch:3 step:3520 [D loss: 0.582213, acc.: 67.97%] [G loss: 1.005567]\n",
      "epoch:3 step:3521 [D loss: 0.692344, acc.: 58.59%] [G loss: 0.959096]\n",
      "epoch:3 step:3522 [D loss: 0.651527, acc.: 63.28%] [G loss: 0.925236]\n",
      "epoch:3 step:3523 [D loss: 0.664045, acc.: 58.59%] [G loss: 1.036142]\n",
      "epoch:3 step:3524 [D loss: 0.638323, acc.: 67.97%] [G loss: 0.984952]\n",
      "epoch:3 step:3525 [D loss: 0.639250, acc.: 60.16%] [G loss: 0.975516]\n",
      "epoch:3 step:3526 [D loss: 0.697781, acc.: 52.34%] [G loss: 0.978131]\n",
      "epoch:3 step:3527 [D loss: 0.733471, acc.: 50.78%] [G loss: 1.016660]\n",
      "epoch:3 step:3528 [D loss: 0.730518, acc.: 54.69%] [G loss: 0.876337]\n",
      "epoch:3 step:3529 [D loss: 0.665932, acc.: 65.62%] [G loss: 0.971954]\n",
      "epoch:3 step:3530 [D loss: 0.681884, acc.: 58.59%] [G loss: 0.922158]\n",
      "epoch:3 step:3531 [D loss: 0.700051, acc.: 55.47%] [G loss: 0.918700]\n",
      "epoch:3 step:3532 [D loss: 0.695407, acc.: 58.59%] [G loss: 0.996913]\n",
      "epoch:3 step:3533 [D loss: 0.694384, acc.: 55.47%] [G loss: 0.897873]\n",
      "epoch:3 step:3534 [D loss: 0.652403, acc.: 60.16%] [G loss: 0.928371]\n",
      "epoch:3 step:3535 [D loss: 0.636012, acc.: 67.97%] [G loss: 1.003704]\n",
      "epoch:3 step:3536 [D loss: 0.707215, acc.: 57.03%] [G loss: 0.896879]\n",
      "epoch:3 step:3537 [D loss: 0.672027, acc.: 57.81%] [G loss: 0.870391]\n",
      "epoch:3 step:3538 [D loss: 0.665327, acc.: 57.81%] [G loss: 0.908823]\n",
      "epoch:3 step:3539 [D loss: 0.690996, acc.: 58.59%] [G loss: 0.833985]\n",
      "epoch:3 step:3540 [D loss: 0.658660, acc.: 57.03%] [G loss: 0.923718]\n",
      "epoch:3 step:3541 [D loss: 0.628594, acc.: 60.94%] [G loss: 0.945835]\n",
      "epoch:3 step:3542 [D loss: 0.634310, acc.: 64.84%] [G loss: 0.998386]\n",
      "epoch:3 step:3543 [D loss: 0.647625, acc.: 63.28%] [G loss: 0.992254]\n",
      "epoch:3 step:3544 [D loss: 0.642070, acc.: 64.84%] [G loss: 1.010491]\n",
      "epoch:3 step:3545 [D loss: 0.693157, acc.: 61.72%] [G loss: 1.003210]\n",
      "epoch:3 step:3546 [D loss: 0.660095, acc.: 60.16%] [G loss: 0.993656]\n",
      "epoch:3 step:3547 [D loss: 0.682951, acc.: 57.03%] [G loss: 0.912330]\n",
      "epoch:3 step:3548 [D loss: 0.666793, acc.: 61.72%] [G loss: 0.927294]\n",
      "epoch:3 step:3549 [D loss: 0.716222, acc.: 53.12%] [G loss: 0.912750]\n",
      "epoch:3 step:3550 [D loss: 0.727560, acc.: 57.03%] [G loss: 0.923749]\n",
      "epoch:3 step:3551 [D loss: 0.624794, acc.: 59.38%] [G loss: 0.890675]\n",
      "epoch:3 step:3552 [D loss: 0.685613, acc.: 58.59%] [G loss: 1.000507]\n",
      "epoch:3 step:3553 [D loss: 0.671056, acc.: 59.38%] [G loss: 0.869435]\n",
      "epoch:3 step:3554 [D loss: 0.669933, acc.: 57.81%] [G loss: 0.883466]\n",
      "epoch:3 step:3555 [D loss: 0.704864, acc.: 57.03%] [G loss: 0.996353]\n",
      "epoch:3 step:3556 [D loss: 0.629701, acc.: 60.94%] [G loss: 1.115892]\n",
      "epoch:3 step:3557 [D loss: 0.597438, acc.: 68.75%] [G loss: 1.066801]\n",
      "epoch:3 step:3558 [D loss: 0.608800, acc.: 70.31%] [G loss: 1.023726]\n",
      "epoch:3 step:3559 [D loss: 0.662726, acc.: 61.72%] [G loss: 1.062269]\n",
      "epoch:3 step:3560 [D loss: 0.703925, acc.: 53.91%] [G loss: 1.021712]\n",
      "epoch:3 step:3561 [D loss: 0.644111, acc.: 63.28%] [G loss: 0.858749]\n",
      "epoch:3 step:3562 [D loss: 0.688979, acc.: 55.47%] [G loss: 0.907861]\n",
      "epoch:3 step:3563 [D loss: 0.733794, acc.: 49.22%] [G loss: 0.859785]\n",
      "epoch:3 step:3564 [D loss: 0.640472, acc.: 60.94%] [G loss: 0.978956]\n",
      "epoch:3 step:3565 [D loss: 0.623705, acc.: 66.41%] [G loss: 0.955282]\n",
      "epoch:3 step:3566 [D loss: 0.654665, acc.: 57.81%] [G loss: 0.881093]\n",
      "epoch:3 step:3567 [D loss: 0.688991, acc.: 57.03%] [G loss: 0.964447]\n",
      "epoch:3 step:3568 [D loss: 0.645080, acc.: 60.94%] [G loss: 0.916334]\n",
      "epoch:3 step:3569 [D loss: 0.682961, acc.: 55.47%] [G loss: 1.035376]\n",
      "epoch:3 step:3570 [D loss: 0.683593, acc.: 57.81%] [G loss: 0.959102]\n",
      "epoch:3 step:3571 [D loss: 0.706836, acc.: 56.25%] [G loss: 0.881791]\n",
      "epoch:3 step:3572 [D loss: 0.652360, acc.: 61.72%] [G loss: 0.899027]\n",
      "epoch:3 step:3573 [D loss: 0.676206, acc.: 54.69%] [G loss: 0.872176]\n",
      "epoch:3 step:3574 [D loss: 0.687930, acc.: 57.03%] [G loss: 1.074590]\n",
      "epoch:3 step:3575 [D loss: 0.664221, acc.: 59.38%] [G loss: 0.897402]\n",
      "epoch:3 step:3576 [D loss: 0.753027, acc.: 45.31%] [G loss: 0.896016]\n",
      "epoch:3 step:3577 [D loss: 0.711178, acc.: 55.47%] [G loss: 0.928306]\n",
      "epoch:3 step:3578 [D loss: 0.681574, acc.: 53.91%] [G loss: 0.962084]\n",
      "epoch:3 step:3579 [D loss: 0.730178, acc.: 55.47%] [G loss: 0.866710]\n",
      "epoch:3 step:3580 [D loss: 0.708470, acc.: 57.03%] [G loss: 0.853879]\n",
      "epoch:3 step:3581 [D loss: 0.663798, acc.: 59.38%] [G loss: 0.907720]\n",
      "epoch:3 step:3582 [D loss: 0.643267, acc.: 59.38%] [G loss: 0.961889]\n",
      "epoch:3 step:3583 [D loss: 0.623378, acc.: 65.62%] [G loss: 0.960292]\n",
      "epoch:3 step:3584 [D loss: 0.719435, acc.: 54.69%] [G loss: 0.908586]\n",
      "epoch:3 step:3585 [D loss: 0.699964, acc.: 58.59%] [G loss: 0.984371]\n",
      "epoch:3 step:3586 [D loss: 0.613607, acc.: 69.53%] [G loss: 0.859445]\n",
      "epoch:3 step:3587 [D loss: 0.656249, acc.: 62.50%] [G loss: 0.957572]\n",
      "epoch:3 step:3588 [D loss: 0.648899, acc.: 67.19%] [G loss: 0.895619]\n",
      "epoch:3 step:3589 [D loss: 0.695774, acc.: 56.25%] [G loss: 0.903723]\n",
      "epoch:3 step:3590 [D loss: 0.678441, acc.: 52.34%] [G loss: 1.010434]\n",
      "epoch:3 step:3591 [D loss: 0.700430, acc.: 60.16%] [G loss: 0.901377]\n",
      "epoch:3 step:3592 [D loss: 0.615638, acc.: 64.84%] [G loss: 0.980478]\n",
      "epoch:3 step:3593 [D loss: 0.636434, acc.: 61.72%] [G loss: 0.982742]\n",
      "epoch:3 step:3594 [D loss: 0.701319, acc.: 58.59%] [G loss: 0.932570]\n",
      "epoch:3 step:3595 [D loss: 0.635004, acc.: 59.38%] [G loss: 0.932756]\n",
      "epoch:3 step:3596 [D loss: 0.670915, acc.: 59.38%] [G loss: 0.963614]\n",
      "epoch:3 step:3597 [D loss: 0.657861, acc.: 62.50%] [G loss: 0.967535]\n",
      "epoch:3 step:3598 [D loss: 0.733821, acc.: 54.69%] [G loss: 0.915986]\n",
      "epoch:3 step:3599 [D loss: 0.749194, acc.: 50.78%] [G loss: 0.861021]\n",
      "epoch:3 step:3600 [D loss: 0.703198, acc.: 56.25%] [G loss: 0.864121]\n",
      "##############\n",
      "[1.7744542  0.56444064 4.95217269 4.18580048 2.43588059 5.05597287\n",
      " 3.42178596 4.02090701 3.39022459 2.99887943]\n",
      "##########\n",
      "epoch:3 step:3601 [D loss: 0.631404, acc.: 64.84%] [G loss: 0.922937]\n",
      "epoch:3 step:3602 [D loss: 0.698254, acc.: 56.25%] [G loss: 0.997315]\n",
      "epoch:3 step:3603 [D loss: 0.646380, acc.: 61.72%] [G loss: 1.007057]\n",
      "epoch:3 step:3604 [D loss: 0.660551, acc.: 60.16%] [G loss: 0.947728]\n",
      "epoch:3 step:3605 [D loss: 0.747458, acc.: 49.22%] [G loss: 0.956530]\n",
      "epoch:3 step:3606 [D loss: 0.649677, acc.: 65.62%] [G loss: 0.962492]\n",
      "epoch:3 step:3607 [D loss: 0.625824, acc.: 63.28%] [G loss: 0.920892]\n",
      "epoch:3 step:3608 [D loss: 0.683936, acc.: 57.81%] [G loss: 0.896239]\n",
      "epoch:3 step:3609 [D loss: 0.647667, acc.: 61.72%] [G loss: 0.934337]\n",
      "epoch:3 step:3610 [D loss: 0.684552, acc.: 58.59%] [G loss: 0.916404]\n",
      "epoch:3 step:3611 [D loss: 0.739138, acc.: 51.56%] [G loss: 1.004467]\n",
      "epoch:3 step:3612 [D loss: 0.725590, acc.: 53.12%] [G loss: 0.825704]\n",
      "epoch:3 step:3613 [D loss: 0.689624, acc.: 53.91%] [G loss: 0.895601]\n",
      "epoch:3 step:3614 [D loss: 0.594482, acc.: 71.88%] [G loss: 0.894332]\n",
      "epoch:3 step:3615 [D loss: 0.670489, acc.: 65.62%] [G loss: 0.964532]\n",
      "epoch:3 step:3616 [D loss: 0.666299, acc.: 60.16%] [G loss: 0.975208]\n",
      "epoch:3 step:3617 [D loss: 0.645535, acc.: 60.16%] [G loss: 1.051066]\n",
      "epoch:3 step:3618 [D loss: 0.625584, acc.: 63.28%] [G loss: 0.876863]\n",
      "epoch:3 step:3619 [D loss: 0.710831, acc.: 61.72%] [G loss: 0.979568]\n",
      "epoch:3 step:3620 [D loss: 0.661023, acc.: 60.94%] [G loss: 0.902668]\n",
      "epoch:3 step:3621 [D loss: 0.677820, acc.: 58.59%] [G loss: 0.976050]\n",
      "epoch:3 step:3622 [D loss: 0.692923, acc.: 59.38%] [G loss: 1.013753]\n",
      "epoch:3 step:3623 [D loss: 0.651720, acc.: 64.06%] [G loss: 0.938837]\n",
      "epoch:3 step:3624 [D loss: 0.653639, acc.: 63.28%] [G loss: 0.866998]\n",
      "epoch:3 step:3625 [D loss: 0.718589, acc.: 52.34%] [G loss: 0.927708]\n",
      "epoch:3 step:3626 [D loss: 0.721191, acc.: 55.47%] [G loss: 0.891661]\n",
      "epoch:3 step:3627 [D loss: 0.617732, acc.: 64.84%] [G loss: 1.104246]\n",
      "epoch:3 step:3628 [D loss: 0.640027, acc.: 63.28%] [G loss: 0.925933]\n",
      "epoch:3 step:3629 [D loss: 0.679936, acc.: 59.38%] [G loss: 0.891395]\n",
      "epoch:3 step:3630 [D loss: 0.601507, acc.: 68.75%] [G loss: 0.924551]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3631 [D loss: 0.742579, acc.: 50.00%] [G loss: 1.021803]\n",
      "epoch:3 step:3632 [D loss: 0.673815, acc.: 58.59%] [G loss: 0.891793]\n",
      "epoch:3 step:3633 [D loss: 0.601460, acc.: 70.31%] [G loss: 0.964158]\n",
      "epoch:3 step:3634 [D loss: 0.580025, acc.: 70.31%] [G loss: 0.962776]\n",
      "epoch:3 step:3635 [D loss: 0.726604, acc.: 51.56%] [G loss: 0.993411]\n",
      "epoch:3 step:3636 [D loss: 0.647008, acc.: 66.41%] [G loss: 0.921022]\n",
      "epoch:3 step:3637 [D loss: 0.672389, acc.: 64.84%] [G loss: 0.817372]\n",
      "epoch:3 step:3638 [D loss: 0.643105, acc.: 67.97%] [G loss: 0.900615]\n",
      "epoch:3 step:3639 [D loss: 0.678805, acc.: 53.91%] [G loss: 0.974194]\n",
      "epoch:3 step:3640 [D loss: 0.652506, acc.: 58.59%] [G loss: 0.798336]\n",
      "epoch:3 step:3641 [D loss: 0.674331, acc.: 60.16%] [G loss: 1.044478]\n",
      "epoch:3 step:3642 [D loss: 0.646895, acc.: 65.62%] [G loss: 0.966279]\n",
      "epoch:3 step:3643 [D loss: 0.630646, acc.: 64.06%] [G loss: 0.945042]\n",
      "epoch:3 step:3644 [D loss: 0.590410, acc.: 72.66%] [G loss: 1.023870]\n",
      "epoch:3 step:3645 [D loss: 0.613726, acc.: 67.97%] [G loss: 0.985057]\n",
      "epoch:3 step:3646 [D loss: 0.604882, acc.: 72.66%] [G loss: 1.010605]\n",
      "epoch:3 step:3647 [D loss: 0.701570, acc.: 57.03%] [G loss: 1.022700]\n",
      "epoch:3 step:3648 [D loss: 0.702412, acc.: 51.56%] [G loss: 0.982325]\n",
      "epoch:3 step:3649 [D loss: 0.593484, acc.: 66.41%] [G loss: 1.139005]\n",
      "epoch:3 step:3650 [D loss: 0.701304, acc.: 59.38%] [G loss: 0.995435]\n",
      "epoch:3 step:3651 [D loss: 0.684707, acc.: 60.16%] [G loss: 1.002485]\n",
      "epoch:3 step:3652 [D loss: 0.626850, acc.: 63.28%] [G loss: 0.952008]\n",
      "epoch:3 step:3653 [D loss: 0.606859, acc.: 67.19%] [G loss: 1.000514]\n",
      "epoch:3 step:3654 [D loss: 0.679583, acc.: 58.59%] [G loss: 0.956280]\n",
      "epoch:3 step:3655 [D loss: 0.704936, acc.: 50.78%] [G loss: 0.970836]\n",
      "epoch:3 step:3656 [D loss: 0.637011, acc.: 64.84%] [G loss: 1.008152]\n",
      "epoch:3 step:3657 [D loss: 0.611345, acc.: 67.97%] [G loss: 1.062837]\n",
      "epoch:3 step:3658 [D loss: 0.697751, acc.: 53.12%] [G loss: 0.931155]\n",
      "epoch:3 step:3659 [D loss: 0.644301, acc.: 64.06%] [G loss: 0.880892]\n",
      "epoch:3 step:3660 [D loss: 0.639324, acc.: 63.28%] [G loss: 0.892788]\n",
      "epoch:3 step:3661 [D loss: 0.690316, acc.: 55.47%] [G loss: 0.937374]\n",
      "epoch:3 step:3662 [D loss: 0.717210, acc.: 53.91%] [G loss: 0.864771]\n",
      "epoch:3 step:3663 [D loss: 0.673312, acc.: 61.72%] [G loss: 0.883974]\n",
      "epoch:3 step:3664 [D loss: 0.655421, acc.: 62.50%] [G loss: 0.961524]\n",
      "epoch:3 step:3665 [D loss: 0.595670, acc.: 69.53%] [G loss: 0.931287]\n",
      "epoch:3 step:3666 [D loss: 0.614252, acc.: 65.62%] [G loss: 1.060112]\n",
      "epoch:3 step:3667 [D loss: 0.702969, acc.: 56.25%] [G loss: 0.891303]\n",
      "epoch:3 step:3668 [D loss: 0.637896, acc.: 62.50%] [G loss: 0.960101]\n",
      "epoch:3 step:3669 [D loss: 0.694703, acc.: 55.47%] [G loss: 0.999455]\n",
      "epoch:3 step:3670 [D loss: 0.700050, acc.: 55.47%] [G loss: 0.928277]\n",
      "epoch:3 step:3671 [D loss: 0.696142, acc.: 53.91%] [G loss: 0.829601]\n",
      "epoch:3 step:3672 [D loss: 0.658836, acc.: 59.38%] [G loss: 0.856699]\n",
      "epoch:3 step:3673 [D loss: 0.655774, acc.: 61.72%] [G loss: 0.873581]\n",
      "epoch:3 step:3674 [D loss: 0.640491, acc.: 64.06%] [G loss: 0.956459]\n",
      "epoch:3 step:3675 [D loss: 0.641499, acc.: 63.28%] [G loss: 0.924784]\n",
      "epoch:3 step:3676 [D loss: 0.661429, acc.: 57.03%] [G loss: 0.909024]\n",
      "epoch:3 step:3677 [D loss: 0.617713, acc.: 64.84%] [G loss: 0.887298]\n",
      "epoch:3 step:3678 [D loss: 0.745814, acc.: 53.12%] [G loss: 0.897513]\n",
      "epoch:3 step:3679 [D loss: 0.739419, acc.: 48.44%] [G loss: 0.848986]\n",
      "epoch:3 step:3680 [D loss: 0.637349, acc.: 64.06%] [G loss: 0.878379]\n",
      "epoch:3 step:3681 [D loss: 0.720935, acc.: 49.22%] [G loss: 0.824337]\n",
      "epoch:3 step:3682 [D loss: 0.703860, acc.: 54.69%] [G loss: 0.779381]\n",
      "epoch:3 step:3683 [D loss: 0.618904, acc.: 67.97%] [G loss: 0.895563]\n",
      "epoch:3 step:3684 [D loss: 0.627774, acc.: 64.84%] [G loss: 0.949639]\n",
      "epoch:3 step:3685 [D loss: 0.649498, acc.: 60.94%] [G loss: 1.084015]\n",
      "epoch:3 step:3686 [D loss: 0.636329, acc.: 64.84%] [G loss: 0.997915]\n",
      "epoch:3 step:3687 [D loss: 0.650927, acc.: 61.72%] [G loss: 1.055711]\n",
      "epoch:3 step:3688 [D loss: 0.690678, acc.: 53.91%] [G loss: 0.956375]\n",
      "epoch:3 step:3689 [D loss: 0.703368, acc.: 55.47%] [G loss: 0.940014]\n",
      "epoch:3 step:3690 [D loss: 0.665575, acc.: 60.16%] [G loss: 0.958406]\n",
      "epoch:3 step:3691 [D loss: 0.686829, acc.: 54.69%] [G loss: 1.000740]\n",
      "epoch:3 step:3692 [D loss: 0.666273, acc.: 60.16%] [G loss: 0.892666]\n",
      "epoch:3 step:3693 [D loss: 0.654593, acc.: 60.94%] [G loss: 0.906326]\n",
      "epoch:3 step:3694 [D loss: 0.705088, acc.: 57.03%] [G loss: 0.998252]\n",
      "epoch:3 step:3695 [D loss: 0.645911, acc.: 63.28%] [G loss: 0.942293]\n",
      "epoch:3 step:3696 [D loss: 0.673965, acc.: 57.81%] [G loss: 0.977715]\n",
      "epoch:3 step:3697 [D loss: 0.625586, acc.: 67.19%] [G loss: 1.024058]\n",
      "epoch:3 step:3698 [D loss: 0.658763, acc.: 60.16%] [G loss: 0.939978]\n",
      "epoch:3 step:3699 [D loss: 0.685628, acc.: 57.03%] [G loss: 0.813185]\n",
      "epoch:3 step:3700 [D loss: 0.600897, acc.: 68.75%] [G loss: 1.109599]\n",
      "epoch:3 step:3701 [D loss: 0.605166, acc.: 67.19%] [G loss: 1.236031]\n",
      "epoch:3 step:3702 [D loss: 0.616610, acc.: 66.41%] [G loss: 0.917184]\n",
      "epoch:3 step:3703 [D loss: 0.731420, acc.: 50.00%] [G loss: 0.863432]\n",
      "epoch:3 step:3704 [D loss: 0.609580, acc.: 66.41%] [G loss: 0.919747]\n",
      "epoch:3 step:3705 [D loss: 0.652413, acc.: 62.50%] [G loss: 0.974837]\n",
      "epoch:3 step:3706 [D loss: 0.704654, acc.: 57.03%] [G loss: 0.867097]\n",
      "epoch:3 step:3707 [D loss: 0.655406, acc.: 56.25%] [G loss: 1.034426]\n",
      "epoch:3 step:3708 [D loss: 0.701751, acc.: 54.69%] [G loss: 0.922284]\n",
      "epoch:3 step:3709 [D loss: 0.651938, acc.: 63.28%] [G loss: 0.839721]\n",
      "epoch:3 step:3710 [D loss: 0.649682, acc.: 59.38%] [G loss: 1.039168]\n",
      "epoch:3 step:3711 [D loss: 0.625548, acc.: 71.09%] [G loss: 0.881769]\n",
      "epoch:3 step:3712 [D loss: 0.663657, acc.: 57.81%] [G loss: 1.025539]\n",
      "epoch:3 step:3713 [D loss: 0.659663, acc.: 59.38%] [G loss: 0.992716]\n",
      "epoch:3 step:3714 [D loss: 0.664006, acc.: 63.28%] [G loss: 0.879261]\n",
      "epoch:3 step:3715 [D loss: 0.668531, acc.: 61.72%] [G loss: 0.900626]\n",
      "epoch:3 step:3716 [D loss: 0.618127, acc.: 62.50%] [G loss: 1.011048]\n",
      "epoch:3 step:3717 [D loss: 0.710316, acc.: 53.12%] [G loss: 1.001850]\n",
      "epoch:3 step:3718 [D loss: 0.666367, acc.: 59.38%] [G loss: 0.965171]\n",
      "epoch:3 step:3719 [D loss: 0.694243, acc.: 55.47%] [G loss: 1.002873]\n",
      "epoch:3 step:3720 [D loss: 0.657730, acc.: 60.94%] [G loss: 0.928265]\n",
      "epoch:3 step:3721 [D loss: 0.667044, acc.: 62.50%] [G loss: 0.977663]\n",
      "epoch:3 step:3722 [D loss: 0.635956, acc.: 64.06%] [G loss: 1.005076]\n",
      "epoch:3 step:3723 [D loss: 0.652849, acc.: 61.72%] [G loss: 0.989867]\n",
      "epoch:3 step:3724 [D loss: 0.698216, acc.: 55.47%] [G loss: 0.947635]\n",
      "epoch:3 step:3725 [D loss: 0.605599, acc.: 66.41%] [G loss: 1.003725]\n",
      "epoch:3 step:3726 [D loss: 0.673898, acc.: 60.94%] [G loss: 0.959336]\n",
      "epoch:3 step:3727 [D loss: 0.658158, acc.: 64.06%] [G loss: 0.955165]\n",
      "epoch:3 step:3728 [D loss: 0.638397, acc.: 64.84%] [G loss: 0.932238]\n",
      "epoch:3 step:3729 [D loss: 0.624989, acc.: 64.84%] [G loss: 0.897957]\n",
      "epoch:3 step:3730 [D loss: 0.552883, acc.: 76.56%] [G loss: 1.050776]\n",
      "epoch:3 step:3731 [D loss: 0.808998, acc.: 37.50%] [G loss: 0.868402]\n",
      "epoch:3 step:3732 [D loss: 0.602475, acc.: 70.31%] [G loss: 0.998945]\n",
      "epoch:3 step:3733 [D loss: 0.571306, acc.: 71.09%] [G loss: 0.953512]\n",
      "epoch:3 step:3734 [D loss: 0.492599, acc.: 82.03%] [G loss: 1.033414]\n",
      "epoch:3 step:3735 [D loss: 0.652004, acc.: 59.38%] [G loss: 0.902765]\n",
      "epoch:3 step:3736 [D loss: 0.600025, acc.: 70.31%] [G loss: 1.024543]\n",
      "epoch:3 step:3737 [D loss: 0.593048, acc.: 71.09%] [G loss: 1.019944]\n",
      "epoch:3 step:3738 [D loss: 0.653510, acc.: 60.16%] [G loss: 0.926180]\n",
      "epoch:3 step:3739 [D loss: 0.836068, acc.: 51.56%] [G loss: 1.055498]\n",
      "epoch:3 step:3740 [D loss: 0.779550, acc.: 42.97%] [G loss: 0.858508]\n",
      "epoch:3 step:3741 [D loss: 0.559849, acc.: 70.31%] [G loss: 0.984898]\n",
      "epoch:3 step:3742 [D loss: 0.613143, acc.: 63.28%] [G loss: 1.036974]\n",
      "epoch:3 step:3743 [D loss: 0.686741, acc.: 58.59%] [G loss: 0.953005]\n",
      "epoch:3 step:3744 [D loss: 0.607831, acc.: 69.53%] [G loss: 1.046112]\n",
      "epoch:3 step:3745 [D loss: 0.641998, acc.: 61.72%] [G loss: 0.950532]\n",
      "epoch:3 step:3746 [D loss: 0.648874, acc.: 61.72%] [G loss: 1.043334]\n",
      "epoch:3 step:3747 [D loss: 0.506634, acc.: 78.91%] [G loss: 1.134822]\n",
      "epoch:3 step:3748 [D loss: 0.526016, acc.: 78.91%] [G loss: 1.157229]\n",
      "epoch:4 step:3749 [D loss: 0.775814, acc.: 48.44%] [G loss: 1.129210]\n",
      "epoch:4 step:3750 [D loss: 0.669159, acc.: 58.59%] [G loss: 0.932186]\n",
      "epoch:4 step:3751 [D loss: 0.656770, acc.: 60.94%] [G loss: 1.150511]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3752 [D loss: 0.670623, acc.: 57.03%] [G loss: 0.946754]\n",
      "epoch:4 step:3753 [D loss: 0.660641, acc.: 61.72%] [G loss: 1.019437]\n",
      "epoch:4 step:3754 [D loss: 0.674342, acc.: 60.16%] [G loss: 1.064646]\n",
      "epoch:4 step:3755 [D loss: 0.607901, acc.: 67.19%] [G loss: 1.084063]\n",
      "epoch:4 step:3756 [D loss: 0.613980, acc.: 65.62%] [G loss: 1.012736]\n",
      "epoch:4 step:3757 [D loss: 0.660720, acc.: 60.94%] [G loss: 1.058545]\n",
      "epoch:4 step:3758 [D loss: 0.639031, acc.: 64.06%] [G loss: 1.057247]\n",
      "epoch:4 step:3759 [D loss: 0.591240, acc.: 63.28%] [G loss: 1.141416]\n",
      "epoch:4 step:3760 [D loss: 0.759421, acc.: 50.78%] [G loss: 0.962631]\n",
      "epoch:4 step:3761 [D loss: 0.664522, acc.: 62.50%] [G loss: 1.088481]\n",
      "epoch:4 step:3762 [D loss: 0.624040, acc.: 61.72%] [G loss: 0.985877]\n",
      "epoch:4 step:3763 [D loss: 0.581696, acc.: 63.28%] [G loss: 0.992374]\n",
      "epoch:4 step:3764 [D loss: 0.624651, acc.: 63.28%] [G loss: 1.094710]\n",
      "epoch:4 step:3765 [D loss: 0.695851, acc.: 57.81%] [G loss: 0.948697]\n",
      "epoch:4 step:3766 [D loss: 0.732231, acc.: 47.66%] [G loss: 0.946468]\n",
      "epoch:4 step:3767 [D loss: 0.651037, acc.: 61.72%] [G loss: 1.172954]\n",
      "epoch:4 step:3768 [D loss: 0.904748, acc.: 35.16%] [G loss: 0.803974]\n",
      "epoch:4 step:3769 [D loss: 0.674357, acc.: 60.16%] [G loss: 0.970658]\n",
      "epoch:4 step:3770 [D loss: 0.682546, acc.: 58.59%] [G loss: 0.912665]\n",
      "epoch:4 step:3771 [D loss: 0.632443, acc.: 65.62%] [G loss: 0.916420]\n",
      "epoch:4 step:3772 [D loss: 0.650388, acc.: 64.06%] [G loss: 0.976930]\n",
      "epoch:4 step:3773 [D loss: 0.681280, acc.: 60.16%] [G loss: 1.012844]\n",
      "epoch:4 step:3774 [D loss: 0.671886, acc.: 61.72%] [G loss: 0.927186]\n",
      "epoch:4 step:3775 [D loss: 0.658938, acc.: 60.94%] [G loss: 0.994351]\n",
      "epoch:4 step:3776 [D loss: 0.709304, acc.: 50.78%] [G loss: 1.027991]\n",
      "epoch:4 step:3777 [D loss: 0.668981, acc.: 60.16%] [G loss: 0.980323]\n",
      "epoch:4 step:3778 [D loss: 0.653167, acc.: 60.94%] [G loss: 0.840765]\n",
      "epoch:4 step:3779 [D loss: 0.712985, acc.: 53.91%] [G loss: 0.970040]\n",
      "epoch:4 step:3780 [D loss: 0.667873, acc.: 62.50%] [G loss: 0.969797]\n",
      "epoch:4 step:3781 [D loss: 0.733244, acc.: 50.78%] [G loss: 0.907592]\n",
      "epoch:4 step:3782 [D loss: 0.580793, acc.: 71.09%] [G loss: 1.033610]\n",
      "epoch:4 step:3783 [D loss: 0.687483, acc.: 52.34%] [G loss: 0.909343]\n",
      "epoch:4 step:3784 [D loss: 0.573156, acc.: 67.97%] [G loss: 1.137223]\n",
      "epoch:4 step:3785 [D loss: 0.632015, acc.: 62.50%] [G loss: 0.962776]\n",
      "epoch:4 step:3786 [D loss: 0.640202, acc.: 63.28%] [G loss: 0.978372]\n",
      "epoch:4 step:3787 [D loss: 0.693598, acc.: 57.03%] [G loss: 1.011731]\n",
      "epoch:4 step:3788 [D loss: 0.636955, acc.: 62.50%] [G loss: 1.009444]\n",
      "epoch:4 step:3789 [D loss: 0.652348, acc.: 58.59%] [G loss: 1.012512]\n",
      "epoch:4 step:3790 [D loss: 0.563238, acc.: 71.09%] [G loss: 1.033658]\n",
      "epoch:4 step:3791 [D loss: 0.657079, acc.: 54.69%] [G loss: 0.976560]\n",
      "epoch:4 step:3792 [D loss: 0.692981, acc.: 58.59%] [G loss: 0.974941]\n",
      "epoch:4 step:3793 [D loss: 0.732603, acc.: 50.78%] [G loss: 0.858162]\n",
      "epoch:4 step:3794 [D loss: 0.681371, acc.: 57.81%] [G loss: 0.931431]\n",
      "epoch:4 step:3795 [D loss: 0.617103, acc.: 69.53%] [G loss: 1.035934]\n",
      "epoch:4 step:3796 [D loss: 0.637290, acc.: 65.62%] [G loss: 0.998931]\n",
      "epoch:4 step:3797 [D loss: 0.676939, acc.: 57.03%] [G loss: 0.994513]\n",
      "epoch:4 step:3798 [D loss: 0.581917, acc.: 69.53%] [G loss: 1.137777]\n",
      "epoch:4 step:3799 [D loss: 0.721185, acc.: 51.56%] [G loss: 1.013935]\n",
      "epoch:4 step:3800 [D loss: 0.656297, acc.: 55.47%] [G loss: 0.957310]\n",
      "##############\n",
      "[1.73763017 1.12839283 4.97150851 3.95626953 2.42463811 4.84691266\n",
      " 3.64315764 4.4234107  3.4282475  2.79788742]\n",
      "##########\n",
      "epoch:4 step:3801 [D loss: 0.708465, acc.: 53.12%] [G loss: 0.975388]\n",
      "epoch:4 step:3802 [D loss: 0.629878, acc.: 65.62%] [G loss: 0.968057]\n",
      "epoch:4 step:3803 [D loss: 0.625705, acc.: 64.06%] [G loss: 1.012209]\n",
      "epoch:4 step:3804 [D loss: 0.718580, acc.: 53.12%] [G loss: 0.890621]\n",
      "epoch:4 step:3805 [D loss: 0.643129, acc.: 60.16%] [G loss: 0.921685]\n",
      "epoch:4 step:3806 [D loss: 0.666527, acc.: 64.84%] [G loss: 0.957116]\n",
      "epoch:4 step:3807 [D loss: 0.660842, acc.: 60.16%] [G loss: 0.959111]\n",
      "epoch:4 step:3808 [D loss: 0.669902, acc.: 60.16%] [G loss: 0.948740]\n",
      "epoch:4 step:3809 [D loss: 0.661836, acc.: 58.59%] [G loss: 0.905746]\n",
      "epoch:4 step:3810 [D loss: 0.716003, acc.: 54.69%] [G loss: 0.884018]\n",
      "epoch:4 step:3811 [D loss: 0.690254, acc.: 54.69%] [G loss: 0.833642]\n",
      "epoch:4 step:3812 [D loss: 0.632485, acc.: 67.19%] [G loss: 0.908001]\n",
      "epoch:4 step:3813 [D loss: 0.644231, acc.: 58.59%] [G loss: 0.946514]\n",
      "epoch:4 step:3814 [D loss: 0.647178, acc.: 62.50%] [G loss: 0.881809]\n",
      "epoch:4 step:3815 [D loss: 0.636645, acc.: 65.62%] [G loss: 0.988335]\n",
      "epoch:4 step:3816 [D loss: 0.658295, acc.: 62.50%] [G loss: 0.931902]\n",
      "epoch:4 step:3817 [D loss: 0.674572, acc.: 57.81%] [G loss: 0.951031]\n",
      "epoch:4 step:3818 [D loss: 0.651132, acc.: 58.59%] [G loss: 0.948525]\n",
      "epoch:4 step:3819 [D loss: 0.629122, acc.: 70.31%] [G loss: 0.901159]\n",
      "epoch:4 step:3820 [D loss: 0.618051, acc.: 71.09%] [G loss: 1.035497]\n",
      "epoch:4 step:3821 [D loss: 0.751681, acc.: 50.78%] [G loss: 0.972560]\n",
      "epoch:4 step:3822 [D loss: 0.582571, acc.: 75.00%] [G loss: 1.026599]\n",
      "epoch:4 step:3823 [D loss: 0.646324, acc.: 66.41%] [G loss: 1.066669]\n",
      "epoch:4 step:3824 [D loss: 0.590581, acc.: 67.97%] [G loss: 1.063325]\n",
      "epoch:4 step:3825 [D loss: 0.563452, acc.: 75.00%] [G loss: 1.079999]\n",
      "epoch:4 step:3826 [D loss: 0.707243, acc.: 53.91%] [G loss: 1.109802]\n",
      "epoch:4 step:3827 [D loss: 0.682659, acc.: 61.72%] [G loss: 0.844357]\n",
      "epoch:4 step:3828 [D loss: 0.639162, acc.: 64.84%] [G loss: 0.897746]\n",
      "epoch:4 step:3829 [D loss: 0.708707, acc.: 53.91%] [G loss: 0.871259]\n",
      "epoch:4 step:3830 [D loss: 0.733940, acc.: 50.78%] [G loss: 0.895975]\n",
      "epoch:4 step:3831 [D loss: 0.674637, acc.: 60.94%] [G loss: 0.899475]\n",
      "epoch:4 step:3832 [D loss: 0.638363, acc.: 65.62%] [G loss: 0.881667]\n",
      "epoch:4 step:3833 [D loss: 0.731921, acc.: 55.47%] [G loss: 0.923944]\n",
      "epoch:4 step:3834 [D loss: 0.720325, acc.: 50.78%] [G loss: 0.865440]\n",
      "epoch:4 step:3835 [D loss: 0.700806, acc.: 54.69%] [G loss: 0.926163]\n",
      "epoch:4 step:3836 [D loss: 0.741314, acc.: 46.88%] [G loss: 0.879407]\n",
      "epoch:4 step:3837 [D loss: 0.721514, acc.: 50.78%] [G loss: 0.920978]\n",
      "epoch:4 step:3838 [D loss: 0.690919, acc.: 54.69%] [G loss: 0.965875]\n",
      "epoch:4 step:3839 [D loss: 0.679813, acc.: 55.47%] [G loss: 0.977145]\n",
      "epoch:4 step:3840 [D loss: 0.648272, acc.: 60.16%] [G loss: 0.992010]\n",
      "epoch:4 step:3841 [D loss: 0.685440, acc.: 54.69%] [G loss: 1.019542]\n",
      "epoch:4 step:3842 [D loss: 0.703821, acc.: 56.25%] [G loss: 0.985567]\n",
      "epoch:4 step:3843 [D loss: 0.673406, acc.: 53.12%] [G loss: 0.926283]\n",
      "epoch:4 step:3844 [D loss: 0.635200, acc.: 63.28%] [G loss: 0.972889]\n",
      "epoch:4 step:3845 [D loss: 0.623361, acc.: 60.94%] [G loss: 0.919042]\n",
      "epoch:4 step:3846 [D loss: 0.686410, acc.: 55.47%] [G loss: 0.851771]\n",
      "epoch:4 step:3847 [D loss: 0.757153, acc.: 43.75%] [G loss: 0.973423]\n",
      "epoch:4 step:3848 [D loss: 0.642610, acc.: 63.28%] [G loss: 0.892062]\n",
      "epoch:4 step:3849 [D loss: 0.710619, acc.: 56.25%] [G loss: 0.962262]\n",
      "epoch:4 step:3850 [D loss: 0.666202, acc.: 59.38%] [G loss: 0.941842]\n",
      "epoch:4 step:3851 [D loss: 0.562835, acc.: 71.88%] [G loss: 1.018585]\n",
      "epoch:4 step:3852 [D loss: 0.640258, acc.: 62.50%] [G loss: 0.997722]\n",
      "epoch:4 step:3853 [D loss: 0.657019, acc.: 60.16%] [G loss: 0.982011]\n",
      "epoch:4 step:3854 [D loss: 0.650122, acc.: 60.94%] [G loss: 1.041362]\n",
      "epoch:4 step:3855 [D loss: 0.649193, acc.: 67.97%] [G loss: 0.881773]\n",
      "epoch:4 step:3856 [D loss: 0.705000, acc.: 58.59%] [G loss: 0.944880]\n",
      "epoch:4 step:3857 [D loss: 0.713030, acc.: 49.22%] [G loss: 0.885831]\n",
      "epoch:4 step:3858 [D loss: 0.700381, acc.: 58.59%] [G loss: 0.880989]\n",
      "epoch:4 step:3859 [D loss: 0.678342, acc.: 60.16%] [G loss: 1.031966]\n",
      "epoch:4 step:3860 [D loss: 0.580549, acc.: 73.44%] [G loss: 1.006115]\n",
      "epoch:4 step:3861 [D loss: 0.687157, acc.: 61.72%] [G loss: 0.992697]\n",
      "epoch:4 step:3862 [D loss: 0.690851, acc.: 59.38%] [G loss: 0.930646]\n",
      "epoch:4 step:3863 [D loss: 0.668313, acc.: 62.50%] [G loss: 0.918781]\n",
      "epoch:4 step:3864 [D loss: 0.677938, acc.: 63.28%] [G loss: 0.979468]\n",
      "epoch:4 step:3865 [D loss: 0.591637, acc.: 67.97%] [G loss: 0.942835]\n",
      "epoch:4 step:3866 [D loss: 0.688170, acc.: 60.16%] [G loss: 0.956706]\n",
      "epoch:4 step:3867 [D loss: 0.680026, acc.: 58.59%] [G loss: 0.991893]\n",
      "epoch:4 step:3868 [D loss: 0.753214, acc.: 48.44%] [G loss: 0.948164]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3869 [D loss: 0.742442, acc.: 50.00%] [G loss: 0.807669]\n",
      "epoch:4 step:3870 [D loss: 0.684839, acc.: 55.47%] [G loss: 0.963678]\n",
      "epoch:4 step:3871 [D loss: 0.671360, acc.: 60.94%] [G loss: 1.030340]\n",
      "epoch:4 step:3872 [D loss: 0.649648, acc.: 65.62%] [G loss: 0.978140]\n",
      "epoch:4 step:3873 [D loss: 0.732489, acc.: 51.56%] [G loss: 0.896067]\n",
      "epoch:4 step:3874 [D loss: 0.701363, acc.: 57.03%] [G loss: 0.883563]\n",
      "epoch:4 step:3875 [D loss: 0.701936, acc.: 60.16%] [G loss: 1.008430]\n",
      "epoch:4 step:3876 [D loss: 0.680916, acc.: 59.38%] [G loss: 0.995681]\n",
      "epoch:4 step:3877 [D loss: 0.709628, acc.: 50.78%] [G loss: 0.907858]\n",
      "epoch:4 step:3878 [D loss: 0.648406, acc.: 64.06%] [G loss: 0.933474]\n",
      "epoch:4 step:3879 [D loss: 0.647962, acc.: 62.50%] [G loss: 1.008780]\n",
      "epoch:4 step:3880 [D loss: 0.648288, acc.: 62.50%] [G loss: 0.964911]\n",
      "epoch:4 step:3881 [D loss: 0.841912, acc.: 35.94%] [G loss: 0.889867]\n",
      "epoch:4 step:3882 [D loss: 0.711645, acc.: 53.12%] [G loss: 0.995393]\n",
      "epoch:4 step:3883 [D loss: 0.697812, acc.: 55.47%] [G loss: 0.952062]\n",
      "epoch:4 step:3884 [D loss: 0.659969, acc.: 59.38%] [G loss: 0.996562]\n",
      "epoch:4 step:3885 [D loss: 0.727743, acc.: 53.91%] [G loss: 0.888018]\n",
      "epoch:4 step:3886 [D loss: 0.658317, acc.: 63.28%] [G loss: 0.898863]\n",
      "epoch:4 step:3887 [D loss: 0.695477, acc.: 57.03%] [G loss: 0.968089]\n",
      "epoch:4 step:3888 [D loss: 0.624316, acc.: 67.97%] [G loss: 0.973597]\n",
      "epoch:4 step:3889 [D loss: 0.654600, acc.: 60.16%] [G loss: 1.002399]\n",
      "epoch:4 step:3890 [D loss: 0.660970, acc.: 60.94%] [G loss: 1.027891]\n",
      "epoch:4 step:3891 [D loss: 0.654108, acc.: 65.62%] [G loss: 0.956555]\n",
      "epoch:4 step:3892 [D loss: 0.652855, acc.: 60.94%] [G loss: 0.981526]\n",
      "epoch:4 step:3893 [D loss: 0.641023, acc.: 60.94%] [G loss: 0.817432]\n",
      "epoch:4 step:3894 [D loss: 0.677034, acc.: 57.03%] [G loss: 0.916245]\n",
      "epoch:4 step:3895 [D loss: 0.678959, acc.: 57.81%] [G loss: 1.017622]\n",
      "epoch:4 step:3896 [D loss: 0.694103, acc.: 55.47%] [G loss: 0.899656]\n",
      "epoch:4 step:3897 [D loss: 0.645414, acc.: 59.38%] [G loss: 1.067975]\n",
      "epoch:4 step:3898 [D loss: 0.692048, acc.: 59.38%] [G loss: 0.888431]\n",
      "epoch:4 step:3899 [D loss: 0.629573, acc.: 67.19%] [G loss: 0.922919]\n",
      "epoch:4 step:3900 [D loss: 0.645509, acc.: 61.72%] [G loss: 0.982866]\n",
      "epoch:4 step:3901 [D loss: 0.656456, acc.: 60.16%] [G loss: 1.053906]\n",
      "epoch:4 step:3902 [D loss: 0.636167, acc.: 62.50%] [G loss: 0.984195]\n",
      "epoch:4 step:3903 [D loss: 0.636962, acc.: 64.06%] [G loss: 0.912867]\n",
      "epoch:4 step:3904 [D loss: 0.643436, acc.: 63.28%] [G loss: 0.887773]\n",
      "epoch:4 step:3905 [D loss: 0.725764, acc.: 50.78%] [G loss: 0.945954]\n",
      "epoch:4 step:3906 [D loss: 0.664080, acc.: 58.59%] [G loss: 0.929345]\n",
      "epoch:4 step:3907 [D loss: 0.688096, acc.: 59.38%] [G loss: 1.053563]\n",
      "epoch:4 step:3908 [D loss: 0.748514, acc.: 53.91%] [G loss: 0.985055]\n",
      "epoch:4 step:3909 [D loss: 0.700765, acc.: 53.91%] [G loss: 0.879659]\n",
      "epoch:4 step:3910 [D loss: 0.556819, acc.: 78.12%] [G loss: 0.962572]\n",
      "epoch:4 step:3911 [D loss: 0.650403, acc.: 60.16%] [G loss: 0.951611]\n",
      "epoch:4 step:3912 [D loss: 0.686802, acc.: 54.69%] [G loss: 0.898734]\n",
      "epoch:4 step:3913 [D loss: 0.666556, acc.: 56.25%] [G loss: 1.027144]\n",
      "epoch:4 step:3914 [D loss: 0.640113, acc.: 64.84%] [G loss: 0.928029]\n",
      "epoch:4 step:3915 [D loss: 0.689849, acc.: 59.38%] [G loss: 0.949858]\n",
      "epoch:4 step:3916 [D loss: 0.596894, acc.: 69.53%] [G loss: 0.970736]\n",
      "epoch:4 step:3917 [D loss: 0.642514, acc.: 65.62%] [G loss: 1.022636]\n",
      "epoch:4 step:3918 [D loss: 0.620153, acc.: 63.28%] [G loss: 1.098070]\n",
      "epoch:4 step:3919 [D loss: 0.639314, acc.: 65.62%] [G loss: 1.024081]\n",
      "epoch:4 step:3920 [D loss: 0.614314, acc.: 63.28%] [G loss: 1.001434]\n",
      "epoch:4 step:3921 [D loss: 0.711002, acc.: 51.56%] [G loss: 0.842775]\n",
      "epoch:4 step:3922 [D loss: 0.679012, acc.: 59.38%] [G loss: 0.957069]\n",
      "epoch:4 step:3923 [D loss: 0.669118, acc.: 57.81%] [G loss: 0.922607]\n",
      "epoch:4 step:3924 [D loss: 0.656126, acc.: 61.72%] [G loss: 0.974846]\n",
      "epoch:4 step:3925 [D loss: 0.620442, acc.: 65.62%] [G loss: 0.998836]\n",
      "epoch:4 step:3926 [D loss: 0.583628, acc.: 67.19%] [G loss: 0.966475]\n",
      "epoch:4 step:3927 [D loss: 0.687788, acc.: 54.69%] [G loss: 0.892485]\n",
      "epoch:4 step:3928 [D loss: 0.675681, acc.: 60.16%] [G loss: 0.852799]\n",
      "epoch:4 step:3929 [D loss: 0.641733, acc.: 66.41%] [G loss: 0.859429]\n",
      "epoch:4 step:3930 [D loss: 0.724651, acc.: 51.56%] [G loss: 0.876573]\n",
      "epoch:4 step:3931 [D loss: 0.735516, acc.: 53.91%] [G loss: 0.870000]\n",
      "epoch:4 step:3932 [D loss: 0.672361, acc.: 61.72%] [G loss: 0.914727]\n",
      "epoch:4 step:3933 [D loss: 0.703954, acc.: 52.34%] [G loss: 0.856946]\n",
      "epoch:4 step:3934 [D loss: 0.707403, acc.: 53.91%] [G loss: 0.900897]\n",
      "epoch:4 step:3935 [D loss: 0.685690, acc.: 58.59%] [G loss: 0.881604]\n",
      "epoch:4 step:3936 [D loss: 0.659610, acc.: 59.38%] [G loss: 0.961594]\n",
      "epoch:4 step:3937 [D loss: 0.640232, acc.: 63.28%] [G loss: 1.019279]\n",
      "epoch:4 step:3938 [D loss: 0.684057, acc.: 54.69%] [G loss: 0.890673]\n",
      "epoch:4 step:3939 [D loss: 0.680679, acc.: 62.50%] [G loss: 0.895606]\n",
      "epoch:4 step:3940 [D loss: 0.671680, acc.: 56.25%] [G loss: 0.947109]\n",
      "epoch:4 step:3941 [D loss: 0.686789, acc.: 57.81%] [G loss: 1.059992]\n",
      "epoch:4 step:3942 [D loss: 0.612354, acc.: 67.97%] [G loss: 1.057477]\n",
      "epoch:4 step:3943 [D loss: 0.695988, acc.: 57.03%] [G loss: 0.948805]\n",
      "epoch:4 step:3944 [D loss: 0.685713, acc.: 62.50%] [G loss: 1.022701]\n",
      "epoch:4 step:3945 [D loss: 0.701952, acc.: 55.47%] [G loss: 0.969633]\n",
      "epoch:4 step:3946 [D loss: 0.649768, acc.: 57.03%] [G loss: 1.043942]\n",
      "epoch:4 step:3947 [D loss: 0.754350, acc.: 49.22%] [G loss: 0.962837]\n",
      "epoch:4 step:3948 [D loss: 0.716090, acc.: 51.56%] [G loss: 0.910483]\n",
      "epoch:4 step:3949 [D loss: 0.814933, acc.: 43.75%] [G loss: 0.931007]\n",
      "epoch:4 step:3950 [D loss: 0.692401, acc.: 59.38%] [G loss: 0.920663]\n",
      "epoch:4 step:3951 [D loss: 0.740058, acc.: 48.44%] [G loss: 0.948694]\n",
      "epoch:4 step:3952 [D loss: 0.720099, acc.: 53.91%] [G loss: 0.898041]\n",
      "epoch:4 step:3953 [D loss: 0.716350, acc.: 56.25%] [G loss: 0.771426]\n",
      "epoch:4 step:3954 [D loss: 0.639618, acc.: 66.41%] [G loss: 0.859560]\n",
      "epoch:4 step:3955 [D loss: 0.584964, acc.: 71.09%] [G loss: 1.051064]\n",
      "epoch:4 step:3956 [D loss: 0.580006, acc.: 71.88%] [G loss: 1.007431]\n",
      "epoch:4 step:3957 [D loss: 0.650171, acc.: 67.97%] [G loss: 1.031323]\n",
      "epoch:4 step:3958 [D loss: 0.687319, acc.: 56.25%] [G loss: 0.983852]\n",
      "epoch:4 step:3959 [D loss: 0.687325, acc.: 60.16%] [G loss: 0.953394]\n",
      "epoch:4 step:3960 [D loss: 0.723764, acc.: 52.34%] [G loss: 0.898106]\n",
      "epoch:4 step:3961 [D loss: 0.695509, acc.: 57.03%] [G loss: 0.930030]\n",
      "epoch:4 step:3962 [D loss: 0.674833, acc.: 58.59%] [G loss: 0.912068]\n",
      "epoch:4 step:3963 [D loss: 0.779557, acc.: 41.41%] [G loss: 0.917197]\n",
      "epoch:4 step:3964 [D loss: 0.640655, acc.: 55.47%] [G loss: 1.061525]\n",
      "epoch:4 step:3965 [D loss: 0.656244, acc.: 56.25%] [G loss: 0.923215]\n",
      "epoch:4 step:3966 [D loss: 0.581275, acc.: 74.22%] [G loss: 0.984930]\n",
      "epoch:4 step:3967 [D loss: 0.711088, acc.: 50.78%] [G loss: 0.793476]\n",
      "epoch:4 step:3968 [D loss: 0.764176, acc.: 50.00%] [G loss: 1.072651]\n",
      "epoch:4 step:3969 [D loss: 0.705640, acc.: 56.25%] [G loss: 0.905778]\n",
      "epoch:4 step:3970 [D loss: 0.698012, acc.: 57.03%] [G loss: 0.936002]\n",
      "epoch:4 step:3971 [D loss: 0.648243, acc.: 63.28%] [G loss: 0.984515]\n",
      "epoch:4 step:3972 [D loss: 0.699364, acc.: 55.47%] [G loss: 0.890495]\n",
      "epoch:4 step:3973 [D loss: 0.740023, acc.: 50.00%] [G loss: 0.936622]\n",
      "epoch:4 step:3974 [D loss: 0.696432, acc.: 54.69%] [G loss: 0.882968]\n",
      "epoch:4 step:3975 [D loss: 0.733395, acc.: 47.66%] [G loss: 1.013442]\n",
      "epoch:4 step:3976 [D loss: 0.721656, acc.: 53.12%] [G loss: 0.911764]\n",
      "epoch:4 step:3977 [D loss: 0.625480, acc.: 65.62%] [G loss: 0.948292]\n",
      "epoch:4 step:3978 [D loss: 0.610222, acc.: 68.75%] [G loss: 1.001009]\n",
      "epoch:4 step:3979 [D loss: 0.606336, acc.: 66.41%] [G loss: 1.009116]\n",
      "epoch:4 step:3980 [D loss: 0.549550, acc.: 75.78%] [G loss: 1.083152]\n",
      "epoch:4 step:3981 [D loss: 0.580059, acc.: 67.19%] [G loss: 1.131038]\n",
      "epoch:4 step:3982 [D loss: 0.670188, acc.: 57.81%] [G loss: 0.977009]\n",
      "epoch:4 step:3983 [D loss: 0.671353, acc.: 61.72%] [G loss: 0.921970]\n",
      "epoch:4 step:3984 [D loss: 0.653993, acc.: 62.50%] [G loss: 0.944499]\n",
      "epoch:4 step:3985 [D loss: 0.683398, acc.: 57.03%] [G loss: 0.988647]\n",
      "epoch:4 step:3986 [D loss: 0.682565, acc.: 53.91%] [G loss: 0.899092]\n",
      "epoch:4 step:3987 [D loss: 0.690951, acc.: 54.69%] [G loss: 0.919222]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3988 [D loss: 0.693314, acc.: 55.47%] [G loss: 0.872233]\n",
      "epoch:4 step:3989 [D loss: 0.700552, acc.: 62.50%] [G loss: 0.884088]\n",
      "epoch:4 step:3990 [D loss: 0.715695, acc.: 57.03%] [G loss: 0.914813]\n",
      "epoch:4 step:3991 [D loss: 0.687796, acc.: 56.25%] [G loss: 1.024591]\n",
      "epoch:4 step:3992 [D loss: 0.655859, acc.: 57.81%] [G loss: 0.953120]\n",
      "epoch:4 step:3993 [D loss: 0.634972, acc.: 64.84%] [G loss: 0.876931]\n",
      "epoch:4 step:3994 [D loss: 0.679790, acc.: 58.59%] [G loss: 0.972394]\n",
      "epoch:4 step:3995 [D loss: 0.712086, acc.: 49.22%] [G loss: 0.830747]\n",
      "epoch:4 step:3996 [D loss: 0.695283, acc.: 55.47%] [G loss: 0.879534]\n",
      "epoch:4 step:3997 [D loss: 0.720091, acc.: 50.78%] [G loss: 0.807277]\n",
      "epoch:4 step:3998 [D loss: 0.757242, acc.: 49.22%] [G loss: 0.795804]\n",
      "epoch:4 step:3999 [D loss: 0.723436, acc.: 50.78%] [G loss: 0.907366]\n",
      "epoch:4 step:4000 [D loss: 0.670356, acc.: 56.25%] [G loss: 0.916889]\n",
      "##############\n",
      "[1.85506452 0.88453838 5.15980732 3.98794724 2.25150449 4.84607906\n",
      " 3.59532166 4.10354742 3.4888821  2.88592109]\n",
      "##########\n",
      "epoch:4 step:4001 [D loss: 0.673643, acc.: 54.69%] [G loss: 0.861621]\n",
      "epoch:4 step:4002 [D loss: 0.607459, acc.: 67.97%] [G loss: 0.877850]\n",
      "epoch:4 step:4003 [D loss: 0.640876, acc.: 64.84%] [G loss: 0.949905]\n",
      "epoch:4 step:4004 [D loss: 0.710587, acc.: 58.59%] [G loss: 1.012130]\n",
      "epoch:4 step:4005 [D loss: 0.683128, acc.: 60.16%] [G loss: 0.924043]\n",
      "epoch:4 step:4006 [D loss: 0.665182, acc.: 57.03%] [G loss: 0.880992]\n",
      "epoch:4 step:4007 [D loss: 0.629008, acc.: 69.53%] [G loss: 0.927952]\n",
      "epoch:4 step:4008 [D loss: 0.639702, acc.: 60.94%] [G loss: 0.933489]\n",
      "epoch:4 step:4009 [D loss: 0.585544, acc.: 68.75%] [G loss: 0.955415]\n",
      "epoch:4 step:4010 [D loss: 0.679178, acc.: 60.16%] [G loss: 0.853702]\n",
      "epoch:4 step:4011 [D loss: 0.701347, acc.: 51.56%] [G loss: 0.933688]\n",
      "epoch:4 step:4012 [D loss: 0.671949, acc.: 57.03%] [G loss: 0.963080]\n",
      "epoch:4 step:4013 [D loss: 0.679285, acc.: 63.28%] [G loss: 0.866734]\n",
      "epoch:4 step:4014 [D loss: 0.708563, acc.: 60.94%] [G loss: 0.906494]\n",
      "epoch:4 step:4015 [D loss: 0.739124, acc.: 48.44%] [G loss: 0.844485]\n",
      "epoch:4 step:4016 [D loss: 0.720652, acc.: 51.56%] [G loss: 0.980065]\n",
      "epoch:4 step:4017 [D loss: 0.628060, acc.: 60.94%] [G loss: 1.007260]\n",
      "epoch:4 step:4018 [D loss: 0.637211, acc.: 64.06%] [G loss: 0.916777]\n",
      "epoch:4 step:4019 [D loss: 0.661670, acc.: 54.69%] [G loss: 0.950758]\n",
      "epoch:4 step:4020 [D loss: 0.636415, acc.: 64.06%] [G loss: 1.067025]\n",
      "epoch:4 step:4021 [D loss: 0.696115, acc.: 57.03%] [G loss: 0.914932]\n",
      "epoch:4 step:4022 [D loss: 0.708476, acc.: 53.91%] [G loss: 1.042732]\n",
      "epoch:4 step:4023 [D loss: 0.700438, acc.: 60.94%] [G loss: 0.873464]\n",
      "epoch:4 step:4024 [D loss: 0.680498, acc.: 57.81%] [G loss: 0.988372]\n",
      "epoch:4 step:4025 [D loss: 0.708817, acc.: 53.91%] [G loss: 0.969116]\n",
      "epoch:4 step:4026 [D loss: 0.725323, acc.: 46.09%] [G loss: 0.857325]\n",
      "epoch:4 step:4027 [D loss: 0.704431, acc.: 56.25%] [G loss: 0.916168]\n",
      "epoch:4 step:4028 [D loss: 0.575775, acc.: 68.75%] [G loss: 0.931254]\n",
      "epoch:4 step:4029 [D loss: 0.718069, acc.: 49.22%] [G loss: 0.974108]\n",
      "epoch:4 step:4030 [D loss: 0.673604, acc.: 57.81%] [G loss: 1.007182]\n",
      "epoch:4 step:4031 [D loss: 0.618153, acc.: 63.28%] [G loss: 0.923106]\n",
      "epoch:4 step:4032 [D loss: 0.611090, acc.: 68.75%] [G loss: 1.039183]\n",
      "epoch:4 step:4033 [D loss: 0.661202, acc.: 62.50%] [G loss: 0.902470]\n",
      "epoch:4 step:4034 [D loss: 0.611417, acc.: 66.41%] [G loss: 1.026603]\n",
      "epoch:4 step:4035 [D loss: 0.727530, acc.: 48.44%] [G loss: 0.860778]\n",
      "epoch:4 step:4036 [D loss: 0.654522, acc.: 62.50%] [G loss: 1.079223]\n",
      "epoch:4 step:4037 [D loss: 0.681333, acc.: 57.81%] [G loss: 0.941942]\n",
      "epoch:4 step:4038 [D loss: 0.738408, acc.: 50.78%] [G loss: 0.875432]\n",
      "epoch:4 step:4039 [D loss: 0.752046, acc.: 47.66%] [G loss: 0.924287]\n",
      "epoch:4 step:4040 [D loss: 0.716481, acc.: 51.56%] [G loss: 0.990035]\n",
      "epoch:4 step:4041 [D loss: 0.630264, acc.: 67.19%] [G loss: 0.953371]\n",
      "epoch:4 step:4042 [D loss: 0.598611, acc.: 67.19%] [G loss: 1.008239]\n",
      "epoch:4 step:4043 [D loss: 0.686842, acc.: 54.69%] [G loss: 1.004254]\n",
      "epoch:4 step:4044 [D loss: 0.603185, acc.: 67.19%] [G loss: 0.854222]\n",
      "epoch:4 step:4045 [D loss: 0.645463, acc.: 60.94%] [G loss: 0.952926]\n",
      "epoch:4 step:4046 [D loss: 0.671675, acc.: 64.84%] [G loss: 0.864746]\n",
      "epoch:4 step:4047 [D loss: 0.641168, acc.: 60.16%] [G loss: 0.928524]\n",
      "epoch:4 step:4048 [D loss: 0.696924, acc.: 56.25%] [G loss: 1.002645]\n",
      "epoch:4 step:4049 [D loss: 0.733471, acc.: 52.34%] [G loss: 0.884542]\n",
      "epoch:4 step:4050 [D loss: 0.620003, acc.: 67.19%] [G loss: 0.979568]\n",
      "epoch:4 step:4051 [D loss: 0.657292, acc.: 64.84%] [G loss: 0.896474]\n",
      "epoch:4 step:4052 [D loss: 0.636737, acc.: 61.72%] [G loss: 0.916030]\n",
      "epoch:4 step:4053 [D loss: 0.609378, acc.: 67.19%] [G loss: 0.980895]\n",
      "epoch:4 step:4054 [D loss: 0.661123, acc.: 57.81%] [G loss: 1.032881]\n",
      "epoch:4 step:4055 [D loss: 0.618510, acc.: 65.62%] [G loss: 1.048764]\n",
      "epoch:4 step:4056 [D loss: 0.667967, acc.: 61.72%] [G loss: 0.996068]\n",
      "epoch:4 step:4057 [D loss: 0.638896, acc.: 62.50%] [G loss: 0.881519]\n",
      "epoch:4 step:4058 [D loss: 0.657461, acc.: 59.38%] [G loss: 0.977479]\n",
      "epoch:4 step:4059 [D loss: 0.688764, acc.: 61.72%] [G loss: 1.012569]\n",
      "epoch:4 step:4060 [D loss: 0.691083, acc.: 54.69%] [G loss: 1.016807]\n",
      "epoch:4 step:4061 [D loss: 0.638778, acc.: 64.84%] [G loss: 1.045212]\n",
      "epoch:4 step:4062 [D loss: 0.617435, acc.: 64.84%] [G loss: 1.185812]\n",
      "epoch:4 step:4063 [D loss: 0.580282, acc.: 71.88%] [G loss: 1.031998]\n",
      "epoch:4 step:4064 [D loss: 0.699399, acc.: 54.69%] [G loss: 1.102695]\n",
      "epoch:4 step:4065 [D loss: 0.699578, acc.: 55.47%] [G loss: 0.861297]\n",
      "epoch:4 step:4066 [D loss: 0.640660, acc.: 65.62%] [G loss: 0.930374]\n",
      "epoch:4 step:4067 [D loss: 0.673048, acc.: 53.91%] [G loss: 0.924860]\n",
      "epoch:4 step:4068 [D loss: 0.744452, acc.: 48.44%] [G loss: 0.949151]\n",
      "epoch:4 step:4069 [D loss: 0.647471, acc.: 60.94%] [G loss: 0.927835]\n",
      "epoch:4 step:4070 [D loss: 0.701523, acc.: 57.81%] [G loss: 1.067506]\n",
      "epoch:4 step:4071 [D loss: 0.688230, acc.: 56.25%] [G loss: 0.897725]\n",
      "epoch:4 step:4072 [D loss: 0.690806, acc.: 52.34%] [G loss: 0.976271]\n",
      "epoch:4 step:4073 [D loss: 0.672797, acc.: 57.81%] [G loss: 0.932027]\n",
      "epoch:4 step:4074 [D loss: 0.677416, acc.: 58.59%] [G loss: 0.882643]\n",
      "epoch:4 step:4075 [D loss: 0.621213, acc.: 65.62%] [G loss: 1.022759]\n",
      "epoch:4 step:4076 [D loss: 0.618978, acc.: 65.62%] [G loss: 0.960633]\n",
      "epoch:4 step:4077 [D loss: 0.646726, acc.: 58.59%] [G loss: 0.911207]\n",
      "epoch:4 step:4078 [D loss: 0.628644, acc.: 64.06%] [G loss: 0.951651]\n",
      "epoch:4 step:4079 [D loss: 0.653501, acc.: 61.72%] [G loss: 0.888785]\n",
      "epoch:4 step:4080 [D loss: 0.677605, acc.: 59.38%] [G loss: 0.947873]\n",
      "epoch:4 step:4081 [D loss: 0.663617, acc.: 60.16%] [G loss: 0.936072]\n",
      "epoch:4 step:4082 [D loss: 0.715123, acc.: 53.12%] [G loss: 0.960023]\n",
      "epoch:4 step:4083 [D loss: 0.722492, acc.: 50.78%] [G loss: 0.853200]\n",
      "epoch:4 step:4084 [D loss: 0.665427, acc.: 57.81%] [G loss: 0.931793]\n",
      "epoch:4 step:4085 [D loss: 0.598342, acc.: 69.53%] [G loss: 0.966465]\n",
      "epoch:4 step:4086 [D loss: 0.630994, acc.: 64.06%] [G loss: 0.988544]\n",
      "epoch:4 step:4087 [D loss: 0.684102, acc.: 60.16%] [G loss: 0.926848]\n",
      "epoch:4 step:4088 [D loss: 0.670902, acc.: 55.47%] [G loss: 0.884759]\n",
      "epoch:4 step:4089 [D loss: 0.669816, acc.: 64.06%] [G loss: 0.946162]\n",
      "epoch:4 step:4090 [D loss: 0.664996, acc.: 62.50%] [G loss: 1.011135]\n",
      "epoch:4 step:4091 [D loss: 0.611722, acc.: 66.41%] [G loss: 1.113695]\n",
      "epoch:4 step:4092 [D loss: 0.611729, acc.: 65.62%] [G loss: 0.971841]\n",
      "epoch:4 step:4093 [D loss: 0.619272, acc.: 66.41%] [G loss: 0.903438]\n",
      "epoch:4 step:4094 [D loss: 0.637028, acc.: 64.06%] [G loss: 0.792912]\n",
      "epoch:4 step:4095 [D loss: 0.671458, acc.: 57.81%] [G loss: 1.005595]\n",
      "epoch:4 step:4096 [D loss: 0.739034, acc.: 53.12%] [G loss: 1.000106]\n",
      "epoch:4 step:4097 [D loss: 0.746805, acc.: 50.00%] [G loss: 0.950169]\n",
      "epoch:4 step:4098 [D loss: 0.611000, acc.: 67.97%] [G loss: 0.998278]\n",
      "epoch:4 step:4099 [D loss: 0.655921, acc.: 60.16%] [G loss: 0.981178]\n",
      "epoch:4 step:4100 [D loss: 0.725112, acc.: 55.47%] [G loss: 1.034475]\n",
      "epoch:4 step:4101 [D loss: 0.732939, acc.: 53.91%] [G loss: 0.924775]\n",
      "epoch:4 step:4102 [D loss: 0.648592, acc.: 64.84%] [G loss: 0.930610]\n",
      "epoch:4 step:4103 [D loss: 0.765299, acc.: 47.66%] [G loss: 0.871774]\n",
      "epoch:4 step:4104 [D loss: 0.735080, acc.: 52.34%] [G loss: 0.990198]\n",
      "epoch:4 step:4105 [D loss: 0.718146, acc.: 49.22%] [G loss: 0.808180]\n",
      "epoch:4 step:4106 [D loss: 0.652277, acc.: 62.50%] [G loss: 0.985660]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4107 [D loss: 0.615803, acc.: 65.62%] [G loss: 1.032497]\n",
      "epoch:4 step:4108 [D loss: 0.696573, acc.: 54.69%] [G loss: 0.991036]\n",
      "epoch:4 step:4109 [D loss: 0.698832, acc.: 53.91%] [G loss: 0.886771]\n",
      "epoch:4 step:4110 [D loss: 0.713381, acc.: 56.25%] [G loss: 0.911040]\n",
      "epoch:4 step:4111 [D loss: 0.687640, acc.: 58.59%] [G loss: 0.830753]\n",
      "epoch:4 step:4112 [D loss: 0.693794, acc.: 60.16%] [G loss: 0.959409]\n",
      "epoch:4 step:4113 [D loss: 0.691626, acc.: 55.47%] [G loss: 0.966342]\n",
      "epoch:4 step:4114 [D loss: 0.701125, acc.: 55.47%] [G loss: 0.916434]\n",
      "epoch:4 step:4115 [D loss: 0.691847, acc.: 56.25%] [G loss: 0.875466]\n",
      "epoch:4 step:4116 [D loss: 0.630283, acc.: 64.84%] [G loss: 0.914117]\n",
      "epoch:4 step:4117 [D loss: 0.634154, acc.: 64.84%] [G loss: 0.990359]\n",
      "epoch:4 step:4118 [D loss: 0.628830, acc.: 62.50%] [G loss: 0.885988]\n",
      "epoch:4 step:4119 [D loss: 0.623975, acc.: 64.06%] [G loss: 0.965142]\n",
      "epoch:4 step:4120 [D loss: 0.631385, acc.: 64.06%] [G loss: 0.929420]\n",
      "epoch:4 step:4121 [D loss: 0.764630, acc.: 46.88%] [G loss: 0.983235]\n",
      "epoch:4 step:4122 [D loss: 0.682273, acc.: 58.59%] [G loss: 0.978790]\n",
      "epoch:4 step:4123 [D loss: 0.717043, acc.: 50.78%] [G loss: 0.845494]\n",
      "epoch:4 step:4124 [D loss: 0.712828, acc.: 56.25%] [G loss: 0.967782]\n",
      "epoch:4 step:4125 [D loss: 0.724724, acc.: 53.12%] [G loss: 0.962451]\n",
      "epoch:4 step:4126 [D loss: 0.700000, acc.: 57.81%] [G loss: 0.874565]\n",
      "epoch:4 step:4127 [D loss: 0.673431, acc.: 60.16%] [G loss: 0.958036]\n",
      "epoch:4 step:4128 [D loss: 0.632608, acc.: 62.50%] [G loss: 1.051406]\n",
      "epoch:4 step:4129 [D loss: 0.599075, acc.: 71.09%] [G loss: 0.937052]\n",
      "epoch:4 step:4130 [D loss: 0.663107, acc.: 58.59%] [G loss: 0.984856]\n",
      "epoch:4 step:4131 [D loss: 0.733896, acc.: 51.56%] [G loss: 0.913189]\n",
      "epoch:4 step:4132 [D loss: 0.652281, acc.: 64.84%] [G loss: 1.055967]\n",
      "epoch:4 step:4133 [D loss: 0.600842, acc.: 65.62%] [G loss: 1.019228]\n",
      "epoch:4 step:4134 [D loss: 0.712121, acc.: 55.47%] [G loss: 0.917923]\n",
      "epoch:4 step:4135 [D loss: 0.661269, acc.: 64.84%] [G loss: 0.911116]\n",
      "epoch:4 step:4136 [D loss: 0.696308, acc.: 54.69%] [G loss: 0.903254]\n",
      "epoch:4 step:4137 [D loss: 0.648618, acc.: 62.50%] [G loss: 0.894224]\n",
      "epoch:4 step:4138 [D loss: 0.609812, acc.: 65.62%] [G loss: 0.940928]\n",
      "epoch:4 step:4139 [D loss: 0.672149, acc.: 64.06%] [G loss: 0.924360]\n",
      "epoch:4 step:4140 [D loss: 0.636912, acc.: 61.72%] [G loss: 0.909134]\n",
      "epoch:4 step:4141 [D loss: 0.732822, acc.: 55.47%] [G loss: 0.836214]\n",
      "epoch:4 step:4142 [D loss: 0.657714, acc.: 63.28%] [G loss: 0.941823]\n",
      "epoch:4 step:4143 [D loss: 0.703645, acc.: 57.81%] [G loss: 0.821076]\n",
      "epoch:4 step:4144 [D loss: 0.697595, acc.: 54.69%] [G loss: 0.964531]\n",
      "epoch:4 step:4145 [D loss: 0.672011, acc.: 53.91%] [G loss: 1.057938]\n",
      "epoch:4 step:4146 [D loss: 0.656385, acc.: 58.59%] [G loss: 0.847121]\n",
      "epoch:4 step:4147 [D loss: 0.610418, acc.: 67.97%] [G loss: 1.094640]\n",
      "epoch:4 step:4148 [D loss: 0.786088, acc.: 42.97%] [G loss: 0.966289]\n",
      "epoch:4 step:4149 [D loss: 0.652668, acc.: 62.50%] [G loss: 1.081511]\n",
      "epoch:4 step:4150 [D loss: 0.635258, acc.: 62.50%] [G loss: 0.947356]\n",
      "epoch:4 step:4151 [D loss: 0.646002, acc.: 62.50%] [G loss: 0.880956]\n",
      "epoch:4 step:4152 [D loss: 0.641416, acc.: 62.50%] [G loss: 0.957360]\n",
      "epoch:4 step:4153 [D loss: 0.625338, acc.: 62.50%] [G loss: 0.915089]\n",
      "epoch:4 step:4154 [D loss: 0.641302, acc.: 60.94%] [G loss: 1.074134]\n",
      "epoch:4 step:4155 [D loss: 0.653634, acc.: 64.06%] [G loss: 0.994194]\n",
      "epoch:4 step:4156 [D loss: 0.663902, acc.: 57.81%] [G loss: 0.997903]\n",
      "epoch:4 step:4157 [D loss: 0.728494, acc.: 51.56%] [G loss: 0.853440]\n",
      "epoch:4 step:4158 [D loss: 0.647902, acc.: 64.84%] [G loss: 1.066392]\n",
      "epoch:4 step:4159 [D loss: 0.631137, acc.: 63.28%] [G loss: 0.927399]\n",
      "epoch:4 step:4160 [D loss: 0.673457, acc.: 62.50%] [G loss: 1.014974]\n",
      "epoch:4 step:4161 [D loss: 0.695030, acc.: 54.69%] [G loss: 0.979473]\n",
      "epoch:4 step:4162 [D loss: 0.732986, acc.: 50.78%] [G loss: 0.848584]\n",
      "epoch:4 step:4163 [D loss: 0.660557, acc.: 60.94%] [G loss: 0.938430]\n",
      "epoch:4 step:4164 [D loss: 0.657436, acc.: 60.16%] [G loss: 0.948522]\n",
      "epoch:4 step:4165 [D loss: 0.682618, acc.: 60.94%] [G loss: 0.963977]\n",
      "epoch:4 step:4166 [D loss: 0.620667, acc.: 64.84%] [G loss: 0.991426]\n",
      "epoch:4 step:4167 [D loss: 0.636004, acc.: 64.84%] [G loss: 1.026102]\n",
      "epoch:4 step:4168 [D loss: 0.621689, acc.: 67.97%] [G loss: 1.052220]\n",
      "epoch:4 step:4169 [D loss: 0.734179, acc.: 56.25%] [G loss: 0.878323]\n",
      "epoch:4 step:4170 [D loss: 0.655927, acc.: 71.09%] [G loss: 0.989456]\n",
      "epoch:4 step:4171 [D loss: 0.645249, acc.: 57.03%] [G loss: 0.897740]\n",
      "epoch:4 step:4172 [D loss: 0.669825, acc.: 62.50%] [G loss: 0.877180]\n",
      "epoch:4 step:4173 [D loss: 0.716756, acc.: 56.25%] [G loss: 0.973476]\n",
      "epoch:4 step:4174 [D loss: 0.655364, acc.: 61.72%] [G loss: 0.832753]\n",
      "epoch:4 step:4175 [D loss: 0.732260, acc.: 55.47%] [G loss: 0.841357]\n",
      "epoch:4 step:4176 [D loss: 0.622983, acc.: 64.06%] [G loss: 1.025438]\n",
      "epoch:4 step:4177 [D loss: 0.642521, acc.: 59.38%] [G loss: 1.034509]\n",
      "epoch:4 step:4178 [D loss: 0.630046, acc.: 65.62%] [G loss: 1.082457]\n",
      "epoch:4 step:4179 [D loss: 0.663878, acc.: 59.38%] [G loss: 1.030824]\n",
      "epoch:4 step:4180 [D loss: 0.791637, acc.: 47.66%] [G loss: 0.846371]\n",
      "epoch:4 step:4181 [D loss: 0.639922, acc.: 62.50%] [G loss: 1.038153]\n",
      "epoch:4 step:4182 [D loss: 0.631690, acc.: 68.75%] [G loss: 0.898077]\n",
      "epoch:4 step:4183 [D loss: 0.661019, acc.: 65.62%] [G loss: 0.986856]\n",
      "epoch:4 step:4184 [D loss: 0.661066, acc.: 58.59%] [G loss: 0.901526]\n",
      "epoch:4 step:4185 [D loss: 0.716242, acc.: 50.78%] [G loss: 0.881861]\n",
      "epoch:4 step:4186 [D loss: 0.621534, acc.: 67.97%] [G loss: 0.940209]\n",
      "epoch:4 step:4187 [D loss: 0.686211, acc.: 58.59%] [G loss: 0.942545]\n",
      "epoch:4 step:4188 [D loss: 0.680277, acc.: 59.38%] [G loss: 0.921022]\n",
      "epoch:4 step:4189 [D loss: 0.758470, acc.: 46.09%] [G loss: 0.868401]\n",
      "epoch:4 step:4190 [D loss: 0.735238, acc.: 53.91%] [G loss: 0.823040]\n",
      "epoch:4 step:4191 [D loss: 0.645323, acc.: 66.41%] [G loss: 0.932329]\n",
      "epoch:4 step:4192 [D loss: 0.652968, acc.: 64.06%] [G loss: 0.861421]\n",
      "epoch:4 step:4193 [D loss: 0.670106, acc.: 53.91%] [G loss: 0.899944]\n",
      "epoch:4 step:4194 [D loss: 0.697442, acc.: 52.34%] [G loss: 0.804925]\n",
      "epoch:4 step:4195 [D loss: 0.655429, acc.: 57.03%] [G loss: 0.900404]\n",
      "epoch:4 step:4196 [D loss: 0.739156, acc.: 45.31%] [G loss: 0.870824]\n",
      "epoch:4 step:4197 [D loss: 0.793851, acc.: 41.41%] [G loss: 0.991703]\n",
      "epoch:4 step:4198 [D loss: 0.668259, acc.: 60.16%] [G loss: 0.924796]\n",
      "epoch:4 step:4199 [D loss: 0.650022, acc.: 57.81%] [G loss: 1.042680]\n",
      "epoch:4 step:4200 [D loss: 0.671426, acc.: 59.38%] [G loss: 0.929136]\n",
      "##############\n",
      "[2.09306651 0.74143369 5.25030301 4.00598887 2.45233959 5.07992105\n",
      " 3.44860955 4.05312206 3.68228996 2.86624679]\n",
      "##########\n",
      "epoch:4 step:4201 [D loss: 0.575420, acc.: 68.75%] [G loss: 0.946667]\n",
      "epoch:4 step:4202 [D loss: 0.644580, acc.: 61.72%] [G loss: 0.969620]\n",
      "epoch:4 step:4203 [D loss: 0.573067, acc.: 66.41%] [G loss: 1.086063]\n",
      "epoch:4 step:4204 [D loss: 0.638984, acc.: 60.94%] [G loss: 1.055123]\n",
      "epoch:4 step:4205 [D loss: 0.643603, acc.: 59.38%] [G loss: 0.933454]\n",
      "epoch:4 step:4206 [D loss: 0.699958, acc.: 57.03%] [G loss: 1.024472]\n",
      "epoch:4 step:4207 [D loss: 0.724622, acc.: 55.47%] [G loss: 0.899383]\n",
      "epoch:4 step:4208 [D loss: 0.690112, acc.: 55.47%] [G loss: 0.896793]\n",
      "epoch:4 step:4209 [D loss: 0.675073, acc.: 56.25%] [G loss: 0.959786]\n",
      "epoch:4 step:4210 [D loss: 0.681929, acc.: 58.59%] [G loss: 0.939957]\n",
      "epoch:4 step:4211 [D loss: 0.667090, acc.: 58.59%] [G loss: 0.962906]\n",
      "epoch:4 step:4212 [D loss: 0.637636, acc.: 61.72%] [G loss: 0.995759]\n",
      "epoch:4 step:4213 [D loss: 0.728656, acc.: 53.12%] [G loss: 0.837817]\n",
      "epoch:4 step:4214 [D loss: 0.661208, acc.: 59.38%] [G loss: 1.018048]\n",
      "epoch:4 step:4215 [D loss: 0.697175, acc.: 57.03%] [G loss: 0.991771]\n",
      "epoch:4 step:4216 [D loss: 0.669950, acc.: 60.16%] [G loss: 0.879855]\n",
      "epoch:4 step:4217 [D loss: 0.614099, acc.: 67.97%] [G loss: 0.903954]\n",
      "epoch:4 step:4218 [D loss: 0.690409, acc.: 58.59%] [G loss: 0.897333]\n",
      "epoch:4 step:4219 [D loss: 0.639104, acc.: 64.06%] [G loss: 0.952851]\n",
      "epoch:4 step:4220 [D loss: 0.654797, acc.: 60.94%] [G loss: 0.935703]\n",
      "epoch:4 step:4221 [D loss: 0.816915, acc.: 39.84%] [G loss: 0.892228]\n",
      "epoch:4 step:4222 [D loss: 0.781812, acc.: 44.53%] [G loss: 0.893951]\n",
      "epoch:4 step:4223 [D loss: 0.697416, acc.: 56.25%] [G loss: 0.962144]\n",
      "epoch:4 step:4224 [D loss: 0.668562, acc.: 57.03%] [G loss: 0.912265]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4225 [D loss: 0.648446, acc.: 63.28%] [G loss: 0.942279]\n",
      "epoch:4 step:4226 [D loss: 0.686730, acc.: 57.03%] [G loss: 0.833390]\n",
      "epoch:4 step:4227 [D loss: 0.770285, acc.: 46.09%] [G loss: 0.804453]\n",
      "epoch:4 step:4228 [D loss: 0.660722, acc.: 59.38%] [G loss: 0.892603]\n",
      "epoch:4 step:4229 [D loss: 0.655057, acc.: 64.84%] [G loss: 0.926287]\n",
      "epoch:4 step:4230 [D loss: 0.694848, acc.: 57.03%] [G loss: 0.834658]\n",
      "epoch:4 step:4231 [D loss: 0.713320, acc.: 53.91%] [G loss: 0.936174]\n",
      "epoch:4 step:4232 [D loss: 0.595577, acc.: 68.75%] [G loss: 0.915832]\n",
      "epoch:4 step:4233 [D loss: 0.680545, acc.: 53.91%] [G loss: 0.862194]\n",
      "epoch:4 step:4234 [D loss: 0.732811, acc.: 53.91%] [G loss: 0.873924]\n",
      "epoch:4 step:4235 [D loss: 0.680040, acc.: 57.81%] [G loss: 0.951226]\n",
      "epoch:4 step:4236 [D loss: 0.684712, acc.: 57.81%] [G loss: 0.834063]\n",
      "epoch:4 step:4237 [D loss: 0.668710, acc.: 61.72%] [G loss: 0.989208]\n",
      "epoch:4 step:4238 [D loss: 0.682680, acc.: 60.94%] [G loss: 0.971188]\n",
      "epoch:4 step:4239 [D loss: 0.655317, acc.: 63.28%] [G loss: 0.943026]\n",
      "epoch:4 step:4240 [D loss: 0.686512, acc.: 57.03%] [G loss: 1.013475]\n",
      "epoch:4 step:4241 [D loss: 0.619608, acc.: 67.97%] [G loss: 0.980591]\n",
      "epoch:4 step:4242 [D loss: 0.608171, acc.: 66.41%] [G loss: 0.931580]\n",
      "epoch:4 step:4243 [D loss: 0.642808, acc.: 64.06%] [G loss: 0.918114]\n",
      "epoch:4 step:4244 [D loss: 0.698638, acc.: 60.16%] [G loss: 0.961673]\n",
      "epoch:4 step:4245 [D loss: 0.703453, acc.: 57.81%] [G loss: 0.894849]\n",
      "epoch:4 step:4246 [D loss: 0.613591, acc.: 67.97%] [G loss: 0.940344]\n",
      "epoch:4 step:4247 [D loss: 0.659230, acc.: 64.84%] [G loss: 0.942303]\n",
      "epoch:4 step:4248 [D loss: 0.692495, acc.: 57.81%] [G loss: 1.125104]\n",
      "epoch:4 step:4249 [D loss: 0.690415, acc.: 58.59%] [G loss: 1.045654]\n",
      "epoch:4 step:4250 [D loss: 0.705271, acc.: 53.12%] [G loss: 0.936008]\n",
      "epoch:4 step:4251 [D loss: 0.663830, acc.: 59.38%] [G loss: 0.877820]\n",
      "epoch:4 step:4252 [D loss: 0.659306, acc.: 58.59%] [G loss: 0.901112]\n",
      "epoch:4 step:4253 [D loss: 0.646820, acc.: 63.28%] [G loss: 0.924478]\n",
      "epoch:4 step:4254 [D loss: 0.683695, acc.: 53.12%] [G loss: 1.075569]\n",
      "epoch:4 step:4255 [D loss: 0.747991, acc.: 51.56%] [G loss: 0.835983]\n",
      "epoch:4 step:4256 [D loss: 0.682171, acc.: 58.59%] [G loss: 0.943672]\n",
      "epoch:4 step:4257 [D loss: 0.707732, acc.: 56.25%] [G loss: 0.910917]\n",
      "epoch:4 step:4258 [D loss: 0.666369, acc.: 60.94%] [G loss: 0.934264]\n",
      "epoch:4 step:4259 [D loss: 0.687216, acc.: 60.16%] [G loss: 1.021550]\n",
      "epoch:4 step:4260 [D loss: 0.681442, acc.: 57.81%] [G loss: 0.946476]\n",
      "epoch:4 step:4261 [D loss: 0.649820, acc.: 66.41%] [G loss: 0.979401]\n",
      "epoch:4 step:4262 [D loss: 0.650573, acc.: 58.59%] [G loss: 1.052454]\n",
      "epoch:4 step:4263 [D loss: 0.642668, acc.: 59.38%] [G loss: 0.991262]\n",
      "epoch:4 step:4264 [D loss: 0.645325, acc.: 61.72%] [G loss: 0.932337]\n",
      "epoch:4 step:4265 [D loss: 0.658909, acc.: 64.06%] [G loss: 1.017730]\n",
      "epoch:4 step:4266 [D loss: 0.718369, acc.: 50.00%] [G loss: 0.946630]\n",
      "epoch:4 step:4267 [D loss: 0.670853, acc.: 60.16%] [G loss: 0.876730]\n",
      "epoch:4 step:4268 [D loss: 0.679966, acc.: 56.25%] [G loss: 0.986309]\n",
      "epoch:4 step:4269 [D loss: 0.654605, acc.: 57.03%] [G loss: 0.927615]\n",
      "epoch:4 step:4270 [D loss: 0.681170, acc.: 58.59%] [G loss: 0.856887]\n",
      "epoch:4 step:4271 [D loss: 0.629611, acc.: 64.06%] [G loss: 0.896385]\n",
      "epoch:4 step:4272 [D loss: 0.670100, acc.: 60.16%] [G loss: 0.965892]\n",
      "epoch:4 step:4273 [D loss: 0.651510, acc.: 60.94%] [G loss: 0.971498]\n",
      "epoch:4 step:4274 [D loss: 0.704523, acc.: 53.91%] [G loss: 0.913896]\n",
      "epoch:4 step:4275 [D loss: 0.669007, acc.: 63.28%] [G loss: 0.838731]\n",
      "epoch:4 step:4276 [D loss: 0.656104, acc.: 57.03%] [G loss: 0.900490]\n",
      "epoch:4 step:4277 [D loss: 0.701640, acc.: 52.34%] [G loss: 0.915073]\n",
      "epoch:4 step:4278 [D loss: 0.673116, acc.: 60.16%] [G loss: 0.899772]\n",
      "epoch:4 step:4279 [D loss: 0.641237, acc.: 63.28%] [G loss: 0.894399]\n",
      "epoch:4 step:4280 [D loss: 0.631223, acc.: 61.72%] [G loss: 1.058661]\n",
      "epoch:4 step:4281 [D loss: 0.708226, acc.: 57.03%] [G loss: 0.946346]\n",
      "epoch:4 step:4282 [D loss: 0.685319, acc.: 55.47%] [G loss: 0.933328]\n",
      "epoch:4 step:4283 [D loss: 0.647067, acc.: 62.50%] [G loss: 0.869593]\n",
      "epoch:4 step:4284 [D loss: 0.618270, acc.: 63.28%] [G loss: 0.874657]\n",
      "epoch:4 step:4285 [D loss: 0.689352, acc.: 53.12%] [G loss: 0.915702]\n",
      "epoch:4 step:4286 [D loss: 0.681698, acc.: 60.94%] [G loss: 0.866205]\n",
      "epoch:4 step:4287 [D loss: 0.651314, acc.: 60.16%] [G loss: 0.912494]\n",
      "epoch:4 step:4288 [D loss: 0.632324, acc.: 67.19%] [G loss: 0.842124]\n",
      "epoch:4 step:4289 [D loss: 0.689890, acc.: 53.12%] [G loss: 0.840007]\n",
      "epoch:4 step:4290 [D loss: 0.729551, acc.: 50.00%] [G loss: 0.862614]\n",
      "epoch:4 step:4291 [D loss: 0.750988, acc.: 51.56%] [G loss: 0.812656]\n",
      "epoch:4 step:4292 [D loss: 0.691368, acc.: 59.38%] [G loss: 0.836275]\n",
      "epoch:4 step:4293 [D loss: 0.630891, acc.: 63.28%] [G loss: 0.924031]\n",
      "epoch:4 step:4294 [D loss: 0.713864, acc.: 52.34%] [G loss: 0.856606]\n",
      "epoch:4 step:4295 [D loss: 0.640013, acc.: 64.84%] [G loss: 0.998705]\n",
      "epoch:4 step:4296 [D loss: 0.655558, acc.: 60.16%] [G loss: 0.978768]\n",
      "epoch:4 step:4297 [D loss: 0.632696, acc.: 65.62%] [G loss: 0.954025]\n",
      "epoch:4 step:4298 [D loss: 0.596642, acc.: 69.53%] [G loss: 0.977287]\n",
      "epoch:4 step:4299 [D loss: 0.663395, acc.: 58.59%] [G loss: 0.887444]\n",
      "epoch:4 step:4300 [D loss: 0.628458, acc.: 62.50%] [G loss: 1.080164]\n",
      "epoch:4 step:4301 [D loss: 0.683840, acc.: 60.16%] [G loss: 0.973773]\n",
      "epoch:4 step:4302 [D loss: 0.551507, acc.: 75.00%] [G loss: 0.900637]\n",
      "epoch:4 step:4303 [D loss: 0.653010, acc.: 64.84%] [G loss: 0.892763]\n",
      "epoch:4 step:4304 [D loss: 0.617624, acc.: 71.88%] [G loss: 0.979558]\n",
      "epoch:4 step:4305 [D loss: 0.596674, acc.: 67.19%] [G loss: 1.074561]\n",
      "epoch:4 step:4306 [D loss: 0.608174, acc.: 65.62%] [G loss: 0.941659]\n",
      "epoch:4 step:4307 [D loss: 0.732898, acc.: 47.66%] [G loss: 1.008357]\n",
      "epoch:4 step:4308 [D loss: 0.729165, acc.: 50.78%] [G loss: 0.993448]\n",
      "epoch:4 step:4309 [D loss: 0.693887, acc.: 60.16%] [G loss: 0.888732]\n",
      "epoch:4 step:4310 [D loss: 0.660918, acc.: 61.72%] [G loss: 0.947042]\n",
      "epoch:4 step:4311 [D loss: 0.694264, acc.: 54.69%] [G loss: 0.926541]\n",
      "epoch:4 step:4312 [D loss: 0.609144, acc.: 71.88%] [G loss: 0.907452]\n",
      "epoch:4 step:4313 [D loss: 0.710632, acc.: 58.59%] [G loss: 0.936191]\n",
      "epoch:4 step:4314 [D loss: 0.732383, acc.: 52.34%] [G loss: 0.915670]\n",
      "epoch:4 step:4315 [D loss: 0.712522, acc.: 55.47%] [G loss: 0.905398]\n",
      "epoch:4 step:4316 [D loss: 0.699401, acc.: 53.91%] [G loss: 0.927045]\n",
      "epoch:4 step:4317 [D loss: 0.732906, acc.: 53.91%] [G loss: 0.941084]\n",
      "epoch:4 step:4318 [D loss: 0.666259, acc.: 58.59%] [G loss: 0.958797]\n",
      "epoch:4 step:4319 [D loss: 0.658252, acc.: 64.84%] [G loss: 0.945585]\n",
      "epoch:4 step:4320 [D loss: 0.657359, acc.: 58.59%] [G loss: 0.952198]\n",
      "epoch:4 step:4321 [D loss: 0.670606, acc.: 57.81%] [G loss: 0.876914]\n",
      "epoch:4 step:4322 [D loss: 0.643971, acc.: 58.59%] [G loss: 0.991565]\n",
      "epoch:4 step:4323 [D loss: 0.657977, acc.: 59.38%] [G loss: 0.895967]\n",
      "epoch:4 step:4324 [D loss: 0.706803, acc.: 57.81%] [G loss: 0.933912]\n",
      "epoch:4 step:4325 [D loss: 0.684549, acc.: 58.59%] [G loss: 0.921405]\n",
      "epoch:4 step:4326 [D loss: 0.672395, acc.: 60.94%] [G loss: 0.918301]\n",
      "epoch:4 step:4327 [D loss: 0.690014, acc.: 57.03%] [G loss: 0.853721]\n",
      "epoch:4 step:4328 [D loss: 0.716664, acc.: 53.91%] [G loss: 0.855343]\n",
      "epoch:4 step:4329 [D loss: 0.734372, acc.: 48.44%] [G loss: 0.962777]\n",
      "epoch:4 step:4330 [D loss: 0.679813, acc.: 57.81%] [G loss: 0.854068]\n",
      "epoch:4 step:4331 [D loss: 0.603802, acc.: 75.00%] [G loss: 0.977185]\n",
      "epoch:4 step:4332 [D loss: 0.688874, acc.: 53.12%] [G loss: 0.868184]\n",
      "epoch:4 step:4333 [D loss: 0.695028, acc.: 55.47%] [G loss: 0.839123]\n",
      "epoch:4 step:4334 [D loss: 0.633588, acc.: 68.75%] [G loss: 1.022939]\n",
      "epoch:4 step:4335 [D loss: 0.666346, acc.: 61.72%] [G loss: 0.935976]\n",
      "epoch:4 step:4336 [D loss: 0.622522, acc.: 64.84%] [G loss: 0.977923]\n",
      "epoch:4 step:4337 [D loss: 0.616976, acc.: 67.19%] [G loss: 0.917011]\n",
      "epoch:4 step:4338 [D loss: 0.704317, acc.: 59.38%] [G loss: 0.944812]\n",
      "epoch:4 step:4339 [D loss: 0.656909, acc.: 60.16%] [G loss: 0.888151]\n",
      "epoch:4 step:4340 [D loss: 0.665990, acc.: 62.50%] [G loss: 0.968738]\n",
      "epoch:4 step:4341 [D loss: 0.654700, acc.: 60.16%] [G loss: 1.002569]\n",
      "epoch:4 step:4342 [D loss: 0.616813, acc.: 67.19%] [G loss: 0.926064]\n",
      "epoch:4 step:4343 [D loss: 0.649827, acc.: 64.84%] [G loss: 0.963166]\n",
      "epoch:4 step:4344 [D loss: 0.634153, acc.: 64.84%] [G loss: 1.019115]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4345 [D loss: 0.758888, acc.: 44.53%] [G loss: 0.830208]\n",
      "epoch:4 step:4346 [D loss: 0.714417, acc.: 51.56%] [G loss: 0.898889]\n",
      "epoch:4 step:4347 [D loss: 0.716808, acc.: 55.47%] [G loss: 0.843572]\n",
      "epoch:4 step:4348 [D loss: 0.675796, acc.: 57.03%] [G loss: 0.781764]\n",
      "epoch:4 step:4349 [D loss: 0.646070, acc.: 60.16%] [G loss: 0.835725]\n",
      "epoch:4 step:4350 [D loss: 0.655496, acc.: 60.94%] [G loss: 0.954250]\n",
      "epoch:4 step:4351 [D loss: 0.615361, acc.: 67.19%] [G loss: 0.958637]\n",
      "epoch:4 step:4352 [D loss: 0.704479, acc.: 50.00%] [G loss: 0.860495]\n",
      "epoch:4 step:4353 [D loss: 0.621983, acc.: 63.28%] [G loss: 0.867615]\n",
      "epoch:4 step:4354 [D loss: 0.624363, acc.: 67.19%] [G loss: 0.933170]\n",
      "epoch:4 step:4355 [D loss: 0.684782, acc.: 54.69%] [G loss: 0.741304]\n",
      "epoch:4 step:4356 [D loss: 0.621860, acc.: 63.28%] [G loss: 0.865859]\n",
      "epoch:4 step:4357 [D loss: 0.651091, acc.: 59.38%] [G loss: 1.012906]\n",
      "epoch:4 step:4358 [D loss: 0.692872, acc.: 55.47%] [G loss: 0.884392]\n",
      "epoch:4 step:4359 [D loss: 0.633063, acc.: 64.84%] [G loss: 0.984612]\n",
      "epoch:4 step:4360 [D loss: 0.665533, acc.: 57.03%] [G loss: 0.892908]\n",
      "epoch:4 step:4361 [D loss: 0.621550, acc.: 62.50%] [G loss: 1.011514]\n",
      "epoch:4 step:4362 [D loss: 0.615733, acc.: 66.41%] [G loss: 1.023105]\n",
      "epoch:4 step:4363 [D loss: 0.687716, acc.: 59.38%] [G loss: 0.863213]\n",
      "epoch:4 step:4364 [D loss: 0.722403, acc.: 54.69%] [G loss: 0.895219]\n",
      "epoch:4 step:4365 [D loss: 0.673085, acc.: 60.16%] [G loss: 0.978082]\n",
      "epoch:4 step:4366 [D loss: 0.624805, acc.: 65.62%] [G loss: 0.857670]\n",
      "epoch:4 step:4367 [D loss: 0.659186, acc.: 62.50%] [G loss: 0.895089]\n",
      "epoch:4 step:4368 [D loss: 0.653712, acc.: 58.59%] [G loss: 0.992226]\n",
      "epoch:4 step:4369 [D loss: 0.696254, acc.: 54.69%] [G loss: 1.030725]\n",
      "epoch:4 step:4370 [D loss: 0.692263, acc.: 53.12%] [G loss: 0.939390]\n",
      "epoch:4 step:4371 [D loss: 0.622769, acc.: 68.75%] [G loss: 1.214748]\n",
      "epoch:4 step:4372 [D loss: 0.631837, acc.: 70.31%] [G loss: 0.913584]\n",
      "epoch:4 step:4373 [D loss: 0.676934, acc.: 61.72%] [G loss: 0.903367]\n",
      "epoch:4 step:4374 [D loss: 0.677532, acc.: 53.91%] [G loss: 0.918546]\n",
      "epoch:4 step:4375 [D loss: 0.698591, acc.: 56.25%] [G loss: 0.911097]\n",
      "epoch:4 step:4376 [D loss: 0.661026, acc.: 58.59%] [G loss: 0.908813]\n",
      "epoch:4 step:4377 [D loss: 0.649584, acc.: 62.50%] [G loss: 0.981866]\n",
      "epoch:4 step:4378 [D loss: 0.629412, acc.: 67.97%] [G loss: 0.883602]\n",
      "epoch:4 step:4379 [D loss: 0.650629, acc.: 60.16%] [G loss: 1.019761]\n",
      "epoch:4 step:4380 [D loss: 0.678132, acc.: 57.03%] [G loss: 1.023165]\n",
      "epoch:4 step:4381 [D loss: 0.656169, acc.: 63.28%] [G loss: 1.075316]\n",
      "epoch:4 step:4382 [D loss: 0.620090, acc.: 68.75%] [G loss: 0.964617]\n",
      "epoch:4 step:4383 [D loss: 0.607159, acc.: 64.84%] [G loss: 1.151574]\n",
      "epoch:4 step:4384 [D loss: 0.724034, acc.: 46.88%] [G loss: 1.009297]\n",
      "epoch:4 step:4385 [D loss: 0.674853, acc.: 57.81%] [G loss: 0.982843]\n",
      "epoch:4 step:4386 [D loss: 0.646976, acc.: 67.19%] [G loss: 1.015389]\n",
      "epoch:4 step:4387 [D loss: 0.699186, acc.: 57.81%] [G loss: 0.872736]\n",
      "epoch:4 step:4388 [D loss: 0.715584, acc.: 55.47%] [G loss: 0.982829]\n",
      "epoch:4 step:4389 [D loss: 0.708247, acc.: 50.00%] [G loss: 0.999132]\n",
      "epoch:4 step:4390 [D loss: 0.689820, acc.: 55.47%] [G loss: 1.044735]\n",
      "epoch:4 step:4391 [D loss: 0.705316, acc.: 57.03%] [G loss: 0.938281]\n",
      "epoch:4 step:4392 [D loss: 0.644681, acc.: 66.41%] [G loss: 0.916824]\n",
      "epoch:4 step:4393 [D loss: 0.652268, acc.: 63.28%] [G loss: 0.894783]\n",
      "epoch:4 step:4394 [D loss: 0.684154, acc.: 56.25%] [G loss: 0.954177]\n",
      "epoch:4 step:4395 [D loss: 0.651444, acc.: 64.06%] [G loss: 0.986189]\n",
      "epoch:4 step:4396 [D loss: 0.639734, acc.: 60.94%] [G loss: 0.952801]\n",
      "epoch:4 step:4397 [D loss: 0.625751, acc.: 64.84%] [G loss: 0.939045]\n",
      "epoch:4 step:4398 [D loss: 0.622531, acc.: 65.62%] [G loss: 0.844515]\n",
      "epoch:4 step:4399 [D loss: 0.670110, acc.: 60.16%] [G loss: 0.961341]\n",
      "epoch:4 step:4400 [D loss: 0.727759, acc.: 51.56%] [G loss: 0.864613]\n",
      "##############\n",
      "[1.95058696 1.46758962 5.04898492 3.97401031 2.7411481  4.98504239\n",
      " 3.57751739 4.26781868 3.68360374 3.24684667]\n",
      "##########\n",
      "epoch:4 step:4401 [D loss: 0.717807, acc.: 53.91%] [G loss: 0.972584]\n",
      "epoch:4 step:4402 [D loss: 0.591867, acc.: 67.19%] [G loss: 0.933943]\n",
      "epoch:4 step:4403 [D loss: 0.644718, acc.: 64.06%] [G loss: 0.975203]\n",
      "epoch:4 step:4404 [D loss: 0.721607, acc.: 50.78%] [G loss: 0.944511]\n",
      "epoch:4 step:4405 [D loss: 0.704743, acc.: 53.12%] [G loss: 0.880654]\n",
      "epoch:4 step:4406 [D loss: 0.696938, acc.: 53.91%] [G loss: 0.990622]\n",
      "epoch:4 step:4407 [D loss: 0.647043, acc.: 63.28%] [G loss: 0.950539]\n",
      "epoch:4 step:4408 [D loss: 0.628407, acc.: 61.72%] [G loss: 0.928243]\n",
      "epoch:4 step:4409 [D loss: 0.675115, acc.: 57.81%] [G loss: 0.915596]\n",
      "epoch:4 step:4410 [D loss: 0.720649, acc.: 56.25%] [G loss: 0.900478]\n",
      "epoch:4 step:4411 [D loss: 0.648939, acc.: 60.94%] [G loss: 0.969012]\n",
      "epoch:4 step:4412 [D loss: 0.657000, acc.: 61.72%] [G loss: 0.915271]\n",
      "epoch:4 step:4413 [D loss: 0.654947, acc.: 60.16%] [G loss: 0.934195]\n",
      "epoch:4 step:4414 [D loss: 0.671044, acc.: 56.25%] [G loss: 0.891795]\n",
      "epoch:4 step:4415 [D loss: 0.687823, acc.: 59.38%] [G loss: 0.931403]\n",
      "epoch:4 step:4416 [D loss: 0.683896, acc.: 61.72%] [G loss: 0.864291]\n",
      "epoch:4 step:4417 [D loss: 0.689880, acc.: 55.47%] [G loss: 0.953754]\n",
      "epoch:4 step:4418 [D loss: 0.656579, acc.: 63.28%] [G loss: 0.916957]\n",
      "epoch:4 step:4419 [D loss: 0.620491, acc.: 71.09%] [G loss: 0.935503]\n",
      "epoch:4 step:4420 [D loss: 0.665109, acc.: 60.16%] [G loss: 1.006578]\n",
      "epoch:4 step:4421 [D loss: 0.740202, acc.: 45.31%] [G loss: 0.854093]\n",
      "epoch:4 step:4422 [D loss: 0.689774, acc.: 57.81%] [G loss: 0.882614]\n",
      "epoch:4 step:4423 [D loss: 0.657545, acc.: 60.94%] [G loss: 0.936173]\n",
      "epoch:4 step:4424 [D loss: 0.631067, acc.: 64.84%] [G loss: 1.018122]\n",
      "epoch:4 step:4425 [D loss: 0.642289, acc.: 64.84%] [G loss: 0.983380]\n",
      "epoch:4 step:4426 [D loss: 0.611212, acc.: 67.19%] [G loss: 1.003494]\n",
      "epoch:4 step:4427 [D loss: 0.638204, acc.: 63.28%] [G loss: 0.943210]\n",
      "epoch:4 step:4428 [D loss: 0.700735, acc.: 52.34%] [G loss: 0.864443]\n",
      "epoch:4 step:4429 [D loss: 0.627504, acc.: 64.84%] [G loss: 0.957167]\n",
      "epoch:4 step:4430 [D loss: 0.718610, acc.: 57.81%] [G loss: 1.048180]\n",
      "epoch:4 step:4431 [D loss: 0.679586, acc.: 58.59%] [G loss: 1.003792]\n",
      "epoch:4 step:4432 [D loss: 0.666724, acc.: 59.38%] [G loss: 0.998752]\n",
      "epoch:4 step:4433 [D loss: 0.652344, acc.: 64.84%] [G loss: 0.976508]\n",
      "epoch:4 step:4434 [D loss: 0.664216, acc.: 57.81%] [G loss: 0.927043]\n",
      "epoch:4 step:4435 [D loss: 0.688787, acc.: 55.47%] [G loss: 0.892597]\n",
      "epoch:4 step:4436 [D loss: 0.644848, acc.: 61.72%] [G loss: 0.936049]\n",
      "epoch:4 step:4437 [D loss: 0.697487, acc.: 57.03%] [G loss: 0.919697]\n",
      "epoch:4 step:4438 [D loss: 0.681842, acc.: 59.38%] [G loss: 0.898507]\n",
      "epoch:4 step:4439 [D loss: 0.621902, acc.: 62.50%] [G loss: 0.867029]\n",
      "epoch:4 step:4440 [D loss: 0.717848, acc.: 48.44%] [G loss: 0.739798]\n",
      "epoch:4 step:4441 [D loss: 0.657697, acc.: 62.50%] [G loss: 0.950700]\n",
      "epoch:4 step:4442 [D loss: 0.697737, acc.: 52.34%] [G loss: 0.884929]\n",
      "epoch:4 step:4443 [D loss: 0.647677, acc.: 62.50%] [G loss: 0.964250]\n",
      "epoch:4 step:4444 [D loss: 0.681934, acc.: 56.25%] [G loss: 0.901518]\n",
      "epoch:4 step:4445 [D loss: 0.688550, acc.: 55.47%] [G loss: 0.975171]\n",
      "epoch:4 step:4446 [D loss: 0.661963, acc.: 62.50%] [G loss: 0.925965]\n",
      "epoch:4 step:4447 [D loss: 0.635376, acc.: 60.16%] [G loss: 0.994587]\n",
      "epoch:4 step:4448 [D loss: 0.668764, acc.: 60.16%] [G loss: 1.021497]\n",
      "epoch:4 step:4449 [D loss: 0.559739, acc.: 77.34%] [G loss: 1.058311]\n",
      "epoch:4 step:4450 [D loss: 0.703306, acc.: 50.78%] [G loss: 0.914898]\n",
      "epoch:4 step:4451 [D loss: 0.670066, acc.: 60.94%] [G loss: 0.916372]\n",
      "epoch:4 step:4452 [D loss: 0.724585, acc.: 57.81%] [G loss: 0.888166]\n",
      "epoch:4 step:4453 [D loss: 0.736128, acc.: 46.88%] [G loss: 0.876735]\n",
      "epoch:4 step:4454 [D loss: 0.686178, acc.: 64.06%] [G loss: 0.896226]\n",
      "epoch:4 step:4455 [D loss: 0.626784, acc.: 68.75%] [G loss: 1.031413]\n",
      "epoch:4 step:4456 [D loss: 0.657459, acc.: 64.84%] [G loss: 0.914681]\n",
      "epoch:4 step:4457 [D loss: 0.574412, acc.: 74.22%] [G loss: 1.031083]\n",
      "epoch:4 step:4458 [D loss: 0.717003, acc.: 52.34%] [G loss: 0.953961]\n",
      "epoch:4 step:4459 [D loss: 0.716931, acc.: 56.25%] [G loss: 0.953479]\n",
      "epoch:4 step:4460 [D loss: 0.676056, acc.: 60.16%] [G loss: 0.846247]\n",
      "epoch:4 step:4461 [D loss: 0.614632, acc.: 65.62%] [G loss: 0.952822]\n",
      "epoch:4 step:4462 [D loss: 0.674175, acc.: 57.03%] [G loss: 0.904236]\n",
      "epoch:4 step:4463 [D loss: 0.660219, acc.: 53.91%] [G loss: 0.975686]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4464 [D loss: 0.699524, acc.: 53.91%] [G loss: 0.738498]\n",
      "epoch:4 step:4465 [D loss: 0.702505, acc.: 54.69%] [G loss: 0.913006]\n",
      "epoch:4 step:4466 [D loss: 0.709816, acc.: 55.47%] [G loss: 0.910152]\n",
      "epoch:4 step:4467 [D loss: 0.680929, acc.: 59.38%] [G loss: 0.796782]\n",
      "epoch:4 step:4468 [D loss: 0.618513, acc.: 65.62%] [G loss: 0.895703]\n",
      "epoch:4 step:4469 [D loss: 0.663110, acc.: 56.25%] [G loss: 0.842312]\n",
      "epoch:4 step:4470 [D loss: 0.675444, acc.: 54.69%] [G loss: 0.908306]\n",
      "epoch:4 step:4471 [D loss: 0.649685, acc.: 61.72%] [G loss: 0.976903]\n",
      "epoch:4 step:4472 [D loss: 0.686196, acc.: 55.47%] [G loss: 0.766929]\n",
      "epoch:4 step:4473 [D loss: 0.631537, acc.: 61.72%] [G loss: 0.933566]\n",
      "epoch:4 step:4474 [D loss: 0.670821, acc.: 56.25%] [G loss: 0.912074]\n",
      "epoch:4 step:4475 [D loss: 0.690408, acc.: 56.25%] [G loss: 0.844975]\n",
      "epoch:4 step:4476 [D loss: 0.714778, acc.: 57.03%] [G loss: 1.062092]\n",
      "epoch:4 step:4477 [D loss: 0.704799, acc.: 57.03%] [G loss: 0.859523]\n",
      "epoch:4 step:4478 [D loss: 0.631250, acc.: 61.72%] [G loss: 0.890126]\n",
      "epoch:4 step:4479 [D loss: 0.592504, acc.: 71.09%] [G loss: 0.983023]\n",
      "epoch:4 step:4480 [D loss: 0.647161, acc.: 60.94%] [G loss: 0.996981]\n",
      "epoch:4 step:4481 [D loss: 0.659054, acc.: 55.47%] [G loss: 0.923666]\n",
      "epoch:4 step:4482 [D loss: 0.695497, acc.: 56.25%] [G loss: 0.962518]\n",
      "epoch:4 step:4483 [D loss: 0.688380, acc.: 53.91%] [G loss: 1.065733]\n",
      "epoch:4 step:4484 [D loss: 0.697931, acc.: 55.47%] [G loss: 0.960848]\n",
      "epoch:4 step:4485 [D loss: 0.646288, acc.: 61.72%] [G loss: 1.005193]\n",
      "epoch:4 step:4486 [D loss: 0.675566, acc.: 58.59%] [G loss: 1.021599]\n",
      "epoch:4 step:4487 [D loss: 0.688597, acc.: 59.38%] [G loss: 0.950311]\n",
      "epoch:4 step:4488 [D loss: 0.672771, acc.: 60.94%] [G loss: 0.932859]\n",
      "epoch:4 step:4489 [D loss: 0.743201, acc.: 53.12%] [G loss: 0.947668]\n",
      "epoch:4 step:4490 [D loss: 0.754892, acc.: 47.66%] [G loss: 0.864061]\n",
      "epoch:4 step:4491 [D loss: 0.669293, acc.: 58.59%] [G loss: 0.890182]\n",
      "epoch:4 step:4492 [D loss: 0.686683, acc.: 59.38%] [G loss: 1.021049]\n",
      "epoch:4 step:4493 [D loss: 0.612691, acc.: 69.53%] [G loss: 0.970628]\n",
      "epoch:4 step:4494 [D loss: 0.639045, acc.: 60.94%] [G loss: 0.981469]\n",
      "epoch:4 step:4495 [D loss: 0.595903, acc.: 71.09%] [G loss: 0.929201]\n",
      "epoch:4 step:4496 [D loss: 0.700862, acc.: 58.59%] [G loss: 0.983325]\n",
      "epoch:4 step:4497 [D loss: 0.652793, acc.: 58.59%] [G loss: 0.927597]\n",
      "epoch:4 step:4498 [D loss: 0.609733, acc.: 71.09%] [G loss: 0.935090]\n",
      "epoch:4 step:4499 [D loss: 0.668642, acc.: 54.69%] [G loss: 0.921943]\n",
      "epoch:4 step:4500 [D loss: 0.677816, acc.: 53.91%] [G loss: 1.013705]\n",
      "epoch:4 step:4501 [D loss: 0.657555, acc.: 53.91%] [G loss: 0.914116]\n",
      "epoch:4 step:4502 [D loss: 0.683888, acc.: 57.03%] [G loss: 0.866771]\n",
      "epoch:4 step:4503 [D loss: 0.663770, acc.: 61.72%] [G loss: 0.952315]\n",
      "epoch:4 step:4504 [D loss: 0.656098, acc.: 59.38%] [G loss: 0.921018]\n",
      "epoch:4 step:4505 [D loss: 0.682008, acc.: 58.59%] [G loss: 0.868659]\n",
      "epoch:4 step:4506 [D loss: 0.648803, acc.: 62.50%] [G loss: 1.012074]\n",
      "epoch:4 step:4507 [D loss: 0.732315, acc.: 50.78%] [G loss: 0.995293]\n",
      "epoch:4 step:4508 [D loss: 0.715980, acc.: 55.47%] [G loss: 0.834050]\n",
      "epoch:4 step:4509 [D loss: 0.633160, acc.: 63.28%] [G loss: 0.854649]\n",
      "epoch:4 step:4510 [D loss: 0.642487, acc.: 63.28%] [G loss: 0.944699]\n",
      "epoch:4 step:4511 [D loss: 0.680598, acc.: 53.91%] [G loss: 0.851743]\n",
      "epoch:4 step:4512 [D loss: 0.628141, acc.: 67.19%] [G loss: 0.930220]\n",
      "epoch:4 step:4513 [D loss: 0.756641, acc.: 47.66%] [G loss: 0.911466]\n",
      "epoch:4 step:4514 [D loss: 0.650663, acc.: 63.28%] [G loss: 0.909945]\n",
      "epoch:4 step:4515 [D loss: 0.722290, acc.: 53.91%] [G loss: 0.901527]\n",
      "epoch:4 step:4516 [D loss: 0.697379, acc.: 58.59%] [G loss: 0.897959]\n",
      "epoch:4 step:4517 [D loss: 0.710004, acc.: 55.47%] [G loss: 0.882472]\n",
      "epoch:4 step:4518 [D loss: 0.643595, acc.: 62.50%] [G loss: 0.976708]\n",
      "epoch:4 step:4519 [D loss: 0.645713, acc.: 64.06%] [G loss: 0.975058]\n",
      "epoch:4 step:4520 [D loss: 0.654127, acc.: 64.84%] [G loss: 0.994562]\n",
      "epoch:4 step:4521 [D loss: 0.649733, acc.: 63.28%] [G loss: 0.981737]\n",
      "epoch:4 step:4522 [D loss: 0.668256, acc.: 55.47%] [G loss: 0.967462]\n",
      "epoch:4 step:4523 [D loss: 0.659572, acc.: 60.16%] [G loss: 0.862501]\n",
      "epoch:4 step:4524 [D loss: 0.617875, acc.: 64.84%] [G loss: 0.996807]\n",
      "epoch:4 step:4525 [D loss: 0.655852, acc.: 66.41%] [G loss: 0.880281]\n",
      "epoch:4 step:4526 [D loss: 0.675338, acc.: 55.47%] [G loss: 0.864068]\n",
      "epoch:4 step:4527 [D loss: 0.656375, acc.: 60.16%] [G loss: 0.877684]\n",
      "epoch:4 step:4528 [D loss: 0.709190, acc.: 58.59%] [G loss: 0.963373]\n",
      "epoch:4 step:4529 [D loss: 0.754671, acc.: 48.44%] [G loss: 0.874100]\n",
      "epoch:4 step:4530 [D loss: 0.616631, acc.: 70.31%] [G loss: 0.999316]\n",
      "epoch:4 step:4531 [D loss: 0.674296, acc.: 57.03%] [G loss: 0.943446]\n",
      "epoch:4 step:4532 [D loss: 0.716705, acc.: 56.25%] [G loss: 0.790012]\n",
      "epoch:4 step:4533 [D loss: 0.653887, acc.: 57.81%] [G loss: 0.904877]\n",
      "epoch:4 step:4534 [D loss: 0.621539, acc.: 67.97%] [G loss: 0.862831]\n",
      "epoch:4 step:4535 [D loss: 0.708659, acc.: 53.12%] [G loss: 0.876259]\n",
      "epoch:4 step:4536 [D loss: 0.686832, acc.: 54.69%] [G loss: 0.970580]\n",
      "epoch:4 step:4537 [D loss: 0.634787, acc.: 61.72%] [G loss: 1.045612]\n",
      "epoch:4 step:4538 [D loss: 0.647980, acc.: 64.84%] [G loss: 0.913216]\n",
      "epoch:4 step:4539 [D loss: 0.734382, acc.: 51.56%] [G loss: 0.874227]\n",
      "epoch:4 step:4540 [D loss: 0.639732, acc.: 63.28%] [G loss: 0.902471]\n",
      "epoch:4 step:4541 [D loss: 0.650734, acc.: 59.38%] [G loss: 0.909066]\n",
      "epoch:4 step:4542 [D loss: 0.726144, acc.: 53.91%] [G loss: 0.897537]\n",
      "epoch:4 step:4543 [D loss: 0.720457, acc.: 53.12%] [G loss: 0.829071]\n",
      "epoch:4 step:4544 [D loss: 0.710702, acc.: 59.38%] [G loss: 0.870551]\n",
      "epoch:4 step:4545 [D loss: 0.655506, acc.: 58.59%] [G loss: 0.883693]\n",
      "epoch:4 step:4546 [D loss: 0.605047, acc.: 71.09%] [G loss: 0.920827]\n",
      "epoch:4 step:4547 [D loss: 0.730136, acc.: 50.78%] [G loss: 0.869719]\n",
      "epoch:4 step:4548 [D loss: 0.723267, acc.: 52.34%] [G loss: 0.964494]\n",
      "epoch:4 step:4549 [D loss: 0.694062, acc.: 55.47%] [G loss: 0.886277]\n",
      "epoch:4 step:4550 [D loss: 0.649414, acc.: 57.03%] [G loss: 1.011078]\n",
      "epoch:4 step:4551 [D loss: 0.694437, acc.: 57.03%] [G loss: 0.910628]\n",
      "epoch:4 step:4552 [D loss: 0.608887, acc.: 67.97%] [G loss: 1.036502]\n",
      "epoch:4 step:4553 [D loss: 0.654999, acc.: 63.28%] [G loss: 1.081771]\n",
      "epoch:4 step:4554 [D loss: 0.623369, acc.: 65.62%] [G loss: 1.002717]\n",
      "epoch:4 step:4555 [D loss: 0.638349, acc.: 62.50%] [G loss: 0.909728]\n",
      "epoch:4 step:4556 [D loss: 0.689370, acc.: 53.12%] [G loss: 0.992302]\n",
      "epoch:4 step:4557 [D loss: 0.621172, acc.: 67.19%] [G loss: 0.989115]\n",
      "epoch:4 step:4558 [D loss: 0.657202, acc.: 60.94%] [G loss: 0.936859]\n",
      "epoch:4 step:4559 [D loss: 0.638990, acc.: 62.50%] [G loss: 0.980338]\n",
      "epoch:4 step:4560 [D loss: 0.648890, acc.: 58.59%] [G loss: 1.004566]\n",
      "epoch:4 step:4561 [D loss: 0.652771, acc.: 61.72%] [G loss: 0.873536]\n",
      "epoch:4 step:4562 [D loss: 0.705221, acc.: 54.69%] [G loss: 0.866314]\n",
      "epoch:4 step:4563 [D loss: 0.717858, acc.: 53.12%] [G loss: 0.915781]\n",
      "epoch:4 step:4564 [D loss: 0.594984, acc.: 70.31%] [G loss: 0.965325]\n",
      "epoch:4 step:4565 [D loss: 0.621753, acc.: 64.84%] [G loss: 1.006407]\n",
      "epoch:4 step:4566 [D loss: 0.637807, acc.: 64.06%] [G loss: 0.944890]\n",
      "epoch:4 step:4567 [D loss: 0.642652, acc.: 65.62%] [G loss: 0.971486]\n",
      "epoch:4 step:4568 [D loss: 0.708510, acc.: 53.12%] [G loss: 0.965662]\n",
      "epoch:4 step:4569 [D loss: 0.658338, acc.: 60.16%] [G loss: 0.965766]\n",
      "epoch:4 step:4570 [D loss: 0.617984, acc.: 61.72%] [G loss: 0.962072]\n",
      "epoch:4 step:4571 [D loss: 0.740994, acc.: 53.91%] [G loss: 0.967999]\n",
      "epoch:4 step:4572 [D loss: 0.789631, acc.: 41.41%] [G loss: 0.939544]\n",
      "epoch:4 step:4573 [D loss: 0.674228, acc.: 59.38%] [G loss: 0.943990]\n",
      "epoch:4 step:4574 [D loss: 0.723809, acc.: 56.25%] [G loss: 0.995409]\n",
      "epoch:4 step:4575 [D loss: 0.746915, acc.: 52.34%] [G loss: 0.882131]\n",
      "epoch:4 step:4576 [D loss: 0.722108, acc.: 51.56%] [G loss: 0.861840]\n",
      "epoch:4 step:4577 [D loss: 0.662297, acc.: 59.38%] [G loss: 1.044005]\n",
      "epoch:4 step:4578 [D loss: 0.681331, acc.: 57.03%] [G loss: 0.799952]\n",
      "epoch:4 step:4579 [D loss: 0.650300, acc.: 57.81%] [G loss: 0.902960]\n",
      "epoch:4 step:4580 [D loss: 0.571070, acc.: 72.66%] [G loss: 0.921848]\n",
      "epoch:4 step:4581 [D loss: 0.636440, acc.: 64.84%] [G loss: 0.964343]\n",
      "epoch:4 step:4582 [D loss: 0.634935, acc.: 67.19%] [G loss: 1.014538]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4583 [D loss: 0.683090, acc.: 58.59%] [G loss: 1.064811]\n",
      "epoch:4 step:4584 [D loss: 0.715707, acc.: 54.69%] [G loss: 0.923886]\n",
      "epoch:4 step:4585 [D loss: 0.701171, acc.: 55.47%] [G loss: 0.910150]\n",
      "epoch:4 step:4586 [D loss: 0.610108, acc.: 67.19%] [G loss: 0.851943]\n",
      "epoch:4 step:4587 [D loss: 0.660879, acc.: 57.81%] [G loss: 0.937629]\n",
      "epoch:4 step:4588 [D loss: 0.654218, acc.: 58.59%] [G loss: 0.963607]\n",
      "epoch:4 step:4589 [D loss: 0.631088, acc.: 66.41%] [G loss: 0.906104]\n",
      "epoch:4 step:4590 [D loss: 0.607981, acc.: 60.94%] [G loss: 1.013012]\n",
      "epoch:4 step:4591 [D loss: 0.648550, acc.: 60.94%] [G loss: 1.095803]\n",
      "epoch:4 step:4592 [D loss: 0.670092, acc.: 56.25%] [G loss: 1.058770]\n",
      "epoch:4 step:4593 [D loss: 0.641955, acc.: 64.06%] [G loss: 0.970527]\n",
      "epoch:4 step:4594 [D loss: 0.670979, acc.: 59.38%] [G loss: 0.875597]\n",
      "epoch:4 step:4595 [D loss: 0.664667, acc.: 57.81%] [G loss: 1.016125]\n",
      "epoch:4 step:4596 [D loss: 0.654627, acc.: 64.84%] [G loss: 1.020525]\n",
      "epoch:4 step:4597 [D loss: 0.669718, acc.: 62.50%] [G loss: 0.971386]\n",
      "epoch:4 step:4598 [D loss: 0.669495, acc.: 64.06%] [G loss: 0.953318]\n",
      "epoch:4 step:4599 [D loss: 0.702441, acc.: 59.38%] [G loss: 0.870814]\n",
      "epoch:4 step:4600 [D loss: 0.684246, acc.: 57.03%] [G loss: 0.976585]\n",
      "##############\n",
      "[1.79187911 0.85085909 5.07362676 3.706422   2.48932137 5.00804874\n",
      " 3.40554136 4.22635997 3.51675613 2.96059949]\n",
      "##########\n",
      "epoch:4 step:4601 [D loss: 0.663745, acc.: 62.50%] [G loss: 0.916182]\n",
      "epoch:4 step:4602 [D loss: 0.629998, acc.: 65.62%] [G loss: 0.869049]\n",
      "epoch:4 step:4603 [D loss: 0.618974, acc.: 68.75%] [G loss: 0.983617]\n",
      "epoch:4 step:4604 [D loss: 0.678503, acc.: 61.72%] [G loss: 0.871244]\n",
      "epoch:4 step:4605 [D loss: 0.625324, acc.: 66.41%] [G loss: 0.884952]\n",
      "epoch:4 step:4606 [D loss: 0.662015, acc.: 57.81%] [G loss: 0.972043]\n",
      "epoch:4 step:4607 [D loss: 0.685712, acc.: 55.47%] [G loss: 0.912093]\n",
      "epoch:4 step:4608 [D loss: 0.648113, acc.: 60.16%] [G loss: 0.981585]\n",
      "epoch:4 step:4609 [D loss: 0.698808, acc.: 60.16%] [G loss: 1.006147]\n",
      "epoch:4 step:4610 [D loss: 0.655442, acc.: 61.72%] [G loss: 0.976754]\n",
      "epoch:4 step:4611 [D loss: 0.671415, acc.: 57.81%] [G loss: 0.944094]\n",
      "epoch:4 step:4612 [D loss: 0.693122, acc.: 60.16%] [G loss: 0.984511]\n",
      "epoch:4 step:4613 [D loss: 0.715215, acc.: 57.03%] [G loss: 0.910980]\n",
      "epoch:4 step:4614 [D loss: 0.741994, acc.: 49.22%] [G loss: 0.941700]\n",
      "epoch:4 step:4615 [D loss: 0.745768, acc.: 50.78%] [G loss: 0.895143]\n",
      "epoch:4 step:4616 [D loss: 0.671050, acc.: 60.16%] [G loss: 0.850520]\n",
      "epoch:4 step:4617 [D loss: 0.677720, acc.: 57.81%] [G loss: 0.842989]\n",
      "epoch:4 step:4618 [D loss: 0.684650, acc.: 57.81%] [G loss: 0.891080]\n",
      "epoch:4 step:4619 [D loss: 0.695145, acc.: 57.03%] [G loss: 0.841624]\n",
      "epoch:4 step:4620 [D loss: 0.605926, acc.: 67.19%] [G loss: 0.969083]\n",
      "epoch:4 step:4621 [D loss: 0.688916, acc.: 57.03%] [G loss: 0.893420]\n",
      "epoch:4 step:4622 [D loss: 0.713772, acc.: 52.34%] [G loss: 0.893800]\n",
      "epoch:4 step:4623 [D loss: 0.647124, acc.: 62.50%] [G loss: 0.854120]\n",
      "epoch:4 step:4624 [D loss: 0.663294, acc.: 58.59%] [G loss: 0.903668]\n",
      "epoch:4 step:4625 [D loss: 0.668987, acc.: 58.59%] [G loss: 0.970834]\n",
      "epoch:4 step:4626 [D loss: 0.694734, acc.: 58.59%] [G loss: 0.962824]\n",
      "epoch:4 step:4627 [D loss: 0.643531, acc.: 58.59%] [G loss: 0.978517]\n",
      "epoch:4 step:4628 [D loss: 0.653655, acc.: 61.72%] [G loss: 0.938099]\n",
      "epoch:4 step:4629 [D loss: 0.667087, acc.: 58.59%] [G loss: 1.003173]\n",
      "epoch:4 step:4630 [D loss: 0.647034, acc.: 59.38%] [G loss: 0.922428]\n",
      "epoch:4 step:4631 [D loss: 0.693654, acc.: 57.81%] [G loss: 0.916078]\n",
      "epoch:4 step:4632 [D loss: 0.647121, acc.: 61.72%] [G loss: 0.930895]\n",
      "epoch:4 step:4633 [D loss: 0.633579, acc.: 63.28%] [G loss: 0.953437]\n",
      "epoch:4 step:4634 [D loss: 0.680448, acc.: 55.47%] [G loss: 1.078983]\n",
      "epoch:4 step:4635 [D loss: 0.670889, acc.: 57.03%] [G loss: 0.938328]\n",
      "epoch:4 step:4636 [D loss: 0.575181, acc.: 71.09%] [G loss: 1.146413]\n",
      "epoch:4 step:4637 [D loss: 0.617883, acc.: 66.41%] [G loss: 1.025768]\n",
      "epoch:4 step:4638 [D loss: 0.558938, acc.: 71.09%] [G loss: 1.083422]\n",
      "epoch:4 step:4639 [D loss: 0.701199, acc.: 55.47%] [G loss: 1.041679]\n",
      "epoch:4 step:4640 [D loss: 0.761450, acc.: 50.00%] [G loss: 0.889381]\n",
      "epoch:4 step:4641 [D loss: 0.725591, acc.: 54.69%] [G loss: 0.942621]\n",
      "epoch:4 step:4642 [D loss: 0.650380, acc.: 66.41%] [G loss: 0.958132]\n",
      "epoch:4 step:4643 [D loss: 0.676127, acc.: 60.16%] [G loss: 0.878660]\n",
      "epoch:4 step:4644 [D loss: 0.676996, acc.: 57.81%] [G loss: 0.886403]\n",
      "epoch:4 step:4645 [D loss: 0.733038, acc.: 53.12%] [G loss: 0.889952]\n",
      "epoch:4 step:4646 [D loss: 0.630341, acc.: 66.41%] [G loss: 1.023369]\n",
      "epoch:4 step:4647 [D loss: 0.644672, acc.: 64.06%] [G loss: 0.937306]\n",
      "epoch:4 step:4648 [D loss: 0.689606, acc.: 57.03%] [G loss: 0.869399]\n",
      "epoch:4 step:4649 [D loss: 0.685362, acc.: 57.81%] [G loss: 0.947768]\n",
      "epoch:4 step:4650 [D loss: 0.642884, acc.: 61.72%] [G loss: 0.918839]\n",
      "epoch:4 step:4651 [D loss: 0.612513, acc.: 73.44%] [G loss: 1.024032]\n",
      "epoch:4 step:4652 [D loss: 0.693565, acc.: 55.47%] [G loss: 0.880141]\n",
      "epoch:4 step:4653 [D loss: 0.626804, acc.: 64.84%] [G loss: 0.905849]\n",
      "epoch:4 step:4654 [D loss: 0.611753, acc.: 65.62%] [G loss: 0.966596]\n",
      "epoch:4 step:4655 [D loss: 0.677218, acc.: 59.38%] [G loss: 0.916557]\n",
      "epoch:4 step:4656 [D loss: 0.696386, acc.: 50.78%] [G loss: 0.887410]\n",
      "epoch:4 step:4657 [D loss: 0.670055, acc.: 60.16%] [G loss: 0.971751]\n",
      "epoch:4 step:4658 [D loss: 0.617334, acc.: 67.19%] [G loss: 0.935008]\n",
      "epoch:4 step:4659 [D loss: 0.596025, acc.: 67.19%] [G loss: 0.894225]\n",
      "epoch:4 step:4660 [D loss: 0.647032, acc.: 66.41%] [G loss: 0.951161]\n",
      "epoch:4 step:4661 [D loss: 0.719095, acc.: 52.34%] [G loss: 0.908954]\n",
      "epoch:4 step:4662 [D loss: 0.566533, acc.: 72.66%] [G loss: 0.967486]\n",
      "epoch:4 step:4663 [D loss: 0.657264, acc.: 60.94%] [G loss: 0.858043]\n",
      "epoch:4 step:4664 [D loss: 0.668110, acc.: 60.16%] [G loss: 0.857247]\n",
      "epoch:4 step:4665 [D loss: 0.610776, acc.: 64.84%] [G loss: 0.981478]\n",
      "epoch:4 step:4666 [D loss: 0.562980, acc.: 73.44%] [G loss: 0.971887]\n",
      "epoch:4 step:4667 [D loss: 0.562758, acc.: 75.78%] [G loss: 0.974791]\n",
      "epoch:4 step:4668 [D loss: 0.756138, acc.: 46.88%] [G loss: 0.962042]\n",
      "epoch:4 step:4669 [D loss: 0.651055, acc.: 60.16%] [G loss: 1.046452]\n",
      "epoch:4 step:4670 [D loss: 0.560067, acc.: 75.78%] [G loss: 1.019136]\n",
      "epoch:4 step:4671 [D loss: 0.532913, acc.: 79.69%] [G loss: 1.084741]\n",
      "epoch:4 step:4672 [D loss: 0.588569, acc.: 69.53%] [G loss: 1.022412]\n",
      "epoch:4 step:4673 [D loss: 0.572465, acc.: 75.00%] [G loss: 0.944353]\n",
      "epoch:4 step:4674 [D loss: 0.590241, acc.: 68.75%] [G loss: 1.117726]\n",
      "epoch:4 step:4675 [D loss: 0.667119, acc.: 62.50%] [G loss: 0.971190]\n",
      "epoch:4 step:4676 [D loss: 0.831365, acc.: 50.00%] [G loss: 0.983458]\n",
      "epoch:4 step:4677 [D loss: 0.789852, acc.: 42.97%] [G loss: 0.836650]\n",
      "epoch:4 step:4678 [D loss: 0.564404, acc.: 74.22%] [G loss: 0.927557]\n",
      "epoch:4 step:4679 [D loss: 0.685207, acc.: 56.25%] [G loss: 0.944688]\n",
      "epoch:4 step:4680 [D loss: 0.666484, acc.: 58.59%] [G loss: 0.989816]\n",
      "epoch:4 step:4681 [D loss: 0.703740, acc.: 54.69%] [G loss: 0.865382]\n",
      "epoch:4 step:4682 [D loss: 0.628393, acc.: 64.06%] [G loss: 0.954185]\n",
      "epoch:4 step:4683 [D loss: 0.680322, acc.: 58.59%] [G loss: 1.049551]\n",
      "epoch:4 step:4684 [D loss: 0.510112, acc.: 80.47%] [G loss: 1.075215]\n",
      "epoch:4 step:4685 [D loss: 0.509480, acc.: 76.56%] [G loss: 1.115345]\n",
      "epoch:5 step:4686 [D loss: 0.709180, acc.: 55.47%] [G loss: 0.918077]\n",
      "epoch:5 step:4687 [D loss: 0.647126, acc.: 60.94%] [G loss: 1.012057]\n",
      "epoch:5 step:4688 [D loss: 0.645934, acc.: 59.38%] [G loss: 1.013281]\n",
      "epoch:5 step:4689 [D loss: 0.693297, acc.: 51.56%] [G loss: 0.974712]\n",
      "epoch:5 step:4690 [D loss: 0.613234, acc.: 67.19%] [G loss: 0.946985]\n",
      "epoch:5 step:4691 [D loss: 0.619606, acc.: 66.41%] [G loss: 0.956321]\n",
      "epoch:5 step:4692 [D loss: 0.585272, acc.: 71.88%] [G loss: 0.977037]\n",
      "epoch:5 step:4693 [D loss: 0.705144, acc.: 57.81%] [G loss: 0.874052]\n",
      "epoch:5 step:4694 [D loss: 0.651460, acc.: 64.84%] [G loss: 0.945974]\n",
      "epoch:5 step:4695 [D loss: 0.616903, acc.: 69.53%] [G loss: 1.142880]\n",
      "epoch:5 step:4696 [D loss: 0.593608, acc.: 66.41%] [G loss: 1.093967]\n",
      "epoch:5 step:4697 [D loss: 0.632406, acc.: 67.97%] [G loss: 1.040618]\n",
      "epoch:5 step:4698 [D loss: 0.641608, acc.: 61.72%] [G loss: 0.936000]\n",
      "epoch:5 step:4699 [D loss: 0.687812, acc.: 55.47%] [G loss: 0.965303]\n",
      "epoch:5 step:4700 [D loss: 0.659255, acc.: 60.16%] [G loss: 0.963671]\n",
      "epoch:5 step:4701 [D loss: 0.622071, acc.: 67.19%] [G loss: 0.986824]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4702 [D loss: 0.644291, acc.: 57.81%] [G loss: 0.990374]\n",
      "epoch:5 step:4703 [D loss: 0.677144, acc.: 58.59%] [G loss: 0.995209]\n",
      "epoch:5 step:4704 [D loss: 0.676026, acc.: 57.03%] [G loss: 0.832734]\n",
      "epoch:5 step:4705 [D loss: 0.793784, acc.: 45.31%] [G loss: 0.960095]\n",
      "epoch:5 step:4706 [D loss: 0.631442, acc.: 64.84%] [G loss: 0.887178]\n",
      "epoch:5 step:4707 [D loss: 0.726953, acc.: 53.91%] [G loss: 0.866647]\n",
      "epoch:5 step:4708 [D loss: 0.628987, acc.: 66.41%] [G loss: 0.942696]\n",
      "epoch:5 step:4709 [D loss: 0.659101, acc.: 63.28%] [G loss: 1.071230]\n",
      "epoch:5 step:4710 [D loss: 0.652406, acc.: 61.72%] [G loss: 0.987554]\n",
      "epoch:5 step:4711 [D loss: 0.721122, acc.: 50.78%] [G loss: 1.112722]\n",
      "epoch:5 step:4712 [D loss: 0.656464, acc.: 60.16%] [G loss: 1.045040]\n",
      "epoch:5 step:4713 [D loss: 0.737761, acc.: 53.91%] [G loss: 0.982482]\n",
      "epoch:5 step:4714 [D loss: 0.680185, acc.: 57.81%] [G loss: 0.950712]\n",
      "epoch:5 step:4715 [D loss: 0.731280, acc.: 52.34%] [G loss: 0.946176]\n",
      "epoch:5 step:4716 [D loss: 0.789488, acc.: 45.31%] [G loss: 0.849405]\n",
      "epoch:5 step:4717 [D loss: 0.736946, acc.: 48.44%] [G loss: 0.778424]\n",
      "epoch:5 step:4718 [D loss: 0.624406, acc.: 64.06%] [G loss: 1.082397]\n",
      "epoch:5 step:4719 [D loss: 0.646217, acc.: 67.97%] [G loss: 1.121424]\n",
      "epoch:5 step:4720 [D loss: 0.624620, acc.: 60.16%] [G loss: 1.072216]\n",
      "epoch:5 step:4721 [D loss: 0.648252, acc.: 67.97%] [G loss: 1.153286]\n",
      "epoch:5 step:4722 [D loss: 0.713747, acc.: 57.03%] [G loss: 0.947083]\n",
      "epoch:5 step:4723 [D loss: 0.690669, acc.: 53.91%] [G loss: 0.947039]\n",
      "epoch:5 step:4724 [D loss: 0.674723, acc.: 57.03%] [G loss: 0.957312]\n",
      "epoch:5 step:4725 [D loss: 0.612916, acc.: 66.41%] [G loss: 1.004980]\n",
      "epoch:5 step:4726 [D loss: 0.674222, acc.: 61.72%] [G loss: 1.014333]\n",
      "epoch:5 step:4727 [D loss: 0.605245, acc.: 64.06%] [G loss: 0.962542]\n",
      "epoch:5 step:4728 [D loss: 0.657158, acc.: 60.16%] [G loss: 0.916192]\n",
      "epoch:5 step:4729 [D loss: 0.735424, acc.: 53.12%] [G loss: 0.827243]\n",
      "epoch:5 step:4730 [D loss: 0.690900, acc.: 55.47%] [G loss: 0.995743]\n",
      "epoch:5 step:4731 [D loss: 0.711317, acc.: 53.91%] [G loss: 1.023891]\n",
      "epoch:5 step:4732 [D loss: 0.682425, acc.: 57.03%] [G loss: 0.890343]\n",
      "epoch:5 step:4733 [D loss: 0.586756, acc.: 69.53%] [G loss: 1.023932]\n",
      "epoch:5 step:4734 [D loss: 0.575880, acc.: 75.78%] [G loss: 1.010057]\n",
      "epoch:5 step:4735 [D loss: 0.591608, acc.: 70.31%] [G loss: 1.011297]\n",
      "epoch:5 step:4736 [D loss: 0.621988, acc.: 66.41%] [G loss: 0.984092]\n",
      "epoch:5 step:4737 [D loss: 0.593859, acc.: 69.53%] [G loss: 0.943834]\n",
      "epoch:5 step:4738 [D loss: 0.609109, acc.: 67.19%] [G loss: 0.991302]\n",
      "epoch:5 step:4739 [D loss: 0.652587, acc.: 65.62%] [G loss: 0.945518]\n",
      "epoch:5 step:4740 [D loss: 0.602557, acc.: 67.19%] [G loss: 1.025427]\n",
      "epoch:5 step:4741 [D loss: 0.631110, acc.: 63.28%] [G loss: 0.898194]\n",
      "epoch:5 step:4742 [D loss: 0.648849, acc.: 64.06%] [G loss: 1.014312]\n",
      "epoch:5 step:4743 [D loss: 0.668730, acc.: 58.59%] [G loss: 0.877382]\n",
      "epoch:5 step:4744 [D loss: 0.688541, acc.: 60.16%] [G loss: 0.913399]\n",
      "epoch:5 step:4745 [D loss: 0.601440, acc.: 66.41%] [G loss: 1.048999]\n",
      "epoch:5 step:4746 [D loss: 0.658681, acc.: 60.94%] [G loss: 0.941716]\n",
      "epoch:5 step:4747 [D loss: 0.743306, acc.: 47.66%] [G loss: 0.867506]\n",
      "epoch:5 step:4748 [D loss: 0.692730, acc.: 61.72%] [G loss: 0.967388]\n",
      "epoch:5 step:4749 [D loss: 0.656687, acc.: 63.28%] [G loss: 0.932465]\n",
      "epoch:5 step:4750 [D loss: 0.664567, acc.: 65.62%] [G loss: 0.935871]\n",
      "epoch:5 step:4751 [D loss: 0.663909, acc.: 58.59%] [G loss: 0.966660]\n",
      "epoch:5 step:4752 [D loss: 0.663023, acc.: 65.62%] [G loss: 0.962663]\n",
      "epoch:5 step:4753 [D loss: 0.659770, acc.: 64.06%] [G loss: 1.010090]\n",
      "epoch:5 step:4754 [D loss: 0.658463, acc.: 61.72%] [G loss: 1.034316]\n",
      "epoch:5 step:4755 [D loss: 0.736876, acc.: 48.44%] [G loss: 0.975565]\n",
      "epoch:5 step:4756 [D loss: 0.581113, acc.: 73.44%] [G loss: 1.038528]\n",
      "epoch:5 step:4757 [D loss: 0.572462, acc.: 72.66%] [G loss: 1.063196]\n",
      "epoch:5 step:4758 [D loss: 0.697033, acc.: 56.25%] [G loss: 0.876824]\n",
      "epoch:5 step:4759 [D loss: 0.630547, acc.: 65.62%] [G loss: 0.972037]\n",
      "epoch:5 step:4760 [D loss: 0.601740, acc.: 66.41%] [G loss: 1.059463]\n",
      "epoch:5 step:4761 [D loss: 0.626551, acc.: 66.41%] [G loss: 0.932720]\n",
      "epoch:5 step:4762 [D loss: 0.599734, acc.: 72.66%] [G loss: 0.949040]\n",
      "epoch:5 step:4763 [D loss: 0.665108, acc.: 62.50%] [G loss: 0.960926]\n",
      "epoch:5 step:4764 [D loss: 0.659267, acc.: 61.72%] [G loss: 0.962975]\n",
      "epoch:5 step:4765 [D loss: 0.697592, acc.: 57.03%] [G loss: 0.779489]\n",
      "epoch:5 step:4766 [D loss: 0.747570, acc.: 48.44%] [G loss: 0.962088]\n",
      "epoch:5 step:4767 [D loss: 0.670112, acc.: 55.47%] [G loss: 0.839561]\n",
      "epoch:5 step:4768 [D loss: 0.659643, acc.: 60.94%] [G loss: 1.027772]\n",
      "epoch:5 step:4769 [D loss: 0.679136, acc.: 53.91%] [G loss: 0.805090]\n",
      "epoch:5 step:4770 [D loss: 0.628903, acc.: 68.75%] [G loss: 0.841184]\n",
      "epoch:5 step:4771 [D loss: 0.721059, acc.: 54.69%] [G loss: 1.016000]\n",
      "epoch:5 step:4772 [D loss: 0.688240, acc.: 58.59%] [G loss: 0.948202]\n",
      "epoch:5 step:4773 [D loss: 0.618076, acc.: 66.41%] [G loss: 0.993369]\n",
      "epoch:5 step:4774 [D loss: 0.663300, acc.: 60.94%] [G loss: 0.856220]\n",
      "epoch:5 step:4775 [D loss: 0.620448, acc.: 67.19%] [G loss: 0.916869]\n",
      "epoch:5 step:4776 [D loss: 0.703845, acc.: 57.81%] [G loss: 0.934681]\n",
      "epoch:5 step:4777 [D loss: 0.662241, acc.: 58.59%] [G loss: 1.046330]\n",
      "epoch:5 step:4778 [D loss: 0.659144, acc.: 58.59%] [G loss: 0.852401]\n",
      "epoch:5 step:4779 [D loss: 0.640824, acc.: 62.50%] [G loss: 0.984428]\n",
      "epoch:5 step:4780 [D loss: 0.635495, acc.: 63.28%] [G loss: 0.922670]\n",
      "epoch:5 step:4781 [D loss: 0.637257, acc.: 64.84%] [G loss: 0.914289]\n",
      "epoch:5 step:4782 [D loss: 0.669218, acc.: 57.81%] [G loss: 0.975241]\n",
      "epoch:5 step:4783 [D loss: 0.647988, acc.: 61.72%] [G loss: 0.913407]\n",
      "epoch:5 step:4784 [D loss: 0.653862, acc.: 62.50%] [G loss: 1.006098]\n",
      "epoch:5 step:4785 [D loss: 0.653598, acc.: 59.38%] [G loss: 0.899660]\n",
      "epoch:5 step:4786 [D loss: 0.710996, acc.: 53.12%] [G loss: 0.849554]\n",
      "epoch:5 step:4787 [D loss: 0.705167, acc.: 53.91%] [G loss: 0.876199]\n",
      "epoch:5 step:4788 [D loss: 0.638837, acc.: 68.75%] [G loss: 0.950385]\n",
      "epoch:5 step:4789 [D loss: 0.688604, acc.: 56.25%] [G loss: 0.936258]\n",
      "epoch:5 step:4790 [D loss: 0.670009, acc.: 61.72%] [G loss: 0.952082]\n",
      "epoch:5 step:4791 [D loss: 0.654638, acc.: 60.16%] [G loss: 1.015389]\n",
      "epoch:5 step:4792 [D loss: 0.656618, acc.: 59.38%] [G loss: 1.020729]\n",
      "epoch:5 step:4793 [D loss: 0.705968, acc.: 59.38%] [G loss: 0.915894]\n",
      "epoch:5 step:4794 [D loss: 0.738997, acc.: 53.12%] [G loss: 0.951252]\n",
      "epoch:5 step:4795 [D loss: 0.706336, acc.: 57.81%] [G loss: 0.908002]\n",
      "epoch:5 step:4796 [D loss: 0.688641, acc.: 55.47%] [G loss: 0.928046]\n",
      "epoch:5 step:4797 [D loss: 0.622069, acc.: 66.41%] [G loss: 0.948831]\n",
      "epoch:5 step:4798 [D loss: 0.666792, acc.: 61.72%] [G loss: 0.977695]\n",
      "epoch:5 step:4799 [D loss: 0.713345, acc.: 51.56%] [G loss: 0.933306]\n",
      "epoch:5 step:4800 [D loss: 0.678304, acc.: 60.94%] [G loss: 0.928457]\n",
      "##############\n",
      "[1.9514483  1.19710809 5.04705827 4.21099641 2.53527055 5.25512683\n",
      " 3.85055342 4.34278127 3.37849355 3.01115135]\n",
      "##########\n",
      "epoch:5 step:4801 [D loss: 0.701214, acc.: 56.25%] [G loss: 0.931718]\n",
      "epoch:5 step:4802 [D loss: 0.625649, acc.: 66.41%] [G loss: 0.880559]\n",
      "epoch:5 step:4803 [D loss: 0.692430, acc.: 53.12%] [G loss: 0.954153]\n",
      "epoch:5 step:4804 [D loss: 0.681005, acc.: 55.47%] [G loss: 0.942849]\n",
      "epoch:5 step:4805 [D loss: 0.821468, acc.: 43.75%] [G loss: 0.974600]\n",
      "epoch:5 step:4806 [D loss: 0.671979, acc.: 57.03%] [G loss: 1.003762]\n",
      "epoch:5 step:4807 [D loss: 0.654428, acc.: 58.59%] [G loss: 1.041414]\n",
      "epoch:5 step:4808 [D loss: 0.630362, acc.: 68.75%] [G loss: 0.971388]\n",
      "epoch:5 step:4809 [D loss: 0.728473, acc.: 49.22%] [G loss: 0.968292]\n",
      "epoch:5 step:4810 [D loss: 0.727007, acc.: 51.56%] [G loss: 0.910802]\n",
      "epoch:5 step:4811 [D loss: 0.684264, acc.: 57.81%] [G loss: 0.980309]\n",
      "epoch:5 step:4812 [D loss: 0.612827, acc.: 67.19%] [G loss: 0.908936]\n",
      "epoch:5 step:4813 [D loss: 0.701974, acc.: 59.38%] [G loss: 0.974059]\n",
      "epoch:5 step:4814 [D loss: 0.674655, acc.: 60.94%] [G loss: 0.885246]\n",
      "epoch:5 step:4815 [D loss: 0.633735, acc.: 64.84%] [G loss: 0.833998]\n",
      "epoch:5 step:4816 [D loss: 0.668566, acc.: 59.38%] [G loss: 0.964523]\n",
      "epoch:5 step:4817 [D loss: 0.584954, acc.: 69.53%] [G loss: 0.950444]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4818 [D loss: 0.761343, acc.: 50.00%] [G loss: 0.842698]\n",
      "epoch:5 step:4819 [D loss: 0.660725, acc.: 62.50%] [G loss: 0.977694]\n",
      "epoch:5 step:4820 [D loss: 0.686881, acc.: 53.91%] [G loss: 0.855199]\n",
      "epoch:5 step:4821 [D loss: 0.698553, acc.: 53.12%] [G loss: 0.959252]\n",
      "epoch:5 step:4822 [D loss: 0.720304, acc.: 51.56%] [G loss: 0.954086]\n",
      "epoch:5 step:4823 [D loss: 0.643518, acc.: 57.03%] [G loss: 0.926952]\n",
      "epoch:5 step:4824 [D loss: 0.659038, acc.: 60.16%] [G loss: 1.004836]\n",
      "epoch:5 step:4825 [D loss: 0.681938, acc.: 56.25%] [G loss: 0.979203]\n",
      "epoch:5 step:4826 [D loss: 0.667265, acc.: 58.59%] [G loss: 1.005935]\n",
      "epoch:5 step:4827 [D loss: 0.700339, acc.: 59.38%] [G loss: 0.900186]\n",
      "epoch:5 step:4828 [D loss: 0.677730, acc.: 55.47%] [G loss: 0.962735]\n",
      "epoch:5 step:4829 [D loss: 0.642202, acc.: 67.19%] [G loss: 0.895342]\n",
      "epoch:5 step:4830 [D loss: 0.613025, acc.: 67.97%] [G loss: 0.893542]\n",
      "epoch:5 step:4831 [D loss: 0.722396, acc.: 54.69%] [G loss: 0.855448]\n",
      "epoch:5 step:4832 [D loss: 0.742223, acc.: 50.78%] [G loss: 1.004750]\n",
      "epoch:5 step:4833 [D loss: 0.721723, acc.: 52.34%] [G loss: 0.908935]\n",
      "epoch:5 step:4834 [D loss: 0.706160, acc.: 51.56%] [G loss: 1.044871]\n",
      "epoch:5 step:4835 [D loss: 0.769383, acc.: 48.44%] [G loss: 0.918414]\n",
      "epoch:5 step:4836 [D loss: 0.643147, acc.: 61.72%] [G loss: 1.021171]\n",
      "epoch:5 step:4837 [D loss: 0.651863, acc.: 57.81%] [G loss: 0.979196]\n",
      "epoch:5 step:4838 [D loss: 0.626169, acc.: 67.97%] [G loss: 0.957763]\n",
      "epoch:5 step:4839 [D loss: 0.609489, acc.: 68.75%] [G loss: 0.854989]\n",
      "epoch:5 step:4840 [D loss: 0.683616, acc.: 62.50%] [G loss: 0.947672]\n",
      "epoch:5 step:4841 [D loss: 0.649036, acc.: 57.03%] [G loss: 0.871663]\n",
      "epoch:5 step:4842 [D loss: 0.708856, acc.: 57.81%] [G loss: 0.942056]\n",
      "epoch:5 step:4843 [D loss: 0.614210, acc.: 66.41%] [G loss: 1.002860]\n",
      "epoch:5 step:4844 [D loss: 0.739313, acc.: 47.66%] [G loss: 0.867725]\n",
      "epoch:5 step:4845 [D loss: 0.684023, acc.: 55.47%] [G loss: 0.927172]\n",
      "epoch:5 step:4846 [D loss: 0.668697, acc.: 61.72%] [G loss: 0.859505]\n",
      "epoch:5 step:4847 [D loss: 0.631446, acc.: 66.41%] [G loss: 0.968428]\n",
      "epoch:5 step:4848 [D loss: 0.628914, acc.: 66.41%] [G loss: 0.995986]\n",
      "epoch:5 step:4849 [D loss: 0.690445, acc.: 53.12%] [G loss: 0.987398]\n",
      "epoch:5 step:4850 [D loss: 0.641746, acc.: 65.62%] [G loss: 0.899911]\n",
      "epoch:5 step:4851 [D loss: 0.690550, acc.: 54.69%] [G loss: 0.960640]\n",
      "epoch:5 step:4852 [D loss: 0.707377, acc.: 54.69%] [G loss: 1.031883]\n",
      "epoch:5 step:4853 [D loss: 0.597264, acc.: 70.31%] [G loss: 1.005850]\n",
      "epoch:5 step:4854 [D loss: 0.678206, acc.: 59.38%] [G loss: 0.902721]\n",
      "epoch:5 step:4855 [D loss: 0.661954, acc.: 62.50%] [G loss: 0.872846]\n",
      "epoch:5 step:4856 [D loss: 0.578174, acc.: 67.19%] [G loss: 1.005584]\n",
      "epoch:5 step:4857 [D loss: 0.673151, acc.: 55.47%] [G loss: 0.835466]\n",
      "epoch:5 step:4858 [D loss: 0.637653, acc.: 64.06%] [G loss: 0.941451]\n",
      "epoch:5 step:4859 [D loss: 0.686887, acc.: 55.47%] [G loss: 0.941118]\n",
      "epoch:5 step:4860 [D loss: 0.646866, acc.: 65.62%] [G loss: 0.933413]\n",
      "epoch:5 step:4861 [D loss: 0.643324, acc.: 65.62%] [G loss: 0.998597]\n",
      "epoch:5 step:4862 [D loss: 0.705563, acc.: 54.69%] [G loss: 0.877731]\n",
      "epoch:5 step:4863 [D loss: 0.687688, acc.: 57.81%] [G loss: 0.933751]\n",
      "epoch:5 step:4864 [D loss: 0.702401, acc.: 54.69%] [G loss: 0.892039]\n",
      "epoch:5 step:4865 [D loss: 0.683979, acc.: 54.69%] [G loss: 1.025258]\n",
      "epoch:5 step:4866 [D loss: 0.699776, acc.: 57.03%] [G loss: 0.921312]\n",
      "epoch:5 step:4867 [D loss: 0.708041, acc.: 55.47%] [G loss: 0.980009]\n",
      "epoch:5 step:4868 [D loss: 0.779597, acc.: 46.88%] [G loss: 0.808765]\n",
      "epoch:5 step:4869 [D loss: 0.715496, acc.: 54.69%] [G loss: 0.937564]\n",
      "epoch:5 step:4870 [D loss: 0.706684, acc.: 57.03%] [G loss: 0.951331]\n",
      "epoch:5 step:4871 [D loss: 0.655175, acc.: 61.72%] [G loss: 0.864729]\n",
      "epoch:5 step:4872 [D loss: 0.656462, acc.: 55.47%] [G loss: 1.040063]\n",
      "epoch:5 step:4873 [D loss: 0.627610, acc.: 61.72%] [G loss: 1.106457]\n",
      "epoch:5 step:4874 [D loss: 0.637717, acc.: 64.06%] [G loss: 0.928960]\n",
      "epoch:5 step:4875 [D loss: 0.631208, acc.: 64.06%] [G loss: 1.044929]\n",
      "epoch:5 step:4876 [D loss: 0.629871, acc.: 62.50%] [G loss: 0.989141]\n",
      "epoch:5 step:4877 [D loss: 0.685331, acc.: 60.16%] [G loss: 0.962828]\n",
      "epoch:5 step:4878 [D loss: 0.669352, acc.: 64.84%] [G loss: 0.825263]\n",
      "epoch:5 step:4879 [D loss: 0.619366, acc.: 69.53%] [G loss: 1.051898]\n",
      "epoch:5 step:4880 [D loss: 0.638261, acc.: 60.94%] [G loss: 0.987734]\n",
      "epoch:5 step:4881 [D loss: 0.697653, acc.: 55.47%] [G loss: 0.874423]\n",
      "epoch:5 step:4882 [D loss: 0.716831, acc.: 53.12%] [G loss: 0.885239]\n",
      "epoch:5 step:4883 [D loss: 0.740844, acc.: 53.91%] [G loss: 0.950868]\n",
      "epoch:5 step:4884 [D loss: 0.649217, acc.: 63.28%] [G loss: 0.950283]\n",
      "epoch:5 step:4885 [D loss: 0.713506, acc.: 52.34%] [G loss: 1.100921]\n",
      "epoch:5 step:4886 [D loss: 0.658063, acc.: 54.69%] [G loss: 0.912852]\n",
      "epoch:5 step:4887 [D loss: 0.690032, acc.: 61.72%] [G loss: 0.918045]\n",
      "epoch:5 step:4888 [D loss: 0.736010, acc.: 50.78%] [G loss: 1.020533]\n",
      "epoch:5 step:4889 [D loss: 0.678109, acc.: 56.25%] [G loss: 0.878868]\n",
      "epoch:5 step:4890 [D loss: 0.656660, acc.: 64.06%] [G loss: 0.849838]\n",
      "epoch:5 step:4891 [D loss: 0.661159, acc.: 59.38%] [G loss: 0.980200]\n",
      "epoch:5 step:4892 [D loss: 0.591624, acc.: 67.97%] [G loss: 1.060243]\n",
      "epoch:5 step:4893 [D loss: 0.577920, acc.: 74.22%] [G loss: 1.048481]\n",
      "epoch:5 step:4894 [D loss: 0.606928, acc.: 68.75%] [G loss: 0.955459]\n",
      "epoch:5 step:4895 [D loss: 0.716345, acc.: 55.47%] [G loss: 0.993740]\n",
      "epoch:5 step:4896 [D loss: 0.677568, acc.: 57.81%] [G loss: 0.899560]\n",
      "epoch:5 step:4897 [D loss: 0.658166, acc.: 62.50%] [G loss: 0.982927]\n",
      "epoch:5 step:4898 [D loss: 0.667876, acc.: 59.38%] [G loss: 0.915910]\n",
      "epoch:5 step:4899 [D loss: 0.735076, acc.: 45.31%] [G loss: 0.929249]\n",
      "epoch:5 step:4900 [D loss: 0.771817, acc.: 43.75%] [G loss: 0.912766]\n",
      "epoch:5 step:4901 [D loss: 0.600180, acc.: 68.75%] [G loss: 0.924879]\n",
      "epoch:5 step:4902 [D loss: 0.684413, acc.: 54.69%] [G loss: 0.971542]\n",
      "epoch:5 step:4903 [D loss: 0.611990, acc.: 67.97%] [G loss: 0.983512]\n",
      "epoch:5 step:4904 [D loss: 0.603263, acc.: 67.97%] [G loss: 1.045270]\n",
      "epoch:5 step:4905 [D loss: 0.712663, acc.: 52.34%] [G loss: 0.924658]\n",
      "epoch:5 step:4906 [D loss: 0.721243, acc.: 54.69%] [G loss: 1.021039]\n",
      "epoch:5 step:4907 [D loss: 0.694681, acc.: 54.69%] [G loss: 0.900650]\n",
      "epoch:5 step:4908 [D loss: 0.671823, acc.: 59.38%] [G loss: 1.029963]\n",
      "epoch:5 step:4909 [D loss: 0.723440, acc.: 56.25%] [G loss: 1.000413]\n",
      "epoch:5 step:4910 [D loss: 0.680914, acc.: 60.94%] [G loss: 0.864445]\n",
      "epoch:5 step:4911 [D loss: 0.685480, acc.: 55.47%] [G loss: 0.872839]\n",
      "epoch:5 step:4912 [D loss: 0.735951, acc.: 49.22%] [G loss: 0.969608]\n",
      "epoch:5 step:4913 [D loss: 0.765931, acc.: 50.00%] [G loss: 0.898615]\n",
      "epoch:5 step:4914 [D loss: 0.647150, acc.: 61.72%] [G loss: 0.868998]\n",
      "epoch:5 step:4915 [D loss: 0.611421, acc.: 65.62%] [G loss: 1.018193]\n",
      "epoch:5 step:4916 [D loss: 0.564779, acc.: 71.88%] [G loss: 1.164340]\n",
      "epoch:5 step:4917 [D loss: 0.610891, acc.: 62.50%] [G loss: 0.989740]\n",
      "epoch:5 step:4918 [D loss: 0.688312, acc.: 60.16%] [G loss: 1.093335]\n",
      "epoch:5 step:4919 [D loss: 0.725674, acc.: 57.81%] [G loss: 1.011917]\n",
      "epoch:5 step:4920 [D loss: 0.668460, acc.: 60.94%] [G loss: 1.094514]\n",
      "epoch:5 step:4921 [D loss: 0.661701, acc.: 63.28%] [G loss: 1.057576]\n",
      "epoch:5 step:4922 [D loss: 0.660360, acc.: 57.03%] [G loss: 0.884666]\n",
      "epoch:5 step:4923 [D loss: 0.723315, acc.: 52.34%] [G loss: 0.980393]\n",
      "epoch:5 step:4924 [D loss: 0.674123, acc.: 60.94%] [G loss: 0.884900]\n",
      "epoch:5 step:4925 [D loss: 0.640429, acc.: 65.62%] [G loss: 0.957690]\n",
      "epoch:5 step:4926 [D loss: 0.781497, acc.: 47.66%] [G loss: 0.883760]\n",
      "epoch:5 step:4927 [D loss: 0.672911, acc.: 57.81%] [G loss: 0.855967]\n",
      "epoch:5 step:4928 [D loss: 0.628950, acc.: 61.72%] [G loss: 0.991624]\n",
      "epoch:5 step:4929 [D loss: 0.655343, acc.: 62.50%] [G loss: 0.963942]\n",
      "epoch:5 step:4930 [D loss: 0.590735, acc.: 73.44%] [G loss: 0.924475]\n",
      "epoch:5 step:4931 [D loss: 0.728070, acc.: 50.00%] [G loss: 0.851004]\n",
      "epoch:5 step:4932 [D loss: 0.719490, acc.: 50.00%] [G loss: 0.858110]\n",
      "epoch:5 step:4933 [D loss: 0.656541, acc.: 56.25%] [G loss: 0.924376]\n",
      "epoch:5 step:4934 [D loss: 0.733480, acc.: 49.22%] [G loss: 0.934791]\n",
      "epoch:5 step:4935 [D loss: 0.691719, acc.: 56.25%] [G loss: 0.989146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4936 [D loss: 0.764170, acc.: 45.31%] [G loss: 0.970128]\n",
      "epoch:5 step:4937 [D loss: 0.704361, acc.: 53.91%] [G loss: 0.861002]\n",
      "epoch:5 step:4938 [D loss: 0.657359, acc.: 59.38%] [G loss: 0.895034]\n",
      "epoch:5 step:4939 [D loss: 0.621171, acc.: 69.53%] [G loss: 0.915816]\n",
      "epoch:5 step:4940 [D loss: 0.615315, acc.: 65.62%] [G loss: 0.921083]\n",
      "epoch:5 step:4941 [D loss: 0.650118, acc.: 67.19%] [G loss: 0.956614]\n",
      "epoch:5 step:4942 [D loss: 0.696524, acc.: 53.91%] [G loss: 0.884178]\n",
      "epoch:5 step:4943 [D loss: 0.660830, acc.: 55.47%] [G loss: 0.927992]\n",
      "epoch:5 step:4944 [D loss: 0.619526, acc.: 64.06%] [G loss: 0.984477]\n",
      "epoch:5 step:4945 [D loss: 0.704055, acc.: 53.12%] [G loss: 1.019957]\n",
      "epoch:5 step:4946 [D loss: 0.712162, acc.: 56.25%] [G loss: 0.984681]\n",
      "epoch:5 step:4947 [D loss: 0.663514, acc.: 57.81%] [G loss: 0.981642]\n",
      "epoch:5 step:4948 [D loss: 0.725506, acc.: 50.78%] [G loss: 0.929711]\n",
      "epoch:5 step:4949 [D loss: 0.621798, acc.: 64.06%] [G loss: 1.000581]\n",
      "epoch:5 step:4950 [D loss: 0.619936, acc.: 64.84%] [G loss: 0.854054]\n",
      "epoch:5 step:4951 [D loss: 0.726922, acc.: 50.00%] [G loss: 0.938704]\n",
      "epoch:5 step:4952 [D loss: 0.660884, acc.: 57.81%] [G loss: 0.825238]\n",
      "epoch:5 step:4953 [D loss: 0.635842, acc.: 65.62%] [G loss: 0.955284]\n",
      "epoch:5 step:4954 [D loss: 0.648632, acc.: 64.06%] [G loss: 0.925740]\n",
      "epoch:5 step:4955 [D loss: 0.599405, acc.: 71.09%] [G loss: 0.833481]\n",
      "epoch:5 step:4956 [D loss: 0.657133, acc.: 55.47%] [G loss: 0.870933]\n",
      "epoch:5 step:4957 [D loss: 0.631546, acc.: 61.72%] [G loss: 0.953879]\n",
      "epoch:5 step:4958 [D loss: 0.618763, acc.: 67.97%] [G loss: 0.998490]\n",
      "epoch:5 step:4959 [D loss: 0.615652, acc.: 59.38%] [G loss: 0.931413]\n",
      "epoch:5 step:4960 [D loss: 0.637726, acc.: 67.97%] [G loss: 0.890719]\n",
      "epoch:5 step:4961 [D loss: 0.636060, acc.: 60.94%] [G loss: 0.943546]\n",
      "epoch:5 step:4962 [D loss: 0.715923, acc.: 53.91%] [G loss: 0.947768]\n",
      "epoch:5 step:4963 [D loss: 0.693712, acc.: 51.56%] [G loss: 0.808985]\n",
      "epoch:5 step:4964 [D loss: 0.768734, acc.: 46.09%] [G loss: 0.848919]\n",
      "epoch:5 step:4965 [D loss: 0.659626, acc.: 62.50%] [G loss: 0.882226]\n",
      "epoch:5 step:4966 [D loss: 0.798545, acc.: 44.53%] [G loss: 0.765905]\n",
      "epoch:5 step:4967 [D loss: 0.693529, acc.: 59.38%] [G loss: 1.030237]\n",
      "epoch:5 step:4968 [D loss: 0.621417, acc.: 58.59%] [G loss: 0.991579]\n",
      "epoch:5 step:4969 [D loss: 0.647237, acc.: 64.84%] [G loss: 0.960887]\n",
      "epoch:5 step:4970 [D loss: 0.680671, acc.: 61.72%] [G loss: 0.868212]\n",
      "epoch:5 step:4971 [D loss: 0.713223, acc.: 55.47%] [G loss: 0.819316]\n",
      "epoch:5 step:4972 [D loss: 0.697368, acc.: 59.38%] [G loss: 0.853164]\n",
      "epoch:5 step:4973 [D loss: 0.673918, acc.: 59.38%] [G loss: 0.950200]\n",
      "epoch:5 step:4974 [D loss: 0.663302, acc.: 60.16%] [G loss: 0.833853]\n",
      "epoch:5 step:4975 [D loss: 0.721649, acc.: 54.69%] [G loss: 0.904673]\n",
      "epoch:5 step:4976 [D loss: 0.674466, acc.: 55.47%] [G loss: 0.928223]\n",
      "epoch:5 step:4977 [D loss: 0.689909, acc.: 50.78%] [G loss: 0.866502]\n",
      "epoch:5 step:4978 [D loss: 0.684766, acc.: 57.03%] [G loss: 0.845052]\n",
      "epoch:5 step:4979 [D loss: 0.681366, acc.: 53.91%] [G loss: 0.848605]\n",
      "epoch:5 step:4980 [D loss: 0.629472, acc.: 67.97%] [G loss: 0.939019]\n",
      "epoch:5 step:4981 [D loss: 0.581425, acc.: 73.44%] [G loss: 0.943868]\n",
      "epoch:5 step:4982 [D loss: 0.721677, acc.: 48.44%] [G loss: 0.929990]\n",
      "epoch:5 step:4983 [D loss: 0.635762, acc.: 64.06%] [G loss: 0.912077]\n",
      "epoch:5 step:4984 [D loss: 0.668681, acc.: 58.59%] [G loss: 0.846105]\n",
      "epoch:5 step:4985 [D loss: 0.622974, acc.: 67.97%] [G loss: 1.027197]\n",
      "epoch:5 step:4986 [D loss: 0.794200, acc.: 40.62%] [G loss: 0.837905]\n",
      "epoch:5 step:4987 [D loss: 0.637110, acc.: 62.50%] [G loss: 0.875722]\n",
      "epoch:5 step:4988 [D loss: 0.628752, acc.: 61.72%] [G loss: 0.936631]\n",
      "epoch:5 step:4989 [D loss: 0.659389, acc.: 60.94%] [G loss: 0.919898]\n",
      "epoch:5 step:4990 [D loss: 0.716351, acc.: 48.44%] [G loss: 0.865523]\n",
      "epoch:5 step:4991 [D loss: 0.663914, acc.: 60.16%] [G loss: 0.869735]\n",
      "epoch:5 step:4992 [D loss: 0.658441, acc.: 58.59%] [G loss: 0.814311]\n",
      "epoch:5 step:4993 [D loss: 0.687776, acc.: 56.25%] [G loss: 0.879010]\n",
      "epoch:5 step:4994 [D loss: 0.629016, acc.: 66.41%] [G loss: 0.921087]\n",
      "epoch:5 step:4995 [D loss: 0.571930, acc.: 69.53%] [G loss: 1.136825]\n",
      "epoch:5 step:4996 [D loss: 0.654206, acc.: 63.28%] [G loss: 0.928324]\n",
      "epoch:5 step:4997 [D loss: 0.672972, acc.: 57.03%] [G loss: 1.019676]\n",
      "epoch:5 step:4998 [D loss: 0.635568, acc.: 65.62%] [G loss: 1.100952]\n",
      "epoch:5 step:4999 [D loss: 0.615593, acc.: 69.53%] [G loss: 0.994422]\n",
      "epoch:5 step:5000 [D loss: 0.547653, acc.: 71.88%] [G loss: 1.027764]\n",
      "##############\n",
      "[2.04663215 0.70409019 4.92613031 3.95105054 2.48261288 4.80119469\n",
      " 3.69885845 4.08353085 3.563148   3.11567724]\n",
      "##########\n",
      "epoch:5 step:5001 [D loss: 0.715974, acc.: 53.91%] [G loss: 0.977916]\n",
      "epoch:5 step:5002 [D loss: 0.689737, acc.: 57.03%] [G loss: 1.119312]\n",
      "epoch:5 step:5003 [D loss: 0.664859, acc.: 63.28%] [G loss: 0.963989]\n",
      "epoch:5 step:5004 [D loss: 0.696237, acc.: 56.25%] [G loss: 0.922745]\n",
      "epoch:5 step:5005 [D loss: 0.734764, acc.: 49.22%] [G loss: 0.892449]\n",
      "epoch:5 step:5006 [D loss: 0.702435, acc.: 57.03%] [G loss: 0.895919]\n",
      "epoch:5 step:5007 [D loss: 0.663172, acc.: 57.81%] [G loss: 0.839785]\n",
      "epoch:5 step:5008 [D loss: 0.708978, acc.: 56.25%] [G loss: 0.955537]\n",
      "epoch:5 step:5009 [D loss: 0.640275, acc.: 63.28%] [G loss: 0.978234]\n",
      "epoch:5 step:5010 [D loss: 0.670751, acc.: 60.16%] [G loss: 0.945894]\n",
      "epoch:5 step:5011 [D loss: 0.675882, acc.: 59.38%] [G loss: 0.901911]\n",
      "epoch:5 step:5012 [D loss: 0.695998, acc.: 55.47%] [G loss: 0.974023]\n",
      "epoch:5 step:5013 [D loss: 0.676244, acc.: 59.38%] [G loss: 0.929526]\n",
      "epoch:5 step:5014 [D loss: 0.647055, acc.: 55.47%] [G loss: 0.845685]\n",
      "epoch:5 step:5015 [D loss: 0.612991, acc.: 64.06%] [G loss: 0.981495]\n",
      "epoch:5 step:5016 [D loss: 0.699165, acc.: 60.94%] [G loss: 0.911751]\n",
      "epoch:5 step:5017 [D loss: 0.685780, acc.: 60.94%] [G loss: 0.970845]\n",
      "epoch:5 step:5018 [D loss: 0.610853, acc.: 68.75%] [G loss: 0.885620]\n",
      "epoch:5 step:5019 [D loss: 0.716269, acc.: 50.78%] [G loss: 1.032180]\n",
      "epoch:5 step:5020 [D loss: 0.694571, acc.: 56.25%] [G loss: 0.957969]\n",
      "epoch:5 step:5021 [D loss: 0.578232, acc.: 68.75%] [G loss: 0.972103]\n",
      "epoch:5 step:5022 [D loss: 0.604029, acc.: 67.97%] [G loss: 0.960296]\n",
      "epoch:5 step:5023 [D loss: 0.647679, acc.: 67.19%] [G loss: 0.992972]\n",
      "epoch:5 step:5024 [D loss: 0.735963, acc.: 54.69%] [G loss: 0.946895]\n",
      "epoch:5 step:5025 [D loss: 0.661286, acc.: 59.38%] [G loss: 0.949488]\n",
      "epoch:5 step:5026 [D loss: 0.675729, acc.: 58.59%] [G loss: 0.916213]\n",
      "epoch:5 step:5027 [D loss: 0.667810, acc.: 60.94%] [G loss: 0.930974]\n",
      "epoch:5 step:5028 [D loss: 0.672184, acc.: 53.91%] [G loss: 0.754742]\n",
      "epoch:5 step:5029 [D loss: 0.676135, acc.: 60.94%] [G loss: 0.891256]\n",
      "epoch:5 step:5030 [D loss: 0.650956, acc.: 61.72%] [G loss: 1.022154]\n",
      "epoch:5 step:5031 [D loss: 0.683235, acc.: 57.81%] [G loss: 0.868964]\n",
      "epoch:5 step:5032 [D loss: 0.632214, acc.: 63.28%] [G loss: 0.979751]\n",
      "epoch:5 step:5033 [D loss: 0.732627, acc.: 53.12%] [G loss: 0.875525]\n",
      "epoch:5 step:5034 [D loss: 0.767502, acc.: 49.22%] [G loss: 0.955923]\n",
      "epoch:5 step:5035 [D loss: 0.688621, acc.: 57.03%] [G loss: 0.975111]\n",
      "epoch:5 step:5036 [D loss: 0.680328, acc.: 60.16%] [G loss: 0.774703]\n",
      "epoch:5 step:5037 [D loss: 0.704805, acc.: 56.25%] [G loss: 0.882519]\n",
      "epoch:5 step:5038 [D loss: 0.658831, acc.: 63.28%] [G loss: 0.934569]\n",
      "epoch:5 step:5039 [D loss: 0.675201, acc.: 54.69%] [G loss: 0.912620]\n",
      "epoch:5 step:5040 [D loss: 0.631822, acc.: 63.28%] [G loss: 0.917635]\n",
      "epoch:5 step:5041 [D loss: 0.715474, acc.: 57.81%] [G loss: 0.831665]\n",
      "epoch:5 step:5042 [D loss: 0.659616, acc.: 63.28%] [G loss: 0.977959]\n",
      "epoch:5 step:5043 [D loss: 0.604285, acc.: 64.84%] [G loss: 1.033756]\n",
      "epoch:5 step:5044 [D loss: 0.654002, acc.: 60.16%] [G loss: 0.976253]\n",
      "epoch:5 step:5045 [D loss: 0.676702, acc.: 57.03%] [G loss: 0.949796]\n",
      "epoch:5 step:5046 [D loss: 0.675056, acc.: 58.59%] [G loss: 0.977930]\n",
      "epoch:5 step:5047 [D loss: 0.713283, acc.: 57.81%] [G loss: 0.892095]\n",
      "epoch:5 step:5048 [D loss: 0.657927, acc.: 58.59%] [G loss: 0.977573]\n",
      "epoch:5 step:5049 [D loss: 0.653410, acc.: 60.94%] [G loss: 0.987894]\n",
      "epoch:5 step:5050 [D loss: 0.677438, acc.: 57.81%] [G loss: 0.966511]\n",
      "epoch:5 step:5051 [D loss: 0.668422, acc.: 55.47%] [G loss: 0.947608]\n",
      "epoch:5 step:5052 [D loss: 0.622829, acc.: 67.19%] [G loss: 0.935797]\n",
      "epoch:5 step:5053 [D loss: 0.681746, acc.: 59.38%] [G loss: 0.840370]\n",
      "epoch:5 step:5054 [D loss: 0.642978, acc.: 64.06%] [G loss: 1.040001]\n",
      "epoch:5 step:5055 [D loss: 0.591200, acc.: 64.84%] [G loss: 0.961006]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5056 [D loss: 0.650345, acc.: 62.50%] [G loss: 0.917154]\n",
      "epoch:5 step:5057 [D loss: 0.653608, acc.: 61.72%] [G loss: 0.900615]\n",
      "epoch:5 step:5058 [D loss: 0.751108, acc.: 44.53%] [G loss: 0.902956]\n",
      "epoch:5 step:5059 [D loss: 0.630452, acc.: 65.62%] [G loss: 0.962079]\n",
      "epoch:5 step:5060 [D loss: 0.758728, acc.: 46.09%] [G loss: 0.853707]\n",
      "epoch:5 step:5061 [D loss: 0.729765, acc.: 50.78%] [G loss: 0.924585]\n",
      "epoch:5 step:5062 [D loss: 0.678361, acc.: 57.81%] [G loss: 1.025609]\n",
      "epoch:5 step:5063 [D loss: 0.683476, acc.: 56.25%] [G loss: 0.894654]\n",
      "epoch:5 step:5064 [D loss: 0.639687, acc.: 60.94%] [G loss: 0.896478]\n",
      "epoch:5 step:5065 [D loss: 0.640610, acc.: 57.81%] [G loss: 0.831668]\n",
      "epoch:5 step:5066 [D loss: 0.593135, acc.: 68.75%] [G loss: 0.928875]\n",
      "epoch:5 step:5067 [D loss: 0.759756, acc.: 44.53%] [G loss: 0.828761]\n",
      "epoch:5 step:5068 [D loss: 0.650630, acc.: 60.16%] [G loss: 0.947010]\n",
      "epoch:5 step:5069 [D loss: 0.600235, acc.: 69.53%] [G loss: 1.003381]\n",
      "epoch:5 step:5070 [D loss: 0.595642, acc.: 69.53%] [G loss: 0.982695]\n",
      "epoch:5 step:5071 [D loss: 0.749219, acc.: 46.09%] [G loss: 0.902068]\n",
      "epoch:5 step:5072 [D loss: 0.657457, acc.: 59.38%] [G loss: 0.966228]\n",
      "epoch:5 step:5073 [D loss: 0.730293, acc.: 54.69%] [G loss: 0.851131]\n",
      "epoch:5 step:5074 [D loss: 0.686802, acc.: 57.81%] [G loss: 1.036350]\n",
      "epoch:5 step:5075 [D loss: 0.684375, acc.: 55.47%] [G loss: 0.939384]\n",
      "epoch:5 step:5076 [D loss: 0.647253, acc.: 62.50%] [G loss: 0.947614]\n",
      "epoch:5 step:5077 [D loss: 0.674361, acc.: 56.25%] [G loss: 0.988233]\n",
      "epoch:5 step:5078 [D loss: 0.700489, acc.: 52.34%] [G loss: 0.995874]\n",
      "epoch:5 step:5079 [D loss: 0.693149, acc.: 53.12%] [G loss: 0.875105]\n",
      "epoch:5 step:5080 [D loss: 0.660047, acc.: 57.81%] [G loss: 0.942908]\n",
      "epoch:5 step:5081 [D loss: 0.723454, acc.: 55.47%] [G loss: 1.035894]\n",
      "epoch:5 step:5082 [D loss: 0.730833, acc.: 51.56%] [G loss: 0.893255]\n",
      "epoch:5 step:5083 [D loss: 0.664178, acc.: 57.03%] [G loss: 0.881133]\n",
      "epoch:5 step:5084 [D loss: 0.607634, acc.: 67.97%] [G loss: 0.979025]\n",
      "epoch:5 step:5085 [D loss: 0.694179, acc.: 53.91%] [G loss: 0.917559]\n",
      "epoch:5 step:5086 [D loss: 0.667847, acc.: 57.81%] [G loss: 1.024428]\n",
      "epoch:5 step:5087 [D loss: 0.612603, acc.: 69.53%] [G loss: 1.090229]\n",
      "epoch:5 step:5088 [D loss: 0.681863, acc.: 50.78%] [G loss: 0.946401]\n",
      "epoch:5 step:5089 [D loss: 0.604119, acc.: 64.06%] [G loss: 1.084435]\n",
      "epoch:5 step:5090 [D loss: 0.593638, acc.: 71.88%] [G loss: 1.019192]\n",
      "epoch:5 step:5091 [D loss: 0.602314, acc.: 64.84%] [G loss: 1.081967]\n",
      "epoch:5 step:5092 [D loss: 0.626114, acc.: 67.19%] [G loss: 1.074060]\n",
      "epoch:5 step:5093 [D loss: 0.698579, acc.: 58.59%] [G loss: 1.026300]\n",
      "epoch:5 step:5094 [D loss: 0.650867, acc.: 60.94%] [G loss: 0.917788]\n",
      "epoch:5 step:5095 [D loss: 0.638569, acc.: 60.94%] [G loss: 0.967831]\n",
      "epoch:5 step:5096 [D loss: 0.692979, acc.: 59.38%] [G loss: 0.957512]\n",
      "epoch:5 step:5097 [D loss: 0.707551, acc.: 54.69%] [G loss: 0.954574]\n",
      "epoch:5 step:5098 [D loss: 0.637052, acc.: 62.50%] [G loss: 0.917166]\n",
      "epoch:5 step:5099 [D loss: 0.643764, acc.: 62.50%] [G loss: 0.893493]\n",
      "epoch:5 step:5100 [D loss: 0.667725, acc.: 57.81%] [G loss: 1.017951]\n",
      "epoch:5 step:5101 [D loss: 0.681428, acc.: 58.59%] [G loss: 0.902930]\n",
      "epoch:5 step:5102 [D loss: 0.707310, acc.: 55.47%] [G loss: 0.782764]\n",
      "epoch:5 step:5103 [D loss: 0.639720, acc.: 60.94%] [G loss: 0.875861]\n",
      "epoch:5 step:5104 [D loss: 0.667537, acc.: 63.28%] [G loss: 0.941393]\n",
      "epoch:5 step:5105 [D loss: 0.611928, acc.: 61.72%] [G loss: 0.923329]\n",
      "epoch:5 step:5106 [D loss: 0.673404, acc.: 60.16%] [G loss: 0.968366]\n",
      "epoch:5 step:5107 [D loss: 0.709834, acc.: 52.34%] [G loss: 0.949046]\n",
      "epoch:5 step:5108 [D loss: 0.742117, acc.: 51.56%] [G loss: 0.937330]\n",
      "epoch:5 step:5109 [D loss: 0.710330, acc.: 52.34%] [G loss: 0.863706]\n",
      "epoch:5 step:5110 [D loss: 0.713003, acc.: 50.78%] [G loss: 0.923700]\n",
      "epoch:5 step:5111 [D loss: 0.710168, acc.: 57.81%] [G loss: 0.869939]\n",
      "epoch:5 step:5112 [D loss: 0.687053, acc.: 57.81%] [G loss: 0.850977]\n",
      "epoch:5 step:5113 [D loss: 0.629349, acc.: 63.28%] [G loss: 0.990454]\n",
      "epoch:5 step:5114 [D loss: 0.655554, acc.: 63.28%] [G loss: 1.055965]\n",
      "epoch:5 step:5115 [D loss: 0.632259, acc.: 60.16%] [G loss: 1.076285]\n",
      "epoch:5 step:5116 [D loss: 0.666738, acc.: 57.81%] [G loss: 0.980418]\n",
      "epoch:5 step:5117 [D loss: 0.749489, acc.: 51.56%] [G loss: 0.980588]\n",
      "epoch:5 step:5118 [D loss: 0.718782, acc.: 54.69%] [G loss: 0.872683]\n",
      "epoch:5 step:5119 [D loss: 0.695402, acc.: 60.94%] [G loss: 0.880141]\n",
      "epoch:5 step:5120 [D loss: 0.683650, acc.: 52.34%] [G loss: 0.920939]\n",
      "epoch:5 step:5121 [D loss: 0.792820, acc.: 37.50%] [G loss: 0.847290]\n",
      "epoch:5 step:5122 [D loss: 0.648859, acc.: 63.28%] [G loss: 0.931752]\n",
      "epoch:5 step:5123 [D loss: 0.629750, acc.: 67.97%] [G loss: 0.947219]\n",
      "epoch:5 step:5124 [D loss: 0.602948, acc.: 63.28%] [G loss: 1.034691]\n",
      "epoch:5 step:5125 [D loss: 0.731086, acc.: 54.69%] [G loss: 0.878968]\n",
      "epoch:5 step:5126 [D loss: 0.663887, acc.: 60.94%] [G loss: 0.953492]\n",
      "epoch:5 step:5127 [D loss: 0.747137, acc.: 50.00%] [G loss: 0.846293]\n",
      "epoch:5 step:5128 [D loss: 0.668141, acc.: 59.38%] [G loss: 0.969396]\n",
      "epoch:5 step:5129 [D loss: 0.638776, acc.: 62.50%] [G loss: 0.827885]\n",
      "epoch:5 step:5130 [D loss: 0.624507, acc.: 62.50%] [G loss: 0.922823]\n",
      "epoch:5 step:5131 [D loss: 0.686602, acc.: 53.91%] [G loss: 0.975350]\n",
      "epoch:5 step:5132 [D loss: 0.619460, acc.: 64.06%] [G loss: 0.946025]\n",
      "epoch:5 step:5133 [D loss: 0.772245, acc.: 45.31%] [G loss: 0.898590]\n",
      "epoch:5 step:5134 [D loss: 0.734977, acc.: 53.12%] [G loss: 1.063871]\n",
      "epoch:5 step:5135 [D loss: 0.708273, acc.: 59.38%] [G loss: 0.997051]\n",
      "epoch:5 step:5136 [D loss: 0.646862, acc.: 61.72%] [G loss: 0.991796]\n",
      "epoch:5 step:5137 [D loss: 0.688897, acc.: 61.72%] [G loss: 0.885485]\n",
      "epoch:5 step:5138 [D loss: 0.621820, acc.: 71.88%] [G loss: 0.991732]\n",
      "epoch:5 step:5139 [D loss: 0.635767, acc.: 66.41%] [G loss: 0.971776]\n",
      "epoch:5 step:5140 [D loss: 0.636269, acc.: 64.06%] [G loss: 1.013198]\n",
      "epoch:5 step:5141 [D loss: 0.619548, acc.: 65.62%] [G loss: 1.026710]\n",
      "epoch:5 step:5142 [D loss: 0.653693, acc.: 60.16%] [G loss: 0.938049]\n",
      "epoch:5 step:5143 [D loss: 0.704513, acc.: 56.25%] [G loss: 0.967855]\n",
      "epoch:5 step:5144 [D loss: 0.709642, acc.: 50.78%] [G loss: 0.851105]\n",
      "epoch:5 step:5145 [D loss: 0.770256, acc.: 45.31%] [G loss: 0.871261]\n",
      "epoch:5 step:5146 [D loss: 0.680969, acc.: 53.91%] [G loss: 0.942380]\n",
      "epoch:5 step:5147 [D loss: 0.714104, acc.: 53.91%] [G loss: 0.989237]\n",
      "epoch:5 step:5148 [D loss: 0.677141, acc.: 59.38%] [G loss: 0.912032]\n",
      "epoch:5 step:5149 [D loss: 0.664346, acc.: 54.69%] [G loss: 0.877549]\n",
      "epoch:5 step:5150 [D loss: 0.702169, acc.: 55.47%] [G loss: 0.920587]\n",
      "epoch:5 step:5151 [D loss: 0.653069, acc.: 60.94%] [G loss: 0.867937]\n",
      "epoch:5 step:5152 [D loss: 0.682586, acc.: 54.69%] [G loss: 0.970968]\n",
      "epoch:5 step:5153 [D loss: 0.630326, acc.: 64.84%] [G loss: 0.967532]\n",
      "epoch:5 step:5154 [D loss: 0.622968, acc.: 66.41%] [G loss: 1.016760]\n",
      "epoch:5 step:5155 [D loss: 0.615308, acc.: 64.06%] [G loss: 1.024768]\n",
      "epoch:5 step:5156 [D loss: 0.572568, acc.: 74.22%] [G loss: 1.009038]\n",
      "epoch:5 step:5157 [D loss: 0.637358, acc.: 60.94%] [G loss: 1.011614]\n",
      "epoch:5 step:5158 [D loss: 0.747531, acc.: 54.69%] [G loss: 0.898541]\n",
      "epoch:5 step:5159 [D loss: 0.672305, acc.: 49.22%] [G loss: 0.972349]\n",
      "epoch:5 step:5160 [D loss: 0.651147, acc.: 63.28%] [G loss: 1.019948]\n",
      "epoch:5 step:5161 [D loss: 0.671199, acc.: 60.16%] [G loss: 0.989185]\n",
      "epoch:5 step:5162 [D loss: 0.683114, acc.: 58.59%] [G loss: 0.971275]\n",
      "epoch:5 step:5163 [D loss: 0.670412, acc.: 60.16%] [G loss: 0.904608]\n",
      "epoch:5 step:5164 [D loss: 0.717806, acc.: 53.91%] [G loss: 0.779101]\n",
      "epoch:5 step:5165 [D loss: 0.721900, acc.: 51.56%] [G loss: 0.898463]\n",
      "epoch:5 step:5166 [D loss: 0.648707, acc.: 62.50%] [G loss: 0.906310]\n",
      "epoch:5 step:5167 [D loss: 0.701943, acc.: 49.22%] [G loss: 0.830340]\n",
      "epoch:5 step:5168 [D loss: 0.658753, acc.: 64.06%] [G loss: 0.966409]\n",
      "epoch:5 step:5169 [D loss: 0.742522, acc.: 50.78%] [G loss: 0.840879]\n",
      "epoch:5 step:5170 [D loss: 0.720461, acc.: 48.44%] [G loss: 0.917594]\n",
      "epoch:5 step:5171 [D loss: 0.690115, acc.: 53.91%] [G loss: 0.923059]\n",
      "epoch:5 step:5172 [D loss: 0.716325, acc.: 57.81%] [G loss: 0.973395]\n",
      "epoch:5 step:5173 [D loss: 0.621377, acc.: 64.06%] [G loss: 0.881322]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5174 [D loss: 0.598966, acc.: 67.19%] [G loss: 0.989681]\n",
      "epoch:5 step:5175 [D loss: 0.650927, acc.: 62.50%] [G loss: 0.828977]\n",
      "epoch:5 step:5176 [D loss: 0.691011, acc.: 54.69%] [G loss: 0.906015]\n",
      "epoch:5 step:5177 [D loss: 0.629811, acc.: 62.50%] [G loss: 1.020557]\n",
      "epoch:5 step:5178 [D loss: 0.702105, acc.: 54.69%] [G loss: 0.956210]\n",
      "epoch:5 step:5179 [D loss: 0.658316, acc.: 59.38%] [G loss: 0.877951]\n",
      "epoch:5 step:5180 [D loss: 0.694754, acc.: 57.81%] [G loss: 0.943544]\n",
      "epoch:5 step:5181 [D loss: 0.731612, acc.: 50.00%] [G loss: 0.845871]\n",
      "epoch:5 step:5182 [D loss: 0.694761, acc.: 55.47%] [G loss: 0.982932]\n",
      "epoch:5 step:5183 [D loss: 0.669216, acc.: 60.16%] [G loss: 0.911659]\n",
      "epoch:5 step:5184 [D loss: 0.576798, acc.: 69.53%] [G loss: 1.150040]\n",
      "epoch:5 step:5185 [D loss: 0.778605, acc.: 48.44%] [G loss: 0.899277]\n",
      "epoch:5 step:5186 [D loss: 0.710227, acc.: 55.47%] [G loss: 0.949671]\n",
      "epoch:5 step:5187 [D loss: 0.743231, acc.: 50.78%] [G loss: 0.928261]\n",
      "epoch:5 step:5188 [D loss: 0.634871, acc.: 60.16%] [G loss: 0.835056]\n",
      "epoch:5 step:5189 [D loss: 0.640567, acc.: 63.28%] [G loss: 0.959618]\n",
      "epoch:5 step:5190 [D loss: 0.674372, acc.: 59.38%] [G loss: 0.869099]\n",
      "epoch:5 step:5191 [D loss: 0.670750, acc.: 57.81%] [G loss: 0.934430]\n",
      "epoch:5 step:5192 [D loss: 0.738418, acc.: 50.00%] [G loss: 0.923580]\n",
      "epoch:5 step:5193 [D loss: 0.631983, acc.: 61.72%] [G loss: 0.931300]\n",
      "epoch:5 step:5194 [D loss: 0.693129, acc.: 54.69%] [G loss: 0.885837]\n",
      "epoch:5 step:5195 [D loss: 0.653273, acc.: 64.84%] [G loss: 0.891686]\n",
      "epoch:5 step:5196 [D loss: 0.677322, acc.: 60.94%] [G loss: 0.934493]\n",
      "epoch:5 step:5197 [D loss: 0.727384, acc.: 51.56%] [G loss: 0.790104]\n",
      "epoch:5 step:5198 [D loss: 0.672139, acc.: 59.38%] [G loss: 0.923972]\n",
      "epoch:5 step:5199 [D loss: 0.658227, acc.: 60.16%] [G loss: 0.898564]\n",
      "epoch:5 step:5200 [D loss: 0.691617, acc.: 57.03%] [G loss: 0.792965]\n",
      "##############\n",
      "[2.0876603  0.967369   4.94902368 4.12722915 2.76123306 5.05885389\n",
      " 3.86933393 4.42986354 3.6234584  3.2693437 ]\n",
      "##########\n",
      "epoch:5 step:5201 [D loss: 0.622082, acc.: 66.41%] [G loss: 0.814993]\n",
      "epoch:5 step:5202 [D loss: 0.640297, acc.: 55.47%] [G loss: 0.982486]\n",
      "epoch:5 step:5203 [D loss: 0.759699, acc.: 45.31%] [G loss: 0.828854]\n",
      "epoch:5 step:5204 [D loss: 0.676409, acc.: 55.47%] [G loss: 0.963898]\n",
      "epoch:5 step:5205 [D loss: 0.627751, acc.: 65.62%] [G loss: 1.026070]\n",
      "epoch:5 step:5206 [D loss: 0.690112, acc.: 57.03%] [G loss: 0.908640]\n",
      "epoch:5 step:5207 [D loss: 0.661411, acc.: 58.59%] [G loss: 0.989031]\n",
      "epoch:5 step:5208 [D loss: 0.640394, acc.: 59.38%] [G loss: 0.975092]\n",
      "epoch:5 step:5209 [D loss: 0.678114, acc.: 57.03%] [G loss: 0.896541]\n",
      "epoch:5 step:5210 [D loss: 0.692764, acc.: 57.81%] [G loss: 0.999635]\n",
      "epoch:5 step:5211 [D loss: 0.697984, acc.: 54.69%] [G loss: 0.909614]\n",
      "epoch:5 step:5212 [D loss: 0.729131, acc.: 48.44%] [G loss: 0.880001]\n",
      "epoch:5 step:5213 [D loss: 0.657850, acc.: 61.72%] [G loss: 0.954904]\n",
      "epoch:5 step:5214 [D loss: 0.717654, acc.: 42.97%] [G loss: 0.809520]\n",
      "epoch:5 step:5215 [D loss: 0.706529, acc.: 56.25%] [G loss: 0.946656]\n",
      "epoch:5 step:5216 [D loss: 0.661070, acc.: 58.59%] [G loss: 0.905281]\n",
      "epoch:5 step:5217 [D loss: 0.613482, acc.: 66.41%] [G loss: 0.909002]\n",
      "epoch:5 step:5218 [D loss: 0.630314, acc.: 62.50%] [G loss: 0.964837]\n",
      "epoch:5 step:5219 [D loss: 0.697236, acc.: 51.56%] [G loss: 0.925460]\n",
      "epoch:5 step:5220 [D loss: 0.653655, acc.: 60.94%] [G loss: 0.898701]\n",
      "epoch:5 step:5221 [D loss: 0.603417, acc.: 66.41%] [G loss: 0.978673]\n",
      "epoch:5 step:5222 [D loss: 0.671376, acc.: 58.59%] [G loss: 0.980560]\n",
      "epoch:5 step:5223 [D loss: 0.634264, acc.: 64.06%] [G loss: 1.047133]\n",
      "epoch:5 step:5224 [D loss: 0.691206, acc.: 57.03%] [G loss: 0.910234]\n",
      "epoch:5 step:5225 [D loss: 0.711523, acc.: 56.25%] [G loss: 0.893278]\n",
      "epoch:5 step:5226 [D loss: 0.715985, acc.: 51.56%] [G loss: 0.909034]\n",
      "epoch:5 step:5227 [D loss: 0.777528, acc.: 42.97%] [G loss: 0.864454]\n",
      "epoch:5 step:5228 [D loss: 0.717657, acc.: 48.44%] [G loss: 0.942374]\n",
      "epoch:5 step:5229 [D loss: 0.663866, acc.: 60.94%] [G loss: 0.956665]\n",
      "epoch:5 step:5230 [D loss: 0.692878, acc.: 56.25%] [G loss: 0.922451]\n",
      "epoch:5 step:5231 [D loss: 0.648797, acc.: 64.84%] [G loss: 0.694882]\n",
      "epoch:5 step:5232 [D loss: 0.591700, acc.: 75.00%] [G loss: 0.931797]\n",
      "epoch:5 step:5233 [D loss: 0.661797, acc.: 58.59%] [G loss: 0.979485]\n",
      "epoch:5 step:5234 [D loss: 0.623926, acc.: 65.62%] [G loss: 0.936785]\n",
      "epoch:5 step:5235 [D loss: 0.610843, acc.: 69.53%] [G loss: 1.025467]\n",
      "epoch:5 step:5236 [D loss: 0.585896, acc.: 70.31%] [G loss: 1.096892]\n",
      "epoch:5 step:5237 [D loss: 0.627392, acc.: 61.72%] [G loss: 0.937400]\n",
      "epoch:5 step:5238 [D loss: 0.615484, acc.: 63.28%] [G loss: 0.889107]\n",
      "epoch:5 step:5239 [D loss: 0.574937, acc.: 69.53%] [G loss: 1.119930]\n",
      "epoch:5 step:5240 [D loss: 0.554492, acc.: 75.78%] [G loss: 1.053572]\n",
      "epoch:5 step:5241 [D loss: 0.627057, acc.: 62.50%] [G loss: 0.986833]\n",
      "epoch:5 step:5242 [D loss: 0.549290, acc.: 73.44%] [G loss: 1.011065]\n",
      "epoch:5 step:5243 [D loss: 0.682144, acc.: 56.25%] [G loss: 0.960465]\n",
      "epoch:5 step:5244 [D loss: 0.781714, acc.: 46.88%] [G loss: 0.925518]\n",
      "epoch:5 step:5245 [D loss: 0.695190, acc.: 55.47%] [G loss: 0.875402]\n",
      "epoch:5 step:5246 [D loss: 0.723056, acc.: 53.12%] [G loss: 0.955373]\n",
      "epoch:5 step:5247 [D loss: 0.667723, acc.: 57.81%] [G loss: 0.950781]\n",
      "epoch:5 step:5248 [D loss: 0.613000, acc.: 67.19%] [G loss: 0.958298]\n",
      "epoch:5 step:5249 [D loss: 0.648450, acc.: 63.28%] [G loss: 0.910177]\n",
      "epoch:5 step:5250 [D loss: 0.695172, acc.: 59.38%] [G loss: 0.944001]\n",
      "epoch:5 step:5251 [D loss: 0.689293, acc.: 53.12%] [G loss: 0.998704]\n",
      "epoch:5 step:5252 [D loss: 0.739887, acc.: 47.66%] [G loss: 0.886511]\n",
      "epoch:5 step:5253 [D loss: 0.678634, acc.: 60.94%] [G loss: 1.023344]\n",
      "epoch:5 step:5254 [D loss: 0.715383, acc.: 53.91%] [G loss: 1.076766]\n",
      "epoch:5 step:5255 [D loss: 0.607365, acc.: 67.97%] [G loss: 1.033726]\n",
      "epoch:5 step:5256 [D loss: 0.701942, acc.: 53.12%] [G loss: 0.823046]\n",
      "epoch:5 step:5257 [D loss: 0.671888, acc.: 58.59%] [G loss: 0.884254]\n",
      "epoch:5 step:5258 [D loss: 0.699502, acc.: 51.56%] [G loss: 0.846536]\n",
      "epoch:5 step:5259 [D loss: 0.657387, acc.: 60.94%] [G loss: 0.976427]\n",
      "epoch:5 step:5260 [D loss: 0.690247, acc.: 57.81%] [G loss: 0.960115]\n",
      "epoch:5 step:5261 [D loss: 0.632706, acc.: 62.50%] [G loss: 1.071757]\n",
      "epoch:5 step:5262 [D loss: 0.719000, acc.: 50.00%] [G loss: 0.927984]\n",
      "epoch:5 step:5263 [D loss: 0.725202, acc.: 49.22%] [G loss: 0.875577]\n",
      "epoch:5 step:5264 [D loss: 0.682729, acc.: 57.81%] [G loss: 0.876706]\n",
      "epoch:5 step:5265 [D loss: 0.704672, acc.: 52.34%] [G loss: 0.829526]\n",
      "epoch:5 step:5266 [D loss: 0.640027, acc.: 64.06%] [G loss: 0.838289]\n",
      "epoch:5 step:5267 [D loss: 0.678763, acc.: 57.81%] [G loss: 0.907988]\n",
      "epoch:5 step:5268 [D loss: 0.673732, acc.: 57.81%] [G loss: 0.846900]\n",
      "epoch:5 step:5269 [D loss: 0.660792, acc.: 56.25%] [G loss: 0.923508]\n",
      "epoch:5 step:5270 [D loss: 0.657608, acc.: 60.94%] [G loss: 0.846768]\n",
      "epoch:5 step:5271 [D loss: 0.684320, acc.: 59.38%] [G loss: 0.940764]\n",
      "epoch:5 step:5272 [D loss: 0.644176, acc.: 64.84%] [G loss: 0.909114]\n",
      "epoch:5 step:5273 [D loss: 0.658398, acc.: 59.38%] [G loss: 1.032842]\n",
      "epoch:5 step:5274 [D loss: 0.632697, acc.: 64.84%] [G loss: 0.860021]\n",
      "epoch:5 step:5275 [D loss: 0.720985, acc.: 57.03%] [G loss: 0.893995]\n",
      "epoch:5 step:5276 [D loss: 0.644750, acc.: 66.41%] [G loss: 0.844663]\n",
      "epoch:5 step:5277 [D loss: 0.682610, acc.: 59.38%] [G loss: 0.883157]\n",
      "epoch:5 step:5278 [D loss: 0.658183, acc.: 65.62%] [G loss: 0.893957]\n",
      "epoch:5 step:5279 [D loss: 0.702340, acc.: 57.81%] [G loss: 0.869535]\n",
      "epoch:5 step:5280 [D loss: 0.674716, acc.: 60.16%] [G loss: 0.963739]\n",
      "epoch:5 step:5281 [D loss: 0.666021, acc.: 57.03%] [G loss: 0.981989]\n",
      "epoch:5 step:5282 [D loss: 0.704642, acc.: 52.34%] [G loss: 1.016917]\n",
      "epoch:5 step:5283 [D loss: 0.665499, acc.: 58.59%] [G loss: 0.923897]\n",
      "epoch:5 step:5284 [D loss: 0.634790, acc.: 61.72%] [G loss: 0.962893]\n",
      "epoch:5 step:5285 [D loss: 0.745403, acc.: 48.44%] [G loss: 0.832146]\n",
      "epoch:5 step:5286 [D loss: 0.647241, acc.: 60.94%] [G loss: 0.959101]\n",
      "epoch:5 step:5287 [D loss: 0.690078, acc.: 59.38%] [G loss: 0.890261]\n",
      "epoch:5 step:5288 [D loss: 0.636276, acc.: 66.41%] [G loss: 0.910749]\n",
      "epoch:5 step:5289 [D loss: 0.679802, acc.: 56.25%] [G loss: 1.016175]\n",
      "epoch:5 step:5290 [D loss: 0.666248, acc.: 57.03%] [G loss: 0.933796]\n",
      "epoch:5 step:5291 [D loss: 0.628921, acc.: 63.28%] [G loss: 0.913911]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5292 [D loss: 0.716677, acc.: 56.25%] [G loss: 0.927885]\n",
      "epoch:5 step:5293 [D loss: 0.615111, acc.: 71.88%] [G loss: 0.990845]\n",
      "epoch:5 step:5294 [D loss: 0.639174, acc.: 60.94%] [G loss: 0.916058]\n",
      "epoch:5 step:5295 [D loss: 0.621779, acc.: 64.84%] [G loss: 0.901049]\n",
      "epoch:5 step:5296 [D loss: 0.692572, acc.: 53.91%] [G loss: 0.855857]\n",
      "epoch:5 step:5297 [D loss: 0.655013, acc.: 60.94%] [G loss: 0.911108]\n",
      "epoch:5 step:5298 [D loss: 0.610507, acc.: 66.41%] [G loss: 0.919687]\n",
      "epoch:5 step:5299 [D loss: 0.706215, acc.: 54.69%] [G loss: 0.939653]\n",
      "epoch:5 step:5300 [D loss: 0.699049, acc.: 54.69%] [G loss: 0.908205]\n",
      "epoch:5 step:5301 [D loss: 0.684722, acc.: 59.38%] [G loss: 0.838113]\n",
      "epoch:5 step:5302 [D loss: 0.704474, acc.: 58.59%] [G loss: 0.920131]\n",
      "epoch:5 step:5303 [D loss: 0.618976, acc.: 64.06%] [G loss: 0.938004]\n",
      "epoch:5 step:5304 [D loss: 0.638004, acc.: 66.41%] [G loss: 0.949343]\n",
      "epoch:5 step:5305 [D loss: 0.743331, acc.: 50.78%] [G loss: 0.836321]\n",
      "epoch:5 step:5306 [D loss: 0.625974, acc.: 67.97%] [G loss: 0.898460]\n",
      "epoch:5 step:5307 [D loss: 0.645314, acc.: 61.72%] [G loss: 0.945076]\n",
      "epoch:5 step:5308 [D loss: 0.705820, acc.: 56.25%] [G loss: 0.964422]\n",
      "epoch:5 step:5309 [D loss: 0.622426, acc.: 70.31%] [G loss: 1.032381]\n",
      "epoch:5 step:5310 [D loss: 0.684410, acc.: 53.91%] [G loss: 0.979944]\n",
      "epoch:5 step:5311 [D loss: 0.681191, acc.: 60.94%] [G loss: 0.954443]\n",
      "epoch:5 step:5312 [D loss: 0.695685, acc.: 59.38%] [G loss: 0.845968]\n",
      "epoch:5 step:5313 [D loss: 0.626739, acc.: 65.62%] [G loss: 1.091436]\n",
      "epoch:5 step:5314 [D loss: 0.613369, acc.: 69.53%] [G loss: 1.003919]\n",
      "epoch:5 step:5315 [D loss: 0.623275, acc.: 61.72%] [G loss: 1.017084]\n",
      "epoch:5 step:5316 [D loss: 0.668239, acc.: 60.94%] [G loss: 0.934788]\n",
      "epoch:5 step:5317 [D loss: 0.622562, acc.: 63.28%] [G loss: 0.953235]\n",
      "epoch:5 step:5318 [D loss: 0.630406, acc.: 65.62%] [G loss: 1.225923]\n",
      "epoch:5 step:5319 [D loss: 0.642269, acc.: 61.72%] [G loss: 1.024863]\n",
      "epoch:5 step:5320 [D loss: 0.649904, acc.: 61.72%] [G loss: 0.931034]\n",
      "epoch:5 step:5321 [D loss: 0.673580, acc.: 58.59%] [G loss: 0.883625]\n",
      "epoch:5 step:5322 [D loss: 0.699399, acc.: 55.47%] [G loss: 0.937118]\n",
      "epoch:5 step:5323 [D loss: 0.655618, acc.: 60.94%] [G loss: 1.014322]\n",
      "epoch:5 step:5324 [D loss: 0.690182, acc.: 55.47%] [G loss: 0.927220]\n",
      "epoch:5 step:5325 [D loss: 0.694550, acc.: 58.59%] [G loss: 0.891789]\n",
      "epoch:5 step:5326 [D loss: 0.704944, acc.: 55.47%] [G loss: 0.993120]\n",
      "epoch:5 step:5327 [D loss: 0.664246, acc.: 58.59%] [G loss: 1.047407]\n",
      "epoch:5 step:5328 [D loss: 0.630177, acc.: 60.94%] [G loss: 1.007189]\n",
      "epoch:5 step:5329 [D loss: 0.684979, acc.: 60.16%] [G loss: 0.914245]\n",
      "epoch:5 step:5330 [D loss: 0.670620, acc.: 58.59%] [G loss: 0.910435]\n",
      "epoch:5 step:5331 [D loss: 0.597779, acc.: 67.97%] [G loss: 0.953491]\n",
      "epoch:5 step:5332 [D loss: 0.609313, acc.: 64.06%] [G loss: 1.015230]\n",
      "epoch:5 step:5333 [D loss: 0.585003, acc.: 66.41%] [G loss: 0.928404]\n",
      "epoch:5 step:5334 [D loss: 0.649123, acc.: 62.50%] [G loss: 1.026651]\n",
      "epoch:5 step:5335 [D loss: 0.683412, acc.: 57.03%] [G loss: 1.038877]\n",
      "epoch:5 step:5336 [D loss: 0.744645, acc.: 51.56%] [G loss: 0.840872]\n",
      "epoch:5 step:5337 [D loss: 0.752830, acc.: 52.34%] [G loss: 0.970742]\n",
      "epoch:5 step:5338 [D loss: 0.674518, acc.: 53.91%] [G loss: 0.955760]\n",
      "epoch:5 step:5339 [D loss: 0.634560, acc.: 65.62%] [G loss: 0.973973]\n",
      "epoch:5 step:5340 [D loss: 0.710294, acc.: 53.12%] [G loss: 0.848085]\n",
      "epoch:5 step:5341 [D loss: 0.621485, acc.: 66.41%] [G loss: 0.999239]\n",
      "epoch:5 step:5342 [D loss: 0.693925, acc.: 51.56%] [G loss: 0.896632]\n",
      "epoch:5 step:5343 [D loss: 0.639227, acc.: 60.16%] [G loss: 0.900416]\n",
      "epoch:5 step:5344 [D loss: 0.631744, acc.: 65.62%] [G loss: 1.011064]\n",
      "epoch:5 step:5345 [D loss: 0.571602, acc.: 70.31%] [G loss: 1.030683]\n",
      "epoch:5 step:5346 [D loss: 0.559476, acc.: 73.44%] [G loss: 0.975051]\n",
      "epoch:5 step:5347 [D loss: 0.717269, acc.: 53.91%] [G loss: 0.881132]\n",
      "epoch:5 step:5348 [D loss: 0.692967, acc.: 58.59%] [G loss: 1.036036]\n",
      "epoch:5 step:5349 [D loss: 0.749325, acc.: 47.66%] [G loss: 0.884769]\n",
      "epoch:5 step:5350 [D loss: 0.690579, acc.: 53.12%] [G loss: 0.808031]\n",
      "epoch:5 step:5351 [D loss: 0.674829, acc.: 55.47%] [G loss: 0.989071]\n",
      "epoch:5 step:5352 [D loss: 0.675521, acc.: 61.72%] [G loss: 0.892838]\n",
      "epoch:5 step:5353 [D loss: 0.660748, acc.: 59.38%] [G loss: 0.859194]\n",
      "epoch:5 step:5354 [D loss: 0.647942, acc.: 66.41%] [G loss: 0.935433]\n",
      "epoch:5 step:5355 [D loss: 0.703000, acc.: 62.50%] [G loss: 0.891175]\n",
      "epoch:5 step:5356 [D loss: 0.655967, acc.: 57.03%] [G loss: 0.921019]\n",
      "epoch:5 step:5357 [D loss: 0.700562, acc.: 56.25%] [G loss: 1.002523]\n",
      "epoch:5 step:5358 [D loss: 0.729716, acc.: 51.56%] [G loss: 0.837890]\n",
      "epoch:5 step:5359 [D loss: 0.699470, acc.: 54.69%] [G loss: 0.853825]\n",
      "epoch:5 step:5360 [D loss: 0.711307, acc.: 53.91%] [G loss: 0.902877]\n",
      "epoch:5 step:5361 [D loss: 0.667810, acc.: 63.28%] [G loss: 0.883386]\n",
      "epoch:5 step:5362 [D loss: 0.585366, acc.: 74.22%] [G loss: 0.896915]\n",
      "epoch:5 step:5363 [D loss: 0.590288, acc.: 71.88%] [G loss: 0.941980]\n",
      "epoch:5 step:5364 [D loss: 0.682787, acc.: 59.38%] [G loss: 0.839088]\n",
      "epoch:5 step:5365 [D loss: 0.617817, acc.: 65.62%] [G loss: 0.960854]\n",
      "epoch:5 step:5366 [D loss: 0.629773, acc.: 60.94%] [G loss: 0.921243]\n",
      "epoch:5 step:5367 [D loss: 0.612157, acc.: 69.53%] [G loss: 1.048240]\n",
      "epoch:5 step:5368 [D loss: 0.644162, acc.: 65.62%] [G loss: 0.988158]\n",
      "epoch:5 step:5369 [D loss: 0.605426, acc.: 68.75%] [G loss: 0.928819]\n",
      "epoch:5 step:5370 [D loss: 0.633575, acc.: 59.38%] [G loss: 0.983135]\n",
      "epoch:5 step:5371 [D loss: 0.625623, acc.: 65.62%] [G loss: 0.936621]\n",
      "epoch:5 step:5372 [D loss: 0.611441, acc.: 67.97%] [G loss: 1.007272]\n",
      "epoch:5 step:5373 [D loss: 0.633825, acc.: 60.94%] [G loss: 0.960832]\n",
      "epoch:5 step:5374 [D loss: 0.704064, acc.: 54.69%] [G loss: 0.950761]\n",
      "epoch:5 step:5375 [D loss: 0.643745, acc.: 64.06%] [G loss: 0.896029]\n",
      "epoch:5 step:5376 [D loss: 0.600330, acc.: 67.97%] [G loss: 0.928718]\n",
      "epoch:5 step:5377 [D loss: 0.640642, acc.: 67.97%] [G loss: 0.999541]\n",
      "epoch:5 step:5378 [D loss: 0.677716, acc.: 58.59%] [G loss: 0.890201]\n",
      "epoch:5 step:5379 [D loss: 0.621686, acc.: 64.06%] [G loss: 0.992477]\n",
      "epoch:5 step:5380 [D loss: 0.680547, acc.: 56.25%] [G loss: 0.949780]\n",
      "epoch:5 step:5381 [D loss: 0.661415, acc.: 55.47%] [G loss: 1.006203]\n",
      "epoch:5 step:5382 [D loss: 0.708422, acc.: 56.25%] [G loss: 0.938013]\n",
      "epoch:5 step:5383 [D loss: 0.673405, acc.: 61.72%] [G loss: 0.890400]\n",
      "epoch:5 step:5384 [D loss: 0.671475, acc.: 55.47%] [G loss: 1.052408]\n",
      "epoch:5 step:5385 [D loss: 0.665315, acc.: 60.94%] [G loss: 0.989874]\n",
      "epoch:5 step:5386 [D loss: 0.640584, acc.: 61.72%] [G loss: 0.932035]\n",
      "epoch:5 step:5387 [D loss: 0.700025, acc.: 54.69%] [G loss: 0.922047]\n",
      "epoch:5 step:5388 [D loss: 0.761277, acc.: 51.56%] [G loss: 0.946461]\n",
      "epoch:5 step:5389 [D loss: 0.759035, acc.: 50.78%] [G loss: 0.877857]\n",
      "epoch:5 step:5390 [D loss: 0.618834, acc.: 61.72%] [G loss: 0.994384]\n",
      "epoch:5 step:5391 [D loss: 0.624760, acc.: 66.41%] [G loss: 0.919766]\n",
      "epoch:5 step:5392 [D loss: 0.662989, acc.: 62.50%] [G loss: 0.987241]\n",
      "epoch:5 step:5393 [D loss: 0.640786, acc.: 60.16%] [G loss: 0.904955]\n",
      "epoch:5 step:5394 [D loss: 0.577416, acc.: 73.44%] [G loss: 0.998818]\n",
      "epoch:5 step:5395 [D loss: 0.732484, acc.: 50.78%] [G loss: 1.045669]\n",
      "epoch:5 step:5396 [D loss: 0.737009, acc.: 49.22%] [G loss: 1.027989]\n",
      "epoch:5 step:5397 [D loss: 0.622040, acc.: 63.28%] [G loss: 0.959670]\n",
      "epoch:5 step:5398 [D loss: 0.692147, acc.: 52.34%] [G loss: 0.984414]\n",
      "epoch:5 step:5399 [D loss: 0.640711, acc.: 66.41%] [G loss: 1.024591]\n",
      "epoch:5 step:5400 [D loss: 0.656919, acc.: 67.19%] [G loss: 0.960493]\n",
      "##############\n",
      "[1.78417412 1.13236936 4.90738638 4.07437285 2.69384891 5.02296085\n",
      " 3.67286319 4.43913541 3.39197979 3.22594359]\n",
      "##########\n",
      "epoch:5 step:5401 [D loss: 0.742348, acc.: 50.00%] [G loss: 0.866128]\n",
      "epoch:5 step:5402 [D loss: 0.683246, acc.: 57.03%] [G loss: 0.895009]\n",
      "epoch:5 step:5403 [D loss: 0.707366, acc.: 57.03%] [G loss: 0.900992]\n",
      "epoch:5 step:5404 [D loss: 0.685330, acc.: 61.72%] [G loss: 0.890800]\n",
      "epoch:5 step:5405 [D loss: 0.715859, acc.: 55.47%] [G loss: 0.942817]\n",
      "epoch:5 step:5406 [D loss: 0.722095, acc.: 45.31%] [G loss: 0.890213]\n",
      "epoch:5 step:5407 [D loss: 0.713537, acc.: 49.22%] [G loss: 0.775734]\n",
      "epoch:5 step:5408 [D loss: 0.669612, acc.: 62.50%] [G loss: 0.943501]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5409 [D loss: 0.712201, acc.: 50.78%] [G loss: 0.959475]\n",
      "epoch:5 step:5410 [D loss: 0.643053, acc.: 64.84%] [G loss: 0.972598]\n",
      "epoch:5 step:5411 [D loss: 0.692206, acc.: 58.59%] [G loss: 0.958237]\n",
      "epoch:5 step:5412 [D loss: 0.682005, acc.: 60.16%] [G loss: 0.861996]\n",
      "epoch:5 step:5413 [D loss: 0.708288, acc.: 53.12%] [G loss: 0.900448]\n",
      "epoch:5 step:5414 [D loss: 0.689452, acc.: 57.03%] [G loss: 0.898628]\n",
      "epoch:5 step:5415 [D loss: 0.655049, acc.: 64.84%] [G loss: 0.936310]\n",
      "epoch:5 step:5416 [D loss: 0.676228, acc.: 56.25%] [G loss: 0.918785]\n",
      "epoch:5 step:5417 [D loss: 0.628740, acc.: 67.97%] [G loss: 0.995902]\n",
      "epoch:5 step:5418 [D loss: 0.616253, acc.: 68.75%] [G loss: 0.955533]\n",
      "epoch:5 step:5419 [D loss: 0.741847, acc.: 43.75%] [G loss: 0.784205]\n",
      "epoch:5 step:5420 [D loss: 0.640706, acc.: 61.72%] [G loss: 0.985110]\n",
      "epoch:5 step:5421 [D loss: 0.706028, acc.: 55.47%] [G loss: 0.898700]\n",
      "epoch:5 step:5422 [D loss: 0.657881, acc.: 59.38%] [G loss: 0.895806]\n",
      "epoch:5 step:5423 [D loss: 0.710042, acc.: 56.25%] [G loss: 0.916348]\n",
      "epoch:5 step:5424 [D loss: 0.673441, acc.: 55.47%] [G loss: 0.935767]\n",
      "epoch:5 step:5425 [D loss: 0.692472, acc.: 53.91%] [G loss: 0.923622]\n",
      "epoch:5 step:5426 [D loss: 0.758957, acc.: 45.31%] [G loss: 0.955229]\n",
      "epoch:5 step:5427 [D loss: 0.724238, acc.: 52.34%] [G loss: 0.923297]\n",
      "epoch:5 step:5428 [D loss: 0.648702, acc.: 63.28%] [G loss: 0.917707]\n",
      "epoch:5 step:5429 [D loss: 0.687901, acc.: 59.38%] [G loss: 0.890655]\n",
      "epoch:5 step:5430 [D loss: 0.582634, acc.: 71.88%] [G loss: 0.793756]\n",
      "epoch:5 step:5431 [D loss: 0.630330, acc.: 69.53%] [G loss: 0.907072]\n",
      "epoch:5 step:5432 [D loss: 0.604123, acc.: 70.31%] [G loss: 0.980896]\n",
      "epoch:5 step:5433 [D loss: 0.644399, acc.: 60.16%] [G loss: 0.885640]\n",
      "epoch:5 step:5434 [D loss: 0.701878, acc.: 49.22%] [G loss: 0.818779]\n",
      "epoch:5 step:5435 [D loss: 0.637513, acc.: 60.16%] [G loss: 0.845031]\n",
      "epoch:5 step:5436 [D loss: 0.700276, acc.: 57.03%] [G loss: 0.956966]\n",
      "epoch:5 step:5437 [D loss: 0.693398, acc.: 56.25%] [G loss: 0.914651]\n",
      "epoch:5 step:5438 [D loss: 0.707512, acc.: 53.12%] [G loss: 0.888123]\n",
      "epoch:5 step:5439 [D loss: 0.666224, acc.: 59.38%] [G loss: 0.980147]\n",
      "epoch:5 step:5440 [D loss: 0.659364, acc.: 57.81%] [G loss: 0.973242]\n",
      "epoch:5 step:5441 [D loss: 0.739066, acc.: 49.22%] [G loss: 0.901206]\n",
      "epoch:5 step:5442 [D loss: 0.662079, acc.: 57.81%] [G loss: 1.050212]\n",
      "epoch:5 step:5443 [D loss: 0.684710, acc.: 59.38%] [G loss: 0.920906]\n",
      "epoch:5 step:5444 [D loss: 0.701073, acc.: 54.69%] [G loss: 0.971032]\n",
      "epoch:5 step:5445 [D loss: 0.697537, acc.: 57.03%] [G loss: 0.921260]\n",
      "epoch:5 step:5446 [D loss: 0.614543, acc.: 70.31%] [G loss: 0.932729]\n",
      "epoch:5 step:5447 [D loss: 0.694713, acc.: 53.12%] [G loss: 0.860505]\n",
      "epoch:5 step:5448 [D loss: 0.621651, acc.: 63.28%] [G loss: 0.914998]\n",
      "epoch:5 step:5449 [D loss: 0.681199, acc.: 55.47%] [G loss: 0.964099]\n",
      "epoch:5 step:5450 [D loss: 0.715415, acc.: 50.00%] [G loss: 0.925072]\n",
      "epoch:5 step:5451 [D loss: 0.747193, acc.: 49.22%] [G loss: 0.922592]\n",
      "epoch:5 step:5452 [D loss: 0.692718, acc.: 60.16%] [G loss: 0.942615]\n",
      "epoch:5 step:5453 [D loss: 0.676965, acc.: 58.59%] [G loss: 0.918389]\n",
      "epoch:5 step:5454 [D loss: 0.648729, acc.: 60.94%] [G loss: 1.016887]\n",
      "epoch:5 step:5455 [D loss: 0.663542, acc.: 63.28%] [G loss: 0.980061]\n",
      "epoch:5 step:5456 [D loss: 0.700451, acc.: 57.81%] [G loss: 0.955612]\n",
      "epoch:5 step:5457 [D loss: 0.675519, acc.: 57.81%] [G loss: 0.941055]\n",
      "epoch:5 step:5458 [D loss: 0.648553, acc.: 61.72%] [G loss: 0.991771]\n",
      "epoch:5 step:5459 [D loss: 0.691098, acc.: 54.69%] [G loss: 0.905575]\n",
      "epoch:5 step:5460 [D loss: 0.642394, acc.: 60.94%] [G loss: 0.982252]\n",
      "epoch:5 step:5461 [D loss: 0.656741, acc.: 56.25%] [G loss: 0.891136]\n",
      "epoch:5 step:5462 [D loss: 0.650729, acc.: 61.72%] [G loss: 0.989216]\n",
      "epoch:5 step:5463 [D loss: 0.621502, acc.: 61.72%] [G loss: 0.967013]\n",
      "epoch:5 step:5464 [D loss: 0.736906, acc.: 51.56%] [G loss: 0.902813]\n",
      "epoch:5 step:5465 [D loss: 0.651357, acc.: 57.81%] [G loss: 0.865301]\n",
      "epoch:5 step:5466 [D loss: 0.644737, acc.: 64.84%] [G loss: 0.985094]\n",
      "epoch:5 step:5467 [D loss: 0.612736, acc.: 67.97%] [G loss: 0.993727]\n",
      "epoch:5 step:5468 [D loss: 0.744981, acc.: 46.88%] [G loss: 0.840244]\n",
      "epoch:5 step:5469 [D loss: 0.671120, acc.: 59.38%] [G loss: 1.027985]\n",
      "epoch:5 step:5470 [D loss: 0.672969, acc.: 59.38%] [G loss: 0.979990]\n",
      "epoch:5 step:5471 [D loss: 0.558251, acc.: 70.31%] [G loss: 0.997750]\n",
      "epoch:5 step:5472 [D loss: 0.691587, acc.: 56.25%] [G loss: 1.064310]\n",
      "epoch:5 step:5473 [D loss: 0.776084, acc.: 44.53%] [G loss: 0.967499]\n",
      "epoch:5 step:5474 [D loss: 0.644413, acc.: 57.81%] [G loss: 0.895860]\n",
      "epoch:5 step:5475 [D loss: 0.659590, acc.: 57.81%] [G loss: 0.925965]\n",
      "epoch:5 step:5476 [D loss: 0.594818, acc.: 75.00%] [G loss: 0.887726]\n",
      "epoch:5 step:5477 [D loss: 0.686191, acc.: 60.16%] [G loss: 0.872887]\n",
      "epoch:5 step:5478 [D loss: 0.625580, acc.: 67.97%] [G loss: 1.058345]\n",
      "epoch:5 step:5479 [D loss: 0.737909, acc.: 56.25%] [G loss: 0.908899]\n",
      "epoch:5 step:5480 [D loss: 0.723597, acc.: 53.91%] [G loss: 0.830072]\n",
      "epoch:5 step:5481 [D loss: 0.628326, acc.: 67.97%] [G loss: 0.922025]\n",
      "epoch:5 step:5482 [D loss: 0.648604, acc.: 67.97%] [G loss: 0.971525]\n",
      "epoch:5 step:5483 [D loss: 0.684745, acc.: 57.81%] [G loss: 0.894708]\n",
      "epoch:5 step:5484 [D loss: 0.661394, acc.: 60.16%] [G loss: 1.035709]\n",
      "epoch:5 step:5485 [D loss: 0.722195, acc.: 49.22%] [G loss: 0.866272]\n",
      "epoch:5 step:5486 [D loss: 0.642150, acc.: 62.50%] [G loss: 0.988585]\n",
      "epoch:5 step:5487 [D loss: 0.588827, acc.: 72.66%] [G loss: 0.978709]\n",
      "epoch:5 step:5488 [D loss: 0.582570, acc.: 75.00%] [G loss: 0.983226]\n",
      "epoch:5 step:5489 [D loss: 0.699543, acc.: 48.44%] [G loss: 0.890493]\n",
      "epoch:5 step:5490 [D loss: 0.625366, acc.: 60.94%] [G loss: 0.769139]\n",
      "epoch:5 step:5491 [D loss: 0.645652, acc.: 66.41%] [G loss: 0.923830]\n",
      "epoch:5 step:5492 [D loss: 0.632373, acc.: 65.62%] [G loss: 0.946920]\n",
      "epoch:5 step:5493 [D loss: 0.647870, acc.: 60.16%] [G loss: 1.106401]\n",
      "epoch:5 step:5494 [D loss: 0.692008, acc.: 57.03%] [G loss: 1.026574]\n",
      "epoch:5 step:5495 [D loss: 0.648519, acc.: 65.62%] [G loss: 0.870396]\n",
      "epoch:5 step:5496 [D loss: 0.631828, acc.: 65.62%] [G loss: 1.080150]\n",
      "epoch:5 step:5497 [D loss: 0.690405, acc.: 51.56%] [G loss: 0.853559]\n",
      "epoch:5 step:5498 [D loss: 0.628296, acc.: 62.50%] [G loss: 0.872554]\n",
      "epoch:5 step:5499 [D loss: 0.777601, acc.: 51.56%] [G loss: 0.875984]\n",
      "epoch:5 step:5500 [D loss: 0.709812, acc.: 53.91%] [G loss: 0.921154]\n",
      "epoch:5 step:5501 [D loss: 0.628844, acc.: 67.19%] [G loss: 1.012236]\n",
      "epoch:5 step:5502 [D loss: 0.620638, acc.: 67.97%] [G loss: 0.971740]\n",
      "epoch:5 step:5503 [D loss: 0.650573, acc.: 61.72%] [G loss: 0.939077]\n",
      "epoch:5 step:5504 [D loss: 0.653893, acc.: 58.59%] [G loss: 1.014163]\n",
      "epoch:5 step:5505 [D loss: 0.755546, acc.: 50.00%] [G loss: 1.016735]\n",
      "epoch:5 step:5506 [D loss: 0.586931, acc.: 71.88%] [G loss: 1.085934]\n",
      "epoch:5 step:5507 [D loss: 0.582540, acc.: 70.31%] [G loss: 0.916959]\n",
      "epoch:5 step:5508 [D loss: 0.663683, acc.: 59.38%] [G loss: 0.783916]\n",
      "epoch:5 step:5509 [D loss: 0.598275, acc.: 65.62%] [G loss: 1.007754]\n",
      "epoch:5 step:5510 [D loss: 0.640419, acc.: 66.41%] [G loss: 0.900877]\n",
      "epoch:5 step:5511 [D loss: 0.678340, acc.: 57.81%] [G loss: 0.877265]\n",
      "epoch:5 step:5512 [D loss: 0.698019, acc.: 53.12%] [G loss: 0.978496]\n",
      "epoch:5 step:5513 [D loss: 0.660818, acc.: 57.03%] [G loss: 0.865682]\n",
      "epoch:5 step:5514 [D loss: 0.721075, acc.: 54.69%] [G loss: 0.948522]\n",
      "epoch:5 step:5515 [D loss: 0.657452, acc.: 60.16%] [G loss: 0.919709]\n",
      "epoch:5 step:5516 [D loss: 0.647082, acc.: 64.06%] [G loss: 0.917472]\n",
      "epoch:5 step:5517 [D loss: 0.563177, acc.: 72.66%] [G loss: 0.892736]\n",
      "epoch:5 step:5518 [D loss: 0.644885, acc.: 57.81%] [G loss: 1.056509]\n",
      "epoch:5 step:5519 [D loss: 0.715004, acc.: 55.47%] [G loss: 0.913512]\n",
      "epoch:5 step:5520 [D loss: 0.659062, acc.: 60.16%] [G loss: 0.949607]\n",
      "epoch:5 step:5521 [D loss: 0.627174, acc.: 65.62%] [G loss: 0.979774]\n",
      "epoch:5 step:5522 [D loss: 0.650835, acc.: 62.50%] [G loss: 0.906997]\n",
      "epoch:5 step:5523 [D loss: 0.576896, acc.: 69.53%] [G loss: 0.977157]\n",
      "epoch:5 step:5524 [D loss: 0.649260, acc.: 59.38%] [G loss: 0.911023]\n",
      "epoch:5 step:5525 [D loss: 0.649019, acc.: 58.59%] [G loss: 0.984534]\n",
      "epoch:5 step:5526 [D loss: 0.645948, acc.: 56.25%] [G loss: 1.100930]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5527 [D loss: 0.588291, acc.: 71.09%] [G loss: 1.035690]\n",
      "epoch:5 step:5528 [D loss: 0.696475, acc.: 54.69%] [G loss: 1.028174]\n",
      "epoch:5 step:5529 [D loss: 0.655588, acc.: 58.59%] [G loss: 0.965155]\n",
      "epoch:5 step:5530 [D loss: 0.760090, acc.: 50.00%] [G loss: 1.014949]\n",
      "epoch:5 step:5531 [D loss: 0.641845, acc.: 58.59%] [G loss: 0.958816]\n",
      "epoch:5 step:5532 [D loss: 0.692878, acc.: 53.91%] [G loss: 0.967649]\n",
      "epoch:5 step:5533 [D loss: 0.618388, acc.: 67.97%] [G loss: 1.034807]\n",
      "epoch:5 step:5534 [D loss: 0.667094, acc.: 64.06%] [G loss: 0.900686]\n",
      "epoch:5 step:5535 [D loss: 0.685326, acc.: 56.25%] [G loss: 0.878662]\n",
      "epoch:5 step:5536 [D loss: 0.709876, acc.: 53.12%] [G loss: 0.918828]\n",
      "epoch:5 step:5537 [D loss: 0.650285, acc.: 57.81%] [G loss: 0.986344]\n",
      "epoch:5 step:5538 [D loss: 0.656476, acc.: 59.38%] [G loss: 0.994989]\n",
      "epoch:5 step:5539 [D loss: 0.677879, acc.: 60.16%] [G loss: 1.008855]\n",
      "epoch:5 step:5540 [D loss: 0.691098, acc.: 57.03%] [G loss: 0.871545]\n",
      "epoch:5 step:5541 [D loss: 0.640694, acc.: 65.62%] [G loss: 0.899821]\n",
      "epoch:5 step:5542 [D loss: 0.706667, acc.: 51.56%] [G loss: 0.863223]\n",
      "epoch:5 step:5543 [D loss: 0.704941, acc.: 59.38%] [G loss: 0.899343]\n",
      "epoch:5 step:5544 [D loss: 0.682159, acc.: 58.59%] [G loss: 0.862742]\n",
      "epoch:5 step:5545 [D loss: 0.649863, acc.: 61.72%] [G loss: 1.042883]\n",
      "epoch:5 step:5546 [D loss: 0.685879, acc.: 55.47%] [G loss: 0.926426]\n",
      "epoch:5 step:5547 [D loss: 0.626725, acc.: 64.06%] [G loss: 0.901248]\n",
      "epoch:5 step:5548 [D loss: 0.692413, acc.: 57.03%] [G loss: 0.840873]\n",
      "epoch:5 step:5549 [D loss: 0.701130, acc.: 50.00%] [G loss: 0.818099]\n",
      "epoch:5 step:5550 [D loss: 0.700839, acc.: 50.78%] [G loss: 0.932362]\n",
      "epoch:5 step:5551 [D loss: 0.675824, acc.: 61.72%] [G loss: 0.908265]\n",
      "epoch:5 step:5552 [D loss: 0.751429, acc.: 46.88%] [G loss: 0.806457]\n",
      "epoch:5 step:5553 [D loss: 0.717380, acc.: 51.56%] [G loss: 0.920095]\n",
      "epoch:5 step:5554 [D loss: 0.669393, acc.: 57.03%] [G loss: 0.909539]\n",
      "epoch:5 step:5555 [D loss: 0.706924, acc.: 60.16%] [G loss: 0.994390]\n",
      "epoch:5 step:5556 [D loss: 0.692354, acc.: 56.25%] [G loss: 0.916421]\n",
      "epoch:5 step:5557 [D loss: 0.616427, acc.: 67.19%] [G loss: 0.973166]\n",
      "epoch:5 step:5558 [D loss: 0.727030, acc.: 51.56%] [G loss: 0.917809]\n",
      "epoch:5 step:5559 [D loss: 0.708663, acc.: 55.47%] [G loss: 0.831510]\n",
      "epoch:5 step:5560 [D loss: 0.590739, acc.: 71.88%] [G loss: 0.902083]\n",
      "epoch:5 step:5561 [D loss: 0.654314, acc.: 60.94%] [G loss: 1.027636]\n",
      "epoch:5 step:5562 [D loss: 0.654835, acc.: 63.28%] [G loss: 0.958458]\n",
      "epoch:5 step:5563 [D loss: 0.717046, acc.: 52.34%] [G loss: 0.904612]\n",
      "epoch:5 step:5564 [D loss: 0.653837, acc.: 59.38%] [G loss: 0.859361]\n",
      "epoch:5 step:5565 [D loss: 0.678139, acc.: 58.59%] [G loss: 0.961578]\n",
      "epoch:5 step:5566 [D loss: 0.685538, acc.: 55.47%] [G loss: 0.926007]\n",
      "epoch:5 step:5567 [D loss: 0.625868, acc.: 67.19%] [G loss: 1.028970]\n",
      "epoch:5 step:5568 [D loss: 0.679446, acc.: 61.72%] [G loss: 0.807940]\n",
      "epoch:5 step:5569 [D loss: 0.650234, acc.: 60.16%] [G loss: 0.897016]\n",
      "epoch:5 step:5570 [D loss: 0.681148, acc.: 62.50%] [G loss: 0.954348]\n",
      "epoch:5 step:5571 [D loss: 0.594475, acc.: 65.62%] [G loss: 0.955722]\n",
      "epoch:5 step:5572 [D loss: 0.659735, acc.: 57.03%] [G loss: 0.927074]\n",
      "epoch:5 step:5573 [D loss: 0.576017, acc.: 71.88%] [G loss: 0.968298]\n",
      "epoch:5 step:5574 [D loss: 0.652547, acc.: 64.84%] [G loss: 0.997847]\n",
      "epoch:5 step:5575 [D loss: 0.541409, acc.: 73.44%] [G loss: 0.945067]\n",
      "epoch:5 step:5576 [D loss: 0.704823, acc.: 53.12%] [G loss: 0.864835]\n",
      "epoch:5 step:5577 [D loss: 0.785677, acc.: 45.31%] [G loss: 0.889467]\n",
      "epoch:5 step:5578 [D loss: 0.665103, acc.: 57.03%] [G loss: 0.910478]\n",
      "epoch:5 step:5579 [D loss: 0.708107, acc.: 60.16%] [G loss: 0.949342]\n",
      "epoch:5 step:5580 [D loss: 0.642415, acc.: 64.84%] [G loss: 0.894116]\n",
      "epoch:5 step:5581 [D loss: 0.746164, acc.: 47.66%] [G loss: 0.835837]\n",
      "epoch:5 step:5582 [D loss: 0.689585, acc.: 54.69%] [G loss: 0.862400]\n",
      "epoch:5 step:5583 [D loss: 0.706625, acc.: 50.78%] [G loss: 0.899090]\n",
      "epoch:5 step:5584 [D loss: 0.642251, acc.: 63.28%] [G loss: 0.902544]\n",
      "epoch:5 step:5585 [D loss: 0.626763, acc.: 64.84%] [G loss: 1.073293]\n",
      "epoch:5 step:5586 [D loss: 0.683632, acc.: 57.81%] [G loss: 0.903186]\n",
      "epoch:5 step:5587 [D loss: 0.692566, acc.: 57.81%] [G loss: 0.874987]\n",
      "epoch:5 step:5588 [D loss: 0.677597, acc.: 57.81%] [G loss: 0.906487]\n",
      "epoch:5 step:5589 [D loss: 0.677700, acc.: 60.94%] [G loss: 0.967083]\n",
      "epoch:5 step:5590 [D loss: 0.685826, acc.: 59.38%] [G loss: 0.844713]\n",
      "epoch:5 step:5591 [D loss: 0.628081, acc.: 66.41%] [G loss: 0.907139]\n",
      "epoch:5 step:5592 [D loss: 0.649504, acc.: 62.50%] [G loss: 0.823442]\n",
      "epoch:5 step:5593 [D loss: 0.702404, acc.: 47.66%] [G loss: 0.980214]\n",
      "epoch:5 step:5594 [D loss: 0.673726, acc.: 57.03%] [G loss: 1.065401]\n",
      "epoch:5 step:5595 [D loss: 0.570603, acc.: 68.75%] [G loss: 0.966553]\n",
      "epoch:5 step:5596 [D loss: 0.627438, acc.: 64.06%] [G loss: 0.923350]\n",
      "epoch:5 step:5597 [D loss: 0.613045, acc.: 67.97%] [G loss: 0.945385]\n",
      "epoch:5 step:5598 [D loss: 0.708580, acc.: 53.91%] [G loss: 0.994171]\n",
      "epoch:5 step:5599 [D loss: 0.676386, acc.: 60.94%] [G loss: 0.948344]\n",
      "epoch:5 step:5600 [D loss: 0.685811, acc.: 64.06%] [G loss: 0.832664]\n",
      "##############\n",
      "[1.80821534 1.326195   4.63820974 3.90807619 2.80775156 4.76322869\n",
      " 3.69783756 4.584887   3.31323833 3.01059563]\n",
      "##########\n",
      "epoch:5 step:5601 [D loss: 0.661228, acc.: 67.97%] [G loss: 1.017286]\n",
      "epoch:5 step:5602 [D loss: 0.647453, acc.: 56.25%] [G loss: 0.879764]\n",
      "epoch:5 step:5603 [D loss: 0.562320, acc.: 74.22%] [G loss: 0.963583]\n",
      "epoch:5 step:5604 [D loss: 0.553637, acc.: 72.66%] [G loss: 0.981621]\n",
      "epoch:5 step:5605 [D loss: 0.722310, acc.: 55.47%] [G loss: 0.969235]\n",
      "epoch:5 step:5606 [D loss: 0.653354, acc.: 60.16%] [G loss: 0.894625]\n",
      "epoch:5 step:5607 [D loss: 0.553882, acc.: 73.44%] [G loss: 0.985041]\n",
      "epoch:5 step:5608 [D loss: 0.513728, acc.: 76.56%] [G loss: 1.118066]\n",
      "epoch:5 step:5609 [D loss: 0.611760, acc.: 63.28%] [G loss: 0.922939]\n",
      "epoch:5 step:5610 [D loss: 0.546005, acc.: 71.88%] [G loss: 1.051849]\n",
      "epoch:5 step:5611 [D loss: 0.608703, acc.: 66.41%] [G loss: 1.120371]\n",
      "epoch:5 step:5612 [D loss: 0.590350, acc.: 72.66%] [G loss: 1.038313]\n",
      "epoch:5 step:5613 [D loss: 0.878209, acc.: 42.19%] [G loss: 0.959680]\n",
      "epoch:5 step:5614 [D loss: 0.822070, acc.: 42.97%] [G loss: 0.974822]\n",
      "epoch:5 step:5615 [D loss: 0.543831, acc.: 71.88%] [G loss: 1.009351]\n",
      "epoch:5 step:5616 [D loss: 0.710830, acc.: 57.03%] [G loss: 0.893041]\n",
      "epoch:5 step:5617 [D loss: 0.693131, acc.: 56.25%] [G loss: 0.824000]\n",
      "epoch:5 step:5618 [D loss: 0.616318, acc.: 64.84%] [G loss: 0.843167]\n",
      "epoch:5 step:5619 [D loss: 0.613738, acc.: 64.06%] [G loss: 0.977938]\n",
      "epoch:5 step:5620 [D loss: 0.659602, acc.: 62.50%] [G loss: 1.046819]\n",
      "epoch:5 step:5621 [D loss: 0.569640, acc.: 75.00%] [G loss: 0.957155]\n",
      "epoch:5 step:5622 [D loss: 0.530689, acc.: 74.22%] [G loss: 1.085577]\n",
      "epoch:6 step:5623 [D loss: 0.714917, acc.: 52.34%] [G loss: 0.962403]\n",
      "epoch:6 step:5624 [D loss: 0.693666, acc.: 58.59%] [G loss: 1.091708]\n",
      "epoch:6 step:5625 [D loss: 0.746066, acc.: 51.56%] [G loss: 0.931540]\n",
      "epoch:6 step:5626 [D loss: 0.654124, acc.: 61.72%] [G loss: 1.016547]\n",
      "epoch:6 step:5627 [D loss: 0.663097, acc.: 61.72%] [G loss: 0.818383]\n",
      "epoch:6 step:5628 [D loss: 0.640394, acc.: 61.72%] [G loss: 0.990125]\n",
      "epoch:6 step:5629 [D loss: 0.612857, acc.: 66.41%] [G loss: 1.048920]\n",
      "epoch:6 step:5630 [D loss: 0.621004, acc.: 65.62%] [G loss: 0.998544]\n",
      "epoch:6 step:5631 [D loss: 0.644592, acc.: 60.16%] [G loss: 1.078798]\n",
      "epoch:6 step:5632 [D loss: 0.637469, acc.: 63.28%] [G loss: 1.008098]\n",
      "epoch:6 step:5633 [D loss: 0.702667, acc.: 53.91%] [G loss: 0.810502]\n",
      "epoch:6 step:5634 [D loss: 0.658838, acc.: 61.72%] [G loss: 1.067305]\n",
      "epoch:6 step:5635 [D loss: 0.628546, acc.: 66.41%] [G loss: 1.037716]\n",
      "epoch:6 step:5636 [D loss: 0.615311, acc.: 67.97%] [G loss: 0.851097]\n",
      "epoch:6 step:5637 [D loss: 0.573633, acc.: 73.44%] [G loss: 1.123412]\n",
      "epoch:6 step:5638 [D loss: 0.626855, acc.: 66.41%] [G loss: 1.027491]\n",
      "epoch:6 step:5639 [D loss: 0.671475, acc.: 57.03%] [G loss: 0.922380]\n",
      "epoch:6 step:5640 [D loss: 0.740907, acc.: 53.91%] [G loss: 0.960480]\n",
      "epoch:6 step:5641 [D loss: 0.697002, acc.: 57.03%] [G loss: 0.933854]\n",
      "epoch:6 step:5642 [D loss: 0.890424, acc.: 37.50%] [G loss: 0.923238]\n",
      "epoch:6 step:5643 [D loss: 0.716149, acc.: 51.56%] [G loss: 0.938356]\n",
      "epoch:6 step:5644 [D loss: 0.679049, acc.: 64.84%] [G loss: 0.979611]\n",
      "epoch:6 step:5645 [D loss: 0.557835, acc.: 74.22%] [G loss: 1.068854]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5646 [D loss: 0.684067, acc.: 61.72%] [G loss: 0.924446]\n",
      "epoch:6 step:5647 [D loss: 0.687326, acc.: 54.69%] [G loss: 0.838252]\n",
      "epoch:6 step:5648 [D loss: 0.709141, acc.: 54.69%] [G loss: 0.926888]\n",
      "epoch:6 step:5649 [D loss: 0.758631, acc.: 49.22%] [G loss: 0.959582]\n",
      "epoch:6 step:5650 [D loss: 0.586002, acc.: 68.75%] [G loss: 1.097312]\n",
      "epoch:6 step:5651 [D loss: 0.651055, acc.: 60.94%] [G loss: 0.921276]\n",
      "epoch:6 step:5652 [D loss: 0.675559, acc.: 63.28%] [G loss: 0.973357]\n",
      "epoch:6 step:5653 [D loss: 0.622940, acc.: 69.53%] [G loss: 0.923733]\n",
      "epoch:6 step:5654 [D loss: 0.691281, acc.: 57.03%] [G loss: 0.942985]\n",
      "epoch:6 step:5655 [D loss: 0.671858, acc.: 62.50%] [G loss: 1.034390]\n",
      "epoch:6 step:5656 [D loss: 0.645763, acc.: 64.84%] [G loss: 0.973999]\n",
      "epoch:6 step:5657 [D loss: 0.657335, acc.: 63.28%] [G loss: 0.938589]\n",
      "epoch:6 step:5658 [D loss: 0.607368, acc.: 64.06%] [G loss: 1.048805]\n",
      "epoch:6 step:5659 [D loss: 0.649829, acc.: 60.94%] [G loss: 1.027725]\n",
      "epoch:6 step:5660 [D loss: 0.661057, acc.: 60.16%] [G loss: 1.044276]\n",
      "epoch:6 step:5661 [D loss: 0.665670, acc.: 59.38%] [G loss: 0.900606]\n",
      "epoch:6 step:5662 [D loss: 0.635998, acc.: 64.06%] [G loss: 0.921811]\n",
      "epoch:6 step:5663 [D loss: 0.654930, acc.: 60.94%] [G loss: 1.042863]\n",
      "epoch:6 step:5664 [D loss: 0.612591, acc.: 60.94%] [G loss: 0.854441]\n",
      "epoch:6 step:5665 [D loss: 0.708200, acc.: 50.78%] [G loss: 0.890623]\n",
      "epoch:6 step:5666 [D loss: 0.752330, acc.: 46.88%] [G loss: 0.880910]\n",
      "epoch:6 step:5667 [D loss: 0.707065, acc.: 54.69%] [G loss: 0.944089]\n",
      "epoch:6 step:5668 [D loss: 0.679269, acc.: 57.81%] [G loss: 1.063097]\n",
      "epoch:6 step:5669 [D loss: 0.590958, acc.: 70.31%] [G loss: 0.833395]\n",
      "epoch:6 step:5670 [D loss: 0.631044, acc.: 63.28%] [G loss: 0.887513]\n",
      "epoch:6 step:5671 [D loss: 0.602361, acc.: 70.31%] [G loss: 0.992763]\n",
      "epoch:6 step:5672 [D loss: 0.572340, acc.: 71.88%] [G loss: 0.945993]\n",
      "epoch:6 step:5673 [D loss: 0.725633, acc.: 50.00%] [G loss: 0.843551]\n",
      "epoch:6 step:5674 [D loss: 0.631653, acc.: 69.53%] [G loss: 0.940266]\n",
      "epoch:6 step:5675 [D loss: 0.638720, acc.: 62.50%] [G loss: 0.979078]\n",
      "epoch:6 step:5676 [D loss: 0.666955, acc.: 57.03%] [G loss: 0.975767]\n",
      "epoch:6 step:5677 [D loss: 0.633637, acc.: 68.75%] [G loss: 0.898235]\n",
      "epoch:6 step:5678 [D loss: 0.632903, acc.: 64.06%] [G loss: 0.925135]\n",
      "epoch:6 step:5679 [D loss: 0.642028, acc.: 64.84%] [G loss: 1.015453]\n",
      "epoch:6 step:5680 [D loss: 0.645410, acc.: 63.28%] [G loss: 0.937375]\n",
      "epoch:6 step:5681 [D loss: 0.690531, acc.: 53.12%] [G loss: 1.024891]\n",
      "epoch:6 step:5682 [D loss: 0.700499, acc.: 57.81%] [G loss: 0.900408]\n",
      "epoch:6 step:5683 [D loss: 0.661105, acc.: 60.16%] [G loss: 0.917639]\n",
      "epoch:6 step:5684 [D loss: 0.657248, acc.: 64.84%] [G loss: 0.910493]\n",
      "epoch:6 step:5685 [D loss: 0.707366, acc.: 55.47%] [G loss: 0.836547]\n",
      "epoch:6 step:5686 [D loss: 0.685488, acc.: 61.72%] [G loss: 0.812162]\n",
      "epoch:6 step:5687 [D loss: 0.630212, acc.: 67.97%] [G loss: 0.900671]\n",
      "epoch:6 step:5688 [D loss: 0.608325, acc.: 69.53%] [G loss: 1.017248]\n",
      "epoch:6 step:5689 [D loss: 0.602959, acc.: 67.19%] [G loss: 1.002292]\n",
      "epoch:6 step:5690 [D loss: 0.697331, acc.: 56.25%] [G loss: 0.951462]\n",
      "epoch:6 step:5691 [D loss: 0.655949, acc.: 56.25%] [G loss: 0.947940]\n",
      "epoch:6 step:5692 [D loss: 0.688525, acc.: 60.94%] [G loss: 0.946451]\n",
      "epoch:6 step:5693 [D loss: 0.641889, acc.: 58.59%] [G loss: 0.934588]\n",
      "epoch:6 step:5694 [D loss: 0.571995, acc.: 69.53%] [G loss: 1.026132]\n",
      "epoch:6 step:5695 [D loss: 0.662781, acc.: 61.72%] [G loss: 1.044785]\n",
      "epoch:6 step:5696 [D loss: 0.731726, acc.: 51.56%] [G loss: 0.985538]\n",
      "epoch:6 step:5697 [D loss: 0.601476, acc.: 71.88%] [G loss: 1.005335]\n",
      "epoch:6 step:5698 [D loss: 0.617363, acc.: 62.50%] [G loss: 1.057493]\n",
      "epoch:6 step:5699 [D loss: 0.600976, acc.: 69.53%] [G loss: 0.987638]\n",
      "epoch:6 step:5700 [D loss: 0.711829, acc.: 57.03%] [G loss: 0.983789]\n",
      "epoch:6 step:5701 [D loss: 0.697972, acc.: 53.91%] [G loss: 0.938708]\n",
      "epoch:6 step:5702 [D loss: 0.681704, acc.: 60.16%] [G loss: 0.974017]\n",
      "epoch:6 step:5703 [D loss: 0.704298, acc.: 55.47%] [G loss: 0.974435]\n",
      "epoch:6 step:5704 [D loss: 0.656988, acc.: 61.72%] [G loss: 0.843174]\n",
      "epoch:6 step:5705 [D loss: 0.683621, acc.: 53.12%] [G loss: 0.893357]\n",
      "epoch:6 step:5706 [D loss: 0.670886, acc.: 55.47%] [G loss: 0.909271]\n",
      "epoch:6 step:5707 [D loss: 0.667760, acc.: 58.59%] [G loss: 0.954393]\n",
      "epoch:6 step:5708 [D loss: 0.718891, acc.: 50.00%] [G loss: 0.898879]\n",
      "epoch:6 step:5709 [D loss: 0.718985, acc.: 55.47%] [G loss: 0.879845]\n",
      "epoch:6 step:5710 [D loss: 0.620288, acc.: 64.06%] [G loss: 0.877477]\n",
      "epoch:6 step:5711 [D loss: 0.719492, acc.: 50.00%] [G loss: 0.879961]\n",
      "epoch:6 step:5712 [D loss: 0.693691, acc.: 57.03%] [G loss: 0.944913]\n",
      "epoch:6 step:5713 [D loss: 0.632614, acc.: 67.19%] [G loss: 0.951050]\n",
      "epoch:6 step:5714 [D loss: 0.643642, acc.: 62.50%] [G loss: 0.954742]\n",
      "epoch:6 step:5715 [D loss: 0.724455, acc.: 57.81%] [G loss: 0.873526]\n",
      "epoch:6 step:5716 [D loss: 0.700881, acc.: 52.34%] [G loss: 0.906111]\n",
      "epoch:6 step:5717 [D loss: 0.671674, acc.: 60.94%] [G loss: 0.994548]\n",
      "epoch:6 step:5718 [D loss: 0.645931, acc.: 63.28%] [G loss: 1.017350]\n",
      "epoch:6 step:5719 [D loss: 0.624437, acc.: 63.28%] [G loss: 0.938563]\n",
      "epoch:6 step:5720 [D loss: 0.703351, acc.: 57.03%] [G loss: 0.978772]\n",
      "epoch:6 step:5721 [D loss: 0.603808, acc.: 67.19%] [G loss: 0.974217]\n",
      "epoch:6 step:5722 [D loss: 0.666634, acc.: 60.94%] [G loss: 0.859131]\n",
      "epoch:6 step:5723 [D loss: 0.667215, acc.: 61.72%] [G loss: 0.971639]\n",
      "epoch:6 step:5724 [D loss: 0.597944, acc.: 67.19%] [G loss: 1.000562]\n",
      "epoch:6 step:5725 [D loss: 0.634938, acc.: 64.06%] [G loss: 0.976629]\n",
      "epoch:6 step:5726 [D loss: 0.564057, acc.: 74.22%] [G loss: 0.922482]\n",
      "epoch:6 step:5727 [D loss: 0.680025, acc.: 57.81%] [G loss: 0.946854]\n",
      "epoch:6 step:5728 [D loss: 0.670520, acc.: 64.06%] [G loss: 1.009838]\n",
      "epoch:6 step:5729 [D loss: 0.682269, acc.: 62.50%] [G loss: 0.903996]\n",
      "epoch:6 step:5730 [D loss: 0.758780, acc.: 46.09%] [G loss: 0.956370]\n",
      "epoch:6 step:5731 [D loss: 0.703762, acc.: 51.56%] [G loss: 0.906382]\n",
      "epoch:6 step:5732 [D loss: 0.615371, acc.: 67.97%] [G loss: 1.011113]\n",
      "epoch:6 step:5733 [D loss: 0.626850, acc.: 67.97%] [G loss: 0.962757]\n",
      "epoch:6 step:5734 [D loss: 0.655600, acc.: 59.38%] [G loss: 0.959860]\n",
      "epoch:6 step:5735 [D loss: 0.767660, acc.: 46.09%] [G loss: 0.855560]\n",
      "epoch:6 step:5736 [D loss: 0.709154, acc.: 56.25%] [G loss: 0.979830]\n",
      "epoch:6 step:5737 [D loss: 0.663945, acc.: 65.62%] [G loss: 1.054675]\n",
      "epoch:6 step:5738 [D loss: 0.617475, acc.: 68.75%] [G loss: 0.955244]\n",
      "epoch:6 step:5739 [D loss: 0.715126, acc.: 53.91%] [G loss: 0.898028]\n",
      "epoch:6 step:5740 [D loss: 0.644108, acc.: 60.16%] [G loss: 1.016721]\n",
      "epoch:6 step:5741 [D loss: 0.578042, acc.: 75.00%] [G loss: 1.050666]\n",
      "epoch:6 step:5742 [D loss: 0.786280, acc.: 50.00%] [G loss: 0.880649]\n",
      "epoch:6 step:5743 [D loss: 0.645111, acc.: 60.16%] [G loss: 0.926078]\n",
      "epoch:6 step:5744 [D loss: 0.703650, acc.: 52.34%] [G loss: 0.875404]\n",
      "epoch:6 step:5745 [D loss: 0.658990, acc.: 61.72%] [G loss: 1.001263]\n",
      "epoch:6 step:5746 [D loss: 0.672145, acc.: 55.47%] [G loss: 0.870898]\n",
      "epoch:6 step:5747 [D loss: 0.686463, acc.: 50.78%] [G loss: 0.942898]\n",
      "epoch:6 step:5748 [D loss: 0.712983, acc.: 53.91%] [G loss: 0.867078]\n",
      "epoch:6 step:5749 [D loss: 0.637879, acc.: 60.94%] [G loss: 0.944397]\n",
      "epoch:6 step:5750 [D loss: 0.679759, acc.: 56.25%] [G loss: 0.817983]\n",
      "epoch:6 step:5751 [D loss: 0.723720, acc.: 53.12%] [G loss: 0.938292]\n",
      "epoch:6 step:5752 [D loss: 0.687908, acc.: 56.25%] [G loss: 0.975283]\n",
      "epoch:6 step:5753 [D loss: 0.631376, acc.: 64.06%] [G loss: 0.981925]\n",
      "epoch:6 step:5754 [D loss: 0.598523, acc.: 70.31%] [G loss: 1.034654]\n",
      "epoch:6 step:5755 [D loss: 0.747848, acc.: 50.78%] [G loss: 0.890389]\n",
      "epoch:6 step:5756 [D loss: 0.701483, acc.: 50.78%] [G loss: 0.910915]\n",
      "epoch:6 step:5757 [D loss: 0.665482, acc.: 63.28%] [G loss: 0.949680]\n",
      "epoch:6 step:5758 [D loss: 0.720174, acc.: 53.12%] [G loss: 0.804238]\n",
      "epoch:6 step:5759 [D loss: 0.697582, acc.: 60.94%] [G loss: 0.959496]\n",
      "epoch:6 step:5760 [D loss: 0.657609, acc.: 57.81%] [G loss: 0.946734]\n",
      "epoch:6 step:5761 [D loss: 0.651073, acc.: 60.16%] [G loss: 0.908527]\n",
      "epoch:6 step:5762 [D loss: 0.753599, acc.: 46.88%] [G loss: 0.918514]\n",
      "epoch:6 step:5763 [D loss: 0.646262, acc.: 64.06%] [G loss: 0.997059]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5764 [D loss: 0.625743, acc.: 64.06%] [G loss: 0.992225]\n",
      "epoch:6 step:5765 [D loss: 0.659821, acc.: 61.72%] [G loss: 0.826272]\n",
      "epoch:6 step:5766 [D loss: 0.683262, acc.: 58.59%] [G loss: 0.870369]\n",
      "epoch:6 step:5767 [D loss: 0.658501, acc.: 54.69%] [G loss: 0.922569]\n",
      "epoch:6 step:5768 [D loss: 0.606700, acc.: 68.75%] [G loss: 1.013843]\n",
      "epoch:6 step:5769 [D loss: 0.703051, acc.: 52.34%] [G loss: 0.852320]\n",
      "epoch:6 step:5770 [D loss: 0.670176, acc.: 60.16%] [G loss: 0.944353]\n",
      "epoch:6 step:5771 [D loss: 0.708470, acc.: 51.56%] [G loss: 1.023556]\n",
      "epoch:6 step:5772 [D loss: 0.716908, acc.: 50.78%] [G loss: 0.901242]\n",
      "epoch:6 step:5773 [D loss: 0.659073, acc.: 58.59%] [G loss: 0.931761]\n",
      "epoch:6 step:5774 [D loss: 0.686640, acc.: 57.81%] [G loss: 0.885043]\n",
      "epoch:6 step:5775 [D loss: 0.660864, acc.: 61.72%] [G loss: 0.956196]\n",
      "epoch:6 step:5776 [D loss: 0.695771, acc.: 59.38%] [G loss: 0.962511]\n",
      "epoch:6 step:5777 [D loss: 0.618366, acc.: 64.84%] [G loss: 0.960075]\n",
      "epoch:6 step:5778 [D loss: 0.623268, acc.: 64.06%] [G loss: 1.056253]\n",
      "epoch:6 step:5779 [D loss: 0.605845, acc.: 67.97%] [G loss: 0.892913]\n",
      "epoch:6 step:5780 [D loss: 0.681114, acc.: 54.69%] [G loss: 1.037753]\n",
      "epoch:6 step:5781 [D loss: 0.728449, acc.: 50.00%] [G loss: 0.918258]\n",
      "epoch:6 step:5782 [D loss: 0.751302, acc.: 43.75%] [G loss: 0.860964]\n",
      "epoch:6 step:5783 [D loss: 0.789548, acc.: 45.31%] [G loss: 0.832560]\n",
      "epoch:6 step:5784 [D loss: 0.641049, acc.: 64.06%] [G loss: 0.767033]\n",
      "epoch:6 step:5785 [D loss: 0.668996, acc.: 56.25%] [G loss: 0.788481]\n",
      "epoch:6 step:5786 [D loss: 0.721472, acc.: 49.22%] [G loss: 0.890744]\n",
      "epoch:6 step:5787 [D loss: 0.632360, acc.: 65.62%] [G loss: 0.983746]\n",
      "epoch:6 step:5788 [D loss: 0.658626, acc.: 61.72%] [G loss: 0.903738]\n",
      "epoch:6 step:5789 [D loss: 0.654144, acc.: 58.59%] [G loss: 0.949792]\n",
      "epoch:6 step:5790 [D loss: 0.603686, acc.: 72.66%] [G loss: 1.088794]\n",
      "epoch:6 step:5791 [D loss: 0.688599, acc.: 55.47%] [G loss: 0.866908]\n",
      "epoch:6 step:5792 [D loss: 0.703030, acc.: 53.91%] [G loss: 0.930077]\n",
      "epoch:6 step:5793 [D loss: 0.674621, acc.: 57.03%] [G loss: 1.022503]\n",
      "epoch:6 step:5794 [D loss: 0.690074, acc.: 53.91%] [G loss: 0.975583]\n",
      "epoch:6 step:5795 [D loss: 0.691735, acc.: 55.47%] [G loss: 0.833408]\n",
      "epoch:6 step:5796 [D loss: 0.679444, acc.: 57.81%] [G loss: 0.861896]\n",
      "epoch:6 step:5797 [D loss: 0.658565, acc.: 59.38%] [G loss: 0.993844]\n",
      "epoch:6 step:5798 [D loss: 0.660173, acc.: 60.16%] [G loss: 0.996980]\n",
      "epoch:6 step:5799 [D loss: 0.679424, acc.: 60.16%] [G loss: 0.910041]\n",
      "epoch:6 step:5800 [D loss: 0.615023, acc.: 66.41%] [G loss: 0.939923]\n",
      "##############\n",
      "[1.98820687 1.076575   5.01797685 4.16179852 2.64381539 5.07544116\n",
      " 3.64048827 4.36273734 3.46607306 3.22089307]\n",
      "##########\n",
      "epoch:6 step:5801 [D loss: 0.727862, acc.: 51.56%] [G loss: 0.922473]\n",
      "epoch:6 step:5802 [D loss: 0.688590, acc.: 57.03%] [G loss: 0.919088]\n",
      "epoch:6 step:5803 [D loss: 0.716640, acc.: 52.34%] [G loss: 0.931202]\n",
      "epoch:6 step:5804 [D loss: 0.761310, acc.: 46.88%] [G loss: 0.808122]\n",
      "epoch:6 step:5805 [D loss: 0.721821, acc.: 50.78%] [G loss: 0.930798]\n",
      "epoch:6 step:5806 [D loss: 0.697678, acc.: 53.91%] [G loss: 0.907545]\n",
      "epoch:6 step:5807 [D loss: 0.683701, acc.: 60.16%] [G loss: 0.766822]\n",
      "epoch:6 step:5808 [D loss: 0.638350, acc.: 63.28%] [G loss: 1.008129]\n",
      "epoch:6 step:5809 [D loss: 0.632201, acc.: 67.19%] [G loss: 0.907291]\n",
      "epoch:6 step:5810 [D loss: 0.639381, acc.: 58.59%] [G loss: 0.943879]\n",
      "epoch:6 step:5811 [D loss: 0.695420, acc.: 57.03%] [G loss: 0.945016]\n",
      "epoch:6 step:5812 [D loss: 0.689163, acc.: 62.50%] [G loss: 0.895531]\n",
      "epoch:6 step:5813 [D loss: 0.631828, acc.: 64.84%] [G loss: 1.014100]\n",
      "epoch:6 step:5814 [D loss: 0.666879, acc.: 60.94%] [G loss: 0.984048]\n",
      "epoch:6 step:5815 [D loss: 0.702377, acc.: 55.47%] [G loss: 0.909907]\n",
      "epoch:6 step:5816 [D loss: 0.581739, acc.: 66.41%] [G loss: 0.919264]\n",
      "epoch:6 step:5817 [D loss: 0.694025, acc.: 53.91%] [G loss: 0.967583]\n",
      "epoch:6 step:5818 [D loss: 0.712028, acc.: 53.12%] [G loss: 0.961031]\n",
      "epoch:6 step:5819 [D loss: 0.695484, acc.: 53.91%] [G loss: 0.942199]\n",
      "epoch:6 step:5820 [D loss: 0.672757, acc.: 60.94%] [G loss: 0.956051]\n",
      "epoch:6 step:5821 [D loss: 0.697560, acc.: 56.25%] [G loss: 0.896210]\n",
      "epoch:6 step:5822 [D loss: 0.733624, acc.: 50.00%] [G loss: 0.885599]\n",
      "epoch:6 step:5823 [D loss: 0.671457, acc.: 62.50%] [G loss: 0.907457]\n",
      "epoch:6 step:5824 [D loss: 0.676013, acc.: 60.16%] [G loss: 0.854659]\n",
      "epoch:6 step:5825 [D loss: 0.704447, acc.: 58.59%] [G loss: 0.880326]\n",
      "epoch:6 step:5826 [D loss: 0.684265, acc.: 63.28%] [G loss: 0.965294]\n",
      "epoch:6 step:5827 [D loss: 0.666938, acc.: 57.81%] [G loss: 0.882466]\n",
      "epoch:6 step:5828 [D loss: 0.639018, acc.: 62.50%] [G loss: 1.022544]\n",
      "epoch:6 step:5829 [D loss: 0.634294, acc.: 60.94%] [G loss: 0.920619]\n",
      "epoch:6 step:5830 [D loss: 0.635262, acc.: 67.19%] [G loss: 1.156639]\n",
      "epoch:6 step:5831 [D loss: 0.618505, acc.: 66.41%] [G loss: 0.990611]\n",
      "epoch:6 step:5832 [D loss: 0.669978, acc.: 55.47%] [G loss: 0.914011]\n",
      "epoch:6 step:5833 [D loss: 0.638035, acc.: 60.94%] [G loss: 1.044825]\n",
      "epoch:6 step:5834 [D loss: 0.646077, acc.: 62.50%] [G loss: 0.929376]\n",
      "epoch:6 step:5835 [D loss: 0.754652, acc.: 47.66%] [G loss: 0.746987]\n",
      "epoch:6 step:5836 [D loss: 0.670474, acc.: 55.47%] [G loss: 0.936141]\n",
      "epoch:6 step:5837 [D loss: 0.746158, acc.: 45.31%] [G loss: 1.003077]\n",
      "epoch:6 step:5838 [D loss: 0.708224, acc.: 55.47%] [G loss: 0.877452]\n",
      "epoch:6 step:5839 [D loss: 0.609201, acc.: 71.88%] [G loss: 0.950234]\n",
      "epoch:6 step:5840 [D loss: 0.617400, acc.: 66.41%] [G loss: 1.040973]\n",
      "epoch:6 step:5841 [D loss: 0.593671, acc.: 70.31%] [G loss: 0.935287]\n",
      "epoch:6 step:5842 [D loss: 0.846710, acc.: 37.50%] [G loss: 0.884764]\n",
      "epoch:6 step:5843 [D loss: 0.683257, acc.: 54.69%] [G loss: 0.949875]\n",
      "epoch:6 step:5844 [D loss: 0.636507, acc.: 62.50%] [G loss: 1.031588]\n",
      "epoch:6 step:5845 [D loss: 0.622620, acc.: 61.72%] [G loss: 0.955179]\n",
      "epoch:6 step:5846 [D loss: 0.667439, acc.: 57.03%] [G loss: 1.025018]\n",
      "epoch:6 step:5847 [D loss: 0.640055, acc.: 64.06%] [G loss: 0.946849]\n",
      "epoch:6 step:5848 [D loss: 0.680890, acc.: 57.81%] [G loss: 0.952453]\n",
      "epoch:6 step:5849 [D loss: 0.703273, acc.: 53.91%] [G loss: 0.805104]\n",
      "epoch:6 step:5850 [D loss: 0.694877, acc.: 59.38%] [G loss: 0.873662]\n",
      "epoch:6 step:5851 [D loss: 0.700200, acc.: 58.59%] [G loss: 0.799889]\n",
      "epoch:6 step:5852 [D loss: 0.656267, acc.: 57.81%] [G loss: 0.932860]\n",
      "epoch:6 step:5853 [D loss: 0.609037, acc.: 70.31%] [G loss: 1.052573]\n",
      "epoch:6 step:5854 [D loss: 0.544882, acc.: 78.12%] [G loss: 1.092531]\n",
      "epoch:6 step:5855 [D loss: 0.606126, acc.: 63.28%] [G loss: 1.135836]\n",
      "epoch:6 step:5856 [D loss: 0.757801, acc.: 45.31%] [G loss: 0.948902]\n",
      "epoch:6 step:5857 [D loss: 0.689849, acc.: 58.59%] [G loss: 0.884852]\n",
      "epoch:6 step:5858 [D loss: 0.671862, acc.: 57.81%] [G loss: 0.890821]\n",
      "epoch:6 step:5859 [D loss: 0.654190, acc.: 65.62%] [G loss: 0.925355]\n",
      "epoch:6 step:5860 [D loss: 0.627360, acc.: 65.62%] [G loss: 0.908701]\n",
      "epoch:6 step:5861 [D loss: 0.684672, acc.: 58.59%] [G loss: 0.991481]\n",
      "epoch:6 step:5862 [D loss: 0.696244, acc.: 53.12%] [G loss: 0.962860]\n",
      "epoch:6 step:5863 [D loss: 0.645197, acc.: 63.28%] [G loss: 0.983581]\n",
      "epoch:6 step:5864 [D loss: 0.652177, acc.: 62.50%] [G loss: 0.966102]\n",
      "epoch:6 step:5865 [D loss: 0.661986, acc.: 60.16%] [G loss: 0.836647]\n",
      "epoch:6 step:5866 [D loss: 0.661988, acc.: 54.69%] [G loss: 1.010367]\n",
      "epoch:6 step:5867 [D loss: 0.643350, acc.: 64.06%] [G loss: 0.935862]\n",
      "epoch:6 step:5868 [D loss: 0.726906, acc.: 50.78%] [G loss: 0.989119]\n",
      "epoch:6 step:5869 [D loss: 0.774289, acc.: 45.31%] [G loss: 0.907346]\n",
      "epoch:6 step:5870 [D loss: 0.715833, acc.: 57.03%] [G loss: 0.934635]\n",
      "epoch:6 step:5871 [D loss: 0.719172, acc.: 50.00%] [G loss: 0.922937]\n",
      "epoch:6 step:5872 [D loss: 0.654258, acc.: 63.28%] [G loss: 0.989219]\n",
      "epoch:6 step:5873 [D loss: 0.715125, acc.: 53.91%] [G loss: 0.960438]\n",
      "epoch:6 step:5874 [D loss: 0.659938, acc.: 62.50%] [G loss: 0.948844]\n",
      "epoch:6 step:5875 [D loss: 0.685665, acc.: 58.59%] [G loss: 0.913028]\n",
      "epoch:6 step:5876 [D loss: 0.641701, acc.: 60.94%] [G loss: 0.972626]\n",
      "epoch:6 step:5877 [D loss: 0.660616, acc.: 60.94%] [G loss: 0.977456]\n",
      "epoch:6 step:5878 [D loss: 0.701974, acc.: 58.59%] [G loss: 0.872977]\n",
      "epoch:6 step:5879 [D loss: 0.607338, acc.: 67.19%] [G loss: 0.910202]\n",
      "epoch:6 step:5880 [D loss: 0.663116, acc.: 59.38%] [G loss: 0.817392]\n",
      "epoch:6 step:5881 [D loss: 0.653982, acc.: 60.16%] [G loss: 0.908464]\n",
      "epoch:6 step:5882 [D loss: 0.637931, acc.: 65.62%] [G loss: 1.005300]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5883 [D loss: 0.661973, acc.: 57.03%] [G loss: 1.029724]\n",
      "epoch:6 step:5884 [D loss: 0.609250, acc.: 65.62%] [G loss: 0.936271]\n",
      "epoch:6 step:5885 [D loss: 0.697475, acc.: 54.69%] [G loss: 0.906790]\n",
      "epoch:6 step:5886 [D loss: 0.643998, acc.: 63.28%] [G loss: 0.979772]\n",
      "epoch:6 step:5887 [D loss: 0.651843, acc.: 60.16%] [G loss: 0.926889]\n",
      "epoch:6 step:5888 [D loss: 0.730954, acc.: 49.22%] [G loss: 0.950689]\n",
      "epoch:6 step:5889 [D loss: 0.683770, acc.: 58.59%] [G loss: 0.815203]\n",
      "epoch:6 step:5890 [D loss: 0.705490, acc.: 57.03%] [G loss: 0.901522]\n",
      "epoch:6 step:5891 [D loss: 0.695120, acc.: 52.34%] [G loss: 0.893404]\n",
      "epoch:6 step:5892 [D loss: 0.688752, acc.: 53.91%] [G loss: 1.018958]\n",
      "epoch:6 step:5893 [D loss: 0.657566, acc.: 62.50%] [G loss: 0.913160]\n",
      "epoch:6 step:5894 [D loss: 0.658085, acc.: 61.72%] [G loss: 0.981141]\n",
      "epoch:6 step:5895 [D loss: 0.617000, acc.: 63.28%] [G loss: 0.903352]\n",
      "epoch:6 step:5896 [D loss: 0.658062, acc.: 57.81%] [G loss: 0.967277]\n",
      "epoch:6 step:5897 [D loss: 0.713658, acc.: 50.78%] [G loss: 0.897344]\n",
      "epoch:6 step:5898 [D loss: 0.746980, acc.: 46.88%] [G loss: 0.757921]\n",
      "epoch:6 step:5899 [D loss: 0.647981, acc.: 67.97%] [G loss: 0.884270]\n",
      "epoch:6 step:5900 [D loss: 0.664164, acc.: 57.03%] [G loss: 0.991575]\n",
      "epoch:6 step:5901 [D loss: 0.714976, acc.: 51.56%] [G loss: 0.909578]\n",
      "epoch:6 step:5902 [D loss: 0.672970, acc.: 52.34%] [G loss: 0.917992]\n",
      "epoch:6 step:5903 [D loss: 0.706690, acc.: 53.12%] [G loss: 0.823048]\n",
      "epoch:6 step:5904 [D loss: 0.689108, acc.: 59.38%] [G loss: 1.008234]\n",
      "epoch:6 step:5905 [D loss: 0.662922, acc.: 60.94%] [G loss: 0.988109]\n",
      "epoch:6 step:5906 [D loss: 0.646091, acc.: 64.06%] [G loss: 0.989388]\n",
      "epoch:6 step:5907 [D loss: 0.690184, acc.: 52.34%] [G loss: 0.921716]\n",
      "epoch:6 step:5908 [D loss: 0.652374, acc.: 60.94%] [G loss: 1.023209]\n",
      "epoch:6 step:5909 [D loss: 0.693686, acc.: 55.47%] [G loss: 0.933836]\n",
      "epoch:6 step:5910 [D loss: 0.722676, acc.: 52.34%] [G loss: 0.864540]\n",
      "epoch:6 step:5911 [D loss: 0.691572, acc.: 56.25%] [G loss: 0.786282]\n",
      "epoch:6 step:5912 [D loss: 0.674720, acc.: 54.69%] [G loss: 0.906422]\n",
      "epoch:6 step:5913 [D loss: 0.702395, acc.: 54.69%] [G loss: 0.980108]\n",
      "epoch:6 step:5914 [D loss: 0.747169, acc.: 49.22%] [G loss: 0.810502]\n",
      "epoch:6 step:5915 [D loss: 0.669752, acc.: 60.94%] [G loss: 0.969048]\n",
      "epoch:6 step:5916 [D loss: 0.640410, acc.: 58.59%] [G loss: 0.897940]\n",
      "epoch:6 step:5917 [D loss: 0.681803, acc.: 61.72%] [G loss: 0.858987]\n",
      "epoch:6 step:5918 [D loss: 0.627789, acc.: 66.41%] [G loss: 0.979297]\n",
      "epoch:6 step:5919 [D loss: 0.663382, acc.: 59.38%] [G loss: 0.931857]\n",
      "epoch:6 step:5920 [D loss: 0.582934, acc.: 73.44%] [G loss: 0.986439]\n",
      "epoch:6 step:5921 [D loss: 0.640075, acc.: 60.94%] [G loss: 0.939018]\n",
      "epoch:6 step:5922 [D loss: 0.678002, acc.: 53.91%] [G loss: 1.008767]\n",
      "epoch:6 step:5923 [D loss: 0.748983, acc.: 51.56%] [G loss: 0.879179]\n",
      "epoch:6 step:5924 [D loss: 0.666592, acc.: 60.94%] [G loss: 0.812355]\n",
      "epoch:6 step:5925 [D loss: 0.661788, acc.: 58.59%] [G loss: 0.855320]\n",
      "epoch:6 step:5926 [D loss: 0.646885, acc.: 61.72%] [G loss: 1.001488]\n",
      "epoch:6 step:5927 [D loss: 0.681711, acc.: 57.03%] [G loss: 0.864117]\n",
      "epoch:6 step:5928 [D loss: 0.614401, acc.: 65.62%] [G loss: 0.942303]\n",
      "epoch:6 step:5929 [D loss: 0.610144, acc.: 63.28%] [G loss: 0.958815]\n",
      "epoch:6 step:5930 [D loss: 0.626349, acc.: 68.75%] [G loss: 1.087537]\n",
      "epoch:6 step:5931 [D loss: 0.598620, acc.: 69.53%] [G loss: 1.021325]\n",
      "epoch:6 step:5932 [D loss: 0.605887, acc.: 65.62%] [G loss: 1.124814]\n",
      "epoch:6 step:5933 [D loss: 0.631086, acc.: 60.94%] [G loss: 0.929052]\n",
      "epoch:6 step:5934 [D loss: 0.634156, acc.: 66.41%] [G loss: 1.047477]\n",
      "epoch:6 step:5935 [D loss: 0.618080, acc.: 69.53%] [G loss: 0.956547]\n",
      "epoch:6 step:5936 [D loss: 0.578902, acc.: 71.09%] [G loss: 1.010020]\n",
      "epoch:6 step:5937 [D loss: 0.615428, acc.: 64.84%] [G loss: 1.048711]\n",
      "epoch:6 step:5938 [D loss: 0.751867, acc.: 50.00%] [G loss: 1.017152]\n",
      "epoch:6 step:5939 [D loss: 0.655833, acc.: 59.38%] [G loss: 0.949593]\n",
      "epoch:6 step:5940 [D loss: 0.653969, acc.: 63.28%] [G loss: 1.042788]\n",
      "epoch:6 step:5941 [D loss: 0.655351, acc.: 61.72%] [G loss: 0.949938]\n",
      "epoch:6 step:5942 [D loss: 0.634368, acc.: 64.06%] [G loss: 0.869188]\n",
      "epoch:6 step:5943 [D loss: 0.636852, acc.: 62.50%] [G loss: 0.987592]\n",
      "epoch:6 step:5944 [D loss: 0.688026, acc.: 56.25%] [G loss: 0.915167]\n",
      "epoch:6 step:5945 [D loss: 0.731400, acc.: 48.44%] [G loss: 0.967090]\n",
      "epoch:6 step:5946 [D loss: 0.655890, acc.: 63.28%] [G loss: 0.853773]\n",
      "epoch:6 step:5947 [D loss: 0.739705, acc.: 48.44%] [G loss: 0.891307]\n",
      "epoch:6 step:5948 [D loss: 0.719789, acc.: 56.25%] [G loss: 0.899945]\n",
      "epoch:6 step:5949 [D loss: 0.734472, acc.: 47.66%] [G loss: 0.884629]\n",
      "epoch:6 step:5950 [D loss: 0.671587, acc.: 58.59%] [G loss: 0.833961]\n",
      "epoch:6 step:5951 [D loss: 0.635505, acc.: 60.16%] [G loss: 1.053955]\n",
      "epoch:6 step:5952 [D loss: 0.612954, acc.: 70.31%] [G loss: 0.973154]\n",
      "epoch:6 step:5953 [D loss: 0.746538, acc.: 47.66%] [G loss: 0.942212]\n",
      "epoch:6 step:5954 [D loss: 0.656684, acc.: 63.28%] [G loss: 0.944578]\n",
      "epoch:6 step:5955 [D loss: 0.706814, acc.: 52.34%] [G loss: 0.923312]\n",
      "epoch:6 step:5956 [D loss: 0.717672, acc.: 55.47%] [G loss: 0.885310]\n",
      "epoch:6 step:5957 [D loss: 0.640686, acc.: 62.50%] [G loss: 0.823880]\n",
      "epoch:6 step:5958 [D loss: 0.658315, acc.: 62.50%] [G loss: 0.830054]\n",
      "epoch:6 step:5959 [D loss: 0.590760, acc.: 67.19%] [G loss: 0.905276]\n",
      "epoch:6 step:5960 [D loss: 0.652615, acc.: 64.06%] [G loss: 0.972513]\n",
      "epoch:6 step:5961 [D loss: 0.639500, acc.: 61.72%] [G loss: 0.918675]\n",
      "epoch:6 step:5962 [D loss: 0.600918, acc.: 69.53%] [G loss: 0.969909]\n",
      "epoch:6 step:5963 [D loss: 0.638805, acc.: 61.72%] [G loss: 1.056556]\n",
      "epoch:6 step:5964 [D loss: 0.730991, acc.: 45.31%] [G loss: 0.870952]\n",
      "epoch:6 step:5965 [D loss: 0.611123, acc.: 65.62%] [G loss: 0.984160]\n",
      "epoch:6 step:5966 [D loss: 0.604082, acc.: 64.84%] [G loss: 1.013358]\n",
      "epoch:6 step:5967 [D loss: 0.653331, acc.: 60.16%] [G loss: 0.969079]\n",
      "epoch:6 step:5968 [D loss: 0.628411, acc.: 65.62%] [G loss: 0.860749]\n",
      "epoch:6 step:5969 [D loss: 0.610208, acc.: 66.41%] [G loss: 1.079432]\n",
      "epoch:6 step:5970 [D loss: 0.709044, acc.: 53.91%] [G loss: 0.923642]\n",
      "epoch:6 step:5971 [D loss: 0.707883, acc.: 54.69%] [G loss: 0.993529]\n",
      "epoch:6 step:5972 [D loss: 0.684164, acc.: 55.47%] [G loss: 0.941386]\n",
      "epoch:6 step:5973 [D loss: 0.684036, acc.: 59.38%] [G loss: 0.828749]\n",
      "epoch:6 step:5974 [D loss: 0.752283, acc.: 49.22%] [G loss: 0.851438]\n",
      "epoch:6 step:5975 [D loss: 0.707702, acc.: 53.91%] [G loss: 0.902983]\n",
      "epoch:6 step:5976 [D loss: 0.676272, acc.: 62.50%] [G loss: 0.989327]\n",
      "epoch:6 step:5977 [D loss: 0.682865, acc.: 60.16%] [G loss: 0.934988]\n",
      "epoch:6 step:5978 [D loss: 0.679758, acc.: 58.59%] [G loss: 0.866332]\n",
      "epoch:6 step:5979 [D loss: 0.615145, acc.: 68.75%] [G loss: 0.905431]\n",
      "epoch:6 step:5980 [D loss: 0.625142, acc.: 64.84%] [G loss: 1.044008]\n",
      "epoch:6 step:5981 [D loss: 0.614311, acc.: 64.84%] [G loss: 1.042184]\n",
      "epoch:6 step:5982 [D loss: 0.608788, acc.: 66.41%] [G loss: 1.062597]\n",
      "epoch:6 step:5983 [D loss: 0.674719, acc.: 54.69%] [G loss: 0.969296]\n",
      "epoch:6 step:5984 [D loss: 0.691237, acc.: 55.47%] [G loss: 1.020127]\n",
      "epoch:6 step:5985 [D loss: 0.667884, acc.: 63.28%] [G loss: 0.808874]\n",
      "epoch:6 step:5986 [D loss: 0.621739, acc.: 66.41%] [G loss: 0.955436]\n",
      "epoch:6 step:5987 [D loss: 0.697716, acc.: 57.03%] [G loss: 0.984154]\n",
      "epoch:6 step:5988 [D loss: 0.681757, acc.: 51.56%] [G loss: 0.879013]\n",
      "epoch:6 step:5989 [D loss: 0.649337, acc.: 60.16%] [G loss: 0.979527]\n",
      "epoch:6 step:5990 [D loss: 0.680181, acc.: 57.81%] [G loss: 0.903314]\n",
      "epoch:6 step:5991 [D loss: 0.680689, acc.: 57.03%] [G loss: 0.860969]\n",
      "epoch:6 step:5992 [D loss: 0.571782, acc.: 71.09%] [G loss: 1.060798]\n",
      "epoch:6 step:5993 [D loss: 0.542186, acc.: 75.00%] [G loss: 0.959701]\n",
      "epoch:6 step:5994 [D loss: 0.753783, acc.: 46.88%] [G loss: 1.072250]\n",
      "epoch:6 step:5995 [D loss: 0.804828, acc.: 40.62%] [G loss: 0.774270]\n",
      "epoch:6 step:5996 [D loss: 0.688539, acc.: 53.12%] [G loss: 0.983934]\n",
      "epoch:6 step:5997 [D loss: 0.668658, acc.: 56.25%] [G loss: 0.932783]\n",
      "epoch:6 step:5998 [D loss: 0.728420, acc.: 52.34%] [G loss: 0.924768]\n",
      "epoch:6 step:5999 [D loss: 0.795725, acc.: 46.09%] [G loss: 0.841931]\n",
      "epoch:6 step:6000 [D loss: 0.623433, acc.: 67.19%] [G loss: 0.964681]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[2.0012028  1.33633005 4.87195145 4.12027145 2.80756044 4.9778474\n",
      " 3.71812301 4.54589176 3.39241494 3.31965054]\n",
      "##########\n",
      "epoch:6 step:6001 [D loss: 0.677762, acc.: 65.62%] [G loss: 0.938989]\n",
      "epoch:6 step:6002 [D loss: 0.617717, acc.: 67.97%] [G loss: 1.022799]\n",
      "epoch:6 step:6003 [D loss: 0.609438, acc.: 64.84%] [G loss: 1.079454]\n",
      "epoch:6 step:6004 [D loss: 0.717590, acc.: 51.56%] [G loss: 0.904617]\n",
      "epoch:6 step:6005 [D loss: 0.595606, acc.: 66.41%] [G loss: 0.982653]\n",
      "epoch:6 step:6006 [D loss: 0.611641, acc.: 69.53%] [G loss: 1.039906]\n",
      "epoch:6 step:6007 [D loss: 0.669446, acc.: 58.59%] [G loss: 0.996312]\n",
      "epoch:6 step:6008 [D loss: 0.618112, acc.: 67.97%] [G loss: 0.931079]\n",
      "epoch:6 step:6009 [D loss: 0.615765, acc.: 65.62%] [G loss: 0.984546]\n",
      "epoch:6 step:6010 [D loss: 0.622609, acc.: 69.53%] [G loss: 0.955202]\n",
      "epoch:6 step:6011 [D loss: 0.656339, acc.: 60.94%] [G loss: 0.983742]\n",
      "epoch:6 step:6012 [D loss: 0.730918, acc.: 47.66%] [G loss: 1.024961]\n",
      "epoch:6 step:6013 [D loss: 0.676803, acc.: 51.56%] [G loss: 0.957853]\n",
      "epoch:6 step:6014 [D loss: 0.592784, acc.: 71.88%] [G loss: 0.935640]\n",
      "epoch:6 step:6015 [D loss: 0.791679, acc.: 51.56%] [G loss: 0.947001]\n",
      "epoch:6 step:6016 [D loss: 0.714244, acc.: 51.56%] [G loss: 0.896350]\n",
      "epoch:6 step:6017 [D loss: 0.586298, acc.: 69.53%] [G loss: 1.035598]\n",
      "epoch:6 step:6018 [D loss: 0.773378, acc.: 43.75%] [G loss: 0.909976]\n",
      "epoch:6 step:6019 [D loss: 0.639964, acc.: 62.50%] [G loss: 0.908743]\n",
      "epoch:6 step:6020 [D loss: 0.564229, acc.: 75.78%] [G loss: 0.939509]\n",
      "epoch:6 step:6021 [D loss: 0.652554, acc.: 59.38%] [G loss: 1.035136]\n",
      "epoch:6 step:6022 [D loss: 0.665256, acc.: 60.94%] [G loss: 0.891455]\n",
      "epoch:6 step:6023 [D loss: 0.646130, acc.: 68.75%] [G loss: 0.924899]\n",
      "epoch:6 step:6024 [D loss: 0.709284, acc.: 54.69%] [G loss: 0.850789]\n",
      "epoch:6 step:6025 [D loss: 0.727309, acc.: 56.25%] [G loss: 0.861009]\n",
      "epoch:6 step:6026 [D loss: 0.648590, acc.: 57.03%] [G loss: 0.952483]\n",
      "epoch:6 step:6027 [D loss: 0.618874, acc.: 66.41%] [G loss: 0.907086]\n",
      "epoch:6 step:6028 [D loss: 0.608516, acc.: 60.94%] [G loss: 1.079802]\n",
      "epoch:6 step:6029 [D loss: 0.632617, acc.: 63.28%] [G loss: 0.921382]\n",
      "epoch:6 step:6030 [D loss: 0.731271, acc.: 53.12%] [G loss: 0.886914]\n",
      "epoch:6 step:6031 [D loss: 0.590392, acc.: 69.53%] [G loss: 0.998498]\n",
      "epoch:6 step:6032 [D loss: 0.629218, acc.: 68.75%] [G loss: 0.906967]\n",
      "epoch:6 step:6033 [D loss: 0.624780, acc.: 66.41%] [G loss: 0.987378]\n",
      "epoch:6 step:6034 [D loss: 0.613227, acc.: 65.62%] [G loss: 0.998144]\n",
      "epoch:6 step:6035 [D loss: 0.663799, acc.: 60.16%] [G loss: 0.856537]\n",
      "epoch:6 step:6036 [D loss: 0.700886, acc.: 55.47%] [G loss: 0.942619]\n",
      "epoch:6 step:6037 [D loss: 0.722296, acc.: 49.22%] [G loss: 0.888578]\n",
      "epoch:6 step:6038 [D loss: 0.696806, acc.: 57.03%] [G loss: 0.916872]\n",
      "epoch:6 step:6039 [D loss: 0.640553, acc.: 68.75%] [G loss: 1.059509]\n",
      "epoch:6 step:6040 [D loss: 0.648090, acc.: 62.50%] [G loss: 1.027738]\n",
      "epoch:6 step:6041 [D loss: 0.613175, acc.: 67.97%] [G loss: 0.982907]\n",
      "epoch:6 step:6042 [D loss: 0.592082, acc.: 69.53%] [G loss: 0.823796]\n",
      "epoch:6 step:6043 [D loss: 0.669292, acc.: 58.59%] [G loss: 0.924357]\n",
      "epoch:6 step:6044 [D loss: 0.674487, acc.: 64.06%] [G loss: 0.882958]\n",
      "epoch:6 step:6045 [D loss: 0.663766, acc.: 59.38%] [G loss: 0.891488]\n",
      "epoch:6 step:6046 [D loss: 0.626790, acc.: 60.16%] [G loss: 0.931382]\n",
      "epoch:6 step:6047 [D loss: 0.702889, acc.: 49.22%] [G loss: 0.832495]\n",
      "epoch:6 step:6048 [D loss: 0.622804, acc.: 64.06%] [G loss: 0.925809]\n",
      "epoch:6 step:6049 [D loss: 0.667620, acc.: 64.84%] [G loss: 0.962810]\n",
      "epoch:6 step:6050 [D loss: 0.632001, acc.: 67.19%] [G loss: 0.962299]\n",
      "epoch:6 step:6051 [D loss: 0.638399, acc.: 60.94%] [G loss: 0.910116]\n",
      "epoch:6 step:6052 [D loss: 0.669514, acc.: 61.72%] [G loss: 0.902627]\n",
      "epoch:6 step:6053 [D loss: 0.668247, acc.: 60.94%] [G loss: 1.034456]\n",
      "epoch:6 step:6054 [D loss: 0.775449, acc.: 46.09%] [G loss: 1.027899]\n",
      "epoch:6 step:6055 [D loss: 0.675258, acc.: 60.94%] [G loss: 1.059548]\n",
      "epoch:6 step:6056 [D loss: 0.677264, acc.: 58.59%] [G loss: 0.926739]\n",
      "epoch:6 step:6057 [D loss: 0.612076, acc.: 65.62%] [G loss: 1.043850]\n",
      "epoch:6 step:6058 [D loss: 0.696279, acc.: 51.56%] [G loss: 0.866600]\n",
      "epoch:6 step:6059 [D loss: 0.689833, acc.: 58.59%] [G loss: 0.850984]\n",
      "epoch:6 step:6060 [D loss: 0.623227, acc.: 65.62%] [G loss: 1.019927]\n",
      "epoch:6 step:6061 [D loss: 0.697161, acc.: 56.25%] [G loss: 0.948522]\n",
      "epoch:6 step:6062 [D loss: 0.680209, acc.: 60.16%] [G loss: 0.968018]\n",
      "epoch:6 step:6063 [D loss: 0.691048, acc.: 57.03%] [G loss: 0.989903]\n",
      "epoch:6 step:6064 [D loss: 0.691800, acc.: 55.47%] [G loss: 0.934316]\n",
      "epoch:6 step:6065 [D loss: 0.737888, acc.: 46.88%] [G loss: 0.891555]\n",
      "epoch:6 step:6066 [D loss: 0.703015, acc.: 53.12%] [G loss: 0.873218]\n",
      "epoch:6 step:6067 [D loss: 0.675422, acc.: 61.72%] [G loss: 0.860892]\n",
      "epoch:6 step:6068 [D loss: 0.689201, acc.: 53.12%] [G loss: 0.953362]\n",
      "epoch:6 step:6069 [D loss: 0.692601, acc.: 55.47%] [G loss: 0.917481]\n",
      "epoch:6 step:6070 [D loss: 0.670552, acc.: 59.38%] [G loss: 1.001809]\n",
      "epoch:6 step:6071 [D loss: 0.678512, acc.: 56.25%] [G loss: 0.980597]\n",
      "epoch:6 step:6072 [D loss: 0.679546, acc.: 57.81%] [G loss: 0.942832]\n",
      "epoch:6 step:6073 [D loss: 0.644797, acc.: 63.28%] [G loss: 1.034109]\n",
      "epoch:6 step:6074 [D loss: 0.703359, acc.: 56.25%] [G loss: 0.991110]\n",
      "epoch:6 step:6075 [D loss: 0.653326, acc.: 57.81%] [G loss: 0.994456]\n",
      "epoch:6 step:6076 [D loss: 0.722547, acc.: 50.00%] [G loss: 0.908380]\n",
      "epoch:6 step:6077 [D loss: 0.597578, acc.: 67.97%] [G loss: 0.906821]\n",
      "epoch:6 step:6078 [D loss: 0.610196, acc.: 64.84%] [G loss: 1.151546]\n",
      "epoch:6 step:6079 [D loss: 0.567678, acc.: 74.22%] [G loss: 1.009633]\n",
      "epoch:6 step:6080 [D loss: 0.777020, acc.: 46.09%] [G loss: 0.843157]\n",
      "epoch:6 step:6081 [D loss: 0.697281, acc.: 52.34%] [G loss: 0.902983]\n",
      "epoch:6 step:6082 [D loss: 0.670239, acc.: 57.03%] [G loss: 0.869745]\n",
      "epoch:6 step:6083 [D loss: 0.596363, acc.: 71.09%] [G loss: 1.085076]\n",
      "epoch:6 step:6084 [D loss: 0.680915, acc.: 55.47%] [G loss: 1.016160]\n",
      "epoch:6 step:6085 [D loss: 0.768533, acc.: 46.09%] [G loss: 0.833087]\n",
      "epoch:6 step:6086 [D loss: 0.655824, acc.: 62.50%] [G loss: 0.737663]\n",
      "epoch:6 step:6087 [D loss: 0.701682, acc.: 60.16%] [G loss: 0.896510]\n",
      "epoch:6 step:6088 [D loss: 0.647603, acc.: 65.62%] [G loss: 0.941911]\n",
      "epoch:6 step:6089 [D loss: 0.700363, acc.: 57.81%] [G loss: 0.791056]\n",
      "epoch:6 step:6090 [D loss: 0.581014, acc.: 71.09%] [G loss: 1.086993]\n",
      "epoch:6 step:6091 [D loss: 0.657197, acc.: 62.50%] [G loss: 0.867528]\n",
      "epoch:6 step:6092 [D loss: 0.611366, acc.: 65.62%] [G loss: 0.992509]\n",
      "epoch:6 step:6093 [D loss: 0.651604, acc.: 64.84%] [G loss: 0.982762]\n",
      "epoch:6 step:6094 [D loss: 0.748708, acc.: 53.91%] [G loss: 0.927920]\n",
      "epoch:6 step:6095 [D loss: 0.784390, acc.: 46.88%] [G loss: 0.957128]\n",
      "epoch:6 step:6096 [D loss: 0.736534, acc.: 42.97%] [G loss: 0.814153]\n",
      "epoch:6 step:6097 [D loss: 0.725464, acc.: 53.91%] [G loss: 0.882318]\n",
      "epoch:6 step:6098 [D loss: 0.656333, acc.: 64.06%] [G loss: 0.985653]\n",
      "epoch:6 step:6099 [D loss: 0.675510, acc.: 57.81%] [G loss: 0.877828]\n",
      "epoch:6 step:6100 [D loss: 0.742366, acc.: 53.12%] [G loss: 0.836049]\n",
      "epoch:6 step:6101 [D loss: 0.702691, acc.: 53.12%] [G loss: 0.903333]\n",
      "epoch:6 step:6102 [D loss: 0.671905, acc.: 57.03%] [G loss: 0.864075]\n",
      "epoch:6 step:6103 [D loss: 0.597987, acc.: 68.75%] [G loss: 0.911799]\n",
      "epoch:6 step:6104 [D loss: 0.691127, acc.: 57.81%] [G loss: 0.881178]\n",
      "epoch:6 step:6105 [D loss: 0.674915, acc.: 59.38%] [G loss: 0.928353]\n",
      "epoch:6 step:6106 [D loss: 0.701525, acc.: 57.81%] [G loss: 0.901275]\n",
      "epoch:6 step:6107 [D loss: 0.672242, acc.: 58.59%] [G loss: 0.974431]\n",
      "epoch:6 step:6108 [D loss: 0.680314, acc.: 53.91%] [G loss: 0.886241]\n",
      "epoch:6 step:6109 [D loss: 0.641324, acc.: 65.62%] [G loss: 0.931345]\n",
      "epoch:6 step:6110 [D loss: 0.624393, acc.: 66.41%] [G loss: 0.949439]\n",
      "epoch:6 step:6111 [D loss: 0.692090, acc.: 56.25%] [G loss: 0.956747]\n",
      "epoch:6 step:6112 [D loss: 0.656173, acc.: 64.84%] [G loss: 1.029962]\n",
      "epoch:6 step:6113 [D loss: 0.714926, acc.: 55.47%] [G loss: 0.871065]\n",
      "epoch:6 step:6114 [D loss: 0.643425, acc.: 64.06%] [G loss: 0.903865]\n",
      "epoch:6 step:6115 [D loss: 0.690266, acc.: 58.59%] [G loss: 0.891895]\n",
      "epoch:6 step:6116 [D loss: 0.666313, acc.: 57.03%] [G loss: 0.972646]\n",
      "epoch:6 step:6117 [D loss: 0.566954, acc.: 71.88%] [G loss: 0.989195]\n",
      "epoch:6 step:6118 [D loss: 0.694355, acc.: 56.25%] [G loss: 0.909271]\n",
      "epoch:6 step:6119 [D loss: 0.757602, acc.: 47.66%] [G loss: 0.914192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6120 [D loss: 0.603206, acc.: 67.97%] [G loss: 0.934456]\n",
      "epoch:6 step:6121 [D loss: 0.695848, acc.: 52.34%] [G loss: 0.946877]\n",
      "epoch:6 step:6122 [D loss: 0.719329, acc.: 57.81%] [G loss: 0.971298]\n",
      "epoch:6 step:6123 [D loss: 0.720517, acc.: 46.09%] [G loss: 0.900412]\n",
      "epoch:6 step:6124 [D loss: 0.671310, acc.: 56.25%] [G loss: 0.994178]\n",
      "epoch:6 step:6125 [D loss: 0.636361, acc.: 65.62%] [G loss: 0.949725]\n",
      "epoch:6 step:6126 [D loss: 0.593032, acc.: 67.97%] [G loss: 0.874634]\n",
      "epoch:6 step:6127 [D loss: 0.622532, acc.: 66.41%] [G loss: 1.014037]\n",
      "epoch:6 step:6128 [D loss: 0.681522, acc.: 56.25%] [G loss: 0.848480]\n",
      "epoch:6 step:6129 [D loss: 0.721506, acc.: 51.56%] [G loss: 0.911832]\n",
      "epoch:6 step:6130 [D loss: 0.642263, acc.: 59.38%] [G loss: 0.943546]\n",
      "epoch:6 step:6131 [D loss: 0.641799, acc.: 60.16%] [G loss: 1.012270]\n",
      "epoch:6 step:6132 [D loss: 0.693156, acc.: 53.91%] [G loss: 0.893490]\n",
      "epoch:6 step:6133 [D loss: 0.721152, acc.: 50.78%] [G loss: 0.921405]\n",
      "epoch:6 step:6134 [D loss: 0.727498, acc.: 55.47%] [G loss: 0.927132]\n",
      "epoch:6 step:6135 [D loss: 0.637838, acc.: 63.28%] [G loss: 0.988080]\n",
      "epoch:6 step:6136 [D loss: 0.729739, acc.: 50.78%] [G loss: 0.850444]\n",
      "epoch:6 step:6137 [D loss: 0.680110, acc.: 54.69%] [G loss: 0.864298]\n",
      "epoch:6 step:6138 [D loss: 0.672454, acc.: 54.69%] [G loss: 0.990735]\n",
      "epoch:6 step:6139 [D loss: 0.729260, acc.: 52.34%] [G loss: 0.846829]\n",
      "epoch:6 step:6140 [D loss: 0.681424, acc.: 57.03%] [G loss: 0.893207]\n",
      "epoch:6 step:6141 [D loss: 0.604298, acc.: 69.53%] [G loss: 0.929387]\n",
      "epoch:6 step:6142 [D loss: 0.700675, acc.: 53.12%] [G loss: 0.941395]\n",
      "epoch:6 step:6143 [D loss: 0.593773, acc.: 68.75%] [G loss: 1.148910]\n",
      "epoch:6 step:6144 [D loss: 0.588464, acc.: 67.97%] [G loss: 0.990649]\n",
      "epoch:6 step:6145 [D loss: 0.639194, acc.: 59.38%] [G loss: 1.006299]\n",
      "epoch:6 step:6146 [D loss: 0.657240, acc.: 61.72%] [G loss: 0.985447]\n",
      "epoch:6 step:6147 [D loss: 0.692608, acc.: 56.25%] [G loss: 0.926696]\n",
      "epoch:6 step:6148 [D loss: 0.656215, acc.: 64.06%] [G loss: 0.888520]\n",
      "epoch:6 step:6149 [D loss: 0.752837, acc.: 57.03%] [G loss: 0.873588]\n",
      "epoch:6 step:6150 [D loss: 0.714105, acc.: 47.66%] [G loss: 0.978706]\n",
      "epoch:6 step:6151 [D loss: 0.769267, acc.: 46.88%] [G loss: 0.807544]\n",
      "epoch:6 step:6152 [D loss: 0.621229, acc.: 65.62%] [G loss: 0.892595]\n",
      "epoch:6 step:6153 [D loss: 0.690997, acc.: 55.47%] [G loss: 0.990963]\n",
      "epoch:6 step:6154 [D loss: 0.648260, acc.: 58.59%] [G loss: 0.951887]\n",
      "epoch:6 step:6155 [D loss: 0.648819, acc.: 64.84%] [G loss: 0.946828]\n",
      "epoch:6 step:6156 [D loss: 0.683205, acc.: 57.03%] [G loss: 0.897580]\n",
      "epoch:6 step:6157 [D loss: 0.648413, acc.: 63.28%] [G loss: 0.895874]\n",
      "epoch:6 step:6158 [D loss: 0.652181, acc.: 63.28%] [G loss: 1.006305]\n",
      "epoch:6 step:6159 [D loss: 0.629391, acc.: 67.19%] [G loss: 1.114697]\n",
      "epoch:6 step:6160 [D loss: 0.680218, acc.: 57.81%] [G loss: 0.922440]\n",
      "epoch:6 step:6161 [D loss: 0.689250, acc.: 63.28%] [G loss: 0.855525]\n",
      "epoch:6 step:6162 [D loss: 0.687846, acc.: 58.59%] [G loss: 0.863606]\n",
      "epoch:6 step:6163 [D loss: 0.726593, acc.: 47.66%] [G loss: 0.853201]\n",
      "epoch:6 step:6164 [D loss: 0.698136, acc.: 57.03%] [G loss: 0.969419]\n",
      "epoch:6 step:6165 [D loss: 0.684621, acc.: 55.47%] [G loss: 0.991410]\n",
      "epoch:6 step:6166 [D loss: 0.735114, acc.: 49.22%] [G loss: 0.895777]\n",
      "epoch:6 step:6167 [D loss: 0.681747, acc.: 58.59%] [G loss: 0.802562]\n",
      "epoch:6 step:6168 [D loss: 0.614349, acc.: 65.62%] [G loss: 0.993173]\n",
      "epoch:6 step:6169 [D loss: 0.621112, acc.: 64.84%] [G loss: 1.054672]\n",
      "epoch:6 step:6170 [D loss: 0.639582, acc.: 64.84%] [G loss: 0.939075]\n",
      "epoch:6 step:6171 [D loss: 0.620316, acc.: 61.72%] [G loss: 0.931814]\n",
      "epoch:6 step:6172 [D loss: 0.610366, acc.: 64.06%] [G loss: 1.063599]\n",
      "epoch:6 step:6173 [D loss: 0.603781, acc.: 69.53%] [G loss: 1.066188]\n",
      "epoch:6 step:6174 [D loss: 0.618443, acc.: 63.28%] [G loss: 1.002940]\n",
      "epoch:6 step:6175 [D loss: 0.721211, acc.: 50.00%] [G loss: 0.881250]\n",
      "epoch:6 step:6176 [D loss: 0.576255, acc.: 76.56%] [G loss: 0.962089]\n",
      "epoch:6 step:6177 [D loss: 0.554149, acc.: 66.41%] [G loss: 0.986952]\n",
      "epoch:6 step:6178 [D loss: 0.629645, acc.: 61.72%] [G loss: 0.926321]\n",
      "epoch:6 step:6179 [D loss: 0.612986, acc.: 65.62%] [G loss: 0.929938]\n",
      "epoch:6 step:6180 [D loss: 0.624463, acc.: 67.97%] [G loss: 0.943459]\n",
      "epoch:6 step:6181 [D loss: 0.768225, acc.: 41.41%] [G loss: 1.002173]\n",
      "epoch:6 step:6182 [D loss: 0.652573, acc.: 63.28%] [G loss: 0.990792]\n",
      "epoch:6 step:6183 [D loss: 0.667958, acc.: 56.25%] [G loss: 0.958263]\n",
      "epoch:6 step:6184 [D loss: 0.660932, acc.: 57.81%] [G loss: 0.923498]\n",
      "epoch:6 step:6185 [D loss: 0.665557, acc.: 60.94%] [G loss: 1.003006]\n",
      "epoch:6 step:6186 [D loss: 0.618909, acc.: 67.19%] [G loss: 0.982223]\n",
      "epoch:6 step:6187 [D loss: 0.707035, acc.: 51.56%] [G loss: 0.909005]\n",
      "epoch:6 step:6188 [D loss: 0.720925, acc.: 51.56%] [G loss: 0.881232]\n",
      "epoch:6 step:6189 [D loss: 0.741084, acc.: 50.78%] [G loss: 0.834579]\n",
      "epoch:6 step:6190 [D loss: 0.623021, acc.: 67.19%] [G loss: 0.927241]\n",
      "epoch:6 step:6191 [D loss: 0.678286, acc.: 58.59%] [G loss: 0.929511]\n",
      "epoch:6 step:6192 [D loss: 0.687404, acc.: 62.50%] [G loss: 0.903264]\n",
      "epoch:6 step:6193 [D loss: 0.692362, acc.: 56.25%] [G loss: 0.904031]\n",
      "epoch:6 step:6194 [D loss: 0.738920, acc.: 52.34%] [G loss: 0.891687]\n",
      "epoch:6 step:6195 [D loss: 0.641777, acc.: 64.06%] [G loss: 0.921208]\n",
      "epoch:6 step:6196 [D loss: 0.653513, acc.: 60.16%] [G loss: 0.851077]\n",
      "epoch:6 step:6197 [D loss: 0.686823, acc.: 55.47%] [G loss: 0.837002]\n",
      "epoch:6 step:6198 [D loss: 0.687840, acc.: 55.47%] [G loss: 0.988646]\n",
      "epoch:6 step:6199 [D loss: 0.639703, acc.: 63.28%] [G loss: 0.896553]\n",
      "epoch:6 step:6200 [D loss: 0.654348, acc.: 59.38%] [G loss: 0.821584]\n",
      "##############\n",
      "[2.01313862 0.91599254 5.33445785 3.97487594 2.60607683 5.07831233\n",
      " 3.80957762 4.15755783 3.71198859 3.57331287]\n",
      "##########\n",
      "epoch:6 step:6201 [D loss: 0.748821, acc.: 48.44%] [G loss: 0.886865]\n",
      "epoch:6 step:6202 [D loss: 0.714859, acc.: 49.22%] [G loss: 0.910457]\n",
      "epoch:6 step:6203 [D loss: 0.626070, acc.: 68.75%] [G loss: 0.945674]\n",
      "epoch:6 step:6204 [D loss: 0.660642, acc.: 64.06%] [G loss: 0.887050]\n",
      "epoch:6 step:6205 [D loss: 0.673375, acc.: 60.94%] [G loss: 0.939653]\n",
      "epoch:6 step:6206 [D loss: 0.680362, acc.: 54.69%] [G loss: 0.942943]\n",
      "epoch:6 step:6207 [D loss: 0.629574, acc.: 64.06%] [G loss: 0.931939]\n",
      "epoch:6 step:6208 [D loss: 0.629753, acc.: 64.06%] [G loss: 0.937279]\n",
      "epoch:6 step:6209 [D loss: 0.655276, acc.: 61.72%] [G loss: 0.909045]\n",
      "epoch:6 step:6210 [D loss: 0.733580, acc.: 57.81%] [G loss: 0.854707]\n",
      "epoch:6 step:6211 [D loss: 0.649668, acc.: 60.94%] [G loss: 0.899678]\n",
      "epoch:6 step:6212 [D loss: 0.692599, acc.: 57.03%] [G loss: 0.977935]\n",
      "epoch:6 step:6213 [D loss: 0.615669, acc.: 67.19%] [G loss: 0.971528]\n",
      "epoch:6 step:6214 [D loss: 0.633963, acc.: 65.62%] [G loss: 0.987583]\n",
      "epoch:6 step:6215 [D loss: 0.577103, acc.: 71.88%] [G loss: 1.049371]\n",
      "epoch:6 step:6216 [D loss: 0.649445, acc.: 60.16%] [G loss: 1.022812]\n",
      "epoch:6 step:6217 [D loss: 0.659487, acc.: 60.16%] [G loss: 1.005633]\n",
      "epoch:6 step:6218 [D loss: 0.644706, acc.: 65.62%] [G loss: 0.883303]\n",
      "epoch:6 step:6219 [D loss: 0.680676, acc.: 57.81%] [G loss: 0.948572]\n",
      "epoch:6 step:6220 [D loss: 0.667036, acc.: 59.38%] [G loss: 1.061031]\n",
      "epoch:6 step:6221 [D loss: 0.708867, acc.: 52.34%] [G loss: 0.933559]\n",
      "epoch:6 step:6222 [D loss: 0.725754, acc.: 48.44%] [G loss: 0.895063]\n",
      "epoch:6 step:6223 [D loss: 0.660198, acc.: 55.47%] [G loss: 0.909188]\n",
      "epoch:6 step:6224 [D loss: 0.695247, acc.: 55.47%] [G loss: 0.891140]\n",
      "epoch:6 step:6225 [D loss: 0.638858, acc.: 66.41%] [G loss: 0.931567]\n",
      "epoch:6 step:6226 [D loss: 0.717971, acc.: 55.47%] [G loss: 0.967551]\n",
      "epoch:6 step:6227 [D loss: 0.616093, acc.: 67.97%] [G loss: 0.990784]\n",
      "epoch:6 step:6228 [D loss: 0.697539, acc.: 55.47%] [G loss: 1.023750]\n",
      "epoch:6 step:6229 [D loss: 0.597371, acc.: 70.31%] [G loss: 1.000519]\n",
      "epoch:6 step:6230 [D loss: 0.639840, acc.: 59.38%] [G loss: 1.027431]\n",
      "epoch:6 step:6231 [D loss: 0.664407, acc.: 60.16%] [G loss: 0.960531]\n",
      "epoch:6 step:6232 [D loss: 0.692740, acc.: 57.81%] [G loss: 1.001449]\n",
      "epoch:6 step:6233 [D loss: 0.640021, acc.: 60.94%] [G loss: 0.895246]\n",
      "epoch:6 step:6234 [D loss: 0.630153, acc.: 64.06%] [G loss: 0.969328]\n",
      "epoch:6 step:6235 [D loss: 0.689710, acc.: 55.47%] [G loss: 0.978917]\n",
      "epoch:6 step:6236 [D loss: 0.737389, acc.: 52.34%] [G loss: 0.951598]\n",
      "epoch:6 step:6237 [D loss: 0.739753, acc.: 50.78%] [G loss: 0.785585]\n",
      "epoch:6 step:6238 [D loss: 0.690132, acc.: 60.16%] [G loss: 0.940520]\n",
      "epoch:6 step:6239 [D loss: 0.729258, acc.: 53.12%] [G loss: 0.826764]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6240 [D loss: 0.656961, acc.: 58.59%] [G loss: 0.945606]\n",
      "epoch:6 step:6241 [D loss: 0.680168, acc.: 56.25%] [G loss: 0.876610]\n",
      "epoch:6 step:6242 [D loss: 0.644127, acc.: 66.41%] [G loss: 0.972269]\n",
      "epoch:6 step:6243 [D loss: 0.725242, acc.: 49.22%] [G loss: 0.840440]\n",
      "epoch:6 step:6244 [D loss: 0.681565, acc.: 60.94%] [G loss: 0.832033]\n",
      "epoch:6 step:6245 [D loss: 0.645498, acc.: 62.50%] [G loss: 1.072918]\n",
      "epoch:6 step:6246 [D loss: 0.655333, acc.: 66.41%] [G loss: 0.984306]\n",
      "epoch:6 step:6247 [D loss: 0.674386, acc.: 58.59%] [G loss: 0.951724]\n",
      "epoch:6 step:6248 [D loss: 0.640929, acc.: 61.72%] [G loss: 0.796494]\n",
      "epoch:6 step:6249 [D loss: 0.684451, acc.: 57.03%] [G loss: 0.937335]\n",
      "epoch:6 step:6250 [D loss: 0.672399, acc.: 57.03%] [G loss: 0.917865]\n",
      "epoch:6 step:6251 [D loss: 0.578844, acc.: 71.09%] [G loss: 0.923409]\n",
      "epoch:6 step:6252 [D loss: 0.687454, acc.: 62.50%] [G loss: 0.914648]\n",
      "epoch:6 step:6253 [D loss: 0.588664, acc.: 74.22%] [G loss: 1.015913]\n",
      "epoch:6 step:6254 [D loss: 0.656765, acc.: 58.59%] [G loss: 0.915587]\n",
      "epoch:6 step:6255 [D loss: 0.668891, acc.: 63.28%] [G loss: 0.927606]\n",
      "epoch:6 step:6256 [D loss: 0.635915, acc.: 62.50%] [G loss: 1.014150]\n",
      "epoch:6 step:6257 [D loss: 0.616547, acc.: 66.41%] [G loss: 0.967589]\n",
      "epoch:6 step:6258 [D loss: 0.667796, acc.: 57.81%] [G loss: 0.889658]\n",
      "epoch:6 step:6259 [D loss: 0.662129, acc.: 57.81%] [G loss: 1.008748]\n",
      "epoch:6 step:6260 [D loss: 0.693860, acc.: 57.03%] [G loss: 0.914689]\n",
      "epoch:6 step:6261 [D loss: 0.638485, acc.: 62.50%] [G loss: 0.971965]\n",
      "epoch:6 step:6262 [D loss: 0.661060, acc.: 63.28%] [G loss: 0.981872]\n",
      "epoch:6 step:6263 [D loss: 0.640019, acc.: 64.84%] [G loss: 1.027292]\n",
      "epoch:6 step:6264 [D loss: 0.763833, acc.: 50.78%] [G loss: 0.853834]\n",
      "epoch:6 step:6265 [D loss: 0.683343, acc.: 53.91%] [G loss: 0.888759]\n",
      "epoch:6 step:6266 [D loss: 0.635207, acc.: 65.62%] [G loss: 1.068716]\n",
      "epoch:6 step:6267 [D loss: 0.690745, acc.: 57.03%] [G loss: 0.985206]\n",
      "epoch:6 step:6268 [D loss: 0.650524, acc.: 61.72%] [G loss: 1.013456]\n",
      "epoch:6 step:6269 [D loss: 0.616118, acc.: 67.97%] [G loss: 1.015364]\n",
      "epoch:6 step:6270 [D loss: 0.568547, acc.: 71.88%] [G loss: 0.966558]\n",
      "epoch:6 step:6271 [D loss: 0.626792, acc.: 61.72%] [G loss: 0.950902]\n",
      "epoch:6 step:6272 [D loss: 0.637364, acc.: 64.84%] [G loss: 1.059732]\n",
      "epoch:6 step:6273 [D loss: 0.633814, acc.: 64.06%] [G loss: 0.930711]\n",
      "epoch:6 step:6274 [D loss: 0.714278, acc.: 54.69%] [G loss: 1.043838]\n",
      "epoch:6 step:6275 [D loss: 0.713003, acc.: 51.56%] [G loss: 0.895193]\n",
      "epoch:6 step:6276 [D loss: 0.683097, acc.: 60.16%] [G loss: 0.844382]\n",
      "epoch:6 step:6277 [D loss: 0.682814, acc.: 57.03%] [G loss: 0.898428]\n",
      "epoch:6 step:6278 [D loss: 0.691003, acc.: 63.28%] [G loss: 0.938755]\n",
      "epoch:6 step:6279 [D loss: 0.740800, acc.: 49.22%] [G loss: 0.901880]\n",
      "epoch:6 step:6280 [D loss: 0.723054, acc.: 54.69%] [G loss: 0.909850]\n",
      "epoch:6 step:6281 [D loss: 0.662192, acc.: 64.06%] [G loss: 0.920059]\n",
      "epoch:6 step:6282 [D loss: 0.570951, acc.: 76.56%] [G loss: 1.022396]\n",
      "epoch:6 step:6283 [D loss: 0.686676, acc.: 57.03%] [G loss: 0.949921]\n",
      "epoch:6 step:6284 [D loss: 0.656689, acc.: 60.94%] [G loss: 0.930102]\n",
      "epoch:6 step:6285 [D loss: 0.675221, acc.: 57.81%] [G loss: 0.916890]\n",
      "epoch:6 step:6286 [D loss: 0.684080, acc.: 52.34%] [G loss: 1.006867]\n",
      "epoch:6 step:6287 [D loss: 0.703232, acc.: 60.16%] [G loss: 0.970215]\n",
      "epoch:6 step:6288 [D loss: 0.731500, acc.: 54.69%] [G loss: 0.926005]\n",
      "epoch:6 step:6289 [D loss: 0.679057, acc.: 55.47%] [G loss: 0.883509]\n",
      "epoch:6 step:6290 [D loss: 0.659005, acc.: 67.97%] [G loss: 0.985636]\n",
      "epoch:6 step:6291 [D loss: 0.676077, acc.: 60.94%] [G loss: 0.898714]\n",
      "epoch:6 step:6292 [D loss: 0.684334, acc.: 59.38%] [G loss: 0.919854]\n",
      "epoch:6 step:6293 [D loss: 0.656771, acc.: 59.38%] [G loss: 0.890121]\n",
      "epoch:6 step:6294 [D loss: 0.633423, acc.: 60.94%] [G loss: 0.963379]\n",
      "epoch:6 step:6295 [D loss: 0.768053, acc.: 47.66%] [G loss: 0.813895]\n",
      "epoch:6 step:6296 [D loss: 0.679806, acc.: 62.50%] [G loss: 0.933581]\n",
      "epoch:6 step:6297 [D loss: 0.662842, acc.: 60.16%] [G loss: 0.927006]\n",
      "epoch:6 step:6298 [D loss: 0.644793, acc.: 60.94%] [G loss: 0.951989]\n",
      "epoch:6 step:6299 [D loss: 0.629352, acc.: 66.41%] [G loss: 0.906249]\n",
      "epoch:6 step:6300 [D loss: 0.658954, acc.: 58.59%] [G loss: 0.908752]\n",
      "epoch:6 step:6301 [D loss: 0.611319, acc.: 68.75%] [G loss: 1.049766]\n",
      "epoch:6 step:6302 [D loss: 0.650543, acc.: 64.06%] [G loss: 0.988866]\n",
      "epoch:6 step:6303 [D loss: 0.635727, acc.: 66.41%] [G loss: 1.012479]\n",
      "epoch:6 step:6304 [D loss: 0.610342, acc.: 67.97%] [G loss: 0.913759]\n",
      "epoch:6 step:6305 [D loss: 0.649106, acc.: 58.59%] [G loss: 0.940959]\n",
      "epoch:6 step:6306 [D loss: 0.675375, acc.: 61.72%] [G loss: 1.037143]\n",
      "epoch:6 step:6307 [D loss: 0.667931, acc.: 57.03%] [G loss: 0.974273]\n",
      "epoch:6 step:6308 [D loss: 0.727183, acc.: 49.22%] [G loss: 0.824902]\n",
      "epoch:6 step:6309 [D loss: 0.639944, acc.: 65.62%] [G loss: 0.967038]\n",
      "epoch:6 step:6310 [D loss: 0.609388, acc.: 67.19%] [G loss: 1.008258]\n",
      "epoch:6 step:6311 [D loss: 0.625177, acc.: 64.84%] [G loss: 0.907482]\n",
      "epoch:6 step:6312 [D loss: 0.622071, acc.: 61.72%] [G loss: 0.984939]\n",
      "epoch:6 step:6313 [D loss: 0.647124, acc.: 59.38%] [G loss: 0.900259]\n",
      "epoch:6 step:6314 [D loss: 0.723749, acc.: 49.22%] [G loss: 0.955672]\n",
      "epoch:6 step:6315 [D loss: 0.597052, acc.: 70.31%] [G loss: 1.016817]\n",
      "epoch:6 step:6316 [D loss: 0.618172, acc.: 61.72%] [G loss: 0.864380]\n",
      "epoch:6 step:6317 [D loss: 0.678809, acc.: 68.75%] [G loss: 0.995801]\n",
      "epoch:6 step:6318 [D loss: 0.726085, acc.: 50.00%] [G loss: 0.942095]\n",
      "epoch:6 step:6319 [D loss: 0.709608, acc.: 51.56%] [G loss: 0.879005]\n",
      "epoch:6 step:6320 [D loss: 0.717285, acc.: 55.47%] [G loss: 0.829926]\n",
      "epoch:6 step:6321 [D loss: 0.747731, acc.: 52.34%] [G loss: 0.768747]\n",
      "epoch:6 step:6322 [D loss: 0.696772, acc.: 57.03%] [G loss: 0.844119]\n",
      "epoch:6 step:6323 [D loss: 0.673378, acc.: 62.50%] [G loss: 0.820490]\n",
      "epoch:6 step:6324 [D loss: 0.708589, acc.: 56.25%] [G loss: 0.911923]\n",
      "epoch:6 step:6325 [D loss: 0.723801, acc.: 50.78%] [G loss: 0.892166]\n",
      "epoch:6 step:6326 [D loss: 0.671496, acc.: 57.03%] [G loss: 0.926115]\n",
      "epoch:6 step:6327 [D loss: 0.673718, acc.: 51.56%] [G loss: 0.962700]\n",
      "epoch:6 step:6328 [D loss: 0.668538, acc.: 60.16%] [G loss: 0.830487]\n",
      "epoch:6 step:6329 [D loss: 0.547633, acc.: 73.44%] [G loss: 0.929714]\n",
      "epoch:6 step:6330 [D loss: 0.636394, acc.: 65.62%] [G loss: 1.018322]\n",
      "epoch:6 step:6331 [D loss: 0.589146, acc.: 71.09%] [G loss: 0.939181]\n",
      "epoch:6 step:6332 [D loss: 0.657619, acc.: 58.59%] [G loss: 0.994806]\n",
      "epoch:6 step:6333 [D loss: 0.728745, acc.: 51.56%] [G loss: 0.896306]\n",
      "epoch:6 step:6334 [D loss: 0.700122, acc.: 53.91%] [G loss: 0.829864]\n",
      "epoch:6 step:6335 [D loss: 0.639563, acc.: 60.16%] [G loss: 0.895693]\n",
      "epoch:6 step:6336 [D loss: 0.686092, acc.: 56.25%] [G loss: 0.847962]\n",
      "epoch:6 step:6337 [D loss: 0.614480, acc.: 70.31%] [G loss: 1.019857]\n",
      "epoch:6 step:6338 [D loss: 0.694013, acc.: 54.69%] [G loss: 0.929577]\n",
      "epoch:6 step:6339 [D loss: 0.722635, acc.: 53.91%] [G loss: 0.829669]\n",
      "epoch:6 step:6340 [D loss: 0.761437, acc.: 44.53%] [G loss: 0.817730]\n",
      "epoch:6 step:6341 [D loss: 0.659119, acc.: 57.81%] [G loss: 0.901896]\n",
      "epoch:6 step:6342 [D loss: 0.828097, acc.: 35.94%] [G loss: 0.778953]\n",
      "epoch:6 step:6343 [D loss: 0.683051, acc.: 59.38%] [G loss: 0.853096]\n",
      "epoch:6 step:6344 [D loss: 0.707331, acc.: 51.56%] [G loss: 0.836916]\n",
      "epoch:6 step:6345 [D loss: 0.743607, acc.: 43.75%] [G loss: 0.866077]\n",
      "epoch:6 step:6346 [D loss: 0.744455, acc.: 46.09%] [G loss: 0.930548]\n",
      "epoch:6 step:6347 [D loss: 0.689809, acc.: 55.47%] [G loss: 0.947520]\n",
      "epoch:6 step:6348 [D loss: 0.675894, acc.: 59.38%] [G loss: 0.891947]\n",
      "epoch:6 step:6349 [D loss: 0.673591, acc.: 55.47%] [G loss: 0.909844]\n",
      "epoch:6 step:6350 [D loss: 0.641383, acc.: 64.06%] [G loss: 0.879916]\n",
      "epoch:6 step:6351 [D loss: 0.700196, acc.: 53.91%] [G loss: 0.890131]\n",
      "epoch:6 step:6352 [D loss: 0.637096, acc.: 65.62%] [G loss: 1.034455]\n",
      "epoch:6 step:6353 [D loss: 0.663242, acc.: 57.03%] [G loss: 0.869058]\n",
      "epoch:6 step:6354 [D loss: 0.623572, acc.: 63.28%] [G loss: 0.942526]\n",
      "epoch:6 step:6355 [D loss: 0.602538, acc.: 65.62%] [G loss: 0.995309]\n",
      "epoch:6 step:6356 [D loss: 0.685431, acc.: 64.84%] [G loss: 1.013606]\n",
      "epoch:6 step:6357 [D loss: 0.709697, acc.: 50.00%] [G loss: 0.848982]\n",
      "epoch:6 step:6358 [D loss: 0.658835, acc.: 60.16%] [G loss: 0.893434]\n",
      "epoch:6 step:6359 [D loss: 0.689607, acc.: 51.56%] [G loss: 0.907626]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6360 [D loss: 0.724932, acc.: 52.34%] [G loss: 0.919444]\n",
      "epoch:6 step:6361 [D loss: 0.721629, acc.: 56.25%] [G loss: 1.000536]\n",
      "epoch:6 step:6362 [D loss: 0.667644, acc.: 60.16%] [G loss: 0.884041]\n",
      "epoch:6 step:6363 [D loss: 0.679132, acc.: 59.38%] [G loss: 0.969288]\n",
      "epoch:6 step:6364 [D loss: 0.744458, acc.: 47.66%] [G loss: 0.888913]\n",
      "epoch:6 step:6365 [D loss: 0.729875, acc.: 51.56%] [G loss: 0.890108]\n",
      "epoch:6 step:6366 [D loss: 0.734461, acc.: 53.12%] [G loss: 0.814329]\n",
      "epoch:6 step:6367 [D loss: 0.710755, acc.: 52.34%] [G loss: 0.891823]\n",
      "epoch:6 step:6368 [D loss: 0.574977, acc.: 74.22%] [G loss: 1.041085]\n",
      "epoch:6 step:6369 [D loss: 0.631651, acc.: 64.84%] [G loss: 0.967253]\n",
      "epoch:6 step:6370 [D loss: 0.600806, acc.: 64.06%] [G loss: 1.137344]\n",
      "epoch:6 step:6371 [D loss: 0.672444, acc.: 57.03%] [G loss: 1.075667]\n",
      "epoch:6 step:6372 [D loss: 0.632419, acc.: 61.72%] [G loss: 0.957462]\n",
      "epoch:6 step:6373 [D loss: 0.613803, acc.: 64.06%] [G loss: 0.974037]\n",
      "epoch:6 step:6374 [D loss: 0.707267, acc.: 58.59%] [G loss: 1.005586]\n",
      "epoch:6 step:6375 [D loss: 0.674465, acc.: 61.72%] [G loss: 0.870011]\n",
      "epoch:6 step:6376 [D loss: 0.670845, acc.: 59.38%] [G loss: 0.994589]\n",
      "epoch:6 step:6377 [D loss: 0.682094, acc.: 56.25%] [G loss: 0.818169]\n",
      "epoch:6 step:6378 [D loss: 0.708732, acc.: 57.03%] [G loss: 0.901956]\n",
      "epoch:6 step:6379 [D loss: 0.693367, acc.: 53.91%] [G loss: 0.903656]\n",
      "epoch:6 step:6380 [D loss: 0.671484, acc.: 60.16%] [G loss: 0.924235]\n",
      "epoch:6 step:6381 [D loss: 0.716386, acc.: 57.81%] [G loss: 0.893879]\n",
      "epoch:6 step:6382 [D loss: 0.659582, acc.: 60.16%] [G loss: 1.020368]\n",
      "epoch:6 step:6383 [D loss: 0.679745, acc.: 53.91%] [G loss: 0.959118]\n",
      "epoch:6 step:6384 [D loss: 0.697746, acc.: 53.91%] [G loss: 0.905197]\n",
      "epoch:6 step:6385 [D loss: 0.667663, acc.: 64.84%] [G loss: 0.918418]\n",
      "epoch:6 step:6386 [D loss: 0.687500, acc.: 57.03%] [G loss: 0.882698]\n",
      "epoch:6 step:6387 [D loss: 0.699160, acc.: 57.81%] [G loss: 0.805812]\n",
      "epoch:6 step:6388 [D loss: 0.703619, acc.: 57.81%] [G loss: 0.910023]\n",
      "epoch:6 step:6389 [D loss: 0.649882, acc.: 60.16%] [G loss: 0.996587]\n",
      "epoch:6 step:6390 [D loss: 0.671649, acc.: 62.50%] [G loss: 0.968003]\n",
      "epoch:6 step:6391 [D loss: 0.703827, acc.: 53.91%] [G loss: 0.865098]\n",
      "epoch:6 step:6392 [D loss: 0.701766, acc.: 55.47%] [G loss: 0.924812]\n",
      "epoch:6 step:6393 [D loss: 0.695711, acc.: 56.25%] [G loss: 0.790399]\n",
      "epoch:6 step:6394 [D loss: 0.671883, acc.: 58.59%] [G loss: 0.973706]\n",
      "epoch:6 step:6395 [D loss: 0.696830, acc.: 51.56%] [G loss: 0.915281]\n",
      "epoch:6 step:6396 [D loss: 0.704249, acc.: 53.12%] [G loss: 0.854998]\n",
      "epoch:6 step:6397 [D loss: 0.676016, acc.: 59.38%] [G loss: 0.863348]\n",
      "epoch:6 step:6398 [D loss: 0.635980, acc.: 62.50%] [G loss: 0.984814]\n",
      "epoch:6 step:6399 [D loss: 0.711880, acc.: 53.91%] [G loss: 0.907219]\n",
      "epoch:6 step:6400 [D loss: 0.693589, acc.: 57.03%] [G loss: 0.919209]\n",
      "##############\n",
      "[1.93110246 1.15596758 4.85630777 4.05609012 2.51606407 5.09184522\n",
      " 3.71544259 4.16122059 3.5264203  3.36590035]\n",
      "##########\n",
      "epoch:6 step:6401 [D loss: 0.727765, acc.: 48.44%] [G loss: 0.885296]\n",
      "epoch:6 step:6402 [D loss: 0.723909, acc.: 53.91%] [G loss: 0.931596]\n",
      "epoch:6 step:6403 [D loss: 0.635906, acc.: 67.19%] [G loss: 0.864169]\n",
      "epoch:6 step:6404 [D loss: 0.639907, acc.: 60.16%] [G loss: 0.965650]\n",
      "epoch:6 step:6405 [D loss: 0.668976, acc.: 57.03%] [G loss: 0.943638]\n",
      "epoch:6 step:6406 [D loss: 0.680335, acc.: 56.25%] [G loss: 0.903464]\n",
      "epoch:6 step:6407 [D loss: 0.679630, acc.: 54.69%] [G loss: 0.874269]\n",
      "epoch:6 step:6408 [D loss: 0.598370, acc.: 70.31%] [G loss: 0.923488]\n",
      "epoch:6 step:6409 [D loss: 0.710347, acc.: 55.47%] [G loss: 0.929773]\n",
      "epoch:6 step:6410 [D loss: 0.729949, acc.: 49.22%] [G loss: 0.783736]\n",
      "epoch:6 step:6411 [D loss: 0.691623, acc.: 56.25%] [G loss: 0.816229]\n",
      "epoch:6 step:6412 [D loss: 0.652085, acc.: 62.50%] [G loss: 0.878495]\n",
      "epoch:6 step:6413 [D loss: 0.583859, acc.: 73.44%] [G loss: 1.027878]\n",
      "epoch:6 step:6414 [D loss: 0.528223, acc.: 79.69%] [G loss: 1.003910]\n",
      "epoch:6 step:6415 [D loss: 0.655725, acc.: 61.72%] [G loss: 1.023801]\n",
      "epoch:6 step:6416 [D loss: 0.756584, acc.: 50.78%] [G loss: 0.766267]\n",
      "epoch:6 step:6417 [D loss: 0.619193, acc.: 66.41%] [G loss: 0.967406]\n",
      "epoch:6 step:6418 [D loss: 0.629041, acc.: 66.41%] [G loss: 0.900571]\n",
      "epoch:6 step:6419 [D loss: 0.647049, acc.: 67.97%] [G loss: 0.925103]\n",
      "epoch:6 step:6420 [D loss: 0.589436, acc.: 71.88%] [G loss: 0.955110]\n",
      "epoch:6 step:6421 [D loss: 0.610350, acc.: 71.09%] [G loss: 0.938676]\n",
      "epoch:6 step:6422 [D loss: 0.770820, acc.: 46.09%] [G loss: 0.940427]\n",
      "epoch:6 step:6423 [D loss: 0.747548, acc.: 47.66%] [G loss: 0.909081]\n",
      "epoch:6 step:6424 [D loss: 0.698937, acc.: 47.66%] [G loss: 0.911642]\n",
      "epoch:6 step:6425 [D loss: 0.645587, acc.: 62.50%] [G loss: 0.928145]\n",
      "epoch:6 step:6426 [D loss: 0.625936, acc.: 62.50%] [G loss: 0.959759]\n",
      "epoch:6 step:6427 [D loss: 0.642254, acc.: 58.59%] [G loss: 0.966507]\n",
      "epoch:6 step:6428 [D loss: 0.602885, acc.: 71.09%] [G loss: 0.924525]\n",
      "epoch:6 step:6429 [D loss: 0.622971, acc.: 64.84%] [G loss: 0.997540]\n",
      "epoch:6 step:6430 [D loss: 0.694599, acc.: 53.91%] [G loss: 1.109871]\n",
      "epoch:6 step:6431 [D loss: 0.619264, acc.: 69.53%] [G loss: 0.985916]\n",
      "epoch:6 step:6432 [D loss: 0.717226, acc.: 52.34%] [G loss: 0.946707]\n",
      "epoch:6 step:6433 [D loss: 0.702710, acc.: 52.34%] [G loss: 0.917065]\n",
      "epoch:6 step:6434 [D loss: 0.719131, acc.: 54.69%] [G loss: 0.875904]\n",
      "epoch:6 step:6435 [D loss: 0.692494, acc.: 51.56%] [G loss: 0.926498]\n",
      "epoch:6 step:6436 [D loss: 0.730837, acc.: 49.22%] [G loss: 0.895993]\n",
      "epoch:6 step:6437 [D loss: 0.652148, acc.: 63.28%] [G loss: 0.902196]\n",
      "epoch:6 step:6438 [D loss: 0.729290, acc.: 52.34%] [G loss: 0.842991]\n",
      "epoch:6 step:6439 [D loss: 0.680862, acc.: 54.69%] [G loss: 0.987636]\n",
      "epoch:6 step:6440 [D loss: 0.663795, acc.: 60.16%] [G loss: 0.858341]\n",
      "epoch:6 step:6441 [D loss: 0.595876, acc.: 69.53%] [G loss: 0.971955]\n",
      "epoch:6 step:6442 [D loss: 0.654040, acc.: 60.94%] [G loss: 0.980633]\n",
      "epoch:6 step:6443 [D loss: 0.725654, acc.: 52.34%] [G loss: 0.869828]\n",
      "epoch:6 step:6444 [D loss: 0.609288, acc.: 67.19%] [G loss: 0.921181]\n",
      "epoch:6 step:6445 [D loss: 0.658750, acc.: 60.94%] [G loss: 0.885758]\n",
      "epoch:6 step:6446 [D loss: 0.730436, acc.: 53.12%] [G loss: 0.884107]\n",
      "epoch:6 step:6447 [D loss: 0.646383, acc.: 59.38%] [G loss: 0.903569]\n",
      "epoch:6 step:6448 [D loss: 0.689975, acc.: 56.25%] [G loss: 0.984880]\n",
      "epoch:6 step:6449 [D loss: 0.711589, acc.: 53.91%] [G loss: 0.954683]\n",
      "epoch:6 step:6450 [D loss: 0.656323, acc.: 60.16%] [G loss: 0.838461]\n",
      "epoch:6 step:6451 [D loss: 0.739939, acc.: 52.34%] [G loss: 0.933016]\n",
      "epoch:6 step:6452 [D loss: 0.592975, acc.: 70.31%] [G loss: 0.917816]\n",
      "epoch:6 step:6453 [D loss: 0.625505, acc.: 65.62%] [G loss: 0.991997]\n",
      "epoch:6 step:6454 [D loss: 0.612150, acc.: 68.75%] [G loss: 1.011747]\n",
      "epoch:6 step:6455 [D loss: 0.642491, acc.: 65.62%] [G loss: 0.854998]\n",
      "epoch:6 step:6456 [D loss: 0.658802, acc.: 57.81%] [G loss: 1.118008]\n",
      "epoch:6 step:6457 [D loss: 0.636438, acc.: 57.81%] [G loss: 1.001340]\n",
      "epoch:6 step:6458 [D loss: 0.705277, acc.: 57.81%] [G loss: 0.883956]\n",
      "epoch:6 step:6459 [D loss: 0.647982, acc.: 63.28%] [G loss: 0.996264]\n",
      "epoch:6 step:6460 [D loss: 0.619917, acc.: 64.06%] [G loss: 1.017244]\n",
      "epoch:6 step:6461 [D loss: 0.665210, acc.: 60.16%] [G loss: 0.944113]\n",
      "epoch:6 step:6462 [D loss: 0.674923, acc.: 58.59%] [G loss: 1.100769]\n",
      "epoch:6 step:6463 [D loss: 0.596457, acc.: 71.88%] [G loss: 0.821869]\n",
      "epoch:6 step:6464 [D loss: 0.585888, acc.: 70.31%] [G loss: 0.877612]\n",
      "epoch:6 step:6465 [D loss: 0.698535, acc.: 51.56%] [G loss: 1.041812]\n",
      "epoch:6 step:6466 [D loss: 0.662181, acc.: 61.72%] [G loss: 0.906313]\n",
      "epoch:6 step:6467 [D loss: 0.592629, acc.: 67.97%] [G loss: 0.969110]\n",
      "epoch:6 step:6468 [D loss: 0.666069, acc.: 59.38%] [G loss: 0.963458]\n",
      "epoch:6 step:6469 [D loss: 0.682953, acc.: 57.03%] [G loss: 0.827953]\n",
      "epoch:6 step:6470 [D loss: 0.602905, acc.: 68.75%] [G loss: 0.853608]\n",
      "epoch:6 step:6471 [D loss: 0.661346, acc.: 63.28%] [G loss: 0.854367]\n",
      "epoch:6 step:6472 [D loss: 0.707732, acc.: 57.81%] [G loss: 0.871589]\n",
      "epoch:6 step:6473 [D loss: 0.637841, acc.: 64.84%] [G loss: 0.788340]\n",
      "epoch:6 step:6474 [D loss: 0.682679, acc.: 58.59%] [G loss: 0.972457]\n",
      "epoch:6 step:6475 [D loss: 0.690771, acc.: 55.47%] [G loss: 0.855072]\n",
      "epoch:6 step:6476 [D loss: 0.638019, acc.: 63.28%] [G loss: 1.000744]\n",
      "epoch:6 step:6477 [D loss: 0.621827, acc.: 65.62%] [G loss: 1.024067]\n",
      "epoch:6 step:6478 [D loss: 0.659317, acc.: 59.38%] [G loss: 0.896376]\n",
      "epoch:6 step:6479 [D loss: 0.653939, acc.: 60.16%] [G loss: 0.959555]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6480 [D loss: 0.780316, acc.: 48.44%] [G loss: 0.913162]\n",
      "epoch:6 step:6481 [D loss: 0.747905, acc.: 49.22%] [G loss: 0.854611]\n",
      "epoch:6 step:6482 [D loss: 0.668212, acc.: 58.59%] [G loss: 0.872927]\n",
      "epoch:6 step:6483 [D loss: 0.636275, acc.: 60.94%] [G loss: 0.968786]\n",
      "epoch:6 step:6484 [D loss: 0.731139, acc.: 50.00%] [G loss: 0.796295]\n",
      "epoch:6 step:6485 [D loss: 0.596175, acc.: 71.09%] [G loss: 0.860371]\n",
      "epoch:6 step:6486 [D loss: 0.693986, acc.: 59.38%] [G loss: 0.920672]\n",
      "epoch:6 step:6487 [D loss: 0.717402, acc.: 48.44%] [G loss: 0.938369]\n",
      "epoch:6 step:6488 [D loss: 0.700847, acc.: 53.12%] [G loss: 0.809051]\n",
      "epoch:6 step:6489 [D loss: 0.739560, acc.: 46.88%] [G loss: 0.986277]\n",
      "epoch:6 step:6490 [D loss: 0.660262, acc.: 58.59%] [G loss: 0.900354]\n",
      "epoch:6 step:6491 [D loss: 0.703843, acc.: 51.56%] [G loss: 0.858440]\n",
      "epoch:6 step:6492 [D loss: 0.714840, acc.: 53.12%] [G loss: 0.877494]\n",
      "epoch:6 step:6493 [D loss: 0.685407, acc.: 54.69%] [G loss: 0.898147]\n",
      "epoch:6 step:6494 [D loss: 0.670059, acc.: 60.94%] [G loss: 0.932600]\n",
      "epoch:6 step:6495 [D loss: 0.651173, acc.: 60.94%] [G loss: 0.881365]\n",
      "epoch:6 step:6496 [D loss: 0.689916, acc.: 56.25%] [G loss: 0.881886]\n",
      "epoch:6 step:6497 [D loss: 0.680633, acc.: 57.03%] [G loss: 0.873181]\n",
      "epoch:6 step:6498 [D loss: 0.648668, acc.: 56.25%] [G loss: 0.997437]\n",
      "epoch:6 step:6499 [D loss: 0.642346, acc.: 61.72%] [G loss: 0.911041]\n",
      "epoch:6 step:6500 [D loss: 0.734039, acc.: 46.88%] [G loss: 0.926321]\n",
      "epoch:6 step:6501 [D loss: 0.703124, acc.: 47.66%] [G loss: 0.934392]\n",
      "epoch:6 step:6502 [D loss: 0.685913, acc.: 54.69%] [G loss: 0.948576]\n",
      "epoch:6 step:6503 [D loss: 0.624638, acc.: 66.41%] [G loss: 0.984992]\n",
      "epoch:6 step:6504 [D loss: 0.641145, acc.: 62.50%] [G loss: 0.955542]\n",
      "epoch:6 step:6505 [D loss: 0.712335, acc.: 57.81%] [G loss: 0.946576]\n",
      "epoch:6 step:6506 [D loss: 0.654263, acc.: 63.28%] [G loss: 0.953078]\n",
      "epoch:6 step:6507 [D loss: 0.644894, acc.: 65.62%] [G loss: 0.804261]\n",
      "epoch:6 step:6508 [D loss: 0.696625, acc.: 55.47%] [G loss: 0.925313]\n",
      "epoch:6 step:6509 [D loss: 0.656236, acc.: 59.38%] [G loss: 0.890625]\n",
      "epoch:6 step:6510 [D loss: 0.584267, acc.: 70.31%] [G loss: 1.021996]\n",
      "epoch:6 step:6511 [D loss: 0.621530, acc.: 63.28%] [G loss: 0.971497]\n",
      "epoch:6 step:6512 [D loss: 0.599876, acc.: 67.97%] [G loss: 0.999681]\n",
      "epoch:6 step:6513 [D loss: 0.785632, acc.: 48.44%] [G loss: 0.865803]\n",
      "epoch:6 step:6514 [D loss: 0.799906, acc.: 45.31%] [G loss: 0.883654]\n",
      "epoch:6 step:6515 [D loss: 0.765955, acc.: 46.09%] [G loss: 0.906417]\n",
      "epoch:6 step:6516 [D loss: 0.692305, acc.: 57.03%] [G loss: 0.917525]\n",
      "epoch:6 step:6517 [D loss: 0.695716, acc.: 53.91%] [G loss: 0.993977]\n",
      "epoch:6 step:6518 [D loss: 0.682038, acc.: 57.03%] [G loss: 1.009259]\n",
      "epoch:6 step:6519 [D loss: 0.706491, acc.: 53.91%] [G loss: 0.891527]\n",
      "epoch:6 step:6520 [D loss: 0.668658, acc.: 63.28%] [G loss: 0.824816]\n",
      "epoch:6 step:6521 [D loss: 0.644916, acc.: 66.41%] [G loss: 0.893560]\n",
      "epoch:6 step:6522 [D loss: 0.717742, acc.: 57.03%] [G loss: 1.035443]\n",
      "epoch:6 step:6523 [D loss: 0.714122, acc.: 51.56%] [G loss: 1.019807]\n",
      "epoch:6 step:6524 [D loss: 0.721043, acc.: 57.81%] [G loss: 1.045714]\n",
      "epoch:6 step:6525 [D loss: 0.714284, acc.: 49.22%] [G loss: 0.920865]\n",
      "epoch:6 step:6526 [D loss: 0.639988, acc.: 62.50%] [G loss: 0.838233]\n",
      "epoch:6 step:6527 [D loss: 0.681671, acc.: 55.47%] [G loss: 0.770938]\n",
      "epoch:6 step:6528 [D loss: 0.706288, acc.: 57.03%] [G loss: 0.860090]\n",
      "epoch:6 step:6529 [D loss: 0.539555, acc.: 82.03%] [G loss: 1.031529]\n",
      "epoch:6 step:6530 [D loss: 0.733260, acc.: 53.91%] [G loss: 0.879997]\n",
      "epoch:6 step:6531 [D loss: 0.679144, acc.: 55.47%] [G loss: 0.997367]\n",
      "epoch:6 step:6532 [D loss: 0.563435, acc.: 78.12%] [G loss: 1.072988]\n",
      "epoch:6 step:6533 [D loss: 0.646828, acc.: 60.94%] [G loss: 0.898729]\n",
      "epoch:6 step:6534 [D loss: 0.552943, acc.: 71.88%] [G loss: 1.081821]\n",
      "epoch:6 step:6535 [D loss: 0.672014, acc.: 60.94%] [G loss: 1.063811]\n",
      "epoch:6 step:6536 [D loss: 0.622408, acc.: 64.06%] [G loss: 1.024323]\n",
      "epoch:6 step:6537 [D loss: 0.694756, acc.: 61.72%] [G loss: 0.904653]\n",
      "epoch:6 step:6538 [D loss: 0.722243, acc.: 50.78%] [G loss: 0.779342]\n",
      "epoch:6 step:6539 [D loss: 0.677046, acc.: 60.16%] [G loss: 0.794471]\n",
      "epoch:6 step:6540 [D loss: 0.532485, acc.: 79.69%] [G loss: 0.896792]\n",
      "epoch:6 step:6541 [D loss: 0.576207, acc.: 72.66%] [G loss: 0.973272]\n",
      "epoch:6 step:6542 [D loss: 0.772922, acc.: 45.31%] [G loss: 0.980908]\n",
      "epoch:6 step:6543 [D loss: 0.605683, acc.: 65.62%] [G loss: 0.942234]\n",
      "epoch:6 step:6544 [D loss: 0.540903, acc.: 74.22%] [G loss: 0.932154]\n",
      "epoch:6 step:6545 [D loss: 0.602923, acc.: 67.97%] [G loss: 0.981429]\n",
      "epoch:6 step:6546 [D loss: 0.569284, acc.: 75.78%] [G loss: 0.922809]\n",
      "epoch:6 step:6547 [D loss: 0.590496, acc.: 70.31%] [G loss: 1.011354]\n",
      "epoch:6 step:6548 [D loss: 0.537563, acc.: 73.44%] [G loss: 1.016248]\n",
      "epoch:6 step:6549 [D loss: 0.583413, acc.: 71.09%] [G loss: 1.075576]\n",
      "epoch:6 step:6550 [D loss: 0.741208, acc.: 49.22%] [G loss: 0.991617]\n",
      "epoch:6 step:6551 [D loss: 0.758129, acc.: 43.75%] [G loss: 0.921768]\n",
      "epoch:6 step:6552 [D loss: 0.592093, acc.: 68.75%] [G loss: 1.021302]\n",
      "epoch:6 step:6553 [D loss: 0.621008, acc.: 66.41%] [G loss: 0.937698]\n",
      "epoch:6 step:6554 [D loss: 0.657894, acc.: 59.38%] [G loss: 1.020616]\n",
      "epoch:6 step:6555 [D loss: 0.666407, acc.: 59.38%] [G loss: 0.967638]\n",
      "epoch:6 step:6556 [D loss: 0.566825, acc.: 71.09%] [G loss: 1.020857]\n",
      "epoch:6 step:6557 [D loss: 0.659062, acc.: 63.28%] [G loss: 0.907004]\n",
      "epoch:6 step:6558 [D loss: 0.518240, acc.: 79.69%] [G loss: 1.021736]\n",
      "epoch:6 step:6559 [D loss: 0.498164, acc.: 82.03%] [G loss: 0.980206]\n",
      "epoch:7 step:6560 [D loss: 0.622244, acc.: 64.06%] [G loss: 1.096884]\n",
      "epoch:7 step:6561 [D loss: 0.709534, acc.: 57.03%] [G loss: 0.952660]\n",
      "epoch:7 step:6562 [D loss: 0.646791, acc.: 63.28%] [G loss: 1.004153]\n",
      "epoch:7 step:6563 [D loss: 0.667393, acc.: 62.50%] [G loss: 0.991597]\n",
      "epoch:7 step:6564 [D loss: 0.667990, acc.: 64.06%] [G loss: 0.910857]\n",
      "epoch:7 step:6565 [D loss: 0.671708, acc.: 57.81%] [G loss: 0.861536]\n",
      "epoch:7 step:6566 [D loss: 0.677038, acc.: 57.03%] [G loss: 0.989097]\n",
      "epoch:7 step:6567 [D loss: 0.708117, acc.: 56.25%] [G loss: 0.903639]\n",
      "epoch:7 step:6568 [D loss: 0.613730, acc.: 64.06%] [G loss: 1.044107]\n",
      "epoch:7 step:6569 [D loss: 0.663307, acc.: 66.41%] [G loss: 0.926785]\n",
      "epoch:7 step:6570 [D loss: 0.614701, acc.: 68.75%] [G loss: 1.101232]\n",
      "epoch:7 step:6571 [D loss: 0.751220, acc.: 54.69%] [G loss: 0.907834]\n",
      "epoch:7 step:6572 [D loss: 0.622311, acc.: 59.38%] [G loss: 1.042529]\n",
      "epoch:7 step:6573 [D loss: 0.677159, acc.: 57.03%] [G loss: 0.984454]\n",
      "epoch:7 step:6574 [D loss: 0.598735, acc.: 67.97%] [G loss: 0.995576]\n",
      "epoch:7 step:6575 [D loss: 0.609422, acc.: 64.84%] [G loss: 1.052712]\n",
      "epoch:7 step:6576 [D loss: 0.656790, acc.: 65.62%] [G loss: 1.015071]\n",
      "epoch:7 step:6577 [D loss: 0.722329, acc.: 52.34%] [G loss: 0.938272]\n",
      "epoch:7 step:6578 [D loss: 0.712501, acc.: 52.34%] [G loss: 0.903764]\n",
      "epoch:7 step:6579 [D loss: 0.916936, acc.: 32.03%] [G loss: 0.875863]\n",
      "epoch:7 step:6580 [D loss: 0.733037, acc.: 55.47%] [G loss: 0.866010]\n",
      "epoch:7 step:6581 [D loss: 0.725816, acc.: 50.00%] [G loss: 0.867170]\n",
      "epoch:7 step:6582 [D loss: 0.666996, acc.: 57.03%] [G loss: 0.911060]\n",
      "epoch:7 step:6583 [D loss: 0.688099, acc.: 56.25%] [G loss: 0.832443]\n",
      "epoch:7 step:6584 [D loss: 0.578979, acc.: 73.44%] [G loss: 1.018032]\n",
      "epoch:7 step:6585 [D loss: 0.674125, acc.: 57.81%] [G loss: 0.965955]\n",
      "epoch:7 step:6586 [D loss: 0.716095, acc.: 53.12%] [G loss: 0.897494]\n",
      "epoch:7 step:6587 [D loss: 0.670722, acc.: 61.72%] [G loss: 1.074535]\n",
      "epoch:7 step:6588 [D loss: 0.589099, acc.: 70.31%] [G loss: 0.929845]\n",
      "epoch:7 step:6589 [D loss: 0.632465, acc.: 64.84%] [G loss: 1.070514]\n",
      "epoch:7 step:6590 [D loss: 0.747004, acc.: 46.88%] [G loss: 0.858055]\n",
      "epoch:7 step:6591 [D loss: 0.772713, acc.: 41.41%] [G loss: 0.772151]\n",
      "epoch:7 step:6592 [D loss: 0.657317, acc.: 57.81%] [G loss: 0.877662]\n",
      "epoch:7 step:6593 [D loss: 0.660295, acc.: 58.59%] [G loss: 0.977055]\n",
      "epoch:7 step:6594 [D loss: 0.653859, acc.: 59.38%] [G loss: 0.906281]\n",
      "epoch:7 step:6595 [D loss: 0.642408, acc.: 61.72%] [G loss: 0.982657]\n",
      "epoch:7 step:6596 [D loss: 0.630690, acc.: 66.41%] [G loss: 1.012709]\n",
      "epoch:7 step:6597 [D loss: 0.663498, acc.: 63.28%] [G loss: 0.871505]\n",
      "epoch:7 step:6598 [D loss: 0.617915, acc.: 69.53%] [G loss: 0.994372]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6599 [D loss: 0.648231, acc.: 61.72%] [G loss: 0.920689]\n",
      "epoch:7 step:6600 [D loss: 0.615508, acc.: 67.19%] [G loss: 0.970075]\n",
      "##############\n",
      "[2.03865414 1.27426732 5.24439735 3.95299456 2.88503452 5.141352\n",
      " 4.00710194 4.60395019 3.52662039 3.31429983]\n",
      "##########\n",
      "epoch:7 step:6601 [D loss: 0.654864, acc.: 62.50%] [G loss: 0.899140]\n",
      "epoch:7 step:6602 [D loss: 0.639795, acc.: 62.50%] [G loss: 1.026122]\n",
      "epoch:7 step:6603 [D loss: 0.652134, acc.: 59.38%] [G loss: 0.979772]\n",
      "epoch:7 step:6604 [D loss: 0.689420, acc.: 60.16%] [G loss: 0.955175]\n",
      "epoch:7 step:6605 [D loss: 0.700122, acc.: 55.47%] [G loss: 0.879711]\n",
      "epoch:7 step:6606 [D loss: 0.594384, acc.: 70.31%] [G loss: 0.954907]\n",
      "epoch:7 step:6607 [D loss: 0.689190, acc.: 53.91%] [G loss: 0.882002]\n",
      "epoch:7 step:6608 [D loss: 0.669570, acc.: 53.91%] [G loss: 0.908716]\n",
      "epoch:7 step:6609 [D loss: 0.639114, acc.: 63.28%] [G loss: 0.960563]\n",
      "epoch:7 step:6610 [D loss: 0.674163, acc.: 60.16%] [G loss: 0.877604]\n",
      "epoch:7 step:6611 [D loss: 0.596591, acc.: 65.62%] [G loss: 0.969600]\n",
      "epoch:7 step:6612 [D loss: 0.658513, acc.: 59.38%] [G loss: 0.858307]\n",
      "epoch:7 step:6613 [D loss: 0.598040, acc.: 66.41%] [G loss: 1.016762]\n",
      "epoch:7 step:6614 [D loss: 0.607024, acc.: 69.53%] [G loss: 0.994475]\n",
      "epoch:7 step:6615 [D loss: 0.611917, acc.: 67.19%] [G loss: 1.110988]\n",
      "epoch:7 step:6616 [D loss: 0.664585, acc.: 57.03%] [G loss: 1.046784]\n",
      "epoch:7 step:6617 [D loss: 0.689605, acc.: 59.38%] [G loss: 1.043624]\n",
      "epoch:7 step:6618 [D loss: 0.742282, acc.: 50.00%] [G loss: 0.840791]\n",
      "epoch:7 step:6619 [D loss: 0.711485, acc.: 56.25%] [G loss: 1.006613]\n",
      "epoch:7 step:6620 [D loss: 0.624151, acc.: 64.06%] [G loss: 0.877949]\n",
      "epoch:7 step:6621 [D loss: 0.675749, acc.: 56.25%] [G loss: 0.905803]\n",
      "epoch:7 step:6622 [D loss: 0.648980, acc.: 66.41%] [G loss: 0.923830]\n",
      "epoch:7 step:6623 [D loss: 0.675835, acc.: 60.16%] [G loss: 0.958910]\n",
      "epoch:7 step:6624 [D loss: 0.625965, acc.: 64.84%] [G loss: 1.012105]\n",
      "epoch:7 step:6625 [D loss: 0.718591, acc.: 48.44%] [G loss: 0.837670]\n",
      "epoch:7 step:6626 [D loss: 0.638323, acc.: 67.19%] [G loss: 0.875562]\n",
      "epoch:7 step:6627 [D loss: 0.700264, acc.: 55.47%] [G loss: 0.934931]\n",
      "epoch:7 step:6628 [D loss: 0.665983, acc.: 61.72%] [G loss: 0.967298]\n",
      "epoch:7 step:6629 [D loss: 0.694141, acc.: 53.12%] [G loss: 0.962982]\n",
      "epoch:7 step:6630 [D loss: 0.652290, acc.: 64.06%] [G loss: 0.968648]\n",
      "epoch:7 step:6631 [D loss: 0.636265, acc.: 59.38%] [G loss: 1.001731]\n",
      "epoch:7 step:6632 [D loss: 0.700146, acc.: 53.12%] [G loss: 0.959997]\n",
      "epoch:7 step:6633 [D loss: 0.655057, acc.: 62.50%] [G loss: 1.039356]\n",
      "epoch:7 step:6634 [D loss: 0.552127, acc.: 71.88%] [G loss: 0.934251]\n",
      "epoch:7 step:6635 [D loss: 0.610236, acc.: 65.62%] [G loss: 0.920231]\n",
      "epoch:7 step:6636 [D loss: 0.607709, acc.: 65.62%] [G loss: 0.977677]\n",
      "epoch:7 step:6637 [D loss: 0.693823, acc.: 56.25%] [G loss: 0.973766]\n",
      "epoch:7 step:6638 [D loss: 0.725286, acc.: 57.03%] [G loss: 1.058226]\n",
      "epoch:7 step:6639 [D loss: 0.666730, acc.: 59.38%] [G loss: 0.914690]\n",
      "epoch:7 step:6640 [D loss: 0.716520, acc.: 60.16%] [G loss: 0.866632]\n",
      "epoch:7 step:6641 [D loss: 0.699351, acc.: 50.00%] [G loss: 0.878956]\n",
      "epoch:7 step:6642 [D loss: 0.674229, acc.: 57.03%] [G loss: 0.925135]\n",
      "epoch:7 step:6643 [D loss: 0.703219, acc.: 52.34%] [G loss: 0.782959]\n",
      "epoch:7 step:6644 [D loss: 0.672909, acc.: 61.72%] [G loss: 0.874384]\n",
      "epoch:7 step:6645 [D loss: 0.629953, acc.: 64.06%] [G loss: 0.960507]\n",
      "epoch:7 step:6646 [D loss: 0.672438, acc.: 59.38%] [G loss: 0.891298]\n",
      "epoch:7 step:6647 [D loss: 0.660794, acc.: 64.06%] [G loss: 0.967160]\n",
      "epoch:7 step:6648 [D loss: 0.578468, acc.: 77.34%] [G loss: 1.040293]\n",
      "epoch:7 step:6649 [D loss: 0.697968, acc.: 60.16%] [G loss: 0.982303]\n",
      "epoch:7 step:6650 [D loss: 0.730118, acc.: 50.00%] [G loss: 0.842357]\n",
      "epoch:7 step:6651 [D loss: 0.613348, acc.: 68.75%] [G loss: 0.846056]\n",
      "epoch:7 step:6652 [D loss: 0.692328, acc.: 61.72%] [G loss: 0.961231]\n",
      "epoch:7 step:6653 [D loss: 0.718816, acc.: 50.78%] [G loss: 0.924872]\n",
      "epoch:7 step:6654 [D loss: 0.642437, acc.: 62.50%] [G loss: 0.970468]\n",
      "epoch:7 step:6655 [D loss: 0.680174, acc.: 57.81%] [G loss: 0.863445]\n",
      "epoch:7 step:6656 [D loss: 0.617630, acc.: 66.41%] [G loss: 1.012987]\n",
      "epoch:7 step:6657 [D loss: 0.688944, acc.: 57.03%] [G loss: 0.892645]\n",
      "epoch:7 step:6658 [D loss: 0.676236, acc.: 61.72%] [G loss: 0.898049]\n",
      "epoch:7 step:6659 [D loss: 0.681746, acc.: 56.25%] [G loss: 0.946453]\n",
      "epoch:7 step:6660 [D loss: 0.630083, acc.: 65.62%] [G loss: 0.855296]\n",
      "epoch:7 step:6661 [D loss: 0.639992, acc.: 65.62%] [G loss: 0.969410]\n",
      "epoch:7 step:6662 [D loss: 0.654394, acc.: 60.94%] [G loss: 0.808903]\n",
      "epoch:7 step:6663 [D loss: 0.622095, acc.: 64.84%] [G loss: 0.998460]\n",
      "epoch:7 step:6664 [D loss: 0.659225, acc.: 57.81%] [G loss: 0.989998]\n",
      "epoch:7 step:6665 [D loss: 0.580225, acc.: 75.78%] [G loss: 0.946897]\n",
      "epoch:7 step:6666 [D loss: 0.664771, acc.: 56.25%] [G loss: 1.021537]\n",
      "epoch:7 step:6667 [D loss: 0.768590, acc.: 52.34%] [G loss: 0.776893]\n",
      "epoch:7 step:6668 [D loss: 0.657731, acc.: 57.81%] [G loss: 0.942872]\n",
      "epoch:7 step:6669 [D loss: 0.743328, acc.: 49.22%] [G loss: 0.853683]\n",
      "epoch:7 step:6670 [D loss: 0.676590, acc.: 58.59%] [G loss: 0.925200]\n",
      "epoch:7 step:6671 [D loss: 0.636869, acc.: 61.72%] [G loss: 0.935607]\n",
      "epoch:7 step:6672 [D loss: 0.669459, acc.: 53.12%] [G loss: 0.873931]\n",
      "epoch:7 step:6673 [D loss: 0.736745, acc.: 52.34%] [G loss: 0.962106]\n",
      "epoch:7 step:6674 [D loss: 0.699867, acc.: 52.34%] [G loss: 0.903103]\n",
      "epoch:7 step:6675 [D loss: 0.632106, acc.: 64.84%] [G loss: 0.949161]\n",
      "epoch:7 step:6676 [D loss: 0.590629, acc.: 69.53%] [G loss: 1.051799]\n",
      "epoch:7 step:6677 [D loss: 0.603701, acc.: 72.66%] [G loss: 0.982716]\n",
      "epoch:7 step:6678 [D loss: 0.578553, acc.: 75.00%] [G loss: 1.172910]\n",
      "epoch:7 step:6679 [D loss: 0.781673, acc.: 46.09%] [G loss: 0.905743]\n",
      "epoch:7 step:6680 [D loss: 0.714387, acc.: 50.78%] [G loss: 0.972371]\n",
      "epoch:7 step:6681 [D loss: 0.685682, acc.: 60.94%] [G loss: 1.008515]\n",
      "epoch:7 step:6682 [D loss: 0.647091, acc.: 65.62%] [G loss: 0.852745]\n",
      "epoch:7 step:6683 [D loss: 0.653809, acc.: 60.16%] [G loss: 0.884183]\n",
      "epoch:7 step:6684 [D loss: 0.639460, acc.: 67.19%] [G loss: 1.006457]\n",
      "epoch:7 step:6685 [D loss: 0.606079, acc.: 65.62%] [G loss: 0.952824]\n",
      "epoch:7 step:6686 [D loss: 0.587799, acc.: 70.31%] [G loss: 1.000964]\n",
      "epoch:7 step:6687 [D loss: 0.706454, acc.: 56.25%] [G loss: 0.938743]\n",
      "epoch:7 step:6688 [D loss: 0.725877, acc.: 50.78%] [G loss: 0.858229]\n",
      "epoch:7 step:6689 [D loss: 0.684988, acc.: 56.25%] [G loss: 0.851819]\n",
      "epoch:7 step:6690 [D loss: 0.654533, acc.: 57.03%] [G loss: 1.046216]\n",
      "epoch:7 step:6691 [D loss: 0.653041, acc.: 60.94%] [G loss: 0.940310]\n",
      "epoch:7 step:6692 [D loss: 0.710493, acc.: 50.78%] [G loss: 0.909021]\n",
      "epoch:7 step:6693 [D loss: 0.657663, acc.: 58.59%] [G loss: 0.923701]\n",
      "epoch:7 step:6694 [D loss: 0.701234, acc.: 50.00%] [G loss: 0.875135]\n",
      "epoch:7 step:6695 [D loss: 0.673647, acc.: 62.50%] [G loss: 0.943860]\n",
      "epoch:7 step:6696 [D loss: 0.686180, acc.: 58.59%] [G loss: 1.046770]\n",
      "epoch:7 step:6697 [D loss: 0.676952, acc.: 55.47%] [G loss: 0.933551]\n",
      "epoch:7 step:6698 [D loss: 0.685478, acc.: 60.94%] [G loss: 0.917208]\n",
      "epoch:7 step:6699 [D loss: 0.664681, acc.: 58.59%] [G loss: 0.917071]\n",
      "epoch:7 step:6700 [D loss: 0.696871, acc.: 57.81%] [G loss: 0.992719]\n",
      "epoch:7 step:6701 [D loss: 0.673710, acc.: 59.38%] [G loss: 0.986357]\n",
      "epoch:7 step:6702 [D loss: 0.715400, acc.: 57.81%] [G loss: 0.883037]\n",
      "epoch:7 step:6703 [D loss: 0.619411, acc.: 66.41%] [G loss: 0.824512]\n",
      "epoch:7 step:6704 [D loss: 0.653636, acc.: 64.84%] [G loss: 0.881538]\n",
      "epoch:7 step:6705 [D loss: 0.772693, acc.: 50.00%] [G loss: 0.830957]\n",
      "epoch:7 step:6706 [D loss: 0.688076, acc.: 54.69%] [G loss: 0.836428]\n",
      "epoch:7 step:6707 [D loss: 0.691179, acc.: 53.91%] [G loss: 1.065776]\n",
      "epoch:7 step:6708 [D loss: 0.712021, acc.: 54.69%] [G loss: 0.900650]\n",
      "epoch:7 step:6709 [D loss: 0.617217, acc.: 66.41%] [G loss: 0.893633]\n",
      "epoch:7 step:6710 [D loss: 0.625214, acc.: 64.06%] [G loss: 1.016203]\n",
      "epoch:7 step:6711 [D loss: 0.614308, acc.: 67.19%] [G loss: 1.066041]\n",
      "epoch:7 step:6712 [D loss: 0.697564, acc.: 57.81%] [G loss: 0.878701]\n",
      "epoch:7 step:6713 [D loss: 0.678835, acc.: 60.94%] [G loss: 0.834058]\n",
      "epoch:7 step:6714 [D loss: 0.601378, acc.: 66.41%] [G loss: 0.906173]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6715 [D loss: 0.653794, acc.: 61.72%] [G loss: 0.899923]\n",
      "epoch:7 step:6716 [D loss: 0.673854, acc.: 55.47%] [G loss: 0.923759]\n",
      "epoch:7 step:6717 [D loss: 0.695587, acc.: 48.44%] [G loss: 0.900562]\n",
      "epoch:7 step:6718 [D loss: 0.658542, acc.: 56.25%] [G loss: 0.829221]\n",
      "epoch:7 step:6719 [D loss: 0.761972, acc.: 45.31%] [G loss: 0.864923]\n",
      "epoch:7 step:6720 [D loss: 0.764900, acc.: 44.53%] [G loss: 0.814152]\n",
      "epoch:7 step:6721 [D loss: 0.648372, acc.: 63.28%] [G loss: 0.896863]\n",
      "epoch:7 step:6722 [D loss: 0.633793, acc.: 60.94%] [G loss: 0.853710]\n",
      "epoch:7 step:6723 [D loss: 0.645457, acc.: 59.38%] [G loss: 0.844664]\n",
      "epoch:7 step:6724 [D loss: 0.662811, acc.: 63.28%] [G loss: 1.013173]\n",
      "epoch:7 step:6725 [D loss: 0.575850, acc.: 69.53%] [G loss: 0.990172]\n",
      "epoch:7 step:6726 [D loss: 0.668601, acc.: 60.16%] [G loss: 0.935310]\n",
      "epoch:7 step:6727 [D loss: 0.664740, acc.: 64.06%] [G loss: 0.826693]\n",
      "epoch:7 step:6728 [D loss: 0.644217, acc.: 67.19%] [G loss: 0.980717]\n",
      "epoch:7 step:6729 [D loss: 0.681608, acc.: 56.25%] [G loss: 0.963482]\n",
      "epoch:7 step:6730 [D loss: 0.630807, acc.: 64.84%] [G loss: 1.035713]\n",
      "epoch:7 step:6731 [D loss: 0.655934, acc.: 64.84%] [G loss: 0.913028]\n",
      "epoch:7 step:6732 [D loss: 0.717278, acc.: 54.69%] [G loss: 0.858127]\n",
      "epoch:7 step:6733 [D loss: 0.756439, acc.: 42.97%] [G loss: 0.854635]\n",
      "epoch:7 step:6734 [D loss: 0.719004, acc.: 51.56%] [G loss: 0.895828]\n",
      "epoch:7 step:6735 [D loss: 0.622860, acc.: 62.50%] [G loss: 0.884252]\n",
      "epoch:7 step:6736 [D loss: 0.602255, acc.: 67.19%] [G loss: 0.969673]\n",
      "epoch:7 step:6737 [D loss: 0.641505, acc.: 60.94%] [G loss: 1.006458]\n",
      "epoch:7 step:6738 [D loss: 0.636781, acc.: 62.50%] [G loss: 0.888672]\n",
      "epoch:7 step:6739 [D loss: 0.684300, acc.: 57.81%] [G loss: 0.978737]\n",
      "epoch:7 step:6740 [D loss: 0.765587, acc.: 50.00%] [G loss: 0.980512]\n",
      "epoch:7 step:6741 [D loss: 0.780811, acc.: 44.53%] [G loss: 0.900328]\n",
      "epoch:7 step:6742 [D loss: 0.642558, acc.: 59.38%] [G loss: 0.939799]\n",
      "epoch:7 step:6743 [D loss: 0.782817, acc.: 50.78%] [G loss: 0.778736]\n",
      "epoch:7 step:6744 [D loss: 0.717200, acc.: 51.56%] [G loss: 0.785998]\n",
      "epoch:7 step:6745 [D loss: 0.729573, acc.: 52.34%] [G loss: 0.844154]\n",
      "epoch:7 step:6746 [D loss: 0.715660, acc.: 53.12%] [G loss: 0.799147]\n",
      "epoch:7 step:6747 [D loss: 0.725939, acc.: 50.00%] [G loss: 0.851295]\n",
      "epoch:7 step:6748 [D loss: 0.695738, acc.: 55.47%] [G loss: 0.932535]\n",
      "epoch:7 step:6749 [D loss: 0.654048, acc.: 61.72%] [G loss: 0.906853]\n",
      "epoch:7 step:6750 [D loss: 0.621216, acc.: 67.97%] [G loss: 0.976806]\n",
      "epoch:7 step:6751 [D loss: 0.731468, acc.: 50.00%] [G loss: 0.961750]\n",
      "epoch:7 step:6752 [D loss: 0.762588, acc.: 48.44%] [G loss: 0.844142]\n",
      "epoch:7 step:6753 [D loss: 0.689276, acc.: 57.81%] [G loss: 0.929120]\n",
      "epoch:7 step:6754 [D loss: 0.705763, acc.: 56.25%] [G loss: 0.977995]\n",
      "epoch:7 step:6755 [D loss: 0.693300, acc.: 54.69%] [G loss: 0.961731]\n",
      "epoch:7 step:6756 [D loss: 0.726021, acc.: 52.34%] [G loss: 0.873204]\n",
      "epoch:7 step:6757 [D loss: 0.724123, acc.: 53.91%] [G loss: 0.891404]\n",
      "epoch:7 step:6758 [D loss: 0.658164, acc.: 57.81%] [G loss: 0.968159]\n",
      "epoch:7 step:6759 [D loss: 0.711287, acc.: 53.91%] [G loss: 0.892699]\n",
      "epoch:7 step:6760 [D loss: 0.729895, acc.: 49.22%] [G loss: 0.865524]\n",
      "epoch:7 step:6761 [D loss: 0.742806, acc.: 50.00%] [G loss: 0.962469]\n",
      "epoch:7 step:6762 [D loss: 0.738206, acc.: 46.88%] [G loss: 0.936884]\n",
      "epoch:7 step:6763 [D loss: 0.696828, acc.: 53.12%] [G loss: 0.920488]\n",
      "epoch:7 step:6764 [D loss: 0.679498, acc.: 53.91%] [G loss: 0.967018]\n",
      "epoch:7 step:6765 [D loss: 0.610522, acc.: 64.06%] [G loss: 0.876835]\n",
      "epoch:7 step:6766 [D loss: 0.687316, acc.: 53.91%] [G loss: 0.938570]\n",
      "epoch:7 step:6767 [D loss: 0.610004, acc.: 67.19%] [G loss: 1.099443]\n",
      "epoch:7 step:6768 [D loss: 0.648171, acc.: 60.94%] [G loss: 0.922235]\n",
      "epoch:7 step:6769 [D loss: 0.666543, acc.: 60.16%] [G loss: 0.916195]\n",
      "epoch:7 step:6770 [D loss: 0.645673, acc.: 64.06%] [G loss: 1.093471]\n",
      "epoch:7 step:6771 [D loss: 0.660964, acc.: 60.16%] [G loss: 0.901505]\n",
      "epoch:7 step:6772 [D loss: 0.685241, acc.: 53.91%] [G loss: 0.966386]\n",
      "epoch:7 step:6773 [D loss: 0.754005, acc.: 42.97%] [G loss: 0.908161]\n",
      "epoch:7 step:6774 [D loss: 0.696507, acc.: 57.03%] [G loss: 0.917372]\n",
      "epoch:7 step:6775 [D loss: 0.644361, acc.: 60.94%] [G loss: 0.930529]\n",
      "epoch:7 step:6776 [D loss: 0.655666, acc.: 59.38%] [G loss: 0.894138]\n",
      "epoch:7 step:6777 [D loss: 0.586418, acc.: 69.53%] [G loss: 0.938688]\n",
      "epoch:7 step:6778 [D loss: 0.676154, acc.: 55.47%] [G loss: 0.900032]\n",
      "epoch:7 step:6779 [D loss: 0.692321, acc.: 55.47%] [G loss: 1.035623]\n",
      "epoch:7 step:6780 [D loss: 0.719641, acc.: 53.91%] [G loss: 0.941472]\n",
      "epoch:7 step:6781 [D loss: 0.693642, acc.: 60.16%] [G loss: 0.924083]\n",
      "epoch:7 step:6782 [D loss: 0.663302, acc.: 61.72%] [G loss: 0.978209]\n",
      "epoch:7 step:6783 [D loss: 0.694947, acc.: 59.38%] [G loss: 0.942159]\n",
      "epoch:7 step:6784 [D loss: 0.693573, acc.: 53.12%] [G loss: 0.889593]\n",
      "epoch:7 step:6785 [D loss: 0.721566, acc.: 51.56%] [G loss: 0.899121]\n",
      "epoch:7 step:6786 [D loss: 0.694537, acc.: 53.12%] [G loss: 0.912864]\n",
      "epoch:7 step:6787 [D loss: 0.730942, acc.: 48.44%] [G loss: 0.903956]\n",
      "epoch:7 step:6788 [D loss: 0.625653, acc.: 65.62%] [G loss: 0.896392]\n",
      "epoch:7 step:6789 [D loss: 0.633208, acc.: 62.50%] [G loss: 0.983355]\n",
      "epoch:7 step:6790 [D loss: 0.569694, acc.: 71.09%] [G loss: 0.932437]\n",
      "epoch:7 step:6791 [D loss: 0.596519, acc.: 67.97%] [G loss: 1.023456]\n",
      "epoch:7 step:6792 [D loss: 0.657856, acc.: 60.94%] [G loss: 1.065336]\n",
      "epoch:7 step:6793 [D loss: 0.733106, acc.: 47.66%] [G loss: 0.961104]\n",
      "epoch:7 step:6794 [D loss: 0.656911, acc.: 56.25%] [G loss: 1.009861]\n",
      "epoch:7 step:6795 [D loss: 0.680774, acc.: 59.38%] [G loss: 0.828557]\n",
      "epoch:7 step:6796 [D loss: 0.676778, acc.: 54.69%] [G loss: 1.010816]\n",
      "epoch:7 step:6797 [D loss: 0.701060, acc.: 59.38%] [G loss: 0.908492]\n",
      "epoch:7 step:6798 [D loss: 0.649164, acc.: 61.72%] [G loss: 0.932032]\n",
      "epoch:7 step:6799 [D loss: 0.742147, acc.: 49.22%] [G loss: 0.930816]\n",
      "epoch:7 step:6800 [D loss: 0.631440, acc.: 66.41%] [G loss: 0.947928]\n",
      "##############\n",
      "[2.10976373 1.33251404 5.15594598 3.95644319 2.70545255 5.19724865\n",
      " 3.96424691 4.60308112 3.56533965 3.45903329]\n",
      "##########\n",
      "epoch:7 step:6801 [D loss: 0.627379, acc.: 62.50%] [G loss: 0.967364]\n",
      "epoch:7 step:6802 [D loss: 0.622840, acc.: 64.84%] [G loss: 0.971919]\n",
      "epoch:7 step:6803 [D loss: 0.706593, acc.: 60.16%] [G loss: 0.931555]\n",
      "epoch:7 step:6804 [D loss: 0.618011, acc.: 69.53%] [G loss: 0.956904]\n",
      "epoch:7 step:6805 [D loss: 0.745685, acc.: 48.44%] [G loss: 0.871077]\n",
      "epoch:7 step:6806 [D loss: 0.706905, acc.: 54.69%] [G loss: 0.916727]\n",
      "epoch:7 step:6807 [D loss: 0.700698, acc.: 53.91%] [G loss: 0.767132]\n",
      "epoch:7 step:6808 [D loss: 0.646333, acc.: 63.28%] [G loss: 0.871015]\n",
      "epoch:7 step:6809 [D loss: 0.655532, acc.: 65.62%] [G loss: 0.921789]\n",
      "epoch:7 step:6810 [D loss: 0.767835, acc.: 42.19%] [G loss: 0.755590]\n",
      "epoch:7 step:6811 [D loss: 0.633088, acc.: 62.50%] [G loss: 0.885574]\n",
      "epoch:7 step:6812 [D loss: 0.637087, acc.: 64.06%] [G loss: 0.982870]\n",
      "epoch:7 step:6813 [D loss: 0.655016, acc.: 63.28%] [G loss: 1.038239]\n",
      "epoch:7 step:6814 [D loss: 0.655073, acc.: 59.38%] [G loss: 0.989095]\n",
      "epoch:7 step:6815 [D loss: 0.648418, acc.: 60.94%] [G loss: 0.920593]\n",
      "epoch:7 step:6816 [D loss: 0.604989, acc.: 62.50%] [G loss: 0.900702]\n",
      "epoch:7 step:6817 [D loss: 0.641433, acc.: 64.84%] [G loss: 0.827637]\n",
      "epoch:7 step:6818 [D loss: 0.671868, acc.: 61.72%] [G loss: 0.876063]\n",
      "epoch:7 step:6819 [D loss: 0.635282, acc.: 64.06%] [G loss: 0.974319]\n",
      "epoch:7 step:6820 [D loss: 0.706233, acc.: 59.38%] [G loss: 0.850633]\n",
      "epoch:7 step:6821 [D loss: 0.651572, acc.: 64.06%] [G loss: 0.898885]\n",
      "epoch:7 step:6822 [D loss: 0.630348, acc.: 64.06%] [G loss: 0.997750]\n",
      "epoch:7 step:6823 [D loss: 0.666297, acc.: 57.81%] [G loss: 0.995847]\n",
      "epoch:7 step:6824 [D loss: 0.700950, acc.: 55.47%] [G loss: 0.967127]\n",
      "epoch:7 step:6825 [D loss: 0.746559, acc.: 52.34%] [G loss: 0.830091]\n",
      "epoch:7 step:6826 [D loss: 0.682820, acc.: 51.56%] [G loss: 0.941734]\n",
      "epoch:7 step:6827 [D loss: 0.682742, acc.: 61.72%] [G loss: 0.839746]\n",
      "epoch:7 step:6828 [D loss: 0.646933, acc.: 61.72%] [G loss: 0.883563]\n",
      "epoch:7 step:6829 [D loss: 0.703300, acc.: 53.91%] [G loss: 0.801540]\n",
      "epoch:7 step:6830 [D loss: 0.624443, acc.: 64.06%] [G loss: 0.939544]\n",
      "epoch:7 step:6831 [D loss: 0.655378, acc.: 61.72%] [G loss: 1.081188]\n",
      "epoch:7 step:6832 [D loss: 0.644747, acc.: 65.62%] [G loss: 0.853720]\n",
      "epoch:7 step:6833 [D loss: 0.662637, acc.: 59.38%] [G loss: 0.886356]\n",
      "epoch:7 step:6834 [D loss: 0.708387, acc.: 53.91%] [G loss: 0.962544]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6835 [D loss: 0.692652, acc.: 53.91%] [G loss: 1.026427]\n",
      "epoch:7 step:6836 [D loss: 0.699868, acc.: 52.34%] [G loss: 0.906134]\n",
      "epoch:7 step:6837 [D loss: 0.611649, acc.: 71.88%] [G loss: 0.947783]\n",
      "epoch:7 step:6838 [D loss: 0.718233, acc.: 54.69%] [G loss: 0.868417]\n",
      "epoch:7 step:6839 [D loss: 0.656035, acc.: 62.50%] [G loss: 1.003298]\n",
      "epoch:7 step:6840 [D loss: 0.755828, acc.: 46.09%] [G loss: 0.836911]\n",
      "epoch:7 step:6841 [D loss: 0.675327, acc.: 58.59%] [G loss: 0.863855]\n",
      "epoch:7 step:6842 [D loss: 0.650082, acc.: 65.62%] [G loss: 0.827356]\n",
      "epoch:7 step:6843 [D loss: 0.665516, acc.: 61.72%] [G loss: 0.916650]\n",
      "epoch:7 step:6844 [D loss: 0.699562, acc.: 53.91%] [G loss: 0.893153]\n",
      "epoch:7 step:6845 [D loss: 0.710979, acc.: 53.12%] [G loss: 0.837347]\n",
      "epoch:7 step:6846 [D loss: 0.631529, acc.: 67.19%] [G loss: 0.871574]\n",
      "epoch:7 step:6847 [D loss: 0.764221, acc.: 45.31%] [G loss: 0.879611]\n",
      "epoch:7 step:6848 [D loss: 0.693898, acc.: 58.59%] [G loss: 0.823875]\n",
      "epoch:7 step:6849 [D loss: 0.744285, acc.: 46.88%] [G loss: 0.868981]\n",
      "epoch:7 step:6850 [D loss: 0.655846, acc.: 59.38%] [G loss: 0.914555]\n",
      "epoch:7 step:6851 [D loss: 0.701824, acc.: 51.56%] [G loss: 0.880983]\n",
      "epoch:7 step:6852 [D loss: 0.590130, acc.: 73.44%] [G loss: 0.969390]\n",
      "epoch:7 step:6853 [D loss: 0.700374, acc.: 54.69%] [G loss: 0.839680]\n",
      "epoch:7 step:6854 [D loss: 0.654609, acc.: 59.38%] [G loss: 0.875671]\n",
      "epoch:7 step:6855 [D loss: 0.679641, acc.: 57.81%] [G loss: 0.868522]\n",
      "epoch:7 step:6856 [D loss: 0.629883, acc.: 63.28%] [G loss: 0.930344]\n",
      "epoch:7 step:6857 [D loss: 0.651576, acc.: 60.94%] [G loss: 0.929343]\n",
      "epoch:7 step:6858 [D loss: 0.663181, acc.: 58.59%] [G loss: 0.906832]\n",
      "epoch:7 step:6859 [D loss: 0.654599, acc.: 61.72%] [G loss: 0.962249]\n",
      "epoch:7 step:6860 [D loss: 0.698863, acc.: 53.12%] [G loss: 0.884849]\n",
      "epoch:7 step:6861 [D loss: 0.654389, acc.: 59.38%] [G loss: 0.923303]\n",
      "epoch:7 step:6862 [D loss: 0.663385, acc.: 60.94%] [G loss: 0.960663]\n",
      "epoch:7 step:6863 [D loss: 0.636774, acc.: 68.75%] [G loss: 1.026909]\n",
      "epoch:7 step:6864 [D loss: 0.661831, acc.: 59.38%] [G loss: 0.910233]\n",
      "epoch:7 step:6865 [D loss: 0.681666, acc.: 58.59%] [G loss: 1.006809]\n",
      "epoch:7 step:6866 [D loss: 0.711350, acc.: 56.25%] [G loss: 0.911584]\n",
      "epoch:7 step:6867 [D loss: 0.673953, acc.: 56.25%] [G loss: 0.882150]\n",
      "epoch:7 step:6868 [D loss: 0.703543, acc.: 51.56%] [G loss: 0.885744]\n",
      "epoch:7 step:6869 [D loss: 0.641203, acc.: 62.50%] [G loss: 0.919901]\n",
      "epoch:7 step:6870 [D loss: 0.617940, acc.: 67.97%] [G loss: 1.102988]\n",
      "epoch:7 step:6871 [D loss: 0.646961, acc.: 64.06%] [G loss: 0.985839]\n",
      "epoch:7 step:6872 [D loss: 0.566487, acc.: 75.00%] [G loss: 1.106712]\n",
      "epoch:7 step:6873 [D loss: 0.592770, acc.: 69.53%] [G loss: 1.003448]\n",
      "epoch:7 step:6874 [D loss: 0.580990, acc.: 69.53%] [G loss: 0.968282]\n",
      "epoch:7 step:6875 [D loss: 0.709499, acc.: 55.47%] [G loss: 1.052520]\n",
      "epoch:7 step:6876 [D loss: 0.670051, acc.: 61.72%] [G loss: 1.028214]\n",
      "epoch:7 step:6877 [D loss: 0.636020, acc.: 60.16%] [G loss: 1.003197]\n",
      "epoch:7 step:6878 [D loss: 0.726540, acc.: 50.78%] [G loss: 0.903681]\n",
      "epoch:7 step:6879 [D loss: 0.634609, acc.: 63.28%] [G loss: 0.937989]\n",
      "epoch:7 step:6880 [D loss: 0.617484, acc.: 64.84%] [G loss: 0.917091]\n",
      "epoch:7 step:6881 [D loss: 0.696248, acc.: 53.91%] [G loss: 0.857998]\n",
      "epoch:7 step:6882 [D loss: 0.670304, acc.: 57.81%] [G loss: 0.944837]\n",
      "epoch:7 step:6883 [D loss: 0.717668, acc.: 46.09%] [G loss: 0.857255]\n",
      "epoch:7 step:6884 [D loss: 0.697925, acc.: 57.81%] [G loss: 0.876707]\n",
      "epoch:7 step:6885 [D loss: 0.688915, acc.: 54.69%] [G loss: 0.938059]\n",
      "epoch:7 step:6886 [D loss: 0.688158, acc.: 57.81%] [G loss: 0.840020]\n",
      "epoch:7 step:6887 [D loss: 0.659666, acc.: 63.28%] [G loss: 0.912930]\n",
      "epoch:7 step:6888 [D loss: 0.650476, acc.: 59.38%] [G loss: 0.862756]\n",
      "epoch:7 step:6889 [D loss: 0.674560, acc.: 60.94%] [G loss: 0.963272]\n",
      "epoch:7 step:6890 [D loss: 0.633002, acc.: 64.06%] [G loss: 0.950911]\n",
      "epoch:7 step:6891 [D loss: 0.603353, acc.: 66.41%] [G loss: 0.937763]\n",
      "epoch:7 step:6892 [D loss: 0.622629, acc.: 64.84%] [G loss: 0.987072]\n",
      "epoch:7 step:6893 [D loss: 0.676347, acc.: 64.84%] [G loss: 0.910935]\n",
      "epoch:7 step:6894 [D loss: 0.632988, acc.: 64.84%] [G loss: 0.979097]\n",
      "epoch:7 step:6895 [D loss: 0.635417, acc.: 63.28%] [G loss: 1.002900]\n",
      "epoch:7 step:6896 [D loss: 0.605596, acc.: 70.31%] [G loss: 1.052578]\n",
      "epoch:7 step:6897 [D loss: 0.604496, acc.: 64.84%] [G loss: 0.952764]\n",
      "epoch:7 step:6898 [D loss: 0.581654, acc.: 68.75%] [G loss: 0.962024]\n",
      "epoch:7 step:6899 [D loss: 0.622266, acc.: 66.41%] [G loss: 1.019857]\n",
      "epoch:7 step:6900 [D loss: 0.674475, acc.: 54.69%] [G loss: 0.962933]\n",
      "epoch:7 step:6901 [D loss: 0.779620, acc.: 46.88%] [G loss: 0.964923]\n",
      "epoch:7 step:6902 [D loss: 0.721965, acc.: 55.47%] [G loss: 0.820358]\n",
      "epoch:7 step:6903 [D loss: 0.583596, acc.: 74.22%] [G loss: 1.018190]\n",
      "epoch:7 step:6904 [D loss: 0.625372, acc.: 65.62%] [G loss: 0.901698]\n",
      "epoch:7 step:6905 [D loss: 0.562476, acc.: 71.09%] [G loss: 0.952606]\n",
      "epoch:7 step:6906 [D loss: 0.672609, acc.: 60.94%] [G loss: 0.945630]\n",
      "epoch:7 step:6907 [D loss: 0.694531, acc.: 57.03%] [G loss: 1.029823]\n",
      "epoch:7 step:6908 [D loss: 0.737600, acc.: 52.34%] [G loss: 0.982797]\n",
      "epoch:7 step:6909 [D loss: 0.658809, acc.: 61.72%] [G loss: 0.812034]\n",
      "epoch:7 step:6910 [D loss: 0.697346, acc.: 60.16%] [G loss: 0.917130]\n",
      "epoch:7 step:6911 [D loss: 0.697650, acc.: 55.47%] [G loss: 0.857101]\n",
      "epoch:7 step:6912 [D loss: 0.669775, acc.: 62.50%] [G loss: 0.939718]\n",
      "epoch:7 step:6913 [D loss: 0.736246, acc.: 50.78%] [G loss: 0.779477]\n",
      "epoch:7 step:6914 [D loss: 0.672098, acc.: 62.50%] [G loss: 0.886051]\n",
      "epoch:7 step:6915 [D loss: 0.624052, acc.: 69.53%] [G loss: 0.870559]\n",
      "epoch:7 step:6916 [D loss: 0.625023, acc.: 60.16%] [G loss: 0.981510]\n",
      "epoch:7 step:6917 [D loss: 0.617253, acc.: 64.84%] [G loss: 0.787804]\n",
      "epoch:7 step:6918 [D loss: 0.664242, acc.: 59.38%] [G loss: 0.984151]\n",
      "epoch:7 step:6919 [D loss: 0.669690, acc.: 58.59%] [G loss: 0.911295]\n",
      "epoch:7 step:6920 [D loss: 0.686511, acc.: 54.69%] [G loss: 0.865055]\n",
      "epoch:7 step:6921 [D loss: 0.651003, acc.: 60.94%] [G loss: 0.989180]\n",
      "epoch:7 step:6922 [D loss: 0.665877, acc.: 59.38%] [G loss: 0.854411]\n",
      "epoch:7 step:6923 [D loss: 0.701021, acc.: 56.25%] [G loss: 0.889310]\n",
      "epoch:7 step:6924 [D loss: 0.711306, acc.: 53.91%] [G loss: 0.912306]\n",
      "epoch:7 step:6925 [D loss: 0.671087, acc.: 57.81%] [G loss: 0.991498]\n",
      "epoch:7 step:6926 [D loss: 0.612177, acc.: 68.75%] [G loss: 0.924993]\n",
      "epoch:7 step:6927 [D loss: 0.703711, acc.: 56.25%] [G loss: 0.860563]\n",
      "epoch:7 step:6928 [D loss: 0.602349, acc.: 66.41%] [G loss: 1.069396]\n",
      "epoch:7 step:6929 [D loss: 0.615314, acc.: 64.06%] [G loss: 0.938816]\n",
      "epoch:7 step:6930 [D loss: 0.632064, acc.: 66.41%] [G loss: 0.971937]\n",
      "epoch:7 step:6931 [D loss: 0.706455, acc.: 57.81%] [G loss: 0.819036]\n",
      "epoch:7 step:6932 [D loss: 0.705258, acc.: 55.47%] [G loss: 0.947615]\n",
      "epoch:7 step:6933 [D loss: 0.664514, acc.: 58.59%] [G loss: 0.856717]\n",
      "epoch:7 step:6934 [D loss: 0.703836, acc.: 53.91%] [G loss: 0.910929]\n",
      "epoch:7 step:6935 [D loss: 0.679068, acc.: 58.59%] [G loss: 0.914183]\n",
      "epoch:7 step:6936 [D loss: 0.697810, acc.: 55.47%] [G loss: 1.041816]\n",
      "epoch:7 step:6937 [D loss: 0.665450, acc.: 62.50%] [G loss: 0.879841]\n",
      "epoch:7 step:6938 [D loss: 0.645557, acc.: 59.38%] [G loss: 0.886680]\n",
      "epoch:7 step:6939 [D loss: 0.632801, acc.: 62.50%] [G loss: 0.941826]\n",
      "epoch:7 step:6940 [D loss: 0.616533, acc.: 63.28%] [G loss: 0.946192]\n",
      "epoch:7 step:6941 [D loss: 0.679782, acc.: 58.59%] [G loss: 0.982883]\n",
      "epoch:7 step:6942 [D loss: 0.666221, acc.: 64.84%] [G loss: 0.890144]\n",
      "epoch:7 step:6943 [D loss: 0.678366, acc.: 60.94%] [G loss: 0.900006]\n",
      "epoch:7 step:6944 [D loss: 0.673863, acc.: 57.81%] [G loss: 0.843612]\n",
      "epoch:7 step:6945 [D loss: 0.668997, acc.: 54.69%] [G loss: 0.949263]\n",
      "epoch:7 step:6946 [D loss: 0.649714, acc.: 61.72%] [G loss: 0.938898]\n",
      "epoch:7 step:6947 [D loss: 0.625081, acc.: 67.19%] [G loss: 1.026061]\n",
      "epoch:7 step:6948 [D loss: 0.688749, acc.: 61.72%] [G loss: 0.947467]\n",
      "epoch:7 step:6949 [D loss: 0.699494, acc.: 52.34%] [G loss: 0.858451]\n",
      "epoch:7 step:6950 [D loss: 0.643141, acc.: 66.41%] [G loss: 0.866862]\n",
      "epoch:7 step:6951 [D loss: 0.632413, acc.: 65.62%] [G loss: 0.969264]\n",
      "epoch:7 step:6952 [D loss: 0.672821, acc.: 59.38%] [G loss: 0.982147]\n",
      "epoch:7 step:6953 [D loss: 0.667829, acc.: 60.94%] [G loss: 0.851801]\n",
      "epoch:7 step:6954 [D loss: 0.611260, acc.: 65.62%] [G loss: 1.007564]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6955 [D loss: 0.750490, acc.: 42.19%] [G loss: 1.023561]\n",
      "epoch:7 step:6956 [D loss: 0.782408, acc.: 43.75%] [G loss: 0.957608]\n",
      "epoch:7 step:6957 [D loss: 0.663594, acc.: 60.94%] [G loss: 0.995123]\n",
      "epoch:7 step:6958 [D loss: 0.584317, acc.: 70.31%] [G loss: 1.068671]\n",
      "epoch:7 step:6959 [D loss: 0.680653, acc.: 60.94%] [G loss: 0.912188]\n",
      "epoch:7 step:6960 [D loss: 0.654371, acc.: 60.16%] [G loss: 1.026408]\n",
      "epoch:7 step:6961 [D loss: 0.706627, acc.: 55.47%] [G loss: 0.876983]\n",
      "epoch:7 step:6962 [D loss: 0.669836, acc.: 60.94%] [G loss: 0.899793]\n",
      "epoch:7 step:6963 [D loss: 0.622658, acc.: 64.84%] [G loss: 1.008713]\n",
      "epoch:7 step:6964 [D loss: 0.676609, acc.: 57.81%] [G loss: 0.973859]\n",
      "epoch:7 step:6965 [D loss: 0.639412, acc.: 62.50%] [G loss: 0.948612]\n",
      "epoch:7 step:6966 [D loss: 0.607869, acc.: 64.06%] [G loss: 1.009507]\n",
      "epoch:7 step:6967 [D loss: 0.624305, acc.: 64.84%] [G loss: 0.903751]\n",
      "epoch:7 step:6968 [D loss: 0.691821, acc.: 58.59%] [G loss: 0.842582]\n",
      "epoch:7 step:6969 [D loss: 0.701405, acc.: 56.25%] [G loss: 0.891329]\n",
      "epoch:7 step:6970 [D loss: 0.736865, acc.: 52.34%] [G loss: 0.939775]\n",
      "epoch:7 step:6971 [D loss: 0.659683, acc.: 59.38%] [G loss: 0.941608]\n",
      "epoch:7 step:6972 [D loss: 0.744375, acc.: 48.44%] [G loss: 0.952024]\n",
      "epoch:7 step:6973 [D loss: 0.702693, acc.: 53.12%] [G loss: 0.847775]\n",
      "epoch:7 step:6974 [D loss: 0.663509, acc.: 60.94%] [G loss: 0.897158]\n",
      "epoch:7 step:6975 [D loss: 0.677180, acc.: 61.72%] [G loss: 0.946886]\n",
      "epoch:7 step:6976 [D loss: 0.654377, acc.: 63.28%] [G loss: 0.989401]\n",
      "epoch:7 step:6977 [D loss: 0.702373, acc.: 54.69%] [G loss: 0.859116]\n",
      "epoch:7 step:6978 [D loss: 0.598442, acc.: 71.88%] [G loss: 0.957607]\n",
      "epoch:7 step:6979 [D loss: 0.683993, acc.: 59.38%] [G loss: 0.803552]\n",
      "epoch:7 step:6980 [D loss: 0.649017, acc.: 60.94%] [G loss: 0.949523]\n",
      "epoch:7 step:6981 [D loss: 0.651219, acc.: 60.16%] [G loss: 1.018006]\n",
      "epoch:7 step:6982 [D loss: 0.671134, acc.: 59.38%] [G loss: 0.772360]\n",
      "epoch:7 step:6983 [D loss: 0.698643, acc.: 53.91%] [G loss: 0.898664]\n",
      "epoch:7 step:6984 [D loss: 0.760618, acc.: 44.53%] [G loss: 0.890830]\n",
      "epoch:7 step:6985 [D loss: 0.621073, acc.: 67.19%] [G loss: 1.048624]\n",
      "epoch:7 step:6986 [D loss: 0.602645, acc.: 66.41%] [G loss: 0.895265]\n",
      "epoch:7 step:6987 [D loss: 0.657676, acc.: 60.16%] [G loss: 0.938405]\n",
      "epoch:7 step:6988 [D loss: 0.593119, acc.: 71.88%] [G loss: 1.049170]\n",
      "epoch:7 step:6989 [D loss: 0.563542, acc.: 70.31%] [G loss: 1.206098]\n",
      "epoch:7 step:6990 [D loss: 0.651663, acc.: 60.16%] [G loss: 1.056390]\n",
      "epoch:7 step:6991 [D loss: 0.743236, acc.: 50.78%] [G loss: 0.969125]\n",
      "epoch:7 step:6992 [D loss: 0.664130, acc.: 61.72%] [G loss: 0.948213]\n",
      "epoch:7 step:6993 [D loss: 0.633025, acc.: 58.59%] [G loss: 0.926640]\n",
      "epoch:7 step:6994 [D loss: 0.724538, acc.: 57.03%] [G loss: 0.871601]\n",
      "epoch:7 step:6995 [D loss: 0.655652, acc.: 61.72%] [G loss: 0.897460]\n",
      "epoch:7 step:6996 [D loss: 0.735471, acc.: 50.00%] [G loss: 1.047066]\n",
      "epoch:7 step:6997 [D loss: 0.604209, acc.: 70.31%] [G loss: 0.881151]\n",
      "epoch:7 step:6998 [D loss: 0.670266, acc.: 61.72%] [G loss: 0.897946]\n",
      "epoch:7 step:6999 [D loss: 0.612733, acc.: 67.97%] [G loss: 1.116382]\n",
      "epoch:7 step:7000 [D loss: 0.669983, acc.: 55.47%] [G loss: 1.035842]\n",
      "##############\n",
      "[1.89067814 1.17700262 4.94519404 4.06329339 2.90917599 4.90288692\n",
      " 3.73148369 4.43184843 3.36672444 2.93688043]\n",
      "##########\n",
      "epoch:7 step:7001 [D loss: 0.647916, acc.: 59.38%] [G loss: 0.974931]\n",
      "epoch:7 step:7002 [D loss: 0.680060, acc.: 57.03%] [G loss: 0.964838]\n",
      "epoch:7 step:7003 [D loss: 0.660992, acc.: 56.25%] [G loss: 0.900964]\n",
      "epoch:7 step:7004 [D loss: 0.642844, acc.: 65.62%] [G loss: 0.907703]\n",
      "epoch:7 step:7005 [D loss: 0.735418, acc.: 50.78%] [G loss: 0.825848]\n",
      "epoch:7 step:7006 [D loss: 0.603325, acc.: 64.06%] [G loss: 1.063814]\n",
      "epoch:7 step:7007 [D loss: 0.677144, acc.: 57.03%] [G loss: 0.944000]\n",
      "epoch:7 step:7008 [D loss: 0.763008, acc.: 46.88%] [G loss: 0.953358]\n",
      "epoch:7 step:7009 [D loss: 0.717945, acc.: 53.12%] [G loss: 0.954910]\n",
      "epoch:7 step:7010 [D loss: 0.641077, acc.: 60.16%] [G loss: 1.027117]\n",
      "epoch:7 step:7011 [D loss: 0.680933, acc.: 55.47%] [G loss: 1.053452]\n",
      "epoch:7 step:7012 [D loss: 0.686214, acc.: 57.81%] [G loss: 0.950071]\n",
      "epoch:7 step:7013 [D loss: 0.597187, acc.: 65.62%] [G loss: 1.085149]\n",
      "epoch:7 step:7014 [D loss: 0.665625, acc.: 62.50%] [G loss: 0.962244]\n",
      "epoch:7 step:7015 [D loss: 0.621568, acc.: 67.19%] [G loss: 1.018010]\n",
      "epoch:7 step:7016 [D loss: 0.646341, acc.: 67.97%] [G loss: 0.947526]\n",
      "epoch:7 step:7017 [D loss: 0.767866, acc.: 45.31%] [G loss: 0.906613]\n",
      "epoch:7 step:7018 [D loss: 0.710672, acc.: 53.91%] [G loss: 1.010892]\n",
      "epoch:7 step:7019 [D loss: 0.620061, acc.: 65.62%] [G loss: 0.999275]\n",
      "epoch:7 step:7020 [D loss: 0.666496, acc.: 57.03%] [G loss: 0.888828]\n",
      "epoch:7 step:7021 [D loss: 0.701010, acc.: 53.91%] [G loss: 0.922414]\n",
      "epoch:7 step:7022 [D loss: 0.712756, acc.: 54.69%] [G loss: 0.871172]\n",
      "epoch:7 step:7023 [D loss: 0.686589, acc.: 57.81%] [G loss: 0.971650]\n",
      "epoch:7 step:7024 [D loss: 0.629827, acc.: 58.59%] [G loss: 0.968939]\n",
      "epoch:7 step:7025 [D loss: 0.629072, acc.: 69.53%] [G loss: 1.018787]\n",
      "epoch:7 step:7026 [D loss: 0.650095, acc.: 60.16%] [G loss: 0.898781]\n",
      "epoch:7 step:7027 [D loss: 0.606500, acc.: 71.09%] [G loss: 0.964922]\n",
      "epoch:7 step:7028 [D loss: 0.604220, acc.: 62.50%] [G loss: 0.941742]\n",
      "epoch:7 step:7029 [D loss: 0.624935, acc.: 65.62%] [G loss: 0.906550]\n",
      "epoch:7 step:7030 [D loss: 0.670098, acc.: 60.16%] [G loss: 1.067189]\n",
      "epoch:7 step:7031 [D loss: 0.685393, acc.: 59.38%] [G loss: 0.938441]\n",
      "epoch:7 step:7032 [D loss: 0.836282, acc.: 42.97%] [G loss: 0.864617]\n",
      "epoch:7 step:7033 [D loss: 0.709977, acc.: 54.69%] [G loss: 0.933042]\n",
      "epoch:7 step:7034 [D loss: 0.634356, acc.: 64.84%] [G loss: 0.922011]\n",
      "epoch:7 step:7035 [D loss: 0.663297, acc.: 62.50%] [G loss: 0.810466]\n",
      "epoch:7 step:7036 [D loss: 0.713121, acc.: 49.22%] [G loss: 0.998758]\n",
      "epoch:7 step:7037 [D loss: 0.714764, acc.: 50.00%] [G loss: 0.817154]\n",
      "epoch:7 step:7038 [D loss: 0.694978, acc.: 54.69%] [G loss: 0.871571]\n",
      "epoch:7 step:7039 [D loss: 0.684693, acc.: 57.81%] [G loss: 1.007594]\n",
      "epoch:7 step:7040 [D loss: 0.662679, acc.: 62.50%] [G loss: 0.942061]\n",
      "epoch:7 step:7041 [D loss: 0.736572, acc.: 46.88%] [G loss: 0.968070]\n",
      "epoch:7 step:7042 [D loss: 0.637017, acc.: 64.06%] [G loss: 1.027153]\n",
      "epoch:7 step:7043 [D loss: 0.655407, acc.: 60.16%] [G loss: 1.005935]\n",
      "epoch:7 step:7044 [D loss: 0.728246, acc.: 50.78%] [G loss: 1.005094]\n",
      "epoch:7 step:7045 [D loss: 0.673244, acc.: 63.28%] [G loss: 0.867050]\n",
      "epoch:7 step:7046 [D loss: 0.729821, acc.: 50.78%] [G loss: 0.936148]\n",
      "epoch:7 step:7047 [D loss: 0.705259, acc.: 53.91%] [G loss: 1.011722]\n",
      "epoch:7 step:7048 [D loss: 0.695014, acc.: 57.81%] [G loss: 1.003745]\n",
      "epoch:7 step:7049 [D loss: 0.643623, acc.: 63.28%] [G loss: 0.998197]\n",
      "epoch:7 step:7050 [D loss: 0.724236, acc.: 57.81%] [G loss: 0.908739]\n",
      "epoch:7 step:7051 [D loss: 0.706442, acc.: 53.12%] [G loss: 1.039112]\n",
      "epoch:7 step:7052 [D loss: 0.686515, acc.: 57.03%] [G loss: 0.880447]\n",
      "epoch:7 step:7053 [D loss: 0.578723, acc.: 71.88%] [G loss: 0.910205]\n",
      "epoch:7 step:7054 [D loss: 0.637119, acc.: 65.62%] [G loss: 0.979221]\n",
      "epoch:7 step:7055 [D loss: 0.694745, acc.: 53.12%] [G loss: 0.952141]\n",
      "epoch:7 step:7056 [D loss: 0.656064, acc.: 61.72%] [G loss: 0.994370]\n",
      "epoch:7 step:7057 [D loss: 0.640223, acc.: 61.72%] [G loss: 0.961348]\n",
      "epoch:7 step:7058 [D loss: 0.623093, acc.: 67.97%] [G loss: 0.965222]\n",
      "epoch:7 step:7059 [D loss: 0.705627, acc.: 54.69%] [G loss: 0.835121]\n",
      "epoch:7 step:7060 [D loss: 0.709186, acc.: 57.03%] [G loss: 0.977020]\n",
      "epoch:7 step:7061 [D loss: 0.654398, acc.: 61.72%] [G loss: 0.862060]\n",
      "epoch:7 step:7062 [D loss: 0.659166, acc.: 60.16%] [G loss: 0.959737]\n",
      "epoch:7 step:7063 [D loss: 0.609467, acc.: 62.50%] [G loss: 0.910457]\n",
      "epoch:7 step:7064 [D loss: 0.644988, acc.: 71.88%] [G loss: 0.882000]\n",
      "epoch:7 step:7065 [D loss: 0.647701, acc.: 64.84%] [G loss: 0.931076]\n",
      "epoch:7 step:7066 [D loss: 0.702430, acc.: 57.81%] [G loss: 0.940473]\n",
      "epoch:7 step:7067 [D loss: 0.618089, acc.: 66.41%] [G loss: 0.783356]\n",
      "epoch:7 step:7068 [D loss: 0.711011, acc.: 54.69%] [G loss: 0.883234]\n",
      "epoch:7 step:7069 [D loss: 0.726428, acc.: 53.12%] [G loss: 0.801483]\n",
      "epoch:7 step:7070 [D loss: 0.795994, acc.: 34.38%] [G loss: 0.849399]\n",
      "epoch:7 step:7071 [D loss: 0.718003, acc.: 46.88%] [G loss: 0.955629]\n",
      "epoch:7 step:7072 [D loss: 0.591332, acc.: 69.53%] [G loss: 0.871267]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7073 [D loss: 0.646135, acc.: 60.16%] [G loss: 0.916011]\n",
      "epoch:7 step:7074 [D loss: 0.673480, acc.: 57.03%] [G loss: 0.935615]\n",
      "epoch:7 step:7075 [D loss: 0.624110, acc.: 66.41%] [G loss: 1.039467]\n",
      "epoch:7 step:7076 [D loss: 0.642661, acc.: 61.72%] [G loss: 0.945960]\n",
      "epoch:7 step:7077 [D loss: 0.683085, acc.: 55.47%] [G loss: 0.938060]\n",
      "epoch:7 step:7078 [D loss: 0.612845, acc.: 63.28%] [G loss: 0.998526]\n",
      "epoch:7 step:7079 [D loss: 0.664985, acc.: 60.94%] [G loss: 0.975250]\n",
      "epoch:7 step:7080 [D loss: 0.668310, acc.: 59.38%] [G loss: 0.862865]\n",
      "epoch:7 step:7081 [D loss: 0.717443, acc.: 55.47%] [G loss: 0.954170]\n",
      "epoch:7 step:7082 [D loss: 0.648858, acc.: 63.28%] [G loss: 1.033331]\n",
      "epoch:7 step:7083 [D loss: 0.642350, acc.: 61.72%] [G loss: 0.971389]\n",
      "epoch:7 step:7084 [D loss: 0.660519, acc.: 62.50%] [G loss: 0.911038]\n",
      "epoch:7 step:7085 [D loss: 0.695582, acc.: 59.38%] [G loss: 0.808886]\n",
      "epoch:7 step:7086 [D loss: 0.670933, acc.: 61.72%] [G loss: 0.960338]\n",
      "epoch:7 step:7087 [D loss: 0.687764, acc.: 54.69%] [G loss: 0.947209]\n",
      "epoch:7 step:7088 [D loss: 0.706689, acc.: 50.78%] [G loss: 0.980373]\n",
      "epoch:7 step:7089 [D loss: 0.684695, acc.: 60.94%] [G loss: 0.862258]\n",
      "epoch:7 step:7090 [D loss: 0.700137, acc.: 57.03%] [G loss: 0.825660]\n",
      "epoch:7 step:7091 [D loss: 0.610299, acc.: 68.75%] [G loss: 0.885555]\n",
      "epoch:7 step:7092 [D loss: 0.601903, acc.: 66.41%] [G loss: 0.909130]\n",
      "epoch:7 step:7093 [D loss: 0.680157, acc.: 57.03%] [G loss: 0.903264]\n",
      "epoch:7 step:7094 [D loss: 0.668135, acc.: 60.16%] [G loss: 0.958537]\n",
      "epoch:7 step:7095 [D loss: 0.655025, acc.: 60.16%] [G loss: 0.966702]\n",
      "epoch:7 step:7096 [D loss: 0.661653, acc.: 57.81%] [G loss: 0.970089]\n",
      "epoch:7 step:7097 [D loss: 0.665954, acc.: 60.16%] [G loss: 1.054628]\n",
      "epoch:7 step:7098 [D loss: 0.670630, acc.: 55.47%] [G loss: 0.908596]\n",
      "epoch:7 step:7099 [D loss: 0.698192, acc.: 52.34%] [G loss: 0.900436]\n",
      "epoch:7 step:7100 [D loss: 0.720029, acc.: 52.34%] [G loss: 0.821422]\n",
      "epoch:7 step:7101 [D loss: 0.694788, acc.: 51.56%] [G loss: 0.847762]\n",
      "epoch:7 step:7102 [D loss: 0.720024, acc.: 56.25%] [G loss: 0.792247]\n",
      "epoch:7 step:7103 [D loss: 0.768028, acc.: 43.75%] [G loss: 0.770940]\n",
      "epoch:7 step:7104 [D loss: 0.627800, acc.: 63.28%] [G loss: 0.860165]\n",
      "epoch:7 step:7105 [D loss: 0.663884, acc.: 60.16%] [G loss: 0.920653]\n",
      "epoch:7 step:7106 [D loss: 0.591259, acc.: 71.09%] [G loss: 0.969875]\n",
      "epoch:7 step:7107 [D loss: 0.690651, acc.: 57.81%] [G loss: 1.027878]\n",
      "epoch:7 step:7108 [D loss: 0.632888, acc.: 58.59%] [G loss: 0.898278]\n",
      "epoch:7 step:7109 [D loss: 0.635441, acc.: 69.53%] [G loss: 0.888734]\n",
      "epoch:7 step:7110 [D loss: 0.587199, acc.: 71.88%] [G loss: 1.016089]\n",
      "epoch:7 step:7111 [D loss: 0.633333, acc.: 64.84%] [G loss: 0.915622]\n",
      "epoch:7 step:7112 [D loss: 0.591031, acc.: 71.09%] [G loss: 1.069672]\n",
      "epoch:7 step:7113 [D loss: 0.632915, acc.: 65.62%] [G loss: 1.004979]\n",
      "epoch:7 step:7114 [D loss: 0.602791, acc.: 70.31%] [G loss: 1.075390]\n",
      "epoch:7 step:7115 [D loss: 0.601220, acc.: 72.66%] [G loss: 1.009064]\n",
      "epoch:7 step:7116 [D loss: 0.598252, acc.: 68.75%] [G loss: 1.033780]\n",
      "epoch:7 step:7117 [D loss: 0.649534, acc.: 61.72%] [G loss: 0.906629]\n",
      "epoch:7 step:7118 [D loss: 0.746181, acc.: 49.22%] [G loss: 1.026327]\n",
      "epoch:7 step:7119 [D loss: 0.731373, acc.: 51.56%] [G loss: 0.874176]\n",
      "epoch:7 step:7120 [D loss: 0.730267, acc.: 50.00%] [G loss: 0.876162]\n",
      "epoch:7 step:7121 [D loss: 0.732718, acc.: 53.91%] [G loss: 0.901537]\n",
      "epoch:7 step:7122 [D loss: 0.670322, acc.: 57.03%] [G loss: 0.961731]\n",
      "epoch:7 step:7123 [D loss: 0.617627, acc.: 69.53%] [G loss: 0.844743]\n",
      "epoch:7 step:7124 [D loss: 0.624744, acc.: 62.50%] [G loss: 0.958523]\n",
      "epoch:7 step:7125 [D loss: 0.690733, acc.: 56.25%] [G loss: 0.927500]\n",
      "epoch:7 step:7126 [D loss: 0.723168, acc.: 48.44%] [G loss: 0.916231]\n",
      "epoch:7 step:7127 [D loss: 0.710945, acc.: 58.59%] [G loss: 0.879446]\n",
      "epoch:7 step:7128 [D loss: 0.684761, acc.: 56.25%] [G loss: 0.955466]\n",
      "epoch:7 step:7129 [D loss: 0.680054, acc.: 54.69%] [G loss: 0.942603]\n",
      "epoch:7 step:7130 [D loss: 0.664154, acc.: 63.28%] [G loss: 0.830803]\n",
      "epoch:7 step:7131 [D loss: 0.719602, acc.: 54.69%] [G loss: 0.993577]\n",
      "epoch:7 step:7132 [D loss: 0.687782, acc.: 55.47%] [G loss: 0.985939]\n",
      "epoch:7 step:7133 [D loss: 0.709250, acc.: 50.00%] [G loss: 0.901417]\n",
      "epoch:7 step:7134 [D loss: 0.556465, acc.: 76.56%] [G loss: 0.960229]\n",
      "epoch:7 step:7135 [D loss: 0.723467, acc.: 48.44%] [G loss: 0.786771]\n",
      "epoch:7 step:7136 [D loss: 0.674060, acc.: 57.81%] [G loss: 0.799146]\n",
      "epoch:7 step:7137 [D loss: 0.625117, acc.: 64.06%] [G loss: 0.845637]\n",
      "epoch:7 step:7138 [D loss: 0.689629, acc.: 54.69%] [G loss: 0.884069]\n",
      "epoch:7 step:7139 [D loss: 0.694259, acc.: 55.47%] [G loss: 0.794630]\n",
      "epoch:7 step:7140 [D loss: 0.628929, acc.: 64.84%] [G loss: 0.840286]\n",
      "epoch:7 step:7141 [D loss: 0.638360, acc.: 64.84%] [G loss: 0.895494]\n",
      "epoch:7 step:7142 [D loss: 0.664061, acc.: 57.03%] [G loss: 0.960369]\n",
      "epoch:7 step:7143 [D loss: 0.685032, acc.: 55.47%] [G loss: 0.953840]\n",
      "epoch:7 step:7144 [D loss: 0.643567, acc.: 58.59%] [G loss: 0.929167]\n",
      "epoch:7 step:7145 [D loss: 0.694461, acc.: 60.94%] [G loss: 0.965126]\n",
      "epoch:7 step:7146 [D loss: 0.652947, acc.: 62.50%] [G loss: 0.877692]\n",
      "epoch:7 step:7147 [D loss: 0.687985, acc.: 53.12%] [G loss: 0.818926]\n",
      "epoch:7 step:7148 [D loss: 0.677520, acc.: 53.12%] [G loss: 0.918043]\n",
      "epoch:7 step:7149 [D loss: 0.788648, acc.: 46.88%] [G loss: 0.883634]\n",
      "epoch:7 step:7150 [D loss: 0.715073, acc.: 45.31%] [G loss: 0.943093]\n",
      "epoch:7 step:7151 [D loss: 0.642525, acc.: 63.28%] [G loss: 0.869322]\n",
      "epoch:7 step:7152 [D loss: 0.649205, acc.: 62.50%] [G loss: 0.961653]\n",
      "epoch:7 step:7153 [D loss: 0.749715, acc.: 44.53%] [G loss: 0.926522]\n",
      "epoch:7 step:7154 [D loss: 0.669704, acc.: 60.94%] [G loss: 1.017240]\n",
      "epoch:7 step:7155 [D loss: 0.715919, acc.: 54.69%] [G loss: 0.861455]\n",
      "epoch:7 step:7156 [D loss: 0.687414, acc.: 54.69%] [G loss: 0.922269]\n",
      "epoch:7 step:7157 [D loss: 0.643796, acc.: 64.84%] [G loss: 0.895016]\n",
      "epoch:7 step:7158 [D loss: 0.714905, acc.: 47.66%] [G loss: 0.844199]\n",
      "epoch:7 step:7159 [D loss: 0.726601, acc.: 46.88%] [G loss: 0.842864]\n",
      "epoch:7 step:7160 [D loss: 0.642383, acc.: 59.38%] [G loss: 0.933473]\n",
      "epoch:7 step:7161 [D loss: 0.706384, acc.: 52.34%] [G loss: 0.994436]\n",
      "epoch:7 step:7162 [D loss: 0.607261, acc.: 72.66%] [G loss: 0.864452]\n",
      "epoch:7 step:7163 [D loss: 0.659535, acc.: 61.72%] [G loss: 0.867876]\n",
      "epoch:7 step:7164 [D loss: 0.642808, acc.: 59.38%] [G loss: 0.925940]\n",
      "epoch:7 step:7165 [D loss: 0.671290, acc.: 57.81%] [G loss: 0.929454]\n",
      "epoch:7 step:7166 [D loss: 0.733638, acc.: 49.22%] [G loss: 0.798657]\n",
      "epoch:7 step:7167 [D loss: 0.628307, acc.: 64.06%] [G loss: 0.826419]\n",
      "epoch:7 step:7168 [D loss: 0.683533, acc.: 52.34%] [G loss: 0.932607]\n",
      "epoch:7 step:7169 [D loss: 0.660617, acc.: 62.50%] [G loss: 0.891680]\n",
      "epoch:7 step:7170 [D loss: 0.655316, acc.: 64.06%] [G loss: 0.841635]\n",
      "epoch:7 step:7171 [D loss: 0.639090, acc.: 65.62%] [G loss: 0.980156]\n",
      "epoch:7 step:7172 [D loss: 0.619252, acc.: 66.41%] [G loss: 0.954205]\n",
      "epoch:7 step:7173 [D loss: 0.680097, acc.: 53.91%] [G loss: 1.016711]\n",
      "epoch:7 step:7174 [D loss: 0.678799, acc.: 57.81%] [G loss: 0.951478]\n",
      "epoch:7 step:7175 [D loss: 0.681656, acc.: 56.25%] [G loss: 0.868701]\n",
      "epoch:7 step:7176 [D loss: 0.675597, acc.: 55.47%] [G loss: 0.789857]\n",
      "epoch:7 step:7177 [D loss: 0.667013, acc.: 57.81%] [G loss: 0.966417]\n",
      "epoch:7 step:7178 [D loss: 0.621970, acc.: 64.84%] [G loss: 1.039805]\n",
      "epoch:7 step:7179 [D loss: 0.719483, acc.: 59.38%] [G loss: 0.930711]\n",
      "epoch:7 step:7180 [D loss: 0.656117, acc.: 57.03%] [G loss: 0.949064]\n",
      "epoch:7 step:7181 [D loss: 0.706698, acc.: 50.78%] [G loss: 0.943585]\n",
      "epoch:7 step:7182 [D loss: 0.609324, acc.: 67.19%] [G loss: 1.013623]\n",
      "epoch:7 step:7183 [D loss: 0.570916, acc.: 76.56%] [G loss: 1.023714]\n",
      "epoch:7 step:7184 [D loss: 0.740812, acc.: 45.31%] [G loss: 0.826439]\n",
      "epoch:7 step:7185 [D loss: 0.748321, acc.: 49.22%] [G loss: 0.867965]\n",
      "epoch:7 step:7186 [D loss: 0.661958, acc.: 57.81%] [G loss: 0.963123]\n",
      "epoch:7 step:7187 [D loss: 0.740854, acc.: 51.56%] [G loss: 0.917366]\n",
      "epoch:7 step:7188 [D loss: 0.724536, acc.: 46.09%] [G loss: 0.866054]\n",
      "epoch:7 step:7189 [D loss: 0.615051, acc.: 68.75%] [G loss: 1.041131]\n",
      "epoch:7 step:7190 [D loss: 0.626084, acc.: 64.84%] [G loss: 0.988467]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7191 [D loss: 0.667163, acc.: 56.25%] [G loss: 0.948104]\n",
      "epoch:7 step:7192 [D loss: 0.618952, acc.: 67.19%] [G loss: 0.932860]\n",
      "epoch:7 step:7193 [D loss: 0.635635, acc.: 62.50%] [G loss: 0.965269]\n",
      "epoch:7 step:7194 [D loss: 0.641751, acc.: 60.16%] [G loss: 0.927488]\n",
      "epoch:7 step:7195 [D loss: 0.712831, acc.: 57.03%] [G loss: 0.871796]\n",
      "epoch:7 step:7196 [D loss: 0.652574, acc.: 60.94%] [G loss: 0.951747]\n",
      "epoch:7 step:7197 [D loss: 0.675634, acc.: 62.50%] [G loss: 0.890925]\n",
      "epoch:7 step:7198 [D loss: 0.654607, acc.: 58.59%] [G loss: 0.962372]\n",
      "epoch:7 step:7199 [D loss: 0.710038, acc.: 53.12%] [G loss: 0.909983]\n",
      "epoch:7 step:7200 [D loss: 0.716221, acc.: 54.69%] [G loss: 0.905748]\n",
      "##############\n",
      "[1.91618846 1.08139728 5.33648978 4.09159527 2.73668081 4.94661365\n",
      " 3.81565311 4.41095285 3.52872298 3.36344378]\n",
      "##########\n",
      "epoch:7 step:7201 [D loss: 0.642309, acc.: 57.81%] [G loss: 0.893817]\n",
      "epoch:7 step:7202 [D loss: 0.612631, acc.: 66.41%] [G loss: 0.917229]\n",
      "epoch:7 step:7203 [D loss: 0.640837, acc.: 61.72%] [G loss: 1.047233]\n",
      "epoch:7 step:7204 [D loss: 0.652592, acc.: 61.72%] [G loss: 1.074632]\n",
      "epoch:7 step:7205 [D loss: 0.727852, acc.: 46.09%] [G loss: 0.857406]\n",
      "epoch:7 step:7206 [D loss: 0.605094, acc.: 72.66%] [G loss: 0.884934]\n",
      "epoch:7 step:7207 [D loss: 0.609828, acc.: 65.62%] [G loss: 0.951567]\n",
      "epoch:7 step:7208 [D loss: 0.657768, acc.: 57.03%] [G loss: 0.898612]\n",
      "epoch:7 step:7209 [D loss: 0.705470, acc.: 50.00%] [G loss: 0.975027]\n",
      "epoch:7 step:7210 [D loss: 0.597281, acc.: 69.53%] [G loss: 0.985743]\n",
      "epoch:7 step:7211 [D loss: 0.734677, acc.: 53.12%] [G loss: 1.039073]\n",
      "epoch:7 step:7212 [D loss: 0.742034, acc.: 48.44%] [G loss: 0.857218]\n",
      "epoch:7 step:7213 [D loss: 0.668815, acc.: 57.81%] [G loss: 0.976138]\n",
      "epoch:7 step:7214 [D loss: 0.674635, acc.: 56.25%] [G loss: 0.864465]\n",
      "epoch:7 step:7215 [D loss: 0.716186, acc.: 51.56%] [G loss: 0.859971]\n",
      "epoch:7 step:7216 [D loss: 0.689623, acc.: 59.38%] [G loss: 1.002131]\n",
      "epoch:7 step:7217 [D loss: 0.723385, acc.: 55.47%] [G loss: 0.937634]\n",
      "epoch:7 step:7218 [D loss: 0.635578, acc.: 65.62%] [G loss: 0.969686]\n",
      "epoch:7 step:7219 [D loss: 0.619393, acc.: 64.84%] [G loss: 0.982560]\n",
      "epoch:7 step:7220 [D loss: 0.648715, acc.: 62.50%] [G loss: 0.930738]\n",
      "epoch:7 step:7221 [D loss: 0.698256, acc.: 55.47%] [G loss: 0.952462]\n",
      "epoch:7 step:7222 [D loss: 0.664979, acc.: 60.16%] [G loss: 0.953277]\n",
      "epoch:7 step:7223 [D loss: 0.719807, acc.: 50.78%] [G loss: 0.926856]\n",
      "epoch:7 step:7224 [D loss: 0.635292, acc.: 65.62%] [G loss: 0.944358]\n",
      "epoch:7 step:7225 [D loss: 0.663689, acc.: 57.81%] [G loss: 1.039930]\n",
      "epoch:7 step:7226 [D loss: 0.725785, acc.: 47.66%] [G loss: 0.895421]\n",
      "epoch:7 step:7227 [D loss: 0.653699, acc.: 63.28%] [G loss: 0.925902]\n",
      "epoch:7 step:7228 [D loss: 0.747814, acc.: 46.09%] [G loss: 0.828111]\n",
      "epoch:7 step:7229 [D loss: 0.605027, acc.: 69.53%] [G loss: 0.899557]\n",
      "epoch:7 step:7230 [D loss: 0.652638, acc.: 61.72%] [G loss: 0.919176]\n",
      "epoch:7 step:7231 [D loss: 0.709635, acc.: 57.81%] [G loss: 0.930489]\n",
      "epoch:7 step:7232 [D loss: 0.636506, acc.: 56.25%] [G loss: 0.990468]\n",
      "epoch:7 step:7233 [D loss: 0.699401, acc.: 54.69%] [G loss: 0.862237]\n",
      "epoch:7 step:7234 [D loss: 0.635444, acc.: 64.84%] [G loss: 0.849674]\n",
      "epoch:7 step:7235 [D loss: 0.616662, acc.: 71.09%] [G loss: 1.032707]\n",
      "epoch:7 step:7236 [D loss: 0.645329, acc.: 67.19%] [G loss: 1.011523]\n",
      "epoch:7 step:7237 [D loss: 0.666743, acc.: 58.59%] [G loss: 0.959359]\n",
      "epoch:7 step:7238 [D loss: 0.642767, acc.: 60.94%] [G loss: 1.026098]\n",
      "epoch:7 step:7239 [D loss: 0.693550, acc.: 57.03%] [G loss: 0.922064]\n",
      "epoch:7 step:7240 [D loss: 0.707688, acc.: 52.34%] [G loss: 0.934429]\n",
      "epoch:7 step:7241 [D loss: 0.637552, acc.: 65.62%] [G loss: 0.911748]\n",
      "epoch:7 step:7242 [D loss: 0.671757, acc.: 59.38%] [G loss: 0.889156]\n",
      "epoch:7 step:7243 [D loss: 0.686659, acc.: 53.12%] [G loss: 0.906664]\n",
      "epoch:7 step:7244 [D loss: 0.682992, acc.: 54.69%] [G loss: 0.961994]\n",
      "epoch:7 step:7245 [D loss: 0.669668, acc.: 56.25%] [G loss: 0.872777]\n",
      "epoch:7 step:7246 [D loss: 0.631289, acc.: 64.06%] [G loss: 1.031719]\n",
      "epoch:7 step:7247 [D loss: 0.608976, acc.: 69.53%] [G loss: 0.971553]\n",
      "epoch:7 step:7248 [D loss: 0.710749, acc.: 53.91%] [G loss: 0.855840]\n",
      "epoch:7 step:7249 [D loss: 0.678187, acc.: 53.12%] [G loss: 0.859118]\n",
      "epoch:7 step:7250 [D loss: 0.672474, acc.: 58.59%] [G loss: 0.914361]\n",
      "epoch:7 step:7251 [D loss: 0.682114, acc.: 55.47%] [G loss: 0.963970]\n",
      "epoch:7 step:7252 [D loss: 0.691250, acc.: 54.69%] [G loss: 0.886836]\n",
      "epoch:7 step:7253 [D loss: 0.650415, acc.: 62.50%] [G loss: 0.917064]\n",
      "epoch:7 step:7254 [D loss: 0.701629, acc.: 51.56%] [G loss: 1.053210]\n",
      "epoch:7 step:7255 [D loss: 0.676910, acc.: 54.69%] [G loss: 1.056589]\n",
      "epoch:7 step:7256 [D loss: 0.641186, acc.: 64.84%] [G loss: 0.932829]\n",
      "epoch:7 step:7257 [D loss: 0.683067, acc.: 58.59%] [G loss: 0.954872]\n",
      "epoch:7 step:7258 [D loss: 0.690332, acc.: 57.81%] [G loss: 0.847771]\n",
      "epoch:7 step:7259 [D loss: 0.629334, acc.: 62.50%] [G loss: 0.870434]\n",
      "epoch:7 step:7260 [D loss: 0.665402, acc.: 64.06%] [G loss: 0.900891]\n",
      "epoch:7 step:7261 [D loss: 0.638140, acc.: 64.84%] [G loss: 0.880178]\n",
      "epoch:7 step:7262 [D loss: 0.712812, acc.: 53.12%] [G loss: 0.838486]\n",
      "epoch:7 step:7263 [D loss: 0.692691, acc.: 58.59%] [G loss: 0.874419]\n",
      "epoch:7 step:7264 [D loss: 0.734488, acc.: 52.34%] [G loss: 0.872382]\n",
      "epoch:7 step:7265 [D loss: 0.608444, acc.: 67.97%] [G loss: 0.899269]\n",
      "epoch:7 step:7266 [D loss: 0.644468, acc.: 64.06%] [G loss: 0.906384]\n",
      "epoch:7 step:7267 [D loss: 0.591967, acc.: 69.53%] [G loss: 0.982870]\n",
      "epoch:7 step:7268 [D loss: 0.616467, acc.: 66.41%] [G loss: 0.955163]\n",
      "epoch:7 step:7269 [D loss: 0.697931, acc.: 53.91%] [G loss: 0.933222]\n",
      "epoch:7 step:7270 [D loss: 0.742733, acc.: 51.56%] [G loss: 1.051254]\n",
      "epoch:7 step:7271 [D loss: 0.628967, acc.: 64.06%] [G loss: 1.064469]\n",
      "epoch:7 step:7272 [D loss: 0.641477, acc.: 66.41%] [G loss: 0.915632]\n",
      "epoch:7 step:7273 [D loss: 0.667907, acc.: 60.94%] [G loss: 0.921228]\n",
      "epoch:7 step:7274 [D loss: 0.620544, acc.: 71.88%] [G loss: 1.053820]\n",
      "epoch:7 step:7275 [D loss: 0.711360, acc.: 53.12%] [G loss: 1.027196]\n",
      "epoch:7 step:7276 [D loss: 0.652858, acc.: 53.91%] [G loss: 0.983767]\n",
      "epoch:7 step:7277 [D loss: 0.651703, acc.: 63.28%] [G loss: 0.851994]\n",
      "epoch:7 step:7278 [D loss: 0.706214, acc.: 57.03%] [G loss: 0.979821]\n",
      "epoch:7 step:7279 [D loss: 0.733837, acc.: 50.78%] [G loss: 0.814818]\n",
      "epoch:7 step:7280 [D loss: 0.757768, acc.: 42.97%] [G loss: 0.907736]\n",
      "epoch:7 step:7281 [D loss: 0.656574, acc.: 62.50%] [G loss: 0.873531]\n",
      "epoch:7 step:7282 [D loss: 0.684108, acc.: 54.69%] [G loss: 0.935452]\n",
      "epoch:7 step:7283 [D loss: 0.694491, acc.: 56.25%] [G loss: 0.889879]\n",
      "epoch:7 step:7284 [D loss: 0.643576, acc.: 66.41%] [G loss: 0.831045]\n",
      "epoch:7 step:7285 [D loss: 0.678151, acc.: 56.25%] [G loss: 0.931757]\n",
      "epoch:7 step:7286 [D loss: 0.670204, acc.: 60.94%] [G loss: 0.898360]\n",
      "epoch:7 step:7287 [D loss: 0.722438, acc.: 47.66%] [G loss: 0.825490]\n",
      "epoch:7 step:7288 [D loss: 0.610145, acc.: 64.84%] [G loss: 0.934701]\n",
      "epoch:7 step:7289 [D loss: 0.651886, acc.: 60.94%] [G loss: 0.997530]\n",
      "epoch:7 step:7290 [D loss: 0.634434, acc.: 65.62%] [G loss: 1.089941]\n",
      "epoch:7 step:7291 [D loss: 0.649370, acc.: 64.06%] [G loss: 0.913349]\n",
      "epoch:7 step:7292 [D loss: 0.625292, acc.: 65.62%] [G loss: 0.809332]\n",
      "epoch:7 step:7293 [D loss: 0.691306, acc.: 56.25%] [G loss: 0.970109]\n",
      "epoch:7 step:7294 [D loss: 0.653076, acc.: 63.28%] [G loss: 0.961498]\n",
      "epoch:7 step:7295 [D loss: 0.646095, acc.: 60.94%] [G loss: 0.902717]\n",
      "epoch:7 step:7296 [D loss: 0.650007, acc.: 55.47%] [G loss: 0.823850]\n",
      "epoch:7 step:7297 [D loss: 0.701963, acc.: 50.78%] [G loss: 0.928604]\n",
      "epoch:7 step:7298 [D loss: 0.712993, acc.: 59.38%] [G loss: 0.950676]\n",
      "epoch:7 step:7299 [D loss: 0.622522, acc.: 67.19%] [G loss: 0.929856]\n",
      "epoch:7 step:7300 [D loss: 0.793241, acc.: 38.28%] [G loss: 0.873206]\n",
      "epoch:7 step:7301 [D loss: 0.757992, acc.: 47.66%] [G loss: 0.926327]\n",
      "epoch:7 step:7302 [D loss: 0.698306, acc.: 54.69%] [G loss: 0.930682]\n",
      "epoch:7 step:7303 [D loss: 0.677826, acc.: 59.38%] [G loss: 0.930910]\n",
      "epoch:7 step:7304 [D loss: 0.669593, acc.: 59.38%] [G loss: 0.901490]\n",
      "epoch:7 step:7305 [D loss: 0.604153, acc.: 69.53%] [G loss: 1.016186]\n",
      "epoch:7 step:7306 [D loss: 0.635456, acc.: 65.62%] [G loss: 0.992455]\n",
      "epoch:7 step:7307 [D loss: 0.630693, acc.: 62.50%] [G loss: 1.054271]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7308 [D loss: 0.709731, acc.: 50.00%] [G loss: 1.092335]\n",
      "epoch:7 step:7309 [D loss: 0.620096, acc.: 70.31%] [G loss: 0.907985]\n",
      "epoch:7 step:7310 [D loss: 0.668008, acc.: 60.94%] [G loss: 0.966961]\n",
      "epoch:7 step:7311 [D loss: 0.667038, acc.: 56.25%] [G loss: 0.895494]\n",
      "epoch:7 step:7312 [D loss: 0.651394, acc.: 63.28%] [G loss: 0.922898]\n",
      "epoch:7 step:7313 [D loss: 0.619543, acc.: 68.75%] [G loss: 0.868735]\n",
      "epoch:7 step:7314 [D loss: 0.627867, acc.: 62.50%] [G loss: 0.874649]\n",
      "epoch:7 step:7315 [D loss: 0.632517, acc.: 63.28%] [G loss: 0.985792]\n",
      "epoch:7 step:7316 [D loss: 0.689997, acc.: 58.59%] [G loss: 0.847441]\n",
      "epoch:7 step:7317 [D loss: 0.633806, acc.: 67.19%] [G loss: 1.054667]\n",
      "epoch:7 step:7318 [D loss: 0.707487, acc.: 54.69%] [G loss: 0.829714]\n",
      "epoch:7 step:7319 [D loss: 0.684292, acc.: 53.91%] [G loss: 0.863780]\n",
      "epoch:7 step:7320 [D loss: 0.681396, acc.: 54.69%] [G loss: 0.973536]\n",
      "epoch:7 step:7321 [D loss: 0.742745, acc.: 43.75%] [G loss: 0.903451]\n",
      "epoch:7 step:7322 [D loss: 0.718737, acc.: 55.47%] [G loss: 0.876647]\n",
      "epoch:7 step:7323 [D loss: 0.731378, acc.: 48.44%] [G loss: 0.908586]\n",
      "epoch:7 step:7324 [D loss: 0.646597, acc.: 60.16%] [G loss: 0.925579]\n",
      "epoch:7 step:7325 [D loss: 0.740145, acc.: 53.12%] [G loss: 0.924926]\n",
      "epoch:7 step:7326 [D loss: 0.636255, acc.: 61.72%] [G loss: 0.993174]\n",
      "epoch:7 step:7327 [D loss: 0.790843, acc.: 43.75%] [G loss: 0.831781]\n",
      "epoch:7 step:7328 [D loss: 0.612000, acc.: 64.06%] [G loss: 0.961831]\n",
      "epoch:7 step:7329 [D loss: 0.682186, acc.: 55.47%] [G loss: 0.945248]\n",
      "epoch:7 step:7330 [D loss: 0.688343, acc.: 56.25%] [G loss: 0.949629]\n",
      "epoch:7 step:7331 [D loss: 0.671411, acc.: 59.38%] [G loss: 0.900626]\n",
      "epoch:7 step:7332 [D loss: 0.647268, acc.: 63.28%] [G loss: 0.914403]\n",
      "epoch:7 step:7333 [D loss: 0.648023, acc.: 66.41%] [G loss: 0.852385]\n",
      "epoch:7 step:7334 [D loss: 0.671102, acc.: 64.06%] [G loss: 0.965890]\n",
      "epoch:7 step:7335 [D loss: 0.636309, acc.: 58.59%] [G loss: 1.040264]\n",
      "epoch:7 step:7336 [D loss: 0.722082, acc.: 53.91%] [G loss: 0.940040]\n",
      "epoch:7 step:7337 [D loss: 0.661683, acc.: 63.28%] [G loss: 0.995904]\n",
      "epoch:7 step:7338 [D loss: 0.664422, acc.: 58.59%] [G loss: 0.900808]\n",
      "epoch:7 step:7339 [D loss: 0.705101, acc.: 51.56%] [G loss: 0.808578]\n",
      "epoch:7 step:7340 [D loss: 0.660936, acc.: 60.94%] [G loss: 0.876078]\n",
      "epoch:7 step:7341 [D loss: 0.635549, acc.: 67.19%] [G loss: 0.942929]\n",
      "epoch:7 step:7342 [D loss: 0.700989, acc.: 50.00%] [G loss: 0.890411]\n",
      "epoch:7 step:7343 [D loss: 0.677125, acc.: 57.03%] [G loss: 0.837875]\n",
      "epoch:7 step:7344 [D loss: 0.718521, acc.: 51.56%] [G loss: 0.797420]\n",
      "epoch:7 step:7345 [D loss: 0.557084, acc.: 76.56%] [G loss: 0.949404]\n",
      "epoch:7 step:7346 [D loss: 0.698464, acc.: 58.59%] [G loss: 0.923877]\n",
      "epoch:7 step:7347 [D loss: 0.719988, acc.: 53.12%] [G loss: 0.964544]\n",
      "epoch:7 step:7348 [D loss: 0.628484, acc.: 62.50%] [G loss: 0.929516]\n",
      "epoch:7 step:7349 [D loss: 0.654324, acc.: 60.94%] [G loss: 0.975048]\n",
      "epoch:7 step:7350 [D loss: 0.637992, acc.: 63.28%] [G loss: 0.896562]\n",
      "epoch:7 step:7351 [D loss: 0.671805, acc.: 55.47%] [G loss: 0.866247]\n",
      "epoch:7 step:7352 [D loss: 0.558995, acc.: 73.44%] [G loss: 1.001900]\n",
      "epoch:7 step:7353 [D loss: 0.756248, acc.: 48.44%] [G loss: 0.856393]\n",
      "epoch:7 step:7354 [D loss: 0.628011, acc.: 62.50%] [G loss: 1.043406]\n",
      "epoch:7 step:7355 [D loss: 0.615826, acc.: 65.62%] [G loss: 0.974473]\n",
      "epoch:7 step:7356 [D loss: 0.662118, acc.: 61.72%] [G loss: 0.993677]\n",
      "epoch:7 step:7357 [D loss: 0.634651, acc.: 62.50%] [G loss: 0.870429]\n",
      "epoch:7 step:7358 [D loss: 0.676823, acc.: 60.16%] [G loss: 0.979825]\n",
      "epoch:7 step:7359 [D loss: 0.746786, acc.: 51.56%] [G loss: 0.923628]\n",
      "epoch:7 step:7360 [D loss: 0.714611, acc.: 54.69%] [G loss: 0.868619]\n",
      "epoch:7 step:7361 [D loss: 0.686996, acc.: 57.03%] [G loss: 0.894346]\n",
      "epoch:7 step:7362 [D loss: 0.602785, acc.: 67.19%] [G loss: 0.889467]\n",
      "epoch:7 step:7363 [D loss: 0.633346, acc.: 59.38%] [G loss: 0.961094]\n",
      "epoch:7 step:7364 [D loss: 0.623012, acc.: 64.84%] [G loss: 0.939970]\n",
      "epoch:7 step:7365 [D loss: 0.547153, acc.: 78.12%] [G loss: 1.066453]\n",
      "epoch:7 step:7366 [D loss: 0.637733, acc.: 66.41%] [G loss: 0.964953]\n",
      "epoch:7 step:7367 [D loss: 0.630681, acc.: 66.41%] [G loss: 1.030974]\n",
      "epoch:7 step:7368 [D loss: 0.672906, acc.: 64.06%] [G loss: 0.918383]\n",
      "epoch:7 step:7369 [D loss: 0.582468, acc.: 70.31%] [G loss: 0.989642]\n",
      "epoch:7 step:7370 [D loss: 0.683764, acc.: 57.03%] [G loss: 0.776845]\n",
      "epoch:7 step:7371 [D loss: 0.694987, acc.: 54.69%] [G loss: 0.962271]\n",
      "epoch:7 step:7372 [D loss: 0.706026, acc.: 57.03%] [G loss: 0.895559]\n",
      "epoch:7 step:7373 [D loss: 0.680407, acc.: 53.91%] [G loss: 0.902348]\n",
      "epoch:7 step:7374 [D loss: 0.683859, acc.: 55.47%] [G loss: 0.978127]\n",
      "epoch:7 step:7375 [D loss: 0.652613, acc.: 58.59%] [G loss: 0.944148]\n",
      "epoch:7 step:7376 [D loss: 0.723150, acc.: 49.22%] [G loss: 0.829211]\n",
      "epoch:7 step:7377 [D loss: 0.701336, acc.: 57.81%] [G loss: 0.919447]\n",
      "epoch:7 step:7378 [D loss: 0.635491, acc.: 62.50%] [G loss: 0.929036]\n",
      "epoch:7 step:7379 [D loss: 0.680246, acc.: 59.38%] [G loss: 0.939209]\n",
      "epoch:7 step:7380 [D loss: 0.647076, acc.: 57.81%] [G loss: 0.932806]\n",
      "epoch:7 step:7381 [D loss: 0.653734, acc.: 63.28%] [G loss: 0.837565]\n",
      "epoch:7 step:7382 [D loss: 0.679770, acc.: 57.03%] [G loss: 0.831008]\n",
      "epoch:7 step:7383 [D loss: 0.739267, acc.: 49.22%] [G loss: 0.926486]\n",
      "epoch:7 step:7384 [D loss: 0.715074, acc.: 54.69%] [G loss: 0.857628]\n",
      "epoch:7 step:7385 [D loss: 0.648551, acc.: 61.72%] [G loss: 0.933082]\n",
      "epoch:7 step:7386 [D loss: 0.660559, acc.: 57.03%] [G loss: 1.011602]\n",
      "epoch:7 step:7387 [D loss: 0.666882, acc.: 60.94%] [G loss: 0.849298]\n",
      "epoch:7 step:7388 [D loss: 0.732573, acc.: 49.22%] [G loss: 0.890392]\n",
      "epoch:7 step:7389 [D loss: 0.657520, acc.: 64.06%] [G loss: 1.048054]\n",
      "epoch:7 step:7390 [D loss: 0.597262, acc.: 70.31%] [G loss: 0.942927]\n",
      "epoch:7 step:7391 [D loss: 0.684221, acc.: 53.12%] [G loss: 0.891971]\n",
      "epoch:7 step:7392 [D loss: 0.602752, acc.: 67.97%] [G loss: 0.938450]\n",
      "epoch:7 step:7393 [D loss: 0.620841, acc.: 61.72%] [G loss: 1.106076]\n",
      "epoch:7 step:7394 [D loss: 0.625935, acc.: 65.62%] [G loss: 0.938848]\n",
      "epoch:7 step:7395 [D loss: 0.628915, acc.: 66.41%] [G loss: 0.966469]\n",
      "epoch:7 step:7396 [D loss: 0.677820, acc.: 51.56%] [G loss: 0.864101]\n",
      "epoch:7 step:7397 [D loss: 0.677671, acc.: 57.81%] [G loss: 0.846678]\n",
      "epoch:7 step:7398 [D loss: 0.670092, acc.: 59.38%] [G loss: 0.949754]\n",
      "epoch:7 step:7399 [D loss: 0.579465, acc.: 67.97%] [G loss: 0.893737]\n",
      "epoch:7 step:7400 [D loss: 0.639648, acc.: 64.84%] [G loss: 0.915196]\n",
      "##############\n",
      "[2.34223375 1.62177757 5.40067147 4.40366035 3.09946815 5.29127202\n",
      " 4.06537354 4.62890812 3.6879106  3.61348086]\n",
      "##########\n",
      "epoch:7 step:7401 [D loss: 0.717513, acc.: 58.59%] [G loss: 1.018591]\n",
      "epoch:7 step:7402 [D loss: 0.701606, acc.: 59.38%] [G loss: 1.014060]\n",
      "epoch:7 step:7403 [D loss: 0.685914, acc.: 59.38%] [G loss: 0.904037]\n",
      "epoch:7 step:7404 [D loss: 0.630088, acc.: 67.19%] [G loss: 0.995492]\n",
      "epoch:7 step:7405 [D loss: 0.625410, acc.: 60.16%] [G loss: 0.941320]\n",
      "epoch:7 step:7406 [D loss: 0.605982, acc.: 68.75%] [G loss: 0.974864]\n",
      "epoch:7 step:7407 [D loss: 0.656720, acc.: 58.59%] [G loss: 0.914551]\n",
      "epoch:7 step:7408 [D loss: 0.752838, acc.: 47.66%] [G loss: 0.806282]\n",
      "epoch:7 step:7409 [D loss: 0.661398, acc.: 60.16%] [G loss: 0.945246]\n",
      "epoch:7 step:7410 [D loss: 0.647012, acc.: 60.16%] [G loss: 0.955343]\n",
      "epoch:7 step:7411 [D loss: 0.641394, acc.: 62.50%] [G loss: 0.915786]\n",
      "epoch:7 step:7412 [D loss: 0.585467, acc.: 74.22%] [G loss: 0.957705]\n",
      "epoch:7 step:7413 [D loss: 0.650767, acc.: 61.72%] [G loss: 0.950874]\n",
      "epoch:7 step:7414 [D loss: 0.666942, acc.: 57.81%] [G loss: 0.922790]\n",
      "epoch:7 step:7415 [D loss: 0.710240, acc.: 56.25%] [G loss: 0.978878]\n",
      "epoch:7 step:7416 [D loss: 0.699919, acc.: 53.12%] [G loss: 0.851822]\n",
      "epoch:7 step:7417 [D loss: 0.699332, acc.: 53.91%] [G loss: 0.982949]\n",
      "epoch:7 step:7418 [D loss: 0.730746, acc.: 50.00%] [G loss: 0.841815]\n",
      "epoch:7 step:7419 [D loss: 0.630246, acc.: 64.06%] [G loss: 1.003450]\n",
      "epoch:7 step:7420 [D loss: 0.632267, acc.: 61.72%] [G loss: 0.927380]\n",
      "epoch:7 step:7421 [D loss: 0.609701, acc.: 65.62%] [G loss: 0.918268]\n",
      "epoch:7 step:7422 [D loss: 0.660845, acc.: 57.81%] [G loss: 0.880572]\n",
      "epoch:7 step:7423 [D loss: 0.658817, acc.: 61.72%] [G loss: 0.902457]\n",
      "epoch:7 step:7424 [D loss: 0.673710, acc.: 62.50%] [G loss: 0.837617]\n",
      "epoch:7 step:7425 [D loss: 0.668644, acc.: 60.94%] [G loss: 0.922494]\n",
      "epoch:7 step:7426 [D loss: 0.675757, acc.: 56.25%] [G loss: 0.921747]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7427 [D loss: 0.685889, acc.: 50.78%] [G loss: 0.872510]\n",
      "epoch:7 step:7428 [D loss: 0.695847, acc.: 54.69%] [G loss: 0.931650]\n",
      "epoch:7 step:7429 [D loss: 0.676526, acc.: 54.69%] [G loss: 0.953268]\n",
      "epoch:7 step:7430 [D loss: 0.670424, acc.: 57.03%] [G loss: 0.897521]\n",
      "epoch:7 step:7431 [D loss: 0.611286, acc.: 74.22%] [G loss: 0.933739]\n",
      "epoch:7 step:7432 [D loss: 0.716737, acc.: 56.25%] [G loss: 0.888009]\n",
      "epoch:7 step:7433 [D loss: 0.671942, acc.: 61.72%] [G loss: 0.917460]\n",
      "epoch:7 step:7434 [D loss: 0.629319, acc.: 64.84%] [G loss: 0.902493]\n",
      "epoch:7 step:7435 [D loss: 0.661673, acc.: 62.50%] [G loss: 1.021091]\n",
      "epoch:7 step:7436 [D loss: 0.665637, acc.: 60.94%] [G loss: 0.899779]\n",
      "epoch:7 step:7437 [D loss: 0.710987, acc.: 50.78%] [G loss: 0.938800]\n",
      "epoch:7 step:7438 [D loss: 0.615172, acc.: 71.88%] [G loss: 0.970509]\n",
      "epoch:7 step:7439 [D loss: 0.649149, acc.: 65.62%] [G loss: 0.911007]\n",
      "epoch:7 step:7440 [D loss: 0.735461, acc.: 50.78%] [G loss: 0.886922]\n",
      "epoch:7 step:7441 [D loss: 0.703981, acc.: 60.16%] [G loss: 0.854931]\n",
      "epoch:7 step:7442 [D loss: 0.681557, acc.: 60.16%] [G loss: 0.975905]\n",
      "epoch:7 step:7443 [D loss: 0.628703, acc.: 66.41%] [G loss: 0.945509]\n",
      "epoch:7 step:7444 [D loss: 0.585539, acc.: 71.88%] [G loss: 0.905616]\n",
      "epoch:7 step:7445 [D loss: 0.625365, acc.: 59.38%] [G loss: 0.905818]\n",
      "epoch:7 step:7446 [D loss: 0.699942, acc.: 51.56%] [G loss: 0.865968]\n",
      "epoch:7 step:7447 [D loss: 0.616137, acc.: 66.41%] [G loss: 0.917590]\n",
      "epoch:7 step:7448 [D loss: 0.541033, acc.: 80.47%] [G loss: 0.982812]\n",
      "epoch:7 step:7449 [D loss: 0.570353, acc.: 73.44%] [G loss: 1.076988]\n",
      "epoch:7 step:7450 [D loss: 0.653919, acc.: 62.50%] [G loss: 1.033211]\n",
      "epoch:7 step:7451 [D loss: 0.735332, acc.: 53.12%] [G loss: 0.824597]\n",
      "epoch:7 step:7452 [D loss: 0.655780, acc.: 62.50%] [G loss: 0.870831]\n",
      "epoch:7 step:7453 [D loss: 0.681774, acc.: 58.59%] [G loss: 0.884167]\n",
      "epoch:7 step:7454 [D loss: 0.664021, acc.: 63.28%] [G loss: 0.820592]\n",
      "epoch:7 step:7455 [D loss: 0.689327, acc.: 55.47%] [G loss: 0.851698]\n",
      "epoch:7 step:7456 [D loss: 0.618117, acc.: 71.09%] [G loss: 0.878868]\n",
      "epoch:7 step:7457 [D loss: 0.657022, acc.: 60.16%] [G loss: 0.918015]\n",
      "epoch:7 step:7458 [D loss: 0.598973, acc.: 67.19%] [G loss: 0.949628]\n",
      "epoch:7 step:7459 [D loss: 0.685851, acc.: 61.72%] [G loss: 0.888166]\n",
      "epoch:7 step:7460 [D loss: 0.679154, acc.: 63.28%] [G loss: 1.052071]\n",
      "epoch:7 step:7461 [D loss: 0.675574, acc.: 57.03%] [G loss: 0.978321]\n",
      "epoch:7 step:7462 [D loss: 0.697196, acc.: 58.59%] [G loss: 0.909571]\n",
      "epoch:7 step:7463 [D loss: 0.643221, acc.: 62.50%] [G loss: 0.903297]\n",
      "epoch:7 step:7464 [D loss: 0.655580, acc.: 62.50%] [G loss: 1.037909]\n",
      "epoch:7 step:7465 [D loss: 0.644582, acc.: 65.62%] [G loss: 0.910105]\n",
      "epoch:7 step:7466 [D loss: 0.665688, acc.: 60.16%] [G loss: 0.889197]\n",
      "epoch:7 step:7467 [D loss: 0.712505, acc.: 57.03%] [G loss: 0.986431]\n",
      "epoch:7 step:7468 [D loss: 0.576559, acc.: 71.88%] [G loss: 0.985410]\n",
      "epoch:7 step:7469 [D loss: 0.578299, acc.: 72.66%] [G loss: 1.022547]\n",
      "epoch:7 step:7470 [D loss: 0.606406, acc.: 64.84%] [G loss: 0.949727]\n",
      "epoch:7 step:7471 [D loss: 0.534969, acc.: 80.47%] [G loss: 1.064259]\n",
      "epoch:7 step:7472 [D loss: 0.713655, acc.: 50.78%] [G loss: 0.999937]\n",
      "epoch:7 step:7473 [D loss: 0.691426, acc.: 53.91%] [G loss: 0.955076]\n",
      "epoch:7 step:7474 [D loss: 0.733775, acc.: 54.69%] [G loss: 0.926079]\n",
      "epoch:7 step:7475 [D loss: 0.737958, acc.: 47.66%] [G loss: 0.889355]\n",
      "epoch:7 step:7476 [D loss: 0.671761, acc.: 60.94%] [G loss: 0.881844]\n",
      "epoch:7 step:7477 [D loss: 0.573735, acc.: 75.00%] [G loss: 0.835611]\n",
      "epoch:7 step:7478 [D loss: 0.581686, acc.: 74.22%] [G loss: 1.066819]\n",
      "epoch:7 step:7479 [D loss: 0.787981, acc.: 51.56%] [G loss: 0.954232]\n",
      "epoch:7 step:7480 [D loss: 0.715931, acc.: 53.91%] [G loss: 0.886355]\n",
      "epoch:7 step:7481 [D loss: 0.527314, acc.: 78.12%] [G loss: 1.151692]\n",
      "epoch:7 step:7482 [D loss: 0.547587, acc.: 74.22%] [G loss: 1.083858]\n",
      "epoch:7 step:7483 [D loss: 0.539439, acc.: 71.09%] [G loss: 1.091927]\n",
      "epoch:7 step:7484 [D loss: 0.567438, acc.: 71.88%] [G loss: 1.156296]\n",
      "epoch:7 step:7485 [D loss: 0.582017, acc.: 66.41%] [G loss: 0.951393]\n",
      "epoch:7 step:7486 [D loss: 0.662349, acc.: 56.25%] [G loss: 0.996972]\n",
      "epoch:7 step:7487 [D loss: 0.808861, acc.: 46.09%] [G loss: 0.945343]\n",
      "epoch:7 step:7488 [D loss: 0.787390, acc.: 43.75%] [G loss: 0.783788]\n",
      "epoch:7 step:7489 [D loss: 0.544811, acc.: 75.78%] [G loss: 0.950752]\n",
      "epoch:7 step:7490 [D loss: 0.617044, acc.: 66.41%] [G loss: 0.853812]\n",
      "epoch:7 step:7491 [D loss: 0.574003, acc.: 71.09%] [G loss: 0.997614]\n",
      "epoch:7 step:7492 [D loss: 0.648797, acc.: 66.41%] [G loss: 0.942702]\n",
      "epoch:7 step:7493 [D loss: 0.661699, acc.: 60.16%] [G loss: 0.856083]\n",
      "epoch:7 step:7494 [D loss: 0.614496, acc.: 65.62%] [G loss: 0.992459]\n",
      "epoch:7 step:7495 [D loss: 0.638384, acc.: 60.94%] [G loss: 0.940050]\n",
      "epoch:7 step:7496 [D loss: 0.407997, acc.: 87.50%] [G loss: 1.261140]\n",
      "epoch:8 step:7497 [D loss: 0.684046, acc.: 57.81%] [G loss: 1.076633]\n",
      "epoch:8 step:7498 [D loss: 0.671763, acc.: 59.38%] [G loss: 1.090230]\n",
      "epoch:8 step:7499 [D loss: 0.680483, acc.: 58.59%] [G loss: 0.900899]\n",
      "epoch:8 step:7500 [D loss: 0.746140, acc.: 51.56%] [G loss: 0.851697]\n",
      "epoch:8 step:7501 [D loss: 0.626920, acc.: 64.84%] [G loss: 1.033390]\n",
      "epoch:8 step:7502 [D loss: 0.667330, acc.: 60.94%] [G loss: 0.856407]\n",
      "epoch:8 step:7503 [D loss: 0.623108, acc.: 64.06%] [G loss: 0.897774]\n",
      "epoch:8 step:7504 [D loss: 0.604686, acc.: 63.28%] [G loss: 0.991564]\n",
      "epoch:8 step:7505 [D loss: 0.641103, acc.: 58.59%] [G loss: 1.176709]\n",
      "epoch:8 step:7506 [D loss: 0.585089, acc.: 71.88%] [G loss: 1.040035]\n",
      "epoch:8 step:7507 [D loss: 0.639513, acc.: 66.41%] [G loss: 0.912285]\n",
      "epoch:8 step:7508 [D loss: 0.685702, acc.: 58.59%] [G loss: 0.825804]\n",
      "epoch:8 step:7509 [D loss: 0.604732, acc.: 67.19%] [G loss: 0.942771]\n",
      "epoch:8 step:7510 [D loss: 0.663098, acc.: 60.94%] [G loss: 0.875659]\n",
      "epoch:8 step:7511 [D loss: 0.582876, acc.: 71.88%] [G loss: 1.067401]\n",
      "epoch:8 step:7512 [D loss: 0.618612, acc.: 66.41%] [G loss: 0.951437]\n",
      "epoch:8 step:7513 [D loss: 0.754028, acc.: 50.78%] [G loss: 1.010651]\n",
      "epoch:8 step:7514 [D loss: 0.716218, acc.: 52.34%] [G loss: 0.996319]\n",
      "epoch:8 step:7515 [D loss: 0.724806, acc.: 50.00%] [G loss: 0.940220]\n",
      "epoch:8 step:7516 [D loss: 0.818455, acc.: 36.72%] [G loss: 0.829863]\n",
      "epoch:8 step:7517 [D loss: 0.810886, acc.: 40.62%] [G loss: 0.838446]\n",
      "epoch:8 step:7518 [D loss: 0.680249, acc.: 57.81%] [G loss: 0.883356]\n",
      "epoch:8 step:7519 [D loss: 0.679310, acc.: 59.38%] [G loss: 0.928640]\n",
      "epoch:8 step:7520 [D loss: 0.661274, acc.: 64.84%] [G loss: 1.044413]\n",
      "epoch:8 step:7521 [D loss: 0.588044, acc.: 71.88%] [G loss: 1.130077]\n",
      "epoch:8 step:7522 [D loss: 0.711667, acc.: 56.25%] [G loss: 1.027630]\n",
      "epoch:8 step:7523 [D loss: 0.727654, acc.: 53.91%] [G loss: 0.934942]\n",
      "epoch:8 step:7524 [D loss: 0.651310, acc.: 68.75%] [G loss: 0.969609]\n",
      "epoch:8 step:7525 [D loss: 0.671645, acc.: 60.94%] [G loss: 0.866430]\n",
      "epoch:8 step:7526 [D loss: 0.742202, acc.: 51.56%] [G loss: 0.897267]\n",
      "epoch:8 step:7527 [D loss: 0.694340, acc.: 53.12%] [G loss: 1.019080]\n",
      "epoch:8 step:7528 [D loss: 0.681964, acc.: 57.03%] [G loss: 0.981739]\n",
      "epoch:8 step:7529 [D loss: 0.616123, acc.: 68.75%] [G loss: 1.008069]\n",
      "epoch:8 step:7530 [D loss: 0.600266, acc.: 72.66%] [G loss: 1.033943]\n",
      "epoch:8 step:7531 [D loss: 0.652203, acc.: 57.03%] [G loss: 0.955699]\n",
      "epoch:8 step:7532 [D loss: 0.572501, acc.: 66.41%] [G loss: 0.955889]\n",
      "epoch:8 step:7533 [D loss: 0.628708, acc.: 59.38%] [G loss: 0.997817]\n",
      "epoch:8 step:7534 [D loss: 0.686636, acc.: 51.56%] [G loss: 0.880176]\n",
      "epoch:8 step:7535 [D loss: 0.671894, acc.: 57.03%] [G loss: 0.934936]\n",
      "epoch:8 step:7536 [D loss: 0.585043, acc.: 68.75%] [G loss: 0.980210]\n",
      "epoch:8 step:7537 [D loss: 0.719049, acc.: 46.88%] [G loss: 0.945313]\n",
      "epoch:8 step:7538 [D loss: 0.596395, acc.: 67.19%] [G loss: 0.968667]\n",
      "epoch:8 step:7539 [D loss: 0.652084, acc.: 64.06%] [G loss: 0.960390]\n",
      "epoch:8 step:7540 [D loss: 0.747111, acc.: 49.22%] [G loss: 0.942458]\n",
      "epoch:8 step:7541 [D loss: 0.696846, acc.: 57.03%] [G loss: 0.851983]\n",
      "epoch:8 step:7542 [D loss: 0.659362, acc.: 57.81%] [G loss: 0.788742]\n",
      "epoch:8 step:7543 [D loss: 0.585851, acc.: 71.88%] [G loss: 0.908611]\n",
      "epoch:8 step:7544 [D loss: 0.637411, acc.: 64.84%] [G loss: 0.795992]\n",
      "epoch:8 step:7545 [D loss: 0.670675, acc.: 59.38%] [G loss: 0.975766]\n",
      "epoch:8 step:7546 [D loss: 0.663425, acc.: 54.69%] [G loss: 0.853672]\n",
      "epoch:8 step:7547 [D loss: 0.689611, acc.: 56.25%] [G loss: 0.928652]\n",
      "epoch:8 step:7548 [D loss: 0.615556, acc.: 64.84%] [G loss: 1.081400]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7549 [D loss: 0.629666, acc.: 67.19%] [G loss: 0.966122]\n",
      "epoch:8 step:7550 [D loss: 0.610014, acc.: 63.28%] [G loss: 0.969252]\n",
      "epoch:8 step:7551 [D loss: 0.641117, acc.: 63.28%] [G loss: 0.921275]\n",
      "epoch:8 step:7552 [D loss: 0.657796, acc.: 60.16%] [G loss: 1.032991]\n",
      "epoch:8 step:7553 [D loss: 0.689006, acc.: 51.56%] [G loss: 0.872286]\n",
      "epoch:8 step:7554 [D loss: 0.715711, acc.: 47.66%] [G loss: 0.892777]\n",
      "epoch:8 step:7555 [D loss: 0.758827, acc.: 48.44%] [G loss: 0.932927]\n",
      "epoch:8 step:7556 [D loss: 0.650532, acc.: 62.50%] [G loss: 0.954608]\n",
      "epoch:8 step:7557 [D loss: 0.670563, acc.: 61.72%] [G loss: 0.979241]\n",
      "epoch:8 step:7558 [D loss: 0.669209, acc.: 59.38%] [G loss: 1.034596]\n",
      "epoch:8 step:7559 [D loss: 0.703877, acc.: 52.34%] [G loss: 0.971268]\n",
      "epoch:8 step:7560 [D loss: 0.666843, acc.: 59.38%] [G loss: 0.908442]\n",
      "epoch:8 step:7561 [D loss: 0.599741, acc.: 67.97%] [G loss: 0.946066]\n",
      "epoch:8 step:7562 [D loss: 0.697258, acc.: 59.38%] [G loss: 1.041761]\n",
      "epoch:8 step:7563 [D loss: 0.654337, acc.: 57.03%] [G loss: 0.964726]\n",
      "epoch:8 step:7564 [D loss: 0.692202, acc.: 54.69%] [G loss: 0.939522]\n",
      "epoch:8 step:7565 [D loss: 0.678794, acc.: 62.50%] [G loss: 0.904143]\n",
      "epoch:8 step:7566 [D loss: 0.641093, acc.: 65.62%] [G loss: 0.965334]\n",
      "epoch:8 step:7567 [D loss: 0.698151, acc.: 55.47%] [G loss: 1.033542]\n",
      "epoch:8 step:7568 [D loss: 0.570984, acc.: 70.31%] [G loss: 0.998361]\n",
      "epoch:8 step:7569 [D loss: 0.705320, acc.: 50.78%] [G loss: 0.928198]\n",
      "epoch:8 step:7570 [D loss: 0.594712, acc.: 71.09%] [G loss: 0.997456]\n",
      "epoch:8 step:7571 [D loss: 0.648796, acc.: 60.94%] [G loss: 0.895418]\n",
      "epoch:8 step:7572 [D loss: 0.599852, acc.: 71.09%] [G loss: 0.855376]\n",
      "epoch:8 step:7573 [D loss: 0.615453, acc.: 70.31%] [G loss: 0.986308]\n",
      "epoch:8 step:7574 [D loss: 0.691290, acc.: 57.03%] [G loss: 0.890373]\n",
      "epoch:8 step:7575 [D loss: 0.759793, acc.: 51.56%] [G loss: 0.903185]\n",
      "epoch:8 step:7576 [D loss: 0.665187, acc.: 62.50%] [G loss: 1.015186]\n",
      "epoch:8 step:7577 [D loss: 0.685430, acc.: 58.59%] [G loss: 0.917024]\n",
      "epoch:8 step:7578 [D loss: 0.725978, acc.: 50.78%] [G loss: 0.841638]\n",
      "epoch:8 step:7579 [D loss: 0.651611, acc.: 60.94%] [G loss: 0.874720]\n",
      "epoch:8 step:7580 [D loss: 0.684318, acc.: 56.25%] [G loss: 0.945279]\n",
      "epoch:8 step:7581 [D loss: 0.672667, acc.: 58.59%] [G loss: 0.866448]\n",
      "epoch:8 step:7582 [D loss: 0.619431, acc.: 69.53%] [G loss: 0.909503]\n",
      "epoch:8 step:7583 [D loss: 0.645389, acc.: 59.38%] [G loss: 0.924514]\n",
      "epoch:8 step:7584 [D loss: 0.702201, acc.: 58.59%] [G loss: 0.880903]\n",
      "epoch:8 step:7585 [D loss: 0.657503, acc.: 60.94%] [G loss: 0.986717]\n",
      "epoch:8 step:7586 [D loss: 0.698904, acc.: 55.47%] [G loss: 0.947390]\n",
      "epoch:8 step:7587 [D loss: 0.642636, acc.: 62.50%] [G loss: 0.987430]\n",
      "epoch:8 step:7588 [D loss: 0.738725, acc.: 51.56%] [G loss: 0.871761]\n",
      "epoch:8 step:7589 [D loss: 0.745713, acc.: 49.22%] [G loss: 0.882458]\n",
      "epoch:8 step:7590 [D loss: 0.722988, acc.: 53.91%] [G loss: 0.909025]\n",
      "epoch:8 step:7591 [D loss: 0.687352, acc.: 54.69%] [G loss: 0.921340]\n",
      "epoch:8 step:7592 [D loss: 0.691240, acc.: 52.34%] [G loss: 0.967189]\n",
      "epoch:8 step:7593 [D loss: 0.665401, acc.: 60.94%] [G loss: 0.967487]\n",
      "epoch:8 step:7594 [D loss: 0.722416, acc.: 47.66%] [G loss: 0.874973]\n",
      "epoch:8 step:7595 [D loss: 0.671713, acc.: 52.34%] [G loss: 1.004538]\n",
      "epoch:8 step:7596 [D loss: 0.671888, acc.: 60.94%] [G loss: 0.874011]\n",
      "epoch:8 step:7597 [D loss: 0.673190, acc.: 56.25%] [G loss: 0.958277]\n",
      "epoch:8 step:7598 [D loss: 0.644201, acc.: 66.41%] [G loss: 0.866745]\n",
      "epoch:8 step:7599 [D loss: 0.628646, acc.: 67.19%] [G loss: 0.991606]\n",
      "epoch:8 step:7600 [D loss: 0.634065, acc.: 63.28%] [G loss: 1.008475]\n",
      "##############\n",
      "[2.27054036 1.06609496 5.48300906 4.23329985 2.66038218 5.1404264\n",
      " 4.07182269 4.64411303 3.75965001 3.68164247]\n",
      "##########\n",
      "epoch:8 step:7601 [D loss: 0.695991, acc.: 51.56%] [G loss: 0.877203]\n",
      "epoch:8 step:7602 [D loss: 0.685034, acc.: 60.94%] [G loss: 0.967810]\n",
      "epoch:8 step:7603 [D loss: 0.670048, acc.: 60.94%] [G loss: 0.960465]\n",
      "epoch:8 step:7604 [D loss: 0.703807, acc.: 54.69%] [G loss: 0.898844]\n",
      "epoch:8 step:7605 [D loss: 0.693665, acc.: 55.47%] [G loss: 0.875332]\n",
      "epoch:8 step:7606 [D loss: 0.675913, acc.: 59.38%] [G loss: 0.899830]\n",
      "epoch:8 step:7607 [D loss: 0.629790, acc.: 69.53%] [G loss: 0.945343]\n",
      "epoch:8 step:7608 [D loss: 0.656798, acc.: 57.81%] [G loss: 0.938004]\n",
      "epoch:8 step:7609 [D loss: 0.655493, acc.: 60.16%] [G loss: 0.954032]\n",
      "epoch:8 step:7610 [D loss: 0.665525, acc.: 52.34%] [G loss: 0.936580]\n",
      "epoch:8 step:7611 [D loss: 0.570817, acc.: 72.66%] [G loss: 1.096907]\n",
      "epoch:8 step:7612 [D loss: 0.663497, acc.: 60.94%] [G loss: 0.930331]\n",
      "epoch:8 step:7613 [D loss: 0.665769, acc.: 60.16%] [G loss: 0.862900]\n",
      "epoch:8 step:7614 [D loss: 0.701694, acc.: 54.69%] [G loss: 0.864567]\n",
      "epoch:8 step:7615 [D loss: 0.672088, acc.: 58.59%] [G loss: 1.084588]\n",
      "epoch:8 step:7616 [D loss: 0.736144, acc.: 50.00%] [G loss: 0.977513]\n",
      "epoch:8 step:7617 [D loss: 0.667385, acc.: 57.81%] [G loss: 0.980778]\n",
      "epoch:8 step:7618 [D loss: 0.698685, acc.: 52.34%] [G loss: 0.987476]\n",
      "epoch:8 step:7619 [D loss: 0.621173, acc.: 65.62%] [G loss: 0.952222]\n",
      "epoch:8 step:7620 [D loss: 0.685323, acc.: 56.25%] [G loss: 0.870206]\n",
      "epoch:8 step:7621 [D loss: 0.631430, acc.: 66.41%] [G loss: 1.018132]\n",
      "epoch:8 step:7622 [D loss: 0.679189, acc.: 57.03%] [G loss: 1.071581]\n",
      "epoch:8 step:7623 [D loss: 0.667834, acc.: 54.69%] [G loss: 0.930140]\n",
      "epoch:8 step:7624 [D loss: 0.693857, acc.: 55.47%] [G loss: 0.951866]\n",
      "epoch:8 step:7625 [D loss: 0.726348, acc.: 46.88%] [G loss: 0.974523]\n",
      "epoch:8 step:7626 [D loss: 0.635439, acc.: 60.94%] [G loss: 0.926070]\n",
      "epoch:8 step:7627 [D loss: 0.639643, acc.: 57.03%] [G loss: 0.858220]\n",
      "epoch:8 step:7628 [D loss: 0.678214, acc.: 53.91%] [G loss: 0.926064]\n",
      "epoch:8 step:7629 [D loss: 0.756341, acc.: 47.66%] [G loss: 0.893970]\n",
      "epoch:8 step:7630 [D loss: 0.685213, acc.: 56.25%] [G loss: 0.966021]\n",
      "epoch:8 step:7631 [D loss: 0.742154, acc.: 46.88%] [G loss: 0.915583]\n",
      "epoch:8 step:7632 [D loss: 0.831867, acc.: 35.16%] [G loss: 0.862770]\n",
      "epoch:8 step:7633 [D loss: 0.738994, acc.: 42.97%] [G loss: 0.820012]\n",
      "epoch:8 step:7634 [D loss: 0.692946, acc.: 50.78%] [G loss: 0.964987]\n",
      "epoch:8 step:7635 [D loss: 0.696131, acc.: 58.59%] [G loss: 0.898902]\n",
      "epoch:8 step:7636 [D loss: 0.673007, acc.: 55.47%] [G loss: 0.946305]\n",
      "epoch:8 step:7637 [D loss: 0.670376, acc.: 61.72%] [G loss: 0.918465]\n",
      "epoch:8 step:7638 [D loss: 0.660294, acc.: 59.38%] [G loss: 1.057213]\n",
      "epoch:8 step:7639 [D loss: 0.691639, acc.: 53.12%] [G loss: 0.937614]\n",
      "epoch:8 step:7640 [D loss: 0.620282, acc.: 69.53%] [G loss: 0.918492]\n",
      "epoch:8 step:7641 [D loss: 0.702674, acc.: 52.34%] [G loss: 0.939837]\n",
      "epoch:8 step:7642 [D loss: 0.677248, acc.: 55.47%] [G loss: 0.949260]\n",
      "epoch:8 step:7643 [D loss: 0.654582, acc.: 62.50%] [G loss: 0.875207]\n",
      "epoch:8 step:7644 [D loss: 0.652145, acc.: 62.50%] [G loss: 0.874907]\n",
      "epoch:8 step:7645 [D loss: 0.678818, acc.: 54.69%] [G loss: 1.120590]\n",
      "epoch:8 step:7646 [D loss: 0.689479, acc.: 57.03%] [G loss: 0.838458]\n",
      "epoch:8 step:7647 [D loss: 0.604194, acc.: 71.09%] [G loss: 0.849878]\n",
      "epoch:8 step:7648 [D loss: 0.584958, acc.: 70.31%] [G loss: 1.005610]\n",
      "epoch:8 step:7649 [D loss: 0.695707, acc.: 57.03%] [G loss: 0.971161]\n",
      "epoch:8 step:7650 [D loss: 0.685505, acc.: 61.72%] [G loss: 0.938822]\n",
      "epoch:8 step:7651 [D loss: 0.704622, acc.: 50.00%] [G loss: 1.013029]\n",
      "epoch:8 step:7652 [D loss: 0.671540, acc.: 58.59%] [G loss: 0.910949]\n",
      "epoch:8 step:7653 [D loss: 0.675278, acc.: 60.94%] [G loss: 0.930302]\n",
      "epoch:8 step:7654 [D loss: 0.660684, acc.: 61.72%] [G loss: 0.874847]\n",
      "epoch:8 step:7655 [D loss: 0.693873, acc.: 55.47%] [G loss: 0.800020]\n",
      "epoch:8 step:7656 [D loss: 0.827929, acc.: 38.28%] [G loss: 0.818807]\n",
      "epoch:8 step:7657 [D loss: 0.811603, acc.: 34.38%] [G loss: 0.955579]\n",
      "epoch:8 step:7658 [D loss: 0.596272, acc.: 66.41%] [G loss: 1.020647]\n",
      "epoch:8 step:7659 [D loss: 0.706177, acc.: 50.78%] [G loss: 0.860803]\n",
      "epoch:8 step:7660 [D loss: 0.653927, acc.: 59.38%] [G loss: 0.868726]\n",
      "epoch:8 step:7661 [D loss: 0.699595, acc.: 56.25%] [G loss: 0.827284]\n",
      "epoch:8 step:7662 [D loss: 0.629169, acc.: 63.28%] [G loss: 0.894277]\n",
      "epoch:8 step:7663 [D loss: 0.688743, acc.: 50.78%] [G loss: 0.951162]\n",
      "epoch:8 step:7664 [D loss: 0.671124, acc.: 56.25%] [G loss: 0.876824]\n",
      "epoch:8 step:7665 [D loss: 0.630142, acc.: 60.94%] [G loss: 0.886501]\n",
      "epoch:8 step:7666 [D loss: 0.733533, acc.: 51.56%] [G loss: 0.849042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7667 [D loss: 0.618114, acc.: 68.75%] [G loss: 0.881396]\n",
      "epoch:8 step:7668 [D loss: 0.711712, acc.: 53.12%] [G loss: 0.838802]\n",
      "epoch:8 step:7669 [D loss: 0.714966, acc.: 50.00%] [G loss: 0.867607]\n",
      "epoch:8 step:7670 [D loss: 0.688405, acc.: 56.25%] [G loss: 0.896947]\n",
      "epoch:8 step:7671 [D loss: 0.617472, acc.: 64.06%] [G loss: 0.862810]\n",
      "epoch:8 step:7672 [D loss: 0.670092, acc.: 57.81%] [G loss: 0.835843]\n",
      "epoch:8 step:7673 [D loss: 0.641314, acc.: 64.84%] [G loss: 0.825115]\n",
      "epoch:8 step:7674 [D loss: 0.733927, acc.: 51.56%] [G loss: 0.870104]\n",
      "epoch:8 step:7675 [D loss: 0.622068, acc.: 67.97%] [G loss: 0.914925]\n",
      "epoch:8 step:7676 [D loss: 0.686818, acc.: 60.16%] [G loss: 0.923131]\n",
      "epoch:8 step:7677 [D loss: 0.694983, acc.: 58.59%] [G loss: 0.833858]\n",
      "epoch:8 step:7678 [D loss: 0.741352, acc.: 46.09%] [G loss: 0.825291]\n",
      "epoch:8 step:7679 [D loss: 0.727053, acc.: 50.78%] [G loss: 0.915892]\n",
      "epoch:8 step:7680 [D loss: 0.669040, acc.: 57.81%] [G loss: 1.018545]\n",
      "epoch:8 step:7681 [D loss: 0.672766, acc.: 55.47%] [G loss: 0.788708]\n",
      "epoch:8 step:7682 [D loss: 0.645238, acc.: 64.84%] [G loss: 0.955419]\n",
      "epoch:8 step:7683 [D loss: 0.692628, acc.: 55.47%] [G loss: 0.902530]\n",
      "epoch:8 step:7684 [D loss: 0.645730, acc.: 61.72%] [G loss: 0.887556]\n",
      "epoch:8 step:7685 [D loss: 0.682611, acc.: 54.69%] [G loss: 0.931004]\n",
      "epoch:8 step:7686 [D loss: 0.635565, acc.: 63.28%] [G loss: 0.863612]\n",
      "epoch:8 step:7687 [D loss: 0.586077, acc.: 71.09%] [G loss: 1.049286]\n",
      "epoch:8 step:7688 [D loss: 0.647707, acc.: 60.16%] [G loss: 0.939654]\n",
      "epoch:8 step:7689 [D loss: 0.659776, acc.: 62.50%] [G loss: 0.973960]\n",
      "epoch:8 step:7690 [D loss: 0.701834, acc.: 53.91%] [G loss: 0.934437]\n",
      "epoch:8 step:7691 [D loss: 0.678027, acc.: 58.59%] [G loss: 0.827369]\n",
      "epoch:8 step:7692 [D loss: 0.746058, acc.: 46.09%] [G loss: 0.891196]\n",
      "epoch:8 step:7693 [D loss: 0.724508, acc.: 50.78%] [G loss: 0.840666]\n",
      "epoch:8 step:7694 [D loss: 0.683326, acc.: 64.06%] [G loss: 0.774634]\n",
      "epoch:8 step:7695 [D loss: 0.697158, acc.: 53.12%] [G loss: 0.922609]\n",
      "epoch:8 step:7696 [D loss: 0.677247, acc.: 60.16%] [G loss: 0.910671]\n",
      "epoch:8 step:7697 [D loss: 0.750445, acc.: 45.31%] [G loss: 0.857535]\n",
      "epoch:8 step:7698 [D loss: 0.753922, acc.: 51.56%] [G loss: 0.821929]\n",
      "epoch:8 step:7699 [D loss: 0.618346, acc.: 67.19%] [G loss: 1.067254]\n",
      "epoch:8 step:7700 [D loss: 0.665258, acc.: 62.50%] [G loss: 0.913136]\n",
      "epoch:8 step:7701 [D loss: 0.630002, acc.: 62.50%] [G loss: 0.840353]\n",
      "epoch:8 step:7702 [D loss: 0.664638, acc.: 60.94%] [G loss: 0.907279]\n",
      "epoch:8 step:7703 [D loss: 0.598322, acc.: 69.53%] [G loss: 0.993354]\n",
      "epoch:8 step:7704 [D loss: 0.586400, acc.: 71.09%] [G loss: 1.022073]\n",
      "epoch:8 step:7705 [D loss: 0.576157, acc.: 67.97%] [G loss: 1.083509]\n",
      "epoch:8 step:7706 [D loss: 0.646238, acc.: 64.06%] [G loss: 0.890152]\n",
      "epoch:8 step:7707 [D loss: 0.718450, acc.: 54.69%] [G loss: 0.840737]\n",
      "epoch:8 step:7708 [D loss: 0.638804, acc.: 63.28%] [G loss: 1.029303]\n",
      "epoch:8 step:7709 [D loss: 0.635635, acc.: 64.06%] [G loss: 1.084861]\n",
      "epoch:8 step:7710 [D loss: 0.786294, acc.: 40.62%] [G loss: 0.842234]\n",
      "epoch:8 step:7711 [D loss: 0.780001, acc.: 45.31%] [G loss: 0.915665]\n",
      "epoch:8 step:7712 [D loss: 0.681640, acc.: 57.03%] [G loss: 0.876099]\n",
      "epoch:8 step:7713 [D loss: 0.651538, acc.: 63.28%] [G loss: 0.900487]\n",
      "epoch:8 step:7714 [D loss: 0.631533, acc.: 67.97%] [G loss: 0.946117]\n",
      "epoch:8 step:7715 [D loss: 0.559599, acc.: 71.09%] [G loss: 0.966756]\n",
      "epoch:8 step:7716 [D loss: 0.758246, acc.: 46.88%] [G loss: 0.941222]\n",
      "epoch:8 step:7717 [D loss: 0.716191, acc.: 53.12%] [G loss: 0.917374]\n",
      "epoch:8 step:7718 [D loss: 0.696175, acc.: 54.69%] [G loss: 1.034627]\n",
      "epoch:8 step:7719 [D loss: 0.673019, acc.: 56.25%] [G loss: 1.130911]\n",
      "epoch:8 step:7720 [D loss: 0.724368, acc.: 52.34%] [G loss: 0.819872]\n",
      "epoch:8 step:7721 [D loss: 0.671095, acc.: 63.28%] [G loss: 0.928046]\n",
      "epoch:8 step:7722 [D loss: 0.721470, acc.: 54.69%] [G loss: 0.936156]\n",
      "epoch:8 step:7723 [D loss: 0.753255, acc.: 52.34%] [G loss: 0.833887]\n",
      "epoch:8 step:7724 [D loss: 0.783887, acc.: 43.75%] [G loss: 0.708654]\n",
      "epoch:8 step:7725 [D loss: 0.702973, acc.: 53.91%] [G loss: 0.922929]\n",
      "epoch:8 step:7726 [D loss: 0.614829, acc.: 68.75%] [G loss: 0.956352]\n",
      "epoch:8 step:7727 [D loss: 0.640949, acc.: 63.28%] [G loss: 0.863867]\n",
      "epoch:8 step:7728 [D loss: 0.577954, acc.: 71.88%] [G loss: 0.939314]\n",
      "epoch:8 step:7729 [D loss: 0.678438, acc.: 57.03%] [G loss: 0.977975]\n",
      "epoch:8 step:7730 [D loss: 0.743517, acc.: 50.00%] [G loss: 1.009719]\n",
      "epoch:8 step:7731 [D loss: 0.660949, acc.: 57.81%] [G loss: 0.901672]\n",
      "epoch:8 step:7732 [D loss: 0.627378, acc.: 60.16%] [G loss: 0.931226]\n",
      "epoch:8 step:7733 [D loss: 0.643489, acc.: 61.72%] [G loss: 0.938774]\n",
      "epoch:8 step:7734 [D loss: 0.662691, acc.: 62.50%] [G loss: 0.913882]\n",
      "epoch:8 step:7735 [D loss: 0.659935, acc.: 59.38%] [G loss: 0.983004]\n",
      "epoch:8 step:7736 [D loss: 0.659907, acc.: 60.16%] [G loss: 0.798552]\n",
      "epoch:8 step:7737 [D loss: 0.663870, acc.: 60.94%] [G loss: 0.970002]\n",
      "epoch:8 step:7738 [D loss: 0.729713, acc.: 49.22%] [G loss: 0.870202]\n",
      "epoch:8 step:7739 [D loss: 0.701070, acc.: 58.59%] [G loss: 0.952309]\n",
      "epoch:8 step:7740 [D loss: 0.628158, acc.: 65.62%] [G loss: 1.043309]\n",
      "epoch:8 step:7741 [D loss: 0.645794, acc.: 65.62%] [G loss: 0.866487]\n",
      "epoch:8 step:7742 [D loss: 0.732924, acc.: 48.44%] [G loss: 0.855593]\n",
      "epoch:8 step:7743 [D loss: 0.631151, acc.: 66.41%] [G loss: 0.918544]\n",
      "epoch:8 step:7744 [D loss: 0.689645, acc.: 52.34%] [G loss: 0.939340]\n",
      "epoch:8 step:7745 [D loss: 0.671153, acc.: 57.81%] [G loss: 0.779699]\n",
      "epoch:8 step:7746 [D loss: 0.758630, acc.: 53.12%] [G loss: 0.918556]\n",
      "epoch:8 step:7747 [D loss: 0.660008, acc.: 59.38%] [G loss: 0.892142]\n",
      "epoch:8 step:7748 [D loss: 0.630815, acc.: 64.06%] [G loss: 0.885370]\n",
      "epoch:8 step:7749 [D loss: 0.712276, acc.: 49.22%] [G loss: 0.881339]\n",
      "epoch:8 step:7750 [D loss: 0.659749, acc.: 62.50%] [G loss: 0.978127]\n",
      "epoch:8 step:7751 [D loss: 0.603656, acc.: 64.84%] [G loss: 0.931311]\n",
      "epoch:8 step:7752 [D loss: 0.648010, acc.: 64.06%] [G loss: 0.926009]\n",
      "epoch:8 step:7753 [D loss: 0.617748, acc.: 64.84%] [G loss: 0.895755]\n",
      "epoch:8 step:7754 [D loss: 0.702575, acc.: 57.81%] [G loss: 0.858541]\n",
      "epoch:8 step:7755 [D loss: 0.624212, acc.: 60.94%] [G loss: 0.987029]\n",
      "epoch:8 step:7756 [D loss: 0.604661, acc.: 62.50%] [G loss: 0.926290]\n",
      "epoch:8 step:7757 [D loss: 0.672210, acc.: 62.50%] [G loss: 0.901762]\n",
      "epoch:8 step:7758 [D loss: 0.671167, acc.: 58.59%] [G loss: 0.836557]\n",
      "epoch:8 step:7759 [D loss: 0.694455, acc.: 52.34%] [G loss: 0.933643]\n",
      "epoch:8 step:7760 [D loss: 0.646950, acc.: 62.50%] [G loss: 0.888287]\n",
      "epoch:8 step:7761 [D loss: 0.691638, acc.: 56.25%] [G loss: 0.836307]\n",
      "epoch:8 step:7762 [D loss: 0.726194, acc.: 50.78%] [G loss: 0.865451]\n",
      "epoch:8 step:7763 [D loss: 0.680894, acc.: 53.91%] [G loss: 0.961792]\n",
      "epoch:8 step:7764 [D loss: 0.733314, acc.: 53.12%] [G loss: 0.797334]\n",
      "epoch:8 step:7765 [D loss: 0.733657, acc.: 51.56%] [G loss: 0.877067]\n",
      "epoch:8 step:7766 [D loss: 0.642115, acc.: 60.94%] [G loss: 0.920729]\n",
      "epoch:8 step:7767 [D loss: 0.661298, acc.: 60.94%] [G loss: 0.948067]\n",
      "epoch:8 step:7768 [D loss: 0.641807, acc.: 63.28%] [G loss: 0.870162]\n",
      "epoch:8 step:7769 [D loss: 0.595265, acc.: 71.88%] [G loss: 1.061508]\n",
      "epoch:8 step:7770 [D loss: 0.641480, acc.: 64.06%] [G loss: 0.932110]\n",
      "epoch:8 step:7771 [D loss: 0.719543, acc.: 51.56%] [G loss: 0.834119]\n",
      "epoch:8 step:7772 [D loss: 0.716139, acc.: 60.16%] [G loss: 0.831215]\n",
      "epoch:8 step:7773 [D loss: 0.605944, acc.: 68.75%] [G loss: 0.914573]\n",
      "epoch:8 step:7774 [D loss: 0.613202, acc.: 67.97%] [G loss: 0.907379]\n",
      "epoch:8 step:7775 [D loss: 0.663855, acc.: 60.16%] [G loss: 0.946334]\n",
      "epoch:8 step:7776 [D loss: 0.651772, acc.: 61.72%] [G loss: 0.902940]\n",
      "epoch:8 step:7777 [D loss: 0.706055, acc.: 62.50%] [G loss: 0.925813]\n",
      "epoch:8 step:7778 [D loss: 0.692534, acc.: 56.25%] [G loss: 1.044946]\n",
      "epoch:8 step:7779 [D loss: 0.731453, acc.: 53.91%] [G loss: 0.842917]\n",
      "epoch:8 step:7780 [D loss: 0.634341, acc.: 61.72%] [G loss: 0.841181]\n",
      "epoch:8 step:7781 [D loss: 0.628527, acc.: 65.62%] [G loss: 0.965304]\n",
      "epoch:8 step:7782 [D loss: 0.669606, acc.: 64.06%] [G loss: 0.916875]\n",
      "epoch:8 step:7783 [D loss: 0.639827, acc.: 60.94%] [G loss: 0.965208]\n",
      "epoch:8 step:7784 [D loss: 0.657190, acc.: 58.59%] [G loss: 0.881959]\n",
      "epoch:8 step:7785 [D loss: 0.630796, acc.: 69.53%] [G loss: 0.867242]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7786 [D loss: 0.730300, acc.: 46.09%] [G loss: 0.851446]\n",
      "epoch:8 step:7787 [D loss: 0.689977, acc.: 59.38%] [G loss: 0.912548]\n",
      "epoch:8 step:7788 [D loss: 0.742680, acc.: 50.78%] [G loss: 0.898053]\n",
      "epoch:8 step:7789 [D loss: 0.624499, acc.: 63.28%] [G loss: 0.955875]\n",
      "epoch:8 step:7790 [D loss: 0.625852, acc.: 67.19%] [G loss: 0.941626]\n",
      "epoch:8 step:7791 [D loss: 0.658507, acc.: 57.81%] [G loss: 0.986665]\n",
      "epoch:8 step:7792 [D loss: 0.568017, acc.: 71.88%] [G loss: 1.081872]\n",
      "epoch:8 step:7793 [D loss: 0.687262, acc.: 55.47%] [G loss: 0.811048]\n",
      "epoch:8 step:7794 [D loss: 0.638843, acc.: 65.62%] [G loss: 1.154560]\n",
      "epoch:8 step:7795 [D loss: 0.605291, acc.: 68.75%] [G loss: 0.935113]\n",
      "epoch:8 step:7796 [D loss: 0.680490, acc.: 60.16%] [G loss: 0.919488]\n",
      "epoch:8 step:7797 [D loss: 0.714748, acc.: 51.56%] [G loss: 0.923165]\n",
      "epoch:8 step:7798 [D loss: 0.643196, acc.: 60.94%] [G loss: 1.029858]\n",
      "epoch:8 step:7799 [D loss: 0.705778, acc.: 53.12%] [G loss: 0.999195]\n",
      "epoch:8 step:7800 [D loss: 0.658831, acc.: 59.38%] [G loss: 0.888372]\n",
      "##############\n",
      "[1.93865578 1.53579215 5.50380884 4.28410375 2.92288446 5.14380144\n",
      " 3.83328219 4.49004297 3.60475782 3.24408977]\n",
      "##########\n",
      "epoch:8 step:7801 [D loss: 0.634997, acc.: 65.62%] [G loss: 0.953095]\n",
      "epoch:8 step:7802 [D loss: 0.665786, acc.: 60.94%] [G loss: 0.891994]\n",
      "epoch:8 step:7803 [D loss: 0.622515, acc.: 66.41%] [G loss: 0.895197]\n",
      "epoch:8 step:7804 [D loss: 0.669194, acc.: 58.59%] [G loss: 0.902861]\n",
      "epoch:8 step:7805 [D loss: 0.727813, acc.: 55.47%] [G loss: 0.841204]\n",
      "epoch:8 step:7806 [D loss: 0.667318, acc.: 56.25%] [G loss: 0.924752]\n",
      "epoch:8 step:7807 [D loss: 0.643094, acc.: 59.38%] [G loss: 1.012213]\n",
      "epoch:8 step:7808 [D loss: 0.634169, acc.: 63.28%] [G loss: 0.951301]\n",
      "epoch:8 step:7809 [D loss: 0.580530, acc.: 67.19%] [G loss: 0.982657]\n",
      "epoch:8 step:7810 [D loss: 0.520792, acc.: 77.34%] [G loss: 1.173004]\n",
      "epoch:8 step:7811 [D loss: 0.577199, acc.: 75.00%] [G loss: 1.076466]\n",
      "epoch:8 step:7812 [D loss: 0.712639, acc.: 53.12%] [G loss: 1.036938]\n",
      "epoch:8 step:7813 [D loss: 0.639882, acc.: 59.38%] [G loss: 0.988356]\n",
      "epoch:8 step:7814 [D loss: 0.691916, acc.: 57.03%] [G loss: 0.979749]\n",
      "epoch:8 step:7815 [D loss: 0.708958, acc.: 53.12%] [G loss: 0.684821]\n",
      "epoch:8 step:7816 [D loss: 0.683531, acc.: 60.16%] [G loss: 0.930791]\n",
      "epoch:8 step:7817 [D loss: 0.688326, acc.: 58.59%] [G loss: 0.942300]\n",
      "epoch:8 step:7818 [D loss: 0.622262, acc.: 66.41%] [G loss: 0.938512]\n",
      "epoch:8 step:7819 [D loss: 0.723805, acc.: 51.56%] [G loss: 0.834845]\n",
      "epoch:8 step:7820 [D loss: 0.656861, acc.: 57.03%] [G loss: 0.941183]\n",
      "epoch:8 step:7821 [D loss: 0.683487, acc.: 58.59%] [G loss: 0.914666]\n",
      "epoch:8 step:7822 [D loss: 0.704699, acc.: 56.25%] [G loss: 0.936629]\n",
      "epoch:8 step:7823 [D loss: 0.627647, acc.: 63.28%] [G loss: 0.939558]\n",
      "epoch:8 step:7824 [D loss: 0.672039, acc.: 56.25%] [G loss: 0.952554]\n",
      "epoch:8 step:7825 [D loss: 0.671616, acc.: 53.91%] [G loss: 0.932345]\n",
      "epoch:8 step:7826 [D loss: 0.607746, acc.: 64.84%] [G loss: 1.126609]\n",
      "epoch:8 step:7827 [D loss: 0.688038, acc.: 57.03%] [G loss: 0.962726]\n",
      "epoch:8 step:7828 [D loss: 0.627267, acc.: 63.28%] [G loss: 0.814021]\n",
      "epoch:8 step:7829 [D loss: 0.631103, acc.: 64.06%] [G loss: 1.032934]\n",
      "epoch:8 step:7830 [D loss: 0.668569, acc.: 57.81%] [G loss: 0.883944]\n",
      "epoch:8 step:7831 [D loss: 0.675993, acc.: 61.72%] [G loss: 0.838904]\n",
      "epoch:8 step:7832 [D loss: 0.637430, acc.: 67.19%] [G loss: 0.960681]\n",
      "epoch:8 step:7833 [D loss: 0.582406, acc.: 69.53%] [G loss: 0.888400]\n",
      "epoch:8 step:7834 [D loss: 0.619981, acc.: 64.84%] [G loss: 0.975949]\n",
      "epoch:8 step:7835 [D loss: 0.707882, acc.: 55.47%] [G loss: 0.946162]\n",
      "epoch:8 step:7836 [D loss: 0.684180, acc.: 59.38%] [G loss: 0.961074]\n",
      "epoch:8 step:7837 [D loss: 0.662889, acc.: 61.72%] [G loss: 0.862873]\n",
      "epoch:8 step:7838 [D loss: 0.640551, acc.: 60.94%] [G loss: 0.877324]\n",
      "epoch:8 step:7839 [D loss: 0.608655, acc.: 69.53%] [G loss: 1.021972]\n",
      "epoch:8 step:7840 [D loss: 0.670385, acc.: 57.03%] [G loss: 0.870053]\n",
      "epoch:8 step:7841 [D loss: 0.629514, acc.: 61.72%] [G loss: 0.864306]\n",
      "epoch:8 step:7842 [D loss: 0.590441, acc.: 67.19%] [G loss: 1.127230]\n",
      "epoch:8 step:7843 [D loss: 0.662738, acc.: 63.28%] [G loss: 1.035506]\n",
      "epoch:8 step:7844 [D loss: 0.741594, acc.: 52.34%] [G loss: 0.941183]\n",
      "epoch:8 step:7845 [D loss: 0.749099, acc.: 47.66%] [G loss: 0.846526]\n",
      "epoch:8 step:7846 [D loss: 0.673832, acc.: 58.59%] [G loss: 0.846560]\n",
      "epoch:8 step:7847 [D loss: 0.749706, acc.: 46.88%] [G loss: 0.833282]\n",
      "epoch:8 step:7848 [D loss: 0.697967, acc.: 57.03%] [G loss: 0.999435]\n",
      "epoch:8 step:7849 [D loss: 0.698904, acc.: 53.12%] [G loss: 0.925279]\n",
      "epoch:8 step:7850 [D loss: 0.610421, acc.: 64.84%] [G loss: 0.983448]\n",
      "epoch:8 step:7851 [D loss: 0.626656, acc.: 64.84%] [G loss: 1.020734]\n",
      "epoch:8 step:7852 [D loss: 0.745046, acc.: 54.69%] [G loss: 0.942715]\n",
      "epoch:8 step:7853 [D loss: 0.597250, acc.: 68.75%] [G loss: 0.945202]\n",
      "epoch:8 step:7854 [D loss: 0.673285, acc.: 57.81%] [G loss: 0.861275]\n",
      "epoch:8 step:7855 [D loss: 0.648500, acc.: 60.16%] [G loss: 0.920378]\n",
      "epoch:8 step:7856 [D loss: 0.595570, acc.: 64.84%] [G loss: 1.039557]\n",
      "epoch:8 step:7857 [D loss: 0.672517, acc.: 64.06%] [G loss: 0.981215]\n",
      "epoch:8 step:7858 [D loss: 0.711554, acc.: 47.66%] [G loss: 0.951847]\n",
      "epoch:8 step:7859 [D loss: 0.658797, acc.: 61.72%] [G loss: 0.933064]\n",
      "epoch:8 step:7860 [D loss: 0.638457, acc.: 60.94%] [G loss: 0.941899]\n",
      "epoch:8 step:7861 [D loss: 0.654976, acc.: 61.72%] [G loss: 0.948310]\n",
      "epoch:8 step:7862 [D loss: 0.689639, acc.: 52.34%] [G loss: 0.872749]\n",
      "epoch:8 step:7863 [D loss: 0.699902, acc.: 57.03%] [G loss: 0.943820]\n",
      "epoch:8 step:7864 [D loss: 0.636791, acc.: 60.94%] [G loss: 0.994820]\n",
      "epoch:8 step:7865 [D loss: 0.668376, acc.: 64.06%] [G loss: 1.009468]\n",
      "epoch:8 step:7866 [D loss: 0.594609, acc.: 67.19%] [G loss: 0.963836]\n",
      "epoch:8 step:7867 [D loss: 0.669687, acc.: 56.25%] [G loss: 0.921458]\n",
      "epoch:8 step:7868 [D loss: 0.718282, acc.: 61.72%] [G loss: 0.879716]\n",
      "epoch:8 step:7869 [D loss: 0.797235, acc.: 43.75%] [G loss: 0.845414]\n",
      "epoch:8 step:7870 [D loss: 0.713107, acc.: 53.91%] [G loss: 0.839963]\n",
      "epoch:8 step:7871 [D loss: 0.763250, acc.: 48.44%] [G loss: 0.869431]\n",
      "epoch:8 step:7872 [D loss: 0.637093, acc.: 62.50%] [G loss: 0.938833]\n",
      "epoch:8 step:7873 [D loss: 0.618139, acc.: 65.62%] [G loss: 0.927936]\n",
      "epoch:8 step:7874 [D loss: 0.705660, acc.: 54.69%] [G loss: 0.943889]\n",
      "epoch:8 step:7875 [D loss: 0.653588, acc.: 60.94%] [G loss: 0.906540]\n",
      "epoch:8 step:7876 [D loss: 0.637674, acc.: 60.16%] [G loss: 0.842828]\n",
      "epoch:8 step:7877 [D loss: 0.616106, acc.: 61.72%] [G loss: 1.001344]\n",
      "epoch:8 step:7878 [D loss: 0.653148, acc.: 62.50%] [G loss: 0.910364]\n",
      "epoch:8 step:7879 [D loss: 0.677096, acc.: 53.12%] [G loss: 0.946277]\n",
      "epoch:8 step:7880 [D loss: 0.636034, acc.: 64.84%] [G loss: 0.909691]\n",
      "epoch:8 step:7881 [D loss: 0.630772, acc.: 66.41%] [G loss: 0.899196]\n",
      "epoch:8 step:7882 [D loss: 0.693529, acc.: 57.03%] [G loss: 0.879624]\n",
      "epoch:8 step:7883 [D loss: 0.597382, acc.: 71.09%] [G loss: 1.004539]\n",
      "epoch:8 step:7884 [D loss: 0.637501, acc.: 61.72%] [G loss: 1.128532]\n",
      "epoch:8 step:7885 [D loss: 0.670222, acc.: 61.72%] [G loss: 0.873533]\n",
      "epoch:8 step:7886 [D loss: 0.716172, acc.: 52.34%] [G loss: 0.807203]\n",
      "epoch:8 step:7887 [D loss: 0.647312, acc.: 62.50%] [G loss: 0.896798]\n",
      "epoch:8 step:7888 [D loss: 0.671625, acc.: 55.47%] [G loss: 0.975955]\n",
      "epoch:8 step:7889 [D loss: 0.663902, acc.: 63.28%] [G loss: 0.858417]\n",
      "epoch:8 step:7890 [D loss: 0.670974, acc.: 60.94%] [G loss: 0.800099]\n",
      "epoch:8 step:7891 [D loss: 0.698037, acc.: 54.69%] [G loss: 0.859729]\n",
      "epoch:8 step:7892 [D loss: 0.727655, acc.: 46.09%] [G loss: 0.938841]\n",
      "epoch:8 step:7893 [D loss: 0.690125, acc.: 56.25%] [G loss: 0.970495]\n",
      "epoch:8 step:7894 [D loss: 0.637455, acc.: 63.28%] [G loss: 0.990951]\n",
      "epoch:8 step:7895 [D loss: 0.613361, acc.: 67.97%] [G loss: 1.061874]\n",
      "epoch:8 step:7896 [D loss: 0.639186, acc.: 61.72%] [G loss: 0.996821]\n",
      "epoch:8 step:7897 [D loss: 0.717343, acc.: 56.25%] [G loss: 0.932462]\n",
      "epoch:8 step:7898 [D loss: 0.629124, acc.: 62.50%] [G loss: 0.992157]\n",
      "epoch:8 step:7899 [D loss: 0.638477, acc.: 61.72%] [G loss: 1.082766]\n",
      "epoch:8 step:7900 [D loss: 0.687132, acc.: 57.81%] [G loss: 0.925790]\n",
      "epoch:8 step:7901 [D loss: 0.669781, acc.: 58.59%] [G loss: 0.999126]\n",
      "epoch:8 step:7902 [D loss: 0.700453, acc.: 57.03%] [G loss: 0.966077]\n",
      "epoch:8 step:7903 [D loss: 0.665468, acc.: 60.16%] [G loss: 0.982240]\n",
      "epoch:8 step:7904 [D loss: 0.662265, acc.: 60.16%] [G loss: 1.028206]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7905 [D loss: 0.692111, acc.: 59.38%] [G loss: 0.879748]\n",
      "epoch:8 step:7906 [D loss: 0.720345, acc.: 53.91%] [G loss: 0.884888]\n",
      "epoch:8 step:7907 [D loss: 0.717909, acc.: 44.53%] [G loss: 0.947083]\n",
      "epoch:8 step:7908 [D loss: 0.551844, acc.: 77.34%] [G loss: 0.953383]\n",
      "epoch:8 step:7909 [D loss: 0.655262, acc.: 61.72%] [G loss: 0.769928]\n",
      "epoch:8 step:7910 [D loss: 0.675695, acc.: 57.81%] [G loss: 0.791523]\n",
      "epoch:8 step:7911 [D loss: 0.647079, acc.: 64.84%] [G loss: 1.090799]\n",
      "epoch:8 step:7912 [D loss: 0.621106, acc.: 63.28%] [G loss: 1.000372]\n",
      "epoch:8 step:7913 [D loss: 0.623460, acc.: 64.84%] [G loss: 0.927876]\n",
      "epoch:8 step:7914 [D loss: 0.570383, acc.: 71.09%] [G loss: 1.039600]\n",
      "epoch:8 step:7915 [D loss: 0.550096, acc.: 75.00%] [G loss: 1.065839]\n",
      "epoch:8 step:7916 [D loss: 0.680100, acc.: 55.47%] [G loss: 0.961097]\n",
      "epoch:8 step:7917 [D loss: 0.642786, acc.: 64.06%] [G loss: 0.996583]\n",
      "epoch:8 step:7918 [D loss: 0.745631, acc.: 47.66%] [G loss: 0.938084]\n",
      "epoch:8 step:7919 [D loss: 0.674288, acc.: 59.38%] [G loss: 0.797707]\n",
      "epoch:8 step:7920 [D loss: 0.636443, acc.: 61.72%] [G loss: 0.863798]\n",
      "epoch:8 step:7921 [D loss: 0.651132, acc.: 60.16%] [G loss: 0.941962]\n",
      "epoch:8 step:7922 [D loss: 0.627676, acc.: 70.31%] [G loss: 1.102113]\n",
      "epoch:8 step:7923 [D loss: 0.612959, acc.: 67.97%] [G loss: 0.956361]\n",
      "epoch:8 step:7924 [D loss: 0.489735, acc.: 79.69%] [G loss: 0.989173]\n",
      "epoch:8 step:7925 [D loss: 0.613883, acc.: 69.53%] [G loss: 0.823658]\n",
      "epoch:8 step:7926 [D loss: 0.545578, acc.: 76.56%] [G loss: 1.041332]\n",
      "epoch:8 step:7927 [D loss: 0.737326, acc.: 46.88%] [G loss: 0.965324]\n",
      "epoch:8 step:7928 [D loss: 0.703671, acc.: 54.69%] [G loss: 1.092089]\n",
      "epoch:8 step:7929 [D loss: 0.644560, acc.: 61.72%] [G loss: 0.941181]\n",
      "epoch:8 step:7930 [D loss: 0.651677, acc.: 60.16%] [G loss: 0.968163]\n",
      "epoch:8 step:7931 [D loss: 0.757624, acc.: 49.22%] [G loss: 0.897839]\n",
      "epoch:8 step:7932 [D loss: 0.659771, acc.: 60.94%] [G loss: 1.052009]\n",
      "epoch:8 step:7933 [D loss: 0.750637, acc.: 55.47%] [G loss: 0.897211]\n",
      "epoch:8 step:7934 [D loss: 0.711557, acc.: 55.47%] [G loss: 0.825941]\n",
      "epoch:8 step:7935 [D loss: 0.690777, acc.: 57.03%] [G loss: 0.847137]\n",
      "epoch:8 step:7936 [D loss: 0.604556, acc.: 66.41%] [G loss: 1.055835]\n",
      "epoch:8 step:7937 [D loss: 0.643438, acc.: 60.94%] [G loss: 1.029268]\n",
      "epoch:8 step:7938 [D loss: 0.643004, acc.: 60.16%] [G loss: 0.980850]\n",
      "epoch:8 step:7939 [D loss: 0.713351, acc.: 54.69%] [G loss: 0.880739]\n",
      "epoch:8 step:7940 [D loss: 0.722295, acc.: 50.78%] [G loss: 0.837148]\n",
      "epoch:8 step:7941 [D loss: 0.732976, acc.: 50.78%] [G loss: 0.854271]\n",
      "epoch:8 step:7942 [D loss: 0.696706, acc.: 57.03%] [G loss: 0.830502]\n",
      "epoch:8 step:7943 [D loss: 0.629783, acc.: 63.28%] [G loss: 0.968718]\n",
      "epoch:8 step:7944 [D loss: 0.713725, acc.: 50.78%] [G loss: 0.991857]\n",
      "epoch:8 step:7945 [D loss: 0.713798, acc.: 47.66%] [G loss: 1.008677]\n",
      "epoch:8 step:7946 [D loss: 0.660348, acc.: 61.72%] [G loss: 0.949917]\n",
      "epoch:8 step:7947 [D loss: 0.651206, acc.: 63.28%] [G loss: 0.972889]\n",
      "epoch:8 step:7948 [D loss: 0.649831, acc.: 64.06%] [G loss: 1.038520]\n",
      "epoch:8 step:7949 [D loss: 0.666655, acc.: 64.06%] [G loss: 0.968007]\n",
      "epoch:8 step:7950 [D loss: 0.629304, acc.: 59.38%] [G loss: 0.893265]\n",
      "epoch:8 step:7951 [D loss: 0.604651, acc.: 68.75%] [G loss: 0.826173]\n",
      "epoch:8 step:7952 [D loss: 0.664692, acc.: 57.03%] [G loss: 0.963009]\n",
      "epoch:8 step:7953 [D loss: 0.636189, acc.: 64.06%] [G loss: 0.972770]\n",
      "epoch:8 step:7954 [D loss: 0.737672, acc.: 54.69%] [G loss: 0.999864]\n",
      "epoch:8 step:7955 [D loss: 0.690259, acc.: 59.38%] [G loss: 0.970770]\n",
      "epoch:8 step:7956 [D loss: 0.609890, acc.: 63.28%] [G loss: 1.074244]\n",
      "epoch:8 step:7957 [D loss: 0.664713, acc.: 61.72%] [G loss: 0.998156]\n",
      "epoch:8 step:7958 [D loss: 0.746301, acc.: 53.12%] [G loss: 0.956895]\n",
      "epoch:8 step:7959 [D loss: 0.649880, acc.: 57.81%] [G loss: 0.925102]\n",
      "epoch:8 step:7960 [D loss: 0.650018, acc.: 62.50%] [G loss: 0.801781]\n",
      "epoch:8 step:7961 [D loss: 0.715802, acc.: 50.00%] [G loss: 0.921990]\n",
      "epoch:8 step:7962 [D loss: 0.652589, acc.: 63.28%] [G loss: 1.015314]\n",
      "epoch:8 step:7963 [D loss: 0.636882, acc.: 61.72%] [G loss: 0.977240]\n",
      "epoch:8 step:7964 [D loss: 0.627639, acc.: 63.28%] [G loss: 1.011598]\n",
      "epoch:8 step:7965 [D loss: 0.549658, acc.: 75.00%] [G loss: 1.029614]\n",
      "epoch:8 step:7966 [D loss: 0.578217, acc.: 68.75%] [G loss: 1.075665]\n",
      "epoch:8 step:7967 [D loss: 0.615871, acc.: 60.94%] [G loss: 0.973359]\n",
      "epoch:8 step:7968 [D loss: 0.579782, acc.: 69.53%] [G loss: 1.119300]\n",
      "epoch:8 step:7969 [D loss: 0.771536, acc.: 46.09%] [G loss: 0.883459]\n",
      "epoch:8 step:7970 [D loss: 0.749347, acc.: 46.88%] [G loss: 0.806425]\n",
      "epoch:8 step:7971 [D loss: 0.725615, acc.: 46.09%] [G loss: 0.965747]\n",
      "epoch:8 step:7972 [D loss: 0.630039, acc.: 64.84%] [G loss: 1.032283]\n",
      "epoch:8 step:7973 [D loss: 0.726396, acc.: 49.22%] [G loss: 0.966969]\n",
      "epoch:8 step:7974 [D loss: 0.662633, acc.: 60.16%] [G loss: 0.905250]\n",
      "epoch:8 step:7975 [D loss: 0.704758, acc.: 61.72%] [G loss: 0.890774]\n",
      "epoch:8 step:7976 [D loss: 0.660052, acc.: 59.38%] [G loss: 0.923482]\n",
      "epoch:8 step:7977 [D loss: 0.599006, acc.: 64.84%] [G loss: 0.945575]\n",
      "epoch:8 step:7978 [D loss: 0.719690, acc.: 55.47%] [G loss: 1.021876]\n",
      "epoch:8 step:7979 [D loss: 0.641685, acc.: 66.41%] [G loss: 1.031651]\n",
      "epoch:8 step:7980 [D loss: 0.594361, acc.: 69.53%] [G loss: 0.965659]\n",
      "epoch:8 step:7981 [D loss: 0.683662, acc.: 60.94%] [G loss: 1.006110]\n",
      "epoch:8 step:7982 [D loss: 0.671598, acc.: 60.16%] [G loss: 0.866415]\n",
      "epoch:8 step:7983 [D loss: 0.722190, acc.: 53.12%] [G loss: 0.934573]\n",
      "epoch:8 step:7984 [D loss: 0.628531, acc.: 67.19%] [G loss: 0.956611]\n",
      "epoch:8 step:7985 [D loss: 0.570022, acc.: 73.44%] [G loss: 1.108185]\n",
      "epoch:8 step:7986 [D loss: 0.574731, acc.: 71.88%] [G loss: 0.969809]\n",
      "epoch:8 step:7987 [D loss: 0.645788, acc.: 61.72%] [G loss: 0.931001]\n",
      "epoch:8 step:7988 [D loss: 0.670506, acc.: 57.03%] [G loss: 1.022704]\n",
      "epoch:8 step:7989 [D loss: 0.647646, acc.: 59.38%] [G loss: 1.107718]\n",
      "epoch:8 step:7990 [D loss: 0.671116, acc.: 60.94%] [G loss: 0.897407]\n",
      "epoch:8 step:7991 [D loss: 0.702321, acc.: 53.12%] [G loss: 0.935292]\n",
      "epoch:8 step:7992 [D loss: 0.768194, acc.: 44.53%] [G loss: 0.952139]\n",
      "epoch:8 step:7993 [D loss: 0.735121, acc.: 50.78%] [G loss: 0.923872]\n",
      "epoch:8 step:7994 [D loss: 0.650268, acc.: 55.47%] [G loss: 0.993403]\n",
      "epoch:8 step:7995 [D loss: 0.664925, acc.: 60.16%] [G loss: 0.997652]\n",
      "epoch:8 step:7996 [D loss: 0.753830, acc.: 46.88%] [G loss: 0.943199]\n",
      "epoch:8 step:7997 [D loss: 0.713764, acc.: 54.69%] [G loss: 0.971836]\n",
      "epoch:8 step:7998 [D loss: 0.665113, acc.: 55.47%] [G loss: 0.962927]\n",
      "epoch:8 step:7999 [D loss: 0.644480, acc.: 61.72%] [G loss: 1.043712]\n",
      "epoch:8 step:8000 [D loss: 0.633203, acc.: 67.97%] [G loss: 0.990751]\n",
      "##############\n",
      "[1.90216306 1.44903307 5.02025693 3.71384249 2.86169622 4.83519906\n",
      " 3.95037224 4.49724959 3.29135997 3.3232454 ]\n",
      "##########\n",
      "epoch:8 step:8001 [D loss: 0.664574, acc.: 56.25%] [G loss: 0.893762]\n",
      "epoch:8 step:8002 [D loss: 0.653741, acc.: 61.72%] [G loss: 1.062278]\n",
      "epoch:8 step:8003 [D loss: 0.677731, acc.: 53.91%] [G loss: 1.104572]\n",
      "epoch:8 step:8004 [D loss: 0.633947, acc.: 58.59%] [G loss: 0.898620]\n",
      "epoch:8 step:8005 [D loss: 0.707425, acc.: 53.91%] [G loss: 0.968128]\n",
      "epoch:8 step:8006 [D loss: 0.667315, acc.: 60.16%] [G loss: 0.878921]\n",
      "epoch:8 step:8007 [D loss: 0.658281, acc.: 62.50%] [G loss: 0.999593]\n",
      "epoch:8 step:8008 [D loss: 0.693977, acc.: 50.00%] [G loss: 0.854479]\n",
      "epoch:8 step:8009 [D loss: 0.684815, acc.: 57.03%] [G loss: 0.819368]\n",
      "epoch:8 step:8010 [D loss: 0.616773, acc.: 65.62%] [G loss: 0.967753]\n",
      "epoch:8 step:8011 [D loss: 0.635491, acc.: 61.72%] [G loss: 0.881821]\n",
      "epoch:8 step:8012 [D loss: 0.686718, acc.: 58.59%] [G loss: 0.867873]\n",
      "epoch:8 step:8013 [D loss: 0.663025, acc.: 64.06%] [G loss: 0.937235]\n",
      "epoch:8 step:8014 [D loss: 0.725262, acc.: 52.34%] [G loss: 0.929405]\n",
      "epoch:8 step:8015 [D loss: 0.623099, acc.: 62.50%] [G loss: 0.915069]\n",
      "epoch:8 step:8016 [D loss: 0.577976, acc.: 68.75%] [G loss: 0.933427]\n",
      "epoch:8 step:8017 [D loss: 0.716169, acc.: 51.56%] [G loss: 0.962233]\n",
      "epoch:8 step:8018 [D loss: 0.654969, acc.: 64.06%] [G loss: 0.937285]\n",
      "epoch:8 step:8019 [D loss: 0.643036, acc.: 62.50%] [G loss: 0.966455]\n",
      "epoch:8 step:8020 [D loss: 0.680664, acc.: 57.81%] [G loss: 0.861821]\n",
      "epoch:8 step:8021 [D loss: 0.665831, acc.: 57.03%] [G loss: 0.866926]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8022 [D loss: 0.672922, acc.: 61.72%] [G loss: 0.871453]\n",
      "epoch:8 step:8023 [D loss: 0.656871, acc.: 62.50%] [G loss: 0.810863]\n",
      "epoch:8 step:8024 [D loss: 0.758593, acc.: 45.31%] [G loss: 0.847497]\n",
      "epoch:8 step:8025 [D loss: 0.654124, acc.: 61.72%] [G loss: 0.848521]\n",
      "epoch:8 step:8026 [D loss: 0.701687, acc.: 53.12%] [G loss: 0.924411]\n",
      "epoch:8 step:8027 [D loss: 0.630134, acc.: 64.06%] [G loss: 0.995104]\n",
      "epoch:8 step:8028 [D loss: 0.656675, acc.: 61.72%] [G loss: 1.003862]\n",
      "epoch:8 step:8029 [D loss: 0.604365, acc.: 69.53%] [G loss: 0.965900]\n",
      "epoch:8 step:8030 [D loss: 0.618002, acc.: 60.16%] [G loss: 0.928661]\n",
      "epoch:8 step:8031 [D loss: 0.651981, acc.: 64.06%] [G loss: 0.896846]\n",
      "epoch:8 step:8032 [D loss: 0.592283, acc.: 68.75%] [G loss: 0.978263]\n",
      "epoch:8 step:8033 [D loss: 0.749048, acc.: 46.09%] [G loss: 0.869222]\n",
      "epoch:8 step:8034 [D loss: 0.691246, acc.: 57.81%] [G loss: 1.017847]\n",
      "epoch:8 step:8035 [D loss: 0.654196, acc.: 57.81%] [G loss: 0.974543]\n",
      "epoch:8 step:8036 [D loss: 0.668545, acc.: 63.28%] [G loss: 0.908928]\n",
      "epoch:8 step:8037 [D loss: 0.734425, acc.: 53.91%] [G loss: 0.851880]\n",
      "epoch:8 step:8038 [D loss: 0.735953, acc.: 55.47%] [G loss: 0.894222]\n",
      "epoch:8 step:8039 [D loss: 0.683683, acc.: 58.59%] [G loss: 0.974005]\n",
      "epoch:8 step:8040 [D loss: 0.666319, acc.: 60.94%] [G loss: 0.920784]\n",
      "epoch:8 step:8041 [D loss: 0.683378, acc.: 57.81%] [G loss: 0.873151]\n",
      "epoch:8 step:8042 [D loss: 0.709780, acc.: 56.25%] [G loss: 0.854323]\n",
      "epoch:8 step:8043 [D loss: 0.642384, acc.: 67.19%] [G loss: 0.969611]\n",
      "epoch:8 step:8044 [D loss: 0.630010, acc.: 66.41%] [G loss: 0.903369]\n",
      "epoch:8 step:8045 [D loss: 0.592721, acc.: 69.53%] [G loss: 0.979085]\n",
      "epoch:8 step:8046 [D loss: 0.674380, acc.: 57.03%] [G loss: 0.918899]\n",
      "epoch:8 step:8047 [D loss: 0.559682, acc.: 71.09%] [G loss: 1.019067]\n",
      "epoch:8 step:8048 [D loss: 0.616817, acc.: 67.19%] [G loss: 1.008182]\n",
      "epoch:8 step:8049 [D loss: 0.608568, acc.: 65.62%] [G loss: 0.987799]\n",
      "epoch:8 step:8050 [D loss: 0.623249, acc.: 66.41%] [G loss: 1.004333]\n",
      "epoch:8 step:8051 [D loss: 0.528832, acc.: 78.12%] [G loss: 0.985205]\n",
      "epoch:8 step:8052 [D loss: 0.603111, acc.: 66.41%] [G loss: 1.022044]\n",
      "epoch:8 step:8053 [D loss: 0.585443, acc.: 69.53%] [G loss: 1.006700]\n",
      "epoch:8 step:8054 [D loss: 0.602645, acc.: 67.19%] [G loss: 1.044090]\n",
      "epoch:8 step:8055 [D loss: 0.701659, acc.: 51.56%] [G loss: 0.943735]\n",
      "epoch:8 step:8056 [D loss: 0.703210, acc.: 46.88%] [G loss: 0.877200]\n",
      "epoch:8 step:8057 [D loss: 0.649740, acc.: 60.16%] [G loss: 0.766489]\n",
      "epoch:8 step:8058 [D loss: 0.765379, acc.: 46.09%] [G loss: 0.844956]\n",
      "epoch:8 step:8059 [D loss: 0.640746, acc.: 63.28%] [G loss: 0.861181]\n",
      "epoch:8 step:8060 [D loss: 0.728025, acc.: 48.44%] [G loss: 0.849415]\n",
      "epoch:8 step:8061 [D loss: 0.707445, acc.: 52.34%] [G loss: 0.867427]\n",
      "epoch:8 step:8062 [D loss: 0.735715, acc.: 50.78%] [G loss: 0.850644]\n",
      "epoch:8 step:8063 [D loss: 0.707268, acc.: 53.91%] [G loss: 0.903669]\n",
      "epoch:8 step:8064 [D loss: 0.688552, acc.: 52.34%] [G loss: 0.907052]\n",
      "epoch:8 step:8065 [D loss: 0.716533, acc.: 51.56%] [G loss: 0.985397]\n",
      "epoch:8 step:8066 [D loss: 0.626644, acc.: 67.19%] [G loss: 0.952101]\n",
      "epoch:8 step:8067 [D loss: 0.620675, acc.: 64.06%] [G loss: 0.925052]\n",
      "epoch:8 step:8068 [D loss: 0.721296, acc.: 47.66%] [G loss: 0.831593]\n",
      "epoch:8 step:8069 [D loss: 0.705462, acc.: 52.34%] [G loss: 0.931713]\n",
      "epoch:8 step:8070 [D loss: 0.625393, acc.: 61.72%] [G loss: 0.828016]\n",
      "epoch:8 step:8071 [D loss: 0.740820, acc.: 46.88%] [G loss: 0.833327]\n",
      "epoch:8 step:8072 [D loss: 0.638124, acc.: 61.72%] [G loss: 1.013806]\n",
      "epoch:8 step:8073 [D loss: 0.651705, acc.: 61.72%] [G loss: 0.912043]\n",
      "epoch:8 step:8074 [D loss: 0.714209, acc.: 50.00%] [G loss: 0.862066]\n",
      "epoch:8 step:8075 [D loss: 0.686777, acc.: 60.16%] [G loss: 0.887441]\n",
      "epoch:8 step:8076 [D loss: 0.678719, acc.: 60.16%] [G loss: 0.839851]\n",
      "epoch:8 step:8077 [D loss: 0.669440, acc.: 57.81%] [G loss: 1.010368]\n",
      "epoch:8 step:8078 [D loss: 0.667648, acc.: 64.06%] [G loss: 0.890188]\n",
      "epoch:8 step:8079 [D loss: 0.674920, acc.: 56.25%] [G loss: 0.895585]\n",
      "epoch:8 step:8080 [D loss: 0.652918, acc.: 59.38%] [G loss: 1.016265]\n",
      "epoch:8 step:8081 [D loss: 0.631260, acc.: 62.50%] [G loss: 0.986807]\n",
      "epoch:8 step:8082 [D loss: 0.654393, acc.: 61.72%] [G loss: 0.975614]\n",
      "epoch:8 step:8083 [D loss: 0.582822, acc.: 68.75%] [G loss: 1.010792]\n",
      "epoch:8 step:8084 [D loss: 0.626876, acc.: 64.06%] [G loss: 1.004379]\n",
      "epoch:8 step:8085 [D loss: 0.566278, acc.: 71.09%] [G loss: 0.956378]\n",
      "epoch:8 step:8086 [D loss: 0.712819, acc.: 57.03%] [G loss: 0.893922]\n",
      "epoch:8 step:8087 [D loss: 0.670392, acc.: 60.16%] [G loss: 0.962748]\n",
      "epoch:8 step:8088 [D loss: 0.650221, acc.: 67.97%] [G loss: 0.915514]\n",
      "epoch:8 step:8089 [D loss: 0.655279, acc.: 58.59%] [G loss: 1.075431]\n",
      "epoch:8 step:8090 [D loss: 0.640914, acc.: 63.28%] [G loss: 0.848306]\n",
      "epoch:8 step:8091 [D loss: 0.630894, acc.: 64.06%] [G loss: 1.037971]\n",
      "epoch:8 step:8092 [D loss: 0.701614, acc.: 53.91%] [G loss: 0.995226]\n",
      "epoch:8 step:8093 [D loss: 0.679273, acc.: 55.47%] [G loss: 0.840324]\n",
      "epoch:8 step:8094 [D loss: 0.618858, acc.: 64.84%] [G loss: 1.014568]\n",
      "epoch:8 step:8095 [D loss: 0.677327, acc.: 56.25%] [G loss: 0.917335]\n",
      "epoch:8 step:8096 [D loss: 0.648801, acc.: 63.28%] [G loss: 1.046810]\n",
      "epoch:8 step:8097 [D loss: 0.680955, acc.: 60.16%] [G loss: 0.950044]\n",
      "epoch:8 step:8098 [D loss: 0.756707, acc.: 49.22%] [G loss: 0.903659]\n",
      "epoch:8 step:8099 [D loss: 0.656622, acc.: 59.38%] [G loss: 0.894175]\n",
      "epoch:8 step:8100 [D loss: 0.652398, acc.: 60.94%] [G loss: 0.968400]\n",
      "epoch:8 step:8101 [D loss: 0.691173, acc.: 53.91%] [G loss: 0.938901]\n",
      "epoch:8 step:8102 [D loss: 0.635075, acc.: 63.28%] [G loss: 1.008217]\n",
      "epoch:8 step:8103 [D loss: 0.629602, acc.: 61.72%] [G loss: 0.977119]\n",
      "epoch:8 step:8104 [D loss: 0.627762, acc.: 64.84%] [G loss: 0.907538]\n",
      "epoch:8 step:8105 [D loss: 0.699586, acc.: 55.47%] [G loss: 0.852994]\n",
      "epoch:8 step:8106 [D loss: 0.669233, acc.: 56.25%] [G loss: 0.940312]\n",
      "epoch:8 step:8107 [D loss: 0.586154, acc.: 73.44%] [G loss: 1.060189]\n",
      "epoch:8 step:8108 [D loss: 0.604406, acc.: 63.28%] [G loss: 0.981623]\n",
      "epoch:8 step:8109 [D loss: 0.640858, acc.: 67.97%] [G loss: 0.976675]\n",
      "epoch:8 step:8110 [D loss: 0.658042, acc.: 60.94%] [G loss: 0.933500]\n",
      "epoch:8 step:8111 [D loss: 0.634162, acc.: 64.84%] [G loss: 0.999737]\n",
      "epoch:8 step:8112 [D loss: 0.653191, acc.: 60.16%] [G loss: 0.978120]\n",
      "epoch:8 step:8113 [D loss: 0.628284, acc.: 68.75%] [G loss: 0.947744]\n",
      "epoch:8 step:8114 [D loss: 0.665440, acc.: 60.94%] [G loss: 0.926825]\n",
      "epoch:8 step:8115 [D loss: 0.655241, acc.: 59.38%] [G loss: 0.950191]\n",
      "epoch:8 step:8116 [D loss: 0.643543, acc.: 65.62%] [G loss: 0.908708]\n",
      "epoch:8 step:8117 [D loss: 0.640583, acc.: 64.06%] [G loss: 0.862538]\n",
      "epoch:8 step:8118 [D loss: 0.752975, acc.: 50.00%] [G loss: 0.915846]\n",
      "epoch:8 step:8119 [D loss: 0.604459, acc.: 71.88%] [G loss: 0.915961]\n",
      "epoch:8 step:8120 [D loss: 0.627262, acc.: 65.62%] [G loss: 0.900631]\n",
      "epoch:8 step:8121 [D loss: 0.666254, acc.: 60.16%] [G loss: 1.028167]\n",
      "epoch:8 step:8122 [D loss: 0.755018, acc.: 44.53%] [G loss: 0.825925]\n",
      "epoch:8 step:8123 [D loss: 0.686653, acc.: 51.56%] [G loss: 0.811294]\n",
      "epoch:8 step:8124 [D loss: 0.684209, acc.: 55.47%] [G loss: 0.928669]\n",
      "epoch:8 step:8125 [D loss: 0.597159, acc.: 70.31%] [G loss: 0.912583]\n",
      "epoch:8 step:8126 [D loss: 0.633767, acc.: 65.62%] [G loss: 0.881590]\n",
      "epoch:8 step:8127 [D loss: 0.668042, acc.: 57.81%] [G loss: 1.003269]\n",
      "epoch:8 step:8128 [D loss: 0.659011, acc.: 59.38%] [G loss: 0.953671]\n",
      "epoch:8 step:8129 [D loss: 0.628059, acc.: 69.53%] [G loss: 0.971669]\n",
      "epoch:8 step:8130 [D loss: 0.662014, acc.: 64.84%] [G loss: 0.872885]\n",
      "epoch:8 step:8131 [D loss: 0.615307, acc.: 69.53%] [G loss: 1.127630]\n",
      "epoch:8 step:8132 [D loss: 0.715033, acc.: 53.91%] [G loss: 0.943548]\n",
      "epoch:8 step:8133 [D loss: 0.633150, acc.: 64.84%] [G loss: 0.901703]\n",
      "epoch:8 step:8134 [D loss: 0.673872, acc.: 55.47%] [G loss: 0.933797]\n",
      "epoch:8 step:8135 [D loss: 0.667989, acc.: 57.03%] [G loss: 0.953997]\n",
      "epoch:8 step:8136 [D loss: 0.649779, acc.: 61.72%] [G loss: 0.869182]\n",
      "epoch:8 step:8137 [D loss: 0.659415, acc.: 61.72%] [G loss: 0.890520]\n",
      "epoch:8 step:8138 [D loss: 0.644429, acc.: 65.62%] [G loss: 0.915766]\n",
      "epoch:8 step:8139 [D loss: 0.582777, acc.: 71.88%] [G loss: 0.998880]\n",
      "epoch:8 step:8140 [D loss: 0.683560, acc.: 53.91%] [G loss: 0.899821]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8141 [D loss: 0.589294, acc.: 71.88%] [G loss: 0.936505]\n",
      "epoch:8 step:8142 [D loss: 0.636180, acc.: 64.06%] [G loss: 0.846362]\n",
      "epoch:8 step:8143 [D loss: 0.592783, acc.: 71.88%] [G loss: 0.957358]\n",
      "epoch:8 step:8144 [D loss: 0.616871, acc.: 69.53%] [G loss: 0.911765]\n",
      "epoch:8 step:8145 [D loss: 0.615387, acc.: 65.62%] [G loss: 0.999212]\n",
      "epoch:8 step:8146 [D loss: 0.661301, acc.: 60.94%] [G loss: 0.968934]\n",
      "epoch:8 step:8147 [D loss: 0.603418, acc.: 64.84%] [G loss: 1.021242]\n",
      "epoch:8 step:8148 [D loss: 0.767869, acc.: 42.19%] [G loss: 0.905650]\n",
      "epoch:8 step:8149 [D loss: 0.708444, acc.: 53.12%] [G loss: 0.903093]\n",
      "epoch:8 step:8150 [D loss: 0.679799, acc.: 57.81%] [G loss: 0.840963]\n",
      "epoch:8 step:8151 [D loss: 0.701110, acc.: 54.69%] [G loss: 0.917270]\n",
      "epoch:8 step:8152 [D loss: 0.625500, acc.: 66.41%] [G loss: 0.987865]\n",
      "epoch:8 step:8153 [D loss: 0.755911, acc.: 49.22%] [G loss: 0.893224]\n",
      "epoch:8 step:8154 [D loss: 0.720387, acc.: 50.00%] [G loss: 0.933470]\n",
      "epoch:8 step:8155 [D loss: 0.722763, acc.: 57.03%] [G loss: 0.876140]\n",
      "epoch:8 step:8156 [D loss: 0.626975, acc.: 64.06%] [G loss: 1.017198]\n",
      "epoch:8 step:8157 [D loss: 0.633188, acc.: 65.62%] [G loss: 0.989783]\n",
      "epoch:8 step:8158 [D loss: 0.792886, acc.: 40.62%] [G loss: 0.992829]\n",
      "epoch:8 step:8159 [D loss: 0.707265, acc.: 54.69%] [G loss: 0.937356]\n",
      "epoch:8 step:8160 [D loss: 0.715385, acc.: 50.00%] [G loss: 0.908543]\n",
      "epoch:8 step:8161 [D loss: 0.675942, acc.: 59.38%] [G loss: 1.018175]\n",
      "epoch:8 step:8162 [D loss: 0.699603, acc.: 50.00%] [G loss: 0.837543]\n",
      "epoch:8 step:8163 [D loss: 0.746861, acc.: 51.56%] [G loss: 0.781840]\n",
      "epoch:8 step:8164 [D loss: 0.697661, acc.: 53.91%] [G loss: 0.881342]\n",
      "epoch:8 step:8165 [D loss: 0.677997, acc.: 57.81%] [G loss: 0.919957]\n",
      "epoch:8 step:8166 [D loss: 0.685419, acc.: 59.38%] [G loss: 0.979923]\n",
      "epoch:8 step:8167 [D loss: 0.685041, acc.: 55.47%] [G loss: 0.946509]\n",
      "epoch:8 step:8168 [D loss: 0.707221, acc.: 53.91%] [G loss: 0.888763]\n",
      "epoch:8 step:8169 [D loss: 0.754704, acc.: 46.88%] [G loss: 1.046832]\n",
      "epoch:8 step:8170 [D loss: 0.692397, acc.: 55.47%] [G loss: 0.922220]\n",
      "epoch:8 step:8171 [D loss: 0.667389, acc.: 62.50%] [G loss: 0.932154]\n",
      "epoch:8 step:8172 [D loss: 0.585779, acc.: 69.53%] [G loss: 0.969882]\n",
      "epoch:8 step:8173 [D loss: 0.576973, acc.: 74.22%] [G loss: 1.058817]\n",
      "epoch:8 step:8174 [D loss: 0.623825, acc.: 63.28%] [G loss: 0.980983]\n",
      "epoch:8 step:8175 [D loss: 0.654864, acc.: 61.72%] [G loss: 0.930913]\n",
      "epoch:8 step:8176 [D loss: 0.644333, acc.: 60.16%] [G loss: 0.872425]\n",
      "epoch:8 step:8177 [D loss: 0.609117, acc.: 69.53%] [G loss: 0.986051]\n",
      "epoch:8 step:8178 [D loss: 0.643407, acc.: 61.72%] [G loss: 0.995910]\n",
      "epoch:8 step:8179 [D loss: 0.665589, acc.: 62.50%] [G loss: 0.999364]\n",
      "epoch:8 step:8180 [D loss: 0.711142, acc.: 60.16%] [G loss: 0.938542]\n",
      "epoch:8 step:8181 [D loss: 0.668510, acc.: 62.50%] [G loss: 0.982662]\n",
      "epoch:8 step:8182 [D loss: 0.647607, acc.: 56.25%] [G loss: 0.961738]\n",
      "epoch:8 step:8183 [D loss: 0.670893, acc.: 57.03%] [G loss: 1.055380]\n",
      "epoch:8 step:8184 [D loss: 0.709383, acc.: 51.56%] [G loss: 1.033746]\n",
      "epoch:8 step:8185 [D loss: 0.596927, acc.: 69.53%] [G loss: 0.997367]\n",
      "epoch:8 step:8186 [D loss: 0.651795, acc.: 62.50%] [G loss: 0.937554]\n",
      "epoch:8 step:8187 [D loss: 0.659480, acc.: 58.59%] [G loss: 0.950141]\n",
      "epoch:8 step:8188 [D loss: 0.680082, acc.: 58.59%] [G loss: 1.115597]\n",
      "epoch:8 step:8189 [D loss: 0.647197, acc.: 67.19%] [G loss: 0.869939]\n",
      "epoch:8 step:8190 [D loss: 0.578104, acc.: 70.31%] [G loss: 0.975775]\n",
      "epoch:8 step:8191 [D loss: 0.627343, acc.: 69.53%] [G loss: 0.905054]\n",
      "epoch:8 step:8192 [D loss: 0.662316, acc.: 57.03%] [G loss: 0.866147]\n",
      "epoch:8 step:8193 [D loss: 0.658524, acc.: 63.28%] [G loss: 0.826598]\n",
      "epoch:8 step:8194 [D loss: 0.702354, acc.: 52.34%] [G loss: 0.963167]\n",
      "epoch:8 step:8195 [D loss: 0.664015, acc.: 57.81%] [G loss: 0.867845]\n",
      "epoch:8 step:8196 [D loss: 0.652836, acc.: 60.94%] [G loss: 1.020279]\n",
      "epoch:8 step:8197 [D loss: 0.674318, acc.: 60.94%] [G loss: 0.985210]\n",
      "epoch:8 step:8198 [D loss: 0.736946, acc.: 50.78%] [G loss: 0.976195]\n",
      "epoch:8 step:8199 [D loss: 0.689249, acc.: 57.03%] [G loss: 0.867093]\n",
      "epoch:8 step:8200 [D loss: 0.749816, acc.: 46.88%] [G loss: 0.816683]\n",
      "##############\n",
      "[2.17752343 1.47135684 5.33319267 4.24683391 2.93554069 5.23873796\n",
      " 4.10924079 4.39851971 3.56074754 3.40020021]\n",
      "##########\n",
      "epoch:8 step:8201 [D loss: 0.656968, acc.: 60.16%] [G loss: 0.851450]\n",
      "epoch:8 step:8202 [D loss: 0.646375, acc.: 60.94%] [G loss: 0.823183]\n",
      "epoch:8 step:8203 [D loss: 0.640528, acc.: 67.97%] [G loss: 0.980390]\n",
      "epoch:8 step:8204 [D loss: 0.634221, acc.: 64.06%] [G loss: 0.881263]\n",
      "epoch:8 step:8205 [D loss: 0.556634, acc.: 75.78%] [G loss: 1.094358]\n",
      "epoch:8 step:8206 [D loss: 0.730608, acc.: 51.56%] [G loss: 0.893684]\n",
      "epoch:8 step:8207 [D loss: 0.683383, acc.: 59.38%] [G loss: 1.018811]\n",
      "epoch:8 step:8208 [D loss: 0.649224, acc.: 58.59%] [G loss: 0.900966]\n",
      "epoch:8 step:8209 [D loss: 0.733844, acc.: 45.31%] [G loss: 0.891318]\n",
      "epoch:8 step:8210 [D loss: 0.695888, acc.: 57.81%] [G loss: 1.022280]\n",
      "epoch:8 step:8211 [D loss: 0.697674, acc.: 54.69%] [G loss: 0.975019]\n",
      "epoch:8 step:8212 [D loss: 0.703812, acc.: 53.12%] [G loss: 0.984058]\n",
      "epoch:8 step:8213 [D loss: 0.690969, acc.: 54.69%] [G loss: 0.922409]\n",
      "epoch:8 step:8214 [D loss: 0.737092, acc.: 51.56%] [G loss: 0.944701]\n",
      "epoch:8 step:8215 [D loss: 0.588361, acc.: 75.00%] [G loss: 1.030090]\n",
      "epoch:8 step:8216 [D loss: 0.695860, acc.: 56.25%] [G loss: 0.966793]\n",
      "epoch:8 step:8217 [D loss: 0.632271, acc.: 64.06%] [G loss: 0.956812]\n",
      "epoch:8 step:8218 [D loss: 0.705288, acc.: 52.34%] [G loss: 0.881196]\n",
      "epoch:8 step:8219 [D loss: 0.653827, acc.: 61.72%] [G loss: 0.872471]\n",
      "epoch:8 step:8220 [D loss: 0.635393, acc.: 60.94%] [G loss: 0.836417]\n",
      "epoch:8 step:8221 [D loss: 0.663163, acc.: 64.84%] [G loss: 0.830661]\n",
      "epoch:8 step:8222 [D loss: 0.754609, acc.: 47.66%] [G loss: 0.887753]\n",
      "epoch:8 step:8223 [D loss: 0.667061, acc.: 55.47%] [G loss: 0.942428]\n",
      "epoch:8 step:8224 [D loss: 0.667781, acc.: 61.72%] [G loss: 0.943208]\n",
      "epoch:8 step:8225 [D loss: 0.676290, acc.: 57.81%] [G loss: 1.030060]\n",
      "epoch:8 step:8226 [D loss: 0.609541, acc.: 65.62%] [G loss: 1.016133]\n",
      "epoch:8 step:8227 [D loss: 0.549412, acc.: 76.56%] [G loss: 0.954570]\n",
      "epoch:8 step:8228 [D loss: 0.620293, acc.: 62.50%] [G loss: 1.001694]\n",
      "epoch:8 step:8229 [D loss: 0.623248, acc.: 65.62%] [G loss: 0.845553]\n",
      "epoch:8 step:8230 [D loss: 0.594453, acc.: 67.97%] [G loss: 0.950740]\n",
      "epoch:8 step:8231 [D loss: 0.629014, acc.: 67.19%] [G loss: 0.973367]\n",
      "epoch:8 step:8232 [D loss: 0.669407, acc.: 60.94%] [G loss: 0.949301]\n",
      "epoch:8 step:8233 [D loss: 0.631819, acc.: 66.41%] [G loss: 0.941632]\n",
      "epoch:8 step:8234 [D loss: 0.689484, acc.: 55.47%] [G loss: 0.888337]\n",
      "epoch:8 step:8235 [D loss: 0.668170, acc.: 59.38%] [G loss: 0.877696]\n",
      "epoch:8 step:8236 [D loss: 0.648633, acc.: 59.38%] [G loss: 0.883987]\n",
      "epoch:8 step:8237 [D loss: 0.611236, acc.: 67.19%] [G loss: 1.041355]\n",
      "epoch:8 step:8238 [D loss: 0.771944, acc.: 43.75%] [G loss: 0.790192]\n",
      "epoch:8 step:8239 [D loss: 0.689060, acc.: 57.03%] [G loss: 0.858547]\n",
      "epoch:8 step:8240 [D loss: 0.731092, acc.: 49.22%] [G loss: 0.821946]\n",
      "epoch:8 step:8241 [D loss: 0.641764, acc.: 60.94%] [G loss: 0.838531]\n",
      "epoch:8 step:8242 [D loss: 0.629962, acc.: 61.72%] [G loss: 1.003179]\n",
      "epoch:8 step:8243 [D loss: 0.653872, acc.: 57.81%] [G loss: 0.928075]\n",
      "epoch:8 step:8244 [D loss: 0.662445, acc.: 60.94%] [G loss: 0.954291]\n",
      "epoch:8 step:8245 [D loss: 0.660403, acc.: 57.81%] [G loss: 1.012114]\n",
      "epoch:8 step:8246 [D loss: 0.601113, acc.: 71.09%] [G loss: 0.991934]\n",
      "epoch:8 step:8247 [D loss: 0.672335, acc.: 57.03%] [G loss: 0.976178]\n",
      "epoch:8 step:8248 [D loss: 0.688016, acc.: 59.38%] [G loss: 1.027165]\n",
      "epoch:8 step:8249 [D loss: 0.610324, acc.: 69.53%] [G loss: 1.023953]\n",
      "epoch:8 step:8250 [D loss: 0.650624, acc.: 57.81%] [G loss: 0.929712]\n",
      "epoch:8 step:8251 [D loss: 0.658201, acc.: 61.72%] [G loss: 0.768152]\n",
      "epoch:8 step:8252 [D loss: 0.659488, acc.: 60.16%] [G loss: 0.892388]\n",
      "epoch:8 step:8253 [D loss: 0.642489, acc.: 63.28%] [G loss: 0.927970]\n",
      "epoch:8 step:8254 [D loss: 0.671651, acc.: 57.81%] [G loss: 0.933394]\n",
      "epoch:8 step:8255 [D loss: 0.701335, acc.: 51.56%] [G loss: 0.945339]\n",
      "epoch:8 step:8256 [D loss: 0.681071, acc.: 55.47%] [G loss: 0.953727]\n",
      "epoch:8 step:8257 [D loss: 0.678995, acc.: 56.25%] [G loss: 0.997162]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8258 [D loss: 0.717772, acc.: 53.12%] [G loss: 0.888510]\n",
      "epoch:8 step:8259 [D loss: 0.693063, acc.: 60.16%] [G loss: 0.842541]\n",
      "epoch:8 step:8260 [D loss: 0.719169, acc.: 55.47%] [G loss: 0.928421]\n",
      "epoch:8 step:8261 [D loss: 0.707814, acc.: 55.47%] [G loss: 0.811478]\n",
      "epoch:8 step:8262 [D loss: 0.660983, acc.: 64.84%] [G loss: 0.990442]\n",
      "epoch:8 step:8263 [D loss: 0.698489, acc.: 54.69%] [G loss: 1.013365]\n",
      "epoch:8 step:8264 [D loss: 0.704008, acc.: 54.69%] [G loss: 0.758330]\n",
      "epoch:8 step:8265 [D loss: 0.656474, acc.: 59.38%] [G loss: 0.879609]\n",
      "epoch:8 step:8266 [D loss: 0.672820, acc.: 59.38%] [G loss: 0.914168]\n",
      "epoch:8 step:8267 [D loss: 0.706330, acc.: 53.12%] [G loss: 0.909868]\n",
      "epoch:8 step:8268 [D loss: 0.734981, acc.: 52.34%] [G loss: 0.822372]\n",
      "epoch:8 step:8269 [D loss: 0.684603, acc.: 53.12%] [G loss: 0.881836]\n",
      "epoch:8 step:8270 [D loss: 0.677389, acc.: 59.38%] [G loss: 0.973561]\n",
      "epoch:8 step:8271 [D loss: 0.650044, acc.: 57.03%] [G loss: 1.046837]\n",
      "epoch:8 step:8272 [D loss: 0.633660, acc.: 63.28%] [G loss: 0.981683]\n",
      "epoch:8 step:8273 [D loss: 0.732822, acc.: 53.12%] [G loss: 0.972305]\n",
      "epoch:8 step:8274 [D loss: 0.689235, acc.: 54.69%] [G loss: 0.906868]\n",
      "epoch:8 step:8275 [D loss: 0.691392, acc.: 52.34%] [G loss: 0.957876]\n",
      "epoch:8 step:8276 [D loss: 0.723138, acc.: 53.91%] [G loss: 0.829707]\n",
      "epoch:8 step:8277 [D loss: 0.741339, acc.: 47.66%] [G loss: 0.815414]\n",
      "epoch:8 step:8278 [D loss: 0.575959, acc.: 70.31%] [G loss: 0.932715]\n",
      "epoch:8 step:8279 [D loss: 0.657950, acc.: 56.25%] [G loss: 0.868979]\n",
      "epoch:8 step:8280 [D loss: 0.689914, acc.: 52.34%] [G loss: 0.993325]\n",
      "epoch:8 step:8281 [D loss: 0.613336, acc.: 67.97%] [G loss: 0.814941]\n",
      "epoch:8 step:8282 [D loss: 0.587106, acc.: 71.09%] [G loss: 0.946624]\n",
      "epoch:8 step:8283 [D loss: 0.665454, acc.: 59.38%] [G loss: 0.869305]\n",
      "epoch:8 step:8284 [D loss: 0.724490, acc.: 50.78%] [G loss: 0.869451]\n",
      "epoch:8 step:8285 [D loss: 0.681577, acc.: 55.47%] [G loss: 0.782666]\n",
      "epoch:8 step:8286 [D loss: 0.643063, acc.: 63.28%] [G loss: 0.985173]\n",
      "epoch:8 step:8287 [D loss: 0.625514, acc.: 65.62%] [G loss: 0.942978]\n",
      "epoch:8 step:8288 [D loss: 0.555086, acc.: 74.22%] [G loss: 1.042951]\n",
      "epoch:8 step:8289 [D loss: 0.626884, acc.: 66.41%] [G loss: 1.060203]\n",
      "epoch:8 step:8290 [D loss: 0.704210, acc.: 58.59%] [G loss: 0.931376]\n",
      "epoch:8 step:8291 [D loss: 0.690037, acc.: 54.69%] [G loss: 0.905703]\n",
      "epoch:8 step:8292 [D loss: 0.602758, acc.: 67.97%] [G loss: 0.931434]\n",
      "epoch:8 step:8293 [D loss: 0.640870, acc.: 62.50%] [G loss: 0.925275]\n",
      "epoch:8 step:8294 [D loss: 0.598167, acc.: 72.66%] [G loss: 1.009229]\n",
      "epoch:8 step:8295 [D loss: 0.710306, acc.: 50.78%] [G loss: 0.986176]\n",
      "epoch:8 step:8296 [D loss: 0.731704, acc.: 50.78%] [G loss: 0.836270]\n",
      "epoch:8 step:8297 [D loss: 0.756765, acc.: 52.34%] [G loss: 0.827355]\n",
      "epoch:8 step:8298 [D loss: 0.631796, acc.: 64.06%] [G loss: 0.895577]\n",
      "epoch:8 step:8299 [D loss: 0.645751, acc.: 64.84%] [G loss: 0.954738]\n",
      "epoch:8 step:8300 [D loss: 0.585261, acc.: 71.09%] [G loss: 0.908554]\n",
      "epoch:8 step:8301 [D loss: 0.687453, acc.: 57.03%] [G loss: 0.890813]\n",
      "epoch:8 step:8302 [D loss: 0.631433, acc.: 60.94%] [G loss: 0.996375]\n",
      "epoch:8 step:8303 [D loss: 0.585046, acc.: 71.88%] [G loss: 0.925227]\n",
      "epoch:8 step:8304 [D loss: 0.607969, acc.: 68.75%] [G loss: 0.917681]\n",
      "epoch:8 step:8305 [D loss: 0.673579, acc.: 59.38%] [G loss: 1.030249]\n",
      "epoch:8 step:8306 [D loss: 0.590612, acc.: 73.44%] [G loss: 1.050696]\n",
      "epoch:8 step:8307 [D loss: 0.676526, acc.: 53.12%] [G loss: 0.941610]\n",
      "epoch:8 step:8308 [D loss: 0.636822, acc.: 62.50%] [G loss: 1.054948]\n",
      "epoch:8 step:8309 [D loss: 0.682081, acc.: 55.47%] [G loss: 0.812480]\n",
      "epoch:8 step:8310 [D loss: 0.625439, acc.: 65.62%] [G loss: 0.957553]\n",
      "epoch:8 step:8311 [D loss: 0.662360, acc.: 57.81%] [G loss: 0.949291]\n",
      "epoch:8 step:8312 [D loss: 0.682152, acc.: 63.28%] [G loss: 1.090397]\n",
      "epoch:8 step:8313 [D loss: 0.602283, acc.: 62.50%] [G loss: 1.079168]\n",
      "epoch:8 step:8314 [D loss: 0.694686, acc.: 51.56%] [G loss: 0.897552]\n",
      "epoch:8 step:8315 [D loss: 0.569617, acc.: 71.88%] [G loss: 1.071432]\n",
      "epoch:8 step:8316 [D loss: 0.715551, acc.: 47.66%] [G loss: 1.041599]\n",
      "epoch:8 step:8317 [D loss: 0.618497, acc.: 65.62%] [G loss: 0.990021]\n",
      "epoch:8 step:8318 [D loss: 0.629233, acc.: 62.50%] [G loss: 0.932945]\n",
      "epoch:8 step:8319 [D loss: 0.623239, acc.: 64.06%] [G loss: 0.743400]\n",
      "epoch:8 step:8320 [D loss: 0.666462, acc.: 53.12%] [G loss: 1.014982]\n",
      "epoch:8 step:8321 [D loss: 0.615162, acc.: 67.97%] [G loss: 0.982205]\n",
      "epoch:8 step:8322 [D loss: 0.750690, acc.: 53.12%] [G loss: 0.767444]\n",
      "epoch:8 step:8323 [D loss: 0.731352, acc.: 45.31%] [G loss: 0.899246]\n",
      "epoch:8 step:8324 [D loss: 0.693477, acc.: 53.12%] [G loss: 0.959898]\n",
      "epoch:8 step:8325 [D loss: 0.685325, acc.: 57.03%] [G loss: 0.848522]\n",
      "epoch:8 step:8326 [D loss: 0.702896, acc.: 54.69%] [G loss: 0.882297]\n",
      "epoch:8 step:8327 [D loss: 0.553304, acc.: 77.34%] [G loss: 1.074700]\n",
      "epoch:8 step:8328 [D loss: 0.601771, acc.: 71.09%] [G loss: 0.985854]\n",
      "epoch:8 step:8329 [D loss: 0.624202, acc.: 67.97%] [G loss: 0.999810]\n",
      "epoch:8 step:8330 [D loss: 0.651250, acc.: 59.38%] [G loss: 0.908417]\n",
      "epoch:8 step:8331 [D loss: 0.583333, acc.: 71.88%] [G loss: 1.007310]\n",
      "epoch:8 step:8332 [D loss: 0.700268, acc.: 50.78%] [G loss: 0.904298]\n",
      "epoch:8 step:8333 [D loss: 0.712414, acc.: 57.81%] [G loss: 0.792321]\n",
      "epoch:8 step:8334 [D loss: 0.616345, acc.: 67.19%] [G loss: 1.052011]\n",
      "epoch:8 step:8335 [D loss: 0.604973, acc.: 67.97%] [G loss: 0.968722]\n",
      "epoch:8 step:8336 [D loss: 0.642107, acc.: 60.16%] [G loss: 0.872738]\n",
      "epoch:8 step:8337 [D loss: 0.683336, acc.: 51.56%] [G loss: 0.859495]\n",
      "epoch:8 step:8338 [D loss: 0.591027, acc.: 71.88%] [G loss: 0.937366]\n",
      "epoch:8 step:8339 [D loss: 0.646750, acc.: 60.16%] [G loss: 1.018886]\n",
      "epoch:8 step:8340 [D loss: 0.686515, acc.: 56.25%] [G loss: 0.973256]\n",
      "epoch:8 step:8341 [D loss: 0.649520, acc.: 64.06%] [G loss: 0.900064]\n",
      "epoch:8 step:8342 [D loss: 0.642782, acc.: 61.72%] [G loss: 0.992320]\n",
      "epoch:8 step:8343 [D loss: 0.628524, acc.: 69.53%] [G loss: 1.024341]\n",
      "epoch:8 step:8344 [D loss: 0.677025, acc.: 59.38%] [G loss: 0.890068]\n",
      "epoch:8 step:8345 [D loss: 0.670567, acc.: 58.59%] [G loss: 0.864171]\n",
      "epoch:8 step:8346 [D loss: 0.732652, acc.: 52.34%] [G loss: 0.770177]\n",
      "epoch:8 step:8347 [D loss: 0.648516, acc.: 60.16%] [G loss: 0.845252]\n",
      "epoch:8 step:8348 [D loss: 0.671273, acc.: 61.72%] [G loss: 0.937241]\n",
      "epoch:8 step:8349 [D loss: 0.616419, acc.: 66.41%] [G loss: 0.991963]\n",
      "epoch:8 step:8350 [D loss: 0.650661, acc.: 60.94%] [G loss: 0.902106]\n",
      "epoch:8 step:8351 [D loss: 0.598022, acc.: 67.97%] [G loss: 1.026305]\n",
      "epoch:8 step:8352 [D loss: 0.707912, acc.: 54.69%] [G loss: 0.936667]\n",
      "epoch:8 step:8353 [D loss: 0.640676, acc.: 65.62%] [G loss: 0.928699]\n",
      "epoch:8 step:8354 [D loss: 0.735609, acc.: 50.78%] [G loss: 0.932322]\n",
      "epoch:8 step:8355 [D loss: 0.729967, acc.: 46.88%] [G loss: 0.881877]\n",
      "epoch:8 step:8356 [D loss: 0.623913, acc.: 60.16%] [G loss: 0.948560]\n",
      "epoch:8 step:8357 [D loss: 0.647667, acc.: 55.47%] [G loss: 0.892497]\n",
      "epoch:8 step:8358 [D loss: 0.594554, acc.: 71.09%] [G loss: 0.824860]\n",
      "epoch:8 step:8359 [D loss: 0.687391, acc.: 54.69%] [G loss: 0.987673]\n",
      "epoch:8 step:8360 [D loss: 0.665201, acc.: 58.59%] [G loss: 0.964785]\n",
      "epoch:8 step:8361 [D loss: 0.637251, acc.: 59.38%] [G loss: 0.930627]\n",
      "epoch:8 step:8362 [D loss: 0.756675, acc.: 46.09%] [G loss: 0.845277]\n",
      "epoch:8 step:8363 [D loss: 0.612106, acc.: 64.84%] [G loss: 0.869170]\n",
      "epoch:8 step:8364 [D loss: 0.705673, acc.: 52.34%] [G loss: 0.929187]\n",
      "epoch:8 step:8365 [D loss: 0.702736, acc.: 54.69%] [G loss: 0.975371]\n",
      "epoch:8 step:8366 [D loss: 0.712331, acc.: 53.12%] [G loss: 0.857267]\n",
      "epoch:8 step:8367 [D loss: 0.606985, acc.: 70.31%] [G loss: 1.120162]\n",
      "epoch:8 step:8368 [D loss: 0.673741, acc.: 67.97%] [G loss: 1.017766]\n",
      "epoch:8 step:8369 [D loss: 0.666164, acc.: 62.50%] [G loss: 0.889273]\n",
      "epoch:8 step:8370 [D loss: 0.643495, acc.: 67.19%] [G loss: 1.015273]\n",
      "epoch:8 step:8371 [D loss: 0.607042, acc.: 65.62%] [G loss: 0.982909]\n",
      "epoch:8 step:8372 [D loss: 0.661088, acc.: 58.59%] [G loss: 0.876997]\n",
      "epoch:8 step:8373 [D loss: 0.771508, acc.: 45.31%] [G loss: 0.817843]\n",
      "epoch:8 step:8374 [D loss: 0.649660, acc.: 60.16%] [G loss: 1.090723]\n",
      "epoch:8 step:8375 [D loss: 0.607100, acc.: 67.19%] [G loss: 0.956123]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8376 [D loss: 0.718930, acc.: 51.56%] [G loss: 0.867581]\n",
      "epoch:8 step:8377 [D loss: 0.647240, acc.: 60.94%] [G loss: 0.865940]\n",
      "epoch:8 step:8378 [D loss: 0.694536, acc.: 54.69%] [G loss: 0.907116]\n",
      "epoch:8 step:8379 [D loss: 0.672238, acc.: 56.25%] [G loss: 0.936066]\n",
      "epoch:8 step:8380 [D loss: 0.675730, acc.: 64.06%] [G loss: 0.952946]\n",
      "epoch:8 step:8381 [D loss: 0.600918, acc.: 71.88%] [G loss: 0.989573]\n",
      "epoch:8 step:8382 [D loss: 0.682193, acc.: 57.81%] [G loss: 0.969530]\n",
      "epoch:8 step:8383 [D loss: 0.689510, acc.: 50.00%] [G loss: 0.834735]\n",
      "epoch:8 step:8384 [D loss: 0.640328, acc.: 61.72%] [G loss: 0.916362]\n",
      "epoch:8 step:8385 [D loss: 0.599137, acc.: 68.75%] [G loss: 0.937305]\n",
      "epoch:8 step:8386 [D loss: 0.610556, acc.: 67.19%] [G loss: 0.910699]\n",
      "epoch:8 step:8387 [D loss: 0.686475, acc.: 56.25%] [G loss: 0.960687]\n",
      "epoch:8 step:8388 [D loss: 0.785865, acc.: 46.88%] [G loss: 0.881209]\n",
      "epoch:8 step:8389 [D loss: 0.713749, acc.: 48.44%] [G loss: 0.850627]\n",
      "epoch:8 step:8390 [D loss: 0.660695, acc.: 58.59%] [G loss: 0.821000]\n",
      "epoch:8 step:8391 [D loss: 0.699053, acc.: 53.12%] [G loss: 0.961127]\n",
      "epoch:8 step:8392 [D loss: 0.700205, acc.: 52.34%] [G loss: 1.018437]\n",
      "epoch:8 step:8393 [D loss: 0.650596, acc.: 63.28%] [G loss: 0.863318]\n",
      "epoch:8 step:8394 [D loss: 0.655659, acc.: 60.94%] [G loss: 0.931789]\n",
      "epoch:8 step:8395 [D loss: 0.614717, acc.: 64.06%] [G loss: 0.994973]\n",
      "epoch:8 step:8396 [D loss: 0.683001, acc.: 56.25%] [G loss: 0.920917]\n",
      "epoch:8 step:8397 [D loss: 0.645870, acc.: 66.41%] [G loss: 0.967165]\n",
      "epoch:8 step:8398 [D loss: 0.663823, acc.: 66.41%] [G loss: 0.974046]\n",
      "epoch:8 step:8399 [D loss: 0.625648, acc.: 63.28%] [G loss: 0.894694]\n",
      "epoch:8 step:8400 [D loss: 0.665321, acc.: 58.59%] [G loss: 0.903467]\n",
      "##############\n",
      "[2.2504976  1.41872092 5.25192803 4.34296593 2.97643098 5.22153789\n",
      " 4.2317439  4.50581224 3.59093659 3.65655465]\n",
      "##########\n",
      "epoch:8 step:8401 [D loss: 0.592384, acc.: 70.31%] [G loss: 1.024594]\n",
      "epoch:8 step:8402 [D loss: 0.624048, acc.: 60.16%] [G loss: 1.077302]\n",
      "epoch:8 step:8403 [D loss: 0.618477, acc.: 64.84%] [G loss: 0.951528]\n",
      "epoch:8 step:8404 [D loss: 0.671503, acc.: 61.72%] [G loss: 0.889198]\n",
      "epoch:8 step:8405 [D loss: 0.655907, acc.: 58.59%] [G loss: 0.880848]\n",
      "epoch:8 step:8406 [D loss: 0.592498, acc.: 71.88%] [G loss: 0.996900]\n",
      "epoch:8 step:8407 [D loss: 0.646784, acc.: 66.41%] [G loss: 0.845695]\n",
      "epoch:8 step:8408 [D loss: 0.569480, acc.: 68.75%] [G loss: 1.038186]\n",
      "epoch:8 step:8409 [D loss: 0.632241, acc.: 67.97%] [G loss: 0.942897]\n",
      "epoch:8 step:8410 [D loss: 0.637930, acc.: 63.28%] [G loss: 1.001572]\n",
      "epoch:8 step:8411 [D loss: 0.762560, acc.: 50.00%] [G loss: 0.835235]\n",
      "epoch:8 step:8412 [D loss: 0.657174, acc.: 63.28%] [G loss: 0.989842]\n",
      "epoch:8 step:8413 [D loss: 0.735790, acc.: 49.22%] [G loss: 0.800014]\n",
      "epoch:8 step:8414 [D loss: 0.611757, acc.: 67.19%] [G loss: 1.008191]\n",
      "epoch:8 step:8415 [D loss: 0.649381, acc.: 63.28%] [G loss: 0.927460]\n",
      "epoch:8 step:8416 [D loss: 0.733949, acc.: 47.66%] [G loss: 0.881539]\n",
      "epoch:8 step:8417 [D loss: 0.616396, acc.: 67.19%] [G loss: 1.020180]\n",
      "epoch:8 step:8418 [D loss: 0.628777, acc.: 65.62%] [G loss: 0.919894]\n",
      "epoch:8 step:8419 [D loss: 0.632471, acc.: 64.84%] [G loss: 0.960040]\n",
      "epoch:8 step:8420 [D loss: 0.563898, acc.: 66.41%] [G loss: 0.869512]\n",
      "epoch:8 step:8421 [D loss: 0.538660, acc.: 74.22%] [G loss: 1.034163]\n",
      "epoch:8 step:8422 [D loss: 0.559198, acc.: 74.22%] [G loss: 1.111266]\n",
      "epoch:8 step:8423 [D loss: 0.572032, acc.: 72.66%] [G loss: 1.033645]\n",
      "epoch:8 step:8424 [D loss: 0.807086, acc.: 50.78%] [G loss: 1.018008]\n",
      "epoch:8 step:8425 [D loss: 0.859180, acc.: 36.72%] [G loss: 0.813313]\n",
      "epoch:8 step:8426 [D loss: 0.594622, acc.: 71.09%] [G loss: 0.846701]\n",
      "epoch:8 step:8427 [D loss: 0.619962, acc.: 64.84%] [G loss: 0.906024]\n",
      "epoch:8 step:8428 [D loss: 0.577708, acc.: 74.22%] [G loss: 0.869114]\n",
      "epoch:8 step:8429 [D loss: 0.571231, acc.: 69.53%] [G loss: 1.002123]\n",
      "epoch:8 step:8430 [D loss: 0.565113, acc.: 74.22%] [G loss: 1.042402]\n",
      "epoch:8 step:8431 [D loss: 0.626269, acc.: 64.84%] [G loss: 0.998158]\n",
      "epoch:8 step:8432 [D loss: 0.517352, acc.: 76.56%] [G loss: 0.906399]\n",
      "epoch:8 step:8433 [D loss: 0.504296, acc.: 71.88%] [G loss: 0.932274]\n",
      "epoch:9 step:8434 [D loss: 0.715050, acc.: 61.72%] [G loss: 1.146875]\n",
      "epoch:9 step:8435 [D loss: 0.680194, acc.: 58.59%] [G loss: 0.936817]\n",
      "epoch:9 step:8436 [D loss: 0.690247, acc.: 61.72%] [G loss: 0.999436]\n",
      "epoch:9 step:8437 [D loss: 0.646782, acc.: 63.28%] [G loss: 1.039142]\n",
      "epoch:9 step:8438 [D loss: 0.683249, acc.: 57.03%] [G loss: 1.050474]\n",
      "epoch:9 step:8439 [D loss: 0.606474, acc.: 71.09%] [G loss: 0.918047]\n",
      "epoch:9 step:8440 [D loss: 0.625303, acc.: 60.16%] [G loss: 0.986360]\n",
      "epoch:9 step:8441 [D loss: 0.589131, acc.: 69.53%] [G loss: 1.012209]\n",
      "epoch:9 step:8442 [D loss: 0.665096, acc.: 64.06%] [G loss: 0.925267]\n",
      "epoch:9 step:8443 [D loss: 0.624219, acc.: 65.62%] [G loss: 0.969252]\n",
      "epoch:9 step:8444 [D loss: 0.653296, acc.: 60.94%] [G loss: 0.998944]\n",
      "epoch:9 step:8445 [D loss: 0.709052, acc.: 53.12%] [G loss: 0.992297]\n",
      "epoch:9 step:8446 [D loss: 0.612015, acc.: 67.97%] [G loss: 1.006655]\n",
      "epoch:9 step:8447 [D loss: 0.684437, acc.: 57.81%] [G loss: 1.007842]\n",
      "epoch:9 step:8448 [D loss: 0.661297, acc.: 57.03%] [G loss: 1.006075]\n",
      "epoch:9 step:8449 [D loss: 0.605452, acc.: 71.09%] [G loss: 0.877213]\n",
      "epoch:9 step:8450 [D loss: 0.787743, acc.: 43.75%] [G loss: 1.025098]\n",
      "epoch:9 step:8451 [D loss: 0.707466, acc.: 56.25%] [G loss: 0.966891]\n",
      "epoch:9 step:8452 [D loss: 0.757550, acc.: 45.31%] [G loss: 0.807275]\n",
      "epoch:9 step:8453 [D loss: 0.809909, acc.: 43.75%] [G loss: 0.916479]\n",
      "epoch:9 step:8454 [D loss: 0.689560, acc.: 58.59%] [G loss: 1.018339]\n",
      "epoch:9 step:8455 [D loss: 0.714159, acc.: 57.03%] [G loss: 0.797963]\n",
      "epoch:9 step:8456 [D loss: 0.622035, acc.: 60.94%] [G loss: 0.985782]\n",
      "epoch:9 step:8457 [D loss: 0.693016, acc.: 58.59%] [G loss: 1.028166]\n",
      "epoch:9 step:8458 [D loss: 0.683555, acc.: 55.47%] [G loss: 0.891248]\n",
      "epoch:9 step:8459 [D loss: 0.653479, acc.: 64.06%] [G loss: 0.972075]\n",
      "epoch:9 step:8460 [D loss: 0.726553, acc.: 50.78%] [G loss: 0.873034]\n",
      "epoch:9 step:8461 [D loss: 0.649692, acc.: 63.28%] [G loss: 1.005419]\n",
      "epoch:9 step:8462 [D loss: 0.605296, acc.: 66.41%] [G loss: 0.951449]\n",
      "epoch:9 step:8463 [D loss: 0.644689, acc.: 65.62%] [G loss: 0.882081]\n",
      "epoch:9 step:8464 [D loss: 0.652529, acc.: 59.38%] [G loss: 0.920551]\n",
      "epoch:9 step:8465 [D loss: 0.698971, acc.: 54.69%] [G loss: 0.961255]\n",
      "epoch:9 step:8466 [D loss: 0.617366, acc.: 70.31%] [G loss: 0.961986]\n",
      "epoch:9 step:8467 [D loss: 0.700778, acc.: 57.81%] [G loss: 0.896047]\n",
      "epoch:9 step:8468 [D loss: 0.585095, acc.: 67.97%] [G loss: 1.059809]\n",
      "epoch:9 step:8469 [D loss: 0.572995, acc.: 69.53%] [G loss: 0.986166]\n",
      "epoch:9 step:8470 [D loss: 0.596076, acc.: 69.53%] [G loss: 1.103128]\n",
      "epoch:9 step:8471 [D loss: 0.724499, acc.: 50.00%] [G loss: 1.078481]\n",
      "epoch:9 step:8472 [D loss: 0.750662, acc.: 49.22%] [G loss: 0.879097]\n",
      "epoch:9 step:8473 [D loss: 0.686779, acc.: 57.81%] [G loss: 0.991910]\n",
      "epoch:9 step:8474 [D loss: 0.654837, acc.: 63.28%] [G loss: 1.014894]\n",
      "epoch:9 step:8475 [D loss: 0.668090, acc.: 58.59%] [G loss: 0.907494]\n",
      "epoch:9 step:8476 [D loss: 0.645142, acc.: 64.84%] [G loss: 0.876330]\n",
      "epoch:9 step:8477 [D loss: 0.700025, acc.: 51.56%] [G loss: 0.839828]\n",
      "epoch:9 step:8478 [D loss: 0.666924, acc.: 63.28%] [G loss: 0.971631]\n",
      "epoch:9 step:8479 [D loss: 0.721662, acc.: 49.22%] [G loss: 0.872463]\n",
      "epoch:9 step:8480 [D loss: 0.645336, acc.: 62.50%] [G loss: 0.888642]\n",
      "epoch:9 step:8481 [D loss: 0.698780, acc.: 57.03%] [G loss: 0.862144]\n",
      "epoch:9 step:8482 [D loss: 0.636551, acc.: 60.94%] [G loss: 1.039691]\n",
      "epoch:9 step:8483 [D loss: 0.628543, acc.: 64.84%] [G loss: 0.801703]\n",
      "epoch:9 step:8484 [D loss: 0.710673, acc.: 48.44%] [G loss: 0.914792]\n",
      "epoch:9 step:8485 [D loss: 0.599628, acc.: 65.62%] [G loss: 1.022695]\n",
      "epoch:9 step:8486 [D loss: 0.638616, acc.: 74.22%] [G loss: 0.998234]\n",
      "epoch:9 step:8487 [D loss: 0.658847, acc.: 59.38%] [G loss: 0.909413]\n",
      "epoch:9 step:8488 [D loss: 0.617813, acc.: 67.19%] [G loss: 0.896333]\n",
      "epoch:9 step:8489 [D loss: 0.653718, acc.: 60.94%] [G loss: 0.841972]\n",
      "epoch:9 step:8490 [D loss: 0.696399, acc.: 58.59%] [G loss: 0.870038]\n",
      "epoch:9 step:8491 [D loss: 0.671267, acc.: 58.59%] [G loss: 1.003335]\n",
      "epoch:9 step:8492 [D loss: 0.680034, acc.: 57.81%] [G loss: 1.013716]\n",
      "epoch:9 step:8493 [D loss: 0.727152, acc.: 48.44%] [G loss: 0.824368]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8494 [D loss: 0.641667, acc.: 63.28%] [G loss: 1.009038]\n",
      "epoch:9 step:8495 [D loss: 0.699751, acc.: 53.91%] [G loss: 0.934825]\n",
      "epoch:9 step:8496 [D loss: 0.803793, acc.: 40.62%] [G loss: 0.881095]\n",
      "epoch:9 step:8497 [D loss: 0.702479, acc.: 50.78%] [G loss: 0.862367]\n",
      "epoch:9 step:8498 [D loss: 0.683725, acc.: 60.94%] [G loss: 0.922806]\n",
      "epoch:9 step:8499 [D loss: 0.659314, acc.: 64.84%] [G loss: 0.991224]\n",
      "epoch:9 step:8500 [D loss: 0.648622, acc.: 60.16%] [G loss: 1.077553]\n",
      "epoch:9 step:8501 [D loss: 0.622148, acc.: 62.50%] [G loss: 1.021367]\n",
      "epoch:9 step:8502 [D loss: 0.622245, acc.: 63.28%] [G loss: 1.064265]\n",
      "epoch:9 step:8503 [D loss: 0.652467, acc.: 60.16%] [G loss: 0.967734]\n",
      "epoch:9 step:8504 [D loss: 0.634299, acc.: 64.84%] [G loss: 1.050544]\n",
      "epoch:9 step:8505 [D loss: 0.674132, acc.: 54.69%] [G loss: 1.003156]\n",
      "epoch:9 step:8506 [D loss: 0.720854, acc.: 53.12%] [G loss: 0.918998]\n",
      "epoch:9 step:8507 [D loss: 0.674548, acc.: 61.72%] [G loss: 0.839400]\n",
      "epoch:9 step:8508 [D loss: 0.578781, acc.: 72.66%] [G loss: 0.986054]\n",
      "epoch:9 step:8509 [D loss: 0.627566, acc.: 62.50%] [G loss: 0.910554]\n",
      "epoch:9 step:8510 [D loss: 0.596992, acc.: 68.75%] [G loss: 0.940603]\n",
      "epoch:9 step:8511 [D loss: 0.680358, acc.: 54.69%] [G loss: 0.973495]\n",
      "epoch:9 step:8512 [D loss: 0.725171, acc.: 53.12%] [G loss: 0.879355]\n",
      "epoch:9 step:8513 [D loss: 0.664481, acc.: 61.72%] [G loss: 0.885017]\n",
      "epoch:9 step:8514 [D loss: 0.714237, acc.: 60.94%] [G loss: 0.869153]\n",
      "epoch:9 step:8515 [D loss: 0.722940, acc.: 50.00%] [G loss: 0.898748]\n",
      "epoch:9 step:8516 [D loss: 0.657749, acc.: 63.28%] [G loss: 0.876716]\n",
      "epoch:9 step:8517 [D loss: 0.629849, acc.: 60.94%] [G loss: 0.935631]\n",
      "epoch:9 step:8518 [D loss: 0.620050, acc.: 63.28%] [G loss: 0.868297]\n",
      "epoch:9 step:8519 [D loss: 0.669221, acc.: 57.03%] [G loss: 0.833772]\n",
      "epoch:9 step:8520 [D loss: 0.640731, acc.: 64.06%] [G loss: 0.852103]\n",
      "epoch:9 step:8521 [D loss: 0.682322, acc.: 56.25%] [G loss: 0.875023]\n",
      "epoch:9 step:8522 [D loss: 0.692657, acc.: 59.38%] [G loss: 0.897108]\n",
      "epoch:9 step:8523 [D loss: 0.676278, acc.: 57.03%] [G loss: 0.995986]\n",
      "epoch:9 step:8524 [D loss: 0.693709, acc.: 57.81%] [G loss: 0.819843]\n",
      "epoch:9 step:8525 [D loss: 0.661285, acc.: 56.25%] [G loss: 0.909546]\n",
      "epoch:9 step:8526 [D loss: 0.677404, acc.: 60.94%] [G loss: 0.918359]\n",
      "epoch:9 step:8527 [D loss: 0.720170, acc.: 50.78%] [G loss: 1.013118]\n",
      "epoch:9 step:8528 [D loss: 0.650973, acc.: 61.72%] [G loss: 0.971392]\n",
      "epoch:9 step:8529 [D loss: 0.724762, acc.: 57.81%] [G loss: 0.846404]\n",
      "epoch:9 step:8530 [D loss: 0.683885, acc.: 54.69%] [G loss: 0.903268]\n",
      "epoch:9 step:8531 [D loss: 0.661688, acc.: 57.81%] [G loss: 0.912893]\n",
      "epoch:9 step:8532 [D loss: 0.679880, acc.: 60.16%] [G loss: 0.838038]\n",
      "epoch:9 step:8533 [D loss: 0.677038, acc.: 57.81%] [G loss: 0.913423]\n",
      "epoch:9 step:8534 [D loss: 0.608018, acc.: 67.97%] [G loss: 0.988387]\n",
      "epoch:9 step:8535 [D loss: 0.561532, acc.: 74.22%] [G loss: 1.126022]\n",
      "epoch:9 step:8536 [D loss: 0.617265, acc.: 69.53%] [G loss: 0.996568]\n",
      "epoch:9 step:8537 [D loss: 0.653822, acc.: 60.16%] [G loss: 0.905304]\n",
      "epoch:9 step:8538 [D loss: 0.652032, acc.: 60.16%] [G loss: 0.919473]\n",
      "epoch:9 step:8539 [D loss: 0.559317, acc.: 72.66%] [G loss: 0.988153]\n",
      "epoch:9 step:8540 [D loss: 0.661128, acc.: 53.91%] [G loss: 1.073557]\n",
      "epoch:9 step:8541 [D loss: 0.752958, acc.: 50.78%] [G loss: 0.779584]\n",
      "epoch:9 step:8542 [D loss: 0.717972, acc.: 50.78%] [G loss: 0.986635]\n",
      "epoch:9 step:8543 [D loss: 0.713193, acc.: 55.47%] [G loss: 0.922191]\n",
      "epoch:9 step:8544 [D loss: 0.664596, acc.: 57.81%] [G loss: 0.840679]\n",
      "epoch:9 step:8545 [D loss: 0.582300, acc.: 67.19%] [G loss: 0.929239]\n",
      "epoch:9 step:8546 [D loss: 0.689859, acc.: 57.81%] [G loss: 0.893221]\n",
      "epoch:9 step:8547 [D loss: 0.660674, acc.: 56.25%] [G loss: 0.986881]\n",
      "epoch:9 step:8548 [D loss: 0.659407, acc.: 60.94%] [G loss: 0.916316]\n",
      "epoch:9 step:8549 [D loss: 0.588856, acc.: 67.19%] [G loss: 0.940559]\n",
      "epoch:9 step:8550 [D loss: 0.654783, acc.: 64.06%] [G loss: 0.808637]\n",
      "epoch:9 step:8551 [D loss: 0.709951, acc.: 52.34%] [G loss: 0.871066]\n",
      "epoch:9 step:8552 [D loss: 0.638371, acc.: 63.28%] [G loss: 1.069975]\n",
      "epoch:9 step:8553 [D loss: 0.736264, acc.: 54.69%] [G loss: 1.001527]\n",
      "epoch:9 step:8554 [D loss: 0.617156, acc.: 64.06%] [G loss: 1.002377]\n",
      "epoch:9 step:8555 [D loss: 0.684594, acc.: 62.50%] [G loss: 0.913396]\n",
      "epoch:9 step:8556 [D loss: 0.656716, acc.: 63.28%] [G loss: 0.860899]\n",
      "epoch:9 step:8557 [D loss: 0.694290, acc.: 54.69%] [G loss: 0.973047]\n",
      "epoch:9 step:8558 [D loss: 0.674071, acc.: 60.94%] [G loss: 0.937321]\n",
      "epoch:9 step:8559 [D loss: 0.622374, acc.: 67.97%] [G loss: 0.824887]\n",
      "epoch:9 step:8560 [D loss: 0.697608, acc.: 55.47%] [G loss: 0.944013]\n",
      "epoch:9 step:8561 [D loss: 0.639710, acc.: 64.84%] [G loss: 0.887648]\n",
      "epoch:9 step:8562 [D loss: 0.691239, acc.: 59.38%] [G loss: 0.981713]\n",
      "epoch:9 step:8563 [D loss: 0.612706, acc.: 66.41%] [G loss: 0.854207]\n",
      "epoch:9 step:8564 [D loss: 0.653349, acc.: 65.62%] [G loss: 0.825602]\n",
      "epoch:9 step:8565 [D loss: 0.639953, acc.: 64.84%] [G loss: 0.814421]\n",
      "epoch:9 step:8566 [D loss: 0.757142, acc.: 48.44%] [G loss: 0.946756]\n",
      "epoch:9 step:8567 [D loss: 0.683108, acc.: 54.69%] [G loss: 0.988364]\n",
      "epoch:9 step:8568 [D loss: 0.667755, acc.: 61.72%] [G loss: 0.947942]\n",
      "epoch:9 step:8569 [D loss: 0.693388, acc.: 51.56%] [G loss: 1.023983]\n",
      "epoch:9 step:8570 [D loss: 0.656533, acc.: 58.59%] [G loss: 0.959962]\n",
      "epoch:9 step:8571 [D loss: 0.709370, acc.: 52.34%] [G loss: 1.015918]\n",
      "epoch:9 step:8572 [D loss: 0.647351, acc.: 60.94%] [G loss: 0.838323]\n",
      "epoch:9 step:8573 [D loss: 0.675147, acc.: 54.69%] [G loss: 0.929408]\n",
      "epoch:9 step:8574 [D loss: 0.670248, acc.: 59.38%] [G loss: 0.880633]\n",
      "epoch:9 step:8575 [D loss: 0.603923, acc.: 66.41%] [G loss: 0.849697]\n",
      "epoch:9 step:8576 [D loss: 0.640586, acc.: 60.94%] [G loss: 0.940135]\n",
      "epoch:9 step:8577 [D loss: 0.648347, acc.: 60.94%] [G loss: 0.897530]\n",
      "epoch:9 step:8578 [D loss: 0.631338, acc.: 64.06%] [G loss: 1.010667]\n",
      "epoch:9 step:8579 [D loss: 0.668698, acc.: 57.81%] [G loss: 0.879258]\n",
      "epoch:9 step:8580 [D loss: 0.609879, acc.: 61.72%] [G loss: 1.050745]\n",
      "epoch:9 step:8581 [D loss: 0.693372, acc.: 53.12%] [G loss: 0.948870]\n",
      "epoch:9 step:8582 [D loss: 0.649038, acc.: 64.06%] [G loss: 1.043862]\n",
      "epoch:9 step:8583 [D loss: 0.654637, acc.: 65.62%] [G loss: 0.896915]\n",
      "epoch:9 step:8584 [D loss: 0.598793, acc.: 67.97%] [G loss: 1.087832]\n",
      "epoch:9 step:8585 [D loss: 0.650518, acc.: 62.50%] [G loss: 0.920259]\n",
      "epoch:9 step:8586 [D loss: 0.667207, acc.: 62.50%] [G loss: 0.980595]\n",
      "epoch:9 step:8587 [D loss: 0.683279, acc.: 55.47%] [G loss: 1.020830]\n",
      "epoch:9 step:8588 [D loss: 0.621465, acc.: 68.75%] [G loss: 1.002101]\n",
      "epoch:9 step:8589 [D loss: 0.635807, acc.: 68.75%] [G loss: 0.867974]\n",
      "epoch:9 step:8590 [D loss: 0.718441, acc.: 49.22%] [G loss: 1.023623]\n",
      "epoch:9 step:8591 [D loss: 0.778419, acc.: 47.66%] [G loss: 0.933276]\n",
      "epoch:9 step:8592 [D loss: 0.696125, acc.: 62.50%] [G loss: 0.890608]\n",
      "epoch:9 step:8593 [D loss: 0.737815, acc.: 56.25%] [G loss: 0.849977]\n",
      "epoch:9 step:8594 [D loss: 0.737416, acc.: 45.31%] [G loss: 1.002139]\n",
      "epoch:9 step:8595 [D loss: 0.632645, acc.: 64.06%] [G loss: 0.874522]\n",
      "epoch:9 step:8596 [D loss: 0.671328, acc.: 58.59%] [G loss: 0.929319]\n",
      "epoch:9 step:8597 [D loss: 0.685755, acc.: 55.47%] [G loss: 0.992333]\n",
      "epoch:9 step:8598 [D loss: 0.656618, acc.: 60.16%] [G loss: 1.000414]\n",
      "epoch:9 step:8599 [D loss: 0.664175, acc.: 58.59%] [G loss: 0.875619]\n",
      "epoch:9 step:8600 [D loss: 0.720335, acc.: 47.66%] [G loss: 0.895779]\n",
      "##############\n",
      "[2.16126904 1.1270184  5.28459269 4.13434193 2.61824696 5.1362003\n",
      " 4.04420375 4.26888447 3.87827083 3.32266415]\n",
      "##########\n",
      "epoch:9 step:8601 [D loss: 0.678656, acc.: 58.59%] [G loss: 1.023924]\n",
      "epoch:9 step:8602 [D loss: 0.696553, acc.: 54.69%] [G loss: 1.067416]\n",
      "epoch:9 step:8603 [D loss: 0.693603, acc.: 57.03%] [G loss: 0.873879]\n",
      "epoch:9 step:8604 [D loss: 0.699505, acc.: 54.69%] [G loss: 0.899330]\n",
      "epoch:9 step:8605 [D loss: 0.615917, acc.: 61.72%] [G loss: 1.037493]\n",
      "epoch:9 step:8606 [D loss: 0.665525, acc.: 61.72%] [G loss: 0.933715]\n",
      "epoch:9 step:8607 [D loss: 0.724387, acc.: 48.44%] [G loss: 0.889245]\n",
      "epoch:9 step:8608 [D loss: 0.675250, acc.: 53.91%] [G loss: 0.896066]\n",
      "epoch:9 step:8609 [D loss: 0.655622, acc.: 59.38%] [G loss: 0.867607]\n",
      "epoch:9 step:8610 [D loss: 0.635744, acc.: 64.84%] [G loss: 0.933006]\n",
      "epoch:9 step:8611 [D loss: 0.652406, acc.: 61.72%] [G loss: 0.965741]\n",
      "epoch:9 step:8612 [D loss: 0.656101, acc.: 66.41%] [G loss: 0.970988]\n",
      "epoch:9 step:8613 [D loss: 0.660469, acc.: 64.06%] [G loss: 0.881914]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8614 [D loss: 0.707564, acc.: 54.69%] [G loss: 0.989712]\n",
      "epoch:9 step:8615 [D loss: 0.723575, acc.: 48.44%] [G loss: 0.918865]\n",
      "epoch:9 step:8616 [D loss: 0.665859, acc.: 59.38%] [G loss: 0.824322]\n",
      "epoch:9 step:8617 [D loss: 0.685331, acc.: 60.16%] [G loss: 0.863298]\n",
      "epoch:9 step:8618 [D loss: 0.678835, acc.: 55.47%] [G loss: 0.876711]\n",
      "epoch:9 step:8619 [D loss: 0.689979, acc.: 60.16%] [G loss: 0.873309]\n",
      "epoch:9 step:8620 [D loss: 0.645983, acc.: 63.28%] [G loss: 0.875417]\n",
      "epoch:9 step:8621 [D loss: 0.670626, acc.: 61.72%] [G loss: 0.981200]\n",
      "epoch:9 step:8622 [D loss: 0.709421, acc.: 54.69%] [G loss: 0.855417]\n",
      "epoch:9 step:8623 [D loss: 0.532311, acc.: 77.34%] [G loss: 1.125285]\n",
      "epoch:9 step:8624 [D loss: 0.605131, acc.: 67.19%] [G loss: 0.987762]\n",
      "epoch:9 step:8625 [D loss: 0.643235, acc.: 61.72%] [G loss: 0.925989]\n",
      "epoch:9 step:8626 [D loss: 0.702874, acc.: 56.25%] [G loss: 0.989422]\n",
      "epoch:9 step:8627 [D loss: 0.646638, acc.: 63.28%] [G loss: 0.999507]\n",
      "epoch:9 step:8628 [D loss: 0.688546, acc.: 53.91%] [G loss: 0.945915]\n",
      "epoch:9 step:8629 [D loss: 0.759400, acc.: 47.66%] [G loss: 1.102112]\n",
      "epoch:9 step:8630 [D loss: 0.635675, acc.: 60.94%] [G loss: 0.984316]\n",
      "epoch:9 step:8631 [D loss: 0.647761, acc.: 59.38%] [G loss: 1.046695]\n",
      "epoch:9 step:8632 [D loss: 0.671705, acc.: 55.47%] [G loss: 0.903836]\n",
      "epoch:9 step:8633 [D loss: 0.728729, acc.: 51.56%] [G loss: 0.896853]\n",
      "epoch:9 step:8634 [D loss: 0.676663, acc.: 63.28%] [G loss: 0.856246]\n",
      "epoch:9 step:8635 [D loss: 0.708696, acc.: 55.47%] [G loss: 0.827011]\n",
      "epoch:9 step:8636 [D loss: 0.700168, acc.: 57.81%] [G loss: 0.925679]\n",
      "epoch:9 step:8637 [D loss: 0.671579, acc.: 56.25%] [G loss: 0.941518]\n",
      "epoch:9 step:8638 [D loss: 0.731749, acc.: 57.03%] [G loss: 0.965136]\n",
      "epoch:9 step:8639 [D loss: 0.645040, acc.: 62.50%] [G loss: 0.834687]\n",
      "epoch:9 step:8640 [D loss: 0.581476, acc.: 71.88%] [G loss: 0.977267]\n",
      "epoch:9 step:8641 [D loss: 0.692081, acc.: 53.12%] [G loss: 0.940204]\n",
      "epoch:9 step:8642 [D loss: 0.632805, acc.: 64.84%] [G loss: 0.890921]\n",
      "epoch:9 step:8643 [D loss: 0.658640, acc.: 63.28%] [G loss: 0.887899]\n",
      "epoch:9 step:8644 [D loss: 0.625249, acc.: 67.19%] [G loss: 1.007703]\n",
      "epoch:9 step:8645 [D loss: 0.679338, acc.: 57.81%] [G loss: 0.799243]\n",
      "epoch:9 step:8646 [D loss: 0.707658, acc.: 53.91%] [G loss: 0.958125]\n",
      "epoch:9 step:8647 [D loss: 0.756726, acc.: 45.31%] [G loss: 0.827417]\n",
      "epoch:9 step:8648 [D loss: 0.779066, acc.: 38.28%] [G loss: 0.922301]\n",
      "epoch:9 step:8649 [D loss: 0.632632, acc.: 62.50%] [G loss: 0.937520]\n",
      "epoch:9 step:8650 [D loss: 0.636575, acc.: 64.06%] [G loss: 0.870957]\n",
      "epoch:9 step:8651 [D loss: 0.590509, acc.: 71.09%] [G loss: 0.964846]\n",
      "epoch:9 step:8652 [D loss: 0.596080, acc.: 67.97%] [G loss: 0.962620]\n",
      "epoch:9 step:8653 [D loss: 0.711748, acc.: 50.00%] [G loss: 0.962820]\n",
      "epoch:9 step:8654 [D loss: 0.693072, acc.: 53.12%] [G loss: 0.929890]\n",
      "epoch:9 step:8655 [D loss: 0.655319, acc.: 66.41%] [G loss: 0.950269]\n",
      "epoch:9 step:8656 [D loss: 0.569673, acc.: 73.44%] [G loss: 1.191312]\n",
      "epoch:9 step:8657 [D loss: 0.649611, acc.: 62.50%] [G loss: 0.956711]\n",
      "epoch:9 step:8658 [D loss: 0.666297, acc.: 56.25%] [G loss: 0.944113]\n",
      "epoch:9 step:8659 [D loss: 0.690606, acc.: 57.81%] [G loss: 0.906854]\n",
      "epoch:9 step:8660 [D loss: 0.715363, acc.: 50.00%] [G loss: 0.827071]\n",
      "epoch:9 step:8661 [D loss: 0.683354, acc.: 56.25%] [G loss: 0.891944]\n",
      "epoch:9 step:8662 [D loss: 0.670380, acc.: 60.94%] [G loss: 0.867337]\n",
      "epoch:9 step:8663 [D loss: 0.496689, acc.: 79.69%] [G loss: 1.047199]\n",
      "epoch:9 step:8664 [D loss: 0.573686, acc.: 75.78%] [G loss: 1.146976]\n",
      "epoch:9 step:8665 [D loss: 0.562066, acc.: 71.09%] [G loss: 0.901155]\n",
      "epoch:9 step:8666 [D loss: 0.675931, acc.: 57.81%] [G loss: 1.081651]\n",
      "epoch:9 step:8667 [D loss: 0.721244, acc.: 55.47%] [G loss: 1.001191]\n",
      "epoch:9 step:8668 [D loss: 0.635230, acc.: 62.50%] [G loss: 1.084719]\n",
      "epoch:9 step:8669 [D loss: 0.661127, acc.: 57.81%] [G loss: 0.946003]\n",
      "epoch:9 step:8670 [D loss: 0.638927, acc.: 61.72%] [G loss: 0.925561]\n",
      "epoch:9 step:8671 [D loss: 0.661578, acc.: 62.50%] [G loss: 0.881061]\n",
      "epoch:9 step:8672 [D loss: 0.718785, acc.: 50.00%] [G loss: 0.876693]\n",
      "epoch:9 step:8673 [D loss: 0.763856, acc.: 53.12%] [G loss: 0.812250]\n",
      "epoch:9 step:8674 [D loss: 0.631854, acc.: 61.72%] [G loss: 0.857362]\n",
      "epoch:9 step:8675 [D loss: 0.608005, acc.: 67.97%] [G loss: 0.947984]\n",
      "epoch:9 step:8676 [D loss: 0.712512, acc.: 52.34%] [G loss: 0.897922]\n",
      "epoch:9 step:8677 [D loss: 0.579937, acc.: 70.31%] [G loss: 0.970125]\n",
      "epoch:9 step:8678 [D loss: 0.667917, acc.: 57.81%] [G loss: 0.894555]\n",
      "epoch:9 step:8679 [D loss: 0.630651, acc.: 61.72%] [G loss: 0.884951]\n",
      "epoch:9 step:8680 [D loss: 0.766425, acc.: 46.88%] [G loss: 0.876151]\n",
      "epoch:9 step:8681 [D loss: 0.677519, acc.: 59.38%] [G loss: 1.030794]\n",
      "epoch:9 step:8682 [D loss: 0.784111, acc.: 42.19%] [G loss: 0.850733]\n",
      "epoch:9 step:8683 [D loss: 0.754576, acc.: 53.91%] [G loss: 0.912206]\n",
      "epoch:9 step:8684 [D loss: 0.666753, acc.: 60.94%] [G loss: 0.894389]\n",
      "epoch:9 step:8685 [D loss: 0.637763, acc.: 59.38%] [G loss: 0.949142]\n",
      "epoch:9 step:8686 [D loss: 0.693863, acc.: 51.56%] [G loss: 0.934471]\n",
      "epoch:9 step:8687 [D loss: 0.580129, acc.: 66.41%] [G loss: 0.922696]\n",
      "epoch:9 step:8688 [D loss: 0.684844, acc.: 51.56%] [G loss: 0.866916]\n",
      "epoch:9 step:8689 [D loss: 0.624931, acc.: 66.41%] [G loss: 0.915904]\n",
      "epoch:9 step:8690 [D loss: 0.647956, acc.: 63.28%] [G loss: 0.929327]\n",
      "epoch:9 step:8691 [D loss: 0.599528, acc.: 67.19%] [G loss: 1.024136]\n",
      "epoch:9 step:8692 [D loss: 0.650921, acc.: 64.06%] [G loss: 0.972597]\n",
      "epoch:9 step:8693 [D loss: 0.685103, acc.: 60.16%] [G loss: 0.901938]\n",
      "epoch:9 step:8694 [D loss: 0.616851, acc.: 67.19%] [G loss: 0.990274]\n",
      "epoch:9 step:8695 [D loss: 0.606781, acc.: 67.19%] [G loss: 0.965874]\n",
      "epoch:9 step:8696 [D loss: 0.710122, acc.: 51.56%] [G loss: 0.947385]\n",
      "epoch:9 step:8697 [D loss: 0.588044, acc.: 66.41%] [G loss: 0.935614]\n",
      "epoch:9 step:8698 [D loss: 0.622153, acc.: 65.62%] [G loss: 0.998649]\n",
      "epoch:9 step:8699 [D loss: 0.628814, acc.: 64.84%] [G loss: 0.917955]\n",
      "epoch:9 step:8700 [D loss: 0.623453, acc.: 64.84%] [G loss: 0.993264]\n",
      "epoch:9 step:8701 [D loss: 0.734676, acc.: 50.78%] [G loss: 0.923041]\n",
      "epoch:9 step:8702 [D loss: 0.653638, acc.: 63.28%] [G loss: 1.001621]\n",
      "epoch:9 step:8703 [D loss: 0.642674, acc.: 60.94%] [G loss: 0.886609]\n",
      "epoch:9 step:8704 [D loss: 0.686697, acc.: 53.12%] [G loss: 0.840079]\n",
      "epoch:9 step:8705 [D loss: 0.706077, acc.: 53.91%] [G loss: 0.847261]\n",
      "epoch:9 step:8706 [D loss: 0.606717, acc.: 67.97%] [G loss: 0.953155]\n",
      "epoch:9 step:8707 [D loss: 0.671797, acc.: 60.16%] [G loss: 0.985160]\n",
      "epoch:9 step:8708 [D loss: 0.677655, acc.: 54.69%] [G loss: 0.986732]\n",
      "epoch:9 step:8709 [D loss: 0.744274, acc.: 52.34%] [G loss: 0.911242]\n",
      "epoch:9 step:8710 [D loss: 0.713154, acc.: 57.81%] [G loss: 0.970001]\n",
      "epoch:9 step:8711 [D loss: 0.688373, acc.: 56.25%] [G loss: 0.891424]\n",
      "epoch:9 step:8712 [D loss: 0.682939, acc.: 57.81%] [G loss: 0.884879]\n",
      "epoch:9 step:8713 [D loss: 0.680806, acc.: 57.81%] [G loss: 0.979960]\n",
      "epoch:9 step:8714 [D loss: 0.678499, acc.: 57.03%] [G loss: 1.023095]\n",
      "epoch:9 step:8715 [D loss: 0.683750, acc.: 55.47%] [G loss: 1.027140]\n",
      "epoch:9 step:8716 [D loss: 0.609695, acc.: 68.75%] [G loss: 1.048153]\n",
      "epoch:9 step:8717 [D loss: 0.664418, acc.: 57.03%] [G loss: 0.918838]\n",
      "epoch:9 step:8718 [D loss: 0.667729, acc.: 57.81%] [G loss: 0.927578]\n",
      "epoch:9 step:8719 [D loss: 0.620393, acc.: 67.19%] [G loss: 0.940564]\n",
      "epoch:9 step:8720 [D loss: 0.644148, acc.: 61.72%] [G loss: 0.946881]\n",
      "epoch:9 step:8721 [D loss: 0.700743, acc.: 49.22%] [G loss: 1.023713]\n",
      "epoch:9 step:8722 [D loss: 0.607642, acc.: 68.75%] [G loss: 1.014875]\n",
      "epoch:9 step:8723 [D loss: 0.728850, acc.: 52.34%] [G loss: 0.792604]\n",
      "epoch:9 step:8724 [D loss: 0.689485, acc.: 53.91%] [G loss: 0.932783]\n",
      "epoch:9 step:8725 [D loss: 0.683554, acc.: 57.81%] [G loss: 0.991759]\n",
      "epoch:9 step:8726 [D loss: 0.680509, acc.: 53.91%] [G loss: 0.908061]\n",
      "epoch:9 step:8727 [D loss: 0.709860, acc.: 50.78%] [G loss: 0.788184]\n",
      "epoch:9 step:8728 [D loss: 0.625720, acc.: 67.97%] [G loss: 0.984357]\n",
      "epoch:9 step:8729 [D loss: 0.622468, acc.: 61.72%] [G loss: 0.940514]\n",
      "epoch:9 step:8730 [D loss: 0.627885, acc.: 63.28%] [G loss: 0.930119]\n",
      "epoch:9 step:8731 [D loss: 0.619442, acc.: 63.28%] [G loss: 0.874591]\n",
      "epoch:9 step:8732 [D loss: 0.649603, acc.: 60.94%] [G loss: 0.830227]\n",
      "epoch:9 step:8733 [D loss: 0.612300, acc.: 66.41%] [G loss: 0.892881]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8734 [D loss: 0.743750, acc.: 48.44%] [G loss: 0.933378]\n",
      "epoch:9 step:8735 [D loss: 0.623598, acc.: 69.53%] [G loss: 0.905342]\n",
      "epoch:9 step:8736 [D loss: 0.690601, acc.: 56.25%] [G loss: 0.906305]\n",
      "epoch:9 step:8737 [D loss: 0.629843, acc.: 61.72%] [G loss: 0.986213]\n",
      "epoch:9 step:8738 [D loss: 0.631272, acc.: 60.94%] [G loss: 0.974889]\n",
      "epoch:9 step:8739 [D loss: 0.656245, acc.: 60.16%] [G loss: 0.947819]\n",
      "epoch:9 step:8740 [D loss: 0.625152, acc.: 71.09%] [G loss: 0.964513]\n",
      "epoch:9 step:8741 [D loss: 0.633186, acc.: 67.19%] [G loss: 0.898320]\n",
      "epoch:9 step:8742 [D loss: 0.654362, acc.: 63.28%] [G loss: 0.968848]\n",
      "epoch:9 step:8743 [D loss: 0.615854, acc.: 68.75%] [G loss: 0.804770]\n",
      "epoch:9 step:8744 [D loss: 0.593235, acc.: 72.66%] [G loss: 0.837891]\n",
      "epoch:9 step:8745 [D loss: 0.643022, acc.: 64.84%] [G loss: 0.915035]\n",
      "epoch:9 step:8746 [D loss: 0.577828, acc.: 71.88%] [G loss: 1.006610]\n",
      "epoch:9 step:8747 [D loss: 0.593459, acc.: 68.75%] [G loss: 1.027916]\n",
      "epoch:9 step:8748 [D loss: 0.589560, acc.: 65.62%] [G loss: 0.993177]\n",
      "epoch:9 step:8749 [D loss: 0.666619, acc.: 59.38%] [G loss: 1.080457]\n",
      "epoch:9 step:8750 [D loss: 0.736180, acc.: 56.25%] [G loss: 0.991271]\n",
      "epoch:9 step:8751 [D loss: 0.647084, acc.: 60.94%] [G loss: 1.127036]\n",
      "epoch:9 step:8752 [D loss: 0.695217, acc.: 57.81%] [G loss: 0.927606]\n",
      "epoch:9 step:8753 [D loss: 0.640082, acc.: 64.06%] [G loss: 0.902922]\n",
      "epoch:9 step:8754 [D loss: 0.586281, acc.: 72.66%] [G loss: 0.983813]\n",
      "epoch:9 step:8755 [D loss: 0.636634, acc.: 64.06%] [G loss: 0.961489]\n",
      "epoch:9 step:8756 [D loss: 0.638004, acc.: 64.06%] [G loss: 0.943534]\n",
      "epoch:9 step:8757 [D loss: 0.673204, acc.: 56.25%] [G loss: 1.016440]\n",
      "epoch:9 step:8758 [D loss: 0.588554, acc.: 67.19%] [G loss: 0.985831]\n",
      "epoch:9 step:8759 [D loss: 0.619005, acc.: 62.50%] [G loss: 0.985403]\n",
      "epoch:9 step:8760 [D loss: 0.662780, acc.: 57.03%] [G loss: 0.903227]\n",
      "epoch:9 step:8761 [D loss: 0.690875, acc.: 55.47%] [G loss: 0.890549]\n",
      "epoch:9 step:8762 [D loss: 0.642087, acc.: 62.50%] [G loss: 1.000471]\n",
      "epoch:9 step:8763 [D loss: 0.647545, acc.: 56.25%] [G loss: 0.933727]\n",
      "epoch:9 step:8764 [D loss: 0.696884, acc.: 59.38%] [G loss: 0.905479]\n",
      "epoch:9 step:8765 [D loss: 0.696467, acc.: 54.69%] [G loss: 0.876082]\n",
      "epoch:9 step:8766 [D loss: 0.739194, acc.: 50.00%] [G loss: 0.872716]\n",
      "epoch:9 step:8767 [D loss: 0.770383, acc.: 42.19%] [G loss: 0.935392]\n",
      "epoch:9 step:8768 [D loss: 0.606760, acc.: 67.97%] [G loss: 0.927830]\n",
      "epoch:9 step:8769 [D loss: 0.607247, acc.: 64.84%] [G loss: 0.998150]\n",
      "epoch:9 step:8770 [D loss: 0.620612, acc.: 64.06%] [G loss: 0.928358]\n",
      "epoch:9 step:8771 [D loss: 0.655909, acc.: 61.72%] [G loss: 0.885442]\n",
      "epoch:9 step:8772 [D loss: 0.657890, acc.: 64.84%] [G loss: 1.003462]\n",
      "epoch:9 step:8773 [D loss: 0.679929, acc.: 52.34%] [G loss: 0.929500]\n",
      "epoch:9 step:8774 [D loss: 0.670691, acc.: 63.28%] [G loss: 0.908166]\n",
      "epoch:9 step:8775 [D loss: 0.650521, acc.: 61.72%] [G loss: 0.912120]\n",
      "epoch:9 step:8776 [D loss: 0.674602, acc.: 60.16%] [G loss: 0.932368]\n",
      "epoch:9 step:8777 [D loss: 0.608188, acc.: 72.66%] [G loss: 0.848410]\n",
      "epoch:9 step:8778 [D loss: 0.634702, acc.: 64.06%] [G loss: 0.865985]\n",
      "epoch:9 step:8779 [D loss: 0.523858, acc.: 81.25%] [G loss: 1.027711]\n",
      "epoch:9 step:8780 [D loss: 0.628335, acc.: 63.28%] [G loss: 1.090104]\n",
      "epoch:9 step:8781 [D loss: 0.649030, acc.: 60.94%] [G loss: 0.978474]\n",
      "epoch:9 step:8782 [D loss: 0.729183, acc.: 50.00%] [G loss: 0.859749]\n",
      "epoch:9 step:8783 [D loss: 0.688310, acc.: 58.59%] [G loss: 0.861198]\n",
      "epoch:9 step:8784 [D loss: 0.621949, acc.: 69.53%] [G loss: 1.000628]\n",
      "epoch:9 step:8785 [D loss: 0.764842, acc.: 52.34%] [G loss: 0.824565]\n",
      "epoch:9 step:8786 [D loss: 0.701780, acc.: 53.12%] [G loss: 0.839754]\n",
      "epoch:9 step:8787 [D loss: 0.726238, acc.: 48.44%] [G loss: 0.872171]\n",
      "epoch:9 step:8788 [D loss: 0.718947, acc.: 47.66%] [G loss: 0.931101]\n",
      "epoch:9 step:8789 [D loss: 0.693440, acc.: 62.50%] [G loss: 0.860329]\n",
      "epoch:9 step:8790 [D loss: 0.633053, acc.: 61.72%] [G loss: 1.033339]\n",
      "epoch:9 step:8791 [D loss: 0.638360, acc.: 61.72%] [G loss: 1.027745]\n",
      "epoch:9 step:8792 [D loss: 0.648265, acc.: 65.62%] [G loss: 0.969018]\n",
      "epoch:9 step:8793 [D loss: 0.630382, acc.: 59.38%] [G loss: 0.974610]\n",
      "epoch:9 step:8794 [D loss: 0.615548, acc.: 67.19%] [G loss: 1.026361]\n",
      "epoch:9 step:8795 [D loss: 0.721575, acc.: 46.88%] [G loss: 0.921815]\n",
      "epoch:9 step:8796 [D loss: 0.688004, acc.: 56.25%] [G loss: 0.951453]\n",
      "epoch:9 step:8797 [D loss: 0.656113, acc.: 64.06%] [G loss: 0.916029]\n",
      "epoch:9 step:8798 [D loss: 0.654768, acc.: 61.72%] [G loss: 1.011815]\n",
      "epoch:9 step:8799 [D loss: 0.621521, acc.: 62.50%] [G loss: 0.894810]\n",
      "epoch:9 step:8800 [D loss: 0.618898, acc.: 64.84%] [G loss: 1.089943]\n",
      "##############\n",
      "[2.13420983 1.19894002 5.24452066 4.39700185 2.77495389 5.36031933\n",
      " 3.90368755 4.47039776 3.74063313 3.43001888]\n",
      "##########\n",
      "epoch:9 step:8801 [D loss: 0.608303, acc.: 64.06%] [G loss: 0.967730]\n",
      "epoch:9 step:8802 [D loss: 0.660468, acc.: 57.81%] [G loss: 1.031108]\n",
      "epoch:9 step:8803 [D loss: 0.640283, acc.: 64.84%] [G loss: 0.928547]\n",
      "epoch:9 step:8804 [D loss: 0.605765, acc.: 66.41%] [G loss: 1.029553]\n",
      "epoch:9 step:8805 [D loss: 0.727239, acc.: 52.34%] [G loss: 0.878702]\n",
      "epoch:9 step:8806 [D loss: 0.748638, acc.: 45.31%] [G loss: 0.942481]\n",
      "epoch:9 step:8807 [D loss: 0.601857, acc.: 64.06%] [G loss: 0.961935]\n",
      "epoch:9 step:8808 [D loss: 0.620324, acc.: 71.09%] [G loss: 1.029656]\n",
      "epoch:9 step:8809 [D loss: 0.723461, acc.: 51.56%] [G loss: 0.967170]\n",
      "epoch:9 step:8810 [D loss: 0.673538, acc.: 55.47%] [G loss: 0.857659]\n",
      "epoch:9 step:8811 [D loss: 0.674419, acc.: 59.38%] [G loss: 0.896015]\n",
      "epoch:9 step:8812 [D loss: 0.644583, acc.: 63.28%] [G loss: 0.947108]\n",
      "epoch:9 step:8813 [D loss: 0.663468, acc.: 59.38%] [G loss: 0.900791]\n",
      "epoch:9 step:8814 [D loss: 0.669710, acc.: 58.59%] [G loss: 0.937491]\n",
      "epoch:9 step:8815 [D loss: 0.687961, acc.: 61.72%] [G loss: 0.961149]\n",
      "epoch:9 step:8816 [D loss: 0.664167, acc.: 60.16%] [G loss: 1.081852]\n",
      "epoch:9 step:8817 [D loss: 0.661772, acc.: 63.28%] [G loss: 0.989451]\n",
      "epoch:9 step:8818 [D loss: 0.644464, acc.: 61.72%] [G loss: 1.013355]\n",
      "epoch:9 step:8819 [D loss: 0.667820, acc.: 57.81%] [G loss: 1.111832]\n",
      "epoch:9 step:8820 [D loss: 0.680731, acc.: 54.69%] [G loss: 0.971354]\n",
      "epoch:9 step:8821 [D loss: 0.667744, acc.: 61.72%] [G loss: 0.885436]\n",
      "epoch:9 step:8822 [D loss: 0.599185, acc.: 66.41%] [G loss: 0.765409]\n",
      "epoch:9 step:8823 [D loss: 0.675734, acc.: 57.03%] [G loss: 0.855878]\n",
      "epoch:9 step:8824 [D loss: 0.612026, acc.: 64.06%] [G loss: 1.028270]\n",
      "epoch:9 step:8825 [D loss: 0.664837, acc.: 60.94%] [G loss: 0.884506]\n",
      "epoch:9 step:8826 [D loss: 0.723099, acc.: 49.22%] [G loss: 0.950690]\n",
      "epoch:9 step:8827 [D loss: 0.652086, acc.: 61.72%] [G loss: 0.896992]\n",
      "epoch:9 step:8828 [D loss: 0.602039, acc.: 64.84%] [G loss: 0.871447]\n",
      "epoch:9 step:8829 [D loss: 0.720496, acc.: 51.56%] [G loss: 0.952466]\n",
      "epoch:9 step:8830 [D loss: 0.736192, acc.: 49.22%] [G loss: 0.915991]\n",
      "epoch:9 step:8831 [D loss: 0.664679, acc.: 56.25%] [G loss: 0.980666]\n",
      "epoch:9 step:8832 [D loss: 0.676451, acc.: 57.03%] [G loss: 0.940118]\n",
      "epoch:9 step:8833 [D loss: 0.712301, acc.: 57.03%] [G loss: 1.017630]\n",
      "epoch:9 step:8834 [D loss: 0.585348, acc.: 67.19%] [G loss: 0.964027]\n",
      "epoch:9 step:8835 [D loss: 0.672752, acc.: 60.16%] [G loss: 0.958066]\n",
      "epoch:9 step:8836 [D loss: 0.688902, acc.: 53.12%] [G loss: 0.920872]\n",
      "epoch:9 step:8837 [D loss: 0.718151, acc.: 55.47%] [G loss: 0.928941]\n",
      "epoch:9 step:8838 [D loss: 0.620600, acc.: 63.28%] [G loss: 0.998856]\n",
      "epoch:9 step:8839 [D loss: 0.506143, acc.: 78.91%] [G loss: 1.013815]\n",
      "epoch:9 step:8840 [D loss: 0.659644, acc.: 62.50%] [G loss: 0.927767]\n",
      "epoch:9 step:8841 [D loss: 0.664998, acc.: 60.94%] [G loss: 0.922789]\n",
      "epoch:9 step:8842 [D loss: 0.658261, acc.: 60.94%] [G loss: 0.922517]\n",
      "epoch:9 step:8843 [D loss: 0.642898, acc.: 60.94%] [G loss: 1.108598]\n",
      "epoch:9 step:8844 [D loss: 0.688063, acc.: 52.34%] [G loss: 0.871174]\n",
      "epoch:9 step:8845 [D loss: 0.640456, acc.: 61.72%] [G loss: 0.965106]\n",
      "epoch:9 step:8846 [D loss: 0.623158, acc.: 64.84%] [G loss: 0.968181]\n",
      "epoch:9 step:8847 [D loss: 0.645928, acc.: 64.84%] [G loss: 0.959330]\n",
      "epoch:9 step:8848 [D loss: 0.703004, acc.: 57.81%] [G loss: 1.101206]\n",
      "epoch:9 step:8849 [D loss: 0.614995, acc.: 65.62%] [G loss: 0.967796]\n",
      "epoch:9 step:8850 [D loss: 0.597809, acc.: 65.62%] [G loss: 1.017366]\n",
      "epoch:9 step:8851 [D loss: 0.648705, acc.: 60.94%] [G loss: 1.077142]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8852 [D loss: 0.724308, acc.: 53.12%] [G loss: 0.897735]\n",
      "epoch:9 step:8853 [D loss: 0.570432, acc.: 71.88%] [G loss: 1.139909]\n",
      "epoch:9 step:8854 [D loss: 0.630512, acc.: 61.72%] [G loss: 0.997109]\n",
      "epoch:9 step:8855 [D loss: 0.703612, acc.: 51.56%] [G loss: 0.823728]\n",
      "epoch:9 step:8856 [D loss: 0.680225, acc.: 59.38%] [G loss: 0.770173]\n",
      "epoch:9 step:8857 [D loss: 0.591010, acc.: 68.75%] [G loss: 1.126382]\n",
      "epoch:9 step:8858 [D loss: 0.668877, acc.: 60.94%] [G loss: 0.952419]\n",
      "epoch:9 step:8859 [D loss: 0.626310, acc.: 67.19%] [G loss: 0.999703]\n",
      "epoch:9 step:8860 [D loss: 0.642572, acc.: 59.38%] [G loss: 1.002832]\n",
      "epoch:9 step:8861 [D loss: 0.585302, acc.: 72.66%] [G loss: 0.998385]\n",
      "epoch:9 step:8862 [D loss: 0.618280, acc.: 66.41%] [G loss: 0.939748]\n",
      "epoch:9 step:8863 [D loss: 0.563290, acc.: 75.00%] [G loss: 1.024822]\n",
      "epoch:9 step:8864 [D loss: 0.649644, acc.: 63.28%] [G loss: 0.869828]\n",
      "epoch:9 step:8865 [D loss: 0.753612, acc.: 50.00%] [G loss: 1.074883]\n",
      "epoch:9 step:8866 [D loss: 0.674384, acc.: 57.03%] [G loss: 0.929665]\n",
      "epoch:9 step:8867 [D loss: 0.666631, acc.: 59.38%] [G loss: 0.907597]\n",
      "epoch:9 step:8868 [D loss: 0.703022, acc.: 56.25%] [G loss: 0.775457]\n",
      "epoch:9 step:8869 [D loss: 0.714254, acc.: 52.34%] [G loss: 1.014441]\n",
      "epoch:9 step:8870 [D loss: 0.737234, acc.: 56.25%] [G loss: 1.007779]\n",
      "epoch:9 step:8871 [D loss: 0.636776, acc.: 62.50%] [G loss: 0.974761]\n",
      "epoch:9 step:8872 [D loss: 0.684330, acc.: 57.03%] [G loss: 0.998774]\n",
      "epoch:9 step:8873 [D loss: 0.653315, acc.: 60.94%] [G loss: 1.052613]\n",
      "epoch:9 step:8874 [D loss: 0.726990, acc.: 49.22%] [G loss: 0.911884]\n",
      "epoch:9 step:8875 [D loss: 0.685814, acc.: 53.12%] [G loss: 1.074435]\n",
      "epoch:9 step:8876 [D loss: 0.669698, acc.: 60.16%] [G loss: 0.851757]\n",
      "epoch:9 step:8877 [D loss: 0.645256, acc.: 61.72%] [G loss: 0.895045]\n",
      "epoch:9 step:8878 [D loss: 0.747641, acc.: 48.44%] [G loss: 0.838554]\n",
      "epoch:9 step:8879 [D loss: 0.688942, acc.: 57.81%] [G loss: 0.871582]\n",
      "epoch:9 step:8880 [D loss: 0.643104, acc.: 63.28%] [G loss: 0.921098]\n",
      "epoch:9 step:8881 [D loss: 0.665828, acc.: 58.59%] [G loss: 0.913636]\n",
      "epoch:9 step:8882 [D loss: 0.690392, acc.: 56.25%] [G loss: 0.851889]\n",
      "epoch:9 step:8883 [D loss: 0.692526, acc.: 58.59%] [G loss: 0.957217]\n",
      "epoch:9 step:8884 [D loss: 0.665361, acc.: 60.94%] [G loss: 0.962392]\n",
      "epoch:9 step:8885 [D loss: 0.674349, acc.: 61.72%] [G loss: 1.083336]\n",
      "epoch:9 step:8886 [D loss: 0.621105, acc.: 65.62%] [G loss: 1.022469]\n",
      "epoch:9 step:8887 [D loss: 0.579365, acc.: 74.22%] [G loss: 1.039497]\n",
      "epoch:9 step:8888 [D loss: 0.616788, acc.: 67.19%] [G loss: 0.939939]\n",
      "epoch:9 step:8889 [D loss: 0.658463, acc.: 63.28%] [G loss: 0.976118]\n",
      "epoch:9 step:8890 [D loss: 0.591041, acc.: 68.75%] [G loss: 0.863100]\n",
      "epoch:9 step:8891 [D loss: 0.738187, acc.: 53.12%] [G loss: 0.989941]\n",
      "epoch:9 step:8892 [D loss: 0.752696, acc.: 44.53%] [G loss: 0.910760]\n",
      "epoch:9 step:8893 [D loss: 0.698316, acc.: 57.03%] [G loss: 0.978732]\n",
      "epoch:9 step:8894 [D loss: 0.670902, acc.: 61.72%] [G loss: 0.931345]\n",
      "epoch:9 step:8895 [D loss: 0.787358, acc.: 42.97%] [G loss: 0.938274]\n",
      "epoch:9 step:8896 [D loss: 0.687712, acc.: 58.59%] [G loss: 0.933385]\n",
      "epoch:9 step:8897 [D loss: 0.681356, acc.: 55.47%] [G loss: 0.955365]\n",
      "epoch:9 step:8898 [D loss: 0.605212, acc.: 67.97%] [G loss: 0.942933]\n",
      "epoch:9 step:8899 [D loss: 0.603218, acc.: 67.19%] [G loss: 0.907711]\n",
      "epoch:9 step:8900 [D loss: 0.697175, acc.: 56.25%] [G loss: 0.737281]\n",
      "epoch:9 step:8901 [D loss: 0.580915, acc.: 73.44%] [G loss: 1.078633]\n",
      "epoch:9 step:8902 [D loss: 0.604981, acc.: 67.97%] [G loss: 0.842636]\n",
      "epoch:9 step:8903 [D loss: 0.528272, acc.: 75.78%] [G loss: 1.078313]\n",
      "epoch:9 step:8904 [D loss: 0.538308, acc.: 76.56%] [G loss: 1.002726]\n",
      "epoch:9 step:8905 [D loss: 0.657499, acc.: 61.72%] [G loss: 0.954213]\n",
      "epoch:9 step:8906 [D loss: 0.762088, acc.: 50.00%] [G loss: 0.917696]\n",
      "epoch:9 step:8907 [D loss: 0.824628, acc.: 36.72%] [G loss: 0.898005]\n",
      "epoch:9 step:8908 [D loss: 0.707817, acc.: 47.66%] [G loss: 0.985509]\n",
      "epoch:9 step:8909 [D loss: 0.623936, acc.: 64.84%] [G loss: 0.950915]\n",
      "epoch:9 step:8910 [D loss: 0.596960, acc.: 68.75%] [G loss: 1.063908]\n",
      "epoch:9 step:8911 [D loss: 0.640884, acc.: 63.28%] [G loss: 0.965125]\n",
      "epoch:9 step:8912 [D loss: 0.627802, acc.: 65.62%] [G loss: 0.934034]\n",
      "epoch:9 step:8913 [D loss: 0.689743, acc.: 63.28%] [G loss: 0.791573]\n",
      "epoch:9 step:8914 [D loss: 0.625799, acc.: 63.28%] [G loss: 0.907226]\n",
      "epoch:9 step:8915 [D loss: 0.694683, acc.: 58.59%] [G loss: 0.896735]\n",
      "epoch:9 step:8916 [D loss: 0.679498, acc.: 57.81%] [G loss: 0.893629]\n",
      "epoch:9 step:8917 [D loss: 0.655875, acc.: 62.50%] [G loss: 0.992038]\n",
      "epoch:9 step:8918 [D loss: 0.738525, acc.: 49.22%] [G loss: 0.959885]\n",
      "epoch:9 step:8919 [D loss: 0.688899, acc.: 54.69%] [G loss: 0.826789]\n",
      "epoch:9 step:8920 [D loss: 0.656884, acc.: 61.72%] [G loss: 0.961591]\n",
      "epoch:9 step:8921 [D loss: 0.657255, acc.: 60.94%] [G loss: 0.859172]\n",
      "epoch:9 step:8922 [D loss: 0.673189, acc.: 60.16%] [G loss: 0.779062]\n",
      "epoch:9 step:8923 [D loss: 0.658536, acc.: 64.84%] [G loss: 1.099905]\n",
      "epoch:9 step:8924 [D loss: 0.601283, acc.: 70.31%] [G loss: 0.945718]\n",
      "epoch:9 step:8925 [D loss: 0.707404, acc.: 53.12%] [G loss: 0.935315]\n",
      "epoch:9 step:8926 [D loss: 0.823143, acc.: 47.66%] [G loss: 0.851223]\n",
      "epoch:9 step:8927 [D loss: 0.704240, acc.: 56.25%] [G loss: 0.989082]\n",
      "epoch:9 step:8928 [D loss: 0.661572, acc.: 62.50%] [G loss: 0.977571]\n",
      "epoch:9 step:8929 [D loss: 0.726550, acc.: 50.78%] [G loss: 0.924347]\n",
      "epoch:9 step:8930 [D loss: 0.709562, acc.: 57.81%] [G loss: 0.824276]\n",
      "epoch:9 step:8931 [D loss: 0.624987, acc.: 67.19%] [G loss: 0.977521]\n",
      "epoch:9 step:8932 [D loss: 0.673793, acc.: 57.03%] [G loss: 0.918498]\n",
      "epoch:9 step:8933 [D loss: 0.727994, acc.: 49.22%] [G loss: 0.955373]\n",
      "epoch:9 step:8934 [D loss: 0.722397, acc.: 49.22%] [G loss: 1.050878]\n",
      "epoch:9 step:8935 [D loss: 0.735124, acc.: 46.88%] [G loss: 0.926642]\n",
      "epoch:9 step:8936 [D loss: 0.637669, acc.: 60.94%] [G loss: 0.998894]\n",
      "epoch:9 step:8937 [D loss: 0.648974, acc.: 64.84%] [G loss: 0.875199]\n",
      "epoch:9 step:8938 [D loss: 0.610749, acc.: 69.53%] [G loss: 0.973275]\n",
      "epoch:9 step:8939 [D loss: 0.635384, acc.: 62.50%] [G loss: 0.998604]\n",
      "epoch:9 step:8940 [D loss: 0.785074, acc.: 43.75%] [G loss: 0.781630]\n",
      "epoch:9 step:8941 [D loss: 0.587177, acc.: 71.88%] [G loss: 1.056018]\n",
      "epoch:9 step:8942 [D loss: 0.764386, acc.: 50.00%] [G loss: 0.870347]\n",
      "epoch:9 step:8943 [D loss: 0.685048, acc.: 57.03%] [G loss: 0.963696]\n",
      "epoch:9 step:8944 [D loss: 0.632476, acc.: 65.62%] [G loss: 0.983357]\n",
      "epoch:9 step:8945 [D loss: 0.721586, acc.: 54.69%] [G loss: 0.921394]\n",
      "epoch:9 step:8946 [D loss: 0.620426, acc.: 58.59%] [G loss: 1.032970]\n",
      "epoch:9 step:8947 [D loss: 0.651663, acc.: 59.38%] [G loss: 0.914827]\n",
      "epoch:9 step:8948 [D loss: 0.699464, acc.: 57.81%] [G loss: 0.903438]\n",
      "epoch:9 step:8949 [D loss: 0.683036, acc.: 57.81%] [G loss: 1.017204]\n",
      "epoch:9 step:8950 [D loss: 0.667901, acc.: 59.38%] [G loss: 0.900027]\n",
      "epoch:9 step:8951 [D loss: 0.764923, acc.: 49.22%] [G loss: 0.904277]\n",
      "epoch:9 step:8952 [D loss: 0.609003, acc.: 64.84%] [G loss: 0.915649]\n",
      "epoch:9 step:8953 [D loss: 0.625417, acc.: 63.28%] [G loss: 0.847261]\n",
      "epoch:9 step:8954 [D loss: 0.627521, acc.: 66.41%] [G loss: 0.935343]\n",
      "epoch:9 step:8955 [D loss: 0.652477, acc.: 60.16%] [G loss: 1.015905]\n",
      "epoch:9 step:8956 [D loss: 0.601695, acc.: 72.66%] [G loss: 1.082934]\n",
      "epoch:9 step:8957 [D loss: 0.636821, acc.: 58.59%] [G loss: 0.972827]\n",
      "epoch:9 step:8958 [D loss: 0.761796, acc.: 45.31%] [G loss: 0.867926]\n",
      "epoch:9 step:8959 [D loss: 0.668046, acc.: 57.81%] [G loss: 0.963760]\n",
      "epoch:9 step:8960 [D loss: 0.725126, acc.: 51.56%] [G loss: 0.876080]\n",
      "epoch:9 step:8961 [D loss: 0.694944, acc.: 53.91%] [G loss: 0.964542]\n",
      "epoch:9 step:8962 [D loss: 0.663713, acc.: 57.81%] [G loss: 0.869105]\n",
      "epoch:9 step:8963 [D loss: 0.636881, acc.: 61.72%] [G loss: 0.890876]\n",
      "epoch:9 step:8964 [D loss: 0.670946, acc.: 59.38%] [G loss: 0.794676]\n",
      "epoch:9 step:8965 [D loss: 0.648280, acc.: 61.72%] [G loss: 0.943106]\n",
      "epoch:9 step:8966 [D loss: 0.633729, acc.: 66.41%] [G loss: 0.948748]\n",
      "epoch:9 step:8967 [D loss: 0.636143, acc.: 62.50%] [G loss: 0.936032]\n",
      "epoch:9 step:8968 [D loss: 0.679331, acc.: 57.81%] [G loss: 0.926893]\n",
      "epoch:9 step:8969 [D loss: 0.599785, acc.: 67.97%] [G loss: 1.014355]\n",
      "epoch:9 step:8970 [D loss: 0.666841, acc.: 57.81%] [G loss: 0.950956]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8971 [D loss: 0.702418, acc.: 53.91%] [G loss: 1.033313]\n",
      "epoch:9 step:8972 [D loss: 0.622035, acc.: 64.84%] [G loss: 0.936561]\n",
      "epoch:9 step:8973 [D loss: 0.675345, acc.: 59.38%] [G loss: 0.900924]\n",
      "epoch:9 step:8974 [D loss: 0.671552, acc.: 57.81%] [G loss: 0.916967]\n",
      "epoch:9 step:8975 [D loss: 0.702818, acc.: 52.34%] [G loss: 0.884950]\n",
      "epoch:9 step:8976 [D loss: 0.653928, acc.: 59.38%] [G loss: 0.895113]\n",
      "epoch:9 step:8977 [D loss: 0.737339, acc.: 42.19%] [G loss: 0.856919]\n",
      "epoch:9 step:8978 [D loss: 0.664858, acc.: 59.38%] [G loss: 0.896948]\n",
      "epoch:9 step:8979 [D loss: 0.649637, acc.: 63.28%] [G loss: 0.937080]\n",
      "epoch:9 step:8980 [D loss: 0.650190, acc.: 64.06%] [G loss: 0.960519]\n",
      "epoch:9 step:8981 [D loss: 0.669818, acc.: 57.81%] [G loss: 0.877328]\n",
      "epoch:9 step:8982 [D loss: 0.651287, acc.: 63.28%] [G loss: 0.943211]\n",
      "epoch:9 step:8983 [D loss: 0.647783, acc.: 61.72%] [G loss: 0.928146]\n",
      "epoch:9 step:8984 [D loss: 0.530331, acc.: 77.34%] [G loss: 0.940832]\n",
      "epoch:9 step:8985 [D loss: 0.637991, acc.: 60.94%] [G loss: 0.941728]\n",
      "epoch:9 step:8986 [D loss: 0.592173, acc.: 71.09%] [G loss: 1.079793]\n",
      "epoch:9 step:8987 [D loss: 0.590638, acc.: 67.97%] [G loss: 0.953217]\n",
      "epoch:9 step:8988 [D loss: 0.547777, acc.: 71.09%] [G loss: 0.966057]\n",
      "epoch:9 step:8989 [D loss: 0.602749, acc.: 67.19%] [G loss: 0.923767]\n",
      "epoch:9 step:8990 [D loss: 0.561620, acc.: 73.44%] [G loss: 1.085185]\n",
      "epoch:9 step:8991 [D loss: 0.515866, acc.: 78.91%] [G loss: 1.173623]\n",
      "epoch:9 step:8992 [D loss: 0.729065, acc.: 48.44%] [G loss: 0.974658]\n",
      "epoch:9 step:8993 [D loss: 0.688896, acc.: 55.47%] [G loss: 0.969010]\n",
      "epoch:9 step:8994 [D loss: 0.685356, acc.: 57.03%] [G loss: 0.908779]\n",
      "epoch:9 step:8995 [D loss: 0.628530, acc.: 65.62%] [G loss: 0.872110]\n",
      "epoch:9 step:8996 [D loss: 0.657484, acc.: 60.94%] [G loss: 0.961860]\n",
      "epoch:9 step:8997 [D loss: 0.644616, acc.: 61.72%] [G loss: 1.005265]\n",
      "epoch:9 step:8998 [D loss: 0.705522, acc.: 51.56%] [G loss: 1.030942]\n",
      "epoch:9 step:8999 [D loss: 0.777715, acc.: 40.62%] [G loss: 0.935898]\n",
      "epoch:9 step:9000 [D loss: 0.792285, acc.: 46.09%] [G loss: 0.977500]\n",
      "##############\n",
      "[2.03113655 1.60042998 5.06514421 4.14733917 2.87918611 5.26267435\n",
      " 4.04964314 4.52724263 3.33426183 3.46635433]\n",
      "##########\n",
      "epoch:9 step:9001 [D loss: 0.701358, acc.: 53.12%] [G loss: 1.003168]\n",
      "epoch:9 step:9002 [D loss: 0.736665, acc.: 49.22%] [G loss: 0.898195]\n",
      "epoch:9 step:9003 [D loss: 0.658181, acc.: 59.38%] [G loss: 0.942770]\n",
      "epoch:9 step:9004 [D loss: 0.594129, acc.: 68.75%] [G loss: 0.950374]\n",
      "epoch:9 step:9005 [D loss: 0.678276, acc.: 57.81%] [G loss: 0.958637]\n",
      "epoch:9 step:9006 [D loss: 0.713872, acc.: 51.56%] [G loss: 0.936887]\n",
      "epoch:9 step:9007 [D loss: 0.602715, acc.: 69.53%] [G loss: 0.858725]\n",
      "epoch:9 step:9008 [D loss: 0.572872, acc.: 73.44%] [G loss: 1.001522]\n",
      "epoch:9 step:9009 [D loss: 0.734551, acc.: 51.56%] [G loss: 0.934989]\n",
      "epoch:9 step:9010 [D loss: 0.621679, acc.: 64.84%] [G loss: 0.886477]\n",
      "epoch:9 step:9011 [D loss: 0.662783, acc.: 56.25%] [G loss: 0.783282]\n",
      "epoch:9 step:9012 [D loss: 0.662483, acc.: 58.59%] [G loss: 0.999605]\n",
      "epoch:9 step:9013 [D loss: 0.647272, acc.: 63.28%] [G loss: 0.859670]\n",
      "epoch:9 step:9014 [D loss: 0.639826, acc.: 59.38%] [G loss: 0.942405]\n",
      "epoch:9 step:9015 [D loss: 0.699521, acc.: 58.59%] [G loss: 0.908176]\n",
      "epoch:9 step:9016 [D loss: 0.677117, acc.: 54.69%] [G loss: 0.901863]\n",
      "epoch:9 step:9017 [D loss: 0.592024, acc.: 69.53%] [G loss: 1.026354]\n",
      "epoch:9 step:9018 [D loss: 0.619270, acc.: 68.75%] [G loss: 1.021931]\n",
      "epoch:9 step:9019 [D loss: 0.636575, acc.: 63.28%] [G loss: 0.995344]\n",
      "epoch:9 step:9020 [D loss: 0.588255, acc.: 72.66%] [G loss: 0.978215]\n",
      "epoch:9 step:9021 [D loss: 0.631620, acc.: 63.28%] [G loss: 0.866239]\n",
      "epoch:9 step:9022 [D loss: 0.643179, acc.: 66.41%] [G loss: 0.984506]\n",
      "epoch:9 step:9023 [D loss: 0.692691, acc.: 55.47%] [G loss: 0.905721]\n",
      "epoch:9 step:9024 [D loss: 0.715129, acc.: 52.34%] [G loss: 0.939205]\n",
      "epoch:9 step:9025 [D loss: 0.673931, acc.: 60.16%] [G loss: 0.899728]\n",
      "epoch:9 step:9026 [D loss: 0.630510, acc.: 63.28%] [G loss: 0.849203]\n",
      "epoch:9 step:9027 [D loss: 0.652242, acc.: 63.28%] [G loss: 1.001269]\n",
      "epoch:9 step:9028 [D loss: 0.752494, acc.: 46.88%] [G loss: 0.979748]\n",
      "epoch:9 step:9029 [D loss: 0.664951, acc.: 60.16%] [G loss: 0.986982]\n",
      "epoch:9 step:9030 [D loss: 0.763201, acc.: 44.53%] [G loss: 0.797329]\n",
      "epoch:9 step:9031 [D loss: 0.639420, acc.: 65.62%] [G loss: 1.034482]\n",
      "epoch:9 step:9032 [D loss: 0.711467, acc.: 52.34%] [G loss: 0.905000]\n",
      "epoch:9 step:9033 [D loss: 0.670375, acc.: 56.25%] [G loss: 0.975588]\n",
      "epoch:9 step:9034 [D loss: 0.666930, acc.: 57.81%] [G loss: 0.835054]\n",
      "epoch:9 step:9035 [D loss: 0.648418, acc.: 57.81%] [G loss: 0.882204]\n",
      "epoch:9 step:9036 [D loss: 0.584662, acc.: 67.97%] [G loss: 0.946757]\n",
      "epoch:9 step:9037 [D loss: 0.642520, acc.: 62.50%] [G loss: 0.932895]\n",
      "epoch:9 step:9038 [D loss: 0.651802, acc.: 66.41%] [G loss: 0.995550]\n",
      "epoch:9 step:9039 [D loss: 0.622752, acc.: 69.53%] [G loss: 0.953303]\n",
      "epoch:9 step:9040 [D loss: 0.635700, acc.: 64.06%] [G loss: 0.810948]\n",
      "epoch:9 step:9041 [D loss: 0.627458, acc.: 66.41%] [G loss: 1.069633]\n",
      "epoch:9 step:9042 [D loss: 0.641848, acc.: 59.38%] [G loss: 0.870463]\n",
      "epoch:9 step:9043 [D loss: 0.639155, acc.: 60.94%] [G loss: 0.987785]\n",
      "epoch:9 step:9044 [D loss: 0.625239, acc.: 65.62%] [G loss: 0.900890]\n",
      "epoch:9 step:9045 [D loss: 0.587630, acc.: 68.75%] [G loss: 1.071481]\n",
      "epoch:9 step:9046 [D loss: 0.631969, acc.: 66.41%] [G loss: 0.846686]\n",
      "epoch:9 step:9047 [D loss: 0.578529, acc.: 69.53%] [G loss: 0.956207]\n",
      "epoch:9 step:9048 [D loss: 0.595738, acc.: 71.09%] [G loss: 1.006251]\n",
      "epoch:9 step:9049 [D loss: 0.682239, acc.: 53.91%] [G loss: 0.904144]\n",
      "epoch:9 step:9050 [D loss: 0.722697, acc.: 53.12%] [G loss: 0.914345]\n",
      "epoch:9 step:9051 [D loss: 0.633073, acc.: 64.06%] [G loss: 0.888284]\n",
      "epoch:9 step:9052 [D loss: 0.684118, acc.: 57.03%] [G loss: 0.838684]\n",
      "epoch:9 step:9053 [D loss: 0.654602, acc.: 60.94%] [G loss: 0.939445]\n",
      "epoch:9 step:9054 [D loss: 0.657023, acc.: 59.38%] [G loss: 0.887153]\n",
      "epoch:9 step:9055 [D loss: 0.747388, acc.: 53.91%] [G loss: 0.882259]\n",
      "epoch:9 step:9056 [D loss: 0.653685, acc.: 60.16%] [G loss: 0.963946]\n",
      "epoch:9 step:9057 [D loss: 0.631983, acc.: 63.28%] [G loss: 1.027955]\n",
      "epoch:9 step:9058 [D loss: 0.741907, acc.: 48.44%] [G loss: 0.885987]\n",
      "epoch:9 step:9059 [D loss: 0.756819, acc.: 46.88%] [G loss: 0.918280]\n",
      "epoch:9 step:9060 [D loss: 0.682175, acc.: 51.56%] [G loss: 1.007432]\n",
      "epoch:9 step:9061 [D loss: 0.740477, acc.: 42.97%] [G loss: 0.891067]\n",
      "epoch:9 step:9062 [D loss: 0.631110, acc.: 65.62%] [G loss: 0.957954]\n",
      "epoch:9 step:9063 [D loss: 0.659727, acc.: 63.28%] [G loss: 0.898411]\n",
      "epoch:9 step:9064 [D loss: 0.672456, acc.: 58.59%] [G loss: 0.963964]\n",
      "epoch:9 step:9065 [D loss: 0.683154, acc.: 57.81%] [G loss: 0.986320]\n",
      "epoch:9 step:9066 [D loss: 0.589496, acc.: 70.31%] [G loss: 0.880922]\n",
      "epoch:9 step:9067 [D loss: 0.650670, acc.: 64.06%] [G loss: 0.948803]\n",
      "epoch:9 step:9068 [D loss: 0.589778, acc.: 74.22%] [G loss: 1.029643]\n",
      "epoch:9 step:9069 [D loss: 0.645884, acc.: 59.38%] [G loss: 1.161960]\n",
      "epoch:9 step:9070 [D loss: 0.611303, acc.: 70.31%] [G loss: 1.050019]\n",
      "epoch:9 step:9071 [D loss: 0.641374, acc.: 62.50%] [G loss: 1.002966]\n",
      "epoch:9 step:9072 [D loss: 0.611072, acc.: 67.19%] [G loss: 0.817175]\n",
      "epoch:9 step:9073 [D loss: 0.672737, acc.: 60.94%] [G loss: 0.889855]\n",
      "epoch:9 step:9074 [D loss: 0.645864, acc.: 64.06%] [G loss: 0.810356]\n",
      "epoch:9 step:9075 [D loss: 0.609973, acc.: 72.66%] [G loss: 1.064707]\n",
      "epoch:9 step:9076 [D loss: 0.715678, acc.: 55.47%] [G loss: 0.954744]\n",
      "epoch:9 step:9077 [D loss: 0.652014, acc.: 60.16%] [G loss: 1.164677]\n",
      "epoch:9 step:9078 [D loss: 0.695539, acc.: 52.34%] [G loss: 0.890008]\n",
      "epoch:9 step:9079 [D loss: 0.594477, acc.: 70.31%] [G loss: 1.128119]\n",
      "epoch:9 step:9080 [D loss: 0.649338, acc.: 61.72%] [G loss: 1.113709]\n",
      "epoch:9 step:9081 [D loss: 0.591013, acc.: 71.09%] [G loss: 0.968810]\n",
      "epoch:9 step:9082 [D loss: 0.653843, acc.: 60.16%] [G loss: 0.980538]\n",
      "epoch:9 step:9083 [D loss: 0.692794, acc.: 60.16%] [G loss: 0.901367]\n",
      "epoch:9 step:9084 [D loss: 0.548914, acc.: 76.56%] [G loss: 0.980139]\n",
      "epoch:9 step:9085 [D loss: 0.754544, acc.: 45.31%] [G loss: 0.896340]\n",
      "epoch:9 step:9086 [D loss: 0.644501, acc.: 63.28%] [G loss: 0.875114]\n",
      "epoch:9 step:9087 [D loss: 0.671254, acc.: 59.38%] [G loss: 0.921582]\n",
      "epoch:9 step:9088 [D loss: 0.728500, acc.: 54.69%] [G loss: 1.026896]\n",
      "epoch:9 step:9089 [D loss: 0.629796, acc.: 64.84%] [G loss: 0.906415]\n",
      "epoch:9 step:9090 [D loss: 0.648777, acc.: 61.72%] [G loss: 0.948447]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9091 [D loss: 0.745924, acc.: 50.00%] [G loss: 0.874694]\n",
      "epoch:9 step:9092 [D loss: 0.618815, acc.: 65.62%] [G loss: 0.916746]\n",
      "epoch:9 step:9093 [D loss: 0.697900, acc.: 55.47%] [G loss: 0.831326]\n",
      "epoch:9 step:9094 [D loss: 0.617008, acc.: 57.81%] [G loss: 0.976911]\n",
      "epoch:9 step:9095 [D loss: 0.676988, acc.: 57.81%] [G loss: 0.844263]\n",
      "epoch:9 step:9096 [D loss: 0.748389, acc.: 45.31%] [G loss: 0.843606]\n",
      "epoch:9 step:9097 [D loss: 0.679307, acc.: 57.03%] [G loss: 0.867424]\n",
      "epoch:9 step:9098 [D loss: 0.674440, acc.: 53.91%] [G loss: 0.929953]\n",
      "epoch:9 step:9099 [D loss: 0.692980, acc.: 55.47%] [G loss: 0.866415]\n",
      "epoch:9 step:9100 [D loss: 0.698362, acc.: 51.56%] [G loss: 1.028141]\n",
      "epoch:9 step:9101 [D loss: 0.658914, acc.: 59.38%] [G loss: 0.918106]\n",
      "epoch:9 step:9102 [D loss: 0.737199, acc.: 53.12%] [G loss: 1.043918]\n",
      "epoch:9 step:9103 [D loss: 0.743033, acc.: 48.44%] [G loss: 0.996216]\n",
      "epoch:9 step:9104 [D loss: 0.591604, acc.: 71.09%] [G loss: 0.936913]\n",
      "epoch:9 step:9105 [D loss: 0.676717, acc.: 57.03%] [G loss: 0.804730]\n",
      "epoch:9 step:9106 [D loss: 0.715817, acc.: 54.69%] [G loss: 1.054242]\n",
      "epoch:9 step:9107 [D loss: 0.725835, acc.: 51.56%] [G loss: 0.827394]\n",
      "epoch:9 step:9108 [D loss: 0.605999, acc.: 64.06%] [G loss: 0.905845]\n",
      "epoch:9 step:9109 [D loss: 0.667473, acc.: 50.00%] [G loss: 0.793185]\n",
      "epoch:9 step:9110 [D loss: 0.622489, acc.: 67.19%] [G loss: 0.957287]\n",
      "epoch:9 step:9111 [D loss: 0.658563, acc.: 63.28%] [G loss: 1.048544]\n",
      "epoch:9 step:9112 [D loss: 0.640762, acc.: 63.28%] [G loss: 0.822303]\n",
      "epoch:9 step:9113 [D loss: 0.615168, acc.: 67.97%] [G loss: 0.816495]\n",
      "epoch:9 step:9114 [D loss: 0.616523, acc.: 69.53%] [G loss: 0.999432]\n",
      "epoch:9 step:9115 [D loss: 0.670997, acc.: 54.69%] [G loss: 0.909790]\n",
      "epoch:9 step:9116 [D loss: 0.637891, acc.: 64.06%] [G loss: 0.977988]\n",
      "epoch:9 step:9117 [D loss: 0.653930, acc.: 62.50%] [G loss: 0.821875]\n",
      "epoch:9 step:9118 [D loss: 0.605912, acc.: 68.75%] [G loss: 0.861763]\n",
      "epoch:9 step:9119 [D loss: 0.638123, acc.: 63.28%] [G loss: 0.996558]\n",
      "epoch:9 step:9120 [D loss: 0.675016, acc.: 58.59%] [G loss: 0.881819]\n",
      "epoch:9 step:9121 [D loss: 0.618139, acc.: 62.50%] [G loss: 1.044451]\n",
      "epoch:9 step:9122 [D loss: 0.580983, acc.: 72.66%] [G loss: 0.995743]\n",
      "epoch:9 step:9123 [D loss: 0.549295, acc.: 75.00%] [G loss: 1.086413]\n",
      "epoch:9 step:9124 [D loss: 0.612133, acc.: 68.75%] [G loss: 0.950848]\n",
      "epoch:9 step:9125 [D loss: 0.649038, acc.: 67.19%] [G loss: 1.084632]\n",
      "epoch:9 step:9126 [D loss: 0.580149, acc.: 73.44%] [G loss: 1.036799]\n",
      "epoch:9 step:9127 [D loss: 0.622527, acc.: 65.62%] [G loss: 1.096449]\n",
      "epoch:9 step:9128 [D loss: 0.644868, acc.: 61.72%] [G loss: 0.942148]\n",
      "epoch:9 step:9129 [D loss: 0.660615, acc.: 54.69%] [G loss: 1.115784]\n",
      "epoch:9 step:9130 [D loss: 0.696034, acc.: 53.91%] [G loss: 0.906068]\n",
      "epoch:9 step:9131 [D loss: 0.652625, acc.: 63.28%] [G loss: 1.019629]\n",
      "epoch:9 step:9132 [D loss: 0.649542, acc.: 67.97%] [G loss: 0.990421]\n",
      "epoch:9 step:9133 [D loss: 0.671666, acc.: 53.91%] [G loss: 0.827720]\n",
      "epoch:9 step:9134 [D loss: 0.620437, acc.: 63.28%] [G loss: 0.929572]\n",
      "epoch:9 step:9135 [D loss: 0.659940, acc.: 65.62%] [G loss: 0.916330]\n",
      "epoch:9 step:9136 [D loss: 0.722618, acc.: 52.34%] [G loss: 0.931761]\n",
      "epoch:9 step:9137 [D loss: 0.711361, acc.: 57.03%] [G loss: 0.861231]\n",
      "epoch:9 step:9138 [D loss: 0.655325, acc.: 64.06%] [G loss: 0.858170]\n",
      "epoch:9 step:9139 [D loss: 0.591298, acc.: 68.75%] [G loss: 1.014578]\n",
      "epoch:9 step:9140 [D loss: 0.594620, acc.: 67.97%] [G loss: 0.955968]\n",
      "epoch:9 step:9141 [D loss: 0.658353, acc.: 62.50%] [G loss: 0.866018]\n",
      "epoch:9 step:9142 [D loss: 0.555225, acc.: 72.66%] [G loss: 1.189618]\n",
      "epoch:9 step:9143 [D loss: 0.678720, acc.: 64.06%] [G loss: 0.984347]\n",
      "epoch:9 step:9144 [D loss: 0.658530, acc.: 60.94%] [G loss: 1.014584]\n",
      "epoch:9 step:9145 [D loss: 0.625644, acc.: 63.28%] [G loss: 0.874657]\n",
      "epoch:9 step:9146 [D loss: 0.619109, acc.: 67.19%] [G loss: 0.962428]\n",
      "epoch:9 step:9147 [D loss: 0.614686, acc.: 67.19%] [G loss: 0.947924]\n",
      "epoch:9 step:9148 [D loss: 0.586922, acc.: 67.19%] [G loss: 0.990338]\n",
      "epoch:9 step:9149 [D loss: 0.750772, acc.: 46.88%] [G loss: 1.026696]\n",
      "epoch:9 step:9150 [D loss: 0.695590, acc.: 54.69%] [G loss: 0.956761]\n",
      "epoch:9 step:9151 [D loss: 0.714382, acc.: 53.12%] [G loss: 0.932912]\n",
      "epoch:9 step:9152 [D loss: 0.701512, acc.: 52.34%] [G loss: 0.949039]\n",
      "epoch:9 step:9153 [D loss: 0.674143, acc.: 53.91%] [G loss: 0.941002]\n",
      "epoch:9 step:9154 [D loss: 0.644344, acc.: 62.50%] [G loss: 0.905062]\n",
      "epoch:9 step:9155 [D loss: 0.670475, acc.: 57.81%] [G loss: 0.919503]\n",
      "epoch:9 step:9156 [D loss: 0.664590, acc.: 59.38%] [G loss: 0.905916]\n",
      "epoch:9 step:9157 [D loss: 0.619174, acc.: 67.97%] [G loss: 0.885198]\n",
      "epoch:9 step:9158 [D loss: 0.575278, acc.: 77.34%] [G loss: 1.004200]\n",
      "epoch:9 step:9159 [D loss: 0.632732, acc.: 67.97%] [G loss: 0.912311]\n",
      "epoch:9 step:9160 [D loss: 0.572632, acc.: 71.88%] [G loss: 0.954169]\n",
      "epoch:9 step:9161 [D loss: 0.602098, acc.: 68.75%] [G loss: 0.845853]\n",
      "epoch:9 step:9162 [D loss: 0.674892, acc.: 59.38%] [G loss: 0.943744]\n",
      "epoch:9 step:9163 [D loss: 0.581687, acc.: 71.88%] [G loss: 1.042669]\n",
      "epoch:9 step:9164 [D loss: 0.587124, acc.: 70.31%] [G loss: 0.926183]\n",
      "epoch:9 step:9165 [D loss: 0.608374, acc.: 68.75%] [G loss: 0.957587]\n",
      "epoch:9 step:9166 [D loss: 0.557175, acc.: 74.22%] [G loss: 0.981158]\n",
      "epoch:9 step:9167 [D loss: 0.671397, acc.: 60.16%] [G loss: 1.044495]\n",
      "epoch:9 step:9168 [D loss: 0.560794, acc.: 74.22%] [G loss: 1.077746]\n",
      "epoch:9 step:9169 [D loss: 0.583921, acc.: 68.75%] [G loss: 0.981020]\n",
      "epoch:9 step:9170 [D loss: 0.655606, acc.: 62.50%] [G loss: 1.013094]\n",
      "epoch:9 step:9171 [D loss: 0.652313, acc.: 60.16%] [G loss: 1.009972]\n",
      "epoch:9 step:9172 [D loss: 0.703443, acc.: 49.22%] [G loss: 0.871048]\n",
      "epoch:9 step:9173 [D loss: 0.661991, acc.: 60.16%] [G loss: 0.901088]\n",
      "epoch:9 step:9174 [D loss: 0.788889, acc.: 46.09%] [G loss: 0.830454]\n",
      "epoch:9 step:9175 [D loss: 0.679569, acc.: 56.25%] [G loss: 0.809689]\n",
      "epoch:9 step:9176 [D loss: 0.737293, acc.: 47.66%] [G loss: 0.889163]\n",
      "epoch:9 step:9177 [D loss: 0.729891, acc.: 56.25%] [G loss: 0.851154]\n",
      "epoch:9 step:9178 [D loss: 0.596660, acc.: 70.31%] [G loss: 1.015710]\n",
      "epoch:9 step:9179 [D loss: 0.664458, acc.: 59.38%] [G loss: 0.873164]\n",
      "epoch:9 step:9180 [D loss: 0.702233, acc.: 55.47%] [G loss: 0.868126]\n",
      "epoch:9 step:9181 [D loss: 0.641002, acc.: 60.94%] [G loss: 0.961474]\n",
      "epoch:9 step:9182 [D loss: 0.713748, acc.: 54.69%] [G loss: 0.979573]\n",
      "epoch:9 step:9183 [D loss: 0.588057, acc.: 75.78%] [G loss: 0.934357]\n",
      "epoch:9 step:9184 [D loss: 0.628732, acc.: 64.06%] [G loss: 0.854886]\n",
      "epoch:9 step:9185 [D loss: 0.729573, acc.: 50.78%] [G loss: 0.889867]\n",
      "epoch:9 step:9186 [D loss: 0.625238, acc.: 60.16%] [G loss: 0.896503]\n",
      "epoch:9 step:9187 [D loss: 0.674923, acc.: 60.94%] [G loss: 0.879782]\n",
      "epoch:9 step:9188 [D loss: 0.644933, acc.: 67.19%] [G loss: 0.850517]\n",
      "epoch:9 step:9189 [D loss: 0.660763, acc.: 60.16%] [G loss: 0.919769]\n",
      "epoch:9 step:9190 [D loss: 0.626796, acc.: 64.84%] [G loss: 0.917391]\n",
      "epoch:9 step:9191 [D loss: 0.747051, acc.: 50.78%] [G loss: 0.927756]\n",
      "epoch:9 step:9192 [D loss: 0.683731, acc.: 57.81%] [G loss: 0.922326]\n",
      "epoch:9 step:9193 [D loss: 0.632011, acc.: 66.41%] [G loss: 0.937871]\n",
      "epoch:9 step:9194 [D loss: 0.707275, acc.: 54.69%] [G loss: 0.793552]\n",
      "epoch:9 step:9195 [D loss: 0.710748, acc.: 50.78%] [G loss: 0.980915]\n",
      "epoch:9 step:9196 [D loss: 0.644489, acc.: 58.59%] [G loss: 0.898093]\n",
      "epoch:9 step:9197 [D loss: 0.663365, acc.: 59.38%] [G loss: 0.961338]\n",
      "epoch:9 step:9198 [D loss: 0.669334, acc.: 57.81%] [G loss: 0.969378]\n",
      "epoch:9 step:9199 [D loss: 0.645065, acc.: 67.19%] [G loss: 0.958690]\n",
      "epoch:9 step:9200 [D loss: 0.613317, acc.: 64.84%] [G loss: 1.054353]\n",
      "##############\n",
      "[2.21444336 1.30955825 5.24533438 4.28019372 2.94236762 5.44643621\n",
      " 3.96719127 4.6486248  3.62826053 3.57664836]\n",
      "##########\n",
      "epoch:9 step:9201 [D loss: 0.599956, acc.: 72.66%] [G loss: 0.853858]\n",
      "epoch:9 step:9202 [D loss: 0.650589, acc.: 60.16%] [G loss: 0.811133]\n",
      "epoch:9 step:9203 [D loss: 0.722071, acc.: 49.22%] [G loss: 0.850505]\n",
      "epoch:9 step:9204 [D loss: 0.701115, acc.: 53.91%] [G loss: 0.829851]\n",
      "epoch:9 step:9205 [D loss: 0.664920, acc.: 60.94%] [G loss: 0.861010]\n",
      "epoch:9 step:9206 [D loss: 0.681359, acc.: 53.91%] [G loss: 0.850529]\n",
      "epoch:9 step:9207 [D loss: 0.649304, acc.: 58.59%] [G loss: 0.869338]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9208 [D loss: 0.626869, acc.: 62.50%] [G loss: 0.980355]\n",
      "epoch:9 step:9209 [D loss: 0.609346, acc.: 60.94%] [G loss: 0.903342]\n",
      "epoch:9 step:9210 [D loss: 0.698560, acc.: 56.25%] [G loss: 1.020620]\n",
      "epoch:9 step:9211 [D loss: 0.688185, acc.: 60.94%] [G loss: 0.826957]\n",
      "epoch:9 step:9212 [D loss: 0.702946, acc.: 53.91%] [G loss: 0.984896]\n",
      "epoch:9 step:9213 [D loss: 0.634814, acc.: 64.06%] [G loss: 1.025955]\n",
      "epoch:9 step:9214 [D loss: 0.723870, acc.: 48.44%] [G loss: 0.933594]\n",
      "epoch:9 step:9215 [D loss: 0.624648, acc.: 63.28%] [G loss: 0.999257]\n",
      "epoch:9 step:9216 [D loss: 0.685014, acc.: 56.25%] [G loss: 0.934072]\n",
      "epoch:9 step:9217 [D loss: 0.647597, acc.: 60.94%] [G loss: 1.060302]\n",
      "epoch:9 step:9218 [D loss: 0.659503, acc.: 61.72%] [G loss: 0.904903]\n",
      "epoch:9 step:9219 [D loss: 0.614405, acc.: 68.75%] [G loss: 0.909300]\n",
      "epoch:9 step:9220 [D loss: 0.662657, acc.: 57.81%] [G loss: 0.776760]\n",
      "epoch:9 step:9221 [D loss: 0.775763, acc.: 43.75%] [G loss: 0.842282]\n",
      "epoch:9 step:9222 [D loss: 0.703824, acc.: 58.59%] [G loss: 0.860621]\n",
      "epoch:9 step:9223 [D loss: 0.603029, acc.: 70.31%] [G loss: 0.913462]\n",
      "epoch:9 step:9224 [D loss: 0.635202, acc.: 60.16%] [G loss: 0.964815]\n",
      "epoch:9 step:9225 [D loss: 0.623703, acc.: 65.62%] [G loss: 0.872083]\n",
      "epoch:9 step:9226 [D loss: 0.572641, acc.: 67.97%] [G loss: 1.100425]\n",
      "epoch:9 step:9227 [D loss: 0.738413, acc.: 51.56%] [G loss: 0.862892]\n",
      "epoch:9 step:9228 [D loss: 0.753743, acc.: 50.78%] [G loss: 0.820782]\n",
      "epoch:9 step:9229 [D loss: 0.694051, acc.: 57.81%] [G loss: 0.886296]\n",
      "epoch:9 step:9230 [D loss: 0.699073, acc.: 63.28%] [G loss: 0.967938]\n",
      "epoch:9 step:9231 [D loss: 0.662099, acc.: 60.94%] [G loss: 0.918260]\n",
      "epoch:9 step:9232 [D loss: 0.693594, acc.: 56.25%] [G loss: 0.940104]\n",
      "epoch:9 step:9233 [D loss: 0.734119, acc.: 49.22%] [G loss: 0.927633]\n",
      "epoch:9 step:9234 [D loss: 0.692227, acc.: 57.03%] [G loss: 0.863518]\n",
      "epoch:9 step:9235 [D loss: 0.700648, acc.: 57.81%] [G loss: 0.953146]\n",
      "epoch:9 step:9236 [D loss: 0.634689, acc.: 63.28%] [G loss: 1.079777]\n",
      "epoch:9 step:9237 [D loss: 0.647335, acc.: 62.50%] [G loss: 0.828006]\n",
      "epoch:9 step:9238 [D loss: 0.616349, acc.: 64.06%] [G loss: 1.087784]\n",
      "epoch:9 step:9239 [D loss: 0.539576, acc.: 78.91%] [G loss: 0.981331]\n",
      "epoch:9 step:9240 [D loss: 0.609709, acc.: 66.41%] [G loss: 1.083253]\n",
      "epoch:9 step:9241 [D loss: 0.655026, acc.: 65.62%] [G loss: 0.997259]\n",
      "epoch:9 step:9242 [D loss: 0.648049, acc.: 57.81%] [G loss: 0.894340]\n",
      "epoch:9 step:9243 [D loss: 0.650946, acc.: 60.94%] [G loss: 0.895219]\n",
      "epoch:9 step:9244 [D loss: 0.650401, acc.: 58.59%] [G loss: 1.060032]\n",
      "epoch:9 step:9245 [D loss: 0.641352, acc.: 63.28%] [G loss: 0.845636]\n",
      "epoch:9 step:9246 [D loss: 0.676581, acc.: 60.94%] [G loss: 0.812858]\n",
      "epoch:9 step:9247 [D loss: 0.693447, acc.: 54.69%] [G loss: 1.023422]\n",
      "epoch:9 step:9248 [D loss: 0.636450, acc.: 61.72%] [G loss: 0.878508]\n",
      "epoch:9 step:9249 [D loss: 0.672863, acc.: 57.81%] [G loss: 0.904459]\n",
      "epoch:9 step:9250 [D loss: 0.599681, acc.: 68.75%] [G loss: 0.903930]\n",
      "epoch:9 step:9251 [D loss: 0.709165, acc.: 54.69%] [G loss: 0.969863]\n",
      "epoch:9 step:9252 [D loss: 0.636666, acc.: 72.66%] [G loss: 0.799264]\n",
      "epoch:9 step:9253 [D loss: 0.696399, acc.: 57.81%] [G loss: 0.830344]\n",
      "epoch:9 step:9254 [D loss: 0.610969, acc.: 65.62%] [G loss: 1.172437]\n",
      "epoch:9 step:9255 [D loss: 0.587086, acc.: 66.41%] [G loss: 1.056523]\n",
      "epoch:9 step:9256 [D loss: 0.657549, acc.: 59.38%] [G loss: 0.929293]\n",
      "epoch:9 step:9257 [D loss: 0.703356, acc.: 54.69%] [G loss: 0.900176]\n",
      "epoch:9 step:9258 [D loss: 0.630238, acc.: 65.62%] [G loss: 0.825007]\n",
      "epoch:9 step:9259 [D loss: 0.784793, acc.: 46.09%] [G loss: 0.845455]\n",
      "epoch:9 step:9260 [D loss: 0.692711, acc.: 54.69%] [G loss: 0.863509]\n",
      "epoch:9 step:9261 [D loss: 0.702317, acc.: 54.69%] [G loss: 0.973179]\n",
      "epoch:9 step:9262 [D loss: 0.652114, acc.: 60.16%] [G loss: 0.930875]\n",
      "epoch:9 step:9263 [D loss: 0.658126, acc.: 60.94%] [G loss: 1.034596]\n",
      "epoch:9 step:9264 [D loss: 0.637069, acc.: 64.84%] [G loss: 0.968216]\n",
      "epoch:9 step:9265 [D loss: 0.633671, acc.: 64.84%] [G loss: 1.033507]\n",
      "epoch:9 step:9266 [D loss: 0.597652, acc.: 71.09%] [G loss: 0.958374]\n",
      "epoch:9 step:9267 [D loss: 0.666506, acc.: 58.59%] [G loss: 0.894792]\n",
      "epoch:9 step:9268 [D loss: 0.583947, acc.: 71.88%] [G loss: 1.025969]\n",
      "epoch:9 step:9269 [D loss: 0.629629, acc.: 64.06%] [G loss: 0.965032]\n",
      "epoch:9 step:9270 [D loss: 0.723893, acc.: 47.66%] [G loss: 0.873943]\n",
      "epoch:9 step:9271 [D loss: 0.670934, acc.: 60.16%] [G loss: 1.033991]\n",
      "epoch:9 step:9272 [D loss: 0.598491, acc.: 69.53%] [G loss: 1.031385]\n",
      "epoch:9 step:9273 [D loss: 0.650248, acc.: 60.94%] [G loss: 0.875161]\n",
      "epoch:9 step:9274 [D loss: 0.614756, acc.: 62.50%] [G loss: 0.784344]\n",
      "epoch:9 step:9275 [D loss: 0.609898, acc.: 63.28%] [G loss: 1.055318]\n",
      "epoch:9 step:9276 [D loss: 0.617806, acc.: 64.06%] [G loss: 1.185509]\n",
      "epoch:9 step:9277 [D loss: 0.826331, acc.: 40.62%] [G loss: 0.800179]\n",
      "epoch:9 step:9278 [D loss: 0.592956, acc.: 71.09%] [G loss: 0.998804]\n",
      "epoch:9 step:9279 [D loss: 0.690631, acc.: 60.94%] [G loss: 0.912067]\n",
      "epoch:9 step:9280 [D loss: 0.683117, acc.: 57.03%] [G loss: 0.933693]\n",
      "epoch:9 step:9281 [D loss: 0.687250, acc.: 60.16%] [G loss: 0.852796]\n",
      "epoch:9 step:9282 [D loss: 0.685478, acc.: 59.38%] [G loss: 0.942977]\n",
      "epoch:9 step:9283 [D loss: 0.683121, acc.: 57.03%] [G loss: 0.835616]\n",
      "epoch:9 step:9284 [D loss: 0.626644, acc.: 67.19%] [G loss: 0.980031]\n",
      "epoch:9 step:9285 [D loss: 0.616111, acc.: 64.06%] [G loss: 1.083856]\n",
      "epoch:9 step:9286 [D loss: 0.643541, acc.: 67.19%] [G loss: 0.974740]\n",
      "epoch:9 step:9287 [D loss: 0.576522, acc.: 73.44%] [G loss: 1.065859]\n",
      "epoch:9 step:9288 [D loss: 0.673035, acc.: 59.38%] [G loss: 0.888644]\n",
      "epoch:9 step:9289 [D loss: 0.692670, acc.: 55.47%] [G loss: 0.850016]\n",
      "epoch:9 step:9290 [D loss: 0.656833, acc.: 60.16%] [G loss: 0.840544]\n",
      "epoch:9 step:9291 [D loss: 0.694128, acc.: 55.47%] [G loss: 0.922181]\n",
      "epoch:9 step:9292 [D loss: 0.762506, acc.: 43.75%] [G loss: 0.770797]\n",
      "epoch:9 step:9293 [D loss: 0.596700, acc.: 67.97%] [G loss: 0.992801]\n",
      "epoch:9 step:9294 [D loss: 0.601274, acc.: 71.88%] [G loss: 0.889873]\n",
      "epoch:9 step:9295 [D loss: 0.635441, acc.: 62.50%] [G loss: 0.901884]\n",
      "epoch:9 step:9296 [D loss: 0.607786, acc.: 66.41%] [G loss: 0.905260]\n",
      "epoch:9 step:9297 [D loss: 0.723203, acc.: 57.81%] [G loss: 0.846281]\n",
      "epoch:9 step:9298 [D loss: 0.638714, acc.: 60.16%] [G loss: 0.917485]\n",
      "epoch:9 step:9299 [D loss: 0.688825, acc.: 59.38%] [G loss: 0.837795]\n",
      "epoch:9 step:9300 [D loss: 0.692613, acc.: 57.03%] [G loss: 0.915125]\n",
      "epoch:9 step:9301 [D loss: 0.684473, acc.: 55.47%] [G loss: 0.828483]\n",
      "epoch:9 step:9302 [D loss: 0.717254, acc.: 50.00%] [G loss: 0.855913]\n",
      "epoch:9 step:9303 [D loss: 0.645519, acc.: 60.94%] [G loss: 0.965616]\n",
      "epoch:9 step:9304 [D loss: 0.647349, acc.: 61.72%] [G loss: 0.958039]\n",
      "epoch:9 step:9305 [D loss: 0.613141, acc.: 67.97%] [G loss: 0.927255]\n",
      "epoch:9 step:9306 [D loss: 0.666797, acc.: 59.38%] [G loss: 0.902033]\n",
      "epoch:9 step:9307 [D loss: 0.709096, acc.: 52.34%] [G loss: 0.891210]\n",
      "epoch:9 step:9308 [D loss: 0.698411, acc.: 57.81%] [G loss: 0.786653]\n",
      "epoch:9 step:9309 [D loss: 0.629041, acc.: 66.41%] [G loss: 0.936134]\n",
      "epoch:9 step:9310 [D loss: 0.680483, acc.: 56.25%] [G loss: 0.940781]\n",
      "epoch:9 step:9311 [D loss: 0.620801, acc.: 63.28%] [G loss: 1.024495]\n",
      "epoch:9 step:9312 [D loss: 0.684334, acc.: 59.38%] [G loss: 0.900715]\n",
      "epoch:9 step:9313 [D loss: 0.682626, acc.: 57.03%] [G loss: 0.926666]\n",
      "epoch:9 step:9314 [D loss: 0.658679, acc.: 57.81%] [G loss: 0.935942]\n",
      "epoch:9 step:9315 [D loss: 0.664092, acc.: 58.59%] [G loss: 0.973114]\n",
      "epoch:9 step:9316 [D loss: 0.659487, acc.: 58.59%] [G loss: 0.942861]\n",
      "epoch:9 step:9317 [D loss: 0.667795, acc.: 60.94%] [G loss: 1.073056]\n",
      "epoch:9 step:9318 [D loss: 0.679064, acc.: 58.59%] [G loss: 0.824956]\n",
      "epoch:9 step:9319 [D loss: 0.644091, acc.: 63.28%] [G loss: 1.013726]\n",
      "epoch:9 step:9320 [D loss: 0.707323, acc.: 60.16%] [G loss: 0.976319]\n",
      "epoch:9 step:9321 [D loss: 0.627217, acc.: 63.28%] [G loss: 1.014071]\n",
      "epoch:9 step:9322 [D loss: 0.597632, acc.: 64.06%] [G loss: 1.013112]\n",
      "epoch:9 step:9323 [D loss: 0.596144, acc.: 68.75%] [G loss: 1.039746]\n",
      "epoch:9 step:9324 [D loss: 0.752918, acc.: 45.31%] [G loss: 0.962427]\n",
      "epoch:9 step:9325 [D loss: 0.756392, acc.: 48.44%] [G loss: 0.947220]\n",
      "epoch:9 step:9326 [D loss: 0.759239, acc.: 50.78%] [G loss: 0.889417]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9327 [D loss: 0.622255, acc.: 63.28%] [G loss: 0.856627]\n",
      "epoch:9 step:9328 [D loss: 0.717392, acc.: 50.78%] [G loss: 0.839078]\n",
      "epoch:9 step:9329 [D loss: 0.660984, acc.: 62.50%] [G loss: 0.944316]\n",
      "epoch:9 step:9330 [D loss: 0.670033, acc.: 58.59%] [G loss: 0.832211]\n",
      "epoch:9 step:9331 [D loss: 0.652577, acc.: 64.06%] [G loss: 0.975299]\n",
      "epoch:9 step:9332 [D loss: 0.588133, acc.: 69.53%] [G loss: 1.079386]\n",
      "epoch:9 step:9333 [D loss: 0.635474, acc.: 64.84%] [G loss: 0.996945]\n",
      "epoch:9 step:9334 [D loss: 0.641635, acc.: 66.41%] [G loss: 1.046127]\n",
      "epoch:9 step:9335 [D loss: 0.667123, acc.: 64.06%] [G loss: 0.946788]\n",
      "epoch:9 step:9336 [D loss: 0.638500, acc.: 63.28%] [G loss: 0.908183]\n",
      "epoch:9 step:9337 [D loss: 0.668706, acc.: 61.72%] [G loss: 0.890170]\n",
      "epoch:9 step:9338 [D loss: 0.606415, acc.: 61.72%] [G loss: 0.875065]\n",
      "epoch:9 step:9339 [D loss: 0.655659, acc.: 57.03%] [G loss: 0.961789]\n",
      "epoch:9 step:9340 [D loss: 0.730264, acc.: 50.78%] [G loss: 0.831049]\n",
      "epoch:9 step:9341 [D loss: 0.717338, acc.: 50.78%] [G loss: 0.839177]\n",
      "epoch:9 step:9342 [D loss: 0.621776, acc.: 65.62%] [G loss: 0.941150]\n",
      "epoch:9 step:9343 [D loss: 0.560693, acc.: 70.31%] [G loss: 0.995389]\n",
      "epoch:9 step:9344 [D loss: 0.600127, acc.: 68.75%] [G loss: 1.032355]\n",
      "epoch:9 step:9345 [D loss: 0.540219, acc.: 78.12%] [G loss: 1.039617]\n",
      "epoch:9 step:9346 [D loss: 0.740673, acc.: 50.00%] [G loss: 0.941023]\n",
      "epoch:9 step:9347 [D loss: 0.667421, acc.: 55.47%] [G loss: 0.939555]\n",
      "epoch:9 step:9348 [D loss: 0.699631, acc.: 54.69%] [G loss: 0.863940]\n",
      "epoch:9 step:9349 [D loss: 0.655769, acc.: 60.16%] [G loss: 1.019864]\n",
      "epoch:9 step:9350 [D loss: 0.701654, acc.: 53.91%] [G loss: 0.886477]\n",
      "epoch:9 step:9351 [D loss: 0.632144, acc.: 64.84%] [G loss: 0.808822]\n",
      "epoch:9 step:9352 [D loss: 0.624090, acc.: 69.53%] [G loss: 1.066703]\n",
      "epoch:9 step:9353 [D loss: 0.705639, acc.: 51.56%] [G loss: 0.931591]\n",
      "epoch:9 step:9354 [D loss: 0.652451, acc.: 64.84%] [G loss: 0.985362]\n",
      "epoch:9 step:9355 [D loss: 0.594593, acc.: 70.31%] [G loss: 0.917073]\n",
      "epoch:9 step:9356 [D loss: 0.567401, acc.: 68.75%] [G loss: 0.869316]\n",
      "epoch:9 step:9357 [D loss: 0.583418, acc.: 68.75%] [G loss: 1.073517]\n",
      "epoch:9 step:9358 [D loss: 0.619787, acc.: 66.41%] [G loss: 0.974796]\n",
      "epoch:9 step:9359 [D loss: 0.574295, acc.: 69.53%] [G loss: 0.957450]\n",
      "epoch:9 step:9360 [D loss: 0.568040, acc.: 71.88%] [G loss: 1.031256]\n",
      "epoch:9 step:9361 [D loss: 0.936182, acc.: 32.81%] [G loss: 0.819483]\n",
      "epoch:9 step:9362 [D loss: 0.830927, acc.: 42.97%] [G loss: 0.931732]\n",
      "epoch:9 step:9363 [D loss: 0.539523, acc.: 75.00%] [G loss: 1.001856]\n",
      "epoch:9 step:9364 [D loss: 0.574475, acc.: 72.66%] [G loss: 0.968120]\n",
      "epoch:9 step:9365 [D loss: 0.620230, acc.: 65.62%] [G loss: 0.871398]\n",
      "epoch:9 step:9366 [D loss: 0.614060, acc.: 63.28%] [G loss: 0.940068]\n",
      "epoch:9 step:9367 [D loss: 0.632258, acc.: 64.06%] [G loss: 1.016137]\n",
      "epoch:9 step:9368 [D loss: 0.614869, acc.: 65.62%] [G loss: 0.906508]\n",
      "epoch:9 step:9369 [D loss: 0.566247, acc.: 73.44%] [G loss: 1.098273]\n",
      "epoch:9 step:9370 [D loss: 0.435001, acc.: 85.16%] [G loss: 1.281673]\n",
      "epoch:10 step:9371 [D loss: 0.681838, acc.: 61.72%] [G loss: 1.064260]\n",
      "epoch:10 step:9372 [D loss: 0.669900, acc.: 57.81%] [G loss: 1.085095]\n",
      "epoch:10 step:9373 [D loss: 0.668623, acc.: 57.81%] [G loss: 0.927673]\n",
      "epoch:10 step:9374 [D loss: 0.689521, acc.: 57.81%] [G loss: 1.123279]\n",
      "epoch:10 step:9375 [D loss: 0.646614, acc.: 65.62%] [G loss: 1.052695]\n",
      "epoch:10 step:9376 [D loss: 0.657325, acc.: 63.28%] [G loss: 0.895154]\n",
      "epoch:10 step:9377 [D loss: 0.638768, acc.: 63.28%] [G loss: 0.972636]\n",
      "epoch:10 step:9378 [D loss: 0.648068, acc.: 60.16%] [G loss: 1.003669]\n",
      "epoch:10 step:9379 [D loss: 0.588905, acc.: 67.19%] [G loss: 0.969066]\n",
      "epoch:10 step:9380 [D loss: 0.555500, acc.: 77.34%] [G loss: 1.105155]\n",
      "epoch:10 step:9381 [D loss: 0.658843, acc.: 63.28%] [G loss: 0.858643]\n",
      "epoch:10 step:9382 [D loss: 0.640211, acc.: 60.16%] [G loss: 1.098047]\n",
      "epoch:10 step:9383 [D loss: 0.611264, acc.: 66.41%] [G loss: 1.022592]\n",
      "epoch:10 step:9384 [D loss: 0.582046, acc.: 69.53%] [G loss: 1.000777]\n",
      "epoch:10 step:9385 [D loss: 0.494931, acc.: 83.59%] [G loss: 1.118754]\n",
      "epoch:10 step:9386 [D loss: 0.590534, acc.: 71.88%] [G loss: 0.980433]\n",
      "epoch:10 step:9387 [D loss: 0.673314, acc.: 57.03%] [G loss: 0.943845]\n",
      "epoch:10 step:9388 [D loss: 0.710343, acc.: 53.12%] [G loss: 0.942869]\n",
      "epoch:10 step:9389 [D loss: 0.650134, acc.: 62.50%] [G loss: 0.896177]\n",
      "epoch:10 step:9390 [D loss: 0.811012, acc.: 41.41%] [G loss: 0.801528]\n",
      "epoch:10 step:9391 [D loss: 0.691310, acc.: 58.59%] [G loss: 0.910856]\n",
      "epoch:10 step:9392 [D loss: 0.730924, acc.: 50.78%] [G loss: 0.779851]\n",
      "epoch:10 step:9393 [D loss: 0.604826, acc.: 67.19%] [G loss: 0.886131]\n",
      "epoch:10 step:9394 [D loss: 0.616755, acc.: 66.41%] [G loss: 0.941522]\n",
      "epoch:10 step:9395 [D loss: 0.618589, acc.: 65.62%] [G loss: 0.952327]\n",
      "epoch:10 step:9396 [D loss: 0.690320, acc.: 52.34%] [G loss: 1.053570]\n",
      "epoch:10 step:9397 [D loss: 0.664926, acc.: 60.94%] [G loss: 0.946845]\n",
      "epoch:10 step:9398 [D loss: 0.701675, acc.: 58.59%] [G loss: 0.898521]\n",
      "epoch:10 step:9399 [D loss: 0.608282, acc.: 67.97%] [G loss: 1.010768]\n",
      "epoch:10 step:9400 [D loss: 0.677259, acc.: 59.38%] [G loss: 0.975609]\n",
      "##############\n",
      "[2.18882019 1.61112822 5.14415335 4.22312971 2.70043205 5.58073005\n",
      " 4.24022824 4.55629121 3.79092417 3.62839164]\n",
      "##########\n",
      "epoch:10 step:9401 [D loss: 0.750018, acc.: 48.44%] [G loss: 0.963450]\n",
      "epoch:10 step:9402 [D loss: 0.682692, acc.: 58.59%] [G loss: 1.031985]\n",
      "epoch:10 step:9403 [D loss: 0.668571, acc.: 60.16%] [G loss: 1.060470]\n",
      "epoch:10 step:9404 [D loss: 0.647298, acc.: 60.16%] [G loss: 0.998523]\n",
      "epoch:10 step:9405 [D loss: 0.657839, acc.: 62.50%] [G loss: 0.913356]\n",
      "epoch:10 step:9406 [D loss: 0.548603, acc.: 72.66%] [G loss: 0.926780]\n",
      "epoch:10 step:9407 [D loss: 0.674966, acc.: 60.94%] [G loss: 0.970947]\n",
      "epoch:10 step:9408 [D loss: 0.719852, acc.: 57.81%] [G loss: 0.987387]\n",
      "epoch:10 step:9409 [D loss: 0.696677, acc.: 54.69%] [G loss: 0.998822]\n",
      "epoch:10 step:9410 [D loss: 0.569560, acc.: 72.66%] [G loss: 1.080370]\n",
      "epoch:10 step:9411 [D loss: 0.614443, acc.: 66.41%] [G loss: 0.943655]\n",
      "epoch:10 step:9412 [D loss: 0.603132, acc.: 67.97%] [G loss: 0.973235]\n",
      "epoch:10 step:9413 [D loss: 0.617418, acc.: 65.62%] [G loss: 0.997348]\n",
      "epoch:10 step:9414 [D loss: 0.622937, acc.: 61.72%] [G loss: 0.997517]\n",
      "epoch:10 step:9415 [D loss: 0.693943, acc.: 54.69%] [G loss: 0.913574]\n",
      "epoch:10 step:9416 [D loss: 0.677946, acc.: 57.81%] [G loss: 0.852173]\n",
      "epoch:10 step:9417 [D loss: 0.615031, acc.: 67.19%] [G loss: 0.933304]\n",
      "epoch:10 step:9418 [D loss: 0.667907, acc.: 54.69%] [G loss: 1.021404]\n",
      "epoch:10 step:9419 [D loss: 0.681676, acc.: 55.47%] [G loss: 0.981982]\n",
      "epoch:10 step:9420 [D loss: 0.681651, acc.: 63.28%] [G loss: 0.909630]\n",
      "epoch:10 step:9421 [D loss: 0.631879, acc.: 63.28%] [G loss: 0.968602]\n",
      "epoch:10 step:9422 [D loss: 0.665199, acc.: 59.38%] [G loss: 0.981845]\n",
      "epoch:10 step:9423 [D loss: 0.676139, acc.: 59.38%] [G loss: 0.962138]\n",
      "epoch:10 step:9424 [D loss: 0.605904, acc.: 70.31%] [G loss: 0.923396]\n",
      "epoch:10 step:9425 [D loss: 0.628483, acc.: 67.19%] [G loss: 0.997257]\n",
      "epoch:10 step:9426 [D loss: 0.642420, acc.: 60.94%] [G loss: 0.996251]\n",
      "epoch:10 step:9427 [D loss: 0.677210, acc.: 54.69%] [G loss: 1.010564]\n",
      "epoch:10 step:9428 [D loss: 0.588758, acc.: 69.53%] [G loss: 0.887767]\n",
      "epoch:10 step:9429 [D loss: 0.637104, acc.: 60.16%] [G loss: 1.022254]\n",
      "epoch:10 step:9430 [D loss: 0.614528, acc.: 67.19%] [G loss: 0.909165]\n",
      "epoch:10 step:9431 [D loss: 0.678571, acc.: 55.47%] [G loss: 0.930883]\n",
      "epoch:10 step:9432 [D loss: 0.658444, acc.: 61.72%] [G loss: 0.966956]\n",
      "epoch:10 step:9433 [D loss: 0.720263, acc.: 50.78%] [G loss: 0.866322]\n",
      "epoch:10 step:9434 [D loss: 0.650853, acc.: 62.50%] [G loss: 0.966237]\n",
      "epoch:10 step:9435 [D loss: 0.667397, acc.: 58.59%] [G loss: 0.900219]\n",
      "epoch:10 step:9436 [D loss: 0.712520, acc.: 54.69%] [G loss: 0.903913]\n",
      "epoch:10 step:9437 [D loss: 0.645352, acc.: 62.50%] [G loss: 0.948696]\n",
      "epoch:10 step:9438 [D loss: 0.697606, acc.: 52.34%] [G loss: 0.862018]\n",
      "epoch:10 step:9439 [D loss: 0.751636, acc.: 48.44%] [G loss: 0.871454]\n",
      "epoch:10 step:9440 [D loss: 0.564195, acc.: 73.44%] [G loss: 0.894226]\n",
      "epoch:10 step:9441 [D loss: 0.604853, acc.: 65.62%] [G loss: 0.954393]\n",
      "epoch:10 step:9442 [D loss: 0.650328, acc.: 63.28%] [G loss: 0.918949]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9443 [D loss: 0.583494, acc.: 69.53%] [G loss: 0.923058]\n",
      "epoch:10 step:9444 [D loss: 0.597919, acc.: 69.53%] [G loss: 0.942013]\n",
      "epoch:10 step:9445 [D loss: 0.593891, acc.: 71.09%] [G loss: 0.983291]\n",
      "epoch:10 step:9446 [D loss: 0.564387, acc.: 71.88%] [G loss: 1.054173]\n",
      "epoch:10 step:9447 [D loss: 0.579133, acc.: 69.53%] [G loss: 1.143376]\n",
      "epoch:10 step:9448 [D loss: 0.695589, acc.: 58.59%] [G loss: 0.971669]\n",
      "epoch:10 step:9449 [D loss: 0.655805, acc.: 63.28%] [G loss: 0.972959]\n",
      "epoch:10 step:9450 [D loss: 0.649175, acc.: 57.03%] [G loss: 0.889441]\n",
      "epoch:10 step:9451 [D loss: 0.786229, acc.: 43.75%] [G loss: 0.916496]\n",
      "epoch:10 step:9452 [D loss: 0.662167, acc.: 57.81%] [G loss: 0.914720]\n",
      "epoch:10 step:9453 [D loss: 0.666708, acc.: 61.72%] [G loss: 0.882695]\n",
      "epoch:10 step:9454 [D loss: 0.712158, acc.: 52.34%] [G loss: 0.936937]\n",
      "epoch:10 step:9455 [D loss: 0.671505, acc.: 60.16%] [G loss: 0.939079]\n",
      "epoch:10 step:9456 [D loss: 0.711188, acc.: 50.78%] [G loss: 0.985763]\n",
      "epoch:10 step:9457 [D loss: 0.701826, acc.: 51.56%] [G loss: 0.986455]\n",
      "epoch:10 step:9458 [D loss: 0.618379, acc.: 67.97%] [G loss: 0.955618]\n",
      "epoch:10 step:9459 [D loss: 0.678789, acc.: 61.72%] [G loss: 0.867196]\n",
      "epoch:10 step:9460 [D loss: 0.642250, acc.: 62.50%] [G loss: 0.847715]\n",
      "epoch:10 step:9461 [D loss: 0.744536, acc.: 46.88%] [G loss: 0.954629]\n",
      "epoch:10 step:9462 [D loss: 0.685417, acc.: 59.38%] [G loss: 0.941213]\n",
      "epoch:10 step:9463 [D loss: 0.692280, acc.: 58.59%] [G loss: 0.869429]\n",
      "epoch:10 step:9464 [D loss: 0.784159, acc.: 40.62%] [G loss: 0.857906]\n",
      "epoch:10 step:9465 [D loss: 0.660388, acc.: 63.28%] [G loss: 0.879530]\n",
      "epoch:10 step:9466 [D loss: 0.690117, acc.: 58.59%] [G loss: 0.993992]\n",
      "epoch:10 step:9467 [D loss: 0.592160, acc.: 73.44%] [G loss: 1.084937]\n",
      "epoch:10 step:9468 [D loss: 0.699927, acc.: 55.47%] [G loss: 0.780455]\n",
      "epoch:10 step:9469 [D loss: 0.779067, acc.: 46.09%] [G loss: 0.919966]\n",
      "epoch:10 step:9470 [D loss: 0.701440, acc.: 54.69%] [G loss: 0.956050]\n",
      "epoch:10 step:9471 [D loss: 0.623848, acc.: 63.28%] [G loss: 0.995673]\n",
      "epoch:10 step:9472 [D loss: 0.654675, acc.: 68.75%] [G loss: 0.952946]\n",
      "epoch:10 step:9473 [D loss: 0.561705, acc.: 75.78%] [G loss: 0.965262]\n",
      "epoch:10 step:9474 [D loss: 0.709186, acc.: 53.91%] [G loss: 0.966238]\n",
      "epoch:10 step:9475 [D loss: 0.689275, acc.: 56.25%] [G loss: 1.033481]\n",
      "epoch:10 step:9476 [D loss: 0.671981, acc.: 56.25%] [G loss: 0.997461]\n",
      "epoch:10 step:9477 [D loss: 0.723615, acc.: 55.47%] [G loss: 0.880172]\n",
      "epoch:10 step:9478 [D loss: 0.655078, acc.: 63.28%] [G loss: 0.864570]\n",
      "epoch:10 step:9479 [D loss: 0.640031, acc.: 60.16%] [G loss: 0.913423]\n",
      "epoch:10 step:9480 [D loss: 0.647956, acc.: 60.16%] [G loss: 0.940534]\n",
      "epoch:10 step:9481 [D loss: 0.665563, acc.: 59.38%] [G loss: 0.923007]\n",
      "epoch:10 step:9482 [D loss: 0.587956, acc.: 70.31%] [G loss: 1.050420]\n",
      "epoch:10 step:9483 [D loss: 0.626629, acc.: 64.06%] [G loss: 1.073773]\n",
      "epoch:10 step:9484 [D loss: 0.700080, acc.: 56.25%] [G loss: 0.935379]\n",
      "epoch:10 step:9485 [D loss: 0.699776, acc.: 57.03%] [G loss: 0.969157]\n",
      "epoch:10 step:9486 [D loss: 0.657982, acc.: 57.81%] [G loss: 0.971897]\n",
      "epoch:10 step:9487 [D loss: 0.677334, acc.: 59.38%] [G loss: 1.024134]\n",
      "epoch:10 step:9488 [D loss: 0.692638, acc.: 54.69%] [G loss: 0.969797]\n",
      "epoch:10 step:9489 [D loss: 0.633597, acc.: 66.41%] [G loss: 0.901765]\n",
      "epoch:10 step:9490 [D loss: 0.707065, acc.: 55.47%] [G loss: 1.003412]\n",
      "epoch:10 step:9491 [D loss: 0.669920, acc.: 57.81%] [G loss: 0.939874]\n",
      "epoch:10 step:9492 [D loss: 0.692974, acc.: 57.81%] [G loss: 0.958783]\n",
      "epoch:10 step:9493 [D loss: 0.593280, acc.: 69.53%] [G loss: 1.152870]\n",
      "epoch:10 step:9494 [D loss: 0.647248, acc.: 64.06%] [G loss: 0.956417]\n",
      "epoch:10 step:9495 [D loss: 0.725828, acc.: 52.34%] [G loss: 0.973783]\n",
      "epoch:10 step:9496 [D loss: 0.646701, acc.: 58.59%] [G loss: 1.076820]\n",
      "epoch:10 step:9497 [D loss: 0.714646, acc.: 55.47%] [G loss: 0.877538]\n",
      "epoch:10 step:9498 [D loss: 0.748675, acc.: 52.34%] [G loss: 0.785888]\n",
      "epoch:10 step:9499 [D loss: 0.696652, acc.: 53.91%] [G loss: 0.953353]\n",
      "epoch:10 step:9500 [D loss: 0.610153, acc.: 64.84%] [G loss: 0.952452]\n",
      "epoch:10 step:9501 [D loss: 0.566480, acc.: 75.78%] [G loss: 0.986779]\n",
      "epoch:10 step:9502 [D loss: 0.611559, acc.: 67.19%] [G loss: 0.966387]\n",
      "epoch:10 step:9503 [D loss: 0.729476, acc.: 56.25%] [G loss: 1.069648]\n",
      "epoch:10 step:9504 [D loss: 0.738382, acc.: 50.78%] [G loss: 0.827337]\n",
      "epoch:10 step:9505 [D loss: 0.652811, acc.: 63.28%] [G loss: 0.873214]\n",
      "epoch:10 step:9506 [D loss: 0.757556, acc.: 48.44%] [G loss: 0.954761]\n",
      "epoch:10 step:9507 [D loss: 0.651368, acc.: 60.16%] [G loss: 0.873787]\n",
      "epoch:10 step:9508 [D loss: 0.633322, acc.: 59.38%] [G loss: 0.910233]\n",
      "epoch:10 step:9509 [D loss: 0.725617, acc.: 50.00%] [G loss: 0.782415]\n",
      "epoch:10 step:9510 [D loss: 0.694517, acc.: 51.56%] [G loss: 0.896771]\n",
      "epoch:10 step:9511 [D loss: 0.673674, acc.: 54.69%] [G loss: 0.859146]\n",
      "epoch:10 step:9512 [D loss: 0.687887, acc.: 51.56%] [G loss: 0.862887]\n",
      "epoch:10 step:9513 [D loss: 0.726962, acc.: 49.22%] [G loss: 0.898943]\n",
      "epoch:10 step:9514 [D loss: 0.654151, acc.: 57.03%] [G loss: 1.081401]\n",
      "epoch:10 step:9515 [D loss: 0.632042, acc.: 64.84%] [G loss: 0.869555]\n",
      "epoch:10 step:9516 [D loss: 0.684429, acc.: 57.03%] [G loss: 0.897593]\n",
      "epoch:10 step:9517 [D loss: 0.648303, acc.: 61.72%] [G loss: 0.917245]\n",
      "epoch:10 step:9518 [D loss: 0.716621, acc.: 51.56%] [G loss: 0.891897]\n",
      "epoch:10 step:9519 [D loss: 0.694635, acc.: 56.25%] [G loss: 0.874727]\n",
      "epoch:10 step:9520 [D loss: 0.576456, acc.: 78.12%] [G loss: 0.934634]\n",
      "epoch:10 step:9521 [D loss: 0.636170, acc.: 64.06%] [G loss: 1.005527]\n",
      "epoch:10 step:9522 [D loss: 0.609453, acc.: 67.97%] [G loss: 1.045352]\n",
      "epoch:10 step:9523 [D loss: 0.638696, acc.: 60.94%] [G loss: 1.181169]\n",
      "epoch:10 step:9524 [D loss: 0.588925, acc.: 69.53%] [G loss: 1.097699]\n",
      "epoch:10 step:9525 [D loss: 0.660741, acc.: 61.72%] [G loss: 0.912902]\n",
      "epoch:10 step:9526 [D loss: 0.630510, acc.: 65.62%] [G loss: 1.010188]\n",
      "epoch:10 step:9527 [D loss: 0.710040, acc.: 49.22%] [G loss: 0.902171]\n",
      "epoch:10 step:9528 [D loss: 0.645435, acc.: 61.72%] [G loss: 1.014431]\n",
      "epoch:10 step:9529 [D loss: 0.721141, acc.: 55.47%] [G loss: 0.869350]\n",
      "epoch:10 step:9530 [D loss: 0.772463, acc.: 44.53%] [G loss: 0.806991]\n",
      "epoch:10 step:9531 [D loss: 0.761029, acc.: 49.22%] [G loss: 0.833521]\n",
      "epoch:10 step:9532 [D loss: 0.672977, acc.: 55.47%] [G loss: 0.730528]\n",
      "epoch:10 step:9533 [D loss: 0.667463, acc.: 58.59%] [G loss: 0.961687]\n",
      "epoch:10 step:9534 [D loss: 0.726279, acc.: 49.22%] [G loss: 0.877347]\n",
      "epoch:10 step:9535 [D loss: 0.673400, acc.: 59.38%] [G loss: 0.896557]\n",
      "epoch:10 step:9536 [D loss: 0.666837, acc.: 53.12%] [G loss: 0.842273]\n",
      "epoch:10 step:9537 [D loss: 0.693646, acc.: 57.81%] [G loss: 0.880966]\n",
      "epoch:10 step:9538 [D loss: 0.690315, acc.: 53.12%] [G loss: 0.942171]\n",
      "epoch:10 step:9539 [D loss: 0.676669, acc.: 62.50%] [G loss: 0.915162]\n",
      "epoch:10 step:9540 [D loss: 0.645171, acc.: 62.50%] [G loss: 0.987637]\n",
      "epoch:10 step:9541 [D loss: 0.645717, acc.: 62.50%] [G loss: 0.901772]\n",
      "epoch:10 step:9542 [D loss: 0.648161, acc.: 61.72%] [G loss: 0.887446]\n",
      "epoch:10 step:9543 [D loss: 0.638406, acc.: 60.16%] [G loss: 0.892933]\n",
      "epoch:10 step:9544 [D loss: 0.665753, acc.: 53.12%] [G loss: 0.990526]\n",
      "epoch:10 step:9545 [D loss: 0.682467, acc.: 56.25%] [G loss: 0.928963]\n",
      "epoch:10 step:9546 [D loss: 0.722415, acc.: 50.78%] [G loss: 0.873970]\n",
      "epoch:10 step:9547 [D loss: 0.704916, acc.: 53.91%] [G loss: 0.948329]\n",
      "epoch:10 step:9548 [D loss: 0.623423, acc.: 64.06%] [G loss: 0.913426]\n",
      "epoch:10 step:9549 [D loss: 0.661902, acc.: 59.38%] [G loss: 0.931965]\n",
      "epoch:10 step:9550 [D loss: 0.683730, acc.: 53.91%] [G loss: 0.843163]\n",
      "epoch:10 step:9551 [D loss: 0.703008, acc.: 54.69%] [G loss: 0.950533]\n",
      "epoch:10 step:9552 [D loss: 0.670950, acc.: 58.59%] [G loss: 0.941374]\n",
      "epoch:10 step:9553 [D loss: 0.783325, acc.: 43.75%] [G loss: 0.808613]\n",
      "epoch:10 step:9554 [D loss: 0.673698, acc.: 59.38%] [G loss: 0.992441]\n",
      "epoch:10 step:9555 [D loss: 0.707736, acc.: 54.69%] [G loss: 0.855378]\n",
      "epoch:10 step:9556 [D loss: 0.701548, acc.: 55.47%] [G loss: 0.833703]\n",
      "epoch:10 step:9557 [D loss: 0.754292, acc.: 46.88%] [G loss: 0.916478]\n",
      "epoch:10 step:9558 [D loss: 0.705011, acc.: 49.22%] [G loss: 0.811423]\n",
      "epoch:10 step:9559 [D loss: 0.723052, acc.: 51.56%] [G loss: 0.940278]\n",
      "epoch:10 step:9560 [D loss: 0.648080, acc.: 64.06%] [G loss: 0.816861]\n",
      "epoch:10 step:9561 [D loss: 0.708764, acc.: 52.34%] [G loss: 0.889758]\n",
      "epoch:10 step:9562 [D loss: 0.596553, acc.: 71.09%] [G loss: 1.041335]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9563 [D loss: 0.732189, acc.: 51.56%] [G loss: 0.919880]\n",
      "epoch:10 step:9564 [D loss: 0.694499, acc.: 56.25%] [G loss: 0.902056]\n",
      "epoch:10 step:9565 [D loss: 0.666056, acc.: 60.94%] [G loss: 0.922265]\n",
      "epoch:10 step:9566 [D loss: 0.754976, acc.: 49.22%] [G loss: 0.983140]\n",
      "epoch:10 step:9567 [D loss: 0.666996, acc.: 59.38%] [G loss: 0.846404]\n",
      "epoch:10 step:9568 [D loss: 0.651513, acc.: 61.72%] [G loss: 0.983394]\n",
      "epoch:10 step:9569 [D loss: 0.676111, acc.: 56.25%] [G loss: 0.964302]\n",
      "epoch:10 step:9570 [D loss: 0.702454, acc.: 59.38%] [G loss: 0.865241]\n",
      "epoch:10 step:9571 [D loss: 0.694913, acc.: 53.12%] [G loss: 0.936488]\n",
      "epoch:10 step:9572 [D loss: 0.705342, acc.: 57.81%] [G loss: 0.770934]\n",
      "epoch:10 step:9573 [D loss: 0.677507, acc.: 57.81%] [G loss: 0.938225]\n",
      "epoch:10 step:9574 [D loss: 0.626147, acc.: 68.75%] [G loss: 0.951265]\n",
      "epoch:10 step:9575 [D loss: 0.711796, acc.: 52.34%] [G loss: 0.995443]\n",
      "epoch:10 step:9576 [D loss: 0.624682, acc.: 66.41%] [G loss: 1.103697]\n",
      "epoch:10 step:9577 [D loss: 0.611419, acc.: 66.41%] [G loss: 0.966835]\n",
      "epoch:10 step:9578 [D loss: 0.563549, acc.: 75.00%] [G loss: 0.876679]\n",
      "epoch:10 step:9579 [D loss: 0.584265, acc.: 67.97%] [G loss: 0.905229]\n",
      "epoch:10 step:9580 [D loss: 0.677664, acc.: 58.59%] [G loss: 0.972607]\n",
      "epoch:10 step:9581 [D loss: 0.671185, acc.: 60.16%] [G loss: 0.942081]\n",
      "epoch:10 step:9582 [D loss: 0.705114, acc.: 55.47%] [G loss: 0.896341]\n",
      "epoch:10 step:9583 [D loss: 0.720899, acc.: 51.56%] [G loss: 0.896532]\n",
      "epoch:10 step:9584 [D loss: 0.728633, acc.: 50.00%] [G loss: 0.913310]\n",
      "epoch:10 step:9585 [D loss: 0.773809, acc.: 46.09%] [G loss: 0.957228]\n",
      "epoch:10 step:9586 [D loss: 0.644464, acc.: 60.94%] [G loss: 1.008348]\n",
      "epoch:10 step:9587 [D loss: 0.647609, acc.: 64.84%] [G loss: 0.870523]\n",
      "epoch:10 step:9588 [D loss: 0.655866, acc.: 64.84%] [G loss: 0.912803]\n",
      "epoch:10 step:9589 [D loss: 0.508490, acc.: 78.12%] [G loss: 1.091233]\n",
      "epoch:10 step:9590 [D loss: 0.788205, acc.: 46.09%] [G loss: 0.971262]\n",
      "epoch:10 step:9591 [D loss: 0.648409, acc.: 62.50%] [G loss: 0.792373]\n",
      "epoch:10 step:9592 [D loss: 0.705433, acc.: 55.47%] [G loss: 0.883028]\n",
      "epoch:10 step:9593 [D loss: 0.697051, acc.: 55.47%] [G loss: 0.944164]\n",
      "epoch:10 step:9594 [D loss: 0.719605, acc.: 53.12%] [G loss: 0.968584]\n",
      "epoch:10 step:9595 [D loss: 0.731250, acc.: 50.78%] [G loss: 1.034923]\n",
      "epoch:10 step:9596 [D loss: 0.670438, acc.: 57.81%] [G loss: 0.947839]\n",
      "epoch:10 step:9597 [D loss: 0.697088, acc.: 55.47%] [G loss: 1.053380]\n",
      "epoch:10 step:9598 [D loss: 0.718297, acc.: 55.47%] [G loss: 0.886774]\n",
      "epoch:10 step:9599 [D loss: 0.616532, acc.: 64.06%] [G loss: 0.917077]\n",
      "epoch:10 step:9600 [D loss: 0.552616, acc.: 70.31%] [G loss: 0.991126]\n",
      "##############\n",
      "[2.31324426 1.55978463 5.38027543 4.07956536 2.71592343 5.29749874\n",
      " 4.26647059 4.52281351 3.51223332 3.58597159]\n",
      "##########\n",
      "epoch:10 step:9601 [D loss: 0.497825, acc.: 75.78%] [G loss: 1.020552]\n",
      "epoch:10 step:9602 [D loss: 0.506992, acc.: 77.34%] [G loss: 1.103739]\n",
      "epoch:10 step:9603 [D loss: 0.697477, acc.: 53.91%] [G loss: 1.023652]\n",
      "epoch:10 step:9604 [D loss: 0.784121, acc.: 48.44%] [G loss: 0.946650]\n",
      "epoch:10 step:9605 [D loss: 0.691599, acc.: 59.38%] [G loss: 0.870376]\n",
      "epoch:10 step:9606 [D loss: 0.649478, acc.: 62.50%] [G loss: 0.985789]\n",
      "epoch:10 step:9607 [D loss: 0.694910, acc.: 55.47%] [G loss: 0.954502]\n",
      "epoch:10 step:9608 [D loss: 0.574390, acc.: 68.75%] [G loss: 1.098497]\n",
      "epoch:10 step:9609 [D loss: 0.703253, acc.: 53.12%] [G loss: 0.936783]\n",
      "epoch:10 step:9610 [D loss: 0.651711, acc.: 59.38%] [G loss: 0.953846]\n",
      "epoch:10 step:9611 [D loss: 0.620899, acc.: 65.62%] [G loss: 0.957177]\n",
      "epoch:10 step:9612 [D loss: 0.701025, acc.: 54.69%] [G loss: 0.910436]\n",
      "epoch:10 step:9613 [D loss: 0.660125, acc.: 58.59%] [G loss: 1.065658]\n",
      "epoch:10 step:9614 [D loss: 0.655435, acc.: 64.06%] [G loss: 0.776775]\n",
      "epoch:10 step:9615 [D loss: 0.681937, acc.: 53.91%] [G loss: 0.876184]\n",
      "epoch:10 step:9616 [D loss: 0.693872, acc.: 57.81%] [G loss: 0.962365]\n",
      "epoch:10 step:9617 [D loss: 0.725852, acc.: 53.91%] [G loss: 0.782550]\n",
      "epoch:10 step:9618 [D loss: 0.687231, acc.: 53.91%] [G loss: 0.882570]\n",
      "epoch:10 step:9619 [D loss: 0.699015, acc.: 59.38%] [G loss: 0.863129]\n",
      "epoch:10 step:9620 [D loss: 0.653131, acc.: 60.94%] [G loss: 1.071367]\n",
      "epoch:10 step:9621 [D loss: 0.719436, acc.: 53.12%] [G loss: 0.842956]\n",
      "epoch:10 step:9622 [D loss: 0.651270, acc.: 64.06%] [G loss: 0.880787]\n",
      "epoch:10 step:9623 [D loss: 0.640686, acc.: 59.38%] [G loss: 0.839816]\n",
      "epoch:10 step:9624 [D loss: 0.597715, acc.: 70.31%] [G loss: 0.989819]\n",
      "epoch:10 step:9625 [D loss: 0.616064, acc.: 69.53%] [G loss: 0.974535]\n",
      "epoch:10 step:9626 [D loss: 0.670806, acc.: 58.59%] [G loss: 0.965664]\n",
      "epoch:10 step:9627 [D loss: 0.604925, acc.: 65.62%] [G loss: 0.943333]\n",
      "epoch:10 step:9628 [D loss: 0.604028, acc.: 66.41%] [G loss: 0.960684]\n",
      "epoch:10 step:9629 [D loss: 0.641936, acc.: 59.38%] [G loss: 0.841149]\n",
      "epoch:10 step:9630 [D loss: 0.675306, acc.: 57.03%] [G loss: 0.956777]\n",
      "epoch:10 step:9631 [D loss: 0.625766, acc.: 68.75%] [G loss: 1.131306]\n",
      "epoch:10 step:9632 [D loss: 0.584494, acc.: 67.97%] [G loss: 1.129884]\n",
      "epoch:10 step:9633 [D loss: 0.716939, acc.: 52.34%] [G loss: 0.954026]\n",
      "epoch:10 step:9634 [D loss: 0.632378, acc.: 65.62%] [G loss: 1.023706]\n",
      "epoch:10 step:9635 [D loss: 0.608800, acc.: 67.19%] [G loss: 0.948846]\n",
      "epoch:10 step:9636 [D loss: 0.728537, acc.: 49.22%] [G loss: 0.887888]\n",
      "epoch:10 step:9637 [D loss: 0.634077, acc.: 63.28%] [G loss: 0.963490]\n",
      "epoch:10 step:9638 [D loss: 0.601732, acc.: 71.09%] [G loss: 0.909961]\n",
      "epoch:10 step:9639 [D loss: 0.673792, acc.: 53.12%] [G loss: 0.840613]\n",
      "epoch:10 step:9640 [D loss: 0.704424, acc.: 55.47%] [G loss: 0.872142]\n",
      "epoch:10 step:9641 [D loss: 0.679637, acc.: 57.81%] [G loss: 0.921550]\n",
      "epoch:10 step:9642 [D loss: 0.667177, acc.: 58.59%] [G loss: 0.899931]\n",
      "epoch:10 step:9643 [D loss: 0.584889, acc.: 67.97%] [G loss: 1.124450]\n",
      "epoch:10 step:9644 [D loss: 0.678149, acc.: 56.25%] [G loss: 0.941647]\n",
      "epoch:10 step:9645 [D loss: 0.692564, acc.: 53.91%] [G loss: 0.944359]\n",
      "epoch:10 step:9646 [D loss: 0.674171, acc.: 53.12%] [G loss: 0.897388]\n",
      "epoch:10 step:9647 [D loss: 0.640281, acc.: 64.84%] [G loss: 0.877704]\n",
      "epoch:10 step:9648 [D loss: 0.656745, acc.: 57.03%] [G loss: 0.895030]\n",
      "epoch:10 step:9649 [D loss: 0.609564, acc.: 62.50%] [G loss: 0.982028]\n",
      "epoch:10 step:9650 [D loss: 0.614935, acc.: 64.84%] [G loss: 0.999337]\n",
      "epoch:10 step:9651 [D loss: 0.691843, acc.: 57.81%] [G loss: 0.899987]\n",
      "epoch:10 step:9652 [D loss: 0.739859, acc.: 48.44%] [G loss: 0.915262]\n",
      "epoch:10 step:9653 [D loss: 0.628951, acc.: 65.62%] [G loss: 0.943375]\n",
      "epoch:10 step:9654 [D loss: 0.681006, acc.: 57.03%] [G loss: 0.925217]\n",
      "epoch:10 step:9655 [D loss: 0.607667, acc.: 74.22%] [G loss: 0.868685]\n",
      "epoch:10 step:9656 [D loss: 0.565117, acc.: 72.66%] [G loss: 0.932779]\n",
      "epoch:10 step:9657 [D loss: 0.660428, acc.: 63.28%] [G loss: 1.056638]\n",
      "epoch:10 step:9658 [D loss: 0.716400, acc.: 55.47%] [G loss: 0.858358]\n",
      "epoch:10 step:9659 [D loss: 0.622615, acc.: 60.16%] [G loss: 0.937391]\n",
      "epoch:10 step:9660 [D loss: 0.635830, acc.: 64.06%] [G loss: 0.869408]\n",
      "epoch:10 step:9661 [D loss: 0.668898, acc.: 56.25%] [G loss: 0.984477]\n",
      "epoch:10 step:9662 [D loss: 0.647376, acc.: 58.59%] [G loss: 0.844032]\n",
      "epoch:10 step:9663 [D loss: 0.635659, acc.: 69.53%] [G loss: 0.962830]\n",
      "epoch:10 step:9664 [D loss: 0.686183, acc.: 57.03%] [G loss: 0.927471]\n",
      "epoch:10 step:9665 [D loss: 0.701888, acc.: 50.78%] [G loss: 0.949068]\n",
      "epoch:10 step:9666 [D loss: 0.583908, acc.: 69.53%] [G loss: 0.910312]\n",
      "epoch:10 step:9667 [D loss: 0.653699, acc.: 64.06%] [G loss: 1.027632]\n",
      "epoch:10 step:9668 [D loss: 0.663572, acc.: 62.50%] [G loss: 0.954242]\n",
      "epoch:10 step:9669 [D loss: 0.651349, acc.: 61.72%] [G loss: 0.969803]\n",
      "epoch:10 step:9670 [D loss: 0.602278, acc.: 74.22%] [G loss: 0.890045]\n",
      "epoch:10 step:9671 [D loss: 0.664275, acc.: 61.72%] [G loss: 0.949465]\n",
      "epoch:10 step:9672 [D loss: 0.558812, acc.: 75.78%] [G loss: 1.009702]\n",
      "epoch:10 step:9673 [D loss: 0.616472, acc.: 67.97%] [G loss: 1.016138]\n",
      "epoch:10 step:9674 [D loss: 0.696748, acc.: 52.34%] [G loss: 0.885324]\n",
      "epoch:10 step:9675 [D loss: 0.600369, acc.: 71.88%] [G loss: 0.940075]\n",
      "epoch:10 step:9676 [D loss: 0.688675, acc.: 56.25%] [G loss: 0.844842]\n",
      "epoch:10 step:9677 [D loss: 0.673194, acc.: 56.25%] [G loss: 0.861302]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9678 [D loss: 0.653057, acc.: 57.03%] [G loss: 1.077797]\n",
      "epoch:10 step:9679 [D loss: 0.660794, acc.: 61.72%] [G loss: 0.885278]\n",
      "epoch:10 step:9680 [D loss: 0.607303, acc.: 69.53%] [G loss: 0.869450]\n",
      "epoch:10 step:9681 [D loss: 0.581035, acc.: 70.31%] [G loss: 0.945040]\n",
      "epoch:10 step:9682 [D loss: 0.614853, acc.: 67.97%] [G loss: 0.931531]\n",
      "epoch:10 step:9683 [D loss: 0.562952, acc.: 70.31%] [G loss: 1.087572]\n",
      "epoch:10 step:9684 [D loss: 0.559151, acc.: 74.22%] [G loss: 1.106237]\n",
      "epoch:10 step:9685 [D loss: 0.533750, acc.: 72.66%] [G loss: 1.140208]\n",
      "epoch:10 step:9686 [D loss: 0.720194, acc.: 54.69%] [G loss: 0.967078]\n",
      "epoch:10 step:9687 [D loss: 0.695247, acc.: 54.69%] [G loss: 0.988052]\n",
      "epoch:10 step:9688 [D loss: 0.640783, acc.: 61.72%] [G loss: 0.948221]\n",
      "epoch:10 step:9689 [D loss: 0.660157, acc.: 62.50%] [G loss: 0.831817]\n",
      "epoch:10 step:9690 [D loss: 0.707512, acc.: 58.59%] [G loss: 0.885749]\n",
      "epoch:10 step:9691 [D loss: 0.731185, acc.: 46.09%] [G loss: 0.872769]\n",
      "epoch:10 step:9692 [D loss: 0.682061, acc.: 53.12%] [G loss: 0.889789]\n",
      "epoch:10 step:9693 [D loss: 0.676493, acc.: 54.69%] [G loss: 1.052712]\n",
      "epoch:10 step:9694 [D loss: 0.654849, acc.: 63.28%] [G loss: 1.038509]\n",
      "epoch:10 step:9695 [D loss: 0.665854, acc.: 59.38%] [G loss: 0.856616]\n",
      "epoch:10 step:9696 [D loss: 0.596659, acc.: 68.75%] [G loss: 0.985915]\n",
      "epoch:10 step:9697 [D loss: 0.705110, acc.: 52.34%] [G loss: 0.880563]\n",
      "epoch:10 step:9698 [D loss: 0.597884, acc.: 67.97%] [G loss: 0.960887]\n",
      "epoch:10 step:9699 [D loss: 0.673242, acc.: 56.25%] [G loss: 0.843216]\n",
      "epoch:10 step:9700 [D loss: 0.658907, acc.: 63.28%] [G loss: 0.916179]\n",
      "epoch:10 step:9701 [D loss: 0.605747, acc.: 68.75%] [G loss: 0.815437]\n",
      "epoch:10 step:9702 [D loss: 0.721296, acc.: 57.03%] [G loss: 0.918532]\n",
      "epoch:10 step:9703 [D loss: 0.618723, acc.: 67.97%] [G loss: 0.948372]\n",
      "epoch:10 step:9704 [D loss: 0.667599, acc.: 57.03%] [G loss: 0.783689]\n",
      "epoch:10 step:9705 [D loss: 0.628116, acc.: 67.19%] [G loss: 0.942100]\n",
      "epoch:10 step:9706 [D loss: 0.636515, acc.: 60.16%] [G loss: 0.880252]\n",
      "epoch:10 step:9707 [D loss: 0.641774, acc.: 66.41%] [G loss: 0.856627]\n",
      "epoch:10 step:9708 [D loss: 0.619603, acc.: 65.62%] [G loss: 1.043416]\n",
      "epoch:10 step:9709 [D loss: 0.653962, acc.: 66.41%] [G loss: 0.902726]\n",
      "epoch:10 step:9710 [D loss: 0.625094, acc.: 67.19%] [G loss: 1.015056]\n",
      "epoch:10 step:9711 [D loss: 0.669734, acc.: 60.94%] [G loss: 1.110887]\n",
      "epoch:10 step:9712 [D loss: 0.729651, acc.: 51.56%] [G loss: 0.935346]\n",
      "epoch:10 step:9713 [D loss: 0.657944, acc.: 59.38%] [G loss: 0.984569]\n",
      "epoch:10 step:9714 [D loss: 0.638258, acc.: 62.50%] [G loss: 1.001052]\n",
      "epoch:10 step:9715 [D loss: 0.600200, acc.: 67.97%] [G loss: 1.071168]\n",
      "epoch:10 step:9716 [D loss: 0.621681, acc.: 65.62%] [G loss: 0.917468]\n",
      "epoch:10 step:9717 [D loss: 0.523851, acc.: 76.56%] [G loss: 1.120590]\n",
      "epoch:10 step:9718 [D loss: 0.713780, acc.: 57.03%] [G loss: 1.098324]\n",
      "epoch:10 step:9719 [D loss: 0.654792, acc.: 56.25%] [G loss: 0.940676]\n",
      "epoch:10 step:9720 [D loss: 0.652334, acc.: 61.72%] [G loss: 0.900740]\n",
      "epoch:10 step:9721 [D loss: 0.615669, acc.: 67.97%] [G loss: 0.880003]\n",
      "epoch:10 step:9722 [D loss: 0.750715, acc.: 50.00%] [G loss: 0.995943]\n",
      "epoch:10 step:9723 [D loss: 0.614009, acc.: 67.97%] [G loss: 0.970880]\n",
      "epoch:10 step:9724 [D loss: 0.590749, acc.: 67.19%] [G loss: 1.132977]\n",
      "epoch:10 step:9725 [D loss: 0.696795, acc.: 58.59%] [G loss: 0.907978]\n",
      "epoch:10 step:9726 [D loss: 0.745044, acc.: 48.44%] [G loss: 0.968522]\n",
      "epoch:10 step:9727 [D loss: 0.663641, acc.: 63.28%] [G loss: 0.918609]\n",
      "epoch:10 step:9728 [D loss: 0.636800, acc.: 59.38%] [G loss: 1.023211]\n",
      "epoch:10 step:9729 [D loss: 0.643919, acc.: 64.06%] [G loss: 0.997222]\n",
      "epoch:10 step:9730 [D loss: 0.647510, acc.: 61.72%] [G loss: 1.120783]\n",
      "epoch:10 step:9731 [D loss: 0.575653, acc.: 72.66%] [G loss: 0.964237]\n",
      "epoch:10 step:9732 [D loss: 0.754287, acc.: 50.78%] [G loss: 0.881015]\n",
      "epoch:10 step:9733 [D loss: 0.649400, acc.: 64.06%] [G loss: 1.018438]\n",
      "epoch:10 step:9734 [D loss: 0.629028, acc.: 64.06%] [G loss: 1.051889]\n",
      "epoch:10 step:9735 [D loss: 0.672786, acc.: 56.25%] [G loss: 1.033302]\n",
      "epoch:10 step:9736 [D loss: 0.624992, acc.: 64.84%] [G loss: 0.885652]\n",
      "epoch:10 step:9737 [D loss: 0.699839, acc.: 58.59%] [G loss: 0.928473]\n",
      "epoch:10 step:9738 [D loss: 0.685011, acc.: 60.94%] [G loss: 0.899318]\n",
      "epoch:10 step:9739 [D loss: 0.678338, acc.: 59.38%] [G loss: 0.909519]\n",
      "epoch:10 step:9740 [D loss: 0.610063, acc.: 64.06%] [G loss: 0.853236]\n",
      "epoch:10 step:9741 [D loss: 0.611599, acc.: 67.19%] [G loss: 0.892202]\n",
      "epoch:10 step:9742 [D loss: 0.726024, acc.: 53.12%] [G loss: 0.982855]\n",
      "epoch:10 step:9743 [D loss: 0.742683, acc.: 49.22%] [G loss: 0.779350]\n",
      "epoch:10 step:9744 [D loss: 0.717968, acc.: 53.91%] [G loss: 0.865311]\n",
      "epoch:10 step:9745 [D loss: 0.736920, acc.: 51.56%] [G loss: 0.836307]\n",
      "epoch:10 step:9746 [D loss: 0.730289, acc.: 52.34%] [G loss: 0.962613]\n",
      "epoch:10 step:9747 [D loss: 0.688506, acc.: 57.03%] [G loss: 0.997236]\n",
      "epoch:10 step:9748 [D loss: 0.665314, acc.: 57.03%] [G loss: 0.963084]\n",
      "epoch:10 step:9749 [D loss: 0.617476, acc.: 68.75%] [G loss: 0.904531]\n",
      "epoch:10 step:9750 [D loss: 0.655453, acc.: 59.38%] [G loss: 0.996393]\n",
      "epoch:10 step:9751 [D loss: 0.612622, acc.: 67.97%] [G loss: 0.907569]\n",
      "epoch:10 step:9752 [D loss: 0.711435, acc.: 52.34%] [G loss: 1.062085]\n",
      "epoch:10 step:9753 [D loss: 0.732447, acc.: 50.00%] [G loss: 0.950453]\n",
      "epoch:10 step:9754 [D loss: 0.603533, acc.: 71.09%] [G loss: 0.947279]\n",
      "epoch:10 step:9755 [D loss: 0.615349, acc.: 65.62%] [G loss: 0.980933]\n",
      "epoch:10 step:9756 [D loss: 0.682023, acc.: 55.47%] [G loss: 0.869329]\n",
      "epoch:10 step:9757 [D loss: 0.629655, acc.: 60.94%] [G loss: 0.943078]\n",
      "epoch:10 step:9758 [D loss: 0.679675, acc.: 55.47%] [G loss: 0.890390]\n",
      "epoch:10 step:9759 [D loss: 0.741857, acc.: 49.22%] [G loss: 0.947019]\n",
      "epoch:10 step:9760 [D loss: 0.665146, acc.: 59.38%] [G loss: 0.983537]\n",
      "epoch:10 step:9761 [D loss: 0.716145, acc.: 50.00%] [G loss: 0.915320]\n",
      "epoch:10 step:9762 [D loss: 0.643564, acc.: 58.59%] [G loss: 1.027238]\n",
      "epoch:10 step:9763 [D loss: 0.659418, acc.: 57.03%] [G loss: 0.983121]\n",
      "epoch:10 step:9764 [D loss: 0.638387, acc.: 65.62%] [G loss: 0.885248]\n",
      "epoch:10 step:9765 [D loss: 0.712942, acc.: 47.66%] [G loss: 0.922823]\n",
      "epoch:10 step:9766 [D loss: 0.771059, acc.: 48.44%] [G loss: 0.994718]\n",
      "epoch:10 step:9767 [D loss: 0.719724, acc.: 54.69%] [G loss: 0.949503]\n",
      "epoch:10 step:9768 [D loss: 0.597720, acc.: 65.62%] [G loss: 1.053099]\n",
      "epoch:10 step:9769 [D loss: 0.631372, acc.: 66.41%] [G loss: 1.012614]\n",
      "epoch:10 step:9770 [D loss: 0.657926, acc.: 57.03%] [G loss: 0.966004]\n",
      "epoch:10 step:9771 [D loss: 0.565410, acc.: 71.88%] [G loss: 1.018391]\n",
      "epoch:10 step:9772 [D loss: 0.653956, acc.: 60.94%] [G loss: 0.968449]\n",
      "epoch:10 step:9773 [D loss: 0.707237, acc.: 57.03%] [G loss: 0.909956]\n",
      "epoch:10 step:9774 [D loss: 0.629731, acc.: 68.75%] [G loss: 1.002446]\n",
      "epoch:10 step:9775 [D loss: 0.617428, acc.: 65.62%] [G loss: 1.047181]\n",
      "epoch:10 step:9776 [D loss: 0.577248, acc.: 70.31%] [G loss: 0.942827]\n",
      "epoch:10 step:9777 [D loss: 0.638577, acc.: 64.06%] [G loss: 1.095564]\n",
      "epoch:10 step:9778 [D loss: 0.629128, acc.: 64.06%] [G loss: 1.051249]\n",
      "epoch:10 step:9779 [D loss: 0.711084, acc.: 55.47%] [G loss: 0.948338]\n",
      "epoch:10 step:9780 [D loss: 0.632348, acc.: 61.72%] [G loss: 0.910167]\n",
      "epoch:10 step:9781 [D loss: 0.673489, acc.: 61.72%] [G loss: 0.944805]\n",
      "epoch:10 step:9782 [D loss: 0.681642, acc.: 54.69%] [G loss: 0.825639]\n",
      "epoch:10 step:9783 [D loss: 0.708039, acc.: 53.12%] [G loss: 0.994466]\n",
      "epoch:10 step:9784 [D loss: 0.792937, acc.: 50.00%] [G loss: 0.854713]\n",
      "epoch:10 step:9785 [D loss: 0.720900, acc.: 53.12%] [G loss: 0.991950]\n",
      "epoch:10 step:9786 [D loss: 0.580912, acc.: 71.88%] [G loss: 1.108559]\n",
      "epoch:10 step:9787 [D loss: 0.688007, acc.: 63.28%] [G loss: 0.953260]\n",
      "epoch:10 step:9788 [D loss: 0.587615, acc.: 67.19%] [G loss: 1.001472]\n",
      "epoch:10 step:9789 [D loss: 0.590414, acc.: 66.41%] [G loss: 0.951772]\n",
      "epoch:10 step:9790 [D loss: 0.688377, acc.: 59.38%] [G loss: 0.833600]\n",
      "epoch:10 step:9791 [D loss: 0.763865, acc.: 43.75%] [G loss: 0.965299]\n",
      "epoch:10 step:9792 [D loss: 0.745889, acc.: 46.09%] [G loss: 1.018617]\n",
      "epoch:10 step:9793 [D loss: 0.701891, acc.: 53.91%] [G loss: 0.967166]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9794 [D loss: 0.627334, acc.: 64.84%] [G loss: 1.016606]\n",
      "epoch:10 step:9795 [D loss: 0.649997, acc.: 64.06%] [G loss: 1.129288]\n",
      "epoch:10 step:9796 [D loss: 0.658224, acc.: 61.72%] [G loss: 0.908320]\n",
      "epoch:10 step:9797 [D loss: 0.664075, acc.: 56.25%] [G loss: 0.925599]\n",
      "epoch:10 step:9798 [D loss: 0.689694, acc.: 57.03%] [G loss: 0.963772]\n",
      "epoch:10 step:9799 [D loss: 0.620598, acc.: 66.41%] [G loss: 1.012707]\n",
      "epoch:10 step:9800 [D loss: 0.594648, acc.: 71.88%] [G loss: 1.071569]\n",
      "##############\n",
      "[2.06690265 1.78300331 5.44652197 4.58004496 3.24419472 5.14340385\n",
      " 3.9713005  4.29880231 3.830782   3.2739811 ]\n",
      "##########\n",
      "epoch:10 step:9801 [D loss: 0.667550, acc.: 59.38%] [G loss: 1.064175]\n",
      "epoch:10 step:9802 [D loss: 0.783355, acc.: 46.88%] [G loss: 0.930670]\n",
      "epoch:10 step:9803 [D loss: 0.734645, acc.: 49.22%] [G loss: 0.980125]\n",
      "epoch:10 step:9804 [D loss: 0.765188, acc.: 49.22%] [G loss: 0.865303]\n",
      "epoch:10 step:9805 [D loss: 0.635298, acc.: 65.62%] [G loss: 1.001046]\n",
      "epoch:10 step:9806 [D loss: 0.642526, acc.: 63.28%] [G loss: 0.994586]\n",
      "epoch:10 step:9807 [D loss: 0.723569, acc.: 53.91%] [G loss: 0.956234]\n",
      "epoch:10 step:9808 [D loss: 0.663354, acc.: 63.28%] [G loss: 1.049216]\n",
      "epoch:10 step:9809 [D loss: 0.697063, acc.: 50.78%] [G loss: 0.999843]\n",
      "epoch:10 step:9810 [D loss: 0.665421, acc.: 55.47%] [G loss: 0.917545]\n",
      "epoch:10 step:9811 [D loss: 0.732689, acc.: 49.22%] [G loss: 0.943359]\n",
      "epoch:10 step:9812 [D loss: 0.690489, acc.: 55.47%] [G loss: 0.799492]\n",
      "epoch:10 step:9813 [D loss: 0.701165, acc.: 57.81%] [G loss: 0.920041]\n",
      "epoch:10 step:9814 [D loss: 0.689055, acc.: 55.47%] [G loss: 0.846112]\n",
      "epoch:10 step:9815 [D loss: 0.669182, acc.: 54.69%] [G loss: 1.000346]\n",
      "epoch:10 step:9816 [D loss: 0.680761, acc.: 58.59%] [G loss: 0.900685]\n",
      "epoch:10 step:9817 [D loss: 0.687859, acc.: 53.91%] [G loss: 0.844571]\n",
      "epoch:10 step:9818 [D loss: 0.708573, acc.: 55.47%] [G loss: 0.858273]\n",
      "epoch:10 step:9819 [D loss: 0.669811, acc.: 58.59%] [G loss: 0.840356]\n",
      "epoch:10 step:9820 [D loss: 0.629913, acc.: 66.41%] [G loss: 1.014757]\n",
      "epoch:10 step:9821 [D loss: 0.687090, acc.: 58.59%] [G loss: 0.891979]\n",
      "epoch:10 step:9822 [D loss: 0.751606, acc.: 46.09%] [G loss: 0.964077]\n",
      "epoch:10 step:9823 [D loss: 0.627449, acc.: 66.41%] [G loss: 0.986852]\n",
      "epoch:10 step:9824 [D loss: 0.547027, acc.: 75.00%] [G loss: 1.170904]\n",
      "epoch:10 step:9825 [D loss: 0.628332, acc.: 68.75%] [G loss: 1.053031]\n",
      "epoch:10 step:9826 [D loss: 0.569617, acc.: 71.09%] [G loss: 1.058884]\n",
      "epoch:10 step:9827 [D loss: 0.615798, acc.: 62.50%] [G loss: 1.142452]\n",
      "epoch:10 step:9828 [D loss: 0.758760, acc.: 50.00%] [G loss: 0.888096]\n",
      "epoch:10 step:9829 [D loss: 0.652237, acc.: 61.72%] [G loss: 1.012498]\n",
      "epoch:10 step:9830 [D loss: 0.702772, acc.: 51.56%] [G loss: 0.890645]\n",
      "epoch:10 step:9831 [D loss: 0.744487, acc.: 47.66%] [G loss: 0.963983]\n",
      "epoch:10 step:9832 [D loss: 0.670205, acc.: 54.69%] [G loss: 0.956199]\n",
      "epoch:10 step:9833 [D loss: 0.691566, acc.: 57.81%] [G loss: 0.972980]\n",
      "epoch:10 step:9834 [D loss: 0.609575, acc.: 68.75%] [G loss: 1.023391]\n",
      "epoch:10 step:9835 [D loss: 0.672281, acc.: 59.38%] [G loss: 1.030643]\n",
      "epoch:10 step:9836 [D loss: 0.607747, acc.: 70.31%] [G loss: 1.060801]\n",
      "epoch:10 step:9837 [D loss: 0.650928, acc.: 64.06%] [G loss: 0.965932]\n",
      "epoch:10 step:9838 [D loss: 0.644967, acc.: 61.72%] [G loss: 0.989901]\n",
      "epoch:10 step:9839 [D loss: 0.519468, acc.: 79.69%] [G loss: 1.142993]\n",
      "epoch:10 step:9840 [D loss: 0.534485, acc.: 76.56%] [G loss: 0.964448]\n",
      "epoch:10 step:9841 [D loss: 0.524568, acc.: 75.78%] [G loss: 1.080721]\n",
      "epoch:10 step:9842 [D loss: 0.606830, acc.: 67.19%] [G loss: 1.193946]\n",
      "epoch:10 step:9843 [D loss: 0.887713, acc.: 39.06%] [G loss: 0.842718]\n",
      "epoch:10 step:9844 [D loss: 0.756950, acc.: 45.31%] [G loss: 0.813328]\n",
      "epoch:10 step:9845 [D loss: 0.788791, acc.: 45.31%] [G loss: 0.791483]\n",
      "epoch:10 step:9846 [D loss: 0.665780, acc.: 53.91%] [G loss: 0.890229]\n",
      "epoch:10 step:9847 [D loss: 0.718245, acc.: 50.78%] [G loss: 0.891573]\n",
      "epoch:10 step:9848 [D loss: 0.667837, acc.: 54.69%] [G loss: 0.938562]\n",
      "epoch:10 step:9849 [D loss: 0.670269, acc.: 57.81%] [G loss: 0.969534]\n",
      "epoch:10 step:9850 [D loss: 0.614097, acc.: 64.84%] [G loss: 0.930636]\n",
      "epoch:10 step:9851 [D loss: 0.604454, acc.: 65.62%] [G loss: 1.013027]\n",
      "epoch:10 step:9852 [D loss: 0.661177, acc.: 59.38%] [G loss: 0.971335]\n",
      "epoch:10 step:9853 [D loss: 0.760702, acc.: 35.94%] [G loss: 0.913201]\n",
      "epoch:10 step:9854 [D loss: 0.587921, acc.: 73.44%] [G loss: 1.012839]\n",
      "epoch:10 step:9855 [D loss: 0.694401, acc.: 52.34%] [G loss: 1.001672]\n",
      "epoch:10 step:9856 [D loss: 0.691443, acc.: 57.03%] [G loss: 0.931196]\n",
      "epoch:10 step:9857 [D loss: 0.682383, acc.: 57.81%] [G loss: 0.852201]\n",
      "epoch:10 step:9858 [D loss: 0.662064, acc.: 61.72%] [G loss: 0.868030]\n",
      "epoch:10 step:9859 [D loss: 0.578665, acc.: 73.44%] [G loss: 0.846694]\n",
      "epoch:10 step:9860 [D loss: 0.625946, acc.: 62.50%] [G loss: 0.926554]\n",
      "epoch:10 step:9861 [D loss: 0.631375, acc.: 67.97%] [G loss: 1.092266]\n",
      "epoch:10 step:9862 [D loss: 0.633386, acc.: 64.06%] [G loss: 1.068812]\n",
      "epoch:10 step:9863 [D loss: 0.697693, acc.: 56.25%] [G loss: 0.896370]\n",
      "epoch:10 step:9864 [D loss: 0.674962, acc.: 55.47%] [G loss: 0.831952]\n",
      "epoch:10 step:9865 [D loss: 0.608511, acc.: 63.28%] [G loss: 0.975366]\n",
      "epoch:10 step:9866 [D loss: 0.710477, acc.: 51.56%] [G loss: 1.045567]\n",
      "epoch:10 step:9867 [D loss: 0.720832, acc.: 53.12%] [G loss: 0.951350]\n",
      "epoch:10 step:9868 [D loss: 0.621376, acc.: 64.06%] [G loss: 1.068319]\n",
      "epoch:10 step:9869 [D loss: 0.574217, acc.: 69.53%] [G loss: 1.151678]\n",
      "epoch:10 step:9870 [D loss: 0.656370, acc.: 61.72%] [G loss: 0.979601]\n",
      "epoch:10 step:9871 [D loss: 0.731251, acc.: 53.12%] [G loss: 0.977044]\n",
      "epoch:10 step:9872 [D loss: 0.704547, acc.: 56.25%] [G loss: 0.945871]\n",
      "epoch:10 step:9873 [D loss: 0.594831, acc.: 73.44%] [G loss: 0.953701]\n",
      "epoch:10 step:9874 [D loss: 0.604862, acc.: 70.31%] [G loss: 0.950225]\n",
      "epoch:10 step:9875 [D loss: 0.585863, acc.: 71.09%] [G loss: 0.949157]\n",
      "epoch:10 step:9876 [D loss: 0.674883, acc.: 57.03%] [G loss: 1.066665]\n",
      "epoch:10 step:9877 [D loss: 0.684015, acc.: 55.47%] [G loss: 0.862300]\n",
      "epoch:10 step:9878 [D loss: 0.530196, acc.: 77.34%] [G loss: 0.973738]\n",
      "epoch:10 step:9879 [D loss: 0.704557, acc.: 50.00%] [G loss: 0.869349]\n",
      "epoch:10 step:9880 [D loss: 0.707264, acc.: 56.25%] [G loss: 0.854621]\n",
      "epoch:10 step:9881 [D loss: 0.674874, acc.: 61.72%] [G loss: 0.932111]\n",
      "epoch:10 step:9882 [D loss: 0.675205, acc.: 60.94%] [G loss: 0.946538]\n",
      "epoch:10 step:9883 [D loss: 0.641395, acc.: 59.38%] [G loss: 0.930925]\n",
      "epoch:10 step:9884 [D loss: 0.682572, acc.: 58.59%] [G loss: 0.932998]\n",
      "epoch:10 step:9885 [D loss: 0.604324, acc.: 63.28%] [G loss: 0.866521]\n",
      "epoch:10 step:9886 [D loss: 0.570282, acc.: 71.88%] [G loss: 0.875940]\n",
      "epoch:10 step:9887 [D loss: 0.651564, acc.: 67.19%] [G loss: 0.975028]\n",
      "epoch:10 step:9888 [D loss: 0.692040, acc.: 58.59%] [G loss: 0.827223]\n",
      "epoch:10 step:9889 [D loss: 0.646173, acc.: 60.16%] [G loss: 0.916653]\n",
      "epoch:10 step:9890 [D loss: 0.668648, acc.: 57.81%] [G loss: 0.925307]\n",
      "epoch:10 step:9891 [D loss: 0.730335, acc.: 48.44%] [G loss: 0.885290]\n",
      "epoch:10 step:9892 [D loss: 0.656972, acc.: 64.84%] [G loss: 1.091697]\n",
      "epoch:10 step:9893 [D loss: 0.625738, acc.: 66.41%] [G loss: 0.962950]\n",
      "epoch:10 step:9894 [D loss: 0.721354, acc.: 50.78%] [G loss: 0.844807]\n",
      "epoch:10 step:9895 [D loss: 0.601959, acc.: 69.53%] [G loss: 0.993862]\n",
      "epoch:10 step:9896 [D loss: 0.677616, acc.: 56.25%] [G loss: 1.038600]\n",
      "epoch:10 step:9897 [D loss: 0.653683, acc.: 58.59%] [G loss: 0.900471]\n",
      "epoch:10 step:9898 [D loss: 0.727486, acc.: 53.12%] [G loss: 0.994325]\n",
      "epoch:10 step:9899 [D loss: 0.647171, acc.: 61.72%] [G loss: 0.931223]\n",
      "epoch:10 step:9900 [D loss: 0.627563, acc.: 61.72%] [G loss: 0.829857]\n",
      "epoch:10 step:9901 [D loss: 0.646879, acc.: 60.16%] [G loss: 0.885561]\n",
      "epoch:10 step:9902 [D loss: 0.576171, acc.: 75.00%] [G loss: 0.940319]\n",
      "epoch:10 step:9903 [D loss: 0.659745, acc.: 60.94%] [G loss: 0.920199]\n",
      "epoch:10 step:9904 [D loss: 0.641341, acc.: 61.72%] [G loss: 0.912638]\n",
      "epoch:10 step:9905 [D loss: 0.649253, acc.: 62.50%] [G loss: 0.925005]\n",
      "epoch:10 step:9906 [D loss: 0.655864, acc.: 64.06%] [G loss: 0.821544]\n",
      "epoch:10 step:9907 [D loss: 0.617734, acc.: 64.84%] [G loss: 0.982657]\n",
      "epoch:10 step:9908 [D loss: 0.725748, acc.: 53.91%] [G loss: 0.885141]\n",
      "epoch:10 step:9909 [D loss: 0.613710, acc.: 68.75%] [G loss: 0.949005]\n",
      "epoch:10 step:9910 [D loss: 0.718565, acc.: 53.12%] [G loss: 0.851189]\n",
      "epoch:10 step:9911 [D loss: 0.668006, acc.: 56.25%] [G loss: 0.961397]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9912 [D loss: 0.805786, acc.: 34.38%] [G loss: 0.855245]\n",
      "epoch:10 step:9913 [D loss: 0.726861, acc.: 50.78%] [G loss: 0.863068]\n",
      "epoch:10 step:9914 [D loss: 0.671528, acc.: 52.34%] [G loss: 0.963498]\n",
      "epoch:10 step:9915 [D loss: 0.627816, acc.: 70.31%] [G loss: 0.967332]\n",
      "epoch:10 step:9916 [D loss: 0.699064, acc.: 55.47%] [G loss: 0.903067]\n",
      "epoch:10 step:9917 [D loss: 0.593235, acc.: 65.62%] [G loss: 1.034506]\n",
      "epoch:10 step:9918 [D loss: 0.677011, acc.: 55.47%] [G loss: 1.017343]\n",
      "epoch:10 step:9919 [D loss: 0.602472, acc.: 71.88%] [G loss: 0.983258]\n",
      "epoch:10 step:9920 [D loss: 0.704056, acc.: 48.44%] [G loss: 0.882596]\n",
      "epoch:10 step:9921 [D loss: 0.606610, acc.: 69.53%] [G loss: 0.994552]\n",
      "epoch:10 step:9922 [D loss: 0.663745, acc.: 57.03%] [G loss: 0.970855]\n",
      "epoch:10 step:9923 [D loss: 0.608413, acc.: 66.41%] [G loss: 1.197242]\n",
      "epoch:10 step:9924 [D loss: 0.600555, acc.: 66.41%] [G loss: 1.122975]\n",
      "epoch:10 step:9925 [D loss: 0.610686, acc.: 65.62%] [G loss: 0.994864]\n",
      "epoch:10 step:9926 [D loss: 0.591434, acc.: 73.44%] [G loss: 0.979953]\n",
      "epoch:10 step:9927 [D loss: 0.575744, acc.: 72.66%] [G loss: 0.983589]\n",
      "epoch:10 step:9928 [D loss: 0.580243, acc.: 69.53%] [G loss: 0.968213]\n",
      "epoch:10 step:9929 [D loss: 0.760501, acc.: 49.22%] [G loss: 0.961638]\n",
      "epoch:10 step:9930 [D loss: 0.736879, acc.: 50.78%] [G loss: 0.988372]\n",
      "epoch:10 step:9931 [D loss: 0.707119, acc.: 55.47%] [G loss: 0.957869]\n",
      "epoch:10 step:9932 [D loss: 0.688376, acc.: 54.69%] [G loss: 0.879950]\n",
      "epoch:10 step:9933 [D loss: 0.670114, acc.: 54.69%] [G loss: 0.853506]\n",
      "epoch:10 step:9934 [D loss: 0.585332, acc.: 70.31%] [G loss: 0.954993]\n",
      "epoch:10 step:9935 [D loss: 0.696542, acc.: 58.59%] [G loss: 0.931283]\n",
      "epoch:10 step:9936 [D loss: 0.706106, acc.: 59.38%] [G loss: 0.919390]\n",
      "epoch:10 step:9937 [D loss: 0.768679, acc.: 46.09%] [G loss: 0.924787]\n",
      "epoch:10 step:9938 [D loss: 0.671998, acc.: 59.38%] [G loss: 0.951053]\n",
      "epoch:10 step:9939 [D loss: 0.658146, acc.: 64.06%] [G loss: 0.880752]\n",
      "epoch:10 step:9940 [D loss: 0.664528, acc.: 60.16%] [G loss: 0.886601]\n",
      "epoch:10 step:9941 [D loss: 0.649275, acc.: 64.84%] [G loss: 1.014295]\n",
      "epoch:10 step:9942 [D loss: 0.727282, acc.: 55.47%] [G loss: 0.905968]\n",
      "epoch:10 step:9943 [D loss: 0.658286, acc.: 64.84%] [G loss: 0.882841]\n",
      "epoch:10 step:9944 [D loss: 0.646356, acc.: 58.59%] [G loss: 0.958848]\n",
      "epoch:10 step:9945 [D loss: 0.685015, acc.: 55.47%] [G loss: 0.947441]\n",
      "epoch:10 step:9946 [D loss: 0.676806, acc.: 55.47%] [G loss: 0.834826]\n",
      "epoch:10 step:9947 [D loss: 0.673374, acc.: 60.16%] [G loss: 0.783314]\n",
      "epoch:10 step:9948 [D loss: 0.696175, acc.: 54.69%] [G loss: 0.918625]\n",
      "epoch:10 step:9949 [D loss: 0.720124, acc.: 49.22%] [G loss: 0.926152]\n",
      "epoch:10 step:9950 [D loss: 0.686724, acc.: 55.47%] [G loss: 0.927201]\n",
      "epoch:10 step:9951 [D loss: 0.688703, acc.: 56.25%] [G loss: 0.886064]\n",
      "epoch:10 step:9952 [D loss: 0.634712, acc.: 60.16%] [G loss: 0.878953]\n",
      "epoch:10 step:9953 [D loss: 0.618546, acc.: 67.97%] [G loss: 0.909238]\n",
      "epoch:10 step:9954 [D loss: 0.675172, acc.: 59.38%] [G loss: 1.050127]\n",
      "epoch:10 step:9955 [D loss: 0.630603, acc.: 64.06%] [G loss: 0.871159]\n",
      "epoch:10 step:9956 [D loss: 0.602482, acc.: 71.09%] [G loss: 0.944832]\n",
      "epoch:10 step:9957 [D loss: 0.612340, acc.: 67.19%] [G loss: 1.055195]\n",
      "epoch:10 step:9958 [D loss: 0.592125, acc.: 68.75%] [G loss: 0.944236]\n",
      "epoch:10 step:9959 [D loss: 0.567843, acc.: 74.22%] [G loss: 1.090806]\n",
      "epoch:10 step:9960 [D loss: 0.632822, acc.: 64.06%] [G loss: 1.002529]\n",
      "epoch:10 step:9961 [D loss: 0.689552, acc.: 56.25%] [G loss: 0.984647]\n",
      "epoch:10 step:9962 [D loss: 0.695860, acc.: 51.56%] [G loss: 0.911536]\n",
      "epoch:10 step:9963 [D loss: 0.658010, acc.: 58.59%] [G loss: 0.900699]\n",
      "epoch:10 step:9964 [D loss: 0.690292, acc.: 49.22%] [G loss: 1.008499]\n",
      "epoch:10 step:9965 [D loss: 0.660475, acc.: 59.38%] [G loss: 0.884533]\n",
      "epoch:10 step:9966 [D loss: 0.668439, acc.: 59.38%] [G loss: 0.941416]\n",
      "epoch:10 step:9967 [D loss: 0.734546, acc.: 54.69%] [G loss: 0.827002]\n",
      "epoch:10 step:9968 [D loss: 0.706289, acc.: 54.69%] [G loss: 0.980303]\n",
      "epoch:10 step:9969 [D loss: 0.601400, acc.: 67.97%] [G loss: 1.045714]\n",
      "epoch:10 step:9970 [D loss: 0.712399, acc.: 58.59%] [G loss: 0.935182]\n",
      "epoch:10 step:9971 [D loss: 0.676589, acc.: 59.38%] [G loss: 0.969646]\n",
      "epoch:10 step:9972 [D loss: 0.670365, acc.: 64.84%] [G loss: 0.945032]\n",
      "epoch:10 step:9973 [D loss: 0.674351, acc.: 58.59%] [G loss: 0.967569]\n",
      "epoch:10 step:9974 [D loss: 0.614316, acc.: 64.06%] [G loss: 1.040643]\n",
      "epoch:10 step:9975 [D loss: 0.614740, acc.: 63.28%] [G loss: 0.930695]\n",
      "epoch:10 step:9976 [D loss: 0.698144, acc.: 55.47%] [G loss: 0.879459]\n",
      "epoch:10 step:9977 [D loss: 0.565364, acc.: 75.00%] [G loss: 0.950190]\n",
      "epoch:10 step:9978 [D loss: 0.706097, acc.: 52.34%] [G loss: 0.794181]\n",
      "epoch:10 step:9979 [D loss: 0.639754, acc.: 65.62%] [G loss: 0.924838]\n",
      "epoch:10 step:9980 [D loss: 0.687442, acc.: 61.72%] [G loss: 0.957664]\n",
      "epoch:10 step:9981 [D loss: 0.617420, acc.: 66.41%] [G loss: 0.885969]\n",
      "epoch:10 step:9982 [D loss: 0.641289, acc.: 58.59%] [G loss: 0.959235]\n",
      "epoch:10 step:9983 [D loss: 0.624984, acc.: 67.19%] [G loss: 0.895701]\n",
      "epoch:10 step:9984 [D loss: 0.717366, acc.: 49.22%] [G loss: 0.811560]\n",
      "epoch:10 step:9985 [D loss: 0.651796, acc.: 60.94%] [G loss: 0.879123]\n",
      "epoch:10 step:9986 [D loss: 0.633286, acc.: 64.06%] [G loss: 0.902753]\n",
      "epoch:10 step:9987 [D loss: 0.720425, acc.: 54.69%] [G loss: 0.908632]\n",
      "epoch:10 step:9988 [D loss: 0.700906, acc.: 57.03%] [G loss: 0.867317]\n",
      "epoch:10 step:9989 [D loss: 0.672748, acc.: 57.03%] [G loss: 0.984904]\n",
      "epoch:10 step:9990 [D loss: 0.615780, acc.: 66.41%] [G loss: 1.071307]\n",
      "epoch:10 step:9991 [D loss: 0.688170, acc.: 60.16%] [G loss: 0.981247]\n",
      "epoch:10 step:9992 [D loss: 0.735154, acc.: 46.09%] [G loss: 0.934625]\n",
      "epoch:10 step:9993 [D loss: 0.615435, acc.: 70.31%] [G loss: 1.138404]\n",
      "epoch:10 step:9994 [D loss: 0.636995, acc.: 65.62%] [G loss: 0.920427]\n",
      "epoch:10 step:9995 [D loss: 0.746803, acc.: 48.44%] [G loss: 0.959493]\n",
      "epoch:10 step:9996 [D loss: 0.666930, acc.: 55.47%] [G loss: 0.813042]\n",
      "epoch:10 step:9997 [D loss: 0.735109, acc.: 51.56%] [G loss: 0.815872]\n",
      "epoch:10 step:9998 [D loss: 0.674792, acc.: 55.47%] [G loss: 0.868072]\n",
      "epoch:10 step:9999 [D loss: 0.638246, acc.: 64.06%] [G loss: 0.900296]\n",
      "epoch:10 step:10000 [D loss: 0.664563, acc.: 58.59%] [G loss: 0.984768]\n",
      "##############\n",
      "[2.09399003 1.44935048 5.46391162 4.25720285 3.0012897  5.53916544\n",
      " 4.05564491 4.65355006 3.7664512  3.78319382]\n",
      "##########\n",
      "epoch:10 step:10001 [D loss: 0.664909, acc.: 55.47%] [G loss: 1.061417]\n",
      "epoch:10 step:10002 [D loss: 0.609921, acc.: 66.41%] [G loss: 1.062869]\n",
      "epoch:10 step:10003 [D loss: 0.607404, acc.: 67.97%] [G loss: 0.960053]\n",
      "epoch:10 step:10004 [D loss: 0.622812, acc.: 65.62%] [G loss: 0.942541]\n",
      "epoch:10 step:10005 [D loss: 0.577719, acc.: 70.31%] [G loss: 1.179192]\n",
      "epoch:10 step:10006 [D loss: 0.728101, acc.: 57.81%] [G loss: 0.971061]\n",
      "epoch:10 step:10007 [D loss: 0.572031, acc.: 75.00%] [G loss: 1.159667]\n",
      "epoch:10 step:10008 [D loss: 0.627310, acc.: 64.84%] [G loss: 0.927730]\n",
      "epoch:10 step:10009 [D loss: 0.631280, acc.: 62.50%] [G loss: 1.116952]\n",
      "epoch:10 step:10010 [D loss: 0.670821, acc.: 61.72%] [G loss: 0.899599]\n",
      "epoch:10 step:10011 [D loss: 0.690585, acc.: 60.16%] [G loss: 0.898102]\n",
      "epoch:10 step:10012 [D loss: 0.690070, acc.: 57.81%] [G loss: 1.013769]\n",
      "epoch:10 step:10013 [D loss: 0.632884, acc.: 62.50%] [G loss: 0.861735]\n",
      "epoch:10 step:10014 [D loss: 0.689005, acc.: 51.56%] [G loss: 0.837254]\n",
      "epoch:10 step:10015 [D loss: 0.568896, acc.: 70.31%] [G loss: 0.958637]\n",
      "epoch:10 step:10016 [D loss: 0.565792, acc.: 71.88%] [G loss: 0.955331]\n",
      "epoch:10 step:10017 [D loss: 0.654094, acc.: 64.84%] [G loss: 0.835207]\n",
      "epoch:10 step:10018 [D loss: 0.529992, acc.: 82.81%] [G loss: 0.991482]\n",
      "epoch:10 step:10019 [D loss: 0.597753, acc.: 67.97%] [G loss: 0.954637]\n",
      "epoch:10 step:10020 [D loss: 0.602805, acc.: 70.31%] [G loss: 1.007354]\n",
      "epoch:10 step:10021 [D loss: 0.595506, acc.: 65.62%] [G loss: 1.105238]\n",
      "epoch:10 step:10022 [D loss: 0.670096, acc.: 64.06%] [G loss: 0.945737]\n",
      "epoch:10 step:10023 [D loss: 0.755022, acc.: 42.97%] [G loss: 0.868536]\n",
      "epoch:10 step:10024 [D loss: 0.714942, acc.: 53.12%] [G loss: 0.682006]\n",
      "epoch:10 step:10025 [D loss: 0.700902, acc.: 57.03%] [G loss: 0.841297]\n",
      "epoch:10 step:10026 [D loss: 0.624769, acc.: 64.06%] [G loss: 0.958107]\n",
      "epoch:10 step:10027 [D loss: 0.696772, acc.: 52.34%] [G loss: 0.931497]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:10028 [D loss: 0.705861, acc.: 50.00%] [G loss: 0.958862]\n",
      "epoch:10 step:10029 [D loss: 0.560328, acc.: 77.34%] [G loss: 1.051558]\n",
      "epoch:10 step:10030 [D loss: 0.665331, acc.: 54.69%] [G loss: 0.955075]\n",
      "epoch:10 step:10031 [D loss: 0.671169, acc.: 57.03%] [G loss: 0.920727]\n",
      "epoch:10 step:10032 [D loss: 0.696131, acc.: 57.81%] [G loss: 0.924645]\n",
      "epoch:10 step:10033 [D loss: 0.692987, acc.: 51.56%] [G loss: 0.889994]\n",
      "epoch:10 step:10034 [D loss: 0.616668, acc.: 66.41%] [G loss: 0.831509]\n",
      "epoch:10 step:10035 [D loss: 0.682889, acc.: 57.81%] [G loss: 0.942099]\n",
      "epoch:10 step:10036 [D loss: 0.681522, acc.: 57.81%] [G loss: 0.837135]\n",
      "epoch:10 step:10037 [D loss: 0.756690, acc.: 46.09%] [G loss: 1.002012]\n",
      "epoch:10 step:10038 [D loss: 0.713050, acc.: 49.22%] [G loss: 0.859139]\n",
      "epoch:10 step:10039 [D loss: 0.690789, acc.: 52.34%] [G loss: 0.856142]\n",
      "epoch:10 step:10040 [D loss: 0.696823, acc.: 58.59%] [G loss: 0.965100]\n",
      "epoch:10 step:10041 [D loss: 0.653584, acc.: 61.72%] [G loss: 1.020567]\n",
      "epoch:10 step:10042 [D loss: 0.690399, acc.: 60.94%] [G loss: 0.902433]\n",
      "epoch:10 step:10043 [D loss: 0.728742, acc.: 49.22%] [G loss: 0.887157]\n",
      "epoch:10 step:10044 [D loss: 0.722870, acc.: 51.56%] [G loss: 0.955155]\n",
      "epoch:10 step:10045 [D loss: 0.647297, acc.: 62.50%] [G loss: 1.064796]\n",
      "epoch:10 step:10046 [D loss: 0.619153, acc.: 64.84%] [G loss: 0.904639]\n",
      "epoch:10 step:10047 [D loss: 0.574848, acc.: 71.09%] [G loss: 1.179670]\n",
      "epoch:10 step:10048 [D loss: 0.632872, acc.: 65.62%] [G loss: 0.917431]\n",
      "epoch:10 step:10049 [D loss: 0.587455, acc.: 64.84%] [G loss: 1.115585]\n",
      "epoch:10 step:10050 [D loss: 0.582405, acc.: 72.66%] [G loss: 0.974871]\n",
      "epoch:10 step:10051 [D loss: 0.612674, acc.: 71.09%] [G loss: 0.940836]\n",
      "epoch:10 step:10052 [D loss: 0.636532, acc.: 64.84%] [G loss: 1.019840]\n",
      "epoch:10 step:10053 [D loss: 0.683220, acc.: 58.59%] [G loss: 1.005842]\n",
      "epoch:10 step:10054 [D loss: 0.683711, acc.: 54.69%] [G loss: 0.998598]\n",
      "epoch:10 step:10055 [D loss: 0.637843, acc.: 62.50%] [G loss: 0.906111]\n",
      "epoch:10 step:10056 [D loss: 0.670247, acc.: 57.03%] [G loss: 0.965937]\n",
      "epoch:10 step:10057 [D loss: 0.656371, acc.: 61.72%] [G loss: 0.810245]\n",
      "epoch:10 step:10058 [D loss: 0.703737, acc.: 54.69%] [G loss: 0.827886]\n",
      "epoch:10 step:10059 [D loss: 0.630739, acc.: 63.28%] [G loss: 0.964413]\n",
      "epoch:10 step:10060 [D loss: 0.610593, acc.: 65.62%] [G loss: 0.972871]\n",
      "epoch:10 step:10061 [D loss: 0.577978, acc.: 73.44%] [G loss: 0.914704]\n",
      "epoch:10 step:10062 [D loss: 0.564420, acc.: 75.00%] [G loss: 1.023250]\n",
      "epoch:10 step:10063 [D loss: 0.605884, acc.: 71.88%] [G loss: 0.902896]\n",
      "epoch:10 step:10064 [D loss: 0.561889, acc.: 73.44%] [G loss: 1.062570]\n",
      "epoch:10 step:10065 [D loss: 0.633449, acc.: 59.38%] [G loss: 1.018036]\n",
      "epoch:10 step:10066 [D loss: 0.676647, acc.: 57.03%] [G loss: 0.997753]\n",
      "epoch:10 step:10067 [D loss: 0.786542, acc.: 41.41%] [G loss: 0.928658]\n",
      "epoch:10 step:10068 [D loss: 0.670228, acc.: 62.50%] [G loss: 0.919059]\n",
      "epoch:10 step:10069 [D loss: 0.670299, acc.: 57.81%] [G loss: 0.995019]\n",
      "epoch:10 step:10070 [D loss: 0.596177, acc.: 71.88%] [G loss: 0.969479]\n",
      "epoch:10 step:10071 [D loss: 0.639410, acc.: 64.06%] [G loss: 0.995819]\n",
      "epoch:10 step:10072 [D loss: 0.722324, acc.: 51.56%] [G loss: 0.894134]\n",
      "epoch:10 step:10073 [D loss: 0.736270, acc.: 50.00%] [G loss: 0.817775]\n",
      "epoch:10 step:10074 [D loss: 0.714213, acc.: 55.47%] [G loss: 0.834000]\n",
      "epoch:10 step:10075 [D loss: 0.696431, acc.: 55.47%] [G loss: 0.874362]\n",
      "epoch:10 step:10076 [D loss: 0.654558, acc.: 64.06%] [G loss: 0.957302]\n",
      "epoch:10 step:10077 [D loss: 0.572930, acc.: 73.44%] [G loss: 0.896685]\n",
      "epoch:10 step:10078 [D loss: 0.579196, acc.: 66.41%] [G loss: 1.028652]\n",
      "epoch:10 step:10079 [D loss: 0.521648, acc.: 78.12%] [G loss: 0.950289]\n",
      "epoch:10 step:10080 [D loss: 0.719181, acc.: 50.00%] [G loss: 0.882837]\n",
      "epoch:10 step:10081 [D loss: 0.668511, acc.: 62.50%] [G loss: 0.956063]\n",
      "epoch:10 step:10082 [D loss: 0.670602, acc.: 58.59%] [G loss: 0.934894]\n",
      "epoch:10 step:10083 [D loss: 0.704153, acc.: 55.47%] [G loss: 0.943533]\n",
      "epoch:10 step:10084 [D loss: 0.617950, acc.: 69.53%] [G loss: 1.031456]\n",
      "epoch:10 step:10085 [D loss: 0.684559, acc.: 56.25%] [G loss: 0.882840]\n",
      "epoch:10 step:10086 [D loss: 0.781935, acc.: 45.31%] [G loss: 0.913222]\n",
      "epoch:10 step:10087 [D loss: 0.670847, acc.: 60.94%] [G loss: 0.910656]\n",
      "epoch:10 step:10088 [D loss: 0.737670, acc.: 50.78%] [G loss: 0.781561]\n",
      "epoch:10 step:10089 [D loss: 0.695281, acc.: 55.47%] [G loss: 0.916654]\n",
      "epoch:10 step:10090 [D loss: 0.739285, acc.: 51.56%] [G loss: 0.921179]\n",
      "epoch:10 step:10091 [D loss: 0.699925, acc.: 54.69%] [G loss: 0.815478]\n",
      "epoch:10 step:10092 [D loss: 0.642039, acc.: 62.50%] [G loss: 1.054959]\n",
      "epoch:10 step:10093 [D loss: 0.690119, acc.: 53.12%] [G loss: 0.909213]\n",
      "epoch:10 step:10094 [D loss: 0.670606, acc.: 60.16%] [G loss: 1.015104]\n",
      "epoch:10 step:10095 [D loss: 0.653400, acc.: 64.06%] [G loss: 0.963809]\n",
      "epoch:10 step:10096 [D loss: 0.659439, acc.: 62.50%] [G loss: 0.823572]\n",
      "epoch:10 step:10097 [D loss: 0.676406, acc.: 54.69%] [G loss: 0.959992]\n",
      "epoch:10 step:10098 [D loss: 0.610803, acc.: 68.75%] [G loss: 0.939718]\n",
      "epoch:10 step:10099 [D loss: 0.644092, acc.: 66.41%] [G loss: 0.985538]\n",
      "epoch:10 step:10100 [D loss: 0.661355, acc.: 63.28%] [G loss: 0.993100]\n",
      "epoch:10 step:10101 [D loss: 0.598151, acc.: 69.53%] [G loss: 0.950048]\n",
      "epoch:10 step:10102 [D loss: 0.579102, acc.: 77.34%] [G loss: 0.974914]\n",
      "epoch:10 step:10103 [D loss: 0.649069, acc.: 61.72%] [G loss: 0.966645]\n",
      "epoch:10 step:10104 [D loss: 0.673143, acc.: 57.81%] [G loss: 1.001142]\n",
      "epoch:10 step:10105 [D loss: 0.680294, acc.: 60.16%] [G loss: 0.901843]\n",
      "epoch:10 step:10106 [D loss: 0.578040, acc.: 70.31%] [G loss: 1.064566]\n",
      "epoch:10 step:10107 [D loss: 0.617247, acc.: 64.84%] [G loss: 0.907471]\n",
      "epoch:10 step:10108 [D loss: 0.706780, acc.: 57.03%] [G loss: 0.797911]\n",
      "epoch:10 step:10109 [D loss: 0.642760, acc.: 63.28%] [G loss: 1.043189]\n",
      "epoch:10 step:10110 [D loss: 0.631768, acc.: 65.62%] [G loss: 1.052525]\n",
      "epoch:10 step:10111 [D loss: 0.861190, acc.: 37.50%] [G loss: 0.935781]\n",
      "epoch:10 step:10112 [D loss: 0.691854, acc.: 54.69%] [G loss: 0.793281]\n",
      "epoch:10 step:10113 [D loss: 0.717122, acc.: 54.69%] [G loss: 0.975387]\n",
      "epoch:10 step:10114 [D loss: 0.707155, acc.: 53.12%] [G loss: 0.926987]\n",
      "epoch:10 step:10115 [D loss: 0.613257, acc.: 71.88%] [G loss: 0.987465]\n",
      "epoch:10 step:10116 [D loss: 0.705784, acc.: 55.47%] [G loss: 0.879808]\n",
      "epoch:10 step:10117 [D loss: 0.640265, acc.: 60.16%] [G loss: 0.880340]\n",
      "epoch:10 step:10118 [D loss: 0.648404, acc.: 64.84%] [G loss: 1.081793]\n",
      "epoch:10 step:10119 [D loss: 0.702011, acc.: 53.91%] [G loss: 0.937578]\n",
      "epoch:10 step:10120 [D loss: 0.675989, acc.: 57.03%] [G loss: 0.993457]\n",
      "epoch:10 step:10121 [D loss: 0.679174, acc.: 56.25%] [G loss: 1.026095]\n",
      "epoch:10 step:10122 [D loss: 0.704040, acc.: 52.34%] [G loss: 0.953651]\n",
      "epoch:10 step:10123 [D loss: 0.651657, acc.: 60.94%] [G loss: 0.942939]\n",
      "epoch:10 step:10124 [D loss: 0.665283, acc.: 59.38%] [G loss: 0.934522]\n",
      "epoch:10 step:10125 [D loss: 0.616953, acc.: 64.84%] [G loss: 0.889322]\n",
      "epoch:10 step:10126 [D loss: 0.633892, acc.: 67.19%] [G loss: 0.870090]\n",
      "epoch:10 step:10127 [D loss: 0.692020, acc.: 55.47%] [G loss: 0.889543]\n",
      "epoch:10 step:10128 [D loss: 0.656631, acc.: 62.50%] [G loss: 0.940322]\n",
      "epoch:10 step:10129 [D loss: 0.691377, acc.: 53.91%] [G loss: 0.844149]\n",
      "epoch:10 step:10130 [D loss: 0.722478, acc.: 54.69%] [G loss: 0.934464]\n",
      "epoch:10 step:10131 [D loss: 0.629403, acc.: 64.84%] [G loss: 0.906847]\n",
      "epoch:10 step:10132 [D loss: 0.635807, acc.: 62.50%] [G loss: 0.941592]\n",
      "epoch:10 step:10133 [D loss: 0.708768, acc.: 57.03%] [G loss: 0.880174]\n",
      "epoch:10 step:10134 [D loss: 0.725680, acc.: 47.66%] [G loss: 0.818471]\n",
      "epoch:10 step:10135 [D loss: 0.680403, acc.: 60.16%] [G loss: 0.816037]\n",
      "epoch:10 step:10136 [D loss: 0.691574, acc.: 54.69%] [G loss: 0.955161]\n",
      "epoch:10 step:10137 [D loss: 0.628660, acc.: 68.75%] [G loss: 1.006732]\n",
      "epoch:10 step:10138 [D loss: 0.655336, acc.: 59.38%] [G loss: 0.834562]\n",
      "epoch:10 step:10139 [D loss: 0.670756, acc.: 58.59%] [G loss: 0.926383]\n",
      "epoch:10 step:10140 [D loss: 0.649462, acc.: 60.94%] [G loss: 0.855499]\n",
      "epoch:10 step:10141 [D loss: 0.652636, acc.: 62.50%] [G loss: 0.993494]\n",
      "epoch:10 step:10142 [D loss: 0.690375, acc.: 57.03%] [G loss: 0.954783]\n",
      "epoch:10 step:10143 [D loss: 0.702070, acc.: 49.22%] [G loss: 0.874118]\n",
      "epoch:10 step:10144 [D loss: 0.614236, acc.: 63.28%] [G loss: 0.962915]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:10145 [D loss: 0.620678, acc.: 67.97%] [G loss: 0.944978]\n",
      "epoch:10 step:10146 [D loss: 0.620169, acc.: 64.06%] [G loss: 1.103376]\n",
      "epoch:10 step:10147 [D loss: 0.578443, acc.: 70.31%] [G loss: 1.103346]\n",
      "epoch:10 step:10148 [D loss: 0.692599, acc.: 54.69%] [G loss: 1.020003]\n",
      "epoch:10 step:10149 [D loss: 0.682409, acc.: 57.03%] [G loss: 0.948723]\n",
      "epoch:10 step:10150 [D loss: 0.713550, acc.: 53.91%] [G loss: 0.857665]\n",
      "epoch:10 step:10151 [D loss: 0.692946, acc.: 54.69%] [G loss: 0.901593]\n",
      "epoch:10 step:10152 [D loss: 0.623998, acc.: 64.06%] [G loss: 1.019268]\n",
      "epoch:10 step:10153 [D loss: 0.680538, acc.: 58.59%] [G loss: 0.865732]\n",
      "epoch:10 step:10154 [D loss: 0.673695, acc.: 59.38%] [G loss: 0.928717]\n",
      "epoch:10 step:10155 [D loss: 0.677686, acc.: 61.72%] [G loss: 0.960862]\n",
      "epoch:10 step:10156 [D loss: 0.633853, acc.: 66.41%] [G loss: 0.994692]\n",
      "epoch:10 step:10157 [D loss: 0.665250, acc.: 59.38%] [G loss: 0.977494]\n",
      "epoch:10 step:10158 [D loss: 0.732348, acc.: 49.22%] [G loss: 0.805904]\n",
      "epoch:10 step:10159 [D loss: 0.703307, acc.: 52.34%] [G loss: 0.795397]\n",
      "epoch:10 step:10160 [D loss: 0.663855, acc.: 60.94%] [G loss: 0.934081]\n",
      "epoch:10 step:10161 [D loss: 0.592958, acc.: 71.88%] [G loss: 0.958019]\n",
      "epoch:10 step:10162 [D loss: 0.556320, acc.: 75.78%] [G loss: 0.973018]\n",
      "epoch:10 step:10163 [D loss: 0.587702, acc.: 73.44%] [G loss: 0.967977]\n",
      "epoch:10 step:10164 [D loss: 0.641272, acc.: 62.50%] [G loss: 1.098181]\n",
      "epoch:10 step:10165 [D loss: 0.682329, acc.: 57.81%] [G loss: 1.059999]\n",
      "epoch:10 step:10166 [D loss: 0.657934, acc.: 65.62%] [G loss: 0.919352]\n",
      "epoch:10 step:10167 [D loss: 0.692507, acc.: 56.25%] [G loss: 0.925592]\n",
      "epoch:10 step:10168 [D loss: 0.518109, acc.: 78.12%] [G loss: 1.007054]\n",
      "epoch:10 step:10169 [D loss: 0.708615, acc.: 51.56%] [G loss: 0.965243]\n",
      "epoch:10 step:10170 [D loss: 0.740932, acc.: 53.91%] [G loss: 0.886366]\n",
      "epoch:10 step:10171 [D loss: 0.669111, acc.: 55.47%] [G loss: 0.895057]\n",
      "epoch:10 step:10172 [D loss: 0.650417, acc.: 64.06%] [G loss: 0.902390]\n",
      "epoch:10 step:10173 [D loss: 0.657940, acc.: 59.38%] [G loss: 0.951770]\n",
      "epoch:10 step:10174 [D loss: 0.712964, acc.: 49.22%] [G loss: 0.957242]\n",
      "epoch:10 step:10175 [D loss: 0.640787, acc.: 60.94%] [G loss: 0.941940]\n",
      "epoch:10 step:10176 [D loss: 0.532652, acc.: 76.56%] [G loss: 1.077251]\n",
      "epoch:10 step:10177 [D loss: 0.686888, acc.: 57.81%] [G loss: 0.956991]\n",
      "epoch:10 step:10178 [D loss: 0.731356, acc.: 50.00%] [G loss: 0.875546]\n",
      "epoch:10 step:10179 [D loss: 0.601187, acc.: 71.09%] [G loss: 0.942417]\n",
      "epoch:10 step:10180 [D loss: 0.585382, acc.: 72.66%] [G loss: 0.982563]\n",
      "epoch:10 step:10181 [D loss: 0.754689, acc.: 45.31%] [G loss: 0.790935]\n",
      "epoch:10 step:10182 [D loss: 0.722511, acc.: 54.69%] [G loss: 0.950086]\n",
      "epoch:10 step:10183 [D loss: 0.631863, acc.: 60.94%] [G loss: 0.990082]\n",
      "epoch:10 step:10184 [D loss: 0.715240, acc.: 48.44%] [G loss: 0.911624]\n",
      "epoch:10 step:10185 [D loss: 0.599854, acc.: 68.75%] [G loss: 0.861122]\n",
      "epoch:10 step:10186 [D loss: 0.666188, acc.: 59.38%] [G loss: 0.845723]\n",
      "epoch:10 step:10187 [D loss: 0.634627, acc.: 64.06%] [G loss: 0.976741]\n",
      "epoch:10 step:10188 [D loss: 0.674999, acc.: 57.03%] [G loss: 0.949381]\n",
      "epoch:10 step:10189 [D loss: 0.631675, acc.: 64.06%] [G loss: 0.954115]\n",
      "epoch:10 step:10190 [D loss: 0.672877, acc.: 60.16%] [G loss: 0.977184]\n",
      "epoch:10 step:10191 [D loss: 0.669445, acc.: 57.03%] [G loss: 0.959660]\n",
      "epoch:10 step:10192 [D loss: 0.677912, acc.: 62.50%] [G loss: 0.952332]\n",
      "epoch:10 step:10193 [D loss: 0.578416, acc.: 71.09%] [G loss: 0.980284]\n",
      "epoch:10 step:10194 [D loss: 0.669779, acc.: 53.91%] [G loss: 0.984881]\n",
      "epoch:10 step:10195 [D loss: 0.647470, acc.: 63.28%] [G loss: 0.812444]\n",
      "epoch:10 step:10196 [D loss: 0.693441, acc.: 59.38%] [G loss: 0.911373]\n",
      "epoch:10 step:10197 [D loss: 0.634681, acc.: 63.28%] [G loss: 0.974901]\n",
      "epoch:10 step:10198 [D loss: 0.694850, acc.: 55.47%] [G loss: 0.860043]\n",
      "epoch:10 step:10199 [D loss: 0.681310, acc.: 55.47%] [G loss: 0.943163]\n",
      "epoch:10 step:10200 [D loss: 0.625510, acc.: 64.06%] [G loss: 0.924625]\n",
      "##############\n",
      "[1.96725225 1.3531339  4.98932258 4.137729   2.78581131 5.02063389\n",
      " 3.94571479 4.1712716  3.53011291 3.08372816]\n",
      "##########\n",
      "epoch:10 step:10201 [D loss: 0.570152, acc.: 74.22%] [G loss: 0.961614]\n",
      "epoch:10 step:10202 [D loss: 0.645722, acc.: 64.06%] [G loss: 1.019870]\n",
      "epoch:10 step:10203 [D loss: 0.649783, acc.: 63.28%] [G loss: 0.920169]\n",
      "epoch:10 step:10204 [D loss: 0.591104, acc.: 71.88%] [G loss: 0.913454]\n",
      "epoch:10 step:10205 [D loss: 0.613123, acc.: 67.97%] [G loss: 0.963377]\n",
      "epoch:10 step:10206 [D loss: 0.688315, acc.: 57.81%] [G loss: 0.887606]\n",
      "epoch:10 step:10207 [D loss: 0.669311, acc.: 57.81%] [G loss: 0.927895]\n",
      "epoch:10 step:10208 [D loss: 0.705038, acc.: 55.47%] [G loss: 0.875543]\n",
      "epoch:10 step:10209 [D loss: 0.614947, acc.: 69.53%] [G loss: 0.946881]\n",
      "epoch:10 step:10210 [D loss: 0.630161, acc.: 67.97%] [G loss: 0.922561]\n",
      "epoch:10 step:10211 [D loss: 0.642028, acc.: 66.41%] [G loss: 1.051523]\n",
      "epoch:10 step:10212 [D loss: 0.650291, acc.: 60.94%] [G loss: 0.972220]\n",
      "epoch:10 step:10213 [D loss: 0.762052, acc.: 50.00%] [G loss: 0.879909]\n",
      "epoch:10 step:10214 [D loss: 0.621596, acc.: 63.28%] [G loss: 0.832842]\n",
      "epoch:10 step:10215 [D loss: 0.611968, acc.: 68.75%] [G loss: 1.058491]\n",
      "epoch:10 step:10216 [D loss: 0.642221, acc.: 59.38%] [G loss: 0.866645]\n",
      "epoch:10 step:10217 [D loss: 0.612730, acc.: 68.75%] [G loss: 0.903013]\n",
      "epoch:10 step:10218 [D loss: 0.682914, acc.: 55.47%] [G loss: 1.031870]\n",
      "epoch:10 step:10219 [D loss: 0.692101, acc.: 53.12%] [G loss: 0.836984]\n",
      "epoch:10 step:10220 [D loss: 0.754071, acc.: 42.97%] [G loss: 0.767588]\n",
      "epoch:10 step:10221 [D loss: 0.612025, acc.: 65.62%] [G loss: 0.877361]\n",
      "epoch:10 step:10222 [D loss: 0.589860, acc.: 71.88%] [G loss: 1.034870]\n",
      "epoch:10 step:10223 [D loss: 0.649087, acc.: 61.72%] [G loss: 1.023522]\n",
      "epoch:10 step:10224 [D loss: 0.618504, acc.: 65.62%] [G loss: 0.985304]\n",
      "epoch:10 step:10225 [D loss: 0.640178, acc.: 60.94%] [G loss: 1.008119]\n",
      "epoch:10 step:10226 [D loss: 0.709248, acc.: 50.78%] [G loss: 0.791242]\n",
      "epoch:10 step:10227 [D loss: 0.640256, acc.: 70.31%] [G loss: 0.934537]\n",
      "epoch:10 step:10228 [D loss: 0.723960, acc.: 48.44%] [G loss: 0.933957]\n",
      "epoch:10 step:10229 [D loss: 0.701705, acc.: 53.91%] [G loss: 0.931466]\n",
      "epoch:10 step:10230 [D loss: 0.641024, acc.: 61.72%] [G loss: 0.804909]\n",
      "epoch:10 step:10231 [D loss: 0.759251, acc.: 47.66%] [G loss: 0.877005]\n",
      "epoch:10 step:10232 [D loss: 0.662191, acc.: 59.38%] [G loss: 0.875904]\n",
      "epoch:10 step:10233 [D loss: 0.692707, acc.: 55.47%] [G loss: 0.993392]\n",
      "epoch:10 step:10234 [D loss: 0.735630, acc.: 46.88%] [G loss: 0.831870]\n",
      "epoch:10 step:10235 [D loss: 0.736065, acc.: 50.78%] [G loss: 0.936400]\n",
      "epoch:10 step:10236 [D loss: 0.779863, acc.: 44.53%] [G loss: 0.956561]\n",
      "epoch:10 step:10237 [D loss: 0.702483, acc.: 55.47%] [G loss: 0.828947]\n",
      "epoch:10 step:10238 [D loss: 0.647747, acc.: 62.50%] [G loss: 0.813896]\n",
      "epoch:10 step:10239 [D loss: 0.752663, acc.: 45.31%] [G loss: 0.817759]\n",
      "epoch:10 step:10240 [D loss: 0.661893, acc.: 51.56%] [G loss: 0.979708]\n",
      "epoch:10 step:10241 [D loss: 0.676892, acc.: 55.47%] [G loss: 0.922105]\n",
      "epoch:10 step:10242 [D loss: 0.656903, acc.: 57.81%] [G loss: 0.940558]\n",
      "epoch:10 step:10243 [D loss: 0.656009, acc.: 58.59%] [G loss: 0.958758]\n",
      "epoch:10 step:10244 [D loss: 0.637914, acc.: 65.62%] [G loss: 1.028355]\n",
      "epoch:10 step:10245 [D loss: 0.609276, acc.: 65.62%] [G loss: 0.910876]\n",
      "epoch:10 step:10246 [D loss: 0.647976, acc.: 60.94%] [G loss: 0.917680]\n",
      "epoch:10 step:10247 [D loss: 0.612961, acc.: 65.62%] [G loss: 1.001999]\n",
      "epoch:10 step:10248 [D loss: 0.644785, acc.: 64.06%] [G loss: 0.926475]\n",
      "epoch:10 step:10249 [D loss: 0.631693, acc.: 64.84%] [G loss: 0.904234]\n",
      "epoch:10 step:10250 [D loss: 0.689162, acc.: 58.59%] [G loss: 0.984810]\n",
      "epoch:10 step:10251 [D loss: 0.709830, acc.: 52.34%] [G loss: 0.974486]\n",
      "epoch:10 step:10252 [D loss: 0.624010, acc.: 71.88%] [G loss: 0.912610]\n",
      "epoch:10 step:10253 [D loss: 0.646034, acc.: 60.16%] [G loss: 0.865814]\n",
      "epoch:10 step:10254 [D loss: 0.637450, acc.: 61.72%] [G loss: 0.874736]\n",
      "epoch:10 step:10255 [D loss: 0.676334, acc.: 57.81%] [G loss: 0.967644]\n",
      "epoch:10 step:10256 [D loss: 0.688057, acc.: 59.38%] [G loss: 1.015045]\n",
      "epoch:10 step:10257 [D loss: 0.678567, acc.: 59.38%] [G loss: 0.938593]\n",
      "epoch:10 step:10258 [D loss: 0.622458, acc.: 66.41%] [G loss: 1.091849]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:10259 [D loss: 0.589484, acc.: 67.97%] [G loss: 1.060912]\n",
      "epoch:10 step:10260 [D loss: 0.566137, acc.: 72.66%] [G loss: 0.957465]\n",
      "epoch:10 step:10261 [D loss: 0.714858, acc.: 58.59%] [G loss: 0.856793]\n",
      "epoch:10 step:10262 [D loss: 0.755494, acc.: 47.66%] [G loss: 0.812259]\n",
      "epoch:10 step:10263 [D loss: 0.691010, acc.: 57.03%] [G loss: 0.957205]\n",
      "epoch:10 step:10264 [D loss: 0.606461, acc.: 65.62%] [G loss: 0.882349]\n",
      "epoch:10 step:10265 [D loss: 0.668056, acc.: 64.84%] [G loss: 0.915145]\n",
      "epoch:10 step:10266 [D loss: 0.707082, acc.: 57.81%] [G loss: 0.812379]\n",
      "epoch:10 step:10267 [D loss: 0.636260, acc.: 63.28%] [G loss: 0.985428]\n",
      "epoch:10 step:10268 [D loss: 0.618790, acc.: 65.62%] [G loss: 1.045283]\n",
      "epoch:10 step:10269 [D loss: 0.601333, acc.: 67.97%] [G loss: 1.005131]\n",
      "epoch:10 step:10270 [D loss: 0.583573, acc.: 68.75%] [G loss: 1.062419]\n",
      "epoch:10 step:10271 [D loss: 0.604294, acc.: 65.62%] [G loss: 0.974060]\n",
      "epoch:10 step:10272 [D loss: 0.699153, acc.: 53.91%] [G loss: 0.858866]\n",
      "epoch:10 step:10273 [D loss: 0.732065, acc.: 54.69%] [G loss: 0.892440]\n",
      "epoch:10 step:10274 [D loss: 0.683682, acc.: 56.25%] [G loss: 1.036021]\n",
      "epoch:10 step:10275 [D loss: 0.626095, acc.: 60.94%] [G loss: 0.902532]\n",
      "epoch:10 step:10276 [D loss: 0.631569, acc.: 61.72%] [G loss: 1.012635]\n",
      "epoch:10 step:10277 [D loss: 0.682135, acc.: 56.25%] [G loss: 0.918135]\n",
      "epoch:10 step:10278 [D loss: 0.674715, acc.: 59.38%] [G loss: 0.998218]\n",
      "epoch:10 step:10279 [D loss: 0.506117, acc.: 82.03%] [G loss: 0.983940]\n",
      "epoch:10 step:10280 [D loss: 0.546987, acc.: 71.88%] [G loss: 1.037755]\n",
      "epoch:10 step:10281 [D loss: 0.481880, acc.: 88.28%] [G loss: 1.185554]\n",
      "epoch:10 step:10282 [D loss: 0.567306, acc.: 71.88%] [G loss: 0.959217]\n",
      "epoch:10 step:10283 [D loss: 0.719197, acc.: 53.12%] [G loss: 1.103593]\n",
      "epoch:10 step:10284 [D loss: 0.705383, acc.: 55.47%] [G loss: 0.885854]\n",
      "epoch:10 step:10285 [D loss: 0.709528, acc.: 55.47%] [G loss: 0.987945]\n",
      "epoch:10 step:10286 [D loss: 0.652448, acc.: 60.94%] [G loss: 0.819106]\n",
      "epoch:10 step:10287 [D loss: 0.657013, acc.: 60.94%] [G loss: 1.012117]\n",
      "epoch:10 step:10288 [D loss: 0.625962, acc.: 64.06%] [G loss: 1.006997]\n",
      "epoch:10 step:10289 [D loss: 0.636582, acc.: 60.94%] [G loss: 0.922527]\n",
      "epoch:10 step:10290 [D loss: 0.848285, acc.: 41.41%] [G loss: 0.990935]\n",
      "epoch:10 step:10291 [D loss: 0.726167, acc.: 56.25%] [G loss: 0.808292]\n",
      "epoch:10 step:10292 [D loss: 0.618113, acc.: 66.41%] [G loss: 0.976221]\n",
      "epoch:10 step:10293 [D loss: 0.521079, acc.: 76.56%] [G loss: 1.011765]\n",
      "epoch:10 step:10294 [D loss: 0.510783, acc.: 78.12%] [G loss: 1.080876]\n",
      "epoch:10 step:10295 [D loss: 0.607996, acc.: 72.66%] [G loss: 0.900017]\n",
      "epoch:10 step:10296 [D loss: 0.595668, acc.: 69.53%] [G loss: 0.977578]\n",
      "epoch:10 step:10297 [D loss: 0.530608, acc.: 80.47%] [G loss: 0.890009]\n",
      "epoch:10 step:10298 [D loss: 0.810244, acc.: 42.19%] [G loss: 0.926407]\n",
      "epoch:10 step:10299 [D loss: 0.759084, acc.: 46.09%] [G loss: 1.071083]\n",
      "epoch:10 step:10300 [D loss: 0.659334, acc.: 60.94%] [G loss: 0.882208]\n",
      "epoch:10 step:10301 [D loss: 0.651245, acc.: 64.84%] [G loss: 0.871706]\n",
      "epoch:10 step:10302 [D loss: 0.610833, acc.: 66.41%] [G loss: 0.887245]\n",
      "epoch:10 step:10303 [D loss: 0.632323, acc.: 67.19%] [G loss: 0.863260]\n",
      "epoch:10 step:10304 [D loss: 0.557607, acc.: 70.31%] [G loss: 0.891557]\n",
      "epoch:10 step:10305 [D loss: 0.632229, acc.: 63.28%] [G loss: 0.856970]\n",
      "epoch:10 step:10306 [D loss: 0.639955, acc.: 68.75%] [G loss: 1.102452]\n",
      "epoch:10 step:10307 [D loss: 0.423737, acc.: 87.50%] [G loss: 1.037228]\n",
      "epoch:11 step:10308 [D loss: 0.656010, acc.: 63.28%] [G loss: 1.161811]\n",
      "epoch:11 step:10309 [D loss: 0.676899, acc.: 60.94%] [G loss: 1.098262]\n",
      "epoch:11 step:10310 [D loss: 0.653756, acc.: 60.16%] [G loss: 1.112753]\n",
      "epoch:11 step:10311 [D loss: 0.594495, acc.: 69.53%] [G loss: 0.956440]\n",
      "epoch:11 step:10312 [D loss: 0.692036, acc.: 53.12%] [G loss: 0.917392]\n",
      "epoch:11 step:10313 [D loss: 0.676768, acc.: 55.47%] [G loss: 0.905835]\n",
      "epoch:11 step:10314 [D loss: 0.600316, acc.: 71.88%] [G loss: 0.953538]\n",
      "epoch:11 step:10315 [D loss: 0.627112, acc.: 65.62%] [G loss: 0.970997]\n",
      "epoch:11 step:10316 [D loss: 0.532594, acc.: 82.03%] [G loss: 1.152138]\n",
      "epoch:11 step:10317 [D loss: 0.614457, acc.: 64.84%] [G loss: 1.059145]\n",
      "epoch:11 step:10318 [D loss: 0.677539, acc.: 64.84%] [G loss: 0.908817]\n",
      "epoch:11 step:10319 [D loss: 0.719778, acc.: 53.91%] [G loss: 0.977499]\n",
      "epoch:11 step:10320 [D loss: 0.611262, acc.: 66.41%] [G loss: 0.972353]\n",
      "epoch:11 step:10321 [D loss: 0.717957, acc.: 52.34%] [G loss: 1.045939]\n",
      "epoch:11 step:10322 [D loss: 0.552651, acc.: 73.44%] [G loss: 1.122715]\n",
      "epoch:11 step:10323 [D loss: 0.567306, acc.: 71.88%] [G loss: 1.051169]\n",
      "epoch:11 step:10324 [D loss: 0.731853, acc.: 53.91%] [G loss: 0.902761]\n",
      "epoch:11 step:10325 [D loss: 0.844323, acc.: 37.50%] [G loss: 0.903593]\n",
      "epoch:11 step:10326 [D loss: 0.712612, acc.: 51.56%] [G loss: 1.020097]\n",
      "epoch:11 step:10327 [D loss: 0.861576, acc.: 32.03%] [G loss: 0.962801]\n",
      "epoch:11 step:10328 [D loss: 0.701827, acc.: 51.56%] [G loss: 1.077730]\n",
      "epoch:11 step:10329 [D loss: 0.649527, acc.: 64.06%] [G loss: 1.083348]\n",
      "epoch:11 step:10330 [D loss: 0.723853, acc.: 56.25%] [G loss: 0.825351]\n",
      "epoch:11 step:10331 [D loss: 0.699741, acc.: 53.91%] [G loss: 0.936352]\n",
      "epoch:11 step:10332 [D loss: 0.674160, acc.: 59.38%] [G loss: 0.880200]\n",
      "epoch:11 step:10333 [D loss: 0.634993, acc.: 62.50%] [G loss: 0.985652]\n",
      "epoch:11 step:10334 [D loss: 0.763705, acc.: 50.78%] [G loss: 0.944101]\n",
      "epoch:11 step:10335 [D loss: 0.714221, acc.: 54.69%] [G loss: 0.934502]\n",
      "epoch:11 step:10336 [D loss: 0.580908, acc.: 71.09%] [G loss: 1.050001]\n",
      "epoch:11 step:10337 [D loss: 0.658116, acc.: 60.16%] [G loss: 0.978143]\n",
      "epoch:11 step:10338 [D loss: 0.584834, acc.: 69.53%] [G loss: 0.878517]\n",
      "epoch:11 step:10339 [D loss: 0.598502, acc.: 68.75%] [G loss: 1.187193]\n",
      "epoch:11 step:10340 [D loss: 0.624104, acc.: 61.72%] [G loss: 0.948611]\n",
      "epoch:11 step:10341 [D loss: 0.641673, acc.: 65.62%] [G loss: 1.052625]\n",
      "epoch:11 step:10342 [D loss: 0.587564, acc.: 74.22%] [G loss: 0.986412]\n",
      "epoch:11 step:10343 [D loss: 0.523431, acc.: 76.56%] [G loss: 1.093306]\n",
      "epoch:11 step:10344 [D loss: 0.553447, acc.: 69.53%] [G loss: 1.048728]\n",
      "epoch:11 step:10345 [D loss: 0.717948, acc.: 53.91%] [G loss: 1.068765]\n",
      "epoch:11 step:10346 [D loss: 0.722935, acc.: 49.22%] [G loss: 0.951823]\n",
      "epoch:11 step:10347 [D loss: 0.597469, acc.: 68.75%] [G loss: 0.891946]\n",
      "epoch:11 step:10348 [D loss: 0.651016, acc.: 62.50%] [G loss: 1.109742]\n",
      "epoch:11 step:10349 [D loss: 0.590165, acc.: 71.09%] [G loss: 0.920292]\n",
      "epoch:11 step:10350 [D loss: 0.623719, acc.: 65.62%] [G loss: 1.048683]\n",
      "epoch:11 step:10351 [D loss: 0.647571, acc.: 62.50%] [G loss: 0.828124]\n",
      "epoch:11 step:10352 [D loss: 0.638986, acc.: 65.62%] [G loss: 1.147190]\n",
      "epoch:11 step:10353 [D loss: 0.692595, acc.: 57.81%] [G loss: 1.047378]\n",
      "epoch:11 step:10354 [D loss: 0.619990, acc.: 65.62%] [G loss: 0.948700]\n",
      "epoch:11 step:10355 [D loss: 0.605696, acc.: 67.97%] [G loss: 1.061488]\n",
      "epoch:11 step:10356 [D loss: 0.658426, acc.: 60.16%] [G loss: 0.993875]\n",
      "epoch:11 step:10357 [D loss: 0.600558, acc.: 70.31%] [G loss: 1.013026]\n",
      "epoch:11 step:10358 [D loss: 0.663579, acc.: 57.81%] [G loss: 1.019895]\n",
      "epoch:11 step:10359 [D loss: 0.642077, acc.: 64.84%] [G loss: 0.837901]\n",
      "epoch:11 step:10360 [D loss: 0.619404, acc.: 62.50%] [G loss: 0.906895]\n",
      "epoch:11 step:10361 [D loss: 0.605159, acc.: 67.19%] [G loss: 1.180412]\n",
      "epoch:11 step:10362 [D loss: 0.595762, acc.: 71.09%] [G loss: 0.957767]\n",
      "epoch:11 step:10363 [D loss: 0.659813, acc.: 63.28%] [G loss: 0.945167]\n",
      "epoch:11 step:10364 [D loss: 0.654594, acc.: 61.72%] [G loss: 1.051478]\n",
      "epoch:11 step:10365 [D loss: 0.609940, acc.: 67.19%] [G loss: 0.939701]\n",
      "epoch:11 step:10366 [D loss: 0.716307, acc.: 54.69%] [G loss: 0.893798]\n",
      "epoch:11 step:10367 [D loss: 0.656585, acc.: 59.38%] [G loss: 0.989617]\n",
      "epoch:11 step:10368 [D loss: 0.650699, acc.: 60.94%] [G loss: 1.032606]\n",
      "epoch:11 step:10369 [D loss: 0.688493, acc.: 58.59%] [G loss: 0.978467]\n",
      "epoch:11 step:10370 [D loss: 0.634627, acc.: 60.94%] [G loss: 0.954186]\n",
      "epoch:11 step:10371 [D loss: 0.685033, acc.: 53.91%] [G loss: 0.985699]\n",
      "epoch:11 step:10372 [D loss: 0.664622, acc.: 60.16%] [G loss: 0.892829]\n",
      "epoch:11 step:10373 [D loss: 0.650565, acc.: 62.50%] [G loss: 0.848431]\n",
      "epoch:11 step:10374 [D loss: 0.728213, acc.: 46.88%] [G loss: 0.959329]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10375 [D loss: 0.713057, acc.: 54.69%] [G loss: 0.915240]\n",
      "epoch:11 step:10376 [D loss: 0.614617, acc.: 62.50%] [G loss: 0.923119]\n",
      "epoch:11 step:10377 [D loss: 0.639307, acc.: 63.28%] [G loss: 0.886872]\n",
      "epoch:11 step:10378 [D loss: 0.565693, acc.: 75.78%] [G loss: 0.992120]\n",
      "epoch:11 step:10379 [D loss: 0.624316, acc.: 71.09%] [G loss: 0.955372]\n",
      "epoch:11 step:10380 [D loss: 0.619190, acc.: 68.75%] [G loss: 0.906207]\n",
      "epoch:11 step:10381 [D loss: 0.629638, acc.: 64.06%] [G loss: 0.873997]\n",
      "epoch:11 step:10382 [D loss: 0.587846, acc.: 71.88%] [G loss: 0.961655]\n",
      "epoch:11 step:10383 [D loss: 0.509686, acc.: 78.12%] [G loss: 1.027091]\n",
      "epoch:11 step:10384 [D loss: 0.565833, acc.: 77.34%] [G loss: 1.132834]\n",
      "epoch:11 step:10385 [D loss: 0.767938, acc.: 51.56%] [G loss: 0.939927]\n",
      "epoch:11 step:10386 [D loss: 0.753597, acc.: 53.12%] [G loss: 0.973781]\n",
      "epoch:11 step:10387 [D loss: 0.718975, acc.: 51.56%] [G loss: 0.904214]\n",
      "epoch:11 step:10388 [D loss: 0.777691, acc.: 46.09%] [G loss: 0.924832]\n",
      "epoch:11 step:10389 [D loss: 0.645625, acc.: 64.06%] [G loss: 0.933419]\n",
      "epoch:11 step:10390 [D loss: 0.661306, acc.: 57.03%] [G loss: 0.928885]\n",
      "epoch:11 step:10391 [D loss: 0.659891, acc.: 62.50%] [G loss: 0.949919]\n",
      "epoch:11 step:10392 [D loss: 0.625808, acc.: 65.62%] [G loss: 0.943788]\n",
      "epoch:11 step:10393 [D loss: 0.702747, acc.: 56.25%] [G loss: 0.864630]\n",
      "epoch:11 step:10394 [D loss: 0.670947, acc.: 60.16%] [G loss: 0.959627]\n",
      "epoch:11 step:10395 [D loss: 0.668539, acc.: 60.94%] [G loss: 0.959854]\n",
      "epoch:11 step:10396 [D loss: 0.642552, acc.: 62.50%] [G loss: 0.837148]\n",
      "epoch:11 step:10397 [D loss: 0.679731, acc.: 56.25%] [G loss: 0.936745]\n",
      "epoch:11 step:10398 [D loss: 0.738063, acc.: 49.22%] [G loss: 0.947828]\n",
      "epoch:11 step:10399 [D loss: 0.631164, acc.: 67.97%] [G loss: 1.018328]\n",
      "epoch:11 step:10400 [D loss: 0.585169, acc.: 71.09%] [G loss: 0.939654]\n",
      "##############\n",
      "[2.0876487  1.59065559 5.25987837 4.14810784 3.04468642 5.17914504\n",
      " 3.93596344 4.62552101 3.52671695 3.29014739]\n",
      "##########\n",
      "epoch:11 step:10401 [D loss: 0.650558, acc.: 64.06%] [G loss: 1.005547]\n",
      "epoch:11 step:10402 [D loss: 0.625921, acc.: 67.19%] [G loss: 1.089002]\n",
      "epoch:11 step:10403 [D loss: 0.590683, acc.: 64.06%] [G loss: 0.986469]\n",
      "epoch:11 step:10404 [D loss: 0.597631, acc.: 68.75%] [G loss: 0.903782]\n",
      "epoch:11 step:10405 [D loss: 0.632635, acc.: 64.84%] [G loss: 0.901912]\n",
      "epoch:11 step:10406 [D loss: 0.683877, acc.: 60.94%] [G loss: 1.052888]\n",
      "epoch:11 step:10407 [D loss: 0.622079, acc.: 60.16%] [G loss: 1.046640]\n",
      "epoch:11 step:10408 [D loss: 0.647433, acc.: 60.94%] [G loss: 0.997854]\n",
      "epoch:11 step:10409 [D loss: 0.691277, acc.: 55.47%] [G loss: 0.948968]\n",
      "epoch:11 step:10410 [D loss: 0.609573, acc.: 68.75%] [G loss: 1.062267]\n",
      "epoch:11 step:10411 [D loss: 0.616184, acc.: 66.41%] [G loss: 1.022877]\n",
      "epoch:11 step:10412 [D loss: 0.732117, acc.: 51.56%] [G loss: 0.959852]\n",
      "epoch:11 step:10413 [D loss: 0.744099, acc.: 48.44%] [G loss: 0.903520]\n",
      "epoch:11 step:10414 [D loss: 0.624441, acc.: 64.84%] [G loss: 0.957291]\n",
      "epoch:11 step:10415 [D loss: 0.726600, acc.: 50.78%] [G loss: 0.848582]\n",
      "epoch:11 step:10416 [D loss: 0.748298, acc.: 43.75%] [G loss: 0.820911]\n",
      "epoch:11 step:10417 [D loss: 0.774951, acc.: 46.88%] [G loss: 0.833351]\n",
      "epoch:11 step:10418 [D loss: 0.636545, acc.: 63.28%] [G loss: 0.964908]\n",
      "epoch:11 step:10419 [D loss: 0.652569, acc.: 64.06%] [G loss: 0.842710]\n",
      "epoch:11 step:10420 [D loss: 0.649131, acc.: 63.28%] [G loss: 1.061879]\n",
      "epoch:11 step:10421 [D loss: 0.648685, acc.: 67.19%] [G loss: 0.954736]\n",
      "epoch:11 step:10422 [D loss: 0.664127, acc.: 64.06%] [G loss: 0.959320]\n",
      "epoch:11 step:10423 [D loss: 0.704802, acc.: 53.91%] [G loss: 0.923992]\n",
      "epoch:11 step:10424 [D loss: 0.654180, acc.: 59.38%] [G loss: 1.075512]\n",
      "epoch:11 step:10425 [D loss: 0.630037, acc.: 66.41%] [G loss: 1.003579]\n",
      "epoch:11 step:10426 [D loss: 0.616998, acc.: 65.62%] [G loss: 1.107449]\n",
      "epoch:11 step:10427 [D loss: 0.771983, acc.: 50.78%] [G loss: 0.948754]\n",
      "epoch:11 step:10428 [D loss: 0.642012, acc.: 61.72%] [G loss: 0.865239]\n",
      "epoch:11 step:10429 [D loss: 0.621367, acc.: 69.53%] [G loss: 0.863949]\n",
      "epoch:11 step:10430 [D loss: 0.597632, acc.: 64.84%] [G loss: 1.050650]\n",
      "epoch:11 step:10431 [D loss: 0.618579, acc.: 64.06%] [G loss: 1.032247]\n",
      "epoch:11 step:10432 [D loss: 0.712735, acc.: 57.03%] [G loss: 0.799643]\n",
      "epoch:11 step:10433 [D loss: 0.633971, acc.: 60.16%] [G loss: 0.988075]\n",
      "epoch:11 step:10434 [D loss: 0.673516, acc.: 54.69%] [G loss: 0.900259]\n",
      "epoch:11 step:10435 [D loss: 0.681750, acc.: 55.47%] [G loss: 0.871209]\n",
      "epoch:11 step:10436 [D loss: 0.763014, acc.: 44.53%] [G loss: 0.926257]\n",
      "epoch:11 step:10437 [D loss: 0.565582, acc.: 68.75%] [G loss: 0.969999]\n",
      "epoch:11 step:10438 [D loss: 0.606059, acc.: 66.41%] [G loss: 0.948507]\n",
      "epoch:11 step:10439 [D loss: 0.664280, acc.: 59.38%] [G loss: 1.045938]\n",
      "epoch:11 step:10440 [D loss: 0.750853, acc.: 46.88%] [G loss: 0.924321]\n",
      "epoch:11 step:10441 [D loss: 0.678403, acc.: 60.94%] [G loss: 0.934406]\n",
      "epoch:11 step:10442 [D loss: 0.694282, acc.: 56.25%] [G loss: 0.957872]\n",
      "epoch:11 step:10443 [D loss: 0.676929, acc.: 58.59%] [G loss: 0.994653]\n",
      "epoch:11 step:10444 [D loss: 0.702440, acc.: 57.03%] [G loss: 0.831199]\n",
      "epoch:11 step:10445 [D loss: 0.730719, acc.: 47.66%] [G loss: 0.885115]\n",
      "epoch:11 step:10446 [D loss: 0.632672, acc.: 61.72%] [G loss: 0.878664]\n",
      "epoch:11 step:10447 [D loss: 0.714876, acc.: 53.91%] [G loss: 0.938747]\n",
      "epoch:11 step:10448 [D loss: 0.631240, acc.: 64.84%] [G loss: 0.947899]\n",
      "epoch:11 step:10449 [D loss: 0.653632, acc.: 60.94%] [G loss: 0.982730]\n",
      "epoch:11 step:10450 [D loss: 0.628247, acc.: 67.19%] [G loss: 0.976204]\n",
      "epoch:11 step:10451 [D loss: 0.604999, acc.: 64.84%] [G loss: 1.021249]\n",
      "epoch:11 step:10452 [D loss: 0.632221, acc.: 64.84%] [G loss: 1.058398]\n",
      "epoch:11 step:10453 [D loss: 0.675977, acc.: 59.38%] [G loss: 1.023366]\n",
      "epoch:11 step:10454 [D loss: 0.653290, acc.: 59.38%] [G loss: 0.863227]\n",
      "epoch:11 step:10455 [D loss: 0.621249, acc.: 64.84%] [G loss: 1.071873]\n",
      "epoch:11 step:10456 [D loss: 0.600781, acc.: 71.88%] [G loss: 0.916994]\n",
      "epoch:11 step:10457 [D loss: 0.639312, acc.: 65.62%] [G loss: 0.928886]\n",
      "epoch:11 step:10458 [D loss: 0.638157, acc.: 66.41%] [G loss: 0.901748]\n",
      "epoch:11 step:10459 [D loss: 0.556012, acc.: 76.56%] [G loss: 1.015063]\n",
      "epoch:11 step:10460 [D loss: 0.621551, acc.: 64.84%] [G loss: 0.975042]\n",
      "epoch:11 step:10461 [D loss: 0.674103, acc.: 54.69%] [G loss: 0.973668]\n",
      "epoch:11 step:10462 [D loss: 0.670708, acc.: 59.38%] [G loss: 0.891446]\n",
      "epoch:11 step:10463 [D loss: 0.667124, acc.: 57.81%] [G loss: 0.915415]\n",
      "epoch:11 step:10464 [D loss: 0.726314, acc.: 53.12%] [G loss: 0.895733]\n",
      "epoch:11 step:10465 [D loss: 0.688556, acc.: 57.81%] [G loss: 0.925437]\n",
      "epoch:11 step:10466 [D loss: 0.747742, acc.: 46.09%] [G loss: 0.957589]\n",
      "epoch:11 step:10467 [D loss: 0.687806, acc.: 57.03%] [G loss: 0.840027]\n",
      "epoch:11 step:10468 [D loss: 0.694865, acc.: 55.47%] [G loss: 0.865224]\n",
      "epoch:11 step:10469 [D loss: 0.634374, acc.: 65.62%] [G loss: 0.790715]\n",
      "epoch:11 step:10470 [D loss: 0.660712, acc.: 57.81%] [G loss: 0.790982]\n",
      "epoch:11 step:10471 [D loss: 0.732571, acc.: 50.00%] [G loss: 0.778452]\n",
      "epoch:11 step:10472 [D loss: 0.680060, acc.: 49.22%] [G loss: 0.933496]\n",
      "epoch:11 step:10473 [D loss: 0.677723, acc.: 60.16%] [G loss: 0.906010]\n",
      "epoch:11 step:10474 [D loss: 0.746163, acc.: 49.22%] [G loss: 0.877439]\n",
      "epoch:11 step:10475 [D loss: 0.647649, acc.: 63.28%] [G loss: 0.987770]\n",
      "epoch:11 step:10476 [D loss: 0.686940, acc.: 58.59%] [G loss: 0.918921]\n",
      "epoch:11 step:10477 [D loss: 0.671751, acc.: 58.59%] [G loss: 0.872275]\n",
      "epoch:11 step:10478 [D loss: 0.702091, acc.: 58.59%] [G loss: 0.999784]\n",
      "epoch:11 step:10479 [D loss: 0.615285, acc.: 64.84%] [G loss: 0.888239]\n",
      "epoch:11 step:10480 [D loss: 0.598540, acc.: 65.62%] [G loss: 0.927852]\n",
      "epoch:11 step:10481 [D loss: 0.672207, acc.: 57.81%] [G loss: 0.818913]\n",
      "epoch:11 step:10482 [D loss: 0.679928, acc.: 55.47%] [G loss: 0.860216]\n",
      "epoch:11 step:10483 [D loss: 0.686344, acc.: 57.81%] [G loss: 0.859203]\n",
      "epoch:11 step:10484 [D loss: 0.606237, acc.: 71.09%] [G loss: 0.989376]\n",
      "epoch:11 step:10485 [D loss: 0.644918, acc.: 64.06%] [G loss: 1.000758]\n",
      "epoch:11 step:10486 [D loss: 0.710035, acc.: 51.56%] [G loss: 0.944394]\n",
      "epoch:11 step:10487 [D loss: 0.697305, acc.: 54.69%] [G loss: 0.898098]\n",
      "epoch:11 step:10488 [D loss: 0.802344, acc.: 41.41%] [G loss: 0.973174]\n",
      "epoch:11 step:10489 [D loss: 0.666433, acc.: 60.94%] [G loss: 1.051380]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10490 [D loss: 0.629552, acc.: 66.41%] [G loss: 0.953029]\n",
      "epoch:11 step:10491 [D loss: 0.631679, acc.: 59.38%] [G loss: 1.057585]\n",
      "epoch:11 step:10492 [D loss: 0.705333, acc.: 55.47%] [G loss: 0.820079]\n",
      "epoch:11 step:10493 [D loss: 0.658814, acc.: 60.16%] [G loss: 0.841225]\n",
      "epoch:11 step:10494 [D loss: 0.635547, acc.: 66.41%] [G loss: 0.917990]\n",
      "epoch:11 step:10495 [D loss: 0.710100, acc.: 51.56%] [G loss: 0.847502]\n",
      "epoch:11 step:10496 [D loss: 0.689144, acc.: 57.03%] [G loss: 0.903581]\n",
      "epoch:11 step:10497 [D loss: 0.593923, acc.: 71.09%] [G loss: 0.885014]\n",
      "epoch:11 step:10498 [D loss: 0.654478, acc.: 61.72%] [G loss: 0.945998]\n",
      "epoch:11 step:10499 [D loss: 0.574706, acc.: 69.53%] [G loss: 0.872381]\n",
      "epoch:11 step:10500 [D loss: 0.719298, acc.: 52.34%] [G loss: 0.998096]\n",
      "epoch:11 step:10501 [D loss: 0.627416, acc.: 66.41%] [G loss: 0.895810]\n",
      "epoch:11 step:10502 [D loss: 0.672034, acc.: 59.38%] [G loss: 1.097624]\n",
      "epoch:11 step:10503 [D loss: 0.640243, acc.: 62.50%] [G loss: 0.920824]\n",
      "epoch:11 step:10504 [D loss: 0.555446, acc.: 74.22%] [G loss: 1.101107]\n",
      "epoch:11 step:10505 [D loss: 0.651518, acc.: 64.06%] [G loss: 0.939159]\n",
      "epoch:11 step:10506 [D loss: 0.721011, acc.: 49.22%] [G loss: 0.928636]\n",
      "epoch:11 step:10507 [D loss: 0.819561, acc.: 41.41%] [G loss: 0.879890]\n",
      "epoch:11 step:10508 [D loss: 0.695425, acc.: 54.69%] [G loss: 1.014351]\n",
      "epoch:11 step:10509 [D loss: 0.697764, acc.: 57.03%] [G loss: 0.907696]\n",
      "epoch:11 step:10510 [D loss: 0.698437, acc.: 56.25%] [G loss: 0.876776]\n",
      "epoch:11 step:10511 [D loss: 0.626753, acc.: 59.38%] [G loss: 0.758358]\n",
      "epoch:11 step:10512 [D loss: 0.662850, acc.: 60.94%] [G loss: 0.967897]\n",
      "epoch:11 step:10513 [D loss: 0.621148, acc.: 67.97%] [G loss: 0.922592]\n",
      "epoch:11 step:10514 [D loss: 0.594664, acc.: 68.75%] [G loss: 0.873835]\n",
      "epoch:11 step:10515 [D loss: 0.694414, acc.: 58.59%] [G loss: 1.034680]\n",
      "epoch:11 step:10516 [D loss: 0.566984, acc.: 73.44%] [G loss: 0.996452]\n",
      "epoch:11 step:10517 [D loss: 0.749193, acc.: 47.66%] [G loss: 0.973194]\n",
      "epoch:11 step:10518 [D loss: 0.734567, acc.: 52.34%] [G loss: 1.087175]\n",
      "epoch:11 step:10519 [D loss: 0.720535, acc.: 54.69%] [G loss: 0.975366]\n",
      "epoch:11 step:10520 [D loss: 0.673253, acc.: 57.03%] [G loss: 0.986604]\n",
      "epoch:11 step:10521 [D loss: 0.714401, acc.: 48.44%] [G loss: 0.881849]\n",
      "epoch:11 step:10522 [D loss: 0.731076, acc.: 51.56%] [G loss: 0.932915]\n",
      "epoch:11 step:10523 [D loss: 0.662652, acc.: 61.72%] [G loss: 0.825861]\n",
      "epoch:11 step:10524 [D loss: 0.648524, acc.: 55.47%] [G loss: 0.912931]\n",
      "epoch:11 step:10525 [D loss: 0.578566, acc.: 71.88%] [G loss: 0.971864]\n",
      "epoch:11 step:10526 [D loss: 0.623729, acc.: 64.84%] [G loss: 0.893267]\n",
      "epoch:11 step:10527 [D loss: 0.619336, acc.: 67.97%] [G loss: 1.033455]\n",
      "epoch:11 step:10528 [D loss: 0.548690, acc.: 72.66%] [G loss: 0.919564]\n",
      "epoch:11 step:10529 [D loss: 0.635509, acc.: 71.09%] [G loss: 1.068789]\n",
      "epoch:11 step:10530 [D loss: 0.553550, acc.: 75.78%] [G loss: 1.047147]\n",
      "epoch:11 step:10531 [D loss: 0.719452, acc.: 51.56%] [G loss: 0.979393]\n",
      "epoch:11 step:10532 [D loss: 0.679655, acc.: 57.81%] [G loss: 0.967846]\n",
      "epoch:11 step:10533 [D loss: 0.642361, acc.: 63.28%] [G loss: 0.869969]\n",
      "epoch:11 step:10534 [D loss: 0.682300, acc.: 58.59%] [G loss: 0.873012]\n",
      "epoch:11 step:10535 [D loss: 0.749304, acc.: 51.56%] [G loss: 0.771248]\n",
      "epoch:11 step:10536 [D loss: 0.581564, acc.: 68.75%] [G loss: 1.112013]\n",
      "epoch:11 step:10537 [D loss: 0.464172, acc.: 83.59%] [G loss: 1.071400]\n",
      "epoch:11 step:10538 [D loss: 0.498715, acc.: 78.12%] [G loss: 1.250461]\n",
      "epoch:11 step:10539 [D loss: 0.423685, acc.: 85.94%] [G loss: 1.230914]\n",
      "epoch:11 step:10540 [D loss: 0.589242, acc.: 65.62%] [G loss: 1.266549]\n",
      "epoch:11 step:10541 [D loss: 0.697886, acc.: 59.38%] [G loss: 0.959051]\n",
      "epoch:11 step:10542 [D loss: 0.713404, acc.: 56.25%] [G loss: 0.873638]\n",
      "epoch:11 step:10543 [D loss: 0.709256, acc.: 57.81%] [G loss: 0.878087]\n",
      "epoch:11 step:10544 [D loss: 0.636404, acc.: 64.84%] [G loss: 0.931540]\n",
      "epoch:11 step:10545 [D loss: 0.683579, acc.: 57.03%] [G loss: 0.953157]\n",
      "epoch:11 step:10546 [D loss: 0.692018, acc.: 57.81%] [G loss: 0.977378]\n",
      "epoch:11 step:10547 [D loss: 0.753133, acc.: 50.00%] [G loss: 0.942247]\n",
      "epoch:11 step:10548 [D loss: 0.656548, acc.: 61.72%] [G loss: 0.909751]\n",
      "epoch:11 step:10549 [D loss: 0.708067, acc.: 52.34%] [G loss: 0.875287]\n",
      "epoch:11 step:10550 [D loss: 0.670411, acc.: 58.59%] [G loss: 0.912198]\n",
      "epoch:11 step:10551 [D loss: 0.710055, acc.: 52.34%] [G loss: 0.793858]\n",
      "epoch:11 step:10552 [D loss: 0.690994, acc.: 55.47%] [G loss: 0.947761]\n",
      "epoch:11 step:10553 [D loss: 0.711131, acc.: 52.34%] [G loss: 0.901563]\n",
      "epoch:11 step:10554 [D loss: 0.736068, acc.: 48.44%] [G loss: 1.029714]\n",
      "epoch:11 step:10555 [D loss: 0.723619, acc.: 54.69%] [G loss: 0.990228]\n",
      "epoch:11 step:10556 [D loss: 0.668055, acc.: 57.81%] [G loss: 0.851140]\n",
      "epoch:11 step:10557 [D loss: 0.694744, acc.: 55.47%] [G loss: 0.787651]\n",
      "epoch:11 step:10558 [D loss: 0.651544, acc.: 64.84%] [G loss: 0.882185]\n",
      "epoch:11 step:10559 [D loss: 0.654559, acc.: 62.50%] [G loss: 0.831753]\n",
      "epoch:11 step:10560 [D loss: 0.615747, acc.: 64.06%] [G loss: 0.965273]\n",
      "epoch:11 step:10561 [D loss: 0.634404, acc.: 63.28%] [G loss: 0.897513]\n",
      "epoch:11 step:10562 [D loss: 0.618491, acc.: 69.53%] [G loss: 0.934803]\n",
      "epoch:11 step:10563 [D loss: 0.649985, acc.: 63.28%] [G loss: 0.976781]\n",
      "epoch:11 step:10564 [D loss: 0.664901, acc.: 58.59%] [G loss: 1.021560]\n",
      "epoch:11 step:10565 [D loss: 0.686235, acc.: 57.81%] [G loss: 1.050292]\n",
      "epoch:11 step:10566 [D loss: 0.616985, acc.: 66.41%] [G loss: 0.923738]\n",
      "epoch:11 step:10567 [D loss: 0.664659, acc.: 60.94%] [G loss: 1.037094]\n",
      "epoch:11 step:10568 [D loss: 0.624499, acc.: 65.62%] [G loss: 0.938425]\n",
      "epoch:11 step:10569 [D loss: 0.604985, acc.: 67.19%] [G loss: 1.037953]\n",
      "epoch:11 step:10570 [D loss: 0.709310, acc.: 55.47%] [G loss: 0.875393]\n",
      "epoch:11 step:10571 [D loss: 0.678263, acc.: 58.59%] [G loss: 0.846032]\n",
      "epoch:11 step:10572 [D loss: 0.630183, acc.: 64.84%] [G loss: 0.961917]\n",
      "epoch:11 step:10573 [D loss: 0.617422, acc.: 71.09%] [G loss: 0.955626]\n",
      "epoch:11 step:10574 [D loss: 0.605959, acc.: 69.53%] [G loss: 0.958003]\n",
      "epoch:11 step:10575 [D loss: 0.689535, acc.: 54.69%] [G loss: 0.981637]\n",
      "epoch:11 step:10576 [D loss: 0.611232, acc.: 65.62%] [G loss: 0.986047]\n",
      "epoch:11 step:10577 [D loss: 0.693839, acc.: 57.03%] [G loss: 0.944841]\n",
      "epoch:11 step:10578 [D loss: 0.656840, acc.: 60.16%] [G loss: 0.974499]\n",
      "epoch:11 step:10579 [D loss: 0.560114, acc.: 71.09%] [G loss: 0.943486]\n",
      "epoch:11 step:10580 [D loss: 0.614911, acc.: 65.62%] [G loss: 0.911172]\n",
      "epoch:11 step:10581 [D loss: 0.606969, acc.: 67.97%] [G loss: 0.920273]\n",
      "epoch:11 step:10582 [D loss: 0.698237, acc.: 53.91%] [G loss: 1.011112]\n",
      "epoch:11 step:10583 [D loss: 0.750579, acc.: 50.78%] [G loss: 0.994216]\n",
      "epoch:11 step:10584 [D loss: 0.656175, acc.: 60.94%] [G loss: 0.902538]\n",
      "epoch:11 step:10585 [D loss: 0.633402, acc.: 69.53%] [G loss: 0.985637]\n",
      "epoch:11 step:10586 [D loss: 0.686919, acc.: 55.47%] [G loss: 0.855467]\n",
      "epoch:11 step:10587 [D loss: 0.601441, acc.: 71.09%] [G loss: 0.898748]\n",
      "epoch:11 step:10588 [D loss: 0.606429, acc.: 71.09%] [G loss: 0.866933]\n",
      "epoch:11 step:10589 [D loss: 0.633010, acc.: 63.28%] [G loss: 0.978278]\n",
      "epoch:11 step:10590 [D loss: 0.633558, acc.: 68.75%] [G loss: 0.998307]\n",
      "epoch:11 step:10591 [D loss: 0.661049, acc.: 59.38%] [G loss: 0.802045]\n",
      "epoch:11 step:10592 [D loss: 0.626631, acc.: 63.28%] [G loss: 0.864826]\n",
      "epoch:11 step:10593 [D loss: 0.639463, acc.: 60.16%] [G loss: 0.989059]\n",
      "epoch:11 step:10594 [D loss: 0.690918, acc.: 57.03%] [G loss: 0.976643]\n",
      "epoch:11 step:10595 [D loss: 0.688712, acc.: 55.47%] [G loss: 0.950784]\n",
      "epoch:11 step:10596 [D loss: 0.633891, acc.: 67.19%] [G loss: 1.037081]\n",
      "epoch:11 step:10597 [D loss: 0.684259, acc.: 57.03%] [G loss: 0.900510]\n",
      "epoch:11 step:10598 [D loss: 0.703801, acc.: 57.03%] [G loss: 0.962353]\n",
      "epoch:11 step:10599 [D loss: 0.668436, acc.: 59.38%] [G loss: 0.917718]\n",
      "epoch:11 step:10600 [D loss: 0.636430, acc.: 62.50%] [G loss: 1.074281]\n",
      "##############\n",
      "[2.13219401 1.16706424 5.41402339 4.22901227 3.0211232  5.04485217\n",
      " 4.01794335 4.42481206 3.84965643 3.3482339 ]\n",
      "##########\n",
      "epoch:11 step:10601 [D loss: 0.569528, acc.: 73.44%] [G loss: 0.961258]\n",
      "epoch:11 step:10602 [D loss: 0.649000, acc.: 60.94%] [G loss: 0.913313]\n",
      "epoch:11 step:10603 [D loss: 0.596807, acc.: 66.41%] [G loss: 0.944403]\n",
      "epoch:11 step:10604 [D loss: 0.629783, acc.: 68.75%] [G loss: 0.988558]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10605 [D loss: 0.623786, acc.: 68.75%] [G loss: 0.933965]\n",
      "epoch:11 step:10606 [D loss: 0.554502, acc.: 71.88%] [G loss: 1.107822]\n",
      "epoch:11 step:10607 [D loss: 0.609607, acc.: 65.62%] [G loss: 1.015965]\n",
      "epoch:11 step:10608 [D loss: 0.682884, acc.: 60.94%] [G loss: 1.018866]\n",
      "epoch:11 step:10609 [D loss: 0.653082, acc.: 60.16%] [G loss: 0.990871]\n",
      "epoch:11 step:10610 [D loss: 0.650667, acc.: 60.16%] [G loss: 1.068042]\n",
      "epoch:11 step:10611 [D loss: 0.654931, acc.: 58.59%] [G loss: 0.948704]\n",
      "epoch:11 step:10612 [D loss: 0.624461, acc.: 63.28%] [G loss: 0.958402]\n",
      "epoch:11 step:10613 [D loss: 0.621998, acc.: 64.06%] [G loss: 0.962279]\n",
      "epoch:11 step:10614 [D loss: 0.660724, acc.: 58.59%] [G loss: 1.080798]\n",
      "epoch:11 step:10615 [D loss: 0.701290, acc.: 54.69%] [G loss: 0.870123]\n",
      "epoch:11 step:10616 [D loss: 0.612736, acc.: 64.06%] [G loss: 0.943685]\n",
      "epoch:11 step:10617 [D loss: 0.669176, acc.: 58.59%] [G loss: 0.735736]\n",
      "epoch:11 step:10618 [D loss: 0.652969, acc.: 64.84%] [G loss: 0.958476]\n",
      "epoch:11 step:10619 [D loss: 0.652660, acc.: 58.59%] [G loss: 0.938914]\n",
      "epoch:11 step:10620 [D loss: 0.630421, acc.: 64.84%] [G loss: 1.010340]\n",
      "epoch:11 step:10621 [D loss: 0.573866, acc.: 72.66%] [G loss: 1.063309]\n",
      "epoch:11 step:10622 [D loss: 0.566622, acc.: 70.31%] [G loss: 1.187648]\n",
      "epoch:11 step:10623 [D loss: 0.767024, acc.: 41.41%] [G loss: 0.965187]\n",
      "epoch:11 step:10624 [D loss: 0.698285, acc.: 59.38%] [G loss: 0.936933]\n",
      "epoch:11 step:10625 [D loss: 0.682070, acc.: 58.59%] [G loss: 0.966604]\n",
      "epoch:11 step:10626 [D loss: 0.664715, acc.: 59.38%] [G loss: 1.001789]\n",
      "epoch:11 step:10627 [D loss: 0.751791, acc.: 46.09%] [G loss: 0.844791]\n",
      "epoch:11 step:10628 [D loss: 0.679729, acc.: 60.94%] [G loss: 0.923170]\n",
      "epoch:11 step:10629 [D loss: 0.617521, acc.: 66.41%] [G loss: 0.953365]\n",
      "epoch:11 step:10630 [D loss: 0.663621, acc.: 57.81%] [G loss: 0.955412]\n",
      "epoch:11 step:10631 [D loss: 0.641542, acc.: 67.19%] [G loss: 0.987582]\n",
      "epoch:11 step:10632 [D loss: 0.729520, acc.: 51.56%] [G loss: 0.776479]\n",
      "epoch:11 step:10633 [D loss: 0.615491, acc.: 67.19%] [G loss: 0.915511]\n",
      "epoch:11 step:10634 [D loss: 0.636335, acc.: 56.25%] [G loss: 0.883262]\n",
      "epoch:11 step:10635 [D loss: 0.631309, acc.: 61.72%] [G loss: 0.967725]\n",
      "epoch:11 step:10636 [D loss: 0.661184, acc.: 56.25%] [G loss: 1.011512]\n",
      "epoch:11 step:10637 [D loss: 0.570462, acc.: 72.66%] [G loss: 0.993906]\n",
      "epoch:11 step:10638 [D loss: 0.668959, acc.: 64.06%] [G loss: 0.853916]\n",
      "epoch:11 step:10639 [D loss: 0.639942, acc.: 64.06%] [G loss: 0.860227]\n",
      "epoch:11 step:10640 [D loss: 0.654063, acc.: 60.16%] [G loss: 0.922192]\n",
      "epoch:11 step:10641 [D loss: 0.735427, acc.: 48.44%] [G loss: 0.853950]\n",
      "epoch:11 step:10642 [D loss: 0.575792, acc.: 70.31%] [G loss: 1.086448]\n",
      "epoch:11 step:10643 [D loss: 0.574683, acc.: 76.56%] [G loss: 1.067671]\n",
      "epoch:11 step:10644 [D loss: 0.622625, acc.: 67.97%] [G loss: 1.021859]\n",
      "epoch:11 step:10645 [D loss: 0.591276, acc.: 68.75%] [G loss: 0.908685]\n",
      "epoch:11 step:10646 [D loss: 0.640886, acc.: 64.84%] [G loss: 0.992293]\n",
      "epoch:11 step:10647 [D loss: 0.639106, acc.: 63.28%] [G loss: 0.915035]\n",
      "epoch:11 step:10648 [D loss: 0.659274, acc.: 64.06%] [G loss: 0.907672]\n",
      "epoch:11 step:10649 [D loss: 0.789228, acc.: 46.88%] [G loss: 0.925681]\n",
      "epoch:11 step:10650 [D loss: 0.592300, acc.: 73.44%] [G loss: 1.006682]\n",
      "epoch:11 step:10651 [D loss: 0.572719, acc.: 71.88%] [G loss: 0.943269]\n",
      "epoch:11 step:10652 [D loss: 0.686776, acc.: 60.16%] [G loss: 0.944205]\n",
      "epoch:11 step:10653 [D loss: 0.580272, acc.: 72.66%] [G loss: 1.044060]\n",
      "epoch:11 step:10654 [D loss: 0.601791, acc.: 65.62%] [G loss: 0.976646]\n",
      "epoch:11 step:10655 [D loss: 0.771836, acc.: 42.19%] [G loss: 0.953059]\n",
      "epoch:11 step:10656 [D loss: 0.687631, acc.: 57.81%] [G loss: 1.051469]\n",
      "epoch:11 step:10657 [D loss: 0.637249, acc.: 66.41%] [G loss: 0.839045]\n",
      "epoch:11 step:10658 [D loss: 0.667016, acc.: 64.06%] [G loss: 1.047082]\n",
      "epoch:11 step:10659 [D loss: 0.670424, acc.: 61.72%] [G loss: 0.791674]\n",
      "epoch:11 step:10660 [D loss: 0.691625, acc.: 53.12%] [G loss: 0.906074]\n",
      "epoch:11 step:10661 [D loss: 0.646076, acc.: 61.72%] [G loss: 0.940659]\n",
      "epoch:11 step:10662 [D loss: 0.729658, acc.: 51.56%] [G loss: 0.894236]\n",
      "epoch:11 step:10663 [D loss: 0.641013, acc.: 61.72%] [G loss: 1.006259]\n",
      "epoch:11 step:10664 [D loss: 0.665261, acc.: 59.38%] [G loss: 0.917976]\n",
      "epoch:11 step:10665 [D loss: 0.635113, acc.: 62.50%] [G loss: 0.903961]\n",
      "epoch:11 step:10666 [D loss: 0.602003, acc.: 71.09%] [G loss: 0.838706]\n",
      "epoch:11 step:10667 [D loss: 0.620849, acc.: 68.75%] [G loss: 0.943168]\n",
      "epoch:11 step:10668 [D loss: 0.615339, acc.: 69.53%] [G loss: 0.973261]\n",
      "epoch:11 step:10669 [D loss: 0.644963, acc.: 60.94%] [G loss: 0.993510]\n",
      "epoch:11 step:10670 [D loss: 0.649074, acc.: 61.72%] [G loss: 0.851660]\n",
      "epoch:11 step:10671 [D loss: 0.655483, acc.: 65.62%] [G loss: 1.037098]\n",
      "epoch:11 step:10672 [D loss: 0.682204, acc.: 59.38%] [G loss: 0.907683]\n",
      "epoch:11 step:10673 [D loss: 0.644595, acc.: 61.72%] [G loss: 0.937951]\n",
      "epoch:11 step:10674 [D loss: 0.655916, acc.: 65.62%] [G loss: 0.894263]\n",
      "epoch:11 step:10675 [D loss: 0.744613, acc.: 53.12%] [G loss: 0.926209]\n",
      "epoch:11 step:10676 [D loss: 0.624507, acc.: 67.97%] [G loss: 1.019292]\n",
      "epoch:11 step:10677 [D loss: 0.576727, acc.: 70.31%] [G loss: 1.170757]\n",
      "epoch:11 step:10678 [D loss: 0.547163, acc.: 80.47%] [G loss: 0.877093]\n",
      "epoch:11 step:10679 [D loss: 0.630029, acc.: 66.41%] [G loss: 1.039620]\n",
      "epoch:11 step:10680 [D loss: 0.715397, acc.: 50.78%] [G loss: 0.943115]\n",
      "epoch:11 step:10681 [D loss: 0.593671, acc.: 70.31%] [G loss: 0.895499]\n",
      "epoch:11 step:10682 [D loss: 0.688908, acc.: 62.50%] [G loss: 0.812489]\n",
      "epoch:11 step:10683 [D loss: 0.733077, acc.: 53.91%] [G loss: 0.944776]\n",
      "epoch:11 step:10684 [D loss: 0.672432, acc.: 56.25%] [G loss: 0.850328]\n",
      "epoch:11 step:10685 [D loss: 0.651885, acc.: 62.50%] [G loss: 0.916019]\n",
      "epoch:11 step:10686 [D loss: 0.699025, acc.: 52.34%] [G loss: 0.834226]\n",
      "epoch:11 step:10687 [D loss: 0.555110, acc.: 66.41%] [G loss: 0.972372]\n",
      "epoch:11 step:10688 [D loss: 0.555588, acc.: 71.09%] [G loss: 1.183728]\n",
      "epoch:11 step:10689 [D loss: 0.612209, acc.: 64.06%] [G loss: 1.107550]\n",
      "epoch:11 step:10690 [D loss: 0.678932, acc.: 60.16%] [G loss: 0.824753]\n",
      "epoch:11 step:10691 [D loss: 0.633006, acc.: 63.28%] [G loss: 0.803091]\n",
      "epoch:11 step:10692 [D loss: 0.546786, acc.: 77.34%] [G loss: 0.935764]\n",
      "epoch:11 step:10693 [D loss: 0.715885, acc.: 48.44%] [G loss: 0.880549]\n",
      "epoch:11 step:10694 [D loss: 0.694363, acc.: 55.47%] [G loss: 0.932137]\n",
      "epoch:11 step:10695 [D loss: 0.653923, acc.: 60.94%] [G loss: 0.990381]\n",
      "epoch:11 step:10696 [D loss: 0.594647, acc.: 68.75%] [G loss: 1.101926]\n",
      "epoch:11 step:10697 [D loss: 0.652303, acc.: 62.50%] [G loss: 0.996435]\n",
      "epoch:11 step:10698 [D loss: 0.710317, acc.: 53.12%] [G loss: 0.923260]\n",
      "epoch:11 step:10699 [D loss: 0.600405, acc.: 67.19%] [G loss: 1.103220]\n",
      "epoch:11 step:10700 [D loss: 0.650522, acc.: 59.38%] [G loss: 0.912383]\n",
      "epoch:11 step:10701 [D loss: 0.665866, acc.: 57.81%] [G loss: 0.843721]\n",
      "epoch:11 step:10702 [D loss: 0.647730, acc.: 64.06%] [G loss: 1.026718]\n",
      "epoch:11 step:10703 [D loss: 0.661223, acc.: 67.19%] [G loss: 0.955170]\n",
      "epoch:11 step:10704 [D loss: 0.564144, acc.: 70.31%] [G loss: 0.928773]\n",
      "epoch:11 step:10705 [D loss: 0.569671, acc.: 71.88%] [G loss: 0.940216]\n",
      "epoch:11 step:10706 [D loss: 0.614437, acc.: 64.84%] [G loss: 0.916307]\n",
      "epoch:11 step:10707 [D loss: 0.715112, acc.: 60.16%] [G loss: 1.011394]\n",
      "epoch:11 step:10708 [D loss: 0.646034, acc.: 59.38%] [G loss: 1.001580]\n",
      "epoch:11 step:10709 [D loss: 0.648048, acc.: 64.06%] [G loss: 1.053643]\n",
      "epoch:11 step:10710 [D loss: 0.614436, acc.: 62.50%] [G loss: 1.065479]\n",
      "epoch:11 step:10711 [D loss: 0.649493, acc.: 67.19%] [G loss: 1.006087]\n",
      "epoch:11 step:10712 [D loss: 0.574231, acc.: 72.66%] [G loss: 1.087980]\n",
      "epoch:11 step:10713 [D loss: 0.592610, acc.: 72.66%] [G loss: 1.062269]\n",
      "epoch:11 step:10714 [D loss: 0.612453, acc.: 69.53%] [G loss: 1.040149]\n",
      "epoch:11 step:10715 [D loss: 0.667222, acc.: 64.06%] [G loss: 1.035669]\n",
      "epoch:11 step:10716 [D loss: 0.633273, acc.: 64.06%] [G loss: 0.960224]\n",
      "epoch:11 step:10717 [D loss: 0.688756, acc.: 64.06%] [G loss: 0.972734]\n",
      "epoch:11 step:10718 [D loss: 0.633899, acc.: 64.06%] [G loss: 1.063235]\n",
      "epoch:11 step:10719 [D loss: 0.668487, acc.: 60.94%] [G loss: 0.990857]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10720 [D loss: 0.645434, acc.: 61.72%] [G loss: 0.878842]\n",
      "epoch:11 step:10721 [D loss: 0.733200, acc.: 51.56%] [G loss: 0.880214]\n",
      "epoch:11 step:10722 [D loss: 0.825686, acc.: 39.84%] [G loss: 0.758499]\n",
      "epoch:11 step:10723 [D loss: 0.640508, acc.: 62.50%] [G loss: 0.947005]\n",
      "epoch:11 step:10724 [D loss: 0.660215, acc.: 60.16%] [G loss: 1.048439]\n",
      "epoch:11 step:10725 [D loss: 0.641095, acc.: 60.16%] [G loss: 0.983808]\n",
      "epoch:11 step:10726 [D loss: 0.585661, acc.: 71.88%] [G loss: 1.121736]\n",
      "epoch:11 step:10727 [D loss: 0.644629, acc.: 59.38%] [G loss: 0.982830]\n",
      "epoch:11 step:10728 [D loss: 0.723114, acc.: 50.00%] [G loss: 0.922729]\n",
      "epoch:11 step:10729 [D loss: 0.754239, acc.: 48.44%] [G loss: 1.076149]\n",
      "epoch:11 step:10730 [D loss: 0.685299, acc.: 56.25%] [G loss: 0.972511]\n",
      "epoch:11 step:10731 [D loss: 0.626199, acc.: 65.62%] [G loss: 1.028632]\n",
      "epoch:11 step:10732 [D loss: 0.732714, acc.: 49.22%] [G loss: 0.946356]\n",
      "epoch:11 step:10733 [D loss: 0.560204, acc.: 75.00%] [G loss: 1.042127]\n",
      "epoch:11 step:10734 [D loss: 0.668783, acc.: 58.59%] [G loss: 0.926540]\n",
      "epoch:11 step:10735 [D loss: 0.654157, acc.: 59.38%] [G loss: 1.029618]\n",
      "epoch:11 step:10736 [D loss: 0.590017, acc.: 69.53%] [G loss: 1.051153]\n",
      "epoch:11 step:10737 [D loss: 0.605155, acc.: 62.50%] [G loss: 1.010966]\n",
      "epoch:11 step:10738 [D loss: 0.669988, acc.: 58.59%] [G loss: 1.058242]\n",
      "epoch:11 step:10739 [D loss: 0.749213, acc.: 52.34%] [G loss: 1.020595]\n",
      "epoch:11 step:10740 [D loss: 0.641458, acc.: 61.72%] [G loss: 1.059592]\n",
      "epoch:11 step:10741 [D loss: 0.626098, acc.: 64.84%] [G loss: 1.080924]\n",
      "epoch:11 step:10742 [D loss: 0.673659, acc.: 58.59%] [G loss: 0.945561]\n",
      "epoch:11 step:10743 [D loss: 0.659100, acc.: 63.28%] [G loss: 0.979370]\n",
      "epoch:11 step:10744 [D loss: 0.675714, acc.: 60.94%] [G loss: 0.980086]\n",
      "epoch:11 step:10745 [D loss: 0.702122, acc.: 53.91%] [G loss: 0.930668]\n",
      "epoch:11 step:10746 [D loss: 0.647447, acc.: 64.06%] [G loss: 1.109052]\n",
      "epoch:11 step:10747 [D loss: 0.638859, acc.: 62.50%] [G loss: 1.107106]\n",
      "epoch:11 step:10748 [D loss: 0.623768, acc.: 62.50%] [G loss: 0.981506]\n",
      "epoch:11 step:10749 [D loss: 0.677583, acc.: 54.69%] [G loss: 0.981260]\n",
      "epoch:11 step:10750 [D loss: 0.709706, acc.: 58.59%] [G loss: 1.018064]\n",
      "epoch:11 step:10751 [D loss: 0.647297, acc.: 61.72%] [G loss: 0.999348]\n",
      "epoch:11 step:10752 [D loss: 0.630294, acc.: 61.72%] [G loss: 1.012947]\n",
      "epoch:11 step:10753 [D loss: 0.755738, acc.: 40.62%] [G loss: 0.831291]\n",
      "epoch:11 step:10754 [D loss: 0.621790, acc.: 62.50%] [G loss: 0.924819]\n",
      "epoch:11 step:10755 [D loss: 0.682793, acc.: 57.03%] [G loss: 1.000932]\n",
      "epoch:11 step:10756 [D loss: 0.686665, acc.: 55.47%] [G loss: 0.865822]\n",
      "epoch:11 step:10757 [D loss: 0.617725, acc.: 65.62%] [G loss: 1.094956]\n",
      "epoch:11 step:10758 [D loss: 0.580796, acc.: 67.97%] [G loss: 0.959096]\n",
      "epoch:11 step:10759 [D loss: 0.590594, acc.: 70.31%] [G loss: 0.969769]\n",
      "epoch:11 step:10760 [D loss: 0.557809, acc.: 72.66%] [G loss: 0.985186]\n",
      "epoch:11 step:10761 [D loss: 0.513915, acc.: 80.47%] [G loss: 1.143171]\n",
      "epoch:11 step:10762 [D loss: 0.593339, acc.: 67.19%] [G loss: 1.027814]\n",
      "epoch:11 step:10763 [D loss: 0.525872, acc.: 73.44%] [G loss: 1.099425]\n",
      "epoch:11 step:10764 [D loss: 0.565101, acc.: 69.53%] [G loss: 1.072712]\n",
      "epoch:11 step:10765 [D loss: 0.812003, acc.: 42.19%] [G loss: 1.004647]\n",
      "epoch:11 step:10766 [D loss: 0.622582, acc.: 71.88%] [G loss: 0.935524]\n",
      "epoch:11 step:10767 [D loss: 0.774390, acc.: 46.88%] [G loss: 0.980688]\n",
      "epoch:11 step:10768 [D loss: 0.797627, acc.: 44.53%] [G loss: 0.938259]\n",
      "epoch:11 step:10769 [D loss: 0.802053, acc.: 42.97%] [G loss: 0.938426]\n",
      "epoch:11 step:10770 [D loss: 0.729971, acc.: 52.34%] [G loss: 0.861097]\n",
      "epoch:11 step:10771 [D loss: 0.514995, acc.: 82.03%] [G loss: 1.104484]\n",
      "epoch:11 step:10772 [D loss: 0.641037, acc.: 64.84%] [G loss: 0.953708]\n",
      "epoch:11 step:10773 [D loss: 0.620196, acc.: 64.06%] [G loss: 0.903809]\n",
      "epoch:11 step:10774 [D loss: 0.619454, acc.: 62.50%] [G loss: 1.043278]\n",
      "epoch:11 step:10775 [D loss: 0.609069, acc.: 75.00%] [G loss: 0.979331]\n",
      "epoch:11 step:10776 [D loss: 0.510843, acc.: 75.00%] [G loss: 1.107871]\n",
      "epoch:11 step:10777 [D loss: 0.578767, acc.: 75.00%] [G loss: 1.216130]\n",
      "epoch:11 step:10778 [D loss: 0.475467, acc.: 85.16%] [G loss: 1.132385]\n",
      "epoch:11 step:10779 [D loss: 0.643723, acc.: 67.19%] [G loss: 1.102516]\n",
      "epoch:11 step:10780 [D loss: 0.838604, acc.: 39.06%] [G loss: 0.862741]\n",
      "epoch:11 step:10781 [D loss: 0.756714, acc.: 45.31%] [G loss: 1.009968]\n",
      "epoch:11 step:10782 [D loss: 0.785593, acc.: 46.09%] [G loss: 0.916305]\n",
      "epoch:11 step:10783 [D loss: 0.624083, acc.: 62.50%] [G loss: 1.040371]\n",
      "epoch:11 step:10784 [D loss: 0.684358, acc.: 55.47%] [G loss: 1.120123]\n",
      "epoch:11 step:10785 [D loss: 0.704338, acc.: 56.25%] [G loss: 0.973728]\n",
      "epoch:11 step:10786 [D loss: 0.611418, acc.: 66.41%] [G loss: 0.923222]\n",
      "epoch:11 step:10787 [D loss: 0.662006, acc.: 56.25%] [G loss: 0.976249]\n",
      "epoch:11 step:10788 [D loss: 0.575267, acc.: 69.53%] [G loss: 0.939540]\n",
      "epoch:11 step:10789 [D loss: 0.696958, acc.: 57.81%] [G loss: 1.070459]\n",
      "epoch:11 step:10790 [D loss: 0.651842, acc.: 58.59%] [G loss: 1.042215]\n",
      "epoch:11 step:10791 [D loss: 0.641927, acc.: 65.62%] [G loss: 1.045716]\n",
      "epoch:11 step:10792 [D loss: 0.702940, acc.: 53.12%] [G loss: 1.003352]\n",
      "epoch:11 step:10793 [D loss: 0.687698, acc.: 57.81%] [G loss: 0.996139]\n",
      "epoch:11 step:10794 [D loss: 0.664027, acc.: 63.28%] [G loss: 0.980277]\n",
      "epoch:11 step:10795 [D loss: 0.644498, acc.: 57.03%] [G loss: 0.979106]\n",
      "epoch:11 step:10796 [D loss: 0.673646, acc.: 57.03%] [G loss: 1.014916]\n",
      "epoch:11 step:10797 [D loss: 0.567222, acc.: 72.66%] [G loss: 1.028073]\n",
      "epoch:11 step:10798 [D loss: 0.680653, acc.: 58.59%] [G loss: 0.946533]\n",
      "epoch:11 step:10799 [D loss: 0.663627, acc.: 60.16%] [G loss: 1.145942]\n",
      "epoch:11 step:10800 [D loss: 0.679634, acc.: 61.72%] [G loss: 0.850060]\n",
      "##############\n",
      "[2.32938865 1.58580301 5.37419449 4.29667422 3.22099678 5.61728137\n",
      " 4.15709626 4.6843277  3.90522284 3.47568571]\n",
      "##########\n",
      "epoch:11 step:10801 [D loss: 0.650417, acc.: 64.84%] [G loss: 0.890549]\n",
      "epoch:11 step:10802 [D loss: 0.572391, acc.: 74.22%] [G loss: 0.942150]\n",
      "epoch:11 step:10803 [D loss: 0.661630, acc.: 61.72%] [G loss: 1.005647]\n",
      "epoch:11 step:10804 [D loss: 0.639464, acc.: 60.94%] [G loss: 1.058656]\n",
      "epoch:11 step:10805 [D loss: 0.593455, acc.: 71.09%] [G loss: 1.114291]\n",
      "epoch:11 step:10806 [D loss: 0.568877, acc.: 64.84%] [G loss: 0.946562]\n",
      "epoch:11 step:10807 [D loss: 0.716270, acc.: 57.03%] [G loss: 0.930674]\n",
      "epoch:11 step:10808 [D loss: 0.734287, acc.: 53.12%] [G loss: 0.964758]\n",
      "epoch:11 step:10809 [D loss: 0.759129, acc.: 52.34%] [G loss: 0.918883]\n",
      "epoch:11 step:10810 [D loss: 0.667980, acc.: 62.50%] [G loss: 0.918102]\n",
      "epoch:11 step:10811 [D loss: 0.574223, acc.: 71.88%] [G loss: 0.925602]\n",
      "epoch:11 step:10812 [D loss: 0.653333, acc.: 62.50%] [G loss: 0.925179]\n",
      "epoch:11 step:10813 [D loss: 0.587231, acc.: 71.09%] [G loss: 0.944867]\n",
      "epoch:11 step:10814 [D loss: 0.665168, acc.: 57.03%] [G loss: 0.911935]\n",
      "epoch:11 step:10815 [D loss: 0.617117, acc.: 63.28%] [G loss: 0.971607]\n",
      "epoch:11 step:10816 [D loss: 0.715104, acc.: 50.78%] [G loss: 0.989494]\n",
      "epoch:11 step:10817 [D loss: 0.722150, acc.: 55.47%] [G loss: 0.924239]\n",
      "epoch:11 step:10818 [D loss: 0.714507, acc.: 56.25%] [G loss: 0.999200]\n",
      "epoch:11 step:10819 [D loss: 0.694980, acc.: 53.12%] [G loss: 0.893837]\n",
      "epoch:11 step:10820 [D loss: 0.642457, acc.: 64.84%] [G loss: 0.896832]\n",
      "epoch:11 step:10821 [D loss: 0.646518, acc.: 64.84%] [G loss: 0.795281]\n",
      "epoch:11 step:10822 [D loss: 0.691308, acc.: 55.47%] [G loss: 0.894521]\n",
      "epoch:11 step:10823 [D loss: 0.704934, acc.: 57.03%] [G loss: 0.963311]\n",
      "epoch:11 step:10824 [D loss: 0.793207, acc.: 45.31%] [G loss: 0.876397]\n",
      "epoch:11 step:10825 [D loss: 0.720896, acc.: 46.88%] [G loss: 0.987151]\n",
      "epoch:11 step:10826 [D loss: 0.682904, acc.: 55.47%] [G loss: 0.905120]\n",
      "epoch:11 step:10827 [D loss: 0.644521, acc.: 62.50%] [G loss: 1.053686]\n",
      "epoch:11 step:10828 [D loss: 0.648270, acc.: 64.06%] [G loss: 0.889779]\n",
      "epoch:11 step:10829 [D loss: 0.592700, acc.: 67.19%] [G loss: 1.002703]\n",
      "epoch:11 step:10830 [D loss: 0.690808, acc.: 57.81%] [G loss: 0.949882]\n",
      "epoch:11 step:10831 [D loss: 0.659749, acc.: 59.38%] [G loss: 1.067515]\n",
      "epoch:11 step:10832 [D loss: 0.681172, acc.: 57.81%] [G loss: 0.930492]\n",
      "epoch:11 step:10833 [D loss: 0.612777, acc.: 65.62%] [G loss: 0.903067]\n",
      "epoch:11 step:10834 [D loss: 0.653741, acc.: 64.84%] [G loss: 0.956752]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10835 [D loss: 0.720615, acc.: 50.78%] [G loss: 0.911915]\n",
      "epoch:11 step:10836 [D loss: 0.722221, acc.: 52.34%] [G loss: 0.843882]\n",
      "epoch:11 step:10837 [D loss: 0.630122, acc.: 64.06%] [G loss: 0.923195]\n",
      "epoch:11 step:10838 [D loss: 0.652383, acc.: 63.28%] [G loss: 0.949502]\n",
      "epoch:11 step:10839 [D loss: 0.621431, acc.: 60.94%] [G loss: 0.909420]\n",
      "epoch:11 step:10840 [D loss: 0.648334, acc.: 57.81%] [G loss: 0.967067]\n",
      "epoch:11 step:10841 [D loss: 0.674429, acc.: 57.81%] [G loss: 1.015990]\n",
      "epoch:11 step:10842 [D loss: 0.619665, acc.: 63.28%] [G loss: 0.996926]\n",
      "epoch:11 step:10843 [D loss: 0.594843, acc.: 70.31%] [G loss: 1.038152]\n",
      "epoch:11 step:10844 [D loss: 0.661275, acc.: 60.16%] [G loss: 0.944609]\n",
      "epoch:11 step:10845 [D loss: 0.611287, acc.: 64.06%] [G loss: 0.994017]\n",
      "epoch:11 step:10846 [D loss: 0.654825, acc.: 56.25%] [G loss: 1.025015]\n",
      "epoch:11 step:10847 [D loss: 0.595230, acc.: 69.53%] [G loss: 0.932126]\n",
      "epoch:11 step:10848 [D loss: 0.719925, acc.: 51.56%] [G loss: 0.957468]\n",
      "epoch:11 step:10849 [D loss: 0.668454, acc.: 55.47%] [G loss: 0.876482]\n",
      "epoch:11 step:10850 [D loss: 0.702991, acc.: 56.25%] [G loss: 0.886957]\n",
      "epoch:11 step:10851 [D loss: 0.663056, acc.: 61.72%] [G loss: 0.874539]\n",
      "epoch:11 step:10852 [D loss: 0.690919, acc.: 53.12%] [G loss: 0.938076]\n",
      "epoch:11 step:10853 [D loss: 0.651805, acc.: 59.38%] [G loss: 1.047134]\n",
      "epoch:11 step:10854 [D loss: 0.607653, acc.: 66.41%] [G loss: 1.005030]\n",
      "epoch:11 step:10855 [D loss: 0.646141, acc.: 64.06%] [G loss: 0.962494]\n",
      "epoch:11 step:10856 [D loss: 0.653844, acc.: 58.59%] [G loss: 0.914993]\n",
      "epoch:11 step:10857 [D loss: 0.600392, acc.: 65.62%] [G loss: 1.052828]\n",
      "epoch:11 step:10858 [D loss: 0.514088, acc.: 76.56%] [G loss: 1.126190]\n",
      "epoch:11 step:10859 [D loss: 0.580825, acc.: 70.31%] [G loss: 1.039483]\n",
      "epoch:11 step:10860 [D loss: 0.624255, acc.: 67.19%] [G loss: 1.285015]\n",
      "epoch:11 step:10861 [D loss: 0.598416, acc.: 71.88%] [G loss: 1.064777]\n",
      "epoch:11 step:10862 [D loss: 0.548821, acc.: 74.22%] [G loss: 0.994582]\n",
      "epoch:11 step:10863 [D loss: 0.651706, acc.: 59.38%] [G loss: 1.052324]\n",
      "epoch:11 step:10864 [D loss: 0.599489, acc.: 69.53%] [G loss: 0.947171]\n",
      "epoch:11 step:10865 [D loss: 0.617683, acc.: 67.97%] [G loss: 1.002055]\n",
      "epoch:11 step:10866 [D loss: 0.772881, acc.: 41.41%] [G loss: 1.065201]\n",
      "epoch:11 step:10867 [D loss: 0.741010, acc.: 53.12%] [G loss: 1.227147]\n",
      "epoch:11 step:10868 [D loss: 0.705682, acc.: 54.69%] [G loss: 0.948245]\n",
      "epoch:11 step:10869 [D loss: 0.673660, acc.: 60.94%] [G loss: 0.901188]\n",
      "epoch:11 step:10870 [D loss: 0.706981, acc.: 54.69%] [G loss: 0.939548]\n",
      "epoch:11 step:10871 [D loss: 0.575457, acc.: 73.44%] [G loss: 1.082592]\n",
      "epoch:11 step:10872 [D loss: 0.699965, acc.: 54.69%] [G loss: 0.965834]\n",
      "epoch:11 step:10873 [D loss: 0.579889, acc.: 70.31%] [G loss: 1.116979]\n",
      "epoch:11 step:10874 [D loss: 0.640190, acc.: 60.94%] [G loss: 0.982447]\n",
      "epoch:11 step:10875 [D loss: 0.640821, acc.: 63.28%] [G loss: 1.106819]\n",
      "epoch:11 step:10876 [D loss: 0.679952, acc.: 60.94%] [G loss: 0.959539]\n",
      "epoch:11 step:10877 [D loss: 0.633561, acc.: 61.72%] [G loss: 0.979800]\n",
      "epoch:11 step:10878 [D loss: 0.631263, acc.: 64.06%] [G loss: 0.878808]\n",
      "epoch:11 step:10879 [D loss: 0.677422, acc.: 59.38%] [G loss: 0.843901]\n",
      "epoch:11 step:10880 [D loss: 0.721780, acc.: 46.09%] [G loss: 0.815461]\n",
      "epoch:11 step:10881 [D loss: 0.693054, acc.: 57.81%] [G loss: 0.762112]\n",
      "epoch:11 step:10882 [D loss: 0.658250, acc.: 57.03%] [G loss: 0.886044]\n",
      "epoch:11 step:10883 [D loss: 0.690007, acc.: 57.03%] [G loss: 0.977723]\n",
      "epoch:11 step:10884 [D loss: 0.630544, acc.: 64.84%] [G loss: 0.935687]\n",
      "epoch:11 step:10885 [D loss: 0.602980, acc.: 71.88%] [G loss: 0.928208]\n",
      "epoch:11 step:10886 [D loss: 0.700380, acc.: 52.34%] [G loss: 0.878667]\n",
      "epoch:11 step:10887 [D loss: 0.706853, acc.: 57.03%] [G loss: 0.887121]\n",
      "epoch:11 step:10888 [D loss: 0.619677, acc.: 64.84%] [G loss: 0.912702]\n",
      "epoch:11 step:10889 [D loss: 0.713557, acc.: 50.00%] [G loss: 0.949138]\n",
      "epoch:11 step:10890 [D loss: 0.652521, acc.: 61.72%] [G loss: 1.010055]\n",
      "epoch:11 step:10891 [D loss: 0.635641, acc.: 62.50%] [G loss: 0.939539]\n",
      "epoch:11 step:10892 [D loss: 0.645965, acc.: 57.03%] [G loss: 1.156378]\n",
      "epoch:11 step:10893 [D loss: 0.627973, acc.: 61.72%] [G loss: 1.111766]\n",
      "epoch:11 step:10894 [D loss: 0.526715, acc.: 77.34%] [G loss: 1.018180]\n",
      "epoch:11 step:10895 [D loss: 0.567405, acc.: 74.22%] [G loss: 1.106396]\n",
      "epoch:11 step:10896 [D loss: 0.517294, acc.: 80.47%] [G loss: 1.219750]\n",
      "epoch:11 step:10897 [D loss: 0.661845, acc.: 64.06%] [G loss: 1.125409]\n",
      "epoch:11 step:10898 [D loss: 0.777655, acc.: 41.41%] [G loss: 0.968551]\n",
      "epoch:11 step:10899 [D loss: 0.600913, acc.: 71.09%] [G loss: 0.965716]\n",
      "epoch:11 step:10900 [D loss: 0.712615, acc.: 52.34%] [G loss: 0.860103]\n",
      "epoch:11 step:10901 [D loss: 0.664486, acc.: 58.59%] [G loss: 1.024649]\n",
      "epoch:11 step:10902 [D loss: 0.766097, acc.: 45.31%] [G loss: 0.936638]\n",
      "epoch:11 step:10903 [D loss: 0.691756, acc.: 50.78%] [G loss: 1.040341]\n",
      "epoch:11 step:10904 [D loss: 0.744077, acc.: 46.09%] [G loss: 1.002006]\n",
      "epoch:11 step:10905 [D loss: 0.665174, acc.: 61.72%] [G loss: 0.978823]\n",
      "epoch:11 step:10906 [D loss: 0.787313, acc.: 44.53%] [G loss: 0.947740]\n",
      "epoch:11 step:10907 [D loss: 0.699615, acc.: 56.25%] [G loss: 1.045648]\n",
      "epoch:11 step:10908 [D loss: 0.618222, acc.: 63.28%] [G loss: 0.985294]\n",
      "epoch:11 step:10909 [D loss: 0.677649, acc.: 56.25%] [G loss: 0.987063]\n",
      "epoch:11 step:10910 [D loss: 0.599204, acc.: 68.75%] [G loss: 1.101465]\n",
      "epoch:11 step:10911 [D loss: 0.716598, acc.: 47.66%] [G loss: 0.819723]\n",
      "epoch:11 step:10912 [D loss: 0.666307, acc.: 63.28%] [G loss: 0.967843]\n",
      "epoch:11 step:10913 [D loss: 0.668724, acc.: 60.16%] [G loss: 0.937868]\n",
      "epoch:11 step:10914 [D loss: 0.576079, acc.: 70.31%] [G loss: 1.060557]\n",
      "epoch:11 step:10915 [D loss: 0.666178, acc.: 53.91%] [G loss: 1.012064]\n",
      "epoch:11 step:10916 [D loss: 0.667874, acc.: 57.81%] [G loss: 0.874246]\n",
      "epoch:11 step:10917 [D loss: 0.641998, acc.: 60.94%] [G loss: 0.971029]\n",
      "epoch:11 step:10918 [D loss: 0.672792, acc.: 57.81%] [G loss: 0.895983]\n",
      "epoch:11 step:10919 [D loss: 0.698590, acc.: 58.59%] [G loss: 0.878447]\n",
      "epoch:11 step:10920 [D loss: 0.698992, acc.: 58.59%] [G loss: 0.916505]\n",
      "epoch:11 step:10921 [D loss: 0.703591, acc.: 55.47%] [G loss: 0.893916]\n",
      "epoch:11 step:10922 [D loss: 0.729719, acc.: 53.91%] [G loss: 0.973762]\n",
      "epoch:11 step:10923 [D loss: 0.654927, acc.: 61.72%] [G loss: 0.891500]\n",
      "epoch:11 step:10924 [D loss: 0.681175, acc.: 55.47%] [G loss: 0.995709]\n",
      "epoch:11 step:10925 [D loss: 0.651812, acc.: 60.94%] [G loss: 0.874130]\n",
      "epoch:11 step:10926 [D loss: 0.634306, acc.: 66.41%] [G loss: 0.983261]\n",
      "epoch:11 step:10927 [D loss: 0.664946, acc.: 60.94%] [G loss: 0.896426]\n",
      "epoch:11 step:10928 [D loss: 0.658983, acc.: 61.72%] [G loss: 0.950429]\n",
      "epoch:11 step:10929 [D loss: 0.674303, acc.: 60.16%] [G loss: 0.956680]\n",
      "epoch:11 step:10930 [D loss: 0.705541, acc.: 53.91%] [G loss: 0.867049]\n",
      "epoch:11 step:10931 [D loss: 0.649420, acc.: 64.06%] [G loss: 1.006447]\n",
      "epoch:11 step:10932 [D loss: 0.747620, acc.: 48.44%] [G loss: 0.963636]\n",
      "epoch:11 step:10933 [D loss: 0.753374, acc.: 46.09%] [G loss: 0.877070]\n",
      "epoch:11 step:10934 [D loss: 0.775880, acc.: 46.88%] [G loss: 0.866332]\n",
      "epoch:11 step:10935 [D loss: 0.651882, acc.: 63.28%] [G loss: 0.886776]\n",
      "epoch:11 step:10936 [D loss: 0.592116, acc.: 68.75%] [G loss: 1.021342]\n",
      "epoch:11 step:10937 [D loss: 0.588149, acc.: 70.31%] [G loss: 1.041451]\n",
      "epoch:11 step:10938 [D loss: 0.607505, acc.: 71.88%] [G loss: 1.014811]\n",
      "epoch:11 step:10939 [D loss: 0.662626, acc.: 60.94%] [G loss: 1.180893]\n",
      "epoch:11 step:10940 [D loss: 0.533094, acc.: 78.91%] [G loss: 1.006687]\n",
      "epoch:11 step:10941 [D loss: 0.640786, acc.: 60.94%] [G loss: 0.966120]\n",
      "epoch:11 step:10942 [D loss: 0.559846, acc.: 75.78%] [G loss: 1.030760]\n",
      "epoch:11 step:10943 [D loss: 0.632630, acc.: 65.62%] [G loss: 1.040851]\n",
      "epoch:11 step:10944 [D loss: 0.574190, acc.: 68.75%] [G loss: 1.087521]\n",
      "epoch:11 step:10945 [D loss: 0.613620, acc.: 67.19%] [G loss: 0.948485]\n",
      "epoch:11 step:10946 [D loss: 0.737292, acc.: 53.12%] [G loss: 0.882956]\n",
      "epoch:11 step:10947 [D loss: 0.689655, acc.: 53.91%] [G loss: 0.967452]\n",
      "epoch:11 step:10948 [D loss: 0.571507, acc.: 74.22%] [G loss: 1.129890]\n",
      "epoch:11 step:10949 [D loss: 0.691484, acc.: 54.69%] [G loss: 0.894104]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10950 [D loss: 0.684911, acc.: 58.59%] [G loss: 0.946228]\n",
      "epoch:11 step:10951 [D loss: 0.632167, acc.: 61.72%] [G loss: 1.052578]\n",
      "epoch:11 step:10952 [D loss: 0.637845, acc.: 64.06%] [G loss: 1.115258]\n",
      "epoch:11 step:10953 [D loss: 0.657326, acc.: 62.50%] [G loss: 1.173018]\n",
      "epoch:11 step:10954 [D loss: 0.556269, acc.: 72.66%] [G loss: 1.200412]\n",
      "epoch:11 step:10955 [D loss: 0.558540, acc.: 73.44%] [G loss: 1.110110]\n",
      "epoch:11 step:10956 [D loss: 0.624023, acc.: 68.75%] [G loss: 0.948409]\n",
      "epoch:11 step:10957 [D loss: 0.597586, acc.: 70.31%] [G loss: 1.194067]\n",
      "epoch:11 step:10958 [D loss: 0.644123, acc.: 59.38%] [G loss: 1.187460]\n",
      "epoch:11 step:10959 [D loss: 0.731591, acc.: 52.34%] [G loss: 1.019647]\n",
      "epoch:11 step:10960 [D loss: 0.668632, acc.: 59.38%] [G loss: 0.901370]\n",
      "epoch:11 step:10961 [D loss: 0.631732, acc.: 67.97%] [G loss: 0.945089]\n",
      "epoch:11 step:10962 [D loss: 0.690440, acc.: 55.47%] [G loss: 0.831827]\n",
      "epoch:11 step:10963 [D loss: 0.607069, acc.: 67.19%] [G loss: 0.898714]\n",
      "epoch:11 step:10964 [D loss: 0.747984, acc.: 48.44%] [G loss: 0.798169]\n",
      "epoch:11 step:10965 [D loss: 0.761432, acc.: 41.41%] [G loss: 0.975460]\n",
      "epoch:11 step:10966 [D loss: 0.719066, acc.: 53.91%] [G loss: 0.881981]\n",
      "epoch:11 step:10967 [D loss: 0.599029, acc.: 71.09%] [G loss: 1.045915]\n",
      "epoch:11 step:10968 [D loss: 0.724112, acc.: 52.34%] [G loss: 0.804365]\n",
      "epoch:11 step:10969 [D loss: 0.712807, acc.: 50.78%] [G loss: 0.884656]\n",
      "epoch:11 step:10970 [D loss: 0.618071, acc.: 65.62%] [G loss: 0.943167]\n",
      "epoch:11 step:10971 [D loss: 0.591993, acc.: 68.75%] [G loss: 1.008488]\n",
      "epoch:11 step:10972 [D loss: 0.605492, acc.: 71.09%] [G loss: 0.947730]\n",
      "epoch:11 step:10973 [D loss: 0.623910, acc.: 62.50%] [G loss: 0.965823]\n",
      "epoch:11 step:10974 [D loss: 0.592567, acc.: 70.31%] [G loss: 1.062109]\n",
      "epoch:11 step:10975 [D loss: 0.619798, acc.: 69.53%] [G loss: 0.975746]\n",
      "epoch:11 step:10976 [D loss: 0.637965, acc.: 62.50%] [G loss: 0.822614]\n",
      "epoch:11 step:10977 [D loss: 0.642108, acc.: 62.50%] [G loss: 1.021151]\n",
      "epoch:11 step:10978 [D loss: 0.631948, acc.: 64.84%] [G loss: 1.001282]\n",
      "epoch:11 step:10979 [D loss: 0.725218, acc.: 56.25%] [G loss: 0.956883]\n",
      "epoch:11 step:10980 [D loss: 0.786273, acc.: 47.66%] [G loss: 0.913787]\n",
      "epoch:11 step:10981 [D loss: 0.770082, acc.: 53.12%] [G loss: 0.946599]\n",
      "epoch:11 step:10982 [D loss: 0.712174, acc.: 56.25%] [G loss: 0.778457]\n",
      "epoch:11 step:10983 [D loss: 0.543949, acc.: 75.78%] [G loss: 1.033912]\n",
      "epoch:11 step:10984 [D loss: 0.584737, acc.: 69.53%] [G loss: 1.079400]\n",
      "epoch:11 step:10985 [D loss: 0.689276, acc.: 60.94%] [G loss: 0.994583]\n",
      "epoch:11 step:10986 [D loss: 0.656014, acc.: 62.50%] [G loss: 0.826506]\n",
      "epoch:11 step:10987 [D loss: 0.630098, acc.: 67.97%] [G loss: 0.952227]\n",
      "epoch:11 step:10988 [D loss: 0.586747, acc.: 71.88%] [G loss: 0.973403]\n",
      "epoch:11 step:10989 [D loss: 0.595260, acc.: 71.09%] [G loss: 0.980233]\n",
      "epoch:11 step:10990 [D loss: 0.721351, acc.: 53.91%] [G loss: 0.880523]\n",
      "epoch:11 step:10991 [D loss: 0.536660, acc.: 76.56%] [G loss: 1.034671]\n",
      "epoch:11 step:10992 [D loss: 0.629346, acc.: 65.62%] [G loss: 0.838922]\n",
      "epoch:11 step:10993 [D loss: 0.643188, acc.: 62.50%] [G loss: 0.929830]\n",
      "epoch:11 step:10994 [D loss: 0.688255, acc.: 53.91%] [G loss: 0.889702]\n",
      "epoch:11 step:10995 [D loss: 0.657636, acc.: 62.50%] [G loss: 0.957826]\n",
      "epoch:11 step:10996 [D loss: 0.720820, acc.: 51.56%] [G loss: 0.984756]\n",
      "epoch:11 step:10997 [D loss: 0.642682, acc.: 60.16%] [G loss: 0.959609]\n",
      "epoch:11 step:10998 [D loss: 0.651015, acc.: 60.94%] [G loss: 0.943859]\n",
      "epoch:11 step:10999 [D loss: 0.627025, acc.: 65.62%] [G loss: 0.993940]\n",
      "epoch:11 step:11000 [D loss: 0.704966, acc.: 50.78%] [G loss: 0.964032]\n",
      "##############\n",
      "[2.32978695 1.5019356  5.32126976 4.31342343 2.68567056 5.32033778\n",
      " 3.90703907 4.43148996 3.66949593 3.50975183]\n",
      "##########\n",
      "epoch:11 step:11001 [D loss: 0.611139, acc.: 66.41%] [G loss: 0.988257]\n",
      "epoch:11 step:11002 [D loss: 0.735879, acc.: 50.78%] [G loss: 0.910516]\n",
      "epoch:11 step:11003 [D loss: 0.593737, acc.: 68.75%] [G loss: 0.997333]\n",
      "epoch:11 step:11004 [D loss: 0.719442, acc.: 53.91%] [G loss: 1.035892]\n",
      "epoch:11 step:11005 [D loss: 0.705232, acc.: 57.03%] [G loss: 1.021902]\n",
      "epoch:11 step:11006 [D loss: 0.673719, acc.: 57.03%] [G loss: 0.850568]\n",
      "epoch:11 step:11007 [D loss: 0.628694, acc.: 64.84%] [G loss: 0.846175]\n",
      "epoch:11 step:11008 [D loss: 0.686183, acc.: 60.16%] [G loss: 0.942090]\n",
      "epoch:11 step:11009 [D loss: 0.690356, acc.: 58.59%] [G loss: 0.973577]\n",
      "epoch:11 step:11010 [D loss: 0.685371, acc.: 57.03%] [G loss: 0.880523]\n",
      "epoch:11 step:11011 [D loss: 0.650444, acc.: 59.38%] [G loss: 0.911400]\n",
      "epoch:11 step:11012 [D loss: 0.634797, acc.: 60.94%] [G loss: 0.970881]\n",
      "epoch:11 step:11013 [D loss: 0.613773, acc.: 67.19%] [G loss: 0.993958]\n",
      "epoch:11 step:11014 [D loss: 0.554360, acc.: 73.44%] [G loss: 1.013729]\n",
      "epoch:11 step:11015 [D loss: 0.575028, acc.: 71.09%] [G loss: 0.908536]\n",
      "epoch:11 step:11016 [D loss: 0.567977, acc.: 71.88%] [G loss: 1.075836]\n",
      "epoch:11 step:11017 [D loss: 0.656974, acc.: 60.94%] [G loss: 1.013553]\n",
      "epoch:11 step:11018 [D loss: 0.646000, acc.: 65.62%] [G loss: 0.971260]\n",
      "epoch:11 step:11019 [D loss: 0.673928, acc.: 61.72%] [G loss: 1.006543]\n",
      "epoch:11 step:11020 [D loss: 0.676424, acc.: 56.25%] [G loss: 0.992657]\n",
      "epoch:11 step:11021 [D loss: 0.617824, acc.: 67.19%] [G loss: 1.098048]\n",
      "epoch:11 step:11022 [D loss: 0.598009, acc.: 73.44%] [G loss: 0.971359]\n",
      "epoch:11 step:11023 [D loss: 0.767802, acc.: 44.53%] [G loss: 1.052233]\n",
      "epoch:11 step:11024 [D loss: 0.664157, acc.: 57.03%] [G loss: 0.982447]\n",
      "epoch:11 step:11025 [D loss: 0.732365, acc.: 49.22%] [G loss: 0.914666]\n",
      "epoch:11 step:11026 [D loss: 0.681404, acc.: 60.94%] [G loss: 0.844627]\n",
      "epoch:11 step:11027 [D loss: 0.669453, acc.: 63.28%] [G loss: 0.782431]\n",
      "epoch:11 step:11028 [D loss: 0.673778, acc.: 59.38%] [G loss: 0.944056]\n",
      "epoch:11 step:11029 [D loss: 0.673312, acc.: 64.06%] [G loss: 0.884848]\n",
      "epoch:11 step:11030 [D loss: 0.629802, acc.: 61.72%] [G loss: 0.852699]\n",
      "epoch:11 step:11031 [D loss: 0.657515, acc.: 65.62%] [G loss: 1.037319]\n",
      "epoch:11 step:11032 [D loss: 0.606181, acc.: 68.75%] [G loss: 0.985323]\n",
      "epoch:11 step:11033 [D loss: 0.648252, acc.: 62.50%] [G loss: 0.981161]\n",
      "epoch:11 step:11034 [D loss: 0.699572, acc.: 57.03%] [G loss: 1.111121]\n",
      "epoch:11 step:11035 [D loss: 0.592865, acc.: 68.75%] [G loss: 1.068449]\n",
      "epoch:11 step:11036 [D loss: 0.639339, acc.: 60.16%] [G loss: 0.908014]\n",
      "epoch:11 step:11037 [D loss: 0.716944, acc.: 54.69%] [G loss: 0.965422]\n",
      "epoch:11 step:11038 [D loss: 0.644069, acc.: 66.41%] [G loss: 0.902921]\n",
      "epoch:11 step:11039 [D loss: 0.610928, acc.: 67.19%] [G loss: 0.980667]\n",
      "epoch:11 step:11040 [D loss: 0.644587, acc.: 59.38%] [G loss: 0.954372]\n",
      "epoch:11 step:11041 [D loss: 0.666588, acc.: 57.81%] [G loss: 0.985305]\n",
      "epoch:11 step:11042 [D loss: 0.702648, acc.: 51.56%] [G loss: 0.879502]\n",
      "epoch:11 step:11043 [D loss: 0.647291, acc.: 62.50%] [G loss: 0.869272]\n",
      "epoch:11 step:11044 [D loss: 0.696692, acc.: 57.03%] [G loss: 0.992411]\n",
      "epoch:11 step:11045 [D loss: 0.654992, acc.: 60.94%] [G loss: 0.999515]\n",
      "epoch:11 step:11046 [D loss: 0.700750, acc.: 50.00%] [G loss: 0.847550]\n",
      "epoch:11 step:11047 [D loss: 0.636562, acc.: 64.84%] [G loss: 0.936947]\n",
      "epoch:11 step:11048 [D loss: 0.743913, acc.: 50.00%] [G loss: 0.938743]\n",
      "epoch:11 step:11049 [D loss: 0.731102, acc.: 47.66%] [G loss: 0.845342]\n",
      "epoch:11 step:11050 [D loss: 0.625220, acc.: 67.97%] [G loss: 0.982105]\n",
      "epoch:11 step:11051 [D loss: 0.797198, acc.: 47.66%] [G loss: 0.851404]\n",
      "epoch:11 step:11052 [D loss: 0.572960, acc.: 71.09%] [G loss: 1.002105]\n",
      "epoch:11 step:11053 [D loss: 0.571933, acc.: 70.31%] [G loss: 1.012141]\n",
      "epoch:11 step:11054 [D loss: 0.627564, acc.: 65.62%] [G loss: 1.026477]\n",
      "epoch:11 step:11055 [D loss: 0.695405, acc.: 57.81%] [G loss: 0.899230]\n",
      "epoch:11 step:11056 [D loss: 0.670422, acc.: 57.03%] [G loss: 1.007101]\n",
      "epoch:11 step:11057 [D loss: 0.701492, acc.: 55.47%] [G loss: 0.986311]\n",
      "epoch:11 step:11058 [D loss: 0.601576, acc.: 71.09%] [G loss: 0.878848]\n",
      "epoch:11 step:11059 [D loss: 0.683382, acc.: 60.94%] [G loss: 0.914198]\n",
      "epoch:11 step:11060 [D loss: 0.654435, acc.: 57.03%] [G loss: 0.886968]\n",
      "epoch:11 step:11061 [D loss: 0.653621, acc.: 63.28%] [G loss: 0.851253]\n",
      "epoch:11 step:11062 [D loss: 0.635398, acc.: 64.06%] [G loss: 0.789249]\n",
      "epoch:11 step:11063 [D loss: 0.709361, acc.: 63.28%] [G loss: 0.758291]\n",
      "epoch:11 step:11064 [D loss: 0.705183, acc.: 55.47%] [G loss: 1.018121]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:11065 [D loss: 0.610409, acc.: 67.19%] [G loss: 0.947072]\n",
      "epoch:11 step:11066 [D loss: 0.656392, acc.: 58.59%] [G loss: 0.954463]\n",
      "epoch:11 step:11067 [D loss: 0.665635, acc.: 58.59%] [G loss: 0.962815]\n",
      "epoch:11 step:11068 [D loss: 0.644106, acc.: 60.16%] [G loss: 0.985521]\n",
      "epoch:11 step:11069 [D loss: 0.710354, acc.: 49.22%] [G loss: 0.926642]\n",
      "epoch:11 step:11070 [D loss: 0.702706, acc.: 53.12%] [G loss: 1.007848]\n",
      "epoch:11 step:11071 [D loss: 0.683305, acc.: 59.38%] [G loss: 0.905200]\n",
      "epoch:11 step:11072 [D loss: 0.641372, acc.: 63.28%] [G loss: 0.855185]\n",
      "epoch:11 step:11073 [D loss: 0.629312, acc.: 66.41%] [G loss: 0.992935]\n",
      "epoch:11 step:11074 [D loss: 0.616188, acc.: 66.41%] [G loss: 1.114563]\n",
      "epoch:11 step:11075 [D loss: 0.616157, acc.: 64.84%] [G loss: 0.970265]\n",
      "epoch:11 step:11076 [D loss: 0.603960, acc.: 67.97%] [G loss: 1.093643]\n",
      "epoch:11 step:11077 [D loss: 0.688439, acc.: 60.94%] [G loss: 1.014440]\n",
      "epoch:11 step:11078 [D loss: 0.749261, acc.: 53.91%] [G loss: 0.912211]\n",
      "epoch:11 step:11079 [D loss: 0.697201, acc.: 58.59%] [G loss: 0.918072]\n",
      "epoch:11 step:11080 [D loss: 0.723540, acc.: 54.69%] [G loss: 0.960715]\n",
      "epoch:11 step:11081 [D loss: 0.644393, acc.: 63.28%] [G loss: 1.021912]\n",
      "epoch:11 step:11082 [D loss: 0.550174, acc.: 75.78%] [G loss: 1.055109]\n",
      "epoch:11 step:11083 [D loss: 0.666372, acc.: 57.03%] [G loss: 1.148342]\n",
      "epoch:11 step:11084 [D loss: 0.674552, acc.: 57.81%] [G loss: 1.065427]\n",
      "epoch:11 step:11085 [D loss: 0.810044, acc.: 42.19%] [G loss: 0.961579]\n",
      "epoch:11 step:11086 [D loss: 0.739280, acc.: 50.00%] [G loss: 0.921650]\n",
      "epoch:11 step:11087 [D loss: 0.705936, acc.: 53.91%] [G loss: 0.787985]\n",
      "epoch:11 step:11088 [D loss: 0.677052, acc.: 57.81%] [G loss: 1.060972]\n",
      "epoch:11 step:11089 [D loss: 0.672853, acc.: 57.81%] [G loss: 1.047806]\n",
      "epoch:11 step:11090 [D loss: 0.666714, acc.: 57.81%] [G loss: 0.874387]\n",
      "epoch:11 step:11091 [D loss: 0.656174, acc.: 56.25%] [G loss: 0.872451]\n",
      "epoch:11 step:11092 [D loss: 0.590910, acc.: 71.09%] [G loss: 1.078933]\n",
      "epoch:11 step:11093 [D loss: 0.618877, acc.: 69.53%] [G loss: 0.868551]\n",
      "epoch:11 step:11094 [D loss: 0.716123, acc.: 53.91%] [G loss: 0.938463]\n",
      "epoch:11 step:11095 [D loss: 0.799171, acc.: 42.97%] [G loss: 0.887866]\n",
      "epoch:11 step:11096 [D loss: 0.627397, acc.: 64.84%] [G loss: 0.841528]\n",
      "epoch:11 step:11097 [D loss: 0.627993, acc.: 64.06%] [G loss: 0.911103]\n",
      "epoch:11 step:11098 [D loss: 0.605436, acc.: 64.84%] [G loss: 0.795135]\n",
      "epoch:11 step:11099 [D loss: 0.588542, acc.: 70.31%] [G loss: 1.001998]\n",
      "epoch:11 step:11100 [D loss: 0.593844, acc.: 70.31%] [G loss: 1.192692]\n",
      "epoch:11 step:11101 [D loss: 0.726203, acc.: 51.56%] [G loss: 1.048680]\n",
      "epoch:11 step:11102 [D loss: 0.672794, acc.: 58.59%] [G loss: 1.035474]\n",
      "epoch:11 step:11103 [D loss: 0.669911, acc.: 59.38%] [G loss: 0.970345]\n",
      "epoch:11 step:11104 [D loss: 0.692417, acc.: 56.25%] [G loss: 0.929190]\n",
      "epoch:11 step:11105 [D loss: 0.648657, acc.: 65.62%] [G loss: 0.916279]\n",
      "epoch:11 step:11106 [D loss: 0.672361, acc.: 59.38%] [G loss: 1.044006]\n",
      "epoch:11 step:11107 [D loss: 0.776351, acc.: 45.31%] [G loss: 0.968401]\n",
      "epoch:11 step:11108 [D loss: 0.730333, acc.: 46.09%] [G loss: 0.975441]\n",
      "epoch:11 step:11109 [D loss: 0.633741, acc.: 66.41%] [G loss: 0.963845]\n",
      "epoch:11 step:11110 [D loss: 0.673725, acc.: 54.69%] [G loss: 0.996476]\n",
      "epoch:11 step:11111 [D loss: 0.667925, acc.: 58.59%] [G loss: 0.936312]\n",
      "epoch:11 step:11112 [D loss: 0.560633, acc.: 75.78%] [G loss: 1.075025]\n",
      "epoch:11 step:11113 [D loss: 0.602385, acc.: 67.19%] [G loss: 0.923601]\n",
      "epoch:11 step:11114 [D loss: 0.581167, acc.: 70.31%] [G loss: 0.950436]\n",
      "epoch:11 step:11115 [D loss: 0.588271, acc.: 70.31%] [G loss: 0.954376]\n",
      "epoch:11 step:11116 [D loss: 0.684241, acc.: 60.16%] [G loss: 0.992407]\n",
      "epoch:11 step:11117 [D loss: 0.639729, acc.: 64.84%] [G loss: 0.904503]\n",
      "epoch:11 step:11118 [D loss: 0.672093, acc.: 60.94%] [G loss: 0.865276]\n",
      "epoch:11 step:11119 [D loss: 0.670057, acc.: 62.50%] [G loss: 0.855239]\n",
      "epoch:11 step:11120 [D loss: 0.698003, acc.: 56.25%] [G loss: 0.869519]\n",
      "epoch:11 step:11121 [D loss: 0.701201, acc.: 55.47%] [G loss: 1.023996]\n",
      "epoch:11 step:11122 [D loss: 0.588726, acc.: 67.97%] [G loss: 0.935542]\n",
      "epoch:11 step:11123 [D loss: 0.740557, acc.: 50.00%] [G loss: 0.893890]\n",
      "epoch:11 step:11124 [D loss: 0.732038, acc.: 53.91%] [G loss: 0.927859]\n",
      "epoch:11 step:11125 [D loss: 0.667891, acc.: 61.72%] [G loss: 0.906776]\n",
      "epoch:11 step:11126 [D loss: 0.650833, acc.: 59.38%] [G loss: 0.934130]\n",
      "epoch:11 step:11127 [D loss: 0.795068, acc.: 42.19%] [G loss: 0.983729]\n",
      "epoch:11 step:11128 [D loss: 0.654777, acc.: 60.94%] [G loss: 0.898783]\n",
      "epoch:11 step:11129 [D loss: 0.691911, acc.: 54.69%] [G loss: 0.914369]\n",
      "epoch:11 step:11130 [D loss: 0.580961, acc.: 70.31%] [G loss: 1.182866]\n",
      "epoch:11 step:11131 [D loss: 0.614090, acc.: 71.88%] [G loss: 1.017017]\n",
      "epoch:11 step:11132 [D loss: 0.643533, acc.: 62.50%] [G loss: 0.949728]\n",
      "epoch:11 step:11133 [D loss: 0.555587, acc.: 74.22%] [G loss: 0.905048]\n",
      "epoch:11 step:11134 [D loss: 0.756542, acc.: 46.88%] [G loss: 0.760582]\n",
      "epoch:11 step:11135 [D loss: 0.663631, acc.: 60.16%] [G loss: 0.926154]\n",
      "epoch:11 step:11136 [D loss: 0.641499, acc.: 65.62%] [G loss: 0.846125]\n",
      "epoch:11 step:11137 [D loss: 0.667391, acc.: 59.38%] [G loss: 1.049669]\n",
      "epoch:11 step:11138 [D loss: 0.628071, acc.: 65.62%] [G loss: 0.998569]\n",
      "epoch:11 step:11139 [D loss: 0.575472, acc.: 69.53%] [G loss: 0.931213]\n",
      "epoch:11 step:11140 [D loss: 0.634508, acc.: 65.62%] [G loss: 1.017133]\n",
      "epoch:11 step:11141 [D loss: 0.611117, acc.: 65.62%] [G loss: 1.145143]\n",
      "epoch:11 step:11142 [D loss: 0.586754, acc.: 71.88%] [G loss: 1.142233]\n",
      "epoch:11 step:11143 [D loss: 0.653413, acc.: 57.03%] [G loss: 1.028144]\n",
      "epoch:11 step:11144 [D loss: 0.715392, acc.: 51.56%] [G loss: 0.834346]\n",
      "epoch:11 step:11145 [D loss: 0.613978, acc.: 66.41%] [G loss: 0.806610]\n",
      "epoch:11 step:11146 [D loss: 0.651801, acc.: 64.84%] [G loss: 0.813415]\n",
      "epoch:11 step:11147 [D loss: 0.666596, acc.: 61.72%] [G loss: 0.966106]\n",
      "epoch:11 step:11148 [D loss: 0.581721, acc.: 69.53%] [G loss: 0.928577]\n",
      "epoch:11 step:11149 [D loss: 0.636020, acc.: 64.84%] [G loss: 0.956600]\n",
      "epoch:11 step:11150 [D loss: 0.720281, acc.: 50.78%] [G loss: 1.089551]\n",
      "epoch:11 step:11151 [D loss: 0.793096, acc.: 45.31%] [G loss: 0.940848]\n",
      "epoch:11 step:11152 [D loss: 0.724232, acc.: 44.53%] [G loss: 0.932762]\n",
      "epoch:11 step:11153 [D loss: 0.594455, acc.: 72.66%] [G loss: 1.123281]\n",
      "epoch:11 step:11154 [D loss: 0.640407, acc.: 62.50%] [G loss: 1.080085]\n",
      "epoch:11 step:11155 [D loss: 0.603892, acc.: 67.19%] [G loss: 1.044516]\n",
      "epoch:11 step:11156 [D loss: 0.616972, acc.: 67.19%] [G loss: 0.921004]\n",
      "epoch:11 step:11157 [D loss: 0.663634, acc.: 60.16%] [G loss: 0.982988]\n",
      "epoch:11 step:11158 [D loss: 0.640751, acc.: 59.38%] [G loss: 1.052075]\n",
      "epoch:11 step:11159 [D loss: 0.624021, acc.: 67.97%] [G loss: 1.050771]\n",
      "epoch:11 step:11160 [D loss: 0.558098, acc.: 75.00%] [G loss: 1.102459]\n",
      "epoch:11 step:11161 [D loss: 0.593611, acc.: 67.97%] [G loss: 0.816365]\n",
      "epoch:11 step:11162 [D loss: 0.674434, acc.: 57.03%] [G loss: 1.102101]\n",
      "epoch:11 step:11163 [D loss: 0.605373, acc.: 67.97%] [G loss: 0.980391]\n",
      "epoch:11 step:11164 [D loss: 0.677356, acc.: 55.47%] [G loss: 0.926528]\n",
      "epoch:11 step:11165 [D loss: 0.833329, acc.: 42.97%] [G loss: 0.858084]\n",
      "epoch:11 step:11166 [D loss: 0.720083, acc.: 50.00%] [G loss: 0.886956]\n",
      "epoch:11 step:11167 [D loss: 0.660210, acc.: 61.72%] [G loss: 0.907805]\n",
      "epoch:11 step:11168 [D loss: 0.689403, acc.: 56.25%] [G loss: 0.861974]\n",
      "epoch:11 step:11169 [D loss: 0.692733, acc.: 58.59%] [G loss: 0.983414]\n",
      "epoch:11 step:11170 [D loss: 0.645253, acc.: 64.84%] [G loss: 0.817540]\n",
      "epoch:11 step:11171 [D loss: 0.685561, acc.: 57.03%] [G loss: 0.990833]\n",
      "epoch:11 step:11172 [D loss: 0.612235, acc.: 68.75%] [G loss: 1.039334]\n",
      "epoch:11 step:11173 [D loss: 0.670739, acc.: 58.59%] [G loss: 0.916796]\n",
      "epoch:11 step:11174 [D loss: 0.646173, acc.: 58.59%] [G loss: 0.892330]\n",
      "epoch:11 step:11175 [D loss: 0.700717, acc.: 52.34%] [G loss: 0.962591]\n",
      "epoch:11 step:11176 [D loss: 0.749744, acc.: 47.66%] [G loss: 0.928161]\n",
      "epoch:11 step:11177 [D loss: 0.714467, acc.: 50.00%] [G loss: 0.909112]\n",
      "epoch:11 step:11178 [D loss: 0.649565, acc.: 59.38%] [G loss: 0.789493]\n",
      "epoch:11 step:11179 [D loss: 0.662077, acc.: 60.16%] [G loss: 1.019923]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:11180 [D loss: 0.687756, acc.: 53.91%] [G loss: 0.886003]\n",
      "epoch:11 step:11181 [D loss: 0.682373, acc.: 58.59%] [G loss: 0.931944]\n",
      "epoch:11 step:11182 [D loss: 0.626559, acc.: 67.19%] [G loss: 1.015066]\n",
      "epoch:11 step:11183 [D loss: 0.578898, acc.: 71.09%] [G loss: 1.040513]\n",
      "epoch:11 step:11184 [D loss: 0.664939, acc.: 63.28%] [G loss: 1.042833]\n",
      "epoch:11 step:11185 [D loss: 0.707210, acc.: 53.91%] [G loss: 0.857581]\n",
      "epoch:11 step:11186 [D loss: 0.681074, acc.: 57.03%] [G loss: 0.912860]\n",
      "epoch:11 step:11187 [D loss: 0.662594, acc.: 59.38%] [G loss: 1.011876]\n",
      "epoch:11 step:11188 [D loss: 0.640605, acc.: 64.06%] [G loss: 1.028049]\n",
      "epoch:11 step:11189 [D loss: 0.657300, acc.: 60.94%] [G loss: 0.993142]\n",
      "epoch:11 step:11190 [D loss: 0.657149, acc.: 60.94%] [G loss: 0.834963]\n",
      "epoch:11 step:11191 [D loss: 0.584845, acc.: 74.22%] [G loss: 0.853886]\n",
      "epoch:11 step:11192 [D loss: 0.566918, acc.: 69.53%] [G loss: 0.890640]\n",
      "epoch:11 step:11193 [D loss: 0.640374, acc.: 62.50%] [G loss: 0.932522]\n",
      "epoch:11 step:11194 [D loss: 0.624395, acc.: 64.84%] [G loss: 0.972409]\n",
      "epoch:11 step:11195 [D loss: 0.597380, acc.: 70.31%] [G loss: 1.015569]\n",
      "epoch:11 step:11196 [D loss: 0.579155, acc.: 67.97%] [G loss: 0.964615]\n",
      "epoch:11 step:11197 [D loss: 0.539213, acc.: 71.88%] [G loss: 0.996551]\n",
      "epoch:11 step:11198 [D loss: 0.766430, acc.: 47.66%] [G loss: 0.980124]\n",
      "epoch:11 step:11199 [D loss: 0.783452, acc.: 47.66%] [G loss: 0.838793]\n",
      "epoch:11 step:11200 [D loss: 0.699962, acc.: 57.81%] [G loss: 0.856660]\n",
      "##############\n",
      "[2.27193784 1.75283206 5.43557748 4.37542639 3.22411259 5.15280041\n",
      " 4.3259837  4.74371992 4.01050823 3.65842987]\n",
      "##########\n",
      "epoch:11 step:11201 [D loss: 0.685722, acc.: 57.81%] [G loss: 0.900000]\n",
      "epoch:11 step:11202 [D loss: 0.722075, acc.: 53.91%] [G loss: 0.885170]\n",
      "epoch:11 step:11203 [D loss: 0.684271, acc.: 57.81%] [G loss: 0.953457]\n",
      "epoch:11 step:11204 [D loss: 0.695134, acc.: 53.12%] [G loss: 0.915979]\n",
      "epoch:11 step:11205 [D loss: 0.676109, acc.: 61.72%] [G loss: 0.968659]\n",
      "epoch:11 step:11206 [D loss: 0.512270, acc.: 78.91%] [G loss: 0.983323]\n",
      "epoch:11 step:11207 [D loss: 0.573946, acc.: 67.97%] [G loss: 1.070355]\n",
      "epoch:11 step:11208 [D loss: 0.613187, acc.: 67.19%] [G loss: 1.126012]\n",
      "epoch:11 step:11209 [D loss: 0.743582, acc.: 49.22%] [G loss: 0.885042]\n",
      "epoch:11 step:11210 [D loss: 0.664537, acc.: 60.16%] [G loss: 0.937076]\n",
      "epoch:11 step:11211 [D loss: 0.613422, acc.: 67.19%] [G loss: 0.863190]\n",
      "epoch:11 step:11212 [D loss: 0.609492, acc.: 67.97%] [G loss: 0.928562]\n",
      "epoch:11 step:11213 [D loss: 0.662066, acc.: 60.16%] [G loss: 0.861719]\n",
      "epoch:11 step:11214 [D loss: 0.660499, acc.: 60.94%] [G loss: 1.003810]\n",
      "epoch:11 step:11215 [D loss: 0.696440, acc.: 54.69%] [G loss: 0.868067]\n",
      "epoch:11 step:11216 [D loss: 0.573102, acc.: 70.31%] [G loss: 0.936099]\n",
      "epoch:11 step:11217 [D loss: 0.674548, acc.: 59.38%] [G loss: 1.084322]\n",
      "epoch:11 step:11218 [D loss: 0.546550, acc.: 79.69%] [G loss: 1.057384]\n",
      "epoch:11 step:11219 [D loss: 0.416502, acc.: 89.06%] [G loss: 1.098689]\n",
      "epoch:11 step:11220 [D loss: 0.733327, acc.: 46.88%] [G loss: 0.915318]\n",
      "epoch:11 step:11221 [D loss: 0.717619, acc.: 50.00%] [G loss: 0.891477]\n",
      "epoch:11 step:11222 [D loss: 0.667994, acc.: 62.50%] [G loss: 0.962917]\n",
      "epoch:11 step:11223 [D loss: 0.648409, acc.: 60.16%] [G loss: 1.016745]\n",
      "epoch:11 step:11224 [D loss: 0.655382, acc.: 60.94%] [G loss: 0.984029]\n",
      "epoch:11 step:11225 [D loss: 0.546062, acc.: 72.66%] [G loss: 0.857254]\n",
      "epoch:11 step:11226 [D loss: 0.554100, acc.: 72.66%] [G loss: 1.019099]\n",
      "epoch:11 step:11227 [D loss: 0.734925, acc.: 48.44%] [G loss: 0.987300]\n",
      "epoch:11 step:11228 [D loss: 0.684575, acc.: 50.78%] [G loss: 1.032068]\n",
      "epoch:11 step:11229 [D loss: 0.538013, acc.: 78.91%] [G loss: 1.106862]\n",
      "epoch:11 step:11230 [D loss: 0.546807, acc.: 71.88%] [G loss: 1.057107]\n",
      "epoch:11 step:11231 [D loss: 0.555705, acc.: 70.31%] [G loss: 0.980428]\n",
      "epoch:11 step:11232 [D loss: 0.535010, acc.: 75.78%] [G loss: 1.098638]\n",
      "epoch:11 step:11233 [D loss: 0.565886, acc.: 68.75%] [G loss: 0.934031]\n",
      "epoch:11 step:11234 [D loss: 0.469220, acc.: 84.38%] [G loss: 1.108181]\n",
      "epoch:11 step:11235 [D loss: 0.944734, acc.: 32.03%] [G loss: 0.925964]\n",
      "epoch:11 step:11236 [D loss: 0.699641, acc.: 56.25%] [G loss: 1.079264]\n",
      "epoch:11 step:11237 [D loss: 0.577102, acc.: 71.09%] [G loss: 0.950756]\n",
      "epoch:11 step:11238 [D loss: 0.553285, acc.: 71.88%] [G loss: 1.037744]\n",
      "epoch:11 step:11239 [D loss: 0.679176, acc.: 61.72%] [G loss: 0.886634]\n",
      "epoch:11 step:11240 [D loss: 0.604338, acc.: 71.09%] [G loss: 0.865278]\n",
      "epoch:11 step:11241 [D loss: 0.564757, acc.: 68.75%] [G loss: 0.959597]\n",
      "epoch:11 step:11242 [D loss: 0.593147, acc.: 68.75%] [G loss: 1.056538]\n",
      "epoch:11 step:11243 [D loss: 0.485652, acc.: 76.56%] [G loss: 1.383002]\n",
      "epoch:11 step:11244 [D loss: 0.363703, acc.: 89.84%] [G loss: 1.171409]\n",
      "epoch:12 step:11245 [D loss: 0.742236, acc.: 56.25%] [G loss: 1.107746]\n",
      "epoch:12 step:11246 [D loss: 0.680503, acc.: 60.94%] [G loss: 1.172397]\n",
      "epoch:12 step:11247 [D loss: 0.684069, acc.: 58.59%] [G loss: 1.113485]\n",
      "epoch:12 step:11248 [D loss: 0.763873, acc.: 53.12%] [G loss: 1.020725]\n",
      "epoch:12 step:11249 [D loss: 0.650779, acc.: 60.16%] [G loss: 0.948710]\n",
      "epoch:12 step:11250 [D loss: 0.686285, acc.: 57.81%] [G loss: 1.200400]\n",
      "epoch:12 step:11251 [D loss: 0.632987, acc.: 67.19%] [G loss: 1.010030]\n",
      "epoch:12 step:11252 [D loss: 0.653643, acc.: 58.59%] [G loss: 0.872361]\n",
      "epoch:12 step:11253 [D loss: 0.612500, acc.: 68.75%] [G loss: 1.095080]\n",
      "epoch:12 step:11254 [D loss: 0.574274, acc.: 78.91%] [G loss: 1.080948]\n",
      "epoch:12 step:11255 [D loss: 0.616780, acc.: 67.97%] [G loss: 1.093328]\n",
      "epoch:12 step:11256 [D loss: 0.697826, acc.: 60.94%] [G loss: 0.994659]\n",
      "epoch:12 step:11257 [D loss: 0.585741, acc.: 69.53%] [G loss: 0.971377]\n",
      "epoch:12 step:11258 [D loss: 0.642098, acc.: 64.06%] [G loss: 0.980171]\n",
      "epoch:12 step:11259 [D loss: 0.599922, acc.: 70.31%] [G loss: 1.060269]\n",
      "epoch:12 step:11260 [D loss: 0.552908, acc.: 73.44%] [G loss: 1.159620]\n",
      "epoch:12 step:11261 [D loss: 0.677585, acc.: 61.72%] [G loss: 1.014452]\n",
      "epoch:12 step:11262 [D loss: 0.724118, acc.: 47.66%] [G loss: 0.869469]\n",
      "epoch:12 step:11263 [D loss: 0.725393, acc.: 50.78%] [G loss: 1.124509]\n",
      "epoch:12 step:11264 [D loss: 0.813572, acc.: 43.75%] [G loss: 1.064120]\n",
      "epoch:12 step:11265 [D loss: 0.716558, acc.: 57.03%] [G loss: 1.055600]\n",
      "epoch:12 step:11266 [D loss: 0.722195, acc.: 50.00%] [G loss: 0.924682]\n",
      "epoch:12 step:11267 [D loss: 0.559029, acc.: 78.91%] [G loss: 1.040579]\n",
      "epoch:12 step:11268 [D loss: 0.623333, acc.: 67.19%] [G loss: 0.944847]\n",
      "epoch:12 step:11269 [D loss: 0.636237, acc.: 70.31%] [G loss: 1.023651]\n",
      "epoch:12 step:11270 [D loss: 0.693423, acc.: 53.91%] [G loss: 0.890859]\n",
      "epoch:12 step:11271 [D loss: 0.622570, acc.: 64.84%] [G loss: 0.981734]\n",
      "epoch:12 step:11272 [D loss: 0.600850, acc.: 65.62%] [G loss: 1.075374]\n",
      "epoch:12 step:11273 [D loss: 0.580333, acc.: 70.31%] [G loss: 1.019184]\n",
      "epoch:12 step:11274 [D loss: 0.703333, acc.: 60.94%] [G loss: 0.888480]\n",
      "epoch:12 step:11275 [D loss: 0.668372, acc.: 63.28%] [G loss: 1.211783]\n",
      "epoch:12 step:11276 [D loss: 0.601204, acc.: 66.41%] [G loss: 0.970261]\n",
      "epoch:12 step:11277 [D loss: 0.636177, acc.: 64.84%] [G loss: 1.051297]\n",
      "epoch:12 step:11278 [D loss: 0.605770, acc.: 69.53%] [G loss: 1.124641]\n",
      "epoch:12 step:11279 [D loss: 0.534074, acc.: 78.91%] [G loss: 1.211083]\n",
      "epoch:12 step:11280 [D loss: 0.507911, acc.: 81.25%] [G loss: 1.026892]\n",
      "epoch:12 step:11281 [D loss: 0.681833, acc.: 60.16%] [G loss: 0.957929]\n",
      "epoch:12 step:11282 [D loss: 0.682222, acc.: 52.34%] [G loss: 0.965747]\n",
      "epoch:12 step:11283 [D loss: 0.811727, acc.: 40.62%] [G loss: 0.858705]\n",
      "epoch:12 step:11284 [D loss: 0.601095, acc.: 69.53%] [G loss: 0.935863]\n",
      "epoch:12 step:11285 [D loss: 0.681284, acc.: 54.69%] [G loss: 0.974331]\n",
      "epoch:12 step:11286 [D loss: 0.620257, acc.: 66.41%] [G loss: 0.875541]\n",
      "epoch:12 step:11287 [D loss: 0.644406, acc.: 64.06%] [G loss: 0.948677]\n",
      "epoch:12 step:11288 [D loss: 0.675089, acc.: 57.03%] [G loss: 0.944355]\n",
      "epoch:12 step:11289 [D loss: 0.603236, acc.: 69.53%] [G loss: 0.972699]\n",
      "epoch:12 step:11290 [D loss: 0.628895, acc.: 64.06%] [G loss: 0.995976]\n",
      "epoch:12 step:11291 [D loss: 0.660642, acc.: 57.03%] [G loss: 0.910279]\n",
      "epoch:12 step:11292 [D loss: 0.607636, acc.: 63.28%] [G loss: 0.943973]\n",
      "epoch:12 step:11293 [D loss: 0.596362, acc.: 68.75%] [G loss: 1.035933]\n",
      "epoch:12 step:11294 [D loss: 0.654444, acc.: 67.19%] [G loss: 0.838631]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11295 [D loss: 0.681625, acc.: 58.59%] [G loss: 0.963685]\n",
      "epoch:12 step:11296 [D loss: 0.614457, acc.: 67.19%] [G loss: 0.909042]\n",
      "epoch:12 step:11297 [D loss: 0.596261, acc.: 65.62%] [G loss: 0.976927]\n",
      "epoch:12 step:11298 [D loss: 0.626066, acc.: 64.06%] [G loss: 0.868114]\n",
      "epoch:12 step:11299 [D loss: 0.592637, acc.: 71.09%] [G loss: 1.102605]\n",
      "epoch:12 step:11300 [D loss: 0.563171, acc.: 70.31%] [G loss: 1.090336]\n",
      "epoch:12 step:11301 [D loss: 0.660812, acc.: 60.16%] [G loss: 0.992182]\n",
      "epoch:12 step:11302 [D loss: 0.639730, acc.: 62.50%] [G loss: 1.068917]\n",
      "epoch:12 step:11303 [D loss: 0.707755, acc.: 56.25%] [G loss: 0.767152]\n",
      "epoch:12 step:11304 [D loss: 0.754104, acc.: 47.66%] [G loss: 0.903344]\n",
      "epoch:12 step:11305 [D loss: 0.696982, acc.: 53.91%] [G loss: 1.025942]\n",
      "epoch:12 step:11306 [D loss: 0.728468, acc.: 53.91%] [G loss: 0.929060]\n",
      "epoch:12 step:11307 [D loss: 0.652428, acc.: 60.16%] [G loss: 0.920908]\n",
      "epoch:12 step:11308 [D loss: 0.655096, acc.: 66.41%] [G loss: 1.080834]\n",
      "epoch:12 step:11309 [D loss: 0.701357, acc.: 51.56%] [G loss: 0.955351]\n",
      "epoch:12 step:11310 [D loss: 0.679962, acc.: 54.69%] [G loss: 0.968135]\n",
      "epoch:12 step:11311 [D loss: 0.588349, acc.: 67.19%] [G loss: 1.077229]\n",
      "epoch:12 step:11312 [D loss: 0.659746, acc.: 58.59%] [G loss: 0.961901]\n",
      "epoch:12 step:11313 [D loss: 0.540145, acc.: 72.66%] [G loss: 0.958124]\n",
      "epoch:12 step:11314 [D loss: 0.628877, acc.: 68.75%] [G loss: 0.827364]\n",
      "epoch:12 step:11315 [D loss: 0.597887, acc.: 70.31%] [G loss: 1.031352]\n",
      "epoch:12 step:11316 [D loss: 0.637441, acc.: 62.50%] [G loss: 1.047266]\n",
      "epoch:12 step:11317 [D loss: 0.729300, acc.: 51.56%] [G loss: 0.982558]\n",
      "epoch:12 step:11318 [D loss: 0.610579, acc.: 64.84%] [G loss: 0.927703]\n",
      "epoch:12 step:11319 [D loss: 0.578570, acc.: 70.31%] [G loss: 0.850113]\n",
      "epoch:12 step:11320 [D loss: 0.634485, acc.: 66.41%] [G loss: 0.838927]\n",
      "epoch:12 step:11321 [D loss: 0.582475, acc.: 70.31%] [G loss: 0.959269]\n",
      "epoch:12 step:11322 [D loss: 0.707951, acc.: 50.00%] [G loss: 0.855838]\n",
      "epoch:12 step:11323 [D loss: 0.751044, acc.: 50.78%] [G loss: 0.915311]\n",
      "epoch:12 step:11324 [D loss: 0.632656, acc.: 66.41%] [G loss: 1.004803]\n",
      "epoch:12 step:11325 [D loss: 0.709715, acc.: 49.22%] [G loss: 0.918116]\n",
      "epoch:12 step:11326 [D loss: 0.720602, acc.: 52.34%] [G loss: 0.854683]\n",
      "epoch:12 step:11327 [D loss: 0.605889, acc.: 59.38%] [G loss: 0.964151]\n",
      "epoch:12 step:11328 [D loss: 0.670175, acc.: 64.84%] [G loss: 0.840192]\n",
      "epoch:12 step:11329 [D loss: 0.727471, acc.: 50.78%] [G loss: 0.872282]\n",
      "epoch:12 step:11330 [D loss: 0.697909, acc.: 55.47%] [G loss: 0.908759]\n",
      "epoch:12 step:11331 [D loss: 0.719161, acc.: 53.91%] [G loss: 0.793953]\n",
      "epoch:12 step:11332 [D loss: 0.653492, acc.: 58.59%] [G loss: 0.889314]\n",
      "epoch:12 step:11333 [D loss: 0.626848, acc.: 64.06%] [G loss: 0.989260]\n",
      "epoch:12 step:11334 [D loss: 0.711242, acc.: 55.47%] [G loss: 0.970300]\n",
      "epoch:12 step:11335 [D loss: 0.661503, acc.: 63.28%] [G loss: 0.896486]\n",
      "epoch:12 step:11336 [D loss: 0.546547, acc.: 75.78%] [G loss: 0.930960]\n",
      "epoch:12 step:11337 [D loss: 0.619925, acc.: 66.41%] [G loss: 0.869208]\n",
      "epoch:12 step:11338 [D loss: 0.704659, acc.: 53.91%] [G loss: 0.715684]\n",
      "epoch:12 step:11339 [D loss: 0.634797, acc.: 64.06%] [G loss: 1.109509]\n",
      "epoch:12 step:11340 [D loss: 0.653684, acc.: 64.06%] [G loss: 1.160453]\n",
      "epoch:12 step:11341 [D loss: 0.659176, acc.: 62.50%] [G loss: 0.998073]\n",
      "epoch:12 step:11342 [D loss: 0.657991, acc.: 63.28%] [G loss: 0.901723]\n",
      "epoch:12 step:11343 [D loss: 0.709809, acc.: 51.56%] [G loss: 0.861964]\n",
      "epoch:12 step:11344 [D loss: 0.661109, acc.: 58.59%] [G loss: 0.869498]\n",
      "epoch:12 step:11345 [D loss: 0.645790, acc.: 61.72%] [G loss: 0.973889]\n",
      "epoch:12 step:11346 [D loss: 0.730366, acc.: 50.00%] [G loss: 0.875244]\n",
      "epoch:12 step:11347 [D loss: 0.578132, acc.: 69.53%] [G loss: 1.017629]\n",
      "epoch:12 step:11348 [D loss: 0.731770, acc.: 47.66%] [G loss: 0.894465]\n",
      "epoch:12 step:11349 [D loss: 0.732960, acc.: 52.34%] [G loss: 0.994094]\n",
      "epoch:12 step:11350 [D loss: 0.645332, acc.: 59.38%] [G loss: 0.949649]\n",
      "epoch:12 step:11351 [D loss: 0.731946, acc.: 51.56%] [G loss: 0.940499]\n",
      "epoch:12 step:11352 [D loss: 0.748805, acc.: 53.91%] [G loss: 0.974387]\n",
      "epoch:12 step:11353 [D loss: 0.772567, acc.: 39.84%] [G loss: 0.867728]\n",
      "epoch:12 step:11354 [D loss: 0.753056, acc.: 45.31%] [G loss: 0.924829]\n",
      "epoch:12 step:11355 [D loss: 0.571638, acc.: 72.66%] [G loss: 0.878486]\n",
      "epoch:12 step:11356 [D loss: 0.692675, acc.: 54.69%] [G loss: 0.914904]\n",
      "epoch:12 step:11357 [D loss: 0.640303, acc.: 59.38%] [G loss: 0.996187]\n",
      "epoch:12 step:11358 [D loss: 0.648404, acc.: 58.59%] [G loss: 0.983202]\n",
      "epoch:12 step:11359 [D loss: 0.648130, acc.: 57.81%] [G loss: 0.966058]\n",
      "epoch:12 step:11360 [D loss: 0.653552, acc.: 61.72%] [G loss: 0.907592]\n",
      "epoch:12 step:11361 [D loss: 0.658511, acc.: 62.50%] [G loss: 0.833550]\n",
      "epoch:12 step:11362 [D loss: 0.692305, acc.: 53.12%] [G loss: 1.015694]\n",
      "epoch:12 step:11363 [D loss: 0.574140, acc.: 73.44%] [G loss: 0.932023]\n",
      "epoch:12 step:11364 [D loss: 0.706497, acc.: 56.25%] [G loss: 1.037408]\n",
      "epoch:12 step:11365 [D loss: 0.670326, acc.: 57.03%] [G loss: 1.077460]\n",
      "epoch:12 step:11366 [D loss: 0.707041, acc.: 52.34%] [G loss: 0.938073]\n",
      "epoch:12 step:11367 [D loss: 0.653480, acc.: 60.94%] [G loss: 0.992442]\n",
      "epoch:12 step:11368 [D loss: 0.671867, acc.: 56.25%] [G loss: 0.940103]\n",
      "epoch:12 step:11369 [D loss: 0.657596, acc.: 63.28%] [G loss: 1.011925]\n",
      "epoch:12 step:11370 [D loss: 0.687009, acc.: 55.47%] [G loss: 0.859552]\n",
      "epoch:12 step:11371 [D loss: 0.623545, acc.: 67.97%] [G loss: 1.105361]\n",
      "epoch:12 step:11372 [D loss: 0.680472, acc.: 56.25%] [G loss: 0.808961]\n",
      "epoch:12 step:11373 [D loss: 0.646398, acc.: 60.16%] [G loss: 1.006291]\n",
      "epoch:12 step:11374 [D loss: 0.644850, acc.: 64.84%] [G loss: 0.818624]\n",
      "epoch:12 step:11375 [D loss: 0.595867, acc.: 71.09%] [G loss: 1.025185]\n",
      "epoch:12 step:11376 [D loss: 0.625983, acc.: 67.97%] [G loss: 0.913614]\n",
      "epoch:12 step:11377 [D loss: 0.704896, acc.: 53.12%] [G loss: 0.853401]\n",
      "epoch:12 step:11378 [D loss: 0.627820, acc.: 64.84%] [G loss: 1.004222]\n",
      "epoch:12 step:11379 [D loss: 0.702983, acc.: 49.22%] [G loss: 0.838105]\n",
      "epoch:12 step:11380 [D loss: 0.690233, acc.: 55.47%] [G loss: 1.001840]\n",
      "epoch:12 step:11381 [D loss: 0.811541, acc.: 35.94%] [G loss: 0.950207]\n",
      "epoch:12 step:11382 [D loss: 0.774123, acc.: 48.44%] [G loss: 0.753469]\n",
      "epoch:12 step:11383 [D loss: 0.689307, acc.: 58.59%] [G loss: 0.936122]\n",
      "epoch:12 step:11384 [D loss: 0.706560, acc.: 57.81%] [G loss: 0.913831]\n",
      "epoch:12 step:11385 [D loss: 0.634722, acc.: 63.28%] [G loss: 0.895799]\n",
      "epoch:12 step:11386 [D loss: 0.613007, acc.: 61.72%] [G loss: 1.001726]\n",
      "epoch:12 step:11387 [D loss: 0.715824, acc.: 51.56%] [G loss: 1.011517]\n",
      "epoch:12 step:11388 [D loss: 0.548444, acc.: 77.34%] [G loss: 0.934472]\n",
      "epoch:12 step:11389 [D loss: 0.658299, acc.: 61.72%] [G loss: 1.073601]\n",
      "epoch:12 step:11390 [D loss: 0.697781, acc.: 55.47%] [G loss: 0.936283]\n",
      "epoch:12 step:11391 [D loss: 0.706970, acc.: 58.59%] [G loss: 0.918909]\n",
      "epoch:12 step:11392 [D loss: 0.681370, acc.: 57.03%] [G loss: 0.956029]\n",
      "epoch:12 step:11393 [D loss: 0.713405, acc.: 50.78%] [G loss: 0.804641]\n",
      "epoch:12 step:11394 [D loss: 0.611854, acc.: 66.41%] [G loss: 1.022972]\n",
      "epoch:12 step:11395 [D loss: 0.563882, acc.: 75.00%] [G loss: 1.215124]\n",
      "epoch:12 step:11396 [D loss: 0.543358, acc.: 70.31%] [G loss: 0.989208]\n",
      "epoch:12 step:11397 [D loss: 0.758734, acc.: 47.66%] [G loss: 0.999098]\n",
      "epoch:12 step:11398 [D loss: 0.635314, acc.: 64.84%] [G loss: 1.280128]\n",
      "epoch:12 step:11399 [D loss: 0.608896, acc.: 67.97%] [G loss: 0.959431]\n",
      "epoch:12 step:11400 [D loss: 0.697771, acc.: 56.25%] [G loss: 1.072922]\n",
      "##############\n",
      "[2.25667593 1.8514125  5.41766907 4.39797195 2.90704089 5.33717196\n",
      " 4.09571375 4.61004912 3.64616437 3.69164785]\n",
      "##########\n",
      "epoch:12 step:11401 [D loss: 0.687383, acc.: 58.59%] [G loss: 0.999584]\n",
      "epoch:12 step:11402 [D loss: 0.698500, acc.: 54.69%] [G loss: 0.950037]\n",
      "epoch:12 step:11403 [D loss: 0.680966, acc.: 55.47%] [G loss: 0.981768]\n",
      "epoch:12 step:11404 [D loss: 0.821628, acc.: 40.62%] [G loss: 0.979735]\n",
      "epoch:12 step:11405 [D loss: 0.772854, acc.: 46.88%] [G loss: 0.814032]\n",
      "epoch:12 step:11406 [D loss: 0.669065, acc.: 60.94%] [G loss: 0.900453]\n",
      "epoch:12 step:11407 [D loss: 0.629501, acc.: 67.97%] [G loss: 0.928968]\n",
      "epoch:12 step:11408 [D loss: 0.738805, acc.: 45.31%] [G loss: 0.810236]\n",
      "epoch:12 step:11409 [D loss: 0.653293, acc.: 57.81%] [G loss: 0.896968]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11410 [D loss: 0.685023, acc.: 63.28%] [G loss: 0.868015]\n",
      "epoch:12 step:11411 [D loss: 0.698930, acc.: 49.22%] [G loss: 0.908100]\n",
      "epoch:12 step:11412 [D loss: 0.677821, acc.: 57.81%] [G loss: 0.989418]\n",
      "epoch:12 step:11413 [D loss: 0.652735, acc.: 60.94%] [G loss: 1.034308]\n",
      "epoch:12 step:11414 [D loss: 0.657476, acc.: 57.03%] [G loss: 0.902837]\n",
      "epoch:12 step:11415 [D loss: 0.705995, acc.: 50.78%] [G loss: 0.836732]\n",
      "epoch:12 step:11416 [D loss: 0.641645, acc.: 63.28%] [G loss: 1.005211]\n",
      "epoch:12 step:11417 [D loss: 0.599775, acc.: 72.66%] [G loss: 0.939849]\n",
      "epoch:12 step:11418 [D loss: 0.687898, acc.: 60.16%] [G loss: 0.931302]\n",
      "epoch:12 step:11419 [D loss: 0.705937, acc.: 54.69%] [G loss: 0.795239]\n",
      "epoch:12 step:11420 [D loss: 0.692508, acc.: 56.25%] [G loss: 0.841182]\n",
      "epoch:12 step:11421 [D loss: 0.673531, acc.: 63.28%] [G loss: 0.864294]\n",
      "epoch:12 step:11422 [D loss: 0.647419, acc.: 62.50%] [G loss: 0.940472]\n",
      "epoch:12 step:11423 [D loss: 0.757355, acc.: 42.97%] [G loss: 0.874667]\n",
      "epoch:12 step:11424 [D loss: 0.702751, acc.: 53.91%] [G loss: 0.959111]\n",
      "epoch:12 step:11425 [D loss: 0.647794, acc.: 60.94%] [G loss: 1.064646]\n",
      "epoch:12 step:11426 [D loss: 0.760119, acc.: 44.53%] [G loss: 0.921871]\n",
      "epoch:12 step:11427 [D loss: 0.749829, acc.: 50.00%] [G loss: 0.875701]\n",
      "epoch:12 step:11428 [D loss: 0.688158, acc.: 50.00%] [G loss: 0.973508]\n",
      "epoch:12 step:11429 [D loss: 0.713021, acc.: 45.31%] [G loss: 0.977287]\n",
      "epoch:12 step:11430 [D loss: 0.757213, acc.: 42.97%] [G loss: 0.901092]\n",
      "epoch:12 step:11431 [D loss: 0.662107, acc.: 60.16%] [G loss: 0.874822]\n",
      "epoch:12 step:11432 [D loss: 0.726011, acc.: 51.56%] [G loss: 0.876239]\n",
      "epoch:12 step:11433 [D loss: 0.735734, acc.: 48.44%] [G loss: 0.955578]\n",
      "epoch:12 step:11434 [D loss: 0.627433, acc.: 63.28%] [G loss: 1.012359]\n",
      "epoch:12 step:11435 [D loss: 0.653875, acc.: 57.81%] [G loss: 0.858278]\n",
      "epoch:12 step:11436 [D loss: 0.577114, acc.: 74.22%] [G loss: 0.916129]\n",
      "epoch:12 step:11437 [D loss: 0.652019, acc.: 60.94%] [G loss: 0.877222]\n",
      "epoch:12 step:11438 [D loss: 0.613005, acc.: 68.75%] [G loss: 0.902376]\n",
      "epoch:12 step:11439 [D loss: 0.636382, acc.: 59.38%] [G loss: 1.031186]\n",
      "epoch:12 step:11440 [D loss: 0.670875, acc.: 58.59%] [G loss: 1.009383]\n",
      "epoch:12 step:11441 [D loss: 0.639991, acc.: 67.19%] [G loss: 1.026450]\n",
      "epoch:12 step:11442 [D loss: 0.679554, acc.: 50.00%] [G loss: 0.896649]\n",
      "epoch:12 step:11443 [D loss: 0.715165, acc.: 54.69%] [G loss: 0.995832]\n",
      "epoch:12 step:11444 [D loss: 0.712874, acc.: 48.44%] [G loss: 0.894273]\n",
      "epoch:12 step:11445 [D loss: 0.753300, acc.: 53.91%] [G loss: 0.989047]\n",
      "epoch:12 step:11446 [D loss: 0.701968, acc.: 54.69%] [G loss: 0.948289]\n",
      "epoch:12 step:11447 [D loss: 0.721888, acc.: 50.78%] [G loss: 0.872539]\n",
      "epoch:12 step:11448 [D loss: 0.694745, acc.: 60.16%] [G loss: 1.046704]\n",
      "epoch:12 step:11449 [D loss: 0.728180, acc.: 51.56%] [G loss: 0.911240]\n",
      "epoch:12 step:11450 [D loss: 0.559512, acc.: 75.78%] [G loss: 0.924448]\n",
      "epoch:12 step:11451 [D loss: 0.604510, acc.: 66.41%] [G loss: 0.946651]\n",
      "epoch:12 step:11452 [D loss: 0.596739, acc.: 68.75%] [G loss: 0.873917]\n",
      "epoch:12 step:11453 [D loss: 0.577320, acc.: 73.44%] [G loss: 1.007408]\n",
      "epoch:12 step:11454 [D loss: 0.691953, acc.: 55.47%] [G loss: 1.043434]\n",
      "epoch:12 step:11455 [D loss: 0.635041, acc.: 63.28%] [G loss: 0.966339]\n",
      "epoch:12 step:11456 [D loss: 0.593559, acc.: 70.31%] [G loss: 0.956092]\n",
      "epoch:12 step:11457 [D loss: 0.659829, acc.: 64.06%] [G loss: 0.924574]\n",
      "epoch:12 step:11458 [D loss: 0.759030, acc.: 42.19%] [G loss: 0.899712]\n",
      "epoch:12 step:11459 [D loss: 0.765240, acc.: 46.88%] [G loss: 0.769051]\n",
      "epoch:12 step:11460 [D loss: 0.757859, acc.: 53.12%] [G loss: 0.936754]\n",
      "epoch:12 step:11461 [D loss: 0.627776, acc.: 66.41%] [G loss: 0.924548]\n",
      "epoch:12 step:11462 [D loss: 0.574417, acc.: 71.09%] [G loss: 0.982661]\n",
      "epoch:12 step:11463 [D loss: 0.596345, acc.: 64.84%] [G loss: 1.224176]\n",
      "epoch:12 step:11464 [D loss: 0.603083, acc.: 67.97%] [G loss: 0.978157]\n",
      "epoch:12 step:11465 [D loss: 0.659259, acc.: 60.94%] [G loss: 0.990353]\n",
      "epoch:12 step:11466 [D loss: 0.671430, acc.: 55.47%] [G loss: 1.007397]\n",
      "epoch:12 step:11467 [D loss: 0.592229, acc.: 72.66%] [G loss: 0.979185]\n",
      "epoch:12 step:11468 [D loss: 0.706642, acc.: 56.25%] [G loss: 0.982397]\n",
      "epoch:12 step:11469 [D loss: 0.702044, acc.: 57.81%] [G loss: 1.098359]\n",
      "epoch:12 step:11470 [D loss: 0.628006, acc.: 64.84%] [G loss: 0.983927]\n",
      "epoch:12 step:11471 [D loss: 0.716256, acc.: 56.25%] [G loss: 0.942526]\n",
      "epoch:12 step:11472 [D loss: 0.633421, acc.: 61.72%] [G loss: 0.857481]\n",
      "epoch:12 step:11473 [D loss: 0.661596, acc.: 57.81%] [G loss: 0.715774]\n",
      "epoch:12 step:11474 [D loss: 0.494550, acc.: 81.25%] [G loss: 0.972485]\n",
      "epoch:12 step:11475 [D loss: 0.580360, acc.: 65.62%] [G loss: 1.041040]\n",
      "epoch:12 step:11476 [D loss: 0.502700, acc.: 80.47%] [G loss: 1.217575]\n",
      "epoch:12 step:11477 [D loss: 0.714437, acc.: 50.78%] [G loss: 1.028152]\n",
      "epoch:12 step:11478 [D loss: 0.780293, acc.: 47.66%] [G loss: 1.032053]\n",
      "epoch:12 step:11479 [D loss: 0.767137, acc.: 42.19%] [G loss: 0.890752]\n",
      "epoch:12 step:11480 [D loss: 0.671827, acc.: 60.16%] [G loss: 0.817971]\n",
      "epoch:12 step:11481 [D loss: 0.544194, acc.: 74.22%] [G loss: 1.042594]\n",
      "epoch:12 step:11482 [D loss: 0.709708, acc.: 57.03%] [G loss: 0.913296]\n",
      "epoch:12 step:11483 [D loss: 0.594453, acc.: 64.84%] [G loss: 0.932631]\n",
      "epoch:12 step:11484 [D loss: 0.699884, acc.: 51.56%] [G loss: 1.077078]\n",
      "epoch:12 step:11485 [D loss: 0.701168, acc.: 53.91%] [G loss: 0.976134]\n",
      "epoch:12 step:11486 [D loss: 0.683499, acc.: 58.59%] [G loss: 0.846461]\n",
      "epoch:12 step:11487 [D loss: 0.708075, acc.: 50.00%] [G loss: 0.935336]\n",
      "epoch:12 step:11488 [D loss: 0.641413, acc.: 65.62%] [G loss: 0.944198]\n",
      "epoch:12 step:11489 [D loss: 0.791230, acc.: 43.75%] [G loss: 0.745072]\n",
      "epoch:12 step:11490 [D loss: 0.689976, acc.: 57.03%] [G loss: 0.936271]\n",
      "epoch:12 step:11491 [D loss: 0.640096, acc.: 61.72%] [G loss: 0.912664]\n",
      "epoch:12 step:11492 [D loss: 0.684987, acc.: 53.91%] [G loss: 0.935989]\n",
      "epoch:12 step:11493 [D loss: 0.760513, acc.: 51.56%] [G loss: 0.967323]\n",
      "epoch:12 step:11494 [D loss: 0.753835, acc.: 48.44%] [G loss: 0.802261]\n",
      "epoch:12 step:11495 [D loss: 0.702842, acc.: 53.12%] [G loss: 0.798201]\n",
      "epoch:12 step:11496 [D loss: 0.705813, acc.: 54.69%] [G loss: 0.989197]\n",
      "epoch:12 step:11497 [D loss: 0.620123, acc.: 71.09%] [G loss: 0.867524]\n",
      "epoch:12 step:11498 [D loss: 0.648977, acc.: 60.94%] [G loss: 0.989816]\n",
      "epoch:12 step:11499 [D loss: 0.761055, acc.: 45.31%] [G loss: 0.834795]\n",
      "epoch:12 step:11500 [D loss: 0.615119, acc.: 71.88%] [G loss: 0.927569]\n",
      "epoch:12 step:11501 [D loss: 0.612111, acc.: 66.41%] [G loss: 0.872080]\n",
      "epoch:12 step:11502 [D loss: 0.602124, acc.: 68.75%] [G loss: 1.023554]\n",
      "epoch:12 step:11503 [D loss: 0.638995, acc.: 65.62%] [G loss: 0.931946]\n",
      "epoch:12 step:11504 [D loss: 0.667414, acc.: 60.94%] [G loss: 0.868653]\n",
      "epoch:12 step:11505 [D loss: 0.689166, acc.: 57.81%] [G loss: 0.842410]\n",
      "epoch:12 step:11506 [D loss: 0.689165, acc.: 57.81%] [G loss: 0.896255]\n",
      "epoch:12 step:11507 [D loss: 0.641740, acc.: 64.84%] [G loss: 1.027601]\n",
      "epoch:12 step:11508 [D loss: 0.638420, acc.: 61.72%] [G loss: 0.988925]\n",
      "epoch:12 step:11509 [D loss: 0.722647, acc.: 48.44%] [G loss: 0.800903]\n",
      "epoch:12 step:11510 [D loss: 0.669461, acc.: 59.38%] [G loss: 0.964994]\n",
      "epoch:12 step:11511 [D loss: 0.609775, acc.: 67.97%] [G loss: 1.042966]\n",
      "epoch:12 step:11512 [D loss: 0.737831, acc.: 51.56%] [G loss: 0.869080]\n",
      "epoch:12 step:11513 [D loss: 0.677726, acc.: 53.91%] [G loss: 0.870053]\n",
      "epoch:12 step:11514 [D loss: 0.700449, acc.: 53.12%] [G loss: 0.889039]\n",
      "epoch:12 step:11515 [D loss: 0.620622, acc.: 64.84%] [G loss: 0.985306]\n",
      "epoch:12 step:11516 [D loss: 0.649926, acc.: 67.19%] [G loss: 1.090037]\n",
      "epoch:12 step:11517 [D loss: 0.704084, acc.: 56.25%] [G loss: 0.966536]\n",
      "epoch:12 step:11518 [D loss: 0.625396, acc.: 63.28%] [G loss: 1.078790]\n",
      "epoch:12 step:11519 [D loss: 0.687891, acc.: 56.25%] [G loss: 0.984802]\n",
      "epoch:12 step:11520 [D loss: 0.682683, acc.: 60.16%] [G loss: 0.966263]\n",
      "epoch:12 step:11521 [D loss: 0.636345, acc.: 60.16%] [G loss: 0.853313]\n",
      "epoch:12 step:11522 [D loss: 0.662846, acc.: 62.50%] [G loss: 0.883057]\n",
      "epoch:12 step:11523 [D loss: 0.651801, acc.: 62.50%] [G loss: 0.842811]\n",
      "epoch:12 step:11524 [D loss: 0.606371, acc.: 67.97%] [G loss: 1.039684]\n",
      "epoch:12 step:11525 [D loss: 0.634498, acc.: 64.06%] [G loss: 0.997779]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11526 [D loss: 0.688923, acc.: 57.81%] [G loss: 0.850223]\n",
      "epoch:12 step:11527 [D loss: 0.622508, acc.: 69.53%] [G loss: 0.913924]\n",
      "epoch:12 step:11528 [D loss: 0.678702, acc.: 58.59%] [G loss: 0.987583]\n",
      "epoch:12 step:11529 [D loss: 0.622720, acc.: 64.06%] [G loss: 0.925071]\n",
      "epoch:12 step:11530 [D loss: 0.544853, acc.: 74.22%] [G loss: 1.007116]\n",
      "epoch:12 step:11531 [D loss: 0.712706, acc.: 52.34%] [G loss: 0.953350]\n",
      "epoch:12 step:11532 [D loss: 0.631217, acc.: 64.06%] [G loss: 0.974698]\n",
      "epoch:12 step:11533 [D loss: 0.576141, acc.: 70.31%] [G loss: 0.963638]\n",
      "epoch:12 step:11534 [D loss: 0.663154, acc.: 60.16%] [G loss: 0.993303]\n",
      "epoch:12 step:11535 [D loss: 0.707187, acc.: 57.03%] [G loss: 0.966654]\n",
      "epoch:12 step:11536 [D loss: 0.667287, acc.: 53.12%] [G loss: 0.889494]\n",
      "epoch:12 step:11537 [D loss: 0.637506, acc.: 64.84%] [G loss: 0.958614]\n",
      "epoch:12 step:11538 [D loss: 0.638170, acc.: 64.06%] [G loss: 0.996485]\n",
      "epoch:12 step:11539 [D loss: 0.725437, acc.: 53.12%] [G loss: 0.929596]\n",
      "epoch:12 step:11540 [D loss: 0.609348, acc.: 63.28%] [G loss: 0.935072]\n",
      "epoch:12 step:11541 [D loss: 0.660464, acc.: 65.62%] [G loss: 1.136440]\n",
      "epoch:12 step:11542 [D loss: 0.607264, acc.: 63.28%] [G loss: 1.030233]\n",
      "epoch:12 step:11543 [D loss: 0.572017, acc.: 69.53%] [G loss: 1.070081]\n",
      "epoch:12 step:11544 [D loss: 0.608745, acc.: 69.53%] [G loss: 1.012753]\n",
      "epoch:12 step:11545 [D loss: 0.727547, acc.: 50.00%] [G loss: 1.018074]\n",
      "epoch:12 step:11546 [D loss: 0.658103, acc.: 58.59%] [G loss: 0.858329]\n",
      "epoch:12 step:11547 [D loss: 0.675367, acc.: 58.59%] [G loss: 1.010135]\n",
      "epoch:12 step:11548 [D loss: 0.742594, acc.: 50.00%] [G loss: 0.943616]\n",
      "epoch:12 step:11549 [D loss: 0.692383, acc.: 51.56%] [G loss: 0.973533]\n",
      "epoch:12 step:11550 [D loss: 0.675731, acc.: 57.03%] [G loss: 0.983761]\n",
      "epoch:12 step:11551 [D loss: 0.642392, acc.: 67.97%] [G loss: 0.955653]\n",
      "epoch:12 step:11552 [D loss: 0.724461, acc.: 53.12%] [G loss: 0.947010]\n",
      "epoch:12 step:11553 [D loss: 0.608933, acc.: 69.53%] [G loss: 0.930364]\n",
      "epoch:12 step:11554 [D loss: 0.648932, acc.: 65.62%] [G loss: 0.817239]\n",
      "epoch:12 step:11555 [D loss: 0.584545, acc.: 71.09%] [G loss: 0.984539]\n",
      "epoch:12 step:11556 [D loss: 0.512079, acc.: 79.69%] [G loss: 0.934988]\n",
      "epoch:12 step:11557 [D loss: 0.588737, acc.: 74.22%] [G loss: 0.915504]\n",
      "epoch:12 step:11558 [D loss: 0.579226, acc.: 70.31%] [G loss: 0.981132]\n",
      "epoch:12 step:11559 [D loss: 0.613135, acc.: 65.62%] [G loss: 1.021279]\n",
      "epoch:12 step:11560 [D loss: 0.675196, acc.: 57.03%] [G loss: 1.062813]\n",
      "epoch:12 step:11561 [D loss: 0.620482, acc.: 66.41%] [G loss: 1.078868]\n",
      "epoch:12 step:11562 [D loss: 0.665281, acc.: 57.81%] [G loss: 0.956896]\n",
      "epoch:12 step:11563 [D loss: 0.646131, acc.: 67.19%] [G loss: 0.802104]\n",
      "epoch:12 step:11564 [D loss: 0.633323, acc.: 60.94%] [G loss: 0.850188]\n",
      "epoch:12 step:11565 [D loss: 0.677389, acc.: 53.91%] [G loss: 0.868995]\n",
      "epoch:12 step:11566 [D loss: 0.628742, acc.: 64.84%] [G loss: 0.836624]\n",
      "epoch:12 step:11567 [D loss: 0.636715, acc.: 62.50%] [G loss: 0.998112]\n",
      "epoch:12 step:11568 [D loss: 0.704281, acc.: 47.66%] [G loss: 0.847458]\n",
      "epoch:12 step:11569 [D loss: 0.768208, acc.: 49.22%] [G loss: 0.899157]\n",
      "epoch:12 step:11570 [D loss: 0.654247, acc.: 60.16%] [G loss: 0.913665]\n",
      "epoch:12 step:11571 [D loss: 0.630820, acc.: 65.62%] [G loss: 1.074210]\n",
      "epoch:12 step:11572 [D loss: 0.575971, acc.: 72.66%] [G loss: 1.010915]\n",
      "epoch:12 step:11573 [D loss: 0.703368, acc.: 55.47%] [G loss: 1.064874]\n",
      "epoch:12 step:11574 [D loss: 0.708819, acc.: 50.00%] [G loss: 0.976504]\n",
      "epoch:12 step:11575 [D loss: 0.698430, acc.: 55.47%] [G loss: 0.992602]\n",
      "epoch:12 step:11576 [D loss: 0.771880, acc.: 46.88%] [G loss: 0.937264]\n",
      "epoch:12 step:11577 [D loss: 0.617370, acc.: 67.97%] [G loss: 1.057479]\n",
      "epoch:12 step:11578 [D loss: 0.633889, acc.: 65.62%] [G loss: 1.013935]\n",
      "epoch:12 step:11579 [D loss: 0.682903, acc.: 58.59%] [G loss: 0.871333]\n",
      "epoch:12 step:11580 [D loss: 0.666913, acc.: 58.59%] [G loss: 1.039510]\n",
      "epoch:12 step:11581 [D loss: 0.679350, acc.: 62.50%] [G loss: 0.876450]\n",
      "epoch:12 step:11582 [D loss: 0.609541, acc.: 66.41%] [G loss: 0.920732]\n",
      "epoch:12 step:11583 [D loss: 0.704576, acc.: 55.47%] [G loss: 0.886766]\n",
      "epoch:12 step:11584 [D loss: 0.666626, acc.: 61.72%] [G loss: 1.009227]\n",
      "epoch:12 step:11585 [D loss: 0.765970, acc.: 47.66%] [G loss: 1.017757]\n",
      "epoch:12 step:11586 [D loss: 0.749381, acc.: 49.22%] [G loss: 0.861250]\n",
      "epoch:12 step:11587 [D loss: 0.661473, acc.: 60.16%] [G loss: 0.902504]\n",
      "epoch:12 step:11588 [D loss: 0.611565, acc.: 70.31%] [G loss: 1.046006]\n",
      "epoch:12 step:11589 [D loss: 0.653137, acc.: 65.62%] [G loss: 0.918357]\n",
      "epoch:12 step:11590 [D loss: 0.550253, acc.: 75.78%] [G loss: 0.987194]\n",
      "epoch:12 step:11591 [D loss: 0.528194, acc.: 75.78%] [G loss: 0.917053]\n",
      "epoch:12 step:11592 [D loss: 0.659993, acc.: 58.59%] [G loss: 1.060586]\n",
      "epoch:12 step:11593 [D loss: 0.762755, acc.: 46.88%] [G loss: 1.017322]\n",
      "epoch:12 step:11594 [D loss: 0.658563, acc.: 60.94%] [G loss: 0.892847]\n",
      "epoch:12 step:11595 [D loss: 0.702134, acc.: 62.50%] [G loss: 0.824717]\n",
      "epoch:12 step:11596 [D loss: 0.625115, acc.: 70.31%] [G loss: 0.989916]\n",
      "epoch:12 step:11597 [D loss: 0.629192, acc.: 57.81%] [G loss: 0.976444]\n",
      "epoch:12 step:11598 [D loss: 0.569202, acc.: 69.53%] [G loss: 1.023441]\n",
      "epoch:12 step:11599 [D loss: 0.669898, acc.: 60.16%] [G loss: 0.903597]\n",
      "epoch:12 step:11600 [D loss: 0.704357, acc.: 53.91%] [G loss: 0.956794]\n",
      "##############\n",
      "[2.22199856 1.14049177 5.33091862 4.37992672 2.60768747 5.35738775\n",
      " 3.89895134 4.36029344 3.64917671 3.58980498]\n",
      "##########\n",
      "epoch:12 step:11601 [D loss: 0.682224, acc.: 59.38%] [G loss: 1.049761]\n",
      "epoch:12 step:11602 [D loss: 0.546537, acc.: 74.22%] [G loss: 0.996236]\n",
      "epoch:12 step:11603 [D loss: 0.596810, acc.: 67.97%] [G loss: 1.081650]\n",
      "epoch:12 step:11604 [D loss: 0.627670, acc.: 65.62%] [G loss: 0.987919]\n",
      "epoch:12 step:11605 [D loss: 0.678025, acc.: 56.25%] [G loss: 1.053571]\n",
      "epoch:12 step:11606 [D loss: 0.633647, acc.: 62.50%] [G loss: 1.027786]\n",
      "epoch:12 step:11607 [D loss: 0.680173, acc.: 59.38%] [G loss: 0.825220]\n",
      "epoch:12 step:11608 [D loss: 0.694829, acc.: 53.12%] [G loss: 0.981065]\n",
      "epoch:12 step:11609 [D loss: 0.602354, acc.: 68.75%] [G loss: 1.092315]\n",
      "epoch:12 step:11610 [D loss: 0.611085, acc.: 70.31%] [G loss: 0.941604]\n",
      "epoch:12 step:11611 [D loss: 0.621281, acc.: 66.41%] [G loss: 0.927781]\n",
      "epoch:12 step:11612 [D loss: 0.609757, acc.: 70.31%] [G loss: 0.986127]\n",
      "epoch:12 step:11613 [D loss: 0.699375, acc.: 60.94%] [G loss: 0.933246]\n",
      "epoch:12 step:11614 [D loss: 0.590319, acc.: 75.00%] [G loss: 1.005008]\n",
      "epoch:12 step:11615 [D loss: 0.654611, acc.: 60.16%] [G loss: 0.990990]\n",
      "epoch:12 step:11616 [D loss: 0.718385, acc.: 55.47%] [G loss: 0.955745]\n",
      "epoch:12 step:11617 [D loss: 0.717406, acc.: 53.12%] [G loss: 0.888860]\n",
      "epoch:12 step:11618 [D loss: 0.722192, acc.: 53.91%] [G loss: 0.839619]\n",
      "epoch:12 step:11619 [D loss: 0.768631, acc.: 45.31%] [G loss: 0.956101]\n",
      "epoch:12 step:11620 [D loss: 0.777874, acc.: 40.62%] [G loss: 0.958379]\n",
      "epoch:12 step:11621 [D loss: 0.709654, acc.: 50.78%] [G loss: 0.829835]\n",
      "epoch:12 step:11622 [D loss: 0.659075, acc.: 60.94%] [G loss: 0.936918]\n",
      "epoch:12 step:11623 [D loss: 0.646865, acc.: 58.59%] [G loss: 0.989880]\n",
      "epoch:12 step:11624 [D loss: 0.558075, acc.: 72.66%] [G loss: 1.011756]\n",
      "epoch:12 step:11625 [D loss: 0.583418, acc.: 70.31%] [G loss: 0.977443]\n",
      "epoch:12 step:11626 [D loss: 0.698316, acc.: 58.59%] [G loss: 1.029894]\n",
      "epoch:12 step:11627 [D loss: 0.698728, acc.: 55.47%] [G loss: 0.957402]\n",
      "epoch:12 step:11628 [D loss: 0.657193, acc.: 64.06%] [G loss: 0.961966]\n",
      "epoch:12 step:11629 [D loss: 0.677477, acc.: 62.50%] [G loss: 0.890054]\n",
      "epoch:12 step:11630 [D loss: 0.659306, acc.: 58.59%] [G loss: 0.882113]\n",
      "epoch:12 step:11631 [D loss: 0.614058, acc.: 72.66%] [G loss: 0.957899]\n",
      "epoch:12 step:11632 [D loss: 0.608767, acc.: 73.44%] [G loss: 0.864662]\n",
      "epoch:12 step:11633 [D loss: 0.630827, acc.: 64.06%] [G loss: 0.905664]\n",
      "epoch:12 step:11634 [D loss: 0.635465, acc.: 61.72%] [G loss: 0.856397]\n",
      "epoch:12 step:11635 [D loss: 0.656562, acc.: 65.62%] [G loss: 0.885945]\n",
      "epoch:12 step:11636 [D loss: 0.658291, acc.: 60.94%] [G loss: 0.955423]\n",
      "epoch:12 step:11637 [D loss: 0.693143, acc.: 50.00%] [G loss: 0.998466]\n",
      "epoch:12 step:11638 [D loss: 0.644170, acc.: 60.16%] [G loss: 1.024219]\n",
      "epoch:12 step:11639 [D loss: 0.605749, acc.: 69.53%] [G loss: 0.929291]\n",
      "epoch:12 step:11640 [D loss: 0.621825, acc.: 66.41%] [G loss: 0.906975]\n",
      "epoch:12 step:11641 [D loss: 0.628374, acc.: 64.06%] [G loss: 0.982914]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11642 [D loss: 0.663026, acc.: 56.25%] [G loss: 0.886362]\n",
      "epoch:12 step:11643 [D loss: 0.561481, acc.: 76.56%] [G loss: 1.041401]\n",
      "epoch:12 step:11644 [D loss: 0.694296, acc.: 52.34%] [G loss: 1.033433]\n",
      "epoch:12 step:11645 [D loss: 0.650105, acc.: 60.94%] [G loss: 0.978113]\n",
      "epoch:12 step:11646 [D loss: 0.649065, acc.: 61.72%] [G loss: 0.991085]\n",
      "epoch:12 step:11647 [D loss: 0.679507, acc.: 58.59%] [G loss: 1.165388]\n",
      "epoch:12 step:11648 [D loss: 0.663950, acc.: 60.94%] [G loss: 0.827467]\n",
      "epoch:12 step:11649 [D loss: 0.434359, acc.: 87.50%] [G loss: 1.324290]\n",
      "epoch:12 step:11650 [D loss: 0.591438, acc.: 67.97%] [G loss: 1.018046]\n",
      "epoch:12 step:11651 [D loss: 0.615756, acc.: 64.06%] [G loss: 1.033168]\n",
      "epoch:12 step:11652 [D loss: 0.702139, acc.: 56.25%] [G loss: 0.980140]\n",
      "epoch:12 step:11653 [D loss: 0.667698, acc.: 55.47%] [G loss: 0.963355]\n",
      "epoch:12 step:11654 [D loss: 0.649388, acc.: 60.94%] [G loss: 1.061395]\n",
      "epoch:12 step:11655 [D loss: 0.719731, acc.: 47.66%] [G loss: 0.876511]\n",
      "epoch:12 step:11656 [D loss: 0.701475, acc.: 58.59%] [G loss: 0.875161]\n",
      "epoch:12 step:11657 [D loss: 0.696668, acc.: 53.91%] [G loss: 0.910170]\n",
      "epoch:12 step:11658 [D loss: 0.636423, acc.: 62.50%] [G loss: 0.927910]\n",
      "epoch:12 step:11659 [D loss: 0.728598, acc.: 49.22%] [G loss: 0.898088]\n",
      "epoch:12 step:11660 [D loss: 0.670731, acc.: 62.50%] [G loss: 0.852237]\n",
      "epoch:12 step:11661 [D loss: 0.743921, acc.: 55.47%] [G loss: 0.869276]\n",
      "epoch:12 step:11662 [D loss: 0.661042, acc.: 60.94%] [G loss: 0.904565]\n",
      "epoch:12 step:11663 [D loss: 0.585992, acc.: 73.44%] [G loss: 0.991268]\n",
      "epoch:12 step:11664 [D loss: 0.615041, acc.: 64.84%] [G loss: 1.097114]\n",
      "epoch:12 step:11665 [D loss: 0.675015, acc.: 60.94%] [G loss: 0.889610]\n",
      "epoch:12 step:11666 [D loss: 0.767005, acc.: 42.19%] [G loss: 0.812322]\n",
      "epoch:12 step:11667 [D loss: 0.766506, acc.: 48.44%] [G loss: 0.888351]\n",
      "epoch:12 step:11668 [D loss: 0.601606, acc.: 70.31%] [G loss: 0.966035]\n",
      "epoch:12 step:11669 [D loss: 0.725486, acc.: 50.78%] [G loss: 0.912615]\n",
      "epoch:12 step:11670 [D loss: 0.795749, acc.: 44.53%] [G loss: 0.902506]\n",
      "epoch:12 step:11671 [D loss: 0.632825, acc.: 62.50%] [G loss: 0.958080]\n",
      "epoch:12 step:11672 [D loss: 0.507676, acc.: 80.47%] [G loss: 1.072946]\n",
      "epoch:12 step:11673 [D loss: 0.579106, acc.: 75.00%] [G loss: 1.031275]\n",
      "epoch:12 step:11674 [D loss: 0.630541, acc.: 67.19%] [G loss: 1.004786]\n",
      "epoch:12 step:11675 [D loss: 0.792197, acc.: 44.53%] [G loss: 1.016564]\n",
      "epoch:12 step:11676 [D loss: 0.830688, acc.: 38.28%] [G loss: 0.929631]\n",
      "epoch:12 step:11677 [D loss: 0.718227, acc.: 53.12%] [G loss: 0.978945]\n",
      "epoch:12 step:11678 [D loss: 0.595658, acc.: 71.09%] [G loss: 1.055578]\n",
      "epoch:12 step:11679 [D loss: 0.663976, acc.: 59.38%] [G loss: 1.024032]\n",
      "epoch:12 step:11680 [D loss: 0.608998, acc.: 70.31%] [G loss: 1.134409]\n",
      "epoch:12 step:11681 [D loss: 0.738199, acc.: 52.34%] [G loss: 1.014798]\n",
      "epoch:12 step:11682 [D loss: 0.730133, acc.: 52.34%] [G loss: 0.982055]\n",
      "epoch:12 step:11683 [D loss: 0.735684, acc.: 50.00%] [G loss: 0.986195]\n",
      "epoch:12 step:11684 [D loss: 0.602363, acc.: 64.84%] [G loss: 1.076302]\n",
      "epoch:12 step:11685 [D loss: 0.662636, acc.: 53.12%] [G loss: 0.983064]\n",
      "epoch:12 step:11686 [D loss: 0.682854, acc.: 56.25%] [G loss: 0.893551]\n",
      "epoch:12 step:11687 [D loss: 0.582637, acc.: 69.53%] [G loss: 1.064804]\n",
      "epoch:12 step:11688 [D loss: 0.672352, acc.: 60.16%] [G loss: 0.975290]\n",
      "epoch:12 step:11689 [D loss: 0.609447, acc.: 66.41%] [G loss: 1.064235]\n",
      "epoch:12 step:11690 [D loss: 0.645701, acc.: 57.03%] [G loss: 0.981034]\n",
      "epoch:12 step:11691 [D loss: 0.594121, acc.: 69.53%] [G loss: 0.912397]\n",
      "epoch:12 step:11692 [D loss: 0.643669, acc.: 61.72%] [G loss: 0.931645]\n",
      "epoch:12 step:11693 [D loss: 0.588748, acc.: 68.75%] [G loss: 1.038526]\n",
      "epoch:12 step:11694 [D loss: 0.588393, acc.: 71.88%] [G loss: 0.850342]\n",
      "epoch:12 step:11695 [D loss: 0.632265, acc.: 61.72%] [G loss: 0.910069]\n",
      "epoch:12 step:11696 [D loss: 0.533965, acc.: 78.91%] [G loss: 0.995341]\n",
      "epoch:12 step:11697 [D loss: 0.498495, acc.: 81.25%] [G loss: 1.187619]\n",
      "epoch:12 step:11698 [D loss: 0.600249, acc.: 68.75%] [G loss: 1.096718]\n",
      "epoch:12 step:11699 [D loss: 0.484647, acc.: 82.81%] [G loss: 1.307353]\n",
      "epoch:12 step:11700 [D loss: 0.546492, acc.: 75.00%] [G loss: 1.037427]\n",
      "epoch:12 step:11701 [D loss: 0.425446, acc.: 83.59%] [G loss: 1.251405]\n",
      "epoch:12 step:11702 [D loss: 0.847092, acc.: 39.84%] [G loss: 0.933637]\n",
      "epoch:12 step:11703 [D loss: 0.696126, acc.: 57.81%] [G loss: 1.103770]\n",
      "epoch:12 step:11704 [D loss: 0.682881, acc.: 56.25%] [G loss: 1.016118]\n",
      "epoch:12 step:11705 [D loss: 0.758924, acc.: 47.66%] [G loss: 0.835450]\n",
      "epoch:12 step:11706 [D loss: 0.702432, acc.: 53.12%] [G loss: 0.991372]\n",
      "epoch:12 step:11707 [D loss: 0.740135, acc.: 50.00%] [G loss: 0.877534]\n",
      "epoch:12 step:11708 [D loss: 0.550433, acc.: 75.78%] [G loss: 1.127175]\n",
      "epoch:12 step:11709 [D loss: 0.613411, acc.: 68.75%] [G loss: 1.000380]\n",
      "epoch:12 step:11710 [D loss: 0.648656, acc.: 64.84%] [G loss: 0.979758]\n",
      "epoch:12 step:11711 [D loss: 0.748500, acc.: 48.44%] [G loss: 1.092416]\n",
      "epoch:12 step:11712 [D loss: 0.548627, acc.: 75.00%] [G loss: 1.198357]\n",
      "epoch:12 step:11713 [D loss: 0.593344, acc.: 66.41%] [G loss: 1.110395]\n",
      "epoch:12 step:11714 [D loss: 0.564961, acc.: 69.53%] [G loss: 1.119981]\n",
      "epoch:12 step:11715 [D loss: 0.534857, acc.: 74.22%] [G loss: 1.097422]\n",
      "epoch:12 step:11716 [D loss: 0.540873, acc.: 70.31%] [G loss: 1.262282]\n",
      "epoch:12 step:11717 [D loss: 0.941276, acc.: 37.50%] [G loss: 0.898620]\n",
      "epoch:12 step:11718 [D loss: 0.758216, acc.: 49.22%] [G loss: 1.121232]\n",
      "epoch:12 step:11719 [D loss: 0.809509, acc.: 44.53%] [G loss: 0.934496]\n",
      "epoch:12 step:11720 [D loss: 0.681821, acc.: 57.03%] [G loss: 0.880383]\n",
      "epoch:12 step:11721 [D loss: 0.724921, acc.: 54.69%] [G loss: 0.956051]\n",
      "epoch:12 step:11722 [D loss: 0.686899, acc.: 57.03%] [G loss: 0.910537]\n",
      "epoch:12 step:11723 [D loss: 0.685894, acc.: 53.91%] [G loss: 0.952508]\n",
      "epoch:12 step:11724 [D loss: 0.750394, acc.: 49.22%] [G loss: 0.850007]\n",
      "epoch:12 step:11725 [D loss: 0.705164, acc.: 52.34%] [G loss: 0.937443]\n",
      "epoch:12 step:11726 [D loss: 0.690726, acc.: 54.69%] [G loss: 1.113164]\n",
      "epoch:12 step:11727 [D loss: 0.690948, acc.: 53.91%] [G loss: 1.140649]\n",
      "epoch:12 step:11728 [D loss: 0.609873, acc.: 66.41%] [G loss: 1.082822]\n",
      "epoch:12 step:11729 [D loss: 0.830514, acc.: 40.62%] [G loss: 0.954491]\n",
      "epoch:12 step:11730 [D loss: 0.594394, acc.: 69.53%] [G loss: 0.972553]\n",
      "epoch:12 step:11731 [D loss: 0.588168, acc.: 69.53%] [G loss: 1.094403]\n",
      "epoch:12 step:11732 [D loss: 0.626464, acc.: 64.84%] [G loss: 1.068390]\n",
      "epoch:12 step:11733 [D loss: 0.684106, acc.: 57.81%] [G loss: 1.019819]\n",
      "epoch:12 step:11734 [D loss: 0.644529, acc.: 67.97%] [G loss: 0.998105]\n",
      "epoch:12 step:11735 [D loss: 0.719878, acc.: 53.12%] [G loss: 0.899593]\n",
      "epoch:12 step:11736 [D loss: 0.635073, acc.: 65.62%] [G loss: 0.868039]\n",
      "epoch:12 step:11737 [D loss: 0.793307, acc.: 44.53%] [G loss: 0.912728]\n",
      "epoch:12 step:11738 [D loss: 0.662939, acc.: 62.50%] [G loss: 0.944259]\n",
      "epoch:12 step:11739 [D loss: 0.648701, acc.: 60.16%] [G loss: 0.829153]\n",
      "epoch:12 step:11740 [D loss: 0.595214, acc.: 70.31%] [G loss: 1.024858]\n",
      "epoch:12 step:11741 [D loss: 0.595777, acc.: 67.97%] [G loss: 0.959166]\n",
      "epoch:12 step:11742 [D loss: 0.534647, acc.: 76.56%] [G loss: 0.852854]\n",
      "epoch:12 step:11743 [D loss: 0.480598, acc.: 85.94%] [G loss: 1.172205]\n",
      "epoch:12 step:11744 [D loss: 0.790862, acc.: 46.88%] [G loss: 0.931642]\n",
      "epoch:12 step:11745 [D loss: 0.690690, acc.: 57.03%] [G loss: 0.945847]\n",
      "epoch:12 step:11746 [D loss: 0.693412, acc.: 58.59%] [G loss: 0.834999]\n",
      "epoch:12 step:11747 [D loss: 0.560654, acc.: 73.44%] [G loss: 0.891558]\n",
      "epoch:12 step:11748 [D loss: 0.568396, acc.: 76.56%] [G loss: 0.871532]\n",
      "epoch:12 step:11749 [D loss: 0.680515, acc.: 56.25%] [G loss: 0.877530]\n",
      "epoch:12 step:11750 [D loss: 0.692361, acc.: 54.69%] [G loss: 0.845999]\n",
      "epoch:12 step:11751 [D loss: 0.704082, acc.: 53.12%] [G loss: 0.878641]\n",
      "epoch:12 step:11752 [D loss: 0.614962, acc.: 68.75%] [G loss: 0.847062]\n",
      "epoch:12 step:11753 [D loss: 0.671066, acc.: 60.16%] [G loss: 0.888786]\n",
      "epoch:12 step:11754 [D loss: 0.677606, acc.: 57.81%] [G loss: 0.873838]\n",
      "epoch:12 step:11755 [D loss: 0.681765, acc.: 53.91%] [G loss: 0.952584]\n",
      "epoch:12 step:11756 [D loss: 0.655506, acc.: 57.81%] [G loss: 0.920809]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11757 [D loss: 0.530980, acc.: 73.44%] [G loss: 1.029498]\n",
      "epoch:12 step:11758 [D loss: 0.627068, acc.: 63.28%] [G loss: 0.969038]\n",
      "epoch:12 step:11759 [D loss: 0.554506, acc.: 71.88%] [G loss: 0.896773]\n",
      "epoch:12 step:11760 [D loss: 0.651793, acc.: 61.72%] [G loss: 0.831337]\n",
      "epoch:12 step:11761 [D loss: 0.667527, acc.: 60.94%] [G loss: 0.931721]\n",
      "epoch:12 step:11762 [D loss: 0.738189, acc.: 50.00%] [G loss: 0.853761]\n",
      "epoch:12 step:11763 [D loss: 0.691554, acc.: 56.25%] [G loss: 0.814581]\n",
      "epoch:12 step:11764 [D loss: 0.639347, acc.: 64.84%] [G loss: 0.890146]\n",
      "epoch:12 step:11765 [D loss: 0.701864, acc.: 57.03%] [G loss: 0.879700]\n",
      "epoch:12 step:11766 [D loss: 0.640138, acc.: 63.28%] [G loss: 0.946645]\n",
      "epoch:12 step:11767 [D loss: 0.598173, acc.: 72.66%] [G loss: 0.832701]\n",
      "epoch:12 step:11768 [D loss: 0.640449, acc.: 61.72%] [G loss: 0.980892]\n",
      "epoch:12 step:11769 [D loss: 0.576473, acc.: 72.66%] [G loss: 0.936321]\n",
      "epoch:12 step:11770 [D loss: 0.581067, acc.: 75.78%] [G loss: 0.933055]\n",
      "epoch:12 step:11771 [D loss: 0.606582, acc.: 66.41%] [G loss: 0.918090]\n",
      "epoch:12 step:11772 [D loss: 0.734437, acc.: 51.56%] [G loss: 1.020340]\n",
      "epoch:12 step:11773 [D loss: 0.614823, acc.: 67.97%] [G loss: 0.947815]\n",
      "epoch:12 step:11774 [D loss: 0.543561, acc.: 75.00%] [G loss: 0.955358]\n",
      "epoch:12 step:11775 [D loss: 0.771504, acc.: 48.44%] [G loss: 0.815631]\n",
      "epoch:12 step:11776 [D loss: 0.688849, acc.: 58.59%] [G loss: 0.947672]\n",
      "epoch:12 step:11777 [D loss: 0.706940, acc.: 53.12%] [G loss: 0.827098]\n",
      "epoch:12 step:11778 [D loss: 0.627115, acc.: 65.62%] [G loss: 0.966938]\n",
      "epoch:12 step:11779 [D loss: 0.648713, acc.: 59.38%] [G loss: 0.920067]\n",
      "epoch:12 step:11780 [D loss: 0.545883, acc.: 76.56%] [G loss: 1.068666]\n",
      "epoch:12 step:11781 [D loss: 0.520866, acc.: 82.03%] [G loss: 1.130810]\n",
      "epoch:12 step:11782 [D loss: 0.560711, acc.: 69.53%] [G loss: 0.892740]\n",
      "epoch:12 step:11783 [D loss: 0.654581, acc.: 62.50%] [G loss: 0.806987]\n",
      "epoch:12 step:11784 [D loss: 0.630782, acc.: 67.19%] [G loss: 0.927812]\n",
      "epoch:12 step:11785 [D loss: 0.670574, acc.: 55.47%] [G loss: 0.995127]\n",
      "epoch:12 step:11786 [D loss: 0.783159, acc.: 46.09%] [G loss: 0.997726]\n",
      "epoch:12 step:11787 [D loss: 0.703890, acc.: 55.47%] [G loss: 0.957736]\n",
      "epoch:12 step:11788 [D loss: 0.683577, acc.: 57.81%] [G loss: 0.900187]\n",
      "epoch:12 step:11789 [D loss: 0.650807, acc.: 64.06%] [G loss: 0.915398]\n",
      "epoch:12 step:11790 [D loss: 0.578871, acc.: 72.66%] [G loss: 0.854320]\n",
      "epoch:12 step:11791 [D loss: 0.631839, acc.: 63.28%] [G loss: 0.973872]\n",
      "epoch:12 step:11792 [D loss: 0.675711, acc.: 59.38%] [G loss: 0.894560]\n",
      "epoch:12 step:11793 [D loss: 0.518779, acc.: 78.91%] [G loss: 1.072601]\n",
      "epoch:12 step:11794 [D loss: 0.551633, acc.: 75.78%] [G loss: 1.033844]\n",
      "epoch:12 step:11795 [D loss: 0.512601, acc.: 77.34%] [G loss: 1.253447]\n",
      "epoch:12 step:11796 [D loss: 0.566325, acc.: 69.53%] [G loss: 0.884981]\n",
      "epoch:12 step:11797 [D loss: 0.774386, acc.: 47.66%] [G loss: 0.902679]\n",
      "epoch:12 step:11798 [D loss: 0.597924, acc.: 69.53%] [G loss: 1.070482]\n",
      "epoch:12 step:11799 [D loss: 0.531920, acc.: 75.00%] [G loss: 1.097780]\n",
      "epoch:12 step:11800 [D loss: 0.511278, acc.: 79.69%] [G loss: 0.976388]\n",
      "##############\n",
      "[2.22517819 1.54632778 5.40598979 4.3058665  3.27733131 5.22683691\n",
      " 4.13567453 4.50346603 3.79418961 3.87857122]\n",
      "##########\n",
      "epoch:12 step:11801 [D loss: 0.542769, acc.: 75.78%] [G loss: 1.060471]\n",
      "epoch:12 step:11802 [D loss: 0.607487, acc.: 69.53%] [G loss: 1.189417]\n",
      "epoch:12 step:11803 [D loss: 0.766849, acc.: 44.53%] [G loss: 1.014949]\n",
      "epoch:12 step:11804 [D loss: 0.748889, acc.: 50.00%] [G loss: 0.990454]\n",
      "epoch:12 step:11805 [D loss: 0.621945, acc.: 69.53%] [G loss: 0.923539]\n",
      "epoch:12 step:11806 [D loss: 0.646106, acc.: 62.50%] [G loss: 0.927173]\n",
      "epoch:12 step:11807 [D loss: 0.642193, acc.: 60.94%] [G loss: 0.971916]\n",
      "epoch:12 step:11808 [D loss: 0.589003, acc.: 70.31%] [G loss: 0.975241]\n",
      "epoch:12 step:11809 [D loss: 0.683166, acc.: 54.69%] [G loss: 1.040015]\n",
      "epoch:12 step:11810 [D loss: 0.751636, acc.: 46.09%] [G loss: 0.847919]\n",
      "epoch:12 step:11811 [D loss: 0.665750, acc.: 57.81%] [G loss: 1.013288]\n",
      "epoch:12 step:11812 [D loss: 0.699209, acc.: 56.25%] [G loss: 1.012378]\n",
      "epoch:12 step:11813 [D loss: 0.569936, acc.: 73.44%] [G loss: 1.073426]\n",
      "epoch:12 step:11814 [D loss: 0.652631, acc.: 67.97%] [G loss: 0.910637]\n",
      "epoch:12 step:11815 [D loss: 0.686595, acc.: 55.47%] [G loss: 0.904868]\n",
      "epoch:12 step:11816 [D loss: 0.695062, acc.: 60.16%] [G loss: 0.876329]\n",
      "epoch:12 step:11817 [D loss: 0.665627, acc.: 62.50%] [G loss: 0.819644]\n",
      "epoch:12 step:11818 [D loss: 0.616743, acc.: 63.28%] [G loss: 1.023745]\n",
      "epoch:12 step:11819 [D loss: 0.676341, acc.: 57.03%] [G loss: 0.941725]\n",
      "epoch:12 step:11820 [D loss: 0.642928, acc.: 61.72%] [G loss: 1.119761]\n",
      "epoch:12 step:11821 [D loss: 0.749537, acc.: 49.22%] [G loss: 0.989172]\n",
      "epoch:12 step:11822 [D loss: 0.707891, acc.: 51.56%] [G loss: 0.954241]\n",
      "epoch:12 step:11823 [D loss: 0.658755, acc.: 53.91%] [G loss: 1.048726]\n",
      "epoch:12 step:11824 [D loss: 0.698249, acc.: 54.69%] [G loss: 0.904689]\n",
      "epoch:12 step:11825 [D loss: 0.676023, acc.: 63.28%] [G loss: 0.975928]\n",
      "epoch:12 step:11826 [D loss: 0.732177, acc.: 52.34%] [G loss: 0.940660]\n",
      "epoch:12 step:11827 [D loss: 0.683345, acc.: 58.59%] [G loss: 0.874149]\n",
      "epoch:12 step:11828 [D loss: 0.676525, acc.: 58.59%] [G loss: 0.927899]\n",
      "epoch:12 step:11829 [D loss: 0.648423, acc.: 61.72%] [G loss: 1.012090]\n",
      "epoch:12 step:11830 [D loss: 0.648030, acc.: 61.72%] [G loss: 0.983827]\n",
      "epoch:12 step:11831 [D loss: 0.535799, acc.: 75.00%] [G loss: 1.099273]\n",
      "epoch:12 step:11832 [D loss: 0.600212, acc.: 65.62%] [G loss: 0.928930]\n",
      "epoch:12 step:11833 [D loss: 0.596643, acc.: 71.09%] [G loss: 1.037730]\n",
      "epoch:12 step:11834 [D loss: 0.640032, acc.: 64.06%] [G loss: 1.043965]\n",
      "epoch:12 step:11835 [D loss: 0.706547, acc.: 55.47%] [G loss: 1.012099]\n",
      "epoch:12 step:11836 [D loss: 0.641558, acc.: 64.84%] [G loss: 0.901587]\n",
      "epoch:12 step:11837 [D loss: 0.631425, acc.: 65.62%] [G loss: 0.928877]\n",
      "epoch:12 step:11838 [D loss: 0.675506, acc.: 55.47%] [G loss: 0.941766]\n",
      "epoch:12 step:11839 [D loss: 0.672424, acc.: 56.25%] [G loss: 0.911809]\n",
      "epoch:12 step:11840 [D loss: 0.645872, acc.: 62.50%] [G loss: 0.929490]\n",
      "epoch:12 step:11841 [D loss: 0.743747, acc.: 50.78%] [G loss: 0.950530]\n",
      "epoch:12 step:11842 [D loss: 0.613876, acc.: 69.53%] [G loss: 0.899613]\n",
      "epoch:12 step:11843 [D loss: 0.685389, acc.: 54.69%] [G loss: 1.287175]\n",
      "epoch:12 step:11844 [D loss: 0.733200, acc.: 48.44%] [G loss: 0.855683]\n",
      "epoch:12 step:11845 [D loss: 0.666038, acc.: 61.72%] [G loss: 0.782674]\n",
      "epoch:12 step:11846 [D loss: 0.665905, acc.: 58.59%] [G loss: 0.923044]\n",
      "epoch:12 step:11847 [D loss: 0.608747, acc.: 65.62%] [G loss: 0.985768]\n",
      "epoch:12 step:11848 [D loss: 0.667339, acc.: 60.16%] [G loss: 0.906979]\n",
      "epoch:12 step:11849 [D loss: 0.624524, acc.: 69.53%] [G loss: 1.011260]\n",
      "epoch:12 step:11850 [D loss: 0.739387, acc.: 48.44%] [G loss: 0.874164]\n",
      "epoch:12 step:11851 [D loss: 0.666984, acc.: 62.50%] [G loss: 0.954135]\n",
      "epoch:12 step:11852 [D loss: 0.702221, acc.: 54.69%] [G loss: 0.879638]\n",
      "epoch:12 step:11853 [D loss: 0.683568, acc.: 52.34%] [G loss: 0.734316]\n",
      "epoch:12 step:11854 [D loss: 0.636152, acc.: 62.50%] [G loss: 0.920495]\n",
      "epoch:12 step:11855 [D loss: 0.638568, acc.: 63.28%] [G loss: 1.039540]\n",
      "epoch:12 step:11856 [D loss: 0.702671, acc.: 53.12%] [G loss: 0.908214]\n",
      "epoch:12 step:11857 [D loss: 0.587500, acc.: 71.09%] [G loss: 1.009365]\n",
      "epoch:12 step:11858 [D loss: 0.674283, acc.: 57.81%] [G loss: 0.901943]\n",
      "epoch:12 step:11859 [D loss: 0.652836, acc.: 65.62%] [G loss: 0.969214]\n",
      "epoch:12 step:11860 [D loss: 0.623244, acc.: 66.41%] [G loss: 0.943753]\n",
      "epoch:12 step:11861 [D loss: 0.710413, acc.: 49.22%] [G loss: 0.937951]\n",
      "epoch:12 step:11862 [D loss: 0.751584, acc.: 44.53%] [G loss: 0.896964]\n",
      "epoch:12 step:11863 [D loss: 0.688965, acc.: 58.59%] [G loss: 0.952615]\n",
      "epoch:12 step:11864 [D loss: 0.642184, acc.: 60.94%] [G loss: 1.024558]\n",
      "epoch:12 step:11865 [D loss: 0.673323, acc.: 59.38%] [G loss: 0.841067]\n",
      "epoch:12 step:11866 [D loss: 0.741964, acc.: 49.22%] [G loss: 0.977886]\n",
      "epoch:12 step:11867 [D loss: 0.662869, acc.: 57.81%] [G loss: 0.861220]\n",
      "epoch:12 step:11868 [D loss: 0.674202, acc.: 55.47%] [G loss: 0.954014]\n",
      "epoch:12 step:11869 [D loss: 0.766339, acc.: 43.75%] [G loss: 0.805460]\n",
      "epoch:12 step:11870 [D loss: 0.706839, acc.: 54.69%] [G loss: 0.958986]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11871 [D loss: 0.731229, acc.: 50.00%] [G loss: 0.885628]\n",
      "epoch:12 step:11872 [D loss: 0.679346, acc.: 55.47%] [G loss: 0.907421]\n",
      "epoch:12 step:11873 [D loss: 0.629046, acc.: 63.28%] [G loss: 0.874028]\n",
      "epoch:12 step:11874 [D loss: 0.685213, acc.: 61.72%] [G loss: 0.911371]\n",
      "epoch:12 step:11875 [D loss: 0.660059, acc.: 59.38%] [G loss: 0.923851]\n",
      "epoch:12 step:11876 [D loss: 0.575502, acc.: 71.88%] [G loss: 0.953133]\n",
      "epoch:12 step:11877 [D loss: 0.585961, acc.: 70.31%] [G loss: 0.932795]\n",
      "epoch:12 step:11878 [D loss: 0.637688, acc.: 67.97%] [G loss: 0.978319]\n",
      "epoch:12 step:11879 [D loss: 0.601350, acc.: 63.28%] [G loss: 1.058018]\n",
      "epoch:12 step:11880 [D loss: 0.668545, acc.: 60.16%] [G loss: 1.132855]\n",
      "epoch:12 step:11881 [D loss: 0.659028, acc.: 61.72%] [G loss: 1.090802]\n",
      "epoch:12 step:11882 [D loss: 0.679134, acc.: 54.69%] [G loss: 0.900571]\n",
      "epoch:12 step:11883 [D loss: 0.688346, acc.: 59.38%] [G loss: 1.028182]\n",
      "epoch:12 step:11884 [D loss: 0.637759, acc.: 67.97%] [G loss: 1.097392]\n",
      "epoch:12 step:11885 [D loss: 0.675230, acc.: 56.25%] [G loss: 0.993726]\n",
      "epoch:12 step:11886 [D loss: 0.525609, acc.: 79.69%] [G loss: 1.167683]\n",
      "epoch:12 step:11887 [D loss: 0.621808, acc.: 60.94%] [G loss: 1.124432]\n",
      "epoch:12 step:11888 [D loss: 0.694005, acc.: 58.59%] [G loss: 0.903199]\n",
      "epoch:12 step:11889 [D loss: 0.684089, acc.: 58.59%] [G loss: 0.953066]\n",
      "epoch:12 step:11890 [D loss: 0.732253, acc.: 51.56%] [G loss: 0.933130]\n",
      "epoch:12 step:11891 [D loss: 0.623946, acc.: 65.62%] [G loss: 0.942075]\n",
      "epoch:12 step:11892 [D loss: 0.521059, acc.: 79.69%] [G loss: 0.913599]\n",
      "epoch:12 step:11893 [D loss: 0.575960, acc.: 77.34%] [G loss: 1.000884]\n",
      "epoch:12 step:11894 [D loss: 0.543967, acc.: 73.44%] [G loss: 0.981559]\n",
      "epoch:12 step:11895 [D loss: 0.638079, acc.: 63.28%] [G loss: 0.895691]\n",
      "epoch:12 step:11896 [D loss: 0.820598, acc.: 42.97%] [G loss: 0.816439]\n",
      "epoch:12 step:11897 [D loss: 0.758097, acc.: 46.88%] [G loss: 0.939749]\n",
      "epoch:12 step:11898 [D loss: 0.762395, acc.: 50.78%] [G loss: 0.809240]\n",
      "epoch:12 step:11899 [D loss: 0.723111, acc.: 50.00%] [G loss: 0.841853]\n",
      "epoch:12 step:11900 [D loss: 0.670394, acc.: 62.50%] [G loss: 0.921567]\n",
      "epoch:12 step:11901 [D loss: 0.771686, acc.: 46.88%] [G loss: 0.994208]\n",
      "epoch:12 step:11902 [D loss: 0.726576, acc.: 51.56%] [G loss: 0.932588]\n",
      "epoch:12 step:11903 [D loss: 0.723368, acc.: 51.56%] [G loss: 0.920219]\n",
      "epoch:12 step:11904 [D loss: 0.618136, acc.: 64.84%] [G loss: 0.976338]\n",
      "epoch:12 step:11905 [D loss: 0.614646, acc.: 63.28%] [G loss: 0.949762]\n",
      "epoch:12 step:11906 [D loss: 0.754623, acc.: 50.78%] [G loss: 0.865007]\n",
      "epoch:12 step:11907 [D loss: 0.668498, acc.: 56.25%] [G loss: 0.991495]\n",
      "epoch:12 step:11908 [D loss: 0.653994, acc.: 62.50%] [G loss: 1.034648]\n",
      "epoch:12 step:11909 [D loss: 0.590667, acc.: 71.09%] [G loss: 1.133827]\n",
      "epoch:12 step:11910 [D loss: 0.639953, acc.: 59.38%] [G loss: 0.973314]\n",
      "epoch:12 step:11911 [D loss: 0.628061, acc.: 63.28%] [G loss: 0.904787]\n",
      "epoch:12 step:11912 [D loss: 0.627184, acc.: 60.16%] [G loss: 1.068792]\n",
      "epoch:12 step:11913 [D loss: 0.644154, acc.: 58.59%] [G loss: 0.990804]\n",
      "epoch:12 step:11914 [D loss: 0.680748, acc.: 60.16%] [G loss: 0.917550]\n",
      "epoch:12 step:11915 [D loss: 0.694701, acc.: 52.34%] [G loss: 0.942031]\n",
      "epoch:12 step:11916 [D loss: 0.633972, acc.: 68.75%] [G loss: 0.957289]\n",
      "epoch:12 step:11917 [D loss: 0.673031, acc.: 64.84%] [G loss: 0.858886]\n",
      "epoch:12 step:11918 [D loss: 0.719232, acc.: 52.34%] [G loss: 0.998222]\n",
      "epoch:12 step:11919 [D loss: 0.762639, acc.: 48.44%] [G loss: 0.836278]\n",
      "epoch:12 step:11920 [D loss: 0.612403, acc.: 62.50%] [G loss: 0.840968]\n",
      "epoch:12 step:11921 [D loss: 0.673890, acc.: 57.03%] [G loss: 0.991647]\n",
      "epoch:12 step:11922 [D loss: 0.654155, acc.: 57.03%] [G loss: 0.863792]\n",
      "epoch:12 step:11923 [D loss: 0.682811, acc.: 55.47%] [G loss: 0.873296]\n",
      "epoch:12 step:11924 [D loss: 0.543964, acc.: 77.34%] [G loss: 0.967195]\n",
      "epoch:12 step:11925 [D loss: 0.599210, acc.: 69.53%] [G loss: 0.846262]\n",
      "epoch:12 step:11926 [D loss: 0.651905, acc.: 64.84%] [G loss: 1.014822]\n",
      "epoch:12 step:11927 [D loss: 0.711132, acc.: 52.34%] [G loss: 0.929060]\n",
      "epoch:12 step:11928 [D loss: 0.769342, acc.: 46.09%] [G loss: 0.798975]\n",
      "epoch:12 step:11929 [D loss: 0.667509, acc.: 63.28%] [G loss: 1.044378]\n",
      "epoch:12 step:11930 [D loss: 0.626875, acc.: 64.06%] [G loss: 0.919354]\n",
      "epoch:12 step:11931 [D loss: 0.656412, acc.: 60.94%] [G loss: 0.858103]\n",
      "epoch:12 step:11932 [D loss: 0.637615, acc.: 61.72%] [G loss: 0.926348]\n",
      "epoch:12 step:11933 [D loss: 0.585283, acc.: 71.09%] [G loss: 0.955207]\n",
      "epoch:12 step:11934 [D loss: 0.605864, acc.: 67.19%] [G loss: 1.084618]\n",
      "epoch:12 step:11935 [D loss: 0.706281, acc.: 56.25%] [G loss: 0.807190]\n",
      "epoch:12 step:11936 [D loss: 0.762373, acc.: 47.66%] [G loss: 0.891474]\n",
      "epoch:12 step:11937 [D loss: 0.638053, acc.: 59.38%] [G loss: 1.039195]\n",
      "epoch:12 step:11938 [D loss: 0.565481, acc.: 74.22%] [G loss: 0.980056]\n",
      "epoch:12 step:11939 [D loss: 0.613852, acc.: 64.84%] [G loss: 0.983599]\n",
      "epoch:12 step:11940 [D loss: 0.718131, acc.: 57.03%] [G loss: 0.925379]\n",
      "epoch:12 step:11941 [D loss: 0.744899, acc.: 47.66%] [G loss: 0.809945]\n",
      "epoch:12 step:11942 [D loss: 0.710467, acc.: 51.56%] [G loss: 0.937466]\n",
      "epoch:12 step:11943 [D loss: 0.610946, acc.: 67.19%] [G loss: 0.977984]\n",
      "epoch:12 step:11944 [D loss: 0.594313, acc.: 73.44%] [G loss: 0.984624]\n",
      "epoch:12 step:11945 [D loss: 0.529541, acc.: 77.34%] [G loss: 0.925870]\n",
      "epoch:12 step:11946 [D loss: 0.623143, acc.: 63.28%] [G loss: 0.906654]\n",
      "epoch:12 step:11947 [D loss: 0.751142, acc.: 43.75%] [G loss: 0.918808]\n",
      "epoch:12 step:11948 [D loss: 0.657339, acc.: 59.38%] [G loss: 0.833143]\n",
      "epoch:12 step:11949 [D loss: 0.675558, acc.: 60.16%] [G loss: 0.841275]\n",
      "epoch:12 step:11950 [D loss: 0.577863, acc.: 69.53%] [G loss: 0.849370]\n",
      "epoch:12 step:11951 [D loss: 0.482534, acc.: 80.47%] [G loss: 1.054879]\n",
      "epoch:12 step:11952 [D loss: 0.583657, acc.: 67.97%] [G loss: 0.941995]\n",
      "epoch:12 step:11953 [D loss: 0.588310, acc.: 70.31%] [G loss: 1.041830]\n",
      "epoch:12 step:11954 [D loss: 0.709031, acc.: 52.34%] [G loss: 0.921110]\n",
      "epoch:12 step:11955 [D loss: 0.625249, acc.: 67.19%] [G loss: 0.970192]\n",
      "epoch:12 step:11956 [D loss: 0.677946, acc.: 60.16%] [G loss: 0.803111]\n",
      "epoch:12 step:11957 [D loss: 0.583257, acc.: 71.09%] [G loss: 0.956697]\n",
      "epoch:12 step:11958 [D loss: 0.535762, acc.: 82.03%] [G loss: 1.052899]\n",
      "epoch:12 step:11959 [D loss: 0.640506, acc.: 62.50%] [G loss: 0.964047]\n",
      "epoch:12 step:11960 [D loss: 0.863797, acc.: 31.25%] [G loss: 0.826370]\n",
      "epoch:12 step:11961 [D loss: 0.722308, acc.: 53.91%] [G loss: 0.947670]\n",
      "epoch:12 step:11962 [D loss: 0.708045, acc.: 54.69%] [G loss: 0.917326]\n",
      "epoch:12 step:11963 [D loss: 0.642456, acc.: 64.84%] [G loss: 0.947215]\n",
      "epoch:12 step:11964 [D loss: 0.684262, acc.: 54.69%] [G loss: 0.918307]\n",
      "epoch:12 step:11965 [D loss: 0.730179, acc.: 51.56%] [G loss: 0.832476]\n",
      "epoch:12 step:11966 [D loss: 0.729858, acc.: 47.66%] [G loss: 0.834495]\n",
      "epoch:12 step:11967 [D loss: 0.667840, acc.: 58.59%] [G loss: 0.791066]\n",
      "epoch:12 step:11968 [D loss: 0.649980, acc.: 60.16%] [G loss: 0.902128]\n",
      "epoch:12 step:11969 [D loss: 0.665915, acc.: 59.38%] [G loss: 0.831118]\n",
      "epoch:12 step:11970 [D loss: 0.639371, acc.: 65.62%] [G loss: 1.118871]\n",
      "epoch:12 step:11971 [D loss: 0.635278, acc.: 67.19%] [G loss: 1.088174]\n",
      "epoch:12 step:11972 [D loss: 0.578534, acc.: 74.22%] [G loss: 1.079531]\n",
      "epoch:12 step:11973 [D loss: 0.653832, acc.: 56.25%] [G loss: 1.119546]\n",
      "epoch:12 step:11974 [D loss: 0.567110, acc.: 73.44%] [G loss: 0.965956]\n",
      "epoch:12 step:11975 [D loss: 0.595236, acc.: 70.31%] [G loss: 1.017115]\n",
      "epoch:12 step:11976 [D loss: 0.648248, acc.: 65.62%] [G loss: 0.964497]\n",
      "epoch:12 step:11977 [D loss: 0.679658, acc.: 58.59%] [G loss: 0.985732]\n",
      "epoch:12 step:11978 [D loss: 0.626985, acc.: 65.62%] [G loss: 0.999998]\n",
      "epoch:12 step:11979 [D loss: 0.633629, acc.: 67.19%] [G loss: 0.989012]\n",
      "epoch:12 step:11980 [D loss: 0.749809, acc.: 51.56%] [G loss: 0.780184]\n",
      "epoch:12 step:11981 [D loss: 0.696241, acc.: 53.12%] [G loss: 0.850743]\n",
      "epoch:12 step:11982 [D loss: 0.660379, acc.: 58.59%] [G loss: 0.801781]\n",
      "epoch:12 step:11983 [D loss: 0.683332, acc.: 53.12%] [G loss: 0.913682]\n",
      "epoch:12 step:11984 [D loss: 0.667919, acc.: 57.81%] [G loss: 0.887660]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11985 [D loss: 0.678987, acc.: 60.16%] [G loss: 0.893354]\n",
      "epoch:12 step:11986 [D loss: 0.645799, acc.: 64.06%] [G loss: 0.869839]\n",
      "epoch:12 step:11987 [D loss: 0.639743, acc.: 63.28%] [G loss: 0.945990]\n",
      "epoch:12 step:11988 [D loss: 0.665539, acc.: 60.94%] [G loss: 1.041133]\n",
      "epoch:12 step:11989 [D loss: 0.638705, acc.: 64.06%] [G loss: 0.985199]\n",
      "epoch:12 step:11990 [D loss: 0.598778, acc.: 70.31%] [G loss: 1.059555]\n",
      "epoch:12 step:11991 [D loss: 0.569956, acc.: 74.22%] [G loss: 1.060624]\n",
      "epoch:12 step:11992 [D loss: 0.713196, acc.: 51.56%] [G loss: 1.037715]\n",
      "epoch:12 step:11993 [D loss: 0.650696, acc.: 62.50%] [G loss: 0.892089]\n",
      "epoch:12 step:11994 [D loss: 0.631153, acc.: 68.75%] [G loss: 1.097418]\n",
      "epoch:12 step:11995 [D loss: 0.678589, acc.: 54.69%] [G loss: 1.003262]\n",
      "epoch:12 step:11996 [D loss: 0.719483, acc.: 53.12%] [G loss: 0.919815]\n",
      "epoch:12 step:11997 [D loss: 0.728051, acc.: 50.00%] [G loss: 0.827878]\n",
      "epoch:12 step:11998 [D loss: 0.751012, acc.: 49.22%] [G loss: 0.937417]\n",
      "epoch:12 step:11999 [D loss: 0.650403, acc.: 59.38%] [G loss: 0.922274]\n",
      "epoch:12 step:12000 [D loss: 0.629804, acc.: 63.28%] [G loss: 1.035392]\n",
      "##############\n",
      "[2.13322635 1.25950356 5.47596432 4.25001892 2.73545518 5.12917363\n",
      " 4.06599581 4.44032561 4.0421549  3.43204922]\n",
      "##########\n",
      "epoch:12 step:12001 [D loss: 0.628685, acc.: 64.06%] [G loss: 0.990118]\n",
      "epoch:12 step:12002 [D loss: 0.681120, acc.: 54.69%] [G loss: 0.990049]\n",
      "epoch:12 step:12003 [D loss: 0.660344, acc.: 62.50%] [G loss: 0.896872]\n",
      "epoch:12 step:12004 [D loss: 0.667269, acc.: 60.94%] [G loss: 0.882857]\n",
      "epoch:12 step:12005 [D loss: 0.709958, acc.: 51.56%] [G loss: 0.892976]\n",
      "epoch:12 step:12006 [D loss: 0.694792, acc.: 56.25%] [G loss: 1.024457]\n",
      "epoch:12 step:12007 [D loss: 0.690194, acc.: 56.25%] [G loss: 0.877268]\n",
      "epoch:12 step:12008 [D loss: 0.715977, acc.: 47.66%] [G loss: 0.910363]\n",
      "epoch:12 step:12009 [D loss: 0.584556, acc.: 67.97%] [G loss: 1.055423]\n",
      "epoch:12 step:12010 [D loss: 0.584837, acc.: 68.75%] [G loss: 0.987798]\n",
      "epoch:12 step:12011 [D loss: 0.522978, acc.: 78.12%] [G loss: 1.011969]\n",
      "epoch:12 step:12012 [D loss: 0.601679, acc.: 71.09%] [G loss: 1.032603]\n",
      "epoch:12 step:12013 [D loss: 0.560687, acc.: 69.53%] [G loss: 0.996175]\n",
      "epoch:12 step:12014 [D loss: 0.587040, acc.: 73.44%] [G loss: 0.997628]\n",
      "epoch:12 step:12015 [D loss: 0.671098, acc.: 63.28%] [G loss: 0.889803]\n",
      "epoch:12 step:12016 [D loss: 0.694277, acc.: 52.34%] [G loss: 0.917549]\n",
      "epoch:12 step:12017 [D loss: 0.656271, acc.: 58.59%] [G loss: 0.990610]\n",
      "epoch:12 step:12018 [D loss: 0.473348, acc.: 80.47%] [G loss: 1.158633]\n",
      "epoch:12 step:12019 [D loss: 0.469125, acc.: 83.59%] [G loss: 1.054206]\n",
      "epoch:12 step:12020 [D loss: 0.629420, acc.: 63.28%] [G loss: 1.088085]\n",
      "epoch:12 step:12021 [D loss: 0.628881, acc.: 65.62%] [G loss: 1.167359]\n",
      "epoch:12 step:12022 [D loss: 0.704117, acc.: 55.47%] [G loss: 1.065434]\n",
      "epoch:12 step:12023 [D loss: 0.834428, acc.: 36.72%] [G loss: 0.867919]\n",
      "epoch:12 step:12024 [D loss: 0.668643, acc.: 61.72%] [G loss: 0.961084]\n",
      "epoch:12 step:12025 [D loss: 0.683437, acc.: 57.81%] [G loss: 0.922078]\n",
      "epoch:12 step:12026 [D loss: 0.623860, acc.: 66.41%] [G loss: 1.004308]\n",
      "epoch:12 step:12027 [D loss: 0.711016, acc.: 46.88%] [G loss: 0.907892]\n",
      "epoch:12 step:12028 [D loss: 0.769868, acc.: 46.88%] [G loss: 1.067238]\n",
      "epoch:12 step:12029 [D loss: 0.659158, acc.: 60.16%] [G loss: 0.840877]\n",
      "epoch:12 step:12030 [D loss: 0.548420, acc.: 76.56%] [G loss: 1.056385]\n",
      "epoch:12 step:12031 [D loss: 0.723567, acc.: 50.78%] [G loss: 0.958314]\n",
      "epoch:12 step:12032 [D loss: 0.727995, acc.: 48.44%] [G loss: 1.066024]\n",
      "epoch:12 step:12033 [D loss: 0.685532, acc.: 57.03%] [G loss: 0.771043]\n",
      "epoch:12 step:12034 [D loss: 0.668085, acc.: 60.94%] [G loss: 0.934471]\n",
      "epoch:12 step:12035 [D loss: 0.640006, acc.: 64.06%] [G loss: 1.003370]\n",
      "epoch:12 step:12036 [D loss: 0.618126, acc.: 69.53%] [G loss: 1.042470]\n",
      "epoch:12 step:12037 [D loss: 0.641184, acc.: 61.72%] [G loss: 0.977873]\n",
      "epoch:12 step:12038 [D loss: 0.642354, acc.: 63.28%] [G loss: 1.003163]\n",
      "epoch:12 step:12039 [D loss: 0.642303, acc.: 68.75%] [G loss: 1.041154]\n",
      "epoch:12 step:12040 [D loss: 0.592872, acc.: 63.28%] [G loss: 0.991428]\n",
      "epoch:12 step:12041 [D loss: 0.666123, acc.: 57.03%] [G loss: 0.937719]\n",
      "epoch:12 step:12042 [D loss: 0.679522, acc.: 53.91%] [G loss: 0.876583]\n",
      "epoch:12 step:12043 [D loss: 0.708473, acc.: 50.00%] [G loss: 0.949128]\n",
      "epoch:12 step:12044 [D loss: 0.796020, acc.: 42.19%] [G loss: 0.964317]\n",
      "epoch:12 step:12045 [D loss: 0.671479, acc.: 58.59%] [G loss: 1.158329]\n",
      "epoch:12 step:12046 [D loss: 0.667527, acc.: 61.72%] [G loss: 0.829969]\n",
      "epoch:12 step:12047 [D loss: 0.683958, acc.: 64.06%] [G loss: 0.922261]\n",
      "epoch:12 step:12048 [D loss: 0.636941, acc.: 67.97%] [G loss: 0.931709]\n",
      "epoch:12 step:12049 [D loss: 0.618126, acc.: 65.62%] [G loss: 0.844661]\n",
      "epoch:12 step:12050 [D loss: 0.595043, acc.: 69.53%] [G loss: 0.976741]\n",
      "epoch:12 step:12051 [D loss: 0.603964, acc.: 71.88%] [G loss: 0.975974]\n",
      "epoch:12 step:12052 [D loss: 0.649060, acc.: 61.72%] [G loss: 0.906045]\n",
      "epoch:12 step:12053 [D loss: 0.626128, acc.: 67.19%] [G loss: 1.036378]\n",
      "epoch:12 step:12054 [D loss: 0.624752, acc.: 66.41%] [G loss: 0.979137]\n",
      "epoch:12 step:12055 [D loss: 0.726078, acc.: 46.88%] [G loss: 0.994604]\n",
      "epoch:12 step:12056 [D loss: 0.677522, acc.: 58.59%] [G loss: 0.865381]\n",
      "epoch:12 step:12057 [D loss: 0.649261, acc.: 62.50%] [G loss: 0.876123]\n",
      "epoch:12 step:12058 [D loss: 0.690667, acc.: 56.25%] [G loss: 0.929289]\n",
      "epoch:12 step:12059 [D loss: 0.553936, acc.: 69.53%] [G loss: 0.905039]\n",
      "epoch:12 step:12060 [D loss: 0.588802, acc.: 70.31%] [G loss: 1.141061]\n",
      "epoch:12 step:12061 [D loss: 0.665947, acc.: 60.16%] [G loss: 0.856083]\n",
      "epoch:12 step:12062 [D loss: 0.659634, acc.: 60.94%] [G loss: 0.927132]\n",
      "epoch:12 step:12063 [D loss: 0.627237, acc.: 64.84%] [G loss: 0.962850]\n",
      "epoch:12 step:12064 [D loss: 0.742012, acc.: 52.34%] [G loss: 0.885020]\n",
      "epoch:12 step:12065 [D loss: 0.746288, acc.: 50.00%] [G loss: 0.905092]\n",
      "epoch:12 step:12066 [D loss: 0.731107, acc.: 44.53%] [G loss: 0.822623]\n",
      "epoch:12 step:12067 [D loss: 0.633323, acc.: 65.62%] [G loss: 0.955009]\n",
      "epoch:12 step:12068 [D loss: 0.692827, acc.: 56.25%] [G loss: 1.005551]\n",
      "epoch:12 step:12069 [D loss: 0.575188, acc.: 69.53%] [G loss: 0.990553]\n",
      "epoch:12 step:12070 [D loss: 0.696470, acc.: 58.59%] [G loss: 0.950221]\n",
      "epoch:12 step:12071 [D loss: 0.667574, acc.: 59.38%] [G loss: 0.968485]\n",
      "epoch:12 step:12072 [D loss: 0.698595, acc.: 57.81%] [G loss: 0.899101]\n",
      "epoch:12 step:12073 [D loss: 0.662112, acc.: 58.59%] [G loss: 0.963940]\n",
      "epoch:12 step:12074 [D loss: 0.678596, acc.: 54.69%] [G loss: 0.890478]\n",
      "epoch:12 step:12075 [D loss: 0.543487, acc.: 74.22%] [G loss: 1.020791]\n",
      "epoch:12 step:12076 [D loss: 0.525238, acc.: 81.25%] [G loss: 1.063174]\n",
      "epoch:12 step:12077 [D loss: 0.588806, acc.: 71.88%] [G loss: 1.131725]\n",
      "epoch:12 step:12078 [D loss: 0.734354, acc.: 43.75%] [G loss: 0.928303]\n",
      "epoch:12 step:12079 [D loss: 0.660765, acc.: 56.25%] [G loss: 0.893933]\n",
      "epoch:12 step:12080 [D loss: 0.715622, acc.: 53.12%] [G loss: 0.949825]\n",
      "epoch:12 step:12081 [D loss: 0.670957, acc.: 59.38%] [G loss: 1.010552]\n",
      "epoch:12 step:12082 [D loss: 0.673228, acc.: 63.28%] [G loss: 1.010965]\n",
      "epoch:12 step:12083 [D loss: 0.683963, acc.: 57.03%] [G loss: 0.966975]\n",
      "epoch:12 step:12084 [D loss: 0.733504, acc.: 50.00%] [G loss: 0.842950]\n",
      "epoch:12 step:12085 [D loss: 0.617666, acc.: 65.62%] [G loss: 1.054128]\n",
      "epoch:12 step:12086 [D loss: 0.592569, acc.: 72.66%] [G loss: 0.981865]\n",
      "epoch:12 step:12087 [D loss: 0.690603, acc.: 53.12%] [G loss: 0.900956]\n",
      "epoch:12 step:12088 [D loss: 0.650795, acc.: 59.38%] [G loss: 1.043806]\n",
      "epoch:12 step:12089 [D loss: 0.666225, acc.: 63.28%] [G loss: 0.989830]\n",
      "epoch:12 step:12090 [D loss: 0.687674, acc.: 61.72%] [G loss: 0.925298]\n",
      "epoch:12 step:12091 [D loss: 0.654453, acc.: 64.84%] [G loss: 0.962738]\n",
      "epoch:12 step:12092 [D loss: 0.624556, acc.: 66.41%] [G loss: 1.016586]\n",
      "epoch:12 step:12093 [D loss: 0.640030, acc.: 59.38%] [G loss: 0.867782]\n",
      "epoch:12 step:12094 [D loss: 0.577663, acc.: 71.09%] [G loss: 1.024593]\n",
      "epoch:12 step:12095 [D loss: 0.517511, acc.: 78.12%] [G loss: 1.039150]\n",
      "epoch:12 step:12096 [D loss: 0.547079, acc.: 74.22%] [G loss: 1.057330]\n",
      "epoch:12 step:12097 [D loss: 0.544542, acc.: 76.56%] [G loss: 1.058203]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:12098 [D loss: 0.534561, acc.: 78.91%] [G loss: 1.166649]\n",
      "epoch:12 step:12099 [D loss: 0.554029, acc.: 74.22%] [G loss: 1.033388]\n",
      "epoch:12 step:12100 [D loss: 0.633324, acc.: 62.50%] [G loss: 1.087958]\n",
      "epoch:12 step:12101 [D loss: 0.522026, acc.: 75.78%] [G loss: 1.075441]\n",
      "epoch:12 step:12102 [D loss: 0.748540, acc.: 53.12%] [G loss: 1.039771]\n",
      "epoch:12 step:12103 [D loss: 0.750612, acc.: 44.53%] [G loss: 0.844632]\n",
      "epoch:12 step:12104 [D loss: 0.680186, acc.: 57.03%] [G loss: 0.899237]\n",
      "epoch:12 step:12105 [D loss: 0.593922, acc.: 73.44%] [G loss: 0.859307]\n",
      "epoch:12 step:12106 [D loss: 0.662652, acc.: 62.50%] [G loss: 0.889138]\n",
      "epoch:12 step:12107 [D loss: 0.562473, acc.: 78.12%] [G loss: 0.877400]\n",
      "epoch:12 step:12108 [D loss: 0.729220, acc.: 53.91%] [G loss: 0.878407]\n",
      "epoch:12 step:12109 [D loss: 0.592582, acc.: 67.19%] [G loss: 0.870725]\n",
      "epoch:12 step:12110 [D loss: 0.686388, acc.: 55.47%] [G loss: 0.959992]\n",
      "epoch:12 step:12111 [D loss: 0.769093, acc.: 47.66%] [G loss: 0.886106]\n",
      "epoch:12 step:12112 [D loss: 0.689923, acc.: 54.69%] [G loss: 0.985668]\n",
      "epoch:12 step:12113 [D loss: 0.678617, acc.: 62.50%] [G loss: 0.995806]\n",
      "epoch:12 step:12114 [D loss: 0.727704, acc.: 53.12%] [G loss: 0.852344]\n",
      "epoch:12 step:12115 [D loss: 0.637625, acc.: 63.28%] [G loss: 1.024149]\n",
      "epoch:12 step:12116 [D loss: 0.634084, acc.: 61.72%] [G loss: 0.908116]\n",
      "epoch:12 step:12117 [D loss: 0.724912, acc.: 53.12%] [G loss: 0.878232]\n",
      "epoch:12 step:12118 [D loss: 0.668383, acc.: 57.03%] [G loss: 0.934631]\n",
      "epoch:12 step:12119 [D loss: 0.666774, acc.: 60.16%] [G loss: 0.904733]\n",
      "epoch:12 step:12120 [D loss: 0.606515, acc.: 68.75%] [G loss: 0.942555]\n",
      "epoch:12 step:12121 [D loss: 0.670506, acc.: 58.59%] [G loss: 0.892826]\n",
      "epoch:12 step:12122 [D loss: 0.670937, acc.: 60.94%] [G loss: 0.956581]\n",
      "epoch:12 step:12123 [D loss: 0.648258, acc.: 61.72%] [G loss: 0.966997]\n",
      "epoch:12 step:12124 [D loss: 0.739456, acc.: 46.88%] [G loss: 1.077313]\n",
      "epoch:12 step:12125 [D loss: 0.657679, acc.: 60.16%] [G loss: 0.897314]\n",
      "epoch:12 step:12126 [D loss: 0.719274, acc.: 50.78%] [G loss: 0.932377]\n",
      "epoch:12 step:12127 [D loss: 0.682373, acc.: 57.03%] [G loss: 0.870003]\n",
      "epoch:12 step:12128 [D loss: 0.639745, acc.: 66.41%] [G loss: 0.922016]\n",
      "epoch:12 step:12129 [D loss: 0.581261, acc.: 65.62%] [G loss: 0.861208]\n",
      "epoch:12 step:12130 [D loss: 0.532875, acc.: 79.69%] [G loss: 1.005260]\n",
      "epoch:12 step:12131 [D loss: 0.592908, acc.: 70.31%] [G loss: 1.033977]\n",
      "epoch:12 step:12132 [D loss: 0.670026, acc.: 60.16%] [G loss: 1.038734]\n",
      "epoch:12 step:12133 [D loss: 0.599264, acc.: 70.31%] [G loss: 0.950397]\n",
      "epoch:12 step:12134 [D loss: 0.518322, acc.: 82.03%] [G loss: 1.155185]\n",
      "epoch:12 step:12135 [D loss: 0.745947, acc.: 49.22%] [G loss: 0.986465]\n",
      "epoch:12 step:12136 [D loss: 0.706236, acc.: 50.78%] [G loss: 1.064889]\n",
      "epoch:12 step:12137 [D loss: 0.660783, acc.: 64.06%] [G loss: 0.931879]\n",
      "epoch:12 step:12138 [D loss: 0.643710, acc.: 64.84%] [G loss: 0.964471]\n",
      "epoch:12 step:12139 [D loss: 0.634527, acc.: 60.16%] [G loss: 0.996360]\n",
      "epoch:12 step:12140 [D loss: 0.657008, acc.: 58.59%] [G loss: 0.963080]\n",
      "epoch:12 step:12141 [D loss: 0.611508, acc.: 65.62%] [G loss: 0.950603]\n",
      "epoch:12 step:12142 [D loss: 0.586758, acc.: 73.44%] [G loss: 0.955909]\n",
      "epoch:12 step:12143 [D loss: 0.482243, acc.: 78.12%] [G loss: 0.976908]\n",
      "epoch:12 step:12144 [D loss: 0.541758, acc.: 73.44%] [G loss: 0.961277]\n",
      "epoch:12 step:12145 [D loss: 0.555304, acc.: 76.56%] [G loss: 1.096435]\n",
      "epoch:12 step:12146 [D loss: 0.691661, acc.: 58.59%] [G loss: 0.823686]\n",
      "epoch:12 step:12147 [D loss: 0.702772, acc.: 59.38%] [G loss: 0.921419]\n",
      "epoch:12 step:12148 [D loss: 0.751097, acc.: 48.44%] [G loss: 0.952889]\n",
      "epoch:12 step:12149 [D loss: 0.708206, acc.: 50.00%] [G loss: 0.951306]\n",
      "epoch:12 step:12150 [D loss: 0.667152, acc.: 60.16%] [G loss: 0.968356]\n",
      "epoch:12 step:12151 [D loss: 0.588853, acc.: 72.66%] [G loss: 1.186416]\n",
      "epoch:12 step:12152 [D loss: 0.614473, acc.: 65.62%] [G loss: 0.960761]\n",
      "epoch:12 step:12153 [D loss: 0.478387, acc.: 82.81%] [G loss: 0.970100]\n",
      "epoch:12 step:12154 [D loss: 0.623979, acc.: 68.75%] [G loss: 1.023072]\n",
      "epoch:12 step:12155 [D loss: 0.544683, acc.: 78.12%] [G loss: 0.923343]\n",
      "epoch:12 step:12156 [D loss: 0.410361, acc.: 85.94%] [G loss: 1.207098]\n",
      "epoch:12 step:12157 [D loss: 0.750492, acc.: 50.78%] [G loss: 1.143010]\n",
      "epoch:12 step:12158 [D loss: 0.670715, acc.: 60.16%] [G loss: 0.925220]\n",
      "epoch:12 step:12159 [D loss: 0.667510, acc.: 58.59%] [G loss: 1.015221]\n",
      "epoch:12 step:12160 [D loss: 0.655279, acc.: 59.38%] [G loss: 0.938497]\n",
      "epoch:12 step:12161 [D loss: 0.728930, acc.: 50.00%] [G loss: 1.039530]\n",
      "epoch:12 step:12162 [D loss: 0.597053, acc.: 64.84%] [G loss: 0.961076]\n",
      "epoch:12 step:12163 [D loss: 0.607301, acc.: 63.28%] [G loss: 1.133296]\n",
      "epoch:12 step:12164 [D loss: 0.692341, acc.: 53.12%] [G loss: 0.971374]\n",
      "epoch:12 step:12165 [D loss: 0.628046, acc.: 60.94%] [G loss: 1.039813]\n",
      "epoch:12 step:12166 [D loss: 0.584084, acc.: 74.22%] [G loss: 1.133458]\n",
      "epoch:12 step:12167 [D loss: 0.587380, acc.: 71.09%] [G loss: 1.102070]\n",
      "epoch:12 step:12168 [D loss: 0.532760, acc.: 82.03%] [G loss: 0.973244]\n",
      "epoch:12 step:12169 [D loss: 0.572676, acc.: 75.00%] [G loss: 1.134187]\n",
      "epoch:12 step:12170 [D loss: 0.550324, acc.: 73.44%] [G loss: 1.095060]\n",
      "epoch:12 step:12171 [D loss: 0.462983, acc.: 86.72%] [G loss: 1.126500]\n",
      "epoch:12 step:12172 [D loss: 0.975534, acc.: 31.25%] [G loss: 0.930726]\n",
      "epoch:12 step:12173 [D loss: 0.627113, acc.: 67.97%] [G loss: 1.203207]\n",
      "epoch:12 step:12174 [D loss: 0.581348, acc.: 68.75%] [G loss: 0.860332]\n",
      "epoch:12 step:12175 [D loss: 0.620519, acc.: 65.62%] [G loss: 1.161315]\n",
      "epoch:12 step:12176 [D loss: 0.573545, acc.: 72.66%] [G loss: 1.124716]\n",
      "epoch:12 step:12177 [D loss: 0.681047, acc.: 54.69%] [G loss: 0.923166]\n",
      "epoch:12 step:12178 [D loss: 0.534550, acc.: 78.12%] [G loss: 1.046684]\n",
      "epoch:12 step:12179 [D loss: 0.636099, acc.: 59.38%] [G loss: 1.158592]\n",
      "epoch:12 step:12180 [D loss: 0.592120, acc.: 71.09%] [G loss: 0.933067]\n",
      "epoch:12 step:12181 [D loss: 0.373898, acc.: 90.62%] [G loss: 1.039193]\n",
      "epoch:13 step:12182 [D loss: 0.768387, acc.: 47.66%] [G loss: 0.987910]\n",
      "epoch:13 step:12183 [D loss: 0.735364, acc.: 50.78%] [G loss: 0.952295]\n",
      "epoch:13 step:12184 [D loss: 0.743901, acc.: 47.66%] [G loss: 0.891114]\n",
      "epoch:13 step:12185 [D loss: 0.729557, acc.: 49.22%] [G loss: 1.072072]\n",
      "epoch:13 step:12186 [D loss: 0.652660, acc.: 58.59%] [G loss: 1.025407]\n",
      "epoch:13 step:12187 [D loss: 0.677451, acc.: 57.03%] [G loss: 1.002794]\n",
      "epoch:13 step:12188 [D loss: 0.640919, acc.: 62.50%] [G loss: 1.066967]\n",
      "epoch:13 step:12189 [D loss: 0.702497, acc.: 59.38%] [G loss: 1.136588]\n",
      "epoch:13 step:12190 [D loss: 0.640711, acc.: 59.38%] [G loss: 0.949062]\n",
      "epoch:13 step:12191 [D loss: 0.614713, acc.: 66.41%] [G loss: 1.024653]\n",
      "epoch:13 step:12192 [D loss: 0.613913, acc.: 68.75%] [G loss: 0.928987]\n",
      "epoch:13 step:12193 [D loss: 0.695645, acc.: 59.38%] [G loss: 0.970430]\n",
      "epoch:13 step:12194 [D loss: 0.624716, acc.: 67.97%] [G loss: 1.045012]\n",
      "epoch:13 step:12195 [D loss: 0.614591, acc.: 67.97%] [G loss: 1.110999]\n",
      "epoch:13 step:12196 [D loss: 0.528749, acc.: 78.91%] [G loss: 1.066341]\n",
      "epoch:13 step:12197 [D loss: 0.531548, acc.: 82.81%] [G loss: 1.139399]\n",
      "epoch:13 step:12198 [D loss: 0.692010, acc.: 62.50%] [G loss: 1.120731]\n",
      "epoch:13 step:12199 [D loss: 0.859054, acc.: 37.50%] [G loss: 0.798848]\n",
      "epoch:13 step:12200 [D loss: 0.819364, acc.: 35.16%] [G loss: 0.896331]\n",
      "##############\n",
      "[2.31179085 1.31934755 5.3474085  4.31079942 2.84027039 5.54700356\n",
      " 4.26860515 4.57888885 3.93834629 3.50895031]\n",
      "##########\n",
      "epoch:13 step:12201 [D loss: 0.781288, acc.: 46.09%] [G loss: 1.108267]\n",
      "epoch:13 step:12202 [D loss: 0.760331, acc.: 51.56%] [G loss: 0.934202]\n",
      "epoch:13 step:12203 [D loss: 0.777455, acc.: 46.09%] [G loss: 0.948660]\n",
      "epoch:13 step:12204 [D loss: 0.641001, acc.: 60.94%] [G loss: 0.913753]\n",
      "epoch:13 step:12205 [D loss: 0.723909, acc.: 51.56%] [G loss: 0.911565]\n",
      "epoch:13 step:12206 [D loss: 0.569116, acc.: 73.44%] [G loss: 1.074785]\n",
      "epoch:13 step:12207 [D loss: 0.657823, acc.: 58.59%] [G loss: 1.019473]\n",
      "epoch:13 step:12208 [D loss: 0.645952, acc.: 60.94%] [G loss: 1.020754]\n",
      "epoch:13 step:12209 [D loss: 0.582023, acc.: 71.09%] [G loss: 0.975696]\n",
      "epoch:13 step:12210 [D loss: 0.599348, acc.: 70.31%] [G loss: 0.996370]\n",
      "epoch:13 step:12211 [D loss: 0.555816, acc.: 74.22%] [G loss: 0.945317]\n",
      "epoch:13 step:12212 [D loss: 0.577627, acc.: 72.66%] [G loss: 1.079258]\n",
      "epoch:13 step:12213 [D loss: 0.543065, acc.: 76.56%] [G loss: 1.151676]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12214 [D loss: 0.609480, acc.: 64.06%] [G loss: 0.926668]\n",
      "epoch:13 step:12215 [D loss: 0.547068, acc.: 74.22%] [G loss: 0.938468]\n",
      "epoch:13 step:12216 [D loss: 0.501819, acc.: 78.91%] [G loss: 1.096794]\n",
      "epoch:13 step:12217 [D loss: 0.478180, acc.: 82.03%] [G loss: 1.240773]\n",
      "epoch:13 step:12218 [D loss: 0.673369, acc.: 62.50%] [G loss: 1.147404]\n",
      "epoch:13 step:12219 [D loss: 0.708215, acc.: 59.38%] [G loss: 1.132656]\n",
      "epoch:13 step:12220 [D loss: 0.724116, acc.: 53.91%] [G loss: 1.199330]\n",
      "epoch:13 step:12221 [D loss: 0.643873, acc.: 60.94%] [G loss: 0.976457]\n",
      "epoch:13 step:12222 [D loss: 0.637019, acc.: 68.75%] [G loss: 0.814579]\n",
      "epoch:13 step:12223 [D loss: 0.586337, acc.: 67.97%] [G loss: 1.042675]\n",
      "epoch:13 step:12224 [D loss: 0.598834, acc.: 69.53%] [G loss: 0.950004]\n",
      "epoch:13 step:12225 [D loss: 0.686476, acc.: 57.81%] [G loss: 0.942212]\n",
      "epoch:13 step:12226 [D loss: 0.706433, acc.: 53.12%] [G loss: 0.927232]\n",
      "epoch:13 step:12227 [D loss: 0.670141, acc.: 58.59%] [G loss: 0.881064]\n",
      "epoch:13 step:12228 [D loss: 0.717317, acc.: 49.22%] [G loss: 0.940964]\n",
      "epoch:13 step:12229 [D loss: 0.666154, acc.: 57.81%] [G loss: 0.950746]\n",
      "epoch:13 step:12230 [D loss: 0.623474, acc.: 65.62%] [G loss: 0.913230]\n",
      "epoch:13 step:12231 [D loss: 0.624304, acc.: 64.06%] [G loss: 1.004503]\n",
      "epoch:13 step:12232 [D loss: 0.623739, acc.: 66.41%] [G loss: 1.043441]\n",
      "epoch:13 step:12233 [D loss: 0.691567, acc.: 56.25%] [G loss: 1.001570]\n",
      "epoch:13 step:12234 [D loss: 0.665465, acc.: 57.81%] [G loss: 0.862177]\n",
      "epoch:13 step:12235 [D loss: 0.570140, acc.: 71.88%] [G loss: 0.979151]\n",
      "epoch:13 step:12236 [D loss: 0.549370, acc.: 78.91%] [G loss: 1.114640]\n",
      "epoch:13 step:12237 [D loss: 0.639016, acc.: 60.94%] [G loss: 0.920488]\n",
      "epoch:13 step:12238 [D loss: 0.687637, acc.: 56.25%] [G loss: 0.966129]\n",
      "epoch:13 step:12239 [D loss: 0.707408, acc.: 53.12%] [G loss: 0.919278]\n",
      "epoch:13 step:12240 [D loss: 0.665799, acc.: 63.28%] [G loss: 0.876549]\n",
      "epoch:13 step:12241 [D loss: 0.712480, acc.: 53.12%] [G loss: 0.931341]\n",
      "epoch:13 step:12242 [D loss: 0.658990, acc.: 57.03%] [G loss: 0.945866]\n",
      "epoch:13 step:12243 [D loss: 0.744062, acc.: 44.53%] [G loss: 0.842451]\n",
      "epoch:13 step:12244 [D loss: 0.768888, acc.: 43.75%] [G loss: 0.768466]\n",
      "epoch:13 step:12245 [D loss: 0.653130, acc.: 62.50%] [G loss: 0.871439]\n",
      "epoch:13 step:12246 [D loss: 0.607655, acc.: 67.97%] [G loss: 1.057310]\n",
      "epoch:13 step:12247 [D loss: 0.647829, acc.: 59.38%] [G loss: 0.861898]\n",
      "epoch:13 step:12248 [D loss: 0.664768, acc.: 62.50%] [G loss: 0.797955]\n",
      "epoch:13 step:12249 [D loss: 0.644203, acc.: 67.19%] [G loss: 0.869720]\n",
      "epoch:13 step:12250 [D loss: 0.623871, acc.: 67.19%] [G loss: 0.936170]\n",
      "epoch:13 step:12251 [D loss: 0.620994, acc.: 64.84%] [G loss: 0.899853]\n",
      "epoch:13 step:12252 [D loss: 0.614776, acc.: 66.41%] [G loss: 1.069802]\n",
      "epoch:13 step:12253 [D loss: 0.614053, acc.: 65.62%] [G loss: 1.007677]\n",
      "epoch:13 step:12254 [D loss: 0.605139, acc.: 64.06%] [G loss: 1.029322]\n",
      "epoch:13 step:12255 [D loss: 0.575261, acc.: 74.22%] [G loss: 0.975355]\n",
      "epoch:13 step:12256 [D loss: 0.536227, acc.: 77.34%] [G loss: 1.160914]\n",
      "epoch:13 step:12257 [D loss: 0.543592, acc.: 73.44%] [G loss: 1.078246]\n",
      "epoch:13 step:12258 [D loss: 0.577715, acc.: 71.88%] [G loss: 1.110016]\n",
      "epoch:13 step:12259 [D loss: 0.673163, acc.: 54.69%] [G loss: 1.013163]\n",
      "epoch:13 step:12260 [D loss: 0.743578, acc.: 54.69%] [G loss: 0.946650]\n",
      "epoch:13 step:12261 [D loss: 0.695751, acc.: 58.59%] [G loss: 0.902077]\n",
      "epoch:13 step:12262 [D loss: 0.773712, acc.: 46.09%] [G loss: 0.957074]\n",
      "epoch:13 step:12263 [D loss: 0.643230, acc.: 64.06%] [G loss: 0.912308]\n",
      "epoch:13 step:12264 [D loss: 0.627648, acc.: 64.06%] [G loss: 1.000083]\n",
      "epoch:13 step:12265 [D loss: 0.692599, acc.: 56.25%] [G loss: 1.006875]\n",
      "epoch:13 step:12266 [D loss: 0.642557, acc.: 63.28%] [G loss: 0.917449]\n",
      "epoch:13 step:12267 [D loss: 0.694929, acc.: 56.25%] [G loss: 0.876966]\n",
      "epoch:13 step:12268 [D loss: 0.717615, acc.: 52.34%] [G loss: 0.760328]\n",
      "epoch:13 step:12269 [D loss: 0.623382, acc.: 68.75%] [G loss: 0.954975]\n",
      "epoch:13 step:12270 [D loss: 0.687949, acc.: 54.69%] [G loss: 1.108773]\n",
      "epoch:13 step:12271 [D loss: 0.549332, acc.: 80.47%] [G loss: 0.988484]\n",
      "epoch:13 step:12272 [D loss: 0.696723, acc.: 58.59%] [G loss: 0.833032]\n",
      "epoch:13 step:12273 [D loss: 0.670396, acc.: 58.59%] [G loss: 0.992484]\n",
      "epoch:13 step:12274 [D loss: 0.591175, acc.: 69.53%] [G loss: 1.052865]\n",
      "epoch:13 step:12275 [D loss: 0.641822, acc.: 63.28%] [G loss: 0.873753]\n",
      "epoch:13 step:12276 [D loss: 0.722265, acc.: 53.12%] [G loss: 0.846842]\n",
      "epoch:13 step:12277 [D loss: 0.671085, acc.: 55.47%] [G loss: 0.973628]\n",
      "epoch:13 step:12278 [D loss: 0.602965, acc.: 72.66%] [G loss: 0.986247]\n",
      "epoch:13 step:12279 [D loss: 0.649162, acc.: 63.28%] [G loss: 0.912113]\n",
      "epoch:13 step:12280 [D loss: 0.680041, acc.: 60.94%] [G loss: 0.907777]\n",
      "epoch:13 step:12281 [D loss: 0.621032, acc.: 65.62%] [G loss: 0.824259]\n",
      "epoch:13 step:12282 [D loss: 0.639503, acc.: 63.28%] [G loss: 1.027750]\n",
      "epoch:13 step:12283 [D loss: 0.729047, acc.: 49.22%] [G loss: 0.863653]\n",
      "epoch:13 step:12284 [D loss: 0.619698, acc.: 63.28%] [G loss: 0.900265]\n",
      "epoch:13 step:12285 [D loss: 0.622849, acc.: 67.19%] [G loss: 1.031356]\n",
      "epoch:13 step:12286 [D loss: 0.712387, acc.: 53.12%] [G loss: 0.944798]\n",
      "epoch:13 step:12287 [D loss: 0.623165, acc.: 66.41%] [G loss: 1.080335]\n",
      "epoch:13 step:12288 [D loss: 0.632050, acc.: 62.50%] [G loss: 1.047488]\n",
      "epoch:13 step:12289 [D loss: 0.739132, acc.: 50.78%] [G loss: 1.110092]\n",
      "epoch:13 step:12290 [D loss: 0.642226, acc.: 60.94%] [G loss: 0.945478]\n",
      "epoch:13 step:12291 [D loss: 0.666357, acc.: 62.50%] [G loss: 0.823827]\n",
      "epoch:13 step:12292 [D loss: 0.565956, acc.: 73.44%] [G loss: 0.857121]\n",
      "epoch:13 step:12293 [D loss: 0.600341, acc.: 65.62%] [G loss: 0.941446]\n",
      "epoch:13 step:12294 [D loss: 0.607985, acc.: 67.19%] [G loss: 0.837771]\n",
      "epoch:13 step:12295 [D loss: 0.701390, acc.: 59.38%] [G loss: 0.870540]\n",
      "epoch:13 step:12296 [D loss: 0.578569, acc.: 72.66%] [G loss: 0.857079]\n",
      "epoch:13 step:12297 [D loss: 0.612624, acc.: 70.31%] [G loss: 0.879453]\n",
      "epoch:13 step:12298 [D loss: 0.627848, acc.: 66.41%] [G loss: 1.034682]\n",
      "epoch:13 step:12299 [D loss: 0.557909, acc.: 75.00%] [G loss: 1.052069]\n",
      "epoch:13 step:12300 [D loss: 0.607785, acc.: 68.75%] [G loss: 1.199027]\n",
      "epoch:13 step:12301 [D loss: 0.779527, acc.: 49.22%] [G loss: 0.967126]\n",
      "epoch:13 step:12302 [D loss: 0.635621, acc.: 59.38%] [G loss: 1.103791]\n",
      "epoch:13 step:12303 [D loss: 0.651366, acc.: 61.72%] [G loss: 1.014530]\n",
      "epoch:13 step:12304 [D loss: 0.537915, acc.: 72.66%] [G loss: 0.881211]\n",
      "epoch:13 step:12305 [D loss: 0.640448, acc.: 59.38%] [G loss: 1.083577]\n",
      "epoch:13 step:12306 [D loss: 0.685669, acc.: 56.25%] [G loss: 0.920611]\n",
      "epoch:13 step:12307 [D loss: 0.658513, acc.: 65.62%] [G loss: 1.110976]\n",
      "epoch:13 step:12308 [D loss: 0.667947, acc.: 59.38%] [G loss: 1.018642]\n",
      "epoch:13 step:12309 [D loss: 0.719134, acc.: 50.78%] [G loss: 0.895987]\n",
      "epoch:13 step:12310 [D loss: 0.782189, acc.: 39.84%] [G loss: 0.871483]\n",
      "epoch:13 step:12311 [D loss: 0.679132, acc.: 59.38%] [G loss: 1.059676]\n",
      "epoch:13 step:12312 [D loss: 0.546108, acc.: 76.56%] [G loss: 0.953963]\n",
      "epoch:13 step:12313 [D loss: 0.657613, acc.: 60.16%] [G loss: 0.958581]\n",
      "epoch:13 step:12314 [D loss: 0.810808, acc.: 43.75%] [G loss: 0.976144]\n",
      "epoch:13 step:12315 [D loss: 0.707285, acc.: 55.47%] [G loss: 0.961821]\n",
      "epoch:13 step:12316 [D loss: 0.645379, acc.: 60.94%] [G loss: 0.904465]\n",
      "epoch:13 step:12317 [D loss: 0.793249, acc.: 42.19%] [G loss: 0.852191]\n",
      "epoch:13 step:12318 [D loss: 0.706019, acc.: 57.03%] [G loss: 0.880245]\n",
      "epoch:13 step:12319 [D loss: 0.703075, acc.: 56.25%] [G loss: 1.000138]\n",
      "epoch:13 step:12320 [D loss: 0.625376, acc.: 67.19%] [G loss: 0.922354]\n",
      "epoch:13 step:12321 [D loss: 0.698182, acc.: 50.78%] [G loss: 1.035504]\n",
      "epoch:13 step:12322 [D loss: 0.668153, acc.: 63.28%] [G loss: 1.031978]\n",
      "epoch:13 step:12323 [D loss: 0.622358, acc.: 62.50%] [G loss: 0.897018]\n",
      "epoch:13 step:12324 [D loss: 0.637434, acc.: 60.16%] [G loss: 0.995898]\n",
      "epoch:13 step:12325 [D loss: 0.569271, acc.: 73.44%] [G loss: 1.008145]\n",
      "epoch:13 step:12326 [D loss: 0.602846, acc.: 69.53%] [G loss: 1.015520]\n",
      "epoch:13 step:12327 [D loss: 0.643964, acc.: 63.28%] [G loss: 0.953562]\n",
      "epoch:13 step:12328 [D loss: 0.754197, acc.: 48.44%] [G loss: 0.919658]\n",
      "epoch:13 step:12329 [D loss: 0.661942, acc.: 57.03%] [G loss: 0.891604]\n",
      "epoch:13 step:12330 [D loss: 0.617302, acc.: 68.75%] [G loss: 0.766735]\n",
      "epoch:13 step:12331 [D loss: 0.602883, acc.: 68.75%] [G loss: 0.936363]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12332 [D loss: 0.506332, acc.: 78.91%] [G loss: 1.010612]\n",
      "epoch:13 step:12333 [D loss: 0.487474, acc.: 85.94%] [G loss: 1.265254]\n",
      "epoch:13 step:12334 [D loss: 0.725737, acc.: 51.56%] [G loss: 1.068589]\n",
      "epoch:13 step:12335 [D loss: 0.709180, acc.: 48.44%] [G loss: 0.964910]\n",
      "epoch:13 step:12336 [D loss: 0.579564, acc.: 74.22%] [G loss: 0.926747]\n",
      "epoch:13 step:12337 [D loss: 0.643316, acc.: 61.72%] [G loss: 0.862991]\n",
      "epoch:13 step:12338 [D loss: 0.653929, acc.: 60.16%] [G loss: 1.081974]\n",
      "epoch:13 step:12339 [D loss: 0.641998, acc.: 62.50%] [G loss: 0.885531]\n",
      "epoch:13 step:12340 [D loss: 0.703815, acc.: 56.25%] [G loss: 0.871612]\n",
      "epoch:13 step:12341 [D loss: 0.673998, acc.: 57.81%] [G loss: 0.951974]\n",
      "epoch:13 step:12342 [D loss: 0.689414, acc.: 57.03%] [G loss: 0.774324]\n",
      "epoch:13 step:12343 [D loss: 0.634867, acc.: 62.50%] [G loss: 0.865343]\n",
      "epoch:13 step:12344 [D loss: 0.631133, acc.: 63.28%] [G loss: 0.887831]\n",
      "epoch:13 step:12345 [D loss: 0.652718, acc.: 57.03%] [G loss: 1.053485]\n",
      "epoch:13 step:12346 [D loss: 0.699926, acc.: 54.69%] [G loss: 0.836223]\n",
      "epoch:13 step:12347 [D loss: 0.712522, acc.: 52.34%] [G loss: 0.973722]\n",
      "epoch:13 step:12348 [D loss: 0.745161, acc.: 44.53%] [G loss: 0.846164]\n",
      "epoch:13 step:12349 [D loss: 0.674737, acc.: 59.38%] [G loss: 0.897618]\n",
      "epoch:13 step:12350 [D loss: 0.701573, acc.: 56.25%] [G loss: 0.895864]\n",
      "epoch:13 step:12351 [D loss: 0.674231, acc.: 60.16%] [G loss: 0.904457]\n",
      "epoch:13 step:12352 [D loss: 0.642561, acc.: 64.06%] [G loss: 0.837090]\n",
      "epoch:13 step:12353 [D loss: 0.664276, acc.: 60.94%] [G loss: 0.985388]\n",
      "epoch:13 step:12354 [D loss: 0.700750, acc.: 57.81%] [G loss: 1.030223]\n",
      "epoch:13 step:12355 [D loss: 0.699835, acc.: 50.78%] [G loss: 0.976533]\n",
      "epoch:13 step:12356 [D loss: 0.664186, acc.: 61.72%] [G loss: 0.802891]\n",
      "epoch:13 step:12357 [D loss: 0.603911, acc.: 67.97%] [G loss: 1.040434]\n",
      "epoch:13 step:12358 [D loss: 0.649379, acc.: 63.28%] [G loss: 0.959280]\n",
      "epoch:13 step:12359 [D loss: 0.613963, acc.: 66.41%] [G loss: 0.943212]\n",
      "epoch:13 step:12360 [D loss: 0.666028, acc.: 63.28%] [G loss: 0.886879]\n",
      "epoch:13 step:12361 [D loss: 0.643404, acc.: 66.41%] [G loss: 0.954440]\n",
      "epoch:13 step:12362 [D loss: 0.655083, acc.: 60.94%] [G loss: 0.951608]\n",
      "epoch:13 step:12363 [D loss: 0.604284, acc.: 67.97%] [G loss: 1.058562]\n",
      "epoch:13 step:12364 [D loss: 0.702700, acc.: 54.69%] [G loss: 0.804206]\n",
      "epoch:13 step:12365 [D loss: 0.652179, acc.: 60.94%] [G loss: 0.915051]\n",
      "epoch:13 step:12366 [D loss: 0.692155, acc.: 54.69%] [G loss: 0.964473]\n",
      "epoch:13 step:12367 [D loss: 0.700729, acc.: 57.03%] [G loss: 1.067909]\n",
      "epoch:13 step:12368 [D loss: 0.694944, acc.: 53.12%] [G loss: 1.023683]\n",
      "epoch:13 step:12369 [D loss: 0.620702, acc.: 67.19%] [G loss: 0.980604]\n",
      "epoch:13 step:12370 [D loss: 0.688584, acc.: 54.69%] [G loss: 1.022194]\n",
      "epoch:13 step:12371 [D loss: 0.667908, acc.: 58.59%] [G loss: 1.018595]\n",
      "epoch:13 step:12372 [D loss: 0.571694, acc.: 72.66%] [G loss: 0.988213]\n",
      "epoch:13 step:12373 [D loss: 0.594219, acc.: 67.97%] [G loss: 0.924417]\n",
      "epoch:13 step:12374 [D loss: 0.609654, acc.: 69.53%] [G loss: 1.082663]\n",
      "epoch:13 step:12375 [D loss: 0.628001, acc.: 60.94%] [G loss: 0.880418]\n",
      "epoch:13 step:12376 [D loss: 0.690884, acc.: 57.03%] [G loss: 1.003455]\n",
      "epoch:13 step:12377 [D loss: 0.700216, acc.: 53.12%] [G loss: 0.903470]\n",
      "epoch:13 step:12378 [D loss: 0.685586, acc.: 57.81%] [G loss: 0.866964]\n",
      "epoch:13 step:12379 [D loss: 0.731797, acc.: 50.00%] [G loss: 1.024496]\n",
      "epoch:13 step:12380 [D loss: 0.746076, acc.: 48.44%] [G loss: 0.880491]\n",
      "epoch:13 step:12381 [D loss: 0.650955, acc.: 63.28%] [G loss: 0.878362]\n",
      "epoch:13 step:12382 [D loss: 0.622201, acc.: 67.19%] [G loss: 1.025591]\n",
      "epoch:13 step:12383 [D loss: 0.673695, acc.: 55.47%] [G loss: 0.881255]\n",
      "epoch:13 step:12384 [D loss: 0.717998, acc.: 56.25%] [G loss: 0.840833]\n",
      "epoch:13 step:12385 [D loss: 0.804628, acc.: 40.62%] [G loss: 0.847969]\n",
      "epoch:13 step:12386 [D loss: 0.729572, acc.: 51.56%] [G loss: 0.850891]\n",
      "epoch:13 step:12387 [D loss: 0.645333, acc.: 59.38%] [G loss: 0.789076]\n",
      "epoch:13 step:12388 [D loss: 0.604865, acc.: 64.84%] [G loss: 1.090624]\n",
      "epoch:13 step:12389 [D loss: 0.593456, acc.: 71.09%] [G loss: 0.918127]\n",
      "epoch:13 step:12390 [D loss: 0.556753, acc.: 73.44%] [G loss: 1.005763]\n",
      "epoch:13 step:12391 [D loss: 0.659748, acc.: 64.06%] [G loss: 0.915683]\n",
      "epoch:13 step:12392 [D loss: 0.641120, acc.: 64.84%] [G loss: 1.026479]\n",
      "epoch:13 step:12393 [D loss: 0.670502, acc.: 63.28%] [G loss: 1.059392]\n",
      "epoch:13 step:12394 [D loss: 0.621483, acc.: 65.62%] [G loss: 1.000801]\n",
      "epoch:13 step:12395 [D loss: 0.664211, acc.: 55.47%] [G loss: 1.057172]\n",
      "epoch:13 step:12396 [D loss: 0.687415, acc.: 57.81%] [G loss: 0.903474]\n",
      "epoch:13 step:12397 [D loss: 0.710002, acc.: 48.44%] [G loss: 0.948306]\n",
      "epoch:13 step:12398 [D loss: 0.650255, acc.: 60.94%] [G loss: 0.840346]\n",
      "epoch:13 step:12399 [D loss: 0.636477, acc.: 66.41%] [G loss: 0.959242]\n",
      "epoch:13 step:12400 [D loss: 0.598674, acc.: 70.31%] [G loss: 1.083372]\n",
      "##############\n",
      "[2.33287753 1.51692785 5.63693465 4.20365953 2.92271113 5.23867798\n",
      " 4.22645876 4.56515756 3.802137   3.66655861]\n",
      "##########\n",
      "epoch:13 step:12401 [D loss: 0.518326, acc.: 75.78%] [G loss: 0.986757]\n",
      "epoch:13 step:12402 [D loss: 0.510057, acc.: 75.00%] [G loss: 1.221212]\n",
      "epoch:13 step:12403 [D loss: 0.490745, acc.: 81.25%] [G loss: 1.221117]\n",
      "epoch:13 step:12404 [D loss: 0.544535, acc.: 74.22%] [G loss: 1.109361]\n",
      "epoch:13 step:12405 [D loss: 0.764708, acc.: 43.75%] [G loss: 1.042506]\n",
      "epoch:13 step:12406 [D loss: 0.703763, acc.: 56.25%] [G loss: 0.902461]\n",
      "epoch:13 step:12407 [D loss: 0.643916, acc.: 64.84%] [G loss: 0.862966]\n",
      "epoch:13 step:12408 [D loss: 0.618143, acc.: 65.62%] [G loss: 1.052087]\n",
      "epoch:13 step:12409 [D loss: 0.622209, acc.: 64.06%] [G loss: 0.868734]\n",
      "epoch:13 step:12410 [D loss: 0.635759, acc.: 62.50%] [G loss: 0.829220]\n",
      "epoch:13 step:12411 [D loss: 0.445619, acc.: 83.59%] [G loss: 1.151666]\n",
      "epoch:13 step:12412 [D loss: 0.531184, acc.: 73.44%] [G loss: 1.007801]\n",
      "epoch:13 step:12413 [D loss: 0.482333, acc.: 78.91%] [G loss: 1.083507]\n",
      "epoch:13 step:12414 [D loss: 0.730999, acc.: 52.34%] [G loss: 1.170194]\n",
      "epoch:13 step:12415 [D loss: 0.799476, acc.: 45.31%] [G loss: 1.044112]\n",
      "epoch:13 step:12416 [D loss: 0.765889, acc.: 47.66%] [G loss: 0.941604]\n",
      "epoch:13 step:12417 [D loss: 0.565978, acc.: 70.31%] [G loss: 1.037433]\n",
      "epoch:13 step:12418 [D loss: 0.731396, acc.: 53.12%] [G loss: 0.837227]\n",
      "epoch:13 step:12419 [D loss: 0.574549, acc.: 73.44%] [G loss: 0.992041]\n",
      "epoch:13 step:12420 [D loss: 0.741059, acc.: 49.22%] [G loss: 0.960149]\n",
      "epoch:13 step:12421 [D loss: 0.838401, acc.: 39.84%] [G loss: 0.797527]\n",
      "epoch:13 step:12422 [D loss: 0.741202, acc.: 50.78%] [G loss: 0.770075]\n",
      "epoch:13 step:12423 [D loss: 0.639503, acc.: 61.72%] [G loss: 0.872061]\n",
      "epoch:13 step:12424 [D loss: 0.676567, acc.: 58.59%] [G loss: 0.897228]\n",
      "epoch:13 step:12425 [D loss: 0.672291, acc.: 57.81%] [G loss: 1.028704]\n",
      "epoch:13 step:12426 [D loss: 0.627989, acc.: 61.72%] [G loss: 0.980266]\n",
      "epoch:13 step:12427 [D loss: 0.590980, acc.: 71.88%] [G loss: 0.910240]\n",
      "epoch:13 step:12428 [D loss: 0.727422, acc.: 43.75%] [G loss: 0.934732]\n",
      "epoch:13 step:12429 [D loss: 0.685040, acc.: 54.69%] [G loss: 0.949912]\n",
      "epoch:13 step:12430 [D loss: 0.701332, acc.: 47.66%] [G loss: 0.880906]\n",
      "epoch:13 step:12431 [D loss: 0.675680, acc.: 60.16%] [G loss: 0.945560]\n",
      "epoch:13 step:12432 [D loss: 0.728484, acc.: 48.44%] [G loss: 0.818065]\n",
      "epoch:13 step:12433 [D loss: 0.701655, acc.: 57.81%] [G loss: 0.860843]\n",
      "epoch:13 step:12434 [D loss: 0.633102, acc.: 60.94%] [G loss: 0.932680]\n",
      "epoch:13 step:12435 [D loss: 0.666135, acc.: 59.38%] [G loss: 1.051380]\n",
      "epoch:13 step:12436 [D loss: 0.644000, acc.: 57.03%] [G loss: 0.968615]\n",
      "epoch:13 step:12437 [D loss: 0.625511, acc.: 69.53%] [G loss: 1.066930]\n",
      "epoch:13 step:12438 [D loss: 0.702315, acc.: 50.78%] [G loss: 0.821566]\n",
      "epoch:13 step:12439 [D loss: 0.670113, acc.: 61.72%] [G loss: 0.982304]\n",
      "epoch:13 step:12440 [D loss: 0.624650, acc.: 67.19%] [G loss: 0.779988]\n",
      "epoch:13 step:12441 [D loss: 0.619074, acc.: 63.28%] [G loss: 0.979153]\n",
      "epoch:13 step:12442 [D loss: 0.809808, acc.: 35.16%] [G loss: 0.983266]\n",
      "epoch:13 step:12443 [D loss: 0.601986, acc.: 67.19%] [G loss: 0.976099]\n",
      "epoch:13 step:12444 [D loss: 0.691175, acc.: 56.25%] [G loss: 0.943736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12445 [D loss: 0.600722, acc.: 67.19%] [G loss: 0.873599]\n",
      "epoch:13 step:12446 [D loss: 0.702741, acc.: 58.59%] [G loss: 1.031054]\n",
      "epoch:13 step:12447 [D loss: 0.679763, acc.: 59.38%] [G loss: 1.043467]\n",
      "epoch:13 step:12448 [D loss: 0.644087, acc.: 65.62%] [G loss: 0.977810]\n",
      "epoch:13 step:12449 [D loss: 0.730366, acc.: 47.66%] [G loss: 0.946856]\n",
      "epoch:13 step:12450 [D loss: 0.609948, acc.: 64.84%] [G loss: 1.017101]\n",
      "epoch:13 step:12451 [D loss: 0.773066, acc.: 42.97%] [G loss: 0.897368]\n",
      "epoch:13 step:12452 [D loss: 0.657889, acc.: 60.16%] [G loss: 1.066834]\n",
      "epoch:13 step:12453 [D loss: 0.695495, acc.: 52.34%] [G loss: 1.029620]\n",
      "epoch:13 step:12454 [D loss: 0.568164, acc.: 77.34%] [G loss: 1.108586]\n",
      "epoch:13 step:12455 [D loss: 0.688437, acc.: 57.03%] [G loss: 0.929994]\n",
      "epoch:13 step:12456 [D loss: 0.616050, acc.: 64.06%] [G loss: 1.089660]\n",
      "epoch:13 step:12457 [D loss: 0.718889, acc.: 52.34%] [G loss: 0.884103]\n",
      "epoch:13 step:12458 [D loss: 0.726082, acc.: 48.44%] [G loss: 0.877501]\n",
      "epoch:13 step:12459 [D loss: 0.739570, acc.: 43.75%] [G loss: 0.912475]\n",
      "epoch:13 step:12460 [D loss: 0.700074, acc.: 57.03%] [G loss: 0.922018]\n",
      "epoch:13 step:12461 [D loss: 0.590764, acc.: 72.66%] [G loss: 0.895657]\n",
      "epoch:13 step:12462 [D loss: 0.713968, acc.: 58.59%] [G loss: 0.968624]\n",
      "epoch:13 step:12463 [D loss: 0.677330, acc.: 54.69%] [G loss: 0.967102]\n",
      "epoch:13 step:12464 [D loss: 0.673899, acc.: 61.72%] [G loss: 1.027930]\n",
      "epoch:13 step:12465 [D loss: 0.575614, acc.: 71.88%] [G loss: 1.114116]\n",
      "epoch:13 step:12466 [D loss: 0.609061, acc.: 67.97%] [G loss: 1.155738]\n",
      "epoch:13 step:12467 [D loss: 0.557603, acc.: 74.22%] [G loss: 0.974733]\n",
      "epoch:13 step:12468 [D loss: 0.637537, acc.: 58.59%] [G loss: 0.930902]\n",
      "epoch:13 step:12469 [D loss: 0.632644, acc.: 62.50%] [G loss: 0.985737]\n",
      "epoch:13 step:12470 [D loss: 0.585515, acc.: 71.88%] [G loss: 0.906230]\n",
      "epoch:13 step:12471 [D loss: 0.639033, acc.: 61.72%] [G loss: 1.019853]\n",
      "epoch:13 step:12472 [D loss: 0.688437, acc.: 54.69%] [G loss: 0.984892]\n",
      "epoch:13 step:12473 [D loss: 0.525892, acc.: 77.34%] [G loss: 0.999958]\n",
      "epoch:13 step:12474 [D loss: 0.648989, acc.: 65.62%] [G loss: 0.995452]\n",
      "epoch:13 step:12475 [D loss: 0.685686, acc.: 56.25%] [G loss: 0.949308]\n",
      "epoch:13 step:12476 [D loss: 0.750859, acc.: 46.09%] [G loss: 0.897352]\n",
      "epoch:13 step:12477 [D loss: 0.681698, acc.: 56.25%] [G loss: 0.840190]\n",
      "epoch:13 step:12478 [D loss: 0.685031, acc.: 55.47%] [G loss: 0.953924]\n",
      "epoch:13 step:12479 [D loss: 0.538691, acc.: 78.91%] [G loss: 0.987534]\n",
      "epoch:13 step:12480 [D loss: 0.604082, acc.: 67.19%] [G loss: 0.999410]\n",
      "epoch:13 step:12481 [D loss: 0.544500, acc.: 75.78%] [G loss: 1.028262]\n",
      "epoch:13 step:12482 [D loss: 0.748730, acc.: 46.88%] [G loss: 0.926863]\n",
      "epoch:13 step:12483 [D loss: 0.689194, acc.: 59.38%] [G loss: 0.934661]\n",
      "epoch:13 step:12484 [D loss: 0.673277, acc.: 61.72%] [G loss: 0.835949]\n",
      "epoch:13 step:12485 [D loss: 0.616722, acc.: 62.50%] [G loss: 0.878639]\n",
      "epoch:13 step:12486 [D loss: 0.643282, acc.: 64.06%] [G loss: 0.995701]\n",
      "epoch:13 step:12487 [D loss: 0.683475, acc.: 61.72%] [G loss: 0.935070]\n",
      "epoch:13 step:12488 [D loss: 0.570732, acc.: 69.53%] [G loss: 0.889293]\n",
      "epoch:13 step:12489 [D loss: 0.579267, acc.: 71.88%] [G loss: 0.971247]\n",
      "epoch:13 step:12490 [D loss: 0.601850, acc.: 66.41%] [G loss: 0.924960]\n",
      "epoch:13 step:12491 [D loss: 0.667201, acc.: 60.94%] [G loss: 0.910676]\n",
      "epoch:13 step:12492 [D loss: 0.636134, acc.: 63.28%] [G loss: 0.897802]\n",
      "epoch:13 step:12493 [D loss: 0.554281, acc.: 75.78%] [G loss: 0.806223]\n",
      "epoch:13 step:12494 [D loss: 0.583249, acc.: 66.41%] [G loss: 1.013016]\n",
      "epoch:13 step:12495 [D loss: 0.564252, acc.: 67.19%] [G loss: 1.041020]\n",
      "epoch:13 step:12496 [D loss: 0.596636, acc.: 68.75%] [G loss: 1.113902]\n",
      "epoch:13 step:12497 [D loss: 0.788027, acc.: 48.44%] [G loss: 1.035409]\n",
      "epoch:13 step:12498 [D loss: 0.782978, acc.: 45.31%] [G loss: 0.916255]\n",
      "epoch:13 step:12499 [D loss: 0.570526, acc.: 78.12%] [G loss: 1.044961]\n",
      "epoch:13 step:12500 [D loss: 0.668449, acc.: 57.03%] [G loss: 1.054182]\n",
      "epoch:13 step:12501 [D loss: 0.646079, acc.: 63.28%] [G loss: 0.932241]\n",
      "epoch:13 step:12502 [D loss: 0.601426, acc.: 64.84%] [G loss: 0.935275]\n",
      "epoch:13 step:12503 [D loss: 0.621693, acc.: 64.06%] [G loss: 0.942253]\n",
      "epoch:13 step:12504 [D loss: 0.764060, acc.: 50.00%] [G loss: 0.921981]\n",
      "epoch:13 step:12505 [D loss: 0.582667, acc.: 71.88%] [G loss: 0.945514]\n",
      "epoch:13 step:12506 [D loss: 0.669252, acc.: 58.59%] [G loss: 0.838307]\n",
      "epoch:13 step:12507 [D loss: 0.658282, acc.: 61.72%] [G loss: 1.020426]\n",
      "epoch:13 step:12508 [D loss: 0.499362, acc.: 82.03%] [G loss: 1.081999]\n",
      "epoch:13 step:12509 [D loss: 0.524457, acc.: 77.34%] [G loss: 1.081649]\n",
      "epoch:13 step:12510 [D loss: 0.619376, acc.: 67.19%] [G loss: 0.963120]\n",
      "epoch:13 step:12511 [D loss: 0.637165, acc.: 64.84%] [G loss: 0.934059]\n",
      "epoch:13 step:12512 [D loss: 0.651426, acc.: 61.72%] [G loss: 0.944482]\n",
      "epoch:13 step:12513 [D loss: 0.638037, acc.: 65.62%] [G loss: 0.979312]\n",
      "epoch:13 step:12514 [D loss: 0.637943, acc.: 61.72%] [G loss: 0.911738]\n",
      "epoch:13 step:12515 [D loss: 0.711222, acc.: 50.78%] [G loss: 0.918383]\n",
      "epoch:13 step:12516 [D loss: 0.628947, acc.: 70.31%] [G loss: 0.987303]\n",
      "epoch:13 step:12517 [D loss: 0.573508, acc.: 74.22%] [G loss: 1.074398]\n",
      "epoch:13 step:12518 [D loss: 0.707908, acc.: 55.47%] [G loss: 0.781183]\n",
      "epoch:13 step:12519 [D loss: 0.649668, acc.: 62.50%] [G loss: 0.933023]\n",
      "epoch:13 step:12520 [D loss: 0.686106, acc.: 57.03%] [G loss: 0.967044]\n",
      "epoch:13 step:12521 [D loss: 0.629773, acc.: 61.72%] [G loss: 0.878478]\n",
      "epoch:13 step:12522 [D loss: 0.765253, acc.: 49.22%] [G loss: 0.927918]\n",
      "epoch:13 step:12523 [D loss: 0.685669, acc.: 60.16%] [G loss: 1.105438]\n",
      "epoch:13 step:12524 [D loss: 0.653636, acc.: 61.72%] [G loss: 0.899613]\n",
      "epoch:13 step:12525 [D loss: 0.612376, acc.: 68.75%] [G loss: 0.952192]\n",
      "epoch:13 step:12526 [D loss: 0.564294, acc.: 76.56%] [G loss: 1.039498]\n",
      "epoch:13 step:12527 [D loss: 0.521877, acc.: 77.34%] [G loss: 1.051153]\n",
      "epoch:13 step:12528 [D loss: 0.529357, acc.: 76.56%] [G loss: 1.082941]\n",
      "epoch:13 step:12529 [D loss: 0.668368, acc.: 56.25%] [G loss: 1.050863]\n",
      "epoch:13 step:12530 [D loss: 0.778347, acc.: 48.44%] [G loss: 1.090208]\n",
      "epoch:13 step:12531 [D loss: 0.632631, acc.: 64.06%] [G loss: 0.870639]\n",
      "epoch:13 step:12532 [D loss: 0.692588, acc.: 57.03%] [G loss: 0.935169]\n",
      "epoch:13 step:12533 [D loss: 0.606097, acc.: 66.41%] [G loss: 0.958857]\n",
      "epoch:13 step:12534 [D loss: 0.633041, acc.: 64.06%] [G loss: 0.944272]\n",
      "epoch:13 step:12535 [D loss: 0.635012, acc.: 60.94%] [G loss: 0.901863]\n",
      "epoch:13 step:12536 [D loss: 0.675492, acc.: 60.16%] [G loss: 0.919903]\n",
      "epoch:13 step:12537 [D loss: 0.788763, acc.: 42.19%] [G loss: 0.926571]\n",
      "epoch:13 step:12538 [D loss: 0.586601, acc.: 75.00%] [G loss: 1.046935]\n",
      "epoch:13 step:12539 [D loss: 0.648257, acc.: 63.28%] [G loss: 1.020835]\n",
      "epoch:13 step:12540 [D loss: 0.643329, acc.: 65.62%] [G loss: 0.880181]\n",
      "epoch:13 step:12541 [D loss: 0.556779, acc.: 76.56%] [G loss: 1.078746]\n",
      "epoch:13 step:12542 [D loss: 0.638271, acc.: 60.94%] [G loss: 0.907580]\n",
      "epoch:13 step:12543 [D loss: 0.693627, acc.: 59.38%] [G loss: 0.930214]\n",
      "epoch:13 step:12544 [D loss: 0.631564, acc.: 57.03%] [G loss: 1.044520]\n",
      "epoch:13 step:12545 [D loss: 0.709716, acc.: 55.47%] [G loss: 0.955396]\n",
      "epoch:13 step:12546 [D loss: 0.708368, acc.: 53.91%] [G loss: 0.938122]\n",
      "epoch:13 step:12547 [D loss: 0.576729, acc.: 71.88%] [G loss: 1.123131]\n",
      "epoch:13 step:12548 [D loss: 0.550720, acc.: 71.88%] [G loss: 1.223728]\n",
      "epoch:13 step:12549 [D loss: 0.626331, acc.: 63.28%] [G loss: 1.158675]\n",
      "epoch:13 step:12550 [D loss: 0.723649, acc.: 60.16%] [G loss: 1.087435]\n",
      "epoch:13 step:12551 [D loss: 0.672302, acc.: 57.03%] [G loss: 0.918461]\n",
      "epoch:13 step:12552 [D loss: 0.682785, acc.: 52.34%] [G loss: 0.898073]\n",
      "epoch:13 step:12553 [D loss: 0.659421, acc.: 62.50%] [G loss: 0.973500]\n",
      "epoch:13 step:12554 [D loss: 0.729280, acc.: 53.91%] [G loss: 0.871023]\n",
      "epoch:13 step:12555 [D loss: 0.649260, acc.: 65.62%] [G loss: 1.080580]\n",
      "epoch:13 step:12556 [D loss: 0.712211, acc.: 50.78%] [G loss: 0.746034]\n",
      "epoch:13 step:12557 [D loss: 0.830815, acc.: 41.41%] [G loss: 0.704736]\n",
      "epoch:13 step:12558 [D loss: 0.747016, acc.: 49.22%] [G loss: 0.862241]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12559 [D loss: 0.619933, acc.: 70.31%] [G loss: 0.998327]\n",
      "epoch:13 step:12560 [D loss: 0.646062, acc.: 60.94%] [G loss: 0.909566]\n",
      "epoch:13 step:12561 [D loss: 0.614774, acc.: 67.97%] [G loss: 0.954101]\n",
      "epoch:13 step:12562 [D loss: 0.532995, acc.: 73.44%] [G loss: 1.000001]\n",
      "epoch:13 step:12563 [D loss: 0.751733, acc.: 46.88%] [G loss: 1.021183]\n",
      "epoch:13 step:12564 [D loss: 0.602003, acc.: 67.19%] [G loss: 1.117999]\n",
      "epoch:13 step:12565 [D loss: 0.571906, acc.: 69.53%] [G loss: 1.020314]\n",
      "epoch:13 step:12566 [D loss: 0.616439, acc.: 63.28%] [G loss: 0.987809]\n",
      "epoch:13 step:12567 [D loss: 0.695279, acc.: 55.47%] [G loss: 1.028158]\n",
      "epoch:13 step:12568 [D loss: 0.646019, acc.: 59.38%] [G loss: 0.884914]\n",
      "epoch:13 step:12569 [D loss: 0.589828, acc.: 67.19%] [G loss: 0.839510]\n",
      "epoch:13 step:12570 [D loss: 0.643758, acc.: 61.72%] [G loss: 0.968475]\n",
      "epoch:13 step:12571 [D loss: 0.646415, acc.: 59.38%] [G loss: 0.885203]\n",
      "epoch:13 step:12572 [D loss: 0.625315, acc.: 66.41%] [G loss: 0.922769]\n",
      "epoch:13 step:12573 [D loss: 0.760832, acc.: 46.88%] [G loss: 0.960865]\n",
      "epoch:13 step:12574 [D loss: 0.650548, acc.: 60.94%] [G loss: 0.885701]\n",
      "epoch:13 step:12575 [D loss: 0.697030, acc.: 57.03%] [G loss: 0.928909]\n",
      "epoch:13 step:12576 [D loss: 0.584404, acc.: 74.22%] [G loss: 0.873856]\n",
      "epoch:13 step:12577 [D loss: 0.613699, acc.: 65.62%] [G loss: 0.990901]\n",
      "epoch:13 step:12578 [D loss: 0.594806, acc.: 68.75%] [G loss: 1.038023]\n",
      "epoch:13 step:12579 [D loss: 0.546976, acc.: 76.56%] [G loss: 1.166222]\n",
      "epoch:13 step:12580 [D loss: 0.483183, acc.: 82.03%] [G loss: 1.122793]\n",
      "epoch:13 step:12581 [D loss: 0.600397, acc.: 65.62%] [G loss: 1.059300]\n",
      "epoch:13 step:12582 [D loss: 0.692216, acc.: 60.16%] [G loss: 0.803678]\n",
      "epoch:13 step:12583 [D loss: 0.557792, acc.: 70.31%] [G loss: 0.994384]\n",
      "epoch:13 step:12584 [D loss: 0.608394, acc.: 65.62%] [G loss: 1.104575]\n",
      "epoch:13 step:12585 [D loss: 0.522903, acc.: 78.12%] [G loss: 1.052523]\n",
      "epoch:13 step:12586 [D loss: 0.501114, acc.: 82.03%] [G loss: 1.106723]\n",
      "epoch:13 step:12587 [D loss: 0.567706, acc.: 73.44%] [G loss: 1.011053]\n",
      "epoch:13 step:12588 [D loss: 0.618313, acc.: 62.50%] [G loss: 0.940050]\n",
      "epoch:13 step:12589 [D loss: 0.631788, acc.: 64.84%] [G loss: 1.080340]\n",
      "epoch:13 step:12590 [D loss: 0.657283, acc.: 60.16%] [G loss: 1.007785]\n",
      "epoch:13 step:12591 [D loss: 0.637015, acc.: 60.16%] [G loss: 0.981366]\n",
      "epoch:13 step:12592 [D loss: 0.758738, acc.: 51.56%] [G loss: 0.975021]\n",
      "epoch:13 step:12593 [D loss: 0.692800, acc.: 57.03%] [G loss: 0.912067]\n",
      "epoch:13 step:12594 [D loss: 0.832734, acc.: 39.84%] [G loss: 0.945479]\n",
      "epoch:13 step:12595 [D loss: 0.767557, acc.: 51.56%] [G loss: 0.659916]\n",
      "epoch:13 step:12596 [D loss: 0.664872, acc.: 60.94%] [G loss: 1.055110]\n",
      "epoch:13 step:12597 [D loss: 0.697030, acc.: 56.25%] [G loss: 0.726719]\n",
      "epoch:13 step:12598 [D loss: 0.760109, acc.: 49.22%] [G loss: 0.907455]\n",
      "epoch:13 step:12599 [D loss: 0.676195, acc.: 59.38%] [G loss: 0.968334]\n",
      "epoch:13 step:12600 [D loss: 0.652245, acc.: 64.06%] [G loss: 0.844698]\n",
      "##############\n",
      "[2.37778707 1.9558287  5.39294416 4.28622818 3.27842446 5.30589677\n",
      " 4.14373339 4.50868549 4.01609593 3.40310462]\n",
      "##########\n",
      "epoch:13 step:12601 [D loss: 0.652910, acc.: 62.50%] [G loss: 0.890943]\n",
      "epoch:13 step:12602 [D loss: 0.744114, acc.: 51.56%] [G loss: 1.015399]\n",
      "epoch:13 step:12603 [D loss: 0.679863, acc.: 57.81%] [G loss: 1.015850]\n",
      "epoch:13 step:12604 [D loss: 0.763826, acc.: 46.09%] [G loss: 0.912911]\n",
      "epoch:13 step:12605 [D loss: 0.708908, acc.: 59.38%] [G loss: 0.964226]\n",
      "epoch:13 step:12606 [D loss: 0.616036, acc.: 65.62%] [G loss: 1.096297]\n",
      "epoch:13 step:12607 [D loss: 0.667437, acc.: 56.25%] [G loss: 0.925678]\n",
      "epoch:13 step:12608 [D loss: 0.641063, acc.: 59.38%] [G loss: 1.051886]\n",
      "epoch:13 step:12609 [D loss: 0.699445, acc.: 56.25%] [G loss: 0.737975]\n",
      "epoch:13 step:12610 [D loss: 0.742051, acc.: 52.34%] [G loss: 0.806185]\n",
      "epoch:13 step:12611 [D loss: 0.636262, acc.: 68.75%] [G loss: 1.139734]\n",
      "epoch:13 step:12612 [D loss: 0.725460, acc.: 50.00%] [G loss: 1.064720]\n",
      "epoch:13 step:12613 [D loss: 0.765252, acc.: 47.66%] [G loss: 1.113470]\n",
      "epoch:13 step:12614 [D loss: 0.561783, acc.: 71.88%] [G loss: 0.969797]\n",
      "epoch:13 step:12615 [D loss: 0.676827, acc.: 58.59%] [G loss: 1.032556]\n",
      "epoch:13 step:12616 [D loss: 0.569218, acc.: 73.44%] [G loss: 0.995455]\n",
      "epoch:13 step:12617 [D loss: 0.553319, acc.: 76.56%] [G loss: 1.046913]\n",
      "epoch:13 step:12618 [D loss: 0.758228, acc.: 49.22%] [G loss: 0.959095]\n",
      "epoch:13 step:12619 [D loss: 0.650839, acc.: 57.81%] [G loss: 0.930754]\n",
      "epoch:13 step:12620 [D loss: 0.716868, acc.: 53.91%] [G loss: 0.984994]\n",
      "epoch:13 step:12621 [D loss: 0.598112, acc.: 66.41%] [G loss: 1.095710]\n",
      "epoch:13 step:12622 [D loss: 0.664411, acc.: 63.28%] [G loss: 1.153829]\n",
      "epoch:13 step:12623 [D loss: 0.581756, acc.: 71.88%] [G loss: 0.997956]\n",
      "epoch:13 step:12624 [D loss: 0.593358, acc.: 60.94%] [G loss: 1.124713]\n",
      "epoch:13 step:12625 [D loss: 0.604900, acc.: 68.75%] [G loss: 0.932643]\n",
      "epoch:13 step:12626 [D loss: 0.656560, acc.: 60.94%] [G loss: 0.954273]\n",
      "epoch:13 step:12627 [D loss: 0.631844, acc.: 59.38%] [G loss: 0.956616]\n",
      "epoch:13 step:12628 [D loss: 0.611434, acc.: 69.53%] [G loss: 1.118974]\n",
      "epoch:13 step:12629 [D loss: 0.684765, acc.: 56.25%] [G loss: 1.016024]\n",
      "epoch:13 step:12630 [D loss: 0.557916, acc.: 75.78%] [G loss: 1.069307]\n",
      "epoch:13 step:12631 [D loss: 0.642349, acc.: 63.28%] [G loss: 1.142895]\n",
      "epoch:13 step:12632 [D loss: 0.579023, acc.: 72.66%] [G loss: 1.156022]\n",
      "epoch:13 step:12633 [D loss: 0.541706, acc.: 74.22%] [G loss: 1.143328]\n",
      "epoch:13 step:12634 [D loss: 0.537088, acc.: 73.44%] [G loss: 1.078012]\n",
      "epoch:13 step:12635 [D loss: 0.539355, acc.: 75.00%] [G loss: 1.175022]\n",
      "epoch:13 step:12636 [D loss: 0.559459, acc.: 74.22%] [G loss: 0.982829]\n",
      "epoch:13 step:12637 [D loss: 0.511491, acc.: 75.00%] [G loss: 1.090276]\n",
      "epoch:13 step:12638 [D loss: 0.437177, acc.: 81.25%] [G loss: 1.284413]\n",
      "epoch:13 step:12639 [D loss: 0.900687, acc.: 36.72%] [G loss: 0.977753]\n",
      "epoch:13 step:12640 [D loss: 0.795460, acc.: 52.34%] [G loss: 1.062588]\n",
      "epoch:13 step:12641 [D loss: 0.794434, acc.: 50.00%] [G loss: 1.181747]\n",
      "epoch:13 step:12642 [D loss: 0.840821, acc.: 43.75%] [G loss: 0.938456]\n",
      "epoch:13 step:12643 [D loss: 0.871626, acc.: 36.72%] [G loss: 0.863630]\n",
      "epoch:13 step:12644 [D loss: 0.777589, acc.: 45.31%] [G loss: 0.991137]\n",
      "epoch:13 step:12645 [D loss: 0.683970, acc.: 54.69%] [G loss: 1.004201]\n",
      "epoch:13 step:12646 [D loss: 0.667136, acc.: 58.59%] [G loss: 1.004992]\n",
      "epoch:13 step:12647 [D loss: 0.559546, acc.: 68.75%] [G loss: 1.168878]\n",
      "epoch:13 step:12648 [D loss: 0.875005, acc.: 39.06%] [G loss: 0.942552]\n",
      "epoch:13 step:12649 [D loss: 0.595519, acc.: 72.66%] [G loss: 0.962430]\n",
      "epoch:13 step:12650 [D loss: 0.662476, acc.: 59.38%] [G loss: 0.966825]\n",
      "epoch:13 step:12651 [D loss: 0.509179, acc.: 79.69%] [G loss: 1.178541]\n",
      "epoch:13 step:12652 [D loss: 0.475024, acc.: 75.78%] [G loss: 1.249681]\n",
      "epoch:13 step:12653 [D loss: 0.635954, acc.: 59.38%] [G loss: 1.161243]\n",
      "epoch:13 step:12654 [D loss: 0.838914, acc.: 46.09%] [G loss: 1.082240]\n",
      "epoch:13 step:12655 [D loss: 0.717294, acc.: 54.69%] [G loss: 1.111505]\n",
      "epoch:13 step:12656 [D loss: 0.631976, acc.: 64.06%] [G loss: 0.980091]\n",
      "epoch:13 step:12657 [D loss: 0.651284, acc.: 60.16%] [G loss: 1.185447]\n",
      "epoch:13 step:12658 [D loss: 0.696864, acc.: 51.56%] [G loss: 1.091420]\n",
      "epoch:13 step:12659 [D loss: 0.725440, acc.: 52.34%] [G loss: 0.920735]\n",
      "epoch:13 step:12660 [D loss: 0.615243, acc.: 65.62%] [G loss: 1.025990]\n",
      "epoch:13 step:12661 [D loss: 0.752617, acc.: 49.22%] [G loss: 0.895796]\n",
      "epoch:13 step:12662 [D loss: 0.608004, acc.: 64.06%] [G loss: 0.938725]\n",
      "epoch:13 step:12663 [D loss: 0.686493, acc.: 55.47%] [G loss: 0.978724]\n",
      "epoch:13 step:12664 [D loss: 0.645148, acc.: 57.81%] [G loss: 1.028728]\n",
      "epoch:13 step:12665 [D loss: 0.558110, acc.: 71.88%] [G loss: 1.067719]\n",
      "epoch:13 step:12666 [D loss: 0.595635, acc.: 71.88%] [G loss: 1.128947]\n",
      "epoch:13 step:12667 [D loss: 0.655562, acc.: 64.06%] [G loss: 1.066952]\n",
      "epoch:13 step:12668 [D loss: 0.624001, acc.: 64.84%] [G loss: 1.090724]\n",
      "epoch:13 step:12669 [D loss: 0.598970, acc.: 69.53%] [G loss: 1.109435]\n",
      "epoch:13 step:12670 [D loss: 0.700375, acc.: 55.47%] [G loss: 0.955643]\n",
      "epoch:13 step:12671 [D loss: 0.709239, acc.: 55.47%] [G loss: 1.006441]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12672 [D loss: 0.715866, acc.: 47.66%] [G loss: 0.857383]\n",
      "epoch:13 step:12673 [D loss: 0.643344, acc.: 64.84%] [G loss: 0.939077]\n",
      "epoch:13 step:12674 [D loss: 0.610045, acc.: 66.41%] [G loss: 1.071092]\n",
      "epoch:13 step:12675 [D loss: 0.567948, acc.: 71.09%] [G loss: 0.850683]\n",
      "epoch:13 step:12676 [D loss: 0.626033, acc.: 69.53%] [G loss: 0.986267]\n",
      "epoch:13 step:12677 [D loss: 0.612429, acc.: 68.75%] [G loss: 0.839592]\n",
      "epoch:13 step:12678 [D loss: 0.485411, acc.: 82.81%] [G loss: 0.988248]\n",
      "epoch:13 step:12679 [D loss: 0.477183, acc.: 81.25%] [G loss: 1.218244]\n",
      "epoch:13 step:12680 [D loss: 0.425885, acc.: 86.72%] [G loss: 1.364899]\n",
      "epoch:13 step:12681 [D loss: 0.712108, acc.: 55.47%] [G loss: 1.121358]\n",
      "epoch:13 step:12682 [D loss: 0.758948, acc.: 50.78%] [G loss: 0.920712]\n",
      "epoch:13 step:12683 [D loss: 0.685924, acc.: 62.50%] [G loss: 0.990665]\n",
      "epoch:13 step:12684 [D loss: 0.641301, acc.: 65.62%] [G loss: 0.911761]\n",
      "epoch:13 step:12685 [D loss: 0.616466, acc.: 68.75%] [G loss: 0.936306]\n",
      "epoch:13 step:12686 [D loss: 0.676601, acc.: 56.25%] [G loss: 0.958994]\n",
      "epoch:13 step:12687 [D loss: 0.734035, acc.: 53.12%] [G loss: 0.886842]\n",
      "epoch:13 step:12688 [D loss: 0.618047, acc.: 67.97%] [G loss: 0.908764]\n",
      "epoch:13 step:12689 [D loss: 0.544751, acc.: 75.00%] [G loss: 1.043187]\n",
      "epoch:13 step:12690 [D loss: 0.660984, acc.: 64.06%] [G loss: 0.908635]\n",
      "epoch:13 step:12691 [D loss: 0.737627, acc.: 48.44%] [G loss: 0.909520]\n",
      "epoch:13 step:12692 [D loss: 0.723307, acc.: 52.34%] [G loss: 0.932485]\n",
      "epoch:13 step:12693 [D loss: 0.622303, acc.: 67.97%] [G loss: 0.931865]\n",
      "epoch:13 step:12694 [D loss: 0.582784, acc.: 74.22%] [G loss: 1.127967]\n",
      "epoch:13 step:12695 [D loss: 0.623428, acc.: 63.28%] [G loss: 0.959646]\n",
      "epoch:13 step:12696 [D loss: 0.659087, acc.: 62.50%] [G loss: 1.113200]\n",
      "epoch:13 step:12697 [D loss: 0.684886, acc.: 62.50%] [G loss: 0.914230]\n",
      "epoch:13 step:12698 [D loss: 0.685824, acc.: 58.59%] [G loss: 1.052195]\n",
      "epoch:13 step:12699 [D loss: 0.657263, acc.: 67.19%] [G loss: 0.954610]\n",
      "epoch:13 step:12700 [D loss: 0.616408, acc.: 67.19%] [G loss: 0.906130]\n",
      "epoch:13 step:12701 [D loss: 0.626607, acc.: 61.72%] [G loss: 0.878829]\n",
      "epoch:13 step:12702 [D loss: 0.649458, acc.: 65.62%] [G loss: 1.049952]\n",
      "epoch:13 step:12703 [D loss: 0.526923, acc.: 78.12%] [G loss: 0.899096]\n",
      "epoch:13 step:12704 [D loss: 0.627747, acc.: 65.62%] [G loss: 0.997431]\n",
      "epoch:13 step:12705 [D loss: 0.670251, acc.: 60.94%] [G loss: 0.880554]\n",
      "epoch:13 step:12706 [D loss: 0.771699, acc.: 47.66%] [G loss: 0.830162]\n",
      "epoch:13 step:12707 [D loss: 0.595698, acc.: 70.31%] [G loss: 1.037514]\n",
      "epoch:13 step:12708 [D loss: 0.663080, acc.: 60.16%] [G loss: 1.018554]\n",
      "epoch:13 step:12709 [D loss: 0.743276, acc.: 49.22%] [G loss: 0.960869]\n",
      "epoch:13 step:12710 [D loss: 0.702935, acc.: 49.22%] [G loss: 1.009300]\n",
      "epoch:13 step:12711 [D loss: 0.686853, acc.: 60.16%] [G loss: 0.845994]\n",
      "epoch:13 step:12712 [D loss: 0.674298, acc.: 61.72%] [G loss: 1.000279]\n",
      "epoch:13 step:12713 [D loss: 0.585486, acc.: 68.75%] [G loss: 0.857719]\n",
      "epoch:13 step:12714 [D loss: 0.579448, acc.: 70.31%] [G loss: 0.912583]\n",
      "epoch:13 step:12715 [D loss: 0.556915, acc.: 75.00%] [G loss: 1.082484]\n",
      "epoch:13 step:12716 [D loss: 0.707700, acc.: 55.47%] [G loss: 0.910264]\n",
      "epoch:13 step:12717 [D loss: 0.616137, acc.: 68.75%] [G loss: 0.948946]\n",
      "epoch:13 step:12718 [D loss: 0.578923, acc.: 68.75%] [G loss: 1.081149]\n",
      "epoch:13 step:12719 [D loss: 0.672416, acc.: 60.94%] [G loss: 0.925201]\n",
      "epoch:13 step:12720 [D loss: 0.591279, acc.: 68.75%] [G loss: 1.054298]\n",
      "epoch:13 step:12721 [D loss: 0.683100, acc.: 56.25%] [G loss: 0.869095]\n",
      "epoch:13 step:12722 [D loss: 0.667394, acc.: 58.59%] [G loss: 1.051498]\n",
      "epoch:13 step:12723 [D loss: 0.700534, acc.: 53.12%] [G loss: 0.890768]\n",
      "epoch:13 step:12724 [D loss: 0.679403, acc.: 59.38%] [G loss: 0.842589]\n",
      "epoch:13 step:12725 [D loss: 0.681091, acc.: 60.16%] [G loss: 1.008146]\n",
      "epoch:13 step:12726 [D loss: 0.658821, acc.: 53.12%] [G loss: 0.973443]\n",
      "epoch:13 step:12727 [D loss: 0.549905, acc.: 76.56%] [G loss: 1.025943]\n",
      "epoch:13 step:12728 [D loss: 0.620590, acc.: 66.41%] [G loss: 0.949569]\n",
      "epoch:13 step:12729 [D loss: 0.544939, acc.: 78.12%] [G loss: 1.082309]\n",
      "epoch:13 step:12730 [D loss: 0.606789, acc.: 68.75%] [G loss: 0.978115]\n",
      "epoch:13 step:12731 [D loss: 0.535573, acc.: 76.56%] [G loss: 1.175166]\n",
      "epoch:13 step:12732 [D loss: 0.489616, acc.: 83.59%] [G loss: 1.175722]\n",
      "epoch:13 step:12733 [D loss: 0.573012, acc.: 72.66%] [G loss: 1.238448]\n",
      "epoch:13 step:12734 [D loss: 0.585084, acc.: 67.97%] [G loss: 1.200691]\n",
      "epoch:13 step:12735 [D loss: 0.569338, acc.: 70.31%] [G loss: 0.999168]\n",
      "epoch:13 step:12736 [D loss: 0.486033, acc.: 76.56%] [G loss: 1.025986]\n",
      "epoch:13 step:12737 [D loss: 0.543420, acc.: 76.56%] [G loss: 1.025083]\n",
      "epoch:13 step:12738 [D loss: 0.523075, acc.: 75.00%] [G loss: 1.024493]\n",
      "epoch:13 step:12739 [D loss: 0.538396, acc.: 75.78%] [G loss: 1.223635]\n",
      "epoch:13 step:12740 [D loss: 0.921732, acc.: 35.16%] [G loss: 0.928431]\n",
      "epoch:13 step:12741 [D loss: 0.862122, acc.: 39.84%] [G loss: 1.087935]\n",
      "epoch:13 step:12742 [D loss: 0.657978, acc.: 60.94%] [G loss: 1.072237]\n",
      "epoch:13 step:12743 [D loss: 0.767979, acc.: 48.44%] [G loss: 1.125666]\n",
      "epoch:13 step:12744 [D loss: 0.731886, acc.: 54.69%] [G loss: 1.044567]\n",
      "epoch:13 step:12745 [D loss: 0.768769, acc.: 48.44%] [G loss: 0.896409]\n",
      "epoch:13 step:12746 [D loss: 0.692553, acc.: 55.47%] [G loss: 1.011201]\n",
      "epoch:13 step:12747 [D loss: 0.579474, acc.: 71.88%] [G loss: 0.985016]\n",
      "epoch:13 step:12748 [D loss: 0.606609, acc.: 69.53%] [G loss: 0.954883]\n",
      "epoch:13 step:12749 [D loss: 0.670261, acc.: 58.59%] [G loss: 1.141586]\n",
      "epoch:13 step:12750 [D loss: 0.603929, acc.: 66.41%] [G loss: 0.935727]\n",
      "epoch:13 step:12751 [D loss: 0.621160, acc.: 67.19%] [G loss: 1.025778]\n",
      "epoch:13 step:12752 [D loss: 0.621140, acc.: 66.41%] [G loss: 0.951360]\n",
      "epoch:13 step:12753 [D loss: 0.647148, acc.: 60.16%] [G loss: 1.075085]\n",
      "epoch:13 step:12754 [D loss: 0.606022, acc.: 67.97%] [G loss: 1.184906]\n",
      "epoch:13 step:12755 [D loss: 0.623997, acc.: 64.84%] [G loss: 0.885587]\n",
      "epoch:13 step:12756 [D loss: 0.615541, acc.: 67.97%] [G loss: 0.869266]\n",
      "epoch:13 step:12757 [D loss: 0.694460, acc.: 53.12%] [G loss: 0.870129]\n",
      "epoch:13 step:12758 [D loss: 0.604891, acc.: 70.31%] [G loss: 1.010741]\n",
      "epoch:13 step:12759 [D loss: 0.639940, acc.: 63.28%] [G loss: 0.987611]\n",
      "epoch:13 step:12760 [D loss: 0.682176, acc.: 57.81%] [G loss: 0.852266]\n",
      "epoch:13 step:12761 [D loss: 0.662046, acc.: 60.16%] [G loss: 0.947556]\n",
      "epoch:13 step:12762 [D loss: 0.669654, acc.: 59.38%] [G loss: 0.929168]\n",
      "epoch:13 step:12763 [D loss: 0.748275, acc.: 50.00%] [G loss: 0.890826]\n",
      "epoch:13 step:12764 [D loss: 0.654966, acc.: 59.38%] [G loss: 0.983538]\n",
      "epoch:13 step:12765 [D loss: 0.644937, acc.: 60.16%] [G loss: 0.925214]\n",
      "epoch:13 step:12766 [D loss: 0.702428, acc.: 55.47%] [G loss: 0.920021]\n",
      "epoch:13 step:12767 [D loss: 0.690279, acc.: 57.81%] [G loss: 0.982610]\n",
      "epoch:13 step:12768 [D loss: 0.530593, acc.: 74.22%] [G loss: 1.178666]\n",
      "epoch:13 step:12769 [D loss: 0.478289, acc.: 85.16%] [G loss: 1.133468]\n",
      "epoch:13 step:12770 [D loss: 0.534387, acc.: 78.12%] [G loss: 1.290494]\n",
      "epoch:13 step:12771 [D loss: 0.667968, acc.: 56.25%] [G loss: 0.898426]\n",
      "epoch:13 step:12772 [D loss: 0.690751, acc.: 45.31%] [G loss: 0.963780]\n",
      "epoch:13 step:12773 [D loss: 0.678554, acc.: 57.03%] [G loss: 0.958993]\n",
      "epoch:13 step:12774 [D loss: 0.653422, acc.: 64.84%] [G loss: 0.855234]\n",
      "epoch:13 step:12775 [D loss: 0.689209, acc.: 53.12%] [G loss: 0.944544]\n",
      "epoch:13 step:12776 [D loss: 0.751245, acc.: 49.22%] [G loss: 0.940499]\n",
      "epoch:13 step:12777 [D loss: 0.626819, acc.: 64.84%] [G loss: 1.101807]\n",
      "epoch:13 step:12778 [D loss: 0.609734, acc.: 67.19%] [G loss: 0.979801]\n",
      "epoch:13 step:12779 [D loss: 0.534630, acc.: 75.78%] [G loss: 1.001740]\n",
      "epoch:13 step:12780 [D loss: 0.667475, acc.: 64.84%] [G loss: 1.009841]\n",
      "epoch:13 step:12781 [D loss: 0.646627, acc.: 57.03%] [G loss: 1.046159]\n",
      "epoch:13 step:12782 [D loss: 0.676527, acc.: 58.59%] [G loss: 0.972116]\n",
      "epoch:13 step:12783 [D loss: 0.686016, acc.: 58.59%] [G loss: 0.927667]\n",
      "epoch:13 step:12784 [D loss: 0.539096, acc.: 75.78%] [G loss: 0.780691]\n",
      "epoch:13 step:12785 [D loss: 0.598594, acc.: 68.75%] [G loss: 0.761302]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12786 [D loss: 0.503411, acc.: 82.03%] [G loss: 1.039937]\n",
      "epoch:13 step:12787 [D loss: 0.665790, acc.: 60.16%] [G loss: 0.860858]\n",
      "epoch:13 step:12788 [D loss: 0.645103, acc.: 56.25%] [G loss: 0.958369]\n",
      "epoch:13 step:12789 [D loss: 0.550016, acc.: 75.78%] [G loss: 0.927386]\n",
      "epoch:13 step:12790 [D loss: 0.706472, acc.: 58.59%] [G loss: 0.965912]\n",
      "epoch:13 step:12791 [D loss: 0.675139, acc.: 60.16%] [G loss: 0.976780]\n",
      "epoch:13 step:12792 [D loss: 0.707583, acc.: 57.03%] [G loss: 1.092899]\n",
      "epoch:13 step:12793 [D loss: 0.693653, acc.: 53.12%] [G loss: 0.965058]\n",
      "epoch:13 step:12794 [D loss: 0.557527, acc.: 71.09%] [G loss: 1.049251]\n",
      "epoch:13 step:12795 [D loss: 0.610776, acc.: 64.84%] [G loss: 0.907976]\n",
      "epoch:13 step:12796 [D loss: 0.634745, acc.: 69.53%] [G loss: 0.930427]\n",
      "epoch:13 step:12797 [D loss: 0.562757, acc.: 75.00%] [G loss: 0.992041]\n",
      "epoch:13 step:12798 [D loss: 0.719029, acc.: 53.12%] [G loss: 1.021671]\n",
      "epoch:13 step:12799 [D loss: 0.670638, acc.: 57.03%] [G loss: 0.852428]\n",
      "epoch:13 step:12800 [D loss: 0.715838, acc.: 52.34%] [G loss: 0.944328]\n",
      "##############\n",
      "[2.34963391 1.2703446  5.56464146 4.39546914 2.95496916 5.06032267\n",
      " 4.07765339 4.36913557 3.9352943  3.45137487]\n",
      "##########\n",
      "epoch:13 step:12801 [D loss: 0.776672, acc.: 45.31%] [G loss: 0.915867]\n",
      "epoch:13 step:12802 [D loss: 0.728521, acc.: 49.22%] [G loss: 0.925356]\n",
      "epoch:13 step:12803 [D loss: 0.736538, acc.: 55.47%] [G loss: 0.962440]\n",
      "epoch:13 step:12804 [D loss: 0.565722, acc.: 72.66%] [G loss: 0.961117]\n",
      "epoch:13 step:12805 [D loss: 0.630274, acc.: 62.50%] [G loss: 0.908512]\n",
      "epoch:13 step:12806 [D loss: 0.720789, acc.: 52.34%] [G loss: 0.928870]\n",
      "epoch:13 step:12807 [D loss: 0.655885, acc.: 61.72%] [G loss: 0.956055]\n",
      "epoch:13 step:12808 [D loss: 0.743634, acc.: 46.88%] [G loss: 1.107062]\n",
      "epoch:13 step:12809 [D loss: 0.723892, acc.: 52.34%] [G loss: 0.955287]\n",
      "epoch:13 step:12810 [D loss: 0.550569, acc.: 73.44%] [G loss: 0.913851]\n",
      "epoch:13 step:12811 [D loss: 0.527323, acc.: 76.56%] [G loss: 1.099022]\n",
      "epoch:13 step:12812 [D loss: 0.604715, acc.: 70.31%] [G loss: 1.124223]\n",
      "epoch:13 step:12813 [D loss: 0.588416, acc.: 67.97%] [G loss: 0.967677]\n",
      "epoch:13 step:12814 [D loss: 0.512485, acc.: 81.25%] [G loss: 0.993090]\n",
      "epoch:13 step:12815 [D loss: 0.603276, acc.: 68.75%] [G loss: 0.986647]\n",
      "epoch:13 step:12816 [D loss: 0.635982, acc.: 62.50%] [G loss: 1.116367]\n",
      "epoch:13 step:12817 [D loss: 0.617785, acc.: 68.75%] [G loss: 1.292921]\n",
      "epoch:13 step:12818 [D loss: 0.746042, acc.: 48.44%] [G loss: 0.890503]\n",
      "epoch:13 step:12819 [D loss: 0.597290, acc.: 68.75%] [G loss: 1.023490]\n",
      "epoch:13 step:12820 [D loss: 0.644953, acc.: 63.28%] [G loss: 0.995770]\n",
      "epoch:13 step:12821 [D loss: 0.660476, acc.: 60.16%] [G loss: 0.899816]\n",
      "epoch:13 step:12822 [D loss: 0.640532, acc.: 65.62%] [G loss: 0.849509]\n",
      "epoch:13 step:12823 [D loss: 0.653130, acc.: 59.38%] [G loss: 0.964556]\n",
      "epoch:13 step:12824 [D loss: 0.654656, acc.: 60.94%] [G loss: 1.113216]\n",
      "epoch:13 step:12825 [D loss: 0.700643, acc.: 56.25%] [G loss: 1.057324]\n",
      "epoch:13 step:12826 [D loss: 0.584366, acc.: 70.31%] [G loss: 1.116883]\n",
      "epoch:13 step:12827 [D loss: 0.661521, acc.: 58.59%] [G loss: 0.873859]\n",
      "epoch:13 step:12828 [D loss: 0.654662, acc.: 64.84%] [G loss: 1.047367]\n",
      "epoch:13 step:12829 [D loss: 0.580114, acc.: 68.75%] [G loss: 0.956476]\n",
      "epoch:13 step:12830 [D loss: 0.622853, acc.: 64.84%] [G loss: 1.116728]\n",
      "epoch:13 step:12831 [D loss: 0.575126, acc.: 75.78%] [G loss: 1.090615]\n",
      "epoch:13 step:12832 [D loss: 0.687921, acc.: 58.59%] [G loss: 0.920690]\n",
      "epoch:13 step:12833 [D loss: 0.742075, acc.: 50.78%] [G loss: 0.904155]\n",
      "epoch:13 step:12834 [D loss: 0.567793, acc.: 75.00%] [G loss: 0.853960]\n",
      "epoch:13 step:12835 [D loss: 0.716963, acc.: 54.69%] [G loss: 0.816389]\n",
      "epoch:13 step:12836 [D loss: 0.685250, acc.: 57.03%] [G loss: 1.045864]\n",
      "epoch:13 step:12837 [D loss: 0.683242, acc.: 55.47%] [G loss: 0.824347]\n",
      "epoch:13 step:12838 [D loss: 0.664673, acc.: 54.69%] [G loss: 0.913087]\n",
      "epoch:13 step:12839 [D loss: 0.779235, acc.: 47.66%] [G loss: 0.866616]\n",
      "epoch:13 step:12840 [D loss: 0.645143, acc.: 56.25%] [G loss: 0.956215]\n",
      "epoch:13 step:12841 [D loss: 0.598959, acc.: 65.62%] [G loss: 1.007429]\n",
      "epoch:13 step:12842 [D loss: 0.628940, acc.: 66.41%] [G loss: 0.984535]\n",
      "epoch:13 step:12843 [D loss: 0.671612, acc.: 58.59%] [G loss: 0.961092]\n",
      "epoch:13 step:12844 [D loss: 0.446100, acc.: 85.94%] [G loss: 1.110237]\n",
      "epoch:13 step:12845 [D loss: 0.505628, acc.: 80.47%] [G loss: 1.058643]\n",
      "epoch:13 step:12846 [D loss: 0.505879, acc.: 80.47%] [G loss: 1.157236]\n",
      "epoch:13 step:12847 [D loss: 0.537165, acc.: 75.00%] [G loss: 1.209303]\n",
      "epoch:13 step:12848 [D loss: 0.543860, acc.: 71.88%] [G loss: 0.958994]\n",
      "epoch:13 step:12849 [D loss: 0.667449, acc.: 57.81%] [G loss: 0.936416]\n",
      "epoch:13 step:12850 [D loss: 0.625568, acc.: 59.38%] [G loss: 0.996918]\n",
      "epoch:13 step:12851 [D loss: 0.673142, acc.: 60.16%] [G loss: 0.944704]\n",
      "epoch:13 step:12852 [D loss: 0.611911, acc.: 62.50%] [G loss: 0.842075]\n",
      "epoch:13 step:12853 [D loss: 0.762844, acc.: 42.97%] [G loss: 0.843586]\n",
      "epoch:13 step:12854 [D loss: 0.727271, acc.: 53.12%] [G loss: 0.986332]\n",
      "epoch:13 step:12855 [D loss: 0.682861, acc.: 60.16%] [G loss: 1.048008]\n",
      "epoch:13 step:12856 [D loss: 0.702245, acc.: 56.25%] [G loss: 0.999396]\n",
      "epoch:13 step:12857 [D loss: 0.733600, acc.: 46.09%] [G loss: 0.907556]\n",
      "epoch:13 step:12858 [D loss: 0.718065, acc.: 56.25%] [G loss: 1.010906]\n",
      "epoch:13 step:12859 [D loss: 0.753915, acc.: 48.44%] [G loss: 1.050323]\n",
      "epoch:13 step:12860 [D loss: 0.743609, acc.: 50.00%] [G loss: 0.949798]\n",
      "epoch:13 step:12861 [D loss: 0.631775, acc.: 67.19%] [G loss: 0.969962]\n",
      "epoch:13 step:12862 [D loss: 0.663291, acc.: 56.25%] [G loss: 0.941987]\n",
      "epoch:13 step:12863 [D loss: 0.665590, acc.: 57.81%] [G loss: 0.914914]\n",
      "epoch:13 step:12864 [D loss: 0.703721, acc.: 53.91%] [G loss: 1.049096]\n",
      "epoch:13 step:12865 [D loss: 0.712650, acc.: 51.56%] [G loss: 0.961322]\n",
      "epoch:13 step:12866 [D loss: 0.581613, acc.: 65.62%] [G loss: 0.904426]\n",
      "epoch:13 step:12867 [D loss: 0.665556, acc.: 59.38%] [G loss: 1.031628]\n",
      "epoch:13 step:12868 [D loss: 0.698035, acc.: 53.12%] [G loss: 0.956077]\n",
      "epoch:13 step:12869 [D loss: 0.720183, acc.: 53.91%] [G loss: 0.907206]\n",
      "epoch:13 step:12870 [D loss: 0.620915, acc.: 66.41%] [G loss: 0.878119]\n",
      "epoch:13 step:12871 [D loss: 0.530453, acc.: 75.00%] [G loss: 1.070021]\n",
      "epoch:13 step:12872 [D loss: 0.546025, acc.: 74.22%] [G loss: 1.026048]\n",
      "epoch:13 step:12873 [D loss: 0.607297, acc.: 71.09%] [G loss: 1.189606]\n",
      "epoch:13 step:12874 [D loss: 0.561253, acc.: 71.09%] [G loss: 0.982469]\n",
      "epoch:13 step:12875 [D loss: 0.542176, acc.: 75.78%] [G loss: 0.878333]\n",
      "epoch:13 step:12876 [D loss: 0.539923, acc.: 75.00%] [G loss: 1.085830]\n",
      "epoch:13 step:12877 [D loss: 0.725086, acc.: 53.91%] [G loss: 1.107313]\n",
      "epoch:13 step:12878 [D loss: 0.754162, acc.: 47.66%] [G loss: 1.012900]\n",
      "epoch:13 step:12879 [D loss: 0.687375, acc.: 54.69%] [G loss: 1.110971]\n",
      "epoch:13 step:12880 [D loss: 0.705540, acc.: 52.34%] [G loss: 0.941538]\n",
      "epoch:13 step:12881 [D loss: 0.681756, acc.: 55.47%] [G loss: 1.031176]\n",
      "epoch:13 step:12882 [D loss: 0.693579, acc.: 53.12%] [G loss: 1.021111]\n",
      "epoch:13 step:12883 [D loss: 0.667777, acc.: 60.16%] [G loss: 0.976521]\n",
      "epoch:13 step:12884 [D loss: 0.659489, acc.: 57.03%] [G loss: 0.835158]\n",
      "epoch:13 step:12885 [D loss: 0.703613, acc.: 57.03%] [G loss: 0.929558]\n",
      "epoch:13 step:12886 [D loss: 0.688249, acc.: 55.47%] [G loss: 1.005623]\n",
      "epoch:13 step:12887 [D loss: 0.624324, acc.: 62.50%] [G loss: 1.040905]\n",
      "epoch:13 step:12888 [D loss: 0.667310, acc.: 60.94%] [G loss: 0.977952]\n",
      "epoch:13 step:12889 [D loss: 0.606865, acc.: 69.53%] [G loss: 0.994266]\n",
      "epoch:13 step:12890 [D loss: 0.494204, acc.: 78.12%] [G loss: 1.284329]\n",
      "epoch:13 step:12891 [D loss: 0.726510, acc.: 50.00%] [G loss: 1.059540]\n",
      "epoch:13 step:12892 [D loss: 0.835698, acc.: 38.28%] [G loss: 0.864975]\n",
      "epoch:13 step:12893 [D loss: 0.643009, acc.: 64.84%] [G loss: 1.054823]\n",
      "epoch:13 step:12894 [D loss: 0.637933, acc.: 64.84%] [G loss: 0.996208]\n",
      "epoch:13 step:12895 [D loss: 0.652168, acc.: 57.81%] [G loss: 0.954954]\n",
      "epoch:13 step:12896 [D loss: 0.674819, acc.: 60.16%] [G loss: 0.928905]\n",
      "epoch:13 step:12897 [D loss: 0.799700, acc.: 46.09%] [G loss: 0.975151]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12898 [D loss: 0.669156, acc.: 58.59%] [G loss: 0.887921]\n",
      "epoch:13 step:12899 [D loss: 0.685251, acc.: 53.12%] [G loss: 0.981191]\n",
      "epoch:13 step:12900 [D loss: 0.602390, acc.: 70.31%] [G loss: 1.064230]\n",
      "epoch:13 step:12901 [D loss: 0.714966, acc.: 52.34%] [G loss: 0.882081]\n",
      "epoch:13 step:12902 [D loss: 0.584624, acc.: 67.19%] [G loss: 0.800468]\n",
      "epoch:13 step:12903 [D loss: 0.691610, acc.: 59.38%] [G loss: 0.953397]\n",
      "epoch:13 step:12904 [D loss: 0.642337, acc.: 66.41%] [G loss: 1.053409]\n",
      "epoch:13 step:12905 [D loss: 0.489052, acc.: 84.38%] [G loss: 1.080991]\n",
      "epoch:13 step:12906 [D loss: 0.609869, acc.: 67.97%] [G loss: 1.025705]\n",
      "epoch:13 step:12907 [D loss: 0.660111, acc.: 60.94%] [G loss: 1.022258]\n",
      "epoch:13 step:12908 [D loss: 0.704301, acc.: 57.81%] [G loss: 1.064178]\n",
      "epoch:13 step:12909 [D loss: 0.557315, acc.: 73.44%] [G loss: 1.058749]\n",
      "epoch:13 step:12910 [D loss: 0.631759, acc.: 66.41%] [G loss: 0.928610]\n",
      "epoch:13 step:12911 [D loss: 0.542840, acc.: 76.56%] [G loss: 1.002556]\n",
      "epoch:13 step:12912 [D loss: 0.594056, acc.: 71.88%] [G loss: 0.912701]\n",
      "epoch:13 step:12913 [D loss: 0.594337, acc.: 64.84%] [G loss: 1.006199]\n",
      "epoch:13 step:12914 [D loss: 0.573133, acc.: 71.09%] [G loss: 0.921951]\n",
      "epoch:13 step:12915 [D loss: 0.652812, acc.: 57.81%] [G loss: 0.983457]\n",
      "epoch:13 step:12916 [D loss: 0.726415, acc.: 52.34%] [G loss: 1.161398]\n",
      "epoch:13 step:12917 [D loss: 0.567768, acc.: 77.34%] [G loss: 1.028965]\n",
      "epoch:13 step:12918 [D loss: 0.595074, acc.: 68.75%] [G loss: 1.028051]\n",
      "epoch:13 step:12919 [D loss: 0.648473, acc.: 58.59%] [G loss: 1.037736]\n",
      "epoch:13 step:12920 [D loss: 0.678993, acc.: 60.94%] [G loss: 1.011869]\n",
      "epoch:13 step:12921 [D loss: 0.680871, acc.: 58.59%] [G loss: 0.938934]\n",
      "epoch:13 step:12922 [D loss: 0.750459, acc.: 46.88%] [G loss: 0.841984]\n",
      "epoch:13 step:12923 [D loss: 0.663691, acc.: 57.81%] [G loss: 0.946345]\n",
      "epoch:13 step:12924 [D loss: 0.642290, acc.: 63.28%] [G loss: 1.033273]\n",
      "epoch:13 step:12925 [D loss: 0.660909, acc.: 56.25%] [G loss: 0.854362]\n",
      "epoch:13 step:12926 [D loss: 0.512662, acc.: 79.69%] [G loss: 1.044864]\n",
      "epoch:13 step:12927 [D loss: 0.608037, acc.: 65.62%] [G loss: 0.911040]\n",
      "epoch:13 step:12928 [D loss: 0.593537, acc.: 69.53%] [G loss: 0.937718]\n",
      "epoch:13 step:12929 [D loss: 0.582665, acc.: 70.31%] [G loss: 1.014259]\n",
      "epoch:13 step:12930 [D loss: 0.671670, acc.: 62.50%] [G loss: 0.960801]\n",
      "epoch:13 step:12931 [D loss: 0.599674, acc.: 70.31%] [G loss: 1.002439]\n",
      "epoch:13 step:12932 [D loss: 0.584973, acc.: 71.09%] [G loss: 1.026810]\n",
      "epoch:13 step:12933 [D loss: 0.769014, acc.: 43.75%] [G loss: 0.845655]\n",
      "epoch:13 step:12934 [D loss: 0.616707, acc.: 63.28%] [G loss: 0.942774]\n",
      "epoch:13 step:12935 [D loss: 0.712583, acc.: 53.12%] [G loss: 1.072789]\n",
      "epoch:13 step:12936 [D loss: 0.605443, acc.: 69.53%] [G loss: 1.024249]\n",
      "epoch:13 step:12937 [D loss: 0.695401, acc.: 54.69%] [G loss: 0.880157]\n",
      "epoch:13 step:12938 [D loss: 0.658926, acc.: 63.28%] [G loss: 1.058887]\n",
      "epoch:13 step:12939 [D loss: 0.643370, acc.: 64.84%] [G loss: 1.070854]\n",
      "epoch:13 step:12940 [D loss: 0.652825, acc.: 60.94%] [G loss: 1.069802]\n",
      "epoch:13 step:12941 [D loss: 0.756111, acc.: 51.56%] [G loss: 1.081359]\n",
      "epoch:13 step:12942 [D loss: 0.716024, acc.: 52.34%] [G loss: 0.802646]\n",
      "epoch:13 step:12943 [D loss: 0.633292, acc.: 65.62%] [G loss: 0.899694]\n",
      "epoch:13 step:12944 [D loss: 0.673812, acc.: 59.38%] [G loss: 0.909724]\n",
      "epoch:13 step:12945 [D loss: 0.603889, acc.: 64.06%] [G loss: 0.807705]\n",
      "epoch:13 step:12946 [D loss: 0.720694, acc.: 52.34%] [G loss: 0.871828]\n",
      "epoch:13 step:12947 [D loss: 0.717482, acc.: 55.47%] [G loss: 0.933113]\n",
      "epoch:13 step:12948 [D loss: 0.529387, acc.: 78.91%] [G loss: 1.071625]\n",
      "epoch:13 step:12949 [D loss: 0.635283, acc.: 62.50%] [G loss: 1.058888]\n",
      "epoch:13 step:12950 [D loss: 0.532549, acc.: 78.91%] [G loss: 1.156556]\n",
      "epoch:13 step:12951 [D loss: 0.687204, acc.: 60.94%] [G loss: 1.003318]\n",
      "epoch:13 step:12952 [D loss: 0.616344, acc.: 64.84%] [G loss: 1.162801]\n",
      "epoch:13 step:12953 [D loss: 0.712639, acc.: 52.34%] [G loss: 0.968998]\n",
      "epoch:13 step:12954 [D loss: 0.618292, acc.: 62.50%] [G loss: 0.979020]\n",
      "epoch:13 step:12955 [D loss: 0.565931, acc.: 67.97%] [G loss: 1.022105]\n",
      "epoch:13 step:12956 [D loss: 0.453188, acc.: 83.59%] [G loss: 1.108691]\n",
      "epoch:13 step:12957 [D loss: 0.539019, acc.: 77.34%] [G loss: 1.115875]\n",
      "epoch:13 step:12958 [D loss: 0.586444, acc.: 72.66%] [G loss: 0.999845]\n",
      "epoch:13 step:12959 [D loss: 0.652375, acc.: 65.62%] [G loss: 1.308291]\n",
      "epoch:13 step:12960 [D loss: 0.866310, acc.: 33.59%] [G loss: 0.856012]\n",
      "epoch:13 step:12961 [D loss: 0.661274, acc.: 60.16%] [G loss: 0.942658]\n",
      "epoch:13 step:12962 [D loss: 0.612218, acc.: 67.19%] [G loss: 1.136356]\n",
      "epoch:13 step:12963 [D loss: 0.595704, acc.: 71.09%] [G loss: 0.963148]\n",
      "epoch:13 step:12964 [D loss: 0.639598, acc.: 64.84%] [G loss: 1.060177]\n",
      "epoch:13 step:12965 [D loss: 0.731485, acc.: 48.44%] [G loss: 0.918949]\n",
      "epoch:13 step:12966 [D loss: 0.706798, acc.: 56.25%] [G loss: 0.746109]\n",
      "epoch:13 step:12967 [D loss: 0.615857, acc.: 63.28%] [G loss: 0.846426]\n",
      "epoch:13 step:12968 [D loss: 0.707067, acc.: 56.25%] [G loss: 0.949339]\n",
      "epoch:13 step:12969 [D loss: 0.661600, acc.: 57.03%] [G loss: 1.008895]\n",
      "epoch:13 step:12970 [D loss: 0.706604, acc.: 52.34%] [G loss: 0.874529]\n",
      "epoch:13 step:12971 [D loss: 0.599549, acc.: 70.31%] [G loss: 0.886785]\n",
      "epoch:13 step:12972 [D loss: 0.509907, acc.: 78.91%] [G loss: 1.132894]\n",
      "epoch:13 step:12973 [D loss: 0.473995, acc.: 82.81%] [G loss: 1.056245]\n",
      "epoch:13 step:12974 [D loss: 0.438381, acc.: 85.94%] [G loss: 1.142307]\n",
      "epoch:13 step:12975 [D loss: 0.538602, acc.: 74.22%] [G loss: 1.250037]\n",
      "epoch:13 step:12976 [D loss: 0.668699, acc.: 60.94%] [G loss: 0.992339]\n",
      "epoch:13 step:12977 [D loss: 0.655040, acc.: 60.94%] [G loss: 0.985209]\n",
      "epoch:13 step:12978 [D loss: 0.596797, acc.: 64.84%] [G loss: 1.103621]\n",
      "epoch:13 step:12979 [D loss: 0.658274, acc.: 57.81%] [G loss: 0.841785]\n",
      "epoch:13 step:12980 [D loss: 0.672772, acc.: 61.72%] [G loss: 0.885504]\n",
      "epoch:13 step:12981 [D loss: 0.672665, acc.: 57.81%] [G loss: 0.947405]\n",
      "epoch:13 step:12982 [D loss: 0.825027, acc.: 39.84%] [G loss: 0.994606]\n",
      "epoch:13 step:12983 [D loss: 0.671756, acc.: 61.72%] [G loss: 1.025781]\n",
      "epoch:13 step:12984 [D loss: 0.701553, acc.: 53.12%] [G loss: 0.945791]\n",
      "epoch:13 step:12985 [D loss: 0.540620, acc.: 75.78%] [G loss: 0.989877]\n",
      "epoch:13 step:12986 [D loss: 0.594094, acc.: 71.88%] [G loss: 1.007452]\n",
      "epoch:13 step:12987 [D loss: 0.481947, acc.: 78.12%] [G loss: 0.887440]\n",
      "epoch:13 step:12988 [D loss: 0.692912, acc.: 58.59%] [G loss: 0.827638]\n",
      "epoch:13 step:12989 [D loss: 0.654727, acc.: 60.94%] [G loss: 1.089353]\n",
      "epoch:13 step:12990 [D loss: 0.653635, acc.: 60.94%] [G loss: 0.990911]\n",
      "epoch:13 step:12991 [D loss: 0.671211, acc.: 62.50%] [G loss: 1.029838]\n",
      "epoch:13 step:12992 [D loss: 0.733898, acc.: 53.12%] [G loss: 0.983428]\n",
      "epoch:13 step:12993 [D loss: 0.685353, acc.: 55.47%] [G loss: 0.958386]\n",
      "epoch:13 step:12994 [D loss: 0.727819, acc.: 52.34%] [G loss: 0.780158]\n",
      "epoch:13 step:12995 [D loss: 0.619191, acc.: 63.28%] [G loss: 0.956426]\n",
      "epoch:13 step:12996 [D loss: 0.434745, acc.: 83.59%] [G loss: 1.088945]\n",
      "epoch:13 step:12997 [D loss: 0.548800, acc.: 76.56%] [G loss: 1.037060]\n",
      "epoch:13 step:12998 [D loss: 0.595541, acc.: 70.31%] [G loss: 1.178030]\n",
      "epoch:13 step:12999 [D loss: 0.609978, acc.: 63.28%] [G loss: 0.962988]\n",
      "epoch:13 step:13000 [D loss: 0.682463, acc.: 53.91%] [G loss: 0.772856]\n",
      "##############\n",
      "[2.01483145 1.65020019 5.34961198 4.42735965 2.9069288  5.29723757\n",
      " 4.15769184 4.34693779 3.76081117 3.2598615 ]\n",
      "##########\n",
      "epoch:13 step:13001 [D loss: 0.703820, acc.: 53.91%] [G loss: 0.992031]\n",
      "epoch:13 step:13002 [D loss: 0.744740, acc.: 50.78%] [G loss: 0.910957]\n",
      "epoch:13 step:13003 [D loss: 0.709215, acc.: 54.69%] [G loss: 1.016063]\n",
      "epoch:13 step:13004 [D loss: 0.576236, acc.: 74.22%] [G loss: 1.009256]\n",
      "epoch:13 step:13005 [D loss: 0.664796, acc.: 60.16%] [G loss: 1.052112]\n",
      "epoch:13 step:13006 [D loss: 0.610236, acc.: 72.66%] [G loss: 1.048567]\n",
      "epoch:13 step:13007 [D loss: 0.565366, acc.: 71.88%] [G loss: 1.063111]\n",
      "epoch:13 step:13008 [D loss: 0.621150, acc.: 62.50%] [G loss: 1.019586]\n",
      "epoch:13 step:13009 [D loss: 0.713262, acc.: 51.56%] [G loss: 1.038077]\n",
      "epoch:13 step:13010 [D loss: 0.663530, acc.: 54.69%] [G loss: 0.878440]\n",
      "epoch:13 step:13011 [D loss: 0.618868, acc.: 67.19%] [G loss: 0.880904]\n",
      "epoch:13 step:13012 [D loss: 0.505911, acc.: 78.12%] [G loss: 1.079115]\n",
      "epoch:13 step:13013 [D loss: 0.570406, acc.: 67.19%] [G loss: 1.021729]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:13014 [D loss: 0.586463, acc.: 71.09%] [G loss: 1.009911]\n",
      "epoch:13 step:13015 [D loss: 0.781500, acc.: 43.75%] [G loss: 0.949728]\n",
      "epoch:13 step:13016 [D loss: 0.770439, acc.: 41.41%] [G loss: 1.015959]\n",
      "epoch:13 step:13017 [D loss: 0.759184, acc.: 46.88%] [G loss: 1.186743]\n",
      "epoch:13 step:13018 [D loss: 0.606028, acc.: 67.19%] [G loss: 1.035131]\n",
      "epoch:13 step:13019 [D loss: 0.603854, acc.: 68.75%] [G loss: 0.953366]\n",
      "epoch:13 step:13020 [D loss: 0.584791, acc.: 73.44%] [G loss: 0.999921]\n",
      "epoch:13 step:13021 [D loss: 0.638802, acc.: 64.06%] [G loss: 1.155527]\n",
      "epoch:13 step:13022 [D loss: 0.600641, acc.: 69.53%] [G loss: 1.008448]\n",
      "epoch:13 step:13023 [D loss: 0.620477, acc.: 64.06%] [G loss: 0.941367]\n",
      "epoch:13 step:13024 [D loss: 0.718389, acc.: 54.69%] [G loss: 1.035355]\n",
      "epoch:13 step:13025 [D loss: 0.666138, acc.: 60.16%] [G loss: 1.028558]\n",
      "epoch:13 step:13026 [D loss: 0.648740, acc.: 60.16%] [G loss: 0.939686]\n",
      "epoch:13 step:13027 [D loss: 0.723744, acc.: 54.69%] [G loss: 1.005201]\n",
      "epoch:13 step:13028 [D loss: 0.667364, acc.: 60.94%] [G loss: 0.939529]\n",
      "epoch:13 step:13029 [D loss: 0.638816, acc.: 67.97%] [G loss: 0.953603]\n",
      "epoch:13 step:13030 [D loss: 0.554713, acc.: 72.66%] [G loss: 0.940920]\n",
      "epoch:13 step:13031 [D loss: 0.553277, acc.: 75.78%] [G loss: 1.123699]\n",
      "epoch:13 step:13032 [D loss: 0.599145, acc.: 64.06%] [G loss: 1.044576]\n",
      "epoch:13 step:13033 [D loss: 0.489155, acc.: 83.59%] [G loss: 1.340526]\n",
      "epoch:13 step:13034 [D loss: 0.529292, acc.: 75.00%] [G loss: 1.200284]\n",
      "epoch:13 step:13035 [D loss: 0.467457, acc.: 83.59%] [G loss: 1.089903]\n",
      "epoch:13 step:13036 [D loss: 0.579035, acc.: 71.09%] [G loss: 1.106673]\n",
      "epoch:13 step:13037 [D loss: 0.559172, acc.: 70.31%] [G loss: 1.262123]\n",
      "epoch:13 step:13038 [D loss: 0.500226, acc.: 79.69%] [G loss: 1.073157]\n",
      "epoch:13 step:13039 [D loss: 0.928816, acc.: 31.25%] [G loss: 0.984457]\n",
      "epoch:13 step:13040 [D loss: 0.758247, acc.: 48.44%] [G loss: 0.844569]\n",
      "epoch:13 step:13041 [D loss: 0.645151, acc.: 59.38%] [G loss: 0.884907]\n",
      "epoch:13 step:13042 [D loss: 0.623294, acc.: 66.41%] [G loss: 0.965379]\n",
      "epoch:13 step:13043 [D loss: 0.674890, acc.: 59.38%] [G loss: 1.037769]\n",
      "epoch:13 step:13044 [D loss: 0.584663, acc.: 67.97%] [G loss: 0.999729]\n",
      "epoch:13 step:13045 [D loss: 0.696453, acc.: 60.94%] [G loss: 0.775122]\n",
      "epoch:13 step:13046 [D loss: 0.655475, acc.: 60.16%] [G loss: 0.863964]\n",
      "epoch:13 step:13047 [D loss: 0.687972, acc.: 55.47%] [G loss: 1.022529]\n",
      "epoch:13 step:13048 [D loss: 0.695951, acc.: 57.03%] [G loss: 0.975778]\n",
      "epoch:13 step:13049 [D loss: 0.744687, acc.: 45.31%] [G loss: 0.859710]\n",
      "epoch:13 step:13050 [D loss: 0.582352, acc.: 68.75%] [G loss: 0.894154]\n",
      "epoch:13 step:13051 [D loss: 0.719971, acc.: 53.12%] [G loss: 0.779138]\n",
      "epoch:13 step:13052 [D loss: 0.624964, acc.: 68.75%] [G loss: 0.882546]\n",
      "epoch:13 step:13053 [D loss: 0.568835, acc.: 72.66%] [G loss: 1.014183]\n",
      "epoch:13 step:13054 [D loss: 0.681655, acc.: 60.94%] [G loss: 1.020387]\n",
      "epoch:13 step:13055 [D loss: 0.677944, acc.: 58.59%] [G loss: 0.926369]\n",
      "epoch:13 step:13056 [D loss: 0.568703, acc.: 71.09%] [G loss: 1.023137]\n",
      "epoch:13 step:13057 [D loss: 0.651185, acc.: 64.84%] [G loss: 0.950521]\n",
      "epoch:13 step:13058 [D loss: 0.712713, acc.: 46.09%] [G loss: 0.849218]\n",
      "epoch:13 step:13059 [D loss: 0.732120, acc.: 51.56%] [G loss: 0.875377]\n",
      "epoch:13 step:13060 [D loss: 0.647065, acc.: 63.28%] [G loss: 1.029673]\n",
      "epoch:13 step:13061 [D loss: 0.659572, acc.: 57.81%] [G loss: 0.951627]\n",
      "epoch:13 step:13062 [D loss: 0.794694, acc.: 44.53%] [G loss: 0.824845]\n",
      "epoch:13 step:13063 [D loss: 0.677641, acc.: 64.06%] [G loss: 0.982925]\n",
      "epoch:13 step:13064 [D loss: 0.679681, acc.: 60.94%] [G loss: 0.877313]\n",
      "epoch:13 step:13065 [D loss: 0.587748, acc.: 69.53%] [G loss: 0.871302]\n",
      "epoch:13 step:13066 [D loss: 0.535526, acc.: 74.22%] [G loss: 1.018324]\n",
      "epoch:13 step:13067 [D loss: 0.570486, acc.: 71.09%] [G loss: 1.122465]\n",
      "epoch:13 step:13068 [D loss: 0.672620, acc.: 54.69%] [G loss: 0.748610]\n",
      "epoch:13 step:13069 [D loss: 0.567551, acc.: 77.34%] [G loss: 0.989610]\n",
      "epoch:13 step:13070 [D loss: 0.555073, acc.: 75.00%] [G loss: 1.117609]\n",
      "epoch:13 step:13071 [D loss: 0.626249, acc.: 62.50%] [G loss: 1.024805]\n",
      "epoch:13 step:13072 [D loss: 0.803072, acc.: 40.62%] [G loss: 0.811227]\n",
      "epoch:13 step:13073 [D loss: 0.697845, acc.: 56.25%] [G loss: 1.106133]\n",
      "epoch:13 step:13074 [D loss: 0.681242, acc.: 53.12%] [G loss: 1.039077]\n",
      "epoch:13 step:13075 [D loss: 0.584854, acc.: 71.09%] [G loss: 1.038498]\n",
      "epoch:13 step:13076 [D loss: 0.572410, acc.: 68.75%] [G loss: 1.079256]\n",
      "epoch:13 step:13077 [D loss: 0.600272, acc.: 68.75%] [G loss: 1.009044]\n",
      "epoch:13 step:13078 [D loss: 0.563906, acc.: 67.97%] [G loss: 0.968737]\n",
      "epoch:13 step:13079 [D loss: 0.471727, acc.: 78.12%] [G loss: 1.125555]\n",
      "epoch:13 step:13080 [D loss: 0.411056, acc.: 85.16%] [G loss: 1.262701]\n",
      "epoch:13 step:13081 [D loss: 0.378413, acc.: 89.84%] [G loss: 1.247956]\n",
      "epoch:13 step:13082 [D loss: 0.515890, acc.: 74.22%] [G loss: 1.229606]\n",
      "epoch:13 step:13083 [D loss: 0.593784, acc.: 66.41%] [G loss: 1.209906]\n",
      "epoch:13 step:13084 [D loss: 0.641236, acc.: 60.16%] [G loss: 0.936638]\n",
      "epoch:13 step:13085 [D loss: 0.795380, acc.: 42.97%] [G loss: 0.899557]\n",
      "epoch:13 step:13086 [D loss: 0.701834, acc.: 56.25%] [G loss: 0.994683]\n",
      "epoch:13 step:13087 [D loss: 0.669020, acc.: 57.81%] [G loss: 0.924224]\n",
      "epoch:13 step:13088 [D loss: 0.685378, acc.: 56.25%] [G loss: 0.834346]\n",
      "epoch:13 step:13089 [D loss: 0.650644, acc.: 60.94%] [G loss: 1.194226]\n",
      "epoch:13 step:13090 [D loss: 0.559292, acc.: 71.88%] [G loss: 1.138548]\n",
      "epoch:13 step:13091 [D loss: 0.561761, acc.: 71.09%] [G loss: 0.938056]\n",
      "epoch:13 step:13092 [D loss: 0.500091, acc.: 79.69%] [G loss: 0.884352]\n",
      "epoch:13 step:13093 [D loss: 0.352936, acc.: 89.84%] [G loss: 1.446310]\n",
      "epoch:13 step:13094 [D loss: 0.753386, acc.: 50.00%] [G loss: 1.294895]\n",
      "epoch:13 step:13095 [D loss: 0.738726, acc.: 52.34%] [G loss: 0.998842]\n",
      "epoch:13 step:13096 [D loss: 0.868078, acc.: 35.16%] [G loss: 0.780179]\n",
      "epoch:13 step:13097 [D loss: 0.729822, acc.: 57.03%] [G loss: 1.043182]\n",
      "epoch:13 step:13098 [D loss: 0.645941, acc.: 61.72%] [G loss: 1.006886]\n",
      "epoch:13 step:13099 [D loss: 0.575499, acc.: 73.44%] [G loss: 1.101522]\n",
      "epoch:13 step:13100 [D loss: 0.473753, acc.: 80.47%] [G loss: 1.116183]\n",
      "epoch:13 step:13101 [D loss: 0.725564, acc.: 53.91%] [G loss: 1.134067]\n",
      "epoch:13 step:13102 [D loss: 0.767821, acc.: 49.22%] [G loss: 0.922018]\n",
      "epoch:13 step:13103 [D loss: 0.433338, acc.: 88.28%] [G loss: 0.992668]\n",
      "epoch:13 step:13104 [D loss: 0.564679, acc.: 72.66%] [G loss: 0.946793]\n",
      "epoch:13 step:13105 [D loss: 0.517427, acc.: 75.78%] [G loss: 0.949156]\n",
      "epoch:13 step:13106 [D loss: 0.559387, acc.: 69.53%] [G loss: 1.161455]\n",
      "epoch:13 step:13107 [D loss: 0.497150, acc.: 82.03%] [G loss: 1.054389]\n",
      "epoch:13 step:13108 [D loss: 0.461686, acc.: 82.03%] [G loss: 1.171541]\n",
      "epoch:13 step:13109 [D loss: 0.866983, acc.: 42.97%] [G loss: 1.096046]\n",
      "epoch:13 step:13110 [D loss: 0.606600, acc.: 67.97%] [G loss: 1.267397]\n",
      "epoch:13 step:13111 [D loss: 0.610893, acc.: 64.84%] [G loss: 1.148597]\n",
      "epoch:13 step:13112 [D loss: 0.588202, acc.: 64.84%] [G loss: 1.086523]\n",
      "epoch:13 step:13113 [D loss: 0.638119, acc.: 58.59%] [G loss: 0.936573]\n",
      "epoch:13 step:13114 [D loss: 0.609281, acc.: 67.97%] [G loss: 0.900749]\n",
      "epoch:13 step:13115 [D loss: 0.572121, acc.: 73.44%] [G loss: 0.878072]\n",
      "epoch:13 step:13116 [D loss: 0.600862, acc.: 64.84%] [G loss: 0.946927]\n",
      "epoch:13 step:13117 [D loss: 0.498125, acc.: 80.47%] [G loss: 1.112516]\n",
      "epoch:13 step:13118 [D loss: 0.367868, acc.: 88.28%] [G loss: 1.182087]\n",
      "epoch:14 step:13119 [D loss: 0.740836, acc.: 51.56%] [G loss: 0.927922]\n",
      "epoch:14 step:13120 [D loss: 0.687021, acc.: 56.25%] [G loss: 1.149355]\n",
      "epoch:14 step:13121 [D loss: 0.734160, acc.: 44.53%] [G loss: 0.977749]\n",
      "epoch:14 step:13122 [D loss: 0.698545, acc.: 60.16%] [G loss: 1.005897]\n",
      "epoch:14 step:13123 [D loss: 0.648106, acc.: 58.59%] [G loss: 0.983919]\n",
      "epoch:14 step:13124 [D loss: 0.620737, acc.: 64.06%] [G loss: 1.115811]\n",
      "epoch:14 step:13125 [D loss: 0.640328, acc.: 62.50%] [G loss: 1.011342]\n",
      "epoch:14 step:13126 [D loss: 0.659511, acc.: 62.50%] [G loss: 1.036584]\n",
      "epoch:14 step:13127 [D loss: 0.571537, acc.: 70.31%] [G loss: 1.016318]\n",
      "epoch:14 step:13128 [D loss: 0.690108, acc.: 57.03%] [G loss: 0.903631]\n",
      "epoch:14 step:13129 [D loss: 0.684411, acc.: 59.38%] [G loss: 0.929134]\n",
      "epoch:14 step:13130 [D loss: 0.734589, acc.: 52.34%] [G loss: 0.879194]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13131 [D loss: 0.724801, acc.: 54.69%] [G loss: 0.954747]\n",
      "epoch:14 step:13132 [D loss: 0.673351, acc.: 64.06%] [G loss: 1.020108]\n",
      "epoch:14 step:13133 [D loss: 0.548581, acc.: 72.66%] [G loss: 0.994154]\n",
      "epoch:14 step:13134 [D loss: 0.620777, acc.: 63.28%] [G loss: 1.094268]\n",
      "epoch:14 step:13135 [D loss: 0.635991, acc.: 61.72%] [G loss: 1.126036]\n",
      "epoch:14 step:13136 [D loss: 0.733430, acc.: 51.56%] [G loss: 0.939643]\n",
      "epoch:14 step:13137 [D loss: 0.667524, acc.: 56.25%] [G loss: 0.981362]\n",
      "epoch:14 step:13138 [D loss: 0.626797, acc.: 64.06%] [G loss: 1.019962]\n",
      "epoch:14 step:13139 [D loss: 0.662269, acc.: 61.72%] [G loss: 0.855420]\n",
      "epoch:14 step:13140 [D loss: 0.719559, acc.: 53.12%] [G loss: 0.864570]\n",
      "epoch:14 step:13141 [D loss: 0.606260, acc.: 67.19%] [G loss: 0.935106]\n",
      "epoch:14 step:13142 [D loss: 0.619830, acc.: 62.50%] [G loss: 0.826720]\n",
      "epoch:14 step:13143 [D loss: 0.636364, acc.: 64.06%] [G loss: 0.962966]\n",
      "epoch:14 step:13144 [D loss: 0.572130, acc.: 68.75%] [G loss: 0.944542]\n",
      "epoch:14 step:13145 [D loss: 0.602704, acc.: 70.31%] [G loss: 1.016130]\n",
      "epoch:14 step:13146 [D loss: 0.542962, acc.: 75.00%] [G loss: 1.141804]\n",
      "epoch:14 step:13147 [D loss: 0.553898, acc.: 70.31%] [G loss: 1.121315]\n",
      "epoch:14 step:13148 [D loss: 0.635816, acc.: 60.16%] [G loss: 1.097520]\n",
      "epoch:14 step:13149 [D loss: 0.674473, acc.: 57.03%] [G loss: 1.046126]\n",
      "epoch:14 step:13150 [D loss: 0.522250, acc.: 76.56%] [G loss: 1.119419]\n",
      "epoch:14 step:13151 [D loss: 0.500564, acc.: 81.25%] [G loss: 1.192136]\n",
      "epoch:14 step:13152 [D loss: 0.613271, acc.: 67.97%] [G loss: 1.011024]\n",
      "epoch:14 step:13153 [D loss: 0.517460, acc.: 77.34%] [G loss: 1.163662]\n",
      "epoch:14 step:13154 [D loss: 0.446422, acc.: 85.16%] [G loss: 1.335374]\n",
      "epoch:14 step:13155 [D loss: 0.796425, acc.: 50.00%] [G loss: 1.185586]\n",
      "epoch:14 step:13156 [D loss: 0.824250, acc.: 39.84%] [G loss: 0.921514]\n",
      "epoch:14 step:13157 [D loss: 0.711221, acc.: 55.47%] [G loss: 1.084779]\n",
      "epoch:14 step:13158 [D loss: 0.675482, acc.: 57.03%] [G loss: 0.972626]\n",
      "epoch:14 step:13159 [D loss: 0.683536, acc.: 63.28%] [G loss: 0.957185]\n",
      "epoch:14 step:13160 [D loss: 0.626284, acc.: 64.84%] [G loss: 1.056606]\n",
      "epoch:14 step:13161 [D loss: 0.592379, acc.: 64.84%] [G loss: 1.019951]\n",
      "epoch:14 step:13162 [D loss: 0.680408, acc.: 58.59%] [G loss: 0.956667]\n",
      "epoch:14 step:13163 [D loss: 0.693083, acc.: 56.25%] [G loss: 0.834921]\n",
      "epoch:14 step:13164 [D loss: 0.746040, acc.: 51.56%] [G loss: 0.854612]\n",
      "epoch:14 step:13165 [D loss: 0.624313, acc.: 63.28%] [G loss: 0.994526]\n",
      "epoch:14 step:13166 [D loss: 0.649395, acc.: 60.16%] [G loss: 0.966167]\n",
      "epoch:14 step:13167 [D loss: 0.536818, acc.: 72.66%] [G loss: 1.152605]\n",
      "epoch:14 step:13168 [D loss: 0.595760, acc.: 66.41%] [G loss: 1.121174]\n",
      "epoch:14 step:13169 [D loss: 0.662517, acc.: 64.06%] [G loss: 1.095544]\n",
      "epoch:14 step:13170 [D loss: 0.644308, acc.: 65.62%] [G loss: 0.881641]\n",
      "epoch:14 step:13171 [D loss: 0.637158, acc.: 60.94%] [G loss: 0.975966]\n",
      "epoch:14 step:13172 [D loss: 0.554378, acc.: 69.53%] [G loss: 0.959955]\n",
      "epoch:14 step:13173 [D loss: 0.522542, acc.: 75.78%] [G loss: 1.149665]\n",
      "epoch:14 step:13174 [D loss: 0.663715, acc.: 54.69%] [G loss: 1.018769]\n",
      "epoch:14 step:13175 [D loss: 0.699902, acc.: 53.12%] [G loss: 1.091270]\n",
      "epoch:14 step:13176 [D loss: 0.687011, acc.: 54.69%] [G loss: 1.031439]\n",
      "epoch:14 step:13177 [D loss: 0.682226, acc.: 57.03%] [G loss: 1.208229]\n",
      "epoch:14 step:13178 [D loss: 0.759652, acc.: 49.22%] [G loss: 1.032521]\n",
      "epoch:14 step:13179 [D loss: 0.615296, acc.: 61.72%] [G loss: 0.960246]\n",
      "epoch:14 step:13180 [D loss: 0.664199, acc.: 59.38%] [G loss: 0.852404]\n",
      "epoch:14 step:13181 [D loss: 0.689437, acc.: 56.25%] [G loss: 0.921789]\n",
      "epoch:14 step:13182 [D loss: 0.641187, acc.: 59.38%] [G loss: 0.889590]\n",
      "epoch:14 step:13183 [D loss: 0.592301, acc.: 70.31%] [G loss: 0.905948]\n",
      "epoch:14 step:13184 [D loss: 0.581295, acc.: 73.44%] [G loss: 0.951569]\n",
      "epoch:14 step:13185 [D loss: 0.685624, acc.: 60.94%] [G loss: 0.913353]\n",
      "epoch:14 step:13186 [D loss: 0.595533, acc.: 70.31%] [G loss: 0.961243]\n",
      "epoch:14 step:13187 [D loss: 0.617760, acc.: 67.19%] [G loss: 1.015914]\n",
      "epoch:14 step:13188 [D loss: 0.590406, acc.: 69.53%] [G loss: 1.096383]\n",
      "epoch:14 step:13189 [D loss: 0.612041, acc.: 70.31%] [G loss: 1.074283]\n",
      "epoch:14 step:13190 [D loss: 0.634970, acc.: 59.38%] [G loss: 1.080474]\n",
      "epoch:14 step:13191 [D loss: 0.651643, acc.: 59.38%] [G loss: 0.976930]\n",
      "epoch:14 step:13192 [D loss: 0.561845, acc.: 75.00%] [G loss: 0.993501]\n",
      "epoch:14 step:13193 [D loss: 0.469570, acc.: 82.03%] [G loss: 1.091868]\n",
      "epoch:14 step:13194 [D loss: 0.581507, acc.: 73.44%] [G loss: 1.067759]\n",
      "epoch:14 step:13195 [D loss: 0.527519, acc.: 78.12%] [G loss: 1.312836]\n",
      "epoch:14 step:13196 [D loss: 0.758381, acc.: 54.69%] [G loss: 1.029928]\n",
      "epoch:14 step:13197 [D loss: 0.708915, acc.: 52.34%] [G loss: 1.070075]\n",
      "epoch:14 step:13198 [D loss: 0.671584, acc.: 59.38%] [G loss: 0.935826]\n",
      "epoch:14 step:13199 [D loss: 0.662268, acc.: 60.94%] [G loss: 0.870974]\n",
      "epoch:14 step:13200 [D loss: 0.584900, acc.: 70.31%] [G loss: 1.014785]\n",
      "##############\n",
      "[2.117303   1.40572009 5.44424245 4.26053121 2.8147293  5.27242377\n",
      " 4.09313728 4.52500582 3.88385174 3.59445383]\n",
      "##########\n",
      "epoch:14 step:13201 [D loss: 0.566490, acc.: 67.97%] [G loss: 0.936572]\n",
      "epoch:14 step:13202 [D loss: 0.665767, acc.: 59.38%] [G loss: 0.910253]\n",
      "epoch:14 step:13203 [D loss: 0.789328, acc.: 48.44%] [G loss: 0.878981]\n",
      "epoch:14 step:13204 [D loss: 0.721477, acc.: 53.91%] [G loss: 0.762233]\n",
      "epoch:14 step:13205 [D loss: 0.640329, acc.: 64.84%] [G loss: 1.004666]\n",
      "epoch:14 step:13206 [D loss: 0.675014, acc.: 60.94%] [G loss: 0.838626]\n",
      "epoch:14 step:13207 [D loss: 0.609218, acc.: 68.75%] [G loss: 1.044395]\n",
      "epoch:14 step:13208 [D loss: 0.719775, acc.: 53.12%] [G loss: 0.913237]\n",
      "epoch:14 step:13209 [D loss: 0.690780, acc.: 60.94%] [G loss: 0.971480]\n",
      "epoch:14 step:13210 [D loss: 0.593529, acc.: 69.53%] [G loss: 0.852590]\n",
      "epoch:14 step:13211 [D loss: 0.634179, acc.: 61.72%] [G loss: 0.875771]\n",
      "epoch:14 step:13212 [D loss: 0.719914, acc.: 50.78%] [G loss: 0.965514]\n",
      "epoch:14 step:13213 [D loss: 0.769491, acc.: 46.88%] [G loss: 0.958153]\n",
      "epoch:14 step:13214 [D loss: 0.701203, acc.: 59.38%] [G loss: 1.110666]\n",
      "epoch:14 step:13215 [D loss: 0.629107, acc.: 62.50%] [G loss: 1.072862]\n",
      "epoch:14 step:13216 [D loss: 0.616738, acc.: 63.28%] [G loss: 1.088823]\n",
      "epoch:14 step:13217 [D loss: 0.715105, acc.: 56.25%] [G loss: 0.796194]\n",
      "epoch:14 step:13218 [D loss: 0.729988, acc.: 50.00%] [G loss: 0.917446]\n",
      "epoch:14 step:13219 [D loss: 0.667188, acc.: 58.59%] [G loss: 0.901452]\n",
      "epoch:14 step:13220 [D loss: 0.753471, acc.: 47.66%] [G loss: 0.925982]\n",
      "epoch:14 step:13221 [D loss: 0.643678, acc.: 63.28%] [G loss: 0.876805]\n",
      "epoch:14 step:13222 [D loss: 0.650479, acc.: 63.28%] [G loss: 0.942882]\n",
      "epoch:14 step:13223 [D loss: 0.670108, acc.: 62.50%] [G loss: 1.117560]\n",
      "epoch:14 step:13224 [D loss: 0.607892, acc.: 68.75%] [G loss: 1.117503]\n",
      "epoch:14 step:13225 [D loss: 0.671037, acc.: 60.16%] [G loss: 1.079975]\n",
      "epoch:14 step:13226 [D loss: 0.740718, acc.: 46.88%] [G loss: 0.936038]\n",
      "epoch:14 step:13227 [D loss: 0.664818, acc.: 61.72%] [G loss: 0.976325]\n",
      "epoch:14 step:13228 [D loss: 0.671236, acc.: 57.81%] [G loss: 0.867438]\n",
      "epoch:14 step:13229 [D loss: 0.573852, acc.: 64.84%] [G loss: 1.066678]\n",
      "epoch:14 step:13230 [D loss: 0.631418, acc.: 64.84%] [G loss: 0.872389]\n",
      "epoch:14 step:13231 [D loss: 0.628805, acc.: 68.75%] [G loss: 0.889123]\n",
      "epoch:14 step:13232 [D loss: 0.657630, acc.: 60.16%] [G loss: 0.900073]\n",
      "epoch:14 step:13233 [D loss: 0.520375, acc.: 78.91%] [G loss: 1.017389]\n",
      "epoch:14 step:13234 [D loss: 0.725223, acc.: 57.81%] [G loss: 0.848658]\n",
      "epoch:14 step:13235 [D loss: 0.655406, acc.: 55.47%] [G loss: 0.974309]\n",
      "epoch:14 step:13236 [D loss: 0.705190, acc.: 57.81%] [G loss: 1.046669]\n",
      "epoch:14 step:13237 [D loss: 0.535477, acc.: 70.31%] [G loss: 1.065332]\n",
      "epoch:14 step:13238 [D loss: 0.672530, acc.: 61.72%] [G loss: 0.947443]\n",
      "epoch:14 step:13239 [D loss: 0.602292, acc.: 64.84%] [G loss: 0.947723]\n",
      "epoch:14 step:13240 [D loss: 0.598161, acc.: 67.97%] [G loss: 1.014906]\n",
      "epoch:14 step:13241 [D loss: 0.587850, acc.: 71.09%] [G loss: 1.105239]\n",
      "epoch:14 step:13242 [D loss: 0.633437, acc.: 60.94%] [G loss: 1.159670]\n",
      "epoch:14 step:13243 [D loss: 0.693403, acc.: 57.81%] [G loss: 1.114658]\n",
      "epoch:14 step:13244 [D loss: 0.575713, acc.: 70.31%] [G loss: 1.001953]\n",
      "epoch:14 step:13245 [D loss: 0.579617, acc.: 74.22%] [G loss: 0.907858]\n",
      "epoch:14 step:13246 [D loss: 0.588371, acc.: 68.75%] [G loss: 0.972876]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13247 [D loss: 0.770616, acc.: 47.66%] [G loss: 0.792235]\n",
      "epoch:14 step:13248 [D loss: 0.569877, acc.: 68.75%] [G loss: 0.897081]\n",
      "epoch:14 step:13249 [D loss: 0.537822, acc.: 76.56%] [G loss: 0.959687]\n",
      "epoch:14 step:13250 [D loss: 0.613664, acc.: 65.62%] [G loss: 0.941511]\n",
      "epoch:14 step:13251 [D loss: 0.682084, acc.: 60.16%] [G loss: 1.001035]\n",
      "epoch:14 step:13252 [D loss: 0.658665, acc.: 58.59%] [G loss: 0.908868]\n",
      "epoch:14 step:13253 [D loss: 0.629377, acc.: 63.28%] [G loss: 0.936463]\n",
      "epoch:14 step:13254 [D loss: 0.752182, acc.: 45.31%] [G loss: 1.060339]\n",
      "epoch:14 step:13255 [D loss: 0.740859, acc.: 51.56%] [G loss: 1.042624]\n",
      "epoch:14 step:13256 [D loss: 0.806539, acc.: 43.75%] [G loss: 0.857163]\n",
      "epoch:14 step:13257 [D loss: 0.632862, acc.: 64.06%] [G loss: 0.942464]\n",
      "epoch:14 step:13258 [D loss: 0.665256, acc.: 64.84%] [G loss: 0.955240]\n",
      "epoch:14 step:13259 [D loss: 0.572392, acc.: 69.53%] [G loss: 1.114228]\n",
      "epoch:14 step:13260 [D loss: 0.524480, acc.: 78.91%] [G loss: 0.896871]\n",
      "epoch:14 step:13261 [D loss: 0.584528, acc.: 69.53%] [G loss: 0.980188]\n",
      "epoch:14 step:13262 [D loss: 0.532755, acc.: 82.03%] [G loss: 1.173639]\n",
      "epoch:14 step:13263 [D loss: 0.568865, acc.: 75.78%] [G loss: 1.104603]\n",
      "epoch:14 step:13264 [D loss: 0.612780, acc.: 65.62%] [G loss: 0.920712]\n",
      "epoch:14 step:13265 [D loss: 0.733329, acc.: 53.12%] [G loss: 0.812073]\n",
      "epoch:14 step:13266 [D loss: 0.710607, acc.: 46.88%] [G loss: 0.911432]\n",
      "epoch:14 step:13267 [D loss: 0.495723, acc.: 82.81%] [G loss: 1.117620]\n",
      "epoch:14 step:13268 [D loss: 0.529256, acc.: 75.78%] [G loss: 0.998505]\n",
      "epoch:14 step:13269 [D loss: 0.509328, acc.: 80.47%] [G loss: 1.151484]\n",
      "epoch:14 step:13270 [D loss: 0.473882, acc.: 82.81%] [G loss: 1.177066]\n",
      "epoch:14 step:13271 [D loss: 0.769979, acc.: 46.88%] [G loss: 0.994682]\n",
      "epoch:14 step:13272 [D loss: 0.733129, acc.: 53.12%] [G loss: 0.969014]\n",
      "epoch:14 step:13273 [D loss: 0.635284, acc.: 62.50%] [G loss: 1.186785]\n",
      "epoch:14 step:13274 [D loss: 0.749948, acc.: 48.44%] [G loss: 1.033275]\n",
      "epoch:14 step:13275 [D loss: 0.675005, acc.: 54.69%] [G loss: 1.100502]\n",
      "epoch:14 step:13276 [D loss: 0.674045, acc.: 56.25%] [G loss: 1.011497]\n",
      "epoch:14 step:13277 [D loss: 0.711367, acc.: 53.12%] [G loss: 0.799177]\n",
      "epoch:14 step:13278 [D loss: 0.694437, acc.: 60.94%] [G loss: 0.882146]\n",
      "epoch:14 step:13279 [D loss: 0.714066, acc.: 53.12%] [G loss: 0.812966]\n",
      "epoch:14 step:13280 [D loss: 0.636226, acc.: 62.50%] [G loss: 0.874863]\n",
      "epoch:14 step:13281 [D loss: 0.640703, acc.: 61.72%] [G loss: 0.913619]\n",
      "epoch:14 step:13282 [D loss: 0.714915, acc.: 53.91%] [G loss: 0.824657]\n",
      "epoch:14 step:13283 [D loss: 0.643788, acc.: 57.81%] [G loss: 0.891675]\n",
      "epoch:14 step:13284 [D loss: 0.719754, acc.: 59.38%] [G loss: 0.920677]\n",
      "epoch:14 step:13285 [D loss: 0.567511, acc.: 70.31%] [G loss: 0.941621]\n",
      "epoch:14 step:13286 [D loss: 0.536171, acc.: 77.34%] [G loss: 0.878406]\n",
      "epoch:14 step:13287 [D loss: 0.597363, acc.: 67.19%] [G loss: 0.940869]\n",
      "epoch:14 step:13288 [D loss: 0.715472, acc.: 53.12%] [G loss: 0.949001]\n",
      "epoch:14 step:13289 [D loss: 0.592277, acc.: 70.31%] [G loss: 0.923018]\n",
      "epoch:14 step:13290 [D loss: 0.631855, acc.: 63.28%] [G loss: 0.906861]\n",
      "epoch:14 step:13291 [D loss: 0.649480, acc.: 65.62%] [G loss: 0.858752]\n",
      "epoch:14 step:13292 [D loss: 0.688095, acc.: 57.03%] [G loss: 0.992661]\n",
      "epoch:14 step:13293 [D loss: 0.768112, acc.: 48.44%] [G loss: 0.773818]\n",
      "epoch:14 step:13294 [D loss: 0.685809, acc.: 55.47%] [G loss: 0.908342]\n",
      "epoch:14 step:13295 [D loss: 0.678810, acc.: 55.47%] [G loss: 0.998436]\n",
      "epoch:14 step:13296 [D loss: 0.676790, acc.: 55.47%] [G loss: 0.925329]\n",
      "epoch:14 step:13297 [D loss: 0.699616, acc.: 53.91%] [G loss: 0.943628]\n",
      "epoch:14 step:13298 [D loss: 0.608049, acc.: 64.84%] [G loss: 1.087330]\n",
      "epoch:14 step:13299 [D loss: 0.578066, acc.: 72.66%] [G loss: 0.940415]\n",
      "epoch:14 step:13300 [D loss: 0.527586, acc.: 78.91%] [G loss: 0.987952]\n",
      "epoch:14 step:13301 [D loss: 0.787031, acc.: 45.31%] [G loss: 0.974576]\n",
      "epoch:14 step:13302 [D loss: 0.671764, acc.: 60.94%] [G loss: 1.031791]\n",
      "epoch:14 step:13303 [D loss: 0.786343, acc.: 47.66%] [G loss: 0.922667]\n",
      "epoch:14 step:13304 [D loss: 0.728425, acc.: 54.69%] [G loss: 0.927316]\n",
      "epoch:14 step:13305 [D loss: 0.618649, acc.: 66.41%] [G loss: 1.032324]\n",
      "epoch:14 step:13306 [D loss: 0.642048, acc.: 62.50%] [G loss: 1.028094]\n",
      "epoch:14 step:13307 [D loss: 0.826127, acc.: 35.16%] [G loss: 0.867463]\n",
      "epoch:14 step:13308 [D loss: 0.666841, acc.: 57.81%] [G loss: 0.883436]\n",
      "epoch:14 step:13309 [D loss: 0.638568, acc.: 64.06%] [G loss: 1.016018]\n",
      "epoch:14 step:13310 [D loss: 0.610508, acc.: 62.50%] [G loss: 0.919310]\n",
      "epoch:14 step:13311 [D loss: 0.645514, acc.: 67.19%] [G loss: 0.913381]\n",
      "epoch:14 step:13312 [D loss: 0.575812, acc.: 71.88%] [G loss: 1.195381]\n",
      "epoch:14 step:13313 [D loss: 0.708309, acc.: 57.03%] [G loss: 0.971568]\n",
      "epoch:14 step:13314 [D loss: 0.652711, acc.: 57.81%] [G loss: 0.980905]\n",
      "epoch:14 step:13315 [D loss: 0.723956, acc.: 47.66%] [G loss: 0.854384]\n",
      "epoch:14 step:13316 [D loss: 0.718938, acc.: 60.16%] [G loss: 0.966943]\n",
      "epoch:14 step:13317 [D loss: 0.604137, acc.: 67.97%] [G loss: 1.179312]\n",
      "epoch:14 step:13318 [D loss: 0.654714, acc.: 60.16%] [G loss: 1.030728]\n",
      "epoch:14 step:13319 [D loss: 0.734095, acc.: 46.09%] [G loss: 1.145714]\n",
      "epoch:14 step:13320 [D loss: 0.752018, acc.: 53.91%] [G loss: 0.934214]\n",
      "epoch:14 step:13321 [D loss: 0.730765, acc.: 48.44%] [G loss: 0.960346]\n",
      "epoch:14 step:13322 [D loss: 0.579854, acc.: 75.00%] [G loss: 1.040925]\n",
      "epoch:14 step:13323 [D loss: 0.701878, acc.: 56.25%] [G loss: 0.960861]\n",
      "epoch:14 step:13324 [D loss: 0.635521, acc.: 60.94%] [G loss: 0.897538]\n",
      "epoch:14 step:13325 [D loss: 0.587763, acc.: 70.31%] [G loss: 0.933152]\n",
      "epoch:14 step:13326 [D loss: 0.595940, acc.: 71.88%] [G loss: 0.977433]\n",
      "epoch:14 step:13327 [D loss: 0.584911, acc.: 67.97%] [G loss: 0.979424]\n",
      "epoch:14 step:13328 [D loss: 0.661411, acc.: 64.84%] [G loss: 0.909699]\n",
      "epoch:14 step:13329 [D loss: 0.650721, acc.: 61.72%] [G loss: 1.017427]\n",
      "epoch:14 step:13330 [D loss: 0.621339, acc.: 63.28%] [G loss: 1.082306]\n",
      "epoch:14 step:13331 [D loss: 0.554291, acc.: 76.56%] [G loss: 1.041266]\n",
      "epoch:14 step:13332 [D loss: 0.648621, acc.: 63.28%] [G loss: 0.934372]\n",
      "epoch:14 step:13333 [D loss: 0.602702, acc.: 67.97%] [G loss: 0.932476]\n",
      "epoch:14 step:13334 [D loss: 0.720635, acc.: 50.00%] [G loss: 0.915659]\n",
      "epoch:14 step:13335 [D loss: 0.631169, acc.: 65.62%] [G loss: 1.075253]\n",
      "epoch:14 step:13336 [D loss: 0.686166, acc.: 60.16%] [G loss: 0.961066]\n",
      "epoch:14 step:13337 [D loss: 0.659477, acc.: 62.50%] [G loss: 0.949571]\n",
      "epoch:14 step:13338 [D loss: 0.445842, acc.: 84.38%] [G loss: 0.940637]\n",
      "epoch:14 step:13339 [D loss: 0.398451, acc.: 90.62%] [G loss: 1.252849]\n",
      "epoch:14 step:13340 [D loss: 0.468481, acc.: 87.50%] [G loss: 1.142037]\n",
      "epoch:14 step:13341 [D loss: 0.395006, acc.: 90.62%] [G loss: 1.163303]\n",
      "epoch:14 step:13342 [D loss: 0.720752, acc.: 55.47%] [G loss: 1.107873]\n",
      "epoch:14 step:13343 [D loss: 0.738843, acc.: 51.56%] [G loss: 0.847704]\n",
      "epoch:14 step:13344 [D loss: 0.567454, acc.: 72.66%] [G loss: 1.093495]\n",
      "epoch:14 step:13345 [D loss: 0.740509, acc.: 50.78%] [G loss: 0.910748]\n",
      "epoch:14 step:13346 [D loss: 0.800746, acc.: 45.31%] [G loss: 0.954057]\n",
      "epoch:14 step:13347 [D loss: 0.636104, acc.: 63.28%] [G loss: 0.934643]\n",
      "epoch:14 step:13348 [D loss: 0.325382, acc.: 89.84%] [G loss: 1.318624]\n",
      "epoch:14 step:13349 [D loss: 0.448955, acc.: 82.81%] [G loss: 1.119677]\n",
      "epoch:14 step:13350 [D loss: 0.339385, acc.: 94.53%] [G loss: 1.490669]\n",
      "epoch:14 step:13351 [D loss: 0.846983, acc.: 51.56%] [G loss: 1.044481]\n",
      "epoch:14 step:13352 [D loss: 0.819034, acc.: 42.19%] [G loss: 1.036115]\n",
      "epoch:14 step:13353 [D loss: 0.699181, acc.: 53.91%] [G loss: 0.846535]\n",
      "epoch:14 step:13354 [D loss: 0.712823, acc.: 53.91%] [G loss: 1.008097]\n",
      "epoch:14 step:13355 [D loss: 0.773321, acc.: 50.78%] [G loss: 0.937731]\n",
      "epoch:14 step:13356 [D loss: 0.671540, acc.: 57.03%] [G loss: 0.970670]\n",
      "epoch:14 step:13357 [D loss: 0.684872, acc.: 54.69%] [G loss: 0.957241]\n",
      "epoch:14 step:13358 [D loss: 0.791308, acc.: 46.09%] [G loss: 0.912777]\n",
      "epoch:14 step:13359 [D loss: 0.627917, acc.: 60.94%] [G loss: 0.904247]\n",
      "epoch:14 step:13360 [D loss: 0.629012, acc.: 67.19%] [G loss: 1.040647]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13361 [D loss: 0.658995, acc.: 64.06%] [G loss: 1.020921]\n",
      "epoch:14 step:13362 [D loss: 0.600687, acc.: 67.97%] [G loss: 0.958540]\n",
      "epoch:14 step:13363 [D loss: 0.717180, acc.: 55.47%] [G loss: 0.810341]\n",
      "epoch:14 step:13364 [D loss: 0.651808, acc.: 64.84%] [G loss: 0.967525]\n",
      "epoch:14 step:13365 [D loss: 0.701044, acc.: 59.38%] [G loss: 1.032086]\n",
      "epoch:14 step:13366 [D loss: 0.578908, acc.: 68.75%] [G loss: 0.957123]\n",
      "epoch:14 step:13367 [D loss: 0.669483, acc.: 58.59%] [G loss: 1.019662]\n",
      "epoch:14 step:13368 [D loss: 0.716858, acc.: 50.78%] [G loss: 0.985056]\n",
      "epoch:14 step:13369 [D loss: 0.627727, acc.: 62.50%] [G loss: 0.784859]\n",
      "epoch:14 step:13370 [D loss: 0.660133, acc.: 57.03%] [G loss: 1.051898]\n",
      "epoch:14 step:13371 [D loss: 0.690823, acc.: 52.34%] [G loss: 0.909300]\n",
      "epoch:14 step:13372 [D loss: 0.647559, acc.: 65.62%] [G loss: 0.976057]\n",
      "epoch:14 step:13373 [D loss: 0.688409, acc.: 59.38%] [G loss: 0.897639]\n",
      "epoch:14 step:13374 [D loss: 0.623476, acc.: 66.41%] [G loss: 1.094072]\n",
      "epoch:14 step:13375 [D loss: 0.598718, acc.: 64.84%] [G loss: 0.907731]\n",
      "epoch:14 step:13376 [D loss: 0.682434, acc.: 52.34%] [G loss: 0.975748]\n",
      "epoch:14 step:13377 [D loss: 0.632069, acc.: 65.62%] [G loss: 0.801073]\n",
      "epoch:14 step:13378 [D loss: 0.668879, acc.: 57.03%] [G loss: 1.032738]\n",
      "epoch:14 step:13379 [D loss: 0.622271, acc.: 69.53%] [G loss: 0.983392]\n",
      "epoch:14 step:13380 [D loss: 0.714291, acc.: 53.91%] [G loss: 0.771217]\n",
      "epoch:14 step:13381 [D loss: 0.721944, acc.: 58.59%] [G loss: 0.916859]\n",
      "epoch:14 step:13382 [D loss: 0.619785, acc.: 69.53%] [G loss: 1.066937]\n",
      "epoch:14 step:13383 [D loss: 0.722175, acc.: 58.59%] [G loss: 0.930809]\n",
      "epoch:14 step:13384 [D loss: 0.659486, acc.: 60.94%] [G loss: 0.967305]\n",
      "epoch:14 step:13385 [D loss: 0.616704, acc.: 65.62%] [G loss: 1.011100]\n",
      "epoch:14 step:13386 [D loss: 0.646312, acc.: 60.94%] [G loss: 0.946991]\n",
      "epoch:14 step:13387 [D loss: 0.558112, acc.: 72.66%] [G loss: 0.887994]\n",
      "epoch:14 step:13388 [D loss: 0.637319, acc.: 59.38%] [G loss: 0.990448]\n",
      "epoch:14 step:13389 [D loss: 0.673854, acc.: 58.59%] [G loss: 1.073778]\n",
      "epoch:14 step:13390 [D loss: 0.511461, acc.: 78.12%] [G loss: 1.047453]\n",
      "epoch:14 step:13391 [D loss: 0.550173, acc.: 75.00%] [G loss: 0.993417]\n",
      "epoch:14 step:13392 [D loss: 0.645674, acc.: 61.72%] [G loss: 0.882834]\n",
      "epoch:14 step:13393 [D loss: 0.693704, acc.: 57.81%] [G loss: 0.880981]\n",
      "epoch:14 step:13394 [D loss: 0.692752, acc.: 55.47%] [G loss: 1.023250]\n",
      "epoch:14 step:13395 [D loss: 0.753366, acc.: 51.56%] [G loss: 1.072994]\n",
      "epoch:14 step:13396 [D loss: 0.719314, acc.: 55.47%] [G loss: 1.009110]\n",
      "epoch:14 step:13397 [D loss: 0.617753, acc.: 60.94%] [G loss: 1.052021]\n",
      "epoch:14 step:13398 [D loss: 0.620485, acc.: 67.19%] [G loss: 0.983687]\n",
      "epoch:14 step:13399 [D loss: 0.686918, acc.: 54.69%] [G loss: 0.990657]\n",
      "epoch:14 step:13400 [D loss: 0.647235, acc.: 62.50%] [G loss: 1.227581]\n",
      "##############\n",
      "[1.91623573 1.543364   5.3232679  4.11879472 3.13346076 5.3151212\n",
      " 4.08328057 4.6335195  3.86416086 3.36119948]\n",
      "##########\n",
      "epoch:14 step:13401 [D loss: 0.665577, acc.: 62.50%] [G loss: 1.093755]\n",
      "epoch:14 step:13402 [D loss: 0.575846, acc.: 77.34%] [G loss: 1.090343]\n",
      "epoch:14 step:13403 [D loss: 0.544250, acc.: 74.22%] [G loss: 1.051630]\n",
      "epoch:14 step:13404 [D loss: 0.602988, acc.: 67.97%] [G loss: 1.092435]\n",
      "epoch:14 step:13405 [D loss: 0.713379, acc.: 51.56%] [G loss: 0.977468]\n",
      "epoch:14 step:13406 [D loss: 0.633423, acc.: 66.41%] [G loss: 0.934382]\n",
      "epoch:14 step:13407 [D loss: 0.564299, acc.: 73.44%] [G loss: 0.914495]\n",
      "epoch:14 step:13408 [D loss: 0.672716, acc.: 59.38%] [G loss: 1.012158]\n",
      "epoch:14 step:13409 [D loss: 0.668576, acc.: 57.03%] [G loss: 1.071519]\n",
      "epoch:14 step:13410 [D loss: 0.577300, acc.: 67.97%] [G loss: 0.959569]\n",
      "epoch:14 step:13411 [D loss: 0.683297, acc.: 53.91%] [G loss: 0.899646]\n",
      "epoch:14 step:13412 [D loss: 0.629449, acc.: 67.19%] [G loss: 1.095506]\n",
      "epoch:14 step:13413 [D loss: 0.776684, acc.: 45.31%] [G loss: 0.848530]\n",
      "epoch:14 step:13414 [D loss: 0.590289, acc.: 67.19%] [G loss: 0.951761]\n",
      "epoch:14 step:13415 [D loss: 0.704035, acc.: 57.81%] [G loss: 1.013896]\n",
      "epoch:14 step:13416 [D loss: 0.631061, acc.: 66.41%] [G loss: 1.129429]\n",
      "epoch:14 step:13417 [D loss: 0.623519, acc.: 64.84%] [G loss: 1.042414]\n",
      "epoch:14 step:13418 [D loss: 0.553342, acc.: 75.78%] [G loss: 1.117266]\n",
      "epoch:14 step:13419 [D loss: 0.662616, acc.: 57.03%] [G loss: 0.967377]\n",
      "epoch:14 step:13420 [D loss: 0.674306, acc.: 61.72%] [G loss: 0.901776]\n",
      "epoch:14 step:13421 [D loss: 0.624858, acc.: 65.62%] [G loss: 0.887360]\n",
      "epoch:14 step:13422 [D loss: 0.689962, acc.: 56.25%] [G loss: 0.806267]\n",
      "epoch:14 step:13423 [D loss: 0.714826, acc.: 51.56%] [G loss: 1.003897]\n",
      "epoch:14 step:13424 [D loss: 0.691574, acc.: 57.03%] [G loss: 0.803079]\n",
      "epoch:14 step:13425 [D loss: 0.584703, acc.: 73.44%] [G loss: 0.947869]\n",
      "epoch:14 step:13426 [D loss: 0.594364, acc.: 65.62%] [G loss: 1.051695]\n",
      "epoch:14 step:13427 [D loss: 0.583411, acc.: 68.75%] [G loss: 0.955340]\n",
      "epoch:14 step:13428 [D loss: 0.591937, acc.: 71.88%] [G loss: 1.115438]\n",
      "epoch:14 step:13429 [D loss: 0.578439, acc.: 70.31%] [G loss: 1.015149]\n",
      "epoch:14 step:13430 [D loss: 0.548879, acc.: 75.78%] [G loss: 1.014727]\n",
      "epoch:14 step:13431 [D loss: 0.517976, acc.: 80.47%] [G loss: 1.192190]\n",
      "epoch:14 step:13432 [D loss: 0.592918, acc.: 69.53%] [G loss: 1.080276]\n",
      "epoch:14 step:13433 [D loss: 0.608124, acc.: 67.19%] [G loss: 1.125991]\n",
      "epoch:14 step:13434 [D loss: 0.715083, acc.: 58.59%] [G loss: 0.901164]\n",
      "epoch:14 step:13435 [D loss: 0.794718, acc.: 44.53%] [G loss: 0.971322]\n",
      "epoch:14 step:13436 [D loss: 0.661790, acc.: 64.84%] [G loss: 0.935580]\n",
      "epoch:14 step:13437 [D loss: 0.629420, acc.: 66.41%] [G loss: 0.963340]\n",
      "epoch:14 step:13438 [D loss: 0.680691, acc.: 58.59%] [G loss: 1.004690]\n",
      "epoch:14 step:13439 [D loss: 0.642235, acc.: 63.28%] [G loss: 0.857622]\n",
      "epoch:14 step:13440 [D loss: 0.619197, acc.: 62.50%] [G loss: 0.897295]\n",
      "epoch:14 step:13441 [D loss: 0.709804, acc.: 53.91%] [G loss: 0.923182]\n",
      "epoch:14 step:13442 [D loss: 0.681488, acc.: 53.91%] [G loss: 0.932291]\n",
      "epoch:14 step:13443 [D loss: 0.618039, acc.: 68.75%] [G loss: 1.036209]\n",
      "epoch:14 step:13444 [D loss: 0.676734, acc.: 58.59%] [G loss: 0.867232]\n",
      "epoch:14 step:13445 [D loss: 0.542270, acc.: 73.44%] [G loss: 0.975502]\n",
      "epoch:14 step:13446 [D loss: 0.472433, acc.: 82.81%] [G loss: 1.072160]\n",
      "epoch:14 step:13447 [D loss: 0.745752, acc.: 47.66%] [G loss: 1.054130]\n",
      "epoch:14 step:13448 [D loss: 0.690704, acc.: 52.34%] [G loss: 1.006606]\n",
      "epoch:14 step:13449 [D loss: 0.671091, acc.: 57.81%] [G loss: 0.899855]\n",
      "epoch:14 step:13450 [D loss: 0.646532, acc.: 60.16%] [G loss: 1.074587]\n",
      "epoch:14 step:13451 [D loss: 0.696108, acc.: 60.16%] [G loss: 0.991954]\n",
      "epoch:14 step:13452 [D loss: 0.786177, acc.: 45.31%] [G loss: 0.863480]\n",
      "epoch:14 step:13453 [D loss: 0.602134, acc.: 64.84%] [G loss: 0.932898]\n",
      "epoch:14 step:13454 [D loss: 0.542184, acc.: 78.12%] [G loss: 0.865712]\n",
      "epoch:14 step:13455 [D loss: 0.700652, acc.: 53.91%] [G loss: 1.044170]\n",
      "epoch:14 step:13456 [D loss: 0.689819, acc.: 60.94%] [G loss: 1.024526]\n",
      "epoch:14 step:13457 [D loss: 0.587765, acc.: 67.97%] [G loss: 0.898129]\n",
      "epoch:14 step:13458 [D loss: 0.657453, acc.: 59.38%] [G loss: 0.957212]\n",
      "epoch:14 step:13459 [D loss: 0.665634, acc.: 61.72%] [G loss: 1.006982]\n",
      "epoch:14 step:13460 [D loss: 0.753988, acc.: 45.31%] [G loss: 1.026499]\n",
      "epoch:14 step:13461 [D loss: 0.674454, acc.: 53.91%] [G loss: 0.914911]\n",
      "epoch:14 step:13462 [D loss: 0.591436, acc.: 69.53%] [G loss: 1.038755]\n",
      "epoch:14 step:13463 [D loss: 0.530484, acc.: 76.56%] [G loss: 1.265662]\n",
      "epoch:14 step:13464 [D loss: 0.521583, acc.: 76.56%] [G loss: 1.126804]\n",
      "epoch:14 step:13465 [D loss: 0.453404, acc.: 80.47%] [G loss: 1.469671]\n",
      "epoch:14 step:13466 [D loss: 0.670329, acc.: 58.59%] [G loss: 1.101357]\n",
      "epoch:14 step:13467 [D loss: 0.846380, acc.: 41.41%] [G loss: 0.857889]\n",
      "epoch:14 step:13468 [D loss: 0.658529, acc.: 62.50%] [G loss: 0.834264]\n",
      "epoch:14 step:13469 [D loss: 0.679798, acc.: 60.94%] [G loss: 0.925153]\n",
      "epoch:14 step:13470 [D loss: 0.594956, acc.: 64.06%] [G loss: 1.075577]\n",
      "epoch:14 step:13471 [D loss: 0.662547, acc.: 60.16%] [G loss: 0.841334]\n",
      "epoch:14 step:13472 [D loss: 0.581760, acc.: 72.66%] [G loss: 1.010473]\n",
      "epoch:14 step:13473 [D loss: 0.658517, acc.: 64.06%] [G loss: 1.060744]\n",
      "epoch:14 step:13474 [D loss: 0.776067, acc.: 42.97%] [G loss: 0.782376]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13475 [D loss: 0.631233, acc.: 63.28%] [G loss: 0.978444]\n",
      "epoch:14 step:13476 [D loss: 0.636629, acc.: 65.62%] [G loss: 0.860414]\n",
      "epoch:14 step:13477 [D loss: 0.597767, acc.: 64.06%] [G loss: 1.079710]\n",
      "epoch:14 step:13478 [D loss: 0.627551, acc.: 64.84%] [G loss: 1.100267]\n",
      "epoch:14 step:13479 [D loss: 0.645667, acc.: 63.28%] [G loss: 0.994198]\n",
      "epoch:14 step:13480 [D loss: 0.695916, acc.: 53.91%] [G loss: 0.859156]\n",
      "epoch:14 step:13481 [D loss: 0.646154, acc.: 60.16%] [G loss: 1.008599]\n",
      "epoch:14 step:13482 [D loss: 0.695155, acc.: 62.50%] [G loss: 0.893862]\n",
      "epoch:14 step:13483 [D loss: 0.751158, acc.: 46.09%] [G loss: 1.079371]\n",
      "epoch:14 step:13484 [D loss: 0.598552, acc.: 64.84%] [G loss: 1.060874]\n",
      "epoch:14 step:13485 [D loss: 0.605497, acc.: 67.19%] [G loss: 1.147653]\n",
      "epoch:14 step:13486 [D loss: 0.639281, acc.: 64.06%] [G loss: 1.095870]\n",
      "epoch:14 step:13487 [D loss: 0.667111, acc.: 60.94%] [G loss: 0.928251]\n",
      "epoch:14 step:13488 [D loss: 0.591061, acc.: 69.53%] [G loss: 0.992903]\n",
      "epoch:14 step:13489 [D loss: 0.659095, acc.: 63.28%] [G loss: 0.918806]\n",
      "epoch:14 step:13490 [D loss: 0.701941, acc.: 60.16%] [G loss: 0.933957]\n",
      "epoch:14 step:13491 [D loss: 0.695999, acc.: 58.59%] [G loss: 0.911274]\n",
      "epoch:14 step:13492 [D loss: 0.672882, acc.: 60.16%] [G loss: 0.969467]\n",
      "epoch:14 step:13493 [D loss: 0.728185, acc.: 53.91%] [G loss: 0.850586]\n",
      "epoch:14 step:13494 [D loss: 0.787024, acc.: 39.84%] [G loss: 0.813367]\n",
      "epoch:14 step:13495 [D loss: 0.628579, acc.: 67.97%] [G loss: 0.930296]\n",
      "epoch:14 step:13496 [D loss: 0.675950, acc.: 57.03%] [G loss: 0.824404]\n",
      "epoch:14 step:13497 [D loss: 0.719151, acc.: 48.44%] [G loss: 1.013964]\n",
      "epoch:14 step:13498 [D loss: 0.563630, acc.: 67.97%] [G loss: 0.962545]\n",
      "epoch:14 step:13499 [D loss: 0.494138, acc.: 78.12%] [G loss: 1.054110]\n",
      "epoch:14 step:13500 [D loss: 0.670607, acc.: 50.00%] [G loss: 0.983187]\n",
      "epoch:14 step:13501 [D loss: 0.615728, acc.: 71.88%] [G loss: 0.833702]\n",
      "epoch:14 step:13502 [D loss: 0.601756, acc.: 67.19%] [G loss: 0.887601]\n",
      "epoch:14 step:13503 [D loss: 0.637663, acc.: 64.84%] [G loss: 0.930811]\n",
      "epoch:14 step:13504 [D loss: 0.615211, acc.: 65.62%] [G loss: 1.126961]\n",
      "epoch:14 step:13505 [D loss: 0.600211, acc.: 73.44%] [G loss: 0.949350]\n",
      "epoch:14 step:13506 [D loss: 0.623263, acc.: 64.06%] [G loss: 0.804033]\n",
      "epoch:14 step:13507 [D loss: 0.669132, acc.: 57.03%] [G loss: 1.008890]\n",
      "epoch:14 step:13508 [D loss: 0.692558, acc.: 60.94%] [G loss: 0.847522]\n",
      "epoch:14 step:13509 [D loss: 0.597172, acc.: 70.31%] [G loss: 1.014121]\n",
      "epoch:14 step:13510 [D loss: 0.639645, acc.: 65.62%] [G loss: 0.920815]\n",
      "epoch:14 step:13511 [D loss: 0.716117, acc.: 51.56%] [G loss: 0.942282]\n",
      "epoch:14 step:13512 [D loss: 0.558496, acc.: 75.00%] [G loss: 1.072290]\n",
      "epoch:14 step:13513 [D loss: 0.710130, acc.: 52.34%] [G loss: 0.862441]\n",
      "epoch:14 step:13514 [D loss: 0.586497, acc.: 67.19%] [G loss: 1.025674]\n",
      "epoch:14 step:13515 [D loss: 0.465226, acc.: 82.03%] [G loss: 1.030714]\n",
      "epoch:14 step:13516 [D loss: 0.504620, acc.: 80.47%] [G loss: 0.966470]\n",
      "epoch:14 step:13517 [D loss: 0.522197, acc.: 75.00%] [G loss: 1.206275]\n",
      "epoch:14 step:13518 [D loss: 0.482723, acc.: 81.25%] [G loss: 1.389089]\n",
      "epoch:14 step:13519 [D loss: 0.637446, acc.: 63.28%] [G loss: 1.075232]\n",
      "epoch:14 step:13520 [D loss: 0.552716, acc.: 72.66%] [G loss: 0.988078]\n",
      "epoch:14 step:13521 [D loss: 0.629572, acc.: 68.75%] [G loss: 0.786815]\n",
      "epoch:14 step:13522 [D loss: 0.551564, acc.: 71.88%] [G loss: 1.127986]\n",
      "epoch:14 step:13523 [D loss: 0.478747, acc.: 85.94%] [G loss: 1.187736]\n",
      "epoch:14 step:13524 [D loss: 0.499955, acc.: 78.91%] [G loss: 1.358574]\n",
      "epoch:14 step:13525 [D loss: 0.729810, acc.: 53.12%] [G loss: 0.909056]\n",
      "epoch:14 step:13526 [D loss: 0.724937, acc.: 49.22%] [G loss: 1.166075]\n",
      "epoch:14 step:13527 [D loss: 0.622425, acc.: 66.41%] [G loss: 0.992185]\n",
      "epoch:14 step:13528 [D loss: 0.650881, acc.: 65.62%] [G loss: 1.056804]\n",
      "epoch:14 step:13529 [D loss: 0.743800, acc.: 55.47%] [G loss: 1.134254]\n",
      "epoch:14 step:13530 [D loss: 0.659399, acc.: 59.38%] [G loss: 0.923651]\n",
      "epoch:14 step:13531 [D loss: 0.884615, acc.: 35.94%] [G loss: 0.745047]\n",
      "epoch:14 step:13532 [D loss: 0.702746, acc.: 54.69%] [G loss: 0.942011]\n",
      "epoch:14 step:13533 [D loss: 0.749383, acc.: 45.31%] [G loss: 1.067980]\n",
      "epoch:14 step:13534 [D loss: 0.756324, acc.: 45.31%] [G loss: 0.788405]\n",
      "epoch:14 step:13535 [D loss: 0.663216, acc.: 62.50%] [G loss: 1.019974]\n",
      "epoch:14 step:13536 [D loss: 0.655804, acc.: 63.28%] [G loss: 0.927773]\n",
      "epoch:14 step:13537 [D loss: 0.572044, acc.: 74.22%] [G loss: 1.056171]\n",
      "epoch:14 step:13538 [D loss: 0.753409, acc.: 48.44%] [G loss: 0.861705]\n",
      "epoch:14 step:13539 [D loss: 0.770698, acc.: 50.00%] [G loss: 0.948746]\n",
      "epoch:14 step:13540 [D loss: 0.831154, acc.: 35.94%] [G loss: 1.010920]\n",
      "epoch:14 step:13541 [D loss: 0.651562, acc.: 56.25%] [G loss: 1.150795]\n",
      "epoch:14 step:13542 [D loss: 0.737303, acc.: 50.00%] [G loss: 0.936032]\n",
      "epoch:14 step:13543 [D loss: 0.692083, acc.: 56.25%] [G loss: 1.140531]\n",
      "epoch:14 step:13544 [D loss: 0.713722, acc.: 52.34%] [G loss: 1.017853]\n",
      "epoch:14 step:13545 [D loss: 0.669956, acc.: 58.59%] [G loss: 1.006202]\n",
      "epoch:14 step:13546 [D loss: 0.590699, acc.: 67.19%] [G loss: 0.905452]\n",
      "epoch:14 step:13547 [D loss: 0.610745, acc.: 67.97%] [G loss: 1.062473]\n",
      "epoch:14 step:13548 [D loss: 0.497513, acc.: 83.59%] [G loss: 1.157247]\n",
      "epoch:14 step:13549 [D loss: 0.611704, acc.: 68.75%] [G loss: 0.937403]\n",
      "epoch:14 step:13550 [D loss: 0.650944, acc.: 60.16%] [G loss: 1.088186]\n",
      "epoch:14 step:13551 [D loss: 0.565215, acc.: 72.66%] [G loss: 1.089379]\n",
      "epoch:14 step:13552 [D loss: 0.489986, acc.: 76.56%] [G loss: 1.116855]\n",
      "epoch:14 step:13553 [D loss: 0.571009, acc.: 75.00%] [G loss: 1.145772]\n",
      "epoch:14 step:13554 [D loss: 0.422134, acc.: 90.62%] [G loss: 1.307940]\n",
      "epoch:14 step:13555 [D loss: 0.843010, acc.: 39.84%] [G loss: 1.104832]\n",
      "epoch:14 step:13556 [D loss: 0.614852, acc.: 65.62%] [G loss: 1.094095]\n",
      "epoch:14 step:13557 [D loss: 0.683455, acc.: 64.06%] [G loss: 1.070312]\n",
      "epoch:14 step:13558 [D loss: 0.596671, acc.: 71.09%] [G loss: 1.143524]\n",
      "epoch:14 step:13559 [D loss: 0.667020, acc.: 60.16%] [G loss: 1.174160]\n",
      "epoch:14 step:13560 [D loss: 0.579648, acc.: 66.41%] [G loss: 1.144418]\n",
      "epoch:14 step:13561 [D loss: 0.558254, acc.: 75.00%] [G loss: 0.998784]\n",
      "epoch:14 step:13562 [D loss: 0.576766, acc.: 73.44%] [G loss: 1.080274]\n",
      "epoch:14 step:13563 [D loss: 0.617264, acc.: 64.84%] [G loss: 0.852004]\n",
      "epoch:14 step:13564 [D loss: 0.746542, acc.: 49.22%] [G loss: 0.907940]\n",
      "epoch:14 step:13565 [D loss: 0.673471, acc.: 58.59%] [G loss: 0.885705]\n",
      "epoch:14 step:13566 [D loss: 0.565583, acc.: 68.75%] [G loss: 1.121327]\n",
      "epoch:14 step:13567 [D loss: 0.529532, acc.: 78.91%] [G loss: 1.240836]\n",
      "epoch:14 step:13568 [D loss: 0.550394, acc.: 76.56%] [G loss: 1.148965]\n",
      "epoch:14 step:13569 [D loss: 0.435266, acc.: 85.16%] [G loss: 1.368344]\n",
      "epoch:14 step:13570 [D loss: 0.673344, acc.: 60.94%] [G loss: 1.039821]\n",
      "epoch:14 step:13571 [D loss: 0.530656, acc.: 75.78%] [G loss: 1.253479]\n",
      "epoch:14 step:13572 [D loss: 0.527904, acc.: 76.56%] [G loss: 0.997534]\n",
      "epoch:14 step:13573 [D loss: 0.596562, acc.: 71.09%] [G loss: 1.035855]\n",
      "epoch:14 step:13574 [D loss: 0.567511, acc.: 71.88%] [G loss: 1.033323]\n",
      "epoch:14 step:13575 [D loss: 0.435232, acc.: 85.16%] [G loss: 1.206205]\n",
      "epoch:14 step:13576 [D loss: 0.814255, acc.: 44.53%] [G loss: 0.947658]\n",
      "epoch:14 step:13577 [D loss: 0.782769, acc.: 43.75%] [G loss: 0.748002]\n",
      "epoch:14 step:13578 [D loss: 0.820065, acc.: 41.41%] [G loss: 0.949180]\n",
      "epoch:14 step:13579 [D loss: 0.788801, acc.: 43.75%] [G loss: 0.962435]\n",
      "epoch:14 step:13580 [D loss: 0.958269, acc.: 27.34%] [G loss: 1.096761]\n",
      "epoch:14 step:13581 [D loss: 0.795373, acc.: 50.00%] [G loss: 1.038445]\n",
      "epoch:14 step:13582 [D loss: 0.675971, acc.: 54.69%] [G loss: 0.923540]\n",
      "epoch:14 step:13583 [D loss: 0.610486, acc.: 67.19%] [G loss: 1.156115]\n",
      "epoch:14 step:13584 [D loss: 0.636086, acc.: 60.16%] [G loss: 1.132451]\n",
      "epoch:14 step:13585 [D loss: 0.742463, acc.: 45.31%] [G loss: 0.920758]\n",
      "epoch:14 step:13586 [D loss: 0.599288, acc.: 73.44%] [G loss: 1.049171]\n",
      "epoch:14 step:13587 [D loss: 0.601598, acc.: 72.66%] [G loss: 1.157034]\n",
      "epoch:14 step:13588 [D loss: 0.615095, acc.: 65.62%] [G loss: 1.041973]\n",
      "epoch:14 step:13589 [D loss: 0.454301, acc.: 79.69%] [G loss: 1.218357]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13590 [D loss: 0.621909, acc.: 67.97%] [G loss: 1.149859]\n",
      "epoch:14 step:13591 [D loss: 0.816683, acc.: 39.06%] [G loss: 0.968687]\n",
      "epoch:14 step:13592 [D loss: 0.655733, acc.: 54.69%] [G loss: 1.286451]\n",
      "epoch:14 step:13593 [D loss: 0.584364, acc.: 71.88%] [G loss: 1.280553]\n",
      "epoch:14 step:13594 [D loss: 0.678877, acc.: 60.16%] [G loss: 1.059571]\n",
      "epoch:14 step:13595 [D loss: 0.778723, acc.: 51.56%] [G loss: 1.103606]\n",
      "epoch:14 step:13596 [D loss: 0.727652, acc.: 53.91%] [G loss: 0.955129]\n",
      "epoch:14 step:13597 [D loss: 0.607729, acc.: 68.75%] [G loss: 0.947325]\n",
      "epoch:14 step:13598 [D loss: 0.697014, acc.: 54.69%] [G loss: 1.008542]\n",
      "epoch:14 step:13599 [D loss: 0.634314, acc.: 66.41%] [G loss: 1.047940]\n",
      "epoch:14 step:13600 [D loss: 0.632021, acc.: 63.28%] [G loss: 1.015573]\n",
      "##############\n",
      "[2.45053674 1.67261629 5.35452594 4.29641625 3.18123993 5.71803632\n",
      " 4.30482276 4.83766348 3.7933808  3.75393885]\n",
      "##########\n",
      "epoch:14 step:13601 [D loss: 0.633520, acc.: 64.84%] [G loss: 0.989221]\n",
      "epoch:14 step:13602 [D loss: 0.526244, acc.: 75.00%] [G loss: 0.959674]\n",
      "epoch:14 step:13603 [D loss: 0.566535, acc.: 70.31%] [G loss: 1.077713]\n",
      "epoch:14 step:13604 [D loss: 0.558005, acc.: 74.22%] [G loss: 1.055738]\n",
      "epoch:14 step:13605 [D loss: 0.622155, acc.: 68.75%] [G loss: 1.019120]\n",
      "epoch:14 step:13606 [D loss: 0.609698, acc.: 66.41%] [G loss: 0.977501]\n",
      "epoch:14 step:13607 [D loss: 0.740531, acc.: 50.00%] [G loss: 0.902745]\n",
      "epoch:14 step:13608 [D loss: 0.714630, acc.: 50.78%] [G loss: 0.842382]\n",
      "epoch:14 step:13609 [D loss: 0.657601, acc.: 57.03%] [G loss: 0.980594]\n",
      "epoch:14 step:13610 [D loss: 0.703249, acc.: 53.91%] [G loss: 1.002115]\n",
      "epoch:14 step:13611 [D loss: 0.693609, acc.: 53.12%] [G loss: 0.920108]\n",
      "epoch:14 step:13612 [D loss: 0.646132, acc.: 63.28%] [G loss: 0.964393]\n",
      "epoch:14 step:13613 [D loss: 0.591056, acc.: 71.09%] [G loss: 1.044882]\n",
      "epoch:14 step:13614 [D loss: 0.660044, acc.: 63.28%] [G loss: 1.051199]\n",
      "epoch:14 step:13615 [D loss: 0.640502, acc.: 65.62%] [G loss: 0.923376]\n",
      "epoch:14 step:13616 [D loss: 0.505134, acc.: 78.91%] [G loss: 1.085914]\n",
      "epoch:14 step:13617 [D loss: 0.476819, acc.: 85.16%] [G loss: 0.996699]\n",
      "epoch:14 step:13618 [D loss: 0.701157, acc.: 56.25%] [G loss: 1.114426]\n",
      "epoch:14 step:13619 [D loss: 0.707243, acc.: 59.38%] [G loss: 1.220603]\n",
      "epoch:14 step:13620 [D loss: 0.660451, acc.: 57.81%] [G loss: 0.842754]\n",
      "epoch:14 step:13621 [D loss: 0.550940, acc.: 78.12%] [G loss: 0.985290]\n",
      "epoch:14 step:13622 [D loss: 0.526895, acc.: 75.00%] [G loss: 0.951719]\n",
      "epoch:14 step:13623 [D loss: 0.669438, acc.: 58.59%] [G loss: 1.036936]\n",
      "epoch:14 step:13624 [D loss: 0.653722, acc.: 62.50%] [G loss: 0.881777]\n",
      "epoch:14 step:13625 [D loss: 0.655798, acc.: 60.94%] [G loss: 0.905435]\n",
      "epoch:14 step:13626 [D loss: 0.495835, acc.: 81.25%] [G loss: 1.010618]\n",
      "epoch:14 step:13627 [D loss: 0.645932, acc.: 61.72%] [G loss: 1.147219]\n",
      "epoch:14 step:13628 [D loss: 0.723444, acc.: 47.66%] [G loss: 0.890551]\n",
      "epoch:14 step:13629 [D loss: 0.587602, acc.: 67.97%] [G loss: 1.036595]\n",
      "epoch:14 step:13630 [D loss: 0.640615, acc.: 66.41%] [G loss: 1.087732]\n",
      "epoch:14 step:13631 [D loss: 0.612815, acc.: 69.53%] [G loss: 1.063814]\n",
      "epoch:14 step:13632 [D loss: 0.627906, acc.: 64.06%] [G loss: 0.888535]\n",
      "epoch:14 step:13633 [D loss: 0.551295, acc.: 74.22%] [G loss: 1.017259]\n",
      "epoch:14 step:13634 [D loss: 0.671332, acc.: 54.69%] [G loss: 0.998266]\n",
      "epoch:14 step:13635 [D loss: 0.702771, acc.: 56.25%] [G loss: 0.969884]\n",
      "epoch:14 step:13636 [D loss: 0.696339, acc.: 54.69%] [G loss: 0.868875]\n",
      "epoch:14 step:13637 [D loss: 0.574555, acc.: 71.09%] [G loss: 0.982451]\n",
      "epoch:14 step:13638 [D loss: 0.592794, acc.: 68.75%] [G loss: 0.998488]\n",
      "epoch:14 step:13639 [D loss: 0.736664, acc.: 51.56%] [G loss: 1.027655]\n",
      "epoch:14 step:13640 [D loss: 0.615965, acc.: 67.97%] [G loss: 1.030339]\n",
      "epoch:14 step:13641 [D loss: 0.532225, acc.: 79.69%] [G loss: 1.185449]\n",
      "epoch:14 step:13642 [D loss: 0.694831, acc.: 50.00%] [G loss: 0.825812]\n",
      "epoch:14 step:13643 [D loss: 0.711736, acc.: 53.91%] [G loss: 0.993002]\n",
      "epoch:14 step:13644 [D loss: 0.708484, acc.: 53.12%] [G loss: 0.950311]\n",
      "epoch:14 step:13645 [D loss: 0.617779, acc.: 64.06%] [G loss: 1.078159]\n",
      "epoch:14 step:13646 [D loss: 0.710705, acc.: 50.00%] [G loss: 0.853963]\n",
      "epoch:14 step:13647 [D loss: 0.721241, acc.: 48.44%] [G loss: 0.918612]\n",
      "epoch:14 step:13648 [D loss: 0.636891, acc.: 60.16%] [G loss: 0.870227]\n",
      "epoch:14 step:13649 [D loss: 0.728998, acc.: 51.56%] [G loss: 0.690445]\n",
      "epoch:14 step:13650 [D loss: 0.573031, acc.: 75.78%] [G loss: 1.036586]\n",
      "epoch:14 step:13651 [D loss: 0.468188, acc.: 82.03%] [G loss: 1.101045]\n",
      "epoch:14 step:13652 [D loss: 0.555747, acc.: 73.44%] [G loss: 1.076880]\n",
      "epoch:14 step:13653 [D loss: 0.625908, acc.: 66.41%] [G loss: 1.021256]\n",
      "epoch:14 step:13654 [D loss: 0.653434, acc.: 57.81%] [G loss: 1.006549]\n",
      "epoch:14 step:13655 [D loss: 0.599300, acc.: 71.88%] [G loss: 1.060345]\n",
      "epoch:14 step:13656 [D loss: 0.714054, acc.: 53.12%] [G loss: 0.786979]\n",
      "epoch:14 step:13657 [D loss: 0.641284, acc.: 60.94%] [G loss: 0.928026]\n",
      "epoch:14 step:13658 [D loss: 0.743639, acc.: 46.09%] [G loss: 0.891366]\n",
      "epoch:14 step:13659 [D loss: 0.733313, acc.: 57.81%] [G loss: 0.896989]\n",
      "epoch:14 step:13660 [D loss: 0.709038, acc.: 50.78%] [G loss: 0.954250]\n",
      "epoch:14 step:13661 [D loss: 0.693192, acc.: 57.81%] [G loss: 1.064741]\n",
      "epoch:14 step:13662 [D loss: 0.696824, acc.: 56.25%] [G loss: 1.074040]\n",
      "epoch:14 step:13663 [D loss: 0.537300, acc.: 78.91%] [G loss: 0.976325]\n",
      "epoch:14 step:13664 [D loss: 0.543605, acc.: 70.31%] [G loss: 1.118368]\n",
      "epoch:14 step:13665 [D loss: 0.587639, acc.: 67.97%] [G loss: 0.990770]\n",
      "epoch:14 step:13666 [D loss: 0.580796, acc.: 72.66%] [G loss: 1.093010]\n",
      "epoch:14 step:13667 [D loss: 0.452536, acc.: 85.16%] [G loss: 1.288681]\n",
      "epoch:14 step:13668 [D loss: 0.489202, acc.: 76.56%] [G loss: 0.992643]\n",
      "epoch:14 step:13669 [D loss: 0.402652, acc.: 86.72%] [G loss: 1.231051]\n",
      "epoch:14 step:13670 [D loss: 0.524107, acc.: 81.25%] [G loss: 1.150668]\n",
      "epoch:14 step:13671 [D loss: 0.623418, acc.: 64.06%] [G loss: 1.135800]\n",
      "epoch:14 step:13672 [D loss: 0.469563, acc.: 83.59%] [G loss: 1.181816]\n",
      "epoch:14 step:13673 [D loss: 0.511677, acc.: 81.25%] [G loss: 1.032536]\n",
      "epoch:14 step:13674 [D loss: 0.442041, acc.: 85.94%] [G loss: 1.201854]\n",
      "epoch:14 step:13675 [D loss: 0.478613, acc.: 80.47%] [G loss: 1.237590]\n",
      "epoch:14 step:13676 [D loss: 0.490619, acc.: 78.91%] [G loss: 1.097487]\n",
      "epoch:14 step:13677 [D loss: 0.937471, acc.: 33.59%] [G loss: 0.910168]\n",
      "epoch:14 step:13678 [D loss: 0.798335, acc.: 52.34%] [G loss: 1.184810]\n",
      "epoch:14 step:13679 [D loss: 0.587985, acc.: 66.41%] [G loss: 1.183962]\n",
      "epoch:14 step:13680 [D loss: 0.735717, acc.: 52.34%] [G loss: 1.114834]\n",
      "epoch:14 step:13681 [D loss: 0.723336, acc.: 50.00%] [G loss: 0.999377]\n",
      "epoch:14 step:13682 [D loss: 0.689962, acc.: 59.38%] [G loss: 0.733332]\n",
      "epoch:14 step:13683 [D loss: 0.633443, acc.: 64.84%] [G loss: 0.919220]\n",
      "epoch:14 step:13684 [D loss: 0.483709, acc.: 81.25%] [G loss: 1.034683]\n",
      "epoch:14 step:13685 [D loss: 0.554606, acc.: 75.00%] [G loss: 1.302942]\n",
      "epoch:14 step:13686 [D loss: 0.619756, acc.: 64.84%] [G loss: 1.030422]\n",
      "epoch:14 step:13687 [D loss: 0.711931, acc.: 57.81%] [G loss: 0.853016]\n",
      "epoch:14 step:13688 [D loss: 0.773825, acc.: 43.75%] [G loss: 0.890000]\n",
      "epoch:14 step:13689 [D loss: 0.678218, acc.: 58.59%] [G loss: 0.829728]\n",
      "epoch:14 step:13690 [D loss: 0.636070, acc.: 59.38%] [G loss: 1.050854]\n",
      "epoch:14 step:13691 [D loss: 0.622302, acc.: 62.50%] [G loss: 1.079595]\n",
      "epoch:14 step:13692 [D loss: 0.565200, acc.: 72.66%] [G loss: 0.942959]\n",
      "epoch:14 step:13693 [D loss: 0.658255, acc.: 59.38%] [G loss: 1.081138]\n",
      "epoch:14 step:13694 [D loss: 0.627852, acc.: 66.41%] [G loss: 0.873208]\n",
      "epoch:14 step:13695 [D loss: 0.678074, acc.: 58.59%] [G loss: 0.970970]\n",
      "epoch:14 step:13696 [D loss: 0.647321, acc.: 59.38%] [G loss: 0.997878]\n",
      "epoch:14 step:13697 [D loss: 0.588637, acc.: 66.41%] [G loss: 1.110674]\n",
      "epoch:14 step:13698 [D loss: 0.791024, acc.: 38.28%] [G loss: 0.964302]\n",
      "epoch:14 step:13699 [D loss: 0.656268, acc.: 63.28%] [G loss: 0.921849]\n",
      "epoch:14 step:13700 [D loss: 0.775672, acc.: 44.53%] [G loss: 0.965565]\n",
      "epoch:14 step:13701 [D loss: 0.641541, acc.: 64.06%] [G loss: 0.938583]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13702 [D loss: 0.686462, acc.: 57.81%] [G loss: 0.807377]\n",
      "epoch:14 step:13703 [D loss: 0.710874, acc.: 51.56%] [G loss: 1.009975]\n",
      "epoch:14 step:13704 [D loss: 0.607135, acc.: 66.41%] [G loss: 0.954535]\n",
      "epoch:14 step:13705 [D loss: 0.493350, acc.: 83.59%] [G loss: 1.043262]\n",
      "epoch:14 step:13706 [D loss: 0.512251, acc.: 81.25%] [G loss: 1.153759]\n",
      "epoch:14 step:13707 [D loss: 0.546039, acc.: 70.31%] [G loss: 0.971212]\n",
      "epoch:14 step:13708 [D loss: 0.651852, acc.: 63.28%] [G loss: 1.247882]\n",
      "epoch:14 step:13709 [D loss: 0.728937, acc.: 54.69%] [G loss: 0.812804]\n",
      "epoch:14 step:13710 [D loss: 0.696884, acc.: 56.25%] [G loss: 0.885636]\n",
      "epoch:14 step:13711 [D loss: 0.602928, acc.: 68.75%] [G loss: 1.011358]\n",
      "epoch:14 step:13712 [D loss: 0.601256, acc.: 71.09%] [G loss: 0.974539]\n",
      "epoch:14 step:13713 [D loss: 0.605234, acc.: 67.19%] [G loss: 1.064898]\n",
      "epoch:14 step:13714 [D loss: 0.681266, acc.: 54.69%] [G loss: 0.935392]\n",
      "epoch:14 step:13715 [D loss: 0.591889, acc.: 66.41%] [G loss: 0.962866]\n",
      "epoch:14 step:13716 [D loss: 0.444695, acc.: 89.06%] [G loss: 1.169754]\n",
      "epoch:14 step:13717 [D loss: 0.723535, acc.: 53.91%] [G loss: 0.993683]\n",
      "epoch:14 step:13718 [D loss: 0.696018, acc.: 53.91%] [G loss: 0.869006]\n",
      "epoch:14 step:13719 [D loss: 0.612269, acc.: 65.62%] [G loss: 0.973324]\n",
      "epoch:14 step:13720 [D loss: 0.745807, acc.: 48.44%] [G loss: 0.933003]\n",
      "epoch:14 step:13721 [D loss: 0.533597, acc.: 79.69%] [G loss: 1.113906]\n",
      "epoch:14 step:13722 [D loss: 0.558514, acc.: 72.66%] [G loss: 1.159164]\n",
      "epoch:14 step:13723 [D loss: 0.495242, acc.: 79.69%] [G loss: 1.075646]\n",
      "epoch:14 step:13724 [D loss: 0.622166, acc.: 67.97%] [G loss: 1.056796]\n",
      "epoch:14 step:13725 [D loss: 0.700353, acc.: 51.56%] [G loss: 0.984010]\n",
      "epoch:14 step:13726 [D loss: 0.620049, acc.: 61.72%] [G loss: 0.933635]\n",
      "epoch:14 step:13727 [D loss: 0.755797, acc.: 49.22%] [G loss: 1.033323]\n",
      "epoch:14 step:13728 [D loss: 0.636122, acc.: 64.06%] [G loss: 1.185873]\n",
      "epoch:14 step:13729 [D loss: 0.664773, acc.: 57.03%] [G loss: 0.921546]\n",
      "epoch:14 step:13730 [D loss: 0.711859, acc.: 55.47%] [G loss: 0.937675]\n",
      "epoch:14 step:13731 [D loss: 0.614146, acc.: 67.19%] [G loss: 0.995196]\n",
      "epoch:14 step:13732 [D loss: 0.540696, acc.: 73.44%] [G loss: 0.988471]\n",
      "epoch:14 step:13733 [D loss: 0.549943, acc.: 72.66%] [G loss: 1.033704]\n",
      "epoch:14 step:13734 [D loss: 0.491933, acc.: 82.03%] [G loss: 1.017619]\n",
      "epoch:14 step:13735 [D loss: 0.579981, acc.: 74.22%] [G loss: 1.067117]\n",
      "epoch:14 step:13736 [D loss: 0.754569, acc.: 49.22%] [G loss: 0.840233]\n",
      "epoch:14 step:13737 [D loss: 0.835699, acc.: 39.06%] [G loss: 0.935226]\n",
      "epoch:14 step:13738 [D loss: 0.853625, acc.: 39.06%] [G loss: 0.791402]\n",
      "epoch:14 step:13739 [D loss: 0.752744, acc.: 52.34%] [G loss: 0.940714]\n",
      "epoch:14 step:13740 [D loss: 0.678651, acc.: 56.25%] [G loss: 1.031180]\n",
      "epoch:14 step:13741 [D loss: 0.671457, acc.: 56.25%] [G loss: 0.947554]\n",
      "epoch:14 step:13742 [D loss: 0.499731, acc.: 82.81%] [G loss: 1.130067]\n",
      "epoch:14 step:13743 [D loss: 0.673813, acc.: 56.25%] [G loss: 0.987032]\n",
      "epoch:14 step:13744 [D loss: 0.698542, acc.: 53.12%] [G loss: 1.013827]\n",
      "epoch:14 step:13745 [D loss: 0.746786, acc.: 47.66%] [G loss: 0.766265]\n",
      "epoch:14 step:13746 [D loss: 0.756136, acc.: 48.44%] [G loss: 1.044438]\n",
      "epoch:14 step:13747 [D loss: 0.597722, acc.: 69.53%] [G loss: 1.013005]\n",
      "epoch:14 step:13748 [D loss: 0.671732, acc.: 59.38%] [G loss: 1.027432]\n",
      "epoch:14 step:13749 [D loss: 0.676122, acc.: 55.47%] [G loss: 1.029587]\n",
      "epoch:14 step:13750 [D loss: 0.652970, acc.: 62.50%] [G loss: 0.886519]\n",
      "epoch:14 step:13751 [D loss: 0.568617, acc.: 73.44%] [G loss: 1.009840]\n",
      "epoch:14 step:13752 [D loss: 0.627776, acc.: 60.16%] [G loss: 1.009587]\n",
      "epoch:14 step:13753 [D loss: 0.659940, acc.: 62.50%] [G loss: 1.117484]\n",
      "epoch:14 step:13754 [D loss: 0.648064, acc.: 64.84%] [G loss: 1.055821]\n",
      "epoch:14 step:13755 [D loss: 0.711818, acc.: 60.94%] [G loss: 0.974473]\n",
      "epoch:14 step:13756 [D loss: 0.644230, acc.: 60.16%] [G loss: 0.874687]\n",
      "epoch:14 step:13757 [D loss: 0.652079, acc.: 64.06%] [G loss: 0.971468]\n",
      "epoch:14 step:13758 [D loss: 0.619632, acc.: 64.06%] [G loss: 0.982403]\n",
      "epoch:14 step:13759 [D loss: 0.441310, acc.: 85.16%] [G loss: 1.197681]\n",
      "epoch:14 step:13760 [D loss: 0.463375, acc.: 85.94%] [G loss: 1.222782]\n",
      "epoch:14 step:13761 [D loss: 0.682903, acc.: 59.38%] [G loss: 1.084095]\n",
      "epoch:14 step:13762 [D loss: 0.624798, acc.: 62.50%] [G loss: 1.048491]\n",
      "epoch:14 step:13763 [D loss: 0.626404, acc.: 63.28%] [G loss: 1.016227]\n",
      "epoch:14 step:13764 [D loss: 0.707201, acc.: 50.78%] [G loss: 0.913438]\n",
      "epoch:14 step:13765 [D loss: 0.511939, acc.: 78.12%] [G loss: 0.831229]\n",
      "epoch:14 step:13766 [D loss: 0.677048, acc.: 58.59%] [G loss: 0.898469]\n",
      "epoch:14 step:13767 [D loss: 0.538219, acc.: 73.44%] [G loss: 1.006283]\n",
      "epoch:14 step:13768 [D loss: 0.520191, acc.: 78.91%] [G loss: 1.129659]\n",
      "epoch:14 step:13769 [D loss: 0.676737, acc.: 57.81%] [G loss: 1.160355]\n",
      "epoch:14 step:13770 [D loss: 0.722426, acc.: 46.88%] [G loss: 0.956633]\n",
      "epoch:14 step:13771 [D loss: 0.627190, acc.: 69.53%] [G loss: 0.960330]\n",
      "epoch:14 step:13772 [D loss: 0.663471, acc.: 62.50%] [G loss: 1.081129]\n",
      "epoch:14 step:13773 [D loss: 0.688612, acc.: 53.91%] [G loss: 1.012993]\n",
      "epoch:14 step:13774 [D loss: 0.647379, acc.: 58.59%] [G loss: 0.977874]\n",
      "epoch:14 step:13775 [D loss: 0.752633, acc.: 45.31%] [G loss: 0.908539]\n",
      "epoch:14 step:13776 [D loss: 0.645714, acc.: 66.41%] [G loss: 0.971965]\n",
      "epoch:14 step:13777 [D loss: 0.658739, acc.: 60.16%] [G loss: 0.899327]\n",
      "epoch:14 step:13778 [D loss: 0.588185, acc.: 65.62%] [G loss: 1.067443]\n",
      "epoch:14 step:13779 [D loss: 0.683761, acc.: 57.81%] [G loss: 0.852550]\n",
      "epoch:14 step:13780 [D loss: 0.612254, acc.: 62.50%] [G loss: 1.004338]\n",
      "epoch:14 step:13781 [D loss: 0.497771, acc.: 82.81%] [G loss: 1.217494]\n",
      "epoch:14 step:13782 [D loss: 0.462177, acc.: 84.38%] [G loss: 1.201955]\n",
      "epoch:14 step:13783 [D loss: 0.600562, acc.: 67.19%] [G loss: 1.098336]\n",
      "epoch:14 step:13784 [D loss: 0.575643, acc.: 66.41%] [G loss: 1.249152]\n",
      "epoch:14 step:13785 [D loss: 0.631050, acc.: 64.06%] [G loss: 0.906308]\n",
      "epoch:14 step:13786 [D loss: 0.701224, acc.: 57.81%] [G loss: 1.184343]\n",
      "epoch:14 step:13787 [D loss: 0.616490, acc.: 60.94%] [G loss: 1.239081]\n",
      "epoch:14 step:13788 [D loss: 0.654981, acc.: 60.16%] [G loss: 0.885072]\n",
      "epoch:14 step:13789 [D loss: 0.677687, acc.: 56.25%] [G loss: 0.971029]\n",
      "epoch:14 step:13790 [D loss: 0.718422, acc.: 50.00%] [G loss: 0.996014]\n",
      "epoch:14 step:13791 [D loss: 0.714649, acc.: 48.44%] [G loss: 0.825244]\n",
      "epoch:14 step:13792 [D loss: 0.801703, acc.: 42.97%] [G loss: 0.643490]\n",
      "epoch:14 step:13793 [D loss: 0.728146, acc.: 46.88%] [G loss: 0.908128]\n",
      "epoch:14 step:13794 [D loss: 0.747153, acc.: 43.75%] [G loss: 0.787881]\n",
      "epoch:14 step:13795 [D loss: 0.615601, acc.: 66.41%] [G loss: 1.212549]\n",
      "epoch:14 step:13796 [D loss: 0.756818, acc.: 48.44%] [G loss: 1.006779]\n",
      "epoch:14 step:13797 [D loss: 0.661332, acc.: 60.16%] [G loss: 0.860631]\n",
      "epoch:14 step:13798 [D loss: 0.645951, acc.: 60.16%] [G loss: 1.091631]\n",
      "epoch:14 step:13799 [D loss: 0.605969, acc.: 66.41%] [G loss: 1.070934]\n",
      "epoch:14 step:13800 [D loss: 0.610790, acc.: 65.62%] [G loss: 0.856317]\n",
      "##############\n",
      "[2.48203046 1.72680861 5.42232921 4.42947126 3.22479228 5.13657484\n",
      " 4.28768844 4.57564228 3.78289811 3.75621567]\n",
      "##########\n",
      "epoch:14 step:13801 [D loss: 0.705681, acc.: 57.81%] [G loss: 0.814883]\n",
      "epoch:14 step:13802 [D loss: 0.717545, acc.: 55.47%] [G loss: 0.905127]\n",
      "epoch:14 step:13803 [D loss: 0.603741, acc.: 71.88%] [G loss: 0.890429]\n",
      "epoch:14 step:13804 [D loss: 0.552790, acc.: 72.66%] [G loss: 1.006643]\n",
      "epoch:14 step:13805 [D loss: 0.593429, acc.: 65.62%] [G loss: 1.005731]\n",
      "epoch:14 step:13806 [D loss: 0.676529, acc.: 58.59%] [G loss: 0.972377]\n",
      "epoch:14 step:13807 [D loss: 0.557312, acc.: 69.53%] [G loss: 1.066263]\n",
      "epoch:14 step:13808 [D loss: 0.470761, acc.: 85.94%] [G loss: 1.081486]\n",
      "epoch:14 step:13809 [D loss: 0.597223, acc.: 67.97%] [G loss: 0.838846]\n",
      "epoch:14 step:13810 [D loss: 0.520643, acc.: 79.69%] [G loss: 1.243077]\n",
      "epoch:14 step:13811 [D loss: 0.624878, acc.: 66.41%] [G loss: 1.185663]\n",
      "epoch:14 step:13812 [D loss: 0.452666, acc.: 85.94%] [G loss: 1.044983]\n",
      "epoch:14 step:13813 [D loss: 0.525880, acc.: 76.56%] [G loss: 1.183332]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13814 [D loss: 0.674011, acc.: 58.59%] [G loss: 1.112228]\n",
      "epoch:14 step:13815 [D loss: 0.789813, acc.: 42.19%] [G loss: 0.922209]\n",
      "epoch:14 step:13816 [D loss: 0.709848, acc.: 48.44%] [G loss: 0.950178]\n",
      "epoch:14 step:13817 [D loss: 0.703606, acc.: 51.56%] [G loss: 0.947940]\n",
      "epoch:14 step:13818 [D loss: 0.645860, acc.: 61.72%] [G loss: 0.892609]\n",
      "epoch:14 step:13819 [D loss: 0.610546, acc.: 63.28%] [G loss: 1.062727]\n",
      "epoch:14 step:13820 [D loss: 0.661320, acc.: 64.06%] [G loss: 0.903298]\n",
      "epoch:14 step:13821 [D loss: 0.587311, acc.: 71.09%] [G loss: 1.071830]\n",
      "epoch:14 step:13822 [D loss: 0.612060, acc.: 67.19%] [G loss: 0.929566]\n",
      "epoch:14 step:13823 [D loss: 0.663916, acc.: 59.38%] [G loss: 0.932142]\n",
      "epoch:14 step:13824 [D loss: 0.512337, acc.: 78.91%] [G loss: 1.104298]\n",
      "epoch:14 step:13825 [D loss: 0.437352, acc.: 87.50%] [G loss: 1.212011]\n",
      "epoch:14 step:13826 [D loss: 0.562514, acc.: 75.00%] [G loss: 1.043722]\n",
      "epoch:14 step:13827 [D loss: 0.447309, acc.: 84.38%] [G loss: 1.160366]\n",
      "epoch:14 step:13828 [D loss: 0.748248, acc.: 53.91%] [G loss: 1.175454]\n",
      "epoch:14 step:13829 [D loss: 0.727446, acc.: 54.69%] [G loss: 0.958685]\n",
      "epoch:14 step:13830 [D loss: 0.603794, acc.: 66.41%] [G loss: 1.017864]\n",
      "epoch:14 step:13831 [D loss: 0.587028, acc.: 67.97%] [G loss: 0.910833]\n",
      "epoch:14 step:13832 [D loss: 0.558854, acc.: 75.00%] [G loss: 1.140526]\n",
      "epoch:14 step:13833 [D loss: 0.686175, acc.: 59.38%] [G loss: 0.951202]\n",
      "epoch:14 step:13834 [D loss: 0.845471, acc.: 38.28%] [G loss: 0.891137]\n",
      "epoch:14 step:13835 [D loss: 0.691068, acc.: 57.81%] [G loss: 1.057113]\n",
      "epoch:14 step:13836 [D loss: 0.742371, acc.: 55.47%] [G loss: 0.915140]\n",
      "epoch:14 step:13837 [D loss: 0.699293, acc.: 53.12%] [G loss: 0.860682]\n",
      "epoch:14 step:13838 [D loss: 0.689552, acc.: 54.69%] [G loss: 0.931676]\n",
      "epoch:14 step:13839 [D loss: 0.623961, acc.: 61.72%] [G loss: 1.016608]\n",
      "epoch:14 step:13840 [D loss: 0.737456, acc.: 53.12%] [G loss: 0.893556]\n",
      "epoch:14 step:13841 [D loss: 0.664347, acc.: 61.72%] [G loss: 0.946378]\n",
      "epoch:14 step:13842 [D loss: 0.686602, acc.: 58.59%] [G loss: 0.910513]\n",
      "epoch:14 step:13843 [D loss: 0.559589, acc.: 71.09%] [G loss: 0.997094]\n",
      "epoch:14 step:13844 [D loss: 0.589997, acc.: 74.22%] [G loss: 1.205270]\n",
      "epoch:14 step:13845 [D loss: 0.552098, acc.: 71.09%] [G loss: 1.093194]\n",
      "epoch:14 step:13846 [D loss: 0.566239, acc.: 75.78%] [G loss: 0.870729]\n",
      "epoch:14 step:13847 [D loss: 0.740760, acc.: 54.69%] [G loss: 0.890367]\n",
      "epoch:14 step:13848 [D loss: 0.596263, acc.: 67.97%] [G loss: 1.005660]\n",
      "epoch:14 step:13849 [D loss: 0.594452, acc.: 64.84%] [G loss: 1.065024]\n",
      "epoch:14 step:13850 [D loss: 0.523031, acc.: 78.12%] [G loss: 1.135303]\n",
      "epoch:14 step:13851 [D loss: 0.484189, acc.: 81.25%] [G loss: 1.116297]\n",
      "epoch:14 step:13852 [D loss: 0.775604, acc.: 49.22%] [G loss: 0.989411]\n",
      "epoch:14 step:13853 [D loss: 0.696721, acc.: 54.69%] [G loss: 1.068459]\n",
      "epoch:14 step:13854 [D loss: 0.773049, acc.: 48.44%] [G loss: 0.976500]\n",
      "epoch:14 step:13855 [D loss: 0.743237, acc.: 52.34%] [G loss: 0.790257]\n",
      "epoch:14 step:13856 [D loss: 0.592487, acc.: 71.88%] [G loss: 0.989251]\n",
      "epoch:14 step:13857 [D loss: 0.743865, acc.: 44.53%] [G loss: 0.878759]\n",
      "epoch:14 step:13858 [D loss: 0.643658, acc.: 61.72%] [G loss: 0.994301]\n",
      "epoch:14 step:13859 [D loss: 0.760716, acc.: 39.06%] [G loss: 0.848044]\n",
      "epoch:14 step:13860 [D loss: 0.686816, acc.: 58.59%] [G loss: 1.049804]\n",
      "epoch:14 step:13861 [D loss: 0.508741, acc.: 78.91%] [G loss: 1.025740]\n",
      "epoch:14 step:13862 [D loss: 0.725082, acc.: 51.56%] [G loss: 0.968890]\n",
      "epoch:14 step:13863 [D loss: 0.548927, acc.: 74.22%] [G loss: 0.927954]\n",
      "epoch:14 step:13864 [D loss: 0.563923, acc.: 74.22%] [G loss: 1.017356]\n",
      "epoch:14 step:13865 [D loss: 0.607618, acc.: 67.19%] [G loss: 1.148047]\n",
      "epoch:14 step:13866 [D loss: 0.625472, acc.: 66.41%] [G loss: 1.092390]\n",
      "epoch:14 step:13867 [D loss: 0.653421, acc.: 56.25%] [G loss: 1.069401]\n",
      "epoch:14 step:13868 [D loss: 0.579971, acc.: 75.00%] [G loss: 0.824482]\n",
      "epoch:14 step:13869 [D loss: 0.667766, acc.: 60.94%] [G loss: 1.101392]\n",
      "epoch:14 step:13870 [D loss: 0.722506, acc.: 50.78%] [G loss: 1.040596]\n",
      "epoch:14 step:13871 [D loss: 0.666391, acc.: 60.94%] [G loss: 0.861021]\n",
      "epoch:14 step:13872 [D loss: 0.694607, acc.: 58.59%] [G loss: 0.914746]\n",
      "epoch:14 step:13873 [D loss: 0.540658, acc.: 72.66%] [G loss: 1.073015]\n",
      "epoch:14 step:13874 [D loss: 0.619065, acc.: 64.06%] [G loss: 0.917658]\n",
      "epoch:14 step:13875 [D loss: 0.600433, acc.: 67.19%] [G loss: 0.996197]\n",
      "epoch:14 step:13876 [D loss: 0.654909, acc.: 62.50%] [G loss: 0.834461]\n",
      "epoch:14 step:13877 [D loss: 0.844124, acc.: 36.72%] [G loss: 0.850060]\n",
      "epoch:14 step:13878 [D loss: 0.727494, acc.: 53.12%] [G loss: 0.953307]\n",
      "epoch:14 step:13879 [D loss: 0.666430, acc.: 55.47%] [G loss: 1.017894]\n",
      "epoch:14 step:13880 [D loss: 0.814475, acc.: 41.41%] [G loss: 0.917570]\n",
      "epoch:14 step:13881 [D loss: 0.666825, acc.: 57.81%] [G loss: 1.011787]\n",
      "epoch:14 step:13882 [D loss: 0.620202, acc.: 65.62%] [G loss: 0.948952]\n",
      "epoch:14 step:13883 [D loss: 0.661231, acc.: 57.03%] [G loss: 1.023142]\n",
      "epoch:14 step:13884 [D loss: 0.657129, acc.: 57.81%] [G loss: 1.026334]\n",
      "epoch:14 step:13885 [D loss: 0.480150, acc.: 82.81%] [G loss: 1.152667]\n",
      "epoch:14 step:13886 [D loss: 0.526109, acc.: 73.44%] [G loss: 1.111585]\n",
      "epoch:14 step:13887 [D loss: 0.494287, acc.: 75.78%] [G loss: 1.038903]\n",
      "epoch:14 step:13888 [D loss: 0.670182, acc.: 57.81%] [G loss: 1.177029]\n",
      "epoch:14 step:13889 [D loss: 0.645784, acc.: 60.16%] [G loss: 1.010594]\n",
      "epoch:14 step:13890 [D loss: 0.659890, acc.: 64.06%] [G loss: 1.019267]\n",
      "epoch:14 step:13891 [D loss: 0.602701, acc.: 70.31%] [G loss: 0.923294]\n",
      "epoch:14 step:13892 [D loss: 0.424533, acc.: 83.59%] [G loss: 1.222198]\n",
      "epoch:14 step:13893 [D loss: 0.589815, acc.: 64.84%] [G loss: 0.759095]\n",
      "epoch:14 step:13894 [D loss: 0.519474, acc.: 79.69%] [G loss: 1.459310]\n",
      "epoch:14 step:13895 [D loss: 0.684693, acc.: 60.16%] [G loss: 1.229248]\n",
      "epoch:14 step:13896 [D loss: 0.840471, acc.: 38.28%] [G loss: 0.993826]\n",
      "epoch:14 step:13897 [D loss: 0.807178, acc.: 46.88%] [G loss: 0.833300]\n",
      "epoch:14 step:13898 [D loss: 0.757343, acc.: 51.56%] [G loss: 1.150587]\n",
      "epoch:14 step:13899 [D loss: 0.581660, acc.: 69.53%] [G loss: 0.915663]\n",
      "epoch:14 step:13900 [D loss: 0.487474, acc.: 80.47%] [G loss: 1.138057]\n",
      "epoch:14 step:13901 [D loss: 0.655479, acc.: 60.94%] [G loss: 1.091801]\n",
      "epoch:14 step:13902 [D loss: 0.690472, acc.: 56.25%] [G loss: 1.127848]\n",
      "epoch:14 step:13903 [D loss: 0.682112, acc.: 59.38%] [G loss: 0.903972]\n",
      "epoch:14 step:13904 [D loss: 0.492792, acc.: 82.03%] [G loss: 0.992273]\n",
      "epoch:14 step:13905 [D loss: 0.724883, acc.: 52.34%] [G loss: 1.025968]\n",
      "epoch:14 step:13906 [D loss: 0.625504, acc.: 61.72%] [G loss: 0.991327]\n",
      "epoch:14 step:13907 [D loss: 0.640206, acc.: 67.19%] [G loss: 1.039247]\n",
      "epoch:14 step:13908 [D loss: 0.540386, acc.: 73.44%] [G loss: 0.913194]\n",
      "epoch:14 step:13909 [D loss: 0.500354, acc.: 76.56%] [G loss: 1.003127]\n",
      "epoch:14 step:13910 [D loss: 0.474223, acc.: 82.03%] [G loss: 1.295197]\n",
      "epoch:14 step:13911 [D loss: 0.494329, acc.: 78.91%] [G loss: 1.294612]\n",
      "epoch:14 step:13912 [D loss: 0.499033, acc.: 76.56%] [G loss: 1.156252]\n",
      "epoch:14 step:13913 [D loss: 0.607136, acc.: 68.75%] [G loss: 1.124821]\n",
      "epoch:14 step:13914 [D loss: 0.664698, acc.: 60.16%] [G loss: 0.895524]\n",
      "epoch:14 step:13915 [D loss: 0.644165, acc.: 63.28%] [G loss: 0.987919]\n",
      "epoch:14 step:13916 [D loss: 0.613212, acc.: 68.75%] [G loss: 1.158136]\n",
      "epoch:14 step:13917 [D loss: 0.665960, acc.: 61.72%] [G loss: 1.055064]\n",
      "epoch:14 step:13918 [D loss: 0.837162, acc.: 40.62%] [G loss: 0.782935]\n",
      "epoch:14 step:13919 [D loss: 0.726600, acc.: 56.25%] [G loss: 0.891356]\n",
      "epoch:14 step:13920 [D loss: 0.704034, acc.: 55.47%] [G loss: 0.751849]\n",
      "epoch:14 step:13921 [D loss: 0.707281, acc.: 57.81%] [G loss: 0.860421]\n",
      "epoch:14 step:13922 [D loss: 0.650893, acc.: 60.16%] [G loss: 0.944353]\n",
      "epoch:14 step:13923 [D loss: 0.500845, acc.: 83.59%] [G loss: 1.130088]\n",
      "epoch:14 step:13924 [D loss: 0.559975, acc.: 69.53%] [G loss: 1.036798]\n",
      "epoch:14 step:13925 [D loss: 0.668344, acc.: 60.16%] [G loss: 0.916163]\n",
      "epoch:14 step:13926 [D loss: 0.588484, acc.: 71.09%] [G loss: 1.053720]\n",
      "epoch:14 step:13927 [D loss: 0.695643, acc.: 54.69%] [G loss: 0.954089]\n",
      "epoch:14 step:13928 [D loss: 0.606129, acc.: 71.09%] [G loss: 1.282715]\n",
      "epoch:14 step:13929 [D loss: 0.665784, acc.: 63.28%] [G loss: 1.091988]\n",
      "epoch:14 step:13930 [D loss: 0.678948, acc.: 60.16%] [G loss: 0.982385]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13931 [D loss: 0.592683, acc.: 70.31%] [G loss: 1.083292]\n",
      "epoch:14 step:13932 [D loss: 0.573550, acc.: 71.88%] [G loss: 0.988341]\n",
      "epoch:14 step:13933 [D loss: 0.375427, acc.: 86.72%] [G loss: 1.214198]\n",
      "epoch:14 step:13934 [D loss: 0.469618, acc.: 83.59%] [G loss: 1.167231]\n",
      "epoch:14 step:13935 [D loss: 0.628262, acc.: 69.53%] [G loss: 0.933021]\n",
      "epoch:14 step:13936 [D loss: 0.656566, acc.: 59.38%] [G loss: 0.885174]\n",
      "epoch:14 step:13937 [D loss: 0.568580, acc.: 73.44%] [G loss: 1.096895]\n",
      "epoch:14 step:13938 [D loss: 0.897029, acc.: 36.72%] [G loss: 0.890314]\n",
      "epoch:14 step:13939 [D loss: 0.680972, acc.: 57.03%] [G loss: 1.006229]\n",
      "epoch:14 step:13940 [D loss: 0.855517, acc.: 35.16%] [G loss: 1.032854]\n",
      "epoch:14 step:13941 [D loss: 0.646085, acc.: 62.50%] [G loss: 1.136428]\n",
      "epoch:14 step:13942 [D loss: 0.592266, acc.: 70.31%] [G loss: 1.132394]\n",
      "epoch:14 step:13943 [D loss: 0.574715, acc.: 75.00%] [G loss: 0.857013]\n",
      "epoch:14 step:13944 [D loss: 0.569201, acc.: 70.31%] [G loss: 1.092624]\n",
      "epoch:14 step:13945 [D loss: 0.736633, acc.: 53.91%] [G loss: 0.894926]\n",
      "epoch:14 step:13946 [D loss: 0.651378, acc.: 61.72%] [G loss: 0.991024]\n",
      "epoch:14 step:13947 [D loss: 0.712784, acc.: 53.91%] [G loss: 0.985842]\n",
      "epoch:14 step:13948 [D loss: 0.795952, acc.: 49.22%] [G loss: 0.765477]\n",
      "epoch:14 step:13949 [D loss: 0.635770, acc.: 60.94%] [G loss: 0.981337]\n",
      "epoch:14 step:13950 [D loss: 0.585794, acc.: 67.97%] [G loss: 0.968901]\n",
      "epoch:14 step:13951 [D loss: 0.554817, acc.: 76.56%] [G loss: 1.241938]\n",
      "epoch:14 step:13952 [D loss: 0.767119, acc.: 46.09%] [G loss: 1.135524]\n",
      "epoch:14 step:13953 [D loss: 0.640986, acc.: 59.38%] [G loss: 1.055103]\n",
      "epoch:14 step:13954 [D loss: 0.694965, acc.: 55.47%] [G loss: 1.106733]\n",
      "epoch:14 step:13955 [D loss: 0.735807, acc.: 53.12%] [G loss: 0.883862]\n",
      "epoch:14 step:13956 [D loss: 0.595083, acc.: 61.72%] [G loss: 1.126198]\n",
      "epoch:14 step:13957 [D loss: 0.620006, acc.: 65.62%] [G loss: 1.058283]\n",
      "epoch:14 step:13958 [D loss: 0.634936, acc.: 62.50%] [G loss: 1.138762]\n",
      "epoch:14 step:13959 [D loss: 0.495034, acc.: 82.81%] [G loss: 1.121666]\n",
      "epoch:14 step:13960 [D loss: 0.564741, acc.: 70.31%] [G loss: 1.167878]\n",
      "epoch:14 step:13961 [D loss: 0.711440, acc.: 53.91%] [G loss: 1.166163]\n",
      "epoch:14 step:13962 [D loss: 0.803686, acc.: 39.84%] [G loss: 0.910849]\n",
      "epoch:14 step:13963 [D loss: 0.701463, acc.: 53.12%] [G loss: 0.873991]\n",
      "epoch:14 step:13964 [D loss: 0.608486, acc.: 66.41%] [G loss: 0.885231]\n",
      "epoch:14 step:13965 [D loss: 0.532774, acc.: 75.78%] [G loss: 1.054089]\n",
      "epoch:14 step:13966 [D loss: 0.650717, acc.: 59.38%] [G loss: 1.202819]\n",
      "epoch:14 step:13967 [D loss: 0.542745, acc.: 75.00%] [G loss: 1.019099]\n",
      "epoch:14 step:13968 [D loss: 0.513710, acc.: 75.00%] [G loss: 1.101581]\n",
      "epoch:14 step:13969 [D loss: 0.503058, acc.: 78.91%] [G loss: 1.111284]\n",
      "epoch:14 step:13970 [D loss: 0.512077, acc.: 76.56%] [G loss: 1.175777]\n",
      "epoch:14 step:13971 [D loss: 0.539774, acc.: 75.00%] [G loss: 1.440459]\n",
      "epoch:14 step:13972 [D loss: 0.502658, acc.: 78.12%] [G loss: 1.291628]\n",
      "epoch:14 step:13973 [D loss: 0.490562, acc.: 82.03%] [G loss: 1.298848]\n",
      "epoch:14 step:13974 [D loss: 0.739792, acc.: 53.91%] [G loss: 0.868969]\n",
      "epoch:14 step:13975 [D loss: 0.639188, acc.: 63.28%] [G loss: 0.879574]\n",
      "epoch:14 step:13976 [D loss: 0.952362, acc.: 28.91%] [G loss: 0.910293]\n",
      "epoch:14 step:13977 [D loss: 0.969148, acc.: 26.56%] [G loss: 0.712551]\n",
      "epoch:14 step:13978 [D loss: 0.672468, acc.: 60.16%] [G loss: 0.991337]\n",
      "epoch:14 step:13979 [D loss: 0.628413, acc.: 64.84%] [G loss: 0.882571]\n",
      "epoch:14 step:13980 [D loss: 0.735276, acc.: 53.91%] [G loss: 0.928083]\n",
      "epoch:14 step:13981 [D loss: 0.645131, acc.: 60.16%] [G loss: 0.969858]\n",
      "epoch:14 step:13982 [D loss: 0.686703, acc.: 57.81%] [G loss: 0.990017]\n",
      "epoch:14 step:13983 [D loss: 0.686454, acc.: 57.81%] [G loss: 0.906239]\n",
      "epoch:14 step:13984 [D loss: 0.674010, acc.: 57.03%] [G loss: 0.837997]\n",
      "epoch:14 step:13985 [D loss: 0.617859, acc.: 62.50%] [G loss: 0.843870]\n",
      "epoch:14 step:13986 [D loss: 0.650378, acc.: 61.72%] [G loss: 0.847036]\n",
      "epoch:14 step:13987 [D loss: 0.671463, acc.: 57.81%] [G loss: 1.037560]\n",
      "epoch:14 step:13988 [D loss: 0.656755, acc.: 62.50%] [G loss: 0.931469]\n",
      "epoch:14 step:13989 [D loss: 0.667629, acc.: 60.16%] [G loss: 0.962008]\n",
      "epoch:14 step:13990 [D loss: 0.638304, acc.: 60.16%] [G loss: 0.909279]\n",
      "epoch:14 step:13991 [D loss: 0.651575, acc.: 60.16%] [G loss: 1.002248]\n",
      "epoch:14 step:13992 [D loss: 0.645952, acc.: 65.62%] [G loss: 0.879601]\n",
      "epoch:14 step:13993 [D loss: 0.606453, acc.: 67.19%] [G loss: 0.889118]\n",
      "epoch:14 step:13994 [D loss: 0.636085, acc.: 64.06%] [G loss: 1.019670]\n",
      "epoch:14 step:13995 [D loss: 0.602942, acc.: 68.75%] [G loss: 1.098319]\n",
      "epoch:14 step:13996 [D loss: 0.541784, acc.: 79.69%] [G loss: 1.061035]\n",
      "epoch:14 step:13997 [D loss: 0.702740, acc.: 54.69%] [G loss: 0.901374]\n",
      "epoch:14 step:13998 [D loss: 0.750879, acc.: 50.78%] [G loss: 0.977883]\n",
      "epoch:14 step:13999 [D loss: 0.725445, acc.: 52.34%] [G loss: 1.027311]\n",
      "epoch:14 step:14000 [D loss: 0.659396, acc.: 63.28%] [G loss: 0.869071]\n",
      "##############\n",
      "[2.4529584  1.7092905  5.48738769 4.36610393 3.14638179 5.41962754\n",
      " 4.30913368 4.59337318 4.09796158 3.67431255]\n",
      "##########\n",
      "epoch:14 step:14001 [D loss: 0.695460, acc.: 57.81%] [G loss: 0.934387]\n",
      "epoch:14 step:14002 [D loss: 0.633146, acc.: 61.72%] [G loss: 0.957823]\n",
      "epoch:14 step:14003 [D loss: 0.559678, acc.: 68.75%] [G loss: 0.844009]\n",
      "epoch:14 step:14004 [D loss: 0.613704, acc.: 65.62%] [G loss: 0.912426]\n",
      "epoch:14 step:14005 [D loss: 0.526779, acc.: 75.00%] [G loss: 0.928507]\n",
      "epoch:14 step:14006 [D loss: 0.625638, acc.: 61.72%] [G loss: 0.956539]\n",
      "epoch:14 step:14007 [D loss: 0.596901, acc.: 67.97%] [G loss: 1.280801]\n",
      "epoch:14 step:14008 [D loss: 0.472124, acc.: 86.72%] [G loss: 1.233520]\n",
      "epoch:14 step:14009 [D loss: 0.736919, acc.: 49.22%] [G loss: 1.080620]\n",
      "epoch:14 step:14010 [D loss: 0.830162, acc.: 40.62%] [G loss: 0.895437]\n",
      "epoch:14 step:14011 [D loss: 0.674405, acc.: 56.25%] [G loss: 0.886578]\n",
      "epoch:14 step:14012 [D loss: 0.555886, acc.: 75.78%] [G loss: 0.912135]\n",
      "epoch:14 step:14013 [D loss: 0.668059, acc.: 55.47%] [G loss: 0.988593]\n",
      "epoch:14 step:14014 [D loss: 0.612989, acc.: 71.88%] [G loss: 1.043869]\n",
      "epoch:14 step:14015 [D loss: 0.545436, acc.: 74.22%] [G loss: 1.138560]\n",
      "epoch:14 step:14016 [D loss: 0.565794, acc.: 68.75%] [G loss: 0.881951]\n",
      "epoch:14 step:14017 [D loss: 0.456212, acc.: 82.03%] [G loss: 1.194140]\n",
      "epoch:14 step:14018 [D loss: 0.589989, acc.: 67.19%] [G loss: 1.010588]\n",
      "epoch:14 step:14019 [D loss: 0.697634, acc.: 56.25%] [G loss: 1.213489]\n",
      "epoch:14 step:14020 [D loss: 0.714167, acc.: 57.03%] [G loss: 0.917680]\n",
      "epoch:14 step:14021 [D loss: 0.732500, acc.: 45.31%] [G loss: 1.102707]\n",
      "epoch:14 step:14022 [D loss: 0.693479, acc.: 57.03%] [G loss: 1.129236]\n",
      "epoch:14 step:14023 [D loss: 0.600034, acc.: 67.19%] [G loss: 0.992221]\n",
      "epoch:14 step:14024 [D loss: 0.625553, acc.: 66.41%] [G loss: 0.975291]\n",
      "epoch:14 step:14025 [D loss: 0.624024, acc.: 65.62%] [G loss: 0.850587]\n",
      "epoch:14 step:14026 [D loss: 0.761147, acc.: 50.78%] [G loss: 0.991447]\n",
      "epoch:14 step:14027 [D loss: 0.628185, acc.: 67.97%] [G loss: 0.908436]\n",
      "epoch:14 step:14028 [D loss: 0.600678, acc.: 69.53%] [G loss: 1.037327]\n",
      "epoch:14 step:14029 [D loss: 0.466617, acc.: 83.59%] [G loss: 1.017371]\n",
      "epoch:14 step:14030 [D loss: 0.352026, acc.: 89.84%] [G loss: 1.131508]\n",
      "epoch:14 step:14031 [D loss: 0.740979, acc.: 51.56%] [G loss: 1.139485]\n",
      "epoch:14 step:14032 [D loss: 0.698934, acc.: 50.78%] [G loss: 1.003892]\n",
      "epoch:14 step:14033 [D loss: 0.612165, acc.: 67.97%] [G loss: 0.957307]\n",
      "epoch:14 step:14034 [D loss: 0.654262, acc.: 60.94%] [G loss: 0.915183]\n",
      "epoch:14 step:14035 [D loss: 0.774958, acc.: 46.88%] [G loss: 0.912860]\n",
      "epoch:14 step:14036 [D loss: 0.583939, acc.: 69.53%] [G loss: 1.023274]\n",
      "epoch:14 step:14037 [D loss: 0.526896, acc.: 78.91%] [G loss: 1.024983]\n",
      "epoch:14 step:14038 [D loss: 0.591355, acc.: 65.62%] [G loss: 1.221162]\n",
      "epoch:14 step:14039 [D loss: 0.600270, acc.: 69.53%] [G loss: 1.039840]\n",
      "epoch:14 step:14040 [D loss: 0.627737, acc.: 63.28%] [G loss: 1.034818]\n",
      "epoch:14 step:14041 [D loss: 0.563287, acc.: 72.66%] [G loss: 0.990351]\n",
      "epoch:14 step:14042 [D loss: 0.464285, acc.: 84.38%] [G loss: 1.067477]\n",
      "epoch:14 step:14043 [D loss: 0.508597, acc.: 80.47%] [G loss: 1.161129]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:14044 [D loss: 0.544061, acc.: 77.34%] [G loss: 1.069240]\n",
      "epoch:14 step:14045 [D loss: 0.468637, acc.: 86.72%] [G loss: 1.253536]\n",
      "epoch:14 step:14046 [D loss: 0.936316, acc.: 35.16%] [G loss: 0.884709]\n",
      "epoch:14 step:14047 [D loss: 0.429514, acc.: 84.38%] [G loss: 1.146093]\n",
      "epoch:14 step:14048 [D loss: 0.541570, acc.: 71.88%] [G loss: 1.201185]\n",
      "epoch:14 step:14049 [D loss: 0.606316, acc.: 66.41%] [G loss: 1.020661]\n",
      "epoch:14 step:14050 [D loss: 0.605326, acc.: 67.19%] [G loss: 1.065667]\n",
      "epoch:14 step:14051 [D loss: 0.575852, acc.: 68.75%] [G loss: 0.969905]\n",
      "epoch:14 step:14052 [D loss: 0.465117, acc.: 78.91%] [G loss: 1.102131]\n",
      "epoch:14 step:14053 [D loss: 0.550271, acc.: 75.78%] [G loss: 1.127421]\n",
      "epoch:14 step:14054 [D loss: 0.576263, acc.: 70.31%] [G loss: 0.966309]\n",
      "epoch:14 step:14055 [D loss: 0.285671, acc.: 92.19%] [G loss: 1.292217]\n",
      "epoch:15 step:14056 [D loss: 0.733593, acc.: 54.69%] [G loss: 1.089440]\n",
      "epoch:15 step:14057 [D loss: 0.742480, acc.: 52.34%] [G loss: 0.913189]\n",
      "epoch:15 step:14058 [D loss: 0.825064, acc.: 40.62%] [G loss: 0.933646]\n",
      "epoch:15 step:14059 [D loss: 0.692855, acc.: 53.91%] [G loss: 0.951683]\n",
      "epoch:15 step:14060 [D loss: 0.674142, acc.: 61.72%] [G loss: 1.164116]\n",
      "epoch:15 step:14061 [D loss: 0.680835, acc.: 60.16%] [G loss: 1.075705]\n",
      "epoch:15 step:14062 [D loss: 0.668453, acc.: 57.03%] [G loss: 0.927399]\n",
      "epoch:15 step:14063 [D loss: 0.514496, acc.: 81.25%] [G loss: 1.227429]\n",
      "epoch:15 step:14064 [D loss: 0.545645, acc.: 74.22%] [G loss: 1.052151]\n",
      "epoch:15 step:14065 [D loss: 0.654230, acc.: 64.06%] [G loss: 0.970331]\n",
      "epoch:15 step:14066 [D loss: 0.627888, acc.: 65.62%] [G loss: 1.000263]\n",
      "epoch:15 step:14067 [D loss: 0.648351, acc.: 61.72%] [G loss: 1.168446]\n",
      "epoch:15 step:14068 [D loss: 0.733004, acc.: 50.78%] [G loss: 0.991952]\n",
      "epoch:15 step:14069 [D loss: 0.693144, acc.: 60.94%] [G loss: 0.994880]\n",
      "epoch:15 step:14070 [D loss: 0.585618, acc.: 69.53%] [G loss: 1.051624]\n",
      "epoch:15 step:14071 [D loss: 0.476214, acc.: 86.72%] [G loss: 1.289855]\n",
      "epoch:15 step:14072 [D loss: 0.647197, acc.: 63.28%] [G loss: 1.075555]\n",
      "epoch:15 step:14073 [D loss: 0.689995, acc.: 56.25%] [G loss: 1.089279]\n",
      "epoch:15 step:14074 [D loss: 0.748695, acc.: 51.56%] [G loss: 1.065190]\n",
      "epoch:15 step:14075 [D loss: 0.685072, acc.: 59.38%] [G loss: 1.018329]\n",
      "epoch:15 step:14076 [D loss: 0.686789, acc.: 53.91%] [G loss: 0.965536]\n",
      "epoch:15 step:14077 [D loss: 0.713027, acc.: 53.91%] [G loss: 0.959951]\n",
      "epoch:15 step:14078 [D loss: 0.589849, acc.: 64.84%] [G loss: 1.039169]\n",
      "epoch:15 step:14079 [D loss: 0.671054, acc.: 54.69%] [G loss: 0.946425]\n",
      "epoch:15 step:14080 [D loss: 0.568666, acc.: 73.44%] [G loss: 0.947659]\n",
      "epoch:15 step:14081 [D loss: 0.600330, acc.: 65.62%] [G loss: 1.090690]\n",
      "epoch:15 step:14082 [D loss: 0.614961, acc.: 63.28%] [G loss: 1.122423]\n",
      "epoch:15 step:14083 [D loss: 0.446044, acc.: 85.94%] [G loss: 1.112404]\n",
      "epoch:15 step:14084 [D loss: 0.527885, acc.: 77.34%] [G loss: 1.220041]\n",
      "epoch:15 step:14085 [D loss: 0.536132, acc.: 77.34%] [G loss: 1.143420]\n",
      "epoch:15 step:14086 [D loss: 0.529440, acc.: 77.34%] [G loss: 1.142962]\n",
      "epoch:15 step:14087 [D loss: 0.484666, acc.: 80.47%] [G loss: 1.163023]\n",
      "epoch:15 step:14088 [D loss: 0.451535, acc.: 83.59%] [G loss: 1.227616]\n",
      "epoch:15 step:14089 [D loss: 0.500301, acc.: 81.25%] [G loss: 1.239615]\n",
      "epoch:15 step:14090 [D loss: 0.444036, acc.: 85.94%] [G loss: 1.166319]\n",
      "epoch:15 step:14091 [D loss: 0.384017, acc.: 88.28%] [G loss: 1.230650]\n",
      "epoch:15 step:14092 [D loss: 0.698449, acc.: 60.16%] [G loss: 1.303128]\n",
      "epoch:15 step:14093 [D loss: 0.846587, acc.: 38.28%] [G loss: 0.855711]\n",
      "epoch:15 step:14094 [D loss: 0.696122, acc.: 55.47%] [G loss: 0.867636]\n",
      "epoch:15 step:14095 [D loss: 0.692270, acc.: 55.47%] [G loss: 1.144094]\n",
      "epoch:15 step:14096 [D loss: 0.678907, acc.: 57.81%] [G loss: 0.991329]\n",
      "epoch:15 step:14097 [D loss: 0.612944, acc.: 65.62%] [G loss: 0.963231]\n",
      "epoch:15 step:14098 [D loss: 0.645497, acc.: 59.38%] [G loss: 1.031226]\n",
      "epoch:15 step:14099 [D loss: 0.555706, acc.: 72.66%] [G loss: 1.170337]\n",
      "epoch:15 step:14100 [D loss: 0.722605, acc.: 54.69%] [G loss: 0.951225]\n",
      "epoch:15 step:14101 [D loss: 0.741435, acc.: 52.34%] [G loss: 0.881228]\n",
      "epoch:15 step:14102 [D loss: 0.722550, acc.: 58.59%] [G loss: 0.987128]\n",
      "epoch:15 step:14103 [D loss: 0.741449, acc.: 53.12%] [G loss: 1.011909]\n",
      "epoch:15 step:14104 [D loss: 0.624055, acc.: 70.31%] [G loss: 0.966777]\n",
      "epoch:15 step:14105 [D loss: 0.543538, acc.: 78.12%] [G loss: 1.111238]\n",
      "epoch:15 step:14106 [D loss: 0.627185, acc.: 64.06%] [G loss: 0.864986]\n",
      "epoch:15 step:14107 [D loss: 0.728363, acc.: 50.78%] [G loss: 0.930656]\n",
      "epoch:15 step:14108 [D loss: 0.631154, acc.: 64.84%] [G loss: 0.989817]\n",
      "epoch:15 step:14109 [D loss: 0.582780, acc.: 67.97%] [G loss: 0.953700]\n",
      "epoch:15 step:14110 [D loss: 0.555504, acc.: 69.53%] [G loss: 0.980103]\n",
      "epoch:15 step:14111 [D loss: 0.657489, acc.: 59.38%] [G loss: 1.052616]\n",
      "epoch:15 step:14112 [D loss: 0.750994, acc.: 50.00%] [G loss: 0.939289]\n",
      "epoch:15 step:14113 [D loss: 0.802926, acc.: 43.75%] [G loss: 0.774593]\n",
      "epoch:15 step:14114 [D loss: 0.715195, acc.: 52.34%] [G loss: 0.780582]\n",
      "epoch:15 step:14115 [D loss: 0.776098, acc.: 44.53%] [G loss: 0.821313]\n",
      "epoch:15 step:14116 [D loss: 0.743334, acc.: 53.12%] [G loss: 0.963912]\n",
      "epoch:15 step:14117 [D loss: 0.785604, acc.: 46.09%] [G loss: 0.858815]\n",
      "epoch:15 step:14118 [D loss: 0.671045, acc.: 60.94%] [G loss: 1.170648]\n",
      "epoch:15 step:14119 [D loss: 0.709740, acc.: 54.69%] [G loss: 0.848974]\n",
      "epoch:15 step:14120 [D loss: 0.684634, acc.: 59.38%] [G loss: 0.938251]\n",
      "epoch:15 step:14121 [D loss: 0.709658, acc.: 52.34%] [G loss: 1.120390]\n",
      "epoch:15 step:14122 [D loss: 0.608701, acc.: 75.00%] [G loss: 0.909031]\n",
      "epoch:15 step:14123 [D loss: 0.629447, acc.: 62.50%] [G loss: 1.023561]\n",
      "epoch:15 step:14124 [D loss: 0.624708, acc.: 65.62%] [G loss: 0.994676]\n",
      "epoch:15 step:14125 [D loss: 0.675813, acc.: 57.81%] [G loss: 0.865349]\n",
      "epoch:15 step:14126 [D loss: 0.624912, acc.: 69.53%] [G loss: 1.004991]\n",
      "epoch:15 step:14127 [D loss: 0.591710, acc.: 66.41%] [G loss: 0.974993]\n",
      "epoch:15 step:14128 [D loss: 0.583957, acc.: 69.53%] [G loss: 0.974947]\n",
      "epoch:15 step:14129 [D loss: 0.541012, acc.: 72.66%] [G loss: 1.146160]\n",
      "epoch:15 step:14130 [D loss: 0.386944, acc.: 87.50%] [G loss: 1.253045]\n",
      "epoch:15 step:14131 [D loss: 0.396299, acc.: 92.19%] [G loss: 1.408340]\n",
      "epoch:15 step:14132 [D loss: 0.455885, acc.: 83.59%] [G loss: 1.305975]\n",
      "epoch:15 step:14133 [D loss: 0.770161, acc.: 46.88%] [G loss: 0.991790]\n",
      "epoch:15 step:14134 [D loss: 0.648486, acc.: 61.72%] [G loss: 0.842516]\n",
      "epoch:15 step:14135 [D loss: 0.761855, acc.: 46.09%] [G loss: 1.008257]\n",
      "epoch:15 step:14136 [D loss: 0.767982, acc.: 43.75%] [G loss: 0.880326]\n",
      "epoch:15 step:14137 [D loss: 0.716169, acc.: 54.69%] [G loss: 0.770032]\n",
      "epoch:15 step:14138 [D loss: 0.628820, acc.: 62.50%] [G loss: 1.145990]\n",
      "epoch:15 step:14139 [D loss: 0.718224, acc.: 55.47%] [G loss: 1.019896]\n",
      "epoch:15 step:14140 [D loss: 0.798179, acc.: 40.62%] [G loss: 0.908082]\n",
      "epoch:15 step:14141 [D loss: 0.698476, acc.: 53.91%] [G loss: 0.965588]\n",
      "epoch:15 step:14142 [D loss: 0.643135, acc.: 65.62%] [G loss: 0.828106]\n",
      "epoch:15 step:14143 [D loss: 0.575457, acc.: 71.88%] [G loss: 1.126250]\n",
      "epoch:15 step:14144 [D loss: 0.659026, acc.: 61.72%] [G loss: 0.894409]\n",
      "epoch:15 step:14145 [D loss: 0.543149, acc.: 74.22%] [G loss: 1.019260]\n",
      "epoch:15 step:14146 [D loss: 0.554595, acc.: 73.44%] [G loss: 1.220703]\n",
      "epoch:15 step:14147 [D loss: 0.638105, acc.: 59.38%] [G loss: 0.868936]\n",
      "epoch:15 step:14148 [D loss: 0.593089, acc.: 67.97%] [G loss: 1.026620]\n",
      "epoch:15 step:14149 [D loss: 0.614719, acc.: 64.06%] [G loss: 1.076241]\n",
      "epoch:15 step:14150 [D loss: 0.699008, acc.: 53.91%] [G loss: 0.967451]\n",
      "epoch:15 step:14151 [D loss: 0.849172, acc.: 36.72%] [G loss: 0.812198]\n",
      "epoch:15 step:14152 [D loss: 0.673065, acc.: 58.59%] [G loss: 1.069155]\n",
      "epoch:15 step:14153 [D loss: 0.649849, acc.: 65.62%] [G loss: 0.898684]\n",
      "epoch:15 step:14154 [D loss: 0.730382, acc.: 49.22%] [G loss: 0.895373]\n",
      "epoch:15 step:14155 [D loss: 0.606224, acc.: 67.97%] [G loss: 0.816516]\n",
      "epoch:15 step:14156 [D loss: 0.679261, acc.: 55.47%] [G loss: 0.944757]\n",
      "epoch:15 step:14157 [D loss: 0.610444, acc.: 71.88%] [G loss: 1.123384]\n",
      "epoch:15 step:14158 [D loss: 0.649081, acc.: 61.72%] [G loss: 0.939786]\n",
      "epoch:15 step:14159 [D loss: 0.733231, acc.: 53.91%] [G loss: 1.025159]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14160 [D loss: 0.656682, acc.: 55.47%] [G loss: 1.218369]\n",
      "epoch:15 step:14161 [D loss: 0.704930, acc.: 57.03%] [G loss: 0.863265]\n",
      "epoch:15 step:14162 [D loss: 0.718578, acc.: 54.69%] [G loss: 1.017919]\n",
      "epoch:15 step:14163 [D loss: 0.668274, acc.: 59.38%] [G loss: 1.129233]\n",
      "epoch:15 step:14164 [D loss: 0.674406, acc.: 59.38%] [G loss: 0.864322]\n",
      "epoch:15 step:14165 [D loss: 0.624459, acc.: 63.28%] [G loss: 0.823013]\n",
      "epoch:15 step:14166 [D loss: 0.565231, acc.: 72.66%] [G loss: 1.018540]\n",
      "epoch:15 step:14167 [D loss: 0.594101, acc.: 67.19%] [G loss: 0.991823]\n",
      "epoch:15 step:14168 [D loss: 0.586818, acc.: 71.88%] [G loss: 0.920163]\n",
      "epoch:15 step:14169 [D loss: 0.607132, acc.: 65.62%] [G loss: 0.842824]\n",
      "epoch:15 step:14170 [D loss: 0.620714, acc.: 66.41%] [G loss: 0.915982]\n",
      "epoch:15 step:14171 [D loss: 0.653894, acc.: 60.94%] [G loss: 0.993376]\n",
      "epoch:15 step:14172 [D loss: 0.717823, acc.: 54.69%] [G loss: 1.082266]\n",
      "epoch:15 step:14173 [D loss: 0.611460, acc.: 59.38%] [G loss: 0.929570]\n",
      "epoch:15 step:14174 [D loss: 0.439043, acc.: 86.72%] [G loss: 1.266230]\n",
      "epoch:15 step:14175 [D loss: 0.707476, acc.: 54.69%] [G loss: 0.886963]\n",
      "epoch:15 step:14176 [D loss: 0.689345, acc.: 57.03%] [G loss: 0.965134]\n",
      "epoch:15 step:14177 [D loss: 0.673650, acc.: 54.69%] [G loss: 1.028205]\n",
      "epoch:15 step:14178 [D loss: 0.695935, acc.: 51.56%] [G loss: 0.949093]\n",
      "epoch:15 step:14179 [D loss: 0.590678, acc.: 67.19%] [G loss: 1.021273]\n",
      "epoch:15 step:14180 [D loss: 0.642556, acc.: 58.59%] [G loss: 0.954748]\n",
      "epoch:15 step:14181 [D loss: 0.566756, acc.: 75.78%] [G loss: 1.027830]\n",
      "epoch:15 step:14182 [D loss: 0.676566, acc.: 56.25%] [G loss: 0.994409]\n",
      "epoch:15 step:14183 [D loss: 0.599259, acc.: 64.84%] [G loss: 0.871918]\n",
      "epoch:15 step:14184 [D loss: 0.721736, acc.: 53.91%] [G loss: 0.936421]\n",
      "epoch:15 step:14185 [D loss: 0.614635, acc.: 65.62%] [G loss: 0.970437]\n",
      "epoch:15 step:14186 [D loss: 0.606104, acc.: 71.09%] [G loss: 0.926296]\n",
      "epoch:15 step:14187 [D loss: 0.717416, acc.: 54.69%] [G loss: 0.870108]\n",
      "epoch:15 step:14188 [D loss: 0.708787, acc.: 57.81%] [G loss: 0.857845]\n",
      "epoch:15 step:14189 [D loss: 0.587514, acc.: 65.62%] [G loss: 1.186001]\n",
      "epoch:15 step:14190 [D loss: 0.589117, acc.: 67.97%] [G loss: 1.075009]\n",
      "epoch:15 step:14191 [D loss: 0.729233, acc.: 55.47%] [G loss: 0.966269]\n",
      "epoch:15 step:14192 [D loss: 0.738416, acc.: 47.66%] [G loss: 0.900173]\n",
      "epoch:15 step:14193 [D loss: 0.740216, acc.: 48.44%] [G loss: 0.922749]\n",
      "epoch:15 step:14194 [D loss: 0.691281, acc.: 57.81%] [G loss: 0.923691]\n",
      "epoch:15 step:14195 [D loss: 0.607245, acc.: 73.44%] [G loss: 0.983036]\n",
      "epoch:15 step:14196 [D loss: 0.576674, acc.: 73.44%] [G loss: 1.112738]\n",
      "epoch:15 step:14197 [D loss: 0.581458, acc.: 73.44%] [G loss: 0.930552]\n",
      "epoch:15 step:14198 [D loss: 0.563211, acc.: 75.78%] [G loss: 0.992530]\n",
      "epoch:15 step:14199 [D loss: 0.609912, acc.: 61.72%] [G loss: 1.080577]\n",
      "epoch:15 step:14200 [D loss: 0.617877, acc.: 71.09%] [G loss: 0.938269]\n",
      "##############\n",
      "[2.2667229  1.43071553 5.65280341 4.46961101 2.95503488 5.37685859\n",
      " 4.13488748 4.54223013 3.91001953 3.70332399]\n",
      "##########\n",
      "epoch:15 step:14201 [D loss: 0.666615, acc.: 57.03%] [G loss: 0.937975]\n",
      "epoch:15 step:14202 [D loss: 0.608081, acc.: 67.19%] [G loss: 0.892564]\n",
      "epoch:15 step:14203 [D loss: 0.750903, acc.: 53.12%] [G loss: 0.935347]\n",
      "epoch:15 step:14204 [D loss: 0.639790, acc.: 57.03%] [G loss: 1.092259]\n",
      "epoch:15 step:14205 [D loss: 0.552415, acc.: 74.22%] [G loss: 1.186571]\n",
      "epoch:15 step:14206 [D loss: 0.493502, acc.: 82.03%] [G loss: 1.219816]\n",
      "epoch:15 step:14207 [D loss: 0.422728, acc.: 86.72%] [G loss: 1.334754]\n",
      "epoch:15 step:14208 [D loss: 0.702798, acc.: 56.25%] [G loss: 1.064727]\n",
      "epoch:15 step:14209 [D loss: 0.833616, acc.: 42.97%] [G loss: 0.906416]\n",
      "epoch:15 step:14210 [D loss: 0.673617, acc.: 60.94%] [G loss: 0.991301]\n",
      "epoch:15 step:14211 [D loss: 0.635687, acc.: 60.16%] [G loss: 1.141570]\n",
      "epoch:15 step:14212 [D loss: 0.734940, acc.: 49.22%] [G loss: 0.944750]\n",
      "epoch:15 step:14213 [D loss: 0.622950, acc.: 67.97%] [G loss: 1.048482]\n",
      "epoch:15 step:14214 [D loss: 0.542319, acc.: 76.56%] [G loss: 0.912668]\n",
      "epoch:15 step:14215 [D loss: 0.685303, acc.: 54.69%] [G loss: 0.916502]\n",
      "epoch:15 step:14216 [D loss: 0.666983, acc.: 57.81%] [G loss: 1.059444]\n",
      "epoch:15 step:14217 [D loss: 0.532410, acc.: 80.47%] [G loss: 1.112326]\n",
      "epoch:15 step:14218 [D loss: 0.625166, acc.: 67.19%] [G loss: 0.857936]\n",
      "epoch:15 step:14219 [D loss: 0.621372, acc.: 64.06%] [G loss: 1.077028]\n",
      "epoch:15 step:14220 [D loss: 0.590892, acc.: 72.66%] [G loss: 0.982304]\n",
      "epoch:15 step:14221 [D loss: 0.642644, acc.: 63.28%] [G loss: 0.997689]\n",
      "epoch:15 step:14222 [D loss: 0.549353, acc.: 71.09%] [G loss: 0.900679]\n",
      "epoch:15 step:14223 [D loss: 0.544282, acc.: 75.00%] [G loss: 1.072082]\n",
      "epoch:15 step:14224 [D loss: 0.640702, acc.: 66.41%] [G loss: 0.928706]\n",
      "epoch:15 step:14225 [D loss: 0.652565, acc.: 55.47%] [G loss: 0.985263]\n",
      "epoch:15 step:14226 [D loss: 0.588914, acc.: 71.09%] [G loss: 1.153474]\n",
      "epoch:15 step:14227 [D loss: 0.688961, acc.: 57.81%] [G loss: 0.950181]\n",
      "epoch:15 step:14228 [D loss: 0.694255, acc.: 62.50%] [G loss: 0.915149]\n",
      "epoch:15 step:14229 [D loss: 0.710266, acc.: 53.12%] [G loss: 0.808498]\n",
      "epoch:15 step:14230 [D loss: 0.819219, acc.: 44.53%] [G loss: 0.921834]\n",
      "epoch:15 step:14231 [D loss: 0.593127, acc.: 70.31%] [G loss: 1.036163]\n",
      "epoch:15 step:14232 [D loss: 0.708816, acc.: 50.00%] [G loss: 1.004932]\n",
      "epoch:15 step:14233 [D loss: 0.662148, acc.: 59.38%] [G loss: 0.980222]\n",
      "epoch:15 step:14234 [D loss: 0.777322, acc.: 50.00%] [G loss: 0.931642]\n",
      "epoch:15 step:14235 [D loss: 0.639141, acc.: 60.16%] [G loss: 0.933883]\n",
      "epoch:15 step:14236 [D loss: 0.623200, acc.: 63.28%] [G loss: 0.945592]\n",
      "epoch:15 step:14237 [D loss: 0.628828, acc.: 60.94%] [G loss: 0.899199]\n",
      "epoch:15 step:14238 [D loss: 0.822757, acc.: 39.84%] [G loss: 0.917755]\n",
      "epoch:15 step:14239 [D loss: 0.762790, acc.: 46.88%] [G loss: 0.886976]\n",
      "epoch:15 step:14240 [D loss: 0.755467, acc.: 47.66%] [G loss: 1.036782]\n",
      "epoch:15 step:14241 [D loss: 0.766818, acc.: 50.00%] [G loss: 1.000744]\n",
      "epoch:15 step:14242 [D loss: 0.854845, acc.: 35.94%] [G loss: 0.847073]\n",
      "epoch:15 step:14243 [D loss: 0.632742, acc.: 66.41%] [G loss: 1.118547]\n",
      "epoch:15 step:14244 [D loss: 0.741979, acc.: 46.88%] [G loss: 0.990199]\n",
      "epoch:15 step:14245 [D loss: 0.678930, acc.: 57.03%] [G loss: 1.000551]\n",
      "epoch:15 step:14246 [D loss: 0.686599, acc.: 59.38%] [G loss: 0.877180]\n",
      "epoch:15 step:14247 [D loss: 0.546978, acc.: 75.78%] [G loss: 1.131639]\n",
      "epoch:15 step:14248 [D loss: 0.797755, acc.: 50.00%] [G loss: 0.933395]\n",
      "epoch:15 step:14249 [D loss: 0.678979, acc.: 62.50%] [G loss: 0.893890]\n",
      "epoch:15 step:14250 [D loss: 0.627791, acc.: 62.50%] [G loss: 1.042581]\n",
      "epoch:15 step:14251 [D loss: 0.789580, acc.: 45.31%] [G loss: 0.881958]\n",
      "epoch:15 step:14252 [D loss: 0.756774, acc.: 50.00%] [G loss: 0.798473]\n",
      "epoch:15 step:14253 [D loss: 0.760474, acc.: 47.66%] [G loss: 1.004293]\n",
      "epoch:15 step:14254 [D loss: 0.668396, acc.: 63.28%] [G loss: 0.981574]\n",
      "epoch:15 step:14255 [D loss: 0.658302, acc.: 56.25%] [G loss: 1.159737]\n",
      "epoch:15 step:14256 [D loss: 0.593111, acc.: 66.41%] [G loss: 1.162175]\n",
      "epoch:15 step:14257 [D loss: 0.736685, acc.: 50.78%] [G loss: 1.151848]\n",
      "epoch:15 step:14258 [D loss: 0.716246, acc.: 53.12%] [G loss: 1.031709]\n",
      "epoch:15 step:14259 [D loss: 0.644764, acc.: 64.06%] [G loss: 0.936827]\n",
      "epoch:15 step:14260 [D loss: 0.731853, acc.: 56.25%] [G loss: 0.914520]\n",
      "epoch:15 step:14261 [D loss: 0.684574, acc.: 53.91%] [G loss: 0.808494]\n",
      "epoch:15 step:14262 [D loss: 0.572882, acc.: 75.00%] [G loss: 0.897262]\n",
      "epoch:15 step:14263 [D loss: 0.552490, acc.: 75.78%] [G loss: 0.857569]\n",
      "epoch:15 step:14264 [D loss: 0.573470, acc.: 72.66%] [G loss: 0.874321]\n",
      "epoch:15 step:14265 [D loss: 0.708334, acc.: 53.12%] [G loss: 0.863156]\n",
      "epoch:15 step:14266 [D loss: 0.676958, acc.: 57.03%] [G loss: 0.914629]\n",
      "epoch:15 step:14267 [D loss: 0.640517, acc.: 61.72%] [G loss: 0.916341]\n",
      "epoch:15 step:14268 [D loss: 0.605573, acc.: 63.28%] [G loss: 1.043489]\n",
      "epoch:15 step:14269 [D loss: 0.736874, acc.: 48.44%] [G loss: 0.948127]\n",
      "epoch:15 step:14270 [D loss: 0.574315, acc.: 69.53%] [G loss: 1.038506]\n",
      "epoch:15 step:14271 [D loss: 0.652982, acc.: 60.94%] [G loss: 1.076409]\n",
      "epoch:15 step:14272 [D loss: 0.747907, acc.: 53.12%] [G loss: 0.934317]\n",
      "epoch:15 step:14273 [D loss: 0.826823, acc.: 38.28%] [G loss: 0.795743]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14274 [D loss: 0.705928, acc.: 53.91%] [G loss: 0.942896]\n",
      "epoch:15 step:14275 [D loss: 0.370651, acc.: 87.50%] [G loss: 1.089191]\n",
      "epoch:15 step:14276 [D loss: 0.419600, acc.: 90.62%] [G loss: 1.229003]\n",
      "epoch:15 step:14277 [D loss: 0.502007, acc.: 77.34%] [G loss: 1.177107]\n",
      "epoch:15 step:14278 [D loss: 0.378649, acc.: 85.94%] [G loss: 1.208664]\n",
      "epoch:15 step:14279 [D loss: 0.710987, acc.: 55.47%] [G loss: 1.289210]\n",
      "epoch:15 step:14280 [D loss: 0.877687, acc.: 40.62%] [G loss: 0.931564]\n",
      "epoch:15 step:14281 [D loss: 0.649452, acc.: 64.06%] [G loss: 0.963224]\n",
      "epoch:15 step:14282 [D loss: 0.842648, acc.: 40.62%] [G loss: 0.926004]\n",
      "epoch:15 step:14283 [D loss: 0.788444, acc.: 52.34%] [G loss: 0.974471]\n",
      "epoch:15 step:14284 [D loss: 0.688945, acc.: 55.47%] [G loss: 0.901472]\n",
      "epoch:15 step:14285 [D loss: 0.379572, acc.: 87.50%] [G loss: 1.043385]\n",
      "epoch:15 step:14286 [D loss: 0.443250, acc.: 80.47%] [G loss: 1.302964]\n",
      "epoch:15 step:14287 [D loss: 0.398200, acc.: 85.16%] [G loss: 1.134945]\n",
      "epoch:15 step:14288 [D loss: 0.706490, acc.: 59.38%] [G loss: 1.331812]\n",
      "epoch:15 step:14289 [D loss: 0.742877, acc.: 52.34%] [G loss: 1.110170]\n",
      "epoch:15 step:14290 [D loss: 0.697586, acc.: 57.03%] [G loss: 0.802847]\n",
      "epoch:15 step:14291 [D loss: 0.705271, acc.: 53.91%] [G loss: 0.956630]\n",
      "epoch:15 step:14292 [D loss: 0.641126, acc.: 59.38%] [G loss: 0.883659]\n",
      "epoch:15 step:14293 [D loss: 0.721560, acc.: 57.81%] [G loss: 0.914760]\n",
      "epoch:15 step:14294 [D loss: 0.692459, acc.: 59.38%] [G loss: 1.052502]\n",
      "epoch:15 step:14295 [D loss: 0.641287, acc.: 66.41%] [G loss: 0.994717]\n",
      "epoch:15 step:14296 [D loss: 0.658642, acc.: 60.16%] [G loss: 0.964264]\n",
      "epoch:15 step:14297 [D loss: 0.713240, acc.: 57.03%] [G loss: 1.022531]\n",
      "epoch:15 step:14298 [D loss: 0.643749, acc.: 63.28%] [G loss: 1.029058]\n",
      "epoch:15 step:14299 [D loss: 0.592892, acc.: 71.88%] [G loss: 0.976274]\n",
      "epoch:15 step:14300 [D loss: 0.668128, acc.: 58.59%] [G loss: 1.046011]\n",
      "epoch:15 step:14301 [D loss: 0.535941, acc.: 78.91%] [G loss: 0.995782]\n",
      "epoch:15 step:14302 [D loss: 0.663103, acc.: 57.81%] [G loss: 1.211565]\n",
      "epoch:15 step:14303 [D loss: 0.588553, acc.: 72.66%] [G loss: 1.108674]\n",
      "epoch:15 step:14304 [D loss: 0.733003, acc.: 56.25%] [G loss: 1.268566]\n",
      "epoch:15 step:14305 [D loss: 0.672792, acc.: 60.16%] [G loss: 0.970857]\n",
      "epoch:15 step:14306 [D loss: 0.687972, acc.: 57.03%] [G loss: 1.160916]\n",
      "epoch:15 step:14307 [D loss: 0.632652, acc.: 64.06%] [G loss: 1.012028]\n",
      "epoch:15 step:14308 [D loss: 0.642532, acc.: 64.06%] [G loss: 1.098920]\n",
      "epoch:15 step:14309 [D loss: 0.580593, acc.: 71.88%] [G loss: 0.999704]\n",
      "epoch:15 step:14310 [D loss: 0.683354, acc.: 59.38%] [G loss: 1.093367]\n",
      "epoch:15 step:14311 [D loss: 0.699475, acc.: 58.59%] [G loss: 1.062217]\n",
      "epoch:15 step:14312 [D loss: 0.694712, acc.: 57.81%] [G loss: 0.946164]\n",
      "epoch:15 step:14313 [D loss: 0.606562, acc.: 65.62%] [G loss: 0.935539]\n",
      "epoch:15 step:14314 [D loss: 0.615320, acc.: 67.19%] [G loss: 0.931040]\n",
      "epoch:15 step:14315 [D loss: 0.645855, acc.: 65.62%] [G loss: 0.927641]\n",
      "epoch:15 step:14316 [D loss: 0.695874, acc.: 56.25%] [G loss: 0.921095]\n",
      "epoch:15 step:14317 [D loss: 0.711830, acc.: 55.47%] [G loss: 0.906521]\n",
      "epoch:15 step:14318 [D loss: 0.741585, acc.: 57.81%] [G loss: 0.943538]\n",
      "epoch:15 step:14319 [D loss: 0.585548, acc.: 69.53%] [G loss: 0.957364]\n",
      "epoch:15 step:14320 [D loss: 0.679464, acc.: 59.38%] [G loss: 1.057529]\n",
      "epoch:15 step:14321 [D loss: 0.628938, acc.: 64.84%] [G loss: 1.036413]\n",
      "epoch:15 step:14322 [D loss: 0.598680, acc.: 64.06%] [G loss: 1.014067]\n",
      "epoch:15 step:14323 [D loss: 0.683724, acc.: 59.38%] [G loss: 0.900262]\n",
      "epoch:15 step:14324 [D loss: 0.715971, acc.: 50.00%] [G loss: 1.019936]\n",
      "epoch:15 step:14325 [D loss: 0.718812, acc.: 51.56%] [G loss: 1.013637]\n",
      "epoch:15 step:14326 [D loss: 0.717504, acc.: 56.25%] [G loss: 1.027407]\n",
      "epoch:15 step:14327 [D loss: 0.579539, acc.: 70.31%] [G loss: 1.062918]\n",
      "epoch:15 step:14328 [D loss: 0.598194, acc.: 68.75%] [G loss: 0.965524]\n",
      "epoch:15 step:14329 [D loss: 0.590998, acc.: 76.56%] [G loss: 1.005612]\n",
      "epoch:15 step:14330 [D loss: 0.605337, acc.: 64.06%] [G loss: 1.035034]\n",
      "epoch:15 step:14331 [D loss: 0.706330, acc.: 54.69%] [G loss: 0.908077]\n",
      "epoch:15 step:14332 [D loss: 0.728905, acc.: 46.09%] [G loss: 0.804649]\n",
      "epoch:15 step:14333 [D loss: 0.630512, acc.: 64.84%] [G loss: 0.945515]\n",
      "epoch:15 step:14334 [D loss: 0.582601, acc.: 69.53%] [G loss: 1.057709]\n",
      "epoch:15 step:14335 [D loss: 0.579274, acc.: 68.75%] [G loss: 0.979909]\n",
      "epoch:15 step:14336 [D loss: 0.731313, acc.: 52.34%] [G loss: 0.990324]\n",
      "epoch:15 step:14337 [D loss: 0.624283, acc.: 64.06%] [G loss: 1.008117]\n",
      "epoch:15 step:14338 [D loss: 0.603005, acc.: 68.75%] [G loss: 1.053209]\n",
      "epoch:15 step:14339 [D loss: 0.591986, acc.: 67.19%] [G loss: 1.011678]\n",
      "epoch:15 step:14340 [D loss: 0.520244, acc.: 78.12%] [G loss: 1.092254]\n",
      "epoch:15 step:14341 [D loss: 0.586360, acc.: 72.66%] [G loss: 0.955349]\n",
      "epoch:15 step:14342 [D loss: 0.548343, acc.: 79.69%] [G loss: 1.065491]\n",
      "epoch:15 step:14343 [D loss: 0.641562, acc.: 63.28%] [G loss: 1.017801]\n",
      "epoch:15 step:14344 [D loss: 0.601181, acc.: 64.84%] [G loss: 1.110407]\n",
      "epoch:15 step:14345 [D loss: 0.593560, acc.: 67.19%] [G loss: 1.231768]\n",
      "epoch:15 step:14346 [D loss: 0.539418, acc.: 73.44%] [G loss: 1.173755]\n",
      "epoch:15 step:14347 [D loss: 0.511441, acc.: 77.34%] [G loss: 1.126088]\n",
      "epoch:15 step:14348 [D loss: 0.630699, acc.: 60.94%] [G loss: 1.004077]\n",
      "epoch:15 step:14349 [D loss: 0.639092, acc.: 61.72%] [G loss: 0.856500]\n",
      "epoch:15 step:14350 [D loss: 0.729782, acc.: 53.12%] [G loss: 1.020133]\n",
      "epoch:15 step:14351 [D loss: 0.731310, acc.: 52.34%] [G loss: 0.969061]\n",
      "epoch:15 step:14352 [D loss: 0.804801, acc.: 46.09%] [G loss: 1.033523]\n",
      "epoch:15 step:14353 [D loss: 0.623846, acc.: 61.72%] [G loss: 1.060911]\n",
      "epoch:15 step:14354 [D loss: 0.572315, acc.: 71.09%] [G loss: 1.178260]\n",
      "epoch:15 step:14355 [D loss: 0.514253, acc.: 76.56%] [G loss: 1.109591]\n",
      "epoch:15 step:14356 [D loss: 0.680822, acc.: 57.81%] [G loss: 0.913477]\n",
      "epoch:15 step:14357 [D loss: 0.619012, acc.: 62.50%] [G loss: 1.015850]\n",
      "epoch:15 step:14358 [D loss: 0.726939, acc.: 53.12%] [G loss: 1.021647]\n",
      "epoch:15 step:14359 [D loss: 0.548095, acc.: 75.78%] [G loss: 0.905963]\n",
      "epoch:15 step:14360 [D loss: 0.707649, acc.: 52.34%] [G loss: 0.816535]\n",
      "epoch:15 step:14361 [D loss: 0.636120, acc.: 64.06%] [G loss: 0.904058]\n",
      "epoch:15 step:14362 [D loss: 0.592772, acc.: 72.66%] [G loss: 0.967242]\n",
      "epoch:15 step:14363 [D loss: 0.641723, acc.: 63.28%] [G loss: 1.127794]\n",
      "epoch:15 step:14364 [D loss: 0.597830, acc.: 72.66%] [G loss: 1.078440]\n",
      "epoch:15 step:14365 [D loss: 0.613022, acc.: 67.19%] [G loss: 1.044330]\n",
      "epoch:15 step:14366 [D loss: 0.560788, acc.: 71.09%] [G loss: 0.949656]\n",
      "epoch:15 step:14367 [D loss: 0.552173, acc.: 74.22%] [G loss: 1.022096]\n",
      "epoch:15 step:14368 [D loss: 0.516183, acc.: 75.00%] [G loss: 0.962649]\n",
      "epoch:15 step:14369 [D loss: 0.512315, acc.: 82.03%] [G loss: 1.106714]\n",
      "epoch:15 step:14370 [D loss: 0.563825, acc.: 69.53%] [G loss: 1.200716]\n",
      "epoch:15 step:14371 [D loss: 0.849338, acc.: 40.62%] [G loss: 0.916845]\n",
      "epoch:15 step:14372 [D loss: 0.712030, acc.: 54.69%] [G loss: 1.020898]\n",
      "epoch:15 step:14373 [D loss: 0.574221, acc.: 67.97%] [G loss: 1.183239]\n",
      "epoch:15 step:14374 [D loss: 0.726186, acc.: 51.56%] [G loss: 0.971793]\n",
      "epoch:15 step:14375 [D loss: 0.631468, acc.: 60.94%] [G loss: 1.079656]\n",
      "epoch:15 step:14376 [D loss: 0.659706, acc.: 58.59%] [G loss: 0.822446]\n",
      "epoch:15 step:14377 [D loss: 0.625126, acc.: 66.41%] [G loss: 1.062471]\n",
      "epoch:15 step:14378 [D loss: 0.695697, acc.: 56.25%] [G loss: 1.077345]\n",
      "epoch:15 step:14379 [D loss: 0.679255, acc.: 56.25%] [G loss: 0.947946]\n",
      "epoch:15 step:14380 [D loss: 0.588311, acc.: 68.75%] [G loss: 0.828766]\n",
      "epoch:15 step:14381 [D loss: 0.702784, acc.: 58.59%] [G loss: 0.871333]\n",
      "epoch:15 step:14382 [D loss: 0.560577, acc.: 75.00%] [G loss: 1.007387]\n",
      "epoch:15 step:14383 [D loss: 0.518615, acc.: 78.12%] [G loss: 1.095353]\n",
      "epoch:15 step:14384 [D loss: 0.654837, acc.: 59.38%] [G loss: 1.116601]\n",
      "epoch:15 step:14385 [D loss: 0.684771, acc.: 57.81%] [G loss: 0.964152]\n",
      "epoch:15 step:14386 [D loss: 0.716282, acc.: 49.22%] [G loss: 0.989213]\n",
      "epoch:15 step:14387 [D loss: 0.582469, acc.: 71.88%] [G loss: 1.084610]\n",
      "epoch:15 step:14388 [D loss: 0.621345, acc.: 64.06%] [G loss: 0.904057]\n",
      "epoch:15 step:14389 [D loss: 0.720967, acc.: 50.00%] [G loss: 0.830749]\n",
      "epoch:15 step:14390 [D loss: 0.670376, acc.: 60.16%] [G loss: 1.057350]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14391 [D loss: 0.583994, acc.: 71.88%] [G loss: 1.003705]\n",
      "epoch:15 step:14392 [D loss: 0.680567, acc.: 58.59%] [G loss: 0.925275]\n",
      "epoch:15 step:14393 [D loss: 0.685248, acc.: 49.22%] [G loss: 0.862234]\n",
      "epoch:15 step:14394 [D loss: 0.646201, acc.: 67.97%] [G loss: 1.094496]\n",
      "epoch:15 step:14395 [D loss: 0.648969, acc.: 64.84%] [G loss: 0.992490]\n",
      "epoch:15 step:14396 [D loss: 0.658491, acc.: 60.94%] [G loss: 1.027714]\n",
      "epoch:15 step:14397 [D loss: 0.589881, acc.: 71.09%] [G loss: 0.938104]\n",
      "epoch:15 step:14398 [D loss: 0.486070, acc.: 82.81%] [G loss: 0.964704]\n",
      "epoch:15 step:14399 [D loss: 0.605785, acc.: 68.75%] [G loss: 0.866584]\n",
      "epoch:15 step:14400 [D loss: 0.521418, acc.: 74.22%] [G loss: 1.066600]\n",
      "##############\n",
      "[2.14990054 1.53307474 5.16086234 4.23608576 2.9604598  5.29075471\n",
      " 4.04284128 4.36547265 3.63210809 3.3064418 ]\n",
      "##########\n",
      "epoch:15 step:14401 [D loss: 0.408063, acc.: 90.62%] [G loss: 1.342445]\n",
      "epoch:15 step:14402 [D loss: 0.422092, acc.: 79.69%] [G loss: 1.176530]\n",
      "epoch:15 step:14403 [D loss: 0.702625, acc.: 60.16%] [G loss: 1.180740]\n",
      "epoch:15 step:14404 [D loss: 0.791149, acc.: 45.31%] [G loss: 1.004041]\n",
      "epoch:15 step:14405 [D loss: 0.759892, acc.: 53.91%] [G loss: 0.784535]\n",
      "epoch:15 step:14406 [D loss: 0.719642, acc.: 50.78%] [G loss: 1.011310]\n",
      "epoch:15 step:14407 [D loss: 0.620710, acc.: 67.19%] [G loss: 0.946009]\n",
      "epoch:15 step:14408 [D loss: 0.573191, acc.: 70.31%] [G loss: 0.950155]\n",
      "epoch:15 step:14409 [D loss: 0.515313, acc.: 75.78%] [G loss: 1.204416]\n",
      "epoch:15 step:14410 [D loss: 0.641875, acc.: 57.81%] [G loss: 1.002301]\n",
      "epoch:15 step:14411 [D loss: 0.676584, acc.: 53.12%] [G loss: 0.878093]\n",
      "epoch:15 step:14412 [D loss: 0.671589, acc.: 57.81%] [G loss: 0.841937]\n",
      "epoch:15 step:14413 [D loss: 0.491454, acc.: 82.03%] [G loss: 1.131892]\n",
      "epoch:15 step:14414 [D loss: 0.515563, acc.: 79.69%] [G loss: 1.207762]\n",
      "epoch:15 step:14415 [D loss: 0.691188, acc.: 56.25%] [G loss: 0.932518]\n",
      "epoch:15 step:14416 [D loss: 0.626268, acc.: 65.62%] [G loss: 0.987770]\n",
      "epoch:15 step:14417 [D loss: 0.698517, acc.: 52.34%] [G loss: 1.001956]\n",
      "epoch:15 step:14418 [D loss: 0.647483, acc.: 64.06%] [G loss: 1.074880]\n",
      "epoch:15 step:14419 [D loss: 0.691167, acc.: 55.47%] [G loss: 0.824792]\n",
      "epoch:15 step:14420 [D loss: 0.672789, acc.: 61.72%] [G loss: 1.065784]\n",
      "epoch:15 step:14421 [D loss: 0.475133, acc.: 80.47%] [G loss: 1.112499]\n",
      "epoch:15 step:14422 [D loss: 0.531558, acc.: 79.69%] [G loss: 1.228134]\n",
      "epoch:15 step:14423 [D loss: 0.736156, acc.: 54.69%] [G loss: 1.132596]\n",
      "epoch:15 step:14424 [D loss: 0.693008, acc.: 57.81%] [G loss: 1.152366]\n",
      "epoch:15 step:14425 [D loss: 0.666827, acc.: 58.59%] [G loss: 0.929847]\n",
      "epoch:15 step:14426 [D loss: 0.630355, acc.: 61.72%] [G loss: 0.964487]\n",
      "epoch:15 step:14427 [D loss: 0.683363, acc.: 56.25%] [G loss: 1.071993]\n",
      "epoch:15 step:14428 [D loss: 0.808451, acc.: 40.62%] [G loss: 0.864130]\n",
      "epoch:15 step:14429 [D loss: 0.704465, acc.: 57.03%] [G loss: 0.792795]\n",
      "epoch:15 step:14430 [D loss: 0.743848, acc.: 42.19%] [G loss: 0.838494]\n",
      "epoch:15 step:14431 [D loss: 0.719004, acc.: 50.78%] [G loss: 0.896236]\n",
      "epoch:15 step:14432 [D loss: 0.673398, acc.: 61.72%] [G loss: 0.993162]\n",
      "epoch:15 step:14433 [D loss: 0.572789, acc.: 71.09%] [G loss: 1.118510]\n",
      "epoch:15 step:14434 [D loss: 0.710432, acc.: 53.91%] [G loss: 0.878110]\n",
      "epoch:15 step:14435 [D loss: 0.764256, acc.: 46.88%] [G loss: 0.938435]\n",
      "epoch:15 step:14436 [D loss: 0.515603, acc.: 78.12%] [G loss: 0.997186]\n",
      "epoch:15 step:14437 [D loss: 0.756010, acc.: 50.78%] [G loss: 0.854195]\n",
      "epoch:15 step:14438 [D loss: 0.709056, acc.: 55.47%] [G loss: 0.880868]\n",
      "epoch:15 step:14439 [D loss: 0.607807, acc.: 66.41%] [G loss: 0.903524]\n",
      "epoch:15 step:14440 [D loss: 0.666735, acc.: 56.25%] [G loss: 1.113709]\n",
      "epoch:15 step:14441 [D loss: 0.657192, acc.: 57.03%] [G loss: 0.997681]\n",
      "epoch:15 step:14442 [D loss: 0.660179, acc.: 62.50%] [G loss: 0.761075]\n",
      "epoch:15 step:14443 [D loss: 0.652340, acc.: 57.03%] [G loss: 0.870887]\n",
      "epoch:15 step:14444 [D loss: 0.730978, acc.: 49.22%] [G loss: 0.954231]\n",
      "epoch:15 step:14445 [D loss: 0.548767, acc.: 82.03%] [G loss: 1.014486]\n",
      "epoch:15 step:14446 [D loss: 0.600175, acc.: 71.88%] [G loss: 0.962234]\n",
      "epoch:15 step:14447 [D loss: 0.548345, acc.: 74.22%] [G loss: 1.252690]\n",
      "epoch:15 step:14448 [D loss: 0.718767, acc.: 58.59%] [G loss: 0.883565]\n",
      "epoch:15 step:14449 [D loss: 0.585269, acc.: 67.19%] [G loss: 0.929575]\n",
      "epoch:15 step:14450 [D loss: 0.689484, acc.: 55.47%] [G loss: 0.961988]\n",
      "epoch:15 step:14451 [D loss: 0.545439, acc.: 75.78%] [G loss: 0.943459]\n",
      "epoch:15 step:14452 [D loss: 0.459000, acc.: 81.25%] [G loss: 1.010258]\n",
      "epoch:15 step:14453 [D loss: 0.440072, acc.: 86.72%] [G loss: 1.163770]\n",
      "epoch:15 step:14454 [D loss: 0.467442, acc.: 84.38%] [G loss: 1.180483]\n",
      "epoch:15 step:14455 [D loss: 0.472130, acc.: 82.81%] [G loss: 1.097496]\n",
      "epoch:15 step:14456 [D loss: 0.540940, acc.: 73.44%] [G loss: 1.036967]\n",
      "epoch:15 step:14457 [D loss: 0.455300, acc.: 81.25%] [G loss: 1.226243]\n",
      "epoch:15 step:14458 [D loss: 0.728198, acc.: 53.12%] [G loss: 0.972872]\n",
      "epoch:15 step:14459 [D loss: 0.650172, acc.: 60.94%] [G loss: 1.103675]\n",
      "epoch:15 step:14460 [D loss: 0.445870, acc.: 86.72%] [G loss: 1.353819]\n",
      "epoch:15 step:14461 [D loss: 0.557444, acc.: 69.53%] [G loss: 1.345031]\n",
      "epoch:15 step:14462 [D loss: 0.642510, acc.: 70.31%] [G loss: 0.956266]\n",
      "epoch:15 step:14463 [D loss: 0.851115, acc.: 44.53%] [G loss: 0.869302]\n",
      "epoch:15 step:14464 [D loss: 0.581101, acc.: 67.19%] [G loss: 1.155267]\n",
      "epoch:15 step:14465 [D loss: 0.775644, acc.: 45.31%] [G loss: 0.769768]\n",
      "epoch:15 step:14466 [D loss: 0.832288, acc.: 44.53%] [G loss: 0.912900]\n",
      "epoch:15 step:14467 [D loss: 0.791396, acc.: 40.62%] [G loss: 0.896507]\n",
      "epoch:15 step:14468 [D loss: 0.822752, acc.: 37.50%] [G loss: 1.001973]\n",
      "epoch:15 step:14469 [D loss: 0.836706, acc.: 36.72%] [G loss: 0.871318]\n",
      "epoch:15 step:14470 [D loss: 0.889042, acc.: 37.50%] [G loss: 0.985085]\n",
      "epoch:15 step:14471 [D loss: 0.600092, acc.: 62.50%] [G loss: 0.879898]\n",
      "epoch:15 step:14472 [D loss: 0.965452, acc.: 28.91%] [G loss: 0.862763]\n",
      "epoch:15 step:14473 [D loss: 0.676484, acc.: 57.03%] [G loss: 0.772398]\n",
      "epoch:15 step:14474 [D loss: 0.635980, acc.: 64.84%] [G loss: 1.056627]\n",
      "epoch:15 step:14475 [D loss: 0.665887, acc.: 57.03%] [G loss: 1.031325]\n",
      "epoch:15 step:14476 [D loss: 0.727034, acc.: 50.00%] [G loss: 0.981728]\n",
      "epoch:15 step:14477 [D loss: 0.731005, acc.: 56.25%] [G loss: 0.991270]\n",
      "epoch:15 step:14478 [D loss: 0.698292, acc.: 53.91%] [G loss: 1.111209]\n",
      "epoch:15 step:14479 [D loss: 0.679333, acc.: 57.03%] [G loss: 0.869174]\n",
      "epoch:15 step:14480 [D loss: 0.744718, acc.: 49.22%] [G loss: 0.927426]\n",
      "epoch:15 step:14481 [D loss: 0.717773, acc.: 57.81%] [G loss: 1.023836]\n",
      "epoch:15 step:14482 [D loss: 0.615243, acc.: 67.19%] [G loss: 0.986714]\n",
      "epoch:15 step:14483 [D loss: 0.679968, acc.: 54.69%] [G loss: 1.106351]\n",
      "epoch:15 step:14484 [D loss: 0.726419, acc.: 49.22%] [G loss: 0.996625]\n",
      "epoch:15 step:14485 [D loss: 0.624696, acc.: 67.19%] [G loss: 1.010521]\n",
      "epoch:15 step:14486 [D loss: 0.623782, acc.: 63.28%] [G loss: 1.098977]\n",
      "epoch:15 step:14487 [D loss: 0.642664, acc.: 61.72%] [G loss: 0.848511]\n",
      "epoch:15 step:14488 [D loss: 0.615515, acc.: 65.62%] [G loss: 1.096175]\n",
      "epoch:15 step:14489 [D loss: 0.645853, acc.: 62.50%] [G loss: 1.081109]\n",
      "epoch:15 step:14490 [D loss: 0.523985, acc.: 74.22%] [G loss: 1.195867]\n",
      "epoch:15 step:14491 [D loss: 0.530192, acc.: 76.56%] [G loss: 1.236696]\n",
      "epoch:15 step:14492 [D loss: 0.724326, acc.: 53.12%] [G loss: 1.057076]\n",
      "epoch:15 step:14493 [D loss: 0.683929, acc.: 53.12%] [G loss: 0.892516]\n",
      "epoch:15 step:14494 [D loss: 0.695888, acc.: 55.47%] [G loss: 0.889219]\n",
      "epoch:15 step:14495 [D loss: 0.722459, acc.: 54.69%] [G loss: 0.960603]\n",
      "epoch:15 step:14496 [D loss: 0.608557, acc.: 64.84%] [G loss: 1.035598]\n",
      "epoch:15 step:14497 [D loss: 0.642138, acc.: 60.16%] [G loss: 0.963800]\n",
      "epoch:15 step:14498 [D loss: 0.537196, acc.: 71.09%] [G loss: 1.054935]\n",
      "epoch:15 step:14499 [D loss: 0.625100, acc.: 63.28%] [G loss: 0.920367]\n",
      "epoch:15 step:14500 [D loss: 0.689749, acc.: 57.03%] [G loss: 1.095454]\n",
      "epoch:15 step:14501 [D loss: 0.706086, acc.: 54.69%] [G loss: 0.861957]\n",
      "epoch:15 step:14502 [D loss: 0.630222, acc.: 62.50%] [G loss: 1.060041]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14503 [D loss: 0.538167, acc.: 75.78%] [G loss: 1.165931]\n",
      "epoch:15 step:14504 [D loss: 0.399679, acc.: 88.28%] [G loss: 1.079231]\n",
      "epoch:15 step:14505 [D loss: 0.554122, acc.: 71.88%] [G loss: 1.149032]\n",
      "epoch:15 step:14506 [D loss: 0.468876, acc.: 79.69%] [G loss: 1.280591]\n",
      "epoch:15 step:14507 [D loss: 0.488829, acc.: 80.47%] [G loss: 1.636001]\n",
      "epoch:15 step:14508 [D loss: 0.459348, acc.: 81.25%] [G loss: 1.366139]\n",
      "epoch:15 step:14509 [D loss: 0.504234, acc.: 78.12%] [G loss: 1.357736]\n",
      "epoch:15 step:14510 [D loss: 0.581562, acc.: 70.31%] [G loss: 1.137314]\n",
      "epoch:15 step:14511 [D loss: 0.562583, acc.: 72.66%] [G loss: 1.152270]\n",
      "epoch:15 step:14512 [D loss: 0.535810, acc.: 70.31%] [G loss: 1.352904]\n",
      "epoch:15 step:14513 [D loss: 1.063910, acc.: 31.25%] [G loss: 1.022192]\n",
      "epoch:15 step:14514 [D loss: 0.890442, acc.: 35.94%] [G loss: 1.111262]\n",
      "epoch:15 step:14515 [D loss: 0.769257, acc.: 49.22%] [G loss: 1.216425]\n",
      "epoch:15 step:14516 [D loss: 0.783077, acc.: 41.41%] [G loss: 1.314420]\n",
      "epoch:15 step:14517 [D loss: 0.775024, acc.: 46.88%] [G loss: 1.267391]\n",
      "epoch:15 step:14518 [D loss: 0.786695, acc.: 42.19%] [G loss: 1.254026]\n",
      "epoch:15 step:14519 [D loss: 0.675920, acc.: 56.25%] [G loss: 1.182040]\n",
      "epoch:15 step:14520 [D loss: 0.679265, acc.: 57.03%] [G loss: 0.983691]\n",
      "epoch:15 step:14521 [D loss: 0.692723, acc.: 58.59%] [G loss: 0.908225]\n",
      "epoch:15 step:14522 [D loss: 0.662646, acc.: 60.16%] [G loss: 1.029229]\n",
      "epoch:15 step:14523 [D loss: 0.654756, acc.: 57.81%] [G loss: 0.988103]\n",
      "epoch:15 step:14524 [D loss: 0.661150, acc.: 67.19%] [G loss: 1.171279]\n",
      "epoch:15 step:14525 [D loss: 0.580725, acc.: 71.09%] [G loss: 1.052901]\n",
      "epoch:15 step:14526 [D loss: 0.410955, acc.: 85.94%] [G loss: 1.133659]\n",
      "epoch:15 step:14527 [D loss: 0.597539, acc.: 68.75%] [G loss: 1.162791]\n",
      "epoch:15 step:14528 [D loss: 0.629314, acc.: 63.28%] [G loss: 1.143340]\n",
      "epoch:15 step:14529 [D loss: 0.562278, acc.: 68.75%] [G loss: 1.095912]\n",
      "epoch:15 step:14530 [D loss: 0.539319, acc.: 77.34%] [G loss: 1.139204]\n",
      "epoch:15 step:14531 [D loss: 0.760385, acc.: 53.91%] [G loss: 1.071921]\n",
      "epoch:15 step:14532 [D loss: 0.716730, acc.: 55.47%] [G loss: 1.010510]\n",
      "epoch:15 step:14533 [D loss: 0.706442, acc.: 57.03%] [G loss: 0.900206]\n",
      "epoch:15 step:14534 [D loss: 0.591253, acc.: 71.88%] [G loss: 0.767871]\n",
      "epoch:15 step:14535 [D loss: 0.696792, acc.: 56.25%] [G loss: 0.917682]\n",
      "epoch:15 step:14536 [D loss: 0.701610, acc.: 57.03%] [G loss: 0.749803]\n",
      "epoch:15 step:14537 [D loss: 0.649944, acc.: 63.28%] [G loss: 0.862710]\n",
      "epoch:15 step:14538 [D loss: 0.679024, acc.: 60.94%] [G loss: 1.127952]\n",
      "epoch:15 step:14539 [D loss: 0.545111, acc.: 76.56%] [G loss: 1.093312]\n",
      "epoch:15 step:14540 [D loss: 0.617565, acc.: 66.41%] [G loss: 1.067023]\n",
      "epoch:15 step:14541 [D loss: 0.720701, acc.: 53.91%] [G loss: 1.085407]\n",
      "epoch:15 step:14542 [D loss: 0.584174, acc.: 71.88%] [G loss: 1.188097]\n",
      "epoch:15 step:14543 [D loss: 0.755500, acc.: 51.56%] [G loss: 1.041599]\n",
      "epoch:15 step:14544 [D loss: 0.666044, acc.: 57.03%] [G loss: 1.101656]\n",
      "epoch:15 step:14545 [D loss: 0.579354, acc.: 67.19%] [G loss: 1.149323]\n",
      "epoch:15 step:14546 [D loss: 0.548650, acc.: 75.78%] [G loss: 0.933737]\n",
      "epoch:15 step:14547 [D loss: 0.669690, acc.: 62.50%] [G loss: 0.948507]\n",
      "epoch:15 step:14548 [D loss: 0.755048, acc.: 51.56%] [G loss: 0.976661]\n",
      "epoch:15 step:14549 [D loss: 0.659649, acc.: 58.59%] [G loss: 0.884902]\n",
      "epoch:15 step:14550 [D loss: 0.666529, acc.: 57.03%] [G loss: 0.977809]\n",
      "epoch:15 step:14551 [D loss: 0.667032, acc.: 58.59%] [G loss: 1.071209]\n",
      "epoch:15 step:14552 [D loss: 0.702705, acc.: 61.72%] [G loss: 1.052471]\n",
      "epoch:15 step:14553 [D loss: 0.618280, acc.: 66.41%] [G loss: 0.942255]\n",
      "epoch:15 step:14554 [D loss: 0.501106, acc.: 77.34%] [G loss: 0.918396]\n",
      "epoch:15 step:14555 [D loss: 0.653682, acc.: 63.28%] [G loss: 1.091119]\n",
      "epoch:15 step:14556 [D loss: 0.760652, acc.: 44.53%] [G loss: 1.018930]\n",
      "epoch:15 step:14557 [D loss: 0.669377, acc.: 54.69%] [G loss: 0.968817]\n",
      "epoch:15 step:14558 [D loss: 0.523259, acc.: 75.00%] [G loss: 1.041977]\n",
      "epoch:15 step:14559 [D loss: 0.451398, acc.: 82.81%] [G loss: 1.014875]\n",
      "epoch:15 step:14560 [D loss: 0.569770, acc.: 71.09%] [G loss: 1.102073]\n",
      "epoch:15 step:14561 [D loss: 0.624096, acc.: 65.62%] [G loss: 1.093596]\n",
      "epoch:15 step:14562 [D loss: 0.632112, acc.: 64.84%] [G loss: 0.946151]\n",
      "epoch:15 step:14563 [D loss: 0.463494, acc.: 82.03%] [G loss: 0.912250]\n",
      "epoch:15 step:14564 [D loss: 0.819692, acc.: 39.06%] [G loss: 1.062283]\n",
      "epoch:15 step:14565 [D loss: 0.846453, acc.: 29.69%] [G loss: 0.947647]\n",
      "epoch:15 step:14566 [D loss: 0.663679, acc.: 60.94%] [G loss: 1.093532]\n",
      "epoch:15 step:14567 [D loss: 0.659669, acc.: 63.28%] [G loss: 0.901644]\n",
      "epoch:15 step:14568 [D loss: 0.602325, acc.: 67.19%] [G loss: 1.186437]\n",
      "epoch:15 step:14569 [D loss: 0.614530, acc.: 71.09%] [G loss: 1.052220]\n",
      "epoch:15 step:14570 [D loss: 0.530165, acc.: 76.56%] [G loss: 1.259640]\n",
      "epoch:15 step:14571 [D loss: 0.576588, acc.: 71.09%] [G loss: 1.046240]\n",
      "epoch:15 step:14572 [D loss: 0.638946, acc.: 66.41%] [G loss: 0.955053]\n",
      "epoch:15 step:14573 [D loss: 0.685699, acc.: 56.25%] [G loss: 0.905675]\n",
      "epoch:15 step:14574 [D loss: 0.622336, acc.: 63.28%] [G loss: 0.839008]\n",
      "epoch:15 step:14575 [D loss: 0.584779, acc.: 72.66%] [G loss: 0.911404]\n",
      "epoch:15 step:14576 [D loss: 0.612749, acc.: 70.31%] [G loss: 0.952034]\n",
      "epoch:15 step:14577 [D loss: 0.622400, acc.: 67.97%] [G loss: 0.883670]\n",
      "epoch:15 step:14578 [D loss: 0.582523, acc.: 66.41%] [G loss: 1.153786]\n",
      "epoch:15 step:14579 [D loss: 0.637627, acc.: 60.94%] [G loss: 1.175257]\n",
      "epoch:15 step:14580 [D loss: 0.628758, acc.: 64.06%] [G loss: 0.967814]\n",
      "epoch:15 step:14581 [D loss: 0.638025, acc.: 67.19%] [G loss: 1.011138]\n",
      "epoch:15 step:14582 [D loss: 0.579017, acc.: 68.75%] [G loss: 1.076382]\n",
      "epoch:15 step:14583 [D loss: 0.735644, acc.: 52.34%] [G loss: 0.990264]\n",
      "epoch:15 step:14584 [D loss: 0.683558, acc.: 57.03%] [G loss: 0.860009]\n",
      "epoch:15 step:14585 [D loss: 0.595354, acc.: 64.06%] [G loss: 0.956800]\n",
      "epoch:15 step:14586 [D loss: 0.684649, acc.: 57.03%] [G loss: 0.995241]\n",
      "epoch:15 step:14587 [D loss: 0.588603, acc.: 71.09%] [G loss: 0.971319]\n",
      "epoch:15 step:14588 [D loss: 0.535477, acc.: 74.22%] [G loss: 1.052196]\n",
      "epoch:15 step:14589 [D loss: 0.575882, acc.: 71.09%] [G loss: 1.242039]\n",
      "epoch:15 step:14590 [D loss: 0.606773, acc.: 66.41%] [G loss: 0.889941]\n",
      "epoch:15 step:14591 [D loss: 0.591103, acc.: 68.75%] [G loss: 0.953880]\n",
      "epoch:15 step:14592 [D loss: 0.505712, acc.: 80.47%] [G loss: 1.132255]\n",
      "epoch:15 step:14593 [D loss: 0.677193, acc.: 56.25%] [G loss: 1.051342]\n",
      "epoch:15 step:14594 [D loss: 0.615579, acc.: 69.53%] [G loss: 1.054289]\n",
      "epoch:15 step:14595 [D loss: 0.718545, acc.: 57.03%] [G loss: 1.033181]\n",
      "epoch:15 step:14596 [D loss: 0.709484, acc.: 49.22%] [G loss: 0.814303]\n",
      "epoch:15 step:14597 [D loss: 0.870999, acc.: 35.16%] [G loss: 0.948241]\n",
      "epoch:15 step:14598 [D loss: 0.707034, acc.: 57.81%] [G loss: 0.924386]\n",
      "epoch:15 step:14599 [D loss: 0.580370, acc.: 69.53%] [G loss: 1.016607]\n",
      "epoch:15 step:14600 [D loss: 0.501296, acc.: 76.56%] [G loss: 1.109472]\n",
      "##############\n",
      "[2.18412073 1.29839784 5.32602121 4.48914194 2.9454155  5.51030287\n",
      " 3.99403205 4.27484603 3.7183549  3.70637209]\n",
      "##########\n",
      "epoch:15 step:14601 [D loss: 0.543395, acc.: 74.22%] [G loss: 1.184874]\n",
      "epoch:15 step:14602 [D loss: 0.507204, acc.: 75.78%] [G loss: 1.218259]\n",
      "epoch:15 step:14603 [D loss: 0.616776, acc.: 68.75%] [G loss: 0.958075]\n",
      "epoch:15 step:14604 [D loss: 0.483889, acc.: 76.56%] [G loss: 1.013492]\n",
      "epoch:15 step:14605 [D loss: 0.460685, acc.: 85.94%] [G loss: 1.357405]\n",
      "epoch:15 step:14606 [D loss: 0.434878, acc.: 87.50%] [G loss: 1.380793]\n",
      "epoch:15 step:14607 [D loss: 0.502593, acc.: 78.91%] [G loss: 1.108329]\n",
      "epoch:15 step:14608 [D loss: 0.499248, acc.: 82.81%] [G loss: 1.248226]\n",
      "epoch:15 step:14609 [D loss: 0.413576, acc.: 89.84%] [G loss: 1.372431]\n",
      "epoch:15 step:14610 [D loss: 0.476379, acc.: 81.25%] [G loss: 1.093813]\n",
      "epoch:15 step:14611 [D loss: 0.417676, acc.: 83.59%] [G loss: 1.348201]\n",
      "epoch:15 step:14612 [D loss: 0.426917, acc.: 87.50%] [G loss: 1.228089]\n",
      "epoch:15 step:14613 [D loss: 0.615159, acc.: 66.41%] [G loss: 1.065412]\n",
      "epoch:15 step:14614 [D loss: 0.902792, acc.: 45.31%] [G loss: 1.160301]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14615 [D loss: 0.789557, acc.: 46.09%] [G loss: 1.222483]\n",
      "epoch:15 step:14616 [D loss: 0.524790, acc.: 75.00%] [G loss: 1.104381]\n",
      "epoch:15 step:14617 [D loss: 0.724161, acc.: 54.69%] [G loss: 1.035246]\n",
      "epoch:15 step:14618 [D loss: 0.697077, acc.: 61.72%] [G loss: 0.942672]\n",
      "epoch:15 step:14619 [D loss: 0.634553, acc.: 64.06%] [G loss: 1.100563]\n",
      "epoch:15 step:14620 [D loss: 0.642382, acc.: 60.16%] [G loss: 1.089764]\n",
      "epoch:15 step:14621 [D loss: 0.526441, acc.: 75.00%] [G loss: 1.228861]\n",
      "epoch:15 step:14622 [D loss: 0.458535, acc.: 89.06%] [G loss: 1.218767]\n",
      "epoch:15 step:14623 [D loss: 0.583425, acc.: 71.09%] [G loss: 1.156053]\n",
      "epoch:15 step:14624 [D loss: 0.743325, acc.: 42.97%] [G loss: 1.128664]\n",
      "epoch:15 step:14625 [D loss: 0.618080, acc.: 68.75%] [G loss: 0.904597]\n",
      "epoch:15 step:14626 [D loss: 0.674853, acc.: 57.03%] [G loss: 1.032187]\n",
      "epoch:15 step:14627 [D loss: 0.654798, acc.: 57.03%] [G loss: 0.968319]\n",
      "epoch:15 step:14628 [D loss: 0.512458, acc.: 78.12%] [G loss: 1.147287]\n",
      "epoch:15 step:14629 [D loss: 0.533618, acc.: 75.00%] [G loss: 1.085348]\n",
      "epoch:15 step:14630 [D loss: 0.601883, acc.: 67.97%] [G loss: 0.852788]\n",
      "epoch:15 step:14631 [D loss: 0.491069, acc.: 78.12%] [G loss: 1.041464]\n",
      "epoch:15 step:14632 [D loss: 0.541434, acc.: 75.00%] [G loss: 0.978934]\n",
      "epoch:15 step:14633 [D loss: 0.580860, acc.: 73.44%] [G loss: 0.963215]\n",
      "epoch:15 step:14634 [D loss: 0.639963, acc.: 62.50%] [G loss: 0.901290]\n",
      "epoch:15 step:14635 [D loss: 0.782376, acc.: 45.31%] [G loss: 0.867195]\n",
      "epoch:15 step:14636 [D loss: 0.616922, acc.: 67.19%] [G loss: 0.967892]\n",
      "epoch:15 step:14637 [D loss: 0.735204, acc.: 56.25%] [G loss: 0.888814]\n",
      "epoch:15 step:14638 [D loss: 0.708936, acc.: 53.91%] [G loss: 0.820598]\n",
      "epoch:15 step:14639 [D loss: 0.767232, acc.: 50.00%] [G loss: 0.869696]\n",
      "epoch:15 step:14640 [D loss: 0.690584, acc.: 60.16%] [G loss: 1.002377]\n",
      "epoch:15 step:14641 [D loss: 0.724741, acc.: 49.22%] [G loss: 0.961363]\n",
      "epoch:15 step:14642 [D loss: 0.545066, acc.: 72.66%] [G loss: 1.094519]\n",
      "epoch:15 step:14643 [D loss: 0.489552, acc.: 82.03%] [G loss: 1.258025]\n",
      "epoch:15 step:14644 [D loss: 0.483526, acc.: 79.69%] [G loss: 1.265774]\n",
      "epoch:15 step:14645 [D loss: 0.725960, acc.: 50.78%] [G loss: 1.032381]\n",
      "epoch:15 step:14646 [D loss: 0.603828, acc.: 69.53%] [G loss: 1.122692]\n",
      "epoch:15 step:14647 [D loss: 0.609396, acc.: 69.53%] [G loss: 1.051000]\n",
      "epoch:15 step:14648 [D loss: 0.655043, acc.: 56.25%] [G loss: 0.968762]\n",
      "epoch:15 step:14649 [D loss: 0.599760, acc.: 62.50%] [G loss: 0.967475]\n",
      "epoch:15 step:14650 [D loss: 0.651156, acc.: 62.50%] [G loss: 0.965688]\n",
      "epoch:15 step:14651 [D loss: 0.593500, acc.: 71.88%] [G loss: 0.950001]\n",
      "epoch:15 step:14652 [D loss: 0.560921, acc.: 71.88%] [G loss: 1.021662]\n",
      "epoch:15 step:14653 [D loss: 0.426572, acc.: 85.16%] [G loss: 1.257137]\n",
      "epoch:15 step:14654 [D loss: 0.739238, acc.: 52.34%] [G loss: 1.066327]\n",
      "epoch:15 step:14655 [D loss: 0.783864, acc.: 50.78%] [G loss: 1.124947]\n",
      "epoch:15 step:14656 [D loss: 0.643140, acc.: 61.72%] [G loss: 0.936957]\n",
      "epoch:15 step:14657 [D loss: 0.804865, acc.: 42.19%] [G loss: 1.129018]\n",
      "epoch:15 step:14658 [D loss: 0.435478, acc.: 85.16%] [G loss: 1.322549]\n",
      "epoch:15 step:14659 [D loss: 0.494544, acc.: 76.56%] [G loss: 1.083152]\n",
      "epoch:15 step:14660 [D loss: 0.576446, acc.: 69.53%] [G loss: 1.237975]\n",
      "epoch:15 step:14661 [D loss: 0.683061, acc.: 60.94%] [G loss: 1.092377]\n",
      "epoch:15 step:14662 [D loss: 0.635694, acc.: 63.28%] [G loss: 0.998063]\n",
      "epoch:15 step:14663 [D loss: 0.634596, acc.: 65.62%] [G loss: 0.990718]\n",
      "epoch:15 step:14664 [D loss: 0.735358, acc.: 50.78%] [G loss: 0.801168]\n",
      "epoch:15 step:14665 [D loss: 0.659517, acc.: 60.94%] [G loss: 1.075156]\n",
      "epoch:15 step:14666 [D loss: 0.680476, acc.: 59.38%] [G loss: 1.008557]\n",
      "epoch:15 step:14667 [D loss: 0.643217, acc.: 64.06%] [G loss: 1.111313]\n",
      "epoch:15 step:14668 [D loss: 0.560608, acc.: 74.22%] [G loss: 1.082916]\n",
      "epoch:15 step:14669 [D loss: 0.606304, acc.: 65.62%] [G loss: 0.959802]\n",
      "epoch:15 step:14670 [D loss: 0.489580, acc.: 85.94%] [G loss: 1.184707]\n",
      "epoch:15 step:14671 [D loss: 0.552597, acc.: 72.66%] [G loss: 1.101960]\n",
      "epoch:15 step:14672 [D loss: 0.698872, acc.: 59.38%] [G loss: 1.058443]\n",
      "epoch:15 step:14673 [D loss: 0.693004, acc.: 56.25%] [G loss: 1.167540]\n",
      "epoch:15 step:14674 [D loss: 0.612063, acc.: 64.84%] [G loss: 1.104209]\n",
      "epoch:15 step:14675 [D loss: 0.660603, acc.: 60.94%] [G loss: 1.018914]\n",
      "epoch:15 step:14676 [D loss: 0.652521, acc.: 58.59%] [G loss: 1.120923]\n",
      "epoch:15 step:14677 [D loss: 0.712668, acc.: 54.69%] [G loss: 1.086562]\n",
      "epoch:15 step:14678 [D loss: 0.711709, acc.: 52.34%] [G loss: 0.972371]\n",
      "epoch:15 step:14679 [D loss: 0.616779, acc.: 64.06%] [G loss: 0.893616]\n",
      "epoch:15 step:14680 [D loss: 0.746653, acc.: 52.34%] [G loss: 0.914348]\n",
      "epoch:15 step:14681 [D loss: 0.663720, acc.: 57.03%] [G loss: 1.095656]\n",
      "epoch:15 step:14682 [D loss: 0.717317, acc.: 55.47%] [G loss: 0.911955]\n",
      "epoch:15 step:14683 [D loss: 0.663778, acc.: 57.81%] [G loss: 0.973154]\n",
      "epoch:15 step:14684 [D loss: 0.509720, acc.: 77.34%] [G loss: 1.091343]\n",
      "epoch:15 step:14685 [D loss: 0.601060, acc.: 68.75%] [G loss: 1.025847]\n",
      "epoch:15 step:14686 [D loss: 0.820126, acc.: 39.06%] [G loss: 0.952760]\n",
      "epoch:15 step:14687 [D loss: 0.610115, acc.: 67.97%] [G loss: 0.952458]\n",
      "epoch:15 step:14688 [D loss: 0.665426, acc.: 59.38%] [G loss: 1.142845]\n",
      "epoch:15 step:14689 [D loss: 0.536339, acc.: 75.00%] [G loss: 0.870156]\n",
      "epoch:15 step:14690 [D loss: 0.571795, acc.: 70.31%] [G loss: 1.187160]\n",
      "epoch:15 step:14691 [D loss: 0.714182, acc.: 55.47%] [G loss: 0.912849]\n",
      "epoch:15 step:14692 [D loss: 0.750362, acc.: 52.34%] [G loss: 0.916430]\n",
      "epoch:15 step:14693 [D loss: 0.692674, acc.: 57.81%] [G loss: 0.845185]\n",
      "epoch:15 step:14694 [D loss: 0.686718, acc.: 54.69%] [G loss: 0.953625]\n",
      "epoch:15 step:14695 [D loss: 0.584900, acc.: 68.75%] [G loss: 1.184153]\n",
      "epoch:15 step:14696 [D loss: 0.533242, acc.: 77.34%] [G loss: 1.150130]\n",
      "epoch:15 step:14697 [D loss: 0.493840, acc.: 81.25%] [G loss: 1.291274]\n",
      "epoch:15 step:14698 [D loss: 0.669387, acc.: 55.47%] [G loss: 1.047284]\n",
      "epoch:15 step:14699 [D loss: 0.792217, acc.: 48.44%] [G loss: 1.128713]\n",
      "epoch:15 step:14700 [D loss: 0.701624, acc.: 53.91%] [G loss: 0.863603]\n",
      "epoch:15 step:14701 [D loss: 0.671259, acc.: 60.94%] [G loss: 1.014337]\n",
      "epoch:15 step:14702 [D loss: 0.550558, acc.: 73.44%] [G loss: 0.859193]\n",
      "epoch:15 step:14703 [D loss: 0.578015, acc.: 70.31%] [G loss: 0.980766]\n",
      "epoch:15 step:14704 [D loss: 0.602852, acc.: 68.75%] [G loss: 1.233647]\n",
      "epoch:15 step:14705 [D loss: 0.436261, acc.: 86.72%] [G loss: 1.069778]\n",
      "epoch:15 step:14706 [D loss: 0.656147, acc.: 58.59%] [G loss: 1.078461]\n",
      "epoch:15 step:14707 [D loss: 0.737974, acc.: 53.91%] [G loss: 0.912723]\n",
      "epoch:15 step:14708 [D loss: 0.655627, acc.: 67.19%] [G loss: 0.999078]\n",
      "epoch:15 step:14709 [D loss: 0.603770, acc.: 70.31%] [G loss: 0.975180]\n",
      "epoch:15 step:14710 [D loss: 0.727713, acc.: 49.22%] [G loss: 0.866948]\n",
      "epoch:15 step:14711 [D loss: 0.678900, acc.: 55.47%] [G loss: 0.955326]\n",
      "epoch:15 step:14712 [D loss: 0.645424, acc.: 61.72%] [G loss: 0.889196]\n",
      "epoch:15 step:14713 [D loss: 0.663198, acc.: 61.72%] [G loss: 0.919829]\n",
      "epoch:15 step:14714 [D loss: 0.658213, acc.: 61.72%] [G loss: 0.869207]\n",
      "epoch:15 step:14715 [D loss: 0.581671, acc.: 75.00%] [G loss: 1.004657]\n",
      "epoch:15 step:14716 [D loss: 0.676768, acc.: 60.16%] [G loss: 0.928576]\n",
      "epoch:15 step:14717 [D loss: 0.625116, acc.: 62.50%] [G loss: 0.952636]\n",
      "epoch:15 step:14718 [D loss: 0.561947, acc.: 71.88%] [G loss: 1.044107]\n",
      "epoch:15 step:14719 [D loss: 0.505682, acc.: 81.25%] [G loss: 1.259228]\n",
      "epoch:15 step:14720 [D loss: 0.453591, acc.: 86.72%] [G loss: 1.081728]\n",
      "epoch:15 step:14721 [D loss: 0.717061, acc.: 53.12%] [G loss: 1.041193]\n",
      "epoch:15 step:14722 [D loss: 0.614616, acc.: 67.19%] [G loss: 1.178584]\n",
      "epoch:15 step:14723 [D loss: 0.655739, acc.: 64.06%] [G loss: 1.032318]\n",
      "epoch:15 step:14724 [D loss: 0.567558, acc.: 69.53%] [G loss: 0.973620]\n",
      "epoch:15 step:14725 [D loss: 0.613649, acc.: 64.06%] [G loss: 0.856652]\n",
      "epoch:15 step:14726 [D loss: 0.817570, acc.: 40.62%] [G loss: 0.783773]\n",
      "epoch:15 step:14727 [D loss: 0.630153, acc.: 64.84%] [G loss: 1.136311]\n",
      "epoch:15 step:14728 [D loss: 0.852195, acc.: 35.94%] [G loss: 0.808091]\n",
      "epoch:15 step:14729 [D loss: 0.853474, acc.: 38.28%] [G loss: 0.852160]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14730 [D loss: 0.756071, acc.: 44.53%] [G loss: 0.857409]\n",
      "epoch:15 step:14731 [D loss: 0.683349, acc.: 58.59%] [G loss: 0.975189]\n",
      "epoch:15 step:14732 [D loss: 0.789474, acc.: 47.66%] [G loss: 0.977214]\n",
      "epoch:15 step:14733 [D loss: 0.616947, acc.: 64.84%] [G loss: 1.129276]\n",
      "epoch:15 step:14734 [D loss: 0.738593, acc.: 51.56%] [G loss: 0.867107]\n",
      "epoch:15 step:14735 [D loss: 0.668706, acc.: 60.16%] [G loss: 0.887326]\n",
      "epoch:15 step:14736 [D loss: 0.635610, acc.: 64.06%] [G loss: 1.097051]\n",
      "epoch:15 step:14737 [D loss: 0.629908, acc.: 63.28%] [G loss: 1.073489]\n",
      "epoch:15 step:14738 [D loss: 0.748046, acc.: 48.44%] [G loss: 0.648128]\n",
      "epoch:15 step:14739 [D loss: 0.688065, acc.: 55.47%] [G loss: 0.839257]\n",
      "epoch:15 step:14740 [D loss: 0.641699, acc.: 60.94%] [G loss: 0.889642]\n",
      "epoch:15 step:14741 [D loss: 0.610630, acc.: 67.19%] [G loss: 0.968274]\n",
      "epoch:15 step:14742 [D loss: 0.775115, acc.: 45.31%] [G loss: 0.932672]\n",
      "epoch:15 step:14743 [D loss: 0.617297, acc.: 61.72%] [G loss: 0.932685]\n",
      "epoch:15 step:14744 [D loss: 0.586848, acc.: 67.19%] [G loss: 1.100591]\n",
      "epoch:15 step:14745 [D loss: 0.501423, acc.: 80.47%] [G loss: 1.059641]\n",
      "epoch:15 step:14746 [D loss: 0.474173, acc.: 84.38%] [G loss: 1.102119]\n",
      "epoch:15 step:14747 [D loss: 0.573862, acc.: 71.09%] [G loss: 1.141811]\n",
      "epoch:15 step:14748 [D loss: 0.572216, acc.: 66.41%] [G loss: 1.059076]\n",
      "epoch:15 step:14749 [D loss: 0.375789, acc.: 89.06%] [G loss: 1.343786]\n",
      "epoch:15 step:14750 [D loss: 0.516199, acc.: 80.47%] [G loss: 1.305772]\n",
      "epoch:15 step:14751 [D loss: 0.800546, acc.: 44.53%] [G loss: 0.995961]\n",
      "epoch:15 step:14752 [D loss: 0.731514, acc.: 53.12%] [G loss: 1.018028]\n",
      "epoch:15 step:14753 [D loss: 0.822293, acc.: 44.53%] [G loss: 0.855795]\n",
      "epoch:15 step:14754 [D loss: 0.696749, acc.: 56.25%] [G loss: 1.140777]\n",
      "epoch:15 step:14755 [D loss: 0.595396, acc.: 70.31%] [G loss: 1.041736]\n",
      "epoch:15 step:14756 [D loss: 0.592961, acc.: 72.66%] [G loss: 1.049563]\n",
      "epoch:15 step:14757 [D loss: 0.670593, acc.: 65.62%] [G loss: 1.046478]\n",
      "epoch:15 step:14758 [D loss: 0.644955, acc.: 60.94%] [G loss: 1.016712]\n",
      "epoch:15 step:14759 [D loss: 0.709847, acc.: 59.38%] [G loss: 0.837126]\n",
      "epoch:15 step:14760 [D loss: 0.642248, acc.: 60.94%] [G loss: 0.940970]\n",
      "epoch:15 step:14761 [D loss: 0.487546, acc.: 82.03%] [G loss: 1.227769]\n",
      "epoch:15 step:14762 [D loss: 0.488168, acc.: 80.47%] [G loss: 0.994704]\n",
      "epoch:15 step:14763 [D loss: 0.571701, acc.: 72.66%] [G loss: 1.102422]\n",
      "epoch:15 step:14764 [D loss: 0.614449, acc.: 64.84%] [G loss: 1.042919]\n",
      "epoch:15 step:14765 [D loss: 0.763075, acc.: 45.31%] [G loss: 1.174670]\n",
      "epoch:15 step:14766 [D loss: 0.781910, acc.: 46.88%] [G loss: 1.035176]\n",
      "epoch:15 step:14767 [D loss: 0.607916, acc.: 65.62%] [G loss: 0.890401]\n",
      "epoch:15 step:14768 [D loss: 0.498427, acc.: 78.91%] [G loss: 1.103898]\n",
      "epoch:15 step:14769 [D loss: 0.649380, acc.: 62.50%] [G loss: 0.778487]\n",
      "epoch:15 step:14770 [D loss: 0.700384, acc.: 53.12%] [G loss: 0.979582]\n",
      "epoch:15 step:14771 [D loss: 0.780286, acc.: 48.44%] [G loss: 0.998621]\n",
      "epoch:15 step:14772 [D loss: 0.668293, acc.: 52.34%] [G loss: 0.908107]\n",
      "epoch:15 step:14773 [D loss: 0.710801, acc.: 54.69%] [G loss: 0.854643]\n",
      "epoch:15 step:14774 [D loss: 0.668757, acc.: 57.81%] [G loss: 0.848392]\n",
      "epoch:15 step:14775 [D loss: 0.656025, acc.: 63.28%] [G loss: 0.884665]\n",
      "epoch:15 step:14776 [D loss: 0.659189, acc.: 62.50%] [G loss: 0.809747]\n",
      "epoch:15 step:14777 [D loss: 0.677567, acc.: 58.59%] [G loss: 1.026149]\n",
      "epoch:15 step:14778 [D loss: 0.683902, acc.: 50.78%] [G loss: 0.961763]\n",
      "epoch:15 step:14779 [D loss: 0.488873, acc.: 83.59%] [G loss: 1.074203]\n",
      "epoch:15 step:14780 [D loss: 0.549728, acc.: 78.12%] [G loss: 0.898761]\n",
      "epoch:15 step:14781 [D loss: 0.547311, acc.: 77.34%] [G loss: 1.134683]\n",
      "epoch:15 step:14782 [D loss: 0.755172, acc.: 48.44%] [G loss: 1.035965]\n",
      "epoch:15 step:14783 [D loss: 0.752850, acc.: 51.56%] [G loss: 1.015510]\n",
      "epoch:15 step:14784 [D loss: 0.709131, acc.: 51.56%] [G loss: 1.028745]\n",
      "epoch:15 step:14785 [D loss: 0.657352, acc.: 61.72%] [G loss: 1.041754]\n",
      "epoch:15 step:14786 [D loss: 0.493671, acc.: 82.81%] [G loss: 1.099728]\n",
      "epoch:15 step:14787 [D loss: 0.503899, acc.: 78.12%] [G loss: 1.133136]\n",
      "epoch:15 step:14788 [D loss: 0.553417, acc.: 72.66%] [G loss: 1.051080]\n",
      "epoch:15 step:14789 [D loss: 0.710698, acc.: 53.12%] [G loss: 0.975811]\n",
      "epoch:15 step:14790 [D loss: 0.601238, acc.: 65.62%] [G loss: 1.011421]\n",
      "epoch:15 step:14791 [D loss: 0.615793, acc.: 66.41%] [G loss: 0.911506]\n",
      "epoch:15 step:14792 [D loss: 0.712556, acc.: 58.59%] [G loss: 0.999656]\n",
      "epoch:15 step:14793 [D loss: 0.608728, acc.: 67.19%] [G loss: 1.100131]\n",
      "epoch:15 step:14794 [D loss: 0.827059, acc.: 35.94%] [G loss: 0.752730]\n",
      "epoch:15 step:14795 [D loss: 0.650787, acc.: 57.81%] [G loss: 1.070272]\n",
      "epoch:15 step:14796 [D loss: 0.632860, acc.: 60.94%] [G loss: 0.906555]\n",
      "epoch:15 step:14797 [D loss: 0.728368, acc.: 50.00%] [G loss: 1.098346]\n",
      "epoch:15 step:14798 [D loss: 0.558120, acc.: 75.00%] [G loss: 0.990537]\n",
      "epoch:15 step:14799 [D loss: 0.717137, acc.: 52.34%] [G loss: 0.848096]\n",
      "epoch:15 step:14800 [D loss: 0.617051, acc.: 67.19%] [G loss: 1.018430]\n",
      "##############\n",
      "[2.09402944 1.16801198 5.25405368 4.01002671 2.65127394 5.20903863\n",
      " 4.12670442 4.2168935  3.83815417 3.45497107]\n",
      "##########\n",
      "epoch:15 step:14801 [D loss: 0.602004, acc.: 68.75%] [G loss: 1.046349]\n",
      "epoch:15 step:14802 [D loss: 0.589056, acc.: 68.75%] [G loss: 1.083058]\n",
      "epoch:15 step:14803 [D loss: 0.649530, acc.: 63.28%] [G loss: 1.083697]\n",
      "epoch:15 step:14804 [D loss: 0.626006, acc.: 63.28%] [G loss: 1.003332]\n",
      "epoch:15 step:14805 [D loss: 0.565501, acc.: 72.66%] [G loss: 1.046624]\n",
      "epoch:15 step:14806 [D loss: 0.690354, acc.: 55.47%] [G loss: 0.872816]\n",
      "epoch:15 step:14807 [D loss: 0.721837, acc.: 50.78%] [G loss: 0.923031]\n",
      "epoch:15 step:14808 [D loss: 0.685702, acc.: 55.47%] [G loss: 0.800780]\n",
      "epoch:15 step:14809 [D loss: 0.640453, acc.: 66.41%] [G loss: 1.078972]\n",
      "epoch:15 step:14810 [D loss: 0.561079, acc.: 74.22%] [G loss: 0.933940]\n",
      "epoch:15 step:14811 [D loss: 0.577905, acc.: 71.09%] [G loss: 1.050110]\n",
      "epoch:15 step:14812 [D loss: 0.577372, acc.: 75.78%] [G loss: 0.929726]\n",
      "epoch:15 step:14813 [D loss: 0.702275, acc.: 54.69%] [G loss: 0.906781]\n",
      "epoch:15 step:14814 [D loss: 0.684032, acc.: 59.38%] [G loss: 0.977336]\n",
      "epoch:15 step:14815 [D loss: 0.700724, acc.: 52.34%] [G loss: 0.904207]\n",
      "epoch:15 step:14816 [D loss: 0.572409, acc.: 73.44%] [G loss: 1.041506]\n",
      "epoch:15 step:14817 [D loss: 0.757338, acc.: 47.66%] [G loss: 1.049495]\n",
      "epoch:15 step:14818 [D loss: 0.670461, acc.: 60.94%] [G loss: 0.885544]\n",
      "epoch:15 step:14819 [D loss: 0.694141, acc.: 54.69%] [G loss: 0.909543]\n",
      "epoch:15 step:14820 [D loss: 0.820933, acc.: 44.53%] [G loss: 0.935916]\n",
      "epoch:15 step:14821 [D loss: 0.728977, acc.: 53.12%] [G loss: 1.009473]\n",
      "epoch:15 step:14822 [D loss: 0.519480, acc.: 75.78%] [G loss: 1.110592]\n",
      "epoch:15 step:14823 [D loss: 0.532474, acc.: 78.91%] [G loss: 0.984885]\n",
      "epoch:15 step:14824 [D loss: 0.470413, acc.: 80.47%] [G loss: 1.353194]\n",
      "epoch:15 step:14825 [D loss: 0.606584, acc.: 71.09%] [G loss: 1.044304]\n",
      "epoch:15 step:14826 [D loss: 0.714094, acc.: 46.88%] [G loss: 0.902703]\n",
      "epoch:15 step:14827 [D loss: 0.641810, acc.: 66.41%] [G loss: 1.021052]\n",
      "epoch:15 step:14828 [D loss: 0.696019, acc.: 59.38%] [G loss: 0.798683]\n",
      "epoch:15 step:14829 [D loss: 0.469066, acc.: 78.12%] [G loss: 1.164525]\n",
      "epoch:15 step:14830 [D loss: 0.385811, acc.: 89.06%] [G loss: 1.284756]\n",
      "epoch:15 step:14831 [D loss: 0.517149, acc.: 76.56%] [G loss: 1.353614]\n",
      "epoch:15 step:14832 [D loss: 0.762721, acc.: 46.88%] [G loss: 0.877535]\n",
      "epoch:15 step:14833 [D loss: 0.650075, acc.: 60.16%] [G loss: 1.155413]\n",
      "epoch:15 step:14834 [D loss: 0.979518, acc.: 32.03%] [G loss: 0.980824]\n",
      "epoch:15 step:14835 [D loss: 0.708953, acc.: 58.59%] [G loss: 1.174910]\n",
      "epoch:15 step:14836 [D loss: 0.597796, acc.: 65.62%] [G loss: 1.115406]\n",
      "epoch:15 step:14837 [D loss: 0.534228, acc.: 73.44%] [G loss: 1.197473]\n",
      "epoch:15 step:14838 [D loss: 0.772062, acc.: 47.66%] [G loss: 0.967925]\n",
      "epoch:15 step:14839 [D loss: 0.679078, acc.: 59.38%] [G loss: 0.975338]\n",
      "epoch:15 step:14840 [D loss: 0.636947, acc.: 57.81%] [G loss: 0.861765]\n",
      "epoch:15 step:14841 [D loss: 0.496079, acc.: 80.47%] [G loss: 1.007694]\n",
      "epoch:15 step:14842 [D loss: 0.827528, acc.: 40.62%] [G loss: 0.839876]\n",
      "epoch:15 step:14843 [D loss: 0.620860, acc.: 69.53%] [G loss: 0.998217]\n",
      "epoch:15 step:14844 [D loss: 0.675499, acc.: 56.25%] [G loss: 0.848835]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14845 [D loss: 0.512773, acc.: 77.34%] [G loss: 1.143408]\n",
      "epoch:15 step:14846 [D loss: 0.563024, acc.: 73.44%] [G loss: 1.019513]\n",
      "epoch:15 step:14847 [D loss: 0.421106, acc.: 85.16%] [G loss: 1.305937]\n",
      "epoch:15 step:14848 [D loss: 0.465721, acc.: 85.16%] [G loss: 1.190620]\n",
      "epoch:15 step:14849 [D loss: 0.500285, acc.: 80.47%] [G loss: 1.091932]\n",
      "epoch:15 step:14850 [D loss: 0.529900, acc.: 79.69%] [G loss: 1.304542]\n",
      "epoch:15 step:14851 [D loss: 0.581668, acc.: 71.09%] [G loss: 0.988870]\n",
      "epoch:15 step:14852 [D loss: 0.609575, acc.: 64.84%] [G loss: 1.095132]\n",
      "epoch:15 step:14853 [D loss: 0.591589, acc.: 68.75%] [G loss: 1.097683]\n",
      "epoch:15 step:14854 [D loss: 0.721310, acc.: 53.91%] [G loss: 0.839537]\n",
      "epoch:15 step:14855 [D loss: 0.766825, acc.: 46.09%] [G loss: 1.141634]\n",
      "epoch:15 step:14856 [D loss: 0.830830, acc.: 33.59%] [G loss: 0.763614]\n",
      "epoch:15 step:14857 [D loss: 0.673976, acc.: 60.94%] [G loss: 0.902651]\n",
      "epoch:15 step:14858 [D loss: 0.711259, acc.: 53.12%] [G loss: 1.103288]\n",
      "epoch:15 step:14859 [D loss: 0.676171, acc.: 57.03%] [G loss: 0.944604]\n",
      "epoch:15 step:14860 [D loss: 0.599342, acc.: 74.22%] [G loss: 1.115597]\n",
      "epoch:15 step:14861 [D loss: 0.511150, acc.: 82.03%] [G loss: 1.222846]\n",
      "epoch:15 step:14862 [D loss: 0.692996, acc.: 57.03%] [G loss: 1.029086]\n",
      "epoch:15 step:14863 [D loss: 0.549298, acc.: 75.00%] [G loss: 1.121329]\n",
      "epoch:15 step:14864 [D loss: 0.630390, acc.: 65.62%] [G loss: 0.998181]\n",
      "epoch:15 step:14865 [D loss: 0.576455, acc.: 78.91%] [G loss: 1.071405]\n",
      "epoch:15 step:14866 [D loss: 0.674988, acc.: 59.38%] [G loss: 1.063947]\n",
      "epoch:15 step:14867 [D loss: 0.564591, acc.: 71.09%] [G loss: 1.107732]\n",
      "epoch:15 step:14868 [D loss: 0.602838, acc.: 64.84%] [G loss: 0.993853]\n",
      "epoch:15 step:14869 [D loss: 0.646609, acc.: 61.72%] [G loss: 0.787735]\n",
      "epoch:15 step:14870 [D loss: 0.366431, acc.: 83.59%] [G loss: 1.208556]\n",
      "epoch:15 step:14871 [D loss: 0.447930, acc.: 82.81%] [G loss: 1.372790]\n",
      "epoch:15 step:14872 [D loss: 0.643676, acc.: 62.50%] [G loss: 0.956290]\n",
      "epoch:15 step:14873 [D loss: 0.549345, acc.: 78.12%] [G loss: 1.216454]\n",
      "epoch:15 step:14874 [D loss: 0.570633, acc.: 69.53%] [G loss: 1.045012]\n",
      "epoch:15 step:14875 [D loss: 0.769810, acc.: 43.75%] [G loss: 1.345857]\n",
      "epoch:15 step:14876 [D loss: 0.787774, acc.: 53.91%] [G loss: 0.764135]\n",
      "epoch:15 step:14877 [D loss: 0.683325, acc.: 57.03%] [G loss: 0.864302]\n",
      "epoch:15 step:14878 [D loss: 0.555924, acc.: 71.09%] [G loss: 0.941883]\n",
      "epoch:15 step:14879 [D loss: 0.571482, acc.: 75.00%] [G loss: 1.133312]\n",
      "epoch:15 step:14880 [D loss: 0.542603, acc.: 77.34%] [G loss: 1.026585]\n",
      "epoch:15 step:14881 [D loss: 0.620929, acc.: 67.19%] [G loss: 1.165045]\n",
      "epoch:15 step:14882 [D loss: 0.911819, acc.: 32.03%] [G loss: 0.898317]\n",
      "epoch:15 step:14883 [D loss: 0.709343, acc.: 53.12%] [G loss: 0.977056]\n",
      "epoch:15 step:14884 [D loss: 0.597927, acc.: 70.31%] [G loss: 0.809884]\n",
      "epoch:15 step:14885 [D loss: 0.722914, acc.: 46.88%] [G loss: 0.895082]\n",
      "epoch:15 step:14886 [D loss: 0.471602, acc.: 79.69%] [G loss: 1.094046]\n",
      "epoch:15 step:14887 [D loss: 0.475382, acc.: 84.38%] [G loss: 1.239441]\n",
      "epoch:15 step:14888 [D loss: 0.652772, acc.: 61.72%] [G loss: 1.058764]\n",
      "epoch:15 step:14889 [D loss: 0.727563, acc.: 53.12%] [G loss: 1.181690]\n",
      "epoch:15 step:14890 [D loss: 0.829189, acc.: 39.84%] [G loss: 0.931129]\n",
      "epoch:15 step:14891 [D loss: 0.689014, acc.: 59.38%] [G loss: 1.076284]\n",
      "epoch:15 step:14892 [D loss: 0.586558, acc.: 72.66%] [G loss: 0.996165]\n",
      "epoch:15 step:14893 [D loss: 0.655949, acc.: 62.50%] [G loss: 0.960501]\n",
      "epoch:15 step:14894 [D loss: 0.640133, acc.: 64.06%] [G loss: 1.041459]\n",
      "epoch:15 step:14895 [D loss: 0.573333, acc.: 71.09%] [G loss: 1.095247]\n",
      "epoch:15 step:14896 [D loss: 0.484185, acc.: 85.94%] [G loss: 1.090247]\n",
      "epoch:15 step:14897 [D loss: 0.480675, acc.: 82.81%] [G loss: 1.231425]\n",
      "epoch:15 step:14898 [D loss: 0.800197, acc.: 46.88%] [G loss: 0.958948]\n",
      "epoch:15 step:14899 [D loss: 0.761599, acc.: 50.78%] [G loss: 0.924191]\n",
      "epoch:15 step:14900 [D loss: 0.736294, acc.: 48.44%] [G loss: 1.051074]\n",
      "epoch:15 step:14901 [D loss: 0.639982, acc.: 61.72%] [G loss: 0.875337]\n",
      "epoch:15 step:14902 [D loss: 0.535193, acc.: 75.00%] [G loss: 1.054902]\n",
      "epoch:15 step:14903 [D loss: 0.642079, acc.: 63.28%] [G loss: 0.875063]\n",
      "epoch:15 step:14904 [D loss: 0.609894, acc.: 68.75%] [G loss: 1.047806]\n",
      "epoch:15 step:14905 [D loss: 0.562967, acc.: 71.88%] [G loss: 1.133212]\n",
      "epoch:15 step:14906 [D loss: 0.489805, acc.: 76.56%] [G loss: 1.220209]\n",
      "epoch:15 step:14907 [D loss: 0.464955, acc.: 86.72%] [G loss: 1.385042]\n",
      "epoch:15 step:14908 [D loss: 0.504472, acc.: 79.69%] [G loss: 1.339225]\n",
      "epoch:15 step:14909 [D loss: 0.365379, acc.: 92.19%] [G loss: 1.374606]\n",
      "epoch:15 step:14910 [D loss: 0.519268, acc.: 75.00%] [G loss: 1.058733]\n",
      "epoch:15 step:14911 [D loss: 0.634579, acc.: 67.19%] [G loss: 1.053947]\n",
      "epoch:15 step:14912 [D loss: 0.508140, acc.: 81.25%] [G loss: 1.245254]\n",
      "epoch:15 step:14913 [D loss: 0.840682, acc.: 46.09%] [G loss: 1.052699]\n",
      "epoch:15 step:14914 [D loss: 0.658837, acc.: 64.84%] [G loss: 0.945049]\n",
      "epoch:15 step:14915 [D loss: 0.667638, acc.: 57.03%] [G loss: 0.960956]\n",
      "epoch:15 step:14916 [D loss: 0.616276, acc.: 64.06%] [G loss: 1.057820]\n",
      "epoch:15 step:14917 [D loss: 0.642787, acc.: 58.59%] [G loss: 0.803275]\n",
      "epoch:15 step:14918 [D loss: 0.594332, acc.: 67.97%] [G loss: 0.913269]\n",
      "epoch:15 step:14919 [D loss: 0.693600, acc.: 57.81%] [G loss: 0.918877]\n",
      "epoch:15 step:14920 [D loss: 0.659766, acc.: 57.81%] [G loss: 0.986704]\n",
      "epoch:15 step:14921 [D loss: 0.619394, acc.: 68.75%] [G loss: 0.938070]\n",
      "epoch:15 step:14922 [D loss: 0.752871, acc.: 48.44%] [G loss: 0.960764]\n",
      "epoch:15 step:14923 [D loss: 0.626239, acc.: 59.38%] [G loss: 1.032486]\n",
      "epoch:15 step:14924 [D loss: 0.663402, acc.: 63.28%] [G loss: 1.024294]\n",
      "epoch:15 step:14925 [D loss: 0.695508, acc.: 52.34%] [G loss: 0.912076]\n",
      "epoch:15 step:14926 [D loss: 0.694447, acc.: 56.25%] [G loss: 0.868611]\n",
      "epoch:15 step:14927 [D loss: 0.644720, acc.: 61.72%] [G loss: 0.865452]\n",
      "epoch:15 step:14928 [D loss: 0.601576, acc.: 67.19%] [G loss: 0.999943]\n",
      "epoch:15 step:14929 [D loss: 0.605879, acc.: 68.75%] [G loss: 0.870985]\n",
      "epoch:15 step:14930 [D loss: 0.555788, acc.: 73.44%] [G loss: 0.925822]\n",
      "epoch:15 step:14931 [D loss: 0.507936, acc.: 81.25%] [G loss: 1.154096]\n",
      "epoch:15 step:14932 [D loss: 0.588715, acc.: 67.97%] [G loss: 0.978924]\n",
      "epoch:15 step:14933 [D loss: 0.460353, acc.: 85.16%] [G loss: 1.059058]\n",
      "epoch:15 step:14934 [D loss: 0.605919, acc.: 64.84%] [G loss: 1.125530]\n",
      "epoch:15 step:14935 [D loss: 0.849229, acc.: 36.72%] [G loss: 1.064527]\n",
      "epoch:15 step:14936 [D loss: 0.770082, acc.: 43.75%] [G loss: 0.908404]\n",
      "epoch:15 step:14937 [D loss: 0.803568, acc.: 47.66%] [G loss: 0.890613]\n",
      "epoch:15 step:14938 [D loss: 0.628572, acc.: 63.28%] [G loss: 1.152681]\n",
      "epoch:15 step:14939 [D loss: 0.667823, acc.: 56.25%] [G loss: 0.910325]\n",
      "epoch:15 step:14940 [D loss: 0.557226, acc.: 72.66%] [G loss: 1.119414]\n",
      "epoch:15 step:14941 [D loss: 0.707504, acc.: 53.91%] [G loss: 0.941022]\n",
      "epoch:15 step:14942 [D loss: 0.472089, acc.: 84.38%] [G loss: 1.209855]\n",
      "epoch:15 step:14943 [D loss: 0.541868, acc.: 76.56%] [G loss: 1.078301]\n",
      "epoch:15 step:14944 [D loss: 0.561876, acc.: 69.53%] [G loss: 0.988861]\n",
      "epoch:15 step:14945 [D loss: 0.524071, acc.: 78.91%] [G loss: 1.008456]\n",
      "epoch:15 step:14946 [D loss: 0.873114, acc.: 44.53%] [G loss: 1.057630]\n",
      "epoch:15 step:14947 [D loss: 0.663273, acc.: 60.16%] [G loss: 1.213546]\n",
      "epoch:15 step:14948 [D loss: 0.637262, acc.: 62.50%] [G loss: 0.891096]\n",
      "epoch:15 step:14949 [D loss: 0.605863, acc.: 70.31%] [G loss: 1.065686]\n",
      "epoch:15 step:14950 [D loss: 0.654143, acc.: 64.84%] [G loss: 0.898842]\n",
      "epoch:15 step:14951 [D loss: 0.667042, acc.: 57.03%] [G loss: 0.959481]\n",
      "epoch:15 step:14952 [D loss: 0.588096, acc.: 65.62%] [G loss: 1.001688]\n",
      "epoch:15 step:14953 [D loss: 0.520204, acc.: 75.78%] [G loss: 1.181583]\n",
      "epoch:15 step:14954 [D loss: 0.436915, acc.: 88.28%] [G loss: 1.056383]\n",
      "epoch:15 step:14955 [D loss: 0.504798, acc.: 78.12%] [G loss: 1.089472]\n",
      "epoch:15 step:14956 [D loss: 0.554794, acc.: 78.91%] [G loss: 1.156122]\n",
      "epoch:15 step:14957 [D loss: 0.708274, acc.: 53.12%] [G loss: 0.992205]\n",
      "epoch:15 step:14958 [D loss: 0.712475, acc.: 52.34%] [G loss: 0.923099]\n",
      "epoch:15 step:14959 [D loss: 0.652669, acc.: 57.81%] [G loss: 1.005552]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14960 [D loss: 0.715580, acc.: 53.12%] [G loss: 0.949208]\n",
      "epoch:15 step:14961 [D loss: 0.745522, acc.: 47.66%] [G loss: 0.948491]\n",
      "epoch:15 step:14962 [D loss: 0.550187, acc.: 70.31%] [G loss: 1.224580]\n",
      "epoch:15 step:14963 [D loss: 0.703610, acc.: 57.81%] [G loss: 0.863943]\n",
      "epoch:15 step:14964 [D loss: 0.617888, acc.: 67.19%] [G loss: 1.004806]\n",
      "epoch:15 step:14965 [D loss: 0.586208, acc.: 64.84%] [G loss: 0.956495]\n",
      "epoch:15 step:14966 [D loss: 0.573826, acc.: 70.31%] [G loss: 0.969136]\n",
      "epoch:15 step:14967 [D loss: 0.399547, acc.: 89.84%] [G loss: 1.266465]\n",
      "epoch:15 step:14968 [D loss: 0.793518, acc.: 45.31%] [G loss: 0.960851]\n",
      "epoch:15 step:14969 [D loss: 0.612685, acc.: 67.19%] [G loss: 0.916254]\n",
      "epoch:15 step:14970 [D loss: 0.681594, acc.: 57.81%] [G loss: 0.964813]\n",
      "epoch:15 step:14971 [D loss: 0.681649, acc.: 60.16%] [G loss: 0.898089]\n",
      "epoch:15 step:14972 [D loss: 0.733446, acc.: 56.25%] [G loss: 0.800549]\n",
      "epoch:15 step:14973 [D loss: 0.505974, acc.: 79.69%] [G loss: 1.039701]\n",
      "epoch:15 step:14974 [D loss: 0.633131, acc.: 62.50%] [G loss: 0.952172]\n",
      "epoch:15 step:14975 [D loss: 0.511464, acc.: 78.12%] [G loss: 1.060288]\n",
      "epoch:15 step:14976 [D loss: 0.574451, acc.: 72.66%] [G loss: 0.954541]\n",
      "epoch:15 step:14977 [D loss: 0.686455, acc.: 57.81%] [G loss: 1.061746]\n",
      "epoch:15 step:14978 [D loss: 0.586956, acc.: 65.62%] [G loss: 1.059621]\n",
      "epoch:15 step:14979 [D loss: 0.529215, acc.: 79.69%] [G loss: 1.137137]\n",
      "epoch:15 step:14980 [D loss: 0.493571, acc.: 81.25%] [G loss: 1.047134]\n",
      "epoch:15 step:14981 [D loss: 0.451241, acc.: 88.28%] [G loss: 0.954709]\n",
      "epoch:15 step:14982 [D loss: 0.441442, acc.: 82.81%] [G loss: 1.132590]\n",
      "epoch:15 step:14983 [D loss: 0.897855, acc.: 35.94%] [G loss: 1.028350]\n",
      "epoch:15 step:14984 [D loss: 0.574317, acc.: 70.31%] [G loss: 1.091137]\n",
      "epoch:15 step:14985 [D loss: 0.628600, acc.: 65.62%] [G loss: 1.153388]\n",
      "epoch:15 step:14986 [D loss: 0.524141, acc.: 76.56%] [G loss: 1.325941]\n",
      "epoch:15 step:14987 [D loss: 0.636653, acc.: 65.62%] [G loss: 1.081176]\n",
      "epoch:15 step:14988 [D loss: 0.599967, acc.: 68.75%] [G loss: 1.003309]\n",
      "epoch:15 step:14989 [D loss: 0.412548, acc.: 88.28%] [G loss: 1.071203]\n",
      "epoch:15 step:14990 [D loss: 0.545822, acc.: 74.22%] [G loss: 1.051129]\n",
      "epoch:15 step:14991 [D loss: 0.418827, acc.: 89.06%] [G loss: 1.257721]\n",
      "epoch:15 step:14992 [D loss: 0.234483, acc.: 96.09%] [G loss: 1.356208]\n",
      "epoch:16 step:14993 [D loss: 0.666203, acc.: 63.28%] [G loss: 1.129179]\n",
      "epoch:16 step:14994 [D loss: 0.806959, acc.: 44.53%] [G loss: 0.882632]\n",
      "epoch:16 step:14995 [D loss: 0.798567, acc.: 46.88%] [G loss: 0.981175]\n",
      "epoch:16 step:14996 [D loss: 0.761891, acc.: 54.69%] [G loss: 1.066801]\n",
      "epoch:16 step:14997 [D loss: 0.849011, acc.: 36.72%] [G loss: 0.874581]\n",
      "epoch:16 step:14998 [D loss: 0.663284, acc.: 60.16%] [G loss: 1.036255]\n",
      "epoch:16 step:14999 [D loss: 0.641177, acc.: 61.72%] [G loss: 1.042965]\n",
      "epoch:16 step:15000 [D loss: 0.627967, acc.: 62.50%] [G loss: 1.086470]\n",
      "##############\n",
      "[2.45234214 1.44367059 5.5570667  4.23744758 2.83964406 5.22380262\n",
      " 4.08751191 4.43042732 4.11271298 3.46123428]\n",
      "##########\n",
      "epoch:16 step:15001 [D loss: 0.557344, acc.: 74.22%] [G loss: 1.056743]\n",
      "epoch:16 step:15002 [D loss: 0.628059, acc.: 59.38%] [G loss: 1.044175]\n",
      "epoch:16 step:15003 [D loss: 0.654454, acc.: 59.38%] [G loss: 1.086824]\n",
      "epoch:16 step:15004 [D loss: 0.613484, acc.: 70.31%] [G loss: 1.059262]\n",
      "epoch:16 step:15005 [D loss: 0.684100, acc.: 57.03%] [G loss: 0.932474]\n",
      "epoch:16 step:15006 [D loss: 0.618355, acc.: 68.75%] [G loss: 0.744935]\n",
      "epoch:16 step:15007 [D loss: 0.533367, acc.: 74.22%] [G loss: 0.952697]\n",
      "epoch:16 step:15008 [D loss: 0.529371, acc.: 75.78%] [G loss: 1.184420]\n",
      "epoch:16 step:15009 [D loss: 0.730162, acc.: 50.00%] [G loss: 0.933985]\n",
      "epoch:16 step:15010 [D loss: 0.742100, acc.: 55.47%] [G loss: 1.057896]\n",
      "epoch:16 step:15011 [D loss: 0.737388, acc.: 50.78%] [G loss: 0.894002]\n",
      "epoch:16 step:15012 [D loss: 0.588520, acc.: 71.09%] [G loss: 1.063639]\n",
      "epoch:16 step:15013 [D loss: 0.764819, acc.: 48.44%] [G loss: 1.056299]\n",
      "epoch:16 step:15014 [D loss: 0.680751, acc.: 57.03%] [G loss: 1.040150]\n",
      "epoch:16 step:15015 [D loss: 0.579493, acc.: 71.88%] [G loss: 0.944706]\n",
      "epoch:16 step:15016 [D loss: 0.761495, acc.: 45.31%] [G loss: 0.938221]\n",
      "epoch:16 step:15017 [D loss: 0.616495, acc.: 67.19%] [G loss: 1.038570]\n",
      "epoch:16 step:15018 [D loss: 0.568537, acc.: 72.66%] [G loss: 1.114684]\n",
      "epoch:16 step:15019 [D loss: 0.517026, acc.: 79.69%] [G loss: 1.205427]\n",
      "epoch:16 step:15020 [D loss: 0.463996, acc.: 82.81%] [G loss: 1.163462]\n",
      "epoch:16 step:15021 [D loss: 0.526295, acc.: 74.22%] [G loss: 1.310299]\n",
      "epoch:16 step:15022 [D loss: 0.468122, acc.: 86.72%] [G loss: 1.221759]\n",
      "epoch:16 step:15023 [D loss: 0.490609, acc.: 76.56%] [G loss: 1.292740]\n",
      "epoch:16 step:15024 [D loss: 0.475492, acc.: 78.91%] [G loss: 1.336938]\n",
      "epoch:16 step:15025 [D loss: 0.488242, acc.: 79.69%] [G loss: 1.210085]\n",
      "epoch:16 step:15026 [D loss: 0.481305, acc.: 80.47%] [G loss: 1.386868]\n",
      "epoch:16 step:15027 [D loss: 0.426373, acc.: 85.94%] [G loss: 1.341944]\n",
      "epoch:16 step:15028 [D loss: 0.336045, acc.: 92.97%] [G loss: 1.596180]\n",
      "epoch:16 step:15029 [D loss: 0.839924, acc.: 47.66%] [G loss: 0.955481]\n",
      "epoch:16 step:15030 [D loss: 0.916008, acc.: 39.84%] [G loss: 0.915490]\n",
      "epoch:16 step:15031 [D loss: 0.774849, acc.: 48.44%] [G loss: 0.873976]\n",
      "epoch:16 step:15032 [D loss: 0.621032, acc.: 65.62%] [G loss: 1.032343]\n",
      "epoch:16 step:15033 [D loss: 0.733590, acc.: 53.12%] [G loss: 1.113693]\n",
      "epoch:16 step:15034 [D loss: 0.672709, acc.: 56.25%] [G loss: 0.865693]\n",
      "epoch:16 step:15035 [D loss: 0.611552, acc.: 69.53%] [G loss: 1.067744]\n",
      "epoch:16 step:15036 [D loss: 0.594283, acc.: 61.72%] [G loss: 1.089861]\n",
      "epoch:16 step:15037 [D loss: 0.683951, acc.: 62.50%] [G loss: 0.776982]\n",
      "epoch:16 step:15038 [D loss: 0.675829, acc.: 58.59%] [G loss: 1.118461]\n",
      "epoch:16 step:15039 [D loss: 0.672847, acc.: 62.50%] [G loss: 0.867506]\n",
      "epoch:16 step:15040 [D loss: 0.657827, acc.: 62.50%] [G loss: 1.097122]\n",
      "epoch:16 step:15041 [D loss: 0.634382, acc.: 65.62%] [G loss: 0.999938]\n",
      "epoch:16 step:15042 [D loss: 0.498802, acc.: 79.69%] [G loss: 1.142861]\n",
      "epoch:16 step:15043 [D loss: 0.672193, acc.: 57.03%] [G loss: 1.020311]\n",
      "epoch:16 step:15044 [D loss: 0.700421, acc.: 50.78%] [G loss: 1.050879]\n",
      "epoch:16 step:15045 [D loss: 0.635736, acc.: 65.62%] [G loss: 0.968892]\n",
      "epoch:16 step:15046 [D loss: 0.604148, acc.: 67.19%] [G loss: 0.962706]\n",
      "epoch:16 step:15047 [D loss: 0.543903, acc.: 75.00%] [G loss: 1.001397]\n",
      "epoch:16 step:15048 [D loss: 0.653843, acc.: 57.81%] [G loss: 1.031497]\n",
      "epoch:16 step:15049 [D loss: 0.805486, acc.: 41.41%] [G loss: 1.068308]\n",
      "epoch:16 step:15050 [D loss: 0.699978, acc.: 56.25%] [G loss: 0.940104]\n",
      "epoch:16 step:15051 [D loss: 0.704145, acc.: 55.47%] [G loss: 1.090465]\n",
      "epoch:16 step:15052 [D loss: 0.733242, acc.: 55.47%] [G loss: 0.926090]\n",
      "epoch:16 step:15053 [D loss: 0.660673, acc.: 63.28%] [G loss: 0.835033]\n",
      "epoch:16 step:15054 [D loss: 0.707127, acc.: 53.91%] [G loss: 0.959369]\n",
      "epoch:16 step:15055 [D loss: 0.720897, acc.: 53.91%] [G loss: 0.906896]\n",
      "epoch:16 step:15056 [D loss: 0.646919, acc.: 60.94%] [G loss: 0.995476]\n",
      "epoch:16 step:15057 [D loss: 0.607242, acc.: 65.62%] [G loss: 1.011095]\n",
      "epoch:16 step:15058 [D loss: 0.591945, acc.: 74.22%] [G loss: 0.951231]\n",
      "epoch:16 step:15059 [D loss: 0.564181, acc.: 76.56%] [G loss: 1.063646]\n",
      "epoch:16 step:15060 [D loss: 0.650473, acc.: 64.84%] [G loss: 0.894550]\n",
      "epoch:16 step:15061 [D loss: 0.505181, acc.: 77.34%] [G loss: 0.940104]\n",
      "epoch:16 step:15062 [D loss: 0.573741, acc.: 74.22%] [G loss: 1.179494]\n",
      "epoch:16 step:15063 [D loss: 0.592122, acc.: 73.44%] [G loss: 0.995011]\n",
      "epoch:16 step:15064 [D loss: 0.613590, acc.: 64.84%] [G loss: 1.071278]\n",
      "epoch:16 step:15065 [D loss: 0.704371, acc.: 57.03%] [G loss: 0.911339]\n",
      "epoch:16 step:15066 [D loss: 0.510402, acc.: 76.56%] [G loss: 1.008983]\n",
      "epoch:16 step:15067 [D loss: 0.424568, acc.: 84.38%] [G loss: 1.142058]\n",
      "epoch:16 step:15068 [D loss: 0.562014, acc.: 71.88%] [G loss: 1.091477]\n",
      "epoch:16 step:15069 [D loss: 0.445048, acc.: 85.16%] [G loss: 1.126230]\n",
      "epoch:16 step:15070 [D loss: 0.721364, acc.: 53.12%] [G loss: 1.145235]\n",
      "epoch:16 step:15071 [D loss: 0.725905, acc.: 50.00%] [G loss: 1.020182]\n",
      "epoch:16 step:15072 [D loss: 0.699249, acc.: 50.78%] [G loss: 0.965170]\n",
      "epoch:16 step:15073 [D loss: 0.635223, acc.: 61.72%] [G loss: 0.957514]\n",
      "epoch:16 step:15074 [D loss: 0.618259, acc.: 64.06%] [G loss: 0.816752]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15075 [D loss: 0.526819, acc.: 75.00%] [G loss: 1.055220]\n",
      "epoch:16 step:15076 [D loss: 0.644436, acc.: 64.84%] [G loss: 0.901875]\n",
      "epoch:16 step:15077 [D loss: 0.605552, acc.: 64.06%] [G loss: 1.069532]\n",
      "epoch:16 step:15078 [D loss: 0.606647, acc.: 70.31%] [G loss: 1.074899]\n",
      "epoch:16 step:15079 [D loss: 0.615138, acc.: 63.28%] [G loss: 1.001511]\n",
      "epoch:16 step:15080 [D loss: 0.559978, acc.: 69.53%] [G loss: 0.981455]\n",
      "epoch:16 step:15081 [D loss: 0.693965, acc.: 59.38%] [G loss: 0.945131]\n",
      "epoch:16 step:15082 [D loss: 0.600273, acc.: 72.66%] [G loss: 0.963352]\n",
      "epoch:16 step:15083 [D loss: 0.724177, acc.: 53.91%] [G loss: 1.059114]\n",
      "epoch:16 step:15084 [D loss: 0.573159, acc.: 67.97%] [G loss: 0.979027]\n",
      "epoch:16 step:15085 [D loss: 0.582254, acc.: 70.31%] [G loss: 1.012916]\n",
      "epoch:16 step:15086 [D loss: 0.576987, acc.: 71.88%] [G loss: 1.239526]\n",
      "epoch:16 step:15087 [D loss: 0.714575, acc.: 44.53%] [G loss: 0.922144]\n",
      "epoch:16 step:15088 [D loss: 0.756149, acc.: 45.31%] [G loss: 0.833094]\n",
      "epoch:16 step:15089 [D loss: 0.646864, acc.: 62.50%] [G loss: 1.047301]\n",
      "epoch:16 step:15090 [D loss: 0.712322, acc.: 57.03%] [G loss: 0.951133]\n",
      "epoch:16 step:15091 [D loss: 0.816180, acc.: 36.72%] [G loss: 0.879162]\n",
      "epoch:16 step:15092 [D loss: 0.553755, acc.: 77.34%] [G loss: 0.940739]\n",
      "epoch:16 step:15093 [D loss: 0.626123, acc.: 64.84%] [G loss: 0.844924]\n",
      "epoch:16 step:15094 [D loss: 0.590424, acc.: 67.97%] [G loss: 0.912503]\n",
      "epoch:16 step:15095 [D loss: 0.601971, acc.: 66.41%] [G loss: 1.122359]\n",
      "epoch:16 step:15096 [D loss: 0.533188, acc.: 79.69%] [G loss: 1.171888]\n",
      "epoch:16 step:15097 [D loss: 0.557197, acc.: 74.22%] [G loss: 1.038230]\n",
      "epoch:16 step:15098 [D loss: 0.566786, acc.: 75.78%] [G loss: 1.203182]\n",
      "epoch:16 step:15099 [D loss: 0.606954, acc.: 68.75%] [G loss: 1.298002]\n",
      "epoch:16 step:15100 [D loss: 0.532014, acc.: 74.22%] [G loss: 1.112069]\n",
      "epoch:16 step:15101 [D loss: 0.569528, acc.: 73.44%] [G loss: 1.069916]\n",
      "epoch:16 step:15102 [D loss: 0.706078, acc.: 58.59%] [G loss: 0.850500]\n",
      "epoch:16 step:15103 [D loss: 0.772070, acc.: 47.66%] [G loss: 0.872263]\n",
      "epoch:16 step:15104 [D loss: 0.529520, acc.: 79.69%] [G loss: 0.987119]\n",
      "epoch:16 step:15105 [D loss: 0.876059, acc.: 42.19%] [G loss: 0.772960]\n",
      "epoch:16 step:15106 [D loss: 0.695053, acc.: 57.81%] [G loss: 0.924005]\n",
      "epoch:16 step:15107 [D loss: 0.620677, acc.: 64.06%] [G loss: 0.983768]\n",
      "epoch:16 step:15108 [D loss: 0.644201, acc.: 67.19%] [G loss: 0.907904]\n",
      "epoch:16 step:15109 [D loss: 0.526142, acc.: 73.44%] [G loss: 0.990402]\n",
      "epoch:16 step:15110 [D loss: 0.586604, acc.: 70.31%] [G loss: 1.156960]\n",
      "epoch:16 step:15111 [D loss: 0.533672, acc.: 73.44%] [G loss: 0.951470]\n",
      "epoch:16 step:15112 [D loss: 0.684363, acc.: 57.81%] [G loss: 1.117682]\n",
      "epoch:16 step:15113 [D loss: 0.542300, acc.: 72.66%] [G loss: 1.061383]\n",
      "epoch:16 step:15114 [D loss: 0.474633, acc.: 83.59%] [G loss: 1.174388]\n",
      "epoch:16 step:15115 [D loss: 0.612215, acc.: 66.41%] [G loss: 1.021343]\n",
      "epoch:16 step:15116 [D loss: 0.617379, acc.: 67.19%] [G loss: 0.976426]\n",
      "epoch:16 step:15117 [D loss: 0.650905, acc.: 62.50%] [G loss: 1.078892]\n",
      "epoch:16 step:15118 [D loss: 0.658186, acc.: 60.16%] [G loss: 0.827956]\n",
      "epoch:16 step:15119 [D loss: 0.602012, acc.: 67.19%] [G loss: 0.924429]\n",
      "epoch:16 step:15120 [D loss: 0.620685, acc.: 61.72%] [G loss: 0.795849]\n",
      "epoch:16 step:15121 [D loss: 0.551947, acc.: 71.88%] [G loss: 0.986065]\n",
      "epoch:16 step:15122 [D loss: 0.513583, acc.: 72.66%] [G loss: 1.011771]\n",
      "epoch:16 step:15123 [D loss: 0.379325, acc.: 92.19%] [G loss: 1.132612]\n",
      "epoch:16 step:15124 [D loss: 0.573732, acc.: 71.88%] [G loss: 1.103078]\n",
      "epoch:16 step:15125 [D loss: 0.823905, acc.: 42.19%] [G loss: 0.867042]\n",
      "epoch:16 step:15126 [D loss: 0.714635, acc.: 54.69%] [G loss: 0.963450]\n",
      "epoch:16 step:15127 [D loss: 0.660415, acc.: 66.41%] [G loss: 0.787126]\n",
      "epoch:16 step:15128 [D loss: 0.629991, acc.: 66.41%] [G loss: 0.993165]\n",
      "epoch:16 step:15129 [D loss: 0.791378, acc.: 40.62%] [G loss: 0.870466]\n",
      "epoch:16 step:15130 [D loss: 0.793319, acc.: 51.56%] [G loss: 0.805132]\n",
      "epoch:16 step:15131 [D loss: 0.620027, acc.: 64.84%] [G loss: 0.902063]\n",
      "epoch:16 step:15132 [D loss: 0.657742, acc.: 61.72%] [G loss: 1.010903]\n",
      "epoch:16 step:15133 [D loss: 0.648897, acc.: 64.84%] [G loss: 1.036077]\n",
      "epoch:16 step:15134 [D loss: 0.603025, acc.: 69.53%] [G loss: 0.999496]\n",
      "epoch:16 step:15135 [D loss: 0.553650, acc.: 78.91%] [G loss: 1.173421]\n",
      "epoch:16 step:15136 [D loss: 0.479962, acc.: 80.47%] [G loss: 1.332472]\n",
      "epoch:16 step:15137 [D loss: 0.391387, acc.: 89.06%] [G loss: 1.403692]\n",
      "epoch:16 step:15138 [D loss: 0.568920, acc.: 70.31%] [G loss: 1.110768]\n",
      "epoch:16 step:15139 [D loss: 0.588164, acc.: 67.19%] [G loss: 1.174634]\n",
      "epoch:16 step:15140 [D loss: 0.714037, acc.: 56.25%] [G loss: 0.921633]\n",
      "epoch:16 step:15141 [D loss: 0.480060, acc.: 81.25%] [G loss: 1.261605]\n",
      "epoch:16 step:15142 [D loss: 0.515133, acc.: 71.09%] [G loss: 1.062940]\n",
      "epoch:16 step:15143 [D loss: 0.453410, acc.: 85.16%] [G loss: 1.226065]\n",
      "epoch:16 step:15144 [D loss: 0.473907, acc.: 81.25%] [G loss: 1.446620]\n",
      "epoch:16 step:15145 [D loss: 0.792038, acc.: 49.22%] [G loss: 0.922960]\n",
      "epoch:16 step:15146 [D loss: 0.735216, acc.: 54.69%] [G loss: 1.041724]\n",
      "epoch:16 step:15147 [D loss: 0.818664, acc.: 39.06%] [G loss: 0.910806]\n",
      "epoch:16 step:15148 [D loss: 0.826242, acc.: 40.62%] [G loss: 1.025104]\n",
      "epoch:16 step:15149 [D loss: 0.830388, acc.: 43.75%] [G loss: 0.959184]\n",
      "epoch:16 step:15150 [D loss: 0.663853, acc.: 60.94%] [G loss: 1.197498]\n",
      "epoch:16 step:15151 [D loss: 0.733147, acc.: 51.56%] [G loss: 0.783311]\n",
      "epoch:16 step:15152 [D loss: 0.832972, acc.: 42.97%] [G loss: 0.796388]\n",
      "epoch:16 step:15153 [D loss: 0.720757, acc.: 56.25%] [G loss: 0.983967]\n",
      "epoch:16 step:15154 [D loss: 0.685001, acc.: 52.34%] [G loss: 0.842295]\n",
      "epoch:16 step:15155 [D loss: 0.730802, acc.: 50.78%] [G loss: 1.014998]\n",
      "epoch:16 step:15156 [D loss: 0.715896, acc.: 53.91%] [G loss: 1.149412]\n",
      "epoch:16 step:15157 [D loss: 0.602830, acc.: 70.31%] [G loss: 1.095943]\n",
      "epoch:16 step:15158 [D loss: 0.575345, acc.: 71.09%] [G loss: 1.144992]\n",
      "epoch:16 step:15159 [D loss: 0.484406, acc.: 79.69%] [G loss: 1.105970]\n",
      "epoch:16 step:15160 [D loss: 0.480806, acc.: 80.47%] [G loss: 1.206802]\n",
      "epoch:16 step:15161 [D loss: 0.463107, acc.: 83.59%] [G loss: 1.191555]\n",
      "epoch:16 step:15162 [D loss: 0.685391, acc.: 57.03%] [G loss: 1.030008]\n",
      "epoch:16 step:15163 [D loss: 0.572891, acc.: 71.88%] [G loss: 0.979091]\n",
      "epoch:16 step:15164 [D loss: 0.490563, acc.: 82.03%] [G loss: 1.172410]\n",
      "epoch:16 step:15165 [D loss: 0.707333, acc.: 56.25%] [G loss: 1.022714]\n",
      "epoch:16 step:15166 [D loss: 0.725019, acc.: 50.78%] [G loss: 1.018025]\n",
      "epoch:16 step:15167 [D loss: 0.758784, acc.: 51.56%] [G loss: 0.881185]\n",
      "epoch:16 step:15168 [D loss: 0.596922, acc.: 66.41%] [G loss: 1.088588]\n",
      "epoch:16 step:15169 [D loss: 0.726983, acc.: 51.56%] [G loss: 1.125688]\n",
      "epoch:16 step:15170 [D loss: 0.677572, acc.: 56.25%] [G loss: 0.970593]\n",
      "epoch:16 step:15171 [D loss: 0.725297, acc.: 47.66%] [G loss: 1.001830]\n",
      "epoch:16 step:15172 [D loss: 0.657745, acc.: 56.25%] [G loss: 1.071276]\n",
      "epoch:16 step:15173 [D loss: 0.543588, acc.: 75.78%] [G loss: 1.001473]\n",
      "epoch:16 step:15174 [D loss: 0.693598, acc.: 56.25%] [G loss: 0.913306]\n",
      "epoch:16 step:15175 [D loss: 0.747291, acc.: 50.78%] [G loss: 0.951268]\n",
      "epoch:16 step:15176 [D loss: 0.808029, acc.: 46.09%] [G loss: 0.722690]\n",
      "epoch:16 step:15177 [D loss: 0.808892, acc.: 42.97%] [G loss: 0.985415]\n",
      "epoch:16 step:15178 [D loss: 0.949697, acc.: 30.47%] [G loss: 0.792012]\n",
      "epoch:16 step:15179 [D loss: 0.661116, acc.: 59.38%] [G loss: 1.024108]\n",
      "epoch:16 step:15180 [D loss: 0.771157, acc.: 53.12%] [G loss: 0.956429]\n",
      "epoch:16 step:15181 [D loss: 0.748758, acc.: 48.44%] [G loss: 0.926916]\n",
      "epoch:16 step:15182 [D loss: 0.658315, acc.: 65.62%] [G loss: 0.954288]\n",
      "epoch:16 step:15183 [D loss: 0.679969, acc.: 61.72%] [G loss: 1.130516]\n",
      "epoch:16 step:15184 [D loss: 0.476715, acc.: 82.81%] [G loss: 1.223900]\n",
      "epoch:16 step:15185 [D loss: 0.733800, acc.: 54.69%] [G loss: 0.857572]\n",
      "epoch:16 step:15186 [D loss: 0.576944, acc.: 75.00%] [G loss: 1.077767]\n",
      "epoch:16 step:15187 [D loss: 0.672126, acc.: 58.59%] [G loss: 0.941620]\n",
      "epoch:16 step:15188 [D loss: 0.744474, acc.: 53.91%] [G loss: 0.860374]\n",
      "epoch:16 step:15189 [D loss: 0.746369, acc.: 46.88%] [G loss: 0.769147]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15190 [D loss: 0.683380, acc.: 55.47%] [G loss: 0.903748]\n",
      "epoch:16 step:15191 [D loss: 0.723699, acc.: 50.00%] [G loss: 0.927915]\n",
      "epoch:16 step:15192 [D loss: 0.743897, acc.: 50.78%] [G loss: 0.966464]\n",
      "epoch:16 step:15193 [D loss: 0.535171, acc.: 75.78%] [G loss: 1.234512]\n",
      "epoch:16 step:15194 [D loss: 0.765796, acc.: 46.88%] [G loss: 1.042860]\n",
      "epoch:16 step:15195 [D loss: 0.821926, acc.: 36.72%] [G loss: 0.916104]\n",
      "epoch:16 step:15196 [D loss: 0.649111, acc.: 63.28%] [G loss: 1.041872]\n",
      "epoch:16 step:15197 [D loss: 0.680507, acc.: 61.72%] [G loss: 0.911973]\n",
      "epoch:16 step:15198 [D loss: 0.678049, acc.: 62.50%] [G loss: 0.819880]\n",
      "epoch:16 step:15199 [D loss: 0.592739, acc.: 70.31%] [G loss: 0.907607]\n",
      "epoch:16 step:15200 [D loss: 0.676659, acc.: 61.72%] [G loss: 1.014698]\n",
      "##############\n",
      "[2.2887955  1.44053779 5.4651054  3.99315192 3.12288277 5.22603243\n",
      " 3.86352914 4.54252615 3.95936011 3.56864165]\n",
      "##########\n",
      "epoch:16 step:15201 [D loss: 0.569574, acc.: 67.19%] [G loss: 1.039096]\n",
      "epoch:16 step:15202 [D loss: 0.740266, acc.: 48.44%] [G loss: 0.981821]\n",
      "epoch:16 step:15203 [D loss: 0.567948, acc.: 74.22%] [G loss: 0.981331]\n",
      "epoch:16 step:15204 [D loss: 0.648566, acc.: 63.28%] [G loss: 1.176134]\n",
      "epoch:16 step:15205 [D loss: 0.554485, acc.: 75.00%] [G loss: 1.080035]\n",
      "epoch:16 step:15206 [D loss: 0.728655, acc.: 51.56%] [G loss: 0.979734]\n",
      "epoch:16 step:15207 [D loss: 0.612541, acc.: 66.41%] [G loss: 1.275585]\n",
      "epoch:16 step:15208 [D loss: 0.642364, acc.: 62.50%] [G loss: 1.051499]\n",
      "epoch:16 step:15209 [D loss: 0.690544, acc.: 54.69%] [G loss: 0.992004]\n",
      "epoch:16 step:15210 [D loss: 0.600220, acc.: 64.84%] [G loss: 0.996214]\n",
      "epoch:16 step:15211 [D loss: 0.597709, acc.: 64.06%] [G loss: 1.038141]\n",
      "epoch:16 step:15212 [D loss: 0.458355, acc.: 83.59%] [G loss: 1.084367]\n",
      "epoch:16 step:15213 [D loss: 0.395199, acc.: 86.72%] [G loss: 1.083398]\n",
      "epoch:16 step:15214 [D loss: 0.493857, acc.: 81.25%] [G loss: 1.225733]\n",
      "epoch:16 step:15215 [D loss: 0.431125, acc.: 89.06%] [G loss: 1.175119]\n",
      "epoch:16 step:15216 [D loss: 0.759031, acc.: 47.66%] [G loss: 1.254980]\n",
      "epoch:16 step:15217 [D loss: 0.733111, acc.: 53.12%] [G loss: 1.097887]\n",
      "epoch:16 step:15218 [D loss: 0.721813, acc.: 51.56%] [G loss: 0.801253]\n",
      "epoch:16 step:15219 [D loss: 0.611600, acc.: 64.06%] [G loss: 1.104779]\n",
      "epoch:16 step:15220 [D loss: 0.694580, acc.: 52.34%] [G loss: 0.960862]\n",
      "epoch:16 step:15221 [D loss: 0.735509, acc.: 50.00%] [G loss: 0.828095]\n",
      "epoch:16 step:15222 [D loss: 0.371082, acc.: 84.38%] [G loss: 1.253788]\n",
      "epoch:16 step:15223 [D loss: 0.394921, acc.: 90.62%] [G loss: 1.175807]\n",
      "epoch:16 step:15224 [D loss: 0.459150, acc.: 80.47%] [G loss: 1.182158]\n",
      "epoch:16 step:15225 [D loss: 0.754781, acc.: 46.88%] [G loss: 0.994514]\n",
      "epoch:16 step:15226 [D loss: 0.831229, acc.: 43.75%] [G loss: 0.956575]\n",
      "epoch:16 step:15227 [D loss: 0.691730, acc.: 55.47%] [G loss: 0.910323]\n",
      "epoch:16 step:15228 [D loss: 0.728371, acc.: 53.91%] [G loss: 0.915602]\n",
      "epoch:16 step:15229 [D loss: 0.751407, acc.: 50.00%] [G loss: 0.870091]\n",
      "epoch:16 step:15230 [D loss: 0.587011, acc.: 67.97%] [G loss: 1.238063]\n",
      "epoch:16 step:15231 [D loss: 0.757198, acc.: 50.00%] [G loss: 0.854006]\n",
      "epoch:16 step:15232 [D loss: 0.695549, acc.: 60.16%] [G loss: 1.048761]\n",
      "epoch:16 step:15233 [D loss: 0.707596, acc.: 53.91%] [G loss: 0.841107]\n",
      "epoch:16 step:15234 [D loss: 0.753540, acc.: 46.09%] [G loss: 0.884956]\n",
      "epoch:16 step:15235 [D loss: 0.667017, acc.: 57.81%] [G loss: 0.982843]\n",
      "epoch:16 step:15236 [D loss: 0.644328, acc.: 60.94%] [G loss: 0.999065]\n",
      "epoch:16 step:15237 [D loss: 0.544563, acc.: 73.44%] [G loss: 1.210175]\n",
      "epoch:16 step:15238 [D loss: 0.553360, acc.: 74.22%] [G loss: 1.021402]\n",
      "epoch:16 step:15239 [D loss: 0.517925, acc.: 72.66%] [G loss: 1.270478]\n",
      "epoch:16 step:15240 [D loss: 0.511992, acc.: 76.56%] [G loss: 1.130497]\n",
      "epoch:16 step:15241 [D loss: 0.640197, acc.: 65.62%] [G loss: 1.217525]\n",
      "epoch:16 step:15242 [D loss: 0.591041, acc.: 67.97%] [G loss: 1.320670]\n",
      "epoch:16 step:15243 [D loss: 0.726434, acc.: 50.00%] [G loss: 1.037565]\n",
      "epoch:16 step:15244 [D loss: 0.546034, acc.: 75.78%] [G loss: 1.069639]\n",
      "epoch:16 step:15245 [D loss: 0.596238, acc.: 68.75%] [G loss: 1.175034]\n",
      "epoch:16 step:15246 [D loss: 0.628866, acc.: 66.41%] [G loss: 0.939052]\n",
      "epoch:16 step:15247 [D loss: 0.701742, acc.: 56.25%] [G loss: 0.969481]\n",
      "epoch:16 step:15248 [D loss: 0.794890, acc.: 48.44%] [G loss: 0.851952]\n",
      "epoch:16 step:15249 [D loss: 0.665066, acc.: 60.94%] [G loss: 1.082040]\n",
      "epoch:16 step:15250 [D loss: 0.666344, acc.: 58.59%] [G loss: 0.857398]\n",
      "epoch:16 step:15251 [D loss: 0.677753, acc.: 55.47%] [G loss: 1.017965]\n",
      "epoch:16 step:15252 [D loss: 0.692261, acc.: 53.91%] [G loss: 1.158611]\n",
      "epoch:16 step:15253 [D loss: 0.644724, acc.: 64.84%] [G loss: 1.048134]\n",
      "epoch:16 step:15254 [D loss: 0.646460, acc.: 67.97%] [G loss: 1.020997]\n",
      "epoch:16 step:15255 [D loss: 0.703638, acc.: 55.47%] [G loss: 0.952776]\n",
      "epoch:16 step:15256 [D loss: 0.677345, acc.: 57.81%] [G loss: 0.994959]\n",
      "epoch:16 step:15257 [D loss: 0.634742, acc.: 64.84%] [G loss: 1.089774]\n",
      "epoch:16 step:15258 [D loss: 0.731320, acc.: 47.66%] [G loss: 0.984988]\n",
      "epoch:16 step:15259 [D loss: 0.578345, acc.: 71.88%] [G loss: 0.920114]\n",
      "epoch:16 step:15260 [D loss: 0.607928, acc.: 65.62%] [G loss: 0.950805]\n",
      "epoch:16 step:15261 [D loss: 0.689570, acc.: 56.25%] [G loss: 0.930975]\n",
      "epoch:16 step:15262 [D loss: 0.638288, acc.: 61.72%] [G loss: 0.905816]\n",
      "epoch:16 step:15263 [D loss: 0.646164, acc.: 60.94%] [G loss: 0.922587]\n",
      "epoch:16 step:15264 [D loss: 0.556629, acc.: 69.53%] [G loss: 1.038650]\n",
      "epoch:16 step:15265 [D loss: 0.665447, acc.: 66.41%] [G loss: 1.008492]\n",
      "epoch:16 step:15266 [D loss: 0.659490, acc.: 62.50%] [G loss: 0.886891]\n",
      "epoch:16 step:15267 [D loss: 0.637908, acc.: 66.41%] [G loss: 0.912432]\n",
      "epoch:16 step:15268 [D loss: 0.639831, acc.: 64.06%] [G loss: 1.019413]\n",
      "epoch:16 step:15269 [D loss: 0.751418, acc.: 44.53%] [G loss: 0.818224]\n",
      "epoch:16 step:15270 [D loss: 0.603520, acc.: 71.88%] [G loss: 0.997209]\n",
      "epoch:16 step:15271 [D loss: 0.550693, acc.: 70.31%] [G loss: 0.977923]\n",
      "epoch:16 step:15272 [D loss: 0.587553, acc.: 69.53%] [G loss: 1.048341]\n",
      "epoch:16 step:15273 [D loss: 0.759343, acc.: 47.66%] [G loss: 1.103732]\n",
      "epoch:16 step:15274 [D loss: 0.656490, acc.: 60.94%] [G loss: 1.112319]\n",
      "epoch:16 step:15275 [D loss: 0.711468, acc.: 53.91%] [G loss: 0.818439]\n",
      "epoch:16 step:15276 [D loss: 0.585919, acc.: 71.88%] [G loss: 1.028030]\n",
      "epoch:16 step:15277 [D loss: 0.550668, acc.: 76.56%] [G loss: 0.980280]\n",
      "epoch:16 step:15278 [D loss: 0.523593, acc.: 78.91%] [G loss: 1.167732]\n",
      "epoch:16 step:15279 [D loss: 0.635267, acc.: 65.62%] [G loss: 1.017571]\n",
      "epoch:16 step:15280 [D loss: 0.695923, acc.: 58.59%] [G loss: 0.945035]\n",
      "epoch:16 step:15281 [D loss: 0.550197, acc.: 75.00%] [G loss: 1.170134]\n",
      "epoch:16 step:15282 [D loss: 0.642711, acc.: 69.53%] [G loss: 1.167165]\n",
      "epoch:16 step:15283 [D loss: 0.658159, acc.: 62.50%] [G loss: 0.820450]\n",
      "epoch:16 step:15284 [D loss: 0.643404, acc.: 64.06%] [G loss: 1.092229]\n",
      "epoch:16 step:15285 [D loss: 0.633792, acc.: 60.16%] [G loss: 1.018465]\n",
      "epoch:16 step:15286 [D loss: 0.678017, acc.: 53.12%] [G loss: 1.052851]\n",
      "epoch:16 step:15287 [D loss: 0.888398, acc.: 35.94%] [G loss: 1.010091]\n",
      "epoch:16 step:15288 [D loss: 0.597759, acc.: 72.66%] [G loss: 1.060606]\n",
      "epoch:16 step:15289 [D loss: 0.668392, acc.: 62.50%] [G loss: 1.123782]\n",
      "epoch:16 step:15290 [D loss: 0.531627, acc.: 74.22%] [G loss: 1.160913]\n",
      "epoch:16 step:15291 [D loss: 0.611277, acc.: 64.06%] [G loss: 0.781593]\n",
      "epoch:16 step:15292 [D loss: 0.550936, acc.: 74.22%] [G loss: 1.090979]\n",
      "epoch:16 step:15293 [D loss: 0.754993, acc.: 49.22%] [G loss: 0.988884]\n",
      "epoch:16 step:15294 [D loss: 0.587622, acc.: 67.97%] [G loss: 0.994060]\n",
      "epoch:16 step:15295 [D loss: 0.521633, acc.: 77.34%] [G loss: 1.127890]\n",
      "epoch:16 step:15296 [D loss: 0.745881, acc.: 45.31%] [G loss: 0.909807]\n",
      "epoch:16 step:15297 [D loss: 0.711493, acc.: 58.59%] [G loss: 0.955279]\n",
      "epoch:16 step:15298 [D loss: 0.726819, acc.: 49.22%] [G loss: 0.905298]\n",
      "epoch:16 step:15299 [D loss: 0.591184, acc.: 75.78%] [G loss: 1.042977]\n",
      "epoch:16 step:15300 [D loss: 0.673661, acc.: 60.16%] [G loss: 1.044034]\n",
      "epoch:16 step:15301 [D loss: 0.740922, acc.: 42.97%] [G loss: 1.022107]\n",
      "epoch:16 step:15302 [D loss: 0.639807, acc.: 60.94%] [G loss: 1.140481]\n",
      "epoch:16 step:15303 [D loss: 0.582048, acc.: 69.53%] [G loss: 1.057144]\n",
      "epoch:16 step:15304 [D loss: 0.565509, acc.: 71.09%] [G loss: 0.880654]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15305 [D loss: 0.528629, acc.: 75.00%] [G loss: 1.167626]\n",
      "epoch:16 step:15306 [D loss: 0.478563, acc.: 79.69%] [G loss: 1.165135]\n",
      "epoch:16 step:15307 [D loss: 0.515904, acc.: 79.69%] [G loss: 1.168859]\n",
      "epoch:16 step:15308 [D loss: 0.776660, acc.: 44.53%] [G loss: 0.868265]\n",
      "epoch:16 step:15309 [D loss: 0.716860, acc.: 50.78%] [G loss: 0.881104]\n",
      "epoch:16 step:15310 [D loss: 0.687391, acc.: 54.69%] [G loss: 0.955917]\n",
      "epoch:16 step:15311 [D loss: 0.702004, acc.: 53.12%] [G loss: 0.899065]\n",
      "epoch:16 step:15312 [D loss: 0.664281, acc.: 57.03%] [G loss: 0.937550]\n",
      "epoch:16 step:15313 [D loss: 0.629428, acc.: 67.97%] [G loss: 0.916338]\n",
      "epoch:16 step:15314 [D loss: 0.579004, acc.: 68.75%] [G loss: 1.032602]\n",
      "epoch:16 step:15315 [D loss: 0.714738, acc.: 50.00%] [G loss: 0.949253]\n",
      "epoch:16 step:15316 [D loss: 0.765988, acc.: 48.44%] [G loss: 0.895288]\n",
      "epoch:16 step:15317 [D loss: 0.675251, acc.: 60.16%] [G loss: 1.020754]\n",
      "epoch:16 step:15318 [D loss: 0.633300, acc.: 65.62%] [G loss: 0.858251]\n",
      "epoch:16 step:15319 [D loss: 0.535261, acc.: 76.56%] [G loss: 1.012675]\n",
      "epoch:16 step:15320 [D loss: 0.545324, acc.: 68.75%] [G loss: 1.019939]\n",
      "epoch:16 step:15321 [D loss: 0.618229, acc.: 63.28%] [G loss: 1.144802]\n",
      "epoch:16 step:15322 [D loss: 0.665466, acc.: 66.41%] [G loss: 1.055510]\n",
      "epoch:16 step:15323 [D loss: 0.739327, acc.: 50.00%] [G loss: 0.824118]\n",
      "epoch:16 step:15324 [D loss: 0.686657, acc.: 55.47%] [G loss: 0.884173]\n",
      "epoch:16 step:15325 [D loss: 0.716093, acc.: 53.91%] [G loss: 0.944990]\n",
      "epoch:16 step:15326 [D loss: 0.586694, acc.: 68.75%] [G loss: 0.947190]\n",
      "epoch:16 step:15327 [D loss: 0.643264, acc.: 60.94%] [G loss: 1.003003]\n",
      "epoch:16 step:15328 [D loss: 0.578749, acc.: 65.62%] [G loss: 1.057840]\n",
      "epoch:16 step:15329 [D loss: 0.699394, acc.: 58.59%] [G loss: 0.917441]\n",
      "epoch:16 step:15330 [D loss: 0.682223, acc.: 53.12%] [G loss: 1.004961]\n",
      "epoch:16 step:15331 [D loss: 0.619990, acc.: 64.06%] [G loss: 1.054468]\n",
      "epoch:16 step:15332 [D loss: 0.616756, acc.: 64.84%] [G loss: 0.862135]\n",
      "epoch:16 step:15333 [D loss: 0.564363, acc.: 73.44%] [G loss: 1.036567]\n",
      "epoch:16 step:15334 [D loss: 0.455879, acc.: 86.72%] [G loss: 1.109523]\n",
      "epoch:16 step:15335 [D loss: 0.485955, acc.: 75.78%] [G loss: 0.912399]\n",
      "epoch:16 step:15336 [D loss: 0.568885, acc.: 71.88%] [G loss: 1.021790]\n",
      "epoch:16 step:15337 [D loss: 0.471105, acc.: 82.03%] [G loss: 1.136591]\n",
      "epoch:16 step:15338 [D loss: 0.328415, acc.: 96.09%] [G loss: 1.418558]\n",
      "epoch:16 step:15339 [D loss: 0.436463, acc.: 83.59%] [G loss: 1.137846]\n",
      "epoch:16 step:15340 [D loss: 0.714095, acc.: 56.25%] [G loss: 1.174897]\n",
      "epoch:16 step:15341 [D loss: 0.871534, acc.: 38.28%] [G loss: 1.122919]\n",
      "epoch:16 step:15342 [D loss: 0.754487, acc.: 47.66%] [G loss: 0.977444]\n",
      "epoch:16 step:15343 [D loss: 0.601760, acc.: 67.19%] [G loss: 0.925694]\n",
      "epoch:16 step:15344 [D loss: 0.473982, acc.: 82.81%] [G loss: 1.196746]\n",
      "epoch:16 step:15345 [D loss: 0.550367, acc.: 77.34%] [G loss: 0.968086]\n",
      "epoch:16 step:15346 [D loss: 0.462924, acc.: 82.81%] [G loss: 1.238481]\n",
      "epoch:16 step:15347 [D loss: 0.644454, acc.: 64.06%] [G loss: 1.102385]\n",
      "epoch:16 step:15348 [D loss: 0.627370, acc.: 64.84%] [G loss: 1.079435]\n",
      "epoch:16 step:15349 [D loss: 0.558672, acc.: 73.44%] [G loss: 1.028840]\n",
      "epoch:16 step:15350 [D loss: 0.580573, acc.: 72.66%] [G loss: 1.116351]\n",
      "epoch:16 step:15351 [D loss: 0.616666, acc.: 65.62%] [G loss: 1.026431]\n",
      "epoch:16 step:15352 [D loss: 0.536765, acc.: 71.88%] [G loss: 1.287970]\n",
      "epoch:16 step:15353 [D loss: 0.678490, acc.: 61.72%] [G loss: 1.179238]\n",
      "epoch:16 step:15354 [D loss: 0.707644, acc.: 52.34%] [G loss: 1.076422]\n",
      "epoch:16 step:15355 [D loss: 0.889760, acc.: 31.25%] [G loss: 0.698977]\n",
      "epoch:16 step:15356 [D loss: 0.678764, acc.: 61.72%] [G loss: 1.074339]\n",
      "epoch:16 step:15357 [D loss: 0.809836, acc.: 41.41%] [G loss: 0.755406]\n",
      "epoch:16 step:15358 [D loss: 0.535827, acc.: 75.00%] [G loss: 1.233343]\n",
      "epoch:16 step:15359 [D loss: 0.597186, acc.: 71.09%] [G loss: 1.167318]\n",
      "epoch:16 step:15360 [D loss: 0.566736, acc.: 74.22%] [G loss: 1.237542]\n",
      "epoch:16 step:15361 [D loss: 0.637788, acc.: 64.84%] [G loss: 1.141222]\n",
      "epoch:16 step:15362 [D loss: 0.548192, acc.: 79.69%] [G loss: 1.083039]\n",
      "epoch:16 step:15363 [D loss: 0.610450, acc.: 64.84%] [G loss: 0.862738]\n",
      "epoch:16 step:15364 [D loss: 0.688789, acc.: 55.47%] [G loss: 0.921931]\n",
      "epoch:16 step:15365 [D loss: 0.682669, acc.: 57.03%] [G loss: 0.894038]\n",
      "epoch:16 step:15366 [D loss: 0.747525, acc.: 45.31%] [G loss: 0.820548]\n",
      "epoch:16 step:15367 [D loss: 0.760924, acc.: 50.00%] [G loss: 0.823514]\n",
      "epoch:16 step:15368 [D loss: 0.690655, acc.: 63.28%] [G loss: 0.992618]\n",
      "epoch:16 step:15369 [D loss: 0.704973, acc.: 52.34%] [G loss: 0.949897]\n",
      "epoch:16 step:15370 [D loss: 0.576759, acc.: 72.66%] [G loss: 1.017514]\n",
      "epoch:16 step:15371 [D loss: 0.615180, acc.: 64.06%] [G loss: 1.026227]\n",
      "epoch:16 step:15372 [D loss: 0.635523, acc.: 67.19%] [G loss: 0.990187]\n",
      "epoch:16 step:15373 [D loss: 0.575831, acc.: 71.88%] [G loss: 0.998201]\n",
      "epoch:16 step:15374 [D loss: 0.596155, acc.: 70.31%] [G loss: 1.105686]\n",
      "epoch:16 step:15375 [D loss: 0.711802, acc.: 51.56%] [G loss: 0.887108]\n",
      "epoch:16 step:15376 [D loss: 0.665128, acc.: 61.72%] [G loss: 0.911466]\n",
      "epoch:16 step:15377 [D loss: 0.643487, acc.: 64.84%] [G loss: 0.888938]\n",
      "epoch:16 step:15378 [D loss: 0.656736, acc.: 58.59%] [G loss: 0.982750]\n",
      "epoch:16 step:15379 [D loss: 0.683933, acc.: 54.69%] [G loss: 0.818506]\n",
      "epoch:16 step:15380 [D loss: 0.671033, acc.: 57.03%] [G loss: 0.932885]\n",
      "epoch:16 step:15381 [D loss: 0.656067, acc.: 59.38%] [G loss: 1.055263]\n",
      "epoch:16 step:15382 [D loss: 0.583475, acc.: 75.78%] [G loss: 1.039686]\n",
      "epoch:16 step:15383 [D loss: 0.567257, acc.: 75.78%] [G loss: 1.040348]\n",
      "epoch:16 step:15384 [D loss: 0.616207, acc.: 67.97%] [G loss: 1.090489]\n",
      "epoch:16 step:15385 [D loss: 0.627654, acc.: 67.19%] [G loss: 0.958041]\n",
      "epoch:16 step:15386 [D loss: 0.492486, acc.: 79.69%] [G loss: 1.325991]\n",
      "epoch:16 step:15387 [D loss: 0.588106, acc.: 67.19%] [G loss: 1.075217]\n",
      "epoch:16 step:15388 [D loss: 0.496072, acc.: 79.69%] [G loss: 0.932600]\n",
      "epoch:16 step:15389 [D loss: 0.443213, acc.: 85.16%] [G loss: 1.158602]\n",
      "epoch:16 step:15390 [D loss: 0.365106, acc.: 91.41%] [G loss: 1.183801]\n",
      "epoch:16 step:15391 [D loss: 0.432754, acc.: 85.94%] [G loss: 1.436173]\n",
      "epoch:16 step:15392 [D loss: 0.447966, acc.: 85.94%] [G loss: 1.488294]\n",
      "epoch:16 step:15393 [D loss: 0.435548, acc.: 85.94%] [G loss: 1.104705]\n",
      "epoch:16 step:15394 [D loss: 0.493952, acc.: 77.34%] [G loss: 1.059046]\n",
      "epoch:16 step:15395 [D loss: 0.538423, acc.: 76.56%] [G loss: 1.266260]\n",
      "epoch:16 step:15396 [D loss: 0.525545, acc.: 75.00%] [G loss: 1.041739]\n",
      "epoch:16 step:15397 [D loss: 0.416805, acc.: 87.50%] [G loss: 1.405990]\n",
      "epoch:16 step:15398 [D loss: 0.506566, acc.: 80.47%] [G loss: 1.224476]\n",
      "epoch:16 step:15399 [D loss: 0.582900, acc.: 67.97%] [G loss: 1.191470]\n",
      "epoch:16 step:15400 [D loss: 0.579771, acc.: 70.31%] [G loss: 1.132546]\n",
      "##############\n",
      "[2.52760451 1.91723433 5.42302721 4.49230262 3.27546053 5.16558319\n",
      " 4.20220051 4.69433334 3.92069905 3.73083554]\n",
      "##########\n",
      "epoch:16 step:15401 [D loss: 0.761301, acc.: 51.56%] [G loss: 0.824547]\n",
      "epoch:16 step:15402 [D loss: 0.734937, acc.: 48.44%] [G loss: 0.934251]\n",
      "epoch:16 step:15403 [D loss: 1.018676, acc.: 21.09%] [G loss: 0.842895]\n",
      "epoch:16 step:15404 [D loss: 0.793410, acc.: 45.31%] [G loss: 1.066842]\n",
      "epoch:16 step:15405 [D loss: 0.879759, acc.: 34.38%] [G loss: 0.733377]\n",
      "epoch:16 step:15406 [D loss: 1.006854, acc.: 32.03%] [G loss: 0.735048]\n",
      "epoch:16 step:15407 [D loss: 0.852700, acc.: 44.53%] [G loss: 0.959117]\n",
      "epoch:16 step:15408 [D loss: 0.779755, acc.: 44.53%] [G loss: 0.938260]\n",
      "epoch:16 step:15409 [D loss: 0.665494, acc.: 58.59%] [G loss: 0.977513]\n",
      "epoch:16 step:15410 [D loss: 0.737666, acc.: 56.25%] [G loss: 0.884252]\n",
      "epoch:16 step:15411 [D loss: 0.669849, acc.: 58.59%] [G loss: 0.912707]\n",
      "epoch:16 step:15412 [D loss: 0.716079, acc.: 54.69%] [G loss: 1.124692]\n",
      "epoch:16 step:15413 [D loss: 0.709813, acc.: 54.69%] [G loss: 1.106928]\n",
      "epoch:16 step:15414 [D loss: 0.747064, acc.: 49.22%] [G loss: 1.135743]\n",
      "epoch:16 step:15415 [D loss: 0.764821, acc.: 46.88%] [G loss: 0.982831]\n",
      "epoch:16 step:15416 [D loss: 0.696232, acc.: 54.69%] [G loss: 0.964321]\n",
      "epoch:16 step:15417 [D loss: 0.709280, acc.: 55.47%] [G loss: 1.242820]\n",
      "epoch:16 step:15418 [D loss: 0.706529, acc.: 55.47%] [G loss: 0.927054]\n",
      "epoch:16 step:15419 [D loss: 0.708170, acc.: 56.25%] [G loss: 1.127896]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15420 [D loss: 0.645838, acc.: 60.16%] [G loss: 1.119424]\n",
      "epoch:16 step:15421 [D loss: 0.670624, acc.: 60.16%] [G loss: 1.090954]\n",
      "epoch:16 step:15422 [D loss: 0.676949, acc.: 58.59%] [G loss: 0.893529]\n",
      "epoch:16 step:15423 [D loss: 0.648448, acc.: 64.06%] [G loss: 1.232341]\n",
      "epoch:16 step:15424 [D loss: 0.587719, acc.: 74.22%] [G loss: 1.030106]\n",
      "epoch:16 step:15425 [D loss: 0.581136, acc.: 68.75%] [G loss: 1.222509]\n",
      "epoch:16 step:15426 [D loss: 0.549341, acc.: 74.22%] [G loss: 1.255731]\n",
      "epoch:16 step:15427 [D loss: 0.532432, acc.: 76.56%] [G loss: 1.310293]\n",
      "epoch:16 step:15428 [D loss: 0.520362, acc.: 78.91%] [G loss: 1.176885]\n",
      "epoch:16 step:15429 [D loss: 0.768976, acc.: 50.00%] [G loss: 1.267113]\n",
      "epoch:16 step:15430 [D loss: 0.745531, acc.: 51.56%] [G loss: 1.120603]\n",
      "epoch:16 step:15431 [D loss: 0.706808, acc.: 59.38%] [G loss: 0.963129]\n",
      "epoch:16 step:15432 [D loss: 0.640457, acc.: 66.41%] [G loss: 0.985387]\n",
      "epoch:16 step:15433 [D loss: 0.691057, acc.: 58.59%] [G loss: 1.106616]\n",
      "epoch:16 step:15434 [D loss: 0.550376, acc.: 76.56%] [G loss: 1.169785]\n",
      "epoch:16 step:15435 [D loss: 0.573565, acc.: 68.75%] [G loss: 1.040643]\n",
      "epoch:16 step:15436 [D loss: 0.595992, acc.: 67.97%] [G loss: 1.160492]\n",
      "epoch:16 step:15437 [D loss: 0.644868, acc.: 67.97%] [G loss: 0.954391]\n",
      "epoch:16 step:15438 [D loss: 0.705437, acc.: 59.38%] [G loss: 1.180078]\n",
      "epoch:16 step:15439 [D loss: 0.639343, acc.: 63.28%] [G loss: 0.860011]\n",
      "epoch:16 step:15440 [D loss: 0.564783, acc.: 74.22%] [G loss: 1.073627]\n",
      "epoch:16 step:15441 [D loss: 0.611111, acc.: 69.53%] [G loss: 1.021178]\n",
      "epoch:16 step:15442 [D loss: 0.637657, acc.: 66.41%] [G loss: 1.158079]\n",
      "epoch:16 step:15443 [D loss: 0.508750, acc.: 80.47%] [G loss: 1.118081]\n",
      "epoch:16 step:15444 [D loss: 0.564535, acc.: 71.88%] [G loss: 1.076709]\n",
      "epoch:16 step:15445 [D loss: 0.536568, acc.: 73.44%] [G loss: 1.152241]\n",
      "epoch:16 step:15446 [D loss: 0.486111, acc.: 81.25%] [G loss: 1.231290]\n",
      "epoch:16 step:15447 [D loss: 0.638634, acc.: 64.84%] [G loss: 1.055604]\n",
      "epoch:16 step:15448 [D loss: 0.513244, acc.: 77.34%] [G loss: 1.161558]\n",
      "epoch:16 step:15449 [D loss: 0.481961, acc.: 77.34%] [G loss: 1.143514]\n",
      "epoch:16 step:15450 [D loss: 0.954070, acc.: 37.50%] [G loss: 0.926116]\n",
      "epoch:16 step:15451 [D loss: 0.791255, acc.: 42.19%] [G loss: 1.113503]\n",
      "epoch:16 step:15452 [D loss: 1.021667, acc.: 19.53%] [G loss: 0.893337]\n",
      "epoch:16 step:15453 [D loss: 0.810201, acc.: 42.19%] [G loss: 1.266552]\n",
      "epoch:16 step:15454 [D loss: 0.625192, acc.: 67.97%] [G loss: 1.347682]\n",
      "epoch:16 step:15455 [D loss: 0.672681, acc.: 57.81%] [G loss: 1.282188]\n",
      "epoch:16 step:15456 [D loss: 0.666632, acc.: 58.59%] [G loss: 1.063019]\n",
      "epoch:16 step:15457 [D loss: 0.652899, acc.: 65.62%] [G loss: 1.106316]\n",
      "epoch:16 step:15458 [D loss: 0.666472, acc.: 61.72%] [G loss: 1.018882]\n",
      "epoch:16 step:15459 [D loss: 0.635560, acc.: 64.06%] [G loss: 0.973023]\n",
      "epoch:16 step:15460 [D loss: 0.627258, acc.: 67.19%] [G loss: 0.881059]\n",
      "epoch:16 step:15461 [D loss: 0.633944, acc.: 59.38%] [G loss: 0.910513]\n",
      "epoch:16 step:15462 [D loss: 0.566740, acc.: 71.09%] [G loss: 0.977281]\n",
      "epoch:16 step:15463 [D loss: 0.483001, acc.: 75.78%] [G loss: 1.105176]\n",
      "epoch:16 step:15464 [D loss: 0.615237, acc.: 63.28%] [G loss: 0.957909]\n",
      "epoch:16 step:15465 [D loss: 0.613311, acc.: 68.75%] [G loss: 1.106362]\n",
      "epoch:16 step:15466 [D loss: 0.519300, acc.: 79.69%] [G loss: 1.085694]\n",
      "epoch:16 step:15467 [D loss: 0.627919, acc.: 68.75%] [G loss: 1.019271]\n",
      "epoch:16 step:15468 [D loss: 0.696867, acc.: 55.47%] [G loss: 1.202893]\n",
      "epoch:16 step:15469 [D loss: 0.689319, acc.: 58.59%] [G loss: 0.992042]\n",
      "epoch:16 step:15470 [D loss: 0.687944, acc.: 60.94%] [G loss: 1.107582]\n",
      "epoch:16 step:15471 [D loss: 0.595305, acc.: 69.53%] [G loss: 0.998848]\n",
      "epoch:16 step:15472 [D loss: 0.537610, acc.: 75.78%] [G loss: 1.145281]\n",
      "epoch:16 step:15473 [D loss: 0.674049, acc.: 59.38%] [G loss: 0.973631]\n",
      "epoch:16 step:15474 [D loss: 0.677381, acc.: 58.59%] [G loss: 0.853822]\n",
      "epoch:16 step:15475 [D loss: 0.760131, acc.: 41.41%] [G loss: 0.908654]\n",
      "epoch:16 step:15476 [D loss: 0.536242, acc.: 75.00%] [G loss: 1.153327]\n",
      "epoch:16 step:15477 [D loss: 0.578441, acc.: 70.31%] [G loss: 1.191632]\n",
      "epoch:16 step:15478 [D loss: 0.728829, acc.: 54.69%] [G loss: 0.941155]\n",
      "epoch:16 step:15479 [D loss: 0.536067, acc.: 72.66%] [G loss: 1.297540]\n",
      "epoch:16 step:15480 [D loss: 0.647088, acc.: 61.72%] [G loss: 1.128878]\n",
      "epoch:16 step:15481 [D loss: 0.734839, acc.: 49.22%] [G loss: 0.838152]\n",
      "epoch:16 step:15482 [D loss: 0.592759, acc.: 69.53%] [G loss: 1.179891]\n",
      "epoch:16 step:15483 [D loss: 0.751050, acc.: 46.88%] [G loss: 0.909526]\n",
      "epoch:16 step:15484 [D loss: 0.684776, acc.: 57.81%] [G loss: 0.913589]\n",
      "epoch:16 step:15485 [D loss: 0.710504, acc.: 53.91%] [G loss: 1.053962]\n",
      "epoch:16 step:15486 [D loss: 0.728033, acc.: 47.66%] [G loss: 1.028800]\n",
      "epoch:16 step:15487 [D loss: 0.550652, acc.: 75.78%] [G loss: 1.095490]\n",
      "epoch:16 step:15488 [D loss: 0.630283, acc.: 64.06%] [G loss: 0.925890]\n",
      "epoch:16 step:15489 [D loss: 0.547423, acc.: 75.00%] [G loss: 1.062149]\n",
      "epoch:16 step:15490 [D loss: 0.542310, acc.: 72.66%] [G loss: 0.906471]\n",
      "epoch:16 step:15491 [D loss: 0.537608, acc.: 72.66%] [G loss: 1.252417]\n",
      "epoch:16 step:15492 [D loss: 0.745280, acc.: 53.91%] [G loss: 1.170978]\n",
      "epoch:16 step:15493 [D loss: 0.761302, acc.: 48.44%] [G loss: 1.141788]\n",
      "epoch:16 step:15494 [D loss: 0.655792, acc.: 60.94%] [G loss: 1.127992]\n",
      "epoch:16 step:15495 [D loss: 0.515065, acc.: 78.12%] [G loss: 1.022435]\n",
      "epoch:16 step:15496 [D loss: 0.378823, acc.: 90.62%] [G loss: 1.237364]\n",
      "epoch:16 step:15497 [D loss: 0.469697, acc.: 83.59%] [G loss: 1.193421]\n",
      "epoch:16 step:15498 [D loss: 0.507527, acc.: 79.69%] [G loss: 0.970278]\n",
      "epoch:16 step:15499 [D loss: 0.588797, acc.: 71.88%] [G loss: 0.915920]\n",
      "epoch:16 step:15500 [D loss: 0.446366, acc.: 85.16%] [G loss: 1.236601]\n",
      "epoch:16 step:15501 [D loss: 0.775998, acc.: 50.00%] [G loss: 1.191748]\n",
      "epoch:16 step:15502 [D loss: 0.806377, acc.: 44.53%] [G loss: 0.996119]\n",
      "epoch:16 step:15503 [D loss: 0.640163, acc.: 59.38%] [G loss: 1.116923]\n",
      "epoch:16 step:15504 [D loss: 0.533473, acc.: 75.78%] [G loss: 1.037052]\n",
      "epoch:16 step:15505 [D loss: 0.545901, acc.: 72.66%] [G loss: 0.958504]\n",
      "epoch:16 step:15506 [D loss: 0.635666, acc.: 66.41%] [G loss: 1.014919]\n",
      "epoch:16 step:15507 [D loss: 0.496872, acc.: 80.47%] [G loss: 1.033434]\n",
      "epoch:16 step:15508 [D loss: 0.635074, acc.: 60.94%] [G loss: 0.967257]\n",
      "epoch:16 step:15509 [D loss: 0.667841, acc.: 57.03%] [G loss: 0.932434]\n",
      "epoch:16 step:15510 [D loss: 0.746999, acc.: 50.00%] [G loss: 0.936152]\n",
      "epoch:16 step:15511 [D loss: 0.551892, acc.: 77.34%] [G loss: 1.110711]\n",
      "epoch:16 step:15512 [D loss: 0.589825, acc.: 65.62%] [G loss: 1.091021]\n",
      "epoch:16 step:15513 [D loss: 0.639393, acc.: 62.50%] [G loss: 1.074808]\n",
      "epoch:16 step:15514 [D loss: 0.537744, acc.: 76.56%] [G loss: 1.042833]\n",
      "epoch:16 step:15515 [D loss: 0.511364, acc.: 77.34%] [G loss: 0.916582]\n",
      "epoch:16 step:15516 [D loss: 0.649883, acc.: 63.28%] [G loss: 0.946329]\n",
      "epoch:16 step:15517 [D loss: 0.688410, acc.: 60.94%] [G loss: 1.080393]\n",
      "epoch:16 step:15518 [D loss: 0.659223, acc.: 60.94%] [G loss: 1.027310]\n",
      "epoch:16 step:15519 [D loss: 0.639185, acc.: 64.84%] [G loss: 1.079207]\n",
      "epoch:16 step:15520 [D loss: 0.728613, acc.: 46.88%] [G loss: 0.887766]\n",
      "epoch:16 step:15521 [D loss: 0.713741, acc.: 53.12%] [G loss: 0.845893]\n",
      "epoch:16 step:15522 [D loss: 0.622830, acc.: 66.41%] [G loss: 0.900632]\n",
      "epoch:16 step:15523 [D loss: 0.722904, acc.: 52.34%] [G loss: 0.822981]\n",
      "epoch:16 step:15524 [D loss: 0.607962, acc.: 71.09%] [G loss: 0.875389]\n",
      "epoch:16 step:15525 [D loss: 0.546281, acc.: 75.00%] [G loss: 0.896614]\n",
      "epoch:16 step:15526 [D loss: 0.573717, acc.: 74.22%] [G loss: 0.897871]\n",
      "epoch:16 step:15527 [D loss: 0.554985, acc.: 72.66%] [G loss: 1.041806]\n",
      "epoch:16 step:15528 [D loss: 0.480617, acc.: 86.72%] [G loss: 1.204103]\n",
      "epoch:16 step:15529 [D loss: 0.504945, acc.: 74.22%] [G loss: 0.985670]\n",
      "epoch:16 step:15530 [D loss: 0.610533, acc.: 65.62%] [G loss: 1.136453]\n",
      "epoch:16 step:15531 [D loss: 0.542059, acc.: 75.78%] [G loss: 1.187338]\n",
      "epoch:16 step:15532 [D loss: 0.636794, acc.: 64.06%] [G loss: 0.985744]\n",
      "epoch:16 step:15533 [D loss: 0.599946, acc.: 67.97%] [G loss: 0.883520]\n",
      "epoch:16 step:15534 [D loss: 0.920266, acc.: 30.47%] [G loss: 1.008794]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15535 [D loss: 0.725730, acc.: 53.12%] [G loss: 1.059138]\n",
      "epoch:16 step:15536 [D loss: 0.763583, acc.: 46.09%] [G loss: 0.842023]\n",
      "epoch:16 step:15537 [D loss: 0.680351, acc.: 60.94%] [G loss: 0.997526]\n",
      "epoch:16 step:15538 [D loss: 0.564232, acc.: 73.44%] [G loss: 0.994107]\n",
      "epoch:16 step:15539 [D loss: 0.596017, acc.: 67.97%] [G loss: 0.973550]\n",
      "epoch:16 step:15540 [D loss: 0.623509, acc.: 62.50%] [G loss: 1.037868]\n",
      "epoch:16 step:15541 [D loss: 0.465859, acc.: 87.50%] [G loss: 1.235087]\n",
      "epoch:16 step:15542 [D loss: 0.503402, acc.: 79.69%] [G loss: 1.145493]\n",
      "epoch:16 step:15543 [D loss: 0.354735, acc.: 92.97%] [G loss: 1.236473]\n",
      "epoch:16 step:15544 [D loss: 0.531952, acc.: 78.12%] [G loss: 1.076389]\n",
      "epoch:16 step:15545 [D loss: 0.590790, acc.: 68.75%] [G loss: 1.216639]\n",
      "epoch:16 step:15546 [D loss: 0.507945, acc.: 74.22%] [G loss: 1.201353]\n",
      "epoch:16 step:15547 [D loss: 0.457431, acc.: 81.25%] [G loss: 1.306618]\n",
      "epoch:16 step:15548 [D loss: 0.502677, acc.: 82.03%] [G loss: 1.208645]\n",
      "epoch:16 step:15549 [D loss: 0.504816, acc.: 78.91%] [G loss: 1.097175]\n",
      "epoch:16 step:15550 [D loss: 0.563848, acc.: 72.66%] [G loss: 1.130739]\n",
      "epoch:16 step:15551 [D loss: 0.879480, acc.: 37.50%] [G loss: 1.059060]\n",
      "epoch:16 step:15552 [D loss: 0.777684, acc.: 51.56%] [G loss: 1.174407]\n",
      "epoch:16 step:15553 [D loss: 0.541685, acc.: 76.56%] [G loss: 1.196766]\n",
      "epoch:16 step:15554 [D loss: 0.767188, acc.: 51.56%] [G loss: 0.986380]\n",
      "epoch:16 step:15555 [D loss: 0.738646, acc.: 49.22%] [G loss: 1.027342]\n",
      "epoch:16 step:15556 [D loss: 0.605855, acc.: 66.41%] [G loss: 1.016035]\n",
      "epoch:16 step:15557 [D loss: 0.596624, acc.: 70.31%] [G loss: 0.960513]\n",
      "epoch:16 step:15558 [D loss: 0.480248, acc.: 79.69%] [G loss: 1.127209]\n",
      "epoch:16 step:15559 [D loss: 0.456618, acc.: 82.03%] [G loss: 1.189444]\n",
      "epoch:16 step:15560 [D loss: 0.611283, acc.: 71.09%] [G loss: 1.248437]\n",
      "epoch:16 step:15561 [D loss: 0.651053, acc.: 60.94%] [G loss: 1.060809]\n",
      "epoch:16 step:15562 [D loss: 0.742617, acc.: 53.91%] [G loss: 0.923659]\n",
      "epoch:16 step:15563 [D loss: 0.590048, acc.: 68.75%] [G loss: 1.014886]\n",
      "epoch:16 step:15564 [D loss: 0.606639, acc.: 66.41%] [G loss: 0.843206]\n",
      "epoch:16 step:15565 [D loss: 0.528640, acc.: 77.34%] [G loss: 1.120418]\n",
      "epoch:16 step:15566 [D loss: 0.548906, acc.: 71.09%] [G loss: 1.049883]\n",
      "epoch:16 step:15567 [D loss: 0.515872, acc.: 78.91%] [G loss: 1.172055]\n",
      "epoch:16 step:15568 [D loss: 0.437659, acc.: 85.94%] [G loss: 1.453983]\n",
      "epoch:16 step:15569 [D loss: 0.667881, acc.: 59.38%] [G loss: 0.905102]\n",
      "epoch:16 step:15570 [D loss: 0.409311, acc.: 90.62%] [G loss: 1.257337]\n",
      "epoch:16 step:15571 [D loss: 0.598335, acc.: 65.62%] [G loss: 0.915408]\n",
      "epoch:16 step:15572 [D loss: 0.776908, acc.: 47.66%] [G loss: 0.779087]\n",
      "epoch:16 step:15573 [D loss: 0.609740, acc.: 63.28%] [G loss: 1.020910]\n",
      "epoch:16 step:15574 [D loss: 0.829797, acc.: 37.50%] [G loss: 0.787909]\n",
      "epoch:16 step:15575 [D loss: 0.805574, acc.: 48.44%] [G loss: 0.581814]\n",
      "epoch:16 step:15576 [D loss: 0.793342, acc.: 44.53%] [G loss: 0.789554]\n",
      "epoch:16 step:15577 [D loss: 0.712265, acc.: 49.22%] [G loss: 0.933461]\n",
      "epoch:16 step:15578 [D loss: 0.764342, acc.: 49.22%] [G loss: 1.000442]\n",
      "epoch:16 step:15579 [D loss: 0.563230, acc.: 69.53%] [G loss: 1.001300]\n",
      "epoch:16 step:15580 [D loss: 0.504142, acc.: 80.47%] [G loss: 1.493581]\n",
      "epoch:16 step:15581 [D loss: 0.655573, acc.: 62.50%] [G loss: 1.000021]\n",
      "epoch:16 step:15582 [D loss: 0.711891, acc.: 50.78%] [G loss: 1.303231]\n",
      "epoch:16 step:15583 [D loss: 0.640682, acc.: 67.19%] [G loss: 1.126228]\n",
      "epoch:16 step:15584 [D loss: 0.686427, acc.: 57.81%] [G loss: 1.024672]\n",
      "epoch:16 step:15585 [D loss: 0.614639, acc.: 67.19%] [G loss: 1.101981]\n",
      "epoch:16 step:15586 [D loss: 0.694411, acc.: 53.12%] [G loss: 0.887284]\n",
      "epoch:16 step:15587 [D loss: 0.671578, acc.: 59.38%] [G loss: 1.032204]\n",
      "epoch:16 step:15588 [D loss: 0.546602, acc.: 74.22%] [G loss: 0.933112]\n",
      "epoch:16 step:15589 [D loss: 0.599629, acc.: 68.75%] [G loss: 1.005746]\n",
      "epoch:16 step:15590 [D loss: 0.396025, acc.: 89.06%] [G loss: 1.162871]\n",
      "epoch:16 step:15591 [D loss: 0.632901, acc.: 64.06%] [G loss: 1.140581]\n",
      "epoch:16 step:15592 [D loss: 0.769447, acc.: 46.88%] [G loss: 0.845939]\n",
      "epoch:16 step:15593 [D loss: 0.582723, acc.: 69.53%] [G loss: 1.068484]\n",
      "epoch:16 step:15594 [D loss: 0.605276, acc.: 64.06%] [G loss: 1.000192]\n",
      "epoch:16 step:15595 [D loss: 0.468673, acc.: 81.25%] [G loss: 1.082496]\n",
      "epoch:16 step:15596 [D loss: 0.376136, acc.: 91.41%] [G loss: 1.393370]\n",
      "epoch:16 step:15597 [D loss: 0.427397, acc.: 89.06%] [G loss: 1.346985]\n",
      "epoch:16 step:15598 [D loss: 0.632337, acc.: 63.28%] [G loss: 1.099002]\n",
      "epoch:16 step:15599 [D loss: 0.660911, acc.: 62.50%] [G loss: 1.232827]\n",
      "epoch:16 step:15600 [D loss: 0.614199, acc.: 60.94%] [G loss: 0.995570]\n",
      "##############\n",
      "[2.42242463 1.29891326 5.29120748 4.15450212 2.96201864 5.47270525\n",
      " 4.03852709 4.33328942 3.77875114 3.47724527]\n",
      "##########\n",
      "epoch:16 step:15601 [D loss: 0.844072, acc.: 35.16%] [G loss: 0.819294]\n",
      "epoch:16 step:15602 [D loss: 0.756972, acc.: 52.34%] [G loss: 0.910097]\n",
      "epoch:16 step:15603 [D loss: 0.700448, acc.: 56.25%] [G loss: 1.058159]\n",
      "epoch:16 step:15604 [D loss: 0.738674, acc.: 52.34%] [G loss: 1.005198]\n",
      "epoch:16 step:15605 [D loss: 0.681762, acc.: 58.59%] [G loss: 0.845580]\n",
      "epoch:16 step:15606 [D loss: 0.545401, acc.: 71.09%] [G loss: 1.088252]\n",
      "epoch:16 step:15607 [D loss: 0.549922, acc.: 77.34%] [G loss: 1.146590]\n",
      "epoch:16 step:15608 [D loss: 0.496031, acc.: 82.03%] [G loss: 1.147096]\n",
      "epoch:16 step:15609 [D loss: 0.919427, acc.: 30.47%] [G loss: 0.797879]\n",
      "epoch:16 step:15610 [D loss: 0.762989, acc.: 53.91%] [G loss: 0.893051]\n",
      "epoch:16 step:15611 [D loss: 0.710947, acc.: 56.25%] [G loss: 1.254123]\n",
      "epoch:16 step:15612 [D loss: 0.783391, acc.: 45.31%] [G loss: 1.094666]\n",
      "epoch:16 step:15613 [D loss: 0.716232, acc.: 54.69%] [G loss: 1.099416]\n",
      "epoch:16 step:15614 [D loss: 0.765922, acc.: 46.09%] [G loss: 0.953480]\n",
      "epoch:16 step:15615 [D loss: 0.696407, acc.: 59.38%] [G loss: 0.847644]\n",
      "epoch:16 step:15616 [D loss: 0.620639, acc.: 62.50%] [G loss: 0.973934]\n",
      "epoch:16 step:15617 [D loss: 0.754055, acc.: 46.88%] [G loss: 1.005682]\n",
      "epoch:16 step:15618 [D loss: 0.696275, acc.: 59.38%] [G loss: 0.992552]\n",
      "epoch:16 step:15619 [D loss: 0.666861, acc.: 60.16%] [G loss: 0.917840]\n",
      "epoch:16 step:15620 [D loss: 0.668850, acc.: 57.03%] [G loss: 1.004708]\n",
      "epoch:16 step:15621 [D loss: 0.569337, acc.: 74.22%] [G loss: 0.991220]\n",
      "epoch:16 step:15622 [D loss: 0.610625, acc.: 67.97%] [G loss: 1.050952]\n",
      "epoch:16 step:15623 [D loss: 0.603330, acc.: 66.41%] [G loss: 1.006308]\n",
      "epoch:16 step:15624 [D loss: 0.643104, acc.: 61.72%] [G loss: 0.904472]\n",
      "epoch:16 step:15625 [D loss: 0.560725, acc.: 77.34%] [G loss: 1.044970]\n",
      "epoch:16 step:15626 [D loss: 0.571503, acc.: 76.56%] [G loss: 0.790875]\n",
      "epoch:16 step:15627 [D loss: 0.717451, acc.: 54.69%] [G loss: 0.987141]\n",
      "epoch:16 step:15628 [D loss: 0.651803, acc.: 60.94%] [G loss: 1.144199]\n",
      "epoch:16 step:15629 [D loss: 0.650037, acc.: 63.28%] [G loss: 1.247325]\n",
      "epoch:16 step:15630 [D loss: 0.618842, acc.: 67.97%] [G loss: 0.974239]\n",
      "epoch:16 step:15631 [D loss: 0.675526, acc.: 59.38%] [G loss: 0.996176]\n",
      "epoch:16 step:15632 [D loss: 0.550711, acc.: 69.53%] [G loss: 1.018406]\n",
      "epoch:16 step:15633 [D loss: 0.496489, acc.: 80.47%] [G loss: 1.238111]\n",
      "epoch:16 step:15634 [D loss: 0.485366, acc.: 82.03%] [G loss: 1.191298]\n",
      "epoch:16 step:15635 [D loss: 0.719498, acc.: 58.59%] [G loss: 1.159707]\n",
      "epoch:16 step:15636 [D loss: 0.698109, acc.: 57.03%] [G loss: 0.929198]\n",
      "epoch:16 step:15637 [D loss: 0.603166, acc.: 66.41%] [G loss: 1.101231]\n",
      "epoch:16 step:15638 [D loss: 0.630421, acc.: 63.28%] [G loss: 0.942490]\n",
      "epoch:16 step:15639 [D loss: 0.545669, acc.: 74.22%] [G loss: 1.105458]\n",
      "epoch:16 step:15640 [D loss: 0.502377, acc.: 84.38%] [G loss: 1.101858]\n",
      "epoch:16 step:15641 [D loss: 0.703222, acc.: 56.25%] [G loss: 0.814908]\n",
      "epoch:16 step:15642 [D loss: 0.537956, acc.: 71.88%] [G loss: 1.007676]\n",
      "epoch:16 step:15643 [D loss: 0.542787, acc.: 76.56%] [G loss: 0.948145]\n",
      "epoch:16 step:15644 [D loss: 0.737397, acc.: 54.69%] [G loss: 0.971983]\n",
      "epoch:16 step:15645 [D loss: 0.688101, acc.: 53.12%] [G loss: 1.098044]\n",
      "epoch:16 step:15646 [D loss: 0.702283, acc.: 53.91%] [G loss: 1.034620]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15647 [D loss: 0.720074, acc.: 53.12%] [G loss: 0.929203]\n",
      "epoch:16 step:15648 [D loss: 0.712346, acc.: 54.69%] [G loss: 0.847566]\n",
      "epoch:16 step:15649 [D loss: 0.707323, acc.: 52.34%] [G loss: 0.954036]\n",
      "epoch:16 step:15650 [D loss: 0.653499, acc.: 57.03%] [G loss: 0.984180]\n",
      "epoch:16 step:15651 [D loss: 0.670845, acc.: 61.72%] [G loss: 0.948677]\n",
      "epoch:16 step:15652 [D loss: 0.655723, acc.: 60.16%] [G loss: 1.180555]\n",
      "epoch:16 step:15653 [D loss: 0.666464, acc.: 64.06%] [G loss: 0.946482]\n",
      "epoch:16 step:15654 [D loss: 0.616359, acc.: 67.97%] [G loss: 0.860110]\n",
      "epoch:16 step:15655 [D loss: 0.491384, acc.: 80.47%] [G loss: 1.025049]\n",
      "epoch:16 step:15656 [D loss: 0.436472, acc.: 85.16%] [G loss: 1.118859]\n",
      "epoch:16 step:15657 [D loss: 0.473883, acc.: 78.91%] [G loss: 1.281658]\n",
      "epoch:16 step:15658 [D loss: 0.532907, acc.: 74.22%] [G loss: 1.191029]\n",
      "epoch:16 step:15659 [D loss: 0.604530, acc.: 67.19%] [G loss: 1.125307]\n",
      "epoch:16 step:15660 [D loss: 0.588882, acc.: 68.75%] [G loss: 1.282947]\n",
      "epoch:16 step:15661 [D loss: 0.650004, acc.: 64.84%] [G loss: 0.813899]\n",
      "epoch:16 step:15662 [D loss: 0.718832, acc.: 50.00%] [G loss: 0.920872]\n",
      "epoch:16 step:15663 [D loss: 0.757065, acc.: 49.22%] [G loss: 0.976424]\n",
      "epoch:16 step:15664 [D loss: 0.632988, acc.: 63.28%] [G loss: 1.131220]\n",
      "epoch:16 step:15665 [D loss: 0.746937, acc.: 47.66%] [G loss: 1.134444]\n",
      "epoch:16 step:15666 [D loss: 0.744045, acc.: 53.91%] [G loss: 0.784786]\n",
      "epoch:16 step:15667 [D loss: 0.841883, acc.: 39.84%] [G loss: 0.907792]\n",
      "epoch:16 step:15668 [D loss: 0.579605, acc.: 70.31%] [G loss: 0.983992]\n",
      "epoch:16 step:15669 [D loss: 0.552689, acc.: 73.44%] [G loss: 0.950716]\n",
      "epoch:16 step:15670 [D loss: 0.766536, acc.: 53.91%] [G loss: 0.995902]\n",
      "epoch:16 step:15671 [D loss: 0.700961, acc.: 53.91%] [G loss: 1.021954]\n",
      "epoch:16 step:15672 [D loss: 0.671966, acc.: 60.16%] [G loss: 1.067452]\n",
      "epoch:16 step:15673 [D loss: 0.615945, acc.: 63.28%] [G loss: 0.889484]\n",
      "epoch:16 step:15674 [D loss: 0.580440, acc.: 71.09%] [G loss: 1.183852]\n",
      "epoch:16 step:15675 [D loss: 0.687501, acc.: 53.12%] [G loss: 0.976438]\n",
      "epoch:16 step:15676 [D loss: 0.668547, acc.: 60.16%] [G loss: 0.979177]\n",
      "epoch:16 step:15677 [D loss: 0.552838, acc.: 75.78%] [G loss: 1.113880]\n",
      "epoch:16 step:15678 [D loss: 0.590763, acc.: 71.88%] [G loss: 1.038162]\n",
      "epoch:16 step:15679 [D loss: 0.661603, acc.: 60.94%] [G loss: 0.955134]\n",
      "epoch:16 step:15680 [D loss: 0.596025, acc.: 67.19%] [G loss: 0.999979]\n",
      "epoch:16 step:15681 [D loss: 0.517185, acc.: 79.69%] [G loss: 1.005242]\n",
      "epoch:16 step:15682 [D loss: 0.460027, acc.: 82.81%] [G loss: 1.236581]\n",
      "epoch:16 step:15683 [D loss: 0.414280, acc.: 87.50%] [G loss: 1.285833]\n",
      "epoch:16 step:15684 [D loss: 0.508256, acc.: 80.47%] [G loss: 1.246435]\n",
      "epoch:16 step:15685 [D loss: 0.480110, acc.: 79.69%] [G loss: 1.202879]\n",
      "epoch:16 step:15686 [D loss: 0.344597, acc.: 92.97%] [G loss: 1.504558]\n",
      "epoch:16 step:15687 [D loss: 0.638129, acc.: 63.28%] [G loss: 1.048947]\n",
      "epoch:16 step:15688 [D loss: 0.769132, acc.: 48.44%] [G loss: 1.217581]\n",
      "epoch:16 step:15689 [D loss: 0.835402, acc.: 39.06%] [G loss: 0.881429]\n",
      "epoch:16 step:15690 [D loss: 0.687231, acc.: 60.16%] [G loss: 1.137001]\n",
      "epoch:16 step:15691 [D loss: 0.663556, acc.: 59.38%] [G loss: 0.860818]\n",
      "epoch:16 step:15692 [D loss: 0.795614, acc.: 43.75%] [G loss: 0.832725]\n",
      "epoch:16 step:15693 [D loss: 0.723019, acc.: 46.09%] [G loss: 0.972220]\n",
      "epoch:16 step:15694 [D loss: 0.600441, acc.: 67.19%] [G loss: 1.092976]\n",
      "epoch:16 step:15695 [D loss: 0.592940, acc.: 67.19%] [G loss: 1.178647]\n",
      "epoch:16 step:15696 [D loss: 0.636248, acc.: 67.19%] [G loss: 1.006197]\n",
      "epoch:16 step:15697 [D loss: 0.640929, acc.: 61.72%] [G loss: 0.941145]\n",
      "epoch:16 step:15698 [D loss: 0.469157, acc.: 82.03%] [G loss: 1.123234]\n",
      "epoch:16 step:15699 [D loss: 0.421156, acc.: 87.50%] [G loss: 1.122490]\n",
      "epoch:16 step:15700 [D loss: 0.375430, acc.: 92.19%] [G loss: 1.518818]\n",
      "epoch:16 step:15701 [D loss: 0.332517, acc.: 95.31%] [G loss: 1.292369]\n",
      "epoch:16 step:15702 [D loss: 0.807070, acc.: 46.88%] [G loss: 0.979000]\n",
      "epoch:16 step:15703 [D loss: 0.751996, acc.: 49.22%] [G loss: 1.030959]\n",
      "epoch:16 step:15704 [D loss: 0.642089, acc.: 61.72%] [G loss: 0.939383]\n",
      "epoch:16 step:15705 [D loss: 0.516782, acc.: 73.44%] [G loss: 1.024406]\n",
      "epoch:16 step:15706 [D loss: 0.454979, acc.: 84.38%] [G loss: 1.307884]\n",
      "epoch:16 step:15707 [D loss: 0.709535, acc.: 54.69%] [G loss: 0.984650]\n",
      "epoch:16 step:15708 [D loss: 0.767832, acc.: 52.34%] [G loss: 1.023655]\n",
      "epoch:16 step:15709 [D loss: 0.751174, acc.: 50.00%] [G loss: 0.814950]\n",
      "epoch:16 step:15710 [D loss: 0.866781, acc.: 39.06%] [G loss: 1.200827]\n",
      "epoch:16 step:15711 [D loss: 0.698673, acc.: 57.03%] [G loss: 0.976292]\n",
      "epoch:16 step:15712 [D loss: 0.742596, acc.: 51.56%] [G loss: 1.018771]\n",
      "epoch:16 step:15713 [D loss: 0.655743, acc.: 57.81%] [G loss: 1.017071]\n",
      "epoch:16 step:15714 [D loss: 0.613294, acc.: 66.41%] [G loss: 0.850670]\n",
      "epoch:16 step:15715 [D loss: 0.616145, acc.: 70.31%] [G loss: 1.039241]\n",
      "epoch:16 step:15716 [D loss: 0.530218, acc.: 78.91%] [G loss: 1.069519]\n",
      "epoch:16 step:15717 [D loss: 0.520167, acc.: 76.56%] [G loss: 1.110234]\n",
      "epoch:16 step:15718 [D loss: 0.546284, acc.: 76.56%] [G loss: 1.147767]\n",
      "epoch:16 step:15719 [D loss: 0.616087, acc.: 69.53%] [G loss: 1.072320]\n",
      "epoch:16 step:15720 [D loss: 0.627463, acc.: 61.72%] [G loss: 0.931295]\n",
      "epoch:16 step:15721 [D loss: 0.670055, acc.: 57.03%] [G loss: 0.977481]\n",
      "epoch:16 step:15722 [D loss: 0.592532, acc.: 71.09%] [G loss: 1.050655]\n",
      "epoch:16 step:15723 [D loss: 0.645088, acc.: 61.72%] [G loss: 0.874698]\n",
      "epoch:16 step:15724 [D loss: 0.583167, acc.: 71.88%] [G loss: 0.960683]\n",
      "epoch:16 step:15725 [D loss: 0.561988, acc.: 69.53%] [G loss: 0.851958]\n",
      "epoch:16 step:15726 [D loss: 0.657788, acc.: 62.50%] [G loss: 1.171978]\n",
      "epoch:16 step:15727 [D loss: 0.658271, acc.: 67.19%] [G loss: 0.930800]\n",
      "epoch:16 step:15728 [D loss: 0.692220, acc.: 53.91%] [G loss: 1.048278]\n",
      "epoch:16 step:15729 [D loss: 0.616770, acc.: 67.19%] [G loss: 0.976248]\n",
      "epoch:16 step:15730 [D loss: 0.745439, acc.: 50.00%] [G loss: 1.021140]\n",
      "epoch:16 step:15731 [D loss: 0.696808, acc.: 54.69%] [G loss: 0.936110]\n",
      "epoch:16 step:15732 [D loss: 0.606642, acc.: 69.53%] [G loss: 1.052785]\n",
      "epoch:16 step:15733 [D loss: 0.596305, acc.: 65.62%] [G loss: 0.943096]\n",
      "epoch:16 step:15734 [D loss: 0.567752, acc.: 71.09%] [G loss: 1.148031]\n",
      "epoch:16 step:15735 [D loss: 0.545211, acc.: 75.00%] [G loss: 0.884716]\n",
      "epoch:16 step:15736 [D loss: 0.610219, acc.: 67.19%] [G loss: 0.927300]\n",
      "epoch:16 step:15737 [D loss: 0.586850, acc.: 66.41%] [G loss: 1.031900]\n",
      "epoch:16 step:15738 [D loss: 0.556640, acc.: 70.31%] [G loss: 0.984826]\n",
      "epoch:16 step:15739 [D loss: 0.656307, acc.: 56.25%] [G loss: 0.879773]\n",
      "epoch:16 step:15740 [D loss: 0.602919, acc.: 67.97%] [G loss: 0.943898]\n",
      "epoch:16 step:15741 [D loss: 0.656551, acc.: 60.94%] [G loss: 1.035959]\n",
      "epoch:16 step:15742 [D loss: 0.584406, acc.: 71.09%] [G loss: 0.946967]\n",
      "epoch:16 step:15743 [D loss: 0.666529, acc.: 57.03%] [G loss: 0.899229]\n",
      "epoch:16 step:15744 [D loss: 0.798117, acc.: 46.88%] [G loss: 0.903892]\n",
      "epoch:16 step:15745 [D loss: 0.618147, acc.: 66.41%] [G loss: 1.012720]\n",
      "epoch:16 step:15746 [D loss: 0.632884, acc.: 63.28%] [G loss: 0.889168]\n",
      "epoch:16 step:15747 [D loss: 0.508428, acc.: 80.47%] [G loss: 0.955386]\n",
      "epoch:16 step:15748 [D loss: 0.569506, acc.: 67.97%] [G loss: 1.027667]\n",
      "epoch:16 step:15749 [D loss: 0.608090, acc.: 64.84%] [G loss: 1.049612]\n",
      "epoch:16 step:15750 [D loss: 0.631038, acc.: 57.03%] [G loss: 1.067196]\n",
      "epoch:16 step:15751 [D loss: 0.631497, acc.: 63.28%] [G loss: 1.118926]\n",
      "epoch:16 step:15752 [D loss: 0.671910, acc.: 61.72%] [G loss: 1.074655]\n",
      "epoch:16 step:15753 [D loss: 0.666426, acc.: 61.72%] [G loss: 0.990949]\n",
      "epoch:16 step:15754 [D loss: 0.618003, acc.: 71.09%] [G loss: 0.948236]\n",
      "epoch:16 step:15755 [D loss: 0.632675, acc.: 64.84%] [G loss: 1.119314]\n",
      "epoch:16 step:15756 [D loss: 0.651628, acc.: 62.50%] [G loss: 1.000296]\n",
      "epoch:16 step:15757 [D loss: 0.779438, acc.: 48.44%] [G loss: 0.862431]\n",
      "epoch:16 step:15758 [D loss: 0.698201, acc.: 54.69%] [G loss: 0.909134]\n",
      "epoch:16 step:15759 [D loss: 0.753234, acc.: 42.97%] [G loss: 0.910802]\n",
      "epoch:16 step:15760 [D loss: 0.670329, acc.: 61.72%] [G loss: 0.930618]\n",
      "epoch:16 step:15761 [D loss: 0.533983, acc.: 75.78%] [G loss: 1.149452]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15762 [D loss: 0.528934, acc.: 75.78%] [G loss: 1.043807]\n",
      "epoch:16 step:15763 [D loss: 0.750682, acc.: 46.09%] [G loss: 1.028199]\n",
      "epoch:16 step:15764 [D loss: 0.633662, acc.: 61.72%] [G loss: 0.825764]\n",
      "epoch:16 step:15765 [D loss: 0.638138, acc.: 62.50%] [G loss: 0.946118]\n",
      "epoch:16 step:15766 [D loss: 0.356757, acc.: 87.50%] [G loss: 1.076699]\n",
      "epoch:16 step:15767 [D loss: 0.375374, acc.: 87.50%] [G loss: 1.112729]\n",
      "epoch:16 step:15768 [D loss: 0.549058, acc.: 75.78%] [G loss: 1.157115]\n",
      "epoch:16 step:15769 [D loss: 0.579171, acc.: 70.31%] [G loss: 1.308692]\n",
      "epoch:16 step:15770 [D loss: 0.633653, acc.: 65.62%] [G loss: 1.106078]\n",
      "epoch:16 step:15771 [D loss: 0.726150, acc.: 55.47%] [G loss: 1.182009]\n",
      "epoch:16 step:15772 [D loss: 0.649764, acc.: 64.06%] [G loss: 0.844224]\n",
      "epoch:16 step:15773 [D loss: 0.521743, acc.: 76.56%] [G loss: 0.999167]\n",
      "epoch:16 step:15774 [D loss: 0.549104, acc.: 70.31%] [G loss: 1.146481]\n",
      "epoch:16 step:15775 [D loss: 0.723911, acc.: 56.25%] [G loss: 1.004883]\n",
      "epoch:16 step:15776 [D loss: 0.737421, acc.: 48.44%] [G loss: 0.878028]\n",
      "epoch:16 step:15777 [D loss: 0.645587, acc.: 62.50%] [G loss: 1.123439]\n",
      "epoch:16 step:15778 [D loss: 0.569611, acc.: 70.31%] [G loss: 1.076522]\n",
      "epoch:16 step:15779 [D loss: 0.725691, acc.: 53.12%] [G loss: 0.928301]\n",
      "epoch:16 step:15780 [D loss: 0.690740, acc.: 53.91%] [G loss: 1.026059]\n",
      "epoch:16 step:15781 [D loss: 0.718411, acc.: 55.47%] [G loss: 0.971057]\n",
      "epoch:16 step:15782 [D loss: 0.640704, acc.: 65.62%] [G loss: 0.984672]\n",
      "epoch:16 step:15783 [D loss: 0.516734, acc.: 75.78%] [G loss: 1.084677]\n",
      "epoch:16 step:15784 [D loss: 0.437649, acc.: 87.50%] [G loss: 1.186442]\n",
      "epoch:16 step:15785 [D loss: 0.518600, acc.: 78.12%] [G loss: 1.144190]\n",
      "epoch:16 step:15786 [D loss: 0.491448, acc.: 83.59%] [G loss: 1.213511]\n",
      "epoch:16 step:15787 [D loss: 0.693537, acc.: 53.12%] [G loss: 0.935210]\n",
      "epoch:16 step:15788 [D loss: 0.623285, acc.: 64.06%] [G loss: 1.059763]\n",
      "epoch:16 step:15789 [D loss: 0.598815, acc.: 64.84%] [G loss: 1.111228]\n",
      "epoch:16 step:15790 [D loss: 0.614380, acc.: 63.28%] [G loss: 1.004721]\n",
      "epoch:16 step:15791 [D loss: 0.806570, acc.: 42.19%] [G loss: 0.793429]\n",
      "epoch:16 step:15792 [D loss: 0.697509, acc.: 57.81%] [G loss: 1.044255]\n",
      "epoch:16 step:15793 [D loss: 0.768425, acc.: 43.75%] [G loss: 1.164705]\n",
      "epoch:16 step:15794 [D loss: 0.600383, acc.: 73.44%] [G loss: 0.967077]\n",
      "epoch:16 step:15795 [D loss: 0.689621, acc.: 53.12%] [G loss: 1.037266]\n",
      "epoch:16 step:15796 [D loss: 0.576295, acc.: 71.09%] [G loss: 1.008673]\n",
      "epoch:16 step:15797 [D loss: 0.577325, acc.: 71.09%] [G loss: 0.980236]\n",
      "epoch:16 step:15798 [D loss: 0.700596, acc.: 54.69%] [G loss: 1.021945]\n",
      "epoch:16 step:15799 [D loss: 0.670222, acc.: 62.50%] [G loss: 0.905828]\n",
      "epoch:16 step:15800 [D loss: 0.570004, acc.: 71.88%] [G loss: 1.253223]\n",
      "##############\n",
      "[2.29984299 1.5573077  5.67003419 4.33085832 3.05596846 5.28495431\n",
      " 4.31505864 4.57476248 3.96466565 3.60985755]\n",
      "##########\n",
      "epoch:16 step:15801 [D loss: 0.562850, acc.: 75.00%] [G loss: 1.187860]\n",
      "epoch:16 step:15802 [D loss: 0.584725, acc.: 71.09%] [G loss: 1.220994]\n",
      "epoch:16 step:15803 [D loss: 0.651760, acc.: 62.50%] [G loss: 1.211171]\n",
      "epoch:16 step:15804 [D loss: 0.661606, acc.: 57.81%] [G loss: 0.957237]\n",
      "epoch:16 step:15805 [D loss: 0.580516, acc.: 67.97%] [G loss: 1.101000]\n",
      "epoch:16 step:15806 [D loss: 0.583629, acc.: 65.62%] [G loss: 0.876761]\n",
      "epoch:16 step:15807 [D loss: 0.268866, acc.: 96.09%] [G loss: 1.331507]\n",
      "epoch:16 step:15808 [D loss: 0.487486, acc.: 81.25%] [G loss: 1.374882]\n",
      "epoch:16 step:15809 [D loss: 0.637651, acc.: 63.28%] [G loss: 1.130000]\n",
      "epoch:16 step:15810 [D loss: 0.724345, acc.: 50.78%] [G loss: 0.955183]\n",
      "epoch:16 step:15811 [D loss: 0.685506, acc.: 57.03%] [G loss: 0.858811]\n",
      "epoch:16 step:15812 [D loss: 0.984297, acc.: 23.44%] [G loss: 0.831284]\n",
      "epoch:16 step:15813 [D loss: 0.858523, acc.: 38.28%] [G loss: 0.981728]\n",
      "epoch:16 step:15814 [D loss: 0.970391, acc.: 28.91%] [G loss: 0.887827]\n",
      "epoch:16 step:15815 [D loss: 0.616055, acc.: 70.31%] [G loss: 1.271695]\n",
      "epoch:16 step:15816 [D loss: 0.700294, acc.: 57.03%] [G loss: 1.102180]\n",
      "epoch:16 step:15817 [D loss: 0.626067, acc.: 64.06%] [G loss: 0.994519]\n",
      "epoch:16 step:15818 [D loss: 0.776068, acc.: 44.53%] [G loss: 0.822567]\n",
      "epoch:16 step:15819 [D loss: 0.765341, acc.: 48.44%] [G loss: 0.926257]\n",
      "epoch:16 step:15820 [D loss: 0.668703, acc.: 59.38%] [G loss: 1.205400]\n",
      "epoch:16 step:15821 [D loss: 0.802076, acc.: 39.84%] [G loss: 0.857770]\n",
      "epoch:16 step:15822 [D loss: 0.611777, acc.: 63.28%] [G loss: 1.085788]\n",
      "epoch:16 step:15823 [D loss: 0.562258, acc.: 71.88%] [G loss: 1.030911]\n",
      "epoch:16 step:15824 [D loss: 0.530346, acc.: 77.34%] [G loss: 0.948415]\n",
      "epoch:16 step:15825 [D loss: 0.655802, acc.: 65.62%] [G loss: 1.092833]\n",
      "epoch:16 step:15826 [D loss: 0.691451, acc.: 58.59%] [G loss: 1.185741]\n",
      "epoch:16 step:15827 [D loss: 0.597967, acc.: 66.41%] [G loss: 1.154386]\n",
      "epoch:16 step:15828 [D loss: 0.586508, acc.: 69.53%] [G loss: 0.991870]\n",
      "epoch:16 step:15829 [D loss: 0.446381, acc.: 87.50%] [G loss: 1.571251]\n",
      "epoch:16 step:15830 [D loss: 0.586666, acc.: 71.09%] [G loss: 1.435023]\n",
      "epoch:16 step:15831 [D loss: 0.545998, acc.: 75.00%] [G loss: 1.075146]\n",
      "epoch:16 step:15832 [D loss: 0.561457, acc.: 71.09%] [G loss: 1.060205]\n",
      "epoch:16 step:15833 [D loss: 0.490423, acc.: 78.91%] [G loss: 1.245789]\n",
      "epoch:16 step:15834 [D loss: 0.522816, acc.: 76.56%] [G loss: 1.134105]\n",
      "epoch:16 step:15835 [D loss: 0.834812, acc.: 42.97%] [G loss: 0.871997]\n",
      "epoch:16 step:15836 [D loss: 0.831827, acc.: 39.06%] [G loss: 0.998830]\n",
      "epoch:16 step:15837 [D loss: 0.829090, acc.: 37.50%] [G loss: 0.858630]\n",
      "epoch:16 step:15838 [D loss: 0.557661, acc.: 75.78%] [G loss: 1.148163]\n",
      "epoch:16 step:15839 [D loss: 0.515254, acc.: 80.47%] [G loss: 1.158378]\n",
      "epoch:16 step:15840 [D loss: 0.566728, acc.: 71.88%] [G loss: 1.087564]\n",
      "epoch:16 step:15841 [D loss: 0.448740, acc.: 87.50%] [G loss: 1.051867]\n",
      "epoch:16 step:15842 [D loss: 0.441433, acc.: 87.50%] [G loss: 1.179020]\n",
      "epoch:16 step:15843 [D loss: 0.407715, acc.: 87.50%] [G loss: 1.218394]\n",
      "epoch:16 step:15844 [D loss: 0.433017, acc.: 80.47%] [G loss: 1.209284]\n",
      "epoch:16 step:15845 [D loss: 0.523577, acc.: 73.44%] [G loss: 1.227800]\n",
      "epoch:16 step:15846 [D loss: 0.520322, acc.: 78.91%] [G loss: 1.283053]\n",
      "epoch:16 step:15847 [D loss: 0.721838, acc.: 54.69%] [G loss: 0.872071]\n",
      "epoch:16 step:15848 [D loss: 0.671796, acc.: 61.72%] [G loss: 1.077664]\n",
      "epoch:16 step:15849 [D loss: 0.528271, acc.: 75.00%] [G loss: 1.121474]\n",
      "epoch:16 step:15850 [D loss: 0.777782, acc.: 49.22%] [G loss: 0.967547]\n",
      "epoch:16 step:15851 [D loss: 0.898542, acc.: 28.91%] [G loss: 0.693141]\n",
      "epoch:16 step:15852 [D loss: 0.553218, acc.: 75.78%] [G loss: 1.110463]\n",
      "epoch:16 step:15853 [D loss: 0.674778, acc.: 57.81%] [G loss: 0.911492]\n",
      "epoch:16 step:15854 [D loss: 0.696395, acc.: 53.91%] [G loss: 0.991464]\n",
      "epoch:16 step:15855 [D loss: 0.658198, acc.: 60.16%] [G loss: 0.970663]\n",
      "epoch:16 step:15856 [D loss: 0.687537, acc.: 58.59%] [G loss: 0.960422]\n",
      "epoch:16 step:15857 [D loss: 0.729665, acc.: 51.56%] [G loss: 0.802938]\n",
      "epoch:16 step:15858 [D loss: 0.586211, acc.: 67.19%] [G loss: 0.914037]\n",
      "epoch:16 step:15859 [D loss: 0.703745, acc.: 53.12%] [G loss: 1.005584]\n",
      "epoch:16 step:15860 [D loss: 0.610379, acc.: 67.19%] [G loss: 1.070798]\n",
      "epoch:16 step:15861 [D loss: 0.723276, acc.: 55.47%] [G loss: 0.945518]\n",
      "epoch:16 step:15862 [D loss: 0.730605, acc.: 52.34%] [G loss: 0.824571]\n",
      "epoch:16 step:15863 [D loss: 0.702475, acc.: 53.91%] [G loss: 0.814262]\n",
      "epoch:16 step:15864 [D loss: 0.645010, acc.: 60.16%] [G loss: 0.977485]\n",
      "epoch:16 step:15865 [D loss: 0.702809, acc.: 59.38%] [G loss: 0.963642]\n",
      "epoch:16 step:15866 [D loss: 0.633126, acc.: 64.84%] [G loss: 0.917124]\n",
      "epoch:16 step:15867 [D loss: 0.730015, acc.: 51.56%] [G loss: 0.905241]\n",
      "epoch:16 step:15868 [D loss: 0.702467, acc.: 55.47%] [G loss: 0.972877]\n",
      "epoch:16 step:15869 [D loss: 0.716492, acc.: 52.34%] [G loss: 0.902303]\n",
      "epoch:16 step:15870 [D loss: 0.452839, acc.: 82.81%] [G loss: 1.097323]\n",
      "epoch:16 step:15871 [D loss: 0.725663, acc.: 53.91%] [G loss: 1.087214]\n",
      "epoch:16 step:15872 [D loss: 0.722845, acc.: 46.09%] [G loss: 1.021367]\n",
      "epoch:16 step:15873 [D loss: 0.757865, acc.: 46.09%] [G loss: 0.993186]\n",
      "epoch:16 step:15874 [D loss: 0.658537, acc.: 56.25%] [G loss: 1.001337]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15875 [D loss: 0.643223, acc.: 62.50%] [G loss: 0.944437]\n",
      "epoch:16 step:15876 [D loss: 0.632652, acc.: 58.59%] [G loss: 1.139543]\n",
      "epoch:16 step:15877 [D loss: 0.615323, acc.: 63.28%] [G loss: 0.935466]\n",
      "epoch:16 step:15878 [D loss: 0.488052, acc.: 84.38%] [G loss: 1.263835]\n",
      "epoch:16 step:15879 [D loss: 0.594376, acc.: 67.97%] [G loss: 1.005435]\n",
      "epoch:16 step:15880 [D loss: 0.619666, acc.: 66.41%] [G loss: 1.251024]\n",
      "epoch:16 step:15881 [D loss: 0.495101, acc.: 82.81%] [G loss: 1.294047]\n",
      "epoch:16 step:15882 [D loss: 0.459352, acc.: 86.72%] [G loss: 1.339448]\n",
      "epoch:16 step:15883 [D loss: 0.795219, acc.: 44.53%] [G loss: 1.038381]\n",
      "epoch:16 step:15884 [D loss: 0.712339, acc.: 53.91%] [G loss: 1.158765]\n",
      "epoch:16 step:15885 [D loss: 0.781791, acc.: 46.09%] [G loss: 1.041983]\n",
      "epoch:16 step:15886 [D loss: 0.585350, acc.: 70.31%] [G loss: 0.838332]\n",
      "epoch:16 step:15887 [D loss: 0.677973, acc.: 57.81%] [G loss: 0.949690]\n",
      "epoch:16 step:15888 [D loss: 0.584151, acc.: 67.97%] [G loss: 1.025944]\n",
      "epoch:16 step:15889 [D loss: 0.524180, acc.: 74.22%] [G loss: 1.180550]\n",
      "epoch:16 step:15890 [D loss: 0.462298, acc.: 88.28%] [G loss: 1.201254]\n",
      "epoch:16 step:15891 [D loss: 0.425067, acc.: 86.72%] [G loss: 1.334652]\n",
      "epoch:16 step:15892 [D loss: 0.405967, acc.: 89.84%] [G loss: 1.489508]\n",
      "epoch:16 step:15893 [D loss: 0.514850, acc.: 77.34%] [G loss: 1.353590]\n",
      "epoch:16 step:15894 [D loss: 0.713322, acc.: 56.25%] [G loss: 1.038640]\n",
      "epoch:16 step:15895 [D loss: 0.633786, acc.: 64.06%] [G loss: 0.928109]\n",
      "epoch:16 step:15896 [D loss: 0.801887, acc.: 44.53%] [G loss: 0.940721]\n",
      "epoch:16 step:15897 [D loss: 0.659255, acc.: 60.94%] [G loss: 0.958235]\n",
      "epoch:16 step:15898 [D loss: 0.665900, acc.: 63.28%] [G loss: 1.140936]\n",
      "epoch:16 step:15899 [D loss: 0.702577, acc.: 51.56%] [G loss: 1.029397]\n",
      "epoch:16 step:15900 [D loss: 0.749969, acc.: 55.47%] [G loss: 1.161357]\n",
      "epoch:16 step:15901 [D loss: 0.654374, acc.: 61.72%] [G loss: 0.989008]\n",
      "epoch:16 step:15902 [D loss: 0.556685, acc.: 73.44%] [G loss: 1.143802]\n",
      "epoch:16 step:15903 [D loss: 0.459605, acc.: 82.03%] [G loss: 1.013172]\n",
      "epoch:16 step:15904 [D loss: 0.309940, acc.: 94.53%] [G loss: 1.332117]\n",
      "epoch:16 step:15905 [D loss: 0.848692, acc.: 39.06%] [G loss: 1.026078]\n",
      "epoch:16 step:15906 [D loss: 0.710045, acc.: 51.56%] [G loss: 1.027953]\n",
      "epoch:16 step:15907 [D loss: 0.873953, acc.: 41.41%] [G loss: 0.940916]\n",
      "epoch:16 step:15908 [D loss: 0.664253, acc.: 58.59%] [G loss: 1.099564]\n",
      "epoch:16 step:15909 [D loss: 0.653702, acc.: 58.59%] [G loss: 1.004097]\n",
      "epoch:16 step:15910 [D loss: 0.619910, acc.: 67.19%] [G loss: 0.888343]\n",
      "epoch:16 step:15911 [D loss: 0.612175, acc.: 67.19%] [G loss: 1.022988]\n",
      "epoch:16 step:15912 [D loss: 0.444338, acc.: 83.59%] [G loss: 1.059219]\n",
      "epoch:16 step:15913 [D loss: 0.491626, acc.: 80.47%] [G loss: 1.105507]\n",
      "epoch:16 step:15914 [D loss: 0.623028, acc.: 64.84%] [G loss: 1.130216]\n",
      "epoch:16 step:15915 [D loss: 0.549140, acc.: 76.56%] [G loss: 1.047384]\n",
      "epoch:16 step:15916 [D loss: 0.615505, acc.: 67.19%] [G loss: 0.911919]\n",
      "epoch:16 step:15917 [D loss: 0.572176, acc.: 75.00%] [G loss: 1.073486]\n",
      "epoch:16 step:15918 [D loss: 0.603316, acc.: 65.62%] [G loss: 1.016322]\n",
      "epoch:16 step:15919 [D loss: 0.445408, acc.: 84.38%] [G loss: 1.121437]\n",
      "epoch:16 step:15920 [D loss: 0.774398, acc.: 56.25%] [G loss: 1.050664]\n",
      "epoch:16 step:15921 [D loss: 0.553253, acc.: 75.00%] [G loss: 1.257865]\n",
      "epoch:16 step:15922 [D loss: 0.532276, acc.: 79.69%] [G loss: 1.213263]\n",
      "epoch:16 step:15923 [D loss: 0.639763, acc.: 60.16%] [G loss: 1.180313]\n",
      "epoch:16 step:15924 [D loss: 0.624722, acc.: 64.84%] [G loss: 0.947472]\n",
      "epoch:16 step:15925 [D loss: 0.517859, acc.: 75.78%] [G loss: 0.981906]\n",
      "epoch:16 step:15926 [D loss: 0.459890, acc.: 82.81%] [G loss: 1.139021]\n",
      "epoch:16 step:15927 [D loss: 0.497419, acc.: 80.47%] [G loss: 1.079342]\n",
      "epoch:16 step:15928 [D loss: 0.420923, acc.: 83.59%] [G loss: 1.206636]\n",
      "epoch:16 step:15929 [D loss: 0.233491, acc.: 92.19%] [G loss: 1.601992]\n",
      "epoch:17 step:15930 [D loss: 0.875226, acc.: 44.53%] [G loss: 1.105127]\n",
      "epoch:17 step:15931 [D loss: 0.789759, acc.: 47.66%] [G loss: 1.113509]\n",
      "epoch:17 step:15932 [D loss: 0.727629, acc.: 53.12%] [G loss: 1.214744]\n",
      "epoch:17 step:15933 [D loss: 0.857904, acc.: 38.28%] [G loss: 0.856245]\n",
      "epoch:17 step:15934 [D loss: 0.602170, acc.: 65.62%] [G loss: 1.163619]\n",
      "epoch:17 step:15935 [D loss: 0.740448, acc.: 46.88%] [G loss: 1.116802]\n",
      "epoch:17 step:15936 [D loss: 0.702141, acc.: 56.25%] [G loss: 1.037878]\n",
      "epoch:17 step:15937 [D loss: 0.629471, acc.: 63.28%] [G loss: 1.076044]\n",
      "epoch:17 step:15938 [D loss: 0.600875, acc.: 64.84%] [G loss: 1.205272]\n",
      "epoch:17 step:15939 [D loss: 0.545402, acc.: 72.66%] [G loss: 1.071126]\n",
      "epoch:17 step:15940 [D loss: 0.585761, acc.: 68.75%] [G loss: 1.048424]\n",
      "epoch:17 step:15941 [D loss: 0.784221, acc.: 39.84%] [G loss: 1.109651]\n",
      "epoch:17 step:15942 [D loss: 0.682209, acc.: 57.03%] [G loss: 1.131810]\n",
      "epoch:17 step:15943 [D loss: 0.661259, acc.: 57.03%] [G loss: 1.137118]\n",
      "epoch:17 step:15944 [D loss: 0.639669, acc.: 64.84%] [G loss: 0.781739]\n",
      "epoch:17 step:15945 [D loss: 0.513260, acc.: 81.25%] [G loss: 1.095133]\n",
      "epoch:17 step:15946 [D loss: 0.694960, acc.: 53.91%] [G loss: 1.006753]\n",
      "epoch:17 step:15947 [D loss: 0.908762, acc.: 34.38%] [G loss: 0.882517]\n",
      "epoch:17 step:15948 [D loss: 0.808204, acc.: 44.53%] [G loss: 0.778183]\n",
      "epoch:17 step:15949 [D loss: 0.599817, acc.: 69.53%] [G loss: 0.998736]\n",
      "epoch:17 step:15950 [D loss: 0.619963, acc.: 67.97%] [G loss: 1.253068]\n",
      "epoch:17 step:15951 [D loss: 0.672731, acc.: 56.25%] [G loss: 1.097768]\n",
      "epoch:17 step:15952 [D loss: 0.634969, acc.: 62.50%] [G loss: 1.056931]\n",
      "epoch:17 step:15953 [D loss: 0.665660, acc.: 59.38%] [G loss: 1.073088]\n",
      "epoch:17 step:15954 [D loss: 0.541778, acc.: 75.78%] [G loss: 1.000225]\n",
      "epoch:17 step:15955 [D loss: 0.512453, acc.: 76.56%] [G loss: 0.952482]\n",
      "epoch:17 step:15956 [D loss: 0.473513, acc.: 82.03%] [G loss: 1.183333]\n",
      "epoch:17 step:15957 [D loss: 0.446718, acc.: 80.47%] [G loss: 1.205773]\n",
      "epoch:17 step:15958 [D loss: 0.439543, acc.: 89.84%] [G loss: 1.322080]\n",
      "epoch:17 step:15959 [D loss: 0.472249, acc.: 85.94%] [G loss: 1.051977]\n",
      "epoch:17 step:15960 [D loss: 0.426255, acc.: 86.72%] [G loss: 1.118655]\n",
      "epoch:17 step:15961 [D loss: 0.350617, acc.: 91.41%] [G loss: 1.412892]\n",
      "epoch:17 step:15962 [D loss: 0.399143, acc.: 89.84%] [G loss: 1.182456]\n",
      "epoch:17 step:15963 [D loss: 0.386481, acc.: 88.28%] [G loss: 1.402448]\n",
      "epoch:17 step:15964 [D loss: 0.373664, acc.: 90.62%] [G loss: 1.416125]\n",
      "epoch:17 step:15965 [D loss: 0.419665, acc.: 83.59%] [G loss: 1.293511]\n",
      "epoch:17 step:15966 [D loss: 0.852134, acc.: 42.19%] [G loss: 1.218005]\n",
      "epoch:17 step:15967 [D loss: 1.033125, acc.: 35.94%] [G loss: 1.072535]\n",
      "epoch:17 step:15968 [D loss: 0.770406, acc.: 48.44%] [G loss: 1.003396]\n",
      "epoch:17 step:15969 [D loss: 0.669741, acc.: 60.16%] [G loss: 1.129330]\n",
      "epoch:17 step:15970 [D loss: 0.712008, acc.: 55.47%] [G loss: 0.804597]\n",
      "epoch:17 step:15971 [D loss: 0.665948, acc.: 62.50%] [G loss: 0.992100]\n",
      "epoch:17 step:15972 [D loss: 0.615538, acc.: 65.62%] [G loss: 0.827251]\n",
      "epoch:17 step:15973 [D loss: 0.579866, acc.: 71.88%] [G loss: 1.027623]\n",
      "epoch:17 step:15974 [D loss: 0.646342, acc.: 60.94%] [G loss: 1.080240]\n",
      "epoch:17 step:15975 [D loss: 0.787266, acc.: 41.41%] [G loss: 0.920875]\n",
      "epoch:17 step:15976 [D loss: 0.686588, acc.: 59.38%] [G loss: 0.831415]\n",
      "epoch:17 step:15977 [D loss: 0.676294, acc.: 56.25%] [G loss: 0.970440]\n",
      "epoch:17 step:15978 [D loss: 0.566660, acc.: 67.19%] [G loss: 1.146131]\n",
      "epoch:17 step:15979 [D loss: 0.595788, acc.: 67.97%] [G loss: 1.158445]\n",
      "epoch:17 step:15980 [D loss: 0.594635, acc.: 66.41%] [G loss: 0.974882]\n",
      "epoch:17 step:15981 [D loss: 0.599798, acc.: 71.88%] [G loss: 0.974441]\n",
      "epoch:17 step:15982 [D loss: 0.594638, acc.: 69.53%] [G loss: 1.001464]\n",
      "epoch:17 step:15983 [D loss: 0.586046, acc.: 62.50%] [G loss: 1.041882]\n",
      "epoch:17 step:15984 [D loss: 0.554078, acc.: 72.66%] [G loss: 1.161597]\n",
      "epoch:17 step:15985 [D loss: 0.637371, acc.: 65.62%] [G loss: 1.245974]\n",
      "epoch:17 step:15986 [D loss: 0.738060, acc.: 50.78%] [G loss: 0.854959]\n",
      "epoch:17 step:15987 [D loss: 0.676996, acc.: 53.12%] [G loss: 1.191127]\n",
      "epoch:17 step:15988 [D loss: 0.651882, acc.: 60.94%] [G loss: 1.156862]\n",
      "epoch:17 step:15989 [D loss: 0.607014, acc.: 66.41%] [G loss: 0.998266]\n",
      "epoch:17 step:15990 [D loss: 0.564413, acc.: 72.66%] [G loss: 0.997050]\n",
      "epoch:17 step:15991 [D loss: 0.731185, acc.: 50.00%] [G loss: 0.942014]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:15992 [D loss: 0.694013, acc.: 62.50%] [G loss: 0.954294]\n",
      "epoch:17 step:15993 [D loss: 0.560489, acc.: 71.88%] [G loss: 1.032699]\n",
      "epoch:17 step:15994 [D loss: 0.640129, acc.: 63.28%] [G loss: 0.911195]\n",
      "epoch:17 step:15995 [D loss: 0.740580, acc.: 50.78%] [G loss: 1.070905]\n",
      "epoch:17 step:15996 [D loss: 0.664391, acc.: 58.59%] [G loss: 1.057831]\n",
      "epoch:17 step:15997 [D loss: 0.593346, acc.: 68.75%] [G loss: 1.036369]\n",
      "epoch:17 step:15998 [D loss: 0.562487, acc.: 72.66%] [G loss: 1.008916]\n",
      "epoch:17 step:15999 [D loss: 0.633301, acc.: 60.94%] [G loss: 1.022616]\n",
      "epoch:17 step:16000 [D loss: 0.770449, acc.: 42.97%] [G loss: 0.961989]\n",
      "##############\n",
      "[2.27095264 1.58660279 5.47008309 4.07294625 3.04226971 5.2181408\n",
      " 4.00198442 4.51864365 4.22144666 3.75904343]\n",
      "##########\n",
      "epoch:17 step:16001 [D loss: 0.755328, acc.: 46.88%] [G loss: 1.032838]\n",
      "epoch:17 step:16002 [D loss: 0.611604, acc.: 68.75%] [G loss: 1.173852]\n",
      "epoch:17 step:16003 [D loss: 0.540641, acc.: 74.22%] [G loss: 1.020860]\n",
      "epoch:17 step:16004 [D loss: 0.363344, acc.: 88.28%] [G loss: 1.116437]\n",
      "epoch:17 step:16005 [D loss: 0.399550, acc.: 87.50%] [G loss: 1.214585]\n",
      "epoch:17 step:16006 [D loss: 0.426120, acc.: 86.72%] [G loss: 1.144083]\n",
      "epoch:17 step:16007 [D loss: 0.719458, acc.: 56.25%] [G loss: 1.244501]\n",
      "epoch:17 step:16008 [D loss: 0.642558, acc.: 67.97%] [G loss: 0.984660]\n",
      "epoch:17 step:16009 [D loss: 0.664224, acc.: 60.16%] [G loss: 1.063937]\n",
      "epoch:17 step:16010 [D loss: 0.888695, acc.: 44.53%] [G loss: 0.678129]\n",
      "epoch:17 step:16011 [D loss: 0.767174, acc.: 47.66%] [G loss: 0.842400]\n",
      "epoch:17 step:16012 [D loss: 0.714767, acc.: 53.12%] [G loss: 1.047614]\n",
      "epoch:17 step:16013 [D loss: 0.685491, acc.: 53.12%] [G loss: 0.959313]\n",
      "epoch:17 step:16014 [D loss: 0.736534, acc.: 53.12%] [G loss: 1.034447]\n",
      "epoch:17 step:16015 [D loss: 0.642323, acc.: 61.72%] [G loss: 0.862535]\n",
      "epoch:17 step:16016 [D loss: 0.747088, acc.: 47.66%] [G loss: 0.950857]\n",
      "epoch:17 step:16017 [D loss: 0.676025, acc.: 57.81%] [G loss: 0.829315]\n",
      "epoch:17 step:16018 [D loss: 0.655008, acc.: 58.59%] [G loss: 1.171958]\n",
      "epoch:17 step:16019 [D loss: 0.658525, acc.: 63.28%] [G loss: 1.023654]\n",
      "epoch:17 step:16020 [D loss: 0.719759, acc.: 50.00%] [G loss: 0.914687]\n",
      "epoch:17 step:16021 [D loss: 0.622595, acc.: 68.75%] [G loss: 0.842719]\n",
      "epoch:17 step:16022 [D loss: 0.678518, acc.: 59.38%] [G loss: 0.910766]\n",
      "epoch:17 step:16023 [D loss: 0.619632, acc.: 66.41%] [G loss: 1.055004]\n",
      "epoch:17 step:16024 [D loss: 0.666677, acc.: 57.03%] [G loss: 1.041998]\n",
      "epoch:17 step:16025 [D loss: 0.740305, acc.: 50.00%] [G loss: 0.914074]\n",
      "epoch:17 step:16026 [D loss: 0.593776, acc.: 67.97%] [G loss: 0.988252]\n",
      "epoch:17 step:16027 [D loss: 0.684541, acc.: 61.72%] [G loss: 0.869803]\n",
      "epoch:17 step:16028 [D loss: 0.690613, acc.: 55.47%] [G loss: 0.931279]\n",
      "epoch:17 step:16029 [D loss: 0.603530, acc.: 63.28%] [G loss: 0.993150]\n",
      "epoch:17 step:16030 [D loss: 0.679868, acc.: 58.59%] [G loss: 0.951340]\n",
      "epoch:17 step:16031 [D loss: 0.668385, acc.: 58.59%] [G loss: 0.999484]\n",
      "epoch:17 step:16032 [D loss: 0.616944, acc.: 69.53%] [G loss: 0.997670]\n",
      "epoch:17 step:16033 [D loss: 0.764795, acc.: 50.78%] [G loss: 0.970733]\n",
      "epoch:17 step:16034 [D loss: 0.519315, acc.: 80.47%] [G loss: 1.096588]\n",
      "epoch:17 step:16035 [D loss: 0.662917, acc.: 63.28%] [G loss: 0.938250]\n",
      "epoch:17 step:16036 [D loss: 0.735999, acc.: 51.56%] [G loss: 1.019045]\n",
      "epoch:17 step:16037 [D loss: 0.791854, acc.: 48.44%] [G loss: 0.809812]\n",
      "epoch:17 step:16038 [D loss: 0.622133, acc.: 66.41%] [G loss: 0.967396]\n",
      "epoch:17 step:16039 [D loss: 0.763907, acc.: 47.66%] [G loss: 1.151134]\n",
      "epoch:17 step:16040 [D loss: 0.668695, acc.: 60.16%] [G loss: 0.805975]\n",
      "epoch:17 step:16041 [D loss: 0.576104, acc.: 67.97%] [G loss: 1.050459]\n",
      "epoch:17 step:16042 [D loss: 0.648207, acc.: 60.94%] [G loss: 0.992491]\n",
      "epoch:17 step:16043 [D loss: 0.716048, acc.: 47.66%] [G loss: 1.060293]\n",
      "epoch:17 step:16044 [D loss: 0.684731, acc.: 58.59%] [G loss: 0.892992]\n",
      "epoch:17 step:16045 [D loss: 0.624199, acc.: 60.16%] [G loss: 1.035078]\n",
      "epoch:17 step:16046 [D loss: 0.526286, acc.: 75.78%] [G loss: 0.949480]\n",
      "epoch:17 step:16047 [D loss: 0.660291, acc.: 59.38%] [G loss: 0.888363]\n",
      "epoch:17 step:16048 [D loss: 0.495788, acc.: 80.47%] [G loss: 1.167645]\n",
      "epoch:17 step:16049 [D loss: 0.719905, acc.: 51.56%] [G loss: 0.889661]\n",
      "epoch:17 step:16050 [D loss: 0.528274, acc.: 76.56%] [G loss: 0.830503]\n",
      "epoch:17 step:16051 [D loss: 0.530510, acc.: 71.09%] [G loss: 1.047667]\n",
      "epoch:17 step:16052 [D loss: 0.577127, acc.: 72.66%] [G loss: 1.082603]\n",
      "epoch:17 step:16053 [D loss: 0.720938, acc.: 57.81%] [G loss: 1.182366]\n",
      "epoch:17 step:16054 [D loss: 0.632703, acc.: 60.94%] [G loss: 0.940712]\n",
      "epoch:17 step:16055 [D loss: 0.716428, acc.: 55.47%] [G loss: 0.958164]\n",
      "epoch:17 step:16056 [D loss: 0.723797, acc.: 53.91%] [G loss: 0.976126]\n",
      "epoch:17 step:16057 [D loss: 0.655805, acc.: 65.62%] [G loss: 1.037106]\n",
      "epoch:17 step:16058 [D loss: 0.595116, acc.: 67.19%] [G loss: 0.858513]\n",
      "epoch:17 step:16059 [D loss: 0.431758, acc.: 85.94%] [G loss: 0.942323]\n",
      "epoch:17 step:16060 [D loss: 0.439843, acc.: 83.59%] [G loss: 1.216317]\n",
      "epoch:17 step:16061 [D loss: 0.548287, acc.: 72.66%] [G loss: 1.073339]\n",
      "epoch:17 step:16062 [D loss: 0.766309, acc.: 51.56%] [G loss: 1.173346]\n",
      "epoch:17 step:16063 [D loss: 0.645157, acc.: 61.72%] [G loss: 1.005425]\n",
      "epoch:17 step:16064 [D loss: 0.691905, acc.: 58.59%] [G loss: 1.003400]\n",
      "epoch:17 step:16065 [D loss: 0.632116, acc.: 62.50%] [G loss: 1.169878]\n",
      "epoch:17 step:16066 [D loss: 0.689495, acc.: 54.69%] [G loss: 0.843453]\n",
      "epoch:17 step:16067 [D loss: 0.689047, acc.: 60.16%] [G loss: 0.787349]\n",
      "epoch:17 step:16068 [D loss: 0.616199, acc.: 66.41%] [G loss: 1.026589]\n",
      "epoch:17 step:16069 [D loss: 0.826777, acc.: 40.62%] [G loss: 0.819316]\n",
      "epoch:17 step:16070 [D loss: 0.654438, acc.: 64.06%] [G loss: 1.059732]\n",
      "epoch:17 step:16071 [D loss: 0.643889, acc.: 62.50%] [G loss: 1.075434]\n",
      "epoch:17 step:16072 [D loss: 0.650577, acc.: 60.94%] [G loss: 0.855586]\n",
      "epoch:17 step:16073 [D loss: 0.568082, acc.: 68.75%] [G loss: 1.067482]\n",
      "epoch:17 step:16074 [D loss: 0.478733, acc.: 81.25%] [G loss: 1.101417]\n",
      "epoch:17 step:16075 [D loss: 0.645088, acc.: 64.06%] [G loss: 1.014288]\n",
      "epoch:17 step:16076 [D loss: 0.578076, acc.: 73.44%] [G loss: 0.966553]\n",
      "epoch:17 step:16077 [D loss: 0.693529, acc.: 57.03%] [G loss: 0.800138]\n",
      "epoch:17 step:16078 [D loss: 0.581511, acc.: 72.66%] [G loss: 0.977166]\n",
      "epoch:17 step:16079 [D loss: 0.572307, acc.: 67.97%] [G loss: 0.901089]\n",
      "epoch:17 step:16080 [D loss: 0.398363, acc.: 89.06%] [G loss: 1.242848]\n",
      "epoch:17 step:16081 [D loss: 0.409345, acc.: 89.84%] [G loss: 1.262712]\n",
      "epoch:17 step:16082 [D loss: 0.775605, acc.: 50.00%] [G loss: 1.058320]\n",
      "epoch:17 step:16083 [D loss: 0.559721, acc.: 71.09%] [G loss: 1.256766]\n",
      "epoch:17 step:16084 [D loss: 0.758753, acc.: 49.22%] [G loss: 1.005548]\n",
      "epoch:17 step:16085 [D loss: 0.714727, acc.: 53.91%] [G loss: 0.826557]\n",
      "epoch:17 step:16086 [D loss: 0.771741, acc.: 43.75%] [G loss: 0.931273]\n",
      "epoch:17 step:16087 [D loss: 0.624550, acc.: 64.06%] [G loss: 1.094383]\n",
      "epoch:17 step:16088 [D loss: 0.484370, acc.: 83.59%] [G loss: 1.125275]\n",
      "epoch:17 step:16089 [D loss: 0.830682, acc.: 35.16%] [G loss: 0.851597]\n",
      "epoch:17 step:16090 [D loss: 0.604000, acc.: 68.75%] [G loss: 1.020253]\n",
      "epoch:17 step:16091 [D loss: 0.721439, acc.: 52.34%] [G loss: 0.919155]\n",
      "epoch:17 step:16092 [D loss: 0.617523, acc.: 67.97%] [G loss: 0.990946]\n",
      "epoch:17 step:16093 [D loss: 0.715700, acc.: 52.34%] [G loss: 0.808093]\n",
      "epoch:17 step:16094 [D loss: 0.534905, acc.: 82.81%] [G loss: 1.095055]\n",
      "epoch:17 step:16095 [D loss: 0.594469, acc.: 67.97%] [G loss: 1.043313]\n",
      "epoch:17 step:16096 [D loss: 0.500448, acc.: 79.69%] [G loss: 0.931687]\n",
      "epoch:17 step:16097 [D loss: 0.558096, acc.: 74.22%] [G loss: 0.880422]\n",
      "epoch:17 step:16098 [D loss: 0.518545, acc.: 79.69%] [G loss: 1.048041]\n",
      "epoch:17 step:16099 [D loss: 0.637859, acc.: 67.19%] [G loss: 1.226078]\n",
      "epoch:17 step:16100 [D loss: 0.612753, acc.: 66.41%] [G loss: 1.119402]\n",
      "epoch:17 step:16101 [D loss: 0.496104, acc.: 78.91%] [G loss: 1.074775]\n",
      "epoch:17 step:16102 [D loss: 0.602294, acc.: 66.41%] [G loss: 1.095290]\n",
      "epoch:17 step:16103 [D loss: 0.790395, acc.: 36.72%] [G loss: 0.943089]\n",
      "epoch:17 step:16104 [D loss: 0.742948, acc.: 52.34%] [G loss: 0.908466]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16105 [D loss: 0.620148, acc.: 64.84%] [G loss: 1.044395]\n",
      "epoch:17 step:16106 [D loss: 0.721007, acc.: 50.78%] [G loss: 0.857238]\n",
      "epoch:17 step:16107 [D loss: 0.795538, acc.: 48.44%] [G loss: 0.728309]\n",
      "epoch:17 step:16108 [D loss: 0.875764, acc.: 31.25%] [G loss: 0.847788]\n",
      "epoch:17 step:16109 [D loss: 0.821102, acc.: 41.41%] [G loss: 0.934375]\n",
      "epoch:17 step:16110 [D loss: 0.691846, acc.: 58.59%] [G loss: 0.806467]\n",
      "epoch:17 step:16111 [D loss: 0.683768, acc.: 58.59%] [G loss: 1.024191]\n",
      "epoch:17 step:16112 [D loss: 0.761393, acc.: 48.44%] [G loss: 1.030005]\n",
      "epoch:17 step:16113 [D loss: 0.678360, acc.: 60.94%] [G loss: 1.069006]\n",
      "epoch:17 step:16114 [D loss: 0.762158, acc.: 46.88%] [G loss: 0.854759]\n",
      "epoch:17 step:16115 [D loss: 0.871027, acc.: 34.38%] [G loss: 0.850108]\n",
      "epoch:17 step:16116 [D loss: 0.808248, acc.: 41.41%] [G loss: 1.001343]\n",
      "epoch:17 step:16117 [D loss: 0.589891, acc.: 73.44%] [G loss: 1.098026]\n",
      "epoch:17 step:16118 [D loss: 0.743577, acc.: 51.56%] [G loss: 0.902849]\n",
      "epoch:17 step:16119 [D loss: 0.625943, acc.: 62.50%] [G loss: 0.886844]\n",
      "epoch:17 step:16120 [D loss: 0.697360, acc.: 60.94%] [G loss: 0.936088]\n",
      "epoch:17 step:16121 [D loss: 0.596262, acc.: 64.84%] [G loss: 1.078266]\n",
      "epoch:17 step:16122 [D loss: 0.628092, acc.: 66.41%] [G loss: 1.263286]\n",
      "epoch:17 step:16123 [D loss: 0.751327, acc.: 54.69%] [G loss: 0.855996]\n",
      "epoch:17 step:16124 [D loss: 0.715186, acc.: 54.69%] [G loss: 0.938465]\n",
      "epoch:17 step:16125 [D loss: 0.745641, acc.: 50.78%] [G loss: 1.059086]\n",
      "epoch:17 step:16126 [D loss: 0.708319, acc.: 54.69%] [G loss: 0.952659]\n",
      "epoch:17 step:16127 [D loss: 0.691523, acc.: 52.34%] [G loss: 1.049991]\n",
      "epoch:17 step:16128 [D loss: 0.637223, acc.: 64.06%] [G loss: 0.963144]\n",
      "epoch:17 step:16129 [D loss: 0.722191, acc.: 51.56%] [G loss: 0.962576]\n",
      "epoch:17 step:16130 [D loss: 0.670528, acc.: 60.16%] [G loss: 1.130308]\n",
      "epoch:17 step:16131 [D loss: 0.713186, acc.: 52.34%] [G loss: 1.216765]\n",
      "epoch:17 step:16132 [D loss: 0.724452, acc.: 53.91%] [G loss: 0.936471]\n",
      "epoch:17 step:16133 [D loss: 0.705127, acc.: 58.59%] [G loss: 0.992102]\n",
      "epoch:17 step:16134 [D loss: 0.686765, acc.: 57.03%] [G loss: 0.889659]\n",
      "epoch:17 step:16135 [D loss: 0.619580, acc.: 64.06%] [G loss: 1.146539]\n",
      "epoch:17 step:16136 [D loss: 0.608987, acc.: 68.75%] [G loss: 1.024798]\n",
      "epoch:17 step:16137 [D loss: 0.657809, acc.: 62.50%] [G loss: 0.872928]\n",
      "epoch:17 step:16138 [D loss: 0.547071, acc.: 75.00%] [G loss: 0.991151]\n",
      "epoch:17 step:16139 [D loss: 0.684392, acc.: 60.94%] [G loss: 1.025576]\n",
      "epoch:17 step:16140 [D loss: 0.657544, acc.: 64.06%] [G loss: 0.921350]\n",
      "epoch:17 step:16141 [D loss: 0.665078, acc.: 57.03%] [G loss: 1.007188]\n",
      "epoch:17 step:16142 [D loss: 0.539680, acc.: 79.69%] [G loss: 1.218483]\n",
      "epoch:17 step:16143 [D loss: 0.736555, acc.: 55.47%] [G loss: 1.042346]\n",
      "epoch:17 step:16144 [D loss: 0.543876, acc.: 75.00%] [G loss: 1.023697]\n",
      "epoch:17 step:16145 [D loss: 0.494716, acc.: 83.59%] [G loss: 1.279436]\n",
      "epoch:17 step:16146 [D loss: 0.711405, acc.: 58.59%] [G loss: 1.032000]\n",
      "epoch:17 step:16147 [D loss: 0.612222, acc.: 68.75%] [G loss: 0.890829]\n",
      "epoch:17 step:16148 [D loss: 0.631102, acc.: 63.28%] [G loss: 1.010904]\n",
      "epoch:17 step:16149 [D loss: 0.446147, acc.: 77.34%] [G loss: 1.067573]\n",
      "epoch:17 step:16150 [D loss: 0.441417, acc.: 81.25%] [G loss: 1.268114]\n",
      "epoch:17 step:16151 [D loss: 0.498177, acc.: 79.69%] [G loss: 1.422180]\n",
      "epoch:17 step:16152 [D loss: 0.373218, acc.: 90.62%] [G loss: 1.303405]\n",
      "epoch:17 step:16153 [D loss: 0.762116, acc.: 53.12%] [G loss: 1.206016]\n",
      "epoch:17 step:16154 [D loss: 0.913345, acc.: 36.72%] [G loss: 0.909835]\n",
      "epoch:17 step:16155 [D loss: 0.533647, acc.: 76.56%] [G loss: 1.181770]\n",
      "epoch:17 step:16156 [D loss: 0.652897, acc.: 61.72%] [G loss: 1.021205]\n",
      "epoch:17 step:16157 [D loss: 0.738054, acc.: 46.09%] [G loss: 0.843804]\n",
      "epoch:17 step:16158 [D loss: 0.556543, acc.: 71.88%] [G loss: 1.165166]\n",
      "epoch:17 step:16159 [D loss: 0.304350, acc.: 89.84%] [G loss: 1.337213]\n",
      "epoch:17 step:16160 [D loss: 0.298841, acc.: 96.88%] [G loss: 1.433907]\n",
      "epoch:17 step:16161 [D loss: 0.345712, acc.: 89.84%] [G loss: 1.488802]\n",
      "epoch:17 step:16162 [D loss: 0.746903, acc.: 55.47%] [G loss: 1.308755]\n",
      "epoch:17 step:16163 [D loss: 0.979473, acc.: 35.16%] [G loss: 0.743129]\n",
      "epoch:17 step:16164 [D loss: 0.627285, acc.: 62.50%] [G loss: 0.959118]\n",
      "epoch:17 step:16165 [D loss: 0.835788, acc.: 45.31%] [G loss: 0.926422]\n",
      "epoch:17 step:16166 [D loss: 0.783314, acc.: 48.44%] [G loss: 0.955498]\n",
      "epoch:17 step:16167 [D loss: 0.713176, acc.: 53.12%] [G loss: 1.044461]\n",
      "epoch:17 step:16168 [D loss: 0.686141, acc.: 57.03%] [G loss: 1.165380]\n",
      "epoch:17 step:16169 [D loss: 0.890002, acc.: 40.62%] [G loss: 0.961858]\n",
      "epoch:17 step:16170 [D loss: 0.672660, acc.: 59.38%] [G loss: 1.065811]\n",
      "epoch:17 step:16171 [D loss: 0.833942, acc.: 39.06%] [G loss: 0.822201]\n",
      "epoch:17 step:16172 [D loss: 0.670651, acc.: 63.28%] [G loss: 0.973301]\n",
      "epoch:17 step:16173 [D loss: 0.581112, acc.: 71.88%] [G loss: 1.173785]\n",
      "epoch:17 step:16174 [D loss: 0.544239, acc.: 72.66%] [G loss: 1.177852]\n",
      "epoch:17 step:16175 [D loss: 0.432238, acc.: 85.94%] [G loss: 1.180261]\n",
      "epoch:17 step:16176 [D loss: 0.501501, acc.: 80.47%] [G loss: 1.221290]\n",
      "epoch:17 step:16177 [D loss: 0.565098, acc.: 72.66%] [G loss: 1.145426]\n",
      "epoch:17 step:16178 [D loss: 0.605536, acc.: 66.41%] [G loss: 1.098933]\n",
      "epoch:17 step:16179 [D loss: 0.604863, acc.: 68.75%] [G loss: 1.111631]\n",
      "epoch:17 step:16180 [D loss: 0.673176, acc.: 56.25%] [G loss: 0.873703]\n",
      "epoch:17 step:16181 [D loss: 0.541320, acc.: 72.66%] [G loss: 1.105874]\n",
      "epoch:17 step:16182 [D loss: 0.520723, acc.: 78.91%] [G loss: 1.151607]\n",
      "epoch:17 step:16183 [D loss: 0.599912, acc.: 70.31%] [G loss: 1.059540]\n",
      "epoch:17 step:16184 [D loss: 0.874646, acc.: 39.06%] [G loss: 0.740871]\n",
      "epoch:17 step:16185 [D loss: 0.632059, acc.: 66.41%] [G loss: 1.047084]\n",
      "epoch:17 step:16186 [D loss: 0.639769, acc.: 67.97%] [G loss: 0.864162]\n",
      "epoch:17 step:16187 [D loss: 0.677904, acc.: 58.59%] [G loss: 0.850321]\n",
      "epoch:17 step:16188 [D loss: 0.745300, acc.: 50.78%] [G loss: 0.938035]\n",
      "epoch:17 step:16189 [D loss: 0.670162, acc.: 58.59%] [G loss: 1.006427]\n",
      "epoch:17 step:16190 [D loss: 0.702164, acc.: 60.16%] [G loss: 0.904200]\n",
      "epoch:17 step:16191 [D loss: 0.565272, acc.: 75.00%] [G loss: 0.949573]\n",
      "epoch:17 step:16192 [D loss: 0.682355, acc.: 54.69%] [G loss: 1.014490]\n",
      "epoch:17 step:16193 [D loss: 0.562402, acc.: 73.44%] [G loss: 0.982029]\n",
      "epoch:17 step:16194 [D loss: 0.646551, acc.: 61.72%] [G loss: 1.148518]\n",
      "epoch:17 step:16195 [D loss: 0.667834, acc.: 54.69%] [G loss: 0.903465]\n",
      "epoch:17 step:16196 [D loss: 0.607431, acc.: 67.97%] [G loss: 0.909625]\n",
      "epoch:17 step:16197 [D loss: 0.568328, acc.: 68.75%] [G loss: 1.143873]\n",
      "epoch:17 step:16198 [D loss: 0.669641, acc.: 60.16%] [G loss: 0.990395]\n",
      "epoch:17 step:16199 [D loss: 0.716864, acc.: 49.22%] [G loss: 1.001139]\n",
      "epoch:17 step:16200 [D loss: 0.599701, acc.: 70.31%] [G loss: 1.073599]\n",
      "##############\n",
      "[2.4235358  1.6066688  5.24631031 4.1974919  2.95453684 5.11192269\n",
      " 3.91015492 4.61642926 3.97369309 3.63226514]\n",
      "##########\n",
      "epoch:17 step:16201 [D loss: 0.540244, acc.: 75.78%] [G loss: 1.135862]\n",
      "epoch:17 step:16202 [D loss: 0.684533, acc.: 49.22%] [G loss: 1.092461]\n",
      "epoch:17 step:16203 [D loss: 0.643528, acc.: 64.06%] [G loss: 0.917540]\n",
      "epoch:17 step:16204 [D loss: 0.703980, acc.: 56.25%] [G loss: 0.918566]\n",
      "epoch:17 step:16205 [D loss: 0.629904, acc.: 64.84%] [G loss: 1.023075]\n",
      "epoch:17 step:16206 [D loss: 0.734432, acc.: 51.56%] [G loss: 1.077261]\n",
      "epoch:17 step:16207 [D loss: 0.645147, acc.: 63.28%] [G loss: 0.929505]\n",
      "epoch:17 step:16208 [D loss: 0.464439, acc.: 81.25%] [G loss: 1.203590]\n",
      "epoch:17 step:16209 [D loss: 0.576142, acc.: 71.09%] [G loss: 1.014770]\n",
      "epoch:17 step:16210 [D loss: 0.750133, acc.: 46.09%] [G loss: 0.978924]\n",
      "epoch:17 step:16211 [D loss: 0.736773, acc.: 53.91%] [G loss: 0.997460]\n",
      "epoch:17 step:16212 [D loss: 0.646603, acc.: 60.16%] [G loss: 0.898048]\n",
      "epoch:17 step:16213 [D loss: 0.534727, acc.: 79.69%] [G loss: 1.071001]\n",
      "epoch:17 step:16214 [D loss: 0.479340, acc.: 84.38%] [G loss: 1.120594]\n",
      "epoch:17 step:16215 [D loss: 0.579673, acc.: 72.66%] [G loss: 1.108778]\n",
      "epoch:17 step:16216 [D loss: 0.663690, acc.: 59.38%] [G loss: 0.925886]\n",
      "epoch:17 step:16217 [D loss: 0.629829, acc.: 63.28%] [G loss: 1.100480]\n",
      "epoch:17 step:16218 [D loss: 0.532092, acc.: 77.34%] [G loss: 1.342067]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16219 [D loss: 0.686947, acc.: 53.91%] [G loss: 0.904753]\n",
      "epoch:17 step:16220 [D loss: 0.503142, acc.: 75.78%] [G loss: 1.061219]\n",
      "epoch:17 step:16221 [D loss: 0.625574, acc.: 65.62%] [G loss: 1.001861]\n",
      "epoch:17 step:16222 [D loss: 0.575142, acc.: 72.66%] [G loss: 1.003395]\n",
      "epoch:17 step:16223 [D loss: 0.652092, acc.: 62.50%] [G loss: 1.033735]\n",
      "epoch:17 step:16224 [D loss: 0.893803, acc.: 31.25%] [G loss: 0.887062]\n",
      "epoch:17 step:16225 [D loss: 0.856146, acc.: 41.41%] [G loss: 0.795845]\n",
      "epoch:17 step:16226 [D loss: 0.663200, acc.: 62.50%] [G loss: 0.798217]\n",
      "epoch:17 step:16227 [D loss: 0.524862, acc.: 78.91%] [G loss: 1.158328]\n",
      "epoch:17 step:16228 [D loss: 0.544031, acc.: 75.78%] [G loss: 1.237126]\n",
      "epoch:17 step:16229 [D loss: 0.590929, acc.: 70.31%] [G loss: 1.137379]\n",
      "epoch:17 step:16230 [D loss: 0.730225, acc.: 53.91%] [G loss: 1.105274]\n",
      "epoch:17 step:16231 [D loss: 0.654728, acc.: 64.84%] [G loss: 0.946885]\n",
      "epoch:17 step:16232 [D loss: 0.549129, acc.: 73.44%] [G loss: 1.152513]\n",
      "epoch:17 step:16233 [D loss: 0.749566, acc.: 46.09%] [G loss: 0.905637]\n",
      "epoch:17 step:16234 [D loss: 0.759713, acc.: 43.75%] [G loss: 0.908060]\n",
      "epoch:17 step:16235 [D loss: 0.598600, acc.: 72.66%] [G loss: 0.960863]\n",
      "epoch:17 step:16236 [D loss: 0.617176, acc.: 65.62%] [G loss: 0.879283]\n",
      "epoch:17 step:16237 [D loss: 0.646026, acc.: 60.94%] [G loss: 0.887587]\n",
      "epoch:17 step:16238 [D loss: 0.638503, acc.: 64.06%] [G loss: 1.073343]\n",
      "epoch:17 step:16239 [D loss: 0.652296, acc.: 60.94%] [G loss: 0.968745]\n",
      "epoch:17 step:16240 [D loss: 0.661237, acc.: 60.16%] [G loss: 1.046054]\n",
      "epoch:17 step:16241 [D loss: 0.553490, acc.: 75.00%] [G loss: 0.996332]\n",
      "epoch:17 step:16242 [D loss: 0.428715, acc.: 87.50%] [G loss: 1.018262]\n",
      "epoch:17 step:16243 [D loss: 0.508216, acc.: 85.16%] [G loss: 1.123535]\n",
      "epoch:17 step:16244 [D loss: 0.523948, acc.: 78.91%] [G loss: 1.068547]\n",
      "epoch:17 step:16245 [D loss: 0.644617, acc.: 62.50%] [G loss: 1.086820]\n",
      "epoch:17 step:16246 [D loss: 0.725544, acc.: 53.91%] [G loss: 1.050682]\n",
      "epoch:17 step:16247 [D loss: 0.685885, acc.: 56.25%] [G loss: 1.078552]\n",
      "epoch:17 step:16248 [D loss: 0.598327, acc.: 68.75%] [G loss: 1.138736]\n",
      "epoch:17 step:16249 [D loss: 0.508750, acc.: 77.34%] [G loss: 1.081053]\n",
      "epoch:17 step:16250 [D loss: 0.499886, acc.: 78.12%] [G loss: 0.986906]\n",
      "epoch:17 step:16251 [D loss: 0.652720, acc.: 60.94%] [G loss: 0.970873]\n",
      "epoch:17 step:16252 [D loss: 0.734443, acc.: 51.56%] [G loss: 0.941478]\n",
      "epoch:17 step:16253 [D loss: 0.677576, acc.: 60.16%] [G loss: 1.049745]\n",
      "epoch:17 step:16254 [D loss: 0.678882, acc.: 57.81%] [G loss: 0.934059]\n",
      "epoch:17 step:16255 [D loss: 0.611271, acc.: 64.84%] [G loss: 0.997754]\n",
      "epoch:17 step:16256 [D loss: 0.508795, acc.: 81.25%] [G loss: 1.001881]\n",
      "epoch:17 step:16257 [D loss: 0.517695, acc.: 79.69%] [G loss: 1.086818]\n",
      "epoch:17 step:16258 [D loss: 0.728080, acc.: 50.00%] [G loss: 1.016982]\n",
      "epoch:17 step:16259 [D loss: 0.680896, acc.: 60.94%] [G loss: 1.025179]\n",
      "epoch:17 step:16260 [D loss: 0.720515, acc.: 54.69%] [G loss: 0.999840]\n",
      "epoch:17 step:16261 [D loss: 0.671533, acc.: 61.72%] [G loss: 1.009912]\n",
      "epoch:17 step:16262 [D loss: 0.630603, acc.: 67.97%] [G loss: 0.991834]\n",
      "epoch:17 step:16263 [D loss: 0.559506, acc.: 70.31%] [G loss: 0.921389]\n",
      "epoch:17 step:16264 [D loss: 0.523426, acc.: 78.12%] [G loss: 0.995840]\n",
      "epoch:17 step:16265 [D loss: 0.610687, acc.: 69.53%] [G loss: 1.011218]\n",
      "epoch:17 step:16266 [D loss: 0.674295, acc.: 63.28%] [G loss: 0.845641]\n",
      "epoch:17 step:16267 [D loss: 0.753572, acc.: 44.53%] [G loss: 0.929629]\n",
      "epoch:17 step:16268 [D loss: 0.599793, acc.: 67.97%] [G loss: 1.018672]\n",
      "epoch:17 step:16269 [D loss: 0.732200, acc.: 55.47%] [G loss: 1.113699]\n",
      "epoch:17 step:16270 [D loss: 0.676682, acc.: 55.47%] [G loss: 1.109506]\n",
      "epoch:17 step:16271 [D loss: 0.482462, acc.: 76.56%] [G loss: 1.083814]\n",
      "epoch:17 step:16272 [D loss: 0.422987, acc.: 84.38%] [G loss: 1.081346]\n",
      "epoch:17 step:16273 [D loss: 0.545016, acc.: 74.22%] [G loss: 1.176054]\n",
      "epoch:17 step:16274 [D loss: 0.391094, acc.: 89.84%] [G loss: 1.409560]\n",
      "epoch:17 step:16275 [D loss: 0.511191, acc.: 74.22%] [G loss: 0.830067]\n",
      "epoch:17 step:16276 [D loss: 0.349442, acc.: 94.53%] [G loss: 1.274992]\n",
      "epoch:17 step:16277 [D loss: 0.778878, acc.: 50.78%] [G loss: 1.159513]\n",
      "epoch:17 step:16278 [D loss: 0.992054, acc.: 32.03%] [G loss: 1.084332]\n",
      "epoch:17 step:16279 [D loss: 0.713484, acc.: 50.00%] [G loss: 1.020723]\n",
      "epoch:17 step:16280 [D loss: 0.742634, acc.: 50.00%] [G loss: 0.858377]\n",
      "epoch:17 step:16281 [D loss: 0.554638, acc.: 77.34%] [G loss: 1.099497]\n",
      "epoch:17 step:16282 [D loss: 0.565544, acc.: 76.56%] [G loss: 1.160056]\n",
      "epoch:17 step:16283 [D loss: 0.497747, acc.: 81.25%] [G loss: 1.177871]\n",
      "epoch:17 step:16284 [D loss: 0.619512, acc.: 67.97%] [G loss: 1.040810]\n",
      "epoch:17 step:16285 [D loss: 0.618302, acc.: 68.75%] [G loss: 1.323807]\n",
      "epoch:17 step:16286 [D loss: 0.566119, acc.: 74.22%] [G loss: 0.925357]\n",
      "epoch:17 step:16287 [D loss: 0.504026, acc.: 76.56%] [G loss: 1.113970]\n",
      "epoch:17 step:16288 [D loss: 0.470991, acc.: 81.25%] [G loss: 1.337827]\n",
      "epoch:17 step:16289 [D loss: 0.501200, acc.: 82.81%] [G loss: 1.330410]\n",
      "epoch:17 step:16290 [D loss: 0.657978, acc.: 64.06%] [G loss: 1.056673]\n",
      "epoch:17 step:16291 [D loss: 0.926046, acc.: 35.94%] [G loss: 0.744184]\n",
      "epoch:17 step:16292 [D loss: 0.844340, acc.: 41.41%] [G loss: 1.050801]\n",
      "epoch:17 step:16293 [D loss: 0.663452, acc.: 58.59%] [G loss: 0.940523]\n",
      "epoch:17 step:16294 [D loss: 0.867958, acc.: 34.38%] [G loss: 0.995301]\n",
      "epoch:17 step:16295 [D loss: 0.638667, acc.: 61.72%] [G loss: 1.025136]\n",
      "epoch:17 step:16296 [D loss: 0.680456, acc.: 62.50%] [G loss: 1.096729]\n",
      "epoch:17 step:16297 [D loss: 0.720455, acc.: 54.69%] [G loss: 1.181795]\n",
      "epoch:17 step:16298 [D loss: 0.520844, acc.: 78.91%] [G loss: 1.188471]\n",
      "epoch:17 step:16299 [D loss: 0.475218, acc.: 78.91%] [G loss: 1.172651]\n",
      "epoch:17 step:16300 [D loss: 0.478099, acc.: 85.94%] [G loss: 1.185688]\n",
      "epoch:17 step:16301 [D loss: 0.741733, acc.: 46.88%] [G loss: 1.053948]\n",
      "epoch:17 step:16302 [D loss: 0.696208, acc.: 50.78%] [G loss: 1.042707]\n",
      "epoch:17 step:16303 [D loss: 0.684775, acc.: 56.25%] [G loss: 0.968495]\n",
      "epoch:17 step:16304 [D loss: 0.794461, acc.: 46.09%] [G loss: 0.837753]\n",
      "epoch:17 step:16305 [D loss: 0.753871, acc.: 53.91%] [G loss: 0.850008]\n",
      "epoch:17 step:16306 [D loss: 0.615111, acc.: 70.31%] [G loss: 0.934807]\n",
      "epoch:17 step:16307 [D loss: 0.604887, acc.: 61.72%] [G loss: 1.038443]\n",
      "epoch:17 step:16308 [D loss: 0.704976, acc.: 55.47%] [G loss: 1.077757]\n",
      "epoch:17 step:16309 [D loss: 0.630867, acc.: 66.41%] [G loss: 0.994234]\n",
      "epoch:17 step:16310 [D loss: 0.585283, acc.: 68.75%] [G loss: 1.016578]\n",
      "epoch:17 step:16311 [D loss: 0.709094, acc.: 56.25%] [G loss: 1.023830]\n",
      "epoch:17 step:16312 [D loss: 0.600731, acc.: 70.31%] [G loss: 0.822488]\n",
      "epoch:17 step:16313 [D loss: 0.684759, acc.: 56.25%] [G loss: 0.983606]\n",
      "epoch:17 step:16314 [D loss: 0.680732, acc.: 55.47%] [G loss: 0.942287]\n",
      "epoch:17 step:16315 [D loss: 0.550265, acc.: 74.22%] [G loss: 0.971614]\n",
      "epoch:17 step:16316 [D loss: 0.625982, acc.: 64.84%] [G loss: 0.902214]\n",
      "epoch:17 step:16317 [D loss: 0.628012, acc.: 67.19%] [G loss: 0.899249]\n",
      "epoch:17 step:16318 [D loss: 0.747042, acc.: 49.22%] [G loss: 0.719507]\n",
      "epoch:17 step:16319 [D loss: 0.520374, acc.: 73.44%] [G loss: 0.971594]\n",
      "epoch:17 step:16320 [D loss: 0.613321, acc.: 67.97%] [G loss: 0.926608]\n",
      "epoch:17 step:16321 [D loss: 0.548581, acc.: 76.56%] [G loss: 1.207611]\n",
      "epoch:17 step:16322 [D loss: 0.705571, acc.: 60.16%] [G loss: 1.061760]\n",
      "epoch:17 step:16323 [D loss: 0.595018, acc.: 66.41%] [G loss: 1.037152]\n",
      "epoch:17 step:16324 [D loss: 0.779425, acc.: 54.69%] [G loss: 0.814210]\n",
      "epoch:17 step:16325 [D loss: 0.376847, acc.: 87.50%] [G loss: 1.514453]\n",
      "epoch:17 step:16326 [D loss: 0.343610, acc.: 90.62%] [G loss: 1.400843]\n",
      "epoch:17 step:16327 [D loss: 0.355788, acc.: 89.06%] [G loss: 1.666970]\n",
      "epoch:17 step:16328 [D loss: 0.421372, acc.: 88.28%] [G loss: 1.441837]\n",
      "epoch:17 step:16329 [D loss: 0.546369, acc.: 72.66%] [G loss: 1.169516]\n",
      "epoch:17 step:16330 [D loss: 0.737881, acc.: 54.69%] [G loss: 0.666389]\n",
      "epoch:17 step:16331 [D loss: 0.479366, acc.: 81.25%] [G loss: 1.355608]\n",
      "epoch:17 step:16332 [D loss: 0.624583, acc.: 62.50%] [G loss: 1.226846]\n",
      "epoch:17 step:16333 [D loss: 0.512283, acc.: 76.56%] [G loss: 1.277883]\n",
      "epoch:17 step:16334 [D loss: 0.597493, acc.: 66.41%] [G loss: 1.131098]\n",
      "epoch:17 step:16335 [D loss: 0.509531, acc.: 79.69%] [G loss: 1.594784]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16336 [D loss: 0.498735, acc.: 82.03%] [G loss: 1.246884]\n",
      "epoch:17 step:16337 [D loss: 0.902012, acc.: 35.94%] [G loss: 0.666498]\n",
      "epoch:17 step:16338 [D loss: 0.746024, acc.: 55.47%] [G loss: 0.807353]\n",
      "epoch:17 step:16339 [D loss: 0.770053, acc.: 52.34%] [G loss: 0.994600]\n",
      "epoch:17 step:16340 [D loss: 0.898312, acc.: 35.16%] [G loss: 0.857443]\n",
      "epoch:17 step:16341 [D loss: 0.851867, acc.: 43.75%] [G loss: 0.957201]\n",
      "epoch:17 step:16342 [D loss: 0.872523, acc.: 39.06%] [G loss: 0.982924]\n",
      "epoch:17 step:16343 [D loss: 0.864018, acc.: 37.50%] [G loss: 0.877661]\n",
      "epoch:17 step:16344 [D loss: 0.817000, acc.: 41.41%] [G loss: 0.938524]\n",
      "epoch:17 step:16345 [D loss: 0.657764, acc.: 62.50%] [G loss: 0.924677]\n",
      "epoch:17 step:16346 [D loss: 0.916652, acc.: 32.81%] [G loss: 0.956410]\n",
      "epoch:17 step:16347 [D loss: 0.782311, acc.: 45.31%] [G loss: 0.916100]\n",
      "epoch:17 step:16348 [D loss: 0.793480, acc.: 48.44%] [G loss: 0.961586]\n",
      "epoch:17 step:16349 [D loss: 0.637073, acc.: 60.94%] [G loss: 1.153310]\n",
      "epoch:17 step:16350 [D loss: 0.746763, acc.: 46.09%] [G loss: 0.927286]\n",
      "epoch:17 step:16351 [D loss: 0.808519, acc.: 45.31%] [G loss: 0.837692]\n",
      "epoch:17 step:16352 [D loss: 0.846384, acc.: 43.75%] [G loss: 1.161112]\n",
      "epoch:17 step:16353 [D loss: 0.600948, acc.: 65.62%] [G loss: 1.078941]\n",
      "epoch:17 step:16354 [D loss: 0.701792, acc.: 50.78%] [G loss: 0.940669]\n",
      "epoch:17 step:16355 [D loss: 0.696389, acc.: 53.91%] [G loss: 0.869076]\n",
      "epoch:17 step:16356 [D loss: 0.654588, acc.: 61.72%] [G loss: 1.126788]\n",
      "epoch:17 step:16357 [D loss: 0.661139, acc.: 60.16%] [G loss: 0.952523]\n",
      "epoch:17 step:16358 [D loss: 0.547976, acc.: 79.69%] [G loss: 1.301614]\n",
      "epoch:17 step:16359 [D loss: 0.580548, acc.: 71.88%] [G loss: 1.222009]\n",
      "epoch:17 step:16360 [D loss: 0.670305, acc.: 59.38%] [G loss: 1.278901]\n",
      "epoch:17 step:16361 [D loss: 0.675001, acc.: 57.81%] [G loss: 1.034180]\n",
      "epoch:17 step:16362 [D loss: 0.551038, acc.: 73.44%] [G loss: 1.418428]\n",
      "epoch:17 step:16363 [D loss: 0.550691, acc.: 69.53%] [G loss: 1.272904]\n",
      "epoch:17 step:16364 [D loss: 0.629667, acc.: 64.06%] [G loss: 1.131850]\n",
      "epoch:17 step:16365 [D loss: 0.496762, acc.: 80.47%] [G loss: 1.241947]\n",
      "epoch:17 step:16366 [D loss: 0.752636, acc.: 53.91%] [G loss: 1.054777]\n",
      "epoch:17 step:16367 [D loss: 0.686039, acc.: 60.16%] [G loss: 0.820341]\n",
      "epoch:17 step:16368 [D loss: 0.698805, acc.: 56.25%] [G loss: 0.949705]\n",
      "epoch:17 step:16369 [D loss: 0.640628, acc.: 60.16%] [G loss: 1.040670]\n",
      "epoch:17 step:16370 [D loss: 0.649642, acc.: 58.59%] [G loss: 0.905060]\n",
      "epoch:17 step:16371 [D loss: 0.755721, acc.: 54.69%] [G loss: 0.856414]\n",
      "epoch:17 step:16372 [D loss: 0.602630, acc.: 65.62%] [G loss: 1.068278]\n",
      "epoch:17 step:16373 [D loss: 0.556946, acc.: 72.66%] [G loss: 1.101459]\n",
      "epoch:17 step:16374 [D loss: 0.728739, acc.: 53.12%] [G loss: 1.008009]\n",
      "epoch:17 step:16375 [D loss: 0.946125, acc.: 30.47%] [G loss: 0.870193]\n",
      "epoch:17 step:16376 [D loss: 0.641201, acc.: 64.84%] [G loss: 0.928660]\n",
      "epoch:17 step:16377 [D loss: 0.609625, acc.: 67.19%] [G loss: 0.955044]\n",
      "epoch:17 step:16378 [D loss: 0.535542, acc.: 72.66%] [G loss: 1.049190]\n",
      "epoch:17 step:16379 [D loss: 0.602327, acc.: 69.53%] [G loss: 1.014555]\n",
      "epoch:17 step:16380 [D loss: 0.490976, acc.: 80.47%] [G loss: 1.128481]\n",
      "epoch:17 step:16381 [D loss: 0.534944, acc.: 72.66%] [G loss: 1.119749]\n",
      "epoch:17 step:16382 [D loss: 0.454439, acc.: 84.38%] [G loss: 1.368477]\n",
      "epoch:17 step:16383 [D loss: 0.558656, acc.: 72.66%] [G loss: 1.271986]\n",
      "epoch:17 step:16384 [D loss: 0.633950, acc.: 60.16%] [G loss: 1.053629]\n",
      "epoch:17 step:16385 [D loss: 0.507581, acc.: 80.47%] [G loss: 1.077321]\n",
      "epoch:17 step:16386 [D loss: 0.541348, acc.: 73.44%] [G loss: 0.751697]\n",
      "epoch:17 step:16387 [D loss: 0.886254, acc.: 40.62%] [G loss: 1.175561]\n",
      "epoch:17 step:16388 [D loss: 0.821633, acc.: 39.84%] [G loss: 1.076087]\n",
      "epoch:17 step:16389 [D loss: 0.874336, acc.: 31.25%] [G loss: 0.932176]\n",
      "epoch:17 step:16390 [D loss: 0.700786, acc.: 55.47%] [G loss: 1.174423]\n",
      "epoch:17 step:16391 [D loss: 0.646584, acc.: 68.75%] [G loss: 1.239068]\n",
      "epoch:17 step:16392 [D loss: 0.712950, acc.: 57.03%] [G loss: 1.088494]\n",
      "epoch:17 step:16393 [D loss: 0.599479, acc.: 64.84%] [G loss: 1.024204]\n",
      "epoch:17 step:16394 [D loss: 0.602101, acc.: 67.19%] [G loss: 0.988457]\n",
      "epoch:17 step:16395 [D loss: 0.543051, acc.: 70.31%] [G loss: 1.100929]\n",
      "epoch:17 step:16396 [D loss: 0.612364, acc.: 65.62%] [G loss: 1.163269]\n",
      "epoch:17 step:16397 [D loss: 0.573283, acc.: 71.88%] [G loss: 1.204894]\n",
      "epoch:17 step:16398 [D loss: 0.550988, acc.: 67.19%] [G loss: 0.994108]\n",
      "epoch:17 step:16399 [D loss: 0.422281, acc.: 85.16%] [G loss: 1.102701]\n",
      "epoch:17 step:16400 [D loss: 0.421938, acc.: 77.34%] [G loss: 1.243150]\n",
      "##############\n",
      "[2.14427422 1.45758321 5.36280276 4.24509596 2.94537288 5.47403369\n",
      " 3.80679177 4.41239831 3.83544233 3.53944053]\n",
      "##########\n",
      "epoch:17 step:16401 [D loss: 0.443645, acc.: 78.91%] [G loss: 1.335093]\n",
      "epoch:17 step:16402 [D loss: 0.644603, acc.: 65.62%] [G loss: 1.425118]\n",
      "epoch:17 step:16403 [D loss: 0.484915, acc.: 83.59%] [G loss: 1.212336]\n",
      "epoch:17 step:16404 [D loss: 0.583582, acc.: 74.22%] [G loss: 1.187695]\n",
      "epoch:17 step:16405 [D loss: 0.602199, acc.: 65.62%] [G loss: 1.192510]\n",
      "epoch:17 step:16406 [D loss: 0.654411, acc.: 54.69%] [G loss: 1.434965]\n",
      "epoch:17 step:16407 [D loss: 0.690832, acc.: 56.25%] [G loss: 1.005665]\n",
      "epoch:17 step:16408 [D loss: 0.640708, acc.: 62.50%] [G loss: 0.964776]\n",
      "epoch:17 step:16409 [D loss: 0.609297, acc.: 66.41%] [G loss: 1.025199]\n",
      "epoch:17 step:16410 [D loss: 0.556349, acc.: 70.31%] [G loss: 1.042349]\n",
      "epoch:17 step:16411 [D loss: 0.636396, acc.: 64.84%] [G loss: 1.076248]\n",
      "epoch:17 step:16412 [D loss: 0.682238, acc.: 57.03%] [G loss: 1.029141]\n",
      "epoch:17 step:16413 [D loss: 0.538983, acc.: 75.78%] [G loss: 1.075892]\n",
      "epoch:17 step:16414 [D loss: 0.554176, acc.: 75.78%] [G loss: 1.286798]\n",
      "epoch:17 step:16415 [D loss: 0.619693, acc.: 65.62%] [G loss: 1.076136]\n",
      "epoch:17 step:16416 [D loss: 0.612754, acc.: 67.19%] [G loss: 1.009818]\n",
      "epoch:17 step:16417 [D loss: 0.540214, acc.: 80.47%] [G loss: 1.129663]\n",
      "epoch:17 step:16418 [D loss: 0.603299, acc.: 71.09%] [G loss: 1.094266]\n",
      "epoch:17 step:16419 [D loss: 0.524868, acc.: 82.03%] [G loss: 1.063417]\n",
      "epoch:17 step:16420 [D loss: 0.717974, acc.: 51.56%] [G loss: 0.897557]\n",
      "epoch:17 step:16421 [D loss: 0.692634, acc.: 53.12%] [G loss: 0.933624]\n",
      "epoch:17 step:16422 [D loss: 0.654300, acc.: 64.84%] [G loss: 1.062633]\n",
      "epoch:17 step:16423 [D loss: 0.567807, acc.: 71.88%] [G loss: 1.062717]\n",
      "epoch:17 step:16424 [D loss: 0.668296, acc.: 58.59%] [G loss: 0.871528]\n",
      "epoch:17 step:16425 [D loss: 0.649179, acc.: 61.72%] [G loss: 1.084991]\n",
      "epoch:17 step:16426 [D loss: 0.704951, acc.: 53.91%] [G loss: 1.034338]\n",
      "epoch:17 step:16427 [D loss: 0.618352, acc.: 62.50%] [G loss: 1.301692]\n",
      "epoch:17 step:16428 [D loss: 0.421208, acc.: 89.84%] [G loss: 1.155184]\n",
      "epoch:17 step:16429 [D loss: 0.723953, acc.: 50.00%] [G loss: 1.118039]\n",
      "epoch:17 step:16430 [D loss: 0.709008, acc.: 53.12%] [G loss: 1.014676]\n",
      "epoch:17 step:16431 [D loss: 0.749270, acc.: 50.00%] [G loss: 0.897252]\n",
      "epoch:17 step:16432 [D loss: 0.475179, acc.: 82.03%] [G loss: 0.983513]\n",
      "epoch:17 step:16433 [D loss: 0.467936, acc.: 80.47%] [G loss: 1.166889]\n",
      "epoch:17 step:16434 [D loss: 0.549112, acc.: 76.56%] [G loss: 1.176750]\n",
      "epoch:17 step:16435 [D loss: 0.636905, acc.: 65.62%] [G loss: 0.984380]\n",
      "epoch:17 step:16436 [D loss: 0.489691, acc.: 77.34%] [G loss: 1.210776]\n",
      "epoch:17 step:16437 [D loss: 0.394305, acc.: 83.59%] [G loss: 1.159491]\n",
      "epoch:17 step:16438 [D loss: 0.744353, acc.: 50.00%] [G loss: 1.139917]\n",
      "epoch:17 step:16439 [D loss: 0.795128, acc.: 44.53%] [G loss: 1.040771]\n",
      "epoch:17 step:16440 [D loss: 0.593919, acc.: 72.66%] [G loss: 1.053563]\n",
      "epoch:17 step:16441 [D loss: 0.580914, acc.: 73.44%] [G loss: 0.865552]\n",
      "epoch:17 step:16442 [D loss: 0.542073, acc.: 77.34%] [G loss: 1.065234]\n",
      "epoch:17 step:16443 [D loss: 0.522515, acc.: 76.56%] [G loss: 1.237097]\n",
      "epoch:17 step:16444 [D loss: 0.588470, acc.: 71.88%] [G loss: 1.219113]\n",
      "epoch:17 step:16445 [D loss: 0.686504, acc.: 57.03%] [G loss: 0.881243]\n",
      "epoch:17 step:16446 [D loss: 0.648332, acc.: 62.50%] [G loss: 0.954465]\n",
      "epoch:17 step:16447 [D loss: 0.621531, acc.: 63.28%] [G loss: 1.014568]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16448 [D loss: 0.550571, acc.: 74.22%] [G loss: 1.137235]\n",
      "epoch:17 step:16449 [D loss: 0.577595, acc.: 71.09%] [G loss: 1.076127]\n",
      "epoch:17 step:16450 [D loss: 0.602060, acc.: 68.75%] [G loss: 0.945230]\n",
      "epoch:17 step:16451 [D loss: 0.694436, acc.: 58.59%] [G loss: 0.780976]\n",
      "epoch:17 step:16452 [D loss: 0.492102, acc.: 79.69%] [G loss: 1.061948]\n",
      "epoch:17 step:16453 [D loss: 0.684678, acc.: 57.03%] [G loss: 1.054810]\n",
      "epoch:17 step:16454 [D loss: 0.751079, acc.: 46.09%] [G loss: 0.949264]\n",
      "epoch:17 step:16455 [D loss: 0.676912, acc.: 59.38%] [G loss: 0.996423]\n",
      "epoch:17 step:16456 [D loss: 0.656370, acc.: 64.84%] [G loss: 0.976709]\n",
      "epoch:17 step:16457 [D loss: 0.624899, acc.: 61.72%] [G loss: 0.908991]\n",
      "epoch:17 step:16458 [D loss: 0.634217, acc.: 67.19%] [G loss: 0.866281]\n",
      "epoch:17 step:16459 [D loss: 0.651266, acc.: 64.06%] [G loss: 0.963904]\n",
      "epoch:17 step:16460 [D loss: 0.709425, acc.: 54.69%] [G loss: 1.049514]\n",
      "epoch:17 step:16461 [D loss: 0.609031, acc.: 69.53%] [G loss: 0.917043]\n",
      "epoch:17 step:16462 [D loss: 0.506140, acc.: 74.22%] [G loss: 0.932466]\n",
      "epoch:17 step:16463 [D loss: 0.596747, acc.: 66.41%] [G loss: 0.980164]\n",
      "epoch:17 step:16464 [D loss: 0.644525, acc.: 60.16%] [G loss: 1.052611]\n",
      "epoch:17 step:16465 [D loss: 0.583400, acc.: 71.88%] [G loss: 0.867961]\n",
      "epoch:17 step:16466 [D loss: 0.561520, acc.: 71.09%] [G loss: 1.073530]\n",
      "epoch:17 step:16467 [D loss: 0.649684, acc.: 62.50%] [G loss: 1.172311]\n",
      "epoch:17 step:16468 [D loss: 0.673361, acc.: 60.16%] [G loss: 0.841423]\n",
      "epoch:17 step:16469 [D loss: 0.643515, acc.: 57.81%] [G loss: 0.921701]\n",
      "epoch:17 step:16470 [D loss: 0.631042, acc.: 64.06%] [G loss: 1.040760]\n",
      "epoch:17 step:16471 [D loss: 0.572303, acc.: 67.19%] [G loss: 0.978349]\n",
      "epoch:17 step:16472 [D loss: 0.633617, acc.: 61.72%] [G loss: 0.888341]\n",
      "epoch:17 step:16473 [D loss: 0.593723, acc.: 69.53%] [G loss: 1.013944]\n",
      "epoch:17 step:16474 [D loss: 0.536273, acc.: 75.00%] [G loss: 1.024575]\n",
      "epoch:17 step:16475 [D loss: 0.474326, acc.: 79.69%] [G loss: 1.149501]\n",
      "epoch:17 step:16476 [D loss: 0.420419, acc.: 89.06%] [G loss: 1.187477]\n",
      "epoch:17 step:16477 [D loss: 0.435316, acc.: 87.50%] [G loss: 1.163735]\n",
      "epoch:17 step:16478 [D loss: 0.458356, acc.: 83.59%] [G loss: 0.985725]\n",
      "epoch:17 step:16479 [D loss: 0.475300, acc.: 85.16%] [G loss: 1.134154]\n",
      "epoch:17 step:16480 [D loss: 0.331946, acc.: 93.75%] [G loss: 1.310692]\n",
      "epoch:17 step:16481 [D loss: 0.521584, acc.: 81.25%] [G loss: 1.164833]\n",
      "epoch:17 step:16482 [D loss: 0.519189, acc.: 76.56%] [G loss: 1.287483]\n",
      "epoch:17 step:16483 [D loss: 0.338002, acc.: 92.19%] [G loss: 1.333373]\n",
      "epoch:17 step:16484 [D loss: 0.546983, acc.: 62.50%] [G loss: 1.265956]\n",
      "epoch:17 step:16485 [D loss: 0.440269, acc.: 85.94%] [G loss: 1.397921]\n",
      "epoch:17 step:16486 [D loss: 0.408621, acc.: 88.28%] [G loss: 1.437595]\n",
      "epoch:17 step:16487 [D loss: 0.550573, acc.: 71.88%] [G loss: 1.225317]\n",
      "epoch:17 step:16488 [D loss: 1.043551, acc.: 35.16%] [G loss: 1.147004]\n",
      "epoch:17 step:16489 [D loss: 0.815600, acc.: 50.78%] [G loss: 1.325122]\n",
      "epoch:17 step:16490 [D loss: 0.543974, acc.: 73.44%] [G loss: 1.310783]\n",
      "epoch:17 step:16491 [D loss: 0.705975, acc.: 57.03%] [G loss: 1.296444]\n",
      "epoch:17 step:16492 [D loss: 0.691795, acc.: 55.47%] [G loss: 1.128031]\n",
      "epoch:17 step:16493 [D loss: 0.571830, acc.: 74.22%] [G loss: 1.059460]\n",
      "epoch:17 step:16494 [D loss: 0.638757, acc.: 62.50%] [G loss: 1.032911]\n",
      "epoch:17 step:16495 [D loss: 0.353358, acc.: 92.97%] [G loss: 1.225669]\n",
      "epoch:17 step:16496 [D loss: 0.415802, acc.: 85.94%] [G loss: 1.524798]\n",
      "epoch:17 step:16497 [D loss: 0.573558, acc.: 69.53%] [G loss: 1.092683]\n",
      "epoch:17 step:16498 [D loss: 0.671535, acc.: 56.25%] [G loss: 1.092211]\n",
      "epoch:17 step:16499 [D loss: 0.705576, acc.: 53.91%] [G loss: 1.018901]\n",
      "epoch:17 step:16500 [D loss: 0.563516, acc.: 72.66%] [G loss: 0.908063]\n",
      "epoch:17 step:16501 [D loss: 0.623667, acc.: 60.16%] [G loss: 1.052788]\n",
      "epoch:17 step:16502 [D loss: 0.597927, acc.: 67.97%] [G loss: 1.056469]\n",
      "epoch:17 step:16503 [D loss: 0.449216, acc.: 85.94%] [G loss: 1.273702]\n",
      "epoch:17 step:16504 [D loss: 0.467433, acc.: 83.59%] [G loss: 1.375819]\n",
      "epoch:17 step:16505 [D loss: 0.448280, acc.: 84.38%] [G loss: 1.131624]\n",
      "epoch:17 step:16506 [D loss: 0.505090, acc.: 79.69%] [G loss: 1.181869]\n",
      "epoch:17 step:16507 [D loss: 0.448958, acc.: 84.38%] [G loss: 1.357517]\n",
      "epoch:17 step:16508 [D loss: 0.709487, acc.: 53.12%] [G loss: 0.692469]\n",
      "epoch:17 step:16509 [D loss: 0.826287, acc.: 45.31%] [G loss: 1.039065]\n",
      "epoch:17 step:16510 [D loss: 0.643047, acc.: 60.16%] [G loss: 0.942674]\n",
      "epoch:17 step:16511 [D loss: 0.824990, acc.: 46.88%] [G loss: 0.842171]\n",
      "epoch:17 step:16512 [D loss: 0.714816, acc.: 53.91%] [G loss: 0.849163]\n",
      "epoch:17 step:16513 [D loss: 0.842394, acc.: 44.53%] [G loss: 0.787553]\n",
      "epoch:17 step:16514 [D loss: 0.675247, acc.: 58.59%] [G loss: 1.107121]\n",
      "epoch:17 step:16515 [D loss: 0.811985, acc.: 41.41%] [G loss: 0.910933]\n",
      "epoch:17 step:16516 [D loss: 0.757069, acc.: 53.12%] [G loss: 0.797004]\n",
      "epoch:17 step:16517 [D loss: 0.440709, acc.: 85.94%] [G loss: 1.493785]\n",
      "epoch:17 step:16518 [D loss: 0.481731, acc.: 77.34%] [G loss: 1.655275]\n",
      "epoch:17 step:16519 [D loss: 0.788041, acc.: 42.97%] [G loss: 0.971171]\n",
      "epoch:17 step:16520 [D loss: 0.820832, acc.: 38.28%] [G loss: 1.132439]\n",
      "epoch:17 step:16521 [D loss: 0.607239, acc.: 66.41%] [G loss: 1.015833]\n",
      "epoch:17 step:16522 [D loss: 0.615160, acc.: 60.16%] [G loss: 1.274555]\n",
      "epoch:17 step:16523 [D loss: 0.536402, acc.: 75.00%] [G loss: 1.067866]\n",
      "epoch:17 step:16524 [D loss: 0.623793, acc.: 61.72%] [G loss: 0.850932]\n",
      "epoch:17 step:16525 [D loss: 0.594339, acc.: 68.75%] [G loss: 1.125322]\n",
      "epoch:17 step:16526 [D loss: 0.494046, acc.: 79.69%] [G loss: 1.121710]\n",
      "epoch:17 step:16527 [D loss: 0.413413, acc.: 87.50%] [G loss: 1.272952]\n",
      "epoch:17 step:16528 [D loss: 0.520601, acc.: 76.56%] [G loss: 1.403727]\n",
      "epoch:17 step:16529 [D loss: 0.683903, acc.: 57.03%] [G loss: 1.118121]\n",
      "epoch:17 step:16530 [D loss: 0.530717, acc.: 75.78%] [G loss: 1.090659]\n",
      "epoch:17 step:16531 [D loss: 0.760058, acc.: 50.00%] [G loss: 1.003667]\n",
      "epoch:17 step:16532 [D loss: 0.437837, acc.: 85.94%] [G loss: 1.374732]\n",
      "epoch:17 step:16533 [D loss: 0.417346, acc.: 87.50%] [G loss: 1.270127]\n",
      "epoch:17 step:16534 [D loss: 0.427030, acc.: 82.81%] [G loss: 1.500738]\n",
      "epoch:17 step:16535 [D loss: 0.650863, acc.: 62.50%] [G loss: 1.083015]\n",
      "epoch:17 step:16536 [D loss: 0.668865, acc.: 55.47%] [G loss: 1.298756]\n",
      "epoch:17 step:16537 [D loss: 0.506615, acc.: 82.81%] [G loss: 1.223478]\n",
      "epoch:17 step:16538 [D loss: 0.790777, acc.: 43.75%] [G loss: 1.014204]\n",
      "epoch:17 step:16539 [D loss: 0.599395, acc.: 71.88%] [G loss: 1.242807]\n",
      "epoch:17 step:16540 [D loss: 0.829089, acc.: 36.72%] [G loss: 0.903107]\n",
      "epoch:17 step:16541 [D loss: 0.695323, acc.: 54.69%] [G loss: 1.015911]\n",
      "epoch:17 step:16542 [D loss: 0.559286, acc.: 67.19%] [G loss: 0.969099]\n",
      "epoch:17 step:16543 [D loss: 0.532961, acc.: 77.34%] [G loss: 0.933621]\n",
      "epoch:17 step:16544 [D loss: 0.517523, acc.: 71.88%] [G loss: 1.339098]\n",
      "epoch:17 step:16545 [D loss: 0.508384, acc.: 78.12%] [G loss: 1.347698]\n",
      "epoch:17 step:16546 [D loss: 0.642402, acc.: 63.28%] [G loss: 1.000949]\n",
      "epoch:17 step:16547 [D loss: 0.895776, acc.: 31.25%] [G loss: 1.113922]\n",
      "epoch:17 step:16548 [D loss: 0.787596, acc.: 46.09%] [G loss: 1.233474]\n",
      "epoch:17 step:16549 [D loss: 0.585341, acc.: 65.62%] [G loss: 1.335328]\n",
      "epoch:17 step:16550 [D loss: 0.811297, acc.: 40.62%] [G loss: 1.168909]\n",
      "epoch:17 step:16551 [D loss: 0.631573, acc.: 63.28%] [G loss: 1.321240]\n",
      "epoch:17 step:16552 [D loss: 0.663781, acc.: 62.50%] [G loss: 1.208946]\n",
      "epoch:17 step:16553 [D loss: 0.556420, acc.: 73.44%] [G loss: 1.146230]\n",
      "epoch:17 step:16554 [D loss: 0.652261, acc.: 63.28%] [G loss: 1.092384]\n",
      "epoch:17 step:16555 [D loss: 0.666594, acc.: 56.25%] [G loss: 0.823422]\n",
      "epoch:17 step:16556 [D loss: 0.607416, acc.: 64.06%] [G loss: 1.120736]\n",
      "epoch:17 step:16557 [D loss: 0.656821, acc.: 60.16%] [G loss: 0.987065]\n",
      "epoch:17 step:16558 [D loss: 0.665180, acc.: 59.38%] [G loss: 0.994807]\n",
      "epoch:17 step:16559 [D loss: 0.759505, acc.: 48.44%] [G loss: 0.926120]\n",
      "epoch:17 step:16560 [D loss: 0.623078, acc.: 68.75%] [G loss: 0.768432]\n",
      "epoch:17 step:16561 [D loss: 0.710936, acc.: 52.34%] [G loss: 0.975623]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16562 [D loss: 0.638083, acc.: 67.97%] [G loss: 1.067383]\n",
      "epoch:17 step:16563 [D loss: 0.546960, acc.: 72.66%] [G loss: 1.256270]\n",
      "epoch:17 step:16564 [D loss: 0.575844, acc.: 68.75%] [G loss: 0.999329]\n",
      "epoch:17 step:16565 [D loss: 0.594091, acc.: 69.53%] [G loss: 0.915060]\n",
      "epoch:17 step:16566 [D loss: 0.673238, acc.: 56.25%] [G loss: 1.027698]\n",
      "epoch:17 step:16567 [D loss: 0.574587, acc.: 71.09%] [G loss: 1.125569]\n",
      "epoch:17 step:16568 [D loss: 0.731008, acc.: 49.22%] [G loss: 0.964636]\n",
      "epoch:17 step:16569 [D loss: 0.532306, acc.: 77.34%] [G loss: 1.071571]\n",
      "epoch:17 step:16570 [D loss: 0.628504, acc.: 60.16%] [G loss: 1.096430]\n",
      "epoch:17 step:16571 [D loss: 0.551722, acc.: 75.00%] [G loss: 1.219021]\n",
      "epoch:17 step:16572 [D loss: 0.654566, acc.: 60.16%] [G loss: 1.049248]\n",
      "epoch:17 step:16573 [D loss: 0.809230, acc.: 46.09%] [G loss: 0.823039]\n",
      "epoch:17 step:16574 [D loss: 0.643000, acc.: 63.28%] [G loss: 0.897666]\n",
      "epoch:17 step:16575 [D loss: 0.484945, acc.: 79.69%] [G loss: 1.094182]\n",
      "epoch:17 step:16576 [D loss: 0.434721, acc.: 84.38%] [G loss: 1.097651]\n",
      "epoch:17 step:16577 [D loss: 0.416670, acc.: 85.16%] [G loss: 1.310204]\n",
      "epoch:17 step:16578 [D loss: 0.420569, acc.: 89.06%] [G loss: 1.062553]\n",
      "epoch:17 step:16579 [D loss: 0.425202, acc.: 88.28%] [G loss: 1.174403]\n",
      "epoch:17 step:16580 [D loss: 0.621821, acc.: 71.09%] [G loss: 1.212508]\n",
      "epoch:17 step:16581 [D loss: 0.840674, acc.: 50.00%] [G loss: 1.129353]\n",
      "epoch:17 step:16582 [D loss: 0.909838, acc.: 37.50%] [G loss: 1.009707]\n",
      "epoch:17 step:16583 [D loss: 0.793864, acc.: 44.53%] [G loss: 1.017291]\n",
      "epoch:17 step:16584 [D loss: 0.660181, acc.: 60.94%] [G loss: 1.037073]\n",
      "epoch:17 step:16585 [D loss: 0.635041, acc.: 67.19%] [G loss: 1.032658]\n",
      "epoch:17 step:16586 [D loss: 0.777173, acc.: 50.00%] [G loss: 0.753346]\n",
      "epoch:17 step:16587 [D loss: 0.752612, acc.: 47.66%] [G loss: 0.984974]\n",
      "epoch:17 step:16588 [D loss: 0.649261, acc.: 57.81%] [G loss: 1.044168]\n",
      "epoch:17 step:16589 [D loss: 0.623153, acc.: 64.06%] [G loss: 0.977165]\n",
      "epoch:17 step:16590 [D loss: 0.643891, acc.: 63.28%] [G loss: 1.194844]\n",
      "epoch:17 step:16591 [D loss: 0.589256, acc.: 67.19%] [G loss: 1.157586]\n",
      "epoch:17 step:16592 [D loss: 0.489509, acc.: 80.47%] [G loss: 1.293208]\n",
      "epoch:17 step:16593 [D loss: 0.443520, acc.: 85.94%] [G loss: 1.359276]\n",
      "epoch:17 step:16594 [D loss: 0.385512, acc.: 89.06%] [G loss: 1.307980]\n",
      "epoch:17 step:16595 [D loss: 0.464600, acc.: 82.03%] [G loss: 1.423118]\n",
      "epoch:17 step:16596 [D loss: 0.572617, acc.: 68.75%] [G loss: 0.956982]\n",
      "epoch:17 step:16597 [D loss: 0.698987, acc.: 52.34%] [G loss: 1.024014]\n",
      "epoch:17 step:16598 [D loss: 0.583552, acc.: 64.06%] [G loss: 0.900342]\n",
      "epoch:17 step:16599 [D loss: 0.652748, acc.: 63.28%] [G loss: 0.998385]\n",
      "epoch:17 step:16600 [D loss: 0.741530, acc.: 52.34%] [G loss: 0.942467]\n",
      "##############\n",
      "[2.08438891 1.28209997 5.35464405 3.83917194 2.72587891 5.14451778\n",
      " 3.91072326 4.42126072 3.80854621 3.74198741]\n",
      "##########\n",
      "epoch:17 step:16601 [D loss: 0.788035, acc.: 50.78%] [G loss: 1.082829]\n",
      "epoch:17 step:16602 [D loss: 0.746428, acc.: 53.12%] [G loss: 0.795699]\n",
      "epoch:17 step:16603 [D loss: 0.826365, acc.: 42.97%] [G loss: 0.839915]\n",
      "epoch:17 step:16604 [D loss: 0.759058, acc.: 42.97%] [G loss: 0.957169]\n",
      "epoch:17 step:16605 [D loss: 0.606157, acc.: 66.41%] [G loss: 1.034539]\n",
      "epoch:17 step:16606 [D loss: 0.726399, acc.: 53.12%] [G loss: 1.176697]\n",
      "epoch:17 step:16607 [D loss: 0.806326, acc.: 42.19%] [G loss: 1.110838]\n",
      "epoch:17 step:16608 [D loss: 0.628291, acc.: 67.19%] [G loss: 1.088211]\n",
      "epoch:17 step:16609 [D loss: 0.729501, acc.: 52.34%] [G loss: 0.973569]\n",
      "epoch:17 step:16610 [D loss: 0.689868, acc.: 59.38%] [G loss: 1.060937]\n",
      "epoch:17 step:16611 [D loss: 0.535324, acc.: 75.78%] [G loss: 0.983669]\n",
      "epoch:17 step:16612 [D loss: 0.666144, acc.: 63.28%] [G loss: 0.931034]\n",
      "epoch:17 step:16613 [D loss: 0.669723, acc.: 61.72%] [G loss: 1.130862]\n",
      "epoch:17 step:16614 [D loss: 0.602437, acc.: 70.31%] [G loss: 0.921912]\n",
      "epoch:17 step:16615 [D loss: 0.806817, acc.: 42.97%] [G loss: 0.862283]\n",
      "epoch:17 step:16616 [D loss: 0.679722, acc.: 57.03%] [G loss: 0.911882]\n",
      "epoch:17 step:16617 [D loss: 0.730329, acc.: 51.56%] [G loss: 0.862298]\n",
      "epoch:17 step:16618 [D loss: 0.614510, acc.: 61.72%] [G loss: 1.038186]\n",
      "epoch:17 step:16619 [D loss: 0.519110, acc.: 78.91%] [G loss: 1.063369]\n",
      "epoch:17 step:16620 [D loss: 0.554712, acc.: 76.56%] [G loss: 1.097539]\n",
      "epoch:17 step:16621 [D loss: 0.515058, acc.: 78.91%] [G loss: 1.035740]\n",
      "epoch:17 step:16622 [D loss: 0.521714, acc.: 82.03%] [G loss: 1.003949]\n",
      "epoch:17 step:16623 [D loss: 0.353380, acc.: 93.75%] [G loss: 1.248958]\n",
      "epoch:17 step:16624 [D loss: 0.476236, acc.: 79.69%] [G loss: 1.317420]\n",
      "epoch:17 step:16625 [D loss: 0.701082, acc.: 53.91%] [G loss: 1.204875]\n",
      "epoch:17 step:16626 [D loss: 0.717201, acc.: 50.00%] [G loss: 0.918523]\n",
      "epoch:17 step:16627 [D loss: 0.712059, acc.: 56.25%] [G loss: 1.004983]\n",
      "epoch:17 step:16628 [D loss: 0.632129, acc.: 62.50%] [G loss: 0.924949]\n",
      "epoch:17 step:16629 [D loss: 0.654777, acc.: 60.94%] [G loss: 0.951340]\n",
      "epoch:17 step:16630 [D loss: 0.609331, acc.: 67.97%] [G loss: 0.974364]\n",
      "epoch:17 step:16631 [D loss: 0.687421, acc.: 57.03%] [G loss: 0.925395]\n",
      "epoch:17 step:16632 [D loss: 0.646470, acc.: 64.06%] [G loss: 1.064053]\n",
      "epoch:17 step:16633 [D loss: 0.756512, acc.: 53.12%] [G loss: 0.872077]\n",
      "epoch:17 step:16634 [D loss: 0.662940, acc.: 60.94%] [G loss: 0.945535]\n",
      "epoch:17 step:16635 [D loss: 0.490046, acc.: 78.91%] [G loss: 1.057728]\n",
      "epoch:17 step:16636 [D loss: 0.600155, acc.: 67.19%] [G loss: 0.882956]\n",
      "epoch:17 step:16637 [D loss: 0.523242, acc.: 73.44%] [G loss: 1.188410]\n",
      "epoch:17 step:16638 [D loss: 0.416702, acc.: 86.72%] [G loss: 1.296186]\n",
      "epoch:17 step:16639 [D loss: 0.720644, acc.: 54.69%] [G loss: 1.119927]\n",
      "epoch:17 step:16640 [D loss: 0.748148, acc.: 50.00%] [G loss: 1.030385]\n",
      "epoch:17 step:16641 [D loss: 0.588664, acc.: 68.75%] [G loss: 1.161335]\n",
      "epoch:17 step:16642 [D loss: 0.458826, acc.: 75.78%] [G loss: 1.087255]\n",
      "epoch:17 step:16643 [D loss: 0.524663, acc.: 75.00%] [G loss: 1.047724]\n",
      "epoch:17 step:16644 [D loss: 0.608110, acc.: 64.84%] [G loss: 1.157297]\n",
      "epoch:17 step:16645 [D loss: 0.881186, acc.: 35.16%] [G loss: 1.003506]\n",
      "epoch:17 step:16646 [D loss: 0.760214, acc.: 48.44%] [G loss: 0.800286]\n",
      "epoch:17 step:16647 [D loss: 0.773764, acc.: 49.22%] [G loss: 0.921423]\n",
      "epoch:17 step:16648 [D loss: 0.772215, acc.: 46.09%] [G loss: 1.009503]\n",
      "epoch:17 step:16649 [D loss: 0.536349, acc.: 75.78%] [G loss: 0.989951]\n",
      "epoch:17 step:16650 [D loss: 0.710960, acc.: 53.91%] [G loss: 0.865267]\n",
      "epoch:17 step:16651 [D loss: 0.644393, acc.: 62.50%] [G loss: 0.930322]\n",
      "epoch:17 step:16652 [D loss: 0.551947, acc.: 76.56%] [G loss: 0.976655]\n",
      "epoch:17 step:16653 [D loss: 0.423084, acc.: 88.28%] [G loss: 1.165276]\n",
      "epoch:17 step:16654 [D loss: 0.529873, acc.: 74.22%] [G loss: 1.108502]\n",
      "epoch:17 step:16655 [D loss: 0.569870, acc.: 67.97%] [G loss: 1.183145]\n",
      "epoch:17 step:16656 [D loss: 0.715803, acc.: 55.47%] [G loss: 0.878125]\n",
      "epoch:17 step:16657 [D loss: 0.607459, acc.: 68.75%] [G loss: 1.144318]\n",
      "epoch:17 step:16658 [D loss: 0.642767, acc.: 58.59%] [G loss: 1.229484]\n",
      "epoch:17 step:16659 [D loss: 0.635949, acc.: 66.41%] [G loss: 1.172940]\n",
      "epoch:17 step:16660 [D loss: 0.524947, acc.: 79.69%] [G loss: 1.094037]\n",
      "epoch:17 step:16661 [D loss: 0.516000, acc.: 78.12%] [G loss: 1.131880]\n",
      "epoch:17 step:16662 [D loss: 0.609683, acc.: 67.19%] [G loss: 1.113774]\n",
      "epoch:17 step:16663 [D loss: 0.781276, acc.: 45.31%] [G loss: 0.993519]\n",
      "epoch:17 step:16664 [D loss: 0.769742, acc.: 41.41%] [G loss: 0.992328]\n",
      "epoch:17 step:16665 [D loss: 0.653081, acc.: 60.94%] [G loss: 1.120374]\n",
      "epoch:17 step:16666 [D loss: 0.650282, acc.: 66.41%] [G loss: 1.108646]\n",
      "epoch:17 step:16667 [D loss: 0.708195, acc.: 54.69%] [G loss: 1.031794]\n",
      "epoch:17 step:16668 [D loss: 0.654572, acc.: 60.16%] [G loss: 0.939531]\n",
      "epoch:17 step:16669 [D loss: 0.650887, acc.: 58.59%] [G loss: 0.914404]\n",
      "epoch:17 step:16670 [D loss: 0.456220, acc.: 88.28%] [G loss: 0.903725]\n",
      "epoch:17 step:16671 [D loss: 0.597153, acc.: 69.53%] [G loss: 0.882500]\n",
      "epoch:17 step:16672 [D loss: 0.594215, acc.: 66.41%] [G loss: 0.909983]\n",
      "epoch:17 step:16673 [D loss: 0.672817, acc.: 55.47%] [G loss: 0.945261]\n",
      "epoch:17 step:16674 [D loss: 0.600773, acc.: 66.41%] [G loss: 1.095299]\n",
      "epoch:17 step:16675 [D loss: 0.572499, acc.: 75.00%] [G loss: 1.036135]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16676 [D loss: 0.646760, acc.: 59.38%] [G loss: 1.092789]\n",
      "epoch:17 step:16677 [D loss: 0.706839, acc.: 59.38%] [G loss: 0.902167]\n",
      "epoch:17 step:16678 [D loss: 0.615086, acc.: 67.97%] [G loss: 0.995696]\n",
      "epoch:17 step:16679 [D loss: 0.533188, acc.: 75.00%] [G loss: 1.114952]\n",
      "epoch:17 step:16680 [D loss: 0.599423, acc.: 66.41%] [G loss: 1.034110]\n",
      "epoch:17 step:16681 [D loss: 0.695314, acc.: 58.59%] [G loss: 0.939632]\n",
      "epoch:17 step:16682 [D loss: 0.604430, acc.: 64.84%] [G loss: 0.928232]\n",
      "epoch:17 step:16683 [D loss: 0.652735, acc.: 64.06%] [G loss: 0.998103]\n",
      "epoch:17 step:16684 [D loss: 0.505895, acc.: 78.91%] [G loss: 1.170478]\n",
      "epoch:17 step:16685 [D loss: 0.606694, acc.: 65.62%] [G loss: 0.817013]\n",
      "epoch:17 step:16686 [D loss: 0.602532, acc.: 71.88%] [G loss: 0.985233]\n",
      "epoch:17 step:16687 [D loss: 0.689751, acc.: 54.69%] [G loss: 0.948239]\n",
      "epoch:17 step:16688 [D loss: 0.615687, acc.: 64.06%] [G loss: 1.083308]\n",
      "epoch:17 step:16689 [D loss: 0.653614, acc.: 65.62%] [G loss: 1.034790]\n",
      "epoch:17 step:16690 [D loss: 0.699620, acc.: 57.81%] [G loss: 0.725189]\n",
      "epoch:17 step:16691 [D loss: 0.705860, acc.: 55.47%] [G loss: 0.802223]\n",
      "epoch:17 step:16692 [D loss: 0.505359, acc.: 82.81%] [G loss: 0.938452]\n",
      "epoch:17 step:16693 [D loss: 0.730103, acc.: 60.16%] [G loss: 0.991954]\n",
      "epoch:17 step:16694 [D loss: 0.691424, acc.: 57.03%] [G loss: 1.000507]\n",
      "epoch:17 step:16695 [D loss: 0.657884, acc.: 59.38%] [G loss: 1.076214]\n",
      "epoch:17 step:16696 [D loss: 0.576850, acc.: 67.97%] [G loss: 1.099668]\n",
      "epoch:17 step:16697 [D loss: 0.578103, acc.: 74.22%] [G loss: 1.019148]\n",
      "epoch:17 step:16698 [D loss: 0.368026, acc.: 91.41%] [G loss: 1.194949]\n",
      "epoch:17 step:16699 [D loss: 0.607985, acc.: 66.41%] [G loss: 1.009576]\n",
      "epoch:17 step:16700 [D loss: 0.683698, acc.: 61.72%] [G loss: 1.034169]\n",
      "epoch:17 step:16701 [D loss: 0.767155, acc.: 49.22%] [G loss: 1.001590]\n",
      "epoch:17 step:16702 [D loss: 0.811940, acc.: 47.66%] [G loss: 0.644533]\n",
      "epoch:17 step:16703 [D loss: 0.332349, acc.: 92.19%] [G loss: 1.340207]\n",
      "epoch:17 step:16704 [D loss: 0.393341, acc.: 83.59%] [G loss: 1.300120]\n",
      "epoch:17 step:16705 [D loss: 0.614543, acc.: 68.75%] [G loss: 1.265187]\n",
      "epoch:17 step:16706 [D loss: 0.664884, acc.: 59.38%] [G loss: 1.106886]\n",
      "epoch:17 step:16707 [D loss: 0.593182, acc.: 69.53%] [G loss: 0.929922]\n",
      "epoch:17 step:16708 [D loss: 0.774723, acc.: 49.22%] [G loss: 1.108705]\n",
      "epoch:17 step:16709 [D loss: 0.652201, acc.: 60.16%] [G loss: 0.993425]\n",
      "epoch:17 step:16710 [D loss: 0.684104, acc.: 57.03%] [G loss: 0.969214]\n",
      "epoch:17 step:16711 [D loss: 0.499304, acc.: 76.56%] [G loss: 1.283087]\n",
      "epoch:17 step:16712 [D loss: 0.683778, acc.: 62.50%] [G loss: 1.337525]\n",
      "epoch:17 step:16713 [D loss: 0.744924, acc.: 46.09%] [G loss: 0.967048]\n",
      "epoch:17 step:16714 [D loss: 0.569037, acc.: 69.53%] [G loss: 1.023414]\n",
      "epoch:17 step:16715 [D loss: 0.444375, acc.: 85.94%] [G loss: 1.158129]\n",
      "epoch:17 step:16716 [D loss: 0.754131, acc.: 54.69%] [G loss: 1.064604]\n",
      "epoch:17 step:16717 [D loss: 0.631941, acc.: 64.06%] [G loss: 1.005330]\n",
      "epoch:17 step:16718 [D loss: 0.736768, acc.: 49.22%] [G loss: 0.923588]\n",
      "epoch:17 step:16719 [D loss: 0.598859, acc.: 64.84%] [G loss: 0.965970]\n",
      "epoch:17 step:16720 [D loss: 0.429089, acc.: 82.03%] [G loss: 1.238974]\n",
      "epoch:17 step:16721 [D loss: 0.374065, acc.: 91.41%] [G loss: 1.296606]\n",
      "epoch:17 step:16722 [D loss: 0.387973, acc.: 89.06%] [G loss: 1.629839]\n",
      "epoch:17 step:16723 [D loss: 0.360271, acc.: 92.19%] [G loss: 1.340207]\n",
      "epoch:17 step:16724 [D loss: 0.625885, acc.: 64.84%] [G loss: 1.139814]\n",
      "epoch:17 step:16725 [D loss: 0.593233, acc.: 69.53%] [G loss: 1.283206]\n",
      "epoch:17 step:16726 [D loss: 0.604980, acc.: 60.94%] [G loss: 1.093699]\n",
      "epoch:17 step:16727 [D loss: 0.828130, acc.: 42.19%] [G loss: 0.858938]\n",
      "epoch:17 step:16728 [D loss: 0.532909, acc.: 76.56%] [G loss: 1.294270]\n",
      "epoch:17 step:16729 [D loss: 1.092278, acc.: 17.97%] [G loss: 0.742861]\n",
      "epoch:17 step:16730 [D loss: 0.895191, acc.: 31.25%] [G loss: 0.904761]\n",
      "epoch:17 step:16731 [D loss: 0.815589, acc.: 40.62%] [G loss: 0.742921]\n",
      "epoch:17 step:16732 [D loss: 0.745700, acc.: 52.34%] [G loss: 1.136181]\n",
      "epoch:17 step:16733 [D loss: 0.606256, acc.: 73.44%] [G loss: 0.985097]\n",
      "epoch:17 step:16734 [D loss: 0.587271, acc.: 67.97%] [G loss: 1.129338]\n",
      "epoch:17 step:16735 [D loss: 0.463300, acc.: 78.91%] [G loss: 1.154025]\n",
      "epoch:17 step:16736 [D loss: 0.841476, acc.: 39.84%] [G loss: 1.009699]\n",
      "epoch:17 step:16737 [D loss: 0.627112, acc.: 64.06%] [G loss: 0.908753]\n",
      "epoch:17 step:16738 [D loss: 0.590181, acc.: 67.19%] [G loss: 1.213213]\n",
      "epoch:17 step:16739 [D loss: 0.558653, acc.: 71.88%] [G loss: 1.233916]\n",
      "epoch:17 step:16740 [D loss: 0.651538, acc.: 61.72%] [G loss: 1.217545]\n",
      "epoch:17 step:16741 [D loss: 0.606654, acc.: 71.88%] [G loss: 1.018411]\n",
      "epoch:17 step:16742 [D loss: 0.505494, acc.: 78.91%] [G loss: 1.102253]\n",
      "epoch:17 step:16743 [D loss: 0.480170, acc.: 79.69%] [G loss: 1.171661]\n",
      "epoch:17 step:16744 [D loss: 0.231289, acc.: 95.31%] [G loss: 1.404310]\n",
      "epoch:17 step:16745 [D loss: 0.241486, acc.: 98.44%] [G loss: 1.512221]\n",
      "epoch:17 step:16746 [D loss: 0.467922, acc.: 83.59%] [G loss: 1.130630]\n",
      "epoch:17 step:16747 [D loss: 0.395593, acc.: 91.41%] [G loss: 1.394835]\n",
      "epoch:17 step:16748 [D loss: 0.434851, acc.: 86.72%] [G loss: 1.384135]\n",
      "epoch:17 step:16749 [D loss: 0.863389, acc.: 30.47%] [G loss: 0.821135]\n",
      "epoch:17 step:16750 [D loss: 0.595607, acc.: 68.75%] [G loss: 1.142896]\n",
      "epoch:17 step:16751 [D loss: 0.677489, acc.: 53.91%] [G loss: 1.047726]\n",
      "epoch:17 step:16752 [D loss: 0.489018, acc.: 78.91%] [G loss: 1.041572]\n",
      "epoch:17 step:16753 [D loss: 0.506334, acc.: 73.44%] [G loss: 0.895243]\n",
      "epoch:17 step:16754 [D loss: 0.487328, acc.: 82.03%] [G loss: 1.261471]\n",
      "epoch:17 step:16755 [D loss: 0.776666, acc.: 47.66%] [G loss: 0.967946]\n",
      "epoch:17 step:16756 [D loss: 0.893689, acc.: 32.03%] [G loss: 1.072458]\n",
      "epoch:17 step:16757 [D loss: 0.724835, acc.: 51.56%] [G loss: 1.001034]\n",
      "epoch:17 step:16758 [D loss: 0.839896, acc.: 45.31%] [G loss: 0.784375]\n",
      "epoch:17 step:16759 [D loss: 0.618274, acc.: 67.97%] [G loss: 1.288498]\n",
      "epoch:17 step:16760 [D loss: 0.437446, acc.: 81.25%] [G loss: 1.105979]\n",
      "epoch:17 step:16761 [D loss: 0.628822, acc.: 63.28%] [G loss: 1.147379]\n",
      "epoch:17 step:16762 [D loss: 0.549903, acc.: 75.78%] [G loss: 1.174806]\n",
      "epoch:17 step:16763 [D loss: 0.906355, acc.: 46.09%] [G loss: 1.157762]\n",
      "epoch:17 step:16764 [D loss: 0.719511, acc.: 54.69%] [G loss: 1.180820]\n",
      "epoch:17 step:16765 [D loss: 0.922535, acc.: 32.81%] [G loss: 1.006581]\n",
      "epoch:17 step:16766 [D loss: 0.745149, acc.: 51.56%] [G loss: 0.951498]\n",
      "epoch:17 step:16767 [D loss: 0.721052, acc.: 53.91%] [G loss: 0.939032]\n",
      "epoch:17 step:16768 [D loss: 0.531030, acc.: 78.12%] [G loss: 1.304882]\n",
      "epoch:17 step:16769 [D loss: 0.712152, acc.: 53.91%] [G loss: 1.121723]\n",
      "epoch:17 step:16770 [D loss: 0.727658, acc.: 51.56%] [G loss: 1.284533]\n",
      "epoch:17 step:16771 [D loss: 0.534239, acc.: 75.00%] [G loss: 1.314650]\n",
      "epoch:17 step:16772 [D loss: 0.752513, acc.: 50.00%] [G loss: 1.042352]\n",
      "epoch:17 step:16773 [D loss: 0.719809, acc.: 59.38%] [G loss: 1.013103]\n",
      "epoch:17 step:16774 [D loss: 0.778141, acc.: 49.22%] [G loss: 0.875761]\n",
      "epoch:17 step:16775 [D loss: 0.622711, acc.: 68.75%] [G loss: 1.043230]\n",
      "epoch:17 step:16776 [D loss: 0.510181, acc.: 78.91%] [G loss: 1.257287]\n",
      "epoch:17 step:16777 [D loss: 0.571449, acc.: 69.53%] [G loss: 1.062377]\n",
      "epoch:17 step:16778 [D loss: 0.462515, acc.: 81.25%] [G loss: 1.193572]\n",
      "epoch:17 step:16779 [D loss: 0.457815, acc.: 80.47%] [G loss: 1.363129]\n",
      "epoch:17 step:16780 [D loss: 0.336155, acc.: 93.75%] [G loss: 1.233163]\n",
      "epoch:17 step:16781 [D loss: 0.449318, acc.: 79.69%] [G loss: 1.376583]\n",
      "epoch:17 step:16782 [D loss: 0.384686, acc.: 90.62%] [G loss: 1.637295]\n",
      "epoch:17 step:16783 [D loss: 0.287151, acc.: 96.88%] [G loss: 1.798018]\n",
      "epoch:17 step:16784 [D loss: 0.430131, acc.: 85.94%] [G loss: 1.355901]\n",
      "epoch:17 step:16785 [D loss: 0.667240, acc.: 59.38%] [G loss: 0.928857]\n",
      "epoch:17 step:16786 [D loss: 0.588056, acc.: 64.84%] [G loss: 1.241696]\n",
      "epoch:17 step:16787 [D loss: 1.206695, acc.: 39.84%] [G loss: 1.177981]\n",
      "epoch:17 step:16788 [D loss: 0.780994, acc.: 50.78%] [G loss: 1.067803]\n",
      "epoch:17 step:16789 [D loss: 0.735154, acc.: 54.69%] [G loss: 0.823705]\n",
      "epoch:17 step:16790 [D loss: 0.654981, acc.: 64.06%] [G loss: 0.829149]\n",
      "epoch:17 step:16791 [D loss: 0.647480, acc.: 62.50%] [G loss: 1.063383]\n",
      "epoch:17 step:16792 [D loss: 0.705702, acc.: 56.25%] [G loss: 1.133480]\n",
      "epoch:17 step:16793 [D loss: 0.768777, acc.: 50.00%] [G loss: 0.788451]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16794 [D loss: 0.605801, acc.: 67.19%] [G loss: 0.913844]\n",
      "epoch:17 step:16795 [D loss: 0.687244, acc.: 57.81%] [G loss: 0.984854]\n",
      "epoch:17 step:16796 [D loss: 0.715595, acc.: 47.66%] [G loss: 0.899967]\n",
      "epoch:17 step:16797 [D loss: 0.724551, acc.: 50.78%] [G loss: 1.089754]\n",
      "epoch:17 step:16798 [D loss: 0.574454, acc.: 68.75%] [G loss: 1.034343]\n",
      "epoch:17 step:16799 [D loss: 0.827975, acc.: 37.50%] [G loss: 0.819089]\n",
      "epoch:17 step:16800 [D loss: 0.539467, acc.: 75.78%] [G loss: 0.978503]\n",
      "##############\n",
      "[2.63552056 1.48701882 5.60348922 4.14780648 3.05961733 5.30387001\n",
      " 4.10823692 4.43001231 3.93671391 3.69579557]\n",
      "##########\n",
      "epoch:17 step:16801 [D loss: 0.645977, acc.: 63.28%] [G loss: 0.855898]\n",
      "epoch:17 step:16802 [D loss: 0.638411, acc.: 66.41%] [G loss: 1.085840]\n",
      "epoch:17 step:16803 [D loss: 0.734763, acc.: 49.22%] [G loss: 0.887414]\n",
      "epoch:17 step:16804 [D loss: 0.651343, acc.: 66.41%] [G loss: 0.826269]\n",
      "epoch:17 step:16805 [D loss: 0.639955, acc.: 59.38%] [G loss: 0.911050]\n",
      "epoch:17 step:16806 [D loss: 0.664255, acc.: 58.59%] [G loss: 0.932476]\n",
      "epoch:17 step:16807 [D loss: 0.530885, acc.: 72.66%] [G loss: 1.077288]\n",
      "epoch:17 step:16808 [D loss: 0.669706, acc.: 57.81%] [G loss: 1.022285]\n",
      "epoch:17 step:16809 [D loss: 0.707583, acc.: 53.91%] [G loss: 0.890142]\n",
      "epoch:17 step:16810 [D loss: 0.740647, acc.: 49.22%] [G loss: 0.955688]\n",
      "epoch:17 step:16811 [D loss: 0.675583, acc.: 56.25%] [G loss: 1.185966]\n",
      "epoch:17 step:16812 [D loss: 0.703713, acc.: 53.12%] [G loss: 0.779651]\n",
      "epoch:17 step:16813 [D loss: 0.572366, acc.: 73.44%] [G loss: 1.014463]\n",
      "epoch:17 step:16814 [D loss: 0.572238, acc.: 69.53%] [G loss: 0.948452]\n",
      "epoch:17 step:16815 [D loss: 0.676661, acc.: 55.47%] [G loss: 0.955646]\n",
      "epoch:17 step:16816 [D loss: 0.568874, acc.: 73.44%] [G loss: 0.960700]\n",
      "epoch:17 step:16817 [D loss: 0.648186, acc.: 63.28%] [G loss: 0.964764]\n",
      "epoch:17 step:16818 [D loss: 0.528612, acc.: 78.91%] [G loss: 1.028475]\n",
      "epoch:17 step:16819 [D loss: 0.585506, acc.: 68.75%] [G loss: 0.916666]\n",
      "epoch:17 step:16820 [D loss: 0.727766, acc.: 54.69%] [G loss: 0.897649]\n",
      "epoch:17 step:16821 [D loss: 0.580141, acc.: 69.53%] [G loss: 0.935121]\n",
      "epoch:17 step:16822 [D loss: 0.511180, acc.: 75.00%] [G loss: 1.295004]\n",
      "epoch:17 step:16823 [D loss: 0.459366, acc.: 86.72%] [G loss: 1.197282]\n",
      "epoch:17 step:16824 [D loss: 0.397457, acc.: 85.94%] [G loss: 1.570982]\n",
      "epoch:17 step:16825 [D loss: 0.588720, acc.: 67.19%] [G loss: 0.880186]\n",
      "epoch:17 step:16826 [D loss: 0.509197, acc.: 82.03%] [G loss: 1.303023]\n",
      "epoch:17 step:16827 [D loss: 0.435195, acc.: 82.03%] [G loss: 1.143848]\n",
      "epoch:17 step:16828 [D loss: 0.356117, acc.: 90.62%] [G loss: 1.220738]\n",
      "epoch:17 step:16829 [D loss: 0.317999, acc.: 92.97%] [G loss: 1.724472]\n",
      "epoch:17 step:16830 [D loss: 0.429095, acc.: 84.38%] [G loss: 1.644672]\n",
      "epoch:17 step:16831 [D loss: 0.610945, acc.: 64.06%] [G loss: 1.263535]\n",
      "epoch:17 step:16832 [D loss: 0.734341, acc.: 53.91%] [G loss: 0.903341]\n",
      "epoch:17 step:16833 [D loss: 1.008448, acc.: 28.12%] [G loss: 0.857004]\n",
      "epoch:17 step:16834 [D loss: 0.760684, acc.: 48.44%] [G loss: 1.053618]\n",
      "epoch:17 step:16835 [D loss: 0.739128, acc.: 47.66%] [G loss: 1.110057]\n",
      "epoch:17 step:16836 [D loss: 0.653595, acc.: 58.59%] [G loss: 1.097282]\n",
      "epoch:17 step:16837 [D loss: 0.753121, acc.: 51.56%] [G loss: 0.927777]\n",
      "epoch:17 step:16838 [D loss: 0.539420, acc.: 67.19%] [G loss: 1.092799]\n",
      "epoch:17 step:16839 [D loss: 0.649071, acc.: 60.94%] [G loss: 0.954268]\n",
      "epoch:17 step:16840 [D loss: 0.462395, acc.: 79.69%] [G loss: 1.006891]\n",
      "epoch:17 step:16841 [D loss: 0.257123, acc.: 95.31%] [G loss: 1.427758]\n",
      "epoch:17 step:16842 [D loss: 0.801793, acc.: 50.78%] [G loss: 1.341532]\n",
      "epoch:17 step:16843 [D loss: 0.737629, acc.: 54.69%] [G loss: 0.951578]\n",
      "epoch:17 step:16844 [D loss: 0.735714, acc.: 48.44%] [G loss: 0.843675]\n",
      "epoch:17 step:16845 [D loss: 0.793774, acc.: 49.22%] [G loss: 1.011523]\n",
      "epoch:17 step:16846 [D loss: 0.809883, acc.: 42.19%] [G loss: 1.055002]\n",
      "epoch:17 step:16847 [D loss: 0.547291, acc.: 74.22%] [G loss: 0.850073]\n",
      "epoch:17 step:16848 [D loss: 0.555696, acc.: 74.22%] [G loss: 1.217375]\n",
      "epoch:17 step:16849 [D loss: 0.455075, acc.: 82.81%] [G loss: 1.178809]\n",
      "epoch:17 step:16850 [D loss: 0.468944, acc.: 85.94%] [G loss: 1.269828]\n",
      "epoch:17 step:16851 [D loss: 0.640769, acc.: 62.50%] [G loss: 0.894440]\n",
      "epoch:17 step:16852 [D loss: 0.607135, acc.: 69.53%] [G loss: 1.085536]\n",
      "epoch:17 step:16853 [D loss: 0.563346, acc.: 75.00%] [G loss: 1.026872]\n",
      "epoch:17 step:16854 [D loss: 0.606495, acc.: 67.19%] [G loss: 0.993252]\n",
      "epoch:17 step:16855 [D loss: 0.528686, acc.: 76.56%] [G loss: 1.144074]\n",
      "epoch:17 step:16856 [D loss: 0.512728, acc.: 75.00%] [G loss: 1.163883]\n",
      "epoch:17 step:16857 [D loss: 0.773397, acc.: 48.44%] [G loss: 1.237657]\n",
      "epoch:17 step:16858 [D loss: 0.484057, acc.: 78.12%] [G loss: 1.199708]\n",
      "epoch:17 step:16859 [D loss: 0.434952, acc.: 86.72%] [G loss: 1.334270]\n",
      "epoch:17 step:16860 [D loss: 0.511389, acc.: 79.69%] [G loss: 1.225523]\n",
      "epoch:17 step:16861 [D loss: 0.581475, acc.: 71.09%] [G loss: 1.082568]\n",
      "epoch:17 step:16862 [D loss: 0.654730, acc.: 59.38%] [G loss: 1.100537]\n",
      "epoch:17 step:16863 [D loss: 0.483480, acc.: 79.69%] [G loss: 1.021559]\n",
      "epoch:17 step:16864 [D loss: 0.546879, acc.: 67.97%] [G loss: 1.079700]\n",
      "epoch:17 step:16865 [D loss: 0.467254, acc.: 82.03%] [G loss: 1.035127]\n",
      "epoch:17 step:16866 [D loss: 0.263887, acc.: 92.19%] [G loss: 1.354020]\n",
      "epoch:18 step:16867 [D loss: 0.640050, acc.: 61.72%] [G loss: 1.133535]\n",
      "epoch:18 step:16868 [D loss: 0.652548, acc.: 57.03%] [G loss: 1.153983]\n",
      "epoch:18 step:16869 [D loss: 0.605731, acc.: 64.84%] [G loss: 1.158495]\n",
      "epoch:18 step:16870 [D loss: 0.663526, acc.: 60.16%] [G loss: 1.063337]\n",
      "epoch:18 step:16871 [D loss: 0.628830, acc.: 64.84%] [G loss: 0.991808]\n",
      "epoch:18 step:16872 [D loss: 0.614959, acc.: 65.62%] [G loss: 1.152023]\n",
      "epoch:18 step:16873 [D loss: 0.701020, acc.: 54.69%] [G loss: 0.926928]\n",
      "epoch:18 step:16874 [D loss: 0.548360, acc.: 73.44%] [G loss: 0.863073]\n",
      "epoch:18 step:16875 [D loss: 0.574761, acc.: 71.88%] [G loss: 0.902613]\n",
      "epoch:18 step:16876 [D loss: 0.627481, acc.: 67.97%] [G loss: 0.885985]\n",
      "epoch:18 step:16877 [D loss: 0.676762, acc.: 57.81%] [G loss: 1.191659]\n",
      "epoch:18 step:16878 [D loss: 0.658095, acc.: 63.28%] [G loss: 1.190967]\n",
      "epoch:18 step:16879 [D loss: 0.836002, acc.: 32.81%] [G loss: 0.954532]\n",
      "epoch:18 step:16880 [D loss: 0.660989, acc.: 64.84%] [G loss: 1.120834]\n",
      "epoch:18 step:16881 [D loss: 0.500533, acc.: 81.25%] [G loss: 1.156520]\n",
      "epoch:18 step:16882 [D loss: 0.588855, acc.: 70.31%] [G loss: 1.095591]\n",
      "epoch:18 step:16883 [D loss: 0.624912, acc.: 65.62%] [G loss: 1.002240]\n",
      "epoch:18 step:16884 [D loss: 0.827738, acc.: 40.62%] [G loss: 1.021044]\n",
      "epoch:18 step:16885 [D loss: 0.809510, acc.: 41.41%] [G loss: 0.968322]\n",
      "epoch:18 step:16886 [D loss: 0.615521, acc.: 64.84%] [G loss: 1.298700]\n",
      "epoch:18 step:16887 [D loss: 0.736820, acc.: 53.12%] [G loss: 1.046126]\n",
      "epoch:18 step:16888 [D loss: 0.618210, acc.: 66.41%] [G loss: 1.124101]\n",
      "epoch:18 step:16889 [D loss: 0.679559, acc.: 58.59%] [G loss: 0.990928]\n",
      "epoch:18 step:16890 [D loss: 0.676172, acc.: 58.59%] [G loss: 0.977988]\n",
      "epoch:18 step:16891 [D loss: 0.700602, acc.: 58.59%] [G loss: 1.017440]\n",
      "epoch:18 step:16892 [D loss: 0.546995, acc.: 75.78%] [G loss: 1.036287]\n",
      "epoch:18 step:16893 [D loss: 0.423912, acc.: 85.16%] [G loss: 1.026418]\n",
      "epoch:18 step:16894 [D loss: 0.457156, acc.: 83.59%] [G loss: 1.254420]\n",
      "epoch:18 step:16895 [D loss: 0.394576, acc.: 89.06%] [G loss: 1.294030]\n",
      "epoch:18 step:16896 [D loss: 0.386926, acc.: 92.97%] [G loss: 1.527014]\n",
      "epoch:18 step:16897 [D loss: 0.382436, acc.: 92.97%] [G loss: 1.264616]\n",
      "epoch:18 step:16898 [D loss: 0.413643, acc.: 86.72%] [G loss: 1.284627]\n",
      "epoch:18 step:16899 [D loss: 0.381925, acc.: 91.41%] [G loss: 1.816549]\n",
      "epoch:18 step:16900 [D loss: 0.485971, acc.: 78.12%] [G loss: 1.212199]\n",
      "epoch:18 step:16901 [D loss: 0.323467, acc.: 91.41%] [G loss: 1.493080]\n",
      "epoch:18 step:16902 [D loss: 0.319668, acc.: 92.19%] [G loss: 1.543952]\n",
      "epoch:18 step:16903 [D loss: 0.864796, acc.: 53.12%] [G loss: 1.326742]\n",
      "epoch:18 step:16904 [D loss: 1.065382, acc.: 25.78%] [G loss: 0.926478]\n",
      "epoch:18 step:16905 [D loss: 0.802786, acc.: 39.06%] [G loss: 0.859482]\n",
      "epoch:18 step:16906 [D loss: 0.780120, acc.: 47.66%] [G loss: 0.948364]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:16907 [D loss: 0.765436, acc.: 48.44%] [G loss: 0.835187]\n",
      "epoch:18 step:16908 [D loss: 0.601243, acc.: 71.09%] [G loss: 1.150410]\n",
      "epoch:18 step:16909 [D loss: 0.641552, acc.: 64.84%] [G loss: 1.012529]\n",
      "epoch:18 step:16910 [D loss: 0.613061, acc.: 64.06%] [G loss: 0.979221]\n",
      "epoch:18 step:16911 [D loss: 0.719217, acc.: 54.69%] [G loss: 0.862677]\n",
      "epoch:18 step:16912 [D loss: 0.792123, acc.: 46.88%] [G loss: 0.967483]\n",
      "epoch:18 step:16913 [D loss: 0.580236, acc.: 68.75%] [G loss: 1.326329]\n",
      "epoch:18 step:16914 [D loss: 0.700650, acc.: 56.25%] [G loss: 0.852832]\n",
      "epoch:18 step:16915 [D loss: 0.643733, acc.: 62.50%] [G loss: 1.166435]\n",
      "epoch:18 step:16916 [D loss: 0.565920, acc.: 72.66%] [G loss: 1.139103]\n",
      "epoch:18 step:16917 [D loss: 0.668108, acc.: 60.16%] [G loss: 0.968139]\n",
      "epoch:18 step:16918 [D loss: 0.620511, acc.: 65.62%] [G loss: 1.129750]\n",
      "epoch:18 step:16919 [D loss: 0.572951, acc.: 70.31%] [G loss: 1.038357]\n",
      "epoch:18 step:16920 [D loss: 0.528539, acc.: 75.00%] [G loss: 1.037897]\n",
      "epoch:18 step:16921 [D loss: 0.488955, acc.: 79.69%] [G loss: 0.931395]\n",
      "epoch:18 step:16922 [D loss: 0.530319, acc.: 77.34%] [G loss: 1.172980]\n",
      "epoch:18 step:16923 [D loss: 0.667387, acc.: 58.59%] [G loss: 0.949492]\n",
      "epoch:18 step:16924 [D loss: 0.683675, acc.: 61.72%] [G loss: 0.910838]\n",
      "epoch:18 step:16925 [D loss: 0.701286, acc.: 59.38%] [G loss: 0.988295]\n",
      "epoch:18 step:16926 [D loss: 0.776796, acc.: 46.88%] [G loss: 0.959181]\n",
      "epoch:18 step:16927 [D loss: 0.543504, acc.: 77.34%] [G loss: 1.099366]\n",
      "epoch:18 step:16928 [D loss: 0.663883, acc.: 63.28%] [G loss: 0.746986]\n",
      "epoch:18 step:16929 [D loss: 0.710575, acc.: 47.66%] [G loss: 1.165800]\n",
      "epoch:18 step:16930 [D loss: 0.634319, acc.: 62.50%] [G loss: 0.965595]\n",
      "epoch:18 step:16931 [D loss: 0.541997, acc.: 71.88%] [G loss: 1.089825]\n",
      "epoch:18 step:16932 [D loss: 0.672610, acc.: 54.69%] [G loss: 1.052648]\n",
      "epoch:18 step:16933 [D loss: 0.714021, acc.: 59.38%] [G loss: 1.007517]\n",
      "epoch:18 step:16934 [D loss: 0.541660, acc.: 75.78%] [G loss: 0.849264]\n",
      "epoch:18 step:16935 [D loss: 0.426118, acc.: 90.62%] [G loss: 1.274830]\n",
      "epoch:18 step:16936 [D loss: 0.584190, acc.: 71.09%] [G loss: 1.004299]\n",
      "epoch:18 step:16937 [D loss: 0.712691, acc.: 53.91%] [G loss: 1.342869]\n",
      "epoch:18 step:16938 [D loss: 0.676500, acc.: 60.16%] [G loss: 1.170706]\n",
      "epoch:18 step:16939 [D loss: 0.665722, acc.: 58.59%] [G loss: 1.041038]\n",
      "epoch:18 step:16940 [D loss: 0.582370, acc.: 67.97%] [G loss: 1.046229]\n",
      "epoch:18 step:16941 [D loss: 0.409333, acc.: 82.03%] [G loss: 1.041347]\n",
      "epoch:18 step:16942 [D loss: 0.394342, acc.: 88.28%] [G loss: 1.291077]\n",
      "epoch:18 step:16943 [D loss: 0.429876, acc.: 84.38%] [G loss: 1.217191]\n",
      "epoch:18 step:16944 [D loss: 0.687100, acc.: 57.81%] [G loss: 1.176033]\n",
      "epoch:18 step:16945 [D loss: 0.677279, acc.: 55.47%] [G loss: 1.026408]\n",
      "epoch:18 step:16946 [D loss: 0.729237, acc.: 55.47%] [G loss: 0.993596]\n",
      "epoch:18 step:16947 [D loss: 0.627977, acc.: 60.94%] [G loss: 1.109393]\n",
      "epoch:18 step:16948 [D loss: 0.806390, acc.: 40.62%] [G loss: 0.802928]\n",
      "epoch:18 step:16949 [D loss: 0.656905, acc.: 55.47%] [G loss: 1.121646]\n",
      "epoch:18 step:16950 [D loss: 0.675870, acc.: 56.25%] [G loss: 0.984437]\n",
      "epoch:18 step:16951 [D loss: 0.698429, acc.: 53.91%] [G loss: 1.093611]\n",
      "epoch:18 step:16952 [D loss: 0.617042, acc.: 69.53%] [G loss: 0.990162]\n",
      "epoch:18 step:16953 [D loss: 0.654985, acc.: 58.59%] [G loss: 0.975222]\n",
      "epoch:18 step:16954 [D loss: 0.642758, acc.: 60.16%] [G loss: 0.996015]\n",
      "epoch:18 step:16955 [D loss: 0.651972, acc.: 62.50%] [G loss: 0.992288]\n",
      "epoch:18 step:16956 [D loss: 0.673545, acc.: 57.81%] [G loss: 0.942146]\n",
      "epoch:18 step:16957 [D loss: 0.650960, acc.: 64.06%] [G loss: 1.051359]\n",
      "epoch:18 step:16958 [D loss: 0.638368, acc.: 60.94%] [G loss: 0.909521]\n",
      "epoch:18 step:16959 [D loss: 0.561949, acc.: 73.44%] [G loss: 1.012036]\n",
      "epoch:18 step:16960 [D loss: 0.740475, acc.: 50.00%] [G loss: 0.925651]\n",
      "epoch:18 step:16961 [D loss: 0.673772, acc.: 58.59%] [G loss: 0.775076]\n",
      "epoch:18 step:16962 [D loss: 0.724431, acc.: 53.91%] [G loss: 0.887476]\n",
      "epoch:18 step:16963 [D loss: 0.670987, acc.: 60.16%] [G loss: 1.073759]\n",
      "epoch:18 step:16964 [D loss: 0.760517, acc.: 44.53%] [G loss: 1.102679]\n",
      "epoch:18 step:16965 [D loss: 0.726723, acc.: 47.66%] [G loss: 0.893103]\n",
      "epoch:18 step:16966 [D loss: 0.639982, acc.: 58.59%] [G loss: 0.965324]\n",
      "epoch:18 step:16967 [D loss: 0.666389, acc.: 56.25%] [G loss: 1.053020]\n",
      "epoch:18 step:16968 [D loss: 0.637057, acc.: 61.72%] [G loss: 0.945985]\n",
      "epoch:18 step:16969 [D loss: 0.525840, acc.: 76.56%] [G loss: 0.926109]\n",
      "epoch:18 step:16970 [D loss: 0.558389, acc.: 71.09%] [G loss: 1.040826]\n",
      "epoch:18 step:16971 [D loss: 0.559455, acc.: 74.22%] [G loss: 1.119307]\n",
      "epoch:18 step:16972 [D loss: 0.551079, acc.: 77.34%] [G loss: 1.127505]\n",
      "epoch:18 step:16973 [D loss: 0.673608, acc.: 60.94%] [G loss: 0.918604]\n",
      "epoch:18 step:16974 [D loss: 0.612783, acc.: 65.62%] [G loss: 0.944485]\n",
      "epoch:18 step:16975 [D loss: 0.622912, acc.: 65.62%] [G loss: 0.894304]\n",
      "epoch:18 step:16976 [D loss: 0.580337, acc.: 67.97%] [G loss: 1.107766]\n",
      "epoch:18 step:16977 [D loss: 0.721900, acc.: 55.47%] [G loss: 0.905129]\n",
      "epoch:18 step:16978 [D loss: 0.610093, acc.: 67.19%] [G loss: 1.224089]\n",
      "epoch:18 step:16979 [D loss: 0.657037, acc.: 64.06%] [G loss: 1.021240]\n",
      "epoch:18 step:16980 [D loss: 0.910970, acc.: 32.03%] [G loss: 0.789243]\n",
      "epoch:18 step:16981 [D loss: 0.618281, acc.: 65.62%] [G loss: 0.901176]\n",
      "epoch:18 step:16982 [D loss: 0.633486, acc.: 66.41%] [G loss: 0.931114]\n",
      "epoch:18 step:16983 [D loss: 0.517209, acc.: 78.91%] [G loss: 1.159428]\n",
      "epoch:18 step:16984 [D loss: 0.685497, acc.: 52.34%] [G loss: 1.027191]\n",
      "epoch:18 step:16985 [D loss: 0.537451, acc.: 71.09%] [G loss: 1.170022]\n",
      "epoch:18 step:16986 [D loss: 0.934649, acc.: 33.59%] [G loss: 0.785933]\n",
      "epoch:18 step:16987 [D loss: 0.591926, acc.: 68.75%] [G loss: 1.068081]\n",
      "epoch:18 step:16988 [D loss: 0.489926, acc.: 78.91%] [G loss: 1.159787]\n",
      "epoch:18 step:16989 [D loss: 0.737228, acc.: 50.00%] [G loss: 1.003831]\n",
      "epoch:18 step:16990 [D loss: 0.735298, acc.: 53.12%] [G loss: 1.097947]\n",
      "epoch:18 step:16991 [D loss: 0.743094, acc.: 46.88%] [G loss: 1.177193]\n",
      "epoch:18 step:16992 [D loss: 0.676684, acc.: 57.03%] [G loss: 0.958968]\n",
      "epoch:18 step:16993 [D loss: 0.661932, acc.: 63.28%] [G loss: 1.031859]\n",
      "epoch:18 step:16994 [D loss: 0.681064, acc.: 60.16%] [G loss: 0.857072]\n",
      "epoch:18 step:16995 [D loss: 0.600934, acc.: 64.84%] [G loss: 0.936325]\n",
      "epoch:18 step:16996 [D loss: 0.403014, acc.: 86.72%] [G loss: 1.269938]\n",
      "epoch:18 step:16997 [D loss: 0.425109, acc.: 87.50%] [G loss: 1.086673]\n",
      "epoch:18 step:16998 [D loss: 0.630567, acc.: 64.84%] [G loss: 1.254885]\n",
      "epoch:18 step:16999 [D loss: 0.887029, acc.: 37.50%] [G loss: 0.878598]\n",
      "epoch:18 step:17000 [D loss: 0.764529, acc.: 46.88%] [G loss: 0.961609]\n",
      "##############\n",
      "[2.2270748  1.28333993 5.44427816 4.10818786 2.66584978 5.31989032\n",
      " 3.99542136 4.44390378 4.04540394 3.46721229]\n",
      "##########\n",
      "epoch:18 step:17001 [D loss: 0.672630, acc.: 61.72%] [G loss: 1.121156]\n",
      "epoch:18 step:17002 [D loss: 0.622586, acc.: 64.84%] [G loss: 0.984963]\n",
      "epoch:18 step:17003 [D loss: 0.607458, acc.: 67.19%] [G loss: 0.917605]\n",
      "epoch:18 step:17004 [D loss: 0.661491, acc.: 61.72%] [G loss: 1.249047]\n",
      "epoch:18 step:17005 [D loss: 0.588060, acc.: 66.41%] [G loss: 1.058283]\n",
      "epoch:18 step:17006 [D loss: 0.710453, acc.: 51.56%] [G loss: 1.207164]\n",
      "epoch:18 step:17007 [D loss: 0.691509, acc.: 59.38%] [G loss: 1.169286]\n",
      "epoch:18 step:17008 [D loss: 0.568160, acc.: 72.66%] [G loss: 1.021390]\n",
      "epoch:18 step:17009 [D loss: 0.595158, acc.: 70.31%] [G loss: 1.001790]\n",
      "epoch:18 step:17010 [D loss: 0.559525, acc.: 68.75%] [G loss: 1.233766]\n",
      "epoch:18 step:17011 [D loss: 0.414294, acc.: 89.06%] [G loss: 1.230207]\n",
      "epoch:18 step:17012 [D loss: 0.604106, acc.: 69.53%] [G loss: 1.118626]\n",
      "epoch:18 step:17013 [D loss: 0.624788, acc.: 64.06%] [G loss: 1.047205]\n",
      "epoch:18 step:17014 [D loss: 0.658754, acc.: 59.38%] [G loss: 0.995328]\n",
      "epoch:18 step:17015 [D loss: 0.657877, acc.: 57.81%] [G loss: 0.968848]\n",
      "epoch:18 step:17016 [D loss: 0.425072, acc.: 87.50%] [G loss: 1.050391]\n",
      "epoch:18 step:17017 [D loss: 0.338429, acc.: 95.31%] [G loss: 1.199702]\n",
      "epoch:18 step:17018 [D loss: 0.377351, acc.: 91.41%] [G loss: 1.402262]\n",
      "epoch:18 step:17019 [D loss: 0.610838, acc.: 67.19%] [G loss: 1.236358]\n",
      "epoch:18 step:17020 [D loss: 0.875662, acc.: 39.06%] [G loss: 0.975014]\n",
      "epoch:18 step:17021 [D loss: 0.678030, acc.: 55.47%] [G loss: 0.979039]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17022 [D loss: 0.926092, acc.: 32.81%] [G loss: 0.907682]\n",
      "epoch:18 step:17023 [D loss: 0.756324, acc.: 46.09%] [G loss: 0.866743]\n",
      "epoch:18 step:17024 [D loss: 0.702215, acc.: 54.69%] [G loss: 1.006530]\n",
      "epoch:18 step:17025 [D loss: 0.661461, acc.: 60.16%] [G loss: 0.960082]\n",
      "epoch:18 step:17026 [D loss: 0.837577, acc.: 40.62%] [G loss: 0.899188]\n",
      "epoch:18 step:17027 [D loss: 0.760978, acc.: 42.97%] [G loss: 0.926088]\n",
      "epoch:18 step:17028 [D loss: 0.544747, acc.: 74.22%] [G loss: 0.935954]\n",
      "epoch:18 step:17029 [D loss: 0.603378, acc.: 64.84%] [G loss: 0.966753]\n",
      "epoch:18 step:17030 [D loss: 0.761631, acc.: 44.53%] [G loss: 0.874007]\n",
      "epoch:18 step:17031 [D loss: 0.654284, acc.: 60.16%] [G loss: 0.762832]\n",
      "epoch:18 step:17032 [D loss: 0.723077, acc.: 49.22%] [G loss: 0.855318]\n",
      "epoch:18 step:17033 [D loss: 0.597485, acc.: 69.53%] [G loss: 1.127911]\n",
      "epoch:18 step:17034 [D loss: 0.461369, acc.: 82.81%] [G loss: 1.007409]\n",
      "epoch:18 step:17035 [D loss: 0.656227, acc.: 60.16%] [G loss: 0.932892]\n",
      "epoch:18 step:17036 [D loss: 0.688446, acc.: 55.47%] [G loss: 1.090200]\n",
      "epoch:18 step:17037 [D loss: 0.559416, acc.: 71.88%] [G loss: 1.143744]\n",
      "epoch:18 step:17038 [D loss: 0.647074, acc.: 60.94%] [G loss: 1.067926]\n",
      "epoch:18 step:17039 [D loss: 0.593365, acc.: 70.31%] [G loss: 0.989453]\n",
      "epoch:18 step:17040 [D loss: 0.649384, acc.: 61.72%] [G loss: 1.348261]\n",
      "epoch:18 step:17041 [D loss: 0.693043, acc.: 56.25%] [G loss: 0.752701]\n",
      "epoch:18 step:17042 [D loss: 0.707551, acc.: 55.47%] [G loss: 0.950432]\n",
      "epoch:18 step:17043 [D loss: 0.770488, acc.: 48.44%] [G loss: 0.964254]\n",
      "epoch:18 step:17044 [D loss: 0.682089, acc.: 60.94%] [G loss: 0.995955]\n",
      "epoch:18 step:17045 [D loss: 0.707966, acc.: 60.16%] [G loss: 0.960584]\n",
      "epoch:18 step:17046 [D loss: 0.834753, acc.: 35.94%] [G loss: 0.894214]\n",
      "epoch:18 step:17047 [D loss: 0.800119, acc.: 46.88%] [G loss: 0.891360]\n",
      "epoch:18 step:17048 [D loss: 0.580815, acc.: 68.75%] [G loss: 1.081633]\n",
      "epoch:18 step:17049 [D loss: 0.689206, acc.: 60.16%] [G loss: 1.173542]\n",
      "epoch:18 step:17050 [D loss: 0.690462, acc.: 60.16%] [G loss: 0.842579]\n",
      "epoch:18 step:17051 [D loss: 0.944785, acc.: 27.34%] [G loss: 0.724067]\n",
      "epoch:18 step:17052 [D loss: 0.846173, acc.: 39.06%] [G loss: 1.012859]\n",
      "epoch:18 step:17053 [D loss: 0.784306, acc.: 46.88%] [G loss: 0.996480]\n",
      "epoch:18 step:17054 [D loss: 0.651214, acc.: 61.72%] [G loss: 1.157234]\n",
      "epoch:18 step:17055 [D loss: 0.746937, acc.: 48.44%] [G loss: 0.993492]\n",
      "epoch:18 step:17056 [D loss: 0.633852, acc.: 67.19%] [G loss: 1.013880]\n",
      "epoch:18 step:17057 [D loss: 0.713552, acc.: 54.69%] [G loss: 1.071497]\n",
      "epoch:18 step:17058 [D loss: 0.491628, acc.: 78.12%] [G loss: 1.238406]\n",
      "epoch:18 step:17059 [D loss: 0.618815, acc.: 67.19%] [G loss: 1.050850]\n",
      "epoch:18 step:17060 [D loss: 0.673637, acc.: 64.06%] [G loss: 0.903447]\n",
      "epoch:18 step:17061 [D loss: 0.595363, acc.: 67.97%] [G loss: 1.306531]\n",
      "epoch:18 step:17062 [D loss: 0.760428, acc.: 39.84%] [G loss: 0.907670]\n",
      "epoch:18 step:17063 [D loss: 0.665946, acc.: 65.62%] [G loss: 0.962336]\n",
      "epoch:18 step:17064 [D loss: 0.727619, acc.: 53.91%] [G loss: 0.990468]\n",
      "epoch:18 step:17065 [D loss: 0.736537, acc.: 51.56%] [G loss: 1.047439]\n",
      "epoch:18 step:17066 [D loss: 0.613251, acc.: 66.41%] [G loss: 1.013043]\n",
      "epoch:18 step:17067 [D loss: 0.591211, acc.: 67.97%] [G loss: 1.148472]\n",
      "epoch:18 step:17068 [D loss: 0.675970, acc.: 53.12%] [G loss: 1.063008]\n",
      "epoch:18 step:17069 [D loss: 0.673196, acc.: 56.25%] [G loss: 0.875793]\n",
      "epoch:18 step:17070 [D loss: 0.723975, acc.: 52.34%] [G loss: 0.856338]\n",
      "epoch:18 step:17071 [D loss: 0.613715, acc.: 64.84%] [G loss: 1.006186]\n",
      "epoch:18 step:17072 [D loss: 0.604101, acc.: 66.41%] [G loss: 1.143665]\n",
      "epoch:18 step:17073 [D loss: 0.585107, acc.: 75.00%] [G loss: 1.072711]\n",
      "epoch:18 step:17074 [D loss: 0.613679, acc.: 65.62%] [G loss: 0.875095]\n",
      "epoch:18 step:17075 [D loss: 0.626752, acc.: 64.84%] [G loss: 1.032914]\n",
      "epoch:18 step:17076 [D loss: 0.671615, acc.: 60.16%] [G loss: 0.991292]\n",
      "epoch:18 step:17077 [D loss: 0.587221, acc.: 71.88%] [G loss: 0.965976]\n",
      "epoch:18 step:17078 [D loss: 0.691860, acc.: 53.12%] [G loss: 0.970790]\n",
      "epoch:18 step:17079 [D loss: 0.583203, acc.: 68.75%] [G loss: 1.030801]\n",
      "epoch:18 step:17080 [D loss: 0.780882, acc.: 46.09%] [G loss: 0.953788]\n",
      "epoch:18 step:17081 [D loss: 0.613307, acc.: 63.28%] [G loss: 1.020965]\n",
      "epoch:18 step:17082 [D loss: 0.565311, acc.: 73.44%] [G loss: 1.154747]\n",
      "epoch:18 step:17083 [D loss: 0.730792, acc.: 54.69%] [G loss: 0.949290]\n",
      "epoch:18 step:17084 [D loss: 0.661122, acc.: 60.94%] [G loss: 1.059047]\n",
      "epoch:18 step:17085 [D loss: 0.634507, acc.: 67.19%] [G loss: 0.969875]\n",
      "epoch:18 step:17086 [D loss: 0.462517, acc.: 78.12%] [G loss: 1.026216]\n",
      "epoch:18 step:17087 [D loss: 0.380064, acc.: 89.06%] [G loss: 1.246666]\n",
      "epoch:18 step:17088 [D loss: 0.415821, acc.: 88.28%] [G loss: 1.425883]\n",
      "epoch:18 step:17089 [D loss: 0.416361, acc.: 87.50%] [G loss: 1.391345]\n",
      "epoch:18 step:17090 [D loss: 0.776548, acc.: 50.78%] [G loss: 1.330526]\n",
      "epoch:18 step:17091 [D loss: 0.756801, acc.: 52.34%] [G loss: 1.043681]\n",
      "epoch:18 step:17092 [D loss: 0.654844, acc.: 62.50%] [G loss: 0.948664]\n",
      "epoch:18 step:17093 [D loss: 0.618397, acc.: 63.28%] [G loss: 0.989950]\n",
      "epoch:18 step:17094 [D loss: 0.607921, acc.: 67.97%] [G loss: 0.888913]\n",
      "epoch:18 step:17095 [D loss: 0.822053, acc.: 43.75%] [G loss: 0.706964]\n",
      "epoch:18 step:17096 [D loss: 0.355547, acc.: 85.16%] [G loss: 1.333812]\n",
      "epoch:18 step:17097 [D loss: 0.321437, acc.: 93.75%] [G loss: 1.517394]\n",
      "epoch:18 step:17098 [D loss: 0.367162, acc.: 89.84%] [G loss: 1.473629]\n",
      "epoch:18 step:17099 [D loss: 0.848928, acc.: 42.19%] [G loss: 1.069422]\n",
      "epoch:18 step:17100 [D loss: 0.756173, acc.: 47.66%] [G loss: 1.144936]\n",
      "epoch:18 step:17101 [D loss: 0.621536, acc.: 64.84%] [G loss: 0.979357]\n",
      "epoch:18 step:17102 [D loss: 0.619656, acc.: 64.06%] [G loss: 1.046121]\n",
      "epoch:18 step:17103 [D loss: 0.634552, acc.: 63.28%] [G loss: 1.003865]\n",
      "epoch:18 step:17104 [D loss: 0.741180, acc.: 55.47%] [G loss: 0.893791]\n",
      "epoch:18 step:17105 [D loss: 0.737753, acc.: 55.47%] [G loss: 1.088692]\n",
      "epoch:18 step:17106 [D loss: 0.780789, acc.: 44.53%] [G loss: 0.943181]\n",
      "epoch:18 step:17107 [D loss: 0.806685, acc.: 40.62%] [G loss: 0.872492]\n",
      "epoch:18 step:17108 [D loss: 0.833284, acc.: 34.38%] [G loss: 0.712864]\n",
      "epoch:18 step:17109 [D loss: 0.625791, acc.: 61.72%] [G loss: 1.099933]\n",
      "epoch:18 step:17110 [D loss: 0.628921, acc.: 62.50%] [G loss: 1.063691]\n",
      "epoch:18 step:17111 [D loss: 0.685686, acc.: 61.72%] [G loss: 0.884076]\n",
      "epoch:18 step:17112 [D loss: 0.704186, acc.: 58.59%] [G loss: 1.113588]\n",
      "epoch:18 step:17113 [D loss: 0.516599, acc.: 79.69%] [G loss: 1.267299]\n",
      "epoch:18 step:17114 [D loss: 0.530153, acc.: 77.34%] [G loss: 1.268516]\n",
      "epoch:18 step:17115 [D loss: 0.669681, acc.: 60.94%] [G loss: 1.130869]\n",
      "epoch:18 step:17116 [D loss: 0.536451, acc.: 78.12%] [G loss: 1.084290]\n",
      "epoch:18 step:17117 [D loss: 0.623154, acc.: 67.19%] [G loss: 1.217119]\n",
      "epoch:18 step:17118 [D loss: 0.552894, acc.: 78.91%] [G loss: 1.035886]\n",
      "epoch:18 step:17119 [D loss: 0.512736, acc.: 80.47%] [G loss: 1.132194]\n",
      "epoch:18 step:17120 [D loss: 0.654805, acc.: 66.41%] [G loss: 0.958950]\n",
      "epoch:18 step:17121 [D loss: 0.785054, acc.: 44.53%] [G loss: 1.086460]\n",
      "epoch:18 step:17122 [D loss: 0.767119, acc.: 47.66%] [G loss: 0.885034]\n",
      "epoch:18 step:17123 [D loss: 0.719734, acc.: 50.00%] [G loss: 0.770310]\n",
      "epoch:18 step:17124 [D loss: 0.680973, acc.: 57.81%] [G loss: 0.933005]\n",
      "epoch:18 step:17125 [D loss: 0.725513, acc.: 53.12%] [G loss: 1.199121]\n",
      "epoch:18 step:17126 [D loss: 0.733087, acc.: 54.69%] [G loss: 0.871459]\n",
      "epoch:18 step:17127 [D loss: 0.688805, acc.: 60.16%] [G loss: 0.951772]\n",
      "epoch:18 step:17128 [D loss: 0.661287, acc.: 58.59%] [G loss: 1.028803]\n",
      "epoch:18 step:17129 [D loss: 0.592450, acc.: 70.31%] [G loss: 0.936275]\n",
      "epoch:18 step:17130 [D loss: 0.469543, acc.: 83.59%] [G loss: 1.288639]\n",
      "epoch:18 step:17131 [D loss: 0.667129, acc.: 57.03%] [G loss: 0.924206]\n",
      "epoch:18 step:17132 [D loss: 0.825431, acc.: 42.19%] [G loss: 0.904158]\n",
      "epoch:18 step:17133 [D loss: 0.567715, acc.: 74.22%] [G loss: 0.919506]\n",
      "epoch:18 step:17134 [D loss: 0.703267, acc.: 54.69%] [G loss: 1.022621]\n",
      "epoch:18 step:17135 [D loss: 0.608411, acc.: 64.84%] [G loss: 0.911290]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17136 [D loss: 0.633377, acc.: 64.06%] [G loss: 0.821494]\n",
      "epoch:18 step:17137 [D loss: 0.731583, acc.: 53.12%] [G loss: 0.874028]\n",
      "epoch:18 step:17138 [D loss: 0.460280, acc.: 85.16%] [G loss: 1.075572]\n",
      "epoch:18 step:17139 [D loss: 0.685866, acc.: 57.03%] [G loss: 0.995052]\n",
      "epoch:18 step:17140 [D loss: 0.663299, acc.: 56.25%] [G loss: 0.876530]\n",
      "epoch:18 step:17141 [D loss: 0.631663, acc.: 66.41%] [G loss: 1.323870]\n",
      "epoch:18 step:17142 [D loss: 0.622729, acc.: 64.84%] [G loss: 1.099030]\n",
      "epoch:18 step:17143 [D loss: 0.613154, acc.: 65.62%] [G loss: 1.043336]\n",
      "epoch:18 step:17144 [D loss: 0.623772, acc.: 65.62%] [G loss: 0.875122]\n",
      "epoch:18 step:17145 [D loss: 0.426617, acc.: 84.38%] [G loss: 1.114520]\n",
      "epoch:18 step:17146 [D loss: 0.494517, acc.: 81.25%] [G loss: 1.306100]\n",
      "epoch:18 step:17147 [D loss: 0.788134, acc.: 49.22%] [G loss: 0.955890]\n",
      "epoch:18 step:17148 [D loss: 0.661031, acc.: 59.38%] [G loss: 1.059087]\n",
      "epoch:18 step:17149 [D loss: 0.615997, acc.: 66.41%] [G loss: 1.030603]\n",
      "epoch:18 step:17150 [D loss: 0.651529, acc.: 60.16%] [G loss: 1.009842]\n",
      "epoch:18 step:17151 [D loss: 0.591303, acc.: 67.97%] [G loss: 1.156267]\n",
      "epoch:18 step:17152 [D loss: 0.572829, acc.: 76.56%] [G loss: 1.253569]\n",
      "epoch:18 step:17153 [D loss: 0.537671, acc.: 73.44%] [G loss: 1.337131]\n",
      "epoch:18 step:17154 [D loss: 0.697566, acc.: 60.16%] [G loss: 1.057348]\n",
      "epoch:18 step:17155 [D loss: 0.568678, acc.: 76.56%] [G loss: 0.937635]\n",
      "epoch:18 step:17156 [D loss: 0.605958, acc.: 59.38%] [G loss: 1.048883]\n",
      "epoch:18 step:17157 [D loss: 0.593253, acc.: 68.75%] [G loss: 0.788554]\n",
      "epoch:18 step:17158 [D loss: 0.621332, acc.: 67.97%] [G loss: 1.124483]\n",
      "epoch:18 step:17159 [D loss: 0.621457, acc.: 64.84%] [G loss: 1.056320]\n",
      "epoch:18 step:17160 [D loss: 0.617448, acc.: 66.41%] [G loss: 0.835609]\n",
      "epoch:18 step:17161 [D loss: 0.717747, acc.: 48.44%] [G loss: 0.978497]\n",
      "epoch:18 step:17162 [D loss: 0.695173, acc.: 54.69%] [G loss: 0.767776]\n",
      "epoch:18 step:17163 [D loss: 0.650521, acc.: 60.94%] [G loss: 0.976210]\n",
      "epoch:18 step:17164 [D loss: 0.432169, acc.: 85.94%] [G loss: 1.222540]\n",
      "epoch:18 step:17165 [D loss: 0.534116, acc.: 75.00%] [G loss: 1.165976]\n",
      "epoch:18 step:17166 [D loss: 0.579262, acc.: 69.53%] [G loss: 0.888864]\n",
      "epoch:18 step:17167 [D loss: 0.754004, acc.: 43.75%] [G loss: 0.955807]\n",
      "epoch:18 step:17168 [D loss: 0.740690, acc.: 49.22%] [G loss: 0.831158]\n",
      "epoch:18 step:17169 [D loss: 0.604859, acc.: 71.09%] [G loss: 1.110376]\n",
      "epoch:18 step:17170 [D loss: 0.686632, acc.: 53.12%] [G loss: 1.079108]\n",
      "epoch:18 step:17171 [D loss: 0.690311, acc.: 56.25%] [G loss: 0.950216]\n",
      "epoch:18 step:17172 [D loss: 0.599096, acc.: 67.97%] [G loss: 0.979722]\n",
      "epoch:18 step:17173 [D loss: 0.610187, acc.: 66.41%] [G loss: 0.876480]\n",
      "epoch:18 step:17174 [D loss: 0.625193, acc.: 64.84%] [G loss: 1.016113]\n",
      "epoch:18 step:17175 [D loss: 0.585132, acc.: 68.75%] [G loss: 1.106655]\n",
      "epoch:18 step:17176 [D loss: 0.737499, acc.: 48.44%] [G loss: 0.995209]\n",
      "epoch:18 step:17177 [D loss: 0.566008, acc.: 72.66%] [G loss: 1.035274]\n",
      "epoch:18 step:17178 [D loss: 0.493251, acc.: 80.47%] [G loss: 1.068744]\n",
      "epoch:18 step:17179 [D loss: 0.492500, acc.: 79.69%] [G loss: 1.127839]\n",
      "epoch:18 step:17180 [D loss: 0.507455, acc.: 78.91%] [G loss: 1.211493]\n",
      "epoch:18 step:17181 [D loss: 0.477729, acc.: 79.69%] [G loss: 1.137322]\n",
      "epoch:18 step:17182 [D loss: 0.721601, acc.: 55.47%] [G loss: 1.160482]\n",
      "epoch:18 step:17183 [D loss: 0.736577, acc.: 46.09%] [G loss: 1.049707]\n",
      "epoch:18 step:17184 [D loss: 0.673997, acc.: 57.81%] [G loss: 0.858794]\n",
      "epoch:18 step:17185 [D loss: 0.704343, acc.: 55.47%] [G loss: 1.117415]\n",
      "epoch:18 step:17186 [D loss: 0.708270, acc.: 55.47%] [G loss: 0.750679]\n",
      "epoch:18 step:17187 [D loss: 0.525857, acc.: 79.69%] [G loss: 1.106521]\n",
      "epoch:18 step:17188 [D loss: 0.559785, acc.: 68.75%] [G loss: 0.876916]\n",
      "epoch:18 step:17189 [D loss: 0.800706, acc.: 42.97%] [G loss: 0.885737]\n",
      "epoch:18 step:17190 [D loss: 0.675550, acc.: 57.81%] [G loss: 1.292490]\n",
      "epoch:18 step:17191 [D loss: 0.619244, acc.: 65.62%] [G loss: 1.194258]\n",
      "epoch:18 step:17192 [D loss: 0.541539, acc.: 77.34%] [G loss: 1.135280]\n",
      "epoch:18 step:17193 [D loss: 0.453811, acc.: 80.47%] [G loss: 1.158514]\n",
      "epoch:18 step:17194 [D loss: 0.420834, acc.: 84.38%] [G loss: 1.279958]\n",
      "epoch:18 step:17195 [D loss: 0.559899, acc.: 68.75%] [G loss: 1.277539]\n",
      "epoch:18 step:17196 [D loss: 0.758401, acc.: 48.44%] [G loss: 1.163894]\n",
      "epoch:18 step:17197 [D loss: 0.703391, acc.: 58.59%] [G loss: 0.827637]\n",
      "epoch:18 step:17198 [D loss: 0.752084, acc.: 51.56%] [G loss: 0.982037]\n",
      "epoch:18 step:17199 [D loss: 0.730337, acc.: 53.12%] [G loss: 0.921013]\n",
      "epoch:18 step:17200 [D loss: 0.698460, acc.: 56.25%] [G loss: 1.036680]\n",
      "##############\n",
      "[2.28059439 1.48800246 5.3613034  4.07453944 3.08149227 5.30041019\n",
      " 4.20837043 4.39413152 4.15832673 3.68167564]\n",
      "##########\n",
      "epoch:18 step:17201 [D loss: 0.593766, acc.: 67.97%] [G loss: 1.072385]\n",
      "epoch:18 step:17202 [D loss: 0.694023, acc.: 57.03%] [G loss: 0.952941]\n",
      "epoch:18 step:17203 [D loss: 0.795939, acc.: 46.09%] [G loss: 0.819669]\n",
      "epoch:18 step:17204 [D loss: 0.775263, acc.: 49.22%] [G loss: 0.821065]\n",
      "epoch:18 step:17205 [D loss: 0.553341, acc.: 77.34%] [G loss: 1.345789]\n",
      "epoch:18 step:17206 [D loss: 0.680854, acc.: 57.03%] [G loss: 1.263948]\n",
      "epoch:18 step:17207 [D loss: 0.679049, acc.: 60.94%] [G loss: 1.146429]\n",
      "epoch:18 step:17208 [D loss: 0.565959, acc.: 71.09%] [G loss: 1.229068]\n",
      "epoch:18 step:17209 [D loss: 0.435146, acc.: 84.38%] [G loss: 1.115508]\n",
      "epoch:18 step:17210 [D loss: 0.481330, acc.: 79.69%] [G loss: 1.306301]\n",
      "epoch:18 step:17211 [D loss: 0.372168, acc.: 89.84%] [G loss: 1.308703]\n",
      "epoch:18 step:17212 [D loss: 0.317730, acc.: 94.53%] [G loss: 1.448965]\n",
      "epoch:18 step:17213 [D loss: 0.252408, acc.: 97.66%] [G loss: 1.696984]\n",
      "epoch:18 step:17214 [D loss: 0.643915, acc.: 60.94%] [G loss: 1.300121]\n",
      "epoch:18 step:17215 [D loss: 0.928040, acc.: 34.38%] [G loss: 1.055704]\n",
      "epoch:18 step:17216 [D loss: 0.879805, acc.: 41.41%] [G loss: 0.791303]\n",
      "epoch:18 step:17217 [D loss: 0.665971, acc.: 62.50%] [G loss: 1.074276]\n",
      "epoch:18 step:17218 [D loss: 0.621360, acc.: 67.97%] [G loss: 1.102122]\n",
      "epoch:18 step:17219 [D loss: 0.663041, acc.: 60.94%] [G loss: 0.839614]\n",
      "epoch:18 step:17220 [D loss: 0.529627, acc.: 78.12%] [G loss: 1.055165]\n",
      "epoch:18 step:17221 [D loss: 0.637970, acc.: 64.84%] [G loss: 0.993940]\n",
      "epoch:18 step:17222 [D loss: 0.702934, acc.: 57.81%] [G loss: 1.042754]\n",
      "epoch:18 step:17223 [D loss: 0.649596, acc.: 60.16%] [G loss: 0.998800]\n",
      "epoch:18 step:17224 [D loss: 0.488469, acc.: 82.03%] [G loss: 0.973725]\n",
      "epoch:18 step:17225 [D loss: 0.573192, acc.: 67.19%] [G loss: 0.909580]\n",
      "epoch:18 step:17226 [D loss: 0.628024, acc.: 64.06%] [G loss: 1.018426]\n",
      "epoch:18 step:17227 [D loss: 0.669121, acc.: 57.03%] [G loss: 0.884498]\n",
      "epoch:18 step:17228 [D loss: 0.645293, acc.: 58.59%] [G loss: 1.054738]\n",
      "epoch:18 step:17229 [D loss: 0.671140, acc.: 57.81%] [G loss: 0.922908]\n",
      "epoch:18 step:17230 [D loss: 0.682761, acc.: 60.16%] [G loss: 0.833528]\n",
      "epoch:18 step:17231 [D loss: 0.582901, acc.: 70.31%] [G loss: 0.952394]\n",
      "epoch:18 step:17232 [D loss: 0.360190, acc.: 90.62%] [G loss: 1.185254]\n",
      "epoch:18 step:17233 [D loss: 0.458550, acc.: 79.69%] [G loss: 1.318855]\n",
      "epoch:18 step:17234 [D loss: 0.694006, acc.: 58.59%] [G loss: 1.177945]\n",
      "epoch:18 step:17235 [D loss: 0.688508, acc.: 64.06%] [G loss: 1.276864]\n",
      "epoch:18 step:17236 [D loss: 0.658255, acc.: 60.94%] [G loss: 0.957332]\n",
      "epoch:18 step:17237 [D loss: 0.608518, acc.: 72.66%] [G loss: 1.024338]\n",
      "epoch:18 step:17238 [D loss: 0.567282, acc.: 71.88%] [G loss: 1.104825]\n",
      "epoch:18 step:17239 [D loss: 0.638842, acc.: 62.50%] [G loss: 1.266910]\n",
      "epoch:18 step:17240 [D loss: 0.687358, acc.: 57.81%] [G loss: 1.038821]\n",
      "epoch:18 step:17241 [D loss: 0.709383, acc.: 53.91%] [G loss: 0.990992]\n",
      "epoch:18 step:17242 [D loss: 0.717428, acc.: 52.34%] [G loss: 0.967200]\n",
      "epoch:18 step:17243 [D loss: 0.617330, acc.: 67.19%] [G loss: 0.801630]\n",
      "epoch:18 step:17244 [D loss: 0.692692, acc.: 54.69%] [G loss: 0.960516]\n",
      "epoch:18 step:17245 [D loss: 0.734550, acc.: 51.56%] [G loss: 1.077441]\n",
      "epoch:18 step:17246 [D loss: 0.522069, acc.: 78.12%] [G loss: 0.943434]\n",
      "epoch:18 step:17247 [D loss: 0.481642, acc.: 83.59%] [G loss: 1.098594]\n",
      "epoch:18 step:17248 [D loss: 0.768888, acc.: 51.56%] [G loss: 1.037151]\n",
      "epoch:18 step:17249 [D loss: 0.623378, acc.: 68.75%] [G loss: 0.839654]\n",
      "epoch:18 step:17250 [D loss: 0.734698, acc.: 49.22%] [G loss: 0.807371]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17251 [D loss: 0.708864, acc.: 50.00%] [G loss: 0.893722]\n",
      "epoch:18 step:17252 [D loss: 0.588237, acc.: 69.53%] [G loss: 0.926421]\n",
      "epoch:18 step:17253 [D loss: 0.706851, acc.: 60.94%] [G loss: 0.866058]\n",
      "epoch:18 step:17254 [D loss: 0.586885, acc.: 69.53%] [G loss: 0.967370]\n",
      "epoch:18 step:17255 [D loss: 0.749969, acc.: 51.56%] [G loss: 0.838122]\n",
      "epoch:18 step:17256 [D loss: 0.598609, acc.: 64.84%] [G loss: 1.051538]\n",
      "epoch:18 step:17257 [D loss: 0.495101, acc.: 78.12%] [G loss: 1.158629]\n",
      "epoch:18 step:17258 [D loss: 0.666769, acc.: 58.59%] [G loss: 0.974499]\n",
      "epoch:18 step:17259 [D loss: 0.579855, acc.: 70.31%] [G loss: 1.057829]\n",
      "epoch:18 step:17260 [D loss: 0.523195, acc.: 75.00%] [G loss: 1.056287]\n",
      "epoch:18 step:17261 [D loss: 0.646513, acc.: 56.25%] [G loss: 1.155478]\n",
      "epoch:18 step:17262 [D loss: 0.530241, acc.: 71.88%] [G loss: 0.964827]\n",
      "epoch:18 step:17263 [D loss: 0.345758, acc.: 92.97%] [G loss: 1.432763]\n",
      "epoch:18 step:17264 [D loss: 0.408737, acc.: 85.94%] [G loss: 1.312259]\n",
      "epoch:18 step:17265 [D loss: 0.403453, acc.: 86.72%] [G loss: 1.286354]\n",
      "epoch:18 step:17266 [D loss: 0.365773, acc.: 92.19%] [G loss: 1.652271]\n",
      "epoch:18 step:17267 [D loss: 0.507833, acc.: 78.91%] [G loss: 1.208169]\n",
      "epoch:18 step:17268 [D loss: 0.521368, acc.: 75.00%] [G loss: 1.308026]\n",
      "epoch:18 step:17269 [D loss: 0.545701, acc.: 72.66%] [G loss: 1.063211]\n",
      "epoch:18 step:17270 [D loss: 0.394162, acc.: 85.94%] [G loss: 1.232773]\n",
      "epoch:18 step:17271 [D loss: 0.394440, acc.: 87.50%] [G loss: 1.399096]\n",
      "epoch:18 step:17272 [D loss: 0.535053, acc.: 74.22%] [G loss: 1.192937]\n",
      "epoch:18 step:17273 [D loss: 0.622425, acc.: 67.19%] [G loss: 1.147106]\n",
      "epoch:18 step:17274 [D loss: 0.781535, acc.: 51.56%] [G loss: 0.985868]\n",
      "epoch:18 step:17275 [D loss: 1.036962, acc.: 28.12%] [G loss: 0.516029]\n",
      "epoch:18 step:17276 [D loss: 0.671978, acc.: 56.25%] [G loss: 1.033150]\n",
      "epoch:18 step:17277 [D loss: 1.122530, acc.: 25.00%] [G loss: 0.733007]\n",
      "epoch:18 step:17278 [D loss: 0.899655, acc.: 35.94%] [G loss: 0.606709]\n",
      "epoch:18 step:17279 [D loss: 0.768470, acc.: 44.53%] [G loss: 1.122651]\n",
      "epoch:18 step:17280 [D loss: 0.740131, acc.: 51.56%] [G loss: 1.193743]\n",
      "epoch:18 step:17281 [D loss: 1.150627, acc.: 20.31%] [G loss: 0.835684]\n",
      "epoch:18 step:17282 [D loss: 0.790449, acc.: 42.19%] [G loss: 1.000694]\n",
      "epoch:18 step:17283 [D loss: 0.780090, acc.: 42.97%] [G loss: 1.246497]\n",
      "epoch:18 step:17284 [D loss: 0.747867, acc.: 51.56%] [G loss: 1.095438]\n",
      "epoch:18 step:17285 [D loss: 0.636153, acc.: 65.62%] [G loss: 1.064695]\n",
      "epoch:18 step:17286 [D loss: 0.782218, acc.: 49.22%] [G loss: 1.055488]\n",
      "epoch:18 step:17287 [D loss: 0.659083, acc.: 60.16%] [G loss: 1.027839]\n",
      "epoch:18 step:17288 [D loss: 0.673569, acc.: 60.16%] [G loss: 0.992564]\n",
      "epoch:18 step:17289 [D loss: 0.753822, acc.: 47.66%] [G loss: 1.163113]\n",
      "epoch:18 step:17290 [D loss: 0.763718, acc.: 52.34%] [G loss: 1.202218]\n",
      "epoch:18 step:17291 [D loss: 0.681429, acc.: 53.91%] [G loss: 0.965185]\n",
      "epoch:18 step:17292 [D loss: 0.773296, acc.: 44.53%] [G loss: 1.003668]\n",
      "epoch:18 step:17293 [D loss: 0.642853, acc.: 62.50%] [G loss: 0.988809]\n",
      "epoch:18 step:17294 [D loss: 0.643284, acc.: 60.94%] [G loss: 1.132931]\n",
      "epoch:18 step:17295 [D loss: 0.581874, acc.: 72.66%] [G loss: 1.106311]\n",
      "epoch:18 step:17296 [D loss: 0.583697, acc.: 66.41%] [G loss: 1.232985]\n",
      "epoch:18 step:17297 [D loss: 0.630275, acc.: 63.28%] [G loss: 1.171590]\n",
      "epoch:18 step:17298 [D loss: 0.535870, acc.: 72.66%] [G loss: 1.121771]\n",
      "epoch:18 step:17299 [D loss: 0.556373, acc.: 71.88%] [G loss: 1.441491]\n",
      "epoch:18 step:17300 [D loss: 0.557037, acc.: 73.44%] [G loss: 1.178051]\n",
      "epoch:18 step:17301 [D loss: 0.497625, acc.: 78.91%] [G loss: 1.444236]\n",
      "epoch:18 step:17302 [D loss: 0.540102, acc.: 72.66%] [G loss: 1.122515]\n",
      "epoch:18 step:17303 [D loss: 0.773748, acc.: 53.12%] [G loss: 1.168159]\n",
      "epoch:18 step:17304 [D loss: 0.917947, acc.: 32.81%] [G loss: 1.049332]\n",
      "epoch:18 step:17305 [D loss: 0.769098, acc.: 48.44%] [G loss: 1.033762]\n",
      "epoch:18 step:17306 [D loss: 0.613110, acc.: 70.31%] [G loss: 1.173069]\n",
      "epoch:18 step:17307 [D loss: 0.697620, acc.: 57.03%] [G loss: 0.951398]\n",
      "epoch:18 step:17308 [D loss: 0.767493, acc.: 50.78%] [G loss: 0.801324]\n",
      "epoch:18 step:17309 [D loss: 0.533333, acc.: 75.00%] [G loss: 1.136562]\n",
      "epoch:18 step:17310 [D loss: 0.661785, acc.: 60.16%] [G loss: 1.042060]\n",
      "epoch:18 step:17311 [D loss: 0.706091, acc.: 54.69%] [G loss: 0.902669]\n",
      "epoch:18 step:17312 [D loss: 0.799369, acc.: 41.41%] [G loss: 0.818545]\n",
      "epoch:18 step:17313 [D loss: 0.685782, acc.: 57.81%] [G loss: 1.002033]\n",
      "epoch:18 step:17314 [D loss: 0.644729, acc.: 66.41%] [G loss: 1.163445]\n",
      "epoch:18 step:17315 [D loss: 0.587431, acc.: 69.53%] [G loss: 1.026074]\n",
      "epoch:18 step:17316 [D loss: 0.621536, acc.: 64.06%] [G loss: 1.135425]\n",
      "epoch:18 step:17317 [D loss: 0.633446, acc.: 57.81%] [G loss: 1.008626]\n",
      "epoch:18 step:17318 [D loss: 0.518172, acc.: 76.56%] [G loss: 1.279652]\n",
      "epoch:18 step:17319 [D loss: 0.521200, acc.: 73.44%] [G loss: 1.125889]\n",
      "epoch:18 step:17320 [D loss: 0.511102, acc.: 81.25%] [G loss: 1.270615]\n",
      "epoch:18 step:17321 [D loss: 0.621188, acc.: 65.62%] [G loss: 1.142497]\n",
      "epoch:18 step:17322 [D loss: 0.582081, acc.: 69.53%] [G loss: 1.153449]\n",
      "epoch:18 step:17323 [D loss: 0.463096, acc.: 81.25%] [G loss: 1.273242]\n",
      "epoch:18 step:17324 [D loss: 0.721585, acc.: 51.56%] [G loss: 1.002479]\n",
      "epoch:18 step:17325 [D loss: 0.754379, acc.: 50.78%] [G loss: 0.945212]\n",
      "epoch:18 step:17326 [D loss: 0.832685, acc.: 45.31%] [G loss: 0.728514]\n",
      "epoch:18 step:17327 [D loss: 0.690484, acc.: 57.03%] [G loss: 1.258661]\n",
      "epoch:18 step:17328 [D loss: 0.690410, acc.: 58.59%] [G loss: 1.182866]\n",
      "epoch:18 step:17329 [D loss: 0.677604, acc.: 57.81%] [G loss: 1.125808]\n",
      "epoch:18 step:17330 [D loss: 0.663016, acc.: 58.59%] [G loss: 1.064087]\n",
      "epoch:18 step:17331 [D loss: 0.623390, acc.: 67.97%] [G loss: 1.134429]\n",
      "epoch:18 step:17332 [D loss: 0.720124, acc.: 57.03%] [G loss: 1.057974]\n",
      "epoch:18 step:17333 [D loss: 0.689540, acc.: 50.00%] [G loss: 0.928149]\n",
      "epoch:18 step:17334 [D loss: 0.516636, acc.: 78.12%] [G loss: 1.057240]\n",
      "epoch:18 step:17335 [D loss: 0.529164, acc.: 71.09%] [G loss: 1.139082]\n",
      "epoch:18 step:17336 [D loss: 0.655606, acc.: 60.94%] [G loss: 0.889789]\n",
      "epoch:18 step:17337 [D loss: 0.393387, acc.: 88.28%] [G loss: 1.441506]\n",
      "epoch:18 step:17338 [D loss: 0.655815, acc.: 61.72%] [G loss: 1.131413]\n",
      "epoch:18 step:17339 [D loss: 0.546460, acc.: 69.53%] [G loss: 1.195988]\n",
      "epoch:18 step:17340 [D loss: 0.546199, acc.: 71.88%] [G loss: 1.039194]\n",
      "epoch:18 step:17341 [D loss: 0.493520, acc.: 82.03%] [G loss: 1.356335]\n",
      "epoch:18 step:17342 [D loss: 0.577567, acc.: 67.97%] [G loss: 1.296600]\n",
      "epoch:18 step:17343 [D loss: 0.759363, acc.: 47.66%] [G loss: 1.044646]\n",
      "epoch:18 step:17344 [D loss: 0.733728, acc.: 56.25%] [G loss: 0.945196]\n",
      "epoch:18 step:17345 [D loss: 0.518930, acc.: 75.78%] [G loss: 0.935778]\n",
      "epoch:18 step:17346 [D loss: 0.652026, acc.: 64.06%] [G loss: 0.764370]\n",
      "epoch:18 step:17347 [D loss: 0.610039, acc.: 62.50%] [G loss: 1.078519]\n",
      "epoch:18 step:17348 [D loss: 0.614184, acc.: 67.19%] [G loss: 1.062255]\n",
      "epoch:18 step:17349 [D loss: 0.534356, acc.: 77.34%] [G loss: 1.087163]\n",
      "epoch:18 step:17350 [D loss: 0.543137, acc.: 73.44%] [G loss: 1.076013]\n",
      "epoch:18 step:17351 [D loss: 0.537637, acc.: 72.66%] [G loss: 1.367216]\n",
      "epoch:18 step:17352 [D loss: 0.648092, acc.: 63.28%] [G loss: 1.112113]\n",
      "epoch:18 step:17353 [D loss: 0.624261, acc.: 67.97%] [G loss: 1.219972]\n",
      "epoch:18 step:17354 [D loss: 0.648832, acc.: 63.28%] [G loss: 1.004502]\n",
      "epoch:18 step:17355 [D loss: 0.727420, acc.: 51.56%] [G loss: 0.902181]\n",
      "epoch:18 step:17356 [D loss: 0.593901, acc.: 73.44%] [G loss: 0.916120]\n",
      "epoch:18 step:17357 [D loss: 0.635391, acc.: 60.16%] [G loss: 0.962786]\n",
      "epoch:18 step:17358 [D loss: 0.664227, acc.: 57.81%] [G loss: 1.027539]\n",
      "epoch:18 step:17359 [D loss: 0.593999, acc.: 67.97%] [G loss: 1.096116]\n",
      "epoch:18 step:17360 [D loss: 0.600011, acc.: 71.09%] [G loss: 1.039050]\n",
      "epoch:18 step:17361 [D loss: 0.652254, acc.: 64.84%] [G loss: 0.952956]\n",
      "epoch:18 step:17362 [D loss: 0.661905, acc.: 57.03%] [G loss: 1.081554]\n",
      "epoch:18 step:17363 [D loss: 0.441214, acc.: 86.72%] [G loss: 1.072727]\n",
      "epoch:18 step:17364 [D loss: 0.480998, acc.: 80.47%] [G loss: 1.356604]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17365 [D loss: 0.468318, acc.: 78.91%] [G loss: 1.085825]\n",
      "epoch:18 step:17366 [D loss: 0.852784, acc.: 38.28%] [G loss: 1.216980]\n",
      "epoch:18 step:17367 [D loss: 0.833700, acc.: 39.84%] [G loss: 0.913264]\n",
      "epoch:18 step:17368 [D loss: 0.680097, acc.: 56.25%] [G loss: 0.903974]\n",
      "epoch:18 step:17369 [D loss: 0.520510, acc.: 80.47%] [G loss: 1.087291]\n",
      "epoch:18 step:17370 [D loss: 0.442936, acc.: 85.94%] [G loss: 1.185687]\n",
      "epoch:18 step:17371 [D loss: 0.613213, acc.: 66.41%] [G loss: 0.970954]\n",
      "epoch:18 step:17372 [D loss: 0.540074, acc.: 76.56%] [G loss: 1.062158]\n",
      "epoch:18 step:17373 [D loss: 0.487451, acc.: 79.69%] [G loss: 0.901335]\n",
      "epoch:18 step:17374 [D loss: 0.378146, acc.: 88.28%] [G loss: 1.096316]\n",
      "epoch:18 step:17375 [D loss: 0.705387, acc.: 55.47%] [G loss: 1.248719]\n",
      "epoch:18 step:17376 [D loss: 0.726009, acc.: 50.00%] [G loss: 1.265805]\n",
      "epoch:18 step:17377 [D loss: 0.738025, acc.: 49.22%] [G loss: 0.791978]\n",
      "epoch:18 step:17378 [D loss: 0.611346, acc.: 67.19%] [G loss: 1.112742]\n",
      "epoch:18 step:17379 [D loss: 0.442921, acc.: 87.50%] [G loss: 1.105439]\n",
      "epoch:18 step:17380 [D loss: 0.538569, acc.: 79.69%] [G loss: 1.233510]\n",
      "epoch:18 step:17381 [D loss: 0.505323, acc.: 78.91%] [G loss: 1.236404]\n",
      "epoch:18 step:17382 [D loss: 0.582905, acc.: 64.06%] [G loss: 1.110242]\n",
      "epoch:18 step:17383 [D loss: 0.742831, acc.: 51.56%] [G loss: 0.963233]\n",
      "epoch:18 step:17384 [D loss: 0.662727, acc.: 56.25%] [G loss: 1.029943]\n",
      "epoch:18 step:17385 [D loss: 0.577247, acc.: 72.66%] [G loss: 1.063182]\n",
      "epoch:18 step:17386 [D loss: 0.548511, acc.: 75.78%] [G loss: 1.093964]\n",
      "epoch:18 step:17387 [D loss: 0.598549, acc.: 70.31%] [G loss: 0.966242]\n",
      "epoch:18 step:17388 [D loss: 0.516385, acc.: 76.56%] [G loss: 0.958626]\n",
      "epoch:18 step:17389 [D loss: 0.593069, acc.: 69.53%] [G loss: 1.075883]\n",
      "epoch:18 step:17390 [D loss: 0.688275, acc.: 57.81%] [G loss: 0.977709]\n",
      "epoch:18 step:17391 [D loss: 0.738581, acc.: 54.69%] [G loss: 0.929457]\n",
      "epoch:18 step:17392 [D loss: 0.604170, acc.: 64.06%] [G loss: 1.017519]\n",
      "epoch:18 step:17393 [D loss: 0.598866, acc.: 61.72%] [G loss: 1.103738]\n",
      "epoch:18 step:17394 [D loss: 0.658157, acc.: 60.16%] [G loss: 1.093628]\n",
      "epoch:18 step:17395 [D loss: 0.584654, acc.: 74.22%] [G loss: 1.080782]\n",
      "epoch:18 step:17396 [D loss: 0.513649, acc.: 79.69%] [G loss: 1.139785]\n",
      "epoch:18 step:17397 [D loss: 0.737814, acc.: 53.12%] [G loss: 0.961149]\n",
      "epoch:18 step:17398 [D loss: 0.683324, acc.: 56.25%] [G loss: 1.091009]\n",
      "epoch:18 step:17399 [D loss: 0.468419, acc.: 79.69%] [G loss: 0.999436]\n",
      "epoch:18 step:17400 [D loss: 0.548291, acc.: 71.09%] [G loss: 1.252639]\n",
      "##############\n",
      "[2.41138439 1.64453034 5.33959669 4.17182962 3.10180531 5.35088077\n",
      " 4.14087718 4.70745079 4.08317714 3.58973602]\n",
      "##########\n",
      "epoch:18 step:17401 [D loss: 0.495570, acc.: 82.81%] [G loss: 0.972912]\n",
      "epoch:18 step:17402 [D loss: 0.461637, acc.: 86.72%] [G loss: 1.302864]\n",
      "epoch:18 step:17403 [D loss: 0.419914, acc.: 86.72%] [G loss: 1.168016]\n",
      "epoch:18 step:17404 [D loss: 0.627759, acc.: 63.28%] [G loss: 1.178937]\n",
      "epoch:18 step:17405 [D loss: 0.524594, acc.: 79.69%] [G loss: 1.092426]\n",
      "epoch:18 step:17406 [D loss: 0.604363, acc.: 70.31%] [G loss: 0.971389]\n",
      "epoch:18 step:17407 [D loss: 0.696586, acc.: 62.50%] [G loss: 1.053579]\n",
      "epoch:18 step:17408 [D loss: 0.648052, acc.: 60.16%] [G loss: 0.918208]\n",
      "epoch:18 step:17409 [D loss: 0.717017, acc.: 53.12%] [G loss: 0.865715]\n",
      "epoch:18 step:17410 [D loss: 0.560813, acc.: 74.22%] [G loss: 1.018793]\n",
      "epoch:18 step:17411 [D loss: 0.518024, acc.: 74.22%] [G loss: 0.833488]\n",
      "epoch:18 step:17412 [D loss: 0.524712, acc.: 78.91%] [G loss: 1.079365]\n",
      "epoch:18 step:17413 [D loss: 0.552185, acc.: 75.00%] [G loss: 1.167123]\n",
      "epoch:18 step:17414 [D loss: 0.457927, acc.: 85.94%] [G loss: 1.250299]\n",
      "epoch:18 step:17415 [D loss: 0.349535, acc.: 93.75%] [G loss: 1.255875]\n",
      "epoch:18 step:17416 [D loss: 0.515810, acc.: 71.88%] [G loss: 1.355931]\n",
      "epoch:18 step:17417 [D loss: 0.323649, acc.: 92.19%] [G loss: 1.523880]\n",
      "epoch:18 step:17418 [D loss: 0.455270, acc.: 87.50%] [G loss: 1.354728]\n",
      "epoch:18 step:17419 [D loss: 0.524276, acc.: 77.34%] [G loss: 1.076710]\n",
      "epoch:18 step:17420 [D loss: 0.439090, acc.: 83.59%] [G loss: 1.422646]\n",
      "epoch:18 step:17421 [D loss: 0.451322, acc.: 79.69%] [G loss: 1.352098]\n",
      "epoch:18 step:17422 [D loss: 0.446096, acc.: 82.03%] [G loss: 1.099472]\n",
      "epoch:18 step:17423 [D loss: 0.419673, acc.: 86.72%] [G loss: 1.581935]\n",
      "epoch:18 step:17424 [D loss: 0.512919, acc.: 79.69%] [G loss: 1.129496]\n",
      "epoch:18 step:17425 [D loss: 0.886078, acc.: 42.19%] [G loss: 1.293511]\n",
      "epoch:18 step:17426 [D loss: 0.874028, acc.: 49.22%] [G loss: 1.335816]\n",
      "epoch:18 step:17427 [D loss: 0.621451, acc.: 65.62%] [G loss: 1.131743]\n",
      "epoch:18 step:17428 [D loss: 0.774852, acc.: 49.22%] [G loss: 1.230853]\n",
      "epoch:18 step:17429 [D loss: 0.676799, acc.: 55.47%] [G loss: 0.975126]\n",
      "epoch:18 step:17430 [D loss: 0.561327, acc.: 75.00%] [G loss: 1.053557]\n",
      "epoch:18 step:17431 [D loss: 0.665508, acc.: 58.59%] [G loss: 0.934005]\n",
      "epoch:18 step:17432 [D loss: 0.375206, acc.: 93.75%] [G loss: 1.203337]\n",
      "epoch:18 step:17433 [D loss: 0.412264, acc.: 87.50%] [G loss: 1.627108]\n",
      "epoch:18 step:17434 [D loss: 0.635595, acc.: 64.06%] [G loss: 1.208984]\n",
      "epoch:18 step:17435 [D loss: 0.847483, acc.: 45.31%] [G loss: 0.914645]\n",
      "epoch:18 step:17436 [D loss: 0.566785, acc.: 66.41%] [G loss: 1.251595]\n",
      "epoch:18 step:17437 [D loss: 0.690354, acc.: 58.59%] [G loss: 0.914986]\n",
      "epoch:18 step:17438 [D loss: 0.587755, acc.: 67.97%] [G loss: 1.083467]\n",
      "epoch:18 step:17439 [D loss: 0.437271, acc.: 83.59%] [G loss: 1.549430]\n",
      "epoch:18 step:17440 [D loss: 0.496958, acc.: 82.81%] [G loss: 1.187936]\n",
      "epoch:18 step:17441 [D loss: 0.453947, acc.: 85.16%] [G loss: 1.298759]\n",
      "epoch:18 step:17442 [D loss: 0.457589, acc.: 84.38%] [G loss: 1.448888]\n",
      "epoch:18 step:17443 [D loss: 0.427645, acc.: 85.16%] [G loss: 1.227016]\n",
      "epoch:18 step:17444 [D loss: 0.548941, acc.: 73.44%] [G loss: 0.966214]\n",
      "epoch:18 step:17445 [D loss: 0.672621, acc.: 61.72%] [G loss: 0.903050]\n",
      "epoch:18 step:17446 [D loss: 0.723314, acc.: 53.12%] [G loss: 1.231667]\n",
      "epoch:18 step:17447 [D loss: 0.677545, acc.: 54.69%] [G loss: 0.789638]\n",
      "epoch:18 step:17448 [D loss: 0.881025, acc.: 41.41%] [G loss: 0.846809]\n",
      "epoch:18 step:17449 [D loss: 0.679047, acc.: 57.81%] [G loss: 0.917782]\n",
      "epoch:18 step:17450 [D loss: 0.920104, acc.: 35.16%] [G loss: 0.682797]\n",
      "epoch:18 step:17451 [D loss: 0.691685, acc.: 59.38%] [G loss: 0.849370]\n",
      "epoch:18 step:17452 [D loss: 0.708328, acc.: 55.47%] [G loss: 0.920589]\n",
      "epoch:18 step:17453 [D loss: 0.458185, acc.: 79.69%] [G loss: 1.405532]\n",
      "epoch:18 step:17454 [D loss: 0.624710, acc.: 64.84%] [G loss: 1.127015]\n",
      "epoch:18 step:17455 [D loss: 0.521087, acc.: 73.44%] [G loss: 1.377240]\n",
      "epoch:18 step:17456 [D loss: 0.889153, acc.: 37.50%] [G loss: 1.273551]\n",
      "epoch:18 step:17457 [D loss: 0.840540, acc.: 43.75%] [G loss: 1.216311]\n",
      "epoch:18 step:17458 [D loss: 0.670129, acc.: 60.16%] [G loss: 1.125903]\n",
      "epoch:18 step:17459 [D loss: 0.748561, acc.: 48.44%] [G loss: 1.162839]\n",
      "epoch:18 step:17460 [D loss: 0.600566, acc.: 72.66%] [G loss: 1.182715]\n",
      "epoch:18 step:17461 [D loss: 0.691088, acc.: 57.03%] [G loss: 0.987825]\n",
      "epoch:18 step:17462 [D loss: 0.696926, acc.: 56.25%] [G loss: 0.931231]\n",
      "epoch:18 step:17463 [D loss: 0.578648, acc.: 71.09%] [G loss: 1.030767]\n",
      "epoch:18 step:17464 [D loss: 0.396907, acc.: 83.59%] [G loss: 1.255098]\n",
      "epoch:18 step:17465 [D loss: 0.689091, acc.: 57.03%] [G loss: 1.152933]\n",
      "epoch:18 step:17466 [D loss: 0.732955, acc.: 46.88%] [G loss: 0.958482]\n",
      "epoch:18 step:17467 [D loss: 0.608678, acc.: 68.75%] [G loss: 0.830633]\n",
      "epoch:18 step:17468 [D loss: 0.632101, acc.: 63.28%] [G loss: 0.983160]\n",
      "epoch:18 step:17469 [D loss: 0.492147, acc.: 79.69%] [G loss: 1.209847]\n",
      "epoch:18 step:17470 [D loss: 0.393598, acc.: 88.28%] [G loss: 1.276625]\n",
      "epoch:18 step:17471 [D loss: 0.345759, acc.: 91.41%] [G loss: 1.428247]\n",
      "epoch:18 step:17472 [D loss: 0.710667, acc.: 55.47%] [G loss: 1.137207]\n",
      "epoch:18 step:17473 [D loss: 0.626573, acc.: 64.84%] [G loss: 1.046117]\n",
      "epoch:18 step:17474 [D loss: 0.511247, acc.: 78.91%] [G loss: 1.297682]\n",
      "epoch:18 step:17475 [D loss: 0.633458, acc.: 66.41%] [G loss: 1.092654]\n",
      "epoch:18 step:17476 [D loss: 0.585902, acc.: 68.75%] [G loss: 0.871903]\n",
      "epoch:18 step:17477 [D loss: 0.807434, acc.: 42.19%] [G loss: 0.905348]\n",
      "epoch:18 step:17478 [D loss: 0.646056, acc.: 65.62%] [G loss: 1.175817]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17479 [D loss: 0.439901, acc.: 84.38%] [G loss: 1.120889]\n",
      "epoch:18 step:17480 [D loss: 0.529775, acc.: 75.00%] [G loss: 1.235796]\n",
      "epoch:18 step:17481 [D loss: 0.455166, acc.: 79.69%] [G loss: 1.337185]\n",
      "epoch:18 step:17482 [D loss: 0.507363, acc.: 73.44%] [G loss: 1.169442]\n",
      "epoch:18 step:17483 [D loss: 0.651174, acc.: 67.97%] [G loss: 1.146354]\n",
      "epoch:18 step:17484 [D loss: 0.822279, acc.: 43.75%] [G loss: 1.126436]\n",
      "epoch:18 step:17485 [D loss: 0.894882, acc.: 33.59%] [G loss: 0.935639]\n",
      "epoch:18 step:17486 [D loss: 0.790878, acc.: 39.84%] [G loss: 0.944361]\n",
      "epoch:18 step:17487 [D loss: 0.814834, acc.: 40.62%] [G loss: 1.172637]\n",
      "epoch:18 step:17488 [D loss: 0.601320, acc.: 65.62%] [G loss: 1.244631]\n",
      "epoch:18 step:17489 [D loss: 0.706402, acc.: 53.12%] [G loss: 1.103365]\n",
      "epoch:18 step:17490 [D loss: 0.498465, acc.: 78.91%] [G loss: 1.158760]\n",
      "epoch:18 step:17491 [D loss: 0.720365, acc.: 52.34%] [G loss: 0.839506]\n",
      "epoch:18 step:17492 [D loss: 0.674735, acc.: 61.72%] [G loss: 0.927520]\n",
      "epoch:18 step:17493 [D loss: 0.719667, acc.: 51.56%] [G loss: 0.818431]\n",
      "epoch:18 step:17494 [D loss: 0.745974, acc.: 58.59%] [G loss: 1.039277]\n",
      "epoch:18 step:17495 [D loss: 0.548258, acc.: 74.22%] [G loss: 1.050552]\n",
      "epoch:18 step:17496 [D loss: 0.664345, acc.: 58.59%] [G loss: 0.958203]\n",
      "epoch:18 step:17497 [D loss: 0.588733, acc.: 72.66%] [G loss: 0.911391]\n",
      "epoch:18 step:17498 [D loss: 0.695649, acc.: 57.81%] [G loss: 0.981870]\n",
      "epoch:18 step:17499 [D loss: 0.536960, acc.: 77.34%] [G loss: 0.941663]\n",
      "epoch:18 step:17500 [D loss: 0.529793, acc.: 76.56%] [G loss: 1.103030]\n",
      "epoch:18 step:17501 [D loss: 0.586308, acc.: 71.09%] [G loss: 0.888851]\n",
      "epoch:18 step:17502 [D loss: 0.655727, acc.: 57.03%] [G loss: 0.947457]\n",
      "epoch:18 step:17503 [D loss: 0.684952, acc.: 55.47%] [G loss: 1.017223]\n",
      "epoch:18 step:17504 [D loss: 0.746157, acc.: 45.31%] [G loss: 1.087281]\n",
      "epoch:18 step:17505 [D loss: 0.738920, acc.: 53.12%] [G loss: 1.216344]\n",
      "epoch:18 step:17506 [D loss: 0.558935, acc.: 69.53%] [G loss: 1.303519]\n",
      "epoch:18 step:17507 [D loss: 0.462589, acc.: 90.62%] [G loss: 1.237454]\n",
      "epoch:18 step:17508 [D loss: 0.414100, acc.: 89.84%] [G loss: 1.540866]\n",
      "epoch:18 step:17509 [D loss: 0.723026, acc.: 48.44%] [G loss: 1.290871]\n",
      "epoch:18 step:17510 [D loss: 0.688904, acc.: 55.47%] [G loss: 0.932917]\n",
      "epoch:18 step:17511 [D loss: 0.643178, acc.: 63.28%] [G loss: 0.965991]\n",
      "epoch:18 step:17512 [D loss: 0.588807, acc.: 67.19%] [G loss: 1.012678]\n",
      "epoch:18 step:17513 [D loss: 0.484035, acc.: 79.69%] [G loss: 1.077027]\n",
      "epoch:18 step:17514 [D loss: 0.465682, acc.: 82.81%] [G loss: 1.134127]\n",
      "epoch:18 step:17515 [D loss: 0.522581, acc.: 76.56%] [G loss: 1.171451]\n",
      "epoch:18 step:17516 [D loss: 0.451780, acc.: 85.94%] [G loss: 1.067118]\n",
      "epoch:18 step:17517 [D loss: 0.564341, acc.: 67.19%] [G loss: 0.988391]\n",
      "epoch:18 step:17518 [D loss: 0.854829, acc.: 37.50%] [G loss: 0.933688]\n",
      "epoch:18 step:17519 [D loss: 0.654907, acc.: 61.72%] [G loss: 1.071095]\n",
      "epoch:18 step:17520 [D loss: 0.673914, acc.: 56.25%] [G loss: 1.056494]\n",
      "epoch:18 step:17521 [D loss: 0.752937, acc.: 51.56%] [G loss: 0.947483]\n",
      "epoch:18 step:17522 [D loss: 0.634958, acc.: 67.19%] [G loss: 1.202938]\n",
      "epoch:18 step:17523 [D loss: 0.702301, acc.: 54.69%] [G loss: 0.971633]\n",
      "epoch:18 step:17524 [D loss: 0.710991, acc.: 50.78%] [G loss: 0.920699]\n",
      "epoch:18 step:17525 [D loss: 0.660526, acc.: 64.06%] [G loss: 1.040819]\n",
      "epoch:18 step:17526 [D loss: 0.545420, acc.: 73.44%] [G loss: 1.198021]\n",
      "epoch:18 step:17527 [D loss: 0.627917, acc.: 67.19%] [G loss: 0.974101]\n",
      "epoch:18 step:17528 [D loss: 0.632729, acc.: 62.50%] [G loss: 1.076663]\n",
      "epoch:18 step:17529 [D loss: 0.441976, acc.: 88.28%] [G loss: 1.091573]\n",
      "epoch:18 step:17530 [D loss: 0.550937, acc.: 69.53%] [G loss: 1.186187]\n",
      "epoch:18 step:17531 [D loss: 0.360237, acc.: 92.19%] [G loss: 1.228936]\n",
      "epoch:18 step:17532 [D loss: 0.587411, acc.: 69.53%] [G loss: 1.031710]\n",
      "epoch:18 step:17533 [D loss: 0.489226, acc.: 82.81%] [G loss: 1.237461]\n",
      "epoch:18 step:17534 [D loss: 0.691374, acc.: 57.03%] [G loss: 1.070439]\n",
      "epoch:18 step:17535 [D loss: 0.735741, acc.: 54.69%] [G loss: 0.940768]\n",
      "epoch:18 step:17536 [D loss: 0.621912, acc.: 66.41%] [G loss: 1.124201]\n",
      "epoch:18 step:17537 [D loss: 0.666009, acc.: 60.94%] [G loss: 0.904522]\n",
      "epoch:18 step:17538 [D loss: 0.723634, acc.: 53.12%] [G loss: 0.924972]\n",
      "epoch:18 step:17539 [D loss: 0.894452, acc.: 35.94%] [G loss: 1.026491]\n",
      "epoch:18 step:17540 [D loss: 0.674797, acc.: 59.38%] [G loss: 0.884814]\n",
      "epoch:18 step:17541 [D loss: 0.787563, acc.: 42.97%] [G loss: 0.770260]\n",
      "epoch:18 step:17542 [D loss: 0.700430, acc.: 58.59%] [G loss: 0.995622]\n",
      "epoch:18 step:17543 [D loss: 0.790414, acc.: 43.75%] [G loss: 1.098398]\n",
      "epoch:18 step:17544 [D loss: 0.783737, acc.: 45.31%] [G loss: 1.217886]\n",
      "epoch:18 step:17545 [D loss: 0.686698, acc.: 55.47%] [G loss: 1.252214]\n",
      "epoch:18 step:17546 [D loss: 0.793964, acc.: 47.66%] [G loss: 0.902618]\n",
      "epoch:18 step:17547 [D loss: 0.604286, acc.: 70.31%] [G loss: 1.131760]\n",
      "epoch:18 step:17548 [D loss: 0.694281, acc.: 53.91%] [G loss: 1.005421]\n",
      "epoch:18 step:17549 [D loss: 0.700476, acc.: 53.12%] [G loss: 0.935745]\n",
      "epoch:18 step:17550 [D loss: 0.615574, acc.: 66.41%] [G loss: 0.859309]\n",
      "epoch:18 step:17551 [D loss: 0.675258, acc.: 52.34%] [G loss: 0.875525]\n",
      "epoch:18 step:17552 [D loss: 0.641184, acc.: 62.50%] [G loss: 1.135534]\n",
      "epoch:18 step:17553 [D loss: 0.606896, acc.: 71.88%] [G loss: 1.152622]\n",
      "epoch:18 step:17554 [D loss: 0.556212, acc.: 75.00%] [G loss: 1.231355]\n",
      "epoch:18 step:17555 [D loss: 0.481663, acc.: 75.78%] [G loss: 1.091972]\n",
      "epoch:18 step:17556 [D loss: 0.319993, acc.: 91.41%] [G loss: 1.306546]\n",
      "epoch:18 step:17557 [D loss: 0.538320, acc.: 78.12%] [G loss: 1.308398]\n",
      "epoch:18 step:17558 [D loss: 0.462861, acc.: 85.94%] [G loss: 1.262163]\n",
      "epoch:18 step:17559 [D loss: 0.504622, acc.: 78.12%] [G loss: 0.991974]\n",
      "epoch:18 step:17560 [D loss: 0.423456, acc.: 81.25%] [G loss: 1.386070]\n",
      "epoch:18 step:17561 [D loss: 0.535200, acc.: 73.44%] [G loss: 1.312662]\n",
      "epoch:18 step:17562 [D loss: 0.939002, acc.: 28.91%] [G loss: 0.845882]\n",
      "epoch:18 step:17563 [D loss: 0.834718, acc.: 42.19%] [G loss: 0.928593]\n",
      "epoch:18 step:17564 [D loss: 0.762584, acc.: 51.56%] [G loss: 1.186284]\n",
      "epoch:18 step:17565 [D loss: 0.704134, acc.: 53.91%] [G loss: 0.928995]\n",
      "epoch:18 step:17566 [D loss: 0.590335, acc.: 65.62%] [G loss: 1.182825]\n",
      "epoch:18 step:17567 [D loss: 0.521882, acc.: 79.69%] [G loss: 1.157048]\n",
      "epoch:18 step:17568 [D loss: 0.664268, acc.: 60.16%] [G loss: 1.019692]\n",
      "epoch:18 step:17569 [D loss: 0.643402, acc.: 63.28%] [G loss: 1.102514]\n",
      "epoch:18 step:17570 [D loss: 0.549555, acc.: 72.66%] [G loss: 0.893709]\n",
      "epoch:18 step:17571 [D loss: 0.591339, acc.: 68.75%] [G loss: 0.994093]\n",
      "epoch:18 step:17572 [D loss: 0.409911, acc.: 88.28%] [G loss: 1.126502]\n",
      "epoch:18 step:17573 [D loss: 0.443806, acc.: 82.03%] [G loss: 0.962219]\n",
      "epoch:18 step:17574 [D loss: 0.297871, acc.: 96.88%] [G loss: 1.685761]\n",
      "epoch:18 step:17575 [D loss: 0.296700, acc.: 94.53%] [G loss: 1.521525]\n",
      "epoch:18 step:17576 [D loss: 0.891265, acc.: 41.41%] [G loss: 0.922968]\n",
      "epoch:18 step:17577 [D loss: 0.834915, acc.: 38.28%] [G loss: 0.830084]\n",
      "epoch:18 step:17578 [D loss: 0.500657, acc.: 83.59%] [G loss: 1.037431]\n",
      "epoch:18 step:17579 [D loss: 0.570766, acc.: 71.09%] [G loss: 1.112781]\n",
      "epoch:18 step:17580 [D loss: 0.443205, acc.: 86.72%] [G loss: 1.391519]\n",
      "epoch:18 step:17581 [D loss: 0.664626, acc.: 58.59%] [G loss: 1.295135]\n",
      "epoch:18 step:17582 [D loss: 0.862725, acc.: 46.88%] [G loss: 0.903265]\n",
      "epoch:18 step:17583 [D loss: 0.795670, acc.: 42.97%] [G loss: 0.792230]\n",
      "epoch:18 step:17584 [D loss: 0.792211, acc.: 47.66%] [G loss: 0.765543]\n",
      "epoch:18 step:17585 [D loss: 0.802906, acc.: 43.75%] [G loss: 0.778461]\n",
      "epoch:18 step:17586 [D loss: 0.636048, acc.: 67.19%] [G loss: 0.947750]\n",
      "epoch:18 step:17587 [D loss: 0.635432, acc.: 64.06%] [G loss: 1.081710]\n",
      "epoch:18 step:17588 [D loss: 0.723975, acc.: 56.25%] [G loss: 0.809372]\n",
      "epoch:18 step:17589 [D loss: 0.621851, acc.: 67.19%] [G loss: 0.972768]\n",
      "epoch:18 step:17590 [D loss: 0.455615, acc.: 81.25%] [G loss: 1.019797]\n",
      "epoch:18 step:17591 [D loss: 0.450923, acc.: 85.16%] [G loss: 1.184650]\n",
      "epoch:18 step:17592 [D loss: 0.588742, acc.: 72.66%] [G loss: 0.920061]\n",
      "epoch:18 step:17593 [D loss: 0.604766, acc.: 67.97%] [G loss: 1.123986]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17594 [D loss: 0.613627, acc.: 65.62%] [G loss: 1.162178]\n",
      "epoch:18 step:17595 [D loss: 0.600903, acc.: 70.31%] [G loss: 1.074113]\n",
      "epoch:18 step:17596 [D loss: 0.537964, acc.: 74.22%] [G loss: 1.004140]\n",
      "epoch:18 step:17597 [D loss: 0.514274, acc.: 78.12%] [G loss: 1.096931]\n",
      "epoch:18 step:17598 [D loss: 0.511122, acc.: 73.44%] [G loss: 0.889619]\n",
      "epoch:18 step:17599 [D loss: 0.566060, acc.: 75.00%] [G loss: 1.098205]\n",
      "epoch:18 step:17600 [D loss: 0.700172, acc.: 53.12%] [G loss: 1.067667]\n",
      "##############\n",
      "[2.46024278 1.31621902 5.35483704 4.48616848 3.03952981 5.30942924\n",
      " 4.16478395 4.38290234 4.11569691 3.53580542]\n",
      "##########\n",
      "epoch:18 step:17601 [D loss: 0.605714, acc.: 65.62%] [G loss: 1.153580]\n",
      "epoch:18 step:17602 [D loss: 0.724364, acc.: 50.00%] [G loss: 0.819015]\n",
      "epoch:18 step:17603 [D loss: 0.594929, acc.: 67.19%] [G loss: 1.008066]\n",
      "epoch:18 step:17604 [D loss: 0.686963, acc.: 56.25%] [G loss: 1.087540]\n",
      "epoch:18 step:17605 [D loss: 0.674496, acc.: 60.94%] [G loss: 1.057866]\n",
      "epoch:18 step:17606 [D loss: 0.643562, acc.: 61.72%] [G loss: 1.005707]\n",
      "epoch:18 step:17607 [D loss: 0.490814, acc.: 82.81%] [G loss: 0.953019]\n",
      "epoch:18 step:17608 [D loss: 0.632193, acc.: 64.84%] [G loss: 1.248988]\n",
      "epoch:18 step:17609 [D loss: 0.477832, acc.: 80.47%] [G loss: 1.132256]\n",
      "epoch:18 step:17610 [D loss: 0.612106, acc.: 66.41%] [G loss: 1.110838]\n",
      "epoch:18 step:17611 [D loss: 0.554789, acc.: 74.22%] [G loss: 1.205951]\n",
      "epoch:18 step:17612 [D loss: 0.681087, acc.: 57.81%] [G loss: 1.200690]\n",
      "epoch:18 step:17613 [D loss: 0.623492, acc.: 67.97%] [G loss: 1.148698]\n",
      "epoch:18 step:17614 [D loss: 0.562558, acc.: 70.31%] [G loss: 0.898940]\n",
      "epoch:18 step:17615 [D loss: 0.560445, acc.: 71.09%] [G loss: 0.966547]\n",
      "epoch:18 step:17616 [D loss: 0.565823, acc.: 71.09%] [G loss: 1.091464]\n",
      "epoch:18 step:17617 [D loss: 0.632801, acc.: 65.62%] [G loss: 1.013249]\n",
      "epoch:18 step:17618 [D loss: 0.781425, acc.: 47.66%] [G loss: 0.896348]\n",
      "epoch:18 step:17619 [D loss: 0.752902, acc.: 50.00%] [G loss: 0.891416]\n",
      "epoch:18 step:17620 [D loss: 0.859774, acc.: 40.62%] [G loss: 0.757975]\n",
      "epoch:18 step:17621 [D loss: 0.582285, acc.: 70.31%] [G loss: 0.974665]\n",
      "epoch:18 step:17622 [D loss: 0.638839, acc.: 64.06%] [G loss: 1.007708]\n",
      "epoch:18 step:17623 [D loss: 0.496156, acc.: 82.81%] [G loss: 1.228511]\n",
      "epoch:18 step:17624 [D loss: 0.591301, acc.: 69.53%] [G loss: 1.101916]\n",
      "epoch:18 step:17625 [D loss: 0.728636, acc.: 56.25%] [G loss: 0.903985]\n",
      "epoch:18 step:17626 [D loss: 0.770008, acc.: 39.06%] [G loss: 0.797384]\n",
      "epoch:18 step:17627 [D loss: 0.747871, acc.: 53.12%] [G loss: 0.865700]\n",
      "epoch:18 step:17628 [D loss: 0.751387, acc.: 45.31%] [G loss: 0.890217]\n",
      "epoch:18 step:17629 [D loss: 0.605657, acc.: 61.72%] [G loss: 0.943957]\n",
      "epoch:18 step:17630 [D loss: 0.589828, acc.: 64.06%] [G loss: 0.915284]\n",
      "epoch:18 step:17631 [D loss: 0.753927, acc.: 53.91%] [G loss: 0.998002]\n",
      "epoch:18 step:17632 [D loss: 0.792529, acc.: 48.44%] [G loss: 1.109428]\n",
      "epoch:18 step:17633 [D loss: 0.639530, acc.: 64.84%] [G loss: 1.100550]\n",
      "epoch:18 step:17634 [D loss: 0.494670, acc.: 82.81%] [G loss: 1.298479]\n",
      "epoch:18 step:17635 [D loss: 0.531064, acc.: 72.66%] [G loss: 1.114200]\n",
      "epoch:18 step:17636 [D loss: 0.602910, acc.: 70.31%] [G loss: 0.927608]\n",
      "epoch:18 step:17637 [D loss: 0.767800, acc.: 49.22%] [G loss: 1.191385]\n",
      "epoch:18 step:17638 [D loss: 0.685766, acc.: 53.91%] [G loss: 1.004309]\n",
      "epoch:18 step:17639 [D loss: 0.701963, acc.: 60.94%] [G loss: 0.843001]\n",
      "epoch:18 step:17640 [D loss: 0.457323, acc.: 78.12%] [G loss: 0.997121]\n",
      "epoch:18 step:17641 [D loss: 0.335272, acc.: 92.19%] [G loss: 1.344828]\n",
      "epoch:18 step:17642 [D loss: 0.647171, acc.: 59.38%] [G loss: 1.147158]\n",
      "epoch:18 step:17643 [D loss: 0.598331, acc.: 71.09%] [G loss: 1.169765]\n",
      "epoch:18 step:17644 [D loss: 0.673611, acc.: 51.56%] [G loss: 0.915056]\n",
      "epoch:18 step:17645 [D loss: 0.706155, acc.: 48.44%] [G loss: 0.929910]\n",
      "epoch:18 step:17646 [D loss: 0.621826, acc.: 67.19%] [G loss: 0.969257]\n",
      "epoch:18 step:17647 [D loss: 0.488847, acc.: 81.25%] [G loss: 1.452417]\n",
      "epoch:18 step:17648 [D loss: 0.448674, acc.: 92.19%] [G loss: 1.389074]\n",
      "epoch:18 step:17649 [D loss: 0.708887, acc.: 57.03%] [G loss: 1.118360]\n",
      "epoch:18 step:17650 [D loss: 0.708491, acc.: 57.81%] [G loss: 1.051227]\n",
      "epoch:18 step:17651 [D loss: 0.570151, acc.: 76.56%] [G loss: 0.715646]\n",
      "epoch:18 step:17652 [D loss: 0.462650, acc.: 84.38%] [G loss: 1.177874]\n",
      "epoch:18 step:17653 [D loss: 0.638434, acc.: 64.84%] [G loss: 0.991292]\n",
      "epoch:18 step:17654 [D loss: 0.842799, acc.: 39.06%] [G loss: 0.926475]\n",
      "epoch:18 step:17655 [D loss: 0.634183, acc.: 64.84%] [G loss: 1.030668]\n",
      "epoch:18 step:17656 [D loss: 0.517839, acc.: 75.78%] [G loss: 1.109642]\n",
      "epoch:18 step:17657 [D loss: 0.318987, acc.: 94.53%] [G loss: 1.474097]\n",
      "epoch:18 step:17658 [D loss: 0.382448, acc.: 86.72%] [G loss: 1.418237]\n",
      "epoch:18 step:17659 [D loss: 0.570130, acc.: 71.09%] [G loss: 1.088054]\n",
      "epoch:18 step:17660 [D loss: 0.328785, acc.: 92.19%] [G loss: 1.441701]\n",
      "epoch:18 step:17661 [D loss: 0.534497, acc.: 74.22%] [G loss: 1.357510]\n",
      "epoch:18 step:17662 [D loss: 0.546497, acc.: 78.91%] [G loss: 1.176502]\n",
      "epoch:18 step:17663 [D loss: 0.697261, acc.: 57.03%] [G loss: 0.933597]\n",
      "epoch:18 step:17664 [D loss: 0.664170, acc.: 59.38%] [G loss: 0.949825]\n",
      "epoch:18 step:17665 [D loss: 0.720948, acc.: 58.59%] [G loss: 0.806207]\n",
      "epoch:18 step:17666 [D loss: 0.963675, acc.: 25.78%] [G loss: 0.875328]\n",
      "epoch:18 step:17667 [D loss: 0.902280, acc.: 37.50%] [G loss: 0.955337]\n",
      "epoch:18 step:17668 [D loss: 0.854800, acc.: 35.94%] [G loss: 0.858181]\n",
      "epoch:18 step:17669 [D loss: 0.906767, acc.: 30.47%] [G loss: 0.895469]\n",
      "epoch:18 step:17670 [D loss: 0.553958, acc.: 69.53%] [G loss: 0.956441]\n",
      "epoch:18 step:17671 [D loss: 0.648078, acc.: 64.06%] [G loss: 0.739305]\n",
      "epoch:18 step:17672 [D loss: 0.490815, acc.: 83.59%] [G loss: 1.094774]\n",
      "epoch:18 step:17673 [D loss: 0.739871, acc.: 54.69%] [G loss: 1.102929]\n",
      "epoch:18 step:17674 [D loss: 0.549844, acc.: 74.22%] [G loss: 1.534441]\n",
      "epoch:18 step:17675 [D loss: 0.578737, acc.: 69.53%] [G loss: 1.340673]\n",
      "epoch:18 step:17676 [D loss: 0.568325, acc.: 73.44%] [G loss: 1.079337]\n",
      "epoch:18 step:17677 [D loss: 0.643032, acc.: 58.59%] [G loss: 1.091536]\n",
      "epoch:18 step:17678 [D loss: 0.550641, acc.: 75.00%] [G loss: 1.024448]\n",
      "epoch:18 step:17679 [D loss: 0.554571, acc.: 71.88%] [G loss: 1.114208]\n",
      "epoch:18 step:17680 [D loss: 0.396363, acc.: 89.84%] [G loss: 1.168010]\n",
      "epoch:18 step:17681 [D loss: 0.187907, acc.: 97.66%] [G loss: 1.563025]\n",
      "epoch:18 step:17682 [D loss: 0.340586, acc.: 88.28%] [G loss: 1.318573]\n",
      "epoch:18 step:17683 [D loss: 0.432201, acc.: 85.94%] [G loss: 1.554411]\n",
      "epoch:18 step:17684 [D loss: 0.425266, acc.: 89.06%] [G loss: 1.317672]\n",
      "epoch:18 step:17685 [D loss: 0.592554, acc.: 68.75%] [G loss: 1.031214]\n",
      "epoch:18 step:17686 [D loss: 0.857728, acc.: 45.31%] [G loss: 1.081847]\n",
      "epoch:18 step:17687 [D loss: 0.692743, acc.: 54.69%] [G loss: 1.244120]\n",
      "epoch:18 step:17688 [D loss: 0.776419, acc.: 43.75%] [G loss: 1.009050]\n",
      "epoch:18 step:17689 [D loss: 0.706874, acc.: 56.25%] [G loss: 1.096380]\n",
      "epoch:18 step:17690 [D loss: 0.279727, acc.: 97.66%] [G loss: 1.774540]\n",
      "epoch:18 step:17691 [D loss: 0.377016, acc.: 89.06%] [G loss: 1.444747]\n",
      "epoch:18 step:17692 [D loss: 0.692521, acc.: 56.25%] [G loss: 0.705331]\n",
      "epoch:18 step:17693 [D loss: 1.008307, acc.: 25.00%] [G loss: 0.684194]\n",
      "epoch:18 step:17694 [D loss: 0.710242, acc.: 57.03%] [G loss: 1.025263]\n",
      "epoch:18 step:17695 [D loss: 0.592560, acc.: 64.06%] [G loss: 1.158090]\n",
      "epoch:18 step:17696 [D loss: 0.663256, acc.: 60.94%] [G loss: 1.027136]\n",
      "epoch:18 step:17697 [D loss: 0.453329, acc.: 78.91%] [G loss: 0.918170]\n",
      "epoch:18 step:17698 [D loss: 0.491286, acc.: 77.34%] [G loss: 1.192844]\n",
      "epoch:18 step:17699 [D loss: 0.628656, acc.: 67.19%] [G loss: 1.132775]\n",
      "epoch:18 step:17700 [D loss: 1.023456, acc.: 40.62%] [G loss: 1.073613]\n",
      "epoch:18 step:17701 [D loss: 0.893117, acc.: 35.94%] [G loss: 1.123688]\n",
      "epoch:18 step:17702 [D loss: 1.048334, acc.: 19.53%] [G loss: 0.924994]\n",
      "epoch:18 step:17703 [D loss: 0.645029, acc.: 57.03%] [G loss: 1.259301]\n",
      "epoch:18 step:17704 [D loss: 0.757995, acc.: 50.00%] [G loss: 1.107509]\n",
      "epoch:18 step:17705 [D loss: 0.671112, acc.: 56.25%] [G loss: 1.189250]\n",
      "epoch:18 step:17706 [D loss: 0.525199, acc.: 82.03%] [G loss: 1.395918]\n",
      "epoch:18 step:17707 [D loss: 0.513362, acc.: 78.12%] [G loss: 1.211470]\n",
      "epoch:18 step:17708 [D loss: 0.516036, acc.: 78.12%] [G loss: 1.282141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17709 [D loss: 0.677899, acc.: 57.81%] [G loss: 1.290598]\n",
      "epoch:18 step:17710 [D loss: 0.739908, acc.: 53.91%] [G loss: 0.856373]\n",
      "epoch:18 step:17711 [D loss: 0.763210, acc.: 48.44%] [G loss: 0.801218]\n",
      "epoch:18 step:17712 [D loss: 0.594807, acc.: 67.97%] [G loss: 0.949047]\n",
      "epoch:18 step:17713 [D loss: 0.482194, acc.: 80.47%] [G loss: 1.161908]\n",
      "epoch:18 step:17714 [D loss: 0.564314, acc.: 72.66%] [G loss: 1.077180]\n",
      "epoch:18 step:17715 [D loss: 0.374965, acc.: 91.41%] [G loss: 1.210632]\n",
      "epoch:18 step:17716 [D loss: 0.401873, acc.: 89.06%] [G loss: 1.086661]\n",
      "epoch:18 step:17717 [D loss: 0.453724, acc.: 87.50%] [G loss: 1.332907]\n",
      "epoch:18 step:17718 [D loss: 0.319017, acc.: 96.88%] [G loss: 1.433845]\n",
      "epoch:18 step:17719 [D loss: 0.364981, acc.: 90.62%] [G loss: 1.608317]\n",
      "epoch:18 step:17720 [D loss: 0.385039, acc.: 91.41%] [G loss: 1.481466]\n",
      "epoch:18 step:17721 [D loss: 0.482195, acc.: 81.25%] [G loss: 1.200232]\n",
      "epoch:18 step:17722 [D loss: 0.691915, acc.: 57.81%] [G loss: 0.835160]\n",
      "epoch:18 step:17723 [D loss: 0.457749, acc.: 78.91%] [G loss: 1.343011]\n",
      "epoch:18 step:17724 [D loss: 0.897557, acc.: 43.75%] [G loss: 1.095351]\n",
      "epoch:18 step:17725 [D loss: 0.752444, acc.: 53.12%] [G loss: 0.940911]\n",
      "epoch:18 step:17726 [D loss: 0.740420, acc.: 55.47%] [G loss: 0.895095]\n",
      "epoch:18 step:17727 [D loss: 0.650235, acc.: 66.41%] [G loss: 1.050196]\n",
      "epoch:18 step:17728 [D loss: 0.760952, acc.: 47.66%] [G loss: 0.958848]\n",
      "epoch:18 step:17729 [D loss: 0.656285, acc.: 56.25%] [G loss: 1.051604]\n",
      "epoch:18 step:17730 [D loss: 0.639778, acc.: 59.38%] [G loss: 1.016721]\n",
      "epoch:18 step:17731 [D loss: 0.755884, acc.: 49.22%] [G loss: 0.874549]\n",
      "epoch:18 step:17732 [D loss: 0.626405, acc.: 68.75%] [G loss: 0.882138]\n",
      "epoch:18 step:17733 [D loss: 0.788644, acc.: 46.88%] [G loss: 0.884768]\n",
      "epoch:18 step:17734 [D loss: 0.613845, acc.: 67.19%] [G loss: 1.113190]\n",
      "epoch:18 step:17735 [D loss: 0.698532, acc.: 55.47%] [G loss: 0.957601]\n",
      "epoch:18 step:17736 [D loss: 0.701351, acc.: 52.34%] [G loss: 1.026977]\n",
      "epoch:18 step:17737 [D loss: 0.632215, acc.: 67.97%] [G loss: 0.883530]\n",
      "epoch:18 step:17738 [D loss: 0.639797, acc.: 64.06%] [G loss: 0.846269]\n",
      "epoch:18 step:17739 [D loss: 0.624103, acc.: 66.41%] [G loss: 0.788698]\n",
      "epoch:18 step:17740 [D loss: 0.705983, acc.: 51.56%] [G loss: 0.981461]\n",
      "epoch:18 step:17741 [D loss: 0.627977, acc.: 65.62%] [G loss: 1.019527]\n",
      "epoch:18 step:17742 [D loss: 0.625820, acc.: 69.53%] [G loss: 0.926134]\n",
      "epoch:18 step:17743 [D loss: 0.571356, acc.: 72.66%] [G loss: 1.052588]\n",
      "epoch:18 step:17744 [D loss: 0.419379, acc.: 87.50%] [G loss: 0.995688]\n",
      "epoch:18 step:17745 [D loss: 0.670786, acc.: 57.03%] [G loss: 1.238160]\n",
      "epoch:18 step:17746 [D loss: 0.839373, acc.: 43.75%] [G loss: 0.810237]\n",
      "epoch:18 step:17747 [D loss: 0.735464, acc.: 52.34%] [G loss: 0.997905]\n",
      "epoch:18 step:17748 [D loss: 0.671744, acc.: 55.47%] [G loss: 0.835620]\n",
      "epoch:18 step:17749 [D loss: 0.713125, acc.: 53.12%] [G loss: 0.987105]\n",
      "epoch:18 step:17750 [D loss: 0.556658, acc.: 78.12%] [G loss: 1.046243]\n",
      "epoch:18 step:17751 [D loss: 0.444695, acc.: 89.06%] [G loss: 1.086149]\n",
      "epoch:18 step:17752 [D loss: 0.629258, acc.: 66.41%] [G loss: 0.935067]\n",
      "epoch:18 step:17753 [D loss: 0.531462, acc.: 71.09%] [G loss: 0.982802]\n",
      "epoch:18 step:17754 [D loss: 0.593659, acc.: 70.31%] [G loss: 1.191398]\n",
      "epoch:18 step:17755 [D loss: 0.517623, acc.: 72.66%] [G loss: 0.938420]\n",
      "epoch:18 step:17756 [D loss: 0.494675, acc.: 76.56%] [G loss: 1.207119]\n",
      "epoch:18 step:17757 [D loss: 0.784337, acc.: 50.00%] [G loss: 1.171381]\n",
      "epoch:18 step:17758 [D loss: 0.701820, acc.: 53.12%] [G loss: 0.952336]\n",
      "epoch:18 step:17759 [D loss: 0.602158, acc.: 67.97%] [G loss: 0.981851]\n",
      "epoch:18 step:17760 [D loss: 0.602971, acc.: 66.41%] [G loss: 1.000271]\n",
      "epoch:18 step:17761 [D loss: 0.584102, acc.: 68.75%] [G loss: 1.019874]\n",
      "epoch:18 step:17762 [D loss: 0.553485, acc.: 72.66%] [G loss: 1.004627]\n",
      "epoch:18 step:17763 [D loss: 0.606867, acc.: 65.62%] [G loss: 1.143784]\n",
      "epoch:18 step:17764 [D loss: 0.451565, acc.: 80.47%] [G loss: 1.298871]\n",
      "epoch:18 step:17765 [D loss: 0.413065, acc.: 85.94%] [G loss: 1.443206]\n",
      "epoch:18 step:17766 [D loss: 0.369300, acc.: 87.50%] [G loss: 1.213913]\n",
      "epoch:18 step:17767 [D loss: 0.625999, acc.: 63.28%] [G loss: 1.089178]\n",
      "epoch:18 step:17768 [D loss: 0.716290, acc.: 56.25%] [G loss: 1.135935]\n",
      "epoch:18 step:17769 [D loss: 0.686237, acc.: 53.91%] [G loss: 0.861367]\n",
      "epoch:18 step:17770 [D loss: 0.684263, acc.: 59.38%] [G loss: 1.129369]\n",
      "epoch:18 step:17771 [D loss: 0.695332, acc.: 57.81%] [G loss: 0.816611]\n",
      "epoch:18 step:17772 [D loss: 0.531476, acc.: 77.34%] [G loss: 1.189675]\n",
      "epoch:18 step:17773 [D loss: 0.700542, acc.: 54.69%] [G loss: 1.062951]\n",
      "epoch:18 step:17774 [D loss: 0.705330, acc.: 56.25%] [G loss: 1.069668]\n",
      "epoch:18 step:17775 [D loss: 0.562038, acc.: 71.09%] [G loss: 0.950968]\n",
      "epoch:18 step:17776 [D loss: 0.577768, acc.: 74.22%] [G loss: 0.846330]\n",
      "epoch:18 step:17777 [D loss: 0.555387, acc.: 71.09%] [G loss: 1.093594]\n",
      "epoch:18 step:17778 [D loss: 0.298853, acc.: 96.88%] [G loss: 1.252503]\n",
      "epoch:18 step:17779 [D loss: 0.809447, acc.: 44.53%] [G loss: 0.971809]\n",
      "epoch:18 step:17780 [D loss: 0.756739, acc.: 50.00%] [G loss: 0.902957]\n",
      "epoch:18 step:17781 [D loss: 0.725462, acc.: 53.12%] [G loss: 0.921254]\n",
      "epoch:18 step:17782 [D loss: 0.693610, acc.: 57.81%] [G loss: 0.903364]\n",
      "epoch:18 step:17783 [D loss: 0.600711, acc.: 68.75%] [G loss: 1.107466]\n",
      "epoch:18 step:17784 [D loss: 0.581507, acc.: 70.31%] [G loss: 1.002328]\n",
      "epoch:18 step:17785 [D loss: 0.606831, acc.: 64.06%] [G loss: 1.082861]\n",
      "epoch:18 step:17786 [D loss: 0.443563, acc.: 80.47%] [G loss: 1.110131]\n",
      "epoch:18 step:17787 [D loss: 0.452051, acc.: 85.94%] [G loss: 1.140688]\n",
      "epoch:18 step:17788 [D loss: 0.572651, acc.: 70.31%] [G loss: 1.259925]\n",
      "epoch:18 step:17789 [D loss: 0.554218, acc.: 75.00%] [G loss: 1.106709]\n",
      "epoch:18 step:17790 [D loss: 0.476220, acc.: 82.03%] [G loss: 1.051561]\n",
      "epoch:18 step:17791 [D loss: 0.475489, acc.: 79.69%] [G loss: 1.015184]\n",
      "epoch:18 step:17792 [D loss: 0.549011, acc.: 71.88%] [G loss: 0.891963]\n",
      "epoch:18 step:17793 [D loss: 0.359688, acc.: 89.84%] [G loss: 1.122206]\n",
      "epoch:18 step:17794 [D loss: 1.053161, acc.: 27.34%] [G loss: 0.888193]\n",
      "epoch:18 step:17795 [D loss: 0.446931, acc.: 85.16%] [G loss: 1.279764]\n",
      "epoch:18 step:17796 [D loss: 0.489875, acc.: 85.16%] [G loss: 1.153800]\n",
      "epoch:18 step:17797 [D loss: 0.641643, acc.: 62.50%] [G loss: 1.010961]\n",
      "epoch:18 step:17798 [D loss: 0.603004, acc.: 64.84%] [G loss: 1.170889]\n",
      "epoch:18 step:17799 [D loss: 0.519470, acc.: 80.47%] [G loss: 1.045542]\n",
      "epoch:18 step:17800 [D loss: 0.455180, acc.: 85.16%] [G loss: 1.079938]\n",
      "##############\n",
      "[2.20090934 1.46911799 5.4516796  4.29694586 2.89041296 5.32483853\n",
      " 4.11101861 4.50830185 4.04482199 3.56689857]\n",
      "##########\n",
      "epoch:18 step:17801 [D loss: 0.473438, acc.: 85.94%] [G loss: 1.146255]\n",
      "epoch:18 step:17802 [D loss: 0.492700, acc.: 76.56%] [G loss: 1.076281]\n",
      "epoch:18 step:17803 [D loss: 0.288084, acc.: 89.06%] [G loss: 1.439429]\n",
      "epoch:19 step:17804 [D loss: 0.758617, acc.: 55.47%] [G loss: 1.355081]\n",
      "epoch:19 step:17805 [D loss: 0.598527, acc.: 65.62%] [G loss: 1.306609]\n",
      "epoch:19 step:17806 [D loss: 0.847174, acc.: 37.50%] [G loss: 0.871034]\n",
      "epoch:19 step:17807 [D loss: 0.650831, acc.: 62.50%] [G loss: 1.194132]\n",
      "epoch:19 step:17808 [D loss: 0.796741, acc.: 41.41%] [G loss: 0.781693]\n",
      "epoch:19 step:17809 [D loss: 0.654656, acc.: 60.16%] [G loss: 0.906016]\n",
      "epoch:19 step:17810 [D loss: 0.626053, acc.: 65.62%] [G loss: 0.905379]\n",
      "epoch:19 step:17811 [D loss: 0.526022, acc.: 80.47%] [G loss: 1.401240]\n",
      "epoch:19 step:17812 [D loss: 0.551226, acc.: 73.44%] [G loss: 1.087759]\n",
      "epoch:19 step:17813 [D loss: 0.465143, acc.: 82.81%] [G loss: 1.120315]\n",
      "epoch:19 step:17814 [D loss: 0.516267, acc.: 76.56%] [G loss: 1.321613]\n",
      "epoch:19 step:17815 [D loss: 0.601290, acc.: 71.09%] [G loss: 0.979071]\n",
      "epoch:19 step:17816 [D loss: 0.731053, acc.: 58.59%] [G loss: 0.820881]\n",
      "epoch:19 step:17817 [D loss: 0.736379, acc.: 50.78%] [G loss: 1.036282]\n",
      "epoch:19 step:17818 [D loss: 0.557641, acc.: 69.53%] [G loss: 1.124387]\n",
      "epoch:19 step:17819 [D loss: 0.495037, acc.: 78.91%] [G loss: 1.197868]\n",
      "epoch:19 step:17820 [D loss: 0.704259, acc.: 58.59%] [G loss: 1.290094]\n",
      "epoch:19 step:17821 [D loss: 0.627257, acc.: 62.50%] [G loss: 1.060289]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:17822 [D loss: 0.961646, acc.: 32.03%] [G loss: 0.728980]\n",
      "epoch:19 step:17823 [D loss: 0.715441, acc.: 52.34%] [G loss: 1.089820]\n",
      "epoch:19 step:17824 [D loss: 0.658936, acc.: 55.47%] [G loss: 1.099580]\n",
      "epoch:19 step:17825 [D loss: 0.664067, acc.: 60.16%] [G loss: 0.925932]\n",
      "epoch:19 step:17826 [D loss: 0.600127, acc.: 67.19%] [G loss: 1.119068]\n",
      "epoch:19 step:17827 [D loss: 0.674956, acc.: 54.69%] [G loss: 1.008783]\n",
      "epoch:19 step:17828 [D loss: 0.629670, acc.: 63.28%] [G loss: 1.069597]\n",
      "epoch:19 step:17829 [D loss: 0.550634, acc.: 75.78%] [G loss: 1.060893]\n",
      "epoch:19 step:17830 [D loss: 0.322586, acc.: 93.75%] [G loss: 1.446074]\n",
      "epoch:19 step:17831 [D loss: 0.358536, acc.: 94.53%] [G loss: 1.304633]\n",
      "epoch:19 step:17832 [D loss: 0.465231, acc.: 83.59%] [G loss: 1.071743]\n",
      "epoch:19 step:17833 [D loss: 0.355355, acc.: 92.97%] [G loss: 1.505200]\n",
      "epoch:19 step:17834 [D loss: 0.354888, acc.: 94.53%] [G loss: 1.327128]\n",
      "epoch:19 step:17835 [D loss: 0.274379, acc.: 96.09%] [G loss: 1.423837]\n",
      "epoch:19 step:17836 [D loss: 0.394221, acc.: 85.16%] [G loss: 1.502010]\n",
      "epoch:19 step:17837 [D loss: 0.336287, acc.: 91.41%] [G loss: 1.524465]\n",
      "epoch:19 step:17838 [D loss: 0.346540, acc.: 90.62%] [G loss: 1.670583]\n",
      "epoch:19 step:17839 [D loss: 0.257515, acc.: 96.09%] [G loss: 1.919900]\n",
      "epoch:19 step:17840 [D loss: 0.841654, acc.: 50.78%] [G loss: 1.272337]\n",
      "epoch:19 step:17841 [D loss: 0.946797, acc.: 36.72%] [G loss: 0.884852]\n",
      "epoch:19 step:17842 [D loss: 1.022499, acc.: 23.44%] [G loss: 0.784492]\n",
      "epoch:19 step:17843 [D loss: 0.743972, acc.: 51.56%] [G loss: 0.897298]\n",
      "epoch:19 step:17844 [D loss: 0.661861, acc.: 61.72%] [G loss: 0.864647]\n",
      "epoch:19 step:17845 [D loss: 0.561166, acc.: 69.53%] [G loss: 0.962656]\n",
      "epoch:19 step:17846 [D loss: 0.578065, acc.: 73.44%] [G loss: 1.166397]\n",
      "epoch:19 step:17847 [D loss: 0.772061, acc.: 50.00%] [G loss: 0.654016]\n",
      "epoch:19 step:17848 [D loss: 0.622490, acc.: 59.38%] [G loss: 1.237304]\n",
      "epoch:19 step:17849 [D loss: 0.823507, acc.: 34.38%] [G loss: 0.716168]\n",
      "epoch:19 step:17850 [D loss: 0.584620, acc.: 65.62%] [G loss: 1.280682]\n",
      "epoch:19 step:17851 [D loss: 0.695904, acc.: 57.03%] [G loss: 1.002819]\n",
      "epoch:19 step:17852 [D loss: 0.553842, acc.: 72.66%] [G loss: 1.062267]\n",
      "epoch:19 step:17853 [D loss: 0.646187, acc.: 59.38%] [G loss: 1.243086]\n",
      "epoch:19 step:17854 [D loss: 0.678528, acc.: 56.25%] [G loss: 1.060495]\n",
      "epoch:19 step:17855 [D loss: 0.645716, acc.: 64.06%] [G loss: 0.975335]\n",
      "epoch:19 step:17856 [D loss: 0.574539, acc.: 71.09%] [G loss: 0.998834]\n",
      "epoch:19 step:17857 [D loss: 0.557252, acc.: 75.78%] [G loss: 1.194587]\n",
      "epoch:19 step:17858 [D loss: 0.462269, acc.: 85.94%] [G loss: 1.137135]\n",
      "epoch:19 step:17859 [D loss: 0.579162, acc.: 71.09%] [G loss: 1.191461]\n",
      "epoch:19 step:17860 [D loss: 0.704535, acc.: 54.69%] [G loss: 1.011210]\n",
      "epoch:19 step:17861 [D loss: 0.695437, acc.: 59.38%] [G loss: 0.871396]\n",
      "epoch:19 step:17862 [D loss: 0.685965, acc.: 63.28%] [G loss: 1.044138]\n",
      "epoch:19 step:17863 [D loss: 0.695713, acc.: 54.69%] [G loss: 0.976580]\n",
      "epoch:19 step:17864 [D loss: 0.746887, acc.: 50.00%] [G loss: 0.787952]\n",
      "epoch:19 step:17865 [D loss: 0.593853, acc.: 70.31%] [G loss: 1.102009]\n",
      "epoch:19 step:17866 [D loss: 0.845525, acc.: 38.28%] [G loss: 0.906378]\n",
      "epoch:19 step:17867 [D loss: 0.623439, acc.: 66.41%] [G loss: 1.034365]\n",
      "epoch:19 step:17868 [D loss: 0.506036, acc.: 78.12%] [G loss: 1.083694]\n",
      "epoch:19 step:17869 [D loss: 0.548465, acc.: 71.09%] [G loss: 1.177601]\n",
      "epoch:19 step:17870 [D loss: 0.792228, acc.: 48.44%] [G loss: 0.782735]\n",
      "epoch:19 step:17871 [D loss: 0.566817, acc.: 72.66%] [G loss: 0.964433]\n",
      "epoch:19 step:17872 [D loss: 0.561176, acc.: 71.09%] [G loss: 1.006489]\n",
      "epoch:19 step:17873 [D loss: 0.535328, acc.: 70.31%] [G loss: 1.411162]\n",
      "epoch:19 step:17874 [D loss: 0.772051, acc.: 46.88%] [G loss: 0.921245]\n",
      "epoch:19 step:17875 [D loss: 0.721016, acc.: 53.12%] [G loss: 1.001242]\n",
      "epoch:19 step:17876 [D loss: 0.716511, acc.: 50.78%] [G loss: 0.943867]\n",
      "epoch:19 step:17877 [D loss: 0.589303, acc.: 67.19%] [G loss: 0.911424]\n",
      "epoch:19 step:17878 [D loss: 0.397646, acc.: 86.72%] [G loss: 1.322716]\n",
      "epoch:19 step:17879 [D loss: 0.350755, acc.: 93.75%] [G loss: 1.354545]\n",
      "epoch:19 step:17880 [D loss: 0.386267, acc.: 91.41%] [G loss: 1.421440]\n",
      "epoch:19 step:17881 [D loss: 0.675215, acc.: 57.81%] [G loss: 1.274484]\n",
      "epoch:19 step:17882 [D loss: 0.565902, acc.: 69.53%] [G loss: 1.007901]\n",
      "epoch:19 step:17883 [D loss: 0.745139, acc.: 53.12%] [G loss: 0.945649]\n",
      "epoch:19 step:17884 [D loss: 0.690958, acc.: 59.38%] [G loss: 1.185445]\n",
      "epoch:19 step:17885 [D loss: 0.674266, acc.: 56.25%] [G loss: 1.160505]\n",
      "epoch:19 step:17886 [D loss: 0.667187, acc.: 61.72%] [G loss: 0.979981]\n",
      "epoch:19 step:17887 [D loss: 0.615869, acc.: 60.94%] [G loss: 1.204513]\n",
      "epoch:19 step:17888 [D loss: 0.600788, acc.: 71.88%] [G loss: 1.075191]\n",
      "epoch:19 step:17889 [D loss: 0.709153, acc.: 55.47%] [G loss: 1.029600]\n",
      "epoch:19 step:17890 [D loss: 0.766924, acc.: 49.22%] [G loss: 0.864496]\n",
      "epoch:19 step:17891 [D loss: 0.607176, acc.: 63.28%] [G loss: 1.030104]\n",
      "epoch:19 step:17892 [D loss: 0.713101, acc.: 56.25%] [G loss: 0.941287]\n",
      "epoch:19 step:17893 [D loss: 0.726131, acc.: 51.56%] [G loss: 0.971753]\n",
      "epoch:19 step:17894 [D loss: 0.688858, acc.: 53.91%] [G loss: 0.996602]\n",
      "epoch:19 step:17895 [D loss: 0.497083, acc.: 76.56%] [G loss: 0.937582]\n",
      "epoch:19 step:17896 [D loss: 0.593537, acc.: 65.62%] [G loss: 1.001755]\n",
      "epoch:19 step:17897 [D loss: 0.696497, acc.: 55.47%] [G loss: 0.810693]\n",
      "epoch:19 step:17898 [D loss: 0.643462, acc.: 59.38%] [G loss: 0.852616]\n",
      "epoch:19 step:17899 [D loss: 0.643442, acc.: 54.69%] [G loss: 0.870298]\n",
      "epoch:19 step:17900 [D loss: 0.515335, acc.: 77.34%] [G loss: 1.161399]\n",
      "epoch:19 step:17901 [D loss: 0.647608, acc.: 64.06%] [G loss: 1.042860]\n",
      "epoch:19 step:17902 [D loss: 0.667786, acc.: 60.94%] [G loss: 0.887267]\n",
      "epoch:19 step:17903 [D loss: 0.620368, acc.: 65.62%] [G loss: 0.925251]\n",
      "epoch:19 step:17904 [D loss: 0.618545, acc.: 64.84%] [G loss: 0.934795]\n",
      "epoch:19 step:17905 [D loss: 0.621073, acc.: 68.75%] [G loss: 1.032876]\n",
      "epoch:19 step:17906 [D loss: 0.631175, acc.: 63.28%] [G loss: 0.998937]\n",
      "epoch:19 step:17907 [D loss: 0.626894, acc.: 69.53%] [G loss: 1.101000]\n",
      "epoch:19 step:17908 [D loss: 0.541994, acc.: 75.00%] [G loss: 0.905308]\n",
      "epoch:19 step:17909 [D loss: 0.596574, acc.: 73.44%] [G loss: 1.101636]\n",
      "epoch:19 step:17910 [D loss: 0.795712, acc.: 42.19%] [G loss: 0.942592]\n",
      "epoch:19 step:17911 [D loss: 0.630185, acc.: 61.72%] [G loss: 1.082334]\n",
      "epoch:19 step:17912 [D loss: 0.727835, acc.: 57.03%] [G loss: 0.913074]\n",
      "epoch:19 step:17913 [D loss: 0.637597, acc.: 62.50%] [G loss: 1.023597]\n",
      "epoch:19 step:17914 [D loss: 0.632939, acc.: 67.19%] [G loss: 1.037673]\n",
      "epoch:19 step:17915 [D loss: 0.778364, acc.: 46.88%] [G loss: 0.774385]\n",
      "epoch:19 step:17916 [D loss: 0.731008, acc.: 48.44%] [G loss: 0.934581]\n",
      "epoch:19 step:17917 [D loss: 0.629229, acc.: 65.62%] [G loss: 0.991429]\n",
      "epoch:19 step:17918 [D loss: 0.639799, acc.: 60.94%] [G loss: 1.124229]\n",
      "epoch:19 step:17919 [D loss: 0.717937, acc.: 50.00%] [G loss: 1.055438]\n",
      "epoch:19 step:17920 [D loss: 0.601968, acc.: 62.50%] [G loss: 0.891294]\n",
      "epoch:19 step:17921 [D loss: 0.644706, acc.: 60.16%] [G loss: 1.174073]\n",
      "epoch:19 step:17922 [D loss: 0.467647, acc.: 82.03%] [G loss: 1.099561]\n",
      "epoch:19 step:17923 [D loss: 0.642782, acc.: 57.81%] [G loss: 1.187208]\n",
      "epoch:19 step:17924 [D loss: 0.480260, acc.: 77.34%] [G loss: 1.140467]\n",
      "epoch:19 step:17925 [D loss: 0.349001, acc.: 90.62%] [G loss: 1.193522]\n",
      "epoch:19 step:17926 [D loss: 0.604482, acc.: 73.44%] [G loss: 1.152593]\n",
      "epoch:19 step:17927 [D loss: 0.745547, acc.: 53.12%] [G loss: 1.036345]\n",
      "epoch:19 step:17928 [D loss: 0.832785, acc.: 43.75%] [G loss: 1.178767]\n",
      "epoch:19 step:17929 [D loss: 0.570391, acc.: 72.66%] [G loss: 1.006583]\n",
      "epoch:19 step:17930 [D loss: 0.598826, acc.: 71.88%] [G loss: 1.000367]\n",
      "epoch:19 step:17931 [D loss: 0.598957, acc.: 65.62%] [G loss: 0.831716]\n",
      "epoch:19 step:17932 [D loss: 0.520579, acc.: 77.34%] [G loss: 0.880726]\n",
      "epoch:19 step:17933 [D loss: 0.393609, acc.: 85.94%] [G loss: 1.329021]\n",
      "epoch:19 step:17934 [D loss: 0.287357, acc.: 96.09%] [G loss: 1.392993]\n",
      "epoch:19 step:17935 [D loss: 0.499997, acc.: 80.47%] [G loss: 1.240071]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:17936 [D loss: 0.930215, acc.: 32.03%] [G loss: 1.030980]\n",
      "epoch:19 step:17937 [D loss: 0.746277, acc.: 45.31%] [G loss: 0.907312]\n",
      "epoch:19 step:17938 [D loss: 0.719087, acc.: 48.44%] [G loss: 0.814508]\n",
      "epoch:19 step:17939 [D loss: 0.777176, acc.: 45.31%] [G loss: 0.880334]\n",
      "epoch:19 step:17940 [D loss: 0.671517, acc.: 60.16%] [G loss: 0.888630]\n",
      "epoch:19 step:17941 [D loss: 0.554146, acc.: 73.44%] [G loss: 1.083424]\n",
      "epoch:19 step:17942 [D loss: 0.448735, acc.: 85.94%] [G loss: 1.049919]\n",
      "epoch:19 step:17943 [D loss: 0.689050, acc.: 57.03%] [G loss: 1.074269]\n",
      "epoch:19 step:17944 [D loss: 0.718901, acc.: 52.34%] [G loss: 0.935378]\n",
      "epoch:19 step:17945 [D loss: 0.675437, acc.: 57.81%] [G loss: 0.841694]\n",
      "epoch:19 step:17946 [D loss: 0.651801, acc.: 64.06%] [G loss: 0.968696]\n",
      "epoch:19 step:17947 [D loss: 0.502316, acc.: 82.03%] [G loss: 0.994764]\n",
      "epoch:19 step:17948 [D loss: 0.448739, acc.: 82.03%] [G loss: 1.058613]\n",
      "epoch:19 step:17949 [D loss: 0.647902, acc.: 59.38%] [G loss: 0.994109]\n",
      "epoch:19 step:17950 [D loss: 0.580953, acc.: 71.88%] [G loss: 1.227617]\n",
      "epoch:19 step:17951 [D loss: 0.777555, acc.: 42.19%] [G loss: 0.813878]\n",
      "epoch:19 step:17952 [D loss: 0.529580, acc.: 76.56%] [G loss: 1.009353]\n",
      "epoch:19 step:17953 [D loss: 0.445547, acc.: 81.25%] [G loss: 1.099019]\n",
      "epoch:19 step:17954 [D loss: 0.452277, acc.: 78.12%] [G loss: 1.173498]\n",
      "epoch:19 step:17955 [D loss: 0.258726, acc.: 96.09%] [G loss: 1.718030]\n",
      "epoch:19 step:17956 [D loss: 0.789849, acc.: 53.91%] [G loss: 1.469070]\n",
      "epoch:19 step:17957 [D loss: 1.025029, acc.: 26.56%] [G loss: 0.647925]\n",
      "epoch:19 step:17958 [D loss: 0.678775, acc.: 57.81%] [G loss: 1.136583]\n",
      "epoch:19 step:17959 [D loss: 0.715610, acc.: 56.25%] [G loss: 0.964452]\n",
      "epoch:19 step:17960 [D loss: 0.702931, acc.: 54.69%] [G loss: 1.029722]\n",
      "epoch:19 step:17961 [D loss: 0.622674, acc.: 66.41%] [G loss: 1.222920]\n",
      "epoch:19 step:17962 [D loss: 0.580950, acc.: 72.66%] [G loss: 0.848041]\n",
      "epoch:19 step:17963 [D loss: 0.717963, acc.: 54.69%] [G loss: 0.922416]\n",
      "epoch:19 step:17964 [D loss: 0.640505, acc.: 64.06%] [G loss: 1.020929]\n",
      "epoch:19 step:17965 [D loss: 0.624193, acc.: 65.62%] [G loss: 0.853392]\n",
      "epoch:19 step:17966 [D loss: 0.594649, acc.: 66.41%] [G loss: 1.009610]\n",
      "epoch:19 step:17967 [D loss: 0.610965, acc.: 67.19%] [G loss: 0.984547]\n",
      "epoch:19 step:17968 [D loss: 0.729017, acc.: 50.78%] [G loss: 0.996537]\n",
      "epoch:19 step:17969 [D loss: 0.570946, acc.: 67.97%] [G loss: 0.964421]\n",
      "epoch:19 step:17970 [D loss: 0.547893, acc.: 71.09%] [G loss: 0.976244]\n",
      "epoch:19 step:17971 [D loss: 0.501442, acc.: 76.56%] [G loss: 1.017052]\n",
      "epoch:19 step:17972 [D loss: 0.609314, acc.: 64.06%] [G loss: 0.927189]\n",
      "epoch:19 step:17973 [D loss: 0.684008, acc.: 53.91%] [G loss: 1.200372]\n",
      "epoch:19 step:17974 [D loss: 0.575282, acc.: 69.53%] [G loss: 1.263532]\n",
      "epoch:19 step:17975 [D loss: 0.574240, acc.: 72.66%] [G loss: 0.991258]\n",
      "epoch:19 step:17976 [D loss: 0.553217, acc.: 75.00%] [G loss: 1.113856]\n",
      "epoch:19 step:17977 [D loss: 0.711794, acc.: 55.47%] [G loss: 0.874642]\n",
      "epoch:19 step:17978 [D loss: 0.714994, acc.: 51.56%] [G loss: 1.090003]\n",
      "epoch:19 step:17979 [D loss: 0.639166, acc.: 62.50%] [G loss: 0.805582]\n",
      "epoch:19 step:17980 [D loss: 0.636759, acc.: 67.97%] [G loss: 0.937372]\n",
      "epoch:19 step:17981 [D loss: 0.748793, acc.: 57.03%] [G loss: 0.744541]\n",
      "epoch:19 step:17982 [D loss: 0.952164, acc.: 33.59%] [G loss: 0.760433]\n",
      "epoch:19 step:17983 [D loss: 0.782647, acc.: 44.53%] [G loss: 0.832883]\n",
      "epoch:19 step:17984 [D loss: 0.941469, acc.: 35.94%] [G loss: 0.777435]\n",
      "epoch:19 step:17985 [D loss: 0.569025, acc.: 73.44%] [G loss: 1.172966]\n",
      "epoch:19 step:17986 [D loss: 0.893715, acc.: 31.25%] [G loss: 0.868524]\n",
      "epoch:19 step:17987 [D loss: 0.685753, acc.: 57.81%] [G loss: 1.158246]\n",
      "epoch:19 step:17988 [D loss: 0.851211, acc.: 38.28%] [G loss: 0.750121]\n",
      "epoch:19 step:17989 [D loss: 0.851227, acc.: 41.41%] [G loss: 0.925436]\n",
      "epoch:19 step:17990 [D loss: 0.742239, acc.: 51.56%] [G loss: 1.204926]\n",
      "epoch:19 step:17991 [D loss: 0.785461, acc.: 46.09%] [G loss: 0.790781]\n",
      "epoch:19 step:17992 [D loss: 0.864047, acc.: 36.72%] [G loss: 0.998531]\n",
      "epoch:19 step:17993 [D loss: 0.625690, acc.: 63.28%] [G loss: 1.015425]\n",
      "epoch:19 step:17994 [D loss: 0.561437, acc.: 71.09%] [G loss: 0.846066]\n",
      "epoch:19 step:17995 [D loss: 0.520220, acc.: 79.69%] [G loss: 0.947233]\n",
      "epoch:19 step:17996 [D loss: 0.904513, acc.: 34.38%] [G loss: 0.950256]\n",
      "epoch:19 step:17997 [D loss: 0.781041, acc.: 47.66%] [G loss: 1.003786]\n",
      "epoch:19 step:17998 [D loss: 0.641184, acc.: 64.06%] [G loss: 1.132006]\n",
      "epoch:19 step:17999 [D loss: 0.844451, acc.: 38.28%] [G loss: 1.135701]\n",
      "epoch:19 step:18000 [D loss: 0.720855, acc.: 53.12%] [G loss: 0.924967]\n",
      "##############\n",
      "[2.35146628 1.57901832 5.62622605 4.09700419 3.06513362 5.66048164\n",
      " 4.33756626 4.5710697  4.35783102 3.83299009]\n",
      "##########\n",
      "epoch:19 step:18001 [D loss: 0.784721, acc.: 42.19%] [G loss: 0.897331]\n",
      "epoch:19 step:18002 [D loss: 0.784565, acc.: 46.09%] [G loss: 1.034113]\n",
      "epoch:19 step:18003 [D loss: 0.727134, acc.: 57.81%] [G loss: 1.067735]\n",
      "epoch:19 step:18004 [D loss: 0.559271, acc.: 71.09%] [G loss: 1.070371]\n",
      "epoch:19 step:18005 [D loss: 0.691348, acc.: 63.28%] [G loss: 1.234910]\n",
      "epoch:19 step:18006 [D loss: 0.827168, acc.: 42.97%] [G loss: 0.913870]\n",
      "epoch:19 step:18007 [D loss: 0.675597, acc.: 58.59%] [G loss: 0.934962]\n",
      "epoch:19 step:18008 [D loss: 0.752557, acc.: 44.53%] [G loss: 0.974242]\n",
      "epoch:19 step:18009 [D loss: 0.645254, acc.: 61.72%] [G loss: 0.985902]\n",
      "epoch:19 step:18010 [D loss: 0.565469, acc.: 71.88%] [G loss: 1.019102]\n",
      "epoch:19 step:18011 [D loss: 0.684493, acc.: 55.47%] [G loss: 0.955895]\n",
      "epoch:19 step:18012 [D loss: 0.525987, acc.: 82.03%] [G loss: 1.190850]\n",
      "epoch:19 step:18013 [D loss: 0.594100, acc.: 67.97%] [G loss: 0.980699]\n",
      "epoch:19 step:18014 [D loss: 0.434752, acc.: 82.81%] [G loss: 1.127627]\n",
      "epoch:19 step:18015 [D loss: 0.664032, acc.: 56.25%] [G loss: 1.139228]\n",
      "epoch:19 step:18016 [D loss: 0.448236, acc.: 82.03%] [G loss: 1.135678]\n",
      "epoch:19 step:18017 [D loss: 0.679466, acc.: 59.38%] [G loss: 1.165654]\n",
      "epoch:19 step:18018 [D loss: 0.336661, acc.: 94.53%] [G loss: 1.234432]\n",
      "epoch:19 step:18019 [D loss: 0.566338, acc.: 74.22%] [G loss: 1.153876]\n",
      "epoch:19 step:18020 [D loss: 1.000507, acc.: 26.56%] [G loss: 0.929249]\n",
      "epoch:19 step:18021 [D loss: 0.729156, acc.: 55.47%] [G loss: 0.969289]\n",
      "epoch:19 step:18022 [D loss: 0.720858, acc.: 51.56%] [G loss: 1.217860]\n",
      "epoch:19 step:18023 [D loss: 0.367131, acc.: 85.94%] [G loss: 1.107344]\n",
      "epoch:19 step:18024 [D loss: 0.376325, acc.: 82.81%] [G loss: 1.351320]\n",
      "epoch:19 step:18025 [D loss: 0.375028, acc.: 92.97%] [G loss: 1.560728]\n",
      "epoch:19 step:18026 [D loss: 0.291713, acc.: 94.53%] [G loss: 1.458946]\n",
      "epoch:19 step:18027 [D loss: 0.861125, acc.: 44.53%] [G loss: 1.126899]\n",
      "epoch:19 step:18028 [D loss: 0.702523, acc.: 57.03%] [G loss: 1.057853]\n",
      "epoch:19 step:18029 [D loss: 0.629689, acc.: 62.50%] [G loss: 1.081654]\n",
      "epoch:19 step:18030 [D loss: 0.666788, acc.: 57.03%] [G loss: 1.103334]\n",
      "epoch:19 step:18031 [D loss: 0.584016, acc.: 71.09%] [G loss: 1.001637]\n",
      "epoch:19 step:18032 [D loss: 0.778125, acc.: 50.78%] [G loss: 0.740820]\n",
      "epoch:19 step:18033 [D loss: 0.374983, acc.: 79.69%] [G loss: 0.894673]\n",
      "epoch:19 step:18034 [D loss: 0.294381, acc.: 95.31%] [G loss: 1.514954]\n",
      "epoch:19 step:18035 [D loss: 0.275459, acc.: 97.66%] [G loss: 1.828433]\n",
      "epoch:19 step:18036 [D loss: 0.785586, acc.: 53.12%] [G loss: 1.250447]\n",
      "epoch:19 step:18037 [D loss: 0.912602, acc.: 33.59%] [G loss: 0.677161]\n",
      "epoch:19 step:18038 [D loss: 0.529125, acc.: 76.56%] [G loss: 1.224937]\n",
      "epoch:19 step:18039 [D loss: 0.794802, acc.: 47.66%] [G loss: 0.942446]\n",
      "epoch:19 step:18040 [D loss: 0.605931, acc.: 70.31%] [G loss: 1.271911]\n",
      "epoch:19 step:18041 [D loss: 0.738765, acc.: 53.12%] [G loss: 0.898944]\n",
      "epoch:19 step:18042 [D loss: 0.865429, acc.: 40.62%] [G loss: 0.691372]\n",
      "epoch:19 step:18043 [D loss: 0.783968, acc.: 43.75%] [G loss: 1.354890]\n",
      "epoch:19 step:18044 [D loss: 0.912275, acc.: 28.12%] [G loss: 0.925075]\n",
      "epoch:19 step:18045 [D loss: 0.888022, acc.: 35.94%] [G loss: 1.084526]\n",
      "epoch:19 step:18046 [D loss: 0.714996, acc.: 56.25%] [G loss: 1.108348]\n",
      "epoch:19 step:18047 [D loss: 0.591298, acc.: 70.31%] [G loss: 0.987656]\n",
      "epoch:19 step:18048 [D loss: 0.515764, acc.: 78.12%] [G loss: 1.444857]\n",
      "epoch:19 step:18049 [D loss: 0.384016, acc.: 91.41%] [G loss: 1.334236]\n",
      "epoch:19 step:18050 [D loss: 0.455901, acc.: 82.03%] [G loss: 1.446975]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18051 [D loss: 0.432151, acc.: 85.16%] [G loss: 1.128231]\n",
      "epoch:19 step:18052 [D loss: 0.688678, acc.: 55.47%] [G loss: 1.183558]\n",
      "epoch:19 step:18053 [D loss: 0.538929, acc.: 78.12%] [G loss: 1.116500]\n",
      "epoch:19 step:18054 [D loss: 0.633747, acc.: 66.41%] [G loss: 0.877439]\n",
      "epoch:19 step:18055 [D loss: 0.670355, acc.: 60.94%] [G loss: 1.051947]\n",
      "epoch:19 step:18056 [D loss: 0.525425, acc.: 78.12%] [G loss: 1.199338]\n",
      "epoch:19 step:18057 [D loss: 0.612291, acc.: 66.41%] [G loss: 1.178933]\n",
      "epoch:19 step:18058 [D loss: 0.753759, acc.: 46.09%] [G loss: 1.060082]\n",
      "epoch:19 step:18059 [D loss: 0.768961, acc.: 49.22%] [G loss: 0.981754]\n",
      "epoch:19 step:18060 [D loss: 0.663334, acc.: 62.50%] [G loss: 0.816148]\n",
      "epoch:19 step:18061 [D loss: 0.686179, acc.: 58.59%] [G loss: 0.931268]\n",
      "epoch:19 step:18062 [D loss: 0.689120, acc.: 60.16%] [G loss: 0.810789]\n",
      "epoch:19 step:18063 [D loss: 0.697894, acc.: 54.69%] [G loss: 1.017264]\n",
      "epoch:19 step:18064 [D loss: 0.710073, acc.: 50.78%] [G loss: 1.063606]\n",
      "epoch:19 step:18065 [D loss: 0.616348, acc.: 72.66%] [G loss: 0.975058]\n",
      "epoch:19 step:18066 [D loss: 0.576005, acc.: 71.09%] [G loss: 1.083140]\n",
      "epoch:19 step:18067 [D loss: 0.557113, acc.: 73.44%] [G loss: 0.938045]\n",
      "epoch:19 step:18068 [D loss: 0.651903, acc.: 60.16%] [G loss: 1.009472]\n",
      "epoch:19 step:18069 [D loss: 0.713726, acc.: 48.44%] [G loss: 1.068951]\n",
      "epoch:19 step:18070 [D loss: 0.620248, acc.: 67.97%] [G loss: 0.970851]\n",
      "epoch:19 step:18071 [D loss: 0.665714, acc.: 60.94%] [G loss: 1.031832]\n",
      "epoch:19 step:18072 [D loss: 0.648737, acc.: 59.38%] [G loss: 0.969849]\n",
      "epoch:19 step:18073 [D loss: 0.627877, acc.: 69.53%] [G loss: 1.115134]\n",
      "epoch:19 step:18074 [D loss: 0.669198, acc.: 60.94%] [G loss: 0.971472]\n",
      "epoch:19 step:18075 [D loss: 0.474926, acc.: 81.25%] [G loss: 1.203645]\n",
      "epoch:19 step:18076 [D loss: 0.690350, acc.: 57.81%] [G loss: 0.997868]\n",
      "epoch:19 step:18077 [D loss: 0.597094, acc.: 68.75%] [G loss: 1.016623]\n",
      "epoch:19 step:18078 [D loss: 0.593718, acc.: 71.88%] [G loss: 1.095436]\n",
      "epoch:19 step:18079 [D loss: 0.696724, acc.: 51.56%] [G loss: 0.765998]\n",
      "epoch:19 step:18080 [D loss: 0.622271, acc.: 64.06%] [G loss: 0.914450]\n",
      "epoch:19 step:18081 [D loss: 0.624422, acc.: 62.50%] [G loss: 0.807492]\n",
      "epoch:19 step:18082 [D loss: 0.417265, acc.: 83.59%] [G loss: 1.286223]\n",
      "epoch:19 step:18083 [D loss: 0.512400, acc.: 76.56%] [G loss: 1.132398]\n",
      "epoch:19 step:18084 [D loss: 0.604793, acc.: 67.97%] [G loss: 1.135383]\n",
      "epoch:19 step:18085 [D loss: 0.729112, acc.: 52.34%] [G loss: 1.199446]\n",
      "epoch:19 step:18086 [D loss: 0.629158, acc.: 64.06%] [G loss: 0.957312]\n",
      "epoch:19 step:18087 [D loss: 0.450837, acc.: 83.59%] [G loss: 1.163694]\n",
      "epoch:19 step:18088 [D loss: 0.558623, acc.: 69.53%] [G loss: 1.003834]\n",
      "epoch:19 step:18089 [D loss: 0.503374, acc.: 78.12%] [G loss: 0.942464]\n",
      "epoch:19 step:18090 [D loss: 0.570427, acc.: 73.44%] [G loss: 1.097223]\n",
      "epoch:19 step:18091 [D loss: 0.729419, acc.: 55.47%] [G loss: 1.064219]\n",
      "epoch:19 step:18092 [D loss: 0.532524, acc.: 73.44%] [G loss: 1.087927]\n",
      "epoch:19 step:18093 [D loss: 0.742659, acc.: 52.34%] [G loss: 0.912579]\n",
      "epoch:19 step:18094 [D loss: 0.525826, acc.: 78.12%] [G loss: 1.299819]\n",
      "epoch:19 step:18095 [D loss: 0.651513, acc.: 63.28%] [G loss: 0.964635]\n",
      "epoch:19 step:18096 [D loss: 0.631532, acc.: 60.16%] [G loss: 1.015760]\n",
      "epoch:19 step:18097 [D loss: 0.667305, acc.: 56.25%] [G loss: 1.063024]\n",
      "epoch:19 step:18098 [D loss: 0.952669, acc.: 29.69%] [G loss: 0.696291]\n",
      "epoch:19 step:18099 [D loss: 0.720030, acc.: 47.66%] [G loss: 1.189877]\n",
      "epoch:19 step:18100 [D loss: 0.667708, acc.: 56.25%] [G loss: 1.028015]\n",
      "epoch:19 step:18101 [D loss: 0.414523, acc.: 92.97%] [G loss: 1.414604]\n",
      "epoch:19 step:18102 [D loss: 0.516675, acc.: 78.91%] [G loss: 0.923604]\n",
      "epoch:19 step:18103 [D loss: 0.483149, acc.: 82.03%] [G loss: 1.178516]\n",
      "epoch:19 step:18104 [D loss: 0.661756, acc.: 61.72%] [G loss: 1.189330]\n",
      "epoch:19 step:18105 [D loss: 0.560679, acc.: 71.88%] [G loss: 0.892409]\n",
      "epoch:19 step:18106 [D loss: 0.477741, acc.: 81.25%] [G loss: 1.162853]\n",
      "epoch:19 step:18107 [D loss: 0.612377, acc.: 63.28%] [G loss: 1.040317]\n",
      "epoch:19 step:18108 [D loss: 0.632211, acc.: 62.50%] [G loss: 1.141745]\n",
      "epoch:19 step:18109 [D loss: 0.569080, acc.: 76.56%] [G loss: 1.073187]\n",
      "epoch:19 step:18110 [D loss: 0.470177, acc.: 85.16%] [G loss: 1.046731]\n",
      "epoch:19 step:18111 [D loss: 0.640987, acc.: 64.84%] [G loss: 1.134045]\n",
      "epoch:19 step:18112 [D loss: 0.740340, acc.: 51.56%] [G loss: 0.881186]\n",
      "epoch:19 step:18113 [D loss: 0.603514, acc.: 63.28%] [G loss: 1.168840]\n",
      "epoch:19 step:18114 [D loss: 0.681633, acc.: 57.03%] [G loss: 1.063054]\n",
      "epoch:19 step:18115 [D loss: 0.543835, acc.: 71.88%] [G loss: 1.057809]\n",
      "epoch:19 step:18116 [D loss: 0.527944, acc.: 79.69%] [G loss: 1.021423]\n",
      "epoch:19 step:18117 [D loss: 0.555339, acc.: 70.31%] [G loss: 1.099380]\n",
      "epoch:19 step:18118 [D loss: 0.509942, acc.: 81.25%] [G loss: 1.177207]\n",
      "epoch:19 step:18119 [D loss: 0.630377, acc.: 63.28%] [G loss: 1.083704]\n",
      "epoch:19 step:18120 [D loss: 0.650047, acc.: 64.06%] [G loss: 1.031303]\n",
      "epoch:19 step:18121 [D loss: 0.599761, acc.: 60.16%] [G loss: 1.101073]\n",
      "epoch:19 step:18122 [D loss: 0.676427, acc.: 59.38%] [G loss: 0.998222]\n",
      "epoch:19 step:18123 [D loss: 0.488804, acc.: 83.59%] [G loss: 0.845132]\n",
      "epoch:19 step:18124 [D loss: 0.522247, acc.: 78.91%] [G loss: 0.986360]\n",
      "epoch:19 step:18125 [D loss: 0.551655, acc.: 72.66%] [G loss: 1.065939]\n",
      "epoch:19 step:18126 [D loss: 0.609725, acc.: 64.84%] [G loss: 0.965253]\n",
      "epoch:19 step:18127 [D loss: 0.766655, acc.: 50.78%] [G loss: 0.734774]\n",
      "epoch:19 step:18128 [D loss: 0.772515, acc.: 45.31%] [G loss: 0.816882]\n",
      "epoch:19 step:18129 [D loss: 0.552962, acc.: 72.66%] [G loss: 1.214409]\n",
      "epoch:19 step:18130 [D loss: 0.420811, acc.: 87.50%] [G loss: 1.246048]\n",
      "epoch:19 step:18131 [D loss: 0.523653, acc.: 77.34%] [G loss: 1.033033]\n",
      "epoch:19 step:18132 [D loss: 0.555454, acc.: 73.44%] [G loss: 1.033786]\n",
      "epoch:19 step:18133 [D loss: 0.711313, acc.: 53.91%] [G loss: 0.789396]\n",
      "epoch:19 step:18134 [D loss: 0.740648, acc.: 50.78%] [G loss: 0.770785]\n",
      "epoch:19 step:18135 [D loss: 0.669190, acc.: 59.38%] [G loss: 1.045941]\n",
      "epoch:19 step:18136 [D loss: 0.672335, acc.: 64.06%] [G loss: 1.036251]\n",
      "epoch:19 step:18137 [D loss: 0.708460, acc.: 54.69%] [G loss: 0.861199]\n",
      "epoch:19 step:18138 [D loss: 0.574553, acc.: 71.88%] [G loss: 1.078173]\n",
      "epoch:19 step:18139 [D loss: 0.651104, acc.: 61.72%] [G loss: 0.926880]\n",
      "epoch:19 step:18140 [D loss: 0.664848, acc.: 56.25%] [G loss: 0.961612]\n",
      "epoch:19 step:18141 [D loss: 0.615155, acc.: 68.75%] [G loss: 0.983364]\n",
      "epoch:19 step:18142 [D loss: 0.670532, acc.: 59.38%] [G loss: 1.056967]\n",
      "epoch:19 step:18143 [D loss: 0.749886, acc.: 48.44%] [G loss: 0.898057]\n",
      "epoch:19 step:18144 [D loss: 0.632516, acc.: 60.16%] [G loss: 1.064655]\n",
      "epoch:19 step:18145 [D loss: 0.510300, acc.: 73.44%] [G loss: 1.073756]\n",
      "epoch:19 step:18146 [D loss: 0.413261, acc.: 85.94%] [G loss: 1.253370]\n",
      "epoch:19 step:18147 [D loss: 0.517210, acc.: 79.69%] [G loss: 1.049337]\n",
      "epoch:19 step:18148 [D loss: 0.392044, acc.: 87.50%] [G loss: 1.434552]\n",
      "epoch:19 step:18149 [D loss: 0.348231, acc.: 93.75%] [G loss: 1.593812]\n",
      "epoch:19 step:18150 [D loss: 0.352781, acc.: 89.84%] [G loss: 1.282357]\n",
      "epoch:19 step:18151 [D loss: 0.689665, acc.: 59.38%] [G loss: 1.299083]\n",
      "epoch:19 step:18152 [D loss: 0.976170, acc.: 29.69%] [G loss: 0.784768]\n",
      "epoch:19 step:18153 [D loss: 0.919316, acc.: 32.03%] [G loss: 0.925405]\n",
      "epoch:19 step:18154 [D loss: 0.784461, acc.: 49.22%] [G loss: 0.799013]\n",
      "epoch:19 step:18155 [D loss: 0.586235, acc.: 73.44%] [G loss: 1.187995]\n",
      "epoch:19 step:18156 [D loss: 0.570347, acc.: 71.09%] [G loss: 1.102088]\n",
      "epoch:19 step:18157 [D loss: 0.407005, acc.: 86.72%] [G loss: 1.235559]\n",
      "epoch:19 step:18158 [D loss: 0.683928, acc.: 60.94%] [G loss: 0.881945]\n",
      "epoch:19 step:18159 [D loss: 0.654105, acc.: 61.72%] [G loss: 0.975082]\n",
      "epoch:19 step:18160 [D loss: 0.529774, acc.: 78.91%] [G loss: 1.079244]\n",
      "epoch:19 step:18161 [D loss: 0.483507, acc.: 76.56%] [G loss: 0.888177]\n",
      "epoch:19 step:18162 [D loss: 0.567814, acc.: 72.66%] [G loss: 1.036963]\n",
      "epoch:19 step:18163 [D loss: 0.589131, acc.: 64.84%] [G loss: 1.295119]\n",
      "epoch:19 step:18164 [D loss: 0.711664, acc.: 50.00%] [G loss: 0.950142]\n",
      "epoch:19 step:18165 [D loss: 0.718671, acc.: 60.16%] [G loss: 1.123797]\n",
      "epoch:19 step:18166 [D loss: 0.753362, acc.: 51.56%] [G loss: 0.989002]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18167 [D loss: 0.829124, acc.: 37.50%] [G loss: 0.869271]\n",
      "epoch:19 step:18168 [D loss: 0.814843, acc.: 46.88%] [G loss: 0.865736]\n",
      "epoch:19 step:18169 [D loss: 0.580094, acc.: 67.97%] [G loss: 1.069482]\n",
      "epoch:19 step:18170 [D loss: 0.438441, acc.: 83.59%] [G loss: 1.240991]\n",
      "epoch:19 step:18171 [D loss: 0.733196, acc.: 55.47%] [G loss: 1.106346]\n",
      "epoch:19 step:18172 [D loss: 0.712788, acc.: 54.69%] [G loss: 1.009499]\n",
      "epoch:19 step:18173 [D loss: 0.562039, acc.: 73.44%] [G loss: 1.016115]\n",
      "epoch:19 step:18174 [D loss: 0.478180, acc.: 82.03%] [G loss: 1.190966]\n",
      "epoch:19 step:18175 [D loss: 0.578877, acc.: 67.97%] [G loss: 1.048238]\n",
      "epoch:19 step:18176 [D loss: 0.772000, acc.: 50.78%] [G loss: 0.892293]\n",
      "epoch:19 step:18177 [D loss: 0.730328, acc.: 56.25%] [G loss: 0.935735]\n",
      "epoch:19 step:18178 [D loss: 0.795547, acc.: 41.41%] [G loss: 0.817232]\n",
      "epoch:19 step:18179 [D loss: 0.825972, acc.: 40.62%] [G loss: 0.931163]\n",
      "epoch:19 step:18180 [D loss: 0.641700, acc.: 56.25%] [G loss: 0.923549]\n",
      "epoch:19 step:18181 [D loss: 0.457292, acc.: 85.16%] [G loss: 1.058388]\n",
      "epoch:19 step:18182 [D loss: 0.617344, acc.: 64.84%] [G loss: 1.127836]\n",
      "epoch:19 step:18183 [D loss: 0.602345, acc.: 64.84%] [G loss: 1.136198]\n",
      "epoch:19 step:18184 [D loss: 0.710358, acc.: 57.81%] [G loss: 0.927666]\n",
      "epoch:19 step:18185 [D loss: 0.631893, acc.: 64.06%] [G loss: 1.038596]\n",
      "epoch:19 step:18186 [D loss: 0.658677, acc.: 60.94%] [G loss: 0.969131]\n",
      "epoch:19 step:18187 [D loss: 0.597331, acc.: 70.31%] [G loss: 1.081233]\n",
      "epoch:19 step:18188 [D loss: 0.595292, acc.: 68.75%] [G loss: 0.992854]\n",
      "epoch:19 step:18189 [D loss: 0.612567, acc.: 68.75%] [G loss: 1.020997]\n",
      "epoch:19 step:18190 [D loss: 0.656463, acc.: 60.16%] [G loss: 1.052857]\n",
      "epoch:19 step:18191 [D loss: 0.570389, acc.: 67.97%] [G loss: 0.815906]\n",
      "epoch:19 step:18192 [D loss: 0.647173, acc.: 64.06%] [G loss: 1.222561]\n",
      "epoch:19 step:18193 [D loss: 0.576916, acc.: 69.53%] [G loss: 1.116781]\n",
      "epoch:19 step:18194 [D loss: 0.594762, acc.: 70.31%] [G loss: 0.900288]\n",
      "epoch:19 step:18195 [D loss: 0.549681, acc.: 74.22%] [G loss: 1.054435]\n",
      "epoch:19 step:18196 [D loss: 0.636211, acc.: 61.72%] [G loss: 1.116149]\n",
      "epoch:19 step:18197 [D loss: 0.566968, acc.: 67.97%] [G loss: 0.996122]\n",
      "epoch:19 step:18198 [D loss: 0.586492, acc.: 73.44%] [G loss: 0.990927]\n",
      "epoch:19 step:18199 [D loss: 0.318316, acc.: 92.19%] [G loss: 1.330282]\n",
      "epoch:19 step:18200 [D loss: 0.306367, acc.: 94.53%] [G loss: 1.346090]\n",
      "##############\n",
      "[2.39361124 1.6124494  5.33903186 4.09639882 2.82169763 5.40979804\n",
      " 4.22164881 4.61931576 4.10051024 3.63685022]\n",
      "##########\n",
      "epoch:19 step:18201 [D loss: 0.353104, acc.: 94.53%] [G loss: 1.406834]\n",
      "epoch:19 step:18202 [D loss: 0.328867, acc.: 94.53%] [G loss: 1.567866]\n",
      "epoch:19 step:18203 [D loss: 0.393847, acc.: 88.28%] [G loss: 1.343452]\n",
      "epoch:19 step:18204 [D loss: 0.458108, acc.: 85.16%] [G loss: 1.368009]\n",
      "epoch:19 step:18205 [D loss: 0.466379, acc.: 81.25%] [G loss: 1.360451]\n",
      "epoch:19 step:18206 [D loss: 0.741046, acc.: 46.09%] [G loss: 0.961057]\n",
      "epoch:19 step:18207 [D loss: 0.543772, acc.: 66.41%] [G loss: 1.035797]\n",
      "epoch:19 step:18208 [D loss: 0.329424, acc.: 94.53%] [G loss: 1.601040]\n",
      "epoch:19 step:18209 [D loss: 0.428278, acc.: 85.16%] [G loss: 1.211129]\n",
      "epoch:19 step:18210 [D loss: 0.628825, acc.: 66.41%] [G loss: 1.097892]\n",
      "epoch:19 step:18211 [D loss: 0.758545, acc.: 53.12%] [G loss: 1.167904]\n",
      "epoch:19 step:18212 [D loss: 0.691734, acc.: 58.59%] [G loss: 0.968609]\n",
      "epoch:19 step:18213 [D loss: 0.833066, acc.: 40.62%] [G loss: 0.877256]\n",
      "epoch:19 step:18214 [D loss: 0.919671, acc.: 34.38%] [G loss: 1.020446]\n",
      "epoch:19 step:18215 [D loss: 0.897391, acc.: 35.16%] [G loss: 1.065800]\n",
      "epoch:19 step:18216 [D loss: 0.861023, acc.: 39.06%] [G loss: 1.041689]\n",
      "epoch:19 step:18217 [D loss: 0.646614, acc.: 59.38%] [G loss: 1.301575]\n",
      "epoch:19 step:18218 [D loss: 0.871301, acc.: 40.62%] [G loss: 1.178260]\n",
      "epoch:19 step:18219 [D loss: 0.899365, acc.: 34.38%] [G loss: 0.883933]\n",
      "epoch:19 step:18220 [D loss: 0.800761, acc.: 43.75%] [G loss: 1.154119]\n",
      "epoch:19 step:18221 [D loss: 0.794012, acc.: 49.22%] [G loss: 0.990941]\n",
      "epoch:19 step:18222 [D loss: 0.659016, acc.: 62.50%] [G loss: 0.997580]\n",
      "epoch:19 step:18223 [D loss: 0.614923, acc.: 66.41%] [G loss: 1.013981]\n",
      "epoch:19 step:18224 [D loss: 0.643438, acc.: 62.50%] [G loss: 1.021961]\n",
      "epoch:19 step:18225 [D loss: 0.628139, acc.: 61.72%] [G loss: 1.205379]\n",
      "epoch:19 step:18226 [D loss: 0.713806, acc.: 50.78%] [G loss: 1.124080]\n",
      "epoch:19 step:18227 [D loss: 0.698310, acc.: 54.69%] [G loss: 0.985942]\n",
      "epoch:19 step:18228 [D loss: 0.719305, acc.: 52.34%] [G loss: 1.034078]\n",
      "epoch:19 step:18229 [D loss: 0.587501, acc.: 70.31%] [G loss: 1.088722]\n",
      "epoch:19 step:18230 [D loss: 0.760576, acc.: 52.34%] [G loss: 0.928129]\n",
      "epoch:19 step:18231 [D loss: 0.623014, acc.: 70.31%] [G loss: 0.994178]\n",
      "epoch:19 step:18232 [D loss: 0.697904, acc.: 58.59%] [G loss: 1.129385]\n",
      "epoch:19 step:18233 [D loss: 0.609924, acc.: 65.62%] [G loss: 1.215040]\n",
      "epoch:19 step:18234 [D loss: 0.628266, acc.: 63.28%] [G loss: 0.929282]\n",
      "epoch:19 step:18235 [D loss: 0.524844, acc.: 79.69%] [G loss: 1.231419]\n",
      "epoch:19 step:18236 [D loss: 0.512682, acc.: 75.00%] [G loss: 1.245755]\n",
      "epoch:19 step:18237 [D loss: 0.590152, acc.: 71.88%] [G loss: 1.108374]\n",
      "epoch:19 step:18238 [D loss: 0.578399, acc.: 70.31%] [G loss: 1.128845]\n",
      "epoch:19 step:18239 [D loss: 0.484143, acc.: 82.03%] [G loss: 1.146548]\n",
      "epoch:19 step:18240 [D loss: 0.811316, acc.: 48.44%] [G loss: 1.004933]\n",
      "epoch:19 step:18241 [D loss: 0.722481, acc.: 55.47%] [G loss: 1.006426]\n",
      "epoch:19 step:18242 [D loss: 0.780229, acc.: 50.00%] [G loss: 0.938623]\n",
      "epoch:19 step:18243 [D loss: 0.679504, acc.: 56.25%] [G loss: 0.970079]\n",
      "epoch:19 step:18244 [D loss: 0.775340, acc.: 46.88%] [G loss: 0.970272]\n",
      "epoch:19 step:18245 [D loss: 0.706373, acc.: 57.03%] [G loss: 0.912519]\n",
      "epoch:19 step:18246 [D loss: 0.562202, acc.: 67.19%] [G loss: 0.977167]\n",
      "epoch:19 step:18247 [D loss: 0.762102, acc.: 53.12%] [G loss: 1.010172]\n",
      "epoch:19 step:18248 [D loss: 0.754664, acc.: 49.22%] [G loss: 1.132585]\n",
      "epoch:19 step:18249 [D loss: 0.758467, acc.: 50.78%] [G loss: 1.147443]\n",
      "epoch:19 step:18250 [D loss: 0.740289, acc.: 47.66%] [G loss: 1.019822]\n",
      "epoch:19 step:18251 [D loss: 0.560624, acc.: 73.44%] [G loss: 1.047675]\n",
      "epoch:19 step:18252 [D loss: 0.534629, acc.: 75.78%] [G loss: 1.148489]\n",
      "epoch:19 step:18253 [D loss: 0.577457, acc.: 70.31%] [G loss: 1.058888]\n",
      "epoch:19 step:18254 [D loss: 0.631191, acc.: 62.50%] [G loss: 1.110559]\n",
      "epoch:19 step:18255 [D loss: 0.606995, acc.: 70.31%] [G loss: 1.013340]\n",
      "epoch:19 step:18256 [D loss: 0.547699, acc.: 75.00%] [G loss: 1.177838]\n",
      "epoch:19 step:18257 [D loss: 0.592154, acc.: 67.97%] [G loss: 1.247705]\n",
      "epoch:19 step:18258 [D loss: 0.575504, acc.: 68.75%] [G loss: 1.209558]\n",
      "epoch:19 step:18259 [D loss: 0.615267, acc.: 66.41%] [G loss: 0.888857]\n",
      "epoch:19 step:18260 [D loss: 0.551481, acc.: 75.00%] [G loss: 1.215575]\n",
      "epoch:19 step:18261 [D loss: 0.900903, acc.: 37.50%] [G loss: 0.862582]\n",
      "epoch:19 step:18262 [D loss: 0.884735, acc.: 31.25%] [G loss: 1.022259]\n",
      "epoch:19 step:18263 [D loss: 0.756029, acc.: 45.31%] [G loss: 1.033540]\n",
      "epoch:19 step:18264 [D loss: 0.824197, acc.: 38.28%] [G loss: 1.012532]\n",
      "epoch:19 step:18265 [D loss: 0.631790, acc.: 63.28%] [G loss: 1.206893]\n",
      "epoch:19 step:18266 [D loss: 0.639563, acc.: 57.81%] [G loss: 1.307609]\n",
      "epoch:19 step:18267 [D loss: 0.696844, acc.: 55.47%] [G loss: 1.158917]\n",
      "epoch:19 step:18268 [D loss: 0.645138, acc.: 59.38%] [G loss: 0.853112]\n",
      "epoch:19 step:18269 [D loss: 0.652177, acc.: 63.28%] [G loss: 1.026551]\n",
      "epoch:19 step:18270 [D loss: 0.597795, acc.: 67.97%] [G loss: 0.997018]\n",
      "epoch:19 step:18271 [D loss: 0.547278, acc.: 71.88%] [G loss: 1.198464]\n",
      "epoch:19 step:18272 [D loss: 0.573750, acc.: 71.09%] [G loss: 1.162049]\n",
      "epoch:19 step:18273 [D loss: 0.477004, acc.: 82.03%] [G loss: 1.066027]\n",
      "epoch:19 step:18274 [D loss: 0.359466, acc.: 86.72%] [G loss: 1.115360]\n",
      "epoch:19 step:18275 [D loss: 0.562966, acc.: 71.88%] [G loss: 1.177940]\n",
      "epoch:19 step:18276 [D loss: 0.579529, acc.: 71.09%] [G loss: 1.299245]\n",
      "epoch:19 step:18277 [D loss: 0.421255, acc.: 85.16%] [G loss: 1.305667]\n",
      "epoch:19 step:18278 [D loss: 0.521955, acc.: 75.00%] [G loss: 1.379076]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18279 [D loss: 0.656815, acc.: 60.16%] [G loss: 1.191775]\n",
      "epoch:19 step:18280 [D loss: 0.659080, acc.: 63.28%] [G loss: 1.153278]\n",
      "epoch:19 step:18281 [D loss: 0.609811, acc.: 65.62%] [G loss: 0.942568]\n",
      "epoch:19 step:18282 [D loss: 0.534474, acc.: 76.56%] [G loss: 0.914405]\n",
      "epoch:19 step:18283 [D loss: 0.810916, acc.: 43.75%] [G loss: 0.811695]\n",
      "epoch:19 step:18284 [D loss: 0.462604, acc.: 82.03%] [G loss: 1.176080]\n",
      "epoch:19 step:18285 [D loss: 0.676774, acc.: 60.16%] [G loss: 1.115445]\n",
      "epoch:19 step:18286 [D loss: 0.638732, acc.: 68.75%] [G loss: 0.986710]\n",
      "epoch:19 step:18287 [D loss: 0.484756, acc.: 82.81%] [G loss: 1.306074]\n",
      "epoch:19 step:18288 [D loss: 0.531285, acc.: 75.00%] [G loss: 1.090205]\n",
      "epoch:19 step:18289 [D loss: 0.688863, acc.: 60.16%] [G loss: 0.985312]\n",
      "epoch:19 step:18290 [D loss: 0.638457, acc.: 63.28%] [G loss: 1.146290]\n",
      "epoch:19 step:18291 [D loss: 0.700306, acc.: 57.03%] [G loss: 0.901499]\n",
      "epoch:19 step:18292 [D loss: 0.586192, acc.: 69.53%] [G loss: 0.972999]\n",
      "epoch:19 step:18293 [D loss: 0.497525, acc.: 80.47%] [G loss: 1.217235]\n",
      "epoch:19 step:18294 [D loss: 0.621208, acc.: 66.41%] [G loss: 1.202235]\n",
      "epoch:19 step:18295 [D loss: 0.620504, acc.: 65.62%] [G loss: 0.892193]\n",
      "epoch:19 step:18296 [D loss: 0.724644, acc.: 46.09%] [G loss: 0.866781]\n",
      "epoch:19 step:18297 [D loss: 0.645413, acc.: 57.81%] [G loss: 0.942236]\n",
      "epoch:19 step:18298 [D loss: 0.602623, acc.: 64.84%] [G loss: 1.148265]\n",
      "epoch:19 step:18299 [D loss: 0.582915, acc.: 69.53%] [G loss: 1.181893]\n",
      "epoch:19 step:18300 [D loss: 0.538760, acc.: 75.78%] [G loss: 1.006010]\n",
      "epoch:19 step:18301 [D loss: 0.489580, acc.: 81.25%] [G loss: 1.253540]\n",
      "epoch:19 step:18302 [D loss: 0.381754, acc.: 86.72%] [G loss: 0.996248]\n",
      "epoch:19 step:18303 [D loss: 0.801240, acc.: 49.22%] [G loss: 1.139025]\n",
      "epoch:19 step:18304 [D loss: 0.878664, acc.: 44.53%] [G loss: 0.886238]\n",
      "epoch:19 step:18305 [D loss: 0.804318, acc.: 41.41%] [G loss: 0.908479]\n",
      "epoch:19 step:18306 [D loss: 0.453643, acc.: 73.44%] [G loss: 1.253679]\n",
      "epoch:19 step:18307 [D loss: 0.373621, acc.: 89.06%] [G loss: 1.260639]\n",
      "epoch:19 step:18308 [D loss: 0.449278, acc.: 82.03%] [G loss: 1.089807]\n",
      "epoch:19 step:18309 [D loss: 0.586544, acc.: 67.19%] [G loss: 1.061476]\n",
      "epoch:19 step:18310 [D loss: 0.444371, acc.: 85.94%] [G loss: 1.259288]\n",
      "epoch:19 step:18311 [D loss: 0.261394, acc.: 94.53%] [G loss: 1.343511]\n",
      "epoch:19 step:18312 [D loss: 0.901997, acc.: 41.41%] [G loss: 0.881046]\n",
      "epoch:19 step:18313 [D loss: 0.964800, acc.: 34.38%] [G loss: 0.979522]\n",
      "epoch:19 step:18314 [D loss: 0.691892, acc.: 57.03%] [G loss: 1.009506]\n",
      "epoch:19 step:18315 [D loss: 0.617883, acc.: 66.41%] [G loss: 1.192021]\n",
      "epoch:19 step:18316 [D loss: 0.479868, acc.: 80.47%] [G loss: 1.262860]\n",
      "epoch:19 step:18317 [D loss: 0.560949, acc.: 73.44%] [G loss: 1.244235]\n",
      "epoch:19 step:18318 [D loss: 0.589984, acc.: 67.19%] [G loss: 1.102278]\n",
      "epoch:19 step:18319 [D loss: 0.558671, acc.: 71.88%] [G loss: 1.229343]\n",
      "epoch:19 step:18320 [D loss: 0.682773, acc.: 56.25%] [G loss: 1.054413]\n",
      "epoch:19 step:18321 [D loss: 0.652930, acc.: 63.28%] [G loss: 0.915688]\n",
      "epoch:19 step:18322 [D loss: 0.515346, acc.: 79.69%] [G loss: 1.119460]\n",
      "epoch:19 step:18323 [D loss: 0.552268, acc.: 73.44%] [G loss: 1.034956]\n",
      "epoch:19 step:18324 [D loss: 0.579835, acc.: 71.09%] [G loss: 1.073082]\n",
      "epoch:19 step:18325 [D loss: 0.541233, acc.: 78.12%] [G loss: 0.908281]\n",
      "epoch:19 step:18326 [D loss: 0.400020, acc.: 91.41%] [G loss: 1.195925]\n",
      "epoch:19 step:18327 [D loss: 0.707276, acc.: 57.03%] [G loss: 1.003608]\n",
      "epoch:19 step:18328 [D loss: 0.689918, acc.: 60.94%] [G loss: 1.080815]\n",
      "epoch:19 step:18329 [D loss: 0.607399, acc.: 67.97%] [G loss: 1.280283]\n",
      "epoch:19 step:18330 [D loss: 0.729052, acc.: 53.12%] [G loss: 0.985244]\n",
      "epoch:19 step:18331 [D loss: 0.606498, acc.: 65.62%] [G loss: 1.098716]\n",
      "epoch:19 step:18332 [D loss: 0.640311, acc.: 66.41%] [G loss: 0.903413]\n",
      "epoch:19 step:18333 [D loss: 0.653962, acc.: 60.94%] [G loss: 1.049255]\n",
      "epoch:19 step:18334 [D loss: 0.630706, acc.: 62.50%] [G loss: 0.865388]\n",
      "epoch:19 step:18335 [D loss: 0.614101, acc.: 68.75%] [G loss: 0.939408]\n",
      "epoch:19 step:18336 [D loss: 0.484888, acc.: 81.25%] [G loss: 1.249715]\n",
      "epoch:19 step:18337 [D loss: 0.453140, acc.: 85.16%] [G loss: 1.197673]\n",
      "epoch:19 step:18338 [D loss: 0.547010, acc.: 75.78%] [G loss: 1.194020]\n",
      "epoch:19 step:18339 [D loss: 0.522919, acc.: 76.56%] [G loss: 1.284470]\n",
      "epoch:19 step:18340 [D loss: 0.395752, acc.: 89.84%] [G loss: 1.267745]\n",
      "epoch:19 step:18341 [D loss: 0.628332, acc.: 65.62%] [G loss: 1.139616]\n",
      "epoch:19 step:18342 [D loss: 0.570365, acc.: 68.75%] [G loss: 1.329452]\n",
      "epoch:19 step:18343 [D loss: 0.647981, acc.: 61.72%] [G loss: 1.165431]\n",
      "epoch:19 step:18344 [D loss: 0.749397, acc.: 48.44%] [G loss: 0.929194]\n",
      "epoch:19 step:18345 [D loss: 0.711305, acc.: 53.91%] [G loss: 0.992717]\n",
      "epoch:19 step:18346 [D loss: 0.714996, acc.: 52.34%] [G loss: 0.808118]\n",
      "epoch:19 step:18347 [D loss: 0.666174, acc.: 59.38%] [G loss: 1.015195]\n",
      "epoch:19 step:18348 [D loss: 0.525342, acc.: 77.34%] [G loss: 1.071556]\n",
      "epoch:19 step:18349 [D loss: 0.440977, acc.: 85.94%] [G loss: 1.071880]\n",
      "epoch:19 step:18350 [D loss: 0.484644, acc.: 75.00%] [G loss: 0.959190]\n",
      "epoch:19 step:18351 [D loss: 0.601451, acc.: 68.75%] [G loss: 1.118022]\n",
      "epoch:19 step:18352 [D loss: 0.400673, acc.: 87.50%] [G loss: 1.285542]\n",
      "epoch:19 step:18353 [D loss: 0.469768, acc.: 82.03%] [G loss: 1.241985]\n",
      "epoch:19 step:18354 [D loss: 0.370910, acc.: 91.41%] [G loss: 1.443138]\n",
      "epoch:19 step:18355 [D loss: 0.458510, acc.: 87.50%] [G loss: 1.431088]\n",
      "epoch:19 step:18356 [D loss: 0.600493, acc.: 64.84%] [G loss: 1.049479]\n",
      "epoch:19 step:18357 [D loss: 0.348778, acc.: 91.41%] [G loss: 1.438520]\n",
      "epoch:19 step:18358 [D loss: 0.350127, acc.: 93.75%] [G loss: 1.090329]\n",
      "epoch:19 step:18359 [D loss: 0.428822, acc.: 83.59%] [G loss: 1.133475]\n",
      "epoch:19 step:18360 [D loss: 0.523108, acc.: 72.66%] [G loss: 1.136383]\n",
      "epoch:19 step:18361 [D loss: 0.592745, acc.: 67.19%] [G loss: 1.422848]\n",
      "epoch:19 step:18362 [D loss: 0.896427, acc.: 45.31%] [G loss: 1.140835]\n",
      "epoch:19 step:18363 [D loss: 0.807508, acc.: 53.91%] [G loss: 1.475733]\n",
      "epoch:19 step:18364 [D loss: 0.522733, acc.: 75.00%] [G loss: 1.363228]\n",
      "epoch:19 step:18365 [D loss: 0.782680, acc.: 49.22%] [G loss: 1.085966]\n",
      "epoch:19 step:18366 [D loss: 0.672097, acc.: 58.59%] [G loss: 1.167768]\n",
      "epoch:19 step:18367 [D loss: 0.582598, acc.: 71.88%] [G loss: 1.191952]\n",
      "epoch:19 step:18368 [D loss: 0.622528, acc.: 61.72%] [G loss: 0.968830]\n",
      "epoch:19 step:18369 [D loss: 0.361209, acc.: 88.28%] [G loss: 1.459395]\n",
      "epoch:19 step:18370 [D loss: 0.357488, acc.: 90.62%] [G loss: 1.462907]\n",
      "epoch:19 step:18371 [D loss: 0.689453, acc.: 55.47%] [G loss: 1.025511]\n",
      "epoch:19 step:18372 [D loss: 0.720510, acc.: 51.56%] [G loss: 1.094189]\n",
      "epoch:19 step:18373 [D loss: 0.728659, acc.: 47.66%] [G loss: 1.060967]\n",
      "epoch:19 step:18374 [D loss: 0.641287, acc.: 62.50%] [G loss: 0.871808]\n",
      "epoch:19 step:18375 [D loss: 0.646597, acc.: 64.84%] [G loss: 0.973869]\n",
      "epoch:19 step:18376 [D loss: 0.525047, acc.: 78.12%] [G loss: 1.125407]\n",
      "epoch:19 step:18377 [D loss: 0.510526, acc.: 78.91%] [G loss: 1.220453]\n",
      "epoch:19 step:18378 [D loss: 0.543404, acc.: 71.09%] [G loss: 1.200841]\n",
      "epoch:19 step:18379 [D loss: 0.418316, acc.: 86.72%] [G loss: 1.128306]\n",
      "epoch:19 step:18380 [D loss: 0.590412, acc.: 67.19%] [G loss: 1.057613]\n",
      "epoch:19 step:18381 [D loss: 0.417502, acc.: 87.50%] [G loss: 1.200468]\n",
      "epoch:19 step:18382 [D loss: 0.491235, acc.: 79.69%] [G loss: 1.205764]\n",
      "epoch:19 step:18383 [D loss: 0.938894, acc.: 30.47%] [G loss: 0.710835]\n",
      "epoch:19 step:18384 [D loss: 0.585466, acc.: 71.88%] [G loss: 1.189576]\n",
      "epoch:19 step:18385 [D loss: 0.704449, acc.: 54.69%] [G loss: 0.851092]\n",
      "epoch:19 step:18386 [D loss: 0.748767, acc.: 51.56%] [G loss: 0.908828]\n",
      "epoch:19 step:18387 [D loss: 0.872704, acc.: 40.62%] [G loss: 0.640036]\n",
      "epoch:19 step:18388 [D loss: 0.612591, acc.: 66.41%] [G loss: 1.010184]\n",
      "epoch:19 step:18389 [D loss: 0.683600, acc.: 57.81%] [G loss: 0.975829]\n",
      "epoch:19 step:18390 [D loss: 0.532779, acc.: 74.22%] [G loss: 0.981465]\n",
      "epoch:19 step:18391 [D loss: 0.331592, acc.: 96.09%] [G loss: 1.509482]\n",
      "epoch:19 step:18392 [D loss: 0.524430, acc.: 75.78%] [G loss: 1.221648]\n",
      "epoch:19 step:18393 [D loss: 0.833366, acc.: 33.59%] [G loss: 1.084382]\n",
      "epoch:19 step:18394 [D loss: 0.824468, acc.: 36.72%] [G loss: 1.145093]\n",
      "epoch:19 step:18395 [D loss: 0.663742, acc.: 60.16%] [G loss: 1.013809]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18396 [D loss: 0.719325, acc.: 53.12%] [G loss: 0.998226]\n",
      "epoch:19 step:18397 [D loss: 0.588309, acc.: 68.75%] [G loss: 1.013061]\n",
      "epoch:19 step:18398 [D loss: 0.729271, acc.: 52.34%] [G loss: 1.038242]\n",
      "epoch:19 step:18399 [D loss: 0.759420, acc.: 49.22%] [G loss: 1.149461]\n",
      "epoch:19 step:18400 [D loss: 0.500320, acc.: 78.91%] [G loss: 1.145981]\n",
      "##############\n",
      "[2.79488272 1.75187283 5.58622516 4.300991   3.09388653 5.53678012\n",
      " 4.0984321  4.31532665 4.17186478 3.80354173]\n",
      "##########\n",
      "epoch:19 step:18401 [D loss: 0.398620, acc.: 86.72%] [G loss: 1.336852]\n",
      "epoch:19 step:18402 [D loss: 0.500940, acc.: 75.00%] [G loss: 1.358193]\n",
      "epoch:19 step:18403 [D loss: 0.734212, acc.: 54.69%] [G loss: 1.050653]\n",
      "epoch:19 step:18404 [D loss: 0.611524, acc.: 66.41%] [G loss: 1.003944]\n",
      "epoch:19 step:18405 [D loss: 0.552141, acc.: 71.88%] [G loss: 0.894808]\n",
      "epoch:19 step:18406 [D loss: 0.518996, acc.: 76.56%] [G loss: 1.283982]\n",
      "epoch:19 step:18407 [D loss: 0.324403, acc.: 89.84%] [G loss: 1.534553]\n",
      "epoch:19 step:18408 [D loss: 0.329536, acc.: 92.19%] [G loss: 1.509596]\n",
      "epoch:19 step:18409 [D loss: 0.585757, acc.: 65.62%] [G loss: 1.197786]\n",
      "epoch:19 step:18410 [D loss: 0.630084, acc.: 63.28%] [G loss: 1.128052]\n",
      "epoch:19 step:18411 [D loss: 0.691954, acc.: 54.69%] [G loss: 0.994545]\n",
      "epoch:19 step:18412 [D loss: 0.671595, acc.: 53.91%] [G loss: 0.769915]\n",
      "epoch:19 step:18413 [D loss: 0.564477, acc.: 71.88%] [G loss: 1.182064]\n",
      "epoch:19 step:18414 [D loss: 0.757248, acc.: 47.66%] [G loss: 1.070776]\n",
      "epoch:19 step:18415 [D loss: 0.642818, acc.: 60.16%] [G loss: 1.155020]\n",
      "epoch:19 step:18416 [D loss: 0.624718, acc.: 61.72%] [G loss: 1.048491]\n",
      "epoch:19 step:18417 [D loss: 0.542844, acc.: 75.78%] [G loss: 1.142870]\n",
      "epoch:19 step:18418 [D loss: 0.435939, acc.: 84.38%] [G loss: 1.326143]\n",
      "epoch:19 step:18419 [D loss: 0.432412, acc.: 88.28%] [G loss: 1.118966]\n",
      "epoch:19 step:18420 [D loss: 0.677170, acc.: 57.03%] [G loss: 1.064825]\n",
      "epoch:19 step:18421 [D loss: 0.947335, acc.: 35.16%] [G loss: 0.800797]\n",
      "epoch:19 step:18422 [D loss: 1.038460, acc.: 23.44%] [G loss: 0.677813]\n",
      "epoch:19 step:18423 [D loss: 0.737628, acc.: 50.00%] [G loss: 1.205897]\n",
      "epoch:19 step:18424 [D loss: 0.724717, acc.: 49.22%] [G loss: 1.292228]\n",
      "epoch:19 step:18425 [D loss: 0.673257, acc.: 58.59%] [G loss: 1.192989]\n",
      "epoch:19 step:18426 [D loss: 0.595695, acc.: 61.72%] [G loss: 1.075441]\n",
      "epoch:19 step:18427 [D loss: 0.524065, acc.: 79.69%] [G loss: 1.311972]\n",
      "epoch:19 step:18428 [D loss: 0.673101, acc.: 61.72%] [G loss: 0.989792]\n",
      "epoch:19 step:18429 [D loss: 0.717083, acc.: 57.03%] [G loss: 0.874080]\n",
      "epoch:19 step:18430 [D loss: 0.660047, acc.: 57.03%] [G loss: 0.999713]\n",
      "epoch:19 step:18431 [D loss: 0.626999, acc.: 64.84%] [G loss: 0.877245]\n",
      "epoch:19 step:18432 [D loss: 0.703401, acc.: 52.34%] [G loss: 0.912713]\n",
      "epoch:19 step:18433 [D loss: 0.638844, acc.: 60.16%] [G loss: 0.916828]\n",
      "epoch:19 step:18434 [D loss: 0.670619, acc.: 62.50%] [G loss: 0.906087]\n",
      "epoch:19 step:18435 [D loss: 0.706704, acc.: 54.69%] [G loss: 1.123126]\n",
      "epoch:19 step:18436 [D loss: 0.604179, acc.: 70.31%] [G loss: 1.163541]\n",
      "epoch:19 step:18437 [D loss: 0.606548, acc.: 69.53%] [G loss: 1.055493]\n",
      "epoch:19 step:18438 [D loss: 0.593239, acc.: 67.19%] [G loss: 1.181944]\n",
      "epoch:19 step:18439 [D loss: 0.557903, acc.: 74.22%] [G loss: 1.083099]\n",
      "epoch:19 step:18440 [D loss: 0.583561, acc.: 70.31%] [G loss: 0.968876]\n",
      "epoch:19 step:18441 [D loss: 0.557174, acc.: 71.88%] [G loss: 1.063690]\n",
      "epoch:19 step:18442 [D loss: 0.655811, acc.: 61.72%] [G loss: 1.084591]\n",
      "epoch:19 step:18443 [D loss: 0.544231, acc.: 72.66%] [G loss: 1.071548]\n",
      "epoch:19 step:18444 [D loss: 0.510728, acc.: 77.34%] [G loss: 1.182378]\n",
      "epoch:19 step:18445 [D loss: 0.459802, acc.: 88.28%] [G loss: 1.488914]\n",
      "epoch:19 step:18446 [D loss: 0.680209, acc.: 57.81%] [G loss: 1.151411]\n",
      "epoch:19 step:18447 [D loss: 0.785032, acc.: 50.00%] [G loss: 1.058003]\n",
      "epoch:19 step:18448 [D loss: 0.534960, acc.: 77.34%] [G loss: 1.031773]\n",
      "epoch:19 step:18449 [D loss: 0.447494, acc.: 84.38%] [G loss: 1.034753]\n",
      "epoch:19 step:18450 [D loss: 0.408036, acc.: 88.28%] [G loss: 1.124741]\n",
      "epoch:19 step:18451 [D loss: 0.499378, acc.: 74.22%] [G loss: 1.220691]\n",
      "epoch:19 step:18452 [D loss: 0.458305, acc.: 85.94%] [G loss: 1.333477]\n",
      "epoch:19 step:18453 [D loss: 0.498190, acc.: 78.91%] [G loss: 1.149115]\n",
      "epoch:19 step:18454 [D loss: 0.467466, acc.: 82.03%] [G loss: 1.439202]\n",
      "epoch:19 step:18455 [D loss: 0.859522, acc.: 46.09%] [G loss: 1.252867]\n",
      "epoch:19 step:18456 [D loss: 0.858207, acc.: 36.72%] [G loss: 1.018966]\n",
      "epoch:19 step:18457 [D loss: 0.708089, acc.: 54.69%] [G loss: 1.081158]\n",
      "epoch:19 step:18458 [D loss: 0.687258, acc.: 55.47%] [G loss: 1.106554]\n",
      "epoch:19 step:18459 [D loss: 0.784298, acc.: 44.53%] [G loss: 0.900702]\n",
      "epoch:19 step:18460 [D loss: 0.687089, acc.: 57.81%] [G loss: 0.967938]\n",
      "epoch:19 step:18461 [D loss: 0.693957, acc.: 58.59%] [G loss: 1.135319]\n",
      "epoch:19 step:18462 [D loss: 0.700859, acc.: 52.34%] [G loss: 1.126099]\n",
      "epoch:19 step:18463 [D loss: 0.591521, acc.: 72.66%] [G loss: 1.137231]\n",
      "epoch:19 step:18464 [D loss: 0.769427, acc.: 49.22%] [G loss: 0.895696]\n",
      "epoch:19 step:18465 [D loss: 0.709211, acc.: 58.59%] [G loss: 0.934687]\n",
      "epoch:19 step:18466 [D loss: 0.457003, acc.: 82.81%] [G loss: 1.238472]\n",
      "epoch:19 step:18467 [D loss: 0.460805, acc.: 82.81%] [G loss: 1.295447]\n",
      "epoch:19 step:18468 [D loss: 0.408834, acc.: 89.06%] [G loss: 1.473441]\n",
      "epoch:19 step:18469 [D loss: 0.582358, acc.: 69.53%] [G loss: 1.309625]\n",
      "epoch:19 step:18470 [D loss: 0.563022, acc.: 75.00%] [G loss: 1.174167]\n",
      "epoch:19 step:18471 [D loss: 0.649976, acc.: 63.28%] [G loss: 1.124966]\n",
      "epoch:19 step:18472 [D loss: 0.522090, acc.: 81.25%] [G loss: 1.023907]\n",
      "epoch:19 step:18473 [D loss: 0.700777, acc.: 58.59%] [G loss: 1.014574]\n",
      "epoch:19 step:18474 [D loss: 0.720665, acc.: 52.34%] [G loss: 0.998007]\n",
      "epoch:19 step:18475 [D loss: 0.874749, acc.: 39.06%] [G loss: 0.867766]\n",
      "epoch:19 step:18476 [D loss: 0.824258, acc.: 42.97%] [G loss: 0.862918]\n",
      "epoch:19 step:18477 [D loss: 0.593765, acc.: 70.31%] [G loss: 1.031016]\n",
      "epoch:19 step:18478 [D loss: 0.841073, acc.: 42.19%] [G loss: 0.788850]\n",
      "epoch:19 step:18479 [D loss: 0.701885, acc.: 58.59%] [G loss: 0.879277]\n",
      "epoch:19 step:18480 [D loss: 0.653620, acc.: 64.06%] [G loss: 1.132438]\n",
      "epoch:19 step:18481 [D loss: 0.728034, acc.: 54.69%] [G loss: 1.074511]\n",
      "epoch:19 step:18482 [D loss: 0.801845, acc.: 45.31%] [G loss: 0.930462]\n",
      "epoch:19 step:18483 [D loss: 0.642268, acc.: 63.28%] [G loss: 0.956477]\n",
      "epoch:19 step:18484 [D loss: 0.578081, acc.: 70.31%] [G loss: 0.904783]\n",
      "epoch:19 step:18485 [D loss: 0.647637, acc.: 64.06%] [G loss: 1.001651]\n",
      "epoch:19 step:18486 [D loss: 0.768075, acc.: 48.44%] [G loss: 0.857977]\n",
      "epoch:19 step:18487 [D loss: 0.646024, acc.: 66.41%] [G loss: 0.867938]\n",
      "epoch:19 step:18488 [D loss: 0.509259, acc.: 80.47%] [G loss: 0.998078]\n",
      "epoch:19 step:18489 [D loss: 0.615885, acc.: 62.50%] [G loss: 1.027964]\n",
      "epoch:19 step:18490 [D loss: 0.567757, acc.: 71.88%] [G loss: 0.924160]\n",
      "epoch:19 step:18491 [D loss: 0.552465, acc.: 77.34%] [G loss: 1.340083]\n",
      "epoch:19 step:18492 [D loss: 0.547357, acc.: 71.88%] [G loss: 1.359891]\n",
      "epoch:19 step:18493 [D loss: 0.416638, acc.: 76.56%] [G loss: 1.250479]\n",
      "epoch:19 step:18494 [D loss: 0.474909, acc.: 80.47%] [G loss: 1.440722]\n",
      "epoch:19 step:18495 [D loss: 0.402699, acc.: 90.62%] [G loss: 1.367658]\n",
      "epoch:19 step:18496 [D loss: 0.588545, acc.: 64.06%] [G loss: 1.130314]\n",
      "epoch:19 step:18497 [D loss: 0.328465, acc.: 91.41%] [G loss: 1.457939]\n",
      "epoch:19 step:18498 [D loss: 0.446332, acc.: 82.81%] [G loss: 1.516916]\n",
      "epoch:19 step:18499 [D loss: 0.909357, acc.: 41.41%] [G loss: 1.095316]\n",
      "epoch:19 step:18500 [D loss: 0.751444, acc.: 55.47%] [G loss: 1.187559]\n",
      "epoch:19 step:18501 [D loss: 0.929042, acc.: 32.03%] [G loss: 0.961173]\n",
      "epoch:19 step:18502 [D loss: 0.671443, acc.: 61.72%] [G loss: 1.015379]\n",
      "epoch:19 step:18503 [D loss: 0.657677, acc.: 61.72%] [G loss: 1.001283]\n",
      "epoch:19 step:18504 [D loss: 0.476102, acc.: 79.69%] [G loss: 1.027280]\n",
      "epoch:19 step:18505 [D loss: 0.754088, acc.: 50.00%] [G loss: 1.101541]\n",
      "epoch:19 step:18506 [D loss: 0.576249, acc.: 69.53%] [G loss: 1.055189]\n",
      "epoch:19 step:18507 [D loss: 0.663988, acc.: 66.41%] [G loss: 1.038330]\n",
      "epoch:19 step:18508 [D loss: 0.551111, acc.: 72.66%] [G loss: 1.106228]\n",
      "epoch:19 step:18509 [D loss: 0.464448, acc.: 82.03%] [G loss: 1.217704]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18510 [D loss: 0.326376, acc.: 94.53%] [G loss: 1.274547]\n",
      "epoch:19 step:18511 [D loss: 0.418610, acc.: 86.72%] [G loss: 1.349267]\n",
      "epoch:19 step:18512 [D loss: 0.386663, acc.: 85.16%] [G loss: 1.259552]\n",
      "epoch:19 step:18513 [D loss: 0.773782, acc.: 53.91%] [G loss: 1.209504]\n",
      "epoch:19 step:18514 [D loss: 0.764239, acc.: 44.53%] [G loss: 0.851699]\n",
      "epoch:19 step:18515 [D loss: 0.702291, acc.: 52.34%] [G loss: 0.886714]\n",
      "epoch:19 step:18516 [D loss: 0.372371, acc.: 90.62%] [G loss: 1.246617]\n",
      "epoch:19 step:18517 [D loss: 0.526966, acc.: 77.34%] [G loss: 1.259208]\n",
      "epoch:19 step:18518 [D loss: 0.689850, acc.: 54.69%] [G loss: 1.167166]\n",
      "epoch:19 step:18519 [D loss: 0.799386, acc.: 48.44%] [G loss: 1.103541]\n",
      "epoch:19 step:18520 [D loss: 0.669421, acc.: 60.94%] [G loss: 1.048319]\n",
      "epoch:19 step:18521 [D loss: 0.806887, acc.: 45.31%] [G loss: 0.748547]\n",
      "epoch:19 step:18522 [D loss: 0.895057, acc.: 41.41%] [G loss: 0.534828]\n",
      "epoch:19 step:18523 [D loss: 0.822502, acc.: 39.84%] [G loss: 0.889721]\n",
      "epoch:19 step:18524 [D loss: 0.705622, acc.: 55.47%] [G loss: 1.121272]\n",
      "epoch:19 step:18525 [D loss: 0.601177, acc.: 71.09%] [G loss: 0.986341]\n",
      "epoch:19 step:18526 [D loss: 0.618633, acc.: 73.44%] [G loss: 1.071814]\n",
      "epoch:19 step:18527 [D loss: 0.557903, acc.: 73.44%] [G loss: 0.896158]\n",
      "epoch:19 step:18528 [D loss: 0.446941, acc.: 89.06%] [G loss: 1.127633]\n",
      "epoch:19 step:18529 [D loss: 0.498298, acc.: 78.91%] [G loss: 1.263048]\n",
      "epoch:19 step:18530 [D loss: 0.765760, acc.: 46.88%] [G loss: 1.018867]\n",
      "epoch:19 step:18531 [D loss: 0.650945, acc.: 60.16%] [G loss: 1.006252]\n",
      "epoch:19 step:18532 [D loss: 0.630177, acc.: 66.41%] [G loss: 0.949345]\n",
      "epoch:19 step:18533 [D loss: 0.581226, acc.: 70.31%] [G loss: 0.905264]\n",
      "epoch:19 step:18534 [D loss: 0.568401, acc.: 75.00%] [G loss: 1.052002]\n",
      "epoch:19 step:18535 [D loss: 0.565827, acc.: 71.88%] [G loss: 1.080676]\n",
      "epoch:19 step:18536 [D loss: 0.509800, acc.: 78.91%] [G loss: 1.164841]\n",
      "epoch:19 step:18537 [D loss: 0.606933, acc.: 67.97%] [G loss: 1.134505]\n",
      "epoch:19 step:18538 [D loss: 0.585074, acc.: 67.19%] [G loss: 1.054410]\n",
      "epoch:19 step:18539 [D loss: 0.739908, acc.: 50.00%] [G loss: 0.825073]\n",
      "epoch:19 step:18540 [D loss: 0.602430, acc.: 64.84%] [G loss: 0.966375]\n",
      "epoch:19 step:18541 [D loss: 0.673002, acc.: 57.03%] [G loss: 0.995792]\n",
      "epoch:19 step:18542 [D loss: 0.694907, acc.: 53.91%] [G loss: 0.976028]\n",
      "epoch:19 step:18543 [D loss: 0.599766, acc.: 67.19%] [G loss: 0.866090]\n",
      "epoch:19 step:18544 [D loss: 0.553335, acc.: 71.88%] [G loss: 0.982364]\n",
      "epoch:19 step:18545 [D loss: 0.636477, acc.: 64.84%] [G loss: 1.058951]\n",
      "epoch:19 step:18546 [D loss: 0.376287, acc.: 90.62%] [G loss: 0.945755]\n",
      "epoch:19 step:18547 [D loss: 0.677532, acc.: 54.69%] [G loss: 1.029047]\n",
      "epoch:19 step:18548 [D loss: 0.471415, acc.: 78.12%] [G loss: 1.106359]\n",
      "epoch:19 step:18549 [D loss: 0.557671, acc.: 75.78%] [G loss: 1.140079]\n",
      "epoch:19 step:18550 [D loss: 0.594799, acc.: 67.19%] [G loss: 1.215027]\n",
      "epoch:19 step:18551 [D loss: 0.534728, acc.: 78.12%] [G loss: 0.953132]\n",
      "epoch:19 step:18552 [D loss: 0.560003, acc.: 65.62%] [G loss: 0.968569]\n",
      "epoch:19 step:18553 [D loss: 0.561373, acc.: 70.31%] [G loss: 1.364994]\n",
      "epoch:19 step:18554 [D loss: 0.680791, acc.: 57.81%] [G loss: 1.061873]\n",
      "epoch:19 step:18555 [D loss: 0.694230, acc.: 53.91%] [G loss: 0.926593]\n",
      "epoch:19 step:18556 [D loss: 0.655120, acc.: 60.16%] [G loss: 1.007128]\n",
      "epoch:19 step:18557 [D loss: 0.693528, acc.: 59.38%] [G loss: 0.947748]\n",
      "epoch:19 step:18558 [D loss: 0.548034, acc.: 75.78%] [G loss: 1.118974]\n",
      "epoch:19 step:18559 [D loss: 0.681042, acc.: 57.03%] [G loss: 1.078594]\n",
      "epoch:19 step:18560 [D loss: 0.657824, acc.: 58.59%] [G loss: 0.953464]\n",
      "epoch:19 step:18561 [D loss: 0.706758, acc.: 57.03%] [G loss: 0.945512]\n",
      "epoch:19 step:18562 [D loss: 0.698278, acc.: 57.03%] [G loss: 0.920586]\n",
      "epoch:19 step:18563 [D loss: 0.680252, acc.: 50.78%] [G loss: 0.942119]\n",
      "epoch:19 step:18564 [D loss: 0.786277, acc.: 42.19%] [G loss: 0.917040]\n",
      "epoch:19 step:18565 [D loss: 0.725877, acc.: 50.78%] [G loss: 1.092870]\n",
      "epoch:19 step:18566 [D loss: 0.628299, acc.: 60.16%] [G loss: 1.031735]\n",
      "epoch:19 step:18567 [D loss: 0.681891, acc.: 58.59%] [G loss: 1.209114]\n",
      "epoch:19 step:18568 [D loss: 0.762600, acc.: 50.00%] [G loss: 0.932580]\n",
      "epoch:19 step:18569 [D loss: 0.759929, acc.: 45.31%] [G loss: 1.071221]\n",
      "epoch:19 step:18570 [D loss: 0.559842, acc.: 75.78%] [G loss: 1.229478]\n",
      "epoch:19 step:18571 [D loss: 0.524394, acc.: 79.69%] [G loss: 0.951044]\n",
      "epoch:19 step:18572 [D loss: 0.391448, acc.: 87.50%] [G loss: 1.031709]\n",
      "epoch:19 step:18573 [D loss: 0.555290, acc.: 76.56%] [G loss: 0.998742]\n",
      "epoch:19 step:18574 [D loss: 0.649406, acc.: 64.84%] [G loss: 0.940313]\n",
      "epoch:19 step:18575 [D loss: 0.642861, acc.: 63.28%] [G loss: 0.901538]\n",
      "epoch:19 step:18576 [D loss: 0.669086, acc.: 59.38%] [G loss: 0.776148]\n",
      "epoch:19 step:18577 [D loss: 0.412776, acc.: 81.25%] [G loss: 1.124032]\n",
      "epoch:19 step:18578 [D loss: 0.375506, acc.: 83.59%] [G loss: 1.399971]\n",
      "epoch:19 step:18579 [D loss: 0.647354, acc.: 63.28%] [G loss: 1.134002]\n",
      "epoch:19 step:18580 [D loss: 0.746548, acc.: 55.47%] [G loss: 0.951599]\n",
      "epoch:19 step:18581 [D loss: 0.686980, acc.: 58.59%] [G loss: 1.057171]\n",
      "epoch:19 step:18582 [D loss: 0.759451, acc.: 53.91%] [G loss: 1.096133]\n",
      "epoch:19 step:18583 [D loss: 0.655063, acc.: 57.81%] [G loss: 0.943759]\n",
      "epoch:19 step:18584 [D loss: 0.426884, acc.: 90.62%] [G loss: 1.302535]\n",
      "epoch:19 step:18585 [D loss: 0.401580, acc.: 92.97%] [G loss: 1.368922]\n",
      "epoch:19 step:18586 [D loss: 0.667168, acc.: 58.59%] [G loss: 1.049290]\n",
      "epoch:19 step:18587 [D loss: 0.660485, acc.: 60.94%] [G loss: 1.162877]\n",
      "epoch:19 step:18588 [D loss: 0.583003, acc.: 72.66%] [G loss: 1.066048]\n",
      "epoch:19 step:18589 [D loss: 0.447345, acc.: 86.72%] [G loss: 1.175526]\n",
      "epoch:19 step:18590 [D loss: 0.732111, acc.: 53.12%] [G loss: 0.935412]\n",
      "epoch:19 step:18591 [D loss: 0.659711, acc.: 60.16%] [G loss: 1.000293]\n",
      "epoch:19 step:18592 [D loss: 0.656746, acc.: 64.06%] [G loss: 1.076291]\n",
      "epoch:19 step:18593 [D loss: 0.439454, acc.: 89.06%] [G loss: 1.379890]\n",
      "epoch:19 step:18594 [D loss: 0.448760, acc.: 72.66%] [G loss: 1.244252]\n",
      "epoch:19 step:18595 [D loss: 0.288604, acc.: 95.31%] [G loss: 1.598888]\n",
      "epoch:19 step:18596 [D loss: 0.350895, acc.: 92.97%] [G loss: 1.575158]\n",
      "epoch:19 step:18597 [D loss: 0.279038, acc.: 96.09%] [G loss: 1.560999]\n",
      "epoch:19 step:18598 [D loss: 0.486938, acc.: 78.91%] [G loss: 1.221683]\n",
      "epoch:19 step:18599 [D loss: 0.583642, acc.: 66.41%] [G loss: 1.083235]\n",
      "epoch:19 step:18600 [D loss: 0.608182, acc.: 65.62%] [G loss: 1.019137]\n",
      "##############\n",
      "[2.41529937 1.65487447 5.5260673  4.14446345 3.16808844 5.3849331\n",
      " 4.10809126 4.55153995 3.87543525 3.73641452]\n",
      "##########\n",
      "epoch:19 step:18601 [D loss: 0.534877, acc.: 76.56%] [G loss: 1.139172]\n",
      "epoch:19 step:18602 [D loss: 0.532908, acc.: 75.00%] [G loss: 1.073301]\n",
      "epoch:19 step:18603 [D loss: 0.947612, acc.: 27.34%] [G loss: 0.834886]\n",
      "epoch:19 step:18604 [D loss: 0.759241, acc.: 50.00%] [G loss: 1.084036]\n",
      "epoch:19 step:18605 [D loss: 0.814942, acc.: 47.66%] [G loss: 0.873473]\n",
      "epoch:19 step:18606 [D loss: 0.886886, acc.: 35.16%] [G loss: 0.878092]\n",
      "epoch:19 step:18607 [D loss: 0.671433, acc.: 59.38%] [G loss: 1.258211]\n",
      "epoch:19 step:18608 [D loss: 0.702539, acc.: 57.03%] [G loss: 1.004563]\n",
      "epoch:19 step:18609 [D loss: 0.461230, acc.: 80.47%] [G loss: 1.261238]\n",
      "epoch:19 step:18610 [D loss: 0.721272, acc.: 50.78%] [G loss: 1.236918]\n",
      "epoch:19 step:18611 [D loss: 0.696924, acc.: 52.34%] [G loss: 1.166099]\n",
      "epoch:19 step:18612 [D loss: 0.629578, acc.: 68.75%] [G loss: 1.226354]\n",
      "epoch:19 step:18613 [D loss: 0.538619, acc.: 71.09%] [G loss: 1.312406]\n",
      "epoch:19 step:18614 [D loss: 0.701613, acc.: 59.38%] [G loss: 1.140201]\n",
      "epoch:19 step:18615 [D loss: 0.569199, acc.: 67.97%] [G loss: 1.223608]\n",
      "epoch:19 step:18616 [D loss: 0.527045, acc.: 78.91%] [G loss: 1.029735]\n",
      "epoch:19 step:18617 [D loss: 0.491877, acc.: 78.91%] [G loss: 1.099502]\n",
      "epoch:19 step:18618 [D loss: 0.274492, acc.: 88.28%] [G loss: 1.312663]\n",
      "epoch:19 step:18619 [D loss: 0.277768, acc.: 92.19%] [G loss: 1.439499]\n",
      "epoch:19 step:18620 [D loss: 0.383014, acc.: 89.84%] [G loss: 1.301480]\n",
      "epoch:19 step:18621 [D loss: 0.390158, acc.: 87.50%] [G loss: 1.582579]\n",
      "epoch:19 step:18622 [D loss: 0.529162, acc.: 79.69%] [G loss: 1.171559]\n",
      "epoch:19 step:18623 [D loss: 0.931616, acc.: 34.38%] [G loss: 0.800971]\n",
      "epoch:19 step:18624 [D loss: 0.755306, acc.: 50.00%] [G loss: 0.929611]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18625 [D loss: 0.910564, acc.: 31.25%] [G loss: 1.001812]\n",
      "epoch:19 step:18626 [D loss: 0.500987, acc.: 79.69%] [G loss: 1.329206]\n",
      "epoch:19 step:18627 [D loss: 0.469667, acc.: 77.34%] [G loss: 1.360205]\n",
      "epoch:19 step:18628 [D loss: 0.350121, acc.: 92.97%] [G loss: 1.464343]\n",
      "epoch:19 step:18629 [D loss: 0.521694, acc.: 78.91%] [G loss: 0.911038]\n",
      "epoch:19 step:18630 [D loss: 0.756899, acc.: 50.00%] [G loss: 0.913678]\n",
      "epoch:19 step:18631 [D loss: 0.798017, acc.: 45.31%] [G loss: 0.489651]\n",
      "epoch:19 step:18632 [D loss: 0.567461, acc.: 69.53%] [G loss: 1.070850]\n",
      "epoch:19 step:18633 [D loss: 0.536403, acc.: 73.44%] [G loss: 1.337203]\n",
      "epoch:19 step:18634 [D loss: 0.427808, acc.: 82.03%] [G loss: 1.224810]\n",
      "epoch:19 step:18635 [D loss: 0.474387, acc.: 83.59%] [G loss: 1.407693]\n",
      "epoch:19 step:18636 [D loss: 0.562061, acc.: 70.31%] [G loss: 1.239989]\n",
      "epoch:19 step:18637 [D loss: 1.001939, acc.: 43.75%] [G loss: 1.186852]\n",
      "epoch:19 step:18638 [D loss: 0.824398, acc.: 51.56%] [G loss: 1.082745]\n",
      "epoch:19 step:18639 [D loss: 0.981444, acc.: 28.91%] [G loss: 1.013618]\n",
      "epoch:19 step:18640 [D loss: 0.915896, acc.: 34.38%] [G loss: 0.944219]\n",
      "epoch:19 step:18641 [D loss: 0.682159, acc.: 57.81%] [G loss: 1.331119]\n",
      "epoch:19 step:18642 [D loss: 0.781443, acc.: 51.56%] [G loss: 0.912857]\n",
      "epoch:19 step:18643 [D loss: 0.688766, acc.: 55.47%] [G loss: 1.152402]\n",
      "epoch:19 step:18644 [D loss: 0.552163, acc.: 75.00%] [G loss: 1.223950]\n",
      "epoch:19 step:18645 [D loss: 0.466843, acc.: 84.38%] [G loss: 1.063886]\n",
      "epoch:19 step:18646 [D loss: 0.639662, acc.: 56.25%] [G loss: 1.055146]\n",
      "epoch:19 step:18647 [D loss: 0.725801, acc.: 52.34%] [G loss: 0.838819]\n",
      "epoch:19 step:18648 [D loss: 0.618894, acc.: 69.53%] [G loss: 1.028248]\n",
      "epoch:19 step:18649 [D loss: 0.563361, acc.: 72.66%] [G loss: 0.944774]\n",
      "epoch:19 step:18650 [D loss: 0.476547, acc.: 82.81%] [G loss: 1.205471]\n",
      "epoch:19 step:18651 [D loss: 0.453550, acc.: 85.16%] [G loss: 1.212047]\n",
      "epoch:19 step:18652 [D loss: 0.288206, acc.: 97.66%] [G loss: 1.617539]\n",
      "epoch:19 step:18653 [D loss: 0.311446, acc.: 92.97%] [G loss: 1.582069]\n",
      "epoch:19 step:18654 [D loss: 0.321852, acc.: 92.19%] [G loss: 1.487658]\n",
      "epoch:19 step:18655 [D loss: 0.241692, acc.: 97.66%] [G loss: 1.544638]\n",
      "epoch:19 step:18656 [D loss: 0.300324, acc.: 94.53%] [G loss: 1.553376]\n",
      "epoch:19 step:18657 [D loss: 0.327786, acc.: 91.41%] [G loss: 1.315249]\n",
      "epoch:19 step:18658 [D loss: 0.451909, acc.: 80.47%] [G loss: 1.237597]\n",
      "epoch:19 step:18659 [D loss: 0.461159, acc.: 82.81%] [G loss: 1.549800]\n",
      "epoch:19 step:18660 [D loss: 0.354602, acc.: 88.28%] [G loss: 1.432224]\n",
      "epoch:19 step:18661 [D loss: 1.257432, acc.: 19.53%] [G loss: 0.934099]\n",
      "epoch:19 step:18662 [D loss: 0.866796, acc.: 39.06%] [G loss: 0.912019]\n",
      "epoch:19 step:18663 [D loss: 0.601402, acc.: 70.31%] [G loss: 0.899483]\n",
      "epoch:19 step:18664 [D loss: 0.675130, acc.: 60.16%] [G loss: 0.833511]\n",
      "epoch:19 step:18665 [D loss: 0.626166, acc.: 70.31%] [G loss: 0.959589]\n",
      "epoch:19 step:18666 [D loss: 0.683357, acc.: 61.72%] [G loss: 0.844380]\n",
      "epoch:19 step:18667 [D loss: 0.715703, acc.: 54.69%] [G loss: 0.841458]\n",
      "epoch:19 step:18668 [D loss: 0.677371, acc.: 57.03%] [G loss: 1.062451]\n",
      "epoch:19 step:18669 [D loss: 0.806784, acc.: 42.19%] [G loss: 0.782825]\n",
      "epoch:19 step:18670 [D loss: 0.729650, acc.: 53.12%] [G loss: 1.001235]\n",
      "epoch:19 step:18671 [D loss: 0.818314, acc.: 39.06%] [G loss: 0.666474]\n",
      "epoch:19 step:18672 [D loss: 0.608458, acc.: 66.41%] [G loss: 0.988581]\n",
      "epoch:19 step:18673 [D loss: 0.606539, acc.: 63.28%] [G loss: 1.061653]\n",
      "epoch:19 step:18674 [D loss: 0.647687, acc.: 62.50%] [G loss: 0.935699]\n",
      "epoch:19 step:18675 [D loss: 0.692651, acc.: 58.59%] [G loss: 1.008591]\n",
      "epoch:19 step:18676 [D loss: 0.717294, acc.: 53.12%] [G loss: 0.838106]\n",
      "epoch:19 step:18677 [D loss: 0.608201, acc.: 72.66%] [G loss: 0.927399]\n",
      "epoch:19 step:18678 [D loss: 0.542364, acc.: 74.22%] [G loss: 0.977517]\n",
      "epoch:19 step:18679 [D loss: 0.678559, acc.: 61.72%] [G loss: 0.988565]\n",
      "epoch:19 step:18680 [D loss: 0.627790, acc.: 62.50%] [G loss: 0.971759]\n",
      "epoch:19 step:18681 [D loss: 0.559093, acc.: 75.00%] [G loss: 1.114589]\n",
      "epoch:19 step:18682 [D loss: 0.610501, acc.: 64.06%] [G loss: 1.134068]\n",
      "epoch:19 step:18683 [D loss: 0.669994, acc.: 58.59%] [G loss: 1.076203]\n",
      "epoch:19 step:18684 [D loss: 0.647352, acc.: 62.50%] [G loss: 1.033628]\n",
      "epoch:19 step:18685 [D loss: 0.614181, acc.: 65.62%] [G loss: 0.942327]\n",
      "epoch:19 step:18686 [D loss: 0.738632, acc.: 51.56%] [G loss: 0.913552]\n",
      "epoch:19 step:18687 [D loss: 0.533991, acc.: 76.56%] [G loss: 1.105781]\n",
      "epoch:19 step:18688 [D loss: 0.501566, acc.: 78.12%] [G loss: 1.269165]\n",
      "epoch:19 step:18689 [D loss: 0.569310, acc.: 71.09%] [G loss: 1.067676]\n",
      "epoch:19 step:18690 [D loss: 0.552630, acc.: 77.34%] [G loss: 1.152383]\n",
      "epoch:19 step:18691 [D loss: 0.634831, acc.: 67.97%] [G loss: 1.084184]\n",
      "epoch:19 step:18692 [D loss: 0.477959, acc.: 83.59%] [G loss: 1.106124]\n",
      "epoch:19 step:18693 [D loss: 0.404733, acc.: 89.84%] [G loss: 1.189297]\n",
      "epoch:19 step:18694 [D loss: 0.818057, acc.: 44.53%] [G loss: 1.091304]\n",
      "epoch:19 step:18695 [D loss: 0.631528, acc.: 60.16%] [G loss: 1.094466]\n",
      "epoch:19 step:18696 [D loss: 0.622264, acc.: 66.41%] [G loss: 1.034612]\n",
      "epoch:19 step:18697 [D loss: 0.576636, acc.: 67.97%] [G loss: 1.121412]\n",
      "epoch:19 step:18698 [D loss: 0.515456, acc.: 82.03%] [G loss: 1.008167]\n",
      "epoch:19 step:18699 [D loss: 0.508171, acc.: 75.00%] [G loss: 1.147416]\n",
      "epoch:19 step:18700 [D loss: 0.411646, acc.: 90.62%] [G loss: 1.262359]\n",
      "epoch:19 step:18701 [D loss: 0.334234, acc.: 91.41%] [G loss: 1.574966]\n",
      "epoch:19 step:18702 [D loss: 0.304094, acc.: 94.53%] [G loss: 1.384561]\n",
      "epoch:19 step:18703 [D loss: 0.228953, acc.: 99.22%] [G loss: 1.711784]\n",
      "epoch:19 step:18704 [D loss: 0.520769, acc.: 76.56%] [G loss: 1.342204]\n",
      "epoch:19 step:18705 [D loss: 0.617576, acc.: 65.62%] [G loss: 1.231019]\n",
      "epoch:19 step:18706 [D loss: 0.723662, acc.: 59.38%] [G loss: 0.994668]\n",
      "epoch:19 step:18707 [D loss: 0.839943, acc.: 50.78%] [G loss: 1.034378]\n",
      "epoch:19 step:18708 [D loss: 0.907515, acc.: 32.81%] [G loss: 0.841386]\n",
      "epoch:19 step:18709 [D loss: 0.816170, acc.: 48.44%] [G loss: 1.160991]\n",
      "epoch:19 step:18710 [D loss: 0.844819, acc.: 38.28%] [G loss: 0.809052]\n",
      "epoch:19 step:18711 [D loss: 0.722476, acc.: 50.78%] [G loss: 1.232734]\n",
      "epoch:19 step:18712 [D loss: 0.422494, acc.: 87.50%] [G loss: 1.028123]\n",
      "epoch:19 step:18713 [D loss: 0.610333, acc.: 60.16%] [G loss: 1.069507]\n",
      "epoch:19 step:18714 [D loss: 0.495900, acc.: 71.88%] [G loss: 0.885745]\n",
      "epoch:19 step:18715 [D loss: 0.314490, acc.: 89.06%] [G loss: 1.409147]\n",
      "epoch:19 step:18716 [D loss: 0.828657, acc.: 51.56%] [G loss: 1.421313]\n",
      "epoch:19 step:18717 [D loss: 0.843342, acc.: 42.97%] [G loss: 1.067789]\n",
      "epoch:19 step:18718 [D loss: 0.820030, acc.: 45.31%] [G loss: 0.959672]\n",
      "epoch:19 step:18719 [D loss: 0.642113, acc.: 64.84%] [G loss: 1.043058]\n",
      "epoch:19 step:18720 [D loss: 0.702199, acc.: 59.38%] [G loss: 1.025603]\n",
      "epoch:19 step:18721 [D loss: 0.560247, acc.: 77.34%] [G loss: 1.088161]\n",
      "epoch:19 step:18722 [D loss: 0.627791, acc.: 63.28%] [G loss: 1.046531]\n",
      "epoch:19 step:18723 [D loss: 0.335022, acc.: 89.84%] [G loss: 1.454183]\n",
      "epoch:19 step:18724 [D loss: 0.387772, acc.: 88.28%] [G loss: 1.455501]\n",
      "epoch:19 step:18725 [D loss: 0.720260, acc.: 51.56%] [G loss: 1.297034]\n",
      "epoch:19 step:18726 [D loss: 0.595459, acc.: 67.19%] [G loss: 0.982712]\n",
      "epoch:19 step:18727 [D loss: 0.569344, acc.: 73.44%] [G loss: 1.074201]\n",
      "epoch:19 step:18728 [D loss: 0.514687, acc.: 80.47%] [G loss: 1.084300]\n",
      "epoch:19 step:18729 [D loss: 0.620926, acc.: 67.19%] [G loss: 1.127175]\n",
      "epoch:19 step:18730 [D loss: 0.482299, acc.: 75.00%] [G loss: 0.951602]\n",
      "epoch:19 step:18731 [D loss: 0.817511, acc.: 50.78%] [G loss: 1.131002]\n",
      "epoch:19 step:18732 [D loss: 0.380115, acc.: 87.50%] [G loss: 1.140278]\n",
      "epoch:19 step:18733 [D loss: 0.424614, acc.: 88.28%] [G loss: 1.323600]\n",
      "epoch:19 step:18734 [D loss: 0.574440, acc.: 71.88%] [G loss: 1.375203]\n",
      "epoch:19 step:18735 [D loss: 0.725118, acc.: 55.47%] [G loss: 0.959605]\n",
      "epoch:19 step:18736 [D loss: 0.646530, acc.: 69.53%] [G loss: 1.031147]\n",
      "epoch:19 step:18737 [D loss: 0.499133, acc.: 80.47%] [G loss: 0.862467]\n",
      "epoch:19 step:18738 [D loss: 0.493714, acc.: 81.25%] [G loss: 1.141415]\n",
      "epoch:19 step:18739 [D loss: 0.499638, acc.: 73.44%] [G loss: 1.020440]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18740 [D loss: 0.258566, acc.: 90.62%] [G loss: 1.310056]\n",
      "epoch:20 step:18741 [D loss: 0.672553, acc.: 63.28%] [G loss: 1.123307]\n",
      "epoch:20 step:18742 [D loss: 0.696389, acc.: 53.12%] [G loss: 1.049787]\n",
      "epoch:20 step:18743 [D loss: 0.726161, acc.: 51.56%] [G loss: 1.109554]\n",
      "epoch:20 step:18744 [D loss: 0.615584, acc.: 64.84%] [G loss: 1.078623]\n",
      "epoch:20 step:18745 [D loss: 0.587947, acc.: 73.44%] [G loss: 0.892102]\n",
      "epoch:20 step:18746 [D loss: 0.598328, acc.: 69.53%] [G loss: 0.953941]\n",
      "epoch:20 step:18747 [D loss: 0.589325, acc.: 67.19%] [G loss: 1.038316]\n",
      "epoch:20 step:18748 [D loss: 0.632185, acc.: 64.06%] [G loss: 1.012760]\n",
      "epoch:20 step:18749 [D loss: 0.576611, acc.: 75.00%] [G loss: 0.992785]\n",
      "epoch:20 step:18750 [D loss: 0.580208, acc.: 73.44%] [G loss: 1.042295]\n",
      "epoch:20 step:18751 [D loss: 0.603569, acc.: 65.62%] [G loss: 1.063330]\n",
      "epoch:20 step:18752 [D loss: 0.522582, acc.: 78.91%] [G loss: 0.916766]\n",
      "epoch:20 step:18753 [D loss: 0.526635, acc.: 77.34%] [G loss: 0.919180]\n",
      "epoch:20 step:18754 [D loss: 0.626810, acc.: 64.06%] [G loss: 1.032199]\n",
      "epoch:20 step:18755 [D loss: 0.491732, acc.: 77.34%] [G loss: 1.085435]\n",
      "epoch:20 step:18756 [D loss: 0.539564, acc.: 73.44%] [G loss: 0.974937]\n",
      "epoch:20 step:18757 [D loss: 0.687723, acc.: 60.16%] [G loss: 1.083186]\n",
      "epoch:20 step:18758 [D loss: 0.837356, acc.: 37.50%] [G loss: 0.889833]\n",
      "epoch:20 step:18759 [D loss: 0.712405, acc.: 53.91%] [G loss: 1.158660]\n",
      "epoch:20 step:18760 [D loss: 0.658347, acc.: 61.72%] [G loss: 1.090797]\n",
      "epoch:20 step:18761 [D loss: 0.727408, acc.: 53.12%] [G loss: 0.989077]\n",
      "epoch:20 step:18762 [D loss: 0.730404, acc.: 50.00%] [G loss: 1.032196]\n",
      "epoch:20 step:18763 [D loss: 0.637220, acc.: 63.28%] [G loss: 1.190880]\n",
      "epoch:20 step:18764 [D loss: 0.677619, acc.: 60.94%] [G loss: 0.970066]\n",
      "epoch:20 step:18765 [D loss: 0.737321, acc.: 57.03%] [G loss: 0.967827]\n",
      "epoch:20 step:18766 [D loss: 0.604845, acc.: 68.75%] [G loss: 1.069523]\n",
      "epoch:20 step:18767 [D loss: 0.461785, acc.: 78.12%] [G loss: 1.122556]\n",
      "epoch:20 step:18768 [D loss: 0.478045, acc.: 80.47%] [G loss: 1.262944]\n",
      "epoch:20 step:18769 [D loss: 0.513350, acc.: 82.03%] [G loss: 1.203367]\n",
      "epoch:20 step:18770 [D loss: 0.476833, acc.: 81.25%] [G loss: 1.320020]\n",
      "epoch:20 step:18771 [D loss: 0.394618, acc.: 87.50%] [G loss: 1.433358]\n",
      "epoch:20 step:18772 [D loss: 0.342408, acc.: 92.97%] [G loss: 1.426970]\n",
      "epoch:20 step:18773 [D loss: 0.329509, acc.: 94.53%] [G loss: 1.744128]\n",
      "epoch:20 step:18774 [D loss: 0.421416, acc.: 85.94%] [G loss: 1.321218]\n",
      "epoch:20 step:18775 [D loss: 0.315207, acc.: 94.53%] [G loss: 1.681045]\n",
      "epoch:20 step:18776 [D loss: 0.217594, acc.: 96.88%] [G loss: 1.666192]\n",
      "epoch:20 step:18777 [D loss: 0.808246, acc.: 55.47%] [G loss: 1.254252]\n",
      "epoch:20 step:18778 [D loss: 0.868770, acc.: 39.84%] [G loss: 0.928423]\n",
      "epoch:20 step:18779 [D loss: 0.924705, acc.: 35.16%] [G loss: 0.799065]\n",
      "epoch:20 step:18780 [D loss: 0.743777, acc.: 47.66%] [G loss: 1.003781]\n",
      "epoch:20 step:18781 [D loss: 0.667367, acc.: 58.59%] [G loss: 1.004229]\n",
      "epoch:20 step:18782 [D loss: 0.662714, acc.: 57.03%] [G loss: 0.797376]\n",
      "epoch:20 step:18783 [D loss: 0.537349, acc.: 76.56%] [G loss: 1.072541]\n",
      "epoch:20 step:18784 [D loss: 0.504643, acc.: 75.00%] [G loss: 0.910734]\n",
      "epoch:20 step:18785 [D loss: 0.600346, acc.: 65.62%] [G loss: 1.123680]\n",
      "epoch:20 step:18786 [D loss: 0.729394, acc.: 53.12%] [G loss: 1.053897]\n",
      "epoch:20 step:18787 [D loss: 0.802735, acc.: 45.31%] [G loss: 0.841230]\n",
      "epoch:20 step:18788 [D loss: 0.831861, acc.: 42.97%] [G loss: 0.912568]\n",
      "epoch:20 step:18789 [D loss: 0.611088, acc.: 66.41%] [G loss: 1.007616]\n",
      "epoch:20 step:18790 [D loss: 0.579460, acc.: 67.19%] [G loss: 1.067659]\n",
      "epoch:20 step:18791 [D loss: 0.656097, acc.: 66.41%] [G loss: 1.138934]\n",
      "epoch:20 step:18792 [D loss: 0.688282, acc.: 58.59%] [G loss: 1.065065]\n",
      "epoch:20 step:18793 [D loss: 0.659307, acc.: 61.72%] [G loss: 1.089806]\n",
      "epoch:20 step:18794 [D loss: 0.580066, acc.: 73.44%] [G loss: 1.121283]\n",
      "epoch:20 step:18795 [D loss: 0.496546, acc.: 82.81%] [G loss: 1.160163]\n",
      "epoch:20 step:18796 [D loss: 0.608574, acc.: 64.06%] [G loss: 1.079180]\n",
      "epoch:20 step:18797 [D loss: 0.685534, acc.: 57.03%] [G loss: 0.945760]\n",
      "epoch:20 step:18798 [D loss: 0.806906, acc.: 46.88%] [G loss: 0.886916]\n",
      "epoch:20 step:18799 [D loss: 0.706644, acc.: 56.25%] [G loss: 0.883791]\n",
      "epoch:20 step:18800 [D loss: 0.768447, acc.: 49.22%] [G loss: 0.891498]\n",
      "##############\n",
      "[2.42566211 1.75212238 5.61724966 4.17400957 2.9839637  5.7064512\n",
      " 4.14616603 4.66563782 4.0115165  3.62219565]\n",
      "##########\n",
      "epoch:20 step:18801 [D loss: 0.653738, acc.: 66.41%] [G loss: 1.019819]\n",
      "epoch:20 step:18802 [D loss: 0.641241, acc.: 62.50%] [G loss: 0.956893]\n",
      "epoch:20 step:18803 [D loss: 0.662926, acc.: 62.50%] [G loss: 1.007353]\n",
      "epoch:20 step:18804 [D loss: 0.617508, acc.: 60.16%] [G loss: 0.955739]\n",
      "epoch:20 step:18805 [D loss: 0.591813, acc.: 67.97%] [G loss: 0.997639]\n",
      "epoch:20 step:18806 [D loss: 0.621365, acc.: 64.84%] [G loss: 1.053197]\n",
      "epoch:20 step:18807 [D loss: 0.610734, acc.: 64.06%] [G loss: 0.934651]\n",
      "epoch:20 step:18808 [D loss: 0.539235, acc.: 73.44%] [G loss: 0.933835]\n",
      "epoch:20 step:18809 [D loss: 0.475459, acc.: 78.91%] [G loss: 0.946322]\n",
      "epoch:20 step:18810 [D loss: 0.622948, acc.: 63.28%] [G loss: 1.041428]\n",
      "epoch:20 step:18811 [D loss: 0.714858, acc.: 58.59%] [G loss: 1.387996]\n",
      "epoch:20 step:18812 [D loss: 0.757742, acc.: 52.34%] [G loss: 1.000949]\n",
      "epoch:20 step:18813 [D loss: 0.657715, acc.: 60.16%] [G loss: 1.224771]\n",
      "epoch:20 step:18814 [D loss: 0.717776, acc.: 52.34%] [G loss: 0.842822]\n",
      "epoch:20 step:18815 [D loss: 0.422498, acc.: 81.25%] [G loss: 1.219524]\n",
      "epoch:20 step:18816 [D loss: 0.471400, acc.: 79.69%] [G loss: 1.420791]\n",
      "epoch:20 step:18817 [D loss: 0.402995, acc.: 90.62%] [G loss: 1.481317]\n",
      "epoch:20 step:18818 [D loss: 0.680161, acc.: 60.94%] [G loss: 1.338016]\n",
      "epoch:20 step:18819 [D loss: 0.574012, acc.: 71.09%] [G loss: 1.076904]\n",
      "epoch:20 step:18820 [D loss: 0.674906, acc.: 57.81%] [G loss: 1.037120]\n",
      "epoch:20 step:18821 [D loss: 0.805555, acc.: 39.84%] [G loss: 0.847284]\n",
      "epoch:20 step:18822 [D loss: 0.621809, acc.: 67.97%] [G loss: 1.094848]\n",
      "epoch:20 step:18823 [D loss: 0.654887, acc.: 67.97%] [G loss: 1.001029]\n",
      "epoch:20 step:18824 [D loss: 0.673970, acc.: 57.81%] [G loss: 0.932620]\n",
      "epoch:20 step:18825 [D loss: 0.658937, acc.: 60.16%] [G loss: 0.930361]\n",
      "epoch:20 step:18826 [D loss: 0.687099, acc.: 57.81%] [G loss: 0.920868]\n",
      "epoch:20 step:18827 [D loss: 0.728999, acc.: 53.12%] [G loss: 0.873357]\n",
      "epoch:20 step:18828 [D loss: 0.530468, acc.: 72.66%] [G loss: 0.993244]\n",
      "epoch:20 step:18829 [D loss: 0.676335, acc.: 53.12%] [G loss: 0.936991]\n",
      "epoch:20 step:18830 [D loss: 0.729373, acc.: 53.12%] [G loss: 1.136418]\n",
      "epoch:20 step:18831 [D loss: 0.791819, acc.: 42.19%] [G loss: 0.812710]\n",
      "epoch:20 step:18832 [D loss: 0.699437, acc.: 51.56%] [G loss: 0.982433]\n",
      "epoch:20 step:18833 [D loss: 0.665032, acc.: 60.94%] [G loss: 0.894014]\n",
      "epoch:20 step:18834 [D loss: 0.724008, acc.: 49.22%] [G loss: 0.844118]\n",
      "epoch:20 step:18835 [D loss: 0.658396, acc.: 58.59%] [G loss: 1.019564]\n",
      "epoch:20 step:18836 [D loss: 0.689417, acc.: 59.38%] [G loss: 0.916831]\n",
      "epoch:20 step:18837 [D loss: 0.648046, acc.: 60.94%] [G loss: 0.980393]\n",
      "epoch:20 step:18838 [D loss: 0.699482, acc.: 57.03%] [G loss: 0.972117]\n",
      "epoch:20 step:18839 [D loss: 0.638374, acc.: 62.50%] [G loss: 0.865307]\n",
      "epoch:20 step:18840 [D loss: 0.515996, acc.: 78.91%] [G loss: 1.221057]\n",
      "epoch:20 step:18841 [D loss: 0.659317, acc.: 58.59%] [G loss: 1.104895]\n",
      "epoch:20 step:18842 [D loss: 0.559579, acc.: 71.88%] [G loss: 1.049383]\n",
      "epoch:20 step:18843 [D loss: 0.720022, acc.: 50.78%] [G loss: 0.794601]\n",
      "epoch:20 step:18844 [D loss: 0.535411, acc.: 78.12%] [G loss: 0.993399]\n",
      "epoch:20 step:18845 [D loss: 0.442226, acc.: 83.59%] [G loss: 0.991290]\n",
      "epoch:20 step:18846 [D loss: 0.583734, acc.: 72.66%] [G loss: 0.928296]\n",
      "epoch:20 step:18847 [D loss: 0.579274, acc.: 68.75%] [G loss: 0.970764]\n",
      "epoch:20 step:18848 [D loss: 0.642822, acc.: 62.50%] [G loss: 0.914974]\n",
      "epoch:20 step:18849 [D loss: 0.491298, acc.: 82.03%] [G loss: 1.015433]\n",
      "epoch:20 step:18850 [D loss: 0.603969, acc.: 64.06%] [G loss: 1.145832]\n",
      "epoch:20 step:18851 [D loss: 0.601794, acc.: 71.09%] [G loss: 0.976114]\n",
      "epoch:20 step:18852 [D loss: 0.889376, acc.: 35.94%] [G loss: 0.844366]\n",
      "epoch:20 step:18853 [D loss: 0.651632, acc.: 60.94%] [G loss: 1.056076]\n",
      "epoch:20 step:18854 [D loss: 0.652125, acc.: 60.94%] [G loss: 1.242079]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:18855 [D loss: 0.652042, acc.: 56.25%] [G loss: 1.068797]\n",
      "epoch:20 step:18856 [D loss: 0.649477, acc.: 66.41%] [G loss: 0.894120]\n",
      "epoch:20 step:18857 [D loss: 0.374840, acc.: 93.75%] [G loss: 1.269567]\n",
      "epoch:20 step:18858 [D loss: 0.886250, acc.: 39.06%] [G loss: 0.680574]\n",
      "epoch:20 step:18859 [D loss: 0.494878, acc.: 79.69%] [G loss: 1.155528]\n",
      "epoch:20 step:18860 [D loss: 0.678177, acc.: 59.38%] [G loss: 1.174565]\n",
      "epoch:20 step:18861 [D loss: 0.429969, acc.: 85.94%] [G loss: 1.147912]\n",
      "epoch:20 step:18862 [D loss: 0.362214, acc.: 89.84%] [G loss: 1.452290]\n",
      "epoch:20 step:18863 [D loss: 0.644699, acc.: 58.59%] [G loss: 1.325169]\n",
      "epoch:20 step:18864 [D loss: 0.708897, acc.: 54.69%] [G loss: 1.006052]\n",
      "epoch:20 step:18865 [D loss: 0.713594, acc.: 52.34%] [G loss: 1.012301]\n",
      "epoch:20 step:18866 [D loss: 0.707998, acc.: 52.34%] [G loss: 1.006703]\n",
      "epoch:20 step:18867 [D loss: 0.641852, acc.: 59.38%] [G loss: 0.964245]\n",
      "epoch:20 step:18868 [D loss: 0.676323, acc.: 60.94%] [G loss: 0.869226]\n",
      "epoch:20 step:18869 [D loss: 0.497561, acc.: 80.47%] [G loss: 1.059384]\n",
      "epoch:20 step:18870 [D loss: 0.386195, acc.: 87.50%] [G loss: 1.058833]\n",
      "epoch:20 step:18871 [D loss: 0.384187, acc.: 89.06%] [G loss: 1.302252]\n",
      "epoch:20 step:18872 [D loss: 0.468788, acc.: 82.81%] [G loss: 1.120424]\n",
      "epoch:20 step:18873 [D loss: 0.853585, acc.: 39.06%] [G loss: 0.999606]\n",
      "epoch:20 step:18874 [D loss: 0.633571, acc.: 63.28%] [G loss: 1.146859]\n",
      "epoch:20 step:18875 [D loss: 0.700420, acc.: 57.81%] [G loss: 1.045707]\n",
      "epoch:20 step:18876 [D loss: 0.670521, acc.: 57.81%] [G loss: 1.119995]\n",
      "epoch:20 step:18877 [D loss: 0.563220, acc.: 75.78%] [G loss: 1.022119]\n",
      "epoch:20 step:18878 [D loss: 0.611892, acc.: 65.62%] [G loss: 0.776264]\n",
      "epoch:20 step:18879 [D loss: 0.477853, acc.: 77.34%] [G loss: 1.048098]\n",
      "epoch:20 step:18880 [D loss: 0.595009, acc.: 67.97%] [G loss: 1.168741]\n",
      "epoch:20 step:18881 [D loss: 0.727955, acc.: 50.78%] [G loss: 1.006053]\n",
      "epoch:20 step:18882 [D loss: 0.697901, acc.: 55.47%] [G loss: 0.898688]\n",
      "epoch:20 step:18883 [D loss: 0.548944, acc.: 71.88%] [G loss: 1.145183]\n",
      "epoch:20 step:18884 [D loss: 0.535271, acc.: 73.44%] [G loss: 1.147030]\n",
      "epoch:20 step:18885 [D loss: 0.482790, acc.: 82.03%] [G loss: 1.238463]\n",
      "epoch:20 step:18886 [D loss: 0.674931, acc.: 62.50%] [G loss: 1.078905]\n",
      "epoch:20 step:18887 [D loss: 0.710575, acc.: 53.12%] [G loss: 1.057927]\n",
      "epoch:20 step:18888 [D loss: 0.782184, acc.: 47.66%] [G loss: 0.929446]\n",
      "epoch:20 step:18889 [D loss: 0.535285, acc.: 72.66%] [G loss: 0.881303]\n",
      "epoch:20 step:18890 [D loss: 0.415869, acc.: 85.16%] [G loss: 1.086087]\n",
      "epoch:20 step:18891 [D loss: 0.388267, acc.: 87.50%] [G loss: 1.263613]\n",
      "epoch:20 step:18892 [D loss: 0.385266, acc.: 86.72%] [G loss: 1.359569]\n",
      "epoch:20 step:18893 [D loss: 0.645143, acc.: 60.94%] [G loss: 1.255621]\n",
      "epoch:20 step:18894 [D loss: 0.798078, acc.: 48.44%] [G loss: 0.815375]\n",
      "epoch:20 step:18895 [D loss: 0.654181, acc.: 57.81%] [G loss: 1.042312]\n",
      "epoch:20 step:18896 [D loss: 0.596998, acc.: 73.44%] [G loss: 0.990651]\n",
      "epoch:20 step:18897 [D loss: 0.762829, acc.: 47.66%] [G loss: 1.088511]\n",
      "epoch:20 step:18898 [D loss: 0.731277, acc.: 53.12%] [G loss: 1.049352]\n",
      "epoch:20 step:18899 [D loss: 0.605410, acc.: 67.97%] [G loss: 0.987322]\n",
      "epoch:20 step:18900 [D loss: 0.814680, acc.: 46.09%] [G loss: 1.049900]\n",
      "epoch:20 step:18901 [D loss: 0.703299, acc.: 56.25%] [G loss: 0.844201]\n",
      "epoch:20 step:18902 [D loss: 0.688340, acc.: 55.47%] [G loss: 0.852273]\n",
      "epoch:20 step:18903 [D loss: 0.665450, acc.: 59.38%] [G loss: 1.060197]\n",
      "epoch:20 step:18904 [D loss: 0.709377, acc.: 56.25%] [G loss: 0.907249]\n",
      "epoch:20 step:18905 [D loss: 0.597767, acc.: 67.97%] [G loss: 0.961956]\n",
      "epoch:20 step:18906 [D loss: 0.549693, acc.: 71.09%] [G loss: 1.048105]\n",
      "epoch:20 step:18907 [D loss: 0.583264, acc.: 71.88%] [G loss: 1.006991]\n",
      "epoch:20 step:18908 [D loss: 0.534876, acc.: 77.34%] [G loss: 1.115761]\n",
      "epoch:20 step:18909 [D loss: 0.576061, acc.: 67.97%] [G loss: 1.102142]\n",
      "epoch:20 step:18910 [D loss: 0.497334, acc.: 81.25%] [G loss: 1.123187]\n",
      "epoch:20 step:18911 [D loss: 0.611221, acc.: 66.41%] [G loss: 1.181809]\n",
      "epoch:20 step:18912 [D loss: 0.659553, acc.: 60.94%] [G loss: 0.968131]\n",
      "epoch:20 step:18913 [D loss: 0.623738, acc.: 65.62%] [G loss: 0.956338]\n",
      "epoch:20 step:18914 [D loss: 0.849739, acc.: 35.94%] [G loss: 0.863384]\n",
      "epoch:20 step:18915 [D loss: 0.809251, acc.: 36.72%] [G loss: 1.054038]\n",
      "epoch:20 step:18916 [D loss: 0.687597, acc.: 60.94%] [G loss: 0.829353]\n",
      "epoch:20 step:18917 [D loss: 0.773584, acc.: 45.31%] [G loss: 1.161922]\n",
      "epoch:20 step:18918 [D loss: 0.755192, acc.: 46.88%] [G loss: 0.786033]\n",
      "epoch:20 step:18919 [D loss: 0.839107, acc.: 39.06%] [G loss: 0.942337]\n",
      "epoch:20 step:18920 [D loss: 0.717700, acc.: 53.12%] [G loss: 0.844418]\n",
      "epoch:20 step:18921 [D loss: 0.632741, acc.: 61.72%] [G loss: 0.856028]\n",
      "epoch:20 step:18922 [D loss: 0.731527, acc.: 53.91%] [G loss: 0.854817]\n",
      "epoch:20 step:18923 [D loss: 0.876470, acc.: 36.72%] [G loss: 0.821394]\n",
      "epoch:20 step:18924 [D loss: 0.708354, acc.: 52.34%] [G loss: 1.095258]\n",
      "epoch:20 step:18925 [D loss: 0.888323, acc.: 32.81%] [G loss: 0.947403]\n",
      "epoch:20 step:18926 [D loss: 0.759922, acc.: 47.66%] [G loss: 0.974699]\n",
      "epoch:20 step:18927 [D loss: 0.843705, acc.: 38.28%] [G loss: 0.834055]\n",
      "epoch:20 step:18928 [D loss: 0.619203, acc.: 66.41%] [G loss: 1.029106]\n",
      "epoch:20 step:18929 [D loss: 0.681690, acc.: 57.81%] [G loss: 0.900636]\n",
      "epoch:20 step:18930 [D loss: 0.620971, acc.: 63.28%] [G loss: 0.961162]\n",
      "epoch:20 step:18931 [D loss: 0.635020, acc.: 61.72%] [G loss: 1.028351]\n",
      "epoch:20 step:18932 [D loss: 0.514205, acc.: 81.25%] [G loss: 1.122611]\n",
      "epoch:20 step:18933 [D loss: 0.594400, acc.: 70.31%] [G loss: 0.833223]\n",
      "epoch:20 step:18934 [D loss: 0.640213, acc.: 64.06%] [G loss: 0.984183]\n",
      "epoch:20 step:18935 [D loss: 0.662259, acc.: 58.59%] [G loss: 1.044898]\n",
      "epoch:20 step:18936 [D loss: 0.764281, acc.: 52.34%] [G loss: 0.799603]\n",
      "epoch:20 step:18937 [D loss: 0.738129, acc.: 50.00%] [G loss: 0.966675]\n",
      "epoch:20 step:18938 [D loss: 0.696513, acc.: 55.47%] [G loss: 1.040044]\n",
      "epoch:20 step:18939 [D loss: 0.607108, acc.: 71.09%] [G loss: 0.968905]\n",
      "epoch:20 step:18940 [D loss: 0.540947, acc.: 74.22%] [G loss: 1.224854]\n",
      "epoch:20 step:18941 [D loss: 0.412118, acc.: 85.94%] [G loss: 1.062713]\n",
      "epoch:20 step:18942 [D loss: 0.595655, acc.: 69.53%] [G loss: 1.095734]\n",
      "epoch:20 step:18943 [D loss: 0.754069, acc.: 49.22%] [G loss: 0.902576]\n",
      "epoch:20 step:18944 [D loss: 0.699339, acc.: 51.56%] [G loss: 1.003339]\n",
      "epoch:20 step:18945 [D loss: 0.715804, acc.: 50.00%] [G loss: 0.995618]\n",
      "epoch:20 step:18946 [D loss: 0.718533, acc.: 54.69%] [G loss: 0.921173]\n",
      "epoch:20 step:18947 [D loss: 0.616753, acc.: 67.19%] [G loss: 0.973322]\n",
      "epoch:20 step:18948 [D loss: 0.578800, acc.: 70.31%] [G loss: 1.177879]\n",
      "epoch:20 step:18949 [D loss: 0.507066, acc.: 79.69%] [G loss: 0.934142]\n",
      "epoch:20 step:18950 [D loss: 0.702706, acc.: 57.03%] [G loss: 0.992628]\n",
      "epoch:20 step:18951 [D loss: 0.625327, acc.: 67.97%] [G loss: 1.117907]\n",
      "epoch:20 step:18952 [D loss: 0.621264, acc.: 66.41%] [G loss: 1.192221]\n",
      "epoch:20 step:18953 [D loss: 0.498221, acc.: 80.47%] [G loss: 1.157970]\n",
      "epoch:20 step:18954 [D loss: 0.655014, acc.: 64.84%] [G loss: 1.117813]\n",
      "epoch:20 step:18955 [D loss: 0.632855, acc.: 64.84%] [G loss: 0.785428]\n",
      "epoch:20 step:18956 [D loss: 0.634255, acc.: 66.41%] [G loss: 1.114868]\n",
      "epoch:20 step:18957 [D loss: 0.665234, acc.: 64.06%] [G loss: 1.139001]\n",
      "epoch:20 step:18958 [D loss: 0.566291, acc.: 73.44%] [G loss: 1.087842]\n",
      "epoch:20 step:18959 [D loss: 0.617738, acc.: 67.19%] [G loss: 1.004103]\n",
      "epoch:20 step:18960 [D loss: 0.385359, acc.: 82.81%] [G loss: 1.141927]\n",
      "epoch:20 step:18961 [D loss: 0.396621, acc.: 86.72%] [G loss: 1.611059]\n",
      "epoch:20 step:18962 [D loss: 0.443938, acc.: 82.81%] [G loss: 1.447557]\n",
      "epoch:20 step:18963 [D loss: 0.295056, acc.: 96.09%] [G loss: 1.526608]\n",
      "epoch:20 step:18964 [D loss: 0.777349, acc.: 53.12%] [G loss: 1.466242]\n",
      "epoch:20 step:18965 [D loss: 0.695026, acc.: 55.47%] [G loss: 0.972667]\n",
      "epoch:20 step:18966 [D loss: 0.539744, acc.: 72.66%] [G loss: 1.050224]\n",
      "epoch:20 step:18967 [D loss: 0.699743, acc.: 58.59%] [G loss: 0.941410]\n",
      "epoch:20 step:18968 [D loss: 0.748727, acc.: 53.12%] [G loss: 0.864480]\n",
      "epoch:20 step:18969 [D loss: 0.614804, acc.: 67.19%] [G loss: 1.240579]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:18970 [D loss: 0.285986, acc.: 90.62%] [G loss: 1.215450]\n",
      "epoch:20 step:18971 [D loss: 0.354840, acc.: 93.75%] [G loss: 1.308821]\n",
      "epoch:20 step:18972 [D loss: 0.358501, acc.: 90.62%] [G loss: 1.374760]\n",
      "epoch:20 step:18973 [D loss: 0.930382, acc.: 34.38%] [G loss: 0.899490]\n",
      "epoch:20 step:18974 [D loss: 0.893893, acc.: 41.41%] [G loss: 1.104289]\n",
      "epoch:20 step:18975 [D loss: 0.509710, acc.: 77.34%] [G loss: 1.143485]\n",
      "epoch:20 step:18976 [D loss: 0.952333, acc.: 32.81%] [G loss: 0.628973]\n",
      "epoch:20 step:18977 [D loss: 0.575385, acc.: 69.53%] [G loss: 1.014199]\n",
      "epoch:20 step:18978 [D loss: 0.951872, acc.: 32.03%] [G loss: 0.749069]\n",
      "epoch:20 step:18979 [D loss: 0.800590, acc.: 40.62%] [G loss: 0.842444]\n",
      "epoch:20 step:18980 [D loss: 0.697121, acc.: 53.91%] [G loss: 0.976954]\n",
      "epoch:20 step:18981 [D loss: 0.585809, acc.: 69.53%] [G loss: 1.091429]\n",
      "epoch:20 step:18982 [D loss: 0.570301, acc.: 73.44%] [G loss: 1.288940]\n",
      "epoch:20 step:18983 [D loss: 0.632273, acc.: 61.72%] [G loss: 0.952136]\n",
      "epoch:20 step:18984 [D loss: 0.550485, acc.: 77.34%] [G loss: 1.053782]\n",
      "epoch:20 step:18985 [D loss: 0.463390, acc.: 83.59%] [G loss: 1.084150]\n",
      "epoch:20 step:18986 [D loss: 0.443361, acc.: 82.81%] [G loss: 1.263718]\n",
      "epoch:20 step:18987 [D loss: 0.445146, acc.: 85.94%] [G loss: 1.417670]\n",
      "epoch:20 step:18988 [D loss: 0.479898, acc.: 80.47%] [G loss: 0.983956]\n",
      "epoch:20 step:18989 [D loss: 0.753446, acc.: 53.91%] [G loss: 1.160854]\n",
      "epoch:20 step:18990 [D loss: 0.508478, acc.: 77.34%] [G loss: 1.250887]\n",
      "epoch:20 step:18991 [D loss: 0.702948, acc.: 58.59%] [G loss: 0.886541]\n",
      "epoch:20 step:18992 [D loss: 0.650520, acc.: 59.38%] [G loss: 1.120701]\n",
      "epoch:20 step:18993 [D loss: 0.696125, acc.: 57.03%] [G loss: 0.937159]\n",
      "epoch:20 step:18994 [D loss: 0.810226, acc.: 42.19%] [G loss: 0.868728]\n",
      "epoch:20 step:18995 [D loss: 0.782405, acc.: 48.44%] [G loss: 1.107861]\n",
      "epoch:20 step:18996 [D loss: 0.761117, acc.: 46.09%] [G loss: 0.890062]\n",
      "epoch:20 step:18997 [D loss: 0.787107, acc.: 43.75%] [G loss: 0.729692]\n",
      "epoch:20 step:18998 [D loss: 0.901358, acc.: 42.19%] [G loss: 0.706381]\n",
      "epoch:20 step:18999 [D loss: 0.650060, acc.: 64.84%] [G loss: 1.268730]\n",
      "epoch:20 step:19000 [D loss: 0.582094, acc.: 71.88%] [G loss: 1.262340]\n",
      "##############\n",
      "[2.29063147 1.43589217 5.45014985 4.49545254 3.0617926  5.42520018\n",
      " 4.24095184 4.5780758  4.10599151 3.56379965]\n",
      "##########\n",
      "epoch:20 step:19001 [D loss: 0.513543, acc.: 72.66%] [G loss: 1.004511]\n",
      "epoch:20 step:19002 [D loss: 0.598285, acc.: 71.88%] [G loss: 1.056631]\n",
      "epoch:20 step:19003 [D loss: 0.742051, acc.: 42.19%] [G loss: 0.918836]\n",
      "epoch:20 step:19004 [D loss: 0.599622, acc.: 69.53%] [G loss: 0.965054]\n",
      "epoch:20 step:19005 [D loss: 0.641005, acc.: 64.84%] [G loss: 1.058040]\n",
      "epoch:20 step:19006 [D loss: 0.692522, acc.: 57.03%] [G loss: 0.888626]\n",
      "epoch:20 step:19007 [D loss: 0.591403, acc.: 71.09%] [G loss: 0.905736]\n",
      "epoch:20 step:19008 [D loss: 0.542398, acc.: 75.78%] [G loss: 1.356764]\n",
      "epoch:20 step:19009 [D loss: 0.638844, acc.: 61.72%] [G loss: 1.213421]\n",
      "epoch:20 step:19010 [D loss: 0.637682, acc.: 63.28%] [G loss: 0.912245]\n",
      "epoch:20 step:19011 [D loss: 0.634469, acc.: 63.28%] [G loss: 1.135144]\n",
      "epoch:20 step:19012 [D loss: 0.498488, acc.: 80.47%] [G loss: 1.100328]\n",
      "epoch:20 step:19013 [D loss: 0.624871, acc.: 64.84%] [G loss: 1.121057]\n",
      "epoch:20 step:19014 [D loss: 0.638671, acc.: 61.72%] [G loss: 1.075861]\n",
      "epoch:20 step:19015 [D loss: 0.813278, acc.: 41.41%] [G loss: 0.842909]\n",
      "epoch:20 step:19016 [D loss: 0.736997, acc.: 48.44%] [G loss: 0.873953]\n",
      "epoch:20 step:19017 [D loss: 0.647193, acc.: 61.72%] [G loss: 1.000359]\n",
      "epoch:20 step:19018 [D loss: 0.440433, acc.: 82.03%] [G loss: 1.192174]\n",
      "epoch:20 step:19019 [D loss: 0.308903, acc.: 93.75%] [G loss: 1.250380]\n",
      "epoch:20 step:19020 [D loss: 0.410037, acc.: 89.06%] [G loss: 1.228933]\n",
      "epoch:20 step:19021 [D loss: 0.776453, acc.: 48.44%] [G loss: 1.257832]\n",
      "epoch:20 step:19022 [D loss: 0.875798, acc.: 35.16%] [G loss: 0.978656]\n",
      "epoch:20 step:19023 [D loss: 0.610359, acc.: 68.75%] [G loss: 1.078876]\n",
      "epoch:20 step:19024 [D loss: 0.476477, acc.: 76.56%] [G loss: 1.043282]\n",
      "epoch:20 step:19025 [D loss: 0.331974, acc.: 93.75%] [G loss: 1.106842]\n",
      "epoch:20 step:19026 [D loss: 0.369608, acc.: 93.75%] [G loss: 1.274524]\n",
      "epoch:20 step:19027 [D loss: 0.504863, acc.: 79.69%] [G loss: 1.353261]\n",
      "epoch:20 step:19028 [D loss: 0.527736, acc.: 75.00%] [G loss: 1.270855]\n",
      "epoch:20 step:19029 [D loss: 0.560278, acc.: 67.97%] [G loss: 1.060829]\n",
      "epoch:20 step:19030 [D loss: 0.642102, acc.: 63.28%] [G loss: 1.180850]\n",
      "epoch:20 step:19031 [D loss: 0.485539, acc.: 82.03%] [G loss: 1.252949]\n",
      "epoch:20 step:19032 [D loss: 0.740225, acc.: 53.91%] [G loss: 0.739697]\n",
      "epoch:20 step:19033 [D loss: 0.382171, acc.: 90.62%] [G loss: 1.417621]\n",
      "epoch:20 step:19034 [D loss: 0.811528, acc.: 50.00%] [G loss: 0.811304]\n",
      "epoch:20 step:19035 [D loss: 0.941550, acc.: 34.38%] [G loss: 1.002058]\n",
      "epoch:20 step:19036 [D loss: 0.809389, acc.: 44.53%] [G loss: 1.022065]\n",
      "epoch:20 step:19037 [D loss: 0.788231, acc.: 45.31%] [G loss: 1.058243]\n",
      "epoch:20 step:19038 [D loss: 0.613287, acc.: 68.75%] [G loss: 1.157240]\n",
      "epoch:20 step:19039 [D loss: 0.619157, acc.: 65.62%] [G loss: 1.369018]\n",
      "epoch:20 step:19040 [D loss: 0.547761, acc.: 73.44%] [G loss: 1.263128]\n",
      "epoch:20 step:19041 [D loss: 0.773400, acc.: 50.00%] [G loss: 1.133216]\n",
      "epoch:20 step:19042 [D loss: 0.655748, acc.: 56.25%] [G loss: 1.057596]\n",
      "epoch:20 step:19043 [D loss: 0.572564, acc.: 70.31%] [G loss: 1.006173]\n",
      "epoch:20 step:19044 [D loss: 0.587306, acc.: 67.97%] [G loss: 1.125646]\n",
      "epoch:20 step:19045 [D loss: 0.622806, acc.: 61.72%] [G loss: 1.019365]\n",
      "epoch:20 step:19046 [D loss: 0.562746, acc.: 69.53%] [G loss: 0.934714]\n",
      "epoch:20 step:19047 [D loss: 0.487273, acc.: 77.34%] [G loss: 1.103631]\n",
      "epoch:20 step:19048 [D loss: 0.671038, acc.: 53.91%] [G loss: 1.084042]\n",
      "epoch:20 step:19049 [D loss: 0.593944, acc.: 67.97%] [G loss: 1.009282]\n",
      "epoch:20 step:19050 [D loss: 0.701969, acc.: 57.03%] [G loss: 0.942250]\n",
      "epoch:20 step:19051 [D loss: 0.598530, acc.: 71.09%] [G loss: 1.114151]\n",
      "epoch:20 step:19052 [D loss: 0.453181, acc.: 85.94%] [G loss: 1.254350]\n",
      "epoch:20 step:19053 [D loss: 0.587404, acc.: 65.62%] [G loss: 1.099473]\n",
      "epoch:20 step:19054 [D loss: 0.536582, acc.: 78.12%] [G loss: 1.141197]\n",
      "epoch:20 step:19055 [D loss: 0.622950, acc.: 64.84%] [G loss: 0.966196]\n",
      "epoch:20 step:19056 [D loss: 0.520279, acc.: 78.91%] [G loss: 1.033574]\n",
      "epoch:20 step:19057 [D loss: 0.574475, acc.: 72.66%] [G loss: 1.092039]\n",
      "epoch:20 step:19058 [D loss: 0.501680, acc.: 78.12%] [G loss: 0.928882]\n",
      "epoch:20 step:19059 [D loss: 0.700479, acc.: 50.78%] [G loss: 1.138867]\n",
      "epoch:20 step:19060 [D loss: 0.530450, acc.: 75.78%] [G loss: 1.183321]\n",
      "epoch:20 step:19061 [D loss: 0.448487, acc.: 88.28%] [G loss: 0.958121]\n",
      "epoch:20 step:19062 [D loss: 0.438331, acc.: 85.94%] [G loss: 1.181797]\n",
      "epoch:20 step:19063 [D loss: 0.810549, acc.: 46.88%] [G loss: 0.907047]\n",
      "epoch:20 step:19064 [D loss: 0.667476, acc.: 58.59%] [G loss: 1.022882]\n",
      "epoch:20 step:19065 [D loss: 0.647947, acc.: 60.94%] [G loss: 0.959860]\n",
      "epoch:20 step:19066 [D loss: 0.584137, acc.: 67.97%] [G loss: 0.998483]\n",
      "epoch:20 step:19067 [D loss: 0.389938, acc.: 88.28%] [G loss: 1.091909]\n",
      "epoch:20 step:19068 [D loss: 0.354345, acc.: 92.97%] [G loss: 1.305039]\n",
      "epoch:20 step:19069 [D loss: 0.637375, acc.: 63.28%] [G loss: 1.133157]\n",
      "epoch:20 step:19070 [D loss: 0.901780, acc.: 35.16%] [G loss: 1.109343]\n",
      "epoch:20 step:19071 [D loss: 0.867694, acc.: 39.84%] [G loss: 0.744152]\n",
      "epoch:20 step:19072 [D loss: 0.845040, acc.: 41.41%] [G loss: 0.845822]\n",
      "epoch:20 step:19073 [D loss: 0.809962, acc.: 39.84%] [G loss: 0.804831]\n",
      "epoch:20 step:19074 [D loss: 0.657699, acc.: 56.25%] [G loss: 0.925378]\n",
      "epoch:20 step:19075 [D loss: 0.682737, acc.: 58.59%] [G loss: 1.111299]\n",
      "epoch:20 step:19076 [D loss: 0.558228, acc.: 71.09%] [G loss: 1.103672]\n",
      "epoch:20 step:19077 [D loss: 0.656730, acc.: 60.16%] [G loss: 0.833207]\n",
      "epoch:20 step:19078 [D loss: 0.643334, acc.: 63.28%] [G loss: 0.983987]\n",
      "epoch:20 step:19079 [D loss: 0.650441, acc.: 62.50%] [G loss: 1.025432]\n",
      "epoch:20 step:19080 [D loss: 0.567679, acc.: 73.44%] [G loss: 1.259348]\n",
      "epoch:20 step:19081 [D loss: 0.510854, acc.: 75.78%] [G loss: 1.012345]\n",
      "epoch:20 step:19082 [D loss: 0.387050, acc.: 82.03%] [G loss: 1.339828]\n",
      "epoch:20 step:19083 [D loss: 0.266261, acc.: 96.09%] [G loss: 1.656881]\n",
      "epoch:20 step:19084 [D loss: 0.405203, acc.: 89.84%] [G loss: 1.681636]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19085 [D loss: 0.249467, acc.: 96.88%] [G loss: 1.780564]\n",
      "epoch:20 step:19086 [D loss: 0.272142, acc.: 91.41%] [G loss: 1.407735]\n",
      "epoch:20 step:19087 [D loss: 0.235957, acc.: 98.44%] [G loss: 1.781305]\n",
      "epoch:20 step:19088 [D loss: 0.794603, acc.: 50.00%] [G loss: 1.284429]\n",
      "epoch:20 step:19089 [D loss: 0.893655, acc.: 43.75%] [G loss: 1.097257]\n",
      "epoch:20 step:19090 [D loss: 0.695169, acc.: 54.69%] [G loss: 0.987980]\n",
      "epoch:20 step:19091 [D loss: 0.625772, acc.: 66.41%] [G loss: 1.082666]\n",
      "epoch:20 step:19092 [D loss: 0.713650, acc.: 53.12%] [G loss: 0.906960]\n",
      "epoch:20 step:19093 [D loss: 0.784019, acc.: 42.19%] [G loss: 0.891273]\n",
      "epoch:20 step:19094 [D loss: 0.589655, acc.: 68.75%] [G loss: 1.081013]\n",
      "epoch:20 step:19095 [D loss: 0.761386, acc.: 49.22%] [G loss: 1.070748]\n",
      "epoch:20 step:19096 [D loss: 0.688981, acc.: 57.81%] [G loss: 0.898899]\n",
      "epoch:20 step:19097 [D loss: 0.580654, acc.: 66.41%] [G loss: 1.055512]\n",
      "epoch:20 step:19098 [D loss: 0.564493, acc.: 73.44%] [G loss: 1.083538]\n",
      "epoch:20 step:19099 [D loss: 0.585955, acc.: 71.09%] [G loss: 1.106919]\n",
      "epoch:20 step:19100 [D loss: 0.525899, acc.: 80.47%] [G loss: 1.017252]\n",
      "epoch:20 step:19101 [D loss: 0.587302, acc.: 65.62%] [G loss: 1.053651]\n",
      "epoch:20 step:19102 [D loss: 0.748223, acc.: 47.66%] [G loss: 1.134840]\n",
      "epoch:20 step:19103 [D loss: 0.606296, acc.: 71.09%] [G loss: 0.886588]\n",
      "epoch:20 step:19104 [D loss: 0.637427, acc.: 60.94%] [G loss: 1.113925]\n",
      "epoch:20 step:19105 [D loss: 0.652727, acc.: 64.84%] [G loss: 0.952661]\n",
      "epoch:20 step:19106 [D loss: 0.398595, acc.: 90.62%] [G loss: 0.982292]\n",
      "epoch:20 step:19107 [D loss: 0.452052, acc.: 82.81%] [G loss: 1.173019]\n",
      "epoch:20 step:19108 [D loss: 0.628698, acc.: 64.84%] [G loss: 1.083876]\n",
      "epoch:20 step:19109 [D loss: 0.630889, acc.: 60.16%] [G loss: 1.098398]\n",
      "epoch:20 step:19110 [D loss: 0.444109, acc.: 85.94%] [G loss: 1.304008]\n",
      "epoch:20 step:19111 [D loss: 0.587568, acc.: 71.09%] [G loss: 0.899189]\n",
      "epoch:20 step:19112 [D loss: 0.628388, acc.: 65.62%] [G loss: 0.881059]\n",
      "epoch:20 step:19113 [D loss: 0.725693, acc.: 56.25%] [G loss: 1.039294]\n",
      "epoch:20 step:19114 [D loss: 0.708080, acc.: 55.47%] [G loss: 0.744827]\n",
      "epoch:20 step:19115 [D loss: 0.664352, acc.: 57.03%] [G loss: 1.077253]\n",
      "epoch:20 step:19116 [D loss: 0.791924, acc.: 48.44%] [G loss: 0.928655]\n",
      "epoch:20 step:19117 [D loss: 0.638342, acc.: 61.72%] [G loss: 1.002459]\n",
      "epoch:20 step:19118 [D loss: 0.560879, acc.: 70.31%] [G loss: 0.973711]\n",
      "epoch:20 step:19119 [D loss: 0.540258, acc.: 71.88%] [G loss: 0.987179]\n",
      "epoch:20 step:19120 [D loss: 0.437765, acc.: 85.16%] [G loss: 1.329390]\n",
      "epoch:20 step:19121 [D loss: 0.431793, acc.: 85.94%] [G loss: 1.005352]\n",
      "epoch:20 step:19122 [D loss: 0.607657, acc.: 71.09%] [G loss: 0.997801]\n",
      "epoch:20 step:19123 [D loss: 0.691197, acc.: 58.59%] [G loss: 1.029454]\n",
      "epoch:20 step:19124 [D loss: 0.678257, acc.: 61.72%] [G loss: 0.881604]\n",
      "epoch:20 step:19125 [D loss: 0.609746, acc.: 62.50%] [G loss: 1.029123]\n",
      "epoch:20 step:19126 [D loss: 0.707288, acc.: 54.69%] [G loss: 0.899335]\n",
      "epoch:20 step:19127 [D loss: 0.477684, acc.: 85.16%] [G loss: 1.218057]\n",
      "epoch:20 step:19128 [D loss: 0.533796, acc.: 80.47%] [G loss: 1.151481]\n",
      "epoch:20 step:19129 [D loss: 0.679871, acc.: 57.81%] [G loss: 1.052023]\n",
      "epoch:20 step:19130 [D loss: 0.677508, acc.: 58.59%] [G loss: 0.829365]\n",
      "epoch:20 step:19131 [D loss: 0.583046, acc.: 68.75%] [G loss: 0.999534]\n",
      "epoch:20 step:19132 [D loss: 0.665120, acc.: 58.59%] [G loss: 1.090158]\n",
      "epoch:20 step:19133 [D loss: 0.836823, acc.: 41.41%] [G loss: 1.011290]\n",
      "epoch:20 step:19134 [D loss: 0.539810, acc.: 77.34%] [G loss: 1.095857]\n",
      "epoch:20 step:19135 [D loss: 0.685573, acc.: 57.03%] [G loss: 1.001610]\n",
      "epoch:20 step:19136 [D loss: 0.441228, acc.: 86.72%] [G loss: 1.047637]\n",
      "epoch:20 step:19137 [D loss: 0.296733, acc.: 92.19%] [G loss: 1.172212]\n",
      "epoch:20 step:19138 [D loss: 0.336028, acc.: 89.84%] [G loss: 1.259133]\n",
      "epoch:20 step:19139 [D loss: 0.333232, acc.: 96.88%] [G loss: 1.463119]\n",
      "epoch:20 step:19140 [D loss: 0.359941, acc.: 89.84%] [G loss: 1.640107]\n",
      "epoch:20 step:19141 [D loss: 0.484693, acc.: 80.47%] [G loss: 1.164828]\n",
      "epoch:20 step:19142 [D loss: 0.465954, acc.: 78.91%] [G loss: 1.056911]\n",
      "epoch:20 step:19143 [D loss: 0.598735, acc.: 65.62%] [G loss: 1.212481]\n",
      "epoch:20 step:19144 [D loss: 0.260126, acc.: 95.31%] [G loss: 1.543411]\n",
      "epoch:20 step:19145 [D loss: 0.273285, acc.: 95.31%] [G loss: 1.596740]\n",
      "epoch:20 step:19146 [D loss: 0.305758, acc.: 94.53%] [G loss: 1.552382]\n",
      "epoch:20 step:19147 [D loss: 0.432044, acc.: 85.94%] [G loss: 1.362732]\n",
      "epoch:20 step:19148 [D loss: 0.465705, acc.: 82.81%] [G loss: 1.450188]\n",
      "epoch:20 step:19149 [D loss: 0.527385, acc.: 73.44%] [G loss: 1.083742]\n",
      "epoch:20 step:19150 [D loss: 0.400836, acc.: 90.62%] [G loss: 1.311578]\n",
      "epoch:20 step:19151 [D loss: 0.807028, acc.: 50.78%] [G loss: 1.018604]\n",
      "epoch:20 step:19152 [D loss: 0.811629, acc.: 48.44%] [G loss: 1.023110]\n",
      "epoch:20 step:19153 [D loss: 0.772964, acc.: 43.75%] [G loss: 0.963976]\n",
      "epoch:20 step:19154 [D loss: 0.555308, acc.: 72.66%] [G loss: 1.093928]\n",
      "epoch:20 step:19155 [D loss: 0.839380, acc.: 44.53%] [G loss: 0.925698]\n",
      "epoch:20 step:19156 [D loss: 0.858447, acc.: 46.88%] [G loss: 0.634960]\n",
      "epoch:20 step:19157 [D loss: 0.789251, acc.: 48.44%] [G loss: 0.996385]\n",
      "epoch:20 step:19158 [D loss: 0.575927, acc.: 67.19%] [G loss: 0.967058]\n",
      "epoch:20 step:19159 [D loss: 0.453051, acc.: 81.25%] [G loss: 1.126117]\n",
      "epoch:20 step:19160 [D loss: 0.712568, acc.: 53.12%] [G loss: 1.083037]\n",
      "epoch:20 step:19161 [D loss: 1.045964, acc.: 28.91%] [G loss: 0.715867]\n",
      "epoch:20 step:19162 [D loss: 0.861174, acc.: 46.09%] [G loss: 1.108109]\n",
      "epoch:20 step:19163 [D loss: 0.995723, acc.: 25.78%] [G loss: 0.916782]\n",
      "epoch:20 step:19164 [D loss: 0.651205, acc.: 62.50%] [G loss: 1.213309]\n",
      "epoch:20 step:19165 [D loss: 0.623062, acc.: 62.50%] [G loss: 1.251240]\n",
      "epoch:20 step:19166 [D loss: 0.602582, acc.: 65.62%] [G loss: 1.089960]\n",
      "epoch:20 step:19167 [D loss: 0.646574, acc.: 64.06%] [G loss: 1.091008]\n",
      "epoch:20 step:19168 [D loss: 0.611287, acc.: 67.19%] [G loss: 1.057363]\n",
      "epoch:20 step:19169 [D loss: 0.597909, acc.: 65.62%] [G loss: 1.154214]\n",
      "epoch:20 step:19170 [D loss: 0.599277, acc.: 67.19%] [G loss: 1.273695]\n",
      "epoch:20 step:19171 [D loss: 0.724552, acc.: 57.03%] [G loss: 1.122515]\n",
      "epoch:20 step:19172 [D loss: 0.719852, acc.: 57.81%] [G loss: 1.099155]\n",
      "epoch:20 step:19173 [D loss: 0.584542, acc.: 66.41%] [G loss: 1.144963]\n",
      "epoch:20 step:19174 [D loss: 0.618469, acc.: 65.62%] [G loss: 1.250480]\n",
      "epoch:20 step:19175 [D loss: 0.525438, acc.: 74.22%] [G loss: 1.265168]\n",
      "epoch:20 step:19176 [D loss: 0.504912, acc.: 80.47%] [G loss: 1.243127]\n",
      "epoch:20 step:19177 [D loss: 0.798139, acc.: 47.66%] [G loss: 1.145146]\n",
      "epoch:20 step:19178 [D loss: 0.714482, acc.: 54.69%] [G loss: 0.843136]\n",
      "epoch:20 step:19179 [D loss: 0.743232, acc.: 49.22%] [G loss: 1.032074]\n",
      "epoch:20 step:19180 [D loss: 0.622854, acc.: 59.38%] [G loss: 1.253120]\n",
      "epoch:20 step:19181 [D loss: 0.734998, acc.: 49.22%] [G loss: 1.015719]\n",
      "epoch:20 step:19182 [D loss: 0.794822, acc.: 43.75%] [G loss: 1.118285]\n",
      "epoch:20 step:19183 [D loss: 0.556484, acc.: 72.66%] [G loss: 1.010397]\n",
      "epoch:20 step:19184 [D loss: 0.697625, acc.: 56.25%] [G loss: 0.967252]\n",
      "epoch:20 step:19185 [D loss: 0.631069, acc.: 61.72%] [G loss: 1.084336]\n",
      "epoch:20 step:19186 [D loss: 0.841672, acc.: 40.62%] [G loss: 0.995528]\n",
      "epoch:20 step:19187 [D loss: 0.672963, acc.: 56.25%] [G loss: 0.890993]\n",
      "epoch:20 step:19188 [D loss: 0.542155, acc.: 70.31%] [G loss: 1.278117]\n",
      "epoch:20 step:19189 [D loss: 0.442937, acc.: 85.94%] [G loss: 1.475080]\n",
      "epoch:20 step:19190 [D loss: 0.643585, acc.: 63.28%] [G loss: 1.427762]\n",
      "epoch:20 step:19191 [D loss: 0.472202, acc.: 82.81%] [G loss: 1.422710]\n",
      "epoch:20 step:19192 [D loss: 0.534679, acc.: 76.56%] [G loss: 1.252297]\n",
      "epoch:20 step:19193 [D loss: 0.593596, acc.: 67.19%] [G loss: 1.313502]\n",
      "epoch:20 step:19194 [D loss: 0.591962, acc.: 67.19%] [G loss: 1.400894]\n",
      "epoch:20 step:19195 [D loss: 0.684868, acc.: 62.50%] [G loss: 1.220585]\n",
      "epoch:20 step:19196 [D loss: 0.553462, acc.: 72.66%] [G loss: 1.133037]\n",
      "epoch:20 step:19197 [D loss: 0.535637, acc.: 75.00%] [G loss: 1.070773]\n",
      "epoch:20 step:19198 [D loss: 0.901460, acc.: 46.88%] [G loss: 1.080091]\n",
      "epoch:20 step:19199 [D loss: 0.831873, acc.: 42.19%] [G loss: 0.778494]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19200 [D loss: 0.839633, acc.: 45.31%] [G loss: 0.825847]\n",
      "##############\n",
      "[2.483718   1.55054397 5.58105477 4.65964445 3.18502278 5.81718728\n",
      " 4.09366924 4.38729871 4.37970014 3.95641121]\n",
      "##########\n",
      "epoch:20 step:19201 [D loss: 0.838767, acc.: 39.06%] [G loss: 1.033594]\n",
      "epoch:20 step:19202 [D loss: 0.851474, acc.: 42.19%] [G loss: 0.983831]\n",
      "epoch:20 step:19203 [D loss: 0.897705, acc.: 40.62%] [G loss: 0.886015]\n",
      "epoch:20 step:19204 [D loss: 0.656404, acc.: 58.59%] [G loss: 0.954390]\n",
      "epoch:20 step:19205 [D loss: 0.551991, acc.: 72.66%] [G loss: 1.122297]\n",
      "epoch:20 step:19206 [D loss: 0.624471, acc.: 66.41%] [G loss: 1.131906]\n",
      "epoch:20 step:19207 [D loss: 0.745495, acc.: 53.91%] [G loss: 0.971995]\n",
      "epoch:20 step:19208 [D loss: 0.658988, acc.: 58.59%] [G loss: 1.116609]\n",
      "epoch:20 step:19209 [D loss: 0.608254, acc.: 67.19%] [G loss: 1.108698]\n",
      "epoch:20 step:19210 [D loss: 0.365720, acc.: 94.53%] [G loss: 1.194681]\n",
      "epoch:20 step:19211 [D loss: 0.356888, acc.: 89.06%] [G loss: 1.328507]\n",
      "epoch:20 step:19212 [D loss: 0.510453, acc.: 72.66%] [G loss: 1.258150]\n",
      "epoch:20 step:19213 [D loss: 0.659878, acc.: 61.72%] [G loss: 1.280952]\n",
      "epoch:20 step:19214 [D loss: 0.509924, acc.: 78.91%] [G loss: 1.310867]\n",
      "epoch:20 step:19215 [D loss: 0.562701, acc.: 73.44%] [G loss: 1.269430]\n",
      "epoch:20 step:19216 [D loss: 0.686665, acc.: 60.94%] [G loss: 1.089042]\n",
      "epoch:20 step:19217 [D loss: 0.706460, acc.: 59.38%] [G loss: 1.111889]\n",
      "epoch:20 step:19218 [D loss: 0.622652, acc.: 63.28%] [G loss: 1.139727]\n",
      "epoch:20 step:19219 [D loss: 0.590835, acc.: 68.75%] [G loss: 0.994809]\n",
      "epoch:20 step:19220 [D loss: 0.778841, acc.: 50.78%] [G loss: 1.156217]\n",
      "epoch:20 step:19221 [D loss: 0.603913, acc.: 61.72%] [G loss: 0.995702]\n",
      "epoch:20 step:19222 [D loss: 0.596866, acc.: 65.62%] [G loss: 1.309960]\n",
      "epoch:20 step:19223 [D loss: 0.488452, acc.: 81.25%] [G loss: 1.084476]\n",
      "epoch:20 step:19224 [D loss: 0.471456, acc.: 79.69%] [G loss: 1.127901]\n",
      "epoch:20 step:19225 [D loss: 0.525520, acc.: 78.91%] [G loss: 1.258877]\n",
      "epoch:20 step:19226 [D loss: 0.542298, acc.: 75.00%] [G loss: 0.976922]\n",
      "epoch:20 step:19227 [D loss: 0.509112, acc.: 79.69%] [G loss: 1.137361]\n",
      "epoch:20 step:19228 [D loss: 0.599180, acc.: 64.84%] [G loss: 1.029804]\n",
      "epoch:20 step:19229 [D loss: 0.599561, acc.: 68.75%] [G loss: 1.021033]\n",
      "epoch:20 step:19230 [D loss: 0.547276, acc.: 71.88%] [G loss: 1.009145]\n",
      "epoch:20 step:19231 [D loss: 0.559798, acc.: 71.88%] [G loss: 1.167210]\n",
      "epoch:20 step:19232 [D loss: 0.729881, acc.: 48.44%] [G loss: 1.130868]\n",
      "epoch:20 step:19233 [D loss: 0.717622, acc.: 54.69%] [G loss: 1.109236]\n",
      "epoch:20 step:19234 [D loss: 0.653839, acc.: 62.50%] [G loss: 0.839534]\n",
      "epoch:20 step:19235 [D loss: 0.581283, acc.: 68.75%] [G loss: 1.120487]\n",
      "epoch:20 step:19236 [D loss: 0.637296, acc.: 67.97%] [G loss: 0.945811]\n",
      "epoch:20 step:19237 [D loss: 0.468414, acc.: 82.81%] [G loss: 1.238410]\n",
      "epoch:20 step:19238 [D loss: 0.504192, acc.: 78.91%] [G loss: 1.125108]\n",
      "epoch:20 step:19239 [D loss: 0.347987, acc.: 92.97%] [G loss: 1.195830]\n",
      "epoch:20 step:19240 [D loss: 0.813682, acc.: 46.09%] [G loss: 1.257226]\n",
      "epoch:20 step:19241 [D loss: 0.940219, acc.: 35.16%] [G loss: 0.884196]\n",
      "epoch:20 step:19242 [D loss: 0.646647, acc.: 64.06%] [G loss: 0.930697]\n",
      "epoch:20 step:19243 [D loss: 0.407976, acc.: 78.91%] [G loss: 1.199252]\n",
      "epoch:20 step:19244 [D loss: 0.315171, acc.: 89.84%] [G loss: 1.371751]\n",
      "epoch:20 step:19245 [D loss: 0.462889, acc.: 84.38%] [G loss: 1.337500]\n",
      "epoch:20 step:19246 [D loss: 0.388753, acc.: 91.41%] [G loss: 1.388018]\n",
      "epoch:20 step:19247 [D loss: 0.411985, acc.: 82.81%] [G loss: 1.465769]\n",
      "epoch:20 step:19248 [D loss: 0.285626, acc.: 97.66%] [G loss: 1.571251]\n",
      "epoch:20 step:19249 [D loss: 0.759180, acc.: 45.31%] [G loss: 0.877611]\n",
      "epoch:20 step:19250 [D loss: 0.799897, acc.: 44.53%] [G loss: 0.906649]\n",
      "epoch:20 step:19251 [D loss: 0.587028, acc.: 67.97%] [G loss: 1.142312]\n",
      "epoch:20 step:19252 [D loss: 0.657924, acc.: 60.16%] [G loss: 1.042125]\n",
      "epoch:20 step:19253 [D loss: 0.593720, acc.: 69.53%] [G loss: 1.012637]\n",
      "epoch:20 step:19254 [D loss: 0.500861, acc.: 81.25%] [G loss: 1.213862]\n",
      "epoch:20 step:19255 [D loss: 0.560856, acc.: 70.31%] [G loss: 1.072924]\n",
      "epoch:20 step:19256 [D loss: 0.650273, acc.: 58.59%] [G loss: 1.032816]\n",
      "epoch:20 step:19257 [D loss: 0.550921, acc.: 76.56%] [G loss: 1.155216]\n",
      "epoch:20 step:19258 [D loss: 0.525345, acc.: 78.91%] [G loss: 1.206544]\n",
      "epoch:20 step:19259 [D loss: 0.401412, acc.: 89.84%] [G loss: 1.442500]\n",
      "epoch:20 step:19260 [D loss: 0.549093, acc.: 72.66%] [G loss: 1.037321]\n",
      "epoch:20 step:19261 [D loss: 0.699188, acc.: 62.50%] [G loss: 0.949364]\n",
      "epoch:20 step:19262 [D loss: 0.550450, acc.: 78.12%] [G loss: 1.081010]\n",
      "epoch:20 step:19263 [D loss: 0.497916, acc.: 78.91%] [G loss: 1.317546]\n",
      "epoch:20 step:19264 [D loss: 0.612583, acc.: 70.31%] [G loss: 0.956697]\n",
      "epoch:20 step:19265 [D loss: 0.468521, acc.: 86.72%] [G loss: 1.282202]\n",
      "epoch:20 step:19266 [D loss: 0.576266, acc.: 70.31%] [G loss: 1.113911]\n",
      "epoch:20 step:19267 [D loss: 0.635889, acc.: 65.62%] [G loss: 1.146002]\n",
      "epoch:20 step:19268 [D loss: 0.703131, acc.: 49.22%] [G loss: 0.968483]\n",
      "epoch:20 step:19269 [D loss: 0.453123, acc.: 88.28%] [G loss: 1.303626]\n",
      "epoch:20 step:19270 [D loss: 0.589410, acc.: 68.75%] [G loss: 0.917199]\n",
      "epoch:20 step:19271 [D loss: 0.644353, acc.: 60.94%] [G loss: 1.090919]\n",
      "epoch:20 step:19272 [D loss: 0.764538, acc.: 53.91%] [G loss: 0.921046]\n",
      "epoch:20 step:19273 [D loss: 0.392493, acc.: 89.06%] [G loss: 1.450977]\n",
      "epoch:20 step:19274 [D loss: 0.484351, acc.: 83.59%] [G loss: 1.446490]\n",
      "epoch:20 step:19275 [D loss: 0.591376, acc.: 66.41%] [G loss: 1.014769]\n",
      "epoch:20 step:19276 [D loss: 0.471557, acc.: 82.03%] [G loss: 1.239696]\n",
      "epoch:20 step:19277 [D loss: 0.418755, acc.: 91.41%] [G loss: 1.375789]\n",
      "epoch:20 step:19278 [D loss: 0.557156, acc.: 71.88%] [G loss: 1.139567]\n",
      "epoch:20 step:19279 [D loss: 0.646623, acc.: 62.50%] [G loss: 1.011952]\n",
      "epoch:20 step:19280 [D loss: 0.669644, acc.: 62.50%] [G loss: 1.079402]\n",
      "epoch:20 step:19281 [D loss: 0.702003, acc.: 53.91%] [G loss: 0.907189]\n",
      "epoch:20 step:19282 [D loss: 0.556160, acc.: 74.22%] [G loss: 1.066375]\n",
      "epoch:20 step:19283 [D loss: 0.724501, acc.: 50.00%] [G loss: 0.893921]\n",
      "epoch:20 step:19284 [D loss: 0.598675, acc.: 70.31%] [G loss: 1.031246]\n",
      "epoch:20 step:19285 [D loss: 0.491509, acc.: 82.03%] [G loss: 1.160430]\n",
      "epoch:20 step:19286 [D loss: 0.435253, acc.: 86.72%] [G loss: 1.205714]\n",
      "epoch:20 step:19287 [D loss: 0.387552, acc.: 89.84%] [G loss: 1.324061]\n",
      "epoch:20 step:19288 [D loss: 0.479575, acc.: 81.25%] [G loss: 1.105803]\n",
      "epoch:20 step:19289 [D loss: 0.358701, acc.: 90.62%] [G loss: 1.202603]\n",
      "epoch:20 step:19290 [D loss: 0.356827, acc.: 89.84%] [G loss: 1.308626]\n",
      "epoch:20 step:19291 [D loss: 0.322393, acc.: 93.75%] [G loss: 1.353462]\n",
      "epoch:20 step:19292 [D loss: 0.453465, acc.: 83.59%] [G loss: 1.344913]\n",
      "epoch:20 step:19293 [D loss: 0.463502, acc.: 84.38%] [G loss: 1.234855]\n",
      "epoch:20 step:19294 [D loss: 0.317211, acc.: 93.75%] [G loss: 1.361592]\n",
      "epoch:20 step:19295 [D loss: 0.419261, acc.: 89.06%] [G loss: 1.380076]\n",
      "epoch:20 step:19296 [D loss: 0.306299, acc.: 94.53%] [G loss: 1.457287]\n",
      "epoch:20 step:19297 [D loss: 0.419043, acc.: 84.38%] [G loss: 1.167429]\n",
      "epoch:20 step:19298 [D loss: 0.458838, acc.: 80.47%] [G loss: 1.362442]\n",
      "epoch:20 step:19299 [D loss: 0.782463, acc.: 55.47%] [G loss: 1.482467]\n",
      "epoch:20 step:19300 [D loss: 0.867998, acc.: 43.75%] [G loss: 1.241993]\n",
      "epoch:20 step:19301 [D loss: 0.544676, acc.: 74.22%] [G loss: 1.285632]\n",
      "epoch:20 step:19302 [D loss: 0.656231, acc.: 64.06%] [G loss: 1.023162]\n",
      "epoch:20 step:19303 [D loss: 0.596066, acc.: 70.31%] [G loss: 1.148973]\n",
      "epoch:20 step:19304 [D loss: 0.642052, acc.: 64.06%] [G loss: 1.007603]\n",
      "epoch:20 step:19305 [D loss: 0.689500, acc.: 63.28%] [G loss: 0.821962]\n",
      "epoch:20 step:19306 [D loss: 0.473362, acc.: 82.81%] [G loss: 1.186722]\n",
      "epoch:20 step:19307 [D loss: 0.448991, acc.: 85.16%] [G loss: 1.456325]\n",
      "epoch:20 step:19308 [D loss: 0.624111, acc.: 61.72%] [G loss: 1.225884]\n",
      "epoch:20 step:19309 [D loss: 0.662156, acc.: 62.50%] [G loss: 0.946691]\n",
      "epoch:20 step:19310 [D loss: 0.645991, acc.: 65.62%] [G loss: 1.124694]\n",
      "epoch:20 step:19311 [D loss: 0.611741, acc.: 64.06%] [G loss: 0.941182]\n",
      "epoch:20 step:19312 [D loss: 0.759429, acc.: 47.66%] [G loss: 0.782996]\n",
      "epoch:20 step:19313 [D loss: 0.503486, acc.: 80.47%] [G loss: 1.261537]\n",
      "epoch:20 step:19314 [D loss: 0.472049, acc.: 81.25%] [G loss: 1.403419]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19315 [D loss: 0.475050, acc.: 82.03%] [G loss: 1.253363]\n",
      "epoch:20 step:19316 [D loss: 0.537540, acc.: 75.00%] [G loss: 1.177546]\n",
      "epoch:20 step:19317 [D loss: 0.629848, acc.: 64.84%] [G loss: 1.086987]\n",
      "epoch:20 step:19318 [D loss: 0.499674, acc.: 77.34%] [G loss: 1.155030]\n",
      "epoch:20 step:19319 [D loss: 0.694511, acc.: 59.38%] [G loss: 1.224323]\n",
      "epoch:20 step:19320 [D loss: 0.730353, acc.: 54.69%] [G loss: 1.224241]\n",
      "epoch:20 step:19321 [D loss: 0.677400, acc.: 55.47%] [G loss: 1.055962]\n",
      "epoch:20 step:19322 [D loss: 0.917074, acc.: 29.69%] [G loss: 0.788843]\n",
      "epoch:20 step:19323 [D loss: 0.815275, acc.: 46.09%] [G loss: 0.928762]\n",
      "epoch:20 step:19324 [D loss: 0.641668, acc.: 59.38%] [G loss: 1.023228]\n",
      "epoch:20 step:19325 [D loss: 0.599364, acc.: 71.88%] [G loss: 1.194795]\n",
      "epoch:20 step:19326 [D loss: 0.759023, acc.: 54.69%] [G loss: 0.925392]\n",
      "epoch:20 step:19327 [D loss: 0.326912, acc.: 89.06%] [G loss: 1.291224]\n",
      "epoch:20 step:19328 [D loss: 0.388992, acc.: 87.50%] [G loss: 1.636955]\n",
      "epoch:20 step:19329 [D loss: 0.288064, acc.: 96.09%] [G loss: 2.089976]\n",
      "epoch:20 step:19330 [D loss: 0.917681, acc.: 37.50%] [G loss: 1.139687]\n",
      "epoch:20 step:19331 [D loss: 0.773304, acc.: 50.00%] [G loss: 1.265017]\n",
      "epoch:20 step:19332 [D loss: 0.883845, acc.: 34.38%] [G loss: 0.866000]\n",
      "epoch:20 step:19333 [D loss: 0.635289, acc.: 64.84%] [G loss: 1.116119]\n",
      "epoch:20 step:19334 [D loss: 0.531099, acc.: 77.34%] [G loss: 0.899857]\n",
      "epoch:20 step:19335 [D loss: 0.532147, acc.: 76.56%] [G loss: 1.205195]\n",
      "epoch:20 step:19336 [D loss: 0.793611, acc.: 43.75%] [G loss: 0.822982]\n",
      "epoch:20 step:19337 [D loss: 0.719497, acc.: 58.59%] [G loss: 0.953756]\n",
      "epoch:20 step:19338 [D loss: 0.585577, acc.: 66.41%] [G loss: 1.040199]\n",
      "epoch:20 step:19339 [D loss: 0.735697, acc.: 51.56%] [G loss: 1.184641]\n",
      "epoch:20 step:19340 [D loss: 0.596215, acc.: 71.09%] [G loss: 1.167263]\n",
      "epoch:20 step:19341 [D loss: 0.557436, acc.: 76.56%] [G loss: 0.992261]\n",
      "epoch:20 step:19342 [D loss: 0.617689, acc.: 65.62%] [G loss: 1.281056]\n",
      "epoch:20 step:19343 [D loss: 0.424792, acc.: 85.16%] [G loss: 1.031951]\n",
      "epoch:20 step:19344 [D loss: 0.341876, acc.: 90.62%] [G loss: 1.555385]\n",
      "epoch:20 step:19345 [D loss: 0.374917, acc.: 89.84%] [G loss: 1.584312]\n",
      "epoch:20 step:19346 [D loss: 0.473302, acc.: 82.81%] [G loss: 1.379235]\n",
      "epoch:20 step:19347 [D loss: 0.548175, acc.: 75.00%] [G loss: 0.965644]\n",
      "epoch:20 step:19348 [D loss: 0.477649, acc.: 83.59%] [G loss: 1.068235]\n",
      "epoch:20 step:19349 [D loss: 0.603627, acc.: 64.06%] [G loss: 1.160826]\n",
      "epoch:20 step:19350 [D loss: 0.504596, acc.: 78.91%] [G loss: 1.309478]\n",
      "epoch:20 step:19351 [D loss: 0.499690, acc.: 77.34%] [G loss: 1.168842]\n",
      "epoch:20 step:19352 [D loss: 0.606502, acc.: 66.41%] [G loss: 1.004842]\n",
      "epoch:20 step:19353 [D loss: 0.467554, acc.: 73.44%] [G loss: 0.906936]\n",
      "epoch:20 step:19354 [D loss: 0.364103, acc.: 82.81%] [G loss: 1.238713]\n",
      "epoch:20 step:19355 [D loss: 0.331975, acc.: 86.72%] [G loss: 1.574297]\n",
      "epoch:20 step:19356 [D loss: 0.226564, acc.: 99.22%] [G loss: 1.892480]\n",
      "epoch:20 step:19357 [D loss: 0.372203, acc.: 86.72%] [G loss: 1.743798]\n",
      "epoch:20 step:19358 [D loss: 0.741225, acc.: 56.25%] [G loss: 1.176738]\n",
      "epoch:20 step:19359 [D loss: 1.049897, acc.: 28.91%] [G loss: 0.789297]\n",
      "epoch:20 step:19360 [D loss: 0.938651, acc.: 32.81%] [G loss: 0.734199]\n",
      "epoch:20 step:19361 [D loss: 0.926654, acc.: 30.47%] [G loss: 1.003351]\n",
      "epoch:20 step:19362 [D loss: 0.616108, acc.: 65.62%] [G loss: 1.239166]\n",
      "epoch:20 step:19363 [D loss: 0.485488, acc.: 78.12%] [G loss: 1.334419]\n",
      "epoch:20 step:19364 [D loss: 0.692976, acc.: 60.94%] [G loss: 0.900215]\n",
      "epoch:20 step:19365 [D loss: 0.917893, acc.: 39.06%] [G loss: 1.198225]\n",
      "epoch:20 step:19366 [D loss: 1.141918, acc.: 24.22%] [G loss: 0.527575]\n",
      "epoch:20 step:19367 [D loss: 1.051678, acc.: 22.66%] [G loss: 0.872107]\n",
      "epoch:20 step:19368 [D loss: 0.786020, acc.: 53.91%] [G loss: 0.993479]\n",
      "epoch:20 step:19369 [D loss: 0.371578, acc.: 85.94%] [G loss: 1.184667]\n",
      "epoch:20 step:19370 [D loss: 0.609897, acc.: 67.97%] [G loss: 0.963382]\n",
      "epoch:20 step:19371 [D loss: 0.719796, acc.: 56.25%] [G loss: 1.021375]\n",
      "epoch:20 step:19372 [D loss: 0.656526, acc.: 63.28%] [G loss: 0.964580]\n",
      "epoch:20 step:19373 [D loss: 0.673509, acc.: 62.50%] [G loss: 1.091964]\n",
      "epoch:20 step:19374 [D loss: 0.468122, acc.: 80.47%] [G loss: 1.527669]\n",
      "epoch:20 step:19375 [D loss: 0.883092, acc.: 38.28%] [G loss: 1.048763]\n",
      "epoch:20 step:19376 [D loss: 0.953265, acc.: 30.47%] [G loss: 0.880046]\n",
      "epoch:20 step:19377 [D loss: 0.717465, acc.: 53.12%] [G loss: 1.211129]\n",
      "epoch:20 step:19378 [D loss: 0.686850, acc.: 57.81%] [G loss: 1.516986]\n",
      "epoch:20 step:19379 [D loss: 1.004407, acc.: 25.00%] [G loss: 0.865426]\n",
      "epoch:20 step:19380 [D loss: 0.742670, acc.: 51.56%] [G loss: 1.163158]\n",
      "epoch:20 step:19381 [D loss: 0.635505, acc.: 67.19%] [G loss: 1.409319]\n",
      "epoch:20 step:19382 [D loss: 0.514869, acc.: 79.69%] [G loss: 1.487721]\n",
      "epoch:20 step:19383 [D loss: 0.681732, acc.: 64.06%] [G loss: 1.516208]\n",
      "epoch:20 step:19384 [D loss: 0.748809, acc.: 54.69%] [G loss: 1.232696]\n",
      "epoch:20 step:19385 [D loss: 0.617799, acc.: 63.28%] [G loss: 1.123031]\n",
      "epoch:20 step:19386 [D loss: 0.588298, acc.: 69.53%] [G loss: 1.348511]\n",
      "epoch:20 step:19387 [D loss: 0.627672, acc.: 61.72%] [G loss: 0.942036]\n",
      "epoch:20 step:19388 [D loss: 0.571602, acc.: 72.66%] [G loss: 1.083023]\n",
      "epoch:20 step:19389 [D loss: 0.542482, acc.: 76.56%] [G loss: 1.166248]\n",
      "epoch:20 step:19390 [D loss: 0.516476, acc.: 78.12%] [G loss: 1.004235]\n",
      "epoch:20 step:19391 [D loss: 0.675017, acc.: 58.59%] [G loss: 1.160138]\n",
      "epoch:20 step:19392 [D loss: 0.663308, acc.: 64.84%] [G loss: 1.095957]\n",
      "epoch:20 step:19393 [D loss: 0.478783, acc.: 81.25%] [G loss: 1.236479]\n",
      "epoch:20 step:19394 [D loss: 0.584468, acc.: 72.66%] [G loss: 1.083735]\n",
      "epoch:20 step:19395 [D loss: 0.647554, acc.: 61.72%] [G loss: 1.029915]\n",
      "epoch:20 step:19396 [D loss: 0.595674, acc.: 68.75%] [G loss: 1.138202]\n",
      "epoch:20 step:19397 [D loss: 0.609388, acc.: 72.66%] [G loss: 1.124628]\n",
      "epoch:20 step:19398 [D loss: 0.466305, acc.: 83.59%] [G loss: 1.262742]\n",
      "epoch:20 step:19399 [D loss: 0.591786, acc.: 66.41%] [G loss: 1.282238]\n",
      "epoch:20 step:19400 [D loss: 0.549257, acc.: 71.88%] [G loss: 1.050001]\n",
      "##############\n",
      "[2.48142925 1.77764421 5.49324627 3.94993468 3.20532113 5.47971083\n",
      " 4.41057143 4.75770988 3.86585405 3.72801765]\n",
      "##########\n",
      "epoch:20 step:19401 [D loss: 0.433733, acc.: 82.81%] [G loss: 1.301717]\n",
      "epoch:20 step:19402 [D loss: 0.528400, acc.: 73.44%] [G loss: 1.105752]\n",
      "epoch:20 step:19403 [D loss: 0.323026, acc.: 88.28%] [G loss: 1.407048]\n",
      "epoch:20 step:19404 [D loss: 0.248695, acc.: 94.53%] [G loss: 1.429650]\n",
      "epoch:20 step:19405 [D loss: 0.211759, acc.: 97.66%] [G loss: 1.704451]\n",
      "epoch:20 step:19406 [D loss: 0.315842, acc.: 93.75%] [G loss: 1.903752]\n",
      "epoch:20 step:19407 [D loss: 0.458245, acc.: 81.25%] [G loss: 1.507523]\n",
      "epoch:20 step:19408 [D loss: 0.618931, acc.: 66.41%] [G loss: 1.301569]\n",
      "epoch:20 step:19409 [D loss: 0.526694, acc.: 73.44%] [G loss: 1.019312]\n",
      "epoch:20 step:19410 [D loss: 0.549559, acc.: 69.53%] [G loss: 1.225372]\n",
      "epoch:20 step:19411 [D loss: 0.664803, acc.: 62.50%] [G loss: 0.823266]\n",
      "epoch:20 step:19412 [D loss: 0.731979, acc.: 57.03%] [G loss: 1.067668]\n",
      "epoch:20 step:19413 [D loss: 0.660229, acc.: 60.94%] [G loss: 1.089851]\n",
      "epoch:20 step:19414 [D loss: 0.847852, acc.: 51.56%] [G loss: 0.918948]\n",
      "epoch:20 step:19415 [D loss: 0.821271, acc.: 41.41%] [G loss: 0.826380]\n",
      "epoch:20 step:19416 [D loss: 0.721310, acc.: 53.12%] [G loss: 1.126273]\n",
      "epoch:20 step:19417 [D loss: 0.750220, acc.: 46.88%] [G loss: 0.779938]\n",
      "epoch:20 step:19418 [D loss: 0.916785, acc.: 37.50%] [G loss: 0.878617]\n",
      "epoch:20 step:19419 [D loss: 0.781344, acc.: 46.88%] [G loss: 1.018744]\n",
      "epoch:20 step:19420 [D loss: 0.804054, acc.: 50.00%] [G loss: 1.165951]\n",
      "epoch:20 step:19421 [D loss: 0.677202, acc.: 58.59%] [G loss: 1.083735]\n",
      "epoch:20 step:19422 [D loss: 0.651276, acc.: 60.16%] [G loss: 1.048043]\n",
      "epoch:20 step:19423 [D loss: 0.723894, acc.: 53.91%] [G loss: 0.818821]\n",
      "epoch:20 step:19424 [D loss: 0.691531, acc.: 52.34%] [G loss: 1.298703]\n",
      "epoch:20 step:19425 [D loss: 0.589178, acc.: 67.97%] [G loss: 1.036626]\n",
      "epoch:20 step:19426 [D loss: 0.622427, acc.: 60.94%] [G loss: 1.095078]\n",
      "epoch:20 step:19427 [D loss: 0.618782, acc.: 64.84%] [G loss: 1.009874]\n",
      "epoch:20 step:19428 [D loss: 0.617193, acc.: 72.66%] [G loss: 0.935750]\n",
      "epoch:20 step:19429 [D loss: 0.537409, acc.: 74.22%] [G loss: 1.225574]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19430 [D loss: 0.486214, acc.: 75.78%] [G loss: 1.418246]\n",
      "epoch:20 step:19431 [D loss: 0.525675, acc.: 74.22%] [G loss: 1.253274]\n",
      "epoch:20 step:19432 [D loss: 0.534762, acc.: 72.66%] [G loss: 1.230671]\n",
      "epoch:20 step:19433 [D loss: 0.582502, acc.: 71.88%] [G loss: 1.339790]\n",
      "epoch:20 step:19434 [D loss: 0.447607, acc.: 85.94%] [G loss: 1.189595]\n",
      "epoch:20 step:19435 [D loss: 0.558040, acc.: 69.53%] [G loss: 1.454419]\n",
      "epoch:20 step:19436 [D loss: 1.021204, acc.: 32.03%] [G loss: 0.992915]\n",
      "epoch:20 step:19437 [D loss: 0.736464, acc.: 52.34%] [G loss: 1.247510]\n",
      "epoch:20 step:19438 [D loss: 0.737382, acc.: 53.12%] [G loss: 1.085466]\n",
      "epoch:20 step:19439 [D loss: 0.719566, acc.: 56.25%] [G loss: 0.860546]\n",
      "epoch:20 step:19440 [D loss: 0.649660, acc.: 60.16%] [G loss: 0.953825]\n",
      "epoch:20 step:19441 [D loss: 0.710206, acc.: 53.91%] [G loss: 0.870134]\n",
      "epoch:20 step:19442 [D loss: 0.692574, acc.: 55.47%] [G loss: 1.108863]\n",
      "epoch:20 step:19443 [D loss: 0.721778, acc.: 53.91%] [G loss: 0.945808]\n",
      "epoch:20 step:19444 [D loss: 0.689377, acc.: 58.59%] [G loss: 0.977367]\n",
      "epoch:20 step:19445 [D loss: 0.697132, acc.: 60.94%] [G loss: 1.225872]\n",
      "epoch:20 step:19446 [D loss: 0.560853, acc.: 69.53%] [G loss: 0.805254]\n",
      "epoch:20 step:19447 [D loss: 0.512406, acc.: 75.00%] [G loss: 1.116375]\n",
      "epoch:20 step:19448 [D loss: 0.485194, acc.: 78.91%] [G loss: 1.433414]\n",
      "epoch:20 step:19449 [D loss: 0.493625, acc.: 78.91%] [G loss: 1.038908]\n",
      "epoch:20 step:19450 [D loss: 0.757862, acc.: 47.66%] [G loss: 1.068582]\n",
      "epoch:20 step:19451 [D loss: 0.683678, acc.: 58.59%] [G loss: 0.989349]\n",
      "epoch:20 step:19452 [D loss: 0.603720, acc.: 70.31%] [G loss: 0.878360]\n",
      "epoch:20 step:19453 [D loss: 0.546972, acc.: 71.09%] [G loss: 1.037937]\n",
      "epoch:20 step:19454 [D loss: 0.610569, acc.: 67.19%] [G loss: 1.210019]\n",
      "epoch:20 step:19455 [D loss: 0.677741, acc.: 64.06%] [G loss: 1.080816]\n",
      "epoch:20 step:19456 [D loss: 0.891181, acc.: 37.50%] [G loss: 1.002203]\n",
      "epoch:20 step:19457 [D loss: 0.746202, acc.: 51.56%] [G loss: 0.979331]\n",
      "epoch:20 step:19458 [D loss: 0.754118, acc.: 50.00%] [G loss: 0.983468]\n",
      "epoch:20 step:19459 [D loss: 0.583565, acc.: 72.66%] [G loss: 1.071567]\n",
      "epoch:20 step:19460 [D loss: 0.684061, acc.: 56.25%] [G loss: 1.134740]\n",
      "epoch:20 step:19461 [D loss: 0.540797, acc.: 74.22%] [G loss: 1.228240]\n",
      "epoch:20 step:19462 [D loss: 0.621322, acc.: 66.41%] [G loss: 1.282149]\n",
      "epoch:20 step:19463 [D loss: 0.617644, acc.: 67.97%] [G loss: 1.123162]\n",
      "epoch:20 step:19464 [D loss: 0.426911, acc.: 89.06%] [G loss: 1.217693]\n",
      "epoch:20 step:19465 [D loss: 0.336008, acc.: 92.97%] [G loss: 1.541387]\n",
      "epoch:20 step:19466 [D loss: 0.584425, acc.: 72.66%] [G loss: 1.105941]\n",
      "epoch:20 step:19467 [D loss: 0.860695, acc.: 36.72%] [G loss: 0.856028]\n",
      "epoch:20 step:19468 [D loss: 0.701370, acc.: 52.34%] [G loss: 1.156898]\n",
      "epoch:20 step:19469 [D loss: 0.638058, acc.: 64.84%] [G loss: 0.863872]\n",
      "epoch:20 step:19470 [D loss: 0.551879, acc.: 72.66%] [G loss: 0.945198]\n",
      "epoch:20 step:19471 [D loss: 0.611142, acc.: 64.06%] [G loss: 1.151460]\n",
      "epoch:20 step:19472 [D loss: 0.550812, acc.: 73.44%] [G loss: 1.115939]\n",
      "epoch:20 step:19473 [D loss: 0.582567, acc.: 70.31%] [G loss: 1.198236]\n",
      "epoch:20 step:19474 [D loss: 0.742312, acc.: 45.31%] [G loss: 1.255455]\n",
      "epoch:20 step:19475 [D loss: 0.761488, acc.: 46.09%] [G loss: 0.990753]\n",
      "epoch:20 step:19476 [D loss: 0.586442, acc.: 70.31%] [G loss: 1.000390]\n",
      "epoch:20 step:19477 [D loss: 0.653599, acc.: 60.16%] [G loss: 1.069462]\n",
      "epoch:20 step:19478 [D loss: 0.699356, acc.: 57.03%] [G loss: 0.965008]\n",
      "epoch:20 step:19479 [D loss: 0.730413, acc.: 54.69%] [G loss: 0.825080]\n",
      "epoch:20 step:19480 [D loss: 0.582599, acc.: 71.09%] [G loss: 1.104526]\n",
      "epoch:20 step:19481 [D loss: 0.569928, acc.: 71.09%] [G loss: 0.899096]\n",
      "epoch:20 step:19482 [D loss: 0.531265, acc.: 80.47%] [G loss: 1.114070]\n",
      "epoch:20 step:19483 [D loss: 0.448890, acc.: 88.28%] [G loss: 1.192032]\n",
      "epoch:20 step:19484 [D loss: 0.649192, acc.: 57.03%] [G loss: 1.009182]\n",
      "epoch:20 step:19485 [D loss: 0.417862, acc.: 89.06%] [G loss: 1.130186]\n",
      "epoch:20 step:19486 [D loss: 0.558289, acc.: 72.66%] [G loss: 1.098902]\n",
      "epoch:20 step:19487 [D loss: 0.533125, acc.: 75.78%] [G loss: 1.247980]\n",
      "epoch:20 step:19488 [D loss: 0.615360, acc.: 64.84%] [G loss: 1.134093]\n",
      "epoch:20 step:19489 [D loss: 0.612203, acc.: 69.53%] [G loss: 0.987111]\n",
      "epoch:20 step:19490 [D loss: 0.569341, acc.: 70.31%] [G loss: 1.092174]\n",
      "epoch:20 step:19491 [D loss: 0.729424, acc.: 50.78%] [G loss: 0.912703]\n",
      "epoch:20 step:19492 [D loss: 0.802725, acc.: 41.41%] [G loss: 1.096892]\n",
      "epoch:20 step:19493 [D loss: 0.634880, acc.: 62.50%] [G loss: 0.843406]\n",
      "epoch:20 step:19494 [D loss: 0.626944, acc.: 61.72%] [G loss: 1.088468]\n",
      "epoch:20 step:19495 [D loss: 0.479227, acc.: 82.81%] [G loss: 1.002858]\n",
      "epoch:20 step:19496 [D loss: 0.591147, acc.: 71.09%] [G loss: 1.137301]\n",
      "epoch:20 step:19497 [D loss: 0.532440, acc.: 80.47%] [G loss: 1.043818]\n",
      "epoch:20 step:19498 [D loss: 0.691183, acc.: 57.81%] [G loss: 0.971954]\n",
      "epoch:20 step:19499 [D loss: 0.891424, acc.: 36.72%] [G loss: 0.847103]\n",
      "epoch:20 step:19500 [D loss: 0.675145, acc.: 62.50%] [G loss: 1.111785]\n",
      "epoch:20 step:19501 [D loss: 0.602788, acc.: 68.75%] [G loss: 1.054545]\n",
      "epoch:20 step:19502 [D loss: 0.627042, acc.: 64.06%] [G loss: 1.061572]\n",
      "epoch:20 step:19503 [D loss: 0.573755, acc.: 74.22%] [G loss: 0.990314]\n",
      "epoch:20 step:19504 [D loss: 0.532352, acc.: 76.56%] [G loss: 1.058094]\n",
      "epoch:20 step:19505 [D loss: 0.746109, acc.: 46.88%] [G loss: 0.990784]\n",
      "epoch:20 step:19506 [D loss: 0.732238, acc.: 53.12%] [G loss: 0.914418]\n",
      "epoch:20 step:19507 [D loss: 0.545469, acc.: 76.56%] [G loss: 1.216736]\n",
      "epoch:20 step:19508 [D loss: 0.462304, acc.: 85.16%] [G loss: 1.165082]\n",
      "epoch:20 step:19509 [D loss: 0.386256, acc.: 87.50%] [G loss: 1.179378]\n",
      "epoch:20 step:19510 [D loss: 0.497023, acc.: 78.91%] [G loss: 1.173348]\n",
      "epoch:20 step:19511 [D loss: 0.716039, acc.: 53.91%] [G loss: 1.104277]\n",
      "epoch:20 step:19512 [D loss: 0.718135, acc.: 51.56%] [G loss: 0.916509]\n",
      "epoch:20 step:19513 [D loss: 0.649374, acc.: 64.84%] [G loss: 1.032718]\n",
      "epoch:20 step:19514 [D loss: 0.435847, acc.: 75.78%] [G loss: 1.347228]\n",
      "epoch:20 step:19515 [D loss: 0.290790, acc.: 95.31%] [G loss: 1.541290]\n",
      "epoch:20 step:19516 [D loss: 0.416043, acc.: 84.38%] [G loss: 1.597705]\n",
      "epoch:20 step:19517 [D loss: 0.649364, acc.: 61.72%] [G loss: 0.893884]\n",
      "epoch:20 step:19518 [D loss: 0.631571, acc.: 59.38%] [G loss: 1.202956]\n",
      "epoch:20 step:19519 [D loss: 0.922790, acc.: 32.03%] [G loss: 1.004522]\n",
      "epoch:20 step:19520 [D loss: 0.675223, acc.: 57.03%] [G loss: 0.945096]\n",
      "epoch:20 step:19521 [D loss: 0.579392, acc.: 72.66%] [G loss: 1.330620]\n",
      "epoch:20 step:19522 [D loss: 0.574248, acc.: 72.66%] [G loss: 1.041516]\n",
      "epoch:20 step:19523 [D loss: 0.859003, acc.: 44.53%] [G loss: 1.178088]\n",
      "epoch:20 step:19524 [D loss: 0.700294, acc.: 53.91%] [G loss: 1.015599]\n",
      "epoch:20 step:19525 [D loss: 0.632710, acc.: 64.06%] [G loss: 0.814737]\n",
      "epoch:20 step:19526 [D loss: 0.420215, acc.: 87.50%] [G loss: 1.286361]\n",
      "epoch:20 step:19527 [D loss: 0.839431, acc.: 37.50%] [G loss: 0.880836]\n",
      "epoch:20 step:19528 [D loss: 0.746032, acc.: 51.56%] [G loss: 0.821657]\n",
      "epoch:20 step:19529 [D loss: 0.653477, acc.: 62.50%] [G loss: 0.991218]\n",
      "epoch:20 step:19530 [D loss: 0.554428, acc.: 72.66%] [G loss: 0.884138]\n",
      "epoch:20 step:19531 [D loss: 0.484795, acc.: 78.91%] [G loss: 1.094767]\n",
      "epoch:20 step:19532 [D loss: 0.413548, acc.: 82.03%] [G loss: 1.147106]\n",
      "epoch:20 step:19533 [D loss: 0.406734, acc.: 88.28%] [G loss: 1.588214]\n",
      "epoch:20 step:19534 [D loss: 0.323733, acc.: 93.75%] [G loss: 1.279056]\n",
      "epoch:20 step:19535 [D loss: 0.494321, acc.: 77.34%] [G loss: 1.382887]\n",
      "epoch:20 step:19536 [D loss: 0.550855, acc.: 70.31%] [G loss: 0.970680]\n",
      "epoch:20 step:19537 [D loss: 0.611449, acc.: 68.75%] [G loss: 1.318878]\n",
      "epoch:20 step:19538 [D loss: 0.542574, acc.: 75.78%] [G loss: 1.249306]\n",
      "epoch:20 step:19539 [D loss: 0.877580, acc.: 42.97%] [G loss: 0.862373]\n",
      "epoch:20 step:19540 [D loss: 0.809682, acc.: 43.75%] [G loss: 1.168780]\n",
      "epoch:20 step:19541 [D loss: 0.853826, acc.: 35.94%] [G loss: 0.827680]\n",
      "epoch:20 step:19542 [D loss: 0.777607, acc.: 50.00%] [G loss: 0.869219]\n",
      "epoch:20 step:19543 [D loss: 0.724486, acc.: 50.78%] [G loss: 0.993878]\n",
      "epoch:20 step:19544 [D loss: 0.588039, acc.: 65.62%] [G loss: 1.096036]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19545 [D loss: 0.641592, acc.: 61.72%] [G loss: 0.981858]\n",
      "epoch:20 step:19546 [D loss: 0.438918, acc.: 82.03%] [G loss: 1.462576]\n",
      "epoch:20 step:19547 [D loss: 0.650096, acc.: 61.72%] [G loss: 1.065179]\n",
      "epoch:20 step:19548 [D loss: 0.581201, acc.: 73.44%] [G loss: 1.220512]\n",
      "epoch:20 step:19549 [D loss: 0.630667, acc.: 60.94%] [G loss: 1.108959]\n",
      "epoch:20 step:19550 [D loss: 0.580316, acc.: 67.19%] [G loss: 1.086740]\n",
      "epoch:20 step:19551 [D loss: 0.638373, acc.: 63.28%] [G loss: 1.018218]\n",
      "epoch:20 step:19552 [D loss: 0.692931, acc.: 57.81%] [G loss: 1.056346]\n",
      "epoch:20 step:19553 [D loss: 0.643773, acc.: 63.28%] [G loss: 1.000364]\n",
      "epoch:20 step:19554 [D loss: 0.620326, acc.: 65.62%] [G loss: 0.991530]\n",
      "epoch:20 step:19555 [D loss: 0.358032, acc.: 77.34%] [G loss: 1.234469]\n",
      "epoch:20 step:19556 [D loss: 0.301300, acc.: 93.75%] [G loss: 1.593828]\n",
      "epoch:20 step:19557 [D loss: 0.573235, acc.: 68.75%] [G loss: 1.367552]\n",
      "epoch:20 step:19558 [D loss: 0.527626, acc.: 75.00%] [G loss: 1.026220]\n",
      "epoch:20 step:19559 [D loss: 0.487588, acc.: 75.78%] [G loss: 1.549398]\n",
      "epoch:20 step:19560 [D loss: 1.109370, acc.: 20.31%] [G loss: 0.906065]\n",
      "epoch:20 step:19561 [D loss: 0.648349, acc.: 61.72%] [G loss: 1.291833]\n",
      "epoch:20 step:19562 [D loss: 0.754392, acc.: 50.00%] [G loss: 0.712963]\n",
      "epoch:20 step:19563 [D loss: 0.705245, acc.: 56.25%] [G loss: 1.238481]\n",
      "epoch:20 step:19564 [D loss: 0.525787, acc.: 75.00%] [G loss: 1.038696]\n",
      "epoch:20 step:19565 [D loss: 0.435521, acc.: 89.06%] [G loss: 1.080865]\n",
      "epoch:20 step:19566 [D loss: 0.666199, acc.: 62.50%] [G loss: 1.021554]\n",
      "epoch:20 step:19567 [D loss: 1.097447, acc.: 18.75%] [G loss: 0.785274]\n",
      "epoch:20 step:19568 [D loss: 0.837883, acc.: 39.06%] [G loss: 0.694315]\n",
      "epoch:20 step:19569 [D loss: 0.670596, acc.: 57.03%] [G loss: 1.072975]\n",
      "epoch:20 step:19570 [D loss: 0.613913, acc.: 68.75%] [G loss: 1.087539]\n",
      "epoch:20 step:19571 [D loss: 0.478506, acc.: 81.25%] [G loss: 1.176752]\n",
      "epoch:20 step:19572 [D loss: 0.440197, acc.: 82.81%] [G loss: 1.373397]\n",
      "epoch:20 step:19573 [D loss: 0.615415, acc.: 66.41%] [G loss: 1.028776]\n",
      "epoch:20 step:19574 [D loss: 0.801218, acc.: 46.09%] [G loss: 0.976358]\n",
      "epoch:20 step:19575 [D loss: 0.768066, acc.: 50.78%] [G loss: 1.253412]\n",
      "epoch:20 step:19576 [D loss: 0.739715, acc.: 52.34%] [G loss: 1.018547]\n",
      "epoch:20 step:19577 [D loss: 0.801875, acc.: 47.66%] [G loss: 0.886676]\n",
      "epoch:20 step:19578 [D loss: 0.681002, acc.: 62.50%] [G loss: 1.164865]\n",
      "epoch:20 step:19579 [D loss: 0.721655, acc.: 56.25%] [G loss: 0.984588]\n",
      "epoch:20 step:19580 [D loss: 0.496448, acc.: 82.03%] [G loss: 1.076890]\n",
      "epoch:20 step:19581 [D loss: 0.468601, acc.: 78.91%] [G loss: 1.275765]\n",
      "epoch:20 step:19582 [D loss: 0.410639, acc.: 87.50%] [G loss: 1.332386]\n",
      "epoch:20 step:19583 [D loss: 0.712574, acc.: 50.78%] [G loss: 0.929769]\n",
      "epoch:20 step:19584 [D loss: 0.790460, acc.: 48.44%] [G loss: 0.942195]\n",
      "epoch:20 step:19585 [D loss: 0.709691, acc.: 53.12%] [G loss: 0.770291]\n",
      "epoch:20 step:19586 [D loss: 0.547310, acc.: 73.44%] [G loss: 0.933658]\n",
      "epoch:20 step:19587 [D loss: 0.503128, acc.: 77.34%] [G loss: 1.098258]\n",
      "epoch:20 step:19588 [D loss: 0.452980, acc.: 86.72%] [G loss: 1.062566]\n",
      "epoch:20 step:19589 [D loss: 0.374694, acc.: 93.75%] [G loss: 1.292077]\n",
      "epoch:20 step:19590 [D loss: 0.369349, acc.: 92.19%] [G loss: 1.179616]\n",
      "epoch:20 step:19591 [D loss: 0.382095, acc.: 89.84%] [G loss: 1.224465]\n",
      "epoch:20 step:19592 [D loss: 0.228826, acc.: 99.22%] [G loss: 1.738247]\n",
      "epoch:20 step:19593 [D loss: 0.394900, acc.: 86.72%] [G loss: 1.449931]\n",
      "epoch:20 step:19594 [D loss: 0.452130, acc.: 79.69%] [G loss: 1.365675]\n",
      "epoch:20 step:19595 [D loss: 0.567885, acc.: 69.53%] [G loss: 1.318747]\n",
      "epoch:20 step:19596 [D loss: 0.554693, acc.: 68.75%] [G loss: 1.329090]\n",
      "epoch:20 step:19597 [D loss: 0.393122, acc.: 91.41%] [G loss: 1.356838]\n",
      "epoch:20 step:19598 [D loss: 1.005155, acc.: 30.47%] [G loss: 0.860364]\n",
      "epoch:20 step:19599 [D loss: 0.785130, acc.: 49.22%] [G loss: 0.988565]\n",
      "epoch:20 step:19600 [D loss: 0.635130, acc.: 61.72%] [G loss: 1.149687]\n",
      "##############\n",
      "[2.54451087 1.51566017 5.52181843 4.1484015  2.94629138 5.27661471\n",
      " 4.1101795  4.48768094 4.116155   3.73107279]\n",
      "##########\n",
      "epoch:20 step:19601 [D loss: 0.523402, acc.: 72.66%] [G loss: 1.148698]\n",
      "epoch:20 step:19602 [D loss: 0.762466, acc.: 46.09%] [G loss: 0.951031]\n",
      "epoch:20 step:19603 [D loss: 0.782667, acc.: 43.75%] [G loss: 0.808484]\n",
      "epoch:20 step:19604 [D loss: 0.782721, acc.: 48.44%] [G loss: 0.965791]\n",
      "epoch:20 step:19605 [D loss: 0.786467, acc.: 44.53%] [G loss: 0.821450]\n",
      "epoch:20 step:19606 [D loss: 0.707998, acc.: 54.69%] [G loss: 0.945858]\n",
      "epoch:20 step:19607 [D loss: 0.696714, acc.: 55.47%] [G loss: 1.108260]\n",
      "epoch:20 step:19608 [D loss: 0.626253, acc.: 64.06%] [G loss: 1.017671]\n",
      "epoch:20 step:19609 [D loss: 0.651174, acc.: 58.59%] [G loss: 1.129183]\n",
      "epoch:20 step:19610 [D loss: 0.778717, acc.: 48.44%] [G loss: 0.917986]\n",
      "epoch:20 step:19611 [D loss: 0.538211, acc.: 75.00%] [G loss: 0.930228]\n",
      "epoch:20 step:19612 [D loss: 0.728504, acc.: 50.00%] [G loss: 0.945482]\n",
      "epoch:20 step:19613 [D loss: 0.649094, acc.: 60.94%] [G loss: 1.129266]\n",
      "epoch:20 step:19614 [D loss: 0.685409, acc.: 56.25%] [G loss: 0.961193]\n",
      "epoch:20 step:19615 [D loss: 0.636823, acc.: 61.72%] [G loss: 0.849054]\n",
      "epoch:20 step:19616 [D loss: 0.597437, acc.: 65.62%] [G loss: 0.907317]\n",
      "epoch:20 step:19617 [D loss: 0.509679, acc.: 78.91%] [G loss: 1.172298]\n",
      "epoch:20 step:19618 [D loss: 0.462482, acc.: 79.69%] [G loss: 1.196893]\n",
      "epoch:20 step:19619 [D loss: 0.564853, acc.: 73.44%] [G loss: 1.163752]\n",
      "epoch:20 step:19620 [D loss: 0.808001, acc.: 38.28%] [G loss: 0.833138]\n",
      "epoch:20 step:19621 [D loss: 0.749736, acc.: 47.66%] [G loss: 1.069212]\n",
      "epoch:20 step:19622 [D loss: 0.778552, acc.: 36.72%] [G loss: 0.789720]\n",
      "epoch:20 step:19623 [D loss: 0.626542, acc.: 66.41%] [G loss: 1.125901]\n",
      "epoch:20 step:19624 [D loss: 0.551975, acc.: 75.00%] [G loss: 0.936815]\n",
      "epoch:20 step:19625 [D loss: 0.483902, acc.: 79.69%] [G loss: 1.001411]\n",
      "epoch:20 step:19626 [D loss: 0.506724, acc.: 80.47%] [G loss: 1.203225]\n",
      "epoch:20 step:19627 [D loss: 0.426840, acc.: 89.06%] [G loss: 1.049331]\n",
      "epoch:20 step:19628 [D loss: 0.631990, acc.: 68.75%] [G loss: 1.103729]\n",
      "epoch:20 step:19629 [D loss: 0.503994, acc.: 78.91%] [G loss: 0.996152]\n",
      "epoch:20 step:19630 [D loss: 0.587291, acc.: 64.06%] [G loss: 1.064403]\n",
      "epoch:20 step:19631 [D loss: 0.782409, acc.: 48.44%] [G loss: 1.233587]\n",
      "epoch:20 step:19632 [D loss: 0.529901, acc.: 75.78%] [G loss: 1.196597]\n",
      "epoch:20 step:19633 [D loss: 0.559199, acc.: 72.66%] [G loss: 1.172853]\n",
      "epoch:20 step:19634 [D loss: 0.512340, acc.: 80.47%] [G loss: 1.053737]\n",
      "epoch:20 step:19635 [D loss: 0.485579, acc.: 82.81%] [G loss: 1.314163]\n",
      "epoch:20 step:19636 [D loss: 0.389739, acc.: 92.97%] [G loss: 1.451534]\n",
      "epoch:20 step:19637 [D loss: 0.462338, acc.: 85.16%] [G loss: 1.100291]\n",
      "epoch:20 step:19638 [D loss: 0.273813, acc.: 98.44%] [G loss: 1.589725]\n",
      "epoch:20 step:19639 [D loss: 0.321058, acc.: 91.41%] [G loss: 1.406380]\n",
      "epoch:20 step:19640 [D loss: 0.253348, acc.: 96.88%] [G loss: 1.713182]\n",
      "epoch:20 step:19641 [D loss: 0.497517, acc.: 78.91%] [G loss: 1.325301]\n",
      "epoch:20 step:19642 [D loss: 0.765198, acc.: 49.22%] [G loss: 1.230449]\n",
      "epoch:20 step:19643 [D loss: 0.719542, acc.: 57.03%] [G loss: 0.932730]\n",
      "epoch:20 step:19644 [D loss: 0.793124, acc.: 50.00%] [G loss: 1.126092]\n",
      "epoch:20 step:19645 [D loss: 0.682009, acc.: 56.25%] [G loss: 1.181951]\n",
      "epoch:20 step:19646 [D loss: 0.852118, acc.: 39.84%] [G loss: 0.848171]\n",
      "epoch:20 step:19647 [D loss: 0.767456, acc.: 42.97%] [G loss: 1.045621]\n",
      "epoch:20 step:19648 [D loss: 0.715072, acc.: 55.47%] [G loss: 1.112528]\n",
      "epoch:20 step:19649 [D loss: 0.512196, acc.: 80.47%] [G loss: 1.054902]\n",
      "epoch:20 step:19650 [D loss: 0.597172, acc.: 67.19%] [G loss: 1.019912]\n",
      "epoch:20 step:19651 [D loss: 0.454779, acc.: 81.25%] [G loss: 1.102575]\n",
      "epoch:20 step:19652 [D loss: 0.349075, acc.: 85.16%] [G loss: 1.402225]\n",
      "epoch:20 step:19653 [D loss: 0.776356, acc.: 52.34%] [G loss: 1.434674]\n",
      "epoch:20 step:19654 [D loss: 0.657843, acc.: 63.28%] [G loss: 1.105689]\n",
      "epoch:20 step:19655 [D loss: 0.765673, acc.: 42.97%] [G loss: 0.920747]\n",
      "epoch:20 step:19656 [D loss: 0.707916, acc.: 57.03%] [G loss: 0.921611]\n",
      "epoch:20 step:19657 [D loss: 0.588575, acc.: 69.53%] [G loss: 1.029502]\n",
      "epoch:20 step:19658 [D loss: 0.521265, acc.: 75.78%] [G loss: 1.145507]\n",
      "epoch:20 step:19659 [D loss: 0.659148, acc.: 60.16%] [G loss: 1.170893]\n",
      "epoch:20 step:19660 [D loss: 0.417728, acc.: 79.69%] [G loss: 1.052505]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19661 [D loss: 0.384837, acc.: 86.72%] [G loss: 1.383679]\n",
      "epoch:20 step:19662 [D loss: 0.720081, acc.: 55.47%] [G loss: 1.156299]\n",
      "epoch:20 step:19663 [D loss: 0.593268, acc.: 68.75%] [G loss: 1.215632]\n",
      "epoch:20 step:19664 [D loss: 0.605543, acc.: 64.84%] [G loss: 1.187390]\n",
      "epoch:20 step:19665 [D loss: 0.595319, acc.: 67.97%] [G loss: 1.058937]\n",
      "epoch:20 step:19666 [D loss: 0.545467, acc.: 74.22%] [G loss: 0.975084]\n",
      "epoch:20 step:19667 [D loss: 0.500947, acc.: 76.56%] [G loss: 1.087045]\n",
      "epoch:20 step:19668 [D loss: 0.893609, acc.: 35.94%] [G loss: 1.018109]\n",
      "epoch:20 step:19669 [D loss: 0.400555, acc.: 85.16%] [G loss: 1.133510]\n",
      "epoch:20 step:19670 [D loss: 0.417730, acc.: 83.59%] [G loss: 1.264666]\n",
      "epoch:20 step:19671 [D loss: 0.579866, acc.: 72.66%] [G loss: 1.069542]\n",
      "epoch:20 step:19672 [D loss: 0.706080, acc.: 51.56%] [G loss: 1.117779]\n",
      "epoch:20 step:19673 [D loss: 0.602620, acc.: 67.19%] [G loss: 1.204957]\n",
      "epoch:20 step:19674 [D loss: 0.492871, acc.: 76.56%] [G loss: 1.206013]\n",
      "epoch:20 step:19675 [D loss: 0.538506, acc.: 74.22%] [G loss: 1.268093]\n",
      "epoch:20 step:19676 [D loss: 0.453521, acc.: 82.81%] [G loss: 1.195049]\n",
      "epoch:20 step:19677 [D loss: 0.356221, acc.: 80.47%] [G loss: 0.931731]\n",
      "epoch:21 step:19678 [D loss: 0.701079, acc.: 62.50%] [G loss: 1.401511]\n",
      "epoch:21 step:19679 [D loss: 0.659763, acc.: 65.62%] [G loss: 1.248914]\n",
      "epoch:21 step:19680 [D loss: 0.632242, acc.: 63.28%] [G loss: 1.037185]\n",
      "epoch:21 step:19681 [D loss: 0.765294, acc.: 51.56%] [G loss: 0.728024]\n",
      "epoch:21 step:19682 [D loss: 0.666278, acc.: 59.38%] [G loss: 1.013842]\n",
      "epoch:21 step:19683 [D loss: 0.660788, acc.: 59.38%] [G loss: 1.033211]\n",
      "epoch:21 step:19684 [D loss: 0.666810, acc.: 57.03%] [G loss: 1.019238]\n",
      "epoch:21 step:19685 [D loss: 0.465166, acc.: 80.47%] [G loss: 1.159324]\n",
      "epoch:21 step:19686 [D loss: 0.499966, acc.: 78.12%] [G loss: 0.987471]\n",
      "epoch:21 step:19687 [D loss: 0.564155, acc.: 67.97%] [G loss: 1.076933]\n",
      "epoch:21 step:19688 [D loss: 0.500964, acc.: 80.47%] [G loss: 1.239182]\n",
      "epoch:21 step:19689 [D loss: 0.594170, acc.: 65.62%] [G loss: 1.381573]\n",
      "epoch:21 step:19690 [D loss: 0.551011, acc.: 73.44%] [G loss: 1.247154]\n",
      "epoch:21 step:19691 [D loss: 0.530565, acc.: 75.00%] [G loss: 1.191752]\n",
      "epoch:21 step:19692 [D loss: 0.448552, acc.: 80.47%] [G loss: 1.099166]\n",
      "epoch:21 step:19693 [D loss: 0.553516, acc.: 71.88%] [G loss: 0.952937]\n",
      "epoch:21 step:19694 [D loss: 0.737124, acc.: 52.34%] [G loss: 0.817777]\n",
      "epoch:21 step:19695 [D loss: 0.849787, acc.: 40.62%] [G loss: 1.012287]\n",
      "epoch:21 step:19696 [D loss: 0.776419, acc.: 52.34%] [G loss: 1.172132]\n",
      "epoch:21 step:19697 [D loss: 0.860805, acc.: 41.41%] [G loss: 0.903431]\n",
      "epoch:21 step:19698 [D loss: 0.801147, acc.: 42.19%] [G loss: 1.179835]\n",
      "epoch:21 step:19699 [D loss: 0.807069, acc.: 42.97%] [G loss: 0.813982]\n",
      "epoch:21 step:19700 [D loss: 0.575589, acc.: 66.41%] [G loss: 0.969579]\n",
      "epoch:21 step:19701 [D loss: 0.614094, acc.: 64.06%] [G loss: 1.020377]\n",
      "epoch:21 step:19702 [D loss: 0.620282, acc.: 65.62%] [G loss: 0.964430]\n",
      "epoch:21 step:19703 [D loss: 0.470201, acc.: 85.16%] [G loss: 1.175882]\n",
      "epoch:21 step:19704 [D loss: 0.444642, acc.: 81.25%] [G loss: 1.288318]\n",
      "epoch:21 step:19705 [D loss: 0.384968, acc.: 87.50%] [G loss: 1.425512]\n",
      "epoch:21 step:19706 [D loss: 0.481643, acc.: 79.69%] [G loss: 1.434525]\n",
      "epoch:21 step:19707 [D loss: 0.478335, acc.: 83.59%] [G loss: 1.358561]\n",
      "epoch:21 step:19708 [D loss: 0.319357, acc.: 96.09%] [G loss: 1.596086]\n",
      "epoch:21 step:19709 [D loss: 0.314263, acc.: 92.97%] [G loss: 1.324253]\n",
      "epoch:21 step:19710 [D loss: 0.346593, acc.: 93.75%] [G loss: 1.561352]\n",
      "epoch:21 step:19711 [D loss: 0.299783, acc.: 96.09%] [G loss: 1.682483]\n",
      "epoch:21 step:19712 [D loss: 0.189104, acc.: 98.44%] [G loss: 1.794745]\n",
      "epoch:21 step:19713 [D loss: 0.195742, acc.: 99.22%] [G loss: 1.866267]\n",
      "epoch:21 step:19714 [D loss: 0.819465, acc.: 48.44%] [G loss: 1.303540]\n",
      "epoch:21 step:19715 [D loss: 1.003526, acc.: 32.81%] [G loss: 0.902548]\n",
      "epoch:21 step:19716 [D loss: 0.704895, acc.: 53.91%] [G loss: 1.119991]\n",
      "epoch:21 step:19717 [D loss: 0.625749, acc.: 66.41%] [G loss: 1.136211]\n",
      "epoch:21 step:19718 [D loss: 0.573454, acc.: 69.53%] [G loss: 1.146999]\n",
      "epoch:21 step:19719 [D loss: 0.685448, acc.: 58.59%] [G loss: 0.989471]\n",
      "epoch:21 step:19720 [D loss: 0.525173, acc.: 77.34%] [G loss: 1.022436]\n",
      "epoch:21 step:19721 [D loss: 0.481371, acc.: 82.03%] [G loss: 1.170739]\n",
      "epoch:21 step:19722 [D loss: 0.651875, acc.: 64.06%] [G loss: 1.207558]\n",
      "epoch:21 step:19723 [D loss: 0.810173, acc.: 45.31%] [G loss: 0.900610]\n",
      "epoch:21 step:19724 [D loss: 0.753137, acc.: 46.88%] [G loss: 0.880472]\n",
      "epoch:21 step:19725 [D loss: 0.834552, acc.: 44.53%] [G loss: 0.862880]\n",
      "epoch:21 step:19726 [D loss: 0.714732, acc.: 50.78%] [G loss: 1.136471]\n",
      "epoch:21 step:19727 [D loss: 0.747617, acc.: 52.34%] [G loss: 0.871088]\n",
      "epoch:21 step:19728 [D loss: 0.621706, acc.: 66.41%] [G loss: 1.050956]\n",
      "epoch:21 step:19729 [D loss: 0.546123, acc.: 76.56%] [G loss: 1.264702]\n",
      "epoch:21 step:19730 [D loss: 0.661451, acc.: 60.16%] [G loss: 0.966891]\n",
      "epoch:21 step:19731 [D loss: 0.809487, acc.: 39.84%] [G loss: 0.747057]\n",
      "epoch:21 step:19732 [D loss: 0.680493, acc.: 58.59%] [G loss: 1.039332]\n",
      "epoch:21 step:19733 [D loss: 0.663847, acc.: 59.38%] [G loss: 1.121097]\n",
      "epoch:21 step:19734 [D loss: 0.728959, acc.: 49.22%] [G loss: 1.083393]\n",
      "epoch:21 step:19735 [D loss: 0.666413, acc.: 58.59%] [G loss: 0.997900]\n",
      "epoch:21 step:19736 [D loss: 0.676318, acc.: 54.69%] [G loss: 0.907171]\n",
      "epoch:21 step:19737 [D loss: 0.580678, acc.: 70.31%] [G loss: 1.075142]\n",
      "epoch:21 step:19738 [D loss: 0.634968, acc.: 66.41%] [G loss: 0.834137]\n",
      "epoch:21 step:19739 [D loss: 0.762574, acc.: 47.66%] [G loss: 1.057785]\n",
      "epoch:21 step:19740 [D loss: 0.767377, acc.: 43.75%] [G loss: 0.780659]\n",
      "epoch:21 step:19741 [D loss: 0.622516, acc.: 63.28%] [G loss: 0.905957]\n",
      "epoch:21 step:19742 [D loss: 0.570753, acc.: 73.44%] [G loss: 1.015186]\n",
      "epoch:21 step:19743 [D loss: 0.676444, acc.: 57.03%] [G loss: 1.226765]\n",
      "epoch:21 step:19744 [D loss: 0.570359, acc.: 70.31%] [G loss: 1.191891]\n",
      "epoch:21 step:19745 [D loss: 0.520684, acc.: 77.34%] [G loss: 1.005985]\n",
      "epoch:21 step:19746 [D loss: 0.404555, acc.: 87.50%] [G loss: 1.202179]\n",
      "epoch:21 step:19747 [D loss: 0.473884, acc.: 78.91%] [G loss: 1.226964]\n",
      "epoch:21 step:19748 [D loss: 0.605328, acc.: 63.28%] [G loss: 1.005134]\n",
      "epoch:21 step:19749 [D loss: 0.702838, acc.: 57.81%] [G loss: 0.974370]\n",
      "epoch:21 step:19750 [D loss: 0.663532, acc.: 55.47%] [G loss: 1.115373]\n",
      "epoch:21 step:19751 [D loss: 0.589689, acc.: 67.19%] [G loss: 0.850415]\n",
      "epoch:21 step:19752 [D loss: 0.370051, acc.: 91.41%] [G loss: 1.203863]\n",
      "epoch:21 step:19753 [D loss: 0.432216, acc.: 85.16%] [G loss: 1.458886]\n",
      "epoch:21 step:19754 [D loss: 0.521575, acc.: 78.12%] [G loss: 1.129110]\n",
      "epoch:21 step:19755 [D loss: 0.719601, acc.: 50.00%] [G loss: 1.268599]\n",
      "epoch:21 step:19756 [D loss: 0.665846, acc.: 64.06%] [G loss: 0.995782]\n",
      "epoch:21 step:19757 [D loss: 0.458261, acc.: 83.59%] [G loss: 1.101575]\n",
      "epoch:21 step:19758 [D loss: 0.498090, acc.: 78.91%] [G loss: 1.100893]\n",
      "epoch:21 step:19759 [D loss: 0.419118, acc.: 88.28%] [G loss: 1.433501]\n",
      "epoch:21 step:19760 [D loss: 0.351664, acc.: 89.84%] [G loss: 1.445666]\n",
      "epoch:21 step:19761 [D loss: 0.466879, acc.: 81.25%] [G loss: 1.588990]\n",
      "epoch:21 step:19762 [D loss: 0.546433, acc.: 75.00%] [G loss: 1.078771]\n",
      "epoch:21 step:19763 [D loss: 0.550260, acc.: 68.75%] [G loss: 1.034626]\n",
      "epoch:21 step:19764 [D loss: 0.362370, acc.: 89.84%] [G loss: 1.223457]\n",
      "epoch:21 step:19765 [D loss: 0.439102, acc.: 80.47%] [G loss: 1.030947]\n",
      "epoch:21 step:19766 [D loss: 0.464664, acc.: 83.59%] [G loss: 1.266750]\n",
      "epoch:21 step:19767 [D loss: 0.546446, acc.: 75.00%] [G loss: 1.103312]\n",
      "epoch:21 step:19768 [D loss: 0.743768, acc.: 55.47%] [G loss: 1.170259]\n",
      "epoch:21 step:19769 [D loss: 0.423960, acc.: 87.50%] [G loss: 1.240996]\n",
      "epoch:21 step:19770 [D loss: 0.413403, acc.: 90.62%] [G loss: 1.607396]\n",
      "epoch:21 step:19771 [D loss: 0.757756, acc.: 51.56%] [G loss: 1.149495]\n",
      "epoch:21 step:19772 [D loss: 0.875512, acc.: 36.72%] [G loss: 0.952683]\n",
      "epoch:21 step:19773 [D loss: 0.720966, acc.: 50.00%] [G loss: 0.885347]\n",
      "epoch:21 step:19774 [D loss: 0.760780, acc.: 53.12%] [G loss: 1.076892]\n",
      "epoch:21 step:19775 [D loss: 1.040318, acc.: 25.00%] [G loss: 0.502509]\n",
      "epoch:21 step:19776 [D loss: 0.923901, acc.: 25.78%] [G loss: 0.906442]\n",
      "epoch:21 step:19777 [D loss: 0.908643, acc.: 33.59%] [G loss: 0.891379]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:19778 [D loss: 0.837611, acc.: 46.09%] [G loss: 1.074134]\n",
      "epoch:21 step:19779 [D loss: 0.823423, acc.: 51.56%] [G loss: 1.231713]\n",
      "epoch:21 step:19780 [D loss: 0.925421, acc.: 35.94%] [G loss: 1.034415]\n",
      "epoch:21 step:19781 [D loss: 0.873333, acc.: 34.38%] [G loss: 0.717634]\n",
      "epoch:21 step:19782 [D loss: 0.659303, acc.: 57.81%] [G loss: 1.310245]\n",
      "epoch:21 step:19783 [D loss: 0.673272, acc.: 57.81%] [G loss: 0.893017]\n",
      "epoch:21 step:19784 [D loss: 0.514923, acc.: 84.38%] [G loss: 1.104548]\n",
      "epoch:21 step:19785 [D loss: 0.707302, acc.: 60.94%] [G loss: 1.127816]\n",
      "epoch:21 step:19786 [D loss: 0.574888, acc.: 70.31%] [G loss: 1.101453]\n",
      "epoch:21 step:19787 [D loss: 0.543924, acc.: 72.66%] [G loss: 1.193442]\n",
      "epoch:21 step:19788 [D loss: 0.578248, acc.: 73.44%] [G loss: 1.211212]\n",
      "epoch:21 step:19789 [D loss: 0.483774, acc.: 79.69%] [G loss: 1.229420]\n",
      "epoch:21 step:19790 [D loss: 0.673184, acc.: 57.03%] [G loss: 1.030343]\n",
      "epoch:21 step:19791 [D loss: 0.626288, acc.: 67.19%] [G loss: 1.052397]\n",
      "epoch:21 step:19792 [D loss: 0.606446, acc.: 68.75%] [G loss: 1.044929]\n",
      "epoch:21 step:19793 [D loss: 0.415686, acc.: 85.16%] [G loss: 0.988913]\n",
      "epoch:21 step:19794 [D loss: 0.241486, acc.: 93.75%] [G loss: 1.640789]\n",
      "epoch:21 step:19795 [D loss: 0.280413, acc.: 94.53%] [G loss: 1.439353]\n",
      "epoch:21 step:19796 [D loss: 0.326682, acc.: 90.62%] [G loss: 1.945592]\n",
      "epoch:21 step:19797 [D loss: 1.071970, acc.: 28.91%] [G loss: 1.039238]\n",
      "epoch:21 step:19798 [D loss: 0.979557, acc.: 28.91%] [G loss: 1.039256]\n",
      "epoch:21 step:19799 [D loss: 0.658782, acc.: 55.47%] [G loss: 1.031697]\n",
      "epoch:21 step:19800 [D loss: 0.559642, acc.: 67.97%] [G loss: 1.290345]\n",
      "##############\n",
      "[2.41195135 1.71657873 5.67723662 4.33765772 3.38952924 5.61537827\n",
      " 4.44853775 4.86601986 4.01042686 3.7594403 ]\n",
      "##########\n",
      "epoch:21 step:19801 [D loss: 0.531609, acc.: 74.22%] [G loss: 1.168138]\n",
      "epoch:21 step:19802 [D loss: 0.596210, acc.: 65.62%] [G loss: 1.166681]\n",
      "epoch:21 step:19803 [D loss: 0.611199, acc.: 67.97%] [G loss: 0.965635]\n",
      "epoch:21 step:19804 [D loss: 0.557885, acc.: 75.78%] [G loss: 1.236441]\n",
      "epoch:21 step:19805 [D loss: 0.534562, acc.: 78.91%] [G loss: 1.098395]\n",
      "epoch:21 step:19806 [D loss: 0.730956, acc.: 50.00%] [G loss: 0.859750]\n",
      "epoch:21 step:19807 [D loss: 0.555332, acc.: 70.31%] [G loss: 0.978026]\n",
      "epoch:21 step:19808 [D loss: 0.507117, acc.: 75.78%] [G loss: 1.030933]\n",
      "epoch:21 step:19809 [D loss: 0.683474, acc.: 61.72%] [G loss: 1.045724]\n",
      "epoch:21 step:19810 [D loss: 0.598419, acc.: 67.97%] [G loss: 1.005104]\n",
      "epoch:21 step:19811 [D loss: 0.572793, acc.: 67.19%] [G loss: 0.859996]\n",
      "epoch:21 step:19812 [D loss: 0.540339, acc.: 73.44%] [G loss: 1.040100]\n",
      "epoch:21 step:19813 [D loss: 0.782581, acc.: 51.56%] [G loss: 0.870329]\n",
      "epoch:21 step:19814 [D loss: 0.690399, acc.: 55.47%] [G loss: 0.971418]\n",
      "epoch:21 step:19815 [D loss: 0.730618, acc.: 50.78%] [G loss: 0.892645]\n",
      "epoch:21 step:19816 [D loss: 0.620993, acc.: 67.97%] [G loss: 1.038676]\n",
      "epoch:21 step:19817 [D loss: 0.588615, acc.: 69.53%] [G loss: 1.184961]\n",
      "epoch:21 step:19818 [D loss: 0.537309, acc.: 75.00%] [G loss: 1.075851]\n",
      "epoch:21 step:19819 [D loss: 0.540974, acc.: 74.22%] [G loss: 0.835386]\n",
      "epoch:21 step:19820 [D loss: 0.565336, acc.: 71.09%] [G loss: 0.907251]\n",
      "epoch:21 step:19821 [D loss: 0.673291, acc.: 57.81%] [G loss: 1.305779]\n",
      "epoch:21 step:19822 [D loss: 0.476911, acc.: 81.25%] [G loss: 1.062005]\n",
      "epoch:21 step:19823 [D loss: 0.770542, acc.: 50.78%] [G loss: 1.103551]\n",
      "epoch:21 step:19824 [D loss: 0.909151, acc.: 35.94%] [G loss: 0.924658]\n",
      "epoch:21 step:19825 [D loss: 0.783412, acc.: 42.19%] [G loss: 0.874902]\n",
      "epoch:21 step:19826 [D loss: 0.704241, acc.: 53.12%] [G loss: 0.915520]\n",
      "epoch:21 step:19827 [D loss: 0.553351, acc.: 70.31%] [G loss: 0.928443]\n",
      "epoch:21 step:19828 [D loss: 0.596431, acc.: 64.84%] [G loss: 1.004623]\n",
      "epoch:21 step:19829 [D loss: 0.515205, acc.: 78.12%] [G loss: 1.185801]\n",
      "epoch:21 step:19830 [D loss: 0.762979, acc.: 53.91%] [G loss: 1.036505]\n",
      "epoch:21 step:19831 [D loss: 0.602558, acc.: 69.53%] [G loss: 1.050573]\n",
      "epoch:21 step:19832 [D loss: 0.741690, acc.: 44.53%] [G loss: 0.748629]\n",
      "epoch:21 step:19833 [D loss: 0.465451, acc.: 82.81%] [G loss: 1.275777]\n",
      "epoch:21 step:19834 [D loss: 0.481336, acc.: 80.47%] [G loss: 1.342669]\n",
      "epoch:21 step:19835 [D loss: 0.549865, acc.: 75.78%] [G loss: 1.132648]\n",
      "epoch:21 step:19836 [D loss: 0.380671, acc.: 88.28%] [G loss: 1.283131]\n",
      "epoch:21 step:19837 [D loss: 0.834598, acc.: 39.84%] [G loss: 0.907035]\n",
      "epoch:21 step:19838 [D loss: 0.716062, acc.: 53.91%] [G loss: 1.080386]\n",
      "epoch:21 step:19839 [D loss: 0.559901, acc.: 75.00%] [G loss: 0.934750]\n",
      "epoch:21 step:19840 [D loss: 0.470993, acc.: 85.16%] [G loss: 1.199310]\n",
      "epoch:21 step:19841 [D loss: 0.451890, acc.: 80.47%] [G loss: 1.148398]\n",
      "epoch:21 step:19842 [D loss: 0.534644, acc.: 76.56%] [G loss: 1.051658]\n",
      "epoch:21 step:19843 [D loss: 0.602208, acc.: 66.41%] [G loss: 1.148189]\n",
      "epoch:21 step:19844 [D loss: 0.459249, acc.: 86.72%] [G loss: 1.309493]\n",
      "epoch:21 step:19845 [D loss: 0.475810, acc.: 82.03%] [G loss: 1.186556]\n",
      "epoch:21 step:19846 [D loss: 0.540582, acc.: 70.31%] [G loss: 1.102221]\n",
      "epoch:21 step:19847 [D loss: 0.816611, acc.: 44.53%] [G loss: 0.933273]\n",
      "epoch:21 step:19848 [D loss: 0.807749, acc.: 45.31%] [G loss: 0.727271]\n",
      "epoch:21 step:19849 [D loss: 0.496262, acc.: 82.03%] [G loss: 1.086587]\n",
      "epoch:21 step:19850 [D loss: 0.683546, acc.: 57.81%] [G loss: 0.913081]\n",
      "epoch:21 step:19851 [D loss: 0.953120, acc.: 28.12%] [G loss: 0.675979]\n",
      "epoch:21 step:19852 [D loss: 0.672244, acc.: 57.03%] [G loss: 0.798892]\n",
      "epoch:21 step:19853 [D loss: 0.670783, acc.: 59.38%] [G loss: 0.851518]\n",
      "epoch:21 step:19854 [D loss: 0.885267, acc.: 35.16%] [G loss: 0.809162]\n",
      "epoch:21 step:19855 [D loss: 0.711004, acc.: 50.78%] [G loss: 1.063471]\n",
      "epoch:21 step:19856 [D loss: 0.781216, acc.: 46.09%] [G loss: 0.792878]\n",
      "epoch:21 step:19857 [D loss: 0.849236, acc.: 41.41%] [G loss: 0.862902]\n",
      "epoch:21 step:19858 [D loss: 0.695802, acc.: 55.47%] [G loss: 0.853833]\n",
      "epoch:21 step:19859 [D loss: 0.675767, acc.: 60.94%] [G loss: 1.186946]\n",
      "epoch:21 step:19860 [D loss: 0.670452, acc.: 59.38%] [G loss: 1.217079]\n",
      "epoch:21 step:19861 [D loss: 0.705812, acc.: 52.34%] [G loss: 0.830312]\n",
      "epoch:21 step:19862 [D loss: 0.842989, acc.: 38.28%] [G loss: 1.033695]\n",
      "epoch:21 step:19863 [D loss: 0.744342, acc.: 50.78%] [G loss: 1.055316]\n",
      "epoch:21 step:19864 [D loss: 0.631886, acc.: 63.28%] [G loss: 1.197520]\n",
      "epoch:21 step:19865 [D loss: 0.553247, acc.: 75.00%] [G loss: 1.309249]\n",
      "epoch:21 step:19866 [D loss: 0.668572, acc.: 64.06%] [G loss: 1.132943]\n",
      "epoch:21 step:19867 [D loss: 0.649862, acc.: 63.28%] [G loss: 1.008610]\n",
      "epoch:21 step:19868 [D loss: 0.620994, acc.: 68.75%] [G loss: 1.110277]\n",
      "epoch:21 step:19869 [D loss: 0.610098, acc.: 63.28%] [G loss: 0.955500]\n",
      "epoch:21 step:19870 [D loss: 0.652472, acc.: 59.38%] [G loss: 0.865148]\n",
      "epoch:21 step:19871 [D loss: 0.625641, acc.: 65.62%] [G loss: 0.943474]\n",
      "epoch:21 step:19872 [D loss: 0.780230, acc.: 44.53%] [G loss: 0.914514]\n",
      "epoch:21 step:19873 [D loss: 0.790102, acc.: 49.22%] [G loss: 1.036010]\n",
      "epoch:21 step:19874 [D loss: 0.694126, acc.: 55.47%] [G loss: 1.055326]\n",
      "epoch:21 step:19875 [D loss: 0.724380, acc.: 53.12%] [G loss: 0.870549]\n",
      "epoch:21 step:19876 [D loss: 0.686753, acc.: 54.69%] [G loss: 1.082319]\n",
      "epoch:21 step:19877 [D loss: 0.549812, acc.: 75.00%] [G loss: 1.006609]\n",
      "epoch:21 step:19878 [D loss: 0.536859, acc.: 71.88%] [G loss: 1.193975]\n",
      "epoch:21 step:19879 [D loss: 0.774549, acc.: 49.22%] [G loss: 1.013855]\n",
      "epoch:21 step:19880 [D loss: 0.813876, acc.: 46.88%] [G loss: 0.896467]\n",
      "epoch:21 step:19881 [D loss: 0.718276, acc.: 53.12%] [G loss: 0.812045]\n",
      "epoch:21 step:19882 [D loss: 0.847487, acc.: 40.62%] [G loss: 0.699223]\n",
      "epoch:21 step:19883 [D loss: 0.634826, acc.: 67.19%] [G loss: 0.844939]\n",
      "epoch:21 step:19884 [D loss: 0.612264, acc.: 68.75%] [G loss: 1.042775]\n",
      "epoch:21 step:19885 [D loss: 0.737522, acc.: 51.56%] [G loss: 0.985222]\n",
      "epoch:21 step:19886 [D loss: 0.540794, acc.: 75.00%] [G loss: 1.033639]\n",
      "epoch:21 step:19887 [D loss: 0.614227, acc.: 64.06%] [G loss: 1.087795]\n",
      "epoch:21 step:19888 [D loss: 0.618945, acc.: 66.41%] [G loss: 0.959801]\n",
      "epoch:21 step:19889 [D loss: 0.647540, acc.: 55.47%] [G loss: 1.027775]\n",
      "epoch:21 step:19890 [D loss: 0.561185, acc.: 71.88%] [G loss: 0.937655]\n",
      "epoch:21 step:19891 [D loss: 0.738586, acc.: 50.00%] [G loss: 0.910130]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:19892 [D loss: 0.601606, acc.: 65.62%] [G loss: 0.899890]\n",
      "epoch:21 step:19893 [D loss: 0.731744, acc.: 52.34%] [G loss: 1.113329]\n",
      "epoch:21 step:19894 [D loss: 0.791565, acc.: 50.78%] [G loss: 1.016746]\n",
      "epoch:21 step:19895 [D loss: 0.798130, acc.: 43.75%] [G loss: 1.020350]\n",
      "epoch:21 step:19896 [D loss: 0.670420, acc.: 60.94%] [G loss: 1.284671]\n",
      "epoch:21 step:19897 [D loss: 0.372081, acc.: 92.19%] [G loss: 1.259516]\n",
      "epoch:21 step:19898 [D loss: 0.340825, acc.: 92.19%] [G loss: 1.432802]\n",
      "epoch:21 step:19899 [D loss: 0.423284, acc.: 88.28%] [G loss: 1.457352]\n",
      "epoch:21 step:19900 [D loss: 0.364158, acc.: 91.41%] [G loss: 1.229337]\n",
      "epoch:21 step:19901 [D loss: 0.780849, acc.: 50.78%] [G loss: 1.254599]\n",
      "epoch:21 step:19902 [D loss: 0.642988, acc.: 58.59%] [G loss: 0.972545]\n",
      "epoch:21 step:19903 [D loss: 0.484665, acc.: 82.81%] [G loss: 1.005566]\n",
      "epoch:21 step:19904 [D loss: 0.777247, acc.: 47.66%] [G loss: 0.891787]\n",
      "epoch:21 step:19905 [D loss: 0.672335, acc.: 64.84%] [G loss: 1.097965]\n",
      "epoch:21 step:19906 [D loss: 0.552925, acc.: 74.22%] [G loss: 1.083458]\n",
      "epoch:21 step:19907 [D loss: 0.306141, acc.: 87.50%] [G loss: 1.212548]\n",
      "epoch:21 step:19908 [D loss: 0.363535, acc.: 92.19%] [G loss: 1.408843]\n",
      "epoch:21 step:19909 [D loss: 0.317247, acc.: 93.75%] [G loss: 1.338985]\n",
      "epoch:21 step:19910 [D loss: 0.838650, acc.: 46.09%] [G loss: 1.062135]\n",
      "epoch:21 step:19911 [D loss: 0.809639, acc.: 53.91%] [G loss: 1.134851]\n",
      "epoch:21 step:19912 [D loss: 0.793341, acc.: 51.56%] [G loss: 0.740601]\n",
      "epoch:21 step:19913 [D loss: 0.713227, acc.: 50.00%] [G loss: 1.102967]\n",
      "epoch:21 step:19914 [D loss: 0.780758, acc.: 41.41%] [G loss: 0.977602]\n",
      "epoch:21 step:19915 [D loss: 0.610725, acc.: 67.19%] [G loss: 1.094441]\n",
      "epoch:21 step:19916 [D loss: 0.622883, acc.: 67.97%] [G loss: 1.104669]\n",
      "epoch:21 step:19917 [D loss: 0.807713, acc.: 41.41%] [G loss: 0.878159]\n",
      "epoch:21 step:19918 [D loss: 0.680944, acc.: 61.72%] [G loss: 1.151072]\n",
      "epoch:21 step:19919 [D loss: 0.765305, acc.: 46.88%] [G loss: 1.097214]\n",
      "epoch:21 step:19920 [D loss: 0.662623, acc.: 62.50%] [G loss: 1.069407]\n",
      "epoch:21 step:19921 [D loss: 0.603294, acc.: 67.19%] [G loss: 1.094498]\n",
      "epoch:21 step:19922 [D loss: 0.469288, acc.: 85.94%] [G loss: 1.278722]\n",
      "epoch:21 step:19923 [D loss: 0.338984, acc.: 94.53%] [G loss: 1.377958]\n",
      "epoch:21 step:19924 [D loss: 0.425562, acc.: 86.72%] [G loss: 1.322665]\n",
      "epoch:21 step:19925 [D loss: 0.487937, acc.: 79.69%] [G loss: 1.093542]\n",
      "epoch:21 step:19926 [D loss: 0.814105, acc.: 51.56%] [G loss: 0.966701]\n",
      "epoch:21 step:19927 [D loss: 0.541291, acc.: 75.00%] [G loss: 1.236790]\n",
      "epoch:21 step:19928 [D loss: 0.681380, acc.: 60.16%] [G loss: 1.084455]\n",
      "epoch:21 step:19929 [D loss: 0.557598, acc.: 71.88%] [G loss: 1.048720]\n",
      "epoch:21 step:19930 [D loss: 0.529800, acc.: 78.12%] [G loss: 1.125153]\n",
      "epoch:21 step:19931 [D loss: 0.603966, acc.: 69.53%] [G loss: 1.239050]\n",
      "epoch:21 step:19932 [D loss: 0.872030, acc.: 39.84%] [G loss: 1.031519]\n",
      "epoch:21 step:19933 [D loss: 1.009563, acc.: 28.91%] [G loss: 0.712986]\n",
      "epoch:21 step:19934 [D loss: 0.686783, acc.: 53.12%] [G loss: 0.924977]\n",
      "epoch:21 step:19935 [D loss: 0.679252, acc.: 63.28%] [G loss: 0.903315]\n",
      "epoch:21 step:19936 [D loss: 0.603231, acc.: 68.75%] [G loss: 0.987965]\n",
      "epoch:21 step:19937 [D loss: 0.820477, acc.: 49.22%] [G loss: 0.808374]\n",
      "epoch:21 step:19938 [D loss: 0.502471, acc.: 82.81%] [G loss: 1.060346]\n",
      "epoch:21 step:19939 [D loss: 0.750204, acc.: 53.12%] [G loss: 0.903512]\n",
      "epoch:21 step:19940 [D loss: 0.545396, acc.: 74.22%] [G loss: 1.067620]\n",
      "epoch:21 step:19941 [D loss: 0.501167, acc.: 82.03%] [G loss: 1.107503]\n",
      "epoch:21 step:19942 [D loss: 0.686368, acc.: 56.25%] [G loss: 1.053920]\n",
      "epoch:21 step:19943 [D loss: 0.862381, acc.: 32.03%] [G loss: 0.974455]\n",
      "epoch:21 step:19944 [D loss: 0.449432, acc.: 85.16%] [G loss: 1.120700]\n",
      "epoch:21 step:19945 [D loss: 0.513030, acc.: 80.47%] [G loss: 1.087972]\n",
      "epoch:21 step:19946 [D loss: 0.628073, acc.: 62.50%] [G loss: 0.963226]\n",
      "epoch:21 step:19947 [D loss: 0.647182, acc.: 63.28%] [G loss: 1.075360]\n",
      "epoch:21 step:19948 [D loss: 0.646674, acc.: 59.38%] [G loss: 0.908790]\n",
      "epoch:21 step:19949 [D loss: 0.546415, acc.: 75.00%] [G loss: 1.083882]\n",
      "epoch:21 step:19950 [D loss: 0.525233, acc.: 78.12%] [G loss: 1.037592]\n",
      "epoch:21 step:19951 [D loss: 0.610486, acc.: 66.41%] [G loss: 1.110930]\n",
      "epoch:21 step:19952 [D loss: 0.660797, acc.: 57.81%] [G loss: 1.005268]\n",
      "epoch:21 step:19953 [D loss: 0.611639, acc.: 60.94%] [G loss: 1.139468]\n",
      "epoch:21 step:19954 [D loss: 0.588854, acc.: 68.75%] [G loss: 1.033380]\n",
      "epoch:21 step:19955 [D loss: 0.507228, acc.: 75.78%] [G loss: 1.089460]\n",
      "epoch:21 step:19956 [D loss: 0.398864, acc.: 81.25%] [G loss: 1.215710]\n",
      "epoch:21 step:19957 [D loss: 0.437707, acc.: 84.38%] [G loss: 1.276212]\n",
      "epoch:21 step:19958 [D loss: 0.765135, acc.: 50.78%] [G loss: 1.193920]\n",
      "epoch:21 step:19959 [D loss: 0.697452, acc.: 58.59%] [G loss: 0.989578]\n",
      "epoch:21 step:19960 [D loss: 0.665068, acc.: 55.47%] [G loss: 1.102432]\n",
      "epoch:21 step:19961 [D loss: 0.612479, acc.: 62.50%] [G loss: 1.111088]\n",
      "epoch:21 step:19962 [D loss: 0.492673, acc.: 81.25%] [G loss: 1.237029]\n",
      "epoch:21 step:19963 [D loss: 0.383645, acc.: 91.41%] [G loss: 1.312762]\n",
      "epoch:21 step:19964 [D loss: 0.608770, acc.: 66.41%] [G loss: 1.201742]\n",
      "epoch:21 step:19965 [D loss: 0.575660, acc.: 72.66%] [G loss: 1.191080]\n",
      "epoch:21 step:19966 [D loss: 0.466889, acc.: 78.12%] [G loss: 0.996102]\n",
      "epoch:21 step:19967 [D loss: 0.613125, acc.: 64.84%] [G loss: 1.094574]\n",
      "epoch:21 step:19968 [D loss: 0.842236, acc.: 52.34%] [G loss: 0.577305]\n",
      "epoch:21 step:19969 [D loss: 0.753251, acc.: 59.38%] [G loss: 0.996544]\n",
      "epoch:21 step:19970 [D loss: 0.438218, acc.: 82.81%] [G loss: 1.475025]\n",
      "epoch:21 step:19971 [D loss: 0.721423, acc.: 54.69%] [G loss: 1.344166]\n",
      "epoch:21 step:19972 [D loss: 0.911505, acc.: 35.94%] [G loss: 1.215239]\n",
      "epoch:21 step:19973 [D loss: 0.949285, acc.: 34.38%] [G loss: 1.094169]\n",
      "epoch:21 step:19974 [D loss: 0.689048, acc.: 58.59%] [G loss: 1.210808]\n",
      "epoch:21 step:19975 [D loss: 0.441398, acc.: 85.94%] [G loss: 1.329239]\n",
      "epoch:21 step:19976 [D loss: 0.683125, acc.: 61.72%] [G loss: 1.043534]\n",
      "epoch:21 step:19977 [D loss: 0.536935, acc.: 71.88%] [G loss: 1.043634]\n",
      "epoch:21 step:19978 [D loss: 0.680903, acc.: 59.38%] [G loss: 1.078241]\n",
      "epoch:21 step:19979 [D loss: 0.583937, acc.: 69.53%] [G loss: 0.970566]\n",
      "epoch:21 step:19980 [D loss: 0.502270, acc.: 77.34%] [G loss: 1.039396]\n",
      "epoch:21 step:19981 [D loss: 0.657046, acc.: 63.28%] [G loss: 0.946033]\n",
      "epoch:21 step:19982 [D loss: 0.773066, acc.: 44.53%] [G loss: 0.858381]\n",
      "epoch:21 step:19983 [D loss: 0.562832, acc.: 71.88%] [G loss: 1.117181]\n",
      "epoch:21 step:19984 [D loss: 0.633217, acc.: 62.50%] [G loss: 1.197955]\n",
      "epoch:21 step:19985 [D loss: 0.566252, acc.: 68.75%] [G loss: 1.182782]\n",
      "epoch:21 step:19986 [D loss: 0.643399, acc.: 60.94%] [G loss: 1.249997]\n",
      "epoch:21 step:19987 [D loss: 0.613030, acc.: 65.62%] [G loss: 1.125413]\n",
      "epoch:21 step:19988 [D loss: 0.662561, acc.: 63.28%] [G loss: 1.057781]\n",
      "epoch:21 step:19989 [D loss: 0.517424, acc.: 76.56%] [G loss: 1.105390]\n",
      "epoch:21 step:19990 [D loss: 0.406230, acc.: 89.06%] [G loss: 1.475080]\n",
      "epoch:21 step:19991 [D loss: 0.441691, acc.: 86.72%] [G loss: 1.249587]\n",
      "epoch:21 step:19992 [D loss: 0.453971, acc.: 83.59%] [G loss: 1.230683]\n",
      "epoch:21 step:19993 [D loss: 0.715854, acc.: 58.59%] [G loss: 1.237963]\n",
      "epoch:21 step:19994 [D loss: 0.760477, acc.: 45.31%] [G loss: 1.001723]\n",
      "epoch:21 step:19995 [D loss: 0.656040, acc.: 63.28%] [G loss: 0.957471]\n",
      "epoch:21 step:19996 [D loss: 0.693757, acc.: 58.59%] [G loss: 1.054294]\n",
      "epoch:21 step:19997 [D loss: 0.670787, acc.: 59.38%] [G loss: 1.191399]\n",
      "epoch:21 step:19998 [D loss: 0.546243, acc.: 75.78%] [G loss: 0.940559]\n",
      "epoch:21 step:19999 [D loss: 0.537135, acc.: 76.56%] [G loss: 1.091401]\n",
      "epoch:21 step:20000 [D loss: 0.696572, acc.: 54.69%] [G loss: 1.012669]\n",
      "##############\n",
      "[2.04863944 1.46429518 5.53757714 4.14135468 2.90334689 5.14537588\n",
      " 3.95003354 4.36905811 3.69970059 3.62348339]\n",
      "##########\n",
      "epoch:21 step:20001 [D loss: 0.680409, acc.: 58.59%] [G loss: 0.808826]\n",
      "epoch:21 step:20002 [D loss: 0.615145, acc.: 67.19%] [G loss: 1.065468]\n",
      "epoch:21 step:20003 [D loss: 0.568623, acc.: 72.66%] [G loss: 0.873179]\n",
      "epoch:21 step:20004 [D loss: 0.508024, acc.: 75.00%] [G loss: 1.028934]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20005 [D loss: 0.483158, acc.: 79.69%] [G loss: 1.099626]\n",
      "epoch:21 step:20006 [D loss: 0.722999, acc.: 55.47%] [G loss: 1.004629]\n",
      "epoch:21 step:20007 [D loss: 0.657705, acc.: 63.28%] [G loss: 1.188860]\n",
      "epoch:21 step:20008 [D loss: 0.712629, acc.: 57.03%] [G loss: 0.899006]\n",
      "epoch:21 step:20009 [D loss: 0.700270, acc.: 55.47%] [G loss: 1.089222]\n",
      "epoch:21 step:20010 [D loss: 0.619009, acc.: 65.62%] [G loss: 1.122842]\n",
      "epoch:21 step:20011 [D loss: 0.545043, acc.: 78.91%] [G loss: 0.968114]\n",
      "epoch:21 step:20012 [D loss: 0.596578, acc.: 70.31%] [G loss: 1.039956]\n",
      "epoch:21 step:20013 [D loss: 0.612525, acc.: 65.62%] [G loss: 0.950820]\n",
      "epoch:21 step:20014 [D loss: 0.792895, acc.: 46.88%] [G loss: 1.040948]\n",
      "epoch:21 step:20015 [D loss: 0.635334, acc.: 66.41%] [G loss: 0.920106]\n",
      "epoch:21 step:20016 [D loss: 0.638610, acc.: 61.72%] [G loss: 0.976188]\n",
      "epoch:21 step:20017 [D loss: 0.599140, acc.: 70.31%] [G loss: 1.097154]\n",
      "epoch:21 step:20018 [D loss: 0.677298, acc.: 59.38%] [G loss: 0.919979]\n",
      "epoch:21 step:20019 [D loss: 0.448669, acc.: 83.59%] [G loss: 1.045732]\n",
      "epoch:21 step:20020 [D loss: 0.439099, acc.: 83.59%] [G loss: 1.132608]\n",
      "epoch:21 step:20021 [D loss: 0.477980, acc.: 78.12%] [G loss: 1.067732]\n",
      "epoch:21 step:20022 [D loss: 0.373874, acc.: 90.62%] [G loss: 1.302559]\n",
      "epoch:21 step:20023 [D loss: 0.315576, acc.: 93.75%] [G loss: 1.501802]\n",
      "epoch:21 step:20024 [D loss: 0.324622, acc.: 96.88%] [G loss: 1.313331]\n",
      "epoch:21 step:20025 [D loss: 0.882831, acc.: 39.84%] [G loss: 0.959367]\n",
      "epoch:21 step:20026 [D loss: 0.763473, acc.: 50.00%] [G loss: 1.142579]\n",
      "epoch:21 step:20027 [D loss: 0.694837, acc.: 53.12%] [G loss: 0.944678]\n",
      "epoch:21 step:20028 [D loss: 0.582183, acc.: 71.09%] [G loss: 1.149268]\n",
      "epoch:21 step:20029 [D loss: 0.460848, acc.: 83.59%] [G loss: 1.207383]\n",
      "epoch:21 step:20030 [D loss: 0.465961, acc.: 80.47%] [G loss: 1.070795]\n",
      "epoch:21 step:20031 [D loss: 0.440466, acc.: 86.72%] [G loss: 1.108091]\n",
      "epoch:21 step:20032 [D loss: 0.668806, acc.: 61.72%] [G loss: 1.146514]\n",
      "epoch:21 step:20033 [D loss: 0.608816, acc.: 66.41%] [G loss: 1.113263]\n",
      "epoch:21 step:20034 [D loss: 0.560167, acc.: 70.31%] [G loss: 0.989785]\n",
      "epoch:21 step:20035 [D loss: 0.485883, acc.: 76.56%] [G loss: 1.060205]\n",
      "epoch:21 step:20036 [D loss: 0.460708, acc.: 84.38%] [G loss: 1.162103]\n",
      "epoch:21 step:20037 [D loss: 0.522424, acc.: 80.47%] [G loss: 1.300676]\n",
      "epoch:21 step:20038 [D loss: 0.734886, acc.: 48.44%] [G loss: 1.064525]\n",
      "epoch:21 step:20039 [D loss: 0.699069, acc.: 53.91%] [G loss: 1.131629]\n",
      "epoch:21 step:20040 [D loss: 0.713298, acc.: 57.81%] [G loss: 1.083749]\n",
      "epoch:21 step:20041 [D loss: 0.723398, acc.: 50.78%] [G loss: 1.021973]\n",
      "epoch:21 step:20042 [D loss: 0.668765, acc.: 61.72%] [G loss: 1.147495]\n",
      "epoch:21 step:20043 [D loss: 0.492350, acc.: 79.69%] [G loss: 1.191721]\n",
      "epoch:21 step:20044 [D loss: 0.420090, acc.: 86.72%] [G loss: 1.257910]\n",
      "epoch:21 step:20045 [D loss: 0.648375, acc.: 58.59%] [G loss: 1.267877]\n",
      "epoch:21 step:20046 [D loss: 0.592837, acc.: 68.75%] [G loss: 1.134648]\n",
      "epoch:21 step:20047 [D loss: 0.552938, acc.: 77.34%] [G loss: 1.085735]\n",
      "epoch:21 step:20048 [D loss: 0.509807, acc.: 79.69%] [G loss: 1.127617]\n",
      "epoch:21 step:20049 [D loss: 0.668706, acc.: 60.94%] [G loss: 1.058423]\n",
      "epoch:21 step:20050 [D loss: 0.852783, acc.: 46.88%] [G loss: 1.008109]\n",
      "epoch:21 step:20051 [D loss: 0.762213, acc.: 45.31%] [G loss: 0.963886]\n",
      "epoch:21 step:20052 [D loss: 0.753005, acc.: 51.56%] [G loss: 0.917348]\n",
      "epoch:21 step:20053 [D loss: 0.677106, acc.: 55.47%] [G loss: 0.900890]\n",
      "epoch:21 step:20054 [D loss: 0.548626, acc.: 76.56%] [G loss: 1.094048]\n",
      "epoch:21 step:20055 [D loss: 0.453580, acc.: 82.81%] [G loss: 1.292025]\n",
      "epoch:21 step:20056 [D loss: 0.652102, acc.: 63.28%] [G loss: 1.222458]\n",
      "epoch:21 step:20057 [D loss: 0.544435, acc.: 74.22%] [G loss: 1.076258]\n",
      "epoch:21 step:20058 [D loss: 0.601005, acc.: 68.75%] [G loss: 1.181238]\n",
      "epoch:21 step:20059 [D loss: 0.752926, acc.: 41.41%] [G loss: 1.050888]\n",
      "epoch:21 step:20060 [D loss: 0.657347, acc.: 61.72%] [G loss: 0.886122]\n",
      "epoch:21 step:20061 [D loss: 0.643821, acc.: 61.72%] [G loss: 0.859801]\n",
      "epoch:21 step:20062 [D loss: 0.654758, acc.: 64.06%] [G loss: 1.043679]\n",
      "epoch:21 step:20063 [D loss: 0.644223, acc.: 60.94%] [G loss: 0.957473]\n",
      "epoch:21 step:20064 [D loss: 0.676691, acc.: 57.81%] [G loss: 1.106049]\n",
      "epoch:21 step:20065 [D loss: 0.535020, acc.: 75.00%] [G loss: 0.843666]\n",
      "epoch:21 step:20066 [D loss: 0.706460, acc.: 53.91%] [G loss: 1.011121]\n",
      "epoch:21 step:20067 [D loss: 0.575877, acc.: 73.44%] [G loss: 1.152076]\n",
      "epoch:21 step:20068 [D loss: 0.483499, acc.: 80.47%] [G loss: 1.183755]\n",
      "epoch:21 step:20069 [D loss: 0.627367, acc.: 63.28%] [G loss: 1.013111]\n",
      "epoch:21 step:20070 [D loss: 0.640855, acc.: 64.84%] [G loss: 1.059189]\n",
      "epoch:21 step:20071 [D loss: 0.451660, acc.: 81.25%] [G loss: 1.098277]\n",
      "epoch:21 step:20072 [D loss: 0.525253, acc.: 78.12%] [G loss: 1.127859]\n",
      "epoch:21 step:20073 [D loss: 0.504543, acc.: 71.88%] [G loss: 1.003143]\n",
      "epoch:21 step:20074 [D loss: 0.274314, acc.: 96.09%] [G loss: 1.512186]\n",
      "epoch:21 step:20075 [D loss: 0.271109, acc.: 96.88%] [G loss: 1.478046]\n",
      "epoch:21 step:20076 [D loss: 0.363099, acc.: 90.62%] [G loss: 1.513695]\n",
      "epoch:21 step:20077 [D loss: 0.302967, acc.: 95.31%] [G loss: 1.531654]\n",
      "epoch:21 step:20078 [D loss: 0.334567, acc.: 94.53%] [G loss: 1.478102]\n",
      "epoch:21 step:20079 [D loss: 0.516563, acc.: 76.56%] [G loss: 1.095999]\n",
      "epoch:21 step:20080 [D loss: 0.611444, acc.: 63.28%] [G loss: 1.251390]\n",
      "epoch:21 step:20081 [D loss: 0.297765, acc.: 91.41%] [G loss: 1.563776]\n",
      "epoch:21 step:20082 [D loss: 0.272640, acc.: 96.88%] [G loss: 1.551107]\n",
      "epoch:21 step:20083 [D loss: 0.375088, acc.: 88.28%] [G loss: 1.342430]\n",
      "epoch:21 step:20084 [D loss: 0.856452, acc.: 46.88%] [G loss: 0.960482]\n",
      "epoch:21 step:20085 [D loss: 0.766578, acc.: 50.00%] [G loss: 1.104931]\n",
      "epoch:21 step:20086 [D loss: 0.764405, acc.: 50.00%] [G loss: 0.956957]\n",
      "epoch:21 step:20087 [D loss: 0.826218, acc.: 47.66%] [G loss: 0.754212]\n",
      "epoch:21 step:20088 [D loss: 0.924553, acc.: 46.88%] [G loss: 1.064277]\n",
      "epoch:21 step:20089 [D loss: 0.926245, acc.: 30.47%] [G loss: 0.816380]\n",
      "epoch:21 step:20090 [D loss: 0.922695, acc.: 35.94%] [G loss: 0.920722]\n",
      "epoch:21 step:20091 [D loss: 0.922249, acc.: 39.84%] [G loss: 0.909971]\n",
      "epoch:21 step:20092 [D loss: 0.884384, acc.: 40.62%] [G loss: 1.015837]\n",
      "epoch:21 step:20093 [D loss: 0.839210, acc.: 46.09%] [G loss: 1.228280]\n",
      "epoch:21 step:20094 [D loss: 0.699278, acc.: 56.25%] [G loss: 1.224956]\n",
      "epoch:21 step:20095 [D loss: 0.754520, acc.: 52.34%] [G loss: 0.868154]\n",
      "epoch:21 step:20096 [D loss: 0.617965, acc.: 66.41%] [G loss: 1.274129]\n",
      "epoch:21 step:20097 [D loss: 0.660134, acc.: 64.84%] [G loss: 1.154262]\n",
      "epoch:21 step:20098 [D loss: 0.666849, acc.: 60.16%] [G loss: 1.213895]\n",
      "epoch:21 step:20099 [D loss: 0.746612, acc.: 51.56%] [G loss: 1.340018]\n",
      "epoch:21 step:20100 [D loss: 0.671621, acc.: 59.38%] [G loss: 1.141326]\n",
      "epoch:21 step:20101 [D loss: 0.702110, acc.: 54.69%] [G loss: 1.086589]\n",
      "epoch:21 step:20102 [D loss: 0.676376, acc.: 53.91%] [G loss: 1.217728]\n",
      "epoch:21 step:20103 [D loss: 0.611903, acc.: 65.62%] [G loss: 1.176690]\n",
      "epoch:21 step:20104 [D loss: 0.581449, acc.: 67.97%] [G loss: 1.142840]\n",
      "epoch:21 step:20105 [D loss: 0.643770, acc.: 61.72%] [G loss: 1.064365]\n",
      "epoch:21 step:20106 [D loss: 0.636858, acc.: 60.16%] [G loss: 0.927200]\n",
      "epoch:21 step:20107 [D loss: 0.522826, acc.: 76.56%] [G loss: 1.092480]\n",
      "epoch:21 step:20108 [D loss: 0.632549, acc.: 66.41%] [G loss: 1.018376]\n",
      "epoch:21 step:20109 [D loss: 0.563514, acc.: 69.53%] [G loss: 1.077997]\n",
      "epoch:21 step:20110 [D loss: 0.453340, acc.: 80.47%] [G loss: 1.423449]\n",
      "epoch:21 step:20111 [D loss: 0.554409, acc.: 77.34%] [G loss: 1.415976]\n",
      "epoch:21 step:20112 [D loss: 0.475443, acc.: 77.34%] [G loss: 1.129434]\n",
      "epoch:21 step:20113 [D loss: 0.382007, acc.: 89.84%] [G loss: 1.433845]\n",
      "epoch:21 step:20114 [D loss: 0.951134, acc.: 32.03%] [G loss: 0.945156]\n",
      "epoch:21 step:20115 [D loss: 0.806213, acc.: 43.75%] [G loss: 0.921049]\n",
      "epoch:21 step:20116 [D loss: 0.704480, acc.: 55.47%] [G loss: 0.865389]\n",
      "epoch:21 step:20117 [D loss: 0.794575, acc.: 47.66%] [G loss: 0.893534]\n",
      "epoch:21 step:20118 [D loss: 0.702508, acc.: 57.03%] [G loss: 0.944241]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20119 [D loss: 0.658410, acc.: 56.25%] [G loss: 1.083494]\n",
      "epoch:21 step:20120 [D loss: 0.565675, acc.: 72.66%] [G loss: 1.363879]\n",
      "epoch:21 step:20121 [D loss: 0.655652, acc.: 63.28%] [G loss: 1.176513]\n",
      "epoch:21 step:20122 [D loss: 0.717087, acc.: 55.47%] [G loss: 1.182604]\n",
      "epoch:21 step:20123 [D loss: 0.704125, acc.: 53.91%] [G loss: 1.124145]\n",
      "epoch:21 step:20124 [D loss: 0.650100, acc.: 66.41%] [G loss: 0.923421]\n",
      "epoch:21 step:20125 [D loss: 0.538854, acc.: 78.12%] [G loss: 1.160022]\n",
      "epoch:21 step:20126 [D loss: 0.473263, acc.: 75.00%] [G loss: 1.338367]\n",
      "epoch:21 step:20127 [D loss: 0.615705, acc.: 69.53%] [G loss: 1.111055]\n",
      "epoch:21 step:20128 [D loss: 0.484523, acc.: 78.91%] [G loss: 1.420556]\n",
      "epoch:21 step:20129 [D loss: 0.434535, acc.: 83.59%] [G loss: 1.429284]\n",
      "epoch:21 step:20130 [D loss: 0.504986, acc.: 76.56%] [G loss: 1.091345]\n",
      "epoch:21 step:20131 [D loss: 0.525289, acc.: 78.91%] [G loss: 1.034956]\n",
      "epoch:21 step:20132 [D loss: 0.730836, acc.: 50.00%] [G loss: 1.023548]\n",
      "epoch:21 step:20133 [D loss: 0.607005, acc.: 67.97%] [G loss: 1.011078]\n",
      "epoch:21 step:20134 [D loss: 0.460183, acc.: 78.12%] [G loss: 1.131306]\n",
      "epoch:21 step:20135 [D loss: 0.928632, acc.: 37.50%] [G loss: 0.967530]\n",
      "epoch:21 step:20136 [D loss: 0.731425, acc.: 50.78%] [G loss: 0.834069]\n",
      "epoch:21 step:20137 [D loss: 0.872586, acc.: 36.72%] [G loss: 0.944594]\n",
      "epoch:21 step:20138 [D loss: 0.896624, acc.: 38.28%] [G loss: 0.905688]\n",
      "epoch:21 step:20139 [D loss: 0.725851, acc.: 50.00%] [G loss: 1.358457]\n",
      "epoch:21 step:20140 [D loss: 0.745121, acc.: 50.00%] [G loss: 1.097373]\n",
      "epoch:21 step:20141 [D loss: 0.673855, acc.: 56.25%] [G loss: 1.195133]\n",
      "epoch:21 step:20142 [D loss: 0.644921, acc.: 60.16%] [G loss: 1.019400]\n",
      "epoch:21 step:20143 [D loss: 0.617598, acc.: 62.50%] [G loss: 1.041992]\n",
      "epoch:21 step:20144 [D loss: 0.672469, acc.: 59.38%] [G loss: 1.010216]\n",
      "epoch:21 step:20145 [D loss: 0.625717, acc.: 64.06%] [G loss: 1.142362]\n",
      "epoch:21 step:20146 [D loss: 0.569202, acc.: 74.22%] [G loss: 1.102975]\n",
      "epoch:21 step:20147 [D loss: 0.579707, acc.: 71.09%] [G loss: 1.118240]\n",
      "epoch:21 step:20148 [D loss: 0.344876, acc.: 87.50%] [G loss: 1.432580]\n",
      "epoch:21 step:20149 [D loss: 0.533917, acc.: 75.78%] [G loss: 1.272100]\n",
      "epoch:21 step:20150 [D loss: 0.626412, acc.: 67.97%] [G loss: 1.323277]\n",
      "epoch:21 step:20151 [D loss: 0.302135, acc.: 98.44%] [G loss: 1.394702]\n",
      "epoch:21 step:20152 [D loss: 0.415372, acc.: 89.84%] [G loss: 1.508336]\n",
      "epoch:21 step:20153 [D loss: 0.708565, acc.: 52.34%] [G loss: 1.257938]\n",
      "epoch:21 step:20154 [D loss: 0.725087, acc.: 61.72%] [G loss: 1.111062]\n",
      "epoch:21 step:20155 [D loss: 0.700930, acc.: 53.12%] [G loss: 0.850697]\n",
      "epoch:21 step:20156 [D loss: 0.614374, acc.: 63.28%] [G loss: 1.071663]\n",
      "epoch:21 step:20157 [D loss: 0.587955, acc.: 67.19%] [G loss: 0.976082]\n",
      "epoch:21 step:20158 [D loss: 0.618315, acc.: 65.62%] [G loss: 1.100103]\n",
      "epoch:21 step:20159 [D loss: 0.525429, acc.: 77.34%] [G loss: 1.050348]\n",
      "epoch:21 step:20160 [D loss: 0.528493, acc.: 76.56%] [G loss: 1.078221]\n",
      "epoch:21 step:20161 [D loss: 0.380098, acc.: 83.59%] [G loss: 1.245621]\n",
      "epoch:21 step:20162 [D loss: 0.395702, acc.: 89.84%] [G loss: 1.270792]\n",
      "epoch:21 step:20163 [D loss: 0.687450, acc.: 62.50%] [G loss: 0.908201]\n",
      "epoch:21 step:20164 [D loss: 0.471505, acc.: 83.59%] [G loss: 1.274076]\n",
      "epoch:21 step:20165 [D loss: 0.745742, acc.: 52.34%] [G loss: 1.104750]\n",
      "epoch:21 step:20166 [D loss: 0.663036, acc.: 61.72%] [G loss: 0.944444]\n",
      "epoch:21 step:20167 [D loss: 0.468508, acc.: 88.28%] [G loss: 1.142638]\n",
      "epoch:21 step:20168 [D loss: 0.586905, acc.: 72.66%] [G loss: 1.286925]\n",
      "epoch:21 step:20169 [D loss: 0.570180, acc.: 72.66%] [G loss: 1.232227]\n",
      "epoch:21 step:20170 [D loss: 0.703691, acc.: 57.81%] [G loss: 1.175847]\n",
      "epoch:21 step:20171 [D loss: 0.609777, acc.: 64.06%] [G loss: 1.042290]\n",
      "epoch:21 step:20172 [D loss: 0.668377, acc.: 59.38%] [G loss: 1.152872]\n",
      "epoch:21 step:20173 [D loss: 0.589280, acc.: 69.53%] [G loss: 0.849315]\n",
      "epoch:21 step:20174 [D loss: 0.512065, acc.: 79.69%] [G loss: 1.148125]\n",
      "epoch:21 step:20175 [D loss: 0.492863, acc.: 81.25%] [G loss: 1.268834]\n",
      "epoch:21 step:20176 [D loss: 0.307100, acc.: 96.09%] [G loss: 1.545807]\n",
      "epoch:21 step:20177 [D loss: 0.788543, acc.: 46.88%] [G loss: 1.044598]\n",
      "epoch:21 step:20178 [D loss: 0.862557, acc.: 46.88%] [G loss: 1.280717]\n",
      "epoch:21 step:20179 [D loss: 0.737260, acc.: 50.00%] [G loss: 1.009828]\n",
      "epoch:21 step:20180 [D loss: 0.461599, acc.: 83.59%] [G loss: 1.074764]\n",
      "epoch:21 step:20181 [D loss: 0.297125, acc.: 96.09%] [G loss: 1.321620]\n",
      "epoch:21 step:20182 [D loss: 0.621086, acc.: 62.50%] [G loss: 1.376080]\n",
      "epoch:21 step:20183 [D loss: 0.562217, acc.: 74.22%] [G loss: 1.035203]\n",
      "epoch:21 step:20184 [D loss: 0.458481, acc.: 87.50%] [G loss: 1.199434]\n",
      "epoch:21 step:20185 [D loss: 0.340487, acc.: 91.41%] [G loss: 1.152596]\n",
      "epoch:21 step:20186 [D loss: 0.864238, acc.: 36.72%] [G loss: 1.267252]\n",
      "epoch:21 step:20187 [D loss: 0.788236, acc.: 47.66%] [G loss: 0.936891]\n",
      "epoch:21 step:20188 [D loss: 0.588633, acc.: 67.19%] [G loss: 0.905892]\n",
      "epoch:21 step:20189 [D loss: 0.557853, acc.: 72.66%] [G loss: 1.350466]\n",
      "epoch:21 step:20190 [D loss: 0.431121, acc.: 82.81%] [G loss: 1.373046]\n",
      "epoch:21 step:20191 [D loss: 0.533977, acc.: 75.78%] [G loss: 1.289326]\n",
      "epoch:21 step:20192 [D loss: 0.426438, acc.: 89.06%] [G loss: 1.520997]\n",
      "epoch:21 step:20193 [D loss: 0.761992, acc.: 46.88%] [G loss: 0.978929]\n",
      "epoch:21 step:20194 [D loss: 0.608580, acc.: 71.09%] [G loss: 1.097781]\n",
      "epoch:21 step:20195 [D loss: 0.593186, acc.: 65.62%] [G loss: 1.119169]\n",
      "epoch:21 step:20196 [D loss: 0.429551, acc.: 89.84%] [G loss: 1.128296]\n",
      "epoch:21 step:20197 [D loss: 0.477563, acc.: 85.16%] [G loss: 1.180008]\n",
      "epoch:21 step:20198 [D loss: 0.509138, acc.: 83.59%] [G loss: 1.105635]\n",
      "epoch:21 step:20199 [D loss: 0.419525, acc.: 88.28%] [G loss: 0.957258]\n",
      "epoch:21 step:20200 [D loss: 0.394521, acc.: 92.97%] [G loss: 1.509290]\n",
      "##############\n",
      "[2.48114642 1.80054464 5.65223598 4.49761652 3.37125072 5.50248659\n",
      " 4.1016329  4.58448711 4.28371356 4.0385454 ]\n",
      "##########\n",
      "epoch:21 step:20201 [D loss: 0.610211, acc.: 64.06%] [G loss: 1.218990]\n",
      "epoch:21 step:20202 [D loss: 0.650093, acc.: 67.19%] [G loss: 1.035255]\n",
      "epoch:21 step:20203 [D loss: 0.520786, acc.: 78.12%] [G loss: 1.191702]\n",
      "epoch:21 step:20204 [D loss: 0.701600, acc.: 55.47%] [G loss: 1.014353]\n",
      "epoch:21 step:20205 [D loss: 0.738343, acc.: 50.78%] [G loss: 0.914531]\n",
      "epoch:21 step:20206 [D loss: 0.710663, acc.: 53.91%] [G loss: 0.855533]\n",
      "epoch:21 step:20207 [D loss: 0.692423, acc.: 57.03%] [G loss: 0.835472]\n",
      "epoch:21 step:20208 [D loss: 0.614485, acc.: 65.62%] [G loss: 0.920780]\n",
      "epoch:21 step:20209 [D loss: 0.540092, acc.: 73.44%] [G loss: 1.021240]\n",
      "epoch:21 step:20210 [D loss: 0.362915, acc.: 88.28%] [G loss: 1.228054]\n",
      "epoch:21 step:20211 [D loss: 0.413988, acc.: 89.84%] [G loss: 1.448631]\n",
      "epoch:21 step:20212 [D loss: 0.622228, acc.: 63.28%] [G loss: 1.128393]\n",
      "epoch:21 step:20213 [D loss: 0.474351, acc.: 83.59%] [G loss: 1.341950]\n",
      "epoch:21 step:20214 [D loss: 0.521349, acc.: 78.12%] [G loss: 1.195586]\n",
      "epoch:21 step:20215 [D loss: 0.505693, acc.: 81.25%] [G loss: 1.443748]\n",
      "epoch:21 step:20216 [D loss: 0.556863, acc.: 74.22%] [G loss: 1.187780]\n",
      "epoch:21 step:20217 [D loss: 0.576759, acc.: 71.09%] [G loss: 0.958292]\n",
      "epoch:21 step:20218 [D loss: 0.700565, acc.: 55.47%] [G loss: 0.872482]\n",
      "epoch:21 step:20219 [D loss: 0.614826, acc.: 67.97%] [G loss: 1.118867]\n",
      "epoch:21 step:20220 [D loss: 0.710932, acc.: 54.69%] [G loss: 0.932963]\n",
      "epoch:21 step:20221 [D loss: 0.570042, acc.: 72.66%] [G loss: 1.051904]\n",
      "epoch:21 step:20222 [D loss: 0.408579, acc.: 83.59%] [G loss: 1.171737]\n",
      "epoch:21 step:20223 [D loss: 0.433776, acc.: 87.50%] [G loss: 0.939290]\n",
      "epoch:21 step:20224 [D loss: 0.489844, acc.: 79.69%] [G loss: 1.051659]\n",
      "epoch:21 step:20225 [D loss: 0.544757, acc.: 71.88%] [G loss: 1.073583]\n",
      "epoch:21 step:20226 [D loss: 0.396692, acc.: 85.94%] [G loss: 1.468352]\n",
      "epoch:21 step:20227 [D loss: 0.443997, acc.: 85.16%] [G loss: 1.234089]\n",
      "epoch:21 step:20228 [D loss: 0.440871, acc.: 80.47%] [G loss: 1.227434]\n",
      "epoch:21 step:20229 [D loss: 0.462922, acc.: 82.81%] [G loss: 1.339801]\n",
      "epoch:21 step:20230 [D loss: 0.511231, acc.: 77.34%] [G loss: 1.162271]\n",
      "epoch:21 step:20231 [D loss: 0.341100, acc.: 94.53%] [G loss: 1.408903]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20232 [D loss: 0.289574, acc.: 95.31%] [G loss: 1.568880]\n",
      "epoch:21 step:20233 [D loss: 0.393194, acc.: 86.72%] [G loss: 1.341259]\n",
      "epoch:21 step:20234 [D loss: 0.424169, acc.: 83.59%] [G loss: 1.304620]\n",
      "epoch:21 step:20235 [D loss: 0.627974, acc.: 68.75%] [G loss: 1.403067]\n",
      "epoch:21 step:20236 [D loss: 0.810745, acc.: 50.00%] [G loss: 1.268570]\n",
      "epoch:21 step:20237 [D loss: 0.751595, acc.: 53.12%] [G loss: 1.581751]\n",
      "epoch:21 step:20238 [D loss: 0.379141, acc.: 90.62%] [G loss: 1.686638]\n",
      "epoch:21 step:20239 [D loss: 0.748279, acc.: 49.22%] [G loss: 1.264394]\n",
      "epoch:21 step:20240 [D loss: 0.821880, acc.: 43.75%] [G loss: 0.773416]\n",
      "epoch:21 step:20241 [D loss: 0.512353, acc.: 77.34%] [G loss: 1.224341]\n",
      "epoch:21 step:20242 [D loss: 0.562078, acc.: 74.22%] [G loss: 1.144685]\n",
      "epoch:21 step:20243 [D loss: 0.338973, acc.: 90.62%] [G loss: 1.344142]\n",
      "epoch:21 step:20244 [D loss: 0.244161, acc.: 97.66%] [G loss: 1.640250]\n",
      "epoch:21 step:20245 [D loss: 0.647382, acc.: 58.59%] [G loss: 1.280059]\n",
      "epoch:21 step:20246 [D loss: 0.608038, acc.: 64.84%] [G loss: 1.265248]\n",
      "epoch:21 step:20247 [D loss: 0.767606, acc.: 50.78%] [G loss: 0.935628]\n",
      "epoch:21 step:20248 [D loss: 0.555440, acc.: 78.12%] [G loss: 1.125353]\n",
      "epoch:21 step:20249 [D loss: 0.546058, acc.: 75.78%] [G loss: 1.309098]\n",
      "epoch:21 step:20250 [D loss: 0.478277, acc.: 85.94%] [G loss: 1.341990]\n",
      "epoch:21 step:20251 [D loss: 0.560475, acc.: 69.53%] [G loss: 1.134243]\n",
      "epoch:21 step:20252 [D loss: 0.578885, acc.: 71.09%] [G loss: 1.168508]\n",
      "epoch:21 step:20253 [D loss: 0.415629, acc.: 84.38%] [G loss: 1.424033]\n",
      "epoch:21 step:20254 [D loss: 0.396661, acc.: 89.06%] [G loss: 1.358321]\n",
      "epoch:21 step:20255 [D loss: 0.418393, acc.: 86.72%] [G loss: 0.984744]\n",
      "epoch:21 step:20256 [D loss: 0.647976, acc.: 62.50%] [G loss: 1.158672]\n",
      "epoch:21 step:20257 [D loss: 0.621627, acc.: 67.19%] [G loss: 1.113158]\n",
      "epoch:21 step:20258 [D loss: 0.848015, acc.: 46.88%] [G loss: 0.870084]\n",
      "epoch:21 step:20259 [D loss: 0.712127, acc.: 55.47%] [G loss: 1.127053]\n",
      "epoch:21 step:20260 [D loss: 0.798093, acc.: 48.44%] [G loss: 0.740089]\n",
      "epoch:21 step:20261 [D loss: 0.782970, acc.: 50.78%] [G loss: 0.817768]\n",
      "epoch:21 step:20262 [D loss: 0.717828, acc.: 55.47%] [G loss: 0.908358]\n",
      "epoch:21 step:20263 [D loss: 0.633900, acc.: 64.06%] [G loss: 0.905505]\n",
      "epoch:21 step:20264 [D loss: 0.569877, acc.: 63.28%] [G loss: 0.932360]\n",
      "epoch:21 step:20265 [D loss: 0.362397, acc.: 89.84%] [G loss: 1.431279]\n",
      "epoch:21 step:20266 [D loss: 0.442810, acc.: 86.72%] [G loss: 1.705575]\n",
      "epoch:21 step:20267 [D loss: 0.994125, acc.: 29.69%] [G loss: 0.995782]\n",
      "epoch:21 step:20268 [D loss: 0.891211, acc.: 39.84%] [G loss: 1.051652]\n",
      "epoch:21 step:20269 [D loss: 0.728042, acc.: 57.03%] [G loss: 1.107306]\n",
      "epoch:21 step:20270 [D loss: 0.696801, acc.: 52.34%] [G loss: 1.008258]\n",
      "epoch:21 step:20271 [D loss: 0.607390, acc.: 66.41%] [G loss: 1.149370]\n",
      "epoch:21 step:20272 [D loss: 0.645594, acc.: 65.62%] [G loss: 0.900904]\n",
      "epoch:21 step:20273 [D loss: 0.950075, acc.: 32.03%] [G loss: 0.816104]\n",
      "epoch:21 step:20274 [D loss: 0.460923, acc.: 81.25%] [G loss: 1.100002]\n",
      "epoch:21 step:20275 [D loss: 0.303124, acc.: 91.41%] [G loss: 1.320693]\n",
      "epoch:21 step:20276 [D loss: 0.507957, acc.: 78.12%] [G loss: 1.419651]\n",
      "epoch:21 step:20277 [D loss: 0.632502, acc.: 59.38%] [G loss: 0.954632]\n",
      "epoch:21 step:20278 [D loss: 0.511960, acc.: 75.78%] [G loss: 0.919053]\n",
      "epoch:21 step:20279 [D loss: 0.551170, acc.: 74.22%] [G loss: 1.160147]\n",
      "epoch:21 step:20280 [D loss: 0.410311, acc.: 82.81%] [G loss: 1.134177]\n",
      "epoch:21 step:20281 [D loss: 0.419656, acc.: 81.25%] [G loss: 1.359893]\n",
      "epoch:21 step:20282 [D loss: 0.361204, acc.: 90.62%] [G loss: 1.745058]\n",
      "epoch:21 step:20283 [D loss: 0.636647, acc.: 64.06%] [G loss: 1.384860]\n",
      "epoch:21 step:20284 [D loss: 0.789912, acc.: 41.41%] [G loss: 1.065621]\n",
      "epoch:21 step:20285 [D loss: 0.666368, acc.: 58.59%] [G loss: 1.127217]\n",
      "epoch:21 step:20286 [D loss: 0.752357, acc.: 50.78%] [G loss: 1.045734]\n",
      "epoch:21 step:20287 [D loss: 0.641974, acc.: 64.84%] [G loss: 1.288674]\n",
      "epoch:21 step:20288 [D loss: 0.689680, acc.: 57.81%] [G loss: 1.255622]\n",
      "epoch:21 step:20289 [D loss: 0.725910, acc.: 52.34%] [G loss: 1.198987]\n",
      "epoch:21 step:20290 [D loss: 0.479215, acc.: 77.34%] [G loss: 1.173461]\n",
      "epoch:21 step:20291 [D loss: 0.505827, acc.: 81.25%] [G loss: 1.184428]\n",
      "epoch:21 step:20292 [D loss: 0.339960, acc.: 94.53%] [G loss: 1.456129]\n",
      "epoch:21 step:20293 [D loss: 0.326914, acc.: 92.19%] [G loss: 1.582572]\n",
      "epoch:21 step:20294 [D loss: 0.561462, acc.: 72.66%] [G loss: 0.979826]\n",
      "epoch:21 step:20295 [D loss: 0.967538, acc.: 28.12%] [G loss: 0.873222]\n",
      "epoch:21 step:20296 [D loss: 1.042561, acc.: 25.78%] [G loss: 0.968365]\n",
      "epoch:21 step:20297 [D loss: 0.959850, acc.: 28.91%] [G loss: 1.089129]\n",
      "epoch:21 step:20298 [D loss: 0.794930, acc.: 48.44%] [G loss: 1.220925]\n",
      "epoch:21 step:20299 [D loss: 0.771526, acc.: 55.47%] [G loss: 1.475622]\n",
      "epoch:21 step:20300 [D loss: 0.696300, acc.: 53.91%] [G loss: 0.954028]\n",
      "epoch:21 step:20301 [D loss: 0.593483, acc.: 67.19%] [G loss: 1.129680]\n",
      "epoch:21 step:20302 [D loss: 0.767678, acc.: 49.22%] [G loss: 0.907710]\n",
      "epoch:21 step:20303 [D loss: 0.559200, acc.: 76.56%] [G loss: 1.151769]\n",
      "epoch:21 step:20304 [D loss: 0.690778, acc.: 55.47%] [G loss: 1.033363]\n",
      "epoch:21 step:20305 [D loss: 0.690117, acc.: 57.03%] [G loss: 0.929039]\n",
      "epoch:21 step:20306 [D loss: 0.444816, acc.: 82.81%] [G loss: 1.202303]\n",
      "epoch:21 step:20307 [D loss: 0.560953, acc.: 75.78%] [G loss: 1.055105]\n",
      "epoch:21 step:20308 [D loss: 0.522547, acc.: 77.34%] [G loss: 1.017048]\n",
      "epoch:21 step:20309 [D loss: 0.493638, acc.: 79.69%] [G loss: 1.270881]\n",
      "epoch:21 step:20310 [D loss: 0.432150, acc.: 86.72%] [G loss: 1.225807]\n",
      "epoch:21 step:20311 [D loss: 0.573879, acc.: 71.09%] [G loss: 0.946890]\n",
      "epoch:21 step:20312 [D loss: 0.563585, acc.: 72.66%] [G loss: 1.136784]\n",
      "epoch:21 step:20313 [D loss: 0.705388, acc.: 53.91%] [G loss: 1.109349]\n",
      "epoch:21 step:20314 [D loss: 0.704689, acc.: 56.25%] [G loss: 0.917859]\n",
      "epoch:21 step:20315 [D loss: 0.621078, acc.: 60.16%] [G loss: 1.069630]\n",
      "epoch:21 step:20316 [D loss: 0.690846, acc.: 53.91%] [G loss: 1.292892]\n",
      "epoch:21 step:20317 [D loss: 0.410503, acc.: 84.38%] [G loss: 1.239274]\n",
      "epoch:21 step:20318 [D loss: 0.372535, acc.: 92.19%] [G loss: 1.574940]\n",
      "epoch:21 step:20319 [D loss: 0.415527, acc.: 85.94%] [G loss: 1.440349]\n",
      "epoch:21 step:20320 [D loss: 0.679227, acc.: 55.47%] [G loss: 1.377025]\n",
      "epoch:21 step:20321 [D loss: 0.811372, acc.: 40.62%] [G loss: 1.154490]\n",
      "epoch:21 step:20322 [D loss: 0.633775, acc.: 64.84%] [G loss: 0.947123]\n",
      "epoch:21 step:20323 [D loss: 0.608130, acc.: 64.84%] [G loss: 1.126291]\n",
      "epoch:21 step:20324 [D loss: 0.388423, acc.: 92.97%] [G loss: 1.242203]\n",
      "epoch:21 step:20325 [D loss: 0.445096, acc.: 85.16%] [G loss: 1.116473]\n",
      "epoch:21 step:20326 [D loss: 0.664006, acc.: 60.94%] [G loss: 0.863915]\n",
      "epoch:21 step:20327 [D loss: 0.516613, acc.: 79.69%] [G loss: 1.306186]\n",
      "epoch:21 step:20328 [D loss: 0.542472, acc.: 73.44%] [G loss: 1.274897]\n",
      "epoch:21 step:20329 [D loss: 0.760768, acc.: 50.00%] [G loss: 1.032794]\n",
      "epoch:21 step:20330 [D loss: 0.543492, acc.: 72.66%] [G loss: 1.243212]\n",
      "epoch:21 step:20331 [D loss: 0.621289, acc.: 65.62%] [G loss: 0.994493]\n",
      "epoch:21 step:20332 [D loss: 0.725695, acc.: 51.56%] [G loss: 1.043539]\n",
      "epoch:21 step:20333 [D loss: 0.708168, acc.: 53.12%] [G loss: 0.809046]\n",
      "epoch:21 step:20334 [D loss: 0.644570, acc.: 64.06%] [G loss: 1.039095]\n",
      "epoch:21 step:20335 [D loss: 0.534687, acc.: 78.12%] [G loss: 1.245100]\n",
      "epoch:21 step:20336 [D loss: 0.660724, acc.: 57.81%] [G loss: 1.084941]\n",
      "epoch:21 step:20337 [D loss: 0.654832, acc.: 60.94%] [G loss: 0.956569]\n",
      "epoch:21 step:20338 [D loss: 0.591721, acc.: 68.75%] [G loss: 0.943592]\n",
      "epoch:21 step:20339 [D loss: 0.603705, acc.: 71.09%] [G loss: 0.998327]\n",
      "epoch:21 step:20340 [D loss: 0.413343, acc.: 81.25%] [G loss: 1.252096]\n",
      "epoch:21 step:20341 [D loss: 0.276296, acc.: 92.97%] [G loss: 1.542701]\n",
      "epoch:21 step:20342 [D loss: 0.293328, acc.: 96.88%] [G loss: 1.412906]\n",
      "epoch:21 step:20343 [D loss: 0.573073, acc.: 67.97%] [G loss: 1.342662]\n",
      "epoch:21 step:20344 [D loss: 0.485736, acc.: 80.47%] [G loss: 0.928087]\n",
      "epoch:21 step:20345 [D loss: 0.714355, acc.: 53.12%] [G loss: 1.283770]\n",
      "epoch:21 step:20346 [D loss: 0.566134, acc.: 69.53%] [G loss: 1.117534]\n",
      "epoch:21 step:20347 [D loss: 0.753223, acc.: 52.34%] [G loss: 0.965060]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20348 [D loss: 0.623408, acc.: 67.19%] [G loss: 0.973563]\n",
      "epoch:21 step:20349 [D loss: 0.780248, acc.: 42.97%] [G loss: 0.859879]\n",
      "epoch:21 step:20350 [D loss: 0.953932, acc.: 35.16%] [G loss: 0.784320]\n",
      "epoch:21 step:20351 [D loss: 0.836321, acc.: 43.75%] [G loss: 0.802176]\n",
      "epoch:21 step:20352 [D loss: 0.854802, acc.: 37.50%] [G loss: 0.873640]\n",
      "epoch:21 step:20353 [D loss: 0.851735, acc.: 39.06%] [G loss: 0.816178]\n",
      "epoch:21 step:20354 [D loss: 0.830510, acc.: 42.19%] [G loss: 1.041118]\n",
      "epoch:21 step:20355 [D loss: 0.728172, acc.: 51.56%] [G loss: 0.959207]\n",
      "epoch:21 step:20356 [D loss: 0.970408, acc.: 28.91%] [G loss: 0.849354]\n",
      "epoch:21 step:20357 [D loss: 0.655642, acc.: 65.62%] [G loss: 0.889448]\n",
      "epoch:21 step:20358 [D loss: 0.687133, acc.: 60.16%] [G loss: 0.994272]\n",
      "epoch:21 step:20359 [D loss: 0.793871, acc.: 45.31%] [G loss: 0.695868]\n",
      "epoch:21 step:20360 [D loss: 0.682630, acc.: 52.34%] [G loss: 0.917961]\n",
      "epoch:21 step:20361 [D loss: 0.642987, acc.: 63.28%] [G loss: 1.091803]\n",
      "epoch:21 step:20362 [D loss: 0.638359, acc.: 65.62%] [G loss: 0.966338]\n",
      "epoch:21 step:20363 [D loss: 0.600101, acc.: 70.31%] [G loss: 1.204003]\n",
      "epoch:21 step:20364 [D loss: 0.633769, acc.: 64.84%] [G loss: 0.950854]\n",
      "epoch:21 step:20365 [D loss: 0.482884, acc.: 81.25%] [G loss: 1.532991]\n",
      "epoch:21 step:20366 [D loss: 0.397991, acc.: 86.72%] [G loss: 1.399102]\n",
      "epoch:21 step:20367 [D loss: 0.275419, acc.: 89.06%] [G loss: 1.345827]\n",
      "epoch:21 step:20368 [D loss: 0.274421, acc.: 95.31%] [G loss: 1.677258]\n",
      "epoch:21 step:20369 [D loss: 0.370578, acc.: 91.41%] [G loss: 1.482578]\n",
      "epoch:21 step:20370 [D loss: 0.449054, acc.: 82.81%] [G loss: 1.339667]\n",
      "epoch:21 step:20371 [D loss: 0.273379, acc.: 93.75%] [G loss: 1.400109]\n",
      "epoch:21 step:20372 [D loss: 0.388353, acc.: 89.06%] [G loss: 1.668548]\n",
      "epoch:21 step:20373 [D loss: 0.920729, acc.: 42.97%] [G loss: 1.319592]\n",
      "epoch:21 step:20374 [D loss: 0.902623, acc.: 32.03%] [G loss: 0.913605]\n",
      "epoch:21 step:20375 [D loss: 1.055383, acc.: 27.34%] [G loss: 0.842919]\n",
      "epoch:21 step:20376 [D loss: 0.892220, acc.: 37.50%] [G loss: 0.959653]\n",
      "epoch:21 step:20377 [D loss: 0.642489, acc.: 58.59%] [G loss: 1.254037]\n",
      "epoch:21 step:20378 [D loss: 0.517972, acc.: 78.12%] [G loss: 1.173189]\n",
      "epoch:21 step:20379 [D loss: 0.646607, acc.: 64.84%] [G loss: 1.166542]\n",
      "epoch:21 step:20380 [D loss: 0.745642, acc.: 53.12%] [G loss: 0.964077]\n",
      "epoch:21 step:20381 [D loss: 0.638851, acc.: 60.16%] [G loss: 1.006818]\n",
      "epoch:21 step:20382 [D loss: 0.663895, acc.: 61.72%] [G loss: 1.102134]\n",
      "epoch:21 step:20383 [D loss: 0.486513, acc.: 79.69%] [G loss: 1.105101]\n",
      "epoch:21 step:20384 [D loss: 0.446272, acc.: 82.81%] [G loss: 1.348367]\n",
      "epoch:21 step:20385 [D loss: 0.369482, acc.: 91.41%] [G loss: 1.285565]\n",
      "epoch:21 step:20386 [D loss: 0.362903, acc.: 86.72%] [G loss: 1.204381]\n",
      "epoch:21 step:20387 [D loss: 0.827224, acc.: 46.09%] [G loss: 1.143522]\n",
      "epoch:21 step:20388 [D loss: 0.729265, acc.: 58.59%] [G loss: 1.228597]\n",
      "epoch:21 step:20389 [D loss: 0.628253, acc.: 67.97%] [G loss: 1.125695]\n",
      "epoch:21 step:20390 [D loss: 0.463795, acc.: 79.69%] [G loss: 1.287713]\n",
      "epoch:21 step:20391 [D loss: 0.473328, acc.: 82.81%] [G loss: 1.032912]\n",
      "epoch:21 step:20392 [D loss: 0.700113, acc.: 57.03%] [G loss: 1.233751]\n",
      "epoch:21 step:20393 [D loss: 0.827795, acc.: 45.31%] [G loss: 1.001504]\n",
      "epoch:21 step:20394 [D loss: 0.724535, acc.: 50.78%] [G loss: 0.848780]\n",
      "epoch:21 step:20395 [D loss: 0.737215, acc.: 49.22%] [G loss: 1.052696]\n",
      "epoch:21 step:20396 [D loss: 0.774065, acc.: 44.53%] [G loss: 1.012063]\n",
      "epoch:21 step:20397 [D loss: 0.611345, acc.: 68.75%] [G loss: 0.862034]\n",
      "epoch:21 step:20398 [D loss: 0.617590, acc.: 67.97%] [G loss: 0.898218]\n",
      "epoch:21 step:20399 [D loss: 0.816548, acc.: 38.28%] [G loss: 0.982882]\n",
      "epoch:21 step:20400 [D loss: 0.697123, acc.: 54.69%] [G loss: 1.065525]\n",
      "##############\n",
      "[2.45769563 1.56517818 5.52821173 4.47515327 3.2507789  5.37851998\n",
      " 4.3858058  4.81389612 3.94034846 3.75280201]\n",
      "##########\n",
      "epoch:21 step:20401 [D loss: 0.526676, acc.: 75.78%] [G loss: 1.002569]\n",
      "epoch:21 step:20402 [D loss: 0.467960, acc.: 80.47%] [G loss: 1.052380]\n",
      "epoch:21 step:20403 [D loss: 0.637584, acc.: 64.06%] [G loss: 1.344475]\n",
      "epoch:21 step:20404 [D loss: 0.562192, acc.: 69.53%] [G loss: 1.137685]\n",
      "epoch:21 step:20405 [D loss: 0.469069, acc.: 85.16%] [G loss: 1.128865]\n",
      "epoch:21 step:20406 [D loss: 0.604381, acc.: 68.75%] [G loss: 1.308007]\n",
      "epoch:21 step:20407 [D loss: 0.463371, acc.: 82.03%] [G loss: 1.320811]\n",
      "epoch:21 step:20408 [D loss: 0.452800, acc.: 82.81%] [G loss: 1.075503]\n",
      "epoch:21 step:20409 [D loss: 0.462230, acc.: 82.03%] [G loss: 1.159166]\n",
      "epoch:21 step:20410 [D loss: 0.436395, acc.: 89.06%] [G loss: 1.268071]\n",
      "epoch:21 step:20411 [D loss: 0.601111, acc.: 68.75%] [G loss: 1.128296]\n",
      "epoch:21 step:20412 [D loss: 0.641932, acc.: 61.72%] [G loss: 1.015397]\n",
      "epoch:21 step:20413 [D loss: 0.643458, acc.: 66.41%] [G loss: 1.002431]\n",
      "epoch:21 step:20414 [D loss: 0.572556, acc.: 69.53%] [G loss: 0.932257]\n",
      "epoch:21 step:20415 [D loss: 0.685844, acc.: 55.47%] [G loss: 1.067694]\n",
      "epoch:21 step:20416 [D loss: 0.621216, acc.: 67.19%] [G loss: 0.786973]\n",
      "epoch:21 step:20417 [D loss: 0.533108, acc.: 75.78%] [G loss: 1.035308]\n",
      "epoch:21 step:20418 [D loss: 0.487316, acc.: 82.81%] [G loss: 0.901933]\n",
      "epoch:21 step:20419 [D loss: 0.531637, acc.: 75.00%] [G loss: 1.192475]\n",
      "epoch:21 step:20420 [D loss: 0.442920, acc.: 83.59%] [G loss: 1.185990]\n",
      "epoch:21 step:20421 [D loss: 0.759980, acc.: 50.78%] [G loss: 1.027628]\n",
      "epoch:21 step:20422 [D loss: 0.442048, acc.: 87.50%] [G loss: 1.376812]\n",
      "epoch:21 step:20423 [D loss: 0.513666, acc.: 78.12%] [G loss: 1.292608]\n",
      "epoch:21 step:20424 [D loss: 0.672472, acc.: 62.50%] [G loss: 1.175743]\n",
      "epoch:21 step:20425 [D loss: 0.698002, acc.: 53.12%] [G loss: 1.132781]\n",
      "epoch:21 step:20426 [D loss: 0.662517, acc.: 61.72%] [G loss: 0.955834]\n",
      "epoch:21 step:20427 [D loss: 0.569889, acc.: 71.09%] [G loss: 1.095059]\n",
      "epoch:21 step:20428 [D loss: 0.606733, acc.: 67.19%] [G loss: 1.028262]\n",
      "epoch:21 step:20429 [D loss: 0.728108, acc.: 52.34%] [G loss: 0.902514]\n",
      "epoch:21 step:20430 [D loss: 0.590354, acc.: 68.75%] [G loss: 0.911597]\n",
      "epoch:21 step:20431 [D loss: 0.615269, acc.: 67.19%] [G loss: 1.007736]\n",
      "epoch:21 step:20432 [D loss: 0.450876, acc.: 82.81%] [G loss: 1.119345]\n",
      "epoch:21 step:20433 [D loss: 0.541958, acc.: 73.44%] [G loss: 1.137794]\n",
      "epoch:21 step:20434 [D loss: 0.572243, acc.: 73.44%] [G loss: 1.101872]\n",
      "epoch:21 step:20435 [D loss: 0.610102, acc.: 64.06%] [G loss: 1.022502]\n",
      "epoch:21 step:20436 [D loss: 0.712873, acc.: 51.56%] [G loss: 0.891908]\n",
      "epoch:21 step:20437 [D loss: 0.644804, acc.: 61.72%] [G loss: 0.995393]\n",
      "epoch:21 step:20438 [D loss: 0.650088, acc.: 60.16%] [G loss: 0.874785]\n",
      "epoch:21 step:20439 [D loss: 0.700527, acc.: 52.34%] [G loss: 0.819688]\n",
      "epoch:21 step:20440 [D loss: 0.565372, acc.: 65.62%] [G loss: 0.867096]\n",
      "epoch:21 step:20441 [D loss: 0.608873, acc.: 64.06%] [G loss: 0.892331]\n",
      "epoch:21 step:20442 [D loss: 0.632590, acc.: 67.19%] [G loss: 1.111192]\n",
      "epoch:21 step:20443 [D loss: 0.658136, acc.: 66.41%] [G loss: 1.272192]\n",
      "epoch:21 step:20444 [D loss: 0.556213, acc.: 73.44%] [G loss: 0.919664]\n",
      "epoch:21 step:20445 [D loss: 0.362196, acc.: 89.06%] [G loss: 1.232328]\n",
      "epoch:21 step:20446 [D loss: 0.330926, acc.: 92.97%] [G loss: 1.260748]\n",
      "epoch:21 step:20447 [D loss: 0.520050, acc.: 75.00%] [G loss: 1.574946]\n",
      "epoch:21 step:20448 [D loss: 0.723022, acc.: 55.47%] [G loss: 1.151937]\n",
      "epoch:21 step:20449 [D loss: 0.803730, acc.: 40.62%] [G loss: 1.059613]\n",
      "epoch:21 step:20450 [D loss: 0.598373, acc.: 65.62%] [G loss: 1.065568]\n",
      "epoch:21 step:20451 [D loss: 0.346878, acc.: 86.72%] [G loss: 1.370748]\n",
      "epoch:21 step:20452 [D loss: 0.215987, acc.: 97.66%] [G loss: 1.783427]\n",
      "epoch:21 step:20453 [D loss: 0.643382, acc.: 62.50%] [G loss: 1.621252]\n",
      "epoch:21 step:20454 [D loss: 0.597403, acc.: 67.97%] [G loss: 1.230003]\n",
      "epoch:21 step:20455 [D loss: 0.570107, acc.: 68.75%] [G loss: 1.178536]\n",
      "epoch:21 step:20456 [D loss: 1.083626, acc.: 14.84%] [G loss: 0.724136]\n",
      "epoch:21 step:20457 [D loss: 0.658468, acc.: 62.50%] [G loss: 1.097271]\n",
      "epoch:21 step:20458 [D loss: 0.531078, acc.: 76.56%] [G loss: 1.385199]\n",
      "epoch:21 step:20459 [D loss: 0.403189, acc.: 89.06%] [G loss: 1.267226]\n",
      "epoch:21 step:20460 [D loss: 0.687231, acc.: 57.03%] [G loss: 1.226896]\n",
      "epoch:21 step:20461 [D loss: 0.687345, acc.: 51.56%] [G loss: 0.858230]\n",
      "epoch:21 step:20462 [D loss: 0.528630, acc.: 74.22%] [G loss: 0.855891]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20463 [D loss: 0.546177, acc.: 71.88%] [G loss: 0.810789]\n",
      "epoch:21 step:20464 [D loss: 0.695783, acc.: 60.94%] [G loss: 1.222601]\n",
      "epoch:21 step:20465 [D loss: 0.519507, acc.: 77.34%] [G loss: 1.157573]\n",
      "epoch:21 step:20466 [D loss: 0.767434, acc.: 50.00%] [G loss: 0.857683]\n",
      "epoch:21 step:20467 [D loss: 0.491829, acc.: 70.31%] [G loss: 1.136369]\n",
      "epoch:21 step:20468 [D loss: 0.237763, acc.: 96.09%] [G loss: 1.513375]\n",
      "epoch:21 step:20469 [D loss: 0.295113, acc.: 93.75%] [G loss: 1.492199]\n",
      "epoch:21 step:20470 [D loss: 0.446135, acc.: 81.25%] [G loss: 1.478198]\n",
      "epoch:21 step:20471 [D loss: 0.330574, acc.: 89.84%] [G loss: 1.601190]\n",
      "epoch:21 step:20472 [D loss: 0.546234, acc.: 68.75%] [G loss: 1.188752]\n",
      "epoch:21 step:20473 [D loss: 0.513769, acc.: 77.34%] [G loss: 1.110158]\n",
      "epoch:21 step:20474 [D loss: 0.596242, acc.: 66.41%] [G loss: 1.141164]\n",
      "epoch:21 step:20475 [D loss: 0.456668, acc.: 82.81%] [G loss: 1.385364]\n",
      "epoch:21 step:20476 [D loss: 0.951694, acc.: 42.19%] [G loss: 0.670305]\n",
      "epoch:21 step:20477 [D loss: 0.878796, acc.: 39.06%] [G loss: 1.009497]\n",
      "epoch:21 step:20478 [D loss: 0.876220, acc.: 39.06%] [G loss: 0.927096]\n",
      "epoch:21 step:20479 [D loss: 0.686789, acc.: 57.03%] [G loss: 1.199045]\n",
      "epoch:21 step:20480 [D loss: 0.836551, acc.: 39.06%] [G loss: 0.894362]\n",
      "epoch:21 step:20481 [D loss: 0.500022, acc.: 74.22%] [G loss: 1.035601]\n",
      "epoch:21 step:20482 [D loss: 0.500064, acc.: 75.00%] [G loss: 0.860518]\n",
      "epoch:21 step:20483 [D loss: 0.302413, acc.: 95.31%] [G loss: 1.325967]\n",
      "epoch:21 step:20484 [D loss: 0.747604, acc.: 50.00%] [G loss: 1.041248]\n",
      "epoch:21 step:20485 [D loss: 0.840850, acc.: 46.88%] [G loss: 1.143526]\n",
      "epoch:21 step:20486 [D loss: 0.717154, acc.: 55.47%] [G loss: 1.171727]\n",
      "epoch:21 step:20487 [D loss: 0.835318, acc.: 40.62%] [G loss: 0.847687]\n",
      "epoch:21 step:20488 [D loss: 0.770025, acc.: 49.22%] [G loss: 1.205812]\n",
      "epoch:21 step:20489 [D loss: 0.691318, acc.: 57.81%] [G loss: 1.061027]\n",
      "epoch:21 step:20490 [D loss: 0.644606, acc.: 66.41%] [G loss: 1.000043]\n",
      "epoch:21 step:20491 [D loss: 0.586109, acc.: 71.88%] [G loss: 1.209442]\n",
      "epoch:21 step:20492 [D loss: 0.303443, acc.: 89.84%] [G loss: 1.341152]\n",
      "epoch:21 step:20493 [D loss: 0.338031, acc.: 92.97%] [G loss: 1.252585]\n",
      "epoch:21 step:20494 [D loss: 0.479398, acc.: 75.78%] [G loss: 1.187609]\n",
      "epoch:21 step:20495 [D loss: 0.415602, acc.: 90.62%] [G loss: 1.301593]\n",
      "epoch:21 step:20496 [D loss: 0.536189, acc.: 78.91%] [G loss: 1.261591]\n",
      "epoch:21 step:20497 [D loss: 0.671145, acc.: 61.72%] [G loss: 0.978185]\n",
      "epoch:21 step:20498 [D loss: 0.809338, acc.: 47.66%] [G loss: 0.798462]\n",
      "epoch:21 step:20499 [D loss: 0.688850, acc.: 59.38%] [G loss: 1.116567]\n",
      "epoch:21 step:20500 [D loss: 0.546516, acc.: 78.12%] [G loss: 1.291122]\n",
      "epoch:21 step:20501 [D loss: 0.355013, acc.: 88.28%] [G loss: 1.230114]\n",
      "epoch:21 step:20502 [D loss: 0.432104, acc.: 82.81%] [G loss: 1.102538]\n",
      "epoch:21 step:20503 [D loss: 0.770558, acc.: 53.91%] [G loss: 0.751056]\n",
      "epoch:21 step:20504 [D loss: 0.707193, acc.: 51.56%] [G loss: 1.353038]\n",
      "epoch:21 step:20505 [D loss: 0.602482, acc.: 67.19%] [G loss: 1.152380]\n",
      "epoch:21 step:20506 [D loss: 0.704239, acc.: 54.69%] [G loss: 0.726403]\n",
      "epoch:21 step:20507 [D loss: 0.521678, acc.: 72.66%] [G loss: 0.999955]\n",
      "epoch:21 step:20508 [D loss: 0.375883, acc.: 85.16%] [G loss: 1.171054]\n",
      "epoch:21 step:20509 [D loss: 0.435233, acc.: 82.81%] [G loss: 1.491674]\n",
      "epoch:21 step:20510 [D loss: 0.567444, acc.: 71.88%] [G loss: 1.259864]\n",
      "epoch:21 step:20511 [D loss: 1.120451, acc.: 22.66%] [G loss: 1.058273]\n",
      "epoch:21 step:20512 [D loss: 0.932964, acc.: 33.59%] [G loss: 1.157679]\n",
      "epoch:21 step:20513 [D loss: 0.906961, acc.: 39.84%] [G loss: 0.909286]\n",
      "epoch:21 step:20514 [D loss: 0.823351, acc.: 39.84%] [G loss: 1.048818]\n",
      "epoch:21 step:20515 [D loss: 0.625075, acc.: 63.28%] [G loss: 1.102076]\n",
      "epoch:21 step:20516 [D loss: 0.567597, acc.: 73.44%] [G loss: 0.954387]\n",
      "epoch:21 step:20517 [D loss: 0.522664, acc.: 78.91%] [G loss: 1.168352]\n",
      "epoch:21 step:20518 [D loss: 0.462427, acc.: 83.59%] [G loss: 1.275793]\n",
      "epoch:21 step:20519 [D loss: 0.408697, acc.: 89.06%] [G loss: 1.304012]\n",
      "epoch:21 step:20520 [D loss: 0.762755, acc.: 46.09%] [G loss: 1.179530]\n",
      "epoch:21 step:20521 [D loss: 0.727176, acc.: 58.59%] [G loss: 0.944128]\n",
      "epoch:21 step:20522 [D loss: 0.716526, acc.: 62.50%] [G loss: 0.941621]\n",
      "epoch:21 step:20523 [D loss: 0.536361, acc.: 75.00%] [G loss: 1.089513]\n",
      "epoch:21 step:20524 [D loss: 0.677242, acc.: 51.56%] [G loss: 1.263561]\n",
      "epoch:21 step:20525 [D loss: 0.588425, acc.: 70.31%] [G loss: 1.116363]\n",
      "epoch:21 step:20526 [D loss: 0.463598, acc.: 81.25%] [G loss: 1.420453]\n",
      "epoch:21 step:20527 [D loss: 0.367302, acc.: 92.19%] [G loss: 1.281348]\n",
      "epoch:21 step:20528 [D loss: 0.291815, acc.: 91.41%] [G loss: 1.868854]\n",
      "epoch:21 step:20529 [D loss: 0.247949, acc.: 98.44%] [G loss: 1.664190]\n",
      "epoch:21 step:20530 [D loss: 0.277892, acc.: 95.31%] [G loss: 1.705197]\n",
      "epoch:21 step:20531 [D loss: 0.317758, acc.: 92.19%] [G loss: 1.555906]\n",
      "epoch:21 step:20532 [D loss: 0.282526, acc.: 97.66%] [G loss: 1.889024]\n",
      "epoch:21 step:20533 [D loss: 0.540426, acc.: 74.22%] [G loss: 1.239181]\n",
      "epoch:21 step:20534 [D loss: 0.407746, acc.: 82.81%] [G loss: 1.183117]\n",
      "epoch:21 step:20535 [D loss: 0.927460, acc.: 45.31%] [G loss: 0.946603]\n",
      "epoch:21 step:20536 [D loss: 0.766571, acc.: 50.00%] [G loss: 1.178761]\n",
      "epoch:21 step:20537 [D loss: 0.576137, acc.: 71.09%] [G loss: 1.097696]\n",
      "epoch:21 step:20538 [D loss: 0.570672, acc.: 71.88%] [G loss: 1.040984]\n",
      "epoch:21 step:20539 [D loss: 0.865269, acc.: 37.50%] [G loss: 0.615606]\n",
      "epoch:21 step:20540 [D loss: 0.710495, acc.: 50.78%] [G loss: 0.954840]\n",
      "epoch:21 step:20541 [D loss: 0.720584, acc.: 50.00%] [G loss: 0.974846]\n",
      "epoch:21 step:20542 [D loss: 0.643499, acc.: 66.41%] [G loss: 0.875996]\n",
      "epoch:21 step:20543 [D loss: 0.822251, acc.: 40.62%] [G loss: 0.688166]\n",
      "epoch:21 step:20544 [D loss: 0.754964, acc.: 51.56%] [G loss: 0.867036]\n",
      "epoch:21 step:20545 [D loss: 0.664875, acc.: 63.28%] [G loss: 1.089936]\n",
      "epoch:21 step:20546 [D loss: 0.507017, acc.: 79.69%] [G loss: 1.095326]\n",
      "epoch:21 step:20547 [D loss: 0.789345, acc.: 43.75%] [G loss: 1.021638]\n",
      "epoch:21 step:20548 [D loss: 0.621481, acc.: 63.28%] [G loss: 0.923341]\n",
      "epoch:21 step:20549 [D loss: 0.557891, acc.: 71.09%] [G loss: 1.089610]\n",
      "epoch:21 step:20550 [D loss: 0.884877, acc.: 42.19%] [G loss: 1.008735]\n",
      "epoch:21 step:20551 [D loss: 0.757868, acc.: 51.56%] [G loss: 0.833120]\n",
      "epoch:21 step:20552 [D loss: 0.512334, acc.: 80.47%] [G loss: 1.504272]\n",
      "epoch:21 step:20553 [D loss: 0.764278, acc.: 44.53%] [G loss: 0.886205]\n",
      "epoch:21 step:20554 [D loss: 0.692551, acc.: 55.47%] [G loss: 1.156124]\n",
      "epoch:21 step:20555 [D loss: 0.589970, acc.: 67.19%] [G loss: 1.147706]\n",
      "epoch:21 step:20556 [D loss: 0.734040, acc.: 51.56%] [G loss: 1.023506]\n",
      "epoch:21 step:20557 [D loss: 0.583809, acc.: 71.88%] [G loss: 0.965384]\n",
      "epoch:21 step:20558 [D loss: 0.568805, acc.: 69.53%] [G loss: 1.036260]\n",
      "epoch:21 step:20559 [D loss: 0.653167, acc.: 64.84%] [G loss: 0.810885]\n",
      "epoch:21 step:20560 [D loss: 0.586558, acc.: 67.19%] [G loss: 1.094305]\n",
      "epoch:21 step:20561 [D loss: 0.456546, acc.: 81.25%] [G loss: 1.237251]\n",
      "epoch:21 step:20562 [D loss: 0.604237, acc.: 62.50%] [G loss: 1.124518]\n",
      "epoch:21 step:20563 [D loss: 0.747094, acc.: 49.22%] [G loss: 0.954099]\n",
      "epoch:21 step:20564 [D loss: 0.593767, acc.: 64.84%] [G loss: 1.176336]\n",
      "epoch:21 step:20565 [D loss: 0.677162, acc.: 60.16%] [G loss: 0.922559]\n",
      "epoch:21 step:20566 [D loss: 0.661902, acc.: 57.03%] [G loss: 1.285521]\n",
      "epoch:21 step:20567 [D loss: 0.639506, acc.: 60.16%] [G loss: 0.934858]\n",
      "epoch:21 step:20568 [D loss: 0.769262, acc.: 49.22%] [G loss: 1.336309]\n",
      "epoch:21 step:20569 [D loss: 0.566710, acc.: 71.88%] [G loss: 1.423076]\n",
      "epoch:21 step:20570 [D loss: 0.472959, acc.: 83.59%] [G loss: 1.299246]\n",
      "epoch:21 step:20571 [D loss: 0.413372, acc.: 86.72%] [G loss: 1.562337]\n",
      "epoch:21 step:20572 [D loss: 0.363357, acc.: 92.97%] [G loss: 1.407827]\n",
      "epoch:21 step:20573 [D loss: 0.349742, acc.: 94.53%] [G loss: 1.591618]\n",
      "epoch:21 step:20574 [D loss: 0.337639, acc.: 96.88%] [G loss: 1.670979]\n",
      "epoch:21 step:20575 [D loss: 0.245364, acc.: 99.22%] [G loss: 1.791043]\n",
      "epoch:21 step:20576 [D loss: 0.231049, acc.: 96.09%] [G loss: 1.880308]\n",
      "epoch:21 step:20577 [D loss: 0.167596, acc.: 100.00%] [G loss: 1.952501]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20578 [D loss: 0.342807, acc.: 89.06%] [G loss: 2.007697]\n",
      "epoch:21 step:20579 [D loss: 0.404452, acc.: 83.59%] [G loss: 1.497895]\n",
      "epoch:21 step:20580 [D loss: 0.483557, acc.: 83.59%] [G loss: 1.392807]\n",
      "epoch:21 step:20581 [D loss: 0.966985, acc.: 35.16%] [G loss: 1.258268]\n",
      "epoch:21 step:20582 [D loss: 0.671625, acc.: 62.50%] [G loss: 0.983530]\n",
      "epoch:21 step:20583 [D loss: 1.004754, acc.: 28.91%] [G loss: 0.753628]\n",
      "epoch:21 step:20584 [D loss: 0.591655, acc.: 71.09%] [G loss: 1.100249]\n",
      "epoch:21 step:20585 [D loss: 0.807400, acc.: 44.53%] [G loss: 0.729889]\n",
      "epoch:21 step:20586 [D loss: 0.488980, acc.: 72.66%] [G loss: 1.403893]\n",
      "epoch:21 step:20587 [D loss: 0.624019, acc.: 67.19%] [G loss: 1.282116]\n",
      "epoch:21 step:20588 [D loss: 0.395512, acc.: 80.47%] [G loss: 1.226583]\n",
      "epoch:21 step:20589 [D loss: 0.228759, acc.: 92.97%] [G loss: 1.397839]\n",
      "epoch:21 step:20590 [D loss: 1.120141, acc.: 45.31%] [G loss: 1.370060]\n",
      "epoch:21 step:20591 [D loss: 0.802662, acc.: 48.44%] [G loss: 1.339892]\n",
      "epoch:21 step:20592 [D loss: 0.761458, acc.: 52.34%] [G loss: 1.071742]\n",
      "epoch:21 step:20593 [D loss: 0.849614, acc.: 37.50%] [G loss: 0.924051]\n",
      "epoch:21 step:20594 [D loss: 0.850741, acc.: 40.62%] [G loss: 1.136132]\n",
      "epoch:21 step:20595 [D loss: 0.735224, acc.: 58.59%] [G loss: 0.825646]\n",
      "epoch:21 step:20596 [D loss: 0.531286, acc.: 74.22%] [G loss: 0.993031]\n",
      "epoch:21 step:20597 [D loss: 0.448014, acc.: 84.38%] [G loss: 1.368006]\n",
      "epoch:21 step:20598 [D loss: 0.541203, acc.: 73.44%] [G loss: 1.566473]\n",
      "epoch:21 step:20599 [D loss: 0.640493, acc.: 63.28%] [G loss: 1.245232]\n",
      "epoch:21 step:20600 [D loss: 0.699888, acc.: 52.34%] [G loss: 0.863997]\n",
      "##############\n",
      "[2.28367904 1.49766086 5.60083201 4.1077042  2.87252055 5.58414593\n",
      " 4.0830397  4.64474261 4.00994458 3.74146629]\n",
      "##########\n",
      "epoch:21 step:20601 [D loss: 0.527275, acc.: 81.25%] [G loss: 1.328470]\n",
      "epoch:21 step:20602 [D loss: 0.608338, acc.: 64.84%] [G loss: 0.906464]\n",
      "epoch:21 step:20603 [D loss: 0.655548, acc.: 67.19%] [G loss: 1.040143]\n",
      "epoch:21 step:20604 [D loss: 0.401935, acc.: 89.84%] [G loss: 1.018002]\n",
      "epoch:21 step:20605 [D loss: 1.092090, acc.: 26.56%] [G loss: 0.905377]\n",
      "epoch:21 step:20606 [D loss: 0.385606, acc.: 91.41%] [G loss: 1.381243]\n",
      "epoch:21 step:20607 [D loss: 0.386845, acc.: 89.06%] [G loss: 1.553383]\n",
      "epoch:21 step:20608 [D loss: 0.501579, acc.: 77.34%] [G loss: 1.433958]\n",
      "epoch:21 step:20609 [D loss: 0.666517, acc.: 58.59%] [G loss: 0.999008]\n",
      "epoch:21 step:20610 [D loss: 0.660057, acc.: 58.59%] [G loss: 1.030542]\n",
      "epoch:21 step:20611 [D loss: 0.493560, acc.: 78.12%] [G loss: 1.179878]\n",
      "epoch:21 step:20612 [D loss: 0.606670, acc.: 67.19%] [G loss: 1.042963]\n",
      "epoch:21 step:20613 [D loss: 0.545789, acc.: 73.44%] [G loss: 1.085663]\n",
      "epoch:21 step:20614 [D loss: 0.274637, acc.: 90.62%] [G loss: 1.302657]\n",
      "epoch:22 step:20615 [D loss: 0.767967, acc.: 53.12%] [G loss: 1.138368]\n",
      "epoch:22 step:20616 [D loss: 0.606417, acc.: 65.62%] [G loss: 1.090237]\n",
      "epoch:22 step:20617 [D loss: 0.599694, acc.: 67.97%] [G loss: 1.018262]\n",
      "epoch:22 step:20618 [D loss: 0.534204, acc.: 78.12%] [G loss: 1.031875]\n",
      "epoch:22 step:20619 [D loss: 0.513662, acc.: 75.78%] [G loss: 1.301992]\n",
      "epoch:22 step:20620 [D loss: 0.439223, acc.: 85.16%] [G loss: 1.309684]\n",
      "epoch:22 step:20621 [D loss: 0.608193, acc.: 68.75%] [G loss: 1.040450]\n",
      "epoch:22 step:20622 [D loss: 0.610567, acc.: 64.06%] [G loss: 0.947546]\n",
      "epoch:22 step:20623 [D loss: 0.528726, acc.: 77.34%] [G loss: 0.973562]\n",
      "epoch:22 step:20624 [D loss: 0.526972, acc.: 71.09%] [G loss: 0.927283]\n",
      "epoch:22 step:20625 [D loss: 0.619471, acc.: 70.31%] [G loss: 1.083135]\n",
      "epoch:22 step:20626 [D loss: 0.673858, acc.: 56.25%] [G loss: 0.897747]\n",
      "epoch:22 step:20627 [D loss: 0.608618, acc.: 66.41%] [G loss: 1.035637]\n",
      "epoch:22 step:20628 [D loss: 0.766241, acc.: 50.00%] [G loss: 0.978779]\n",
      "epoch:22 step:20629 [D loss: 0.408520, acc.: 85.94%] [G loss: 1.172632]\n",
      "epoch:22 step:20630 [D loss: 0.527763, acc.: 73.44%] [G loss: 1.175142]\n",
      "epoch:22 step:20631 [D loss: 0.635121, acc.: 61.72%] [G loss: 1.257729]\n",
      "epoch:22 step:20632 [D loss: 0.715017, acc.: 49.22%] [G loss: 0.847255]\n",
      "epoch:22 step:20633 [D loss: 0.782500, acc.: 52.34%] [G loss: 0.997583]\n",
      "epoch:22 step:20634 [D loss: 0.697861, acc.: 54.69%] [G loss: 0.934134]\n",
      "epoch:22 step:20635 [D loss: 0.602089, acc.: 67.97%] [G loss: 0.973836]\n",
      "epoch:22 step:20636 [D loss: 0.803446, acc.: 39.06%] [G loss: 0.781383]\n",
      "epoch:22 step:20637 [D loss: 0.561796, acc.: 71.09%] [G loss: 0.962678]\n",
      "epoch:22 step:20638 [D loss: 0.615506, acc.: 68.75%] [G loss: 1.047344]\n",
      "epoch:22 step:20639 [D loss: 0.590570, acc.: 72.66%] [G loss: 1.007126]\n",
      "epoch:22 step:20640 [D loss: 0.485247, acc.: 82.81%] [G loss: 1.182340]\n",
      "epoch:22 step:20641 [D loss: 0.440378, acc.: 86.72%] [G loss: 1.254492]\n",
      "epoch:22 step:20642 [D loss: 0.409032, acc.: 86.72%] [G loss: 1.442668]\n",
      "epoch:22 step:20643 [D loss: 0.427240, acc.: 87.50%] [G loss: 1.315566]\n",
      "epoch:22 step:20644 [D loss: 0.454630, acc.: 83.59%] [G loss: 1.170451]\n",
      "epoch:22 step:20645 [D loss: 0.486194, acc.: 79.69%] [G loss: 1.208098]\n",
      "epoch:22 step:20646 [D loss: 0.401400, acc.: 88.28%] [G loss: 1.621009]\n",
      "epoch:22 step:20647 [D loss: 0.400254, acc.: 83.59%] [G loss: 1.521343]\n",
      "epoch:22 step:20648 [D loss: 0.403841, acc.: 87.50%] [G loss: 1.340370]\n",
      "epoch:22 step:20649 [D loss: 0.296001, acc.: 91.41%] [G loss: 1.793813]\n",
      "epoch:22 step:20650 [D loss: 0.245364, acc.: 97.66%] [G loss: 1.672787]\n",
      "epoch:22 step:20651 [D loss: 0.888035, acc.: 42.97%] [G loss: 1.308285]\n",
      "epoch:22 step:20652 [D loss: 0.783185, acc.: 45.31%] [G loss: 1.288207]\n",
      "epoch:22 step:20653 [D loss: 0.688675, acc.: 55.47%] [G loss: 1.002196]\n",
      "epoch:22 step:20654 [D loss: 0.661333, acc.: 57.81%] [G loss: 0.998338]\n",
      "epoch:22 step:20655 [D loss: 0.820156, acc.: 42.19%] [G loss: 0.907556]\n",
      "epoch:22 step:20656 [D loss: 0.686637, acc.: 58.59%] [G loss: 1.031827]\n",
      "epoch:22 step:20657 [D loss: 0.593736, acc.: 66.41%] [G loss: 1.052373]\n",
      "epoch:22 step:20658 [D loss: 0.533165, acc.: 76.56%] [G loss: 0.977609]\n",
      "epoch:22 step:20659 [D loss: 0.648467, acc.: 58.59%] [G loss: 1.001844]\n",
      "epoch:22 step:20660 [D loss: 0.759261, acc.: 47.66%] [G loss: 0.894037]\n",
      "epoch:22 step:20661 [D loss: 0.593704, acc.: 64.84%] [G loss: 1.128893]\n",
      "epoch:22 step:20662 [D loss: 0.625809, acc.: 58.59%] [G loss: 0.932405]\n",
      "epoch:22 step:20663 [D loss: 0.526631, acc.: 79.69%] [G loss: 1.217507]\n",
      "epoch:22 step:20664 [D loss: 0.495048, acc.: 83.59%] [G loss: 1.157856]\n",
      "epoch:22 step:20665 [D loss: 0.636138, acc.: 65.62%] [G loss: 1.019124]\n",
      "epoch:22 step:20666 [D loss: 0.687162, acc.: 56.25%] [G loss: 1.002033]\n",
      "epoch:22 step:20667 [D loss: 0.636095, acc.: 61.72%] [G loss: 0.901308]\n",
      "epoch:22 step:20668 [D loss: 0.535873, acc.: 70.31%] [G loss: 1.204265]\n",
      "epoch:22 step:20669 [D loss: 0.478990, acc.: 81.25%] [G loss: 1.101579]\n",
      "epoch:22 step:20670 [D loss: 0.757810, acc.: 48.44%] [G loss: 0.938174]\n",
      "epoch:22 step:20671 [D loss: 0.704772, acc.: 60.16%] [G loss: 0.939335]\n",
      "epoch:22 step:20672 [D loss: 0.731673, acc.: 52.34%] [G loss: 1.013686]\n",
      "epoch:22 step:20673 [D loss: 0.743217, acc.: 51.56%] [G loss: 1.069649]\n",
      "epoch:22 step:20674 [D loss: 0.598086, acc.: 67.97%] [G loss: 0.993530]\n",
      "epoch:22 step:20675 [D loss: 0.659276, acc.: 61.72%] [G loss: 0.819476]\n",
      "epoch:22 step:20676 [D loss: 0.541257, acc.: 71.88%] [G loss: 0.964268]\n",
      "epoch:22 step:20677 [D loss: 0.643363, acc.: 64.06%] [G loss: 0.864755]\n",
      "epoch:22 step:20678 [D loss: 0.621537, acc.: 69.53%] [G loss: 1.101969]\n",
      "epoch:22 step:20679 [D loss: 0.516587, acc.: 78.12%] [G loss: 1.014470]\n",
      "epoch:22 step:20680 [D loss: 0.702156, acc.: 53.91%] [G loss: 0.918148]\n",
      "epoch:22 step:20681 [D loss: 0.715028, acc.: 55.47%] [G loss: 1.039093]\n",
      "epoch:22 step:20682 [D loss: 0.523328, acc.: 72.66%] [G loss: 1.132372]\n",
      "epoch:22 step:20683 [D loss: 0.492424, acc.: 81.25%] [G loss: 1.320359]\n",
      "epoch:22 step:20684 [D loss: 0.616271, acc.: 62.50%] [G loss: 1.510753]\n",
      "epoch:22 step:20685 [D loss: 0.626041, acc.: 65.62%] [G loss: 1.019534]\n",
      "epoch:22 step:20686 [D loss: 0.607455, acc.: 68.75%] [G loss: 1.109427]\n",
      "epoch:22 step:20687 [D loss: 0.551337, acc.: 73.44%] [G loss: 1.047708]\n",
      "epoch:22 step:20688 [D loss: 0.461602, acc.: 83.59%] [G loss: 1.117253]\n",
      "epoch:22 step:20689 [D loss: 0.427106, acc.: 74.22%] [G loss: 1.284276]\n",
      "epoch:22 step:20690 [D loss: 0.405309, acc.: 86.72%] [G loss: 1.406471]\n",
      "epoch:22 step:20691 [D loss: 0.473351, acc.: 78.12%] [G loss: 1.263802]\n",
      "epoch:22 step:20692 [D loss: 0.674269, acc.: 58.59%] [G loss: 1.163792]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20693 [D loss: 0.545737, acc.: 75.78%] [G loss: 1.172567]\n",
      "epoch:22 step:20694 [D loss: 0.652570, acc.: 57.03%] [G loss: 1.061301]\n",
      "epoch:22 step:20695 [D loss: 0.690869, acc.: 57.81%] [G loss: 0.973815]\n",
      "epoch:22 step:20696 [D loss: 0.535554, acc.: 76.56%] [G loss: 1.098109]\n",
      "epoch:22 step:20697 [D loss: 0.601461, acc.: 68.75%] [G loss: 0.760673]\n",
      "epoch:22 step:20698 [D loss: 0.736828, acc.: 53.12%] [G loss: 0.972875]\n",
      "epoch:22 step:20699 [D loss: 0.547256, acc.: 78.91%] [G loss: 1.094475]\n",
      "epoch:22 step:20700 [D loss: 0.595248, acc.: 66.41%] [G loss: 0.921502]\n",
      "epoch:22 step:20701 [D loss: 0.567920, acc.: 70.31%] [G loss: 0.999312]\n",
      "epoch:22 step:20702 [D loss: 0.584716, acc.: 69.53%] [G loss: 1.110844]\n",
      "epoch:22 step:20703 [D loss: 0.552863, acc.: 76.56%] [G loss: 1.088530]\n",
      "epoch:22 step:20704 [D loss: 0.435316, acc.: 89.06%] [G loss: 1.154246]\n",
      "epoch:22 step:20705 [D loss: 0.631004, acc.: 67.97%] [G loss: 0.770733]\n",
      "epoch:22 step:20706 [D loss: 0.457472, acc.: 85.16%] [G loss: 1.480380]\n",
      "epoch:22 step:20707 [D loss: 0.543064, acc.: 75.00%] [G loss: 1.402052]\n",
      "epoch:22 step:20708 [D loss: 0.619139, acc.: 66.41%] [G loss: 1.128365]\n",
      "epoch:22 step:20709 [D loss: 0.874787, acc.: 42.19%] [G loss: 0.757165]\n",
      "epoch:22 step:20710 [D loss: 0.627516, acc.: 61.72%] [G loss: 1.040998]\n",
      "epoch:22 step:20711 [D loss: 0.752839, acc.: 50.78%] [G loss: 0.763287]\n",
      "epoch:22 step:20712 [D loss: 1.012573, acc.: 23.44%] [G loss: 0.746353]\n",
      "epoch:22 step:20713 [D loss: 0.776707, acc.: 47.66%] [G loss: 1.219815]\n",
      "epoch:22 step:20714 [D loss: 0.840074, acc.: 39.06%] [G loss: 0.961411]\n",
      "epoch:22 step:20715 [D loss: 0.684505, acc.: 59.38%] [G loss: 0.915856]\n",
      "epoch:22 step:20716 [D loss: 0.845239, acc.: 41.41%] [G loss: 0.690221]\n",
      "epoch:22 step:20717 [D loss: 0.654169, acc.: 58.59%] [G loss: 1.291886]\n",
      "epoch:22 step:20718 [D loss: 0.611353, acc.: 68.75%] [G loss: 1.086780]\n",
      "epoch:22 step:20719 [D loss: 0.634674, acc.: 66.41%] [G loss: 1.027578]\n",
      "epoch:22 step:20720 [D loss: 0.620870, acc.: 64.84%] [G loss: 1.053055]\n",
      "epoch:22 step:20721 [D loss: 0.697131, acc.: 53.91%] [G loss: 0.960318]\n",
      "epoch:22 step:20722 [D loss: 0.585980, acc.: 69.53%] [G loss: 1.068271]\n",
      "epoch:22 step:20723 [D loss: 0.453237, acc.: 84.38%] [G loss: 1.017869]\n",
      "epoch:22 step:20724 [D loss: 0.460766, acc.: 82.81%] [G loss: 1.108931]\n",
      "epoch:22 step:20725 [D loss: 0.648181, acc.: 60.16%] [G loss: 0.745287]\n",
      "epoch:22 step:20726 [D loss: 0.571480, acc.: 73.44%] [G loss: 0.836019]\n",
      "epoch:22 step:20727 [D loss: 0.796208, acc.: 44.53%] [G loss: 0.874083]\n",
      "epoch:22 step:20728 [D loss: 0.730326, acc.: 50.78%] [G loss: 1.091383]\n",
      "epoch:22 step:20729 [D loss: 0.674071, acc.: 61.72%] [G loss: 0.902634]\n",
      "epoch:22 step:20730 [D loss: 0.532824, acc.: 76.56%] [G loss: 1.133605]\n",
      "epoch:22 step:20731 [D loss: 0.296814, acc.: 93.75%] [G loss: 1.221901]\n",
      "epoch:22 step:20732 [D loss: 0.512452, acc.: 82.81%] [G loss: 1.044122]\n",
      "epoch:22 step:20733 [D loss: 0.284787, acc.: 94.53%] [G loss: 1.380400]\n",
      "epoch:22 step:20734 [D loss: 0.849007, acc.: 51.56%] [G loss: 1.368986]\n",
      "epoch:22 step:20735 [D loss: 0.745094, acc.: 57.03%] [G loss: 1.285786]\n",
      "epoch:22 step:20736 [D loss: 0.415733, acc.: 86.72%] [G loss: 1.380945]\n",
      "epoch:22 step:20737 [D loss: 0.696912, acc.: 56.25%] [G loss: 1.343359]\n",
      "epoch:22 step:20738 [D loss: 0.498971, acc.: 73.44%] [G loss: 1.393223]\n",
      "epoch:22 step:20739 [D loss: 0.479932, acc.: 82.81%] [G loss: 1.048000]\n",
      "epoch:22 step:20740 [D loss: 0.682868, acc.: 56.25%] [G loss: 0.822668]\n",
      "epoch:22 step:20741 [D loss: 0.626942, acc.: 67.19%] [G loss: 1.163759]\n",
      "epoch:22 step:20742 [D loss: 0.674123, acc.: 60.16%] [G loss: 0.872114]\n",
      "epoch:22 step:20743 [D loss: 0.704730, acc.: 57.81%] [G loss: 1.056055]\n",
      "epoch:22 step:20744 [D loss: 0.594008, acc.: 66.41%] [G loss: 1.053046]\n",
      "epoch:22 step:20745 [D loss: 0.520938, acc.: 73.44%] [G loss: 1.135924]\n",
      "epoch:22 step:20746 [D loss: 0.676626, acc.: 54.69%] [G loss: 1.138016]\n",
      "epoch:22 step:20747 [D loss: 0.669252, acc.: 57.81%] [G loss: 1.018218]\n",
      "epoch:22 step:20748 [D loss: 0.648851, acc.: 65.62%] [G loss: 0.959555]\n",
      "epoch:22 step:20749 [D loss: 0.686005, acc.: 60.94%] [G loss: 1.240887]\n",
      "epoch:22 step:20750 [D loss: 0.676548, acc.: 61.72%] [G loss: 1.155268]\n",
      "epoch:22 step:20751 [D loss: 0.684135, acc.: 57.81%] [G loss: 1.097083]\n",
      "epoch:22 step:20752 [D loss: 0.707972, acc.: 53.91%] [G loss: 0.934294]\n",
      "epoch:22 step:20753 [D loss: 0.454680, acc.: 84.38%] [G loss: 1.181568]\n",
      "epoch:22 step:20754 [D loss: 0.738199, acc.: 55.47%] [G loss: 0.989335]\n",
      "epoch:22 step:20755 [D loss: 0.670281, acc.: 57.81%] [G loss: 1.221598]\n",
      "epoch:22 step:20756 [D loss: 0.562076, acc.: 74.22%] [G loss: 1.041032]\n",
      "epoch:22 step:20757 [D loss: 0.623190, acc.: 65.62%] [G loss: 0.827282]\n",
      "epoch:22 step:20758 [D loss: 0.547949, acc.: 73.44%] [G loss: 0.998952]\n",
      "epoch:22 step:20759 [D loss: 0.492405, acc.: 75.78%] [G loss: 1.146394]\n",
      "epoch:22 step:20760 [D loss: 0.607316, acc.: 67.19%] [G loss: 1.094522]\n",
      "epoch:22 step:20761 [D loss: 0.646952, acc.: 60.94%] [G loss: 1.093315]\n",
      "epoch:22 step:20762 [D loss: 0.751290, acc.: 52.34%] [G loss: 1.015762]\n",
      "epoch:22 step:20763 [D loss: 0.804424, acc.: 46.88%] [G loss: 0.941921]\n",
      "epoch:22 step:20764 [D loss: 0.370784, acc.: 92.19%] [G loss: 1.151392]\n",
      "epoch:22 step:20765 [D loss: 0.507688, acc.: 77.34%] [G loss: 1.184922]\n",
      "epoch:22 step:20766 [D loss: 0.548516, acc.: 71.09%] [G loss: 1.259404]\n",
      "epoch:22 step:20767 [D loss: 0.686994, acc.: 59.38%] [G loss: 1.001285]\n",
      "epoch:22 step:20768 [D loss: 0.712140, acc.: 54.69%] [G loss: 1.060355]\n",
      "epoch:22 step:20769 [D loss: 0.546465, acc.: 72.66%] [G loss: 1.005610]\n",
      "epoch:22 step:20770 [D loss: 0.464144, acc.: 85.16%] [G loss: 1.293146]\n",
      "epoch:22 step:20771 [D loss: 0.710529, acc.: 54.69%] [G loss: 1.046913]\n",
      "epoch:22 step:20772 [D loss: 0.460743, acc.: 84.38%] [G loss: 1.282886]\n",
      "epoch:22 step:20773 [D loss: 0.307555, acc.: 92.19%] [G loss: 1.469217]\n",
      "epoch:22 step:20774 [D loss: 0.698211, acc.: 54.69%] [G loss: 1.162006]\n",
      "epoch:22 step:20775 [D loss: 0.774170, acc.: 50.00%] [G loss: 1.094123]\n",
      "epoch:22 step:20776 [D loss: 0.766209, acc.: 47.66%] [G loss: 0.717104]\n",
      "epoch:22 step:20777 [D loss: 0.557802, acc.: 68.75%] [G loss: 0.949556]\n",
      "epoch:22 step:20778 [D loss: 0.552742, acc.: 73.44%] [G loss: 0.972921]\n",
      "epoch:22 step:20779 [D loss: 0.564456, acc.: 71.88%] [G loss: 1.166281]\n",
      "epoch:22 step:20780 [D loss: 0.539652, acc.: 71.09%] [G loss: 1.029866]\n",
      "epoch:22 step:20781 [D loss: 0.429465, acc.: 87.50%] [G loss: 1.358000]\n",
      "epoch:22 step:20782 [D loss: 0.570537, acc.: 76.56%] [G loss: 1.169752]\n",
      "epoch:22 step:20783 [D loss: 0.718432, acc.: 57.03%] [G loss: 0.853763]\n",
      "epoch:22 step:20784 [D loss: 0.713168, acc.: 51.56%] [G loss: 1.083267]\n",
      "epoch:22 step:20785 [D loss: 0.657917, acc.: 62.50%] [G loss: 1.049689]\n",
      "epoch:22 step:20786 [D loss: 0.702175, acc.: 54.69%] [G loss: 0.952581]\n",
      "epoch:22 step:20787 [D loss: 0.744444, acc.: 51.56%] [G loss: 0.906201]\n",
      "epoch:22 step:20788 [D loss: 0.932726, acc.: 26.56%] [G loss: 0.688158]\n",
      "epoch:22 step:20789 [D loss: 0.962034, acc.: 31.25%] [G loss: 0.752389]\n",
      "epoch:22 step:20790 [D loss: 0.657711, acc.: 55.47%] [G loss: 0.972327]\n",
      "epoch:22 step:20791 [D loss: 0.733270, acc.: 50.78%] [G loss: 1.039713]\n",
      "epoch:22 step:20792 [D loss: 0.883818, acc.: 32.81%] [G loss: 0.761989]\n",
      "epoch:22 step:20793 [D loss: 0.713969, acc.: 52.34%] [G loss: 0.764389]\n",
      "epoch:22 step:20794 [D loss: 0.926007, acc.: 30.47%] [G loss: 0.929303]\n",
      "epoch:22 step:20795 [D loss: 0.707650, acc.: 53.91%] [G loss: 0.962726]\n",
      "epoch:22 step:20796 [D loss: 0.565743, acc.: 71.09%] [G loss: 1.057157]\n",
      "epoch:22 step:20797 [D loss: 0.842907, acc.: 39.06%] [G loss: 0.907069]\n",
      "epoch:22 step:20798 [D loss: 0.804575, acc.: 42.97%] [G loss: 0.832887]\n",
      "epoch:22 step:20799 [D loss: 0.992454, acc.: 29.69%] [G loss: 0.802001]\n",
      "epoch:22 step:20800 [D loss: 0.827368, acc.: 46.88%] [G loss: 1.080920]\n",
      "##############\n",
      "[2.5346092  1.39253628 5.55281477 4.33088041 3.08538708 5.76314456\n",
      " 4.41116894 4.79422443 4.14176925 3.84237539]\n",
      "##########\n",
      "epoch:22 step:20801 [D loss: 0.789618, acc.: 49.22%] [G loss: 1.148522]\n",
      "epoch:22 step:20802 [D loss: 0.644625, acc.: 63.28%] [G loss: 1.055151]\n",
      "epoch:22 step:20803 [D loss: 0.733540, acc.: 55.47%] [G loss: 1.207459]\n",
      "epoch:22 step:20804 [D loss: 0.657943, acc.: 62.50%] [G loss: 0.948588]\n",
      "epoch:22 step:20805 [D loss: 0.595177, acc.: 67.97%] [G loss: 1.014932]\n",
      "epoch:22 step:20806 [D loss: 0.535995, acc.: 73.44%] [G loss: 1.030088]\n",
      "epoch:22 step:20807 [D loss: 0.719566, acc.: 55.47%] [G loss: 0.954327]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20808 [D loss: 0.607565, acc.: 67.19%] [G loss: 1.213698]\n",
      "epoch:22 step:20809 [D loss: 0.713233, acc.: 56.25%] [G loss: 1.007418]\n",
      "epoch:22 step:20810 [D loss: 0.759275, acc.: 46.09%] [G loss: 1.006136]\n",
      "epoch:22 step:20811 [D loss: 0.748362, acc.: 53.12%] [G loss: 0.788639]\n",
      "epoch:22 step:20812 [D loss: 0.676825, acc.: 61.72%] [G loss: 1.204687]\n",
      "epoch:22 step:20813 [D loss: 0.735348, acc.: 50.78%] [G loss: 0.965722]\n",
      "epoch:22 step:20814 [D loss: 0.674819, acc.: 56.25%] [G loss: 0.976410]\n",
      "epoch:22 step:20815 [D loss: 0.486811, acc.: 76.56%] [G loss: 1.242084]\n",
      "epoch:22 step:20816 [D loss: 0.672927, acc.: 57.03%] [G loss: 1.373719]\n",
      "epoch:22 step:20817 [D loss: 0.759881, acc.: 53.12%] [G loss: 0.922266]\n",
      "epoch:22 step:20818 [D loss: 0.711020, acc.: 46.09%] [G loss: 0.902124]\n",
      "epoch:22 step:20819 [D loss: 0.694886, acc.: 53.91%] [G loss: 0.855806]\n",
      "epoch:22 step:20820 [D loss: 0.536375, acc.: 78.12%] [G loss: 0.995099]\n",
      "epoch:22 step:20821 [D loss: 0.673872, acc.: 55.47%] [G loss: 0.884142]\n",
      "epoch:22 step:20822 [D loss: 0.626646, acc.: 65.62%] [G loss: 0.927027]\n",
      "epoch:22 step:20823 [D loss: 0.581095, acc.: 70.31%] [G loss: 1.015782]\n",
      "epoch:22 step:20824 [D loss: 0.648773, acc.: 64.84%] [G loss: 1.028043]\n",
      "epoch:22 step:20825 [D loss: 0.626550, acc.: 66.41%] [G loss: 1.087778]\n",
      "epoch:22 step:20826 [D loss: 0.643401, acc.: 60.16%] [G loss: 0.902708]\n",
      "epoch:22 step:20827 [D loss: 0.528782, acc.: 78.12%] [G loss: 1.270192]\n",
      "epoch:22 step:20828 [D loss: 0.787053, acc.: 47.66%] [G loss: 0.713534]\n",
      "epoch:22 step:20829 [D loss: 0.550148, acc.: 71.88%] [G loss: 1.059634]\n",
      "epoch:22 step:20830 [D loss: 0.710054, acc.: 56.25%] [G loss: 1.133232]\n",
      "epoch:22 step:20831 [D loss: 0.842441, acc.: 38.28%] [G loss: 0.803248]\n",
      "epoch:22 step:20832 [D loss: 0.692096, acc.: 57.03%] [G loss: 1.000241]\n",
      "epoch:22 step:20833 [D loss: 0.652546, acc.: 55.47%] [G loss: 0.920307]\n",
      "epoch:22 step:20834 [D loss: 0.318018, acc.: 85.94%] [G loss: 1.273151]\n",
      "epoch:22 step:20835 [D loss: 0.371046, acc.: 87.50%] [G loss: 1.149931]\n",
      "epoch:22 step:20836 [D loss: 0.346581, acc.: 94.53%] [G loss: 1.524322]\n",
      "epoch:22 step:20837 [D loss: 0.324540, acc.: 91.41%] [G loss: 1.641854]\n",
      "epoch:22 step:20838 [D loss: 0.836504, acc.: 51.56%] [G loss: 1.219043]\n",
      "epoch:22 step:20839 [D loss: 1.038999, acc.: 25.78%] [G loss: 0.757963]\n",
      "epoch:22 step:20840 [D loss: 0.515875, acc.: 78.91%] [G loss: 1.204089]\n",
      "epoch:22 step:20841 [D loss: 0.743641, acc.: 48.44%] [G loss: 1.014573]\n",
      "epoch:22 step:20842 [D loss: 0.578367, acc.: 67.19%] [G loss: 1.114017]\n",
      "epoch:22 step:20843 [D loss: 0.546759, acc.: 71.88%] [G loss: 1.207288]\n",
      "epoch:22 step:20844 [D loss: 0.251244, acc.: 92.19%] [G loss: 1.350070]\n",
      "epoch:22 step:20845 [D loss: 0.252680, acc.: 96.09%] [G loss: 1.529846]\n",
      "epoch:22 step:20846 [D loss: 0.288215, acc.: 90.62%] [G loss: 1.368953]\n",
      "epoch:22 step:20847 [D loss: 0.716047, acc.: 56.25%] [G loss: 1.498538]\n",
      "epoch:22 step:20848 [D loss: 0.850338, acc.: 39.84%] [G loss: 1.027525]\n",
      "epoch:22 step:20849 [D loss: 0.636199, acc.: 63.28%] [G loss: 0.988789]\n",
      "epoch:22 step:20850 [D loss: 0.645505, acc.: 64.06%] [G loss: 1.156165]\n",
      "epoch:22 step:20851 [D loss: 0.776728, acc.: 50.00%] [G loss: 0.775624]\n",
      "epoch:22 step:20852 [D loss: 0.569525, acc.: 73.44%] [G loss: 1.056368]\n",
      "epoch:22 step:20853 [D loss: 0.554112, acc.: 71.09%] [G loss: 1.106352]\n",
      "epoch:22 step:20854 [D loss: 0.842586, acc.: 39.06%] [G loss: 0.897559]\n",
      "epoch:22 step:20855 [D loss: 0.978510, acc.: 33.59%] [G loss: 0.999321]\n",
      "epoch:22 step:20856 [D loss: 0.699481, acc.: 54.69%] [G loss: 1.056900]\n",
      "epoch:22 step:20857 [D loss: 0.674384, acc.: 59.38%] [G loss: 1.158476]\n",
      "epoch:22 step:20858 [D loss: 0.582271, acc.: 73.44%] [G loss: 1.227131]\n",
      "epoch:22 step:20859 [D loss: 0.806697, acc.: 45.31%] [G loss: 0.862887]\n",
      "epoch:22 step:20860 [D loss: 0.445356, acc.: 84.38%] [G loss: 1.071267]\n",
      "epoch:22 step:20861 [D loss: 0.430396, acc.: 86.72%] [G loss: 1.493614]\n",
      "epoch:22 step:20862 [D loss: 0.421155, acc.: 84.38%] [G loss: 1.287549]\n",
      "epoch:22 step:20863 [D loss: 0.750290, acc.: 47.66%] [G loss: 1.034798]\n",
      "epoch:22 step:20864 [D loss: 0.515678, acc.: 75.78%] [G loss: 1.113009]\n",
      "epoch:22 step:20865 [D loss: 0.645151, acc.: 62.50%] [G loss: 1.120179]\n",
      "epoch:22 step:20866 [D loss: 0.602621, acc.: 71.09%] [G loss: 1.149247]\n",
      "epoch:22 step:20867 [D loss: 0.663692, acc.: 61.72%] [G loss: 1.067359]\n",
      "epoch:22 step:20868 [D loss: 0.668130, acc.: 57.03%] [G loss: 1.137856]\n",
      "epoch:22 step:20869 [D loss: 0.825144, acc.: 44.53%] [G loss: 1.068633]\n",
      "epoch:22 step:20870 [D loss: 0.704490, acc.: 55.47%] [G loss: 1.114437]\n",
      "epoch:22 step:20871 [D loss: 0.582986, acc.: 72.66%] [G loss: 0.973412]\n",
      "epoch:22 step:20872 [D loss: 0.631561, acc.: 64.06%] [G loss: 0.746744]\n",
      "epoch:22 step:20873 [D loss: 0.715001, acc.: 54.69%] [G loss: 0.942888]\n",
      "epoch:22 step:20874 [D loss: 0.651775, acc.: 61.72%] [G loss: 0.889309]\n",
      "epoch:22 step:20875 [D loss: 0.587076, acc.: 61.72%] [G loss: 0.915121]\n",
      "epoch:22 step:20876 [D loss: 0.682258, acc.: 58.59%] [G loss: 1.049560]\n",
      "epoch:22 step:20877 [D loss: 0.534259, acc.: 73.44%] [G loss: 0.928185]\n",
      "epoch:22 step:20878 [D loss: 0.443928, acc.: 84.38%] [G loss: 1.150289]\n",
      "epoch:22 step:20879 [D loss: 0.709880, acc.: 58.59%] [G loss: 1.035552]\n",
      "epoch:22 step:20880 [D loss: 0.833301, acc.: 37.50%] [G loss: 0.679289]\n",
      "epoch:22 step:20881 [D loss: 0.605072, acc.: 67.19%] [G loss: 1.094436]\n",
      "epoch:22 step:20882 [D loss: 0.553380, acc.: 71.88%] [G loss: 1.096829]\n",
      "epoch:22 step:20883 [D loss: 0.501224, acc.: 76.56%] [G loss: 1.241526]\n",
      "epoch:22 step:20884 [D loss: 0.697205, acc.: 53.12%] [G loss: 0.825730]\n",
      "epoch:22 step:20885 [D loss: 0.737557, acc.: 57.03%] [G loss: 0.728336]\n",
      "epoch:22 step:20886 [D loss: 0.506920, acc.: 78.12%] [G loss: 1.104808]\n",
      "epoch:22 step:20887 [D loss: 0.488393, acc.: 79.69%] [G loss: 1.359190]\n",
      "epoch:22 step:20888 [D loss: 0.575615, acc.: 70.31%] [G loss: 1.106272]\n",
      "epoch:22 step:20889 [D loss: 0.625926, acc.: 62.50%] [G loss: 0.948241]\n",
      "epoch:22 step:20890 [D loss: 0.564602, acc.: 74.22%] [G loss: 0.983323]\n",
      "epoch:22 step:20891 [D loss: 0.688770, acc.: 56.25%] [G loss: 0.918812]\n",
      "epoch:22 step:20892 [D loss: 0.548562, acc.: 73.44%] [G loss: 1.050432]\n",
      "epoch:22 step:20893 [D loss: 0.296004, acc.: 92.97%] [G loss: 1.270762]\n",
      "epoch:22 step:20894 [D loss: 0.347166, acc.: 93.75%] [G loss: 1.450123]\n",
      "epoch:22 step:20895 [D loss: 0.677817, acc.: 54.69%] [G loss: 1.194111]\n",
      "epoch:22 step:20896 [D loss: 0.631983, acc.: 65.62%] [G loss: 0.919261]\n",
      "epoch:22 step:20897 [D loss: 0.669677, acc.: 57.81%] [G loss: 0.948275]\n",
      "epoch:22 step:20898 [D loss: 0.421529, acc.: 85.94%] [G loss: 1.379313]\n",
      "epoch:22 step:20899 [D loss: 0.335277, acc.: 93.75%] [G loss: 1.376844]\n",
      "epoch:22 step:20900 [D loss: 0.356423, acc.: 94.53%] [G loss: 1.276429]\n",
      "epoch:22 step:20901 [D loss: 0.561041, acc.: 73.44%] [G loss: 1.098979]\n",
      "epoch:22 step:20902 [D loss: 0.634303, acc.: 64.06%] [G loss: 0.902647]\n",
      "epoch:22 step:20903 [D loss: 0.474593, acc.: 81.25%] [G loss: 1.383119]\n",
      "epoch:22 step:20904 [D loss: 0.569452, acc.: 66.41%] [G loss: 0.856670]\n",
      "epoch:22 step:20905 [D loss: 0.517530, acc.: 71.88%] [G loss: 1.033960]\n",
      "epoch:22 step:20906 [D loss: 0.561122, acc.: 68.75%] [G loss: 1.248062]\n",
      "epoch:22 step:20907 [D loss: 0.542240, acc.: 72.66%] [G loss: 1.179533]\n",
      "epoch:22 step:20908 [D loss: 0.581376, acc.: 69.53%] [G loss: 1.175522]\n",
      "epoch:22 step:20909 [D loss: 1.046868, acc.: 26.56%] [G loss: 0.752120]\n",
      "epoch:22 step:20910 [D loss: 0.727258, acc.: 51.56%] [G loss: 0.928194]\n",
      "epoch:22 step:20911 [D loss: 0.675149, acc.: 60.94%] [G loss: 0.966889]\n",
      "epoch:22 step:20912 [D loss: 0.539075, acc.: 72.66%] [G loss: 1.091705]\n",
      "epoch:22 step:20913 [D loss: 0.724858, acc.: 55.47%] [G loss: 0.959351]\n",
      "epoch:22 step:20914 [D loss: 0.646691, acc.: 57.81%] [G loss: 0.934955]\n",
      "epoch:22 step:20915 [D loss: 0.680959, acc.: 54.69%] [G loss: 1.197635]\n",
      "epoch:22 step:20916 [D loss: 0.674548, acc.: 60.16%] [G loss: 0.971410]\n",
      "epoch:22 step:20917 [D loss: 0.668761, acc.: 56.25%] [G loss: 1.072634]\n",
      "epoch:22 step:20918 [D loss: 0.583232, acc.: 68.75%] [G loss: 1.018633]\n",
      "epoch:22 step:20919 [D loss: 0.610947, acc.: 69.53%] [G loss: 0.995579]\n",
      "epoch:22 step:20920 [D loss: 0.777948, acc.: 47.66%] [G loss: 0.981579]\n",
      "epoch:22 step:20921 [D loss: 0.554333, acc.: 76.56%] [G loss: 1.046770]\n",
      "epoch:22 step:20922 [D loss: 0.711289, acc.: 57.03%] [G loss: 1.047701]\n",
      "epoch:22 step:20923 [D loss: 0.601192, acc.: 64.84%] [G loss: 1.066537]\n",
      "epoch:22 step:20924 [D loss: 0.649170, acc.: 62.50%] [G loss: 0.946643]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20925 [D loss: 0.582787, acc.: 67.19%] [G loss: 1.064070]\n",
      "epoch:22 step:20926 [D loss: 0.450380, acc.: 78.12%] [G loss: 1.010186]\n",
      "epoch:22 step:20927 [D loss: 0.420827, acc.: 89.06%] [G loss: 1.241309]\n",
      "epoch:22 step:20928 [D loss: 0.532631, acc.: 75.00%] [G loss: 1.078437]\n",
      "epoch:22 step:20929 [D loss: 0.591606, acc.: 66.41%] [G loss: 1.002609]\n",
      "epoch:22 step:20930 [D loss: 0.721675, acc.: 53.91%] [G loss: 1.220050]\n",
      "epoch:22 step:20931 [D loss: 0.690077, acc.: 53.91%] [G loss: 1.117110]\n",
      "epoch:22 step:20932 [D loss: 0.436863, acc.: 85.16%] [G loss: 1.177691]\n",
      "epoch:22 step:20933 [D loss: 0.619746, acc.: 65.62%] [G loss: 1.132819]\n",
      "epoch:22 step:20934 [D loss: 0.645291, acc.: 63.28%] [G loss: 0.823810]\n",
      "epoch:22 step:20935 [D loss: 0.427698, acc.: 83.59%] [G loss: 1.166476]\n",
      "epoch:22 step:20936 [D loss: 0.518924, acc.: 78.12%] [G loss: 1.325018]\n",
      "epoch:22 step:20937 [D loss: 0.741685, acc.: 54.69%] [G loss: 1.262115]\n",
      "epoch:22 step:20938 [D loss: 0.583914, acc.: 71.88%] [G loss: 1.013261]\n",
      "epoch:22 step:20939 [D loss: 0.661113, acc.: 62.50%] [G loss: 0.916756]\n",
      "epoch:22 step:20940 [D loss: 0.444309, acc.: 85.94%] [G loss: 1.058752]\n",
      "epoch:22 step:20941 [D loss: 0.356244, acc.: 89.06%] [G loss: 1.347566]\n",
      "epoch:22 step:20942 [D loss: 0.364094, acc.: 89.84%] [G loss: 1.401392]\n",
      "epoch:22 step:20943 [D loss: 0.531086, acc.: 75.00%] [G loss: 1.189319]\n",
      "epoch:22 step:20944 [D loss: 0.860815, acc.: 45.31%] [G loss: 0.969131]\n",
      "epoch:22 step:20945 [D loss: 0.780777, acc.: 50.00%] [G loss: 1.013425]\n",
      "epoch:22 step:20946 [D loss: 0.706501, acc.: 55.47%] [G loss: 0.969238]\n",
      "epoch:22 step:20947 [D loss: 0.717471, acc.: 53.91%] [G loss: 1.086375]\n",
      "epoch:22 step:20948 [D loss: 0.799622, acc.: 43.75%] [G loss: 1.023831]\n",
      "epoch:22 step:20949 [D loss: 0.672578, acc.: 55.47%] [G loss: 1.100021]\n",
      "epoch:22 step:20950 [D loss: 0.679118, acc.: 56.25%] [G loss: 1.263922]\n",
      "epoch:22 step:20951 [D loss: 0.613923, acc.: 65.62%] [G loss: 1.160209]\n",
      "epoch:22 step:20952 [D loss: 0.683473, acc.: 58.59%] [G loss: 0.803085]\n",
      "epoch:22 step:20953 [D loss: 0.611247, acc.: 67.97%] [G loss: 1.263848]\n",
      "epoch:22 step:20954 [D loss: 0.643297, acc.: 70.31%] [G loss: 1.133499]\n",
      "epoch:22 step:20955 [D loss: 0.615506, acc.: 65.62%] [G loss: 0.949813]\n",
      "epoch:22 step:20956 [D loss: 0.527931, acc.: 72.66%] [G loss: 1.146033]\n",
      "epoch:22 step:20957 [D loss: 0.401918, acc.: 87.50%] [G loss: 1.374609]\n",
      "epoch:22 step:20958 [D loss: 0.454165, acc.: 87.50%] [G loss: 1.182643]\n",
      "epoch:22 step:20959 [D loss: 0.367801, acc.: 89.06%] [G loss: 1.453662]\n",
      "epoch:22 step:20960 [D loss: 0.352250, acc.: 89.06%] [G loss: 1.336974]\n",
      "epoch:22 step:20961 [D loss: 0.282261, acc.: 96.09%] [G loss: 1.531188]\n",
      "epoch:22 step:20962 [D loss: 0.811198, acc.: 48.44%] [G loss: 1.282038]\n",
      "epoch:22 step:20963 [D loss: 0.683372, acc.: 59.38%] [G loss: 1.059519]\n",
      "epoch:22 step:20964 [D loss: 0.674573, acc.: 59.38%] [G loss: 0.949956]\n",
      "epoch:22 step:20965 [D loss: 0.529747, acc.: 75.00%] [G loss: 0.903936]\n",
      "epoch:22 step:20966 [D loss: 0.565757, acc.: 75.00%] [G loss: 0.984567]\n",
      "epoch:22 step:20967 [D loss: 0.615170, acc.: 64.84%] [G loss: 1.009151]\n",
      "epoch:22 step:20968 [D loss: 0.484489, acc.: 82.03%] [G loss: 1.179863]\n",
      "epoch:22 step:20969 [D loss: 0.644096, acc.: 58.59%] [G loss: 1.069910]\n",
      "epoch:22 step:20970 [D loss: 0.772726, acc.: 46.09%] [G loss: 0.854719]\n",
      "epoch:22 step:20971 [D loss: 0.618456, acc.: 64.84%] [G loss: 0.883993]\n",
      "epoch:22 step:20972 [D loss: 0.522362, acc.: 75.78%] [G loss: 1.011799]\n",
      "epoch:22 step:20973 [D loss: 0.605379, acc.: 69.53%] [G loss: 1.097896]\n",
      "epoch:22 step:20974 [D loss: 0.636834, acc.: 65.62%] [G loss: 1.003241]\n",
      "epoch:22 step:20975 [D loss: 0.634890, acc.: 62.50%] [G loss: 1.043478]\n",
      "epoch:22 step:20976 [D loss: 0.826070, acc.: 38.28%] [G loss: 0.975253]\n",
      "epoch:22 step:20977 [D loss: 0.640266, acc.: 64.06%] [G loss: 1.133715]\n",
      "epoch:22 step:20978 [D loss: 0.734578, acc.: 51.56%] [G loss: 0.962677]\n",
      "epoch:22 step:20979 [D loss: 0.548303, acc.: 69.53%] [G loss: 1.069952]\n",
      "epoch:22 step:20980 [D loss: 0.471659, acc.: 76.56%] [G loss: 1.065637]\n",
      "epoch:22 step:20981 [D loss: 0.309843, acc.: 96.09%] [G loss: 1.357074]\n",
      "epoch:22 step:20982 [D loss: 0.836094, acc.: 39.06%] [G loss: 1.056757]\n",
      "epoch:22 step:20983 [D loss: 0.674324, acc.: 61.72%] [G loss: 1.042507]\n",
      "epoch:22 step:20984 [D loss: 0.528847, acc.: 73.44%] [G loss: 1.112655]\n",
      "epoch:22 step:20985 [D loss: 0.563194, acc.: 76.56%] [G loss: 1.007514]\n",
      "epoch:22 step:20986 [D loss: 0.724012, acc.: 55.47%] [G loss: 0.919974]\n",
      "epoch:22 step:20987 [D loss: 0.684437, acc.: 62.50%] [G loss: 0.948208]\n",
      "epoch:22 step:20988 [D loss: 0.709166, acc.: 52.34%] [G loss: 1.154680]\n",
      "epoch:22 step:20989 [D loss: 0.826114, acc.: 42.19%] [G loss: 0.892659]\n",
      "epoch:22 step:20990 [D loss: 0.720347, acc.: 55.47%] [G loss: 0.918846]\n",
      "epoch:22 step:20991 [D loss: 0.678565, acc.: 62.50%] [G loss: 0.926071]\n",
      "epoch:22 step:20992 [D loss: 0.483655, acc.: 75.78%] [G loss: 0.929489]\n",
      "epoch:22 step:20993 [D loss: 0.733190, acc.: 50.00%] [G loss: 1.289123]\n",
      "epoch:22 step:20994 [D loss: 0.471592, acc.: 82.81%] [G loss: 1.213520]\n",
      "epoch:22 step:20995 [D loss: 0.474568, acc.: 82.03%] [G loss: 1.479120]\n",
      "epoch:22 step:20996 [D loss: 0.818990, acc.: 46.09%] [G loss: 1.181738]\n",
      "epoch:22 step:20997 [D loss: 0.773416, acc.: 44.53%] [G loss: 0.695509]\n",
      "epoch:22 step:20998 [D loss: 0.636272, acc.: 61.72%] [G loss: 1.136318]\n",
      "epoch:22 step:20999 [D loss: 0.596437, acc.: 67.97%] [G loss: 1.012895]\n",
      "epoch:22 step:21000 [D loss: 0.643146, acc.: 62.50%] [G loss: 1.157276]\n",
      "##############\n",
      "[2.47963889 1.44168227 5.510793   4.55115148 3.12929413 5.62908002\n",
      " 4.04192944 4.62317086 4.2828098  3.77817809]\n",
      "##########\n",
      "epoch:22 step:21001 [D loss: 0.601803, acc.: 67.97%] [G loss: 0.996951]\n",
      "epoch:22 step:21002 [D loss: 0.626726, acc.: 64.06%] [G loss: 0.981111]\n",
      "epoch:22 step:21003 [D loss: 0.687858, acc.: 57.81%] [G loss: 1.032886]\n",
      "epoch:22 step:21004 [D loss: 0.519146, acc.: 76.56%] [G loss: 1.177464]\n",
      "epoch:22 step:21005 [D loss: 0.553045, acc.: 78.12%] [G loss: 1.118379]\n",
      "epoch:22 step:21006 [D loss: 0.554785, acc.: 69.53%] [G loss: 1.147398]\n",
      "epoch:22 step:21007 [D loss: 0.622779, acc.: 67.97%] [G loss: 1.273659]\n",
      "epoch:22 step:21008 [D loss: 0.466296, acc.: 81.25%] [G loss: 1.204333]\n",
      "epoch:22 step:21009 [D loss: 0.494491, acc.: 79.69%] [G loss: 1.262052]\n",
      "epoch:22 step:21010 [D loss: 0.540641, acc.: 68.75%] [G loss: 1.121921]\n",
      "epoch:22 step:21011 [D loss: 0.261580, acc.: 92.19%] [G loss: 1.376296]\n",
      "epoch:22 step:21012 [D loss: 0.239870, acc.: 96.88%] [G loss: 1.795282]\n",
      "epoch:22 step:21013 [D loss: 0.349245, acc.: 86.72%] [G loss: 1.178711]\n",
      "epoch:22 step:21014 [D loss: 0.320955, acc.: 95.31%] [G loss: 1.623171]\n",
      "epoch:22 step:21015 [D loss: 0.499047, acc.: 78.12%] [G loss: 1.299323]\n",
      "epoch:22 step:21016 [D loss: 0.420212, acc.: 84.38%] [G loss: 1.468559]\n",
      "epoch:22 step:21017 [D loss: 0.485362, acc.: 84.38%] [G loss: 1.450010]\n",
      "epoch:22 step:21018 [D loss: 0.376396, acc.: 88.28%] [G loss: 1.322978]\n",
      "epoch:22 step:21019 [D loss: 0.263029, acc.: 96.88%] [G loss: 1.328744]\n",
      "epoch:22 step:21020 [D loss: 0.554827, acc.: 69.53%] [G loss: 0.850803]\n",
      "epoch:22 step:21021 [D loss: 0.545752, acc.: 71.88%] [G loss: 1.322945]\n",
      "epoch:22 step:21022 [D loss: 0.630742, acc.: 64.84%] [G loss: 1.397850]\n",
      "epoch:22 step:21023 [D loss: 0.640380, acc.: 66.41%] [G loss: 1.083644]\n",
      "epoch:22 step:21024 [D loss: 0.727951, acc.: 56.25%] [G loss: 0.947986]\n",
      "epoch:22 step:21025 [D loss: 0.998003, acc.: 25.78%] [G loss: 0.728997]\n",
      "epoch:22 step:21026 [D loss: 0.875925, acc.: 43.75%] [G loss: 0.839042]\n",
      "epoch:22 step:21027 [D loss: 1.168538, acc.: 19.53%] [G loss: 0.807024]\n",
      "epoch:22 step:21028 [D loss: 0.664617, acc.: 57.81%] [G loss: 1.079601]\n",
      "epoch:22 step:21029 [D loss: 0.836768, acc.: 48.44%] [G loss: 1.326223]\n",
      "epoch:22 step:21030 [D loss: 0.800286, acc.: 46.88%] [G loss: 0.954716]\n",
      "epoch:22 step:21031 [D loss: 0.995916, acc.: 32.81%] [G loss: 1.284831]\n",
      "epoch:22 step:21032 [D loss: 0.697337, acc.: 60.16%] [G loss: 1.087657]\n",
      "epoch:22 step:21033 [D loss: 0.665285, acc.: 64.06%] [G loss: 1.031128]\n",
      "epoch:22 step:21034 [D loss: 0.684369, acc.: 55.47%] [G loss: 1.468743]\n",
      "epoch:22 step:21035 [D loss: 0.629999, acc.: 68.75%] [G loss: 1.228493]\n",
      "epoch:22 step:21036 [D loss: 0.551746, acc.: 73.44%] [G loss: 1.208389]\n",
      "epoch:22 step:21037 [D loss: 0.667428, acc.: 60.94%] [G loss: 1.439508]\n",
      "epoch:22 step:21038 [D loss: 0.694161, acc.: 60.16%] [G loss: 1.247894]\n",
      "epoch:22 step:21039 [D loss: 0.600000, acc.: 64.84%] [G loss: 0.987260]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21040 [D loss: 0.586154, acc.: 66.41%] [G loss: 1.409458]\n",
      "epoch:22 step:21041 [D loss: 0.721334, acc.: 52.34%] [G loss: 0.942333]\n",
      "epoch:22 step:21042 [D loss: 0.570253, acc.: 69.53%] [G loss: 1.171782]\n",
      "epoch:22 step:21043 [D loss: 0.553910, acc.: 72.66%] [G loss: 1.244198]\n",
      "epoch:22 step:21044 [D loss: 0.596792, acc.: 68.75%] [G loss: 1.144663]\n",
      "epoch:22 step:21045 [D loss: 0.511473, acc.: 78.91%] [G loss: 1.273056]\n",
      "epoch:22 step:21046 [D loss: 0.564424, acc.: 69.53%] [G loss: 1.167252]\n",
      "epoch:22 step:21047 [D loss: 0.472504, acc.: 83.59%] [G loss: 1.374992]\n",
      "epoch:22 step:21048 [D loss: 0.543185, acc.: 70.31%] [G loss: 1.220584]\n",
      "epoch:22 step:21049 [D loss: 0.496462, acc.: 77.34%] [G loss: 1.384438]\n",
      "epoch:22 step:21050 [D loss: 0.363400, acc.: 91.41%] [G loss: 1.372145]\n",
      "epoch:22 step:21051 [D loss: 0.750534, acc.: 57.81%] [G loss: 1.323636]\n",
      "epoch:22 step:21052 [D loss: 0.902329, acc.: 35.16%] [G loss: 0.861109]\n",
      "epoch:22 step:21053 [D loss: 0.744790, acc.: 46.88%] [G loss: 1.142437]\n",
      "epoch:22 step:21054 [D loss: 0.814782, acc.: 50.78%] [G loss: 0.909618]\n",
      "epoch:22 step:21055 [D loss: 0.774203, acc.: 43.75%] [G loss: 1.050959]\n",
      "epoch:22 step:21056 [D loss: 0.758855, acc.: 51.56%] [G loss: 1.102947]\n",
      "epoch:22 step:21057 [D loss: 0.539308, acc.: 71.88%] [G loss: 1.368407]\n",
      "epoch:22 step:21058 [D loss: 0.767186, acc.: 53.12%] [G loss: 1.045708]\n",
      "epoch:22 step:21059 [D loss: 0.747082, acc.: 53.12%] [G loss: 1.036887]\n",
      "epoch:22 step:21060 [D loss: 0.939393, acc.: 35.94%] [G loss: 0.904806]\n",
      "epoch:22 step:21061 [D loss: 0.685485, acc.: 56.25%] [G loss: 0.884887]\n",
      "epoch:22 step:21062 [D loss: 0.589877, acc.: 65.62%] [G loss: 1.067578]\n",
      "epoch:22 step:21063 [D loss: 0.542905, acc.: 75.78%] [G loss: 1.109253]\n",
      "epoch:22 step:21064 [D loss: 0.715707, acc.: 53.12%] [G loss: 1.238906]\n",
      "epoch:22 step:21065 [D loss: 0.491719, acc.: 78.91%] [G loss: 1.170426]\n",
      "epoch:22 step:21066 [D loss: 0.586611, acc.: 68.75%] [G loss: 1.053448]\n",
      "epoch:22 step:21067 [D loss: 0.482854, acc.: 77.34%] [G loss: 1.385654]\n",
      "epoch:22 step:21068 [D loss: 0.493937, acc.: 80.47%] [G loss: 1.214015]\n",
      "epoch:22 step:21069 [D loss: 0.628351, acc.: 62.50%] [G loss: 1.135582]\n",
      "epoch:22 step:21070 [D loss: 0.633123, acc.: 62.50%] [G loss: 1.230059]\n",
      "epoch:22 step:21071 [D loss: 0.419143, acc.: 85.16%] [G loss: 1.422683]\n",
      "epoch:22 step:21072 [D loss: 0.950561, acc.: 39.06%] [G loss: 1.150841]\n",
      "epoch:22 step:21073 [D loss: 0.749679, acc.: 50.00%] [G loss: 1.248028]\n",
      "epoch:22 step:21074 [D loss: 0.881634, acc.: 43.75%] [G loss: 0.912989]\n",
      "epoch:22 step:21075 [D loss: 0.857951, acc.: 36.72%] [G loss: 1.202130]\n",
      "epoch:22 step:21076 [D loss: 0.506044, acc.: 81.25%] [G loss: 1.691189]\n",
      "epoch:22 step:21077 [D loss: 0.594185, acc.: 67.97%] [G loss: 1.258158]\n",
      "epoch:22 step:21078 [D loss: 0.679791, acc.: 61.72%] [G loss: 1.105072]\n",
      "epoch:22 step:21079 [D loss: 0.667378, acc.: 55.47%] [G loss: 1.074040]\n",
      "epoch:22 step:21080 [D loss: 0.640843, acc.: 64.06%] [G loss: 0.957955]\n",
      "epoch:22 step:21081 [D loss: 0.641329, acc.: 67.97%] [G loss: 1.134394]\n",
      "epoch:22 step:21082 [D loss: 0.646122, acc.: 64.06%] [G loss: 1.132968]\n",
      "epoch:22 step:21083 [D loss: 0.631538, acc.: 60.94%] [G loss: 1.032187]\n",
      "epoch:22 step:21084 [D loss: 0.562728, acc.: 69.53%] [G loss: 1.166081]\n",
      "epoch:22 step:21085 [D loss: 0.281654, acc.: 95.31%] [G loss: 1.348688]\n",
      "epoch:22 step:21086 [D loss: 0.530245, acc.: 74.22%] [G loss: 1.228083]\n",
      "epoch:22 step:21087 [D loss: 0.550404, acc.: 72.66%] [G loss: 1.163676]\n",
      "epoch:22 step:21088 [D loss: 0.361353, acc.: 93.75%] [G loss: 1.353443]\n",
      "epoch:22 step:21089 [D loss: 0.350657, acc.: 93.75%] [G loss: 1.451126]\n",
      "epoch:22 step:21090 [D loss: 0.645836, acc.: 60.16%] [G loss: 1.350832]\n",
      "epoch:22 step:21091 [D loss: 0.682213, acc.: 61.72%] [G loss: 1.332292]\n",
      "epoch:22 step:21092 [D loss: 0.916225, acc.: 33.59%] [G loss: 0.812774]\n",
      "epoch:22 step:21093 [D loss: 0.576905, acc.: 69.53%] [G loss: 1.067208]\n",
      "epoch:22 step:21094 [D loss: 0.734700, acc.: 51.56%] [G loss: 0.924850]\n",
      "epoch:22 step:21095 [D loss: 0.465381, acc.: 84.38%] [G loss: 1.070685]\n",
      "epoch:22 step:21096 [D loss: 0.643666, acc.: 64.06%] [G loss: 1.208985]\n",
      "epoch:22 step:21097 [D loss: 0.600615, acc.: 71.09%] [G loss: 1.107964]\n",
      "epoch:22 step:21098 [D loss: 0.471571, acc.: 85.16%] [G loss: 1.407084]\n",
      "epoch:22 step:21099 [D loss: 0.594089, acc.: 69.53%] [G loss: 1.267417]\n",
      "epoch:22 step:21100 [D loss: 0.537387, acc.: 74.22%] [G loss: 1.201257]\n",
      "epoch:22 step:21101 [D loss: 0.590039, acc.: 67.97%] [G loss: 1.034243]\n",
      "epoch:22 step:21102 [D loss: 0.580708, acc.: 70.31%] [G loss: 1.494088]\n",
      "epoch:22 step:21103 [D loss: 0.668317, acc.: 55.47%] [G loss: 1.124535]\n",
      "epoch:22 step:21104 [D loss: 0.558272, acc.: 74.22%] [G loss: 1.123516]\n",
      "epoch:22 step:21105 [D loss: 0.638553, acc.: 63.28%] [G loss: 1.294349]\n",
      "epoch:22 step:21106 [D loss: 0.622624, acc.: 62.50%] [G loss: 1.223523]\n",
      "epoch:22 step:21107 [D loss: 0.717489, acc.: 55.47%] [G loss: 1.050645]\n",
      "epoch:22 step:21108 [D loss: 0.464324, acc.: 82.03%] [G loss: 1.060533]\n",
      "epoch:22 step:21109 [D loss: 0.540486, acc.: 69.53%] [G loss: 0.865588]\n",
      "epoch:22 step:21110 [D loss: 0.635174, acc.: 64.06%] [G loss: 1.186192]\n",
      "epoch:22 step:21111 [D loss: 0.573881, acc.: 73.44%] [G loss: 1.124889]\n",
      "epoch:22 step:21112 [D loss: 0.515261, acc.: 75.78%] [G loss: 1.369862]\n",
      "epoch:22 step:21113 [D loss: 0.388280, acc.: 86.72%] [G loss: 1.357358]\n",
      "epoch:22 step:21114 [D loss: 0.687922, acc.: 58.59%] [G loss: 1.322442]\n",
      "epoch:22 step:21115 [D loss: 0.803923, acc.: 43.75%] [G loss: 1.161792]\n",
      "epoch:22 step:21116 [D loss: 0.613009, acc.: 64.84%] [G loss: 1.139180]\n",
      "epoch:22 step:21117 [D loss: 0.333005, acc.: 86.72%] [G loss: 0.964243]\n",
      "epoch:22 step:21118 [D loss: 0.222931, acc.: 96.09%] [G loss: 1.774927]\n",
      "epoch:22 step:21119 [D loss: 0.439559, acc.: 89.06%] [G loss: 1.345847]\n",
      "epoch:22 step:21120 [D loss: 0.461032, acc.: 82.03%] [G loss: 1.305545]\n",
      "epoch:22 step:21121 [D loss: 0.428220, acc.: 85.94%] [G loss: 1.114697]\n",
      "epoch:22 step:21122 [D loss: 0.381773, acc.: 89.84%] [G loss: 1.220866]\n",
      "epoch:22 step:21123 [D loss: 0.802702, acc.: 53.91%] [G loss: 1.178535]\n",
      "epoch:22 step:21124 [D loss: 0.726463, acc.: 52.34%] [G loss: 1.059840]\n",
      "epoch:22 step:21125 [D loss: 0.532099, acc.: 71.88%] [G loss: 1.113645]\n",
      "epoch:22 step:21126 [D loss: 0.626722, acc.: 64.06%] [G loss: 1.245403]\n",
      "epoch:22 step:21127 [D loss: 0.322441, acc.: 94.53%] [G loss: 1.177267]\n",
      "epoch:22 step:21128 [D loss: 0.559365, acc.: 73.44%] [G loss: 1.194846]\n",
      "epoch:22 step:21129 [D loss: 0.430466, acc.: 87.50%] [G loss: 1.268509]\n",
      "epoch:22 step:21130 [D loss: 0.560087, acc.: 71.09%] [G loss: 1.202770]\n",
      "epoch:22 step:21131 [D loss: 0.646919, acc.: 61.72%] [G loss: 1.143395]\n",
      "epoch:22 step:21132 [D loss: 0.570626, acc.: 71.09%] [G loss: 1.051260]\n",
      "epoch:22 step:21133 [D loss: 0.501570, acc.: 80.47%] [G loss: 0.987373]\n",
      "epoch:22 step:21134 [D loss: 0.592522, acc.: 66.41%] [G loss: 1.085780]\n",
      "epoch:22 step:21135 [D loss: 0.694397, acc.: 57.03%] [G loss: 0.884762]\n",
      "epoch:22 step:21136 [D loss: 0.659930, acc.: 61.72%] [G loss: 0.970772]\n",
      "epoch:22 step:21137 [D loss: 0.434749, acc.: 87.50%] [G loss: 1.260738]\n",
      "epoch:22 step:21138 [D loss: 0.523137, acc.: 76.56%] [G loss: 1.468657]\n",
      "epoch:22 step:21139 [D loss: 0.727422, acc.: 54.69%] [G loss: 1.178017]\n",
      "epoch:22 step:21140 [D loss: 0.531984, acc.: 74.22%] [G loss: 1.198344]\n",
      "epoch:22 step:21141 [D loss: 0.568933, acc.: 67.97%] [G loss: 1.323964]\n",
      "epoch:22 step:21142 [D loss: 0.737268, acc.: 57.81%] [G loss: 1.082513]\n",
      "epoch:22 step:21143 [D loss: 0.611405, acc.: 66.41%] [G loss: 0.938118]\n",
      "epoch:22 step:21144 [D loss: 0.455639, acc.: 80.47%] [G loss: 1.040093]\n",
      "epoch:22 step:21145 [D loss: 0.743761, acc.: 49.22%] [G loss: 0.788112]\n",
      "epoch:22 step:21146 [D loss: 0.623790, acc.: 69.53%] [G loss: 1.167214]\n",
      "epoch:22 step:21147 [D loss: 0.443057, acc.: 87.50%] [G loss: 1.185980]\n",
      "epoch:22 step:21148 [D loss: 0.562308, acc.: 75.00%] [G loss: 1.221068]\n",
      "epoch:22 step:21149 [D loss: 0.469495, acc.: 83.59%] [G loss: 1.293277]\n",
      "epoch:22 step:21150 [D loss: 0.424026, acc.: 87.50%] [G loss: 1.184243]\n",
      "epoch:22 step:21151 [D loss: 0.448901, acc.: 82.03%] [G loss: 1.315603]\n",
      "epoch:22 step:21152 [D loss: 0.592786, acc.: 71.09%] [G loss: 1.001485]\n",
      "epoch:22 step:21153 [D loss: 0.544019, acc.: 75.00%] [G loss: 1.201060]\n",
      "epoch:22 step:21154 [D loss: 0.608059, acc.: 67.19%] [G loss: 1.074406]\n",
      "epoch:22 step:21155 [D loss: 0.743069, acc.: 49.22%] [G loss: 0.920227]\n",
      "epoch:22 step:21156 [D loss: 0.930156, acc.: 36.72%] [G loss: 0.816968]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21157 [D loss: 0.827254, acc.: 42.19%] [G loss: 1.056671]\n",
      "epoch:22 step:21158 [D loss: 0.571007, acc.: 71.09%] [G loss: 1.176119]\n",
      "epoch:22 step:21159 [D loss: 0.384208, acc.: 94.53%] [G loss: 1.147870]\n",
      "epoch:22 step:21160 [D loss: 0.363024, acc.: 92.19%] [G loss: 1.382336]\n",
      "epoch:22 step:21161 [D loss: 0.331150, acc.: 96.09%] [G loss: 1.682621]\n",
      "epoch:22 step:21162 [D loss: 0.441098, acc.: 85.94%] [G loss: 1.139619]\n",
      "epoch:22 step:21163 [D loss: 0.259955, acc.: 96.88%] [G loss: 1.483519]\n",
      "epoch:22 step:21164 [D loss: 0.374688, acc.: 89.84%] [G loss: 1.770442]\n",
      "epoch:22 step:21165 [D loss: 0.254125, acc.: 97.66%] [G loss: 1.421308]\n",
      "epoch:22 step:21166 [D loss: 0.366179, acc.: 89.84%] [G loss: 1.685661]\n",
      "epoch:22 step:21167 [D loss: 0.347235, acc.: 89.84%] [G loss: 1.562066]\n",
      "epoch:22 step:21168 [D loss: 0.365646, acc.: 88.28%] [G loss: 1.243986]\n",
      "epoch:22 step:21169 [D loss: 0.379930, acc.: 89.06%] [G loss: 1.112881]\n",
      "epoch:22 step:21170 [D loss: 0.376170, acc.: 85.16%] [G loss: 1.571776]\n",
      "epoch:22 step:21171 [D loss: 0.369544, acc.: 92.97%] [G loss: 1.708431]\n",
      "epoch:22 step:21172 [D loss: 0.513632, acc.: 79.69%] [G loss: 1.471805]\n",
      "epoch:22 step:21173 [D loss: 0.788490, acc.: 53.91%] [G loss: 1.657755]\n",
      "epoch:22 step:21174 [D loss: 1.207546, acc.: 25.78%] [G loss: 1.070537]\n",
      "epoch:22 step:21175 [D loss: 0.566942, acc.: 71.09%] [G loss: 1.234947]\n",
      "epoch:22 step:21176 [D loss: 0.757698, acc.: 56.25%] [G loss: 1.185216]\n",
      "epoch:22 step:21177 [D loss: 0.572080, acc.: 67.19%] [G loss: 1.224813]\n",
      "epoch:22 step:21178 [D loss: 0.547683, acc.: 68.75%] [G loss: 1.263011]\n",
      "epoch:22 step:21179 [D loss: 0.641508, acc.: 62.50%] [G loss: 1.221737]\n",
      "epoch:22 step:21180 [D loss: 0.338931, acc.: 91.41%] [G loss: 1.301082]\n",
      "epoch:22 step:21181 [D loss: 0.365594, acc.: 90.62%] [G loss: 1.394845]\n",
      "epoch:22 step:21182 [D loss: 0.711962, acc.: 52.34%] [G loss: 1.253367]\n",
      "epoch:22 step:21183 [D loss: 0.577143, acc.: 72.66%] [G loss: 1.255595]\n",
      "epoch:22 step:21184 [D loss: 0.597472, acc.: 64.06%] [G loss: 0.864416]\n",
      "epoch:22 step:21185 [D loss: 0.623431, acc.: 64.06%] [G loss: 0.878084]\n",
      "epoch:22 step:21186 [D loss: 0.733839, acc.: 58.59%] [G loss: 1.118231]\n",
      "epoch:22 step:21187 [D loss: 0.477046, acc.: 78.91%] [G loss: 1.425095]\n",
      "epoch:22 step:21188 [D loss: 0.416042, acc.: 86.72%] [G loss: 1.538387]\n",
      "epoch:22 step:21189 [D loss: 0.421113, acc.: 82.81%] [G loss: 1.430007]\n",
      "epoch:22 step:21190 [D loss: 0.614902, acc.: 59.38%] [G loss: 0.670971]\n",
      "epoch:22 step:21191 [D loss: 0.578035, acc.: 68.75%] [G loss: 1.189468]\n",
      "epoch:22 step:21192 [D loss: 0.402120, acc.: 89.06%] [G loss: 1.370629]\n",
      "epoch:22 step:21193 [D loss: 0.631669, acc.: 68.75%] [G loss: 0.963882]\n",
      "epoch:22 step:21194 [D loss: 0.686541, acc.: 53.12%] [G loss: 1.213274]\n",
      "epoch:22 step:21195 [D loss: 0.551575, acc.: 71.88%] [G loss: 0.829100]\n",
      "epoch:22 step:21196 [D loss: 0.805427, acc.: 42.19%] [G loss: 0.658440]\n",
      "epoch:22 step:21197 [D loss: 0.777906, acc.: 46.88%] [G loss: 0.978626]\n",
      "epoch:22 step:21198 [D loss: 0.948233, acc.: 28.12%] [G loss: 0.829312]\n",
      "epoch:22 step:21199 [D loss: 0.721719, acc.: 53.12%] [G loss: 0.888806]\n",
      "epoch:22 step:21200 [D loss: 0.865185, acc.: 36.72%] [G loss: 0.809820]\n",
      "##############\n",
      "[2.33842427 1.13127965 5.69765458 4.18841311 2.91234598 4.99016825\n",
      " 3.88393974 4.01750715 3.92659197 3.77374393]\n",
      "##########\n",
      "epoch:22 step:21201 [D loss: 0.345943, acc.: 92.19%] [G loss: 1.514038]\n",
      "epoch:22 step:21202 [D loss: 0.338489, acc.: 92.97%] [G loss: 1.878863]\n",
      "epoch:22 step:21203 [D loss: 0.351473, acc.: 93.75%] [G loss: 1.752091]\n",
      "epoch:22 step:21204 [D loss: 0.961252, acc.: 29.69%] [G loss: 1.048618]\n",
      "epoch:22 step:21205 [D loss: 0.866204, acc.: 40.62%] [G loss: 1.310336]\n",
      "epoch:22 step:21206 [D loss: 0.630453, acc.: 62.50%] [G loss: 1.273434]\n",
      "epoch:22 step:21207 [D loss: 0.795861, acc.: 46.09%] [G loss: 1.093029]\n",
      "epoch:22 step:21208 [D loss: 0.573342, acc.: 71.09%] [G loss: 1.044213]\n",
      "epoch:22 step:21209 [D loss: 0.631448, acc.: 65.62%] [G loss: 1.179064]\n",
      "epoch:22 step:21210 [D loss: 0.637319, acc.: 69.53%] [G loss: 1.254204]\n",
      "epoch:22 step:21211 [D loss: 0.478398, acc.: 86.72%] [G loss: 1.025090]\n",
      "epoch:22 step:21212 [D loss: 0.286512, acc.: 96.09%] [G loss: 1.229645]\n",
      "epoch:22 step:21213 [D loss: 0.637192, acc.: 64.06%] [G loss: 1.183568]\n",
      "epoch:22 step:21214 [D loss: 0.667136, acc.: 56.25%] [G loss: 1.172055]\n",
      "epoch:22 step:21215 [D loss: 0.462340, acc.: 81.25%] [G loss: 1.241910]\n",
      "epoch:22 step:21216 [D loss: 0.614294, acc.: 69.53%] [G loss: 0.908763]\n",
      "epoch:22 step:21217 [D loss: 0.304563, acc.: 92.19%] [G loss: 1.572548]\n",
      "epoch:22 step:21218 [D loss: 0.303997, acc.: 90.62%] [G loss: 1.694889]\n",
      "epoch:22 step:21219 [D loss: 0.263408, acc.: 96.09%] [G loss: 1.733596]\n",
      "epoch:22 step:21220 [D loss: 0.547361, acc.: 73.44%] [G loss: 1.253032]\n",
      "epoch:22 step:21221 [D loss: 0.619882, acc.: 63.28%] [G loss: 1.254375]\n",
      "epoch:22 step:21222 [D loss: 0.444336, acc.: 84.38%] [G loss: 1.422861]\n",
      "epoch:22 step:21223 [D loss: 0.553407, acc.: 73.44%] [G loss: 1.279692]\n",
      "epoch:22 step:21224 [D loss: 0.584545, acc.: 66.41%] [G loss: 0.919779]\n",
      "epoch:22 step:21225 [D loss: 0.750514, acc.: 55.47%] [G loss: 0.868571]\n",
      "epoch:22 step:21226 [D loss: 0.694252, acc.: 59.38%] [G loss: 0.825585]\n",
      "epoch:22 step:21227 [D loss: 0.434425, acc.: 79.69%] [G loss: 1.070933]\n",
      "epoch:22 step:21228 [D loss: 0.297185, acc.: 94.53%] [G loss: 1.630089]\n",
      "epoch:22 step:21229 [D loss: 0.298685, acc.: 90.62%] [G loss: 1.155350]\n",
      "epoch:22 step:21230 [D loss: 0.389150, acc.: 82.03%] [G loss: 1.081770]\n",
      "epoch:22 step:21231 [D loss: 0.666455, acc.: 64.84%] [G loss: 0.958457]\n",
      "epoch:22 step:21232 [D loss: 1.138004, acc.: 21.09%] [G loss: 0.884575]\n",
      "epoch:22 step:21233 [D loss: 1.047022, acc.: 24.22%] [G loss: 0.927038]\n",
      "epoch:22 step:21234 [D loss: 0.887172, acc.: 36.72%] [G loss: 0.953141]\n",
      "epoch:22 step:21235 [D loss: 0.841455, acc.: 37.50%] [G loss: 1.158833]\n",
      "epoch:22 step:21236 [D loss: 0.607311, acc.: 67.97%] [G loss: 1.031250]\n",
      "epoch:22 step:21237 [D loss: 0.646394, acc.: 60.94%] [G loss: 1.242725]\n",
      "epoch:22 step:21238 [D loss: 0.558926, acc.: 74.22%] [G loss: 1.138015]\n",
      "epoch:22 step:21239 [D loss: 0.723100, acc.: 50.78%] [G loss: 1.186257]\n",
      "epoch:22 step:21240 [D loss: 0.691507, acc.: 54.69%] [G loss: 1.074546]\n",
      "epoch:22 step:21241 [D loss: 0.680413, acc.: 52.34%] [G loss: 0.832470]\n",
      "epoch:22 step:21242 [D loss: 0.617236, acc.: 64.84%] [G loss: 1.180324]\n",
      "epoch:22 step:21243 [D loss: 0.554610, acc.: 74.22%] [G loss: 0.828178]\n",
      "epoch:22 step:21244 [D loss: 0.500889, acc.: 78.12%] [G loss: 1.366633]\n",
      "epoch:22 step:21245 [D loss: 0.587642, acc.: 73.44%] [G loss: 0.938176]\n",
      "epoch:22 step:21246 [D loss: 0.650593, acc.: 60.94%] [G loss: 1.072811]\n",
      "epoch:22 step:21247 [D loss: 0.623174, acc.: 67.19%] [G loss: 0.997981]\n",
      "epoch:22 step:21248 [D loss: 0.572844, acc.: 70.31%] [G loss: 1.468755]\n",
      "epoch:22 step:21249 [D loss: 0.713821, acc.: 51.56%] [G loss: 1.186257]\n",
      "epoch:22 step:21250 [D loss: 0.638932, acc.: 63.28%] [G loss: 1.216223]\n",
      "epoch:22 step:21251 [D loss: 0.757599, acc.: 48.44%] [G loss: 1.073118]\n",
      "epoch:22 step:21252 [D loss: 0.655329, acc.: 66.41%] [G loss: 1.054164]\n",
      "epoch:22 step:21253 [D loss: 0.570213, acc.: 72.66%] [G loss: 1.006687]\n",
      "epoch:22 step:21254 [D loss: 0.402743, acc.: 82.03%] [G loss: 0.994113]\n",
      "epoch:22 step:21255 [D loss: 0.308639, acc.: 95.31%] [G loss: 1.368319]\n",
      "epoch:22 step:21256 [D loss: 0.370591, acc.: 90.62%] [G loss: 1.416642]\n",
      "epoch:22 step:21257 [D loss: 0.704753, acc.: 57.81%] [G loss: 1.428834]\n",
      "epoch:22 step:21258 [D loss: 0.736603, acc.: 53.12%] [G loss: 0.969403]\n",
      "epoch:22 step:21259 [D loss: 0.644422, acc.: 60.16%] [G loss: 0.921690]\n",
      "epoch:22 step:21260 [D loss: 0.611703, acc.: 67.19%] [G loss: 1.117947]\n",
      "epoch:22 step:21261 [D loss: 0.434105, acc.: 85.94%] [G loss: 1.202995]\n",
      "epoch:22 step:21262 [D loss: 0.504492, acc.: 78.91%] [G loss: 1.189756]\n",
      "epoch:22 step:21263 [D loss: 0.579103, acc.: 67.97%] [G loss: 1.217078]\n",
      "epoch:22 step:21264 [D loss: 0.390443, acc.: 94.53%] [G loss: 1.415952]\n",
      "epoch:22 step:21265 [D loss: 0.672318, acc.: 56.25%] [G loss: 0.848488]\n",
      "epoch:22 step:21266 [D loss: 0.641553, acc.: 64.06%] [G loss: 1.192295]\n",
      "epoch:22 step:21267 [D loss: 0.556864, acc.: 74.22%] [G loss: 1.031325]\n",
      "epoch:22 step:21268 [D loss: 0.694466, acc.: 55.47%] [G loss: 1.077886]\n",
      "epoch:22 step:21269 [D loss: 0.786823, acc.: 47.66%] [G loss: 1.080546]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21270 [D loss: 0.713713, acc.: 48.44%] [G loss: 1.053792]\n",
      "epoch:22 step:21271 [D loss: 0.645312, acc.: 61.72%] [G loss: 1.089008]\n",
      "epoch:22 step:21272 [D loss: 0.615521, acc.: 68.75%] [G loss: 1.124054]\n",
      "epoch:22 step:21273 [D loss: 0.630216, acc.: 57.81%] [G loss: 1.136990]\n",
      "epoch:22 step:21274 [D loss: 0.550048, acc.: 73.44%] [G loss: 1.085118]\n",
      "epoch:22 step:21275 [D loss: 0.586861, acc.: 66.41%] [G loss: 1.137646]\n",
      "epoch:22 step:21276 [D loss: 0.506710, acc.: 77.34%] [G loss: 1.127078]\n",
      "epoch:22 step:21277 [D loss: 0.305858, acc.: 89.06%] [G loss: 1.190130]\n",
      "epoch:22 step:21278 [D loss: 0.335254, acc.: 89.06%] [G loss: 1.442049]\n",
      "epoch:22 step:21279 [D loss: 0.250872, acc.: 96.09%] [G loss: 1.833430]\n",
      "epoch:22 step:21280 [D loss: 0.472590, acc.: 75.78%] [G loss: 1.532684]\n",
      "epoch:22 step:21281 [D loss: 0.561050, acc.: 71.88%] [G loss: 0.902721]\n",
      "epoch:22 step:21282 [D loss: 0.680324, acc.: 61.72%] [G loss: 1.144110]\n",
      "epoch:22 step:21283 [D loss: 0.613235, acc.: 69.53%] [G loss: 1.055276]\n",
      "epoch:22 step:21284 [D loss: 0.813467, acc.: 45.31%] [G loss: 0.942486]\n",
      "epoch:22 step:21285 [D loss: 0.584901, acc.: 64.84%] [G loss: 1.017803]\n",
      "epoch:22 step:21286 [D loss: 0.780450, acc.: 42.97%] [G loss: 0.872559]\n",
      "epoch:22 step:21287 [D loss: 0.881949, acc.: 35.16%] [G loss: 0.879207]\n",
      "epoch:22 step:21288 [D loss: 0.855129, acc.: 46.88%] [G loss: 0.662560]\n",
      "epoch:22 step:21289 [D loss: 0.626256, acc.: 65.62%] [G loss: 1.167886]\n",
      "epoch:22 step:21290 [D loss: 0.756737, acc.: 53.91%] [G loss: 1.232522]\n",
      "epoch:22 step:21291 [D loss: 0.668839, acc.: 60.94%] [G loss: 0.942536]\n",
      "epoch:22 step:21292 [D loss: 0.743601, acc.: 53.12%] [G loss: 1.048178]\n",
      "epoch:22 step:21293 [D loss: 0.918286, acc.: 30.47%] [G loss: 0.811900]\n",
      "epoch:22 step:21294 [D loss: 0.684849, acc.: 56.25%] [G loss: 1.060730]\n",
      "epoch:22 step:21295 [D loss: 0.718202, acc.: 48.44%] [G loss: 0.939622]\n",
      "epoch:22 step:21296 [D loss: 0.805290, acc.: 47.66%] [G loss: 0.824119]\n",
      "epoch:22 step:21297 [D loss: 0.673979, acc.: 55.47%] [G loss: 0.874136]\n",
      "epoch:22 step:21298 [D loss: 0.627700, acc.: 67.97%] [G loss: 1.133330]\n",
      "epoch:22 step:21299 [D loss: 0.483274, acc.: 81.25%] [G loss: 1.207784]\n",
      "epoch:22 step:21300 [D loss: 0.626683, acc.: 61.72%] [G loss: 1.335040]\n",
      "epoch:22 step:21301 [D loss: 0.618909, acc.: 64.84%] [G loss: 1.030213]\n",
      "epoch:22 step:21302 [D loss: 0.619079, acc.: 70.31%] [G loss: 1.136610]\n",
      "epoch:22 step:21303 [D loss: 0.416851, acc.: 85.94%] [G loss: 1.412570]\n",
      "epoch:22 step:21304 [D loss: 0.319008, acc.: 93.75%] [G loss: 1.496340]\n",
      "epoch:22 step:21305 [D loss: 0.356431, acc.: 93.75%] [G loss: 1.642546]\n",
      "epoch:22 step:21306 [D loss: 0.410115, acc.: 86.72%] [G loss: 1.658779]\n",
      "epoch:22 step:21307 [D loss: 0.319998, acc.: 95.31%] [G loss: 1.583341]\n",
      "epoch:22 step:21308 [D loss: 0.288676, acc.: 94.53%] [G loss: 1.640101]\n",
      "epoch:22 step:21309 [D loss: 0.445991, acc.: 82.03%] [G loss: 1.138834]\n",
      "epoch:22 step:21310 [D loss: 0.748583, acc.: 53.12%] [G loss: 1.296176]\n",
      "epoch:22 step:21311 [D loss: 1.069366, acc.: 21.88%] [G loss: 0.677625]\n",
      "epoch:22 step:21312 [D loss: 0.724935, acc.: 54.69%] [G loss: 0.902816]\n",
      "epoch:22 step:21313 [D loss: 0.927906, acc.: 35.16%] [G loss: 1.002041]\n",
      "epoch:22 step:21314 [D loss: 0.645767, acc.: 64.84%] [G loss: 0.969431]\n",
      "epoch:22 step:21315 [D loss: 0.663727, acc.: 60.94%] [G loss: 1.165304]\n",
      "epoch:22 step:21316 [D loss: 0.687212, acc.: 53.91%] [G loss: 0.926968]\n",
      "epoch:22 step:21317 [D loss: 0.690764, acc.: 59.38%] [G loss: 1.163026]\n",
      "epoch:22 step:21318 [D loss: 0.703573, acc.: 57.81%] [G loss: 0.818871]\n",
      "epoch:22 step:21319 [D loss: 0.661144, acc.: 65.62%] [G loss: 0.721292]\n",
      "epoch:22 step:21320 [D loss: 0.501131, acc.: 77.34%] [G loss: 1.120448]\n",
      "epoch:22 step:21321 [D loss: 0.406781, acc.: 87.50%] [G loss: 1.190591]\n",
      "epoch:22 step:21322 [D loss: 0.418887, acc.: 87.50%] [G loss: 1.428000]\n",
      "epoch:22 step:21323 [D loss: 0.368664, acc.: 90.62%] [G loss: 1.576572]\n",
      "epoch:22 step:21324 [D loss: 0.745480, acc.: 52.34%] [G loss: 1.332774]\n",
      "epoch:22 step:21325 [D loss: 0.621594, acc.: 63.28%] [G loss: 1.179554]\n",
      "epoch:22 step:21326 [D loss: 0.668199, acc.: 57.03%] [G loss: 1.006720]\n",
      "epoch:22 step:21327 [D loss: 0.514010, acc.: 72.66%] [G loss: 0.971764]\n",
      "epoch:22 step:21328 [D loss: 0.488366, acc.: 78.12%] [G loss: 1.122253]\n",
      "epoch:22 step:21329 [D loss: 0.597395, acc.: 70.31%] [G loss: 1.242125]\n",
      "epoch:22 step:21330 [D loss: 0.760215, acc.: 53.12%] [G loss: 0.917979]\n",
      "epoch:22 step:21331 [D loss: 0.605410, acc.: 69.53%] [G loss: 0.918958]\n",
      "epoch:22 step:21332 [D loss: 0.785075, acc.: 47.66%] [G loss: 0.897031]\n",
      "epoch:22 step:21333 [D loss: 0.662656, acc.: 58.59%] [G loss: 0.972659]\n",
      "epoch:22 step:21334 [D loss: 0.467032, acc.: 86.72%] [G loss: 1.107313]\n",
      "epoch:22 step:21335 [D loss: 0.558513, acc.: 73.44%] [G loss: 1.071801]\n",
      "epoch:22 step:21336 [D loss: 0.692565, acc.: 55.47%] [G loss: 1.118015]\n",
      "epoch:22 step:21337 [D loss: 0.745539, acc.: 55.47%] [G loss: 0.981019]\n",
      "epoch:22 step:21338 [D loss: 0.401279, acc.: 87.50%] [G loss: 1.275298]\n",
      "epoch:22 step:21339 [D loss: 0.341193, acc.: 95.31%] [G loss: 1.541801]\n",
      "epoch:22 step:21340 [D loss: 0.559184, acc.: 72.66%] [G loss: 1.201865]\n",
      "epoch:22 step:21341 [D loss: 0.580533, acc.: 71.09%] [G loss: 1.244797]\n",
      "epoch:22 step:21342 [D loss: 0.463527, acc.: 79.69%] [G loss: 1.108411]\n",
      "epoch:22 step:21343 [D loss: 0.505707, acc.: 78.12%] [G loss: 1.251803]\n",
      "epoch:22 step:21344 [D loss: 0.569847, acc.: 70.31%] [G loss: 1.058406]\n",
      "epoch:22 step:21345 [D loss: 0.468021, acc.: 82.03%] [G loss: 1.355449]\n",
      "epoch:22 step:21346 [D loss: 0.328718, acc.: 94.53%] [G loss: 1.475315]\n",
      "epoch:22 step:21347 [D loss: 0.388269, acc.: 88.28%] [G loss: 1.530387]\n",
      "epoch:22 step:21348 [D loss: 0.705380, acc.: 59.38%] [G loss: 1.431150]\n",
      "epoch:22 step:21349 [D loss: 0.730856, acc.: 53.91%] [G loss: 0.937127]\n",
      "epoch:22 step:21350 [D loss: 0.651824, acc.: 60.16%] [G loss: 0.765931]\n",
      "epoch:22 step:21351 [D loss: 0.514126, acc.: 76.56%] [G loss: 1.247439]\n",
      "epoch:22 step:21352 [D loss: 0.549323, acc.: 72.66%] [G loss: 0.887239]\n",
      "epoch:22 step:21353 [D loss: 0.605053, acc.: 67.97%] [G loss: 0.951946]\n",
      "epoch:22 step:21354 [D loss: 0.457971, acc.: 83.59%] [G loss: 1.040442]\n",
      "epoch:22 step:21355 [D loss: 0.976107, acc.: 30.47%] [G loss: 0.750953]\n",
      "epoch:22 step:21356 [D loss: 0.711942, acc.: 57.81%] [G loss: 0.995194]\n",
      "epoch:22 step:21357 [D loss: 0.584540, acc.: 66.41%] [G loss: 1.361742]\n",
      "epoch:22 step:21358 [D loss: 0.679902, acc.: 62.50%] [G loss: 1.077494]\n",
      "epoch:22 step:21359 [D loss: 0.398106, acc.: 86.72%] [G loss: 1.313812]\n",
      "epoch:22 step:21360 [D loss: 0.494089, acc.: 82.81%] [G loss: 1.279800]\n",
      "epoch:22 step:21361 [D loss: 0.461802, acc.: 82.81%] [G loss: 1.188672]\n",
      "epoch:22 step:21362 [D loss: 0.807343, acc.: 49.22%] [G loss: 1.154906]\n",
      "epoch:22 step:21363 [D loss: 0.663163, acc.: 61.72%] [G loss: 0.919814]\n",
      "epoch:22 step:21364 [D loss: 0.746459, acc.: 51.56%] [G loss: 0.746945]\n",
      "epoch:22 step:21365 [D loss: 0.455661, acc.: 82.03%] [G loss: 1.211747]\n",
      "epoch:22 step:21366 [D loss: 0.828719, acc.: 42.97%] [G loss: 1.177098]\n",
      "epoch:22 step:21367 [D loss: 0.641767, acc.: 60.16%] [G loss: 0.925684]\n",
      "epoch:22 step:21368 [D loss: 0.616519, acc.: 65.62%] [G loss: 1.081113]\n",
      "epoch:22 step:21369 [D loss: 0.417361, acc.: 85.16%] [G loss: 1.175537]\n",
      "epoch:22 step:21370 [D loss: 0.368508, acc.: 92.19%] [G loss: 1.217558]\n",
      "epoch:22 step:21371 [D loss: 0.478232, acc.: 85.94%] [G loss: 1.449886]\n",
      "epoch:22 step:21372 [D loss: 0.580337, acc.: 66.41%] [G loss: 1.225939]\n",
      "epoch:22 step:21373 [D loss: 0.725572, acc.: 54.69%] [G loss: 1.015164]\n",
      "epoch:22 step:21374 [D loss: 0.861421, acc.: 37.50%] [G loss: 0.833923]\n",
      "epoch:22 step:21375 [D loss: 0.727330, acc.: 50.78%] [G loss: 0.925893]\n",
      "epoch:22 step:21376 [D loss: 0.570597, acc.: 71.09%] [G loss: 1.202662]\n",
      "epoch:22 step:21377 [D loss: 0.839823, acc.: 53.12%] [G loss: 0.794005]\n",
      "epoch:22 step:21378 [D loss: 0.578835, acc.: 73.44%] [G loss: 1.172408]\n",
      "epoch:22 step:21379 [D loss: 0.969886, acc.: 35.94%] [G loss: 1.037625]\n",
      "epoch:22 step:21380 [D loss: 0.783609, acc.: 47.66%] [G loss: 1.099384]\n",
      "epoch:22 step:21381 [D loss: 0.545321, acc.: 75.78%] [G loss: 1.219270]\n",
      "epoch:22 step:21382 [D loss: 0.494520, acc.: 75.78%] [G loss: 1.021849]\n",
      "epoch:22 step:21383 [D loss: 0.342719, acc.: 89.84%] [G loss: 1.525653]\n",
      "epoch:22 step:21384 [D loss: 0.606273, acc.: 65.62%] [G loss: 1.149967]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21385 [D loss: 0.619339, acc.: 65.62%] [G loss: 1.020443]\n",
      "epoch:22 step:21386 [D loss: 0.689374, acc.: 58.59%] [G loss: 1.158835]\n",
      "epoch:22 step:21387 [D loss: 0.756388, acc.: 54.69%] [G loss: 0.898259]\n",
      "epoch:22 step:21388 [D loss: 0.318071, acc.: 85.16%] [G loss: 1.414622]\n",
      "epoch:22 step:21389 [D loss: 0.184551, acc.: 98.44%] [G loss: 1.769372]\n",
      "epoch:22 step:21390 [D loss: 0.504500, acc.: 75.00%] [G loss: 1.809469]\n",
      "epoch:22 step:21391 [D loss: 0.409778, acc.: 85.94%] [G loss: 1.659071]\n",
      "epoch:22 step:21392 [D loss: 0.638267, acc.: 63.28%] [G loss: 1.170135]\n",
      "epoch:22 step:21393 [D loss: 0.827729, acc.: 44.53%] [G loss: 1.232515]\n",
      "epoch:22 step:21394 [D loss: 0.795736, acc.: 44.53%] [G loss: 1.016481]\n",
      "epoch:22 step:21395 [D loss: 0.833726, acc.: 45.31%] [G loss: 0.884463]\n",
      "epoch:22 step:21396 [D loss: 0.743257, acc.: 48.44%] [G loss: 0.896623]\n",
      "epoch:22 step:21397 [D loss: 0.751816, acc.: 48.44%] [G loss: 0.899115]\n",
      "epoch:22 step:21398 [D loss: 0.712501, acc.: 55.47%] [G loss: 0.937753]\n",
      "epoch:22 step:21399 [D loss: 0.832791, acc.: 43.75%] [G loss: 0.835487]\n",
      "epoch:22 step:21400 [D loss: 0.652210, acc.: 61.72%] [G loss: 0.968023]\n",
      "##############\n",
      "[2.56282503 1.81015278 5.50975335 4.38381498 3.03300036 5.43466766\n",
      " 4.16413247 4.51524187 4.08949906 3.6937627 ]\n",
      "##########\n",
      "epoch:22 step:21401 [D loss: 0.766727, acc.: 50.00%] [G loss: 1.086566]\n",
      "epoch:22 step:21402 [D loss: 0.742323, acc.: 47.66%] [G loss: 1.057117]\n",
      "epoch:22 step:21403 [D loss: 0.661773, acc.: 60.94%] [G loss: 1.065854]\n",
      "epoch:22 step:21404 [D loss: 0.657976, acc.: 66.41%] [G loss: 0.917549]\n",
      "epoch:22 step:21405 [D loss: 0.505299, acc.: 80.47%] [G loss: 1.305897]\n",
      "epoch:22 step:21406 [D loss: 0.477734, acc.: 83.59%] [G loss: 1.279365]\n",
      "epoch:22 step:21407 [D loss: 0.665798, acc.: 59.38%] [G loss: 0.860963]\n",
      "epoch:22 step:21408 [D loss: 0.392908, acc.: 88.28%] [G loss: 1.087122]\n",
      "epoch:22 step:21409 [D loss: 0.532771, acc.: 75.00%] [G loss: 1.262635]\n",
      "epoch:22 step:21410 [D loss: 0.532682, acc.: 71.88%] [G loss: 0.993308]\n",
      "epoch:22 step:21411 [D loss: 0.591951, acc.: 70.31%] [G loss: 1.306164]\n",
      "epoch:22 step:21412 [D loss: 0.662217, acc.: 64.84%] [G loss: 1.148131]\n",
      "epoch:22 step:21413 [D loss: 0.577240, acc.: 69.53%] [G loss: 0.804300]\n",
      "epoch:22 step:21414 [D loss: 0.621350, acc.: 67.97%] [G loss: 1.092744]\n",
      "epoch:22 step:21415 [D loss: 0.520056, acc.: 75.78%] [G loss: 1.084725]\n",
      "epoch:22 step:21416 [D loss: 0.510803, acc.: 81.25%] [G loss: 0.932019]\n",
      "epoch:22 step:21417 [D loss: 0.580803, acc.: 67.19%] [G loss: 1.068766]\n",
      "epoch:22 step:21418 [D loss: 0.448615, acc.: 82.81%] [G loss: 1.321824]\n",
      "epoch:22 step:21419 [D loss: 0.505826, acc.: 77.34%] [G loss: 1.133315]\n",
      "epoch:22 step:21420 [D loss: 0.358120, acc.: 87.50%] [G loss: 1.270372]\n",
      "epoch:22 step:21421 [D loss: 0.542732, acc.: 74.22%] [G loss: 1.367464]\n",
      "epoch:22 step:21422 [D loss: 0.736099, acc.: 52.34%] [G loss: 1.026875]\n",
      "epoch:22 step:21423 [D loss: 0.556442, acc.: 75.00%] [G loss: 1.116044]\n",
      "epoch:22 step:21424 [D loss: 0.600048, acc.: 65.62%] [G loss: 1.298132]\n",
      "epoch:22 step:21425 [D loss: 0.773837, acc.: 40.62%] [G loss: 0.770878]\n",
      "epoch:22 step:21426 [D loss: 0.621953, acc.: 66.41%] [G loss: 0.824737]\n",
      "epoch:22 step:21427 [D loss: 0.666329, acc.: 56.25%] [G loss: 0.934027]\n",
      "epoch:22 step:21428 [D loss: 0.697030, acc.: 60.16%] [G loss: 1.095623]\n",
      "epoch:22 step:21429 [D loss: 0.445791, acc.: 75.00%] [G loss: 0.942206]\n",
      "epoch:22 step:21430 [D loss: 0.558392, acc.: 71.88%] [G loss: 1.086906]\n",
      "epoch:22 step:21431 [D loss: 0.595433, acc.: 71.88%] [G loss: 1.255383]\n",
      "epoch:22 step:21432 [D loss: 0.666253, acc.: 61.72%] [G loss: 0.992785]\n",
      "epoch:22 step:21433 [D loss: 0.591761, acc.: 67.97%] [G loss: 0.762541]\n",
      "epoch:22 step:21434 [D loss: 0.695010, acc.: 53.91%] [G loss: 0.942975]\n",
      "epoch:22 step:21435 [D loss: 0.799705, acc.: 43.75%] [G loss: 0.909337]\n",
      "epoch:22 step:21436 [D loss: 0.707022, acc.: 59.38%] [G loss: 0.804046]\n",
      "epoch:22 step:21437 [D loss: 0.695815, acc.: 50.78%] [G loss: 0.924555]\n",
      "epoch:22 step:21438 [D loss: 0.596393, acc.: 68.75%] [G loss: 0.873914]\n",
      "epoch:22 step:21439 [D loss: 0.477011, acc.: 80.47%] [G loss: 1.095628]\n",
      "epoch:22 step:21440 [D loss: 0.717753, acc.: 58.59%] [G loss: 0.872040]\n",
      "epoch:22 step:21441 [D loss: 0.747898, acc.: 55.47%] [G loss: 1.158072]\n",
      "epoch:22 step:21442 [D loss: 0.784866, acc.: 48.44%] [G loss: 0.974035]\n",
      "epoch:22 step:21443 [D loss: 0.631890, acc.: 64.06%] [G loss: 0.883734]\n",
      "epoch:22 step:21444 [D loss: 0.551647, acc.: 76.56%] [G loss: 0.862297]\n",
      "epoch:22 step:21445 [D loss: 0.478964, acc.: 78.12%] [G loss: 1.097278]\n",
      "epoch:22 step:21446 [D loss: 0.512266, acc.: 80.47%] [G loss: 1.381176]\n",
      "epoch:22 step:21447 [D loss: 0.487221, acc.: 77.34%] [G loss: 1.076884]\n",
      "epoch:22 step:21448 [D loss: 0.702473, acc.: 53.12%] [G loss: 1.028015]\n",
      "epoch:22 step:21449 [D loss: 0.660246, acc.: 60.94%] [G loss: 1.009875]\n",
      "epoch:22 step:21450 [D loss: 0.512963, acc.: 77.34%] [G loss: 1.305945]\n",
      "epoch:22 step:21451 [D loss: 0.499694, acc.: 80.47%] [G loss: 1.062344]\n",
      "epoch:22 step:21452 [D loss: 0.498320, acc.: 80.47%] [G loss: 1.184774]\n",
      "epoch:22 step:21453 [D loss: 0.594581, acc.: 66.41%] [G loss: 1.176884]\n",
      "epoch:22 step:21454 [D loss: 0.494156, acc.: 83.59%] [G loss: 1.187121]\n",
      "epoch:22 step:21455 [D loss: 0.485210, acc.: 78.12%] [G loss: 1.344708]\n",
      "epoch:22 step:21456 [D loss: 0.496813, acc.: 80.47%] [G loss: 1.210600]\n",
      "epoch:22 step:21457 [D loss: 0.696900, acc.: 60.16%] [G loss: 1.008771]\n",
      "epoch:22 step:21458 [D loss: 0.727577, acc.: 53.12%] [G loss: 1.000830]\n",
      "epoch:22 step:21459 [D loss: 0.707920, acc.: 58.59%] [G loss: 0.981069]\n",
      "epoch:22 step:21460 [D loss: 0.791084, acc.: 50.00%] [G loss: 0.778928]\n",
      "epoch:22 step:21461 [D loss: 0.498535, acc.: 80.47%] [G loss: 1.374368]\n",
      "epoch:22 step:21462 [D loss: 0.631829, acc.: 64.84%] [G loss: 0.906639]\n",
      "epoch:22 step:21463 [D loss: 0.449666, acc.: 87.50%] [G loss: 1.131948]\n",
      "epoch:22 step:21464 [D loss: 0.382619, acc.: 89.84%] [G loss: 1.398313]\n",
      "epoch:22 step:21465 [D loss: 0.457129, acc.: 74.22%] [G loss: 0.952052]\n",
      "epoch:22 step:21466 [D loss: 0.260070, acc.: 96.09%] [G loss: 1.583241]\n",
      "epoch:22 step:21467 [D loss: 0.503794, acc.: 78.12%] [G loss: 1.005900]\n",
      "epoch:22 step:21468 [D loss: 0.408745, acc.: 89.06%] [G loss: 1.234542]\n",
      "epoch:22 step:21469 [D loss: 0.697725, acc.: 57.03%] [G loss: 1.055553]\n",
      "epoch:22 step:21470 [D loss: 0.672134, acc.: 57.81%] [G loss: 1.180439]\n",
      "epoch:22 step:21471 [D loss: 0.470992, acc.: 83.59%] [G loss: 1.017950]\n",
      "epoch:22 step:21472 [D loss: 0.675146, acc.: 56.25%] [G loss: 0.912487]\n",
      "epoch:22 step:21473 [D loss: 0.566946, acc.: 70.31%] [G loss: 1.336475]\n",
      "epoch:22 step:21474 [D loss: 0.500176, acc.: 81.25%] [G loss: 1.295424]\n",
      "epoch:22 step:21475 [D loss: 0.738962, acc.: 50.00%] [G loss: 1.176798]\n",
      "epoch:22 step:21476 [D loss: 0.722831, acc.: 53.12%] [G loss: 1.130803]\n",
      "epoch:22 step:21477 [D loss: 0.572073, acc.: 71.09%] [G loss: 1.041266]\n",
      "epoch:22 step:21478 [D loss: 0.729864, acc.: 58.59%] [G loss: 0.956522]\n",
      "epoch:22 step:21479 [D loss: 0.853833, acc.: 35.16%] [G loss: 0.952511]\n",
      "epoch:22 step:21480 [D loss: 0.616627, acc.: 66.41%] [G loss: 1.215319]\n",
      "epoch:22 step:21481 [D loss: 0.704423, acc.: 56.25%] [G loss: 1.108037]\n",
      "epoch:22 step:21482 [D loss: 0.549541, acc.: 71.09%] [G loss: 1.199837]\n",
      "epoch:22 step:21483 [D loss: 0.800412, acc.: 41.41%] [G loss: 0.974672]\n",
      "epoch:22 step:21484 [D loss: 0.561551, acc.: 75.78%] [G loss: 0.909002]\n",
      "epoch:22 step:21485 [D loss: 0.691724, acc.: 56.25%] [G loss: 0.957496]\n",
      "epoch:22 step:21486 [D loss: 0.633762, acc.: 67.97%] [G loss: 1.167105]\n",
      "epoch:22 step:21487 [D loss: 0.618596, acc.: 69.53%] [G loss: 1.037492]\n",
      "epoch:22 step:21488 [D loss: 0.756115, acc.: 48.44%] [G loss: 1.023875]\n",
      "epoch:22 step:21489 [D loss: 0.619803, acc.: 68.75%] [G loss: 0.856329]\n",
      "epoch:22 step:21490 [D loss: 0.564091, acc.: 73.44%] [G loss: 1.072432]\n",
      "epoch:22 step:21491 [D loss: 0.496650, acc.: 82.03%] [G loss: 1.467948]\n",
      "epoch:22 step:21492 [D loss: 0.469214, acc.: 75.00%] [G loss: 1.234890]\n",
      "epoch:22 step:21493 [D loss: 0.731896, acc.: 54.69%] [G loss: 1.212876]\n",
      "epoch:22 step:21494 [D loss: 0.980566, acc.: 35.94%] [G loss: 1.094630]\n",
      "epoch:22 step:21495 [D loss: 0.903797, acc.: 32.81%] [G loss: 0.734404]\n",
      "epoch:22 step:21496 [D loss: 0.848921, acc.: 35.94%] [G loss: 0.894369]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21497 [D loss: 0.604470, acc.: 66.41%] [G loss: 1.405871]\n",
      "epoch:22 step:21498 [D loss: 0.556349, acc.: 71.09%] [G loss: 1.001593]\n",
      "epoch:22 step:21499 [D loss: 0.413976, acc.: 87.50%] [G loss: 1.357574]\n",
      "epoch:22 step:21500 [D loss: 0.557996, acc.: 72.66%] [G loss: 1.087573]\n",
      "epoch:22 step:21501 [D loss: 0.365445, acc.: 91.41%] [G loss: 1.351623]\n",
      "epoch:22 step:21502 [D loss: 0.566050, acc.: 67.19%] [G loss: 0.984848]\n",
      "epoch:22 step:21503 [D loss: 0.369923, acc.: 88.28%] [G loss: 1.421018]\n",
      "epoch:22 step:21504 [D loss: 0.414915, acc.: 91.41%] [G loss: 1.586445]\n",
      "epoch:22 step:21505 [D loss: 0.848297, acc.: 46.88%] [G loss: 1.356678]\n",
      "epoch:22 step:21506 [D loss: 0.653271, acc.: 61.72%] [G loss: 1.044280]\n",
      "epoch:22 step:21507 [D loss: 0.605138, acc.: 71.09%] [G loss: 1.135476]\n",
      "epoch:22 step:21508 [D loss: 0.553917, acc.: 68.75%] [G loss: 0.981485]\n",
      "epoch:22 step:21509 [D loss: 0.496276, acc.: 83.59%] [G loss: 1.236679]\n",
      "epoch:22 step:21510 [D loss: 0.510832, acc.: 81.25%] [G loss: 1.237344]\n",
      "epoch:22 step:21511 [D loss: 0.499549, acc.: 77.34%] [G loss: 1.156737]\n",
      "epoch:22 step:21512 [D loss: 0.311189, acc.: 92.97%] [G loss: 1.111608]\n",
      "epoch:22 step:21513 [D loss: 0.333919, acc.: 91.41%] [G loss: 1.403808]\n",
      "epoch:22 step:21514 [D loss: 0.304639, acc.: 95.31%] [G loss: 1.546658]\n",
      "epoch:22 step:21515 [D loss: 0.477952, acc.: 82.03%] [G loss: 1.641701]\n",
      "epoch:22 step:21516 [D loss: 0.572795, acc.: 69.53%] [G loss: 1.366328]\n",
      "epoch:22 step:21517 [D loss: 0.750980, acc.: 53.91%] [G loss: 0.891940]\n",
      "epoch:22 step:21518 [D loss: 0.743304, acc.: 49.22%] [G loss: 0.965154]\n",
      "epoch:22 step:21519 [D loss: 0.701342, acc.: 56.25%] [G loss: 1.174096]\n",
      "epoch:22 step:21520 [D loss: 0.450872, acc.: 85.16%] [G loss: 1.247439]\n",
      "epoch:22 step:21521 [D loss: 0.744384, acc.: 50.00%] [G loss: 1.049847]\n",
      "epoch:22 step:21522 [D loss: 0.785441, acc.: 44.53%] [G loss: 0.995705]\n",
      "epoch:22 step:21523 [D loss: 0.652013, acc.: 63.28%] [G loss: 0.747324]\n",
      "epoch:22 step:21524 [D loss: 0.524941, acc.: 73.44%] [G loss: 1.398233]\n",
      "epoch:22 step:21525 [D loss: 0.465502, acc.: 82.03%] [G loss: 1.175002]\n",
      "epoch:22 step:21526 [D loss: 0.265805, acc.: 91.41%] [G loss: 1.350223]\n",
      "epoch:22 step:21527 [D loss: 0.846220, acc.: 46.88%] [G loss: 1.080223]\n",
      "epoch:22 step:21528 [D loss: 0.662183, acc.: 57.03%] [G loss: 1.177662]\n",
      "epoch:22 step:21529 [D loss: 0.632009, acc.: 59.38%] [G loss: 0.952561]\n",
      "epoch:22 step:21530 [D loss: 0.607809, acc.: 69.53%] [G loss: 1.043318]\n",
      "epoch:22 step:21531 [D loss: 0.531661, acc.: 74.22%] [G loss: 1.096751]\n",
      "epoch:22 step:21532 [D loss: 0.519422, acc.: 76.56%] [G loss: 1.150273]\n",
      "epoch:22 step:21533 [D loss: 0.605424, acc.: 68.75%] [G loss: 1.151202]\n",
      "epoch:22 step:21534 [D loss: 0.411682, acc.: 83.59%] [G loss: 1.034743]\n",
      "epoch:22 step:21535 [D loss: 0.374636, acc.: 86.72%] [G loss: 1.391645]\n",
      "epoch:22 step:21536 [D loss: 0.689156, acc.: 54.69%] [G loss: 1.266270]\n",
      "epoch:22 step:21537 [D loss: 0.651985, acc.: 57.03%] [G loss: 1.188417]\n",
      "epoch:22 step:21538 [D loss: 0.601128, acc.: 70.31%] [G loss: 1.176844]\n",
      "epoch:22 step:21539 [D loss: 0.609424, acc.: 65.62%] [G loss: 1.171917]\n",
      "epoch:22 step:21540 [D loss: 0.418763, acc.: 85.94%] [G loss: 1.295365]\n",
      "epoch:22 step:21541 [D loss: 0.306150, acc.: 96.88%] [G loss: 1.588885]\n",
      "epoch:22 step:21542 [D loss: 1.032302, acc.: 39.84%] [G loss: 1.024903]\n",
      "epoch:22 step:21543 [D loss: 0.471810, acc.: 81.25%] [G loss: 1.127501]\n",
      "epoch:22 step:21544 [D loss: 0.401063, acc.: 90.62%] [G loss: 1.314586]\n",
      "epoch:22 step:21545 [D loss: 0.649075, acc.: 62.50%] [G loss: 1.045789]\n",
      "epoch:22 step:21546 [D loss: 0.657751, acc.: 63.28%] [G loss: 1.142230]\n",
      "epoch:22 step:21547 [D loss: 0.482939, acc.: 81.25%] [G loss: 1.260136]\n",
      "epoch:22 step:21548 [D loss: 0.307684, acc.: 95.31%] [G loss: 1.237031]\n",
      "epoch:22 step:21549 [D loss: 0.433211, acc.: 84.38%] [G loss: 1.290309]\n",
      "epoch:22 step:21550 [D loss: 0.394794, acc.: 84.38%] [G loss: 1.192918]\n",
      "epoch:22 step:21551 [D loss: 0.256535, acc.: 90.62%] [G loss: 1.460466]\n",
      "epoch:23 step:21552 [D loss: 0.624636, acc.: 60.94%] [G loss: 1.323501]\n",
      "epoch:23 step:21553 [D loss: 0.601538, acc.: 67.19%] [G loss: 1.366968]\n",
      "epoch:23 step:21554 [D loss: 0.738908, acc.: 53.91%] [G loss: 0.956447]\n",
      "epoch:23 step:21555 [D loss: 1.013876, acc.: 28.91%] [G loss: 0.625539]\n",
      "epoch:23 step:21556 [D loss: 0.734510, acc.: 49.22%] [G loss: 0.962252]\n",
      "epoch:23 step:21557 [D loss: 0.883678, acc.: 32.03%] [G loss: 0.842473]\n",
      "epoch:23 step:21558 [D loss: 0.683335, acc.: 58.59%] [G loss: 1.019667]\n",
      "epoch:23 step:21559 [D loss: 0.650065, acc.: 66.41%] [G loss: 1.162342]\n",
      "epoch:23 step:21560 [D loss: 0.479806, acc.: 85.16%] [G loss: 1.285108]\n",
      "epoch:23 step:21561 [D loss: 0.511176, acc.: 81.25%] [G loss: 1.191607]\n",
      "epoch:23 step:21562 [D loss: 0.499367, acc.: 78.12%] [G loss: 1.173616]\n",
      "epoch:23 step:21563 [D loss: 0.706699, acc.: 58.59%] [G loss: 0.965699]\n",
      "epoch:23 step:21564 [D loss: 0.585079, acc.: 71.09%] [G loss: 1.306527]\n",
      "epoch:23 step:21565 [D loss: 0.553365, acc.: 75.00%] [G loss: 1.113613]\n",
      "epoch:23 step:21566 [D loss: 0.512317, acc.: 75.78%] [G loss: 1.255916]\n",
      "epoch:23 step:21567 [D loss: 0.492722, acc.: 77.34%] [G loss: 1.059046]\n",
      "epoch:23 step:21568 [D loss: 0.686413, acc.: 57.03%] [G loss: 1.078176]\n",
      "epoch:23 step:21569 [D loss: 0.643986, acc.: 61.72%] [G loss: 1.459648]\n",
      "epoch:23 step:21570 [D loss: 0.911744, acc.: 35.16%] [G loss: 0.768048]\n",
      "epoch:23 step:21571 [D loss: 0.682856, acc.: 57.03%] [G loss: 1.126801]\n",
      "epoch:23 step:21572 [D loss: 0.675762, acc.: 56.25%] [G loss: 1.116587]\n",
      "epoch:23 step:21573 [D loss: 0.925484, acc.: 32.81%] [G loss: 0.692587]\n",
      "epoch:23 step:21574 [D loss: 0.618962, acc.: 67.19%] [G loss: 0.975577]\n",
      "epoch:23 step:21575 [D loss: 0.636935, acc.: 62.50%] [G loss: 1.043008]\n",
      "epoch:23 step:21576 [D loss: 0.650532, acc.: 66.41%] [G loss: 1.031573]\n",
      "epoch:23 step:21577 [D loss: 0.386366, acc.: 87.50%] [G loss: 1.322587]\n",
      "epoch:23 step:21578 [D loss: 0.307390, acc.: 93.75%] [G loss: 1.397636]\n",
      "epoch:23 step:21579 [D loss: 0.322370, acc.: 94.53%] [G loss: 1.295233]\n",
      "epoch:23 step:21580 [D loss: 0.377660, acc.: 90.62%] [G loss: 1.395369]\n",
      "epoch:23 step:21581 [D loss: 0.294745, acc.: 95.31%] [G loss: 1.772222]\n",
      "epoch:23 step:21582 [D loss: 0.285023, acc.: 96.09%] [G loss: 1.706631]\n",
      "epoch:23 step:21583 [D loss: 0.203497, acc.: 99.22%] [G loss: 2.280770]\n",
      "epoch:23 step:21584 [D loss: 0.327924, acc.: 90.62%] [G loss: 1.582807]\n",
      "epoch:23 step:21585 [D loss: 0.313237, acc.: 91.41%] [G loss: 1.669627]\n",
      "epoch:23 step:21586 [D loss: 0.185415, acc.: 97.66%] [G loss: 2.206558]\n",
      "epoch:23 step:21587 [D loss: 0.190916, acc.: 97.66%] [G loss: 1.993789]\n",
      "epoch:23 step:21588 [D loss: 0.862090, acc.: 46.88%] [G loss: 1.458606]\n",
      "epoch:23 step:21589 [D loss: 0.945310, acc.: 35.16%] [G loss: 0.911338]\n",
      "epoch:23 step:21590 [D loss: 0.959794, acc.: 31.25%] [G loss: 0.731789]\n",
      "epoch:23 step:21591 [D loss: 0.760482, acc.: 50.00%] [G loss: 0.987943]\n",
      "epoch:23 step:21592 [D loss: 0.721887, acc.: 52.34%] [G loss: 1.192209]\n",
      "epoch:23 step:21593 [D loss: 0.638127, acc.: 63.28%] [G loss: 1.035114]\n",
      "epoch:23 step:21594 [D loss: 0.578708, acc.: 70.31%] [G loss: 1.196019]\n",
      "epoch:23 step:21595 [D loss: 0.470388, acc.: 83.59%] [G loss: 1.077913]\n",
      "epoch:23 step:21596 [D loss: 0.522608, acc.: 74.22%] [G loss: 0.933820]\n",
      "epoch:23 step:21597 [D loss: 1.084587, acc.: 21.09%] [G loss: 0.624102]\n",
      "epoch:23 step:21598 [D loss: 0.802986, acc.: 44.53%] [G loss: 1.066332]\n",
      "epoch:23 step:21599 [D loss: 0.679181, acc.: 57.81%] [G loss: 1.095590]\n",
      "epoch:23 step:21600 [D loss: 0.501901, acc.: 82.03%] [G loss: 1.189738]\n",
      "##############\n",
      "[2.57906778 1.74255678 5.57417619 4.07777249 2.91427828 5.46808486\n",
      " 4.26624164 4.5209675  4.28726855 3.61033687]\n",
      "##########\n",
      "epoch:23 step:21601 [D loss: 0.606909, acc.: 64.84%] [G loss: 0.925151]\n",
      "epoch:23 step:21602 [D loss: 0.676261, acc.: 60.16%] [G loss: 1.110504]\n",
      "epoch:23 step:21603 [D loss: 0.682646, acc.: 60.16%] [G loss: 0.924128]\n",
      "epoch:23 step:21604 [D loss: 0.694318, acc.: 57.81%] [G loss: 1.141262]\n",
      "epoch:23 step:21605 [D loss: 0.557892, acc.: 71.09%] [G loss: 0.985000]\n",
      "epoch:23 step:21606 [D loss: 0.605176, acc.: 67.19%] [G loss: 1.046832]\n",
      "epoch:23 step:21607 [D loss: 0.717062, acc.: 55.47%] [G loss: 1.022432]\n",
      "epoch:23 step:21608 [D loss: 0.784674, acc.: 44.53%] [G loss: 1.106709]\n",
      "epoch:23 step:21609 [D loss: 0.716132, acc.: 51.56%] [G loss: 0.934946]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21610 [D loss: 0.662588, acc.: 64.06%] [G loss: 0.818702]\n",
      "epoch:23 step:21611 [D loss: 0.709638, acc.: 59.38%] [G loss: 0.959318]\n",
      "epoch:23 step:21612 [D loss: 0.580266, acc.: 70.31%] [G loss: 1.080433]\n",
      "epoch:23 step:21613 [D loss: 0.514740, acc.: 79.69%] [G loss: 0.982611]\n",
      "epoch:23 step:21614 [D loss: 0.679326, acc.: 59.38%] [G loss: 0.838289]\n",
      "epoch:23 step:21615 [D loss: 0.567972, acc.: 73.44%] [G loss: 0.820135]\n",
      "epoch:23 step:21616 [D loss: 0.577256, acc.: 67.19%] [G loss: 1.011612]\n",
      "epoch:23 step:21617 [D loss: 0.741890, acc.: 57.03%] [G loss: 0.749397]\n",
      "epoch:23 step:21618 [D loss: 0.580975, acc.: 74.22%] [G loss: 1.110518]\n",
      "epoch:23 step:21619 [D loss: 0.515386, acc.: 75.78%] [G loss: 1.031903]\n",
      "epoch:23 step:21620 [D loss: 0.352702, acc.: 91.41%] [G loss: 1.237861]\n",
      "epoch:23 step:21621 [D loss: 0.504395, acc.: 80.47%] [G loss: 1.285147]\n",
      "epoch:23 step:21622 [D loss: 0.816502, acc.: 37.50%] [G loss: 0.933577]\n",
      "epoch:23 step:21623 [D loss: 0.675373, acc.: 60.16%] [G loss: 1.040640]\n",
      "epoch:23 step:21624 [D loss: 0.686250, acc.: 54.69%] [G loss: 0.826617]\n",
      "epoch:23 step:21625 [D loss: 0.427737, acc.: 84.38%] [G loss: 0.983318]\n",
      "epoch:23 step:21626 [D loss: 0.396573, acc.: 83.59%] [G loss: 1.124084]\n",
      "epoch:23 step:21627 [D loss: 0.334062, acc.: 89.06%] [G loss: 1.604184]\n",
      "epoch:23 step:21628 [D loss: 0.350918, acc.: 90.62%] [G loss: 1.618223]\n",
      "epoch:23 step:21629 [D loss: 0.807097, acc.: 53.12%] [G loss: 1.392969]\n",
      "epoch:23 step:21630 [D loss: 0.594590, acc.: 67.19%] [G loss: 1.076081]\n",
      "epoch:23 step:21631 [D loss: 0.637254, acc.: 64.06%] [G loss: 0.972795]\n",
      "epoch:23 step:21632 [D loss: 0.718120, acc.: 50.00%] [G loss: 0.977993]\n",
      "epoch:23 step:21633 [D loss: 0.664222, acc.: 58.59%] [G loss: 0.885618]\n",
      "epoch:23 step:21634 [D loss: 0.536653, acc.: 75.00%] [G loss: 1.169219]\n",
      "epoch:23 step:21635 [D loss: 0.674626, acc.: 59.38%] [G loss: 0.997011]\n",
      "epoch:23 step:21636 [D loss: 0.733001, acc.: 52.34%] [G loss: 0.972264]\n",
      "epoch:23 step:21637 [D loss: 0.680688, acc.: 54.69%] [G loss: 0.825868]\n",
      "epoch:23 step:21638 [D loss: 0.551676, acc.: 74.22%] [G loss: 1.105215]\n",
      "epoch:23 step:21639 [D loss: 0.505994, acc.: 76.56%] [G loss: 1.143080]\n",
      "epoch:23 step:21640 [D loss: 0.580112, acc.: 68.75%] [G loss: 1.046993]\n",
      "epoch:23 step:21641 [D loss: 0.451995, acc.: 83.59%] [G loss: 0.966684]\n",
      "epoch:23 step:21642 [D loss: 0.797918, acc.: 46.88%] [G loss: 0.911541]\n",
      "epoch:23 step:21643 [D loss: 0.417860, acc.: 89.84%] [G loss: 1.115941]\n",
      "epoch:23 step:21644 [D loss: 0.713324, acc.: 54.69%] [G loss: 0.813711]\n",
      "epoch:23 step:21645 [D loss: 0.664192, acc.: 61.72%] [G loss: 1.024865]\n",
      "epoch:23 step:21646 [D loss: 0.655772, acc.: 61.72%] [G loss: 1.125617]\n",
      "epoch:23 step:21647 [D loss: 0.744324, acc.: 52.34%] [G loss: 0.937940]\n",
      "epoch:23 step:21648 [D loss: 0.616932, acc.: 64.84%] [G loss: 1.020251]\n",
      "epoch:23 step:21649 [D loss: 0.780072, acc.: 44.53%] [G loss: 1.093479]\n",
      "epoch:23 step:21650 [D loss: 0.744446, acc.: 49.22%] [G loss: 0.989648]\n",
      "epoch:23 step:21651 [D loss: 0.691678, acc.: 58.59%] [G loss: 0.958908]\n",
      "epoch:23 step:21652 [D loss: 0.612557, acc.: 60.94%] [G loss: 0.907451]\n",
      "epoch:23 step:21653 [D loss: 0.642007, acc.: 67.97%] [G loss: 0.862286]\n",
      "epoch:23 step:21654 [D loss: 0.559046, acc.: 71.09%] [G loss: 1.046833]\n",
      "epoch:23 step:21655 [D loss: 0.565156, acc.: 75.00%] [G loss: 0.944606]\n",
      "epoch:23 step:21656 [D loss: 0.467032, acc.: 82.81%] [G loss: 1.126050]\n",
      "epoch:23 step:21657 [D loss: 0.531046, acc.: 75.00%] [G loss: 1.060324]\n",
      "epoch:23 step:21658 [D loss: 0.684077, acc.: 58.59%] [G loss: 1.025874]\n",
      "epoch:23 step:21659 [D loss: 0.533074, acc.: 71.88%] [G loss: 1.085041]\n",
      "epoch:23 step:21660 [D loss: 0.562758, acc.: 67.97%] [G loss: 1.242921]\n",
      "epoch:23 step:21661 [D loss: 0.585429, acc.: 66.41%] [G loss: 1.218619]\n",
      "epoch:23 step:21662 [D loss: 0.593246, acc.: 66.41%] [G loss: 1.181062]\n",
      "epoch:23 step:21663 [D loss: 0.580778, acc.: 66.41%] [G loss: 1.219191]\n",
      "epoch:23 step:21664 [D loss: 0.672816, acc.: 59.38%] [G loss: 1.119307]\n",
      "epoch:23 step:21665 [D loss: 0.846328, acc.: 37.50%] [G loss: 0.952654]\n",
      "epoch:23 step:21666 [D loss: 0.900813, acc.: 36.72%] [G loss: 0.770098]\n",
      "epoch:23 step:21667 [D loss: 0.538217, acc.: 78.12%] [G loss: 1.295816]\n",
      "epoch:23 step:21668 [D loss: 0.497577, acc.: 77.34%] [G loss: 1.115565]\n",
      "epoch:23 step:21669 [D loss: 0.513152, acc.: 79.69%] [G loss: 1.366399]\n",
      "epoch:23 step:21670 [D loss: 0.369372, acc.: 89.84%] [G loss: 1.473558]\n",
      "epoch:23 step:21671 [D loss: 0.781768, acc.: 52.34%] [G loss: 1.264171]\n",
      "epoch:23 step:21672 [D loss: 0.583511, acc.: 74.22%] [G loss: 1.291668]\n",
      "epoch:23 step:21673 [D loss: 0.410968, acc.: 87.50%] [G loss: 1.174966]\n",
      "epoch:23 step:21674 [D loss: 0.668526, acc.: 61.72%] [G loss: 1.113461]\n",
      "epoch:23 step:21675 [D loss: 0.589034, acc.: 69.53%] [G loss: 1.076249]\n",
      "epoch:23 step:21676 [D loss: 0.675130, acc.: 58.59%] [G loss: 1.101706]\n",
      "epoch:23 step:21677 [D loss: 0.584062, acc.: 64.06%] [G loss: 0.871967]\n",
      "epoch:23 step:21678 [D loss: 0.702749, acc.: 59.38%] [G loss: 0.897318]\n",
      "epoch:23 step:21679 [D loss: 0.659618, acc.: 60.94%] [G loss: 1.275480]\n",
      "epoch:23 step:21680 [D loss: 0.483627, acc.: 78.91%] [G loss: 1.157534]\n",
      "epoch:23 step:21681 [D loss: 0.389422, acc.: 90.62%] [G loss: 1.094305]\n",
      "epoch:23 step:21682 [D loss: 0.448353, acc.: 87.50%] [G loss: 1.203496]\n",
      "epoch:23 step:21683 [D loss: 0.479840, acc.: 82.03%] [G loss: 1.371855]\n",
      "epoch:23 step:21684 [D loss: 0.754004, acc.: 54.69%] [G loss: 1.148460]\n",
      "epoch:23 step:21685 [D loss: 0.540229, acc.: 72.66%] [G loss: 0.966143]\n",
      "epoch:23 step:21686 [D loss: 0.563912, acc.: 74.22%] [G loss: 0.952137]\n",
      "epoch:23 step:21687 [D loss: 0.714339, acc.: 53.91%] [G loss: 1.071231]\n",
      "epoch:23 step:21688 [D loss: 0.583480, acc.: 65.62%] [G loss: 0.991905]\n",
      "epoch:23 step:21689 [D loss: 0.526928, acc.: 75.00%] [G loss: 1.007949]\n",
      "epoch:23 step:21690 [D loss: 0.400278, acc.: 85.16%] [G loss: 1.122897]\n",
      "epoch:23 step:21691 [D loss: 0.594012, acc.: 67.19%] [G loss: 1.049492]\n",
      "epoch:23 step:21692 [D loss: 0.794782, acc.: 41.41%] [G loss: 0.756031]\n",
      "epoch:23 step:21693 [D loss: 0.703017, acc.: 55.47%] [G loss: 0.807121]\n",
      "epoch:23 step:21694 [D loss: 0.573198, acc.: 71.88%] [G loss: 1.320997]\n",
      "epoch:23 step:21695 [D loss: 0.501997, acc.: 79.69%] [G loss: 1.059848]\n",
      "epoch:23 step:21696 [D loss: 0.463338, acc.: 84.38%] [G loss: 1.254299]\n",
      "epoch:23 step:21697 [D loss: 0.556234, acc.: 72.66%] [G loss: 1.203787]\n",
      "epoch:23 step:21698 [D loss: 0.694921, acc.: 59.38%] [G loss: 0.898613]\n",
      "epoch:23 step:21699 [D loss: 0.790080, acc.: 42.19%] [G loss: 0.758739]\n",
      "epoch:23 step:21700 [D loss: 0.638762, acc.: 63.28%] [G loss: 0.869399]\n",
      "epoch:23 step:21701 [D loss: 0.577236, acc.: 66.41%] [G loss: 0.823025]\n",
      "epoch:23 step:21702 [D loss: 0.467232, acc.: 82.81%] [G loss: 1.311951]\n",
      "epoch:23 step:21703 [D loss: 0.569391, acc.: 70.31%] [G loss: 0.896139]\n",
      "epoch:23 step:21704 [D loss: 0.783168, acc.: 47.66%] [G loss: 1.044971]\n",
      "epoch:23 step:21705 [D loss: 0.683112, acc.: 59.38%] [G loss: 0.962339]\n",
      "epoch:23 step:21706 [D loss: 0.468251, acc.: 81.25%] [G loss: 1.159959]\n",
      "epoch:23 step:21707 [D loss: 0.361653, acc.: 85.94%] [G loss: 1.118868]\n",
      "epoch:23 step:21708 [D loss: 0.523407, acc.: 75.00%] [G loss: 1.327658]\n",
      "epoch:23 step:21709 [D loss: 0.414409, acc.: 89.84%] [G loss: 1.212466]\n",
      "epoch:23 step:21710 [D loss: 0.311411, acc.: 93.75%] [G loss: 1.302428]\n",
      "epoch:23 step:21711 [D loss: 0.662813, acc.: 62.50%] [G loss: 1.377901]\n",
      "epoch:23 step:21712 [D loss: 0.756222, acc.: 50.00%] [G loss: 1.143450]\n",
      "epoch:23 step:21713 [D loss: 0.626397, acc.: 64.84%] [G loss: 1.055767]\n",
      "epoch:23 step:21714 [D loss: 0.587828, acc.: 67.19%] [G loss: 1.085334]\n",
      "epoch:23 step:21715 [D loss: 0.369664, acc.: 92.97%] [G loss: 1.404006]\n",
      "epoch:23 step:21716 [D loss: 0.344576, acc.: 92.97%] [G loss: 1.527546]\n",
      "epoch:23 step:21717 [D loss: 0.500190, acc.: 78.12%] [G loss: 1.227117]\n",
      "epoch:23 step:21718 [D loss: 0.336086, acc.: 92.19%] [G loss: 0.975241]\n",
      "epoch:23 step:21719 [D loss: 0.549253, acc.: 69.53%] [G loss: 0.967948]\n",
      "epoch:23 step:21720 [D loss: 0.667365, acc.: 58.59%] [G loss: 1.080399]\n",
      "epoch:23 step:21721 [D loss: 0.684854, acc.: 59.38%] [G loss: 1.226041]\n",
      "epoch:23 step:21722 [D loss: 0.842456, acc.: 42.19%] [G loss: 0.894980]\n",
      "epoch:23 step:21723 [D loss: 0.595397, acc.: 64.84%] [G loss: 1.050326]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21724 [D loss: 0.708517, acc.: 56.25%] [G loss: 1.232608]\n",
      "epoch:23 step:21725 [D loss: 1.029906, acc.: 25.78%] [G loss: 0.668277]\n",
      "epoch:23 step:21726 [D loss: 0.888187, acc.: 34.38%] [G loss: 0.933446]\n",
      "epoch:23 step:21727 [D loss: 0.832395, acc.: 43.75%] [G loss: 1.072354]\n",
      "epoch:23 step:21728 [D loss: 1.064597, acc.: 28.12%] [G loss: 1.028621]\n",
      "epoch:23 step:21729 [D loss: 1.060001, acc.: 22.66%] [G loss: 0.664988]\n",
      "epoch:23 step:21730 [D loss: 0.908967, acc.: 33.59%] [G loss: 0.920232]\n",
      "epoch:23 step:21731 [D loss: 0.941282, acc.: 35.16%] [G loss: 0.676100]\n",
      "epoch:23 step:21732 [D loss: 0.957055, acc.: 29.69%] [G loss: 0.975373]\n",
      "epoch:23 step:21733 [D loss: 0.742449, acc.: 46.88%] [G loss: 0.981582]\n",
      "epoch:23 step:21734 [D loss: 0.952314, acc.: 28.91%] [G loss: 0.829687]\n",
      "epoch:23 step:21735 [D loss: 0.961122, acc.: 36.72%] [G loss: 0.993573]\n",
      "epoch:23 step:21736 [D loss: 1.019372, acc.: 25.78%] [G loss: 1.029725]\n",
      "epoch:23 step:21737 [D loss: 0.820670, acc.: 49.22%] [G loss: 1.083652]\n",
      "epoch:23 step:21738 [D loss: 0.768550, acc.: 45.31%] [G loss: 1.054050]\n",
      "epoch:23 step:21739 [D loss: 0.732381, acc.: 54.69%] [G loss: 1.153189]\n",
      "epoch:23 step:21740 [D loss: 0.702637, acc.: 58.59%] [G loss: 1.114169]\n",
      "epoch:23 step:21741 [D loss: 0.719927, acc.: 56.25%] [G loss: 0.969763]\n",
      "epoch:23 step:21742 [D loss: 0.560998, acc.: 73.44%] [G loss: 1.189504]\n",
      "epoch:23 step:21743 [D loss: 0.560737, acc.: 72.66%] [G loss: 1.181758]\n",
      "epoch:23 step:21744 [D loss: 0.665643, acc.: 59.38%] [G loss: 0.933178]\n",
      "epoch:23 step:21745 [D loss: 0.612590, acc.: 62.50%] [G loss: 1.061136]\n",
      "epoch:23 step:21746 [D loss: 0.681753, acc.: 57.03%] [G loss: 1.084957]\n",
      "epoch:23 step:21747 [D loss: 0.705396, acc.: 57.03%] [G loss: 1.103460]\n",
      "epoch:23 step:21748 [D loss: 0.646837, acc.: 63.28%] [G loss: 1.128845]\n",
      "epoch:23 step:21749 [D loss: 0.690460, acc.: 54.69%] [G loss: 0.633416]\n",
      "epoch:23 step:21750 [D loss: 0.653914, acc.: 59.38%] [G loss: 1.177896]\n",
      "epoch:23 step:21751 [D loss: 0.559217, acc.: 75.00%] [G loss: 1.177620]\n",
      "epoch:23 step:21752 [D loss: 0.552240, acc.: 72.66%] [G loss: 1.079336]\n",
      "epoch:23 step:21753 [D loss: 0.773944, acc.: 48.44%] [G loss: 1.151145]\n",
      "epoch:23 step:21754 [D loss: 0.657965, acc.: 60.94%] [G loss: 1.182514]\n",
      "epoch:23 step:21755 [D loss: 0.722882, acc.: 54.69%] [G loss: 1.084308]\n",
      "epoch:23 step:21756 [D loss: 0.706983, acc.: 50.78%] [G loss: 0.854622]\n",
      "epoch:23 step:21757 [D loss: 0.620629, acc.: 64.06%] [G loss: 0.841506]\n",
      "epoch:23 step:21758 [D loss: 0.608151, acc.: 67.97%] [G loss: 0.856104]\n",
      "epoch:23 step:21759 [D loss: 0.690215, acc.: 57.03%] [G loss: 1.002002]\n",
      "epoch:23 step:21760 [D loss: 0.618189, acc.: 66.41%] [G loss: 1.195878]\n",
      "epoch:23 step:21761 [D loss: 0.699459, acc.: 57.81%] [G loss: 0.916668]\n",
      "epoch:23 step:21762 [D loss: 0.526732, acc.: 76.56%] [G loss: 1.061327]\n",
      "epoch:23 step:21763 [D loss: 0.696043, acc.: 59.38%] [G loss: 0.936619]\n",
      "epoch:23 step:21764 [D loss: 0.467030, acc.: 80.47%] [G loss: 1.183100]\n",
      "epoch:23 step:21765 [D loss: 0.621575, acc.: 61.72%] [G loss: 1.190518]\n",
      "epoch:23 step:21766 [D loss: 0.598170, acc.: 67.19%] [G loss: 0.925956]\n",
      "epoch:23 step:21767 [D loss: 0.523138, acc.: 75.00%] [G loss: 1.047345]\n",
      "epoch:23 step:21768 [D loss: 0.694176, acc.: 58.59%] [G loss: 1.138913]\n",
      "epoch:23 step:21769 [D loss: 0.786607, acc.: 43.75%] [G loss: 0.850211]\n",
      "epoch:23 step:21770 [D loss: 0.659652, acc.: 57.03%] [G loss: 1.065284]\n",
      "epoch:23 step:21771 [D loss: 0.356392, acc.: 87.50%] [G loss: 0.994769]\n",
      "epoch:23 step:21772 [D loss: 0.388222, acc.: 85.16%] [G loss: 1.440846]\n",
      "epoch:23 step:21773 [D loss: 0.384783, acc.: 89.06%] [G loss: 1.458241]\n",
      "epoch:23 step:21774 [D loss: 0.290029, acc.: 94.53%] [G loss: 1.506016]\n",
      "epoch:23 step:21775 [D loss: 0.805761, acc.: 50.00%] [G loss: 1.119117]\n",
      "epoch:23 step:21776 [D loss: 0.902235, acc.: 37.50%] [G loss: 0.865189]\n",
      "epoch:23 step:21777 [D loss: 0.599622, acc.: 65.62%] [G loss: 1.105701]\n",
      "epoch:23 step:21778 [D loss: 0.669450, acc.: 60.94%] [G loss: 1.070548]\n",
      "epoch:23 step:21779 [D loss: 0.657956, acc.: 63.28%] [G loss: 0.958455]\n",
      "epoch:23 step:21780 [D loss: 0.564601, acc.: 72.66%] [G loss: 1.018069]\n",
      "epoch:23 step:21781 [D loss: 0.313678, acc.: 84.38%] [G loss: 1.313472]\n",
      "epoch:23 step:21782 [D loss: 0.274676, acc.: 94.53%] [G loss: 1.595595]\n",
      "epoch:23 step:21783 [D loss: 0.304478, acc.: 94.53%] [G loss: 1.423707]\n",
      "epoch:23 step:21784 [D loss: 0.794108, acc.: 53.91%] [G loss: 1.632541]\n",
      "epoch:23 step:21785 [D loss: 0.891748, acc.: 40.62%] [G loss: 0.923871]\n",
      "epoch:23 step:21786 [D loss: 0.589164, acc.: 67.19%] [G loss: 0.842091]\n",
      "epoch:23 step:21787 [D loss: 0.649459, acc.: 60.94%] [G loss: 1.235446]\n",
      "epoch:23 step:21788 [D loss: 0.700848, acc.: 61.72%] [G loss: 0.931538]\n",
      "epoch:23 step:21789 [D loss: 0.702936, acc.: 57.81%] [G loss: 1.043046]\n",
      "epoch:23 step:21790 [D loss: 0.750919, acc.: 50.78%] [G loss: 0.752838]\n",
      "epoch:23 step:21791 [D loss: 0.925269, acc.: 36.72%] [G loss: 0.734131]\n",
      "epoch:23 step:21792 [D loss: 0.684504, acc.: 56.25%] [G loss: 1.186488]\n",
      "epoch:23 step:21793 [D loss: 0.931290, acc.: 32.03%] [G loss: 1.058966]\n",
      "epoch:23 step:21794 [D loss: 0.781434, acc.: 47.66%] [G loss: 1.071627]\n",
      "epoch:23 step:21795 [D loss: 0.743451, acc.: 48.44%] [G loss: 1.210818]\n",
      "epoch:23 step:21796 [D loss: 0.567863, acc.: 72.66%] [G loss: 1.158539]\n",
      "epoch:23 step:21797 [D loss: 0.430172, acc.: 87.50%] [G loss: 1.452506]\n",
      "epoch:23 step:21798 [D loss: 0.441536, acc.: 85.94%] [G loss: 1.313117]\n",
      "epoch:23 step:21799 [D loss: 0.361391, acc.: 91.41%] [G loss: 1.437760]\n",
      "epoch:23 step:21800 [D loss: 0.636217, acc.: 64.84%] [G loss: 1.415318]\n",
      "##############\n",
      "[2.67623353 1.79680067 5.96521377 4.50878622 3.21398591 5.58223454\n",
      " 4.6423117  4.78195345 4.08700049 3.8843115 ]\n",
      "##########\n",
      "epoch:23 step:21801 [D loss: 0.538392, acc.: 72.66%] [G loss: 1.115787]\n",
      "epoch:23 step:21802 [D loss: 0.545874, acc.: 77.34%] [G loss: 1.009499]\n",
      "epoch:23 step:21803 [D loss: 0.607931, acc.: 68.75%] [G loss: 1.086374]\n",
      "epoch:23 step:21804 [D loss: 0.418872, acc.: 85.16%] [G loss: 1.436236]\n",
      "epoch:23 step:21805 [D loss: 0.687149, acc.: 53.12%] [G loss: 1.015846]\n",
      "epoch:23 step:21806 [D loss: 0.753827, acc.: 47.66%] [G loss: 0.909616]\n",
      "epoch:23 step:21807 [D loss: 0.681336, acc.: 52.34%] [G loss: 0.941068]\n",
      "epoch:23 step:21808 [D loss: 0.624457, acc.: 66.41%] [G loss: 1.206634]\n",
      "epoch:23 step:21809 [D loss: 0.601599, acc.: 69.53%] [G loss: 0.999799]\n",
      "epoch:23 step:21810 [D loss: 0.707591, acc.: 56.25%] [G loss: 1.110602]\n",
      "epoch:23 step:21811 [D loss: 0.815745, acc.: 43.75%] [G loss: 0.731659]\n",
      "epoch:23 step:21812 [D loss: 0.587101, acc.: 67.97%] [G loss: 1.025705]\n",
      "epoch:23 step:21813 [D loss: 0.619444, acc.: 64.06%] [G loss: 1.082313]\n",
      "epoch:23 step:21814 [D loss: 0.574221, acc.: 67.97%] [G loss: 1.086077]\n",
      "epoch:23 step:21815 [D loss: 0.458070, acc.: 83.59%] [G loss: 1.219119]\n",
      "epoch:23 step:21816 [D loss: 0.749689, acc.: 49.22%] [G loss: 1.120110]\n",
      "epoch:23 step:21817 [D loss: 0.723725, acc.: 49.22%] [G loss: 1.093370]\n",
      "epoch:23 step:21818 [D loss: 0.583874, acc.: 69.53%] [G loss: 1.214116]\n",
      "epoch:23 step:21819 [D loss: 0.671321, acc.: 60.16%] [G loss: 1.126524]\n",
      "epoch:23 step:21820 [D loss: 0.583058, acc.: 73.44%] [G loss: 0.991477]\n",
      "epoch:23 step:21821 [D loss: 0.699459, acc.: 53.91%] [G loss: 1.149763]\n",
      "epoch:23 step:21822 [D loss: 0.674554, acc.: 60.94%] [G loss: 0.800313]\n",
      "epoch:23 step:21823 [D loss: 0.455094, acc.: 79.69%] [G loss: 1.264199]\n",
      "epoch:23 step:21824 [D loss: 0.616536, acc.: 64.06%] [G loss: 1.060999]\n",
      "epoch:23 step:21825 [D loss: 0.580867, acc.: 71.09%] [G loss: 1.160112]\n",
      "epoch:23 step:21826 [D loss: 0.668280, acc.: 56.25%] [G loss: 1.009032]\n",
      "epoch:23 step:21827 [D loss: 0.643478, acc.: 61.72%] [G loss: 0.996821]\n",
      "epoch:23 step:21828 [D loss: 0.743042, acc.: 49.22%] [G loss: 1.037760]\n",
      "epoch:23 step:21829 [D loss: 0.618807, acc.: 64.06%] [G loss: 0.927653]\n",
      "epoch:23 step:21830 [D loss: 0.390057, acc.: 85.16%] [G loss: 1.222419]\n",
      "epoch:23 step:21831 [D loss: 0.341833, acc.: 92.19%] [G loss: 1.241924]\n",
      "epoch:23 step:21832 [D loss: 0.756945, acc.: 52.34%] [G loss: 1.146462]\n",
      "epoch:23 step:21833 [D loss: 0.659245, acc.: 62.50%] [G loss: 1.017898]\n",
      "epoch:23 step:21834 [D loss: 0.665819, acc.: 57.81%] [G loss: 0.821939]\n",
      "epoch:23 step:21835 [D loss: 0.393128, acc.: 90.62%] [G loss: 1.052565]\n",
      "epoch:23 step:21836 [D loss: 0.456919, acc.: 79.69%] [G loss: 1.149443]\n",
      "epoch:23 step:21837 [D loss: 0.362191, acc.: 90.62%] [G loss: 1.158296]\n",
      "epoch:23 step:21838 [D loss: 0.554371, acc.: 72.66%] [G loss: 1.265768]\n",
      "epoch:23 step:21839 [D loss: 0.562720, acc.: 76.56%] [G loss: 1.123097]\n",
      "epoch:23 step:21840 [D loss: 0.472205, acc.: 82.81%] [G loss: 1.134092]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21841 [D loss: 0.487021, acc.: 80.47%] [G loss: 0.969737]\n",
      "epoch:23 step:21842 [D loss: 0.453238, acc.: 81.25%] [G loss: 1.121241]\n",
      "epoch:23 step:21843 [D loss: 0.380272, acc.: 90.62%] [G loss: 1.528951]\n",
      "epoch:23 step:21844 [D loss: 0.467695, acc.: 77.34%] [G loss: 1.247219]\n",
      "epoch:23 step:21845 [D loss: 0.618821, acc.: 66.41%] [G loss: 1.327726]\n",
      "epoch:23 step:21846 [D loss: 0.757792, acc.: 51.56%] [G loss: 1.025745]\n",
      "epoch:23 step:21847 [D loss: 0.741806, acc.: 46.88%] [G loss: 0.597318]\n",
      "epoch:23 step:21848 [D loss: 0.735198, acc.: 51.56%] [G loss: 1.256932]\n",
      "epoch:23 step:21849 [D loss: 0.583689, acc.: 70.31%] [G loss: 1.122208]\n",
      "epoch:23 step:21850 [D loss: 0.691972, acc.: 52.34%] [G loss: 1.045562]\n",
      "epoch:23 step:21851 [D loss: 0.658929, acc.: 61.72%] [G loss: 0.947478]\n",
      "epoch:23 step:21852 [D loss: 0.671807, acc.: 59.38%] [G loss: 1.110782]\n",
      "epoch:23 step:21853 [D loss: 0.733007, acc.: 53.91%] [G loss: 0.937644]\n",
      "epoch:23 step:21854 [D loss: 0.643905, acc.: 60.16%] [G loss: 0.872585]\n",
      "epoch:23 step:21855 [D loss: 0.643548, acc.: 63.28%] [G loss: 1.065457]\n",
      "epoch:23 step:21856 [D loss: 0.599857, acc.: 71.88%] [G loss: 1.006267]\n",
      "epoch:23 step:21857 [D loss: 0.723672, acc.: 52.34%] [G loss: 0.864568]\n",
      "epoch:23 step:21858 [D loss: 0.686082, acc.: 53.12%] [G loss: 1.033376]\n",
      "epoch:23 step:21859 [D loss: 0.451898, acc.: 78.91%] [G loss: 1.093468]\n",
      "epoch:23 step:21860 [D loss: 0.439539, acc.: 85.16%] [G loss: 1.152255]\n",
      "epoch:23 step:21861 [D loss: 0.514704, acc.: 76.56%] [G loss: 1.335022]\n",
      "epoch:23 step:21862 [D loss: 0.527282, acc.: 75.78%] [G loss: 0.832898]\n",
      "epoch:23 step:21863 [D loss: 0.454920, acc.: 77.34%] [G loss: 1.054416]\n",
      "epoch:23 step:21864 [D loss: 0.387105, acc.: 83.59%] [G loss: 1.373585]\n",
      "epoch:23 step:21865 [D loss: 0.425812, acc.: 87.50%] [G loss: 1.231007]\n",
      "epoch:23 step:21866 [D loss: 0.734701, acc.: 49.22%] [G loss: 1.214459]\n",
      "epoch:23 step:21867 [D loss: 0.912431, acc.: 46.09%] [G loss: 1.377756]\n",
      "epoch:23 step:21868 [D loss: 0.950336, acc.: 41.41%] [G loss: 1.026110]\n",
      "epoch:23 step:21869 [D loss: 0.592048, acc.: 75.00%] [G loss: 1.032341]\n",
      "epoch:23 step:21870 [D loss: 0.661688, acc.: 61.72%] [G loss: 1.145643]\n",
      "epoch:23 step:21871 [D loss: 0.374525, acc.: 90.62%] [G loss: 1.325179]\n",
      "epoch:23 step:21872 [D loss: 0.321338, acc.: 93.75%] [G loss: 1.207912]\n",
      "epoch:23 step:21873 [D loss: 0.308042, acc.: 95.31%] [G loss: 1.683090]\n",
      "epoch:23 step:21874 [D loss: 0.591342, acc.: 67.19%] [G loss: 1.401027]\n",
      "epoch:23 step:21875 [D loss: 0.448973, acc.: 82.81%] [G loss: 1.389264]\n",
      "epoch:23 step:21876 [D loss: 0.401367, acc.: 90.62%] [G loss: 1.411563]\n",
      "epoch:23 step:21877 [D loss: 0.305396, acc.: 96.09%] [G loss: 1.464797]\n",
      "epoch:23 step:21878 [D loss: 0.259817, acc.: 92.97%] [G loss: 1.284096]\n",
      "epoch:23 step:21879 [D loss: 0.247354, acc.: 96.88%] [G loss: 1.641898]\n",
      "epoch:23 step:21880 [D loss: 0.435024, acc.: 86.72%] [G loss: 1.529168]\n",
      "epoch:23 step:21881 [D loss: 0.668053, acc.: 57.03%] [G loss: 1.273678]\n",
      "epoch:23 step:21882 [D loss: 0.564503, acc.: 71.88%] [G loss: 1.448147]\n",
      "epoch:23 step:21883 [D loss: 0.633685, acc.: 66.41%] [G loss: 0.902389]\n",
      "epoch:23 step:21884 [D loss: 0.795808, acc.: 51.56%] [G loss: 0.856473]\n",
      "epoch:23 step:21885 [D loss: 0.645528, acc.: 60.94%] [G loss: 1.184247]\n",
      "epoch:23 step:21886 [D loss: 0.585720, acc.: 73.44%] [G loss: 1.005174]\n",
      "epoch:23 step:21887 [D loss: 0.510367, acc.: 76.56%] [G loss: 0.954592]\n",
      "epoch:23 step:21888 [D loss: 0.481425, acc.: 84.38%] [G loss: 1.248186]\n",
      "epoch:23 step:21889 [D loss: 0.648591, acc.: 64.84%] [G loss: 0.909782]\n",
      "epoch:23 step:21890 [D loss: 0.426337, acc.: 85.94%] [G loss: 1.382497]\n",
      "epoch:23 step:21891 [D loss: 0.684586, acc.: 60.94%] [G loss: 0.803318]\n",
      "epoch:23 step:21892 [D loss: 1.022660, acc.: 23.44%] [G loss: 0.872550]\n",
      "epoch:23 step:21893 [D loss: 1.205435, acc.: 14.06%] [G loss: 0.998149]\n",
      "epoch:23 step:21894 [D loss: 0.719257, acc.: 53.91%] [G loss: 1.007388]\n",
      "epoch:23 step:21895 [D loss: 0.662672, acc.: 57.03%] [G loss: 1.132591]\n",
      "epoch:23 step:21896 [D loss: 0.452064, acc.: 82.81%] [G loss: 1.237702]\n",
      "epoch:23 step:21897 [D loss: 0.376307, acc.: 87.50%] [G loss: 1.081135]\n",
      "epoch:23 step:21898 [D loss: 0.308554, acc.: 94.53%] [G loss: 1.167611]\n",
      "epoch:23 step:21899 [D loss: 0.749066, acc.: 53.12%] [G loss: 1.296591]\n",
      "epoch:23 step:21900 [D loss: 0.683711, acc.: 62.50%] [G loss: 1.338141]\n",
      "epoch:23 step:21901 [D loss: 0.581140, acc.: 64.84%] [G loss: 1.082561]\n",
      "epoch:23 step:21902 [D loss: 0.501681, acc.: 82.81%] [G loss: 1.023789]\n",
      "epoch:23 step:21903 [D loss: 0.549124, acc.: 70.31%] [G loss: 0.828192]\n",
      "epoch:23 step:21904 [D loss: 0.602026, acc.: 70.31%] [G loss: 1.100244]\n",
      "epoch:23 step:21905 [D loss: 0.506121, acc.: 80.47%] [G loss: 1.251604]\n",
      "epoch:23 step:21906 [D loss: 0.827892, acc.: 39.84%] [G loss: 0.859032]\n",
      "epoch:23 step:21907 [D loss: 0.812706, acc.: 43.75%] [G loss: 0.976036]\n",
      "epoch:23 step:21908 [D loss: 0.606009, acc.: 63.28%] [G loss: 1.097692]\n",
      "epoch:23 step:21909 [D loss: 0.613868, acc.: 64.84%] [G loss: 0.952653]\n",
      "epoch:23 step:21910 [D loss: 0.555135, acc.: 76.56%] [G loss: 0.992932]\n",
      "epoch:23 step:21911 [D loss: 0.598436, acc.: 67.19%] [G loss: 1.203182]\n",
      "epoch:23 step:21912 [D loss: 0.705728, acc.: 56.25%] [G loss: 1.058874]\n",
      "epoch:23 step:21913 [D loss: 0.873450, acc.: 33.59%] [G loss: 0.845081]\n",
      "epoch:23 step:21914 [D loss: 0.413283, acc.: 87.50%] [G loss: 1.231808]\n",
      "epoch:23 step:21915 [D loss: 0.433439, acc.: 83.59%] [G loss: 1.225886]\n",
      "epoch:23 step:21916 [D loss: 0.396256, acc.: 91.41%] [G loss: 1.668027]\n",
      "epoch:23 step:21917 [D loss: 0.249689, acc.: 96.09%] [G loss: 1.633412]\n",
      "epoch:23 step:21918 [D loss: 0.261503, acc.: 95.31%] [G loss: 1.640088]\n",
      "epoch:23 step:21919 [D loss: 0.525942, acc.: 71.88%] [G loss: 1.775138]\n",
      "epoch:23 step:21920 [D loss: 0.807599, acc.: 50.00%] [G loss: 1.164400]\n",
      "epoch:23 step:21921 [D loss: 0.756140, acc.: 53.12%] [G loss: 0.922325]\n",
      "epoch:23 step:21922 [D loss: 0.716413, acc.: 50.00%] [G loss: 1.080540]\n",
      "epoch:23 step:21923 [D loss: 0.796362, acc.: 42.19%] [G loss: 0.976280]\n",
      "epoch:23 step:21924 [D loss: 0.636101, acc.: 66.41%] [G loss: 1.159299]\n",
      "epoch:23 step:21925 [D loss: 0.785373, acc.: 48.44%] [G loss: 0.817934]\n",
      "epoch:23 step:21926 [D loss: 0.637391, acc.: 64.84%] [G loss: 0.933182]\n",
      "epoch:23 step:21927 [D loss: 0.643627, acc.: 60.94%] [G loss: 1.023510]\n",
      "epoch:23 step:21928 [D loss: 0.443821, acc.: 89.06%] [G loss: 1.139147]\n",
      "epoch:23 step:21929 [D loss: 0.401902, acc.: 81.25%] [G loss: 1.128231]\n",
      "epoch:23 step:21930 [D loss: 0.690026, acc.: 56.25%] [G loss: 1.300469]\n",
      "epoch:23 step:21931 [D loss: 0.525264, acc.: 79.69%] [G loss: 1.337403]\n",
      "epoch:23 step:21932 [D loss: 0.553865, acc.: 75.00%] [G loss: 1.136242]\n",
      "epoch:23 step:21933 [D loss: 0.711648, acc.: 53.12%] [G loss: 0.968758]\n",
      "epoch:23 step:21934 [D loss: 0.851139, acc.: 42.19%] [G loss: 0.835471]\n",
      "epoch:23 step:21935 [D loss: 0.672332, acc.: 57.03%] [G loss: 1.116035]\n",
      "epoch:23 step:21936 [D loss: 0.632759, acc.: 59.38%] [G loss: 1.141116]\n",
      "epoch:23 step:21937 [D loss: 0.695011, acc.: 53.91%] [G loss: 1.102131]\n",
      "epoch:23 step:21938 [D loss: 0.645133, acc.: 61.72%] [G loss: 1.000820]\n",
      "epoch:23 step:21939 [D loss: 0.507758, acc.: 79.69%] [G loss: 1.281567]\n",
      "epoch:23 step:21940 [D loss: 0.694461, acc.: 54.69%] [G loss: 0.972608]\n",
      "epoch:23 step:21941 [D loss: 0.597760, acc.: 71.88%] [G loss: 0.989702]\n",
      "epoch:23 step:21942 [D loss: 0.495827, acc.: 82.03%] [G loss: 1.198875]\n",
      "epoch:23 step:21943 [D loss: 0.545889, acc.: 72.66%] [G loss: 1.243746]\n",
      "epoch:23 step:21944 [D loss: 0.697743, acc.: 62.50%] [G loss: 0.986631]\n",
      "epoch:23 step:21945 [D loss: 0.582394, acc.: 71.09%] [G loss: 0.765115]\n",
      "epoch:23 step:21946 [D loss: 0.721181, acc.: 54.69%] [G loss: 0.802406]\n",
      "epoch:23 step:21947 [D loss: 0.439088, acc.: 80.47%] [G loss: 1.205008]\n",
      "epoch:23 step:21948 [D loss: 0.270455, acc.: 95.31%] [G loss: 1.475903]\n",
      "epoch:23 step:21949 [D loss: 0.299634, acc.: 96.88%] [G loss: 1.571589]\n",
      "epoch:23 step:21950 [D loss: 0.357748, acc.: 89.06%] [G loss: 1.665471]\n",
      "epoch:23 step:21951 [D loss: 0.414405, acc.: 81.25%] [G loss: 1.305400]\n",
      "epoch:23 step:21952 [D loss: 0.432317, acc.: 85.94%] [G loss: 1.507931]\n",
      "epoch:23 step:21953 [D loss: 0.447759, acc.: 82.81%] [G loss: 1.528064]\n",
      "epoch:23 step:21954 [D loss: 0.497229, acc.: 74.22%] [G loss: 1.166773]\n",
      "epoch:23 step:21955 [D loss: 0.620474, acc.: 61.72%] [G loss: 0.979557]\n",
      "epoch:23 step:21956 [D loss: 0.369973, acc.: 88.28%] [G loss: 1.162129]\n",
      "epoch:23 step:21957 [D loss: 0.406952, acc.: 82.03%] [G loss: 1.926303]\n",
      "epoch:23 step:21958 [D loss: 0.455344, acc.: 81.25%] [G loss: 1.850453]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21959 [D loss: 0.790694, acc.: 55.47%] [G loss: 1.050544]\n",
      "epoch:23 step:21960 [D loss: 0.406885, acc.: 87.50%] [G loss: 1.258466]\n",
      "epoch:23 step:21961 [D loss: 0.677889, acc.: 57.03%] [G loss: 1.195755]\n",
      "epoch:23 step:21962 [D loss: 1.039849, acc.: 27.34%] [G loss: 0.579705]\n",
      "epoch:23 step:21963 [D loss: 0.743458, acc.: 54.69%] [G loss: 1.161630]\n",
      "epoch:23 step:21964 [D loss: 0.829792, acc.: 49.22%] [G loss: 0.826075]\n",
      "epoch:23 step:21965 [D loss: 0.983464, acc.: 35.16%] [G loss: 0.557464]\n",
      "epoch:23 step:21966 [D loss: 0.935559, acc.: 32.03%] [G loss: 0.743679]\n",
      "epoch:23 step:21967 [D loss: 0.839142, acc.: 43.75%] [G loss: 1.240340]\n",
      "epoch:23 step:21968 [D loss: 0.823374, acc.: 47.66%] [G loss: 1.263676]\n",
      "epoch:23 step:21969 [D loss: 0.676345, acc.: 58.59%] [G loss: 1.004127]\n",
      "epoch:23 step:21970 [D loss: 0.811275, acc.: 54.69%] [G loss: 0.944444]\n",
      "epoch:23 step:21971 [D loss: 0.676830, acc.: 57.03%] [G loss: 1.252467]\n",
      "epoch:23 step:21972 [D loss: 0.693605, acc.: 54.69%] [G loss: 1.391697]\n",
      "epoch:23 step:21973 [D loss: 0.707215, acc.: 48.44%] [G loss: 1.480969]\n",
      "epoch:23 step:21974 [D loss: 0.743078, acc.: 57.81%] [G loss: 1.508511]\n",
      "epoch:23 step:21975 [D loss: 0.734563, acc.: 49.22%] [G loss: 1.196777]\n",
      "epoch:23 step:21976 [D loss: 0.605045, acc.: 65.62%] [G loss: 1.221673]\n",
      "epoch:23 step:21977 [D loss: 0.630731, acc.: 64.06%] [G loss: 1.112138]\n",
      "epoch:23 step:21978 [D loss: 0.632220, acc.: 63.28%] [G loss: 1.121352]\n",
      "epoch:23 step:21979 [D loss: 0.596384, acc.: 66.41%] [G loss: 1.190294]\n",
      "epoch:23 step:21980 [D loss: 0.732251, acc.: 53.12%] [G loss: 1.309171]\n",
      "epoch:23 step:21981 [D loss: 0.622237, acc.: 66.41%] [G loss: 1.099458]\n",
      "epoch:23 step:21982 [D loss: 0.691719, acc.: 60.94%] [G loss: 0.911834]\n",
      "epoch:23 step:21983 [D loss: 0.432315, acc.: 88.28%] [G loss: 1.441526]\n",
      "epoch:23 step:21984 [D loss: 0.557532, acc.: 68.75%] [G loss: 1.454434]\n",
      "epoch:23 step:21985 [D loss: 0.501691, acc.: 76.56%] [G loss: 1.211177]\n",
      "epoch:23 step:21986 [D loss: 0.535074, acc.: 73.44%] [G loss: 1.377002]\n",
      "epoch:23 step:21987 [D loss: 0.401909, acc.: 89.06%] [G loss: 1.616643]\n",
      "epoch:23 step:21988 [D loss: 0.923677, acc.: 42.19%] [G loss: 1.102173]\n",
      "epoch:23 step:21989 [D loss: 0.674593, acc.: 58.59%] [G loss: 1.042797]\n",
      "epoch:23 step:21990 [D loss: 0.699491, acc.: 60.94%] [G loss: 0.955975]\n",
      "epoch:23 step:21991 [D loss: 0.736345, acc.: 54.69%] [G loss: 0.966643]\n",
      "epoch:23 step:21992 [D loss: 0.658173, acc.: 59.38%] [G loss: 1.125762]\n",
      "epoch:23 step:21993 [D loss: 0.589169, acc.: 68.75%] [G loss: 1.070767]\n",
      "epoch:23 step:21994 [D loss: 0.604828, acc.: 67.97%] [G loss: 0.980759]\n",
      "epoch:23 step:21995 [D loss: 0.648481, acc.: 63.28%] [G loss: 1.239425]\n",
      "epoch:23 step:21996 [D loss: 0.669271, acc.: 59.38%] [G loss: 1.064997]\n",
      "epoch:23 step:21997 [D loss: 0.899625, acc.: 37.50%] [G loss: 0.831254]\n",
      "epoch:23 step:21998 [D loss: 0.705509, acc.: 53.12%] [G loss: 1.072331]\n",
      "epoch:23 step:21999 [D loss: 0.582785, acc.: 65.62%] [G loss: 1.224247]\n",
      "epoch:23 step:22000 [D loss: 0.534761, acc.: 73.44%] [G loss: 1.204450]\n",
      "##############\n",
      "[2.38301901 1.53734065 5.53319686 4.65814768 2.89567717 5.40543784\n",
      " 4.1503184  4.21954176 4.29376775 3.61207432]\n",
      "##########\n",
      "epoch:23 step:22001 [D loss: 0.646230, acc.: 67.97%] [G loss: 0.957136]\n",
      "epoch:23 step:22002 [D loss: 0.568842, acc.: 71.09%] [G loss: 1.203333]\n",
      "epoch:23 step:22003 [D loss: 0.516245, acc.: 74.22%] [G loss: 1.336473]\n",
      "epoch:23 step:22004 [D loss: 0.656858, acc.: 59.38%] [G loss: 1.256079]\n",
      "epoch:23 step:22005 [D loss: 0.476236, acc.: 79.69%] [G loss: 1.498978]\n",
      "epoch:23 step:22006 [D loss: 0.634087, acc.: 63.28%] [G loss: 0.989666]\n",
      "epoch:23 step:22007 [D loss: 0.475983, acc.: 80.47%] [G loss: 1.147349]\n",
      "epoch:23 step:22008 [D loss: 0.431390, acc.: 85.16%] [G loss: 1.381008]\n",
      "epoch:23 step:22009 [D loss: 0.887379, acc.: 39.84%] [G loss: 0.997289]\n",
      "epoch:23 step:22010 [D loss: 0.812869, acc.: 48.44%] [G loss: 0.728197]\n",
      "epoch:23 step:22011 [D loss: 0.767028, acc.: 46.88%] [G loss: 1.055113]\n",
      "epoch:23 step:22012 [D loss: 0.877757, acc.: 34.38%] [G loss: 1.041913]\n",
      "epoch:23 step:22013 [D loss: 0.538395, acc.: 72.66%] [G loss: 1.345744]\n",
      "epoch:23 step:22014 [D loss: 0.579389, acc.: 66.41%] [G loss: 1.440480]\n",
      "epoch:23 step:22015 [D loss: 0.713489, acc.: 57.03%] [G loss: 1.148804]\n",
      "epoch:23 step:22016 [D loss: 0.616454, acc.: 64.84%] [G loss: 0.887355]\n",
      "epoch:23 step:22017 [D loss: 0.428648, acc.: 89.84%] [G loss: 1.286873]\n",
      "epoch:23 step:22018 [D loss: 0.558524, acc.: 70.31%] [G loss: 0.956884]\n",
      "epoch:23 step:22019 [D loss: 0.547529, acc.: 75.78%] [G loss: 1.183533]\n",
      "epoch:23 step:22020 [D loss: 0.510629, acc.: 74.22%] [G loss: 1.203017]\n",
      "epoch:23 step:22021 [D loss: 0.439248, acc.: 86.72%] [G loss: 1.225135]\n",
      "epoch:23 step:22022 [D loss: 0.249723, acc.: 96.88%] [G loss: 1.463815]\n",
      "epoch:23 step:22023 [D loss: 0.458004, acc.: 84.38%] [G loss: 1.715014]\n",
      "epoch:23 step:22024 [D loss: 0.662107, acc.: 60.94%] [G loss: 1.140516]\n",
      "epoch:23 step:22025 [D loss: 0.368310, acc.: 91.41%] [G loss: 1.368334]\n",
      "epoch:23 step:22026 [D loss: 0.411458, acc.: 88.28%] [G loss: 1.440009]\n",
      "epoch:23 step:22027 [D loss: 0.693324, acc.: 57.81%] [G loss: 1.337822]\n",
      "epoch:23 step:22028 [D loss: 0.660872, acc.: 63.28%] [G loss: 1.102272]\n",
      "epoch:23 step:22029 [D loss: 0.620216, acc.: 61.72%] [G loss: 1.129154]\n",
      "epoch:23 step:22030 [D loss: 0.556215, acc.: 71.09%] [G loss: 0.867244]\n",
      "epoch:23 step:22031 [D loss: 0.710119, acc.: 54.69%] [G loss: 1.093691]\n",
      "epoch:23 step:22032 [D loss: 0.627438, acc.: 64.84%] [G loss: 1.133498]\n",
      "epoch:23 step:22033 [D loss: 0.538084, acc.: 75.78%] [G loss: 1.196715]\n",
      "epoch:23 step:22034 [D loss: 0.472303, acc.: 82.03%] [G loss: 1.345215]\n",
      "epoch:23 step:22035 [D loss: 0.280669, acc.: 97.66%] [G loss: 1.565533]\n",
      "epoch:23 step:22036 [D loss: 0.516552, acc.: 75.00%] [G loss: 1.236349]\n",
      "epoch:23 step:22037 [D loss: 0.604539, acc.: 64.84%] [G loss: 0.846107]\n",
      "epoch:23 step:22038 [D loss: 0.522183, acc.: 74.22%] [G loss: 1.050265]\n",
      "epoch:23 step:22039 [D loss: 0.559008, acc.: 71.09%] [G loss: 1.262811]\n",
      "epoch:23 step:22040 [D loss: 0.713224, acc.: 54.69%] [G loss: 1.234240]\n",
      "epoch:23 step:22041 [D loss: 0.452220, acc.: 87.50%] [G loss: 1.193687]\n",
      "epoch:23 step:22042 [D loss: 0.596693, acc.: 71.09%] [G loss: 1.322290]\n",
      "epoch:23 step:22043 [D loss: 0.572347, acc.: 77.34%] [G loss: 1.115930]\n",
      "epoch:23 step:22044 [D loss: 0.685334, acc.: 57.03%] [G loss: 1.213602]\n",
      "epoch:23 step:22045 [D loss: 0.568846, acc.: 72.66%] [G loss: 1.022238]\n",
      "epoch:23 step:22046 [D loss: 0.631340, acc.: 64.84%] [G loss: 0.928629]\n",
      "epoch:23 step:22047 [D loss: 0.637664, acc.: 66.41%] [G loss: 1.121509]\n",
      "epoch:23 step:22048 [D loss: 0.398463, acc.: 83.59%] [G loss: 1.369804]\n",
      "epoch:23 step:22049 [D loss: 0.306111, acc.: 96.09%] [G loss: 1.297720]\n",
      "epoch:23 step:22050 [D loss: 0.259135, acc.: 94.53%] [G loss: 1.627847]\n",
      "epoch:23 step:22051 [D loss: 0.790790, acc.: 51.56%] [G loss: 1.229719]\n",
      "epoch:23 step:22052 [D loss: 0.892945, acc.: 33.59%] [G loss: 0.808754]\n",
      "epoch:23 step:22053 [D loss: 0.720813, acc.: 54.69%] [G loss: 1.146739]\n",
      "epoch:23 step:22054 [D loss: 0.329180, acc.: 91.41%] [G loss: 1.227238]\n",
      "epoch:23 step:22055 [D loss: 0.273691, acc.: 96.88%] [G loss: 1.311828]\n",
      "epoch:23 step:22056 [D loss: 0.370021, acc.: 91.41%] [G loss: 1.468797]\n",
      "epoch:23 step:22057 [D loss: 0.528831, acc.: 77.34%] [G loss: 1.283062]\n",
      "epoch:23 step:22058 [D loss: 0.431863, acc.: 81.25%] [G loss: 1.319420]\n",
      "epoch:23 step:22059 [D loss: 0.354775, acc.: 89.06%] [G loss: 1.150578]\n",
      "epoch:23 step:22060 [D loss: 0.880630, acc.: 44.53%] [G loss: 1.046148]\n",
      "epoch:23 step:22061 [D loss: 0.694930, acc.: 53.91%] [G loss: 1.357688]\n",
      "epoch:23 step:22062 [D loss: 0.402197, acc.: 89.06%] [G loss: 1.075844]\n",
      "epoch:23 step:22063 [D loss: 0.500165, acc.: 80.47%] [G loss: 1.108463]\n",
      "epoch:23 step:22064 [D loss: 0.371152, acc.: 89.84%] [G loss: 1.176693]\n",
      "epoch:23 step:22065 [D loss: 0.395130, acc.: 89.06%] [G loss: 1.456033]\n",
      "epoch:23 step:22066 [D loss: 0.542288, acc.: 74.22%] [G loss: 1.140085]\n",
      "epoch:23 step:22067 [D loss: 0.571832, acc.: 73.44%] [G loss: 0.982313]\n",
      "epoch:23 step:22068 [D loss: 0.541953, acc.: 72.66%] [G loss: 1.176560]\n",
      "epoch:23 step:22069 [D loss: 0.480314, acc.: 83.59%] [G loss: 1.294492]\n",
      "epoch:23 step:22070 [D loss: 0.394507, acc.: 92.19%] [G loss: 1.297988]\n",
      "epoch:23 step:22071 [D loss: 0.442233, acc.: 86.72%] [G loss: 1.414500]\n",
      "epoch:23 step:22072 [D loss: 0.617873, acc.: 68.75%] [G loss: 1.094167]\n",
      "epoch:23 step:22073 [D loss: 0.424143, acc.: 86.72%] [G loss: 1.130849]\n",
      "epoch:23 step:22074 [D loss: 0.452725, acc.: 80.47%] [G loss: 1.396788]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22075 [D loss: 0.662896, acc.: 60.94%] [G loss: 1.337370]\n",
      "epoch:23 step:22076 [D loss: 0.681120, acc.: 56.25%] [G loss: 1.079212]\n",
      "epoch:23 step:22077 [D loss: 0.561345, acc.: 71.09%] [G loss: 1.118179]\n",
      "epoch:23 step:22078 [D loss: 0.767587, acc.: 51.56%] [G loss: 0.846307]\n",
      "epoch:23 step:22079 [D loss: 0.778835, acc.: 46.09%] [G loss: 0.962601]\n",
      "epoch:23 step:22080 [D loss: 0.631250, acc.: 64.06%] [G loss: 0.984826]\n",
      "epoch:23 step:22081 [D loss: 0.581708, acc.: 71.88%] [G loss: 1.147044]\n",
      "epoch:23 step:22082 [D loss: 0.637821, acc.: 64.84%] [G loss: 1.009471]\n",
      "epoch:23 step:22083 [D loss: 0.489210, acc.: 78.12%] [G loss: 1.400056]\n",
      "epoch:23 step:22084 [D loss: 0.237290, acc.: 97.66%] [G loss: 1.569419]\n",
      "epoch:23 step:22085 [D loss: 0.354946, acc.: 92.97%] [G loss: 1.430434]\n",
      "epoch:23 step:22086 [D loss: 0.676414, acc.: 60.94%] [G loss: 1.310097]\n",
      "epoch:23 step:22087 [D loss: 0.470314, acc.: 82.81%] [G loss: 1.196008]\n",
      "epoch:23 step:22088 [D loss: 0.505237, acc.: 75.78%] [G loss: 1.185344]\n",
      "epoch:23 step:22089 [D loss: 0.745806, acc.: 50.78%] [G loss: 1.123945]\n",
      "epoch:23 step:22090 [D loss: 0.508403, acc.: 81.25%] [G loss: 1.135319]\n",
      "epoch:23 step:22091 [D loss: 0.652455, acc.: 57.81%] [G loss: 0.847858]\n",
      "epoch:23 step:22092 [D loss: 0.662429, acc.: 60.94%] [G loss: 1.092168]\n",
      "epoch:23 step:22093 [D loss: 0.480423, acc.: 82.03%] [G loss: 1.328793]\n",
      "epoch:23 step:22094 [D loss: 0.432759, acc.: 82.81%] [G loss: 1.198053]\n",
      "epoch:23 step:22095 [D loss: 0.419594, acc.: 85.94%] [G loss: 1.126720]\n",
      "epoch:23 step:22096 [D loss: 0.323420, acc.: 92.97%] [G loss: 1.101259]\n",
      "epoch:23 step:22097 [D loss: 0.382605, acc.: 82.81%] [G loss: 1.491669]\n",
      "epoch:23 step:22098 [D loss: 0.345673, acc.: 95.31%] [G loss: 1.653985]\n",
      "epoch:23 step:22099 [D loss: 0.438611, acc.: 85.16%] [G loss: 1.530952]\n",
      "epoch:23 step:22100 [D loss: 0.273919, acc.: 97.66%] [G loss: 1.455856]\n",
      "epoch:23 step:22101 [D loss: 0.267606, acc.: 95.31%] [G loss: 1.648560]\n",
      "epoch:23 step:22102 [D loss: 0.281348, acc.: 94.53%] [G loss: 1.423962]\n",
      "epoch:23 step:22103 [D loss: 0.405973, acc.: 86.72%] [G loss: 1.395376]\n",
      "epoch:23 step:22104 [D loss: 0.414920, acc.: 86.72%] [G loss: 1.355258]\n",
      "epoch:23 step:22105 [D loss: 0.420215, acc.: 79.69%] [G loss: 1.519231]\n",
      "epoch:23 step:22106 [D loss: 0.317078, acc.: 94.53%] [G loss: 1.727285]\n",
      "epoch:23 step:22107 [D loss: 0.487503, acc.: 82.81%] [G loss: 1.519416]\n",
      "epoch:23 step:22108 [D loss: 0.619657, acc.: 67.19%] [G loss: 1.120573]\n",
      "epoch:23 step:22109 [D loss: 0.631250, acc.: 60.16%] [G loss: 1.127746]\n",
      "epoch:23 step:22110 [D loss: 1.009719, acc.: 42.97%] [G loss: 1.415734]\n",
      "epoch:23 step:22111 [D loss: 0.848601, acc.: 52.34%] [G loss: 1.647004]\n",
      "epoch:23 step:22112 [D loss: 0.543476, acc.: 74.22%] [G loss: 1.300488]\n",
      "epoch:23 step:22113 [D loss: 0.698047, acc.: 57.03%] [G loss: 1.368889]\n",
      "epoch:23 step:22114 [D loss: 0.631254, acc.: 69.53%] [G loss: 1.259742]\n",
      "epoch:23 step:22115 [D loss: 0.480873, acc.: 82.03%] [G loss: 1.412630]\n",
      "epoch:23 step:22116 [D loss: 0.446198, acc.: 82.03%] [G loss: 1.353502]\n",
      "epoch:23 step:22117 [D loss: 0.280620, acc.: 96.09%] [G loss: 1.257891]\n",
      "epoch:23 step:22118 [D loss: 0.328548, acc.: 92.97%] [G loss: 1.740726]\n",
      "epoch:23 step:22119 [D loss: 0.678844, acc.: 61.72%] [G loss: 1.363948]\n",
      "epoch:23 step:22120 [D loss: 0.646508, acc.: 58.59%] [G loss: 1.216125]\n",
      "epoch:23 step:22121 [D loss: 0.620034, acc.: 65.62%] [G loss: 1.015316]\n",
      "epoch:23 step:22122 [D loss: 0.596152, acc.: 64.06%] [G loss: 1.054293]\n",
      "epoch:23 step:22123 [D loss: 0.508056, acc.: 75.78%] [G loss: 1.306630]\n",
      "epoch:23 step:22124 [D loss: 0.432208, acc.: 82.81%] [G loss: 1.365648]\n",
      "epoch:23 step:22125 [D loss: 0.414986, acc.: 88.28%] [G loss: 1.362061]\n",
      "epoch:23 step:22126 [D loss: 0.657905, acc.: 63.28%] [G loss: 1.133421]\n",
      "epoch:23 step:22127 [D loss: 0.415492, acc.: 87.50%] [G loss: 1.768065]\n",
      "epoch:23 step:22128 [D loss: 0.447529, acc.: 85.16%] [G loss: 1.714957]\n",
      "epoch:23 step:22129 [D loss: 0.305358, acc.: 95.31%] [G loss: 1.466215]\n",
      "epoch:23 step:22130 [D loss: 0.408164, acc.: 89.84%] [G loss: 1.398820]\n",
      "epoch:23 step:22131 [D loss: 0.651598, acc.: 64.84%] [G loss: 1.085298]\n",
      "epoch:23 step:22132 [D loss: 0.694187, acc.: 57.81%] [G loss: 0.762471]\n",
      "epoch:23 step:22133 [D loss: 0.989078, acc.: 23.44%] [G loss: 0.983863]\n",
      "epoch:23 step:22134 [D loss: 0.720507, acc.: 57.03%] [G loss: 0.963819]\n",
      "epoch:23 step:22135 [D loss: 0.697007, acc.: 60.16%] [G loss: 0.775090]\n",
      "epoch:23 step:22136 [D loss: 0.686580, acc.: 62.50%] [G loss: 0.941000]\n",
      "epoch:23 step:22137 [D loss: 0.536351, acc.: 75.00%] [G loss: 0.974783]\n",
      "epoch:23 step:22138 [D loss: 0.494997, acc.: 72.66%] [G loss: 1.238191]\n",
      "epoch:23 step:22139 [D loss: 0.415861, acc.: 85.94%] [G loss: 1.305751]\n",
      "epoch:23 step:22140 [D loss: 0.319887, acc.: 95.31%] [G loss: 1.876345]\n",
      "epoch:23 step:22141 [D loss: 0.848448, acc.: 53.91%] [G loss: 1.487120]\n",
      "epoch:23 step:22142 [D loss: 1.218552, acc.: 17.97%] [G loss: 0.901105]\n",
      "epoch:23 step:22143 [D loss: 0.620912, acc.: 61.72%] [G loss: 1.363996]\n",
      "epoch:23 step:22144 [D loss: 0.703429, acc.: 55.47%] [G loss: 1.461675]\n",
      "epoch:23 step:22145 [D loss: 0.585543, acc.: 70.31%] [G loss: 1.083689]\n",
      "epoch:23 step:22146 [D loss: 0.416885, acc.: 84.38%] [G loss: 1.485795]\n",
      "epoch:23 step:22147 [D loss: 0.732976, acc.: 51.56%] [G loss: 0.979901]\n",
      "epoch:23 step:22148 [D loss: 0.652023, acc.: 64.06%] [G loss: 1.202819]\n",
      "epoch:23 step:22149 [D loss: 0.339239, acc.: 89.06%] [G loss: 1.269641]\n",
      "epoch:23 step:22150 [D loss: 0.558060, acc.: 70.31%] [G loss: 1.352848]\n",
      "epoch:23 step:22151 [D loss: 0.643651, acc.: 60.94%] [G loss: 1.197490]\n",
      "epoch:23 step:22152 [D loss: 0.566286, acc.: 73.44%] [G loss: 1.044238]\n",
      "epoch:23 step:22153 [D loss: 0.511877, acc.: 75.00%] [G loss: 0.941295]\n",
      "epoch:23 step:22154 [D loss: 0.308165, acc.: 89.06%] [G loss: 1.295147]\n",
      "epoch:23 step:22155 [D loss: 0.272791, acc.: 94.53%] [G loss: 1.631925]\n",
      "epoch:23 step:22156 [D loss: 0.277920, acc.: 95.31%] [G loss: 1.621548]\n",
      "epoch:23 step:22157 [D loss: 0.493797, acc.: 71.88%] [G loss: 1.582983]\n",
      "epoch:23 step:22158 [D loss: 0.652523, acc.: 64.84%] [G loss: 1.219165]\n",
      "epoch:23 step:22159 [D loss: 0.493770, acc.: 76.56%] [G loss: 1.703297]\n",
      "epoch:23 step:22160 [D loss: 0.557261, acc.: 69.53%] [G loss: 1.318393]\n",
      "epoch:23 step:22161 [D loss: 0.628899, acc.: 63.28%] [G loss: 1.305646]\n",
      "epoch:23 step:22162 [D loss: 0.749277, acc.: 46.88%] [G loss: 1.168718]\n",
      "epoch:23 step:22163 [D loss: 0.683138, acc.: 59.38%] [G loss: 1.164966]\n",
      "epoch:23 step:22164 [D loss: 0.325873, acc.: 88.28%] [G loss: 1.833078]\n",
      "epoch:23 step:22165 [D loss: 0.297771, acc.: 91.41%] [G loss: 1.618613]\n",
      "epoch:23 step:22166 [D loss: 0.284737, acc.: 93.75%] [G loss: 1.515153]\n",
      "epoch:23 step:22167 [D loss: 0.256535, acc.: 94.53%] [G loss: 1.710982]\n",
      "epoch:23 step:22168 [D loss: 0.530446, acc.: 75.78%] [G loss: 1.205557]\n",
      "epoch:23 step:22169 [D loss: 1.003792, acc.: 35.94%] [G loss: 1.087061]\n",
      "epoch:23 step:22170 [D loss: 1.103123, acc.: 25.00%] [G loss: 0.873244]\n",
      "epoch:23 step:22171 [D loss: 0.876152, acc.: 35.16%] [G loss: 0.982307]\n",
      "epoch:23 step:22172 [D loss: 1.174364, acc.: 16.41%] [G loss: 0.826313]\n",
      "epoch:23 step:22173 [D loss: 0.689918, acc.: 57.81%] [G loss: 1.246032]\n",
      "epoch:23 step:22174 [D loss: 0.634324, acc.: 64.06%] [G loss: 1.321136]\n",
      "epoch:23 step:22175 [D loss: 0.625047, acc.: 64.84%] [G loss: 1.313193]\n",
      "epoch:23 step:22176 [D loss: 0.713309, acc.: 54.69%] [G loss: 1.570088]\n",
      "epoch:23 step:22177 [D loss: 0.619351, acc.: 67.97%] [G loss: 1.129472]\n",
      "epoch:23 step:22178 [D loss: 0.793095, acc.: 50.00%] [G loss: 0.702535]\n",
      "epoch:23 step:22179 [D loss: 0.700193, acc.: 54.69%] [G loss: 0.944876]\n",
      "epoch:23 step:22180 [D loss: 0.412924, acc.: 85.16%] [G loss: 1.330027]\n",
      "epoch:23 step:22181 [D loss: 0.563125, acc.: 75.00%] [G loss: 1.083529]\n",
      "epoch:23 step:22182 [D loss: 0.740413, acc.: 52.34%] [G loss: 1.095510]\n",
      "epoch:23 step:22183 [D loss: 0.581564, acc.: 71.09%] [G loss: 1.366268]\n",
      "epoch:23 step:22184 [D loss: 0.561689, acc.: 68.75%] [G loss: 1.332905]\n",
      "epoch:23 step:22185 [D loss: 0.596626, acc.: 67.97%] [G loss: 1.469981]\n",
      "epoch:23 step:22186 [D loss: 0.566687, acc.: 72.66%] [G loss: 1.299601]\n",
      "epoch:23 step:22187 [D loss: 0.560642, acc.: 67.97%] [G loss: 1.427761]\n",
      "epoch:23 step:22188 [D loss: 0.885733, acc.: 39.06%] [G loss: 0.744123]\n",
      "epoch:23 step:22189 [D loss: 0.597712, acc.: 66.41%] [G loss: 1.087780]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22190 [D loss: 0.646890, acc.: 63.28%] [G loss: 1.433571]\n",
      "epoch:23 step:22191 [D loss: 0.349272, acc.: 90.62%] [G loss: 1.538926]\n",
      "epoch:23 step:22192 [D loss: 0.342630, acc.: 94.53%] [G loss: 1.785172]\n",
      "epoch:23 step:22193 [D loss: 0.329416, acc.: 91.41%] [G loss: 1.889821]\n",
      "epoch:23 step:22194 [D loss: 0.692980, acc.: 56.25%] [G loss: 1.388392]\n",
      "epoch:23 step:22195 [D loss: 0.788880, acc.: 46.09%] [G loss: 1.171863]\n",
      "epoch:23 step:22196 [D loss: 0.630097, acc.: 64.84%] [G loss: 1.027737]\n",
      "epoch:23 step:22197 [D loss: 0.641134, acc.: 62.50%] [G loss: 1.108500]\n",
      "epoch:23 step:22198 [D loss: 0.509916, acc.: 76.56%] [G loss: 1.606080]\n",
      "epoch:23 step:22199 [D loss: 0.471768, acc.: 82.81%] [G loss: 1.207390]\n",
      "epoch:23 step:22200 [D loss: 0.466749, acc.: 81.25%] [G loss: 1.201625]\n",
      "##############\n",
      "[2.42973873 1.38247118 5.66036896 4.12895995 3.03862924 5.52074826\n",
      " 4.2629561  4.74008652 3.77467286 3.82051098]\n",
      "##########\n",
      "epoch:23 step:22201 [D loss: 0.664384, acc.: 60.94%] [G loss: 0.798571]\n",
      "epoch:23 step:22202 [D loss: 0.469017, acc.: 82.81%] [G loss: 1.312676]\n",
      "epoch:23 step:22203 [D loss: 0.741755, acc.: 50.78%] [G loss: 1.021152]\n",
      "epoch:23 step:22204 [D loss: 0.470712, acc.: 82.81%] [G loss: 1.250639]\n",
      "epoch:23 step:22205 [D loss: 0.518634, acc.: 77.34%] [G loss: 0.970870]\n",
      "epoch:23 step:22206 [D loss: 0.618294, acc.: 68.75%] [G loss: 1.006264]\n",
      "epoch:23 step:22207 [D loss: 0.575850, acc.: 72.66%] [G loss: 1.094557]\n",
      "epoch:23 step:22208 [D loss: 0.791731, acc.: 46.88%] [G loss: 0.930078]\n",
      "epoch:23 step:22209 [D loss: 0.522155, acc.: 76.56%] [G loss: 0.980820]\n",
      "epoch:23 step:22210 [D loss: 0.639048, acc.: 60.94%] [G loss: 1.080026]\n",
      "epoch:23 step:22211 [D loss: 0.486271, acc.: 84.38%] [G loss: 1.284287]\n",
      "epoch:23 step:22212 [D loss: 0.685450, acc.: 57.03%] [G loss: 0.836613]\n",
      "epoch:23 step:22213 [D loss: 0.396246, acc.: 88.28%] [G loss: 1.381971]\n",
      "epoch:23 step:22214 [D loss: 0.418934, acc.: 76.56%] [G loss: 1.176005]\n",
      "epoch:23 step:22215 [D loss: 0.236828, acc.: 95.31%] [G loss: 1.808313]\n",
      "epoch:23 step:22216 [D loss: 0.287149, acc.: 94.53%] [G loss: 1.536764]\n",
      "epoch:23 step:22217 [D loss: 0.347652, acc.: 88.28%] [G loss: 2.271566]\n",
      "epoch:23 step:22218 [D loss: 0.517936, acc.: 74.22%] [G loss: 1.272520]\n",
      "epoch:23 step:22219 [D loss: 0.717056, acc.: 52.34%] [G loss: 1.088176]\n",
      "epoch:23 step:22220 [D loss: 0.544866, acc.: 73.44%] [G loss: 1.187851]\n",
      "epoch:23 step:22221 [D loss: 0.608987, acc.: 61.72%] [G loss: 1.228865]\n",
      "epoch:23 step:22222 [D loss: 0.567873, acc.: 69.53%] [G loss: 0.954672]\n",
      "epoch:23 step:22223 [D loss: 0.772148, acc.: 47.66%] [G loss: 0.762219]\n",
      "epoch:23 step:22224 [D loss: 0.835310, acc.: 45.31%] [G loss: 1.108773]\n",
      "epoch:23 step:22225 [D loss: 0.766407, acc.: 53.12%] [G loss: 0.614297]\n",
      "epoch:23 step:22226 [D loss: 0.687336, acc.: 53.12%] [G loss: 0.989477]\n",
      "epoch:23 step:22227 [D loss: 0.761882, acc.: 53.12%] [G loss: 0.853494]\n",
      "epoch:23 step:22228 [D loss: 0.625098, acc.: 64.84%] [G loss: 1.231636]\n",
      "epoch:23 step:22229 [D loss: 0.891983, acc.: 32.03%] [G loss: 1.026499]\n",
      "epoch:23 step:22230 [D loss: 0.644678, acc.: 67.19%] [G loss: 0.885575]\n",
      "epoch:23 step:22231 [D loss: 0.625911, acc.: 61.72%] [G loss: 0.923309]\n",
      "epoch:23 step:22232 [D loss: 0.791319, acc.: 50.00%] [G loss: 0.858887]\n",
      "epoch:23 step:22233 [D loss: 0.651440, acc.: 62.50%] [G loss: 0.973601]\n",
      "epoch:23 step:22234 [D loss: 0.687716, acc.: 57.03%] [G loss: 1.265227]\n",
      "epoch:23 step:22235 [D loss: 0.869210, acc.: 42.19%] [G loss: 0.931834]\n",
      "epoch:23 step:22236 [D loss: 0.682676, acc.: 58.59%] [G loss: 1.127110]\n",
      "epoch:23 step:22237 [D loss: 0.553093, acc.: 69.53%] [G loss: 1.398110]\n",
      "epoch:23 step:22238 [D loss: 0.606638, acc.: 70.31%] [G loss: 1.205031]\n",
      "epoch:23 step:22239 [D loss: 0.503392, acc.: 80.47%] [G loss: 1.375986]\n",
      "epoch:23 step:22240 [D loss: 0.518909, acc.: 78.91%] [G loss: 1.415493]\n",
      "epoch:23 step:22241 [D loss: 0.348894, acc.: 87.50%] [G loss: 1.503321]\n",
      "epoch:23 step:22242 [D loss: 0.341951, acc.: 93.75%] [G loss: 1.959132]\n",
      "epoch:23 step:22243 [D loss: 0.416349, acc.: 82.81%] [G loss: 1.599921]\n",
      "epoch:23 step:22244 [D loss: 0.399943, acc.: 87.50%] [G loss: 1.358176]\n",
      "epoch:23 step:22245 [D loss: 0.309337, acc.: 90.62%] [G loss: 1.410283]\n",
      "epoch:23 step:22246 [D loss: 0.552562, acc.: 75.00%] [G loss: 1.077665]\n",
      "epoch:23 step:22247 [D loss: 0.718171, acc.: 64.06%] [G loss: 1.346038]\n",
      "epoch:23 step:22248 [D loss: 0.811418, acc.: 44.53%] [G loss: 0.916385]\n",
      "epoch:23 step:22249 [D loss: 0.829213, acc.: 46.88%] [G loss: 0.649011]\n",
      "epoch:23 step:22250 [D loss: 0.594701, acc.: 66.41%] [G loss: 0.917349]\n",
      "epoch:23 step:22251 [D loss: 0.640405, acc.: 66.41%] [G loss: 0.964441]\n",
      "epoch:23 step:22252 [D loss: 0.703596, acc.: 54.69%] [G loss: 0.953715]\n",
      "epoch:23 step:22253 [D loss: 0.685784, acc.: 55.47%] [G loss: 1.243551]\n",
      "epoch:23 step:22254 [D loss: 0.684251, acc.: 60.94%] [G loss: 1.091506]\n",
      "epoch:23 step:22255 [D loss: 0.717893, acc.: 53.12%] [G loss: 1.013091]\n",
      "epoch:23 step:22256 [D loss: 0.684091, acc.: 50.00%] [G loss: 0.979489]\n",
      "epoch:23 step:22257 [D loss: 0.472857, acc.: 78.91%] [G loss: 1.134080]\n",
      "epoch:23 step:22258 [D loss: 0.478478, acc.: 84.38%] [G loss: 1.330387]\n",
      "epoch:23 step:22259 [D loss: 0.556641, acc.: 72.66%] [G loss: 1.057846]\n",
      "epoch:23 step:22260 [D loss: 0.410864, acc.: 88.28%] [G loss: 1.343014]\n",
      "epoch:23 step:22261 [D loss: 0.520648, acc.: 74.22%] [G loss: 1.253231]\n",
      "epoch:23 step:22262 [D loss: 0.609390, acc.: 67.19%] [G loss: 1.027924]\n",
      "epoch:23 step:22263 [D loss: 0.528129, acc.: 71.09%] [G loss: 1.441410]\n",
      "epoch:23 step:22264 [D loss: 0.573899, acc.: 64.06%] [G loss: 1.007073]\n",
      "epoch:23 step:22265 [D loss: 0.407194, acc.: 85.16%] [G loss: 0.987477]\n",
      "epoch:23 step:22266 [D loss: 0.729133, acc.: 59.38%] [G loss: 1.170398]\n",
      "epoch:23 step:22267 [D loss: 0.708211, acc.: 60.94%] [G loss: 1.012535]\n",
      "epoch:23 step:22268 [D loss: 0.676612, acc.: 65.62%] [G loss: 0.855008]\n",
      "epoch:23 step:22269 [D loss: 0.733986, acc.: 53.12%] [G loss: 0.951016]\n",
      "epoch:23 step:22270 [D loss: 0.575129, acc.: 73.44%] [G loss: 1.145163]\n",
      "epoch:23 step:22271 [D loss: 0.417152, acc.: 86.72%] [G loss: 1.032728]\n",
      "epoch:23 step:22272 [D loss: 0.663732, acc.: 64.06%] [G loss: 0.958288]\n",
      "epoch:23 step:22273 [D loss: 0.881536, acc.: 35.16%] [G loss: 0.911958]\n",
      "epoch:23 step:22274 [D loss: 0.550629, acc.: 71.88%] [G loss: 1.366466]\n",
      "epoch:23 step:22275 [D loss: 0.424343, acc.: 85.16%] [G loss: 1.235257]\n",
      "epoch:23 step:22276 [D loss: 0.437450, acc.: 84.38%] [G loss: 1.446224]\n",
      "epoch:23 step:22277 [D loss: 0.722631, acc.: 53.91%] [G loss: 1.038785]\n",
      "epoch:23 step:22278 [D loss: 0.602690, acc.: 63.28%] [G loss: 1.079684]\n",
      "epoch:23 step:22279 [D loss: 0.612082, acc.: 63.28%] [G loss: 1.140097]\n",
      "epoch:23 step:22280 [D loss: 0.581232, acc.: 67.19%] [G loss: 1.418512]\n",
      "epoch:23 step:22281 [D loss: 0.581786, acc.: 72.66%] [G loss: 1.011986]\n",
      "epoch:23 step:22282 [D loss: 0.370783, acc.: 92.97%] [G loss: 1.244398]\n",
      "epoch:23 step:22283 [D loss: 0.458252, acc.: 84.38%] [G loss: 1.365044]\n",
      "epoch:23 step:22284 [D loss: 0.391875, acc.: 89.84%] [G loss: 1.432606]\n",
      "epoch:23 step:22285 [D loss: 0.637976, acc.: 64.84%] [G loss: 1.196700]\n",
      "epoch:23 step:22286 [D loss: 0.786978, acc.: 49.22%] [G loss: 0.819283]\n",
      "epoch:23 step:22287 [D loss: 0.781162, acc.: 48.44%] [G loss: 1.015964]\n",
      "epoch:23 step:22288 [D loss: 0.642623, acc.: 55.47%] [G loss: 0.993830]\n",
      "epoch:23 step:22289 [D loss: 0.709209, acc.: 49.22%] [G loss: 1.072805]\n",
      "epoch:23 step:22290 [D loss: 0.612414, acc.: 70.31%] [G loss: 1.062396]\n",
      "epoch:23 step:22291 [D loss: 0.595764, acc.: 64.84%] [G loss: 1.112457]\n",
      "epoch:23 step:22292 [D loss: 0.504316, acc.: 78.91%] [G loss: 1.127923]\n",
      "epoch:23 step:22293 [D loss: 0.512621, acc.: 78.91%] [G loss: 1.201547]\n",
      "epoch:23 step:22294 [D loss: 0.428470, acc.: 85.94%] [G loss: 1.301245]\n",
      "epoch:23 step:22295 [D loss: 0.621543, acc.: 63.28%] [G loss: 1.055137]\n",
      "epoch:23 step:22296 [D loss: 0.352239, acc.: 90.62%] [G loss: 1.102769]\n",
      "epoch:23 step:22297 [D loss: 0.646730, acc.: 62.50%] [G loss: 0.945226]\n",
      "epoch:23 step:22298 [D loss: 0.536414, acc.: 72.66%] [G loss: 1.111182]\n",
      "epoch:23 step:22299 [D loss: 0.673053, acc.: 58.59%] [G loss: 1.180058]\n",
      "epoch:23 step:22300 [D loss: 0.614932, acc.: 64.84%] [G loss: 1.007274]\n",
      "epoch:23 step:22301 [D loss: 0.542445, acc.: 75.78%] [G loss: 1.220422]\n",
      "epoch:23 step:22302 [D loss: 0.647948, acc.: 60.16%] [G loss: 1.108325]\n",
      "epoch:23 step:22303 [D loss: 0.719562, acc.: 53.91%] [G loss: 1.058671]\n",
      "epoch:23 step:22304 [D loss: 0.626336, acc.: 64.84%] [G loss: 0.918601]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22305 [D loss: 0.677162, acc.: 56.25%] [G loss: 0.999054]\n",
      "epoch:23 step:22306 [D loss: 0.434931, acc.: 82.81%] [G loss: 1.101274]\n",
      "epoch:23 step:22307 [D loss: 0.600607, acc.: 70.31%] [G loss: 0.974092]\n",
      "epoch:23 step:22308 [D loss: 0.675879, acc.: 61.72%] [G loss: 0.814875]\n",
      "epoch:23 step:22309 [D loss: 0.639741, acc.: 62.50%] [G loss: 1.136852]\n",
      "epoch:23 step:22310 [D loss: 0.707022, acc.: 55.47%] [G loss: 1.313922]\n",
      "epoch:23 step:22311 [D loss: 0.654551, acc.: 57.03%] [G loss: 1.110888]\n",
      "epoch:23 step:22312 [D loss: 0.848606, acc.: 41.41%] [G loss: 0.809892]\n",
      "epoch:23 step:22313 [D loss: 0.649126, acc.: 62.50%] [G loss: 1.043002]\n",
      "epoch:23 step:22314 [D loss: 0.626035, acc.: 63.28%] [G loss: 1.046868]\n",
      "epoch:23 step:22315 [D loss: 0.564908, acc.: 68.75%] [G loss: 1.042352]\n",
      "epoch:23 step:22316 [D loss: 0.639995, acc.: 66.41%] [G loss: 1.154073]\n",
      "epoch:23 step:22317 [D loss: 0.676735, acc.: 60.94%] [G loss: 0.971730]\n",
      "epoch:23 step:22318 [D loss: 0.478767, acc.: 79.69%] [G loss: 1.040174]\n",
      "epoch:23 step:22319 [D loss: 0.319590, acc.: 92.97%] [G loss: 1.455556]\n",
      "epoch:23 step:22320 [D loss: 0.265384, acc.: 94.53%] [G loss: 1.516337]\n",
      "epoch:23 step:22321 [D loss: 0.464856, acc.: 80.47%] [G loss: 1.030258]\n",
      "epoch:23 step:22322 [D loss: 0.714436, acc.: 57.81%] [G loss: 1.098749]\n",
      "epoch:23 step:22323 [D loss: 0.667040, acc.: 59.38%] [G loss: 0.987517]\n",
      "epoch:23 step:22324 [D loss: 0.754837, acc.: 57.03%] [G loss: 0.739205]\n",
      "epoch:23 step:22325 [D loss: 0.258241, acc.: 94.53%] [G loss: 1.558462]\n",
      "epoch:23 step:22326 [D loss: 0.271070, acc.: 92.97%] [G loss: 1.381938]\n",
      "epoch:23 step:22327 [D loss: 0.502638, acc.: 72.66%] [G loss: 1.514342]\n",
      "epoch:23 step:22328 [D loss: 0.650359, acc.: 62.50%] [G loss: 1.120455]\n",
      "epoch:23 step:22329 [D loss: 0.573021, acc.: 65.62%] [G loss: 0.990213]\n",
      "epoch:23 step:22330 [D loss: 0.784290, acc.: 51.56%] [G loss: 1.031872]\n",
      "epoch:23 step:22331 [D loss: 0.790267, acc.: 47.66%] [G loss: 1.030435]\n",
      "epoch:23 step:22332 [D loss: 0.526179, acc.: 76.56%] [G loss: 1.063097]\n",
      "epoch:23 step:22333 [D loss: 0.456668, acc.: 84.38%] [G loss: 1.426593]\n",
      "epoch:23 step:22334 [D loss: 0.739381, acc.: 53.91%] [G loss: 1.425564]\n",
      "epoch:23 step:22335 [D loss: 0.800792, acc.: 44.53%] [G loss: 1.021711]\n",
      "epoch:23 step:22336 [D loss: 0.750281, acc.: 53.12%] [G loss: 0.853301]\n",
      "epoch:23 step:22337 [D loss: 0.425234, acc.: 83.59%] [G loss: 1.036954]\n",
      "epoch:23 step:22338 [D loss: 0.818088, acc.: 49.22%] [G loss: 1.022915]\n",
      "epoch:23 step:22339 [D loss: 0.635786, acc.: 63.28%] [G loss: 1.074428]\n",
      "epoch:23 step:22340 [D loss: 0.548300, acc.: 75.78%] [G loss: 1.062887]\n",
      "epoch:23 step:22341 [D loss: 0.427902, acc.: 85.16%] [G loss: 1.176234]\n",
      "epoch:23 step:22342 [D loss: 0.529336, acc.: 67.19%] [G loss: 0.800356]\n",
      "epoch:23 step:22343 [D loss: 0.330200, acc.: 89.84%] [G loss: 1.434357]\n",
      "epoch:23 step:22344 [D loss: 0.431593, acc.: 85.16%] [G loss: 1.769494]\n",
      "epoch:23 step:22345 [D loss: 0.207712, acc.: 98.44%] [G loss: 1.729466]\n",
      "epoch:23 step:22346 [D loss: 0.784190, acc.: 48.44%] [G loss: 1.013093]\n",
      "epoch:23 step:22347 [D loss: 0.487948, acc.: 75.78%] [G loss: 1.389314]\n",
      "epoch:23 step:22348 [D loss: 0.996253, acc.: 27.34%] [G loss: 0.710114]\n",
      "epoch:23 step:22349 [D loss: 0.763044, acc.: 46.09%] [G loss: 1.000725]\n",
      "epoch:23 step:22350 [D loss: 0.683982, acc.: 60.16%] [G loss: 0.833316]\n",
      "epoch:23 step:22351 [D loss: 0.700728, acc.: 60.16%] [G loss: 1.303214]\n",
      "epoch:23 step:22352 [D loss: 0.721484, acc.: 53.12%] [G loss: 1.148891]\n",
      "epoch:23 step:22353 [D loss: 0.566400, acc.: 75.00%] [G loss: 1.071948]\n",
      "epoch:23 step:22354 [D loss: 0.615406, acc.: 65.62%] [G loss: 0.927938]\n",
      "epoch:23 step:22355 [D loss: 0.555957, acc.: 72.66%] [G loss: 1.185118]\n",
      "epoch:23 step:22356 [D loss: 0.409423, acc.: 86.72%] [G loss: 1.110013]\n",
      "epoch:23 step:22357 [D loss: 0.330185, acc.: 91.41%] [G loss: 1.451760]\n",
      "epoch:23 step:22358 [D loss: 0.619240, acc.: 65.62%] [G loss: 1.158348]\n",
      "epoch:23 step:22359 [D loss: 0.500510, acc.: 79.69%] [G loss: 1.168712]\n",
      "epoch:23 step:22360 [D loss: 0.605843, acc.: 64.06%] [G loss: 1.275205]\n",
      "epoch:23 step:22361 [D loss: 0.642698, acc.: 63.28%] [G loss: 1.028499]\n",
      "epoch:23 step:22362 [D loss: 0.750881, acc.: 51.56%] [G loss: 1.201108]\n",
      "epoch:23 step:22363 [D loss: 0.589686, acc.: 62.50%] [G loss: 1.022402]\n",
      "epoch:23 step:22364 [D loss: 0.538423, acc.: 74.22%] [G loss: 0.957545]\n",
      "epoch:23 step:22365 [D loss: 0.454143, acc.: 83.59%] [G loss: 1.330146]\n",
      "epoch:23 step:22366 [D loss: 0.214547, acc.: 94.53%] [G loss: 1.297093]\n",
      "epoch:23 step:22367 [D loss: 0.346812, acc.: 92.19%] [G loss: 1.575864]\n",
      "epoch:23 step:22368 [D loss: 0.578621, acc.: 73.44%] [G loss: 1.318567]\n",
      "epoch:23 step:22369 [D loss: 0.505866, acc.: 77.34%] [G loss: 1.517033]\n",
      "epoch:23 step:22370 [D loss: 0.449223, acc.: 78.91%] [G loss: 1.243810]\n",
      "epoch:23 step:22371 [D loss: 0.796811, acc.: 46.09%] [G loss: 0.762088]\n",
      "epoch:23 step:22372 [D loss: 0.827386, acc.: 41.41%] [G loss: 0.753398]\n",
      "epoch:23 step:22373 [D loss: 0.634885, acc.: 59.38%] [G loss: 0.898657]\n",
      "epoch:23 step:22374 [D loss: 0.618120, acc.: 64.84%] [G loss: 0.921661]\n",
      "epoch:23 step:22375 [D loss: 0.449143, acc.: 77.34%] [G loss: 1.005626]\n",
      "epoch:23 step:22376 [D loss: 0.472374, acc.: 80.47%] [G loss: 1.153502]\n",
      "epoch:23 step:22377 [D loss: 0.696465, acc.: 53.91%] [G loss: 1.224548]\n",
      "epoch:23 step:22378 [D loss: 0.759054, acc.: 53.91%] [G loss: 1.139991]\n",
      "epoch:23 step:22379 [D loss: 0.675946, acc.: 60.16%] [G loss: 1.249431]\n",
      "epoch:23 step:22380 [D loss: 0.716257, acc.: 52.34%] [G loss: 0.921464]\n",
      "epoch:23 step:22381 [D loss: 0.636725, acc.: 63.28%] [G loss: 0.849746]\n",
      "epoch:23 step:22382 [D loss: 0.417355, acc.: 83.59%] [G loss: 1.192713]\n",
      "epoch:23 step:22383 [D loss: 0.410641, acc.: 89.06%] [G loss: 1.428383]\n",
      "epoch:23 step:22384 [D loss: 0.499895, acc.: 82.03%] [G loss: 1.260712]\n",
      "epoch:23 step:22385 [D loss: 1.048409, acc.: 26.56%] [G loss: 1.180374]\n",
      "epoch:23 step:22386 [D loss: 0.745945, acc.: 50.78%] [G loss: 1.095791]\n",
      "epoch:23 step:22387 [D loss: 0.708918, acc.: 52.34%] [G loss: 1.294411]\n",
      "epoch:23 step:22388 [D loss: 0.785608, acc.: 45.31%] [G loss: 1.250042]\n",
      "epoch:23 step:22389 [D loss: 0.570736, acc.: 67.19%] [G loss: 1.254597]\n",
      "epoch:23 step:22390 [D loss: 0.567232, acc.: 71.88%] [G loss: 1.326028]\n",
      "epoch:23 step:22391 [D loss: 0.384522, acc.: 90.62%] [G loss: 1.298513]\n",
      "epoch:23 step:22392 [D loss: 0.348657, acc.: 92.97%] [G loss: 1.337238]\n",
      "epoch:23 step:22393 [D loss: 0.351148, acc.: 93.75%] [G loss: 1.425705]\n",
      "epoch:23 step:22394 [D loss: 0.636074, acc.: 57.03%] [G loss: 1.471477]\n",
      "epoch:23 step:22395 [D loss: 0.682246, acc.: 54.69%] [G loss: 1.038890]\n",
      "epoch:23 step:22396 [D loss: 0.719664, acc.: 53.12%] [G loss: 1.021321]\n",
      "epoch:23 step:22397 [D loss: 0.664370, acc.: 64.06%] [G loss: 1.270179]\n",
      "epoch:23 step:22398 [D loss: 0.430817, acc.: 85.94%] [G loss: 1.213940]\n",
      "epoch:23 step:22399 [D loss: 0.548514, acc.: 70.31%] [G loss: 1.308568]\n",
      "epoch:23 step:22400 [D loss: 0.361501, acc.: 90.62%] [G loss: 1.336274]\n",
      "##############\n",
      "[2.43226054 1.80013004 5.63676221 4.30098772 3.31787988 5.41811958\n",
      " 4.39285058 4.70143119 4.10373976 3.76489179]\n",
      "##########\n",
      "epoch:23 step:22401 [D loss: 0.370775, acc.: 92.19%] [G loss: 1.456859]\n",
      "epoch:23 step:22402 [D loss: 0.210751, acc.: 97.66%] [G loss: 1.974608]\n",
      "epoch:23 step:22403 [D loss: 0.224285, acc.: 95.31%] [G loss: 1.989776]\n",
      "epoch:23 step:22404 [D loss: 0.233393, acc.: 96.88%] [G loss: 1.872070]\n",
      "epoch:23 step:22405 [D loss: 0.296273, acc.: 97.66%] [G loss: 1.608456]\n",
      "epoch:23 step:22406 [D loss: 0.343674, acc.: 91.41%] [G loss: 1.747191]\n",
      "epoch:23 step:22407 [D loss: 0.759019, acc.: 46.88%] [G loss: 1.351945]\n",
      "epoch:23 step:22408 [D loss: 0.347588, acc.: 90.62%] [G loss: 1.493066]\n",
      "epoch:23 step:22409 [D loss: 0.912688, acc.: 50.00%] [G loss: 1.441384]\n",
      "epoch:23 step:22410 [D loss: 0.664513, acc.: 57.03%] [G loss: 1.026974]\n",
      "epoch:23 step:22411 [D loss: 0.557198, acc.: 70.31%] [G loss: 1.147520]\n",
      "epoch:23 step:22412 [D loss: 0.715317, acc.: 52.34%] [G loss: 1.006284]\n",
      "epoch:23 step:22413 [D loss: 0.613156, acc.: 61.72%] [G loss: 1.252681]\n",
      "epoch:23 step:22414 [D loss: 0.627214, acc.: 70.31%] [G loss: 1.116343]\n",
      "epoch:23 step:22415 [D loss: 0.667949, acc.: 60.94%] [G loss: 1.011823]\n",
      "epoch:23 step:22416 [D loss: 0.688743, acc.: 56.25%] [G loss: 0.957923]\n",
      "epoch:23 step:22417 [D loss: 1.047923, acc.: 35.94%] [G loss: 0.609807]\n",
      "epoch:23 step:22418 [D loss: 0.629836, acc.: 64.06%] [G loss: 1.084927]\n",
      "epoch:23 step:22419 [D loss: 0.741944, acc.: 50.00%] [G loss: 1.082141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22420 [D loss: 0.827556, acc.: 40.62%] [G loss: 1.159643]\n",
      "epoch:23 step:22421 [D loss: 0.701402, acc.: 55.47%] [G loss: 1.185246]\n",
      "epoch:23 step:22422 [D loss: 0.676510, acc.: 60.94%] [G loss: 1.027613]\n",
      "epoch:23 step:22423 [D loss: 0.694854, acc.: 57.81%] [G loss: 0.933259]\n",
      "epoch:23 step:22424 [D loss: 0.644295, acc.: 63.28%] [G loss: 0.858636]\n",
      "epoch:23 step:22425 [D loss: 0.700693, acc.: 54.69%] [G loss: 1.042637]\n",
      "epoch:23 step:22426 [D loss: 0.713031, acc.: 56.25%] [G loss: 0.983573]\n",
      "epoch:23 step:22427 [D loss: 0.604908, acc.: 64.84%] [G loss: 1.117232]\n",
      "epoch:23 step:22428 [D loss: 0.544707, acc.: 71.09%] [G loss: 1.365213]\n",
      "epoch:23 step:22429 [D loss: 0.507015, acc.: 77.34%] [G loss: 0.971150]\n",
      "epoch:23 step:22430 [D loss: 0.661875, acc.: 62.50%] [G loss: 1.222792]\n",
      "epoch:23 step:22431 [D loss: 0.658067, acc.: 65.62%] [G loss: 1.002439]\n",
      "epoch:23 step:22432 [D loss: 0.643757, acc.: 62.50%] [G loss: 1.015168]\n",
      "epoch:23 step:22433 [D loss: 0.768499, acc.: 43.75%] [G loss: 1.047508]\n",
      "epoch:23 step:22434 [D loss: 0.522631, acc.: 78.12%] [G loss: 1.172584]\n",
      "epoch:23 step:22435 [D loss: 0.387155, acc.: 89.84%] [G loss: 1.071438]\n",
      "epoch:23 step:22436 [D loss: 0.492983, acc.: 71.88%] [G loss: 0.964393]\n",
      "epoch:23 step:22437 [D loss: 0.435508, acc.: 85.16%] [G loss: 1.619975]\n",
      "epoch:23 step:22438 [D loss: 0.346533, acc.: 90.62%] [G loss: 1.473476]\n",
      "epoch:23 step:22439 [D loss: 0.641699, acc.: 60.16%] [G loss: 1.173147]\n",
      "epoch:23 step:22440 [D loss: 0.433418, acc.: 85.16%] [G loss: 1.279244]\n",
      "epoch:23 step:22441 [D loss: 0.577124, acc.: 71.88%] [G loss: 0.954360]\n",
      "epoch:23 step:22442 [D loss: 0.809657, acc.: 48.44%] [G loss: 1.391118]\n",
      "epoch:23 step:22443 [D loss: 0.644439, acc.: 62.50%] [G loss: 1.055501]\n",
      "epoch:23 step:22444 [D loss: 0.578072, acc.: 70.31%] [G loss: 1.197421]\n",
      "epoch:23 step:22445 [D loss: 0.460475, acc.: 83.59%] [G loss: 1.130933]\n",
      "epoch:23 step:22446 [D loss: 0.507540, acc.: 76.56%] [G loss: 1.209100]\n",
      "epoch:23 step:22447 [D loss: 0.468043, acc.: 84.38%] [G loss: 1.447123]\n",
      "epoch:23 step:22448 [D loss: 0.459226, acc.: 83.59%] [G loss: 1.130275]\n",
      "epoch:23 step:22449 [D loss: 0.277320, acc.: 96.88%] [G loss: 1.486109]\n",
      "epoch:23 step:22450 [D loss: 0.296115, acc.: 92.97%] [G loss: 1.426488]\n",
      "epoch:23 step:22451 [D loss: 0.267064, acc.: 96.88%] [G loss: 1.726416]\n",
      "epoch:23 step:22452 [D loss: 0.490243, acc.: 79.69%] [G loss: 1.341508]\n",
      "epoch:23 step:22453 [D loss: 0.748105, acc.: 52.34%] [G loss: 1.272427]\n",
      "epoch:23 step:22454 [D loss: 0.491517, acc.: 82.03%] [G loss: 1.200116]\n",
      "epoch:23 step:22455 [D loss: 0.678828, acc.: 60.94%] [G loss: 0.958580]\n",
      "epoch:23 step:22456 [D loss: 0.672463, acc.: 63.28%] [G loss: 0.972423]\n",
      "epoch:23 step:22457 [D loss: 0.519613, acc.: 78.91%] [G loss: 1.036091]\n",
      "epoch:23 step:22458 [D loss: 0.694217, acc.: 56.25%] [G loss: 0.928276]\n",
      "epoch:23 step:22459 [D loss: 0.764481, acc.: 49.22%] [G loss: 0.985121]\n",
      "epoch:23 step:22460 [D loss: 0.518164, acc.: 78.12%] [G loss: 1.159310]\n",
      "epoch:23 step:22461 [D loss: 0.483950, acc.: 80.47%] [G loss: 1.107257]\n",
      "epoch:23 step:22462 [D loss: 0.409597, acc.: 85.16%] [G loss: 1.254440]\n",
      "epoch:23 step:22463 [D loss: 0.202857, acc.: 95.31%] [G loss: 1.572384]\n",
      "epoch:23 step:22464 [D loss: 0.801660, acc.: 50.00%] [G loss: 1.285069]\n",
      "epoch:23 step:22465 [D loss: 0.710783, acc.: 57.03%] [G loss: 1.126675]\n",
      "epoch:23 step:22466 [D loss: 0.681359, acc.: 60.16%] [G loss: 1.107815]\n",
      "epoch:23 step:22467 [D loss: 0.606838, acc.: 64.06%] [G loss: 0.850035]\n",
      "epoch:23 step:22468 [D loss: 0.643256, acc.: 65.62%] [G loss: 0.783853]\n",
      "epoch:23 step:22469 [D loss: 0.566067, acc.: 75.78%] [G loss: 1.092193]\n",
      "epoch:23 step:22470 [D loss: 0.444595, acc.: 85.16%] [G loss: 1.282387]\n",
      "epoch:23 step:22471 [D loss: 0.431092, acc.: 86.72%] [G loss: 1.390290]\n",
      "epoch:23 step:22472 [D loss: 0.402688, acc.: 86.72%] [G loss: 1.396608]\n",
      "epoch:23 step:22473 [D loss: 0.594358, acc.: 71.88%] [G loss: 1.058466]\n",
      "epoch:23 step:22474 [D loss: 0.608968, acc.: 64.84%] [G loss: 1.023635]\n",
      "epoch:23 step:22475 [D loss: 0.380424, acc.: 91.41%] [G loss: 1.405875]\n",
      "epoch:23 step:22476 [D loss: 0.415093, acc.: 88.28%] [G loss: 1.433016]\n",
      "epoch:23 step:22477 [D loss: 0.415438, acc.: 83.59%] [G loss: 1.301443]\n",
      "epoch:23 step:22478 [D loss: 0.277058, acc.: 89.06%] [G loss: 1.576943]\n",
      "epoch:23 step:22479 [D loss: 1.127261, acc.: 32.81%] [G loss: 1.046847]\n",
      "epoch:23 step:22480 [D loss: 0.369170, acc.: 92.97%] [G loss: 1.639771]\n",
      "epoch:23 step:22481 [D loss: 0.506892, acc.: 78.12%] [G loss: 1.400512]\n",
      "epoch:23 step:22482 [D loss: 0.609819, acc.: 64.84%] [G loss: 1.204355]\n",
      "epoch:23 step:22483 [D loss: 0.730637, acc.: 51.56%] [G loss: 1.083706]\n",
      "epoch:23 step:22484 [D loss: 0.504231, acc.: 83.59%] [G loss: 1.031216]\n",
      "epoch:23 step:22485 [D loss: 0.414406, acc.: 84.38%] [G loss: 1.426286]\n",
      "epoch:23 step:22486 [D loss: 0.496961, acc.: 78.12%] [G loss: 1.201186]\n",
      "epoch:23 step:22487 [D loss: 0.338113, acc.: 90.62%] [G loss: 1.343463]\n",
      "epoch:23 step:22488 [D loss: 0.163621, acc.: 98.44%] [G loss: 1.685839]\n",
      "epoch:24 step:22489 [D loss: 0.898399, acc.: 46.88%] [G loss: 1.253923]\n",
      "epoch:24 step:22490 [D loss: 0.642612, acc.: 65.62%] [G loss: 1.419609]\n",
      "epoch:24 step:22491 [D loss: 0.760954, acc.: 46.09%] [G loss: 1.149964]\n",
      "epoch:24 step:22492 [D loss: 0.701721, acc.: 58.59%] [G loss: 1.082286]\n",
      "epoch:24 step:22493 [D loss: 0.759717, acc.: 47.66%] [G loss: 0.954168]\n",
      "epoch:24 step:22494 [D loss: 0.774326, acc.: 53.91%] [G loss: 0.862460]\n",
      "epoch:24 step:22495 [D loss: 0.643002, acc.: 60.16%] [G loss: 1.053052]\n",
      "epoch:24 step:22496 [D loss: 0.583383, acc.: 69.53%] [G loss: 1.145836]\n",
      "epoch:24 step:22497 [D loss: 0.597937, acc.: 69.53%] [G loss: 1.177058]\n",
      "epoch:24 step:22498 [D loss: 0.484247, acc.: 79.69%] [G loss: 1.008334]\n",
      "epoch:24 step:22499 [D loss: 0.643852, acc.: 61.72%] [G loss: 1.228794]\n",
      "epoch:24 step:22500 [D loss: 0.723907, acc.: 53.91%] [G loss: 1.129703]\n",
      "epoch:24 step:22501 [D loss: 0.721286, acc.: 55.47%] [G loss: 1.214999]\n",
      "epoch:24 step:22502 [D loss: 0.596356, acc.: 64.84%] [G loss: 1.072503]\n",
      "epoch:24 step:22503 [D loss: 0.447484, acc.: 80.47%] [G loss: 1.211996]\n",
      "epoch:24 step:22504 [D loss: 0.372208, acc.: 91.41%] [G loss: 1.484630]\n",
      "epoch:24 step:22505 [D loss: 0.779909, acc.: 52.34%] [G loss: 1.073413]\n",
      "epoch:24 step:22506 [D loss: 0.746427, acc.: 51.56%] [G loss: 1.085316]\n",
      "epoch:24 step:22507 [D loss: 1.088950, acc.: 17.19%] [G loss: 0.677301]\n",
      "epoch:24 step:22508 [D loss: 0.810441, acc.: 43.75%] [G loss: 0.803887]\n",
      "epoch:24 step:22509 [D loss: 0.703265, acc.: 57.81%] [G loss: 1.279689]\n",
      "epoch:24 step:22510 [D loss: 0.574090, acc.: 67.97%] [G loss: 1.224291]\n",
      "epoch:24 step:22511 [D loss: 0.513079, acc.: 83.59%] [G loss: 1.146521]\n",
      "epoch:24 step:22512 [D loss: 0.746559, acc.: 51.56%] [G loss: 0.877653]\n",
      "epoch:24 step:22513 [D loss: 0.618099, acc.: 62.50%] [G loss: 1.089472]\n",
      "epoch:24 step:22514 [D loss: 0.463791, acc.: 78.91%] [G loss: 1.073157]\n",
      "epoch:24 step:22515 [D loss: 0.283559, acc.: 96.09%] [G loss: 1.557316]\n",
      "epoch:24 step:22516 [D loss: 0.403606, acc.: 87.50%] [G loss: 1.453277]\n",
      "epoch:24 step:22517 [D loss: 0.372804, acc.: 90.62%] [G loss: 1.576207]\n",
      "epoch:24 step:22518 [D loss: 0.325773, acc.: 92.19%] [G loss: 1.526995]\n",
      "epoch:24 step:22519 [D loss: 0.186365, acc.: 98.44%] [G loss: 1.878143]\n",
      "epoch:24 step:22520 [D loss: 0.257450, acc.: 94.53%] [G loss: 1.551870]\n",
      "epoch:24 step:22521 [D loss: 0.191973, acc.: 100.00%] [G loss: 2.051273]\n",
      "epoch:24 step:22522 [D loss: 0.243780, acc.: 99.22%] [G loss: 1.929124]\n",
      "epoch:24 step:22523 [D loss: 0.138475, acc.: 100.00%] [G loss: 2.120363]\n",
      "epoch:24 step:22524 [D loss: 0.196307, acc.: 96.88%] [G loss: 1.952388]\n",
      "epoch:24 step:22525 [D loss: 0.727937, acc.: 55.47%] [G loss: 1.568429]\n",
      "epoch:24 step:22526 [D loss: 0.986116, acc.: 40.62%] [G loss: 1.238893]\n",
      "epoch:24 step:22527 [D loss: 0.879059, acc.: 34.38%] [G loss: 0.987556]\n",
      "epoch:24 step:22528 [D loss: 0.635372, acc.: 63.28%] [G loss: 1.174085]\n",
      "epoch:24 step:22529 [D loss: 0.704978, acc.: 55.47%] [G loss: 1.060061]\n",
      "epoch:24 step:22530 [D loss: 0.584537, acc.: 68.75%] [G loss: 1.063253]\n",
      "epoch:24 step:22531 [D loss: 0.480975, acc.: 83.59%] [G loss: 1.604648]\n",
      "epoch:24 step:22532 [D loss: 0.412576, acc.: 90.62%] [G loss: 1.262405]\n",
      "epoch:24 step:22533 [D loss: 0.808172, acc.: 50.00%] [G loss: 0.757501]\n",
      "epoch:24 step:22534 [D loss: 0.777415, acc.: 49.22%] [G loss: 1.163761]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22535 [D loss: 0.730702, acc.: 47.66%] [G loss: 0.915340]\n",
      "epoch:24 step:22536 [D loss: 0.985673, acc.: 27.34%] [G loss: 0.863539]\n",
      "epoch:24 step:22537 [D loss: 0.854579, acc.: 42.19%] [G loss: 1.055954]\n",
      "epoch:24 step:22538 [D loss: 0.685238, acc.: 64.06%] [G loss: 0.994486]\n",
      "epoch:24 step:22539 [D loss: 0.532629, acc.: 75.00%] [G loss: 1.130150]\n",
      "epoch:24 step:22540 [D loss: 0.638492, acc.: 61.72%] [G loss: 1.129011]\n",
      "epoch:24 step:22541 [D loss: 0.712727, acc.: 54.69%] [G loss: 1.005715]\n",
      "epoch:24 step:22542 [D loss: 0.629015, acc.: 62.50%] [G loss: 0.812159]\n",
      "epoch:24 step:22543 [D loss: 0.471448, acc.: 83.59%] [G loss: 1.183556]\n",
      "epoch:24 step:22544 [D loss: 0.713866, acc.: 56.25%] [G loss: 1.224989]\n",
      "epoch:24 step:22545 [D loss: 0.642162, acc.: 63.28%] [G loss: 1.364006]\n",
      "epoch:24 step:22546 [D loss: 0.653296, acc.: 57.81%] [G loss: 1.099122]\n",
      "epoch:24 step:22547 [D loss: 0.634732, acc.: 63.28%] [G loss: 1.104835]\n",
      "epoch:24 step:22548 [D loss: 0.580095, acc.: 70.31%] [G loss: 1.081631]\n",
      "epoch:24 step:22549 [D loss: 0.578154, acc.: 68.75%] [G loss: 1.230429]\n",
      "epoch:24 step:22550 [D loss: 0.683622, acc.: 55.47%] [G loss: 0.776583]\n",
      "epoch:24 step:22551 [D loss: 0.621889, acc.: 66.41%] [G loss: 0.925570]\n",
      "epoch:24 step:22552 [D loss: 0.680167, acc.: 57.03%] [G loss: 1.061113]\n",
      "epoch:24 step:22553 [D loss: 0.502630, acc.: 78.91%] [G loss: 1.203418]\n",
      "epoch:24 step:22554 [D loss: 0.633351, acc.: 62.50%] [G loss: 1.125650]\n",
      "epoch:24 step:22555 [D loss: 0.698631, acc.: 56.25%] [G loss: 1.202565]\n",
      "epoch:24 step:22556 [D loss: 0.463504, acc.: 82.03%] [G loss: 1.080172]\n",
      "epoch:24 step:22557 [D loss: 0.441966, acc.: 83.59%] [G loss: 1.151783]\n",
      "epoch:24 step:22558 [D loss: 0.473003, acc.: 81.25%] [G loss: 1.453377]\n",
      "epoch:24 step:22559 [D loss: 0.583607, acc.: 75.78%] [G loss: 1.012880]\n",
      "epoch:24 step:22560 [D loss: 0.639306, acc.: 63.28%] [G loss: 0.911071]\n",
      "epoch:24 step:22561 [D loss: 0.623032, acc.: 70.31%] [G loss: 1.171417]\n",
      "epoch:24 step:22562 [D loss: 0.419392, acc.: 84.38%] [G loss: 1.182077]\n",
      "epoch:24 step:22563 [D loss: 0.501986, acc.: 69.53%] [G loss: 1.104779]\n",
      "epoch:24 step:22564 [D loss: 0.325407, acc.: 92.19%] [G loss: 1.367607]\n",
      "epoch:24 step:22565 [D loss: 0.593332, acc.: 69.53%] [G loss: 1.294490]\n",
      "epoch:24 step:22566 [D loss: 0.742262, acc.: 53.91%] [G loss: 1.564307]\n",
      "epoch:24 step:22567 [D loss: 0.780500, acc.: 48.44%] [G loss: 1.189525]\n",
      "epoch:24 step:22568 [D loss: 0.595193, acc.: 71.09%] [G loss: 1.065180]\n",
      "epoch:24 step:22569 [D loss: 0.601276, acc.: 71.88%] [G loss: 1.146254]\n",
      "epoch:24 step:22570 [D loss: 0.472207, acc.: 85.16%] [G loss: 1.126455]\n",
      "epoch:24 step:22571 [D loss: 0.448223, acc.: 85.16%] [G loss: 1.125230]\n",
      "epoch:24 step:22572 [D loss: 0.654589, acc.: 62.50%] [G loss: 1.146457]\n",
      "epoch:24 step:22573 [D loss: 0.702928, acc.: 60.16%] [G loss: 0.980827]\n",
      "epoch:24 step:22574 [D loss: 0.511366, acc.: 78.91%] [G loss: 1.034840]\n",
      "epoch:24 step:22575 [D loss: 0.429653, acc.: 89.06%] [G loss: 1.123002]\n",
      "epoch:24 step:22576 [D loss: 0.385466, acc.: 93.75%] [G loss: 1.519149]\n",
      "epoch:24 step:22577 [D loss: 0.511300, acc.: 78.12%] [G loss: 1.281325]\n",
      "epoch:24 step:22578 [D loss: 0.431264, acc.: 91.41%] [G loss: 1.444078]\n",
      "epoch:24 step:22579 [D loss: 0.493687, acc.: 84.38%] [G loss: 1.583714]\n",
      "epoch:24 step:22580 [D loss: 0.654377, acc.: 61.72%] [G loss: 0.775795]\n",
      "epoch:24 step:22581 [D loss: 0.540780, acc.: 77.34%] [G loss: 1.241027]\n",
      "epoch:24 step:22582 [D loss: 0.847675, acc.: 35.94%] [G loss: 0.905005]\n",
      "epoch:24 step:22583 [D loss: 0.805384, acc.: 43.75%] [G loss: 0.980514]\n",
      "epoch:24 step:22584 [D loss: 0.741884, acc.: 50.78%] [G loss: 0.886487]\n",
      "epoch:24 step:22585 [D loss: 0.756064, acc.: 46.09%] [G loss: 1.229781]\n",
      "epoch:24 step:22586 [D loss: 0.762969, acc.: 50.78%] [G loss: 1.046304]\n",
      "epoch:24 step:22587 [D loss: 1.136384, acc.: 14.84%] [G loss: 0.691856]\n",
      "epoch:24 step:22588 [D loss: 1.109077, acc.: 22.66%] [G loss: 0.686191]\n",
      "epoch:24 step:22589 [D loss: 0.661315, acc.: 61.72%] [G loss: 1.144769]\n",
      "epoch:24 step:22590 [D loss: 0.958209, acc.: 29.69%] [G loss: 0.866465]\n",
      "epoch:24 step:22591 [D loss: 0.778873, acc.: 46.88%] [G loss: 1.116429]\n",
      "epoch:24 step:22592 [D loss: 0.637299, acc.: 63.28%] [G loss: 1.151381]\n",
      "epoch:24 step:22593 [D loss: 0.651406, acc.: 57.81%] [G loss: 1.090571]\n",
      "epoch:24 step:22594 [D loss: 0.784262, acc.: 44.53%] [G loss: 1.072641]\n",
      "epoch:24 step:22595 [D loss: 0.613904, acc.: 69.53%] [G loss: 1.262304]\n",
      "epoch:24 step:22596 [D loss: 0.530346, acc.: 72.66%] [G loss: 1.384412]\n",
      "epoch:24 step:22597 [D loss: 0.376202, acc.: 86.72%] [G loss: 1.209602]\n",
      "epoch:24 step:22598 [D loss: 0.598675, acc.: 64.84%] [G loss: 1.050711]\n",
      "epoch:24 step:22599 [D loss: 0.639801, acc.: 66.41%] [G loss: 1.107194]\n",
      "epoch:24 step:22600 [D loss: 0.488487, acc.: 78.91%] [G loss: 1.154683]\n",
      "##############\n",
      "[2.51226308 1.56814092 5.67671017 4.27077006 3.00055862 5.4641057\n",
      " 4.12686952 4.82855776 3.85468491 3.70591481]\n",
      "##########\n",
      "epoch:24 step:22601 [D loss: 0.694506, acc.: 58.59%] [G loss: 1.090405]\n",
      "epoch:24 step:22602 [D loss: 0.764073, acc.: 47.66%] [G loss: 0.868712]\n",
      "epoch:24 step:22603 [D loss: 0.695688, acc.: 55.47%] [G loss: 0.960826]\n",
      "epoch:24 step:22604 [D loss: 0.467748, acc.: 77.34%] [G loss: 0.995313]\n",
      "epoch:24 step:22605 [D loss: 0.361486, acc.: 85.16%] [G loss: 1.143032]\n",
      "epoch:24 step:22606 [D loss: 0.387747, acc.: 89.84%] [G loss: 1.144972]\n",
      "epoch:24 step:22607 [D loss: 0.307137, acc.: 93.75%] [G loss: 1.660235]\n",
      "epoch:24 step:22608 [D loss: 0.852560, acc.: 46.88%] [G loss: 1.377139]\n",
      "epoch:24 step:22609 [D loss: 0.641809, acc.: 63.28%] [G loss: 1.337931]\n",
      "epoch:24 step:22610 [D loss: 0.493086, acc.: 80.47%] [G loss: 1.079349]\n",
      "epoch:24 step:22611 [D loss: 0.694743, acc.: 56.25%] [G loss: 1.359985]\n",
      "epoch:24 step:22612 [D loss: 0.471028, acc.: 84.38%] [G loss: 1.292706]\n",
      "epoch:24 step:22613 [D loss: 0.513545, acc.: 78.12%] [G loss: 1.053223]\n",
      "epoch:24 step:22614 [D loss: 0.415930, acc.: 89.84%] [G loss: 1.201672]\n",
      "epoch:24 step:22615 [D loss: 0.527939, acc.: 77.34%] [G loss: 0.982252]\n",
      "epoch:24 step:22616 [D loss: 0.775387, acc.: 48.44%] [G loss: 0.771308]\n",
      "epoch:24 step:22617 [D loss: 0.833204, acc.: 44.53%] [G loss: 0.807001]\n",
      "epoch:24 step:22618 [D loss: 0.587612, acc.: 68.75%] [G loss: 0.986545]\n",
      "epoch:24 step:22619 [D loss: 0.515777, acc.: 75.78%] [G loss: 1.084905]\n",
      "epoch:24 step:22620 [D loss: 0.550199, acc.: 75.00%] [G loss: 0.989537]\n",
      "epoch:24 step:22621 [D loss: 0.742653, acc.: 53.91%] [G loss: 0.898217]\n",
      "epoch:24 step:22622 [D loss: 0.464468, acc.: 82.81%] [G loss: 1.001743]\n",
      "epoch:24 step:22623 [D loss: 0.459043, acc.: 82.81%] [G loss: 1.227166]\n",
      "epoch:24 step:22624 [D loss: 0.634233, acc.: 60.94%] [G loss: 1.205615]\n",
      "epoch:24 step:22625 [D loss: 0.751317, acc.: 48.44%] [G loss: 0.815506]\n",
      "epoch:24 step:22626 [D loss: 0.706412, acc.: 57.03%] [G loss: 1.151186]\n",
      "epoch:24 step:22627 [D loss: 0.637502, acc.: 64.06%] [G loss: 0.915819]\n",
      "epoch:24 step:22628 [D loss: 0.562405, acc.: 65.62%] [G loss: 1.029013]\n",
      "epoch:24 step:22629 [D loss: 0.817769, acc.: 39.84%] [G loss: 0.913210]\n",
      "epoch:24 step:22630 [D loss: 0.623410, acc.: 72.66%] [G loss: 1.286076]\n",
      "epoch:24 step:22631 [D loss: 0.667120, acc.: 64.84%] [G loss: 1.234082]\n",
      "epoch:24 step:22632 [D loss: 0.544353, acc.: 70.31%] [G loss: 1.189805]\n",
      "epoch:24 step:22633 [D loss: 0.317567, acc.: 96.88%] [G loss: 1.596377]\n",
      "epoch:24 step:22634 [D loss: 0.895289, acc.: 32.81%] [G loss: 0.771185]\n",
      "epoch:24 step:22635 [D loss: 0.799640, acc.: 45.31%] [G loss: 1.005413]\n",
      "epoch:24 step:22636 [D loss: 0.989246, acc.: 28.91%] [G loss: 0.802943]\n",
      "epoch:24 step:22637 [D loss: 0.821126, acc.: 39.84%] [G loss: 0.681688]\n",
      "epoch:24 step:22638 [D loss: 0.437096, acc.: 82.81%] [G loss: 1.341009]\n",
      "epoch:24 step:22639 [D loss: 0.552870, acc.: 71.88%] [G loss: 1.018528]\n",
      "epoch:24 step:22640 [D loss: 0.484760, acc.: 80.47%] [G loss: 1.187785]\n",
      "epoch:24 step:22641 [D loss: 0.966576, acc.: 30.47%] [G loss: 1.135642]\n",
      "epoch:24 step:22642 [D loss: 0.795030, acc.: 47.66%] [G loss: 1.161036]\n",
      "epoch:24 step:22643 [D loss: 0.576100, acc.: 64.84%] [G loss: 1.149774]\n",
      "epoch:24 step:22644 [D loss: 0.458536, acc.: 83.59%] [G loss: 1.554411]\n",
      "epoch:24 step:22645 [D loss: 0.426120, acc.: 83.59%] [G loss: 1.405459]\n",
      "epoch:24 step:22646 [D loss: 0.370374, acc.: 91.41%] [G loss: 1.370952]\n",
      "epoch:24 step:22647 [D loss: 0.282544, acc.: 93.75%] [G loss: 1.601822]\n",
      "epoch:24 step:22648 [D loss: 0.610364, acc.: 67.19%] [G loss: 1.525348]\n",
      "epoch:24 step:22649 [D loss: 0.692440, acc.: 60.94%] [G loss: 1.164053]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22650 [D loss: 0.573427, acc.: 71.88%] [G loss: 1.066523]\n",
      "epoch:24 step:22651 [D loss: 0.315985, acc.: 92.97%] [G loss: 1.474688]\n",
      "epoch:24 step:22652 [D loss: 0.366429, acc.: 90.62%] [G loss: 1.201462]\n",
      "epoch:24 step:22653 [D loss: 0.321557, acc.: 92.97%] [G loss: 1.444878]\n",
      "epoch:24 step:22654 [D loss: 0.339111, acc.: 90.62%] [G loss: 1.502519]\n",
      "epoch:24 step:22655 [D loss: 0.335607, acc.: 92.97%] [G loss: 1.295581]\n",
      "epoch:24 step:22656 [D loss: 0.307725, acc.: 95.31%] [G loss: 1.396676]\n",
      "epoch:24 step:22657 [D loss: 0.398772, acc.: 87.50%] [G loss: 1.538900]\n",
      "epoch:24 step:22658 [D loss: 0.476915, acc.: 82.81%] [G loss: 1.304075]\n",
      "epoch:24 step:22659 [D loss: 0.430923, acc.: 89.84%] [G loss: 1.388425]\n",
      "epoch:24 step:22660 [D loss: 0.483500, acc.: 72.66%] [G loss: 1.156182]\n",
      "epoch:24 step:22661 [D loss: 0.551044, acc.: 69.53%] [G loss: 1.109732]\n",
      "epoch:24 step:22662 [D loss: 0.827389, acc.: 42.97%] [G loss: 1.251414]\n",
      "epoch:24 step:22663 [D loss: 0.701486, acc.: 57.81%] [G loss: 0.793915]\n",
      "epoch:24 step:22664 [D loss: 0.725984, acc.: 57.03%] [G loss: 0.858624]\n",
      "epoch:24 step:22665 [D loss: 1.017031, acc.: 36.72%] [G loss: 1.001880]\n",
      "epoch:24 step:22666 [D loss: 0.832709, acc.: 42.19%] [G loss: 1.184568]\n",
      "epoch:24 step:22667 [D loss: 0.543955, acc.: 70.31%] [G loss: 1.242350]\n",
      "epoch:24 step:22668 [D loss: 1.415594, acc.: 23.44%] [G loss: 0.335009]\n",
      "epoch:24 step:22669 [D loss: 0.791686, acc.: 39.84%] [G loss: 0.740739]\n",
      "epoch:24 step:22670 [D loss: 0.540075, acc.: 72.66%] [G loss: 1.095329]\n",
      "epoch:24 step:22671 [D loss: 0.714294, acc.: 59.38%] [G loss: 1.179378]\n",
      "epoch:24 step:22672 [D loss: 0.810395, acc.: 48.44%] [G loss: 0.846157]\n",
      "epoch:24 step:22673 [D loss: 1.143088, acc.: 21.88%] [G loss: 1.054285]\n",
      "epoch:24 step:22674 [D loss: 1.191127, acc.: 14.84%] [G loss: 0.859367]\n",
      "epoch:24 step:22675 [D loss: 0.962682, acc.: 28.12%] [G loss: 0.858851]\n",
      "epoch:24 step:22676 [D loss: 0.927499, acc.: 44.53%] [G loss: 0.750706]\n",
      "epoch:24 step:22677 [D loss: 0.993992, acc.: 24.22%] [G loss: 0.843411]\n",
      "epoch:24 step:22678 [D loss: 0.760942, acc.: 43.75%] [G loss: 1.300783]\n",
      "epoch:24 step:22679 [D loss: 0.862880, acc.: 35.94%] [G loss: 0.832958]\n",
      "epoch:24 step:22680 [D loss: 0.448633, acc.: 82.03%] [G loss: 1.472068]\n",
      "epoch:24 step:22681 [D loss: 0.727996, acc.: 54.69%] [G loss: 1.112643]\n",
      "epoch:24 step:22682 [D loss: 0.546554, acc.: 77.34%] [G loss: 1.518788]\n",
      "epoch:24 step:22683 [D loss: 0.606800, acc.: 64.84%] [G loss: 1.138349]\n",
      "epoch:24 step:22684 [D loss: 0.908680, acc.: 36.72%] [G loss: 0.947275]\n",
      "epoch:24 step:22685 [D loss: 0.625378, acc.: 63.28%] [G loss: 0.962553]\n",
      "epoch:24 step:22686 [D loss: 0.826972, acc.: 38.28%] [G loss: 0.903563]\n",
      "epoch:24 step:22687 [D loss: 0.961428, acc.: 37.50%] [G loss: 0.828923]\n",
      "epoch:24 step:22688 [D loss: 0.923017, acc.: 33.59%] [G loss: 0.903202]\n",
      "epoch:24 step:22689 [D loss: 1.023353, acc.: 21.09%] [G loss: 0.994620]\n",
      "epoch:24 step:22690 [D loss: 0.745147, acc.: 50.00%] [G loss: 1.252965]\n",
      "epoch:24 step:22691 [D loss: 0.716634, acc.: 50.78%] [G loss: 0.982362]\n",
      "epoch:24 step:22692 [D loss: 0.700370, acc.: 59.38%] [G loss: 1.010476]\n",
      "epoch:24 step:22693 [D loss: 0.724265, acc.: 53.91%] [G loss: 0.985294]\n",
      "epoch:24 step:22694 [D loss: 0.737794, acc.: 53.91%] [G loss: 1.113706]\n",
      "epoch:24 step:22695 [D loss: 0.541036, acc.: 78.91%] [G loss: 1.082023]\n",
      "epoch:24 step:22696 [D loss: 0.689005, acc.: 57.81%] [G loss: 1.192586]\n",
      "epoch:24 step:22697 [D loss: 0.451801, acc.: 84.38%] [G loss: 1.322489]\n",
      "epoch:24 step:22698 [D loss: 0.813953, acc.: 48.44%] [G loss: 0.799163]\n",
      "epoch:24 step:22699 [D loss: 0.684186, acc.: 57.81%] [G loss: 0.871238]\n",
      "epoch:24 step:22700 [D loss: 0.532589, acc.: 82.03%] [G loss: 1.221990]\n",
      "epoch:24 step:22701 [D loss: 0.705021, acc.: 53.91%] [G loss: 1.037105]\n",
      "epoch:24 step:22702 [D loss: 0.698771, acc.: 53.12%] [G loss: 1.071485]\n",
      "epoch:24 step:22703 [D loss: 0.754135, acc.: 48.44%] [G loss: 1.153297]\n",
      "epoch:24 step:22704 [D loss: 0.597856, acc.: 69.53%] [G loss: 0.953621]\n",
      "epoch:24 step:22705 [D loss: 0.678129, acc.: 60.16%] [G loss: 1.106265]\n",
      "epoch:24 step:22706 [D loss: 0.624351, acc.: 67.19%] [G loss: 1.182098]\n",
      "epoch:24 step:22707 [D loss: 0.587665, acc.: 67.97%] [G loss: 1.057036]\n",
      "epoch:24 step:22708 [D loss: 0.417319, acc.: 84.38%] [G loss: 1.069401]\n",
      "epoch:24 step:22709 [D loss: 0.378837, acc.: 89.84%] [G loss: 1.357029]\n",
      "epoch:24 step:22710 [D loss: 0.479866, acc.: 78.91%] [G loss: 1.545587]\n",
      "epoch:24 step:22711 [D loss: 0.357258, acc.: 89.84%] [G loss: 1.563887]\n",
      "epoch:24 step:22712 [D loss: 0.786060, acc.: 57.03%] [G loss: 1.414628]\n",
      "epoch:24 step:22713 [D loss: 0.620180, acc.: 64.06%] [G loss: 1.169817]\n",
      "epoch:24 step:22714 [D loss: 0.463896, acc.: 82.81%] [G loss: 1.128548]\n",
      "epoch:24 step:22715 [D loss: 0.570654, acc.: 67.19%] [G loss: 1.279222]\n",
      "epoch:24 step:22716 [D loss: 0.686251, acc.: 56.25%] [G loss: 0.903863]\n",
      "epoch:24 step:22717 [D loss: 0.514871, acc.: 78.12%] [G loss: 1.143893]\n",
      "epoch:24 step:22718 [D loss: 0.315835, acc.: 82.03%] [G loss: 1.409821]\n",
      "epoch:24 step:22719 [D loss: 0.216805, acc.: 97.66%] [G loss: 2.020624]\n",
      "epoch:24 step:22720 [D loss: 0.317447, acc.: 90.62%] [G loss: 1.714999]\n",
      "epoch:24 step:22721 [D loss: 0.850550, acc.: 53.12%] [G loss: 1.541819]\n",
      "epoch:24 step:22722 [D loss: 0.969181, acc.: 34.38%] [G loss: 0.998607]\n",
      "epoch:24 step:22723 [D loss: 0.391657, acc.: 91.41%] [G loss: 1.322176]\n",
      "epoch:24 step:22724 [D loss: 0.543375, acc.: 74.22%] [G loss: 1.161067]\n",
      "epoch:24 step:22725 [D loss: 0.412865, acc.: 85.94%] [G loss: 1.322252]\n",
      "epoch:24 step:22726 [D loss: 0.494500, acc.: 72.66%] [G loss: 1.198151]\n",
      "epoch:24 step:22727 [D loss: 0.701107, acc.: 57.03%] [G loss: 0.896445]\n",
      "epoch:24 step:22728 [D loss: 0.723532, acc.: 57.03%] [G loss: 1.045040]\n",
      "epoch:24 step:22729 [D loss: 0.821576, acc.: 42.19%] [G loss: 1.146914]\n",
      "epoch:24 step:22730 [D loss: 0.790724, acc.: 44.53%] [G loss: 0.834587]\n",
      "epoch:24 step:22731 [D loss: 0.523899, acc.: 75.78%] [G loss: 0.993220]\n",
      "epoch:24 step:22732 [D loss: 0.894264, acc.: 39.84%] [G loss: 1.163180]\n",
      "epoch:24 step:22733 [D loss: 0.775146, acc.: 47.66%] [G loss: 1.087813]\n",
      "epoch:24 step:22734 [D loss: 0.759043, acc.: 46.09%] [G loss: 1.003448]\n",
      "epoch:24 step:22735 [D loss: 0.905000, acc.: 36.72%] [G loss: 0.781669]\n",
      "epoch:24 step:22736 [D loss: 0.775935, acc.: 50.00%] [G loss: 1.163121]\n",
      "epoch:24 step:22737 [D loss: 0.859005, acc.: 39.06%] [G loss: 0.850945]\n",
      "epoch:24 step:22738 [D loss: 0.707977, acc.: 56.25%] [G loss: 1.006625]\n",
      "epoch:24 step:22739 [D loss: 0.628526, acc.: 65.62%] [G loss: 1.053385]\n",
      "epoch:24 step:22740 [D loss: 0.643048, acc.: 64.06%] [G loss: 0.984723]\n",
      "epoch:24 step:22741 [D loss: 0.582421, acc.: 73.44%] [G loss: 1.077708]\n",
      "epoch:24 step:22742 [D loss: 0.529613, acc.: 76.56%] [G loss: 1.066359]\n",
      "epoch:24 step:22743 [D loss: 0.544558, acc.: 73.44%] [G loss: 1.043566]\n",
      "epoch:24 step:22744 [D loss: 0.541668, acc.: 78.91%] [G loss: 1.172215]\n",
      "epoch:24 step:22745 [D loss: 0.538474, acc.: 77.34%] [G loss: 0.994874]\n",
      "epoch:24 step:22746 [D loss: 0.562492, acc.: 71.09%] [G loss: 1.220000]\n",
      "epoch:24 step:22747 [D loss: 0.416408, acc.: 81.25%] [G loss: 1.419913]\n",
      "epoch:24 step:22748 [D loss: 0.404313, acc.: 85.16%] [G loss: 1.213068]\n",
      "epoch:24 step:22749 [D loss: 0.622090, acc.: 61.72%] [G loss: 0.785827]\n",
      "epoch:24 step:22750 [D loss: 0.617647, acc.: 64.06%] [G loss: 1.279374]\n",
      "epoch:24 step:22751 [D loss: 0.681331, acc.: 60.94%] [G loss: 1.554004]\n",
      "epoch:24 step:22752 [D loss: 0.484314, acc.: 78.12%] [G loss: 0.962482]\n",
      "epoch:24 step:22753 [D loss: 0.557277, acc.: 71.09%] [G loss: 1.106249]\n",
      "epoch:24 step:22754 [D loss: 0.628182, acc.: 70.31%] [G loss: 1.060849]\n",
      "epoch:24 step:22755 [D loss: 0.482032, acc.: 75.00%] [G loss: 1.073396]\n",
      "epoch:24 step:22756 [D loss: 0.755660, acc.: 48.44%] [G loss: 0.922872]\n",
      "epoch:24 step:22757 [D loss: 0.524968, acc.: 78.12%] [G loss: 1.146910]\n",
      "epoch:24 step:22758 [D loss: 0.679871, acc.: 56.25%] [G loss: 1.039423]\n",
      "epoch:24 step:22759 [D loss: 0.543106, acc.: 71.88%] [G loss: 0.971375]\n",
      "epoch:24 step:22760 [D loss: 0.461733, acc.: 80.47%] [G loss: 1.141324]\n",
      "epoch:24 step:22761 [D loss: 0.482949, acc.: 82.03%] [G loss: 1.215768]\n",
      "epoch:24 step:22762 [D loss: 0.532851, acc.: 76.56%] [G loss: 1.318198]\n",
      "epoch:24 step:22763 [D loss: 0.489773, acc.: 78.91%] [G loss: 1.230222]\n",
      "epoch:24 step:22764 [D loss: 0.560970, acc.: 73.44%] [G loss: 1.303869]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22765 [D loss: 0.905771, acc.: 34.38%] [G loss: 0.981093]\n",
      "epoch:24 step:22766 [D loss: 0.702059, acc.: 53.12%] [G loss: 1.005349]\n",
      "epoch:24 step:22767 [D loss: 0.484539, acc.: 77.34%] [G loss: 1.300858]\n",
      "epoch:24 step:22768 [D loss: 0.537030, acc.: 74.22%] [G loss: 1.232776]\n",
      "epoch:24 step:22769 [D loss: 0.672064, acc.: 57.81%] [G loss: 1.111331]\n",
      "epoch:24 step:22770 [D loss: 0.458620, acc.: 85.16%] [G loss: 1.138102]\n",
      "epoch:24 step:22771 [D loss: 0.779562, acc.: 43.75%] [G loss: 0.863783]\n",
      "epoch:24 step:22772 [D loss: 0.721399, acc.: 51.56%] [G loss: 1.025456]\n",
      "epoch:24 step:22773 [D loss: 0.616700, acc.: 64.84%] [G loss: 1.097608]\n",
      "epoch:24 step:22774 [D loss: 0.619114, acc.: 64.06%] [G loss: 0.973348]\n",
      "epoch:24 step:22775 [D loss: 0.758991, acc.: 50.00%] [G loss: 1.101940]\n",
      "epoch:24 step:22776 [D loss: 0.740026, acc.: 47.66%] [G loss: 1.106062]\n",
      "epoch:24 step:22777 [D loss: 0.543864, acc.: 76.56%] [G loss: 0.875910]\n",
      "epoch:24 step:22778 [D loss: 0.822755, acc.: 42.19%] [G loss: 0.811185]\n",
      "epoch:24 step:22779 [D loss: 0.377712, acc.: 89.84%] [G loss: 1.211197]\n",
      "epoch:24 step:22780 [D loss: 0.765162, acc.: 52.34%] [G loss: 0.676699]\n",
      "epoch:24 step:22781 [D loss: 0.423097, acc.: 85.94%] [G loss: 1.276809]\n",
      "epoch:24 step:22782 [D loss: 0.595569, acc.: 71.88%] [G loss: 1.350342]\n",
      "epoch:24 step:22783 [D loss: 0.676533, acc.: 60.16%] [G loss: 1.185736]\n",
      "epoch:24 step:22784 [D loss: 0.712547, acc.: 58.59%] [G loss: 0.905933]\n",
      "epoch:24 step:22785 [D loss: 0.543550, acc.: 76.56%] [G loss: 1.156459]\n",
      "epoch:24 step:22786 [D loss: 0.436695, acc.: 85.94%] [G loss: 1.169022]\n",
      "epoch:24 step:22787 [D loss: 0.526278, acc.: 78.12%] [G loss: 1.241056]\n",
      "epoch:24 step:22788 [D loss: 0.546567, acc.: 75.78%] [G loss: 0.918468]\n",
      "epoch:24 step:22789 [D loss: 0.690266, acc.: 59.38%] [G loss: 1.126858]\n",
      "epoch:24 step:22790 [D loss: 0.677230, acc.: 57.03%] [G loss: 0.851884]\n",
      "epoch:24 step:22791 [D loss: 0.680895, acc.: 58.59%] [G loss: 1.075836]\n",
      "epoch:24 step:22792 [D loss: 0.555878, acc.: 72.66%] [G loss: 1.033092]\n",
      "epoch:24 step:22793 [D loss: 0.632556, acc.: 67.19%] [G loss: 0.999977]\n",
      "epoch:24 step:22794 [D loss: 0.634363, acc.: 61.72%] [G loss: 1.040872]\n",
      "epoch:24 step:22795 [D loss: 0.674817, acc.: 57.81%] [G loss: 1.103011]\n",
      "epoch:24 step:22796 [D loss: 0.495452, acc.: 75.78%] [G loss: 0.883712]\n",
      "epoch:24 step:22797 [D loss: 0.369085, acc.: 92.97%] [G loss: 1.327809]\n",
      "epoch:24 step:22798 [D loss: 0.500485, acc.: 76.56%] [G loss: 1.338075]\n",
      "epoch:24 step:22799 [D loss: 0.456987, acc.: 82.03%] [G loss: 1.343010]\n",
      "epoch:24 step:22800 [D loss: 0.330314, acc.: 92.19%] [G loss: 1.225087]\n",
      "##############\n",
      "[2.22385571 1.44848772 5.45713483 4.25404388 2.81276397 5.09668921\n",
      " 4.13017777 4.3974825  3.8523809  3.4159361 ]\n",
      "##########\n",
      "epoch:24 step:22801 [D loss: 0.326934, acc.: 92.97%] [G loss: 1.322270]\n",
      "epoch:24 step:22802 [D loss: 0.406232, acc.: 85.94%] [G loss: 1.660357]\n",
      "epoch:24 step:22803 [D loss: 0.411466, acc.: 86.72%] [G loss: 1.478261]\n",
      "epoch:24 step:22804 [D loss: 1.081189, acc.: 28.12%] [G loss: 0.951260]\n",
      "epoch:24 step:22805 [D loss: 0.790166, acc.: 50.78%] [G loss: 1.218465]\n",
      "epoch:24 step:22806 [D loss: 0.682592, acc.: 58.59%] [G loss: 1.017711]\n",
      "epoch:24 step:22807 [D loss: 0.788365, acc.: 41.41%] [G loss: 1.075320]\n",
      "epoch:24 step:22808 [D loss: 0.499784, acc.: 75.78%] [G loss: 1.129903]\n",
      "epoch:24 step:22809 [D loss: 0.394001, acc.: 90.62%] [G loss: 1.228718]\n",
      "epoch:24 step:22810 [D loss: 0.489166, acc.: 85.94%] [G loss: 1.173023]\n",
      "epoch:24 step:22811 [D loss: 0.720016, acc.: 53.91%] [G loss: 1.087061]\n",
      "epoch:24 step:22812 [D loss: 0.656995, acc.: 64.06%] [G loss: 1.018718]\n",
      "epoch:24 step:22813 [D loss: 0.511317, acc.: 82.03%] [G loss: 1.098843]\n",
      "epoch:24 step:22814 [D loss: 0.508511, acc.: 79.69%] [G loss: 1.043521]\n",
      "epoch:24 step:22815 [D loss: 0.374057, acc.: 87.50%] [G loss: 1.230446]\n",
      "epoch:24 step:22816 [D loss: 0.311394, acc.: 95.31%] [G loss: 1.400971]\n",
      "epoch:24 step:22817 [D loss: 0.561398, acc.: 73.44%] [G loss: 1.371866]\n",
      "epoch:24 step:22818 [D loss: 0.658082, acc.: 58.59%] [G loss: 1.352440]\n",
      "epoch:24 step:22819 [D loss: 0.630056, acc.: 60.94%] [G loss: 0.968117]\n",
      "epoch:24 step:22820 [D loss: 0.676397, acc.: 60.16%] [G loss: 1.100014]\n",
      "epoch:24 step:22821 [D loss: 0.646130, acc.: 60.16%] [G loss: 0.992422]\n",
      "epoch:24 step:22822 [D loss: 0.560647, acc.: 72.66%] [G loss: 1.170002]\n",
      "epoch:24 step:22823 [D loss: 0.706413, acc.: 59.38%] [G loss: 0.826790]\n",
      "epoch:24 step:22824 [D loss: 0.623972, acc.: 67.19%] [G loss: 0.919334]\n",
      "epoch:24 step:22825 [D loss: 0.611908, acc.: 68.75%] [G loss: 1.246749]\n",
      "epoch:24 step:22826 [D loss: 0.677141, acc.: 53.91%] [G loss: 0.812162]\n",
      "epoch:24 step:22827 [D loss: 0.628612, acc.: 65.62%] [G loss: 1.027076]\n",
      "epoch:24 step:22828 [D loss: 0.741773, acc.: 49.22%] [G loss: 1.038666]\n",
      "epoch:24 step:22829 [D loss: 0.696821, acc.: 57.81%] [G loss: 1.318398]\n",
      "epoch:24 step:22830 [D loss: 1.015790, acc.: 25.78%] [G loss: 0.826778]\n",
      "epoch:24 step:22831 [D loss: 0.527977, acc.: 71.09%] [G loss: 1.256190]\n",
      "epoch:24 step:22832 [D loss: 0.583168, acc.: 75.00%] [G loss: 1.223821]\n",
      "epoch:24 step:22833 [D loss: 0.274927, acc.: 97.66%] [G loss: 1.605348]\n",
      "epoch:24 step:22834 [D loss: 0.291295, acc.: 92.19%] [G loss: 1.439816]\n",
      "epoch:24 step:22835 [D loss: 0.253649, acc.: 95.31%] [G loss: 1.654425]\n",
      "epoch:24 step:22836 [D loss: 0.791702, acc.: 53.12%] [G loss: 1.378975]\n",
      "epoch:24 step:22837 [D loss: 0.820115, acc.: 40.62%] [G loss: 1.181327]\n",
      "epoch:24 step:22838 [D loss: 0.737149, acc.: 50.00%] [G loss: 0.937922]\n",
      "epoch:24 step:22839 [D loss: 0.527840, acc.: 75.78%] [G loss: 1.150266]\n",
      "epoch:24 step:22840 [D loss: 0.523326, acc.: 75.00%] [G loss: 1.069170]\n",
      "epoch:24 step:22841 [D loss: 0.531718, acc.: 73.44%] [G loss: 1.061161]\n",
      "epoch:24 step:22842 [D loss: 0.386813, acc.: 92.19%] [G loss: 1.292166]\n",
      "epoch:24 step:22843 [D loss: 0.762836, acc.: 50.78%] [G loss: 0.731558]\n",
      "epoch:24 step:22844 [D loss: 0.684533, acc.: 56.25%] [G loss: 1.107229]\n",
      "epoch:24 step:22845 [D loss: 0.591159, acc.: 68.75%] [G loss: 1.111870]\n",
      "epoch:24 step:22846 [D loss: 0.448928, acc.: 83.59%] [G loss: 1.050910]\n",
      "epoch:24 step:22847 [D loss: 0.514089, acc.: 78.91%] [G loss: 1.140752]\n",
      "epoch:24 step:22848 [D loss: 0.633975, acc.: 60.16%] [G loss: 1.131458]\n",
      "epoch:24 step:22849 [D loss: 0.787448, acc.: 46.09%] [G loss: 0.748832]\n",
      "epoch:24 step:22850 [D loss: 0.645850, acc.: 62.50%] [G loss: 0.962046]\n",
      "epoch:24 step:22851 [D loss: 0.669106, acc.: 59.38%] [G loss: 1.145645]\n",
      "epoch:24 step:22852 [D loss: 0.689254, acc.: 52.34%] [G loss: 0.927923]\n",
      "epoch:24 step:22853 [D loss: 0.528181, acc.: 74.22%] [G loss: 0.976323]\n",
      "epoch:24 step:22854 [D loss: 0.246613, acc.: 95.31%] [G loss: 1.346783]\n",
      "epoch:24 step:22855 [D loss: 0.258943, acc.: 96.09%] [G loss: 1.720800]\n",
      "epoch:24 step:22856 [D loss: 0.695537, acc.: 59.38%] [G loss: 1.297560]\n",
      "epoch:24 step:22857 [D loss: 0.795469, acc.: 42.19%] [G loss: 1.068471]\n",
      "epoch:24 step:22858 [D loss: 0.670298, acc.: 66.41%] [G loss: 1.113516]\n",
      "epoch:24 step:22859 [D loss: 0.492479, acc.: 81.25%] [G loss: 1.170846]\n",
      "epoch:24 step:22860 [D loss: 0.749442, acc.: 51.56%] [G loss: 0.977368]\n",
      "epoch:24 step:22861 [D loss: 0.868653, acc.: 38.28%] [G loss: 0.835725]\n",
      "epoch:24 step:22862 [D loss: 0.731448, acc.: 53.91%] [G loss: 0.814984]\n",
      "epoch:24 step:22863 [D loss: 0.691569, acc.: 56.25%] [G loss: 1.179056]\n",
      "epoch:24 step:22864 [D loss: 0.583944, acc.: 71.09%] [G loss: 0.911796]\n",
      "epoch:24 step:22865 [D loss: 0.621310, acc.: 66.41%] [G loss: 1.021216]\n",
      "epoch:24 step:22866 [D loss: 0.348758, acc.: 93.75%] [G loss: 1.318671]\n",
      "epoch:24 step:22867 [D loss: 0.669341, acc.: 55.47%] [G loss: 1.190631]\n",
      "epoch:24 step:22868 [D loss: 0.483032, acc.: 78.12%] [G loss: 1.175388]\n",
      "epoch:24 step:22869 [D loss: 0.437867, acc.: 83.59%] [G loss: 1.111714]\n",
      "epoch:24 step:22870 [D loss: 0.790719, acc.: 46.09%] [G loss: 0.863025]\n",
      "epoch:24 step:22871 [D loss: 0.588732, acc.: 67.97%] [G loss: 0.951837]\n",
      "epoch:24 step:22872 [D loss: 0.738262, acc.: 51.56%] [G loss: 0.946306]\n",
      "epoch:24 step:22873 [D loss: 0.648239, acc.: 64.84%] [G loss: 1.265039]\n",
      "epoch:24 step:22874 [D loss: 0.721343, acc.: 52.34%] [G loss: 1.294121]\n",
      "epoch:24 step:22875 [D loss: 0.601593, acc.: 71.09%] [G loss: 0.914479]\n",
      "epoch:24 step:22876 [D loss: 0.527702, acc.: 80.47%] [G loss: 0.950210]\n",
      "epoch:24 step:22877 [D loss: 0.670273, acc.: 60.16%] [G loss: 0.867558]\n",
      "epoch:24 step:22878 [D loss: 0.606806, acc.: 68.75%] [G loss: 0.970021]\n",
      "epoch:24 step:22879 [D loss: 0.564669, acc.: 73.44%] [G loss: 1.242580]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22880 [D loss: 0.661401, acc.: 60.94%] [G loss: 0.999231]\n",
      "epoch:24 step:22881 [D loss: 0.579000, acc.: 71.88%] [G loss: 1.041354]\n",
      "epoch:24 step:22882 [D loss: 0.498107, acc.: 80.47%] [G loss: 1.027311]\n",
      "epoch:24 step:22883 [D loss: 0.718231, acc.: 55.47%] [G loss: 1.078380]\n",
      "epoch:24 step:22884 [D loss: 0.343787, acc.: 89.84%] [G loss: 1.508857]\n",
      "epoch:24 step:22885 [D loss: 0.253737, acc.: 91.41%] [G loss: 1.398572]\n",
      "epoch:24 step:22886 [D loss: 0.388549, acc.: 82.81%] [G loss: 1.261607]\n",
      "epoch:24 step:22887 [D loss: 0.265216, acc.: 93.75%] [G loss: 1.895712]\n",
      "epoch:24 step:22888 [D loss: 0.350695, acc.: 92.97%] [G loss: 1.358629]\n",
      "epoch:24 step:22889 [D loss: 0.416227, acc.: 87.50%] [G loss: 1.778722]\n",
      "epoch:24 step:22890 [D loss: 0.456921, acc.: 83.59%] [G loss: 1.394866]\n",
      "epoch:24 step:22891 [D loss: 0.571100, acc.: 70.31%] [G loss: 1.357262]\n",
      "epoch:24 step:22892 [D loss: 0.356711, acc.: 87.50%] [G loss: 1.255798]\n",
      "epoch:24 step:22893 [D loss: 0.381504, acc.: 84.38%] [G loss: 1.191580]\n",
      "epoch:24 step:22894 [D loss: 0.332763, acc.: 89.84%] [G loss: 1.853512]\n",
      "epoch:24 step:22895 [D loss: 0.717233, acc.: 53.91%] [G loss: 1.013281]\n",
      "epoch:24 step:22896 [D loss: 0.834780, acc.: 46.88%] [G loss: 0.904698]\n",
      "epoch:24 step:22897 [D loss: 0.717877, acc.: 57.03%] [G loss: 0.770611]\n",
      "epoch:24 step:22898 [D loss: 0.697269, acc.: 57.81%] [G loss: 0.818575]\n",
      "epoch:24 step:22899 [D loss: 1.107208, acc.: 28.12%] [G loss: 0.829873]\n",
      "epoch:24 step:22900 [D loss: 0.984599, acc.: 32.81%] [G loss: 0.870284]\n",
      "epoch:24 step:22901 [D loss: 0.953750, acc.: 34.38%] [G loss: 0.810790]\n",
      "epoch:24 step:22902 [D loss: 0.857495, acc.: 40.62%] [G loss: 0.999898]\n",
      "epoch:24 step:22903 [D loss: 0.877063, acc.: 42.97%] [G loss: 1.015937]\n",
      "epoch:24 step:22904 [D loss: 0.803475, acc.: 46.88%] [G loss: 1.209550]\n",
      "epoch:24 step:22905 [D loss: 0.930450, acc.: 34.38%] [G loss: 1.200100]\n",
      "epoch:24 step:22906 [D loss: 0.572913, acc.: 68.75%] [G loss: 1.464893]\n",
      "epoch:24 step:22907 [D loss: 0.606198, acc.: 66.41%] [G loss: 1.054627]\n",
      "epoch:24 step:22908 [D loss: 0.633105, acc.: 66.41%] [G loss: 1.094590]\n",
      "epoch:24 step:22909 [D loss: 0.646595, acc.: 57.81%] [G loss: 1.103854]\n",
      "epoch:24 step:22910 [D loss: 0.535418, acc.: 72.66%] [G loss: 1.348473]\n",
      "epoch:24 step:22911 [D loss: 0.574891, acc.: 70.31%] [G loss: 1.462667]\n",
      "epoch:24 step:22912 [D loss: 0.705187, acc.: 61.72%] [G loss: 1.082596]\n",
      "epoch:24 step:22913 [D loss: 0.687154, acc.: 61.72%] [G loss: 1.154197]\n",
      "epoch:24 step:22914 [D loss: 0.572035, acc.: 68.75%] [G loss: 1.182514]\n",
      "epoch:24 step:22915 [D loss: 0.787067, acc.: 47.66%] [G loss: 1.134310]\n",
      "epoch:24 step:22916 [D loss: 0.690305, acc.: 59.38%] [G loss: 1.258373]\n",
      "epoch:24 step:22917 [D loss: 0.653457, acc.: 59.38%] [G loss: 1.249151]\n",
      "epoch:24 step:22918 [D loss: 0.639804, acc.: 62.50%] [G loss: 1.099391]\n",
      "epoch:24 step:22919 [D loss: 0.581892, acc.: 71.09%] [G loss: 1.180221]\n",
      "epoch:24 step:22920 [D loss: 0.522892, acc.: 78.91%] [G loss: 1.329242]\n",
      "epoch:24 step:22921 [D loss: 0.467125, acc.: 82.03%] [G loss: 1.344334]\n",
      "epoch:24 step:22922 [D loss: 0.484321, acc.: 80.47%] [G loss: 1.310372]\n",
      "epoch:24 step:22923 [D loss: 0.389926, acc.: 91.41%] [G loss: 1.566397]\n",
      "epoch:24 step:22924 [D loss: 0.473505, acc.: 78.12%] [G loss: 1.016193]\n",
      "epoch:24 step:22925 [D loss: 0.873374, acc.: 42.97%] [G loss: 1.266054]\n",
      "epoch:24 step:22926 [D loss: 0.683772, acc.: 58.59%] [G loss: 1.110475]\n",
      "epoch:24 step:22927 [D loss: 0.902441, acc.: 40.62%] [G loss: 0.899116]\n",
      "epoch:24 step:22928 [D loss: 0.755888, acc.: 50.78%] [G loss: 0.928204]\n",
      "epoch:24 step:22929 [D loss: 0.679658, acc.: 57.81%] [G loss: 1.158516]\n",
      "epoch:24 step:22930 [D loss: 0.702492, acc.: 52.34%] [G loss: 1.075379]\n",
      "epoch:24 step:22931 [D loss: 0.769083, acc.: 53.12%] [G loss: 1.052106]\n",
      "epoch:24 step:22932 [D loss: 0.689076, acc.: 60.94%] [G loss: 1.204821]\n",
      "epoch:24 step:22933 [D loss: 0.701617, acc.: 53.91%] [G loss: 1.006709]\n",
      "epoch:24 step:22934 [D loss: 0.779426, acc.: 50.78%] [G loss: 0.995423]\n",
      "epoch:24 step:22935 [D loss: 0.677741, acc.: 58.59%] [G loss: 1.032837]\n",
      "epoch:24 step:22936 [D loss: 0.728156, acc.: 51.56%] [G loss: 0.888314]\n",
      "epoch:24 step:22937 [D loss: 0.478546, acc.: 76.56%] [G loss: 1.425107]\n",
      "epoch:24 step:22938 [D loss: 0.631465, acc.: 64.06%] [G loss: 1.204861]\n",
      "epoch:24 step:22939 [D loss: 0.536389, acc.: 76.56%] [G loss: 1.441928]\n",
      "epoch:24 step:22940 [D loss: 0.549117, acc.: 69.53%] [G loss: 1.196086]\n",
      "epoch:24 step:22941 [D loss: 0.516521, acc.: 75.78%] [G loss: 1.226261]\n",
      "epoch:24 step:22942 [D loss: 0.592046, acc.: 66.41%] [G loss: 0.942423]\n",
      "epoch:24 step:22943 [D loss: 0.540257, acc.: 75.00%] [G loss: 1.054854]\n",
      "epoch:24 step:22944 [D loss: 0.670194, acc.: 63.28%] [G loss: 1.047603]\n",
      "epoch:24 step:22945 [D loss: 0.576171, acc.: 69.53%] [G loss: 1.064054]\n",
      "epoch:24 step:22946 [D loss: 0.793021, acc.: 47.66%] [G loss: 1.059358]\n",
      "epoch:24 step:22947 [D loss: 0.873727, acc.: 35.16%] [G loss: 0.804202]\n",
      "epoch:24 step:22948 [D loss: 0.871431, acc.: 35.94%] [G loss: 0.936844]\n",
      "epoch:24 step:22949 [D loss: 0.786087, acc.: 51.56%] [G loss: 1.212146]\n",
      "epoch:24 step:22950 [D loss: 0.635624, acc.: 65.62%] [G loss: 1.360583]\n",
      "epoch:24 step:22951 [D loss: 0.619006, acc.: 66.41%] [G loss: 1.128394]\n",
      "epoch:24 step:22952 [D loss: 0.799834, acc.: 47.66%] [G loss: 1.099233]\n",
      "epoch:24 step:22953 [D loss: 0.552319, acc.: 70.31%] [G loss: 1.073947]\n",
      "epoch:24 step:22954 [D loss: 0.620652, acc.: 66.41%] [G loss: 1.092715]\n",
      "epoch:24 step:22955 [D loss: 0.634025, acc.: 64.06%] [G loss: 1.003198]\n",
      "epoch:24 step:22956 [D loss: 0.479427, acc.: 77.34%] [G loss: 1.087003]\n",
      "epoch:24 step:22957 [D loss: 0.518077, acc.: 78.12%] [G loss: 1.122338]\n",
      "epoch:24 step:22958 [D loss: 0.468843, acc.: 83.59%] [G loss: 1.182783]\n",
      "epoch:24 step:22959 [D loss: 0.278478, acc.: 92.97%] [G loss: 1.371737]\n",
      "epoch:24 step:22960 [D loss: 0.569275, acc.: 71.88%] [G loss: 1.298546]\n",
      "epoch:24 step:22961 [D loss: 0.487796, acc.: 78.91%] [G loss: 0.893946]\n",
      "epoch:24 step:22962 [D loss: 0.350148, acc.: 89.84%] [G loss: 1.463984]\n",
      "epoch:24 step:22963 [D loss: 0.333137, acc.: 96.09%] [G loss: 1.638886]\n",
      "epoch:24 step:22964 [D loss: 0.720793, acc.: 53.91%] [G loss: 1.260188]\n",
      "epoch:24 step:22965 [D loss: 0.614940, acc.: 64.06%] [G loss: 0.953452]\n",
      "epoch:24 step:22966 [D loss: 0.746287, acc.: 54.69%] [G loss: 0.901683]\n",
      "epoch:24 step:22967 [D loss: 0.501740, acc.: 77.34%] [G loss: 1.103723]\n",
      "epoch:24 step:22968 [D loss: 0.733019, acc.: 50.78%] [G loss: 1.118965]\n",
      "epoch:24 step:22969 [D loss: 0.493157, acc.: 78.91%] [G loss: 1.083647]\n",
      "epoch:24 step:22970 [D loss: 0.483789, acc.: 79.69%] [G loss: 1.256333]\n",
      "epoch:24 step:22971 [D loss: 0.390316, acc.: 85.94%] [G loss: 1.152903]\n",
      "epoch:24 step:22972 [D loss: 0.332933, acc.: 92.97%] [G loss: 1.391512]\n",
      "epoch:24 step:22973 [D loss: 0.358568, acc.: 89.06%] [G loss: 1.302563]\n",
      "epoch:24 step:22974 [D loss: 0.368760, acc.: 92.97%] [G loss: 1.689875]\n",
      "epoch:24 step:22975 [D loss: 0.372046, acc.: 87.50%] [G loss: 1.530252]\n",
      "epoch:24 step:22976 [D loss: 0.522324, acc.: 75.78%] [G loss: 1.214599]\n",
      "epoch:24 step:22977 [D loss: 0.612719, acc.: 68.75%] [G loss: 1.287629]\n",
      "epoch:24 step:22978 [D loss: 0.546325, acc.: 75.78%] [G loss: 1.341500]\n",
      "epoch:24 step:22979 [D loss: 0.676192, acc.: 57.03%] [G loss: 1.006019]\n",
      "epoch:24 step:22980 [D loss: 0.671779, acc.: 61.72%] [G loss: 1.110063]\n",
      "epoch:24 step:22981 [D loss: 0.632611, acc.: 63.28%] [G loss: 0.970884]\n",
      "epoch:24 step:22982 [D loss: 0.872002, acc.: 45.31%] [G loss: 1.014621]\n",
      "epoch:24 step:22983 [D loss: 0.497632, acc.: 78.91%] [G loss: 1.237766]\n",
      "epoch:24 step:22984 [D loss: 0.448587, acc.: 88.28%] [G loss: 1.110381]\n",
      "epoch:24 step:22985 [D loss: 0.390894, acc.: 83.59%] [G loss: 1.207916]\n",
      "epoch:24 step:22986 [D loss: 0.347742, acc.: 92.19%] [G loss: 1.309025]\n",
      "epoch:24 step:22987 [D loss: 0.350044, acc.: 88.28%] [G loss: 1.677795]\n",
      "epoch:24 step:22988 [D loss: 0.836519, acc.: 42.19%] [G loss: 1.484666]\n",
      "epoch:24 step:22989 [D loss: 0.756669, acc.: 54.69%] [G loss: 1.361330]\n",
      "epoch:24 step:22990 [D loss: 0.914194, acc.: 28.91%] [G loss: 0.751828]\n",
      "epoch:24 step:22991 [D loss: 0.525372, acc.: 75.78%] [G loss: 0.905094]\n",
      "epoch:24 step:22992 [D loss: 0.388418, acc.: 87.50%] [G loss: 1.322019]\n",
      "epoch:24 step:22993 [D loss: 0.472345, acc.: 81.25%] [G loss: 1.337656]\n",
      "epoch:24 step:22994 [D loss: 0.524789, acc.: 76.56%] [G loss: 1.428824]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22995 [D loss: 0.390730, acc.: 87.50%] [G loss: 1.286863]\n",
      "epoch:24 step:22996 [D loss: 0.346574, acc.: 89.84%] [G loss: 1.159402]\n",
      "epoch:24 step:22997 [D loss: 0.811255, acc.: 46.88%] [G loss: 1.140362]\n",
      "epoch:24 step:22998 [D loss: 0.848241, acc.: 44.53%] [G loss: 0.911085]\n",
      "epoch:24 step:22999 [D loss: 0.448670, acc.: 80.47%] [G loss: 1.095278]\n",
      "epoch:24 step:23000 [D loss: 0.465559, acc.: 79.69%] [G loss: 1.313580]\n",
      "##############\n",
      "[2.32288662 1.58281561 5.52052725 4.56572867 3.14812804 5.45501758\n",
      " 4.16773238 4.32962274 4.39997012 3.72674624]\n",
      "##########\n",
      "epoch:24 step:23001 [D loss: 0.520646, acc.: 67.97%] [G loss: 1.144841]\n",
      "epoch:24 step:23002 [D loss: 0.507527, acc.: 78.12%] [G loss: 1.182349]\n",
      "epoch:24 step:23003 [D loss: 0.532658, acc.: 75.78%] [G loss: 1.296013]\n",
      "epoch:24 step:23004 [D loss: 0.590614, acc.: 65.62%] [G loss: 1.260621]\n",
      "epoch:24 step:23005 [D loss: 0.383807, acc.: 91.41%] [G loss: 1.537051]\n",
      "epoch:24 step:23006 [D loss: 0.490646, acc.: 80.47%] [G loss: 1.298171]\n",
      "epoch:24 step:23007 [D loss: 0.416706, acc.: 88.28%] [G loss: 1.212034]\n",
      "epoch:24 step:23008 [D loss: 0.373372, acc.: 89.06%] [G loss: 1.425915]\n",
      "epoch:24 step:23009 [D loss: 0.610066, acc.: 66.41%] [G loss: 1.198523]\n",
      "epoch:24 step:23010 [D loss: 0.473580, acc.: 75.78%] [G loss: 1.223630]\n",
      "epoch:24 step:23011 [D loss: 0.416664, acc.: 88.28%] [G loss: 1.338676]\n",
      "epoch:24 step:23012 [D loss: 0.611061, acc.: 61.72%] [G loss: 1.234621]\n",
      "epoch:24 step:23013 [D loss: 0.467519, acc.: 81.25%] [G loss: 1.015851]\n",
      "epoch:24 step:23014 [D loss: 0.483772, acc.: 84.38%] [G loss: 1.138302]\n",
      "epoch:24 step:23015 [D loss: 0.690504, acc.: 60.94%] [G loss: 0.812474]\n",
      "epoch:24 step:23016 [D loss: 0.669348, acc.: 60.94%] [G loss: 0.821846]\n",
      "epoch:24 step:23017 [D loss: 0.758967, acc.: 51.56%] [G loss: 0.996654]\n",
      "epoch:24 step:23018 [D loss: 0.533464, acc.: 74.22%] [G loss: 1.273048]\n",
      "epoch:24 step:23019 [D loss: 0.630367, acc.: 64.84%] [G loss: 0.841772]\n",
      "epoch:24 step:23020 [D loss: 0.475493, acc.: 82.03%] [G loss: 1.068558]\n",
      "epoch:24 step:23021 [D loss: 0.342327, acc.: 85.16%] [G loss: 1.353276]\n",
      "epoch:24 step:23022 [D loss: 0.358170, acc.: 92.19%] [G loss: 1.302118]\n",
      "epoch:24 step:23023 [D loss: 0.517184, acc.: 75.00%] [G loss: 1.335226]\n",
      "epoch:24 step:23024 [D loss: 0.470920, acc.: 83.59%] [G loss: 1.149783]\n",
      "epoch:24 step:23025 [D loss: 0.374070, acc.: 87.50%] [G loss: 1.417162]\n",
      "epoch:24 step:23026 [D loss: 0.666866, acc.: 63.28%] [G loss: 1.160206]\n",
      "epoch:24 step:23027 [D loss: 0.645633, acc.: 59.38%] [G loss: 0.927073]\n",
      "epoch:24 step:23028 [D loss: 0.591619, acc.: 70.31%] [G loss: 1.196602]\n",
      "epoch:24 step:23029 [D loss: 0.602863, acc.: 66.41%] [G loss: 1.007361]\n",
      "epoch:24 step:23030 [D loss: 0.576226, acc.: 67.97%] [G loss: 0.995533]\n",
      "epoch:24 step:23031 [D loss: 0.466343, acc.: 79.69%] [G loss: 1.336014]\n",
      "epoch:24 step:23032 [D loss: 0.529303, acc.: 77.34%] [G loss: 1.091932]\n",
      "epoch:24 step:23033 [D loss: 0.327067, acc.: 94.53%] [G loss: 1.579701]\n",
      "epoch:24 step:23034 [D loss: 0.311931, acc.: 96.09%] [G loss: 1.237511]\n",
      "epoch:24 step:23035 [D loss: 0.330912, acc.: 92.19%] [G loss: 1.588423]\n",
      "epoch:24 step:23036 [D loss: 0.351546, acc.: 92.19%] [G loss: 1.251626]\n",
      "epoch:24 step:23037 [D loss: 0.254505, acc.: 96.88%] [G loss: 1.321762]\n",
      "epoch:24 step:23038 [D loss: 0.339385, acc.: 90.62%] [G loss: 1.459452]\n",
      "epoch:24 step:23039 [D loss: 0.238466, acc.: 99.22%] [G loss: 1.731904]\n",
      "epoch:24 step:23040 [D loss: 0.310751, acc.: 95.31%] [G loss: 1.432651]\n",
      "epoch:24 step:23041 [D loss: 0.437008, acc.: 88.28%] [G loss: 1.680069]\n",
      "epoch:24 step:23042 [D loss: 0.282422, acc.: 96.09%] [G loss: 1.577214]\n",
      "epoch:24 step:23043 [D loss: 0.379066, acc.: 88.28%] [G loss: 1.707113]\n",
      "epoch:24 step:23044 [D loss: 0.378570, acc.: 88.28%] [G loss: 1.395109]\n",
      "epoch:24 step:23045 [D loss: 0.328418, acc.: 89.06%] [G loss: 1.601512]\n",
      "epoch:24 step:23046 [D loss: 0.408552, acc.: 85.16%] [G loss: 1.401487]\n",
      "epoch:24 step:23047 [D loss: 0.971616, acc.: 39.84%] [G loss: 1.547535]\n",
      "epoch:24 step:23048 [D loss: 1.072154, acc.: 39.84%] [G loss: 1.236868]\n",
      "epoch:24 step:23049 [D loss: 0.744736, acc.: 52.34%] [G loss: 0.886194]\n",
      "epoch:24 step:23050 [D loss: 0.779095, acc.: 52.34%] [G loss: 1.438222]\n",
      "epoch:24 step:23051 [D loss: 0.770322, acc.: 49.22%] [G loss: 1.183151]\n",
      "epoch:24 step:23052 [D loss: 0.504409, acc.: 75.00%] [G loss: 1.360727]\n",
      "epoch:24 step:23053 [D loss: 0.547466, acc.: 75.00%] [G loss: 1.121989]\n",
      "epoch:24 step:23054 [D loss: 0.324227, acc.: 91.41%] [G loss: 1.449292]\n",
      "epoch:24 step:23055 [D loss: 0.222675, acc.: 99.22%] [G loss: 1.724061]\n",
      "epoch:24 step:23056 [D loss: 0.542808, acc.: 74.22%] [G loss: 1.459980]\n",
      "epoch:24 step:23057 [D loss: 0.863574, acc.: 43.75%] [G loss: 0.683333]\n",
      "epoch:24 step:23058 [D loss: 0.618267, acc.: 60.16%] [G loss: 0.904225]\n",
      "epoch:24 step:23059 [D loss: 0.541803, acc.: 78.12%] [G loss: 0.921413]\n",
      "epoch:24 step:23060 [D loss: 0.737408, acc.: 52.34%] [G loss: 0.844931]\n",
      "epoch:24 step:23061 [D loss: 0.656570, acc.: 63.28%] [G loss: 0.864017]\n",
      "epoch:24 step:23062 [D loss: 0.402384, acc.: 88.28%] [G loss: 1.698374]\n",
      "epoch:24 step:23063 [D loss: 0.520725, acc.: 76.56%] [G loss: 1.332160]\n",
      "epoch:24 step:23064 [D loss: 0.401033, acc.: 87.50%] [G loss: 1.502196]\n",
      "epoch:24 step:23065 [D loss: 0.402035, acc.: 90.62%] [G loss: 1.685073]\n",
      "epoch:24 step:23066 [D loss: 0.449602, acc.: 79.69%] [G loss: 0.998324]\n",
      "epoch:24 step:23067 [D loss: 0.480336, acc.: 82.81%] [G loss: 1.298994]\n",
      "epoch:24 step:23068 [D loss: 0.811842, acc.: 40.62%] [G loss: 1.053254]\n",
      "epoch:24 step:23069 [D loss: 0.562189, acc.: 75.00%] [G loss: 1.289774]\n",
      "epoch:24 step:23070 [D loss: 0.816031, acc.: 39.06%] [G loss: 0.935546]\n",
      "epoch:24 step:23071 [D loss: 0.807101, acc.: 42.19%] [G loss: 0.750063]\n",
      "epoch:24 step:23072 [D loss: 1.029737, acc.: 25.78%] [G loss: 0.673237]\n",
      "epoch:24 step:23073 [D loss: 0.706264, acc.: 57.81%] [G loss: 1.122698]\n",
      "epoch:24 step:23074 [D loss: 0.816125, acc.: 45.31%] [G loss: 0.828826]\n",
      "epoch:24 step:23075 [D loss: 0.463373, acc.: 79.69%] [G loss: 1.410406]\n",
      "epoch:24 step:23076 [D loss: 0.439103, acc.: 79.69%] [G loss: 1.193843]\n",
      "epoch:24 step:23077 [D loss: 0.374987, acc.: 85.94%] [G loss: 1.405377]\n",
      "epoch:24 step:23078 [D loss: 0.749580, acc.: 50.00%] [G loss: 1.310333]\n",
      "epoch:24 step:23079 [D loss: 0.640381, acc.: 60.94%] [G loss: 1.202312]\n",
      "epoch:24 step:23080 [D loss: 0.459203, acc.: 85.16%] [G loss: 1.327149]\n",
      "epoch:24 step:23081 [D loss: 0.733137, acc.: 54.69%] [G loss: 1.244846]\n",
      "epoch:24 step:23082 [D loss: 0.681608, acc.: 59.38%] [G loss: 1.018210]\n",
      "epoch:24 step:23083 [D loss: 0.589724, acc.: 66.41%] [G loss: 1.184209]\n",
      "epoch:24 step:23084 [D loss: 0.503576, acc.: 80.47%] [G loss: 1.107898]\n",
      "epoch:24 step:23085 [D loss: 0.511707, acc.: 78.12%] [G loss: 1.517470]\n",
      "epoch:24 step:23086 [D loss: 0.297800, acc.: 94.53%] [G loss: 1.527624]\n",
      "epoch:24 step:23087 [D loss: 0.565276, acc.: 71.88%] [G loss: 1.501792]\n",
      "epoch:24 step:23088 [D loss: 0.755827, acc.: 49.22%] [G loss: 1.318594]\n",
      "epoch:24 step:23089 [D loss: 0.719580, acc.: 52.34%] [G loss: 0.872604]\n",
      "epoch:24 step:23090 [D loss: 0.571950, acc.: 71.09%] [G loss: 0.927934]\n",
      "epoch:24 step:23091 [D loss: 0.421169, acc.: 82.81%] [G loss: 1.068405]\n",
      "epoch:24 step:23092 [D loss: 0.358951, acc.: 84.38%] [G loss: 1.683390]\n",
      "epoch:24 step:23093 [D loss: 0.386734, acc.: 85.94%] [G loss: 1.567303]\n",
      "epoch:24 step:23094 [D loss: 0.542428, acc.: 74.22%] [G loss: 1.163519]\n",
      "epoch:24 step:23095 [D loss: 0.608142, acc.: 60.16%] [G loss: 1.226856]\n",
      "epoch:24 step:23096 [D loss: 0.519375, acc.: 75.78%] [G loss: 1.226754]\n",
      "epoch:24 step:23097 [D loss: 0.748078, acc.: 53.12%] [G loss: 0.920164]\n",
      "epoch:24 step:23098 [D loss: 0.453532, acc.: 85.94%] [G loss: 1.382387]\n",
      "epoch:24 step:23099 [D loss: 0.817958, acc.: 42.97%] [G loss: 1.103152]\n",
      "epoch:24 step:23100 [D loss: 0.846361, acc.: 43.75%] [G loss: 0.642894]\n",
      "epoch:24 step:23101 [D loss: 0.277584, acc.: 97.66%] [G loss: 1.499732]\n",
      "epoch:24 step:23102 [D loss: 0.347757, acc.: 89.06%] [G loss: 1.369534]\n",
      "epoch:24 step:23103 [D loss: 0.264248, acc.: 96.09%] [G loss: 1.651469]\n",
      "epoch:24 step:23104 [D loss: 0.260952, acc.: 94.53%] [G loss: 1.639849]\n",
      "epoch:24 step:23105 [D loss: 0.443181, acc.: 87.50%] [G loss: 1.464314]\n",
      "epoch:24 step:23106 [D loss: 0.824905, acc.: 45.31%] [G loss: 0.830116]\n",
      "epoch:24 step:23107 [D loss: 0.771551, acc.: 48.44%] [G loss: 1.192106]\n",
      "epoch:24 step:23108 [D loss: 1.052782, acc.: 28.12%] [G loss: 0.674801]\n",
      "epoch:24 step:23109 [D loss: 0.992448, acc.: 28.12%] [G loss: 0.920710]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:23110 [D loss: 0.784989, acc.: 48.44%] [G loss: 0.977701]\n",
      "epoch:24 step:23111 [D loss: 0.506904, acc.: 75.00%] [G loss: 1.187938]\n",
      "epoch:24 step:23112 [D loss: 0.475086, acc.: 81.25%] [G loss: 1.311447]\n",
      "epoch:24 step:23113 [D loss: 1.050510, acc.: 31.25%] [G loss: 0.857359]\n",
      "epoch:24 step:23114 [D loss: 0.745082, acc.: 55.47%] [G loss: 1.033944]\n",
      "epoch:24 step:23115 [D loss: 0.902228, acc.: 35.94%] [G loss: 0.721285]\n",
      "epoch:24 step:23116 [D loss: 1.048872, acc.: 22.66%] [G loss: 0.847296]\n",
      "epoch:24 step:23117 [D loss: 0.532833, acc.: 73.44%] [G loss: 1.163738]\n",
      "epoch:24 step:23118 [D loss: 0.505086, acc.: 79.69%] [G loss: 1.409033]\n",
      "epoch:24 step:23119 [D loss: 0.650254, acc.: 59.38%] [G loss: 1.223324]\n",
      "epoch:24 step:23120 [D loss: 0.701111, acc.: 54.69%] [G loss: 0.778597]\n",
      "epoch:24 step:23121 [D loss: 0.533348, acc.: 75.00%] [G loss: 1.300367]\n",
      "epoch:24 step:23122 [D loss: 0.562224, acc.: 69.53%] [G loss: 1.143673]\n",
      "epoch:24 step:23123 [D loss: 0.751118, acc.: 58.59%] [G loss: 1.035127]\n",
      "epoch:24 step:23124 [D loss: 0.613426, acc.: 69.53%] [G loss: 1.165574]\n",
      "epoch:24 step:23125 [D loss: 0.774691, acc.: 49.22%] [G loss: 0.970456]\n",
      "epoch:24 step:23126 [D loss: 0.634104, acc.: 64.06%] [G loss: 1.115665]\n",
      "epoch:24 step:23127 [D loss: 0.934101, acc.: 30.47%] [G loss: 1.137025]\n",
      "epoch:24 step:23128 [D loss: 0.670127, acc.: 59.38%] [G loss: 1.135478]\n",
      "epoch:24 step:23129 [D loss: 0.555940, acc.: 75.00%] [G loss: 1.223572]\n",
      "epoch:24 step:23130 [D loss: 0.583679, acc.: 70.31%] [G loss: 1.169909]\n",
      "epoch:24 step:23131 [D loss: 0.655735, acc.: 66.41%] [G loss: 1.222898]\n",
      "epoch:24 step:23132 [D loss: 0.719515, acc.: 52.34%] [G loss: 1.018756]\n",
      "epoch:24 step:23133 [D loss: 0.689191, acc.: 57.81%] [G loss: 1.220526]\n",
      "epoch:24 step:23134 [D loss: 0.586758, acc.: 68.75%] [G loss: 1.135885]\n",
      "epoch:24 step:23135 [D loss: 0.411564, acc.: 88.28%] [G loss: 1.452606]\n",
      "epoch:24 step:23136 [D loss: 0.509215, acc.: 76.56%] [G loss: 1.207120]\n",
      "epoch:24 step:23137 [D loss: 0.670227, acc.: 60.94%] [G loss: 0.905527]\n",
      "epoch:24 step:23138 [D loss: 0.688480, acc.: 58.59%] [G loss: 1.107483]\n",
      "epoch:24 step:23139 [D loss: 0.728937, acc.: 50.78%] [G loss: 1.240712]\n",
      "epoch:24 step:23140 [D loss: 0.705471, acc.: 57.03%] [G loss: 0.914481]\n",
      "epoch:24 step:23141 [D loss: 0.618152, acc.: 63.28%] [G loss: 1.131203]\n",
      "epoch:24 step:23142 [D loss: 0.531645, acc.: 79.69%] [G loss: 1.174353]\n",
      "epoch:24 step:23143 [D loss: 0.693216, acc.: 57.81%] [G loss: 1.082371]\n",
      "epoch:24 step:23144 [D loss: 0.569292, acc.: 68.75%] [G loss: 1.004283]\n",
      "epoch:24 step:23145 [D loss: 0.606480, acc.: 68.75%] [G loss: 1.038549]\n",
      "epoch:24 step:23146 [D loss: 0.506763, acc.: 76.56%] [G loss: 1.228755]\n",
      "epoch:24 step:23147 [D loss: 0.816849, acc.: 42.19%] [G loss: 0.894551]\n",
      "epoch:24 step:23148 [D loss: 0.590594, acc.: 64.84%] [G loss: 1.136073]\n",
      "epoch:24 step:23149 [D loss: 0.533660, acc.: 73.44%] [G loss: 1.054306]\n",
      "epoch:24 step:23150 [D loss: 0.393171, acc.: 87.50%] [G loss: 1.253930]\n",
      "epoch:24 step:23151 [D loss: 0.244755, acc.: 94.53%] [G loss: 1.559245]\n",
      "epoch:24 step:23152 [D loss: 0.245200, acc.: 94.53%] [G loss: 1.701015]\n",
      "epoch:24 step:23153 [D loss: 0.221834, acc.: 97.66%] [G loss: 1.540071]\n",
      "epoch:24 step:23154 [D loss: 0.378173, acc.: 88.28%] [G loss: 1.682984]\n",
      "epoch:24 step:23155 [D loss: 0.427716, acc.: 82.81%] [G loss: 1.617611]\n",
      "epoch:24 step:23156 [D loss: 0.588846, acc.: 70.31%] [G loss: 1.195675]\n",
      "epoch:24 step:23157 [D loss: 0.466989, acc.: 80.47%] [G loss: 1.375791]\n",
      "epoch:24 step:23158 [D loss: 0.539274, acc.: 73.44%] [G loss: 1.176131]\n",
      "epoch:24 step:23159 [D loss: 0.690578, acc.: 58.59%] [G loss: 1.167874]\n",
      "epoch:24 step:23160 [D loss: 0.629159, acc.: 63.28%] [G loss: 1.118963]\n",
      "epoch:24 step:23161 [D loss: 0.847407, acc.: 42.97%] [G loss: 1.239993]\n",
      "epoch:24 step:23162 [D loss: 0.826892, acc.: 52.34%] [G loss: 1.051814]\n",
      "epoch:24 step:23163 [D loss: 0.787627, acc.: 39.06%] [G loss: 1.199352]\n",
      "epoch:24 step:23164 [D loss: 0.680145, acc.: 61.72%] [G loss: 0.860316]\n",
      "epoch:24 step:23165 [D loss: 0.776188, acc.: 45.31%] [G loss: 0.989001]\n",
      "epoch:24 step:23166 [D loss: 1.007108, acc.: 28.12%] [G loss: 0.925184]\n",
      "epoch:24 step:23167 [D loss: 0.745189, acc.: 50.78%] [G loss: 1.054937]\n",
      "epoch:24 step:23168 [D loss: 0.749499, acc.: 46.88%] [G loss: 1.201051]\n",
      "epoch:24 step:23169 [D loss: 0.769831, acc.: 46.88%] [G loss: 0.912599]\n",
      "epoch:24 step:23170 [D loss: 0.504280, acc.: 78.91%] [G loss: 1.176899]\n",
      "epoch:24 step:23171 [D loss: 0.820351, acc.: 47.66%] [G loss: 0.725214]\n",
      "epoch:24 step:23172 [D loss: 0.809597, acc.: 45.31%] [G loss: 0.745463]\n",
      "epoch:24 step:23173 [D loss: 0.818813, acc.: 42.97%] [G loss: 0.992817]\n",
      "epoch:24 step:23174 [D loss: 0.813414, acc.: 46.09%] [G loss: 1.169222]\n",
      "epoch:24 step:23175 [D loss: 0.731428, acc.: 56.25%] [G loss: 1.137907]\n",
      "epoch:24 step:23176 [D loss: 0.747174, acc.: 49.22%] [G loss: 0.947562]\n",
      "epoch:24 step:23177 [D loss: 0.680942, acc.: 57.03%] [G loss: 0.948451]\n",
      "epoch:24 step:23178 [D loss: 0.482429, acc.: 81.25%] [G loss: 1.263669]\n",
      "epoch:24 step:23179 [D loss: 0.404152, acc.: 89.84%] [G loss: 1.574777]\n",
      "epoch:24 step:23180 [D loss: 0.461852, acc.: 81.25%] [G loss: 1.414197]\n",
      "epoch:24 step:23181 [D loss: 0.475141, acc.: 79.69%] [G loss: 1.322457]\n",
      "epoch:24 step:23182 [D loss: 0.285693, acc.: 96.88%] [G loss: 1.861787]\n",
      "epoch:24 step:23183 [D loss: 0.469319, acc.: 83.59%] [G loss: 1.459409]\n",
      "epoch:24 step:23184 [D loss: 0.693809, acc.: 53.12%] [G loss: 1.229867]\n",
      "epoch:24 step:23185 [D loss: 0.614155, acc.: 65.62%] [G loss: 0.920505]\n",
      "epoch:24 step:23186 [D loss: 0.569957, acc.: 71.88%] [G loss: 1.287984]\n",
      "epoch:24 step:23187 [D loss: 0.620572, acc.: 67.97%] [G loss: 1.033382]\n",
      "epoch:24 step:23188 [D loss: 0.540364, acc.: 71.88%] [G loss: 1.060027]\n",
      "epoch:24 step:23189 [D loss: 0.493800, acc.: 78.91%] [G loss: 1.199687]\n",
      "epoch:24 step:23190 [D loss: 0.724770, acc.: 53.91%] [G loss: 0.907099]\n",
      "epoch:24 step:23191 [D loss: 0.701730, acc.: 53.12%] [G loss: 1.198692]\n",
      "epoch:24 step:23192 [D loss: 0.715571, acc.: 55.47%] [G loss: 0.940572]\n",
      "epoch:24 step:23193 [D loss: 0.625212, acc.: 63.28%] [G loss: 0.965975]\n",
      "epoch:24 step:23194 [D loss: 0.527851, acc.: 78.12%] [G loss: 1.089843]\n",
      "epoch:24 step:23195 [D loss: 0.490796, acc.: 78.91%] [G loss: 1.158198]\n",
      "epoch:24 step:23196 [D loss: 0.507699, acc.: 78.12%] [G loss: 1.329824]\n",
      "epoch:24 step:23197 [D loss: 0.520185, acc.: 82.03%] [G loss: 1.153207]\n",
      "epoch:24 step:23198 [D loss: 0.444567, acc.: 84.38%] [G loss: 1.517155]\n",
      "epoch:24 step:23199 [D loss: 0.435704, acc.: 85.94%] [G loss: 1.501448]\n",
      "epoch:24 step:23200 [D loss: 0.695595, acc.: 57.03%] [G loss: 1.118619]\n",
      "##############\n",
      "[2.31563519 1.49334109 5.44404858 4.19378537 3.18124138 5.3276108\n",
      " 4.04358029 4.67285319 4.0496773  3.86568028]\n",
      "##########\n",
      "epoch:24 step:23201 [D loss: 0.518356, acc.: 73.44%] [G loss: 1.141390]\n",
      "epoch:24 step:23202 [D loss: 0.689587, acc.: 59.38%] [G loss: 0.968192]\n",
      "epoch:24 step:23203 [D loss: 0.663670, acc.: 55.47%] [G loss: 0.970250]\n",
      "epoch:24 step:23204 [D loss: 0.526080, acc.: 77.34%] [G loss: 1.015725]\n",
      "epoch:24 step:23205 [D loss: 0.617900, acc.: 63.28%] [G loss: 0.839244]\n",
      "epoch:24 step:23206 [D loss: 0.608613, acc.: 67.19%] [G loss: 1.294182]\n",
      "epoch:24 step:23207 [D loss: 0.576542, acc.: 67.97%] [G loss: 1.391627]\n",
      "epoch:24 step:23208 [D loss: 0.426268, acc.: 86.72%] [G loss: 1.280025]\n",
      "epoch:24 step:23209 [D loss: 0.583355, acc.: 71.88%] [G loss: 1.078673]\n",
      "epoch:24 step:23210 [D loss: 0.644501, acc.: 64.06%] [G loss: 1.298675]\n",
      "epoch:24 step:23211 [D loss: 0.590999, acc.: 67.19%] [G loss: 1.045174]\n",
      "epoch:24 step:23212 [D loss: 0.454700, acc.: 77.34%] [G loss: 1.191911]\n",
      "epoch:24 step:23213 [D loss: 0.554505, acc.: 73.44%] [G loss: 1.146378]\n",
      "epoch:24 step:23214 [D loss: 0.585186, acc.: 69.53%] [G loss: 1.102474]\n",
      "epoch:24 step:23215 [D loss: 0.628329, acc.: 62.50%] [G loss: 1.027971]\n",
      "epoch:24 step:23216 [D loss: 0.572588, acc.: 70.31%] [G loss: 1.325073]\n",
      "epoch:24 step:23217 [D loss: 0.560723, acc.: 69.53%] [G loss: 1.363100]\n",
      "epoch:24 step:23218 [D loss: 0.549308, acc.: 72.66%] [G loss: 1.360173]\n",
      "epoch:24 step:23219 [D loss: 0.399570, acc.: 89.84%] [G loss: 1.471276]\n",
      "epoch:24 step:23220 [D loss: 0.419624, acc.: 84.38%] [G loss: 1.349954]\n",
      "epoch:24 step:23221 [D loss: 0.445571, acc.: 84.38%] [G loss: 1.321177]\n",
      "epoch:24 step:23222 [D loss: 0.717367, acc.: 54.69%] [G loss: 1.261752]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:23223 [D loss: 0.714109, acc.: 55.47%] [G loss: 1.078869]\n",
      "epoch:24 step:23224 [D loss: 0.666491, acc.: 59.38%] [G loss: 1.248554]\n",
      "epoch:24 step:23225 [D loss: 0.699652, acc.: 56.25%] [G loss: 1.196187]\n",
      "epoch:24 step:23226 [D loss: 0.720397, acc.: 57.03%] [G loss: 0.840911]\n",
      "epoch:24 step:23227 [D loss: 0.580822, acc.: 72.66%] [G loss: 0.956480]\n",
      "epoch:24 step:23228 [D loss: 0.475782, acc.: 83.59%] [G loss: 1.239372]\n",
      "epoch:24 step:23229 [D loss: 0.749226, acc.: 55.47%] [G loss: 1.101708]\n",
      "epoch:24 step:23230 [D loss: 0.582485, acc.: 69.53%] [G loss: 1.182722]\n",
      "epoch:24 step:23231 [D loss: 0.445330, acc.: 85.16%] [G loss: 1.273527]\n",
      "epoch:24 step:23232 [D loss: 0.698786, acc.: 57.81%] [G loss: 1.041843]\n",
      "epoch:24 step:23233 [D loss: 0.362809, acc.: 89.06%] [G loss: 1.299194]\n",
      "epoch:24 step:23234 [D loss: 0.516257, acc.: 78.91%] [G loss: 1.080451]\n",
      "epoch:24 step:23235 [D loss: 0.488916, acc.: 81.25%] [G loss: 1.152605]\n",
      "epoch:24 step:23236 [D loss: 0.598922, acc.: 64.84%] [G loss: 1.234453]\n",
      "epoch:24 step:23237 [D loss: 0.709992, acc.: 52.34%] [G loss: 1.111826]\n",
      "epoch:24 step:23238 [D loss: 0.738599, acc.: 55.47%] [G loss: 0.929402]\n",
      "epoch:24 step:23239 [D loss: 0.509408, acc.: 75.00%] [G loss: 1.117153]\n",
      "epoch:24 step:23240 [D loss: 0.690304, acc.: 57.81%] [G loss: 1.238341]\n",
      "epoch:24 step:23241 [D loss: 0.510689, acc.: 82.81%] [G loss: 1.110601]\n",
      "epoch:24 step:23242 [D loss: 0.688704, acc.: 56.25%] [G loss: 0.908484]\n",
      "epoch:24 step:23243 [D loss: 0.443630, acc.: 75.78%] [G loss: 1.186276]\n",
      "epoch:24 step:23244 [D loss: 0.451652, acc.: 82.03%] [G loss: 1.516212]\n",
      "epoch:24 step:23245 [D loss: 0.395627, acc.: 88.28%] [G loss: 1.254163]\n",
      "epoch:24 step:23246 [D loss: 0.631915, acc.: 61.72%] [G loss: 0.994382]\n",
      "epoch:24 step:23247 [D loss: 0.804584, acc.: 40.62%] [G loss: 0.930714]\n",
      "epoch:24 step:23248 [D loss: 0.865694, acc.: 39.06%] [G loss: 1.042395]\n",
      "epoch:24 step:23249 [D loss: 0.737368, acc.: 52.34%] [G loss: 1.048008]\n",
      "epoch:24 step:23250 [D loss: 0.701268, acc.: 54.69%] [G loss: 0.851713]\n",
      "epoch:24 step:23251 [D loss: 0.459755, acc.: 78.91%] [G loss: 1.203572]\n",
      "epoch:24 step:23252 [D loss: 0.414332, acc.: 85.16%] [G loss: 1.394690]\n",
      "epoch:24 step:23253 [D loss: 1.035582, acc.: 28.12%] [G loss: 0.995529]\n",
      "epoch:24 step:23254 [D loss: 0.938646, acc.: 33.59%] [G loss: 1.064052]\n",
      "epoch:24 step:23255 [D loss: 0.552870, acc.: 72.66%] [G loss: 1.366504]\n",
      "epoch:24 step:23256 [D loss: 0.607969, acc.: 65.62%] [G loss: 0.998776]\n",
      "epoch:24 step:23257 [D loss: 0.413151, acc.: 85.94%] [G loss: 1.276486]\n",
      "epoch:24 step:23258 [D loss: 0.604794, acc.: 66.41%] [G loss: 1.164659]\n",
      "epoch:24 step:23259 [D loss: 0.697361, acc.: 59.38%] [G loss: 0.925777]\n",
      "epoch:24 step:23260 [D loss: 0.665522, acc.: 60.94%] [G loss: 1.041055]\n",
      "epoch:24 step:23261 [D loss: 0.552731, acc.: 71.09%] [G loss: 0.964790]\n",
      "epoch:24 step:23262 [D loss: 0.395014, acc.: 80.47%] [G loss: 1.161438]\n",
      "epoch:24 step:23263 [D loss: 0.246272, acc.: 96.09%] [G loss: 1.663292]\n",
      "epoch:24 step:23264 [D loss: 0.611901, acc.: 66.41%] [G loss: 1.278461]\n",
      "epoch:24 step:23265 [D loss: 0.393690, acc.: 89.84%] [G loss: 1.642038]\n",
      "epoch:24 step:23266 [D loss: 0.615910, acc.: 67.19%] [G loss: 1.600474]\n",
      "epoch:24 step:23267 [D loss: 0.898664, acc.: 38.28%] [G loss: 0.942792]\n",
      "epoch:24 step:23268 [D loss: 0.697242, acc.: 56.25%] [G loss: 0.946055]\n",
      "epoch:24 step:23269 [D loss: 0.531306, acc.: 75.78%] [G loss: 1.236670]\n",
      "epoch:24 step:23270 [D loss: 0.484789, acc.: 79.69%] [G loss: 1.231716]\n",
      "epoch:24 step:23271 [D loss: 0.722208, acc.: 52.34%] [G loss: 1.107632]\n",
      "epoch:24 step:23272 [D loss: 0.703505, acc.: 57.81%] [G loss: 0.929310]\n",
      "epoch:24 step:23273 [D loss: 0.694945, acc.: 57.03%] [G loss: 1.068823]\n",
      "epoch:24 step:23274 [D loss: 0.514397, acc.: 76.56%] [G loss: 1.127214]\n",
      "epoch:24 step:23275 [D loss: 0.821497, acc.: 44.53%] [G loss: 0.912780]\n",
      "epoch:24 step:23276 [D loss: 0.729186, acc.: 53.12%] [G loss: 1.231212]\n",
      "epoch:24 step:23277 [D loss: 0.640490, acc.: 64.84%] [G loss: 1.025196]\n",
      "epoch:24 step:23278 [D loss: 0.648483, acc.: 60.94%] [G loss: 0.989589]\n",
      "epoch:24 step:23279 [D loss: 0.550242, acc.: 73.44%] [G loss: 1.231405]\n",
      "epoch:24 step:23280 [D loss: 0.371563, acc.: 91.41%] [G loss: 1.414702]\n",
      "epoch:24 step:23281 [D loss: 0.509720, acc.: 76.56%] [G loss: 1.082765]\n",
      "epoch:24 step:23282 [D loss: 0.307647, acc.: 91.41%] [G loss: 1.505835]\n",
      "epoch:24 step:23283 [D loss: 0.676506, acc.: 64.84%] [G loss: 1.096164]\n",
      "epoch:24 step:23284 [D loss: 0.461488, acc.: 86.72%] [G loss: 1.342565]\n",
      "epoch:24 step:23285 [D loss: 0.655339, acc.: 59.38%] [G loss: 0.880030]\n",
      "epoch:24 step:23286 [D loss: 0.600609, acc.: 65.62%] [G loss: 1.128975]\n",
      "epoch:24 step:23287 [D loss: 0.703727, acc.: 60.94%] [G loss: 0.944267]\n",
      "epoch:24 step:23288 [D loss: 0.637339, acc.: 63.28%] [G loss: 0.830455]\n",
      "epoch:24 step:23289 [D loss: 0.551000, acc.: 73.44%] [G loss: 1.156701]\n",
      "epoch:24 step:23290 [D loss: 0.422074, acc.: 86.72%] [G loss: 1.120916]\n",
      "epoch:24 step:23291 [D loss: 0.565667, acc.: 69.53%] [G loss: 1.161207]\n",
      "epoch:24 step:23292 [D loss: 0.638358, acc.: 64.84%] [G loss: 1.160310]\n",
      "epoch:24 step:23293 [D loss: 0.597727, acc.: 65.62%] [G loss: 0.895847]\n",
      "epoch:24 step:23294 [D loss: 0.420420, acc.: 84.38%] [G loss: 1.218611]\n",
      "epoch:24 step:23295 [D loss: 0.589724, acc.: 69.53%] [G loss: 1.090602]\n",
      "epoch:24 step:23296 [D loss: 0.523326, acc.: 80.47%] [G loss: 1.298473]\n",
      "epoch:24 step:23297 [D loss: 0.499179, acc.: 77.34%] [G loss: 1.183222]\n",
      "epoch:24 step:23298 [D loss: 0.543248, acc.: 73.44%] [G loss: 1.157856]\n",
      "epoch:24 step:23299 [D loss: 0.863203, acc.: 37.50%] [G loss: 0.784969]\n",
      "epoch:24 step:23300 [D loss: 0.585726, acc.: 65.62%] [G loss: 0.912570]\n",
      "epoch:24 step:23301 [D loss: 0.678306, acc.: 57.03%] [G loss: 1.083722]\n",
      "epoch:24 step:23302 [D loss: 0.656237, acc.: 64.84%] [G loss: 1.091307]\n",
      "epoch:24 step:23303 [D loss: 0.346922, acc.: 82.03%] [G loss: 1.131603]\n",
      "epoch:24 step:23304 [D loss: 0.342948, acc.: 96.09%] [G loss: 1.619972]\n",
      "epoch:24 step:23305 [D loss: 0.642688, acc.: 59.38%] [G loss: 1.401064]\n",
      "epoch:24 step:23306 [D loss: 0.658332, acc.: 60.16%] [G loss: 1.089696]\n",
      "epoch:24 step:23307 [D loss: 0.644733, acc.: 61.72%] [G loss: 1.220327]\n",
      "epoch:24 step:23308 [D loss: 0.689844, acc.: 57.81%] [G loss: 0.956385]\n",
      "epoch:24 step:23309 [D loss: 0.814638, acc.: 44.53%] [G loss: 0.955161]\n",
      "epoch:24 step:23310 [D loss: 0.690332, acc.: 55.47%] [G loss: 0.856129]\n",
      "epoch:24 step:23311 [D loss: 0.852865, acc.: 40.62%] [G loss: 0.694171]\n",
      "epoch:24 step:23312 [D loss: 0.472473, acc.: 80.47%] [G loss: 1.051386]\n",
      "epoch:24 step:23313 [D loss: 0.534145, acc.: 76.56%] [G loss: 1.247504]\n",
      "epoch:24 step:23314 [D loss: 0.672796, acc.: 59.38%] [G loss: 1.012794]\n",
      "epoch:24 step:23315 [D loss: 0.931484, acc.: 33.59%] [G loss: 0.832891]\n",
      "epoch:24 step:23316 [D loss: 0.681432, acc.: 59.38%] [G loss: 1.255821]\n",
      "epoch:24 step:23317 [D loss: 0.671676, acc.: 58.59%] [G loss: 0.863416]\n",
      "epoch:24 step:23318 [D loss: 0.668371, acc.: 58.59%] [G loss: 0.755322]\n",
      "epoch:24 step:23319 [D loss: 0.471413, acc.: 75.00%] [G loss: 0.985177]\n",
      "epoch:24 step:23320 [D loss: 0.542456, acc.: 70.31%] [G loss: 1.179673]\n",
      "epoch:24 step:23321 [D loss: 0.529912, acc.: 76.56%] [G loss: 1.009835]\n",
      "epoch:24 step:23322 [D loss: 0.584196, acc.: 71.09%] [G loss: 1.228433]\n",
      "epoch:24 step:23323 [D loss: 0.667278, acc.: 61.72%] [G loss: 1.089068]\n",
      "epoch:24 step:23324 [D loss: 0.465568, acc.: 84.38%] [G loss: 1.206020]\n",
      "epoch:24 step:23325 [D loss: 0.548059, acc.: 72.66%] [G loss: 1.103955]\n",
      "epoch:24 step:23326 [D loss: 0.549174, acc.: 73.44%] [G loss: 1.260881]\n",
      "epoch:24 step:23327 [D loss: 0.480177, acc.: 76.56%] [G loss: 1.429041]\n",
      "epoch:24 step:23328 [D loss: 0.408046, acc.: 87.50%] [G loss: 1.347126]\n",
      "epoch:24 step:23329 [D loss: 0.333333, acc.: 96.88%] [G loss: 1.675811]\n",
      "epoch:24 step:23330 [D loss: 0.473167, acc.: 81.25%] [G loss: 1.303006]\n",
      "epoch:24 step:23331 [D loss: 0.944860, acc.: 43.75%] [G loss: 1.145865]\n",
      "epoch:24 step:23332 [D loss: 0.760709, acc.: 54.69%] [G loss: 1.153744]\n",
      "epoch:24 step:23333 [D loss: 0.580113, acc.: 75.00%] [G loss: 1.073983]\n",
      "epoch:24 step:23334 [D loss: 0.568536, acc.: 75.00%] [G loss: 0.796668]\n",
      "epoch:24 step:23335 [D loss: 0.455581, acc.: 83.59%] [G loss: 1.180628]\n",
      "epoch:24 step:23336 [D loss: 0.548939, acc.: 75.00%] [G loss: 1.389184]\n",
      "epoch:24 step:23337 [D loss: 0.331060, acc.: 89.06%] [G loss: 1.048504]\n",
      "epoch:24 step:23338 [D loss: 0.287131, acc.: 92.19%] [G loss: 1.634116]\n",
      "epoch:24 step:23339 [D loss: 0.409111, acc.: 81.25%] [G loss: 0.957292]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:23340 [D loss: 0.217700, acc.: 96.88%] [G loss: 1.756482]\n",
      "epoch:24 step:23341 [D loss: 0.369934, acc.: 93.75%] [G loss: 1.676309]\n",
      "epoch:24 step:23342 [D loss: 0.263071, acc.: 96.09%] [G loss: 1.945879]\n",
      "epoch:24 step:23343 [D loss: 0.337331, acc.: 92.19%] [G loss: 1.803004]\n",
      "epoch:24 step:23344 [D loss: 0.462788, acc.: 81.25%] [G loss: 1.336005]\n",
      "epoch:24 step:23345 [D loss: 0.527268, acc.: 68.75%] [G loss: 0.927161]\n",
      "epoch:24 step:23346 [D loss: 0.944902, acc.: 39.06%] [G loss: 1.102166]\n",
      "epoch:24 step:23347 [D loss: 0.715178, acc.: 52.34%] [G loss: 1.185397]\n",
      "epoch:24 step:23348 [D loss: 0.582084, acc.: 71.88%] [G loss: 1.166933]\n",
      "epoch:24 step:23349 [D loss: 0.749853, acc.: 55.47%] [G loss: 1.319445]\n",
      "epoch:24 step:23350 [D loss: 0.690498, acc.: 55.47%] [G loss: 0.960580]\n",
      "epoch:24 step:23351 [D loss: 0.596119, acc.: 70.31%] [G loss: 0.931768]\n",
      "epoch:24 step:23352 [D loss: 0.719245, acc.: 54.69%] [G loss: 0.809051]\n",
      "epoch:24 step:23353 [D loss: 0.577536, acc.: 71.88%] [G loss: 0.902234]\n",
      "epoch:24 step:23354 [D loss: 0.732094, acc.: 51.56%] [G loss: 0.769707]\n",
      "epoch:24 step:23355 [D loss: 0.693874, acc.: 57.03%] [G loss: 0.819080]\n",
      "epoch:24 step:23356 [D loss: 0.646823, acc.: 57.03%] [G loss: 0.835860]\n",
      "epoch:24 step:23357 [D loss: 0.603913, acc.: 67.97%] [G loss: 1.013306]\n",
      "epoch:24 step:23358 [D loss: 0.694274, acc.: 56.25%] [G loss: 0.782614]\n",
      "epoch:24 step:23359 [D loss: 0.587593, acc.: 74.22%] [G loss: 1.028172]\n",
      "epoch:24 step:23360 [D loss: 0.616717, acc.: 66.41%] [G loss: 0.951535]\n",
      "epoch:24 step:23361 [D loss: 0.613191, acc.: 64.84%] [G loss: 1.166705]\n",
      "epoch:24 step:23362 [D loss: 0.568786, acc.: 71.09%] [G loss: 0.896265]\n",
      "epoch:24 step:23363 [D loss: 0.565510, acc.: 76.56%] [G loss: 0.980472]\n",
      "epoch:24 step:23364 [D loss: 0.721188, acc.: 53.12%] [G loss: 0.948315]\n",
      "epoch:24 step:23365 [D loss: 0.598918, acc.: 71.88%] [G loss: 1.489802]\n",
      "epoch:24 step:23366 [D loss: 0.502717, acc.: 78.12%] [G loss: 1.317146]\n",
      "epoch:24 step:23367 [D loss: 0.656886, acc.: 55.47%] [G loss: 0.985956]\n",
      "epoch:24 step:23368 [D loss: 0.687607, acc.: 57.81%] [G loss: 1.109265]\n",
      "epoch:24 step:23369 [D loss: 0.659038, acc.: 64.06%] [G loss: 0.728152]\n",
      "epoch:24 step:23370 [D loss: 0.577467, acc.: 71.09%] [G loss: 0.913560]\n",
      "epoch:24 step:23371 [D loss: 0.519807, acc.: 78.91%] [G loss: 1.147134]\n",
      "epoch:24 step:23372 [D loss: 0.454700, acc.: 79.69%] [G loss: 1.087246]\n",
      "epoch:24 step:23373 [D loss: 0.418937, acc.: 81.25%] [G loss: 1.274083]\n",
      "epoch:24 step:23374 [D loss: 0.468403, acc.: 78.91%] [G loss: 1.661205]\n",
      "epoch:24 step:23375 [D loss: 0.384069, acc.: 88.28%] [G loss: 1.376651]\n",
      "epoch:24 step:23376 [D loss: 0.761380, acc.: 52.34%] [G loss: 1.255471]\n",
      "epoch:24 step:23377 [D loss: 0.523829, acc.: 77.34%] [G loss: 1.096166]\n",
      "epoch:24 step:23378 [D loss: 0.568079, acc.: 72.66%] [G loss: 1.043987]\n",
      "epoch:24 step:23379 [D loss: 0.881900, acc.: 50.00%] [G loss: 1.540206]\n",
      "epoch:24 step:23380 [D loss: 0.536772, acc.: 75.78%] [G loss: 1.111844]\n",
      "epoch:24 step:23381 [D loss: 0.465792, acc.: 80.47%] [G loss: 1.168009]\n",
      "epoch:24 step:23382 [D loss: 0.513753, acc.: 78.91%] [G loss: 1.163189]\n",
      "epoch:24 step:23383 [D loss: 0.429597, acc.: 88.28%] [G loss: 1.400313]\n",
      "epoch:24 step:23384 [D loss: 0.497098, acc.: 78.91%] [G loss: 1.623157]\n",
      "epoch:24 step:23385 [D loss: 0.431940, acc.: 88.28%] [G loss: 1.437338]\n",
      "epoch:24 step:23386 [D loss: 0.270296, acc.: 97.66%] [G loss: 1.353251]\n",
      "epoch:24 step:23387 [D loss: 0.246047, acc.: 97.66%] [G loss: 1.804291]\n",
      "epoch:24 step:23388 [D loss: 0.205194, acc.: 98.44%] [G loss: 1.228679]\n",
      "epoch:24 step:23389 [D loss: 0.389454, acc.: 89.84%] [G loss: 1.593440]\n",
      "epoch:24 step:23390 [D loss: 0.537622, acc.: 69.53%] [G loss: 1.438024]\n",
      "epoch:24 step:23391 [D loss: 0.505031, acc.: 78.12%] [G loss: 1.260469]\n",
      "epoch:24 step:23392 [D loss: 0.632184, acc.: 61.72%] [G loss: 1.383035]\n",
      "epoch:24 step:23393 [D loss: 0.607815, acc.: 67.19%] [G loss: 1.102508]\n",
      "epoch:24 step:23394 [D loss: 0.755525, acc.: 47.66%] [G loss: 1.051527]\n",
      "epoch:24 step:23395 [D loss: 0.539869, acc.: 74.22%] [G loss: 1.142555]\n",
      "epoch:24 step:23396 [D loss: 0.707561, acc.: 54.69%] [G loss: 1.219547]\n",
      "epoch:24 step:23397 [D loss: 0.473730, acc.: 80.47%] [G loss: 1.107076]\n",
      "epoch:24 step:23398 [D loss: 0.599830, acc.: 70.31%] [G loss: 1.275867]\n",
      "epoch:24 step:23399 [D loss: 0.270584, acc.: 93.75%] [G loss: 1.260222]\n",
      "epoch:24 step:23400 [D loss: 0.130721, acc.: 100.00%] [G loss: 2.004385]\n",
      "##############\n",
      "[2.31444821 1.8465605  5.41787474 4.09691674 3.18086082 5.38686535\n",
      " 4.20270403 4.4894651  3.96930964 3.89682959]\n",
      "##########\n",
      "epoch:24 step:23401 [D loss: 0.957057, acc.: 45.31%] [G loss: 1.241003]\n",
      "epoch:24 step:23402 [D loss: 0.688560, acc.: 56.25%] [G loss: 1.094649]\n",
      "epoch:24 step:23403 [D loss: 0.658718, acc.: 61.72%] [G loss: 1.148753]\n",
      "epoch:24 step:23404 [D loss: 0.743226, acc.: 50.00%] [G loss: 0.790959]\n",
      "epoch:24 step:23405 [D loss: 1.004163, acc.: 31.25%] [G loss: 0.786938]\n",
      "epoch:24 step:23406 [D loss: 0.581518, acc.: 67.19%] [G loss: 1.068577]\n",
      "epoch:24 step:23407 [D loss: 0.309512, acc.: 89.84%] [G loss: 1.215799]\n",
      "epoch:24 step:23408 [D loss: 0.372307, acc.: 88.28%] [G loss: 1.644665]\n",
      "epoch:24 step:23409 [D loss: 0.451430, acc.: 86.72%] [G loss: 1.465724]\n",
      "epoch:24 step:23410 [D loss: 0.510601, acc.: 79.69%] [G loss: 1.260359]\n",
      "epoch:24 step:23411 [D loss: 0.484559, acc.: 82.03%] [G loss: 1.145923]\n",
      "epoch:24 step:23412 [D loss: 0.390105, acc.: 89.84%] [G loss: 1.284035]\n",
      "epoch:24 step:23413 [D loss: 0.409258, acc.: 83.59%] [G loss: 1.149301]\n",
      "epoch:24 step:23414 [D loss: 0.306167, acc.: 94.53%] [G loss: 1.438011]\n",
      "epoch:24 step:23415 [D loss: 0.169076, acc.: 100.00%] [G loss: 1.464046]\n",
      "epoch:24 step:23416 [D loss: 1.071015, acc.: 35.94%] [G loss: 1.125026]\n",
      "epoch:24 step:23417 [D loss: 0.532586, acc.: 72.66%] [G loss: 1.154629]\n",
      "epoch:24 step:23418 [D loss: 0.579081, acc.: 71.88%] [G loss: 1.282067]\n",
      "epoch:24 step:23419 [D loss: 0.623253, acc.: 63.28%] [G loss: 1.222468]\n",
      "epoch:24 step:23420 [D loss: 0.751627, acc.: 48.44%] [G loss: 1.114736]\n",
      "epoch:24 step:23421 [D loss: 0.671314, acc.: 58.59%] [G loss: 1.278359]\n",
      "epoch:24 step:23422 [D loss: 0.346239, acc.: 87.50%] [G loss: 1.225845]\n",
      "epoch:24 step:23423 [D loss: 0.575774, acc.: 72.66%] [G loss: 1.165043]\n",
      "epoch:24 step:23424 [D loss: 0.371886, acc.: 89.06%] [G loss: 1.506214]\n",
      "epoch:24 step:23425 [D loss: 0.166684, acc.: 97.66%] [G loss: 1.646320]\n",
      "epoch:25 step:23426 [D loss: 0.832988, acc.: 46.09%] [G loss: 1.213784]\n",
      "epoch:25 step:23427 [D loss: 0.947434, acc.: 44.53%] [G loss: 1.347372]\n",
      "epoch:25 step:23428 [D loss: 0.833582, acc.: 41.41%] [G loss: 1.251640]\n",
      "epoch:25 step:23429 [D loss: 0.607598, acc.: 64.84%] [G loss: 1.204233]\n",
      "epoch:25 step:23430 [D loss: 0.684947, acc.: 58.59%] [G loss: 1.144302]\n",
      "epoch:25 step:23431 [D loss: 0.445744, acc.: 88.28%] [G loss: 1.133870]\n",
      "epoch:25 step:23432 [D loss: 0.611791, acc.: 66.41%] [G loss: 1.124058]\n",
      "epoch:25 step:23433 [D loss: 0.699434, acc.: 55.47%] [G loss: 0.995196]\n",
      "epoch:25 step:23434 [D loss: 0.562665, acc.: 71.88%] [G loss: 1.423038]\n",
      "epoch:25 step:23435 [D loss: 0.580593, acc.: 67.19%] [G loss: 1.208498]\n",
      "epoch:25 step:23436 [D loss: 0.739589, acc.: 54.69%] [G loss: 1.049188]\n",
      "epoch:25 step:23437 [D loss: 0.751633, acc.: 50.78%] [G loss: 1.162862]\n",
      "epoch:25 step:23438 [D loss: 0.554569, acc.: 71.09%] [G loss: 1.212277]\n",
      "epoch:25 step:23439 [D loss: 0.758173, acc.: 50.00%] [G loss: 1.152813]\n",
      "epoch:25 step:23440 [D loss: 0.454046, acc.: 83.59%] [G loss: 0.940515]\n",
      "epoch:25 step:23441 [D loss: 0.471770, acc.: 82.81%] [G loss: 1.060313]\n",
      "epoch:25 step:23442 [D loss: 0.601296, acc.: 67.19%] [G loss: 1.289568]\n",
      "epoch:25 step:23443 [D loss: 0.668447, acc.: 60.94%] [G loss: 1.013252]\n",
      "epoch:25 step:23444 [D loss: 0.811082, acc.: 49.22%] [G loss: 1.040673]\n",
      "epoch:25 step:23445 [D loss: 0.446852, acc.: 82.03%] [G loss: 1.124674]\n",
      "epoch:25 step:23446 [D loss: 0.578960, acc.: 74.22%] [G loss: 1.047308]\n",
      "epoch:25 step:23447 [D loss: 0.550377, acc.: 71.88%] [G loss: 1.295472]\n",
      "epoch:25 step:23448 [D loss: 0.602814, acc.: 70.31%] [G loss: 1.130061]\n",
      "epoch:25 step:23449 [D loss: 0.656697, acc.: 60.16%] [G loss: 1.074865]\n",
      "epoch:25 step:23450 [D loss: 0.602916, acc.: 67.19%] [G loss: 1.148954]\n",
      "epoch:25 step:23451 [D loss: 0.344066, acc.: 89.84%] [G loss: 1.212048]\n",
      "epoch:25 step:23452 [D loss: 0.195976, acc.: 98.44%] [G loss: 1.366309]\n",
      "epoch:25 step:23453 [D loss: 0.317162, acc.: 91.41%] [G loss: 1.497587]\n",
      "epoch:25 step:23454 [D loss: 0.293254, acc.: 94.53%] [G loss: 1.588088]\n",
      "epoch:25 step:23455 [D loss: 0.307684, acc.: 95.31%] [G loss: 1.719184]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23456 [D loss: 0.257761, acc.: 96.09%] [G loss: 1.725618]\n",
      "epoch:25 step:23457 [D loss: 0.262309, acc.: 97.66%] [G loss: 1.342013]\n",
      "epoch:25 step:23458 [D loss: 0.321536, acc.: 89.06%] [G loss: 1.349203]\n",
      "epoch:25 step:23459 [D loss: 0.248804, acc.: 97.66%] [G loss: 1.858853]\n",
      "epoch:25 step:23460 [D loss: 0.327475, acc.: 88.28%] [G loss: 1.463299]\n",
      "epoch:25 step:23461 [D loss: 0.210217, acc.: 96.88%] [G loss: 1.815512]\n",
      "epoch:25 step:23462 [D loss: 0.870329, acc.: 52.34%] [G loss: 1.741810]\n",
      "epoch:25 step:23463 [D loss: 0.966161, acc.: 44.53%] [G loss: 1.460032]\n",
      "epoch:25 step:23464 [D loss: 0.837658, acc.: 40.62%] [G loss: 0.902854]\n",
      "epoch:25 step:23465 [D loss: 0.534502, acc.: 75.78%] [G loss: 1.144642]\n",
      "epoch:25 step:23466 [D loss: 0.832432, acc.: 38.28%] [G loss: 0.949908]\n",
      "epoch:25 step:23467 [D loss: 0.512828, acc.: 77.34%] [G loss: 0.922646]\n",
      "epoch:25 step:23468 [D loss: 0.579110, acc.: 75.00%] [G loss: 1.035271]\n",
      "epoch:25 step:23469 [D loss: 0.542282, acc.: 76.56%] [G loss: 1.262463]\n",
      "epoch:25 step:23470 [D loss: 0.825017, acc.: 51.56%] [G loss: 0.725997]\n",
      "epoch:25 step:23471 [D loss: 0.583442, acc.: 74.22%] [G loss: 1.326138]\n",
      "epoch:25 step:23472 [D loss: 0.688595, acc.: 53.12%] [G loss: 1.158373]\n",
      "epoch:25 step:23473 [D loss: 0.799467, acc.: 43.75%] [G loss: 0.948403]\n",
      "epoch:25 step:23474 [D loss: 0.468850, acc.: 88.28%] [G loss: 1.250390]\n",
      "epoch:25 step:23475 [D loss: 0.606043, acc.: 65.62%] [G loss: 1.041056]\n",
      "epoch:25 step:23476 [D loss: 0.566816, acc.: 72.66%] [G loss: 1.251963]\n",
      "epoch:25 step:23477 [D loss: 0.690780, acc.: 57.81%] [G loss: 0.806682]\n",
      "epoch:25 step:23478 [D loss: 0.630615, acc.: 70.31%] [G loss: 1.025599]\n",
      "epoch:25 step:23479 [D loss: 0.444981, acc.: 86.72%] [G loss: 1.036821]\n",
      "epoch:25 step:23480 [D loss: 0.488508, acc.: 78.91%] [G loss: 1.075658]\n",
      "epoch:25 step:23481 [D loss: 0.663306, acc.: 63.28%] [G loss: 1.084737]\n",
      "epoch:25 step:23482 [D loss: 0.725754, acc.: 49.22%] [G loss: 0.976048]\n",
      "epoch:25 step:23483 [D loss: 0.683966, acc.: 56.25%] [G loss: 1.085455]\n",
      "epoch:25 step:23484 [D loss: 0.798116, acc.: 48.44%] [G loss: 0.881591]\n",
      "epoch:25 step:23485 [D loss: 0.597885, acc.: 64.84%] [G loss: 0.907252]\n",
      "epoch:25 step:23486 [D loss: 0.835403, acc.: 35.94%] [G loss: 0.964613]\n",
      "epoch:25 step:23487 [D loss: 0.737284, acc.: 47.66%] [G loss: 0.873233]\n",
      "epoch:25 step:23488 [D loss: 0.560643, acc.: 74.22%] [G loss: 1.051418]\n",
      "epoch:25 step:23489 [D loss: 0.643504, acc.: 67.19%] [G loss: 0.945248]\n",
      "epoch:25 step:23490 [D loss: 0.559990, acc.: 74.22%] [G loss: 1.135177]\n",
      "epoch:25 step:23491 [D loss: 0.744492, acc.: 46.88%] [G loss: 0.934526]\n",
      "epoch:25 step:23492 [D loss: 0.738490, acc.: 51.56%] [G loss: 1.129169]\n",
      "epoch:25 step:23493 [D loss: 0.508602, acc.: 78.91%] [G loss: 1.042969]\n",
      "epoch:25 step:23494 [D loss: 0.390552, acc.: 87.50%] [G loss: 1.254570]\n",
      "epoch:25 step:23495 [D loss: 0.482100, acc.: 77.34%] [G loss: 1.595052]\n",
      "epoch:25 step:23496 [D loss: 0.624394, acc.: 67.19%] [G loss: 1.152088]\n",
      "epoch:25 step:23497 [D loss: 0.606293, acc.: 69.53%] [G loss: 1.343622]\n",
      "epoch:25 step:23498 [D loss: 0.618769, acc.: 66.41%] [G loss: 1.175861]\n",
      "epoch:25 step:23499 [D loss: 0.431007, acc.: 85.94%] [G loss: 1.339997]\n",
      "epoch:25 step:23500 [D loss: 0.292592, acc.: 90.62%] [G loss: 1.175861]\n",
      "epoch:25 step:23501 [D loss: 0.330384, acc.: 95.31%] [G loss: 1.404662]\n",
      "epoch:25 step:23502 [D loss: 0.367151, acc.: 87.50%] [G loss: 1.314281]\n",
      "epoch:25 step:23503 [D loss: 0.897008, acc.: 39.06%] [G loss: 1.410213]\n",
      "epoch:25 step:23504 [D loss: 0.631348, acc.: 62.50%] [G loss: 0.978517]\n",
      "epoch:25 step:23505 [D loss: 0.716633, acc.: 53.91%] [G loss: 1.235882]\n",
      "epoch:25 step:23506 [D loss: 0.559627, acc.: 74.22%] [G loss: 1.148652]\n",
      "epoch:25 step:23507 [D loss: 0.594795, acc.: 65.62%] [G loss: 1.175004]\n",
      "epoch:25 step:23508 [D loss: 0.470667, acc.: 80.47%] [G loss: 1.315151]\n",
      "epoch:25 step:23509 [D loss: 0.675400, acc.: 57.81%] [G loss: 1.014494]\n",
      "epoch:25 step:23510 [D loss: 0.762208, acc.: 53.12%] [G loss: 0.921509]\n",
      "epoch:25 step:23511 [D loss: 0.578642, acc.: 72.66%] [G loss: 1.194205]\n",
      "epoch:25 step:23512 [D loss: 0.578408, acc.: 72.66%] [G loss: 0.870525]\n",
      "epoch:25 step:23513 [D loss: 0.508600, acc.: 77.34%] [G loss: 1.114120]\n",
      "epoch:25 step:23514 [D loss: 0.652389, acc.: 60.16%] [G loss: 1.102799]\n",
      "epoch:25 step:23515 [D loss: 0.520990, acc.: 76.56%] [G loss: 1.090823]\n",
      "epoch:25 step:23516 [D loss: 0.627533, acc.: 67.97%] [G loss: 1.013751]\n",
      "epoch:25 step:23517 [D loss: 0.454227, acc.: 83.59%] [G loss: 0.925329]\n",
      "epoch:25 step:23518 [D loss: 0.633378, acc.: 67.19%] [G loss: 1.112526]\n",
      "epoch:25 step:23519 [D loss: 0.574376, acc.: 70.31%] [G loss: 0.817135]\n",
      "epoch:25 step:23520 [D loss: 0.857481, acc.: 40.62%] [G loss: 1.039117]\n",
      "epoch:25 step:23521 [D loss: 0.682333, acc.: 60.16%] [G loss: 1.049397]\n",
      "epoch:25 step:23522 [D loss: 0.928923, acc.: 29.69%] [G loss: 0.951032]\n",
      "epoch:25 step:23523 [D loss: 0.748487, acc.: 49.22%] [G loss: 1.112232]\n",
      "epoch:25 step:23524 [D loss: 0.803666, acc.: 44.53%] [G loss: 0.979039]\n",
      "epoch:25 step:23525 [D loss: 0.721232, acc.: 53.12%] [G loss: 1.064862]\n",
      "epoch:25 step:23526 [D loss: 0.677094, acc.: 58.59%] [G loss: 1.071854]\n",
      "epoch:25 step:23527 [D loss: 0.482295, acc.: 84.38%] [G loss: 1.330585]\n",
      "epoch:25 step:23528 [D loss: 0.425412, acc.: 86.72%] [G loss: 1.120054]\n",
      "epoch:25 step:23529 [D loss: 0.573828, acc.: 68.75%] [G loss: 1.145661]\n",
      "epoch:25 step:23530 [D loss: 0.476653, acc.: 74.22%] [G loss: 1.153942]\n",
      "epoch:25 step:23531 [D loss: 0.397647, acc.: 87.50%] [G loss: 1.601148]\n",
      "epoch:25 step:23532 [D loss: 0.619231, acc.: 67.97%] [G loss: 1.457336]\n",
      "epoch:25 step:23533 [D loss: 0.423994, acc.: 83.59%] [G loss: 1.324508]\n",
      "epoch:25 step:23534 [D loss: 0.376278, acc.: 89.84%] [G loss: 1.212312]\n",
      "epoch:25 step:23535 [D loss: 0.630879, acc.: 57.81%] [G loss: 1.034214]\n",
      "epoch:25 step:23536 [D loss: 0.618003, acc.: 64.06%] [G loss: 1.620316]\n",
      "epoch:25 step:23537 [D loss: 0.598459, acc.: 65.62%] [G loss: 1.089931]\n",
      "epoch:25 step:23538 [D loss: 0.886580, acc.: 39.84%] [G loss: 0.778485]\n",
      "epoch:25 step:23539 [D loss: 0.782775, acc.: 47.66%] [G loss: 0.941525]\n",
      "epoch:25 step:23540 [D loss: 0.694670, acc.: 56.25%] [G loss: 1.028219]\n",
      "epoch:25 step:23541 [D loss: 0.613682, acc.: 69.53%] [G loss: 1.021987]\n",
      "epoch:25 step:23542 [D loss: 0.273073, acc.: 96.09%] [G loss: 1.687945]\n",
      "epoch:25 step:23543 [D loss: 0.342414, acc.: 92.19%] [G loss: 1.911751]\n",
      "epoch:25 step:23544 [D loss: 0.457047, acc.: 76.56%] [G loss: 1.232145]\n",
      "epoch:25 step:23545 [D loss: 0.969259, acc.: 41.41%] [G loss: 1.309822]\n",
      "epoch:25 step:23546 [D loss: 0.592109, acc.: 67.97%] [G loss: 1.409054]\n",
      "epoch:25 step:23547 [D loss: 0.284186, acc.: 96.09%] [G loss: 1.576872]\n",
      "epoch:25 step:23548 [D loss: 0.728723, acc.: 60.94%] [G loss: 1.145062]\n",
      "epoch:25 step:23549 [D loss: 0.585345, acc.: 68.75%] [G loss: 1.251010]\n",
      "epoch:25 step:23550 [D loss: 0.644065, acc.: 61.72%] [G loss: 1.111453]\n",
      "epoch:25 step:23551 [D loss: 0.485239, acc.: 76.56%] [G loss: 1.071640]\n",
      "epoch:25 step:23552 [D loss: 0.655465, acc.: 62.50%] [G loss: 1.269072]\n",
      "epoch:25 step:23553 [D loss: 0.618857, acc.: 64.06%] [G loss: 1.089928]\n",
      "epoch:25 step:23554 [D loss: 0.531034, acc.: 78.12%] [G loss: 0.944534]\n",
      "epoch:25 step:23555 [D loss: 0.487934, acc.: 78.91%] [G loss: 1.133271]\n",
      "epoch:25 step:23556 [D loss: 0.324839, acc.: 93.75%] [G loss: 1.395013]\n",
      "epoch:25 step:23557 [D loss: 0.539057, acc.: 78.12%] [G loss: 1.270098]\n",
      "epoch:25 step:23558 [D loss: 0.843431, acc.: 39.06%] [G loss: 1.002418]\n",
      "epoch:25 step:23559 [D loss: 0.708426, acc.: 56.25%] [G loss: 1.159733]\n",
      "epoch:25 step:23560 [D loss: 0.696111, acc.: 57.81%] [G loss: 1.037478]\n",
      "epoch:25 step:23561 [D loss: 0.728033, acc.: 56.25%] [G loss: 1.039215]\n",
      "epoch:25 step:23562 [D loss: 0.692641, acc.: 59.38%] [G loss: 0.916151]\n",
      "epoch:25 step:23563 [D loss: 0.624979, acc.: 67.19%] [G loss: 1.017177]\n",
      "epoch:25 step:23564 [D loss: 0.440766, acc.: 83.59%] [G loss: 1.429282]\n",
      "epoch:25 step:23565 [D loss: 0.708512, acc.: 62.50%] [G loss: 1.205498]\n",
      "epoch:25 step:23566 [D loss: 0.506753, acc.: 78.12%] [G loss: 1.387539]\n",
      "epoch:25 step:23567 [D loss: 0.496299, acc.: 77.34%] [G loss: 0.995374]\n",
      "epoch:25 step:23568 [D loss: 0.468422, acc.: 80.47%] [G loss: 1.425167]\n",
      "epoch:25 step:23569 [D loss: 0.465328, acc.: 84.38%] [G loss: 1.164677]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23570 [D loss: 0.309615, acc.: 92.19%] [G loss: 1.713912]\n",
      "epoch:25 step:23571 [D loss: 0.833677, acc.: 40.62%] [G loss: 0.967102]\n",
      "epoch:25 step:23572 [D loss: 0.743830, acc.: 49.22%] [G loss: 1.004537]\n",
      "epoch:25 step:23573 [D loss: 0.793369, acc.: 40.62%] [G loss: 1.112830]\n",
      "epoch:25 step:23574 [D loss: 0.927741, acc.: 35.16%] [G loss: 0.978229]\n",
      "epoch:25 step:23575 [D loss: 0.615392, acc.: 67.97%] [G loss: 1.292642]\n",
      "epoch:25 step:23576 [D loss: 0.392000, acc.: 88.28%] [G loss: 1.797812]\n",
      "epoch:25 step:23577 [D loss: 0.471102, acc.: 82.81%] [G loss: 1.328098]\n",
      "epoch:25 step:23578 [D loss: 0.875194, acc.: 44.53%] [G loss: 1.054206]\n",
      "epoch:25 step:23579 [D loss: 0.638962, acc.: 63.28%] [G loss: 1.069200]\n",
      "epoch:25 step:23580 [D loss: 0.684725, acc.: 63.28%] [G loss: 1.060049]\n",
      "epoch:25 step:23581 [D loss: 0.561391, acc.: 75.00%] [G loss: 1.126876]\n",
      "epoch:25 step:23582 [D loss: 0.646521, acc.: 60.94%] [G loss: 1.300330]\n",
      "epoch:25 step:23583 [D loss: 0.402699, acc.: 89.84%] [G loss: 1.544814]\n",
      "epoch:25 step:23584 [D loss: 0.259884, acc.: 96.88%] [G loss: 1.662549]\n",
      "epoch:25 step:23585 [D loss: 0.674404, acc.: 62.50%] [G loss: 1.087064]\n",
      "epoch:25 step:23586 [D loss: 0.713657, acc.: 58.59%] [G loss: 1.142924]\n",
      "epoch:25 step:23587 [D loss: 0.615947, acc.: 66.41%] [G loss: 1.236433]\n",
      "epoch:25 step:23588 [D loss: 0.396325, acc.: 89.06%] [G loss: 1.355020]\n",
      "epoch:25 step:23589 [D loss: 0.448589, acc.: 82.03%] [G loss: 1.437291]\n",
      "epoch:25 step:23590 [D loss: 0.403608, acc.: 89.84%] [G loss: 1.449288]\n",
      "epoch:25 step:23591 [D loss: 0.384431, acc.: 90.62%] [G loss: 1.114938]\n",
      "epoch:25 step:23592 [D loss: 0.250924, acc.: 97.66%] [G loss: 1.269330]\n",
      "epoch:25 step:23593 [D loss: 0.395439, acc.: 86.72%] [G loss: 1.239320]\n",
      "epoch:25 step:23594 [D loss: 0.451425, acc.: 89.84%] [G loss: 1.358610]\n",
      "epoch:25 step:23595 [D loss: 0.740157, acc.: 53.91%] [G loss: 1.330845]\n",
      "epoch:25 step:23596 [D loss: 0.594946, acc.: 69.53%] [G loss: 1.071296]\n",
      "epoch:25 step:23597 [D loss: 0.537427, acc.: 75.78%] [G loss: 1.406061]\n",
      "epoch:25 step:23598 [D loss: 0.772422, acc.: 50.78%] [G loss: 0.823737]\n",
      "epoch:25 step:23599 [D loss: 0.919091, acc.: 40.62%] [G loss: 1.030290]\n",
      "epoch:25 step:23600 [D loss: 1.144702, acc.: 41.41%] [G loss: 0.479869]\n",
      "##############\n",
      "[2.30698433 1.42749144 5.65145982 4.12956304 2.98180949 5.58723785\n",
      " 4.06524232 4.49780933 4.03635748 3.70687305]\n",
      "##########\n",
      "epoch:25 step:23601 [D loss: 0.682090, acc.: 57.81%] [G loss: 0.965735]\n",
      "epoch:25 step:23602 [D loss: 1.214119, acc.: 13.28%] [G loss: 0.722174]\n",
      "epoch:25 step:23603 [D loss: 0.759131, acc.: 49.22%] [G loss: 1.298625]\n",
      "epoch:25 step:23604 [D loss: 0.750117, acc.: 57.81%] [G loss: 1.133782]\n",
      "epoch:25 step:23605 [D loss: 0.867024, acc.: 36.72%] [G loss: 0.970673]\n",
      "epoch:25 step:23606 [D loss: 0.737620, acc.: 50.00%] [G loss: 0.977643]\n",
      "epoch:25 step:23607 [D loss: 0.794713, acc.: 48.44%] [G loss: 0.858664]\n",
      "epoch:25 step:23608 [D loss: 0.850191, acc.: 41.41%] [G loss: 1.062613]\n",
      "epoch:25 step:23609 [D loss: 0.743455, acc.: 46.09%] [G loss: 1.084373]\n",
      "epoch:25 step:23610 [D loss: 1.185237, acc.: 17.19%] [G loss: 0.934076]\n",
      "epoch:25 step:23611 [D loss: 0.698396, acc.: 57.81%] [G loss: 1.201158]\n",
      "epoch:25 step:23612 [D loss: 1.032981, acc.: 23.44%] [G loss: 0.833663]\n",
      "epoch:25 step:23613 [D loss: 0.727280, acc.: 50.78%] [G loss: 0.791209]\n",
      "epoch:25 step:23614 [D loss: 0.752695, acc.: 50.78%] [G loss: 0.926170]\n",
      "epoch:25 step:23615 [D loss: 0.856711, acc.: 43.75%] [G loss: 0.976409]\n",
      "epoch:25 step:23616 [D loss: 0.900308, acc.: 39.06%] [G loss: 0.999507]\n",
      "epoch:25 step:23617 [D loss: 0.558006, acc.: 70.31%] [G loss: 1.270233]\n",
      "epoch:25 step:23618 [D loss: 0.553341, acc.: 73.44%] [G loss: 1.340610]\n",
      "epoch:25 step:23619 [D loss: 0.618042, acc.: 64.84%] [G loss: 1.143381]\n",
      "epoch:25 step:23620 [D loss: 0.760893, acc.: 49.22%] [G loss: 0.790396]\n",
      "epoch:25 step:23621 [D loss: 0.902059, acc.: 42.97%] [G loss: 0.938067]\n",
      "epoch:25 step:23622 [D loss: 0.587529, acc.: 65.62%] [G loss: 1.297585]\n",
      "epoch:25 step:23623 [D loss: 0.685904, acc.: 55.47%] [G loss: 0.938357]\n",
      "epoch:25 step:23624 [D loss: 0.763918, acc.: 42.97%] [G loss: 0.982657]\n",
      "epoch:25 step:23625 [D loss: 0.970275, acc.: 31.25%] [G loss: 0.987035]\n",
      "epoch:25 step:23626 [D loss: 0.766064, acc.: 42.19%] [G loss: 0.845840]\n",
      "epoch:25 step:23627 [D loss: 0.759729, acc.: 44.53%] [G loss: 1.253534]\n",
      "epoch:25 step:23628 [D loss: 0.540175, acc.: 76.56%] [G loss: 1.097998]\n",
      "epoch:25 step:23629 [D loss: 0.623567, acc.: 66.41%] [G loss: 0.978295]\n",
      "epoch:25 step:23630 [D loss: 0.695653, acc.: 58.59%] [G loss: 1.014047]\n",
      "epoch:25 step:23631 [D loss: 0.737192, acc.: 52.34%] [G loss: 1.122545]\n",
      "epoch:25 step:23632 [D loss: 0.589101, acc.: 69.53%] [G loss: 1.213818]\n",
      "epoch:25 step:23633 [D loss: 0.623711, acc.: 63.28%] [G loss: 1.331073]\n",
      "epoch:25 step:23634 [D loss: 0.679478, acc.: 59.38%] [G loss: 1.076602]\n",
      "epoch:25 step:23635 [D loss: 0.669026, acc.: 60.16%] [G loss: 0.975514]\n",
      "epoch:25 step:23636 [D loss: 0.509780, acc.: 76.56%] [G loss: 1.495055]\n",
      "epoch:25 step:23637 [D loss: 0.610816, acc.: 64.84%] [G loss: 1.164213]\n",
      "epoch:25 step:23638 [D loss: 0.496306, acc.: 78.91%] [G loss: 1.333153]\n",
      "epoch:25 step:23639 [D loss: 0.696362, acc.: 63.28%] [G loss: 1.295025]\n",
      "epoch:25 step:23640 [D loss: 0.527293, acc.: 73.44%] [G loss: 1.247863]\n",
      "epoch:25 step:23641 [D loss: 0.644394, acc.: 65.62%] [G loss: 1.270881]\n",
      "epoch:25 step:23642 [D loss: 0.701613, acc.: 57.03%] [G loss: 1.213408]\n",
      "epoch:25 step:23643 [D loss: 0.777113, acc.: 49.22%] [G loss: 0.839083]\n",
      "epoch:25 step:23644 [D loss: 0.746054, acc.: 54.69%] [G loss: 0.877420]\n",
      "epoch:25 step:23645 [D loss: 0.323405, acc.: 89.06%] [G loss: 1.361966]\n",
      "epoch:25 step:23646 [D loss: 0.268364, acc.: 94.53%] [G loss: 1.526437]\n",
      "epoch:25 step:23647 [D loss: 0.316411, acc.: 89.84%] [G loss: 2.045315]\n",
      "epoch:25 step:23648 [D loss: 0.318784, acc.: 92.19%] [G loss: 1.560889]\n",
      "epoch:25 step:23649 [D loss: 0.786725, acc.: 53.91%] [G loss: 1.532141]\n",
      "epoch:25 step:23650 [D loss: 0.665237, acc.: 55.47%] [G loss: 1.017947]\n",
      "epoch:25 step:23651 [D loss: 0.577566, acc.: 67.19%] [G loss: 1.114738]\n",
      "epoch:25 step:23652 [D loss: 0.659740, acc.: 62.50%] [G loss: 1.083494]\n",
      "epoch:25 step:23653 [D loss: 0.542643, acc.: 76.56%] [G loss: 1.299773]\n",
      "epoch:25 step:23654 [D loss: 0.501766, acc.: 77.34%] [G loss: 1.469164]\n",
      "epoch:25 step:23655 [D loss: 0.266004, acc.: 88.28%] [G loss: 1.517703]\n",
      "epoch:25 step:23656 [D loss: 0.308531, acc.: 90.62%] [G loss: 1.434540]\n",
      "epoch:25 step:23657 [D loss: 0.303634, acc.: 92.19%] [G loss: 1.911759]\n",
      "epoch:25 step:23658 [D loss: 1.054446, acc.: 35.94%] [G loss: 1.389978]\n",
      "epoch:25 step:23659 [D loss: 0.626602, acc.: 65.62%] [G loss: 1.385950]\n",
      "epoch:25 step:23660 [D loss: 0.428431, acc.: 82.03%] [G loss: 1.031951]\n",
      "epoch:25 step:23661 [D loss: 0.534948, acc.: 70.31%] [G loss: 1.121169]\n",
      "epoch:25 step:23662 [D loss: 0.594362, acc.: 68.75%] [G loss: 0.834362]\n",
      "epoch:25 step:23663 [D loss: 0.519030, acc.: 71.09%] [G loss: 1.113490]\n",
      "epoch:25 step:23664 [D loss: 0.814194, acc.: 45.31%] [G loss: 1.155740]\n",
      "epoch:25 step:23665 [D loss: 0.845786, acc.: 42.19%] [G loss: 0.883454]\n",
      "epoch:25 step:23666 [D loss: 1.078497, acc.: 24.22%] [G loss: 0.892731]\n",
      "epoch:25 step:23667 [D loss: 0.669096, acc.: 53.12%] [G loss: 1.092514]\n",
      "epoch:25 step:23668 [D loss: 0.782093, acc.: 56.25%] [G loss: 1.081466]\n",
      "epoch:25 step:23669 [D loss: 0.747349, acc.: 55.47%] [G loss: 1.321424]\n",
      "epoch:25 step:23670 [D loss: 0.771687, acc.: 46.88%] [G loss: 0.756331]\n",
      "epoch:25 step:23671 [D loss: 0.584124, acc.: 71.09%] [G loss: 1.357250]\n",
      "epoch:25 step:23672 [D loss: 0.655028, acc.: 63.28%] [G loss: 1.165002]\n",
      "epoch:25 step:23673 [D loss: 0.468595, acc.: 84.38%] [G loss: 1.520665]\n",
      "epoch:25 step:23674 [D loss: 0.662688, acc.: 62.50%] [G loss: 1.237597]\n",
      "epoch:25 step:23675 [D loss: 0.524156, acc.: 71.09%] [G loss: 0.970396]\n",
      "epoch:25 step:23676 [D loss: 0.478135, acc.: 80.47%] [G loss: 1.168093]\n",
      "epoch:25 step:23677 [D loss: 0.622971, acc.: 70.31%] [G loss: 0.961715]\n",
      "epoch:25 step:23678 [D loss: 0.514100, acc.: 75.78%] [G loss: 1.025662]\n",
      "epoch:25 step:23679 [D loss: 0.485845, acc.: 82.03%] [G loss: 1.026539]\n",
      "epoch:25 step:23680 [D loss: 0.692719, acc.: 57.81%] [G loss: 0.961549]\n",
      "epoch:25 step:23681 [D loss: 0.615722, acc.: 69.53%] [G loss: 1.117909]\n",
      "epoch:25 step:23682 [D loss: 0.676274, acc.: 64.06%] [G loss: 1.077437]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23683 [D loss: 0.663808, acc.: 62.50%] [G loss: 1.120394]\n",
      "epoch:25 step:23684 [D loss: 0.550181, acc.: 71.09%] [G loss: 0.955915]\n",
      "epoch:25 step:23685 [D loss: 0.595367, acc.: 67.19%] [G loss: 1.170694]\n",
      "epoch:25 step:23686 [D loss: 0.547147, acc.: 69.53%] [G loss: 1.129322]\n",
      "epoch:25 step:23687 [D loss: 0.580947, acc.: 70.31%] [G loss: 1.220277]\n",
      "epoch:25 step:23688 [D loss: 0.403541, acc.: 88.28%] [G loss: 1.284639]\n",
      "epoch:25 step:23689 [D loss: 0.392139, acc.: 88.28%] [G loss: 1.115231]\n",
      "epoch:25 step:23690 [D loss: 0.699804, acc.: 55.47%] [G loss: 1.085683]\n",
      "epoch:25 step:23691 [D loss: 0.693362, acc.: 53.12%] [G loss: 1.011304]\n",
      "epoch:25 step:23692 [D loss: 0.513503, acc.: 74.22%] [G loss: 1.289415]\n",
      "epoch:25 step:23693 [D loss: 0.642249, acc.: 62.50%] [G loss: 1.223230]\n",
      "epoch:25 step:23694 [D loss: 0.628965, acc.: 64.06%] [G loss: 1.027726]\n",
      "epoch:25 step:23695 [D loss: 0.594597, acc.: 67.19%] [G loss: 0.981906]\n",
      "epoch:25 step:23696 [D loss: 0.555845, acc.: 76.56%] [G loss: 0.917080]\n",
      "epoch:25 step:23697 [D loss: 0.413926, acc.: 89.06%] [G loss: 1.249428]\n",
      "epoch:25 step:23698 [D loss: 0.480821, acc.: 81.25%] [G loss: 0.850866]\n",
      "epoch:25 step:23699 [D loss: 0.848872, acc.: 39.84%] [G loss: 0.856519]\n",
      "epoch:25 step:23700 [D loss: 0.694118, acc.: 54.69%] [G loss: 1.104678]\n",
      "epoch:25 step:23701 [D loss: 0.644551, acc.: 65.62%] [G loss: 1.432637]\n",
      "epoch:25 step:23702 [D loss: 0.858046, acc.: 43.75%] [G loss: 1.043842]\n",
      "epoch:25 step:23703 [D loss: 0.386117, acc.: 89.06%] [G loss: 1.363455]\n",
      "epoch:25 step:23704 [D loss: 0.280470, acc.: 94.53%] [G loss: 1.592189]\n",
      "epoch:25 step:23705 [D loss: 0.358095, acc.: 89.84%] [G loss: 1.494490]\n",
      "epoch:25 step:23706 [D loss: 0.766510, acc.: 49.22%] [G loss: 1.135744]\n",
      "epoch:25 step:23707 [D loss: 0.596434, acc.: 71.09%] [G loss: 0.937967]\n",
      "epoch:25 step:23708 [D loss: 0.754603, acc.: 48.44%] [G loss: 0.873465]\n",
      "epoch:25 step:23709 [D loss: 0.447685, acc.: 78.91%] [G loss: 1.114575]\n",
      "epoch:25 step:23710 [D loss: 0.412993, acc.: 85.94%] [G loss: 1.137867]\n",
      "epoch:25 step:23711 [D loss: 0.268060, acc.: 96.88%] [G loss: 1.654555]\n",
      "epoch:25 step:23712 [D loss: 0.548131, acc.: 71.88%] [G loss: 1.385432]\n",
      "epoch:25 step:23713 [D loss: 0.608875, acc.: 67.19%] [G loss: 1.260768]\n",
      "epoch:25 step:23714 [D loss: 0.389741, acc.: 84.38%] [G loss: 1.328169]\n",
      "epoch:25 step:23715 [D loss: 0.468381, acc.: 82.03%] [G loss: 1.215080]\n",
      "epoch:25 step:23716 [D loss: 0.461887, acc.: 74.22%] [G loss: 1.128723]\n",
      "epoch:25 step:23717 [D loss: 0.366888, acc.: 89.84%] [G loss: 1.604397]\n",
      "epoch:25 step:23718 [D loss: 0.366383, acc.: 85.94%] [G loss: 1.424994]\n",
      "epoch:25 step:23719 [D loss: 0.790349, acc.: 49.22%] [G loss: 0.907942]\n",
      "epoch:25 step:23720 [D loss: 0.916277, acc.: 47.66%] [G loss: 1.138202]\n",
      "epoch:25 step:23721 [D loss: 0.548657, acc.: 73.44%] [G loss: 1.208421]\n",
      "epoch:25 step:23722 [D loss: 0.801841, acc.: 48.44%] [G loss: 0.976586]\n",
      "epoch:25 step:23723 [D loss: 0.550761, acc.: 72.66%] [G loss: 1.008860]\n",
      "epoch:25 step:23724 [D loss: 0.685090, acc.: 60.16%] [G loss: 1.140061]\n",
      "epoch:25 step:23725 [D loss: 0.706473, acc.: 57.03%] [G loss: 1.070187]\n",
      "epoch:25 step:23726 [D loss: 0.677206, acc.: 58.59%] [G loss: 1.029044]\n",
      "epoch:25 step:23727 [D loss: 0.619750, acc.: 69.53%] [G loss: 0.917336]\n",
      "epoch:25 step:23728 [D loss: 0.689921, acc.: 58.59%] [G loss: 0.966331]\n",
      "epoch:25 step:23729 [D loss: 0.625577, acc.: 67.97%] [G loss: 0.935895]\n",
      "epoch:25 step:23730 [D loss: 0.478388, acc.: 85.16%] [G loss: 1.089285]\n",
      "epoch:25 step:23731 [D loss: 0.760242, acc.: 53.12%] [G loss: 0.985271]\n",
      "epoch:25 step:23732 [D loss: 0.627537, acc.: 67.97%] [G loss: 1.017644]\n",
      "epoch:25 step:23733 [D loss: 0.424545, acc.: 85.94%] [G loss: 1.137020]\n",
      "epoch:25 step:23734 [D loss: 0.448168, acc.: 84.38%] [G loss: 1.095844]\n",
      "epoch:25 step:23735 [D loss: 0.679532, acc.: 56.25%] [G loss: 1.277895]\n",
      "epoch:25 step:23736 [D loss: 0.536242, acc.: 71.88%] [G loss: 0.859218]\n",
      "epoch:25 step:23737 [D loss: 0.344604, acc.: 87.50%] [G loss: 1.200474]\n",
      "epoch:25 step:23738 [D loss: 0.529608, acc.: 69.53%] [G loss: 1.246105]\n",
      "epoch:25 step:23739 [D loss: 0.527750, acc.: 78.12%] [G loss: 1.431166]\n",
      "epoch:25 step:23740 [D loss: 0.492549, acc.: 78.91%] [G loss: 1.164340]\n",
      "epoch:25 step:23741 [D loss: 1.054309, acc.: 39.84%] [G loss: 1.005033]\n",
      "epoch:25 step:23742 [D loss: 0.710138, acc.: 57.03%] [G loss: 1.306702]\n",
      "epoch:25 step:23743 [D loss: 0.850330, acc.: 43.75%] [G loss: 1.198197]\n",
      "epoch:25 step:23744 [D loss: 0.616092, acc.: 66.41%] [G loss: 1.267277]\n",
      "epoch:25 step:23745 [D loss: 0.446096, acc.: 84.38%] [G loss: 1.200481]\n",
      "epoch:25 step:23746 [D loss: 0.311503, acc.: 95.31%] [G loss: 1.602309]\n",
      "epoch:25 step:23747 [D loss: 0.389890, acc.: 88.28%] [G loss: 1.623136]\n",
      "epoch:25 step:23748 [D loss: 0.698929, acc.: 57.03%] [G loss: 1.056436]\n",
      "epoch:25 step:23749 [D loss: 0.486404, acc.: 80.47%] [G loss: 1.098611]\n",
      "epoch:25 step:23750 [D loss: 0.360096, acc.: 89.06%] [G loss: 1.394042]\n",
      "epoch:25 step:23751 [D loss: 0.484591, acc.: 78.12%] [G loss: 1.205771]\n",
      "epoch:25 step:23752 [D loss: 0.231903, acc.: 96.09%] [G loss: 1.543021]\n",
      "epoch:25 step:23753 [D loss: 0.317317, acc.: 89.06%] [G loss: 1.242593]\n",
      "epoch:25 step:23754 [D loss: 0.464709, acc.: 81.25%] [G loss: 1.394208]\n",
      "epoch:25 step:23755 [D loss: 0.796359, acc.: 42.97%] [G loss: 0.814081]\n",
      "epoch:25 step:23756 [D loss: 0.756531, acc.: 54.69%] [G loss: 1.388230]\n",
      "epoch:25 step:23757 [D loss: 0.570387, acc.: 75.78%] [G loss: 1.250302]\n",
      "epoch:25 step:23758 [D loss: 0.583495, acc.: 74.22%] [G loss: 0.962998]\n",
      "epoch:25 step:23759 [D loss: 0.740986, acc.: 50.00%] [G loss: 0.814731]\n",
      "epoch:25 step:23760 [D loss: 0.741963, acc.: 50.00%] [G loss: 0.989095]\n",
      "epoch:25 step:23761 [D loss: 0.588767, acc.: 70.31%] [G loss: 1.329640]\n",
      "epoch:25 step:23762 [D loss: 0.552575, acc.: 67.97%] [G loss: 1.073472]\n",
      "epoch:25 step:23763 [D loss: 0.542193, acc.: 73.44%] [G loss: 1.185480]\n",
      "epoch:25 step:23764 [D loss: 0.543586, acc.: 73.44%] [G loss: 1.239325]\n",
      "epoch:25 step:23765 [D loss: 0.519549, acc.: 76.56%] [G loss: 1.408081]\n",
      "epoch:25 step:23766 [D loss: 0.996243, acc.: 23.44%] [G loss: 0.955229]\n",
      "epoch:25 step:23767 [D loss: 0.769192, acc.: 52.34%] [G loss: 1.025824]\n",
      "epoch:25 step:23768 [D loss: 0.659086, acc.: 60.16%] [G loss: 1.019761]\n",
      "epoch:25 step:23769 [D loss: 0.610536, acc.: 68.75%] [G loss: 1.076280]\n",
      "epoch:25 step:23770 [D loss: 0.440612, acc.: 83.59%] [G loss: 1.113046]\n",
      "epoch:25 step:23771 [D loss: 0.327828, acc.: 92.97%] [G loss: 1.319876]\n",
      "epoch:25 step:23772 [D loss: 0.295151, acc.: 93.75%] [G loss: 1.509336]\n",
      "epoch:25 step:23773 [D loss: 0.693191, acc.: 58.59%] [G loss: 1.218724]\n",
      "epoch:25 step:23774 [D loss: 0.699107, acc.: 53.91%] [G loss: 1.204282]\n",
      "epoch:25 step:23775 [D loss: 0.802135, acc.: 37.50%] [G loss: 1.018529]\n",
      "epoch:25 step:23776 [D loss: 0.509112, acc.: 77.34%] [G loss: 1.054294]\n",
      "epoch:25 step:23777 [D loss: 0.482334, acc.: 79.69%] [G loss: 1.340997]\n",
      "epoch:25 step:23778 [D loss: 0.558365, acc.: 74.22%] [G loss: 1.169895]\n",
      "epoch:25 step:23779 [D loss: 0.601746, acc.: 67.97%] [G loss: 0.979983]\n",
      "epoch:25 step:23780 [D loss: 0.715995, acc.: 51.56%] [G loss: 1.100727]\n",
      "epoch:25 step:23781 [D loss: 0.698683, acc.: 56.25%] [G loss: 1.469296]\n",
      "epoch:25 step:23782 [D loss: 0.568568, acc.: 69.53%] [G loss: 1.124161]\n",
      "epoch:25 step:23783 [D loss: 0.552401, acc.: 71.88%] [G loss: 1.165088]\n",
      "epoch:25 step:23784 [D loss: 0.509622, acc.: 81.25%] [G loss: 1.212646]\n",
      "epoch:25 step:23785 [D loss: 0.530038, acc.: 74.22%] [G loss: 0.869652]\n",
      "epoch:25 step:23786 [D loss: 0.710709, acc.: 56.25%] [G loss: 0.930807]\n",
      "epoch:25 step:23787 [D loss: 1.127732, acc.: 19.53%] [G loss: 0.668319]\n",
      "epoch:25 step:23788 [D loss: 0.428221, acc.: 82.81%] [G loss: 1.584254]\n",
      "epoch:25 step:23789 [D loss: 0.603045, acc.: 64.84%] [G loss: 1.283397]\n",
      "epoch:25 step:23790 [D loss: 0.342317, acc.: 93.75%] [G loss: 1.368897]\n",
      "epoch:25 step:23791 [D loss: 0.231499, acc.: 95.31%] [G loss: 1.427815]\n",
      "epoch:25 step:23792 [D loss: 0.369516, acc.: 86.72%] [G loss: 1.327437]\n",
      "epoch:25 step:23793 [D loss: 0.601807, acc.: 61.72%] [G loss: 1.417923]\n",
      "epoch:25 step:23794 [D loss: 0.755464, acc.: 53.12%] [G loss: 1.144514]\n",
      "epoch:25 step:23795 [D loss: 0.595082, acc.: 71.09%] [G loss: 1.023751]\n",
      "epoch:25 step:23796 [D loss: 0.597406, acc.: 71.09%] [G loss: 1.238046]\n",
      "epoch:25 step:23797 [D loss: 0.798697, acc.: 50.78%] [G loss: 1.081891]\n",
      "epoch:25 step:23798 [D loss: 0.769966, acc.: 46.88%] [G loss: 0.824854]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23799 [D loss: 0.464771, acc.: 82.81%] [G loss: 1.044988]\n",
      "epoch:25 step:23800 [D loss: 0.590010, acc.: 71.88%] [G loss: 1.110654]\n",
      "##############\n",
      "[2.43642531 1.62522595 5.59677859 4.44750367 3.08498779 5.60974982\n",
      " 4.23385031 4.71347001 4.09606966 3.54925968]\n",
      "##########\n",
      "epoch:25 step:23801 [D loss: 0.673073, acc.: 63.28%] [G loss: 1.185937]\n",
      "epoch:25 step:23802 [D loss: 0.356216, acc.: 90.62%] [G loss: 1.155293]\n",
      "epoch:25 step:23803 [D loss: 0.317025, acc.: 92.19%] [G loss: 1.258557]\n",
      "epoch:25 step:23804 [D loss: 0.709228, acc.: 60.16%] [G loss: 1.161565]\n",
      "epoch:25 step:23805 [D loss: 0.686072, acc.: 53.91%] [G loss: 1.033406]\n",
      "epoch:25 step:23806 [D loss: 0.511306, acc.: 78.91%] [G loss: 1.269452]\n",
      "epoch:25 step:23807 [D loss: 0.748091, acc.: 46.09%] [G loss: 1.320783]\n",
      "epoch:25 step:23808 [D loss: 0.647663, acc.: 62.50%] [G loss: 1.055123]\n",
      "epoch:25 step:23809 [D loss: 0.577726, acc.: 73.44%] [G loss: 1.025913]\n",
      "epoch:25 step:23810 [D loss: 0.633773, acc.: 62.50%] [G loss: 0.881429]\n",
      "epoch:25 step:23811 [D loss: 0.658839, acc.: 60.16%] [G loss: 0.945126]\n",
      "epoch:25 step:23812 [D loss: 0.646171, acc.: 65.62%] [G loss: 0.792338]\n",
      "epoch:25 step:23813 [D loss: 0.585046, acc.: 68.75%] [G loss: 1.043019]\n",
      "epoch:25 step:23814 [D loss: 0.694181, acc.: 57.03%] [G loss: 1.143648]\n",
      "epoch:25 step:23815 [D loss: 0.477603, acc.: 77.34%] [G loss: 1.015200]\n",
      "epoch:25 step:23816 [D loss: 0.504604, acc.: 78.12%] [G loss: 1.019418]\n",
      "epoch:25 step:23817 [D loss: 0.510621, acc.: 79.69%] [G loss: 1.166333]\n",
      "epoch:25 step:23818 [D loss: 0.564909, acc.: 68.75%] [G loss: 0.971672]\n",
      "epoch:25 step:23819 [D loss: 0.402250, acc.: 81.25%] [G loss: 1.205132]\n",
      "epoch:25 step:23820 [D loss: 0.615792, acc.: 66.41%] [G loss: 1.284253]\n",
      "epoch:25 step:23821 [D loss: 0.288692, acc.: 93.75%] [G loss: 1.483281]\n",
      "epoch:25 step:23822 [D loss: 0.249627, acc.: 89.84%] [G loss: 1.566350]\n",
      "epoch:25 step:23823 [D loss: 0.231877, acc.: 96.88%] [G loss: 1.854532]\n",
      "epoch:25 step:23824 [D loss: 0.307328, acc.: 92.19%] [G loss: 1.548882]\n",
      "epoch:25 step:23825 [D loss: 0.295999, acc.: 92.97%] [G loss: 1.942216]\n",
      "epoch:25 step:23826 [D loss: 0.459027, acc.: 82.03%] [G loss: 1.114844]\n",
      "epoch:25 step:23827 [D loss: 0.309787, acc.: 92.19%] [G loss: 1.911643]\n",
      "epoch:25 step:23828 [D loss: 0.699860, acc.: 57.03%] [G loss: 1.300953]\n",
      "epoch:25 step:23829 [D loss: 0.424943, acc.: 75.78%] [G loss: 1.232868]\n",
      "epoch:25 step:23830 [D loss: 0.529701, acc.: 71.88%] [G loss: 1.189117]\n",
      "epoch:25 step:23831 [D loss: 0.386324, acc.: 89.06%] [G loss: 1.810203]\n",
      "epoch:25 step:23832 [D loss: 0.842189, acc.: 50.78%] [G loss: 1.056709]\n",
      "epoch:25 step:23833 [D loss: 0.937611, acc.: 41.41%] [G loss: 0.927918]\n",
      "epoch:25 step:23834 [D loss: 0.563293, acc.: 67.19%] [G loss: 1.043003]\n",
      "epoch:25 step:23835 [D loss: 1.004731, acc.: 32.03%] [G loss: 0.808872]\n",
      "epoch:25 step:23836 [D loss: 1.299760, acc.: 18.75%] [G loss: 0.644222]\n",
      "epoch:25 step:23837 [D loss: 0.856279, acc.: 40.62%] [G loss: 0.955519]\n",
      "epoch:25 step:23838 [D loss: 0.872857, acc.: 36.72%] [G loss: 0.771154]\n",
      "epoch:25 step:23839 [D loss: 0.655720, acc.: 57.81%] [G loss: 1.334770]\n",
      "epoch:25 step:23840 [D loss: 0.819168, acc.: 45.31%] [G loss: 1.302245]\n",
      "epoch:25 step:23841 [D loss: 0.598571, acc.: 67.19%] [G loss: 0.855973]\n",
      "epoch:25 step:23842 [D loss: 1.002078, acc.: 33.59%] [G loss: 1.114075]\n",
      "epoch:25 step:23843 [D loss: 0.752345, acc.: 49.22%] [G loss: 1.103942]\n",
      "epoch:25 step:23844 [D loss: 0.594215, acc.: 69.53%] [G loss: 0.882988]\n",
      "epoch:25 step:23845 [D loss: 0.675399, acc.: 62.50%] [G loss: 1.192582]\n",
      "epoch:25 step:23846 [D loss: 0.653298, acc.: 60.94%] [G loss: 1.408793]\n",
      "epoch:25 step:23847 [D loss: 0.555639, acc.: 70.31%] [G loss: 1.515179]\n",
      "epoch:25 step:23848 [D loss: 0.633367, acc.: 64.84%] [G loss: 1.597867]\n",
      "epoch:25 step:23849 [D loss: 0.909945, acc.: 35.16%] [G loss: 1.027173]\n",
      "epoch:25 step:23850 [D loss: 0.618887, acc.: 68.75%] [G loss: 1.203021]\n",
      "epoch:25 step:23851 [D loss: 0.690668, acc.: 60.16%] [G loss: 1.129955]\n",
      "epoch:25 step:23852 [D loss: 0.682198, acc.: 61.72%] [G loss: 1.086955]\n",
      "epoch:25 step:23853 [D loss: 0.694309, acc.: 59.38%] [G loss: 1.058223]\n",
      "epoch:25 step:23854 [D loss: 0.698458, acc.: 58.59%] [G loss: 1.013441]\n",
      "epoch:25 step:23855 [D loss: 0.726660, acc.: 55.47%] [G loss: 1.351576]\n",
      "epoch:25 step:23856 [D loss: 0.651879, acc.: 63.28%] [G loss: 1.346551]\n",
      "epoch:25 step:23857 [D loss: 0.502798, acc.: 74.22%] [G loss: 1.348277]\n",
      "epoch:25 step:23858 [D loss: 0.452289, acc.: 80.47%] [G loss: 1.287357]\n",
      "epoch:25 step:23859 [D loss: 0.556442, acc.: 72.66%] [G loss: 1.048264]\n",
      "epoch:25 step:23860 [D loss: 0.417197, acc.: 84.38%] [G loss: 1.314694]\n",
      "epoch:25 step:23861 [D loss: 0.398657, acc.: 85.94%] [G loss: 1.686119]\n",
      "epoch:25 step:23862 [D loss: 0.728792, acc.: 57.03%] [G loss: 1.163331]\n",
      "epoch:25 step:23863 [D loss: 0.808303, acc.: 50.00%] [G loss: 1.051378]\n",
      "epoch:25 step:23864 [D loss: 0.764933, acc.: 50.00%] [G loss: 1.011483]\n",
      "epoch:25 step:23865 [D loss: 0.818173, acc.: 56.25%] [G loss: 1.194081]\n",
      "epoch:25 step:23866 [D loss: 0.705353, acc.: 56.25%] [G loss: 1.303975]\n",
      "epoch:25 step:23867 [D loss: 0.852909, acc.: 40.62%] [G loss: 1.194434]\n",
      "epoch:25 step:23868 [D loss: 0.470445, acc.: 80.47%] [G loss: 1.335032]\n",
      "epoch:25 step:23869 [D loss: 0.825122, acc.: 42.97%] [G loss: 1.072010]\n",
      "epoch:25 step:23870 [D loss: 0.693599, acc.: 57.03%] [G loss: 0.911776]\n",
      "epoch:25 step:23871 [D loss: 0.897718, acc.: 34.38%] [G loss: 1.227160]\n",
      "epoch:25 step:23872 [D loss: 0.696024, acc.: 58.59%] [G loss: 0.887705]\n",
      "epoch:25 step:23873 [D loss: 0.604803, acc.: 70.31%] [G loss: 1.169253]\n",
      "epoch:25 step:23874 [D loss: 0.546978, acc.: 72.66%] [G loss: 1.353005]\n",
      "epoch:25 step:23875 [D loss: 0.612204, acc.: 66.41%] [G loss: 0.877611]\n",
      "epoch:25 step:23876 [D loss: 0.655737, acc.: 59.38%] [G loss: 1.372010]\n",
      "epoch:25 step:23877 [D loss: 0.483391, acc.: 82.03%] [G loss: 1.290454]\n",
      "epoch:25 step:23878 [D loss: 0.575783, acc.: 71.09%] [G loss: 1.060755]\n",
      "epoch:25 step:23879 [D loss: 0.581934, acc.: 69.53%] [G loss: 0.960479]\n",
      "epoch:25 step:23880 [D loss: 0.761524, acc.: 50.78%] [G loss: 1.287320]\n",
      "epoch:25 step:23881 [D loss: 0.563213, acc.: 68.75%] [G loss: 1.294106]\n",
      "epoch:25 step:23882 [D loss: 0.499050, acc.: 78.12%] [G loss: 1.427060]\n",
      "epoch:25 step:23883 [D loss: 1.211285, acc.: 21.88%] [G loss: 0.796132]\n",
      "epoch:25 step:23884 [D loss: 0.781772, acc.: 42.97%] [G loss: 0.910858]\n",
      "epoch:25 step:23885 [D loss: 0.897466, acc.: 35.16%] [G loss: 0.946462]\n",
      "epoch:25 step:23886 [D loss: 0.859704, acc.: 46.09%] [G loss: 1.172416]\n",
      "epoch:25 step:23887 [D loss: 0.560801, acc.: 71.09%] [G loss: 1.710568]\n",
      "epoch:25 step:23888 [D loss: 0.570263, acc.: 67.97%] [G loss: 1.213080]\n",
      "epoch:25 step:23889 [D loss: 0.680200, acc.: 57.03%] [G loss: 1.456524]\n",
      "epoch:25 step:23890 [D loss: 0.751835, acc.: 46.09%] [G loss: 0.921026]\n",
      "epoch:25 step:23891 [D loss: 0.573079, acc.: 73.44%] [G loss: 1.337519]\n",
      "epoch:25 step:23892 [D loss: 0.753690, acc.: 49.22%] [G loss: 1.178524]\n",
      "epoch:25 step:23893 [D loss: 0.683813, acc.: 57.81%] [G loss: 1.151364]\n",
      "epoch:25 step:23894 [D loss: 0.573204, acc.: 69.53%] [G loss: 1.315903]\n",
      "epoch:25 step:23895 [D loss: 0.455987, acc.: 82.03%] [G loss: 1.476523]\n",
      "epoch:25 step:23896 [D loss: 0.323049, acc.: 89.84%] [G loss: 1.286504]\n",
      "epoch:25 step:23897 [D loss: 0.476447, acc.: 81.25%] [G loss: 1.597034]\n",
      "epoch:25 step:23898 [D loss: 0.514811, acc.: 77.34%] [G loss: 1.522410]\n",
      "epoch:25 step:23899 [D loss: 0.455844, acc.: 81.25%] [G loss: 1.470287]\n",
      "epoch:25 step:23900 [D loss: 0.482175, acc.: 79.69%] [G loss: 1.317490]\n",
      "epoch:25 step:23901 [D loss: 0.723792, acc.: 55.47%] [G loss: 1.349948]\n",
      "epoch:25 step:23902 [D loss: 0.593931, acc.: 69.53%] [G loss: 1.285197]\n",
      "epoch:25 step:23903 [D loss: 0.589580, acc.: 69.53%] [G loss: 0.875213]\n",
      "epoch:25 step:23904 [D loss: 0.394358, acc.: 87.50%] [G loss: 1.301929]\n",
      "epoch:25 step:23905 [D loss: 0.523339, acc.: 78.12%] [G loss: 1.136766]\n",
      "epoch:25 step:23906 [D loss: 0.398713, acc.: 82.81%] [G loss: 1.387695]\n",
      "epoch:25 step:23907 [D loss: 0.745224, acc.: 54.69%] [G loss: 1.174812]\n",
      "epoch:25 step:23908 [D loss: 0.635799, acc.: 60.94%] [G loss: 0.894867]\n",
      "epoch:25 step:23909 [D loss: 0.377112, acc.: 92.97%] [G loss: 1.310581]\n",
      "epoch:25 step:23910 [D loss: 0.538316, acc.: 71.88%] [G loss: 0.976065]\n",
      "epoch:25 step:23911 [D loss: 0.621993, acc.: 65.62%] [G loss: 1.216258]\n",
      "epoch:25 step:23912 [D loss: 0.424734, acc.: 85.16%] [G loss: 1.472539]\n",
      "epoch:25 step:23913 [D loss: 0.490893, acc.: 81.25%] [G loss: 1.082415]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23914 [D loss: 0.552935, acc.: 68.75%] [G loss: 1.160315]\n",
      "epoch:25 step:23915 [D loss: 0.400032, acc.: 87.50%] [G loss: 1.284410]\n",
      "epoch:25 step:23916 [D loss: 0.528043, acc.: 76.56%] [G loss: 0.992726]\n",
      "epoch:25 step:23917 [D loss: 0.687223, acc.: 53.91%] [G loss: 1.476442]\n",
      "epoch:25 step:23918 [D loss: 0.891332, acc.: 36.72%] [G loss: 0.875533]\n",
      "epoch:25 step:23919 [D loss: 0.541616, acc.: 76.56%] [G loss: 0.960009]\n",
      "epoch:25 step:23920 [D loss: 0.632099, acc.: 64.06%] [G loss: 1.061144]\n",
      "epoch:25 step:23921 [D loss: 0.799464, acc.: 45.31%] [G loss: 0.924400]\n",
      "epoch:25 step:23922 [D loss: 0.430214, acc.: 84.38%] [G loss: 1.026287]\n",
      "epoch:25 step:23923 [D loss: 0.406917, acc.: 89.06%] [G loss: 1.428527]\n",
      "epoch:25 step:23924 [D loss: 0.262385, acc.: 96.88%] [G loss: 1.511883]\n",
      "epoch:25 step:23925 [D loss: 0.741783, acc.: 54.69%] [G loss: 1.308667]\n",
      "epoch:25 step:23926 [D loss: 0.851141, acc.: 44.53%] [G loss: 1.271631]\n",
      "epoch:25 step:23927 [D loss: 0.617691, acc.: 63.28%] [G loss: 1.072007]\n",
      "epoch:25 step:23928 [D loss: 0.394992, acc.: 80.47%] [G loss: 1.167037]\n",
      "epoch:25 step:23929 [D loss: 0.314575, acc.: 85.16%] [G loss: 1.602891]\n",
      "epoch:25 step:23930 [D loss: 0.367565, acc.: 90.62%] [G loss: 1.843729]\n",
      "epoch:25 step:23931 [D loss: 0.431212, acc.: 85.16%] [G loss: 1.322900]\n",
      "epoch:25 step:23932 [D loss: 0.411228, acc.: 86.72%] [G loss: 1.234965]\n",
      "epoch:25 step:23933 [D loss: 0.328970, acc.: 87.50%] [G loss: 1.718168]\n",
      "epoch:25 step:23934 [D loss: 0.770460, acc.: 54.69%] [G loss: 1.575188]\n",
      "epoch:25 step:23935 [D loss: 0.803108, acc.: 46.09%] [G loss: 1.097042]\n",
      "epoch:25 step:23936 [D loss: 0.444030, acc.: 84.38%] [G loss: 1.304475]\n",
      "epoch:25 step:23937 [D loss: 0.465870, acc.: 85.94%] [G loss: 1.252829]\n",
      "epoch:25 step:23938 [D loss: 0.416267, acc.: 82.03%] [G loss: 1.294039]\n",
      "epoch:25 step:23939 [D loss: 0.422339, acc.: 85.94%] [G loss: 1.246485]\n",
      "epoch:25 step:23940 [D loss: 0.395385, acc.: 89.84%] [G loss: 1.571712]\n",
      "epoch:25 step:23941 [D loss: 0.658464, acc.: 57.81%] [G loss: 1.259768]\n",
      "epoch:25 step:23942 [D loss: 0.583110, acc.: 67.97%] [G loss: 1.302638]\n",
      "epoch:25 step:23943 [D loss: 0.660118, acc.: 60.94%] [G loss: 1.028058]\n",
      "epoch:25 step:23944 [D loss: 0.517635, acc.: 79.69%] [G loss: 1.235021]\n",
      "epoch:25 step:23945 [D loss: 0.472425, acc.: 85.94%] [G loss: 1.038527]\n",
      "epoch:25 step:23946 [D loss: 0.635294, acc.: 63.28%] [G loss: 1.341175]\n",
      "epoch:25 step:23947 [D loss: 0.505636, acc.: 80.47%] [G loss: 0.998034]\n",
      "epoch:25 step:23948 [D loss: 0.466144, acc.: 82.81%] [G loss: 1.157490]\n",
      "epoch:25 step:23949 [D loss: 0.492272, acc.: 78.12%] [G loss: 1.335090]\n",
      "epoch:25 step:23950 [D loss: 0.443100, acc.: 84.38%] [G loss: 1.351835]\n",
      "epoch:25 step:23951 [D loss: 0.435438, acc.: 85.94%] [G loss: 1.146915]\n",
      "epoch:25 step:23952 [D loss: 0.529540, acc.: 77.34%] [G loss: 1.119874]\n",
      "epoch:25 step:23953 [D loss: 0.622527, acc.: 63.28%] [G loss: 1.160977]\n",
      "epoch:25 step:23954 [D loss: 0.554760, acc.: 73.44%] [G loss: 1.119500]\n",
      "epoch:25 step:23955 [D loss: 0.460697, acc.: 82.81%] [G loss: 1.317071]\n",
      "epoch:25 step:23956 [D loss: 0.907409, acc.: 26.56%] [G loss: 1.119656]\n",
      "epoch:25 step:23957 [D loss: 0.540332, acc.: 76.56%] [G loss: 1.232651]\n",
      "epoch:25 step:23958 [D loss: 0.406397, acc.: 88.28%] [G loss: 1.202525]\n",
      "epoch:25 step:23959 [D loss: 0.475364, acc.: 81.25%] [G loss: 1.476619]\n",
      "epoch:25 step:23960 [D loss: 0.381543, acc.: 88.28%] [G loss: 1.308755]\n",
      "epoch:25 step:23961 [D loss: 0.342254, acc.: 90.62%] [G loss: 1.357063]\n",
      "epoch:25 step:23962 [D loss: 0.277389, acc.: 96.09%] [G loss: 1.516096]\n",
      "epoch:25 step:23963 [D loss: 0.687134, acc.: 56.25%] [G loss: 0.693291]\n",
      "epoch:25 step:23964 [D loss: 0.476725, acc.: 81.25%] [G loss: 1.584252]\n",
      "epoch:25 step:23965 [D loss: 0.620528, acc.: 64.84%] [G loss: 1.434205]\n",
      "epoch:25 step:23966 [D loss: 0.619490, acc.: 62.50%] [G loss: 1.173887]\n",
      "epoch:25 step:23967 [D loss: 1.000028, acc.: 28.12%] [G loss: 1.091262]\n",
      "epoch:25 step:23968 [D loss: 0.843413, acc.: 35.94%] [G loss: 1.008238]\n",
      "epoch:25 step:23969 [D loss: 0.607786, acc.: 64.84%] [G loss: 1.362984]\n",
      "epoch:25 step:23970 [D loss: 0.507944, acc.: 72.66%] [G loss: 1.276486]\n",
      "epoch:25 step:23971 [D loss: 0.339907, acc.: 92.97%] [G loss: 1.431685]\n",
      "epoch:25 step:23972 [D loss: 0.332296, acc.: 92.97%] [G loss: 1.437008]\n",
      "epoch:25 step:23973 [D loss: 0.510224, acc.: 74.22%] [G loss: 1.070378]\n",
      "epoch:25 step:23974 [D loss: 0.317608, acc.: 93.75%] [G loss: 1.510484]\n",
      "epoch:25 step:23975 [D loss: 0.440685, acc.: 83.59%] [G loss: 1.457131]\n",
      "epoch:25 step:23976 [D loss: 0.420042, acc.: 83.59%] [G loss: 1.285799]\n",
      "epoch:25 step:23977 [D loss: 0.446075, acc.: 83.59%] [G loss: 1.534375]\n",
      "epoch:25 step:23978 [D loss: 0.407484, acc.: 84.38%] [G loss: 1.515822]\n",
      "epoch:25 step:23979 [D loss: 0.478808, acc.: 76.56%] [G loss: 1.085686]\n",
      "epoch:25 step:23980 [D loss: 0.320864, acc.: 94.53%] [G loss: 1.543932]\n",
      "epoch:25 step:23981 [D loss: 0.409197, acc.: 82.81%] [G loss: 1.324408]\n",
      "epoch:25 step:23982 [D loss: 0.387320, acc.: 87.50%] [G loss: 1.725325]\n",
      "epoch:25 step:23983 [D loss: 0.507707, acc.: 78.12%] [G loss: 1.251126]\n",
      "epoch:25 step:23984 [D loss: 0.540678, acc.: 74.22%] [G loss: 1.688139]\n",
      "epoch:25 step:23985 [D loss: 0.897959, acc.: 44.53%] [G loss: 1.306504]\n",
      "epoch:25 step:23986 [D loss: 0.291191, acc.: 96.88%] [G loss: 1.483716]\n",
      "epoch:25 step:23987 [D loss: 0.602786, acc.: 68.75%] [G loss: 1.330047]\n",
      "epoch:25 step:23988 [D loss: 0.620911, acc.: 62.50%] [G loss: 1.245007]\n",
      "epoch:25 step:23989 [D loss: 0.475658, acc.: 82.03%] [G loss: 1.307578]\n",
      "epoch:25 step:23990 [D loss: 0.456006, acc.: 82.81%] [G loss: 1.370524]\n",
      "epoch:25 step:23991 [D loss: 0.297841, acc.: 91.41%] [G loss: 1.232720]\n",
      "epoch:25 step:23992 [D loss: 0.377229, acc.: 91.41%] [G loss: 1.275690]\n",
      "epoch:25 step:23993 [D loss: 0.684558, acc.: 58.59%] [G loss: 1.228231]\n",
      "epoch:25 step:23994 [D loss: 0.681200, acc.: 61.72%] [G loss: 1.250210]\n",
      "epoch:25 step:23995 [D loss: 0.625920, acc.: 64.06%] [G loss: 1.303739]\n",
      "epoch:25 step:23996 [D loss: 0.799321, acc.: 46.09%] [G loss: 0.751711]\n",
      "epoch:25 step:23997 [D loss: 0.715200, acc.: 52.34%] [G loss: 0.915656]\n",
      "epoch:25 step:23998 [D loss: 0.635127, acc.: 64.84%] [G loss: 0.974366]\n",
      "epoch:25 step:23999 [D loss: 0.564521, acc.: 70.31%] [G loss: 1.383814]\n",
      "epoch:25 step:24000 [D loss: 0.673139, acc.: 61.72%] [G loss: 0.998248]\n",
      "##############\n",
      "[2.54618172 1.71599354 5.46474966 4.42409559 3.1810948  5.30258559\n",
      " 4.307841   4.8969343  3.82068263 3.65054311]\n",
      "##########\n",
      "epoch:25 step:24001 [D loss: 0.393254, acc.: 89.84%] [G loss: 1.484416]\n",
      "epoch:25 step:24002 [D loss: 0.567041, acc.: 70.31%] [G loss: 1.098686]\n",
      "epoch:25 step:24003 [D loss: 0.404977, acc.: 88.28%] [G loss: 1.311386]\n",
      "epoch:25 step:24004 [D loss: 0.615814, acc.: 61.72%] [G loss: 1.281379]\n",
      "epoch:25 step:24005 [D loss: 0.623306, acc.: 62.50%] [G loss: 0.971506]\n",
      "epoch:25 step:24006 [D loss: 0.607503, acc.: 66.41%] [G loss: 0.834463]\n",
      "epoch:25 step:24007 [D loss: 0.653578, acc.: 58.59%] [G loss: 0.607063]\n",
      "epoch:25 step:24008 [D loss: 0.736437, acc.: 50.78%] [G loss: 0.918998]\n",
      "epoch:25 step:24009 [D loss: 0.776207, acc.: 49.22%] [G loss: 0.889253]\n",
      "epoch:25 step:24010 [D loss: 0.742523, acc.: 50.78%] [G loss: 0.846491]\n",
      "epoch:25 step:24011 [D loss: 0.673809, acc.: 60.16%] [G loss: 1.019876]\n",
      "epoch:25 step:24012 [D loss: 0.460475, acc.: 79.69%] [G loss: 1.034913]\n",
      "epoch:25 step:24013 [D loss: 0.518804, acc.: 72.66%] [G loss: 1.354541]\n",
      "epoch:25 step:24014 [D loss: 0.420389, acc.: 85.16%] [G loss: 1.437651]\n",
      "epoch:25 step:24015 [D loss: 0.829602, acc.: 45.31%] [G loss: 0.945182]\n",
      "epoch:25 step:24016 [D loss: 0.553713, acc.: 72.66%] [G loss: 1.179658]\n",
      "epoch:25 step:24017 [D loss: 0.406464, acc.: 87.50%] [G loss: 1.780976]\n",
      "epoch:25 step:24018 [D loss: 0.686081, acc.: 59.38%] [G loss: 1.067596]\n",
      "epoch:25 step:24019 [D loss: 0.753849, acc.: 57.03%] [G loss: 1.394391]\n",
      "epoch:25 step:24020 [D loss: 0.611995, acc.: 62.50%] [G loss: 1.212424]\n",
      "epoch:25 step:24021 [D loss: 0.505911, acc.: 79.69%] [G loss: 1.252576]\n",
      "epoch:25 step:24022 [D loss: 0.440435, acc.: 85.16%] [G loss: 1.275795]\n",
      "epoch:25 step:24023 [D loss: 0.250140, acc.: 96.09%] [G loss: 1.381293]\n",
      "epoch:25 step:24024 [D loss: 0.478276, acc.: 79.69%] [G loss: 1.259623]\n",
      "epoch:25 step:24025 [D loss: 0.614017, acc.: 64.06%] [G loss: 1.151444]\n",
      "epoch:25 step:24026 [D loss: 0.507711, acc.: 78.12%] [G loss: 1.090248]\n",
      "epoch:25 step:24027 [D loss: 0.625907, acc.: 61.72%] [G loss: 1.027646]\n",
      "epoch:25 step:24028 [D loss: 0.332480, acc.: 92.97%] [G loss: 1.036791]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:24029 [D loss: 0.295609, acc.: 95.31%] [G loss: 1.303023]\n",
      "epoch:25 step:24030 [D loss: 0.350816, acc.: 92.19%] [G loss: 1.414666]\n",
      "epoch:25 step:24031 [D loss: 0.584463, acc.: 69.53%] [G loss: 1.334843]\n",
      "epoch:25 step:24032 [D loss: 0.604617, acc.: 66.41%] [G loss: 1.241914]\n",
      "epoch:25 step:24033 [D loss: 0.652053, acc.: 64.84%] [G loss: 1.087848]\n",
      "epoch:25 step:24034 [D loss: 0.550341, acc.: 73.44%] [G loss: 1.115624]\n",
      "epoch:25 step:24035 [D loss: 0.344742, acc.: 89.06%] [G loss: 1.491721]\n",
      "epoch:25 step:24036 [D loss: 0.635410, acc.: 61.72%] [G loss: 0.948974]\n",
      "epoch:25 step:24037 [D loss: 0.744924, acc.: 48.44%] [G loss: 1.200268]\n",
      "epoch:25 step:24038 [D loss: 0.436183, acc.: 78.12%] [G loss: 1.130736]\n",
      "epoch:25 step:24039 [D loss: 0.351931, acc.: 89.84%] [G loss: 1.671814]\n",
      "epoch:25 step:24040 [D loss: 0.330565, acc.: 88.28%] [G loss: 1.407465]\n",
      "epoch:25 step:24041 [D loss: 0.303997, acc.: 96.88%] [G loss: 1.466313]\n",
      "epoch:25 step:24042 [D loss: 0.384238, acc.: 88.28%] [G loss: 1.433414]\n",
      "epoch:25 step:24043 [D loss: 0.814957, acc.: 48.44%] [G loss: 0.948543]\n",
      "epoch:25 step:24044 [D loss: 0.805986, acc.: 49.22%] [G loss: 0.773933]\n",
      "epoch:25 step:24045 [D loss: 1.120127, acc.: 26.56%] [G loss: 0.736177]\n",
      "epoch:25 step:24046 [D loss: 0.678730, acc.: 59.38%] [G loss: 0.898604]\n",
      "epoch:25 step:24047 [D loss: 0.722589, acc.: 55.47%] [G loss: 1.053905]\n",
      "epoch:25 step:24048 [D loss: 0.518287, acc.: 78.12%] [G loss: 1.447179]\n",
      "epoch:25 step:24049 [D loss: 0.458369, acc.: 83.59%] [G loss: 1.198853]\n",
      "epoch:25 step:24050 [D loss: 1.143668, acc.: 25.00%] [G loss: 0.786403]\n",
      "epoch:25 step:24051 [D loss: 0.717058, acc.: 51.56%] [G loss: 1.094367]\n",
      "epoch:25 step:24052 [D loss: 1.297289, acc.: 11.72%] [G loss: 0.554351]\n",
      "epoch:25 step:24053 [D loss: 0.842933, acc.: 44.53%] [G loss: 1.004006]\n",
      "epoch:25 step:24054 [D loss: 0.368059, acc.: 87.50%] [G loss: 1.363975]\n",
      "epoch:25 step:24055 [D loss: 0.655076, acc.: 62.50%] [G loss: 1.058168]\n",
      "epoch:25 step:24056 [D loss: 0.626530, acc.: 66.41%] [G loss: 1.545626]\n",
      "epoch:25 step:24057 [D loss: 0.605646, acc.: 67.19%] [G loss: 1.032113]\n",
      "epoch:25 step:24058 [D loss: 0.496329, acc.: 79.69%] [G loss: 1.056337]\n",
      "epoch:25 step:24059 [D loss: 0.766191, acc.: 52.34%] [G loss: 0.958923]\n",
      "epoch:25 step:24060 [D loss: 0.786715, acc.: 46.88%] [G loss: 1.219248]\n",
      "epoch:25 step:24061 [D loss: 0.884649, acc.: 37.50%] [G loss: 1.062297]\n",
      "epoch:25 step:24062 [D loss: 0.993434, acc.: 32.81%] [G loss: 1.079167]\n",
      "epoch:25 step:24063 [D loss: 0.806991, acc.: 42.19%] [G loss: 1.165421]\n",
      "epoch:25 step:24064 [D loss: 0.914169, acc.: 42.97%] [G loss: 1.410393]\n",
      "epoch:25 step:24065 [D loss: 0.680566, acc.: 58.59%] [G loss: 1.157492]\n",
      "epoch:25 step:24066 [D loss: 0.605639, acc.: 69.53%] [G loss: 1.558430]\n",
      "epoch:25 step:24067 [D loss: 0.485980, acc.: 77.34%] [G loss: 1.730939]\n",
      "epoch:25 step:24068 [D loss: 0.578422, acc.: 66.41%] [G loss: 1.295060]\n",
      "epoch:25 step:24069 [D loss: 0.791376, acc.: 47.66%] [G loss: 1.016357]\n",
      "epoch:25 step:24070 [D loss: 0.598112, acc.: 71.09%] [G loss: 1.071267]\n",
      "epoch:25 step:24071 [D loss: 0.610831, acc.: 69.53%] [G loss: 0.977927]\n",
      "epoch:25 step:24072 [D loss: 0.616992, acc.: 64.06%] [G loss: 1.048079]\n",
      "epoch:25 step:24073 [D loss: 0.553576, acc.: 72.66%] [G loss: 1.113056]\n",
      "epoch:25 step:24074 [D loss: 0.461258, acc.: 85.16%] [G loss: 1.073564]\n",
      "epoch:25 step:24075 [D loss: 0.556504, acc.: 72.66%] [G loss: 1.250447]\n",
      "epoch:25 step:24076 [D loss: 0.810438, acc.: 47.66%] [G loss: 1.080662]\n",
      "epoch:25 step:24077 [D loss: 0.780721, acc.: 50.78%] [G loss: 0.880341]\n",
      "epoch:25 step:24078 [D loss: 0.717035, acc.: 48.44%] [G loss: 1.009857]\n",
      "epoch:25 step:24079 [D loss: 0.515335, acc.: 81.25%] [G loss: 1.152386]\n",
      "epoch:25 step:24080 [D loss: 0.668742, acc.: 64.06%] [G loss: 1.077616]\n",
      "epoch:25 step:24081 [D loss: 0.655445, acc.: 57.81%] [G loss: 1.039272]\n",
      "epoch:25 step:24082 [D loss: 0.658182, acc.: 57.03%] [G loss: 1.236436]\n",
      "epoch:25 step:24083 [D loss: 0.554253, acc.: 75.00%] [G loss: 1.105924]\n",
      "epoch:25 step:24084 [D loss: 0.733083, acc.: 53.91%] [G loss: 1.267776]\n",
      "epoch:25 step:24085 [D loss: 0.698728, acc.: 54.69%] [G loss: 1.145626]\n",
      "epoch:25 step:24086 [D loss: 0.564627, acc.: 71.09%] [G loss: 1.100331]\n",
      "epoch:25 step:24087 [D loss: 0.471967, acc.: 82.03%] [G loss: 1.314766]\n",
      "epoch:25 step:24088 [D loss: 0.261394, acc.: 94.53%] [G loss: 1.512500]\n",
      "epoch:25 step:24089 [D loss: 0.307896, acc.: 89.84%] [G loss: 1.409938]\n",
      "epoch:25 step:24090 [D loss: 0.239982, acc.: 97.66%] [G loss: 2.046566]\n",
      "epoch:25 step:24091 [D loss: 0.369100, acc.: 90.62%] [G loss: 1.655787]\n",
      "epoch:25 step:24092 [D loss: 0.473050, acc.: 79.69%] [G loss: 1.395916]\n",
      "epoch:25 step:24093 [D loss: 0.586350, acc.: 71.09%] [G loss: 1.452233]\n",
      "epoch:25 step:24094 [D loss: 0.440185, acc.: 83.59%] [G loss: 1.195582]\n",
      "epoch:25 step:24095 [D loss: 0.783975, acc.: 51.56%] [G loss: 0.878989]\n",
      "epoch:25 step:24096 [D loss: 0.731921, acc.: 53.12%] [G loss: 1.465013]\n",
      "epoch:25 step:24097 [D loss: 0.750159, acc.: 60.94%] [G loss: 1.264458]\n",
      "epoch:25 step:24098 [D loss: 0.980063, acc.: 33.59%] [G loss: 0.878332]\n",
      "epoch:25 step:24099 [D loss: 0.789658, acc.: 51.56%] [G loss: 0.988851]\n",
      "epoch:25 step:24100 [D loss: 0.893406, acc.: 40.62%] [G loss: 1.074934]\n",
      "epoch:25 step:24101 [D loss: 1.010126, acc.: 33.59%] [G loss: 0.755408]\n",
      "epoch:25 step:24102 [D loss: 0.827956, acc.: 39.06%] [G loss: 1.107036]\n",
      "epoch:25 step:24103 [D loss: 0.879250, acc.: 39.84%] [G loss: 1.150032]\n",
      "epoch:25 step:24104 [D loss: 0.836845, acc.: 43.75%] [G loss: 1.080397]\n",
      "epoch:25 step:24105 [D loss: 0.649378, acc.: 61.72%] [G loss: 0.944267]\n",
      "epoch:25 step:24106 [D loss: 0.700805, acc.: 52.34%] [G loss: 1.182497]\n",
      "epoch:25 step:24107 [D loss: 0.570331, acc.: 69.53%] [G loss: 1.252051]\n",
      "epoch:25 step:24108 [D loss: 0.643372, acc.: 64.06%] [G loss: 0.884200]\n",
      "epoch:25 step:24109 [D loss: 0.681810, acc.: 58.59%] [G loss: 1.061850]\n",
      "epoch:25 step:24110 [D loss: 0.622387, acc.: 65.62%] [G loss: 0.955465]\n",
      "epoch:25 step:24111 [D loss: 0.740918, acc.: 48.44%] [G loss: 1.188030]\n",
      "epoch:25 step:24112 [D loss: 0.709510, acc.: 54.69%] [G loss: 0.875846]\n",
      "epoch:25 step:24113 [D loss: 0.525797, acc.: 77.34%] [G loss: 1.230309]\n",
      "epoch:25 step:24114 [D loss: 0.569997, acc.: 67.19%] [G loss: 0.907244]\n",
      "epoch:25 step:24115 [D loss: 0.332024, acc.: 95.31%] [G loss: 1.231382]\n",
      "epoch:25 step:24116 [D loss: 0.484689, acc.: 81.25%] [G loss: 1.311643]\n",
      "epoch:25 step:24117 [D loss: 0.482309, acc.: 77.34%] [G loss: 1.578065]\n",
      "epoch:25 step:24118 [D loss: 0.473396, acc.: 82.81%] [G loss: 1.014657]\n",
      "epoch:25 step:24119 [D loss: 0.365208, acc.: 84.38%] [G loss: 1.232939]\n",
      "epoch:25 step:24120 [D loss: 0.601753, acc.: 73.44%] [G loss: 1.154480]\n",
      "epoch:25 step:24121 [D loss: 0.710993, acc.: 57.03%] [G loss: 1.133022]\n",
      "epoch:25 step:24122 [D loss: 0.644596, acc.: 60.94%] [G loss: 0.862704]\n",
      "epoch:25 step:24123 [D loss: 0.711026, acc.: 58.59%] [G loss: 1.044504]\n",
      "epoch:25 step:24124 [D loss: 0.465914, acc.: 81.25%] [G loss: 1.037269]\n",
      "epoch:25 step:24125 [D loss: 0.497344, acc.: 73.44%] [G loss: 1.318813]\n",
      "epoch:25 step:24126 [D loss: 0.340101, acc.: 91.41%] [G loss: 1.467516]\n",
      "epoch:25 step:24127 [D loss: 0.582299, acc.: 70.31%] [G loss: 1.353025]\n",
      "epoch:25 step:24128 [D loss: 0.504725, acc.: 78.12%] [G loss: 1.450166]\n",
      "epoch:25 step:24129 [D loss: 0.563197, acc.: 70.31%] [G loss: 0.933528]\n",
      "epoch:25 step:24130 [D loss: 0.488894, acc.: 84.38%] [G loss: 1.152008]\n",
      "epoch:25 step:24131 [D loss: 0.368259, acc.: 88.28%] [G loss: 1.291078]\n",
      "epoch:25 step:24132 [D loss: 0.512163, acc.: 71.88%] [G loss: 1.046950]\n",
      "epoch:25 step:24133 [D loss: 0.278835, acc.: 92.97%] [G loss: 1.735506]\n",
      "epoch:25 step:24134 [D loss: 0.273414, acc.: 95.31%] [G loss: 1.449538]\n",
      "epoch:25 step:24135 [D loss: 0.942026, acc.: 46.88%] [G loss: 1.278479]\n",
      "epoch:25 step:24136 [D loss: 0.564924, acc.: 67.97%] [G loss: 1.450359]\n",
      "epoch:25 step:24137 [D loss: 0.741569, acc.: 56.25%] [G loss: 0.997364]\n",
      "epoch:25 step:24138 [D loss: 0.432685, acc.: 83.59%] [G loss: 1.014784]\n",
      "epoch:25 step:24139 [D loss: 0.420499, acc.: 89.06%] [G loss: 1.145430]\n",
      "epoch:25 step:24140 [D loss: 0.675502, acc.: 57.81%] [G loss: 1.199314]\n",
      "epoch:25 step:24141 [D loss: 0.694646, acc.: 57.03%] [G loss: 1.157917]\n",
      "epoch:25 step:24142 [D loss: 0.543230, acc.: 75.00%] [G loss: 1.249176]\n",
      "epoch:25 step:24143 [D loss: 0.711289, acc.: 57.03%] [G loss: 0.930217]\n",
      "epoch:25 step:24144 [D loss: 0.581911, acc.: 68.75%] [G loss: 0.964908]\n",
      "epoch:25 step:24145 [D loss: 0.449485, acc.: 81.25%] [G loss: 1.175141]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:24146 [D loss: 0.651830, acc.: 64.06%] [G loss: 1.122314]\n",
      "epoch:25 step:24147 [D loss: 0.622900, acc.: 61.72%] [G loss: 1.113043]\n",
      "epoch:25 step:24148 [D loss: 0.618603, acc.: 67.19%] [G loss: 1.152263]\n",
      "epoch:25 step:24149 [D loss: 0.356063, acc.: 93.75%] [G loss: 1.304048]\n",
      "epoch:25 step:24150 [D loss: 0.337209, acc.: 94.53%] [G loss: 1.417931]\n",
      "epoch:25 step:24151 [D loss: 0.557970, acc.: 72.66%] [G loss: 0.944292]\n",
      "epoch:25 step:24152 [D loss: 0.795832, acc.: 44.53%] [G loss: 0.796975]\n",
      "epoch:25 step:24153 [D loss: 0.557406, acc.: 71.88%] [G loss: 1.086138]\n",
      "epoch:25 step:24154 [D loss: 0.516200, acc.: 72.66%] [G loss: 1.204329]\n",
      "epoch:25 step:24155 [D loss: 0.421182, acc.: 85.16%] [G loss: 1.142616]\n",
      "epoch:25 step:24156 [D loss: 0.369606, acc.: 88.28%] [G loss: 1.348657]\n",
      "epoch:25 step:24157 [D loss: 0.545120, acc.: 72.66%] [G loss: 1.119774]\n",
      "epoch:25 step:24158 [D loss: 0.483100, acc.: 79.69%] [G loss: 1.359018]\n",
      "epoch:25 step:24159 [D loss: 0.798365, acc.: 51.56%] [G loss: 1.208412]\n",
      "epoch:25 step:24160 [D loss: 0.711333, acc.: 50.00%] [G loss: 1.036142]\n",
      "epoch:25 step:24161 [D loss: 0.679781, acc.: 62.50%] [G loss: 1.002281]\n",
      "epoch:25 step:24162 [D loss: 0.620265, acc.: 64.06%] [G loss: 0.901119]\n",
      "epoch:25 step:24163 [D loss: 0.630045, acc.: 66.41%] [G loss: 1.220132]\n",
      "epoch:25 step:24164 [D loss: 0.673545, acc.: 60.94%] [G loss: 0.750388]\n",
      "epoch:25 step:24165 [D loss: 0.601117, acc.: 67.97%] [G loss: 1.366040]\n",
      "epoch:25 step:24166 [D loss: 0.495888, acc.: 78.12%] [G loss: 1.170200]\n",
      "epoch:25 step:24167 [D loss: 0.589691, acc.: 70.31%] [G loss: 1.036631]\n",
      "epoch:25 step:24168 [D loss: 0.618763, acc.: 64.84%] [G loss: 0.912437]\n",
      "epoch:25 step:24169 [D loss: 0.665302, acc.: 60.16%] [G loss: 1.103106]\n",
      "epoch:25 step:24170 [D loss: 0.395151, acc.: 86.72%] [G loss: 1.150118]\n",
      "epoch:25 step:24171 [D loss: 0.413267, acc.: 87.50%] [G loss: 1.201851]\n",
      "epoch:25 step:24172 [D loss: 0.515603, acc.: 76.56%] [G loss: 1.343598]\n",
      "epoch:25 step:24173 [D loss: 0.605280, acc.: 72.66%] [G loss: 1.150565]\n",
      "epoch:25 step:24174 [D loss: 0.633729, acc.: 64.84%] [G loss: 1.137127]\n",
      "epoch:25 step:24175 [D loss: 0.545541, acc.: 71.09%] [G loss: 0.983610]\n",
      "epoch:25 step:24176 [D loss: 0.626550, acc.: 64.84%] [G loss: 0.922222]\n",
      "epoch:25 step:24177 [D loss: 0.711138, acc.: 54.69%] [G loss: 1.026272]\n",
      "epoch:25 step:24178 [D loss: 0.643397, acc.: 62.50%] [G loss: 0.825280]\n",
      "epoch:25 step:24179 [D loss: 0.608035, acc.: 67.97%] [G loss: 0.935207]\n",
      "epoch:25 step:24180 [D loss: 0.425936, acc.: 85.94%] [G loss: 1.128798]\n",
      "epoch:25 step:24181 [D loss: 0.509864, acc.: 77.34%] [G loss: 1.088159]\n",
      "epoch:25 step:24182 [D loss: 0.576295, acc.: 71.09%] [G loss: 1.012809]\n",
      "epoch:25 step:24183 [D loss: 0.673952, acc.: 63.28%] [G loss: 1.133811]\n",
      "epoch:25 step:24184 [D loss: 0.803411, acc.: 46.09%] [G loss: 1.106914]\n",
      "epoch:25 step:24185 [D loss: 0.627552, acc.: 66.41%] [G loss: 1.041899]\n",
      "epoch:25 step:24186 [D loss: 0.659497, acc.: 61.72%] [G loss: 1.004003]\n",
      "epoch:25 step:24187 [D loss: 0.915318, acc.: 32.81%] [G loss: 0.782146]\n",
      "epoch:25 step:24188 [D loss: 0.626777, acc.: 65.62%] [G loss: 0.938298]\n",
      "epoch:25 step:24189 [D loss: 0.761881, acc.: 51.56%] [G loss: 0.909939]\n",
      "epoch:25 step:24190 [D loss: 0.676529, acc.: 59.38%] [G loss: 1.102936]\n",
      "epoch:25 step:24191 [D loss: 0.615991, acc.: 69.53%] [G loss: 1.062000]\n",
      "epoch:25 step:24192 [D loss: 0.450733, acc.: 87.50%] [G loss: 1.289306]\n",
      "epoch:25 step:24193 [D loss: 0.440243, acc.: 82.81%] [G loss: 1.292054]\n",
      "epoch:25 step:24194 [D loss: 0.381356, acc.: 88.28%] [G loss: 1.335253]\n",
      "epoch:25 step:24195 [D loss: 0.593872, acc.: 64.06%] [G loss: 1.226539]\n",
      "epoch:25 step:24196 [D loss: 0.788719, acc.: 47.66%] [G loss: 1.070565]\n",
      "epoch:25 step:24197 [D loss: 0.813723, acc.: 44.53%] [G loss: 1.096948]\n",
      "epoch:25 step:24198 [D loss: 0.625517, acc.: 64.06%] [G loss: 0.872450]\n",
      "epoch:25 step:24199 [D loss: 0.325976, acc.: 88.28%] [G loss: 1.135494]\n",
      "epoch:25 step:24200 [D loss: 0.303744, acc.: 92.97%] [G loss: 1.293684]\n",
      "##############\n",
      "[2.54707682 1.61143826 5.71831617 4.31754911 3.07167742 5.40858754\n",
      " 4.02116495 4.7863234  4.03445307 3.65835206]\n",
      "##########\n",
      "epoch:25 step:24201 [D loss: 0.741237, acc.: 51.56%] [G loss: 0.853311]\n",
      "epoch:25 step:24202 [D loss: 0.582744, acc.: 67.19%] [G loss: 1.206822]\n",
      "epoch:25 step:24203 [D loss: 0.686963, acc.: 57.81%] [G loss: 1.265852]\n",
      "epoch:25 step:24204 [D loss: 0.668478, acc.: 60.16%] [G loss: 1.019106]\n",
      "epoch:25 step:24205 [D loss: 0.443392, acc.: 75.00%] [G loss: 1.128598]\n",
      "epoch:25 step:24206 [D loss: 0.482385, acc.: 80.47%] [G loss: 1.218873]\n",
      "epoch:25 step:24207 [D loss: 0.489377, acc.: 77.34%] [G loss: 1.341139]\n",
      "epoch:25 step:24208 [D loss: 0.717751, acc.: 57.81%] [G loss: 1.411640]\n",
      "epoch:25 step:24209 [D loss: 0.788616, acc.: 43.75%] [G loss: 1.064511]\n",
      "epoch:25 step:24210 [D loss: 0.621281, acc.: 63.28%] [G loss: 0.954636]\n",
      "epoch:25 step:24211 [D loss: 0.385815, acc.: 85.94%] [G loss: 1.299637]\n",
      "epoch:25 step:24212 [D loss: 0.701736, acc.: 57.81%] [G loss: 0.993385]\n",
      "epoch:25 step:24213 [D loss: 0.566363, acc.: 71.09%] [G loss: 1.212309]\n",
      "epoch:25 step:24214 [D loss: 0.682366, acc.: 59.38%] [G loss: 0.812718]\n",
      "epoch:25 step:24215 [D loss: 0.459436, acc.: 78.12%] [G loss: 1.193761]\n",
      "epoch:25 step:24216 [D loss: 0.362509, acc.: 86.72%] [G loss: 1.593695]\n",
      "epoch:25 step:24217 [D loss: 0.197089, acc.: 97.66%] [G loss: 2.382091]\n",
      "epoch:25 step:24218 [D loss: 0.330213, acc.: 91.41%] [G loss: 1.920538]\n",
      "epoch:25 step:24219 [D loss: 0.178360, acc.: 99.22%] [G loss: 2.053978]\n",
      "epoch:25 step:24220 [D loss: 0.436721, acc.: 82.81%] [G loss: 1.427748]\n",
      "epoch:25 step:24221 [D loss: 0.439272, acc.: 83.59%] [G loss: 1.347615]\n",
      "epoch:25 step:24222 [D loss: 0.566699, acc.: 75.00%] [G loss: 1.071752]\n",
      "epoch:25 step:24223 [D loss: 0.572289, acc.: 67.19%] [G loss: 1.392716]\n",
      "epoch:25 step:24224 [D loss: 0.822075, acc.: 42.19%] [G loss: 1.092328]\n",
      "epoch:25 step:24225 [D loss: 1.185860, acc.: 16.41%] [G loss: 0.658790]\n",
      "epoch:25 step:24226 [D loss: 0.927289, acc.: 32.81%] [G loss: 1.153458]\n",
      "epoch:25 step:24227 [D loss: 0.874869, acc.: 42.97%] [G loss: 0.930126]\n",
      "epoch:25 step:24228 [D loss: 0.760064, acc.: 50.78%] [G loss: 1.194712]\n",
      "epoch:25 step:24229 [D loss: 0.428637, acc.: 87.50%] [G loss: 1.468947]\n",
      "epoch:25 step:24230 [D loss: 0.601737, acc.: 66.41%] [G loss: 1.110455]\n",
      "epoch:25 step:24231 [D loss: 0.423604, acc.: 82.81%] [G loss: 1.302259]\n",
      "epoch:25 step:24232 [D loss: 0.667956, acc.: 62.50%] [G loss: 0.995083]\n",
      "epoch:25 step:24233 [D loss: 0.506325, acc.: 77.34%] [G loss: 1.007639]\n",
      "epoch:25 step:24234 [D loss: 0.584834, acc.: 67.19%] [G loss: 1.168107]\n",
      "epoch:25 step:24235 [D loss: 0.620294, acc.: 63.28%] [G loss: 1.100108]\n",
      "epoch:25 step:24236 [D loss: 0.716377, acc.: 54.69%] [G loss: 1.221548]\n",
      "epoch:25 step:24237 [D loss: 0.608857, acc.: 68.75%] [G loss: 1.129953]\n",
      "epoch:25 step:24238 [D loss: 0.611562, acc.: 69.53%] [G loss: 1.208062]\n",
      "epoch:25 step:24239 [D loss: 0.535369, acc.: 75.00%] [G loss: 1.138958]\n",
      "epoch:25 step:24240 [D loss: 0.323994, acc.: 85.94%] [G loss: 1.488120]\n",
      "epoch:25 step:24241 [D loss: 0.341314, acc.: 93.75%] [G loss: 1.514031]\n",
      "epoch:25 step:24242 [D loss: 0.505406, acc.: 75.78%] [G loss: 1.468998]\n",
      "epoch:25 step:24243 [D loss: 0.435956, acc.: 88.28%] [G loss: 1.181059]\n",
      "epoch:25 step:24244 [D loss: 0.467007, acc.: 81.25%] [G loss: 0.968676]\n",
      "epoch:25 step:24245 [D loss: 0.820153, acc.: 39.84%] [G loss: 0.831848]\n",
      "epoch:25 step:24246 [D loss: 0.500143, acc.: 78.91%] [G loss: 0.981940]\n",
      "epoch:25 step:24247 [D loss: 0.762453, acc.: 51.56%] [G loss: 1.032847]\n",
      "epoch:25 step:24248 [D loss: 0.506430, acc.: 78.91%] [G loss: 0.983766]\n",
      "epoch:25 step:24249 [D loss: 0.564352, acc.: 63.28%] [G loss: 0.892289]\n",
      "epoch:25 step:24250 [D loss: 0.418328, acc.: 83.59%] [G loss: 1.120396]\n",
      "epoch:25 step:24251 [D loss: 0.608341, acc.: 67.19%] [G loss: 1.355825]\n",
      "epoch:25 step:24252 [D loss: 0.872180, acc.: 39.06%] [G loss: 1.157940]\n",
      "epoch:25 step:24253 [D loss: 0.589934, acc.: 68.75%] [G loss: 1.296455]\n",
      "epoch:25 step:24254 [D loss: 0.652510, acc.: 62.50%] [G loss: 0.892863]\n",
      "epoch:25 step:24255 [D loss: 0.506562, acc.: 75.00%] [G loss: 1.292888]\n",
      "epoch:25 step:24256 [D loss: 0.357392, acc.: 83.59%] [G loss: 1.546637]\n",
      "epoch:25 step:24257 [D loss: 0.313189, acc.: 90.62%] [G loss: 1.810180]\n",
      "epoch:25 step:24258 [D loss: 0.394510, acc.: 87.50%] [G loss: 1.405172]\n",
      "epoch:25 step:24259 [D loss: 1.477220, acc.: 7.03%] [G loss: 0.691864]\n",
      "epoch:25 step:24260 [D loss: 1.033683, acc.: 22.66%] [G loss: 0.858650]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:24261 [D loss: 0.857915, acc.: 43.75%] [G loss: 1.279721]\n",
      "epoch:25 step:24262 [D loss: 0.643012, acc.: 66.41%] [G loss: 1.336387]\n",
      "epoch:25 step:24263 [D loss: 0.597906, acc.: 71.88%] [G loss: 1.211196]\n",
      "epoch:25 step:24264 [D loss: 0.584150, acc.: 66.41%] [G loss: 1.423134]\n",
      "epoch:25 step:24265 [D loss: 0.456864, acc.: 82.81%] [G loss: 1.132491]\n",
      "epoch:25 step:24266 [D loss: 0.415871, acc.: 85.94%] [G loss: 1.217359]\n",
      "epoch:25 step:24267 [D loss: 0.462898, acc.: 82.03%] [G loss: 1.145306]\n",
      "epoch:25 step:24268 [D loss: 0.594565, acc.: 68.75%] [G loss: 1.388115]\n",
      "epoch:25 step:24269 [D loss: 0.795707, acc.: 46.09%] [G loss: 1.181712]\n",
      "epoch:25 step:24270 [D loss: 0.559917, acc.: 76.56%] [G loss: 1.007024]\n",
      "epoch:25 step:24271 [D loss: 0.712299, acc.: 53.12%] [G loss: 0.908439]\n",
      "epoch:25 step:24272 [D loss: 0.675274, acc.: 57.03%] [G loss: 0.905660]\n",
      "epoch:25 step:24273 [D loss: 0.624263, acc.: 64.06%] [G loss: 1.110163]\n",
      "epoch:25 step:24274 [D loss: 0.476074, acc.: 79.69%] [G loss: 1.109825]\n",
      "epoch:25 step:24275 [D loss: 0.373455, acc.: 85.94%] [G loss: 1.406015]\n",
      "epoch:25 step:24276 [D loss: 0.321219, acc.: 91.41%] [G loss: 1.630731]\n",
      "epoch:25 step:24277 [D loss: 0.194541, acc.: 98.44%] [G loss: 1.754676]\n",
      "epoch:25 step:24278 [D loss: 0.258530, acc.: 96.88%] [G loss: 2.031263]\n",
      "epoch:25 step:24279 [D loss: 0.243597, acc.: 97.66%] [G loss: 1.867088]\n",
      "epoch:25 step:24280 [D loss: 0.343769, acc.: 92.19%] [G loss: 1.650317]\n",
      "epoch:25 step:24281 [D loss: 0.604588, acc.: 67.19%] [G loss: 1.039953]\n",
      "epoch:25 step:24282 [D loss: 0.533760, acc.: 70.31%] [G loss: 1.240806]\n",
      "epoch:25 step:24283 [D loss: 0.829840, acc.: 53.91%] [G loss: 1.682126]\n",
      "epoch:25 step:24284 [D loss: 0.573283, acc.: 68.75%] [G loss: 1.096745]\n",
      "epoch:25 step:24285 [D loss: 0.500149, acc.: 76.56%] [G loss: 1.166967]\n",
      "epoch:25 step:24286 [D loss: 0.766143, acc.: 49.22%] [G loss: 1.130297]\n",
      "epoch:25 step:24287 [D loss: 0.762256, acc.: 48.44%] [G loss: 1.005188]\n",
      "epoch:25 step:24288 [D loss: 0.583837, acc.: 72.66%] [G loss: 1.031612]\n",
      "epoch:25 step:24289 [D loss: 0.751329, acc.: 51.56%] [G loss: 0.871093]\n",
      "epoch:25 step:24290 [D loss: 0.530582, acc.: 72.66%] [G loss: 1.381241]\n",
      "epoch:25 step:24291 [D loss: 0.691229, acc.: 53.91%] [G loss: 1.207787]\n",
      "epoch:25 step:24292 [D loss: 0.655137, acc.: 61.72%] [G loss: 0.986414]\n",
      "epoch:25 step:24293 [D loss: 0.671812, acc.: 56.25%] [G loss: 1.053494]\n",
      "epoch:25 step:24294 [D loss: 0.440746, acc.: 75.00%] [G loss: 0.955922]\n",
      "epoch:25 step:24295 [D loss: 0.622705, acc.: 64.84%] [G loss: 1.075314]\n",
      "epoch:25 step:24296 [D loss: 0.438300, acc.: 84.38%] [G loss: 1.148493]\n",
      "epoch:25 step:24297 [D loss: 0.419065, acc.: 88.28%] [G loss: 1.129771]\n",
      "epoch:25 step:24298 [D loss: 0.458857, acc.: 79.69%] [G loss: 1.071079]\n",
      "epoch:25 step:24299 [D loss: 0.412959, acc.: 89.06%] [G loss: 1.246069]\n",
      "epoch:25 step:24300 [D loss: 0.713244, acc.: 58.59%] [G loss: 0.903399]\n",
      "epoch:25 step:24301 [D loss: 0.634043, acc.: 62.50%] [G loss: 1.477950]\n",
      "epoch:25 step:24302 [D loss: 0.939583, acc.: 29.69%] [G loss: 0.745309]\n",
      "epoch:25 step:24303 [D loss: 0.933755, acc.: 29.69%] [G loss: 1.038752]\n",
      "epoch:25 step:24304 [D loss: 0.740254, acc.: 53.12%] [G loss: 1.259770]\n",
      "epoch:25 step:24305 [D loss: 0.525718, acc.: 77.34%] [G loss: 1.488553]\n",
      "epoch:25 step:24306 [D loss: 0.703876, acc.: 54.69%] [G loss: 0.877538]\n",
      "epoch:25 step:24307 [D loss: 0.685489, acc.: 58.59%] [G loss: 1.139114]\n",
      "epoch:25 step:24308 [D loss: 0.609376, acc.: 66.41%] [G loss: 1.101961]\n",
      "epoch:25 step:24309 [D loss: 0.468434, acc.: 80.47%] [G loss: 1.368370]\n",
      "epoch:25 step:24310 [D loss: 0.506622, acc.: 74.22%] [G loss: 1.310764]\n",
      "epoch:25 step:24311 [D loss: 0.686356, acc.: 59.38%] [G loss: 1.576987]\n",
      "epoch:25 step:24312 [D loss: 0.664020, acc.: 62.50%] [G loss: 1.062158]\n",
      "epoch:25 step:24313 [D loss: 0.766362, acc.: 57.03%] [G loss: 1.194504]\n",
      "epoch:25 step:24314 [D loss: 0.603915, acc.: 66.41%] [G loss: 1.281318]\n",
      "epoch:25 step:24315 [D loss: 0.639026, acc.: 66.41%] [G loss: 1.486932]\n",
      "epoch:25 step:24316 [D loss: 0.924107, acc.: 38.28%] [G loss: 1.087871]\n",
      "epoch:25 step:24317 [D loss: 0.534537, acc.: 71.09%] [G loss: 1.303812]\n",
      "epoch:25 step:24318 [D loss: 0.527347, acc.: 78.91%] [G loss: 1.343054]\n",
      "epoch:25 step:24319 [D loss: 0.370812, acc.: 91.41%] [G loss: 1.291996]\n",
      "epoch:25 step:24320 [D loss: 0.375405, acc.: 92.19%] [G loss: 1.559562]\n",
      "epoch:25 step:24321 [D loss: 0.342425, acc.: 92.19%] [G loss: 1.638783]\n",
      "epoch:25 step:24322 [D loss: 0.252432, acc.: 96.88%] [G loss: 1.804489]\n",
      "epoch:25 step:24323 [D loss: 0.169815, acc.: 100.00%] [G loss: 2.032584]\n",
      "epoch:25 step:24324 [D loss: 0.206870, acc.: 97.66%] [G loss: 1.882089]\n",
      "epoch:25 step:24325 [D loss: 0.154137, acc.: 100.00%] [G loss: 2.099985]\n",
      "epoch:25 step:24326 [D loss: 0.217079, acc.: 97.66%] [G loss: 2.090607]\n",
      "epoch:25 step:24327 [D loss: 0.431543, acc.: 83.59%] [G loss: 1.635893]\n",
      "epoch:25 step:24328 [D loss: 0.262588, acc.: 96.09%] [G loss: 2.222768]\n",
      "epoch:25 step:24329 [D loss: 0.703674, acc.: 56.25%] [G loss: 1.205867]\n",
      "epoch:25 step:24330 [D loss: 0.489780, acc.: 77.34%] [G loss: 1.358891]\n",
      "epoch:25 step:24331 [D loss: 0.709339, acc.: 53.91%] [G loss: 1.052652]\n",
      "epoch:25 step:24332 [D loss: 0.535387, acc.: 71.09%] [G loss: 1.072063]\n",
      "epoch:25 step:24333 [D loss: 0.414110, acc.: 81.25%] [G loss: 1.305890]\n",
      "epoch:25 step:24334 [D loss: 0.175845, acc.: 99.22%] [G loss: 2.133707]\n",
      "epoch:25 step:24335 [D loss: 0.483955, acc.: 75.00%] [G loss: 1.456847]\n",
      "epoch:25 step:24336 [D loss: 0.268767, acc.: 89.06%] [G loss: 1.479686]\n",
      "epoch:25 step:24337 [D loss: 0.134121, acc.: 99.22%] [G loss: 2.009510]\n",
      "epoch:25 step:24338 [D loss: 0.742976, acc.: 55.47%] [G loss: 1.357725]\n",
      "epoch:25 step:24339 [D loss: 0.575468, acc.: 66.41%] [G loss: 1.161716]\n",
      "epoch:25 step:24340 [D loss: 0.602260, acc.: 64.84%] [G loss: 1.116864]\n",
      "epoch:25 step:24341 [D loss: 0.491310, acc.: 81.25%] [G loss: 1.595095]\n",
      "epoch:25 step:24342 [D loss: 0.852794, acc.: 46.88%] [G loss: 0.673345]\n",
      "epoch:25 step:24343 [D loss: 0.453258, acc.: 80.47%] [G loss: 1.449307]\n",
      "epoch:25 step:24344 [D loss: 0.389978, acc.: 80.47%] [G loss: 1.147752]\n",
      "epoch:25 step:24345 [D loss: 0.958172, acc.: 48.44%] [G loss: 1.274441]\n",
      "epoch:25 step:24346 [D loss: 0.917163, acc.: 39.84%] [G loss: 1.446849]\n",
      "epoch:25 step:24347 [D loss: 0.547604, acc.: 71.88%] [G loss: 1.196155]\n",
      "epoch:25 step:24348 [D loss: 0.536396, acc.: 75.78%] [G loss: 1.378139]\n",
      "epoch:25 step:24349 [D loss: 0.440245, acc.: 80.47%] [G loss: 1.265182]\n",
      "epoch:25 step:24350 [D loss: 0.517221, acc.: 80.47%] [G loss: 1.325612]\n",
      "epoch:25 step:24351 [D loss: 0.335119, acc.: 92.97%] [G loss: 1.500131]\n",
      "epoch:25 step:24352 [D loss: 0.179115, acc.: 98.44%] [G loss: 1.772043]\n",
      "epoch:25 step:24353 [D loss: 1.033693, acc.: 45.31%] [G loss: 1.460823]\n",
      "epoch:25 step:24354 [D loss: 0.611820, acc.: 65.62%] [G loss: 1.027488]\n",
      "epoch:25 step:24355 [D loss: 0.496654, acc.: 78.12%] [G loss: 1.512098]\n",
      "epoch:25 step:24356 [D loss: 0.803819, acc.: 50.78%] [G loss: 0.840978]\n",
      "epoch:25 step:24357 [D loss: 0.706701, acc.: 51.56%] [G loss: 1.175773]\n",
      "epoch:25 step:24358 [D loss: 0.567509, acc.: 72.66%] [G loss: 1.300015]\n",
      "epoch:25 step:24359 [D loss: 0.288937, acc.: 94.53%] [G loss: 1.560332]\n",
      "epoch:25 step:24360 [D loss: 0.680639, acc.: 57.81%] [G loss: 1.158424]\n",
      "epoch:25 step:24361 [D loss: 0.507714, acc.: 75.78%] [G loss: 1.141469]\n",
      "epoch:25 step:24362 [D loss: 0.222260, acc.: 92.97%] [G loss: 1.625791]\n",
      "epoch:26 step:24363 [D loss: 0.793309, acc.: 49.22%] [G loss: 1.747395]\n",
      "epoch:26 step:24364 [D loss: 0.994500, acc.: 32.81%] [G loss: 1.042687]\n",
      "epoch:26 step:24365 [D loss: 0.730614, acc.: 48.44%] [G loss: 1.182962]\n",
      "epoch:26 step:24366 [D loss: 0.573735, acc.: 74.22%] [G loss: 1.321725]\n",
      "epoch:26 step:24367 [D loss: 0.559780, acc.: 71.88%] [G loss: 1.287642]\n",
      "epoch:26 step:24368 [D loss: 0.491397, acc.: 78.91%] [G loss: 1.212130]\n",
      "epoch:26 step:24369 [D loss: 0.662042, acc.: 61.72%] [G loss: 1.182559]\n",
      "epoch:26 step:24370 [D loss: 0.691359, acc.: 56.25%] [G loss: 1.123226]\n",
      "epoch:26 step:24371 [D loss: 0.609788, acc.: 63.28%] [G loss: 1.254763]\n",
      "epoch:26 step:24372 [D loss: 0.460187, acc.: 78.12%] [G loss: 1.390810]\n",
      "epoch:26 step:24373 [D loss: 0.620736, acc.: 65.62%] [G loss: 1.351029]\n",
      "epoch:26 step:24374 [D loss: 0.700974, acc.: 60.16%] [G loss: 1.247484]\n",
      "epoch:26 step:24375 [D loss: 0.675309, acc.: 56.25%] [G loss: 1.480820]\n",
      "epoch:26 step:24376 [D loss: 0.595660, acc.: 67.19%] [G loss: 1.157024]\n",
      "epoch:26 step:24377 [D loss: 0.617257, acc.: 65.62%] [G loss: 0.932291]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24378 [D loss: 0.387902, acc.: 91.41%] [G loss: 1.576552]\n",
      "epoch:26 step:24379 [D loss: 0.664386, acc.: 59.38%] [G loss: 1.411139]\n",
      "epoch:26 step:24380 [D loss: 0.705441, acc.: 53.12%] [G loss: 1.178312]\n",
      "epoch:26 step:24381 [D loss: 0.829482, acc.: 39.84%] [G loss: 0.909905]\n",
      "epoch:26 step:24382 [D loss: 0.514151, acc.: 74.22%] [G loss: 1.258919]\n",
      "epoch:26 step:24383 [D loss: 0.610959, acc.: 64.06%] [G loss: 0.996586]\n",
      "epoch:26 step:24384 [D loss: 0.584598, acc.: 71.88%] [G loss: 1.067391]\n",
      "epoch:26 step:24385 [D loss: 0.632152, acc.: 58.59%] [G loss: 1.112029]\n",
      "epoch:26 step:24386 [D loss: 0.590686, acc.: 66.41%] [G loss: 1.113950]\n",
      "epoch:26 step:24387 [D loss: 0.611768, acc.: 68.75%] [G loss: 1.099618]\n",
      "epoch:26 step:24388 [D loss: 0.441851, acc.: 82.03%] [G loss: 1.275834]\n",
      "epoch:26 step:24389 [D loss: 0.303440, acc.: 92.19%] [G loss: 1.444941]\n",
      "epoch:26 step:24390 [D loss: 0.401440, acc.: 86.72%] [G loss: 1.381732]\n",
      "epoch:26 step:24391 [D loss: 0.334435, acc.: 95.31%] [G loss: 1.593700]\n",
      "epoch:26 step:24392 [D loss: 0.308952, acc.: 94.53%] [G loss: 1.429335]\n",
      "epoch:26 step:24393 [D loss: 0.253479, acc.: 96.88%] [G loss: 1.554627]\n",
      "epoch:26 step:24394 [D loss: 0.259431, acc.: 94.53%] [G loss: 1.917017]\n",
      "epoch:26 step:24395 [D loss: 0.282274, acc.: 94.53%] [G loss: 1.887602]\n",
      "epoch:26 step:24396 [D loss: 0.343033, acc.: 89.06%] [G loss: 1.805049]\n",
      "epoch:26 step:24397 [D loss: 0.186391, acc.: 98.44%] [G loss: 1.565396]\n",
      "epoch:26 step:24398 [D loss: 0.127166, acc.: 100.00%] [G loss: 2.236660]\n",
      "epoch:26 step:24399 [D loss: 0.890741, acc.: 52.34%] [G loss: 1.368136]\n",
      "epoch:26 step:24400 [D loss: 0.715030, acc.: 54.69%] [G loss: 1.219151]\n",
      "##############\n",
      "[2.56789169 1.57865542 5.52001538 4.17994938 3.09821353 5.5605789\n",
      " 4.22457838 4.76002595 4.21701415 3.67923791]\n",
      "##########\n",
      "epoch:26 step:24401 [D loss: 0.680764, acc.: 57.03%] [G loss: 1.230017]\n",
      "epoch:26 step:24402 [D loss: 0.688943, acc.: 56.25%] [G loss: 1.001406]\n",
      "epoch:26 step:24403 [D loss: 0.763199, acc.: 54.69%] [G loss: 0.810606]\n",
      "epoch:26 step:24404 [D loss: 0.510412, acc.: 75.00%] [G loss: 1.147652]\n",
      "epoch:26 step:24405 [D loss: 0.498682, acc.: 86.72%] [G loss: 1.098434]\n",
      "epoch:26 step:24406 [D loss: 0.520816, acc.: 73.44%] [G loss: 1.131004]\n",
      "epoch:26 step:24407 [D loss: 0.531094, acc.: 78.91%] [G loss: 0.928246]\n",
      "epoch:26 step:24408 [D loss: 0.827445, acc.: 46.88%] [G loss: 0.992871]\n",
      "epoch:26 step:24409 [D loss: 0.788716, acc.: 46.09%] [G loss: 1.048315]\n",
      "epoch:26 step:24410 [D loss: 0.652052, acc.: 60.94%] [G loss: 1.014287]\n",
      "epoch:26 step:24411 [D loss: 0.586375, acc.: 71.88%] [G loss: 1.160299]\n",
      "epoch:26 step:24412 [D loss: 0.662803, acc.: 62.50%] [G loss: 1.153600]\n",
      "epoch:26 step:24413 [D loss: 0.812226, acc.: 43.75%] [G loss: 1.056511]\n",
      "epoch:26 step:24414 [D loss: 0.680257, acc.: 60.94%] [G loss: 0.986846]\n",
      "epoch:26 step:24415 [D loss: 0.640686, acc.: 60.16%] [G loss: 1.002414]\n",
      "epoch:26 step:24416 [D loss: 0.606405, acc.: 64.84%] [G loss: 0.926350]\n",
      "epoch:26 step:24417 [D loss: 0.547778, acc.: 76.56%] [G loss: 1.207522]\n",
      "epoch:26 step:24418 [D loss: 0.712409, acc.: 53.91%] [G loss: 1.035745]\n",
      "epoch:26 step:24419 [D loss: 0.649850, acc.: 66.41%] [G loss: 1.049559]\n",
      "epoch:26 step:24420 [D loss: 0.741795, acc.: 52.34%] [G loss: 0.847647]\n",
      "epoch:26 step:24421 [D loss: 0.661486, acc.: 60.94%] [G loss: 0.966729]\n",
      "epoch:26 step:24422 [D loss: 0.522984, acc.: 75.00%] [G loss: 1.280976]\n",
      "epoch:26 step:24423 [D loss: 0.847421, acc.: 38.28%] [G loss: 0.803167]\n",
      "epoch:26 step:24424 [D loss: 0.663867, acc.: 64.84%] [G loss: 1.166163]\n",
      "epoch:26 step:24425 [D loss: 0.532344, acc.: 72.66%] [G loss: 1.127175]\n",
      "epoch:26 step:24426 [D loss: 0.640251, acc.: 59.38%] [G loss: 0.945767]\n",
      "epoch:26 step:24427 [D loss: 0.931561, acc.: 33.59%] [G loss: 0.793939]\n",
      "epoch:26 step:24428 [D loss: 0.638543, acc.: 61.72%] [G loss: 1.093999]\n",
      "epoch:26 step:24429 [D loss: 0.579238, acc.: 71.88%] [G loss: 1.012798]\n",
      "epoch:26 step:24430 [D loss: 0.604513, acc.: 66.41%] [G loss: 1.095221]\n",
      "epoch:26 step:24431 [D loss: 0.548854, acc.: 72.66%] [G loss: 1.032393]\n",
      "epoch:26 step:24432 [D loss: 0.628074, acc.: 60.16%] [G loss: 1.153259]\n",
      "epoch:26 step:24433 [D loss: 0.542790, acc.: 78.91%] [G loss: 1.173661]\n",
      "epoch:26 step:24434 [D loss: 0.645651, acc.: 60.94%] [G loss: 1.334502]\n",
      "epoch:26 step:24435 [D loss: 0.542982, acc.: 76.56%] [G loss: 1.187210]\n",
      "epoch:26 step:24436 [D loss: 0.797626, acc.: 53.12%] [G loss: 0.757043]\n",
      "epoch:26 step:24437 [D loss: 0.217183, acc.: 96.09%] [G loss: 1.547357]\n",
      "epoch:26 step:24438 [D loss: 0.367205, acc.: 89.84%] [G loss: 1.424384]\n",
      "epoch:26 step:24439 [D loss: 0.567688, acc.: 68.75%] [G loss: 1.322262]\n",
      "epoch:26 step:24440 [D loss: 0.843324, acc.: 43.75%] [G loss: 1.377938]\n",
      "epoch:26 step:24441 [D loss: 0.737544, acc.: 50.00%] [G loss: 1.297370]\n",
      "epoch:26 step:24442 [D loss: 0.609922, acc.: 67.97%] [G loss: 1.109571]\n",
      "epoch:26 step:24443 [D loss: 0.589499, acc.: 71.88%] [G loss: 0.949389]\n",
      "epoch:26 step:24444 [D loss: 0.517522, acc.: 81.25%] [G loss: 1.099448]\n",
      "epoch:26 step:24445 [D loss: 0.430415, acc.: 83.59%] [G loss: 1.245390]\n",
      "epoch:26 step:24446 [D loss: 0.641457, acc.: 60.16%] [G loss: 0.943400]\n",
      "epoch:26 step:24447 [D loss: 0.639974, acc.: 67.19%] [G loss: 1.119658]\n",
      "epoch:26 step:24448 [D loss: 0.524236, acc.: 76.56%] [G loss: 1.247140]\n",
      "epoch:26 step:24449 [D loss: 0.451872, acc.: 83.59%] [G loss: 1.347871]\n",
      "epoch:26 step:24450 [D loss: 0.415138, acc.: 88.28%] [G loss: 1.453426]\n",
      "epoch:26 step:24451 [D loss: 0.628452, acc.: 64.06%] [G loss: 1.178274]\n",
      "epoch:26 step:24452 [D loss: 0.558608, acc.: 66.41%] [G loss: 1.317672]\n",
      "epoch:26 step:24453 [D loss: 0.531203, acc.: 77.34%] [G loss: 1.232727]\n",
      "epoch:26 step:24454 [D loss: 0.417794, acc.: 87.50%] [G loss: 1.595354]\n",
      "epoch:26 step:24455 [D loss: 0.607854, acc.: 67.97%] [G loss: 0.992601]\n",
      "epoch:26 step:24456 [D loss: 0.606375, acc.: 64.06%] [G loss: 1.445399]\n",
      "epoch:26 step:24457 [D loss: 0.864740, acc.: 35.16%] [G loss: 1.027650]\n",
      "epoch:26 step:24458 [D loss: 0.571464, acc.: 73.44%] [G loss: 1.129388]\n",
      "epoch:26 step:24459 [D loss: 0.756213, acc.: 50.00%] [G loss: 0.804795]\n",
      "epoch:26 step:24460 [D loss: 0.857104, acc.: 35.94%] [G loss: 1.089456]\n",
      "epoch:26 step:24461 [D loss: 0.852883, acc.: 35.16%] [G loss: 0.857437]\n",
      "epoch:26 step:24462 [D loss: 0.594767, acc.: 66.41%] [G loss: 1.016225]\n",
      "epoch:26 step:24463 [D loss: 0.779688, acc.: 51.56%] [G loss: 0.618548]\n",
      "epoch:26 step:24464 [D loss: 0.792939, acc.: 42.19%] [G loss: 1.083125]\n",
      "epoch:26 step:24465 [D loss: 0.778975, acc.: 41.41%] [G loss: 0.946023]\n",
      "epoch:26 step:24466 [D loss: 0.740455, acc.: 50.78%] [G loss: 1.156138]\n",
      "epoch:26 step:24467 [D loss: 0.617214, acc.: 63.28%] [G loss: 1.031172]\n",
      "epoch:26 step:24468 [D loss: 0.467711, acc.: 82.03%] [G loss: 1.258043]\n",
      "epoch:26 step:24469 [D loss: 0.445576, acc.: 85.16%] [G loss: 1.257136]\n",
      "epoch:26 step:24470 [D loss: 0.413885, acc.: 89.06%] [G loss: 0.958763]\n",
      "epoch:26 step:24471 [D loss: 0.475679, acc.: 81.25%] [G loss: 1.594536]\n",
      "epoch:26 step:24472 [D loss: 0.592065, acc.: 67.19%] [G loss: 1.057377]\n",
      "epoch:26 step:24473 [D loss: 0.449555, acc.: 83.59%] [G loss: 1.396155]\n",
      "epoch:26 step:24474 [D loss: 0.613693, acc.: 64.06%] [G loss: 1.219123]\n",
      "epoch:26 step:24475 [D loss: 0.817294, acc.: 46.09%] [G loss: 1.018353]\n",
      "epoch:26 step:24476 [D loss: 0.873310, acc.: 40.62%] [G loss: 0.937140]\n",
      "epoch:26 step:24477 [D loss: 0.776690, acc.: 48.44%] [G loss: 0.993478]\n",
      "epoch:26 step:24478 [D loss: 0.418956, acc.: 89.84%] [G loss: 1.193476]\n",
      "epoch:26 step:24479 [D loss: 0.316474, acc.: 89.06%] [G loss: 1.276276]\n",
      "epoch:26 step:24480 [D loss: 0.381594, acc.: 92.19%] [G loss: 1.821755]\n",
      "epoch:26 step:24481 [D loss: 0.309084, acc.: 93.75%] [G loss: 1.523295]\n",
      "epoch:26 step:24482 [D loss: 0.807075, acc.: 50.78%] [G loss: 1.358142]\n",
      "epoch:26 step:24483 [D loss: 0.476370, acc.: 82.81%] [G loss: 1.548022]\n",
      "epoch:26 step:24484 [D loss: 0.421563, acc.: 87.50%] [G loss: 1.267411]\n",
      "epoch:26 step:24485 [D loss: 0.631166, acc.: 67.19%] [G loss: 1.039942]\n",
      "epoch:26 step:24486 [D loss: 0.425727, acc.: 85.16%] [G loss: 1.343511]\n",
      "epoch:26 step:24487 [D loss: 0.587019, acc.: 65.62%] [G loss: 1.005329]\n",
      "epoch:26 step:24488 [D loss: 0.517219, acc.: 78.12%] [G loss: 1.132321]\n",
      "epoch:26 step:24489 [D loss: 0.509803, acc.: 79.69%] [G loss: 1.013161]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24490 [D loss: 0.719276, acc.: 58.59%] [G loss: 0.966704]\n",
      "epoch:26 step:24491 [D loss: 0.817934, acc.: 44.53%] [G loss: 1.253960]\n",
      "epoch:26 step:24492 [D loss: 0.492604, acc.: 81.25%] [G loss: 1.123700]\n",
      "epoch:26 step:24493 [D loss: 0.392433, acc.: 86.72%] [G loss: 1.185377]\n",
      "epoch:26 step:24494 [D loss: 0.538404, acc.: 73.44%] [G loss: 1.084625]\n",
      "epoch:26 step:24495 [D loss: 0.512440, acc.: 80.47%] [G loss: 1.214465]\n",
      "epoch:26 step:24496 [D loss: 0.429214, acc.: 85.16%] [G loss: 1.102973]\n",
      "epoch:26 step:24497 [D loss: 0.466526, acc.: 80.47%] [G loss: 1.050276]\n",
      "epoch:26 step:24498 [D loss: 0.826476, acc.: 39.06%] [G loss: 0.984866]\n",
      "epoch:26 step:24499 [D loss: 0.742108, acc.: 56.25%] [G loss: 1.097017]\n",
      "epoch:26 step:24500 [D loss: 0.645855, acc.: 57.81%] [G loss: 1.001859]\n",
      "epoch:26 step:24501 [D loss: 0.501324, acc.: 84.38%] [G loss: 1.304656]\n",
      "epoch:26 step:24502 [D loss: 0.548907, acc.: 73.44%] [G loss: 1.108197]\n",
      "epoch:26 step:24503 [D loss: 0.630846, acc.: 60.94%] [G loss: 1.009515]\n",
      "epoch:26 step:24504 [D loss: 0.410901, acc.: 86.72%] [G loss: 1.439821]\n",
      "epoch:26 step:24505 [D loss: 0.615504, acc.: 60.94%] [G loss: 1.383262]\n",
      "epoch:26 step:24506 [D loss: 0.527079, acc.: 70.31%] [G loss: 1.312636]\n",
      "epoch:26 step:24507 [D loss: 0.282358, acc.: 95.31%] [G loss: 1.730024]\n",
      "epoch:26 step:24508 [D loss: 0.896805, acc.: 40.62%] [G loss: 1.085541]\n",
      "epoch:26 step:24509 [D loss: 0.742597, acc.: 55.47%] [G loss: 1.423425]\n",
      "epoch:26 step:24510 [D loss: 0.948623, acc.: 32.81%] [G loss: 1.041173]\n",
      "epoch:26 step:24511 [D loss: 0.840373, acc.: 46.88%] [G loss: 0.790963]\n",
      "epoch:26 step:24512 [D loss: 0.281898, acc.: 96.09%] [G loss: 1.643199]\n",
      "epoch:26 step:24513 [D loss: 0.352014, acc.: 89.06%] [G loss: 1.551560]\n",
      "epoch:26 step:24514 [D loss: 0.503597, acc.: 70.31%] [G loss: 1.383948]\n",
      "epoch:26 step:24515 [D loss: 0.907353, acc.: 48.44%] [G loss: 1.553103]\n",
      "epoch:26 step:24516 [D loss: 0.697731, acc.: 58.59%] [G loss: 1.138469]\n",
      "epoch:26 step:24517 [D loss: 1.005298, acc.: 28.91%] [G loss: 1.047422]\n",
      "epoch:26 step:24518 [D loss: 0.385438, acc.: 89.06%] [G loss: 1.383701]\n",
      "epoch:26 step:24519 [D loss: 0.527719, acc.: 76.56%] [G loss: 1.278704]\n",
      "epoch:26 step:24520 [D loss: 0.464585, acc.: 84.38%] [G loss: 1.200520]\n",
      "epoch:26 step:24521 [D loss: 0.330359, acc.: 87.50%] [G loss: 1.363755]\n",
      "epoch:26 step:24522 [D loss: 0.714723, acc.: 55.47%] [G loss: 1.210135]\n",
      "epoch:26 step:24523 [D loss: 0.802671, acc.: 44.53%] [G loss: 0.934159]\n",
      "epoch:26 step:24524 [D loss: 0.685441, acc.: 58.59%] [G loss: 1.006411]\n",
      "epoch:26 step:24525 [D loss: 0.519910, acc.: 74.22%] [G loss: 0.964206]\n",
      "epoch:26 step:24526 [D loss: 0.440737, acc.: 83.59%] [G loss: 1.283636]\n",
      "epoch:26 step:24527 [D loss: 0.499409, acc.: 82.81%] [G loss: 1.322344]\n",
      "epoch:26 step:24528 [D loss: 0.452006, acc.: 80.47%] [G loss: 1.468701]\n",
      "epoch:26 step:24529 [D loss: 0.371551, acc.: 90.62%] [G loss: 1.255354]\n",
      "epoch:26 step:24530 [D loss: 0.346126, acc.: 95.31%] [G loss: 1.577567]\n",
      "epoch:26 step:24531 [D loss: 0.408726, acc.: 89.06%] [G loss: 1.386589]\n",
      "epoch:26 step:24532 [D loss: 0.704527, acc.: 57.03%] [G loss: 1.079656]\n",
      "epoch:26 step:24533 [D loss: 0.663800, acc.: 62.50%] [G loss: 0.814019]\n",
      "epoch:26 step:24534 [D loss: 0.650293, acc.: 63.28%] [G loss: 0.953895]\n",
      "epoch:26 step:24535 [D loss: 0.591952, acc.: 69.53%] [G loss: 1.366528]\n",
      "epoch:26 step:24536 [D loss: 0.729327, acc.: 54.69%] [G loss: 1.125256]\n",
      "epoch:26 step:24537 [D loss: 0.816709, acc.: 48.44%] [G loss: 0.833831]\n",
      "epoch:26 step:24538 [D loss: 0.595459, acc.: 66.41%] [G loss: 1.004058]\n",
      "epoch:26 step:24539 [D loss: 0.722469, acc.: 57.03%] [G loss: 1.115854]\n",
      "epoch:26 step:24540 [D loss: 1.015052, acc.: 31.25%] [G loss: 0.641206]\n",
      "epoch:26 step:24541 [D loss: 0.814149, acc.: 50.00%] [G loss: 0.847889]\n",
      "epoch:26 step:24542 [D loss: 0.781036, acc.: 48.44%] [G loss: 0.939680]\n",
      "epoch:26 step:24543 [D loss: 0.611618, acc.: 63.28%] [G loss: 1.066164]\n",
      "epoch:26 step:24544 [D loss: 0.795019, acc.: 54.69%] [G loss: 0.763239]\n",
      "epoch:26 step:24545 [D loss: 0.839194, acc.: 44.53%] [G loss: 1.163697]\n",
      "epoch:26 step:24546 [D loss: 0.635053, acc.: 60.94%] [G loss: 1.383709]\n",
      "epoch:26 step:24547 [D loss: 1.049823, acc.: 18.75%] [G loss: 0.593843]\n",
      "epoch:26 step:24548 [D loss: 0.820349, acc.: 46.88%] [G loss: 1.030363]\n",
      "epoch:26 step:24549 [D loss: 0.958161, acc.: 29.69%] [G loss: 0.713557]\n",
      "epoch:26 step:24550 [D loss: 0.720601, acc.: 55.47%] [G loss: 0.825269]\n",
      "epoch:26 step:24551 [D loss: 0.760064, acc.: 55.47%] [G loss: 0.956592]\n",
      "epoch:26 step:24552 [D loss: 0.873763, acc.: 38.28%] [G loss: 0.903834]\n",
      "epoch:26 step:24553 [D loss: 0.586255, acc.: 67.97%] [G loss: 1.007934]\n",
      "epoch:26 step:24554 [D loss: 0.447782, acc.: 78.91%] [G loss: 1.244857]\n",
      "epoch:26 step:24555 [D loss: 0.722662, acc.: 53.91%] [G loss: 1.171291]\n",
      "epoch:26 step:24556 [D loss: 0.613544, acc.: 68.75%] [G loss: 1.327370]\n",
      "epoch:26 step:24557 [D loss: 0.755773, acc.: 50.78%] [G loss: 0.905156]\n",
      "epoch:26 step:24558 [D loss: 0.718645, acc.: 57.81%] [G loss: 1.460763]\n",
      "epoch:26 step:24559 [D loss: 0.682065, acc.: 60.16%] [G loss: 1.109321]\n",
      "epoch:26 step:24560 [D loss: 0.838287, acc.: 41.41%] [G loss: 0.902914]\n",
      "epoch:26 step:24561 [D loss: 0.846660, acc.: 37.50%] [G loss: 1.036493]\n",
      "epoch:26 step:24562 [D loss: 0.937012, acc.: 41.41%] [G loss: 0.946295]\n",
      "epoch:26 step:24563 [D loss: 0.823118, acc.: 42.19%] [G loss: 0.946871]\n",
      "epoch:26 step:24564 [D loss: 0.776635, acc.: 49.22%] [G loss: 0.942834]\n",
      "epoch:26 step:24565 [D loss: 0.739835, acc.: 47.66%] [G loss: 0.967895]\n",
      "epoch:26 step:24566 [D loss: 0.516808, acc.: 74.22%] [G loss: 1.182055]\n",
      "epoch:26 step:24567 [D loss: 0.650549, acc.: 63.28%] [G loss: 1.095098]\n",
      "epoch:26 step:24568 [D loss: 0.609049, acc.: 67.19%] [G loss: 0.931816]\n",
      "epoch:26 step:24569 [D loss: 0.519137, acc.: 75.00%] [G loss: 1.072806]\n",
      "epoch:26 step:24570 [D loss: 0.560369, acc.: 68.75%] [G loss: 1.016596]\n",
      "epoch:26 step:24571 [D loss: 0.512595, acc.: 78.91%] [G loss: 1.125377]\n",
      "epoch:26 step:24572 [D loss: 0.785482, acc.: 46.09%] [G loss: 1.126886]\n",
      "epoch:26 step:24573 [D loss: 0.681692, acc.: 58.59%] [G loss: 1.110792]\n",
      "epoch:26 step:24574 [D loss: 0.676242, acc.: 58.59%] [G loss: 1.119613]\n",
      "epoch:26 step:24575 [D loss: 0.561266, acc.: 72.66%] [G loss: 1.447791]\n",
      "epoch:26 step:24576 [D loss: 0.600952, acc.: 69.53%] [G loss: 1.465034]\n",
      "epoch:26 step:24577 [D loss: 0.579628, acc.: 71.09%] [G loss: 1.224754]\n",
      "epoch:26 step:24578 [D loss: 0.538601, acc.: 76.56%] [G loss: 1.378151]\n",
      "epoch:26 step:24579 [D loss: 0.747155, acc.: 55.47%] [G loss: 0.960630]\n",
      "epoch:26 step:24580 [D loss: 0.579614, acc.: 66.41%] [G loss: 1.155785]\n",
      "epoch:26 step:24581 [D loss: 0.762274, acc.: 48.44%] [G loss: 0.866429]\n",
      "epoch:26 step:24582 [D loss: 0.300077, acc.: 91.41%] [G loss: 1.298094]\n",
      "epoch:26 step:24583 [D loss: 0.336645, acc.: 85.94%] [G loss: 1.455551]\n",
      "epoch:26 step:24584 [D loss: 0.301486, acc.: 93.75%] [G loss: 1.812455]\n",
      "epoch:26 step:24585 [D loss: 0.243542, acc.: 96.88%] [G loss: 1.663490]\n",
      "epoch:26 step:24586 [D loss: 0.716549, acc.: 59.38%] [G loss: 1.615090]\n",
      "epoch:26 step:24587 [D loss: 0.820631, acc.: 44.53%] [G loss: 1.096941]\n",
      "epoch:26 step:24588 [D loss: 0.407441, acc.: 85.16%] [G loss: 1.298372]\n",
      "epoch:26 step:24589 [D loss: 0.554119, acc.: 73.44%] [G loss: 1.023385]\n",
      "epoch:26 step:24590 [D loss: 0.681561, acc.: 56.25%] [G loss: 1.117872]\n",
      "epoch:26 step:24591 [D loss: 0.471703, acc.: 82.03%] [G loss: 1.270348]\n",
      "epoch:26 step:24592 [D loss: 0.216704, acc.: 93.75%] [G loss: 1.378615]\n",
      "epoch:26 step:24593 [D loss: 0.317806, acc.: 88.28%] [G loss: 1.184445]\n",
      "epoch:26 step:24594 [D loss: 0.290237, acc.: 93.75%] [G loss: 1.583344]\n",
      "epoch:26 step:24595 [D loss: 0.919552, acc.: 48.44%] [G loss: 1.383719]\n",
      "epoch:26 step:24596 [D loss: 0.575733, acc.: 66.41%] [G loss: 1.348783]\n",
      "epoch:26 step:24597 [D loss: 0.722924, acc.: 60.16%] [G loss: 0.837931]\n",
      "epoch:26 step:24598 [D loss: 0.650404, acc.: 57.03%] [G loss: 1.205381]\n",
      "epoch:26 step:24599 [D loss: 0.712026, acc.: 52.34%] [G loss: 1.151256]\n",
      "epoch:26 step:24600 [D loss: 0.592299, acc.: 69.53%] [G loss: 1.232421]\n",
      "##############\n",
      "[2.48034529 1.72720674 5.42841723 4.25827749 2.97256577 5.5629338\n",
      " 4.25230603 4.79690813 4.19443777 3.941025  ]\n",
      "##########\n",
      "epoch:26 step:24601 [D loss: 0.771026, acc.: 53.91%] [G loss: 1.030517]\n",
      "epoch:26 step:24602 [D loss: 0.768158, acc.: 49.22%] [G loss: 0.941712]\n",
      "epoch:26 step:24603 [D loss: 1.164844, acc.: 14.84%] [G loss: 0.811733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24604 [D loss: 0.803006, acc.: 42.19%] [G loss: 1.013450]\n",
      "epoch:26 step:24605 [D loss: 0.678436, acc.: 53.12%] [G loss: 1.317995]\n",
      "epoch:26 step:24606 [D loss: 0.713099, acc.: 60.94%] [G loss: 1.403579]\n",
      "epoch:26 step:24607 [D loss: 0.576103, acc.: 70.31%] [G loss: 0.948406]\n",
      "epoch:26 step:24608 [D loss: 0.752167, acc.: 50.00%] [G loss: 1.322724]\n",
      "epoch:26 step:24609 [D loss: 0.628725, acc.: 62.50%] [G loss: 1.180994]\n",
      "epoch:26 step:24610 [D loss: 0.564921, acc.: 72.66%] [G loss: 1.244851]\n",
      "epoch:26 step:24611 [D loss: 0.668643, acc.: 59.38%] [G loss: 1.244775]\n",
      "epoch:26 step:24612 [D loss: 0.548069, acc.: 77.34%] [G loss: 0.987257]\n",
      "epoch:26 step:24613 [D loss: 0.691935, acc.: 52.34%] [G loss: 1.191759]\n",
      "epoch:26 step:24614 [D loss: 0.674111, acc.: 57.03%] [G loss: 1.046997]\n",
      "epoch:26 step:24615 [D loss: 0.600426, acc.: 66.41%] [G loss: 1.057158]\n",
      "epoch:26 step:24616 [D loss: 0.648651, acc.: 59.38%] [G loss: 0.836588]\n",
      "epoch:26 step:24617 [D loss: 0.599573, acc.: 69.53%] [G loss: 0.945168]\n",
      "epoch:26 step:24618 [D loss: 0.617208, acc.: 64.84%] [G loss: 1.022778]\n",
      "epoch:26 step:24619 [D loss: 0.629083, acc.: 60.94%] [G loss: 1.087818]\n",
      "epoch:26 step:24620 [D loss: 0.636021, acc.: 60.94%] [G loss: 1.280393]\n",
      "epoch:26 step:24621 [D loss: 0.562975, acc.: 73.44%] [G loss: 1.068799]\n",
      "epoch:26 step:24622 [D loss: 0.435663, acc.: 89.06%] [G loss: 1.150557]\n",
      "epoch:26 step:24623 [D loss: 0.502424, acc.: 78.91%] [G loss: 0.906291]\n",
      "epoch:26 step:24624 [D loss: 0.492438, acc.: 82.81%] [G loss: 1.272379]\n",
      "epoch:26 step:24625 [D loss: 0.451783, acc.: 87.50%] [G loss: 1.347054]\n",
      "epoch:26 step:24626 [D loss: 0.391797, acc.: 88.28%] [G loss: 1.346804]\n",
      "epoch:26 step:24627 [D loss: 0.624108, acc.: 66.41%] [G loss: 1.258888]\n",
      "epoch:26 step:24628 [D loss: 0.673349, acc.: 58.59%] [G loss: 1.008348]\n",
      "epoch:26 step:24629 [D loss: 0.620659, acc.: 64.84%] [G loss: 1.093448]\n",
      "epoch:26 step:24630 [D loss: 0.775447, acc.: 50.78%] [G loss: 1.115969]\n",
      "epoch:26 step:24631 [D loss: 0.456763, acc.: 82.03%] [G loss: 1.082657]\n",
      "epoch:26 step:24632 [D loss: 0.489894, acc.: 81.25%] [G loss: 1.302464]\n",
      "epoch:26 step:24633 [D loss: 0.442962, acc.: 86.72%] [G loss: 1.309647]\n",
      "epoch:26 step:24634 [D loss: 0.396219, acc.: 86.72%] [G loss: 1.187657]\n",
      "epoch:26 step:24635 [D loss: 0.431041, acc.: 91.41%] [G loss: 1.310212]\n",
      "epoch:26 step:24636 [D loss: 0.604595, acc.: 64.06%] [G loss: 1.144916]\n",
      "epoch:26 step:24637 [D loss: 0.524541, acc.: 78.12%] [G loss: 1.331609]\n",
      "epoch:26 step:24638 [D loss: 0.681542, acc.: 60.94%] [G loss: 1.279946]\n",
      "epoch:26 step:24639 [D loss: 0.870195, acc.: 35.94%] [G loss: 0.913315]\n",
      "epoch:26 step:24640 [D loss: 0.773146, acc.: 53.91%] [G loss: 0.813838]\n",
      "epoch:26 step:24641 [D loss: 0.407088, acc.: 80.47%] [G loss: 1.418711]\n",
      "epoch:26 step:24642 [D loss: 0.419435, acc.: 86.72%] [G loss: 1.566602]\n",
      "epoch:26 step:24643 [D loss: 0.677160, acc.: 58.59%] [G loss: 1.263242]\n",
      "epoch:26 step:24644 [D loss: 0.571574, acc.: 72.66%] [G loss: 1.284365]\n",
      "epoch:26 step:24645 [D loss: 0.700875, acc.: 58.59%] [G loss: 1.146807]\n",
      "epoch:26 step:24646 [D loss: 0.508199, acc.: 80.47%] [G loss: 1.234882]\n",
      "epoch:26 step:24647 [D loss: 0.504018, acc.: 81.25%] [G loss: 1.172843]\n",
      "epoch:26 step:24648 [D loss: 0.484360, acc.: 75.78%] [G loss: 1.187780]\n",
      "epoch:26 step:24649 [D loss: 0.597429, acc.: 66.41%] [G loss: 1.084795]\n",
      "epoch:26 step:24650 [D loss: 0.692396, acc.: 57.03%] [G loss: 0.938875]\n",
      "epoch:26 step:24651 [D loss: 0.441182, acc.: 84.38%] [G loss: 1.445455]\n",
      "epoch:26 step:24652 [D loss: 0.700296, acc.: 59.38%] [G loss: 0.985548]\n",
      "epoch:26 step:24653 [D loss: 0.421378, acc.: 80.47%] [G loss: 1.154556]\n",
      "epoch:26 step:24654 [D loss: 0.526394, acc.: 75.78%] [G loss: 1.135134]\n",
      "epoch:26 step:24655 [D loss: 0.326554, acc.: 95.31%] [G loss: 1.693333]\n",
      "epoch:26 step:24656 [D loss: 0.557946, acc.: 69.53%] [G loss: 1.135528]\n",
      "epoch:26 step:24657 [D loss: 0.737630, acc.: 49.22%] [G loss: 1.113522]\n",
      "epoch:26 step:24658 [D loss: 0.876497, acc.: 46.88%] [G loss: 1.023676]\n",
      "epoch:26 step:24659 [D loss: 0.695312, acc.: 54.69%] [G loss: 1.106320]\n",
      "epoch:26 step:24660 [D loss: 0.362873, acc.: 92.19%] [G loss: 1.165654]\n",
      "epoch:26 step:24661 [D loss: 0.523559, acc.: 79.69%] [G loss: 1.023891]\n",
      "epoch:26 step:24662 [D loss: 0.538791, acc.: 77.34%] [G loss: 1.282819]\n",
      "epoch:26 step:24663 [D loss: 0.864931, acc.: 38.28%] [G loss: 0.955890]\n",
      "epoch:26 step:24664 [D loss: 0.556754, acc.: 73.44%] [G loss: 0.918246]\n",
      "epoch:26 step:24665 [D loss: 0.542851, acc.: 71.88%] [G loss: 1.147668]\n",
      "epoch:26 step:24666 [D loss: 0.637174, acc.: 63.28%] [G loss: 0.938482]\n",
      "epoch:26 step:24667 [D loss: 0.571872, acc.: 71.09%] [G loss: 0.822100]\n",
      "epoch:26 step:24668 [D loss: 0.639901, acc.: 62.50%] [G loss: 1.276992]\n",
      "epoch:26 step:24669 [D loss: 0.633704, acc.: 62.50%] [G loss: 1.177032]\n",
      "epoch:26 step:24670 [D loss: 0.504647, acc.: 75.78%] [G loss: 0.995768]\n",
      "epoch:26 step:24671 [D loss: 0.444898, acc.: 86.72%] [G loss: 1.291558]\n",
      "epoch:26 step:24672 [D loss: 0.577601, acc.: 68.75%] [G loss: 1.011233]\n",
      "epoch:26 step:24673 [D loss: 0.558348, acc.: 71.88%] [G loss: 1.314244]\n",
      "epoch:26 step:24674 [D loss: 0.321011, acc.: 93.75%] [G loss: 1.196447]\n",
      "epoch:26 step:24675 [D loss: 0.308721, acc.: 94.53%] [G loss: 1.302124]\n",
      "epoch:26 step:24676 [D loss: 0.377666, acc.: 85.94%] [G loss: 1.499297]\n",
      "epoch:26 step:24677 [D loss: 0.379903, acc.: 87.50%] [G loss: 1.814484]\n",
      "epoch:26 step:24678 [D loss: 0.933158, acc.: 41.41%] [G loss: 1.157533]\n",
      "epoch:26 step:24679 [D loss: 0.877484, acc.: 43.75%] [G loss: 1.336208]\n",
      "epoch:26 step:24680 [D loss: 0.578418, acc.: 72.66%] [G loss: 1.248043]\n",
      "epoch:26 step:24681 [D loss: 0.540881, acc.: 75.78%] [G loss: 1.235129]\n",
      "epoch:26 step:24682 [D loss: 0.494967, acc.: 84.38%] [G loss: 1.101810]\n",
      "epoch:26 step:24683 [D loss: 0.436498, acc.: 83.59%] [G loss: 1.325707]\n",
      "epoch:26 step:24684 [D loss: 0.496742, acc.: 80.47%] [G loss: 1.186375]\n",
      "epoch:26 step:24685 [D loss: 0.727689, acc.: 53.12%] [G loss: 1.161887]\n",
      "epoch:26 step:24686 [D loss: 0.773365, acc.: 45.31%] [G loss: 0.723357]\n",
      "epoch:26 step:24687 [D loss: 0.622996, acc.: 60.16%] [G loss: 0.793393]\n",
      "epoch:26 step:24688 [D loss: 0.616144, acc.: 66.41%] [G loss: 1.180855]\n",
      "epoch:26 step:24689 [D loss: 0.326769, acc.: 93.75%] [G loss: 1.440606]\n",
      "epoch:26 step:24690 [D loss: 0.295804, acc.: 96.09%] [G loss: 1.700887]\n",
      "epoch:26 step:24691 [D loss: 0.548223, acc.: 74.22%] [G loss: 1.285469]\n",
      "epoch:26 step:24692 [D loss: 0.664096, acc.: 61.72%] [G loss: 1.425156]\n",
      "epoch:26 step:24693 [D loss: 0.812866, acc.: 42.97%] [G loss: 0.881883]\n",
      "epoch:26 step:24694 [D loss: 0.708099, acc.: 54.69%] [G loss: 0.819499]\n",
      "epoch:26 step:24695 [D loss: 0.677407, acc.: 54.69%] [G loss: 1.196892]\n",
      "epoch:26 step:24696 [D loss: 0.663382, acc.: 55.47%] [G loss: 1.132050]\n",
      "epoch:26 step:24697 [D loss: 0.701357, acc.: 54.69%] [G loss: 0.955626]\n",
      "epoch:26 step:24698 [D loss: 0.728766, acc.: 57.03%] [G loss: 0.840231]\n",
      "epoch:26 step:24699 [D loss: 0.561993, acc.: 72.66%] [G loss: 1.318555]\n",
      "epoch:26 step:24700 [D loss: 0.482850, acc.: 80.47%] [G loss: 1.280765]\n",
      "epoch:26 step:24701 [D loss: 0.608990, acc.: 63.28%] [G loss: 0.872083]\n",
      "epoch:26 step:24702 [D loss: 0.515578, acc.: 77.34%] [G loss: 1.217108]\n",
      "epoch:26 step:24703 [D loss: 0.707901, acc.: 57.03%] [G loss: 1.260459]\n",
      "epoch:26 step:24704 [D loss: 0.639098, acc.: 67.19%] [G loss: 0.860376]\n",
      "epoch:26 step:24705 [D loss: 0.386950, acc.: 82.81%] [G loss: 0.991137]\n",
      "epoch:26 step:24706 [D loss: 0.545128, acc.: 71.09%] [G loss: 1.263429]\n",
      "epoch:26 step:24707 [D loss: 0.309913, acc.: 91.41%] [G loss: 1.291530]\n",
      "epoch:26 step:24708 [D loss: 0.210947, acc.: 96.88%] [G loss: 1.462956]\n",
      "epoch:26 step:24709 [D loss: 0.249425, acc.: 96.09%] [G loss: 1.742673]\n",
      "epoch:26 step:24710 [D loss: 0.795218, acc.: 51.56%] [G loss: 1.319310]\n",
      "epoch:26 step:24711 [D loss: 0.887760, acc.: 36.72%] [G loss: 1.123966]\n",
      "epoch:26 step:24712 [D loss: 0.696281, acc.: 54.69%] [G loss: 1.027998]\n",
      "epoch:26 step:24713 [D loss: 0.360021, acc.: 90.62%] [G loss: 0.899370]\n",
      "epoch:26 step:24714 [D loss: 0.369113, acc.: 93.75%] [G loss: 1.424722]\n",
      "epoch:26 step:24715 [D loss: 0.525184, acc.: 75.00%] [G loss: 1.090303]\n",
      "epoch:26 step:24716 [D loss: 0.390164, acc.: 89.84%] [G loss: 1.296677]\n",
      "epoch:26 step:24717 [D loss: 0.707278, acc.: 56.25%] [G loss: 1.204986]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24718 [D loss: 0.638601, acc.: 64.84%] [G loss: 0.795670]\n",
      "epoch:26 step:24719 [D loss: 0.780659, acc.: 47.66%] [G loss: 0.990282]\n",
      "epoch:26 step:24720 [D loss: 0.462622, acc.: 81.25%] [G loss: 1.194739]\n",
      "epoch:26 step:24721 [D loss: 0.529821, acc.: 78.91%] [G loss: 1.338842]\n",
      "epoch:26 step:24722 [D loss: 0.622018, acc.: 59.38%] [G loss: 1.217193]\n",
      "epoch:26 step:24723 [D loss: 0.767144, acc.: 48.44%] [G loss: 0.752387]\n",
      "epoch:26 step:24724 [D loss: 1.009122, acc.: 25.00%] [G loss: 0.710125]\n",
      "epoch:26 step:24725 [D loss: 0.603231, acc.: 71.09%] [G loss: 1.169768]\n",
      "epoch:26 step:24726 [D loss: 0.629136, acc.: 59.38%] [G loss: 1.106256]\n",
      "epoch:26 step:24727 [D loss: 0.496165, acc.: 81.25%] [G loss: 1.065003]\n",
      "epoch:26 step:24728 [D loss: 0.269269, acc.: 91.41%] [G loss: 1.630726]\n",
      "epoch:26 step:24729 [D loss: 0.205340, acc.: 100.00%] [G loss: 1.907157]\n",
      "epoch:26 step:24730 [D loss: 0.589582, acc.: 71.88%] [G loss: 1.228423]\n",
      "epoch:26 step:24731 [D loss: 0.786149, acc.: 46.88%] [G loss: 1.331400]\n",
      "epoch:26 step:24732 [D loss: 0.651423, acc.: 63.28%] [G loss: 1.356895]\n",
      "epoch:26 step:24733 [D loss: 0.575200, acc.: 70.31%] [G loss: 1.015206]\n",
      "epoch:26 step:24734 [D loss: 0.660274, acc.: 57.81%] [G loss: 1.088674]\n",
      "epoch:26 step:24735 [D loss: 0.757666, acc.: 51.56%] [G loss: 0.767783]\n",
      "epoch:26 step:24736 [D loss: 0.566041, acc.: 69.53%] [G loss: 0.952583]\n",
      "epoch:26 step:24737 [D loss: 0.734159, acc.: 53.12%] [G loss: 1.078600]\n",
      "epoch:26 step:24738 [D loss: 0.585691, acc.: 75.00%] [G loss: 1.206407]\n",
      "epoch:26 step:24739 [D loss: 0.327116, acc.: 92.97%] [G loss: 1.384527]\n",
      "epoch:26 step:24740 [D loss: 0.221264, acc.: 95.31%] [G loss: 1.202572]\n",
      "epoch:26 step:24741 [D loss: 0.750237, acc.: 53.12%] [G loss: 1.296549]\n",
      "epoch:26 step:24742 [D loss: 0.783425, acc.: 45.31%] [G loss: 1.173206]\n",
      "epoch:26 step:24743 [D loss: 0.678839, acc.: 62.50%] [G loss: 1.059582]\n",
      "epoch:26 step:24744 [D loss: 0.686367, acc.: 57.03%] [G loss: 1.083327]\n",
      "epoch:26 step:24745 [D loss: 0.683512, acc.: 59.38%] [G loss: 1.043222]\n",
      "epoch:26 step:24746 [D loss: 0.554297, acc.: 75.00%] [G loss: 0.841557]\n",
      "epoch:26 step:24747 [D loss: 0.732663, acc.: 54.69%] [G loss: 0.871867]\n",
      "epoch:26 step:24748 [D loss: 0.722141, acc.: 57.81%] [G loss: 0.973719]\n",
      "epoch:26 step:24749 [D loss: 0.752305, acc.: 48.44%] [G loss: 0.912497]\n",
      "epoch:26 step:24750 [D loss: 0.522936, acc.: 76.56%] [G loss: 1.209255]\n",
      "epoch:26 step:24751 [D loss: 0.587650, acc.: 72.66%] [G loss: 1.115695]\n",
      "epoch:26 step:24752 [D loss: 0.514799, acc.: 78.12%] [G loss: 1.097195]\n",
      "epoch:26 step:24753 [D loss: 0.646614, acc.: 60.16%] [G loss: 0.999410]\n",
      "epoch:26 step:24754 [D loss: 0.667304, acc.: 51.56%] [G loss: 0.934968]\n",
      "epoch:26 step:24755 [D loss: 0.700488, acc.: 55.47%] [G loss: 0.712072]\n",
      "epoch:26 step:24756 [D loss: 0.647642, acc.: 65.62%] [G loss: 1.101220]\n",
      "epoch:26 step:24757 [D loss: 0.546228, acc.: 69.53%] [G loss: 1.165267]\n",
      "epoch:26 step:24758 [D loss: 0.346445, acc.: 86.72%] [G loss: 1.199624]\n",
      "epoch:26 step:24759 [D loss: 0.263976, acc.: 91.41%] [G loss: 1.339954]\n",
      "epoch:26 step:24760 [D loss: 0.223487, acc.: 98.44%] [G loss: 1.579917]\n",
      "epoch:26 step:24761 [D loss: 0.286223, acc.: 96.09%] [G loss: 1.418260]\n",
      "epoch:26 step:24762 [D loss: 0.363912, acc.: 90.62%] [G loss: 1.426257]\n",
      "epoch:26 step:24763 [D loss: 0.369576, acc.: 90.62%] [G loss: 1.467378]\n",
      "epoch:26 step:24764 [D loss: 0.300931, acc.: 92.97%] [G loss: 1.852939]\n",
      "epoch:26 step:24765 [D loss: 0.869326, acc.: 46.09%] [G loss: 1.036377]\n",
      "epoch:26 step:24766 [D loss: 0.295594, acc.: 92.97%] [G loss: 1.690542]\n",
      "epoch:26 step:24767 [D loss: 0.313232, acc.: 91.41%] [G loss: 1.724363]\n",
      "epoch:26 step:24768 [D loss: 0.345219, acc.: 90.62%] [G loss: 1.573689]\n",
      "epoch:26 step:24769 [D loss: 0.710719, acc.: 51.56%] [G loss: 0.911277]\n",
      "epoch:26 step:24770 [D loss: 0.696273, acc.: 55.47%] [G loss: 1.008898]\n",
      "epoch:26 step:24771 [D loss: 0.677001, acc.: 63.28%] [G loss: 1.157120]\n",
      "epoch:26 step:24772 [D loss: 1.031675, acc.: 40.62%] [G loss: 0.634631]\n",
      "epoch:26 step:24773 [D loss: 0.842635, acc.: 50.00%] [G loss: 1.114105]\n",
      "epoch:26 step:24774 [D loss: 0.764281, acc.: 48.44%] [G loss: 0.846169]\n",
      "epoch:26 step:24775 [D loss: 1.405554, acc.: 14.84%] [G loss: 0.527639]\n",
      "epoch:26 step:24776 [D loss: 0.949851, acc.: 42.97%] [G loss: 0.671900]\n",
      "epoch:26 step:24777 [D loss: 0.982727, acc.: 37.50%] [G loss: 0.879785]\n",
      "epoch:26 step:24778 [D loss: 0.827704, acc.: 43.75%] [G loss: 0.759567]\n",
      "epoch:26 step:24779 [D loss: 1.174720, acc.: 28.12%] [G loss: 0.654178]\n",
      "epoch:26 step:24780 [D loss: 0.758773, acc.: 53.91%] [G loss: 1.092123]\n",
      "epoch:26 step:24781 [D loss: 0.575016, acc.: 67.19%] [G loss: 1.456950]\n",
      "epoch:26 step:24782 [D loss: 0.810992, acc.: 47.66%] [G loss: 1.525168]\n",
      "epoch:26 step:24783 [D loss: 0.953036, acc.: 33.59%] [G loss: 1.049800]\n",
      "epoch:26 step:24784 [D loss: 0.921163, acc.: 45.31%] [G loss: 1.628823]\n",
      "epoch:26 step:24785 [D loss: 0.617779, acc.: 65.62%] [G loss: 1.147387]\n",
      "epoch:26 step:24786 [D loss: 0.629203, acc.: 63.28%] [G loss: 1.244317]\n",
      "epoch:26 step:24787 [D loss: 0.680154, acc.: 58.59%] [G loss: 1.297771]\n",
      "epoch:26 step:24788 [D loss: 0.712900, acc.: 60.94%] [G loss: 1.241120]\n",
      "epoch:26 step:24789 [D loss: 0.724910, acc.: 54.69%] [G loss: 1.115911]\n",
      "epoch:26 step:24790 [D loss: 0.529435, acc.: 75.78%] [G loss: 1.391147]\n",
      "epoch:26 step:24791 [D loss: 0.649818, acc.: 60.94%] [G loss: 1.105797]\n",
      "epoch:26 step:24792 [D loss: 0.733733, acc.: 54.69%] [G loss: 0.902333]\n",
      "epoch:26 step:24793 [D loss: 0.537153, acc.: 75.78%] [G loss: 1.396347]\n",
      "epoch:26 step:24794 [D loss: 0.384960, acc.: 91.41%] [G loss: 1.466241]\n",
      "epoch:26 step:24795 [D loss: 0.438700, acc.: 82.03%] [G loss: 1.309769]\n",
      "epoch:26 step:24796 [D loss: 0.461912, acc.: 80.47%] [G loss: 1.514592]\n",
      "epoch:26 step:24797 [D loss: 0.563341, acc.: 69.53%] [G loss: 1.057566]\n",
      "epoch:26 step:24798 [D loss: 0.439670, acc.: 81.25%] [G loss: 1.558611]\n",
      "epoch:26 step:24799 [D loss: 0.624365, acc.: 63.28%] [G loss: 1.641668]\n",
      "epoch:26 step:24800 [D loss: 0.796870, acc.: 47.66%] [G loss: 0.822595]\n",
      "##############\n",
      "[2.51874571 1.7823217  5.32701668 4.58872693 3.15677485 5.28638911\n",
      " 4.05391813 4.56633891 4.01404732 3.47318716]\n",
      "##########\n",
      "epoch:26 step:24801 [D loss: 0.590429, acc.: 66.41%] [G loss: 1.163152]\n",
      "epoch:26 step:24802 [D loss: 0.688725, acc.: 54.69%] [G loss: 1.121603]\n",
      "epoch:26 step:24803 [D loss: 0.731921, acc.: 54.69%] [G loss: 0.914096]\n",
      "epoch:26 step:24804 [D loss: 0.778908, acc.: 50.00%] [G loss: 0.895267]\n",
      "epoch:26 step:24805 [D loss: 0.627617, acc.: 64.06%] [G loss: 1.088286]\n",
      "epoch:26 step:24806 [D loss: 0.656365, acc.: 64.84%] [G loss: 1.398471]\n",
      "epoch:26 step:24807 [D loss: 0.722740, acc.: 58.59%] [G loss: 1.284830]\n",
      "epoch:26 step:24808 [D loss: 0.809879, acc.: 48.44%] [G loss: 0.939834]\n",
      "epoch:26 step:24809 [D loss: 0.673012, acc.: 61.72%] [G loss: 0.986823]\n",
      "epoch:26 step:24810 [D loss: 0.667499, acc.: 61.72%] [G loss: 1.029127]\n",
      "epoch:26 step:24811 [D loss: 0.495251, acc.: 73.44%] [G loss: 1.321894]\n",
      "epoch:26 step:24812 [D loss: 0.688682, acc.: 58.59%] [G loss: 1.219851]\n",
      "epoch:26 step:24813 [D loss: 0.583138, acc.: 67.97%] [G loss: 1.280061]\n",
      "epoch:26 step:24814 [D loss: 0.502045, acc.: 76.56%] [G loss: 1.347241]\n",
      "epoch:26 step:24815 [D loss: 0.537776, acc.: 71.09%] [G loss: 1.295541]\n",
      "epoch:26 step:24816 [D loss: 0.533858, acc.: 71.88%] [G loss: 1.092573]\n",
      "epoch:26 step:24817 [D loss: 0.679593, acc.: 60.16%] [G loss: 1.204059]\n",
      "epoch:26 step:24818 [D loss: 0.491445, acc.: 77.34%] [G loss: 1.314797]\n",
      "epoch:26 step:24819 [D loss: 0.483040, acc.: 83.59%] [G loss: 1.198441]\n",
      "epoch:26 step:24820 [D loss: 0.855269, acc.: 45.31%] [G loss: 1.218707]\n",
      "epoch:26 step:24821 [D loss: 0.918008, acc.: 36.72%] [G loss: 0.958182]\n",
      "epoch:26 step:24822 [D loss: 1.096365, acc.: 18.75%] [G loss: 0.893408]\n",
      "epoch:26 step:24823 [D loss: 0.866810, acc.: 42.19%] [G loss: 0.813790]\n",
      "epoch:26 step:24824 [D loss: 0.644207, acc.: 64.06%] [G loss: 1.263746]\n",
      "epoch:26 step:24825 [D loss: 0.772761, acc.: 53.91%] [G loss: 1.210372]\n",
      "epoch:26 step:24826 [D loss: 0.520748, acc.: 76.56%] [G loss: 1.058681]\n",
      "epoch:26 step:24827 [D loss: 0.712755, acc.: 52.34%] [G loss: 0.966779]\n",
      "epoch:26 step:24828 [D loss: 0.596158, acc.: 74.22%] [G loss: 0.928710]\n",
      "epoch:26 step:24829 [D loss: 0.587779, acc.: 68.75%] [G loss: 1.038930]\n",
      "epoch:26 step:24830 [D loss: 0.389307, acc.: 89.06%] [G loss: 1.228160]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24831 [D loss: 0.410239, acc.: 89.84%] [G loss: 1.258868]\n",
      "epoch:26 step:24832 [D loss: 0.303255, acc.: 93.75%] [G loss: 1.348506]\n",
      "epoch:26 step:24833 [D loss: 0.274823, acc.: 91.41%] [G loss: 1.540488]\n",
      "epoch:26 step:24834 [D loss: 0.448332, acc.: 84.38%] [G loss: 1.624638]\n",
      "epoch:26 step:24835 [D loss: 0.683176, acc.: 60.94%] [G loss: 1.762448]\n",
      "epoch:26 step:24836 [D loss: 0.449029, acc.: 86.72%] [G loss: 1.297347]\n",
      "epoch:26 step:24837 [D loss: 0.379401, acc.: 91.41%] [G loss: 1.323425]\n",
      "epoch:26 step:24838 [D loss: 0.569496, acc.: 67.19%] [G loss: 1.317131]\n",
      "epoch:26 step:24839 [D loss: 0.729587, acc.: 52.34%] [G loss: 1.104187]\n",
      "epoch:26 step:24840 [D loss: 0.672768, acc.: 57.81%] [G loss: 1.051585]\n",
      "epoch:26 step:24841 [D loss: 0.406876, acc.: 84.38%] [G loss: 0.936674]\n",
      "epoch:26 step:24842 [D loss: 0.610925, acc.: 63.28%] [G loss: 1.129097]\n",
      "epoch:26 step:24843 [D loss: 0.466427, acc.: 80.47%] [G loss: 1.248095]\n",
      "epoch:26 step:24844 [D loss: 0.728822, acc.: 50.00%] [G loss: 1.029294]\n",
      "epoch:26 step:24845 [D loss: 0.491932, acc.: 78.91%] [G loss: 1.431948]\n",
      "epoch:26 step:24846 [D loss: 0.286378, acc.: 94.53%] [G loss: 1.699474]\n",
      "epoch:26 step:24847 [D loss: 0.365837, acc.: 93.75%] [G loss: 1.630159]\n",
      "epoch:26 step:24848 [D loss: 0.505859, acc.: 78.12%] [G loss: 1.203426]\n",
      "epoch:26 step:24849 [D loss: 0.387138, acc.: 89.06%] [G loss: 1.580089]\n",
      "epoch:26 step:24850 [D loss: 0.476386, acc.: 84.38%] [G loss: 1.429830]\n",
      "epoch:26 step:24851 [D loss: 0.845496, acc.: 44.53%] [G loss: 1.059892]\n",
      "epoch:26 step:24852 [D loss: 0.510589, acc.: 77.34%] [G loss: 1.304435]\n",
      "epoch:26 step:24853 [D loss: 0.642390, acc.: 67.97%] [G loss: 1.324174]\n",
      "epoch:26 step:24854 [D loss: 0.707120, acc.: 53.91%] [G loss: 1.041650]\n",
      "epoch:26 step:24855 [D loss: 0.736403, acc.: 52.34%] [G loss: 0.914310]\n",
      "epoch:26 step:24856 [D loss: 0.626410, acc.: 66.41%] [G loss: 0.969295]\n",
      "epoch:26 step:24857 [D loss: 0.602429, acc.: 70.31%] [G loss: 0.998917]\n",
      "epoch:26 step:24858 [D loss: 0.620576, acc.: 63.28%] [G loss: 1.030100]\n",
      "epoch:26 step:24859 [D loss: 0.413526, acc.: 83.59%] [G loss: 1.137610]\n",
      "epoch:26 step:24860 [D loss: 0.455339, acc.: 84.38%] [G loss: 1.031341]\n",
      "epoch:26 step:24861 [D loss: 0.288706, acc.: 96.09%] [G loss: 1.592333]\n",
      "epoch:26 step:24862 [D loss: 0.840076, acc.: 46.88%] [G loss: 1.486960]\n",
      "epoch:26 step:24863 [D loss: 0.943759, acc.: 36.72%] [G loss: 1.217306]\n",
      "epoch:26 step:24864 [D loss: 0.809516, acc.: 39.84%] [G loss: 1.228325]\n",
      "epoch:26 step:24865 [D loss: 0.430841, acc.: 78.12%] [G loss: 1.017142]\n",
      "epoch:26 step:24866 [D loss: 0.261807, acc.: 97.66%] [G loss: 1.372560]\n",
      "epoch:26 step:24867 [D loss: 0.469838, acc.: 80.47%] [G loss: 1.508189]\n",
      "epoch:26 step:24868 [D loss: 0.560434, acc.: 75.78%] [G loss: 1.410916]\n",
      "epoch:26 step:24869 [D loss: 0.462178, acc.: 83.59%] [G loss: 1.410178]\n",
      "epoch:26 step:24870 [D loss: 0.260210, acc.: 93.75%] [G loss: 1.396792]\n",
      "epoch:26 step:24871 [D loss: 0.689368, acc.: 52.34%] [G loss: 1.151255]\n",
      "epoch:26 step:24872 [D loss: 0.659043, acc.: 57.81%] [G loss: 1.026315]\n",
      "epoch:26 step:24873 [D loss: 0.302823, acc.: 92.97%] [G loss: 1.294452]\n",
      "epoch:26 step:24874 [D loss: 0.345964, acc.: 94.53%] [G loss: 1.505448]\n",
      "epoch:26 step:24875 [D loss: 0.371537, acc.: 85.94%] [G loss: 1.533726]\n",
      "epoch:26 step:24876 [D loss: 0.433543, acc.: 86.72%] [G loss: 1.340043]\n",
      "epoch:26 step:24877 [D loss: 0.387925, acc.: 88.28%] [G loss: 1.623041]\n",
      "epoch:26 step:24878 [D loss: 0.632518, acc.: 63.28%] [G loss: 1.200377]\n",
      "epoch:26 step:24879 [D loss: 0.618957, acc.: 69.53%] [G loss: 1.221625]\n",
      "epoch:26 step:24880 [D loss: 0.451715, acc.: 88.28%] [G loss: 1.334406]\n",
      "epoch:26 step:24881 [D loss: 0.386976, acc.: 90.62%] [G loss: 1.416634]\n",
      "epoch:26 step:24882 [D loss: 0.503733, acc.: 78.12%] [G loss: 1.271498]\n",
      "epoch:26 step:24883 [D loss: 0.518127, acc.: 77.34%] [G loss: 1.154666]\n",
      "epoch:26 step:24884 [D loss: 0.554062, acc.: 73.44%] [G loss: 1.123108]\n",
      "epoch:26 step:24885 [D loss: 0.451065, acc.: 83.59%] [G loss: 1.097683]\n",
      "epoch:26 step:24886 [D loss: 0.534578, acc.: 77.34%] [G loss: 1.586570]\n",
      "epoch:26 step:24887 [D loss: 0.696586, acc.: 57.03%] [G loss: 1.186999]\n",
      "epoch:26 step:24888 [D loss: 0.411518, acc.: 82.81%] [G loss: 1.285711]\n",
      "epoch:26 step:24889 [D loss: 0.535692, acc.: 74.22%] [G loss: 1.003215]\n",
      "epoch:26 step:24890 [D loss: 0.633897, acc.: 63.28%] [G loss: 0.874839]\n",
      "epoch:26 step:24891 [D loss: 0.656002, acc.: 58.59%] [G loss: 0.887779]\n",
      "epoch:26 step:24892 [D loss: 0.455598, acc.: 82.81%] [G loss: 1.359974]\n",
      "epoch:26 step:24893 [D loss: 0.691576, acc.: 57.03%] [G loss: 1.100337]\n",
      "epoch:26 step:24894 [D loss: 0.492012, acc.: 80.47%] [G loss: 1.209368]\n",
      "epoch:26 step:24895 [D loss: 0.589605, acc.: 68.75%] [G loss: 0.865708]\n",
      "epoch:26 step:24896 [D loss: 0.508181, acc.: 77.34%] [G loss: 1.019774]\n",
      "epoch:26 step:24897 [D loss: 0.397067, acc.: 85.94%] [G loss: 1.441854]\n",
      "epoch:26 step:24898 [D loss: 0.288980, acc.: 92.19%] [G loss: 1.367181]\n",
      "epoch:26 step:24899 [D loss: 0.393447, acc.: 90.62%] [G loss: 1.134851]\n",
      "epoch:26 step:24900 [D loss: 0.473106, acc.: 82.03%] [G loss: 1.711515]\n",
      "epoch:26 step:24901 [D loss: 0.499617, acc.: 78.12%] [G loss: 1.240861]\n",
      "epoch:26 step:24902 [D loss: 0.579091, acc.: 70.31%] [G loss: 1.127808]\n",
      "epoch:26 step:24903 [D loss: 0.631520, acc.: 64.84%] [G loss: 1.142480]\n",
      "epoch:26 step:24904 [D loss: 0.684186, acc.: 59.38%] [G loss: 0.964293]\n",
      "epoch:26 step:24905 [D loss: 0.657210, acc.: 58.59%] [G loss: 1.039119]\n",
      "epoch:26 step:24906 [D loss: 0.510898, acc.: 77.34%] [G loss: 1.036233]\n",
      "epoch:26 step:24907 [D loss: 0.467212, acc.: 82.03%] [G loss: 1.326347]\n",
      "epoch:26 step:24908 [D loss: 0.355852, acc.: 91.41%] [G loss: 1.466680]\n",
      "epoch:26 step:24909 [D loss: 0.291692, acc.: 97.66%] [G loss: 1.496376]\n",
      "epoch:26 step:24910 [D loss: 0.443407, acc.: 88.28%] [G loss: 1.252842]\n",
      "epoch:26 step:24911 [D loss: 0.240404, acc.: 99.22%] [G loss: 1.499525]\n",
      "epoch:26 step:24912 [D loss: 0.297521, acc.: 94.53%] [G loss: 1.540696]\n",
      "epoch:26 step:24913 [D loss: 0.267160, acc.: 96.88%] [G loss: 1.445471]\n",
      "epoch:26 step:24914 [D loss: 0.325249, acc.: 93.75%] [G loss: 1.607732]\n",
      "epoch:26 step:24915 [D loss: 0.360117, acc.: 90.62%] [G loss: 1.338911]\n",
      "epoch:26 step:24916 [D loss: 0.338231, acc.: 89.06%] [G loss: 1.648320]\n",
      "epoch:26 step:24917 [D loss: 0.313253, acc.: 92.97%] [G loss: 1.683474]\n",
      "epoch:26 step:24918 [D loss: 0.194250, acc.: 100.00%] [G loss: 2.044733]\n",
      "epoch:26 step:24919 [D loss: 0.221921, acc.: 98.44%] [G loss: 1.917112]\n",
      "epoch:26 step:24920 [D loss: 0.342686, acc.: 93.75%] [G loss: 1.804102]\n",
      "epoch:26 step:24921 [D loss: 0.921089, acc.: 39.06%] [G loss: 1.322071]\n",
      "epoch:26 step:24922 [D loss: 0.885650, acc.: 39.06%] [G loss: 1.044338]\n",
      "epoch:26 step:24923 [D loss: 0.337230, acc.: 92.19%] [G loss: 1.343588]\n",
      "epoch:26 step:24924 [D loss: 0.691638, acc.: 62.50%] [G loss: 1.183641]\n",
      "epoch:26 step:24925 [D loss: 0.604018, acc.: 67.97%] [G loss: 1.245690]\n",
      "epoch:26 step:24926 [D loss: 0.588170, acc.: 72.66%] [G loss: 0.834387]\n",
      "epoch:26 step:24927 [D loss: 0.537928, acc.: 74.22%] [G loss: 0.942088]\n",
      "epoch:26 step:24928 [D loss: 0.315841, acc.: 92.97%] [G loss: 1.356943]\n",
      "epoch:26 step:24929 [D loss: 0.440632, acc.: 79.69%] [G loss: 1.640172]\n",
      "epoch:26 step:24930 [D loss: 0.593340, acc.: 66.41%] [G loss: 1.510176]\n",
      "epoch:26 step:24931 [D loss: 0.797854, acc.: 51.56%] [G loss: 1.194818]\n",
      "epoch:26 step:24932 [D loss: 0.791784, acc.: 46.88%] [G loss: 0.892001]\n",
      "epoch:26 step:24933 [D loss: 0.596027, acc.: 71.09%] [G loss: 0.919842]\n",
      "epoch:26 step:24934 [D loss: 0.907182, acc.: 39.06%] [G loss: 0.930837]\n",
      "epoch:26 step:24935 [D loss: 0.549945, acc.: 71.09%] [G loss: 1.528302]\n",
      "epoch:26 step:24936 [D loss: 0.472413, acc.: 84.38%] [G loss: 1.200274]\n",
      "epoch:26 step:24937 [D loss: 0.567667, acc.: 68.75%] [G loss: 1.094630]\n",
      "epoch:26 step:24938 [D loss: 0.426863, acc.: 88.28%] [G loss: 1.255921]\n",
      "epoch:26 step:24939 [D loss: 0.557102, acc.: 73.44%] [G loss: 0.842723]\n",
      "epoch:26 step:24940 [D loss: 0.283173, acc.: 96.88%] [G loss: 1.611265]\n",
      "epoch:26 step:24941 [D loss: 0.586227, acc.: 69.53%] [G loss: 1.253768]\n",
      "epoch:26 step:24942 [D loss: 0.741324, acc.: 53.12%] [G loss: 0.686530]\n",
      "epoch:26 step:24943 [D loss: 0.771242, acc.: 50.78%] [G loss: 0.966186]\n",
      "epoch:26 step:24944 [D loss: 0.683925, acc.: 57.03%] [G loss: 1.270079]\n",
      "epoch:26 step:24945 [D loss: 0.636859, acc.: 63.28%] [G loss: 1.201596]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24946 [D loss: 0.681182, acc.: 57.81%] [G loss: 0.910891]\n",
      "epoch:26 step:24947 [D loss: 0.687192, acc.: 57.03%] [G loss: 0.991549]\n",
      "epoch:26 step:24948 [D loss: 0.769344, acc.: 52.34%] [G loss: 0.783863]\n",
      "epoch:26 step:24949 [D loss: 0.459820, acc.: 79.69%] [G loss: 1.399987]\n",
      "epoch:26 step:24950 [D loss: 0.350827, acc.: 88.28%] [G loss: 1.314510]\n",
      "epoch:26 step:24951 [D loss: 0.308160, acc.: 94.53%] [G loss: 1.623502]\n",
      "epoch:26 step:24952 [D loss: 0.871075, acc.: 44.53%] [G loss: 1.289435]\n",
      "epoch:26 step:24953 [D loss: 0.791826, acc.: 48.44%] [G loss: 1.221001]\n",
      "epoch:26 step:24954 [D loss: 0.540933, acc.: 73.44%] [G loss: 1.306664]\n",
      "epoch:26 step:24955 [D loss: 0.576520, acc.: 69.53%] [G loss: 1.277103]\n",
      "epoch:26 step:24956 [D loss: 0.590626, acc.: 69.53%] [G loss: 0.945269]\n",
      "epoch:26 step:24957 [D loss: 0.552598, acc.: 73.44%] [G loss: 1.242435]\n",
      "epoch:26 step:24958 [D loss: 0.622651, acc.: 66.41%] [G loss: 1.038936]\n",
      "epoch:26 step:24959 [D loss: 0.508401, acc.: 76.56%] [G loss: 1.132084]\n",
      "epoch:26 step:24960 [D loss: 0.340089, acc.: 88.28%] [G loss: 1.394021]\n",
      "epoch:26 step:24961 [D loss: 0.598299, acc.: 66.41%] [G loss: 0.997504]\n",
      "epoch:26 step:24962 [D loss: 0.758853, acc.: 54.69%] [G loss: 1.205185]\n",
      "epoch:26 step:24963 [D loss: 0.585436, acc.: 70.31%] [G loss: 1.233086]\n",
      "epoch:26 step:24964 [D loss: 0.743384, acc.: 49.22%] [G loss: 0.955001]\n",
      "epoch:26 step:24965 [D loss: 0.322751, acc.: 96.09%] [G loss: 1.169378]\n",
      "epoch:26 step:24966 [D loss: 0.298620, acc.: 93.75%] [G loss: 1.463419]\n",
      "epoch:26 step:24967 [D loss: 0.354092, acc.: 89.84%] [G loss: 1.476140]\n",
      "epoch:26 step:24968 [D loss: 0.608786, acc.: 68.75%] [G loss: 1.559729]\n",
      "epoch:26 step:24969 [D loss: 0.656032, acc.: 60.16%] [G loss: 1.191988]\n",
      "epoch:26 step:24970 [D loss: 0.579438, acc.: 71.09%] [G loss: 1.119622]\n",
      "epoch:26 step:24971 [D loss: 0.648885, acc.: 65.62%] [G loss: 1.134966]\n",
      "epoch:26 step:24972 [D loss: 0.571258, acc.: 70.31%] [G loss: 1.174440]\n",
      "epoch:26 step:24973 [D loss: 0.938844, acc.: 30.47%] [G loss: 0.762817]\n",
      "epoch:26 step:24974 [D loss: 0.686092, acc.: 54.69%] [G loss: 0.718879]\n",
      "epoch:26 step:24975 [D loss: 0.408421, acc.: 89.06%] [G loss: 1.312080]\n",
      "epoch:26 step:24976 [D loss: 0.438561, acc.: 87.50%] [G loss: 1.388787]\n",
      "epoch:26 step:24977 [D loss: 0.339242, acc.: 92.19%] [G loss: 1.011294]\n",
      "epoch:26 step:24978 [D loss: 0.331288, acc.: 91.41%] [G loss: 1.223312]\n",
      "epoch:26 step:24979 [D loss: 0.622865, acc.: 60.94%] [G loss: 1.144833]\n",
      "epoch:26 step:24980 [D loss: 0.715567, acc.: 58.59%] [G loss: 1.168202]\n",
      "epoch:26 step:24981 [D loss: 0.642197, acc.: 63.28%] [G loss: 1.046357]\n",
      "epoch:26 step:24982 [D loss: 0.650815, acc.: 60.16%] [G loss: 0.937092]\n",
      "epoch:26 step:24983 [D loss: 0.925552, acc.: 36.72%] [G loss: 0.964723]\n",
      "epoch:26 step:24984 [D loss: 0.533653, acc.: 77.34%] [G loss: 1.034043]\n",
      "epoch:26 step:24985 [D loss: 0.674091, acc.: 63.28%] [G loss: 1.008929]\n",
      "epoch:26 step:24986 [D loss: 0.397453, acc.: 89.06%] [G loss: 1.309138]\n",
      "epoch:26 step:24987 [D loss: 0.770020, acc.: 53.12%] [G loss: 1.251155]\n",
      "epoch:26 step:24988 [D loss: 0.555297, acc.: 77.34%] [G loss: 1.234692]\n",
      "epoch:26 step:24989 [D loss: 0.777018, acc.: 48.44%] [G loss: 0.632303]\n",
      "epoch:26 step:24990 [D loss: 0.809139, acc.: 47.66%] [G loss: 0.958009]\n",
      "epoch:26 step:24991 [D loss: 0.358607, acc.: 85.94%] [G loss: 1.485188]\n",
      "epoch:26 step:24992 [D loss: 0.541703, acc.: 76.56%] [G loss: 1.244093]\n",
      "epoch:26 step:24993 [D loss: 0.714658, acc.: 55.47%] [G loss: 1.008450]\n",
      "epoch:26 step:24994 [D loss: 0.408622, acc.: 89.06%] [G loss: 1.327864]\n",
      "epoch:26 step:24995 [D loss: 0.281235, acc.: 96.09%] [G loss: 1.482935]\n",
      "epoch:26 step:24996 [D loss: 0.389882, acc.: 90.62%] [G loss: 1.626172]\n",
      "epoch:26 step:24997 [D loss: 0.530157, acc.: 72.66%] [G loss: 1.346446]\n",
      "epoch:26 step:24998 [D loss: 1.255141, acc.: 32.03%] [G loss: 0.517895]\n",
      "epoch:26 step:24999 [D loss: 0.861572, acc.: 36.72%] [G loss: 1.019022]\n",
      "epoch:26 step:25000 [D loss: 0.687004, acc.: 57.03%] [G loss: 1.349579]\n",
      "##############\n",
      "[2.49822988 1.46144571 5.47805097 4.49736416 3.0401119  5.41972113\n",
      " 4.29091858 4.79240707 4.08700572 3.89633212]\n",
      "##########\n",
      "epoch:26 step:25001 [D loss: 0.862417, acc.: 46.09%] [G loss: 1.361771]\n",
      "epoch:26 step:25002 [D loss: 0.328751, acc.: 92.97%] [G loss: 1.359900]\n",
      "epoch:26 step:25003 [D loss: 0.378916, acc.: 85.16%] [G loss: 1.410099]\n",
      "epoch:26 step:25004 [D loss: 0.305205, acc.: 93.75%] [G loss: 1.650313]\n",
      "epoch:26 step:25005 [D loss: 0.808167, acc.: 48.44%] [G loss: 1.218127]\n",
      "epoch:26 step:25006 [D loss: 0.776186, acc.: 48.44%] [G loss: 1.166724]\n",
      "epoch:26 step:25007 [D loss: 0.683958, acc.: 59.38%] [G loss: 1.177502]\n",
      "epoch:26 step:25008 [D loss: 0.456755, acc.: 82.81%] [G loss: 1.326219]\n",
      "epoch:26 step:25009 [D loss: 0.500323, acc.: 76.56%] [G loss: 1.228302]\n",
      "epoch:26 step:25010 [D loss: 0.546229, acc.: 75.00%] [G loss: 1.250593]\n",
      "epoch:26 step:25011 [D loss: 0.652089, acc.: 64.84%] [G loss: 0.904606]\n",
      "epoch:26 step:25012 [D loss: 0.674829, acc.: 60.16%] [G loss: 0.966960]\n",
      "epoch:26 step:25013 [D loss: 0.581882, acc.: 63.28%] [G loss: 1.519403]\n",
      "epoch:26 step:25014 [D loss: 0.752342, acc.: 50.00%] [G loss: 1.270752]\n",
      "epoch:26 step:25015 [D loss: 0.503407, acc.: 78.91%] [G loss: 1.468124]\n",
      "epoch:26 step:25016 [D loss: 0.506374, acc.: 75.78%] [G loss: 1.381131]\n",
      "epoch:26 step:25017 [D loss: 0.520539, acc.: 78.91%] [G loss: 1.515371]\n",
      "epoch:26 step:25018 [D loss: 0.388076, acc.: 88.28%] [G loss: 1.412543]\n",
      "epoch:26 step:25019 [D loss: 0.676894, acc.: 60.16%] [G loss: 1.163753]\n",
      "epoch:26 step:25020 [D loss: 0.470971, acc.: 82.81%] [G loss: 1.087919]\n",
      "epoch:26 step:25021 [D loss: 0.624958, acc.: 62.50%] [G loss: 1.167104]\n",
      "epoch:26 step:25022 [D loss: 0.973091, acc.: 40.62%] [G loss: 0.842603]\n",
      "epoch:26 step:25023 [D loss: 0.732063, acc.: 53.12%] [G loss: 1.028598]\n",
      "epoch:26 step:25024 [D loss: 0.429803, acc.: 81.25%] [G loss: 1.445460]\n",
      "epoch:26 step:25025 [D loss: 0.138951, acc.: 100.00%] [G loss: 1.915042]\n",
      "epoch:26 step:25026 [D loss: 0.182302, acc.: 97.66%] [G loss: 1.868505]\n",
      "epoch:26 step:25027 [D loss: 0.288488, acc.: 90.62%] [G loss: 1.844114]\n",
      "epoch:26 step:25028 [D loss: 0.472704, acc.: 81.25%] [G loss: 1.537939]\n",
      "epoch:26 step:25029 [D loss: 0.354541, acc.: 84.38%] [G loss: 1.964662]\n",
      "epoch:26 step:25030 [D loss: 0.659187, acc.: 60.94%] [G loss: 1.235988]\n",
      "epoch:26 step:25031 [D loss: 0.625302, acc.: 68.75%] [G loss: 0.802686]\n",
      "epoch:26 step:25032 [D loss: 1.046015, acc.: 32.03%] [G loss: 0.665073]\n",
      "epoch:26 step:25033 [D loss: 0.668431, acc.: 59.38%] [G loss: 1.108720]\n",
      "epoch:26 step:25034 [D loss: 0.890569, acc.: 35.16%] [G loss: 1.119758]\n",
      "epoch:26 step:25035 [D loss: 1.333551, acc.: 15.62%] [G loss: 0.563946]\n",
      "epoch:26 step:25036 [D loss: 0.892481, acc.: 40.62%] [G loss: 1.022935]\n",
      "epoch:26 step:25037 [D loss: 1.125145, acc.: 16.41%] [G loss: 0.840562]\n",
      "epoch:26 step:25038 [D loss: 0.757115, acc.: 54.69%] [G loss: 1.030866]\n",
      "epoch:26 step:25039 [D loss: 1.064232, acc.: 28.12%] [G loss: 1.026976]\n",
      "epoch:26 step:25040 [D loss: 0.841453, acc.: 42.19%] [G loss: 0.878138]\n",
      "epoch:26 step:25041 [D loss: 0.695226, acc.: 56.25%] [G loss: 1.113960]\n",
      "epoch:26 step:25042 [D loss: 0.779487, acc.: 46.88%] [G loss: 0.976626]\n",
      "epoch:26 step:25043 [D loss: 0.896570, acc.: 38.28%] [G loss: 0.784790]\n",
      "epoch:26 step:25044 [D loss: 0.669741, acc.: 60.94%] [G loss: 1.001076]\n",
      "epoch:26 step:25045 [D loss: 0.750099, acc.: 55.47%] [G loss: 1.068190]\n",
      "epoch:26 step:25046 [D loss: 0.825321, acc.: 43.75%] [G loss: 1.221322]\n",
      "epoch:26 step:25047 [D loss: 0.645338, acc.: 61.72%] [G loss: 1.223776]\n",
      "epoch:26 step:25048 [D loss: 0.631151, acc.: 64.84%] [G loss: 1.060482]\n",
      "epoch:26 step:25049 [D loss: 0.678521, acc.: 56.25%] [G loss: 1.240429]\n",
      "epoch:26 step:25050 [D loss: 0.533514, acc.: 74.22%] [G loss: 1.049292]\n",
      "epoch:26 step:25051 [D loss: 0.361908, acc.: 90.62%] [G loss: 1.416012]\n",
      "epoch:26 step:25052 [D loss: 0.248812, acc.: 94.53%] [G loss: 1.728319]\n",
      "epoch:26 step:25053 [D loss: 0.274664, acc.: 96.88%] [G loss: 1.434049]\n",
      "epoch:26 step:25054 [D loss: 0.330401, acc.: 93.75%] [G loss: 1.344245]\n",
      "epoch:26 step:25055 [D loss: 0.234731, acc.: 96.88%] [G loss: 1.802702]\n",
      "epoch:26 step:25056 [D loss: 0.173849, acc.: 98.44%] [G loss: 1.947626]\n",
      "epoch:26 step:25057 [D loss: 0.224632, acc.: 98.44%] [G loss: 2.070878]\n",
      "epoch:26 step:25058 [D loss: 0.667700, acc.: 55.47%] [G loss: 1.482903]\n",
      "epoch:26 step:25059 [D loss: 0.726136, acc.: 57.81%] [G loss: 0.832966]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:25060 [D loss: 0.523074, acc.: 79.69%] [G loss: 1.304461]\n",
      "epoch:26 step:25061 [D loss: 0.578535, acc.: 71.88%] [G loss: 1.417580]\n",
      "epoch:26 step:25062 [D loss: 0.692426, acc.: 56.25%] [G loss: 1.258291]\n",
      "epoch:26 step:25063 [D loss: 0.571780, acc.: 67.97%] [G loss: 1.203394]\n",
      "epoch:26 step:25064 [D loss: 0.529611, acc.: 78.91%] [G loss: 1.244711]\n",
      "epoch:26 step:25065 [D loss: 0.574798, acc.: 69.53%] [G loss: 1.122034]\n",
      "epoch:26 step:25066 [D loss: 0.590378, acc.: 71.88%] [G loss: 0.847455]\n",
      "epoch:26 step:25067 [D loss: 0.472689, acc.: 78.91%] [G loss: 1.191969]\n",
      "epoch:26 step:25068 [D loss: 0.784987, acc.: 48.44%] [G loss: 1.086341]\n",
      "epoch:26 step:25069 [D loss: 0.842587, acc.: 44.53%] [G loss: 0.967471]\n",
      "epoch:26 step:25070 [D loss: 0.553883, acc.: 72.66%] [G loss: 1.152929]\n",
      "epoch:26 step:25071 [D loss: 0.654844, acc.: 60.94%] [G loss: 0.983781]\n",
      "epoch:26 step:25072 [D loss: 0.260282, acc.: 96.09%] [G loss: 1.546111]\n",
      "epoch:26 step:25073 [D loss: 0.309704, acc.: 94.53%] [G loss: 1.714437]\n",
      "epoch:26 step:25074 [D loss: 0.723906, acc.: 50.00%] [G loss: 1.181897]\n",
      "epoch:26 step:25075 [D loss: 0.647069, acc.: 61.72%] [G loss: 1.095170]\n",
      "epoch:26 step:25076 [D loss: 0.756545, acc.: 46.88%] [G loss: 1.147053]\n",
      "epoch:26 step:25077 [D loss: 0.559805, acc.: 75.00%] [G loss: 1.271781]\n",
      "epoch:26 step:25078 [D loss: 0.767490, acc.: 53.12%] [G loss: 1.020989]\n",
      "epoch:26 step:25079 [D loss: 0.625795, acc.: 60.94%] [G loss: 1.089133]\n",
      "epoch:26 step:25080 [D loss: 0.730750, acc.: 57.81%] [G loss: 1.410492]\n",
      "epoch:26 step:25081 [D loss: 0.797177, acc.: 47.66%] [G loss: 0.932240]\n",
      "epoch:26 step:25082 [D loss: 0.453218, acc.: 83.59%] [G loss: 1.277754]\n",
      "epoch:26 step:25083 [D loss: 0.517068, acc.: 77.34%] [G loss: 1.068431]\n",
      "epoch:26 step:25084 [D loss: 0.762574, acc.: 54.69%] [G loss: 0.798012]\n",
      "epoch:26 step:25085 [D loss: 0.657006, acc.: 59.38%] [G loss: 0.769739]\n",
      "epoch:26 step:25086 [D loss: 0.423662, acc.: 85.16%] [G loss: 1.223943]\n",
      "epoch:26 step:25087 [D loss: 0.667797, acc.: 62.50%] [G loss: 1.057697]\n",
      "epoch:26 step:25088 [D loss: 0.688823, acc.: 58.59%] [G loss: 1.117984]\n",
      "epoch:26 step:25089 [D loss: 0.822637, acc.: 50.00%] [G loss: 1.066297]\n",
      "epoch:26 step:25090 [D loss: 0.490244, acc.: 82.03%] [G loss: 1.412067]\n",
      "epoch:26 step:25091 [D loss: 0.440158, acc.: 84.38%] [G loss: 1.927240]\n",
      "epoch:26 step:25092 [D loss: 0.423940, acc.: 85.94%] [G loss: 1.494545]\n",
      "epoch:26 step:25093 [D loss: 0.327394, acc.: 96.09%] [G loss: 1.524774]\n",
      "epoch:26 step:25094 [D loss: 0.371665, acc.: 89.06%] [G loss: 1.704423]\n",
      "epoch:26 step:25095 [D loss: 0.320655, acc.: 93.75%] [G loss: 1.619571]\n",
      "epoch:26 step:25096 [D loss: 0.689200, acc.: 62.50%] [G loss: 1.449835]\n",
      "epoch:26 step:25097 [D loss: 0.704186, acc.: 58.59%] [G loss: 1.126884]\n",
      "epoch:26 step:25098 [D loss: 0.657147, acc.: 57.03%] [G loss: 1.070725]\n",
      "epoch:26 step:25099 [D loss: 0.535982, acc.: 74.22%] [G loss: 1.183111]\n",
      "epoch:26 step:25100 [D loss: 0.598274, acc.: 65.62%] [G loss: 0.957928]\n",
      "epoch:26 step:25101 [D loss: 0.636669, acc.: 66.41%] [G loss: 1.032960]\n",
      "epoch:26 step:25102 [D loss: 0.387026, acc.: 89.84%] [G loss: 1.522204]\n",
      "epoch:26 step:25103 [D loss: 0.690344, acc.: 53.12%] [G loss: 1.182143]\n",
      "epoch:26 step:25104 [D loss: 0.637742, acc.: 63.28%] [G loss: 1.209667]\n",
      "epoch:26 step:25105 [D loss: 0.528606, acc.: 75.78%] [G loss: 0.988523]\n",
      "epoch:26 step:25106 [D loss: 0.775519, acc.: 42.19%] [G loss: 1.046146]\n",
      "epoch:26 step:25107 [D loss: 0.267405, acc.: 90.62%] [G loss: 1.272914]\n",
      "epoch:26 step:25108 [D loss: 0.380198, acc.: 87.50%] [G loss: 1.311630]\n",
      "epoch:26 step:25109 [D loss: 0.514919, acc.: 75.78%] [G loss: 1.198066]\n",
      "epoch:26 step:25110 [D loss: 0.656777, acc.: 62.50%] [G loss: 1.171582]\n",
      "epoch:26 step:25111 [D loss: 0.679552, acc.: 57.81%] [G loss: 0.952126]\n",
      "epoch:26 step:25112 [D loss: 0.700250, acc.: 57.81%] [G loss: 0.943870]\n",
      "epoch:26 step:25113 [D loss: 0.410540, acc.: 87.50%] [G loss: 1.350004]\n",
      "epoch:26 step:25114 [D loss: 0.524541, acc.: 75.78%] [G loss: 1.202428]\n",
      "epoch:26 step:25115 [D loss: 0.631209, acc.: 60.94%] [G loss: 0.829553]\n",
      "epoch:26 step:25116 [D loss: 0.459456, acc.: 80.47%] [G loss: 1.248637]\n",
      "epoch:26 step:25117 [D loss: 0.295808, acc.: 93.75%] [G loss: 1.383146]\n",
      "epoch:26 step:25118 [D loss: 0.462402, acc.: 84.38%] [G loss: 1.569930]\n",
      "epoch:26 step:25119 [D loss: 0.324072, acc.: 94.53%] [G loss: 1.337405]\n",
      "epoch:26 step:25120 [D loss: 0.456640, acc.: 78.91%] [G loss: 1.589827]\n",
      "epoch:26 step:25121 [D loss: 0.804426, acc.: 43.75%] [G loss: 0.968703]\n",
      "epoch:26 step:25122 [D loss: 1.007280, acc.: 27.34%] [G loss: 1.143284]\n",
      "epoch:26 step:25123 [D loss: 0.980816, acc.: 27.34%] [G loss: 1.157371]\n",
      "epoch:26 step:25124 [D loss: 0.846161, acc.: 46.09%] [G loss: 0.874215]\n",
      "epoch:26 step:25125 [D loss: 0.472198, acc.: 78.12%] [G loss: 1.227139]\n",
      "epoch:26 step:25126 [D loss: 0.658040, acc.: 59.38%] [G loss: 0.900718]\n",
      "epoch:26 step:25127 [D loss: 1.271917, acc.: 17.97%] [G loss: 0.797090]\n",
      "epoch:26 step:25128 [D loss: 0.731798, acc.: 53.91%] [G loss: 1.243922]\n",
      "epoch:26 step:25129 [D loss: 0.519540, acc.: 74.22%] [G loss: 1.383931]\n",
      "epoch:26 step:25130 [D loss: 0.388727, acc.: 88.28%] [G loss: 1.173831]\n",
      "epoch:26 step:25131 [D loss: 0.299981, acc.: 92.97%] [G loss: 1.373316]\n",
      "epoch:26 step:25132 [D loss: 0.481043, acc.: 82.03%] [G loss: 1.313268]\n",
      "epoch:26 step:25133 [D loss: 0.594687, acc.: 65.62%] [G loss: 1.495600]\n",
      "epoch:26 step:25134 [D loss: 0.585685, acc.: 71.09%] [G loss: 1.086234]\n",
      "epoch:26 step:25135 [D loss: 0.462548, acc.: 85.94%] [G loss: 1.122055]\n",
      "epoch:26 step:25136 [D loss: 0.220152, acc.: 96.09%] [G loss: 1.378499]\n",
      "epoch:26 step:25137 [D loss: 0.157095, acc.: 98.44%] [G loss: 1.992542]\n",
      "epoch:26 step:25138 [D loss: 0.409964, acc.: 86.72%] [G loss: 1.813042]\n",
      "epoch:26 step:25139 [D loss: 0.290534, acc.: 96.09%] [G loss: 1.759856]\n",
      "epoch:26 step:25140 [D loss: 0.536952, acc.: 71.88%] [G loss: 1.349570]\n",
      "epoch:26 step:25141 [D loss: 0.857040, acc.: 46.09%] [G loss: 1.163224]\n",
      "epoch:26 step:25142 [D loss: 0.595025, acc.: 64.06%] [G loss: 1.196218]\n",
      "epoch:26 step:25143 [D loss: 0.462537, acc.: 82.03%] [G loss: 1.219337]\n",
      "epoch:26 step:25144 [D loss: 0.427407, acc.: 87.50%] [G loss: 1.319359]\n",
      "epoch:26 step:25145 [D loss: 0.823096, acc.: 47.66%] [G loss: 1.041765]\n",
      "epoch:26 step:25146 [D loss: 0.796397, acc.: 42.97%] [G loss: 0.782845]\n",
      "epoch:26 step:25147 [D loss: 0.759207, acc.: 46.09%] [G loss: 0.917349]\n",
      "epoch:26 step:25148 [D loss: 0.642906, acc.: 63.28%] [G loss: 0.967712]\n",
      "epoch:26 step:25149 [D loss: 0.639343, acc.: 63.28%] [G loss: 1.150694]\n",
      "epoch:26 step:25150 [D loss: 0.803349, acc.: 46.88%] [G loss: 1.062568]\n",
      "epoch:26 step:25151 [D loss: 0.655788, acc.: 63.28%] [G loss: 0.994713]\n",
      "epoch:26 step:25152 [D loss: 0.599525, acc.: 67.97%] [G loss: 1.145537]\n",
      "epoch:26 step:25153 [D loss: 0.468169, acc.: 81.25%] [G loss: 1.117945]\n",
      "epoch:26 step:25154 [D loss: 0.359282, acc.: 90.62%] [G loss: 1.275337]\n",
      "epoch:26 step:25155 [D loss: 0.565399, acc.: 71.88%] [G loss: 1.176714]\n",
      "epoch:26 step:25156 [D loss: 0.601630, acc.: 62.50%] [G loss: 1.017210]\n",
      "epoch:26 step:25157 [D loss: 0.571269, acc.: 70.31%] [G loss: 1.215968]\n",
      "epoch:26 step:25158 [D loss: 0.541970, acc.: 75.78%] [G loss: 1.146664]\n",
      "epoch:26 step:25159 [D loss: 0.676496, acc.: 57.03%] [G loss: 0.843960]\n",
      "epoch:26 step:25160 [D loss: 0.617138, acc.: 60.94%] [G loss: 1.200551]\n",
      "epoch:26 step:25161 [D loss: 0.729839, acc.: 60.16%] [G loss: 1.141717]\n",
      "epoch:26 step:25162 [D loss: 0.530673, acc.: 76.56%] [G loss: 1.161215]\n",
      "epoch:26 step:25163 [D loss: 0.452198, acc.: 82.81%] [G loss: 1.296193]\n",
      "epoch:26 step:25164 [D loss: 0.285985, acc.: 94.53%] [G loss: 1.450710]\n",
      "epoch:26 step:25165 [D loss: 0.386692, acc.: 88.28%] [G loss: 1.375355]\n",
      "epoch:26 step:25166 [D loss: 0.671654, acc.: 60.16%] [G loss: 1.356637]\n",
      "epoch:26 step:25167 [D loss: 0.745916, acc.: 50.00%] [G loss: 1.043923]\n",
      "epoch:26 step:25168 [D loss: 0.509826, acc.: 75.78%] [G loss: 1.124098]\n",
      "epoch:26 step:25169 [D loss: 0.650031, acc.: 66.41%] [G loss: 1.185762]\n",
      "epoch:26 step:25170 [D loss: 0.327894, acc.: 86.72%] [G loss: 1.570389]\n",
      "epoch:26 step:25171 [D loss: 0.304060, acc.: 95.31%] [G loss: 1.747610]\n",
      "epoch:26 step:25172 [D loss: 0.304122, acc.: 93.75%] [G loss: 1.459688]\n",
      "epoch:26 step:25173 [D loss: 0.909581, acc.: 37.50%] [G loss: 1.067882]\n",
      "epoch:26 step:25174 [D loss: 0.595278, acc.: 69.53%] [G loss: 1.170433]\n",
      "epoch:26 step:25175 [D loss: 0.549209, acc.: 73.44%] [G loss: 0.911147]\n",
      "epoch:26 step:25176 [D loss: 0.530008, acc.: 77.34%] [G loss: 1.182498]\n",
      "epoch:26 step:25177 [D loss: 0.201233, acc.: 98.44%] [G loss: 1.528101]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:25178 [D loss: 0.252775, acc.: 96.88%] [G loss: 1.612437]\n",
      "epoch:26 step:25179 [D loss: 0.568553, acc.: 71.09%] [G loss: 1.480977]\n",
      "epoch:26 step:25180 [D loss: 0.593891, acc.: 66.41%] [G loss: 1.149569]\n",
      "epoch:26 step:25181 [D loss: 0.642297, acc.: 64.06%] [G loss: 1.423842]\n",
      "epoch:26 step:25182 [D loss: 1.222353, acc.: 21.88%] [G loss: 0.636997]\n",
      "epoch:26 step:25183 [D loss: 1.147732, acc.: 18.75%] [G loss: 0.568743]\n",
      "epoch:26 step:25184 [D loss: 0.713979, acc.: 54.69%] [G loss: 0.829952]\n",
      "epoch:26 step:25185 [D loss: 0.590975, acc.: 67.97%] [G loss: 1.104661]\n",
      "epoch:26 step:25186 [D loss: 0.555451, acc.: 69.53%] [G loss: 1.167773]\n",
      "epoch:26 step:25187 [D loss: 0.656778, acc.: 60.94%] [G loss: 1.098432]\n",
      "epoch:26 step:25188 [D loss: 1.044561, acc.: 23.44%] [G loss: 0.978441]\n",
      "epoch:26 step:25189 [D loss: 0.646887, acc.: 61.72%] [G loss: 1.428091]\n",
      "epoch:26 step:25190 [D loss: 0.799126, acc.: 42.97%] [G loss: 0.956183]\n",
      "epoch:26 step:25191 [D loss: 0.704927, acc.: 54.69%] [G loss: 0.974781]\n",
      "epoch:26 step:25192 [D loss: 0.606011, acc.: 64.84%] [G loss: 0.939575]\n",
      "epoch:26 step:25193 [D loss: 0.506025, acc.: 76.56%] [G loss: 1.259202]\n",
      "epoch:26 step:25194 [D loss: 0.474332, acc.: 84.38%] [G loss: 1.324027]\n",
      "epoch:26 step:25195 [D loss: 0.519641, acc.: 78.12%] [G loss: 1.070226]\n",
      "epoch:26 step:25196 [D loss: 0.597344, acc.: 65.62%] [G loss: 1.053066]\n",
      "epoch:26 step:25197 [D loss: 0.599137, acc.: 68.75%] [G loss: 1.164101]\n",
      "epoch:26 step:25198 [D loss: 0.506107, acc.: 78.91%] [G loss: 1.166769]\n",
      "epoch:26 step:25199 [D loss: 0.429864, acc.: 83.59%] [G loss: 1.025448]\n",
      "epoch:26 step:25200 [D loss: 0.584018, acc.: 68.75%] [G loss: 1.253791]\n",
      "##############\n",
      "[2.3880516  1.45378019 5.56067942 4.12611931 3.0908292  5.4912832\n",
      " 4.30762251 4.58963033 3.91582383 3.60326872]\n",
      "##########\n",
      "epoch:26 step:25201 [D loss: 0.797378, acc.: 46.88%] [G loss: 1.157330]\n",
      "epoch:26 step:25202 [D loss: 0.650579, acc.: 63.28%] [G loss: 0.929039]\n",
      "epoch:26 step:25203 [D loss: 0.347874, acc.: 91.41%] [G loss: 1.491456]\n",
      "epoch:26 step:25204 [D loss: 0.578714, acc.: 64.84%] [G loss: 1.383878]\n",
      "epoch:26 step:25205 [D loss: 0.701669, acc.: 59.38%] [G loss: 1.230732]\n",
      "epoch:26 step:25206 [D loss: 0.704325, acc.: 54.69%] [G loss: 1.117891]\n",
      "epoch:26 step:25207 [D loss: 0.636800, acc.: 61.72%] [G loss: 0.792109]\n",
      "epoch:26 step:25208 [D loss: 0.529486, acc.: 75.78%] [G loss: 1.207791]\n",
      "epoch:26 step:25209 [D loss: 0.568587, acc.: 73.44%] [G loss: 1.034220]\n",
      "epoch:26 step:25210 [D loss: 0.603199, acc.: 68.75%] [G loss: 1.286379]\n",
      "epoch:26 step:25211 [D loss: 0.375279, acc.: 87.50%] [G loss: 1.315479]\n",
      "epoch:26 step:25212 [D loss: 0.376178, acc.: 92.97%] [G loss: 1.473175]\n",
      "epoch:26 step:25213 [D loss: 0.366762, acc.: 90.62%] [G loss: 1.445485]\n",
      "epoch:26 step:25214 [D loss: 0.386739, acc.: 86.72%] [G loss: 1.435952]\n",
      "epoch:26 step:25215 [D loss: 0.337936, acc.: 89.84%] [G loss: 1.644749]\n",
      "epoch:26 step:25216 [D loss: 0.286542, acc.: 96.88%] [G loss: 1.853258]\n",
      "epoch:26 step:25217 [D loss: 0.535351, acc.: 67.97%] [G loss: 1.724859]\n",
      "epoch:26 step:25218 [D loss: 0.569765, acc.: 75.00%] [G loss: 1.208605]\n",
      "epoch:26 step:25219 [D loss: 0.566550, acc.: 67.19%] [G loss: 0.891684]\n",
      "epoch:26 step:25220 [D loss: 0.606567, acc.: 64.06%] [G loss: 1.069537]\n",
      "epoch:26 step:25221 [D loss: 0.511808, acc.: 77.34%] [G loss: 1.425214]\n",
      "epoch:26 step:25222 [D loss: 0.369316, acc.: 92.19%] [G loss: 1.553590]\n",
      "epoch:26 step:25223 [D loss: 0.653518, acc.: 58.59%] [G loss: 1.246455]\n",
      "epoch:26 step:25224 [D loss: 0.735520, acc.: 50.78%] [G loss: 0.861483]\n",
      "epoch:26 step:25225 [D loss: 0.582788, acc.: 68.75%] [G loss: 1.003657]\n",
      "epoch:26 step:25226 [D loss: 0.722785, acc.: 50.78%] [G loss: 1.158336]\n",
      "epoch:26 step:25227 [D loss: 0.694207, acc.: 57.81%] [G loss: 0.898643]\n",
      "epoch:26 step:25228 [D loss: 0.710534, acc.: 57.81%] [G loss: 0.791446]\n",
      "epoch:26 step:25229 [D loss: 0.763659, acc.: 50.78%] [G loss: 0.830686]\n",
      "epoch:26 step:25230 [D loss: 0.619634, acc.: 64.06%] [G loss: 0.898700]\n",
      "epoch:26 step:25231 [D loss: 0.539418, acc.: 78.12%] [G loss: 1.220437]\n",
      "epoch:26 step:25232 [D loss: 0.578518, acc.: 68.75%] [G loss: 0.991905]\n",
      "epoch:26 step:25233 [D loss: 0.579188, acc.: 70.31%] [G loss: 1.164023]\n",
      "epoch:26 step:25234 [D loss: 0.713862, acc.: 52.34%] [G loss: 1.169759]\n",
      "epoch:26 step:25235 [D loss: 0.678846, acc.: 55.47%] [G loss: 1.135924]\n",
      "epoch:26 step:25236 [D loss: 0.608249, acc.: 69.53%] [G loss: 1.130771]\n",
      "epoch:26 step:25237 [D loss: 0.572189, acc.: 67.97%] [G loss: 0.984412]\n",
      "epoch:26 step:25238 [D loss: 0.589341, acc.: 70.31%] [G loss: 0.956318]\n",
      "epoch:26 step:25239 [D loss: 0.544339, acc.: 75.78%] [G loss: 1.088784]\n",
      "epoch:26 step:25240 [D loss: 0.421818, acc.: 82.81%] [G loss: 1.198804]\n",
      "epoch:26 step:25241 [D loss: 0.740267, acc.: 46.88%] [G loss: 1.499323]\n",
      "epoch:26 step:25242 [D loss: 0.877562, acc.: 47.66%] [G loss: 1.038837]\n",
      "epoch:26 step:25243 [D loss: 0.703866, acc.: 54.69%] [G loss: 1.009283]\n",
      "epoch:26 step:25244 [D loss: 0.643553, acc.: 63.28%] [G loss: 0.916399]\n",
      "epoch:26 step:25245 [D loss: 0.530205, acc.: 78.12%] [G loss: 0.944494]\n",
      "epoch:26 step:25246 [D loss: 0.364404, acc.: 89.06%] [G loss: 0.811299]\n",
      "epoch:26 step:25247 [D loss: 0.401344, acc.: 81.25%] [G loss: 1.090742]\n",
      "epoch:26 step:25248 [D loss: 0.443144, acc.: 86.72%] [G loss: 1.297235]\n",
      "epoch:26 step:25249 [D loss: 0.315316, acc.: 94.53%] [G loss: 1.290861]\n",
      "epoch:26 step:25250 [D loss: 0.468828, acc.: 82.03%] [G loss: 1.552129]\n",
      "epoch:26 step:25251 [D loss: 0.383554, acc.: 86.72%] [G loss: 1.038734]\n",
      "epoch:26 step:25252 [D loss: 0.367210, acc.: 91.41%] [G loss: 1.226070]\n",
      "epoch:26 step:25253 [D loss: 0.932571, acc.: 30.47%] [G loss: 0.820891]\n",
      "epoch:26 step:25254 [D loss: 0.518783, acc.: 77.34%] [G loss: 1.301615]\n",
      "epoch:26 step:25255 [D loss: 0.506811, acc.: 78.91%] [G loss: 1.059718]\n",
      "epoch:26 step:25256 [D loss: 0.417221, acc.: 88.28%] [G loss: 1.416391]\n",
      "epoch:26 step:25257 [D loss: 0.400819, acc.: 91.41%] [G loss: 1.226290]\n",
      "epoch:26 step:25258 [D loss: 0.360531, acc.: 92.19%] [G loss: 1.244771]\n",
      "epoch:26 step:25259 [D loss: 0.395314, acc.: 89.84%] [G loss: 1.445214]\n",
      "epoch:26 step:25260 [D loss: 0.350863, acc.: 86.72%] [G loss: 1.515711]\n",
      "epoch:26 step:25261 [D loss: 0.333861, acc.: 90.62%] [G loss: 1.730682]\n",
      "epoch:26 step:25262 [D loss: 0.210413, acc.: 99.22%] [G loss: 2.053949]\n",
      "epoch:26 step:25263 [D loss: 0.408182, acc.: 85.94%] [G loss: 1.911126]\n",
      "epoch:26 step:25264 [D loss: 0.736818, acc.: 52.34%] [G loss: 1.376710]\n",
      "epoch:26 step:25265 [D loss: 0.675651, acc.: 60.16%] [G loss: 1.192963]\n",
      "epoch:26 step:25266 [D loss: 0.555116, acc.: 71.09%] [G loss: 1.326531]\n",
      "epoch:26 step:25267 [D loss: 0.691727, acc.: 57.03%] [G loss: 1.247173]\n",
      "epoch:26 step:25268 [D loss: 0.471320, acc.: 80.47%] [G loss: 1.322004]\n",
      "epoch:26 step:25269 [D loss: 0.622154, acc.: 63.28%] [G loss: 1.141786]\n",
      "epoch:26 step:25270 [D loss: 0.678657, acc.: 61.72%] [G loss: 1.072519]\n",
      "epoch:26 step:25271 [D loss: 0.551791, acc.: 72.66%] [G loss: 1.082750]\n",
      "epoch:26 step:25272 [D loss: 0.470008, acc.: 78.91%] [G loss: 1.325302]\n",
      "epoch:26 step:25273 [D loss: 0.550812, acc.: 69.53%] [G loss: 1.531000]\n",
      "epoch:26 step:25274 [D loss: 0.239695, acc.: 90.62%] [G loss: 1.441260]\n",
      "epoch:26 step:25275 [D loss: 0.886983, acc.: 49.22%] [G loss: 1.516639]\n",
      "epoch:26 step:25276 [D loss: 0.862639, acc.: 41.41%] [G loss: 1.169346]\n",
      "epoch:26 step:25277 [D loss: 0.772163, acc.: 46.88%] [G loss: 0.977953]\n",
      "epoch:26 step:25278 [D loss: 0.711105, acc.: 53.91%] [G loss: 1.062744]\n",
      "epoch:26 step:25279 [D loss: 0.655164, acc.: 60.16%] [G loss: 0.894676]\n",
      "epoch:26 step:25280 [D loss: 0.575048, acc.: 69.53%] [G loss: 1.002093]\n",
      "epoch:26 step:25281 [D loss: 0.379491, acc.: 86.72%] [G loss: 1.389904]\n",
      "epoch:26 step:25282 [D loss: 0.336084, acc.: 91.41%] [G loss: 1.234866]\n",
      "epoch:26 step:25283 [D loss: 0.379186, acc.: 89.06%] [G loss: 1.430094]\n",
      "epoch:26 step:25284 [D loss: 0.508452, acc.: 81.25%] [G loss: 1.754206]\n",
      "epoch:26 step:25285 [D loss: 0.435294, acc.: 82.03%] [G loss: 1.239955]\n",
      "epoch:26 step:25286 [D loss: 0.315835, acc.: 90.62%] [G loss: 1.350727]\n",
      "epoch:26 step:25287 [D loss: 0.347434, acc.: 92.19%] [G loss: 1.447598]\n",
      "epoch:26 step:25288 [D loss: 0.240627, acc.: 97.66%] [G loss: 1.386346]\n",
      "epoch:26 step:25289 [D loss: 0.154451, acc.: 97.66%] [G loss: 1.814442]\n",
      "epoch:26 step:25290 [D loss: 0.915956, acc.: 46.09%] [G loss: 1.401334]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:25291 [D loss: 0.374525, acc.: 88.28%] [G loss: 1.375591]\n",
      "epoch:26 step:25292 [D loss: 0.585884, acc.: 67.19%] [G loss: 1.337930]\n",
      "epoch:26 step:25293 [D loss: 0.751340, acc.: 54.69%] [G loss: 0.934650]\n",
      "epoch:26 step:25294 [D loss: 0.520655, acc.: 69.53%] [G loss: 1.107669]\n",
      "epoch:26 step:25295 [D loss: 0.442943, acc.: 79.69%] [G loss: 1.137872]\n",
      "epoch:26 step:25296 [D loss: 0.201990, acc.: 99.22%] [G loss: 1.577766]\n",
      "epoch:26 step:25297 [D loss: 0.536475, acc.: 75.78%] [G loss: 1.160194]\n",
      "epoch:26 step:25298 [D loss: 0.296244, acc.: 96.09%] [G loss: 1.546819]\n",
      "epoch:26 step:25299 [D loss: 0.149834, acc.: 98.44%] [G loss: 1.656442]\n",
      "epoch:27 step:25300 [D loss: 0.946898, acc.: 46.88%] [G loss: 0.987291]\n",
      "epoch:27 step:25301 [D loss: 0.734571, acc.: 53.91%] [G loss: 1.156056]\n",
      "epoch:27 step:25302 [D loss: 0.788697, acc.: 45.31%] [G loss: 0.946467]\n",
      "epoch:27 step:25303 [D loss: 1.048738, acc.: 22.66%] [G loss: 0.957757]\n",
      "epoch:27 step:25304 [D loss: 0.640815, acc.: 60.16%] [G loss: 1.370589]\n",
      "epoch:27 step:25305 [D loss: 0.617210, acc.: 65.62%] [G loss: 1.216182]\n",
      "epoch:27 step:25306 [D loss: 0.767140, acc.: 52.34%] [G loss: 1.021087]\n",
      "epoch:27 step:25307 [D loss: 0.467438, acc.: 83.59%] [G loss: 1.183686]\n",
      "epoch:27 step:25308 [D loss: 0.418247, acc.: 84.38%] [G loss: 1.129373]\n",
      "epoch:27 step:25309 [D loss: 0.434146, acc.: 84.38%] [G loss: 1.333781]\n",
      "epoch:27 step:25310 [D loss: 0.467998, acc.: 84.38%] [G loss: 1.421906]\n",
      "epoch:27 step:25311 [D loss: 0.731257, acc.: 54.69%] [G loss: 1.041974]\n",
      "epoch:27 step:25312 [D loss: 0.692222, acc.: 62.50%] [G loss: 1.536374]\n",
      "epoch:27 step:25313 [D loss: 0.565753, acc.: 73.44%] [G loss: 0.947058]\n",
      "epoch:27 step:25314 [D loss: 0.490053, acc.: 70.31%] [G loss: 1.231012]\n",
      "epoch:27 step:25315 [D loss: 0.511704, acc.: 82.03%] [G loss: 1.326491]\n",
      "epoch:27 step:25316 [D loss: 0.642334, acc.: 60.94%] [G loss: 1.307300]\n",
      "epoch:27 step:25317 [D loss: 1.136839, acc.: 17.97%] [G loss: 0.940826]\n",
      "epoch:27 step:25318 [D loss: 0.866758, acc.: 42.97%] [G loss: 0.994727]\n",
      "epoch:27 step:25319 [D loss: 0.574129, acc.: 74.22%] [G loss: 1.029794]\n",
      "epoch:27 step:25320 [D loss: 0.783568, acc.: 46.09%] [G loss: 1.007823]\n",
      "epoch:27 step:25321 [D loss: 0.793633, acc.: 48.44%] [G loss: 1.067263]\n",
      "epoch:27 step:25322 [D loss: 0.582261, acc.: 67.19%] [G loss: 1.378994]\n",
      "epoch:27 step:25323 [D loss: 0.514005, acc.: 75.78%] [G loss: 1.037841]\n",
      "epoch:27 step:25324 [D loss: 0.561499, acc.: 70.31%] [G loss: 1.377457]\n",
      "epoch:27 step:25325 [D loss: 0.418532, acc.: 80.47%] [G loss: 1.378198]\n",
      "epoch:27 step:25326 [D loss: 0.267717, acc.: 92.97%] [G loss: 1.653908]\n",
      "epoch:27 step:25327 [D loss: 0.285010, acc.: 95.31%] [G loss: 1.400115]\n",
      "epoch:27 step:25328 [D loss: 0.274183, acc.: 96.09%] [G loss: 1.579723]\n",
      "epoch:27 step:25329 [D loss: 0.303935, acc.: 95.31%] [G loss: 1.637426]\n",
      "epoch:27 step:25330 [D loss: 0.235385, acc.: 97.66%] [G loss: 1.695975]\n",
      "epoch:27 step:25331 [D loss: 0.291275, acc.: 90.62%] [G loss: 1.724050]\n",
      "epoch:27 step:25332 [D loss: 0.192806, acc.: 100.00%] [G loss: 1.917890]\n",
      "epoch:27 step:25333 [D loss: 0.314269, acc.: 93.75%] [G loss: 1.602423]\n",
      "epoch:27 step:25334 [D loss: 0.205532, acc.: 97.66%] [G loss: 1.973313]\n",
      "epoch:27 step:25335 [D loss: 0.208096, acc.: 96.09%] [G loss: 1.444350]\n",
      "epoch:27 step:25336 [D loss: 0.912689, acc.: 51.56%] [G loss: 1.848332]\n",
      "epoch:27 step:25337 [D loss: 1.029806, acc.: 30.47%] [G loss: 1.164781]\n",
      "epoch:27 step:25338 [D loss: 0.655004, acc.: 61.72%] [G loss: 1.131228]\n",
      "epoch:27 step:25339 [D loss: 0.528796, acc.: 75.00%] [G loss: 1.127934]\n",
      "epoch:27 step:25340 [D loss: 0.611681, acc.: 64.84%] [G loss: 1.070241]\n",
      "epoch:27 step:25341 [D loss: 0.469787, acc.: 84.38%] [G loss: 1.105328]\n",
      "epoch:27 step:25342 [D loss: 0.424302, acc.: 86.72%] [G loss: 1.135813]\n",
      "epoch:27 step:25343 [D loss: 0.507362, acc.: 78.12%] [G loss: 0.854804]\n",
      "epoch:27 step:25344 [D loss: 0.525867, acc.: 74.22%] [G loss: 1.172097]\n",
      "epoch:27 step:25345 [D loss: 0.659021, acc.: 62.50%] [G loss: 1.355120]\n",
      "epoch:27 step:25346 [D loss: 1.006273, acc.: 35.94%] [G loss: 0.877058]\n",
      "epoch:27 step:25347 [D loss: 1.166688, acc.: 23.44%] [G loss: 0.909305]\n",
      "epoch:27 step:25348 [D loss: 0.568548, acc.: 67.97%] [G loss: 1.425052]\n",
      "epoch:27 step:25349 [D loss: 0.542773, acc.: 73.44%] [G loss: 1.403947]\n",
      "epoch:27 step:25350 [D loss: 0.692859, acc.: 55.47%] [G loss: 1.093134]\n",
      "epoch:27 step:25351 [D loss: 0.646004, acc.: 62.50%] [G loss: 1.166975]\n",
      "epoch:27 step:25352 [D loss: 0.714363, acc.: 56.25%] [G loss: 0.881958]\n",
      "epoch:27 step:25353 [D loss: 0.624456, acc.: 62.50%] [G loss: 1.205839]\n",
      "epoch:27 step:25354 [D loss: 0.524290, acc.: 75.78%] [G loss: 1.258278]\n",
      "epoch:27 step:25355 [D loss: 0.725807, acc.: 52.34%] [G loss: 0.970495]\n",
      "epoch:27 step:25356 [D loss: 0.846969, acc.: 41.41%] [G loss: 1.083371]\n",
      "epoch:27 step:25357 [D loss: 0.627717, acc.: 62.50%] [G loss: 1.040622]\n",
      "epoch:27 step:25358 [D loss: 0.588076, acc.: 65.62%] [G loss: 0.938858]\n",
      "epoch:27 step:25359 [D loss: 0.526778, acc.: 77.34%] [G loss: 1.112988]\n",
      "epoch:27 step:25360 [D loss: 0.595038, acc.: 64.06%] [G loss: 1.121295]\n",
      "epoch:27 step:25361 [D loss: 0.641820, acc.: 63.28%] [G loss: 0.944908]\n",
      "epoch:27 step:25362 [D loss: 0.939923, acc.: 40.62%] [G loss: 0.532441]\n",
      "epoch:27 step:25363 [D loss: 0.765774, acc.: 48.44%] [G loss: 0.972077]\n",
      "epoch:27 step:25364 [D loss: 0.688377, acc.: 55.47%] [G loss: 1.178755]\n",
      "epoch:27 step:25365 [D loss: 0.789715, acc.: 44.53%] [G loss: 1.018483]\n",
      "epoch:27 step:25366 [D loss: 0.719250, acc.: 50.00%] [G loss: 1.066959]\n",
      "epoch:27 step:25367 [D loss: 0.459683, acc.: 83.59%] [G loss: 1.217960]\n",
      "epoch:27 step:25368 [D loss: 0.387500, acc.: 90.62%] [G loss: 1.532229]\n",
      "epoch:27 step:25369 [D loss: 0.490139, acc.: 83.59%] [G loss: 1.037478]\n",
      "epoch:27 step:25370 [D loss: 0.691338, acc.: 59.38%] [G loss: 1.085428]\n",
      "epoch:27 step:25371 [D loss: 0.562451, acc.: 71.88%] [G loss: 1.185750]\n",
      "epoch:27 step:25372 [D loss: 0.552711, acc.: 71.09%] [G loss: 1.170461]\n",
      "epoch:27 step:25373 [D loss: 0.405379, acc.: 83.59%] [G loss: 0.913445]\n",
      "epoch:27 step:25374 [D loss: 0.321597, acc.: 86.72%] [G loss: 1.110706]\n",
      "epoch:27 step:25375 [D loss: 0.345521, acc.: 92.19%] [G loss: 1.426870]\n",
      "epoch:27 step:25376 [D loss: 0.446835, acc.: 84.38%] [G loss: 1.219625]\n",
      "epoch:27 step:25377 [D loss: 0.678614, acc.: 56.25%] [G loss: 1.217878]\n",
      "epoch:27 step:25378 [D loss: 0.730515, acc.: 50.78%] [G loss: 0.819658]\n",
      "epoch:27 step:25379 [D loss: 0.589580, acc.: 67.19%] [G loss: 1.045157]\n",
      "epoch:27 step:25380 [D loss: 0.569614, acc.: 70.31%] [G loss: 1.305326]\n",
      "epoch:27 step:25381 [D loss: 0.485990, acc.: 80.47%] [G loss: 0.921446]\n",
      "epoch:27 step:25382 [D loss: 0.378783, acc.: 86.72%] [G loss: 1.393672]\n",
      "epoch:27 step:25383 [D loss: 0.526256, acc.: 72.66%] [G loss: 1.463877]\n",
      "epoch:27 step:25384 [D loss: 0.653969, acc.: 57.81%] [G loss: 1.060823]\n",
      "epoch:27 step:25385 [D loss: 0.529668, acc.: 73.44%] [G loss: 1.088151]\n",
      "epoch:27 step:25386 [D loss: 0.481025, acc.: 78.12%] [G loss: 0.944545]\n",
      "epoch:27 step:25387 [D loss: 0.438769, acc.: 84.38%] [G loss: 1.436986]\n",
      "epoch:27 step:25388 [D loss: 0.549007, acc.: 73.44%] [G loss: 1.180493]\n",
      "epoch:27 step:25389 [D loss: 0.391235, acc.: 89.06%] [G loss: 1.559044]\n",
      "epoch:27 step:25390 [D loss: 0.547153, acc.: 70.31%] [G loss: 1.074482]\n",
      "epoch:27 step:25391 [D loss: 0.530954, acc.: 78.12%] [G loss: 0.956336]\n",
      "epoch:27 step:25392 [D loss: 0.723095, acc.: 49.22%] [G loss: 0.834113]\n",
      "epoch:27 step:25393 [D loss: 0.604354, acc.: 67.19%] [G loss: 1.375520]\n",
      "epoch:27 step:25394 [D loss: 1.086572, acc.: 23.44%] [G loss: 0.730436]\n",
      "epoch:27 step:25395 [D loss: 0.711649, acc.: 57.81%] [G loss: 0.768075]\n",
      "epoch:27 step:25396 [D loss: 0.832207, acc.: 37.50%] [G loss: 1.051647]\n",
      "epoch:27 step:25397 [D loss: 0.852035, acc.: 37.50%] [G loss: 0.844727]\n",
      "epoch:27 step:25398 [D loss: 0.825193, acc.: 49.22%] [G loss: 0.979736]\n",
      "epoch:27 step:25399 [D loss: 0.786350, acc.: 44.53%] [G loss: 0.922677]\n",
      "epoch:27 step:25400 [D loss: 0.788114, acc.: 49.22%] [G loss: 0.832244]\n",
      "##############\n",
      "[2.45783716 1.60253726 5.582963   4.33960995 3.04027886 5.48293274\n",
      " 4.22260861 4.69351688 4.11049195 4.00929401]\n",
      "##########\n",
      "epoch:27 step:25401 [D loss: 0.910567, acc.: 31.25%] [G loss: 0.926051]\n",
      "epoch:27 step:25402 [D loss: 0.707186, acc.: 58.59%] [G loss: 1.231117]\n",
      "epoch:27 step:25403 [D loss: 0.541282, acc.: 73.44%] [G loss: 1.113888]\n",
      "epoch:27 step:25404 [D loss: 0.350341, acc.: 92.97%] [G loss: 1.158352]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25405 [D loss: 0.344647, acc.: 90.62%] [G loss: 1.417746]\n",
      "epoch:27 step:25406 [D loss: 0.642502, acc.: 64.84%] [G loss: 1.135798]\n",
      "epoch:27 step:25407 [D loss: 0.453727, acc.: 78.12%] [G loss: 1.253546]\n",
      "epoch:27 step:25408 [D loss: 0.297877, acc.: 94.53%] [G loss: 1.201603]\n",
      "epoch:27 step:25409 [D loss: 0.712899, acc.: 54.69%] [G loss: 1.239378]\n",
      "epoch:27 step:25410 [D loss: 0.602666, acc.: 66.41%] [G loss: 1.270764]\n",
      "epoch:27 step:25411 [D loss: 0.804281, acc.: 45.31%] [G loss: 1.027152]\n",
      "epoch:27 step:25412 [D loss: 0.709292, acc.: 57.03%] [G loss: 1.231721]\n",
      "epoch:27 step:25413 [D loss: 0.759273, acc.: 47.66%] [G loss: 0.982023]\n",
      "epoch:27 step:25414 [D loss: 0.865224, acc.: 42.97%] [G loss: 0.764410]\n",
      "epoch:27 step:25415 [D loss: 0.383801, acc.: 86.72%] [G loss: 1.171311]\n",
      "epoch:27 step:25416 [D loss: 0.382835, acc.: 84.38%] [G loss: 1.312306]\n",
      "epoch:27 step:25417 [D loss: 0.378135, acc.: 87.50%] [G loss: 1.459057]\n",
      "epoch:27 step:25418 [D loss: 0.302586, acc.: 93.75%] [G loss: 1.311601]\n",
      "epoch:27 step:25419 [D loss: 0.805587, acc.: 53.12%] [G loss: 1.535020]\n",
      "epoch:27 step:25420 [D loss: 0.635179, acc.: 66.41%] [G loss: 1.485766]\n",
      "epoch:27 step:25421 [D loss: 0.426754, acc.: 82.03%] [G loss: 1.254560]\n",
      "epoch:27 step:25422 [D loss: 0.753312, acc.: 56.25%] [G loss: 1.378531]\n",
      "epoch:27 step:25423 [D loss: 0.572431, acc.: 70.31%] [G loss: 1.461419]\n",
      "epoch:27 step:25424 [D loss: 0.698140, acc.: 63.28%] [G loss: 1.184881]\n",
      "epoch:27 step:25425 [D loss: 0.504923, acc.: 78.12%] [G loss: 1.224388]\n",
      "epoch:27 step:25426 [D loss: 0.591906, acc.: 69.53%] [G loss: 1.118776]\n",
      "epoch:27 step:25427 [D loss: 0.582609, acc.: 69.53%] [G loss: 1.187737]\n",
      "epoch:27 step:25428 [D loss: 0.593794, acc.: 65.62%] [G loss: 1.156840]\n",
      "epoch:27 step:25429 [D loss: 0.461718, acc.: 78.12%] [G loss: 1.103417]\n",
      "epoch:27 step:25430 [D loss: 0.408810, acc.: 86.72%] [G loss: 1.218164]\n",
      "epoch:27 step:25431 [D loss: 0.517233, acc.: 76.56%] [G loss: 1.374478]\n",
      "epoch:27 step:25432 [D loss: 0.759044, acc.: 54.69%] [G loss: 0.922597]\n",
      "epoch:27 step:25433 [D loss: 0.444677, acc.: 82.81%] [G loss: 1.206345]\n",
      "epoch:27 step:25434 [D loss: 0.615764, acc.: 60.16%] [G loss: 0.879026]\n",
      "epoch:27 step:25435 [D loss: 0.647621, acc.: 60.16%] [G loss: 0.949948]\n",
      "epoch:27 step:25436 [D loss: 0.694802, acc.: 55.47%] [G loss: 0.867972]\n",
      "epoch:27 step:25437 [D loss: 0.644533, acc.: 61.72%] [G loss: 0.873501]\n",
      "epoch:27 step:25438 [D loss: 0.413795, acc.: 89.06%] [G loss: 0.996553]\n",
      "epoch:27 step:25439 [D loss: 0.516399, acc.: 77.34%] [G loss: 1.286515]\n",
      "epoch:27 step:25440 [D loss: 0.662493, acc.: 62.50%] [G loss: 1.165399]\n",
      "epoch:27 step:25441 [D loss: 0.576895, acc.: 73.44%] [G loss: 1.158387]\n",
      "epoch:27 step:25442 [D loss: 0.737087, acc.: 53.12%] [G loss: 0.913725]\n",
      "epoch:27 step:25443 [D loss: 0.561672, acc.: 71.09%] [G loss: 1.008821]\n",
      "epoch:27 step:25444 [D loss: 0.468574, acc.: 82.81%] [G loss: 1.411782]\n",
      "epoch:27 step:25445 [D loss: 0.721320, acc.: 55.47%] [G loss: 1.233453]\n",
      "epoch:27 step:25446 [D loss: 0.738296, acc.: 49.22%] [G loss: 1.090262]\n",
      "epoch:27 step:25447 [D loss: 0.664941, acc.: 64.06%] [G loss: 1.083251]\n",
      "epoch:27 step:25448 [D loss: 0.554885, acc.: 72.66%] [G loss: 0.957922]\n",
      "epoch:27 step:25449 [D loss: 0.668873, acc.: 61.72%] [G loss: 0.976851]\n",
      "epoch:27 step:25450 [D loss: 0.414310, acc.: 86.72%] [G loss: 1.288011]\n",
      "epoch:27 step:25451 [D loss: 0.328688, acc.: 92.97%] [G loss: 1.494167]\n",
      "epoch:27 step:25452 [D loss: 0.680703, acc.: 59.38%] [G loss: 1.340034]\n",
      "epoch:27 step:25453 [D loss: 1.406435, acc.: 25.78%] [G loss: 0.546898]\n",
      "epoch:27 step:25454 [D loss: 0.405937, acc.: 89.84%] [G loss: 1.393311]\n",
      "epoch:27 step:25455 [D loss: 0.305844, acc.: 91.41%] [G loss: 1.512703]\n",
      "epoch:27 step:25456 [D loss: 0.481486, acc.: 78.12%] [G loss: 1.695559]\n",
      "epoch:27 step:25457 [D loss: 0.331066, acc.: 93.75%] [G loss: 1.613004]\n",
      "epoch:27 step:25458 [D loss: 0.265950, acc.: 93.75%] [G loss: 1.324936]\n",
      "epoch:27 step:25459 [D loss: 0.611742, acc.: 67.97%] [G loss: 1.360941]\n",
      "epoch:27 step:25460 [D loss: 0.829676, acc.: 46.09%] [G loss: 1.087068]\n",
      "epoch:27 step:25461 [D loss: 0.549968, acc.: 80.47%] [G loss: 1.185309]\n",
      "epoch:27 step:25462 [D loss: 0.512153, acc.: 77.34%] [G loss: 1.132995]\n",
      "epoch:27 step:25463 [D loss: 0.395082, acc.: 89.84%] [G loss: 1.226115]\n",
      "epoch:27 step:25464 [D loss: 0.479313, acc.: 79.69%] [G loss: 1.004766]\n",
      "epoch:27 step:25465 [D loss: 0.496176, acc.: 75.78%] [G loss: 1.061688]\n",
      "epoch:27 step:25466 [D loss: 0.332574, acc.: 95.31%] [G loss: 1.391965]\n",
      "epoch:27 step:25467 [D loss: 0.526777, acc.: 71.09%] [G loss: 1.085242]\n",
      "epoch:27 step:25468 [D loss: 0.528329, acc.: 74.22%] [G loss: 1.528894]\n",
      "epoch:27 step:25469 [D loss: 0.738664, acc.: 57.81%] [G loss: 0.867803]\n",
      "epoch:27 step:25470 [D loss: 0.667224, acc.: 61.72%] [G loss: 0.999711]\n",
      "epoch:27 step:25471 [D loss: 0.632638, acc.: 64.06%] [G loss: 1.004257]\n",
      "epoch:27 step:25472 [D loss: 0.737579, acc.: 46.88%] [G loss: 1.051450]\n",
      "epoch:27 step:25473 [D loss: 1.304983, acc.: 11.72%] [G loss: 0.468187]\n",
      "epoch:27 step:25474 [D loss: 0.724325, acc.: 52.34%] [G loss: 1.073255]\n",
      "epoch:27 step:25475 [D loss: 0.679834, acc.: 57.03%] [G loss: 1.260041]\n",
      "epoch:27 step:25476 [D loss: 1.210731, acc.: 19.53%] [G loss: 0.639966]\n",
      "epoch:27 step:25477 [D loss: 1.182858, acc.: 25.00%] [G loss: 0.662807]\n",
      "epoch:27 step:25478 [D loss: 1.102133, acc.: 21.88%] [G loss: 0.821881]\n",
      "epoch:27 step:25479 [D loss: 0.881922, acc.: 42.97%] [G loss: 1.068598]\n",
      "epoch:27 step:25480 [D loss: 0.850806, acc.: 36.72%] [G loss: 0.887329]\n",
      "epoch:27 step:25481 [D loss: 0.546650, acc.: 69.53%] [G loss: 1.545957]\n",
      "epoch:27 step:25482 [D loss: 0.838433, acc.: 44.53%] [G loss: 1.013107]\n",
      "epoch:27 step:25483 [D loss: 0.719180, acc.: 54.69%] [G loss: 0.831331]\n",
      "epoch:27 step:25484 [D loss: 1.064382, acc.: 18.75%] [G loss: 0.639262]\n",
      "epoch:27 step:25485 [D loss: 1.012279, acc.: 30.47%] [G loss: 0.598401]\n",
      "epoch:27 step:25486 [D loss: 0.809924, acc.: 44.53%] [G loss: 1.230463]\n",
      "epoch:27 step:25487 [D loss: 0.962966, acc.: 35.16%] [G loss: 0.788263]\n",
      "epoch:27 step:25488 [D loss: 0.808380, acc.: 47.66%] [G loss: 1.042550]\n",
      "epoch:27 step:25489 [D loss: 0.909970, acc.: 35.16%] [G loss: 0.899732]\n",
      "epoch:27 step:25490 [D loss: 0.803561, acc.: 44.53%] [G loss: 1.005267]\n",
      "epoch:27 step:25491 [D loss: 0.521961, acc.: 76.56%] [G loss: 1.035543]\n",
      "epoch:27 step:25492 [D loss: 0.589279, acc.: 69.53%] [G loss: 1.217263]\n",
      "epoch:27 step:25493 [D loss: 0.499362, acc.: 78.91%] [G loss: 1.299367]\n",
      "epoch:27 step:25494 [D loss: 0.665984, acc.: 63.28%] [G loss: 0.935116]\n",
      "epoch:27 step:25495 [D loss: 0.824059, acc.: 46.88%] [G loss: 0.995350]\n",
      "epoch:27 step:25496 [D loss: 0.758187, acc.: 50.78%] [G loss: 0.879591]\n",
      "epoch:27 step:25497 [D loss: 0.743222, acc.: 52.34%] [G loss: 1.030439]\n",
      "epoch:27 step:25498 [D loss: 0.723014, acc.: 54.69%] [G loss: 1.028454]\n",
      "epoch:27 step:25499 [D loss: 0.597066, acc.: 68.75%] [G loss: 1.133240]\n",
      "epoch:27 step:25500 [D loss: 0.465702, acc.: 83.59%] [G loss: 1.390927]\n",
      "epoch:27 step:25501 [D loss: 0.826462, acc.: 42.97%] [G loss: 1.073916]\n",
      "epoch:27 step:25502 [D loss: 0.677922, acc.: 57.81%] [G loss: 1.027474]\n",
      "epoch:27 step:25503 [D loss: 0.660263, acc.: 57.81%] [G loss: 0.912727]\n",
      "epoch:27 step:25504 [D loss: 0.770309, acc.: 50.00%] [G loss: 0.848560]\n",
      "epoch:27 step:25505 [D loss: 0.559380, acc.: 67.19%] [G loss: 1.099760]\n",
      "epoch:27 step:25506 [D loss: 0.646027, acc.: 62.50%] [G loss: 0.927679]\n",
      "epoch:27 step:25507 [D loss: 0.812870, acc.: 46.09%] [G loss: 0.884528]\n",
      "epoch:27 step:25508 [D loss: 0.588845, acc.: 67.19%] [G loss: 1.039768]\n",
      "epoch:27 step:25509 [D loss: 0.696367, acc.: 60.94%] [G loss: 1.123657]\n",
      "epoch:27 step:25510 [D loss: 0.432329, acc.: 79.69%] [G loss: 1.396942]\n",
      "epoch:27 step:25511 [D loss: 0.622689, acc.: 68.75%] [G loss: 0.851649]\n",
      "epoch:27 step:25512 [D loss: 0.560976, acc.: 73.44%] [G loss: 1.176833]\n",
      "epoch:27 step:25513 [D loss: 0.685899, acc.: 63.28%] [G loss: 1.192773]\n",
      "epoch:27 step:25514 [D loss: 0.558517, acc.: 74.22%] [G loss: 1.203110]\n",
      "epoch:27 step:25515 [D loss: 0.743180, acc.: 52.34%] [G loss: 0.955672]\n",
      "epoch:27 step:25516 [D loss: 0.740759, acc.: 53.91%] [G loss: 0.952664]\n",
      "epoch:27 step:25517 [D loss: 0.834600, acc.: 45.31%] [G loss: 0.917589]\n",
      "epoch:27 step:25518 [D loss: 0.647405, acc.: 61.72%] [G loss: 1.124959]\n",
      "epoch:27 step:25519 [D loss: 0.356736, acc.: 85.94%] [G loss: 1.385523]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25520 [D loss: 0.282378, acc.: 95.31%] [G loss: 1.478927]\n",
      "epoch:27 step:25521 [D loss: 0.397351, acc.: 85.16%] [G loss: 1.389607]\n",
      "epoch:27 step:25522 [D loss: 0.255157, acc.: 94.53%] [G loss: 1.568882]\n",
      "epoch:27 step:25523 [D loss: 0.827420, acc.: 50.78%] [G loss: 1.206134]\n",
      "epoch:27 step:25524 [D loss: 0.723912, acc.: 54.69%] [G loss: 1.049484]\n",
      "epoch:27 step:25525 [D loss: 0.437335, acc.: 86.72%] [G loss: 1.239202]\n",
      "epoch:27 step:25526 [D loss: 0.705216, acc.: 51.56%] [G loss: 1.171756]\n",
      "epoch:27 step:25527 [D loss: 0.602933, acc.: 67.19%] [G loss: 1.148470]\n",
      "epoch:27 step:25528 [D loss: 0.444713, acc.: 83.59%] [G loss: 1.483305]\n",
      "epoch:27 step:25529 [D loss: 0.178278, acc.: 99.22%] [G loss: 1.826545]\n",
      "epoch:27 step:25530 [D loss: 0.211153, acc.: 96.88%] [G loss: 1.427627]\n",
      "epoch:27 step:25531 [D loss: 0.195579, acc.: 96.88%] [G loss: 2.039010]\n",
      "epoch:27 step:25532 [D loss: 0.835376, acc.: 51.56%] [G loss: 1.569101]\n",
      "epoch:27 step:25533 [D loss: 0.903553, acc.: 34.38%] [G loss: 0.957439]\n",
      "epoch:27 step:25534 [D loss: 0.347516, acc.: 90.62%] [G loss: 1.179110]\n",
      "epoch:27 step:25535 [D loss: 0.770973, acc.: 53.12%] [G loss: 0.911688]\n",
      "epoch:27 step:25536 [D loss: 0.586030, acc.: 70.31%] [G loss: 1.221551]\n",
      "epoch:27 step:25537 [D loss: 0.620029, acc.: 64.06%] [G loss: 1.089398]\n",
      "epoch:27 step:25538 [D loss: 0.643373, acc.: 60.94%] [G loss: 1.309764]\n",
      "epoch:27 step:25539 [D loss: 0.808147, acc.: 47.66%] [G loss: 1.128850]\n",
      "epoch:27 step:25540 [D loss: 1.029499, acc.: 33.59%] [G loss: 0.749992]\n",
      "epoch:27 step:25541 [D loss: 0.638413, acc.: 63.28%] [G loss: 1.047280]\n",
      "epoch:27 step:25542 [D loss: 0.682020, acc.: 62.50%] [G loss: 0.878840]\n",
      "epoch:27 step:25543 [D loss: 1.080134, acc.: 27.34%] [G loss: 0.860117]\n",
      "epoch:27 step:25544 [D loss: 0.845863, acc.: 41.41%] [G loss: 1.131995]\n",
      "epoch:27 step:25545 [D loss: 0.719552, acc.: 53.91%] [G loss: 1.110477]\n",
      "epoch:27 step:25546 [D loss: 0.781132, acc.: 48.44%] [G loss: 1.061186]\n",
      "epoch:27 step:25547 [D loss: 0.539984, acc.: 77.34%] [G loss: 1.273626]\n",
      "epoch:27 step:25548 [D loss: 0.889918, acc.: 31.25%] [G loss: 0.841882]\n",
      "epoch:27 step:25549 [D loss: 0.581518, acc.: 71.09%] [G loss: 1.205366]\n",
      "epoch:27 step:25550 [D loss: 0.673221, acc.: 64.06%] [G loss: 0.969614]\n",
      "epoch:27 step:25551 [D loss: 0.552416, acc.: 68.75%] [G loss: 1.064579]\n",
      "epoch:27 step:25552 [D loss: 0.552533, acc.: 73.44%] [G loss: 1.330711]\n",
      "epoch:27 step:25553 [D loss: 0.533649, acc.: 78.12%] [G loss: 1.096270]\n",
      "epoch:27 step:25554 [D loss: 0.644316, acc.: 58.59%] [G loss: 1.037400]\n",
      "epoch:27 step:25555 [D loss: 0.749038, acc.: 52.34%] [G loss: 1.142203]\n",
      "epoch:27 step:25556 [D loss: 0.610728, acc.: 65.62%] [G loss: 1.041957]\n",
      "epoch:27 step:25557 [D loss: 0.547935, acc.: 71.88%] [G loss: 1.224683]\n",
      "epoch:27 step:25558 [D loss: 0.529953, acc.: 76.56%] [G loss: 0.905184]\n",
      "epoch:27 step:25559 [D loss: 0.597695, acc.: 67.19%] [G loss: 1.216352]\n",
      "epoch:27 step:25560 [D loss: 0.499650, acc.: 76.56%] [G loss: 1.159642]\n",
      "epoch:27 step:25561 [D loss: 0.633003, acc.: 64.84%] [G loss: 1.320042]\n",
      "epoch:27 step:25562 [D loss: 0.581756, acc.: 71.09%] [G loss: 1.222595]\n",
      "epoch:27 step:25563 [D loss: 0.447425, acc.: 86.72%] [G loss: 1.287046]\n",
      "epoch:27 step:25564 [D loss: 0.682481, acc.: 60.94%] [G loss: 1.208889]\n",
      "epoch:27 step:25565 [D loss: 0.707826, acc.: 52.34%] [G loss: 1.105430]\n",
      "epoch:27 step:25566 [D loss: 0.657698, acc.: 64.06%] [G loss: 0.688933]\n",
      "epoch:27 step:25567 [D loss: 0.778677, acc.: 45.31%] [G loss: 1.186077]\n",
      "epoch:27 step:25568 [D loss: 0.740777, acc.: 53.91%] [G loss: 1.110474]\n",
      "epoch:27 step:25569 [D loss: 0.561859, acc.: 70.31%] [G loss: 1.448754]\n",
      "epoch:27 step:25570 [D loss: 0.462481, acc.: 83.59%] [G loss: 1.432442]\n",
      "epoch:27 step:25571 [D loss: 0.407805, acc.: 79.69%] [G loss: 1.168426]\n",
      "epoch:27 step:25572 [D loss: 0.345259, acc.: 94.53%] [G loss: 1.651721]\n",
      "epoch:27 step:25573 [D loss: 0.489024, acc.: 80.47%] [G loss: 1.441927]\n",
      "epoch:27 step:25574 [D loss: 0.647221, acc.: 60.16%] [G loss: 0.969613]\n",
      "epoch:27 step:25575 [D loss: 0.710641, acc.: 54.69%] [G loss: 1.099328]\n",
      "epoch:27 step:25576 [D loss: 0.792213, acc.: 53.91%] [G loss: 1.302085]\n",
      "epoch:27 step:25577 [D loss: 0.617187, acc.: 66.41%] [G loss: 1.318980]\n",
      "epoch:27 step:25578 [D loss: 0.336054, acc.: 91.41%] [G loss: 1.245910]\n",
      "epoch:27 step:25579 [D loss: 0.553239, acc.: 72.66%] [G loss: 1.157235]\n",
      "epoch:27 step:25580 [D loss: 0.718064, acc.: 58.59%] [G loss: 1.062219]\n",
      "epoch:27 step:25581 [D loss: 0.619451, acc.: 60.94%] [G loss: 1.218365]\n",
      "epoch:27 step:25582 [D loss: 0.835412, acc.: 39.84%] [G loss: 1.060927]\n",
      "epoch:27 step:25583 [D loss: 0.429073, acc.: 85.16%] [G loss: 1.225773]\n",
      "epoch:27 step:25584 [D loss: 0.397221, acc.: 87.50%] [G loss: 1.076184]\n",
      "epoch:27 step:25585 [D loss: 0.484457, acc.: 77.34%] [G loss: 1.122268]\n",
      "epoch:27 step:25586 [D loss: 0.495874, acc.: 73.44%] [G loss: 1.269717]\n",
      "epoch:27 step:25587 [D loss: 0.613358, acc.: 66.41%] [G loss: 1.237924]\n",
      "epoch:27 step:25588 [D loss: 0.455537, acc.: 85.16%] [G loss: 1.418375]\n",
      "epoch:27 step:25589 [D loss: 0.628509, acc.: 60.94%] [G loss: 0.920852]\n",
      "epoch:27 step:25590 [D loss: 0.292737, acc.: 92.19%] [G loss: 1.448279]\n",
      "epoch:27 step:25591 [D loss: 0.559080, acc.: 69.53%] [G loss: 1.161687]\n",
      "epoch:27 step:25592 [D loss: 0.301814, acc.: 94.53%] [G loss: 1.463056]\n",
      "epoch:27 step:25593 [D loss: 0.619230, acc.: 68.75%] [G loss: 1.019735]\n",
      "epoch:27 step:25594 [D loss: 0.812123, acc.: 46.09%] [G loss: 1.356591]\n",
      "epoch:27 step:25595 [D loss: 0.630886, acc.: 60.94%] [G loss: 1.144246]\n",
      "epoch:27 step:25596 [D loss: 0.784791, acc.: 46.09%] [G loss: 1.087247]\n",
      "epoch:27 step:25597 [D loss: 0.404441, acc.: 90.62%] [G loss: 1.295567]\n",
      "epoch:27 step:25598 [D loss: 0.640388, acc.: 62.50%] [G loss: 0.885682]\n",
      "epoch:27 step:25599 [D loss: 0.594289, acc.: 71.09%] [G loss: 0.928570]\n",
      "epoch:27 step:25600 [D loss: 0.624939, acc.: 67.19%] [G loss: 1.140146]\n",
      "##############\n",
      "[2.23572879 1.33027455 5.53729042 4.29683059 2.97357989 5.28733486\n",
      " 4.16761998 4.57000099 4.00690881 3.65160906]\n",
      "##########\n",
      "epoch:27 step:25601 [D loss: 0.674098, acc.: 59.38%] [G loss: 1.144703]\n",
      "epoch:27 step:25602 [D loss: 0.696496, acc.: 57.03%] [G loss: 1.014275]\n",
      "epoch:27 step:25603 [D loss: 0.578151, acc.: 73.44%] [G loss: 1.108248]\n",
      "epoch:27 step:25604 [D loss: 0.509432, acc.: 77.34%] [G loss: 0.968098]\n",
      "epoch:27 step:25605 [D loss: 0.654041, acc.: 60.16%] [G loss: 0.970079]\n",
      "epoch:27 step:25606 [D loss: 0.577682, acc.: 67.97%] [G loss: 1.026326]\n",
      "epoch:27 step:25607 [D loss: 0.384611, acc.: 86.72%] [G loss: 1.093913]\n",
      "epoch:27 step:25608 [D loss: 0.313255, acc.: 90.62%] [G loss: 1.366352]\n",
      "epoch:27 step:25609 [D loss: 0.510851, acc.: 75.78%] [G loss: 1.322614]\n",
      "epoch:27 step:25610 [D loss: 0.432003, acc.: 85.16%] [G loss: 1.219184]\n",
      "epoch:27 step:25611 [D loss: 0.235366, acc.: 99.22%] [G loss: 1.702666]\n",
      "epoch:27 step:25612 [D loss: 0.320682, acc.: 93.75%] [G loss: 1.420932]\n",
      "epoch:27 step:25613 [D loss: 0.235763, acc.: 98.44%] [G loss: 1.570506]\n",
      "epoch:27 step:25614 [D loss: 0.485674, acc.: 78.91%] [G loss: 1.136466]\n",
      "epoch:27 step:25615 [D loss: 0.944644, acc.: 44.53%] [G loss: 1.274719]\n",
      "epoch:27 step:25616 [D loss: 0.819518, acc.: 40.62%] [G loss: 1.180899]\n",
      "epoch:27 step:25617 [D loss: 0.750718, acc.: 50.00%] [G loss: 1.165323]\n",
      "epoch:27 step:25618 [D loss: 0.830489, acc.: 39.84%] [G loss: 1.212297]\n",
      "epoch:27 step:25619 [D loss: 0.713335, acc.: 54.69%] [G loss: 0.931011]\n",
      "epoch:27 step:25620 [D loss: 0.557550, acc.: 71.09%] [G loss: 1.188444]\n",
      "epoch:27 step:25621 [D loss: 0.491404, acc.: 79.69%] [G loss: 1.335529]\n",
      "epoch:27 step:25622 [D loss: 0.615857, acc.: 63.28%] [G loss: 1.326724]\n",
      "epoch:27 step:25623 [D loss: 0.605331, acc.: 70.31%] [G loss: 1.384947]\n",
      "epoch:27 step:25624 [D loss: 0.608169, acc.: 72.66%] [G loss: 1.211655]\n",
      "epoch:27 step:25625 [D loss: 0.469629, acc.: 77.34%] [G loss: 1.236486]\n",
      "epoch:27 step:25626 [D loss: 0.369687, acc.: 89.06%] [G loss: 1.000028]\n",
      "epoch:27 step:25627 [D loss: 0.283959, acc.: 96.09%] [G loss: 1.337257]\n",
      "epoch:27 step:25628 [D loss: 0.562337, acc.: 73.44%] [G loss: 1.287774]\n",
      "epoch:27 step:25629 [D loss: 0.731112, acc.: 53.12%] [G loss: 0.972635]\n",
      "epoch:27 step:25630 [D loss: 0.668843, acc.: 56.25%] [G loss: 1.006007]\n",
      "epoch:27 step:25631 [D loss: 0.527066, acc.: 75.78%] [G loss: 1.151608]\n",
      "epoch:27 step:25632 [D loss: 0.601234, acc.: 66.41%] [G loss: 1.089314]\n",
      "epoch:27 step:25633 [D loss: 0.681917, acc.: 57.81%] [G loss: 0.933162]\n",
      "epoch:27 step:25634 [D loss: 0.567897, acc.: 67.19%] [G loss: 1.430832]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25635 [D loss: 0.533196, acc.: 76.56%] [G loss: 1.105561]\n",
      "epoch:27 step:25636 [D loss: 0.587893, acc.: 67.97%] [G loss: 0.925598]\n",
      "epoch:27 step:25637 [D loss: 0.550109, acc.: 72.66%] [G loss: 1.121346]\n",
      "epoch:27 step:25638 [D loss: 0.488614, acc.: 79.69%] [G loss: 1.337129]\n",
      "epoch:27 step:25639 [D loss: 0.654301, acc.: 61.72%] [G loss: 0.966610]\n",
      "epoch:27 step:25640 [D loss: 0.743864, acc.: 50.78%] [G loss: 0.997894]\n",
      "epoch:27 step:25641 [D loss: 0.769664, acc.: 50.78%] [G loss: 0.690830]\n",
      "epoch:27 step:25642 [D loss: 0.333577, acc.: 90.62%] [G loss: 1.542046]\n",
      "epoch:27 step:25643 [D loss: 0.524661, acc.: 72.66%] [G loss: 1.173158]\n",
      "epoch:27 step:25644 [D loss: 0.390800, acc.: 86.72%] [G loss: 1.260587]\n",
      "epoch:27 step:25645 [D loss: 0.232865, acc.: 97.66%] [G loss: 1.629558]\n",
      "epoch:27 step:25646 [D loss: 0.229938, acc.: 96.88%] [G loss: 1.287833]\n",
      "epoch:27 step:25647 [D loss: 0.803997, acc.: 50.00%] [G loss: 1.367435]\n",
      "epoch:27 step:25648 [D loss: 0.707721, acc.: 60.16%] [G loss: 1.213758]\n",
      "epoch:27 step:25649 [D loss: 0.752731, acc.: 53.91%] [G loss: 1.035909]\n",
      "epoch:27 step:25650 [D loss: 0.427721, acc.: 88.28%] [G loss: 1.097680]\n",
      "epoch:27 step:25651 [D loss: 0.465978, acc.: 77.34%] [G loss: 0.951527]\n",
      "epoch:27 step:25652 [D loss: 0.543102, acc.: 76.56%] [G loss: 1.176386]\n",
      "epoch:27 step:25653 [D loss: 0.438546, acc.: 82.81%] [G loss: 1.205196]\n",
      "epoch:27 step:25654 [D loss: 0.747511, acc.: 53.91%] [G loss: 1.116103]\n",
      "epoch:27 step:25655 [D loss: 0.768825, acc.: 48.44%] [G loss: 1.053699]\n",
      "epoch:27 step:25656 [D loss: 0.687086, acc.: 57.03%] [G loss: 1.065371]\n",
      "epoch:27 step:25657 [D loss: 0.432783, acc.: 89.06%] [G loss: 1.079783]\n",
      "epoch:27 step:25658 [D loss: 0.482858, acc.: 82.81%] [G loss: 0.985994]\n",
      "epoch:27 step:25659 [D loss: 0.644684, acc.: 60.94%] [G loss: 0.781361]\n",
      "epoch:27 step:25660 [D loss: 0.822527, acc.: 39.84%] [G loss: 0.862490]\n",
      "epoch:27 step:25661 [D loss: 0.907151, acc.: 28.12%] [G loss: 1.021039]\n",
      "epoch:27 step:25662 [D loss: 0.691582, acc.: 61.72%] [G loss: 1.162677]\n",
      "epoch:27 step:25663 [D loss: 0.564104, acc.: 72.66%] [G loss: 1.079560]\n",
      "epoch:27 step:25664 [D loss: 0.415197, acc.: 91.41%] [G loss: 1.253385]\n",
      "epoch:27 step:25665 [D loss: 0.227093, acc.: 96.09%] [G loss: 1.603377]\n",
      "epoch:27 step:25666 [D loss: 0.231103, acc.: 98.44%] [G loss: 1.519008]\n",
      "epoch:27 step:25667 [D loss: 0.559203, acc.: 69.53%] [G loss: 1.832118]\n",
      "epoch:27 step:25668 [D loss: 0.779765, acc.: 50.78%] [G loss: 1.187006]\n",
      "epoch:27 step:25669 [D loss: 0.625635, acc.: 66.41%] [G loss: 1.258528]\n",
      "epoch:27 step:25670 [D loss: 0.573041, acc.: 74.22%] [G loss: 1.340902]\n",
      "epoch:27 step:25671 [D loss: 0.822134, acc.: 40.62%] [G loss: 0.854521]\n",
      "epoch:27 step:25672 [D loss: 0.705317, acc.: 58.59%] [G loss: 1.089249]\n",
      "epoch:27 step:25673 [D loss: 0.699141, acc.: 60.16%] [G loss: 1.168677]\n",
      "epoch:27 step:25674 [D loss: 0.790603, acc.: 50.78%] [G loss: 0.918062]\n",
      "epoch:27 step:25675 [D loss: 0.592677, acc.: 67.97%] [G loss: 1.097004]\n",
      "epoch:27 step:25676 [D loss: 0.477928, acc.: 75.78%] [G loss: 1.109511]\n",
      "epoch:27 step:25677 [D loss: 0.344539, acc.: 87.50%] [G loss: 1.193359]\n",
      "epoch:27 step:25678 [D loss: 0.694915, acc.: 56.25%] [G loss: 1.212424]\n",
      "epoch:27 step:25679 [D loss: 0.559438, acc.: 72.66%] [G loss: 1.011734]\n",
      "epoch:27 step:25680 [D loss: 0.531609, acc.: 75.00%] [G loss: 0.989287]\n",
      "epoch:27 step:25681 [D loss: 0.782204, acc.: 47.66%] [G loss: 0.888800]\n",
      "epoch:27 step:25682 [D loss: 0.581531, acc.: 68.75%] [G loss: 0.987602]\n",
      "epoch:27 step:25683 [D loss: 0.712533, acc.: 53.12%] [G loss: 0.931739]\n",
      "epoch:27 step:25684 [D loss: 0.571725, acc.: 68.75%] [G loss: 0.991705]\n",
      "epoch:27 step:25685 [D loss: 0.823008, acc.: 44.53%] [G loss: 1.024632]\n",
      "epoch:27 step:25686 [D loss: 0.555893, acc.: 72.66%] [G loss: 1.086413]\n",
      "epoch:27 step:25687 [D loss: 0.611629, acc.: 64.06%] [G loss: 0.985356]\n",
      "epoch:27 step:25688 [D loss: 0.573996, acc.: 71.09%] [G loss: 0.951309]\n",
      "epoch:27 step:25689 [D loss: 0.411722, acc.: 87.50%] [G loss: 1.148761]\n",
      "epoch:27 step:25690 [D loss: 0.476645, acc.: 82.03%] [G loss: 1.135949]\n",
      "epoch:27 step:25691 [D loss: 0.554153, acc.: 70.31%] [G loss: 0.999993]\n",
      "epoch:27 step:25692 [D loss: 0.554824, acc.: 72.66%] [G loss: 1.214705]\n",
      "epoch:27 step:25693 [D loss: 0.375491, acc.: 87.50%] [G loss: 1.296418]\n",
      "epoch:27 step:25694 [D loss: 0.946080, acc.: 43.75%] [G loss: 0.614988]\n",
      "epoch:27 step:25695 [D loss: 0.245317, acc.: 94.53%] [G loss: 1.869912]\n",
      "epoch:27 step:25696 [D loss: 0.174433, acc.: 98.44%] [G loss: 1.606009]\n",
      "epoch:27 step:25697 [D loss: 0.215980, acc.: 98.44%] [G loss: 1.775180]\n",
      "epoch:27 step:25698 [D loss: 0.251873, acc.: 97.66%] [G loss: 2.093221]\n",
      "epoch:27 step:25699 [D loss: 0.286511, acc.: 92.19%] [G loss: 2.002271]\n",
      "epoch:27 step:25700 [D loss: 0.364897, acc.: 88.28%] [G loss: 1.399543]\n",
      "epoch:27 step:25701 [D loss: 0.317546, acc.: 88.28%] [G loss: 1.896076]\n",
      "epoch:27 step:25702 [D loss: 0.545211, acc.: 75.00%] [G loss: 1.321388]\n",
      "epoch:27 step:25703 [D loss: 0.186867, acc.: 99.22%] [G loss: 1.928597]\n",
      "epoch:27 step:25704 [D loss: 0.274173, acc.: 93.75%] [G loss: 1.563330]\n",
      "epoch:27 step:25705 [D loss: 0.331532, acc.: 93.75%] [G loss: 2.053404]\n",
      "epoch:27 step:25706 [D loss: 0.654589, acc.: 71.09%] [G loss: 1.725750]\n",
      "epoch:27 step:25707 [D loss: 0.737317, acc.: 59.38%] [G loss: 0.949025]\n",
      "epoch:27 step:25708 [D loss: 0.407749, acc.: 87.50%] [G loss: 1.801648]\n",
      "epoch:27 step:25709 [D loss: 1.159247, acc.: 32.81%] [G loss: 0.765267]\n",
      "epoch:27 step:25710 [D loss: 1.470629, acc.: 9.38%] [G loss: 0.775173]\n",
      "epoch:27 step:25711 [D loss: 1.231496, acc.: 16.41%] [G loss: 0.688120]\n",
      "epoch:27 step:25712 [D loss: 0.812036, acc.: 46.88%] [G loss: 0.835308]\n",
      "epoch:27 step:25713 [D loss: 0.809444, acc.: 43.75%] [G loss: 0.824989]\n",
      "epoch:27 step:25714 [D loss: 1.161161, acc.: 25.78%] [G loss: 0.697399]\n",
      "epoch:27 step:25715 [D loss: 0.968005, acc.: 35.16%] [G loss: 0.771882]\n",
      "epoch:27 step:25716 [D loss: 0.881119, acc.: 41.41%] [G loss: 1.239974]\n",
      "epoch:27 step:25717 [D loss: 0.738870, acc.: 55.47%] [G loss: 1.165777]\n",
      "epoch:27 step:25718 [D loss: 0.525007, acc.: 71.88%] [G loss: 0.977653]\n",
      "epoch:27 step:25719 [D loss: 0.766479, acc.: 55.47%] [G loss: 1.465486]\n",
      "epoch:27 step:25720 [D loss: 0.844654, acc.: 46.09%] [G loss: 1.205633]\n",
      "epoch:27 step:25721 [D loss: 0.739928, acc.: 56.25%] [G loss: 1.184658]\n",
      "epoch:27 step:25722 [D loss: 0.713468, acc.: 58.59%] [G loss: 1.200330]\n",
      "epoch:27 step:25723 [D loss: 0.758395, acc.: 52.34%] [G loss: 1.009028]\n",
      "epoch:27 step:25724 [D loss: 0.731427, acc.: 54.69%] [G loss: 1.241695]\n",
      "epoch:27 step:25725 [D loss: 0.646781, acc.: 58.59%] [G loss: 1.323253]\n",
      "epoch:27 step:25726 [D loss: 0.632628, acc.: 60.16%] [G loss: 1.221963]\n",
      "epoch:27 step:25727 [D loss: 0.769911, acc.: 50.78%] [G loss: 1.024243]\n",
      "epoch:27 step:25728 [D loss: 0.687390, acc.: 57.03%] [G loss: 1.253484]\n",
      "epoch:27 step:25729 [D loss: 0.602303, acc.: 66.41%] [G loss: 1.224164]\n",
      "epoch:27 step:25730 [D loss: 0.579267, acc.: 70.31%] [G loss: 1.029517]\n",
      "epoch:27 step:25731 [D loss: 0.649900, acc.: 59.38%] [G loss: 1.728789]\n",
      "epoch:27 step:25732 [D loss: 0.504054, acc.: 71.88%] [G loss: 1.540790]\n",
      "epoch:27 step:25733 [D loss: 0.424403, acc.: 86.72%] [G loss: 1.549925]\n",
      "epoch:27 step:25734 [D loss: 0.468031, acc.: 75.78%] [G loss: 1.191455]\n",
      "epoch:27 step:25735 [D loss: 0.568695, acc.: 71.09%] [G loss: 1.510497]\n",
      "epoch:27 step:25736 [D loss: 0.749007, acc.: 51.56%] [G loss: 1.183947]\n",
      "epoch:27 step:25737 [D loss: 0.994579, acc.: 29.69%] [G loss: 1.079801]\n",
      "epoch:27 step:25738 [D loss: 0.694597, acc.: 60.16%] [G loss: 1.214309]\n",
      "epoch:27 step:25739 [D loss: 0.661167, acc.: 55.47%] [G loss: 1.106486]\n",
      "epoch:27 step:25740 [D loss: 0.850883, acc.: 44.53%] [G loss: 0.989975]\n",
      "epoch:27 step:25741 [D loss: 0.677659, acc.: 60.16%] [G loss: 1.152935]\n",
      "epoch:27 step:25742 [D loss: 0.621225, acc.: 63.28%] [G loss: 1.217722]\n",
      "epoch:27 step:25743 [D loss: 0.549284, acc.: 77.34%] [G loss: 1.423973]\n",
      "epoch:27 step:25744 [D loss: 0.619339, acc.: 66.41%] [G loss: 1.239460]\n",
      "epoch:27 step:25745 [D loss: 0.868163, acc.: 42.97%] [G loss: 1.016804]\n",
      "epoch:27 step:25746 [D loss: 0.792577, acc.: 50.00%] [G loss: 0.998989]\n",
      "epoch:27 step:25747 [D loss: 0.721180, acc.: 57.03%] [G loss: 1.068645]\n",
      "epoch:27 step:25748 [D loss: 0.502166, acc.: 77.34%] [G loss: 1.435807]\n",
      "epoch:27 step:25749 [D loss: 0.634807, acc.: 63.28%] [G loss: 1.276516]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25750 [D loss: 0.485875, acc.: 82.81%] [G loss: 1.404072]\n",
      "epoch:27 step:25751 [D loss: 0.488808, acc.: 78.12%] [G loss: 1.392940]\n",
      "epoch:27 step:25752 [D loss: 0.537018, acc.: 75.00%] [G loss: 1.158857]\n",
      "epoch:27 step:25753 [D loss: 0.522522, acc.: 76.56%] [G loss: 1.056169]\n",
      "epoch:27 step:25754 [D loss: 0.616497, acc.: 64.06%] [G loss: 1.105464]\n",
      "epoch:27 step:25755 [D loss: 0.507161, acc.: 76.56%] [G loss: 1.481660]\n",
      "epoch:27 step:25756 [D loss: 0.460892, acc.: 82.81%] [G loss: 1.477589]\n",
      "epoch:27 step:25757 [D loss: 1.133743, acc.: 28.91%] [G loss: 0.975224]\n",
      "epoch:27 step:25758 [D loss: 0.871728, acc.: 40.62%] [G loss: 1.055818]\n",
      "epoch:27 step:25759 [D loss: 0.854189, acc.: 41.41%] [G loss: 1.052588]\n",
      "epoch:27 step:25760 [D loss: 0.873124, acc.: 39.06%] [G loss: 1.281756]\n",
      "epoch:27 step:25761 [D loss: 0.675614, acc.: 59.38%] [G loss: 1.120444]\n",
      "epoch:27 step:25762 [D loss: 0.835016, acc.: 50.78%] [G loss: 1.145136]\n",
      "epoch:27 step:25763 [D loss: 0.769133, acc.: 45.31%] [G loss: 0.899175]\n",
      "epoch:27 step:25764 [D loss: 0.659619, acc.: 64.84%] [G loss: 1.200413]\n",
      "epoch:27 step:25765 [D loss: 0.677812, acc.: 57.03%] [G loss: 1.024840]\n",
      "epoch:27 step:25766 [D loss: 0.675044, acc.: 64.06%] [G loss: 0.972980]\n",
      "epoch:27 step:25767 [D loss: 0.507773, acc.: 79.69%] [G loss: 1.183579]\n",
      "epoch:27 step:25768 [D loss: 0.555736, acc.: 71.09%] [G loss: 0.840597]\n",
      "epoch:27 step:25769 [D loss: 0.441092, acc.: 77.34%] [G loss: 1.288387]\n",
      "epoch:27 step:25770 [D loss: 0.244290, acc.: 96.09%] [G loss: 1.333293]\n",
      "epoch:27 step:25771 [D loss: 0.484872, acc.: 78.12%] [G loss: 1.521628]\n",
      "epoch:27 step:25772 [D loss: 0.607005, acc.: 64.84%] [G loss: 1.488768]\n",
      "epoch:27 step:25773 [D loss: 0.330109, acc.: 95.31%] [G loss: 1.821275]\n",
      "epoch:27 step:25774 [D loss: 0.421939, acc.: 85.16%] [G loss: 1.884876]\n",
      "epoch:27 step:25775 [D loss: 0.716374, acc.: 55.47%] [G loss: 1.257668]\n",
      "epoch:27 step:25776 [D loss: 0.692766, acc.: 56.25%] [G loss: 1.243185]\n",
      "epoch:27 step:25777 [D loss: 0.696940, acc.: 60.94%] [G loss: 0.869892]\n",
      "epoch:27 step:25778 [D loss: 0.423469, acc.: 83.59%] [G loss: 1.227726]\n",
      "epoch:27 step:25779 [D loss: 0.515096, acc.: 75.78%] [G loss: 0.907103]\n",
      "epoch:27 step:25780 [D loss: 0.446286, acc.: 85.16%] [G loss: 1.427040]\n",
      "epoch:27 step:25781 [D loss: 0.451120, acc.: 86.72%] [G loss: 1.242294]\n",
      "epoch:27 step:25782 [D loss: 0.603312, acc.: 69.53%] [G loss: 1.320069]\n",
      "epoch:27 step:25783 [D loss: 0.415785, acc.: 87.50%] [G loss: 1.257748]\n",
      "epoch:27 step:25784 [D loss: 0.455219, acc.: 84.38%] [G loss: 1.242925]\n",
      "epoch:27 step:25785 [D loss: 0.570762, acc.: 67.97%] [G loss: 1.279834]\n",
      "epoch:27 step:25786 [D loss: 0.430769, acc.: 83.59%] [G loss: 1.200733]\n",
      "epoch:27 step:25787 [D loss: 0.548918, acc.: 73.44%] [G loss: 1.050244]\n",
      "epoch:27 step:25788 [D loss: 0.649242, acc.: 62.50%] [G loss: 1.042279]\n",
      "epoch:27 step:25789 [D loss: 0.414176, acc.: 83.59%] [G loss: 1.422695]\n",
      "epoch:27 step:25790 [D loss: 0.508630, acc.: 77.34%] [G loss: 1.423168]\n",
      "epoch:27 step:25791 [D loss: 0.822499, acc.: 51.56%] [G loss: 1.443203]\n",
      "epoch:27 step:25792 [D loss: 0.684345, acc.: 57.03%] [G loss: 1.127688]\n",
      "epoch:27 step:25793 [D loss: 0.719247, acc.: 50.00%] [G loss: 0.849659]\n",
      "epoch:27 step:25794 [D loss: 0.567463, acc.: 71.09%] [G loss: 1.201072]\n",
      "epoch:27 step:25795 [D loss: 0.557269, acc.: 73.44%] [G loss: 1.124980]\n",
      "epoch:27 step:25796 [D loss: 0.434445, acc.: 82.03%] [G loss: 1.474509]\n",
      "epoch:27 step:25797 [D loss: 0.347943, acc.: 92.19%] [G loss: 1.401073]\n",
      "epoch:27 step:25798 [D loss: 0.273177, acc.: 93.75%] [G loss: 1.633774]\n",
      "epoch:27 step:25799 [D loss: 0.700716, acc.: 57.03%] [G loss: 1.351089]\n",
      "epoch:27 step:25800 [D loss: 0.785993, acc.: 51.56%] [G loss: 1.059129]\n",
      "##############\n",
      "[2.61914175 1.83548559 5.55390004 4.36655188 3.40335891 5.64244148\n",
      " 4.28809686 4.7106671  4.03698358 3.92890124]\n",
      "##########\n",
      "epoch:27 step:25801 [D loss: 0.678194, acc.: 61.72%] [G loss: 0.908355]\n",
      "epoch:27 step:25802 [D loss: 0.352432, acc.: 78.91%] [G loss: 1.190493]\n",
      "epoch:27 step:25803 [D loss: 0.212131, acc.: 96.88%] [G loss: 1.410841]\n",
      "epoch:27 step:25804 [D loss: 0.350173, acc.: 92.19%] [G loss: 1.420306]\n",
      "epoch:27 step:25805 [D loss: 0.479710, acc.: 81.25%] [G loss: 1.567763]\n",
      "epoch:27 step:25806 [D loss: 0.383341, acc.: 89.84%] [G loss: 1.586854]\n",
      "epoch:27 step:25807 [D loss: 0.281260, acc.: 92.97%] [G loss: 1.235722]\n",
      "epoch:27 step:25808 [D loss: 0.851751, acc.: 48.44%] [G loss: 1.347836]\n",
      "epoch:27 step:25809 [D loss: 0.809820, acc.: 46.09%] [G loss: 0.948688]\n",
      "epoch:27 step:25810 [D loss: 0.383899, acc.: 85.94%] [G loss: 1.194613]\n",
      "epoch:27 step:25811 [D loss: 0.340338, acc.: 92.97%] [G loss: 1.368701]\n",
      "epoch:27 step:25812 [D loss: 0.243090, acc.: 100.00%] [G loss: 1.424328]\n",
      "epoch:27 step:25813 [D loss: 0.381643, acc.: 89.06%] [G loss: 1.545451]\n",
      "epoch:27 step:25814 [D loss: 0.341044, acc.: 92.19%] [G loss: 1.636964]\n",
      "epoch:27 step:25815 [D loss: 0.525880, acc.: 71.88%] [G loss: 1.386922]\n",
      "epoch:27 step:25816 [D loss: 0.588106, acc.: 68.75%] [G loss: 1.103645]\n",
      "epoch:27 step:25817 [D loss: 0.569882, acc.: 67.97%] [G loss: 1.089056]\n",
      "epoch:27 step:25818 [D loss: 0.514368, acc.: 79.69%] [G loss: 1.073266]\n",
      "epoch:27 step:25819 [D loss: 0.492472, acc.: 77.34%] [G loss: 1.220602]\n",
      "epoch:27 step:25820 [D loss: 0.597405, acc.: 64.06%] [G loss: 0.953301]\n",
      "epoch:27 step:25821 [D loss: 0.430884, acc.: 88.28%] [G loss: 1.213236]\n",
      "epoch:27 step:25822 [D loss: 0.436826, acc.: 85.94%] [G loss: 1.087596]\n",
      "epoch:27 step:25823 [D loss: 0.420461, acc.: 87.50%] [G loss: 1.227613]\n",
      "epoch:27 step:25824 [D loss: 0.420451, acc.: 87.50%] [G loss: 1.218747]\n",
      "epoch:27 step:25825 [D loss: 0.347433, acc.: 89.84%] [G loss: 1.384745]\n",
      "epoch:27 step:25826 [D loss: 0.351895, acc.: 91.41%] [G loss: 1.308960]\n",
      "epoch:27 step:25827 [D loss: 0.428766, acc.: 85.16%] [G loss: 1.072642]\n",
      "epoch:27 step:25828 [D loss: 0.394357, acc.: 91.41%] [G loss: 1.359664]\n",
      "epoch:27 step:25829 [D loss: 0.411111, acc.: 85.16%] [G loss: 1.312167]\n",
      "epoch:27 step:25830 [D loss: 0.762980, acc.: 51.56%] [G loss: 1.273266]\n",
      "epoch:27 step:25831 [D loss: 0.667140, acc.: 60.94%] [G loss: 1.130507]\n",
      "epoch:27 step:25832 [D loss: 0.382285, acc.: 92.97%] [G loss: 1.548096]\n",
      "epoch:27 step:25833 [D loss: 0.525293, acc.: 76.56%] [G loss: 0.951250]\n",
      "epoch:27 step:25834 [D loss: 0.377601, acc.: 86.72%] [G loss: 1.245238]\n",
      "epoch:27 step:25835 [D loss: 0.277481, acc.: 93.75%] [G loss: 1.542365]\n",
      "epoch:27 step:25836 [D loss: 0.284332, acc.: 95.31%] [G loss: 1.597943]\n",
      "epoch:27 step:25837 [D loss: 0.534405, acc.: 71.09%] [G loss: 1.544743]\n",
      "epoch:27 step:25838 [D loss: 0.578454, acc.: 65.62%] [G loss: 1.180050]\n",
      "epoch:27 step:25839 [D loss: 0.530105, acc.: 73.44%] [G loss: 1.167753]\n",
      "epoch:27 step:25840 [D loss: 0.467595, acc.: 82.81%] [G loss: 1.196780]\n",
      "epoch:27 step:25841 [D loss: 1.211523, acc.: 14.06%] [G loss: 1.087971]\n",
      "epoch:27 step:25842 [D loss: 0.709405, acc.: 55.47%] [G loss: 1.051639]\n",
      "epoch:27 step:25843 [D loss: 0.840710, acc.: 44.53%] [G loss: 0.941101]\n",
      "epoch:27 step:25844 [D loss: 0.396144, acc.: 92.19%] [G loss: 1.320947]\n",
      "epoch:27 step:25845 [D loss: 0.416836, acc.: 85.94%] [G loss: 1.241008]\n",
      "epoch:27 step:25846 [D loss: 0.378598, acc.: 90.62%] [G loss: 1.322655]\n",
      "epoch:27 step:25847 [D loss: 0.441852, acc.: 85.16%] [G loss: 1.436047]\n",
      "epoch:27 step:25848 [D loss: 0.335899, acc.: 89.06%] [G loss: 1.226617]\n",
      "epoch:27 step:25849 [D loss: 0.346851, acc.: 91.41%] [G loss: 1.555229]\n",
      "epoch:27 step:25850 [D loss: 0.337601, acc.: 92.19%] [G loss: 1.265830]\n",
      "epoch:27 step:25851 [D loss: 0.400716, acc.: 84.38%] [G loss: 1.296463]\n",
      "epoch:27 step:25852 [D loss: 0.347526, acc.: 92.97%] [G loss: 1.432415]\n",
      "epoch:27 step:25853 [D loss: 0.336118, acc.: 91.41%] [G loss: 1.731256]\n",
      "epoch:27 step:25854 [D loss: 0.490915, acc.: 76.56%] [G loss: 1.260004]\n",
      "epoch:27 step:25855 [D loss: 0.305075, acc.: 91.41%] [G loss: 1.686492]\n",
      "epoch:27 step:25856 [D loss: 0.274354, acc.: 94.53%] [G loss: 2.046725]\n",
      "epoch:27 step:25857 [D loss: 0.442903, acc.: 90.62%] [G loss: 1.390395]\n",
      "epoch:27 step:25858 [D loss: 0.471968, acc.: 78.12%] [G loss: 1.948850]\n",
      "epoch:27 step:25859 [D loss: 0.741778, acc.: 51.56%] [G loss: 1.483807]\n",
      "epoch:27 step:25860 [D loss: 0.311213, acc.: 92.97%] [G loss: 1.286687]\n",
      "epoch:27 step:25861 [D loss: 0.797776, acc.: 44.53%] [G loss: 1.319288]\n",
      "epoch:27 step:25862 [D loss: 0.556651, acc.: 71.09%] [G loss: 1.425434]\n",
      "epoch:27 step:25863 [D loss: 0.497456, acc.: 85.94%] [G loss: 1.164056]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25864 [D loss: 0.588321, acc.: 66.41%] [G loss: 1.343564]\n",
      "epoch:27 step:25865 [D loss: 0.327060, acc.: 89.84%] [G loss: 1.353075]\n",
      "epoch:27 step:25866 [D loss: 0.246396, acc.: 98.44%] [G loss: 1.790834]\n",
      "epoch:27 step:25867 [D loss: 0.679397, acc.: 64.06%] [G loss: 1.365721]\n",
      "epoch:27 step:25868 [D loss: 0.945021, acc.: 35.94%] [G loss: 0.889028]\n",
      "epoch:27 step:25869 [D loss: 0.486198, acc.: 81.25%] [G loss: 1.190657]\n",
      "epoch:27 step:25870 [D loss: 0.479578, acc.: 78.91%] [G loss: 1.046112]\n",
      "epoch:27 step:25871 [D loss: 0.798759, acc.: 49.22%] [G loss: 0.821012]\n",
      "epoch:27 step:25872 [D loss: 0.565530, acc.: 71.88%] [G loss: 1.317830]\n",
      "epoch:27 step:25873 [D loss: 0.398860, acc.: 85.16%] [G loss: 1.790113]\n",
      "epoch:27 step:25874 [D loss: 0.465929, acc.: 82.03%] [G loss: 1.532064]\n",
      "epoch:27 step:25875 [D loss: 0.346037, acc.: 86.72%] [G loss: 1.528823]\n",
      "epoch:27 step:25876 [D loss: 0.373838, acc.: 89.06%] [G loss: 1.620831]\n",
      "epoch:27 step:25877 [D loss: 0.328041, acc.: 93.75%] [G loss: 1.447667]\n",
      "epoch:27 step:25878 [D loss: 0.406606, acc.: 88.28%] [G loss: 1.392848]\n",
      "epoch:27 step:25879 [D loss: 0.667782, acc.: 59.38%] [G loss: 0.856405]\n",
      "epoch:27 step:25880 [D loss: 0.551713, acc.: 71.88%] [G loss: 1.173881]\n",
      "epoch:27 step:25881 [D loss: 0.586370, acc.: 67.97%] [G loss: 1.298190]\n",
      "epoch:27 step:25882 [D loss: 0.521966, acc.: 78.91%] [G loss: 1.236789]\n",
      "epoch:27 step:25883 [D loss: 0.834070, acc.: 42.19%] [G loss: 0.706316]\n",
      "epoch:27 step:25884 [D loss: 0.822115, acc.: 50.00%] [G loss: 0.718698]\n",
      "epoch:27 step:25885 [D loss: 0.615415, acc.: 67.19%] [G loss: 1.552728]\n",
      "epoch:27 step:25886 [D loss: 0.595077, acc.: 65.62%] [G loss: 1.141480]\n",
      "epoch:27 step:25887 [D loss: 0.209660, acc.: 98.44%] [G loss: 1.849774]\n",
      "epoch:27 step:25888 [D loss: 0.237137, acc.: 96.88%] [G loss: 2.308336]\n",
      "epoch:27 step:25889 [D loss: 0.934468, acc.: 44.53%] [G loss: 1.528485]\n",
      "epoch:27 step:25890 [D loss: 1.067507, acc.: 25.78%] [G loss: 1.137614]\n",
      "epoch:27 step:25891 [D loss: 0.731555, acc.: 54.69%] [G loss: 0.997619]\n",
      "epoch:27 step:25892 [D loss: 0.860516, acc.: 50.78%] [G loss: 1.322325]\n",
      "epoch:27 step:25893 [D loss: 0.686867, acc.: 58.59%] [G loss: 1.782376]\n",
      "epoch:27 step:25894 [D loss: 0.676675, acc.: 57.81%] [G loss: 0.981683]\n",
      "epoch:27 step:25895 [D loss: 0.694534, acc.: 55.47%] [G loss: 1.082941]\n",
      "epoch:27 step:25896 [D loss: 0.343960, acc.: 89.84%] [G loss: 1.651864]\n",
      "epoch:27 step:25897 [D loss: 0.371339, acc.: 88.28%] [G loss: 1.242970]\n",
      "epoch:27 step:25898 [D loss: 0.522216, acc.: 71.88%] [G loss: 1.445294]\n",
      "epoch:27 step:25899 [D loss: 0.654758, acc.: 56.25%] [G loss: 1.055415]\n",
      "epoch:27 step:25900 [D loss: 0.611083, acc.: 71.09%] [G loss: 1.147012]\n",
      "epoch:27 step:25901 [D loss: 0.605481, acc.: 66.41%] [G loss: 1.259916]\n",
      "epoch:27 step:25902 [D loss: 0.358130, acc.: 84.38%] [G loss: 1.241239]\n",
      "epoch:27 step:25903 [D loss: 0.261092, acc.: 96.09%] [G loss: 1.438042]\n",
      "epoch:27 step:25904 [D loss: 0.297281, acc.: 97.66%] [G loss: 1.718807]\n",
      "epoch:27 step:25905 [D loss: 0.668785, acc.: 66.41%] [G loss: 1.491666]\n",
      "epoch:27 step:25906 [D loss: 0.588579, acc.: 68.75%] [G loss: 1.267138]\n",
      "epoch:27 step:25907 [D loss: 0.588099, acc.: 68.75%] [G loss: 1.204604]\n",
      "epoch:27 step:25908 [D loss: 0.679310, acc.: 59.38%] [G loss: 1.107639]\n",
      "epoch:27 step:25909 [D loss: 0.481306, acc.: 75.00%] [G loss: 1.407412]\n",
      "epoch:27 step:25910 [D loss: 0.782542, acc.: 50.78%] [G loss: 1.411131]\n",
      "epoch:27 step:25911 [D loss: 0.639424, acc.: 65.62%] [G loss: 1.096600]\n",
      "epoch:27 step:25912 [D loss: 0.372599, acc.: 89.84%] [G loss: 1.196587]\n",
      "epoch:27 step:25913 [D loss: 0.349384, acc.: 85.94%] [G loss: 1.304378]\n",
      "epoch:27 step:25914 [D loss: 0.170818, acc.: 99.22%] [G loss: 2.113911]\n",
      "epoch:27 step:25915 [D loss: 0.500475, acc.: 71.88%] [G loss: 1.063854]\n",
      "epoch:27 step:25916 [D loss: 0.413071, acc.: 83.59%] [G loss: 1.658489]\n",
      "epoch:27 step:25917 [D loss: 1.101917, acc.: 42.19%] [G loss: 1.118512]\n",
      "epoch:27 step:25918 [D loss: 0.908275, acc.: 35.16%] [G loss: 0.997489]\n",
      "epoch:27 step:25919 [D loss: 0.858509, acc.: 31.25%] [G loss: 0.833543]\n",
      "epoch:27 step:25920 [D loss: 0.999431, acc.: 32.03%] [G loss: 0.893968]\n",
      "epoch:27 step:25921 [D loss: 0.577899, acc.: 73.44%] [G loss: 1.239501]\n",
      "epoch:27 step:25922 [D loss: 0.559784, acc.: 71.09%] [G loss: 1.345311]\n",
      "epoch:27 step:25923 [D loss: 0.515353, acc.: 74.22%] [G loss: 1.135230]\n",
      "epoch:27 step:25924 [D loss: 0.873574, acc.: 44.53%] [G loss: 1.024601]\n",
      "epoch:27 step:25925 [D loss: 0.685117, acc.: 61.72%] [G loss: 1.199825]\n",
      "epoch:27 step:25926 [D loss: 0.921541, acc.: 33.59%] [G loss: 0.892606]\n",
      "epoch:27 step:25927 [D loss: 0.753821, acc.: 52.34%] [G loss: 1.010130]\n",
      "epoch:27 step:25928 [D loss: 0.382660, acc.: 84.38%] [G loss: 1.152645]\n",
      "epoch:27 step:25929 [D loss: 0.447068, acc.: 84.38%] [G loss: 1.296906]\n",
      "epoch:27 step:25930 [D loss: 0.560448, acc.: 69.53%] [G loss: 0.956348]\n",
      "epoch:27 step:25931 [D loss: 0.490381, acc.: 81.25%] [G loss: 0.994541]\n",
      "epoch:27 step:25932 [D loss: 0.360444, acc.: 91.41%] [G loss: 1.533057]\n",
      "epoch:27 step:25933 [D loss: 0.484665, acc.: 80.47%] [G loss: 1.334637]\n",
      "epoch:27 step:25934 [D loss: 0.888800, acc.: 40.62%] [G loss: 0.899446]\n",
      "epoch:27 step:25935 [D loss: 1.070328, acc.: 23.44%] [G loss: 0.906457]\n",
      "epoch:27 step:25936 [D loss: 1.258806, acc.: 13.28%] [G loss: 0.879639]\n",
      "epoch:27 step:25937 [D loss: 0.704807, acc.: 56.25%] [G loss: 1.159233]\n",
      "epoch:27 step:25938 [D loss: 1.025980, acc.: 25.78%] [G loss: 1.200864]\n",
      "epoch:27 step:25939 [D loss: 0.876469, acc.: 46.09%] [G loss: 1.362971]\n",
      "epoch:27 step:25940 [D loss: 0.745482, acc.: 60.16%] [G loss: 1.674311]\n",
      "epoch:27 step:25941 [D loss: 0.507590, acc.: 76.56%] [G loss: 1.466528]\n",
      "epoch:27 step:25942 [D loss: 0.691377, acc.: 53.91%] [G loss: 1.445805]\n",
      "epoch:27 step:25943 [D loss: 0.773392, acc.: 53.12%] [G loss: 1.301956]\n",
      "epoch:27 step:25944 [D loss: 0.699940, acc.: 54.69%] [G loss: 1.270369]\n",
      "epoch:27 step:25945 [D loss: 0.620479, acc.: 67.19%] [G loss: 1.059812]\n",
      "epoch:27 step:25946 [D loss: 0.439999, acc.: 86.72%] [G loss: 1.152254]\n",
      "epoch:27 step:25947 [D loss: 0.517321, acc.: 78.12%] [G loss: 1.050041]\n",
      "epoch:27 step:25948 [D loss: 0.667527, acc.: 57.03%] [G loss: 1.117811]\n",
      "epoch:27 step:25949 [D loss: 0.508936, acc.: 78.91%] [G loss: 1.256961]\n",
      "epoch:27 step:25950 [D loss: 0.660829, acc.: 62.50%] [G loss: 1.034856]\n",
      "epoch:27 step:25951 [D loss: 0.736099, acc.: 52.34%] [G loss: 1.120633]\n",
      "epoch:27 step:25952 [D loss: 0.663445, acc.: 57.81%] [G loss: 1.203269]\n",
      "epoch:27 step:25953 [D loss: 0.575072, acc.: 66.41%] [G loss: 1.481619]\n",
      "epoch:27 step:25954 [D loss: 0.651503, acc.: 60.16%] [G loss: 1.166739]\n",
      "epoch:27 step:25955 [D loss: 0.735028, acc.: 61.72%] [G loss: 1.115806]\n",
      "epoch:27 step:25956 [D loss: 0.668329, acc.: 55.47%] [G loss: 1.067777]\n",
      "epoch:27 step:25957 [D loss: 0.474905, acc.: 83.59%] [G loss: 1.118629]\n",
      "epoch:27 step:25958 [D loss: 0.700937, acc.: 58.59%] [G loss: 0.966142]\n",
      "epoch:27 step:25959 [D loss: 0.588750, acc.: 67.97%] [G loss: 1.176844]\n",
      "epoch:27 step:25960 [D loss: 0.536524, acc.: 75.78%] [G loss: 1.029615]\n",
      "epoch:27 step:25961 [D loss: 0.476695, acc.: 77.34%] [G loss: 1.381365]\n",
      "epoch:27 step:25962 [D loss: 0.319953, acc.: 83.59%] [G loss: 1.202025]\n",
      "epoch:27 step:25963 [D loss: 0.224184, acc.: 96.88%] [G loss: 1.797372]\n",
      "epoch:27 step:25964 [D loss: 0.207466, acc.: 96.09%] [G loss: 2.169350]\n",
      "epoch:27 step:25965 [D loss: 0.503658, acc.: 77.34%] [G loss: 1.688239]\n",
      "epoch:27 step:25966 [D loss: 0.493936, acc.: 82.03%] [G loss: 1.366353]\n",
      "epoch:27 step:25967 [D loss: 0.584957, acc.: 66.41%] [G loss: 1.410722]\n",
      "epoch:27 step:25968 [D loss: 0.419477, acc.: 82.81%] [G loss: 1.104379]\n",
      "epoch:27 step:25969 [D loss: 0.528571, acc.: 79.69%] [G loss: 1.248712]\n",
      "epoch:27 step:25970 [D loss: 0.462933, acc.: 81.25%] [G loss: 0.999575]\n",
      "epoch:27 step:25971 [D loss: 0.481759, acc.: 81.25%] [G loss: 1.186323]\n",
      "epoch:27 step:25972 [D loss: 0.909132, acc.: 42.19%] [G loss: 0.780391]\n",
      "epoch:27 step:25973 [D loss: 0.519050, acc.: 75.00%] [G loss: 0.981312]\n",
      "epoch:27 step:25974 [D loss: 0.649861, acc.: 62.50%] [G loss: 1.383791]\n",
      "epoch:27 step:25975 [D loss: 0.620484, acc.: 67.97%] [G loss: 0.892735]\n",
      "epoch:27 step:25976 [D loss: 0.760834, acc.: 54.69%] [G loss: 1.154037]\n",
      "epoch:27 step:25977 [D loss: 0.671263, acc.: 57.81%] [G loss: 1.058033]\n",
      "epoch:27 step:25978 [D loss: 0.766541, acc.: 50.00%] [G loss: 0.957560]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25979 [D loss: 0.675355, acc.: 52.34%] [G loss: 0.991770]\n",
      "epoch:27 step:25980 [D loss: 0.883454, acc.: 35.94%] [G loss: 1.062519]\n",
      "epoch:27 step:25981 [D loss: 0.522587, acc.: 72.66%] [G loss: 1.041272]\n",
      "epoch:27 step:25982 [D loss: 0.737819, acc.: 58.59%] [G loss: 0.957768]\n",
      "epoch:27 step:25983 [D loss: 0.547393, acc.: 71.88%] [G loss: 1.218200]\n",
      "epoch:27 step:25984 [D loss: 0.528615, acc.: 76.56%] [G loss: 1.328008]\n",
      "epoch:27 step:25985 [D loss: 0.882818, acc.: 35.16%] [G loss: 0.946326]\n",
      "epoch:27 step:25986 [D loss: 0.621974, acc.: 64.06%] [G loss: 1.227562]\n",
      "epoch:27 step:25987 [D loss: 0.810564, acc.: 41.41%] [G loss: 0.782007]\n",
      "epoch:27 step:25988 [D loss: 0.933554, acc.: 42.97%] [G loss: 1.200014]\n",
      "epoch:27 step:25989 [D loss: 0.856276, acc.: 40.62%] [G loss: 1.077493]\n",
      "epoch:27 step:25990 [D loss: 0.648880, acc.: 64.06%] [G loss: 1.255086]\n",
      "epoch:27 step:25991 [D loss: 0.567524, acc.: 75.78%] [G loss: 1.296142]\n",
      "epoch:27 step:25992 [D loss: 0.622533, acc.: 67.19%] [G loss: 1.304969]\n",
      "epoch:27 step:25993 [D loss: 0.348579, acc.: 94.53%] [G loss: 1.541737]\n",
      "epoch:27 step:25994 [D loss: 0.472830, acc.: 78.12%] [G loss: 1.257000]\n",
      "epoch:27 step:25995 [D loss: 0.569077, acc.: 71.09%] [G loss: 1.296497]\n",
      "epoch:27 step:25996 [D loss: 0.474244, acc.: 83.59%] [G loss: 1.081196]\n",
      "epoch:27 step:25997 [D loss: 0.598740, acc.: 67.97%] [G loss: 0.862170]\n",
      "epoch:27 step:25998 [D loss: 0.551356, acc.: 75.00%] [G loss: 1.019087]\n",
      "epoch:27 step:25999 [D loss: 0.581746, acc.: 71.09%] [G loss: 0.904847]\n",
      "epoch:27 step:26000 [D loss: 0.485202, acc.: 82.03%] [G loss: 1.232308]\n",
      "##############\n",
      "[2.45674513 1.69253893 5.45873195 4.27475557 3.31723246 5.48029694\n",
      " 4.44131608 4.75839163 4.03950063 3.70808122]\n",
      "##########\n",
      "epoch:27 step:26001 [D loss: 0.602954, acc.: 68.75%] [G loss: 1.297143]\n",
      "epoch:27 step:26002 [D loss: 0.757550, acc.: 44.53%] [G loss: 1.096669]\n",
      "epoch:27 step:26003 [D loss: 0.687521, acc.: 53.12%] [G loss: 1.146697]\n",
      "epoch:27 step:26004 [D loss: 0.591939, acc.: 69.53%] [G loss: 0.664949]\n",
      "epoch:27 step:26005 [D loss: 0.660134, acc.: 58.59%] [G loss: 0.960862]\n",
      "epoch:27 step:26006 [D loss: 0.323045, acc.: 95.31%] [G loss: 1.525265]\n",
      "epoch:27 step:26007 [D loss: 0.360369, acc.: 89.06%] [G loss: 1.692350]\n",
      "epoch:27 step:26008 [D loss: 0.298813, acc.: 95.31%] [G loss: 1.629747]\n",
      "epoch:27 step:26009 [D loss: 0.701146, acc.: 55.47%] [G loss: 1.537369]\n",
      "epoch:27 step:26010 [D loss: 0.535420, acc.: 71.09%] [G loss: 1.177383]\n",
      "epoch:27 step:26011 [D loss: 0.697647, acc.: 58.59%] [G loss: 1.420642]\n",
      "epoch:27 step:26012 [D loss: 0.487482, acc.: 75.78%] [G loss: 0.986679]\n",
      "epoch:27 step:26013 [D loss: 0.493399, acc.: 78.91%] [G loss: 1.394339]\n",
      "epoch:27 step:26014 [D loss: 0.760307, acc.: 50.78%] [G loss: 1.218323]\n",
      "epoch:27 step:26015 [D loss: 0.525141, acc.: 77.34%] [G loss: 1.373204]\n",
      "epoch:27 step:26016 [D loss: 0.404340, acc.: 87.50%] [G loss: 1.128168]\n",
      "epoch:27 step:26017 [D loss: 0.503016, acc.: 78.91%] [G loss: 1.131431]\n",
      "epoch:27 step:26018 [D loss: 0.494433, acc.: 76.56%] [G loss: 1.295857]\n",
      "epoch:27 step:26019 [D loss: 0.437132, acc.: 82.03%] [G loss: 1.151170]\n",
      "epoch:27 step:26020 [D loss: 0.418310, acc.: 85.94%] [G loss: 1.138743]\n",
      "epoch:27 step:26021 [D loss: 0.692966, acc.: 57.03%] [G loss: 1.100993]\n",
      "epoch:27 step:26022 [D loss: 0.409331, acc.: 85.94%] [G loss: 1.524531]\n",
      "epoch:27 step:26023 [D loss: 0.351895, acc.: 89.06%] [G loss: 1.445059]\n",
      "epoch:27 step:26024 [D loss: 0.353006, acc.: 92.19%] [G loss: 1.322256]\n",
      "epoch:27 step:26025 [D loss: 0.266189, acc.: 97.66%] [G loss: 1.664655]\n",
      "epoch:27 step:26026 [D loss: 0.875922, acc.: 43.75%] [G loss: 1.165713]\n",
      "epoch:27 step:26027 [D loss: 0.649715, acc.: 66.41%] [G loss: 1.130416]\n",
      "epoch:27 step:26028 [D loss: 0.813812, acc.: 44.53%] [G loss: 0.947280]\n",
      "epoch:27 step:26029 [D loss: 0.492137, acc.: 78.91%] [G loss: 1.182382]\n",
      "epoch:27 step:26030 [D loss: 0.316864, acc.: 94.53%] [G loss: 1.675181]\n",
      "epoch:27 step:26031 [D loss: 0.353184, acc.: 92.19%] [G loss: 1.670505]\n",
      "epoch:27 step:26032 [D loss: 0.351314, acc.: 91.41%] [G loss: 1.209729]\n",
      "epoch:27 step:26033 [D loss: 0.569075, acc.: 72.66%] [G loss: 1.203545]\n",
      "epoch:27 step:26034 [D loss: 0.773281, acc.: 51.56%] [G loss: 1.029016]\n",
      "epoch:27 step:26035 [D loss: 0.867063, acc.: 39.06%] [G loss: 0.825638]\n",
      "epoch:27 step:26036 [D loss: 0.712692, acc.: 52.34%] [G loss: 1.169564]\n",
      "epoch:27 step:26037 [D loss: 0.557447, acc.: 76.56%] [G loss: 1.210015]\n",
      "epoch:27 step:26038 [D loss: 0.516193, acc.: 78.12%] [G loss: 1.267103]\n",
      "epoch:27 step:26039 [D loss: 0.395540, acc.: 87.50%] [G loss: 1.479290]\n",
      "epoch:27 step:26040 [D loss: 0.608927, acc.: 67.97%] [G loss: 1.045584]\n",
      "epoch:27 step:26041 [D loss: 0.559071, acc.: 71.88%] [G loss: 1.387996]\n",
      "epoch:27 step:26042 [D loss: 0.551309, acc.: 69.53%] [G loss: 1.217985]\n",
      "epoch:27 step:26043 [D loss: 0.657084, acc.: 62.50%] [G loss: 1.221290]\n",
      "epoch:27 step:26044 [D loss: 0.337296, acc.: 89.06%] [G loss: 1.266750]\n",
      "epoch:27 step:26045 [D loss: 0.533074, acc.: 74.22%] [G loss: 1.356787]\n",
      "epoch:27 step:26046 [D loss: 0.465272, acc.: 83.59%] [G loss: 1.402428]\n",
      "epoch:27 step:26047 [D loss: 0.658576, acc.: 59.38%] [G loss: 1.153592]\n",
      "epoch:27 step:26048 [D loss: 0.645115, acc.: 61.72%] [G loss: 0.802231]\n",
      "epoch:27 step:26049 [D loss: 0.749295, acc.: 50.78%] [G loss: 0.832072]\n",
      "epoch:27 step:26050 [D loss: 0.568213, acc.: 73.44%] [G loss: 1.029223]\n",
      "epoch:27 step:26051 [D loss: 0.738890, acc.: 47.66%] [G loss: 1.140959]\n",
      "epoch:27 step:26052 [D loss: 0.583881, acc.: 70.31%] [G loss: 1.063956]\n",
      "epoch:27 step:26053 [D loss: 0.597624, acc.: 66.41%] [G loss: 0.906894]\n",
      "epoch:27 step:26054 [D loss: 0.403103, acc.: 81.25%] [G loss: 1.049453]\n",
      "epoch:27 step:26055 [D loss: 0.379272, acc.: 89.84%] [G loss: 1.528461]\n",
      "epoch:27 step:26056 [D loss: 0.399685, acc.: 90.62%] [G loss: 1.456556]\n",
      "epoch:27 step:26057 [D loss: 0.497546, acc.: 80.47%] [G loss: 1.368023]\n",
      "epoch:27 step:26058 [D loss: 0.663310, acc.: 59.38%] [G loss: 1.108519]\n",
      "epoch:27 step:26059 [D loss: 0.804624, acc.: 42.97%] [G loss: 1.063487]\n",
      "epoch:27 step:26060 [D loss: 0.910641, acc.: 42.97%] [G loss: 0.648881]\n",
      "epoch:27 step:26061 [D loss: 0.679959, acc.: 60.94%] [G loss: 1.236679]\n",
      "epoch:27 step:26062 [D loss: 0.802974, acc.: 50.78%] [G loss: 0.846930]\n",
      "epoch:27 step:26063 [D loss: 0.284926, acc.: 96.09%] [G loss: 1.088590]\n",
      "epoch:27 step:26064 [D loss: 0.752036, acc.: 54.69%] [G loss: 1.249284]\n",
      "epoch:27 step:26065 [D loss: 0.696030, acc.: 52.34%] [G loss: 0.970864]\n",
      "epoch:27 step:26066 [D loss: 0.552877, acc.: 76.56%] [G loss: 1.052672]\n",
      "epoch:27 step:26067 [D loss: 0.374606, acc.: 88.28%] [G loss: 1.301211]\n",
      "epoch:27 step:26068 [D loss: 0.266545, acc.: 95.31%] [G loss: 1.538454]\n",
      "epoch:27 step:26069 [D loss: 0.586297, acc.: 68.75%] [G loss: 1.055631]\n",
      "epoch:27 step:26070 [D loss: 0.700651, acc.: 56.25%] [G loss: 1.029096]\n",
      "epoch:27 step:26071 [D loss: 0.631671, acc.: 63.28%] [G loss: 1.104426]\n",
      "epoch:27 step:26072 [D loss: 0.653486, acc.: 53.91%] [G loss: 1.138165]\n",
      "epoch:27 step:26073 [D loss: 0.251849, acc.: 93.75%] [G loss: 1.542201]\n",
      "epoch:27 step:26074 [D loss: 0.211695, acc.: 98.44%] [G loss: 1.565950]\n",
      "epoch:27 step:26075 [D loss: 0.352582, acc.: 93.75%] [G loss: 1.190530]\n",
      "epoch:27 step:26076 [D loss: 0.517593, acc.: 75.78%] [G loss: 1.004262]\n",
      "epoch:27 step:26077 [D loss: 0.645677, acc.: 64.06%] [G loss: 0.847439]\n",
      "epoch:27 step:26078 [D loss: 0.809479, acc.: 44.53%] [G loss: 0.821064]\n",
      "epoch:27 step:26079 [D loss: 0.449858, acc.: 85.94%] [G loss: 0.985279]\n",
      "epoch:27 step:26080 [D loss: 0.471301, acc.: 78.12%] [G loss: 1.384901]\n",
      "epoch:27 step:26081 [D loss: 0.332720, acc.: 91.41%] [G loss: 1.733924]\n",
      "epoch:27 step:26082 [D loss: 1.012251, acc.: 33.59%] [G loss: 1.186070]\n",
      "epoch:27 step:26083 [D loss: 0.783906, acc.: 43.75%] [G loss: 0.953421]\n",
      "epoch:27 step:26084 [D loss: 0.690080, acc.: 54.69%] [G loss: 1.191360]\n",
      "epoch:27 step:26085 [D loss: 0.594032, acc.: 63.28%] [G loss: 0.989132]\n",
      "epoch:27 step:26086 [D loss: 0.892386, acc.: 33.59%] [G loss: 0.898494]\n",
      "epoch:27 step:26087 [D loss: 0.674867, acc.: 60.94%] [G loss: 0.961729]\n",
      "epoch:27 step:26088 [D loss: 0.876503, acc.: 36.72%] [G loss: 1.020466]\n",
      "epoch:27 step:26089 [D loss: 0.446081, acc.: 83.59%] [G loss: 1.277952]\n",
      "epoch:27 step:26090 [D loss: 0.274030, acc.: 97.66%] [G loss: 1.279602]\n",
      "epoch:27 step:26091 [D loss: 0.419242, acc.: 78.91%] [G loss: 1.367846]\n",
      "epoch:27 step:26092 [D loss: 0.289031, acc.: 93.75%] [G loss: 1.748677]\n",
      "epoch:27 step:26093 [D loss: 0.205875, acc.: 100.00%] [G loss: 1.677087]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:26094 [D loss: 0.488984, acc.: 81.25%] [G loss: 1.402081]\n",
      "epoch:27 step:26095 [D loss: 0.594716, acc.: 68.75%] [G loss: 1.078489]\n",
      "epoch:27 step:26096 [D loss: 0.899444, acc.: 39.84%] [G loss: 0.949299]\n",
      "epoch:27 step:26097 [D loss: 0.541725, acc.: 75.00%] [G loss: 1.073367]\n",
      "epoch:27 step:26098 [D loss: 0.754312, acc.: 55.47%] [G loss: 0.823457]\n",
      "epoch:27 step:26099 [D loss: 0.781700, acc.: 48.44%] [G loss: 0.930420]\n",
      "epoch:27 step:26100 [D loss: 0.790218, acc.: 43.75%] [G loss: 0.866684]\n",
      "epoch:27 step:26101 [D loss: 0.464606, acc.: 84.38%] [G loss: 1.473533]\n",
      "epoch:27 step:26102 [D loss: 0.427119, acc.: 88.28%] [G loss: 1.489565]\n",
      "epoch:27 step:26103 [D loss: 0.734644, acc.: 51.56%] [G loss: 1.160790]\n",
      "epoch:27 step:26104 [D loss: 0.569909, acc.: 74.22%] [G loss: 1.153746]\n",
      "epoch:27 step:26105 [D loss: 0.406017, acc.: 88.28%] [G loss: 1.393639]\n",
      "epoch:27 step:26106 [D loss: 0.699216, acc.: 50.78%] [G loss: 0.881020]\n",
      "epoch:27 step:26107 [D loss: 0.478288, acc.: 80.47%] [G loss: 1.142985]\n",
      "epoch:27 step:26108 [D loss: 0.443634, acc.: 85.16%] [G loss: 1.361055]\n",
      "epoch:27 step:26109 [D loss: 0.471428, acc.: 80.47%] [G loss: 1.331385]\n",
      "epoch:27 step:26110 [D loss: 0.815559, acc.: 46.09%] [G loss: 1.149943]\n",
      "epoch:27 step:26111 [D loss: 0.704175, acc.: 53.91%] [G loss: 0.917455]\n",
      "epoch:27 step:26112 [D loss: 0.658369, acc.: 59.38%] [G loss: 0.885690]\n",
      "epoch:27 step:26113 [D loss: 0.681915, acc.: 67.19%] [G loss: 1.089443]\n",
      "epoch:27 step:26114 [D loss: 0.263770, acc.: 91.41%] [G loss: 1.282764]\n",
      "epoch:27 step:26115 [D loss: 0.304785, acc.: 96.09%] [G loss: 1.714641]\n",
      "epoch:27 step:26116 [D loss: 0.522199, acc.: 75.78%] [G loss: 1.517829]\n",
      "epoch:27 step:26117 [D loss: 0.598330, acc.: 68.75%] [G loss: 0.855290]\n",
      "epoch:27 step:26118 [D loss: 0.590999, acc.: 67.97%] [G loss: 1.013889]\n",
      "epoch:27 step:26119 [D loss: 0.912431, acc.: 32.03%] [G loss: 0.813678]\n",
      "epoch:27 step:26120 [D loss: 0.674683, acc.: 60.16%] [G loss: 1.027594]\n",
      "epoch:27 step:26121 [D loss: 0.984894, acc.: 28.12%] [G loss: 0.645849]\n",
      "epoch:27 step:26122 [D loss: 0.746031, acc.: 50.78%] [G loss: 0.957368]\n",
      "epoch:27 step:26123 [D loss: 0.415608, acc.: 89.84%] [G loss: 1.171347]\n",
      "epoch:27 step:26124 [D loss: 0.474260, acc.: 82.81%] [G loss: 1.315524]\n",
      "epoch:27 step:26125 [D loss: 0.528170, acc.: 80.47%] [G loss: 1.379992]\n",
      "epoch:27 step:26126 [D loss: 0.774006, acc.: 47.66%] [G loss: 0.851560]\n",
      "epoch:27 step:26127 [D loss: 0.736402, acc.: 52.34%] [G loss: 0.776345]\n",
      "epoch:27 step:26128 [D loss: 0.712356, acc.: 53.91%] [G loss: 1.047457]\n",
      "epoch:27 step:26129 [D loss: 0.690357, acc.: 62.50%] [G loss: 0.784628]\n",
      "epoch:27 step:26130 [D loss: 0.387163, acc.: 82.81%] [G loss: 1.170063]\n",
      "epoch:27 step:26131 [D loss: 0.414741, acc.: 84.38%] [G loss: 1.723554]\n",
      "epoch:27 step:26132 [D loss: 0.447157, acc.: 85.94%] [G loss: 1.552861]\n",
      "epoch:27 step:26133 [D loss: 0.833091, acc.: 50.78%] [G loss: 1.097329]\n",
      "epoch:27 step:26134 [D loss: 0.673838, acc.: 56.25%] [G loss: 1.325024]\n",
      "epoch:27 step:26135 [D loss: 0.666522, acc.: 64.06%] [G loss: 0.899867]\n",
      "epoch:27 step:26136 [D loss: 0.533941, acc.: 76.56%] [G loss: 1.343717]\n",
      "epoch:27 step:26137 [D loss: 0.494521, acc.: 79.69%] [G loss: 1.395694]\n",
      "epoch:27 step:26138 [D loss: 0.637445, acc.: 60.94%] [G loss: 1.190945]\n",
      "epoch:27 step:26139 [D loss: 0.343849, acc.: 93.75%] [G loss: 1.335789]\n",
      "epoch:27 step:26140 [D loss: 0.476078, acc.: 76.56%] [G loss: 1.315336]\n",
      "epoch:27 step:26141 [D loss: 0.409913, acc.: 82.81%] [G loss: 1.592692]\n",
      "epoch:27 step:26142 [D loss: 0.828011, acc.: 46.88%] [G loss: 1.248704]\n",
      "epoch:27 step:26143 [D loss: 0.864917, acc.: 45.31%] [G loss: 0.976501]\n",
      "epoch:27 step:26144 [D loss: 0.612075, acc.: 67.19%] [G loss: 1.091213]\n",
      "epoch:27 step:26145 [D loss: 0.612659, acc.: 61.72%] [G loss: 1.203406]\n",
      "epoch:27 step:26146 [D loss: 0.434327, acc.: 83.59%] [G loss: 1.203786]\n",
      "epoch:27 step:26147 [D loss: 0.527892, acc.: 78.12%] [G loss: 0.928074]\n",
      "epoch:27 step:26148 [D loss: 0.376747, acc.: 88.28%] [G loss: 1.170609]\n",
      "epoch:27 step:26149 [D loss: 0.330591, acc.: 88.28%] [G loss: 1.253577]\n",
      "epoch:27 step:26150 [D loss: 0.253765, acc.: 92.97%] [G loss: 1.804034]\n",
      "epoch:27 step:26151 [D loss: 0.237054, acc.: 96.88%] [G loss: 1.937910]\n",
      "epoch:27 step:26152 [D loss: 0.235259, acc.: 95.31%] [G loss: 1.805498]\n",
      "epoch:27 step:26153 [D loss: 0.234484, acc.: 97.66%] [G loss: 1.529558]\n",
      "epoch:27 step:26154 [D loss: 0.360821, acc.: 87.50%] [G loss: 1.586707]\n",
      "epoch:27 step:26155 [D loss: 0.564255, acc.: 71.09%] [G loss: 1.175048]\n",
      "epoch:27 step:26156 [D loss: 0.357061, acc.: 85.16%] [G loss: 1.081667]\n",
      "epoch:27 step:26157 [D loss: 0.647660, acc.: 61.72%] [G loss: 1.418851]\n",
      "epoch:27 step:26158 [D loss: 0.512984, acc.: 75.78%] [G loss: 1.350074]\n",
      "epoch:27 step:26159 [D loss: 0.465012, acc.: 80.47%] [G loss: 1.249773]\n",
      "epoch:27 step:26160 [D loss: 0.626740, acc.: 64.84%] [G loss: 1.281969]\n",
      "epoch:27 step:26161 [D loss: 0.780071, acc.: 42.97%] [G loss: 0.957246]\n",
      "epoch:27 step:26162 [D loss: 0.585380, acc.: 69.53%] [G loss: 1.235553]\n",
      "epoch:27 step:26163 [D loss: 0.723293, acc.: 56.25%] [G loss: 0.798808]\n",
      "epoch:27 step:26164 [D loss: 0.490085, acc.: 75.78%] [G loss: 0.931661]\n",
      "epoch:27 step:26165 [D loss: 0.571653, acc.: 71.09%] [G loss: 1.031693]\n",
      "epoch:27 step:26166 [D loss: 0.732626, acc.: 50.00%] [G loss: 0.985423]\n",
      "epoch:27 step:26167 [D loss: 0.655416, acc.: 63.28%] [G loss: 0.942433]\n",
      "epoch:27 step:26168 [D loss: 0.600943, acc.: 64.84%] [G loss: 0.682519]\n",
      "epoch:27 step:26169 [D loss: 0.635212, acc.: 63.28%] [G loss: 1.153730]\n",
      "epoch:27 step:26170 [D loss: 0.925344, acc.: 39.84%] [G loss: 0.912816]\n",
      "epoch:27 step:26171 [D loss: 0.715219, acc.: 58.59%] [G loss: 0.843447]\n",
      "epoch:27 step:26172 [D loss: 0.826028, acc.: 46.09%] [G loss: 1.054651]\n",
      "epoch:27 step:26173 [D loss: 1.122722, acc.: 20.31%] [G loss: 0.869657]\n",
      "epoch:27 step:26174 [D loss: 0.645985, acc.: 62.50%] [G loss: 1.296717]\n",
      "epoch:27 step:26175 [D loss: 0.629417, acc.: 63.28%] [G loss: 1.274516]\n",
      "epoch:27 step:26176 [D loss: 0.645098, acc.: 61.72%] [G loss: 0.975713]\n",
      "epoch:27 step:26177 [D loss: 0.415794, acc.: 85.94%] [G loss: 1.407590]\n",
      "epoch:27 step:26178 [D loss: 0.645279, acc.: 62.50%] [G loss: 1.394857]\n",
      "epoch:27 step:26179 [D loss: 0.733605, acc.: 50.00%] [G loss: 1.263941]\n",
      "epoch:27 step:26180 [D loss: 0.602181, acc.: 69.53%] [G loss: 1.175695]\n",
      "epoch:27 step:26181 [D loss: 0.546654, acc.: 70.31%] [G loss: 1.025520]\n",
      "epoch:27 step:26182 [D loss: 0.720913, acc.: 50.00%] [G loss: 0.978401]\n",
      "epoch:27 step:26183 [D loss: 0.592643, acc.: 66.41%] [G loss: 1.035517]\n",
      "epoch:27 step:26184 [D loss: 0.662080, acc.: 62.50%] [G loss: 1.069240]\n",
      "epoch:27 step:26185 [D loss: 0.595903, acc.: 68.75%] [G loss: 1.227799]\n",
      "epoch:27 step:26186 [D loss: 0.390077, acc.: 85.16%] [G loss: 1.167358]\n",
      "epoch:27 step:26187 [D loss: 0.613970, acc.: 60.94%] [G loss: 1.119515]\n",
      "epoch:27 step:26188 [D loss: 0.324780, acc.: 91.41%] [G loss: 1.291095]\n",
      "epoch:27 step:26189 [D loss: 0.457090, acc.: 79.69%] [G loss: 1.229155]\n",
      "epoch:27 step:26190 [D loss: 0.775662, acc.: 47.66%] [G loss: 1.210973]\n",
      "epoch:27 step:26191 [D loss: 0.532746, acc.: 77.34%] [G loss: 1.516169]\n",
      "epoch:27 step:26192 [D loss: 0.385031, acc.: 90.62%] [G loss: 1.300492]\n",
      "epoch:27 step:26193 [D loss: 0.386186, acc.: 90.62%] [G loss: 1.389643]\n",
      "epoch:27 step:26194 [D loss: 0.412472, acc.: 84.38%] [G loss: 1.332046]\n",
      "epoch:27 step:26195 [D loss: 0.305041, acc.: 96.09%] [G loss: 1.517545]\n",
      "epoch:27 step:26196 [D loss: 0.255026, acc.: 97.66%] [G loss: 1.463664]\n",
      "epoch:27 step:26197 [D loss: 0.187083, acc.: 99.22%] [G loss: 1.481637]\n",
      "epoch:27 step:26198 [D loss: 0.214230, acc.: 100.00%] [G loss: 1.668164]\n",
      "epoch:27 step:26199 [D loss: 0.160767, acc.: 99.22%] [G loss: 2.078991]\n",
      "epoch:27 step:26200 [D loss: 0.278862, acc.: 95.31%] [G loss: 2.138617]\n",
      "##############\n",
      "[2.67926562 1.94500118 5.68877235 4.48248096 3.51390063 5.39483727\n",
      " 4.30355331 4.80497157 4.15388184 3.84945664]\n",
      "##########\n",
      "epoch:27 step:26201 [D loss: 0.718116, acc.: 57.81%] [G loss: 1.293182]\n",
      "epoch:27 step:26202 [D loss: 0.356436, acc.: 92.97%] [G loss: 1.330591]\n",
      "epoch:27 step:26203 [D loss: 0.965095, acc.: 30.47%] [G loss: 1.016253]\n",
      "epoch:27 step:26204 [D loss: 0.693763, acc.: 55.47%] [G loss: 1.211782]\n",
      "epoch:27 step:26205 [D loss: 0.693008, acc.: 62.50%] [G loss: 1.216714]\n",
      "epoch:27 step:26206 [D loss: 0.642113, acc.: 66.41%] [G loss: 1.115304]\n",
      "epoch:27 step:26207 [D loss: 0.562775, acc.: 72.66%] [G loss: 0.850996]\n",
      "epoch:27 step:26208 [D loss: 0.434990, acc.: 84.38%] [G loss: 1.177763]\n",
      "epoch:27 step:26209 [D loss: 0.586116, acc.: 67.19%] [G loss: 1.095429]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:26210 [D loss: 0.173376, acc.: 99.22%] [G loss: 1.626565]\n",
      "epoch:27 step:26211 [D loss: 0.181884, acc.: 96.09%] [G loss: 1.401161]\n",
      "epoch:27 step:26212 [D loss: 0.914961, acc.: 46.88%] [G loss: 1.661852]\n",
      "epoch:27 step:26213 [D loss: 0.691221, acc.: 57.03%] [G loss: 1.292510]\n",
      "epoch:27 step:26214 [D loss: 0.474281, acc.: 81.25%] [G loss: 1.210984]\n",
      "epoch:27 step:26215 [D loss: 0.648317, acc.: 63.28%] [G loss: 0.836057]\n",
      "epoch:27 step:26216 [D loss: 0.655501, acc.: 61.72%] [G loss: 0.993257]\n",
      "epoch:27 step:26217 [D loss: 0.674820, acc.: 58.59%] [G loss: 0.653005]\n",
      "epoch:27 step:26218 [D loss: 0.461234, acc.: 77.34%] [G loss: 1.580887]\n",
      "epoch:27 step:26219 [D loss: 0.439545, acc.: 75.78%] [G loss: 1.629370]\n",
      "epoch:27 step:26220 [D loss: 0.396634, acc.: 85.94%] [G loss: 1.918680]\n",
      "epoch:27 step:26221 [D loss: 0.612859, acc.: 71.09%] [G loss: 1.358412]\n",
      "epoch:27 step:26222 [D loss: 0.556895, acc.: 69.53%] [G loss: 1.510502]\n",
      "epoch:27 step:26223 [D loss: 0.349521, acc.: 87.50%] [G loss: 1.406587]\n",
      "epoch:27 step:26224 [D loss: 0.343675, acc.: 92.19%] [G loss: 1.371818]\n",
      "epoch:27 step:26225 [D loss: 0.430943, acc.: 84.38%] [G loss: 1.259528]\n",
      "epoch:27 step:26226 [D loss: 0.241784, acc.: 95.31%] [G loss: 1.739873]\n",
      "epoch:27 step:26227 [D loss: 1.132854, acc.: 37.50%] [G loss: 0.926685]\n",
      "epoch:27 step:26228 [D loss: 0.262974, acc.: 96.09%] [G loss: 1.490098]\n",
      "epoch:27 step:26229 [D loss: 0.412609, acc.: 83.59%] [G loss: 1.711325]\n",
      "epoch:27 step:26230 [D loss: 0.681844, acc.: 56.25%] [G loss: 1.492794]\n",
      "epoch:27 step:26231 [D loss: 0.610050, acc.: 64.06%] [G loss: 0.938730]\n",
      "epoch:27 step:26232 [D loss: 0.534066, acc.: 72.66%] [G loss: 1.047072]\n",
      "epoch:27 step:26233 [D loss: 0.382718, acc.: 82.81%] [G loss: 1.453191]\n",
      "epoch:27 step:26234 [D loss: 0.459227, acc.: 82.81%] [G loss: 1.482407]\n",
      "epoch:27 step:26235 [D loss: 0.565684, acc.: 67.97%] [G loss: 0.796464]\n",
      "epoch:27 step:26236 [D loss: 0.150892, acc.: 97.66%] [G loss: 2.191949]\n",
      "epoch:28 step:26237 [D loss: 1.021804, acc.: 39.06%] [G loss: 1.235568]\n",
      "epoch:28 step:26238 [D loss: 1.023416, acc.: 33.59%] [G loss: 1.028667]\n",
      "epoch:28 step:26239 [D loss: 0.707734, acc.: 61.72%] [G loss: 1.316400]\n",
      "epoch:28 step:26240 [D loss: 0.594538, acc.: 70.31%] [G loss: 1.299843]\n",
      "epoch:28 step:26241 [D loss: 0.601847, acc.: 65.62%] [G loss: 1.022238]\n",
      "epoch:28 step:26242 [D loss: 0.497746, acc.: 80.47%] [G loss: 1.432685]\n",
      "epoch:28 step:26243 [D loss: 0.589838, acc.: 73.44%] [G loss: 1.304449]\n",
      "epoch:28 step:26244 [D loss: 0.595920, acc.: 69.53%] [G loss: 1.129582]\n",
      "epoch:28 step:26245 [D loss: 0.604085, acc.: 68.75%] [G loss: 1.139816]\n",
      "epoch:28 step:26246 [D loss: 0.495774, acc.: 78.91%] [G loss: 1.362224]\n",
      "epoch:28 step:26247 [D loss: 0.644640, acc.: 60.94%] [G loss: 1.177345]\n",
      "epoch:28 step:26248 [D loss: 0.661276, acc.: 58.59%] [G loss: 1.297517]\n",
      "epoch:28 step:26249 [D loss: 0.635024, acc.: 67.19%] [G loss: 0.992828]\n",
      "epoch:28 step:26250 [D loss: 0.645400, acc.: 63.28%] [G loss: 0.885888]\n",
      "epoch:28 step:26251 [D loss: 0.441777, acc.: 72.66%] [G loss: 0.995278]\n",
      "epoch:28 step:26252 [D loss: 0.390271, acc.: 88.28%] [G loss: 1.589581]\n",
      "epoch:28 step:26253 [D loss: 0.844535, acc.: 40.62%] [G loss: 0.965952]\n",
      "epoch:28 step:26254 [D loss: 0.731227, acc.: 53.91%] [G loss: 1.163912]\n",
      "epoch:28 step:26255 [D loss: 0.784935, acc.: 50.78%] [G loss: 1.045106]\n",
      "epoch:28 step:26256 [D loss: 0.511008, acc.: 78.12%] [G loss: 1.142933]\n",
      "epoch:28 step:26257 [D loss: 0.906477, acc.: 39.84%] [G loss: 0.824289]\n",
      "epoch:28 step:26258 [D loss: 0.757738, acc.: 50.78%] [G loss: 1.035022]\n",
      "epoch:28 step:26259 [D loss: 0.546719, acc.: 77.34%] [G loss: 1.101748]\n",
      "epoch:28 step:26260 [D loss: 0.596685, acc.: 67.97%] [G loss: 1.241194]\n",
      "epoch:28 step:26261 [D loss: 0.569469, acc.: 69.53%] [G loss: 0.910190]\n",
      "epoch:28 step:26262 [D loss: 0.406968, acc.: 80.47%] [G loss: 1.179220]\n",
      "epoch:28 step:26263 [D loss: 0.249188, acc.: 94.53%] [G loss: 1.533033]\n",
      "epoch:28 step:26264 [D loss: 0.305824, acc.: 92.97%] [G loss: 1.646411]\n",
      "epoch:28 step:26265 [D loss: 0.305636, acc.: 94.53%] [G loss: 1.470337]\n",
      "epoch:28 step:26266 [D loss: 0.318307, acc.: 92.19%] [G loss: 1.359048]\n",
      "epoch:28 step:26267 [D loss: 0.221944, acc.: 97.66%] [G loss: 2.048383]\n",
      "epoch:28 step:26268 [D loss: 0.231436, acc.: 96.09%] [G loss: 1.919638]\n",
      "epoch:28 step:26269 [D loss: 0.170757, acc.: 99.22%] [G loss: 2.236798]\n",
      "epoch:28 step:26270 [D loss: 0.377244, acc.: 85.16%] [G loss: 1.329773]\n",
      "epoch:28 step:26271 [D loss: 0.208359, acc.: 96.09%] [G loss: 2.121092]\n",
      "epoch:28 step:26272 [D loss: 0.122724, acc.: 100.00%] [G loss: 2.466700]\n",
      "epoch:28 step:26273 [D loss: 0.981604, acc.: 50.78%] [G loss: 1.202177]\n",
      "epoch:28 step:26274 [D loss: 0.957535, acc.: 41.41%] [G loss: 1.368968]\n",
      "epoch:28 step:26275 [D loss: 0.867774, acc.: 35.16%] [G loss: 1.096140]\n",
      "epoch:28 step:26276 [D loss: 0.669873, acc.: 60.16%] [G loss: 1.080038]\n",
      "epoch:28 step:26277 [D loss: 0.644853, acc.: 60.16%] [G loss: 1.244340]\n",
      "epoch:28 step:26278 [D loss: 0.637267, acc.: 58.59%] [G loss: 1.078681]\n",
      "epoch:28 step:26279 [D loss: 0.702299, acc.: 57.81%] [G loss: 1.359064]\n",
      "epoch:28 step:26280 [D loss: 0.613237, acc.: 67.19%] [G loss: 0.897449]\n",
      "epoch:28 step:26281 [D loss: 0.561129, acc.: 69.53%] [G loss: 1.252960]\n",
      "epoch:28 step:26282 [D loss: 0.843410, acc.: 39.06%] [G loss: 1.030355]\n",
      "epoch:28 step:26283 [D loss: 0.648079, acc.: 57.81%] [G loss: 0.992955]\n",
      "epoch:28 step:26284 [D loss: 0.640103, acc.: 63.28%] [G loss: 1.095447]\n",
      "epoch:28 step:26285 [D loss: 0.506274, acc.: 80.47%] [G loss: 1.310137]\n",
      "epoch:28 step:26286 [D loss: 0.478246, acc.: 82.03%] [G loss: 1.326390]\n",
      "epoch:28 step:26287 [D loss: 0.604157, acc.: 67.97%] [G loss: 1.171993]\n",
      "epoch:28 step:26288 [D loss: 0.666220, acc.: 60.94%] [G loss: 1.063992]\n",
      "epoch:28 step:26289 [D loss: 0.470264, acc.: 81.25%] [G loss: 1.276348]\n",
      "epoch:28 step:26290 [D loss: 0.487472, acc.: 82.03%] [G loss: 1.344419]\n",
      "epoch:28 step:26291 [D loss: 0.457103, acc.: 85.16%] [G loss: 1.125305]\n",
      "epoch:28 step:26292 [D loss: 0.803594, acc.: 46.88%] [G loss: 0.862251]\n",
      "epoch:28 step:26293 [D loss: 0.775877, acc.: 50.78%] [G loss: 1.174538]\n",
      "epoch:28 step:26294 [D loss: 0.681065, acc.: 60.94%] [G loss: 0.982825]\n",
      "epoch:28 step:26295 [D loss: 0.750311, acc.: 46.09%] [G loss: 0.899440]\n",
      "epoch:28 step:26296 [D loss: 0.699194, acc.: 61.72%] [G loss: 1.010108]\n",
      "epoch:28 step:26297 [D loss: 0.655186, acc.: 57.03%] [G loss: 1.154360]\n",
      "epoch:28 step:26298 [D loss: 0.768377, acc.: 50.00%] [G loss: 0.721049]\n",
      "epoch:28 step:26299 [D loss: 0.605462, acc.: 67.97%] [G loss: 1.150697]\n",
      "epoch:28 step:26300 [D loss: 0.685406, acc.: 54.69%] [G loss: 1.160959]\n",
      "epoch:28 step:26301 [D loss: 0.597321, acc.: 68.75%] [G loss: 0.953008]\n",
      "epoch:28 step:26302 [D loss: 0.750236, acc.: 53.12%] [G loss: 1.124784]\n",
      "epoch:28 step:26303 [D loss: 0.607758, acc.: 67.97%] [G loss: 1.054980]\n",
      "epoch:28 step:26304 [D loss: 0.492856, acc.: 82.81%] [G loss: 1.271634]\n",
      "epoch:28 step:26305 [D loss: 0.392509, acc.: 86.72%] [G loss: 1.192813]\n",
      "epoch:28 step:26306 [D loss: 0.476460, acc.: 78.91%] [G loss: 1.336591]\n",
      "epoch:28 step:26307 [D loss: 0.473286, acc.: 85.94%] [G loss: 1.156451]\n",
      "epoch:28 step:26308 [D loss: 0.656201, acc.: 59.38%] [G loss: 1.134784]\n",
      "epoch:28 step:26309 [D loss: 0.542534, acc.: 75.00%] [G loss: 1.092914]\n",
      "epoch:28 step:26310 [D loss: 0.396154, acc.: 79.69%] [G loss: 0.989469]\n",
      "epoch:28 step:26311 [D loss: 0.267458, acc.: 91.41%] [G loss: 1.498648]\n",
      "epoch:28 step:26312 [D loss: 0.367700, acc.: 88.28%] [G loss: 1.468207]\n",
      "epoch:28 step:26313 [D loss: 0.281666, acc.: 96.09%] [G loss: 1.884370]\n",
      "epoch:28 step:26314 [D loss: 0.933725, acc.: 47.66%] [G loss: 1.278342]\n",
      "epoch:28 step:26315 [D loss: 0.893519, acc.: 42.97%] [G loss: 0.841925]\n",
      "epoch:28 step:26316 [D loss: 0.570157, acc.: 72.66%] [G loss: 1.214519]\n",
      "epoch:28 step:26317 [D loss: 0.595902, acc.: 69.53%] [G loss: 1.053163]\n",
      "epoch:28 step:26318 [D loss: 0.521432, acc.: 78.12%] [G loss: 1.016015]\n",
      "epoch:28 step:26319 [D loss: 0.365556, acc.: 92.97%] [G loss: 1.289253]\n",
      "epoch:28 step:26320 [D loss: 0.733760, acc.: 46.88%] [G loss: 1.110285]\n",
      "epoch:28 step:26321 [D loss: 0.541325, acc.: 71.88%] [G loss: 1.257779]\n",
      "epoch:28 step:26322 [D loss: 0.521543, acc.: 78.12%] [G loss: 1.079148]\n",
      "epoch:28 step:26323 [D loss: 0.430047, acc.: 85.94%] [G loss: 1.433320]\n",
      "epoch:28 step:26324 [D loss: 0.375828, acc.: 91.41%] [G loss: 1.228096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26325 [D loss: 0.621814, acc.: 65.62%] [G loss: 1.172437]\n",
      "epoch:28 step:26326 [D loss: 0.647675, acc.: 61.72%] [G loss: 1.074013]\n",
      "epoch:28 step:26327 [D loss: 0.582597, acc.: 74.22%] [G loss: 1.280538]\n",
      "epoch:28 step:26328 [D loss: 0.419401, acc.: 85.16%] [G loss: 1.661507]\n",
      "epoch:28 step:26329 [D loss: 0.622284, acc.: 64.84%] [G loss: 0.939274]\n",
      "epoch:28 step:26330 [D loss: 0.701444, acc.: 60.94%] [G loss: 1.099203]\n",
      "epoch:28 step:26331 [D loss: 0.801267, acc.: 50.78%] [G loss: 1.380525]\n",
      "epoch:28 step:26332 [D loss: 0.880222, acc.: 34.38%] [G loss: 0.901747]\n",
      "epoch:28 step:26333 [D loss: 0.667297, acc.: 54.69%] [G loss: 0.995482]\n",
      "epoch:28 step:26334 [D loss: 0.910215, acc.: 29.69%] [G loss: 0.844975]\n",
      "epoch:28 step:26335 [D loss: 0.839230, acc.: 38.28%] [G loss: 1.020060]\n",
      "epoch:28 step:26336 [D loss: 0.574817, acc.: 73.44%] [G loss: 1.145531]\n",
      "epoch:28 step:26337 [D loss: 0.708298, acc.: 53.12%] [G loss: 0.941405]\n",
      "epoch:28 step:26338 [D loss: 0.531114, acc.: 73.44%] [G loss: 1.193446]\n",
      "epoch:28 step:26339 [D loss: 0.431653, acc.: 85.16%] [G loss: 1.432666]\n",
      "epoch:28 step:26340 [D loss: 0.495814, acc.: 84.38%] [G loss: 1.453212]\n",
      "epoch:28 step:26341 [D loss: 0.320512, acc.: 92.97%] [G loss: 1.479803]\n",
      "epoch:28 step:26342 [D loss: 0.311108, acc.: 92.19%] [G loss: 1.786161]\n",
      "epoch:28 step:26343 [D loss: 0.437904, acc.: 82.03%] [G loss: 1.818963]\n",
      "epoch:28 step:26344 [D loss: 0.549639, acc.: 71.09%] [G loss: 1.032277]\n",
      "epoch:28 step:26345 [D loss: 0.377943, acc.: 88.28%] [G loss: 1.221724]\n",
      "epoch:28 step:26346 [D loss: 0.479781, acc.: 75.00%] [G loss: 1.281327]\n",
      "epoch:28 step:26347 [D loss: 0.871228, acc.: 37.50%] [G loss: 0.912773]\n",
      "epoch:28 step:26348 [D loss: 0.684630, acc.: 56.25%] [G loss: 1.063284]\n",
      "epoch:28 step:26349 [D loss: 0.887386, acc.: 41.41%] [G loss: 1.031571]\n",
      "epoch:28 step:26350 [D loss: 0.758052, acc.: 50.78%] [G loss: 1.095738]\n",
      "epoch:28 step:26351 [D loss: 0.673836, acc.: 61.72%] [G loss: 1.009514]\n",
      "epoch:28 step:26352 [D loss: 0.497674, acc.: 72.66%] [G loss: 0.789924]\n",
      "epoch:28 step:26353 [D loss: 0.322686, acc.: 88.28%] [G loss: 1.418275]\n",
      "epoch:28 step:26354 [D loss: 0.496985, acc.: 79.69%] [G loss: 1.301512]\n",
      "epoch:28 step:26355 [D loss: 0.157030, acc.: 100.00%] [G loss: 1.611885]\n",
      "epoch:28 step:26356 [D loss: 0.963342, acc.: 50.00%] [G loss: 1.476048]\n",
      "epoch:28 step:26357 [D loss: 0.548663, acc.: 67.19%] [G loss: 1.413412]\n",
      "epoch:28 step:26358 [D loss: 0.253273, acc.: 95.31%] [G loss: 1.573468]\n",
      "epoch:28 step:26359 [D loss: 0.616902, acc.: 66.41%] [G loss: 1.232233]\n",
      "epoch:28 step:26360 [D loss: 0.596970, acc.: 67.97%] [G loss: 1.106249]\n",
      "epoch:28 step:26361 [D loss: 0.833879, acc.: 49.22%] [G loss: 1.110564]\n",
      "epoch:28 step:26362 [D loss: 0.426603, acc.: 88.28%] [G loss: 1.322046]\n",
      "epoch:28 step:26363 [D loss: 0.759760, acc.: 50.78%] [G loss: 1.041547]\n",
      "epoch:28 step:26364 [D loss: 0.536295, acc.: 75.00%] [G loss: 1.411626]\n",
      "epoch:28 step:26365 [D loss: 0.519333, acc.: 74.22%] [G loss: 1.360026]\n",
      "epoch:28 step:26366 [D loss: 0.314656, acc.: 94.53%] [G loss: 1.445258]\n",
      "epoch:28 step:26367 [D loss: 0.361187, acc.: 86.72%] [G loss: 1.237636]\n",
      "epoch:28 step:26368 [D loss: 0.428750, acc.: 85.94%] [G loss: 1.403875]\n",
      "epoch:28 step:26369 [D loss: 0.707070, acc.: 54.69%] [G loss: 1.195687]\n",
      "epoch:28 step:26370 [D loss: 0.800705, acc.: 46.09%] [G loss: 0.949420]\n",
      "epoch:28 step:26371 [D loss: 0.784812, acc.: 45.31%] [G loss: 0.824222]\n",
      "epoch:28 step:26372 [D loss: 0.595944, acc.: 71.88%] [G loss: 1.166905]\n",
      "epoch:28 step:26373 [D loss: 0.732345, acc.: 50.00%] [G loss: 0.855465]\n",
      "epoch:28 step:26374 [D loss: 0.807930, acc.: 39.06%] [G loss: 0.685516]\n",
      "epoch:28 step:26375 [D loss: 0.446796, acc.: 83.59%] [G loss: 1.343384]\n",
      "epoch:28 step:26376 [D loss: 0.519392, acc.: 78.12%] [G loss: 1.252117]\n",
      "epoch:28 step:26377 [D loss: 0.632599, acc.: 62.50%] [G loss: 0.932737]\n",
      "epoch:28 step:26378 [D loss: 0.810742, acc.: 51.56%] [G loss: 0.985046]\n",
      "epoch:28 step:26379 [D loss: 0.592283, acc.: 64.84%] [G loss: 1.183622]\n",
      "epoch:28 step:26380 [D loss: 0.532955, acc.: 69.53%] [G loss: 1.295765]\n",
      "epoch:28 step:26381 [D loss: 0.392995, acc.: 85.94%] [G loss: 1.413059]\n",
      "epoch:28 step:26382 [D loss: 0.608793, acc.: 64.06%] [G loss: 1.226936]\n",
      "epoch:28 step:26383 [D loss: 0.578171, acc.: 70.31%] [G loss: 1.164669]\n",
      "epoch:28 step:26384 [D loss: 0.794195, acc.: 42.97%] [G loss: 0.995118]\n",
      "epoch:28 step:26385 [D loss: 0.804937, acc.: 46.88%] [G loss: 0.899098]\n",
      "epoch:28 step:26386 [D loss: 0.386231, acc.: 92.19%] [G loss: 1.200731]\n",
      "epoch:28 step:26387 [D loss: 0.443958, acc.: 82.81%] [G loss: 1.420960]\n",
      "epoch:28 step:26388 [D loss: 0.352969, acc.: 90.62%] [G loss: 1.476620]\n",
      "epoch:28 step:26389 [D loss: 0.745008, acc.: 55.47%] [G loss: 1.150108]\n",
      "epoch:28 step:26390 [D loss: 0.515402, acc.: 75.78%] [G loss: 1.300039]\n",
      "epoch:28 step:26391 [D loss: 0.387801, acc.: 91.41%] [G loss: 1.278505]\n",
      "epoch:28 step:26392 [D loss: 0.223962, acc.: 98.44%] [G loss: 1.321614]\n",
      "epoch:28 step:26393 [D loss: 0.459212, acc.: 84.38%] [G loss: 1.393510]\n",
      "epoch:28 step:26394 [D loss: 0.368054, acc.: 89.84%] [G loss: 1.768299]\n",
      "epoch:28 step:26395 [D loss: 0.241080, acc.: 96.88%] [G loss: 1.795384]\n",
      "epoch:28 step:26396 [D loss: 0.694191, acc.: 60.16%] [G loss: 1.483184]\n",
      "epoch:28 step:26397 [D loss: 0.722835, acc.: 48.44%] [G loss: 1.112633]\n",
      "epoch:28 step:26398 [D loss: 0.525351, acc.: 73.44%] [G loss: 1.281643]\n",
      "epoch:28 step:26399 [D loss: 0.325823, acc.: 91.41%] [G loss: 1.195223]\n",
      "epoch:28 step:26400 [D loss: 0.577004, acc.: 64.06%] [G loss: 0.872103]\n",
      "##############\n",
      "[2.63155658 1.60009017 5.58466953 4.52804345 3.17620441 5.23031679\n",
      " 4.17445374 4.5586861  4.08660228 3.80707973]\n",
      "##########\n",
      "epoch:28 step:26401 [D loss: 0.362291, acc.: 91.41%] [G loss: 1.507552]\n",
      "epoch:28 step:26402 [D loss: 0.315227, acc.: 95.31%] [G loss: 1.487360]\n",
      "epoch:28 step:26403 [D loss: 0.357350, acc.: 93.75%] [G loss: 1.677372]\n",
      "epoch:28 step:26404 [D loss: 0.247243, acc.: 96.88%] [G loss: 1.944106]\n",
      "epoch:28 step:26405 [D loss: 0.431672, acc.: 85.94%] [G loss: 1.274714]\n",
      "epoch:28 step:26406 [D loss: 0.637938, acc.: 62.50%] [G loss: 1.092430]\n",
      "epoch:28 step:26407 [D loss: 0.746473, acc.: 53.12%] [G loss: 1.099756]\n",
      "epoch:28 step:26408 [D loss: 0.530556, acc.: 75.78%] [G loss: 1.480224]\n",
      "epoch:28 step:26409 [D loss: 0.599982, acc.: 65.62%] [G loss: 1.665532]\n",
      "epoch:28 step:26410 [D loss: 0.972686, acc.: 31.25%] [G loss: 0.860482]\n",
      "epoch:28 step:26411 [D loss: 0.774505, acc.: 47.66%] [G loss: 1.122233]\n",
      "epoch:28 step:26412 [D loss: 0.854681, acc.: 50.00%] [G loss: 0.741238]\n",
      "epoch:28 step:26413 [D loss: 1.027928, acc.: 30.47%] [G loss: 0.913811]\n",
      "epoch:28 step:26414 [D loss: 0.898330, acc.: 37.50%] [G loss: 0.864668]\n",
      "epoch:28 step:26415 [D loss: 0.916972, acc.: 31.25%] [G loss: 0.904063]\n",
      "epoch:28 step:26416 [D loss: 1.199647, acc.: 20.31%] [G loss: 0.645496]\n",
      "epoch:28 step:26417 [D loss: 0.585593, acc.: 71.09%] [G loss: 0.889821]\n",
      "epoch:28 step:26418 [D loss: 0.666350, acc.: 60.94%] [G loss: 1.227175]\n",
      "epoch:28 step:26419 [D loss: 0.939714, acc.: 35.16%] [G loss: 0.943162]\n",
      "epoch:28 step:26420 [D loss: 0.564993, acc.: 70.31%] [G loss: 1.362983]\n",
      "epoch:28 step:26421 [D loss: 0.934813, acc.: 35.16%] [G loss: 0.935111]\n",
      "epoch:28 step:26422 [D loss: 0.788202, acc.: 47.66%] [G loss: 1.305158]\n",
      "epoch:28 step:26423 [D loss: 1.371770, acc.: 25.78%] [G loss: 0.432715]\n",
      "epoch:28 step:26424 [D loss: 0.589698, acc.: 68.75%] [G loss: 1.179444]\n",
      "epoch:28 step:26425 [D loss: 0.986470, acc.: 34.38%] [G loss: 1.046649]\n",
      "epoch:28 step:26426 [D loss: 0.688614, acc.: 64.06%] [G loss: 1.225558]\n",
      "epoch:28 step:26427 [D loss: 0.693847, acc.: 56.25%] [G loss: 0.993091]\n",
      "epoch:28 step:26428 [D loss: 0.568610, acc.: 69.53%] [G loss: 1.043355]\n",
      "epoch:28 step:26429 [D loss: 0.805275, acc.: 40.62%] [G loss: 0.951452]\n",
      "epoch:28 step:26430 [D loss: 0.544868, acc.: 72.66%] [G loss: 1.220437]\n",
      "epoch:28 step:26431 [D loss: 0.793095, acc.: 44.53%] [G loss: 1.185957]\n",
      "epoch:28 step:26432 [D loss: 0.985989, acc.: 31.25%] [G loss: 1.115899]\n",
      "epoch:28 step:26433 [D loss: 0.600511, acc.: 64.06%] [G loss: 1.281870]\n",
      "epoch:28 step:26434 [D loss: 0.793906, acc.: 50.00%] [G loss: 1.273247]\n",
      "epoch:28 step:26435 [D loss: 0.882718, acc.: 42.19%] [G loss: 0.993108]\n",
      "epoch:28 step:26436 [D loss: 0.809063, acc.: 46.09%] [G loss: 0.941126]\n",
      "epoch:28 step:26437 [D loss: 0.522313, acc.: 78.12%] [G loss: 1.542725]\n",
      "epoch:28 step:26438 [D loss: 0.762827, acc.: 60.16%] [G loss: 1.542415]\n",
      "epoch:28 step:26439 [D loss: 0.770402, acc.: 52.34%] [G loss: 1.123686]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26440 [D loss: 0.772763, acc.: 44.53%] [G loss: 1.079679]\n",
      "epoch:28 step:26441 [D loss: 0.722462, acc.: 58.59%] [G loss: 1.051403]\n",
      "epoch:28 step:26442 [D loss: 0.604030, acc.: 67.97%] [G loss: 1.176397]\n",
      "epoch:28 step:26443 [D loss: 0.589410, acc.: 66.41%] [G loss: 1.021320]\n",
      "epoch:28 step:26444 [D loss: 0.682848, acc.: 59.38%] [G loss: 1.172485]\n",
      "epoch:28 step:26445 [D loss: 0.558307, acc.: 73.44%] [G loss: 1.098853]\n",
      "epoch:28 step:26446 [D loss: 0.772471, acc.: 46.09%] [G loss: 1.195106]\n",
      "epoch:28 step:26447 [D loss: 0.650495, acc.: 59.38%] [G loss: 1.144863]\n",
      "epoch:28 step:26448 [D loss: 0.658351, acc.: 62.50%] [G loss: 1.348483]\n",
      "epoch:28 step:26449 [D loss: 0.535520, acc.: 75.78%] [G loss: 1.378386]\n",
      "epoch:28 step:26450 [D loss: 0.645440, acc.: 61.72%] [G loss: 1.317494]\n",
      "epoch:28 step:26451 [D loss: 0.454639, acc.: 81.25%] [G loss: 1.185805]\n",
      "epoch:28 step:26452 [D loss: 0.599499, acc.: 65.62%] [G loss: 1.036370]\n",
      "epoch:28 step:26453 [D loss: 0.700009, acc.: 56.25%] [G loss: 1.204284]\n",
      "epoch:28 step:26454 [D loss: 0.738906, acc.: 51.56%] [G loss: 1.017020]\n",
      "epoch:28 step:26455 [D loss: 0.782061, acc.: 48.44%] [G loss: 0.952348]\n",
      "epoch:28 step:26456 [D loss: 0.346351, acc.: 82.81%] [G loss: 1.150195]\n",
      "epoch:28 step:26457 [D loss: 0.234966, acc.: 96.09%] [G loss: 1.745619]\n",
      "epoch:28 step:26458 [D loss: 0.387868, acc.: 85.16%] [G loss: 1.398238]\n",
      "epoch:28 step:26459 [D loss: 0.211684, acc.: 97.66%] [G loss: 1.846674]\n",
      "epoch:28 step:26460 [D loss: 0.779131, acc.: 53.12%] [G loss: 1.400749]\n",
      "epoch:28 step:26461 [D loss: 0.631017, acc.: 63.28%] [G loss: 1.185534]\n",
      "epoch:28 step:26462 [D loss: 0.530913, acc.: 72.66%] [G loss: 1.112918]\n",
      "epoch:28 step:26463 [D loss: 0.653625, acc.: 65.62%] [G loss: 1.171347]\n",
      "epoch:28 step:26464 [D loss: 0.593575, acc.: 69.53%] [G loss: 0.904879]\n",
      "epoch:28 step:26465 [D loss: 0.503621, acc.: 76.56%] [G loss: 1.072954]\n",
      "epoch:28 step:26466 [D loss: 0.270452, acc.: 89.06%] [G loss: 1.550578]\n",
      "epoch:28 step:26467 [D loss: 0.315016, acc.: 89.84%] [G loss: 1.849725]\n",
      "epoch:28 step:26468 [D loss: 0.332031, acc.: 88.28%] [G loss: 1.436903]\n",
      "epoch:28 step:26469 [D loss: 1.059180, acc.: 50.00%] [G loss: 1.408874]\n",
      "epoch:28 step:26470 [D loss: 0.881534, acc.: 42.19%] [G loss: 1.156011]\n",
      "epoch:28 step:26471 [D loss: 0.395169, acc.: 84.38%] [G loss: 1.455730]\n",
      "epoch:28 step:26472 [D loss: 0.519202, acc.: 78.12%] [G loss: 1.270074]\n",
      "epoch:28 step:26473 [D loss: 0.465393, acc.: 80.47%] [G loss: 0.981277]\n",
      "epoch:28 step:26474 [D loss: 0.458369, acc.: 77.34%] [G loss: 1.020467]\n",
      "epoch:28 step:26475 [D loss: 0.925265, acc.: 35.94%] [G loss: 0.669309]\n",
      "epoch:28 step:26476 [D loss: 0.868892, acc.: 38.28%] [G loss: 0.806444]\n",
      "epoch:28 step:26477 [D loss: 0.898551, acc.: 39.06%] [G loss: 0.734683]\n",
      "epoch:28 step:26478 [D loss: 0.962322, acc.: 26.56%] [G loss: 0.757248]\n",
      "epoch:28 step:26479 [D loss: 0.668467, acc.: 64.06%] [G loss: 0.851577]\n",
      "epoch:28 step:26480 [D loss: 0.799747, acc.: 49.22%] [G loss: 1.265672]\n",
      "epoch:28 step:26481 [D loss: 0.733946, acc.: 54.69%] [G loss: 0.987123]\n",
      "epoch:28 step:26482 [D loss: 0.674414, acc.: 57.03%] [G loss: 1.162461]\n",
      "epoch:28 step:26483 [D loss: 0.726065, acc.: 50.78%] [G loss: 1.150847]\n",
      "epoch:28 step:26484 [D loss: 0.590034, acc.: 71.09%] [G loss: 1.113058]\n",
      "epoch:28 step:26485 [D loss: 0.714501, acc.: 50.78%] [G loss: 1.243814]\n",
      "epoch:28 step:26486 [D loss: 0.535887, acc.: 76.56%] [G loss: 1.040561]\n",
      "epoch:28 step:26487 [D loss: 0.664576, acc.: 60.94%] [G loss: 1.035526]\n",
      "epoch:28 step:26488 [D loss: 0.613925, acc.: 67.19%] [G loss: 0.983440]\n",
      "epoch:28 step:26489 [D loss: 0.540092, acc.: 76.56%] [G loss: 1.087339]\n",
      "epoch:28 step:26490 [D loss: 0.662885, acc.: 61.72%] [G loss: 0.845065]\n",
      "epoch:28 step:26491 [D loss: 0.756425, acc.: 52.34%] [G loss: 0.906088]\n",
      "epoch:28 step:26492 [D loss: 0.571805, acc.: 69.53%] [G loss: 0.950984]\n",
      "epoch:28 step:26493 [D loss: 0.602491, acc.: 70.31%] [G loss: 0.930172]\n",
      "epoch:28 step:26494 [D loss: 0.637295, acc.: 60.16%] [G loss: 1.161045]\n",
      "epoch:28 step:26495 [D loss: 0.496884, acc.: 75.78%] [G loss: 1.188996]\n",
      "epoch:28 step:26496 [D loss: 0.528117, acc.: 72.66%] [G loss: 1.097639]\n",
      "epoch:28 step:26497 [D loss: 0.486268, acc.: 78.91%] [G loss: 1.213809]\n",
      "epoch:28 step:26498 [D loss: 0.611662, acc.: 64.06%] [G loss: 1.168977]\n",
      "epoch:28 step:26499 [D loss: 0.543119, acc.: 72.66%] [G loss: 1.374455]\n",
      "epoch:28 step:26500 [D loss: 0.520906, acc.: 75.78%] [G loss: 1.319961]\n",
      "epoch:28 step:26501 [D loss: 0.646780, acc.: 59.38%] [G loss: 1.168133]\n",
      "epoch:28 step:26502 [D loss: 0.761267, acc.: 51.56%] [G loss: 0.995336]\n",
      "epoch:28 step:26503 [D loss: 0.483325, acc.: 81.25%] [G loss: 1.124760]\n",
      "epoch:28 step:26504 [D loss: 0.634058, acc.: 64.06%] [G loss: 0.959456]\n",
      "epoch:28 step:26505 [D loss: 0.410207, acc.: 87.50%] [G loss: 1.132056]\n",
      "epoch:28 step:26506 [D loss: 0.588217, acc.: 69.53%] [G loss: 0.962447]\n",
      "epoch:28 step:26507 [D loss: 0.382060, acc.: 94.53%] [G loss: 1.369126]\n",
      "epoch:28 step:26508 [D loss: 0.378824, acc.: 90.62%] [G loss: 1.475718]\n",
      "epoch:28 step:26509 [D loss: 0.527810, acc.: 72.66%] [G loss: 1.334023]\n",
      "epoch:28 step:26510 [D loss: 0.533644, acc.: 76.56%] [G loss: 1.110539]\n",
      "epoch:28 step:26511 [D loss: 0.585741, acc.: 71.09%] [G loss: 1.053858]\n",
      "epoch:28 step:26512 [D loss: 0.525326, acc.: 76.56%] [G loss: 1.105795]\n",
      "epoch:28 step:26513 [D loss: 0.723519, acc.: 56.25%] [G loss: 0.843544]\n",
      "epoch:28 step:26514 [D loss: 0.731804, acc.: 54.69%] [G loss: 1.088728]\n",
      "epoch:28 step:26515 [D loss: 0.343901, acc.: 89.06%] [G loss: 1.382694]\n",
      "epoch:28 step:26516 [D loss: 0.462093, acc.: 82.03%] [G loss: 1.440625]\n",
      "epoch:28 step:26517 [D loss: 0.665501, acc.: 60.94%] [G loss: 0.923572]\n",
      "epoch:28 step:26518 [D loss: 0.529862, acc.: 73.44%] [G loss: 1.101055]\n",
      "epoch:28 step:26519 [D loss: 0.726555, acc.: 53.12%] [G loss: 1.125676]\n",
      "epoch:28 step:26520 [D loss: 0.673661, acc.: 60.94%] [G loss: 1.065770]\n",
      "epoch:28 step:26521 [D loss: 0.476254, acc.: 82.81%] [G loss: 1.481354]\n",
      "epoch:28 step:26522 [D loss: 0.405408, acc.: 82.03%] [G loss: 1.264691]\n",
      "epoch:28 step:26523 [D loss: 0.641948, acc.: 64.06%] [G loss: 1.384345]\n",
      "epoch:28 step:26524 [D loss: 0.558413, acc.: 71.88%] [G loss: 1.382903]\n",
      "epoch:28 step:26525 [D loss: 0.428941, acc.: 86.72%] [G loss: 1.277375]\n",
      "epoch:28 step:26526 [D loss: 0.600826, acc.: 68.75%] [G loss: 1.215691]\n",
      "epoch:28 step:26527 [D loss: 0.374305, acc.: 82.81%] [G loss: 1.247020]\n",
      "epoch:28 step:26528 [D loss: 0.428048, acc.: 85.94%] [G loss: 1.379652]\n",
      "epoch:28 step:26529 [D loss: 0.391529, acc.: 88.28%] [G loss: 1.380943]\n",
      "epoch:28 step:26530 [D loss: 0.723673, acc.: 57.03%] [G loss: 0.965641]\n",
      "epoch:28 step:26531 [D loss: 0.953476, acc.: 28.91%] [G loss: 0.786683]\n",
      "epoch:28 step:26532 [D loss: 0.682425, acc.: 64.06%] [G loss: 1.388706]\n",
      "epoch:28 step:26533 [D loss: 0.640134, acc.: 63.28%] [G loss: 0.943845]\n",
      "epoch:28 step:26534 [D loss: 0.399838, acc.: 89.84%] [G loss: 1.361660]\n",
      "epoch:28 step:26535 [D loss: 0.496567, acc.: 82.03%] [G loss: 1.381062]\n",
      "epoch:28 step:26536 [D loss: 0.517416, acc.: 76.56%] [G loss: 1.224700]\n",
      "epoch:28 step:26537 [D loss: 0.754353, acc.: 52.34%] [G loss: 1.053216]\n",
      "epoch:28 step:26538 [D loss: 0.544825, acc.: 75.78%] [G loss: 1.194918]\n",
      "epoch:28 step:26539 [D loss: 0.657108, acc.: 59.38%] [G loss: 0.786228]\n",
      "epoch:28 step:26540 [D loss: 0.602656, acc.: 64.06%] [G loss: 1.246344]\n",
      "epoch:28 step:26541 [D loss: 0.549561, acc.: 76.56%] [G loss: 0.885707]\n",
      "epoch:28 step:26542 [D loss: 0.716366, acc.: 55.47%] [G loss: 1.009352]\n",
      "epoch:28 step:26543 [D loss: 0.631409, acc.: 69.53%] [G loss: 1.006068]\n",
      "epoch:28 step:26544 [D loss: 0.478876, acc.: 78.91%] [G loss: 1.053898]\n",
      "epoch:28 step:26545 [D loss: 0.519131, acc.: 75.00%] [G loss: 1.142814]\n",
      "epoch:28 step:26546 [D loss: 0.539478, acc.: 72.66%] [G loss: 1.250555]\n",
      "epoch:28 step:26547 [D loss: 0.527211, acc.: 74.22%] [G loss: 1.116652]\n",
      "epoch:28 step:26548 [D loss: 0.226462, acc.: 97.66%] [G loss: 1.388023]\n",
      "epoch:28 step:26549 [D loss: 0.304651, acc.: 92.19%] [G loss: 0.985985]\n",
      "epoch:28 step:26550 [D loss: 0.278541, acc.: 96.88%] [G loss: 1.785501]\n",
      "epoch:28 step:26551 [D loss: 0.398022, acc.: 87.50%] [G loss: 1.472233]\n",
      "epoch:28 step:26552 [D loss: 0.794637, acc.: 50.00%] [G loss: 1.398825]\n",
      "epoch:28 step:26553 [D loss: 0.852316, acc.: 36.72%] [G loss: 0.820120]\n",
      "epoch:28 step:26554 [D loss: 0.509570, acc.: 79.69%] [G loss: 1.160258]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26555 [D loss: 0.664127, acc.: 58.59%] [G loss: 1.117024]\n",
      "epoch:28 step:26556 [D loss: 0.585883, acc.: 75.00%] [G loss: 1.006365]\n",
      "epoch:28 step:26557 [D loss: 0.441503, acc.: 85.16%] [G loss: 1.260930]\n",
      "epoch:28 step:26558 [D loss: 0.452510, acc.: 78.91%] [G loss: 1.105385]\n",
      "epoch:28 step:26559 [D loss: 0.742773, acc.: 53.91%] [G loss: 1.281232]\n",
      "epoch:28 step:26560 [D loss: 0.681680, acc.: 54.69%] [G loss: 1.089893]\n",
      "epoch:28 step:26561 [D loss: 0.595167, acc.: 69.53%] [G loss: 0.849731]\n",
      "epoch:28 step:26562 [D loss: 0.481447, acc.: 77.34%] [G loss: 1.185456]\n",
      "epoch:28 step:26563 [D loss: 0.342163, acc.: 91.41%] [G loss: 1.434482]\n",
      "epoch:28 step:26564 [D loss: 0.441478, acc.: 79.69%] [G loss: 1.405005]\n",
      "epoch:28 step:26565 [D loss: 0.581893, acc.: 69.53%] [G loss: 1.143201]\n",
      "epoch:28 step:26566 [D loss: 0.820872, acc.: 45.31%] [G loss: 1.073944]\n",
      "epoch:28 step:26567 [D loss: 0.752973, acc.: 43.75%] [G loss: 1.095023]\n",
      "epoch:28 step:26568 [D loss: 0.640815, acc.: 63.28%] [G loss: 1.188781]\n",
      "epoch:28 step:26569 [D loss: 0.503671, acc.: 80.47%] [G loss: 1.012753]\n",
      "epoch:28 step:26570 [D loss: 0.547176, acc.: 74.22%] [G loss: 1.174634]\n",
      "epoch:28 step:26571 [D loss: 0.516123, acc.: 77.34%] [G loss: 1.232557]\n",
      "epoch:28 step:26572 [D loss: 0.549065, acc.: 75.00%] [G loss: 1.198162]\n",
      "epoch:28 step:26573 [D loss: 0.624520, acc.: 65.62%] [G loss: 1.147616]\n",
      "epoch:28 step:26574 [D loss: 0.726545, acc.: 57.03%] [G loss: 0.797739]\n",
      "epoch:28 step:26575 [D loss: 0.717652, acc.: 53.91%] [G loss: 1.074888]\n",
      "epoch:28 step:26576 [D loss: 0.606700, acc.: 64.84%] [G loss: 0.989323]\n",
      "epoch:28 step:26577 [D loss: 0.670665, acc.: 58.59%] [G loss: 1.256805]\n",
      "epoch:28 step:26578 [D loss: 0.492840, acc.: 76.56%] [G loss: 1.190512]\n",
      "epoch:28 step:26579 [D loss: 0.256776, acc.: 94.53%] [G loss: 1.445701]\n",
      "epoch:28 step:26580 [D loss: 0.374066, acc.: 86.72%] [G loss: 1.696858]\n",
      "epoch:28 step:26581 [D loss: 0.257009, acc.: 96.88%] [G loss: 1.611287]\n",
      "epoch:28 step:26582 [D loss: 0.331744, acc.: 89.06%] [G loss: 1.400152]\n",
      "epoch:28 step:26583 [D loss: 0.260646, acc.: 91.41%] [G loss: 2.168440]\n",
      "epoch:28 step:26584 [D loss: 0.888240, acc.: 49.22%] [G loss: 1.645305]\n",
      "epoch:28 step:26585 [D loss: 0.783466, acc.: 52.34%] [G loss: 1.389810]\n",
      "epoch:28 step:26586 [D loss: 0.713774, acc.: 54.69%] [G loss: 1.136300]\n",
      "epoch:28 step:26587 [D loss: 0.372181, acc.: 92.97%] [G loss: 1.217036]\n",
      "epoch:28 step:26588 [D loss: 0.350953, acc.: 88.28%] [G loss: 1.334783]\n",
      "epoch:28 step:26589 [D loss: 0.378489, acc.: 89.06%] [G loss: 1.545907]\n",
      "epoch:28 step:26590 [D loss: 0.234871, acc.: 99.22%] [G loss: 1.863124]\n",
      "epoch:28 step:26591 [D loss: 0.570232, acc.: 66.41%] [G loss: 1.356500]\n",
      "epoch:28 step:26592 [D loss: 0.478331, acc.: 78.91%] [G loss: 1.141768]\n",
      "epoch:28 step:26593 [D loss: 0.495468, acc.: 75.78%] [G loss: 1.052518]\n",
      "epoch:28 step:26594 [D loss: 0.331123, acc.: 91.41%] [G loss: 1.185863]\n",
      "epoch:28 step:26595 [D loss: 0.278392, acc.: 94.53%] [G loss: 1.743758]\n",
      "epoch:28 step:26596 [D loss: 0.454138, acc.: 89.84%] [G loss: 1.093976]\n",
      "epoch:28 step:26597 [D loss: 0.557502, acc.: 71.09%] [G loss: 0.872306]\n",
      "epoch:28 step:26598 [D loss: 0.915674, acc.: 43.75%] [G loss: 1.007144]\n",
      "epoch:28 step:26599 [D loss: 0.985355, acc.: 34.38%] [G loss: 0.998617]\n",
      "epoch:28 step:26600 [D loss: 0.799652, acc.: 47.66%] [G loss: 1.014556]\n",
      "##############\n",
      "[2.3686976  1.39505405 5.52785474 4.3892337  2.97587796 5.26970774\n",
      " 4.17993818 4.33795105 4.16494299 3.53113506]\n",
      "##########\n",
      "epoch:28 step:26601 [D loss: 0.804158, acc.: 42.19%] [G loss: 0.827084]\n",
      "epoch:28 step:26602 [D loss: 0.560185, acc.: 72.66%] [G loss: 1.084156]\n",
      "epoch:28 step:26603 [D loss: 0.512992, acc.: 75.78%] [G loss: 1.438758]\n",
      "epoch:28 step:26604 [D loss: 0.671522, acc.: 60.94%] [G loss: 1.377242]\n",
      "epoch:28 step:26605 [D loss: 0.662952, acc.: 60.16%] [G loss: 1.006704]\n",
      "epoch:28 step:26606 [D loss: 0.446041, acc.: 82.81%] [G loss: 1.192611]\n",
      "epoch:28 step:26607 [D loss: 0.467953, acc.: 82.81%] [G loss: 1.212985]\n",
      "epoch:28 step:26608 [D loss: 0.659676, acc.: 57.81%] [G loss: 1.263397]\n",
      "epoch:28 step:26609 [D loss: 0.782856, acc.: 51.56%] [G loss: 0.908937]\n",
      "epoch:28 step:26610 [D loss: 0.614928, acc.: 64.84%] [G loss: 0.931053]\n",
      "epoch:28 step:26611 [D loss: 0.679079, acc.: 56.25%] [G loss: 1.118823]\n",
      "epoch:28 step:26612 [D loss: 0.803393, acc.: 43.75%] [G loss: 0.944761]\n",
      "epoch:28 step:26613 [D loss: 0.624701, acc.: 67.19%] [G loss: 0.889008]\n",
      "epoch:28 step:26614 [D loss: 0.446785, acc.: 75.78%] [G loss: 1.080199]\n",
      "epoch:28 step:26615 [D loss: 0.701033, acc.: 59.38%] [G loss: 1.099510]\n",
      "epoch:28 step:26616 [D loss: 0.588542, acc.: 71.88%] [G loss: 1.148247]\n",
      "epoch:28 step:26617 [D loss: 0.394228, acc.: 90.62%] [G loss: 1.483425]\n",
      "epoch:28 step:26618 [D loss: 0.857492, acc.: 43.75%] [G loss: 1.441227]\n",
      "epoch:28 step:26619 [D loss: 0.770002, acc.: 45.31%] [G loss: 0.930452]\n",
      "epoch:28 step:26620 [D loss: 0.511948, acc.: 76.56%] [G loss: 1.202166]\n",
      "epoch:28 step:26621 [D loss: 0.692777, acc.: 57.03%] [G loss: 0.798324]\n",
      "epoch:28 step:26622 [D loss: 0.864120, acc.: 36.72%] [G loss: 1.165781]\n",
      "epoch:28 step:26623 [D loss: 0.646155, acc.: 58.59%] [G loss: 1.340942]\n",
      "epoch:28 step:26624 [D loss: 0.589025, acc.: 65.62%] [G loss: 1.275217]\n",
      "epoch:28 step:26625 [D loss: 0.507093, acc.: 78.12%] [G loss: 0.921468]\n",
      "epoch:28 step:26626 [D loss: 0.385310, acc.: 85.16%] [G loss: 1.303073]\n",
      "epoch:28 step:26627 [D loss: 0.397751, acc.: 83.59%] [G loss: 1.443356]\n",
      "epoch:28 step:26628 [D loss: 0.546360, acc.: 74.22%] [G loss: 1.184127]\n",
      "epoch:28 step:26629 [D loss: 0.604259, acc.: 63.28%] [G loss: 1.275976]\n",
      "epoch:28 step:26630 [D loss: 0.369394, acc.: 87.50%] [G loss: 1.351224]\n",
      "epoch:28 step:26631 [D loss: 0.506243, acc.: 77.34%] [G loss: 1.398918]\n",
      "epoch:28 step:26632 [D loss: 0.356840, acc.: 78.91%] [G loss: 1.056025]\n",
      "epoch:28 step:26633 [D loss: 0.163894, acc.: 98.44%] [G loss: 1.798264]\n",
      "epoch:28 step:26634 [D loss: 0.156750, acc.: 98.44%] [G loss: 1.792828]\n",
      "epoch:28 step:26635 [D loss: 0.327070, acc.: 90.62%] [G loss: 1.535860]\n",
      "epoch:28 step:26636 [D loss: 0.257162, acc.: 93.75%] [G loss: 1.791438]\n",
      "epoch:28 step:26637 [D loss: 0.241561, acc.: 96.88%] [G loss: 1.694662]\n",
      "epoch:28 step:26638 [D loss: 0.359093, acc.: 88.28%] [G loss: 1.700345]\n",
      "epoch:28 step:26639 [D loss: 1.141762, acc.: 30.47%] [G loss: 0.866301]\n",
      "epoch:28 step:26640 [D loss: 0.154396, acc.: 100.00%] [G loss: 2.555668]\n",
      "epoch:28 step:26641 [D loss: 0.163859, acc.: 99.22%] [G loss: 1.918777]\n",
      "epoch:28 step:26642 [D loss: 0.275020, acc.: 96.88%] [G loss: 1.854811]\n",
      "epoch:28 step:26643 [D loss: 0.572374, acc.: 69.53%] [G loss: 1.242585]\n",
      "epoch:28 step:26644 [D loss: 0.990824, acc.: 47.66%] [G loss: 0.435423]\n",
      "epoch:28 step:26645 [D loss: 0.388047, acc.: 89.06%] [G loss: 1.887091]\n",
      "epoch:28 step:26646 [D loss: 0.932555, acc.: 34.38%] [G loss: 0.775349]\n",
      "epoch:28 step:26647 [D loss: 1.342153, acc.: 12.50%] [G loss: 0.762187]\n",
      "epoch:28 step:26648 [D loss: 1.304358, acc.: 17.97%] [G loss: 0.434728]\n",
      "epoch:28 step:26649 [D loss: 1.161446, acc.: 15.62%] [G loss: 0.744442]\n",
      "epoch:28 step:26650 [D loss: 0.748375, acc.: 50.78%] [G loss: 1.025800]\n",
      "epoch:28 step:26651 [D loss: 0.922639, acc.: 45.31%] [G loss: 1.269592]\n",
      "epoch:28 step:26652 [D loss: 0.889774, acc.: 42.97%] [G loss: 1.037515]\n",
      "epoch:28 step:26653 [D loss: 0.889649, acc.: 44.53%] [G loss: 1.149513]\n",
      "epoch:28 step:26654 [D loss: 0.736979, acc.: 54.69%] [G loss: 1.046049]\n",
      "epoch:28 step:26655 [D loss: 0.641161, acc.: 65.62%] [G loss: 1.257978]\n",
      "epoch:28 step:26656 [D loss: 0.549644, acc.: 72.66%] [G loss: 1.169067]\n",
      "epoch:28 step:26657 [D loss: 0.777296, acc.: 52.34%] [G loss: 0.977655]\n",
      "epoch:28 step:26658 [D loss: 0.641449, acc.: 65.62%] [G loss: 1.062073]\n",
      "epoch:28 step:26659 [D loss: 0.689430, acc.: 63.28%] [G loss: 1.016195]\n",
      "epoch:28 step:26660 [D loss: 0.804122, acc.: 46.09%] [G loss: 1.058289]\n",
      "epoch:28 step:26661 [D loss: 0.806329, acc.: 46.88%] [G loss: 0.871074]\n",
      "epoch:28 step:26662 [D loss: 0.771378, acc.: 50.78%] [G loss: 1.107400]\n",
      "epoch:28 step:26663 [D loss: 0.676446, acc.: 55.47%] [G loss: 1.227716]\n",
      "epoch:28 step:26664 [D loss: 0.775094, acc.: 48.44%] [G loss: 0.939777]\n",
      "epoch:28 step:26665 [D loss: 0.822015, acc.: 49.22%] [G loss: 0.947358]\n",
      "epoch:28 step:26666 [D loss: 0.671125, acc.: 60.16%] [G loss: 1.241322]\n",
      "epoch:28 step:26667 [D loss: 0.608464, acc.: 65.62%] [G loss: 1.331627]\n",
      "epoch:28 step:26668 [D loss: 0.546570, acc.: 78.12%] [G loss: 1.460186]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26669 [D loss: 0.485657, acc.: 79.69%] [G loss: 1.520493]\n",
      "epoch:28 step:26670 [D loss: 0.557730, acc.: 68.75%] [G loss: 1.510673]\n",
      "epoch:28 step:26671 [D loss: 0.533170, acc.: 72.66%] [G loss: 1.625036]\n",
      "epoch:28 step:26672 [D loss: 0.416395, acc.: 87.50%] [G loss: 1.620266]\n",
      "epoch:28 step:26673 [D loss: 0.716210, acc.: 56.25%] [G loss: 1.321830]\n",
      "epoch:28 step:26674 [D loss: 0.800874, acc.: 49.22%] [G loss: 1.212806]\n",
      "epoch:28 step:26675 [D loss: 0.754558, acc.: 51.56%] [G loss: 0.980484]\n",
      "epoch:28 step:26676 [D loss: 0.752411, acc.: 56.25%] [G loss: 1.012109]\n",
      "epoch:28 step:26677 [D loss: 0.844721, acc.: 49.22%] [G loss: 1.096867]\n",
      "epoch:28 step:26678 [D loss: 0.779217, acc.: 45.31%] [G loss: 1.150520]\n",
      "epoch:28 step:26679 [D loss: 0.777137, acc.: 50.00%] [G loss: 0.894810]\n",
      "epoch:28 step:26680 [D loss: 0.694447, acc.: 58.59%] [G loss: 0.929051]\n",
      "epoch:28 step:26681 [D loss: 0.745330, acc.: 50.78%] [G loss: 0.942715]\n",
      "epoch:28 step:26682 [D loss: 0.831678, acc.: 51.56%] [G loss: 1.000059]\n",
      "epoch:28 step:26683 [D loss: 0.694282, acc.: 57.03%] [G loss: 0.970047]\n",
      "epoch:28 step:26684 [D loss: 0.521013, acc.: 77.34%] [G loss: 0.902855]\n",
      "epoch:28 step:26685 [D loss: 0.574066, acc.: 70.31%] [G loss: 1.022035]\n",
      "epoch:28 step:26686 [D loss: 0.571753, acc.: 70.31%] [G loss: 1.246476]\n",
      "epoch:28 step:26687 [D loss: 0.567789, acc.: 69.53%] [G loss: 0.995478]\n",
      "epoch:28 step:26688 [D loss: 0.473864, acc.: 78.91%] [G loss: 1.374352]\n",
      "epoch:28 step:26689 [D loss: 0.660220, acc.: 56.25%] [G loss: 1.181189]\n",
      "epoch:28 step:26690 [D loss: 0.660057, acc.: 60.16%] [G loss: 0.996569]\n",
      "epoch:28 step:26691 [D loss: 0.572627, acc.: 75.00%] [G loss: 1.226433]\n",
      "epoch:28 step:26692 [D loss: 0.512684, acc.: 77.34%] [G loss: 1.192050]\n",
      "epoch:28 step:26693 [D loss: 0.511487, acc.: 76.56%] [G loss: 1.182685]\n",
      "epoch:28 step:26694 [D loss: 0.875058, acc.: 37.50%] [G loss: 1.109660]\n",
      "epoch:28 step:26695 [D loss: 0.713607, acc.: 60.16%] [G loss: 1.403951]\n",
      "epoch:28 step:26696 [D loss: 0.887285, acc.: 38.28%] [G loss: 1.147021]\n",
      "epoch:28 step:26697 [D loss: 0.886985, acc.: 41.41%] [G loss: 0.967017]\n",
      "epoch:28 step:26698 [D loss: 0.644462, acc.: 64.84%] [G loss: 1.297150]\n",
      "epoch:28 step:26699 [D loss: 0.710215, acc.: 59.38%] [G loss: 1.059581]\n",
      "epoch:28 step:26700 [D loss: 0.639947, acc.: 65.62%] [G loss: 1.204370]\n",
      "epoch:28 step:26701 [D loss: 0.616183, acc.: 64.06%] [G loss: 1.122044]\n",
      "epoch:28 step:26702 [D loss: 0.594699, acc.: 67.97%] [G loss: 1.109301]\n",
      "epoch:28 step:26703 [D loss: 0.690072, acc.: 56.25%] [G loss: 1.016057]\n",
      "epoch:28 step:26704 [D loss: 0.353244, acc.: 92.97%] [G loss: 1.582782]\n",
      "epoch:28 step:26705 [D loss: 0.397964, acc.: 90.62%] [G loss: 1.205231]\n",
      "epoch:28 step:26706 [D loss: 0.276927, acc.: 92.19%] [G loss: 1.454508]\n",
      "epoch:28 step:26707 [D loss: 0.217997, acc.: 95.31%] [G loss: 1.704313]\n",
      "epoch:28 step:26708 [D loss: 0.422835, acc.: 83.59%] [G loss: 1.839144]\n",
      "epoch:28 step:26709 [D loss: 0.556012, acc.: 68.75%] [G loss: 1.537425]\n",
      "epoch:28 step:26710 [D loss: 0.351413, acc.: 89.06%] [G loss: 1.578941]\n",
      "epoch:28 step:26711 [D loss: 0.386304, acc.: 85.16%] [G loss: 1.375531]\n",
      "epoch:28 step:26712 [D loss: 0.708144, acc.: 58.59%] [G loss: 0.935274]\n",
      "epoch:28 step:26713 [D loss: 0.579498, acc.: 71.88%] [G loss: 1.338347]\n",
      "epoch:28 step:26714 [D loss: 0.792389, acc.: 46.09%] [G loss: 0.864284]\n",
      "epoch:28 step:26715 [D loss: 0.439817, acc.: 80.47%] [G loss: 1.189630]\n",
      "epoch:28 step:26716 [D loss: 0.537583, acc.: 69.53%] [G loss: 1.548895]\n",
      "epoch:28 step:26717 [D loss: 0.608691, acc.: 66.41%] [G loss: 0.870638]\n",
      "epoch:28 step:26718 [D loss: 0.608154, acc.: 61.72%] [G loss: 1.523099]\n",
      "epoch:28 step:26719 [D loss: 0.502420, acc.: 76.56%] [G loss: 1.243523]\n",
      "epoch:28 step:26720 [D loss: 0.353097, acc.: 86.72%] [G loss: 1.700143]\n",
      "epoch:28 step:26721 [D loss: 0.335744, acc.: 93.75%] [G loss: 1.627845]\n",
      "epoch:28 step:26722 [D loss: 0.422944, acc.: 82.03%] [G loss: 1.546703]\n",
      "epoch:28 step:26723 [D loss: 0.353865, acc.: 92.97%] [G loss: 1.400232]\n",
      "epoch:28 step:26724 [D loss: 0.593917, acc.: 70.31%] [G loss: 1.031300]\n",
      "epoch:28 step:26725 [D loss: 0.615957, acc.: 64.06%] [G loss: 1.304731]\n",
      "epoch:28 step:26726 [D loss: 0.332307, acc.: 92.97%] [G loss: 1.596591]\n",
      "epoch:28 step:26727 [D loss: 0.559216, acc.: 71.09%] [G loss: 1.416881]\n",
      "epoch:28 step:26728 [D loss: 0.778806, acc.: 51.56%] [G loss: 1.159836]\n",
      "epoch:28 step:26729 [D loss: 0.792898, acc.: 40.62%] [G loss: 1.131932]\n",
      "epoch:28 step:26730 [D loss: 0.743182, acc.: 46.09%] [G loss: 1.017808]\n",
      "epoch:28 step:26731 [D loss: 0.613375, acc.: 67.19%] [G loss: 1.131428]\n",
      "epoch:28 step:26732 [D loss: 0.666404, acc.: 56.25%] [G loss: 1.098596]\n",
      "epoch:28 step:26733 [D loss: 0.291779, acc.: 94.53%] [G loss: 1.341447]\n",
      "epoch:28 step:26734 [D loss: 0.340753, acc.: 89.06%] [G loss: 1.360094]\n",
      "epoch:28 step:26735 [D loss: 0.212370, acc.: 98.44%] [G loss: 1.606004]\n",
      "epoch:28 step:26736 [D loss: 0.873349, acc.: 50.00%] [G loss: 1.167866]\n",
      "epoch:28 step:26737 [D loss: 0.805246, acc.: 50.78%] [G loss: 1.204054]\n",
      "epoch:28 step:26738 [D loss: 0.669041, acc.: 58.59%] [G loss: 0.884860]\n",
      "epoch:28 step:26739 [D loss: 0.434871, acc.: 75.00%] [G loss: 0.850179]\n",
      "epoch:28 step:26740 [D loss: 0.349568, acc.: 84.38%] [G loss: 1.274665]\n",
      "epoch:28 step:26741 [D loss: 0.419652, acc.: 85.16%] [G loss: 1.619363]\n",
      "epoch:28 step:26742 [D loss: 0.557159, acc.: 72.66%] [G loss: 1.618484]\n",
      "epoch:28 step:26743 [D loss: 0.449314, acc.: 82.81%] [G loss: 1.394489]\n",
      "epoch:28 step:26744 [D loss: 0.338452, acc.: 91.41%] [G loss: 1.478382]\n",
      "epoch:28 step:26745 [D loss: 0.738577, acc.: 61.72%] [G loss: 1.373394]\n",
      "epoch:28 step:26746 [D loss: 0.610970, acc.: 66.41%] [G loss: 1.140098]\n",
      "epoch:28 step:26747 [D loss: 0.466026, acc.: 74.22%] [G loss: 1.216667]\n",
      "epoch:28 step:26748 [D loss: 0.211928, acc.: 96.88%] [G loss: 1.547153]\n",
      "epoch:28 step:26749 [D loss: 0.283680, acc.: 89.84%] [G loss: 1.538831]\n",
      "epoch:28 step:26750 [D loss: 0.411706, acc.: 86.72%] [G loss: 1.411682]\n",
      "epoch:28 step:26751 [D loss: 0.341198, acc.: 91.41%] [G loss: 1.965340]\n",
      "epoch:28 step:26752 [D loss: 0.646132, acc.: 63.28%] [G loss: 1.310104]\n",
      "epoch:28 step:26753 [D loss: 0.495390, acc.: 80.47%] [G loss: 1.257117]\n",
      "epoch:28 step:26754 [D loss: 0.658773, acc.: 63.28%] [G loss: 0.993183]\n",
      "epoch:28 step:26755 [D loss: 0.412206, acc.: 85.94%] [G loss: 1.352162]\n",
      "epoch:28 step:26756 [D loss: 0.393078, acc.: 85.16%] [G loss: 1.140009]\n",
      "epoch:28 step:26757 [D loss: 0.613686, acc.: 66.41%] [G loss: 1.193470]\n",
      "epoch:28 step:26758 [D loss: 0.413977, acc.: 92.19%] [G loss: 1.184968]\n",
      "epoch:28 step:26759 [D loss: 0.367961, acc.: 95.31%] [G loss: 1.210883]\n",
      "epoch:28 step:26760 [D loss: 0.594982, acc.: 70.31%] [G loss: 1.141111]\n",
      "epoch:28 step:26761 [D loss: 0.608988, acc.: 71.09%] [G loss: 1.105314]\n",
      "epoch:28 step:26762 [D loss: 0.519376, acc.: 79.69%] [G loss: 1.258642]\n",
      "epoch:28 step:26763 [D loss: 0.560871, acc.: 69.53%] [G loss: 0.962915]\n",
      "epoch:28 step:26764 [D loss: 0.543737, acc.: 72.66%] [G loss: 1.207731]\n",
      "epoch:28 step:26765 [D loss: 0.571938, acc.: 74.22%] [G loss: 0.992041]\n",
      "epoch:28 step:26766 [D loss: 0.512528, acc.: 75.00%] [G loss: 1.296823]\n",
      "epoch:28 step:26767 [D loss: 0.598490, acc.: 71.09%] [G loss: 1.301529]\n",
      "epoch:28 step:26768 [D loss: 0.485688, acc.: 80.47%] [G loss: 1.364953]\n",
      "epoch:28 step:26769 [D loss: 0.328087, acc.: 89.06%] [G loss: 1.335973]\n",
      "epoch:28 step:26770 [D loss: 0.404673, acc.: 85.16%] [G loss: 1.558436]\n",
      "epoch:28 step:26771 [D loss: 0.456970, acc.: 78.12%] [G loss: 1.414075]\n",
      "epoch:28 step:26772 [D loss: 0.241832, acc.: 100.00%] [G loss: 1.656089]\n",
      "epoch:28 step:26773 [D loss: 0.283567, acc.: 95.31%] [G loss: 1.477369]\n",
      "epoch:28 step:26774 [D loss: 0.592109, acc.: 64.84%] [G loss: 1.144444]\n",
      "epoch:28 step:26775 [D loss: 0.542162, acc.: 73.44%] [G loss: 1.069512]\n",
      "epoch:28 step:26776 [D loss: 0.758556, acc.: 48.44%] [G loss: 0.789322]\n",
      "epoch:28 step:26777 [D loss: 0.649965, acc.: 60.94%] [G loss: 1.091864]\n",
      "epoch:28 step:26778 [D loss: 0.497699, acc.: 83.59%] [G loss: 1.017872]\n",
      "epoch:28 step:26779 [D loss: 0.496793, acc.: 80.47%] [G loss: 1.316030]\n",
      "epoch:28 step:26780 [D loss: 0.553087, acc.: 71.09%] [G loss: 1.205863]\n",
      "epoch:28 step:26781 [D loss: 0.323749, acc.: 91.41%] [G loss: 1.515948]\n",
      "epoch:28 step:26782 [D loss: 0.246002, acc.: 98.44%] [G loss: 1.425614]\n",
      "epoch:28 step:26783 [D loss: 0.265979, acc.: 96.09%] [G loss: 1.343957]\n",
      "epoch:28 step:26784 [D loss: 0.384724, acc.: 91.41%] [G loss: 1.540810]\n",
      "epoch:28 step:26785 [D loss: 0.304938, acc.: 94.53%] [G loss: 1.214149]\n",
      "epoch:28 step:26786 [D loss: 0.279184, acc.: 96.88%] [G loss: 1.470789]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26787 [D loss: 0.209754, acc.: 98.44%] [G loss: 1.784702]\n",
      "epoch:28 step:26788 [D loss: 0.325233, acc.: 92.97%] [G loss: 1.470628]\n",
      "epoch:28 step:26789 [D loss: 0.620122, acc.: 64.84%] [G loss: 1.327126]\n",
      "epoch:28 step:26790 [D loss: 0.260843, acc.: 96.09%] [G loss: 2.033011]\n",
      "epoch:28 step:26791 [D loss: 0.260018, acc.: 96.88%] [G loss: 1.991827]\n",
      "epoch:28 step:26792 [D loss: 0.172739, acc.: 100.00%] [G loss: 1.928219]\n",
      "epoch:28 step:26793 [D loss: 0.417295, acc.: 84.38%] [G loss: 1.523019]\n",
      "epoch:28 step:26794 [D loss: 0.359191, acc.: 92.19%] [G loss: 1.783749]\n",
      "epoch:28 step:26795 [D loss: 0.461154, acc.: 80.47%] [G loss: 2.168520]\n",
      "epoch:28 step:26796 [D loss: 0.983685, acc.: 50.78%] [G loss: 1.533371]\n",
      "epoch:28 step:26797 [D loss: 0.329118, acc.: 97.66%] [G loss: 1.491053]\n",
      "epoch:28 step:26798 [D loss: 0.644720, acc.: 61.72%] [G loss: 1.153705]\n",
      "epoch:28 step:26799 [D loss: 0.784166, acc.: 41.41%] [G loss: 0.819138]\n",
      "epoch:28 step:26800 [D loss: 0.531148, acc.: 78.12%] [G loss: 1.460717]\n",
      "##############\n",
      "[2.33401096 1.69426615 5.6593055  4.23253008 3.25591647 5.65586049\n",
      " 4.07061586 4.74504192 4.08753565 3.99235145]\n",
      "##########\n",
      "epoch:28 step:26801 [D loss: 0.515751, acc.: 78.91%] [G loss: 1.156975]\n",
      "epoch:28 step:26802 [D loss: 0.316852, acc.: 90.62%] [G loss: 1.319110]\n",
      "epoch:28 step:26803 [D loss: 0.431131, acc.: 84.38%] [G loss: 1.387777]\n",
      "epoch:28 step:26804 [D loss: 1.078406, acc.: 24.22%] [G loss: 1.159123]\n",
      "epoch:28 step:26805 [D loss: 0.869044, acc.: 42.19%] [G loss: 1.163898]\n",
      "epoch:28 step:26806 [D loss: 0.589942, acc.: 64.84%] [G loss: 1.522945]\n",
      "epoch:28 step:26807 [D loss: 0.592071, acc.: 66.41%] [G loss: 1.073351]\n",
      "epoch:28 step:26808 [D loss: 0.750446, acc.: 48.44%] [G loss: 0.901897]\n",
      "epoch:28 step:26809 [D loss: 0.571262, acc.: 70.31%] [G loss: 1.084429]\n",
      "epoch:28 step:26810 [D loss: 0.590422, acc.: 68.75%] [G loss: 1.181156]\n",
      "epoch:28 step:26811 [D loss: 0.520900, acc.: 75.78%] [G loss: 1.245228]\n",
      "epoch:28 step:26812 [D loss: 0.443358, acc.: 85.94%] [G loss: 1.413790]\n",
      "epoch:28 step:26813 [D loss: 0.456095, acc.: 82.03%] [G loss: 1.403185]\n",
      "epoch:28 step:26814 [D loss: 0.355490, acc.: 92.19%] [G loss: 1.415361]\n",
      "epoch:28 step:26815 [D loss: 0.485269, acc.: 80.47%] [G loss: 1.027096]\n",
      "epoch:28 step:26816 [D loss: 0.689428, acc.: 57.81%] [G loss: 1.221873]\n",
      "epoch:28 step:26817 [D loss: 0.574447, acc.: 68.75%] [G loss: 1.219439]\n",
      "epoch:28 step:26818 [D loss: 0.601484, acc.: 69.53%] [G loss: 1.093218]\n",
      "epoch:28 step:26819 [D loss: 0.801616, acc.: 51.56%] [G loss: 0.716222]\n",
      "epoch:28 step:26820 [D loss: 0.739168, acc.: 52.34%] [G loss: 0.941474]\n",
      "epoch:28 step:26821 [D loss: 0.657377, acc.: 62.50%] [G loss: 1.206453]\n",
      "epoch:28 step:26822 [D loss: 0.646773, acc.: 56.25%] [G loss: 0.951493]\n",
      "epoch:28 step:26823 [D loss: 0.278135, acc.: 92.19%] [G loss: 1.260720]\n",
      "epoch:28 step:26824 [D loss: 0.215126, acc.: 99.22%] [G loss: 1.523334]\n",
      "epoch:28 step:26825 [D loss: 0.279368, acc.: 94.53%] [G loss: 1.376390]\n",
      "epoch:28 step:26826 [D loss: 0.635633, acc.: 65.62%] [G loss: 1.236037]\n",
      "epoch:28 step:26827 [D loss: 0.935662, acc.: 41.41%] [G loss: 1.145853]\n",
      "epoch:28 step:26828 [D loss: 0.486218, acc.: 81.25%] [G loss: 1.345996]\n",
      "epoch:28 step:26829 [D loss: 0.875069, acc.: 35.16%] [G loss: 1.306012]\n",
      "epoch:28 step:26830 [D loss: 0.435738, acc.: 85.94%] [G loss: 1.329157]\n",
      "epoch:28 step:26831 [D loss: 1.077615, acc.: 24.22%] [G loss: 0.908434]\n",
      "epoch:28 step:26832 [D loss: 0.422257, acc.: 88.28%] [G loss: 1.262061]\n",
      "epoch:28 step:26833 [D loss: 0.461597, acc.: 82.81%] [G loss: 1.271289]\n",
      "epoch:28 step:26834 [D loss: 0.242122, acc.: 97.66%] [G loss: 1.797226]\n",
      "epoch:28 step:26835 [D loss: 0.739950, acc.: 55.47%] [G loss: 1.246402]\n",
      "epoch:28 step:26836 [D loss: 0.589599, acc.: 71.09%] [G loss: 1.127945]\n",
      "epoch:28 step:26837 [D loss: 0.660368, acc.: 57.81%] [G loss: 1.180330]\n",
      "epoch:28 step:26838 [D loss: 0.565553, acc.: 71.88%] [G loss: 0.965068]\n",
      "epoch:28 step:26839 [D loss: 0.654845, acc.: 58.59%] [G loss: 0.975426]\n",
      "epoch:28 step:26840 [D loss: 0.300262, acc.: 96.88%] [G loss: 1.235839]\n",
      "epoch:28 step:26841 [D loss: 0.494410, acc.: 76.56%] [G loss: 1.355108]\n",
      "epoch:28 step:26842 [D loss: 0.619307, acc.: 67.97%] [G loss: 1.407962]\n",
      "epoch:28 step:26843 [D loss: 0.675457, acc.: 57.81%] [G loss: 1.095797]\n",
      "epoch:28 step:26844 [D loss: 0.704946, acc.: 54.69%] [G loss: 1.035093]\n",
      "epoch:28 step:26845 [D loss: 0.700840, acc.: 57.81%] [G loss: 0.934331]\n",
      "epoch:28 step:26846 [D loss: 0.645036, acc.: 60.94%] [G loss: 1.226624]\n",
      "epoch:28 step:26847 [D loss: 0.676400, acc.: 53.91%] [G loss: 1.064545]\n",
      "epoch:28 step:26848 [D loss: 0.580227, acc.: 66.41%] [G loss: 1.105295]\n",
      "epoch:28 step:26849 [D loss: 0.392004, acc.: 88.28%] [G loss: 1.429613]\n",
      "epoch:28 step:26850 [D loss: 0.471278, acc.: 78.91%] [G loss: 1.032637]\n",
      "epoch:28 step:26851 [D loss: 0.278370, acc.: 96.09%] [G loss: 1.313956]\n",
      "epoch:28 step:26852 [D loss: 0.276950, acc.: 93.75%] [G loss: 1.456154]\n",
      "epoch:28 step:26853 [D loss: 0.453901, acc.: 82.81%] [G loss: 1.332791]\n",
      "epoch:28 step:26854 [D loss: 0.762290, acc.: 50.00%] [G loss: 1.131845]\n",
      "epoch:28 step:26855 [D loss: 0.935420, acc.: 34.38%] [G loss: 0.763575]\n",
      "epoch:28 step:26856 [D loss: 0.599232, acc.: 65.62%] [G loss: 1.028331]\n",
      "epoch:28 step:26857 [D loss: 0.789816, acc.: 50.78%] [G loss: 0.863309]\n",
      "epoch:28 step:26858 [D loss: 0.616178, acc.: 69.53%] [G loss: 1.369552]\n",
      "epoch:28 step:26859 [D loss: 0.458116, acc.: 82.03%] [G loss: 1.223947]\n",
      "epoch:28 step:26860 [D loss: 0.393607, acc.: 86.72%] [G loss: 1.143779]\n",
      "epoch:28 step:26861 [D loss: 0.596440, acc.: 66.41%] [G loss: 1.206870]\n",
      "epoch:28 step:26862 [D loss: 0.584819, acc.: 67.97%] [G loss: 1.057654]\n",
      "epoch:28 step:26863 [D loss: 0.594290, acc.: 69.53%] [G loss: 1.101738]\n",
      "epoch:28 step:26864 [D loss: 0.674122, acc.: 56.25%] [G loss: 1.407526]\n",
      "epoch:28 step:26865 [D loss: 0.318245, acc.: 85.94%] [G loss: 1.443917]\n",
      "epoch:28 step:26866 [D loss: 0.414551, acc.: 85.16%] [G loss: 1.374989]\n",
      "epoch:28 step:26867 [D loss: 0.771727, acc.: 42.19%] [G loss: 0.970515]\n",
      "epoch:28 step:26868 [D loss: 0.475313, acc.: 77.34%] [G loss: 1.206263]\n",
      "epoch:28 step:26869 [D loss: 0.274873, acc.: 92.97%] [G loss: 1.749745]\n",
      "epoch:28 step:26870 [D loss: 0.334675, acc.: 93.75%] [G loss: 1.823262]\n",
      "epoch:28 step:26871 [D loss: 0.878880, acc.: 33.59%] [G loss: 0.854253]\n",
      "epoch:28 step:26872 [D loss: 1.235823, acc.: 14.84%] [G loss: 0.705998]\n",
      "epoch:28 step:26873 [D loss: 1.147031, acc.: 19.53%] [G loss: 1.085362]\n",
      "epoch:28 step:26874 [D loss: 0.871851, acc.: 40.62%] [G loss: 0.820459]\n",
      "epoch:28 step:26875 [D loss: 1.115437, acc.: 34.38%] [G loss: 1.408532]\n",
      "epoch:28 step:26876 [D loss: 0.838274, acc.: 40.62%] [G loss: 1.183660]\n",
      "epoch:28 step:26877 [D loss: 0.548781, acc.: 71.88%] [G loss: 1.676466]\n",
      "epoch:28 step:26878 [D loss: 0.299165, acc.: 92.97%] [G loss: 1.971403]\n",
      "epoch:28 step:26879 [D loss: 0.857282, acc.: 50.00%] [G loss: 1.543086]\n",
      "epoch:28 step:26880 [D loss: 0.719088, acc.: 52.34%] [G loss: 1.229559]\n",
      "epoch:28 step:26881 [D loss: 0.654992, acc.: 63.28%] [G loss: 1.285104]\n",
      "epoch:28 step:26882 [D loss: 0.473868, acc.: 82.03%] [G loss: 1.252052]\n",
      "epoch:28 step:26883 [D loss: 0.518522, acc.: 73.44%] [G loss: 1.087374]\n",
      "epoch:28 step:26884 [D loss: 0.462101, acc.: 78.12%] [G loss: 1.563609]\n",
      "epoch:28 step:26885 [D loss: 0.627548, acc.: 63.28%] [G loss: 1.207738]\n",
      "epoch:28 step:26886 [D loss: 0.437604, acc.: 85.16%] [G loss: 1.428882]\n",
      "epoch:28 step:26887 [D loss: 0.708360, acc.: 56.25%] [G loss: 1.012561]\n",
      "epoch:28 step:26888 [D loss: 0.751429, acc.: 53.91%] [G loss: 0.986989]\n",
      "epoch:28 step:26889 [D loss: 0.452905, acc.: 84.38%] [G loss: 1.437391]\n",
      "epoch:28 step:26890 [D loss: 0.558592, acc.: 74.22%] [G loss: 1.214918]\n",
      "epoch:28 step:26891 [D loss: 0.603040, acc.: 66.41%] [G loss: 1.364711]\n",
      "epoch:28 step:26892 [D loss: 0.633910, acc.: 60.94%] [G loss: 1.051281]\n",
      "epoch:28 step:26893 [D loss: 0.591091, acc.: 71.09%] [G loss: 1.107122]\n",
      "epoch:28 step:26894 [D loss: 0.501741, acc.: 76.56%] [G loss: 1.286257]\n",
      "epoch:28 step:26895 [D loss: 0.539354, acc.: 71.88%] [G loss: 1.296020]\n",
      "epoch:28 step:26896 [D loss: 0.483824, acc.: 79.69%] [G loss: 1.437681]\n",
      "epoch:28 step:26897 [D loss: 0.562262, acc.: 73.44%] [G loss: 0.917270]\n",
      "epoch:28 step:26898 [D loss: 0.400193, acc.: 85.94%] [G loss: 1.496413]\n",
      "epoch:28 step:26899 [D loss: 0.193559, acc.: 96.88%] [G loss: 1.642143]\n",
      "epoch:28 step:26900 [D loss: 0.221337, acc.: 96.88%] [G loss: 1.668112]\n",
      "epoch:28 step:26901 [D loss: 0.159712, acc.: 96.88%] [G loss: 2.318834]\n",
      "epoch:28 step:26902 [D loss: 0.316880, acc.: 94.53%] [G loss: 1.645222]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26903 [D loss: 0.277005, acc.: 96.09%] [G loss: 2.037031]\n",
      "epoch:28 step:26904 [D loss: 0.740816, acc.: 54.69%] [G loss: 1.363732]\n",
      "epoch:28 step:26905 [D loss: 0.459726, acc.: 80.47%] [G loss: 1.301308]\n",
      "epoch:28 step:26906 [D loss: 0.452531, acc.: 82.03%] [G loss: 1.368256]\n",
      "epoch:28 step:26907 [D loss: 0.933539, acc.: 42.19%] [G loss: 0.786897]\n",
      "epoch:28 step:26908 [D loss: 0.648245, acc.: 62.50%] [G loss: 1.423311]\n",
      "epoch:28 step:26909 [D loss: 1.050876, acc.: 23.44%] [G loss: 0.668040]\n",
      "epoch:28 step:26910 [D loss: 0.731785, acc.: 54.69%] [G loss: 1.210480]\n",
      "epoch:28 step:26911 [D loss: 0.850995, acc.: 43.75%] [G loss: 1.195836]\n",
      "epoch:28 step:26912 [D loss: 0.738031, acc.: 52.34%] [G loss: 0.762699]\n",
      "epoch:28 step:26913 [D loss: 0.760584, acc.: 47.66%] [G loss: 1.062613]\n",
      "epoch:28 step:26914 [D loss: 0.781616, acc.: 52.34%] [G loss: 0.834325]\n",
      "epoch:28 step:26915 [D loss: 0.770076, acc.: 46.88%] [G loss: 0.835494]\n",
      "epoch:28 step:26916 [D loss: 1.017760, acc.: 32.03%] [G loss: 0.498677]\n",
      "epoch:28 step:26917 [D loss: 0.789006, acc.: 47.66%] [G loss: 0.890087]\n",
      "epoch:28 step:26918 [D loss: 0.601714, acc.: 67.97%] [G loss: 1.121378]\n",
      "epoch:28 step:26919 [D loss: 0.625682, acc.: 64.06%] [G loss: 1.079054]\n",
      "epoch:28 step:26920 [D loss: 0.761521, acc.: 46.88%] [G loss: 1.017357]\n",
      "epoch:28 step:26921 [D loss: 0.645360, acc.: 64.06%] [G loss: 1.062567]\n",
      "epoch:28 step:26922 [D loss: 0.922238, acc.: 33.59%] [G loss: 0.937655]\n",
      "epoch:28 step:26923 [D loss: 1.041050, acc.: 25.78%] [G loss: 0.829068]\n",
      "epoch:28 step:26924 [D loss: 0.699551, acc.: 57.81%] [G loss: 1.161577]\n",
      "epoch:28 step:26925 [D loss: 0.577252, acc.: 67.19%] [G loss: 1.333934]\n",
      "epoch:28 step:26926 [D loss: 0.523236, acc.: 75.00%] [G loss: 1.074950]\n",
      "epoch:28 step:26927 [D loss: 0.350458, acc.: 92.19%] [G loss: 1.719920]\n",
      "epoch:28 step:26928 [D loss: 0.430348, acc.: 86.72%] [G loss: 1.621215]\n",
      "epoch:28 step:26929 [D loss: 0.371636, acc.: 86.72%] [G loss: 1.197264]\n",
      "epoch:28 step:26930 [D loss: 0.227776, acc.: 97.66%] [G loss: 1.379835]\n",
      "epoch:28 step:26931 [D loss: 0.410097, acc.: 87.50%] [G loss: 1.461680]\n",
      "epoch:28 step:26932 [D loss: 0.723530, acc.: 59.38%] [G loss: 1.605930]\n",
      "epoch:28 step:26933 [D loss: 0.579378, acc.: 71.09%] [G loss: 1.595086]\n",
      "epoch:28 step:26934 [D loss: 0.689988, acc.: 57.03%] [G loss: 0.998390]\n",
      "epoch:28 step:26935 [D loss: 0.612035, acc.: 70.31%] [G loss: 0.834642]\n",
      "epoch:28 step:26936 [D loss: 0.453111, acc.: 89.06%] [G loss: 0.924605]\n",
      "epoch:28 step:26937 [D loss: 0.450321, acc.: 87.50%] [G loss: 1.090073]\n",
      "epoch:28 step:26938 [D loss: 0.615111, acc.: 65.62%] [G loss: 1.021238]\n",
      "epoch:28 step:26939 [D loss: 0.779374, acc.: 50.78%] [G loss: 1.138968]\n",
      "epoch:28 step:26940 [D loss: 0.799395, acc.: 49.22%] [G loss: 1.172623]\n",
      "epoch:28 step:26941 [D loss: 0.575954, acc.: 71.88%] [G loss: 1.171504]\n",
      "epoch:28 step:26942 [D loss: 0.539419, acc.: 72.66%] [G loss: 0.972655]\n",
      "epoch:28 step:26943 [D loss: 0.497879, acc.: 79.69%] [G loss: 1.156600]\n",
      "epoch:28 step:26944 [D loss: 0.457821, acc.: 84.38%] [G loss: 0.991481]\n",
      "epoch:28 step:26945 [D loss: 0.486708, acc.: 81.25%] [G loss: 1.342498]\n",
      "epoch:28 step:26946 [D loss: 0.380126, acc.: 88.28%] [G loss: 1.384534]\n",
      "epoch:28 step:26947 [D loss: 0.336013, acc.: 92.97%] [G loss: 1.652935]\n",
      "epoch:28 step:26948 [D loss: 0.738810, acc.: 50.78%] [G loss: 1.317313]\n",
      "epoch:28 step:26949 [D loss: 0.582995, acc.: 66.41%] [G loss: 1.057726]\n",
      "epoch:28 step:26950 [D loss: 0.611563, acc.: 64.06%] [G loss: 1.276937]\n",
      "epoch:28 step:26951 [D loss: 0.718328, acc.: 53.91%] [G loss: 1.002043]\n",
      "epoch:28 step:26952 [D loss: 0.610453, acc.: 67.97%] [G loss: 1.261341]\n",
      "epoch:28 step:26953 [D loss: 0.425301, acc.: 85.16%] [G loss: 1.554387]\n",
      "epoch:28 step:26954 [D loss: 0.441138, acc.: 85.94%] [G loss: 1.378549]\n",
      "epoch:28 step:26955 [D loss: 0.429267, acc.: 84.38%] [G loss: 1.151049]\n",
      "epoch:28 step:26956 [D loss: 0.317867, acc.: 91.41%] [G loss: 1.525584]\n",
      "epoch:28 step:26957 [D loss: 0.262094, acc.: 96.88%] [G loss: 1.667924]\n",
      "epoch:28 step:26958 [D loss: 0.684040, acc.: 60.16%] [G loss: 0.987790]\n",
      "epoch:28 step:26959 [D loss: 0.548375, acc.: 70.31%] [G loss: 1.045255]\n",
      "epoch:28 step:26960 [D loss: 0.322563, acc.: 89.06%] [G loss: 1.237097]\n",
      "epoch:28 step:26961 [D loss: 0.269517, acc.: 96.09%] [G loss: 1.845231]\n",
      "epoch:28 step:26962 [D loss: 0.332884, acc.: 92.19%] [G loss: 1.628958]\n",
      "epoch:28 step:26963 [D loss: 0.745939, acc.: 56.25%] [G loss: 1.028395]\n",
      "epoch:28 step:26964 [D loss: 0.716782, acc.: 50.00%] [G loss: 1.300879]\n",
      "epoch:28 step:26965 [D loss: 0.484327, acc.: 77.34%] [G loss: 1.676733]\n",
      "epoch:28 step:26966 [D loss: 0.429218, acc.: 82.03%] [G loss: 1.443000]\n",
      "epoch:28 step:26967 [D loss: 0.299305, acc.: 95.31%] [G loss: 1.716503]\n",
      "epoch:28 step:26968 [D loss: 0.328389, acc.: 93.75%] [G loss: 1.385140]\n",
      "epoch:28 step:26969 [D loss: 0.276386, acc.: 97.66%] [G loss: 1.757713]\n",
      "epoch:28 step:26970 [D loss: 0.590815, acc.: 68.75%] [G loss: 1.509651]\n",
      "epoch:28 step:26971 [D loss: 0.778729, acc.: 48.44%] [G loss: 1.240073]\n",
      "epoch:28 step:26972 [D loss: 0.781483, acc.: 47.66%] [G loss: 0.863845]\n",
      "epoch:28 step:26973 [D loss: 0.656022, acc.: 60.16%] [G loss: 1.041905]\n",
      "epoch:28 step:26974 [D loss: 0.499144, acc.: 76.56%] [G loss: 1.231594]\n",
      "epoch:28 step:26975 [D loss: 0.524852, acc.: 78.12%] [G loss: 1.408437]\n",
      "epoch:28 step:26976 [D loss: 0.454669, acc.: 80.47%] [G loss: 1.034554]\n",
      "epoch:28 step:26977 [D loss: 0.618421, acc.: 60.16%] [G loss: 1.328284]\n",
      "epoch:28 step:26978 [D loss: 0.882563, acc.: 33.59%] [G loss: 1.003243]\n",
      "epoch:28 step:26979 [D loss: 0.451212, acc.: 83.59%] [G loss: 1.214355]\n",
      "epoch:28 step:26980 [D loss: 0.816882, acc.: 45.31%] [G loss: 0.867133]\n",
      "epoch:28 step:26981 [D loss: 0.287905, acc.: 98.44%] [G loss: 1.257323]\n",
      "epoch:28 step:26982 [D loss: 0.581746, acc.: 70.31%] [G loss: 1.420779]\n",
      "epoch:28 step:26983 [D loss: 0.553206, acc.: 71.09%] [G loss: 1.330470]\n",
      "epoch:28 step:26984 [D loss: 0.599534, acc.: 67.97%] [G loss: 1.260585]\n",
      "epoch:28 step:26985 [D loss: 0.549509, acc.: 73.44%] [G loss: 0.830542]\n",
      "epoch:28 step:26986 [D loss: 0.590481, acc.: 70.31%] [G loss: 0.965066]\n",
      "epoch:28 step:26987 [D loss: 0.567088, acc.: 67.19%] [G loss: 1.168473]\n",
      "epoch:28 step:26988 [D loss: 0.706072, acc.: 57.81%] [G loss: 0.920820]\n",
      "epoch:28 step:26989 [D loss: 0.560956, acc.: 69.53%] [G loss: 0.971692]\n",
      "epoch:28 step:26990 [D loss: 0.718003, acc.: 53.12%] [G loss: 0.832860]\n",
      "epoch:28 step:26991 [D loss: 0.261689, acc.: 94.53%] [G loss: 1.750486]\n",
      "epoch:28 step:26992 [D loss: 0.498808, acc.: 76.56%] [G loss: 1.231495]\n",
      "epoch:28 step:26993 [D loss: 0.295731, acc.: 94.53%] [G loss: 1.483730]\n",
      "epoch:28 step:26994 [D loss: 0.508559, acc.: 78.12%] [G loss: 1.524992]\n",
      "epoch:28 step:26995 [D loss: 0.691180, acc.: 59.38%] [G loss: 1.093977]\n",
      "epoch:28 step:26996 [D loss: 0.696978, acc.: 57.03%] [G loss: 1.175127]\n",
      "epoch:28 step:26997 [D loss: 0.726543, acc.: 51.56%] [G loss: 0.826472]\n",
      "epoch:28 step:26998 [D loss: 0.749313, acc.: 53.12%] [G loss: 0.898379]\n",
      "epoch:28 step:26999 [D loss: 0.514891, acc.: 78.91%] [G loss: 1.027893]\n",
      "epoch:28 step:27000 [D loss: 0.376684, acc.: 91.41%] [G loss: 1.508811]\n",
      "##############\n",
      "[2.35448266 1.27305193 5.43379723 4.27489389 2.82250288 5.17434643\n",
      " 4.1507939  4.27397925 4.07709511 3.69318524]\n",
      "##########\n",
      "epoch:28 step:27001 [D loss: 0.875312, acc.: 51.56%] [G loss: 1.196911]\n",
      "epoch:28 step:27002 [D loss: 0.893311, acc.: 37.50%] [G loss: 0.819141]\n",
      "epoch:28 step:27003 [D loss: 0.564015, acc.: 70.31%] [G loss: 1.147608]\n",
      "epoch:28 step:27004 [D loss: 0.294153, acc.: 92.97%] [G loss: 1.333163]\n",
      "epoch:28 step:27005 [D loss: 0.309621, acc.: 90.62%] [G loss: 1.677924]\n",
      "epoch:28 step:27006 [D loss: 0.564062, acc.: 71.09%] [G loss: 1.522556]\n",
      "epoch:28 step:27007 [D loss: 0.761561, acc.: 53.12%] [G loss: 1.040871]\n",
      "epoch:28 step:27008 [D loss: 0.833561, acc.: 40.62%] [G loss: 1.136715]\n",
      "epoch:28 step:27009 [D loss: 0.471426, acc.: 83.59%] [G loss: 1.208669]\n",
      "epoch:28 step:27010 [D loss: 0.240539, acc.: 92.97%] [G loss: 1.250864]\n",
      "epoch:28 step:27011 [D loss: 0.274012, acc.: 90.62%] [G loss: 1.360390]\n",
      "epoch:28 step:27012 [D loss: 0.365844, acc.: 87.50%] [G loss: 1.447751]\n",
      "epoch:28 step:27013 [D loss: 0.324905, acc.: 94.53%] [G loss: 1.930227]\n",
      "epoch:28 step:27014 [D loss: 0.516995, acc.: 74.22%] [G loss: 1.354964]\n",
      "epoch:28 step:27015 [D loss: 1.017326, acc.: 27.34%] [G loss: 0.684432]\n",
      "epoch:28 step:27016 [D loss: 0.500820, acc.: 76.56%] [G loss: 1.028935]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:27017 [D loss: 0.308793, acc.: 95.31%] [G loss: 1.406040]\n",
      "epoch:28 step:27018 [D loss: 0.438359, acc.: 79.69%] [G loss: 1.338614]\n",
      "epoch:28 step:27019 [D loss: 0.699806, acc.: 62.50%] [G loss: 1.483770]\n",
      "epoch:28 step:27020 [D loss: 0.689403, acc.: 59.38%] [G loss: 1.085689]\n",
      "epoch:28 step:27021 [D loss: 0.683012, acc.: 60.16%] [G loss: 0.959154]\n",
      "epoch:28 step:27022 [D loss: 0.373320, acc.: 92.19%] [G loss: 1.128017]\n",
      "epoch:28 step:27023 [D loss: 0.686412, acc.: 57.03%] [G loss: 1.137105]\n",
      "epoch:28 step:27024 [D loss: 0.687828, acc.: 55.47%] [G loss: 0.969087]\n",
      "epoch:28 step:27025 [D loss: 0.749266, acc.: 48.44%] [G loss: 0.757271]\n",
      "epoch:28 step:27026 [D loss: 0.517844, acc.: 77.34%] [G loss: 0.902490]\n",
      "epoch:28 step:27027 [D loss: 0.337519, acc.: 85.94%] [G loss: 1.503096]\n",
      "epoch:28 step:27028 [D loss: 0.216361, acc.: 99.22%] [G loss: 1.731926]\n",
      "epoch:28 step:27029 [D loss: 0.251534, acc.: 95.31%] [G loss: 2.108324]\n",
      "epoch:28 step:27030 [D loss: 0.171369, acc.: 99.22%] [G loss: 1.962690]\n",
      "epoch:28 step:27031 [D loss: 0.456506, acc.: 84.38%] [G loss: 1.441338]\n",
      "epoch:28 step:27032 [D loss: 0.475894, acc.: 80.47%] [G loss: 1.399732]\n",
      "epoch:28 step:27033 [D loss: 0.721139, acc.: 53.91%] [G loss: 1.164509]\n",
      "epoch:28 step:27034 [D loss: 0.836262, acc.: 49.22%] [G loss: 0.675465]\n",
      "epoch:28 step:27035 [D loss: 0.590319, acc.: 66.41%] [G loss: 1.128984]\n",
      "epoch:28 step:27036 [D loss: 0.804705, acc.: 44.53%] [G loss: 1.071608]\n",
      "epoch:28 step:27037 [D loss: 0.662703, acc.: 60.16%] [G loss: 1.244681]\n",
      "epoch:28 step:27038 [D loss: 0.438375, acc.: 85.94%] [G loss: 1.386408]\n",
      "epoch:28 step:27039 [D loss: 0.492007, acc.: 80.47%] [G loss: 1.050998]\n",
      "epoch:28 step:27040 [D loss: 0.525439, acc.: 69.53%] [G loss: 1.099434]\n",
      "epoch:28 step:27041 [D loss: 0.325037, acc.: 94.53%] [G loss: 1.337056]\n",
      "epoch:28 step:27042 [D loss: 0.424323, acc.: 82.81%] [G loss: 1.180490]\n",
      "epoch:28 step:27043 [D loss: 0.782405, acc.: 45.31%] [G loss: 1.173687]\n",
      "epoch:28 step:27044 [D loss: 0.433321, acc.: 87.50%] [G loss: 1.287670]\n",
      "epoch:28 step:27045 [D loss: 0.476512, acc.: 81.25%] [G loss: 1.478043]\n",
      "epoch:28 step:27046 [D loss: 0.564756, acc.: 72.66%] [G loss: 1.360040]\n",
      "epoch:28 step:27047 [D loss: 0.766271, acc.: 46.09%] [G loss: 1.148048]\n",
      "epoch:28 step:27048 [D loss: 0.710140, acc.: 52.34%] [G loss: 1.039140]\n",
      "epoch:28 step:27049 [D loss: 0.537685, acc.: 77.34%] [G loss: 1.149824]\n",
      "epoch:28 step:27050 [D loss: 0.594269, acc.: 68.75%] [G loss: 1.163876]\n",
      "epoch:28 step:27051 [D loss: 0.185409, acc.: 97.66%] [G loss: 1.516664]\n",
      "epoch:28 step:27052 [D loss: 0.278201, acc.: 92.19%] [G loss: 1.489059]\n",
      "epoch:28 step:27053 [D loss: 0.518669, acc.: 74.22%] [G loss: 1.279065]\n",
      "epoch:28 step:27054 [D loss: 0.339544, acc.: 89.84%] [G loss: 1.723141]\n",
      "epoch:28 step:27055 [D loss: 0.512939, acc.: 81.25%] [G loss: 1.034573]\n",
      "epoch:28 step:27056 [D loss: 0.828499, acc.: 50.78%] [G loss: 0.908686]\n",
      "epoch:28 step:27057 [D loss: 0.855945, acc.: 36.72%] [G loss: 0.659115]\n",
      "epoch:28 step:27058 [D loss: 0.969863, acc.: 30.47%] [G loss: 0.751993]\n",
      "epoch:28 step:27059 [D loss: 0.742728, acc.: 57.03%] [G loss: 0.814530]\n",
      "epoch:28 step:27060 [D loss: 0.359049, acc.: 89.06%] [G loss: 1.372685]\n",
      "epoch:28 step:27061 [D loss: 0.309634, acc.: 95.31%] [G loss: 1.684134]\n",
      "epoch:28 step:27062 [D loss: 0.525790, acc.: 73.44%] [G loss: 1.347671]\n",
      "epoch:28 step:27063 [D loss: 0.901228, acc.: 37.50%] [G loss: 0.813486]\n",
      "epoch:28 step:27064 [D loss: 0.826872, acc.: 43.75%] [G loss: 0.731632]\n",
      "epoch:28 step:27065 [D loss: 0.711877, acc.: 54.69%] [G loss: 1.069668]\n",
      "epoch:28 step:27066 [D loss: 0.701792, acc.: 61.72%] [G loss: 0.778855]\n",
      "epoch:28 step:27067 [D loss: 0.317565, acc.: 93.75%] [G loss: 1.403427]\n",
      "epoch:28 step:27068 [D loss: 0.679933, acc.: 60.16%] [G loss: 0.869790]\n",
      "epoch:28 step:27069 [D loss: 0.563138, acc.: 70.31%] [G loss: 1.079906]\n",
      "epoch:28 step:27070 [D loss: 0.991876, acc.: 50.00%] [G loss: 1.376201]\n",
      "epoch:28 step:27071 [D loss: 1.046214, acc.: 35.94%] [G loss: 1.220818]\n",
      "epoch:28 step:27072 [D loss: 0.676499, acc.: 60.16%] [G loss: 1.195609]\n",
      "epoch:28 step:27073 [D loss: 0.578757, acc.: 69.53%] [G loss: 1.243107]\n",
      "epoch:28 step:27074 [D loss: 0.582614, acc.: 65.62%] [G loss: 1.472031]\n",
      "epoch:28 step:27075 [D loss: 0.463307, acc.: 85.94%] [G loss: 1.417533]\n",
      "epoch:28 step:27076 [D loss: 0.356317, acc.: 89.06%] [G loss: 1.359846]\n",
      "epoch:28 step:27077 [D loss: 0.453869, acc.: 78.91%] [G loss: 1.359165]\n",
      "epoch:28 step:27078 [D loss: 0.295555, acc.: 95.31%] [G loss: 1.885493]\n",
      "epoch:28 step:27079 [D loss: 0.757970, acc.: 53.91%] [G loss: 1.577785]\n",
      "epoch:28 step:27080 [D loss: 0.981291, acc.: 23.44%] [G loss: 0.851545]\n",
      "epoch:28 step:27081 [D loss: 0.593400, acc.: 71.88%] [G loss: 1.242682]\n",
      "epoch:28 step:27082 [D loss: 0.606077, acc.: 71.09%] [G loss: 1.064056]\n",
      "epoch:28 step:27083 [D loss: 0.539614, acc.: 75.78%] [G loss: 1.285173]\n",
      "epoch:28 step:27084 [D loss: 0.541642, acc.: 72.66%] [G loss: 1.213081]\n",
      "epoch:28 step:27085 [D loss: 0.356516, acc.: 86.72%] [G loss: 1.327246]\n",
      "epoch:28 step:27086 [D loss: 0.399582, acc.: 81.25%] [G loss: 1.326337]\n",
      "epoch:28 step:27087 [D loss: 0.151948, acc.: 97.66%] [G loss: 1.887654]\n",
      "epoch:28 step:27088 [D loss: 0.195887, acc.: 99.22%] [G loss: 1.634838]\n",
      "epoch:28 step:27089 [D loss: 0.165315, acc.: 99.22%] [G loss: 2.042289]\n",
      "epoch:28 step:27090 [D loss: 0.229298, acc.: 96.09%] [G loss: 1.379045]\n",
      "epoch:28 step:27091 [D loss: 0.323297, acc.: 89.84%] [G loss: 2.254464]\n",
      "epoch:28 step:27092 [D loss: 0.470487, acc.: 81.25%] [G loss: 1.521162]\n",
      "epoch:28 step:27093 [D loss: 0.313027, acc.: 92.19%] [G loss: 1.503503]\n",
      "epoch:28 step:27094 [D loss: 0.801580, acc.: 49.22%] [G loss: 1.380266]\n",
      "epoch:28 step:27095 [D loss: 0.547462, acc.: 70.31%] [G loss: 1.541974]\n",
      "epoch:28 step:27096 [D loss: 0.464645, acc.: 82.81%] [G loss: 1.201372]\n",
      "epoch:28 step:27097 [D loss: 0.569997, acc.: 66.41%] [G loss: 1.125210]\n",
      "epoch:28 step:27098 [D loss: 0.716043, acc.: 55.47%] [G loss: 0.950356]\n",
      "epoch:28 step:27099 [D loss: 0.560102, acc.: 71.88%] [G loss: 1.092016]\n",
      "epoch:28 step:27100 [D loss: 0.678417, acc.: 53.91%] [G loss: 0.995948]\n",
      "epoch:28 step:27101 [D loss: 0.702814, acc.: 60.16%] [G loss: 0.739452]\n",
      "epoch:28 step:27102 [D loss: 0.673733, acc.: 57.81%] [G loss: 0.878019]\n",
      "epoch:28 step:27103 [D loss: 0.761371, acc.: 49.22%] [G loss: 0.991260]\n",
      "epoch:28 step:27104 [D loss: 0.670721, acc.: 61.72%] [G loss: 1.167440]\n",
      "epoch:28 step:27105 [D loss: 0.493940, acc.: 71.09%] [G loss: 1.303980]\n",
      "epoch:28 step:27106 [D loss: 0.652002, acc.: 59.38%] [G loss: 1.074647]\n",
      "epoch:28 step:27107 [D loss: 0.549879, acc.: 71.09%] [G loss: 1.115062]\n",
      "epoch:28 step:27108 [D loss: 0.561338, acc.: 75.78%] [G loss: 1.136819]\n",
      "epoch:28 step:27109 [D loss: 0.613953, acc.: 64.84%] [G loss: 1.062285]\n",
      "epoch:28 step:27110 [D loss: 0.686967, acc.: 60.94%] [G loss: 0.918647]\n",
      "epoch:28 step:27111 [D loss: 0.391165, acc.: 86.72%] [G loss: 1.612098]\n",
      "epoch:28 step:27112 [D loss: 0.703762, acc.: 56.25%] [G loss: 1.152139]\n",
      "epoch:28 step:27113 [D loss: 0.784771, acc.: 48.44%] [G loss: 1.012285]\n",
      "epoch:28 step:27114 [D loss: 0.604300, acc.: 66.41%] [G loss: 1.002365]\n",
      "epoch:28 step:27115 [D loss: 0.855197, acc.: 44.53%] [G loss: 1.204721]\n",
      "epoch:28 step:27116 [D loss: 0.654565, acc.: 60.16%] [G loss: 0.961664]\n",
      "epoch:28 step:27117 [D loss: 0.627594, acc.: 65.62%] [G loss: 1.139616]\n",
      "epoch:28 step:27118 [D loss: 0.783550, acc.: 44.53%] [G loss: 1.219799]\n",
      "epoch:28 step:27119 [D loss: 0.461001, acc.: 78.12%] [G loss: 1.344255]\n",
      "epoch:28 step:27120 [D loss: 0.369328, acc.: 88.28%] [G loss: 1.636388]\n",
      "epoch:28 step:27121 [D loss: 0.423034, acc.: 78.91%] [G loss: 0.949389]\n",
      "epoch:28 step:27122 [D loss: 0.672709, acc.: 62.50%] [G loss: 1.375460]\n",
      "epoch:28 step:27123 [D loss: 0.371337, acc.: 85.94%] [G loss: 1.693717]\n",
      "epoch:28 step:27124 [D loss: 0.580137, acc.: 68.75%] [G loss: 1.362426]\n",
      "epoch:28 step:27125 [D loss: 0.468702, acc.: 71.88%] [G loss: 1.215767]\n",
      "epoch:28 step:27126 [D loss: 0.452924, acc.: 83.59%] [G loss: 1.108134]\n",
      "epoch:28 step:27127 [D loss: 0.798765, acc.: 51.56%] [G loss: 1.419678]\n",
      "epoch:28 step:27128 [D loss: 0.468901, acc.: 82.81%] [G loss: 1.280576]\n",
      "epoch:28 step:27129 [D loss: 0.397667, acc.: 89.06%] [G loss: 1.380495]\n",
      "epoch:28 step:27130 [D loss: 0.402048, acc.: 85.94%] [G loss: 1.497096]\n",
      "epoch:28 step:27131 [D loss: 0.357124, acc.: 87.50%] [G loss: 1.511072]\n",
      "epoch:28 step:27132 [D loss: 0.266516, acc.: 97.66%] [G loss: 1.809140]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:27133 [D loss: 0.306908, acc.: 93.75%] [G loss: 2.041781]\n",
      "epoch:28 step:27134 [D loss: 0.162881, acc.: 100.00%] [G loss: 1.737473]\n",
      "epoch:28 step:27135 [D loss: 0.112739, acc.: 100.00%] [G loss: 2.124716]\n",
      "epoch:28 step:27136 [D loss: 0.141769, acc.: 100.00%] [G loss: 2.311738]\n",
      "epoch:28 step:27137 [D loss: 0.166189, acc.: 99.22%] [G loss: 2.413146]\n",
      "epoch:28 step:27138 [D loss: 0.415803, acc.: 82.03%] [G loss: 2.049889]\n",
      "epoch:28 step:27139 [D loss: 0.318905, acc.: 92.97%] [G loss: 1.679291]\n",
      "epoch:28 step:27140 [D loss: 0.869113, acc.: 48.44%] [G loss: 1.197460]\n",
      "epoch:28 step:27141 [D loss: 0.698210, acc.: 51.56%] [G loss: 1.074315]\n",
      "epoch:28 step:27142 [D loss: 0.656925, acc.: 59.38%] [G loss: 1.175964]\n",
      "epoch:28 step:27143 [D loss: 0.535802, acc.: 77.34%] [G loss: 1.496011]\n",
      "epoch:28 step:27144 [D loss: 0.559051, acc.: 70.31%] [G loss: 1.213316]\n",
      "epoch:28 step:27145 [D loss: 0.272546, acc.: 92.97%] [G loss: 1.348244]\n",
      "epoch:28 step:27146 [D loss: 0.507753, acc.: 76.56%] [G loss: 1.394749]\n",
      "epoch:28 step:27147 [D loss: 0.167755, acc.: 96.88%] [G loss: 1.576076]\n",
      "epoch:28 step:27148 [D loss: 0.246242, acc.: 90.62%] [G loss: 1.307319]\n",
      "epoch:28 step:27149 [D loss: 0.864293, acc.: 46.88%] [G loss: 1.143954]\n",
      "epoch:28 step:27150 [D loss: 0.744108, acc.: 50.78%] [G loss: 1.370884]\n",
      "epoch:28 step:27151 [D loss: 0.528763, acc.: 72.66%] [G loss: 1.182659]\n",
      "epoch:28 step:27152 [D loss: 0.655356, acc.: 60.16%] [G loss: 1.144432]\n",
      "epoch:28 step:27153 [D loss: 0.866247, acc.: 39.84%] [G loss: 0.854478]\n",
      "epoch:28 step:27154 [D loss: 0.613758, acc.: 64.84%] [G loss: 0.864768]\n",
      "epoch:28 step:27155 [D loss: 0.260821, acc.: 92.19%] [G loss: 1.572916]\n",
      "epoch:28 step:27156 [D loss: 0.858589, acc.: 46.88%] [G loss: 1.316585]\n",
      "epoch:28 step:27157 [D loss: 0.545495, acc.: 71.09%] [G loss: 1.863824]\n",
      "epoch:28 step:27158 [D loss: 0.524258, acc.: 75.78%] [G loss: 1.351892]\n",
      "epoch:28 step:27159 [D loss: 0.737845, acc.: 53.12%] [G loss: 1.115920]\n",
      "epoch:28 step:27160 [D loss: 0.350866, acc.: 89.06%] [G loss: 1.571152]\n",
      "epoch:28 step:27161 [D loss: 0.441741, acc.: 84.38%] [G loss: 1.309049]\n",
      "epoch:28 step:27162 [D loss: 0.656807, acc.: 62.50%] [G loss: 1.073362]\n",
      "epoch:28 step:27163 [D loss: 0.183373, acc.: 99.22%] [G loss: 1.923658]\n",
      "epoch:28 step:27164 [D loss: 1.261422, acc.: 26.56%] [G loss: 1.112000]\n",
      "epoch:28 step:27165 [D loss: 0.397867, acc.: 83.59%] [G loss: 1.456963]\n",
      "epoch:28 step:27166 [D loss: 0.317251, acc.: 92.97%] [G loss: 1.903956]\n",
      "epoch:28 step:27167 [D loss: 0.513182, acc.: 76.56%] [G loss: 1.683012]\n",
      "epoch:28 step:27168 [D loss: 0.815880, acc.: 47.66%] [G loss: 1.076694]\n",
      "epoch:28 step:27169 [D loss: 0.561074, acc.: 67.97%] [G loss: 1.147430]\n",
      "epoch:28 step:27170 [D loss: 0.483371, acc.: 78.91%] [G loss: 1.325465]\n",
      "epoch:28 step:27171 [D loss: 0.541489, acc.: 71.88%] [G loss: 1.129514]\n",
      "epoch:28 step:27172 [D loss: 0.678679, acc.: 58.59%] [G loss: 0.989387]\n",
      "epoch:28 step:27173 [D loss: 0.217346, acc.: 94.53%] [G loss: 1.551206]\n",
      "epoch:29 step:27174 [D loss: 0.686748, acc.: 53.12%] [G loss: 1.303027]\n",
      "epoch:29 step:27175 [D loss: 0.710523, acc.: 59.38%] [G loss: 1.071132]\n",
      "epoch:29 step:27176 [D loss: 0.623795, acc.: 65.62%] [G loss: 1.121601]\n",
      "epoch:29 step:27177 [D loss: 0.468871, acc.: 78.12%] [G loss: 1.370344]\n",
      "epoch:29 step:27178 [D loss: 0.468061, acc.: 82.03%] [G loss: 1.293674]\n",
      "epoch:29 step:27179 [D loss: 0.489608, acc.: 82.03%] [G loss: 1.508009]\n",
      "epoch:29 step:27180 [D loss: 0.525992, acc.: 74.22%] [G loss: 1.252917]\n",
      "epoch:29 step:27181 [D loss: 0.649071, acc.: 60.16%] [G loss: 1.158431]\n",
      "epoch:29 step:27182 [D loss: 0.621862, acc.: 62.50%] [G loss: 1.054898]\n",
      "epoch:29 step:27183 [D loss: 0.642563, acc.: 63.28%] [G loss: 0.969918]\n",
      "epoch:29 step:27184 [D loss: 0.561673, acc.: 72.66%] [G loss: 1.045173]\n",
      "epoch:29 step:27185 [D loss: 0.710926, acc.: 55.47%] [G loss: 0.748601]\n",
      "epoch:29 step:27186 [D loss: 0.661331, acc.: 62.50%] [G loss: 1.151133]\n",
      "epoch:29 step:27187 [D loss: 0.636404, acc.: 65.62%] [G loss: 1.053426]\n",
      "epoch:29 step:27188 [D loss: 0.257765, acc.: 96.09%] [G loss: 1.567155]\n",
      "epoch:29 step:27189 [D loss: 0.380767, acc.: 87.50%] [G loss: 1.580554]\n",
      "epoch:29 step:27190 [D loss: 0.559831, acc.: 71.09%] [G loss: 1.232478]\n",
      "epoch:29 step:27191 [D loss: 0.704306, acc.: 57.03%] [G loss: 0.867432]\n",
      "epoch:29 step:27192 [D loss: 0.646713, acc.: 58.59%] [G loss: 1.044160]\n",
      "epoch:29 step:27193 [D loss: 0.703994, acc.: 57.81%] [G loss: 1.006744]\n",
      "epoch:29 step:27194 [D loss: 0.775449, acc.: 42.19%] [G loss: 0.742844]\n",
      "epoch:29 step:27195 [D loss: 0.682379, acc.: 53.12%] [G loss: 0.928969]\n",
      "epoch:29 step:27196 [D loss: 0.433524, acc.: 85.16%] [G loss: 1.163318]\n",
      "epoch:29 step:27197 [D loss: 0.703703, acc.: 59.38%] [G loss: 0.920069]\n",
      "epoch:29 step:27198 [D loss: 0.640848, acc.: 62.50%] [G loss: 1.259487]\n",
      "epoch:29 step:27199 [D loss: 0.523888, acc.: 75.78%] [G loss: 1.212579]\n",
      "epoch:29 step:27200 [D loss: 0.291479, acc.: 95.31%] [G loss: 1.570012]\n",
      "##############\n",
      "[2.40433758 1.65149489 5.59083929 4.24641275 3.19337939 5.48275897\n",
      " 4.36460632 4.7797059  4.17630262 3.90180742]\n",
      "##########\n",
      "epoch:29 step:27201 [D loss: 0.344197, acc.: 92.19%] [G loss: 1.473978]\n",
      "epoch:29 step:27202 [D loss: 0.296618, acc.: 93.75%] [G loss: 1.563325]\n",
      "epoch:29 step:27203 [D loss: 0.296279, acc.: 95.31%] [G loss: 1.723799]\n",
      "epoch:29 step:27204 [D loss: 0.441754, acc.: 88.28%] [G loss: 1.358041]\n",
      "epoch:29 step:27205 [D loss: 0.196012, acc.: 99.22%] [G loss: 1.840991]\n",
      "epoch:29 step:27206 [D loss: 0.183164, acc.: 98.44%] [G loss: 1.870159]\n",
      "epoch:29 step:27207 [D loss: 0.324828, acc.: 90.62%] [G loss: 1.682353]\n",
      "epoch:29 step:27208 [D loss: 0.378577, acc.: 77.34%] [G loss: 1.438702]\n",
      "epoch:29 step:27209 [D loss: 0.168832, acc.: 97.66%] [G loss: 2.048882]\n",
      "epoch:29 step:27210 [D loss: 0.944304, acc.: 52.34%] [G loss: 1.482153]\n",
      "epoch:29 step:27211 [D loss: 0.853911, acc.: 44.53%] [G loss: 1.602145]\n",
      "epoch:29 step:27212 [D loss: 0.533095, acc.: 75.00%] [G loss: 1.197357]\n",
      "epoch:29 step:27213 [D loss: 0.512423, acc.: 81.25%] [G loss: 1.130188]\n",
      "epoch:29 step:27214 [D loss: 0.797118, acc.: 49.22%] [G loss: 1.003021]\n",
      "epoch:29 step:27215 [D loss: 0.604197, acc.: 66.41%] [G loss: 1.122145]\n",
      "epoch:29 step:27216 [D loss: 0.562680, acc.: 71.88%] [G loss: 0.973262]\n",
      "epoch:29 step:27217 [D loss: 0.484948, acc.: 82.03%] [G loss: 1.126905]\n",
      "epoch:29 step:27218 [D loss: 0.675306, acc.: 54.69%] [G loss: 1.022353]\n",
      "epoch:29 step:27219 [D loss: 0.945038, acc.: 35.16%] [G loss: 0.781235]\n",
      "epoch:29 step:27220 [D loss: 1.206546, acc.: 28.12%] [G loss: 0.667920]\n",
      "epoch:29 step:27221 [D loss: 0.753522, acc.: 53.12%] [G loss: 0.888664]\n",
      "epoch:29 step:27222 [D loss: 0.346430, acc.: 93.75%] [G loss: 1.676043]\n",
      "epoch:29 step:27223 [D loss: 0.467581, acc.: 79.69%] [G loss: 1.383543]\n",
      "epoch:29 step:27224 [D loss: 0.818359, acc.: 49.22%] [G loss: 1.247627]\n",
      "epoch:29 step:27225 [D loss: 0.749807, acc.: 53.12%] [G loss: 0.856113]\n",
      "epoch:29 step:27226 [D loss: 0.489223, acc.: 82.81%] [G loss: 0.967240]\n",
      "epoch:29 step:27227 [D loss: 0.649173, acc.: 62.50%] [G loss: 0.869668]\n",
      "epoch:29 step:27228 [D loss: 0.474775, acc.: 79.69%] [G loss: 1.123100]\n",
      "epoch:29 step:27229 [D loss: 0.677804, acc.: 65.62%] [G loss: 1.365810]\n",
      "epoch:29 step:27230 [D loss: 0.840908, acc.: 39.84%] [G loss: 1.137668]\n",
      "epoch:29 step:27231 [D loss: 0.685745, acc.: 57.03%] [G loss: 1.170651]\n",
      "epoch:29 step:27232 [D loss: 0.817793, acc.: 48.44%] [G loss: 0.949610]\n",
      "epoch:29 step:27233 [D loss: 0.474848, acc.: 78.12%] [G loss: 1.181862]\n",
      "epoch:29 step:27234 [D loss: 0.717186, acc.: 52.34%] [G loss: 1.026428]\n",
      "epoch:29 step:27235 [D loss: 0.675011, acc.: 56.25%] [G loss: 1.045565]\n",
      "epoch:29 step:27236 [D loss: 0.608167, acc.: 66.41%] [G loss: 1.076016]\n",
      "epoch:29 step:27237 [D loss: 0.822864, acc.: 43.75%] [G loss: 0.944718]\n",
      "epoch:29 step:27238 [D loss: 0.606562, acc.: 69.53%] [G loss: 1.125793]\n",
      "epoch:29 step:27239 [D loss: 0.518070, acc.: 75.78%] [G loss: 1.424071]\n",
      "epoch:29 step:27240 [D loss: 0.542616, acc.: 77.34%] [G loss: 1.034600]\n",
      "epoch:29 step:27241 [D loss: 0.576030, acc.: 67.19%] [G loss: 1.456492]\n",
      "epoch:29 step:27242 [D loss: 0.532863, acc.: 74.22%] [G loss: 1.024092]\n",
      "epoch:29 step:27243 [D loss: 0.575272, acc.: 66.41%] [G loss: 1.169007]\n",
      "epoch:29 step:27244 [D loss: 0.422788, acc.: 85.16%] [G loss: 1.273481]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27245 [D loss: 0.577416, acc.: 64.06%] [G loss: 1.378958]\n",
      "epoch:29 step:27246 [D loss: 0.399510, acc.: 85.16%] [G loss: 1.627505]\n",
      "epoch:29 step:27247 [D loss: 0.238011, acc.: 96.88%] [G loss: 1.658206]\n",
      "epoch:29 step:27248 [D loss: 0.188676, acc.: 96.88%] [G loss: 1.698056]\n",
      "epoch:29 step:27249 [D loss: 0.236320, acc.: 96.09%] [G loss: 1.686180]\n",
      "epoch:29 step:27250 [D loss: 0.227750, acc.: 96.09%] [G loss: 2.053807]\n",
      "epoch:29 step:27251 [D loss: 1.091850, acc.: 28.12%] [G loss: 0.955373]\n",
      "epoch:29 step:27252 [D loss: 0.811850, acc.: 46.09%] [G loss: 0.758741]\n",
      "epoch:29 step:27253 [D loss: 0.804693, acc.: 43.75%] [G loss: 0.804700]\n",
      "epoch:29 step:27254 [D loss: 0.855707, acc.: 50.78%] [G loss: 1.171189]\n",
      "epoch:29 step:27255 [D loss: 0.588633, acc.: 69.53%] [G loss: 1.097688]\n",
      "epoch:29 step:27256 [D loss: 0.409071, acc.: 87.50%] [G loss: 1.227924]\n",
      "epoch:29 step:27257 [D loss: 0.483135, acc.: 83.59%] [G loss: 1.222977]\n",
      "epoch:29 step:27258 [D loss: 0.655591, acc.: 59.38%] [G loss: 1.117470]\n",
      "epoch:29 step:27259 [D loss: 0.454363, acc.: 85.94%] [G loss: 1.303133]\n",
      "epoch:29 step:27260 [D loss: 0.474555, acc.: 82.03%] [G loss: 1.085111]\n",
      "epoch:29 step:27261 [D loss: 0.413719, acc.: 89.06%] [G loss: 1.304933]\n",
      "epoch:29 step:27262 [D loss: 0.610536, acc.: 65.62%] [G loss: 1.392903]\n",
      "epoch:29 step:27263 [D loss: 0.584180, acc.: 70.31%] [G loss: 0.983408]\n",
      "epoch:29 step:27264 [D loss: 0.537077, acc.: 78.12%] [G loss: 1.179264]\n",
      "epoch:29 step:27265 [D loss: 0.411691, acc.: 86.72%] [G loss: 1.378430]\n",
      "epoch:29 step:27266 [D loss: 0.656215, acc.: 63.28%] [G loss: 1.018060]\n",
      "epoch:29 step:27267 [D loss: 0.769253, acc.: 52.34%] [G loss: 1.170148]\n",
      "epoch:29 step:27268 [D loss: 1.191978, acc.: 16.41%] [G loss: 0.597608]\n",
      "epoch:29 step:27269 [D loss: 0.814764, acc.: 43.75%] [G loss: 0.832996]\n",
      "epoch:29 step:27270 [D loss: 0.854214, acc.: 36.72%] [G loss: 0.996731]\n",
      "epoch:29 step:27271 [D loss: 0.868397, acc.: 38.28%] [G loss: 1.023793]\n",
      "epoch:29 step:27272 [D loss: 0.659608, acc.: 60.94%] [G loss: 1.033880]\n",
      "epoch:29 step:27273 [D loss: 0.560371, acc.: 71.09%] [G loss: 0.972270]\n",
      "epoch:29 step:27274 [D loss: 0.635370, acc.: 63.28%] [G loss: 0.999788]\n",
      "epoch:29 step:27275 [D loss: 0.495827, acc.: 77.34%] [G loss: 1.272600]\n",
      "epoch:29 step:27276 [D loss: 0.436559, acc.: 86.72%] [G loss: 1.443678]\n",
      "epoch:29 step:27277 [D loss: 0.552121, acc.: 75.00%] [G loss: 1.380561]\n",
      "epoch:29 step:27278 [D loss: 0.327225, acc.: 88.28%] [G loss: 1.403763]\n",
      "epoch:29 step:27279 [D loss: 0.288699, acc.: 96.09%] [G loss: 1.463660]\n",
      "epoch:29 step:27280 [D loss: 0.543578, acc.: 69.53%] [G loss: 1.134770]\n",
      "epoch:29 step:27281 [D loss: 0.376647, acc.: 85.94%] [G loss: 1.567584]\n",
      "epoch:29 step:27282 [D loss: 0.503003, acc.: 74.22%] [G loss: 1.067216]\n",
      "epoch:29 step:27283 [D loss: 0.471065, acc.: 76.56%] [G loss: 1.902354]\n",
      "epoch:29 step:27284 [D loss: 0.733741, acc.: 57.81%] [G loss: 1.600547]\n",
      "epoch:29 step:27285 [D loss: 0.739995, acc.: 56.25%] [G loss: 1.023624]\n",
      "epoch:29 step:27286 [D loss: 1.072381, acc.: 28.12%] [G loss: 0.792955]\n",
      "epoch:29 step:27287 [D loss: 1.183827, acc.: 19.53%] [G loss: 0.690924]\n",
      "epoch:29 step:27288 [D loss: 0.763011, acc.: 49.22%] [G loss: 1.385604]\n",
      "epoch:29 step:27289 [D loss: 0.746866, acc.: 53.91%] [G loss: 0.987439]\n",
      "epoch:29 step:27290 [D loss: 0.258027, acc.: 93.75%] [G loss: 1.817569]\n",
      "epoch:29 step:27291 [D loss: 0.373072, acc.: 87.50%] [G loss: 1.380996]\n",
      "epoch:29 step:27292 [D loss: 0.280385, acc.: 91.41%] [G loss: 1.449392]\n",
      "epoch:29 step:27293 [D loss: 1.128889, acc.: 28.91%] [G loss: 1.002535]\n",
      "epoch:29 step:27294 [D loss: 0.584928, acc.: 66.41%] [G loss: 1.242383]\n",
      "epoch:29 step:27295 [D loss: 0.325497, acc.: 92.19%] [G loss: 1.727727]\n",
      "epoch:29 step:27296 [D loss: 0.715690, acc.: 57.81%] [G loss: 1.796818]\n",
      "epoch:29 step:27297 [D loss: 0.773911, acc.: 50.78%] [G loss: 1.155624]\n",
      "epoch:29 step:27298 [D loss: 0.713625, acc.: 54.69%] [G loss: 1.053996]\n",
      "epoch:29 step:27299 [D loss: 0.523296, acc.: 72.66%] [G loss: 1.173168]\n",
      "epoch:29 step:27300 [D loss: 0.608646, acc.: 61.72%] [G loss: 1.135795]\n",
      "epoch:29 step:27301 [D loss: 0.580330, acc.: 67.97%] [G loss: 0.931951]\n",
      "epoch:29 step:27302 [D loss: 0.395402, acc.: 84.38%] [G loss: 1.207332]\n",
      "epoch:29 step:27303 [D loss: 0.260898, acc.: 92.19%] [G loss: 1.601423]\n",
      "epoch:29 step:27304 [D loss: 0.175817, acc.: 98.44%] [G loss: 1.780001]\n",
      "epoch:29 step:27305 [D loss: 0.527029, acc.: 76.56%] [G loss: 1.439080]\n",
      "epoch:29 step:27306 [D loss: 0.848217, acc.: 53.12%] [G loss: 1.214836]\n",
      "epoch:29 step:27307 [D loss: 0.732763, acc.: 55.47%] [G loss: 0.943960]\n",
      "epoch:29 step:27308 [D loss: 0.765788, acc.: 49.22%] [G loss: 0.875560]\n",
      "epoch:29 step:27309 [D loss: 0.681155, acc.: 58.59%] [G loss: 0.958644]\n",
      "epoch:29 step:27310 [D loss: 0.560998, acc.: 71.09%] [G loss: 1.182421]\n",
      "epoch:29 step:27311 [D loss: 0.500708, acc.: 82.81%] [G loss: 1.036813]\n",
      "epoch:29 step:27312 [D loss: 0.237703, acc.: 96.88%] [G loss: 1.354744]\n",
      "epoch:29 step:27313 [D loss: 0.837998, acc.: 47.66%] [G loss: 1.129183]\n",
      "epoch:29 step:27314 [D loss: 0.833808, acc.: 38.28%] [G loss: 0.891563]\n",
      "epoch:29 step:27315 [D loss: 0.567064, acc.: 71.09%] [G loss: 1.093148]\n",
      "epoch:29 step:27316 [D loss: 0.642356, acc.: 64.84%] [G loss: 1.215060]\n",
      "epoch:29 step:27317 [D loss: 0.467688, acc.: 80.47%] [G loss: 1.321386]\n",
      "epoch:29 step:27318 [D loss: 0.236106, acc.: 96.09%] [G loss: 1.488635]\n",
      "epoch:29 step:27319 [D loss: 0.436026, acc.: 85.16%] [G loss: 1.365680]\n",
      "epoch:29 step:27320 [D loss: 0.899562, acc.: 35.94%] [G loss: 1.100700]\n",
      "epoch:29 step:27321 [D loss: 0.656923, acc.: 63.28%] [G loss: 1.018548]\n",
      "epoch:29 step:27322 [D loss: 0.464076, acc.: 86.72%] [G loss: 1.185231]\n",
      "epoch:29 step:27323 [D loss: 0.295845, acc.: 91.41%] [G loss: 1.604043]\n",
      "epoch:29 step:27324 [D loss: 0.273940, acc.: 92.19%] [G loss: 1.656055]\n",
      "epoch:29 step:27325 [D loss: 0.324525, acc.: 91.41%] [G loss: 1.620564]\n",
      "epoch:29 step:27326 [D loss: 1.102642, acc.: 31.25%] [G loss: 1.336427]\n",
      "epoch:29 step:27327 [D loss: 0.954529, acc.: 41.41%] [G loss: 1.209507]\n",
      "epoch:29 step:27328 [D loss: 0.672324, acc.: 58.59%] [G loss: 1.080933]\n",
      "epoch:29 step:27329 [D loss: 0.421960, acc.: 86.72%] [G loss: 1.446388]\n",
      "epoch:29 step:27330 [D loss: 0.573156, acc.: 71.09%] [G loss: 1.138653]\n",
      "epoch:29 step:27331 [D loss: 0.248980, acc.: 94.53%] [G loss: 1.689913]\n",
      "epoch:29 step:27332 [D loss: 0.285279, acc.: 94.53%] [G loss: 1.421239]\n",
      "epoch:29 step:27333 [D loss: 0.677721, acc.: 61.72%] [G loss: 1.203905]\n",
      "epoch:29 step:27334 [D loss: 0.595815, acc.: 67.97%] [G loss: 1.252574]\n",
      "epoch:29 step:27335 [D loss: 0.486091, acc.: 79.69%] [G loss: 0.832146]\n",
      "epoch:29 step:27336 [D loss: 0.557517, acc.: 63.28%] [G loss: 1.247156]\n",
      "epoch:29 step:27337 [D loss: 0.323268, acc.: 87.50%] [G loss: 1.664531]\n",
      "epoch:29 step:27338 [D loss: 0.304873, acc.: 92.97%] [G loss: 1.732724]\n",
      "epoch:29 step:27339 [D loss: 0.441635, acc.: 78.12%] [G loss: 1.435331]\n",
      "epoch:29 step:27340 [D loss: 0.212927, acc.: 98.44%] [G loss: 2.113363]\n",
      "epoch:29 step:27341 [D loss: 0.290145, acc.: 96.09%] [G loss: 1.684999]\n",
      "epoch:29 step:27342 [D loss: 0.446122, acc.: 83.59%] [G loss: 1.416471]\n",
      "epoch:29 step:27343 [D loss: 0.718849, acc.: 57.81%] [G loss: 1.134247]\n",
      "epoch:29 step:27344 [D loss: 0.568715, acc.: 70.31%] [G loss: 1.158426]\n",
      "epoch:29 step:27345 [D loss: 0.438741, acc.: 81.25%] [G loss: 1.186832]\n",
      "epoch:29 step:27346 [D loss: 0.498381, acc.: 77.34%] [G loss: 1.748422]\n",
      "epoch:29 step:27347 [D loss: 0.694601, acc.: 57.03%] [G loss: 1.537377]\n",
      "epoch:29 step:27348 [D loss: 0.957796, acc.: 42.97%] [G loss: 0.591787]\n",
      "epoch:29 step:27349 [D loss: 0.424984, acc.: 87.50%] [G loss: 1.523218]\n",
      "epoch:29 step:27350 [D loss: 1.013613, acc.: 33.59%] [G loss: 0.570331]\n",
      "epoch:29 step:27351 [D loss: 1.073814, acc.: 25.78%] [G loss: 0.829208]\n",
      "epoch:29 step:27352 [D loss: 0.805583, acc.: 50.00%] [G loss: 0.707989]\n",
      "epoch:29 step:27353 [D loss: 0.806521, acc.: 39.84%] [G loss: 0.819925]\n",
      "epoch:29 step:27354 [D loss: 0.930514, acc.: 43.75%] [G loss: 0.640274]\n",
      "epoch:29 step:27355 [D loss: 0.497679, acc.: 81.25%] [G loss: 1.141659]\n",
      "epoch:29 step:27356 [D loss: 0.874352, acc.: 44.53%] [G loss: 1.152841]\n",
      "epoch:29 step:27357 [D loss: 0.575664, acc.: 71.88%] [G loss: 1.206141]\n",
      "epoch:29 step:27358 [D loss: 1.210577, acc.: 21.09%] [G loss: 0.796538]\n",
      "epoch:29 step:27359 [D loss: 0.856780, acc.: 39.06%] [G loss: 0.806253]\n",
      "epoch:29 step:27360 [D loss: 0.858759, acc.: 44.53%] [G loss: 0.810704]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27361 [D loss: 0.899094, acc.: 39.06%] [G loss: 0.755249]\n",
      "epoch:29 step:27362 [D loss: 0.968088, acc.: 28.12%] [G loss: 1.125144]\n",
      "epoch:29 step:27363 [D loss: 0.630559, acc.: 64.06%] [G loss: 1.103022]\n",
      "epoch:29 step:27364 [D loss: 0.722978, acc.: 56.25%] [G loss: 1.234594]\n",
      "epoch:29 step:27365 [D loss: 0.517766, acc.: 69.53%] [G loss: 1.304087]\n",
      "epoch:29 step:27366 [D loss: 0.580152, acc.: 71.09%] [G loss: 1.460080]\n",
      "epoch:29 step:27367 [D loss: 0.488025, acc.: 84.38%] [G loss: 1.191206]\n",
      "epoch:29 step:27368 [D loss: 0.654852, acc.: 64.06%] [G loss: 1.325320]\n",
      "epoch:29 step:27369 [D loss: 0.771692, acc.: 47.66%] [G loss: 1.070404]\n",
      "epoch:29 step:27370 [D loss: 0.812599, acc.: 44.53%] [G loss: 0.725948]\n",
      "epoch:29 step:27371 [D loss: 0.823256, acc.: 45.31%] [G loss: 1.116051]\n",
      "epoch:29 step:27372 [D loss: 1.080702, acc.: 17.97%] [G loss: 1.037973]\n",
      "epoch:29 step:27373 [D loss: 1.071962, acc.: 30.47%] [G loss: 0.966796]\n",
      "epoch:29 step:27374 [D loss: 0.949407, acc.: 35.16%] [G loss: 1.155993]\n",
      "epoch:29 step:27375 [D loss: 0.880339, acc.: 46.09%] [G loss: 1.540374]\n",
      "epoch:29 step:27376 [D loss: 0.806361, acc.: 47.66%] [G loss: 0.999865]\n",
      "epoch:29 step:27377 [D loss: 0.674785, acc.: 61.72%] [G loss: 1.127723]\n",
      "epoch:29 step:27378 [D loss: 0.574613, acc.: 63.28%] [G loss: 1.261199]\n",
      "epoch:29 step:27379 [D loss: 0.590101, acc.: 67.19%] [G loss: 1.184727]\n",
      "epoch:29 step:27380 [D loss: 0.588772, acc.: 69.53%] [G loss: 1.182824]\n",
      "epoch:29 step:27381 [D loss: 0.595718, acc.: 69.53%] [G loss: 1.083747]\n",
      "epoch:29 step:27382 [D loss: 0.478790, acc.: 79.69%] [G loss: 1.191896]\n",
      "epoch:29 step:27383 [D loss: 0.852942, acc.: 39.84%] [G loss: 0.952282]\n",
      "epoch:29 step:27384 [D loss: 0.791721, acc.: 46.88%] [G loss: 0.968898]\n",
      "epoch:29 step:27385 [D loss: 0.654638, acc.: 60.16%] [G loss: 1.067352]\n",
      "epoch:29 step:27386 [D loss: 0.533082, acc.: 76.56%] [G loss: 1.222923]\n",
      "epoch:29 step:27387 [D loss: 0.639080, acc.: 64.84%] [G loss: 1.268807]\n",
      "epoch:29 step:27388 [D loss: 0.650041, acc.: 59.38%] [G loss: 1.337499]\n",
      "epoch:29 step:27389 [D loss: 0.642248, acc.: 64.84%] [G loss: 1.333393]\n",
      "epoch:29 step:27390 [D loss: 0.735693, acc.: 54.69%] [G loss: 0.930367]\n",
      "epoch:29 step:27391 [D loss: 0.667849, acc.: 68.75%] [G loss: 0.894003]\n",
      "epoch:29 step:27392 [D loss: 0.667186, acc.: 62.50%] [G loss: 1.002657]\n",
      "epoch:29 step:27393 [D loss: 0.297613, acc.: 89.84%] [G loss: 1.534023]\n",
      "epoch:29 step:27394 [D loss: 0.253184, acc.: 99.22%] [G loss: 1.638532]\n",
      "epoch:29 step:27395 [D loss: 0.328389, acc.: 89.84%] [G loss: 1.785662]\n",
      "epoch:29 step:27396 [D loss: 0.228239, acc.: 98.44%] [G loss: 2.111968]\n",
      "epoch:29 step:27397 [D loss: 0.702882, acc.: 58.59%] [G loss: 1.853364]\n",
      "epoch:29 step:27398 [D loss: 0.797175, acc.: 44.53%] [G loss: 1.096740]\n",
      "epoch:29 step:27399 [D loss: 0.497514, acc.: 77.34%] [G loss: 0.969222]\n",
      "epoch:29 step:27400 [D loss: 0.712756, acc.: 57.03%] [G loss: 1.060717]\n",
      "##############\n",
      "[2.70424818 1.66361707 5.68426429 4.31864809 3.10310185 5.66961345\n",
      " 4.22941867 4.7633149  4.09081115 3.93201537]\n",
      "##########\n",
      "epoch:29 step:27401 [D loss: 0.451602, acc.: 83.59%] [G loss: 1.281222]\n",
      "epoch:29 step:27402 [D loss: 0.407829, acc.: 85.94%] [G loss: 1.470747]\n",
      "epoch:29 step:27403 [D loss: 0.205379, acc.: 96.09%] [G loss: 1.952897]\n",
      "epoch:29 step:27404 [D loss: 0.224348, acc.: 93.75%] [G loss: 1.785014]\n",
      "epoch:29 step:27405 [D loss: 0.287901, acc.: 93.75%] [G loss: 1.669275]\n",
      "epoch:29 step:27406 [D loss: 0.731258, acc.: 57.81%] [G loss: 1.589483]\n",
      "epoch:29 step:27407 [D loss: 0.629880, acc.: 67.19%] [G loss: 1.223390]\n",
      "epoch:29 step:27408 [D loss: 0.403904, acc.: 83.59%] [G loss: 1.154517]\n",
      "epoch:29 step:27409 [D loss: 0.707556, acc.: 56.25%] [G loss: 0.945377]\n",
      "epoch:29 step:27410 [D loss: 0.491979, acc.: 78.12%] [G loss: 1.238210]\n",
      "epoch:29 step:27411 [D loss: 0.390049, acc.: 85.94%] [G loss: 1.231520]\n",
      "epoch:29 step:27412 [D loss: 0.673192, acc.: 59.38%] [G loss: 1.060073]\n",
      "epoch:29 step:27413 [D loss: 1.146677, acc.: 32.03%] [G loss: 0.706805]\n",
      "epoch:29 step:27414 [D loss: 0.816102, acc.: 53.91%] [G loss: 1.016043]\n",
      "epoch:29 step:27415 [D loss: 0.706408, acc.: 52.34%] [G loss: 0.826082]\n",
      "epoch:29 step:27416 [D loss: 0.784470, acc.: 50.78%] [G loss: 0.560461]\n",
      "epoch:29 step:27417 [D loss: 0.963578, acc.: 36.72%] [G loss: 1.006334]\n",
      "epoch:29 step:27418 [D loss: 0.718687, acc.: 53.12%] [G loss: 1.078206]\n",
      "epoch:29 step:27419 [D loss: 0.945184, acc.: 36.72%] [G loss: 0.875095]\n",
      "epoch:29 step:27420 [D loss: 0.741018, acc.: 59.38%] [G loss: 0.841433]\n",
      "epoch:29 step:27421 [D loss: 0.697246, acc.: 54.69%] [G loss: 1.131616]\n",
      "epoch:29 step:27422 [D loss: 0.730735, acc.: 51.56%] [G loss: 0.978875]\n",
      "epoch:29 step:27423 [D loss: 0.792679, acc.: 50.78%] [G loss: 0.893355]\n",
      "epoch:29 step:27424 [D loss: 0.771719, acc.: 47.66%] [G loss: 0.909594]\n",
      "epoch:29 step:27425 [D loss: 0.611017, acc.: 67.19%] [G loss: 1.064083]\n",
      "epoch:29 step:27426 [D loss: 0.581176, acc.: 71.88%] [G loss: 1.237236]\n",
      "epoch:29 step:27427 [D loss: 0.660836, acc.: 61.72%] [G loss: 1.111228]\n",
      "epoch:29 step:27428 [D loss: 0.502632, acc.: 80.47%] [G loss: 0.959945]\n",
      "epoch:29 step:27429 [D loss: 0.450652, acc.: 82.03%] [G loss: 1.526809]\n",
      "epoch:29 step:27430 [D loss: 0.534401, acc.: 77.34%] [G loss: 0.922832]\n",
      "epoch:29 step:27431 [D loss: 0.683192, acc.: 57.03%] [G loss: 0.887657]\n",
      "epoch:29 step:27432 [D loss: 0.348972, acc.: 91.41%] [G loss: 1.252567]\n",
      "epoch:29 step:27433 [D loss: 0.402716, acc.: 85.16%] [G loss: 1.348114]\n",
      "epoch:29 step:27434 [D loss: 0.375610, acc.: 89.06%] [G loss: 1.358572]\n",
      "epoch:29 step:27435 [D loss: 0.735014, acc.: 57.03%] [G loss: 1.003212]\n",
      "epoch:29 step:27436 [D loss: 0.627151, acc.: 67.19%] [G loss: 1.394247]\n",
      "epoch:29 step:27437 [D loss: 0.469013, acc.: 79.69%] [G loss: 1.062608]\n",
      "epoch:29 step:27438 [D loss: 0.586689, acc.: 71.09%] [G loss: 1.347393]\n",
      "epoch:29 step:27439 [D loss: 0.880270, acc.: 39.84%] [G loss: 1.066053]\n",
      "epoch:29 step:27440 [D loss: 0.391110, acc.: 89.06%] [G loss: 1.320143]\n",
      "epoch:29 step:27441 [D loss: 0.600552, acc.: 66.41%] [G loss: 1.078274]\n",
      "epoch:29 step:27442 [D loss: 0.661456, acc.: 60.16%] [G loss: 0.989474]\n",
      "epoch:29 step:27443 [D loss: 0.668723, acc.: 61.72%] [G loss: 1.168744]\n",
      "epoch:29 step:27444 [D loss: 0.483148, acc.: 81.25%] [G loss: 1.246899]\n",
      "epoch:29 step:27445 [D loss: 0.412738, acc.: 88.28%] [G loss: 0.961625]\n",
      "epoch:29 step:27446 [D loss: 0.478046, acc.: 84.38%] [G loss: 1.141721]\n",
      "epoch:29 step:27447 [D loss: 0.461711, acc.: 83.59%] [G loss: 1.030235]\n",
      "epoch:29 step:27448 [D loss: 0.583250, acc.: 75.78%] [G loss: 1.121538]\n",
      "epoch:29 step:27449 [D loss: 0.643347, acc.: 65.62%] [G loss: 1.324979]\n",
      "epoch:29 step:27450 [D loss: 0.688337, acc.: 56.25%] [G loss: 1.390715]\n",
      "epoch:29 step:27451 [D loss: 0.518620, acc.: 75.78%] [G loss: 1.017634]\n",
      "epoch:29 step:27452 [D loss: 0.287436, acc.: 93.75%] [G loss: 1.319426]\n",
      "epoch:29 step:27453 [D loss: 0.290942, acc.: 95.31%] [G loss: 1.292400]\n",
      "epoch:29 step:27454 [D loss: 0.903157, acc.: 42.97%] [G loss: 1.274153]\n",
      "epoch:29 step:27455 [D loss: 0.564570, acc.: 70.31%] [G loss: 1.082433]\n",
      "epoch:29 step:27456 [D loss: 0.625642, acc.: 65.62%] [G loss: 1.085111]\n",
      "epoch:29 step:27457 [D loss: 0.401019, acc.: 88.28%] [G loss: 1.325438]\n",
      "epoch:29 step:27458 [D loss: 0.498823, acc.: 78.12%] [G loss: 1.026657]\n",
      "epoch:29 step:27459 [D loss: 0.297591, acc.: 95.31%] [G loss: 1.594298]\n",
      "epoch:29 step:27460 [D loss: 0.557329, acc.: 75.78%] [G loss: 1.344618]\n",
      "epoch:29 step:27461 [D loss: 0.764861, acc.: 53.12%] [G loss: 0.823421]\n",
      "epoch:29 step:27462 [D loss: 0.568165, acc.: 67.97%] [G loss: 1.185075]\n",
      "epoch:29 step:27463 [D loss: 0.691413, acc.: 57.03%] [G loss: 1.069114]\n",
      "epoch:29 step:27464 [D loss: 0.285000, acc.: 92.19%] [G loss: 1.597060]\n",
      "epoch:29 step:27465 [D loss: 0.565291, acc.: 68.75%] [G loss: 1.302310]\n",
      "epoch:29 step:27466 [D loss: 0.557628, acc.: 69.53%] [G loss: 0.923660]\n",
      "epoch:29 step:27467 [D loss: 0.814582, acc.: 50.00%] [G loss: 1.318208]\n",
      "epoch:29 step:27468 [D loss: 0.755556, acc.: 52.34%] [G loss: 1.377156]\n",
      "epoch:29 step:27469 [D loss: 0.645426, acc.: 62.50%] [G loss: 1.171886]\n",
      "epoch:29 step:27470 [D loss: 0.372939, acc.: 91.41%] [G loss: 1.652796]\n",
      "epoch:29 step:27471 [D loss: 0.320575, acc.: 92.97%] [G loss: 1.318871]\n",
      "epoch:29 step:27472 [D loss: 0.326785, acc.: 94.53%] [G loss: 1.415868]\n",
      "epoch:29 step:27473 [D loss: 0.395291, acc.: 91.41%] [G loss: 1.529325]\n",
      "epoch:29 step:27474 [D loss: 0.749862, acc.: 50.78%] [G loss: 1.342030]\n",
      "epoch:29 step:27475 [D loss: 0.567613, acc.: 69.53%] [G loss: 1.133978]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27476 [D loss: 0.471126, acc.: 81.25%] [G loss: 1.218659]\n",
      "epoch:29 step:27477 [D loss: 0.632924, acc.: 60.94%] [G loss: 1.293222]\n",
      "epoch:29 step:27478 [D loss: 0.685323, acc.: 55.47%] [G loss: 1.199789]\n",
      "epoch:29 step:27479 [D loss: 0.588149, acc.: 64.06%] [G loss: 0.989232]\n",
      "epoch:29 step:27480 [D loss: 0.558403, acc.: 71.88%] [G loss: 1.264848]\n",
      "epoch:29 step:27481 [D loss: 0.503837, acc.: 78.12%] [G loss: 1.231921]\n",
      "epoch:29 step:27482 [D loss: 0.596757, acc.: 65.62%] [G loss: 1.254381]\n",
      "epoch:29 step:27483 [D loss: 0.625426, acc.: 64.84%] [G loss: 1.131705]\n",
      "epoch:29 step:27484 [D loss: 0.517049, acc.: 78.91%] [G loss: 1.031808]\n",
      "epoch:29 step:27485 [D loss: 0.340084, acc.: 86.72%] [G loss: 1.211354]\n",
      "epoch:29 step:27486 [D loss: 0.306520, acc.: 94.53%] [G loss: 1.527332]\n",
      "epoch:29 step:27487 [D loss: 0.362341, acc.: 90.62%] [G loss: 1.546164]\n",
      "epoch:29 step:27488 [D loss: 0.373698, acc.: 93.75%] [G loss: 1.335556]\n",
      "epoch:29 step:27489 [D loss: 0.980467, acc.: 34.38%] [G loss: 1.161019]\n",
      "epoch:29 step:27490 [D loss: 0.721829, acc.: 57.03%] [G loss: 1.188355]\n",
      "epoch:29 step:27491 [D loss: 0.436119, acc.: 85.94%] [G loss: 1.252960]\n",
      "epoch:29 step:27492 [D loss: 0.546799, acc.: 77.34%] [G loss: 1.103347]\n",
      "epoch:29 step:27493 [D loss: 0.431569, acc.: 86.72%] [G loss: 1.352920]\n",
      "epoch:29 step:27494 [D loss: 0.340084, acc.: 92.19%] [G loss: 1.625211]\n",
      "epoch:29 step:27495 [D loss: 0.352678, acc.: 89.06%] [G loss: 1.343579]\n",
      "epoch:29 step:27496 [D loss: 0.750793, acc.: 55.47%] [G loss: 1.266037]\n",
      "epoch:29 step:27497 [D loss: 0.820353, acc.: 46.88%] [G loss: 0.701110]\n",
      "epoch:29 step:27498 [D loss: 0.646016, acc.: 59.38%] [G loss: 1.127446]\n",
      "epoch:29 step:27499 [D loss: 0.415850, acc.: 87.50%] [G loss: 1.415745]\n",
      "epoch:29 step:27500 [D loss: 0.332284, acc.: 86.72%] [G loss: 1.375209]\n",
      "epoch:29 step:27501 [D loss: 0.313651, acc.: 95.31%] [G loss: 1.695270]\n",
      "epoch:29 step:27502 [D loss: 0.715518, acc.: 53.91%] [G loss: 0.921756]\n",
      "epoch:29 step:27503 [D loss: 1.012954, acc.: 30.47%] [G loss: 0.955172]\n",
      "epoch:29 step:27504 [D loss: 0.784159, acc.: 46.88%] [G loss: 1.098090]\n",
      "epoch:29 step:27505 [D loss: 0.684710, acc.: 57.81%] [G loss: 1.052654]\n",
      "epoch:29 step:27506 [D loss: 0.648571, acc.: 60.94%] [G loss: 1.158234]\n",
      "epoch:29 step:27507 [D loss: 0.664726, acc.: 60.16%] [G loss: 0.996972]\n",
      "epoch:29 step:27508 [D loss: 0.619560, acc.: 62.50%] [G loss: 1.258897]\n",
      "epoch:29 step:27509 [D loss: 0.614786, acc.: 65.62%] [G loss: 1.224661]\n",
      "epoch:29 step:27510 [D loss: 0.514173, acc.: 79.69%] [G loss: 1.084535]\n",
      "epoch:29 step:27511 [D loss: 0.696616, acc.: 56.25%] [G loss: 1.091973]\n",
      "epoch:29 step:27512 [D loss: 0.727764, acc.: 50.78%] [G loss: 1.050810]\n",
      "epoch:29 step:27513 [D loss: 0.665002, acc.: 59.38%] [G loss: 0.887738]\n",
      "epoch:29 step:27514 [D loss: 0.600495, acc.: 67.97%] [G loss: 1.315958]\n",
      "epoch:29 step:27515 [D loss: 0.296793, acc.: 91.41%] [G loss: 1.484291]\n",
      "epoch:29 step:27516 [D loss: 0.170895, acc.: 96.88%] [G loss: 2.103197]\n",
      "epoch:29 step:27517 [D loss: 0.236925, acc.: 97.66%] [G loss: 1.918855]\n",
      "epoch:29 step:27518 [D loss: 0.251263, acc.: 100.00%] [G loss: 1.760543]\n",
      "epoch:29 step:27519 [D loss: 0.159375, acc.: 99.22%] [G loss: 1.562040]\n",
      "epoch:29 step:27520 [D loss: 0.173439, acc.: 96.88%] [G loss: 2.064200]\n",
      "epoch:29 step:27521 [D loss: 0.997507, acc.: 44.53%] [G loss: 1.386460]\n",
      "epoch:29 step:27522 [D loss: 0.716782, acc.: 51.56%] [G loss: 1.429560]\n",
      "epoch:29 step:27523 [D loss: 0.486067, acc.: 76.56%] [G loss: 1.211142]\n",
      "epoch:29 step:27524 [D loss: 0.483928, acc.: 78.91%] [G loss: 1.084982]\n",
      "epoch:29 step:27525 [D loss: 0.308776, acc.: 94.53%] [G loss: 1.458800]\n",
      "epoch:29 step:27526 [D loss: 0.495312, acc.: 80.47%] [G loss: 1.091526]\n",
      "epoch:29 step:27527 [D loss: 0.308271, acc.: 93.75%] [G loss: 1.551146]\n",
      "epoch:29 step:27528 [D loss: 0.705304, acc.: 53.12%] [G loss: 1.082998]\n",
      "epoch:29 step:27529 [D loss: 0.554687, acc.: 73.44%] [G loss: 1.146009]\n",
      "epoch:29 step:27530 [D loss: 0.492800, acc.: 82.03%] [G loss: 1.012119]\n",
      "epoch:29 step:27531 [D loss: 0.485132, acc.: 72.66%] [G loss: 1.196435]\n",
      "epoch:29 step:27532 [D loss: 0.467696, acc.: 80.47%] [G loss: 1.202099]\n",
      "epoch:29 step:27533 [D loss: 0.541806, acc.: 75.00%] [G loss: 1.208132]\n",
      "epoch:29 step:27534 [D loss: 0.660288, acc.: 61.72%] [G loss: 1.409569]\n",
      "epoch:29 step:27535 [D loss: 0.783447, acc.: 46.09%] [G loss: 0.875878]\n",
      "epoch:29 step:27536 [D loss: 0.729930, acc.: 55.47%] [G loss: 1.056979]\n",
      "epoch:29 step:27537 [D loss: 0.743900, acc.: 49.22%] [G loss: 1.025740]\n",
      "epoch:29 step:27538 [D loss: 0.405516, acc.: 87.50%] [G loss: 1.200675]\n",
      "epoch:29 step:27539 [D loss: 0.310052, acc.: 90.62%] [G loss: 1.545097]\n",
      "epoch:29 step:27540 [D loss: 0.243873, acc.: 96.09%] [G loss: 1.489622]\n",
      "epoch:29 step:27541 [D loss: 0.718561, acc.: 56.25%] [G loss: 1.269368]\n",
      "epoch:29 step:27542 [D loss: 0.562573, acc.: 69.53%] [G loss: 1.248039]\n",
      "epoch:29 step:27543 [D loss: 0.623527, acc.: 61.72%] [G loss: 1.147747]\n",
      "epoch:29 step:27544 [D loss: 0.393802, acc.: 91.41%] [G loss: 1.614180]\n",
      "epoch:29 step:27545 [D loss: 0.622871, acc.: 58.59%] [G loss: 1.015600]\n",
      "epoch:29 step:27546 [D loss: 0.888457, acc.: 33.59%] [G loss: 0.788011]\n",
      "epoch:29 step:27547 [D loss: 0.744250, acc.: 48.44%] [G loss: 0.857184]\n",
      "epoch:29 step:27548 [D loss: 0.786256, acc.: 53.91%] [G loss: 0.900945]\n",
      "epoch:29 step:27549 [D loss: 0.635221, acc.: 60.94%] [G loss: 1.010061]\n",
      "epoch:29 step:27550 [D loss: 0.461530, acc.: 77.34%] [G loss: 0.962455]\n",
      "epoch:29 step:27551 [D loss: 0.352455, acc.: 85.94%] [G loss: 1.314147]\n",
      "epoch:29 step:27552 [D loss: 0.720972, acc.: 53.91%] [G loss: 1.200650]\n",
      "epoch:29 step:27553 [D loss: 0.564244, acc.: 72.66%] [G loss: 1.365199]\n",
      "epoch:29 step:27554 [D loss: 0.385502, acc.: 89.84%] [G loss: 1.376565]\n",
      "epoch:29 step:27555 [D loss: 0.824393, acc.: 42.97%] [G loss: 1.041350]\n",
      "epoch:29 step:27556 [D loss: 0.586466, acc.: 70.31%] [G loss: 1.133767]\n",
      "epoch:29 step:27557 [D loss: 0.634132, acc.: 64.06%] [G loss: 0.953346]\n",
      "epoch:29 step:27558 [D loss: 0.528547, acc.: 77.34%] [G loss: 1.242773]\n",
      "epoch:29 step:27559 [D loss: 0.753470, acc.: 50.78%] [G loss: 1.129797]\n",
      "epoch:29 step:27560 [D loss: 0.583567, acc.: 71.09%] [G loss: 1.219724]\n",
      "epoch:29 step:27561 [D loss: 0.644360, acc.: 67.19%] [G loss: 0.952145]\n",
      "epoch:29 step:27562 [D loss: 0.561688, acc.: 75.00%] [G loss: 1.001175]\n",
      "epoch:29 step:27563 [D loss: 0.392736, acc.: 78.12%] [G loss: 1.198913]\n",
      "epoch:29 step:27564 [D loss: 0.245627, acc.: 97.66%] [G loss: 1.375266]\n",
      "epoch:29 step:27565 [D loss: 0.567209, acc.: 71.88%] [G loss: 1.144267]\n",
      "epoch:29 step:27566 [D loss: 0.460629, acc.: 80.47%] [G loss: 1.367640]\n",
      "epoch:29 step:27567 [D loss: 0.440415, acc.: 78.91%] [G loss: 0.978370]\n",
      "epoch:29 step:27568 [D loss: 0.521924, acc.: 78.12%] [G loss: 1.074809]\n",
      "epoch:29 step:27569 [D loss: 0.284336, acc.: 88.28%] [G loss: 1.464504]\n",
      "epoch:29 step:27570 [D loss: 0.223916, acc.: 96.09%] [G loss: 1.671907]\n",
      "epoch:29 step:27571 [D loss: 0.113795, acc.: 100.00%] [G loss: 2.256993]\n",
      "epoch:29 step:27572 [D loss: 0.236598, acc.: 97.66%] [G loss: 1.528393]\n",
      "epoch:29 step:27573 [D loss: 0.144941, acc.: 100.00%] [G loss: 2.267659]\n",
      "epoch:29 step:27574 [D loss: 0.287546, acc.: 92.97%] [G loss: 1.873536]\n",
      "epoch:29 step:27575 [D loss: 0.222693, acc.: 96.88%] [G loss: 1.959351]\n",
      "epoch:29 step:27576 [D loss: 0.741619, acc.: 52.34%] [G loss: 0.798945]\n",
      "epoch:29 step:27577 [D loss: 0.204340, acc.: 97.66%] [G loss: 2.038055]\n",
      "epoch:29 step:27578 [D loss: 0.307308, acc.: 92.97%] [G loss: 1.499745]\n",
      "epoch:29 step:27579 [D loss: 0.212177, acc.: 98.44%] [G loss: 2.117892]\n",
      "epoch:29 step:27580 [D loss: 0.444794, acc.: 79.69%] [G loss: 1.545388]\n",
      "epoch:29 step:27581 [D loss: 0.558629, acc.: 71.88%] [G loss: 0.894607]\n",
      "epoch:29 step:27582 [D loss: 0.323555, acc.: 91.41%] [G loss: 1.755418]\n",
      "epoch:29 step:27583 [D loss: 0.951649, acc.: 48.44%] [G loss: 0.644165]\n",
      "epoch:29 step:27584 [D loss: 1.526602, acc.: 10.16%] [G loss: 1.012602]\n",
      "epoch:29 step:27585 [D loss: 0.867846, acc.: 42.19%] [G loss: 0.817290]\n",
      "epoch:29 step:27586 [D loss: 1.029517, acc.: 28.91%] [G loss: 0.784856]\n",
      "epoch:29 step:27587 [D loss: 1.103265, acc.: 23.44%] [G loss: 0.798013]\n",
      "epoch:29 step:27588 [D loss: 1.059511, acc.: 30.47%] [G loss: 0.754587]\n",
      "epoch:29 step:27589 [D loss: 0.700596, acc.: 61.72%] [G loss: 1.039929]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27590 [D loss: 0.901648, acc.: 38.28%] [G loss: 0.857913]\n",
      "epoch:29 step:27591 [D loss: 0.820829, acc.: 49.22%] [G loss: 0.855266]\n",
      "epoch:29 step:27592 [D loss: 0.421525, acc.: 84.38%] [G loss: 1.789577]\n",
      "epoch:29 step:27593 [D loss: 0.601447, acc.: 70.31%] [G loss: 1.153553]\n",
      "epoch:29 step:27594 [D loss: 1.028463, acc.: 29.69%] [G loss: 0.958121]\n",
      "epoch:29 step:27595 [D loss: 0.743399, acc.: 52.34%] [G loss: 1.424889]\n",
      "epoch:29 step:27596 [D loss: 0.899000, acc.: 39.84%] [G loss: 1.100794]\n",
      "epoch:29 step:27597 [D loss: 0.547735, acc.: 72.66%] [G loss: 1.033480]\n",
      "epoch:29 step:27598 [D loss: 0.583493, acc.: 70.31%] [G loss: 1.066093]\n",
      "epoch:29 step:27599 [D loss: 0.722107, acc.: 57.81%] [G loss: 1.117396]\n",
      "epoch:29 step:27600 [D loss: 0.757311, acc.: 48.44%] [G loss: 1.272599]\n",
      "##############\n",
      "[2.41884833 1.75907574 5.81465574 4.62882448 3.04902291 5.4051314\n",
      " 4.03679221 4.41806039 4.19556183 3.34749855]\n",
      "##########\n",
      "epoch:29 step:27601 [D loss: 0.577601, acc.: 69.53%] [G loss: 1.353707]\n",
      "epoch:29 step:27602 [D loss: 0.655540, acc.: 59.38%] [G loss: 1.276933]\n",
      "epoch:29 step:27603 [D loss: 0.717453, acc.: 56.25%] [G loss: 1.429601]\n",
      "epoch:29 step:27604 [D loss: 0.750246, acc.: 55.47%] [G loss: 1.293798]\n",
      "epoch:29 step:27605 [D loss: 0.560626, acc.: 69.53%] [G loss: 1.379935]\n",
      "epoch:29 step:27606 [D loss: 0.443534, acc.: 79.69%] [G loss: 1.523697]\n",
      "epoch:29 step:27607 [D loss: 0.400860, acc.: 84.38%] [G loss: 1.984216]\n",
      "epoch:29 step:27608 [D loss: 0.541788, acc.: 74.22%] [G loss: 1.537642]\n",
      "epoch:29 step:27609 [D loss: 0.440259, acc.: 83.59%] [G loss: 1.484041]\n",
      "epoch:29 step:27610 [D loss: 1.072581, acc.: 35.16%] [G loss: 1.149157]\n",
      "epoch:29 step:27611 [D loss: 0.709344, acc.: 57.03%] [G loss: 1.068486]\n",
      "epoch:29 step:27612 [D loss: 0.781765, acc.: 50.00%] [G loss: 1.036204]\n",
      "epoch:29 step:27613 [D loss: 0.701398, acc.: 57.81%] [G loss: 1.081031]\n",
      "epoch:29 step:27614 [D loss: 0.682996, acc.: 57.81%] [G loss: 1.208610]\n",
      "epoch:29 step:27615 [D loss: 0.854786, acc.: 44.53%] [G loss: 0.950131]\n",
      "epoch:29 step:27616 [D loss: 0.572228, acc.: 75.78%] [G loss: 1.328355]\n",
      "epoch:29 step:27617 [D loss: 0.619303, acc.: 64.84%] [G loss: 1.258608]\n",
      "epoch:29 step:27618 [D loss: 0.666874, acc.: 61.72%] [G loss: 0.858782]\n",
      "epoch:29 step:27619 [D loss: 0.909732, acc.: 42.97%] [G loss: 0.960429]\n",
      "epoch:29 step:27620 [D loss: 0.620819, acc.: 64.06%] [G loss: 1.166089]\n",
      "epoch:29 step:27621 [D loss: 0.590528, acc.: 64.84%] [G loss: 1.063161]\n",
      "epoch:29 step:27622 [D loss: 0.384797, acc.: 89.06%] [G loss: 1.489346]\n",
      "epoch:29 step:27623 [D loss: 0.669341, acc.: 64.84%] [G loss: 1.116761]\n",
      "epoch:29 step:27624 [D loss: 0.573968, acc.: 66.41%] [G loss: 1.371770]\n",
      "epoch:29 step:27625 [D loss: 0.447186, acc.: 79.69%] [G loss: 1.789392]\n",
      "epoch:29 step:27626 [D loss: 0.449644, acc.: 82.81%] [G loss: 1.418370]\n",
      "epoch:29 step:27627 [D loss: 0.526103, acc.: 71.88%] [G loss: 1.125832]\n",
      "epoch:29 step:27628 [D loss: 0.537732, acc.: 81.25%] [G loss: 1.167085]\n",
      "epoch:29 step:27629 [D loss: 0.427963, acc.: 81.25%] [G loss: 1.427683]\n",
      "epoch:29 step:27630 [D loss: 0.389349, acc.: 85.16%] [G loss: 1.465526]\n",
      "epoch:29 step:27631 [D loss: 1.074889, acc.: 38.28%] [G loss: 1.072361]\n",
      "epoch:29 step:27632 [D loss: 1.107793, acc.: 28.91%] [G loss: 1.046806]\n",
      "epoch:29 step:27633 [D loss: 0.823565, acc.: 45.31%] [G loss: 1.130918]\n",
      "epoch:29 step:27634 [D loss: 0.809009, acc.: 55.47%] [G loss: 0.970576]\n",
      "epoch:29 step:27635 [D loss: 0.947880, acc.: 37.50%] [G loss: 0.880110]\n",
      "epoch:29 step:27636 [D loss: 0.651483, acc.: 61.72%] [G loss: 1.161696]\n",
      "epoch:29 step:27637 [D loss: 0.688353, acc.: 58.59%] [G loss: 1.106371]\n",
      "epoch:29 step:27638 [D loss: 0.674601, acc.: 64.84%] [G loss: 1.452725]\n",
      "epoch:29 step:27639 [D loss: 0.627106, acc.: 64.06%] [G loss: 0.989720]\n",
      "epoch:29 step:27640 [D loss: 0.728611, acc.: 50.78%] [G loss: 0.966672]\n",
      "epoch:29 step:27641 [D loss: 0.518033, acc.: 72.66%] [G loss: 1.163038]\n",
      "epoch:29 step:27642 [D loss: 0.444773, acc.: 84.38%] [G loss: 1.244033]\n",
      "epoch:29 step:27643 [D loss: 0.313161, acc.: 94.53%] [G loss: 1.273004]\n",
      "epoch:29 step:27644 [D loss: 0.207875, acc.: 98.44%] [G loss: 1.712929]\n",
      "epoch:29 step:27645 [D loss: 0.443890, acc.: 79.69%] [G loss: 1.445668]\n",
      "epoch:29 step:27646 [D loss: 0.578671, acc.: 72.66%] [G loss: 1.049457]\n",
      "epoch:29 step:27647 [D loss: 0.312626, acc.: 96.09%] [G loss: 1.566013]\n",
      "epoch:29 step:27648 [D loss: 0.388875, acc.: 92.19%] [G loss: 1.653997]\n",
      "epoch:29 step:27649 [D loss: 0.581361, acc.: 67.97%] [G loss: 1.312206]\n",
      "epoch:29 step:27650 [D loss: 0.690970, acc.: 53.12%] [G loss: 1.137139]\n",
      "epoch:29 step:27651 [D loss: 0.742957, acc.: 50.78%] [G loss: 1.070387]\n",
      "epoch:29 step:27652 [D loss: 0.527034, acc.: 75.78%] [G loss: 1.210800]\n",
      "epoch:29 step:27653 [D loss: 0.577641, acc.: 73.44%] [G loss: 1.221034]\n",
      "epoch:29 step:27654 [D loss: 0.392204, acc.: 90.62%] [G loss: 1.204458]\n",
      "epoch:29 step:27655 [D loss: 0.664451, acc.: 60.16%] [G loss: 1.162078]\n",
      "epoch:29 step:27656 [D loss: 0.445172, acc.: 80.47%] [G loss: 1.582256]\n",
      "epoch:29 step:27657 [D loss: 0.289503, acc.: 94.53%] [G loss: 1.606353]\n",
      "epoch:29 step:27658 [D loss: 0.282125, acc.: 92.97%] [G loss: 1.715669]\n",
      "epoch:29 step:27659 [D loss: 0.443161, acc.: 86.72%] [G loss: 1.414421]\n",
      "epoch:29 step:27660 [D loss: 0.388069, acc.: 90.62%] [G loss: 1.324610]\n",
      "epoch:29 step:27661 [D loss: 0.502284, acc.: 77.34%] [G loss: 1.596701]\n",
      "epoch:29 step:27662 [D loss: 0.690216, acc.: 57.81%] [G loss: 1.022157]\n",
      "epoch:29 step:27663 [D loss: 0.444175, acc.: 86.72%] [G loss: 1.320501]\n",
      "epoch:29 step:27664 [D loss: 0.475918, acc.: 78.91%] [G loss: 1.287533]\n",
      "epoch:29 step:27665 [D loss: 0.713249, acc.: 57.81%] [G loss: 1.305491]\n",
      "epoch:29 step:27666 [D loss: 0.754193, acc.: 45.31%] [G loss: 1.116949]\n",
      "epoch:29 step:27667 [D loss: 0.745716, acc.: 54.69%] [G loss: 1.018891]\n",
      "epoch:29 step:27668 [D loss: 0.482585, acc.: 78.12%] [G loss: 1.311311]\n",
      "epoch:29 step:27669 [D loss: 0.695807, acc.: 55.47%] [G loss: 0.869515]\n",
      "epoch:29 step:27670 [D loss: 0.327004, acc.: 89.84%] [G loss: 1.223847]\n",
      "epoch:29 step:27671 [D loss: 0.307283, acc.: 93.75%] [G loss: 1.557673]\n",
      "epoch:29 step:27672 [D loss: 0.224419, acc.: 97.66%] [G loss: 1.584688]\n",
      "epoch:29 step:27673 [D loss: 0.806863, acc.: 51.56%] [G loss: 1.326497]\n",
      "epoch:29 step:27674 [D loss: 0.796861, acc.: 42.97%] [G loss: 1.046935]\n",
      "epoch:29 step:27675 [D loss: 0.817104, acc.: 46.88%] [G loss: 0.881080]\n",
      "epoch:29 step:27676 [D loss: 0.239048, acc.: 94.53%] [G loss: 1.290701]\n",
      "epoch:29 step:27677 [D loss: 0.227883, acc.: 94.53%] [G loss: 1.497645]\n",
      "epoch:29 step:27678 [D loss: 0.437430, acc.: 85.16%] [G loss: 1.206582]\n",
      "epoch:29 step:27679 [D loss: 0.507389, acc.: 78.12%] [G loss: 1.133597]\n",
      "epoch:29 step:27680 [D loss: 0.504356, acc.: 78.12%] [G loss: 1.434460]\n",
      "epoch:29 step:27681 [D loss: 0.342044, acc.: 88.28%] [G loss: 1.595319]\n",
      "epoch:29 step:27682 [D loss: 0.802511, acc.: 51.56%] [G loss: 1.792850]\n",
      "epoch:29 step:27683 [D loss: 0.770195, acc.: 50.78%] [G loss: 1.128701]\n",
      "epoch:29 step:27684 [D loss: 0.281018, acc.: 92.97%] [G loss: 1.487304]\n",
      "epoch:29 step:27685 [D loss: 0.328218, acc.: 95.31%] [G loss: 1.659659]\n",
      "epoch:29 step:27686 [D loss: 0.232190, acc.: 96.09%] [G loss: 1.787007]\n",
      "epoch:29 step:27687 [D loss: 0.285154, acc.: 94.53%] [G loss: 1.568985]\n",
      "epoch:29 step:27688 [D loss: 0.336134, acc.: 92.97%] [G loss: 1.566542]\n",
      "epoch:29 step:27689 [D loss: 0.644945, acc.: 65.62%] [G loss: 1.216292]\n",
      "epoch:29 step:27690 [D loss: 0.588279, acc.: 65.62%] [G loss: 1.370157]\n",
      "epoch:29 step:27691 [D loss: 0.549945, acc.: 75.00%] [G loss: 1.174685]\n",
      "epoch:29 step:27692 [D loss: 0.500225, acc.: 78.12%] [G loss: 1.403376]\n",
      "epoch:29 step:27693 [D loss: 0.539336, acc.: 75.78%] [G loss: 1.022876]\n",
      "epoch:29 step:27694 [D loss: 0.592396, acc.: 72.66%] [G loss: 0.986180]\n",
      "epoch:29 step:27695 [D loss: 0.574033, acc.: 68.75%] [G loss: 1.252444]\n",
      "epoch:29 step:27696 [D loss: 0.507574, acc.: 78.91%] [G loss: 1.434875]\n",
      "epoch:29 step:27697 [D loss: 0.425623, acc.: 85.94%] [G loss: 1.694624]\n",
      "epoch:29 step:27698 [D loss: 0.520213, acc.: 76.56%] [G loss: 1.506102]\n",
      "epoch:29 step:27699 [D loss: 0.360892, acc.: 89.06%] [G loss: 1.802647]\n",
      "epoch:29 step:27700 [D loss: 0.325729, acc.: 91.41%] [G loss: 1.362970]\n",
      "epoch:29 step:27701 [D loss: 0.385286, acc.: 87.50%] [G loss: 1.271496]\n",
      "epoch:29 step:27702 [D loss: 0.494231, acc.: 78.12%] [G loss: 1.331910]\n",
      "epoch:29 step:27703 [D loss: 0.437530, acc.: 79.69%] [G loss: 1.164764]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27704 [D loss: 0.674462, acc.: 57.03%] [G loss: 1.430772]\n",
      "epoch:29 step:27705 [D loss: 0.410679, acc.: 83.59%] [G loss: 1.669879]\n",
      "epoch:29 step:27706 [D loss: 0.307411, acc.: 92.97%] [G loss: 1.445232]\n",
      "epoch:29 step:27707 [D loss: 0.434199, acc.: 82.03%] [G loss: 1.260602]\n",
      "epoch:29 step:27708 [D loss: 0.489463, acc.: 78.12%] [G loss: 1.085173]\n",
      "epoch:29 step:27709 [D loss: 0.340404, acc.: 89.84%] [G loss: 1.479182]\n",
      "epoch:29 step:27710 [D loss: 0.267321, acc.: 92.97%] [G loss: 1.588924]\n",
      "epoch:29 step:27711 [D loss: 0.586005, acc.: 70.31%] [G loss: 1.605783]\n",
      "epoch:29 step:27712 [D loss: 0.578019, acc.: 73.44%] [G loss: 1.449624]\n",
      "epoch:29 step:27713 [D loss: 0.612567, acc.: 67.19%] [G loss: 1.034666]\n",
      "epoch:29 step:27714 [D loss: 0.607586, acc.: 70.31%] [G loss: 1.034946]\n",
      "epoch:29 step:27715 [D loss: 0.781639, acc.: 47.66%] [G loss: 0.849014]\n",
      "epoch:29 step:27716 [D loss: 0.444088, acc.: 86.72%] [G loss: 1.360644]\n",
      "epoch:29 step:27717 [D loss: 0.474105, acc.: 82.81%] [G loss: 1.323527]\n",
      "epoch:29 step:27718 [D loss: 0.320059, acc.: 95.31%] [G loss: 1.138884]\n",
      "epoch:29 step:27719 [D loss: 0.376704, acc.: 87.50%] [G loss: 1.348571]\n",
      "epoch:29 step:27720 [D loss: 0.346089, acc.: 90.62%] [G loss: 1.536770]\n",
      "epoch:29 step:27721 [D loss: 0.336014, acc.: 91.41%] [G loss: 1.595836]\n",
      "epoch:29 step:27722 [D loss: 0.238120, acc.: 99.22%] [G loss: 1.665020]\n",
      "epoch:29 step:27723 [D loss: 0.243075, acc.: 97.66%] [G loss: 1.644689]\n",
      "epoch:29 step:27724 [D loss: 0.172356, acc.: 98.44%] [G loss: 1.872538]\n",
      "epoch:29 step:27725 [D loss: 0.240029, acc.: 96.09%] [G loss: 1.746123]\n",
      "epoch:29 step:27726 [D loss: 0.330662, acc.: 95.31%] [G loss: 1.394240]\n",
      "epoch:29 step:27727 [D loss: 0.231921, acc.: 98.44%] [G loss: 1.885858]\n",
      "epoch:29 step:27728 [D loss: 0.244143, acc.: 98.44%] [G loss: 1.902647]\n",
      "epoch:29 step:27729 [D loss: 0.136578, acc.: 100.00%] [G loss: 2.080366]\n",
      "epoch:29 step:27730 [D loss: 0.201942, acc.: 99.22%] [G loss: 2.023659]\n",
      "epoch:29 step:27731 [D loss: 0.332062, acc.: 91.41%] [G loss: 1.895591]\n",
      "epoch:29 step:27732 [D loss: 0.932599, acc.: 45.31%] [G loss: 1.348163]\n",
      "epoch:29 step:27733 [D loss: 0.821404, acc.: 54.69%] [G loss: 0.985415]\n",
      "epoch:29 step:27734 [D loss: 0.423956, acc.: 83.59%] [G loss: 1.338120]\n",
      "epoch:29 step:27735 [D loss: 0.680524, acc.: 57.03%] [G loss: 1.259861]\n",
      "epoch:29 step:27736 [D loss: 0.597228, acc.: 72.66%] [G loss: 1.151067]\n",
      "epoch:29 step:27737 [D loss: 0.587854, acc.: 69.53%] [G loss: 1.075451]\n",
      "epoch:29 step:27738 [D loss: 0.613255, acc.: 59.38%] [G loss: 1.136604]\n",
      "epoch:29 step:27739 [D loss: 0.337642, acc.: 91.41%] [G loss: 1.601477]\n",
      "epoch:29 step:27740 [D loss: 0.346194, acc.: 93.75%] [G loss: 1.466946]\n",
      "epoch:29 step:27741 [D loss: 0.762236, acc.: 50.78%] [G loss: 1.156517]\n",
      "epoch:29 step:27742 [D loss: 0.798304, acc.: 45.31%] [G loss: 1.286984]\n",
      "epoch:29 step:27743 [D loss: 0.760006, acc.: 55.47%] [G loss: 0.706681]\n",
      "epoch:29 step:27744 [D loss: 0.583210, acc.: 66.41%] [G loss: 1.054074]\n",
      "epoch:29 step:27745 [D loss: 0.758343, acc.: 45.31%] [G loss: 1.023421]\n",
      "epoch:29 step:27746 [D loss: 0.522431, acc.: 71.09%] [G loss: 1.069964]\n",
      "epoch:29 step:27747 [D loss: 0.677484, acc.: 64.06%] [G loss: 1.293405]\n",
      "epoch:29 step:27748 [D loss: 0.665725, acc.: 60.94%] [G loss: 1.128295]\n",
      "epoch:29 step:27749 [D loss: 0.458532, acc.: 80.47%] [G loss: 1.266146]\n",
      "epoch:29 step:27750 [D loss: 0.491185, acc.: 80.47%] [G loss: 1.195883]\n",
      "epoch:29 step:27751 [D loss: 0.436616, acc.: 84.38%] [G loss: 1.176517]\n",
      "epoch:29 step:27752 [D loss: 0.536551, acc.: 70.31%] [G loss: 1.346624]\n",
      "epoch:29 step:27753 [D loss: 0.784737, acc.: 50.78%] [G loss: 1.356980]\n",
      "epoch:29 step:27754 [D loss: 0.689932, acc.: 57.03%] [G loss: 1.164282]\n",
      "epoch:29 step:27755 [D loss: 0.669738, acc.: 57.03%] [G loss: 1.190073]\n",
      "epoch:29 step:27756 [D loss: 0.508021, acc.: 77.34%] [G loss: 0.919314]\n",
      "epoch:29 step:27757 [D loss: 0.860398, acc.: 39.84%] [G loss: 0.861896]\n",
      "epoch:29 step:27758 [D loss: 0.622573, acc.: 66.41%] [G loss: 1.098591]\n",
      "epoch:29 step:27759 [D loss: 0.654997, acc.: 61.72%] [G loss: 1.132147]\n",
      "epoch:29 step:27760 [D loss: 0.570252, acc.: 64.84%] [G loss: 0.809033]\n",
      "epoch:29 step:27761 [D loss: 0.244108, acc.: 95.31%] [G loss: 1.812163]\n",
      "epoch:29 step:27762 [D loss: 0.421004, acc.: 85.94%] [G loss: 1.664831]\n",
      "epoch:29 step:27763 [D loss: 0.702596, acc.: 53.12%] [G loss: 1.493466]\n",
      "epoch:29 step:27764 [D loss: 0.816972, acc.: 43.75%] [G loss: 1.167397]\n",
      "epoch:29 step:27765 [D loss: 0.399147, acc.: 90.62%] [G loss: 1.713782]\n",
      "epoch:29 step:27766 [D loss: 0.754052, acc.: 47.66%] [G loss: 1.265082]\n",
      "epoch:29 step:27767 [D loss: 0.644035, acc.: 67.97%] [G loss: 1.103256]\n",
      "epoch:29 step:27768 [D loss: 0.974857, acc.: 25.78%] [G loss: 0.904972]\n",
      "epoch:29 step:27769 [D loss: 0.425181, acc.: 85.94%] [G loss: 1.305957]\n",
      "epoch:29 step:27770 [D loss: 0.324336, acc.: 96.09%] [G loss: 1.527964]\n",
      "epoch:29 step:27771 [D loss: 0.268997, acc.: 92.19%] [G loss: 1.061015]\n",
      "epoch:29 step:27772 [D loss: 0.598724, acc.: 64.84%] [G loss: 1.335221]\n",
      "epoch:29 step:27773 [D loss: 0.635039, acc.: 60.94%] [G loss: 1.421477]\n",
      "epoch:29 step:27774 [D loss: 0.732874, acc.: 55.47%] [G loss: 1.071071]\n",
      "epoch:29 step:27775 [D loss: 0.659526, acc.: 63.28%] [G loss: 1.169721]\n",
      "epoch:29 step:27776 [D loss: 0.309376, acc.: 94.53%] [G loss: 1.354660]\n",
      "epoch:29 step:27777 [D loss: 0.258166, acc.: 93.75%] [G loss: 1.252989]\n",
      "epoch:29 step:27778 [D loss: 0.361436, acc.: 92.97%] [G loss: 1.386585]\n",
      "epoch:29 step:27779 [D loss: 0.707225, acc.: 55.47%] [G loss: 1.085456]\n",
      "epoch:29 step:27780 [D loss: 0.808041, acc.: 42.97%] [G loss: 0.944539]\n",
      "epoch:29 step:27781 [D loss: 0.727753, acc.: 54.69%] [G loss: 0.995689]\n",
      "epoch:29 step:27782 [D loss: 0.578245, acc.: 71.09%] [G loss: 0.933805]\n",
      "epoch:29 step:27783 [D loss: 0.718473, acc.: 55.47%] [G loss: 0.704397]\n",
      "epoch:29 step:27784 [D loss: 0.867950, acc.: 38.28%] [G loss: 0.915231]\n",
      "epoch:29 step:27785 [D loss: 0.830713, acc.: 44.53%] [G loss: 1.099533]\n",
      "epoch:29 step:27786 [D loss: 0.517001, acc.: 77.34%] [G loss: 0.897720]\n",
      "epoch:29 step:27787 [D loss: 0.313393, acc.: 94.53%] [G loss: 1.510293]\n",
      "epoch:29 step:27788 [D loss: 0.358332, acc.: 90.62%] [G loss: 1.247205]\n",
      "epoch:29 step:27789 [D loss: 0.222290, acc.: 98.44%] [G loss: 1.653850]\n",
      "epoch:29 step:27790 [D loss: 0.397638, acc.: 88.28%] [G loss: 1.579172]\n",
      "epoch:29 step:27791 [D loss: 0.855992, acc.: 45.31%] [G loss: 0.787176]\n",
      "epoch:29 step:27792 [D loss: 0.728556, acc.: 57.81%] [G loss: 1.365458]\n",
      "epoch:29 step:27793 [D loss: 0.898104, acc.: 32.03%] [G loss: 0.727677]\n",
      "epoch:29 step:27794 [D loss: 0.728057, acc.: 56.25%] [G loss: 0.996987]\n",
      "epoch:29 step:27795 [D loss: 0.572575, acc.: 66.41%] [G loss: 0.935128]\n",
      "epoch:29 step:27796 [D loss: 0.556952, acc.: 74.22%] [G loss: 1.055462]\n",
      "epoch:29 step:27797 [D loss: 0.473770, acc.: 81.25%] [G loss: 1.276154]\n",
      "epoch:29 step:27798 [D loss: 0.999840, acc.: 27.34%] [G loss: 0.602192]\n",
      "epoch:29 step:27799 [D loss: 0.734135, acc.: 57.03%] [G loss: 1.068164]\n",
      "epoch:29 step:27800 [D loss: 0.805444, acc.: 42.97%] [G loss: 1.116679]\n",
      "##############\n",
      "[2.47872973 1.50288127 5.51238695 4.4668482  3.05810023 5.43849998\n",
      " 4.21489788 4.5734085  3.99389412 3.90862939]\n",
      "##########\n",
      "epoch:29 step:27801 [D loss: 0.909349, acc.: 32.81%] [G loss: 0.706230]\n",
      "epoch:29 step:27802 [D loss: 0.593331, acc.: 57.81%] [G loss: 0.790755]\n",
      "epoch:29 step:27803 [D loss: 0.382919, acc.: 85.94%] [G loss: 1.556309]\n",
      "epoch:29 step:27804 [D loss: 0.533301, acc.: 70.31%] [G loss: 1.342904]\n",
      "epoch:29 step:27805 [D loss: 0.592896, acc.: 64.84%] [G loss: 1.078874]\n",
      "epoch:29 step:27806 [D loss: 0.387054, acc.: 86.72%] [G loss: 1.013804]\n",
      "epoch:29 step:27807 [D loss: 0.502357, acc.: 82.81%] [G loss: 1.611236]\n",
      "epoch:29 step:27808 [D loss: 0.808342, acc.: 46.88%] [G loss: 0.873194]\n",
      "epoch:29 step:27809 [D loss: 1.021477, acc.: 21.88%] [G loss: 0.718854]\n",
      "epoch:29 step:27810 [D loss: 1.012831, acc.: 25.00%] [G loss: 0.950160]\n",
      "epoch:29 step:27811 [D loss: 0.599736, acc.: 67.19%] [G loss: 1.305193]\n",
      "epoch:29 step:27812 [D loss: 1.177854, acc.: 20.31%] [G loss: 0.917476]\n",
      "epoch:29 step:27813 [D loss: 0.418212, acc.: 85.94%] [G loss: 1.472923]\n",
      "epoch:29 step:27814 [D loss: 0.368418, acc.: 89.84%] [G loss: 1.731075]\n",
      "epoch:29 step:27815 [D loss: 0.307466, acc.: 93.75%] [G loss: 2.089552]\n",
      "epoch:29 step:27816 [D loss: 0.828890, acc.: 53.91%] [G loss: 1.921675]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27817 [D loss: 0.690202, acc.: 60.94%] [G loss: 1.277336]\n",
      "epoch:29 step:27818 [D loss: 0.564049, acc.: 74.22%] [G loss: 1.007800]\n",
      "epoch:29 step:27819 [D loss: 0.399687, acc.: 83.59%] [G loss: 1.306657]\n",
      "epoch:29 step:27820 [D loss: 0.343507, acc.: 89.84%] [G loss: 1.288900]\n",
      "epoch:29 step:27821 [D loss: 0.650845, acc.: 60.16%] [G loss: 1.035024]\n",
      "epoch:29 step:27822 [D loss: 0.407113, acc.: 83.59%] [G loss: 1.517120]\n",
      "epoch:29 step:27823 [D loss: 0.444322, acc.: 82.81%] [G loss: 1.488487]\n",
      "epoch:29 step:27824 [D loss: 0.608612, acc.: 67.19%] [G loss: 1.123974]\n",
      "epoch:29 step:27825 [D loss: 0.680516, acc.: 60.16%] [G loss: 1.104404]\n",
      "epoch:29 step:27826 [D loss: 0.444631, acc.: 85.94%] [G loss: 1.386971]\n",
      "epoch:29 step:27827 [D loss: 0.461872, acc.: 83.59%] [G loss: 1.149473]\n",
      "epoch:29 step:27828 [D loss: 0.583396, acc.: 68.75%] [G loss: 1.243169]\n",
      "epoch:29 step:27829 [D loss: 0.567115, acc.: 72.66%] [G loss: 1.138445]\n",
      "epoch:29 step:27830 [D loss: 0.583514, acc.: 71.09%] [G loss: 1.514255]\n",
      "epoch:29 step:27831 [D loss: 0.466563, acc.: 78.91%] [G loss: 1.546497]\n",
      "epoch:29 step:27832 [D loss: 0.551443, acc.: 71.88%] [G loss: 1.493577]\n",
      "epoch:29 step:27833 [D loss: 0.568227, acc.: 67.19%] [G loss: 0.893009]\n",
      "epoch:29 step:27834 [D loss: 0.431144, acc.: 88.28%] [G loss: 1.228902]\n",
      "epoch:29 step:27835 [D loss: 0.324745, acc.: 90.62%] [G loss: 1.482853]\n",
      "epoch:29 step:27836 [D loss: 0.161316, acc.: 99.22%] [G loss: 1.601796]\n",
      "epoch:29 step:27837 [D loss: 0.215975, acc.: 96.09%] [G loss: 1.638790]\n",
      "epoch:29 step:27838 [D loss: 0.127341, acc.: 100.00%] [G loss: 1.886085]\n",
      "epoch:29 step:27839 [D loss: 0.202847, acc.: 97.66%] [G loss: 2.111477]\n",
      "epoch:29 step:27840 [D loss: 0.307761, acc.: 91.41%] [G loss: 1.736779]\n",
      "epoch:29 step:27841 [D loss: 0.526163, acc.: 67.97%] [G loss: 1.497347]\n",
      "epoch:29 step:27842 [D loss: 0.434476, acc.: 79.69%] [G loss: 1.304923]\n",
      "epoch:29 step:27843 [D loss: 0.512480, acc.: 71.88%] [G loss: 1.237704]\n",
      "epoch:29 step:27844 [D loss: 0.381870, acc.: 86.72%] [G loss: 1.325710]\n",
      "epoch:29 step:27845 [D loss: 0.574060, acc.: 68.75%] [G loss: 1.269595]\n",
      "epoch:29 step:27846 [D loss: 1.115907, acc.: 26.56%] [G loss: 0.727732]\n",
      "epoch:29 step:27847 [D loss: 0.878759, acc.: 40.62%] [G loss: 0.810746]\n",
      "epoch:29 step:27848 [D loss: 1.070980, acc.: 23.44%] [G loss: 0.738616]\n",
      "epoch:29 step:27849 [D loss: 0.677809, acc.: 64.06%] [G loss: 1.062958]\n",
      "epoch:29 step:27850 [D loss: 0.865299, acc.: 40.62%] [G loss: 1.052301]\n",
      "epoch:29 step:27851 [D loss: 0.950708, acc.: 31.25%] [G loss: 1.023686]\n",
      "epoch:29 step:27852 [D loss: 0.891952, acc.: 38.28%] [G loss: 0.916948]\n",
      "epoch:29 step:27853 [D loss: 0.636470, acc.: 60.16%] [G loss: 0.983070]\n",
      "epoch:29 step:27854 [D loss: 0.707413, acc.: 57.03%] [G loss: 1.059357]\n",
      "epoch:29 step:27855 [D loss: 0.725602, acc.: 59.38%] [G loss: 0.700351]\n",
      "epoch:29 step:27856 [D loss: 0.755342, acc.: 45.31%] [G loss: 0.770333]\n",
      "epoch:29 step:27857 [D loss: 0.894686, acc.: 35.16%] [G loss: 1.211007]\n",
      "epoch:29 step:27858 [D loss: 0.698339, acc.: 57.81%] [G loss: 0.772155]\n",
      "epoch:29 step:27859 [D loss: 1.070722, acc.: 24.22%] [G loss: 0.989214]\n",
      "epoch:29 step:27860 [D loss: 0.736679, acc.: 54.69%] [G loss: 1.209116]\n",
      "epoch:29 step:27861 [D loss: 0.685033, acc.: 58.59%] [G loss: 1.240594]\n",
      "epoch:29 step:27862 [D loss: 0.843283, acc.: 39.06%] [G loss: 1.091806]\n",
      "epoch:29 step:27863 [D loss: 0.608298, acc.: 68.75%] [G loss: 1.203325]\n",
      "epoch:29 step:27864 [D loss: 0.372823, acc.: 89.06%] [G loss: 1.344880]\n",
      "epoch:29 step:27865 [D loss: 0.414783, acc.: 83.59%] [G loss: 1.504536]\n",
      "epoch:29 step:27866 [D loss: 0.434443, acc.: 83.59%] [G loss: 1.933195]\n",
      "epoch:29 step:27867 [D loss: 0.169618, acc.: 98.44%] [G loss: 2.074785]\n",
      "epoch:29 step:27868 [D loss: 0.537336, acc.: 74.22%] [G loss: 1.405444]\n",
      "epoch:29 step:27869 [D loss: 1.040776, acc.: 32.81%] [G loss: 0.945520]\n",
      "epoch:29 step:27870 [D loss: 1.029619, acc.: 39.06%] [G loss: 0.953050]\n",
      "epoch:29 step:27871 [D loss: 0.798993, acc.: 39.84%] [G loss: 1.069464]\n",
      "epoch:29 step:27872 [D loss: 0.821368, acc.: 44.53%] [G loss: 1.161771]\n",
      "epoch:29 step:27873 [D loss: 0.588300, acc.: 67.19%] [G loss: 1.360102]\n",
      "epoch:29 step:27874 [D loss: 0.569349, acc.: 67.97%] [G loss: 0.874958]\n",
      "epoch:29 step:27875 [D loss: 0.700183, acc.: 53.91%] [G loss: 1.063918]\n",
      "epoch:29 step:27876 [D loss: 0.544634, acc.: 73.44%] [G loss: 1.186957]\n",
      "epoch:29 step:27877 [D loss: 0.595615, acc.: 73.44%] [G loss: 1.330447]\n",
      "epoch:29 step:27878 [D loss: 0.630806, acc.: 62.50%] [G loss: 1.063320]\n",
      "epoch:29 step:27879 [D loss: 0.537815, acc.: 75.00%] [G loss: 1.218006]\n",
      "epoch:29 step:27880 [D loss: 0.334214, acc.: 92.19%] [G loss: 1.437631]\n",
      "epoch:29 step:27881 [D loss: 0.372912, acc.: 87.50%] [G loss: 1.382309]\n",
      "epoch:29 step:27882 [D loss: 0.443276, acc.: 78.91%] [G loss: 1.264562]\n",
      "epoch:29 step:27883 [D loss: 0.675413, acc.: 58.59%] [G loss: 1.570259]\n",
      "epoch:29 step:27884 [D loss: 0.738013, acc.: 55.47%] [G loss: 1.320759]\n",
      "epoch:29 step:27885 [D loss: 0.637146, acc.: 62.50%] [G loss: 1.175736]\n",
      "epoch:29 step:27886 [D loss: 0.432641, acc.: 81.25%] [G loss: 1.107893]\n",
      "epoch:29 step:27887 [D loss: 0.497016, acc.: 82.81%] [G loss: 1.309672]\n",
      "epoch:29 step:27888 [D loss: 0.849953, acc.: 42.97%] [G loss: 1.365016]\n",
      "epoch:29 step:27889 [D loss: 0.724426, acc.: 56.25%] [G loss: 1.175907]\n",
      "epoch:29 step:27890 [D loss: 0.605835, acc.: 65.62%] [G loss: 1.021672]\n",
      "epoch:29 step:27891 [D loss: 0.537969, acc.: 75.00%] [G loss: 1.031459]\n",
      "epoch:29 step:27892 [D loss: 0.455019, acc.: 84.38%] [G loss: 1.003567]\n",
      "epoch:29 step:27893 [D loss: 0.310470, acc.: 90.62%] [G loss: 1.344096]\n",
      "epoch:29 step:27894 [D loss: 0.370461, acc.: 89.06%] [G loss: 1.514453]\n",
      "epoch:29 step:27895 [D loss: 0.766683, acc.: 50.78%] [G loss: 1.141555]\n",
      "epoch:29 step:27896 [D loss: 0.469833, acc.: 79.69%] [G loss: 1.033609]\n",
      "epoch:29 step:27897 [D loss: 0.200234, acc.: 96.88%] [G loss: 1.804838]\n",
      "epoch:29 step:27898 [D loss: 0.251084, acc.: 97.66%] [G loss: 1.907119]\n",
      "epoch:29 step:27899 [D loss: 0.337410, acc.: 95.31%] [G loss: 1.246734]\n",
      "epoch:29 step:27900 [D loss: 0.535912, acc.: 71.88%] [G loss: 1.317817]\n",
      "epoch:29 step:27901 [D loss: 0.566361, acc.: 70.31%] [G loss: 1.328669]\n",
      "epoch:29 step:27902 [D loss: 0.786018, acc.: 49.22%] [G loss: 1.124453]\n",
      "epoch:29 step:27903 [D loss: 0.550393, acc.: 75.00%] [G loss: 1.267948]\n",
      "epoch:29 step:27904 [D loss: 0.441580, acc.: 85.16%] [G loss: 1.210875]\n",
      "epoch:29 step:27905 [D loss: 0.314956, acc.: 92.97%] [G loss: 1.573269]\n",
      "epoch:29 step:27906 [D loss: 0.348116, acc.: 90.62%] [G loss: 1.425952]\n",
      "epoch:29 step:27907 [D loss: 0.799617, acc.: 41.41%] [G loss: 1.194234]\n",
      "epoch:29 step:27908 [D loss: 0.630120, acc.: 63.28%] [G loss: 1.030752]\n",
      "epoch:29 step:27909 [D loss: 0.511168, acc.: 78.12%] [G loss: 1.128437]\n",
      "epoch:29 step:27910 [D loss: 0.568979, acc.: 65.62%] [G loss: 1.302812]\n",
      "epoch:29 step:27911 [D loss: 0.762673, acc.: 53.12%] [G loss: 0.891225]\n",
      "epoch:29 step:27912 [D loss: 0.806766, acc.: 42.19%] [G loss: 0.861551]\n",
      "epoch:29 step:27913 [D loss: 0.803096, acc.: 46.09%] [G loss: 0.727020]\n",
      "epoch:29 step:27914 [D loss: 0.321265, acc.: 90.62%] [G loss: 1.265977]\n",
      "epoch:29 step:27915 [D loss: 0.306717, acc.: 96.88%] [G loss: 1.554634]\n",
      "epoch:29 step:27916 [D loss: 0.273080, acc.: 96.09%] [G loss: 1.508622]\n",
      "epoch:29 step:27917 [D loss: 0.803261, acc.: 50.78%] [G loss: 1.385503]\n",
      "epoch:29 step:27918 [D loss: 0.423608, acc.: 85.16%] [G loss: 1.341405]\n",
      "epoch:29 step:27919 [D loss: 0.587885, acc.: 66.41%] [G loss: 0.956548]\n",
      "epoch:29 step:27920 [D loss: 0.476091, acc.: 79.69%] [G loss: 1.289935]\n",
      "epoch:29 step:27921 [D loss: 0.678479, acc.: 60.16%] [G loss: 0.955025]\n",
      "epoch:29 step:27922 [D loss: 0.547486, acc.: 71.09%] [G loss: 1.083334]\n",
      "epoch:29 step:27923 [D loss: 0.398506, acc.: 89.06%] [G loss: 1.395824]\n",
      "epoch:29 step:27924 [D loss: 0.635469, acc.: 57.03%] [G loss: 1.084895]\n",
      "epoch:29 step:27925 [D loss: 0.633086, acc.: 64.06%] [G loss: 0.943526]\n",
      "epoch:29 step:27926 [D loss: 0.622505, acc.: 67.19%] [G loss: 0.927248]\n",
      "epoch:29 step:27927 [D loss: 0.708699, acc.: 50.00%] [G loss: 0.876459]\n",
      "epoch:29 step:27928 [D loss: 0.402627, acc.: 85.94%] [G loss: 1.237765]\n",
      "epoch:29 step:27929 [D loss: 0.590605, acc.: 67.97%] [G loss: 1.080595]\n",
      "epoch:29 step:27930 [D loss: 0.508197, acc.: 78.12%] [G loss: 1.404061]\n",
      "epoch:29 step:27931 [D loss: 0.572346, acc.: 71.09%] [G loss: 1.188509]\n",
      "epoch:29 step:27932 [D loss: 0.613407, acc.: 60.94%] [G loss: 1.004460]\n",
      "epoch:29 step:27933 [D loss: 0.558448, acc.: 72.66%] [G loss: 1.094066]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27934 [D loss: 0.663584, acc.: 59.38%] [G loss: 1.246855]\n",
      "epoch:29 step:27935 [D loss: 0.666421, acc.: 65.62%] [G loss: 0.998058]\n",
      "epoch:29 step:27936 [D loss: 0.508755, acc.: 73.44%] [G loss: 0.891932]\n",
      "epoch:29 step:27937 [D loss: 0.648696, acc.: 60.16%] [G loss: 1.189983]\n",
      "epoch:29 step:27938 [D loss: 0.763799, acc.: 53.12%] [G loss: 1.612257]\n",
      "epoch:29 step:27939 [D loss: 0.621532, acc.: 68.75%] [G loss: 1.352158]\n",
      "epoch:29 step:27940 [D loss: 0.376905, acc.: 89.84%] [G loss: 1.730032]\n",
      "epoch:29 step:27941 [D loss: 0.245180, acc.: 95.31%] [G loss: 1.564081]\n",
      "epoch:29 step:27942 [D loss: 0.291458, acc.: 89.06%] [G loss: 1.740634]\n",
      "epoch:29 step:27943 [D loss: 0.337901, acc.: 92.19%] [G loss: 1.775219]\n",
      "epoch:29 step:27944 [D loss: 0.762934, acc.: 54.69%] [G loss: 1.325857]\n",
      "epoch:29 step:27945 [D loss: 0.775800, acc.: 49.22%] [G loss: 0.917859]\n",
      "epoch:29 step:27946 [D loss: 0.345928, acc.: 94.53%] [G loss: 1.426506]\n",
      "epoch:29 step:27947 [D loss: 0.267536, acc.: 90.62%] [G loss: 1.435744]\n",
      "epoch:29 step:27948 [D loss: 0.224944, acc.: 95.31%] [G loss: 1.790779]\n",
      "epoch:29 step:27949 [D loss: 0.327754, acc.: 89.84%] [G loss: 1.474549]\n",
      "epoch:29 step:27950 [D loss: 0.439791, acc.: 85.16%] [G loss: 1.466609]\n",
      "epoch:29 step:27951 [D loss: 0.671560, acc.: 61.72%] [G loss: 1.286600]\n",
      "epoch:29 step:27952 [D loss: 1.035985, acc.: 26.56%] [G loss: 0.827864]\n",
      "epoch:29 step:27953 [D loss: 0.600223, acc.: 66.41%] [G loss: 1.017215]\n",
      "epoch:29 step:27954 [D loss: 0.421120, acc.: 87.50%] [G loss: 1.380292]\n",
      "epoch:29 step:27955 [D loss: 0.368279, acc.: 90.62%] [G loss: 1.616482]\n",
      "epoch:29 step:27956 [D loss: 0.799916, acc.: 40.62%] [G loss: 1.420624]\n",
      "epoch:29 step:27957 [D loss: 0.762658, acc.: 47.66%] [G loss: 1.174883]\n",
      "epoch:29 step:27958 [D loss: 0.497040, acc.: 81.25%] [G loss: 1.453444]\n",
      "epoch:29 step:27959 [D loss: 0.323395, acc.: 93.75%] [G loss: 1.434583]\n",
      "epoch:29 step:27960 [D loss: 0.596365, acc.: 65.62%] [G loss: 1.095488]\n",
      "epoch:29 step:27961 [D loss: 0.615899, acc.: 66.41%] [G loss: 1.106152]\n",
      "epoch:29 step:27962 [D loss: 0.478808, acc.: 81.25%] [G loss: 0.997970]\n",
      "epoch:29 step:27963 [D loss: 0.361751, acc.: 87.50%] [G loss: 0.875514]\n",
      "epoch:29 step:27964 [D loss: 0.176761, acc.: 98.44%] [G loss: 1.657233]\n",
      "epoch:29 step:27965 [D loss: 0.175503, acc.: 97.66%] [G loss: 1.643417]\n",
      "epoch:29 step:27966 [D loss: 0.189702, acc.: 97.66%] [G loss: 1.907243]\n",
      "epoch:29 step:27967 [D loss: 0.231226, acc.: 94.53%] [G loss: 1.815622]\n",
      "epoch:29 step:27968 [D loss: 0.359469, acc.: 91.41%] [G loss: 1.836781]\n",
      "epoch:29 step:27969 [D loss: 0.491573, acc.: 78.12%] [G loss: 1.416747]\n",
      "epoch:29 step:27970 [D loss: 0.805435, acc.: 46.09%] [G loss: 0.765694]\n",
      "epoch:29 step:27971 [D loss: 0.518468, acc.: 74.22%] [G loss: 1.684533]\n",
      "epoch:29 step:27972 [D loss: 0.585652, acc.: 67.97%] [G loss: 1.183475]\n",
      "epoch:29 step:27973 [D loss: 0.823636, acc.: 46.09%] [G loss: 1.201131]\n",
      "epoch:29 step:27974 [D loss: 0.669840, acc.: 57.03%] [G loss: 1.159565]\n",
      "epoch:29 step:27975 [D loss: 0.685755, acc.: 57.81%] [G loss: 1.240880]\n",
      "epoch:29 step:27976 [D loss: 0.667530, acc.: 56.25%] [G loss: 1.052810]\n",
      "epoch:29 step:27977 [D loss: 0.367523, acc.: 89.84%] [G loss: 1.063775]\n",
      "epoch:29 step:27978 [D loss: 0.292049, acc.: 96.09%] [G loss: 1.275402]\n",
      "epoch:29 step:27979 [D loss: 0.208148, acc.: 97.66%] [G loss: 1.258926]\n",
      "epoch:29 step:27980 [D loss: 0.698275, acc.: 56.25%] [G loss: 1.493058]\n",
      "epoch:29 step:27981 [D loss: 0.533343, acc.: 74.22%] [G loss: 1.038345]\n",
      "epoch:29 step:27982 [D loss: 0.667422, acc.: 60.94%] [G loss: 1.038031]\n",
      "epoch:29 step:27983 [D loss: 0.594116, acc.: 71.88%] [G loss: 1.130725]\n",
      "epoch:29 step:27984 [D loss: 0.792922, acc.: 49.22%] [G loss: 1.217546]\n",
      "epoch:29 step:27985 [D loss: 0.628956, acc.: 62.50%] [G loss: 1.138420]\n",
      "epoch:29 step:27986 [D loss: 0.551626, acc.: 71.88%] [G loss: 1.062581]\n",
      "epoch:29 step:27987 [D loss: 0.440023, acc.: 86.72%] [G loss: 1.171740]\n",
      "epoch:29 step:27988 [D loss: 0.237204, acc.: 94.53%] [G loss: 1.783833]\n",
      "epoch:29 step:27989 [D loss: 0.219988, acc.: 96.88%] [G loss: 1.599594]\n",
      "epoch:29 step:27990 [D loss: 0.303045, acc.: 91.41%] [G loss: 1.403718]\n",
      "epoch:29 step:27991 [D loss: 0.448119, acc.: 83.59%] [G loss: 1.517881]\n",
      "epoch:29 step:27992 [D loss: 0.362330, acc.: 89.84%] [G loss: 1.596596]\n",
      "epoch:29 step:27993 [D loss: 0.673585, acc.: 57.03%] [G loss: 1.298606]\n",
      "epoch:29 step:27994 [D loss: 0.730804, acc.: 52.34%] [G loss: 0.799712]\n",
      "epoch:29 step:27995 [D loss: 0.646367, acc.: 61.72%] [G loss: 0.923813]\n",
      "epoch:29 step:27996 [D loss: 0.586273, acc.: 65.62%] [G loss: 0.803430]\n",
      "epoch:29 step:27997 [D loss: 0.255201, acc.: 96.88%] [G loss: 1.797126]\n",
      "epoch:29 step:27998 [D loss: 0.205960, acc.: 96.88%] [G loss: 1.738755]\n",
      "epoch:29 step:27999 [D loss: 0.617575, acc.: 68.75%] [G loss: 0.894539]\n",
      "epoch:29 step:28000 [D loss: 0.754683, acc.: 50.00%] [G loss: 1.027729]\n",
      "##############\n",
      "[2.6341556  1.7164188  5.83017326 4.43124978 3.21563646 5.60326534\n",
      " 4.3067094  4.73557246 4.3209984  3.86840811]\n",
      "##########\n",
      "epoch:29 step:28001 [D loss: 0.550966, acc.: 79.69%] [G loss: 1.407909]\n",
      "epoch:29 step:28002 [D loss: 0.598621, acc.: 67.97%] [G loss: 1.213273]\n",
      "epoch:29 step:28003 [D loss: 0.344847, acc.: 88.28%] [G loss: 1.365999]\n",
      "epoch:29 step:28004 [D loss: 0.592299, acc.: 62.50%] [G loss: 1.215168]\n",
      "epoch:29 step:28005 [D loss: 0.235524, acc.: 96.88%] [G loss: 2.184873]\n",
      "epoch:29 step:28006 [D loss: 0.496922, acc.: 79.69%] [G loss: 1.391221]\n",
      "epoch:29 step:28007 [D loss: 1.140624, acc.: 50.00%] [G loss: 1.442567]\n",
      "epoch:29 step:28008 [D loss: 1.123018, acc.: 26.56%] [G loss: 0.947553]\n",
      "epoch:29 step:28009 [D loss: 0.736950, acc.: 54.69%] [G loss: 1.364732]\n",
      "epoch:29 step:28010 [D loss: 0.642071, acc.: 62.50%] [G loss: 1.092214]\n",
      "epoch:29 step:28011 [D loss: 0.505323, acc.: 76.56%] [G loss: 1.080455]\n",
      "epoch:29 step:28012 [D loss: 0.759854, acc.: 54.69%] [G loss: 1.254355]\n",
      "epoch:29 step:28013 [D loss: 0.485739, acc.: 83.59%] [G loss: 1.118567]\n",
      "epoch:29 step:28014 [D loss: 0.355774, acc.: 91.41%] [G loss: 1.337979]\n",
      "epoch:29 step:28015 [D loss: 0.384117, acc.: 86.72%] [G loss: 1.674205]\n",
      "epoch:29 step:28016 [D loss: 0.820761, acc.: 49.22%] [G loss: 1.374453]\n",
      "epoch:29 step:28017 [D loss: 0.704513, acc.: 56.25%] [G loss: 1.120126]\n",
      "epoch:29 step:28018 [D loss: 0.596079, acc.: 69.53%] [G loss: 1.065555]\n",
      "epoch:29 step:28019 [D loss: 0.532620, acc.: 77.34%] [G loss: 1.043175]\n",
      "epoch:29 step:28020 [D loss: 0.414166, acc.: 85.16%] [G loss: 1.310636]\n",
      "epoch:29 step:28021 [D loss: 0.552006, acc.: 71.09%] [G loss: 0.929774]\n",
      "epoch:29 step:28022 [D loss: 0.270508, acc.: 96.88%] [G loss: 1.546935]\n",
      "epoch:29 step:28023 [D loss: 0.324203, acc.: 89.06%] [G loss: 1.499016]\n",
      "epoch:29 step:28024 [D loss: 0.178674, acc.: 100.00%] [G loss: 1.860222]\n",
      "epoch:29 step:28025 [D loss: 0.182742, acc.: 98.44%] [G loss: 1.937067]\n",
      "epoch:29 step:28026 [D loss: 0.169677, acc.: 100.00%] [G loss: 2.090101]\n",
      "epoch:29 step:28027 [D loss: 0.371210, acc.: 83.59%] [G loss: 1.313253]\n",
      "epoch:29 step:28028 [D loss: 0.428616, acc.: 78.91%] [G loss: 1.913427]\n",
      "epoch:29 step:28029 [D loss: 0.480636, acc.: 80.47%] [G loss: 1.486896]\n",
      "epoch:29 step:28030 [D loss: 0.371175, acc.: 89.84%] [G loss: 1.551204]\n",
      "epoch:29 step:28031 [D loss: 0.462665, acc.: 82.03%] [G loss: 1.702661]\n",
      "epoch:29 step:28032 [D loss: 0.517485, acc.: 78.91%] [G loss: 1.299498]\n",
      "epoch:29 step:28033 [D loss: 0.498102, acc.: 80.47%] [G loss: 1.313177]\n",
      "epoch:29 step:28034 [D loss: 0.512624, acc.: 77.34%] [G loss: 1.393690]\n",
      "epoch:29 step:28035 [D loss: 0.787397, acc.: 46.88%] [G loss: 0.786327]\n",
      "epoch:29 step:28036 [D loss: 0.823741, acc.: 39.84%] [G loss: 1.304838]\n",
      "epoch:29 step:28037 [D loss: 0.734811, acc.: 53.12%] [G loss: 1.166226]\n",
      "epoch:29 step:28038 [D loss: 0.596218, acc.: 65.62%] [G loss: 0.948163]\n",
      "epoch:29 step:28039 [D loss: 0.794966, acc.: 47.66%] [G loss: 0.927273]\n",
      "epoch:29 step:28040 [D loss: 0.611782, acc.: 67.97%] [G loss: 1.372328]\n",
      "epoch:29 step:28041 [D loss: 0.630670, acc.: 60.16%] [G loss: 0.977791]\n",
      "epoch:29 step:28042 [D loss: 0.363912, acc.: 85.94%] [G loss: 1.415836]\n",
      "epoch:29 step:28043 [D loss: 0.675627, acc.: 56.25%] [G loss: 1.316012]\n",
      "epoch:29 step:28044 [D loss: 0.396238, acc.: 88.28%] [G loss: 1.317331]\n",
      "epoch:29 step:28045 [D loss: 0.384952, acc.: 86.72%] [G loss: 1.087356]\n",
      "epoch:29 step:28046 [D loss: 0.413843, acc.: 89.06%] [G loss: 1.130916]\n",
      "epoch:29 step:28047 [D loss: 0.590821, acc.: 69.53%] [G loss: 1.018431]\n",
      "epoch:29 step:28048 [D loss: 0.375254, acc.: 86.72%] [G loss: 1.401071]\n",
      "epoch:29 step:28049 [D loss: 0.666480, acc.: 64.06%] [G loss: 1.093834]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:28050 [D loss: 0.888938, acc.: 39.06%] [G loss: 0.860775]\n",
      "epoch:29 step:28051 [D loss: 0.765020, acc.: 50.78%] [G loss: 1.057114]\n",
      "epoch:29 step:28052 [D loss: 0.633097, acc.: 63.28%] [G loss: 1.774445]\n",
      "epoch:29 step:28053 [D loss: 0.523498, acc.: 78.12%] [G loss: 1.061970]\n",
      "epoch:29 step:28054 [D loss: 0.600184, acc.: 66.41%] [G loss: 1.144270]\n",
      "epoch:29 step:28055 [D loss: 0.583296, acc.: 67.97%] [G loss: 0.783142]\n",
      "epoch:29 step:28056 [D loss: 0.406513, acc.: 85.94%] [G loss: 1.533758]\n",
      "epoch:29 step:28057 [D loss: 0.429918, acc.: 78.12%] [G loss: 1.450818]\n",
      "epoch:29 step:28058 [D loss: 0.312818, acc.: 89.84%] [G loss: 1.656180]\n",
      "epoch:29 step:28059 [D loss: 0.481366, acc.: 78.91%] [G loss: 1.757542]\n",
      "epoch:29 step:28060 [D loss: 0.300144, acc.: 93.75%] [G loss: 1.636974]\n",
      "epoch:29 step:28061 [D loss: 0.785990, acc.: 45.31%] [G loss: 1.204800]\n",
      "epoch:29 step:28062 [D loss: 0.416392, acc.: 82.03%] [G loss: 1.480414]\n",
      "epoch:29 step:28063 [D loss: 0.674656, acc.: 62.50%] [G loss: 1.162367]\n",
      "epoch:29 step:28064 [D loss: 1.199152, acc.: 41.41%] [G loss: 1.762587]\n",
      "epoch:29 step:28065 [D loss: 0.682564, acc.: 54.69%] [G loss: 1.490450]\n",
      "epoch:29 step:28066 [D loss: 0.450829, acc.: 83.59%] [G loss: 1.533612]\n",
      "epoch:29 step:28067 [D loss: 0.246103, acc.: 96.09%] [G loss: 1.924696]\n",
      "epoch:29 step:28068 [D loss: 0.367517, acc.: 89.06%] [G loss: 1.704042]\n",
      "epoch:29 step:28069 [D loss: 0.217509, acc.: 98.44%] [G loss: 2.113002]\n",
      "epoch:29 step:28070 [D loss: 0.185783, acc.: 98.44%] [G loss: 2.046655]\n",
      "epoch:29 step:28071 [D loss: 0.155599, acc.: 98.44%] [G loss: 1.904308]\n",
      "epoch:29 step:28072 [D loss: 0.137017, acc.: 98.44%] [G loss: 2.300285]\n",
      "epoch:29 step:28073 [D loss: 0.107305, acc.: 99.22%] [G loss: 2.456965]\n",
      "epoch:29 step:28074 [D loss: 0.152168, acc.: 97.66%] [G loss: 2.539452]\n",
      "epoch:29 step:28075 [D loss: 0.334563, acc.: 86.72%] [G loss: 2.093359]\n",
      "epoch:29 step:28076 [D loss: 0.177768, acc.: 97.66%] [G loss: 2.286050]\n",
      "epoch:29 step:28077 [D loss: 0.727475, acc.: 57.81%] [G loss: 1.760576]\n",
      "epoch:29 step:28078 [D loss: 0.422453, acc.: 85.16%] [G loss: 1.444282]\n",
      "epoch:29 step:28079 [D loss: 0.598237, acc.: 71.09%] [G loss: 1.269563]\n",
      "epoch:29 step:28080 [D loss: 0.264684, acc.: 98.44%] [G loss: 1.713094]\n",
      "epoch:29 step:28081 [D loss: 0.447196, acc.: 74.22%] [G loss: 1.485553]\n",
      "epoch:29 step:28082 [D loss: 0.124687, acc.: 99.22%] [G loss: 1.947709]\n",
      "epoch:29 step:28083 [D loss: 0.296253, acc.: 95.31%] [G loss: 1.934709]\n",
      "epoch:29 step:28084 [D loss: 0.103725, acc.: 99.22%] [G loss: 1.914778]\n",
      "epoch:29 step:28085 [D loss: 0.115491, acc.: 98.44%] [G loss: 2.095956]\n",
      "epoch:29 step:28086 [D loss: 0.298777, acc.: 96.88%] [G loss: 2.107616]\n",
      "epoch:29 step:28087 [D loss: 0.372450, acc.: 91.41%] [G loss: 1.974679]\n",
      "epoch:29 step:28088 [D loss: 0.200971, acc.: 96.88%] [G loss: 1.483514]\n",
      "epoch:29 step:28089 [D loss: 0.305995, acc.: 93.75%] [G loss: 1.535074]\n",
      "epoch:29 step:28090 [D loss: 0.514003, acc.: 80.47%] [G loss: 1.490489]\n",
      "epoch:29 step:28091 [D loss: 0.205414, acc.: 96.09%] [G loss: 1.598367]\n",
      "epoch:29 step:28092 [D loss: 0.159820, acc.: 96.88%] [G loss: 1.527563]\n",
      "epoch:29 step:28093 [D loss: 1.359960, acc.: 40.62%] [G loss: 1.296620]\n",
      "epoch:29 step:28094 [D loss: 0.823358, acc.: 51.56%] [G loss: 1.427034]\n",
      "epoch:29 step:28095 [D loss: 0.284315, acc.: 93.75%] [G loss: 1.560001]\n",
      "epoch:29 step:28096 [D loss: 0.176870, acc.: 100.00%] [G loss: 2.089844]\n",
      "epoch:29 step:28097 [D loss: 0.275154, acc.: 92.19%] [G loss: 1.482965]\n",
      "epoch:29 step:28098 [D loss: 0.199676, acc.: 99.22%] [G loss: 2.306716]\n",
      "epoch:29 step:28099 [D loss: 0.151894, acc.: 99.22%] [G loss: 1.643688]\n",
      "epoch:29 step:28100 [D loss: 0.107146, acc.: 100.00%] [G loss: 2.193786]\n",
      "epoch:29 step:28101 [D loss: 1.062780, acc.: 39.84%] [G loss: 1.282138]\n",
      "epoch:29 step:28102 [D loss: 0.572201, acc.: 70.31%] [G loss: 1.574568]\n",
      "epoch:29 step:28103 [D loss: 0.784958, acc.: 44.53%] [G loss: 1.288445]\n",
      "epoch:29 step:28104 [D loss: 0.678872, acc.: 57.03%] [G loss: 1.027711]\n",
      "epoch:29 step:28105 [D loss: 0.672831, acc.: 60.94%] [G loss: 0.992673]\n",
      "epoch:29 step:28106 [D loss: 0.355322, acc.: 92.19%] [G loss: 1.714346]\n",
      "epoch:29 step:28107 [D loss: 0.185266, acc.: 98.44%] [G loss: 1.684262]\n",
      "epoch:29 step:28108 [D loss: 0.663353, acc.: 62.50%] [G loss: 1.275267]\n",
      "epoch:29 step:28109 [D loss: 0.266740, acc.: 95.31%] [G loss: 1.905820]\n",
      "epoch:29 step:28110 [D loss: 0.199344, acc.: 90.62%] [G loss: 1.723054]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if not os.path.isdir('saved_models_mnist_{}'.format('dcgan')):\n",
    "    os.mkdir('saved_models_mnist_{}'.format('dcgan'))\n",
    "f = open('saved_models_mnist_{}/log_collapse1.txt'.format('dcgan'), mode='w')\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "class DCGAN():\n",
    "    def __init__(self):\n",
    "        # Input shape\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "        self.x = []\n",
    "        self.y = np.zeros((31, 1), dtype=np.int)\n",
    "        self.y = list(self.y)\n",
    "        for i in range(31):\n",
    "            self.y[i] = []\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generates imgs\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(128 * 7 * 7, activation=\"relu\", input_dim=self.latent_dim))\n",
    "        model.add(Reshape((7, 7, 128)))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Activation(\"relu\"))\n",
    "        model.add(Conv2D(self.channels, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Conv2D(32, kernel_size=3, strides=2, input_shape=self.img_shape, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(ZeroPadding2D(padding=((0,1),(0,1))))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dropout(0.25))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, save_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, _), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = X_train / 127.5 - 1.\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "        X_test = (X_test.astype(np.float32) - 127.5) / 127.5\n",
    "        # X_test = X_test / 127.5 - 1.\n",
    "        X_test = np.expand_dims(X_test, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        nb_batches = int(X_train.shape[0] / batch_size)\n",
    "        global_step = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            for index in range(nb_batches):\n",
    "                global_step += 1\n",
    "                imgs = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "                # labels = y_train[index * batch_size:(index + 1) * batch_size]\n",
    "                # Sample noise and generate a batch of new images\n",
    "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "                gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "                # Train the discriminator (real classified as ones and generated as zeros)\n",
    "                d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "                d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Generator\n",
    "                # ---------------------\n",
    "\n",
    "                # Train the generator (wants discriminator to mistake images as real)\n",
    "                g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "                # Plot the progress\n",
    "                print(\"epoch:%d step:%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch,global_step, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "\n",
    "                sampleSize = 5000\n",
    "                # If at save interval => save generated image samples\n",
    "                if global_step % save_interval == 0:\n",
    "                    s = self.sample_images(global_step, X_test,y_test, sampleSize)\n",
    "    def sample_images(self, epoch,x_test,y_test,sample_num):\n",
    "        r, c = sample_num//10, 10\n",
    "        noise = np.random.normal(0, 1, (r * c, 100))\n",
    "#         sampled_labels = np.array([num for _ in range(r) for num in range(c)])\n",
    "        gen_imgs = self.generator.predict([noise])\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        labels = np.squeeze(y_test[:sample_num])\n",
    "        labels = np.squeeze(labels)\n",
    "        dis_real = cal_distance_image_real(x_test[:sample_num], labels)\n",
    "        dis_fake = cal_distance_image_fake(gen_imgs)\n",
    "        dis_cha = dis_real - dis_fake\n",
    "        print('##############')\n",
    "        # print(dis_real)\n",
    "        # print(dis_fake)\n",
    "        print(dis_cha)\n",
    "        print('##########')\n",
    "        f.writelines('\\n')\n",
    "        f.writelines('epoch:' + str(epoch))\n",
    "        f.writelines('\\n')\n",
    "        f.writelines('紧度')\n",
    "        f.writelines('\\n')\n",
    "        f.writelines(' %.8f ' % (i) for i in dis_cha)\n",
    "        f.writelines('\\n')\n",
    "if __name__ == '__main__':\n",
    "    dcgan = DCGAN()\n",
    "    dcgan.train(epochs=30, batch_size=64, save_interval=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pppppppp [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
