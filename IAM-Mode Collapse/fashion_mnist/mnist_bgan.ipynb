{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*-coding:utf-8-*-\n",
    "import util\n",
    "import tensorflow as tf\n",
    "MNIST_CLASSIFIER_FROZEN_GRAPH = './classify_mnist_graph_def.pb'\n",
    "INPUT_TENSOR = 'inputs:0'\n",
    "OUTPUT_TENSOR = 'logits:0'\n",
    "def EuclideanDistances(A, B):\n",
    "\n",
    "    BT = B.transpose()\n",
    "    # vecProd = A * BT\n",
    "    vecProd = np.dot(A, BT)\n",
    "    # print(vecProd)\n",
    "    SqA = A ** 2\n",
    "    # print(SqA)\n",
    "    sumSqA = np.matrix(np.sum(SqA, axis=1))\n",
    "    sumSqAEx = np.tile(sumSqA.transpose(), (1, vecProd.shape[1]))\n",
    "    # print(sumSqAEx)\n",
    "\n",
    "    SqB = B ** 2\n",
    "    sumSqB = np.sum(SqB, axis=1)\n",
    "    sumSqBEx = np.tile(sumSqB, (vecProd.shape[0], 1))\n",
    "    SqED = sumSqBEx + sumSqAEx - 2 * vecProd\n",
    "    SqED[SqED < 0] = 0.0\n",
    "    ED = np.sqrt(SqED)\n",
    "    return np.divide(ED.sum(),ED.shape[0]*ED.shape[1])\n",
    "def cal_distance_image_real(images,labels):\n",
    "    eval_images=tf.convert_to_tensor(images)\n",
    "    y_logits=util.mnist_logits(eval_images, MNIST_CLASSIFIER_FROZEN_GRAPH, INPUT_TENSOR, OUTPUT_TENSOR)\n",
    "    y_logits=tf.Session().run(y_logits)\n",
    "    dict={}\n",
    "    all_dis=[]\n",
    "    for i in range(10):\n",
    "        dict[i]=[]\n",
    "    for i in range(len(labels)):\n",
    "        dict[labels[i]].append(y_logits[i])\n",
    "    for i in range(10):\n",
    "        dict[i]=np.array(dict[i])\n",
    "        if len(dict[i]):\n",
    "            dis = EuclideanDistances(dict[i], dict[i])  # 生成图片的紧度\n",
    "        else:\n",
    "            dis = -1\n",
    "        all_dis.append(dis)\n",
    "    return np.array(all_dis)\n",
    "def cal_distance_image_fake(images):\n",
    "    eval_images=tf.convert_to_tensor(images)\n",
    "    y_logits=util.mnist_logits(eval_images, MNIST_CLASSIFIER_FROZEN_GRAPH, INPUT_TENSOR, OUTPUT_TENSOR)\n",
    "    y_logits=tf.Session().run(y_logits)\n",
    "    labels = tf.Session().run(tf.argmax(y_logits, 1))\n",
    "    dict={}\n",
    "    all_dis=[]\n",
    "    for i in range(10):\n",
    "        dict[i]=[]\n",
    "    for i in range(len(labels)):\n",
    "        dict[labels[i]].append(y_logits[i])\n",
    "    for i in range(10):\n",
    "        dict[i]=np.array(dict[i])\n",
    "        if len(dict[i]):\n",
    "            dis = EuclideanDistances(dict[i], dict[i])  # 生成图片的紧度\n",
    "        else:\n",
    "            dis = -1\n",
    "        all_dis.append(dis)\n",
    "    return np.array(all_dis)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 533,505\n",
      "Trainable params: 533,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 784)               803600    \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 1,493,520\n",
      "Trainable params: 1,489,936\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:1 [D loss: 0.449949, acc.: 53.91%] [G loss: 0.185739]\n",
      "epoch:0 step:2 [D loss: 0.454315, acc.: 62.50%] [G loss: 0.112001]\n",
      "epoch:0 step:3 [D loss: 0.350803, acc.: 78.91%] [G loss: 0.168612]\n",
      "epoch:0 step:4 [D loss: 0.225489, acc.: 99.22%] [G loss: 0.509961]\n",
      "epoch:0 step:5 [D loss: 0.178659, acc.: 99.22%] [G loss: 0.791281]\n",
      "epoch:0 step:6 [D loss: 0.166051, acc.: 99.22%] [G loss: 0.984321]\n",
      "epoch:0 step:7 [D loss: 0.139902, acc.: 99.22%] [G loss: 1.235713]\n",
      "epoch:0 step:8 [D loss: 0.118457, acc.: 100.00%] [G loss: 1.460355]\n",
      "epoch:0 step:9 [D loss: 0.117186, acc.: 100.00%] [G loss: 1.669372]\n",
      "epoch:0 step:10 [D loss: 0.100809, acc.: 100.00%] [G loss: 1.825359]\n",
      "epoch:0 step:11 [D loss: 0.084996, acc.: 100.00%] [G loss: 1.965951]\n",
      "epoch:0 step:12 [D loss: 0.088377, acc.: 100.00%] [G loss: 2.101921]\n",
      "epoch:0 step:13 [D loss: 0.087739, acc.: 100.00%] [G loss: 2.227346]\n",
      "epoch:0 step:14 [D loss: 0.070623, acc.: 100.00%] [G loss: 2.574449]\n",
      "epoch:0 step:15 [D loss: 0.065674, acc.: 100.00%] [G loss: 2.639516]\n",
      "epoch:0 step:16 [D loss: 0.062901, acc.: 100.00%] [G loss: 2.950792]\n",
      "epoch:0 step:17 [D loss: 0.063974, acc.: 100.00%] [G loss: 3.063475]\n",
      "epoch:0 step:18 [D loss: 0.054208, acc.: 100.00%] [G loss: 3.340304]\n",
      "epoch:0 step:19 [D loss: 0.049418, acc.: 100.00%] [G loss: 3.518086]\n",
      "epoch:0 step:20 [D loss: 0.050665, acc.: 100.00%] [G loss: 3.557327]\n",
      "epoch:0 step:21 [D loss: 0.044757, acc.: 100.00%] [G loss: 3.781214]\n",
      "epoch:0 step:22 [D loss: 0.047202, acc.: 100.00%] [G loss: 4.165014]\n",
      "epoch:0 step:23 [D loss: 0.039745, acc.: 100.00%] [G loss: 4.220149]\n",
      "epoch:0 step:24 [D loss: 0.037704, acc.: 100.00%] [G loss: 4.075791]\n",
      "epoch:0 step:25 [D loss: 0.034395, acc.: 100.00%] [G loss: 4.369173]\n",
      "epoch:0 step:26 [D loss: 0.033804, acc.: 100.00%] [G loss: 4.585352]\n",
      "epoch:0 step:27 [D loss: 0.031513, acc.: 100.00%] [G loss: 4.899374]\n",
      "epoch:0 step:28 [D loss: 0.031098, acc.: 100.00%] [G loss: 5.111146]\n",
      "epoch:0 step:29 [D loss: 0.025158, acc.: 100.00%] [G loss: 5.004888]\n",
      "epoch:0 step:30 [D loss: 0.026882, acc.: 100.00%] [G loss: 5.226436]\n",
      "epoch:0 step:31 [D loss: 0.029972, acc.: 100.00%] [G loss: 5.363880]\n",
      "epoch:0 step:32 [D loss: 0.026466, acc.: 100.00%] [G loss: 5.808047]\n",
      "epoch:0 step:33 [D loss: 0.023982, acc.: 100.00%] [G loss: 5.930937]\n",
      "epoch:0 step:34 [D loss: 0.024314, acc.: 100.00%] [G loss: 6.007685]\n",
      "epoch:0 step:35 [D loss: 0.020129, acc.: 100.00%] [G loss: 6.082568]\n",
      "epoch:0 step:36 [D loss: 0.021678, acc.: 100.00%] [G loss: 6.239847]\n",
      "epoch:0 step:37 [D loss: 0.022694, acc.: 100.00%] [G loss: 6.112301]\n",
      "epoch:0 step:38 [D loss: 0.022932, acc.: 100.00%] [G loss: 6.465033]\n",
      "epoch:0 step:39 [D loss: 0.020514, acc.: 100.00%] [G loss: 6.708050]\n",
      "epoch:0 step:40 [D loss: 0.020369, acc.: 100.00%] [G loss: 6.717309]\n",
      "epoch:0 step:41 [D loss: 0.017642, acc.: 100.00%] [G loss: 7.043009]\n",
      "epoch:0 step:42 [D loss: 0.018014, acc.: 100.00%] [G loss: 6.805697]\n",
      "epoch:0 step:43 [D loss: 0.019511, acc.: 100.00%] [G loss: 7.003064]\n",
      "epoch:0 step:44 [D loss: 0.020244, acc.: 100.00%] [G loss: 7.202793]\n",
      "epoch:0 step:45 [D loss: 0.018896, acc.: 100.00%] [G loss: 6.988610]\n",
      "epoch:0 step:46 [D loss: 0.016840, acc.: 100.00%] [G loss: 7.718639]\n",
      "epoch:0 step:47 [D loss: 0.016144, acc.: 100.00%] [G loss: 7.515132]\n",
      "epoch:0 step:48 [D loss: 0.016857, acc.: 100.00%] [G loss: 7.521027]\n",
      "epoch:0 step:49 [D loss: 0.014537, acc.: 100.00%] [G loss: 8.045129]\n",
      "epoch:0 step:50 [D loss: 0.015603, acc.: 100.00%] [G loss: 7.665126]\n",
      "epoch:0 step:51 [D loss: 0.018223, acc.: 100.00%] [G loss: 7.917029]\n",
      "epoch:0 step:52 [D loss: 0.013266, acc.: 100.00%] [G loss: 8.136890]\n",
      "epoch:0 step:53 [D loss: 0.014995, acc.: 100.00%] [G loss: 7.848630]\n",
      "epoch:0 step:54 [D loss: 0.014817, acc.: 100.00%] [G loss: 8.184246]\n",
      "epoch:0 step:55 [D loss: 0.018898, acc.: 100.00%] [G loss: 8.166378]\n",
      "epoch:0 step:56 [D loss: 0.013927, acc.: 100.00%] [G loss: 8.146625]\n",
      "epoch:0 step:57 [D loss: 0.014447, acc.: 100.00%] [G loss: 8.386795]\n",
      "epoch:0 step:58 [D loss: 0.014965, acc.: 100.00%] [G loss: 8.456869]\n",
      "epoch:0 step:59 [D loss: 0.012568, acc.: 100.00%] [G loss: 8.531479]\n",
      "epoch:0 step:60 [D loss: 0.014816, acc.: 100.00%] [G loss: 8.474305]\n",
      "epoch:0 step:61 [D loss: 0.015270, acc.: 100.00%] [G loss: 9.086807]\n",
      "epoch:0 step:62 [D loss: 0.012953, acc.: 100.00%] [G loss: 9.139591]\n",
      "epoch:0 step:63 [D loss: 0.013531, acc.: 100.00%] [G loss: 9.207325]\n",
      "epoch:0 step:64 [D loss: 0.013972, acc.: 100.00%] [G loss: 8.843824]\n",
      "epoch:0 step:65 [D loss: 0.013997, acc.: 100.00%] [G loss: 9.057245]\n",
      "epoch:0 step:66 [D loss: 0.013607, acc.: 100.00%] [G loss: 9.102544]\n",
      "epoch:0 step:67 [D loss: 0.015456, acc.: 100.00%] [G loss: 9.031916]\n",
      "epoch:0 step:68 [D loss: 0.011628, acc.: 100.00%] [G loss: 8.959874]\n",
      "epoch:0 step:69 [D loss: 0.013554, acc.: 100.00%] [G loss: 9.532391]\n",
      "epoch:0 step:70 [D loss: 0.013581, acc.: 100.00%] [G loss: 9.331526]\n",
      "epoch:0 step:71 [D loss: 0.016215, acc.: 100.00%] [G loss: 9.231269]\n",
      "epoch:0 step:72 [D loss: 0.015867, acc.: 100.00%] [G loss: 8.970112]\n",
      "epoch:0 step:73 [D loss: 0.015348, acc.: 100.00%] [G loss: 9.772653]\n",
      "epoch:0 step:74 [D loss: 0.016319, acc.: 100.00%] [G loss: 8.868797]\n",
      "epoch:0 step:75 [D loss: 0.016508, acc.: 100.00%] [G loss: 9.410465]\n",
      "epoch:0 step:76 [D loss: 0.016747, acc.: 100.00%] [G loss: 9.610972]\n",
      "epoch:0 step:77 [D loss: 0.016340, acc.: 100.00%] [G loss: 9.855950]\n",
      "epoch:0 step:78 [D loss: 0.013450, acc.: 100.00%] [G loss: 9.765820]\n",
      "epoch:0 step:79 [D loss: 0.013768, acc.: 100.00%] [G loss: 9.497688]\n",
      "epoch:0 step:80 [D loss: 0.017269, acc.: 100.00%] [G loss: 10.136576]\n",
      "epoch:0 step:81 [D loss: 0.019897, acc.: 100.00%] [G loss: 10.288431]\n",
      "epoch:0 step:82 [D loss: 0.018293, acc.: 100.00%] [G loss: 10.331652]\n",
      "epoch:0 step:83 [D loss: 0.016566, acc.: 100.00%] [G loss: 9.786470]\n",
      "epoch:0 step:84 [D loss: 0.027081, acc.: 100.00%] [G loss: 11.267996]\n",
      "epoch:0 step:85 [D loss: 0.093784, acc.: 96.88%] [G loss: 11.656858]\n",
      "epoch:0 step:86 [D loss: 0.024825, acc.: 100.00%] [G loss: 10.530085]\n",
      "epoch:0 step:87 [D loss: 0.054943, acc.: 100.00%] [G loss: 11.409865]\n",
      "epoch:0 step:88 [D loss: 0.058343, acc.: 99.22%] [G loss: 12.194395]\n",
      "epoch:0 step:89 [D loss: 0.228030, acc.: 90.62%] [G loss: 9.802664]\n",
      "epoch:0 step:90 [D loss: 0.017879, acc.: 100.00%] [G loss: 12.328921]\n",
      "epoch:0 step:91 [D loss: 0.022399, acc.: 100.00%] [G loss: 11.555749]\n",
      "epoch:0 step:92 [D loss: 0.051468, acc.: 99.22%] [G loss: 12.007804]\n",
      "epoch:0 step:93 [D loss: 0.177085, acc.: 93.75%] [G loss: 10.769258]\n",
      "epoch:0 step:94 [D loss: 0.056850, acc.: 97.66%] [G loss: 10.980646]\n",
      "epoch:0 step:95 [D loss: 0.069262, acc.: 97.66%] [G loss: 10.524847]\n",
      "epoch:0 step:96 [D loss: 0.099922, acc.: 96.09%] [G loss: 12.126406]\n",
      "epoch:0 step:97 [D loss: 0.356257, acc.: 89.06%] [G loss: 8.093017]\n",
      "epoch:0 step:98 [D loss: 0.071110, acc.: 98.44%] [G loss: 10.198596]\n",
      "epoch:0 step:99 [D loss: 0.054059, acc.: 98.44%] [G loss: 11.439980]\n",
      "epoch:0 step:100 [D loss: 0.083711, acc.: 97.66%] [G loss: 14.334096]\n",
      "epoch:0 step:101 [D loss: 1.412115, acc.: 56.25%] [G loss: 20.807825]\n",
      "epoch:0 step:102 [D loss: 0.306077, acc.: 85.94%] [G loss: 7.449128]\n",
      "epoch:0 step:103 [D loss: 0.158632, acc.: 92.19%] [G loss: 14.811638]\n",
      "epoch:0 step:104 [D loss: 0.049123, acc.: 97.66%] [G loss: 12.671122]\n",
      "epoch:0 step:105 [D loss: 0.085995, acc.: 96.09%] [G loss: 13.335178]\n",
      "epoch:0 step:106 [D loss: 0.033043, acc.: 99.22%] [G loss: 12.539660]\n",
      "epoch:0 step:107 [D loss: 0.013577, acc.: 100.00%] [G loss: 12.155356]\n",
      "epoch:0 step:108 [D loss: 0.022632, acc.: 100.00%] [G loss: 9.818268]\n",
      "epoch:0 step:109 [D loss: 0.025057, acc.: 100.00%] [G loss: 10.008083]\n",
      "epoch:0 step:110 [D loss: 0.026196, acc.: 100.00%] [G loss: 9.808959]\n",
      "epoch:0 step:111 [D loss: 0.031007, acc.: 100.00%] [G loss: 8.008844]\n",
      "epoch:0 step:112 [D loss: 0.035405, acc.: 100.00%] [G loss: 7.944498]\n",
      "epoch:0 step:113 [D loss: 0.051385, acc.: 100.00%] [G loss: 7.562461]\n",
      "epoch:0 step:114 [D loss: 0.051759, acc.: 100.00%] [G loss: 6.445757]\n",
      "epoch:0 step:115 [D loss: 0.042142, acc.: 100.00%] [G loss: 6.284629]\n",
      "epoch:0 step:116 [D loss: 0.061580, acc.: 100.00%] [G loss: 7.391160]\n",
      "epoch:0 step:117 [D loss: 0.075348, acc.: 97.66%] [G loss: 7.946802]\n",
      "epoch:0 step:118 [D loss: 0.094671, acc.: 99.22%] [G loss: 7.744665]\n",
      "epoch:0 step:119 [D loss: 0.062137, acc.: 100.00%] [G loss: 6.140950]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:120 [D loss: 0.122556, acc.: 96.88%] [G loss: 6.466031]\n",
      "epoch:0 step:121 [D loss: 0.054285, acc.: 99.22%] [G loss: 8.374132]\n",
      "epoch:0 step:122 [D loss: 0.198350, acc.: 93.75%] [G loss: 5.125208]\n",
      "epoch:0 step:123 [D loss: 0.084123, acc.: 98.44%] [G loss: 7.550138]\n",
      "epoch:0 step:124 [D loss: 0.168070, acc.: 92.97%] [G loss: 7.225974]\n",
      "epoch:0 step:125 [D loss: 0.058280, acc.: 100.00%] [G loss: 8.242271]\n",
      "epoch:0 step:126 [D loss: 0.131117, acc.: 96.09%] [G loss: 8.772146]\n",
      "epoch:0 step:127 [D loss: 0.065521, acc.: 99.22%] [G loss: 7.111512]\n",
      "epoch:0 step:128 [D loss: 0.110426, acc.: 98.44%] [G loss: 7.548186]\n",
      "epoch:0 step:129 [D loss: 0.079653, acc.: 98.44%] [G loss: 8.449320]\n",
      "epoch:0 step:130 [D loss: 0.098329, acc.: 98.44%] [G loss: 8.352005]\n",
      "epoch:0 step:131 [D loss: 0.118552, acc.: 98.44%] [G loss: 7.852937]\n",
      "epoch:0 step:132 [D loss: 0.093813, acc.: 99.22%] [G loss: 8.743954]\n",
      "epoch:0 step:133 [D loss: 0.321893, acc.: 88.28%] [G loss: 6.325898]\n",
      "epoch:0 step:134 [D loss: 0.057189, acc.: 99.22%] [G loss: 10.989669]\n",
      "epoch:0 step:135 [D loss: 0.716359, acc.: 70.31%] [G loss: 5.350471]\n",
      "epoch:0 step:136 [D loss: 0.099315, acc.: 96.09%] [G loss: 11.484241]\n",
      "epoch:0 step:137 [D loss: 0.097829, acc.: 96.88%] [G loss: 8.232969]\n",
      "epoch:0 step:138 [D loss: 0.068757, acc.: 98.44%] [G loss: 9.993221]\n",
      "epoch:0 step:139 [D loss: 0.088688, acc.: 100.00%] [G loss: 7.817703]\n",
      "epoch:0 step:140 [D loss: 0.133497, acc.: 94.53%] [G loss: 9.678705]\n",
      "epoch:0 step:141 [D loss: 0.410096, acc.: 82.03%] [G loss: 7.336808]\n",
      "epoch:0 step:142 [D loss: 0.055695, acc.: 99.22%] [G loss: 10.917505]\n",
      "epoch:0 step:143 [D loss: 0.140324, acc.: 96.09%] [G loss: 10.285490]\n",
      "epoch:0 step:144 [D loss: 0.129460, acc.: 95.31%] [G loss: 7.944611]\n",
      "epoch:0 step:145 [D loss: 0.061970, acc.: 100.00%] [G loss: 9.781761]\n",
      "epoch:0 step:146 [D loss: 0.510460, acc.: 78.91%] [G loss: 4.865579]\n",
      "epoch:0 step:147 [D loss: 0.097982, acc.: 97.66%] [G loss: 10.852816]\n",
      "epoch:0 step:148 [D loss: 0.284981, acc.: 90.62%] [G loss: 4.420187]\n",
      "epoch:0 step:149 [D loss: 0.147659, acc.: 95.31%] [G loss: 9.458258]\n",
      "epoch:0 step:150 [D loss: 0.091291, acc.: 100.00%] [G loss: 9.332169]\n",
      "epoch:0 step:151 [D loss: 0.113168, acc.: 97.66%] [G loss: 7.794404]\n",
      "epoch:0 step:152 [D loss: 0.251219, acc.: 89.84%] [G loss: 6.646952]\n",
      "epoch:0 step:153 [D loss: 0.142724, acc.: 96.88%] [G loss: 7.564115]\n",
      "epoch:0 step:154 [D loss: 0.701696, acc.: 75.78%] [G loss: 3.865697]\n",
      "epoch:0 step:155 [D loss: 0.210270, acc.: 89.84%] [G loss: 11.652417]\n",
      "epoch:0 step:156 [D loss: 0.229379, acc.: 91.41%] [G loss: 10.938009]\n",
      "epoch:0 step:157 [D loss: 0.160765, acc.: 94.53%] [G loss: 7.700110]\n",
      "epoch:0 step:158 [D loss: 0.070126, acc.: 99.22%] [G loss: 9.651525]\n",
      "epoch:0 step:159 [D loss: 0.103900, acc.: 98.44%] [G loss: 9.900189]\n",
      "epoch:0 step:160 [D loss: 0.629460, acc.: 67.19%] [G loss: 3.769906]\n",
      "epoch:0 step:161 [D loss: 0.069391, acc.: 99.22%] [G loss: 9.540596]\n",
      "epoch:0 step:162 [D loss: 0.806688, acc.: 67.19%] [G loss: 7.321922]\n",
      "epoch:0 step:163 [D loss: 0.287334, acc.: 84.38%] [G loss: 8.843300]\n",
      "epoch:0 step:164 [D loss: 0.035104, acc.: 100.00%] [G loss: 13.202905]\n",
      "epoch:0 step:165 [D loss: 0.230091, acc.: 91.41%] [G loss: 5.998866]\n",
      "epoch:0 step:166 [D loss: 0.093350, acc.: 98.44%] [G loss: 7.958394]\n",
      "epoch:0 step:167 [D loss: 0.081506, acc.: 99.22%] [G loss: 9.260966]\n",
      "epoch:0 step:168 [D loss: 0.189413, acc.: 93.75%] [G loss: 8.161112]\n",
      "epoch:0 step:169 [D loss: 0.096355, acc.: 99.22%] [G loss: 8.337605]\n",
      "epoch:0 step:170 [D loss: 0.184087, acc.: 93.75%] [G loss: 8.517889]\n",
      "epoch:0 step:171 [D loss: 0.238874, acc.: 92.97%] [G loss: 6.748341]\n",
      "epoch:0 step:172 [D loss: 0.167258, acc.: 93.75%] [G loss: 8.028328]\n",
      "epoch:0 step:173 [D loss: 0.292217, acc.: 87.50%] [G loss: 5.984518]\n",
      "epoch:0 step:174 [D loss: 0.138450, acc.: 96.88%] [G loss: 8.549015]\n",
      "epoch:0 step:175 [D loss: 0.426626, acc.: 79.69%] [G loss: 6.818839]\n",
      "epoch:0 step:176 [D loss: 0.102646, acc.: 98.44%] [G loss: 7.747932]\n",
      "epoch:0 step:177 [D loss: 0.453407, acc.: 79.69%] [G loss: 6.577725]\n",
      "epoch:0 step:178 [D loss: 0.155993, acc.: 95.31%] [G loss: 9.594529]\n",
      "epoch:0 step:179 [D loss: 0.889918, acc.: 64.06%] [G loss: 3.635769]\n",
      "epoch:0 step:180 [D loss: 0.146765, acc.: 95.31%] [G loss: 9.806194]\n",
      "epoch:0 step:181 [D loss: 0.579999, acc.: 71.09%] [G loss: 4.023611]\n",
      "epoch:0 step:182 [D loss: 0.126091, acc.: 97.66%] [G loss: 7.603241]\n",
      "epoch:0 step:183 [D loss: 0.127571, acc.: 98.44%] [G loss: 7.732150]\n",
      "epoch:0 step:184 [D loss: 0.210071, acc.: 92.97%] [G loss: 6.945818]\n",
      "epoch:0 step:185 [D loss: 0.335916, acc.: 82.81%] [G loss: 3.386864]\n",
      "epoch:0 step:186 [D loss: 0.183894, acc.: 95.31%] [G loss: 7.978518]\n",
      "epoch:0 step:187 [D loss: 0.489105, acc.: 75.00%] [G loss: 7.221818]\n",
      "epoch:0 step:188 [D loss: 0.327447, acc.: 88.28%] [G loss: 6.674032]\n",
      "epoch:0 step:189 [D loss: 0.290758, acc.: 88.28%] [G loss: 7.057631]\n",
      "epoch:0 step:190 [D loss: 0.976278, acc.: 55.47%] [G loss: 2.886152]\n",
      "epoch:0 step:191 [D loss: 0.165692, acc.: 96.09%] [G loss: 6.928192]\n",
      "epoch:0 step:192 [D loss: 0.890533, acc.: 58.59%] [G loss: 1.994262]\n",
      "epoch:0 step:193 [D loss: 0.270215, acc.: 85.16%] [G loss: 6.100838]\n",
      "epoch:0 step:194 [D loss: 0.181182, acc.: 96.09%] [G loss: 7.120190]\n",
      "epoch:0 step:195 [D loss: 0.364783, acc.: 84.38%] [G loss: 3.785136]\n",
      "epoch:0 step:196 [D loss: 0.211509, acc.: 95.31%] [G loss: 5.475890]\n",
      "epoch:0 step:197 [D loss: 0.267288, acc.: 91.41%] [G loss: 5.872239]\n",
      "epoch:0 step:198 [D loss: 0.527392, acc.: 75.78%] [G loss: 4.066733]\n",
      "epoch:0 step:199 [D loss: 0.302274, acc.: 91.41%] [G loss: 3.471312]\n",
      "epoch:0 step:200 [D loss: 0.469353, acc.: 71.88%] [G loss: 4.365188]\n",
      "WARNING:tensorflow:From /home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/contrib/gan/python/eval/python/classifier_metrics_impl.py:185: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      "##############\n",
      "[ 7.46537044  7.59974359 13.25367035  9.43092445  8.71134707 11.98333983\n",
      " 11.27914699  9.6518914   9.52697836 10.29102348]\n",
      "##########\n",
      "epoch:0 step:201 [D loss: 0.220335, acc.: 95.31%] [G loss: 5.443540]\n",
      "epoch:0 step:202 [D loss: 0.823639, acc.: 62.50%] [G loss: 1.808990]\n",
      "epoch:0 step:203 [D loss: 0.238061, acc.: 93.75%] [G loss: 6.838088]\n",
      "epoch:0 step:204 [D loss: 0.852151, acc.: 60.94%] [G loss: 3.281133]\n",
      "epoch:0 step:205 [D loss: 0.195691, acc.: 96.88%] [G loss: 6.045144]\n",
      "epoch:0 step:206 [D loss: 0.419851, acc.: 79.69%] [G loss: 4.469995]\n",
      "epoch:0 step:207 [D loss: 0.331445, acc.: 88.28%] [G loss: 3.707545]\n",
      "epoch:0 step:208 [D loss: 0.286420, acc.: 91.41%] [G loss: 4.815406]\n",
      "epoch:0 step:209 [D loss: 0.427101, acc.: 82.03%] [G loss: 3.407839]\n",
      "epoch:0 step:210 [D loss: 0.389765, acc.: 85.94%] [G loss: 5.302832]\n",
      "epoch:0 step:211 [D loss: 0.674543, acc.: 65.62%] [G loss: 2.518610]\n",
      "epoch:0 step:212 [D loss: 0.216207, acc.: 97.66%] [G loss: 6.794440]\n",
      "epoch:0 step:213 [D loss: 0.702331, acc.: 60.94%] [G loss: 2.626766]\n",
      "epoch:0 step:214 [D loss: 0.262959, acc.: 92.97%] [G loss: 6.579657]\n",
      "epoch:0 step:215 [D loss: 0.516541, acc.: 75.78%] [G loss: 3.678061]\n",
      "epoch:0 step:216 [D loss: 0.212966, acc.: 94.53%] [G loss: 6.612316]\n",
      "epoch:0 step:217 [D loss: 0.759396, acc.: 54.69%] [G loss: 3.200367]\n",
      "epoch:0 step:218 [D loss: 0.264372, acc.: 96.88%] [G loss: 5.859408]\n",
      "epoch:0 step:219 [D loss: 0.926537, acc.: 49.22%] [G loss: 1.221011]\n",
      "epoch:0 step:220 [D loss: 0.564606, acc.: 63.28%] [G loss: 3.648917]\n",
      "epoch:0 step:221 [D loss: 0.847368, acc.: 43.75%] [G loss: 1.021595]\n",
      "epoch:0 step:222 [D loss: 0.295192, acc.: 89.84%] [G loss: 4.379221]\n",
      "epoch:0 step:223 [D loss: 0.588871, acc.: 64.84%] [G loss: 1.609078]\n",
      "epoch:0 step:224 [D loss: 0.431720, acc.: 82.81%] [G loss: 3.962936]\n",
      "epoch:0 step:225 [D loss: 0.906760, acc.: 42.19%] [G loss: 1.019643]\n",
      "epoch:0 step:226 [D loss: 0.291117, acc.: 91.41%] [G loss: 4.402184]\n",
      "epoch:0 step:227 [D loss: 0.729054, acc.: 55.47%] [G loss: 1.424053]\n",
      "epoch:0 step:228 [D loss: 0.305821, acc.: 90.62%] [G loss: 4.508076]\n",
      "epoch:0 step:229 [D loss: 0.916224, acc.: 44.53%] [G loss: 0.703510]\n",
      "epoch:0 step:230 [D loss: 0.407652, acc.: 80.47%] [G loss: 3.706431]\n",
      "epoch:0 step:231 [D loss: 0.452696, acc.: 87.50%] [G loss: 2.314035]\n",
      "epoch:0 step:232 [D loss: 0.503781, acc.: 72.66%] [G loss: 1.889880]\n",
      "epoch:0 step:233 [D loss: 0.843430, acc.: 42.97%] [G loss: 0.730315]\n",
      "epoch:0 step:234 [D loss: 0.400952, acc.: 82.81%] [G loss: 3.439219]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:235 [D loss: 0.920767, acc.: 37.50%] [G loss: 0.315609]\n",
      "epoch:0 step:236 [D loss: 0.479141, acc.: 67.19%] [G loss: 3.177768]\n",
      "epoch:0 step:237 [D loss: 1.043906, acc.: 32.81%] [G loss: 0.308697]\n",
      "epoch:0 step:238 [D loss: 0.412672, acc.: 76.56%] [G loss: 2.479068]\n",
      "epoch:0 step:239 [D loss: 0.733086, acc.: 54.69%] [G loss: 0.574735]\n",
      "epoch:0 step:240 [D loss: 0.384084, acc.: 86.72%] [G loss: 2.390213]\n",
      "epoch:0 step:241 [D loss: 0.726025, acc.: 50.00%] [G loss: 0.692198]\n",
      "epoch:0 step:242 [D loss: 0.528010, acc.: 68.75%] [G loss: 1.430577]\n",
      "epoch:0 step:243 [D loss: 0.767153, acc.: 49.22%] [G loss: 0.596954]\n",
      "epoch:0 step:244 [D loss: 0.523849, acc.: 71.88%] [G loss: 1.242505]\n",
      "epoch:0 step:245 [D loss: 0.680510, acc.: 61.72%] [G loss: 0.726681]\n",
      "epoch:0 step:246 [D loss: 0.651064, acc.: 56.25%] [G loss: 0.930652]\n",
      "epoch:0 step:247 [D loss: 0.645141, acc.: 59.38%] [G loss: 0.996749]\n",
      "epoch:0 step:248 [D loss: 0.601172, acc.: 64.84%] [G loss: 0.825442]\n",
      "epoch:0 step:249 [D loss: 0.738877, acc.: 47.66%] [G loss: 0.526169]\n",
      "epoch:0 step:250 [D loss: 0.520017, acc.: 75.00%] [G loss: 1.427241]\n",
      "epoch:0 step:251 [D loss: 0.792346, acc.: 47.66%] [G loss: 0.365394]\n",
      "epoch:0 step:252 [D loss: 0.599355, acc.: 58.59%] [G loss: 0.763433]\n",
      "epoch:0 step:253 [D loss: 0.728446, acc.: 51.56%] [G loss: 0.689112]\n",
      "epoch:0 step:254 [D loss: 0.672590, acc.: 56.25%] [G loss: 0.720548]\n",
      "epoch:0 step:255 [D loss: 0.656304, acc.: 53.91%] [G loss: 0.627942]\n",
      "epoch:0 step:256 [D loss: 0.722981, acc.: 48.44%] [G loss: 0.444153]\n",
      "epoch:0 step:257 [D loss: 0.529828, acc.: 65.62%] [G loss: 1.261121]\n",
      "epoch:0 step:258 [D loss: 0.720678, acc.: 50.78%] [G loss: 0.379749]\n",
      "epoch:0 step:259 [D loss: 0.613892, acc.: 57.81%] [G loss: 0.673179]\n",
      "epoch:0 step:260 [D loss: 0.691335, acc.: 53.91%] [G loss: 0.349801]\n",
      "epoch:0 step:261 [D loss: 0.618636, acc.: 57.81%] [G loss: 0.636629]\n",
      "epoch:0 step:262 [D loss: 0.733987, acc.: 44.53%] [G loss: 0.254552]\n",
      "epoch:0 step:263 [D loss: 0.900799, acc.: 29.69%] [G loss: 0.058831]\n",
      "epoch:0 step:264 [D loss: 0.600932, acc.: 53.12%] [G loss: 0.364029]\n",
      "epoch:0 step:265 [D loss: 0.677243, acc.: 57.03%] [G loss: 0.459919]\n",
      "epoch:0 step:266 [D loss: 0.672550, acc.: 50.78%] [G loss: 0.281473]\n",
      "epoch:0 step:267 [D loss: 0.629107, acc.: 56.25%] [G loss: 0.412005]\n",
      "epoch:0 step:268 [D loss: 0.750628, acc.: 40.62%] [G loss: 0.216793]\n",
      "epoch:0 step:269 [D loss: 0.769636, acc.: 36.72%] [G loss: 0.091351]\n",
      "epoch:0 step:270 [D loss: 0.633615, acc.: 51.56%] [G loss: 0.294242]\n",
      "epoch:0 step:271 [D loss: 0.636150, acc.: 54.69%] [G loss: 0.227877]\n",
      "epoch:0 step:272 [D loss: 0.617036, acc.: 57.03%] [G loss: 0.306555]\n",
      "epoch:0 step:273 [D loss: 0.666152, acc.: 50.00%] [G loss: 0.292528]\n",
      "epoch:0 step:274 [D loss: 0.678598, acc.: 48.44%] [G loss: 0.192429]\n",
      "epoch:0 step:275 [D loss: 0.630683, acc.: 55.47%] [G loss: 0.266736]\n",
      "epoch:0 step:276 [D loss: 0.649238, acc.: 51.56%] [G loss: 0.221106]\n",
      "epoch:0 step:277 [D loss: 0.600267, acc.: 62.50%] [G loss: 0.374267]\n",
      "epoch:0 step:278 [D loss: 0.643527, acc.: 56.25%] [G loss: 0.334733]\n",
      "epoch:0 step:279 [D loss: 0.578218, acc.: 67.19%] [G loss: 0.463221]\n",
      "epoch:0 step:280 [D loss: 0.599558, acc.: 63.28%] [G loss: 0.366226]\n",
      "epoch:0 step:281 [D loss: 0.716201, acc.: 49.22%] [G loss: 0.152660]\n",
      "epoch:0 step:282 [D loss: 0.663351, acc.: 49.22%] [G loss: 0.268593]\n",
      "epoch:0 step:283 [D loss: 0.627254, acc.: 54.69%] [G loss: 0.340583]\n",
      "epoch:0 step:284 [D loss: 0.591365, acc.: 64.84%] [G loss: 0.348934]\n",
      "epoch:0 step:285 [D loss: 0.610576, acc.: 62.50%] [G loss: 0.264820]\n",
      "epoch:0 step:286 [D loss: 0.590585, acc.: 67.19%] [G loss: 0.398457]\n",
      "epoch:0 step:287 [D loss: 0.567048, acc.: 68.75%] [G loss: 0.372434]\n",
      "epoch:0 step:288 [D loss: 0.683936, acc.: 46.09%] [G loss: 0.185060]\n",
      "epoch:0 step:289 [D loss: 0.579709, acc.: 60.94%] [G loss: 0.561473]\n",
      "epoch:0 step:290 [D loss: 0.738869, acc.: 49.22%] [G loss: 0.158224]\n",
      "epoch:0 step:291 [D loss: 0.758849, acc.: 46.09%] [G loss: 0.081043]\n",
      "epoch:0 step:292 [D loss: 0.675700, acc.: 47.66%] [G loss: 0.166349]\n",
      "epoch:0 step:293 [D loss: 0.641662, acc.: 56.25%] [G loss: 0.165373]\n",
      "epoch:0 step:294 [D loss: 0.673160, acc.: 48.44%] [G loss: 0.127712]\n",
      "epoch:0 step:295 [D loss: 0.673919, acc.: 48.44%] [G loss: 0.104722]\n",
      "epoch:0 step:296 [D loss: 0.600682, acc.: 53.12%] [G loss: 0.208009]\n",
      "epoch:0 step:297 [D loss: 0.684017, acc.: 46.88%] [G loss: 0.120809]\n",
      "epoch:0 step:298 [D loss: 0.704314, acc.: 45.31%] [G loss: 0.078184]\n",
      "epoch:0 step:299 [D loss: 0.600742, acc.: 56.25%] [G loss: 0.232954]\n",
      "epoch:0 step:300 [D loss: 0.636981, acc.: 61.72%] [G loss: 0.168130]\n",
      "epoch:0 step:301 [D loss: 0.748690, acc.: 39.84%] [G loss: 0.065858]\n",
      "epoch:0 step:302 [D loss: 0.647715, acc.: 51.56%] [G loss: 0.136290]\n",
      "epoch:0 step:303 [D loss: 0.669443, acc.: 48.44%] [G loss: 0.120820]\n",
      "epoch:0 step:304 [D loss: 0.649974, acc.: 56.25%] [G loss: 0.146892]\n",
      "epoch:0 step:305 [D loss: 0.605005, acc.: 62.50%] [G loss: 0.216745]\n",
      "epoch:0 step:306 [D loss: 0.599964, acc.: 67.19%] [G loss: 0.188407]\n",
      "epoch:0 step:307 [D loss: 0.587884, acc.: 60.94%] [G loss: 0.249339]\n",
      "epoch:0 step:308 [D loss: 0.667699, acc.: 56.25%] [G loss: 0.133213]\n",
      "epoch:0 step:309 [D loss: 0.656018, acc.: 48.44%] [G loss: 0.132356]\n",
      "epoch:0 step:310 [D loss: 0.584627, acc.: 64.06%] [G loss: 0.199950]\n",
      "epoch:0 step:311 [D loss: 0.627617, acc.: 60.94%] [G loss: 0.165268]\n",
      "epoch:0 step:312 [D loss: 0.825991, acc.: 25.00%] [G loss: 0.032107]\n",
      "epoch:0 step:313 [D loss: 0.656354, acc.: 53.91%] [G loss: 0.072990]\n",
      "epoch:0 step:314 [D loss: 0.570842, acc.: 60.94%] [G loss: 0.154439]\n",
      "epoch:0 step:315 [D loss: 0.635387, acc.: 60.16%] [G loss: 0.152412]\n",
      "epoch:0 step:316 [D loss: 0.781230, acc.: 35.16%] [G loss: 0.021284]\n",
      "epoch:0 step:317 [D loss: 0.631122, acc.: 52.34%] [G loss: 0.064049]\n",
      "epoch:0 step:318 [D loss: 0.598016, acc.: 57.03%] [G loss: 0.099093]\n",
      "epoch:0 step:319 [D loss: 0.620587, acc.: 59.38%] [G loss: 0.111957]\n",
      "epoch:0 step:320 [D loss: 0.600632, acc.: 65.62%] [G loss: 0.158807]\n",
      "epoch:0 step:321 [D loss: 0.652714, acc.: 51.56%] [G loss: 0.084026]\n",
      "epoch:0 step:322 [D loss: 0.606579, acc.: 57.81%] [G loss: 0.117444]\n",
      "epoch:0 step:323 [D loss: 0.591027, acc.: 67.97%] [G loss: 0.174403]\n",
      "epoch:0 step:324 [D loss: 0.576340, acc.: 71.09%] [G loss: 0.175233]\n",
      "epoch:0 step:325 [D loss: 0.618105, acc.: 57.81%] [G loss: 0.143976]\n",
      "epoch:0 step:326 [D loss: 0.666089, acc.: 50.00%] [G loss: 0.086003]\n",
      "epoch:0 step:327 [D loss: 0.586618, acc.: 61.72%] [G loss: 0.144138]\n",
      "epoch:0 step:328 [D loss: 0.662974, acc.: 47.66%] [G loss: 0.099836]\n",
      "epoch:0 step:329 [D loss: 0.609334, acc.: 57.81%] [G loss: 0.129821]\n",
      "epoch:0 step:330 [D loss: 0.605239, acc.: 63.28%] [G loss: 0.109741]\n",
      "epoch:0 step:331 [D loss: 0.623627, acc.: 52.34%] [G loss: 0.119394]\n",
      "epoch:0 step:332 [D loss: 0.627659, acc.: 53.12%] [G loss: 0.113510]\n",
      "epoch:0 step:333 [D loss: 0.630525, acc.: 53.91%] [G loss: 0.111288]\n",
      "epoch:0 step:334 [D loss: 0.651769, acc.: 46.09%] [G loss: 0.078342]\n",
      "epoch:0 step:335 [D loss: 0.601749, acc.: 60.16%] [G loss: 0.113362]\n",
      "epoch:0 step:336 [D loss: 0.555838, acc.: 74.22%] [G loss: 0.167221]\n",
      "epoch:0 step:337 [D loss: 0.571651, acc.: 77.34%] [G loss: 0.200432]\n",
      "epoch:0 step:338 [D loss: 0.604921, acc.: 61.72%] [G loss: 0.165680]\n",
      "epoch:0 step:339 [D loss: 0.595738, acc.: 64.84%] [G loss: 0.116515]\n",
      "epoch:0 step:340 [D loss: 0.585838, acc.: 60.16%] [G loss: 0.146896]\n",
      "epoch:0 step:341 [D loss: 0.663266, acc.: 52.34%] [G loss: 0.097838]\n",
      "epoch:0 step:342 [D loss: 0.602042, acc.: 63.28%] [G loss: 0.134249]\n",
      "epoch:0 step:343 [D loss: 0.579029, acc.: 70.31%] [G loss: 0.156620]\n",
      "epoch:0 step:344 [D loss: 0.554746, acc.: 75.00%] [G loss: 0.254429]\n",
      "epoch:0 step:345 [D loss: 0.762778, acc.: 31.25%] [G loss: 0.028417]\n",
      "epoch:0 step:346 [D loss: 0.643977, acc.: 50.00%] [G loss: 0.029266]\n",
      "epoch:0 step:347 [D loss: 0.587442, acc.: 58.59%] [G loss: 0.127741]\n",
      "epoch:0 step:348 [D loss: 0.619411, acc.: 61.72%] [G loss: 0.087134]\n",
      "epoch:0 step:349 [D loss: 0.651674, acc.: 53.12%] [G loss: 0.040710]\n",
      "epoch:0 step:350 [D loss: 0.609427, acc.: 53.12%] [G loss: 0.090864]\n",
      "epoch:0 step:351 [D loss: 0.644622, acc.: 57.03%] [G loss: 0.072978]\n",
      "epoch:0 step:352 [D loss: 0.668242, acc.: 48.44%] [G loss: 0.040535]\n",
      "epoch:0 step:353 [D loss: 0.596459, acc.: 57.03%] [G loss: 0.068494]\n",
      "epoch:0 step:354 [D loss: 0.599013, acc.: 64.84%] [G loss: 0.082996]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:355 [D loss: 0.590985, acc.: 67.19%] [G loss: 0.117275]\n",
      "epoch:0 step:356 [D loss: 0.603599, acc.: 64.84%] [G loss: 0.104744]\n",
      "epoch:0 step:357 [D loss: 0.595016, acc.: 65.62%] [G loss: 0.138115]\n",
      "epoch:0 step:358 [D loss: 0.541400, acc.: 80.47%] [G loss: 0.169360]\n",
      "epoch:0 step:359 [D loss: 0.604777, acc.: 69.53%] [G loss: 0.128042]\n",
      "epoch:0 step:360 [D loss: 0.607780, acc.: 60.94%] [G loss: 0.118971]\n",
      "epoch:0 step:361 [D loss: 0.586174, acc.: 71.09%] [G loss: 0.149389]\n",
      "epoch:0 step:362 [D loss: 0.621978, acc.: 67.19%] [G loss: 0.090880]\n",
      "epoch:0 step:363 [D loss: 0.550588, acc.: 75.78%] [G loss: 0.106335]\n",
      "epoch:0 step:364 [D loss: 0.558701, acc.: 68.75%] [G loss: 0.127878]\n",
      "epoch:0 step:365 [D loss: 0.631160, acc.: 57.03%] [G loss: 0.081660]\n",
      "epoch:0 step:366 [D loss: 0.598667, acc.: 67.19%] [G loss: 0.095485]\n",
      "epoch:0 step:367 [D loss: 0.590027, acc.: 64.84%] [G loss: 0.114817]\n",
      "epoch:0 step:368 [D loss: 0.601429, acc.: 61.72%] [G loss: 0.106038]\n",
      "epoch:0 step:369 [D loss: 0.656840, acc.: 50.00%] [G loss: 0.049075]\n",
      "epoch:0 step:370 [D loss: 0.597782, acc.: 59.38%] [G loss: 0.046026]\n",
      "epoch:0 step:371 [D loss: 0.646948, acc.: 52.34%] [G loss: 0.049258]\n",
      "epoch:0 step:372 [D loss: 0.599821, acc.: 64.84%] [G loss: 0.067401]\n",
      "epoch:0 step:373 [D loss: 0.620070, acc.: 57.03%] [G loss: 0.060816]\n",
      "epoch:0 step:374 [D loss: 0.626226, acc.: 56.25%] [G loss: 0.049970]\n",
      "epoch:0 step:375 [D loss: 0.549006, acc.: 70.31%] [G loss: 0.098703]\n",
      "epoch:0 step:376 [D loss: 0.540713, acc.: 80.47%] [G loss: 0.145007]\n",
      "epoch:0 step:377 [D loss: 0.546170, acc.: 79.69%] [G loss: 0.125901]\n",
      "epoch:0 step:378 [D loss: 0.529396, acc.: 77.34%] [G loss: 0.139064]\n",
      "epoch:0 step:379 [D loss: 0.582568, acc.: 71.09%] [G loss: 0.150035]\n",
      "epoch:0 step:380 [D loss: 0.626750, acc.: 67.19%] [G loss: 0.108679]\n",
      "epoch:0 step:381 [D loss: 0.527189, acc.: 78.91%] [G loss: 0.119755]\n",
      "epoch:0 step:382 [D loss: 0.592216, acc.: 71.09%] [G loss: 0.088583]\n",
      "epoch:0 step:383 [D loss: 0.592097, acc.: 67.19%] [G loss: 0.108778]\n",
      "epoch:0 step:384 [D loss: 0.592230, acc.: 64.06%] [G loss: 0.070941]\n",
      "epoch:0 step:385 [D loss: 0.618117, acc.: 64.84%] [G loss: 0.078733]\n",
      "epoch:0 step:386 [D loss: 0.526879, acc.: 80.47%] [G loss: 0.137340]\n",
      "epoch:0 step:387 [D loss: 0.557220, acc.: 78.91%] [G loss: 0.139364]\n",
      "epoch:0 step:388 [D loss: 0.517235, acc.: 84.38%] [G loss: 0.172117]\n",
      "epoch:0 step:389 [D loss: 0.602733, acc.: 64.84%] [G loss: 0.103877]\n",
      "epoch:0 step:390 [D loss: 0.570348, acc.: 70.31%] [G loss: 0.114420]\n",
      "epoch:0 step:391 [D loss: 0.552366, acc.: 75.00%] [G loss: 0.126874]\n",
      "epoch:0 step:392 [D loss: 0.550497, acc.: 77.34%] [G loss: 0.147528]\n",
      "epoch:0 step:393 [D loss: 0.601873, acc.: 69.53%] [G loss: 0.077461]\n",
      "epoch:0 step:394 [D loss: 0.606664, acc.: 66.41%] [G loss: 0.060198]\n",
      "epoch:0 step:395 [D loss: 0.565011, acc.: 75.78%] [G loss: 0.083590]\n",
      "epoch:0 step:396 [D loss: 0.617057, acc.: 63.28%] [G loss: 0.086242]\n",
      "epoch:0 step:397 [D loss: 0.521195, acc.: 81.25%] [G loss: 0.146013]\n",
      "epoch:0 step:398 [D loss: 0.533148, acc.: 83.59%] [G loss: 0.178109]\n",
      "epoch:0 step:399 [D loss: 0.533079, acc.: 82.03%] [G loss: 0.173120]\n",
      "epoch:0 step:400 [D loss: 0.607693, acc.: 60.94%] [G loss: 0.120118]\n",
      "##############\n",
      "[ 6.8967711   7.59974359 11.09513021  9.4020205   8.59817527 11.98333983\n",
      " 11.27914699  9.39145031  9.49173232 10.29102348]\n",
      "##########\n",
      "epoch:0 step:401 [D loss: 0.551877, acc.: 82.03%] [G loss: 0.123173]\n",
      "epoch:0 step:402 [D loss: 0.607703, acc.: 65.62%] [G loss: 0.073334]\n",
      "epoch:0 step:403 [D loss: 0.549727, acc.: 75.00%] [G loss: 0.102222]\n",
      "epoch:0 step:404 [D loss: 0.584615, acc.: 76.56%] [G loss: 0.079153]\n",
      "epoch:0 step:405 [D loss: 0.564010, acc.: 69.53%] [G loss: 0.105737]\n",
      "epoch:0 step:406 [D loss: 0.564924, acc.: 75.00%] [G loss: 0.127873]\n",
      "epoch:0 step:407 [D loss: 0.554469, acc.: 75.00%] [G loss: 0.172174]\n",
      "epoch:0 step:408 [D loss: 0.546746, acc.: 82.03%] [G loss: 0.172041]\n",
      "epoch:0 step:409 [D loss: 0.555687, acc.: 77.34%] [G loss: 0.126273]\n",
      "epoch:0 step:410 [D loss: 0.541423, acc.: 71.88%] [G loss: 0.156839]\n",
      "epoch:0 step:411 [D loss: 0.605944, acc.: 67.19%] [G loss: 0.168807]\n",
      "epoch:0 step:412 [D loss: 0.578682, acc.: 73.44%] [G loss: 0.130212]\n",
      "epoch:0 step:413 [D loss: 0.585421, acc.: 71.88%] [G loss: 0.124470]\n",
      "epoch:0 step:414 [D loss: 0.613004, acc.: 67.19%] [G loss: 0.097594]\n",
      "epoch:0 step:415 [D loss: 0.567807, acc.: 77.34%] [G loss: 0.117511]\n",
      "epoch:0 step:416 [D loss: 0.587991, acc.: 71.09%] [G loss: 0.108088]\n",
      "epoch:0 step:417 [D loss: 0.573964, acc.: 75.00%] [G loss: 0.103830]\n",
      "epoch:0 step:418 [D loss: 0.552878, acc.: 78.12%] [G loss: 0.125980]\n",
      "epoch:0 step:419 [D loss: 0.524270, acc.: 80.47%] [G loss: 0.189446]\n",
      "epoch:0 step:420 [D loss: 0.570156, acc.: 74.22%] [G loss: 0.191152]\n",
      "epoch:0 step:421 [D loss: 0.630979, acc.: 63.28%] [G loss: 0.089781]\n",
      "epoch:0 step:422 [D loss: 0.628734, acc.: 60.16%] [G loss: 0.074104]\n",
      "epoch:0 step:423 [D loss: 0.600851, acc.: 67.19%] [G loss: 0.073386]\n",
      "epoch:0 step:424 [D loss: 0.597699, acc.: 67.97%] [G loss: 0.077582]\n",
      "epoch:0 step:425 [D loss: 0.619051, acc.: 65.62%] [G loss: 0.074625]\n",
      "epoch:0 step:426 [D loss: 0.561129, acc.: 75.78%] [G loss: 0.104264]\n",
      "epoch:0 step:427 [D loss: 0.581162, acc.: 74.22%] [G loss: 0.116297]\n",
      "epoch:0 step:428 [D loss: 0.564667, acc.: 73.44%] [G loss: 0.099199]\n",
      "epoch:0 step:429 [D loss: 0.569241, acc.: 78.12%] [G loss: 0.129522]\n",
      "epoch:0 step:430 [D loss: 0.566347, acc.: 79.69%] [G loss: 0.132437]\n",
      "epoch:0 step:431 [D loss: 0.577796, acc.: 75.78%] [G loss: 0.129724]\n",
      "epoch:0 step:432 [D loss: 0.612571, acc.: 67.97%] [G loss: 0.092763]\n",
      "epoch:0 step:433 [D loss: 0.554821, acc.: 75.78%] [G loss: 0.092975]\n",
      "epoch:0 step:434 [D loss: 0.583270, acc.: 70.31%] [G loss: 0.109225]\n",
      "epoch:0 step:435 [D loss: 0.555120, acc.: 78.91%] [G loss: 0.124100]\n",
      "epoch:0 step:436 [D loss: 0.592916, acc.: 65.62%] [G loss: 0.119306]\n",
      "epoch:0 step:437 [D loss: 0.598991, acc.: 68.75%] [G loss: 0.092180]\n",
      "epoch:0 step:438 [D loss: 0.502782, acc.: 80.47%] [G loss: 0.157272]\n",
      "epoch:0 step:439 [D loss: 0.571361, acc.: 75.78%] [G loss: 0.134355]\n",
      "epoch:0 step:440 [D loss: 0.544191, acc.: 78.12%] [G loss: 0.169077]\n",
      "epoch:0 step:441 [D loss: 0.571755, acc.: 75.00%] [G loss: 0.159399]\n",
      "epoch:0 step:442 [D loss: 0.541085, acc.: 84.38%] [G loss: 0.145147]\n",
      "epoch:0 step:443 [D loss: 0.570048, acc.: 71.88%] [G loss: 0.118475]\n",
      "epoch:0 step:444 [D loss: 0.544459, acc.: 79.69%] [G loss: 0.145406]\n",
      "epoch:0 step:445 [D loss: 0.590622, acc.: 71.09%] [G loss: 0.142126]\n",
      "epoch:0 step:446 [D loss: 0.520882, acc.: 83.59%] [G loss: 0.188581]\n",
      "epoch:0 step:447 [D loss: 0.526320, acc.: 85.94%] [G loss: 0.182486]\n",
      "epoch:0 step:448 [D loss: 0.683502, acc.: 56.25%] [G loss: 0.063711]\n",
      "epoch:0 step:449 [D loss: 0.620000, acc.: 56.25%] [G loss: 0.047941]\n",
      "epoch:0 step:450 [D loss: 0.530287, acc.: 76.56%] [G loss: 0.098405]\n",
      "epoch:0 step:451 [D loss: 0.565931, acc.: 77.34%] [G loss: 0.114797]\n",
      "epoch:0 step:452 [D loss: 0.588961, acc.: 72.66%] [G loss: 0.128847]\n",
      "epoch:0 step:453 [D loss: 0.565385, acc.: 78.91%] [G loss: 0.122015]\n",
      "epoch:0 step:454 [D loss: 0.560938, acc.: 75.00%] [G loss: 0.127340]\n",
      "epoch:0 step:455 [D loss: 0.578762, acc.: 72.66%] [G loss: 0.104018]\n",
      "epoch:0 step:456 [D loss: 0.588866, acc.: 73.44%] [G loss: 0.105483]\n",
      "epoch:0 step:457 [D loss: 0.567884, acc.: 71.09%] [G loss: 0.146574]\n",
      "epoch:0 step:458 [D loss: 0.522841, acc.: 87.50%] [G loss: 0.181826]\n",
      "epoch:0 step:459 [D loss: 0.557351, acc.: 78.12%] [G loss: 0.146442]\n",
      "epoch:0 step:460 [D loss: 0.548876, acc.: 74.22%] [G loss: 0.150847]\n",
      "epoch:0 step:461 [D loss: 0.525957, acc.: 85.16%] [G loss: 0.184143]\n",
      "epoch:0 step:462 [D loss: 0.523482, acc.: 87.50%] [G loss: 0.163420]\n",
      "epoch:0 step:463 [D loss: 0.548474, acc.: 79.69%] [G loss: 0.135164]\n",
      "epoch:0 step:464 [D loss: 0.549183, acc.: 80.47%] [G loss: 0.137936]\n",
      "epoch:0 step:465 [D loss: 0.527145, acc.: 78.91%] [G loss: 0.188071]\n",
      "epoch:0 step:466 [D loss: 0.500731, acc.: 83.59%] [G loss: 0.245602]\n",
      "epoch:0 step:467 [D loss: 0.548584, acc.: 79.69%] [G loss: 0.192326]\n",
      "epoch:0 step:468 [D loss: 0.547687, acc.: 77.34%] [G loss: 0.189013]\n",
      "epoch:0 step:469 [D loss: 0.527672, acc.: 80.47%] [G loss: 0.204726]\n",
      "epoch:0 step:470 [D loss: 0.637253, acc.: 65.62%] [G loss: 0.190764]\n",
      "epoch:0 step:471 [D loss: 0.533240, acc.: 81.25%] [G loss: 0.191615]\n",
      "epoch:0 step:472 [D loss: 0.538483, acc.: 77.34%] [G loss: 0.193858]\n",
      "epoch:0 step:473 [D loss: 0.617426, acc.: 65.62%] [G loss: 0.139589]\n",
      "epoch:0 step:474 [D loss: 0.555703, acc.: 72.66%] [G loss: 0.224251]\n",
      "epoch:0 step:475 [D loss: 0.534826, acc.: 78.12%] [G loss: 0.210188]\n",
      "epoch:0 step:476 [D loss: 0.573004, acc.: 74.22%] [G loss: 0.165669]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:477 [D loss: 0.618483, acc.: 60.16%] [G loss: 0.105227]\n",
      "epoch:0 step:478 [D loss: 0.553450, acc.: 71.09%] [G loss: 0.138853]\n",
      "epoch:0 step:479 [D loss: 0.522017, acc.: 82.81%] [G loss: 0.174671]\n",
      "epoch:0 step:480 [D loss: 0.576567, acc.: 73.44%] [G loss: 0.158038]\n",
      "epoch:0 step:481 [D loss: 0.540907, acc.: 80.47%] [G loss: 0.193551]\n",
      "epoch:0 step:482 [D loss: 0.594194, acc.: 67.97%] [G loss: 0.155642]\n",
      "epoch:0 step:483 [D loss: 0.532889, acc.: 80.47%] [G loss: 0.154785]\n",
      "epoch:0 step:484 [D loss: 0.515704, acc.: 79.69%] [G loss: 0.221051]\n",
      "epoch:0 step:485 [D loss: 0.549302, acc.: 76.56%] [G loss: 0.195940]\n",
      "epoch:0 step:486 [D loss: 0.555624, acc.: 77.34%] [G loss: 0.216174]\n",
      "epoch:0 step:487 [D loss: 0.600932, acc.: 64.84%] [G loss: 0.221883]\n",
      "epoch:0 step:488 [D loss: 0.627040, acc.: 63.28%] [G loss: 0.161306]\n",
      "epoch:0 step:489 [D loss: 0.645136, acc.: 58.59%] [G loss: 0.089178]\n",
      "epoch:0 step:490 [D loss: 0.581749, acc.: 70.31%] [G loss: 0.121253]\n",
      "epoch:0 step:491 [D loss: 0.571507, acc.: 71.09%] [G loss: 0.137229]\n",
      "epoch:0 step:492 [D loss: 0.537080, acc.: 76.56%] [G loss: 0.142932]\n",
      "epoch:0 step:493 [D loss: 0.539215, acc.: 71.09%] [G loss: 0.181122]\n",
      "epoch:0 step:494 [D loss: 0.569525, acc.: 71.88%] [G loss: 0.270049]\n",
      "epoch:0 step:495 [D loss: 0.599971, acc.: 69.53%] [G loss: 0.162622]\n",
      "epoch:0 step:496 [D loss: 0.588359, acc.: 68.75%] [G loss: 0.168299]\n",
      "epoch:0 step:497 [D loss: 0.564338, acc.: 75.00%] [G loss: 0.179471]\n",
      "epoch:0 step:498 [D loss: 0.540453, acc.: 76.56%] [G loss: 0.159058]\n",
      "epoch:0 step:499 [D loss: 0.545789, acc.: 75.00%] [G loss: 0.214796]\n",
      "epoch:0 step:500 [D loss: 0.648025, acc.: 55.47%] [G loss: 0.135410]\n",
      "epoch:0 step:501 [D loss: 0.605354, acc.: 66.41%] [G loss: 0.104888]\n",
      "epoch:0 step:502 [D loss: 0.589040, acc.: 74.22%] [G loss: 0.125396]\n",
      "epoch:0 step:503 [D loss: 0.626414, acc.: 61.72%] [G loss: 0.113422]\n",
      "epoch:0 step:504 [D loss: 0.587018, acc.: 71.88%] [G loss: 0.121357]\n",
      "epoch:0 step:505 [D loss: 0.564979, acc.: 72.66%] [G loss: 0.160171]\n",
      "epoch:0 step:506 [D loss: 0.539095, acc.: 81.25%] [G loss: 0.169150]\n",
      "epoch:0 step:507 [D loss: 0.572293, acc.: 71.09%] [G loss: 0.171912]\n",
      "epoch:0 step:508 [D loss: 0.533656, acc.: 78.12%] [G loss: 0.233317]\n",
      "epoch:0 step:509 [D loss: 0.627368, acc.: 71.09%] [G loss: 0.142798]\n",
      "epoch:0 step:510 [D loss: 0.585523, acc.: 75.00%] [G loss: 0.124078]\n",
      "epoch:0 step:511 [D loss: 0.589630, acc.: 68.75%] [G loss: 0.089261]\n",
      "epoch:0 step:512 [D loss: 0.528728, acc.: 75.78%] [G loss: 0.110422]\n",
      "epoch:0 step:513 [D loss: 0.549289, acc.: 72.66%] [G loss: 0.153063]\n",
      "epoch:0 step:514 [D loss: 0.579444, acc.: 74.22%] [G loss: 0.142350]\n",
      "epoch:0 step:515 [D loss: 0.565503, acc.: 73.44%] [G loss: 0.183827]\n",
      "epoch:0 step:516 [D loss: 0.555387, acc.: 75.78%] [G loss: 0.164328]\n",
      "epoch:0 step:517 [D loss: 0.628398, acc.: 59.38%] [G loss: 0.120699]\n",
      "epoch:0 step:518 [D loss: 0.584639, acc.: 65.62%] [G loss: 0.116556]\n",
      "epoch:0 step:519 [D loss: 0.574814, acc.: 73.44%] [G loss: 0.145298]\n",
      "epoch:0 step:520 [D loss: 0.548902, acc.: 76.56%] [G loss: 0.150180]\n",
      "epoch:0 step:521 [D loss: 0.599360, acc.: 68.75%] [G loss: 0.125792]\n",
      "epoch:0 step:522 [D loss: 0.561312, acc.: 67.97%] [G loss: 0.162915]\n",
      "epoch:0 step:523 [D loss: 0.557660, acc.: 71.88%] [G loss: 0.190152]\n",
      "epoch:0 step:524 [D loss: 0.625600, acc.: 64.06%] [G loss: 0.144843]\n",
      "epoch:0 step:525 [D loss: 0.595915, acc.: 68.75%] [G loss: 0.117786]\n",
      "epoch:0 step:526 [D loss: 0.568310, acc.: 71.09%] [G loss: 0.137735]\n",
      "epoch:0 step:527 [D loss: 0.526976, acc.: 85.16%] [G loss: 0.174582]\n",
      "epoch:0 step:528 [D loss: 0.552271, acc.: 66.41%] [G loss: 0.185127]\n",
      "epoch:0 step:529 [D loss: 0.531711, acc.: 80.47%] [G loss: 0.219645]\n",
      "epoch:0 step:530 [D loss: 0.568496, acc.: 72.66%] [G loss: 0.156072]\n",
      "epoch:0 step:531 [D loss: 0.610009, acc.: 67.97%] [G loss: 0.140104]\n",
      "epoch:0 step:532 [D loss: 0.549968, acc.: 77.34%] [G loss: 0.157552]\n",
      "epoch:0 step:533 [D loss: 0.532946, acc.: 82.03%] [G loss: 0.208368]\n",
      "epoch:0 step:534 [D loss: 0.581941, acc.: 71.09%] [G loss: 0.179685]\n",
      "epoch:0 step:535 [D loss: 0.600335, acc.: 68.75%] [G loss: 0.140660]\n",
      "epoch:0 step:536 [D loss: 0.602386, acc.: 64.84%] [G loss: 0.137343]\n",
      "epoch:0 step:537 [D loss: 0.574261, acc.: 71.09%] [G loss: 0.200073]\n",
      "epoch:0 step:538 [D loss: 0.598064, acc.: 69.53%] [G loss: 0.109603]\n",
      "epoch:0 step:539 [D loss: 0.610843, acc.: 71.88%] [G loss: 0.129340]\n",
      "epoch:0 step:540 [D loss: 0.590794, acc.: 67.97%] [G loss: 0.150721]\n",
      "epoch:0 step:541 [D loss: 0.564556, acc.: 71.88%] [G loss: 0.154042]\n",
      "epoch:0 step:542 [D loss: 0.650186, acc.: 64.06%] [G loss: 0.135318]\n",
      "epoch:0 step:543 [D loss: 0.584589, acc.: 75.78%] [G loss: 0.150136]\n",
      "epoch:0 step:544 [D loss: 0.561745, acc.: 76.56%] [G loss: 0.143479]\n",
      "epoch:0 step:545 [D loss: 0.553429, acc.: 75.00%] [G loss: 0.150815]\n",
      "epoch:0 step:546 [D loss: 0.540039, acc.: 74.22%] [G loss: 0.189407]\n",
      "epoch:0 step:547 [D loss: 0.524820, acc.: 82.81%] [G loss: 0.200189]\n",
      "epoch:0 step:548 [D loss: 0.557015, acc.: 71.88%] [G loss: 0.182535]\n",
      "epoch:0 step:549 [D loss: 0.574068, acc.: 68.75%] [G loss: 0.192912]\n",
      "epoch:0 step:550 [D loss: 0.553483, acc.: 73.44%] [G loss: 0.248244]\n",
      "epoch:0 step:551 [D loss: 0.558589, acc.: 75.78%] [G loss: 0.204141]\n",
      "epoch:0 step:552 [D loss: 0.564837, acc.: 67.97%] [G loss: 0.207569]\n",
      "epoch:0 step:553 [D loss: 0.595716, acc.: 64.84%] [G loss: 0.142107]\n",
      "epoch:0 step:554 [D loss: 0.543953, acc.: 76.56%] [G loss: 0.212879]\n",
      "epoch:0 step:555 [D loss: 0.596675, acc.: 68.75%] [G loss: 0.156969]\n",
      "epoch:0 step:556 [D loss: 0.520061, acc.: 82.81%] [G loss: 0.211144]\n",
      "epoch:0 step:557 [D loss: 0.567476, acc.: 70.31%] [G loss: 0.155288]\n",
      "epoch:0 step:558 [D loss: 0.587802, acc.: 72.66%] [G loss: 0.130441]\n",
      "epoch:0 step:559 [D loss: 0.664295, acc.: 60.94%] [G loss: 0.099777]\n",
      "epoch:0 step:560 [D loss: 0.576973, acc.: 67.97%] [G loss: 0.119379]\n",
      "epoch:0 step:561 [D loss: 0.613579, acc.: 66.41%] [G loss: 0.101368]\n",
      "epoch:0 step:562 [D loss: 0.559738, acc.: 74.22%] [G loss: 0.131222]\n",
      "epoch:0 step:563 [D loss: 0.592623, acc.: 69.53%] [G loss: 0.124697]\n",
      "epoch:0 step:564 [D loss: 0.530657, acc.: 74.22%] [G loss: 0.165784]\n",
      "epoch:0 step:565 [D loss: 0.597402, acc.: 70.31%] [G loss: 0.152431]\n",
      "epoch:0 step:566 [D loss: 0.595953, acc.: 74.22%] [G loss: 0.144506]\n",
      "epoch:0 step:567 [D loss: 0.564542, acc.: 80.47%] [G loss: 0.156619]\n",
      "epoch:0 step:568 [D loss: 0.586493, acc.: 74.22%] [G loss: 0.166241]\n",
      "epoch:0 step:569 [D loss: 0.585014, acc.: 70.31%] [G loss: 0.127423]\n",
      "epoch:0 step:570 [D loss: 0.579902, acc.: 68.75%] [G loss: 0.119910]\n",
      "epoch:0 step:571 [D loss: 0.545646, acc.: 77.34%] [G loss: 0.154516]\n",
      "epoch:0 step:572 [D loss: 0.559370, acc.: 76.56%] [G loss: 0.153669]\n",
      "epoch:0 step:573 [D loss: 0.567934, acc.: 74.22%] [G loss: 0.143006]\n",
      "epoch:0 step:574 [D loss: 0.545136, acc.: 79.69%] [G loss: 0.149892]\n",
      "epoch:0 step:575 [D loss: 0.542466, acc.: 75.78%] [G loss: 0.200923]\n",
      "epoch:0 step:576 [D loss: 0.578622, acc.: 79.69%] [G loss: 0.129871]\n",
      "epoch:0 step:577 [D loss: 0.605282, acc.: 70.31%] [G loss: 0.086670]\n",
      "epoch:0 step:578 [D loss: 0.548943, acc.: 77.34%] [G loss: 0.120937]\n",
      "epoch:0 step:579 [D loss: 0.540521, acc.: 79.69%] [G loss: 0.148725]\n",
      "epoch:0 step:580 [D loss: 0.526729, acc.: 80.47%] [G loss: 0.231624]\n",
      "epoch:0 step:581 [D loss: 0.544243, acc.: 79.69%] [G loss: 0.217920]\n",
      "epoch:0 step:582 [D loss: 0.511705, acc.: 79.69%] [G loss: 0.226370]\n",
      "epoch:0 step:583 [D loss: 0.595296, acc.: 72.66%] [G loss: 0.182158]\n",
      "epoch:0 step:584 [D loss: 0.628433, acc.: 59.38%] [G loss: 0.094731]\n",
      "epoch:0 step:585 [D loss: 0.561729, acc.: 72.66%] [G loss: 0.154998]\n",
      "epoch:0 step:586 [D loss: 0.609213, acc.: 67.97%] [G loss: 0.118832]\n",
      "epoch:0 step:587 [D loss: 0.656467, acc.: 55.47%] [G loss: 0.067178]\n",
      "epoch:0 step:588 [D loss: 0.590639, acc.: 67.19%] [G loss: 0.097395]\n",
      "epoch:0 step:589 [D loss: 0.571457, acc.: 72.66%] [G loss: 0.099632]\n",
      "epoch:0 step:590 [D loss: 0.545247, acc.: 80.47%] [G loss: 0.126151]\n",
      "epoch:0 step:591 [D loss: 0.582277, acc.: 72.66%] [G loss: 0.142565]\n",
      "epoch:0 step:592 [D loss: 0.552704, acc.: 81.25%] [G loss: 0.139640]\n",
      "epoch:0 step:593 [D loss: 0.540192, acc.: 84.38%] [G loss: 0.135369]\n",
      "epoch:0 step:594 [D loss: 0.536007, acc.: 84.38%] [G loss: 0.152998]\n",
      "epoch:0 step:595 [D loss: 0.533883, acc.: 80.47%] [G loss: 0.159392]\n",
      "epoch:0 step:596 [D loss: 0.551468, acc.: 72.66%] [G loss: 0.205029]\n",
      "epoch:0 step:597 [D loss: 0.565302, acc.: 75.78%] [G loss: 0.155604]\n",
      "epoch:0 step:598 [D loss: 0.533304, acc.: 82.81%] [G loss: 0.187923]\n",
      "epoch:0 step:599 [D loss: 0.553448, acc.: 74.22%] [G loss: 0.174092]\n",
      "epoch:0 step:600 [D loss: 0.607732, acc.: 66.41%] [G loss: 0.107475]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[ 6.54562458  5.49636697 10.17465056  8.36821754  7.95029813  9.15025789\n",
      "  8.33335574  8.63269647  8.86046557  7.042351  ]\n",
      "##########\n",
      "epoch:0 step:601 [D loss: 0.550164, acc.: 82.03%] [G loss: 0.138154]\n",
      "epoch:0 step:602 [D loss: 0.517775, acc.: 84.38%] [G loss: 0.150086]\n",
      "epoch:0 step:603 [D loss: 0.553686, acc.: 75.78%] [G loss: 0.157847]\n",
      "epoch:0 step:604 [D loss: 0.576748, acc.: 80.47%] [G loss: 0.143318]\n",
      "epoch:0 step:605 [D loss: 0.547717, acc.: 75.00%] [G loss: 0.122918]\n",
      "epoch:0 step:606 [D loss: 0.534915, acc.: 82.81%] [G loss: 0.138700]\n",
      "epoch:0 step:607 [D loss: 0.578675, acc.: 72.66%] [G loss: 0.128398]\n",
      "epoch:0 step:608 [D loss: 0.548890, acc.: 80.47%] [G loss: 0.138817]\n",
      "epoch:0 step:609 [D loss: 0.552330, acc.: 79.69%] [G loss: 0.136909]\n",
      "epoch:0 step:610 [D loss: 0.553038, acc.: 70.31%] [G loss: 0.133803]\n",
      "epoch:0 step:611 [D loss: 0.513631, acc.: 83.59%] [G loss: 0.199901]\n",
      "epoch:0 step:612 [D loss: 0.515352, acc.: 87.50%] [G loss: 0.184392]\n",
      "epoch:0 step:613 [D loss: 0.523045, acc.: 82.81%] [G loss: 0.165677]\n",
      "epoch:0 step:614 [D loss: 0.517639, acc.: 84.38%] [G loss: 0.176532]\n",
      "epoch:0 step:615 [D loss: 0.586390, acc.: 79.69%] [G loss: 0.126664]\n",
      "epoch:0 step:616 [D loss: 0.553069, acc.: 75.78%] [G loss: 0.143409]\n",
      "epoch:0 step:617 [D loss: 0.530379, acc.: 80.47%] [G loss: 0.173077]\n",
      "epoch:0 step:618 [D loss: 0.550411, acc.: 75.78%] [G loss: 0.178260]\n",
      "epoch:0 step:619 [D loss: 0.518595, acc.: 81.25%] [G loss: 0.214973]\n",
      "epoch:0 step:620 [D loss: 0.593331, acc.: 73.44%] [G loss: 0.129267]\n",
      "epoch:0 step:621 [D loss: 0.585129, acc.: 72.66%] [G loss: 0.100293]\n",
      "epoch:0 step:622 [D loss: 0.599473, acc.: 72.66%] [G loss: 0.105407]\n",
      "epoch:0 step:623 [D loss: 0.560824, acc.: 66.41%] [G loss: 0.145238]\n",
      "epoch:0 step:624 [D loss: 0.553784, acc.: 73.44%] [G loss: 0.163672]\n",
      "epoch:0 step:625 [D loss: 0.563878, acc.: 75.78%] [G loss: 0.187652]\n",
      "epoch:0 step:626 [D loss: 0.543272, acc.: 82.03%] [G loss: 0.164933]\n",
      "epoch:0 step:627 [D loss: 0.530653, acc.: 79.69%] [G loss: 0.169607]\n",
      "epoch:0 step:628 [D loss: 0.527043, acc.: 78.12%] [G loss: 0.219855]\n",
      "epoch:0 step:629 [D loss: 0.532655, acc.: 82.03%] [G loss: 0.156973]\n",
      "epoch:0 step:630 [D loss: 0.555315, acc.: 76.56%] [G loss: 0.128063]\n",
      "epoch:0 step:631 [D loss: 0.556519, acc.: 73.44%] [G loss: 0.171240]\n",
      "epoch:0 step:632 [D loss: 0.537346, acc.: 79.69%] [G loss: 0.208320]\n",
      "epoch:0 step:633 [D loss: 0.519363, acc.: 81.25%] [G loss: 0.245264]\n",
      "epoch:0 step:634 [D loss: 0.573536, acc.: 75.78%] [G loss: 0.201207]\n",
      "epoch:0 step:635 [D loss: 0.581478, acc.: 68.75%] [G loss: 0.168006]\n",
      "epoch:0 step:636 [D loss: 0.603419, acc.: 70.31%] [G loss: 0.140851]\n",
      "epoch:0 step:637 [D loss: 0.574510, acc.: 72.66%] [G loss: 0.129879]\n",
      "epoch:0 step:638 [D loss: 0.519870, acc.: 75.78%] [G loss: 0.165226]\n",
      "epoch:0 step:639 [D loss: 0.579855, acc.: 77.34%] [G loss: 0.129483]\n",
      "epoch:0 step:640 [D loss: 0.582974, acc.: 69.53%] [G loss: 0.129804]\n",
      "epoch:0 step:641 [D loss: 0.580085, acc.: 69.53%] [G loss: 0.171117]\n",
      "epoch:0 step:642 [D loss: 0.558453, acc.: 77.34%] [G loss: 0.194179]\n",
      "epoch:0 step:643 [D loss: 0.566248, acc.: 77.34%] [G loss: 0.132260]\n",
      "epoch:0 step:644 [D loss: 0.557330, acc.: 77.34%] [G loss: 0.113754]\n",
      "epoch:0 step:645 [D loss: 0.530268, acc.: 82.03%] [G loss: 0.156418]\n",
      "epoch:0 step:646 [D loss: 0.547405, acc.: 78.91%] [G loss: 0.156360]\n",
      "epoch:0 step:647 [D loss: 0.585044, acc.: 67.19%] [G loss: 0.151530]\n",
      "epoch:0 step:648 [D loss: 0.526536, acc.: 78.91%] [G loss: 0.204582]\n",
      "epoch:0 step:649 [D loss: 0.516154, acc.: 84.38%] [G loss: 0.246213]\n",
      "epoch:0 step:650 [D loss: 0.564272, acc.: 77.34%] [G loss: 0.208952]\n",
      "epoch:0 step:651 [D loss: 0.568936, acc.: 75.00%] [G loss: 0.130399]\n",
      "epoch:0 step:652 [D loss: 0.613791, acc.: 65.62%] [G loss: 0.123232]\n",
      "epoch:0 step:653 [D loss: 0.546732, acc.: 74.22%] [G loss: 0.170837]\n",
      "epoch:0 step:654 [D loss: 0.520651, acc.: 80.47%] [G loss: 0.232445]\n",
      "epoch:0 step:655 [D loss: 0.603169, acc.: 69.53%] [G loss: 0.176952]\n",
      "epoch:0 step:656 [D loss: 0.572710, acc.: 75.78%] [G loss: 0.157119]\n",
      "epoch:0 step:657 [D loss: 0.577129, acc.: 70.31%] [G loss: 0.156028]\n",
      "epoch:0 step:658 [D loss: 0.516844, acc.: 85.16%] [G loss: 0.184282]\n",
      "epoch:0 step:659 [D loss: 0.554921, acc.: 78.91%] [G loss: 0.170350]\n",
      "epoch:0 step:660 [D loss: 0.536297, acc.: 85.94%] [G loss: 0.187988]\n",
      "epoch:0 step:661 [D loss: 0.504546, acc.: 85.16%] [G loss: 0.180394]\n",
      "epoch:0 step:662 [D loss: 0.609236, acc.: 69.53%] [G loss: 0.134461]\n",
      "epoch:0 step:663 [D loss: 0.544172, acc.: 75.78%] [G loss: 0.131337]\n",
      "epoch:0 step:664 [D loss: 0.523370, acc.: 82.03%] [G loss: 0.172142]\n",
      "epoch:0 step:665 [D loss: 0.575658, acc.: 72.66%] [G loss: 0.172971]\n",
      "epoch:0 step:666 [D loss: 0.501689, acc.: 80.47%] [G loss: 0.215233]\n",
      "epoch:0 step:667 [D loss: 0.545724, acc.: 78.91%] [G loss: 0.214599]\n",
      "epoch:0 step:668 [D loss: 0.535911, acc.: 83.59%] [G loss: 0.162859]\n",
      "epoch:0 step:669 [D loss: 0.548874, acc.: 77.34%] [G loss: 0.172461]\n",
      "epoch:0 step:670 [D loss: 0.528149, acc.: 82.03%] [G loss: 0.184251]\n",
      "epoch:0 step:671 [D loss: 0.582320, acc.: 71.09%] [G loss: 0.145896]\n",
      "epoch:0 step:672 [D loss: 0.561539, acc.: 81.25%] [G loss: 0.120872]\n",
      "epoch:0 step:673 [D loss: 0.515299, acc.: 84.38%] [G loss: 0.143381]\n",
      "epoch:0 step:674 [D loss: 0.520785, acc.: 81.25%] [G loss: 0.158240]\n",
      "epoch:0 step:675 [D loss: 0.518380, acc.: 85.16%] [G loss: 0.194935]\n",
      "epoch:0 step:676 [D loss: 0.490759, acc.: 82.03%] [G loss: 0.231180]\n",
      "epoch:0 step:677 [D loss: 0.488499, acc.: 85.16%] [G loss: 0.243392]\n",
      "epoch:0 step:678 [D loss: 0.571967, acc.: 73.44%] [G loss: 0.197129]\n",
      "epoch:0 step:679 [D loss: 0.540820, acc.: 81.25%] [G loss: 0.198657]\n",
      "epoch:0 step:680 [D loss: 0.482556, acc.: 89.06%] [G loss: 0.228465]\n",
      "epoch:0 step:681 [D loss: 0.559005, acc.: 78.12%] [G loss: 0.178489]\n",
      "epoch:0 step:682 [D loss: 0.591968, acc.: 71.09%] [G loss: 0.160853]\n",
      "epoch:0 step:683 [D loss: 0.541988, acc.: 78.12%] [G loss: 0.161630]\n",
      "epoch:0 step:684 [D loss: 0.543270, acc.: 77.34%] [G loss: 0.206346]\n",
      "epoch:0 step:685 [D loss: 0.559410, acc.: 78.91%] [G loss: 0.195657]\n",
      "epoch:0 step:686 [D loss: 0.581639, acc.: 70.31%] [G loss: 0.140599]\n",
      "epoch:0 step:687 [D loss: 0.538046, acc.: 73.44%] [G loss: 0.223099]\n",
      "epoch:0 step:688 [D loss: 0.573256, acc.: 72.66%] [G loss: 0.184917]\n",
      "epoch:0 step:689 [D loss: 0.558762, acc.: 78.12%] [G loss: 0.213592]\n",
      "epoch:0 step:690 [D loss: 0.543255, acc.: 76.56%] [G loss: 0.208925]\n",
      "epoch:0 step:691 [D loss: 0.623165, acc.: 61.72%] [G loss: 0.153672]\n",
      "epoch:0 step:692 [D loss: 0.611487, acc.: 67.19%] [G loss: 0.210015]\n",
      "epoch:0 step:693 [D loss: 0.559605, acc.: 73.44%] [G loss: 0.213578]\n",
      "epoch:0 step:694 [D loss: 0.562482, acc.: 75.00%] [G loss: 0.212908]\n",
      "epoch:0 step:695 [D loss: 0.610225, acc.: 67.19%] [G loss: 0.185346]\n",
      "epoch:0 step:696 [D loss: 0.584232, acc.: 75.00%] [G loss: 0.175377]\n",
      "epoch:0 step:697 [D loss: 0.603795, acc.: 67.97%] [G loss: 0.212621]\n",
      "epoch:0 step:698 [D loss: 0.570269, acc.: 76.56%] [G loss: 0.176894]\n",
      "epoch:0 step:699 [D loss: 0.567696, acc.: 77.34%] [G loss: 0.165382]\n",
      "epoch:0 step:700 [D loss: 0.565675, acc.: 81.25%] [G loss: 0.245603]\n",
      "epoch:0 step:701 [D loss: 0.558443, acc.: 75.78%] [G loss: 0.262762]\n",
      "epoch:0 step:702 [D loss: 0.597030, acc.: 71.09%] [G loss: 0.173433]\n",
      "epoch:0 step:703 [D loss: 0.596364, acc.: 70.31%] [G loss: 0.125694]\n",
      "epoch:0 step:704 [D loss: 0.619477, acc.: 63.28%] [G loss: 0.138920]\n",
      "epoch:0 step:705 [D loss: 0.536307, acc.: 81.25%] [G loss: 0.166935]\n",
      "epoch:0 step:706 [D loss: 0.569916, acc.: 75.78%] [G loss: 0.204049]\n",
      "epoch:0 step:707 [D loss: 0.523450, acc.: 86.72%] [G loss: 0.276784]\n",
      "epoch:0 step:708 [D loss: 0.513869, acc.: 83.59%] [G loss: 0.304314]\n",
      "epoch:0 step:709 [D loss: 0.525292, acc.: 83.59%] [G loss: 0.213132]\n",
      "epoch:0 step:710 [D loss: 0.648157, acc.: 60.16%] [G loss: 0.097363]\n",
      "epoch:0 step:711 [D loss: 0.546408, acc.: 78.91%] [G loss: 0.120736]\n",
      "epoch:0 step:712 [D loss: 0.533659, acc.: 73.44%] [G loss: 0.223126]\n",
      "epoch:0 step:713 [D loss: 0.499911, acc.: 89.84%] [G loss: 0.299819]\n",
      "epoch:0 step:714 [D loss: 0.520267, acc.: 88.28%] [G loss: 0.204543]\n",
      "epoch:0 step:715 [D loss: 0.582308, acc.: 71.09%] [G loss: 0.143268]\n",
      "epoch:0 step:716 [D loss: 0.567396, acc.: 72.66%] [G loss: 0.169704]\n",
      "epoch:0 step:717 [D loss: 0.579556, acc.: 77.34%] [G loss: 0.170510]\n",
      "epoch:0 step:718 [D loss: 0.525172, acc.: 86.72%] [G loss: 0.207457]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:719 [D loss: 0.549872, acc.: 77.34%] [G loss: 0.204525]\n",
      "epoch:0 step:720 [D loss: 0.533885, acc.: 78.91%] [G loss: 0.166249]\n",
      "epoch:0 step:721 [D loss: 0.501493, acc.: 84.38%] [G loss: 0.189109]\n",
      "epoch:0 step:722 [D loss: 0.493557, acc.: 85.94%] [G loss: 0.230134]\n",
      "epoch:0 step:723 [D loss: 0.537062, acc.: 85.16%] [G loss: 0.199070]\n",
      "epoch:0 step:724 [D loss: 0.521446, acc.: 82.81%] [G loss: 0.209453]\n",
      "epoch:0 step:725 [D loss: 0.564234, acc.: 78.91%] [G loss: 0.179645]\n",
      "epoch:0 step:726 [D loss: 0.529675, acc.: 84.38%] [G loss: 0.231759]\n",
      "epoch:0 step:727 [D loss: 0.569648, acc.: 79.69%] [G loss: 0.158093]\n",
      "epoch:0 step:728 [D loss: 0.512155, acc.: 86.72%] [G loss: 0.169772]\n",
      "epoch:0 step:729 [D loss: 0.532380, acc.: 81.25%] [G loss: 0.163267]\n",
      "epoch:0 step:730 [D loss: 0.524060, acc.: 78.91%] [G loss: 0.168423]\n",
      "epoch:0 step:731 [D loss: 0.506214, acc.: 85.94%] [G loss: 0.195261]\n",
      "epoch:0 step:732 [D loss: 0.540081, acc.: 83.59%] [G loss: 0.193979]\n",
      "epoch:0 step:733 [D loss: 0.524967, acc.: 82.03%] [G loss: 0.198043]\n",
      "epoch:0 step:734 [D loss: 0.541528, acc.: 82.81%] [G loss: 0.161136]\n",
      "epoch:0 step:735 [D loss: 0.559123, acc.: 76.56%] [G loss: 0.143548]\n",
      "epoch:0 step:736 [D loss: 0.477880, acc.: 93.75%] [G loss: 0.212832]\n",
      "epoch:0 step:737 [D loss: 0.519389, acc.: 82.81%] [G loss: 0.186969]\n",
      "epoch:0 step:738 [D loss: 0.521865, acc.: 82.81%] [G loss: 0.171413]\n",
      "epoch:0 step:739 [D loss: 0.539220, acc.: 82.81%] [G loss: 0.173539]\n",
      "epoch:0 step:740 [D loss: 0.527415, acc.: 81.25%] [G loss: 0.173190]\n",
      "epoch:0 step:741 [D loss: 0.491665, acc.: 91.41%] [G loss: 0.201801]\n",
      "epoch:0 step:742 [D loss: 0.503537, acc.: 89.06%] [G loss: 0.205251]\n",
      "epoch:0 step:743 [D loss: 0.490487, acc.: 89.06%] [G loss: 0.218908]\n",
      "epoch:0 step:744 [D loss: 0.511597, acc.: 82.81%] [G loss: 0.261369]\n",
      "epoch:0 step:745 [D loss: 0.553280, acc.: 79.69%] [G loss: 0.209702]\n",
      "epoch:0 step:746 [D loss: 0.515706, acc.: 89.84%] [G loss: 0.171960]\n",
      "epoch:0 step:747 [D loss: 0.459295, acc.: 89.84%] [G loss: 0.224991]\n",
      "epoch:0 step:748 [D loss: 0.501498, acc.: 86.72%] [G loss: 0.208044]\n",
      "epoch:0 step:749 [D loss: 0.465646, acc.: 90.62%] [G loss: 0.276593]\n",
      "epoch:0 step:750 [D loss: 0.482110, acc.: 87.50%] [G loss: 0.264326]\n",
      "epoch:0 step:751 [D loss: 0.518052, acc.: 84.38%] [G loss: 0.243185]\n",
      "epoch:0 step:752 [D loss: 0.517057, acc.: 80.47%] [G loss: 0.224517]\n",
      "epoch:0 step:753 [D loss: 0.480427, acc.: 90.62%] [G loss: 0.287676]\n",
      "epoch:0 step:754 [D loss: 0.476893, acc.: 92.19%] [G loss: 0.273800]\n",
      "epoch:0 step:755 [D loss: 0.514678, acc.: 82.81%] [G loss: 0.262844]\n",
      "epoch:0 step:756 [D loss: 0.510197, acc.: 84.38%] [G loss: 0.281170]\n",
      "epoch:0 step:757 [D loss: 0.517750, acc.: 81.25%] [G loss: 0.247116]\n",
      "epoch:0 step:758 [D loss: 0.507583, acc.: 83.59%] [G loss: 0.236857]\n",
      "epoch:0 step:759 [D loss: 0.522435, acc.: 84.38%] [G loss: 0.233082]\n",
      "epoch:0 step:760 [D loss: 0.489250, acc.: 85.16%] [G loss: 0.253003]\n",
      "epoch:0 step:761 [D loss: 0.521970, acc.: 78.91%] [G loss: 0.213846]\n",
      "epoch:0 step:762 [D loss: 0.508380, acc.: 79.69%] [G loss: 0.233267]\n",
      "epoch:0 step:763 [D loss: 0.492718, acc.: 83.59%] [G loss: 0.321731]\n",
      "epoch:0 step:764 [D loss: 0.517462, acc.: 85.94%] [G loss: 0.292756]\n",
      "epoch:0 step:765 [D loss: 0.633864, acc.: 63.28%] [G loss: 0.175517]\n",
      "epoch:0 step:766 [D loss: 0.587922, acc.: 64.84%] [G loss: 0.230938]\n",
      "epoch:0 step:767 [D loss: 0.520407, acc.: 79.69%] [G loss: 0.251886]\n",
      "epoch:0 step:768 [D loss: 0.538966, acc.: 77.34%] [G loss: 0.267674]\n",
      "epoch:0 step:769 [D loss: 0.478062, acc.: 85.94%] [G loss: 0.348349]\n",
      "epoch:0 step:770 [D loss: 0.555008, acc.: 77.34%] [G loss: 0.237389]\n",
      "epoch:0 step:771 [D loss: 0.572926, acc.: 72.66%] [G loss: 0.204608]\n",
      "epoch:0 step:772 [D loss: 0.504687, acc.: 85.94%] [G loss: 0.235297]\n",
      "epoch:0 step:773 [D loss: 0.531846, acc.: 85.16%] [G loss: 0.225126]\n",
      "epoch:0 step:774 [D loss: 0.538858, acc.: 83.59%] [G loss: 0.214642]\n",
      "epoch:0 step:775 [D loss: 0.481074, acc.: 86.72%] [G loss: 0.265242]\n",
      "epoch:0 step:776 [D loss: 0.532817, acc.: 78.12%] [G loss: 0.287081]\n",
      "epoch:0 step:777 [D loss: 0.498296, acc.: 83.59%] [G loss: 0.311419]\n",
      "epoch:0 step:778 [D loss: 0.594927, acc.: 71.09%] [G loss: 0.194568]\n",
      "epoch:0 step:779 [D loss: 0.542366, acc.: 79.69%] [G loss: 0.199025]\n",
      "epoch:0 step:780 [D loss: 0.588518, acc.: 65.62%] [G loss: 0.202632]\n",
      "epoch:0 step:781 [D loss: 0.505764, acc.: 78.91%] [G loss: 0.266945]\n",
      "epoch:0 step:782 [D loss: 0.527354, acc.: 79.69%] [G loss: 0.288044]\n",
      "epoch:0 step:783 [D loss: 0.581062, acc.: 73.44%] [G loss: 0.275441]\n",
      "epoch:0 step:784 [D loss: 0.555862, acc.: 79.69%] [G loss: 0.212978]\n",
      "epoch:0 step:785 [D loss: 0.529986, acc.: 78.12%] [G loss: 0.227188]\n",
      "epoch:0 step:786 [D loss: 0.493637, acc.: 86.72%] [G loss: 0.254023]\n",
      "epoch:0 step:787 [D loss: 0.559593, acc.: 77.34%] [G loss: 0.237519]\n",
      "epoch:0 step:788 [D loss: 0.582440, acc.: 70.31%] [G loss: 0.218914]\n",
      "epoch:0 step:789 [D loss: 0.532466, acc.: 82.81%] [G loss: 0.234495]\n",
      "epoch:0 step:790 [D loss: 0.569362, acc.: 71.09%] [G loss: 0.202199]\n",
      "epoch:0 step:791 [D loss: 0.554724, acc.: 76.56%] [G loss: 0.205706]\n",
      "epoch:0 step:792 [D loss: 0.479316, acc.: 81.25%] [G loss: 0.355448]\n",
      "epoch:0 step:793 [D loss: 0.536566, acc.: 75.78%] [G loss: 0.328992]\n",
      "epoch:0 step:794 [D loss: 0.562873, acc.: 68.75%] [G loss: 0.305682]\n",
      "epoch:0 step:795 [D loss: 0.507405, acc.: 84.38%] [G loss: 0.321105]\n",
      "epoch:0 step:796 [D loss: 0.474152, acc.: 84.38%] [G loss: 0.342415]\n",
      "epoch:0 step:797 [D loss: 0.583941, acc.: 69.53%] [G loss: 0.197909]\n",
      "epoch:0 step:798 [D loss: 0.538553, acc.: 71.09%] [G loss: 0.194049]\n",
      "epoch:0 step:799 [D loss: 0.521049, acc.: 81.25%] [G loss: 0.259091]\n",
      "epoch:0 step:800 [D loss: 0.540129, acc.: 76.56%] [G loss: 0.279500]\n",
      "##############\n",
      "[ 5.76962849  4.86733474 10.03765026  8.0663719   7.22572651  9.06217915\n",
      " 10.27914699  8.20518347  8.65406646  6.89369303]\n",
      "##########\n",
      "epoch:0 step:801 [D loss: 0.490147, acc.: 85.94%] [G loss: 0.301375]\n",
      "epoch:0 step:802 [D loss: 0.476105, acc.: 85.94%] [G loss: 0.338544]\n",
      "epoch:0 step:803 [D loss: 0.491854, acc.: 88.28%] [G loss: 0.307896]\n",
      "epoch:0 step:804 [D loss: 0.563055, acc.: 72.66%] [G loss: 0.213562]\n",
      "epoch:0 step:805 [D loss: 0.538668, acc.: 75.78%] [G loss: 0.224254]\n",
      "epoch:0 step:806 [D loss: 0.532019, acc.: 78.91%] [G loss: 0.225513]\n",
      "epoch:0 step:807 [D loss: 0.556568, acc.: 71.09%] [G loss: 0.229945]\n",
      "epoch:0 step:808 [D loss: 0.524113, acc.: 78.12%] [G loss: 0.282320]\n",
      "epoch:0 step:809 [D loss: 0.542967, acc.: 80.47%] [G loss: 0.248477]\n",
      "epoch:0 step:810 [D loss: 0.519386, acc.: 80.47%] [G loss: 0.244874]\n",
      "epoch:0 step:811 [D loss: 0.580293, acc.: 66.41%] [G loss: 0.228631]\n",
      "epoch:0 step:812 [D loss: 0.550872, acc.: 76.56%] [G loss: 0.202045]\n",
      "epoch:0 step:813 [D loss: 0.536183, acc.: 82.03%] [G loss: 0.177800]\n",
      "epoch:0 step:814 [D loss: 0.479802, acc.: 83.59%] [G loss: 0.328081]\n",
      "epoch:0 step:815 [D loss: 0.560799, acc.: 75.78%] [G loss: 0.335992]\n",
      "epoch:0 step:816 [D loss: 0.448860, acc.: 90.62%] [G loss: 0.447661]\n",
      "epoch:0 step:817 [D loss: 0.505443, acc.: 80.47%] [G loss: 0.313777]\n",
      "epoch:0 step:818 [D loss: 0.539022, acc.: 78.12%] [G loss: 0.298765]\n",
      "epoch:0 step:819 [D loss: 0.512710, acc.: 79.69%] [G loss: 0.292763]\n",
      "epoch:0 step:820 [D loss: 0.580110, acc.: 71.09%] [G loss: 0.231587]\n",
      "epoch:0 step:821 [D loss: 0.549469, acc.: 74.22%] [G loss: 0.255880]\n",
      "epoch:0 step:822 [D loss: 0.507374, acc.: 84.38%] [G loss: 0.284462]\n",
      "epoch:0 step:823 [D loss: 0.565450, acc.: 71.09%] [G loss: 0.250684]\n",
      "epoch:0 step:824 [D loss: 0.559909, acc.: 73.44%] [G loss: 0.217731]\n",
      "epoch:0 step:825 [D loss: 0.504036, acc.: 78.12%] [G loss: 0.269621]\n",
      "epoch:0 step:826 [D loss: 0.527914, acc.: 78.12%] [G loss: 0.315215]\n",
      "epoch:0 step:827 [D loss: 0.523788, acc.: 78.12%] [G loss: 0.332108]\n",
      "epoch:0 step:828 [D loss: 0.578752, acc.: 70.31%] [G loss: 0.263330]\n",
      "epoch:0 step:829 [D loss: 0.536218, acc.: 75.00%] [G loss: 0.284048]\n",
      "epoch:0 step:830 [D loss: 0.511678, acc.: 77.34%] [G loss: 0.327604]\n",
      "epoch:0 step:831 [D loss: 0.595971, acc.: 67.97%] [G loss: 0.222889]\n",
      "epoch:0 step:832 [D loss: 0.503789, acc.: 77.34%] [G loss: 0.305156]\n",
      "epoch:0 step:833 [D loss: 0.606702, acc.: 65.62%] [G loss: 0.255053]\n",
      "epoch:0 step:834 [D loss: 0.608735, acc.: 60.16%] [G loss: 0.229412]\n",
      "epoch:0 step:835 [D loss: 0.547645, acc.: 72.66%] [G loss: 0.231419]\n",
      "epoch:0 step:836 [D loss: 0.558467, acc.: 68.75%] [G loss: 0.235907]\n",
      "epoch:0 step:837 [D loss: 0.551309, acc.: 73.44%] [G loss: 0.393108]\n",
      "epoch:0 step:838 [D loss: 0.502975, acc.: 79.69%] [G loss: 0.359586]\n",
      "epoch:0 step:839 [D loss: 0.553363, acc.: 71.09%] [G loss: 0.301166]\n",
      "epoch:0 step:840 [D loss: 0.566906, acc.: 67.19%] [G loss: 0.303962]\n",
      "epoch:0 step:841 [D loss: 0.541266, acc.: 72.66%] [G loss: 0.391694]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:842 [D loss: 0.576241, acc.: 68.75%] [G loss: 0.365701]\n",
      "epoch:0 step:843 [D loss: 0.681479, acc.: 59.38%] [G loss: 0.194789]\n",
      "epoch:0 step:844 [D loss: 0.620253, acc.: 56.25%] [G loss: 0.208559]\n",
      "epoch:0 step:845 [D loss: 0.602774, acc.: 71.88%] [G loss: 0.269389]\n",
      "epoch:0 step:846 [D loss: 0.576490, acc.: 72.66%] [G loss: 0.221779]\n",
      "epoch:0 step:847 [D loss: 0.554236, acc.: 75.78%] [G loss: 0.248640]\n",
      "epoch:0 step:848 [D loss: 0.562405, acc.: 75.78%] [G loss: 0.295268]\n",
      "epoch:0 step:849 [D loss: 0.590159, acc.: 69.53%] [G loss: 0.290623]\n",
      "epoch:0 step:850 [D loss: 0.562576, acc.: 69.53%] [G loss: 0.264147]\n",
      "epoch:0 step:851 [D loss: 0.551591, acc.: 75.00%] [G loss: 0.309667]\n",
      "epoch:0 step:852 [D loss: 0.532190, acc.: 81.25%] [G loss: 0.299333]\n",
      "epoch:0 step:853 [D loss: 0.516714, acc.: 84.38%] [G loss: 0.352055]\n",
      "epoch:0 step:854 [D loss: 0.531904, acc.: 82.81%] [G loss: 0.352072]\n",
      "epoch:0 step:855 [D loss: 0.537023, acc.: 80.47%] [G loss: 0.324180]\n",
      "epoch:0 step:856 [D loss: 0.537095, acc.: 77.34%] [G loss: 0.319941]\n",
      "epoch:0 step:857 [D loss: 0.537807, acc.: 79.69%] [G loss: 0.301679]\n",
      "epoch:0 step:858 [D loss: 0.682725, acc.: 52.34%] [G loss: 0.160961]\n",
      "epoch:0 step:859 [D loss: 0.564000, acc.: 67.97%] [G loss: 0.224857]\n",
      "epoch:0 step:860 [D loss: 0.504096, acc.: 85.94%] [G loss: 0.291688]\n",
      "epoch:0 step:861 [D loss: 0.552192, acc.: 74.22%] [G loss: 0.271825]\n",
      "epoch:0 step:862 [D loss: 0.500998, acc.: 84.38%] [G loss: 0.274652]\n",
      "epoch:0 step:863 [D loss: 0.513974, acc.: 80.47%] [G loss: 0.290723]\n",
      "epoch:0 step:864 [D loss: 0.570157, acc.: 72.66%] [G loss: 0.249658]\n",
      "epoch:0 step:865 [D loss: 0.522737, acc.: 82.81%] [G loss: 0.231790]\n",
      "epoch:0 step:866 [D loss: 0.531164, acc.: 82.03%] [G loss: 0.215706]\n",
      "epoch:0 step:867 [D loss: 0.557922, acc.: 73.44%] [G loss: 0.233199]\n",
      "epoch:0 step:868 [D loss: 0.543036, acc.: 73.44%] [G loss: 0.371699]\n",
      "epoch:0 step:869 [D loss: 0.531562, acc.: 83.59%] [G loss: 0.324761]\n",
      "epoch:0 step:870 [D loss: 0.557344, acc.: 75.78%] [G loss: 0.252747]\n",
      "epoch:0 step:871 [D loss: 0.532331, acc.: 79.69%] [G loss: 0.248860]\n",
      "epoch:0 step:872 [D loss: 0.531044, acc.: 75.00%] [G loss: 0.296538]\n",
      "epoch:0 step:873 [D loss: 0.589306, acc.: 69.53%] [G loss: 0.293418]\n",
      "epoch:0 step:874 [D loss: 0.587951, acc.: 71.88%] [G loss: 0.209143]\n",
      "epoch:0 step:875 [D loss: 0.546020, acc.: 75.00%] [G loss: 0.219130]\n",
      "epoch:0 step:876 [D loss: 0.577199, acc.: 77.34%] [G loss: 0.192136]\n",
      "epoch:0 step:877 [D loss: 0.527887, acc.: 82.03%] [G loss: 0.250929]\n",
      "epoch:0 step:878 [D loss: 0.512398, acc.: 77.34%] [G loss: 0.245214]\n",
      "epoch:0 step:879 [D loss: 0.588662, acc.: 67.19%] [G loss: 0.194549]\n",
      "epoch:0 step:880 [D loss: 0.598516, acc.: 64.84%] [G loss: 0.177914]\n",
      "epoch:0 step:881 [D loss: 0.522025, acc.: 79.69%] [G loss: 0.248703]\n",
      "epoch:0 step:882 [D loss: 0.546913, acc.: 76.56%] [G loss: 0.236760]\n",
      "epoch:0 step:883 [D loss: 0.615438, acc.: 67.97%] [G loss: 0.207314]\n",
      "epoch:0 step:884 [D loss: 0.621135, acc.: 62.50%] [G loss: 0.165750]\n",
      "epoch:0 step:885 [D loss: 0.524539, acc.: 80.47%] [G loss: 0.292773]\n",
      "epoch:0 step:886 [D loss: 0.514491, acc.: 85.16%] [G loss: 0.336986]\n",
      "epoch:0 step:887 [D loss: 0.522337, acc.: 78.12%] [G loss: 0.324094]\n",
      "epoch:0 step:888 [D loss: 0.509918, acc.: 78.12%] [G loss: 0.394710]\n",
      "epoch:0 step:889 [D loss: 0.554731, acc.: 72.66%] [G loss: 0.307328]\n",
      "epoch:0 step:890 [D loss: 0.558106, acc.: 76.56%] [G loss: 0.238556]\n",
      "epoch:0 step:891 [D loss: 0.629264, acc.: 62.50%] [G loss: 0.149799]\n",
      "epoch:0 step:892 [D loss: 0.625195, acc.: 60.94%] [G loss: 0.119136]\n",
      "epoch:0 step:893 [D loss: 0.619728, acc.: 59.38%] [G loss: 0.146681]\n",
      "epoch:0 step:894 [D loss: 0.544386, acc.: 78.12%] [G loss: 0.199918]\n",
      "epoch:0 step:895 [D loss: 0.587093, acc.: 71.09%] [G loss: 0.187941]\n",
      "epoch:0 step:896 [D loss: 0.565493, acc.: 70.31%] [G loss: 0.216955]\n",
      "epoch:0 step:897 [D loss: 0.519953, acc.: 82.03%] [G loss: 0.246858]\n",
      "epoch:0 step:898 [D loss: 0.549351, acc.: 75.78%] [G loss: 0.242637]\n",
      "epoch:0 step:899 [D loss: 0.576883, acc.: 73.44%] [G loss: 0.237511]\n",
      "epoch:0 step:900 [D loss: 0.546856, acc.: 78.91%] [G loss: 0.224774]\n",
      "epoch:0 step:901 [D loss: 0.547797, acc.: 77.34%] [G loss: 0.188490]\n",
      "epoch:0 step:902 [D loss: 0.612043, acc.: 67.19%] [G loss: 0.135803]\n",
      "epoch:0 step:903 [D loss: 0.564901, acc.: 74.22%] [G loss: 0.177285]\n",
      "epoch:0 step:904 [D loss: 0.568733, acc.: 70.31%] [G loss: 0.223812]\n",
      "epoch:0 step:905 [D loss: 0.584534, acc.: 71.09%] [G loss: 0.198391]\n",
      "epoch:0 step:906 [D loss: 0.596899, acc.: 64.84%] [G loss: 0.152967]\n",
      "epoch:0 step:907 [D loss: 0.576040, acc.: 69.53%] [G loss: 0.188351]\n",
      "epoch:0 step:908 [D loss: 0.506292, acc.: 84.38%] [G loss: 0.207791]\n",
      "epoch:0 step:909 [D loss: 0.466502, acc.: 89.06%] [G loss: 0.279227]\n",
      "epoch:0 step:910 [D loss: 0.557620, acc.: 68.75%] [G loss: 0.246237]\n",
      "epoch:0 step:911 [D loss: 0.539526, acc.: 74.22%] [G loss: 0.223497]\n",
      "epoch:0 step:912 [D loss: 0.526000, acc.: 81.25%] [G loss: 0.196901]\n",
      "epoch:0 step:913 [D loss: 0.531195, acc.: 83.59%] [G loss: 0.219118]\n",
      "epoch:0 step:914 [D loss: 0.506597, acc.: 78.91%] [G loss: 0.244955]\n",
      "epoch:0 step:915 [D loss: 0.561054, acc.: 78.12%] [G loss: 0.168698]\n",
      "epoch:0 step:916 [D loss: 0.517468, acc.: 82.81%] [G loss: 0.192627]\n",
      "epoch:0 step:917 [D loss: 0.516018, acc.: 75.78%] [G loss: 0.171552]\n",
      "epoch:0 step:918 [D loss: 0.473433, acc.: 85.16%] [G loss: 0.270780]\n",
      "epoch:0 step:919 [D loss: 0.511043, acc.: 79.69%] [G loss: 0.312575]\n",
      "epoch:0 step:920 [D loss: 0.645867, acc.: 61.72%] [G loss: 0.183766]\n",
      "epoch:0 step:921 [D loss: 0.508879, acc.: 80.47%] [G loss: 0.218230]\n",
      "epoch:0 step:922 [D loss: 0.558277, acc.: 77.34%] [G loss: 0.153394]\n",
      "epoch:0 step:923 [D loss: 0.493729, acc.: 85.94%] [G loss: 0.214460]\n",
      "epoch:0 step:924 [D loss: 0.499152, acc.: 87.50%] [G loss: 0.245254]\n",
      "epoch:0 step:925 [D loss: 0.487537, acc.: 82.03%] [G loss: 0.315996]\n",
      "epoch:0 step:926 [D loss: 0.504192, acc.: 85.94%] [G loss: 0.345864]\n",
      "epoch:0 step:927 [D loss: 0.520102, acc.: 79.69%] [G loss: 0.352975]\n",
      "epoch:0 step:928 [D loss: 0.627948, acc.: 70.31%] [G loss: 0.247204]\n",
      "epoch:0 step:929 [D loss: 0.444760, acc.: 88.28%] [G loss: 0.401500]\n",
      "epoch:0 step:930 [D loss: 0.502754, acc.: 74.22%] [G loss: 0.341079]\n",
      "epoch:0 step:931 [D loss: 0.596004, acc.: 73.44%] [G loss: 0.153779]\n",
      "epoch:0 step:932 [D loss: 0.523451, acc.: 82.81%] [G loss: 0.152434]\n",
      "epoch:0 step:933 [D loss: 0.472112, acc.: 84.38%] [G loss: 0.237900]\n",
      "epoch:0 step:934 [D loss: 0.480634, acc.: 83.59%] [G loss: 0.277298]\n",
      "epoch:0 step:935 [D loss: 0.433869, acc.: 89.06%] [G loss: 0.421965]\n",
      "epoch:0 step:936 [D loss: 0.378015, acc.: 95.31%] [G loss: 0.566107]\n",
      "epoch:0 step:937 [D loss: 0.532985, acc.: 82.81%] [G loss: 0.340559]\n",
      "epoch:1 step:938 [D loss: 0.550562, acc.: 69.53%] [G loss: 0.270803]\n",
      "epoch:1 step:939 [D loss: 0.489148, acc.: 80.47%] [G loss: 0.314925]\n",
      "epoch:1 step:940 [D loss: 0.558979, acc.: 77.34%] [G loss: 0.274673]\n",
      "epoch:1 step:941 [D loss: 0.542243, acc.: 74.22%] [G loss: 0.231124]\n",
      "epoch:1 step:942 [D loss: 0.529482, acc.: 70.31%] [G loss: 0.259353]\n",
      "epoch:1 step:943 [D loss: 0.553779, acc.: 73.44%] [G loss: 0.241750]\n",
      "epoch:1 step:944 [D loss: 0.510189, acc.: 76.56%] [G loss: 0.279970]\n",
      "epoch:1 step:945 [D loss: 0.498457, acc.: 80.47%] [G loss: 0.289290]\n",
      "epoch:1 step:946 [D loss: 0.533026, acc.: 74.22%] [G loss: 0.281293]\n",
      "epoch:1 step:947 [D loss: 0.515890, acc.: 75.78%] [G loss: 0.283014]\n",
      "epoch:1 step:948 [D loss: 0.497361, acc.: 85.94%] [G loss: 0.303468]\n",
      "epoch:1 step:949 [D loss: 0.560199, acc.: 75.00%] [G loss: 0.228452]\n",
      "epoch:1 step:950 [D loss: 0.537027, acc.: 76.56%] [G loss: 0.230434]\n",
      "epoch:1 step:951 [D loss: 0.525503, acc.: 75.00%] [G loss: 0.221604]\n",
      "epoch:1 step:952 [D loss: 0.537626, acc.: 75.00%] [G loss: 0.235582]\n",
      "epoch:1 step:953 [D loss: 0.488338, acc.: 78.91%] [G loss: 0.299977]\n",
      "epoch:1 step:954 [D loss: 0.547303, acc.: 73.44%] [G loss: 0.304581]\n",
      "epoch:1 step:955 [D loss: 0.584200, acc.: 70.31%] [G loss: 0.306736]\n",
      "epoch:1 step:956 [D loss: 0.573033, acc.: 77.34%] [G loss: 0.223150]\n",
      "epoch:1 step:957 [D loss: 0.607251, acc.: 68.75%] [G loss: 0.148410]\n",
      "epoch:1 step:958 [D loss: 0.530380, acc.: 77.34%] [G loss: 0.226005]\n",
      "epoch:1 step:959 [D loss: 0.463346, acc.: 87.50%] [G loss: 0.268246]\n",
      "epoch:1 step:960 [D loss: 0.562823, acc.: 76.56%] [G loss: 0.189415]\n",
      "epoch:1 step:961 [D loss: 0.547858, acc.: 72.66%] [G loss: 0.216027]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:962 [D loss: 0.581136, acc.: 72.66%] [G loss: 0.221193]\n",
      "epoch:1 step:963 [D loss: 0.563670, acc.: 71.09%] [G loss: 0.238187]\n",
      "epoch:1 step:964 [D loss: 0.548638, acc.: 72.66%] [G loss: 0.249015]\n",
      "epoch:1 step:965 [D loss: 0.566203, acc.: 74.22%] [G loss: 0.218128]\n",
      "epoch:1 step:966 [D loss: 0.521178, acc.: 81.25%] [G loss: 0.295709]\n",
      "epoch:1 step:967 [D loss: 0.524957, acc.: 82.03%] [G loss: 0.260483]\n",
      "epoch:1 step:968 [D loss: 0.547637, acc.: 78.12%] [G loss: 0.245605]\n",
      "epoch:1 step:969 [D loss: 0.517206, acc.: 82.03%] [G loss: 0.279521]\n",
      "epoch:1 step:970 [D loss: 0.521314, acc.: 82.81%] [G loss: 0.305350]\n",
      "epoch:1 step:971 [D loss: 0.551304, acc.: 79.69%] [G loss: 0.263700]\n",
      "epoch:1 step:972 [D loss: 0.560696, acc.: 75.00%] [G loss: 0.217831]\n",
      "epoch:1 step:973 [D loss: 0.536080, acc.: 79.69%] [G loss: 0.328407]\n",
      "epoch:1 step:974 [D loss: 0.608247, acc.: 69.53%] [G loss: 0.179055]\n",
      "epoch:1 step:975 [D loss: 0.638609, acc.: 60.94%] [G loss: 0.113250]\n",
      "epoch:1 step:976 [D loss: 0.529059, acc.: 82.81%] [G loss: 0.180423]\n",
      "epoch:1 step:977 [D loss: 0.525984, acc.: 78.12%] [G loss: 0.249109]\n",
      "epoch:1 step:978 [D loss: 0.519936, acc.: 82.03%] [G loss: 0.247487]\n",
      "epoch:1 step:979 [D loss: 0.547618, acc.: 80.47%] [G loss: 0.239169]\n",
      "epoch:1 step:980 [D loss: 0.547419, acc.: 76.56%] [G loss: 0.200587]\n",
      "epoch:1 step:981 [D loss: 0.592748, acc.: 67.97%] [G loss: 0.172646]\n",
      "epoch:1 step:982 [D loss: 0.535939, acc.: 81.25%] [G loss: 0.216833]\n",
      "epoch:1 step:983 [D loss: 0.562563, acc.: 72.66%] [G loss: 0.177342]\n",
      "epoch:1 step:984 [D loss: 0.551803, acc.: 78.91%] [G loss: 0.171245]\n",
      "epoch:1 step:985 [D loss: 0.566101, acc.: 77.34%] [G loss: 0.165892]\n",
      "epoch:1 step:986 [D loss: 0.537005, acc.: 77.34%] [G loss: 0.152698]\n",
      "epoch:1 step:987 [D loss: 0.516409, acc.: 82.81%] [G loss: 0.250398]\n",
      "epoch:1 step:988 [D loss: 0.535150, acc.: 75.78%] [G loss: 0.276296]\n",
      "epoch:1 step:989 [D loss: 0.531243, acc.: 84.38%] [G loss: 0.248412]\n",
      "epoch:1 step:990 [D loss: 0.516223, acc.: 76.56%] [G loss: 0.276215]\n",
      "epoch:1 step:991 [D loss: 0.526050, acc.: 78.12%] [G loss: 0.230126]\n",
      "epoch:1 step:992 [D loss: 0.535765, acc.: 78.91%] [G loss: 0.255628]\n",
      "epoch:1 step:993 [D loss: 0.551573, acc.: 79.69%] [G loss: 0.211033]\n",
      "epoch:1 step:994 [D loss: 0.584409, acc.: 75.78%] [G loss: 0.143856]\n",
      "epoch:1 step:995 [D loss: 0.530177, acc.: 86.72%] [G loss: 0.195520]\n",
      "epoch:1 step:996 [D loss: 0.527278, acc.: 79.69%] [G loss: 0.237227]\n",
      "epoch:1 step:997 [D loss: 0.528085, acc.: 80.47%] [G loss: 0.226745]\n",
      "epoch:1 step:998 [D loss: 0.514104, acc.: 82.03%] [G loss: 0.257985]\n",
      "epoch:1 step:999 [D loss: 0.562720, acc.: 74.22%] [G loss: 0.188998]\n",
      "epoch:1 step:1000 [D loss: 0.498453, acc.: 87.50%] [G loss: 0.258279]\n",
      "##############\n",
      "[5.42857217 4.41736468 9.6082246  7.47242667 7.19247062 8.62294601\n",
      " 8.01631309 8.01412297 8.21966831 6.60696683]\n",
      "##########\n",
      "epoch:1 step:1001 [D loss: 0.556132, acc.: 75.00%] [G loss: 0.192084]\n",
      "epoch:1 step:1002 [D loss: 0.535596, acc.: 79.69%] [G loss: 0.169444]\n",
      "epoch:1 step:1003 [D loss: 0.506709, acc.: 86.72%] [G loss: 0.223081]\n",
      "epoch:1 step:1004 [D loss: 0.502119, acc.: 85.16%] [G loss: 0.289504]\n",
      "epoch:1 step:1005 [D loss: 0.541059, acc.: 78.12%] [G loss: 0.290606]\n",
      "epoch:1 step:1006 [D loss: 0.567763, acc.: 75.78%] [G loss: 0.253951]\n",
      "epoch:1 step:1007 [D loss: 0.532939, acc.: 72.66%] [G loss: 0.276623]\n",
      "epoch:1 step:1008 [D loss: 0.524579, acc.: 80.47%] [G loss: 0.265951]\n",
      "epoch:1 step:1009 [D loss: 0.477378, acc.: 87.50%] [G loss: 0.303694]\n",
      "epoch:1 step:1010 [D loss: 0.521354, acc.: 82.03%] [G loss: 0.266001]\n",
      "epoch:1 step:1011 [D loss: 0.517471, acc.: 78.91%] [G loss: 0.258434]\n",
      "epoch:1 step:1012 [D loss: 0.513210, acc.: 78.91%] [G loss: 0.305606]\n",
      "epoch:1 step:1013 [D loss: 0.510738, acc.: 78.12%] [G loss: 0.331359]\n",
      "epoch:1 step:1014 [D loss: 0.490048, acc.: 85.16%] [G loss: 0.375012]\n",
      "epoch:1 step:1015 [D loss: 0.579491, acc.: 71.09%] [G loss: 0.219614]\n",
      "epoch:1 step:1016 [D loss: 0.541959, acc.: 78.91%] [G loss: 0.227534]\n",
      "epoch:1 step:1017 [D loss: 0.532582, acc.: 82.03%] [G loss: 0.223290]\n",
      "epoch:1 step:1018 [D loss: 0.536332, acc.: 81.25%] [G loss: 0.191183]\n",
      "epoch:1 step:1019 [D loss: 0.487857, acc.: 87.50%] [G loss: 0.250575]\n",
      "epoch:1 step:1020 [D loss: 0.501154, acc.: 82.81%] [G loss: 0.256113]\n",
      "epoch:1 step:1021 [D loss: 0.492351, acc.: 82.03%] [G loss: 0.253823]\n",
      "epoch:1 step:1022 [D loss: 0.505665, acc.: 79.69%] [G loss: 0.237703]\n",
      "epoch:1 step:1023 [D loss: 0.476436, acc.: 85.16%] [G loss: 0.265341]\n",
      "epoch:1 step:1024 [D loss: 0.504164, acc.: 84.38%] [G loss: 0.276048]\n",
      "epoch:1 step:1025 [D loss: 0.501709, acc.: 79.69%] [G loss: 0.304634]\n",
      "epoch:1 step:1026 [D loss: 0.520164, acc.: 77.34%] [G loss: 0.302276]\n",
      "epoch:1 step:1027 [D loss: 0.484363, acc.: 86.72%] [G loss: 0.327106]\n",
      "epoch:1 step:1028 [D loss: 0.543241, acc.: 78.12%] [G loss: 0.232868]\n",
      "epoch:1 step:1029 [D loss: 0.484871, acc.: 82.03%] [G loss: 0.292794]\n",
      "epoch:1 step:1030 [D loss: 0.482636, acc.: 84.38%] [G loss: 0.292640]\n",
      "epoch:1 step:1031 [D loss: 0.458646, acc.: 89.06%] [G loss: 0.353347]\n",
      "epoch:1 step:1032 [D loss: 0.488614, acc.: 85.16%] [G loss: 0.328963]\n",
      "epoch:1 step:1033 [D loss: 0.444952, acc.: 89.06%] [G loss: 0.367157]\n",
      "epoch:1 step:1034 [D loss: 0.539485, acc.: 76.56%] [G loss: 0.236524]\n",
      "epoch:1 step:1035 [D loss: 0.508075, acc.: 82.03%] [G loss: 0.234574]\n",
      "epoch:1 step:1036 [D loss: 0.556136, acc.: 73.44%] [G loss: 0.245893]\n",
      "epoch:1 step:1037 [D loss: 0.490296, acc.: 82.81%] [G loss: 0.274749]\n",
      "epoch:1 step:1038 [D loss: 0.538538, acc.: 75.78%] [G loss: 0.244156]\n",
      "epoch:1 step:1039 [D loss: 0.587057, acc.: 70.31%] [G loss: 0.200019]\n",
      "epoch:1 step:1040 [D loss: 0.505617, acc.: 78.12%] [G loss: 0.241788]\n",
      "epoch:1 step:1041 [D loss: 0.485729, acc.: 85.16%] [G loss: 0.306688]\n",
      "epoch:1 step:1042 [D loss: 0.602244, acc.: 65.62%] [G loss: 0.222445]\n",
      "epoch:1 step:1043 [D loss: 0.576351, acc.: 70.31%] [G loss: 0.238471]\n",
      "epoch:1 step:1044 [D loss: 0.588782, acc.: 75.00%] [G loss: 0.215574]\n",
      "epoch:1 step:1045 [D loss: 0.476561, acc.: 87.50%] [G loss: 0.271007]\n",
      "epoch:1 step:1046 [D loss: 0.519514, acc.: 88.28%] [G loss: 0.244597]\n",
      "epoch:1 step:1047 [D loss: 0.487309, acc.: 85.16%] [G loss: 0.221390]\n",
      "epoch:1 step:1048 [D loss: 0.509589, acc.: 84.38%] [G loss: 0.223568]\n",
      "epoch:1 step:1049 [D loss: 0.501540, acc.: 85.94%] [G loss: 0.255913]\n",
      "epoch:1 step:1050 [D loss: 0.560610, acc.: 76.56%] [G loss: 0.219144]\n",
      "epoch:1 step:1051 [D loss: 0.529477, acc.: 80.47%] [G loss: 0.207479]\n",
      "epoch:1 step:1052 [D loss: 0.459154, acc.: 88.28%] [G loss: 0.317655]\n",
      "epoch:1 step:1053 [D loss: 0.507809, acc.: 78.91%] [G loss: 0.372567]\n",
      "epoch:1 step:1054 [D loss: 0.557994, acc.: 71.88%] [G loss: 0.313943]\n",
      "epoch:1 step:1055 [D loss: 0.499273, acc.: 84.38%] [G loss: 0.319957]\n",
      "epoch:1 step:1056 [D loss: 0.454568, acc.: 85.16%] [G loss: 0.433481]\n",
      "epoch:1 step:1057 [D loss: 0.522338, acc.: 80.47%] [G loss: 0.309170]\n",
      "epoch:1 step:1058 [D loss: 0.521983, acc.: 78.91%] [G loss: 0.231468]\n",
      "epoch:1 step:1059 [D loss: 0.578147, acc.: 67.97%] [G loss: 0.301015]\n",
      "epoch:1 step:1060 [D loss: 0.547188, acc.: 76.56%] [G loss: 0.291363]\n",
      "epoch:1 step:1061 [D loss: 0.554219, acc.: 74.22%] [G loss: 0.232733]\n",
      "epoch:1 step:1062 [D loss: 0.539305, acc.: 80.47%] [G loss: 0.170302]\n",
      "epoch:1 step:1063 [D loss: 0.513590, acc.: 82.81%] [G loss: 0.228151]\n",
      "epoch:1 step:1064 [D loss: 0.547221, acc.: 75.78%] [G loss: 0.178892]\n",
      "epoch:1 step:1065 [D loss: 0.545047, acc.: 77.34%] [G loss: 0.217686]\n",
      "epoch:1 step:1066 [D loss: 0.495153, acc.: 84.38%] [G loss: 0.255825]\n",
      "epoch:1 step:1067 [D loss: 0.486762, acc.: 86.72%] [G loss: 0.248210]\n",
      "epoch:1 step:1068 [D loss: 0.492824, acc.: 85.94%] [G loss: 0.268026]\n",
      "epoch:1 step:1069 [D loss: 0.509600, acc.: 82.81%] [G loss: 0.257434]\n",
      "epoch:1 step:1070 [D loss: 0.512250, acc.: 85.16%] [G loss: 0.211561]\n",
      "epoch:1 step:1071 [D loss: 0.504215, acc.: 86.72%] [G loss: 0.263437]\n",
      "epoch:1 step:1072 [D loss: 0.494879, acc.: 82.81%] [G loss: 0.263910]\n",
      "epoch:1 step:1073 [D loss: 0.484419, acc.: 85.94%] [G loss: 0.285129]\n",
      "epoch:1 step:1074 [D loss: 0.545876, acc.: 77.34%] [G loss: 0.218770]\n",
      "epoch:1 step:1075 [D loss: 0.507032, acc.: 82.03%] [G loss: 0.247472]\n",
      "epoch:1 step:1076 [D loss: 0.536693, acc.: 82.03%] [G loss: 0.293151]\n",
      "epoch:1 step:1077 [D loss: 0.600042, acc.: 71.09%] [G loss: 0.209210]\n",
      "epoch:1 step:1078 [D loss: 0.484548, acc.: 86.72%] [G loss: 0.281094]\n",
      "epoch:1 step:1079 [D loss: 0.502083, acc.: 82.03%] [G loss: 0.243594]\n",
      "epoch:1 step:1080 [D loss: 0.579867, acc.: 70.31%] [G loss: 0.265589]\n",
      "epoch:1 step:1081 [D loss: 0.540468, acc.: 74.22%] [G loss: 0.246281]\n",
      "epoch:1 step:1082 [D loss: 0.504662, acc.: 80.47%] [G loss: 0.252723]\n",
      "epoch:1 step:1083 [D loss: 0.521353, acc.: 71.88%] [G loss: 0.266225]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1084 [D loss: 0.518355, acc.: 82.03%] [G loss: 0.256797]\n",
      "epoch:1 step:1085 [D loss: 0.531569, acc.: 77.34%] [G loss: 0.253419]\n",
      "epoch:1 step:1086 [D loss: 0.543578, acc.: 76.56%] [G loss: 0.241137]\n",
      "epoch:1 step:1087 [D loss: 0.539825, acc.: 78.91%] [G loss: 0.298116]\n",
      "epoch:1 step:1088 [D loss: 0.527307, acc.: 79.69%] [G loss: 0.240071]\n",
      "epoch:1 step:1089 [D loss: 0.441628, acc.: 86.72%] [G loss: 0.308257]\n",
      "epoch:1 step:1090 [D loss: 0.501937, acc.: 81.25%] [G loss: 0.239917]\n",
      "epoch:1 step:1091 [D loss: 0.542951, acc.: 73.44%] [G loss: 0.261920]\n",
      "epoch:1 step:1092 [D loss: 0.484800, acc.: 82.81%] [G loss: 0.259956]\n",
      "epoch:1 step:1093 [D loss: 0.497947, acc.: 86.72%] [G loss: 0.268180]\n",
      "epoch:1 step:1094 [D loss: 0.490988, acc.: 83.59%] [G loss: 0.286645]\n",
      "epoch:1 step:1095 [D loss: 0.568305, acc.: 72.66%] [G loss: 0.218027]\n",
      "epoch:1 step:1096 [D loss: 0.538205, acc.: 75.00%] [G loss: 0.220345]\n",
      "epoch:1 step:1097 [D loss: 0.504897, acc.: 84.38%] [G loss: 0.235158]\n",
      "epoch:1 step:1098 [D loss: 0.463612, acc.: 90.62%] [G loss: 0.271152]\n",
      "epoch:1 step:1099 [D loss: 0.460602, acc.: 82.03%] [G loss: 0.305207]\n",
      "epoch:1 step:1100 [D loss: 0.487714, acc.: 84.38%] [G loss: 0.303199]\n",
      "epoch:1 step:1101 [D loss: 0.489919, acc.: 83.59%] [G loss: 0.235731]\n",
      "epoch:1 step:1102 [D loss: 0.485112, acc.: 81.25%] [G loss: 0.254840]\n",
      "epoch:1 step:1103 [D loss: 0.533423, acc.: 69.53%] [G loss: 0.214573]\n",
      "epoch:1 step:1104 [D loss: 0.547383, acc.: 73.44%] [G loss: 0.209473]\n",
      "epoch:1 step:1105 [D loss: 0.535331, acc.: 77.34%] [G loss: 0.186413]\n",
      "epoch:1 step:1106 [D loss: 0.536727, acc.: 71.88%] [G loss: 0.202070]\n",
      "epoch:1 step:1107 [D loss: 0.467258, acc.: 83.59%] [G loss: 0.293717]\n",
      "epoch:1 step:1108 [D loss: 0.490199, acc.: 86.72%] [G loss: 0.358222]\n",
      "epoch:1 step:1109 [D loss: 0.536835, acc.: 75.78%] [G loss: 0.234731]\n",
      "epoch:1 step:1110 [D loss: 0.478198, acc.: 86.72%] [G loss: 0.253974]\n",
      "epoch:1 step:1111 [D loss: 0.490833, acc.: 86.72%] [G loss: 0.264943]\n",
      "epoch:1 step:1112 [D loss: 0.498951, acc.: 85.16%] [G loss: 0.227360]\n",
      "epoch:1 step:1113 [D loss: 0.502855, acc.: 78.91%] [G loss: 0.276632]\n",
      "epoch:1 step:1114 [D loss: 0.477552, acc.: 86.72%] [G loss: 0.326604]\n",
      "epoch:1 step:1115 [D loss: 0.478928, acc.: 83.59%] [G loss: 0.293617]\n",
      "epoch:1 step:1116 [D loss: 0.484171, acc.: 85.16%] [G loss: 0.355538]\n",
      "epoch:1 step:1117 [D loss: 0.551674, acc.: 77.34%] [G loss: 0.218054]\n",
      "epoch:1 step:1118 [D loss: 0.474416, acc.: 85.94%] [G loss: 0.240534]\n",
      "epoch:1 step:1119 [D loss: 0.495809, acc.: 81.25%] [G loss: 0.293263]\n",
      "epoch:1 step:1120 [D loss: 0.511734, acc.: 77.34%] [G loss: 0.306296]\n",
      "epoch:1 step:1121 [D loss: 0.465893, acc.: 87.50%] [G loss: 0.321745]\n",
      "epoch:1 step:1122 [D loss: 0.545619, acc.: 69.53%] [G loss: 0.251740]\n",
      "epoch:1 step:1123 [D loss: 0.533955, acc.: 75.78%] [G loss: 0.201264]\n",
      "epoch:1 step:1124 [D loss: 0.511298, acc.: 82.03%] [G loss: 0.232578]\n",
      "epoch:1 step:1125 [D loss: 0.458871, acc.: 89.06%] [G loss: 0.290070]\n",
      "epoch:1 step:1126 [D loss: 0.487638, acc.: 82.81%] [G loss: 0.249770]\n",
      "epoch:1 step:1127 [D loss: 0.450780, acc.: 87.50%] [G loss: 0.288139]\n",
      "epoch:1 step:1128 [D loss: 0.492052, acc.: 86.72%] [G loss: 0.277771]\n",
      "epoch:1 step:1129 [D loss: 0.513338, acc.: 82.03%] [G loss: 0.281768]\n",
      "epoch:1 step:1130 [D loss: 0.548503, acc.: 77.34%] [G loss: 0.237753]\n",
      "epoch:1 step:1131 [D loss: 0.467792, acc.: 85.94%] [G loss: 0.337996]\n",
      "epoch:1 step:1132 [D loss: 0.553275, acc.: 75.78%] [G loss: 0.292171]\n",
      "epoch:1 step:1133 [D loss: 0.584780, acc.: 75.00%] [G loss: 0.240544]\n",
      "epoch:1 step:1134 [D loss: 0.541047, acc.: 77.34%] [G loss: 0.205867]\n",
      "epoch:1 step:1135 [D loss: 0.523448, acc.: 78.91%] [G loss: 0.263553]\n",
      "epoch:1 step:1136 [D loss: 0.579163, acc.: 70.31%] [G loss: 0.227770]\n",
      "epoch:1 step:1137 [D loss: 0.564685, acc.: 71.88%] [G loss: 0.246003]\n",
      "epoch:1 step:1138 [D loss: 0.538427, acc.: 75.00%] [G loss: 0.262268]\n",
      "epoch:1 step:1139 [D loss: 0.534901, acc.: 76.56%] [G loss: 0.324365]\n",
      "epoch:1 step:1140 [D loss: 0.515574, acc.: 80.47%] [G loss: 0.297532]\n",
      "epoch:1 step:1141 [D loss: 0.463660, acc.: 82.03%] [G loss: 0.360389]\n",
      "epoch:1 step:1142 [D loss: 0.460751, acc.: 86.72%] [G loss: 0.397403]\n",
      "epoch:1 step:1143 [D loss: 0.490434, acc.: 78.12%] [G loss: 0.359009]\n",
      "epoch:1 step:1144 [D loss: 0.471945, acc.: 82.03%] [G loss: 0.405653]\n",
      "epoch:1 step:1145 [D loss: 0.497383, acc.: 83.59%] [G loss: 0.403539]\n",
      "epoch:1 step:1146 [D loss: 0.514910, acc.: 80.47%] [G loss: 0.340595]\n",
      "epoch:1 step:1147 [D loss: 0.542106, acc.: 73.44%] [G loss: 0.307153]\n",
      "epoch:1 step:1148 [D loss: 0.534886, acc.: 79.69%] [G loss: 0.260852]\n",
      "epoch:1 step:1149 [D loss: 0.504341, acc.: 76.56%] [G loss: 0.330945]\n",
      "epoch:1 step:1150 [D loss: 0.524080, acc.: 81.25%] [G loss: 0.306366]\n",
      "epoch:1 step:1151 [D loss: 0.622337, acc.: 64.06%] [G loss: 0.183164]\n",
      "epoch:1 step:1152 [D loss: 0.561931, acc.: 71.09%] [G loss: 0.246594]\n",
      "epoch:1 step:1153 [D loss: 0.549883, acc.: 77.34%] [G loss: 0.305393]\n",
      "epoch:1 step:1154 [D loss: 0.480872, acc.: 87.50%] [G loss: 0.395826]\n",
      "epoch:1 step:1155 [D loss: 0.461892, acc.: 87.50%] [G loss: 0.397493]\n",
      "epoch:1 step:1156 [D loss: 0.533086, acc.: 82.03%] [G loss: 0.330846]\n",
      "epoch:1 step:1157 [D loss: 0.625051, acc.: 70.31%] [G loss: 0.149340]\n",
      "epoch:1 step:1158 [D loss: 0.545613, acc.: 71.88%] [G loss: 0.267884]\n",
      "epoch:1 step:1159 [D loss: 0.496954, acc.: 82.81%] [G loss: 0.361582]\n",
      "epoch:1 step:1160 [D loss: 0.505589, acc.: 83.59%] [G loss: 0.374206]\n",
      "epoch:1 step:1161 [D loss: 0.537674, acc.: 78.91%] [G loss: 0.291357]\n",
      "epoch:1 step:1162 [D loss: 0.515964, acc.: 84.38%] [G loss: 0.259116]\n",
      "epoch:1 step:1163 [D loss: 0.557641, acc.: 75.78%] [G loss: 0.207650]\n",
      "epoch:1 step:1164 [D loss: 0.537531, acc.: 79.69%] [G loss: 0.198455]\n",
      "epoch:1 step:1165 [D loss: 0.492538, acc.: 85.94%] [G loss: 0.267190]\n",
      "epoch:1 step:1166 [D loss: 0.520892, acc.: 82.81%] [G loss: 0.347829]\n",
      "epoch:1 step:1167 [D loss: 0.490246, acc.: 84.38%] [G loss: 0.455225]\n",
      "epoch:1 step:1168 [D loss: 0.489534, acc.: 77.34%] [G loss: 0.526432]\n",
      "epoch:1 step:1169 [D loss: 0.510453, acc.: 77.34%] [G loss: 0.561831]\n",
      "epoch:1 step:1170 [D loss: 0.558977, acc.: 69.53%] [G loss: 0.273393]\n",
      "epoch:1 step:1171 [D loss: 0.500901, acc.: 78.91%] [G loss: 0.311047]\n",
      "epoch:1 step:1172 [D loss: 0.490645, acc.: 83.59%] [G loss: 0.266340]\n",
      "epoch:1 step:1173 [D loss: 0.520961, acc.: 78.12%] [G loss: 0.320899]\n",
      "epoch:1 step:1174 [D loss: 0.565276, acc.: 72.66%] [G loss: 0.206694]\n",
      "epoch:1 step:1175 [D loss: 0.533049, acc.: 76.56%] [G loss: 0.249270]\n",
      "epoch:1 step:1176 [D loss: 0.499145, acc.: 78.91%] [G loss: 0.264245]\n",
      "epoch:1 step:1177 [D loss: 0.504528, acc.: 82.03%] [G loss: 0.294748]\n",
      "epoch:1 step:1178 [D loss: 0.514260, acc.: 84.38%] [G loss: 0.280502]\n",
      "epoch:1 step:1179 [D loss: 0.500761, acc.: 79.69%] [G loss: 0.281791]\n",
      "epoch:1 step:1180 [D loss: 0.506219, acc.: 76.56%] [G loss: 0.290606]\n",
      "epoch:1 step:1181 [D loss: 0.477168, acc.: 89.06%] [G loss: 0.294603]\n",
      "epoch:1 step:1182 [D loss: 0.480891, acc.: 86.72%] [G loss: 0.331259]\n",
      "epoch:1 step:1183 [D loss: 0.578918, acc.: 70.31%] [G loss: 0.234104]\n",
      "epoch:1 step:1184 [D loss: 0.562133, acc.: 75.00%] [G loss: 0.288459]\n",
      "epoch:1 step:1185 [D loss: 0.524310, acc.: 81.25%] [G loss: 0.285314]\n",
      "epoch:1 step:1186 [D loss: 0.521696, acc.: 77.34%] [G loss: 0.321654]\n",
      "epoch:1 step:1187 [D loss: 0.505499, acc.: 82.03%] [G loss: 0.315658]\n",
      "epoch:1 step:1188 [D loss: 0.532540, acc.: 75.00%] [G loss: 0.306969]\n",
      "epoch:1 step:1189 [D loss: 0.541196, acc.: 76.56%] [G loss: 0.252269]\n",
      "epoch:1 step:1190 [D loss: 0.554041, acc.: 71.09%] [G loss: 0.297312]\n",
      "epoch:1 step:1191 [D loss: 0.490499, acc.: 79.69%] [G loss: 0.315196]\n",
      "epoch:1 step:1192 [D loss: 0.523658, acc.: 79.69%] [G loss: 0.324375]\n",
      "epoch:1 step:1193 [D loss: 0.536126, acc.: 75.00%] [G loss: 0.293054]\n",
      "epoch:1 step:1194 [D loss: 0.455123, acc.: 86.72%] [G loss: 0.350710]\n",
      "epoch:1 step:1195 [D loss: 0.508981, acc.: 76.56%] [G loss: 0.340531]\n",
      "epoch:1 step:1196 [D loss: 0.515642, acc.: 79.69%] [G loss: 0.393119]\n",
      "epoch:1 step:1197 [D loss: 0.487107, acc.: 86.72%] [G loss: 0.325870]\n",
      "epoch:1 step:1198 [D loss: 0.547827, acc.: 75.00%] [G loss: 0.292946]\n",
      "epoch:1 step:1199 [D loss: 0.499309, acc.: 80.47%] [G loss: 0.310959]\n",
      "epoch:1 step:1200 [D loss: 0.621659, acc.: 62.50%] [G loss: 0.256369]\n",
      "##############\n",
      "[4.78483858 3.6228623  8.96491459 7.22963991 6.71903991 8.24661761\n",
      " 7.46707    7.3022557  7.95625838 6.38537822]\n",
      "##########\n",
      "epoch:1 step:1201 [D loss: 0.575234, acc.: 71.09%] [G loss: 0.219401]\n",
      "epoch:1 step:1202 [D loss: 0.532020, acc.: 76.56%] [G loss: 0.260578]\n",
      "epoch:1 step:1203 [D loss: 0.550643, acc.: 79.69%] [G loss: 0.198947]\n",
      "epoch:1 step:1204 [D loss: 0.524189, acc.: 82.81%] [G loss: 0.214122]\n",
      "epoch:1 step:1205 [D loss: 0.505121, acc.: 76.56%] [G loss: 0.254409]\n",
      "epoch:1 step:1206 [D loss: 0.659873, acc.: 57.81%] [G loss: 0.178873]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1207 [D loss: 0.572467, acc.: 71.09%] [G loss: 0.210138]\n",
      "epoch:1 step:1208 [D loss: 0.504459, acc.: 85.16%] [G loss: 0.240984]\n",
      "epoch:1 step:1209 [D loss: 0.526124, acc.: 76.56%] [G loss: 0.256306]\n",
      "epoch:1 step:1210 [D loss: 0.480365, acc.: 85.16%] [G loss: 0.330033]\n",
      "epoch:1 step:1211 [D loss: 0.589249, acc.: 69.53%] [G loss: 0.241120]\n",
      "epoch:1 step:1212 [D loss: 0.569742, acc.: 72.66%] [G loss: 0.207608]\n",
      "epoch:1 step:1213 [D loss: 0.618601, acc.: 66.41%] [G loss: 0.217409]\n",
      "epoch:1 step:1214 [D loss: 0.544758, acc.: 81.25%] [G loss: 0.245733]\n",
      "epoch:1 step:1215 [D loss: 0.551907, acc.: 71.88%] [G loss: 0.257005]\n",
      "epoch:1 step:1216 [D loss: 0.462516, acc.: 81.25%] [G loss: 0.333303]\n",
      "epoch:1 step:1217 [D loss: 0.512956, acc.: 77.34%] [G loss: 0.393980]\n",
      "epoch:1 step:1218 [D loss: 0.523173, acc.: 80.47%] [G loss: 0.288091]\n",
      "epoch:1 step:1219 [D loss: 0.548521, acc.: 79.69%] [G loss: 0.261682]\n",
      "epoch:1 step:1220 [D loss: 0.495118, acc.: 83.59%] [G loss: 0.243486]\n",
      "epoch:1 step:1221 [D loss: 0.506541, acc.: 86.72%] [G loss: 0.212829]\n",
      "epoch:1 step:1222 [D loss: 0.506194, acc.: 85.94%] [G loss: 0.276951]\n",
      "epoch:1 step:1223 [D loss: 0.473607, acc.: 87.50%] [G loss: 0.316774]\n",
      "epoch:1 step:1224 [D loss: 0.506320, acc.: 82.81%] [G loss: 0.310459]\n",
      "epoch:1 step:1225 [D loss: 0.528306, acc.: 78.12%] [G loss: 0.272340]\n",
      "epoch:1 step:1226 [D loss: 0.463119, acc.: 87.50%] [G loss: 0.271879]\n",
      "epoch:1 step:1227 [D loss: 0.521042, acc.: 82.03%] [G loss: 0.280750]\n",
      "epoch:1 step:1228 [D loss: 0.582034, acc.: 71.09%] [G loss: 0.244298]\n",
      "epoch:1 step:1229 [D loss: 0.512319, acc.: 85.16%] [G loss: 0.294205]\n",
      "epoch:1 step:1230 [D loss: 0.525812, acc.: 77.34%] [G loss: 0.272568]\n",
      "epoch:1 step:1231 [D loss: 0.549923, acc.: 75.00%] [G loss: 0.218387]\n",
      "epoch:1 step:1232 [D loss: 0.536564, acc.: 78.91%] [G loss: 0.232383]\n",
      "epoch:1 step:1233 [D loss: 0.482697, acc.: 83.59%] [G loss: 0.313309]\n",
      "epoch:1 step:1234 [D loss: 0.516851, acc.: 82.03%] [G loss: 0.337235]\n",
      "epoch:1 step:1235 [D loss: 0.506427, acc.: 85.16%] [G loss: 0.244004]\n",
      "epoch:1 step:1236 [D loss: 0.483125, acc.: 85.16%] [G loss: 0.320293]\n",
      "epoch:1 step:1237 [D loss: 0.483337, acc.: 88.28%] [G loss: 0.310989]\n",
      "epoch:1 step:1238 [D loss: 0.536994, acc.: 80.47%] [G loss: 0.244986]\n",
      "epoch:1 step:1239 [D loss: 0.500470, acc.: 77.34%] [G loss: 0.302533]\n",
      "epoch:1 step:1240 [D loss: 0.513105, acc.: 87.50%] [G loss: 0.296842]\n",
      "epoch:1 step:1241 [D loss: 0.458776, acc.: 89.84%] [G loss: 0.310945]\n",
      "epoch:1 step:1242 [D loss: 0.504719, acc.: 83.59%] [G loss: 0.301276]\n",
      "epoch:1 step:1243 [D loss: 0.484651, acc.: 87.50%] [G loss: 0.280224]\n",
      "epoch:1 step:1244 [D loss: 0.465128, acc.: 87.50%] [G loss: 0.336051]\n",
      "epoch:1 step:1245 [D loss: 0.469085, acc.: 85.16%] [G loss: 0.322111]\n",
      "epoch:1 step:1246 [D loss: 0.441767, acc.: 86.72%] [G loss: 0.394232]\n",
      "epoch:1 step:1247 [D loss: 0.469100, acc.: 83.59%] [G loss: 0.443179]\n",
      "epoch:1 step:1248 [D loss: 0.467026, acc.: 78.91%] [G loss: 0.458439]\n",
      "epoch:1 step:1249 [D loss: 0.455531, acc.: 85.16%] [G loss: 0.389448]\n",
      "epoch:1 step:1250 [D loss: 0.466655, acc.: 83.59%] [G loss: 0.482291]\n",
      "epoch:1 step:1251 [D loss: 0.463057, acc.: 82.81%] [G loss: 0.425027]\n",
      "epoch:1 step:1252 [D loss: 0.446341, acc.: 83.59%] [G loss: 0.483504]\n",
      "epoch:1 step:1253 [D loss: 0.601619, acc.: 66.41%] [G loss: 0.248396]\n",
      "epoch:1 step:1254 [D loss: 0.521851, acc.: 81.25%] [G loss: 0.235252]\n",
      "epoch:1 step:1255 [D loss: 0.500840, acc.: 82.03%] [G loss: 0.246773]\n",
      "epoch:1 step:1256 [D loss: 0.493555, acc.: 82.81%] [G loss: 0.289330]\n",
      "epoch:1 step:1257 [D loss: 0.522083, acc.: 82.03%] [G loss: 0.249366]\n",
      "epoch:1 step:1258 [D loss: 0.498926, acc.: 85.16%] [G loss: 0.244057]\n",
      "epoch:1 step:1259 [D loss: 0.459881, acc.: 88.28%] [G loss: 0.294435]\n",
      "epoch:1 step:1260 [D loss: 0.494997, acc.: 82.81%] [G loss: 0.288660]\n",
      "epoch:1 step:1261 [D loss: 0.471483, acc.: 85.16%] [G loss: 0.259297]\n",
      "epoch:1 step:1262 [D loss: 0.478979, acc.: 82.81%] [G loss: 0.350853]\n",
      "epoch:1 step:1263 [D loss: 0.477550, acc.: 85.94%] [G loss: 0.288897]\n",
      "epoch:1 step:1264 [D loss: 0.466861, acc.: 85.16%] [G loss: 0.331775]\n",
      "epoch:1 step:1265 [D loss: 0.469051, acc.: 86.72%] [G loss: 0.392542]\n",
      "epoch:1 step:1266 [D loss: 0.524369, acc.: 78.91%] [G loss: 0.321570]\n",
      "epoch:1 step:1267 [D loss: 0.545980, acc.: 78.12%] [G loss: 0.230092]\n",
      "epoch:1 step:1268 [D loss: 0.464725, acc.: 83.59%] [G loss: 0.293206]\n",
      "epoch:1 step:1269 [D loss: 0.497750, acc.: 81.25%] [G loss: 0.307254]\n",
      "epoch:1 step:1270 [D loss: 0.518717, acc.: 75.78%] [G loss: 0.303837]\n",
      "epoch:1 step:1271 [D loss: 0.488611, acc.: 83.59%] [G loss: 0.401021]\n",
      "epoch:1 step:1272 [D loss: 0.463394, acc.: 81.25%] [G loss: 0.322901]\n",
      "epoch:1 step:1273 [D loss: 0.478879, acc.: 83.59%] [G loss: 0.360394]\n",
      "epoch:1 step:1274 [D loss: 0.435069, acc.: 86.72%] [G loss: 0.435218]\n",
      "epoch:1 step:1275 [D loss: 0.461077, acc.: 84.38%] [G loss: 0.393317]\n",
      "epoch:1 step:1276 [D loss: 0.449525, acc.: 86.72%] [G loss: 0.367856]\n",
      "epoch:1 step:1277 [D loss: 0.459664, acc.: 83.59%] [G loss: 0.372004]\n",
      "epoch:1 step:1278 [D loss: 0.484087, acc.: 82.03%] [G loss: 0.321922]\n",
      "epoch:1 step:1279 [D loss: 0.494179, acc.: 79.69%] [G loss: 0.334521]\n",
      "epoch:1 step:1280 [D loss: 0.409213, acc.: 89.06%] [G loss: 0.457882]\n",
      "epoch:1 step:1281 [D loss: 0.410336, acc.: 89.06%] [G loss: 0.479830]\n",
      "epoch:1 step:1282 [D loss: 0.486399, acc.: 81.25%] [G loss: 0.466249]\n",
      "epoch:1 step:1283 [D loss: 0.522969, acc.: 74.22%] [G loss: 0.407459]\n",
      "epoch:1 step:1284 [D loss: 0.453507, acc.: 83.59%] [G loss: 0.593306]\n",
      "epoch:1 step:1285 [D loss: 0.552903, acc.: 73.44%] [G loss: 0.408852]\n",
      "epoch:1 step:1286 [D loss: 0.618429, acc.: 64.06%] [G loss: 0.238230]\n",
      "epoch:1 step:1287 [D loss: 0.461801, acc.: 85.94%] [G loss: 0.288416]\n",
      "epoch:1 step:1288 [D loss: 0.487571, acc.: 80.47%] [G loss: 0.341217]\n",
      "epoch:1 step:1289 [D loss: 0.516960, acc.: 82.81%] [G loss: 0.372278]\n",
      "epoch:1 step:1290 [D loss: 0.512258, acc.: 79.69%] [G loss: 0.312286]\n",
      "epoch:1 step:1291 [D loss: 0.444917, acc.: 89.06%] [G loss: 0.402418]\n",
      "epoch:1 step:1292 [D loss: 0.488250, acc.: 82.03%] [G loss: 0.352863]\n",
      "epoch:1 step:1293 [D loss: 0.489737, acc.: 79.69%] [G loss: 0.382708]\n",
      "epoch:1 step:1294 [D loss: 0.485747, acc.: 82.81%] [G loss: 0.292015]\n",
      "epoch:1 step:1295 [D loss: 0.455159, acc.: 82.03%] [G loss: 0.328345]\n",
      "epoch:1 step:1296 [D loss: 0.446404, acc.: 85.16%] [G loss: 0.434935]\n",
      "epoch:1 step:1297 [D loss: 0.498846, acc.: 81.25%] [G loss: 0.330762]\n",
      "epoch:1 step:1298 [D loss: 0.494468, acc.: 83.59%] [G loss: 0.330745]\n",
      "epoch:1 step:1299 [D loss: 0.548602, acc.: 71.09%] [G loss: 0.238723]\n",
      "epoch:1 step:1300 [D loss: 0.517882, acc.: 75.78%] [G loss: 0.275561]\n",
      "epoch:1 step:1301 [D loss: 0.504831, acc.: 77.34%] [G loss: 0.301402]\n",
      "epoch:1 step:1302 [D loss: 0.510782, acc.: 77.34%] [G loss: 0.417373]\n",
      "epoch:1 step:1303 [D loss: 0.499464, acc.: 78.91%] [G loss: 0.408668]\n",
      "epoch:1 step:1304 [D loss: 0.508921, acc.: 76.56%] [G loss: 0.374005]\n",
      "epoch:1 step:1305 [D loss: 0.500301, acc.: 78.12%] [G loss: 0.367973]\n",
      "epoch:1 step:1306 [D loss: 0.531654, acc.: 76.56%] [G loss: 0.309722]\n",
      "epoch:1 step:1307 [D loss: 0.544786, acc.: 78.91%] [G loss: 0.304826]\n",
      "epoch:1 step:1308 [D loss: 0.549270, acc.: 76.56%] [G loss: 0.326682]\n",
      "epoch:1 step:1309 [D loss: 0.507690, acc.: 81.25%] [G loss: 0.422581]\n",
      "epoch:1 step:1310 [D loss: 0.524426, acc.: 81.25%] [G loss: 0.395397]\n",
      "epoch:1 step:1311 [D loss: 0.467682, acc.: 82.03%] [G loss: 0.412819]\n",
      "epoch:1 step:1312 [D loss: 0.521731, acc.: 78.91%] [G loss: 0.355223]\n",
      "epoch:1 step:1313 [D loss: 0.639889, acc.: 60.16%] [G loss: 0.179489]\n",
      "epoch:1 step:1314 [D loss: 0.497943, acc.: 78.91%] [G loss: 0.336564]\n",
      "epoch:1 step:1315 [D loss: 0.463116, acc.: 84.38%] [G loss: 0.435997]\n",
      "epoch:1 step:1316 [D loss: 0.517421, acc.: 78.12%] [G loss: 0.362357]\n",
      "epoch:1 step:1317 [D loss: 0.544642, acc.: 78.91%] [G loss: 0.335185]\n",
      "epoch:1 step:1318 [D loss: 0.465211, acc.: 84.38%] [G loss: 0.409048]\n",
      "epoch:1 step:1319 [D loss: 0.493791, acc.: 85.16%] [G loss: 0.397685]\n",
      "epoch:1 step:1320 [D loss: 0.518846, acc.: 78.12%] [G loss: 0.327284]\n",
      "epoch:1 step:1321 [D loss: 0.514506, acc.: 81.25%] [G loss: 0.309058]\n",
      "epoch:1 step:1322 [D loss: 0.534124, acc.: 73.44%] [G loss: 0.298076]\n",
      "epoch:1 step:1323 [D loss: 0.474276, acc.: 82.81%] [G loss: 0.388584]\n",
      "epoch:1 step:1324 [D loss: 0.530541, acc.: 78.91%] [G loss: 0.310022]\n",
      "epoch:1 step:1325 [D loss: 0.485932, acc.: 79.69%] [G loss: 0.330045]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1326 [D loss: 0.518925, acc.: 75.00%] [G loss: 0.276780]\n",
      "epoch:1 step:1327 [D loss: 0.557218, acc.: 71.88%] [G loss: 0.283365]\n",
      "epoch:1 step:1328 [D loss: 0.445432, acc.: 83.59%] [G loss: 0.377366]\n",
      "epoch:1 step:1329 [D loss: 0.411247, acc.: 89.84%] [G loss: 0.474893]\n",
      "epoch:1 step:1330 [D loss: 0.610974, acc.: 67.97%] [G loss: 0.286120]\n",
      "epoch:1 step:1331 [D loss: 0.490008, acc.: 80.47%] [G loss: 0.387605]\n",
      "epoch:1 step:1332 [D loss: 0.531634, acc.: 76.56%] [G loss: 0.342411]\n",
      "epoch:1 step:1333 [D loss: 0.459639, acc.: 85.16%] [G loss: 0.407634]\n",
      "epoch:1 step:1334 [D loss: 0.460176, acc.: 83.59%] [G loss: 0.467770]\n",
      "epoch:1 step:1335 [D loss: 0.433822, acc.: 88.28%] [G loss: 0.463324]\n",
      "epoch:1 step:1336 [D loss: 0.455884, acc.: 86.72%] [G loss: 0.513621]\n",
      "epoch:1 step:1337 [D loss: 0.517914, acc.: 78.91%] [G loss: 0.402258]\n",
      "epoch:1 step:1338 [D loss: 0.511811, acc.: 78.12%] [G loss: 0.354503]\n",
      "epoch:1 step:1339 [D loss: 0.444884, acc.: 82.81%] [G loss: 0.398311]\n",
      "epoch:1 step:1340 [D loss: 0.477585, acc.: 83.59%] [G loss: 0.407575]\n",
      "epoch:1 step:1341 [D loss: 0.528123, acc.: 79.69%] [G loss: 0.358579]\n",
      "epoch:1 step:1342 [D loss: 0.542457, acc.: 68.75%] [G loss: 0.383870]\n",
      "epoch:1 step:1343 [D loss: 0.508240, acc.: 76.56%] [G loss: 0.486321]\n",
      "epoch:1 step:1344 [D loss: 0.480867, acc.: 78.91%] [G loss: 0.515042]\n",
      "epoch:1 step:1345 [D loss: 0.477701, acc.: 85.16%] [G loss: 0.414979]\n",
      "epoch:1 step:1346 [D loss: 0.483230, acc.: 79.69%] [G loss: 0.492200]\n",
      "epoch:1 step:1347 [D loss: 0.525587, acc.: 75.78%] [G loss: 0.326724]\n",
      "epoch:1 step:1348 [D loss: 0.505167, acc.: 84.38%] [G loss: 0.390782]\n",
      "epoch:1 step:1349 [D loss: 0.506947, acc.: 82.81%] [G loss: 0.375265]\n",
      "epoch:1 step:1350 [D loss: 0.500096, acc.: 82.81%] [G loss: 0.365648]\n",
      "epoch:1 step:1351 [D loss: 0.477106, acc.: 83.59%] [G loss: 0.396134]\n",
      "epoch:1 step:1352 [D loss: 0.515711, acc.: 76.56%] [G loss: 0.380932]\n",
      "epoch:1 step:1353 [D loss: 0.503874, acc.: 79.69%] [G loss: 0.407750]\n",
      "epoch:1 step:1354 [D loss: 0.557964, acc.: 78.12%] [G loss: 0.296239]\n",
      "epoch:1 step:1355 [D loss: 0.538656, acc.: 75.78%] [G loss: 0.293061]\n",
      "epoch:1 step:1356 [D loss: 0.528951, acc.: 74.22%] [G loss: 0.326767]\n",
      "epoch:1 step:1357 [D loss: 0.496430, acc.: 75.00%] [G loss: 0.455883]\n",
      "epoch:1 step:1358 [D loss: 0.536443, acc.: 71.09%] [G loss: 0.438780]\n",
      "epoch:1 step:1359 [D loss: 0.537434, acc.: 75.78%] [G loss: 0.369868]\n",
      "epoch:1 step:1360 [D loss: 0.502782, acc.: 75.78%] [G loss: 0.317447]\n",
      "epoch:1 step:1361 [D loss: 0.514977, acc.: 78.91%] [G loss: 0.325332]\n",
      "epoch:1 step:1362 [D loss: 0.483119, acc.: 85.16%] [G loss: 0.413804]\n",
      "epoch:1 step:1363 [D loss: 0.473477, acc.: 80.47%] [G loss: 0.491780]\n",
      "epoch:1 step:1364 [D loss: 0.473278, acc.: 82.81%] [G loss: 0.453837]\n",
      "epoch:1 step:1365 [D loss: 0.472217, acc.: 80.47%] [G loss: 0.499520]\n",
      "epoch:1 step:1366 [D loss: 0.480710, acc.: 80.47%] [G loss: 0.496867]\n",
      "epoch:1 step:1367 [D loss: 0.489989, acc.: 78.91%] [G loss: 0.440681]\n",
      "epoch:1 step:1368 [D loss: 0.491003, acc.: 85.94%] [G loss: 0.349076]\n",
      "epoch:1 step:1369 [D loss: 0.600378, acc.: 67.19%] [G loss: 0.262378]\n",
      "epoch:1 step:1370 [D loss: 0.519905, acc.: 78.12%] [G loss: 0.352591]\n",
      "epoch:1 step:1371 [D loss: 0.533096, acc.: 76.56%] [G loss: 0.296724]\n",
      "epoch:1 step:1372 [D loss: 0.539389, acc.: 75.00%] [G loss: 0.348117]\n",
      "epoch:1 step:1373 [D loss: 0.530575, acc.: 71.88%] [G loss: 0.441502]\n",
      "epoch:1 step:1374 [D loss: 0.583972, acc.: 72.66%] [G loss: 0.274973]\n",
      "epoch:1 step:1375 [D loss: 0.510495, acc.: 78.91%] [G loss: 0.285107]\n",
      "epoch:1 step:1376 [D loss: 0.502611, acc.: 75.78%] [G loss: 0.421402]\n",
      "epoch:1 step:1377 [D loss: 0.483007, acc.: 82.03%] [G loss: 0.434175]\n",
      "epoch:1 step:1378 [D loss: 0.506067, acc.: 83.59%] [G loss: 0.349117]\n",
      "epoch:1 step:1379 [D loss: 0.538615, acc.: 75.78%] [G loss: 0.321552]\n",
      "epoch:1 step:1380 [D loss: 0.502686, acc.: 77.34%] [G loss: 0.337213]\n",
      "epoch:1 step:1381 [D loss: 0.517661, acc.: 77.34%] [G loss: 0.306292]\n",
      "epoch:1 step:1382 [D loss: 0.508180, acc.: 78.91%] [G loss: 0.287326]\n",
      "epoch:1 step:1383 [D loss: 0.495137, acc.: 78.12%] [G loss: 0.386097]\n",
      "epoch:1 step:1384 [D loss: 0.479245, acc.: 82.81%] [G loss: 0.470303]\n",
      "epoch:1 step:1385 [D loss: 0.569674, acc.: 71.88%] [G loss: 0.294102]\n",
      "epoch:1 step:1386 [D loss: 0.514453, acc.: 80.47%] [G loss: 0.335519]\n",
      "epoch:1 step:1387 [D loss: 0.443596, acc.: 85.94%] [G loss: 0.331357]\n",
      "epoch:1 step:1388 [D loss: 0.478091, acc.: 85.94%] [G loss: 0.368963]\n",
      "epoch:1 step:1389 [D loss: 0.467726, acc.: 85.16%] [G loss: 0.380477]\n",
      "epoch:1 step:1390 [D loss: 0.548506, acc.: 78.91%] [G loss: 0.278374]\n",
      "epoch:1 step:1391 [D loss: 0.552113, acc.: 74.22%] [G loss: 0.229882]\n",
      "epoch:1 step:1392 [D loss: 0.546677, acc.: 76.56%] [G loss: 0.277818]\n",
      "epoch:1 step:1393 [D loss: 0.574657, acc.: 67.97%] [G loss: 0.252996]\n",
      "epoch:1 step:1394 [D loss: 0.487581, acc.: 79.69%] [G loss: 0.318311]\n",
      "epoch:1 step:1395 [D loss: 0.508971, acc.: 80.47%] [G loss: 0.352418]\n",
      "epoch:1 step:1396 [D loss: 0.492516, acc.: 79.69%] [G loss: 0.360992]\n",
      "epoch:1 step:1397 [D loss: 0.477396, acc.: 82.03%] [G loss: 0.351864]\n",
      "epoch:1 step:1398 [D loss: 0.439038, acc.: 85.16%] [G loss: 0.396638]\n",
      "epoch:1 step:1399 [D loss: 0.504609, acc.: 82.03%] [G loss: 0.316704]\n",
      "epoch:1 step:1400 [D loss: 0.506297, acc.: 81.25%] [G loss: 0.301282]\n",
      "##############\n",
      "[4.85748944 3.73429213 8.69812981 7.27707132 6.43813394 7.93367044\n",
      " 7.10300523 7.22241889 7.58844885 6.05598084]\n",
      "##########\n",
      "epoch:1 step:1401 [D loss: 0.508640, acc.: 85.16%] [G loss: 0.249055]\n",
      "epoch:1 step:1402 [D loss: 0.510891, acc.: 82.81%] [G loss: 0.351684]\n",
      "epoch:1 step:1403 [D loss: 0.460770, acc.: 81.25%] [G loss: 0.417073]\n",
      "epoch:1 step:1404 [D loss: 0.533561, acc.: 75.00%] [G loss: 0.371684]\n",
      "epoch:1 step:1405 [D loss: 0.489852, acc.: 78.91%] [G loss: 0.401261]\n",
      "epoch:1 step:1406 [D loss: 0.486907, acc.: 82.03%] [G loss: 0.377782]\n",
      "epoch:1 step:1407 [D loss: 0.501579, acc.: 75.78%] [G loss: 0.317881]\n",
      "epoch:1 step:1408 [D loss: 0.460773, acc.: 83.59%] [G loss: 0.439446]\n",
      "epoch:1 step:1409 [D loss: 0.468265, acc.: 81.25%] [G loss: 0.452345]\n",
      "epoch:1 step:1410 [D loss: 0.567444, acc.: 73.44%] [G loss: 0.351724]\n",
      "epoch:1 step:1411 [D loss: 0.494146, acc.: 83.59%] [G loss: 0.359971]\n",
      "epoch:1 step:1412 [D loss: 0.465477, acc.: 85.16%] [G loss: 0.438847]\n",
      "epoch:1 step:1413 [D loss: 0.512580, acc.: 80.47%] [G loss: 0.389211]\n",
      "epoch:1 step:1414 [D loss: 0.585236, acc.: 66.41%] [G loss: 0.246684]\n",
      "epoch:1 step:1415 [D loss: 0.532498, acc.: 80.47%] [G loss: 0.255004]\n",
      "epoch:1 step:1416 [D loss: 0.541972, acc.: 82.03%] [G loss: 0.265177]\n",
      "epoch:1 step:1417 [D loss: 0.504713, acc.: 80.47%] [G loss: 0.312149]\n",
      "epoch:1 step:1418 [D loss: 0.514423, acc.: 79.69%] [G loss: 0.395588]\n",
      "epoch:1 step:1419 [D loss: 0.494911, acc.: 79.69%] [G loss: 0.406404]\n",
      "epoch:1 step:1420 [D loss: 0.523862, acc.: 75.00%] [G loss: 0.321310]\n",
      "epoch:1 step:1421 [D loss: 0.500885, acc.: 82.81%] [G loss: 0.292965]\n",
      "epoch:1 step:1422 [D loss: 0.462179, acc.: 85.94%] [G loss: 0.347913]\n",
      "epoch:1 step:1423 [D loss: 0.493800, acc.: 82.03%] [G loss: 0.436570]\n",
      "epoch:1 step:1424 [D loss: 0.455287, acc.: 85.16%] [G loss: 0.457397]\n",
      "epoch:1 step:1425 [D loss: 0.436560, acc.: 84.38%] [G loss: 0.556614]\n",
      "epoch:1 step:1426 [D loss: 0.513016, acc.: 78.12%] [G loss: 0.374137]\n",
      "epoch:1 step:1427 [D loss: 0.528021, acc.: 76.56%] [G loss: 0.313885]\n",
      "epoch:1 step:1428 [D loss: 0.479309, acc.: 81.25%] [G loss: 0.389198]\n",
      "epoch:1 step:1429 [D loss: 0.497022, acc.: 80.47%] [G loss: 0.397983]\n",
      "epoch:1 step:1430 [D loss: 0.547686, acc.: 75.00%] [G loss: 0.380301]\n",
      "epoch:1 step:1431 [D loss: 0.470593, acc.: 86.72%] [G loss: 0.401528]\n",
      "epoch:1 step:1432 [D loss: 0.526033, acc.: 75.78%] [G loss: 0.389256]\n",
      "epoch:1 step:1433 [D loss: 0.544658, acc.: 73.44%] [G loss: 0.396399]\n",
      "epoch:1 step:1434 [D loss: 0.479711, acc.: 79.69%] [G loss: 0.466531]\n",
      "epoch:1 step:1435 [D loss: 0.392187, acc.: 85.94%] [G loss: 0.716574]\n",
      "epoch:1 step:1436 [D loss: 0.449781, acc.: 82.03%] [G loss: 0.688950]\n",
      "epoch:1 step:1437 [D loss: 0.596288, acc.: 67.97%] [G loss: 0.353627]\n",
      "epoch:1 step:1438 [D loss: 0.580359, acc.: 67.19%] [G loss: 0.293321]\n",
      "epoch:1 step:1439 [D loss: 0.502326, acc.: 86.72%] [G loss: 0.294108]\n",
      "epoch:1 step:1440 [D loss: 0.469115, acc.: 76.56%] [G loss: 0.461161]\n",
      "epoch:1 step:1441 [D loss: 0.465662, acc.: 82.81%] [G loss: 0.467686]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1442 [D loss: 0.515660, acc.: 78.12%] [G loss: 0.368009]\n",
      "epoch:1 step:1443 [D loss: 0.427812, acc.: 89.06%] [G loss: 0.414814]\n",
      "epoch:1 step:1444 [D loss: 0.488748, acc.: 80.47%] [G loss: 0.369652]\n",
      "epoch:1 step:1445 [D loss: 0.434824, acc.: 89.06%] [G loss: 0.379540]\n",
      "epoch:1 step:1446 [D loss: 0.483762, acc.: 82.81%] [G loss: 0.348466]\n",
      "epoch:1 step:1447 [D loss: 0.532541, acc.: 76.56%] [G loss: 0.310275]\n",
      "epoch:1 step:1448 [D loss: 0.519824, acc.: 78.91%] [G loss: 0.290882]\n",
      "epoch:1 step:1449 [D loss: 0.487722, acc.: 81.25%] [G loss: 0.380575]\n",
      "epoch:1 step:1450 [D loss: 0.470787, acc.: 76.56%] [G loss: 0.553259]\n",
      "epoch:1 step:1451 [D loss: 0.430640, acc.: 86.72%] [G loss: 0.512132]\n",
      "epoch:1 step:1452 [D loss: 0.457489, acc.: 81.25%] [G loss: 0.401025]\n",
      "epoch:1 step:1453 [D loss: 0.480751, acc.: 85.16%] [G loss: 0.520804]\n",
      "epoch:1 step:1454 [D loss: 0.553795, acc.: 70.31%] [G loss: 0.402731]\n",
      "epoch:1 step:1455 [D loss: 0.457498, acc.: 85.16%] [G loss: 0.452162]\n",
      "epoch:1 step:1456 [D loss: 0.499741, acc.: 79.69%] [G loss: 0.421839]\n",
      "epoch:1 step:1457 [D loss: 0.486619, acc.: 82.03%] [G loss: 0.357622]\n",
      "epoch:1 step:1458 [D loss: 0.471694, acc.: 86.72%] [G loss: 0.374282]\n",
      "epoch:1 step:1459 [D loss: 0.490535, acc.: 78.12%] [G loss: 0.323298]\n",
      "epoch:1 step:1460 [D loss: 0.450859, acc.: 86.72%] [G loss: 0.406652]\n",
      "epoch:1 step:1461 [D loss: 0.480463, acc.: 80.47%] [G loss: 0.360919]\n",
      "epoch:1 step:1462 [D loss: 0.524474, acc.: 80.47%] [G loss: 0.390777]\n",
      "epoch:1 step:1463 [D loss: 0.478645, acc.: 78.12%] [G loss: 0.380632]\n",
      "epoch:1 step:1464 [D loss: 0.499355, acc.: 84.38%] [G loss: 0.317443]\n",
      "epoch:1 step:1465 [D loss: 0.493023, acc.: 83.59%] [G loss: 0.454717]\n",
      "epoch:1 step:1466 [D loss: 0.457042, acc.: 83.59%] [G loss: 0.429667]\n",
      "epoch:1 step:1467 [D loss: 0.454219, acc.: 86.72%] [G loss: 0.505818]\n",
      "epoch:1 step:1468 [D loss: 0.512835, acc.: 82.03%] [G loss: 0.386928]\n",
      "epoch:1 step:1469 [D loss: 0.472143, acc.: 85.16%] [G loss: 0.452550]\n",
      "epoch:1 step:1470 [D loss: 0.471172, acc.: 82.81%] [G loss: 0.416287]\n",
      "epoch:1 step:1471 [D loss: 0.492467, acc.: 77.34%] [G loss: 0.429921]\n",
      "epoch:1 step:1472 [D loss: 0.499160, acc.: 84.38%] [G loss: 0.340231]\n",
      "epoch:1 step:1473 [D loss: 0.481207, acc.: 78.91%] [G loss: 0.333421]\n",
      "epoch:1 step:1474 [D loss: 0.516318, acc.: 74.22%] [G loss: 0.355195]\n",
      "epoch:1 step:1475 [D loss: 0.498537, acc.: 84.38%] [G loss: 0.386041]\n",
      "epoch:1 step:1476 [D loss: 0.551409, acc.: 69.53%] [G loss: 0.377420]\n",
      "epoch:1 step:1477 [D loss: 0.520113, acc.: 75.00%] [G loss: 0.427157]\n",
      "epoch:1 step:1478 [D loss: 0.477201, acc.: 82.81%] [G loss: 0.362079]\n",
      "epoch:1 step:1479 [D loss: 0.514894, acc.: 78.91%] [G loss: 0.276531]\n",
      "epoch:1 step:1480 [D loss: 0.539588, acc.: 76.56%] [G loss: 0.328466]\n",
      "epoch:1 step:1481 [D loss: 0.435706, acc.: 89.84%] [G loss: 0.381943]\n",
      "epoch:1 step:1482 [D loss: 0.541634, acc.: 77.34%] [G loss: 0.289060]\n",
      "epoch:1 step:1483 [D loss: 0.460951, acc.: 82.81%] [G loss: 0.394075]\n",
      "epoch:1 step:1484 [D loss: 0.446510, acc.: 85.94%] [G loss: 0.405004]\n",
      "epoch:1 step:1485 [D loss: 0.461711, acc.: 79.69%] [G loss: 0.425864]\n",
      "epoch:1 step:1486 [D loss: 0.500263, acc.: 74.22%] [G loss: 0.385069]\n",
      "epoch:1 step:1487 [D loss: 0.485443, acc.: 81.25%] [G loss: 0.441794]\n",
      "epoch:1 step:1488 [D loss: 0.529788, acc.: 74.22%] [G loss: 0.368230]\n",
      "epoch:1 step:1489 [D loss: 0.499222, acc.: 78.12%] [G loss: 0.431373]\n",
      "epoch:1 step:1490 [D loss: 0.469683, acc.: 82.03%] [G loss: 0.386031]\n",
      "epoch:1 step:1491 [D loss: 0.438630, acc.: 87.50%] [G loss: 0.388954]\n",
      "epoch:1 step:1492 [D loss: 0.454095, acc.: 79.69%] [G loss: 0.496859]\n",
      "epoch:1 step:1493 [D loss: 0.448229, acc.: 86.72%] [G loss: 0.488339]\n",
      "epoch:1 step:1494 [D loss: 0.454771, acc.: 82.81%] [G loss: 0.533468]\n",
      "epoch:1 step:1495 [D loss: 0.448738, acc.: 84.38%] [G loss: 0.547863]\n",
      "epoch:1 step:1496 [D loss: 0.546343, acc.: 73.44%] [G loss: 0.449927]\n",
      "epoch:1 step:1497 [D loss: 0.526905, acc.: 75.00%] [G loss: 0.399981]\n",
      "epoch:1 step:1498 [D loss: 0.506723, acc.: 79.69%] [G loss: 0.403836]\n",
      "epoch:1 step:1499 [D loss: 0.543738, acc.: 70.31%] [G loss: 0.462824]\n",
      "epoch:1 step:1500 [D loss: 0.490355, acc.: 80.47%] [G loss: 0.474249]\n",
      "epoch:1 step:1501 [D loss: 0.481898, acc.: 80.47%] [G loss: 0.461703]\n",
      "epoch:1 step:1502 [D loss: 0.464754, acc.: 84.38%] [G loss: 0.497056]\n",
      "epoch:1 step:1503 [D loss: 0.513365, acc.: 80.47%] [G loss: 0.485143]\n",
      "epoch:1 step:1504 [D loss: 0.427030, acc.: 85.16%] [G loss: 0.575063]\n",
      "epoch:1 step:1505 [D loss: 0.481487, acc.: 85.16%] [G loss: 0.467628]\n",
      "epoch:1 step:1506 [D loss: 0.510752, acc.: 80.47%] [G loss: 0.331165]\n",
      "epoch:1 step:1507 [D loss: 0.514731, acc.: 76.56%] [G loss: 0.374148]\n",
      "epoch:1 step:1508 [D loss: 0.483794, acc.: 82.03%] [G loss: 0.357208]\n",
      "epoch:1 step:1509 [D loss: 0.507554, acc.: 75.78%] [G loss: 0.402235]\n",
      "epoch:1 step:1510 [D loss: 0.448466, acc.: 81.25%] [G loss: 0.452289]\n",
      "epoch:1 step:1511 [D loss: 0.495197, acc.: 78.91%] [G loss: 0.414872]\n",
      "epoch:1 step:1512 [D loss: 0.463579, acc.: 79.69%] [G loss: 0.426912]\n",
      "epoch:1 step:1513 [D loss: 0.541128, acc.: 72.66%] [G loss: 0.377401]\n",
      "epoch:1 step:1514 [D loss: 0.539035, acc.: 73.44%] [G loss: 0.451670]\n",
      "epoch:1 step:1515 [D loss: 0.497714, acc.: 80.47%] [G loss: 0.397169]\n",
      "epoch:1 step:1516 [D loss: 0.482746, acc.: 79.69%] [G loss: 0.477262]\n",
      "epoch:1 step:1517 [D loss: 0.513206, acc.: 78.91%] [G loss: 0.344415]\n",
      "epoch:1 step:1518 [D loss: 0.503522, acc.: 76.56%] [G loss: 0.379606]\n",
      "epoch:1 step:1519 [D loss: 0.408029, acc.: 85.94%] [G loss: 0.474903]\n",
      "epoch:1 step:1520 [D loss: 0.552976, acc.: 75.78%] [G loss: 0.400054]\n",
      "epoch:1 step:1521 [D loss: 0.557514, acc.: 72.66%] [G loss: 0.354741]\n",
      "epoch:1 step:1522 [D loss: 0.503714, acc.: 80.47%] [G loss: 0.375634]\n",
      "epoch:1 step:1523 [D loss: 0.553979, acc.: 74.22%] [G loss: 0.309245]\n",
      "epoch:1 step:1524 [D loss: 0.537697, acc.: 73.44%] [G loss: 0.326512]\n",
      "epoch:1 step:1525 [D loss: 0.522470, acc.: 76.56%] [G loss: 0.399596]\n",
      "epoch:1 step:1526 [D loss: 0.489566, acc.: 78.91%] [G loss: 0.402628]\n",
      "epoch:1 step:1527 [D loss: 0.481606, acc.: 78.12%] [G loss: 0.426297]\n",
      "epoch:1 step:1528 [D loss: 0.534531, acc.: 76.56%] [G loss: 0.364393]\n",
      "epoch:1 step:1529 [D loss: 0.456151, acc.: 80.47%] [G loss: 0.472797]\n",
      "epoch:1 step:1530 [D loss: 0.530027, acc.: 75.78%] [G loss: 0.430830]\n",
      "epoch:1 step:1531 [D loss: 0.492119, acc.: 78.91%] [G loss: 0.430723]\n",
      "epoch:1 step:1532 [D loss: 0.550692, acc.: 74.22%] [G loss: 0.368442]\n",
      "epoch:1 step:1533 [D loss: 0.496810, acc.: 78.12%] [G loss: 0.428119]\n",
      "epoch:1 step:1534 [D loss: 0.489678, acc.: 78.91%] [G loss: 0.367939]\n",
      "epoch:1 step:1535 [D loss: 0.494825, acc.: 75.00%] [G loss: 0.426358]\n",
      "epoch:1 step:1536 [D loss: 0.521751, acc.: 75.00%] [G loss: 0.454075]\n",
      "epoch:1 step:1537 [D loss: 0.522539, acc.: 78.12%] [G loss: 0.354477]\n",
      "epoch:1 step:1538 [D loss: 0.522742, acc.: 77.34%] [G loss: 0.297952]\n",
      "epoch:1 step:1539 [D loss: 0.463930, acc.: 83.59%] [G loss: 0.415074]\n",
      "epoch:1 step:1540 [D loss: 0.475811, acc.: 80.47%] [G loss: 0.482586]\n",
      "epoch:1 step:1541 [D loss: 0.548123, acc.: 78.12%] [G loss: 0.415696]\n",
      "epoch:1 step:1542 [D loss: 0.452496, acc.: 85.16%] [G loss: 0.392595]\n",
      "epoch:1 step:1543 [D loss: 0.487735, acc.: 82.03%] [G loss: 0.393283]\n",
      "epoch:1 step:1544 [D loss: 0.496379, acc.: 79.69%] [G loss: 0.389930]\n",
      "epoch:1 step:1545 [D loss: 0.480507, acc.: 82.03%] [G loss: 0.352195]\n",
      "epoch:1 step:1546 [D loss: 0.435331, acc.: 86.72%] [G loss: 0.424621]\n",
      "epoch:1 step:1547 [D loss: 0.487111, acc.: 72.66%] [G loss: 0.392237]\n",
      "epoch:1 step:1548 [D loss: 0.459269, acc.: 81.25%] [G loss: 0.500173]\n",
      "epoch:1 step:1549 [D loss: 0.425639, acc.: 88.28%] [G loss: 0.472571]\n",
      "epoch:1 step:1550 [D loss: 0.461047, acc.: 82.03%] [G loss: 0.488180]\n",
      "epoch:1 step:1551 [D loss: 0.495472, acc.: 78.12%] [G loss: 0.399053]\n",
      "epoch:1 step:1552 [D loss: 0.521981, acc.: 78.12%] [G loss: 0.351131]\n",
      "epoch:1 step:1553 [D loss: 0.492142, acc.: 75.78%] [G loss: 0.357445]\n",
      "epoch:1 step:1554 [D loss: 0.500337, acc.: 76.56%] [G loss: 0.365145]\n",
      "epoch:1 step:1555 [D loss: 0.459785, acc.: 85.16%] [G loss: 0.452537]\n",
      "epoch:1 step:1556 [D loss: 0.446381, acc.: 83.59%] [G loss: 0.427491]\n",
      "epoch:1 step:1557 [D loss: 0.504944, acc.: 78.91%] [G loss: 0.429686]\n",
      "epoch:1 step:1558 [D loss: 0.529399, acc.: 75.00%] [G loss: 0.354748]\n",
      "epoch:1 step:1559 [D loss: 0.559272, acc.: 71.88%] [G loss: 0.383603]\n",
      "epoch:1 step:1560 [D loss: 0.491412, acc.: 79.69%] [G loss: 0.346772]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1561 [D loss: 0.551690, acc.: 68.75%] [G loss: 0.355209]\n",
      "epoch:1 step:1562 [D loss: 0.503640, acc.: 77.34%] [G loss: 0.402985]\n",
      "epoch:1 step:1563 [D loss: 0.493512, acc.: 78.12%] [G loss: 0.345431]\n",
      "epoch:1 step:1564 [D loss: 0.490512, acc.: 78.12%] [G loss: 0.396315]\n",
      "epoch:1 step:1565 [D loss: 0.478114, acc.: 81.25%] [G loss: 0.357221]\n",
      "epoch:1 step:1566 [D loss: 0.450420, acc.: 82.81%] [G loss: 0.460559]\n",
      "epoch:1 step:1567 [D loss: 0.425342, acc.: 89.06%] [G loss: 0.517562]\n",
      "epoch:1 step:1568 [D loss: 0.470509, acc.: 83.59%] [G loss: 0.453747]\n",
      "epoch:1 step:1569 [D loss: 0.426214, acc.: 89.06%] [G loss: 0.429574]\n",
      "epoch:1 step:1570 [D loss: 0.463479, acc.: 83.59%] [G loss: 0.432683]\n",
      "epoch:1 step:1571 [D loss: 0.466496, acc.: 81.25%] [G loss: 0.364098]\n",
      "epoch:1 step:1572 [D loss: 0.482437, acc.: 74.22%] [G loss: 0.444649]\n",
      "epoch:1 step:1573 [D loss: 0.566149, acc.: 71.09%] [G loss: 0.332408]\n",
      "epoch:1 step:1574 [D loss: 0.530081, acc.: 76.56%] [G loss: 0.319020]\n",
      "epoch:1 step:1575 [D loss: 0.478199, acc.: 78.91%] [G loss: 0.449131]\n",
      "epoch:1 step:1576 [D loss: 0.437705, acc.: 84.38%] [G loss: 0.529383]\n",
      "epoch:1 step:1577 [D loss: 0.540175, acc.: 75.78%] [G loss: 0.438639]\n",
      "epoch:1 step:1578 [D loss: 0.476268, acc.: 81.25%] [G loss: 0.485085]\n",
      "epoch:1 step:1579 [D loss: 0.432868, acc.: 88.28%] [G loss: 0.617115]\n",
      "epoch:1 step:1580 [D loss: 0.504081, acc.: 81.25%] [G loss: 0.459912]\n",
      "epoch:1 step:1581 [D loss: 0.543837, acc.: 76.56%] [G loss: 0.380382]\n",
      "epoch:1 step:1582 [D loss: 0.565946, acc.: 69.53%] [G loss: 0.345925]\n",
      "epoch:1 step:1583 [D loss: 0.519348, acc.: 78.91%] [G loss: 0.345663]\n",
      "epoch:1 step:1584 [D loss: 0.480937, acc.: 81.25%] [G loss: 0.454141]\n",
      "epoch:1 step:1585 [D loss: 0.461438, acc.: 81.25%] [G loss: 0.546532]\n",
      "epoch:1 step:1586 [D loss: 0.490667, acc.: 82.03%] [G loss: 0.518794]\n",
      "epoch:1 step:1587 [D loss: 0.489343, acc.: 77.34%] [G loss: 0.485448]\n",
      "epoch:1 step:1588 [D loss: 0.484785, acc.: 79.69%] [G loss: 0.539406]\n",
      "epoch:1 step:1589 [D loss: 0.650206, acc.: 60.16%] [G loss: 0.335979]\n",
      "epoch:1 step:1590 [D loss: 0.553407, acc.: 71.09%] [G loss: 0.408697]\n",
      "epoch:1 step:1591 [D loss: 0.449326, acc.: 87.50%] [G loss: 0.501092]\n",
      "epoch:1 step:1592 [D loss: 0.553810, acc.: 75.78%] [G loss: 0.424657]\n",
      "epoch:1 step:1593 [D loss: 0.509394, acc.: 81.25%] [G loss: 0.358956]\n",
      "epoch:1 step:1594 [D loss: 0.476880, acc.: 79.69%] [G loss: 0.363388]\n",
      "epoch:1 step:1595 [D loss: 0.491334, acc.: 77.34%] [G loss: 0.410017]\n",
      "epoch:1 step:1596 [D loss: 0.483591, acc.: 85.16%] [G loss: 0.454162]\n",
      "epoch:1 step:1597 [D loss: 0.462104, acc.: 85.94%] [G loss: 0.423502]\n",
      "epoch:1 step:1598 [D loss: 0.426149, acc.: 88.28%] [G loss: 0.514211]\n",
      "epoch:1 step:1599 [D loss: 0.555027, acc.: 68.75%] [G loss: 0.407059]\n",
      "epoch:1 step:1600 [D loss: 0.464851, acc.: 82.03%] [G loss: 0.372396]\n",
      "##############\n",
      "[4.82145288 3.48376731 8.64417051 7.09511169 6.0581628  7.16308213\n",
      " 6.78361963 6.95294687 7.1062003  5.60712472]\n",
      "##########\n",
      "epoch:1 step:1601 [D loss: 0.514002, acc.: 75.78%] [G loss: 0.436392]\n",
      "epoch:1 step:1602 [D loss: 0.474204, acc.: 80.47%] [G loss: 0.605700]\n",
      "epoch:1 step:1603 [D loss: 0.464791, acc.: 82.03%] [G loss: 0.666979]\n",
      "epoch:1 step:1604 [D loss: 0.484427, acc.: 79.69%] [G loss: 0.605901]\n",
      "epoch:1 step:1605 [D loss: 0.494367, acc.: 82.03%] [G loss: 0.468608]\n",
      "epoch:1 step:1606 [D loss: 0.450695, acc.: 85.16%] [G loss: 0.518613]\n",
      "epoch:1 step:1607 [D loss: 0.443272, acc.: 83.59%] [G loss: 0.523569]\n",
      "epoch:1 step:1608 [D loss: 0.444349, acc.: 85.16%] [G loss: 0.513695]\n",
      "epoch:1 step:1609 [D loss: 0.581521, acc.: 69.53%] [G loss: 0.334480]\n",
      "epoch:1 step:1610 [D loss: 0.484624, acc.: 80.47%] [G loss: 0.375553]\n",
      "epoch:1 step:1611 [D loss: 0.533987, acc.: 77.34%] [G loss: 0.400482]\n",
      "epoch:1 step:1612 [D loss: 0.445100, acc.: 85.16%] [G loss: 0.445792]\n",
      "epoch:1 step:1613 [D loss: 0.511327, acc.: 77.34%] [G loss: 0.438274]\n",
      "epoch:1 step:1614 [D loss: 0.424733, acc.: 89.84%] [G loss: 0.521756]\n",
      "epoch:1 step:1615 [D loss: 0.438357, acc.: 85.94%] [G loss: 0.453436]\n",
      "epoch:1 step:1616 [D loss: 0.468872, acc.: 83.59%] [G loss: 0.458296]\n",
      "epoch:1 step:1617 [D loss: 0.408796, acc.: 87.50%] [G loss: 0.499111]\n",
      "epoch:1 step:1618 [D loss: 0.456028, acc.: 84.38%] [G loss: 0.483837]\n",
      "epoch:1 step:1619 [D loss: 0.445562, acc.: 87.50%] [G loss: 0.427055]\n",
      "epoch:1 step:1620 [D loss: 0.486457, acc.: 79.69%] [G loss: 0.364558]\n",
      "epoch:1 step:1621 [D loss: 0.427297, acc.: 89.06%] [G loss: 0.448253]\n",
      "epoch:1 step:1622 [D loss: 0.500507, acc.: 78.12%] [G loss: 0.452180]\n",
      "epoch:1 step:1623 [D loss: 0.476349, acc.: 82.81%] [G loss: 0.398923]\n",
      "epoch:1 step:1624 [D loss: 0.454061, acc.: 85.94%] [G loss: 0.403070]\n",
      "epoch:1 step:1625 [D loss: 0.502868, acc.: 76.56%] [G loss: 0.370569]\n",
      "epoch:1 step:1626 [D loss: 0.459641, acc.: 82.81%] [G loss: 0.410573]\n",
      "epoch:1 step:1627 [D loss: 0.463410, acc.: 82.03%] [G loss: 0.506144]\n",
      "epoch:1 step:1628 [D loss: 0.481102, acc.: 78.12%] [G loss: 0.520100]\n",
      "epoch:1 step:1629 [D loss: 0.508438, acc.: 78.12%] [G loss: 0.434537]\n",
      "epoch:1 step:1630 [D loss: 0.501139, acc.: 75.78%] [G loss: 0.443221]\n",
      "epoch:1 step:1631 [D loss: 0.448932, acc.: 89.06%] [G loss: 0.470243]\n",
      "epoch:1 step:1632 [D loss: 0.434497, acc.: 86.72%] [G loss: 0.500435]\n",
      "epoch:1 step:1633 [D loss: 0.485927, acc.: 80.47%] [G loss: 0.486514]\n",
      "epoch:1 step:1634 [D loss: 0.430371, acc.: 84.38%] [G loss: 0.473876]\n",
      "epoch:1 step:1635 [D loss: 0.498339, acc.: 81.25%] [G loss: 0.407948]\n",
      "epoch:1 step:1636 [D loss: 0.481093, acc.: 79.69%] [G loss: 0.403278]\n",
      "epoch:1 step:1637 [D loss: 0.455441, acc.: 85.16%] [G loss: 0.608371]\n",
      "epoch:1 step:1638 [D loss: 0.466649, acc.: 82.03%] [G loss: 0.581036]\n",
      "epoch:1 step:1639 [D loss: 0.506645, acc.: 74.22%] [G loss: 0.486144]\n",
      "epoch:1 step:1640 [D loss: 0.454947, acc.: 82.03%] [G loss: 0.457835]\n",
      "epoch:1 step:1641 [D loss: 0.554442, acc.: 73.44%] [G loss: 0.396139]\n",
      "epoch:1 step:1642 [D loss: 0.461496, acc.: 79.69%] [G loss: 0.402103]\n",
      "epoch:1 step:1643 [D loss: 0.471156, acc.: 81.25%] [G loss: 0.454501]\n",
      "epoch:1 step:1644 [D loss: 0.401883, acc.: 90.62%] [G loss: 0.634640]\n",
      "epoch:1 step:1645 [D loss: 0.409139, acc.: 87.50%] [G loss: 0.786809]\n",
      "epoch:1 step:1646 [D loss: 0.421578, acc.: 85.16%] [G loss: 0.729283]\n",
      "epoch:1 step:1647 [D loss: 0.597192, acc.: 69.53%] [G loss: 0.435438]\n",
      "epoch:1 step:1648 [D loss: 0.565356, acc.: 67.19%] [G loss: 0.363039]\n",
      "epoch:1 step:1649 [D loss: 0.465463, acc.: 82.03%] [G loss: 0.452085]\n",
      "epoch:1 step:1650 [D loss: 0.437824, acc.: 88.28%] [G loss: 0.458131]\n",
      "epoch:1 step:1651 [D loss: 0.451922, acc.: 86.72%] [G loss: 0.519567]\n",
      "epoch:1 step:1652 [D loss: 0.478767, acc.: 81.25%] [G loss: 0.461031]\n",
      "epoch:1 step:1653 [D loss: 0.555628, acc.: 73.44%] [G loss: 0.360819]\n",
      "epoch:1 step:1654 [D loss: 0.540673, acc.: 72.66%] [G loss: 0.326334]\n",
      "epoch:1 step:1655 [D loss: 0.492698, acc.: 81.25%] [G loss: 0.377478]\n",
      "epoch:1 step:1656 [D loss: 0.484139, acc.: 82.03%] [G loss: 0.412835]\n",
      "epoch:1 step:1657 [D loss: 0.544409, acc.: 73.44%] [G loss: 0.341316]\n",
      "epoch:1 step:1658 [D loss: 0.517949, acc.: 73.44%] [G loss: 0.379647]\n",
      "epoch:1 step:1659 [D loss: 0.472196, acc.: 82.81%] [G loss: 0.469334]\n",
      "epoch:1 step:1660 [D loss: 0.571790, acc.: 67.19%] [G loss: 0.407608]\n",
      "epoch:1 step:1661 [D loss: 0.461277, acc.: 82.81%] [G loss: 0.462904]\n",
      "epoch:1 step:1662 [D loss: 0.478740, acc.: 82.03%] [G loss: 0.558836]\n",
      "epoch:1 step:1663 [D loss: 0.456532, acc.: 83.59%] [G loss: 0.530245]\n",
      "epoch:1 step:1664 [D loss: 0.499687, acc.: 78.12%] [G loss: 0.416259]\n",
      "epoch:1 step:1665 [D loss: 0.484871, acc.: 82.81%] [G loss: 0.392715]\n",
      "epoch:1 step:1666 [D loss: 0.466407, acc.: 80.47%] [G loss: 0.417290]\n",
      "epoch:1 step:1667 [D loss: 0.467691, acc.: 86.72%] [G loss: 0.459943]\n",
      "epoch:1 step:1668 [D loss: 0.452359, acc.: 85.94%] [G loss: 0.417757]\n",
      "epoch:1 step:1669 [D loss: 0.470090, acc.: 79.69%] [G loss: 0.559172]\n",
      "epoch:1 step:1670 [D loss: 0.414610, acc.: 88.28%] [G loss: 0.590809]\n",
      "epoch:1 step:1671 [D loss: 0.417802, acc.: 86.72%] [G loss: 0.624710]\n",
      "epoch:1 step:1672 [D loss: 0.474717, acc.: 82.03%] [G loss: 0.445095]\n",
      "epoch:1 step:1673 [D loss: 0.427171, acc.: 88.28%] [G loss: 0.507675]\n",
      "epoch:1 step:1674 [D loss: 0.456517, acc.: 83.59%] [G loss: 0.509151]\n",
      "epoch:1 step:1675 [D loss: 0.490485, acc.: 78.91%] [G loss: 0.496403]\n",
      "epoch:1 step:1676 [D loss: 0.524002, acc.: 78.12%] [G loss: 0.494231]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1677 [D loss: 0.500201, acc.: 77.34%] [G loss: 0.404238]\n",
      "epoch:1 step:1678 [D loss: 0.443738, acc.: 83.59%] [G loss: 0.459887]\n",
      "epoch:1 step:1679 [D loss: 0.466706, acc.: 83.59%] [G loss: 0.498954]\n",
      "epoch:1 step:1680 [D loss: 0.462834, acc.: 81.25%] [G loss: 0.492148]\n",
      "epoch:1 step:1681 [D loss: 0.482954, acc.: 79.69%] [G loss: 0.438499]\n",
      "epoch:1 step:1682 [D loss: 0.519036, acc.: 72.66%] [G loss: 0.436569]\n",
      "epoch:1 step:1683 [D loss: 0.422226, acc.: 86.72%] [G loss: 0.650688]\n",
      "epoch:1 step:1684 [D loss: 0.406999, acc.: 87.50%] [G loss: 0.581790]\n",
      "epoch:1 step:1685 [D loss: 0.420541, acc.: 87.50%] [G loss: 0.553981]\n",
      "epoch:1 step:1686 [D loss: 0.475637, acc.: 79.69%] [G loss: 0.487131]\n",
      "epoch:1 step:1687 [D loss: 0.467109, acc.: 82.03%] [G loss: 0.431582]\n",
      "epoch:1 step:1688 [D loss: 0.442514, acc.: 81.25%] [G loss: 0.493946]\n",
      "epoch:1 step:1689 [D loss: 0.440696, acc.: 83.59%] [G loss: 0.550347]\n",
      "epoch:1 step:1690 [D loss: 0.413804, acc.: 84.38%] [G loss: 0.613144]\n",
      "epoch:1 step:1691 [D loss: 0.414513, acc.: 89.84%] [G loss: 0.600686]\n",
      "epoch:1 step:1692 [D loss: 0.407439, acc.: 87.50%] [G loss: 0.655601]\n",
      "epoch:1 step:1693 [D loss: 0.443456, acc.: 83.59%] [G loss: 0.650963]\n",
      "epoch:1 step:1694 [D loss: 0.442012, acc.: 82.81%] [G loss: 0.577705]\n",
      "epoch:1 step:1695 [D loss: 0.507509, acc.: 76.56%] [G loss: 0.546711]\n",
      "epoch:1 step:1696 [D loss: 0.461190, acc.: 80.47%] [G loss: 0.569200]\n",
      "epoch:1 step:1697 [D loss: 0.473815, acc.: 83.59%] [G loss: 0.555058]\n",
      "epoch:1 step:1698 [D loss: 0.490537, acc.: 80.47%] [G loss: 0.538945]\n",
      "epoch:1 step:1699 [D loss: 0.472685, acc.: 81.25%] [G loss: 0.467550]\n",
      "epoch:1 step:1700 [D loss: 0.475006, acc.: 82.03%] [G loss: 0.418702]\n",
      "epoch:1 step:1701 [D loss: 0.462027, acc.: 82.81%] [G loss: 0.471563]\n",
      "epoch:1 step:1702 [D loss: 0.589600, acc.: 69.53%] [G loss: 0.362525]\n",
      "epoch:1 step:1703 [D loss: 0.543999, acc.: 74.22%] [G loss: 0.404884]\n",
      "epoch:1 step:1704 [D loss: 0.488708, acc.: 78.12%] [G loss: 0.508844]\n",
      "epoch:1 step:1705 [D loss: 0.456038, acc.: 82.03%] [G loss: 0.596421]\n",
      "epoch:1 step:1706 [D loss: 0.453891, acc.: 81.25%] [G loss: 0.668297]\n",
      "epoch:1 step:1707 [D loss: 0.493169, acc.: 79.69%] [G loss: 0.558754]\n",
      "epoch:1 step:1708 [D loss: 0.486100, acc.: 81.25%] [G loss: 0.568950]\n",
      "epoch:1 step:1709 [D loss: 0.480742, acc.: 81.25%] [G loss: 0.473342]\n",
      "epoch:1 step:1710 [D loss: 0.473566, acc.: 84.38%] [G loss: 0.427254]\n",
      "epoch:1 step:1711 [D loss: 0.513668, acc.: 76.56%] [G loss: 0.400317]\n",
      "epoch:1 step:1712 [D loss: 0.447168, acc.: 85.16%] [G loss: 0.506771]\n",
      "epoch:1 step:1713 [D loss: 0.503200, acc.: 77.34%] [G loss: 0.453723]\n",
      "epoch:1 step:1714 [D loss: 0.496587, acc.: 79.69%] [G loss: 0.450904]\n",
      "epoch:1 step:1715 [D loss: 0.497547, acc.: 75.78%] [G loss: 0.428438]\n",
      "epoch:1 step:1716 [D loss: 0.522460, acc.: 76.56%] [G loss: 0.432885]\n",
      "epoch:1 step:1717 [D loss: 0.536465, acc.: 73.44%] [G loss: 0.496776]\n",
      "epoch:1 step:1718 [D loss: 0.466391, acc.: 84.38%] [G loss: 0.511734]\n",
      "epoch:1 step:1719 [D loss: 0.466501, acc.: 79.69%] [G loss: 0.592253]\n",
      "epoch:1 step:1720 [D loss: 0.524976, acc.: 69.53%] [G loss: 0.507645]\n",
      "epoch:1 step:1721 [D loss: 0.498503, acc.: 76.56%] [G loss: 0.501083]\n",
      "epoch:1 step:1722 [D loss: 0.521150, acc.: 78.12%] [G loss: 0.461251]\n",
      "epoch:1 step:1723 [D loss: 0.428903, acc.: 87.50%] [G loss: 0.548671]\n",
      "epoch:1 step:1724 [D loss: 0.492741, acc.: 82.81%] [G loss: 0.465785]\n",
      "epoch:1 step:1725 [D loss: 0.531205, acc.: 77.34%] [G loss: 0.419242]\n",
      "epoch:1 step:1726 [D loss: 0.495061, acc.: 81.25%] [G loss: 0.360829]\n",
      "epoch:1 step:1727 [D loss: 0.463775, acc.: 83.59%] [G loss: 0.577475]\n",
      "epoch:1 step:1728 [D loss: 0.490275, acc.: 81.25%] [G loss: 0.475941]\n",
      "epoch:1 step:1729 [D loss: 0.448993, acc.: 83.59%] [G loss: 0.537659]\n",
      "epoch:1 step:1730 [D loss: 0.484731, acc.: 79.69%] [G loss: 0.519397]\n",
      "epoch:1 step:1731 [D loss: 0.530999, acc.: 71.88%] [G loss: 0.499667]\n",
      "epoch:1 step:1732 [D loss: 0.441302, acc.: 81.25%] [G loss: 0.514872]\n",
      "epoch:1 step:1733 [D loss: 0.425642, acc.: 85.94%] [G loss: 0.669728]\n",
      "epoch:1 step:1734 [D loss: 0.485303, acc.: 81.25%] [G loss: 0.533803]\n",
      "epoch:1 step:1735 [D loss: 0.431623, acc.: 82.81%] [G loss: 0.566298]\n",
      "epoch:1 step:1736 [D loss: 0.482996, acc.: 80.47%] [G loss: 0.472471]\n",
      "epoch:1 step:1737 [D loss: 0.466241, acc.: 82.81%] [G loss: 0.462147]\n",
      "epoch:1 step:1738 [D loss: 0.450665, acc.: 85.16%] [G loss: 0.495875]\n",
      "epoch:1 step:1739 [D loss: 0.401808, acc.: 84.38%] [G loss: 0.583974]\n",
      "epoch:1 step:1740 [D loss: 0.442267, acc.: 81.25%] [G loss: 0.583653]\n",
      "epoch:1 step:1741 [D loss: 0.472555, acc.: 83.59%] [G loss: 0.493763]\n",
      "epoch:1 step:1742 [D loss: 0.450331, acc.: 86.72%] [G loss: 0.458195]\n",
      "epoch:1 step:1743 [D loss: 0.440852, acc.: 84.38%] [G loss: 0.391687]\n",
      "epoch:1 step:1744 [D loss: 0.433866, acc.: 82.81%] [G loss: 0.598465]\n",
      "epoch:1 step:1745 [D loss: 0.536359, acc.: 76.56%] [G loss: 0.487555]\n",
      "epoch:1 step:1746 [D loss: 0.510188, acc.: 79.69%] [G loss: 0.442845]\n",
      "epoch:1 step:1747 [D loss: 0.462121, acc.: 83.59%] [G loss: 0.442931]\n",
      "epoch:1 step:1748 [D loss: 0.488997, acc.: 82.03%] [G loss: 0.438507]\n",
      "epoch:1 step:1749 [D loss: 0.484903, acc.: 82.03%] [G loss: 0.455118]\n",
      "epoch:1 step:1750 [D loss: 0.463525, acc.: 81.25%] [G loss: 0.477090]\n",
      "epoch:1 step:1751 [D loss: 0.474392, acc.: 85.94%] [G loss: 0.399320]\n",
      "epoch:1 step:1752 [D loss: 0.537424, acc.: 77.34%] [G loss: 0.396023]\n",
      "epoch:1 step:1753 [D loss: 0.437749, acc.: 81.25%] [G loss: 0.531512]\n",
      "epoch:1 step:1754 [D loss: 0.528028, acc.: 77.34%] [G loss: 0.430535]\n",
      "epoch:1 step:1755 [D loss: 0.473702, acc.: 81.25%] [G loss: 0.416606]\n",
      "epoch:1 step:1756 [D loss: 0.464465, acc.: 81.25%] [G loss: 0.502748]\n",
      "epoch:1 step:1757 [D loss: 0.492836, acc.: 75.78%] [G loss: 0.525582]\n",
      "epoch:1 step:1758 [D loss: 0.448597, acc.: 84.38%] [G loss: 0.483496]\n",
      "epoch:1 step:1759 [D loss: 0.431107, acc.: 83.59%] [G loss: 0.551824]\n",
      "epoch:1 step:1760 [D loss: 0.420116, acc.: 85.16%] [G loss: 0.670951]\n",
      "epoch:1 step:1761 [D loss: 0.576540, acc.: 75.78%] [G loss: 0.394256]\n",
      "epoch:1 step:1762 [D loss: 0.496043, acc.: 81.25%] [G loss: 0.390365]\n",
      "epoch:1 step:1763 [D loss: 0.533152, acc.: 75.00%] [G loss: 0.395212]\n",
      "epoch:1 step:1764 [D loss: 0.526481, acc.: 77.34%] [G loss: 0.425088]\n",
      "epoch:1 step:1765 [D loss: 0.497257, acc.: 75.78%] [G loss: 0.457614]\n",
      "epoch:1 step:1766 [D loss: 0.455917, acc.: 85.16%] [G loss: 0.516913]\n",
      "epoch:1 step:1767 [D loss: 0.461540, acc.: 82.81%] [G loss: 0.580806]\n",
      "epoch:1 step:1768 [D loss: 0.529132, acc.: 75.00%] [G loss: 0.417256]\n",
      "epoch:1 step:1769 [D loss: 0.451411, acc.: 81.25%] [G loss: 0.558815]\n",
      "epoch:1 step:1770 [D loss: 0.416720, acc.: 89.84%] [G loss: 0.541910]\n",
      "epoch:1 step:1771 [D loss: 0.420029, acc.: 90.62%] [G loss: 0.506409]\n",
      "epoch:1 step:1772 [D loss: 0.481377, acc.: 80.47%] [G loss: 0.464366]\n",
      "epoch:1 step:1773 [D loss: 0.496881, acc.: 76.56%] [G loss: 0.451722]\n",
      "epoch:1 step:1774 [D loss: 0.453558, acc.: 82.03%] [G loss: 0.472360]\n",
      "epoch:1 step:1775 [D loss: 0.466698, acc.: 80.47%] [G loss: 0.446550]\n",
      "epoch:1 step:1776 [D loss: 0.449839, acc.: 81.25%] [G loss: 0.506181]\n",
      "epoch:1 step:1777 [D loss: 0.513441, acc.: 77.34%] [G loss: 0.425377]\n",
      "epoch:1 step:1778 [D loss: 0.463767, acc.: 80.47%] [G loss: 0.496463]\n",
      "epoch:1 step:1779 [D loss: 0.439428, acc.: 87.50%] [G loss: 0.462378]\n",
      "epoch:1 step:1780 [D loss: 0.444354, acc.: 82.03%] [G loss: 0.520317]\n",
      "epoch:1 step:1781 [D loss: 0.547571, acc.: 76.56%] [G loss: 0.355417]\n",
      "epoch:1 step:1782 [D loss: 0.474142, acc.: 85.94%] [G loss: 0.458093]\n",
      "epoch:1 step:1783 [D loss: 0.467413, acc.: 84.38%] [G loss: 0.432750]\n",
      "epoch:1 step:1784 [D loss: 0.444431, acc.: 84.38%] [G loss: 0.520773]\n",
      "epoch:1 step:1785 [D loss: 0.465449, acc.: 81.25%] [G loss: 0.508920]\n",
      "epoch:1 step:1786 [D loss: 0.475518, acc.: 82.81%] [G loss: 0.472363]\n",
      "epoch:1 step:1787 [D loss: 0.470300, acc.: 78.91%] [G loss: 0.488624]\n",
      "epoch:1 step:1788 [D loss: 0.435017, acc.: 83.59%] [G loss: 0.527125]\n",
      "epoch:1 step:1789 [D loss: 0.447955, acc.: 82.03%] [G loss: 0.685961]\n",
      "epoch:1 step:1790 [D loss: 0.399288, acc.: 88.28%] [G loss: 0.626239]\n",
      "epoch:1 step:1791 [D loss: 0.376454, acc.: 88.28%] [G loss: 0.859652]\n",
      "epoch:1 step:1792 [D loss: 0.462096, acc.: 79.69%] [G loss: 0.613541]\n",
      "epoch:1 step:1793 [D loss: 0.504335, acc.: 75.78%] [G loss: 0.569661]\n",
      "epoch:1 step:1794 [D loss: 0.418906, acc.: 83.59%] [G loss: 0.583119]\n",
      "epoch:1 step:1795 [D loss: 0.661906, acc.: 59.38%] [G loss: 0.357833]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1796 [D loss: 0.519920, acc.: 73.44%] [G loss: 0.346951]\n",
      "epoch:1 step:1797 [D loss: 0.485820, acc.: 79.69%] [G loss: 0.493629]\n",
      "epoch:1 step:1798 [D loss: 0.507099, acc.: 78.12%] [G loss: 0.498209]\n",
      "epoch:1 step:1799 [D loss: 0.462989, acc.: 78.12%] [G loss: 0.452342]\n",
      "epoch:1 step:1800 [D loss: 0.483420, acc.: 80.47%] [G loss: 0.481705]\n",
      "##############\n",
      "[4.84355673 3.15628643 8.49332449 6.83312516 6.06667852 7.46777314\n",
      " 6.99510042 6.77607631 7.03588478 5.96007937]\n",
      "##########\n",
      "epoch:1 step:1801 [D loss: 0.464665, acc.: 81.25%] [G loss: 0.474370]\n",
      "epoch:1 step:1802 [D loss: 0.490254, acc.: 77.34%] [G loss: 0.458440]\n",
      "epoch:1 step:1803 [D loss: 0.450950, acc.: 82.81%] [G loss: 0.503711]\n",
      "epoch:1 step:1804 [D loss: 0.483919, acc.: 81.25%] [G loss: 0.482555]\n",
      "epoch:1 step:1805 [D loss: 0.492456, acc.: 79.69%] [G loss: 0.358761]\n",
      "epoch:1 step:1806 [D loss: 0.430285, acc.: 82.03%] [G loss: 0.477236]\n",
      "epoch:1 step:1807 [D loss: 0.417050, acc.: 87.50%] [G loss: 0.568626]\n",
      "epoch:1 step:1808 [D loss: 0.413540, acc.: 84.38%] [G loss: 0.620548]\n",
      "epoch:1 step:1809 [D loss: 0.410047, acc.: 88.28%] [G loss: 0.626819]\n",
      "epoch:1 step:1810 [D loss: 0.464019, acc.: 82.03%] [G loss: 0.562720]\n",
      "epoch:1 step:1811 [D loss: 0.480069, acc.: 76.56%] [G loss: 0.575913]\n",
      "epoch:1 step:1812 [D loss: 0.396888, acc.: 86.72%] [G loss: 0.556806]\n",
      "epoch:1 step:1813 [D loss: 0.426997, acc.: 86.72%] [G loss: 0.593011]\n",
      "epoch:1 step:1814 [D loss: 0.417005, acc.: 85.16%] [G loss: 0.566601]\n",
      "epoch:1 step:1815 [D loss: 0.487626, acc.: 76.56%] [G loss: 0.486697]\n",
      "epoch:1 step:1816 [D loss: 0.468600, acc.: 79.69%] [G loss: 0.503313]\n",
      "epoch:1 step:1817 [D loss: 0.531759, acc.: 73.44%] [G loss: 0.453857]\n",
      "epoch:1 step:1818 [D loss: 0.473258, acc.: 83.59%] [G loss: 0.560473]\n",
      "epoch:1 step:1819 [D loss: 0.424511, acc.: 85.16%] [G loss: 0.589580]\n",
      "epoch:1 step:1820 [D loss: 0.463180, acc.: 81.25%] [G loss: 0.541046]\n",
      "epoch:1 step:1821 [D loss: 0.419561, acc.: 84.38%] [G loss: 0.587919]\n",
      "epoch:1 step:1822 [D loss: 0.398465, acc.: 83.59%] [G loss: 0.643895]\n",
      "epoch:1 step:1823 [D loss: 0.387103, acc.: 90.62%] [G loss: 0.669665]\n",
      "epoch:1 step:1824 [D loss: 0.400968, acc.: 85.16%] [G loss: 0.742641]\n",
      "epoch:1 step:1825 [D loss: 0.416270, acc.: 79.69%] [G loss: 0.753949]\n",
      "epoch:1 step:1826 [D loss: 0.457011, acc.: 84.38%] [G loss: 0.638290]\n",
      "epoch:1 step:1827 [D loss: 0.378196, acc.: 87.50%] [G loss: 0.786407]\n",
      "epoch:1 step:1828 [D loss: 0.501727, acc.: 73.44%] [G loss: 0.552007]\n",
      "epoch:1 step:1829 [D loss: 0.530831, acc.: 76.56%] [G loss: 0.426075]\n",
      "epoch:1 step:1830 [D loss: 0.478125, acc.: 79.69%] [G loss: 0.410269]\n",
      "epoch:1 step:1831 [D loss: 0.477344, acc.: 82.03%] [G loss: 0.453327]\n",
      "epoch:1 step:1832 [D loss: 0.473147, acc.: 82.03%] [G loss: 0.560458]\n",
      "epoch:1 step:1833 [D loss: 0.472000, acc.: 78.12%] [G loss: 0.578547]\n",
      "epoch:1 step:1834 [D loss: 0.436821, acc.: 84.38%] [G loss: 0.550787]\n",
      "epoch:1 step:1835 [D loss: 0.401005, acc.: 87.50%] [G loss: 0.628973]\n",
      "epoch:1 step:1836 [D loss: 0.509962, acc.: 81.25%] [G loss: 0.393001]\n",
      "epoch:1 step:1837 [D loss: 0.468506, acc.: 79.69%] [G loss: 0.557708]\n",
      "epoch:1 step:1838 [D loss: 0.451824, acc.: 81.25%] [G loss: 0.597618]\n",
      "epoch:1 step:1839 [D loss: 0.510525, acc.: 78.12%] [G loss: 0.392961]\n",
      "epoch:1 step:1840 [D loss: 0.513337, acc.: 74.22%] [G loss: 0.452120]\n",
      "epoch:1 step:1841 [D loss: 0.411882, acc.: 90.62%] [G loss: 0.596486]\n",
      "epoch:1 step:1842 [D loss: 0.469850, acc.: 80.47%] [G loss: 0.506719]\n",
      "epoch:1 step:1843 [D loss: 0.497673, acc.: 72.66%] [G loss: 0.595700]\n",
      "epoch:1 step:1844 [D loss: 0.469954, acc.: 76.56%] [G loss: 0.504573]\n",
      "epoch:1 step:1845 [D loss: 0.449883, acc.: 84.38%] [G loss: 0.501624]\n",
      "epoch:1 step:1846 [D loss: 0.414146, acc.: 86.72%] [G loss: 0.662979]\n",
      "epoch:1 step:1847 [D loss: 0.392014, acc.: 85.94%] [G loss: 0.714034]\n",
      "epoch:1 step:1848 [D loss: 0.426276, acc.: 84.38%] [G loss: 0.654659]\n",
      "epoch:1 step:1849 [D loss: 0.459269, acc.: 82.81%] [G loss: 0.478698]\n",
      "epoch:1 step:1850 [D loss: 0.475162, acc.: 76.56%] [G loss: 0.547188]\n",
      "epoch:1 step:1851 [D loss: 0.411633, acc.: 81.25%] [G loss: 0.675306]\n",
      "epoch:1 step:1852 [D loss: 0.548999, acc.: 74.22%] [G loss: 0.382986]\n",
      "epoch:1 step:1853 [D loss: 0.509455, acc.: 77.34%] [G loss: 0.372324]\n",
      "epoch:1 step:1854 [D loss: 0.492090, acc.: 79.69%] [G loss: 0.452466]\n",
      "epoch:1 step:1855 [D loss: 0.425828, acc.: 88.28%] [G loss: 0.568860]\n",
      "epoch:1 step:1856 [D loss: 0.460294, acc.: 81.25%] [G loss: 0.601726]\n",
      "epoch:1 step:1857 [D loss: 0.572430, acc.: 67.97%] [G loss: 0.559702]\n",
      "epoch:1 step:1858 [D loss: 0.379006, acc.: 88.28%] [G loss: 0.647983]\n",
      "epoch:1 step:1859 [D loss: 0.439028, acc.: 88.28%] [G loss: 0.575591]\n",
      "epoch:1 step:1860 [D loss: 0.395016, acc.: 85.16%] [G loss: 0.753006]\n",
      "epoch:1 step:1861 [D loss: 0.369324, acc.: 90.62%] [G loss: 0.895123]\n",
      "epoch:1 step:1862 [D loss: 0.361550, acc.: 89.84%] [G loss: 0.913735]\n",
      "epoch:1 step:1863 [D loss: 0.394753, acc.: 87.50%] [G loss: 0.890104]\n",
      "epoch:1 step:1864 [D loss: 0.469324, acc.: 82.03%] [G loss: 0.738134]\n",
      "epoch:1 step:1865 [D loss: 0.798746, acc.: 50.00%] [G loss: 0.490099]\n",
      "epoch:1 step:1866 [D loss: 0.337594, acc.: 89.84%] [G loss: 0.950561]\n",
      "epoch:1 step:1867 [D loss: 0.362707, acc.: 85.16%] [G loss: 1.033163]\n",
      "epoch:1 step:1868 [D loss: 0.531968, acc.: 72.66%] [G loss: 0.621344]\n",
      "epoch:1 step:1869 [D loss: 0.477727, acc.: 81.25%] [G loss: 0.506765]\n",
      "epoch:1 step:1870 [D loss: 0.430240, acc.: 83.59%] [G loss: 0.686116]\n",
      "epoch:1 step:1871 [D loss: 0.464088, acc.: 82.81%] [G loss: 0.697608]\n",
      "epoch:1 step:1872 [D loss: 0.391721, acc.: 86.72%] [G loss: 0.819223]\n",
      "epoch:1 step:1873 [D loss: 0.308598, acc.: 92.19%] [G loss: 1.237566]\n",
      "epoch:1 step:1874 [D loss: 0.500278, acc.: 76.56%] [G loss: 0.757757]\n",
      "epoch:2 step:1875 [D loss: 0.542840, acc.: 75.00%] [G loss: 0.740149]\n",
      "epoch:2 step:1876 [D loss: 0.393854, acc.: 85.16%] [G loss: 0.886251]\n",
      "epoch:2 step:1877 [D loss: 0.526909, acc.: 75.00%] [G loss: 0.573745]\n",
      "epoch:2 step:1878 [D loss: 0.431161, acc.: 84.38%] [G loss: 0.609922]\n",
      "epoch:2 step:1879 [D loss: 0.460249, acc.: 81.25%] [G loss: 0.565677]\n",
      "epoch:2 step:1880 [D loss: 0.488715, acc.: 78.12%] [G loss: 0.591540]\n",
      "epoch:2 step:1881 [D loss: 0.461050, acc.: 81.25%] [G loss: 0.604800]\n",
      "epoch:2 step:1882 [D loss: 0.451621, acc.: 83.59%] [G loss: 0.597826]\n",
      "epoch:2 step:1883 [D loss: 0.466949, acc.: 80.47%] [G loss: 0.597752]\n",
      "epoch:2 step:1884 [D loss: 0.459345, acc.: 85.16%] [G loss: 0.585351]\n",
      "epoch:2 step:1885 [D loss: 0.438440, acc.: 85.16%] [G loss: 0.662973]\n",
      "epoch:2 step:1886 [D loss: 0.491525, acc.: 78.12%] [G loss: 0.530682]\n",
      "epoch:2 step:1887 [D loss: 0.519477, acc.: 80.47%] [G loss: 0.499231]\n",
      "epoch:2 step:1888 [D loss: 0.486905, acc.: 76.56%] [G loss: 0.526590]\n",
      "epoch:2 step:1889 [D loss: 0.443452, acc.: 80.47%] [G loss: 0.564108]\n",
      "epoch:2 step:1890 [D loss: 0.435714, acc.: 82.81%] [G loss: 0.672040]\n",
      "epoch:2 step:1891 [D loss: 0.540472, acc.: 75.78%] [G loss: 0.504105]\n",
      "epoch:2 step:1892 [D loss: 0.506127, acc.: 81.25%] [G loss: 0.480152]\n",
      "epoch:2 step:1893 [D loss: 0.503892, acc.: 76.56%] [G loss: 0.446219]\n",
      "epoch:2 step:1894 [D loss: 0.627216, acc.: 60.94%] [G loss: 0.372069]\n",
      "epoch:2 step:1895 [D loss: 0.462035, acc.: 81.25%] [G loss: 0.439394]\n",
      "epoch:2 step:1896 [D loss: 0.422014, acc.: 83.59%] [G loss: 0.764796]\n",
      "epoch:2 step:1897 [D loss: 0.506210, acc.: 75.78%] [G loss: 0.614928]\n",
      "epoch:2 step:1898 [D loss: 0.460330, acc.: 82.81%] [G loss: 0.530140]\n",
      "epoch:2 step:1899 [D loss: 0.488162, acc.: 81.25%] [G loss: 0.488764]\n",
      "epoch:2 step:1900 [D loss: 0.452831, acc.: 84.38%] [G loss: 0.531777]\n",
      "epoch:2 step:1901 [D loss: 0.413201, acc.: 85.94%] [G loss: 0.579201]\n",
      "epoch:2 step:1902 [D loss: 0.503499, acc.: 76.56%] [G loss: 0.464050]\n",
      "epoch:2 step:1903 [D loss: 0.469356, acc.: 81.25%] [G loss: 0.540585]\n",
      "epoch:2 step:1904 [D loss: 0.504099, acc.: 80.47%] [G loss: 0.506369]\n",
      "epoch:2 step:1905 [D loss: 0.469732, acc.: 82.03%] [G loss: 0.545178]\n",
      "epoch:2 step:1906 [D loss: 0.435402, acc.: 87.50%] [G loss: 0.614076]\n",
      "epoch:2 step:1907 [D loss: 0.416253, acc.: 83.59%] [G loss: 0.656074]\n",
      "epoch:2 step:1908 [D loss: 0.449081, acc.: 78.91%] [G loss: 0.695909]\n",
      "epoch:2 step:1909 [D loss: 0.426262, acc.: 84.38%] [G loss: 0.819074]\n",
      "epoch:2 step:1910 [D loss: 0.402431, acc.: 84.38%] [G loss: 0.813569]\n",
      "epoch:2 step:1911 [D loss: 0.523938, acc.: 76.56%] [G loss: 0.606919]\n",
      "epoch:2 step:1912 [D loss: 0.545111, acc.: 72.66%] [G loss: 0.550769]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:1913 [D loss: 0.440820, acc.: 85.94%] [G loss: 0.492318]\n",
      "epoch:2 step:1914 [D loss: 0.451789, acc.: 81.25%] [G loss: 0.614200]\n",
      "epoch:2 step:1915 [D loss: 0.448782, acc.: 82.03%] [G loss: 0.656429]\n",
      "epoch:2 step:1916 [D loss: 0.457271, acc.: 82.03%] [G loss: 0.622777]\n",
      "epoch:2 step:1917 [D loss: 0.518062, acc.: 74.22%] [G loss: 0.525104]\n",
      "epoch:2 step:1918 [D loss: 0.549322, acc.: 68.75%] [G loss: 0.510507]\n",
      "epoch:2 step:1919 [D loss: 0.472958, acc.: 80.47%] [G loss: 0.495179]\n",
      "epoch:2 step:1920 [D loss: 0.474425, acc.: 82.03%] [G loss: 0.581374]\n",
      "epoch:2 step:1921 [D loss: 0.467717, acc.: 78.12%] [G loss: 0.606276]\n",
      "epoch:2 step:1922 [D loss: 0.491728, acc.: 75.78%] [G loss: 0.516737]\n",
      "epoch:2 step:1923 [D loss: 0.503447, acc.: 80.47%] [G loss: 0.521073]\n",
      "epoch:2 step:1924 [D loss: 0.477993, acc.: 82.03%] [G loss: 0.450094]\n",
      "epoch:2 step:1925 [D loss: 0.476654, acc.: 83.59%] [G loss: 0.449749]\n",
      "epoch:2 step:1926 [D loss: 0.537810, acc.: 75.78%] [G loss: 0.449878]\n",
      "epoch:2 step:1927 [D loss: 0.446607, acc.: 82.81%] [G loss: 0.508582]\n",
      "epoch:2 step:1928 [D loss: 0.448068, acc.: 83.59%] [G loss: 0.590093]\n",
      "epoch:2 step:1929 [D loss: 0.425198, acc.: 85.94%] [G loss: 0.691960]\n",
      "epoch:2 step:1930 [D loss: 0.506593, acc.: 74.22%] [G loss: 0.486492]\n",
      "epoch:2 step:1931 [D loss: 0.427819, acc.: 87.50%] [G loss: 0.543435]\n",
      "epoch:2 step:1932 [D loss: 0.462108, acc.: 83.59%] [G loss: 0.504017]\n",
      "epoch:2 step:1933 [D loss: 0.429987, acc.: 86.72%] [G loss: 0.631722]\n",
      "epoch:2 step:1934 [D loss: 0.464156, acc.: 77.34%] [G loss: 0.581204]\n",
      "epoch:2 step:1935 [D loss: 0.447928, acc.: 82.03%] [G loss: 0.567736]\n",
      "epoch:2 step:1936 [D loss: 0.538078, acc.: 72.66%] [G loss: 0.458908]\n",
      "epoch:2 step:1937 [D loss: 0.471630, acc.: 80.47%] [G loss: 0.438627]\n",
      "epoch:2 step:1938 [D loss: 0.453816, acc.: 82.03%] [G loss: 0.530661]\n",
      "epoch:2 step:1939 [D loss: 0.481899, acc.: 79.69%] [G loss: 0.631176]\n",
      "epoch:2 step:1940 [D loss: 0.467026, acc.: 79.69%] [G loss: 0.543632]\n",
      "epoch:2 step:1941 [D loss: 0.469918, acc.: 82.03%] [G loss: 0.503888]\n",
      "epoch:2 step:1942 [D loss: 0.480076, acc.: 82.81%] [G loss: 0.470220]\n",
      "epoch:2 step:1943 [D loss: 0.465809, acc.: 83.59%] [G loss: 0.527014]\n",
      "epoch:2 step:1944 [D loss: 0.476058, acc.: 79.69%] [G loss: 0.530658]\n",
      "epoch:2 step:1945 [D loss: 0.433209, acc.: 84.38%] [G loss: 0.535900]\n",
      "epoch:2 step:1946 [D loss: 0.411243, acc.: 82.03%] [G loss: 0.586824]\n",
      "epoch:2 step:1947 [D loss: 0.451451, acc.: 82.81%] [G loss: 0.604083]\n",
      "epoch:2 step:1948 [D loss: 0.478262, acc.: 78.91%] [G loss: 0.514690]\n",
      "epoch:2 step:1949 [D loss: 0.424712, acc.: 83.59%] [G loss: 0.693363]\n",
      "epoch:2 step:1950 [D loss: 0.474321, acc.: 75.00%] [G loss: 0.707308]\n",
      "epoch:2 step:1951 [D loss: 0.399407, acc.: 86.72%] [G loss: 0.813588]\n",
      "epoch:2 step:1952 [D loss: 0.496735, acc.: 74.22%] [G loss: 0.630450]\n",
      "epoch:2 step:1953 [D loss: 0.522004, acc.: 70.31%] [G loss: 0.526262]\n",
      "epoch:2 step:1954 [D loss: 0.504334, acc.: 77.34%] [G loss: 0.426847]\n",
      "epoch:2 step:1955 [D loss: 0.497799, acc.: 78.12%] [G loss: 0.465821]\n",
      "epoch:2 step:1956 [D loss: 0.421829, acc.: 87.50%] [G loss: 0.481548]\n",
      "epoch:2 step:1957 [D loss: 0.432932, acc.: 83.59%] [G loss: 0.506981]\n",
      "epoch:2 step:1958 [D loss: 0.461841, acc.: 79.69%] [G loss: 0.445303]\n",
      "epoch:2 step:1959 [D loss: 0.467835, acc.: 78.12%] [G loss: 0.530748]\n",
      "epoch:2 step:1960 [D loss: 0.406243, acc.: 85.94%] [G loss: 0.551941]\n",
      "epoch:2 step:1961 [D loss: 0.412899, acc.: 86.72%] [G loss: 0.584749]\n",
      "epoch:2 step:1962 [D loss: 0.453737, acc.: 82.81%] [G loss: 0.625619]\n",
      "epoch:2 step:1963 [D loss: 0.505320, acc.: 75.78%] [G loss: 0.590911]\n",
      "epoch:2 step:1964 [D loss: 0.472080, acc.: 82.03%] [G loss: 0.531522]\n",
      "epoch:2 step:1965 [D loss: 0.472572, acc.: 82.81%] [G loss: 0.489451]\n",
      "epoch:2 step:1966 [D loss: 0.522851, acc.: 74.22%] [G loss: 0.528411]\n",
      "epoch:2 step:1967 [D loss: 0.437834, acc.: 83.59%] [G loss: 0.588662]\n",
      "epoch:2 step:1968 [D loss: 0.460315, acc.: 78.12%] [G loss: 0.530689]\n",
      "epoch:2 step:1969 [D loss: 0.458068, acc.: 82.03%] [G loss: 0.501432]\n",
      "epoch:2 step:1970 [D loss: 0.433918, acc.: 84.38%] [G loss: 0.529696]\n",
      "epoch:2 step:1971 [D loss: 0.495954, acc.: 78.91%] [G loss: 0.510521]\n",
      "epoch:2 step:1972 [D loss: 0.453084, acc.: 80.47%] [G loss: 0.547278]\n",
      "epoch:2 step:1973 [D loss: 0.422232, acc.: 85.94%] [G loss: 0.672284]\n",
      "epoch:2 step:1974 [D loss: 0.433452, acc.: 82.81%] [G loss: 0.617437]\n",
      "epoch:2 step:1975 [D loss: 0.487817, acc.: 82.03%] [G loss: 0.515957]\n",
      "epoch:2 step:1976 [D loss: 0.537609, acc.: 73.44%] [G loss: 0.481100]\n",
      "epoch:2 step:1977 [D loss: 0.421918, acc.: 89.84%] [G loss: 0.556417]\n",
      "epoch:2 step:1978 [D loss: 0.440508, acc.: 82.03%] [G loss: 0.584564]\n",
      "epoch:2 step:1979 [D loss: 0.528040, acc.: 69.53%] [G loss: 0.476656]\n",
      "epoch:2 step:1980 [D loss: 0.550615, acc.: 75.78%] [G loss: 0.525385]\n",
      "epoch:2 step:1981 [D loss: 0.571368, acc.: 68.75%] [G loss: 0.397426]\n",
      "epoch:2 step:1982 [D loss: 0.510964, acc.: 70.31%] [G loss: 0.427014]\n",
      "epoch:2 step:1983 [D loss: 0.515214, acc.: 75.00%] [G loss: 0.535782]\n",
      "epoch:2 step:1984 [D loss: 0.489575, acc.: 79.69%] [G loss: 0.534164]\n",
      "epoch:2 step:1985 [D loss: 0.428343, acc.: 84.38%] [G loss: 0.486508]\n",
      "epoch:2 step:1986 [D loss: 0.495339, acc.: 79.69%] [G loss: 0.623598]\n",
      "epoch:2 step:1987 [D loss: 0.572214, acc.: 67.97%] [G loss: 0.471403]\n",
      "epoch:2 step:1988 [D loss: 0.522601, acc.: 73.44%] [G loss: 0.428185]\n",
      "epoch:2 step:1989 [D loss: 0.535484, acc.: 73.44%] [G loss: 0.537496]\n",
      "epoch:2 step:1990 [D loss: 0.513374, acc.: 75.78%] [G loss: 0.599812]\n",
      "epoch:2 step:1991 [D loss: 0.447153, acc.: 87.50%] [G loss: 0.644668]\n",
      "epoch:2 step:1992 [D loss: 0.447868, acc.: 87.50%] [G loss: 0.584333]\n",
      "epoch:2 step:1993 [D loss: 0.444245, acc.: 82.81%] [G loss: 0.772393]\n",
      "epoch:2 step:1994 [D loss: 0.579297, acc.: 71.09%] [G loss: 0.464025]\n",
      "epoch:2 step:1995 [D loss: 0.446983, acc.: 81.25%] [G loss: 0.478109]\n",
      "epoch:2 step:1996 [D loss: 0.447923, acc.: 82.81%] [G loss: 0.614946]\n",
      "epoch:2 step:1997 [D loss: 0.487471, acc.: 81.25%] [G loss: 0.584092]\n",
      "epoch:2 step:1998 [D loss: 0.563187, acc.: 73.44%] [G loss: 0.477167]\n",
      "epoch:2 step:1999 [D loss: 0.477605, acc.: 81.25%] [G loss: 0.421412]\n",
      "epoch:2 step:2000 [D loss: 0.491607, acc.: 78.12%] [G loss: 0.485723]\n",
      "##############\n",
      "[4.99811982 3.35398594 8.10314584 6.72230989 5.7452504  7.51966806\n",
      " 7.16129271 6.74794809 6.97146408 5.37922706]\n",
      "##########\n",
      "epoch:2 step:2001 [D loss: 0.455974, acc.: 79.69%] [G loss: 0.466745]\n",
      "epoch:2 step:2002 [D loss: 0.476248, acc.: 81.25%] [G loss: 0.508203]\n",
      "epoch:2 step:2003 [D loss: 0.486532, acc.: 78.91%] [G loss: 0.503545]\n",
      "epoch:2 step:2004 [D loss: 0.443067, acc.: 83.59%] [G loss: 0.510506]\n",
      "epoch:2 step:2005 [D loss: 0.392054, acc.: 90.62%] [G loss: 0.529513]\n",
      "epoch:2 step:2006 [D loss: 0.495586, acc.: 73.44%] [G loss: 0.592578]\n",
      "epoch:2 step:2007 [D loss: 0.534807, acc.: 73.44%] [G loss: 0.437954]\n",
      "epoch:2 step:2008 [D loss: 0.399880, acc.: 87.50%] [G loss: 0.553107]\n",
      "epoch:2 step:2009 [D loss: 0.443918, acc.: 85.94%] [G loss: 0.514441]\n",
      "epoch:2 step:2010 [D loss: 0.452491, acc.: 77.34%] [G loss: 0.559680]\n",
      "epoch:2 step:2011 [D loss: 0.472400, acc.: 81.25%] [G loss: 0.485273]\n",
      "epoch:2 step:2012 [D loss: 0.432314, acc.: 83.59%] [G loss: 0.606454]\n",
      "epoch:2 step:2013 [D loss: 0.488295, acc.: 75.00%] [G loss: 0.559553]\n",
      "epoch:2 step:2014 [D loss: 0.446702, acc.: 80.47%] [G loss: 0.536661]\n",
      "epoch:2 step:2015 [D loss: 0.456051, acc.: 82.81%] [G loss: 0.578136]\n",
      "epoch:2 step:2016 [D loss: 0.416733, acc.: 87.50%] [G loss: 0.726690]\n",
      "epoch:2 step:2017 [D loss: 0.478642, acc.: 81.25%] [G loss: 0.554980]\n",
      "epoch:2 step:2018 [D loss: 0.442128, acc.: 82.03%] [G loss: 0.683299]\n",
      "epoch:2 step:2019 [D loss: 0.484387, acc.: 75.00%] [G loss: 0.553489]\n",
      "epoch:2 step:2020 [D loss: 0.494995, acc.: 78.12%] [G loss: 0.531442]\n",
      "epoch:2 step:2021 [D loss: 0.486801, acc.: 76.56%] [G loss: 0.532945]\n",
      "epoch:2 step:2022 [D loss: 0.445494, acc.: 80.47%] [G loss: 0.530934]\n",
      "epoch:2 step:2023 [D loss: 0.445678, acc.: 84.38%] [G loss: 0.495466]\n",
      "epoch:2 step:2024 [D loss: 0.575152, acc.: 69.53%] [G loss: 0.589618]\n",
      "epoch:2 step:2025 [D loss: 0.460667, acc.: 82.81%] [G loss: 0.592909]\n",
      "epoch:2 step:2026 [D loss: 0.370637, acc.: 88.28%] [G loss: 0.852635]\n",
      "epoch:2 step:2027 [D loss: 0.468983, acc.: 81.25%] [G loss: 0.628935]\n",
      "epoch:2 step:2028 [D loss: 0.461575, acc.: 82.81%] [G loss: 0.518349]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2029 [D loss: 0.422238, acc.: 82.81%] [G loss: 0.623273]\n",
      "epoch:2 step:2030 [D loss: 0.494273, acc.: 78.12%] [G loss: 0.511948]\n",
      "epoch:2 step:2031 [D loss: 0.443119, acc.: 84.38%] [G loss: 0.560893]\n",
      "epoch:2 step:2032 [D loss: 0.519646, acc.: 72.66%] [G loss: 0.466549]\n",
      "epoch:2 step:2033 [D loss: 0.468682, acc.: 80.47%] [G loss: 0.456319]\n",
      "epoch:2 step:2034 [D loss: 0.482764, acc.: 80.47%] [G loss: 0.402864]\n",
      "epoch:2 step:2035 [D loss: 0.463900, acc.: 84.38%] [G loss: 0.512338]\n",
      "epoch:2 step:2036 [D loss: 0.380567, acc.: 86.72%] [G loss: 0.684130]\n",
      "epoch:2 step:2037 [D loss: 0.388102, acc.: 88.28%] [G loss: 0.640092]\n",
      "epoch:2 step:2038 [D loss: 0.440749, acc.: 82.81%] [G loss: 0.685276]\n",
      "epoch:2 step:2039 [D loss: 0.462478, acc.: 81.25%] [G loss: 0.550169]\n",
      "epoch:2 step:2040 [D loss: 0.477913, acc.: 79.69%] [G loss: 0.508605]\n",
      "epoch:2 step:2041 [D loss: 0.541190, acc.: 73.44%] [G loss: 0.461726]\n",
      "epoch:2 step:2042 [D loss: 0.445903, acc.: 80.47%] [G loss: 0.540294]\n",
      "epoch:2 step:2043 [D loss: 0.472301, acc.: 79.69%] [G loss: 0.545468]\n",
      "epoch:2 step:2044 [D loss: 0.439336, acc.: 81.25%] [G loss: 0.565120]\n",
      "epoch:2 step:2045 [D loss: 0.423278, acc.: 86.72%] [G loss: 0.562104]\n",
      "epoch:2 step:2046 [D loss: 0.471324, acc.: 82.03%] [G loss: 0.592377]\n",
      "epoch:2 step:2047 [D loss: 0.447640, acc.: 82.03%] [G loss: 0.554681]\n",
      "epoch:2 step:2048 [D loss: 0.437261, acc.: 82.03%] [G loss: 0.551247]\n",
      "epoch:2 step:2049 [D loss: 0.463576, acc.: 81.25%] [G loss: 0.653880]\n",
      "epoch:2 step:2050 [D loss: 0.410209, acc.: 86.72%] [G loss: 0.686550]\n",
      "epoch:2 step:2051 [D loss: 0.489300, acc.: 76.56%] [G loss: 0.613956]\n",
      "epoch:2 step:2052 [D loss: 0.439743, acc.: 83.59%] [G loss: 0.556648]\n",
      "epoch:2 step:2053 [D loss: 0.493084, acc.: 75.78%] [G loss: 0.582018]\n",
      "epoch:2 step:2054 [D loss: 0.530338, acc.: 76.56%] [G loss: 0.483626]\n",
      "epoch:2 step:2055 [D loss: 0.502630, acc.: 74.22%] [G loss: 0.454626]\n",
      "epoch:2 step:2056 [D loss: 0.470921, acc.: 82.81%] [G loss: 0.463358]\n",
      "epoch:2 step:2057 [D loss: 0.483931, acc.: 80.47%] [G loss: 0.511632]\n",
      "epoch:2 step:2058 [D loss: 0.514685, acc.: 78.91%] [G loss: 0.529710]\n",
      "epoch:2 step:2059 [D loss: 0.506982, acc.: 78.12%] [G loss: 0.521804]\n",
      "epoch:2 step:2060 [D loss: 0.507609, acc.: 76.56%] [G loss: 0.476065]\n",
      "epoch:2 step:2061 [D loss: 0.508077, acc.: 77.34%] [G loss: 0.496563]\n",
      "epoch:2 step:2062 [D loss: 0.444065, acc.: 82.03%] [G loss: 0.557881]\n",
      "epoch:2 step:2063 [D loss: 0.464862, acc.: 82.03%] [G loss: 0.527952]\n",
      "epoch:2 step:2064 [D loss: 0.398155, acc.: 86.72%] [G loss: 0.586717]\n",
      "epoch:2 step:2065 [D loss: 0.450760, acc.: 83.59%] [G loss: 0.600489]\n",
      "epoch:2 step:2066 [D loss: 0.491128, acc.: 78.91%] [G loss: 0.521300]\n",
      "epoch:2 step:2067 [D loss: 0.415171, acc.: 87.50%] [G loss: 0.621364]\n",
      "epoch:2 step:2068 [D loss: 0.432000, acc.: 84.38%] [G loss: 0.649206]\n",
      "epoch:2 step:2069 [D loss: 0.446219, acc.: 79.69%] [G loss: 0.751118]\n",
      "epoch:2 step:2070 [D loss: 0.544113, acc.: 70.31%] [G loss: 0.554053]\n",
      "epoch:2 step:2071 [D loss: 0.473873, acc.: 78.91%] [G loss: 0.538616]\n",
      "epoch:2 step:2072 [D loss: 0.481878, acc.: 77.34%] [G loss: 0.683016]\n",
      "epoch:2 step:2073 [D loss: 0.484622, acc.: 80.47%] [G loss: 0.541604]\n",
      "epoch:2 step:2074 [D loss: 0.496677, acc.: 74.22%] [G loss: 0.536643]\n",
      "epoch:2 step:2075 [D loss: 0.461032, acc.: 85.16%] [G loss: 0.567218]\n",
      "epoch:2 step:2076 [D loss: 0.451239, acc.: 82.81%] [G loss: 0.563876]\n",
      "epoch:2 step:2077 [D loss: 0.550558, acc.: 72.66%] [G loss: 0.564454]\n",
      "epoch:2 step:2078 [D loss: 0.459338, acc.: 81.25%] [G loss: 0.648064]\n",
      "epoch:2 step:2079 [D loss: 0.456917, acc.: 79.69%] [G loss: 0.863653]\n",
      "epoch:2 step:2080 [D loss: 0.453871, acc.: 82.03%] [G loss: 0.683331]\n",
      "epoch:2 step:2081 [D loss: 0.369492, acc.: 85.94%] [G loss: 0.880225]\n",
      "epoch:2 step:2082 [D loss: 0.414391, acc.: 80.47%] [G loss: 0.749777]\n",
      "epoch:2 step:2083 [D loss: 0.456842, acc.: 77.34%] [G loss: 0.668376]\n",
      "epoch:2 step:2084 [D loss: 0.493887, acc.: 82.03%] [G loss: 0.480475]\n",
      "epoch:2 step:2085 [D loss: 0.501908, acc.: 78.91%] [G loss: 0.579757]\n",
      "epoch:2 step:2086 [D loss: 0.463347, acc.: 82.03%] [G loss: 0.517572]\n",
      "epoch:2 step:2087 [D loss: 0.443302, acc.: 82.03%] [G loss: 0.762405]\n",
      "epoch:2 step:2088 [D loss: 0.579245, acc.: 75.00%] [G loss: 0.442575]\n",
      "epoch:2 step:2089 [D loss: 0.545097, acc.: 71.88%] [G loss: 0.356203]\n",
      "epoch:2 step:2090 [D loss: 0.534974, acc.: 73.44%] [G loss: 0.456360]\n",
      "epoch:2 step:2091 [D loss: 0.458013, acc.: 76.56%] [G loss: 0.616575]\n",
      "epoch:2 step:2092 [D loss: 0.463705, acc.: 76.56%] [G loss: 0.648483]\n",
      "epoch:2 step:2093 [D loss: 0.508104, acc.: 76.56%] [G loss: 0.569656]\n",
      "epoch:2 step:2094 [D loss: 0.569883, acc.: 72.66%] [G loss: 0.442564]\n",
      "epoch:2 step:2095 [D loss: 0.517036, acc.: 72.66%] [G loss: 0.560390]\n",
      "epoch:2 step:2096 [D loss: 0.476246, acc.: 75.00%] [G loss: 0.721097]\n",
      "epoch:2 step:2097 [D loss: 0.488871, acc.: 78.12%] [G loss: 0.678122]\n",
      "epoch:2 step:2098 [D loss: 0.546710, acc.: 73.44%] [G loss: 0.461397]\n",
      "epoch:2 step:2099 [D loss: 0.534772, acc.: 73.44%] [G loss: 0.367224]\n",
      "epoch:2 step:2100 [D loss: 0.465903, acc.: 82.81%] [G loss: 0.482512]\n",
      "epoch:2 step:2101 [D loss: 0.515811, acc.: 76.56%] [G loss: 0.397863]\n",
      "epoch:2 step:2102 [D loss: 0.515274, acc.: 71.09%] [G loss: 0.470927]\n",
      "epoch:2 step:2103 [D loss: 0.517934, acc.: 73.44%] [G loss: 0.487092]\n",
      "epoch:2 step:2104 [D loss: 0.466626, acc.: 82.03%] [G loss: 0.561810]\n",
      "epoch:2 step:2105 [D loss: 0.431159, acc.: 83.59%] [G loss: 0.850908]\n",
      "epoch:2 step:2106 [D loss: 0.408180, acc.: 83.59%] [G loss: 0.858102]\n",
      "epoch:2 step:2107 [D loss: 0.603614, acc.: 67.19%] [G loss: 0.551130]\n",
      "epoch:2 step:2108 [D loss: 0.465311, acc.: 83.59%] [G loss: 0.561800]\n",
      "epoch:2 step:2109 [D loss: 0.551344, acc.: 66.41%] [G loss: 0.513556]\n",
      "epoch:2 step:2110 [D loss: 0.472898, acc.: 79.69%] [G loss: 0.594902]\n",
      "epoch:2 step:2111 [D loss: 0.512397, acc.: 78.12%] [G loss: 0.505507]\n",
      "epoch:2 step:2112 [D loss: 0.486818, acc.: 77.34%] [G loss: 0.547960]\n",
      "epoch:2 step:2113 [D loss: 0.483808, acc.: 76.56%] [G loss: 0.592770]\n",
      "epoch:2 step:2114 [D loss: 0.489379, acc.: 76.56%] [G loss: 0.480369]\n",
      "epoch:2 step:2115 [D loss: 0.532999, acc.: 75.78%] [G loss: 0.498675]\n",
      "epoch:2 step:2116 [D loss: 0.503875, acc.: 76.56%] [G loss: 0.474484]\n",
      "epoch:2 step:2117 [D loss: 0.491974, acc.: 75.78%] [G loss: 0.532636]\n",
      "epoch:2 step:2118 [D loss: 0.445341, acc.: 82.81%] [G loss: 0.579034]\n",
      "epoch:2 step:2119 [D loss: 0.495431, acc.: 75.78%] [G loss: 0.448688]\n",
      "epoch:2 step:2120 [D loss: 0.453245, acc.: 84.38%] [G loss: 0.584444]\n",
      "epoch:2 step:2121 [D loss: 0.526826, acc.: 72.66%] [G loss: 0.453351]\n",
      "epoch:2 step:2122 [D loss: 0.474795, acc.: 78.12%] [G loss: 0.505055]\n",
      "epoch:2 step:2123 [D loss: 0.481891, acc.: 78.91%] [G loss: 0.558776]\n",
      "epoch:2 step:2124 [D loss: 0.622522, acc.: 67.19%] [G loss: 0.510757]\n",
      "epoch:2 step:2125 [D loss: 0.545754, acc.: 73.44%] [G loss: 0.500412]\n",
      "epoch:2 step:2126 [D loss: 0.526422, acc.: 79.69%] [G loss: 0.637487]\n",
      "epoch:2 step:2127 [D loss: 0.477673, acc.: 75.78%] [G loss: 0.577900]\n",
      "epoch:2 step:2128 [D loss: 0.448558, acc.: 81.25%] [G loss: 0.564161]\n",
      "epoch:2 step:2129 [D loss: 0.479150, acc.: 78.91%] [G loss: 0.605777]\n",
      "epoch:2 step:2130 [D loss: 0.468545, acc.: 75.00%] [G loss: 0.728023]\n",
      "epoch:2 step:2131 [D loss: 0.457395, acc.: 82.03%] [G loss: 0.604515]\n",
      "epoch:2 step:2132 [D loss: 0.450765, acc.: 84.38%] [G loss: 0.566276]\n",
      "epoch:2 step:2133 [D loss: 0.465780, acc.: 80.47%] [G loss: 0.611423]\n",
      "epoch:2 step:2134 [D loss: 0.465641, acc.: 78.12%] [G loss: 0.574756]\n",
      "epoch:2 step:2135 [D loss: 0.465472, acc.: 80.47%] [G loss: 0.525531]\n",
      "epoch:2 step:2136 [D loss: 0.495838, acc.: 77.34%] [G loss: 0.513820]\n",
      "epoch:2 step:2137 [D loss: 0.585837, acc.: 67.19%] [G loss: 0.452424]\n",
      "epoch:2 step:2138 [D loss: 0.486908, acc.: 80.47%] [G loss: 0.536819]\n",
      "epoch:2 step:2139 [D loss: 0.521220, acc.: 75.00%] [G loss: 0.447137]\n",
      "epoch:2 step:2140 [D loss: 0.474869, acc.: 80.47%] [G loss: 0.485989]\n",
      "epoch:2 step:2141 [D loss: 0.530251, acc.: 75.00%] [G loss: 0.419234]\n",
      "epoch:2 step:2142 [D loss: 0.513010, acc.: 73.44%] [G loss: 0.465241]\n",
      "epoch:2 step:2143 [D loss: 0.512311, acc.: 73.44%] [G loss: 0.455487]\n",
      "epoch:2 step:2144 [D loss: 0.485705, acc.: 78.91%] [G loss: 0.464631]\n",
      "epoch:2 step:2145 [D loss: 0.407929, acc.: 88.28%] [G loss: 0.536725]\n",
      "epoch:2 step:2146 [D loss: 0.496184, acc.: 80.47%] [G loss: 0.468283]\n",
      "epoch:2 step:2147 [D loss: 0.448298, acc.: 83.59%] [G loss: 0.664477]\n",
      "epoch:2 step:2148 [D loss: 0.529299, acc.: 71.88%] [G loss: 0.448417]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2149 [D loss: 0.527199, acc.: 76.56%] [G loss: 0.466256]\n",
      "epoch:2 step:2150 [D loss: 0.523241, acc.: 72.66%] [G loss: 0.419858]\n",
      "epoch:2 step:2151 [D loss: 0.584871, acc.: 67.19%] [G loss: 0.320666]\n",
      "epoch:2 step:2152 [D loss: 0.530716, acc.: 72.66%] [G loss: 0.449435]\n",
      "epoch:2 step:2153 [D loss: 0.496494, acc.: 77.34%] [G loss: 0.603741]\n",
      "epoch:2 step:2154 [D loss: 0.504946, acc.: 77.34%] [G loss: 0.634582]\n",
      "epoch:2 step:2155 [D loss: 0.483445, acc.: 79.69%] [G loss: 0.499842]\n",
      "epoch:2 step:2156 [D loss: 0.493748, acc.: 79.69%] [G loss: 0.466386]\n",
      "epoch:2 step:2157 [D loss: 0.464069, acc.: 81.25%] [G loss: 0.522398]\n",
      "epoch:2 step:2158 [D loss: 0.504036, acc.: 76.56%] [G loss: 0.525604]\n",
      "epoch:2 step:2159 [D loss: 0.445925, acc.: 84.38%] [G loss: 0.480663]\n",
      "epoch:2 step:2160 [D loss: 0.396062, acc.: 90.62%] [G loss: 0.631913]\n",
      "epoch:2 step:2161 [D loss: 0.499435, acc.: 74.22%] [G loss: 0.538177]\n",
      "epoch:2 step:2162 [D loss: 0.531225, acc.: 71.88%] [G loss: 0.508873]\n",
      "epoch:2 step:2163 [D loss: 0.490751, acc.: 80.47%] [G loss: 0.507378]\n",
      "epoch:2 step:2164 [D loss: 0.427624, acc.: 83.59%] [G loss: 0.624121]\n",
      "epoch:2 step:2165 [D loss: 0.534821, acc.: 70.31%] [G loss: 0.467015]\n",
      "epoch:2 step:2166 [D loss: 0.524112, acc.: 76.56%] [G loss: 0.422027]\n",
      "epoch:2 step:2167 [D loss: 0.495419, acc.: 78.91%] [G loss: 0.537740]\n",
      "epoch:2 step:2168 [D loss: 0.481665, acc.: 79.69%] [G loss: 0.500083]\n",
      "epoch:2 step:2169 [D loss: 0.505886, acc.: 78.12%] [G loss: 0.524722]\n",
      "epoch:2 step:2170 [D loss: 0.409779, acc.: 86.72%] [G loss: 0.669798]\n",
      "epoch:2 step:2171 [D loss: 0.485599, acc.: 76.56%] [G loss: 0.554253]\n",
      "epoch:2 step:2172 [D loss: 0.486067, acc.: 82.03%] [G loss: 0.498259]\n",
      "epoch:2 step:2173 [D loss: 0.425098, acc.: 87.50%] [G loss: 0.486843]\n",
      "epoch:2 step:2174 [D loss: 0.475768, acc.: 74.22%] [G loss: 0.496861]\n",
      "epoch:2 step:2175 [D loss: 0.528467, acc.: 75.78%] [G loss: 0.478024]\n",
      "epoch:2 step:2176 [D loss: 0.452044, acc.: 82.03%] [G loss: 0.448353]\n",
      "epoch:2 step:2177 [D loss: 0.450820, acc.: 82.03%] [G loss: 0.559590]\n",
      "epoch:2 step:2178 [D loss: 0.411768, acc.: 84.38%] [G loss: 0.603742]\n",
      "epoch:2 step:2179 [D loss: 0.439862, acc.: 84.38%] [G loss: 0.532511]\n",
      "epoch:2 step:2180 [D loss: 0.489451, acc.: 76.56%] [G loss: 0.605687]\n",
      "epoch:2 step:2181 [D loss: 0.435049, acc.: 82.81%] [G loss: 0.609599]\n",
      "epoch:2 step:2182 [D loss: 0.434662, acc.: 84.38%] [G loss: 0.545953]\n",
      "epoch:2 step:2183 [D loss: 0.396806, acc.: 84.38%] [G loss: 0.667513]\n",
      "epoch:2 step:2184 [D loss: 0.418648, acc.: 82.81%] [G loss: 0.834401]\n",
      "epoch:2 step:2185 [D loss: 0.451598, acc.: 75.78%] [G loss: 0.757040]\n",
      "epoch:2 step:2186 [D loss: 0.405884, acc.: 80.47%] [G loss: 0.910699]\n",
      "epoch:2 step:2187 [D loss: 0.402897, acc.: 83.59%] [G loss: 1.011212]\n",
      "epoch:2 step:2188 [D loss: 0.429471, acc.: 82.03%] [G loss: 0.946898]\n",
      "epoch:2 step:2189 [D loss: 0.409813, acc.: 83.59%] [G loss: 0.935406]\n",
      "epoch:2 step:2190 [D loss: 0.618678, acc.: 69.53%] [G loss: 0.545506]\n",
      "epoch:2 step:2191 [D loss: 0.572898, acc.: 71.88%] [G loss: 0.461395]\n",
      "epoch:2 step:2192 [D loss: 0.475150, acc.: 78.91%] [G loss: 0.661463]\n",
      "epoch:2 step:2193 [D loss: 0.467897, acc.: 80.47%] [G loss: 0.603916]\n",
      "epoch:2 step:2194 [D loss: 0.492920, acc.: 74.22%] [G loss: 0.556680]\n",
      "epoch:2 step:2195 [D loss: 0.465614, acc.: 78.91%] [G loss: 0.596339]\n",
      "epoch:2 step:2196 [D loss: 0.478326, acc.: 79.69%] [G loss: 0.593773]\n",
      "epoch:2 step:2197 [D loss: 0.449085, acc.: 82.03%] [G loss: 0.611331]\n",
      "epoch:2 step:2198 [D loss: 0.477705, acc.: 81.25%] [G loss: 0.565988]\n",
      "epoch:2 step:2199 [D loss: 0.467806, acc.: 80.47%] [G loss: 0.500623]\n",
      "epoch:2 step:2200 [D loss: 0.447815, acc.: 82.03%] [G loss: 0.586613]\n",
      "##############\n",
      "[4.43550428 2.81185449 8.14120577 6.60036626 5.65103444 6.86931207\n",
      " 6.40772712 6.45469265 6.76393085 4.95486614]\n",
      "##########\n",
      "epoch:2 step:2201 [D loss: 0.490366, acc.: 78.91%] [G loss: 0.575729]\n",
      "epoch:2 step:2202 [D loss: 0.540347, acc.: 66.41%] [G loss: 0.428637]\n",
      "epoch:2 step:2203 [D loss: 0.453192, acc.: 83.59%] [G loss: 0.534504]\n",
      "epoch:2 step:2204 [D loss: 0.456288, acc.: 84.38%] [G loss: 0.589364]\n",
      "epoch:2 step:2205 [D loss: 0.484952, acc.: 79.69%] [G loss: 0.569486]\n",
      "epoch:2 step:2206 [D loss: 0.494627, acc.: 76.56%] [G loss: 0.533222]\n",
      "epoch:2 step:2207 [D loss: 0.433455, acc.: 85.16%] [G loss: 0.578445]\n",
      "epoch:2 step:2208 [D loss: 0.491777, acc.: 76.56%] [G loss: 0.479923]\n",
      "epoch:2 step:2209 [D loss: 0.443449, acc.: 80.47%] [G loss: 0.619379]\n",
      "epoch:2 step:2210 [D loss: 0.479850, acc.: 78.91%] [G loss: 0.650874]\n",
      "epoch:2 step:2211 [D loss: 0.458746, acc.: 79.69%] [G loss: 0.643803]\n",
      "epoch:2 step:2212 [D loss: 0.504743, acc.: 77.34%] [G loss: 0.561544]\n",
      "epoch:2 step:2213 [D loss: 0.446696, acc.: 82.03%] [G loss: 0.604618]\n",
      "epoch:2 step:2214 [D loss: 0.469992, acc.: 79.69%] [G loss: 0.581199]\n",
      "epoch:2 step:2215 [D loss: 0.558814, acc.: 73.44%] [G loss: 0.474145]\n",
      "epoch:2 step:2216 [D loss: 0.509357, acc.: 73.44%] [G loss: 0.533635]\n",
      "epoch:2 step:2217 [D loss: 0.461182, acc.: 76.56%] [G loss: 0.718433]\n",
      "epoch:2 step:2218 [D loss: 0.365041, acc.: 86.72%] [G loss: 0.854857]\n",
      "epoch:2 step:2219 [D loss: 0.470507, acc.: 76.56%] [G loss: 0.857711]\n",
      "epoch:2 step:2220 [D loss: 0.453851, acc.: 78.12%] [G loss: 0.884077]\n",
      "epoch:2 step:2221 [D loss: 0.443105, acc.: 76.56%] [G loss: 0.873161]\n",
      "epoch:2 step:2222 [D loss: 0.584246, acc.: 70.31%] [G loss: 0.618466]\n",
      "epoch:2 step:2223 [D loss: 0.586872, acc.: 66.41%] [G loss: 0.558016]\n",
      "epoch:2 step:2224 [D loss: 0.481021, acc.: 76.56%] [G loss: 0.584116]\n",
      "epoch:2 step:2225 [D loss: 0.481210, acc.: 80.47%] [G loss: 0.648041]\n",
      "epoch:2 step:2226 [D loss: 0.521172, acc.: 75.78%] [G loss: 0.531658]\n",
      "epoch:2 step:2227 [D loss: 0.524866, acc.: 78.91%] [G loss: 0.485931]\n",
      "epoch:2 step:2228 [D loss: 0.405277, acc.: 84.38%] [G loss: 0.649592]\n",
      "epoch:2 step:2229 [D loss: 0.523305, acc.: 72.66%] [G loss: 0.521586]\n",
      "epoch:2 step:2230 [D loss: 0.479653, acc.: 77.34%] [G loss: 0.460216]\n",
      "epoch:2 step:2231 [D loss: 0.440854, acc.: 82.81%] [G loss: 0.526811]\n",
      "epoch:2 step:2232 [D loss: 0.395949, acc.: 85.16%] [G loss: 0.627380]\n",
      "epoch:2 step:2233 [D loss: 0.423598, acc.: 81.25%] [G loss: 0.657080]\n",
      "epoch:2 step:2234 [D loss: 0.449578, acc.: 83.59%] [G loss: 0.599396]\n",
      "epoch:2 step:2235 [D loss: 0.469111, acc.: 82.03%] [G loss: 0.592022]\n",
      "epoch:2 step:2236 [D loss: 0.507179, acc.: 75.78%] [G loss: 0.495504]\n",
      "epoch:2 step:2237 [D loss: 0.457124, acc.: 81.25%] [G loss: 0.578971]\n",
      "epoch:2 step:2238 [D loss: 0.491346, acc.: 77.34%] [G loss: 0.565538]\n",
      "epoch:2 step:2239 [D loss: 0.461380, acc.: 79.69%] [G loss: 0.633530]\n",
      "epoch:2 step:2240 [D loss: 0.446942, acc.: 83.59%] [G loss: 0.666232]\n",
      "epoch:2 step:2241 [D loss: 0.551362, acc.: 69.53%] [G loss: 0.561523]\n",
      "epoch:2 step:2242 [D loss: 0.468618, acc.: 82.81%] [G loss: 0.617245]\n",
      "epoch:2 step:2243 [D loss: 0.456981, acc.: 85.94%] [G loss: 0.542986]\n",
      "epoch:2 step:2244 [D loss: 0.513575, acc.: 76.56%] [G loss: 0.518734]\n",
      "epoch:2 step:2245 [D loss: 0.517414, acc.: 78.91%] [G loss: 0.556710]\n",
      "epoch:2 step:2246 [D loss: 0.429731, acc.: 82.81%] [G loss: 0.633240]\n",
      "epoch:2 step:2247 [D loss: 0.471669, acc.: 80.47%] [G loss: 0.622070]\n",
      "epoch:2 step:2248 [D loss: 0.454311, acc.: 82.03%] [G loss: 0.571989]\n",
      "epoch:2 step:2249 [D loss: 0.499015, acc.: 79.69%] [G loss: 0.497932]\n",
      "epoch:2 step:2250 [D loss: 0.527574, acc.: 74.22%] [G loss: 0.387804]\n",
      "epoch:2 step:2251 [D loss: 0.526447, acc.: 73.44%] [G loss: 0.571087]\n",
      "epoch:2 step:2252 [D loss: 0.488279, acc.: 79.69%] [G loss: 0.588070]\n",
      "epoch:2 step:2253 [D loss: 0.463478, acc.: 78.91%] [G loss: 0.638380]\n",
      "epoch:2 step:2254 [D loss: 0.512998, acc.: 78.12%] [G loss: 0.540835]\n",
      "epoch:2 step:2255 [D loss: 0.425562, acc.: 83.59%] [G loss: 0.456742]\n",
      "epoch:2 step:2256 [D loss: 0.439717, acc.: 78.91%] [G loss: 0.595961]\n",
      "epoch:2 step:2257 [D loss: 0.483164, acc.: 76.56%] [G loss: 0.602691]\n",
      "epoch:2 step:2258 [D loss: 0.484834, acc.: 75.78%] [G loss: 0.575719]\n",
      "epoch:2 step:2259 [D loss: 0.514675, acc.: 76.56%] [G loss: 0.605364]\n",
      "epoch:2 step:2260 [D loss: 0.564671, acc.: 67.19%] [G loss: 0.520648]\n",
      "epoch:2 step:2261 [D loss: 0.490099, acc.: 74.22%] [G loss: 0.579961]\n",
      "epoch:2 step:2262 [D loss: 0.477814, acc.: 76.56%] [G loss: 0.691092]\n",
      "epoch:2 step:2263 [D loss: 0.468391, acc.: 77.34%] [G loss: 0.531242]\n",
      "epoch:2 step:2264 [D loss: 0.503727, acc.: 74.22%] [G loss: 0.401167]\n",
      "epoch:2 step:2265 [D loss: 0.497885, acc.: 71.09%] [G loss: 0.597829]\n",
      "epoch:2 step:2266 [D loss: 0.391201, acc.: 87.50%] [G loss: 0.736629]\n",
      "epoch:2 step:2267 [D loss: 0.506340, acc.: 77.34%] [G loss: 0.689340]\n",
      "epoch:2 step:2268 [D loss: 0.480319, acc.: 78.91%] [G loss: 0.557324]\n",
      "epoch:2 step:2269 [D loss: 0.453620, acc.: 84.38%] [G loss: 0.649052]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2270 [D loss: 0.538638, acc.: 73.44%] [G loss: 0.548136]\n",
      "epoch:2 step:2271 [D loss: 0.449444, acc.: 83.59%] [G loss: 0.557761]\n",
      "epoch:2 step:2272 [D loss: 0.398307, acc.: 81.25%] [G loss: 0.781637]\n",
      "epoch:2 step:2273 [D loss: 0.467283, acc.: 80.47%] [G loss: 0.658866]\n",
      "epoch:2 step:2274 [D loss: 0.554249, acc.: 72.66%] [G loss: 0.662402]\n",
      "epoch:2 step:2275 [D loss: 0.505297, acc.: 75.78%] [G loss: 0.463049]\n",
      "epoch:2 step:2276 [D loss: 0.410918, acc.: 81.25%] [G loss: 0.614650]\n",
      "epoch:2 step:2277 [D loss: 0.462656, acc.: 81.25%] [G loss: 0.625431]\n",
      "epoch:2 step:2278 [D loss: 0.555834, acc.: 75.00%] [G loss: 0.574395]\n",
      "epoch:2 step:2279 [D loss: 0.519169, acc.: 76.56%] [G loss: 0.476360]\n",
      "epoch:2 step:2280 [D loss: 0.481769, acc.: 75.78%] [G loss: 0.554439]\n",
      "epoch:2 step:2281 [D loss: 0.464023, acc.: 78.91%] [G loss: 0.637069]\n",
      "epoch:2 step:2282 [D loss: 0.497598, acc.: 74.22%] [G loss: 0.498801]\n",
      "epoch:2 step:2283 [D loss: 0.458113, acc.: 83.59%] [G loss: 0.514031]\n",
      "epoch:2 step:2284 [D loss: 0.493551, acc.: 75.00%] [G loss: 0.567956]\n",
      "epoch:2 step:2285 [D loss: 0.516900, acc.: 71.88%] [G loss: 0.529638]\n",
      "epoch:2 step:2286 [D loss: 0.516415, acc.: 74.22%] [G loss: 0.476906]\n",
      "epoch:2 step:2287 [D loss: 0.492480, acc.: 73.44%] [G loss: 0.472558]\n",
      "epoch:2 step:2288 [D loss: 0.471922, acc.: 78.12%] [G loss: 0.534894]\n",
      "epoch:2 step:2289 [D loss: 0.483534, acc.: 76.56%] [G loss: 0.561632]\n",
      "epoch:2 step:2290 [D loss: 0.481270, acc.: 78.91%] [G loss: 0.579373]\n",
      "epoch:2 step:2291 [D loss: 0.500299, acc.: 76.56%] [G loss: 0.503080]\n",
      "epoch:2 step:2292 [D loss: 0.466815, acc.: 84.38%] [G loss: 0.468999]\n",
      "epoch:2 step:2293 [D loss: 0.489192, acc.: 75.78%] [G loss: 0.568179]\n",
      "epoch:2 step:2294 [D loss: 0.461375, acc.: 79.69%] [G loss: 0.594401]\n",
      "epoch:2 step:2295 [D loss: 0.544175, acc.: 70.31%] [G loss: 0.539372]\n",
      "epoch:2 step:2296 [D loss: 0.494492, acc.: 72.66%] [G loss: 0.560930]\n",
      "epoch:2 step:2297 [D loss: 0.522988, acc.: 75.00%] [G loss: 0.499422]\n",
      "epoch:2 step:2298 [D loss: 0.536760, acc.: 73.44%] [G loss: 0.495440]\n",
      "epoch:2 step:2299 [D loss: 0.491057, acc.: 79.69%] [G loss: 0.558864]\n",
      "epoch:2 step:2300 [D loss: 0.481283, acc.: 82.81%] [G loss: 0.600303]\n",
      "epoch:2 step:2301 [D loss: 0.441929, acc.: 79.69%] [G loss: 0.647115]\n",
      "epoch:2 step:2302 [D loss: 0.448996, acc.: 80.47%] [G loss: 0.642426]\n",
      "epoch:2 step:2303 [D loss: 0.465447, acc.: 77.34%] [G loss: 0.765297]\n",
      "epoch:2 step:2304 [D loss: 0.448298, acc.: 78.12%] [G loss: 0.667121]\n",
      "epoch:2 step:2305 [D loss: 0.412286, acc.: 88.28%] [G loss: 0.686181]\n",
      "epoch:2 step:2306 [D loss: 0.507341, acc.: 75.00%] [G loss: 0.640489]\n",
      "epoch:2 step:2307 [D loss: 0.523721, acc.: 73.44%] [G loss: 0.388822]\n",
      "epoch:2 step:2308 [D loss: 0.479846, acc.: 79.69%] [G loss: 0.565933]\n",
      "epoch:2 step:2309 [D loss: 0.487820, acc.: 82.03%] [G loss: 0.627433]\n",
      "epoch:2 step:2310 [D loss: 0.502026, acc.: 80.47%] [G loss: 0.592814]\n",
      "epoch:2 step:2311 [D loss: 0.560407, acc.: 74.22%] [G loss: 0.476731]\n",
      "epoch:2 step:2312 [D loss: 0.495656, acc.: 76.56%] [G loss: 0.555103]\n",
      "epoch:2 step:2313 [D loss: 0.452787, acc.: 81.25%] [G loss: 0.527167]\n",
      "epoch:2 step:2314 [D loss: 0.468513, acc.: 76.56%] [G loss: 0.574719]\n",
      "epoch:2 step:2315 [D loss: 0.483314, acc.: 80.47%] [G loss: 0.462795]\n",
      "epoch:2 step:2316 [D loss: 0.532858, acc.: 69.53%] [G loss: 0.429051]\n",
      "epoch:2 step:2317 [D loss: 0.527620, acc.: 74.22%] [G loss: 0.499739]\n",
      "epoch:2 step:2318 [D loss: 0.525550, acc.: 71.88%] [G loss: 0.561167]\n",
      "epoch:2 step:2319 [D loss: 0.519983, acc.: 73.44%] [G loss: 0.475908]\n",
      "epoch:2 step:2320 [D loss: 0.483631, acc.: 78.91%] [G loss: 0.641886]\n",
      "epoch:2 step:2321 [D loss: 0.430657, acc.: 79.69%] [G loss: 0.773586]\n",
      "epoch:2 step:2322 [D loss: 0.497869, acc.: 79.69%] [G loss: 0.628784]\n",
      "epoch:2 step:2323 [D loss: 0.522418, acc.: 77.34%] [G loss: 0.541484]\n",
      "epoch:2 step:2324 [D loss: 0.429942, acc.: 83.59%] [G loss: 0.683025]\n",
      "epoch:2 step:2325 [D loss: 0.430293, acc.: 85.94%] [G loss: 0.639939]\n",
      "epoch:2 step:2326 [D loss: 0.506092, acc.: 75.00%] [G loss: 0.613874]\n",
      "epoch:2 step:2327 [D loss: 0.518214, acc.: 72.66%] [G loss: 0.550619]\n",
      "epoch:2 step:2328 [D loss: 0.523259, acc.: 75.78%] [G loss: 0.565308]\n",
      "epoch:2 step:2329 [D loss: 0.606577, acc.: 67.97%] [G loss: 0.427293]\n",
      "epoch:2 step:2330 [D loss: 0.570441, acc.: 68.75%] [G loss: 0.501728]\n",
      "epoch:2 step:2331 [D loss: 0.468469, acc.: 81.25%] [G loss: 0.503120]\n",
      "epoch:2 step:2332 [D loss: 0.603666, acc.: 63.28%] [G loss: 0.416706]\n",
      "epoch:2 step:2333 [D loss: 0.510552, acc.: 75.78%] [G loss: 0.437737]\n",
      "epoch:2 step:2334 [D loss: 0.470912, acc.: 78.12%] [G loss: 0.486741]\n",
      "epoch:2 step:2335 [D loss: 0.473151, acc.: 80.47%] [G loss: 0.502255]\n",
      "epoch:2 step:2336 [D loss: 0.499150, acc.: 76.56%] [G loss: 0.474558]\n",
      "epoch:2 step:2337 [D loss: 0.537424, acc.: 70.31%] [G loss: 0.365359]\n",
      "epoch:2 step:2338 [D loss: 0.501427, acc.: 75.78%] [G loss: 0.421206]\n",
      "epoch:2 step:2339 [D loss: 0.570864, acc.: 67.97%] [G loss: 0.413044]\n",
      "epoch:2 step:2340 [D loss: 0.486616, acc.: 75.78%] [G loss: 0.561397]\n",
      "epoch:2 step:2341 [D loss: 0.550383, acc.: 69.53%] [G loss: 0.660741]\n",
      "epoch:2 step:2342 [D loss: 0.480827, acc.: 79.69%] [G loss: 0.607636]\n",
      "epoch:2 step:2343 [D loss: 0.512789, acc.: 81.25%] [G loss: 0.502600]\n",
      "epoch:2 step:2344 [D loss: 0.472166, acc.: 82.81%] [G loss: 0.476855]\n",
      "epoch:2 step:2345 [D loss: 0.458954, acc.: 83.59%] [G loss: 0.472955]\n",
      "epoch:2 step:2346 [D loss: 0.424139, acc.: 84.38%] [G loss: 0.627988]\n",
      "epoch:2 step:2347 [D loss: 0.567966, acc.: 71.09%] [G loss: 0.592501]\n",
      "epoch:2 step:2348 [D loss: 0.477675, acc.: 77.34%] [G loss: 0.567285]\n",
      "epoch:2 step:2349 [D loss: 0.399046, acc.: 87.50%] [G loss: 0.782207]\n",
      "epoch:2 step:2350 [D loss: 0.563434, acc.: 73.44%] [G loss: 0.543543]\n",
      "epoch:2 step:2351 [D loss: 0.691916, acc.: 54.69%] [G loss: 0.346631]\n",
      "epoch:2 step:2352 [D loss: 0.505334, acc.: 78.12%] [G loss: 0.424306]\n",
      "epoch:2 step:2353 [D loss: 0.517866, acc.: 76.56%] [G loss: 0.533268]\n",
      "epoch:2 step:2354 [D loss: 0.552118, acc.: 75.78%] [G loss: 0.491997]\n",
      "epoch:2 step:2355 [D loss: 0.507629, acc.: 79.69%] [G loss: 0.524981]\n",
      "epoch:2 step:2356 [D loss: 0.549841, acc.: 73.44%] [G loss: 0.416883]\n",
      "epoch:2 step:2357 [D loss: 0.549524, acc.: 74.22%] [G loss: 0.420549]\n",
      "epoch:2 step:2358 [D loss: 0.463266, acc.: 83.59%] [G loss: 0.490085]\n",
      "epoch:2 step:2359 [D loss: 0.507172, acc.: 78.91%] [G loss: 0.515631]\n",
      "epoch:2 step:2360 [D loss: 0.498619, acc.: 76.56%] [G loss: 0.554835]\n",
      "epoch:2 step:2361 [D loss: 0.455910, acc.: 84.38%] [G loss: 0.633380]\n",
      "epoch:2 step:2362 [D loss: 0.460416, acc.: 78.12%] [G loss: 0.614847]\n",
      "epoch:2 step:2363 [D loss: 0.572137, acc.: 73.44%] [G loss: 0.432329]\n",
      "epoch:2 step:2364 [D loss: 0.502083, acc.: 74.22%] [G loss: 0.471492]\n",
      "epoch:2 step:2365 [D loss: 0.448625, acc.: 80.47%] [G loss: 0.600113]\n",
      "epoch:2 step:2366 [D loss: 0.505357, acc.: 76.56%] [G loss: 0.477731]\n",
      "epoch:2 step:2367 [D loss: 0.539102, acc.: 72.66%] [G loss: 0.385453]\n",
      "epoch:2 step:2368 [D loss: 0.470851, acc.: 78.12%] [G loss: 0.575067]\n",
      "epoch:2 step:2369 [D loss: 0.483128, acc.: 78.12%] [G loss: 0.560718]\n",
      "epoch:2 step:2370 [D loss: 0.508007, acc.: 75.78%] [G loss: 0.611766]\n",
      "epoch:2 step:2371 [D loss: 0.395902, acc.: 89.06%] [G loss: 0.669865]\n",
      "epoch:2 step:2372 [D loss: 0.408683, acc.: 84.38%] [G loss: 0.803162]\n",
      "epoch:2 step:2373 [D loss: 0.435798, acc.: 81.25%] [G loss: 0.934787]\n",
      "epoch:2 step:2374 [D loss: 0.579139, acc.: 68.75%] [G loss: 0.602801]\n",
      "epoch:2 step:2375 [D loss: 0.559000, acc.: 72.66%] [G loss: 0.381238]\n",
      "epoch:2 step:2376 [D loss: 0.511411, acc.: 77.34%] [G loss: 0.383134]\n",
      "epoch:2 step:2377 [D loss: 0.433625, acc.: 82.03%] [G loss: 0.537860]\n",
      "epoch:2 step:2378 [D loss: 0.485872, acc.: 75.78%] [G loss: 0.550948]\n",
      "epoch:2 step:2379 [D loss: 0.484532, acc.: 75.00%] [G loss: 0.551321]\n",
      "epoch:2 step:2380 [D loss: 0.462457, acc.: 79.69%] [G loss: 0.629837]\n",
      "epoch:2 step:2381 [D loss: 0.472693, acc.: 79.69%] [G loss: 0.671166]\n",
      "epoch:2 step:2382 [D loss: 0.433812, acc.: 82.81%] [G loss: 0.574414]\n",
      "epoch:2 step:2383 [D loss: 0.487890, acc.: 77.34%] [G loss: 0.618805]\n",
      "epoch:2 step:2384 [D loss: 0.509641, acc.: 77.34%] [G loss: 0.609583]\n",
      "epoch:2 step:2385 [D loss: 0.490245, acc.: 76.56%] [G loss: 0.620777]\n",
      "epoch:2 step:2386 [D loss: 0.489290, acc.: 79.69%] [G loss: 0.476095]\n",
      "epoch:2 step:2387 [D loss: 0.443629, acc.: 84.38%] [G loss: 0.490196]\n",
      "epoch:2 step:2388 [D loss: 0.441223, acc.: 84.38%] [G loss: 0.576050]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2389 [D loss: 0.412122, acc.: 85.94%] [G loss: 0.689929]\n",
      "epoch:2 step:2390 [D loss: 0.458828, acc.: 81.25%] [G loss: 0.688159]\n",
      "epoch:2 step:2391 [D loss: 0.475020, acc.: 84.38%] [G loss: 0.574297]\n",
      "epoch:2 step:2392 [D loss: 0.422986, acc.: 81.25%] [G loss: 0.576991]\n",
      "epoch:2 step:2393 [D loss: 0.511978, acc.: 77.34%] [G loss: 0.587233]\n",
      "epoch:2 step:2394 [D loss: 0.447561, acc.: 80.47%] [G loss: 0.627711]\n",
      "epoch:2 step:2395 [D loss: 0.455101, acc.: 84.38%] [G loss: 0.584900]\n",
      "epoch:2 step:2396 [D loss: 0.482622, acc.: 79.69%] [G loss: 0.568404]\n",
      "epoch:2 step:2397 [D loss: 0.465063, acc.: 79.69%] [G loss: 0.585358]\n",
      "epoch:2 step:2398 [D loss: 0.462580, acc.: 77.34%] [G loss: 0.550768]\n",
      "epoch:2 step:2399 [D loss: 0.550683, acc.: 69.53%] [G loss: 0.484827]\n",
      "epoch:2 step:2400 [D loss: 0.444274, acc.: 82.03%] [G loss: 0.661782]\n",
      "##############\n",
      "[3.99375714 2.49536637 7.89102454 5.9737136  5.10662263 7.03612057\n",
      " 6.11163676 6.20230101 6.35330762 4.67611814]\n",
      "##########\n",
      "epoch:2 step:2401 [D loss: 0.606328, acc.: 67.19%] [G loss: 0.575061]\n",
      "epoch:2 step:2402 [D loss: 0.539008, acc.: 70.31%] [G loss: 0.483165]\n",
      "epoch:2 step:2403 [D loss: 0.449974, acc.: 81.25%] [G loss: 0.602846]\n",
      "epoch:2 step:2404 [D loss: 0.442205, acc.: 82.81%] [G loss: 0.604961]\n",
      "epoch:2 step:2405 [D loss: 0.541291, acc.: 71.88%] [G loss: 0.451751]\n",
      "epoch:2 step:2406 [D loss: 0.490828, acc.: 82.03%] [G loss: 0.439661]\n",
      "epoch:2 step:2407 [D loss: 0.498482, acc.: 77.34%] [G loss: 0.514191]\n",
      "epoch:2 step:2408 [D loss: 0.454640, acc.: 82.03%] [G loss: 0.486630]\n",
      "epoch:2 step:2409 [D loss: 0.532003, acc.: 74.22%] [G loss: 0.488205]\n",
      "epoch:2 step:2410 [D loss: 0.442212, acc.: 84.38%] [G loss: 0.492339]\n",
      "epoch:2 step:2411 [D loss: 0.512173, acc.: 71.09%] [G loss: 0.570982]\n",
      "epoch:2 step:2412 [D loss: 0.502663, acc.: 75.78%] [G loss: 0.554241]\n",
      "epoch:2 step:2413 [D loss: 0.477302, acc.: 78.91%] [G loss: 0.630642]\n",
      "epoch:2 step:2414 [D loss: 0.514014, acc.: 70.31%] [G loss: 0.579783]\n",
      "epoch:2 step:2415 [D loss: 0.434834, acc.: 86.72%] [G loss: 0.618280]\n",
      "epoch:2 step:2416 [D loss: 0.563886, acc.: 71.88%] [G loss: 0.418765]\n",
      "epoch:2 step:2417 [D loss: 0.527936, acc.: 76.56%] [G loss: 0.509029]\n",
      "epoch:2 step:2418 [D loss: 0.485131, acc.: 75.78%] [G loss: 0.567483]\n",
      "epoch:2 step:2419 [D loss: 0.481039, acc.: 78.91%] [G loss: 0.681672]\n",
      "epoch:2 step:2420 [D loss: 0.436586, acc.: 82.81%] [G loss: 0.662975]\n",
      "epoch:2 step:2421 [D loss: 0.413602, acc.: 83.59%] [G loss: 0.678811]\n",
      "epoch:2 step:2422 [D loss: 0.441474, acc.: 82.81%] [G loss: 0.693101]\n",
      "epoch:2 step:2423 [D loss: 0.502190, acc.: 76.56%] [G loss: 0.593222]\n",
      "epoch:2 step:2424 [D loss: 0.494251, acc.: 78.91%] [G loss: 0.605223]\n",
      "epoch:2 step:2425 [D loss: 0.504637, acc.: 75.78%] [G loss: 0.502568]\n",
      "epoch:2 step:2426 [D loss: 0.489974, acc.: 76.56%] [G loss: 0.467389]\n",
      "epoch:2 step:2427 [D loss: 0.471959, acc.: 80.47%] [G loss: 0.510243]\n",
      "epoch:2 step:2428 [D loss: 0.416055, acc.: 85.16%] [G loss: 0.612652]\n",
      "epoch:2 step:2429 [D loss: 0.415873, acc.: 82.03%] [G loss: 0.635636]\n",
      "epoch:2 step:2430 [D loss: 0.428368, acc.: 86.72%] [G loss: 0.652521]\n",
      "epoch:2 step:2431 [D loss: 0.436601, acc.: 83.59%] [G loss: 0.646255]\n",
      "epoch:2 step:2432 [D loss: 0.449401, acc.: 82.03%] [G loss: 0.608739]\n",
      "epoch:2 step:2433 [D loss: 0.527635, acc.: 77.34%] [G loss: 0.564056]\n",
      "epoch:2 step:2434 [D loss: 0.539831, acc.: 74.22%] [G loss: 0.563728]\n",
      "epoch:2 step:2435 [D loss: 0.522559, acc.: 75.78%] [G loss: 0.529859]\n",
      "epoch:2 step:2436 [D loss: 0.561804, acc.: 73.44%] [G loss: 0.471350]\n",
      "epoch:2 step:2437 [D loss: 0.520546, acc.: 78.91%] [G loss: 0.531083]\n",
      "epoch:2 step:2438 [D loss: 0.530994, acc.: 77.34%] [G loss: 0.549416]\n",
      "epoch:2 step:2439 [D loss: 0.471651, acc.: 80.47%] [G loss: 0.635772]\n",
      "epoch:2 step:2440 [D loss: 0.581266, acc.: 75.00%] [G loss: 0.472637]\n",
      "epoch:2 step:2441 [D loss: 0.468682, acc.: 78.91%] [G loss: 0.609886]\n",
      "epoch:2 step:2442 [D loss: 0.464256, acc.: 79.69%] [G loss: 0.557346]\n",
      "epoch:2 step:2443 [D loss: 0.461666, acc.: 81.25%] [G loss: 0.496252]\n",
      "epoch:2 step:2444 [D loss: 0.439978, acc.: 83.59%] [G loss: 0.596410]\n",
      "epoch:2 step:2445 [D loss: 0.487770, acc.: 81.25%] [G loss: 0.552654]\n",
      "epoch:2 step:2446 [D loss: 0.511534, acc.: 74.22%] [G loss: 0.513940]\n",
      "epoch:2 step:2447 [D loss: 0.464589, acc.: 82.81%] [G loss: 0.631329]\n",
      "epoch:2 step:2448 [D loss: 0.445586, acc.: 78.91%] [G loss: 0.646430]\n",
      "epoch:2 step:2449 [D loss: 0.424028, acc.: 80.47%] [G loss: 0.654023]\n",
      "epoch:2 step:2450 [D loss: 0.500613, acc.: 76.56%] [G loss: 0.630922]\n",
      "epoch:2 step:2451 [D loss: 0.513573, acc.: 75.00%] [G loss: 0.450520]\n",
      "epoch:2 step:2452 [D loss: 0.480568, acc.: 83.59%] [G loss: 0.460290]\n",
      "epoch:2 step:2453 [D loss: 0.510331, acc.: 78.12%] [G loss: 0.492363]\n",
      "epoch:2 step:2454 [D loss: 0.511656, acc.: 75.00%] [G loss: 0.546803]\n",
      "epoch:2 step:2455 [D loss: 0.479643, acc.: 78.12%] [G loss: 0.552282]\n",
      "epoch:2 step:2456 [D loss: 0.423487, acc.: 83.59%] [G loss: 0.610696]\n",
      "epoch:2 step:2457 [D loss: 0.532553, acc.: 73.44%] [G loss: 0.715882]\n",
      "epoch:2 step:2458 [D loss: 0.548237, acc.: 73.44%] [G loss: 0.520666]\n",
      "epoch:2 step:2459 [D loss: 0.485631, acc.: 75.78%] [G loss: 0.527297]\n",
      "epoch:2 step:2460 [D loss: 0.531051, acc.: 71.09%] [G loss: 0.477943]\n",
      "epoch:2 step:2461 [D loss: 0.534916, acc.: 75.00%] [G loss: 0.545728]\n",
      "epoch:2 step:2462 [D loss: 0.507350, acc.: 74.22%] [G loss: 0.649619]\n",
      "epoch:2 step:2463 [D loss: 0.451801, acc.: 81.25%] [G loss: 0.625762]\n",
      "epoch:2 step:2464 [D loss: 0.503302, acc.: 77.34%] [G loss: 0.537609]\n",
      "epoch:2 step:2465 [D loss: 0.559436, acc.: 75.00%] [G loss: 0.524784]\n",
      "epoch:2 step:2466 [D loss: 0.425005, acc.: 82.81%] [G loss: 0.566170]\n",
      "epoch:2 step:2467 [D loss: 0.565452, acc.: 67.97%] [G loss: 0.425188]\n",
      "epoch:2 step:2468 [D loss: 0.506798, acc.: 75.00%] [G loss: 0.553925]\n",
      "epoch:2 step:2469 [D loss: 0.493886, acc.: 79.69%] [G loss: 0.456245]\n",
      "epoch:2 step:2470 [D loss: 0.489396, acc.: 78.91%] [G loss: 0.549020]\n",
      "epoch:2 step:2471 [D loss: 0.466936, acc.: 79.69%] [G loss: 0.509978]\n",
      "epoch:2 step:2472 [D loss: 0.452040, acc.: 79.69%] [G loss: 0.607489]\n",
      "epoch:2 step:2473 [D loss: 0.526479, acc.: 74.22%] [G loss: 0.620860]\n",
      "epoch:2 step:2474 [D loss: 0.544862, acc.: 72.66%] [G loss: 0.470435]\n",
      "epoch:2 step:2475 [D loss: 0.539042, acc.: 73.44%] [G loss: 0.399445]\n",
      "epoch:2 step:2476 [D loss: 0.450041, acc.: 83.59%] [G loss: 0.459087]\n",
      "epoch:2 step:2477 [D loss: 0.459658, acc.: 81.25%] [G loss: 0.564449]\n",
      "epoch:2 step:2478 [D loss: 0.551429, acc.: 74.22%] [G loss: 0.511065]\n",
      "epoch:2 step:2479 [D loss: 0.446831, acc.: 82.03%] [G loss: 0.584250]\n",
      "epoch:2 step:2480 [D loss: 0.525185, acc.: 75.78%] [G loss: 0.451449]\n",
      "epoch:2 step:2481 [D loss: 0.515863, acc.: 75.00%] [G loss: 0.453660]\n",
      "epoch:2 step:2482 [D loss: 0.473053, acc.: 81.25%] [G loss: 0.445282]\n",
      "epoch:2 step:2483 [D loss: 0.467457, acc.: 79.69%] [G loss: 0.536116]\n",
      "epoch:2 step:2484 [D loss: 0.454154, acc.: 82.03%] [G loss: 0.573030]\n",
      "epoch:2 step:2485 [D loss: 0.451122, acc.: 82.03%] [G loss: 0.537963]\n",
      "epoch:2 step:2486 [D loss: 0.443729, acc.: 83.59%] [G loss: 0.541786]\n",
      "epoch:2 step:2487 [D loss: 0.457905, acc.: 82.81%] [G loss: 0.617686]\n",
      "epoch:2 step:2488 [D loss: 0.540448, acc.: 70.31%] [G loss: 0.535780]\n",
      "epoch:2 step:2489 [D loss: 0.565564, acc.: 69.53%] [G loss: 0.439875]\n",
      "epoch:2 step:2490 [D loss: 0.509325, acc.: 74.22%] [G loss: 0.541685]\n",
      "epoch:2 step:2491 [D loss: 0.546392, acc.: 67.97%] [G loss: 0.518142]\n",
      "epoch:2 step:2492 [D loss: 0.482379, acc.: 78.91%] [G loss: 0.530689]\n",
      "epoch:2 step:2493 [D loss: 0.502612, acc.: 75.78%] [G loss: 0.502874]\n",
      "epoch:2 step:2494 [D loss: 0.516674, acc.: 78.12%] [G loss: 0.562111]\n",
      "epoch:2 step:2495 [D loss: 0.535461, acc.: 75.78%] [G loss: 0.557162]\n",
      "epoch:2 step:2496 [D loss: 0.585051, acc.: 67.97%] [G loss: 0.424363]\n",
      "epoch:2 step:2497 [D loss: 0.466288, acc.: 82.81%] [G loss: 0.662774]\n",
      "epoch:2 step:2498 [D loss: 0.493105, acc.: 76.56%] [G loss: 0.633422]\n",
      "epoch:2 step:2499 [D loss: 0.551076, acc.: 67.97%] [G loss: 0.526935]\n",
      "epoch:2 step:2500 [D loss: 0.513098, acc.: 74.22%] [G loss: 0.454430]\n",
      "epoch:2 step:2501 [D loss: 0.491797, acc.: 78.12%] [G loss: 0.453160]\n",
      "epoch:2 step:2502 [D loss: 0.513367, acc.: 75.78%] [G loss: 0.485127]\n",
      "epoch:2 step:2503 [D loss: 0.466473, acc.: 77.34%] [G loss: 0.571896]\n",
      "epoch:2 step:2504 [D loss: 0.519020, acc.: 75.78%] [G loss: 0.475413]\n",
      "epoch:2 step:2505 [D loss: 0.469359, acc.: 79.69%] [G loss: 0.511776]\n",
      "epoch:2 step:2506 [D loss: 0.474862, acc.: 80.47%] [G loss: 0.516270]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2507 [D loss: 0.467365, acc.: 80.47%] [G loss: 0.535770]\n",
      "epoch:2 step:2508 [D loss: 0.430656, acc.: 84.38%] [G loss: 0.560436]\n",
      "epoch:2 step:2509 [D loss: 0.478645, acc.: 81.25%] [G loss: 0.613620]\n",
      "epoch:2 step:2510 [D loss: 0.526369, acc.: 71.88%] [G loss: 0.555614]\n",
      "epoch:2 step:2511 [D loss: 0.469651, acc.: 82.03%] [G loss: 0.569862]\n",
      "epoch:2 step:2512 [D loss: 0.459917, acc.: 83.59%] [G loss: 0.546528]\n",
      "epoch:2 step:2513 [D loss: 0.369447, acc.: 90.62%] [G loss: 0.699861]\n",
      "epoch:2 step:2514 [D loss: 0.469718, acc.: 79.69%] [G loss: 0.580992]\n",
      "epoch:2 step:2515 [D loss: 0.441344, acc.: 84.38%] [G loss: 0.554237]\n",
      "epoch:2 step:2516 [D loss: 0.434983, acc.: 85.16%] [G loss: 0.699844]\n",
      "epoch:2 step:2517 [D loss: 0.522702, acc.: 74.22%] [G loss: 0.690726]\n",
      "epoch:2 step:2518 [D loss: 0.543752, acc.: 71.88%] [G loss: 0.527022]\n",
      "epoch:2 step:2519 [D loss: 0.452736, acc.: 83.59%] [G loss: 0.506330]\n",
      "epoch:2 step:2520 [D loss: 0.508491, acc.: 77.34%] [G loss: 0.548862]\n",
      "epoch:2 step:2521 [D loss: 0.466399, acc.: 82.03%] [G loss: 0.676584]\n",
      "epoch:2 step:2522 [D loss: 0.439117, acc.: 81.25%] [G loss: 0.826143]\n",
      "epoch:2 step:2523 [D loss: 0.495296, acc.: 78.12%] [G loss: 0.576548]\n",
      "epoch:2 step:2524 [D loss: 0.444888, acc.: 82.03%] [G loss: 0.689598]\n",
      "epoch:2 step:2525 [D loss: 0.452483, acc.: 80.47%] [G loss: 0.663651]\n",
      "epoch:2 step:2526 [D loss: 0.626926, acc.: 64.84%] [G loss: 0.466495]\n",
      "epoch:2 step:2527 [D loss: 0.600831, acc.: 63.28%] [G loss: 0.561383]\n",
      "epoch:2 step:2528 [D loss: 0.521719, acc.: 75.78%] [G loss: 0.563960]\n",
      "epoch:2 step:2529 [D loss: 0.587416, acc.: 67.97%] [G loss: 0.367306]\n",
      "epoch:2 step:2530 [D loss: 0.516374, acc.: 73.44%] [G loss: 0.431393]\n",
      "epoch:2 step:2531 [D loss: 0.471750, acc.: 81.25%] [G loss: 0.464036]\n",
      "epoch:2 step:2532 [D loss: 0.527553, acc.: 74.22%] [G loss: 0.461799]\n",
      "epoch:2 step:2533 [D loss: 0.501804, acc.: 78.91%] [G loss: 0.501914]\n",
      "epoch:2 step:2534 [D loss: 0.485663, acc.: 76.56%] [G loss: 0.458814]\n",
      "epoch:2 step:2535 [D loss: 0.482309, acc.: 78.91%] [G loss: 0.450211]\n",
      "epoch:2 step:2536 [D loss: 0.541272, acc.: 71.09%] [G loss: 0.474588]\n",
      "epoch:2 step:2537 [D loss: 0.473522, acc.: 76.56%] [G loss: 0.521499]\n",
      "epoch:2 step:2538 [D loss: 0.540058, acc.: 72.66%] [G loss: 0.663929]\n",
      "epoch:2 step:2539 [D loss: 0.472308, acc.: 77.34%] [G loss: 0.661192]\n",
      "epoch:2 step:2540 [D loss: 0.455025, acc.: 84.38%] [G loss: 0.619822]\n",
      "epoch:2 step:2541 [D loss: 0.479061, acc.: 78.12%] [G loss: 0.605057]\n",
      "epoch:2 step:2542 [D loss: 0.528697, acc.: 78.91%] [G loss: 0.455862]\n",
      "epoch:2 step:2543 [D loss: 0.505648, acc.: 71.88%] [G loss: 0.463052]\n",
      "epoch:2 step:2544 [D loss: 0.439626, acc.: 80.47%] [G loss: 0.614066]\n",
      "epoch:2 step:2545 [D loss: 0.489099, acc.: 76.56%] [G loss: 0.524288]\n",
      "epoch:2 step:2546 [D loss: 0.577076, acc.: 69.53%] [G loss: 0.566208]\n",
      "epoch:2 step:2547 [D loss: 0.512366, acc.: 72.66%] [G loss: 0.486841]\n",
      "epoch:2 step:2548 [D loss: 0.535599, acc.: 71.09%] [G loss: 0.536845]\n",
      "epoch:2 step:2549 [D loss: 0.524335, acc.: 72.66%] [G loss: 0.450928]\n",
      "epoch:2 step:2550 [D loss: 0.488236, acc.: 79.69%] [G loss: 0.443710]\n",
      "epoch:2 step:2551 [D loss: 0.457869, acc.: 81.25%] [G loss: 0.587868]\n",
      "epoch:2 step:2552 [D loss: 0.422137, acc.: 83.59%] [G loss: 0.633638]\n",
      "epoch:2 step:2553 [D loss: 0.469805, acc.: 80.47%] [G loss: 0.544420]\n",
      "epoch:2 step:2554 [D loss: 0.403229, acc.: 85.94%] [G loss: 0.663434]\n",
      "epoch:2 step:2555 [D loss: 0.483263, acc.: 81.25%] [G loss: 0.615132]\n",
      "epoch:2 step:2556 [D loss: 0.482496, acc.: 78.12%] [G loss: 0.494028]\n",
      "epoch:2 step:2557 [D loss: 0.541054, acc.: 71.09%] [G loss: 0.470616]\n",
      "epoch:2 step:2558 [D loss: 0.524310, acc.: 75.78%] [G loss: 0.473879]\n",
      "epoch:2 step:2559 [D loss: 0.493868, acc.: 74.22%] [G loss: 0.508410]\n",
      "epoch:2 step:2560 [D loss: 0.516664, acc.: 78.12%] [G loss: 0.442258]\n",
      "epoch:2 step:2561 [D loss: 0.514061, acc.: 78.91%] [G loss: 0.538958]\n",
      "epoch:2 step:2562 [D loss: 0.563523, acc.: 75.00%] [G loss: 0.437576]\n",
      "epoch:2 step:2563 [D loss: 0.472381, acc.: 77.34%] [G loss: 0.574371]\n",
      "epoch:2 step:2564 [D loss: 0.445613, acc.: 85.94%] [G loss: 0.660996]\n",
      "epoch:2 step:2565 [D loss: 0.439667, acc.: 85.16%] [G loss: 0.800274]\n",
      "epoch:2 step:2566 [D loss: 0.475546, acc.: 79.69%] [G loss: 0.599902]\n",
      "epoch:2 step:2567 [D loss: 0.500791, acc.: 77.34%] [G loss: 0.556885]\n",
      "epoch:2 step:2568 [D loss: 0.455150, acc.: 81.25%] [G loss: 0.650083]\n",
      "epoch:2 step:2569 [D loss: 0.448981, acc.: 86.72%] [G loss: 0.603475]\n",
      "epoch:2 step:2570 [D loss: 0.492727, acc.: 75.78%] [G loss: 0.565306]\n",
      "epoch:2 step:2571 [D loss: 0.495034, acc.: 75.00%] [G loss: 0.528779]\n",
      "epoch:2 step:2572 [D loss: 0.517130, acc.: 76.56%] [G loss: 0.546862]\n",
      "epoch:2 step:2573 [D loss: 0.456582, acc.: 82.81%] [G loss: 0.553504]\n",
      "epoch:2 step:2574 [D loss: 0.478581, acc.: 79.69%] [G loss: 0.633404]\n",
      "epoch:2 step:2575 [D loss: 0.498824, acc.: 80.47%] [G loss: 0.696595]\n",
      "epoch:2 step:2576 [D loss: 0.522499, acc.: 77.34%] [G loss: 0.530826]\n",
      "epoch:2 step:2577 [D loss: 0.481446, acc.: 78.91%] [G loss: 0.490589]\n",
      "epoch:2 step:2578 [D loss: 0.549650, acc.: 71.88%] [G loss: 0.540497]\n",
      "epoch:2 step:2579 [D loss: 0.473078, acc.: 78.91%] [G loss: 0.532833]\n",
      "epoch:2 step:2580 [D loss: 0.468898, acc.: 81.25%] [G loss: 0.502362]\n",
      "epoch:2 step:2581 [D loss: 0.444661, acc.: 82.03%] [G loss: 0.653971]\n",
      "epoch:2 step:2582 [D loss: 0.376907, acc.: 86.72%] [G loss: 0.772740]\n",
      "epoch:2 step:2583 [D loss: 0.435285, acc.: 79.69%] [G loss: 0.801742]\n",
      "epoch:2 step:2584 [D loss: 0.601262, acc.: 71.09%] [G loss: 0.522820]\n",
      "epoch:2 step:2585 [D loss: 0.574191, acc.: 68.75%] [G loss: 0.424055]\n",
      "epoch:2 step:2586 [D loss: 0.479684, acc.: 79.69%] [G loss: 0.431010]\n",
      "epoch:2 step:2587 [D loss: 0.500793, acc.: 79.69%] [G loss: 0.485098]\n",
      "epoch:2 step:2588 [D loss: 0.467866, acc.: 82.03%] [G loss: 0.494028]\n",
      "epoch:2 step:2589 [D loss: 0.467876, acc.: 82.03%] [G loss: 0.512032]\n",
      "epoch:2 step:2590 [D loss: 0.519584, acc.: 78.91%] [G loss: 0.444174]\n",
      "epoch:2 step:2591 [D loss: 0.526271, acc.: 77.34%] [G loss: 0.519125]\n",
      "epoch:2 step:2592 [D loss: 0.532225, acc.: 75.00%] [G loss: 0.524116]\n",
      "epoch:2 step:2593 [D loss: 0.489383, acc.: 81.25%] [G loss: 0.509767]\n",
      "epoch:2 step:2594 [D loss: 0.623037, acc.: 65.62%] [G loss: 0.512633]\n",
      "epoch:2 step:2595 [D loss: 0.507051, acc.: 78.91%] [G loss: 0.419310]\n",
      "epoch:2 step:2596 [D loss: 0.506303, acc.: 78.91%] [G loss: 0.572678]\n",
      "epoch:2 step:2597 [D loss: 0.548046, acc.: 68.75%] [G loss: 0.534746]\n",
      "epoch:2 step:2598 [D loss: 0.514894, acc.: 76.56%] [G loss: 0.474673]\n",
      "epoch:2 step:2599 [D loss: 0.463850, acc.: 81.25%] [G loss: 0.579325]\n",
      "epoch:2 step:2600 [D loss: 0.480924, acc.: 78.12%] [G loss: 0.638306]\n",
      "##############\n",
      "[4.25604606 2.47890854 7.63647816 5.95771638 5.18538354 7.01113068\n",
      " 6.37305807 6.07820043 6.48990868 4.62737276]\n",
      "##########\n",
      "epoch:2 step:2601 [D loss: 0.554922, acc.: 72.66%] [G loss: 0.429467]\n",
      "epoch:2 step:2602 [D loss: 0.508357, acc.: 74.22%] [G loss: 0.479377]\n",
      "epoch:2 step:2603 [D loss: 0.526890, acc.: 76.56%] [G loss: 0.475003]\n",
      "epoch:2 step:2604 [D loss: 0.467905, acc.: 82.81%] [G loss: 0.485891]\n",
      "epoch:2 step:2605 [D loss: 0.488213, acc.: 75.00%] [G loss: 0.601809]\n",
      "epoch:2 step:2606 [D loss: 0.475122, acc.: 78.91%] [G loss: 0.680431]\n",
      "epoch:2 step:2607 [D loss: 0.463098, acc.: 76.56%] [G loss: 0.617598]\n",
      "epoch:2 step:2608 [D loss: 0.510191, acc.: 72.66%] [G loss: 0.668897]\n",
      "epoch:2 step:2609 [D loss: 0.538853, acc.: 74.22%] [G loss: 0.451439]\n",
      "epoch:2 step:2610 [D loss: 0.442360, acc.: 81.25%] [G loss: 0.607508]\n",
      "epoch:2 step:2611 [D loss: 0.490192, acc.: 78.12%] [G loss: 0.565809]\n",
      "epoch:2 step:2612 [D loss: 0.547966, acc.: 68.75%] [G loss: 0.409282]\n",
      "epoch:2 step:2613 [D loss: 0.543612, acc.: 75.00%] [G loss: 0.423796]\n",
      "epoch:2 step:2614 [D loss: 0.602689, acc.: 64.84%] [G loss: 0.425438]\n",
      "epoch:2 step:2615 [D loss: 0.542019, acc.: 74.22%] [G loss: 0.351522]\n",
      "epoch:2 step:2616 [D loss: 0.527367, acc.: 71.88%] [G loss: 0.503615]\n",
      "epoch:2 step:2617 [D loss: 0.460548, acc.: 80.47%] [G loss: 0.584749]\n",
      "epoch:2 step:2618 [D loss: 0.514660, acc.: 80.47%] [G loss: 0.520638]\n",
      "epoch:2 step:2619 [D loss: 0.507457, acc.: 72.66%] [G loss: 0.438813]\n",
      "epoch:2 step:2620 [D loss: 0.393241, acc.: 82.81%] [G loss: 0.689799]\n",
      "epoch:2 step:2621 [D loss: 0.434400, acc.: 85.16%] [G loss: 0.673940]\n",
      "epoch:2 step:2622 [D loss: 0.442943, acc.: 84.38%] [G loss: 0.625941]\n",
      "epoch:2 step:2623 [D loss: 0.576128, acc.: 69.53%] [G loss: 0.487430]\n",
      "epoch:2 step:2624 [D loss: 0.527943, acc.: 75.78%] [G loss: 0.427933]\n",
      "epoch:2 step:2625 [D loss: 0.492896, acc.: 77.34%] [G loss: 0.650890]\n",
      "epoch:2 step:2626 [D loss: 0.466717, acc.: 81.25%] [G loss: 0.585344]\n",
      "epoch:2 step:2627 [D loss: 0.429343, acc.: 84.38%] [G loss: 0.483641]\n",
      "epoch:2 step:2628 [D loss: 0.487690, acc.: 78.91%] [G loss: 0.666652]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2629 [D loss: 0.456362, acc.: 76.56%] [G loss: 0.649598]\n",
      "epoch:2 step:2630 [D loss: 0.446573, acc.: 80.47%] [G loss: 0.750368]\n",
      "epoch:2 step:2631 [D loss: 0.511744, acc.: 77.34%] [G loss: 0.655419]\n",
      "epoch:2 step:2632 [D loss: 0.541453, acc.: 72.66%] [G loss: 0.580535]\n",
      "epoch:2 step:2633 [D loss: 0.533798, acc.: 72.66%] [G loss: 0.569708]\n",
      "epoch:2 step:2634 [D loss: 0.493376, acc.: 79.69%] [G loss: 0.534313]\n",
      "epoch:2 step:2635 [D loss: 0.468304, acc.: 80.47%] [G loss: 0.598436]\n",
      "epoch:2 step:2636 [D loss: 0.501429, acc.: 75.00%] [G loss: 0.591070]\n",
      "epoch:2 step:2637 [D loss: 0.496247, acc.: 78.91%] [G loss: 0.576319]\n",
      "epoch:2 step:2638 [D loss: 0.498534, acc.: 79.69%] [G loss: 0.642841]\n",
      "epoch:2 step:2639 [D loss: 0.644262, acc.: 67.19%] [G loss: 0.454854]\n",
      "epoch:2 step:2640 [D loss: 0.634152, acc.: 64.06%] [G loss: 0.385051]\n",
      "epoch:2 step:2641 [D loss: 0.519403, acc.: 75.78%] [G loss: 0.462533]\n",
      "epoch:2 step:2642 [D loss: 0.518199, acc.: 73.44%] [G loss: 0.521359]\n",
      "epoch:2 step:2643 [D loss: 0.474966, acc.: 78.91%] [G loss: 0.667096]\n",
      "epoch:2 step:2644 [D loss: 0.517496, acc.: 71.88%] [G loss: 0.679197]\n",
      "epoch:2 step:2645 [D loss: 0.478251, acc.: 77.34%] [G loss: 0.531354]\n",
      "epoch:2 step:2646 [D loss: 0.479111, acc.: 78.12%] [G loss: 0.536791]\n",
      "epoch:2 step:2647 [D loss: 0.477160, acc.: 80.47%] [G loss: 0.539623]\n",
      "epoch:2 step:2648 [D loss: 0.570217, acc.: 67.97%] [G loss: 0.410457]\n",
      "epoch:2 step:2649 [D loss: 0.448144, acc.: 81.25%] [G loss: 0.548620]\n",
      "epoch:2 step:2650 [D loss: 0.533089, acc.: 72.66%] [G loss: 0.447301]\n",
      "epoch:2 step:2651 [D loss: 0.469254, acc.: 82.03%] [G loss: 0.668838]\n",
      "epoch:2 step:2652 [D loss: 0.510362, acc.: 72.66%] [G loss: 0.583918]\n",
      "epoch:2 step:2653 [D loss: 0.506323, acc.: 77.34%] [G loss: 0.558307]\n",
      "epoch:2 step:2654 [D loss: 0.497641, acc.: 77.34%] [G loss: 0.644873]\n",
      "epoch:2 step:2655 [D loss: 0.425825, acc.: 83.59%] [G loss: 0.705558]\n",
      "epoch:2 step:2656 [D loss: 0.472644, acc.: 78.12%] [G loss: 0.678751]\n",
      "epoch:2 step:2657 [D loss: 0.527653, acc.: 69.53%] [G loss: 0.646417]\n",
      "epoch:2 step:2658 [D loss: 0.500221, acc.: 73.44%] [G loss: 0.543183]\n",
      "epoch:2 step:2659 [D loss: 0.494733, acc.: 79.69%] [G loss: 0.580443]\n",
      "epoch:2 step:2660 [D loss: 0.438739, acc.: 82.81%] [G loss: 0.630305]\n",
      "epoch:2 step:2661 [D loss: 0.559303, acc.: 75.00%] [G loss: 0.363559]\n",
      "epoch:2 step:2662 [D loss: 0.567133, acc.: 71.09%] [G loss: 0.447411]\n",
      "epoch:2 step:2663 [D loss: 0.501011, acc.: 82.81%] [G loss: 0.463469]\n",
      "epoch:2 step:2664 [D loss: 0.490264, acc.: 77.34%] [G loss: 0.501548]\n",
      "epoch:2 step:2665 [D loss: 0.451744, acc.: 81.25%] [G loss: 0.536411]\n",
      "epoch:2 step:2666 [D loss: 0.409981, acc.: 84.38%] [G loss: 0.718403]\n",
      "epoch:2 step:2667 [D loss: 0.547849, acc.: 73.44%] [G loss: 0.695443]\n",
      "epoch:2 step:2668 [D loss: 0.545425, acc.: 74.22%] [G loss: 0.704076]\n",
      "epoch:2 step:2669 [D loss: 0.506115, acc.: 74.22%] [G loss: 0.592092]\n",
      "epoch:2 step:2670 [D loss: 0.446839, acc.: 78.91%] [G loss: 0.689380]\n",
      "epoch:2 step:2671 [D loss: 0.470901, acc.: 81.25%] [G loss: 0.553930]\n",
      "epoch:2 step:2672 [D loss: 0.433576, acc.: 82.03%] [G loss: 0.607047]\n",
      "epoch:2 step:2673 [D loss: 0.500043, acc.: 79.69%] [G loss: 0.506217]\n",
      "epoch:2 step:2674 [D loss: 0.543634, acc.: 69.53%] [G loss: 0.524825]\n",
      "epoch:2 step:2675 [D loss: 0.471963, acc.: 78.91%] [G loss: 0.598324]\n",
      "epoch:2 step:2676 [D loss: 0.472436, acc.: 76.56%] [G loss: 0.684134]\n",
      "epoch:2 step:2677 [D loss: 0.436186, acc.: 80.47%] [G loss: 0.848164]\n",
      "epoch:2 step:2678 [D loss: 0.469510, acc.: 78.12%] [G loss: 0.575233]\n",
      "epoch:2 step:2679 [D loss: 0.428170, acc.: 85.16%] [G loss: 0.624101]\n",
      "epoch:2 step:2680 [D loss: 0.464022, acc.: 78.91%] [G loss: 0.753039]\n",
      "epoch:2 step:2681 [D loss: 0.462352, acc.: 80.47%] [G loss: 0.636727]\n",
      "epoch:2 step:2682 [D loss: 0.497924, acc.: 78.91%] [G loss: 0.557832]\n",
      "epoch:2 step:2683 [D loss: 0.572180, acc.: 66.41%] [G loss: 0.412925]\n",
      "epoch:2 step:2684 [D loss: 0.472631, acc.: 76.56%] [G loss: 0.527031]\n",
      "epoch:2 step:2685 [D loss: 0.505034, acc.: 78.12%] [G loss: 0.612599]\n",
      "epoch:2 step:2686 [D loss: 0.553559, acc.: 73.44%] [G loss: 0.499061]\n",
      "epoch:2 step:2687 [D loss: 0.491079, acc.: 76.56%] [G loss: 0.536671]\n",
      "epoch:2 step:2688 [D loss: 0.499362, acc.: 82.03%] [G loss: 0.613299]\n",
      "epoch:2 step:2689 [D loss: 0.488413, acc.: 78.91%] [G loss: 0.688744]\n",
      "epoch:2 step:2690 [D loss: 0.582944, acc.: 65.62%] [G loss: 0.719603]\n",
      "epoch:2 step:2691 [D loss: 0.586693, acc.: 66.41%] [G loss: 0.564108]\n",
      "epoch:2 step:2692 [D loss: 0.547756, acc.: 69.53%] [G loss: 0.507465]\n",
      "epoch:2 step:2693 [D loss: 0.501372, acc.: 78.91%] [G loss: 0.481540]\n",
      "epoch:2 step:2694 [D loss: 0.540308, acc.: 71.88%] [G loss: 0.601073]\n",
      "epoch:2 step:2695 [D loss: 0.521456, acc.: 79.69%] [G loss: 0.488751]\n",
      "epoch:2 step:2696 [D loss: 0.423194, acc.: 84.38%] [G loss: 0.545162]\n",
      "epoch:2 step:2697 [D loss: 0.452954, acc.: 81.25%] [G loss: 0.591395]\n",
      "epoch:2 step:2698 [D loss: 0.599733, acc.: 67.19%] [G loss: 0.450214]\n",
      "epoch:2 step:2699 [D loss: 0.577276, acc.: 67.97%] [G loss: 0.355300]\n",
      "epoch:2 step:2700 [D loss: 0.575040, acc.: 68.75%] [G loss: 0.457378]\n",
      "epoch:2 step:2701 [D loss: 0.587486, acc.: 64.06%] [G loss: 0.519783]\n",
      "epoch:2 step:2702 [D loss: 0.554382, acc.: 74.22%] [G loss: 0.457293]\n",
      "epoch:2 step:2703 [D loss: 0.484923, acc.: 79.69%] [G loss: 0.588568]\n",
      "epoch:2 step:2704 [D loss: 0.489509, acc.: 75.78%] [G loss: 0.591786]\n",
      "epoch:2 step:2705 [D loss: 0.568458, acc.: 70.31%] [G loss: 0.540742]\n",
      "epoch:2 step:2706 [D loss: 0.477964, acc.: 78.91%] [G loss: 0.571750]\n",
      "epoch:2 step:2707 [D loss: 0.451148, acc.: 84.38%] [G loss: 0.460718]\n",
      "epoch:2 step:2708 [D loss: 0.463418, acc.: 79.69%] [G loss: 0.556199]\n",
      "epoch:2 step:2709 [D loss: 0.466971, acc.: 79.69%] [G loss: 0.637545]\n",
      "epoch:2 step:2710 [D loss: 0.545161, acc.: 74.22%] [G loss: 0.449164]\n",
      "epoch:2 step:2711 [D loss: 0.503556, acc.: 78.12%] [G loss: 0.476676]\n",
      "epoch:2 step:2712 [D loss: 0.468290, acc.: 80.47%] [G loss: 0.643588]\n",
      "epoch:2 step:2713 [D loss: 0.473612, acc.: 79.69%] [G loss: 0.496226]\n",
      "epoch:2 step:2714 [D loss: 0.526437, acc.: 75.78%] [G loss: 0.452651]\n",
      "epoch:2 step:2715 [D loss: 0.467129, acc.: 84.38%] [G loss: 0.557147]\n",
      "epoch:2 step:2716 [D loss: 0.479879, acc.: 80.47%] [G loss: 0.600996]\n",
      "epoch:2 step:2717 [D loss: 0.481676, acc.: 79.69%] [G loss: 0.542188]\n",
      "epoch:2 step:2718 [D loss: 0.547159, acc.: 75.00%] [G loss: 0.423025]\n",
      "epoch:2 step:2719 [D loss: 0.473492, acc.: 80.47%] [G loss: 0.532009]\n",
      "epoch:2 step:2720 [D loss: 0.516034, acc.: 73.44%] [G loss: 0.343635]\n",
      "epoch:2 step:2721 [D loss: 0.489629, acc.: 77.34%] [G loss: 0.468973]\n",
      "epoch:2 step:2722 [D loss: 0.471225, acc.: 83.59%] [G loss: 0.545156]\n",
      "epoch:2 step:2723 [D loss: 0.518339, acc.: 80.47%] [G loss: 0.525178]\n",
      "epoch:2 step:2724 [D loss: 0.552934, acc.: 67.19%] [G loss: 0.367891]\n",
      "epoch:2 step:2725 [D loss: 0.504841, acc.: 76.56%] [G loss: 0.469418]\n",
      "epoch:2 step:2726 [D loss: 0.501444, acc.: 80.47%] [G loss: 0.609766]\n",
      "epoch:2 step:2727 [D loss: 0.480042, acc.: 77.34%] [G loss: 0.669618]\n",
      "epoch:2 step:2728 [D loss: 0.429004, acc.: 84.38%] [G loss: 0.650979]\n",
      "epoch:2 step:2729 [D loss: 0.524502, acc.: 74.22%] [G loss: 0.550211]\n",
      "epoch:2 step:2730 [D loss: 0.533242, acc.: 75.00%] [G loss: 0.627344]\n",
      "epoch:2 step:2731 [D loss: 0.478221, acc.: 77.34%] [G loss: 0.527517]\n",
      "epoch:2 step:2732 [D loss: 0.619027, acc.: 63.28%] [G loss: 0.449133]\n",
      "epoch:2 step:2733 [D loss: 0.537291, acc.: 72.66%] [G loss: 0.542827]\n",
      "epoch:2 step:2734 [D loss: 0.428398, acc.: 82.03%] [G loss: 0.552579]\n",
      "epoch:2 step:2735 [D loss: 0.535402, acc.: 75.00%] [G loss: 0.521256]\n",
      "epoch:2 step:2736 [D loss: 0.506084, acc.: 76.56%] [G loss: 0.539087]\n",
      "epoch:2 step:2737 [D loss: 0.495269, acc.: 78.12%] [G loss: 0.498682]\n",
      "epoch:2 step:2738 [D loss: 0.507708, acc.: 76.56%] [G loss: 0.425919]\n",
      "epoch:2 step:2739 [D loss: 0.542787, acc.: 73.44%] [G loss: 0.405075]\n",
      "epoch:2 step:2740 [D loss: 0.471250, acc.: 83.59%] [G loss: 0.534222]\n",
      "epoch:2 step:2741 [D loss: 0.563418, acc.: 71.88%] [G loss: 0.438447]\n",
      "epoch:2 step:2742 [D loss: 0.500607, acc.: 71.88%] [G loss: 0.437999]\n",
      "epoch:2 step:2743 [D loss: 0.555524, acc.: 72.66%] [G loss: 0.510155]\n",
      "epoch:2 step:2744 [D loss: 0.477466, acc.: 79.69%] [G loss: 0.581722]\n",
      "epoch:2 step:2745 [D loss: 0.468419, acc.: 78.91%] [G loss: 0.506468]\n",
      "epoch:2 step:2746 [D loss: 0.498406, acc.: 71.88%] [G loss: 0.545438]\n",
      "epoch:2 step:2747 [D loss: 0.508521, acc.: 73.44%] [G loss: 0.531799]\n",
      "epoch:2 step:2748 [D loss: 0.475838, acc.: 76.56%] [G loss: 0.618855]\n",
      "epoch:2 step:2749 [D loss: 0.481438, acc.: 80.47%] [G loss: 0.476126]\n",
      "epoch:2 step:2750 [D loss: 0.422207, acc.: 86.72%] [G loss: 0.602060]\n",
      "epoch:2 step:2751 [D loss: 0.503283, acc.: 74.22%] [G loss: 0.564040]\n",
      "epoch:2 step:2752 [D loss: 0.505657, acc.: 73.44%] [G loss: 0.523036]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2753 [D loss: 0.508695, acc.: 76.56%] [G loss: 0.474630]\n",
      "epoch:2 step:2754 [D loss: 0.551402, acc.: 67.19%] [G loss: 0.428794]\n",
      "epoch:2 step:2755 [D loss: 0.510186, acc.: 75.00%] [G loss: 0.466146]\n",
      "epoch:2 step:2756 [D loss: 0.525705, acc.: 76.56%] [G loss: 0.467690]\n",
      "epoch:2 step:2757 [D loss: 0.531188, acc.: 75.00%] [G loss: 0.458075]\n",
      "epoch:2 step:2758 [D loss: 0.446207, acc.: 83.59%] [G loss: 0.595505]\n",
      "epoch:2 step:2759 [D loss: 0.470442, acc.: 75.00%] [G loss: 0.614504]\n",
      "epoch:2 step:2760 [D loss: 0.445809, acc.: 82.03%] [G loss: 0.662566]\n",
      "epoch:2 step:2761 [D loss: 0.426377, acc.: 80.47%] [G loss: 0.680615]\n",
      "epoch:2 step:2762 [D loss: 0.462805, acc.: 76.56%] [G loss: 0.700101]\n",
      "epoch:2 step:2763 [D loss: 0.418780, acc.: 85.94%] [G loss: 0.633695]\n",
      "epoch:2 step:2764 [D loss: 0.397552, acc.: 88.28%] [G loss: 0.774946]\n",
      "epoch:2 step:2765 [D loss: 0.561627, acc.: 69.53%] [G loss: 0.471120]\n",
      "epoch:2 step:2766 [D loss: 0.553571, acc.: 69.53%] [G loss: 0.533360]\n",
      "epoch:2 step:2767 [D loss: 0.543601, acc.: 71.09%] [G loss: 0.386959]\n",
      "epoch:2 step:2768 [D loss: 0.468930, acc.: 77.34%] [G loss: 0.591500]\n",
      "epoch:2 step:2769 [D loss: 0.501921, acc.: 78.91%] [G loss: 0.561071]\n",
      "epoch:2 step:2770 [D loss: 0.519732, acc.: 71.88%] [G loss: 0.645541]\n",
      "epoch:2 step:2771 [D loss: 0.484258, acc.: 76.56%] [G loss: 0.599595]\n",
      "epoch:2 step:2772 [D loss: 0.485670, acc.: 77.34%] [G loss: 0.580442]\n",
      "epoch:2 step:2773 [D loss: 0.512116, acc.: 71.88%] [G loss: 0.560547]\n",
      "epoch:2 step:2774 [D loss: 0.471153, acc.: 78.12%] [G loss: 0.565183]\n",
      "epoch:2 step:2775 [D loss: 0.506433, acc.: 72.66%] [G loss: 0.598319]\n",
      "epoch:2 step:2776 [D loss: 0.529998, acc.: 74.22%] [G loss: 0.459503]\n",
      "epoch:2 step:2777 [D loss: 0.551726, acc.: 69.53%] [G loss: 0.574522]\n",
      "epoch:2 step:2778 [D loss: 0.475538, acc.: 78.12%] [G loss: 0.582029]\n",
      "epoch:2 step:2779 [D loss: 0.489635, acc.: 78.12%] [G loss: 0.714238]\n",
      "epoch:2 step:2780 [D loss: 0.502408, acc.: 77.34%] [G loss: 0.561701]\n",
      "epoch:2 step:2781 [D loss: 0.524463, acc.: 74.22%] [G loss: 0.442619]\n",
      "epoch:2 step:2782 [D loss: 0.457329, acc.: 83.59%] [G loss: 0.530962]\n",
      "epoch:2 step:2783 [D loss: 0.435221, acc.: 85.94%] [G loss: 0.621618]\n",
      "epoch:2 step:2784 [D loss: 0.423871, acc.: 79.69%] [G loss: 0.653822]\n",
      "epoch:2 step:2785 [D loss: 0.411691, acc.: 85.94%] [G loss: 0.612089]\n",
      "epoch:2 step:2786 [D loss: 0.409996, acc.: 86.72%] [G loss: 0.570221]\n",
      "epoch:2 step:2787 [D loss: 0.532727, acc.: 71.88%] [G loss: 0.551385]\n",
      "epoch:2 step:2788 [D loss: 0.436802, acc.: 84.38%] [G loss: 0.627105]\n",
      "epoch:2 step:2789 [D loss: 0.520510, acc.: 75.78%] [G loss: 0.592937]\n",
      "epoch:2 step:2790 [D loss: 0.496343, acc.: 77.34%] [G loss: 0.616255]\n",
      "epoch:2 step:2791 [D loss: 0.514270, acc.: 80.47%] [G loss: 0.472874]\n",
      "epoch:2 step:2792 [D loss: 0.462728, acc.: 84.38%] [G loss: 0.583284]\n",
      "epoch:2 step:2793 [D loss: 0.488979, acc.: 78.91%] [G loss: 0.647158]\n",
      "epoch:2 step:2794 [D loss: 0.548345, acc.: 68.75%] [G loss: 0.629841]\n",
      "epoch:2 step:2795 [D loss: 0.379927, acc.: 88.28%] [G loss: 0.679640]\n",
      "epoch:2 step:2796 [D loss: 0.580311, acc.: 67.19%] [G loss: 0.424565]\n",
      "epoch:2 step:2797 [D loss: 0.458274, acc.: 81.25%] [G loss: 0.531477]\n",
      "epoch:2 step:2798 [D loss: 0.381785, acc.: 85.94%] [G loss: 0.707577]\n",
      "epoch:2 step:2799 [D loss: 0.445629, acc.: 80.47%] [G loss: 0.985101]\n",
      "epoch:2 step:2800 [D loss: 0.424576, acc.: 81.25%] [G loss: 1.167977]\n",
      "##############\n",
      "[4.24877781 2.25347232 7.71816598 6.02462818 5.13702351 6.77826396\n",
      " 6.2661381  6.0909682  6.32564777 4.59230687]\n",
      "##########\n",
      "epoch:2 step:2801 [D loss: 0.397957, acc.: 87.50%] [G loss: 1.168001]\n",
      "epoch:2 step:2802 [D loss: 0.806579, acc.: 60.94%] [G loss: 0.620198]\n",
      "epoch:2 step:2803 [D loss: 0.469996, acc.: 76.56%] [G loss: 0.706855]\n",
      "epoch:2 step:2804 [D loss: 0.366214, acc.: 85.94%] [G loss: 0.856009]\n",
      "epoch:2 step:2805 [D loss: 0.611564, acc.: 60.94%] [G loss: 0.590909]\n",
      "epoch:2 step:2806 [D loss: 0.523446, acc.: 75.00%] [G loss: 0.610112]\n",
      "epoch:2 step:2807 [D loss: 0.405962, acc.: 89.06%] [G loss: 0.574147]\n",
      "epoch:2 step:2808 [D loss: 0.527036, acc.: 75.00%] [G loss: 0.538336]\n",
      "epoch:2 step:2809 [D loss: 0.479006, acc.: 76.56%] [G loss: 0.668257]\n",
      "epoch:2 step:2810 [D loss: 0.356857, acc.: 87.50%] [G loss: 0.876214]\n",
      "epoch:2 step:2811 [D loss: 0.400298, acc.: 83.59%] [G loss: 0.915090]\n",
      "epoch:3 step:2812 [D loss: 0.503968, acc.: 82.03%] [G loss: 0.653887]\n",
      "epoch:3 step:2813 [D loss: 0.474611, acc.: 77.34%] [G loss: 0.679976]\n",
      "epoch:3 step:2814 [D loss: 0.524717, acc.: 76.56%] [G loss: 0.674879]\n",
      "epoch:3 step:2815 [D loss: 0.468919, acc.: 78.91%] [G loss: 0.540716]\n",
      "epoch:3 step:2816 [D loss: 0.499489, acc.: 70.31%] [G loss: 0.687809]\n",
      "epoch:3 step:2817 [D loss: 0.528600, acc.: 71.09%] [G loss: 0.608988]\n",
      "epoch:3 step:2818 [D loss: 0.440203, acc.: 85.16%] [G loss: 0.645867]\n",
      "epoch:3 step:2819 [D loss: 0.458918, acc.: 78.12%] [G loss: 0.624042]\n",
      "epoch:3 step:2820 [D loss: 0.493913, acc.: 73.44%] [G loss: 0.533223]\n",
      "epoch:3 step:2821 [D loss: 0.454320, acc.: 84.38%] [G loss: 0.688091]\n",
      "epoch:3 step:2822 [D loss: 0.449712, acc.: 79.69%] [G loss: 0.599884]\n",
      "epoch:3 step:2823 [D loss: 0.503803, acc.: 77.34%] [G loss: 0.592432]\n",
      "epoch:3 step:2824 [D loss: 0.457691, acc.: 82.03%] [G loss: 0.626806]\n",
      "epoch:3 step:2825 [D loss: 0.507454, acc.: 78.12%] [G loss: 0.572739]\n",
      "epoch:3 step:2826 [D loss: 0.419458, acc.: 84.38%] [G loss: 0.679694]\n",
      "epoch:3 step:2827 [D loss: 0.442318, acc.: 80.47%] [G loss: 0.555070]\n",
      "epoch:3 step:2828 [D loss: 0.539582, acc.: 72.66%] [G loss: 0.562162]\n",
      "epoch:3 step:2829 [D loss: 0.542173, acc.: 72.66%] [G loss: 0.546035]\n",
      "epoch:3 step:2830 [D loss: 0.501140, acc.: 76.56%] [G loss: 0.479071]\n",
      "epoch:3 step:2831 [D loss: 0.558395, acc.: 72.66%] [G loss: 0.512802]\n",
      "epoch:3 step:2832 [D loss: 0.443736, acc.: 80.47%] [G loss: 0.633974]\n",
      "epoch:3 step:2833 [D loss: 0.429093, acc.: 80.47%] [G loss: 0.784404]\n",
      "epoch:3 step:2834 [D loss: 0.471636, acc.: 79.69%] [G loss: 0.650048]\n",
      "epoch:3 step:2835 [D loss: 0.461641, acc.: 81.25%] [G loss: 0.669860]\n",
      "epoch:3 step:2836 [D loss: 0.453496, acc.: 82.03%] [G loss: 0.612303]\n",
      "epoch:3 step:2837 [D loss: 0.480681, acc.: 76.56%] [G loss: 0.576859]\n",
      "epoch:3 step:2838 [D loss: 0.455277, acc.: 82.03%] [G loss: 0.660867]\n",
      "epoch:3 step:2839 [D loss: 0.488895, acc.: 76.56%] [G loss: 0.581548]\n",
      "epoch:3 step:2840 [D loss: 0.457132, acc.: 76.56%] [G loss: 0.549930]\n",
      "epoch:3 step:2841 [D loss: 0.499843, acc.: 79.69%] [G loss: 0.503505]\n",
      "epoch:3 step:2842 [D loss: 0.523331, acc.: 75.78%] [G loss: 0.498674]\n",
      "epoch:3 step:2843 [D loss: 0.514337, acc.: 71.88%] [G loss: 0.634344]\n",
      "epoch:3 step:2844 [D loss: 0.478034, acc.: 78.12%] [G loss: 0.667717]\n",
      "epoch:3 step:2845 [D loss: 0.411693, acc.: 85.94%] [G loss: 0.749815]\n",
      "epoch:3 step:2846 [D loss: 0.470909, acc.: 82.81%] [G loss: 0.739318]\n",
      "epoch:3 step:2847 [D loss: 0.407171, acc.: 80.47%] [G loss: 0.845431]\n",
      "epoch:3 step:2848 [D loss: 0.462722, acc.: 76.56%] [G loss: 0.553452]\n",
      "epoch:3 step:2849 [D loss: 0.499986, acc.: 77.34%] [G loss: 0.621632]\n",
      "epoch:3 step:2850 [D loss: 0.435786, acc.: 82.81%] [G loss: 0.578108]\n",
      "epoch:3 step:2851 [D loss: 0.437932, acc.: 81.25%] [G loss: 0.690037]\n",
      "epoch:3 step:2852 [D loss: 0.510347, acc.: 78.12%] [G loss: 0.610145]\n",
      "epoch:3 step:2853 [D loss: 0.469675, acc.: 79.69%] [G loss: 0.678040]\n",
      "epoch:3 step:2854 [D loss: 0.489052, acc.: 75.78%] [G loss: 0.586766]\n",
      "epoch:3 step:2855 [D loss: 0.525932, acc.: 74.22%] [G loss: 0.536998]\n",
      "epoch:3 step:2856 [D loss: 0.482061, acc.: 77.34%] [G loss: 0.675408]\n",
      "epoch:3 step:2857 [D loss: 0.502813, acc.: 78.12%] [G loss: 0.595134]\n",
      "epoch:3 step:2858 [D loss: 0.552246, acc.: 72.66%] [G loss: 0.534060]\n",
      "epoch:3 step:2859 [D loss: 0.485494, acc.: 84.38%] [G loss: 0.605772]\n",
      "epoch:3 step:2860 [D loss: 0.513558, acc.: 77.34%] [G loss: 0.534675]\n",
      "epoch:3 step:2861 [D loss: 0.505641, acc.: 77.34%] [G loss: 0.582964]\n",
      "epoch:3 step:2862 [D loss: 0.445071, acc.: 85.16%] [G loss: 0.573656]\n",
      "epoch:3 step:2863 [D loss: 0.514896, acc.: 78.12%] [G loss: 0.510675]\n",
      "epoch:3 step:2864 [D loss: 0.521745, acc.: 76.56%] [G loss: 0.456275]\n",
      "epoch:3 step:2865 [D loss: 0.456234, acc.: 83.59%] [G loss: 0.670475]\n",
      "epoch:3 step:2866 [D loss: 0.502374, acc.: 77.34%] [G loss: 0.632154]\n",
      "epoch:3 step:2867 [D loss: 0.489104, acc.: 75.00%] [G loss: 0.626348]\n",
      "epoch:3 step:2868 [D loss: 0.504820, acc.: 75.78%] [G loss: 0.588966]\n",
      "epoch:3 step:2869 [D loss: 0.453776, acc.: 84.38%] [G loss: 0.580675]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2870 [D loss: 0.490125, acc.: 75.78%] [G loss: 0.534416]\n",
      "epoch:3 step:2871 [D loss: 0.496377, acc.: 75.78%] [G loss: 0.583301]\n",
      "epoch:3 step:2872 [D loss: 0.506374, acc.: 75.78%] [G loss: 0.519363]\n",
      "epoch:3 step:2873 [D loss: 0.534339, acc.: 75.00%] [G loss: 0.473873]\n",
      "epoch:3 step:2874 [D loss: 0.519660, acc.: 75.78%] [G loss: 0.461420]\n",
      "epoch:3 step:2875 [D loss: 0.481013, acc.: 78.12%] [G loss: 0.532914]\n",
      "epoch:3 step:2876 [D loss: 0.556416, acc.: 72.66%] [G loss: 0.625408]\n",
      "epoch:3 step:2877 [D loss: 0.506225, acc.: 71.09%] [G loss: 0.600788]\n",
      "epoch:3 step:2878 [D loss: 0.504999, acc.: 75.78%] [G loss: 0.541250]\n",
      "epoch:3 step:2879 [D loss: 0.534378, acc.: 69.53%] [G loss: 0.604688]\n",
      "epoch:3 step:2880 [D loss: 0.539158, acc.: 74.22%] [G loss: 0.525243]\n",
      "epoch:3 step:2881 [D loss: 0.450926, acc.: 82.81%] [G loss: 0.675620]\n",
      "epoch:3 step:2882 [D loss: 0.492933, acc.: 75.78%] [G loss: 0.534329]\n",
      "epoch:3 step:2883 [D loss: 0.376204, acc.: 87.50%] [G loss: 0.811288]\n",
      "epoch:3 step:2884 [D loss: 0.509804, acc.: 75.78%] [G loss: 0.522731]\n",
      "epoch:3 step:2885 [D loss: 0.480324, acc.: 82.81%] [G loss: 0.516281]\n",
      "epoch:3 step:2886 [D loss: 0.469913, acc.: 78.12%] [G loss: 0.622372]\n",
      "epoch:3 step:2887 [D loss: 0.490223, acc.: 77.34%] [G loss: 0.710207]\n",
      "epoch:3 step:2888 [D loss: 0.394163, acc.: 84.38%] [G loss: 0.794032]\n",
      "epoch:3 step:2889 [D loss: 0.565598, acc.: 74.22%] [G loss: 0.573698]\n",
      "epoch:3 step:2890 [D loss: 0.514798, acc.: 73.44%] [G loss: 0.630254]\n",
      "epoch:3 step:2891 [D loss: 0.521525, acc.: 75.78%] [G loss: 0.431291]\n",
      "epoch:3 step:2892 [D loss: 0.534949, acc.: 71.88%] [G loss: 0.453456]\n",
      "epoch:3 step:2893 [D loss: 0.428676, acc.: 83.59%] [G loss: 0.673280]\n",
      "epoch:3 step:2894 [D loss: 0.530064, acc.: 75.00%] [G loss: 0.499833]\n",
      "epoch:3 step:2895 [D loss: 0.511870, acc.: 75.78%] [G loss: 0.561433]\n",
      "epoch:3 step:2896 [D loss: 0.504311, acc.: 75.78%] [G loss: 0.602812]\n",
      "epoch:3 step:2897 [D loss: 0.485207, acc.: 80.47%] [G loss: 0.565546]\n",
      "epoch:3 step:2898 [D loss: 0.479680, acc.: 76.56%] [G loss: 0.645903]\n",
      "epoch:3 step:2899 [D loss: 0.504649, acc.: 76.56%] [G loss: 0.520780]\n",
      "epoch:3 step:2900 [D loss: 0.519725, acc.: 76.56%] [G loss: 0.581619]\n",
      "epoch:3 step:2901 [D loss: 0.482882, acc.: 78.12%] [G loss: 0.630639]\n",
      "epoch:3 step:2902 [D loss: 0.526486, acc.: 74.22%] [G loss: 0.618184]\n",
      "epoch:3 step:2903 [D loss: 0.486408, acc.: 78.91%] [G loss: 0.580163]\n",
      "epoch:3 step:2904 [D loss: 0.478612, acc.: 78.91%] [G loss: 0.578872]\n",
      "epoch:3 step:2905 [D loss: 0.494747, acc.: 76.56%] [G loss: 0.572503]\n",
      "epoch:3 step:2906 [D loss: 0.447958, acc.: 81.25%] [G loss: 0.684058]\n",
      "epoch:3 step:2907 [D loss: 0.414304, acc.: 82.03%] [G loss: 0.511776]\n",
      "epoch:3 step:2908 [D loss: 0.512574, acc.: 75.00%] [G loss: 0.577221]\n",
      "epoch:3 step:2909 [D loss: 0.488793, acc.: 75.00%] [G loss: 0.682667]\n",
      "epoch:3 step:2910 [D loss: 0.528651, acc.: 71.88%] [G loss: 0.655030]\n",
      "epoch:3 step:2911 [D loss: 0.469750, acc.: 79.69%] [G loss: 0.601288]\n",
      "epoch:3 step:2912 [D loss: 0.513885, acc.: 69.53%] [G loss: 0.649552]\n",
      "epoch:3 step:2913 [D loss: 0.457811, acc.: 83.59%] [G loss: 0.555564]\n",
      "epoch:3 step:2914 [D loss: 0.431278, acc.: 82.03%] [G loss: 0.595315]\n",
      "epoch:3 step:2915 [D loss: 0.481202, acc.: 78.91%] [G loss: 0.634613]\n",
      "epoch:3 step:2916 [D loss: 0.513393, acc.: 75.00%] [G loss: 0.583882]\n",
      "epoch:3 step:2917 [D loss: 0.561949, acc.: 73.44%] [G loss: 0.558070]\n",
      "epoch:3 step:2918 [D loss: 0.601972, acc.: 66.41%] [G loss: 0.504408]\n",
      "epoch:3 step:2919 [D loss: 0.544704, acc.: 71.09%] [G loss: 0.550439]\n",
      "epoch:3 step:2920 [D loss: 0.566921, acc.: 73.44%] [G loss: 0.531502]\n",
      "epoch:3 step:2921 [D loss: 0.492182, acc.: 77.34%] [G loss: 0.593193]\n",
      "epoch:3 step:2922 [D loss: 0.484193, acc.: 77.34%] [G loss: 0.557029]\n",
      "epoch:3 step:2923 [D loss: 0.452629, acc.: 84.38%] [G loss: 0.534932]\n",
      "epoch:3 step:2924 [D loss: 0.594154, acc.: 62.50%] [G loss: 0.528349]\n",
      "epoch:3 step:2925 [D loss: 0.506564, acc.: 76.56%] [G loss: 0.459248]\n",
      "epoch:3 step:2926 [D loss: 0.516473, acc.: 75.00%] [G loss: 0.621450]\n",
      "epoch:3 step:2927 [D loss: 0.504327, acc.: 79.69%] [G loss: 0.676949]\n",
      "epoch:3 step:2928 [D loss: 0.476711, acc.: 81.25%] [G loss: 0.559001]\n",
      "epoch:3 step:2929 [D loss: 0.480603, acc.: 78.91%] [G loss: 0.723506]\n",
      "epoch:3 step:2930 [D loss: 0.507817, acc.: 77.34%] [G loss: 0.733518]\n",
      "epoch:3 step:2931 [D loss: 0.653580, acc.: 66.41%] [G loss: 0.448149]\n",
      "epoch:3 step:2932 [D loss: 0.527039, acc.: 75.78%] [G loss: 0.498127]\n",
      "epoch:3 step:2933 [D loss: 0.510125, acc.: 75.00%] [G loss: 0.565178]\n",
      "epoch:3 step:2934 [D loss: 0.509884, acc.: 72.66%] [G loss: 0.502843]\n",
      "epoch:3 step:2935 [D loss: 0.528584, acc.: 70.31%] [G loss: 0.499700]\n",
      "epoch:3 step:2936 [D loss: 0.507787, acc.: 77.34%] [G loss: 0.502465]\n",
      "epoch:3 step:2937 [D loss: 0.500263, acc.: 78.91%] [G loss: 0.523103]\n",
      "epoch:3 step:2938 [D loss: 0.502636, acc.: 78.12%] [G loss: 0.533325]\n",
      "epoch:3 step:2939 [D loss: 0.445479, acc.: 82.81%] [G loss: 0.621738]\n",
      "epoch:3 step:2940 [D loss: 0.531452, acc.: 72.66%] [G loss: 0.426819]\n",
      "epoch:3 step:2941 [D loss: 0.525738, acc.: 75.78%] [G loss: 0.390355]\n",
      "epoch:3 step:2942 [D loss: 0.456689, acc.: 79.69%] [G loss: 0.458550]\n",
      "epoch:3 step:2943 [D loss: 0.517005, acc.: 75.00%] [G loss: 0.532448]\n",
      "epoch:3 step:2944 [D loss: 0.556496, acc.: 72.66%] [G loss: 0.486572]\n",
      "epoch:3 step:2945 [D loss: 0.500451, acc.: 75.00%] [G loss: 0.518248]\n",
      "epoch:3 step:2946 [D loss: 0.487240, acc.: 77.34%] [G loss: 0.554534]\n",
      "epoch:3 step:2947 [D loss: 0.477998, acc.: 81.25%] [G loss: 0.613887]\n",
      "epoch:3 step:2948 [D loss: 0.566672, acc.: 70.31%] [G loss: 0.516276]\n",
      "epoch:3 step:2949 [D loss: 0.454297, acc.: 78.91%] [G loss: 0.648107]\n",
      "epoch:3 step:2950 [D loss: 0.527633, acc.: 70.31%] [G loss: 0.628417]\n",
      "epoch:3 step:2951 [D loss: 0.501845, acc.: 75.78%] [G loss: 0.535432]\n",
      "epoch:3 step:2952 [D loss: 0.472241, acc.: 75.78%] [G loss: 0.528422]\n",
      "epoch:3 step:2953 [D loss: 0.453583, acc.: 82.03%] [G loss: 0.616345]\n",
      "epoch:3 step:2954 [D loss: 0.534870, acc.: 71.09%] [G loss: 0.647669]\n",
      "epoch:3 step:2955 [D loss: 0.454497, acc.: 84.38%] [G loss: 0.642455]\n",
      "epoch:3 step:2956 [D loss: 0.543340, acc.: 69.53%] [G loss: 0.630664]\n",
      "epoch:3 step:2957 [D loss: 0.502522, acc.: 75.78%] [G loss: 0.745175]\n",
      "epoch:3 step:2958 [D loss: 0.559811, acc.: 75.00%] [G loss: 0.539801]\n",
      "epoch:3 step:2959 [D loss: 0.509355, acc.: 73.44%] [G loss: 0.492711]\n",
      "epoch:3 step:2960 [D loss: 0.412892, acc.: 86.72%] [G loss: 0.576228]\n",
      "epoch:3 step:2961 [D loss: 0.517549, acc.: 75.00%] [G loss: 0.533035]\n",
      "epoch:3 step:2962 [D loss: 0.513792, acc.: 71.88%] [G loss: 0.537915]\n",
      "epoch:3 step:2963 [D loss: 0.387004, acc.: 85.94%] [G loss: 0.879177]\n",
      "epoch:3 step:2964 [D loss: 0.542084, acc.: 75.78%] [G loss: 0.551586]\n",
      "epoch:3 step:2965 [D loss: 0.461033, acc.: 82.81%] [G loss: 0.722801]\n",
      "epoch:3 step:2966 [D loss: 0.420088, acc.: 87.50%] [G loss: 0.631507]\n",
      "epoch:3 step:2967 [D loss: 0.477985, acc.: 81.25%] [G loss: 0.667151]\n",
      "epoch:3 step:2968 [D loss: 0.494274, acc.: 74.22%] [G loss: 0.546139]\n",
      "epoch:3 step:2969 [D loss: 0.512600, acc.: 77.34%] [G loss: 0.427955]\n",
      "epoch:3 step:2970 [D loss: 0.481647, acc.: 77.34%] [G loss: 0.631441]\n",
      "epoch:3 step:2971 [D loss: 0.533687, acc.: 74.22%] [G loss: 0.455563]\n",
      "epoch:3 step:2972 [D loss: 0.444914, acc.: 85.94%] [G loss: 0.554752]\n",
      "epoch:3 step:2973 [D loss: 0.413739, acc.: 81.25%] [G loss: 0.738784]\n",
      "epoch:3 step:2974 [D loss: 0.447918, acc.: 82.03%] [G loss: 0.626898]\n",
      "epoch:3 step:2975 [D loss: 0.500439, acc.: 78.12%] [G loss: 0.626725]\n",
      "epoch:3 step:2976 [D loss: 0.466274, acc.: 79.69%] [G loss: 0.648954]\n",
      "epoch:3 step:2977 [D loss: 0.500232, acc.: 76.56%] [G loss: 0.616660]\n",
      "epoch:3 step:2978 [D loss: 0.533745, acc.: 74.22%] [G loss: 0.474669]\n",
      "epoch:3 step:2979 [D loss: 0.481506, acc.: 77.34%] [G loss: 0.496984]\n",
      "epoch:3 step:2980 [D loss: 0.493981, acc.: 78.12%] [G loss: 0.416274]\n",
      "epoch:3 step:2981 [D loss: 0.503058, acc.: 72.66%] [G loss: 0.519449]\n",
      "epoch:3 step:2982 [D loss: 0.409841, acc.: 84.38%] [G loss: 0.659638]\n",
      "epoch:3 step:2983 [D loss: 0.475600, acc.: 82.81%] [G loss: 0.600366]\n",
      "epoch:3 step:2984 [D loss: 0.434737, acc.: 82.03%] [G loss: 0.684689]\n",
      "epoch:3 step:2985 [D loss: 0.545232, acc.: 72.66%] [G loss: 0.505469]\n",
      "epoch:3 step:2986 [D loss: 0.455019, acc.: 80.47%] [G loss: 0.529955]\n",
      "epoch:3 step:2987 [D loss: 0.488376, acc.: 79.69%] [G loss: 0.590796]\n",
      "epoch:3 step:2988 [D loss: 0.502555, acc.: 79.69%] [G loss: 0.669975]\n",
      "epoch:3 step:2989 [D loss: 0.460657, acc.: 75.00%] [G loss: 0.648493]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2990 [D loss: 0.511277, acc.: 77.34%] [G loss: 0.617474]\n",
      "epoch:3 step:2991 [D loss: 0.558976, acc.: 70.31%] [G loss: 0.570903]\n",
      "epoch:3 step:2992 [D loss: 0.509507, acc.: 74.22%] [G loss: 0.539060]\n",
      "epoch:3 step:2993 [D loss: 0.496192, acc.: 78.12%] [G loss: 0.467143]\n",
      "epoch:3 step:2994 [D loss: 0.569633, acc.: 65.62%] [G loss: 0.532827]\n",
      "epoch:3 step:2995 [D loss: 0.526623, acc.: 75.00%] [G loss: 0.552173]\n",
      "epoch:3 step:2996 [D loss: 0.592478, acc.: 67.97%] [G loss: 0.416408]\n",
      "epoch:3 step:2997 [D loss: 0.559149, acc.: 74.22%] [G loss: 0.507093]\n",
      "epoch:3 step:2998 [D loss: 0.561608, acc.: 68.75%] [G loss: 0.471743]\n",
      "epoch:3 step:2999 [D loss: 0.504321, acc.: 77.34%] [G loss: 0.451503]\n",
      "epoch:3 step:3000 [D loss: 0.506876, acc.: 77.34%] [G loss: 0.485860]\n",
      "##############\n",
      "[4.0164611  2.1612637  7.52476843 5.72143771 4.91107023 6.83958964\n",
      " 5.89380426 5.76340327 5.99060227 4.3471223 ]\n",
      "##########\n",
      "epoch:3 step:3001 [D loss: 0.452636, acc.: 82.81%] [G loss: 0.582447]\n",
      "epoch:3 step:3002 [D loss: 0.470272, acc.: 82.81%] [G loss: 0.518438]\n",
      "epoch:3 step:3003 [D loss: 0.519674, acc.: 72.66%] [G loss: 0.497845]\n",
      "epoch:3 step:3004 [D loss: 0.522472, acc.: 79.69%] [G loss: 0.542728]\n",
      "epoch:3 step:3005 [D loss: 0.492744, acc.: 75.78%] [G loss: 0.587248]\n",
      "epoch:3 step:3006 [D loss: 0.524549, acc.: 74.22%] [G loss: 0.516103]\n",
      "epoch:3 step:3007 [D loss: 0.524997, acc.: 74.22%] [G loss: 0.617911]\n",
      "epoch:3 step:3008 [D loss: 0.481886, acc.: 77.34%] [G loss: 0.471978]\n",
      "epoch:3 step:3009 [D loss: 0.426992, acc.: 84.38%] [G loss: 0.789582]\n",
      "epoch:3 step:3010 [D loss: 0.473726, acc.: 78.12%] [G loss: 0.732881]\n",
      "epoch:3 step:3011 [D loss: 0.581146, acc.: 69.53%] [G loss: 0.528957]\n",
      "epoch:3 step:3012 [D loss: 0.544333, acc.: 69.53%] [G loss: 0.542169]\n",
      "epoch:3 step:3013 [D loss: 0.511494, acc.: 78.91%] [G loss: 0.517094]\n",
      "epoch:3 step:3014 [D loss: 0.567621, acc.: 67.97%] [G loss: 0.474181]\n",
      "epoch:3 step:3015 [D loss: 0.489023, acc.: 76.56%] [G loss: 0.490530]\n",
      "epoch:3 step:3016 [D loss: 0.534969, acc.: 75.78%] [G loss: 0.639619]\n",
      "epoch:3 step:3017 [D loss: 0.489090, acc.: 75.78%] [G loss: 0.586858]\n",
      "epoch:3 step:3018 [D loss: 0.442518, acc.: 79.69%] [G loss: 0.663828]\n",
      "epoch:3 step:3019 [D loss: 0.434266, acc.: 82.03%] [G loss: 0.788412]\n",
      "epoch:3 step:3020 [D loss: 0.479137, acc.: 77.34%] [G loss: 0.749053]\n",
      "epoch:3 step:3021 [D loss: 0.578508, acc.: 69.53%] [G loss: 0.447241]\n",
      "epoch:3 step:3022 [D loss: 0.541991, acc.: 71.09%] [G loss: 0.482251]\n",
      "epoch:3 step:3023 [D loss: 0.453701, acc.: 82.81%] [G loss: 0.478140]\n",
      "epoch:3 step:3024 [D loss: 0.510630, acc.: 76.56%] [G loss: 0.565931]\n",
      "epoch:3 step:3025 [D loss: 0.588550, acc.: 69.53%] [G loss: 0.505145]\n",
      "epoch:3 step:3026 [D loss: 0.539800, acc.: 73.44%] [G loss: 0.518648]\n",
      "epoch:3 step:3027 [D loss: 0.527776, acc.: 70.31%] [G loss: 0.479349]\n",
      "epoch:3 step:3028 [D loss: 0.449013, acc.: 80.47%] [G loss: 0.525648]\n",
      "epoch:3 step:3029 [D loss: 0.487387, acc.: 78.91%] [G loss: 0.514889]\n",
      "epoch:3 step:3030 [D loss: 0.524745, acc.: 74.22%] [G loss: 0.446394]\n",
      "epoch:3 step:3031 [D loss: 0.521969, acc.: 77.34%] [G loss: 0.466397]\n",
      "epoch:3 step:3032 [D loss: 0.462889, acc.: 78.91%] [G loss: 0.654449]\n",
      "epoch:3 step:3033 [D loss: 0.438778, acc.: 79.69%] [G loss: 0.797128]\n",
      "epoch:3 step:3034 [D loss: 0.451812, acc.: 82.81%] [G loss: 0.631982]\n",
      "epoch:3 step:3035 [D loss: 0.564700, acc.: 71.88%] [G loss: 0.471487]\n",
      "epoch:3 step:3036 [D loss: 0.563892, acc.: 71.09%] [G loss: 0.535454]\n",
      "epoch:3 step:3037 [D loss: 0.582586, acc.: 66.41%] [G loss: 0.551637]\n",
      "epoch:3 step:3038 [D loss: 0.522139, acc.: 77.34%] [G loss: 0.438816]\n",
      "epoch:3 step:3039 [D loss: 0.537502, acc.: 70.31%] [G loss: 0.411809]\n",
      "epoch:3 step:3040 [D loss: 0.535212, acc.: 78.91%] [G loss: 0.405240]\n",
      "epoch:3 step:3041 [D loss: 0.441895, acc.: 82.03%] [G loss: 0.573124]\n",
      "epoch:3 step:3042 [D loss: 0.440390, acc.: 78.91%] [G loss: 0.647787]\n",
      "epoch:3 step:3043 [D loss: 0.459928, acc.: 77.34%] [G loss: 0.778365]\n",
      "epoch:3 step:3044 [D loss: 0.474491, acc.: 81.25%] [G loss: 0.728236]\n",
      "epoch:3 step:3045 [D loss: 0.522315, acc.: 73.44%] [G loss: 0.510737]\n",
      "epoch:3 step:3046 [D loss: 0.513140, acc.: 74.22%] [G loss: 0.470193]\n",
      "epoch:3 step:3047 [D loss: 0.491090, acc.: 74.22%] [G loss: 0.586593]\n",
      "epoch:3 step:3048 [D loss: 0.489885, acc.: 79.69%] [G loss: 0.546322]\n",
      "epoch:3 step:3049 [D loss: 0.507117, acc.: 75.78%] [G loss: 0.546640]\n",
      "epoch:3 step:3050 [D loss: 0.522586, acc.: 75.78%] [G loss: 0.432960]\n",
      "epoch:3 step:3051 [D loss: 0.455630, acc.: 84.38%] [G loss: 0.585864]\n",
      "epoch:3 step:3052 [D loss: 0.524391, acc.: 77.34%] [G loss: 0.528475]\n",
      "epoch:3 step:3053 [D loss: 0.513529, acc.: 75.00%] [G loss: 0.409177]\n",
      "epoch:3 step:3054 [D loss: 0.466654, acc.: 79.69%] [G loss: 0.626843]\n",
      "epoch:3 step:3055 [D loss: 0.490996, acc.: 79.69%] [G loss: 0.546926]\n",
      "epoch:3 step:3056 [D loss: 0.446931, acc.: 84.38%] [G loss: 0.551963]\n",
      "epoch:3 step:3057 [D loss: 0.509134, acc.: 73.44%] [G loss: 0.530383]\n",
      "epoch:3 step:3058 [D loss: 0.560915, acc.: 70.31%] [G loss: 0.503617]\n",
      "epoch:3 step:3059 [D loss: 0.520895, acc.: 75.00%] [G loss: 0.511149]\n",
      "epoch:3 step:3060 [D loss: 0.506408, acc.: 73.44%] [G loss: 0.478894]\n",
      "epoch:3 step:3061 [D loss: 0.559080, acc.: 68.75%] [G loss: 0.648259]\n",
      "epoch:3 step:3062 [D loss: 0.534127, acc.: 73.44%] [G loss: 0.478689]\n",
      "epoch:3 step:3063 [D loss: 0.577620, acc.: 68.75%] [G loss: 0.405072]\n",
      "epoch:3 step:3064 [D loss: 0.451814, acc.: 82.81%] [G loss: 0.538812]\n",
      "epoch:3 step:3065 [D loss: 0.477764, acc.: 81.25%] [G loss: 0.554699]\n",
      "epoch:3 step:3066 [D loss: 0.466574, acc.: 82.81%] [G loss: 0.492519]\n",
      "epoch:3 step:3067 [D loss: 0.461790, acc.: 78.91%] [G loss: 0.594841]\n",
      "epoch:3 step:3068 [D loss: 0.516536, acc.: 75.00%] [G loss: 0.535685]\n",
      "epoch:3 step:3069 [D loss: 0.442483, acc.: 80.47%] [G loss: 0.527833]\n",
      "epoch:3 step:3070 [D loss: 0.506425, acc.: 73.44%] [G loss: 0.681360]\n",
      "epoch:3 step:3071 [D loss: 0.503650, acc.: 73.44%] [G loss: 0.652197]\n",
      "epoch:3 step:3072 [D loss: 0.485134, acc.: 77.34%] [G loss: 0.605151]\n",
      "epoch:3 step:3073 [D loss: 0.494368, acc.: 77.34%] [G loss: 0.630893]\n",
      "epoch:3 step:3074 [D loss: 0.562886, acc.: 72.66%] [G loss: 0.454106]\n",
      "epoch:3 step:3075 [D loss: 0.425184, acc.: 86.72%] [G loss: 0.611647]\n",
      "epoch:3 step:3076 [D loss: 0.615116, acc.: 65.62%] [G loss: 0.447782]\n",
      "epoch:3 step:3077 [D loss: 0.504914, acc.: 79.69%] [G loss: 0.560319]\n",
      "epoch:3 step:3078 [D loss: 0.516639, acc.: 73.44%] [G loss: 0.552797]\n",
      "epoch:3 step:3079 [D loss: 0.455880, acc.: 79.69%] [G loss: 0.614046]\n",
      "epoch:3 step:3080 [D loss: 0.520231, acc.: 79.69%] [G loss: 0.589326]\n",
      "epoch:3 step:3081 [D loss: 0.516548, acc.: 75.00%] [G loss: 0.490045]\n",
      "epoch:3 step:3082 [D loss: 0.474807, acc.: 78.91%] [G loss: 0.518577]\n",
      "epoch:3 step:3083 [D loss: 0.492113, acc.: 77.34%] [G loss: 0.586438]\n",
      "epoch:3 step:3084 [D loss: 0.497153, acc.: 71.09%] [G loss: 0.550398]\n",
      "epoch:3 step:3085 [D loss: 0.506853, acc.: 71.88%] [G loss: 0.630918]\n",
      "epoch:3 step:3086 [D loss: 0.610652, acc.: 63.28%] [G loss: 0.457467]\n",
      "epoch:3 step:3087 [D loss: 0.532878, acc.: 75.00%] [G loss: 0.495864]\n",
      "epoch:3 step:3088 [D loss: 0.597805, acc.: 64.06%] [G loss: 0.445020]\n",
      "epoch:3 step:3089 [D loss: 0.531049, acc.: 70.31%] [G loss: 0.682180]\n",
      "epoch:3 step:3090 [D loss: 0.523109, acc.: 73.44%] [G loss: 0.665960]\n",
      "epoch:3 step:3091 [D loss: 0.530005, acc.: 77.34%] [G loss: 0.538501]\n",
      "epoch:3 step:3092 [D loss: 0.568265, acc.: 70.31%] [G loss: 0.396496]\n",
      "epoch:3 step:3093 [D loss: 0.504692, acc.: 75.78%] [G loss: 0.518857]\n",
      "epoch:3 step:3094 [D loss: 0.518835, acc.: 78.91%] [G loss: 0.521209]\n",
      "epoch:3 step:3095 [D loss: 0.472552, acc.: 80.47%] [G loss: 0.525240]\n",
      "epoch:3 step:3096 [D loss: 0.481056, acc.: 73.44%] [G loss: 0.572485]\n",
      "epoch:3 step:3097 [D loss: 0.424351, acc.: 86.72%] [G loss: 0.706419]\n",
      "epoch:3 step:3098 [D loss: 0.525105, acc.: 72.66%] [G loss: 0.491427]\n",
      "epoch:3 step:3099 [D loss: 0.550696, acc.: 76.56%] [G loss: 0.496598]\n",
      "epoch:3 step:3100 [D loss: 0.506070, acc.: 76.56%] [G loss: 0.538651]\n",
      "epoch:3 step:3101 [D loss: 0.444539, acc.: 82.03%] [G loss: 0.594716]\n",
      "epoch:3 step:3102 [D loss: 0.523673, acc.: 73.44%] [G loss: 0.688928]\n",
      "epoch:3 step:3103 [D loss: 0.540593, acc.: 67.97%] [G loss: 0.550675]\n",
      "epoch:3 step:3104 [D loss: 0.485046, acc.: 78.12%] [G loss: 0.441727]\n",
      "epoch:3 step:3105 [D loss: 0.461202, acc.: 85.16%] [G loss: 0.491173]\n",
      "epoch:3 step:3106 [D loss: 0.479631, acc.: 80.47%] [G loss: 0.479606]\n",
      "epoch:3 step:3107 [D loss: 0.428705, acc.: 85.94%] [G loss: 0.567318]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3108 [D loss: 0.512119, acc.: 75.00%] [G loss: 0.402017]\n",
      "epoch:3 step:3109 [D loss: 0.515705, acc.: 78.91%] [G loss: 0.483293]\n",
      "epoch:3 step:3110 [D loss: 0.494765, acc.: 75.78%] [G loss: 0.571332]\n",
      "epoch:3 step:3111 [D loss: 0.471135, acc.: 79.69%] [G loss: 0.605588]\n",
      "epoch:3 step:3112 [D loss: 0.538057, acc.: 73.44%] [G loss: 0.594968]\n",
      "epoch:3 step:3113 [D loss: 0.500533, acc.: 79.69%] [G loss: 0.513497]\n",
      "epoch:3 step:3114 [D loss: 0.476793, acc.: 81.25%] [G loss: 0.550842]\n",
      "epoch:3 step:3115 [D loss: 0.495077, acc.: 77.34%] [G loss: 0.618140]\n",
      "epoch:3 step:3116 [D loss: 0.472168, acc.: 80.47%] [G loss: 0.662321]\n",
      "epoch:3 step:3117 [D loss: 0.503325, acc.: 77.34%] [G loss: 0.580265]\n",
      "epoch:3 step:3118 [D loss: 0.502919, acc.: 78.91%] [G loss: 0.508136]\n",
      "epoch:3 step:3119 [D loss: 0.435790, acc.: 85.16%] [G loss: 0.700380]\n",
      "epoch:3 step:3120 [D loss: 0.456265, acc.: 83.59%] [G loss: 0.719970]\n",
      "epoch:3 step:3121 [D loss: 0.475331, acc.: 80.47%] [G loss: 0.607716]\n",
      "epoch:3 step:3122 [D loss: 0.439498, acc.: 76.56%] [G loss: 0.642387]\n",
      "epoch:3 step:3123 [D loss: 0.388353, acc.: 85.16%] [G loss: 0.882266]\n",
      "epoch:3 step:3124 [D loss: 0.408905, acc.: 84.38%] [G loss: 0.912278]\n",
      "epoch:3 step:3125 [D loss: 0.408184, acc.: 83.59%] [G loss: 0.966625]\n",
      "epoch:3 step:3126 [D loss: 0.406989, acc.: 82.03%] [G loss: 0.885681]\n",
      "epoch:3 step:3127 [D loss: 0.671011, acc.: 64.84%] [G loss: 0.503750]\n",
      "epoch:3 step:3128 [D loss: 0.546381, acc.: 72.66%] [G loss: 0.405300]\n",
      "epoch:3 step:3129 [D loss: 0.496866, acc.: 77.34%] [G loss: 0.567942]\n",
      "epoch:3 step:3130 [D loss: 0.531790, acc.: 71.88%] [G loss: 0.543848]\n",
      "epoch:3 step:3131 [D loss: 0.471212, acc.: 82.03%] [G loss: 0.637161]\n",
      "epoch:3 step:3132 [D loss: 0.432415, acc.: 81.25%] [G loss: 0.613691]\n",
      "epoch:3 step:3133 [D loss: 0.478493, acc.: 78.91%] [G loss: 0.516620]\n",
      "epoch:3 step:3134 [D loss: 0.515843, acc.: 75.78%] [G loss: 0.480849]\n",
      "epoch:3 step:3135 [D loss: 0.495446, acc.: 78.12%] [G loss: 0.370216]\n",
      "epoch:3 step:3136 [D loss: 0.490239, acc.: 78.12%] [G loss: 0.531715]\n",
      "epoch:3 step:3137 [D loss: 0.494177, acc.: 75.78%] [G loss: 0.617890]\n",
      "epoch:3 step:3138 [D loss: 0.501083, acc.: 76.56%] [G loss: 0.633596]\n",
      "epoch:3 step:3139 [D loss: 0.479827, acc.: 75.78%] [G loss: 0.667046]\n",
      "epoch:3 step:3140 [D loss: 0.499148, acc.: 77.34%] [G loss: 0.568592]\n",
      "epoch:3 step:3141 [D loss: 0.473040, acc.: 75.00%] [G loss: 0.606541]\n",
      "epoch:3 step:3142 [D loss: 0.486350, acc.: 81.25%] [G loss: 0.588773]\n",
      "epoch:3 step:3143 [D loss: 0.444325, acc.: 84.38%] [G loss: 0.582116]\n",
      "epoch:3 step:3144 [D loss: 0.433568, acc.: 82.03%] [G loss: 0.554644]\n",
      "epoch:3 step:3145 [D loss: 0.460649, acc.: 81.25%] [G loss: 0.605717]\n",
      "epoch:3 step:3146 [D loss: 0.462985, acc.: 78.12%] [G loss: 0.717539]\n",
      "epoch:3 step:3147 [D loss: 0.442975, acc.: 82.81%] [G loss: 0.768485]\n",
      "epoch:3 step:3148 [D loss: 0.440273, acc.: 78.91%] [G loss: 0.761784]\n",
      "epoch:3 step:3149 [D loss: 0.505609, acc.: 75.00%] [G loss: 0.569292]\n",
      "epoch:3 step:3150 [D loss: 0.467575, acc.: 81.25%] [G loss: 0.581753]\n",
      "epoch:3 step:3151 [D loss: 0.456311, acc.: 82.03%] [G loss: 0.630824]\n",
      "epoch:3 step:3152 [D loss: 0.532259, acc.: 75.78%] [G loss: 0.417426]\n",
      "epoch:3 step:3153 [D loss: 0.563203, acc.: 71.88%] [G loss: 0.439882]\n",
      "epoch:3 step:3154 [D loss: 0.427951, acc.: 83.59%] [G loss: 0.700457]\n",
      "epoch:3 step:3155 [D loss: 0.498578, acc.: 75.00%] [G loss: 0.704261]\n",
      "epoch:3 step:3156 [D loss: 0.428155, acc.: 84.38%] [G loss: 0.758441]\n",
      "epoch:3 step:3157 [D loss: 0.447086, acc.: 77.34%] [G loss: 0.822184]\n",
      "epoch:3 step:3158 [D loss: 0.425290, acc.: 79.69%] [G loss: 0.921036]\n",
      "epoch:3 step:3159 [D loss: 0.564693, acc.: 72.66%] [G loss: 0.686700]\n",
      "epoch:3 step:3160 [D loss: 0.644160, acc.: 67.19%] [G loss: 0.489746]\n",
      "epoch:3 step:3161 [D loss: 0.421324, acc.: 83.59%] [G loss: 0.533343]\n",
      "epoch:3 step:3162 [D loss: 0.489007, acc.: 75.78%] [G loss: 0.599166]\n",
      "epoch:3 step:3163 [D loss: 0.577190, acc.: 69.53%] [G loss: 0.638805]\n",
      "epoch:3 step:3164 [D loss: 0.508426, acc.: 73.44%] [G loss: 0.515142]\n",
      "epoch:3 step:3165 [D loss: 0.480170, acc.: 77.34%] [G loss: 0.554301]\n",
      "epoch:3 step:3166 [D loss: 0.514449, acc.: 73.44%] [G loss: 0.518934]\n",
      "epoch:3 step:3167 [D loss: 0.494640, acc.: 73.44%] [G loss: 0.471937]\n",
      "epoch:3 step:3168 [D loss: 0.466710, acc.: 81.25%] [G loss: 0.737557]\n",
      "epoch:3 step:3169 [D loss: 0.418787, acc.: 80.47%] [G loss: 0.606478]\n",
      "epoch:3 step:3170 [D loss: 0.501213, acc.: 78.12%] [G loss: 0.721166]\n",
      "epoch:3 step:3171 [D loss: 0.448789, acc.: 86.72%] [G loss: 0.595377]\n",
      "epoch:3 step:3172 [D loss: 0.493826, acc.: 78.91%] [G loss: 0.602902]\n",
      "epoch:3 step:3173 [D loss: 0.499565, acc.: 74.22%] [G loss: 0.589326]\n",
      "epoch:3 step:3174 [D loss: 0.481289, acc.: 78.91%] [G loss: 0.573885]\n",
      "epoch:3 step:3175 [D loss: 0.408500, acc.: 89.84%] [G loss: 0.489537]\n",
      "epoch:3 step:3176 [D loss: 0.472411, acc.: 77.34%] [G loss: 0.596388]\n",
      "epoch:3 step:3177 [D loss: 0.453740, acc.: 78.12%] [G loss: 0.689772]\n",
      "epoch:3 step:3178 [D loss: 0.479241, acc.: 75.00%] [G loss: 0.870902]\n",
      "epoch:3 step:3179 [D loss: 0.479259, acc.: 78.12%] [G loss: 0.615053]\n",
      "epoch:3 step:3180 [D loss: 0.493607, acc.: 82.03%] [G loss: 0.556029]\n",
      "epoch:3 step:3181 [D loss: 0.560569, acc.: 68.75%] [G loss: 0.503081]\n",
      "epoch:3 step:3182 [D loss: 0.506373, acc.: 73.44%] [G loss: 0.560631]\n",
      "epoch:3 step:3183 [D loss: 0.477548, acc.: 81.25%] [G loss: 0.539083]\n",
      "epoch:3 step:3184 [D loss: 0.586628, acc.: 71.88%] [G loss: 0.609460]\n",
      "epoch:3 step:3185 [D loss: 0.488817, acc.: 77.34%] [G loss: 0.675554]\n",
      "epoch:3 step:3186 [D loss: 0.538287, acc.: 75.00%] [G loss: 0.546290]\n",
      "epoch:3 step:3187 [D loss: 0.620676, acc.: 65.62%] [G loss: 0.475656]\n",
      "epoch:3 step:3188 [D loss: 0.568672, acc.: 68.75%] [G loss: 0.422767]\n",
      "epoch:3 step:3189 [D loss: 0.465719, acc.: 82.03%] [G loss: 0.511669]\n",
      "epoch:3 step:3190 [D loss: 0.506134, acc.: 75.78%] [G loss: 0.470920]\n",
      "epoch:3 step:3191 [D loss: 0.504600, acc.: 78.91%] [G loss: 0.522284]\n",
      "epoch:3 step:3192 [D loss: 0.471791, acc.: 78.91%] [G loss: 0.612486]\n",
      "epoch:3 step:3193 [D loss: 0.493885, acc.: 76.56%] [G loss: 0.610261]\n",
      "epoch:3 step:3194 [D loss: 0.530756, acc.: 75.00%] [G loss: 0.639383]\n",
      "epoch:3 step:3195 [D loss: 0.470691, acc.: 80.47%] [G loss: 0.625939]\n",
      "epoch:3 step:3196 [D loss: 0.512051, acc.: 75.00%] [G loss: 0.612149]\n",
      "epoch:3 step:3197 [D loss: 0.537570, acc.: 76.56%] [G loss: 0.479853]\n",
      "epoch:3 step:3198 [D loss: 0.512745, acc.: 74.22%] [G loss: 0.650997]\n",
      "epoch:3 step:3199 [D loss: 0.459243, acc.: 80.47%] [G loss: 0.783987]\n",
      "epoch:3 step:3200 [D loss: 0.584035, acc.: 69.53%] [G loss: 0.453711]\n",
      "##############\n",
      "[3.9599307  2.16192336 7.47323326 5.69481523 4.88788729 6.93344434\n",
      " 6.22961664 5.77730382 6.0240959  4.28405802]\n",
      "##########\n",
      "epoch:3 step:3201 [D loss: 0.567890, acc.: 71.88%] [G loss: 0.424677]\n",
      "epoch:3 step:3202 [D loss: 0.456729, acc.: 80.47%] [G loss: 0.539396]\n",
      "epoch:3 step:3203 [D loss: 0.467728, acc.: 80.47%] [G loss: 0.578321]\n",
      "epoch:3 step:3204 [D loss: 0.501578, acc.: 80.47%] [G loss: 0.629232]\n",
      "epoch:3 step:3205 [D loss: 0.506473, acc.: 76.56%] [G loss: 0.584681]\n",
      "epoch:3 step:3206 [D loss: 0.479167, acc.: 79.69%] [G loss: 0.604314]\n",
      "epoch:3 step:3207 [D loss: 0.615034, acc.: 64.84%] [G loss: 0.576345]\n",
      "epoch:3 step:3208 [D loss: 0.471228, acc.: 78.91%] [G loss: 0.634414]\n",
      "epoch:3 step:3209 [D loss: 0.391583, acc.: 82.81%] [G loss: 0.798629]\n",
      "epoch:3 step:3210 [D loss: 0.437158, acc.: 79.69%] [G loss: 0.756762]\n",
      "epoch:3 step:3211 [D loss: 0.570122, acc.: 70.31%] [G loss: 0.616415]\n",
      "epoch:3 step:3212 [D loss: 0.540330, acc.: 74.22%] [G loss: 0.464131]\n",
      "epoch:3 step:3213 [D loss: 0.448373, acc.: 82.03%] [G loss: 0.523469]\n",
      "epoch:3 step:3214 [D loss: 0.528481, acc.: 71.88%] [G loss: 0.604890]\n",
      "epoch:3 step:3215 [D loss: 0.558702, acc.: 71.09%] [G loss: 0.591621]\n",
      "epoch:3 step:3216 [D loss: 0.483949, acc.: 75.78%] [G loss: 0.627431]\n",
      "epoch:3 step:3217 [D loss: 0.497676, acc.: 72.66%] [G loss: 0.553580]\n",
      "epoch:3 step:3218 [D loss: 0.480603, acc.: 78.91%] [G loss: 0.693561]\n",
      "epoch:3 step:3219 [D loss: 0.512450, acc.: 77.34%] [G loss: 0.757464]\n",
      "epoch:3 step:3220 [D loss: 0.437161, acc.: 83.59%] [G loss: 0.738207]\n",
      "epoch:3 step:3221 [D loss: 0.554759, acc.: 72.66%] [G loss: 0.490539]\n",
      "epoch:3 step:3222 [D loss: 0.542558, acc.: 71.09%] [G loss: 0.497330]\n",
      "epoch:3 step:3223 [D loss: 0.515915, acc.: 76.56%] [G loss: 0.480648]\n",
      "epoch:3 step:3224 [D loss: 0.505142, acc.: 82.81%] [G loss: 0.549588]\n",
      "epoch:3 step:3225 [D loss: 0.517394, acc.: 78.12%] [G loss: 0.569853]\n",
      "epoch:3 step:3226 [D loss: 0.522779, acc.: 78.12%] [G loss: 0.450613]\n",
      "epoch:3 step:3227 [D loss: 0.480413, acc.: 80.47%] [G loss: 0.526083]\n",
      "epoch:3 step:3228 [D loss: 0.626595, acc.: 60.94%] [G loss: 0.460609]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3229 [D loss: 0.490909, acc.: 74.22%] [G loss: 0.597959]\n",
      "epoch:3 step:3230 [D loss: 0.499213, acc.: 75.78%] [G loss: 0.527556]\n",
      "epoch:3 step:3231 [D loss: 0.561877, acc.: 65.62%] [G loss: 0.577844]\n",
      "epoch:3 step:3232 [D loss: 0.528684, acc.: 74.22%] [G loss: 0.679647]\n",
      "epoch:3 step:3233 [D loss: 0.503530, acc.: 76.56%] [G loss: 0.559348]\n",
      "epoch:3 step:3234 [D loss: 0.513010, acc.: 74.22%] [G loss: 0.721997]\n",
      "epoch:3 step:3235 [D loss: 0.506396, acc.: 73.44%] [G loss: 0.648297]\n",
      "epoch:3 step:3236 [D loss: 0.478730, acc.: 78.12%] [G loss: 0.703855]\n",
      "epoch:3 step:3237 [D loss: 0.465416, acc.: 82.03%] [G loss: 0.776164]\n",
      "epoch:3 step:3238 [D loss: 0.457943, acc.: 80.47%] [G loss: 0.788287]\n",
      "epoch:3 step:3239 [D loss: 0.402525, acc.: 85.16%] [G loss: 0.729290]\n",
      "epoch:3 step:3240 [D loss: 0.426781, acc.: 84.38%] [G loss: 0.675447]\n",
      "epoch:3 step:3241 [D loss: 0.447372, acc.: 79.69%] [G loss: 0.651568]\n",
      "epoch:3 step:3242 [D loss: 0.469155, acc.: 78.91%] [G loss: 0.750355]\n",
      "epoch:3 step:3243 [D loss: 0.597178, acc.: 64.84%] [G loss: 0.562941]\n",
      "epoch:3 step:3244 [D loss: 0.503715, acc.: 79.69%] [G loss: 0.600333]\n",
      "epoch:3 step:3245 [D loss: 0.542417, acc.: 78.12%] [G loss: 0.420016]\n",
      "epoch:3 step:3246 [D loss: 0.521784, acc.: 78.12%] [G loss: 0.528263]\n",
      "epoch:3 step:3247 [D loss: 0.522210, acc.: 73.44%] [G loss: 0.667338]\n",
      "epoch:3 step:3248 [D loss: 0.597038, acc.: 71.88%] [G loss: 0.440852]\n",
      "epoch:3 step:3249 [D loss: 0.470772, acc.: 80.47%] [G loss: 0.448108]\n",
      "epoch:3 step:3250 [D loss: 0.525462, acc.: 75.78%] [G loss: 0.519261]\n",
      "epoch:3 step:3251 [D loss: 0.464042, acc.: 82.81%] [G loss: 0.576189]\n",
      "epoch:3 step:3252 [D loss: 0.546724, acc.: 70.31%] [G loss: 0.617338]\n",
      "epoch:3 step:3253 [D loss: 0.533237, acc.: 74.22%] [G loss: 0.487201]\n",
      "epoch:3 step:3254 [D loss: 0.455884, acc.: 81.25%] [G loss: 0.618600]\n",
      "epoch:3 step:3255 [D loss: 0.479073, acc.: 79.69%] [G loss: 0.573120]\n",
      "epoch:3 step:3256 [D loss: 0.518737, acc.: 73.44%] [G loss: 0.505843]\n",
      "epoch:3 step:3257 [D loss: 0.497660, acc.: 77.34%] [G loss: 0.618655]\n",
      "epoch:3 step:3258 [D loss: 0.510011, acc.: 71.88%] [G loss: 0.688167]\n",
      "epoch:3 step:3259 [D loss: 0.485882, acc.: 78.91%] [G loss: 0.609183]\n",
      "epoch:3 step:3260 [D loss: 0.542638, acc.: 69.53%] [G loss: 0.607457]\n",
      "epoch:3 step:3261 [D loss: 0.473725, acc.: 78.12%] [G loss: 0.642841]\n",
      "epoch:3 step:3262 [D loss: 0.398198, acc.: 85.16%] [G loss: 0.769288]\n",
      "epoch:3 step:3263 [D loss: 0.471719, acc.: 78.91%] [G loss: 0.797223]\n",
      "epoch:3 step:3264 [D loss: 0.449808, acc.: 79.69%] [G loss: 0.751706]\n",
      "epoch:3 step:3265 [D loss: 0.542011, acc.: 74.22%] [G loss: 0.498602]\n",
      "epoch:3 step:3266 [D loss: 0.576898, acc.: 70.31%] [G loss: 0.479847]\n",
      "epoch:3 step:3267 [D loss: 0.574347, acc.: 72.66%] [G loss: 0.553764]\n",
      "epoch:3 step:3268 [D loss: 0.475224, acc.: 77.34%] [G loss: 0.631866]\n",
      "epoch:3 step:3269 [D loss: 0.578631, acc.: 71.09%] [G loss: 0.583388]\n",
      "epoch:3 step:3270 [D loss: 0.545319, acc.: 74.22%] [G loss: 0.526711]\n",
      "epoch:3 step:3271 [D loss: 0.500444, acc.: 77.34%] [G loss: 0.552367]\n",
      "epoch:3 step:3272 [D loss: 0.465793, acc.: 84.38%] [G loss: 0.522474]\n",
      "epoch:3 step:3273 [D loss: 0.459700, acc.: 82.03%] [G loss: 0.613700]\n",
      "epoch:3 step:3274 [D loss: 0.546977, acc.: 71.88%] [G loss: 0.495977]\n",
      "epoch:3 step:3275 [D loss: 0.474894, acc.: 83.59%] [G loss: 0.503886]\n",
      "epoch:3 step:3276 [D loss: 0.598605, acc.: 66.41%] [G loss: 0.427315]\n",
      "epoch:3 step:3277 [D loss: 0.488313, acc.: 78.12%] [G loss: 0.539908]\n",
      "epoch:3 step:3278 [D loss: 0.550185, acc.: 75.00%] [G loss: 0.618433]\n",
      "epoch:3 step:3279 [D loss: 0.499926, acc.: 74.22%] [G loss: 0.652617]\n",
      "epoch:3 step:3280 [D loss: 0.508240, acc.: 78.12%] [G loss: 0.468014]\n",
      "epoch:3 step:3281 [D loss: 0.528875, acc.: 75.00%] [G loss: 0.484311]\n",
      "epoch:3 step:3282 [D loss: 0.510030, acc.: 78.12%] [G loss: 0.532414]\n",
      "epoch:3 step:3283 [D loss: 0.469157, acc.: 78.91%] [G loss: 0.717527]\n",
      "epoch:3 step:3284 [D loss: 0.580521, acc.: 74.22%] [G loss: 0.476829]\n",
      "epoch:3 step:3285 [D loss: 0.469377, acc.: 75.78%] [G loss: 0.591372]\n",
      "epoch:3 step:3286 [D loss: 0.436201, acc.: 85.16%] [G loss: 0.798011]\n",
      "epoch:3 step:3287 [D loss: 0.563643, acc.: 68.75%] [G loss: 0.590928]\n",
      "epoch:3 step:3288 [D loss: 0.625147, acc.: 66.41%] [G loss: 0.402357]\n",
      "epoch:3 step:3289 [D loss: 0.509188, acc.: 79.69%] [G loss: 0.398316]\n",
      "epoch:3 step:3290 [D loss: 0.499701, acc.: 80.47%] [G loss: 0.538478]\n",
      "epoch:3 step:3291 [D loss: 0.504555, acc.: 76.56%] [G loss: 0.492962]\n",
      "epoch:3 step:3292 [D loss: 0.473626, acc.: 82.81%] [G loss: 0.628096]\n",
      "epoch:3 step:3293 [D loss: 0.595618, acc.: 67.97%] [G loss: 0.517850]\n",
      "epoch:3 step:3294 [D loss: 0.577175, acc.: 64.84%] [G loss: 0.549436]\n",
      "epoch:3 step:3295 [D loss: 0.506238, acc.: 77.34%] [G loss: 0.667011]\n",
      "epoch:3 step:3296 [D loss: 0.528304, acc.: 74.22%] [G loss: 0.613434]\n",
      "epoch:3 step:3297 [D loss: 0.521935, acc.: 78.12%] [G loss: 0.579607]\n",
      "epoch:3 step:3298 [D loss: 0.448926, acc.: 81.25%] [G loss: 0.612645]\n",
      "epoch:3 step:3299 [D loss: 0.460354, acc.: 83.59%] [G loss: 0.558558]\n",
      "epoch:3 step:3300 [D loss: 0.586910, acc.: 69.53%] [G loss: 0.546564]\n",
      "epoch:3 step:3301 [D loss: 0.521170, acc.: 76.56%] [G loss: 0.583388]\n",
      "epoch:3 step:3302 [D loss: 0.505416, acc.: 76.56%] [G loss: 0.704366]\n",
      "epoch:3 step:3303 [D loss: 0.537058, acc.: 74.22%] [G loss: 0.595917]\n",
      "epoch:3 step:3304 [D loss: 0.560542, acc.: 74.22%] [G loss: 0.454200]\n",
      "epoch:3 step:3305 [D loss: 0.502156, acc.: 77.34%] [G loss: 0.582943]\n",
      "epoch:3 step:3306 [D loss: 0.483479, acc.: 85.16%] [G loss: 0.458671]\n",
      "epoch:3 step:3307 [D loss: 0.525471, acc.: 72.66%] [G loss: 0.649856]\n",
      "epoch:3 step:3308 [D loss: 0.459133, acc.: 77.34%] [G loss: 0.738490]\n",
      "epoch:3 step:3309 [D loss: 0.415487, acc.: 85.16%] [G loss: 0.757971]\n",
      "epoch:3 step:3310 [D loss: 0.492451, acc.: 75.00%] [G loss: 0.774588]\n",
      "epoch:3 step:3311 [D loss: 0.636222, acc.: 62.50%] [G loss: 0.600617]\n",
      "epoch:3 step:3312 [D loss: 0.576271, acc.: 68.75%] [G loss: 0.492480]\n",
      "epoch:3 step:3313 [D loss: 0.499641, acc.: 78.91%] [G loss: 0.502114]\n",
      "epoch:3 step:3314 [D loss: 0.528162, acc.: 68.75%] [G loss: 0.574963]\n",
      "epoch:3 step:3315 [D loss: 0.457824, acc.: 81.25%] [G loss: 0.658093]\n",
      "epoch:3 step:3316 [D loss: 0.556795, acc.: 72.66%] [G loss: 0.526022]\n",
      "epoch:3 step:3317 [D loss: 0.474592, acc.: 78.91%] [G loss: 0.599895]\n",
      "epoch:3 step:3318 [D loss: 0.507848, acc.: 78.91%] [G loss: 0.639362]\n",
      "epoch:3 step:3319 [D loss: 0.417180, acc.: 80.47%] [G loss: 0.783254]\n",
      "epoch:3 step:3320 [D loss: 0.509717, acc.: 77.34%] [G loss: 0.579656]\n",
      "epoch:3 step:3321 [D loss: 0.503590, acc.: 77.34%] [G loss: 0.582996]\n",
      "epoch:3 step:3322 [D loss: 0.513462, acc.: 79.69%] [G loss: 0.763152]\n",
      "epoch:3 step:3323 [D loss: 0.514285, acc.: 78.91%] [G loss: 0.633785]\n",
      "epoch:3 step:3324 [D loss: 0.479637, acc.: 78.12%] [G loss: 0.644219]\n",
      "epoch:3 step:3325 [D loss: 0.491132, acc.: 83.59%] [G loss: 0.672189]\n",
      "epoch:3 step:3326 [D loss: 0.454938, acc.: 81.25%] [G loss: 0.756735]\n",
      "epoch:3 step:3327 [D loss: 0.463604, acc.: 78.12%] [G loss: 0.630573]\n",
      "epoch:3 step:3328 [D loss: 0.568650, acc.: 71.09%] [G loss: 0.520023]\n",
      "epoch:3 step:3329 [D loss: 0.428210, acc.: 82.81%] [G loss: 0.628206]\n",
      "epoch:3 step:3330 [D loss: 0.533737, acc.: 72.66%] [G loss: 0.523060]\n",
      "epoch:3 step:3331 [D loss: 0.490193, acc.: 73.44%] [G loss: 0.526635]\n",
      "epoch:3 step:3332 [D loss: 0.468428, acc.: 79.69%] [G loss: 0.549625]\n",
      "epoch:3 step:3333 [D loss: 0.502039, acc.: 73.44%] [G loss: 0.570897]\n",
      "epoch:3 step:3334 [D loss: 0.493390, acc.: 80.47%] [G loss: 0.556974]\n",
      "epoch:3 step:3335 [D loss: 0.537040, acc.: 70.31%] [G loss: 0.618870]\n",
      "epoch:3 step:3336 [D loss: 0.544400, acc.: 72.66%] [G loss: 0.544039]\n",
      "epoch:3 step:3337 [D loss: 0.467147, acc.: 78.12%] [G loss: 0.537657]\n",
      "epoch:3 step:3338 [D loss: 0.531227, acc.: 73.44%] [G loss: 0.458291]\n",
      "epoch:3 step:3339 [D loss: 0.536940, acc.: 71.88%] [G loss: 0.541076]\n",
      "epoch:3 step:3340 [D loss: 0.514966, acc.: 77.34%] [G loss: 0.464465]\n",
      "epoch:3 step:3341 [D loss: 0.459955, acc.: 82.03%] [G loss: 0.546020]\n",
      "epoch:3 step:3342 [D loss: 0.526650, acc.: 75.78%] [G loss: 0.559950]\n",
      "epoch:3 step:3343 [D loss: 0.453820, acc.: 84.38%] [G loss: 0.542090]\n",
      "epoch:3 step:3344 [D loss: 0.578398, acc.: 69.53%] [G loss: 0.494154]\n",
      "epoch:3 step:3345 [D loss: 0.430975, acc.: 82.03%] [G loss: 0.674365]\n",
      "epoch:3 step:3346 [D loss: 0.522283, acc.: 71.09%] [G loss: 0.506437]\n",
      "epoch:3 step:3347 [D loss: 0.449626, acc.: 83.59%] [G loss: 0.619366]\n",
      "epoch:3 step:3348 [D loss: 0.506035, acc.: 75.00%] [G loss: 0.620332]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3349 [D loss: 0.538477, acc.: 75.00%] [G loss: 0.547789]\n",
      "epoch:3 step:3350 [D loss: 0.526993, acc.: 72.66%] [G loss: 0.501411]\n",
      "epoch:3 step:3351 [D loss: 0.540128, acc.: 73.44%] [G loss: 0.542131]\n",
      "epoch:3 step:3352 [D loss: 0.485229, acc.: 82.81%] [G loss: 0.602826]\n",
      "epoch:3 step:3353 [D loss: 0.532484, acc.: 75.78%] [G loss: 0.555144]\n",
      "epoch:3 step:3354 [D loss: 0.523452, acc.: 77.34%] [G loss: 0.616058]\n",
      "epoch:3 step:3355 [D loss: 0.492969, acc.: 74.22%] [G loss: 0.611393]\n",
      "epoch:3 step:3356 [D loss: 0.497131, acc.: 78.12%] [G loss: 0.549368]\n",
      "epoch:3 step:3357 [D loss: 0.465759, acc.: 79.69%] [G loss: 0.709370]\n",
      "epoch:3 step:3358 [D loss: 0.498855, acc.: 73.44%] [G loss: 0.722024]\n",
      "epoch:3 step:3359 [D loss: 0.451683, acc.: 78.12%] [G loss: 0.555063]\n",
      "epoch:3 step:3360 [D loss: 0.517588, acc.: 77.34%] [G loss: 0.635429]\n",
      "epoch:3 step:3361 [D loss: 0.503205, acc.: 76.56%] [G loss: 0.626090]\n",
      "epoch:3 step:3362 [D loss: 0.513427, acc.: 77.34%] [G loss: 0.491279]\n",
      "epoch:3 step:3363 [D loss: 0.441586, acc.: 84.38%] [G loss: 0.654713]\n",
      "epoch:3 step:3364 [D loss: 0.510372, acc.: 76.56%] [G loss: 0.568716]\n",
      "epoch:3 step:3365 [D loss: 0.451458, acc.: 76.56%] [G loss: 0.527968]\n",
      "epoch:3 step:3366 [D loss: 0.413316, acc.: 82.81%] [G loss: 0.622122]\n",
      "epoch:3 step:3367 [D loss: 0.423675, acc.: 82.81%] [G loss: 0.702107]\n",
      "epoch:3 step:3368 [D loss: 0.504546, acc.: 75.78%] [G loss: 0.660308]\n",
      "epoch:3 step:3369 [D loss: 0.419142, acc.: 83.59%] [G loss: 0.762144]\n",
      "epoch:3 step:3370 [D loss: 0.511393, acc.: 76.56%] [G loss: 0.726346]\n",
      "epoch:3 step:3371 [D loss: 0.541851, acc.: 75.78%] [G loss: 0.681436]\n",
      "epoch:3 step:3372 [D loss: 0.495065, acc.: 75.00%] [G loss: 0.656042]\n",
      "epoch:3 step:3373 [D loss: 0.560682, acc.: 71.88%] [G loss: 0.600226]\n",
      "epoch:3 step:3374 [D loss: 0.583560, acc.: 67.97%] [G loss: 0.427990]\n",
      "epoch:3 step:3375 [D loss: 0.463902, acc.: 84.38%] [G loss: 0.681375]\n",
      "epoch:3 step:3376 [D loss: 0.528033, acc.: 75.78%] [G loss: 0.580987]\n",
      "epoch:3 step:3377 [D loss: 0.644071, acc.: 66.41%] [G loss: 0.580972]\n",
      "epoch:3 step:3378 [D loss: 0.422022, acc.: 82.81%] [G loss: 0.670807]\n",
      "epoch:3 step:3379 [D loss: 0.543647, acc.: 75.00%] [G loss: 0.558383]\n",
      "epoch:3 step:3380 [D loss: 0.519116, acc.: 73.44%] [G loss: 0.635869]\n",
      "epoch:3 step:3381 [D loss: 0.493737, acc.: 82.03%] [G loss: 0.613536]\n",
      "epoch:3 step:3382 [D loss: 0.505406, acc.: 73.44%] [G loss: 0.632619]\n",
      "epoch:3 step:3383 [D loss: 0.506340, acc.: 74.22%] [G loss: 0.669756]\n",
      "epoch:3 step:3384 [D loss: 0.511886, acc.: 75.78%] [G loss: 0.550751]\n",
      "epoch:3 step:3385 [D loss: 0.434569, acc.: 85.94%] [G loss: 0.634542]\n",
      "epoch:3 step:3386 [D loss: 0.441297, acc.: 81.25%] [G loss: 0.721367]\n",
      "epoch:3 step:3387 [D loss: 0.505749, acc.: 75.00%] [G loss: 0.499434]\n",
      "epoch:3 step:3388 [D loss: 0.524002, acc.: 74.22%] [G loss: 0.554620]\n",
      "epoch:3 step:3389 [D loss: 0.455808, acc.: 82.81%] [G loss: 0.577687]\n",
      "epoch:3 step:3390 [D loss: 0.500350, acc.: 78.12%] [G loss: 0.624533]\n",
      "epoch:3 step:3391 [D loss: 0.494042, acc.: 78.12%] [G loss: 0.625989]\n",
      "epoch:3 step:3392 [D loss: 0.493664, acc.: 75.00%] [G loss: 0.718199]\n",
      "epoch:3 step:3393 [D loss: 0.470579, acc.: 77.34%] [G loss: 0.668980]\n",
      "epoch:3 step:3394 [D loss: 0.543696, acc.: 72.66%] [G loss: 0.579251]\n",
      "epoch:3 step:3395 [D loss: 0.483263, acc.: 78.91%] [G loss: 0.757227]\n",
      "epoch:3 step:3396 [D loss: 0.546007, acc.: 69.53%] [G loss: 0.599507]\n",
      "epoch:3 step:3397 [D loss: 0.544101, acc.: 71.88%] [G loss: 0.564472]\n",
      "epoch:3 step:3398 [D loss: 0.501329, acc.: 75.00%] [G loss: 0.541334]\n",
      "epoch:3 step:3399 [D loss: 0.519202, acc.: 69.53%] [G loss: 0.706464]\n",
      "epoch:3 step:3400 [D loss: 0.485271, acc.: 80.47%] [G loss: 0.927960]\n",
      "##############\n",
      "[3.87260742 1.57046721 7.10100947 5.52086704 4.78491075 6.58018188\n",
      " 5.96507379 5.39848639 5.69171747 4.11079023]\n",
      "##########\n",
      "epoch:3 step:3401 [D loss: 0.563128, acc.: 74.22%] [G loss: 0.661785]\n",
      "epoch:3 step:3402 [D loss: 0.513775, acc.: 77.34%] [G loss: 0.537414]\n",
      "epoch:3 step:3403 [D loss: 0.463755, acc.: 81.25%] [G loss: 0.556217]\n",
      "epoch:3 step:3404 [D loss: 0.592168, acc.: 69.53%] [G loss: 0.504786]\n",
      "epoch:3 step:3405 [D loss: 0.527131, acc.: 72.66%] [G loss: 0.451486]\n",
      "epoch:3 step:3406 [D loss: 0.466322, acc.: 82.81%] [G loss: 0.491087]\n",
      "epoch:3 step:3407 [D loss: 0.523619, acc.: 79.69%] [G loss: 0.369679]\n",
      "epoch:3 step:3408 [D loss: 0.459846, acc.: 80.47%] [G loss: 0.514529]\n",
      "epoch:3 step:3409 [D loss: 0.428715, acc.: 81.25%] [G loss: 0.756742]\n",
      "epoch:3 step:3410 [D loss: 0.533447, acc.: 75.78%] [G loss: 0.534602]\n",
      "epoch:3 step:3411 [D loss: 0.543679, acc.: 73.44%] [G loss: 0.507940]\n",
      "epoch:3 step:3412 [D loss: 0.565798, acc.: 70.31%] [G loss: 0.595172]\n",
      "epoch:3 step:3413 [D loss: 0.496207, acc.: 74.22%] [G loss: 0.554713]\n",
      "epoch:3 step:3414 [D loss: 0.516905, acc.: 76.56%] [G loss: 0.562345]\n",
      "epoch:3 step:3415 [D loss: 0.529614, acc.: 76.56%] [G loss: 0.550856]\n",
      "epoch:3 step:3416 [D loss: 0.448147, acc.: 83.59%] [G loss: 0.553204]\n",
      "epoch:3 step:3417 [D loss: 0.469881, acc.: 78.12%] [G loss: 0.614181]\n",
      "epoch:3 step:3418 [D loss: 0.505160, acc.: 74.22%] [G loss: 0.705951]\n",
      "epoch:3 step:3419 [D loss: 0.494547, acc.: 75.00%] [G loss: 0.594353]\n",
      "epoch:3 step:3420 [D loss: 0.481869, acc.: 79.69%] [G loss: 0.640640]\n",
      "epoch:3 step:3421 [D loss: 0.499693, acc.: 76.56%] [G loss: 0.535698]\n",
      "epoch:3 step:3422 [D loss: 0.434591, acc.: 86.72%] [G loss: 0.627815]\n",
      "epoch:3 step:3423 [D loss: 0.483392, acc.: 78.91%] [G loss: 0.581095]\n",
      "epoch:3 step:3424 [D loss: 0.431691, acc.: 82.81%] [G loss: 0.685288]\n",
      "epoch:3 step:3425 [D loss: 0.486452, acc.: 72.66%] [G loss: 0.588152]\n",
      "epoch:3 step:3426 [D loss: 0.552078, acc.: 70.31%] [G loss: 0.636471]\n",
      "epoch:3 step:3427 [D loss: 0.520579, acc.: 75.78%] [G loss: 0.553247]\n",
      "epoch:3 step:3428 [D loss: 0.534910, acc.: 71.88%] [G loss: 0.533369]\n",
      "epoch:3 step:3429 [D loss: 0.528379, acc.: 69.53%] [G loss: 0.577178]\n",
      "epoch:3 step:3430 [D loss: 0.516579, acc.: 67.97%] [G loss: 0.537789]\n",
      "epoch:3 step:3431 [D loss: 0.509001, acc.: 72.66%] [G loss: 0.644433]\n",
      "epoch:3 step:3432 [D loss: 0.571829, acc.: 73.44%] [G loss: 0.524902]\n",
      "epoch:3 step:3433 [D loss: 0.520359, acc.: 73.44%] [G loss: 0.580568]\n",
      "epoch:3 step:3434 [D loss: 0.495873, acc.: 73.44%] [G loss: 0.489254]\n",
      "epoch:3 step:3435 [D loss: 0.523873, acc.: 71.88%] [G loss: 0.497944]\n",
      "epoch:3 step:3436 [D loss: 0.511023, acc.: 76.56%] [G loss: 0.557499]\n",
      "epoch:3 step:3437 [D loss: 0.516081, acc.: 75.78%] [G loss: 0.517237]\n",
      "epoch:3 step:3438 [D loss: 0.495703, acc.: 73.44%] [G loss: 0.621266]\n",
      "epoch:3 step:3439 [D loss: 0.528543, acc.: 72.66%] [G loss: 0.498328]\n",
      "epoch:3 step:3440 [D loss: 0.465802, acc.: 79.69%] [G loss: 0.603586]\n",
      "epoch:3 step:3441 [D loss: 0.526426, acc.: 72.66%] [G loss: 0.474273]\n",
      "epoch:3 step:3442 [D loss: 0.439487, acc.: 84.38%] [G loss: 0.595086]\n",
      "epoch:3 step:3443 [D loss: 0.479432, acc.: 79.69%] [G loss: 0.653597]\n",
      "epoch:3 step:3444 [D loss: 0.468130, acc.: 82.81%] [G loss: 0.555461]\n",
      "epoch:3 step:3445 [D loss: 0.468390, acc.: 75.78%] [G loss: 0.607671]\n",
      "epoch:3 step:3446 [D loss: 0.538110, acc.: 71.88%] [G loss: 0.450150]\n",
      "epoch:3 step:3447 [D loss: 0.561763, acc.: 69.53%] [G loss: 0.616583]\n",
      "epoch:3 step:3448 [D loss: 0.555776, acc.: 71.88%] [G loss: 0.561937]\n",
      "epoch:3 step:3449 [D loss: 0.498186, acc.: 75.78%] [G loss: 0.611553]\n",
      "epoch:3 step:3450 [D loss: 0.469991, acc.: 81.25%] [G loss: 0.537113]\n",
      "epoch:3 step:3451 [D loss: 0.462783, acc.: 82.03%] [G loss: 0.667421]\n",
      "epoch:3 step:3452 [D loss: 0.448620, acc.: 82.03%] [G loss: 0.774970]\n",
      "epoch:3 step:3453 [D loss: 0.428719, acc.: 85.94%] [G loss: 0.756677]\n",
      "epoch:3 step:3454 [D loss: 0.497708, acc.: 78.91%] [G loss: 0.615051]\n",
      "epoch:3 step:3455 [D loss: 0.521120, acc.: 71.88%] [G loss: 0.566215]\n",
      "epoch:3 step:3456 [D loss: 0.460615, acc.: 83.59%] [G loss: 0.649241]\n",
      "epoch:3 step:3457 [D loss: 0.535073, acc.: 75.78%] [G loss: 0.631025]\n",
      "epoch:3 step:3458 [D loss: 0.518779, acc.: 75.78%] [G loss: 0.670146]\n",
      "epoch:3 step:3459 [D loss: 0.430399, acc.: 82.03%] [G loss: 0.834293]\n",
      "epoch:3 step:3460 [D loss: 0.483526, acc.: 77.34%] [G loss: 0.756307]\n",
      "epoch:3 step:3461 [D loss: 0.484293, acc.: 75.00%] [G loss: 0.771589]\n",
      "epoch:3 step:3462 [D loss: 0.506424, acc.: 75.00%] [G loss: 0.701513]\n",
      "epoch:3 step:3463 [D loss: 0.562885, acc.: 74.22%] [G loss: 0.498852]\n",
      "epoch:3 step:3464 [D loss: 0.568131, acc.: 71.09%] [G loss: 0.534882]\n",
      "epoch:3 step:3465 [D loss: 0.496920, acc.: 79.69%] [G loss: 0.632659]\n",
      "epoch:3 step:3466 [D loss: 0.530841, acc.: 75.00%] [G loss: 0.518116]\n",
      "epoch:3 step:3467 [D loss: 0.546782, acc.: 71.88%] [G loss: 0.527369]\n",
      "epoch:3 step:3468 [D loss: 0.527648, acc.: 75.78%] [G loss: 0.513630]\n",
      "epoch:3 step:3469 [D loss: 0.578095, acc.: 69.53%] [G loss: 0.529134]\n",
      "epoch:3 step:3470 [D loss: 0.557454, acc.: 76.56%] [G loss: 0.578076]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3471 [D loss: 0.445692, acc.: 82.81%] [G loss: 0.576378]\n",
      "epoch:3 step:3472 [D loss: 0.460326, acc.: 81.25%] [G loss: 0.619747]\n",
      "epoch:3 step:3473 [D loss: 0.548516, acc.: 69.53%] [G loss: 0.516906]\n",
      "epoch:3 step:3474 [D loss: 0.409028, acc.: 87.50%] [G loss: 0.735420]\n",
      "epoch:3 step:3475 [D loss: 0.543099, acc.: 69.53%] [G loss: 0.980265]\n",
      "epoch:3 step:3476 [D loss: 0.506670, acc.: 77.34%] [G loss: 0.808773]\n",
      "epoch:3 step:3477 [D loss: 0.503437, acc.: 75.00%] [G loss: 0.772145]\n",
      "epoch:3 step:3478 [D loss: 0.555388, acc.: 68.75%] [G loss: 0.643113]\n",
      "epoch:3 step:3479 [D loss: 0.547794, acc.: 69.53%] [G loss: 0.637016]\n",
      "epoch:3 step:3480 [D loss: 0.507712, acc.: 75.78%] [G loss: 0.587678]\n",
      "epoch:3 step:3481 [D loss: 0.453315, acc.: 83.59%] [G loss: 0.649130]\n",
      "epoch:3 step:3482 [D loss: 0.547212, acc.: 71.88%] [G loss: 0.694102]\n",
      "epoch:3 step:3483 [D loss: 0.609865, acc.: 67.19%] [G loss: 0.630453]\n",
      "epoch:3 step:3484 [D loss: 0.569589, acc.: 68.75%] [G loss: 0.590886]\n",
      "epoch:3 step:3485 [D loss: 0.504515, acc.: 77.34%] [G loss: 0.735843]\n",
      "epoch:3 step:3486 [D loss: 0.537175, acc.: 71.88%] [G loss: 0.450768]\n",
      "epoch:3 step:3487 [D loss: 0.533287, acc.: 75.00%] [G loss: 0.534945]\n",
      "epoch:3 step:3488 [D loss: 0.430758, acc.: 83.59%] [G loss: 0.552023]\n",
      "epoch:3 step:3489 [D loss: 0.485906, acc.: 80.47%] [G loss: 0.459819]\n",
      "epoch:3 step:3490 [D loss: 0.508301, acc.: 78.91%] [G loss: 0.563665]\n",
      "epoch:3 step:3491 [D loss: 0.441972, acc.: 82.03%] [G loss: 0.677557]\n",
      "epoch:3 step:3492 [D loss: 0.493555, acc.: 76.56%] [G loss: 0.646178]\n",
      "epoch:3 step:3493 [D loss: 0.437868, acc.: 85.94%] [G loss: 0.710706]\n",
      "epoch:3 step:3494 [D loss: 0.502354, acc.: 77.34%] [G loss: 0.548669]\n",
      "epoch:3 step:3495 [D loss: 0.502544, acc.: 75.78%] [G loss: 0.634663]\n",
      "epoch:3 step:3496 [D loss: 0.512880, acc.: 75.00%] [G loss: 0.559731]\n",
      "epoch:3 step:3497 [D loss: 0.533654, acc.: 73.44%] [G loss: 0.477464]\n",
      "epoch:3 step:3498 [D loss: 0.498340, acc.: 77.34%] [G loss: 0.591418]\n",
      "epoch:3 step:3499 [D loss: 0.529349, acc.: 77.34%] [G loss: 0.572378]\n",
      "epoch:3 step:3500 [D loss: 0.508056, acc.: 74.22%] [G loss: 0.649708]\n",
      "epoch:3 step:3501 [D loss: 0.477669, acc.: 79.69%] [G loss: 0.765598]\n",
      "epoch:3 step:3502 [D loss: 0.453373, acc.: 81.25%] [G loss: 0.769702]\n",
      "epoch:3 step:3503 [D loss: 0.478809, acc.: 80.47%] [G loss: 0.687606]\n",
      "epoch:3 step:3504 [D loss: 0.444970, acc.: 81.25%] [G loss: 0.640767]\n",
      "epoch:3 step:3505 [D loss: 0.480878, acc.: 77.34%] [G loss: 0.660044]\n",
      "epoch:3 step:3506 [D loss: 0.489220, acc.: 78.91%] [G loss: 0.569137]\n",
      "epoch:3 step:3507 [D loss: 0.537294, acc.: 74.22%] [G loss: 0.551397]\n",
      "epoch:3 step:3508 [D loss: 0.511487, acc.: 78.91%] [G loss: 0.658837]\n",
      "epoch:3 step:3509 [D loss: 0.498783, acc.: 78.12%] [G loss: 0.578759]\n",
      "epoch:3 step:3510 [D loss: 0.441881, acc.: 80.47%] [G loss: 0.801443]\n",
      "epoch:3 step:3511 [D loss: 0.519868, acc.: 76.56%] [G loss: 0.809226]\n",
      "epoch:3 step:3512 [D loss: 0.462422, acc.: 84.38%] [G loss: 0.783063]\n",
      "epoch:3 step:3513 [D loss: 0.591701, acc.: 67.97%] [G loss: 0.542119]\n",
      "epoch:3 step:3514 [D loss: 0.526799, acc.: 77.34%] [G loss: 0.677071]\n",
      "epoch:3 step:3515 [D loss: 0.580158, acc.: 68.75%] [G loss: 0.561484]\n",
      "epoch:3 step:3516 [D loss: 0.480825, acc.: 75.78%] [G loss: 0.558568]\n",
      "epoch:3 step:3517 [D loss: 0.491298, acc.: 77.34%] [G loss: 0.554588]\n",
      "epoch:3 step:3518 [D loss: 0.417099, acc.: 85.94%] [G loss: 0.752757]\n",
      "epoch:3 step:3519 [D loss: 0.474867, acc.: 78.91%] [G loss: 0.857801]\n",
      "epoch:3 step:3520 [D loss: 0.492927, acc.: 75.00%] [G loss: 0.634130]\n",
      "epoch:3 step:3521 [D loss: 0.660684, acc.: 61.72%] [G loss: 0.511128]\n",
      "epoch:3 step:3522 [D loss: 0.580940, acc.: 65.62%] [G loss: 0.451559]\n",
      "epoch:3 step:3523 [D loss: 0.509627, acc.: 73.44%] [G loss: 0.604692]\n",
      "epoch:3 step:3524 [D loss: 0.598160, acc.: 64.84%] [G loss: 0.437901]\n",
      "epoch:3 step:3525 [D loss: 0.530993, acc.: 68.75%] [G loss: 0.521727]\n",
      "epoch:3 step:3526 [D loss: 0.525995, acc.: 75.78%] [G loss: 0.511696]\n",
      "epoch:3 step:3527 [D loss: 0.579305, acc.: 69.53%] [G loss: 0.571553]\n",
      "epoch:3 step:3528 [D loss: 0.576166, acc.: 71.09%] [G loss: 0.543017]\n",
      "epoch:3 step:3529 [D loss: 0.575338, acc.: 69.53%] [G loss: 0.517310]\n",
      "epoch:3 step:3530 [D loss: 0.527616, acc.: 72.66%] [G loss: 0.543920]\n",
      "epoch:3 step:3531 [D loss: 0.551388, acc.: 69.53%] [G loss: 0.576571]\n",
      "epoch:3 step:3532 [D loss: 0.563511, acc.: 71.09%] [G loss: 0.438632]\n",
      "epoch:3 step:3533 [D loss: 0.481020, acc.: 78.12%] [G loss: 0.547139]\n",
      "epoch:3 step:3534 [D loss: 0.520200, acc.: 75.00%] [G loss: 0.637869]\n",
      "epoch:3 step:3535 [D loss: 0.542964, acc.: 77.34%] [G loss: 0.611679]\n",
      "epoch:3 step:3536 [D loss: 0.519623, acc.: 75.78%] [G loss: 0.746973]\n",
      "epoch:3 step:3537 [D loss: 0.487145, acc.: 78.91%] [G loss: 0.677192]\n",
      "epoch:3 step:3538 [D loss: 0.541361, acc.: 72.66%] [G loss: 0.418155]\n",
      "epoch:3 step:3539 [D loss: 0.543250, acc.: 70.31%] [G loss: 0.452559]\n",
      "epoch:3 step:3540 [D loss: 0.546506, acc.: 73.44%] [G loss: 0.586744]\n",
      "epoch:3 step:3541 [D loss: 0.503934, acc.: 78.12%] [G loss: 0.642772]\n",
      "epoch:3 step:3542 [D loss: 0.479418, acc.: 75.78%] [G loss: 0.710733]\n",
      "epoch:3 step:3543 [D loss: 0.534594, acc.: 75.00%] [G loss: 0.623400]\n",
      "epoch:3 step:3544 [D loss: 0.485115, acc.: 77.34%] [G loss: 0.723171]\n",
      "epoch:3 step:3545 [D loss: 0.533616, acc.: 72.66%] [G loss: 0.594751]\n",
      "epoch:3 step:3546 [D loss: 0.575217, acc.: 67.97%] [G loss: 0.507273]\n",
      "epoch:3 step:3547 [D loss: 0.450376, acc.: 78.91%] [G loss: 0.530548]\n",
      "epoch:3 step:3548 [D loss: 0.487881, acc.: 79.69%] [G loss: 0.545149]\n",
      "epoch:3 step:3549 [D loss: 0.538157, acc.: 72.66%] [G loss: 0.450418]\n",
      "epoch:3 step:3550 [D loss: 0.553415, acc.: 71.09%] [G loss: 0.570471]\n",
      "epoch:3 step:3551 [D loss: 0.619219, acc.: 63.28%] [G loss: 0.400293]\n",
      "epoch:3 step:3552 [D loss: 0.533118, acc.: 77.34%] [G loss: 0.475335]\n",
      "epoch:3 step:3553 [D loss: 0.539157, acc.: 72.66%] [G loss: 0.500658]\n",
      "epoch:3 step:3554 [D loss: 0.497724, acc.: 81.25%] [G loss: 0.648495]\n",
      "epoch:3 step:3555 [D loss: 0.528386, acc.: 75.78%] [G loss: 0.568206]\n",
      "epoch:3 step:3556 [D loss: 0.460191, acc.: 82.81%] [G loss: 0.562698]\n",
      "epoch:3 step:3557 [D loss: 0.462380, acc.: 80.47%] [G loss: 0.602863]\n",
      "epoch:3 step:3558 [D loss: 0.400751, acc.: 84.38%] [G loss: 0.732344]\n",
      "epoch:3 step:3559 [D loss: 0.456143, acc.: 81.25%] [G loss: 0.578362]\n",
      "epoch:3 step:3560 [D loss: 0.556336, acc.: 71.09%] [G loss: 0.606502]\n",
      "epoch:3 step:3561 [D loss: 0.500308, acc.: 75.00%] [G loss: 0.644070]\n",
      "epoch:3 step:3562 [D loss: 0.492478, acc.: 76.56%] [G loss: 0.666394]\n",
      "epoch:3 step:3563 [D loss: 0.501223, acc.: 78.12%] [G loss: 0.602346]\n",
      "epoch:3 step:3564 [D loss: 0.431351, acc.: 82.03%] [G loss: 0.715639]\n",
      "epoch:3 step:3565 [D loss: 0.451302, acc.: 79.69%] [G loss: 0.856147]\n",
      "epoch:3 step:3566 [D loss: 0.462261, acc.: 76.56%] [G loss: 0.803025]\n",
      "epoch:3 step:3567 [D loss: 0.550608, acc.: 67.19%] [G loss: 0.760088]\n",
      "epoch:3 step:3568 [D loss: 0.435819, acc.: 84.38%] [G loss: 0.617852]\n",
      "epoch:3 step:3569 [D loss: 0.507380, acc.: 77.34%] [G loss: 0.518308]\n",
      "epoch:3 step:3570 [D loss: 0.556235, acc.: 67.97%] [G loss: 0.482881]\n",
      "epoch:3 step:3571 [D loss: 0.503847, acc.: 72.66%] [G loss: 0.515908]\n",
      "epoch:3 step:3572 [D loss: 0.502781, acc.: 76.56%] [G loss: 0.575995]\n",
      "epoch:3 step:3573 [D loss: 0.541303, acc.: 72.66%] [G loss: 0.578749]\n",
      "epoch:3 step:3574 [D loss: 0.491825, acc.: 82.81%] [G loss: 0.613574]\n",
      "epoch:3 step:3575 [D loss: 0.496941, acc.: 75.78%] [G loss: 0.572491]\n",
      "epoch:3 step:3576 [D loss: 0.607726, acc.: 67.19%] [G loss: 0.508757]\n",
      "epoch:3 step:3577 [D loss: 0.641788, acc.: 64.06%] [G loss: 0.482577]\n",
      "epoch:3 step:3578 [D loss: 0.521608, acc.: 71.88%] [G loss: 0.503595]\n",
      "epoch:3 step:3579 [D loss: 0.516143, acc.: 74.22%] [G loss: 0.553251]\n",
      "epoch:3 step:3580 [D loss: 0.476728, acc.: 79.69%] [G loss: 0.760877]\n",
      "epoch:3 step:3581 [D loss: 0.534077, acc.: 71.88%] [G loss: 0.640260]\n",
      "epoch:3 step:3582 [D loss: 0.521376, acc.: 75.78%] [G loss: 0.674306]\n",
      "epoch:3 step:3583 [D loss: 0.486722, acc.: 77.34%] [G loss: 0.543097]\n",
      "epoch:3 step:3584 [D loss: 0.525648, acc.: 75.78%] [G loss: 0.503137]\n",
      "epoch:3 step:3585 [D loss: 0.530180, acc.: 78.91%] [G loss: 0.642142]\n",
      "epoch:3 step:3586 [D loss: 0.493889, acc.: 78.12%] [G loss: 0.522801]\n",
      "epoch:3 step:3587 [D loss: 0.515023, acc.: 73.44%] [G loss: 0.552426]\n",
      "epoch:3 step:3588 [D loss: 0.494188, acc.: 74.22%] [G loss: 0.563946]\n",
      "epoch:3 step:3589 [D loss: 0.526705, acc.: 75.78%] [G loss: 0.550386]\n",
      "epoch:3 step:3590 [D loss: 0.522005, acc.: 72.66%] [G loss: 0.591707]\n",
      "epoch:3 step:3591 [D loss: 0.485943, acc.: 76.56%] [G loss: 0.704297]\n",
      "epoch:3 step:3592 [D loss: 0.483509, acc.: 73.44%] [G loss: 0.731534]\n",
      "epoch:3 step:3593 [D loss: 0.509530, acc.: 75.00%] [G loss: 0.670124]\n",
      "epoch:3 step:3594 [D loss: 0.512046, acc.: 77.34%] [G loss: 0.688111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3595 [D loss: 0.532617, acc.: 70.31%] [G loss: 0.534881]\n",
      "epoch:3 step:3596 [D loss: 0.483364, acc.: 78.91%] [G loss: 0.547800]\n",
      "epoch:3 step:3597 [D loss: 0.455424, acc.: 81.25%] [G loss: 0.745681]\n",
      "epoch:3 step:3598 [D loss: 0.571288, acc.: 71.09%] [G loss: 0.594485]\n",
      "epoch:3 step:3599 [D loss: 0.629166, acc.: 62.50%] [G loss: 0.521260]\n",
      "epoch:3 step:3600 [D loss: 0.476944, acc.: 85.16%] [G loss: 0.584145]\n",
      "##############\n",
      "[3.97618569 2.07879129 7.33322445 5.40637751 4.8082213  6.57056733\n",
      " 5.82581504 5.59206992 5.53441076 4.0202996 ]\n",
      "##########\n",
      "epoch:3 step:3601 [D loss: 0.525121, acc.: 78.91%] [G loss: 0.566701]\n",
      "epoch:3 step:3602 [D loss: 0.506573, acc.: 76.56%] [G loss: 0.506210]\n",
      "epoch:3 step:3603 [D loss: 0.396542, acc.: 85.94%] [G loss: 0.645886]\n",
      "epoch:3 step:3604 [D loss: 0.584673, acc.: 69.53%] [G loss: 0.732743]\n",
      "epoch:3 step:3605 [D loss: 0.626129, acc.: 62.50%] [G loss: 0.712647]\n",
      "epoch:3 step:3606 [D loss: 0.494828, acc.: 75.78%] [G loss: 0.722929]\n",
      "epoch:3 step:3607 [D loss: 0.512799, acc.: 70.31%] [G loss: 0.664952]\n",
      "epoch:3 step:3608 [D loss: 0.488105, acc.: 80.47%] [G loss: 0.717891]\n",
      "epoch:3 step:3609 [D loss: 0.473098, acc.: 75.00%] [G loss: 0.611440]\n",
      "epoch:3 step:3610 [D loss: 0.522896, acc.: 75.78%] [G loss: 0.534361]\n",
      "epoch:3 step:3611 [D loss: 0.513993, acc.: 76.56%] [G loss: 0.506176]\n",
      "epoch:3 step:3612 [D loss: 0.485141, acc.: 82.03%] [G loss: 0.494460]\n",
      "epoch:3 step:3613 [D loss: 0.492485, acc.: 71.09%] [G loss: 0.621481]\n",
      "epoch:3 step:3614 [D loss: 0.458865, acc.: 78.12%] [G loss: 0.569770]\n",
      "epoch:3 step:3615 [D loss: 0.494907, acc.: 78.12%] [G loss: 0.617893]\n",
      "epoch:3 step:3616 [D loss: 0.470903, acc.: 77.34%] [G loss: 0.558123]\n",
      "epoch:3 step:3617 [D loss: 0.449989, acc.: 84.38%] [G loss: 0.704158]\n",
      "epoch:3 step:3618 [D loss: 0.491063, acc.: 76.56%] [G loss: 0.588502]\n",
      "epoch:3 step:3619 [D loss: 0.583748, acc.: 63.28%] [G loss: 0.577601]\n",
      "epoch:3 step:3620 [D loss: 0.556276, acc.: 71.88%] [G loss: 0.682812]\n",
      "epoch:3 step:3621 [D loss: 0.498410, acc.: 75.00%] [G loss: 0.573278]\n",
      "epoch:3 step:3622 [D loss: 0.499742, acc.: 75.78%] [G loss: 0.594781]\n",
      "epoch:3 step:3623 [D loss: 0.552304, acc.: 71.88%] [G loss: 0.490363]\n",
      "epoch:3 step:3624 [D loss: 0.514068, acc.: 75.00%] [G loss: 0.488895]\n",
      "epoch:3 step:3625 [D loss: 0.547913, acc.: 75.00%] [G loss: 0.634903]\n",
      "epoch:3 step:3626 [D loss: 0.514522, acc.: 74.22%] [G loss: 0.621492]\n",
      "epoch:3 step:3627 [D loss: 0.523230, acc.: 71.88%] [G loss: 0.667270]\n",
      "epoch:3 step:3628 [D loss: 0.573586, acc.: 69.53%] [G loss: 0.513205]\n",
      "epoch:3 step:3629 [D loss: 0.560388, acc.: 69.53%] [G loss: 0.483304]\n",
      "epoch:3 step:3630 [D loss: 0.542619, acc.: 73.44%] [G loss: 0.421000]\n",
      "epoch:3 step:3631 [D loss: 0.536771, acc.: 71.09%] [G loss: 0.525149]\n",
      "epoch:3 step:3632 [D loss: 0.488776, acc.: 78.91%] [G loss: 0.524095]\n",
      "epoch:3 step:3633 [D loss: 0.428524, acc.: 83.59%] [G loss: 0.742221]\n",
      "epoch:3 step:3634 [D loss: 0.508339, acc.: 78.12%] [G loss: 0.560821]\n",
      "epoch:3 step:3635 [D loss: 0.580287, acc.: 69.53%] [G loss: 0.527440]\n",
      "epoch:3 step:3636 [D loss: 0.501111, acc.: 74.22%] [G loss: 0.620863]\n",
      "epoch:3 step:3637 [D loss: 0.515312, acc.: 78.12%] [G loss: 0.525134]\n",
      "epoch:3 step:3638 [D loss: 0.574426, acc.: 71.88%] [G loss: 0.517199]\n",
      "epoch:3 step:3639 [D loss: 0.540337, acc.: 74.22%] [G loss: 0.444503]\n",
      "epoch:3 step:3640 [D loss: 0.488489, acc.: 73.44%] [G loss: 0.459516]\n",
      "epoch:3 step:3641 [D loss: 0.498742, acc.: 74.22%] [G loss: 0.513980]\n",
      "epoch:3 step:3642 [D loss: 0.511307, acc.: 80.47%] [G loss: 0.467263]\n",
      "epoch:3 step:3643 [D loss: 0.552855, acc.: 70.31%] [G loss: 0.537045]\n",
      "epoch:3 step:3644 [D loss: 0.494986, acc.: 78.91%] [G loss: 0.623523]\n",
      "epoch:3 step:3645 [D loss: 0.448991, acc.: 78.91%] [G loss: 0.619155]\n",
      "epoch:3 step:3646 [D loss: 0.477786, acc.: 78.12%] [G loss: 0.640103]\n",
      "epoch:3 step:3647 [D loss: 0.505841, acc.: 76.56%] [G loss: 0.617090]\n",
      "epoch:3 step:3648 [D loss: 0.544381, acc.: 67.97%] [G loss: 0.476673]\n",
      "epoch:3 step:3649 [D loss: 0.444729, acc.: 81.25%] [G loss: 0.648023]\n",
      "epoch:3 step:3650 [D loss: 0.497608, acc.: 78.12%] [G loss: 0.622988]\n",
      "epoch:3 step:3651 [D loss: 0.518976, acc.: 76.56%] [G loss: 0.512469]\n",
      "epoch:3 step:3652 [D loss: 0.495865, acc.: 77.34%] [G loss: 0.536613]\n",
      "epoch:3 step:3653 [D loss: 0.490598, acc.: 74.22%] [G loss: 0.555663]\n",
      "epoch:3 step:3654 [D loss: 0.512597, acc.: 75.00%] [G loss: 0.604683]\n",
      "epoch:3 step:3655 [D loss: 0.559369, acc.: 69.53%] [G loss: 0.544173]\n",
      "epoch:3 step:3656 [D loss: 0.511656, acc.: 75.00%] [G loss: 0.561215]\n",
      "epoch:3 step:3657 [D loss: 0.503992, acc.: 73.44%] [G loss: 0.486840]\n",
      "epoch:3 step:3658 [D loss: 0.539985, acc.: 75.00%] [G loss: 0.483563]\n",
      "epoch:3 step:3659 [D loss: 0.444438, acc.: 83.59%] [G loss: 0.544901]\n",
      "epoch:3 step:3660 [D loss: 0.576329, acc.: 75.00%] [G loss: 0.395016]\n",
      "epoch:3 step:3661 [D loss: 0.504910, acc.: 75.78%] [G loss: 0.492309]\n",
      "epoch:3 step:3662 [D loss: 0.525534, acc.: 78.91%] [G loss: 0.449506]\n",
      "epoch:3 step:3663 [D loss: 0.447218, acc.: 85.16%] [G loss: 0.590992]\n",
      "epoch:3 step:3664 [D loss: 0.515110, acc.: 79.69%] [G loss: 0.510041]\n",
      "epoch:3 step:3665 [D loss: 0.437909, acc.: 83.59%] [G loss: 0.706338]\n",
      "epoch:3 step:3666 [D loss: 0.497738, acc.: 76.56%] [G loss: 0.718862]\n",
      "epoch:3 step:3667 [D loss: 0.552198, acc.: 74.22%] [G loss: 0.560014]\n",
      "epoch:3 step:3668 [D loss: 0.438687, acc.: 82.81%] [G loss: 0.474302]\n",
      "epoch:3 step:3669 [D loss: 0.658989, acc.: 63.28%] [G loss: 0.548319]\n",
      "epoch:3 step:3670 [D loss: 0.502190, acc.: 78.12%] [G loss: 0.727842]\n",
      "epoch:3 step:3671 [D loss: 0.460610, acc.: 81.25%] [G loss: 0.678353]\n",
      "epoch:3 step:3672 [D loss: 0.533619, acc.: 74.22%] [G loss: 0.568857]\n",
      "epoch:3 step:3673 [D loss: 0.567373, acc.: 70.31%] [G loss: 0.370268]\n",
      "epoch:3 step:3674 [D loss: 0.477063, acc.: 80.47%] [G loss: 0.610449]\n",
      "epoch:3 step:3675 [D loss: 0.488499, acc.: 80.47%] [G loss: 0.539711]\n",
      "epoch:3 step:3676 [D loss: 0.505167, acc.: 73.44%] [G loss: 0.579235]\n",
      "epoch:3 step:3677 [D loss: 0.515283, acc.: 72.66%] [G loss: 0.504400]\n",
      "epoch:3 step:3678 [D loss: 0.570934, acc.: 68.75%] [G loss: 0.401078]\n",
      "epoch:3 step:3679 [D loss: 0.451285, acc.: 82.03%] [G loss: 0.579719]\n",
      "epoch:3 step:3680 [D loss: 0.487134, acc.: 76.56%] [G loss: 0.564384]\n",
      "epoch:3 step:3681 [D loss: 0.481796, acc.: 77.34%] [G loss: 0.595144]\n",
      "epoch:3 step:3682 [D loss: 0.511560, acc.: 77.34%] [G loss: 0.677330]\n",
      "epoch:3 step:3683 [D loss: 0.510411, acc.: 74.22%] [G loss: 0.636347]\n",
      "epoch:3 step:3684 [D loss: 0.535988, acc.: 72.66%] [G loss: 0.557066]\n",
      "epoch:3 step:3685 [D loss: 0.539500, acc.: 75.78%] [G loss: 0.546889]\n",
      "epoch:3 step:3686 [D loss: 0.453301, acc.: 82.81%] [G loss: 0.736823]\n",
      "epoch:3 step:3687 [D loss: 0.492533, acc.: 78.91%] [G loss: 0.600838]\n",
      "epoch:3 step:3688 [D loss: 0.508023, acc.: 74.22%] [G loss: 0.527332]\n",
      "epoch:3 step:3689 [D loss: 0.550832, acc.: 71.09%] [G loss: 0.531065]\n",
      "epoch:3 step:3690 [D loss: 0.492195, acc.: 78.12%] [G loss: 0.499730]\n",
      "epoch:3 step:3691 [D loss: 0.599918, acc.: 65.62%] [G loss: 0.533507]\n",
      "epoch:3 step:3692 [D loss: 0.525543, acc.: 75.00%] [G loss: 0.511777]\n",
      "epoch:3 step:3693 [D loss: 0.580197, acc.: 71.09%] [G loss: 0.445132]\n",
      "epoch:3 step:3694 [D loss: 0.537496, acc.: 73.44%] [G loss: 0.560065]\n",
      "epoch:3 step:3695 [D loss: 0.431523, acc.: 83.59%] [G loss: 0.759589]\n",
      "epoch:3 step:3696 [D loss: 0.473459, acc.: 78.12%] [G loss: 0.618301]\n",
      "epoch:3 step:3697 [D loss: 0.501776, acc.: 72.66%] [G loss: 0.715687]\n",
      "epoch:3 step:3698 [D loss: 0.442769, acc.: 82.03%] [G loss: 0.665037]\n",
      "epoch:3 step:3699 [D loss: 0.472329, acc.: 78.91%] [G loss: 0.807459]\n",
      "epoch:3 step:3700 [D loss: 0.488509, acc.: 78.12%] [G loss: 0.745029]\n",
      "epoch:3 step:3701 [D loss: 0.422474, acc.: 83.59%] [G loss: 0.905463]\n",
      "epoch:3 step:3702 [D loss: 0.592621, acc.: 67.19%] [G loss: 0.535757]\n",
      "epoch:3 step:3703 [D loss: 0.586322, acc.: 65.62%] [G loss: 0.703362]\n",
      "epoch:3 step:3704 [D loss: 0.515998, acc.: 76.56%] [G loss: 0.671355]\n",
      "epoch:3 step:3705 [D loss: 0.516352, acc.: 74.22%] [G loss: 0.676239]\n",
      "epoch:3 step:3706 [D loss: 0.495227, acc.: 78.12%] [G loss: 0.670176]\n",
      "epoch:3 step:3707 [D loss: 0.556420, acc.: 73.44%] [G loss: 0.737642]\n",
      "epoch:3 step:3708 [D loss: 0.471130, acc.: 78.12%] [G loss: 0.700716]\n",
      "epoch:3 step:3709 [D loss: 0.490633, acc.: 72.66%] [G loss: 0.719786]\n",
      "epoch:3 step:3710 [D loss: 0.516666, acc.: 78.91%] [G loss: 0.674086]\n",
      "epoch:3 step:3711 [D loss: 0.481615, acc.: 80.47%] [G loss: 0.656258]\n",
      "epoch:3 step:3712 [D loss: 0.530831, acc.: 69.53%] [G loss: 0.550523]\n",
      "epoch:3 step:3713 [D loss: 0.553301, acc.: 72.66%] [G loss: 0.488728]\n",
      "epoch:3 step:3714 [D loss: 0.534064, acc.: 74.22%] [G loss: 0.584752]\n",
      "epoch:3 step:3715 [D loss: 0.548704, acc.: 71.09%] [G loss: 0.445931]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3716 [D loss: 0.545666, acc.: 70.31%] [G loss: 0.548476]\n",
      "epoch:3 step:3717 [D loss: 0.482392, acc.: 82.81%] [G loss: 0.701540]\n",
      "epoch:3 step:3718 [D loss: 0.532333, acc.: 75.00%] [G loss: 0.637902]\n",
      "epoch:3 step:3719 [D loss: 0.509560, acc.: 76.56%] [G loss: 0.561514]\n",
      "epoch:3 step:3720 [D loss: 0.453493, acc.: 79.69%] [G loss: 0.582887]\n",
      "epoch:3 step:3721 [D loss: 0.475844, acc.: 78.91%] [G loss: 0.642999]\n",
      "epoch:3 step:3722 [D loss: 0.435564, acc.: 78.12%] [G loss: 0.703966]\n",
      "epoch:3 step:3723 [D loss: 0.450073, acc.: 82.03%] [G loss: 0.744457]\n",
      "epoch:3 step:3724 [D loss: 0.548807, acc.: 71.88%] [G loss: 0.556669]\n",
      "epoch:3 step:3725 [D loss: 0.468674, acc.: 78.91%] [G loss: 0.605787]\n",
      "epoch:3 step:3726 [D loss: 0.606685, acc.: 66.41%] [G loss: 0.529705]\n",
      "epoch:3 step:3727 [D loss: 0.484295, acc.: 78.12%] [G loss: 0.669855]\n",
      "epoch:3 step:3728 [D loss: 0.521629, acc.: 71.09%] [G loss: 0.532014]\n",
      "epoch:3 step:3729 [D loss: 0.475411, acc.: 78.91%] [G loss: 0.784688]\n",
      "epoch:3 step:3730 [D loss: 0.501029, acc.: 81.25%] [G loss: 0.712422]\n",
      "epoch:3 step:3731 [D loss: 0.613216, acc.: 65.62%] [G loss: 0.576865]\n",
      "epoch:3 step:3732 [D loss: 0.449605, acc.: 80.47%] [G loss: 0.715690]\n",
      "epoch:3 step:3733 [D loss: 0.514771, acc.: 75.00%] [G loss: 0.601029]\n",
      "epoch:3 step:3734 [D loss: 0.423705, acc.: 86.72%] [G loss: 0.605364]\n",
      "epoch:3 step:3735 [D loss: 0.386575, acc.: 86.72%] [G loss: 0.797699]\n",
      "epoch:3 step:3736 [D loss: 0.447712, acc.: 80.47%] [G loss: 0.839595]\n",
      "epoch:3 step:3737 [D loss: 0.429879, acc.: 83.59%] [G loss: 0.908286]\n",
      "epoch:3 step:3738 [D loss: 0.441758, acc.: 79.69%] [G loss: 0.939818]\n",
      "epoch:3 step:3739 [D loss: 0.806554, acc.: 61.72%] [G loss: 0.871065]\n",
      "epoch:3 step:3740 [D loss: 0.399983, acc.: 85.94%] [G loss: 1.183510]\n",
      "epoch:3 step:3741 [D loss: 0.409260, acc.: 78.91%] [G loss: 0.926170]\n",
      "epoch:3 step:3742 [D loss: 0.552352, acc.: 71.09%] [G loss: 0.697011]\n",
      "epoch:3 step:3743 [D loss: 0.556550, acc.: 72.66%] [G loss: 0.587130]\n",
      "epoch:3 step:3744 [D loss: 0.459860, acc.: 78.91%] [G loss: 0.652598]\n",
      "epoch:3 step:3745 [D loss: 0.529289, acc.: 72.66%] [G loss: 0.702167]\n",
      "epoch:3 step:3746 [D loss: 0.471496, acc.: 73.44%] [G loss: 0.739890]\n",
      "epoch:3 step:3747 [D loss: 0.410880, acc.: 83.59%] [G loss: 0.903885]\n",
      "epoch:3 step:3748 [D loss: 0.463125, acc.: 80.47%] [G loss: 0.893477]\n",
      "epoch:4 step:3749 [D loss: 0.516900, acc.: 75.00%] [G loss: 0.882534]\n",
      "epoch:4 step:3750 [D loss: 0.474105, acc.: 78.12%] [G loss: 0.788442]\n",
      "epoch:4 step:3751 [D loss: 0.542862, acc.: 74.22%] [G loss: 0.580827]\n",
      "epoch:4 step:3752 [D loss: 0.485865, acc.: 75.78%] [G loss: 0.574955]\n",
      "epoch:4 step:3753 [D loss: 0.478320, acc.: 78.12%] [G loss: 0.521394]\n",
      "epoch:4 step:3754 [D loss: 0.513876, acc.: 72.66%] [G loss: 0.657175]\n",
      "epoch:4 step:3755 [D loss: 0.454158, acc.: 82.81%] [G loss: 0.589028]\n",
      "epoch:4 step:3756 [D loss: 0.473513, acc.: 82.03%] [G loss: 0.566939]\n",
      "epoch:4 step:3757 [D loss: 0.466333, acc.: 78.91%] [G loss: 0.637056]\n",
      "epoch:4 step:3758 [D loss: 0.532689, acc.: 74.22%] [G loss: 0.653569]\n",
      "epoch:4 step:3759 [D loss: 0.464478, acc.: 80.47%] [G loss: 0.642375]\n",
      "epoch:4 step:3760 [D loss: 0.525129, acc.: 76.56%] [G loss: 0.671516]\n",
      "epoch:4 step:3761 [D loss: 0.496351, acc.: 71.88%] [G loss: 0.741261]\n",
      "epoch:4 step:3762 [D loss: 0.508610, acc.: 75.78%] [G loss: 0.542354]\n",
      "epoch:4 step:3763 [D loss: 0.461878, acc.: 85.94%] [G loss: 0.632552]\n",
      "epoch:4 step:3764 [D loss: 0.427601, acc.: 83.59%] [G loss: 0.758864]\n",
      "epoch:4 step:3765 [D loss: 0.515582, acc.: 75.00%] [G loss: 0.643814]\n",
      "epoch:4 step:3766 [D loss: 0.517592, acc.: 77.34%] [G loss: 0.604227]\n",
      "epoch:4 step:3767 [D loss: 0.510647, acc.: 77.34%] [G loss: 0.604066]\n",
      "epoch:4 step:3768 [D loss: 0.591492, acc.: 72.66%] [G loss: 0.598686]\n",
      "epoch:4 step:3769 [D loss: 0.493936, acc.: 78.12%] [G loss: 0.634118]\n",
      "epoch:4 step:3770 [D loss: 0.460617, acc.: 81.25%] [G loss: 0.713592]\n",
      "epoch:4 step:3771 [D loss: 0.496096, acc.: 79.69%] [G loss: 0.483101]\n",
      "epoch:4 step:3772 [D loss: 0.464313, acc.: 79.69%] [G loss: 0.606824]\n",
      "epoch:4 step:3773 [D loss: 0.529746, acc.: 75.00%] [G loss: 0.525642]\n",
      "epoch:4 step:3774 [D loss: 0.516886, acc.: 76.56%] [G loss: 0.573293]\n",
      "epoch:4 step:3775 [D loss: 0.446466, acc.: 78.91%] [G loss: 0.641461]\n",
      "epoch:4 step:3776 [D loss: 0.499440, acc.: 74.22%] [G loss: 0.531501]\n",
      "epoch:4 step:3777 [D loss: 0.469377, acc.: 75.78%] [G loss: 0.559272]\n",
      "epoch:4 step:3778 [D loss: 0.519438, acc.: 73.44%] [G loss: 0.521718]\n",
      "epoch:4 step:3779 [D loss: 0.554129, acc.: 72.66%] [G loss: 0.519850]\n",
      "epoch:4 step:3780 [D loss: 0.519952, acc.: 75.78%] [G loss: 0.572588]\n",
      "epoch:4 step:3781 [D loss: 0.487451, acc.: 80.47%] [G loss: 0.496567]\n",
      "epoch:4 step:3782 [D loss: 0.445908, acc.: 84.38%] [G loss: 0.772751]\n",
      "epoch:4 step:3783 [D loss: 0.464714, acc.: 80.47%] [G loss: 0.813041]\n",
      "epoch:4 step:3784 [D loss: 0.464312, acc.: 78.12%] [G loss: 0.695342]\n",
      "epoch:4 step:3785 [D loss: 0.491064, acc.: 80.47%] [G loss: 0.565381]\n",
      "epoch:4 step:3786 [D loss: 0.564899, acc.: 71.88%] [G loss: 0.643458]\n",
      "epoch:4 step:3787 [D loss: 0.446713, acc.: 83.59%] [G loss: 0.588372]\n",
      "epoch:4 step:3788 [D loss: 0.467930, acc.: 74.22%] [G loss: 0.747971]\n",
      "epoch:4 step:3789 [D loss: 0.529870, acc.: 76.56%] [G loss: 0.688247]\n",
      "epoch:4 step:3790 [D loss: 0.467906, acc.: 78.12%] [G loss: 0.629297]\n",
      "epoch:4 step:3791 [D loss: 0.501411, acc.: 73.44%] [G loss: 0.550474]\n",
      "epoch:4 step:3792 [D loss: 0.544502, acc.: 71.09%] [G loss: 0.586827]\n",
      "epoch:4 step:3793 [D loss: 0.541236, acc.: 77.34%] [G loss: 0.649770]\n",
      "epoch:4 step:3794 [D loss: 0.466838, acc.: 80.47%] [G loss: 0.659981]\n",
      "epoch:4 step:3795 [D loss: 0.496687, acc.: 80.47%] [G loss: 0.667867]\n",
      "epoch:4 step:3796 [D loss: 0.528957, acc.: 78.12%] [G loss: 0.486619]\n",
      "epoch:4 step:3797 [D loss: 0.482292, acc.: 79.69%] [G loss: 0.605309]\n",
      "epoch:4 step:3798 [D loss: 0.521660, acc.: 75.78%] [G loss: 0.577934]\n",
      "epoch:4 step:3799 [D loss: 0.475495, acc.: 80.47%] [G loss: 0.736042]\n",
      "epoch:4 step:3800 [D loss: 0.570808, acc.: 77.34%] [G loss: 0.601006]\n",
      "##############\n",
      "[3.50402798 1.80863106 7.20675754 5.43371056 4.48907642 6.43199629\n",
      " 5.50184875 5.3491607  5.27554971 3.89688099]\n",
      "##########\n",
      "epoch:4 step:3801 [D loss: 0.535418, acc.: 72.66%] [G loss: 0.593220]\n",
      "epoch:4 step:3802 [D loss: 0.488992, acc.: 76.56%] [G loss: 0.593682]\n",
      "epoch:4 step:3803 [D loss: 0.534756, acc.: 75.78%] [G loss: 0.687590]\n",
      "epoch:4 step:3804 [D loss: 0.502546, acc.: 78.91%] [G loss: 0.571383]\n",
      "epoch:4 step:3805 [D loss: 0.526691, acc.: 71.88%] [G loss: 0.659626]\n",
      "epoch:4 step:3806 [D loss: 0.525550, acc.: 73.44%] [G loss: 0.562854]\n",
      "epoch:4 step:3807 [D loss: 0.490773, acc.: 73.44%] [G loss: 0.686927]\n",
      "epoch:4 step:3808 [D loss: 0.464358, acc.: 81.25%] [G loss: 0.645345]\n",
      "epoch:4 step:3809 [D loss: 0.531283, acc.: 72.66%] [G loss: 0.570015]\n",
      "epoch:4 step:3810 [D loss: 0.527318, acc.: 70.31%] [G loss: 0.592578]\n",
      "epoch:4 step:3811 [D loss: 0.543770, acc.: 72.66%] [G loss: 0.608115]\n",
      "epoch:4 step:3812 [D loss: 0.508955, acc.: 75.78%] [G loss: 0.561433]\n",
      "epoch:4 step:3813 [D loss: 0.510001, acc.: 79.69%] [G loss: 0.562491]\n",
      "epoch:4 step:3814 [D loss: 0.494696, acc.: 76.56%] [G loss: 0.599285]\n",
      "epoch:4 step:3815 [D loss: 0.536327, acc.: 71.09%] [G loss: 0.448034]\n",
      "epoch:4 step:3816 [D loss: 0.461283, acc.: 79.69%] [G loss: 0.640551]\n",
      "epoch:4 step:3817 [D loss: 0.476512, acc.: 76.56%] [G loss: 0.681472]\n",
      "epoch:4 step:3818 [D loss: 0.466130, acc.: 77.34%] [G loss: 0.542456]\n",
      "epoch:4 step:3819 [D loss: 0.477469, acc.: 78.91%] [G loss: 0.614255]\n",
      "epoch:4 step:3820 [D loss: 0.484583, acc.: 78.91%] [G loss: 0.555924]\n",
      "epoch:4 step:3821 [D loss: 0.482606, acc.: 81.25%] [G loss: 0.556095]\n",
      "epoch:4 step:3822 [D loss: 0.473695, acc.: 80.47%] [G loss: 0.748953]\n",
      "epoch:4 step:3823 [D loss: 0.529768, acc.: 71.88%] [G loss: 0.640694]\n",
      "epoch:4 step:3824 [D loss: 0.518923, acc.: 73.44%] [G loss: 0.683431]\n",
      "epoch:4 step:3825 [D loss: 0.415343, acc.: 85.16%] [G loss: 0.810893]\n",
      "epoch:4 step:3826 [D loss: 0.543596, acc.: 71.88%] [G loss: 0.539304]\n",
      "epoch:4 step:3827 [D loss: 0.534268, acc.: 74.22%] [G loss: 0.428509]\n",
      "epoch:4 step:3828 [D loss: 0.527662, acc.: 74.22%] [G loss: 0.558038]\n",
      "epoch:4 step:3829 [D loss: 0.516428, acc.: 75.00%] [G loss: 0.547193]\n",
      "epoch:4 step:3830 [D loss: 0.511179, acc.: 69.53%] [G loss: 0.591715]\n",
      "epoch:4 step:3831 [D loss: 0.424468, acc.: 82.81%] [G loss: 0.659102]\n",
      "epoch:4 step:3832 [D loss: 0.508855, acc.: 78.91%] [G loss: 0.569554]\n",
      "epoch:4 step:3833 [D loss: 0.524992, acc.: 75.00%] [G loss: 0.489716]\n",
      "epoch:4 step:3834 [D loss: 0.472209, acc.: 80.47%] [G loss: 0.654824]\n",
      "epoch:4 step:3835 [D loss: 0.530218, acc.: 76.56%] [G loss: 0.518911]\n",
      "epoch:4 step:3836 [D loss: 0.441245, acc.: 84.38%] [G loss: 0.712810]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3837 [D loss: 0.469099, acc.: 76.56%] [G loss: 0.647474]\n",
      "epoch:4 step:3838 [D loss: 0.497684, acc.: 79.69%] [G loss: 0.709494]\n",
      "epoch:4 step:3839 [D loss: 0.504626, acc.: 76.56%] [G loss: 0.729332]\n",
      "epoch:4 step:3840 [D loss: 0.520293, acc.: 74.22%] [G loss: 0.596367]\n",
      "epoch:4 step:3841 [D loss: 0.529663, acc.: 67.97%] [G loss: 0.532948]\n",
      "epoch:4 step:3842 [D loss: 0.493842, acc.: 77.34%] [G loss: 0.654999]\n",
      "epoch:4 step:3843 [D loss: 0.527851, acc.: 71.09%] [G loss: 0.596692]\n",
      "epoch:4 step:3844 [D loss: 0.447079, acc.: 83.59%] [G loss: 0.637324]\n",
      "epoch:4 step:3845 [D loss: 0.512004, acc.: 74.22%] [G loss: 0.686394]\n",
      "epoch:4 step:3846 [D loss: 0.534180, acc.: 75.78%] [G loss: 0.522859]\n",
      "epoch:4 step:3847 [D loss: 0.536537, acc.: 72.66%] [G loss: 0.645941]\n",
      "epoch:4 step:3848 [D loss: 0.447571, acc.: 77.34%] [G loss: 0.740722]\n",
      "epoch:4 step:3849 [D loss: 0.460871, acc.: 79.69%] [G loss: 0.692162]\n",
      "epoch:4 step:3850 [D loss: 0.542820, acc.: 77.34%] [G loss: 0.557641]\n",
      "epoch:4 step:3851 [D loss: 0.429912, acc.: 81.25%] [G loss: 0.725922]\n",
      "epoch:4 step:3852 [D loss: 0.474597, acc.: 77.34%] [G loss: 0.712244]\n",
      "epoch:4 step:3853 [D loss: 0.508220, acc.: 73.44%] [G loss: 0.611673]\n",
      "epoch:4 step:3854 [D loss: 0.527361, acc.: 78.12%] [G loss: 0.552708]\n",
      "epoch:4 step:3855 [D loss: 0.628419, acc.: 62.50%] [G loss: 0.330404]\n",
      "epoch:4 step:3856 [D loss: 0.602024, acc.: 63.28%] [G loss: 0.536273]\n",
      "epoch:4 step:3857 [D loss: 0.535041, acc.: 77.34%] [G loss: 0.466349]\n",
      "epoch:4 step:3858 [D loss: 0.558375, acc.: 69.53%] [G loss: 0.508431]\n",
      "epoch:4 step:3859 [D loss: 0.467079, acc.: 78.91%] [G loss: 0.717471]\n",
      "epoch:4 step:3860 [D loss: 0.500233, acc.: 74.22%] [G loss: 0.555638]\n",
      "epoch:4 step:3861 [D loss: 0.566830, acc.: 67.97%] [G loss: 0.491084]\n",
      "epoch:4 step:3862 [D loss: 0.559164, acc.: 73.44%] [G loss: 0.468910]\n",
      "epoch:4 step:3863 [D loss: 0.551323, acc.: 74.22%] [G loss: 0.534362]\n",
      "epoch:4 step:3864 [D loss: 0.520127, acc.: 74.22%] [G loss: 0.592345]\n",
      "epoch:4 step:3865 [D loss: 0.536127, acc.: 73.44%] [G loss: 0.654975]\n",
      "epoch:4 step:3866 [D loss: 0.519931, acc.: 71.88%] [G loss: 0.647700]\n",
      "epoch:4 step:3867 [D loss: 0.463801, acc.: 82.03%] [G loss: 0.880655]\n",
      "epoch:4 step:3868 [D loss: 0.603126, acc.: 67.19%] [G loss: 0.660939]\n",
      "epoch:4 step:3869 [D loss: 0.538992, acc.: 75.78%] [G loss: 0.447033]\n",
      "epoch:4 step:3870 [D loss: 0.540919, acc.: 72.66%] [G loss: 0.588201]\n",
      "epoch:4 step:3871 [D loss: 0.508981, acc.: 74.22%] [G loss: 0.599280]\n",
      "epoch:4 step:3872 [D loss: 0.499278, acc.: 77.34%] [G loss: 0.625705]\n",
      "epoch:4 step:3873 [D loss: 0.468111, acc.: 77.34%] [G loss: 0.637091]\n",
      "epoch:4 step:3874 [D loss: 0.485164, acc.: 78.91%] [G loss: 0.596765]\n",
      "epoch:4 step:3875 [D loss: 0.499005, acc.: 75.78%] [G loss: 0.689971]\n",
      "epoch:4 step:3876 [D loss: 0.517429, acc.: 71.09%] [G loss: 0.538514]\n",
      "epoch:4 step:3877 [D loss: 0.590821, acc.: 68.75%] [G loss: 0.501683]\n",
      "epoch:4 step:3878 [D loss: 0.526771, acc.: 71.88%] [G loss: 0.563079]\n",
      "epoch:4 step:3879 [D loss: 0.493452, acc.: 78.91%] [G loss: 0.631103]\n",
      "epoch:4 step:3880 [D loss: 0.494494, acc.: 78.91%] [G loss: 0.659659]\n",
      "epoch:4 step:3881 [D loss: 0.568168, acc.: 68.75%] [G loss: 0.502014]\n",
      "epoch:4 step:3882 [D loss: 0.543868, acc.: 70.31%] [G loss: 0.609838]\n",
      "epoch:4 step:3883 [D loss: 0.497307, acc.: 78.12%] [G loss: 0.614254]\n",
      "epoch:4 step:3884 [D loss: 0.576888, acc.: 70.31%] [G loss: 0.529133]\n",
      "epoch:4 step:3885 [D loss: 0.562139, acc.: 65.62%] [G loss: 0.532967]\n",
      "epoch:4 step:3886 [D loss: 0.543076, acc.: 71.09%] [G loss: 0.565764]\n",
      "epoch:4 step:3887 [D loss: 0.545877, acc.: 68.75%] [G loss: 0.658479]\n",
      "epoch:4 step:3888 [D loss: 0.496997, acc.: 78.12%] [G loss: 0.589599]\n",
      "epoch:4 step:3889 [D loss: 0.490547, acc.: 76.56%] [G loss: 0.605245]\n",
      "epoch:4 step:3890 [D loss: 0.447135, acc.: 82.81%] [G loss: 0.575735]\n",
      "epoch:4 step:3891 [D loss: 0.576702, acc.: 70.31%] [G loss: 0.483924]\n",
      "epoch:4 step:3892 [D loss: 0.457760, acc.: 75.78%] [G loss: 0.449500]\n",
      "epoch:4 step:3893 [D loss: 0.522562, acc.: 75.00%] [G loss: 0.539253]\n",
      "epoch:4 step:3894 [D loss: 0.473345, acc.: 79.69%] [G loss: 0.656908]\n",
      "epoch:4 step:3895 [D loss: 0.549765, acc.: 73.44%] [G loss: 0.622850]\n",
      "epoch:4 step:3896 [D loss: 0.563635, acc.: 66.41%] [G loss: 0.533860]\n",
      "epoch:4 step:3897 [D loss: 0.457572, acc.: 80.47%] [G loss: 0.617782]\n",
      "epoch:4 step:3898 [D loss: 0.582189, acc.: 72.66%] [G loss: 0.432849]\n",
      "epoch:4 step:3899 [D loss: 0.536224, acc.: 75.00%] [G loss: 0.509204]\n",
      "epoch:4 step:3900 [D loss: 0.418501, acc.: 85.16%] [G loss: 0.800787]\n",
      "epoch:4 step:3901 [D loss: 0.562153, acc.: 73.44%] [G loss: 0.732368]\n",
      "epoch:4 step:3902 [D loss: 0.486499, acc.: 77.34%] [G loss: 0.576378]\n",
      "epoch:4 step:3903 [D loss: 0.458412, acc.: 81.25%] [G loss: 0.552029]\n",
      "epoch:4 step:3904 [D loss: 0.519537, acc.: 78.91%] [G loss: 0.637541]\n",
      "epoch:4 step:3905 [D loss: 0.521719, acc.: 69.53%] [G loss: 0.621552]\n",
      "epoch:4 step:3906 [D loss: 0.495743, acc.: 78.91%] [G loss: 0.642438]\n",
      "epoch:4 step:3907 [D loss: 0.510107, acc.: 78.91%] [G loss: 0.546651]\n",
      "epoch:4 step:3908 [D loss: 0.548629, acc.: 71.09%] [G loss: 0.490119]\n",
      "epoch:4 step:3909 [D loss: 0.460052, acc.: 82.03%] [G loss: 0.603169]\n",
      "epoch:4 step:3910 [D loss: 0.434054, acc.: 80.47%] [G loss: 0.795989]\n",
      "epoch:4 step:3911 [D loss: 0.460665, acc.: 78.91%] [G loss: 0.741843]\n",
      "epoch:4 step:3912 [D loss: 0.490827, acc.: 82.81%] [G loss: 0.819587]\n",
      "epoch:4 step:3913 [D loss: 0.505241, acc.: 72.66%] [G loss: 0.606435]\n",
      "epoch:4 step:3914 [D loss: 0.573274, acc.: 71.09%] [G loss: 0.595706]\n",
      "epoch:4 step:3915 [D loss: 0.569396, acc.: 68.75%] [G loss: 0.562956]\n",
      "epoch:4 step:3916 [D loss: 0.520386, acc.: 75.00%] [G loss: 0.555386]\n",
      "epoch:4 step:3917 [D loss: 0.541033, acc.: 73.44%] [G loss: 0.468600]\n",
      "epoch:4 step:3918 [D loss: 0.516560, acc.: 72.66%] [G loss: 0.414040]\n",
      "epoch:4 step:3919 [D loss: 0.498491, acc.: 76.56%] [G loss: 0.516444]\n",
      "epoch:4 step:3920 [D loss: 0.534693, acc.: 75.00%] [G loss: 0.562443]\n",
      "epoch:4 step:3921 [D loss: 0.455003, acc.: 78.91%] [G loss: 0.642438]\n",
      "epoch:4 step:3922 [D loss: 0.522139, acc.: 75.00%] [G loss: 0.571501]\n",
      "epoch:4 step:3923 [D loss: 0.466376, acc.: 80.47%] [G loss: 0.644081]\n",
      "epoch:4 step:3924 [D loss: 0.528368, acc.: 71.88%] [G loss: 0.679865]\n",
      "epoch:4 step:3925 [D loss: 0.495556, acc.: 79.69%] [G loss: 0.663541]\n",
      "epoch:4 step:3926 [D loss: 0.506372, acc.: 70.31%] [G loss: 0.606116]\n",
      "epoch:4 step:3927 [D loss: 0.549303, acc.: 73.44%] [G loss: 0.657494]\n",
      "epoch:4 step:3928 [D loss: 0.595719, acc.: 70.31%] [G loss: 0.520112]\n",
      "epoch:4 step:3929 [D loss: 0.507767, acc.: 76.56%] [G loss: 0.671674]\n",
      "epoch:4 step:3930 [D loss: 0.560979, acc.: 71.88%] [G loss: 0.654280]\n",
      "epoch:4 step:3931 [D loss: 0.529626, acc.: 75.78%] [G loss: 0.613273]\n",
      "epoch:4 step:3932 [D loss: 0.548113, acc.: 71.09%] [G loss: 0.505353]\n",
      "epoch:4 step:3933 [D loss: 0.563521, acc.: 69.53%] [G loss: 0.506662]\n",
      "epoch:4 step:3934 [D loss: 0.532620, acc.: 79.69%] [G loss: 0.524767]\n",
      "epoch:4 step:3935 [D loss: 0.572544, acc.: 71.09%] [G loss: 0.507278]\n",
      "epoch:4 step:3936 [D loss: 0.506012, acc.: 75.78%] [G loss: 0.582457]\n",
      "epoch:4 step:3937 [D loss: 0.502260, acc.: 77.34%] [G loss: 0.632400]\n",
      "epoch:4 step:3938 [D loss: 0.458890, acc.: 80.47%] [G loss: 0.565798]\n",
      "epoch:4 step:3939 [D loss: 0.516059, acc.: 78.12%] [G loss: 0.672726]\n",
      "epoch:4 step:3940 [D loss: 0.524965, acc.: 76.56%] [G loss: 0.453145]\n",
      "epoch:4 step:3941 [D loss: 0.506358, acc.: 75.78%] [G loss: 0.595811]\n",
      "epoch:4 step:3942 [D loss: 0.456855, acc.: 80.47%] [G loss: 0.632396]\n",
      "epoch:4 step:3943 [D loss: 0.547873, acc.: 73.44%] [G loss: 0.518947]\n",
      "epoch:4 step:3944 [D loss: 0.562613, acc.: 67.19%] [G loss: 0.532545]\n",
      "epoch:4 step:3945 [D loss: 0.528399, acc.: 73.44%] [G loss: 0.729462]\n",
      "epoch:4 step:3946 [D loss: 0.460319, acc.: 82.81%] [G loss: 0.680114]\n",
      "epoch:4 step:3947 [D loss: 0.516005, acc.: 74.22%] [G loss: 0.646554]\n",
      "epoch:4 step:3948 [D loss: 0.596878, acc.: 65.62%] [G loss: 0.681117]\n",
      "epoch:4 step:3949 [D loss: 0.537902, acc.: 73.44%] [G loss: 0.494963]\n",
      "epoch:4 step:3950 [D loss: 0.553457, acc.: 69.53%] [G loss: 0.542954]\n",
      "epoch:4 step:3951 [D loss: 0.624754, acc.: 65.62%] [G loss: 0.538774]\n",
      "epoch:4 step:3952 [D loss: 0.463846, acc.: 79.69%] [G loss: 0.631630]\n",
      "epoch:4 step:3953 [D loss: 0.463350, acc.: 80.47%] [G loss: 0.697820]\n",
      "epoch:4 step:3954 [D loss: 0.523202, acc.: 71.09%] [G loss: 0.525825]\n",
      "epoch:4 step:3955 [D loss: 0.440831, acc.: 80.47%] [G loss: 0.615730]\n",
      "epoch:4 step:3956 [D loss: 0.435439, acc.: 86.72%] [G loss: 0.719040]\n",
      "epoch:4 step:3957 [D loss: 0.462593, acc.: 79.69%] [G loss: 0.622449]\n",
      "epoch:4 step:3958 [D loss: 0.559836, acc.: 70.31%] [G loss: 0.496265]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3959 [D loss: 0.547812, acc.: 71.09%] [G loss: 0.532739]\n",
      "epoch:4 step:3960 [D loss: 0.513132, acc.: 76.56%] [G loss: 0.528329]\n",
      "epoch:4 step:3961 [D loss: 0.474892, acc.: 79.69%] [G loss: 0.670336]\n",
      "epoch:4 step:3962 [D loss: 0.593229, acc.: 67.19%] [G loss: 0.456057]\n",
      "epoch:4 step:3963 [D loss: 0.559804, acc.: 73.44%] [G loss: 0.445132]\n",
      "epoch:4 step:3964 [D loss: 0.547206, acc.: 71.09%] [G loss: 0.551641]\n",
      "epoch:4 step:3965 [D loss: 0.475612, acc.: 75.00%] [G loss: 0.498518]\n",
      "epoch:4 step:3966 [D loss: 0.494712, acc.: 78.91%] [G loss: 0.580204]\n",
      "epoch:4 step:3967 [D loss: 0.515471, acc.: 79.69%] [G loss: 0.603305]\n",
      "epoch:4 step:3968 [D loss: 0.542587, acc.: 71.88%] [G loss: 0.467966]\n",
      "epoch:4 step:3969 [D loss: 0.484963, acc.: 76.56%] [G loss: 0.608883]\n",
      "epoch:4 step:3970 [D loss: 0.436314, acc.: 80.47%] [G loss: 0.819512]\n",
      "epoch:4 step:3971 [D loss: 0.468468, acc.: 80.47%] [G loss: 0.723012]\n",
      "epoch:4 step:3972 [D loss: 0.531062, acc.: 78.12%] [G loss: 0.601669]\n",
      "epoch:4 step:3973 [D loss: 0.592472, acc.: 66.41%] [G loss: 0.552134]\n",
      "epoch:4 step:3974 [D loss: 0.560279, acc.: 67.97%] [G loss: 0.447416]\n",
      "epoch:4 step:3975 [D loss: 0.541442, acc.: 68.75%] [G loss: 0.586985]\n",
      "epoch:4 step:3976 [D loss: 0.559816, acc.: 68.75%] [G loss: 0.537428]\n",
      "epoch:4 step:3977 [D loss: 0.497135, acc.: 75.78%] [G loss: 0.555617]\n",
      "epoch:4 step:3978 [D loss: 0.455336, acc.: 81.25%] [G loss: 0.631588]\n",
      "epoch:4 step:3979 [D loss: 0.471770, acc.: 77.34%] [G loss: 0.874621]\n",
      "epoch:4 step:3980 [D loss: 0.425256, acc.: 85.16%] [G loss: 0.832305]\n",
      "epoch:4 step:3981 [D loss: 0.583573, acc.: 67.19%] [G loss: 0.635126]\n",
      "epoch:4 step:3982 [D loss: 0.496547, acc.: 77.34%] [G loss: 0.605946]\n",
      "epoch:4 step:3983 [D loss: 0.497960, acc.: 76.56%] [G loss: 0.551506]\n",
      "epoch:4 step:3984 [D loss: 0.531445, acc.: 73.44%] [G loss: 0.615795]\n",
      "epoch:4 step:3985 [D loss: 0.499549, acc.: 78.12%] [G loss: 0.607640]\n",
      "epoch:4 step:3986 [D loss: 0.456180, acc.: 79.69%] [G loss: 0.626602]\n",
      "epoch:4 step:3987 [D loss: 0.549634, acc.: 76.56%] [G loss: 0.589458]\n",
      "epoch:4 step:3988 [D loss: 0.463762, acc.: 80.47%] [G loss: 0.688108]\n",
      "epoch:4 step:3989 [D loss: 0.558367, acc.: 69.53%] [G loss: 0.539447]\n",
      "epoch:4 step:3990 [D loss: 0.454366, acc.: 82.03%] [G loss: 0.590765]\n",
      "epoch:4 step:3991 [D loss: 0.529882, acc.: 71.88%] [G loss: 0.531500]\n",
      "epoch:4 step:3992 [D loss: 0.457325, acc.: 83.59%] [G loss: 0.663745]\n",
      "epoch:4 step:3993 [D loss: 0.485874, acc.: 85.16%] [G loss: 0.537771]\n",
      "epoch:4 step:3994 [D loss: 0.575414, acc.: 65.62%] [G loss: 0.587510]\n",
      "epoch:4 step:3995 [D loss: 0.588457, acc.: 64.84%] [G loss: 0.619804]\n",
      "epoch:4 step:3996 [D loss: 0.509095, acc.: 75.00%] [G loss: 0.642206]\n",
      "epoch:4 step:3997 [D loss: 0.556558, acc.: 70.31%] [G loss: 0.700301]\n",
      "epoch:4 step:3998 [D loss: 0.591189, acc.: 64.06%] [G loss: 0.534000]\n",
      "epoch:4 step:3999 [D loss: 0.577980, acc.: 72.66%] [G loss: 0.462056]\n",
      "epoch:4 step:4000 [D loss: 0.515321, acc.: 74.22%] [G loss: 0.485861]\n",
      "##############\n",
      "[3.52553076 1.53684654 6.90761442 5.38862782 4.41308665 6.4452465\n",
      " 5.61927741 5.28399499 5.39704291 3.69932882]\n",
      "##########\n",
      "epoch:4 step:4001 [D loss: 0.499329, acc.: 79.69%] [G loss: 0.478863]\n",
      "epoch:4 step:4002 [D loss: 0.434843, acc.: 82.03%] [G loss: 0.548560]\n",
      "epoch:4 step:4003 [D loss: 0.478728, acc.: 82.03%] [G loss: 0.543243]\n",
      "epoch:4 step:4004 [D loss: 0.485504, acc.: 78.91%] [G loss: 0.561671]\n",
      "epoch:4 step:4005 [D loss: 0.527186, acc.: 74.22%] [G loss: 0.656172]\n",
      "epoch:4 step:4006 [D loss: 0.497076, acc.: 73.44%] [G loss: 0.709463]\n",
      "epoch:4 step:4007 [D loss: 0.522428, acc.: 75.00%] [G loss: 0.606880]\n",
      "epoch:4 step:4008 [D loss: 0.525494, acc.: 73.44%] [G loss: 0.650529]\n",
      "epoch:4 step:4009 [D loss: 0.507381, acc.: 77.34%] [G loss: 0.542038]\n",
      "epoch:4 step:4010 [D loss: 0.519935, acc.: 77.34%] [G loss: 0.568775]\n",
      "epoch:4 step:4011 [D loss: 0.695116, acc.: 57.03%] [G loss: 0.472558]\n",
      "epoch:4 step:4012 [D loss: 0.515361, acc.: 75.78%] [G loss: 0.684015]\n",
      "epoch:4 step:4013 [D loss: 0.576009, acc.: 70.31%] [G loss: 0.481845]\n",
      "epoch:4 step:4014 [D loss: 0.495210, acc.: 75.00%] [G loss: 0.568812]\n",
      "epoch:4 step:4015 [D loss: 0.494782, acc.: 74.22%] [G loss: 0.539101]\n",
      "epoch:4 step:4016 [D loss: 0.481605, acc.: 79.69%] [G loss: 0.585920]\n",
      "epoch:4 step:4017 [D loss: 0.557286, acc.: 68.75%] [G loss: 0.522117]\n",
      "epoch:4 step:4018 [D loss: 0.470343, acc.: 79.69%] [G loss: 0.528921]\n",
      "epoch:4 step:4019 [D loss: 0.473266, acc.: 78.12%] [G loss: 0.558197]\n",
      "epoch:4 step:4020 [D loss: 0.549106, acc.: 72.66%] [G loss: 0.509750]\n",
      "epoch:4 step:4021 [D loss: 0.512963, acc.: 75.00%] [G loss: 0.511562]\n",
      "epoch:4 step:4022 [D loss: 0.533388, acc.: 73.44%] [G loss: 0.669631]\n",
      "epoch:4 step:4023 [D loss: 0.540913, acc.: 73.44%] [G loss: 0.525158]\n",
      "epoch:4 step:4024 [D loss: 0.543284, acc.: 71.09%] [G loss: 0.465780]\n",
      "epoch:4 step:4025 [D loss: 0.620622, acc.: 64.06%] [G loss: 0.558747]\n",
      "epoch:4 step:4026 [D loss: 0.569461, acc.: 71.09%] [G loss: 0.475481]\n",
      "epoch:4 step:4027 [D loss: 0.549626, acc.: 75.78%] [G loss: 0.690548]\n",
      "epoch:4 step:4028 [D loss: 0.566366, acc.: 71.88%] [G loss: 0.668846]\n",
      "epoch:4 step:4029 [D loss: 0.595965, acc.: 69.53%] [G loss: 0.380906]\n",
      "epoch:4 step:4030 [D loss: 0.545113, acc.: 75.78%] [G loss: 0.530354]\n",
      "epoch:4 step:4031 [D loss: 0.485374, acc.: 80.47%] [G loss: 0.474009]\n",
      "epoch:4 step:4032 [D loss: 0.454390, acc.: 77.34%] [G loss: 0.589251]\n",
      "epoch:4 step:4033 [D loss: 0.484786, acc.: 74.22%] [G loss: 0.529327]\n",
      "epoch:4 step:4034 [D loss: 0.479972, acc.: 80.47%] [G loss: 0.536000]\n",
      "epoch:4 step:4035 [D loss: 0.580202, acc.: 67.19%] [G loss: 0.562084]\n",
      "epoch:4 step:4036 [D loss: 0.591197, acc.: 63.28%] [G loss: 0.515998]\n",
      "epoch:4 step:4037 [D loss: 0.523629, acc.: 78.12%] [G loss: 0.577844]\n",
      "epoch:4 step:4038 [D loss: 0.477435, acc.: 79.69%] [G loss: 0.593344]\n",
      "epoch:4 step:4039 [D loss: 0.580055, acc.: 69.53%] [G loss: 0.460931]\n",
      "epoch:4 step:4040 [D loss: 0.505553, acc.: 75.00%] [G loss: 0.640602]\n",
      "epoch:4 step:4041 [D loss: 0.487029, acc.: 77.34%] [G loss: 0.520034]\n",
      "epoch:4 step:4042 [D loss: 0.506184, acc.: 75.00%] [G loss: 0.547278]\n",
      "epoch:4 step:4043 [D loss: 0.528866, acc.: 72.66%] [G loss: 0.480166]\n",
      "epoch:4 step:4044 [D loss: 0.452160, acc.: 86.72%] [G loss: 0.576561]\n",
      "epoch:4 step:4045 [D loss: 0.517752, acc.: 76.56%] [G loss: 0.573298]\n",
      "epoch:4 step:4046 [D loss: 0.527146, acc.: 75.78%] [G loss: 0.494271]\n",
      "epoch:4 step:4047 [D loss: 0.529439, acc.: 75.00%] [G loss: 0.586364]\n",
      "epoch:4 step:4048 [D loss: 0.494699, acc.: 75.78%] [G loss: 0.559437]\n",
      "epoch:4 step:4049 [D loss: 0.555496, acc.: 72.66%] [G loss: 0.573265]\n",
      "epoch:4 step:4050 [D loss: 0.487476, acc.: 75.78%] [G loss: 0.561577]\n",
      "epoch:4 step:4051 [D loss: 0.496508, acc.: 76.56%] [G loss: 0.609842]\n",
      "epoch:4 step:4052 [D loss: 0.448947, acc.: 79.69%] [G loss: 0.706976]\n",
      "epoch:4 step:4053 [D loss: 0.481123, acc.: 77.34%] [G loss: 0.602905]\n",
      "epoch:4 step:4054 [D loss: 0.484678, acc.: 77.34%] [G loss: 0.710158]\n",
      "epoch:4 step:4055 [D loss: 0.452310, acc.: 83.59%] [G loss: 0.646367]\n",
      "epoch:4 step:4056 [D loss: 0.523653, acc.: 71.88%] [G loss: 0.675824]\n",
      "epoch:4 step:4057 [D loss: 0.478183, acc.: 77.34%] [G loss: 0.712007]\n",
      "epoch:4 step:4058 [D loss: 0.439496, acc.: 79.69%] [G loss: 0.769793]\n",
      "epoch:4 step:4059 [D loss: 0.474146, acc.: 75.78%] [G loss: 0.765133]\n",
      "epoch:4 step:4060 [D loss: 0.414201, acc.: 86.72%] [G loss: 0.726835]\n",
      "epoch:4 step:4061 [D loss: 0.448220, acc.: 82.03%] [G loss: 0.783979]\n",
      "epoch:4 step:4062 [D loss: 0.392249, acc.: 84.38%] [G loss: 0.855712]\n",
      "epoch:4 step:4063 [D loss: 0.421566, acc.: 79.69%] [G loss: 0.825791]\n",
      "epoch:4 step:4064 [D loss: 0.641139, acc.: 67.97%] [G loss: 0.503011]\n",
      "epoch:4 step:4065 [D loss: 0.531514, acc.: 72.66%] [G loss: 0.565981]\n",
      "epoch:4 step:4066 [D loss: 0.506284, acc.: 76.56%] [G loss: 0.535081]\n",
      "epoch:4 step:4067 [D loss: 0.506686, acc.: 77.34%] [G loss: 0.633203]\n",
      "epoch:4 step:4068 [D loss: 0.461658, acc.: 78.91%] [G loss: 0.803079]\n",
      "epoch:4 step:4069 [D loss: 0.477846, acc.: 73.44%] [G loss: 0.669084]\n",
      "epoch:4 step:4070 [D loss: 0.532083, acc.: 72.66%] [G loss: 0.648338]\n",
      "epoch:4 step:4071 [D loss: 0.634390, acc.: 62.50%] [G loss: 0.464292]\n",
      "epoch:4 step:4072 [D loss: 0.530871, acc.: 76.56%] [G loss: 0.410485]\n",
      "epoch:4 step:4073 [D loss: 0.493297, acc.: 77.34%] [G loss: 0.453663]\n",
      "epoch:4 step:4074 [D loss: 0.459661, acc.: 78.12%] [G loss: 0.651990]\n",
      "epoch:4 step:4075 [D loss: 0.478311, acc.: 79.69%] [G loss: 0.628719]\n",
      "epoch:4 step:4076 [D loss: 0.500122, acc.: 73.44%] [G loss: 0.688017]\n",
      "epoch:4 step:4077 [D loss: 0.514585, acc.: 75.00%] [G loss: 0.669012]\n",
      "epoch:4 step:4078 [D loss: 0.516645, acc.: 73.44%] [G loss: 0.630274]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4079 [D loss: 0.480146, acc.: 79.69%] [G loss: 0.556682]\n",
      "epoch:4 step:4080 [D loss: 0.438837, acc.: 82.81%] [G loss: 0.601564]\n",
      "epoch:4 step:4081 [D loss: 0.495701, acc.: 78.91%] [G loss: 0.539990]\n",
      "epoch:4 step:4082 [D loss: 0.509477, acc.: 76.56%] [G loss: 0.689715]\n",
      "epoch:4 step:4083 [D loss: 0.533308, acc.: 71.88%] [G loss: 0.788532]\n",
      "epoch:4 step:4084 [D loss: 0.483691, acc.: 75.00%] [G loss: 0.845895]\n",
      "epoch:4 step:4085 [D loss: 0.501911, acc.: 78.12%] [G loss: 0.868940]\n",
      "epoch:4 step:4086 [D loss: 0.536720, acc.: 69.53%] [G loss: 0.680888]\n",
      "epoch:4 step:4087 [D loss: 0.484493, acc.: 79.69%] [G loss: 0.718971]\n",
      "epoch:4 step:4088 [D loss: 0.470088, acc.: 82.81%] [G loss: 0.630632]\n",
      "epoch:4 step:4089 [D loss: 0.497633, acc.: 79.69%] [G loss: 0.497914]\n",
      "epoch:4 step:4090 [D loss: 0.541578, acc.: 77.34%] [G loss: 0.593631]\n",
      "epoch:4 step:4091 [D loss: 0.420679, acc.: 80.47%] [G loss: 0.649815]\n",
      "epoch:4 step:4092 [D loss: 0.385334, acc.: 84.38%] [G loss: 0.882656]\n",
      "epoch:4 step:4093 [D loss: 0.459702, acc.: 80.47%] [G loss: 0.865345]\n",
      "epoch:4 step:4094 [D loss: 0.508579, acc.: 75.78%] [G loss: 0.960343]\n",
      "epoch:4 step:4095 [D loss: 0.449301, acc.: 78.91%] [G loss: 0.946257]\n",
      "epoch:4 step:4096 [D loss: 0.595321, acc.: 71.88%] [G loss: 0.659165]\n",
      "epoch:4 step:4097 [D loss: 0.645166, acc.: 64.84%] [G loss: 0.473440]\n",
      "epoch:4 step:4098 [D loss: 0.443641, acc.: 82.81%] [G loss: 0.537728]\n",
      "epoch:4 step:4099 [D loss: 0.481423, acc.: 79.69%] [G loss: 0.648057]\n",
      "epoch:4 step:4100 [D loss: 0.525967, acc.: 75.00%] [G loss: 0.621914]\n",
      "epoch:4 step:4101 [D loss: 0.498668, acc.: 75.00%] [G loss: 0.678321]\n",
      "epoch:4 step:4102 [D loss: 0.478271, acc.: 75.78%] [G loss: 0.561843]\n",
      "epoch:4 step:4103 [D loss: 0.533751, acc.: 72.66%] [G loss: 0.627263]\n",
      "epoch:4 step:4104 [D loss: 0.544098, acc.: 71.09%] [G loss: 0.625827]\n",
      "epoch:4 step:4105 [D loss: 0.487898, acc.: 75.78%] [G loss: 0.553060]\n",
      "epoch:4 step:4106 [D loss: 0.423045, acc.: 78.91%] [G loss: 0.828224]\n",
      "epoch:4 step:4107 [D loss: 0.455889, acc.: 78.91%] [G loss: 0.719298]\n",
      "epoch:4 step:4108 [D loss: 0.467082, acc.: 82.03%] [G loss: 0.778106]\n",
      "epoch:4 step:4109 [D loss: 0.517773, acc.: 71.09%] [G loss: 0.534058]\n",
      "epoch:4 step:4110 [D loss: 0.458722, acc.: 82.03%] [G loss: 0.736308]\n",
      "epoch:4 step:4111 [D loss: 0.484438, acc.: 78.91%] [G loss: 0.642736]\n",
      "epoch:4 step:4112 [D loss: 0.488559, acc.: 75.00%] [G loss: 0.510622]\n",
      "epoch:4 step:4113 [D loss: 0.476593, acc.: 80.47%] [G loss: 0.681353]\n",
      "epoch:4 step:4114 [D loss: 0.457549, acc.: 80.47%] [G loss: 0.696614]\n",
      "epoch:4 step:4115 [D loss: 0.492697, acc.: 75.78%] [G loss: 0.685495]\n",
      "epoch:4 step:4116 [D loss: 0.562454, acc.: 69.53%] [G loss: 0.588265]\n",
      "epoch:4 step:4117 [D loss: 0.492973, acc.: 78.12%] [G loss: 0.484804]\n",
      "epoch:4 step:4118 [D loss: 0.524791, acc.: 71.09%] [G loss: 0.600650]\n",
      "epoch:4 step:4119 [D loss: 0.520794, acc.: 73.44%] [G loss: 0.582614]\n",
      "epoch:4 step:4120 [D loss: 0.489890, acc.: 79.69%] [G loss: 0.756735]\n",
      "epoch:4 step:4121 [D loss: 0.552129, acc.: 67.97%] [G loss: 0.654450]\n",
      "epoch:4 step:4122 [D loss: 0.430490, acc.: 83.59%] [G loss: 0.802863]\n",
      "epoch:4 step:4123 [D loss: 0.594962, acc.: 69.53%] [G loss: 0.652739]\n",
      "epoch:4 step:4124 [D loss: 0.690382, acc.: 57.03%] [G loss: 0.404759]\n",
      "epoch:4 step:4125 [D loss: 0.570179, acc.: 70.31%] [G loss: 0.561806]\n",
      "epoch:4 step:4126 [D loss: 0.522014, acc.: 74.22%] [G loss: 0.549636]\n",
      "epoch:4 step:4127 [D loss: 0.532282, acc.: 77.34%] [G loss: 0.438356]\n",
      "epoch:4 step:4128 [D loss: 0.580038, acc.: 72.66%] [G loss: 0.431678]\n",
      "epoch:4 step:4129 [D loss: 0.451227, acc.: 78.91%] [G loss: 0.585030]\n",
      "epoch:4 step:4130 [D loss: 0.489697, acc.: 75.78%] [G loss: 0.655726]\n",
      "epoch:4 step:4131 [D loss: 0.503588, acc.: 73.44%] [G loss: 0.629849]\n",
      "epoch:4 step:4132 [D loss: 0.532157, acc.: 69.53%] [G loss: 0.534550]\n",
      "epoch:4 step:4133 [D loss: 0.533758, acc.: 68.75%] [G loss: 0.546784]\n",
      "epoch:4 step:4134 [D loss: 0.578555, acc.: 68.75%] [G loss: 0.434131]\n",
      "epoch:4 step:4135 [D loss: 0.591945, acc.: 67.97%] [G loss: 0.663127]\n",
      "epoch:4 step:4136 [D loss: 0.526286, acc.: 72.66%] [G loss: 0.729608]\n",
      "epoch:4 step:4137 [D loss: 0.538374, acc.: 70.31%] [G loss: 0.571831]\n",
      "epoch:4 step:4138 [D loss: 0.532204, acc.: 75.78%] [G loss: 0.600458]\n",
      "epoch:4 step:4139 [D loss: 0.523559, acc.: 74.22%] [G loss: 0.494612]\n",
      "epoch:4 step:4140 [D loss: 0.467070, acc.: 80.47%] [G loss: 0.548382]\n",
      "epoch:4 step:4141 [D loss: 0.503627, acc.: 75.00%] [G loss: 0.551316]\n",
      "epoch:4 step:4142 [D loss: 0.503561, acc.: 77.34%] [G loss: 0.490033]\n",
      "epoch:4 step:4143 [D loss: 0.485109, acc.: 78.91%] [G loss: 0.491428]\n",
      "epoch:4 step:4144 [D loss: 0.594558, acc.: 64.06%] [G loss: 0.585518]\n",
      "epoch:4 step:4145 [D loss: 0.454732, acc.: 81.25%] [G loss: 0.718740]\n",
      "epoch:4 step:4146 [D loss: 0.437735, acc.: 78.91%] [G loss: 0.929679]\n",
      "epoch:4 step:4147 [D loss: 0.452475, acc.: 81.25%] [G loss: 0.768523]\n",
      "epoch:4 step:4148 [D loss: 0.574178, acc.: 71.09%] [G loss: 0.595503]\n",
      "epoch:4 step:4149 [D loss: 0.564136, acc.: 67.97%] [G loss: 0.472848]\n",
      "epoch:4 step:4150 [D loss: 0.439515, acc.: 80.47%] [G loss: 0.627990]\n",
      "epoch:4 step:4151 [D loss: 0.540896, acc.: 71.09%] [G loss: 0.614479]\n",
      "epoch:4 step:4152 [D loss: 0.599370, acc.: 66.41%] [G loss: 0.629954]\n",
      "epoch:4 step:4153 [D loss: 0.513428, acc.: 80.47%] [G loss: 0.589285]\n",
      "epoch:4 step:4154 [D loss: 0.482570, acc.: 78.91%] [G loss: 0.642299]\n",
      "epoch:4 step:4155 [D loss: 0.498866, acc.: 78.12%] [G loss: 0.652370]\n",
      "epoch:4 step:4156 [D loss: 0.514437, acc.: 71.88%] [G loss: 0.600567]\n",
      "epoch:4 step:4157 [D loss: 0.505411, acc.: 78.12%] [G loss: 0.559490]\n",
      "epoch:4 step:4158 [D loss: 0.535612, acc.: 72.66%] [G loss: 0.471792]\n",
      "epoch:4 step:4159 [D loss: 0.535753, acc.: 72.66%] [G loss: 0.551001]\n",
      "epoch:4 step:4160 [D loss: 0.585488, acc.: 63.28%] [G loss: 0.533262]\n",
      "epoch:4 step:4161 [D loss: 0.547468, acc.: 74.22%] [G loss: 0.646702]\n",
      "epoch:4 step:4162 [D loss: 0.544103, acc.: 72.66%] [G loss: 0.809592]\n",
      "epoch:4 step:4163 [D loss: 0.518365, acc.: 76.56%] [G loss: 0.561143]\n",
      "epoch:4 step:4164 [D loss: 0.499348, acc.: 77.34%] [G loss: 0.615761]\n",
      "epoch:4 step:4165 [D loss: 0.623330, acc.: 65.62%] [G loss: 0.644404]\n",
      "epoch:4 step:4166 [D loss: 0.594466, acc.: 65.62%] [G loss: 0.619991]\n",
      "epoch:4 step:4167 [D loss: 0.487310, acc.: 77.34%] [G loss: 0.544998]\n",
      "epoch:4 step:4168 [D loss: 0.531507, acc.: 69.53%] [G loss: 0.539001]\n",
      "epoch:4 step:4169 [D loss: 0.622611, acc.: 62.50%] [G loss: 0.462094]\n",
      "epoch:4 step:4170 [D loss: 0.508716, acc.: 78.91%] [G loss: 0.612155]\n",
      "epoch:4 step:4171 [D loss: 0.557258, acc.: 73.44%] [G loss: 0.563963]\n",
      "epoch:4 step:4172 [D loss: 0.516158, acc.: 74.22%] [G loss: 0.582158]\n",
      "epoch:4 step:4173 [D loss: 0.515500, acc.: 75.78%] [G loss: 0.577726]\n",
      "epoch:4 step:4174 [D loss: 0.534559, acc.: 75.78%] [G loss: 0.721974]\n",
      "epoch:4 step:4175 [D loss: 0.448360, acc.: 82.81%] [G loss: 0.768568]\n",
      "epoch:4 step:4176 [D loss: 0.490726, acc.: 76.56%] [G loss: 0.688959]\n",
      "epoch:4 step:4177 [D loss: 0.524588, acc.: 75.78%] [G loss: 0.635981]\n",
      "epoch:4 step:4178 [D loss: 0.486037, acc.: 79.69%] [G loss: 0.634366]\n",
      "epoch:4 step:4179 [D loss: 0.462112, acc.: 82.03%] [G loss: 0.662111]\n",
      "epoch:4 step:4180 [D loss: 0.602985, acc.: 62.50%] [G loss: 0.572638]\n",
      "epoch:4 step:4181 [D loss: 0.537488, acc.: 76.56%] [G loss: 0.565949]\n",
      "epoch:4 step:4182 [D loss: 0.487992, acc.: 80.47%] [G loss: 0.570686]\n",
      "epoch:4 step:4183 [D loss: 0.521495, acc.: 78.12%] [G loss: 0.587842]\n",
      "epoch:4 step:4184 [D loss: 0.510570, acc.: 71.09%] [G loss: 0.606231]\n",
      "epoch:4 step:4185 [D loss: 0.639337, acc.: 67.19%] [G loss: 0.487843]\n",
      "epoch:4 step:4186 [D loss: 0.523512, acc.: 77.34%] [G loss: 0.443009]\n",
      "epoch:4 step:4187 [D loss: 0.475991, acc.: 80.47%] [G loss: 0.569209]\n",
      "epoch:4 step:4188 [D loss: 0.538197, acc.: 75.00%] [G loss: 0.389664]\n",
      "epoch:4 step:4189 [D loss: 0.511114, acc.: 75.78%] [G loss: 0.575189]\n",
      "epoch:4 step:4190 [D loss: 0.528766, acc.: 75.78%] [G loss: 0.519949]\n",
      "epoch:4 step:4191 [D loss: 0.498122, acc.: 76.56%] [G loss: 0.735994]\n",
      "epoch:4 step:4192 [D loss: 0.486062, acc.: 77.34%] [G loss: 0.700162]\n",
      "epoch:4 step:4193 [D loss: 0.506917, acc.: 75.78%] [G loss: 0.559887]\n",
      "epoch:4 step:4194 [D loss: 0.501517, acc.: 70.31%] [G loss: 0.587022]\n",
      "epoch:4 step:4195 [D loss: 0.526110, acc.: 71.09%] [G loss: 0.699332]\n",
      "epoch:4 step:4196 [D loss: 0.556024, acc.: 73.44%] [G loss: 0.657060]\n",
      "epoch:4 step:4197 [D loss: 0.538564, acc.: 72.66%] [G loss: 0.608045]\n",
      "epoch:4 step:4198 [D loss: 0.445610, acc.: 78.12%] [G loss: 0.626836]\n",
      "epoch:4 step:4199 [D loss: 0.409668, acc.: 85.16%] [G loss: 0.647170]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4200 [D loss: 0.525448, acc.: 74.22%] [G loss: 0.737198]\n",
      "##############\n",
      "[3.34546075 1.65795299 6.55027542 5.04721507 4.35108523 6.29794071\n",
      " 5.18059717 5.14099482 5.12653845 4.1092111 ]\n",
      "##########\n",
      "epoch:4 step:4201 [D loss: 0.506381, acc.: 74.22%] [G loss: 0.642440]\n",
      "epoch:4 step:4202 [D loss: 0.564777, acc.: 69.53%] [G loss: 0.534547]\n",
      "epoch:4 step:4203 [D loss: 0.563065, acc.: 73.44%] [G loss: 0.614220]\n",
      "epoch:4 step:4204 [D loss: 0.591513, acc.: 67.97%] [G loss: 0.527984]\n",
      "epoch:4 step:4205 [D loss: 0.500494, acc.: 76.56%] [G loss: 0.519124]\n",
      "epoch:4 step:4206 [D loss: 0.557969, acc.: 68.75%] [G loss: 0.592859]\n",
      "epoch:4 step:4207 [D loss: 0.538252, acc.: 73.44%] [G loss: 0.593000]\n",
      "epoch:4 step:4208 [D loss: 0.495817, acc.: 75.00%] [G loss: 0.567433]\n",
      "epoch:4 step:4209 [D loss: 0.525765, acc.: 71.09%] [G loss: 0.503113]\n",
      "epoch:4 step:4210 [D loss: 0.578444, acc.: 67.19%] [G loss: 0.550112]\n",
      "epoch:4 step:4211 [D loss: 0.560890, acc.: 69.53%] [G loss: 0.476063]\n",
      "epoch:4 step:4212 [D loss: 0.484211, acc.: 79.69%] [G loss: 0.503234]\n",
      "epoch:4 step:4213 [D loss: 0.567719, acc.: 72.66%] [G loss: 0.500086]\n",
      "epoch:4 step:4214 [D loss: 0.543721, acc.: 73.44%] [G loss: 0.437993]\n",
      "epoch:4 step:4215 [D loss: 0.450173, acc.: 81.25%] [G loss: 0.635903]\n",
      "epoch:4 step:4216 [D loss: 0.565746, acc.: 71.88%] [G loss: 0.527128]\n",
      "epoch:4 step:4217 [D loss: 0.530204, acc.: 73.44%] [G loss: 0.654710]\n",
      "epoch:4 step:4218 [D loss: 0.492104, acc.: 78.12%] [G loss: 0.665029]\n",
      "epoch:4 step:4219 [D loss: 0.503451, acc.: 75.78%] [G loss: 0.619760]\n",
      "epoch:4 step:4220 [D loss: 0.452904, acc.: 80.47%] [G loss: 0.772585]\n",
      "epoch:4 step:4221 [D loss: 0.563232, acc.: 72.66%] [G loss: 0.629247]\n",
      "epoch:4 step:4222 [D loss: 0.432589, acc.: 83.59%] [G loss: 0.674671]\n",
      "epoch:4 step:4223 [D loss: 0.433548, acc.: 83.59%] [G loss: 0.745025]\n",
      "epoch:4 step:4224 [D loss: 0.539371, acc.: 71.09%] [G loss: 0.668590]\n",
      "epoch:4 step:4225 [D loss: 0.664588, acc.: 59.38%] [G loss: 0.415525]\n",
      "epoch:4 step:4226 [D loss: 0.567924, acc.: 72.66%] [G loss: 0.451277]\n",
      "epoch:4 step:4227 [D loss: 0.529709, acc.: 71.88%] [G loss: 0.483476]\n",
      "epoch:4 step:4228 [D loss: 0.527474, acc.: 82.03%] [G loss: 0.488430]\n",
      "epoch:4 step:4229 [D loss: 0.545879, acc.: 73.44%] [G loss: 0.633248]\n",
      "epoch:4 step:4230 [D loss: 0.598189, acc.: 67.97%] [G loss: 0.493923]\n",
      "epoch:4 step:4231 [D loss: 0.539672, acc.: 74.22%] [G loss: 0.701963]\n",
      "epoch:4 step:4232 [D loss: 0.513180, acc.: 77.34%] [G loss: 0.743322]\n",
      "epoch:4 step:4233 [D loss: 0.544742, acc.: 72.66%] [G loss: 0.579341]\n",
      "epoch:4 step:4234 [D loss: 0.535568, acc.: 73.44%] [G loss: 0.584400]\n",
      "epoch:4 step:4235 [D loss: 0.537397, acc.: 71.88%] [G loss: 0.570526]\n",
      "epoch:4 step:4236 [D loss: 0.472502, acc.: 76.56%] [G loss: 0.670849]\n",
      "epoch:4 step:4237 [D loss: 0.588811, acc.: 64.84%] [G loss: 0.658868]\n",
      "epoch:4 step:4238 [D loss: 0.516078, acc.: 72.66%] [G loss: 0.623636]\n",
      "epoch:4 step:4239 [D loss: 0.506474, acc.: 71.09%] [G loss: 0.576499]\n",
      "epoch:4 step:4240 [D loss: 0.539877, acc.: 73.44%] [G loss: 0.531221]\n",
      "epoch:4 step:4241 [D loss: 0.543148, acc.: 70.31%] [G loss: 0.492317]\n",
      "epoch:4 step:4242 [D loss: 0.531863, acc.: 75.00%] [G loss: 0.397810]\n",
      "epoch:4 step:4243 [D loss: 0.506464, acc.: 77.34%] [G loss: 0.535390]\n",
      "epoch:4 step:4244 [D loss: 0.548235, acc.: 72.66%] [G loss: 0.629684]\n",
      "epoch:4 step:4245 [D loss: 0.468782, acc.: 80.47%] [G loss: 0.685527]\n",
      "epoch:4 step:4246 [D loss: 0.453753, acc.: 81.25%] [G loss: 0.705883]\n",
      "epoch:4 step:4247 [D loss: 0.449216, acc.: 78.12%] [G loss: 0.768482]\n",
      "epoch:4 step:4248 [D loss: 0.619860, acc.: 64.06%] [G loss: 0.615764]\n",
      "epoch:4 step:4249 [D loss: 0.616386, acc.: 65.62%] [G loss: 0.441172]\n",
      "epoch:4 step:4250 [D loss: 0.611242, acc.: 61.72%] [G loss: 0.518967]\n",
      "epoch:4 step:4251 [D loss: 0.512039, acc.: 76.56%] [G loss: 0.630419]\n",
      "epoch:4 step:4252 [D loss: 0.515869, acc.: 75.78%] [G loss: 0.648720]\n",
      "epoch:4 step:4253 [D loss: 0.557925, acc.: 69.53%] [G loss: 0.595363]\n",
      "epoch:4 step:4254 [D loss: 0.515813, acc.: 75.00%] [G loss: 0.561044]\n",
      "epoch:4 step:4255 [D loss: 0.497016, acc.: 76.56%] [G loss: 0.741138]\n",
      "epoch:4 step:4256 [D loss: 0.517587, acc.: 78.91%] [G loss: 0.602452]\n",
      "epoch:4 step:4257 [D loss: 0.473004, acc.: 81.25%] [G loss: 0.586922]\n",
      "epoch:4 step:4258 [D loss: 0.562725, acc.: 68.75%] [G loss: 0.524977]\n",
      "epoch:4 step:4259 [D loss: 0.553846, acc.: 70.31%] [G loss: 0.592773]\n",
      "epoch:4 step:4260 [D loss: 0.508637, acc.: 76.56%] [G loss: 0.586840]\n",
      "epoch:4 step:4261 [D loss: 0.478365, acc.: 81.25%] [G loss: 0.534104]\n",
      "epoch:4 step:4262 [D loss: 0.531083, acc.: 68.75%] [G loss: 0.655039]\n",
      "epoch:4 step:4263 [D loss: 0.486530, acc.: 78.12%] [G loss: 0.732254]\n",
      "epoch:4 step:4264 [D loss: 0.420174, acc.: 83.59%] [G loss: 0.718705]\n",
      "epoch:4 step:4265 [D loss: 0.554991, acc.: 67.19%] [G loss: 0.574812]\n",
      "epoch:4 step:4266 [D loss: 0.473518, acc.: 77.34%] [G loss: 0.612519]\n",
      "epoch:4 step:4267 [D loss: 0.546682, acc.: 71.88%] [G loss: 0.593320]\n",
      "epoch:4 step:4268 [D loss: 0.478831, acc.: 77.34%] [G loss: 0.541702]\n",
      "epoch:4 step:4269 [D loss: 0.504719, acc.: 77.34%] [G loss: 0.560444]\n",
      "epoch:4 step:4270 [D loss: 0.491951, acc.: 74.22%] [G loss: 0.526275]\n",
      "epoch:4 step:4271 [D loss: 0.460020, acc.: 78.91%] [G loss: 0.727617]\n",
      "epoch:4 step:4272 [D loss: 0.506936, acc.: 72.66%] [G loss: 0.580685]\n",
      "epoch:4 step:4273 [D loss: 0.568135, acc.: 68.75%] [G loss: 0.527405]\n",
      "epoch:4 step:4274 [D loss: 0.509377, acc.: 69.53%] [G loss: 0.541553]\n",
      "epoch:4 step:4275 [D loss: 0.542026, acc.: 70.31%] [G loss: 0.479167]\n",
      "epoch:4 step:4276 [D loss: 0.619921, acc.: 64.06%] [G loss: 0.501710]\n",
      "epoch:4 step:4277 [D loss: 0.551724, acc.: 74.22%] [G loss: 0.475635]\n",
      "epoch:4 step:4278 [D loss: 0.465159, acc.: 79.69%] [G loss: 0.650775]\n",
      "epoch:4 step:4279 [D loss: 0.544685, acc.: 71.09%] [G loss: 0.418928]\n",
      "epoch:4 step:4280 [D loss: 0.536690, acc.: 73.44%] [G loss: 0.545064]\n",
      "epoch:4 step:4281 [D loss: 0.568247, acc.: 73.44%] [G loss: 0.485987]\n",
      "epoch:4 step:4282 [D loss: 0.498082, acc.: 78.91%] [G loss: 0.505874]\n",
      "epoch:4 step:4283 [D loss: 0.522181, acc.: 77.34%] [G loss: 0.569740]\n",
      "epoch:4 step:4284 [D loss: 0.472697, acc.: 79.69%] [G loss: 0.655685]\n",
      "epoch:4 step:4285 [D loss: 0.518167, acc.: 76.56%] [G loss: 0.639897]\n",
      "epoch:4 step:4286 [D loss: 0.588439, acc.: 69.53%] [G loss: 0.495621]\n",
      "epoch:4 step:4287 [D loss: 0.547984, acc.: 75.00%] [G loss: 0.616322]\n",
      "epoch:4 step:4288 [D loss: 0.535106, acc.: 75.00%] [G loss: 0.507902]\n",
      "epoch:4 step:4289 [D loss: 0.512038, acc.: 76.56%] [G loss: 0.565364]\n",
      "epoch:4 step:4290 [D loss: 0.546664, acc.: 74.22%] [G loss: 0.527587]\n",
      "epoch:4 step:4291 [D loss: 0.563756, acc.: 71.88%] [G loss: 0.536803]\n",
      "epoch:4 step:4292 [D loss: 0.498831, acc.: 77.34%] [G loss: 0.624876]\n",
      "epoch:4 step:4293 [D loss: 0.530776, acc.: 72.66%] [G loss: 0.580578]\n",
      "epoch:4 step:4294 [D loss: 0.530201, acc.: 78.12%] [G loss: 0.626022]\n",
      "epoch:4 step:4295 [D loss: 0.519015, acc.: 71.88%] [G loss: 0.608387]\n",
      "epoch:4 step:4296 [D loss: 0.486248, acc.: 76.56%] [G loss: 0.653749]\n",
      "epoch:4 step:4297 [D loss: 0.485285, acc.: 77.34%] [G loss: 0.685381]\n",
      "epoch:4 step:4298 [D loss: 0.528077, acc.: 76.56%] [G loss: 0.516151]\n",
      "epoch:4 step:4299 [D loss: 0.545518, acc.: 69.53%] [G loss: 0.659704]\n",
      "epoch:4 step:4300 [D loss: 0.480337, acc.: 78.12%] [G loss: 0.513979]\n",
      "epoch:4 step:4301 [D loss: 0.529596, acc.: 72.66%] [G loss: 0.606831]\n",
      "epoch:4 step:4302 [D loss: 0.430824, acc.: 82.81%] [G loss: 0.559715]\n",
      "epoch:4 step:4303 [D loss: 0.478232, acc.: 76.56%] [G loss: 0.648914]\n",
      "epoch:4 step:4304 [D loss: 0.435440, acc.: 79.69%] [G loss: 0.711802]\n",
      "epoch:4 step:4305 [D loss: 0.529534, acc.: 73.44%] [G loss: 0.641044]\n",
      "epoch:4 step:4306 [D loss: 0.461275, acc.: 77.34%] [G loss: 0.666793]\n",
      "epoch:4 step:4307 [D loss: 0.577478, acc.: 65.62%] [G loss: 0.603480]\n",
      "epoch:4 step:4308 [D loss: 0.570817, acc.: 68.75%] [G loss: 0.537236]\n",
      "epoch:4 step:4309 [D loss: 0.502946, acc.: 78.91%] [G loss: 0.600509]\n",
      "epoch:4 step:4310 [D loss: 0.617737, acc.: 64.84%] [G loss: 0.517126]\n",
      "epoch:4 step:4311 [D loss: 0.568390, acc.: 67.97%] [G loss: 0.673842]\n",
      "epoch:4 step:4312 [D loss: 0.483229, acc.: 81.25%] [G loss: 0.618307]\n",
      "epoch:4 step:4313 [D loss: 0.533204, acc.: 73.44%] [G loss: 0.623385]\n",
      "epoch:4 step:4314 [D loss: 0.609174, acc.: 67.97%] [G loss: 0.464103]\n",
      "epoch:4 step:4315 [D loss: 0.471886, acc.: 82.81%] [G loss: 0.595934]\n",
      "epoch:4 step:4316 [D loss: 0.504510, acc.: 71.88%] [G loss: 0.599269]\n",
      "epoch:4 step:4317 [D loss: 0.502131, acc.: 78.12%] [G loss: 0.543246]\n",
      "epoch:4 step:4318 [D loss: 0.506250, acc.: 75.78%] [G loss: 0.587333]\n",
      "epoch:4 step:4319 [D loss: 0.533103, acc.: 69.53%] [G loss: 0.565147]\n",
      "epoch:4 step:4320 [D loss: 0.626122, acc.: 71.88%] [G loss: 0.639952]\n",
      "epoch:4 step:4321 [D loss: 0.529236, acc.: 75.78%] [G loss: 0.588247]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4322 [D loss: 0.490698, acc.: 76.56%] [G loss: 0.564323]\n",
      "epoch:4 step:4323 [D loss: 0.488149, acc.: 76.56%] [G loss: 0.679971]\n",
      "epoch:4 step:4324 [D loss: 0.526838, acc.: 73.44%] [G loss: 0.608795]\n",
      "epoch:4 step:4325 [D loss: 0.534519, acc.: 70.31%] [G loss: 0.745687]\n",
      "epoch:4 step:4326 [D loss: 0.470745, acc.: 81.25%] [G loss: 0.553733]\n",
      "epoch:4 step:4327 [D loss: 0.499608, acc.: 77.34%] [G loss: 0.569294]\n",
      "epoch:4 step:4328 [D loss: 0.500840, acc.: 73.44%] [G loss: 0.545134]\n",
      "epoch:4 step:4329 [D loss: 0.489681, acc.: 76.56%] [G loss: 0.608154]\n",
      "epoch:4 step:4330 [D loss: 0.496038, acc.: 79.69%] [G loss: 0.807247]\n",
      "epoch:4 step:4331 [D loss: 0.550344, acc.: 71.88%] [G loss: 0.822405]\n",
      "epoch:4 step:4332 [D loss: 0.634925, acc.: 64.84%] [G loss: 0.596444]\n",
      "epoch:4 step:4333 [D loss: 0.546463, acc.: 74.22%] [G loss: 0.527386]\n",
      "epoch:4 step:4334 [D loss: 0.576649, acc.: 71.88%] [G loss: 0.522472]\n",
      "epoch:4 step:4335 [D loss: 0.522158, acc.: 69.53%] [G loss: 0.590877]\n",
      "epoch:4 step:4336 [D loss: 0.600535, acc.: 64.84%] [G loss: 0.621309]\n",
      "epoch:4 step:4337 [D loss: 0.506536, acc.: 75.00%] [G loss: 0.769298]\n",
      "epoch:4 step:4338 [D loss: 0.531363, acc.: 77.34%] [G loss: 0.610385]\n",
      "epoch:4 step:4339 [D loss: 0.573274, acc.: 75.78%] [G loss: 0.508869]\n",
      "epoch:4 step:4340 [D loss: 0.469973, acc.: 78.12%] [G loss: 0.578198]\n",
      "epoch:4 step:4341 [D loss: 0.528122, acc.: 74.22%] [G loss: 0.580955]\n",
      "epoch:4 step:4342 [D loss: 0.505546, acc.: 75.78%] [G loss: 0.516698]\n",
      "epoch:4 step:4343 [D loss: 0.577161, acc.: 67.97%] [G loss: 0.580473]\n",
      "epoch:4 step:4344 [D loss: 0.545240, acc.: 74.22%] [G loss: 0.417756]\n",
      "epoch:4 step:4345 [D loss: 0.534558, acc.: 71.09%] [G loss: 0.415394]\n",
      "epoch:4 step:4346 [D loss: 0.492592, acc.: 77.34%] [G loss: 0.549717]\n",
      "epoch:4 step:4347 [D loss: 0.554106, acc.: 73.44%] [G loss: 0.585557]\n",
      "epoch:4 step:4348 [D loss: 0.644684, acc.: 60.94%] [G loss: 0.479025]\n",
      "epoch:4 step:4349 [D loss: 0.481712, acc.: 78.12%] [G loss: 0.593482]\n",
      "epoch:4 step:4350 [D loss: 0.503836, acc.: 77.34%] [G loss: 0.588593]\n",
      "epoch:4 step:4351 [D loss: 0.542398, acc.: 70.31%] [G loss: 0.607032]\n",
      "epoch:4 step:4352 [D loss: 0.539024, acc.: 70.31%] [G loss: 0.585892]\n",
      "epoch:4 step:4353 [D loss: 0.482286, acc.: 79.69%] [G loss: 0.521110]\n",
      "epoch:4 step:4354 [D loss: 0.515219, acc.: 73.44%] [G loss: 0.581790]\n",
      "epoch:4 step:4355 [D loss: 0.514654, acc.: 71.88%] [G loss: 0.592326]\n",
      "epoch:4 step:4356 [D loss: 0.527519, acc.: 74.22%] [G loss: 0.519328]\n",
      "epoch:4 step:4357 [D loss: 0.464298, acc.: 75.00%] [G loss: 0.676300]\n",
      "epoch:4 step:4358 [D loss: 0.497427, acc.: 77.34%] [G loss: 0.569414]\n",
      "epoch:4 step:4359 [D loss: 0.470350, acc.: 79.69%] [G loss: 0.555700]\n",
      "epoch:4 step:4360 [D loss: 0.563409, acc.: 74.22%] [G loss: 0.445463]\n",
      "epoch:4 step:4361 [D loss: 0.499982, acc.: 76.56%] [G loss: 0.580228]\n",
      "epoch:4 step:4362 [D loss: 0.519279, acc.: 72.66%] [G loss: 0.715070]\n",
      "epoch:4 step:4363 [D loss: 0.618133, acc.: 59.38%] [G loss: 0.471782]\n",
      "epoch:4 step:4364 [D loss: 0.542781, acc.: 68.75%] [G loss: 0.535429]\n",
      "epoch:4 step:4365 [D loss: 0.553863, acc.: 67.97%] [G loss: 0.440742]\n",
      "epoch:4 step:4366 [D loss: 0.519436, acc.: 74.22%] [G loss: 0.591615]\n",
      "epoch:4 step:4367 [D loss: 0.498920, acc.: 74.22%] [G loss: 0.666436]\n",
      "epoch:4 step:4368 [D loss: 0.516291, acc.: 75.00%] [G loss: 0.558008]\n",
      "epoch:4 step:4369 [D loss: 0.546711, acc.: 71.09%] [G loss: 0.455762]\n",
      "epoch:4 step:4370 [D loss: 0.588228, acc.: 68.75%] [G loss: 0.504220]\n",
      "epoch:4 step:4371 [D loss: 0.487406, acc.: 82.03%] [G loss: 0.529789]\n",
      "epoch:4 step:4372 [D loss: 0.503666, acc.: 75.78%] [G loss: 0.526091]\n",
      "epoch:4 step:4373 [D loss: 0.531569, acc.: 68.75%] [G loss: 0.585667]\n",
      "epoch:4 step:4374 [D loss: 0.456446, acc.: 84.38%] [G loss: 0.547805]\n",
      "epoch:4 step:4375 [D loss: 0.517932, acc.: 71.09%] [G loss: 0.671805]\n",
      "epoch:4 step:4376 [D loss: 0.513241, acc.: 76.56%] [G loss: 0.554681]\n",
      "epoch:4 step:4377 [D loss: 0.460871, acc.: 79.69%] [G loss: 0.604603]\n",
      "epoch:4 step:4378 [D loss: 0.537067, acc.: 71.88%] [G loss: 0.514735]\n",
      "epoch:4 step:4379 [D loss: 0.512656, acc.: 78.91%] [G loss: 0.534170]\n",
      "epoch:4 step:4380 [D loss: 0.464533, acc.: 81.25%] [G loss: 0.665654]\n",
      "epoch:4 step:4381 [D loss: 0.558357, acc.: 69.53%] [G loss: 0.516188]\n",
      "epoch:4 step:4382 [D loss: 0.485155, acc.: 78.12%] [G loss: 0.642429]\n",
      "epoch:4 step:4383 [D loss: 0.496268, acc.: 74.22%] [G loss: 0.729464]\n",
      "epoch:4 step:4384 [D loss: 0.587923, acc.: 64.84%] [G loss: 0.507296]\n",
      "epoch:4 step:4385 [D loss: 0.542380, acc.: 67.97%] [G loss: 0.534226]\n",
      "epoch:4 step:4386 [D loss: 0.519419, acc.: 76.56%] [G loss: 0.554555]\n",
      "epoch:4 step:4387 [D loss: 0.454345, acc.: 78.91%] [G loss: 0.734897]\n",
      "epoch:4 step:4388 [D loss: 0.515785, acc.: 75.78%] [G loss: 0.636020]\n",
      "epoch:4 step:4389 [D loss: 0.444789, acc.: 81.25%] [G loss: 0.771777]\n",
      "epoch:4 step:4390 [D loss: 0.466326, acc.: 76.56%] [G loss: 0.841266]\n",
      "epoch:4 step:4391 [D loss: 0.512362, acc.: 78.91%] [G loss: 0.736692]\n",
      "epoch:4 step:4392 [D loss: 0.593427, acc.: 62.50%] [G loss: 0.475326]\n",
      "epoch:4 step:4393 [D loss: 0.501023, acc.: 77.34%] [G loss: 0.679728]\n",
      "epoch:4 step:4394 [D loss: 0.586628, acc.: 64.84%] [G loss: 0.626352]\n",
      "epoch:4 step:4395 [D loss: 0.453274, acc.: 82.81%] [G loss: 0.711371]\n",
      "epoch:4 step:4396 [D loss: 0.461718, acc.: 79.69%] [G loss: 0.733312]\n",
      "epoch:4 step:4397 [D loss: 0.496339, acc.: 76.56%] [G loss: 0.688601]\n",
      "epoch:4 step:4398 [D loss: 0.503988, acc.: 73.44%] [G loss: 0.724496]\n",
      "epoch:4 step:4399 [D loss: 0.528799, acc.: 75.00%] [G loss: 0.696911]\n",
      "epoch:4 step:4400 [D loss: 0.609019, acc.: 63.28%] [G loss: 0.522007]\n",
      "##############\n",
      "[3.54600383 1.96978814 6.98809896 5.26869282 4.64110617 6.21745437\n",
      " 5.6323735  5.42760807 5.18002829 4.04912068]\n",
      "##########\n",
      "epoch:4 step:4401 [D loss: 0.535344, acc.: 71.09%] [G loss: 0.455675]\n",
      "epoch:4 step:4402 [D loss: 0.524573, acc.: 76.56%] [G loss: 0.608981]\n",
      "epoch:4 step:4403 [D loss: 0.593253, acc.: 66.41%] [G loss: 0.526127]\n",
      "epoch:4 step:4404 [D loss: 0.533525, acc.: 77.34%] [G loss: 0.663489]\n",
      "epoch:4 step:4405 [D loss: 0.518923, acc.: 75.00%] [G loss: 0.488277]\n",
      "epoch:4 step:4406 [D loss: 0.604015, acc.: 68.75%] [G loss: 0.589956]\n",
      "epoch:4 step:4407 [D loss: 0.553464, acc.: 71.09%] [G loss: 0.634363]\n",
      "epoch:4 step:4408 [D loss: 0.501399, acc.: 75.78%] [G loss: 0.595238]\n",
      "epoch:4 step:4409 [D loss: 0.555447, acc.: 72.66%] [G loss: 0.572440]\n",
      "epoch:4 step:4410 [D loss: 0.519772, acc.: 72.66%] [G loss: 0.653102]\n",
      "epoch:4 step:4411 [D loss: 0.511971, acc.: 76.56%] [G loss: 0.487569]\n",
      "epoch:4 step:4412 [D loss: 0.490716, acc.: 76.56%] [G loss: 0.775533]\n",
      "epoch:4 step:4413 [D loss: 0.526078, acc.: 71.88%] [G loss: 0.592786]\n",
      "epoch:4 step:4414 [D loss: 0.477790, acc.: 75.78%] [G loss: 0.814437]\n",
      "epoch:4 step:4415 [D loss: 0.515113, acc.: 69.53%] [G loss: 0.683208]\n",
      "epoch:4 step:4416 [D loss: 0.546266, acc.: 74.22%] [G loss: 0.435631]\n",
      "epoch:4 step:4417 [D loss: 0.589443, acc.: 71.09%] [G loss: 0.570054]\n",
      "epoch:4 step:4418 [D loss: 0.494667, acc.: 78.91%] [G loss: 0.587470]\n",
      "epoch:4 step:4419 [D loss: 0.562474, acc.: 68.75%] [G loss: 0.704625]\n",
      "epoch:4 step:4420 [D loss: 0.632907, acc.: 64.84%] [G loss: 0.532210]\n",
      "epoch:4 step:4421 [D loss: 0.534757, acc.: 74.22%] [G loss: 0.633350]\n",
      "epoch:4 step:4422 [D loss: 0.572952, acc.: 71.09%] [G loss: 0.621362]\n",
      "epoch:4 step:4423 [D loss: 0.567532, acc.: 70.31%] [G loss: 0.578629]\n",
      "epoch:4 step:4424 [D loss: 0.561049, acc.: 67.97%] [G loss: 0.534317]\n",
      "epoch:4 step:4425 [D loss: 0.494713, acc.: 76.56%] [G loss: 0.638811]\n",
      "epoch:4 step:4426 [D loss: 0.529856, acc.: 75.78%] [G loss: 0.552926]\n",
      "epoch:4 step:4427 [D loss: 0.538387, acc.: 72.66%] [G loss: 0.610022]\n",
      "epoch:4 step:4428 [D loss: 0.424830, acc.: 86.72%] [G loss: 0.746000]\n",
      "epoch:4 step:4429 [D loss: 0.500741, acc.: 77.34%] [G loss: 0.613310]\n",
      "epoch:4 step:4430 [D loss: 0.515832, acc.: 77.34%] [G loss: 0.665642]\n",
      "epoch:4 step:4431 [D loss: 0.541514, acc.: 75.78%] [G loss: 0.657887]\n",
      "epoch:4 step:4432 [D loss: 0.538163, acc.: 76.56%] [G loss: 0.531260]\n",
      "epoch:4 step:4433 [D loss: 0.511310, acc.: 74.22%] [G loss: 0.539153]\n",
      "epoch:4 step:4434 [D loss: 0.550253, acc.: 71.88%] [G loss: 0.456665]\n",
      "epoch:4 step:4435 [D loss: 0.581729, acc.: 69.53%] [G loss: 0.573065]\n",
      "epoch:4 step:4436 [D loss: 0.560503, acc.: 72.66%] [G loss: 0.575719]\n",
      "epoch:4 step:4437 [D loss: 0.529877, acc.: 76.56%] [G loss: 0.556369]\n",
      "epoch:4 step:4438 [D loss: 0.525860, acc.: 71.09%] [G loss: 0.524524]\n",
      "epoch:4 step:4439 [D loss: 0.477335, acc.: 78.91%] [G loss: 0.792297]\n",
      "epoch:4 step:4440 [D loss: 0.517341, acc.: 76.56%] [G loss: 0.668452]\n",
      "epoch:4 step:4441 [D loss: 0.505069, acc.: 72.66%] [G loss: 0.711291]\n",
      "epoch:4 step:4442 [D loss: 0.477619, acc.: 73.44%] [G loss: 0.600135]\n",
      "epoch:4 step:4443 [D loss: 0.516528, acc.: 77.34%] [G loss: 0.772541]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4444 [D loss: 0.595511, acc.: 66.41%] [G loss: 0.551420]\n",
      "epoch:4 step:4445 [D loss: 0.524084, acc.: 73.44%] [G loss: 0.532043]\n",
      "epoch:4 step:4446 [D loss: 0.546194, acc.: 74.22%] [G loss: 0.558884]\n",
      "epoch:4 step:4447 [D loss: 0.476750, acc.: 78.91%] [G loss: 0.608117]\n",
      "epoch:4 step:4448 [D loss: 0.496986, acc.: 78.91%] [G loss: 0.623858]\n",
      "epoch:4 step:4449 [D loss: 0.500445, acc.: 75.78%] [G loss: 0.643835]\n",
      "epoch:4 step:4450 [D loss: 0.569944, acc.: 67.97%] [G loss: 0.564258]\n",
      "epoch:4 step:4451 [D loss: 0.595229, acc.: 68.75%] [G loss: 0.476585]\n",
      "epoch:4 step:4452 [D loss: 0.589377, acc.: 68.75%] [G loss: 0.489538]\n",
      "epoch:4 step:4453 [D loss: 0.529832, acc.: 74.22%] [G loss: 0.485730]\n",
      "epoch:4 step:4454 [D loss: 0.517755, acc.: 75.78%] [G loss: 0.567072]\n",
      "epoch:4 step:4455 [D loss: 0.445887, acc.: 82.81%] [G loss: 0.586036]\n",
      "epoch:4 step:4456 [D loss: 0.457894, acc.: 82.03%] [G loss: 0.765584]\n",
      "epoch:4 step:4457 [D loss: 0.479597, acc.: 78.91%] [G loss: 0.866059]\n",
      "epoch:4 step:4458 [D loss: 0.646843, acc.: 62.50%] [G loss: 0.610005]\n",
      "epoch:4 step:4459 [D loss: 0.560463, acc.: 70.31%] [G loss: 0.547209]\n",
      "epoch:4 step:4460 [D loss: 0.547425, acc.: 71.09%] [G loss: 0.491733]\n",
      "epoch:4 step:4461 [D loss: 0.551834, acc.: 72.66%] [G loss: 0.553563]\n",
      "epoch:4 step:4462 [D loss: 0.524455, acc.: 75.00%] [G loss: 0.492261]\n",
      "epoch:4 step:4463 [D loss: 0.559633, acc.: 70.31%] [G loss: 0.607966]\n",
      "epoch:4 step:4464 [D loss: 0.648536, acc.: 58.59%] [G loss: 0.371704]\n",
      "epoch:4 step:4465 [D loss: 0.560996, acc.: 71.09%] [G loss: 0.472964]\n",
      "epoch:4 step:4466 [D loss: 0.536187, acc.: 77.34%] [G loss: 0.515016]\n",
      "epoch:4 step:4467 [D loss: 0.552019, acc.: 72.66%] [G loss: 0.463964]\n",
      "epoch:4 step:4468 [D loss: 0.581101, acc.: 73.44%] [G loss: 0.414600]\n",
      "epoch:4 step:4469 [D loss: 0.544929, acc.: 77.34%] [G loss: 0.483555]\n",
      "epoch:4 step:4470 [D loss: 0.504995, acc.: 75.00%] [G loss: 0.522573]\n",
      "epoch:4 step:4471 [D loss: 0.587421, acc.: 66.41%] [G loss: 0.531069]\n",
      "epoch:4 step:4472 [D loss: 0.497959, acc.: 78.12%] [G loss: 0.572435]\n",
      "epoch:4 step:4473 [D loss: 0.470354, acc.: 82.03%] [G loss: 0.650553]\n",
      "epoch:4 step:4474 [D loss: 0.521820, acc.: 74.22%] [G loss: 0.702446]\n",
      "epoch:4 step:4475 [D loss: 0.578688, acc.: 73.44%] [G loss: 0.479338]\n",
      "epoch:4 step:4476 [D loss: 0.495630, acc.: 77.34%] [G loss: 0.556028]\n",
      "epoch:4 step:4477 [D loss: 0.587323, acc.: 68.75%] [G loss: 0.531274]\n",
      "epoch:4 step:4478 [D loss: 0.558835, acc.: 71.88%] [G loss: 0.568917]\n",
      "epoch:4 step:4479 [D loss: 0.524277, acc.: 74.22%] [G loss: 0.659632]\n",
      "epoch:4 step:4480 [D loss: 0.504439, acc.: 75.78%] [G loss: 0.563093]\n",
      "epoch:4 step:4481 [D loss: 0.546861, acc.: 67.97%] [G loss: 0.572782]\n",
      "epoch:4 step:4482 [D loss: 0.557630, acc.: 68.75%] [G loss: 0.514314]\n",
      "epoch:4 step:4483 [D loss: 0.581058, acc.: 71.09%] [G loss: 0.431626]\n",
      "epoch:4 step:4484 [D loss: 0.472579, acc.: 78.12%] [G loss: 0.572157]\n",
      "epoch:4 step:4485 [D loss: 0.512749, acc.: 71.88%] [G loss: 0.555775]\n",
      "epoch:4 step:4486 [D loss: 0.582851, acc.: 69.53%] [G loss: 0.451797]\n",
      "epoch:4 step:4487 [D loss: 0.618093, acc.: 65.62%] [G loss: 0.422713]\n",
      "epoch:4 step:4488 [D loss: 0.582927, acc.: 67.19%] [G loss: 0.452651]\n",
      "epoch:4 step:4489 [D loss: 0.520858, acc.: 72.66%] [G loss: 0.487474]\n",
      "epoch:4 step:4490 [D loss: 0.582856, acc.: 67.97%] [G loss: 0.510149]\n",
      "epoch:4 step:4491 [D loss: 0.517741, acc.: 77.34%] [G loss: 0.582982]\n",
      "epoch:4 step:4492 [D loss: 0.513711, acc.: 74.22%] [G loss: 0.619572]\n",
      "epoch:4 step:4493 [D loss: 0.564389, acc.: 64.06%] [G loss: 0.598458]\n",
      "epoch:4 step:4494 [D loss: 0.451048, acc.: 78.12%] [G loss: 0.607200]\n",
      "epoch:4 step:4495 [D loss: 0.443646, acc.: 78.12%] [G loss: 0.757990]\n",
      "epoch:4 step:4496 [D loss: 0.541117, acc.: 73.44%] [G loss: 0.661701]\n",
      "epoch:4 step:4497 [D loss: 0.508121, acc.: 73.44%] [G loss: 0.554443]\n",
      "epoch:4 step:4498 [D loss: 0.501578, acc.: 75.78%] [G loss: 0.592455]\n",
      "epoch:4 step:4499 [D loss: 0.550150, acc.: 75.00%] [G loss: 0.545023]\n",
      "epoch:4 step:4500 [D loss: 0.479330, acc.: 78.12%] [G loss: 0.696067]\n",
      "epoch:4 step:4501 [D loss: 0.462283, acc.: 76.56%] [G loss: 0.691245]\n",
      "epoch:4 step:4502 [D loss: 0.431090, acc.: 86.72%] [G loss: 0.535519]\n",
      "epoch:4 step:4503 [D loss: 0.530333, acc.: 71.09%] [G loss: 0.656991]\n",
      "epoch:4 step:4504 [D loss: 0.594106, acc.: 64.84%] [G loss: 0.624776]\n",
      "epoch:4 step:4505 [D loss: 0.491211, acc.: 75.78%] [G loss: 0.667537]\n",
      "epoch:4 step:4506 [D loss: 0.553336, acc.: 70.31%] [G loss: 0.536063]\n",
      "epoch:4 step:4507 [D loss: 0.547979, acc.: 73.44%] [G loss: 0.478760]\n",
      "epoch:4 step:4508 [D loss: 0.538093, acc.: 66.41%] [G loss: 0.473321]\n",
      "epoch:4 step:4509 [D loss: 0.524698, acc.: 71.09%] [G loss: 0.577198]\n",
      "epoch:4 step:4510 [D loss: 0.538692, acc.: 72.66%] [G loss: 0.602413]\n",
      "epoch:4 step:4511 [D loss: 0.496145, acc.: 79.69%] [G loss: 0.408561]\n",
      "epoch:4 step:4512 [D loss: 0.516993, acc.: 76.56%] [G loss: 0.521206]\n",
      "epoch:4 step:4513 [D loss: 0.653293, acc.: 62.50%] [G loss: 0.569417]\n",
      "epoch:4 step:4514 [D loss: 0.638472, acc.: 67.97%] [G loss: 0.482569]\n",
      "epoch:4 step:4515 [D loss: 0.525900, acc.: 71.88%] [G loss: 0.671637]\n",
      "epoch:4 step:4516 [D loss: 0.558844, acc.: 67.97%] [G loss: 0.628775]\n",
      "epoch:4 step:4517 [D loss: 0.521813, acc.: 71.09%] [G loss: 0.684839]\n",
      "epoch:4 step:4518 [D loss: 0.523477, acc.: 73.44%] [G loss: 0.711688]\n",
      "epoch:4 step:4519 [D loss: 0.540649, acc.: 72.66%] [G loss: 0.637006]\n",
      "epoch:4 step:4520 [D loss: 0.522343, acc.: 75.00%] [G loss: 0.535635]\n",
      "epoch:4 step:4521 [D loss: 0.532945, acc.: 73.44%] [G loss: 0.504910]\n",
      "epoch:4 step:4522 [D loss: 0.563370, acc.: 71.88%] [G loss: 0.545742]\n",
      "epoch:4 step:4523 [D loss: 0.526742, acc.: 72.66%] [G loss: 0.593515]\n",
      "epoch:4 step:4524 [D loss: 0.545724, acc.: 71.88%] [G loss: 0.644868]\n",
      "epoch:4 step:4525 [D loss: 0.487397, acc.: 76.56%] [G loss: 0.505950]\n",
      "epoch:4 step:4526 [D loss: 0.499010, acc.: 78.91%] [G loss: 0.573125]\n",
      "epoch:4 step:4527 [D loss: 0.576045, acc.: 67.97%] [G loss: 0.571438]\n",
      "epoch:4 step:4528 [D loss: 0.503597, acc.: 80.47%] [G loss: 0.665154]\n",
      "epoch:4 step:4529 [D loss: 0.495812, acc.: 75.00%] [G loss: 0.802956]\n",
      "epoch:4 step:4530 [D loss: 0.500729, acc.: 80.47%] [G loss: 0.760625]\n",
      "epoch:4 step:4531 [D loss: 0.525188, acc.: 76.56%] [G loss: 0.728084]\n",
      "epoch:4 step:4532 [D loss: 0.544647, acc.: 73.44%] [G loss: 0.671358]\n",
      "epoch:4 step:4533 [D loss: 0.530565, acc.: 74.22%] [G loss: 0.590877]\n",
      "epoch:4 step:4534 [D loss: 0.459574, acc.: 82.03%] [G loss: 0.649546]\n",
      "epoch:4 step:4535 [D loss: 0.571632, acc.: 75.00%] [G loss: 0.567206]\n",
      "epoch:4 step:4536 [D loss: 0.618189, acc.: 65.62%] [G loss: 0.491548]\n",
      "epoch:4 step:4537 [D loss: 0.467119, acc.: 85.94%] [G loss: 0.556175]\n",
      "epoch:4 step:4538 [D loss: 0.514928, acc.: 74.22%] [G loss: 0.479901]\n",
      "epoch:4 step:4539 [D loss: 0.523467, acc.: 73.44%] [G loss: 0.491143]\n",
      "epoch:4 step:4540 [D loss: 0.423282, acc.: 82.81%] [G loss: 0.644925]\n",
      "epoch:4 step:4541 [D loss: 0.501918, acc.: 80.47%] [G loss: 0.684019]\n",
      "epoch:4 step:4542 [D loss: 0.613031, acc.: 65.62%] [G loss: 0.762712]\n",
      "epoch:4 step:4543 [D loss: 0.517678, acc.: 75.78%] [G loss: 0.601786]\n",
      "epoch:4 step:4544 [D loss: 0.479170, acc.: 78.91%] [G loss: 0.674585]\n",
      "epoch:4 step:4545 [D loss: 0.541916, acc.: 73.44%] [G loss: 0.621351]\n",
      "epoch:4 step:4546 [D loss: 0.485831, acc.: 73.44%] [G loss: 0.696978]\n",
      "epoch:4 step:4547 [D loss: 0.521271, acc.: 76.56%] [G loss: 0.630201]\n",
      "epoch:4 step:4548 [D loss: 0.471229, acc.: 81.25%] [G loss: 0.628300]\n",
      "epoch:4 step:4549 [D loss: 0.513698, acc.: 78.12%] [G loss: 0.517950]\n",
      "epoch:4 step:4550 [D loss: 0.471242, acc.: 78.91%] [G loss: 0.665997]\n",
      "epoch:4 step:4551 [D loss: 0.498438, acc.: 75.78%] [G loss: 0.628314]\n",
      "epoch:4 step:4552 [D loss: 0.498388, acc.: 71.09%] [G loss: 0.653894]\n",
      "epoch:4 step:4553 [D loss: 0.456380, acc.: 77.34%] [G loss: 0.718806]\n",
      "epoch:4 step:4554 [D loss: 0.536360, acc.: 75.00%] [G loss: 0.676186]\n",
      "epoch:4 step:4555 [D loss: 0.466399, acc.: 82.03%] [G loss: 0.599806]\n",
      "epoch:4 step:4556 [D loss: 0.549031, acc.: 67.97%] [G loss: 0.606219]\n",
      "epoch:4 step:4557 [D loss: 0.520192, acc.: 76.56%] [G loss: 0.511245]\n",
      "epoch:4 step:4558 [D loss: 0.528699, acc.: 71.88%] [G loss: 0.490237]\n",
      "epoch:4 step:4559 [D loss: 0.524909, acc.: 75.78%] [G loss: 0.651525]\n",
      "epoch:4 step:4560 [D loss: 0.621465, acc.: 67.97%] [G loss: 0.573850]\n",
      "epoch:4 step:4561 [D loss: 0.546112, acc.: 76.56%] [G loss: 0.562255]\n",
      "epoch:4 step:4562 [D loss: 0.545309, acc.: 71.88%] [G loss: 0.567250]\n",
      "epoch:4 step:4563 [D loss: 0.498458, acc.: 78.12%] [G loss: 0.574265]\n",
      "epoch:4 step:4564 [D loss: 0.508004, acc.: 71.09%] [G loss: 0.588543]\n",
      "epoch:4 step:4565 [D loss: 0.577933, acc.: 71.09%] [G loss: 0.588659]\n",
      "epoch:4 step:4566 [D loss: 0.561312, acc.: 70.31%] [G loss: 0.565126]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4567 [D loss: 0.556456, acc.: 74.22%] [G loss: 0.490200]\n",
      "epoch:4 step:4568 [D loss: 0.573068, acc.: 71.09%] [G loss: 0.630290]\n",
      "epoch:4 step:4569 [D loss: 0.525188, acc.: 75.78%] [G loss: 0.493592]\n",
      "epoch:4 step:4570 [D loss: 0.502903, acc.: 72.66%] [G loss: 0.559719]\n",
      "epoch:4 step:4571 [D loss: 0.413321, acc.: 85.94%] [G loss: 0.750710]\n",
      "epoch:4 step:4572 [D loss: 0.577766, acc.: 70.31%] [G loss: 0.536075]\n",
      "epoch:4 step:4573 [D loss: 0.487372, acc.: 76.56%] [G loss: 0.449875]\n",
      "epoch:4 step:4574 [D loss: 0.549651, acc.: 69.53%] [G loss: 0.613966]\n",
      "epoch:4 step:4575 [D loss: 0.569954, acc.: 68.75%] [G loss: 0.497856]\n",
      "epoch:4 step:4576 [D loss: 0.591127, acc.: 64.84%] [G loss: 0.574018]\n",
      "epoch:4 step:4577 [D loss: 0.501350, acc.: 76.56%] [G loss: 0.709195]\n",
      "epoch:4 step:4578 [D loss: 0.516683, acc.: 75.00%] [G loss: 0.571673]\n",
      "epoch:4 step:4579 [D loss: 0.539132, acc.: 75.00%] [G loss: 0.539080]\n",
      "epoch:4 step:4580 [D loss: 0.534037, acc.: 71.88%] [G loss: 0.629865]\n",
      "epoch:4 step:4581 [D loss: 0.482604, acc.: 78.12%] [G loss: 0.643636]\n",
      "epoch:4 step:4582 [D loss: 0.455382, acc.: 82.03%] [G loss: 0.608138]\n",
      "epoch:4 step:4583 [D loss: 0.526162, acc.: 73.44%] [G loss: 0.504167]\n",
      "epoch:4 step:4584 [D loss: 0.509442, acc.: 74.22%] [G loss: 0.593594]\n",
      "epoch:4 step:4585 [D loss: 0.481010, acc.: 82.03%] [G loss: 0.567774]\n",
      "epoch:4 step:4586 [D loss: 0.524604, acc.: 75.78%] [G loss: 0.547558]\n",
      "epoch:4 step:4587 [D loss: 0.477722, acc.: 78.91%] [G loss: 0.590039]\n",
      "epoch:4 step:4588 [D loss: 0.591357, acc.: 67.97%] [G loss: 0.437018]\n",
      "epoch:4 step:4589 [D loss: 0.518206, acc.: 71.88%] [G loss: 0.474000]\n",
      "epoch:4 step:4590 [D loss: 0.493006, acc.: 75.00%] [G loss: 0.648374]\n",
      "epoch:4 step:4591 [D loss: 0.503836, acc.: 73.44%] [G loss: 0.606270]\n",
      "epoch:4 step:4592 [D loss: 0.558916, acc.: 75.00%] [G loss: 0.579948]\n",
      "epoch:4 step:4593 [D loss: 0.525277, acc.: 70.31%] [G loss: 0.600744]\n",
      "epoch:4 step:4594 [D loss: 0.555077, acc.: 67.97%] [G loss: 0.527009]\n",
      "epoch:4 step:4595 [D loss: 0.596328, acc.: 68.75%] [G loss: 0.543109]\n",
      "epoch:4 step:4596 [D loss: 0.523437, acc.: 71.88%] [G loss: 0.482368]\n",
      "epoch:4 step:4597 [D loss: 0.576140, acc.: 71.09%] [G loss: 0.494359]\n",
      "epoch:4 step:4598 [D loss: 0.519336, acc.: 75.78%] [G loss: 0.444930]\n",
      "epoch:4 step:4599 [D loss: 0.548694, acc.: 69.53%] [G loss: 0.477180]\n",
      "epoch:4 step:4600 [D loss: 0.487702, acc.: 78.91%] [G loss: 0.722682]\n",
      "##############\n",
      "[3.61159315 1.78358268 6.86773599 5.24028807 4.28635503 6.0795575\n",
      " 5.67063912 5.23966806 5.02156306 3.8544863 ]\n",
      "##########\n",
      "epoch:4 step:4601 [D loss: 0.518034, acc.: 73.44%] [G loss: 0.745285]\n",
      "epoch:4 step:4602 [D loss: 0.448590, acc.: 76.56%] [G loss: 0.642868]\n",
      "epoch:4 step:4603 [D loss: 0.559439, acc.: 71.09%] [G loss: 0.674176]\n",
      "epoch:4 step:4604 [D loss: 0.600648, acc.: 64.06%] [G loss: 0.680820]\n",
      "epoch:4 step:4605 [D loss: 0.448344, acc.: 77.34%] [G loss: 0.703620]\n",
      "epoch:4 step:4606 [D loss: 0.605582, acc.: 68.75%] [G loss: 0.657339]\n",
      "epoch:4 step:4607 [D loss: 0.639107, acc.: 64.84%] [G loss: 0.611526]\n",
      "epoch:4 step:4608 [D loss: 0.488733, acc.: 73.44%] [G loss: 0.678151]\n",
      "epoch:4 step:4609 [D loss: 0.583044, acc.: 67.97%] [G loss: 0.633573]\n",
      "epoch:4 step:4610 [D loss: 0.559959, acc.: 69.53%] [G loss: 0.502668]\n",
      "epoch:4 step:4611 [D loss: 0.509850, acc.: 78.91%] [G loss: 0.517967]\n",
      "epoch:4 step:4612 [D loss: 0.493548, acc.: 74.22%] [G loss: 0.512701]\n",
      "epoch:4 step:4613 [D loss: 0.561068, acc.: 70.31%] [G loss: 0.442905]\n",
      "epoch:4 step:4614 [D loss: 0.578018, acc.: 65.62%] [G loss: 0.401419]\n",
      "epoch:4 step:4615 [D loss: 0.621120, acc.: 67.97%] [G loss: 0.469776]\n",
      "epoch:4 step:4616 [D loss: 0.469677, acc.: 85.16%] [G loss: 0.504816]\n",
      "epoch:4 step:4617 [D loss: 0.508472, acc.: 78.91%] [G loss: 0.677447]\n",
      "epoch:4 step:4618 [D loss: 0.465668, acc.: 81.25%] [G loss: 0.580093]\n",
      "epoch:4 step:4619 [D loss: 0.491384, acc.: 75.78%] [G loss: 0.485950]\n",
      "epoch:4 step:4620 [D loss: 0.534007, acc.: 72.66%] [G loss: 0.624228]\n",
      "epoch:4 step:4621 [D loss: 0.584563, acc.: 65.62%] [G loss: 0.433051]\n",
      "epoch:4 step:4622 [D loss: 0.591670, acc.: 64.84%] [G loss: 0.557233]\n",
      "epoch:4 step:4623 [D loss: 0.523576, acc.: 68.75%] [G loss: 0.494603]\n",
      "epoch:4 step:4624 [D loss: 0.536377, acc.: 71.09%] [G loss: 0.547103]\n",
      "epoch:4 step:4625 [D loss: 0.525668, acc.: 72.66%] [G loss: 0.504739]\n",
      "epoch:4 step:4626 [D loss: 0.589343, acc.: 65.62%] [G loss: 0.516925]\n",
      "epoch:4 step:4627 [D loss: 0.556884, acc.: 69.53%] [G loss: 0.632333]\n",
      "epoch:4 step:4628 [D loss: 0.611494, acc.: 67.19%] [G loss: 0.516761]\n",
      "epoch:4 step:4629 [D loss: 0.537193, acc.: 72.66%] [G loss: 0.428595]\n",
      "epoch:4 step:4630 [D loss: 0.534091, acc.: 73.44%] [G loss: 0.530401]\n",
      "epoch:4 step:4631 [D loss: 0.516009, acc.: 77.34%] [G loss: 0.530650]\n",
      "epoch:4 step:4632 [D loss: 0.502082, acc.: 75.78%] [G loss: 0.689078]\n",
      "epoch:4 step:4633 [D loss: 0.510341, acc.: 78.12%] [G loss: 0.740432]\n",
      "epoch:4 step:4634 [D loss: 0.493649, acc.: 77.34%] [G loss: 0.684222]\n",
      "epoch:4 step:4635 [D loss: 0.478193, acc.: 80.47%] [G loss: 0.717263]\n",
      "epoch:4 step:4636 [D loss: 0.450520, acc.: 78.12%] [G loss: 0.762499]\n",
      "epoch:4 step:4637 [D loss: 0.504810, acc.: 75.00%] [G loss: 0.685017]\n",
      "epoch:4 step:4638 [D loss: 0.399262, acc.: 84.38%] [G loss: 0.804282]\n",
      "epoch:4 step:4639 [D loss: 0.579744, acc.: 70.31%] [G loss: 0.594157]\n",
      "epoch:4 step:4640 [D loss: 0.596962, acc.: 67.19%] [G loss: 0.455899]\n",
      "epoch:4 step:4641 [D loss: 0.576976, acc.: 71.88%] [G loss: 0.570116]\n",
      "epoch:4 step:4642 [D loss: 0.499314, acc.: 74.22%] [G loss: 0.723714]\n",
      "epoch:4 step:4643 [D loss: 0.492145, acc.: 81.25%] [G loss: 0.722153]\n",
      "epoch:4 step:4644 [D loss: 0.534492, acc.: 77.34%] [G loss: 0.690970]\n",
      "epoch:4 step:4645 [D loss: 0.457657, acc.: 81.25%] [G loss: 0.585367]\n",
      "epoch:4 step:4646 [D loss: 0.471715, acc.: 78.12%] [G loss: 0.754866]\n",
      "epoch:4 step:4647 [D loss: 0.488599, acc.: 78.12%] [G loss: 0.692843]\n",
      "epoch:4 step:4648 [D loss: 0.509102, acc.: 79.69%] [G loss: 0.606265]\n",
      "epoch:4 step:4649 [D loss: 0.519259, acc.: 69.53%] [G loss: 0.621077]\n",
      "epoch:4 step:4650 [D loss: 0.621235, acc.: 61.72%] [G loss: 0.471047]\n",
      "epoch:4 step:4651 [D loss: 0.530053, acc.: 74.22%] [G loss: 0.536271]\n",
      "epoch:4 step:4652 [D loss: 0.525370, acc.: 75.00%] [G loss: 0.623940]\n",
      "epoch:4 step:4653 [D loss: 0.564423, acc.: 71.09%] [G loss: 0.633504]\n",
      "epoch:4 step:4654 [D loss: 0.514226, acc.: 73.44%] [G loss: 0.727497]\n",
      "epoch:4 step:4655 [D loss: 0.543389, acc.: 73.44%] [G loss: 0.562726]\n",
      "epoch:4 step:4656 [D loss: 0.482402, acc.: 79.69%] [G loss: 0.603524]\n",
      "epoch:4 step:4657 [D loss: 0.488586, acc.: 75.00%] [G loss: 0.770846]\n",
      "epoch:4 step:4658 [D loss: 0.460765, acc.: 82.03%] [G loss: 0.733677]\n",
      "epoch:4 step:4659 [D loss: 0.437069, acc.: 82.03%] [G loss: 0.785920]\n",
      "epoch:4 step:4660 [D loss: 0.462601, acc.: 80.47%] [G loss: 0.918383]\n",
      "epoch:4 step:4661 [D loss: 0.526424, acc.: 74.22%] [G loss: 0.743320]\n",
      "epoch:4 step:4662 [D loss: 0.557033, acc.: 71.88%] [G loss: 0.726491]\n",
      "epoch:4 step:4663 [D loss: 0.592702, acc.: 70.31%] [G loss: 0.471195]\n",
      "epoch:4 step:4664 [D loss: 0.522178, acc.: 71.88%] [G loss: 0.633857]\n",
      "epoch:4 step:4665 [D loss: 0.638890, acc.: 61.72%] [G loss: 0.724776]\n",
      "epoch:4 step:4666 [D loss: 0.453438, acc.: 83.59%] [G loss: 0.686213]\n",
      "epoch:4 step:4667 [D loss: 0.496516, acc.: 78.91%] [G loss: 0.748993]\n",
      "epoch:4 step:4668 [D loss: 0.611703, acc.: 67.97%] [G loss: 0.656259]\n",
      "epoch:4 step:4669 [D loss: 0.453962, acc.: 79.69%] [G loss: 0.746588]\n",
      "epoch:4 step:4670 [D loss: 0.584116, acc.: 64.06%] [G loss: 0.515828]\n",
      "epoch:4 step:4671 [D loss: 0.440253, acc.: 82.03%] [G loss: 0.585036]\n",
      "epoch:4 step:4672 [D loss: 0.442436, acc.: 81.25%] [G loss: 0.820317]\n",
      "epoch:4 step:4673 [D loss: 0.417172, acc.: 83.59%] [G loss: 0.878128]\n",
      "epoch:4 step:4674 [D loss: 0.476571, acc.: 81.25%] [G loss: 1.024025]\n",
      "epoch:4 step:4675 [D loss: 0.481104, acc.: 78.91%] [G loss: 1.169143]\n",
      "epoch:4 step:4676 [D loss: 0.829180, acc.: 60.94%] [G loss: 0.923748]\n",
      "epoch:4 step:4677 [D loss: 0.488544, acc.: 76.56%] [G loss: 1.010208]\n",
      "epoch:4 step:4678 [D loss: 0.493172, acc.: 77.34%] [G loss: 0.850146]\n",
      "epoch:4 step:4679 [D loss: 0.549476, acc.: 67.97%] [G loss: 0.746956]\n",
      "epoch:4 step:4680 [D loss: 0.624231, acc.: 69.53%] [G loss: 0.628782]\n",
      "epoch:4 step:4681 [D loss: 0.472503, acc.: 79.69%] [G loss: 0.700976]\n",
      "epoch:4 step:4682 [D loss: 0.538487, acc.: 72.66%] [G loss: 0.630023]\n",
      "epoch:4 step:4683 [D loss: 0.455495, acc.: 78.91%] [G loss: 0.652752]\n",
      "epoch:4 step:4684 [D loss: 0.380765, acc.: 82.81%] [G loss: 0.900575]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4685 [D loss: 0.435135, acc.: 79.69%] [G loss: 0.962012]\n",
      "epoch:5 step:4686 [D loss: 0.558335, acc.: 74.22%] [G loss: 0.957322]\n",
      "epoch:5 step:4687 [D loss: 0.490315, acc.: 73.44%] [G loss: 0.895499]\n",
      "epoch:5 step:4688 [D loss: 0.570401, acc.: 71.09%] [G loss: 0.756490]\n",
      "epoch:5 step:4689 [D loss: 0.478788, acc.: 78.12%] [G loss: 0.724882]\n",
      "epoch:5 step:4690 [D loss: 0.524480, acc.: 69.53%] [G loss: 0.578313]\n",
      "epoch:5 step:4691 [D loss: 0.561472, acc.: 69.53%] [G loss: 0.678958]\n",
      "epoch:5 step:4692 [D loss: 0.455885, acc.: 77.34%] [G loss: 0.728702]\n",
      "epoch:5 step:4693 [D loss: 0.585067, acc.: 70.31%] [G loss: 0.613958]\n",
      "epoch:5 step:4694 [D loss: 0.522680, acc.: 73.44%] [G loss: 0.732464]\n",
      "epoch:5 step:4695 [D loss: 0.547119, acc.: 72.66%] [G loss: 0.594515]\n",
      "epoch:5 step:4696 [D loss: 0.510338, acc.: 74.22%] [G loss: 0.702322]\n",
      "epoch:5 step:4697 [D loss: 0.544626, acc.: 67.97%] [G loss: 0.553356]\n",
      "epoch:5 step:4698 [D loss: 0.508741, acc.: 74.22%] [G loss: 0.621552]\n",
      "epoch:5 step:4699 [D loss: 0.591902, acc.: 66.41%] [G loss: 0.432886]\n",
      "epoch:5 step:4700 [D loss: 0.454057, acc.: 81.25%] [G loss: 0.562659]\n",
      "epoch:5 step:4701 [D loss: 0.485552, acc.: 77.34%] [G loss: 0.609476]\n",
      "epoch:5 step:4702 [D loss: 0.529273, acc.: 77.34%] [G loss: 0.681914]\n",
      "epoch:5 step:4703 [D loss: 0.606783, acc.: 69.53%] [G loss: 0.433502]\n",
      "epoch:5 step:4704 [D loss: 0.464547, acc.: 73.44%] [G loss: 0.600189]\n",
      "epoch:5 step:4705 [D loss: 0.526381, acc.: 72.66%] [G loss: 0.482341]\n",
      "epoch:5 step:4706 [D loss: 0.548569, acc.: 77.34%] [G loss: 0.549207]\n",
      "epoch:5 step:4707 [D loss: 0.489573, acc.: 78.91%] [G loss: 0.789795]\n",
      "epoch:5 step:4708 [D loss: 0.485555, acc.: 76.56%] [G loss: 0.540350]\n",
      "epoch:5 step:4709 [D loss: 0.486432, acc.: 78.91%] [G loss: 0.431523]\n",
      "epoch:5 step:4710 [D loss: 0.472854, acc.: 78.91%] [G loss: 0.572462]\n",
      "epoch:5 step:4711 [D loss: 0.499866, acc.: 75.00%] [G loss: 0.622357]\n",
      "epoch:5 step:4712 [D loss: 0.446578, acc.: 82.03%] [G loss: 0.571900]\n",
      "epoch:5 step:4713 [D loss: 0.526388, acc.: 74.22%] [G loss: 0.571145]\n",
      "epoch:5 step:4714 [D loss: 0.448304, acc.: 83.59%] [G loss: 0.572644]\n",
      "epoch:5 step:4715 [D loss: 0.516424, acc.: 77.34%] [G loss: 0.588330]\n",
      "epoch:5 step:4716 [D loss: 0.607814, acc.: 67.19%] [G loss: 0.639133]\n",
      "epoch:5 step:4717 [D loss: 0.577042, acc.: 70.31%] [G loss: 0.608426]\n",
      "epoch:5 step:4718 [D loss: 0.519929, acc.: 75.78%] [G loss: 0.590590]\n",
      "epoch:5 step:4719 [D loss: 0.480741, acc.: 78.12%] [G loss: 0.658968]\n",
      "epoch:5 step:4720 [D loss: 0.504316, acc.: 75.78%] [G loss: 0.630681]\n",
      "epoch:5 step:4721 [D loss: 0.452154, acc.: 80.47%] [G loss: 0.758052]\n",
      "epoch:5 step:4722 [D loss: 0.502390, acc.: 74.22%] [G loss: 0.657706]\n",
      "epoch:5 step:4723 [D loss: 0.589909, acc.: 69.53%] [G loss: 0.610970]\n",
      "epoch:5 step:4724 [D loss: 0.467841, acc.: 78.12%] [G loss: 0.631011]\n",
      "epoch:5 step:4725 [D loss: 0.431853, acc.: 80.47%] [G loss: 0.789814]\n",
      "epoch:5 step:4726 [D loss: 0.516861, acc.: 77.34%] [G loss: 0.579202]\n",
      "epoch:5 step:4727 [D loss: 0.505827, acc.: 75.00%] [G loss: 0.559767]\n",
      "epoch:5 step:4728 [D loss: 0.461950, acc.: 81.25%] [G loss: 0.562510]\n",
      "epoch:5 step:4729 [D loss: 0.588049, acc.: 66.41%] [G loss: 0.547173]\n",
      "epoch:5 step:4730 [D loss: 0.518853, acc.: 78.91%] [G loss: 0.602600]\n",
      "epoch:5 step:4731 [D loss: 0.491673, acc.: 76.56%] [G loss: 0.610452]\n",
      "epoch:5 step:4732 [D loss: 0.490624, acc.: 78.12%] [G loss: 0.620228]\n",
      "epoch:5 step:4733 [D loss: 0.516084, acc.: 74.22%] [G loss: 0.647716]\n",
      "epoch:5 step:4734 [D loss: 0.495204, acc.: 79.69%] [G loss: 0.588802]\n",
      "epoch:5 step:4735 [D loss: 0.555592, acc.: 72.66%] [G loss: 0.559706]\n",
      "epoch:5 step:4736 [D loss: 0.578822, acc.: 71.09%] [G loss: 0.526374]\n",
      "epoch:5 step:4737 [D loss: 0.620788, acc.: 66.41%] [G loss: 0.447406]\n",
      "epoch:5 step:4738 [D loss: 0.507289, acc.: 75.00%] [G loss: 0.602532]\n",
      "epoch:5 step:4739 [D loss: 0.433171, acc.: 84.38%] [G loss: 0.657214]\n",
      "epoch:5 step:4740 [D loss: 0.532894, acc.: 73.44%] [G loss: 0.599450]\n",
      "epoch:5 step:4741 [D loss: 0.493324, acc.: 74.22%] [G loss: 0.652926]\n",
      "epoch:5 step:4742 [D loss: 0.531620, acc.: 73.44%] [G loss: 0.503525]\n",
      "epoch:5 step:4743 [D loss: 0.550862, acc.: 69.53%] [G loss: 0.435063]\n",
      "epoch:5 step:4744 [D loss: 0.478827, acc.: 76.56%] [G loss: 0.586449]\n",
      "epoch:5 step:4745 [D loss: 0.539934, acc.: 68.75%] [G loss: 0.637008]\n",
      "epoch:5 step:4746 [D loss: 0.526430, acc.: 75.00%] [G loss: 0.669191]\n",
      "epoch:5 step:4747 [D loss: 0.541382, acc.: 74.22%] [G loss: 0.499779]\n",
      "epoch:5 step:4748 [D loss: 0.558554, acc.: 67.19%] [G loss: 0.498912]\n",
      "epoch:5 step:4749 [D loss: 0.582600, acc.: 71.88%] [G loss: 0.584786]\n",
      "epoch:5 step:4750 [D loss: 0.545969, acc.: 74.22%] [G loss: 0.430066]\n",
      "epoch:5 step:4751 [D loss: 0.542758, acc.: 70.31%] [G loss: 0.500441]\n",
      "epoch:5 step:4752 [D loss: 0.567127, acc.: 66.41%] [G loss: 0.475086]\n",
      "epoch:5 step:4753 [D loss: 0.550975, acc.: 68.75%] [G loss: 0.472654]\n",
      "epoch:5 step:4754 [D loss: 0.559228, acc.: 73.44%] [G loss: 0.642504]\n",
      "epoch:5 step:4755 [D loss: 0.489154, acc.: 78.91%] [G loss: 0.518563]\n",
      "epoch:5 step:4756 [D loss: 0.472268, acc.: 76.56%] [G loss: 0.617199]\n",
      "epoch:5 step:4757 [D loss: 0.478787, acc.: 78.91%] [G loss: 0.649270]\n",
      "epoch:5 step:4758 [D loss: 0.534656, acc.: 70.31%] [G loss: 0.542371]\n",
      "epoch:5 step:4759 [D loss: 0.494830, acc.: 79.69%] [G loss: 0.588950]\n",
      "epoch:5 step:4760 [D loss: 0.492540, acc.: 75.78%] [G loss: 0.703545]\n",
      "epoch:5 step:4761 [D loss: 0.469033, acc.: 77.34%] [G loss: 0.711925]\n",
      "epoch:5 step:4762 [D loss: 0.453194, acc.: 78.12%] [G loss: 0.756570]\n",
      "epoch:5 step:4763 [D loss: 0.616039, acc.: 64.84%] [G loss: 0.611245]\n",
      "epoch:5 step:4764 [D loss: 0.546500, acc.: 71.88%] [G loss: 0.512910]\n",
      "epoch:5 step:4765 [D loss: 0.557395, acc.: 69.53%] [G loss: 0.604825]\n",
      "epoch:5 step:4766 [D loss: 0.581256, acc.: 68.75%] [G loss: 0.524677]\n",
      "epoch:5 step:4767 [D loss: 0.469785, acc.: 78.12%] [G loss: 0.719081]\n",
      "epoch:5 step:4768 [D loss: 0.463600, acc.: 79.69%] [G loss: 0.595075]\n",
      "epoch:5 step:4769 [D loss: 0.499452, acc.: 75.78%] [G loss: 0.700914]\n",
      "epoch:5 step:4770 [D loss: 0.558485, acc.: 70.31%] [G loss: 0.531094]\n",
      "epoch:5 step:4771 [D loss: 0.518433, acc.: 75.00%] [G loss: 0.462794]\n",
      "epoch:5 step:4772 [D loss: 0.546491, acc.: 69.53%] [G loss: 0.518368]\n",
      "epoch:5 step:4773 [D loss: 0.516155, acc.: 77.34%] [G loss: 0.775184]\n",
      "epoch:5 step:4774 [D loss: 0.479962, acc.: 77.34%] [G loss: 0.718581]\n",
      "epoch:5 step:4775 [D loss: 0.517330, acc.: 72.66%] [G loss: 0.642837]\n",
      "epoch:5 step:4776 [D loss: 0.550471, acc.: 71.09%] [G loss: 0.575688]\n",
      "epoch:5 step:4777 [D loss: 0.508057, acc.: 76.56%] [G loss: 0.588369]\n",
      "epoch:5 step:4778 [D loss: 0.513583, acc.: 71.88%] [G loss: 0.634677]\n",
      "epoch:5 step:4779 [D loss: 0.575752, acc.: 67.97%] [G loss: 0.667689]\n",
      "epoch:5 step:4780 [D loss: 0.529041, acc.: 71.88%] [G loss: 0.665363]\n",
      "epoch:5 step:4781 [D loss: 0.454452, acc.: 80.47%] [G loss: 0.671732]\n",
      "epoch:5 step:4782 [D loss: 0.520125, acc.: 76.56%] [G loss: 0.705914]\n",
      "epoch:5 step:4783 [D loss: 0.581793, acc.: 67.19%] [G loss: 0.643925]\n",
      "epoch:5 step:4784 [D loss: 0.551494, acc.: 68.75%] [G loss: 0.536271]\n",
      "epoch:5 step:4785 [D loss: 0.467253, acc.: 78.12%] [G loss: 0.673317]\n",
      "epoch:5 step:4786 [D loss: 0.492268, acc.: 75.78%] [G loss: 0.576386]\n",
      "epoch:5 step:4787 [D loss: 0.604315, acc.: 66.41%] [G loss: 0.460461]\n",
      "epoch:5 step:4788 [D loss: 0.490507, acc.: 76.56%] [G loss: 0.693918]\n",
      "epoch:5 step:4789 [D loss: 0.454317, acc.: 82.03%] [G loss: 0.596118]\n",
      "epoch:5 step:4790 [D loss: 0.516601, acc.: 71.09%] [G loss: 0.685708]\n",
      "epoch:5 step:4791 [D loss: 0.610591, acc.: 64.84%] [G loss: 0.482406]\n",
      "epoch:5 step:4792 [D loss: 0.617656, acc.: 65.62%] [G loss: 0.505006]\n",
      "epoch:5 step:4793 [D loss: 0.595566, acc.: 71.88%] [G loss: 0.733790]\n",
      "epoch:5 step:4794 [D loss: 0.582693, acc.: 73.44%] [G loss: 0.503219]\n",
      "epoch:5 step:4795 [D loss: 0.548709, acc.: 72.66%] [G loss: 0.441482]\n",
      "epoch:5 step:4796 [D loss: 0.484926, acc.: 82.03%] [G loss: 0.671916]\n",
      "epoch:5 step:4797 [D loss: 0.490510, acc.: 76.56%] [G loss: 0.574994]\n",
      "epoch:5 step:4798 [D loss: 0.595552, acc.: 69.53%] [G loss: 0.605533]\n",
      "epoch:5 step:4799 [D loss: 0.565902, acc.: 70.31%] [G loss: 0.523515]\n",
      "epoch:5 step:4800 [D loss: 0.561322, acc.: 74.22%] [G loss: 0.503801]\n",
      "##############\n",
      "[3.44595914 1.57787676 7.00029535 5.0181386  4.31941434 6.44094892\n",
      " 5.28819647 5.34826053 5.26704069 4.07839861]\n",
      "##########\n",
      "epoch:5 step:4801 [D loss: 0.491252, acc.: 73.44%] [G loss: 0.697314]\n",
      "epoch:5 step:4802 [D loss: 0.496303, acc.: 75.78%] [G loss: 0.682826]\n",
      "epoch:5 step:4803 [D loss: 0.528323, acc.: 71.09%] [G loss: 0.749436]\n",
      "epoch:5 step:4804 [D loss: 0.431297, acc.: 83.59%] [G loss: 0.825478]\n",
      "epoch:5 step:4805 [D loss: 0.618890, acc.: 67.97%] [G loss: 0.510401]\n",
      "epoch:5 step:4806 [D loss: 0.597418, acc.: 67.97%] [G loss: 0.590040]\n",
      "epoch:5 step:4807 [D loss: 0.511370, acc.: 78.12%] [G loss: 0.782948]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4808 [D loss: 0.573603, acc.: 75.00%] [G loss: 0.590270]\n",
      "epoch:5 step:4809 [D loss: 0.588447, acc.: 65.62%] [G loss: 0.646500]\n",
      "epoch:5 step:4810 [D loss: 0.531456, acc.: 71.88%] [G loss: 0.597164]\n",
      "epoch:5 step:4811 [D loss: 0.535614, acc.: 75.00%] [G loss: 0.505503]\n",
      "epoch:5 step:4812 [D loss: 0.534087, acc.: 68.75%] [G loss: 0.649802]\n",
      "epoch:5 step:4813 [D loss: 0.505661, acc.: 74.22%] [G loss: 0.535530]\n",
      "epoch:5 step:4814 [D loss: 0.588327, acc.: 69.53%] [G loss: 0.572099]\n",
      "epoch:5 step:4815 [D loss: 0.513588, acc.: 76.56%] [G loss: 0.490681]\n",
      "epoch:5 step:4816 [D loss: 0.477755, acc.: 78.12%] [G loss: 0.606908]\n",
      "epoch:5 step:4817 [D loss: 0.526763, acc.: 72.66%] [G loss: 0.619742]\n",
      "epoch:5 step:4818 [D loss: 0.587692, acc.: 69.53%] [G loss: 0.592612]\n",
      "epoch:5 step:4819 [D loss: 0.495896, acc.: 76.56%] [G loss: 0.470586]\n",
      "epoch:5 step:4820 [D loss: 0.522250, acc.: 74.22%] [G loss: 0.767390]\n",
      "epoch:5 step:4821 [D loss: 0.538888, acc.: 71.88%] [G loss: 0.650025]\n",
      "epoch:5 step:4822 [D loss: 0.561415, acc.: 67.97%] [G loss: 0.539879]\n",
      "epoch:5 step:4823 [D loss: 0.590914, acc.: 68.75%] [G loss: 0.549720]\n",
      "epoch:5 step:4824 [D loss: 0.556481, acc.: 67.19%] [G loss: 0.552129]\n",
      "epoch:5 step:4825 [D loss: 0.539164, acc.: 69.53%] [G loss: 0.595206]\n",
      "epoch:5 step:4826 [D loss: 0.490312, acc.: 76.56%] [G loss: 0.555859]\n",
      "epoch:5 step:4827 [D loss: 0.514038, acc.: 75.78%] [G loss: 0.720377]\n",
      "epoch:5 step:4828 [D loss: 0.603835, acc.: 64.84%] [G loss: 0.548654]\n",
      "epoch:5 step:4829 [D loss: 0.488669, acc.: 72.66%] [G loss: 0.541070]\n",
      "epoch:5 step:4830 [D loss: 0.523337, acc.: 78.91%] [G loss: 0.732694]\n",
      "epoch:5 step:4831 [D loss: 0.511169, acc.: 72.66%] [G loss: 0.739538]\n",
      "epoch:5 step:4832 [D loss: 0.566263, acc.: 76.56%] [G loss: 0.595003]\n",
      "epoch:5 step:4833 [D loss: 0.526000, acc.: 71.88%] [G loss: 0.543565]\n",
      "epoch:5 step:4834 [D loss: 0.478691, acc.: 78.91%] [G loss: 0.581089]\n",
      "epoch:5 step:4835 [D loss: 0.611293, acc.: 68.75%] [G loss: 0.512024]\n",
      "epoch:5 step:4836 [D loss: 0.514332, acc.: 75.78%] [G loss: 0.574196]\n",
      "epoch:5 step:4837 [D loss: 0.453068, acc.: 81.25%] [G loss: 0.787362]\n",
      "epoch:5 step:4838 [D loss: 0.574195, acc.: 67.97%] [G loss: 0.471291]\n",
      "epoch:5 step:4839 [D loss: 0.465968, acc.: 78.91%] [G loss: 0.658761]\n",
      "epoch:5 step:4840 [D loss: 0.444969, acc.: 83.59%] [G loss: 0.644712]\n",
      "epoch:5 step:4841 [D loss: 0.505079, acc.: 76.56%] [G loss: 0.606025]\n",
      "epoch:5 step:4842 [D loss: 0.559266, acc.: 72.66%] [G loss: 0.466957]\n",
      "epoch:5 step:4843 [D loss: 0.492289, acc.: 81.25%] [G loss: 0.575617]\n",
      "epoch:5 step:4844 [D loss: 0.539112, acc.: 75.00%] [G loss: 0.522655]\n",
      "epoch:5 step:4845 [D loss: 0.632273, acc.: 65.62%] [G loss: 0.632129]\n",
      "epoch:5 step:4846 [D loss: 0.506124, acc.: 77.34%] [G loss: 0.662329]\n",
      "epoch:5 step:4847 [D loss: 0.502275, acc.: 77.34%] [G loss: 0.617035]\n",
      "epoch:5 step:4848 [D loss: 0.465857, acc.: 81.25%] [G loss: 0.743354]\n",
      "epoch:5 step:4849 [D loss: 0.478141, acc.: 79.69%] [G loss: 0.613099]\n",
      "epoch:5 step:4850 [D loss: 0.536426, acc.: 68.75%] [G loss: 0.677947]\n",
      "epoch:5 step:4851 [D loss: 0.519783, acc.: 73.44%] [G loss: 0.587854]\n",
      "epoch:5 step:4852 [D loss: 0.536937, acc.: 67.97%] [G loss: 0.482655]\n",
      "epoch:5 step:4853 [D loss: 0.554238, acc.: 72.66%] [G loss: 0.559061]\n",
      "epoch:5 step:4854 [D loss: 0.555340, acc.: 67.19%] [G loss: 0.574470]\n",
      "epoch:5 step:4855 [D loss: 0.547950, acc.: 73.44%] [G loss: 0.480337]\n",
      "epoch:5 step:4856 [D loss: 0.459551, acc.: 80.47%] [G loss: 0.676758]\n",
      "epoch:5 step:4857 [D loss: 0.504413, acc.: 78.91%] [G loss: 0.575328]\n",
      "epoch:5 step:4858 [D loss: 0.480662, acc.: 80.47%] [G loss: 0.604707]\n",
      "epoch:5 step:4859 [D loss: 0.548623, acc.: 75.00%] [G loss: 0.712604]\n",
      "epoch:5 step:4860 [D loss: 0.557078, acc.: 70.31%] [G loss: 0.591500]\n",
      "epoch:5 step:4861 [D loss: 0.526565, acc.: 73.44%] [G loss: 0.681548]\n",
      "epoch:5 step:4862 [D loss: 0.516634, acc.: 75.00%] [G loss: 0.623101]\n",
      "epoch:5 step:4863 [D loss: 0.542431, acc.: 74.22%] [G loss: 0.581192]\n",
      "epoch:5 step:4864 [D loss: 0.510634, acc.: 75.00%] [G loss: 0.581683]\n",
      "epoch:5 step:4865 [D loss: 0.610806, acc.: 65.62%] [G loss: 0.532827]\n",
      "epoch:5 step:4866 [D loss: 0.533036, acc.: 69.53%] [G loss: 0.599161]\n",
      "epoch:5 step:4867 [D loss: 0.598392, acc.: 62.50%] [G loss: 0.502118]\n",
      "epoch:5 step:4868 [D loss: 0.495432, acc.: 75.78%] [G loss: 0.596405]\n",
      "epoch:5 step:4869 [D loss: 0.572415, acc.: 61.72%] [G loss: 0.585513]\n",
      "epoch:5 step:4870 [D loss: 0.564022, acc.: 73.44%] [G loss: 0.551902]\n",
      "epoch:5 step:4871 [D loss: 0.624137, acc.: 67.97%] [G loss: 0.457541]\n",
      "epoch:5 step:4872 [D loss: 0.564445, acc.: 71.09%] [G loss: 0.565041]\n",
      "epoch:5 step:4873 [D loss: 0.566084, acc.: 66.41%] [G loss: 0.449426]\n",
      "epoch:5 step:4874 [D loss: 0.547604, acc.: 69.53%] [G loss: 0.517112]\n",
      "epoch:5 step:4875 [D loss: 0.491048, acc.: 79.69%] [G loss: 0.668528]\n",
      "epoch:5 step:4876 [D loss: 0.519761, acc.: 73.44%] [G loss: 0.599079]\n",
      "epoch:5 step:4877 [D loss: 0.512207, acc.: 73.44%] [G loss: 0.601012]\n",
      "epoch:5 step:4878 [D loss: 0.531779, acc.: 74.22%] [G loss: 0.562962]\n",
      "epoch:5 step:4879 [D loss: 0.468001, acc.: 75.00%] [G loss: 0.681148]\n",
      "epoch:5 step:4880 [D loss: 0.537874, acc.: 71.09%] [G loss: 0.792727]\n",
      "epoch:5 step:4881 [D loss: 0.576769, acc.: 70.31%] [G loss: 0.592893]\n",
      "epoch:5 step:4882 [D loss: 0.566311, acc.: 68.75%] [G loss: 0.562629]\n",
      "epoch:5 step:4883 [D loss: 0.533431, acc.: 71.88%] [G loss: 0.624534]\n",
      "epoch:5 step:4884 [D loss: 0.542864, acc.: 69.53%] [G loss: 0.716650]\n",
      "epoch:5 step:4885 [D loss: 0.672439, acc.: 58.59%] [G loss: 0.592189]\n",
      "epoch:5 step:4886 [D loss: 0.600703, acc.: 75.00%] [G loss: 0.487331]\n",
      "epoch:5 step:4887 [D loss: 0.565969, acc.: 69.53%] [G loss: 0.512079]\n",
      "epoch:5 step:4888 [D loss: 0.610005, acc.: 67.19%] [G loss: 0.405396]\n",
      "epoch:5 step:4889 [D loss: 0.554834, acc.: 76.56%] [G loss: 0.517735]\n",
      "epoch:5 step:4890 [D loss: 0.497489, acc.: 77.34%] [G loss: 0.630804]\n",
      "epoch:5 step:4891 [D loss: 0.482343, acc.: 76.56%] [G loss: 0.712589]\n",
      "epoch:5 step:4892 [D loss: 0.423487, acc.: 78.91%] [G loss: 0.691754]\n",
      "epoch:5 step:4893 [D loss: 0.468499, acc.: 78.91%] [G loss: 0.767160]\n",
      "epoch:5 step:4894 [D loss: 0.480152, acc.: 81.25%] [G loss: 0.689557]\n",
      "epoch:5 step:4895 [D loss: 0.579093, acc.: 72.66%] [G loss: 0.612579]\n",
      "epoch:5 step:4896 [D loss: 0.599222, acc.: 64.06%] [G loss: 0.504688]\n",
      "epoch:5 step:4897 [D loss: 0.526039, acc.: 77.34%] [G loss: 0.444795]\n",
      "epoch:5 step:4898 [D loss: 0.551061, acc.: 72.66%] [G loss: 0.446590]\n",
      "epoch:5 step:4899 [D loss: 0.665665, acc.: 61.72%] [G loss: 0.417200]\n",
      "epoch:5 step:4900 [D loss: 0.603878, acc.: 64.06%] [G loss: 0.462089]\n",
      "epoch:5 step:4901 [D loss: 0.541875, acc.: 71.88%] [G loss: 0.491358]\n",
      "epoch:5 step:4902 [D loss: 0.527725, acc.: 71.09%] [G loss: 0.623132]\n",
      "epoch:5 step:4903 [D loss: 0.467585, acc.: 79.69%] [G loss: 0.598879]\n",
      "epoch:5 step:4904 [D loss: 0.475725, acc.: 75.78%] [G loss: 0.715990]\n",
      "epoch:5 step:4905 [D loss: 0.598179, acc.: 67.19%] [G loss: 0.427349]\n",
      "epoch:5 step:4906 [D loss: 0.485749, acc.: 75.00%] [G loss: 0.696697]\n",
      "epoch:5 step:4907 [D loss: 0.440734, acc.: 83.59%] [G loss: 0.673429]\n",
      "epoch:5 step:4908 [D loss: 0.483340, acc.: 74.22%] [G loss: 0.704131]\n",
      "epoch:5 step:4909 [D loss: 0.594557, acc.: 68.75%] [G loss: 0.535874]\n",
      "epoch:5 step:4910 [D loss: 0.616163, acc.: 67.97%] [G loss: 0.541728]\n",
      "epoch:5 step:4911 [D loss: 0.570405, acc.: 65.62%] [G loss: 0.580991]\n",
      "epoch:5 step:4912 [D loss: 0.542543, acc.: 74.22%] [G loss: 0.460704]\n",
      "epoch:5 step:4913 [D loss: 0.576907, acc.: 65.62%] [G loss: 0.441865]\n",
      "epoch:5 step:4914 [D loss: 0.543309, acc.: 75.78%] [G loss: 0.424393]\n",
      "epoch:5 step:4915 [D loss: 0.518306, acc.: 71.88%] [G loss: 0.494002]\n",
      "epoch:5 step:4916 [D loss: 0.444709, acc.: 81.25%] [G loss: 0.731315]\n",
      "epoch:5 step:4917 [D loss: 0.469788, acc.: 78.12%] [G loss: 0.750985]\n",
      "epoch:5 step:4918 [D loss: 0.561993, acc.: 69.53%] [G loss: 0.705471]\n",
      "epoch:5 step:4919 [D loss: 0.511776, acc.: 73.44%] [G loss: 0.634880]\n",
      "epoch:5 step:4920 [D loss: 0.537597, acc.: 68.75%] [G loss: 0.574976]\n",
      "epoch:5 step:4921 [D loss: 0.510544, acc.: 76.56%] [G loss: 0.558590]\n",
      "epoch:5 step:4922 [D loss: 0.556557, acc.: 72.66%] [G loss: 0.480094]\n",
      "epoch:5 step:4923 [D loss: 0.524031, acc.: 77.34%] [G loss: 0.580885]\n",
      "epoch:5 step:4924 [D loss: 0.534842, acc.: 74.22%] [G loss: 0.601671]\n",
      "epoch:5 step:4925 [D loss: 0.522643, acc.: 72.66%] [G loss: 0.699562]\n",
      "epoch:5 step:4926 [D loss: 0.525086, acc.: 73.44%] [G loss: 0.604859]\n",
      "epoch:5 step:4927 [D loss: 0.531696, acc.: 72.66%] [G loss: 0.600514]\n",
      "epoch:5 step:4928 [D loss: 0.553247, acc.: 73.44%] [G loss: 0.508508]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4929 [D loss: 0.534648, acc.: 70.31%] [G loss: 0.621061]\n",
      "epoch:5 step:4930 [D loss: 0.499393, acc.: 78.12%] [G loss: 0.630181]\n",
      "epoch:5 step:4931 [D loss: 0.556522, acc.: 67.97%] [G loss: 0.618711]\n",
      "epoch:5 step:4932 [D loss: 0.543390, acc.: 74.22%] [G loss: 0.729428]\n",
      "epoch:5 step:4933 [D loss: 0.474852, acc.: 75.78%] [G loss: 0.685643]\n",
      "epoch:5 step:4934 [D loss: 0.540630, acc.: 77.34%] [G loss: 0.575187]\n",
      "epoch:5 step:4935 [D loss: 0.623412, acc.: 66.41%] [G loss: 0.505260]\n",
      "epoch:5 step:4936 [D loss: 0.556377, acc.: 71.09%] [G loss: 0.542606]\n",
      "epoch:5 step:4937 [D loss: 0.563120, acc.: 72.66%] [G loss: 0.557200]\n",
      "epoch:5 step:4938 [D loss: 0.475545, acc.: 79.69%] [G loss: 0.662638]\n",
      "epoch:5 step:4939 [D loss: 0.518246, acc.: 75.00%] [G loss: 0.676570]\n",
      "epoch:5 step:4940 [D loss: 0.523839, acc.: 73.44%] [G loss: 0.614755]\n",
      "epoch:5 step:4941 [D loss: 0.482194, acc.: 77.34%] [G loss: 0.678736]\n",
      "epoch:5 step:4942 [D loss: 0.573556, acc.: 69.53%] [G loss: 0.555910]\n",
      "epoch:5 step:4943 [D loss: 0.499098, acc.: 74.22%] [G loss: 0.580355]\n",
      "epoch:5 step:4944 [D loss: 0.512382, acc.: 76.56%] [G loss: 0.638641]\n",
      "epoch:5 step:4945 [D loss: 0.565364, acc.: 70.31%] [G loss: 0.590274]\n",
      "epoch:5 step:4946 [D loss: 0.504344, acc.: 78.12%] [G loss: 0.609669]\n",
      "epoch:5 step:4947 [D loss: 0.524609, acc.: 75.00%] [G loss: 0.575496]\n",
      "epoch:5 step:4948 [D loss: 0.649254, acc.: 63.28%] [G loss: 0.495928]\n",
      "epoch:5 step:4949 [D loss: 0.455734, acc.: 81.25%] [G loss: 0.604259]\n",
      "epoch:5 step:4950 [D loss: 0.566398, acc.: 71.88%] [G loss: 0.625373]\n",
      "epoch:5 step:4951 [D loss: 0.495864, acc.: 76.56%] [G loss: 0.643474]\n",
      "epoch:5 step:4952 [D loss: 0.500665, acc.: 75.00%] [G loss: 0.617727]\n",
      "epoch:5 step:4953 [D loss: 0.600940, acc.: 67.97%] [G loss: 0.596135]\n",
      "epoch:5 step:4954 [D loss: 0.544004, acc.: 68.75%] [G loss: 0.588823]\n",
      "epoch:5 step:4955 [D loss: 0.514440, acc.: 75.00%] [G loss: 0.615453]\n",
      "epoch:5 step:4956 [D loss: 0.569433, acc.: 67.97%] [G loss: 0.513074]\n",
      "epoch:5 step:4957 [D loss: 0.517924, acc.: 74.22%] [G loss: 0.534477]\n",
      "epoch:5 step:4958 [D loss: 0.569188, acc.: 65.62%] [G loss: 0.526609]\n",
      "epoch:5 step:4959 [D loss: 0.560812, acc.: 67.97%] [G loss: 0.521865]\n",
      "epoch:5 step:4960 [D loss: 0.603824, acc.: 64.84%] [G loss: 0.703866]\n",
      "epoch:5 step:4961 [D loss: 0.508393, acc.: 75.00%] [G loss: 0.549275]\n",
      "epoch:5 step:4962 [D loss: 0.624270, acc.: 64.84%] [G loss: 0.484887]\n",
      "epoch:5 step:4963 [D loss: 0.591119, acc.: 66.41%] [G loss: 0.543638]\n",
      "epoch:5 step:4964 [D loss: 0.577870, acc.: 70.31%] [G loss: 0.709797]\n",
      "epoch:5 step:4965 [D loss: 0.558733, acc.: 69.53%] [G loss: 0.714467]\n",
      "epoch:5 step:4966 [D loss: 0.662201, acc.: 62.50%] [G loss: 0.454174]\n",
      "epoch:5 step:4967 [D loss: 0.545181, acc.: 75.78%] [G loss: 0.538846]\n",
      "epoch:5 step:4968 [D loss: 0.543411, acc.: 71.88%] [G loss: 0.615843]\n",
      "epoch:5 step:4969 [D loss: 0.523607, acc.: 75.78%] [G loss: 0.647526]\n",
      "epoch:5 step:4970 [D loss: 0.483442, acc.: 78.91%] [G loss: 0.574848]\n",
      "epoch:5 step:4971 [D loss: 0.487405, acc.: 76.56%] [G loss: 0.552504]\n",
      "epoch:5 step:4972 [D loss: 0.529242, acc.: 72.66%] [G loss: 0.472613]\n",
      "epoch:5 step:4973 [D loss: 0.596350, acc.: 62.50%] [G loss: 0.494873]\n",
      "epoch:5 step:4974 [D loss: 0.453235, acc.: 77.34%] [G loss: 0.648102]\n",
      "epoch:5 step:4975 [D loss: 0.501642, acc.: 75.78%] [G loss: 0.691030]\n",
      "epoch:5 step:4976 [D loss: 0.552421, acc.: 70.31%] [G loss: 0.514466]\n",
      "epoch:5 step:4977 [D loss: 0.510187, acc.: 72.66%] [G loss: 0.685105]\n",
      "epoch:5 step:4978 [D loss: 0.553020, acc.: 71.09%] [G loss: 0.551310]\n",
      "epoch:5 step:4979 [D loss: 0.578200, acc.: 70.31%] [G loss: 0.528450]\n",
      "epoch:5 step:4980 [D loss: 0.526558, acc.: 75.00%] [G loss: 0.626580]\n",
      "epoch:5 step:4981 [D loss: 0.482778, acc.: 75.00%] [G loss: 0.514475]\n",
      "epoch:5 step:4982 [D loss: 0.564842, acc.: 69.53%] [G loss: 0.479125]\n",
      "epoch:5 step:4983 [D loss: 0.529169, acc.: 75.00%] [G loss: 0.641084]\n",
      "epoch:5 step:4984 [D loss: 0.517455, acc.: 75.78%] [G loss: 0.603067]\n",
      "epoch:5 step:4985 [D loss: 0.507761, acc.: 76.56%] [G loss: 0.554556]\n",
      "epoch:5 step:4986 [D loss: 0.544844, acc.: 69.53%] [G loss: 0.570101]\n",
      "epoch:5 step:4987 [D loss: 0.504572, acc.: 78.91%] [G loss: 0.534700]\n",
      "epoch:5 step:4988 [D loss: 0.529478, acc.: 75.00%] [G loss: 0.531176]\n",
      "epoch:5 step:4989 [D loss: 0.468641, acc.: 78.91%] [G loss: 0.640738]\n",
      "epoch:5 step:4990 [D loss: 0.499566, acc.: 76.56%] [G loss: 0.607674]\n",
      "epoch:5 step:4991 [D loss: 0.564871, acc.: 69.53%] [G loss: 0.578948]\n",
      "epoch:5 step:4992 [D loss: 0.502384, acc.: 75.78%] [G loss: 0.609744]\n",
      "epoch:5 step:4993 [D loss: 0.504707, acc.: 77.34%] [G loss: 0.565121]\n",
      "epoch:5 step:4994 [D loss: 0.520235, acc.: 75.00%] [G loss: 0.653543]\n",
      "epoch:5 step:4995 [D loss: 0.458165, acc.: 82.03%] [G loss: 0.733619]\n",
      "epoch:5 step:4996 [D loss: 0.484725, acc.: 77.34%] [G loss: 0.588007]\n",
      "epoch:5 step:4997 [D loss: 0.449280, acc.: 78.91%] [G loss: 0.644580]\n",
      "epoch:5 step:4998 [D loss: 0.459197, acc.: 77.34%] [G loss: 0.881810]\n",
      "epoch:5 step:4999 [D loss: 0.463359, acc.: 81.25%] [G loss: 0.900221]\n",
      "epoch:5 step:5000 [D loss: 0.453157, acc.: 80.47%] [G loss: 0.957568]\n",
      "##############\n",
      "[3.44615335 1.53073339 6.57888322 5.05386375 4.43293334 6.21960363\n",
      " 5.12919772 4.95751297 5.1030091  3.861595  ]\n",
      "##########\n",
      "epoch:5 step:5001 [D loss: 0.696071, acc.: 69.53%] [G loss: 0.630679]\n",
      "epoch:5 step:5002 [D loss: 0.602573, acc.: 66.41%] [G loss: 0.428733]\n",
      "epoch:5 step:5003 [D loss: 0.490285, acc.: 75.00%] [G loss: 0.537109]\n",
      "epoch:5 step:5004 [D loss: 0.526563, acc.: 75.78%] [G loss: 0.588678]\n",
      "epoch:5 step:5005 [D loss: 0.522686, acc.: 68.75%] [G loss: 0.443784]\n",
      "epoch:5 step:5006 [D loss: 0.458022, acc.: 81.25%] [G loss: 0.674833]\n",
      "epoch:5 step:5007 [D loss: 0.559591, acc.: 71.09%] [G loss: 0.531272]\n",
      "epoch:5 step:5008 [D loss: 0.587645, acc.: 70.31%] [G loss: 0.452924]\n",
      "epoch:5 step:5009 [D loss: 0.508386, acc.: 76.56%] [G loss: 0.551682]\n",
      "epoch:5 step:5010 [D loss: 0.504839, acc.: 78.91%] [G loss: 0.551658]\n",
      "epoch:5 step:5011 [D loss: 0.553890, acc.: 72.66%] [G loss: 0.572603]\n",
      "epoch:5 step:5012 [D loss: 0.535080, acc.: 71.88%] [G loss: 0.500684]\n",
      "epoch:5 step:5013 [D loss: 0.444134, acc.: 80.47%] [G loss: 0.673192]\n",
      "epoch:5 step:5014 [D loss: 0.563567, acc.: 72.66%] [G loss: 0.767495]\n",
      "epoch:5 step:5015 [D loss: 0.613232, acc.: 62.50%] [G loss: 0.437091]\n",
      "epoch:5 step:5016 [D loss: 0.493773, acc.: 78.91%] [G loss: 0.622750]\n",
      "epoch:5 step:5017 [D loss: 0.480514, acc.: 77.34%] [G loss: 0.547673]\n",
      "epoch:5 step:5018 [D loss: 0.496956, acc.: 75.78%] [G loss: 0.522640]\n",
      "epoch:5 step:5019 [D loss: 0.497210, acc.: 77.34%] [G loss: 0.606263]\n",
      "epoch:5 step:5020 [D loss: 0.469656, acc.: 77.34%] [G loss: 0.709154]\n",
      "epoch:5 step:5021 [D loss: 0.478824, acc.: 77.34%] [G loss: 0.791589]\n",
      "epoch:5 step:5022 [D loss: 0.484866, acc.: 78.91%] [G loss: 0.733433]\n",
      "epoch:5 step:5023 [D loss: 0.551631, acc.: 71.88%] [G loss: 0.634202]\n",
      "epoch:5 step:5024 [D loss: 0.556050, acc.: 72.66%] [G loss: 0.483775]\n",
      "epoch:5 step:5025 [D loss: 0.502113, acc.: 81.25%] [G loss: 0.576793]\n",
      "epoch:5 step:5026 [D loss: 0.553170, acc.: 75.00%] [G loss: 0.637112]\n",
      "epoch:5 step:5027 [D loss: 0.578399, acc.: 70.31%] [G loss: 0.506512]\n",
      "epoch:5 step:5028 [D loss: 0.488107, acc.: 74.22%] [G loss: 0.592022]\n",
      "epoch:5 step:5029 [D loss: 0.509617, acc.: 74.22%] [G loss: 0.598662]\n",
      "epoch:5 step:5030 [D loss: 0.440909, acc.: 82.03%] [G loss: 0.770893]\n",
      "epoch:5 step:5031 [D loss: 0.516415, acc.: 74.22%] [G loss: 0.803125]\n",
      "epoch:5 step:5032 [D loss: 0.413712, acc.: 84.38%] [G loss: 1.032461]\n",
      "epoch:5 step:5033 [D loss: 0.669960, acc.: 67.97%] [G loss: 0.727967]\n",
      "epoch:5 step:5034 [D loss: 0.734156, acc.: 59.38%] [G loss: 0.552427]\n",
      "epoch:5 step:5035 [D loss: 0.475609, acc.: 80.47%] [G loss: 0.510469]\n",
      "epoch:5 step:5036 [D loss: 0.542025, acc.: 73.44%] [G loss: 0.661084]\n",
      "epoch:5 step:5037 [D loss: 0.543501, acc.: 72.66%] [G loss: 0.597806]\n",
      "epoch:5 step:5038 [D loss: 0.550207, acc.: 68.75%] [G loss: 0.729741]\n",
      "epoch:5 step:5039 [D loss: 0.427234, acc.: 81.25%] [G loss: 0.628246]\n",
      "epoch:5 step:5040 [D loss: 0.533356, acc.: 69.53%] [G loss: 0.674993]\n",
      "epoch:5 step:5041 [D loss: 0.567646, acc.: 67.97%] [G loss: 0.571708]\n",
      "epoch:5 step:5042 [D loss: 0.531332, acc.: 72.66%] [G loss: 0.645879]\n",
      "epoch:5 step:5043 [D loss: 0.447757, acc.: 78.91%] [G loss: 0.736980]\n",
      "epoch:5 step:5044 [D loss: 0.472526, acc.: 78.12%] [G loss: 0.764530]\n",
      "epoch:5 step:5045 [D loss: 0.497716, acc.: 73.44%] [G loss: 0.622162]\n",
      "epoch:5 step:5046 [D loss: 0.501527, acc.: 74.22%] [G loss: 0.598017]\n",
      "epoch:5 step:5047 [D loss: 0.540499, acc.: 67.97%] [G loss: 0.584987]\n",
      "epoch:5 step:5048 [D loss: 0.530329, acc.: 74.22%] [G loss: 0.439513]\n",
      "epoch:5 step:5049 [D loss: 0.509699, acc.: 77.34%] [G loss: 0.578954]\n",
      "epoch:5 step:5050 [D loss: 0.501030, acc.: 74.22%] [G loss: 0.579842]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5051 [D loss: 0.529907, acc.: 74.22%] [G loss: 0.610094]\n",
      "epoch:5 step:5052 [D loss: 0.536904, acc.: 70.31%] [G loss: 0.572206]\n",
      "epoch:5 step:5053 [D loss: 0.533858, acc.: 72.66%] [G loss: 0.632687]\n",
      "epoch:5 step:5054 [D loss: 0.514111, acc.: 75.78%] [G loss: 0.618790]\n",
      "epoch:5 step:5055 [D loss: 0.549004, acc.: 75.00%] [G loss: 0.529276]\n",
      "epoch:5 step:5056 [D loss: 0.501602, acc.: 78.12%] [G loss: 0.675089]\n",
      "epoch:5 step:5057 [D loss: 0.532654, acc.: 75.00%] [G loss: 0.704670]\n",
      "epoch:5 step:5058 [D loss: 0.594119, acc.: 67.19%] [G loss: 0.514641]\n",
      "epoch:5 step:5059 [D loss: 0.484978, acc.: 75.78%] [G loss: 0.651495]\n",
      "epoch:5 step:5060 [D loss: 0.602434, acc.: 65.62%] [G loss: 0.444295]\n",
      "epoch:5 step:5061 [D loss: 0.644273, acc.: 60.94%] [G loss: 0.485512]\n",
      "epoch:5 step:5062 [D loss: 0.572995, acc.: 69.53%] [G loss: 0.453114]\n",
      "epoch:5 step:5063 [D loss: 0.543514, acc.: 73.44%] [G loss: 0.550427]\n",
      "epoch:5 step:5064 [D loss: 0.526716, acc.: 67.97%] [G loss: 0.510617]\n",
      "epoch:5 step:5065 [D loss: 0.572648, acc.: 70.31%] [G loss: 0.458223]\n",
      "epoch:5 step:5066 [D loss: 0.440563, acc.: 84.38%] [G loss: 0.602701]\n",
      "epoch:5 step:5067 [D loss: 0.521309, acc.: 71.88%] [G loss: 0.585942]\n",
      "epoch:5 step:5068 [D loss: 0.603573, acc.: 67.97%] [G loss: 0.584121]\n",
      "epoch:5 step:5069 [D loss: 0.595214, acc.: 67.19%] [G loss: 0.503561]\n",
      "epoch:5 step:5070 [D loss: 0.520120, acc.: 77.34%] [G loss: 0.508190]\n",
      "epoch:5 step:5071 [D loss: 0.542162, acc.: 73.44%] [G loss: 0.507531]\n",
      "epoch:5 step:5072 [D loss: 0.561931, acc.: 71.09%] [G loss: 0.508822]\n",
      "epoch:5 step:5073 [D loss: 0.552485, acc.: 71.88%] [G loss: 0.542834]\n",
      "epoch:5 step:5074 [D loss: 0.561314, acc.: 73.44%] [G loss: 0.583121]\n",
      "epoch:5 step:5075 [D loss: 0.590657, acc.: 67.19%] [G loss: 0.501603]\n",
      "epoch:5 step:5076 [D loss: 0.528323, acc.: 72.66%] [G loss: 0.395382]\n",
      "epoch:5 step:5077 [D loss: 0.479505, acc.: 75.78%] [G loss: 0.614014]\n",
      "epoch:5 step:5078 [D loss: 0.555669, acc.: 71.09%] [G loss: 0.474092]\n",
      "epoch:5 step:5079 [D loss: 0.558306, acc.: 70.31%] [G loss: 0.437020]\n",
      "epoch:5 step:5080 [D loss: 0.503992, acc.: 72.66%] [G loss: 0.532077]\n",
      "epoch:5 step:5081 [D loss: 0.590329, acc.: 67.19%] [G loss: 0.568492]\n",
      "epoch:5 step:5082 [D loss: 0.477898, acc.: 78.91%] [G loss: 0.711099]\n",
      "epoch:5 step:5083 [D loss: 0.462208, acc.: 80.47%] [G loss: 0.813903]\n",
      "epoch:5 step:5084 [D loss: 0.509066, acc.: 75.78%] [G loss: 0.649642]\n",
      "epoch:5 step:5085 [D loss: 0.602475, acc.: 64.06%] [G loss: 0.543899]\n",
      "epoch:5 step:5086 [D loss: 0.609097, acc.: 68.75%] [G loss: 0.543051]\n",
      "epoch:5 step:5087 [D loss: 0.494069, acc.: 75.78%] [G loss: 0.630408]\n",
      "epoch:5 step:5088 [D loss: 0.515969, acc.: 70.31%] [G loss: 0.627320]\n",
      "epoch:5 step:5089 [D loss: 0.629444, acc.: 70.31%] [G loss: 0.480870]\n",
      "epoch:5 step:5090 [D loss: 0.557828, acc.: 75.78%] [G loss: 0.593835]\n",
      "epoch:5 step:5091 [D loss: 0.519207, acc.: 76.56%] [G loss: 0.663194]\n",
      "epoch:5 step:5092 [D loss: 0.550838, acc.: 73.44%] [G loss: 0.605647]\n",
      "epoch:5 step:5093 [D loss: 0.525763, acc.: 71.88%] [G loss: 0.560918]\n",
      "epoch:5 step:5094 [D loss: 0.518399, acc.: 74.22%] [G loss: 0.655622]\n",
      "epoch:5 step:5095 [D loss: 0.569134, acc.: 69.53%] [G loss: 0.434936]\n",
      "epoch:5 step:5096 [D loss: 0.600486, acc.: 67.97%] [G loss: 0.483817]\n",
      "epoch:5 step:5097 [D loss: 0.551555, acc.: 74.22%] [G loss: 0.499555]\n",
      "epoch:5 step:5098 [D loss: 0.597352, acc.: 69.53%] [G loss: 0.440522]\n",
      "epoch:5 step:5099 [D loss: 0.544761, acc.: 75.78%] [G loss: 0.457815]\n",
      "epoch:5 step:5100 [D loss: 0.533746, acc.: 73.44%] [G loss: 0.542065]\n",
      "epoch:5 step:5101 [D loss: 0.520077, acc.: 76.56%] [G loss: 0.627556]\n",
      "epoch:5 step:5102 [D loss: 0.617958, acc.: 70.31%] [G loss: 0.454064]\n",
      "epoch:5 step:5103 [D loss: 0.608431, acc.: 62.50%] [G loss: 0.439877]\n",
      "epoch:5 step:5104 [D loss: 0.540476, acc.: 71.88%] [G loss: 0.533065]\n",
      "epoch:5 step:5105 [D loss: 0.574804, acc.: 64.84%] [G loss: 0.494848]\n",
      "epoch:5 step:5106 [D loss: 0.591901, acc.: 67.19%] [G loss: 0.450020]\n",
      "epoch:5 step:5107 [D loss: 0.528901, acc.: 71.88%] [G loss: 0.511360]\n",
      "epoch:5 step:5108 [D loss: 0.530556, acc.: 71.88%] [G loss: 0.446174]\n",
      "epoch:5 step:5109 [D loss: 0.521291, acc.: 75.78%] [G loss: 0.638868]\n",
      "epoch:5 step:5110 [D loss: 0.496926, acc.: 74.22%] [G loss: 0.715676]\n",
      "epoch:5 step:5111 [D loss: 0.485724, acc.: 76.56%] [G loss: 0.801010]\n",
      "epoch:5 step:5112 [D loss: 0.522034, acc.: 77.34%] [G loss: 0.778231]\n",
      "epoch:5 step:5113 [D loss: 0.492428, acc.: 78.12%] [G loss: 0.657475]\n",
      "epoch:5 step:5114 [D loss: 0.492146, acc.: 73.44%] [G loss: 0.784972]\n",
      "epoch:5 step:5115 [D loss: 0.472575, acc.: 78.12%] [G loss: 0.667708]\n",
      "epoch:5 step:5116 [D loss: 0.510751, acc.: 73.44%] [G loss: 0.570082]\n",
      "epoch:5 step:5117 [D loss: 0.553915, acc.: 69.53%] [G loss: 0.607935]\n",
      "epoch:5 step:5118 [D loss: 0.589458, acc.: 67.97%] [G loss: 0.577837]\n",
      "epoch:5 step:5119 [D loss: 0.499452, acc.: 78.12%] [G loss: 0.500343]\n",
      "epoch:5 step:5120 [D loss: 0.527607, acc.: 75.00%] [G loss: 0.567047]\n",
      "epoch:5 step:5121 [D loss: 0.515512, acc.: 75.00%] [G loss: 0.533704]\n",
      "epoch:5 step:5122 [D loss: 0.642108, acc.: 64.84%] [G loss: 0.415114]\n",
      "epoch:5 step:5123 [D loss: 0.553548, acc.: 67.19%] [G loss: 0.475953]\n",
      "epoch:5 step:5124 [D loss: 0.539911, acc.: 71.09%] [G loss: 0.477692]\n",
      "epoch:5 step:5125 [D loss: 0.532584, acc.: 72.66%] [G loss: 0.604066]\n",
      "epoch:5 step:5126 [D loss: 0.553580, acc.: 70.31%] [G loss: 0.545844]\n",
      "epoch:5 step:5127 [D loss: 0.561218, acc.: 70.31%] [G loss: 0.570274]\n",
      "epoch:5 step:5128 [D loss: 0.527373, acc.: 68.75%] [G loss: 0.490323]\n",
      "epoch:5 step:5129 [D loss: 0.523560, acc.: 71.88%] [G loss: 0.528170]\n",
      "epoch:5 step:5130 [D loss: 0.545609, acc.: 69.53%] [G loss: 0.705922]\n",
      "epoch:5 step:5131 [D loss: 0.517248, acc.: 72.66%] [G loss: 0.695105]\n",
      "epoch:5 step:5132 [D loss: 0.513967, acc.: 75.00%] [G loss: 0.632558]\n",
      "epoch:5 step:5133 [D loss: 0.506247, acc.: 80.47%] [G loss: 0.659114]\n",
      "epoch:5 step:5134 [D loss: 0.535639, acc.: 71.88%] [G loss: 0.680237]\n",
      "epoch:5 step:5135 [D loss: 0.571093, acc.: 67.97%] [G loss: 0.567509]\n",
      "epoch:5 step:5136 [D loss: 0.442019, acc.: 81.25%] [G loss: 0.707888]\n",
      "epoch:5 step:5137 [D loss: 0.485639, acc.: 78.91%] [G loss: 0.719094]\n",
      "epoch:5 step:5138 [D loss: 0.507108, acc.: 75.00%] [G loss: 0.738465]\n",
      "epoch:5 step:5139 [D loss: 0.577084, acc.: 68.75%] [G loss: 0.689062]\n",
      "epoch:5 step:5140 [D loss: 0.549298, acc.: 69.53%] [G loss: 0.621354]\n",
      "epoch:5 step:5141 [D loss: 0.625950, acc.: 61.72%] [G loss: 0.417178]\n",
      "epoch:5 step:5142 [D loss: 0.525400, acc.: 75.00%] [G loss: 0.486998]\n",
      "epoch:5 step:5143 [D loss: 0.541946, acc.: 71.88%] [G loss: 0.573371]\n",
      "epoch:5 step:5144 [D loss: 0.510867, acc.: 78.91%] [G loss: 0.474480]\n",
      "epoch:5 step:5145 [D loss: 0.500980, acc.: 78.91%] [G loss: 0.514693]\n",
      "epoch:5 step:5146 [D loss: 0.485701, acc.: 77.34%] [G loss: 0.571445]\n",
      "epoch:5 step:5147 [D loss: 0.550401, acc.: 70.31%] [G loss: 0.668773]\n",
      "epoch:5 step:5148 [D loss: 0.546521, acc.: 75.78%] [G loss: 0.438377]\n",
      "epoch:5 step:5149 [D loss: 0.555619, acc.: 70.31%] [G loss: 0.678950]\n",
      "epoch:5 step:5150 [D loss: 0.587095, acc.: 64.84%] [G loss: 0.472122]\n",
      "epoch:5 step:5151 [D loss: 0.509923, acc.: 74.22%] [G loss: 0.584496]\n",
      "epoch:5 step:5152 [D loss: 0.504190, acc.: 77.34%] [G loss: 0.582087]\n",
      "epoch:5 step:5153 [D loss: 0.567605, acc.: 68.75%] [G loss: 0.573701]\n",
      "epoch:5 step:5154 [D loss: 0.536351, acc.: 73.44%] [G loss: 0.587961]\n",
      "epoch:5 step:5155 [D loss: 0.534020, acc.: 70.31%] [G loss: 0.568327]\n",
      "epoch:5 step:5156 [D loss: 0.483377, acc.: 79.69%] [G loss: 0.742355]\n",
      "epoch:5 step:5157 [D loss: 0.472755, acc.: 78.12%] [G loss: 0.761273]\n",
      "epoch:5 step:5158 [D loss: 0.647762, acc.: 63.28%] [G loss: 0.635010]\n",
      "epoch:5 step:5159 [D loss: 0.552968, acc.: 71.88%] [G loss: 0.796443]\n",
      "epoch:5 step:5160 [D loss: 0.477234, acc.: 77.34%] [G loss: 0.820366]\n",
      "epoch:5 step:5161 [D loss: 0.576856, acc.: 71.88%] [G loss: 0.579594]\n",
      "epoch:5 step:5162 [D loss: 0.663005, acc.: 60.16%] [G loss: 0.465131]\n",
      "epoch:5 step:5163 [D loss: 0.572495, acc.: 65.62%] [G loss: 0.436691]\n",
      "epoch:5 step:5164 [D loss: 0.504022, acc.: 78.91%] [G loss: 0.531726]\n",
      "epoch:5 step:5165 [D loss: 0.530051, acc.: 75.78%] [G loss: 0.445038]\n",
      "epoch:5 step:5166 [D loss: 0.510160, acc.: 71.88%] [G loss: 0.510685]\n",
      "epoch:5 step:5167 [D loss: 0.623575, acc.: 63.28%] [G loss: 0.416952]\n",
      "epoch:5 step:5168 [D loss: 0.565053, acc.: 67.97%] [G loss: 0.454370]\n",
      "epoch:5 step:5169 [D loss: 0.575769, acc.: 66.41%] [G loss: 0.421963]\n",
      "epoch:5 step:5170 [D loss: 0.488849, acc.: 78.12%] [G loss: 0.736872]\n",
      "epoch:5 step:5171 [D loss: 0.560815, acc.: 68.75%] [G loss: 0.521113]\n",
      "epoch:5 step:5172 [D loss: 0.558351, acc.: 71.09%] [G loss: 0.587842]\n",
      "epoch:5 step:5173 [D loss: 0.510546, acc.: 73.44%] [G loss: 0.545953]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5174 [D loss: 0.544511, acc.: 71.88%] [G loss: 0.609929]\n",
      "epoch:5 step:5175 [D loss: 0.542953, acc.: 71.88%] [G loss: 0.593433]\n",
      "epoch:5 step:5176 [D loss: 0.565214, acc.: 71.09%] [G loss: 0.592235]\n",
      "epoch:5 step:5177 [D loss: 0.516194, acc.: 78.12%] [G loss: 0.709560]\n",
      "epoch:5 step:5178 [D loss: 0.620114, acc.: 64.06%] [G loss: 0.527303]\n",
      "epoch:5 step:5179 [D loss: 0.572447, acc.: 70.31%] [G loss: 0.626081]\n",
      "epoch:5 step:5180 [D loss: 0.532671, acc.: 71.88%] [G loss: 0.552167]\n",
      "epoch:5 step:5181 [D loss: 0.572497, acc.: 69.53%] [G loss: 0.629924]\n",
      "epoch:5 step:5182 [D loss: 0.552172, acc.: 68.75%] [G loss: 0.560153]\n",
      "epoch:5 step:5183 [D loss: 0.503460, acc.: 78.12%] [G loss: 0.610630]\n",
      "epoch:5 step:5184 [D loss: 0.450866, acc.: 80.47%] [G loss: 0.722825]\n",
      "epoch:5 step:5185 [D loss: 0.634218, acc.: 64.06%] [G loss: 0.528063]\n",
      "epoch:5 step:5186 [D loss: 0.673646, acc.: 62.50%] [G loss: 0.520356]\n",
      "epoch:5 step:5187 [D loss: 0.624673, acc.: 60.16%] [G loss: 0.421797]\n",
      "epoch:5 step:5188 [D loss: 0.453738, acc.: 80.47%] [G loss: 0.637405]\n",
      "epoch:5 step:5189 [D loss: 0.476242, acc.: 78.91%] [G loss: 0.551085]\n",
      "epoch:5 step:5190 [D loss: 0.511025, acc.: 77.34%] [G loss: 0.565157]\n",
      "epoch:5 step:5191 [D loss: 0.532082, acc.: 72.66%] [G loss: 0.582826]\n",
      "epoch:5 step:5192 [D loss: 0.546404, acc.: 71.09%] [G loss: 0.637532]\n",
      "epoch:5 step:5193 [D loss: 0.469186, acc.: 80.47%] [G loss: 0.485555]\n",
      "epoch:5 step:5194 [D loss: 0.471917, acc.: 76.56%] [G loss: 0.746583]\n",
      "epoch:5 step:5195 [D loss: 0.565413, acc.: 69.53%] [G loss: 0.548367]\n",
      "epoch:5 step:5196 [D loss: 0.690620, acc.: 59.38%] [G loss: 0.430360]\n",
      "epoch:5 step:5197 [D loss: 0.577628, acc.: 71.88%] [G loss: 0.400504]\n",
      "epoch:5 step:5198 [D loss: 0.496390, acc.: 76.56%] [G loss: 0.623550]\n",
      "epoch:5 step:5199 [D loss: 0.530658, acc.: 70.31%] [G loss: 0.535214]\n",
      "epoch:5 step:5200 [D loss: 0.478081, acc.: 81.25%] [G loss: 0.540193]\n",
      "##############\n",
      "[3.39395406 1.61027667 6.80144791 5.01083504 4.46740122 6.31291943\n",
      " 5.26724423 5.03121058 5.09750295 3.93461261]\n",
      "##########\n",
      "epoch:5 step:5201 [D loss: 0.470967, acc.: 81.25%] [G loss: 0.749469]\n",
      "epoch:5 step:5202 [D loss: 0.566245, acc.: 71.09%] [G loss: 0.620040]\n",
      "epoch:5 step:5203 [D loss: 0.524884, acc.: 75.00%] [G loss: 0.548947]\n",
      "epoch:5 step:5204 [D loss: 0.499592, acc.: 74.22%] [G loss: 0.554753]\n",
      "epoch:5 step:5205 [D loss: 0.481526, acc.: 75.00%] [G loss: 0.558018]\n",
      "epoch:5 step:5206 [D loss: 0.478843, acc.: 80.47%] [G loss: 0.633120]\n",
      "epoch:5 step:5207 [D loss: 0.509470, acc.: 68.75%] [G loss: 0.601093]\n",
      "epoch:5 step:5208 [D loss: 0.523421, acc.: 73.44%] [G loss: 0.558752]\n",
      "epoch:5 step:5209 [D loss: 0.570057, acc.: 67.97%] [G loss: 0.512829]\n",
      "epoch:5 step:5210 [D loss: 0.606070, acc.: 68.75%] [G loss: 0.581394]\n",
      "epoch:5 step:5211 [D loss: 0.480785, acc.: 78.12%] [G loss: 0.590124]\n",
      "epoch:5 step:5212 [D loss: 0.595012, acc.: 66.41%] [G loss: 0.517267]\n",
      "epoch:5 step:5213 [D loss: 0.648618, acc.: 60.16%] [G loss: 0.447521]\n",
      "epoch:5 step:5214 [D loss: 0.558258, acc.: 71.88%] [G loss: 0.535227]\n",
      "epoch:5 step:5215 [D loss: 0.477360, acc.: 80.47%] [G loss: 0.676894]\n",
      "epoch:5 step:5216 [D loss: 0.571319, acc.: 64.84%] [G loss: 0.434572]\n",
      "epoch:5 step:5217 [D loss: 0.599288, acc.: 67.19%] [G loss: 0.480615]\n",
      "epoch:5 step:5218 [D loss: 0.515920, acc.: 74.22%] [G loss: 0.535013]\n",
      "epoch:5 step:5219 [D loss: 0.514298, acc.: 72.66%] [G loss: 0.581264]\n",
      "epoch:5 step:5220 [D loss: 0.529336, acc.: 71.88%] [G loss: 0.448390]\n",
      "epoch:5 step:5221 [D loss: 0.467329, acc.: 79.69%] [G loss: 0.465935]\n",
      "epoch:5 step:5222 [D loss: 0.550015, acc.: 71.88%] [G loss: 0.568529]\n",
      "epoch:5 step:5223 [D loss: 0.556671, acc.: 69.53%] [G loss: 0.501469]\n",
      "epoch:5 step:5224 [D loss: 0.536760, acc.: 70.31%] [G loss: 0.499905]\n",
      "epoch:5 step:5225 [D loss: 0.567967, acc.: 70.31%] [G loss: 0.502149]\n",
      "epoch:5 step:5226 [D loss: 0.533052, acc.: 71.09%] [G loss: 0.475892]\n",
      "epoch:5 step:5227 [D loss: 0.609137, acc.: 64.84%] [G loss: 0.511311]\n",
      "epoch:5 step:5228 [D loss: 0.587424, acc.: 71.09%] [G loss: 0.498634]\n",
      "epoch:5 step:5229 [D loss: 0.543228, acc.: 69.53%] [G loss: 0.550205]\n",
      "epoch:5 step:5230 [D loss: 0.549027, acc.: 72.66%] [G loss: 0.646061]\n",
      "epoch:5 step:5231 [D loss: 0.435625, acc.: 79.69%] [G loss: 0.698039]\n",
      "epoch:5 step:5232 [D loss: 0.506573, acc.: 73.44%] [G loss: 0.699685]\n",
      "epoch:5 step:5233 [D loss: 0.510404, acc.: 74.22%] [G loss: 0.640847]\n",
      "epoch:5 step:5234 [D loss: 0.497271, acc.: 77.34%] [G loss: 0.664297]\n",
      "epoch:5 step:5235 [D loss: 0.523746, acc.: 73.44%] [G loss: 0.571317]\n",
      "epoch:5 step:5236 [D loss: 0.574646, acc.: 66.41%] [G loss: 0.493974]\n",
      "epoch:5 step:5237 [D loss: 0.511119, acc.: 70.31%] [G loss: 0.551499]\n",
      "epoch:5 step:5238 [D loss: 0.552966, acc.: 71.88%] [G loss: 0.502006]\n",
      "epoch:5 step:5239 [D loss: 0.477632, acc.: 76.56%] [G loss: 0.774996]\n",
      "epoch:5 step:5240 [D loss: 0.535319, acc.: 71.88%] [G loss: 0.620264]\n",
      "epoch:5 step:5241 [D loss: 0.500386, acc.: 76.56%] [G loss: 0.654543]\n",
      "epoch:5 step:5242 [D loss: 0.523160, acc.: 75.00%] [G loss: 0.560335]\n",
      "epoch:5 step:5243 [D loss: 0.445617, acc.: 83.59%] [G loss: 0.554608]\n",
      "epoch:5 step:5244 [D loss: 0.615138, acc.: 64.06%] [G loss: 0.593407]\n",
      "epoch:5 step:5245 [D loss: 0.617436, acc.: 60.16%] [G loss: 0.402573]\n",
      "epoch:5 step:5246 [D loss: 0.502184, acc.: 78.12%] [G loss: 0.472767]\n",
      "epoch:5 step:5247 [D loss: 0.564483, acc.: 67.19%] [G loss: 0.487180]\n",
      "epoch:5 step:5248 [D loss: 0.542339, acc.: 71.88%] [G loss: 0.486172]\n",
      "epoch:5 step:5249 [D loss: 0.475110, acc.: 78.91%] [G loss: 0.643829]\n",
      "epoch:5 step:5250 [D loss: 0.552311, acc.: 72.66%] [G loss: 0.559311]\n",
      "epoch:5 step:5251 [D loss: 0.624938, acc.: 66.41%] [G loss: 0.476904]\n",
      "epoch:5 step:5252 [D loss: 0.515520, acc.: 72.66%] [G loss: 0.561128]\n",
      "epoch:5 step:5253 [D loss: 0.509117, acc.: 77.34%] [G loss: 0.622485]\n",
      "epoch:5 step:5254 [D loss: 0.540760, acc.: 73.44%] [G loss: 0.539552]\n",
      "epoch:5 step:5255 [D loss: 0.513655, acc.: 74.22%] [G loss: 0.487446]\n",
      "epoch:5 step:5256 [D loss: 0.471517, acc.: 79.69%] [G loss: 0.567292]\n",
      "epoch:5 step:5257 [D loss: 0.632312, acc.: 67.19%] [G loss: 0.362111]\n",
      "epoch:5 step:5258 [D loss: 0.550550, acc.: 70.31%] [G loss: 0.585879]\n",
      "epoch:5 step:5259 [D loss: 0.517143, acc.: 73.44%] [G loss: 0.408686]\n",
      "epoch:5 step:5260 [D loss: 0.484077, acc.: 76.56%] [G loss: 0.679312]\n",
      "epoch:5 step:5261 [D loss: 0.601058, acc.: 70.31%] [G loss: 0.440081]\n",
      "epoch:5 step:5262 [D loss: 0.612012, acc.: 67.19%] [G loss: 0.537256]\n",
      "epoch:5 step:5263 [D loss: 0.555532, acc.: 71.09%] [G loss: 0.576030]\n",
      "epoch:5 step:5264 [D loss: 0.517374, acc.: 78.12%] [G loss: 0.622921]\n",
      "epoch:5 step:5265 [D loss: 0.520654, acc.: 77.34%] [G loss: 0.671526]\n",
      "epoch:5 step:5266 [D loss: 0.562871, acc.: 70.31%] [G loss: 0.537533]\n",
      "epoch:5 step:5267 [D loss: 0.465654, acc.: 80.47%] [G loss: 0.715619]\n",
      "epoch:5 step:5268 [D loss: 0.574783, acc.: 75.00%] [G loss: 0.654579]\n",
      "epoch:5 step:5269 [D loss: 0.573010, acc.: 69.53%] [G loss: 0.611186]\n",
      "epoch:5 step:5270 [D loss: 0.542298, acc.: 67.97%] [G loss: 0.499937]\n",
      "epoch:5 step:5271 [D loss: 0.589643, acc.: 63.28%] [G loss: 0.510347]\n",
      "epoch:5 step:5272 [D loss: 0.497279, acc.: 74.22%] [G loss: 0.660312]\n",
      "epoch:5 step:5273 [D loss: 0.625994, acc.: 61.72%] [G loss: 0.613763]\n",
      "epoch:5 step:5274 [D loss: 0.497202, acc.: 75.78%] [G loss: 0.804331]\n",
      "epoch:5 step:5275 [D loss: 0.608490, acc.: 67.19%] [G loss: 0.602998]\n",
      "epoch:5 step:5276 [D loss: 0.600660, acc.: 67.19%] [G loss: 0.513408]\n",
      "epoch:5 step:5277 [D loss: 0.464311, acc.: 82.03%] [G loss: 0.622841]\n",
      "epoch:5 step:5278 [D loss: 0.544569, acc.: 73.44%] [G loss: 0.515540]\n",
      "epoch:5 step:5279 [D loss: 0.552931, acc.: 71.09%] [G loss: 0.595349]\n",
      "epoch:5 step:5280 [D loss: 0.560778, acc.: 67.19%] [G loss: 0.416978]\n",
      "epoch:5 step:5281 [D loss: 0.551931, acc.: 71.88%] [G loss: 0.537991]\n",
      "epoch:5 step:5282 [D loss: 0.533539, acc.: 72.66%] [G loss: 0.502601]\n",
      "epoch:5 step:5283 [D loss: 0.490046, acc.: 80.47%] [G loss: 0.562498]\n",
      "epoch:5 step:5284 [D loss: 0.561414, acc.: 67.97%] [G loss: 0.532726]\n",
      "epoch:5 step:5285 [D loss: 0.613837, acc.: 63.28%] [G loss: 0.452462]\n",
      "epoch:5 step:5286 [D loss: 0.497850, acc.: 75.78%] [G loss: 0.419782]\n",
      "epoch:5 step:5287 [D loss: 0.485640, acc.: 75.78%] [G loss: 0.646799]\n",
      "epoch:5 step:5288 [D loss: 0.510659, acc.: 73.44%] [G loss: 0.517958]\n",
      "epoch:5 step:5289 [D loss: 0.554922, acc.: 71.88%] [G loss: 0.513938]\n",
      "epoch:5 step:5290 [D loss: 0.457543, acc.: 78.91%] [G loss: 0.629061]\n",
      "epoch:5 step:5291 [D loss: 0.524390, acc.: 68.75%] [G loss: 0.507140]\n",
      "epoch:5 step:5292 [D loss: 0.544487, acc.: 68.75%] [G loss: 0.506335]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5293 [D loss: 0.532065, acc.: 74.22%] [G loss: 0.542716]\n",
      "epoch:5 step:5294 [D loss: 0.446938, acc.: 79.69%] [G loss: 0.622916]\n",
      "epoch:5 step:5295 [D loss: 0.538690, acc.: 74.22%] [G loss: 0.577512]\n",
      "epoch:5 step:5296 [D loss: 0.456965, acc.: 77.34%] [G loss: 0.611534]\n",
      "epoch:5 step:5297 [D loss: 0.561244, acc.: 71.88%] [G loss: 0.508409]\n",
      "epoch:5 step:5298 [D loss: 0.489579, acc.: 78.12%] [G loss: 0.508991]\n",
      "epoch:5 step:5299 [D loss: 0.541839, acc.: 70.31%] [G loss: 0.523050]\n",
      "epoch:5 step:5300 [D loss: 0.569748, acc.: 66.41%] [G loss: 0.535140]\n",
      "epoch:5 step:5301 [D loss: 0.577119, acc.: 64.84%] [G loss: 0.573996]\n",
      "epoch:5 step:5302 [D loss: 0.564715, acc.: 70.31%] [G loss: 0.579511]\n",
      "epoch:5 step:5303 [D loss: 0.527982, acc.: 75.00%] [G loss: 0.569488]\n",
      "epoch:5 step:5304 [D loss: 0.529343, acc.: 67.97%] [G loss: 0.630770]\n",
      "epoch:5 step:5305 [D loss: 0.521143, acc.: 77.34%] [G loss: 0.516579]\n",
      "epoch:5 step:5306 [D loss: 0.585453, acc.: 67.19%] [G loss: 0.507767]\n",
      "epoch:5 step:5307 [D loss: 0.564517, acc.: 68.75%] [G loss: 0.517349]\n",
      "epoch:5 step:5308 [D loss: 0.505127, acc.: 75.78%] [G loss: 0.567554]\n",
      "epoch:5 step:5309 [D loss: 0.485092, acc.: 74.22%] [G loss: 0.575153]\n",
      "epoch:5 step:5310 [D loss: 0.548571, acc.: 67.97%] [G loss: 0.572558]\n",
      "epoch:5 step:5311 [D loss: 0.474431, acc.: 82.03%] [G loss: 0.443242]\n",
      "epoch:5 step:5312 [D loss: 0.531241, acc.: 71.88%] [G loss: 0.645822]\n",
      "epoch:5 step:5313 [D loss: 0.546007, acc.: 71.09%] [G loss: 0.600522]\n",
      "epoch:5 step:5314 [D loss: 0.539414, acc.: 72.66%] [G loss: 0.551514]\n",
      "epoch:5 step:5315 [D loss: 0.531545, acc.: 68.75%] [G loss: 0.503021]\n",
      "epoch:5 step:5316 [D loss: 0.536040, acc.: 75.78%] [G loss: 0.467503]\n",
      "epoch:5 step:5317 [D loss: 0.466519, acc.: 75.78%] [G loss: 0.685425]\n",
      "epoch:5 step:5318 [D loss: 0.520274, acc.: 72.66%] [G loss: 0.707798]\n",
      "epoch:5 step:5319 [D loss: 0.531866, acc.: 75.00%] [G loss: 0.605851]\n",
      "epoch:5 step:5320 [D loss: 0.520120, acc.: 76.56%] [G loss: 0.550137]\n",
      "epoch:5 step:5321 [D loss: 0.635528, acc.: 67.19%] [G loss: 0.540032]\n",
      "epoch:5 step:5322 [D loss: 0.545592, acc.: 75.78%] [G loss: 0.575356]\n",
      "epoch:5 step:5323 [D loss: 0.573921, acc.: 71.88%] [G loss: 0.478184]\n",
      "epoch:5 step:5324 [D loss: 0.490101, acc.: 75.00%] [G loss: 0.730830]\n",
      "epoch:5 step:5325 [D loss: 0.490272, acc.: 76.56%] [G loss: 0.576529]\n",
      "epoch:5 step:5326 [D loss: 0.490008, acc.: 77.34%] [G loss: 0.725857]\n",
      "epoch:5 step:5327 [D loss: 0.522033, acc.: 75.00%] [G loss: 0.770828]\n",
      "epoch:5 step:5328 [D loss: 0.543943, acc.: 72.66%] [G loss: 0.511971]\n",
      "epoch:5 step:5329 [D loss: 0.586390, acc.: 70.31%] [G loss: 0.573770]\n",
      "epoch:5 step:5330 [D loss: 0.562350, acc.: 71.88%] [G loss: 0.413786]\n",
      "epoch:5 step:5331 [D loss: 0.573467, acc.: 67.97%] [G loss: 0.634756]\n",
      "epoch:5 step:5332 [D loss: 0.524333, acc.: 78.12%] [G loss: 0.705692]\n",
      "epoch:5 step:5333 [D loss: 0.429049, acc.: 81.25%] [G loss: 0.658068]\n",
      "epoch:5 step:5334 [D loss: 0.505815, acc.: 79.69%] [G loss: 0.796774]\n",
      "epoch:5 step:5335 [D loss: 0.506501, acc.: 76.56%] [G loss: 0.641923]\n",
      "epoch:5 step:5336 [D loss: 0.505526, acc.: 79.69%] [G loss: 0.584674]\n",
      "epoch:5 step:5337 [D loss: 0.645308, acc.: 63.28%] [G loss: 0.483895]\n",
      "epoch:5 step:5338 [D loss: 0.559058, acc.: 71.09%] [G loss: 0.435906]\n",
      "epoch:5 step:5339 [D loss: 0.514722, acc.: 73.44%] [G loss: 0.537587]\n",
      "epoch:5 step:5340 [D loss: 0.590636, acc.: 60.94%] [G loss: 0.497423]\n",
      "epoch:5 step:5341 [D loss: 0.521771, acc.: 75.78%] [G loss: 0.504101]\n",
      "epoch:5 step:5342 [D loss: 0.521574, acc.: 72.66%] [G loss: 0.603041]\n",
      "epoch:5 step:5343 [D loss: 0.599416, acc.: 64.06%] [G loss: 0.686419]\n",
      "epoch:5 step:5344 [D loss: 0.520407, acc.: 76.56%] [G loss: 0.646710]\n",
      "epoch:5 step:5345 [D loss: 0.546286, acc.: 70.31%] [G loss: 0.606639]\n",
      "epoch:5 step:5346 [D loss: 0.501432, acc.: 74.22%] [G loss: 0.718081]\n",
      "epoch:5 step:5347 [D loss: 0.560849, acc.: 72.66%] [G loss: 0.648631]\n",
      "epoch:5 step:5348 [D loss: 0.544256, acc.: 70.31%] [G loss: 0.470020]\n",
      "epoch:5 step:5349 [D loss: 0.525851, acc.: 70.31%] [G loss: 0.697916]\n",
      "epoch:5 step:5350 [D loss: 0.592171, acc.: 68.75%] [G loss: 0.888759]\n",
      "epoch:5 step:5351 [D loss: 0.567525, acc.: 65.62%] [G loss: 0.730365]\n",
      "epoch:5 step:5352 [D loss: 0.597413, acc.: 71.88%] [G loss: 0.676242]\n",
      "epoch:5 step:5353 [D loss: 0.523170, acc.: 76.56%] [G loss: 0.601844]\n",
      "epoch:5 step:5354 [D loss: 0.546394, acc.: 70.31%] [G loss: 0.577630]\n",
      "epoch:5 step:5355 [D loss: 0.517904, acc.: 72.66%] [G loss: 0.507571]\n",
      "epoch:5 step:5356 [D loss: 0.555384, acc.: 71.88%] [G loss: 0.469047]\n",
      "epoch:5 step:5357 [D loss: 0.620621, acc.: 66.41%] [G loss: 0.562685]\n",
      "epoch:5 step:5358 [D loss: 0.561212, acc.: 71.88%] [G loss: 0.551079]\n",
      "epoch:5 step:5359 [D loss: 0.540580, acc.: 72.66%] [G loss: 0.495290]\n",
      "epoch:5 step:5360 [D loss: 0.564761, acc.: 67.97%] [G loss: 0.506997]\n",
      "epoch:5 step:5361 [D loss: 0.596458, acc.: 69.53%] [G loss: 0.495188]\n",
      "epoch:5 step:5362 [D loss: 0.449597, acc.: 80.47%] [G loss: 0.668285]\n",
      "epoch:5 step:5363 [D loss: 0.499911, acc.: 68.75%] [G loss: 0.624879]\n",
      "epoch:5 step:5364 [D loss: 0.536622, acc.: 72.66%] [G loss: 0.584187]\n",
      "epoch:5 step:5365 [D loss: 0.490940, acc.: 78.12%] [G loss: 0.593208]\n",
      "epoch:5 step:5366 [D loss: 0.498976, acc.: 78.12%] [G loss: 0.595635]\n",
      "epoch:5 step:5367 [D loss: 0.511549, acc.: 76.56%] [G loss: 0.693393]\n",
      "epoch:5 step:5368 [D loss: 0.574589, acc.: 67.97%] [G loss: 0.474507]\n",
      "epoch:5 step:5369 [D loss: 0.546299, acc.: 71.88%] [G loss: 0.532753]\n",
      "epoch:5 step:5370 [D loss: 0.569128, acc.: 71.88%] [G loss: 0.607441]\n",
      "epoch:5 step:5371 [D loss: 0.545874, acc.: 74.22%] [G loss: 0.462270]\n",
      "epoch:5 step:5372 [D loss: 0.543308, acc.: 71.88%] [G loss: 0.508464]\n",
      "epoch:5 step:5373 [D loss: 0.605344, acc.: 71.09%] [G loss: 0.605629]\n",
      "epoch:5 step:5374 [D loss: 0.529339, acc.: 71.88%] [G loss: 0.667080]\n",
      "epoch:5 step:5375 [D loss: 0.489012, acc.: 75.78%] [G loss: 0.756823]\n",
      "epoch:5 step:5376 [D loss: 0.504975, acc.: 77.34%] [G loss: 0.818267]\n",
      "epoch:5 step:5377 [D loss: 0.512411, acc.: 74.22%] [G loss: 0.714229]\n",
      "epoch:5 step:5378 [D loss: 0.532842, acc.: 69.53%] [G loss: 0.560529]\n",
      "epoch:5 step:5379 [D loss: 0.516981, acc.: 75.00%] [G loss: 0.652027]\n",
      "epoch:5 step:5380 [D loss: 0.540045, acc.: 69.53%] [G loss: 0.629526]\n",
      "epoch:5 step:5381 [D loss: 0.589622, acc.: 67.97%] [G loss: 0.477918]\n",
      "epoch:5 step:5382 [D loss: 0.541836, acc.: 67.97%] [G loss: 0.456845]\n",
      "epoch:5 step:5383 [D loss: 0.545260, acc.: 69.53%] [G loss: 0.525719]\n",
      "epoch:5 step:5384 [D loss: 0.519122, acc.: 72.66%] [G loss: 0.691073]\n",
      "epoch:5 step:5385 [D loss: 0.563866, acc.: 71.09%] [G loss: 0.631141]\n",
      "epoch:5 step:5386 [D loss: 0.519014, acc.: 76.56%] [G loss: 0.621403]\n",
      "epoch:5 step:5387 [D loss: 0.604785, acc.: 62.50%] [G loss: 0.439861]\n",
      "epoch:5 step:5388 [D loss: 0.582069, acc.: 68.75%] [G loss: 0.429558]\n",
      "epoch:5 step:5389 [D loss: 0.645057, acc.: 65.62%] [G loss: 0.422832]\n",
      "epoch:5 step:5390 [D loss: 0.536239, acc.: 77.34%] [G loss: 0.644114]\n",
      "epoch:5 step:5391 [D loss: 0.573452, acc.: 67.19%] [G loss: 0.451077]\n",
      "epoch:5 step:5392 [D loss: 0.457728, acc.: 84.38%] [G loss: 0.680995]\n",
      "epoch:5 step:5393 [D loss: 0.466925, acc.: 78.91%] [G loss: 0.752251]\n",
      "epoch:5 step:5394 [D loss: 0.535876, acc.: 67.19%] [G loss: 0.720385]\n",
      "epoch:5 step:5395 [D loss: 0.605976, acc.: 67.97%] [G loss: 0.485766]\n",
      "epoch:5 step:5396 [D loss: 0.537594, acc.: 71.09%] [G loss: 0.642483]\n",
      "epoch:5 step:5397 [D loss: 0.512478, acc.: 75.78%] [G loss: 0.553675]\n",
      "epoch:5 step:5398 [D loss: 0.577422, acc.: 71.88%] [G loss: 0.478022]\n",
      "epoch:5 step:5399 [D loss: 0.528565, acc.: 74.22%] [G loss: 0.501704]\n",
      "epoch:5 step:5400 [D loss: 0.525488, acc.: 75.00%] [G loss: 0.418512]\n",
      "##############\n",
      "[3.25293392 1.7629809  6.8556687  5.02388263 4.20890333 6.02447905\n",
      " 5.29841436 5.03186671 4.96843706 3.87946076]\n",
      "##########\n",
      "epoch:5 step:5401 [D loss: 0.594002, acc.: 67.19%] [G loss: 0.477931]\n",
      "epoch:5 step:5402 [D loss: 0.570282, acc.: 69.53%] [G loss: 0.429613]\n",
      "epoch:5 step:5403 [D loss: 0.611072, acc.: 70.31%] [G loss: 0.453622]\n",
      "epoch:5 step:5404 [D loss: 0.497847, acc.: 73.44%] [G loss: 0.578928]\n",
      "epoch:5 step:5405 [D loss: 0.627073, acc.: 67.19%] [G loss: 0.513046]\n",
      "epoch:5 step:5406 [D loss: 0.569167, acc.: 67.97%] [G loss: 0.479383]\n",
      "epoch:5 step:5407 [D loss: 0.566151, acc.: 66.41%] [G loss: 0.456526]\n",
      "epoch:5 step:5408 [D loss: 0.595764, acc.: 69.53%] [G loss: 0.365471]\n",
      "epoch:5 step:5409 [D loss: 0.563592, acc.: 70.31%] [G loss: 0.523744]\n",
      "epoch:5 step:5410 [D loss: 0.504844, acc.: 75.00%] [G loss: 0.669592]\n",
      "epoch:5 step:5411 [D loss: 0.507293, acc.: 70.31%] [G loss: 0.607715]\n",
      "epoch:5 step:5412 [D loss: 0.583373, acc.: 70.31%] [G loss: 0.516309]\n",
      "epoch:5 step:5413 [D loss: 0.511874, acc.: 71.88%] [G loss: 0.605152]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5414 [D loss: 0.575403, acc.: 75.00%] [G loss: 0.477705]\n",
      "epoch:5 step:5415 [D loss: 0.503143, acc.: 79.69%] [G loss: 0.520289]\n",
      "epoch:5 step:5416 [D loss: 0.559269, acc.: 71.88%] [G loss: 0.489096]\n",
      "epoch:5 step:5417 [D loss: 0.510870, acc.: 78.12%] [G loss: 0.543523]\n",
      "epoch:5 step:5418 [D loss: 0.515217, acc.: 75.78%] [G loss: 0.666672]\n",
      "epoch:5 step:5419 [D loss: 0.542516, acc.: 71.88%] [G loss: 0.592152]\n",
      "epoch:5 step:5420 [D loss: 0.568826, acc.: 71.88%] [G loss: 0.506806]\n",
      "epoch:5 step:5421 [D loss: 0.428425, acc.: 81.25%] [G loss: 0.589991]\n",
      "epoch:5 step:5422 [D loss: 0.523988, acc.: 75.78%] [G loss: 0.611754]\n",
      "epoch:5 step:5423 [D loss: 0.581635, acc.: 66.41%] [G loss: 0.565583]\n",
      "epoch:5 step:5424 [D loss: 0.587481, acc.: 71.09%] [G loss: 0.656035]\n",
      "epoch:5 step:5425 [D loss: 0.654029, acc.: 58.59%] [G loss: 0.461143]\n",
      "epoch:5 step:5426 [D loss: 0.582912, acc.: 66.41%] [G loss: 0.411468]\n",
      "epoch:5 step:5427 [D loss: 0.586155, acc.: 68.75%] [G loss: 0.425255]\n",
      "epoch:5 step:5428 [D loss: 0.515573, acc.: 75.00%] [G loss: 0.598168]\n",
      "epoch:5 step:5429 [D loss: 0.572619, acc.: 76.56%] [G loss: 0.591352]\n",
      "epoch:5 step:5430 [D loss: 0.497244, acc.: 75.00%] [G loss: 0.663295]\n",
      "epoch:5 step:5431 [D loss: 0.455093, acc.: 80.47%] [G loss: 0.583854]\n",
      "epoch:5 step:5432 [D loss: 0.502902, acc.: 75.00%] [G loss: 0.781305]\n",
      "epoch:5 step:5433 [D loss: 0.517118, acc.: 71.09%] [G loss: 0.607251]\n",
      "epoch:5 step:5434 [D loss: 0.540565, acc.: 71.09%] [G loss: 0.554616]\n",
      "epoch:5 step:5435 [D loss: 0.482222, acc.: 79.69%] [G loss: 0.613920]\n",
      "epoch:5 step:5436 [D loss: 0.537603, acc.: 71.88%] [G loss: 0.473186]\n",
      "epoch:5 step:5437 [D loss: 0.581948, acc.: 67.19%] [G loss: 0.580560]\n",
      "epoch:5 step:5438 [D loss: 0.533454, acc.: 71.88%] [G loss: 0.621912]\n",
      "epoch:5 step:5439 [D loss: 0.489317, acc.: 77.34%] [G loss: 0.644859]\n",
      "epoch:5 step:5440 [D loss: 0.523873, acc.: 71.09%] [G loss: 0.678110]\n",
      "epoch:5 step:5441 [D loss: 0.626095, acc.: 64.06%] [G loss: 0.504310]\n",
      "epoch:5 step:5442 [D loss: 0.535082, acc.: 71.09%] [G loss: 0.448789]\n",
      "epoch:5 step:5443 [D loss: 0.559380, acc.: 72.66%] [G loss: 0.511399]\n",
      "epoch:5 step:5444 [D loss: 0.606787, acc.: 66.41%] [G loss: 0.495620]\n",
      "epoch:5 step:5445 [D loss: 0.541331, acc.: 67.19%] [G loss: 0.545930]\n",
      "epoch:5 step:5446 [D loss: 0.530835, acc.: 71.09%] [G loss: 0.569880]\n",
      "epoch:5 step:5447 [D loss: 0.548376, acc.: 71.88%] [G loss: 0.614102]\n",
      "epoch:5 step:5448 [D loss: 0.565436, acc.: 70.31%] [G loss: 0.507301]\n",
      "epoch:5 step:5449 [D loss: 0.568800, acc.: 75.00%] [G loss: 0.590410]\n",
      "epoch:5 step:5450 [D loss: 0.637918, acc.: 64.84%] [G loss: 0.503969]\n",
      "epoch:5 step:5451 [D loss: 0.725368, acc.: 56.25%] [G loss: 0.582238]\n",
      "epoch:5 step:5452 [D loss: 0.533808, acc.: 71.88%] [G loss: 0.473265]\n",
      "epoch:5 step:5453 [D loss: 0.567495, acc.: 66.41%] [G loss: 0.609238]\n",
      "epoch:5 step:5454 [D loss: 0.520825, acc.: 74.22%] [G loss: 0.766488]\n",
      "epoch:5 step:5455 [D loss: 0.542888, acc.: 71.88%] [G loss: 0.747911]\n",
      "epoch:5 step:5456 [D loss: 0.581227, acc.: 67.97%] [G loss: 0.534284]\n",
      "epoch:5 step:5457 [D loss: 0.543492, acc.: 74.22%] [G loss: 0.592357]\n",
      "epoch:5 step:5458 [D loss: 0.516083, acc.: 72.66%] [G loss: 0.529083]\n",
      "epoch:5 step:5459 [D loss: 0.610994, acc.: 68.75%] [G loss: 0.494399]\n",
      "epoch:5 step:5460 [D loss: 0.551421, acc.: 70.31%] [G loss: 0.504531]\n",
      "epoch:5 step:5461 [D loss: 0.563451, acc.: 69.53%] [G loss: 0.564097]\n",
      "epoch:5 step:5462 [D loss: 0.549129, acc.: 69.53%] [G loss: 0.549336]\n",
      "epoch:5 step:5463 [D loss: 0.520431, acc.: 78.12%] [G loss: 0.659305]\n",
      "epoch:5 step:5464 [D loss: 0.569023, acc.: 71.09%] [G loss: 0.587046]\n",
      "epoch:5 step:5465 [D loss: 0.514927, acc.: 75.78%] [G loss: 0.709960]\n",
      "epoch:5 step:5466 [D loss: 0.508870, acc.: 73.44%] [G loss: 0.655886]\n",
      "epoch:5 step:5467 [D loss: 0.529326, acc.: 72.66%] [G loss: 0.716301]\n",
      "epoch:5 step:5468 [D loss: 0.624031, acc.: 67.19%] [G loss: 0.694697]\n",
      "epoch:5 step:5469 [D loss: 0.540067, acc.: 69.53%] [G loss: 0.677538]\n",
      "epoch:5 step:5470 [D loss: 0.552507, acc.: 71.88%] [G loss: 0.447859]\n",
      "epoch:5 step:5471 [D loss: 0.493777, acc.: 74.22%] [G loss: 0.603229]\n",
      "epoch:5 step:5472 [D loss: 0.631006, acc.: 63.28%] [G loss: 0.571216]\n",
      "epoch:5 step:5473 [D loss: 0.638483, acc.: 60.16%] [G loss: 0.405810]\n",
      "epoch:5 step:5474 [D loss: 0.532940, acc.: 70.31%] [G loss: 0.563529]\n",
      "epoch:5 step:5475 [D loss: 0.504159, acc.: 77.34%] [G loss: 0.601709]\n",
      "epoch:5 step:5476 [D loss: 0.569559, acc.: 71.09%] [G loss: 0.490544]\n",
      "epoch:5 step:5477 [D loss: 0.451276, acc.: 79.69%] [G loss: 0.671054]\n",
      "epoch:5 step:5478 [D loss: 0.549289, acc.: 70.31%] [G loss: 0.575313]\n",
      "epoch:5 step:5479 [D loss: 0.641821, acc.: 60.94%] [G loss: 0.534142]\n",
      "epoch:5 step:5480 [D loss: 0.536217, acc.: 72.66%] [G loss: 0.564231]\n",
      "epoch:5 step:5481 [D loss: 0.485354, acc.: 75.78%] [G loss: 0.709031]\n",
      "epoch:5 step:5482 [D loss: 0.525867, acc.: 71.09%] [G loss: 0.602278]\n",
      "epoch:5 step:5483 [D loss: 0.527437, acc.: 66.41%] [G loss: 0.520339]\n",
      "epoch:5 step:5484 [D loss: 0.568824, acc.: 74.22%] [G loss: 0.734228]\n",
      "epoch:5 step:5485 [D loss: 0.546076, acc.: 71.09%] [G loss: 0.573480]\n",
      "epoch:5 step:5486 [D loss: 0.557187, acc.: 71.09%] [G loss: 0.648564]\n",
      "epoch:5 step:5487 [D loss: 0.528895, acc.: 75.78%] [G loss: 0.878424]\n",
      "epoch:5 step:5488 [D loss: 0.492411, acc.: 78.12%] [G loss: 0.670200]\n",
      "epoch:5 step:5489 [D loss: 0.514895, acc.: 71.88%] [G loss: 0.597921]\n",
      "epoch:5 step:5490 [D loss: 0.508245, acc.: 75.78%] [G loss: 0.624807]\n",
      "epoch:5 step:5491 [D loss: 0.514271, acc.: 78.91%] [G loss: 0.581779]\n",
      "epoch:5 step:5492 [D loss: 0.469419, acc.: 78.12%] [G loss: 0.586322]\n",
      "epoch:5 step:5493 [D loss: 0.543217, acc.: 72.66%] [G loss: 0.514308]\n",
      "epoch:5 step:5494 [D loss: 0.545630, acc.: 69.53%] [G loss: 0.678871]\n",
      "epoch:5 step:5495 [D loss: 0.602789, acc.: 68.75%] [G loss: 0.645257]\n",
      "epoch:5 step:5496 [D loss: 0.533537, acc.: 72.66%] [G loss: 0.602024]\n",
      "epoch:5 step:5497 [D loss: 0.650236, acc.: 60.16%] [G loss: 0.597343]\n",
      "epoch:5 step:5498 [D loss: 0.572516, acc.: 70.31%] [G loss: 0.528219]\n",
      "epoch:5 step:5499 [D loss: 0.553456, acc.: 66.41%] [G loss: 0.543058]\n",
      "epoch:5 step:5500 [D loss: 0.568407, acc.: 69.53%] [G loss: 0.636651]\n",
      "epoch:5 step:5501 [D loss: 0.595557, acc.: 65.62%] [G loss: 0.725621]\n",
      "epoch:5 step:5502 [D loss: 0.585019, acc.: 64.84%] [G loss: 0.544883]\n",
      "epoch:5 step:5503 [D loss: 0.572973, acc.: 73.44%] [G loss: 0.387309]\n",
      "epoch:5 step:5504 [D loss: 0.569345, acc.: 71.09%] [G loss: 0.447752]\n",
      "epoch:5 step:5505 [D loss: 0.583767, acc.: 67.97%] [G loss: 0.584602]\n",
      "epoch:5 step:5506 [D loss: 0.528579, acc.: 72.66%] [G loss: 0.503924]\n",
      "epoch:5 step:5507 [D loss: 0.520504, acc.: 69.53%] [G loss: 0.422402]\n",
      "epoch:5 step:5508 [D loss: 0.467276, acc.: 78.12%] [G loss: 0.553841]\n",
      "epoch:5 step:5509 [D loss: 0.596023, acc.: 64.06%] [G loss: 0.629918]\n",
      "epoch:5 step:5510 [D loss: 0.520063, acc.: 72.66%] [G loss: 0.577006]\n",
      "epoch:5 step:5511 [D loss: 0.588444, acc.: 63.28%] [G loss: 0.468903]\n",
      "epoch:5 step:5512 [D loss: 0.591198, acc.: 69.53%] [G loss: 0.406744]\n",
      "epoch:5 step:5513 [D loss: 0.654848, acc.: 57.81%] [G loss: 0.499386]\n",
      "epoch:5 step:5514 [D loss: 0.537204, acc.: 73.44%] [G loss: 0.790248]\n",
      "epoch:5 step:5515 [D loss: 0.514146, acc.: 78.12%] [G loss: 0.672595]\n",
      "epoch:5 step:5516 [D loss: 0.600688, acc.: 65.62%] [G loss: 0.551348]\n",
      "epoch:5 step:5517 [D loss: 0.506624, acc.: 78.12%] [G loss: 0.444874]\n",
      "epoch:5 step:5518 [D loss: 0.475399, acc.: 75.78%] [G loss: 0.458878]\n",
      "epoch:5 step:5519 [D loss: 0.458386, acc.: 81.25%] [G loss: 0.553146]\n",
      "epoch:5 step:5520 [D loss: 0.535941, acc.: 73.44%] [G loss: 0.552242]\n",
      "epoch:5 step:5521 [D loss: 0.552456, acc.: 69.53%] [G loss: 0.392575]\n",
      "epoch:5 step:5522 [D loss: 0.520202, acc.: 75.78%] [G loss: 0.570292]\n",
      "epoch:5 step:5523 [D loss: 0.494508, acc.: 80.47%] [G loss: 0.532225]\n",
      "epoch:5 step:5524 [D loss: 0.547409, acc.: 72.66%] [G loss: 0.518639]\n",
      "epoch:5 step:5525 [D loss: 0.599330, acc.: 66.41%] [G loss: 0.438590]\n",
      "epoch:5 step:5526 [D loss: 0.482032, acc.: 82.03%] [G loss: 0.505743]\n",
      "epoch:5 step:5527 [D loss: 0.485315, acc.: 74.22%] [G loss: 0.590550]\n",
      "epoch:5 step:5528 [D loss: 0.538236, acc.: 73.44%] [G loss: 0.590853]\n",
      "epoch:5 step:5529 [D loss: 0.595700, acc.: 67.19%] [G loss: 0.490463]\n",
      "epoch:5 step:5530 [D loss: 0.613822, acc.: 64.84%] [G loss: 0.513624]\n",
      "epoch:5 step:5531 [D loss: 0.519534, acc.: 70.31%] [G loss: 0.489573]\n",
      "epoch:5 step:5532 [D loss: 0.596151, acc.: 65.62%] [G loss: 0.386811]\n",
      "epoch:5 step:5533 [D loss: 0.561207, acc.: 65.62%] [G loss: 0.370768]\n",
      "epoch:5 step:5534 [D loss: 0.568271, acc.: 73.44%] [G loss: 0.437075]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5535 [D loss: 0.556936, acc.: 71.88%] [G loss: 0.491443]\n",
      "epoch:5 step:5536 [D loss: 0.523902, acc.: 71.09%] [G loss: 0.577202]\n",
      "epoch:5 step:5537 [D loss: 0.578915, acc.: 68.75%] [G loss: 0.559534]\n",
      "epoch:5 step:5538 [D loss: 0.570884, acc.: 67.19%] [G loss: 0.475034]\n",
      "epoch:5 step:5539 [D loss: 0.477754, acc.: 78.12%] [G loss: 0.664360]\n",
      "epoch:5 step:5540 [D loss: 0.547022, acc.: 75.00%] [G loss: 0.605277]\n",
      "epoch:5 step:5541 [D loss: 0.603747, acc.: 61.72%] [G loss: 0.513627]\n",
      "epoch:5 step:5542 [D loss: 0.512302, acc.: 74.22%] [G loss: 0.596020]\n",
      "epoch:5 step:5543 [D loss: 0.608183, acc.: 60.16%] [G loss: 0.604896]\n",
      "epoch:5 step:5544 [D loss: 0.588614, acc.: 68.75%] [G loss: 0.631451]\n",
      "epoch:5 step:5545 [D loss: 0.499768, acc.: 73.44%] [G loss: 0.732604]\n",
      "epoch:5 step:5546 [D loss: 0.615889, acc.: 67.19%] [G loss: 0.622207]\n",
      "epoch:5 step:5547 [D loss: 0.562859, acc.: 69.53%] [G loss: 0.488241]\n",
      "epoch:5 step:5548 [D loss: 0.544077, acc.: 73.44%] [G loss: 0.425485]\n",
      "epoch:5 step:5549 [D loss: 0.511955, acc.: 77.34%] [G loss: 0.452198]\n",
      "epoch:5 step:5550 [D loss: 0.541211, acc.: 72.66%] [G loss: 0.485289]\n",
      "epoch:5 step:5551 [D loss: 0.575464, acc.: 66.41%] [G loss: 0.420770]\n",
      "epoch:5 step:5552 [D loss: 0.646046, acc.: 60.16%] [G loss: 0.406191]\n",
      "epoch:5 step:5553 [D loss: 0.513194, acc.: 74.22%] [G loss: 0.520864]\n",
      "epoch:5 step:5554 [D loss: 0.571706, acc.: 69.53%] [G loss: 0.639923]\n",
      "epoch:5 step:5555 [D loss: 0.485180, acc.: 72.66%] [G loss: 0.646193]\n",
      "epoch:5 step:5556 [D loss: 0.509400, acc.: 74.22%] [G loss: 0.545173]\n",
      "epoch:5 step:5557 [D loss: 0.524170, acc.: 72.66%] [G loss: 0.508673]\n",
      "epoch:5 step:5558 [D loss: 0.573932, acc.: 68.75%] [G loss: 0.605494]\n",
      "epoch:5 step:5559 [D loss: 0.555042, acc.: 66.41%] [G loss: 0.617674]\n",
      "epoch:5 step:5560 [D loss: 0.461541, acc.: 80.47%] [G loss: 0.640831]\n",
      "epoch:5 step:5561 [D loss: 0.531875, acc.: 70.31%] [G loss: 0.649308]\n",
      "epoch:5 step:5562 [D loss: 0.522764, acc.: 75.78%] [G loss: 0.579625]\n",
      "epoch:5 step:5563 [D loss: 0.603778, acc.: 71.09%] [G loss: 0.584543]\n",
      "epoch:5 step:5564 [D loss: 0.597833, acc.: 64.84%] [G loss: 0.517117]\n",
      "epoch:5 step:5565 [D loss: 0.692533, acc.: 52.34%] [G loss: 0.404954]\n",
      "epoch:5 step:5566 [D loss: 0.595610, acc.: 65.62%] [G loss: 0.488089]\n",
      "epoch:5 step:5567 [D loss: 0.553814, acc.: 71.88%] [G loss: 0.405226]\n",
      "epoch:5 step:5568 [D loss: 0.562958, acc.: 70.31%] [G loss: 0.487872]\n",
      "epoch:5 step:5569 [D loss: 0.451837, acc.: 81.25%] [G loss: 0.786547]\n",
      "epoch:5 step:5570 [D loss: 0.517112, acc.: 71.88%] [G loss: 0.853825]\n",
      "epoch:5 step:5571 [D loss: 0.545736, acc.: 71.88%] [G loss: 0.836707]\n",
      "epoch:5 step:5572 [D loss: 0.487939, acc.: 75.00%] [G loss: 0.653404]\n",
      "epoch:5 step:5573 [D loss: 0.448896, acc.: 78.91%] [G loss: 0.679514]\n",
      "epoch:5 step:5574 [D loss: 0.543260, acc.: 75.00%] [G loss: 0.768529]\n",
      "epoch:5 step:5575 [D loss: 0.417290, acc.: 83.59%] [G loss: 0.790742]\n",
      "epoch:5 step:5576 [D loss: 0.568234, acc.: 67.97%] [G loss: 0.694289]\n",
      "epoch:5 step:5577 [D loss: 0.630674, acc.: 60.16%] [G loss: 0.518305]\n",
      "epoch:5 step:5578 [D loss: 0.561702, acc.: 67.97%] [G loss: 0.543623]\n",
      "epoch:5 step:5579 [D loss: 0.498350, acc.: 75.00%] [G loss: 0.729322]\n",
      "epoch:5 step:5580 [D loss: 0.553231, acc.: 66.41%] [G loss: 0.561056]\n",
      "epoch:5 step:5581 [D loss: 0.533673, acc.: 71.09%] [G loss: 0.698229]\n",
      "epoch:5 step:5582 [D loss: 0.524881, acc.: 71.09%] [G loss: 0.593197]\n",
      "epoch:5 step:5583 [D loss: 0.441021, acc.: 82.81%] [G loss: 0.739093]\n",
      "epoch:5 step:5584 [D loss: 0.504351, acc.: 75.00%] [G loss: 0.749304]\n",
      "epoch:5 step:5585 [D loss: 0.506953, acc.: 74.22%] [G loss: 0.619886]\n",
      "epoch:5 step:5586 [D loss: 0.529590, acc.: 72.66%] [G loss: 0.673841]\n",
      "epoch:5 step:5587 [D loss: 0.595200, acc.: 61.72%] [G loss: 0.489550]\n",
      "epoch:5 step:5588 [D loss: 0.573146, acc.: 67.19%] [G loss: 0.468797]\n",
      "epoch:5 step:5589 [D loss: 0.573579, acc.: 70.31%] [G loss: 0.648122]\n",
      "epoch:5 step:5590 [D loss: 0.583434, acc.: 67.97%] [G loss: 0.694684]\n",
      "epoch:5 step:5591 [D loss: 0.582325, acc.: 70.31%] [G loss: 0.681841]\n",
      "epoch:5 step:5592 [D loss: 0.545099, acc.: 76.56%] [G loss: 0.644645]\n",
      "epoch:5 step:5593 [D loss: 0.559376, acc.: 72.66%] [G loss: 0.619619]\n",
      "epoch:5 step:5594 [D loss: 0.503465, acc.: 77.34%] [G loss: 0.596118]\n",
      "epoch:5 step:5595 [D loss: 0.478299, acc.: 75.00%] [G loss: 0.791557]\n",
      "epoch:5 step:5596 [D loss: 0.465708, acc.: 80.47%] [G loss: 0.619032]\n",
      "epoch:5 step:5597 [D loss: 0.454111, acc.: 78.91%] [G loss: 0.758804]\n",
      "epoch:5 step:5598 [D loss: 0.524996, acc.: 75.00%] [G loss: 0.611669]\n",
      "epoch:5 step:5599 [D loss: 0.520348, acc.: 71.09%] [G loss: 0.692932]\n",
      "epoch:5 step:5600 [D loss: 0.606847, acc.: 68.75%] [G loss: 0.560642]\n",
      "##############\n",
      "[3.33871152 1.84980418 6.62948484 4.94557454 3.99367304 6.32379314\n",
      " 4.94043421 4.88151322 4.88670585 3.82943192]\n",
      "##########\n",
      "epoch:5 step:5601 [D loss: 0.556031, acc.: 71.09%] [G loss: 0.564085]\n",
      "epoch:5 step:5602 [D loss: 0.607135, acc.: 61.72%] [G loss: 0.466916]\n",
      "epoch:5 step:5603 [D loss: 0.483018, acc.: 80.47%] [G loss: 0.629618]\n",
      "epoch:5 step:5604 [D loss: 0.442863, acc.: 82.03%] [G loss: 0.720047]\n",
      "epoch:5 step:5605 [D loss: 0.771505, acc.: 56.25%] [G loss: 0.617664]\n",
      "epoch:5 step:5606 [D loss: 0.483712, acc.: 77.34%] [G loss: 0.730753]\n",
      "epoch:5 step:5607 [D loss: 0.584550, acc.: 64.84%] [G loss: 0.624086]\n",
      "epoch:5 step:5608 [D loss: 0.450286, acc.: 79.69%] [G loss: 0.694380]\n",
      "epoch:5 step:5609 [D loss: 0.482348, acc.: 76.56%] [G loss: 0.800628]\n",
      "epoch:5 step:5610 [D loss: 0.439094, acc.: 82.03%] [G loss: 0.881157]\n",
      "epoch:5 step:5611 [D loss: 0.457001, acc.: 78.91%] [G loss: 0.927590]\n",
      "epoch:5 step:5612 [D loss: 0.539250, acc.: 69.53%] [G loss: 0.899676]\n",
      "epoch:5 step:5613 [D loss: 0.833688, acc.: 56.25%] [G loss: 0.758901]\n",
      "epoch:5 step:5614 [D loss: 0.526707, acc.: 72.66%] [G loss: 0.899472]\n",
      "epoch:5 step:5615 [D loss: 0.441158, acc.: 80.47%] [G loss: 1.024468]\n",
      "epoch:5 step:5616 [D loss: 0.556934, acc.: 66.41%] [G loss: 0.656440]\n",
      "epoch:5 step:5617 [D loss: 0.624842, acc.: 67.97%] [G loss: 0.646929]\n",
      "epoch:5 step:5618 [D loss: 0.462447, acc.: 78.12%] [G loss: 0.779570]\n",
      "epoch:5 step:5619 [D loss: 0.568972, acc.: 69.53%] [G loss: 0.735183]\n",
      "epoch:5 step:5620 [D loss: 0.458231, acc.: 75.00%] [G loss: 0.847640]\n",
      "epoch:5 step:5621 [D loss: 0.416386, acc.: 85.94%] [G loss: 1.021958]\n",
      "epoch:5 step:5622 [D loss: 0.463237, acc.: 78.12%] [G loss: 1.163027]\n",
      "epoch:6 step:5623 [D loss: 0.569810, acc.: 75.78%] [G loss: 0.881545]\n",
      "epoch:6 step:5624 [D loss: 0.474482, acc.: 77.34%] [G loss: 0.665806]\n",
      "epoch:6 step:5625 [D loss: 0.594827, acc.: 68.75%] [G loss: 0.682579]\n",
      "epoch:6 step:5626 [D loss: 0.525352, acc.: 72.66%] [G loss: 0.671513]\n",
      "epoch:6 step:5627 [D loss: 0.540649, acc.: 73.44%] [G loss: 0.526377]\n",
      "epoch:6 step:5628 [D loss: 0.530675, acc.: 73.44%] [G loss: 0.582243]\n",
      "epoch:6 step:5629 [D loss: 0.464931, acc.: 77.34%] [G loss: 0.757901]\n",
      "epoch:6 step:5630 [D loss: 0.548773, acc.: 72.66%] [G loss: 0.526507]\n",
      "epoch:6 step:5631 [D loss: 0.527816, acc.: 75.78%] [G loss: 0.616424]\n",
      "epoch:6 step:5632 [D loss: 0.545624, acc.: 70.31%] [G loss: 0.609560]\n",
      "epoch:6 step:5633 [D loss: 0.523307, acc.: 73.44%] [G loss: 0.545250]\n",
      "epoch:6 step:5634 [D loss: 0.551212, acc.: 74.22%] [G loss: 0.595393]\n",
      "epoch:6 step:5635 [D loss: 0.553239, acc.: 66.41%] [G loss: 0.582788]\n",
      "epoch:6 step:5636 [D loss: 0.572667, acc.: 67.97%] [G loss: 0.528139]\n",
      "epoch:6 step:5637 [D loss: 0.516483, acc.: 79.69%] [G loss: 0.610732]\n",
      "epoch:6 step:5638 [D loss: 0.461828, acc.: 77.34%] [G loss: 0.483039]\n",
      "epoch:6 step:5639 [D loss: 0.565972, acc.: 71.09%] [G loss: 0.642862]\n",
      "epoch:6 step:5640 [D loss: 0.643828, acc.: 61.72%] [G loss: 0.406605]\n",
      "epoch:6 step:5641 [D loss: 0.566626, acc.: 67.97%] [G loss: 0.523119]\n",
      "epoch:6 step:5642 [D loss: 0.676856, acc.: 57.03%] [G loss: 0.575628]\n",
      "epoch:6 step:5643 [D loss: 0.583054, acc.: 69.53%] [G loss: 0.538669]\n",
      "epoch:6 step:5644 [D loss: 0.533905, acc.: 75.78%] [G loss: 0.666044]\n",
      "epoch:6 step:5645 [D loss: 0.585871, acc.: 66.41%] [G loss: 0.535273]\n",
      "epoch:6 step:5646 [D loss: 0.519408, acc.: 75.00%] [G loss: 0.598845]\n",
      "epoch:6 step:5647 [D loss: 0.510373, acc.: 78.12%] [G loss: 0.589522]\n",
      "epoch:6 step:5648 [D loss: 0.613600, acc.: 61.72%] [G loss: 0.449654]\n",
      "epoch:6 step:5649 [D loss: 0.469476, acc.: 80.47%] [G loss: 0.523998]\n",
      "epoch:6 step:5650 [D loss: 0.591879, acc.: 67.19%] [G loss: 0.498538]\n",
      "epoch:6 step:5651 [D loss: 0.491237, acc.: 79.69%] [G loss: 0.559878]\n",
      "epoch:6 step:5652 [D loss: 0.539468, acc.: 71.09%] [G loss: 0.544155]\n",
      "epoch:6 step:5653 [D loss: 0.596201, acc.: 64.06%] [G loss: 0.490525]\n",
      "epoch:6 step:5654 [D loss: 0.567780, acc.: 67.97%] [G loss: 0.462068]\n",
      "epoch:6 step:5655 [D loss: 0.512898, acc.: 76.56%] [G loss: 0.598997]\n",
      "epoch:6 step:5656 [D loss: 0.492627, acc.: 73.44%] [G loss: 0.656192]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5657 [D loss: 0.560281, acc.: 71.88%] [G loss: 0.497501]\n",
      "epoch:6 step:5658 [D loss: 0.519125, acc.: 75.00%] [G loss: 0.638983]\n",
      "epoch:6 step:5659 [D loss: 0.506696, acc.: 77.34%] [G loss: 0.614652]\n",
      "epoch:6 step:5660 [D loss: 0.620433, acc.: 65.62%] [G loss: 0.561072]\n",
      "epoch:6 step:5661 [D loss: 0.547530, acc.: 71.88%] [G loss: 0.571022]\n",
      "epoch:6 step:5662 [D loss: 0.475260, acc.: 71.88%] [G loss: 0.583422]\n",
      "epoch:6 step:5663 [D loss: 0.532170, acc.: 69.53%] [G loss: 0.584512]\n",
      "epoch:6 step:5664 [D loss: 0.505959, acc.: 78.91%] [G loss: 0.488052]\n",
      "epoch:6 step:5665 [D loss: 0.457259, acc.: 78.91%] [G loss: 0.699832]\n",
      "epoch:6 step:5666 [D loss: 0.589408, acc.: 65.62%] [G loss: 0.512857]\n",
      "epoch:6 step:5667 [D loss: 0.516113, acc.: 75.78%] [G loss: 0.462682]\n",
      "epoch:6 step:5668 [D loss: 0.569612, acc.: 67.19%] [G loss: 0.625202]\n",
      "epoch:6 step:5669 [D loss: 0.527549, acc.: 74.22%] [G loss: 0.526575]\n",
      "epoch:6 step:5670 [D loss: 0.511248, acc.: 76.56%] [G loss: 0.547762]\n",
      "epoch:6 step:5671 [D loss: 0.532854, acc.: 72.66%] [G loss: 0.596854]\n",
      "epoch:6 step:5672 [D loss: 0.547954, acc.: 68.75%] [G loss: 0.628080]\n",
      "epoch:6 step:5673 [D loss: 0.589804, acc.: 70.31%] [G loss: 0.568833]\n",
      "epoch:6 step:5674 [D loss: 0.556738, acc.: 72.66%] [G loss: 0.558472]\n",
      "epoch:6 step:5675 [D loss: 0.556906, acc.: 69.53%] [G loss: 0.573790]\n",
      "epoch:6 step:5676 [D loss: 0.447545, acc.: 82.81%] [G loss: 0.608109]\n",
      "epoch:6 step:5677 [D loss: 0.535091, acc.: 73.44%] [G loss: 0.728376]\n",
      "epoch:6 step:5678 [D loss: 0.488302, acc.: 76.56%] [G loss: 0.533996]\n",
      "epoch:6 step:5679 [D loss: 0.523642, acc.: 70.31%] [G loss: 0.612431]\n",
      "epoch:6 step:5680 [D loss: 0.587248, acc.: 67.19%] [G loss: 0.540159]\n",
      "epoch:6 step:5681 [D loss: 0.519965, acc.: 76.56%] [G loss: 0.608813]\n",
      "epoch:6 step:5682 [D loss: 0.490907, acc.: 72.66%] [G loss: 0.606422]\n",
      "epoch:6 step:5683 [D loss: 0.565410, acc.: 67.97%] [G loss: 0.481345]\n",
      "epoch:6 step:5684 [D loss: 0.588115, acc.: 68.75%] [G loss: 0.559612]\n",
      "epoch:6 step:5685 [D loss: 0.538457, acc.: 71.09%] [G loss: 0.510486]\n",
      "epoch:6 step:5686 [D loss: 0.568494, acc.: 71.09%] [G loss: 0.610535]\n",
      "epoch:6 step:5687 [D loss: 0.563002, acc.: 66.41%] [G loss: 0.521224]\n",
      "epoch:6 step:5688 [D loss: 0.570890, acc.: 67.19%] [G loss: 0.441922]\n",
      "epoch:6 step:5689 [D loss: 0.553462, acc.: 70.31%] [G loss: 0.477589]\n",
      "epoch:6 step:5690 [D loss: 0.558159, acc.: 68.75%] [G loss: 0.470474]\n",
      "epoch:6 step:5691 [D loss: 0.508972, acc.: 73.44%] [G loss: 0.519186]\n",
      "epoch:6 step:5692 [D loss: 0.580690, acc.: 66.41%] [G loss: 0.598608]\n",
      "epoch:6 step:5693 [D loss: 0.494795, acc.: 70.31%] [G loss: 0.584162]\n",
      "epoch:6 step:5694 [D loss: 0.496294, acc.: 80.47%] [G loss: 0.681353]\n",
      "epoch:6 step:5695 [D loss: 0.571495, acc.: 69.53%] [G loss: 0.573085]\n",
      "epoch:6 step:5696 [D loss: 0.463470, acc.: 85.16%] [G loss: 0.562362]\n",
      "epoch:6 step:5697 [D loss: 0.538234, acc.: 74.22%] [G loss: 0.645567]\n",
      "epoch:6 step:5698 [D loss: 0.577840, acc.: 68.75%] [G loss: 0.625929]\n",
      "epoch:6 step:5699 [D loss: 0.441472, acc.: 81.25%] [G loss: 0.787022]\n",
      "epoch:6 step:5700 [D loss: 0.610496, acc.: 67.97%] [G loss: 0.447833]\n",
      "epoch:6 step:5701 [D loss: 0.556286, acc.: 74.22%] [G loss: 0.520218]\n",
      "epoch:6 step:5702 [D loss: 0.558277, acc.: 66.41%] [G loss: 0.575850]\n",
      "epoch:6 step:5703 [D loss: 0.586989, acc.: 67.97%] [G loss: 0.553278]\n",
      "epoch:6 step:5704 [D loss: 0.469077, acc.: 79.69%] [G loss: 0.615451]\n",
      "epoch:6 step:5705 [D loss: 0.473485, acc.: 75.78%] [G loss: 0.577121]\n",
      "epoch:6 step:5706 [D loss: 0.531751, acc.: 71.88%] [G loss: 0.603559]\n",
      "epoch:6 step:5707 [D loss: 0.549603, acc.: 74.22%] [G loss: 0.564724]\n",
      "epoch:6 step:5708 [D loss: 0.582379, acc.: 66.41%] [G loss: 0.483697]\n",
      "epoch:6 step:5709 [D loss: 0.467065, acc.: 81.25%] [G loss: 0.579781]\n",
      "epoch:6 step:5710 [D loss: 0.559662, acc.: 66.41%] [G loss: 0.512185]\n",
      "epoch:6 step:5711 [D loss: 0.513572, acc.: 71.09%] [G loss: 0.670203]\n",
      "epoch:6 step:5712 [D loss: 0.523069, acc.: 75.00%] [G loss: 0.624702]\n",
      "epoch:6 step:5713 [D loss: 0.545511, acc.: 75.78%] [G loss: 0.674424]\n",
      "epoch:6 step:5714 [D loss: 0.565375, acc.: 69.53%] [G loss: 0.475415]\n",
      "epoch:6 step:5715 [D loss: 0.498123, acc.: 76.56%] [G loss: 0.672285]\n",
      "epoch:6 step:5716 [D loss: 0.519398, acc.: 73.44%] [G loss: 0.537059]\n",
      "epoch:6 step:5717 [D loss: 0.530623, acc.: 71.88%] [G loss: 0.646359]\n",
      "epoch:6 step:5718 [D loss: 0.465305, acc.: 79.69%] [G loss: 0.578258]\n",
      "epoch:6 step:5719 [D loss: 0.548930, acc.: 69.53%] [G loss: 0.475889]\n",
      "epoch:6 step:5720 [D loss: 0.495431, acc.: 73.44%] [G loss: 0.774234]\n",
      "epoch:6 step:5721 [D loss: 0.523864, acc.: 72.66%] [G loss: 0.659653]\n",
      "epoch:6 step:5722 [D loss: 0.466974, acc.: 78.12%] [G loss: 0.637089]\n",
      "epoch:6 step:5723 [D loss: 0.497560, acc.: 78.91%] [G loss: 0.553733]\n",
      "epoch:6 step:5724 [D loss: 0.569443, acc.: 68.75%] [G loss: 0.515360]\n",
      "epoch:6 step:5725 [D loss: 0.496034, acc.: 71.09%] [G loss: 0.495457]\n",
      "epoch:6 step:5726 [D loss: 0.475572, acc.: 75.00%] [G loss: 0.549776]\n",
      "epoch:6 step:5727 [D loss: 0.576151, acc.: 72.66%] [G loss: 0.558184]\n",
      "epoch:6 step:5728 [D loss: 0.547426, acc.: 75.78%] [G loss: 0.475268]\n",
      "epoch:6 step:5729 [D loss: 0.604306, acc.: 65.62%] [G loss: 0.505779]\n",
      "epoch:6 step:5730 [D loss: 0.641603, acc.: 64.84%] [G loss: 0.678814]\n",
      "epoch:6 step:5731 [D loss: 0.535637, acc.: 70.31%] [G loss: 0.537510]\n",
      "epoch:6 step:5732 [D loss: 0.602473, acc.: 67.19%] [G loss: 0.531013]\n",
      "epoch:6 step:5733 [D loss: 0.499103, acc.: 81.25%] [G loss: 0.599001]\n",
      "epoch:6 step:5734 [D loss: 0.523983, acc.: 74.22%] [G loss: 0.657740]\n",
      "epoch:6 step:5735 [D loss: 0.531418, acc.: 75.78%] [G loss: 0.530459]\n",
      "epoch:6 step:5736 [D loss: 0.610498, acc.: 64.84%] [G loss: 0.511451]\n",
      "epoch:6 step:5737 [D loss: 0.608934, acc.: 67.97%] [G loss: 0.537125]\n",
      "epoch:6 step:5738 [D loss: 0.530108, acc.: 69.53%] [G loss: 0.699264]\n",
      "epoch:6 step:5739 [D loss: 0.510743, acc.: 76.56%] [G loss: 0.646907]\n",
      "epoch:6 step:5740 [D loss: 0.539175, acc.: 71.09%] [G loss: 0.722179]\n",
      "epoch:6 step:5741 [D loss: 0.443986, acc.: 82.03%] [G loss: 0.891633]\n",
      "epoch:6 step:5742 [D loss: 0.604345, acc.: 68.75%] [G loss: 0.635244]\n",
      "epoch:6 step:5743 [D loss: 0.630611, acc.: 61.72%] [G loss: 0.465596]\n",
      "epoch:6 step:5744 [D loss: 0.533276, acc.: 78.12%] [G loss: 0.472927]\n",
      "epoch:6 step:5745 [D loss: 0.537326, acc.: 76.56%] [G loss: 0.593947]\n",
      "epoch:6 step:5746 [D loss: 0.554335, acc.: 75.00%] [G loss: 0.549764]\n",
      "epoch:6 step:5747 [D loss: 0.565304, acc.: 66.41%] [G loss: 0.520088]\n",
      "epoch:6 step:5748 [D loss: 0.529924, acc.: 75.00%] [G loss: 0.493836]\n",
      "epoch:6 step:5749 [D loss: 0.530846, acc.: 75.00%] [G loss: 0.455471]\n",
      "epoch:6 step:5750 [D loss: 0.482270, acc.: 78.91%] [G loss: 0.459087]\n",
      "epoch:6 step:5751 [D loss: 0.588302, acc.: 64.84%] [G loss: 0.491407]\n",
      "epoch:6 step:5752 [D loss: 0.506019, acc.: 75.00%] [G loss: 0.499490]\n",
      "epoch:6 step:5753 [D loss: 0.496471, acc.: 73.44%] [G loss: 0.569744]\n",
      "epoch:6 step:5754 [D loss: 0.561837, acc.: 68.75%] [G loss: 0.593833]\n",
      "epoch:6 step:5755 [D loss: 0.589620, acc.: 67.19%] [G loss: 0.498010]\n",
      "epoch:6 step:5756 [D loss: 0.560567, acc.: 66.41%] [G loss: 0.494413]\n",
      "epoch:6 step:5757 [D loss: 0.538704, acc.: 71.88%] [G loss: 0.558996]\n",
      "epoch:6 step:5758 [D loss: 0.545738, acc.: 73.44%] [G loss: 0.570036]\n",
      "epoch:6 step:5759 [D loss: 0.633249, acc.: 63.28%] [G loss: 0.610927]\n",
      "epoch:6 step:5760 [D loss: 0.574154, acc.: 67.19%] [G loss: 0.557674]\n",
      "epoch:6 step:5761 [D loss: 0.547708, acc.: 71.88%] [G loss: 0.697853]\n",
      "epoch:6 step:5762 [D loss: 0.587874, acc.: 60.16%] [G loss: 0.584713]\n",
      "epoch:6 step:5763 [D loss: 0.489427, acc.: 75.00%] [G loss: 0.590240]\n",
      "epoch:6 step:5764 [D loss: 0.570641, acc.: 71.09%] [G loss: 0.519563]\n",
      "epoch:6 step:5765 [D loss: 0.566501, acc.: 68.75%] [G loss: 0.596608]\n",
      "epoch:6 step:5766 [D loss: 0.518450, acc.: 75.78%] [G loss: 0.543471]\n",
      "epoch:6 step:5767 [D loss: 0.543931, acc.: 74.22%] [G loss: 0.711253]\n",
      "epoch:6 step:5768 [D loss: 0.548248, acc.: 75.00%] [G loss: 0.584107]\n",
      "epoch:6 step:5769 [D loss: 0.601525, acc.: 66.41%] [G loss: 0.664334]\n",
      "epoch:6 step:5770 [D loss: 0.507812, acc.: 76.56%] [G loss: 0.557925]\n",
      "epoch:6 step:5771 [D loss: 0.498464, acc.: 73.44%] [G loss: 0.549162]\n",
      "epoch:6 step:5772 [D loss: 0.662742, acc.: 60.16%] [G loss: 0.384338]\n",
      "epoch:6 step:5773 [D loss: 0.555390, acc.: 75.00%] [G loss: 0.527652]\n",
      "epoch:6 step:5774 [D loss: 0.496668, acc.: 77.34%] [G loss: 0.675461]\n",
      "epoch:6 step:5775 [D loss: 0.567287, acc.: 67.97%] [G loss: 0.499253]\n",
      "epoch:6 step:5776 [D loss: 0.529720, acc.: 69.53%] [G loss: 0.580565]\n",
      "epoch:6 step:5777 [D loss: 0.429425, acc.: 81.25%] [G loss: 0.821849]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5778 [D loss: 0.537461, acc.: 75.00%] [G loss: 0.752748]\n",
      "epoch:6 step:5779 [D loss: 0.607368, acc.: 67.97%] [G loss: 0.482727]\n",
      "epoch:6 step:5780 [D loss: 0.541247, acc.: 75.00%] [G loss: 0.561062]\n",
      "epoch:6 step:5781 [D loss: 0.546540, acc.: 75.78%] [G loss: 0.475813]\n",
      "epoch:6 step:5782 [D loss: 0.643638, acc.: 61.72%] [G loss: 0.533753]\n",
      "epoch:6 step:5783 [D loss: 0.579384, acc.: 67.19%] [G loss: 0.480362]\n",
      "epoch:6 step:5784 [D loss: 0.478000, acc.: 78.12%] [G loss: 0.721656]\n",
      "epoch:6 step:5785 [D loss: 0.494954, acc.: 77.34%] [G loss: 0.622528]\n",
      "epoch:6 step:5786 [D loss: 0.537799, acc.: 71.88%] [G loss: 0.740717]\n",
      "epoch:6 step:5787 [D loss: 0.560089, acc.: 70.31%] [G loss: 0.475205]\n",
      "epoch:6 step:5788 [D loss: 0.501529, acc.: 74.22%] [G loss: 0.569264]\n",
      "epoch:6 step:5789 [D loss: 0.529861, acc.: 74.22%] [G loss: 0.522044]\n",
      "epoch:6 step:5790 [D loss: 0.529089, acc.: 73.44%] [G loss: 0.541890]\n",
      "epoch:6 step:5791 [D loss: 0.567644, acc.: 69.53%] [G loss: 0.480828]\n",
      "epoch:6 step:5792 [D loss: 0.573370, acc.: 67.97%] [G loss: 0.432101]\n",
      "epoch:6 step:5793 [D loss: 0.512232, acc.: 77.34%] [G loss: 0.454059]\n",
      "epoch:6 step:5794 [D loss: 0.483714, acc.: 79.69%] [G loss: 0.619772]\n",
      "epoch:6 step:5795 [D loss: 0.517771, acc.: 71.88%] [G loss: 0.586989]\n",
      "epoch:6 step:5796 [D loss: 0.628731, acc.: 64.84%] [G loss: 0.470862]\n",
      "epoch:6 step:5797 [D loss: 0.527744, acc.: 73.44%] [G loss: 0.564541]\n",
      "epoch:6 step:5798 [D loss: 0.563154, acc.: 73.44%] [G loss: 0.420979]\n",
      "epoch:6 step:5799 [D loss: 0.505460, acc.: 75.78%] [G loss: 0.592194]\n",
      "epoch:6 step:5800 [D loss: 0.539770, acc.: 74.22%] [G loss: 0.687045]\n",
      "##############\n",
      "[3.11285507 1.7858487  6.67299792 4.83914845 4.13481637 5.97566785\n",
      " 4.81782504 5.04329117 4.66691311 3.91472061]\n",
      "##########\n",
      "epoch:6 step:5801 [D loss: 0.527441, acc.: 69.53%] [G loss: 0.639322]\n",
      "epoch:6 step:5802 [D loss: 0.561173, acc.: 72.66%] [G loss: 0.492428]\n",
      "epoch:6 step:5803 [D loss: 0.583166, acc.: 64.84%] [G loss: 0.465133]\n",
      "epoch:6 step:5804 [D loss: 0.548198, acc.: 70.31%] [G loss: 0.463222]\n",
      "epoch:6 step:5805 [D loss: 0.495653, acc.: 76.56%] [G loss: 0.646090]\n",
      "epoch:6 step:5806 [D loss: 0.610254, acc.: 64.06%] [G loss: 0.559294]\n",
      "epoch:6 step:5807 [D loss: 0.576441, acc.: 66.41%] [G loss: 0.569269]\n",
      "epoch:6 step:5808 [D loss: 0.551781, acc.: 67.97%] [G loss: 0.611041]\n",
      "epoch:6 step:5809 [D loss: 0.639055, acc.: 57.03%] [G loss: 0.539666]\n",
      "epoch:6 step:5810 [D loss: 0.600477, acc.: 65.62%] [G loss: 0.415973]\n",
      "epoch:6 step:5811 [D loss: 0.530391, acc.: 74.22%] [G loss: 0.404613]\n",
      "epoch:6 step:5812 [D loss: 0.475642, acc.: 75.78%] [G loss: 0.578021]\n",
      "epoch:6 step:5813 [D loss: 0.550596, acc.: 71.88%] [G loss: 0.594087]\n",
      "epoch:6 step:5814 [D loss: 0.544110, acc.: 74.22%] [G loss: 0.489252]\n",
      "epoch:6 step:5815 [D loss: 0.534915, acc.: 75.00%] [G loss: 0.567798]\n",
      "epoch:6 step:5816 [D loss: 0.472037, acc.: 80.47%] [G loss: 0.586540]\n",
      "epoch:6 step:5817 [D loss: 0.613725, acc.: 66.41%] [G loss: 0.656307]\n",
      "epoch:6 step:5818 [D loss: 0.579576, acc.: 71.09%] [G loss: 0.495294]\n",
      "epoch:6 step:5819 [D loss: 0.520294, acc.: 69.53%] [G loss: 0.568108]\n",
      "epoch:6 step:5820 [D loss: 0.473813, acc.: 76.56%] [G loss: 0.629465]\n",
      "epoch:6 step:5821 [D loss: 0.529232, acc.: 71.88%] [G loss: 0.575169]\n",
      "epoch:6 step:5822 [D loss: 0.581392, acc.: 71.09%] [G loss: 0.653384]\n",
      "epoch:6 step:5823 [D loss: 0.529831, acc.: 75.78%] [G loss: 0.487599]\n",
      "epoch:6 step:5824 [D loss: 0.591305, acc.: 69.53%] [G loss: 0.530893]\n",
      "epoch:6 step:5825 [D loss: 0.648652, acc.: 62.50%] [G loss: 0.452731]\n",
      "epoch:6 step:5826 [D loss: 0.518494, acc.: 73.44%] [G loss: 0.575238]\n",
      "epoch:6 step:5827 [D loss: 0.537673, acc.: 70.31%] [G loss: 0.573990]\n",
      "epoch:6 step:5828 [D loss: 0.525544, acc.: 73.44%] [G loss: 0.658547]\n",
      "epoch:6 step:5829 [D loss: 0.487460, acc.: 78.91%] [G loss: 0.638463]\n",
      "epoch:6 step:5830 [D loss: 0.458117, acc.: 82.03%] [G loss: 0.629578]\n",
      "epoch:6 step:5831 [D loss: 0.492238, acc.: 75.00%] [G loss: 0.669868]\n",
      "epoch:6 step:5832 [D loss: 0.575426, acc.: 68.75%] [G loss: 0.453794]\n",
      "epoch:6 step:5833 [D loss: 0.591116, acc.: 71.09%] [G loss: 0.516570]\n",
      "epoch:6 step:5834 [D loss: 0.540321, acc.: 71.09%] [G loss: 0.491218]\n",
      "epoch:6 step:5835 [D loss: 0.469292, acc.: 77.34%] [G loss: 0.564712]\n",
      "epoch:6 step:5836 [D loss: 0.658337, acc.: 59.38%] [G loss: 0.464438]\n",
      "epoch:6 step:5837 [D loss: 0.645112, acc.: 61.72%] [G loss: 0.451817]\n",
      "epoch:6 step:5838 [D loss: 0.500321, acc.: 74.22%] [G loss: 0.586940]\n",
      "epoch:6 step:5839 [D loss: 0.604442, acc.: 69.53%] [G loss: 0.570309]\n",
      "epoch:6 step:5840 [D loss: 0.563223, acc.: 71.88%] [G loss: 0.626817]\n",
      "epoch:6 step:5841 [D loss: 0.539387, acc.: 71.09%] [G loss: 0.580236]\n",
      "epoch:6 step:5842 [D loss: 0.578894, acc.: 65.62%] [G loss: 0.589282]\n",
      "epoch:6 step:5843 [D loss: 0.527121, acc.: 75.00%] [G loss: 0.786889]\n",
      "epoch:6 step:5844 [D loss: 0.474265, acc.: 76.56%] [G loss: 0.598127]\n",
      "epoch:6 step:5845 [D loss: 0.498313, acc.: 77.34%] [G loss: 0.636033]\n",
      "epoch:6 step:5846 [D loss: 0.607317, acc.: 67.19%] [G loss: 0.593750]\n",
      "epoch:6 step:5847 [D loss: 0.544719, acc.: 75.00%] [G loss: 0.518224]\n",
      "epoch:6 step:5848 [D loss: 0.578394, acc.: 67.97%] [G loss: 0.424602]\n",
      "epoch:6 step:5849 [D loss: 0.562866, acc.: 71.09%] [G loss: 0.441173]\n",
      "epoch:6 step:5850 [D loss: 0.607719, acc.: 65.62%] [G loss: 0.516275]\n",
      "epoch:6 step:5851 [D loss: 0.597089, acc.: 71.09%] [G loss: 0.533517]\n",
      "epoch:6 step:5852 [D loss: 0.506823, acc.: 75.00%] [G loss: 0.724869]\n",
      "epoch:6 step:5853 [D loss: 0.488411, acc.: 75.00%] [G loss: 0.621121]\n",
      "epoch:6 step:5854 [D loss: 0.427419, acc.: 85.94%] [G loss: 0.791618]\n",
      "epoch:6 step:5855 [D loss: 0.544253, acc.: 76.56%] [G loss: 0.693977]\n",
      "epoch:6 step:5856 [D loss: 0.586505, acc.: 67.97%] [G loss: 0.647075]\n",
      "epoch:6 step:5857 [D loss: 0.593085, acc.: 62.50%] [G loss: 0.695213]\n",
      "epoch:6 step:5858 [D loss: 0.531689, acc.: 72.66%] [G loss: 0.529510]\n",
      "epoch:6 step:5859 [D loss: 0.572171, acc.: 71.09%] [G loss: 0.634800]\n",
      "epoch:6 step:5860 [D loss: 0.556742, acc.: 71.88%] [G loss: 0.519036]\n",
      "epoch:6 step:5861 [D loss: 0.563093, acc.: 69.53%] [G loss: 0.474114]\n",
      "epoch:6 step:5862 [D loss: 0.573065, acc.: 71.09%] [G loss: 0.368834]\n",
      "epoch:6 step:5863 [D loss: 0.572072, acc.: 69.53%] [G loss: 0.545941]\n",
      "epoch:6 step:5864 [D loss: 0.532400, acc.: 73.44%] [G loss: 0.608382]\n",
      "epoch:6 step:5865 [D loss: 0.647618, acc.: 61.72%] [G loss: 0.486792]\n",
      "epoch:6 step:5866 [D loss: 0.492025, acc.: 77.34%] [G loss: 0.633652]\n",
      "epoch:6 step:5867 [D loss: 0.537569, acc.: 74.22%] [G loss: 0.504912]\n",
      "epoch:6 step:5868 [D loss: 0.580167, acc.: 69.53%] [G loss: 0.535724]\n",
      "epoch:6 step:5869 [D loss: 0.571598, acc.: 70.31%] [G loss: 0.541474]\n",
      "epoch:6 step:5870 [D loss: 0.529817, acc.: 71.09%] [G loss: 0.606057]\n",
      "epoch:6 step:5871 [D loss: 0.587476, acc.: 71.88%] [G loss: 0.589732]\n",
      "epoch:6 step:5872 [D loss: 0.650614, acc.: 59.38%] [G loss: 0.526408]\n",
      "epoch:6 step:5873 [D loss: 0.626463, acc.: 63.28%] [G loss: 0.510309]\n",
      "epoch:6 step:5874 [D loss: 0.527231, acc.: 73.44%] [G loss: 0.480489]\n",
      "epoch:6 step:5875 [D loss: 0.565538, acc.: 71.09%] [G loss: 0.408690]\n",
      "epoch:6 step:5876 [D loss: 0.485121, acc.: 78.12%] [G loss: 0.598404]\n",
      "epoch:6 step:5877 [D loss: 0.516639, acc.: 71.88%] [G loss: 0.566216]\n",
      "epoch:6 step:5878 [D loss: 0.556416, acc.: 67.97%] [G loss: 0.534869]\n",
      "epoch:6 step:5879 [D loss: 0.598790, acc.: 67.19%] [G loss: 0.445536]\n",
      "epoch:6 step:5880 [D loss: 0.504596, acc.: 75.00%] [G loss: 0.565855]\n",
      "epoch:6 step:5881 [D loss: 0.569145, acc.: 74.22%] [G loss: 0.508969]\n",
      "epoch:6 step:5882 [D loss: 0.568529, acc.: 67.19%] [G loss: 0.531114]\n",
      "epoch:6 step:5883 [D loss: 0.535464, acc.: 70.31%] [G loss: 0.548759]\n",
      "epoch:6 step:5884 [D loss: 0.543475, acc.: 69.53%] [G loss: 0.481640]\n",
      "epoch:6 step:5885 [D loss: 0.596901, acc.: 67.19%] [G loss: 0.560785]\n",
      "epoch:6 step:5886 [D loss: 0.499153, acc.: 78.12%] [G loss: 0.602337]\n",
      "epoch:6 step:5887 [D loss: 0.621349, acc.: 63.28%] [G loss: 0.502012]\n",
      "epoch:6 step:5888 [D loss: 0.511906, acc.: 78.12%] [G loss: 0.527680]\n",
      "epoch:6 step:5889 [D loss: 0.572127, acc.: 64.84%] [G loss: 0.394639]\n",
      "epoch:6 step:5890 [D loss: 0.546698, acc.: 72.66%] [G loss: 0.398941]\n",
      "epoch:6 step:5891 [D loss: 0.543653, acc.: 68.75%] [G loss: 0.460774]\n",
      "epoch:6 step:5892 [D loss: 0.511072, acc.: 73.44%] [G loss: 0.540487]\n",
      "epoch:6 step:5893 [D loss: 0.516336, acc.: 77.34%] [G loss: 0.495599]\n",
      "epoch:6 step:5894 [D loss: 0.578866, acc.: 68.75%] [G loss: 0.393649]\n",
      "epoch:6 step:5895 [D loss: 0.500188, acc.: 77.34%] [G loss: 0.532293]\n",
      "epoch:6 step:5896 [D loss: 0.605676, acc.: 74.22%] [G loss: 0.474371]\n",
      "epoch:6 step:5897 [D loss: 0.569461, acc.: 67.19%] [G loss: 0.556016]\n",
      "epoch:6 step:5898 [D loss: 0.487976, acc.: 76.56%] [G loss: 0.482305]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5899 [D loss: 0.636418, acc.: 66.41%] [G loss: 0.406732]\n",
      "epoch:6 step:5900 [D loss: 0.603066, acc.: 61.72%] [G loss: 0.595085]\n",
      "epoch:6 step:5901 [D loss: 0.579410, acc.: 64.06%] [G loss: 0.532412]\n",
      "epoch:6 step:5902 [D loss: 0.544348, acc.: 64.84%] [G loss: 0.531734]\n",
      "epoch:6 step:5903 [D loss: 0.613442, acc.: 68.75%] [G loss: 0.543810]\n",
      "epoch:6 step:5904 [D loss: 0.588686, acc.: 66.41%] [G loss: 0.502811]\n",
      "epoch:6 step:5905 [D loss: 0.507030, acc.: 74.22%] [G loss: 0.571335]\n",
      "epoch:6 step:5906 [D loss: 0.508482, acc.: 73.44%] [G loss: 0.640214]\n",
      "epoch:6 step:5907 [D loss: 0.501853, acc.: 74.22%] [G loss: 0.580575]\n",
      "epoch:6 step:5908 [D loss: 0.466512, acc.: 75.78%] [G loss: 0.599105]\n",
      "epoch:6 step:5909 [D loss: 0.558019, acc.: 70.31%] [G loss: 0.560558]\n",
      "epoch:6 step:5910 [D loss: 0.570911, acc.: 71.09%] [G loss: 0.544789]\n",
      "epoch:6 step:5911 [D loss: 0.609331, acc.: 64.84%] [G loss: 0.416210]\n",
      "epoch:6 step:5912 [D loss: 0.582898, acc.: 69.53%] [G loss: 0.541415]\n",
      "epoch:6 step:5913 [D loss: 0.609134, acc.: 65.62%] [G loss: 0.441462]\n",
      "epoch:6 step:5914 [D loss: 0.588516, acc.: 63.28%] [G loss: 0.393108]\n",
      "epoch:6 step:5915 [D loss: 0.565774, acc.: 71.88%] [G loss: 0.468719]\n",
      "epoch:6 step:5916 [D loss: 0.594707, acc.: 62.50%] [G loss: 0.367086]\n",
      "epoch:6 step:5917 [D loss: 0.539347, acc.: 71.09%] [G loss: 0.500098]\n",
      "epoch:6 step:5918 [D loss: 0.482017, acc.: 78.12%] [G loss: 0.630081]\n",
      "epoch:6 step:5919 [D loss: 0.557508, acc.: 70.31%] [G loss: 0.432704]\n",
      "epoch:6 step:5920 [D loss: 0.564572, acc.: 71.88%] [G loss: 0.638720]\n",
      "epoch:6 step:5921 [D loss: 0.506274, acc.: 75.00%] [G loss: 0.617563]\n",
      "epoch:6 step:5922 [D loss: 0.458793, acc.: 80.47%] [G loss: 0.641866]\n",
      "epoch:6 step:5923 [D loss: 0.640156, acc.: 60.16%] [G loss: 0.437164]\n",
      "epoch:6 step:5924 [D loss: 0.546872, acc.: 72.66%] [G loss: 0.512569]\n",
      "epoch:6 step:5925 [D loss: 0.554982, acc.: 72.66%] [G loss: 0.512675]\n",
      "epoch:6 step:5926 [D loss: 0.575154, acc.: 67.97%] [G loss: 0.547169]\n",
      "epoch:6 step:5927 [D loss: 0.517012, acc.: 71.88%] [G loss: 0.590533]\n",
      "epoch:6 step:5928 [D loss: 0.552264, acc.: 74.22%] [G loss: 0.677726]\n",
      "epoch:6 step:5929 [D loss: 0.531021, acc.: 75.78%] [G loss: 0.484090]\n",
      "epoch:6 step:5930 [D loss: 0.542406, acc.: 72.66%] [G loss: 0.542250]\n",
      "epoch:6 step:5931 [D loss: 0.433712, acc.: 82.81%] [G loss: 0.609187]\n",
      "epoch:6 step:5932 [D loss: 0.518256, acc.: 71.09%] [G loss: 0.738435]\n",
      "epoch:6 step:5933 [D loss: 0.493596, acc.: 75.00%] [G loss: 0.603353]\n",
      "epoch:6 step:5934 [D loss: 0.504401, acc.: 72.66%] [G loss: 0.784733]\n",
      "epoch:6 step:5935 [D loss: 0.475701, acc.: 78.91%] [G loss: 0.866536]\n",
      "epoch:6 step:5936 [D loss: 0.476371, acc.: 79.69%] [G loss: 0.910740]\n",
      "epoch:6 step:5937 [D loss: 0.489430, acc.: 78.12%] [G loss: 0.886756]\n",
      "epoch:6 step:5938 [D loss: 0.688036, acc.: 59.38%] [G loss: 0.519366]\n",
      "epoch:6 step:5939 [D loss: 0.567862, acc.: 67.97%] [G loss: 0.489426]\n",
      "epoch:6 step:5940 [D loss: 0.497163, acc.: 74.22%] [G loss: 0.487592]\n",
      "epoch:6 step:5941 [D loss: 0.565679, acc.: 67.97%] [G loss: 0.503109]\n",
      "epoch:6 step:5942 [D loss: 0.486408, acc.: 81.25%] [G loss: 0.579729]\n",
      "epoch:6 step:5943 [D loss: 0.459443, acc.: 81.25%] [G loss: 0.586540]\n",
      "epoch:6 step:5944 [D loss: 0.580292, acc.: 67.97%] [G loss: 0.498857]\n",
      "epoch:6 step:5945 [D loss: 0.584593, acc.: 69.53%] [G loss: 0.486167]\n",
      "epoch:6 step:5946 [D loss: 0.577662, acc.: 69.53%] [G loss: 0.445973]\n",
      "epoch:6 step:5947 [D loss: 0.535901, acc.: 75.00%] [G loss: 0.468467]\n",
      "epoch:6 step:5948 [D loss: 0.549147, acc.: 69.53%] [G loss: 0.660359]\n",
      "epoch:6 step:5949 [D loss: 0.556982, acc.: 65.62%] [G loss: 0.510353]\n",
      "epoch:6 step:5950 [D loss: 0.507096, acc.: 78.12%] [G loss: 0.597869]\n",
      "epoch:6 step:5951 [D loss: 0.593361, acc.: 65.62%] [G loss: 0.645979]\n",
      "epoch:6 step:5952 [D loss: 0.562798, acc.: 69.53%] [G loss: 0.636542]\n",
      "epoch:6 step:5953 [D loss: 0.508649, acc.: 75.78%] [G loss: 0.571178]\n",
      "epoch:6 step:5954 [D loss: 0.546140, acc.: 71.09%] [G loss: 0.594531]\n",
      "epoch:6 step:5955 [D loss: 0.486501, acc.: 76.56%] [G loss: 0.541416]\n",
      "epoch:6 step:5956 [D loss: 0.504165, acc.: 74.22%] [G loss: 0.584601]\n",
      "epoch:6 step:5957 [D loss: 0.496539, acc.: 77.34%] [G loss: 0.577006]\n",
      "epoch:6 step:5958 [D loss: 0.495636, acc.: 77.34%] [G loss: 0.630017]\n",
      "epoch:6 step:5959 [D loss: 0.516987, acc.: 70.31%] [G loss: 0.590272]\n",
      "epoch:6 step:5960 [D loss: 0.532215, acc.: 73.44%] [G loss: 0.654365]\n",
      "epoch:6 step:5961 [D loss: 0.568428, acc.: 73.44%] [G loss: 0.532874]\n",
      "epoch:6 step:5962 [D loss: 0.547435, acc.: 69.53%] [G loss: 0.591091]\n",
      "epoch:6 step:5963 [D loss: 0.523860, acc.: 74.22%] [G loss: 0.607391]\n",
      "epoch:6 step:5964 [D loss: 0.623377, acc.: 60.16%] [G loss: 0.501388]\n",
      "epoch:6 step:5965 [D loss: 0.451058, acc.: 79.69%] [G loss: 0.602804]\n",
      "epoch:6 step:5966 [D loss: 0.478877, acc.: 79.69%] [G loss: 0.594409]\n",
      "epoch:6 step:5967 [D loss: 0.539284, acc.: 77.34%] [G loss: 0.701656]\n",
      "epoch:6 step:5968 [D loss: 0.553383, acc.: 67.19%] [G loss: 0.766809]\n",
      "epoch:6 step:5969 [D loss: 0.470264, acc.: 80.47%] [G loss: 0.827861]\n",
      "epoch:6 step:5970 [D loss: 0.690574, acc.: 66.41%] [G loss: 0.576269]\n",
      "epoch:6 step:5971 [D loss: 0.691491, acc.: 58.59%] [G loss: 0.491461]\n",
      "epoch:6 step:5972 [D loss: 0.481514, acc.: 78.91%] [G loss: 0.560737]\n",
      "epoch:6 step:5973 [D loss: 0.516490, acc.: 74.22%] [G loss: 0.745083]\n",
      "epoch:6 step:5974 [D loss: 0.558141, acc.: 71.88%] [G loss: 0.647785]\n",
      "epoch:6 step:5975 [D loss: 0.563291, acc.: 68.75%] [G loss: 0.583051]\n",
      "epoch:6 step:5976 [D loss: 0.427953, acc.: 82.03%] [G loss: 0.837031]\n",
      "epoch:6 step:5977 [D loss: 0.561684, acc.: 70.31%] [G loss: 0.684404]\n",
      "epoch:6 step:5978 [D loss: 0.577541, acc.: 68.75%] [G loss: 0.570333]\n",
      "epoch:6 step:5979 [D loss: 0.472434, acc.: 75.00%] [G loss: 0.608369]\n",
      "epoch:6 step:5980 [D loss: 0.428396, acc.: 82.03%] [G loss: 0.713571]\n",
      "epoch:6 step:5981 [D loss: 0.436719, acc.: 80.47%] [G loss: 0.849582]\n",
      "epoch:6 step:5982 [D loss: 0.513826, acc.: 74.22%] [G loss: 0.637726]\n",
      "epoch:6 step:5983 [D loss: 0.494657, acc.: 80.47%] [G loss: 0.721695]\n",
      "epoch:6 step:5984 [D loss: 0.550115, acc.: 69.53%] [G loss: 0.539445]\n",
      "epoch:6 step:5985 [D loss: 0.514623, acc.: 75.00%] [G loss: 0.593445]\n",
      "epoch:6 step:5986 [D loss: 0.472550, acc.: 78.12%] [G loss: 0.624759]\n",
      "epoch:6 step:5987 [D loss: 0.488299, acc.: 76.56%] [G loss: 0.534511]\n",
      "epoch:6 step:5988 [D loss: 0.458162, acc.: 80.47%] [G loss: 0.683481]\n",
      "epoch:6 step:5989 [D loss: 0.507015, acc.: 78.12%] [G loss: 0.710690]\n",
      "epoch:6 step:5990 [D loss: 0.525894, acc.: 72.66%] [G loss: 0.478725]\n",
      "epoch:6 step:5991 [D loss: 0.598095, acc.: 69.53%] [G loss: 0.529614]\n",
      "epoch:6 step:5992 [D loss: 0.562469, acc.: 75.00%] [G loss: 0.730190]\n",
      "epoch:6 step:5993 [D loss: 0.548118, acc.: 69.53%] [G loss: 0.635037]\n",
      "epoch:6 step:5994 [D loss: 0.564890, acc.: 70.31%] [G loss: 0.645330]\n",
      "epoch:6 step:5995 [D loss: 0.576014, acc.: 69.53%] [G loss: 0.528601]\n",
      "epoch:6 step:5996 [D loss: 0.497699, acc.: 75.78%] [G loss: 0.600685]\n",
      "epoch:6 step:5997 [D loss: 0.568021, acc.: 69.53%] [G loss: 0.621336]\n",
      "epoch:6 step:5998 [D loss: 0.693291, acc.: 58.59%] [G loss: 0.519647]\n",
      "epoch:6 step:5999 [D loss: 0.613902, acc.: 65.62%] [G loss: 0.498440]\n",
      "epoch:6 step:6000 [D loss: 0.516733, acc.: 75.00%] [G loss: 0.636478]\n",
      "##############\n",
      "[3.07210116 1.31525585 6.7213706  5.13419654 4.28768744 6.0058362\n",
      " 5.12277826 4.84106254 4.76204252 4.02172425]\n",
      "##########\n",
      "epoch:6 step:6001 [D loss: 0.548723, acc.: 67.97%] [G loss: 0.585077]\n",
      "epoch:6 step:6002 [D loss: 0.551867, acc.: 73.44%] [G loss: 0.445080]\n",
      "epoch:6 step:6003 [D loss: 0.472655, acc.: 76.56%] [G loss: 0.639025]\n",
      "epoch:6 step:6004 [D loss: 0.521911, acc.: 74.22%] [G loss: 0.606494]\n",
      "epoch:6 step:6005 [D loss: 0.537678, acc.: 71.09%] [G loss: 0.648110]\n",
      "epoch:6 step:6006 [D loss: 0.527543, acc.: 75.00%] [G loss: 0.548365]\n",
      "epoch:6 step:6007 [D loss: 0.516615, acc.: 71.09%] [G loss: 0.630963]\n",
      "epoch:6 step:6008 [D loss: 0.546524, acc.: 70.31%] [G loss: 0.531116]\n",
      "epoch:6 step:6009 [D loss: 0.549752, acc.: 72.66%] [G loss: 0.578788]\n",
      "epoch:6 step:6010 [D loss: 0.529563, acc.: 74.22%] [G loss: 0.648914]\n",
      "epoch:6 step:6011 [D loss: 0.549083, acc.: 73.44%] [G loss: 0.534946]\n",
      "epoch:6 step:6012 [D loss: 0.579255, acc.: 67.97%] [G loss: 0.483917]\n",
      "epoch:6 step:6013 [D loss: 0.507490, acc.: 76.56%] [G loss: 0.517370]\n",
      "epoch:6 step:6014 [D loss: 0.481418, acc.: 76.56%] [G loss: 0.623637]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6015 [D loss: 0.558333, acc.: 74.22%] [G loss: 0.479478]\n",
      "epoch:6 step:6016 [D loss: 0.592213, acc.: 62.50%] [G loss: 0.413067]\n",
      "epoch:6 step:6017 [D loss: 0.518549, acc.: 73.44%] [G loss: 0.620273]\n",
      "epoch:6 step:6018 [D loss: 0.617619, acc.: 67.19%] [G loss: 0.576676]\n",
      "epoch:6 step:6019 [D loss: 0.483943, acc.: 78.91%] [G loss: 0.742388]\n",
      "epoch:6 step:6020 [D loss: 0.522732, acc.: 72.66%] [G loss: 0.730876]\n",
      "epoch:6 step:6021 [D loss: 0.489655, acc.: 78.12%] [G loss: 0.785939]\n",
      "epoch:6 step:6022 [D loss: 0.623331, acc.: 60.94%] [G loss: 0.554254]\n",
      "epoch:6 step:6023 [D loss: 0.610352, acc.: 60.94%] [G loss: 0.426988]\n",
      "epoch:6 step:6024 [D loss: 0.532465, acc.: 75.00%] [G loss: 0.444475]\n",
      "epoch:6 step:6025 [D loss: 0.513191, acc.: 74.22%] [G loss: 0.480606]\n",
      "epoch:6 step:6026 [D loss: 0.622922, acc.: 64.06%] [G loss: 0.479355]\n",
      "epoch:6 step:6027 [D loss: 0.506978, acc.: 76.56%] [G loss: 0.670360]\n",
      "epoch:6 step:6028 [D loss: 0.505045, acc.: 74.22%] [G loss: 0.658760]\n",
      "epoch:6 step:6029 [D loss: 0.569768, acc.: 71.88%] [G loss: 0.558078]\n",
      "epoch:6 step:6030 [D loss: 0.583779, acc.: 69.53%] [G loss: 0.658008]\n",
      "epoch:6 step:6031 [D loss: 0.547402, acc.: 68.75%] [G loss: 0.541496]\n",
      "epoch:6 step:6032 [D loss: 0.582503, acc.: 64.84%] [G loss: 0.582910]\n",
      "epoch:6 step:6033 [D loss: 0.531942, acc.: 75.00%] [G loss: 0.558658]\n",
      "epoch:6 step:6034 [D loss: 0.580168, acc.: 62.50%] [G loss: 0.596586]\n",
      "epoch:6 step:6035 [D loss: 0.612370, acc.: 68.75%] [G loss: 0.521368]\n",
      "epoch:6 step:6036 [D loss: 0.542864, acc.: 77.34%] [G loss: 0.601287]\n",
      "epoch:6 step:6037 [D loss: 0.539122, acc.: 70.31%] [G loss: 0.623929]\n",
      "epoch:6 step:6038 [D loss: 0.503158, acc.: 75.00%] [G loss: 0.544981]\n",
      "epoch:6 step:6039 [D loss: 0.631685, acc.: 64.06%] [G loss: 0.435989]\n",
      "epoch:6 step:6040 [D loss: 0.682169, acc.: 60.16%] [G loss: 0.484561]\n",
      "epoch:6 step:6041 [D loss: 0.528941, acc.: 74.22%] [G loss: 0.542718]\n",
      "epoch:6 step:6042 [D loss: 0.570758, acc.: 64.06%] [G loss: 0.617935]\n",
      "epoch:6 step:6043 [D loss: 0.576662, acc.: 67.97%] [G loss: 0.380778]\n",
      "epoch:6 step:6044 [D loss: 0.575379, acc.: 67.19%] [G loss: 0.380824]\n",
      "epoch:6 step:6045 [D loss: 0.529658, acc.: 71.88%] [G loss: 0.521778]\n",
      "epoch:6 step:6046 [D loss: 0.578381, acc.: 70.31%] [G loss: 0.509257]\n",
      "epoch:6 step:6047 [D loss: 0.525767, acc.: 75.00%] [G loss: 0.497886]\n",
      "epoch:6 step:6048 [D loss: 0.513196, acc.: 70.31%] [G loss: 0.600561]\n",
      "epoch:6 step:6049 [D loss: 0.494117, acc.: 75.00%] [G loss: 0.642959]\n",
      "epoch:6 step:6050 [D loss: 0.545647, acc.: 70.31%] [G loss: 0.615937]\n",
      "epoch:6 step:6051 [D loss: 0.486198, acc.: 78.12%] [G loss: 0.692784]\n",
      "epoch:6 step:6052 [D loss: 0.526220, acc.: 76.56%] [G loss: 0.683832]\n",
      "epoch:6 step:6053 [D loss: 0.524654, acc.: 75.78%] [G loss: 0.681796]\n",
      "epoch:6 step:6054 [D loss: 0.572055, acc.: 68.75%] [G loss: 0.625065]\n",
      "epoch:6 step:6055 [D loss: 0.556725, acc.: 75.00%] [G loss: 0.459061]\n",
      "epoch:6 step:6056 [D loss: 0.546875, acc.: 69.53%] [G loss: 0.550092]\n",
      "epoch:6 step:6057 [D loss: 0.579750, acc.: 75.00%] [G loss: 0.473302]\n",
      "epoch:6 step:6058 [D loss: 0.510179, acc.: 78.12%] [G loss: 0.613201]\n",
      "epoch:6 step:6059 [D loss: 0.653644, acc.: 67.19%] [G loss: 0.483878]\n",
      "epoch:6 step:6060 [D loss: 0.534511, acc.: 71.09%] [G loss: 0.469205]\n",
      "epoch:6 step:6061 [D loss: 0.522520, acc.: 73.44%] [G loss: 0.474992]\n",
      "epoch:6 step:6062 [D loss: 0.554849, acc.: 71.88%] [G loss: 0.557273]\n",
      "epoch:6 step:6063 [D loss: 0.602597, acc.: 67.97%] [G loss: 0.607760]\n",
      "epoch:6 step:6064 [D loss: 0.536603, acc.: 68.75%] [G loss: 0.533419]\n",
      "epoch:6 step:6065 [D loss: 0.524041, acc.: 74.22%] [G loss: 0.539899]\n",
      "epoch:6 step:6066 [D loss: 0.534791, acc.: 74.22%] [G loss: 0.627562]\n",
      "epoch:6 step:6067 [D loss: 0.523852, acc.: 68.75%] [G loss: 0.533065]\n",
      "epoch:6 step:6068 [D loss: 0.571245, acc.: 67.19%] [G loss: 0.591658]\n",
      "epoch:6 step:6069 [D loss: 0.526048, acc.: 74.22%] [G loss: 0.584949]\n",
      "epoch:6 step:6070 [D loss: 0.596266, acc.: 65.62%] [G loss: 0.600624]\n",
      "epoch:6 step:6071 [D loss: 0.562716, acc.: 72.66%] [G loss: 0.736824]\n",
      "epoch:6 step:6072 [D loss: 0.527296, acc.: 71.88%] [G loss: 0.641097]\n",
      "epoch:6 step:6073 [D loss: 0.450438, acc.: 82.03%] [G loss: 0.713197]\n",
      "epoch:6 step:6074 [D loss: 0.504358, acc.: 74.22%] [G loss: 0.721519]\n",
      "epoch:6 step:6075 [D loss: 0.526435, acc.: 70.31%] [G loss: 0.708496]\n",
      "epoch:6 step:6076 [D loss: 0.628467, acc.: 65.62%] [G loss: 0.542871]\n",
      "epoch:6 step:6077 [D loss: 0.573382, acc.: 69.53%] [G loss: 0.449558]\n",
      "epoch:6 step:6078 [D loss: 0.655664, acc.: 60.94%] [G loss: 0.466851]\n",
      "epoch:6 step:6079 [D loss: 0.532469, acc.: 77.34%] [G loss: 0.513567]\n",
      "epoch:6 step:6080 [D loss: 0.628228, acc.: 65.62%] [G loss: 0.551646]\n",
      "epoch:6 step:6081 [D loss: 0.532169, acc.: 75.78%] [G loss: 0.560778]\n",
      "epoch:6 step:6082 [D loss: 0.529070, acc.: 73.44%] [G loss: 0.510282]\n",
      "epoch:6 step:6083 [D loss: 0.530980, acc.: 73.44%] [G loss: 0.567198]\n",
      "epoch:6 step:6084 [D loss: 0.584599, acc.: 67.19%] [G loss: 0.561994]\n",
      "epoch:6 step:6085 [D loss: 0.600970, acc.: 62.50%] [G loss: 0.528845]\n",
      "epoch:6 step:6086 [D loss: 0.569926, acc.: 72.66%] [G loss: 0.451209]\n",
      "epoch:6 step:6087 [D loss: 0.640417, acc.: 63.28%] [G loss: 0.486163]\n",
      "epoch:6 step:6088 [D loss: 0.559620, acc.: 67.97%] [G loss: 0.722573]\n",
      "epoch:6 step:6089 [D loss: 0.574824, acc.: 67.97%] [G loss: 0.675802]\n",
      "epoch:6 step:6090 [D loss: 0.560949, acc.: 69.53%] [G loss: 0.600661]\n",
      "epoch:6 step:6091 [D loss: 0.581828, acc.: 74.22%] [G loss: 0.572569]\n",
      "epoch:6 step:6092 [D loss: 0.549921, acc.: 70.31%] [G loss: 0.572286]\n",
      "epoch:6 step:6093 [D loss: 0.522142, acc.: 75.00%] [G loss: 0.576467]\n",
      "epoch:6 step:6094 [D loss: 0.439230, acc.: 78.91%] [G loss: 0.765825]\n",
      "epoch:6 step:6095 [D loss: 0.615455, acc.: 67.97%] [G loss: 0.567361]\n",
      "epoch:6 step:6096 [D loss: 0.581533, acc.: 70.31%] [G loss: 0.710517]\n",
      "epoch:6 step:6097 [D loss: 0.448146, acc.: 82.03%] [G loss: 0.761549]\n",
      "epoch:6 step:6098 [D loss: 0.561382, acc.: 74.22%] [G loss: 0.640371]\n",
      "epoch:6 step:6099 [D loss: 0.680087, acc.: 60.94%] [G loss: 0.493972]\n",
      "epoch:6 step:6100 [D loss: 0.565628, acc.: 67.97%] [G loss: 0.471009]\n",
      "epoch:6 step:6101 [D loss: 0.503274, acc.: 75.78%] [G loss: 0.525973]\n",
      "epoch:6 step:6102 [D loss: 0.605030, acc.: 67.19%] [G loss: 0.396026]\n",
      "epoch:6 step:6103 [D loss: 0.535708, acc.: 74.22%] [G loss: 0.479194]\n",
      "epoch:6 step:6104 [D loss: 0.600910, acc.: 71.09%] [G loss: 0.469149]\n",
      "epoch:6 step:6105 [D loss: 0.514473, acc.: 74.22%] [G loss: 0.528608]\n",
      "epoch:6 step:6106 [D loss: 0.525225, acc.: 71.88%] [G loss: 0.358412]\n",
      "epoch:6 step:6107 [D loss: 0.529716, acc.: 73.44%] [G loss: 0.633253]\n",
      "epoch:6 step:6108 [D loss: 0.513782, acc.: 73.44%] [G loss: 0.575628]\n",
      "epoch:6 step:6109 [D loss: 0.584113, acc.: 66.41%] [G loss: 0.557232]\n",
      "epoch:6 step:6110 [D loss: 0.504392, acc.: 76.56%] [G loss: 0.598756]\n",
      "epoch:6 step:6111 [D loss: 0.554311, acc.: 72.66%] [G loss: 0.550290]\n",
      "epoch:6 step:6112 [D loss: 0.537349, acc.: 72.66%] [G loss: 0.543158]\n",
      "epoch:6 step:6113 [D loss: 0.557412, acc.: 70.31%] [G loss: 0.548682]\n",
      "epoch:6 step:6114 [D loss: 0.620212, acc.: 69.53%] [G loss: 0.562547]\n",
      "epoch:6 step:6115 [D loss: 0.623677, acc.: 66.41%] [G loss: 0.411287]\n",
      "epoch:6 step:6116 [D loss: 0.572237, acc.: 70.31%] [G loss: 0.591259]\n",
      "epoch:6 step:6117 [D loss: 0.553082, acc.: 73.44%] [G loss: 0.496677]\n",
      "epoch:6 step:6118 [D loss: 0.574788, acc.: 69.53%] [G loss: 0.534447]\n",
      "epoch:6 step:6119 [D loss: 0.527002, acc.: 74.22%] [G loss: 0.552038]\n",
      "epoch:6 step:6120 [D loss: 0.553231, acc.: 67.97%] [G loss: 0.491945]\n",
      "epoch:6 step:6121 [D loss: 0.457437, acc.: 78.12%] [G loss: 0.797443]\n",
      "epoch:6 step:6122 [D loss: 0.606476, acc.: 64.06%] [G loss: 0.489217]\n",
      "epoch:6 step:6123 [D loss: 0.621602, acc.: 64.06%] [G loss: 0.451223]\n",
      "epoch:6 step:6124 [D loss: 0.615675, acc.: 61.72%] [G loss: 0.576614]\n",
      "epoch:6 step:6125 [D loss: 0.481424, acc.: 77.34%] [G loss: 0.627343]\n",
      "epoch:6 step:6126 [D loss: 0.517403, acc.: 74.22%] [G loss: 0.570817]\n",
      "epoch:6 step:6127 [D loss: 0.528168, acc.: 71.88%] [G loss: 0.597307]\n",
      "epoch:6 step:6128 [D loss: 0.498472, acc.: 77.34%] [G loss: 0.599386]\n",
      "epoch:6 step:6129 [D loss: 0.553682, acc.: 74.22%] [G loss: 0.606386]\n",
      "epoch:6 step:6130 [D loss: 0.462422, acc.: 76.56%] [G loss: 0.684747]\n",
      "epoch:6 step:6131 [D loss: 0.503732, acc.: 72.66%] [G loss: 0.719837]\n",
      "epoch:6 step:6132 [D loss: 0.614043, acc.: 67.19%] [G loss: 0.451965]\n",
      "epoch:6 step:6133 [D loss: 0.591733, acc.: 65.62%] [G loss: 0.531174]\n",
      "epoch:6 step:6134 [D loss: 0.572321, acc.: 71.09%] [G loss: 0.394201]\n",
      "epoch:6 step:6135 [D loss: 0.561881, acc.: 80.47%] [G loss: 0.535149]\n",
      "epoch:6 step:6136 [D loss: 0.503043, acc.: 73.44%] [G loss: 0.616236]\n",
      "epoch:6 step:6137 [D loss: 0.514811, acc.: 79.69%] [G loss: 0.534003]\n",
      "epoch:6 step:6138 [D loss: 0.473925, acc.: 79.69%] [G loss: 0.682602]\n",
      "epoch:6 step:6139 [D loss: 0.557941, acc.: 74.22%] [G loss: 0.691537]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6140 [D loss: 0.513099, acc.: 73.44%] [G loss: 0.552797]\n",
      "epoch:6 step:6141 [D loss: 0.452777, acc.: 81.25%] [G loss: 0.590202]\n",
      "epoch:6 step:6142 [D loss: 0.522058, acc.: 69.53%] [G loss: 0.582487]\n",
      "epoch:6 step:6143 [D loss: 0.535556, acc.: 74.22%] [G loss: 0.605500]\n",
      "epoch:6 step:6144 [D loss: 0.587788, acc.: 66.41%] [G loss: 0.511149]\n",
      "epoch:6 step:6145 [D loss: 0.517633, acc.: 77.34%] [G loss: 0.505577]\n",
      "epoch:6 step:6146 [D loss: 0.533203, acc.: 71.88%] [G loss: 0.537776]\n",
      "epoch:6 step:6147 [D loss: 0.601518, acc.: 66.41%] [G loss: 0.561515]\n",
      "epoch:6 step:6148 [D loss: 0.485726, acc.: 75.00%] [G loss: 0.649784]\n",
      "epoch:6 step:6149 [D loss: 0.579238, acc.: 66.41%] [G loss: 0.563196]\n",
      "epoch:6 step:6150 [D loss: 0.595748, acc.: 66.41%] [G loss: 0.525763]\n",
      "epoch:6 step:6151 [D loss: 0.556304, acc.: 72.66%] [G loss: 0.585392]\n",
      "epoch:6 step:6152 [D loss: 0.535675, acc.: 71.09%] [G loss: 0.557171]\n",
      "epoch:6 step:6153 [D loss: 0.592902, acc.: 71.09%] [G loss: 0.603128]\n",
      "epoch:6 step:6154 [D loss: 0.552732, acc.: 71.88%] [G loss: 0.645103]\n",
      "epoch:6 step:6155 [D loss: 0.545542, acc.: 76.56%] [G loss: 0.618759]\n",
      "epoch:6 step:6156 [D loss: 0.478886, acc.: 79.69%] [G loss: 0.592866]\n",
      "epoch:6 step:6157 [D loss: 0.632120, acc.: 62.50%] [G loss: 0.471859]\n",
      "epoch:6 step:6158 [D loss: 0.523316, acc.: 76.56%] [G loss: 0.544155]\n",
      "epoch:6 step:6159 [D loss: 0.571893, acc.: 71.09%] [G loss: 0.541080]\n",
      "epoch:6 step:6160 [D loss: 0.595030, acc.: 65.62%] [G loss: 0.441349]\n",
      "epoch:6 step:6161 [D loss: 0.586875, acc.: 65.62%] [G loss: 0.394838]\n",
      "epoch:6 step:6162 [D loss: 0.519431, acc.: 72.66%] [G loss: 0.479942]\n",
      "epoch:6 step:6163 [D loss: 0.553210, acc.: 67.19%] [G loss: 0.448834]\n",
      "epoch:6 step:6164 [D loss: 0.607281, acc.: 68.75%] [G loss: 0.403481]\n",
      "epoch:6 step:6165 [D loss: 0.586751, acc.: 67.97%] [G loss: 0.548622]\n",
      "epoch:6 step:6166 [D loss: 0.540201, acc.: 73.44%] [G loss: 0.571823]\n",
      "epoch:6 step:6167 [D loss: 0.528250, acc.: 75.00%] [G loss: 0.665840]\n",
      "epoch:6 step:6168 [D loss: 0.507922, acc.: 77.34%] [G loss: 0.644135]\n",
      "epoch:6 step:6169 [D loss: 0.557697, acc.: 69.53%] [G loss: 0.656209]\n",
      "epoch:6 step:6170 [D loss: 0.457173, acc.: 82.03%] [G loss: 0.674996]\n",
      "epoch:6 step:6171 [D loss: 0.517376, acc.: 78.12%] [G loss: 0.633893]\n",
      "epoch:6 step:6172 [D loss: 0.552763, acc.: 71.09%] [G loss: 0.474356]\n",
      "epoch:6 step:6173 [D loss: 0.593275, acc.: 67.19%] [G loss: 0.555651]\n",
      "epoch:6 step:6174 [D loss: 0.487404, acc.: 76.56%] [G loss: 0.648400]\n",
      "epoch:6 step:6175 [D loss: 0.576422, acc.: 68.75%] [G loss: 0.485891]\n",
      "epoch:6 step:6176 [D loss: 0.424461, acc.: 82.03%] [G loss: 0.703499]\n",
      "epoch:6 step:6177 [D loss: 0.504882, acc.: 75.78%] [G loss: 0.562688]\n",
      "epoch:6 step:6178 [D loss: 0.497536, acc.: 76.56%] [G loss: 0.580702]\n",
      "epoch:6 step:6179 [D loss: 0.463951, acc.: 80.47%] [G loss: 0.732073]\n",
      "epoch:6 step:6180 [D loss: 0.477615, acc.: 77.34%] [G loss: 0.678020]\n",
      "epoch:6 step:6181 [D loss: 0.594256, acc.: 65.62%] [G loss: 0.515340]\n",
      "epoch:6 step:6182 [D loss: 0.581420, acc.: 65.62%] [G loss: 0.541766]\n",
      "epoch:6 step:6183 [D loss: 0.496370, acc.: 77.34%] [G loss: 0.515661]\n",
      "epoch:6 step:6184 [D loss: 0.607880, acc.: 67.19%] [G loss: 0.456624]\n",
      "epoch:6 step:6185 [D loss: 0.564745, acc.: 65.62%] [G loss: 0.478652]\n",
      "epoch:6 step:6186 [D loss: 0.516644, acc.: 75.78%] [G loss: 0.665526]\n",
      "epoch:6 step:6187 [D loss: 0.525186, acc.: 74.22%] [G loss: 0.595295]\n",
      "epoch:6 step:6188 [D loss: 0.679183, acc.: 60.94%] [G loss: 0.455809]\n",
      "epoch:6 step:6189 [D loss: 0.505746, acc.: 72.66%] [G loss: 0.608218]\n",
      "epoch:6 step:6190 [D loss: 0.518098, acc.: 74.22%] [G loss: 0.624287]\n",
      "epoch:6 step:6191 [D loss: 0.516043, acc.: 75.78%] [G loss: 0.534726]\n",
      "epoch:6 step:6192 [D loss: 0.525756, acc.: 71.88%] [G loss: 0.523364]\n",
      "epoch:6 step:6193 [D loss: 0.475122, acc.: 77.34%] [G loss: 0.436677]\n",
      "epoch:6 step:6194 [D loss: 0.614383, acc.: 63.28%] [G loss: 0.602889]\n",
      "epoch:6 step:6195 [D loss: 0.532017, acc.: 75.78%] [G loss: 0.652110]\n",
      "epoch:6 step:6196 [D loss: 0.530320, acc.: 75.00%] [G loss: 0.715921]\n",
      "epoch:6 step:6197 [D loss: 0.452068, acc.: 78.91%] [G loss: 0.824150]\n",
      "epoch:6 step:6198 [D loss: 0.609401, acc.: 64.84%] [G loss: 0.640852]\n",
      "epoch:6 step:6199 [D loss: 0.622494, acc.: 66.41%] [G loss: 0.556168]\n",
      "epoch:6 step:6200 [D loss: 0.535481, acc.: 70.31%] [G loss: 0.650961]\n",
      "##############\n",
      "[2.72865164 1.40503839 6.4847468  4.91992431 4.20632777 5.90636861\n",
      " 5.08319429 4.79267543 4.93349631 3.82913673]\n",
      "##########\n",
      "epoch:6 step:6201 [D loss: 0.557515, acc.: 67.97%] [G loss: 0.533694]\n",
      "epoch:6 step:6202 [D loss: 0.501349, acc.: 72.66%] [G loss: 0.525512]\n",
      "epoch:6 step:6203 [D loss: 0.587988, acc.: 67.97%] [G loss: 0.492120]\n",
      "epoch:6 step:6204 [D loss: 0.480830, acc.: 78.91%] [G loss: 0.832735]\n",
      "epoch:6 step:6205 [D loss: 0.611282, acc.: 66.41%] [G loss: 0.519340]\n",
      "epoch:6 step:6206 [D loss: 0.586897, acc.: 67.97%] [G loss: 0.529940]\n",
      "epoch:6 step:6207 [D loss: 0.562437, acc.: 70.31%] [G loss: 0.582333]\n",
      "epoch:6 step:6208 [D loss: 0.601802, acc.: 67.97%] [G loss: 0.552832]\n",
      "epoch:6 step:6209 [D loss: 0.594893, acc.: 60.16%] [G loss: 0.465269]\n",
      "epoch:6 step:6210 [D loss: 0.579932, acc.: 68.75%] [G loss: 0.564701]\n",
      "epoch:6 step:6211 [D loss: 0.527271, acc.: 72.66%] [G loss: 0.715883]\n",
      "epoch:6 step:6212 [D loss: 0.565904, acc.: 72.66%] [G loss: 0.583642]\n",
      "epoch:6 step:6213 [D loss: 0.615577, acc.: 69.53%] [G loss: 0.340036]\n",
      "epoch:6 step:6214 [D loss: 0.489304, acc.: 79.69%] [G loss: 0.630528]\n",
      "epoch:6 step:6215 [D loss: 0.525145, acc.: 71.88%] [G loss: 0.586059]\n",
      "epoch:6 step:6216 [D loss: 0.519605, acc.: 74.22%] [G loss: 0.633994]\n",
      "epoch:6 step:6217 [D loss: 0.591623, acc.: 71.88%] [G loss: 0.501266]\n",
      "epoch:6 step:6218 [D loss: 0.543006, acc.: 70.31%] [G loss: 0.549980]\n",
      "epoch:6 step:6219 [D loss: 0.532602, acc.: 71.09%] [G loss: 0.557473]\n",
      "epoch:6 step:6220 [D loss: 0.528946, acc.: 76.56%] [G loss: 0.622690]\n",
      "epoch:6 step:6221 [D loss: 0.499665, acc.: 75.78%] [G loss: 0.606956]\n",
      "epoch:6 step:6222 [D loss: 0.688023, acc.: 61.72%] [G loss: 0.471068]\n",
      "epoch:6 step:6223 [D loss: 0.519476, acc.: 71.88%] [G loss: 0.540360]\n",
      "epoch:6 step:6224 [D loss: 0.550832, acc.: 67.97%] [G loss: 0.575685]\n",
      "epoch:6 step:6225 [D loss: 0.493528, acc.: 77.34%] [G loss: 0.644305]\n",
      "epoch:6 step:6226 [D loss: 0.579546, acc.: 66.41%] [G loss: 0.647144]\n",
      "epoch:6 step:6227 [D loss: 0.445460, acc.: 81.25%] [G loss: 0.659998]\n",
      "epoch:6 step:6228 [D loss: 0.548364, acc.: 71.88%] [G loss: 0.492791]\n",
      "epoch:6 step:6229 [D loss: 0.518956, acc.: 73.44%] [G loss: 0.417082]\n",
      "epoch:6 step:6230 [D loss: 0.529848, acc.: 75.78%] [G loss: 0.540904]\n",
      "epoch:6 step:6231 [D loss: 0.475965, acc.: 76.56%] [G loss: 0.667177]\n",
      "epoch:6 step:6232 [D loss: 0.532854, acc.: 72.66%] [G loss: 0.515454]\n",
      "epoch:6 step:6233 [D loss: 0.486039, acc.: 71.88%] [G loss: 0.638968]\n",
      "epoch:6 step:6234 [D loss: 0.538736, acc.: 71.09%] [G loss: 0.571070]\n",
      "epoch:6 step:6235 [D loss: 0.492808, acc.: 76.56%] [G loss: 0.511043]\n",
      "epoch:6 step:6236 [D loss: 0.557950, acc.: 67.97%] [G loss: 0.518088]\n",
      "epoch:6 step:6237 [D loss: 0.587453, acc.: 64.84%] [G loss: 0.663863]\n",
      "epoch:6 step:6238 [D loss: 0.652511, acc.: 57.03%] [G loss: 0.580899]\n",
      "epoch:6 step:6239 [D loss: 0.526401, acc.: 71.88%] [G loss: 0.671781]\n",
      "epoch:6 step:6240 [D loss: 0.546866, acc.: 72.66%] [G loss: 0.560683]\n",
      "epoch:6 step:6241 [D loss: 0.539694, acc.: 71.09%] [G loss: 0.535349]\n",
      "epoch:6 step:6242 [D loss: 0.562776, acc.: 69.53%] [G loss: 0.590392]\n",
      "epoch:6 step:6243 [D loss: 0.601112, acc.: 64.06%] [G loss: 0.565412]\n",
      "epoch:6 step:6244 [D loss: 0.598547, acc.: 61.72%] [G loss: 0.472200]\n",
      "epoch:6 step:6245 [D loss: 0.510732, acc.: 76.56%] [G loss: 0.659581]\n",
      "epoch:6 step:6246 [D loss: 0.540284, acc.: 69.53%] [G loss: 0.663195]\n",
      "epoch:6 step:6247 [D loss: 0.592033, acc.: 66.41%] [G loss: 0.671766]\n",
      "epoch:6 step:6248 [D loss: 0.474479, acc.: 78.91%] [G loss: 0.545040]\n",
      "epoch:6 step:6249 [D loss: 0.559450, acc.: 68.75%] [G loss: 0.600609]\n",
      "epoch:6 step:6250 [D loss: 0.572141, acc.: 66.41%] [G loss: 0.583702]\n",
      "epoch:6 step:6251 [D loss: 0.492441, acc.: 77.34%] [G loss: 0.612629]\n",
      "epoch:6 step:6252 [D loss: 0.550996, acc.: 71.88%] [G loss: 0.554574]\n",
      "epoch:6 step:6253 [D loss: 0.526197, acc.: 77.34%] [G loss: 0.548466]\n",
      "epoch:6 step:6254 [D loss: 0.473930, acc.: 76.56%] [G loss: 0.571262]\n",
      "epoch:6 step:6255 [D loss: 0.506389, acc.: 75.00%] [G loss: 0.620863]\n",
      "epoch:6 step:6256 [D loss: 0.500102, acc.: 76.56%] [G loss: 0.643581]\n",
      "epoch:6 step:6257 [D loss: 0.547647, acc.: 73.44%] [G loss: 0.650459]\n",
      "epoch:6 step:6258 [D loss: 0.559767, acc.: 67.97%] [G loss: 0.553410]\n",
      "epoch:6 step:6259 [D loss: 0.533621, acc.: 75.78%] [G loss: 0.505933]\n",
      "epoch:6 step:6260 [D loss: 0.489121, acc.: 75.78%] [G loss: 0.648384]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6261 [D loss: 0.483321, acc.: 77.34%] [G loss: 0.658413]\n",
      "epoch:6 step:6262 [D loss: 0.536756, acc.: 70.31%] [G loss: 0.660011]\n",
      "epoch:6 step:6263 [D loss: 0.459262, acc.: 77.34%] [G loss: 0.835980]\n",
      "epoch:6 step:6264 [D loss: 0.472417, acc.: 80.47%] [G loss: 0.910114]\n",
      "epoch:6 step:6265 [D loss: 0.529816, acc.: 73.44%] [G loss: 0.633812]\n",
      "epoch:6 step:6266 [D loss: 0.567852, acc.: 69.53%] [G loss: 0.536051]\n",
      "epoch:6 step:6267 [D loss: 0.512316, acc.: 76.56%] [G loss: 0.492025]\n",
      "epoch:6 step:6268 [D loss: 0.549486, acc.: 71.09%] [G loss: 0.664939]\n",
      "epoch:6 step:6269 [D loss: 0.470140, acc.: 78.91%] [G loss: 0.604140]\n",
      "epoch:6 step:6270 [D loss: 0.457640, acc.: 79.69%] [G loss: 0.863943]\n",
      "epoch:6 step:6271 [D loss: 0.443191, acc.: 80.47%] [G loss: 0.744866]\n",
      "epoch:6 step:6272 [D loss: 0.512554, acc.: 74.22%] [G loss: 0.863885]\n",
      "epoch:6 step:6273 [D loss: 0.535178, acc.: 71.88%] [G loss: 0.618696]\n",
      "epoch:6 step:6274 [D loss: 0.637781, acc.: 65.62%] [G loss: 0.533453]\n",
      "epoch:6 step:6275 [D loss: 0.605901, acc.: 64.06%] [G loss: 0.475907]\n",
      "epoch:6 step:6276 [D loss: 0.509528, acc.: 76.56%] [G loss: 0.482471]\n",
      "epoch:6 step:6277 [D loss: 0.495503, acc.: 76.56%] [G loss: 0.559405]\n",
      "epoch:6 step:6278 [D loss: 0.539519, acc.: 71.09%] [G loss: 0.654572]\n",
      "epoch:6 step:6279 [D loss: 0.541604, acc.: 67.97%] [G loss: 0.689275]\n",
      "epoch:6 step:6280 [D loss: 0.627897, acc.: 62.50%] [G loss: 0.585379]\n",
      "epoch:6 step:6281 [D loss: 0.584470, acc.: 67.97%] [G loss: 0.446357]\n",
      "epoch:6 step:6282 [D loss: 0.499829, acc.: 74.22%] [G loss: 0.597909]\n",
      "epoch:6 step:6283 [D loss: 0.538514, acc.: 74.22%] [G loss: 0.651293]\n",
      "epoch:6 step:6284 [D loss: 0.575336, acc.: 67.97%] [G loss: 0.544470]\n",
      "epoch:6 step:6285 [D loss: 0.555849, acc.: 70.31%] [G loss: 0.559537]\n",
      "epoch:6 step:6286 [D loss: 0.657156, acc.: 58.59%] [G loss: 0.509116]\n",
      "epoch:6 step:6287 [D loss: 0.563753, acc.: 68.75%] [G loss: 0.659495]\n",
      "epoch:6 step:6288 [D loss: 0.549571, acc.: 72.66%] [G loss: 0.674831]\n",
      "epoch:6 step:6289 [D loss: 0.586613, acc.: 64.06%] [G loss: 0.590163]\n",
      "epoch:6 step:6290 [D loss: 0.546508, acc.: 73.44%] [G loss: 0.484767]\n",
      "epoch:6 step:6291 [D loss: 0.560950, acc.: 71.88%] [G loss: 0.520373]\n",
      "epoch:6 step:6292 [D loss: 0.556738, acc.: 67.19%] [G loss: 0.619038]\n",
      "epoch:6 step:6293 [D loss: 0.576430, acc.: 69.53%] [G loss: 0.751848]\n",
      "epoch:6 step:6294 [D loss: 0.645620, acc.: 63.28%] [G loss: 0.613085]\n",
      "epoch:6 step:6295 [D loss: 0.621615, acc.: 64.06%] [G loss: 0.516383]\n",
      "epoch:6 step:6296 [D loss: 0.578890, acc.: 70.31%] [G loss: 0.572148]\n",
      "epoch:6 step:6297 [D loss: 0.555976, acc.: 70.31%] [G loss: 0.621352]\n",
      "epoch:6 step:6298 [D loss: 0.540811, acc.: 72.66%] [G loss: 0.593469]\n",
      "epoch:6 step:6299 [D loss: 0.504773, acc.: 75.00%] [G loss: 0.517553]\n",
      "epoch:6 step:6300 [D loss: 0.526909, acc.: 74.22%] [G loss: 0.599373]\n",
      "epoch:6 step:6301 [D loss: 0.524347, acc.: 75.00%] [G loss: 0.529554]\n",
      "epoch:6 step:6302 [D loss: 0.477490, acc.: 80.47%] [G loss: 0.560976]\n",
      "epoch:6 step:6303 [D loss: 0.523596, acc.: 73.44%] [G loss: 0.602542]\n",
      "epoch:6 step:6304 [D loss: 0.488046, acc.: 75.00%] [G loss: 0.543254]\n",
      "epoch:6 step:6305 [D loss: 0.551596, acc.: 67.97%] [G loss: 0.550063]\n",
      "epoch:6 step:6306 [D loss: 0.545633, acc.: 69.53%] [G loss: 0.590087]\n",
      "epoch:6 step:6307 [D loss: 0.569672, acc.: 71.09%] [G loss: 0.455794]\n",
      "epoch:6 step:6308 [D loss: 0.572050, acc.: 72.66%] [G loss: 0.466992]\n",
      "epoch:6 step:6309 [D loss: 0.569685, acc.: 67.19%] [G loss: 0.411048]\n",
      "epoch:6 step:6310 [D loss: 0.572452, acc.: 66.41%] [G loss: 0.599199]\n",
      "epoch:6 step:6311 [D loss: 0.546859, acc.: 67.19%] [G loss: 0.702976]\n",
      "epoch:6 step:6312 [D loss: 0.511202, acc.: 71.88%] [G loss: 0.738422]\n",
      "epoch:6 step:6313 [D loss: 0.621742, acc.: 67.19%] [G loss: 0.587186]\n",
      "epoch:6 step:6314 [D loss: 0.607891, acc.: 71.09%] [G loss: 0.574966]\n",
      "epoch:6 step:6315 [D loss: 0.496864, acc.: 77.34%] [G loss: 0.841264]\n",
      "epoch:6 step:6316 [D loss: 0.583325, acc.: 66.41%] [G loss: 0.576732]\n",
      "epoch:6 step:6317 [D loss: 0.514272, acc.: 75.78%] [G loss: 0.645433]\n",
      "epoch:6 step:6318 [D loss: 0.654263, acc.: 61.72%] [G loss: 0.431756]\n",
      "epoch:6 step:6319 [D loss: 0.512409, acc.: 75.78%] [G loss: 0.606193]\n",
      "epoch:6 step:6320 [D loss: 0.535611, acc.: 75.00%] [G loss: 0.475963]\n",
      "epoch:6 step:6321 [D loss: 0.534753, acc.: 71.88%] [G loss: 0.380453]\n",
      "epoch:6 step:6322 [D loss: 0.545137, acc.: 71.88%] [G loss: 0.670798]\n",
      "epoch:6 step:6323 [D loss: 0.577580, acc.: 70.31%] [G loss: 0.671700]\n",
      "epoch:6 step:6324 [D loss: 0.569283, acc.: 64.84%] [G loss: 0.641514]\n",
      "epoch:6 step:6325 [D loss: 0.604103, acc.: 67.97%] [G loss: 0.450321]\n",
      "epoch:6 step:6326 [D loss: 0.602327, acc.: 70.31%] [G loss: 0.445689]\n",
      "epoch:6 step:6327 [D loss: 0.523404, acc.: 78.91%] [G loss: 0.522724]\n",
      "epoch:6 step:6328 [D loss: 0.547065, acc.: 74.22%] [G loss: 0.579527]\n",
      "epoch:6 step:6329 [D loss: 0.528354, acc.: 74.22%] [G loss: 0.545290]\n",
      "epoch:6 step:6330 [D loss: 0.489940, acc.: 72.66%] [G loss: 0.750191]\n",
      "epoch:6 step:6331 [D loss: 0.507943, acc.: 75.00%] [G loss: 0.748080]\n",
      "epoch:6 step:6332 [D loss: 0.637807, acc.: 67.19%] [G loss: 0.542473]\n",
      "epoch:6 step:6333 [D loss: 0.565940, acc.: 68.75%] [G loss: 0.536445]\n",
      "epoch:6 step:6334 [D loss: 0.505482, acc.: 77.34%] [G loss: 0.510649]\n",
      "epoch:6 step:6335 [D loss: 0.597870, acc.: 64.84%] [G loss: 0.576764]\n",
      "epoch:6 step:6336 [D loss: 0.559183, acc.: 72.66%] [G loss: 0.563178]\n",
      "epoch:6 step:6337 [D loss: 0.608184, acc.: 64.06%] [G loss: 0.526619]\n",
      "epoch:6 step:6338 [D loss: 0.633624, acc.: 62.50%] [G loss: 0.502061]\n",
      "epoch:6 step:6339 [D loss: 0.612288, acc.: 65.62%] [G loss: 0.464785]\n",
      "epoch:6 step:6340 [D loss: 0.571142, acc.: 66.41%] [G loss: 0.416789]\n",
      "epoch:6 step:6341 [D loss: 0.545469, acc.: 70.31%] [G loss: 0.451814]\n",
      "epoch:6 step:6342 [D loss: 0.574558, acc.: 70.31%] [G loss: 0.548253]\n",
      "epoch:6 step:6343 [D loss: 0.592941, acc.: 70.31%] [G loss: 0.546576]\n",
      "epoch:6 step:6344 [D loss: 0.579347, acc.: 70.31%] [G loss: 0.407648]\n",
      "epoch:6 step:6345 [D loss: 0.538818, acc.: 71.88%] [G loss: 0.621702]\n",
      "epoch:6 step:6346 [D loss: 0.540655, acc.: 72.66%] [G loss: 0.587526]\n",
      "epoch:6 step:6347 [D loss: 0.525469, acc.: 77.34%] [G loss: 0.566101]\n",
      "epoch:6 step:6348 [D loss: 0.513948, acc.: 75.78%] [G loss: 0.628912]\n",
      "epoch:6 step:6349 [D loss: 0.563203, acc.: 68.75%] [G loss: 0.506137]\n",
      "epoch:6 step:6350 [D loss: 0.567458, acc.: 67.19%] [G loss: 0.603634]\n",
      "epoch:6 step:6351 [D loss: 0.613155, acc.: 65.62%] [G loss: 0.513438]\n",
      "epoch:6 step:6352 [D loss: 0.511242, acc.: 75.00%] [G loss: 0.598884]\n",
      "epoch:6 step:6353 [D loss: 0.599375, acc.: 67.19%] [G loss: 0.540545]\n",
      "epoch:6 step:6354 [D loss: 0.566862, acc.: 65.62%] [G loss: 0.500198]\n",
      "epoch:6 step:6355 [D loss: 0.574765, acc.: 68.75%] [G loss: 0.571109]\n",
      "epoch:6 step:6356 [D loss: 0.543597, acc.: 69.53%] [G loss: 0.546256]\n",
      "epoch:6 step:6357 [D loss: 0.602939, acc.: 71.09%] [G loss: 0.461551]\n",
      "epoch:6 step:6358 [D loss: 0.503307, acc.: 68.75%] [G loss: 0.589890]\n",
      "epoch:6 step:6359 [D loss: 0.532524, acc.: 71.88%] [G loss: 0.577076]\n",
      "epoch:6 step:6360 [D loss: 0.557613, acc.: 67.19%] [G loss: 0.545754]\n",
      "epoch:6 step:6361 [D loss: 0.579866, acc.: 69.53%] [G loss: 0.482102]\n",
      "epoch:6 step:6362 [D loss: 0.681448, acc.: 61.72%] [G loss: 0.489160]\n",
      "epoch:6 step:6363 [D loss: 0.555516, acc.: 71.09%] [G loss: 0.453850]\n",
      "epoch:6 step:6364 [D loss: 0.527335, acc.: 74.22%] [G loss: 0.568833]\n",
      "epoch:6 step:6365 [D loss: 0.481676, acc.: 75.00%] [G loss: 0.685593]\n",
      "epoch:6 step:6366 [D loss: 0.577147, acc.: 75.78%] [G loss: 0.562503]\n",
      "epoch:6 step:6367 [D loss: 0.633711, acc.: 60.16%] [G loss: 0.582788]\n",
      "epoch:6 step:6368 [D loss: 0.504516, acc.: 72.66%] [G loss: 0.762654]\n",
      "epoch:6 step:6369 [D loss: 0.507506, acc.: 77.34%] [G loss: 0.681047]\n",
      "epoch:6 step:6370 [D loss: 0.544364, acc.: 70.31%] [G loss: 0.552923]\n",
      "epoch:6 step:6371 [D loss: 0.528304, acc.: 71.88%] [G loss: 0.581281]\n",
      "epoch:6 step:6372 [D loss: 0.564703, acc.: 73.44%] [G loss: 0.628522]\n",
      "epoch:6 step:6373 [D loss: 0.518949, acc.: 76.56%] [G loss: 0.585585]\n",
      "epoch:6 step:6374 [D loss: 0.526341, acc.: 72.66%] [G loss: 0.587057]\n",
      "epoch:6 step:6375 [D loss: 0.519874, acc.: 75.78%] [G loss: 0.646201]\n",
      "epoch:6 step:6376 [D loss: 0.525506, acc.: 71.88%] [G loss: 0.686135]\n",
      "epoch:6 step:6377 [D loss: 0.495583, acc.: 69.53%] [G loss: 0.695211]\n",
      "epoch:6 step:6378 [D loss: 0.498849, acc.: 75.78%] [G loss: 0.633164]\n",
      "epoch:6 step:6379 [D loss: 0.552575, acc.: 66.41%] [G loss: 0.500700]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6380 [D loss: 0.570357, acc.: 67.19%] [G loss: 0.746745]\n",
      "epoch:6 step:6381 [D loss: 0.570632, acc.: 70.31%] [G loss: 0.561158]\n",
      "epoch:6 step:6382 [D loss: 0.543458, acc.: 74.22%] [G loss: 0.557832]\n",
      "epoch:6 step:6383 [D loss: 0.544817, acc.: 66.41%] [G loss: 0.637859]\n",
      "epoch:6 step:6384 [D loss: 0.586591, acc.: 67.97%] [G loss: 0.604166]\n",
      "epoch:6 step:6385 [D loss: 0.552862, acc.: 70.31%] [G loss: 0.484923]\n",
      "epoch:6 step:6386 [D loss: 0.533504, acc.: 71.09%] [G loss: 0.643973]\n",
      "epoch:6 step:6387 [D loss: 0.645532, acc.: 63.28%] [G loss: 0.583596]\n",
      "epoch:6 step:6388 [D loss: 0.673851, acc.: 64.84%] [G loss: 0.413408]\n",
      "epoch:6 step:6389 [D loss: 0.610516, acc.: 66.41%] [G loss: 0.376145]\n",
      "epoch:6 step:6390 [D loss: 0.546975, acc.: 71.09%] [G loss: 0.507100]\n",
      "epoch:6 step:6391 [D loss: 0.462194, acc.: 80.47%] [G loss: 0.699165]\n",
      "epoch:6 step:6392 [D loss: 0.571974, acc.: 70.31%] [G loss: 0.815655]\n",
      "epoch:6 step:6393 [D loss: 0.487325, acc.: 76.56%] [G loss: 0.638011]\n",
      "epoch:6 step:6394 [D loss: 0.572521, acc.: 67.97%] [G loss: 0.434106]\n",
      "epoch:6 step:6395 [D loss: 0.544196, acc.: 71.88%] [G loss: 0.505778]\n",
      "epoch:6 step:6396 [D loss: 0.605965, acc.: 65.62%] [G loss: 0.529300]\n",
      "epoch:6 step:6397 [D loss: 0.518732, acc.: 71.88%] [G loss: 0.538915]\n",
      "epoch:6 step:6398 [D loss: 0.601420, acc.: 66.41%] [G loss: 0.533006]\n",
      "epoch:6 step:6399 [D loss: 0.559937, acc.: 70.31%] [G loss: 0.628512]\n",
      "epoch:6 step:6400 [D loss: 0.568590, acc.: 68.75%] [G loss: 0.641008]\n",
      "##############\n",
      "[3.07839401 1.30109326 6.53351491 5.05971921 3.9762323  5.94383205\n",
      " 4.82536616 4.84387712 4.71681533 4.02199712]\n",
      "##########\n",
      "epoch:6 step:6401 [D loss: 0.602369, acc.: 67.19%] [G loss: 0.456710]\n",
      "epoch:6 step:6402 [D loss: 0.539094, acc.: 71.88%] [G loss: 0.628618]\n",
      "epoch:6 step:6403 [D loss: 0.542018, acc.: 70.31%] [G loss: 0.689077]\n",
      "epoch:6 step:6404 [D loss: 0.539612, acc.: 69.53%] [G loss: 0.885062]\n",
      "epoch:6 step:6405 [D loss: 0.599316, acc.: 68.75%] [G loss: 0.525974]\n",
      "epoch:6 step:6406 [D loss: 0.616341, acc.: 64.06%] [G loss: 0.571910]\n",
      "epoch:6 step:6407 [D loss: 0.573046, acc.: 71.09%] [G loss: 0.511404]\n",
      "epoch:6 step:6408 [D loss: 0.523759, acc.: 71.88%] [G loss: 0.568587]\n",
      "epoch:6 step:6409 [D loss: 0.546531, acc.: 71.09%] [G loss: 0.446832]\n",
      "epoch:6 step:6410 [D loss: 0.623076, acc.: 67.19%] [G loss: 0.528204]\n",
      "epoch:6 step:6411 [D loss: 0.514293, acc.: 73.44%] [G loss: 0.486756]\n",
      "epoch:6 step:6412 [D loss: 0.556970, acc.: 71.09%] [G loss: 0.490152]\n",
      "epoch:6 step:6413 [D loss: 0.575186, acc.: 72.66%] [G loss: 0.539872]\n",
      "epoch:6 step:6414 [D loss: 0.453847, acc.: 81.25%] [G loss: 0.570121]\n",
      "epoch:6 step:6415 [D loss: 0.559776, acc.: 72.66%] [G loss: 0.604834]\n",
      "epoch:6 step:6416 [D loss: 0.631732, acc.: 64.84%] [G loss: 0.562929]\n",
      "epoch:6 step:6417 [D loss: 0.512705, acc.: 74.22%] [G loss: 0.588555]\n",
      "epoch:6 step:6418 [D loss: 0.503536, acc.: 75.00%] [G loss: 0.652735]\n",
      "epoch:6 step:6419 [D loss: 0.568730, acc.: 66.41%] [G loss: 0.625757]\n",
      "epoch:6 step:6420 [D loss: 0.478509, acc.: 73.44%] [G loss: 0.786422]\n",
      "epoch:6 step:6421 [D loss: 0.572422, acc.: 65.62%] [G loss: 0.533899]\n",
      "epoch:6 step:6422 [D loss: 0.587642, acc.: 69.53%] [G loss: 0.608907]\n",
      "epoch:6 step:6423 [D loss: 0.554919, acc.: 71.88%] [G loss: 0.586304]\n",
      "epoch:6 step:6424 [D loss: 0.504047, acc.: 71.88%] [G loss: 0.703604]\n",
      "epoch:6 step:6425 [D loss: 0.478634, acc.: 80.47%] [G loss: 0.750550]\n",
      "epoch:6 step:6426 [D loss: 0.520420, acc.: 74.22%] [G loss: 0.671548]\n",
      "epoch:6 step:6427 [D loss: 0.494375, acc.: 73.44%] [G loss: 0.587807]\n",
      "epoch:6 step:6428 [D loss: 0.509753, acc.: 69.53%] [G loss: 0.565967]\n",
      "epoch:6 step:6429 [D loss: 0.520000, acc.: 74.22%] [G loss: 0.738211]\n",
      "epoch:6 step:6430 [D loss: 0.562355, acc.: 71.09%] [G loss: 0.605153]\n",
      "epoch:6 step:6431 [D loss: 0.567765, acc.: 69.53%] [G loss: 0.466570]\n",
      "epoch:6 step:6432 [D loss: 0.531448, acc.: 72.66%] [G loss: 0.551796]\n",
      "epoch:6 step:6433 [D loss: 0.537518, acc.: 75.78%] [G loss: 0.518450]\n",
      "epoch:6 step:6434 [D loss: 0.641897, acc.: 63.28%] [G loss: 0.360832]\n",
      "epoch:6 step:6435 [D loss: 0.551383, acc.: 71.09%] [G loss: 0.452535]\n",
      "epoch:6 step:6436 [D loss: 0.534957, acc.: 73.44%] [G loss: 0.420319]\n",
      "epoch:6 step:6437 [D loss: 0.530474, acc.: 75.00%] [G loss: 0.642485]\n",
      "epoch:6 step:6438 [D loss: 0.519622, acc.: 71.09%] [G loss: 0.597428]\n",
      "epoch:6 step:6439 [D loss: 0.611195, acc.: 67.19%] [G loss: 0.552555]\n",
      "epoch:6 step:6440 [D loss: 0.610705, acc.: 64.84%] [G loss: 0.525425]\n",
      "epoch:6 step:6441 [D loss: 0.522912, acc.: 75.00%] [G loss: 0.550243]\n",
      "epoch:6 step:6442 [D loss: 0.625104, acc.: 62.50%] [G loss: 0.422075]\n",
      "epoch:6 step:6443 [D loss: 0.599733, acc.: 61.72%] [G loss: 0.465178]\n",
      "epoch:6 step:6444 [D loss: 0.535161, acc.: 68.75%] [G loss: 0.377963]\n",
      "epoch:6 step:6445 [D loss: 0.477364, acc.: 73.44%] [G loss: 0.552384]\n",
      "epoch:6 step:6446 [D loss: 0.581453, acc.: 75.78%] [G loss: 0.579574]\n",
      "epoch:6 step:6447 [D loss: 0.581479, acc.: 71.88%] [G loss: 0.557336]\n",
      "epoch:6 step:6448 [D loss: 0.546809, acc.: 75.78%] [G loss: 0.415637]\n",
      "epoch:6 step:6449 [D loss: 0.589059, acc.: 67.19%] [G loss: 0.359720]\n",
      "epoch:6 step:6450 [D loss: 0.615247, acc.: 66.41%] [G loss: 0.418107]\n",
      "epoch:6 step:6451 [D loss: 0.519692, acc.: 73.44%] [G loss: 0.566961]\n",
      "epoch:6 step:6452 [D loss: 0.613055, acc.: 62.50%] [G loss: 0.443960]\n",
      "epoch:6 step:6453 [D loss: 0.489979, acc.: 80.47%] [G loss: 0.611858]\n",
      "epoch:6 step:6454 [D loss: 0.550043, acc.: 71.88%] [G loss: 0.569368]\n",
      "epoch:6 step:6455 [D loss: 0.499086, acc.: 78.12%] [G loss: 0.442215]\n",
      "epoch:6 step:6456 [D loss: 0.485601, acc.: 76.56%] [G loss: 0.609792]\n",
      "epoch:6 step:6457 [D loss: 0.526071, acc.: 73.44%] [G loss: 0.491343]\n",
      "epoch:6 step:6458 [D loss: 0.528150, acc.: 75.78%] [G loss: 0.531189]\n",
      "epoch:6 step:6459 [D loss: 0.537657, acc.: 68.75%] [G loss: 0.541551]\n",
      "epoch:6 step:6460 [D loss: 0.511314, acc.: 76.56%] [G loss: 0.593006]\n",
      "epoch:6 step:6461 [D loss: 0.547435, acc.: 71.88%] [G loss: 0.543892]\n",
      "epoch:6 step:6462 [D loss: 0.633851, acc.: 63.28%] [G loss: 0.365595]\n",
      "epoch:6 step:6463 [D loss: 0.497531, acc.: 75.78%] [G loss: 0.499982]\n",
      "epoch:6 step:6464 [D loss: 0.521771, acc.: 79.69%] [G loss: 0.421806]\n",
      "epoch:6 step:6465 [D loss: 0.507039, acc.: 73.44%] [G loss: 0.455254]\n",
      "epoch:6 step:6466 [D loss: 0.611880, acc.: 71.09%] [G loss: 0.460638]\n",
      "epoch:6 step:6467 [D loss: 0.612531, acc.: 62.50%] [G loss: 0.485801]\n",
      "epoch:6 step:6468 [D loss: 0.569147, acc.: 64.06%] [G loss: 0.587054]\n",
      "epoch:6 step:6469 [D loss: 0.597676, acc.: 63.28%] [G loss: 0.387616]\n",
      "epoch:6 step:6470 [D loss: 0.508890, acc.: 74.22%] [G loss: 0.382800]\n",
      "epoch:6 step:6471 [D loss: 0.563507, acc.: 72.66%] [G loss: 0.479191]\n",
      "epoch:6 step:6472 [D loss: 0.567604, acc.: 67.97%] [G loss: 0.450483]\n",
      "epoch:6 step:6473 [D loss: 0.561897, acc.: 68.75%] [G loss: 0.616821]\n",
      "epoch:6 step:6474 [D loss: 0.512956, acc.: 77.34%] [G loss: 0.530059]\n",
      "epoch:6 step:6475 [D loss: 0.548113, acc.: 68.75%] [G loss: 0.598820]\n",
      "epoch:6 step:6476 [D loss: 0.546873, acc.: 69.53%] [G loss: 0.626928]\n",
      "epoch:6 step:6477 [D loss: 0.584328, acc.: 67.97%] [G loss: 0.603195]\n",
      "epoch:6 step:6478 [D loss: 0.594870, acc.: 65.62%] [G loss: 0.605953]\n",
      "epoch:6 step:6479 [D loss: 0.476326, acc.: 78.91%] [G loss: 0.503468]\n",
      "epoch:6 step:6480 [D loss: 0.667486, acc.: 56.25%] [G loss: 0.506550]\n",
      "epoch:6 step:6481 [D loss: 0.576280, acc.: 67.97%] [G loss: 0.507702]\n",
      "epoch:6 step:6482 [D loss: 0.485054, acc.: 78.91%] [G loss: 0.602572]\n",
      "epoch:6 step:6483 [D loss: 0.652518, acc.: 57.81%] [G loss: 0.607746]\n",
      "epoch:6 step:6484 [D loss: 0.596343, acc.: 67.97%] [G loss: 0.490936]\n",
      "epoch:6 step:6485 [D loss: 0.580242, acc.: 67.19%] [G loss: 0.445441]\n",
      "epoch:6 step:6486 [D loss: 0.560931, acc.: 67.97%] [G loss: 0.389801]\n",
      "epoch:6 step:6487 [D loss: 0.566240, acc.: 71.09%] [G loss: 0.459874]\n",
      "epoch:6 step:6488 [D loss: 0.550252, acc.: 66.41%] [G loss: 0.499374]\n",
      "epoch:6 step:6489 [D loss: 0.642921, acc.: 63.28%] [G loss: 0.458718]\n",
      "epoch:6 step:6490 [D loss: 0.560040, acc.: 67.97%] [G loss: 0.490869]\n",
      "epoch:6 step:6491 [D loss: 0.574063, acc.: 68.75%] [G loss: 0.491750]\n",
      "epoch:6 step:6492 [D loss: 0.453606, acc.: 80.47%] [G loss: 0.510468]\n",
      "epoch:6 step:6493 [D loss: 0.536599, acc.: 69.53%] [G loss: 0.423634]\n",
      "epoch:6 step:6494 [D loss: 0.542620, acc.: 70.31%] [G loss: 0.472959]\n",
      "epoch:6 step:6495 [D loss: 0.566534, acc.: 71.09%] [G loss: 0.408227]\n",
      "epoch:6 step:6496 [D loss: 0.557526, acc.: 69.53%] [G loss: 0.536759]\n",
      "epoch:6 step:6497 [D loss: 0.502878, acc.: 79.69%] [G loss: 0.538446]\n",
      "epoch:6 step:6498 [D loss: 0.581056, acc.: 71.09%] [G loss: 0.520543]\n",
      "epoch:6 step:6499 [D loss: 0.557283, acc.: 73.44%] [G loss: 0.488271]\n",
      "epoch:6 step:6500 [D loss: 0.564540, acc.: 64.84%] [G loss: 0.472278]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6501 [D loss: 0.571226, acc.: 64.06%] [G loss: 0.579788]\n",
      "epoch:6 step:6502 [D loss: 0.626646, acc.: 63.28%] [G loss: 0.440793]\n",
      "epoch:6 step:6503 [D loss: 0.560116, acc.: 69.53%] [G loss: 0.491394]\n",
      "epoch:6 step:6504 [D loss: 0.614851, acc.: 67.19%] [G loss: 0.405481]\n",
      "epoch:6 step:6505 [D loss: 0.597273, acc.: 64.06%] [G loss: 0.467907]\n",
      "epoch:6 step:6506 [D loss: 0.458200, acc.: 81.25%] [G loss: 0.579467]\n",
      "epoch:6 step:6507 [D loss: 0.591295, acc.: 66.41%] [G loss: 0.599964]\n",
      "epoch:6 step:6508 [D loss: 0.537307, acc.: 71.09%] [G loss: 0.544198]\n",
      "epoch:6 step:6509 [D loss: 0.538672, acc.: 72.66%] [G loss: 0.618116]\n",
      "epoch:6 step:6510 [D loss: 0.525797, acc.: 72.66%] [G loss: 0.610969]\n",
      "epoch:6 step:6511 [D loss: 0.536177, acc.: 70.31%] [G loss: 0.563637]\n",
      "epoch:6 step:6512 [D loss: 0.459342, acc.: 81.25%] [G loss: 0.644487]\n",
      "epoch:6 step:6513 [D loss: 0.600233, acc.: 67.97%] [G loss: 0.506270]\n",
      "epoch:6 step:6514 [D loss: 0.615025, acc.: 65.62%] [G loss: 0.491578]\n",
      "epoch:6 step:6515 [D loss: 0.533098, acc.: 78.12%] [G loss: 0.556402]\n",
      "epoch:6 step:6516 [D loss: 0.527739, acc.: 71.88%] [G loss: 0.519320]\n",
      "epoch:6 step:6517 [D loss: 0.535395, acc.: 75.78%] [G loss: 0.694750]\n",
      "epoch:6 step:6518 [D loss: 0.562531, acc.: 71.88%] [G loss: 0.585049]\n",
      "epoch:6 step:6519 [D loss: 0.476335, acc.: 79.69%] [G loss: 0.592537]\n",
      "epoch:6 step:6520 [D loss: 0.490691, acc.: 75.00%] [G loss: 0.672148]\n",
      "epoch:6 step:6521 [D loss: 0.534888, acc.: 68.75%] [G loss: 0.542216]\n",
      "epoch:6 step:6522 [D loss: 0.543918, acc.: 71.88%] [G loss: 0.783193]\n",
      "epoch:6 step:6523 [D loss: 0.549902, acc.: 73.44%] [G loss: 0.554507]\n",
      "epoch:6 step:6524 [D loss: 0.616807, acc.: 63.28%] [G loss: 0.462618]\n",
      "epoch:6 step:6525 [D loss: 0.577409, acc.: 69.53%] [G loss: 0.469174]\n",
      "epoch:6 step:6526 [D loss: 0.577237, acc.: 69.53%] [G loss: 0.439567]\n",
      "epoch:6 step:6527 [D loss: 0.552335, acc.: 74.22%] [G loss: 0.631595]\n",
      "epoch:6 step:6528 [D loss: 0.524721, acc.: 71.88%] [G loss: 0.675442]\n",
      "epoch:6 step:6529 [D loss: 0.571034, acc.: 71.88%] [G loss: 0.503264]\n",
      "epoch:6 step:6530 [D loss: 0.508242, acc.: 75.00%] [G loss: 0.724344]\n",
      "epoch:6 step:6531 [D loss: 0.542548, acc.: 72.66%] [G loss: 0.594805]\n",
      "epoch:6 step:6532 [D loss: 0.491334, acc.: 77.34%] [G loss: 0.674588]\n",
      "epoch:6 step:6533 [D loss: 0.491584, acc.: 82.03%] [G loss: 0.771307]\n",
      "epoch:6 step:6534 [D loss: 0.498822, acc.: 73.44%] [G loss: 0.760209]\n",
      "epoch:6 step:6535 [D loss: 0.561969, acc.: 72.66%] [G loss: 0.774919]\n",
      "epoch:6 step:6536 [D loss: 0.503022, acc.: 74.22%] [G loss: 0.737809]\n",
      "epoch:6 step:6537 [D loss: 0.609234, acc.: 64.84%] [G loss: 0.493249]\n",
      "epoch:6 step:6538 [D loss: 0.535626, acc.: 78.12%] [G loss: 0.576634]\n",
      "epoch:6 step:6539 [D loss: 0.553928, acc.: 68.75%] [G loss: 0.681638]\n",
      "epoch:6 step:6540 [D loss: 0.491823, acc.: 75.78%] [G loss: 0.634727]\n",
      "epoch:6 step:6541 [D loss: 0.469419, acc.: 77.34%] [G loss: 0.863693]\n",
      "epoch:6 step:6542 [D loss: 0.710287, acc.: 56.25%] [G loss: 0.637156]\n",
      "epoch:6 step:6543 [D loss: 0.451975, acc.: 77.34%] [G loss: 0.788883]\n",
      "epoch:6 step:6544 [D loss: 0.623531, acc.: 64.84%] [G loss: 0.557628]\n",
      "epoch:6 step:6545 [D loss: 0.506681, acc.: 72.66%] [G loss: 0.605502]\n",
      "epoch:6 step:6546 [D loss: 0.473416, acc.: 74.22%] [G loss: 0.798481]\n",
      "epoch:6 step:6547 [D loss: 0.433544, acc.: 77.34%] [G loss: 0.789866]\n",
      "epoch:6 step:6548 [D loss: 0.422250, acc.: 82.81%] [G loss: 0.844573]\n",
      "epoch:6 step:6549 [D loss: 0.470266, acc.: 75.00%] [G loss: 0.989826]\n",
      "epoch:6 step:6550 [D loss: 0.620470, acc.: 67.97%] [G loss: 0.824645]\n",
      "epoch:6 step:6551 [D loss: 0.550238, acc.: 71.88%] [G loss: 0.881666]\n",
      "epoch:6 step:6552 [D loss: 0.450028, acc.: 78.91%] [G loss: 0.859409]\n",
      "epoch:6 step:6553 [D loss: 0.548766, acc.: 73.44%] [G loss: 0.810570]\n",
      "epoch:6 step:6554 [D loss: 0.562664, acc.: 71.09%] [G loss: 0.674863]\n",
      "epoch:6 step:6555 [D loss: 0.519463, acc.: 75.00%] [G loss: 0.743677]\n",
      "epoch:6 step:6556 [D loss: 0.531496, acc.: 74.22%] [G loss: 0.712343]\n",
      "epoch:6 step:6557 [D loss: 0.490975, acc.: 74.22%] [G loss: 0.850692]\n",
      "epoch:6 step:6558 [D loss: 0.379754, acc.: 79.69%] [G loss: 1.108685]\n",
      "epoch:6 step:6559 [D loss: 0.517890, acc.: 72.66%] [G loss: 1.164796]\n",
      "epoch:7 step:6560 [D loss: 0.570744, acc.: 75.00%] [G loss: 0.876078]\n",
      "epoch:7 step:6561 [D loss: 0.485996, acc.: 78.91%] [G loss: 0.836104]\n",
      "epoch:7 step:6562 [D loss: 0.641365, acc.: 64.84%] [G loss: 0.776399]\n",
      "epoch:7 step:6563 [D loss: 0.469199, acc.: 78.91%] [G loss: 0.788508]\n",
      "epoch:7 step:6564 [D loss: 0.552957, acc.: 71.09%] [G loss: 0.578941]\n",
      "epoch:7 step:6565 [D loss: 0.581006, acc.: 70.31%] [G loss: 0.546990]\n",
      "epoch:7 step:6566 [D loss: 0.489676, acc.: 76.56%] [G loss: 0.661093]\n",
      "epoch:7 step:6567 [D loss: 0.529547, acc.: 72.66%] [G loss: 0.652246]\n",
      "epoch:7 step:6568 [D loss: 0.475797, acc.: 74.22%] [G loss: 0.765979]\n",
      "epoch:7 step:6569 [D loss: 0.533880, acc.: 74.22%] [G loss: 0.561340]\n",
      "epoch:7 step:6570 [D loss: 0.523983, acc.: 72.66%] [G loss: 0.714892]\n",
      "epoch:7 step:6571 [D loss: 0.576058, acc.: 67.97%] [G loss: 0.584051]\n",
      "epoch:7 step:6572 [D loss: 0.565609, acc.: 67.19%] [G loss: 0.614830]\n",
      "epoch:7 step:6573 [D loss: 0.578480, acc.: 67.97%] [G loss: 0.615511]\n",
      "epoch:7 step:6574 [D loss: 0.495463, acc.: 80.47%] [G loss: 0.567885]\n",
      "epoch:7 step:6575 [D loss: 0.489028, acc.: 74.22%] [G loss: 0.592973]\n",
      "epoch:7 step:6576 [D loss: 0.542328, acc.: 71.09%] [G loss: 0.574402]\n",
      "epoch:7 step:6577 [D loss: 0.642595, acc.: 57.81%] [G loss: 0.505052]\n",
      "epoch:7 step:6578 [D loss: 0.538628, acc.: 71.88%] [G loss: 0.532226]\n",
      "epoch:7 step:6579 [D loss: 0.628494, acc.: 64.06%] [G loss: 0.519863]\n",
      "epoch:7 step:6580 [D loss: 0.546446, acc.: 71.09%] [G loss: 0.700682]\n",
      "epoch:7 step:6581 [D loss: 0.452829, acc.: 82.81%] [G loss: 0.782105]\n",
      "epoch:7 step:6582 [D loss: 0.545352, acc.: 74.22%] [G loss: 0.599063]\n",
      "epoch:7 step:6583 [D loss: 0.544976, acc.: 71.09%] [G loss: 0.471483]\n",
      "epoch:7 step:6584 [D loss: 0.512785, acc.: 75.00%] [G loss: 0.653902]\n",
      "epoch:7 step:6585 [D loss: 0.599165, acc.: 66.41%] [G loss: 0.475305]\n",
      "epoch:7 step:6586 [D loss: 0.500500, acc.: 76.56%] [G loss: 0.478161]\n",
      "epoch:7 step:6587 [D loss: 0.528282, acc.: 70.31%] [G loss: 0.607070]\n",
      "epoch:7 step:6588 [D loss: 0.505027, acc.: 79.69%] [G loss: 0.584549]\n",
      "epoch:7 step:6589 [D loss: 0.604743, acc.: 66.41%] [G loss: 0.671549]\n",
      "epoch:7 step:6590 [D loss: 0.573773, acc.: 69.53%] [G loss: 0.580283]\n",
      "epoch:7 step:6591 [D loss: 0.518937, acc.: 71.88%] [G loss: 0.585853]\n",
      "epoch:7 step:6592 [D loss: 0.572523, acc.: 70.31%] [G loss: 0.583206]\n",
      "epoch:7 step:6593 [D loss: 0.533452, acc.: 65.62%] [G loss: 0.623131]\n",
      "epoch:7 step:6594 [D loss: 0.511959, acc.: 72.66%] [G loss: 0.730899]\n",
      "epoch:7 step:6595 [D loss: 0.468191, acc.: 79.69%] [G loss: 0.650254]\n",
      "epoch:7 step:6596 [D loss: 0.535207, acc.: 74.22%] [G loss: 0.647369]\n",
      "epoch:7 step:6597 [D loss: 0.645028, acc.: 61.72%] [G loss: 0.604489]\n",
      "epoch:7 step:6598 [D loss: 0.536009, acc.: 71.88%] [G loss: 0.488999]\n",
      "epoch:7 step:6599 [D loss: 0.469747, acc.: 80.47%] [G loss: 0.641247]\n",
      "epoch:7 step:6600 [D loss: 0.543531, acc.: 75.00%] [G loss: 0.610471]\n",
      "##############\n",
      "[3.20435636 1.5941565  6.62789937 4.98706894 3.95241674 6.03635962\n",
      " 5.00428242 5.00693323 4.63092053 3.84860108]\n",
      "##########\n",
      "epoch:7 step:6601 [D loss: 0.538733, acc.: 73.44%] [G loss: 0.606406]\n",
      "epoch:7 step:6602 [D loss: 0.530918, acc.: 75.00%] [G loss: 0.589382]\n",
      "epoch:7 step:6603 [D loss: 0.645473, acc.: 65.62%] [G loss: 0.438102]\n",
      "epoch:7 step:6604 [D loss: 0.554673, acc.: 67.19%] [G loss: 0.590082]\n",
      "epoch:7 step:6605 [D loss: 0.496036, acc.: 71.88%] [G loss: 0.517895]\n",
      "epoch:7 step:6606 [D loss: 0.539561, acc.: 74.22%] [G loss: 0.634432]\n",
      "epoch:7 step:6607 [D loss: 0.559226, acc.: 71.09%] [G loss: 0.437380]\n",
      "epoch:7 step:6608 [D loss: 0.495926, acc.: 73.44%] [G loss: 0.764563]\n",
      "epoch:7 step:6609 [D loss: 0.526065, acc.: 74.22%] [G loss: 0.657199]\n",
      "epoch:7 step:6610 [D loss: 0.619247, acc.: 67.97%] [G loss: 0.529873]\n",
      "epoch:7 step:6611 [D loss: 0.564330, acc.: 67.97%] [G loss: 0.478489]\n",
      "epoch:7 step:6612 [D loss: 0.495207, acc.: 78.12%] [G loss: 0.570021]\n",
      "epoch:7 step:6613 [D loss: 0.448587, acc.: 82.03%] [G loss: 0.673453]\n",
      "epoch:7 step:6614 [D loss: 0.518867, acc.: 74.22%] [G loss: 0.712504]\n",
      "epoch:7 step:6615 [D loss: 0.497183, acc.: 76.56%] [G loss: 0.580490]\n",
      "epoch:7 step:6616 [D loss: 0.529072, acc.: 72.66%] [G loss: 0.597936]\n",
      "epoch:7 step:6617 [D loss: 0.549502, acc.: 65.62%] [G loss: 0.575411]\n",
      "epoch:7 step:6618 [D loss: 0.484351, acc.: 77.34%] [G loss: 0.589034]\n",
      "epoch:7 step:6619 [D loss: 0.533677, acc.: 73.44%] [G loss: 0.682983]\n",
      "epoch:7 step:6620 [D loss: 0.547235, acc.: 70.31%] [G loss: 0.662110]\n",
      "epoch:7 step:6621 [D loss: 0.542131, acc.: 72.66%] [G loss: 0.549819]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6622 [D loss: 0.535815, acc.: 70.31%] [G loss: 0.561604]\n",
      "epoch:7 step:6623 [D loss: 0.547569, acc.: 65.62%] [G loss: 0.607505]\n",
      "epoch:7 step:6624 [D loss: 0.581844, acc.: 69.53%] [G loss: 0.678275]\n",
      "epoch:7 step:6625 [D loss: 0.509087, acc.: 75.00%] [G loss: 0.678628]\n",
      "epoch:7 step:6626 [D loss: 0.603633, acc.: 67.97%] [G loss: 0.383697]\n",
      "epoch:7 step:6627 [D loss: 0.560838, acc.: 67.19%] [G loss: 0.474230]\n",
      "epoch:7 step:6628 [D loss: 0.508353, acc.: 77.34%] [G loss: 0.540104]\n",
      "epoch:7 step:6629 [D loss: 0.511896, acc.: 72.66%] [G loss: 0.550888]\n",
      "epoch:7 step:6630 [D loss: 0.499047, acc.: 70.31%] [G loss: 0.701860]\n",
      "epoch:7 step:6631 [D loss: 0.514229, acc.: 72.66%] [G loss: 0.542612]\n",
      "epoch:7 step:6632 [D loss: 0.554986, acc.: 68.75%] [G loss: 0.482174]\n",
      "epoch:7 step:6633 [D loss: 0.531405, acc.: 69.53%] [G loss: 0.528984]\n",
      "epoch:7 step:6634 [D loss: 0.602672, acc.: 68.75%] [G loss: 0.613700]\n",
      "epoch:7 step:6635 [D loss: 0.511570, acc.: 72.66%] [G loss: 0.644477]\n",
      "epoch:7 step:6636 [D loss: 0.439470, acc.: 78.91%] [G loss: 0.938600]\n",
      "epoch:7 step:6637 [D loss: 0.590527, acc.: 73.44%] [G loss: 0.526032]\n",
      "epoch:7 step:6638 [D loss: 0.560396, acc.: 73.44%] [G loss: 0.576517]\n",
      "epoch:7 step:6639 [D loss: 0.599883, acc.: 63.28%] [G loss: 0.505147]\n",
      "epoch:7 step:6640 [D loss: 0.575713, acc.: 63.28%] [G loss: 0.597646]\n",
      "epoch:7 step:6641 [D loss: 0.556554, acc.: 73.44%] [G loss: 0.558463]\n",
      "epoch:7 step:6642 [D loss: 0.550986, acc.: 75.00%] [G loss: 0.533875]\n",
      "epoch:7 step:6643 [D loss: 0.529044, acc.: 70.31%] [G loss: 0.465318]\n",
      "epoch:7 step:6644 [D loss: 0.531286, acc.: 75.00%] [G loss: 0.493435]\n",
      "epoch:7 step:6645 [D loss: 0.566674, acc.: 71.09%] [G loss: 0.350010]\n",
      "epoch:7 step:6646 [D loss: 0.540682, acc.: 69.53%] [G loss: 0.479488]\n",
      "epoch:7 step:6647 [D loss: 0.497386, acc.: 76.56%] [G loss: 0.588200]\n",
      "epoch:7 step:6648 [D loss: 0.454039, acc.: 75.78%] [G loss: 0.639202]\n",
      "epoch:7 step:6649 [D loss: 0.550690, acc.: 70.31%] [G loss: 0.575948]\n",
      "epoch:7 step:6650 [D loss: 0.583447, acc.: 69.53%] [G loss: 0.513504]\n",
      "epoch:7 step:6651 [D loss: 0.472155, acc.: 75.78%] [G loss: 0.566648]\n",
      "epoch:7 step:6652 [D loss: 0.519289, acc.: 76.56%] [G loss: 0.698517]\n",
      "epoch:7 step:6653 [D loss: 0.525824, acc.: 76.56%] [G loss: 0.526624]\n",
      "epoch:7 step:6654 [D loss: 0.566935, acc.: 71.09%] [G loss: 0.592098]\n",
      "epoch:7 step:6655 [D loss: 0.507121, acc.: 74.22%] [G loss: 0.621783]\n",
      "epoch:7 step:6656 [D loss: 0.512885, acc.: 74.22%] [G loss: 0.698687]\n",
      "epoch:7 step:6657 [D loss: 0.565997, acc.: 68.75%] [G loss: 0.616010]\n",
      "epoch:7 step:6658 [D loss: 0.502439, acc.: 71.09%] [G loss: 0.758928]\n",
      "epoch:7 step:6659 [D loss: 0.537856, acc.: 71.09%] [G loss: 0.577991]\n",
      "epoch:7 step:6660 [D loss: 0.495177, acc.: 75.00%] [G loss: 0.658549]\n",
      "epoch:7 step:6661 [D loss: 0.626453, acc.: 63.28%] [G loss: 0.536979]\n",
      "epoch:7 step:6662 [D loss: 0.501645, acc.: 69.53%] [G loss: 0.479816]\n",
      "epoch:7 step:6663 [D loss: 0.507756, acc.: 67.97%] [G loss: 0.612281]\n",
      "epoch:7 step:6664 [D loss: 0.552870, acc.: 68.75%] [G loss: 0.518417]\n",
      "epoch:7 step:6665 [D loss: 0.553442, acc.: 74.22%] [G loss: 0.664623]\n",
      "epoch:7 step:6666 [D loss: 0.585813, acc.: 64.84%] [G loss: 0.510911]\n",
      "epoch:7 step:6667 [D loss: 0.602692, acc.: 68.75%] [G loss: 0.456700]\n",
      "epoch:7 step:6668 [D loss: 0.568628, acc.: 64.84%] [G loss: 0.474247]\n",
      "epoch:7 step:6669 [D loss: 0.559927, acc.: 69.53%] [G loss: 0.545404]\n",
      "epoch:7 step:6670 [D loss: 0.520557, acc.: 72.66%] [G loss: 0.470546]\n",
      "epoch:7 step:6671 [D loss: 0.499793, acc.: 77.34%] [G loss: 0.521313]\n",
      "epoch:7 step:6672 [D loss: 0.589290, acc.: 68.75%] [G loss: 0.545234]\n",
      "epoch:7 step:6673 [D loss: 0.607821, acc.: 64.84%] [G loss: 0.534085]\n",
      "epoch:7 step:6674 [D loss: 0.555183, acc.: 72.66%] [G loss: 0.669716]\n",
      "epoch:7 step:6675 [D loss: 0.507054, acc.: 75.00%] [G loss: 0.628643]\n",
      "epoch:7 step:6676 [D loss: 0.510167, acc.: 71.09%] [G loss: 0.807534]\n",
      "epoch:7 step:6677 [D loss: 0.511711, acc.: 72.66%] [G loss: 0.844128]\n",
      "epoch:7 step:6678 [D loss: 0.424584, acc.: 85.16%] [G loss: 0.840106]\n",
      "epoch:7 step:6679 [D loss: 0.640291, acc.: 65.62%] [G loss: 0.673628]\n",
      "epoch:7 step:6680 [D loss: 0.581197, acc.: 68.75%] [G loss: 0.594798]\n",
      "epoch:7 step:6681 [D loss: 0.534551, acc.: 78.91%] [G loss: 0.614337]\n",
      "epoch:7 step:6682 [D loss: 0.507382, acc.: 75.78%] [G loss: 0.652991]\n",
      "epoch:7 step:6683 [D loss: 0.619394, acc.: 66.41%] [G loss: 0.497124]\n",
      "epoch:7 step:6684 [D loss: 0.611367, acc.: 64.06%] [G loss: 0.562458]\n",
      "epoch:7 step:6685 [D loss: 0.565837, acc.: 68.75%] [G loss: 0.477131]\n",
      "epoch:7 step:6686 [D loss: 0.553706, acc.: 69.53%] [G loss: 0.595669]\n",
      "epoch:7 step:6687 [D loss: 0.492451, acc.: 76.56%] [G loss: 0.478671]\n",
      "epoch:7 step:6688 [D loss: 0.564444, acc.: 74.22%] [G loss: 0.589556]\n",
      "epoch:7 step:6689 [D loss: 0.528648, acc.: 75.00%] [G loss: 0.554933]\n",
      "epoch:7 step:6690 [D loss: 0.543803, acc.: 71.09%] [G loss: 0.514497]\n",
      "epoch:7 step:6691 [D loss: 0.552607, acc.: 67.19%] [G loss: 0.575000]\n",
      "epoch:7 step:6692 [D loss: 0.553827, acc.: 74.22%] [G loss: 0.552029]\n",
      "epoch:7 step:6693 [D loss: 0.521910, acc.: 71.88%] [G loss: 0.547395]\n",
      "epoch:7 step:6694 [D loss: 0.523246, acc.: 74.22%] [G loss: 0.632775]\n",
      "epoch:7 step:6695 [D loss: 0.573033, acc.: 70.31%] [G loss: 0.562628]\n",
      "epoch:7 step:6696 [D loss: 0.583469, acc.: 68.75%] [G loss: 0.530949]\n",
      "epoch:7 step:6697 [D loss: 0.574541, acc.: 68.75%] [G loss: 0.506637]\n",
      "epoch:7 step:6698 [D loss: 0.577008, acc.: 71.88%] [G loss: 0.521376]\n",
      "epoch:7 step:6699 [D loss: 0.553508, acc.: 69.53%] [G loss: 0.693379]\n",
      "epoch:7 step:6700 [D loss: 0.475030, acc.: 75.78%] [G loss: 0.646427]\n",
      "epoch:7 step:6701 [D loss: 0.574970, acc.: 66.41%] [G loss: 0.418651]\n",
      "epoch:7 step:6702 [D loss: 0.612696, acc.: 59.38%] [G loss: 0.415426]\n",
      "epoch:7 step:6703 [D loss: 0.536497, acc.: 72.66%] [G loss: 0.549212]\n",
      "epoch:7 step:6704 [D loss: 0.549760, acc.: 67.19%] [G loss: 0.558705]\n",
      "epoch:7 step:6705 [D loss: 0.507844, acc.: 74.22%] [G loss: 0.771712]\n",
      "epoch:7 step:6706 [D loss: 0.597665, acc.: 65.62%] [G loss: 0.566129]\n",
      "epoch:7 step:6707 [D loss: 0.561896, acc.: 67.97%] [G loss: 0.599900]\n",
      "epoch:7 step:6708 [D loss: 0.498442, acc.: 75.78%] [G loss: 0.524279]\n",
      "epoch:7 step:6709 [D loss: 0.556642, acc.: 67.97%] [G loss: 0.600035]\n",
      "epoch:7 step:6710 [D loss: 0.591322, acc.: 65.62%] [G loss: 0.455868]\n",
      "epoch:7 step:6711 [D loss: 0.469271, acc.: 76.56%] [G loss: 0.640536]\n",
      "epoch:7 step:6712 [D loss: 0.603388, acc.: 69.53%] [G loss: 0.506909]\n",
      "epoch:7 step:6713 [D loss: 0.527375, acc.: 74.22%] [G loss: 0.584661]\n",
      "epoch:7 step:6714 [D loss: 0.442226, acc.: 77.34%] [G loss: 0.561820]\n",
      "epoch:7 step:6715 [D loss: 0.532371, acc.: 73.44%] [G loss: 0.632127]\n",
      "epoch:7 step:6716 [D loss: 0.593728, acc.: 64.06%] [G loss: 0.407129]\n",
      "epoch:7 step:6717 [D loss: 0.585433, acc.: 65.62%] [G loss: 0.464463]\n",
      "epoch:7 step:6718 [D loss: 0.563066, acc.: 68.75%] [G loss: 0.572118]\n",
      "epoch:7 step:6719 [D loss: 0.585018, acc.: 67.97%] [G loss: 0.514403]\n",
      "epoch:7 step:6720 [D loss: 0.559316, acc.: 69.53%] [G loss: 0.594422]\n",
      "epoch:7 step:6721 [D loss: 0.515734, acc.: 75.00%] [G loss: 0.567984]\n",
      "epoch:7 step:6722 [D loss: 0.506962, acc.: 76.56%] [G loss: 0.794262]\n",
      "epoch:7 step:6723 [D loss: 0.545619, acc.: 69.53%] [G loss: 0.684461]\n",
      "epoch:7 step:6724 [D loss: 0.491453, acc.: 72.66%] [G loss: 0.588512]\n",
      "epoch:7 step:6725 [D loss: 0.544531, acc.: 71.09%] [G loss: 0.516162]\n",
      "epoch:7 step:6726 [D loss: 0.545462, acc.: 72.66%] [G loss: 0.364205]\n",
      "epoch:7 step:6727 [D loss: 0.543721, acc.: 71.88%] [G loss: 0.571223]\n",
      "epoch:7 step:6728 [D loss: 0.571130, acc.: 68.75%] [G loss: 0.478406]\n",
      "epoch:7 step:6729 [D loss: 0.571348, acc.: 70.31%] [G loss: 0.543760]\n",
      "epoch:7 step:6730 [D loss: 0.497773, acc.: 72.66%] [G loss: 0.520030]\n",
      "epoch:7 step:6731 [D loss: 0.526273, acc.: 76.56%] [G loss: 0.618721]\n",
      "epoch:7 step:6732 [D loss: 0.525279, acc.: 73.44%] [G loss: 0.528015]\n",
      "epoch:7 step:6733 [D loss: 0.611440, acc.: 64.84%] [G loss: 0.469836]\n",
      "epoch:7 step:6734 [D loss: 0.546220, acc.: 73.44%] [G loss: 0.548271]\n",
      "epoch:7 step:6735 [D loss: 0.543853, acc.: 66.41%] [G loss: 0.468006]\n",
      "epoch:7 step:6736 [D loss: 0.514758, acc.: 75.00%] [G loss: 0.565056]\n",
      "epoch:7 step:6737 [D loss: 0.526307, acc.: 68.75%] [G loss: 0.546163]\n",
      "epoch:7 step:6738 [D loss: 0.515219, acc.: 74.22%] [G loss: 0.505307]\n",
      "epoch:7 step:6739 [D loss: 0.601866, acc.: 70.31%] [G loss: 0.536383]\n",
      "epoch:7 step:6740 [D loss: 0.624635, acc.: 62.50%] [G loss: 0.538409]\n",
      "epoch:7 step:6741 [D loss: 0.526058, acc.: 73.44%] [G loss: 0.754410]\n",
      "epoch:7 step:6742 [D loss: 0.590655, acc.: 65.62%] [G loss: 0.593998]\n",
      "epoch:7 step:6743 [D loss: 0.576711, acc.: 67.97%] [G loss: 0.503978]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6744 [D loss: 0.568028, acc.: 68.75%] [G loss: 0.595674]\n",
      "epoch:7 step:6745 [D loss: 0.556873, acc.: 70.31%] [G loss: 0.449530]\n",
      "epoch:7 step:6746 [D loss: 0.597623, acc.: 64.84%] [G loss: 0.689688]\n",
      "epoch:7 step:6747 [D loss: 0.626809, acc.: 61.72%] [G loss: 0.468960]\n",
      "epoch:7 step:6748 [D loss: 0.591986, acc.: 62.50%] [G loss: 0.484663]\n",
      "epoch:7 step:6749 [D loss: 0.502937, acc.: 77.34%] [G loss: 0.567401]\n",
      "epoch:7 step:6750 [D loss: 0.530713, acc.: 76.56%] [G loss: 0.579525]\n",
      "epoch:7 step:6751 [D loss: 0.568488, acc.: 71.09%] [G loss: 0.541061]\n",
      "epoch:7 step:6752 [D loss: 0.552681, acc.: 71.88%] [G loss: 0.452733]\n",
      "epoch:7 step:6753 [D loss: 0.475436, acc.: 81.25%] [G loss: 0.597277]\n",
      "epoch:7 step:6754 [D loss: 0.586271, acc.: 67.19%] [G loss: 0.630351]\n",
      "epoch:7 step:6755 [D loss: 0.590255, acc.: 71.09%] [G loss: 0.538555]\n",
      "epoch:7 step:6756 [D loss: 0.503409, acc.: 71.88%] [G loss: 0.570816]\n",
      "epoch:7 step:6757 [D loss: 0.530598, acc.: 71.88%] [G loss: 0.591006]\n",
      "epoch:7 step:6758 [D loss: 0.500184, acc.: 73.44%] [G loss: 0.781509]\n",
      "epoch:7 step:6759 [D loss: 0.617555, acc.: 61.72%] [G loss: 0.593070]\n",
      "epoch:7 step:6760 [D loss: 0.581778, acc.: 73.44%] [G loss: 0.596676]\n",
      "epoch:7 step:6761 [D loss: 0.587776, acc.: 70.31%] [G loss: 0.577948]\n",
      "epoch:7 step:6762 [D loss: 0.679181, acc.: 56.25%] [G loss: 0.462399]\n",
      "epoch:7 step:6763 [D loss: 0.567855, acc.: 67.97%] [G loss: 0.626960]\n",
      "epoch:7 step:6764 [D loss: 0.492837, acc.: 71.88%] [G loss: 0.700228]\n",
      "epoch:7 step:6765 [D loss: 0.493091, acc.: 74.22%] [G loss: 0.892625]\n",
      "epoch:7 step:6766 [D loss: 0.484505, acc.: 75.00%] [G loss: 0.704945]\n",
      "epoch:7 step:6767 [D loss: 0.465346, acc.: 78.12%] [G loss: 0.831013]\n",
      "epoch:7 step:6768 [D loss: 0.497970, acc.: 74.22%] [G loss: 0.733898]\n",
      "epoch:7 step:6769 [D loss: 0.633679, acc.: 67.19%] [G loss: 0.550403]\n",
      "epoch:7 step:6770 [D loss: 0.606215, acc.: 63.28%] [G loss: 0.481067]\n",
      "epoch:7 step:6771 [D loss: 0.578452, acc.: 66.41%] [G loss: 0.496665]\n",
      "epoch:7 step:6772 [D loss: 0.472483, acc.: 75.78%] [G loss: 0.730045]\n",
      "epoch:7 step:6773 [D loss: 0.690490, acc.: 56.25%] [G loss: 0.480743]\n",
      "epoch:7 step:6774 [D loss: 0.610098, acc.: 62.50%] [G loss: 0.509446]\n",
      "epoch:7 step:6775 [D loss: 0.561674, acc.: 74.22%] [G loss: 0.464206]\n",
      "epoch:7 step:6776 [D loss: 0.509928, acc.: 75.78%] [G loss: 0.460880]\n",
      "epoch:7 step:6777 [D loss: 0.514942, acc.: 75.00%] [G loss: 0.564724]\n",
      "epoch:7 step:6778 [D loss: 0.466103, acc.: 79.69%] [G loss: 0.590050]\n",
      "epoch:7 step:6779 [D loss: 0.644711, acc.: 63.28%] [G loss: 0.590237]\n",
      "epoch:7 step:6780 [D loss: 0.494809, acc.: 76.56%] [G loss: 0.436571]\n",
      "epoch:7 step:6781 [D loss: 0.501308, acc.: 75.00%] [G loss: 0.629672]\n",
      "epoch:7 step:6782 [D loss: 0.525559, acc.: 75.78%] [G loss: 0.692221]\n",
      "epoch:7 step:6783 [D loss: 0.562990, acc.: 67.97%] [G loss: 0.605146]\n",
      "epoch:7 step:6784 [D loss: 0.618367, acc.: 65.62%] [G loss: 0.563280]\n",
      "epoch:7 step:6785 [D loss: 0.554706, acc.: 63.28%] [G loss: 0.567755]\n",
      "epoch:7 step:6786 [D loss: 0.583278, acc.: 69.53%] [G loss: 0.377066]\n",
      "epoch:7 step:6787 [D loss: 0.587879, acc.: 64.84%] [G loss: 0.483355]\n",
      "epoch:7 step:6788 [D loss: 0.552760, acc.: 73.44%] [G loss: 0.477571]\n",
      "epoch:7 step:6789 [D loss: 0.510076, acc.: 71.09%] [G loss: 0.628789]\n",
      "epoch:7 step:6790 [D loss: 0.512382, acc.: 72.66%] [G loss: 0.721739]\n",
      "epoch:7 step:6791 [D loss: 0.454452, acc.: 78.91%] [G loss: 0.650125]\n",
      "epoch:7 step:6792 [D loss: 0.552199, acc.: 69.53%] [G loss: 0.686693]\n",
      "epoch:7 step:6793 [D loss: 0.584801, acc.: 65.62%] [G loss: 0.651630]\n",
      "epoch:7 step:6794 [D loss: 0.548552, acc.: 75.78%] [G loss: 0.544358]\n",
      "epoch:7 step:6795 [D loss: 0.560617, acc.: 68.75%] [G loss: 0.646348]\n",
      "epoch:7 step:6796 [D loss: 0.548337, acc.: 72.66%] [G loss: 0.582989]\n",
      "epoch:7 step:6797 [D loss: 0.576106, acc.: 69.53%] [G loss: 0.541654]\n",
      "epoch:7 step:6798 [D loss: 0.561156, acc.: 64.06%] [G loss: 0.580066]\n",
      "epoch:7 step:6799 [D loss: 0.517272, acc.: 75.00%] [G loss: 0.664505]\n",
      "epoch:7 step:6800 [D loss: 0.516097, acc.: 79.69%] [G loss: 0.474956]\n",
      "##############\n",
      "[3.20876896 1.22041859 6.54871722 4.85692175 4.16304158 5.97080934\n",
      " 4.84723726 4.80893166 4.78020888 4.10462817]\n",
      "##########\n",
      "epoch:7 step:6801 [D loss: 0.534922, acc.: 68.75%] [G loss: 0.544293]\n",
      "epoch:7 step:6802 [D loss: 0.516388, acc.: 72.66%] [G loss: 0.580211]\n",
      "epoch:7 step:6803 [D loss: 0.532034, acc.: 68.75%] [G loss: 0.584763]\n",
      "epoch:7 step:6804 [D loss: 0.544532, acc.: 70.31%] [G loss: 0.584575]\n",
      "epoch:7 step:6805 [D loss: 0.540233, acc.: 69.53%] [G loss: 0.545447]\n",
      "epoch:7 step:6806 [D loss: 0.519358, acc.: 71.09%] [G loss: 0.723118]\n",
      "epoch:7 step:6807 [D loss: 0.576700, acc.: 65.62%] [G loss: 0.567959]\n",
      "epoch:7 step:6808 [D loss: 0.585135, acc.: 67.97%] [G loss: 0.609399]\n",
      "epoch:7 step:6809 [D loss: 0.605170, acc.: 65.62%] [G loss: 0.671745]\n",
      "epoch:7 step:6810 [D loss: 0.646256, acc.: 59.38%] [G loss: 0.420907]\n",
      "epoch:7 step:6811 [D loss: 0.562363, acc.: 72.66%] [G loss: 0.535777]\n",
      "epoch:7 step:6812 [D loss: 0.539392, acc.: 72.66%] [G loss: 0.501971]\n",
      "epoch:7 step:6813 [D loss: 0.516990, acc.: 72.66%] [G loss: 0.427194]\n",
      "epoch:7 step:6814 [D loss: 0.539577, acc.: 72.66%] [G loss: 0.415815]\n",
      "epoch:7 step:6815 [D loss: 0.524105, acc.: 72.66%] [G loss: 0.537116]\n",
      "epoch:7 step:6816 [D loss: 0.574037, acc.: 67.19%] [G loss: 0.509786]\n",
      "epoch:7 step:6817 [D loss: 0.543157, acc.: 71.88%] [G loss: 0.553617]\n",
      "epoch:7 step:6818 [D loss: 0.512187, acc.: 76.56%] [G loss: 0.486113]\n",
      "epoch:7 step:6819 [D loss: 0.572739, acc.: 67.97%] [G loss: 0.424233]\n",
      "epoch:7 step:6820 [D loss: 0.488948, acc.: 69.53%] [G loss: 0.620072]\n",
      "epoch:7 step:6821 [D loss: 0.496777, acc.: 78.91%] [G loss: 0.498226]\n",
      "epoch:7 step:6822 [D loss: 0.673154, acc.: 56.25%] [G loss: 0.418833]\n",
      "epoch:7 step:6823 [D loss: 0.522828, acc.: 74.22%] [G loss: 0.597275]\n",
      "epoch:7 step:6824 [D loss: 0.559894, acc.: 73.44%] [G loss: 0.531927]\n",
      "epoch:7 step:6825 [D loss: 0.569503, acc.: 72.66%] [G loss: 0.512467]\n",
      "epoch:7 step:6826 [D loss: 0.607361, acc.: 66.41%] [G loss: 0.426606]\n",
      "epoch:7 step:6827 [D loss: 0.524264, acc.: 78.12%] [G loss: 0.475595]\n",
      "epoch:7 step:6828 [D loss: 0.573172, acc.: 67.97%] [G loss: 0.494002]\n",
      "epoch:7 step:6829 [D loss: 0.562276, acc.: 75.78%] [G loss: 0.514909]\n",
      "epoch:7 step:6830 [D loss: 0.515807, acc.: 72.66%] [G loss: 0.643605]\n",
      "epoch:7 step:6831 [D loss: 0.528298, acc.: 74.22%] [G loss: 0.624877]\n",
      "epoch:7 step:6832 [D loss: 0.547250, acc.: 71.09%] [G loss: 0.654145]\n",
      "epoch:7 step:6833 [D loss: 0.583649, acc.: 72.66%] [G loss: 0.616225]\n",
      "epoch:7 step:6834 [D loss: 0.622089, acc.: 65.62%] [G loss: 0.468192]\n",
      "epoch:7 step:6835 [D loss: 0.529509, acc.: 73.44%] [G loss: 0.440289]\n",
      "epoch:7 step:6836 [D loss: 0.648880, acc.: 61.72%] [G loss: 0.441314]\n",
      "epoch:7 step:6837 [D loss: 0.650911, acc.: 61.72%] [G loss: 0.562460]\n",
      "epoch:7 step:6838 [D loss: 0.602519, acc.: 64.06%] [G loss: 0.502264]\n",
      "epoch:7 step:6839 [D loss: 0.569149, acc.: 67.97%] [G loss: 0.639278]\n",
      "epoch:7 step:6840 [D loss: 0.597017, acc.: 65.62%] [G loss: 0.455593]\n",
      "epoch:7 step:6841 [D loss: 0.589429, acc.: 67.19%] [G loss: 0.528087]\n",
      "epoch:7 step:6842 [D loss: 0.493037, acc.: 79.69%] [G loss: 0.504340]\n",
      "epoch:7 step:6843 [D loss: 0.572180, acc.: 66.41%] [G loss: 0.474314]\n",
      "epoch:7 step:6844 [D loss: 0.534074, acc.: 71.88%] [G loss: 0.609707]\n",
      "epoch:7 step:6845 [D loss: 0.519142, acc.: 78.91%] [G loss: 0.530173]\n",
      "epoch:7 step:6846 [D loss: 0.580308, acc.: 66.41%] [G loss: 0.509063]\n",
      "epoch:7 step:6847 [D loss: 0.624499, acc.: 67.97%] [G loss: 0.521189]\n",
      "epoch:7 step:6848 [D loss: 0.542439, acc.: 68.75%] [G loss: 0.538895]\n",
      "epoch:7 step:6849 [D loss: 0.573119, acc.: 67.97%] [G loss: 0.549521]\n",
      "epoch:7 step:6850 [D loss: 0.595850, acc.: 66.41%] [G loss: 0.485145]\n",
      "epoch:7 step:6851 [D loss: 0.588374, acc.: 73.44%] [G loss: 0.559916]\n",
      "epoch:7 step:6852 [D loss: 0.587861, acc.: 64.06%] [G loss: 0.510994]\n",
      "epoch:7 step:6853 [D loss: 0.637706, acc.: 60.16%] [G loss: 0.480811]\n",
      "epoch:7 step:6854 [D loss: 0.514626, acc.: 74.22%] [G loss: 0.559352]\n",
      "epoch:7 step:6855 [D loss: 0.503869, acc.: 77.34%] [G loss: 0.429536]\n",
      "epoch:7 step:6856 [D loss: 0.538295, acc.: 74.22%] [G loss: 0.450126]\n",
      "epoch:7 step:6857 [D loss: 0.472917, acc.: 80.47%] [G loss: 0.588003]\n",
      "epoch:7 step:6858 [D loss: 0.509512, acc.: 78.91%] [G loss: 0.645869]\n",
      "epoch:7 step:6859 [D loss: 0.523674, acc.: 72.66%] [G loss: 0.687844]\n",
      "epoch:7 step:6860 [D loss: 0.630882, acc.: 67.19%] [G loss: 0.629645]\n",
      "epoch:7 step:6861 [D loss: 0.549382, acc.: 76.56%] [G loss: 0.518626]\n",
      "epoch:7 step:6862 [D loss: 0.561833, acc.: 71.09%] [G loss: 0.536429]\n",
      "epoch:7 step:6863 [D loss: 0.499060, acc.: 74.22%] [G loss: 0.566708]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6864 [D loss: 0.547439, acc.: 69.53%] [G loss: 0.596299]\n",
      "epoch:7 step:6865 [D loss: 0.571972, acc.: 67.97%] [G loss: 0.496139]\n",
      "epoch:7 step:6866 [D loss: 0.510305, acc.: 73.44%] [G loss: 0.664672]\n",
      "epoch:7 step:6867 [D loss: 0.568895, acc.: 64.84%] [G loss: 0.547132]\n",
      "epoch:7 step:6868 [D loss: 0.464164, acc.: 76.56%] [G loss: 0.663923]\n",
      "epoch:7 step:6869 [D loss: 0.497220, acc.: 73.44%] [G loss: 0.611119]\n",
      "epoch:7 step:6870 [D loss: 0.467217, acc.: 74.22%] [G loss: 0.568276]\n",
      "epoch:7 step:6871 [D loss: 0.498925, acc.: 75.78%] [G loss: 0.674341]\n",
      "epoch:7 step:6872 [D loss: 0.492967, acc.: 75.00%] [G loss: 0.697667]\n",
      "epoch:7 step:6873 [D loss: 0.433891, acc.: 81.25%] [G loss: 0.806975]\n",
      "epoch:7 step:6874 [D loss: 0.452935, acc.: 80.47%] [G loss: 0.811625]\n",
      "epoch:7 step:6875 [D loss: 0.696238, acc.: 58.59%] [G loss: 0.568327]\n",
      "epoch:7 step:6876 [D loss: 0.598910, acc.: 66.41%] [G loss: 0.469829]\n",
      "epoch:7 step:6877 [D loss: 0.569017, acc.: 67.19%] [G loss: 0.537641]\n",
      "epoch:7 step:6878 [D loss: 0.548719, acc.: 72.66%] [G loss: 0.613253]\n",
      "epoch:7 step:6879 [D loss: 0.505847, acc.: 78.12%] [G loss: 0.511404]\n",
      "epoch:7 step:6880 [D loss: 0.526443, acc.: 66.41%] [G loss: 0.619265]\n",
      "epoch:7 step:6881 [D loss: 0.580014, acc.: 67.19%] [G loss: 0.555577]\n",
      "epoch:7 step:6882 [D loss: 0.658865, acc.: 67.19%] [G loss: 0.502554]\n",
      "epoch:7 step:6883 [D loss: 0.585997, acc.: 71.88%] [G loss: 0.489353]\n",
      "epoch:7 step:6884 [D loss: 0.540224, acc.: 74.22%] [G loss: 0.475872]\n",
      "epoch:7 step:6885 [D loss: 0.526026, acc.: 71.88%] [G loss: 0.512099]\n",
      "epoch:7 step:6886 [D loss: 0.507554, acc.: 75.78%] [G loss: 0.592459]\n",
      "epoch:7 step:6887 [D loss: 0.558540, acc.: 72.66%] [G loss: 0.725872]\n",
      "epoch:7 step:6888 [D loss: 0.558489, acc.: 68.75%] [G loss: 0.488091]\n",
      "epoch:7 step:6889 [D loss: 0.642292, acc.: 62.50%] [G loss: 0.600232]\n",
      "epoch:7 step:6890 [D loss: 0.584110, acc.: 66.41%] [G loss: 0.431003]\n",
      "epoch:7 step:6891 [D loss: 0.542581, acc.: 67.19%] [G loss: 0.473271]\n",
      "epoch:7 step:6892 [D loss: 0.466186, acc.: 79.69%] [G loss: 0.655130]\n",
      "epoch:7 step:6893 [D loss: 0.523052, acc.: 71.88%] [G loss: 0.633909]\n",
      "epoch:7 step:6894 [D loss: 0.499168, acc.: 76.56%] [G loss: 0.529437]\n",
      "epoch:7 step:6895 [D loss: 0.502850, acc.: 75.00%] [G loss: 0.587405]\n",
      "epoch:7 step:6896 [D loss: 0.495530, acc.: 77.34%] [G loss: 0.626779]\n",
      "epoch:7 step:6897 [D loss: 0.510692, acc.: 74.22%] [G loss: 0.594259]\n",
      "epoch:7 step:6898 [D loss: 0.512518, acc.: 75.00%] [G loss: 0.536053]\n",
      "epoch:7 step:6899 [D loss: 0.549609, acc.: 74.22%] [G loss: 0.637780]\n",
      "epoch:7 step:6900 [D loss: 0.620399, acc.: 70.31%] [G loss: 0.569089]\n",
      "epoch:7 step:6901 [D loss: 0.678052, acc.: 59.38%] [G loss: 0.547854]\n",
      "epoch:7 step:6902 [D loss: 0.464023, acc.: 78.12%] [G loss: 0.592129]\n",
      "epoch:7 step:6903 [D loss: 0.543025, acc.: 71.88%] [G loss: 0.598541]\n",
      "epoch:7 step:6904 [D loss: 0.560107, acc.: 70.31%] [G loss: 0.727677]\n",
      "epoch:7 step:6905 [D loss: 0.548814, acc.: 70.31%] [G loss: 0.933823]\n",
      "epoch:7 step:6906 [D loss: 0.484307, acc.: 78.12%] [G loss: 0.901788]\n",
      "epoch:7 step:6907 [D loss: 0.677050, acc.: 64.84%] [G loss: 0.496455]\n",
      "epoch:7 step:6908 [D loss: 0.712531, acc.: 52.34%] [G loss: 0.383361]\n",
      "epoch:7 step:6909 [D loss: 0.490960, acc.: 82.03%] [G loss: 0.589478]\n",
      "epoch:7 step:6910 [D loss: 0.536628, acc.: 74.22%] [G loss: 0.678464]\n",
      "epoch:7 step:6911 [D loss: 0.611722, acc.: 64.84%] [G loss: 0.691394]\n",
      "epoch:7 step:6912 [D loss: 0.592728, acc.: 62.50%] [G loss: 0.583148]\n",
      "epoch:7 step:6913 [D loss: 0.481475, acc.: 76.56%] [G loss: 0.614057]\n",
      "epoch:7 step:6914 [D loss: 0.566590, acc.: 68.75%] [G loss: 0.638555]\n",
      "epoch:7 step:6915 [D loss: 0.623787, acc.: 65.62%] [G loss: 0.483844]\n",
      "epoch:7 step:6916 [D loss: 0.488685, acc.: 78.12%] [G loss: 0.570975]\n",
      "epoch:7 step:6917 [D loss: 0.504292, acc.: 71.88%] [G loss: 0.650835]\n",
      "epoch:7 step:6918 [D loss: 0.458384, acc.: 78.12%] [G loss: 0.741597]\n",
      "epoch:7 step:6919 [D loss: 0.488527, acc.: 76.56%] [G loss: 0.589337]\n",
      "epoch:7 step:6920 [D loss: 0.533108, acc.: 75.00%] [G loss: 0.595176]\n",
      "epoch:7 step:6921 [D loss: 0.554046, acc.: 66.41%] [G loss: 0.475888]\n",
      "epoch:7 step:6922 [D loss: 0.529941, acc.: 74.22%] [G loss: 0.494100]\n",
      "epoch:7 step:6923 [D loss: 0.487227, acc.: 75.78%] [G loss: 0.596372]\n",
      "epoch:7 step:6924 [D loss: 0.602918, acc.: 64.84%] [G loss: 0.626002]\n",
      "epoch:7 step:6925 [D loss: 0.510212, acc.: 76.56%] [G loss: 0.645993]\n",
      "epoch:7 step:6926 [D loss: 0.524866, acc.: 75.78%] [G loss: 0.621758]\n",
      "epoch:7 step:6927 [D loss: 0.552164, acc.: 71.09%] [G loss: 0.675263]\n",
      "epoch:7 step:6928 [D loss: 0.520691, acc.: 75.00%] [G loss: 0.550626]\n",
      "epoch:7 step:6929 [D loss: 0.575838, acc.: 71.88%] [G loss: 0.618453]\n",
      "epoch:7 step:6930 [D loss: 0.524696, acc.: 75.78%] [G loss: 0.657607]\n",
      "epoch:7 step:6931 [D loss: 0.549957, acc.: 71.09%] [G loss: 0.619780]\n",
      "epoch:7 step:6932 [D loss: 0.528124, acc.: 75.00%] [G loss: 0.607218]\n",
      "epoch:7 step:6933 [D loss: 0.487384, acc.: 77.34%] [G loss: 0.687991]\n",
      "epoch:7 step:6934 [D loss: 0.598600, acc.: 63.28%] [G loss: 0.549697]\n",
      "epoch:7 step:6935 [D loss: 0.657640, acc.: 63.28%] [G loss: 0.411357]\n",
      "epoch:7 step:6936 [D loss: 0.584015, acc.: 69.53%] [G loss: 0.402115]\n",
      "epoch:7 step:6937 [D loss: 0.578451, acc.: 61.72%] [G loss: 0.450731]\n",
      "epoch:7 step:6938 [D loss: 0.547711, acc.: 75.78%] [G loss: 0.550597]\n",
      "epoch:7 step:6939 [D loss: 0.553560, acc.: 71.88%] [G loss: 0.447569]\n",
      "epoch:7 step:6940 [D loss: 0.454250, acc.: 82.81%] [G loss: 0.505031]\n",
      "epoch:7 step:6941 [D loss: 0.517638, acc.: 76.56%] [G loss: 0.702481]\n",
      "epoch:7 step:6942 [D loss: 0.571173, acc.: 67.97%] [G loss: 0.654762]\n",
      "epoch:7 step:6943 [D loss: 0.524142, acc.: 68.75%] [G loss: 0.575592]\n",
      "epoch:7 step:6944 [D loss: 0.538160, acc.: 71.09%] [G loss: 0.541301]\n",
      "epoch:7 step:6945 [D loss: 0.573567, acc.: 66.41%] [G loss: 0.606693]\n",
      "epoch:7 step:6946 [D loss: 0.620834, acc.: 62.50%] [G loss: 0.459018]\n",
      "epoch:7 step:6947 [D loss: 0.521816, acc.: 74.22%] [G loss: 0.587004]\n",
      "epoch:7 step:6948 [D loss: 0.542659, acc.: 70.31%] [G loss: 0.639005]\n",
      "epoch:7 step:6949 [D loss: 0.583514, acc.: 67.19%] [G loss: 0.631642]\n",
      "epoch:7 step:6950 [D loss: 0.499887, acc.: 78.12%] [G loss: 0.538388]\n",
      "epoch:7 step:6951 [D loss: 0.498583, acc.: 72.66%] [G loss: 0.566497]\n",
      "epoch:7 step:6952 [D loss: 0.595249, acc.: 67.19%] [G loss: 0.478274]\n",
      "epoch:7 step:6953 [D loss: 0.555550, acc.: 73.44%] [G loss: 0.450143]\n",
      "epoch:7 step:6954 [D loss: 0.517101, acc.: 74.22%] [G loss: 0.485850]\n",
      "epoch:7 step:6955 [D loss: 0.605555, acc.: 65.62%] [G loss: 0.535412]\n",
      "epoch:7 step:6956 [D loss: 0.559196, acc.: 69.53%] [G loss: 0.582802]\n",
      "epoch:7 step:6957 [D loss: 0.457601, acc.: 76.56%] [G loss: 0.814839]\n",
      "epoch:7 step:6958 [D loss: 0.554226, acc.: 72.66%] [G loss: 0.652537]\n",
      "epoch:7 step:6959 [D loss: 0.670318, acc.: 58.59%] [G loss: 0.591563]\n",
      "epoch:7 step:6960 [D loss: 0.623664, acc.: 57.81%] [G loss: 0.493047]\n",
      "epoch:7 step:6961 [D loss: 0.485905, acc.: 75.78%] [G loss: 0.521912]\n",
      "epoch:7 step:6962 [D loss: 0.486692, acc.: 75.78%] [G loss: 0.601190]\n",
      "epoch:7 step:6963 [D loss: 0.641414, acc.: 60.94%] [G loss: 0.530573]\n",
      "epoch:7 step:6964 [D loss: 0.551055, acc.: 69.53%] [G loss: 0.506336]\n",
      "epoch:7 step:6965 [D loss: 0.582125, acc.: 75.78%] [G loss: 0.560159]\n",
      "epoch:7 step:6966 [D loss: 0.605055, acc.: 60.94%] [G loss: 0.570678]\n",
      "epoch:7 step:6967 [D loss: 0.611430, acc.: 66.41%] [G loss: 0.636460]\n",
      "epoch:7 step:6968 [D loss: 0.569884, acc.: 69.53%] [G loss: 0.645734]\n",
      "epoch:7 step:6969 [D loss: 0.590622, acc.: 67.97%] [G loss: 0.536281]\n",
      "epoch:7 step:6970 [D loss: 0.594005, acc.: 64.06%] [G loss: 0.536885]\n",
      "epoch:7 step:6971 [D loss: 0.593191, acc.: 65.62%] [G loss: 0.469083]\n",
      "epoch:7 step:6972 [D loss: 0.580545, acc.: 67.97%] [G loss: 0.496272]\n",
      "epoch:7 step:6973 [D loss: 0.572605, acc.: 67.97%] [G loss: 0.401000]\n",
      "epoch:7 step:6974 [D loss: 0.534731, acc.: 74.22%] [G loss: 0.613256]\n",
      "epoch:7 step:6975 [D loss: 0.518844, acc.: 72.66%] [G loss: 0.635189]\n",
      "epoch:7 step:6976 [D loss: 0.629755, acc.: 63.28%] [G loss: 0.640966]\n",
      "epoch:7 step:6977 [D loss: 0.608212, acc.: 60.16%] [G loss: 0.479596]\n",
      "epoch:7 step:6978 [D loss: 0.552647, acc.: 70.31%] [G loss: 0.549060]\n",
      "epoch:7 step:6979 [D loss: 0.564564, acc.: 63.28%] [G loss: 0.548028]\n",
      "epoch:7 step:6980 [D loss: 0.574464, acc.: 68.75%] [G loss: 0.467030]\n",
      "epoch:7 step:6981 [D loss: 0.582679, acc.: 66.41%] [G loss: 0.553368]\n",
      "epoch:7 step:6982 [D loss: 0.566156, acc.: 72.66%] [G loss: 0.567246]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6983 [D loss: 0.558962, acc.: 73.44%] [G loss: 0.636716]\n",
      "epoch:7 step:6984 [D loss: 0.533315, acc.: 75.00%] [G loss: 0.701227]\n",
      "epoch:7 step:6985 [D loss: 0.465147, acc.: 78.91%] [G loss: 0.569639]\n",
      "epoch:7 step:6986 [D loss: 0.477089, acc.: 75.78%] [G loss: 0.660365]\n",
      "epoch:7 step:6987 [D loss: 0.518113, acc.: 77.34%] [G loss: 0.563468]\n",
      "epoch:7 step:6988 [D loss: 0.521859, acc.: 75.00%] [G loss: 0.722260]\n",
      "epoch:7 step:6989 [D loss: 0.504753, acc.: 75.78%] [G loss: 0.532119]\n",
      "epoch:7 step:6990 [D loss: 0.510980, acc.: 74.22%] [G loss: 0.695718]\n",
      "epoch:7 step:6991 [D loss: 0.555520, acc.: 71.88%] [G loss: 0.473838]\n",
      "epoch:7 step:6992 [D loss: 0.629875, acc.: 63.28%] [G loss: 0.490111]\n",
      "epoch:7 step:6993 [D loss: 0.540825, acc.: 73.44%] [G loss: 0.540667]\n",
      "epoch:7 step:6994 [D loss: 0.568250, acc.: 70.31%] [G loss: 0.713000]\n",
      "epoch:7 step:6995 [D loss: 0.494707, acc.: 76.56%] [G loss: 0.677436]\n",
      "epoch:7 step:6996 [D loss: 0.700255, acc.: 62.50%] [G loss: 0.492898]\n",
      "epoch:7 step:6997 [D loss: 0.528539, acc.: 72.66%] [G loss: 0.658809]\n",
      "epoch:7 step:6998 [D loss: 0.515579, acc.: 74.22%] [G loss: 0.503396]\n",
      "epoch:7 step:6999 [D loss: 0.546712, acc.: 71.88%] [G loss: 0.536407]\n",
      "epoch:7 step:7000 [D loss: 0.586064, acc.: 65.62%] [G loss: 0.567958]\n",
      "##############\n",
      "[2.98847234 1.33183256 6.47512904 5.0466213  4.17270695 5.82166221\n",
      " 4.96293268 4.72577646 4.63281756 3.73831195]\n",
      "##########\n",
      "epoch:7 step:7001 [D loss: 0.546513, acc.: 68.75%] [G loss: 0.507444]\n",
      "epoch:7 step:7002 [D loss: 0.511146, acc.: 75.00%] [G loss: 0.529507]\n",
      "epoch:7 step:7003 [D loss: 0.509151, acc.: 75.00%] [G loss: 0.519212]\n",
      "epoch:7 step:7004 [D loss: 0.553209, acc.: 67.19%] [G loss: 0.613822]\n",
      "epoch:7 step:7005 [D loss: 0.550815, acc.: 67.19%] [G loss: 0.580259]\n",
      "epoch:7 step:7006 [D loss: 0.487758, acc.: 75.78%] [G loss: 0.675146]\n",
      "epoch:7 step:7007 [D loss: 0.627388, acc.: 67.19%] [G loss: 0.618998]\n",
      "epoch:7 step:7008 [D loss: 0.545361, acc.: 69.53%] [G loss: 0.692558]\n",
      "epoch:7 step:7009 [D loss: 0.478851, acc.: 78.91%] [G loss: 0.766304]\n",
      "epoch:7 step:7010 [D loss: 0.420869, acc.: 81.25%] [G loss: 0.832758]\n",
      "epoch:7 step:7011 [D loss: 0.498056, acc.: 78.12%] [G loss: 0.731239]\n",
      "epoch:7 step:7012 [D loss: 0.570325, acc.: 74.22%] [G loss: 0.762295]\n",
      "epoch:7 step:7013 [D loss: 0.575298, acc.: 73.44%] [G loss: 0.625143]\n",
      "epoch:7 step:7014 [D loss: 0.530330, acc.: 76.56%] [G loss: 0.530429]\n",
      "epoch:7 step:7015 [D loss: 0.650660, acc.: 57.81%] [G loss: 0.495680]\n",
      "epoch:7 step:7016 [D loss: 0.519631, acc.: 75.00%] [G loss: 0.569192]\n",
      "epoch:7 step:7017 [D loss: 0.601436, acc.: 64.06%] [G loss: 0.524107]\n",
      "epoch:7 step:7018 [D loss: 0.553675, acc.: 69.53%] [G loss: 0.534772]\n",
      "epoch:7 step:7019 [D loss: 0.524925, acc.: 73.44%] [G loss: 0.585639]\n",
      "epoch:7 step:7020 [D loss: 0.510301, acc.: 72.66%] [G loss: 0.503802]\n",
      "epoch:7 step:7021 [D loss: 0.581101, acc.: 64.06%] [G loss: 0.622937]\n",
      "epoch:7 step:7022 [D loss: 0.594264, acc.: 68.75%] [G loss: 0.525132]\n",
      "epoch:7 step:7023 [D loss: 0.562293, acc.: 72.66%] [G loss: 0.587512]\n",
      "epoch:7 step:7024 [D loss: 0.629216, acc.: 61.72%] [G loss: 0.474218]\n",
      "epoch:7 step:7025 [D loss: 0.605312, acc.: 65.62%] [G loss: 0.528682]\n",
      "epoch:7 step:7026 [D loss: 0.529557, acc.: 74.22%] [G loss: 0.628988]\n",
      "epoch:7 step:7027 [D loss: 0.582443, acc.: 67.97%] [G loss: 0.573823]\n",
      "epoch:7 step:7028 [D loss: 0.570438, acc.: 69.53%] [G loss: 0.583706]\n",
      "epoch:7 step:7029 [D loss: 0.524328, acc.: 74.22%] [G loss: 0.587293]\n",
      "epoch:7 step:7030 [D loss: 0.453752, acc.: 84.38%] [G loss: 0.743903]\n",
      "epoch:7 step:7031 [D loss: 0.503742, acc.: 75.00%] [G loss: 0.775243]\n",
      "epoch:7 step:7032 [D loss: 0.664747, acc.: 60.94%] [G loss: 0.649227]\n",
      "epoch:7 step:7033 [D loss: 0.544412, acc.: 70.31%] [G loss: 0.597839]\n",
      "epoch:7 step:7034 [D loss: 0.446529, acc.: 78.91%] [G loss: 0.672103]\n",
      "epoch:7 step:7035 [D loss: 0.556760, acc.: 75.78%] [G loss: 0.673365]\n",
      "epoch:7 step:7036 [D loss: 0.662298, acc.: 60.16%] [G loss: 0.400495]\n",
      "epoch:7 step:7037 [D loss: 0.588809, acc.: 67.97%] [G loss: 0.411678]\n",
      "epoch:7 step:7038 [D loss: 0.578749, acc.: 71.09%] [G loss: 0.508538]\n",
      "epoch:7 step:7039 [D loss: 0.536851, acc.: 73.44%] [G loss: 0.499500]\n",
      "epoch:7 step:7040 [D loss: 0.537103, acc.: 78.12%] [G loss: 0.559319]\n",
      "epoch:7 step:7041 [D loss: 0.609173, acc.: 63.28%] [G loss: 0.469803]\n",
      "epoch:7 step:7042 [D loss: 0.543094, acc.: 71.09%] [G loss: 0.563239]\n",
      "epoch:7 step:7043 [D loss: 0.479877, acc.: 77.34%] [G loss: 0.641615]\n",
      "epoch:7 step:7044 [D loss: 0.513596, acc.: 73.44%] [G loss: 0.595621]\n",
      "epoch:7 step:7045 [D loss: 0.561960, acc.: 68.75%] [G loss: 0.511328]\n",
      "epoch:7 step:7046 [D loss: 0.543183, acc.: 72.66%] [G loss: 0.485452]\n",
      "epoch:7 step:7047 [D loss: 0.476684, acc.: 78.12%] [G loss: 0.584773]\n",
      "epoch:7 step:7048 [D loss: 0.567948, acc.: 69.53%] [G loss: 0.564434]\n",
      "epoch:7 step:7049 [D loss: 0.572250, acc.: 65.62%] [G loss: 0.607308]\n",
      "epoch:7 step:7050 [D loss: 0.588145, acc.: 67.97%] [G loss: 0.482073]\n",
      "epoch:7 step:7051 [D loss: 0.558502, acc.: 71.88%] [G loss: 0.564314]\n",
      "epoch:7 step:7052 [D loss: 0.613640, acc.: 62.50%] [G loss: 0.539825]\n",
      "epoch:7 step:7053 [D loss: 0.587563, acc.: 71.09%] [G loss: 0.408695]\n",
      "epoch:7 step:7054 [D loss: 0.526851, acc.: 71.88%] [G loss: 0.474577]\n",
      "epoch:7 step:7055 [D loss: 0.613501, acc.: 63.28%] [G loss: 0.440392]\n",
      "epoch:7 step:7056 [D loss: 0.520579, acc.: 73.44%] [G loss: 0.607815]\n",
      "epoch:7 step:7057 [D loss: 0.561468, acc.: 68.75%] [G loss: 0.515263]\n",
      "epoch:7 step:7058 [D loss: 0.492759, acc.: 73.44%] [G loss: 0.716604]\n",
      "epoch:7 step:7059 [D loss: 0.604917, acc.: 67.19%] [G loss: 0.513317]\n",
      "epoch:7 step:7060 [D loss: 0.636496, acc.: 67.19%] [G loss: 0.438226]\n",
      "epoch:7 step:7061 [D loss: 0.613938, acc.: 61.72%] [G loss: 0.443601]\n",
      "epoch:7 step:7062 [D loss: 0.489150, acc.: 75.00%] [G loss: 0.480590]\n",
      "epoch:7 step:7063 [D loss: 0.495835, acc.: 76.56%] [G loss: 0.732232]\n",
      "epoch:7 step:7064 [D loss: 0.517550, acc.: 74.22%] [G loss: 0.567260]\n",
      "epoch:7 step:7065 [D loss: 0.519060, acc.: 71.88%] [G loss: 0.690228]\n",
      "epoch:7 step:7066 [D loss: 0.563482, acc.: 73.44%] [G loss: 0.682947]\n",
      "epoch:7 step:7067 [D loss: 0.466632, acc.: 78.91%] [G loss: 0.745079]\n",
      "epoch:7 step:7068 [D loss: 0.521301, acc.: 71.88%] [G loss: 0.686990]\n",
      "epoch:7 step:7069 [D loss: 0.648977, acc.: 60.94%] [G loss: 0.533408]\n",
      "epoch:7 step:7070 [D loss: 0.634772, acc.: 58.59%] [G loss: 0.407487]\n",
      "epoch:7 step:7071 [D loss: 0.618374, acc.: 64.06%] [G loss: 0.400985]\n",
      "epoch:7 step:7072 [D loss: 0.533323, acc.: 71.88%] [G loss: 0.395137]\n",
      "epoch:7 step:7073 [D loss: 0.475183, acc.: 77.34%] [G loss: 0.563464]\n",
      "epoch:7 step:7074 [D loss: 0.479511, acc.: 79.69%] [G loss: 0.553312]\n",
      "epoch:7 step:7075 [D loss: 0.491742, acc.: 78.91%] [G loss: 0.677489]\n",
      "epoch:7 step:7076 [D loss: 0.576298, acc.: 70.31%] [G loss: 0.518226]\n",
      "epoch:7 step:7077 [D loss: 0.530682, acc.: 71.09%] [G loss: 0.566473]\n",
      "epoch:7 step:7078 [D loss: 0.479370, acc.: 76.56%] [G loss: 0.674159]\n",
      "epoch:7 step:7079 [D loss: 0.536558, acc.: 71.09%] [G loss: 0.658568]\n",
      "epoch:7 step:7080 [D loss: 0.536280, acc.: 77.34%] [G loss: 0.595450]\n",
      "epoch:7 step:7081 [D loss: 0.540610, acc.: 72.66%] [G loss: 0.537196]\n",
      "epoch:7 step:7082 [D loss: 0.534456, acc.: 72.66%] [G loss: 0.554085]\n",
      "epoch:7 step:7083 [D loss: 0.520678, acc.: 73.44%] [G loss: 0.613890]\n",
      "epoch:7 step:7084 [D loss: 0.626346, acc.: 58.59%] [G loss: 0.437898]\n",
      "epoch:7 step:7085 [D loss: 0.493646, acc.: 80.47%] [G loss: 0.560982]\n",
      "epoch:7 step:7086 [D loss: 0.569815, acc.: 65.62%] [G loss: 0.652099]\n",
      "epoch:7 step:7087 [D loss: 0.646553, acc.: 64.84%] [G loss: 0.525601]\n",
      "epoch:7 step:7088 [D loss: 0.602856, acc.: 64.84%] [G loss: 0.444984]\n",
      "epoch:7 step:7089 [D loss: 0.553384, acc.: 71.09%] [G loss: 0.664418]\n",
      "epoch:7 step:7090 [D loss: 0.634976, acc.: 65.62%] [G loss: 0.581461]\n",
      "epoch:7 step:7091 [D loss: 0.588445, acc.: 65.62%] [G loss: 0.560423]\n",
      "epoch:7 step:7092 [D loss: 0.587770, acc.: 67.97%] [G loss: 0.481107]\n",
      "epoch:7 step:7093 [D loss: 0.544106, acc.: 74.22%] [G loss: 0.685334]\n",
      "epoch:7 step:7094 [D loss: 0.688707, acc.: 55.47%] [G loss: 0.575093]\n",
      "epoch:7 step:7095 [D loss: 0.513629, acc.: 74.22%] [G loss: 0.586077]\n",
      "epoch:7 step:7096 [D loss: 0.559952, acc.: 67.97%] [G loss: 0.456821]\n",
      "epoch:7 step:7097 [D loss: 0.615317, acc.: 63.28%] [G loss: 0.494186]\n",
      "epoch:7 step:7098 [D loss: 0.559811, acc.: 70.31%] [G loss: 0.529000]\n",
      "epoch:7 step:7099 [D loss: 0.514315, acc.: 75.78%] [G loss: 0.528980]\n",
      "epoch:7 step:7100 [D loss: 0.553050, acc.: 69.53%] [G loss: 0.474160]\n",
      "epoch:7 step:7101 [D loss: 0.592204, acc.: 65.62%] [G loss: 0.450212]\n",
      "epoch:7 step:7102 [D loss: 0.582596, acc.: 69.53%] [G loss: 0.522402]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7103 [D loss: 0.552929, acc.: 68.75%] [G loss: 0.639686]\n",
      "epoch:7 step:7104 [D loss: 0.525234, acc.: 70.31%] [G loss: 0.496525]\n",
      "epoch:7 step:7105 [D loss: 0.460402, acc.: 80.47%] [G loss: 0.688735]\n",
      "epoch:7 step:7106 [D loss: 0.534618, acc.: 75.00%] [G loss: 0.630305]\n",
      "epoch:7 step:7107 [D loss: 0.517149, acc.: 73.44%] [G loss: 0.547309]\n",
      "epoch:7 step:7108 [D loss: 0.523733, acc.: 71.09%] [G loss: 0.728976]\n",
      "epoch:7 step:7109 [D loss: 0.572902, acc.: 67.97%] [G loss: 0.558808]\n",
      "epoch:7 step:7110 [D loss: 0.566111, acc.: 71.09%] [G loss: 0.517145]\n",
      "epoch:7 step:7111 [D loss: 0.485569, acc.: 78.12%] [G loss: 0.633686]\n",
      "epoch:7 step:7112 [D loss: 0.544511, acc.: 69.53%] [G loss: 0.607539]\n",
      "epoch:7 step:7113 [D loss: 0.500729, acc.: 75.78%] [G loss: 0.585942]\n",
      "epoch:7 step:7114 [D loss: 0.535123, acc.: 72.66%] [G loss: 0.691001]\n",
      "epoch:7 step:7115 [D loss: 0.492708, acc.: 76.56%] [G loss: 0.744279]\n",
      "epoch:7 step:7116 [D loss: 0.506355, acc.: 71.88%] [G loss: 0.612280]\n",
      "epoch:7 step:7117 [D loss: 0.474660, acc.: 76.56%] [G loss: 0.556087]\n",
      "epoch:7 step:7118 [D loss: 0.617545, acc.: 69.53%] [G loss: 0.559959]\n",
      "epoch:7 step:7119 [D loss: 0.593870, acc.: 64.84%] [G loss: 0.484320]\n",
      "epoch:7 step:7120 [D loss: 0.511705, acc.: 75.00%] [G loss: 0.514802]\n",
      "epoch:7 step:7121 [D loss: 0.581434, acc.: 67.97%] [G loss: 0.417020]\n",
      "epoch:7 step:7122 [D loss: 0.576540, acc.: 70.31%] [G loss: 0.452271]\n",
      "epoch:7 step:7123 [D loss: 0.487311, acc.: 78.12%] [G loss: 0.566604]\n",
      "epoch:7 step:7124 [D loss: 0.578424, acc.: 69.53%] [G loss: 0.474429]\n",
      "epoch:7 step:7125 [D loss: 0.697901, acc.: 53.91%] [G loss: 0.503166]\n",
      "epoch:7 step:7126 [D loss: 0.503223, acc.: 75.00%] [G loss: 0.591758]\n",
      "epoch:7 step:7127 [D loss: 0.553308, acc.: 71.09%] [G loss: 0.580211]\n",
      "epoch:7 step:7128 [D loss: 0.558387, acc.: 71.09%] [G loss: 0.634374]\n",
      "epoch:7 step:7129 [D loss: 0.543983, acc.: 71.09%] [G loss: 0.663661]\n",
      "epoch:7 step:7130 [D loss: 0.544792, acc.: 70.31%] [G loss: 0.540652]\n",
      "epoch:7 step:7131 [D loss: 0.542648, acc.: 71.88%] [G loss: 0.621273]\n",
      "epoch:7 step:7132 [D loss: 0.574862, acc.: 71.09%] [G loss: 0.492669]\n",
      "epoch:7 step:7133 [D loss: 0.556977, acc.: 71.88%] [G loss: 0.630552]\n",
      "epoch:7 step:7134 [D loss: 0.499634, acc.: 75.00%] [G loss: 0.792413]\n",
      "epoch:7 step:7135 [D loss: 0.605675, acc.: 71.09%] [G loss: 0.643075]\n",
      "epoch:7 step:7136 [D loss: 0.590956, acc.: 67.97%] [G loss: 0.769378]\n",
      "epoch:7 step:7137 [D loss: 0.543213, acc.: 72.66%] [G loss: 0.473513]\n",
      "epoch:7 step:7138 [D loss: 0.597136, acc.: 63.28%] [G loss: 0.440100]\n",
      "epoch:7 step:7139 [D loss: 0.566979, acc.: 68.75%] [G loss: 0.499803]\n",
      "epoch:7 step:7140 [D loss: 0.546783, acc.: 71.09%] [G loss: 0.566209]\n",
      "epoch:7 step:7141 [D loss: 0.463423, acc.: 78.91%] [G loss: 0.719611]\n",
      "epoch:7 step:7142 [D loss: 0.567223, acc.: 72.66%] [G loss: 0.947244]\n",
      "epoch:7 step:7143 [D loss: 0.587664, acc.: 64.84%] [G loss: 0.647171]\n",
      "epoch:7 step:7144 [D loss: 0.599254, acc.: 68.75%] [G loss: 0.489471]\n",
      "epoch:7 step:7145 [D loss: 0.589306, acc.: 64.06%] [G loss: 0.492414]\n",
      "epoch:7 step:7146 [D loss: 0.593798, acc.: 60.16%] [G loss: 0.406444]\n",
      "epoch:7 step:7147 [D loss: 0.556672, acc.: 67.19%] [G loss: 0.650454]\n",
      "epoch:7 step:7148 [D loss: 0.497306, acc.: 71.09%] [G loss: 0.678025]\n",
      "epoch:7 step:7149 [D loss: 0.574307, acc.: 71.88%] [G loss: 0.611467]\n",
      "epoch:7 step:7150 [D loss: 0.624448, acc.: 67.19%] [G loss: 0.454284]\n",
      "epoch:7 step:7151 [D loss: 0.525370, acc.: 77.34%] [G loss: 0.609987]\n",
      "epoch:7 step:7152 [D loss: 0.538831, acc.: 71.88%] [G loss: 0.595038]\n",
      "epoch:7 step:7153 [D loss: 0.578935, acc.: 70.31%] [G loss: 0.506763]\n",
      "epoch:7 step:7154 [D loss: 0.512897, acc.: 75.78%] [G loss: 0.497696]\n",
      "epoch:7 step:7155 [D loss: 0.548049, acc.: 70.31%] [G loss: 0.571472]\n",
      "epoch:7 step:7156 [D loss: 0.534659, acc.: 67.97%] [G loss: 0.517676]\n",
      "epoch:7 step:7157 [D loss: 0.519065, acc.: 75.00%] [G loss: 0.509506]\n",
      "epoch:7 step:7158 [D loss: 0.592467, acc.: 67.19%] [G loss: 0.663171]\n",
      "epoch:7 step:7159 [D loss: 0.607881, acc.: 62.50%] [G loss: 0.495865]\n",
      "epoch:7 step:7160 [D loss: 0.523002, acc.: 72.66%] [G loss: 0.499919]\n",
      "epoch:7 step:7161 [D loss: 0.538388, acc.: 72.66%] [G loss: 0.608369]\n",
      "epoch:7 step:7162 [D loss: 0.497917, acc.: 75.00%] [G loss: 0.657440]\n",
      "epoch:7 step:7163 [D loss: 0.629051, acc.: 67.19%] [G loss: 0.631117]\n",
      "epoch:7 step:7164 [D loss: 0.450071, acc.: 78.12%] [G loss: 0.544877]\n",
      "epoch:7 step:7165 [D loss: 0.602239, acc.: 60.16%] [G loss: 0.428874]\n",
      "epoch:7 step:7166 [D loss: 0.530364, acc.: 75.78%] [G loss: 0.499004]\n",
      "epoch:7 step:7167 [D loss: 0.565692, acc.: 64.84%] [G loss: 0.421344]\n",
      "epoch:7 step:7168 [D loss: 0.514736, acc.: 76.56%] [G loss: 0.595855]\n",
      "epoch:7 step:7169 [D loss: 0.545521, acc.: 68.75%] [G loss: 0.480481]\n",
      "epoch:7 step:7170 [D loss: 0.498960, acc.: 73.44%] [G loss: 0.546262]\n",
      "epoch:7 step:7171 [D loss: 0.566730, acc.: 66.41%] [G loss: 0.403128]\n",
      "epoch:7 step:7172 [D loss: 0.492580, acc.: 77.34%] [G loss: 0.480715]\n",
      "epoch:7 step:7173 [D loss: 0.599951, acc.: 65.62%] [G loss: 0.464795]\n",
      "epoch:7 step:7174 [D loss: 0.618921, acc.: 59.38%] [G loss: 0.500865]\n",
      "epoch:7 step:7175 [D loss: 0.623285, acc.: 60.94%] [G loss: 0.518067]\n",
      "epoch:7 step:7176 [D loss: 0.574397, acc.: 65.62%] [G loss: 0.497173]\n",
      "epoch:7 step:7177 [D loss: 0.526696, acc.: 75.00%] [G loss: 0.539956]\n",
      "epoch:7 step:7178 [D loss: 0.540223, acc.: 71.88%] [G loss: 0.517529]\n",
      "epoch:7 step:7179 [D loss: 0.517607, acc.: 72.66%] [G loss: 0.574781]\n",
      "epoch:7 step:7180 [D loss: 0.531639, acc.: 77.34%] [G loss: 0.616986]\n",
      "epoch:7 step:7181 [D loss: 0.609238, acc.: 66.41%] [G loss: 0.490648]\n",
      "epoch:7 step:7182 [D loss: 0.493887, acc.: 73.44%] [G loss: 0.546087]\n",
      "epoch:7 step:7183 [D loss: 0.488688, acc.: 77.34%] [G loss: 0.604969]\n",
      "epoch:7 step:7184 [D loss: 0.610024, acc.: 64.06%] [G loss: 0.584051]\n",
      "epoch:7 step:7185 [D loss: 0.540441, acc.: 72.66%] [G loss: 0.470625]\n",
      "epoch:7 step:7186 [D loss: 0.568068, acc.: 72.66%] [G loss: 0.590453]\n",
      "epoch:7 step:7187 [D loss: 0.594505, acc.: 68.75%] [G loss: 0.419497]\n",
      "epoch:7 step:7188 [D loss: 0.512895, acc.: 78.91%] [G loss: 0.518890]\n",
      "epoch:7 step:7189 [D loss: 0.587674, acc.: 70.31%] [G loss: 0.593978]\n",
      "epoch:7 step:7190 [D loss: 0.543569, acc.: 74.22%] [G loss: 0.406913]\n",
      "epoch:7 step:7191 [D loss: 0.536525, acc.: 71.88%] [G loss: 0.509970]\n",
      "epoch:7 step:7192 [D loss: 0.562287, acc.: 71.09%] [G loss: 0.639196]\n",
      "epoch:7 step:7193 [D loss: 0.502132, acc.: 77.34%] [G loss: 0.632479]\n",
      "epoch:7 step:7194 [D loss: 0.517571, acc.: 75.78%] [G loss: 0.605795]\n",
      "epoch:7 step:7195 [D loss: 0.597570, acc.: 64.06%] [G loss: 0.452986]\n",
      "epoch:7 step:7196 [D loss: 0.522378, acc.: 78.12%] [G loss: 0.503539]\n",
      "epoch:7 step:7197 [D loss: 0.494750, acc.: 77.34%] [G loss: 0.494576]\n",
      "epoch:7 step:7198 [D loss: 0.493067, acc.: 78.12%] [G loss: 0.530845]\n",
      "epoch:7 step:7199 [D loss: 0.550461, acc.: 71.09%] [G loss: 0.733044]\n",
      "epoch:7 step:7200 [D loss: 0.477514, acc.: 82.03%] [G loss: 0.801933]\n",
      "##############\n",
      "[2.80608344 0.99342409 6.55302871 4.77373381 4.10365884 5.77549416\n",
      " 4.80085946 5.02410834 4.69732969 4.02526421]\n",
      "##########\n",
      "epoch:7 step:7201 [D loss: 0.469587, acc.: 80.47%] [G loss: 0.745830]\n",
      "epoch:7 step:7202 [D loss: 0.519786, acc.: 71.88%] [G loss: 0.765830]\n",
      "epoch:7 step:7203 [D loss: 0.565507, acc.: 67.19%] [G loss: 0.476812]\n",
      "epoch:7 step:7204 [D loss: 0.569829, acc.: 71.09%] [G loss: 0.507258]\n",
      "epoch:7 step:7205 [D loss: 0.569142, acc.: 70.31%] [G loss: 0.519642]\n",
      "epoch:7 step:7206 [D loss: 0.477074, acc.: 79.69%] [G loss: 0.737397]\n",
      "epoch:7 step:7207 [D loss: 0.410787, acc.: 83.59%] [G loss: 0.949123]\n",
      "epoch:7 step:7208 [D loss: 0.513160, acc.: 75.00%] [G loss: 0.790039]\n",
      "epoch:7 step:7209 [D loss: 0.506713, acc.: 75.00%] [G loss: 0.846349]\n",
      "epoch:7 step:7210 [D loss: 0.511120, acc.: 75.00%] [G loss: 0.676556]\n",
      "epoch:7 step:7211 [D loss: 0.653380, acc.: 62.50%] [G loss: 0.416270]\n",
      "epoch:7 step:7212 [D loss: 0.601216, acc.: 64.06%] [G loss: 0.554505]\n",
      "epoch:7 step:7213 [D loss: 0.516056, acc.: 72.66%] [G loss: 0.584698]\n",
      "epoch:7 step:7214 [D loss: 0.559937, acc.: 68.75%] [G loss: 0.656234]\n",
      "epoch:7 step:7215 [D loss: 0.583417, acc.: 66.41%] [G loss: 0.507664]\n",
      "epoch:7 step:7216 [D loss: 0.555604, acc.: 69.53%] [G loss: 0.643980]\n",
      "epoch:7 step:7217 [D loss: 0.604215, acc.: 65.62%] [G loss: 0.663931]\n",
      "epoch:7 step:7218 [D loss: 0.503843, acc.: 75.00%] [G loss: 0.563147]\n",
      "epoch:7 step:7219 [D loss: 0.477702, acc.: 78.12%] [G loss: 0.630011]\n",
      "epoch:7 step:7220 [D loss: 0.582861, acc.: 69.53%] [G loss: 0.594478]\n",
      "epoch:7 step:7221 [D loss: 0.595175, acc.: 66.41%] [G loss: 0.562453]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7222 [D loss: 0.561066, acc.: 72.66%] [G loss: 0.529423]\n",
      "epoch:7 step:7223 [D loss: 0.610157, acc.: 71.88%] [G loss: 0.807056]\n",
      "epoch:7 step:7224 [D loss: 0.563041, acc.: 68.75%] [G loss: 0.690005]\n",
      "epoch:7 step:7225 [D loss: 0.583278, acc.: 68.75%] [G loss: 0.657152]\n",
      "epoch:7 step:7226 [D loss: 0.553732, acc.: 71.88%] [G loss: 0.746415]\n",
      "epoch:7 step:7227 [D loss: 0.582688, acc.: 67.97%] [G loss: 0.705657]\n",
      "epoch:7 step:7228 [D loss: 0.570922, acc.: 70.31%] [G loss: 0.533778]\n",
      "epoch:7 step:7229 [D loss: 0.506073, acc.: 78.12%] [G loss: 0.517203]\n",
      "epoch:7 step:7230 [D loss: 0.581929, acc.: 71.88%] [G loss: 0.631528]\n",
      "epoch:7 step:7231 [D loss: 0.581540, acc.: 67.97%] [G loss: 0.675298]\n",
      "epoch:7 step:7232 [D loss: 0.608581, acc.: 71.09%] [G loss: 0.691927]\n",
      "epoch:7 step:7233 [D loss: 0.570500, acc.: 68.75%] [G loss: 0.460387]\n",
      "epoch:7 step:7234 [D loss: 0.596707, acc.: 67.19%] [G loss: 0.662887]\n",
      "epoch:7 step:7235 [D loss: 0.509889, acc.: 75.00%] [G loss: 0.617265]\n",
      "epoch:7 step:7236 [D loss: 0.496118, acc.: 75.78%] [G loss: 0.664999]\n",
      "epoch:7 step:7237 [D loss: 0.553084, acc.: 66.41%] [G loss: 0.587533]\n",
      "epoch:7 step:7238 [D loss: 0.556398, acc.: 66.41%] [G loss: 0.504580]\n",
      "epoch:7 step:7239 [D loss: 0.506468, acc.: 73.44%] [G loss: 0.612392]\n",
      "epoch:7 step:7240 [D loss: 0.515319, acc.: 71.88%] [G loss: 0.520442]\n",
      "epoch:7 step:7241 [D loss: 0.502822, acc.: 75.00%] [G loss: 0.718278]\n",
      "epoch:7 step:7242 [D loss: 0.623730, acc.: 64.84%] [G loss: 0.483879]\n",
      "epoch:7 step:7243 [D loss: 0.558460, acc.: 71.09%] [G loss: 0.621351]\n",
      "epoch:7 step:7244 [D loss: 0.567617, acc.: 71.88%] [G loss: 0.636535]\n",
      "epoch:7 step:7245 [D loss: 0.546506, acc.: 75.00%] [G loss: 0.479062]\n",
      "epoch:7 step:7246 [D loss: 0.581915, acc.: 66.41%] [G loss: 0.451508]\n",
      "epoch:7 step:7247 [D loss: 0.558560, acc.: 72.66%] [G loss: 0.614732]\n",
      "epoch:7 step:7248 [D loss: 0.582194, acc.: 64.84%] [G loss: 0.494532]\n",
      "epoch:7 step:7249 [D loss: 0.548789, acc.: 68.75%] [G loss: 0.562090]\n",
      "epoch:7 step:7250 [D loss: 0.486247, acc.: 78.91%] [G loss: 0.730899]\n",
      "epoch:7 step:7251 [D loss: 0.562760, acc.: 67.19%] [G loss: 0.706303]\n",
      "epoch:7 step:7252 [D loss: 0.501974, acc.: 74.22%] [G loss: 0.726005]\n",
      "epoch:7 step:7253 [D loss: 0.487568, acc.: 79.69%] [G loss: 0.686487]\n",
      "epoch:7 step:7254 [D loss: 0.586262, acc.: 68.75%] [G loss: 0.585937]\n",
      "epoch:7 step:7255 [D loss: 0.578613, acc.: 65.62%] [G loss: 0.500363]\n",
      "epoch:7 step:7256 [D loss: 0.555898, acc.: 64.06%] [G loss: 0.399590]\n",
      "epoch:7 step:7257 [D loss: 0.563780, acc.: 71.09%] [G loss: 0.480392]\n",
      "epoch:7 step:7258 [D loss: 0.508361, acc.: 74.22%] [G loss: 0.566148]\n",
      "epoch:7 step:7259 [D loss: 0.568301, acc.: 71.88%] [G loss: 0.504289]\n",
      "epoch:7 step:7260 [D loss: 0.525121, acc.: 71.88%] [G loss: 0.626476]\n",
      "epoch:7 step:7261 [D loss: 0.642033, acc.: 63.28%] [G loss: 0.647682]\n",
      "epoch:7 step:7262 [D loss: 0.619724, acc.: 68.75%] [G loss: 0.440464]\n",
      "epoch:7 step:7263 [D loss: 0.613317, acc.: 67.97%] [G loss: 0.404984]\n",
      "epoch:7 step:7264 [D loss: 0.536931, acc.: 77.34%] [G loss: 0.468951]\n",
      "epoch:7 step:7265 [D loss: 0.497195, acc.: 75.00%] [G loss: 0.542838]\n",
      "epoch:7 step:7266 [D loss: 0.441678, acc.: 82.81%] [G loss: 0.559231]\n",
      "epoch:7 step:7267 [D loss: 0.520973, acc.: 73.44%] [G loss: 0.720378]\n",
      "epoch:7 step:7268 [D loss: 0.543119, acc.: 71.09%] [G loss: 0.591539]\n",
      "epoch:7 step:7269 [D loss: 0.620845, acc.: 65.62%] [G loss: 0.489420]\n",
      "epoch:7 step:7270 [D loss: 0.571623, acc.: 65.62%] [G loss: 0.549441]\n",
      "epoch:7 step:7271 [D loss: 0.529644, acc.: 69.53%] [G loss: 0.502621]\n",
      "epoch:7 step:7272 [D loss: 0.570906, acc.: 69.53%] [G loss: 0.551163]\n",
      "epoch:7 step:7273 [D loss: 0.532879, acc.: 75.78%] [G loss: 0.424311]\n",
      "epoch:7 step:7274 [D loss: 0.550422, acc.: 70.31%] [G loss: 0.570506]\n",
      "epoch:7 step:7275 [D loss: 0.623163, acc.: 65.62%] [G loss: 0.395209]\n",
      "epoch:7 step:7276 [D loss: 0.585416, acc.: 65.62%] [G loss: 0.446830]\n",
      "epoch:7 step:7277 [D loss: 0.556220, acc.: 71.09%] [G loss: 0.465031]\n",
      "epoch:7 step:7278 [D loss: 0.488743, acc.: 77.34%] [G loss: 0.548225]\n",
      "epoch:7 step:7279 [D loss: 0.590377, acc.: 67.19%] [G loss: 0.648819]\n",
      "epoch:7 step:7280 [D loss: 0.600001, acc.: 65.62%] [G loss: 0.509441]\n",
      "epoch:7 step:7281 [D loss: 0.567562, acc.: 71.09%] [G loss: 0.486315]\n",
      "epoch:7 step:7282 [D loss: 0.592925, acc.: 66.41%] [G loss: 0.468051]\n",
      "epoch:7 step:7283 [D loss: 0.545239, acc.: 71.09%] [G loss: 0.569411]\n",
      "epoch:7 step:7284 [D loss: 0.524803, acc.: 75.00%] [G loss: 0.653734]\n",
      "epoch:7 step:7285 [D loss: 0.566140, acc.: 67.97%] [G loss: 0.647260]\n",
      "epoch:7 step:7286 [D loss: 0.568339, acc.: 71.88%] [G loss: 0.499749]\n",
      "epoch:7 step:7287 [D loss: 0.520954, acc.: 73.44%] [G loss: 0.554219]\n",
      "epoch:7 step:7288 [D loss: 0.648901, acc.: 66.41%] [G loss: 0.505456]\n",
      "epoch:7 step:7289 [D loss: 0.540415, acc.: 71.09%] [G loss: 0.537618]\n",
      "epoch:7 step:7290 [D loss: 0.560336, acc.: 70.31%] [G loss: 0.503280]\n",
      "epoch:7 step:7291 [D loss: 0.462094, acc.: 78.91%] [G loss: 0.606241]\n",
      "epoch:7 step:7292 [D loss: 0.547520, acc.: 74.22%] [G loss: 0.447952]\n",
      "epoch:7 step:7293 [D loss: 0.544985, acc.: 67.97%] [G loss: 0.690472]\n",
      "epoch:7 step:7294 [D loss: 0.547460, acc.: 71.09%] [G loss: 0.491563]\n",
      "epoch:7 step:7295 [D loss: 0.497016, acc.: 74.22%] [G loss: 0.565280]\n",
      "epoch:7 step:7296 [D loss: 0.504076, acc.: 78.12%] [G loss: 0.530325]\n",
      "epoch:7 step:7297 [D loss: 0.544534, acc.: 69.53%] [G loss: 0.523127]\n",
      "epoch:7 step:7298 [D loss: 0.574966, acc.: 66.41%] [G loss: 0.588763]\n",
      "epoch:7 step:7299 [D loss: 0.661055, acc.: 59.38%] [G loss: 0.428827]\n",
      "epoch:7 step:7300 [D loss: 0.568523, acc.: 70.31%] [G loss: 0.435532]\n",
      "epoch:7 step:7301 [D loss: 0.591946, acc.: 71.09%] [G loss: 0.635997]\n",
      "epoch:7 step:7302 [D loss: 0.509095, acc.: 71.88%] [G loss: 0.516617]\n",
      "epoch:7 step:7303 [D loss: 0.583463, acc.: 70.31%] [G loss: 0.571758]\n",
      "epoch:7 step:7304 [D loss: 0.597764, acc.: 67.19%] [G loss: 0.557956]\n",
      "epoch:7 step:7305 [D loss: 0.487150, acc.: 74.22%] [G loss: 0.632117]\n",
      "epoch:7 step:7306 [D loss: 0.482908, acc.: 78.91%] [G loss: 0.657521]\n",
      "epoch:7 step:7307 [D loss: 0.539054, acc.: 74.22%] [G loss: 0.697729]\n",
      "epoch:7 step:7308 [D loss: 0.515133, acc.: 75.00%] [G loss: 0.586990]\n",
      "epoch:7 step:7309 [D loss: 0.505176, acc.: 76.56%] [G loss: 0.592010]\n",
      "epoch:7 step:7310 [D loss: 0.520719, acc.: 75.78%] [G loss: 0.524399]\n",
      "epoch:7 step:7311 [D loss: 0.542076, acc.: 68.75%] [G loss: 0.616645]\n",
      "epoch:7 step:7312 [D loss: 0.509863, acc.: 71.88%] [G loss: 0.397653]\n",
      "epoch:7 step:7313 [D loss: 0.574453, acc.: 65.62%] [G loss: 0.469974]\n",
      "epoch:7 step:7314 [D loss: 0.480402, acc.: 78.12%] [G loss: 0.780851]\n",
      "epoch:7 step:7315 [D loss: 0.552042, acc.: 69.53%] [G loss: 0.553440]\n",
      "epoch:7 step:7316 [D loss: 0.526169, acc.: 75.00%] [G loss: 0.602205]\n",
      "epoch:7 step:7317 [D loss: 0.583407, acc.: 66.41%] [G loss: 0.476742]\n",
      "epoch:7 step:7318 [D loss: 0.558047, acc.: 67.19%] [G loss: 0.496554]\n",
      "epoch:7 step:7319 [D loss: 0.502165, acc.: 75.00%] [G loss: 0.508466]\n",
      "epoch:7 step:7320 [D loss: 0.595365, acc.: 67.19%] [G loss: 0.625311]\n",
      "epoch:7 step:7321 [D loss: 0.612250, acc.: 61.72%] [G loss: 0.536361]\n",
      "epoch:7 step:7322 [D loss: 0.586628, acc.: 69.53%] [G loss: 0.526468]\n",
      "epoch:7 step:7323 [D loss: 0.549722, acc.: 70.31%] [G loss: 0.600239]\n",
      "epoch:7 step:7324 [D loss: 0.651644, acc.: 64.84%] [G loss: 0.490196]\n",
      "epoch:7 step:7325 [D loss: 0.687764, acc.: 57.03%] [G loss: 0.402813]\n",
      "epoch:7 step:7326 [D loss: 0.528096, acc.: 75.00%] [G loss: 0.492974]\n",
      "epoch:7 step:7327 [D loss: 0.463484, acc.: 81.25%] [G loss: 0.769604]\n",
      "epoch:7 step:7328 [D loss: 0.615473, acc.: 67.97%] [G loss: 0.736257]\n",
      "epoch:7 step:7329 [D loss: 0.526622, acc.: 75.00%] [G loss: 0.754955]\n",
      "epoch:7 step:7330 [D loss: 0.499877, acc.: 74.22%] [G loss: 0.880475]\n",
      "epoch:7 step:7331 [D loss: 0.552298, acc.: 74.22%] [G loss: 0.566914]\n",
      "epoch:7 step:7332 [D loss: 0.524420, acc.: 73.44%] [G loss: 0.502848]\n",
      "epoch:7 step:7333 [D loss: 0.576142, acc.: 67.19%] [G loss: 0.542840]\n",
      "epoch:7 step:7334 [D loss: 0.529041, acc.: 71.88%] [G loss: 0.619280]\n",
      "epoch:7 step:7335 [D loss: 0.572207, acc.: 69.53%] [G loss: 0.617218]\n",
      "epoch:7 step:7336 [D loss: 0.569942, acc.: 67.97%] [G loss: 0.535564]\n",
      "epoch:7 step:7337 [D loss: 0.545682, acc.: 70.31%] [G loss: 0.475768]\n",
      "epoch:7 step:7338 [D loss: 0.601297, acc.: 67.19%] [G loss: 0.547640]\n",
      "epoch:7 step:7339 [D loss: 0.546537, acc.: 74.22%] [G loss: 0.644735]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7340 [D loss: 0.515282, acc.: 70.31%] [G loss: 0.686059]\n",
      "epoch:7 step:7341 [D loss: 0.467415, acc.: 75.78%] [G loss: 0.884055]\n",
      "epoch:7 step:7342 [D loss: 0.647976, acc.: 61.72%] [G loss: 0.636922]\n",
      "epoch:7 step:7343 [D loss: 0.586949, acc.: 65.62%] [G loss: 0.509286]\n",
      "epoch:7 step:7344 [D loss: 0.519426, acc.: 76.56%] [G loss: 0.529873]\n",
      "epoch:7 step:7345 [D loss: 0.504829, acc.: 75.78%] [G loss: 0.504444]\n",
      "epoch:7 step:7346 [D loss: 0.602343, acc.: 66.41%] [G loss: 0.604686]\n",
      "epoch:7 step:7347 [D loss: 0.659606, acc.: 59.38%] [G loss: 0.461521]\n",
      "epoch:7 step:7348 [D loss: 0.490174, acc.: 75.78%] [G loss: 0.579106]\n",
      "epoch:7 step:7349 [D loss: 0.511549, acc.: 71.88%] [G loss: 0.633253]\n",
      "epoch:7 step:7350 [D loss: 0.552563, acc.: 69.53%] [G loss: 0.669055]\n",
      "epoch:7 step:7351 [D loss: 0.495051, acc.: 75.00%] [G loss: 0.644937]\n",
      "epoch:7 step:7352 [D loss: 0.592959, acc.: 69.53%] [G loss: 0.584490]\n",
      "epoch:7 step:7353 [D loss: 0.622394, acc.: 65.62%] [G loss: 0.495197]\n",
      "epoch:7 step:7354 [D loss: 0.565045, acc.: 64.06%] [G loss: 0.560545]\n",
      "epoch:7 step:7355 [D loss: 0.571049, acc.: 66.41%] [G loss: 0.549023]\n",
      "epoch:7 step:7356 [D loss: 0.553132, acc.: 72.66%] [G loss: 0.715428]\n",
      "epoch:7 step:7357 [D loss: 0.536147, acc.: 69.53%] [G loss: 0.579713]\n",
      "epoch:7 step:7358 [D loss: 0.600339, acc.: 65.62%] [G loss: 0.565658]\n",
      "epoch:7 step:7359 [D loss: 0.570409, acc.: 71.09%] [G loss: 0.610841]\n",
      "epoch:7 step:7360 [D loss: 0.561747, acc.: 69.53%] [G loss: 0.549798]\n",
      "epoch:7 step:7361 [D loss: 0.509809, acc.: 72.66%] [G loss: 0.838400]\n",
      "epoch:7 step:7362 [D loss: 0.527138, acc.: 73.44%] [G loss: 0.544897]\n",
      "epoch:7 step:7363 [D loss: 0.578053, acc.: 69.53%] [G loss: 0.354049]\n",
      "epoch:7 step:7364 [D loss: 0.488322, acc.: 73.44%] [G loss: 0.677715]\n",
      "epoch:7 step:7365 [D loss: 0.499664, acc.: 73.44%] [G loss: 0.580404]\n",
      "epoch:7 step:7366 [D loss: 0.499510, acc.: 74.22%] [G loss: 0.580299]\n",
      "epoch:7 step:7367 [D loss: 0.570266, acc.: 66.41%] [G loss: 0.547161]\n",
      "epoch:7 step:7368 [D loss: 0.560886, acc.: 69.53%] [G loss: 0.556898]\n",
      "epoch:7 step:7369 [D loss: 0.554261, acc.: 70.31%] [G loss: 0.457529]\n",
      "epoch:7 step:7370 [D loss: 0.568510, acc.: 71.88%] [G loss: 0.541053]\n",
      "epoch:7 step:7371 [D loss: 0.659727, acc.: 56.25%] [G loss: 0.440831]\n",
      "epoch:7 step:7372 [D loss: 0.582690, acc.: 67.97%] [G loss: 0.548923]\n",
      "epoch:7 step:7373 [D loss: 0.555533, acc.: 71.88%] [G loss: 0.549115]\n",
      "epoch:7 step:7374 [D loss: 0.564985, acc.: 71.88%] [G loss: 0.678598]\n",
      "epoch:7 step:7375 [D loss: 0.559530, acc.: 68.75%] [G loss: 0.589098]\n",
      "epoch:7 step:7376 [D loss: 0.562950, acc.: 71.09%] [G loss: 0.579843]\n",
      "epoch:7 step:7377 [D loss: 0.612235, acc.: 64.84%] [G loss: 0.505544]\n",
      "epoch:7 step:7378 [D loss: 0.552391, acc.: 68.75%] [G loss: 0.503420]\n",
      "epoch:7 step:7379 [D loss: 0.619331, acc.: 67.19%] [G loss: 0.496342]\n",
      "epoch:7 step:7380 [D loss: 0.515348, acc.: 78.12%] [G loss: 0.374044]\n",
      "epoch:7 step:7381 [D loss: 0.524433, acc.: 70.31%] [G loss: 0.450852]\n",
      "epoch:7 step:7382 [D loss: 0.463614, acc.: 78.91%] [G loss: 0.485969]\n",
      "epoch:7 step:7383 [D loss: 0.580991, acc.: 69.53%] [G loss: 0.589508]\n",
      "epoch:7 step:7384 [D loss: 0.539787, acc.: 70.31%] [G loss: 0.525805]\n",
      "epoch:7 step:7385 [D loss: 0.579406, acc.: 70.31%] [G loss: 0.509021]\n",
      "epoch:7 step:7386 [D loss: 0.594384, acc.: 67.97%] [G loss: 0.554124]\n",
      "epoch:7 step:7387 [D loss: 0.645653, acc.: 62.50%] [G loss: 0.411872]\n",
      "epoch:7 step:7388 [D loss: 0.485656, acc.: 77.34%] [G loss: 0.500974]\n",
      "epoch:7 step:7389 [D loss: 0.499245, acc.: 76.56%] [G loss: 0.558777]\n",
      "epoch:7 step:7390 [D loss: 0.560716, acc.: 72.66%] [G loss: 0.503723]\n",
      "epoch:7 step:7391 [D loss: 0.544441, acc.: 72.66%] [G loss: 0.609679]\n",
      "epoch:7 step:7392 [D loss: 0.527691, acc.: 77.34%] [G loss: 0.612337]\n",
      "epoch:7 step:7393 [D loss: 0.508371, acc.: 77.34%] [G loss: 0.546821]\n",
      "epoch:7 step:7394 [D loss: 0.524198, acc.: 73.44%] [G loss: 0.631829]\n",
      "epoch:7 step:7395 [D loss: 0.551644, acc.: 73.44%] [G loss: 0.534908]\n",
      "epoch:7 step:7396 [D loss: 0.636258, acc.: 64.84%] [G loss: 0.456244]\n",
      "epoch:7 step:7397 [D loss: 0.503522, acc.: 76.56%] [G loss: 0.494807]\n",
      "epoch:7 step:7398 [D loss: 0.581142, acc.: 67.97%] [G loss: 0.482258]\n",
      "epoch:7 step:7399 [D loss: 0.577382, acc.: 71.88%] [G loss: 0.510580]\n",
      "epoch:7 step:7400 [D loss: 0.527232, acc.: 73.44%] [G loss: 0.388437]\n",
      "##############\n",
      "[3.23499636 1.52944675 6.58598656 4.9438363  4.11119098 5.85113394\n",
      " 5.01754219 4.96427721 4.75199697 3.90253108]\n",
      "##########\n",
      "epoch:7 step:7401 [D loss: 0.491601, acc.: 78.12%] [G loss: 0.430919]\n",
      "epoch:7 step:7402 [D loss: 0.521570, acc.: 71.88%] [G loss: 0.577190]\n",
      "epoch:7 step:7403 [D loss: 0.550875, acc.: 71.09%] [G loss: 0.531364]\n",
      "epoch:7 step:7404 [D loss: 0.563647, acc.: 70.31%] [G loss: 0.454310]\n",
      "epoch:7 step:7405 [D loss: 0.579673, acc.: 64.06%] [G loss: 0.459885]\n",
      "epoch:7 step:7406 [D loss: 0.579959, acc.: 67.19%] [G loss: 0.509479]\n",
      "epoch:7 step:7407 [D loss: 0.497325, acc.: 74.22%] [G loss: 0.512901]\n",
      "epoch:7 step:7408 [D loss: 0.557101, acc.: 70.31%] [G loss: 0.472382]\n",
      "epoch:7 step:7409 [D loss: 0.560704, acc.: 68.75%] [G loss: 0.382387]\n",
      "epoch:7 step:7410 [D loss: 0.588938, acc.: 69.53%] [G loss: 0.467860]\n",
      "epoch:7 step:7411 [D loss: 0.506644, acc.: 77.34%] [G loss: 0.565791]\n",
      "epoch:7 step:7412 [D loss: 0.529997, acc.: 72.66%] [G loss: 0.600847]\n",
      "epoch:7 step:7413 [D loss: 0.511512, acc.: 74.22%] [G loss: 0.577576]\n",
      "epoch:7 step:7414 [D loss: 0.564371, acc.: 71.88%] [G loss: 0.623099]\n",
      "epoch:7 step:7415 [D loss: 0.562890, acc.: 67.19%] [G loss: 0.650502]\n",
      "epoch:7 step:7416 [D loss: 0.471466, acc.: 81.25%] [G loss: 0.710281]\n",
      "epoch:7 step:7417 [D loss: 0.696622, acc.: 56.25%] [G loss: 0.529936]\n",
      "epoch:7 step:7418 [D loss: 0.564969, acc.: 67.97%] [G loss: 0.526547]\n",
      "epoch:7 step:7419 [D loss: 0.459628, acc.: 78.12%] [G loss: 0.735058]\n",
      "epoch:7 step:7420 [D loss: 0.592621, acc.: 70.31%] [G loss: 0.518539]\n",
      "epoch:7 step:7421 [D loss: 0.519964, acc.: 73.44%] [G loss: 0.574717]\n",
      "epoch:7 step:7422 [D loss: 0.600174, acc.: 68.75%] [G loss: 0.496701]\n",
      "epoch:7 step:7423 [D loss: 0.516690, acc.: 73.44%] [G loss: 0.530881]\n",
      "epoch:7 step:7424 [D loss: 0.574702, acc.: 65.62%] [G loss: 0.421353]\n",
      "epoch:7 step:7425 [D loss: 0.571913, acc.: 67.97%] [G loss: 0.453666]\n",
      "epoch:7 step:7426 [D loss: 0.660339, acc.: 60.94%] [G loss: 0.339605]\n",
      "epoch:7 step:7427 [D loss: 0.539813, acc.: 71.09%] [G loss: 0.609100]\n",
      "epoch:7 step:7428 [D loss: 0.545038, acc.: 74.22%] [G loss: 0.423593]\n",
      "epoch:7 step:7429 [D loss: 0.504314, acc.: 72.66%] [G loss: 0.553986]\n",
      "epoch:7 step:7430 [D loss: 0.520944, acc.: 72.66%] [G loss: 0.550111]\n",
      "epoch:7 step:7431 [D loss: 0.535728, acc.: 74.22%] [G loss: 0.644700]\n",
      "epoch:7 step:7432 [D loss: 0.586568, acc.: 63.28%] [G loss: 0.430368]\n",
      "epoch:7 step:7433 [D loss: 0.507040, acc.: 76.56%] [G loss: 0.491103]\n",
      "epoch:7 step:7434 [D loss: 0.489316, acc.: 75.00%] [G loss: 0.487514]\n",
      "epoch:7 step:7435 [D loss: 0.541948, acc.: 71.09%] [G loss: 0.562056]\n",
      "epoch:7 step:7436 [D loss: 0.576065, acc.: 71.88%] [G loss: 0.617309]\n",
      "epoch:7 step:7437 [D loss: 0.580627, acc.: 65.62%] [G loss: 0.383699]\n",
      "epoch:7 step:7438 [D loss: 0.596025, acc.: 67.97%] [G loss: 0.440042]\n",
      "epoch:7 step:7439 [D loss: 0.684982, acc.: 57.03%] [G loss: 0.458667]\n",
      "epoch:7 step:7440 [D loss: 0.570004, acc.: 72.66%] [G loss: 0.623247]\n",
      "epoch:7 step:7441 [D loss: 0.639803, acc.: 60.16%] [G loss: 0.398284]\n",
      "epoch:7 step:7442 [D loss: 0.611229, acc.: 60.16%] [G loss: 0.510645]\n",
      "epoch:7 step:7443 [D loss: 0.492355, acc.: 77.34%] [G loss: 0.628503]\n",
      "epoch:7 step:7444 [D loss: 0.584397, acc.: 66.41%] [G loss: 0.622756]\n",
      "epoch:7 step:7445 [D loss: 0.529206, acc.: 73.44%] [G loss: 0.494803]\n",
      "epoch:7 step:7446 [D loss: 0.552804, acc.: 67.19%] [G loss: 0.620914]\n",
      "epoch:7 step:7447 [D loss: 0.488453, acc.: 75.78%] [G loss: 0.564317]\n",
      "epoch:7 step:7448 [D loss: 0.523266, acc.: 75.78%] [G loss: 0.545899]\n",
      "epoch:7 step:7449 [D loss: 0.469471, acc.: 77.34%] [G loss: 0.650819]\n",
      "epoch:7 step:7450 [D loss: 0.606841, acc.: 64.06%] [G loss: 0.554816]\n",
      "epoch:7 step:7451 [D loss: 0.603878, acc.: 65.62%] [G loss: 0.381598]\n",
      "epoch:7 step:7452 [D loss: 0.523380, acc.: 73.44%] [G loss: 0.480595]\n",
      "epoch:7 step:7453 [D loss: 0.480587, acc.: 79.69%] [G loss: 0.643364]\n",
      "epoch:7 step:7454 [D loss: 0.531940, acc.: 71.88%] [G loss: 0.742548]\n",
      "epoch:7 step:7455 [D loss: 0.557145, acc.: 71.88%] [G loss: 0.539586]\n",
      "epoch:7 step:7456 [D loss: 0.521195, acc.: 72.66%] [G loss: 0.517803]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7457 [D loss: 0.495014, acc.: 78.12%] [G loss: 0.634066]\n",
      "epoch:7 step:7458 [D loss: 0.510162, acc.: 77.34%] [G loss: 0.639352]\n",
      "epoch:7 step:7459 [D loss: 0.551699, acc.: 74.22%] [G loss: 0.646644]\n",
      "epoch:7 step:7460 [D loss: 0.557067, acc.: 68.75%] [G loss: 0.759386]\n",
      "epoch:7 step:7461 [D loss: 0.559765, acc.: 62.50%] [G loss: 0.509601]\n",
      "epoch:7 step:7462 [D loss: 0.531014, acc.: 68.75%] [G loss: 0.576617]\n",
      "epoch:7 step:7463 [D loss: 0.578282, acc.: 68.75%] [G loss: 0.507772]\n",
      "epoch:7 step:7464 [D loss: 0.562856, acc.: 71.09%] [G loss: 0.619794]\n",
      "epoch:7 step:7465 [D loss: 0.513205, acc.: 73.44%] [G loss: 0.803571]\n",
      "epoch:7 step:7466 [D loss: 0.510452, acc.: 74.22%] [G loss: 0.640903]\n",
      "epoch:7 step:7467 [D loss: 0.538692, acc.: 73.44%] [G loss: 0.661810]\n",
      "epoch:7 step:7468 [D loss: 0.536905, acc.: 74.22%] [G loss: 0.621357]\n",
      "epoch:7 step:7469 [D loss: 0.510180, acc.: 77.34%] [G loss: 0.729358]\n",
      "epoch:7 step:7470 [D loss: 0.459832, acc.: 76.56%] [G loss: 0.738937]\n",
      "epoch:7 step:7471 [D loss: 0.432183, acc.: 79.69%] [G loss: 0.804985]\n",
      "epoch:7 step:7472 [D loss: 0.577484, acc.: 67.97%] [G loss: 0.773857]\n",
      "epoch:7 step:7473 [D loss: 0.479606, acc.: 78.91%] [G loss: 0.792068]\n",
      "epoch:7 step:7474 [D loss: 0.661456, acc.: 60.94%] [G loss: 0.557998]\n",
      "epoch:7 step:7475 [D loss: 0.586539, acc.: 66.41%] [G loss: 0.631175]\n",
      "epoch:7 step:7476 [D loss: 0.590995, acc.: 63.28%] [G loss: 0.531314]\n",
      "epoch:7 step:7477 [D loss: 0.427226, acc.: 82.81%] [G loss: 0.620683]\n",
      "epoch:7 step:7478 [D loss: 0.527394, acc.: 67.19%] [G loss: 0.682168]\n",
      "epoch:7 step:7479 [D loss: 0.685690, acc.: 64.84%] [G loss: 0.601856]\n",
      "epoch:7 step:7480 [D loss: 0.493227, acc.: 76.56%] [G loss: 0.697005]\n",
      "epoch:7 step:7481 [D loss: 0.560358, acc.: 67.19%] [G loss: 0.526505]\n",
      "epoch:7 step:7482 [D loss: 0.496067, acc.: 74.22%] [G loss: 0.737817]\n",
      "epoch:7 step:7483 [D loss: 0.451253, acc.: 79.69%] [G loss: 0.700916]\n",
      "epoch:7 step:7484 [D loss: 0.465318, acc.: 73.44%] [G loss: 0.802781]\n",
      "epoch:7 step:7485 [D loss: 0.426893, acc.: 78.91%] [G loss: 0.966489]\n",
      "epoch:7 step:7486 [D loss: 0.478638, acc.: 75.78%] [G loss: 1.288378]\n",
      "epoch:7 step:7487 [D loss: 0.789532, acc.: 62.50%] [G loss: 1.053046]\n",
      "epoch:7 step:7488 [D loss: 0.514251, acc.: 71.09%] [G loss: 1.050353]\n",
      "epoch:7 step:7489 [D loss: 0.487239, acc.: 75.00%] [G loss: 1.021064]\n",
      "epoch:7 step:7490 [D loss: 0.572935, acc.: 72.66%] [G loss: 0.692222]\n",
      "epoch:7 step:7491 [D loss: 0.661442, acc.: 65.62%] [G loss: 0.694822]\n",
      "epoch:7 step:7492 [D loss: 0.435559, acc.: 79.69%] [G loss: 0.822228]\n",
      "epoch:7 step:7493 [D loss: 0.496836, acc.: 73.44%] [G loss: 0.654940]\n",
      "epoch:7 step:7494 [D loss: 0.447477, acc.: 84.38%] [G loss: 0.702126]\n",
      "epoch:7 step:7495 [D loss: 0.438005, acc.: 75.00%] [G loss: 0.999338]\n",
      "epoch:7 step:7496 [D loss: 0.496099, acc.: 73.44%] [G loss: 1.091276]\n",
      "epoch:8 step:7497 [D loss: 0.631408, acc.: 64.84%] [G loss: 1.073094]\n",
      "epoch:8 step:7498 [D loss: 0.479448, acc.: 76.56%] [G loss: 0.997344]\n",
      "epoch:8 step:7499 [D loss: 0.571277, acc.: 72.66%] [G loss: 0.824891]\n",
      "epoch:8 step:7500 [D loss: 0.504133, acc.: 75.00%] [G loss: 0.676483]\n",
      "epoch:8 step:7501 [D loss: 0.557544, acc.: 75.00%] [G loss: 0.496084]\n",
      "epoch:8 step:7502 [D loss: 0.556368, acc.: 71.88%] [G loss: 0.536376]\n",
      "epoch:8 step:7503 [D loss: 0.487464, acc.: 77.34%] [G loss: 0.685085]\n",
      "epoch:8 step:7504 [D loss: 0.534175, acc.: 74.22%] [G loss: 0.744915]\n",
      "epoch:8 step:7505 [D loss: 0.501035, acc.: 76.56%] [G loss: 0.617186]\n",
      "epoch:8 step:7506 [D loss: 0.520345, acc.: 75.78%] [G loss: 0.869857]\n",
      "epoch:8 step:7507 [D loss: 0.476580, acc.: 76.56%] [G loss: 0.779318]\n",
      "epoch:8 step:7508 [D loss: 0.624215, acc.: 61.72%] [G loss: 0.541030]\n",
      "epoch:8 step:7509 [D loss: 0.542480, acc.: 71.09%] [G loss: 0.535081]\n",
      "epoch:8 step:7510 [D loss: 0.556643, acc.: 74.22%] [G loss: 0.497697]\n",
      "epoch:8 step:7511 [D loss: 0.488761, acc.: 76.56%] [G loss: 0.678756]\n",
      "epoch:8 step:7512 [D loss: 0.494900, acc.: 78.12%] [G loss: 0.573944]\n",
      "epoch:8 step:7513 [D loss: 0.572851, acc.: 63.28%] [G loss: 0.571934]\n",
      "epoch:8 step:7514 [D loss: 0.668190, acc.: 56.25%] [G loss: 0.547074]\n",
      "epoch:8 step:7515 [D loss: 0.580461, acc.: 70.31%] [G loss: 0.584652]\n",
      "epoch:8 step:7516 [D loss: 0.629039, acc.: 60.16%] [G loss: 0.685072]\n",
      "epoch:8 step:7517 [D loss: 0.577389, acc.: 70.31%] [G loss: 0.526961]\n",
      "epoch:8 step:7518 [D loss: 0.482389, acc.: 80.47%] [G loss: 0.798337]\n",
      "epoch:8 step:7519 [D loss: 0.516071, acc.: 75.00%] [G loss: 0.565192]\n",
      "epoch:8 step:7520 [D loss: 0.551484, acc.: 66.41%] [G loss: 0.635714]\n",
      "epoch:8 step:7521 [D loss: 0.552942, acc.: 72.66%] [G loss: 0.569456]\n",
      "epoch:8 step:7522 [D loss: 0.575659, acc.: 68.75%] [G loss: 0.600273]\n",
      "epoch:8 step:7523 [D loss: 0.498581, acc.: 75.78%] [G loss: 0.549444]\n",
      "epoch:8 step:7524 [D loss: 0.553189, acc.: 71.09%] [G loss: 0.478965]\n",
      "epoch:8 step:7525 [D loss: 0.431293, acc.: 88.28%] [G loss: 0.530246]\n",
      "epoch:8 step:7526 [D loss: 0.558247, acc.: 73.44%] [G loss: 0.417957]\n",
      "epoch:8 step:7527 [D loss: 0.581125, acc.: 68.75%] [G loss: 0.433648]\n",
      "epoch:8 step:7528 [D loss: 0.554751, acc.: 70.31%] [G loss: 0.524446]\n",
      "epoch:8 step:7529 [D loss: 0.524063, acc.: 67.19%] [G loss: 0.569368]\n",
      "epoch:8 step:7530 [D loss: 0.540125, acc.: 68.75%] [G loss: 0.448557]\n",
      "epoch:8 step:7531 [D loss: 0.552614, acc.: 73.44%] [G loss: 0.682850]\n",
      "epoch:8 step:7532 [D loss: 0.509671, acc.: 75.00%] [G loss: 0.591054]\n",
      "epoch:8 step:7533 [D loss: 0.528136, acc.: 73.44%] [G loss: 0.532040]\n",
      "epoch:8 step:7534 [D loss: 0.574324, acc.: 73.44%] [G loss: 0.604157]\n",
      "epoch:8 step:7535 [D loss: 0.522377, acc.: 71.09%] [G loss: 0.661458]\n",
      "epoch:8 step:7536 [D loss: 0.471403, acc.: 75.78%] [G loss: 0.718487]\n",
      "epoch:8 step:7537 [D loss: 0.478692, acc.: 77.34%] [G loss: 0.732381]\n",
      "epoch:8 step:7538 [D loss: 0.522017, acc.: 70.31%] [G loss: 0.568936]\n",
      "epoch:8 step:7539 [D loss: 0.551181, acc.: 68.75%] [G loss: 0.749512]\n",
      "epoch:8 step:7540 [D loss: 0.600637, acc.: 61.72%] [G loss: 0.587762]\n",
      "epoch:8 step:7541 [D loss: 0.511692, acc.: 74.22%] [G loss: 0.556895]\n",
      "epoch:8 step:7542 [D loss: 0.557398, acc.: 71.09%] [G loss: 0.542845]\n",
      "epoch:8 step:7543 [D loss: 0.537166, acc.: 70.31%] [G loss: 0.511064]\n",
      "epoch:8 step:7544 [D loss: 0.533304, acc.: 71.88%] [G loss: 0.423006]\n",
      "epoch:8 step:7545 [D loss: 0.547774, acc.: 70.31%] [G loss: 0.565953]\n",
      "epoch:8 step:7546 [D loss: 0.564424, acc.: 68.75%] [G loss: 0.536357]\n",
      "epoch:8 step:7547 [D loss: 0.595628, acc.: 67.19%] [G loss: 0.531713]\n",
      "epoch:8 step:7548 [D loss: 0.561327, acc.: 68.75%] [G loss: 0.517481]\n",
      "epoch:8 step:7549 [D loss: 0.559086, acc.: 70.31%] [G loss: 0.510098]\n",
      "epoch:8 step:7550 [D loss: 0.553705, acc.: 67.19%] [G loss: 0.546943]\n",
      "epoch:8 step:7551 [D loss: 0.567236, acc.: 70.31%] [G loss: 0.612530]\n",
      "epoch:8 step:7552 [D loss: 0.466184, acc.: 79.69%] [G loss: 0.836485]\n",
      "epoch:8 step:7553 [D loss: 0.547287, acc.: 70.31%] [G loss: 0.624620]\n",
      "epoch:8 step:7554 [D loss: 0.605905, acc.: 61.72%] [G loss: 0.574227]\n",
      "epoch:8 step:7555 [D loss: 0.541710, acc.: 72.66%] [G loss: 0.622050]\n",
      "epoch:8 step:7556 [D loss: 0.544996, acc.: 71.09%] [G loss: 0.614150]\n",
      "epoch:8 step:7557 [D loss: 0.531751, acc.: 71.88%] [G loss: 0.624549]\n",
      "epoch:8 step:7558 [D loss: 0.571370, acc.: 69.53%] [G loss: 0.596216]\n",
      "epoch:8 step:7559 [D loss: 0.572392, acc.: 66.41%] [G loss: 0.502494]\n",
      "epoch:8 step:7560 [D loss: 0.573079, acc.: 71.88%] [G loss: 0.616571]\n",
      "epoch:8 step:7561 [D loss: 0.518003, acc.: 76.56%] [G loss: 0.431986]\n",
      "epoch:8 step:7562 [D loss: 0.526795, acc.: 71.09%] [G loss: 0.474600]\n",
      "epoch:8 step:7563 [D loss: 0.568431, acc.: 71.88%] [G loss: 0.381440]\n",
      "epoch:8 step:7564 [D loss: 0.558851, acc.: 68.75%] [G loss: 0.488383]\n",
      "epoch:8 step:7565 [D loss: 0.514416, acc.: 75.78%] [G loss: 0.556625]\n",
      "epoch:8 step:7566 [D loss: 0.531166, acc.: 75.00%] [G loss: 0.611873]\n",
      "epoch:8 step:7567 [D loss: 0.533295, acc.: 74.22%] [G loss: 0.518716]\n",
      "epoch:8 step:7568 [D loss: 0.527963, acc.: 75.78%] [G loss: 0.638281]\n",
      "epoch:8 step:7569 [D loss: 0.540176, acc.: 71.88%] [G loss: 0.539290]\n",
      "epoch:8 step:7570 [D loss: 0.493538, acc.: 78.12%] [G loss: 0.638733]\n",
      "epoch:8 step:7571 [D loss: 0.527077, acc.: 73.44%] [G loss: 0.672143]\n",
      "epoch:8 step:7572 [D loss: 0.562928, acc.: 65.62%] [G loss: 0.580097]\n",
      "epoch:8 step:7573 [D loss: 0.452572, acc.: 78.12%] [G loss: 0.675510]\n",
      "epoch:8 step:7574 [D loss: 0.550504, acc.: 71.88%] [G loss: 0.586951]\n",
      "epoch:8 step:7575 [D loss: 0.554357, acc.: 71.88%] [G loss: 0.579296]\n",
      "epoch:8 step:7576 [D loss: 0.555438, acc.: 71.09%] [G loss: 0.525550]\n",
      "epoch:8 step:7577 [D loss: 0.562664, acc.: 71.88%] [G loss: 0.557627]\n",
      "epoch:8 step:7578 [D loss: 0.494014, acc.: 77.34%] [G loss: 0.651977]\n",
      "epoch:8 step:7579 [D loss: 0.524812, acc.: 71.88%] [G loss: 0.555776]\n",
      "epoch:8 step:7580 [D loss: 0.535659, acc.: 73.44%] [G loss: 0.618999]\n",
      "epoch:8 step:7581 [D loss: 0.554057, acc.: 69.53%] [G loss: 0.568361]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7582 [D loss: 0.571186, acc.: 71.88%] [G loss: 0.456408]\n",
      "epoch:8 step:7583 [D loss: 0.546963, acc.: 71.88%] [G loss: 0.641362]\n",
      "epoch:8 step:7584 [D loss: 0.514516, acc.: 73.44%] [G loss: 0.628706]\n",
      "epoch:8 step:7585 [D loss: 0.502835, acc.: 73.44%] [G loss: 0.614818]\n",
      "epoch:8 step:7586 [D loss: 0.486838, acc.: 77.34%] [G loss: 0.704118]\n",
      "epoch:8 step:7587 [D loss: 0.539260, acc.: 71.88%] [G loss: 0.668574]\n",
      "epoch:8 step:7588 [D loss: 0.491219, acc.: 78.12%] [G loss: 0.637944]\n",
      "epoch:8 step:7589 [D loss: 0.549727, acc.: 64.84%] [G loss: 0.579019]\n",
      "epoch:8 step:7590 [D loss: 0.534376, acc.: 75.78%] [G loss: 0.622288]\n",
      "epoch:8 step:7591 [D loss: 0.535024, acc.: 72.66%] [G loss: 0.607972]\n",
      "epoch:8 step:7592 [D loss: 0.509270, acc.: 76.56%] [G loss: 0.567539]\n",
      "epoch:8 step:7593 [D loss: 0.532410, acc.: 71.09%] [G loss: 0.576383]\n",
      "epoch:8 step:7594 [D loss: 0.578863, acc.: 68.75%] [G loss: 0.628779]\n",
      "epoch:8 step:7595 [D loss: 0.546008, acc.: 69.53%] [G loss: 0.486379]\n",
      "epoch:8 step:7596 [D loss: 0.504760, acc.: 74.22%] [G loss: 0.707052]\n",
      "epoch:8 step:7597 [D loss: 0.539609, acc.: 68.75%] [G loss: 0.760197]\n",
      "epoch:8 step:7598 [D loss: 0.608470, acc.: 64.84%] [G loss: 0.494360]\n",
      "epoch:8 step:7599 [D loss: 0.450633, acc.: 82.81%] [G loss: 0.673690]\n",
      "epoch:8 step:7600 [D loss: 0.516753, acc.: 69.53%] [G loss: 0.547653]\n",
      "##############\n",
      "[3.09771889 1.04743383 6.34734162 4.97016903 3.97642018 5.95912061\n",
      " 4.69576992 4.7845944  4.57825072 3.78751392]\n",
      "##########\n",
      "epoch:8 step:7601 [D loss: 0.583251, acc.: 65.62%] [G loss: 0.345405]\n",
      "epoch:8 step:7602 [D loss: 0.535924, acc.: 73.44%] [G loss: 0.579456]\n",
      "epoch:8 step:7603 [D loss: 0.598878, acc.: 64.84%] [G loss: 0.535493]\n",
      "epoch:8 step:7604 [D loss: 0.637049, acc.: 66.41%] [G loss: 0.592952]\n",
      "epoch:8 step:7605 [D loss: 0.603538, acc.: 63.28%] [G loss: 0.527508]\n",
      "epoch:8 step:7606 [D loss: 0.616770, acc.: 65.62%] [G loss: 0.546043]\n",
      "epoch:8 step:7607 [D loss: 0.518235, acc.: 71.09%] [G loss: 0.548424]\n",
      "epoch:8 step:7608 [D loss: 0.577926, acc.: 71.88%] [G loss: 0.509310]\n",
      "epoch:8 step:7609 [D loss: 0.546725, acc.: 72.66%] [G loss: 0.529694]\n",
      "epoch:8 step:7610 [D loss: 0.582131, acc.: 68.75%] [G loss: 0.495207]\n",
      "epoch:8 step:7611 [D loss: 0.562283, acc.: 69.53%] [G loss: 0.519283]\n",
      "epoch:8 step:7612 [D loss: 0.548068, acc.: 69.53%] [G loss: 0.444802]\n",
      "epoch:8 step:7613 [D loss: 0.524541, acc.: 72.66%] [G loss: 0.720085]\n",
      "epoch:8 step:7614 [D loss: 0.513143, acc.: 71.88%] [G loss: 0.789014]\n",
      "epoch:8 step:7615 [D loss: 0.460425, acc.: 79.69%] [G loss: 0.907151]\n",
      "epoch:8 step:7616 [D loss: 0.680948, acc.: 65.62%] [G loss: 0.480833]\n",
      "epoch:8 step:7617 [D loss: 0.561697, acc.: 67.97%] [G loss: 0.578580]\n",
      "epoch:8 step:7618 [D loss: 0.550306, acc.: 72.66%] [G loss: 0.727097]\n",
      "epoch:8 step:7619 [D loss: 0.561981, acc.: 67.97%] [G loss: 0.707121]\n",
      "epoch:8 step:7620 [D loss: 0.578736, acc.: 69.53%] [G loss: 0.512074]\n",
      "epoch:8 step:7621 [D loss: 0.528763, acc.: 74.22%] [G loss: 0.561946]\n",
      "epoch:8 step:7622 [D loss: 0.525308, acc.: 75.00%] [G loss: 0.604741]\n",
      "epoch:8 step:7623 [D loss: 0.489822, acc.: 76.56%] [G loss: 0.508805]\n",
      "epoch:8 step:7624 [D loss: 0.507050, acc.: 75.00%] [G loss: 0.529251]\n",
      "epoch:8 step:7625 [D loss: 0.596820, acc.: 66.41%] [G loss: 0.527648]\n",
      "epoch:8 step:7626 [D loss: 0.563549, acc.: 71.88%] [G loss: 0.524072]\n",
      "epoch:8 step:7627 [D loss: 0.503729, acc.: 73.44%] [G loss: 0.620799]\n",
      "epoch:8 step:7628 [D loss: 0.587227, acc.: 66.41%] [G loss: 0.508776]\n",
      "epoch:8 step:7629 [D loss: 0.600075, acc.: 70.31%] [G loss: 0.567022]\n",
      "epoch:8 step:7630 [D loss: 0.539470, acc.: 74.22%] [G loss: 0.570555]\n",
      "epoch:8 step:7631 [D loss: 0.525448, acc.: 76.56%] [G loss: 0.597369]\n",
      "epoch:8 step:7632 [D loss: 0.552511, acc.: 70.31%] [G loss: 0.584275]\n",
      "epoch:8 step:7633 [D loss: 0.735459, acc.: 59.38%] [G loss: 0.474993]\n",
      "epoch:8 step:7634 [D loss: 0.547029, acc.: 68.75%] [G loss: 0.589829]\n",
      "epoch:8 step:7635 [D loss: 0.560139, acc.: 70.31%] [G loss: 0.616610]\n",
      "epoch:8 step:7636 [D loss: 0.559141, acc.: 67.19%] [G loss: 0.523845]\n",
      "epoch:8 step:7637 [D loss: 0.519257, acc.: 70.31%] [G loss: 0.630209]\n",
      "epoch:8 step:7638 [D loss: 0.580379, acc.: 68.75%] [G loss: 0.591649]\n",
      "epoch:8 step:7639 [D loss: 0.605110, acc.: 61.72%] [G loss: 0.533270]\n",
      "epoch:8 step:7640 [D loss: 0.482056, acc.: 77.34%] [G loss: 0.583352]\n",
      "epoch:8 step:7641 [D loss: 0.495571, acc.: 75.78%] [G loss: 0.623269]\n",
      "epoch:8 step:7642 [D loss: 0.516747, acc.: 75.78%] [G loss: 0.487758]\n",
      "epoch:8 step:7643 [D loss: 0.664285, acc.: 66.41%] [G loss: 0.618687]\n",
      "epoch:8 step:7644 [D loss: 0.549673, acc.: 71.88%] [G loss: 0.495376]\n",
      "epoch:8 step:7645 [D loss: 0.508931, acc.: 77.34%] [G loss: 0.600538]\n",
      "epoch:8 step:7646 [D loss: 0.573047, acc.: 70.31%] [G loss: 0.608811]\n",
      "epoch:8 step:7647 [D loss: 0.563111, acc.: 71.88%] [G loss: 0.624987]\n",
      "epoch:8 step:7648 [D loss: 0.472903, acc.: 78.12%] [G loss: 0.650041]\n",
      "epoch:8 step:7649 [D loss: 0.616714, acc.: 66.41%] [G loss: 0.697493]\n",
      "epoch:8 step:7650 [D loss: 0.525070, acc.: 71.09%] [G loss: 0.693151]\n",
      "epoch:8 step:7651 [D loss: 0.446978, acc.: 83.59%] [G loss: 0.602460]\n",
      "epoch:8 step:7652 [D loss: 0.494973, acc.: 74.22%] [G loss: 0.715005]\n",
      "epoch:8 step:7653 [D loss: 0.577615, acc.: 63.28%] [G loss: 0.577108]\n",
      "epoch:8 step:7654 [D loss: 0.532305, acc.: 73.44%] [G loss: 0.588616]\n",
      "epoch:8 step:7655 [D loss: 0.550483, acc.: 75.78%] [G loss: 0.390242]\n",
      "epoch:8 step:7656 [D loss: 0.585475, acc.: 67.19%] [G loss: 0.584858]\n",
      "epoch:8 step:7657 [D loss: 0.562082, acc.: 68.75%] [G loss: 0.679150]\n",
      "epoch:8 step:7658 [D loss: 0.462191, acc.: 78.91%] [G loss: 0.694743]\n",
      "epoch:8 step:7659 [D loss: 0.529943, acc.: 73.44%] [G loss: 0.619086]\n",
      "epoch:8 step:7660 [D loss: 0.560016, acc.: 65.62%] [G loss: 0.501645]\n",
      "epoch:8 step:7661 [D loss: 0.506704, acc.: 72.66%] [G loss: 0.554387]\n",
      "epoch:8 step:7662 [D loss: 0.601162, acc.: 59.38%] [G loss: 0.532397]\n",
      "epoch:8 step:7663 [D loss: 0.537161, acc.: 73.44%] [G loss: 0.465988]\n",
      "epoch:8 step:7664 [D loss: 0.583000, acc.: 71.09%] [G loss: 0.528128]\n",
      "epoch:8 step:7665 [D loss: 0.573798, acc.: 67.19%] [G loss: 0.512609]\n",
      "epoch:8 step:7666 [D loss: 0.543881, acc.: 69.53%] [G loss: 0.408116]\n",
      "epoch:8 step:7667 [D loss: 0.541666, acc.: 74.22%] [G loss: 0.538442]\n",
      "epoch:8 step:7668 [D loss: 0.508842, acc.: 74.22%] [G loss: 0.512070]\n",
      "epoch:8 step:7669 [D loss: 0.502794, acc.: 73.44%] [G loss: 0.625774]\n",
      "epoch:8 step:7670 [D loss: 0.628949, acc.: 63.28%] [G loss: 0.487460]\n",
      "epoch:8 step:7671 [D loss: 0.597587, acc.: 68.75%] [G loss: 0.541393]\n",
      "epoch:8 step:7672 [D loss: 0.563936, acc.: 65.62%] [G loss: 0.599423]\n",
      "epoch:8 step:7673 [D loss: 0.529225, acc.: 71.88%] [G loss: 0.605904]\n",
      "epoch:8 step:7674 [D loss: 0.547704, acc.: 69.53%] [G loss: 0.545665]\n",
      "epoch:8 step:7675 [D loss: 0.535540, acc.: 71.09%] [G loss: 0.683146]\n",
      "epoch:8 step:7676 [D loss: 0.637718, acc.: 64.84%] [G loss: 0.457180]\n",
      "epoch:8 step:7677 [D loss: 0.592941, acc.: 67.97%] [G loss: 0.450688]\n",
      "epoch:8 step:7678 [D loss: 0.602591, acc.: 66.41%] [G loss: 0.512049]\n",
      "epoch:8 step:7679 [D loss: 0.541914, acc.: 69.53%] [G loss: 0.618776]\n",
      "epoch:8 step:7680 [D loss: 0.589069, acc.: 69.53%] [G loss: 0.543703]\n",
      "epoch:8 step:7681 [D loss: 0.535778, acc.: 74.22%] [G loss: 0.670568]\n",
      "epoch:8 step:7682 [D loss: 0.534093, acc.: 68.75%] [G loss: 0.611834]\n",
      "epoch:8 step:7683 [D loss: 0.606063, acc.: 60.16%] [G loss: 0.516756]\n",
      "epoch:8 step:7684 [D loss: 0.577788, acc.: 64.06%] [G loss: 0.417505]\n",
      "epoch:8 step:7685 [D loss: 0.545478, acc.: 69.53%] [G loss: 0.631316]\n",
      "epoch:8 step:7686 [D loss: 0.507929, acc.: 74.22%] [G loss: 0.520355]\n",
      "epoch:8 step:7687 [D loss: 0.523547, acc.: 73.44%] [G loss: 0.505275]\n",
      "epoch:8 step:7688 [D loss: 0.526743, acc.: 75.00%] [G loss: 0.512289]\n",
      "epoch:8 step:7689 [D loss: 0.553322, acc.: 72.66%] [G loss: 0.508234]\n",
      "epoch:8 step:7690 [D loss: 0.493427, acc.: 80.47%] [G loss: 0.595510]\n",
      "epoch:8 step:7691 [D loss: 0.609543, acc.: 69.53%] [G loss: 0.719644]\n",
      "epoch:8 step:7692 [D loss: 0.620979, acc.: 66.41%] [G loss: 0.529164]\n",
      "epoch:8 step:7693 [D loss: 0.537643, acc.: 67.97%] [G loss: 0.584765]\n",
      "epoch:8 step:7694 [D loss: 0.479783, acc.: 78.12%] [G loss: 0.590475]\n",
      "epoch:8 step:7695 [D loss: 0.565823, acc.: 63.28%] [G loss: 0.638946]\n",
      "epoch:8 step:7696 [D loss: 0.596669, acc.: 64.84%] [G loss: 0.626865]\n",
      "epoch:8 step:7697 [D loss: 0.606435, acc.: 69.53%] [G loss: 0.530617]\n",
      "epoch:8 step:7698 [D loss: 0.549529, acc.: 70.31%] [G loss: 0.665581]\n",
      "epoch:8 step:7699 [D loss: 0.638527, acc.: 69.53%] [G loss: 0.553084]\n",
      "epoch:8 step:7700 [D loss: 0.567043, acc.: 64.84%] [G loss: 0.446243]\n",
      "epoch:8 step:7701 [D loss: 0.527212, acc.: 73.44%] [G loss: 0.528432]\n",
      "epoch:8 step:7702 [D loss: 0.465382, acc.: 73.44%] [G loss: 0.666253]\n",
      "epoch:8 step:7703 [D loss: 0.420064, acc.: 82.81%] [G loss: 0.747083]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7704 [D loss: 0.465055, acc.: 75.78%] [G loss: 0.831364]\n",
      "epoch:8 step:7705 [D loss: 0.509062, acc.: 74.22%] [G loss: 0.708830]\n",
      "epoch:8 step:7706 [D loss: 0.647693, acc.: 60.16%] [G loss: 0.478395]\n",
      "epoch:8 step:7707 [D loss: 0.599345, acc.: 66.41%] [G loss: 0.427892]\n",
      "epoch:8 step:7708 [D loss: 0.510340, acc.: 67.97%] [G loss: 0.487642]\n",
      "epoch:8 step:7709 [D loss: 0.538178, acc.: 68.75%] [G loss: 0.451902]\n",
      "epoch:8 step:7710 [D loss: 0.643996, acc.: 62.50%] [G loss: 0.452217]\n",
      "epoch:8 step:7711 [D loss: 0.610341, acc.: 61.72%] [G loss: 0.377171]\n",
      "epoch:8 step:7712 [D loss: 0.519501, acc.: 75.00%] [G loss: 0.505083]\n",
      "epoch:8 step:7713 [D loss: 0.510168, acc.: 74.22%] [G loss: 0.565404]\n",
      "epoch:8 step:7714 [D loss: 0.562467, acc.: 66.41%] [G loss: 0.429575]\n",
      "epoch:8 step:7715 [D loss: 0.529649, acc.: 72.66%] [G loss: 0.623130]\n",
      "epoch:8 step:7716 [D loss: 0.693736, acc.: 56.25%] [G loss: 0.468581]\n",
      "epoch:8 step:7717 [D loss: 0.568352, acc.: 66.41%] [G loss: 0.540913]\n",
      "epoch:8 step:7718 [D loss: 0.500611, acc.: 74.22%] [G loss: 0.709942]\n",
      "epoch:8 step:7719 [D loss: 0.492807, acc.: 75.78%] [G loss: 0.695378]\n",
      "epoch:8 step:7720 [D loss: 0.594201, acc.: 67.19%] [G loss: 0.586840]\n",
      "epoch:8 step:7721 [D loss: 0.558721, acc.: 68.75%] [G loss: 0.473155]\n",
      "epoch:8 step:7722 [D loss: 0.578860, acc.: 69.53%] [G loss: 0.482831]\n",
      "epoch:8 step:7723 [D loss: 0.548190, acc.: 69.53%] [G loss: 0.493008]\n",
      "epoch:8 step:7724 [D loss: 0.647360, acc.: 63.28%] [G loss: 0.434081]\n",
      "epoch:8 step:7725 [D loss: 0.555313, acc.: 73.44%] [G loss: 0.413655]\n",
      "epoch:8 step:7726 [D loss: 0.530293, acc.: 72.66%] [G loss: 0.589656]\n",
      "epoch:8 step:7727 [D loss: 0.489887, acc.: 76.56%] [G loss: 0.793143]\n",
      "epoch:8 step:7728 [D loss: 0.446460, acc.: 82.81%] [G loss: 0.932474]\n",
      "epoch:8 step:7729 [D loss: 0.660745, acc.: 63.28%] [G loss: 0.748472]\n",
      "epoch:8 step:7730 [D loss: 0.534346, acc.: 71.88%] [G loss: 0.574549]\n",
      "epoch:8 step:7731 [D loss: 0.521125, acc.: 69.53%] [G loss: 0.652048]\n",
      "epoch:8 step:7732 [D loss: 0.531507, acc.: 71.88%] [G loss: 0.553987]\n",
      "epoch:8 step:7733 [D loss: 0.580253, acc.: 64.84%] [G loss: 0.456105]\n",
      "epoch:8 step:7734 [D loss: 0.551902, acc.: 68.75%] [G loss: 0.518662]\n",
      "epoch:8 step:7735 [D loss: 0.542218, acc.: 71.09%] [G loss: 0.528902]\n",
      "epoch:8 step:7736 [D loss: 0.566145, acc.: 67.97%] [G loss: 0.613105]\n",
      "epoch:8 step:7737 [D loss: 0.511905, acc.: 78.91%] [G loss: 0.751318]\n",
      "epoch:8 step:7738 [D loss: 0.522245, acc.: 71.09%] [G loss: 0.619239]\n",
      "epoch:8 step:7739 [D loss: 0.596299, acc.: 66.41%] [G loss: 0.595973]\n",
      "epoch:8 step:7740 [D loss: 0.496671, acc.: 75.78%] [G loss: 0.636231]\n",
      "epoch:8 step:7741 [D loss: 0.547309, acc.: 72.66%] [G loss: 0.550814]\n",
      "epoch:8 step:7742 [D loss: 0.539933, acc.: 74.22%] [G loss: 0.619629]\n",
      "epoch:8 step:7743 [D loss: 0.554394, acc.: 71.09%] [G loss: 0.589920]\n",
      "epoch:8 step:7744 [D loss: 0.494874, acc.: 76.56%] [G loss: 0.639012]\n",
      "epoch:8 step:7745 [D loss: 0.579992, acc.: 72.66%] [G loss: 0.582818]\n",
      "epoch:8 step:7746 [D loss: 0.623158, acc.: 67.97%] [G loss: 0.674077]\n",
      "epoch:8 step:7747 [D loss: 0.571018, acc.: 70.31%] [G loss: 0.455843]\n",
      "epoch:8 step:7748 [D loss: 0.621659, acc.: 64.84%] [G loss: 0.539945]\n",
      "epoch:8 step:7749 [D loss: 0.534330, acc.: 75.00%] [G loss: 0.472579]\n",
      "epoch:8 step:7750 [D loss: 0.501634, acc.: 74.22%] [G loss: 0.531562]\n",
      "epoch:8 step:7751 [D loss: 0.516784, acc.: 73.44%] [G loss: 0.549006]\n",
      "epoch:8 step:7752 [D loss: 0.545504, acc.: 71.09%] [G loss: 0.537980]\n",
      "epoch:8 step:7753 [D loss: 0.591820, acc.: 60.94%] [G loss: 0.571356]\n",
      "epoch:8 step:7754 [D loss: 0.525638, acc.: 75.00%] [G loss: 0.538237]\n",
      "epoch:8 step:7755 [D loss: 0.551786, acc.: 70.31%] [G loss: 0.534794]\n",
      "epoch:8 step:7756 [D loss: 0.576827, acc.: 70.31%] [G loss: 0.437732]\n",
      "epoch:8 step:7757 [D loss: 0.467680, acc.: 80.47%] [G loss: 0.547581]\n",
      "epoch:8 step:7758 [D loss: 0.539144, acc.: 71.88%] [G loss: 0.530412]\n",
      "epoch:8 step:7759 [D loss: 0.611442, acc.: 68.75%] [G loss: 0.486463]\n",
      "epoch:8 step:7760 [D loss: 0.487466, acc.: 75.00%] [G loss: 0.613704]\n",
      "epoch:8 step:7761 [D loss: 0.611211, acc.: 67.19%] [G loss: 0.497241]\n",
      "epoch:8 step:7762 [D loss: 0.530340, acc.: 78.91%] [G loss: 0.587906]\n",
      "epoch:8 step:7763 [D loss: 0.598321, acc.: 61.72%] [G loss: 0.501518]\n",
      "epoch:8 step:7764 [D loss: 0.549552, acc.: 69.53%] [G loss: 0.517158]\n",
      "epoch:8 step:7765 [D loss: 0.580089, acc.: 72.66%] [G loss: 0.515965]\n",
      "epoch:8 step:7766 [D loss: 0.545148, acc.: 71.88%] [G loss: 0.492984]\n",
      "epoch:8 step:7767 [D loss: 0.501162, acc.: 78.91%] [G loss: 0.447664]\n",
      "epoch:8 step:7768 [D loss: 0.552296, acc.: 71.88%] [G loss: 0.611797]\n",
      "epoch:8 step:7769 [D loss: 0.491908, acc.: 75.78%] [G loss: 0.701061]\n",
      "epoch:8 step:7770 [D loss: 0.556856, acc.: 68.75%] [G loss: 0.534908]\n",
      "epoch:8 step:7771 [D loss: 0.661845, acc.: 63.28%] [G loss: 0.463790]\n",
      "epoch:8 step:7772 [D loss: 0.531683, acc.: 74.22%] [G loss: 0.592399]\n",
      "epoch:8 step:7773 [D loss: 0.661909, acc.: 62.50%] [G loss: 0.459508]\n",
      "epoch:8 step:7774 [D loss: 0.582014, acc.: 62.50%] [G loss: 0.495620]\n",
      "epoch:8 step:7775 [D loss: 0.532952, acc.: 66.41%] [G loss: 0.516433]\n",
      "epoch:8 step:7776 [D loss: 0.590854, acc.: 64.06%] [G loss: 0.589750]\n",
      "epoch:8 step:7777 [D loss: 0.599516, acc.: 70.31%] [G loss: 0.430734]\n",
      "epoch:8 step:7778 [D loss: 0.541298, acc.: 70.31%] [G loss: 0.556607]\n",
      "epoch:8 step:7779 [D loss: 0.518950, acc.: 78.12%] [G loss: 0.638586]\n",
      "epoch:8 step:7780 [D loss: 0.478783, acc.: 78.91%] [G loss: 0.639536]\n",
      "epoch:8 step:7781 [D loss: 0.502336, acc.: 76.56%] [G loss: 0.644176]\n",
      "epoch:8 step:7782 [D loss: 0.478866, acc.: 77.34%] [G loss: 0.606213]\n",
      "epoch:8 step:7783 [D loss: 0.606442, acc.: 67.97%] [G loss: 0.543744]\n",
      "epoch:8 step:7784 [D loss: 0.591120, acc.: 67.97%] [G loss: 0.523881]\n",
      "epoch:8 step:7785 [D loss: 0.579439, acc.: 64.84%] [G loss: 0.417664]\n",
      "epoch:8 step:7786 [D loss: 0.592487, acc.: 69.53%] [G loss: 0.474197]\n",
      "epoch:8 step:7787 [D loss: 0.614546, acc.: 63.28%] [G loss: 0.486208]\n",
      "epoch:8 step:7788 [D loss: 0.550184, acc.: 71.88%] [G loss: 0.395669]\n",
      "epoch:8 step:7789 [D loss: 0.611940, acc.: 62.50%] [G loss: 0.390356]\n",
      "epoch:8 step:7790 [D loss: 0.566110, acc.: 68.75%] [G loss: 0.466927]\n",
      "epoch:8 step:7791 [D loss: 0.535904, acc.: 72.66%] [G loss: 0.410931]\n",
      "epoch:8 step:7792 [D loss: 0.496940, acc.: 79.69%] [G loss: 0.524049]\n",
      "epoch:8 step:7793 [D loss: 0.543694, acc.: 72.66%] [G loss: 0.506472]\n",
      "epoch:8 step:7794 [D loss: 0.562670, acc.: 77.34%] [G loss: 0.522965]\n",
      "epoch:8 step:7795 [D loss: 0.503188, acc.: 78.91%] [G loss: 0.603012]\n",
      "epoch:8 step:7796 [D loss: 0.552382, acc.: 71.09%] [G loss: 0.591889]\n",
      "epoch:8 step:7797 [D loss: 0.646193, acc.: 64.84%] [G loss: 0.495053]\n",
      "epoch:8 step:7798 [D loss: 0.529720, acc.: 74.22%] [G loss: 0.583284]\n",
      "epoch:8 step:7799 [D loss: 0.543988, acc.: 72.66%] [G loss: 0.498182]\n",
      "epoch:8 step:7800 [D loss: 0.462474, acc.: 78.12%] [G loss: 0.568141]\n",
      "##############\n",
      "[3.1076466  1.02573435 6.47594696 5.05312999 3.79472746 5.98058454\n",
      " 4.83632655 4.90209992 4.66887614 3.97625534]\n",
      "##########\n",
      "epoch:8 step:7801 [D loss: 0.541373, acc.: 71.09%] [G loss: 0.642240]\n",
      "epoch:8 step:7802 [D loss: 0.563866, acc.: 64.84%] [G loss: 0.515665]\n",
      "epoch:8 step:7803 [D loss: 0.496697, acc.: 73.44%] [G loss: 0.625965]\n",
      "epoch:8 step:7804 [D loss: 0.540143, acc.: 69.53%] [G loss: 0.534421]\n",
      "epoch:8 step:7805 [D loss: 0.486494, acc.: 76.56%] [G loss: 0.641098]\n",
      "epoch:8 step:7806 [D loss: 0.551537, acc.: 71.09%] [G loss: 0.594082]\n",
      "epoch:8 step:7807 [D loss: 0.490033, acc.: 75.78%] [G loss: 0.704048]\n",
      "epoch:8 step:7808 [D loss: 0.479703, acc.: 78.91%] [G loss: 0.747321]\n",
      "epoch:8 step:7809 [D loss: 0.495141, acc.: 75.78%] [G loss: 0.736612]\n",
      "epoch:8 step:7810 [D loss: 0.444502, acc.: 79.69%] [G loss: 0.920699]\n",
      "epoch:8 step:7811 [D loss: 0.484008, acc.: 76.56%] [G loss: 0.739311]\n",
      "epoch:8 step:7812 [D loss: 0.701276, acc.: 60.94%] [G loss: 0.522249]\n",
      "epoch:8 step:7813 [D loss: 0.590681, acc.: 65.62%] [G loss: 0.441718]\n",
      "epoch:8 step:7814 [D loss: 0.549391, acc.: 69.53%] [G loss: 0.519451]\n",
      "epoch:8 step:7815 [D loss: 0.541806, acc.: 70.31%] [G loss: 0.454338]\n",
      "epoch:8 step:7816 [D loss: 0.517566, acc.: 71.88%] [G loss: 0.543366]\n",
      "epoch:8 step:7817 [D loss: 0.504229, acc.: 77.34%] [G loss: 0.640273]\n",
      "epoch:8 step:7818 [D loss: 0.566108, acc.: 68.75%] [G loss: 0.567425]\n",
      "epoch:8 step:7819 [D loss: 0.616563, acc.: 64.06%] [G loss: 0.464523]\n",
      "epoch:8 step:7820 [D loss: 0.562686, acc.: 69.53%] [G loss: 0.556101]\n",
      "epoch:8 step:7821 [D loss: 0.527031, acc.: 74.22%] [G loss: 0.509275]\n",
      "epoch:8 step:7822 [D loss: 0.515065, acc.: 72.66%] [G loss: 0.499943]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7823 [D loss: 0.522283, acc.: 74.22%] [G loss: 0.535070]\n",
      "epoch:8 step:7824 [D loss: 0.543672, acc.: 71.88%] [G loss: 0.696971]\n",
      "epoch:8 step:7825 [D loss: 0.562998, acc.: 69.53%] [G loss: 0.623095]\n",
      "epoch:8 step:7826 [D loss: 0.604828, acc.: 67.97%] [G loss: 0.500127]\n",
      "epoch:8 step:7827 [D loss: 0.527128, acc.: 69.53%] [G loss: 0.516250]\n",
      "epoch:8 step:7828 [D loss: 0.537881, acc.: 71.09%] [G loss: 0.517934]\n",
      "epoch:8 step:7829 [D loss: 0.498416, acc.: 75.78%] [G loss: 0.534082]\n",
      "epoch:8 step:7830 [D loss: 0.519145, acc.: 71.88%] [G loss: 0.666840]\n",
      "epoch:8 step:7831 [D loss: 0.492993, acc.: 74.22%] [G loss: 0.723015]\n",
      "epoch:8 step:7832 [D loss: 0.490497, acc.: 74.22%] [G loss: 0.618673]\n",
      "epoch:8 step:7833 [D loss: 0.534088, acc.: 73.44%] [G loss: 0.574111]\n",
      "epoch:8 step:7834 [D loss: 0.513046, acc.: 74.22%] [G loss: 0.606359]\n",
      "epoch:8 step:7835 [D loss: 0.555187, acc.: 72.66%] [G loss: 0.526450]\n",
      "epoch:8 step:7836 [D loss: 0.521594, acc.: 71.09%] [G loss: 0.603299]\n",
      "epoch:8 step:7837 [D loss: 0.600726, acc.: 68.75%] [G loss: 0.633748]\n",
      "epoch:8 step:7838 [D loss: 0.664029, acc.: 57.03%] [G loss: 0.521813]\n",
      "epoch:8 step:7839 [D loss: 0.494214, acc.: 71.88%] [G loss: 0.810999]\n",
      "epoch:8 step:7840 [D loss: 0.535828, acc.: 71.09%] [G loss: 0.775306]\n",
      "epoch:8 step:7841 [D loss: 0.515759, acc.: 73.44%] [G loss: 0.832805]\n",
      "epoch:8 step:7842 [D loss: 0.552111, acc.: 67.97%] [G loss: 0.725875]\n",
      "epoch:8 step:7843 [D loss: 0.515954, acc.: 75.00%] [G loss: 0.824929]\n",
      "epoch:8 step:7844 [D loss: 0.749543, acc.: 57.81%] [G loss: 0.393398]\n",
      "epoch:8 step:7845 [D loss: 0.682149, acc.: 59.38%] [G loss: 0.459346]\n",
      "epoch:8 step:7846 [D loss: 0.493529, acc.: 77.34%] [G loss: 0.590519]\n",
      "epoch:8 step:7847 [D loss: 0.569487, acc.: 67.97%] [G loss: 0.588069]\n",
      "epoch:8 step:7848 [D loss: 0.625281, acc.: 62.50%] [G loss: 0.550159]\n",
      "epoch:8 step:7849 [D loss: 0.570072, acc.: 67.97%] [G loss: 0.493800]\n",
      "epoch:8 step:7850 [D loss: 0.446580, acc.: 81.25%] [G loss: 0.657506]\n",
      "epoch:8 step:7851 [D loss: 0.569647, acc.: 69.53%] [G loss: 0.573181]\n",
      "epoch:8 step:7852 [D loss: 0.602992, acc.: 67.97%] [G loss: 0.609236]\n",
      "epoch:8 step:7853 [D loss: 0.507686, acc.: 80.47%] [G loss: 0.756631]\n",
      "epoch:8 step:7854 [D loss: 0.487697, acc.: 75.00%] [G loss: 0.637050]\n",
      "epoch:8 step:7855 [D loss: 0.471932, acc.: 78.12%] [G loss: 0.584647]\n",
      "epoch:8 step:7856 [D loss: 0.520968, acc.: 71.88%] [G loss: 0.612600]\n",
      "epoch:8 step:7857 [D loss: 0.537442, acc.: 72.66%] [G loss: 0.589641]\n",
      "epoch:8 step:7858 [D loss: 0.532821, acc.: 75.00%] [G loss: 0.701478]\n",
      "epoch:8 step:7859 [D loss: 0.537299, acc.: 68.75%] [G loss: 0.565810]\n",
      "epoch:8 step:7860 [D loss: 0.525243, acc.: 73.44%] [G loss: 0.566843]\n",
      "epoch:8 step:7861 [D loss: 0.521517, acc.: 75.00%] [G loss: 0.527528]\n",
      "epoch:8 step:7862 [D loss: 0.486902, acc.: 75.78%] [G loss: 0.676317]\n",
      "epoch:8 step:7863 [D loss: 0.534042, acc.: 75.78%] [G loss: 0.627176]\n",
      "epoch:8 step:7864 [D loss: 0.549896, acc.: 69.53%] [G loss: 0.535200]\n",
      "epoch:8 step:7865 [D loss: 0.539132, acc.: 74.22%] [G loss: 0.565252]\n",
      "epoch:8 step:7866 [D loss: 0.595096, acc.: 71.09%] [G loss: 0.673682]\n",
      "epoch:8 step:7867 [D loss: 0.467676, acc.: 79.69%] [G loss: 0.698712]\n",
      "epoch:8 step:7868 [D loss: 0.549670, acc.: 71.88%] [G loss: 0.546249]\n",
      "epoch:8 step:7869 [D loss: 0.585122, acc.: 65.62%] [G loss: 0.682185]\n",
      "epoch:8 step:7870 [D loss: 0.499035, acc.: 75.78%] [G loss: 0.592494]\n",
      "epoch:8 step:7871 [D loss: 0.531904, acc.: 71.88%] [G loss: 0.647378]\n",
      "epoch:8 step:7872 [D loss: 0.650674, acc.: 63.28%] [G loss: 0.485078]\n",
      "epoch:8 step:7873 [D loss: 0.603029, acc.: 66.41%] [G loss: 0.346651]\n",
      "epoch:8 step:7874 [D loss: 0.518103, acc.: 72.66%] [G loss: 0.609101]\n",
      "epoch:8 step:7875 [D loss: 0.567093, acc.: 72.66%] [G loss: 0.505033]\n",
      "epoch:8 step:7876 [D loss: 0.549293, acc.: 64.84%] [G loss: 0.519362]\n",
      "epoch:8 step:7877 [D loss: 0.473530, acc.: 73.44%] [G loss: 0.599687]\n",
      "epoch:8 step:7878 [D loss: 0.545473, acc.: 71.09%] [G loss: 0.603513]\n",
      "epoch:8 step:7879 [D loss: 0.526979, acc.: 72.66%] [G loss: 0.667367]\n",
      "epoch:8 step:7880 [D loss: 0.542859, acc.: 72.66%] [G loss: 0.484509]\n",
      "epoch:8 step:7881 [D loss: 0.556183, acc.: 69.53%] [G loss: 0.527207]\n",
      "epoch:8 step:7882 [D loss: 0.642230, acc.: 61.72%] [G loss: 0.500717]\n",
      "epoch:8 step:7883 [D loss: 0.634140, acc.: 63.28%] [G loss: 0.555192]\n",
      "epoch:8 step:7884 [D loss: 0.590243, acc.: 75.78%] [G loss: 0.621857]\n",
      "epoch:8 step:7885 [D loss: 0.531666, acc.: 75.00%] [G loss: 0.626005]\n",
      "epoch:8 step:7886 [D loss: 0.597828, acc.: 67.19%] [G loss: 0.410758]\n",
      "epoch:8 step:7887 [D loss: 0.619447, acc.: 61.72%] [G loss: 0.454507]\n",
      "epoch:8 step:7888 [D loss: 0.501076, acc.: 71.88%] [G loss: 0.582393]\n",
      "epoch:8 step:7889 [D loss: 0.603411, acc.: 60.94%] [G loss: 0.549934]\n",
      "epoch:8 step:7890 [D loss: 0.568542, acc.: 70.31%] [G loss: 0.520811]\n",
      "epoch:8 step:7891 [D loss: 0.492019, acc.: 76.56%] [G loss: 0.597596]\n",
      "epoch:8 step:7892 [D loss: 0.649466, acc.: 64.84%] [G loss: 0.499530]\n",
      "epoch:8 step:7893 [D loss: 0.548620, acc.: 65.62%] [G loss: 0.481642]\n",
      "epoch:8 step:7894 [D loss: 0.481019, acc.: 76.56%] [G loss: 0.685267]\n",
      "epoch:8 step:7895 [D loss: 0.543921, acc.: 69.53%] [G loss: 0.580388]\n",
      "epoch:8 step:7896 [D loss: 0.653011, acc.: 60.94%] [G loss: 0.378991]\n",
      "epoch:8 step:7897 [D loss: 0.676046, acc.: 57.03%] [G loss: 0.514497]\n",
      "epoch:8 step:7898 [D loss: 0.507003, acc.: 74.22%] [G loss: 0.460766]\n",
      "epoch:8 step:7899 [D loss: 0.553271, acc.: 70.31%] [G loss: 0.554726]\n",
      "epoch:8 step:7900 [D loss: 0.634513, acc.: 65.62%] [G loss: 0.390469]\n",
      "epoch:8 step:7901 [D loss: 0.600217, acc.: 69.53%] [G loss: 0.495202]\n",
      "epoch:8 step:7902 [D loss: 0.494932, acc.: 78.91%] [G loss: 0.685548]\n",
      "epoch:8 step:7903 [D loss: 0.587252, acc.: 68.75%] [G loss: 0.709413]\n",
      "epoch:8 step:7904 [D loss: 0.603215, acc.: 67.19%] [G loss: 0.530910]\n",
      "epoch:8 step:7905 [D loss: 0.618593, acc.: 59.38%] [G loss: 0.457072]\n",
      "epoch:8 step:7906 [D loss: 0.567435, acc.: 67.97%] [G loss: 0.637491]\n",
      "epoch:8 step:7907 [D loss: 0.536210, acc.: 71.88%] [G loss: 0.522972]\n",
      "epoch:8 step:7908 [D loss: 0.594133, acc.: 67.97%] [G loss: 0.439256]\n",
      "epoch:8 step:7909 [D loss: 0.527244, acc.: 69.53%] [G loss: 0.525562]\n",
      "epoch:8 step:7910 [D loss: 0.527785, acc.: 75.78%] [G loss: 0.590852]\n",
      "epoch:8 step:7911 [D loss: 0.554455, acc.: 70.31%] [G loss: 0.539017]\n",
      "epoch:8 step:7912 [D loss: 0.511065, acc.: 74.22%] [G loss: 0.648767]\n",
      "epoch:8 step:7913 [D loss: 0.620022, acc.: 63.28%] [G loss: 0.627876]\n",
      "epoch:8 step:7914 [D loss: 0.627724, acc.: 61.72%] [G loss: 0.550503]\n",
      "epoch:8 step:7915 [D loss: 0.551102, acc.: 68.75%] [G loss: 0.521931]\n",
      "epoch:8 step:7916 [D loss: 0.602785, acc.: 54.69%] [G loss: 0.512350]\n",
      "epoch:8 step:7917 [D loss: 0.570081, acc.: 66.41%] [G loss: 0.555545]\n",
      "epoch:8 step:7918 [D loss: 0.570601, acc.: 65.62%] [G loss: 0.532212]\n",
      "epoch:8 step:7919 [D loss: 0.555686, acc.: 71.88%] [G loss: 0.584914]\n",
      "epoch:8 step:7920 [D loss: 0.553862, acc.: 68.75%] [G loss: 0.537833]\n",
      "epoch:8 step:7921 [D loss: 0.509699, acc.: 75.78%] [G loss: 0.628183]\n",
      "epoch:8 step:7922 [D loss: 0.531786, acc.: 73.44%] [G loss: 0.629445]\n",
      "epoch:8 step:7923 [D loss: 0.494695, acc.: 79.69%] [G loss: 0.674041]\n",
      "epoch:8 step:7924 [D loss: 0.538393, acc.: 71.88%] [G loss: 0.584707]\n",
      "epoch:8 step:7925 [D loss: 0.496757, acc.: 77.34%] [G loss: 0.623739]\n",
      "epoch:8 step:7926 [D loss: 0.551769, acc.: 71.88%] [G loss: 0.646470]\n",
      "epoch:8 step:7927 [D loss: 0.549643, acc.: 71.88%] [G loss: 0.650745]\n",
      "epoch:8 step:7928 [D loss: 0.538965, acc.: 68.75%] [G loss: 0.598475]\n",
      "epoch:8 step:7929 [D loss: 0.569198, acc.: 71.09%] [G loss: 0.445122]\n",
      "epoch:8 step:7930 [D loss: 0.504934, acc.: 75.00%] [G loss: 0.486172]\n",
      "epoch:8 step:7931 [D loss: 0.547157, acc.: 75.00%] [G loss: 0.552674]\n",
      "epoch:8 step:7932 [D loss: 0.485228, acc.: 75.78%] [G loss: 0.599313]\n",
      "epoch:8 step:7933 [D loss: 0.739677, acc.: 56.25%] [G loss: 0.434664]\n",
      "epoch:8 step:7934 [D loss: 0.554183, acc.: 66.41%] [G loss: 0.483919]\n",
      "epoch:8 step:7935 [D loss: 0.485596, acc.: 80.47%] [G loss: 0.721771]\n",
      "epoch:8 step:7936 [D loss: 0.511730, acc.: 74.22%] [G loss: 0.776277]\n",
      "epoch:8 step:7937 [D loss: 0.603572, acc.: 65.62%] [G loss: 0.569804]\n",
      "epoch:8 step:7938 [D loss: 0.564150, acc.: 68.75%] [G loss: 0.664788]\n",
      "epoch:8 step:7939 [D loss: 0.521059, acc.: 75.00%] [G loss: 0.551593]\n",
      "epoch:8 step:7940 [D loss: 0.573673, acc.: 69.53%] [G loss: 0.682162]\n",
      "epoch:8 step:7941 [D loss: 0.560660, acc.: 67.97%] [G loss: 0.572820]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7942 [D loss: 0.528518, acc.: 75.00%] [G loss: 0.427926]\n",
      "epoch:8 step:7943 [D loss: 0.519674, acc.: 71.09%] [G loss: 0.644654]\n",
      "epoch:8 step:7944 [D loss: 0.611471, acc.: 67.97%] [G loss: 0.462036]\n",
      "epoch:8 step:7945 [D loss: 0.529399, acc.: 72.66%] [G loss: 0.518788]\n",
      "epoch:8 step:7946 [D loss: 0.593636, acc.: 72.66%] [G loss: 0.599928]\n",
      "epoch:8 step:7947 [D loss: 0.434431, acc.: 81.25%] [G loss: 0.617973]\n",
      "epoch:8 step:7948 [D loss: 0.511597, acc.: 69.53%] [G loss: 0.752339]\n",
      "epoch:8 step:7949 [D loss: 0.540976, acc.: 71.88%] [G loss: 0.751475]\n",
      "epoch:8 step:7950 [D loss: 0.558868, acc.: 74.22%] [G loss: 0.455623]\n",
      "epoch:8 step:7951 [D loss: 0.594938, acc.: 64.84%] [G loss: 0.581338]\n",
      "epoch:8 step:7952 [D loss: 0.660814, acc.: 57.81%] [G loss: 0.476609]\n",
      "epoch:8 step:7953 [D loss: 0.557028, acc.: 69.53%] [G loss: 0.625945]\n",
      "epoch:8 step:7954 [D loss: 0.611819, acc.: 63.28%] [G loss: 0.504350]\n",
      "epoch:8 step:7955 [D loss: 0.566045, acc.: 70.31%] [G loss: 0.454976]\n",
      "epoch:8 step:7956 [D loss: 0.491680, acc.: 73.44%] [G loss: 0.612244]\n",
      "epoch:8 step:7957 [D loss: 0.496393, acc.: 76.56%] [G loss: 0.534065]\n",
      "epoch:8 step:7958 [D loss: 0.582797, acc.: 66.41%] [G loss: 0.494601]\n",
      "epoch:8 step:7959 [D loss: 0.626326, acc.: 60.94%] [G loss: 0.410711]\n",
      "epoch:8 step:7960 [D loss: 0.536598, acc.: 70.31%] [G loss: 0.578717]\n",
      "epoch:8 step:7961 [D loss: 0.615892, acc.: 64.06%] [G loss: 0.454632]\n",
      "epoch:8 step:7962 [D loss: 0.555650, acc.: 64.84%] [G loss: 0.515830]\n",
      "epoch:8 step:7963 [D loss: 0.512699, acc.: 76.56%] [G loss: 0.622137]\n",
      "epoch:8 step:7964 [D loss: 0.606745, acc.: 60.16%] [G loss: 0.574520]\n",
      "epoch:8 step:7965 [D loss: 0.531613, acc.: 75.78%] [G loss: 0.652204]\n",
      "epoch:8 step:7966 [D loss: 0.500889, acc.: 74.22%] [G loss: 0.701337]\n",
      "epoch:8 step:7967 [D loss: 0.485216, acc.: 81.25%] [G loss: 0.604520]\n",
      "epoch:8 step:7968 [D loss: 0.470666, acc.: 78.91%] [G loss: 0.849951]\n",
      "epoch:8 step:7969 [D loss: 0.607229, acc.: 61.72%] [G loss: 0.751973]\n",
      "epoch:8 step:7970 [D loss: 0.585093, acc.: 69.53%] [G loss: 0.655549]\n",
      "epoch:8 step:7971 [D loss: 0.450273, acc.: 78.12%] [G loss: 0.904276]\n",
      "epoch:8 step:7972 [D loss: 0.592968, acc.: 71.09%] [G loss: 0.702289]\n",
      "epoch:8 step:7973 [D loss: 0.624148, acc.: 64.84%] [G loss: 0.415589]\n",
      "epoch:8 step:7974 [D loss: 0.583302, acc.: 65.62%] [G loss: 0.451141]\n",
      "epoch:8 step:7975 [D loss: 0.510386, acc.: 73.44%] [G loss: 0.605602]\n",
      "epoch:8 step:7976 [D loss: 0.549167, acc.: 72.66%] [G loss: 0.533774]\n",
      "epoch:8 step:7977 [D loss: 0.471870, acc.: 82.81%] [G loss: 0.562928]\n",
      "epoch:8 step:7978 [D loss: 0.641908, acc.: 60.16%] [G loss: 0.585079]\n",
      "epoch:8 step:7979 [D loss: 0.611903, acc.: 58.59%] [G loss: 0.455004]\n",
      "epoch:8 step:7980 [D loss: 0.517870, acc.: 73.44%] [G loss: 0.583651]\n",
      "epoch:8 step:7981 [D loss: 0.566755, acc.: 71.09%] [G loss: 0.552272]\n",
      "epoch:8 step:7982 [D loss: 0.498832, acc.: 78.91%] [G loss: 0.615452]\n",
      "epoch:8 step:7983 [D loss: 0.537419, acc.: 70.31%] [G loss: 0.658526]\n",
      "epoch:8 step:7984 [D loss: 0.534122, acc.: 72.66%] [G loss: 0.637542]\n",
      "epoch:8 step:7985 [D loss: 0.530571, acc.: 71.88%] [G loss: 0.546048]\n",
      "epoch:8 step:7986 [D loss: 0.518991, acc.: 73.44%] [G loss: 0.616314]\n",
      "epoch:8 step:7987 [D loss: 0.595901, acc.: 66.41%] [G loss: 0.483946]\n",
      "epoch:8 step:7988 [D loss: 0.542649, acc.: 77.34%] [G loss: 0.499658]\n",
      "epoch:8 step:7989 [D loss: 0.571629, acc.: 68.75%] [G loss: 0.484307]\n",
      "epoch:8 step:7990 [D loss: 0.608538, acc.: 68.75%] [G loss: 0.477751]\n",
      "epoch:8 step:7991 [D loss: 0.554347, acc.: 69.53%] [G loss: 0.495220]\n",
      "epoch:8 step:7992 [D loss: 0.553391, acc.: 70.31%] [G loss: 0.616799]\n",
      "epoch:8 step:7993 [D loss: 0.599248, acc.: 67.97%] [G loss: 0.523467]\n",
      "epoch:8 step:7994 [D loss: 0.507193, acc.: 72.66%] [G loss: 0.649563]\n",
      "epoch:8 step:7995 [D loss: 0.446103, acc.: 78.12%] [G loss: 0.670256]\n",
      "epoch:8 step:7996 [D loss: 0.627053, acc.: 64.06%] [G loss: 0.463047]\n",
      "epoch:8 step:7997 [D loss: 0.649037, acc.: 62.50%] [G loss: 0.483669]\n",
      "epoch:8 step:7998 [D loss: 0.628526, acc.: 60.16%] [G loss: 0.338064]\n",
      "epoch:8 step:7999 [D loss: 0.514643, acc.: 71.88%] [G loss: 0.489165]\n",
      "epoch:8 step:8000 [D loss: 0.467696, acc.: 76.56%] [G loss: 0.646599]\n",
      "##############\n",
      "[3.23273837 1.03968364 6.29213433 5.0161091  3.99865364 5.82472652\n",
      " 4.63437119 5.05164377 4.6348632  4.0712634 ]\n",
      "##########\n",
      "epoch:8 step:8001 [D loss: 0.613552, acc.: 64.06%] [G loss: 0.680543]\n",
      "epoch:8 step:8002 [D loss: 0.524975, acc.: 73.44%] [G loss: 0.843219]\n",
      "epoch:8 step:8003 [D loss: 0.566602, acc.: 65.62%] [G loss: 0.741480]\n",
      "epoch:8 step:8004 [D loss: 0.494211, acc.: 75.00%] [G loss: 0.943911]\n",
      "epoch:8 step:8005 [D loss: 0.516460, acc.: 75.00%] [G loss: 0.741884]\n",
      "epoch:8 step:8006 [D loss: 0.599857, acc.: 64.84%] [G loss: 0.595075]\n",
      "epoch:8 step:8007 [D loss: 0.662251, acc.: 59.38%] [G loss: 0.556327]\n",
      "epoch:8 step:8008 [D loss: 0.600496, acc.: 63.28%] [G loss: 0.458210]\n",
      "epoch:8 step:8009 [D loss: 0.579734, acc.: 67.19%] [G loss: 0.424034]\n",
      "epoch:8 step:8010 [D loss: 0.499137, acc.: 71.88%] [G loss: 0.579801]\n",
      "epoch:8 step:8011 [D loss: 0.593893, acc.: 67.97%] [G loss: 0.578035]\n",
      "epoch:8 step:8012 [D loss: 0.440046, acc.: 82.81%] [G loss: 0.798096]\n",
      "epoch:8 step:8013 [D loss: 0.596038, acc.: 69.53%] [G loss: 0.549581]\n",
      "epoch:8 step:8014 [D loss: 0.555587, acc.: 72.66%] [G loss: 0.517588]\n",
      "epoch:8 step:8015 [D loss: 0.481895, acc.: 77.34%] [G loss: 0.721377]\n",
      "epoch:8 step:8016 [D loss: 0.499315, acc.: 78.12%] [G loss: 0.724223]\n",
      "epoch:8 step:8017 [D loss: 0.554133, acc.: 77.34%] [G loss: 0.627797]\n",
      "epoch:8 step:8018 [D loss: 0.479218, acc.: 79.69%] [G loss: 0.745699]\n",
      "epoch:8 step:8019 [D loss: 0.521949, acc.: 70.31%] [G loss: 0.657992]\n",
      "epoch:8 step:8020 [D loss: 0.551451, acc.: 71.09%] [G loss: 0.637794]\n",
      "epoch:8 step:8021 [D loss: 0.604979, acc.: 66.41%] [G loss: 0.634921]\n",
      "epoch:8 step:8022 [D loss: 0.527684, acc.: 74.22%] [G loss: 0.455597]\n",
      "epoch:8 step:8023 [D loss: 0.584492, acc.: 64.06%] [G loss: 0.513740]\n",
      "epoch:8 step:8024 [D loss: 0.659313, acc.: 58.59%] [G loss: 0.406122]\n",
      "epoch:8 step:8025 [D loss: 0.546383, acc.: 72.66%] [G loss: 0.531868]\n",
      "epoch:8 step:8026 [D loss: 0.531930, acc.: 72.66%] [G loss: 0.636130]\n",
      "epoch:8 step:8027 [D loss: 0.591845, acc.: 67.97%] [G loss: 0.505822]\n",
      "epoch:8 step:8028 [D loss: 0.566091, acc.: 65.62%] [G loss: 0.520625]\n",
      "epoch:8 step:8029 [D loss: 0.562198, acc.: 68.75%] [G loss: 0.512405]\n",
      "epoch:8 step:8030 [D loss: 0.498502, acc.: 75.00%] [G loss: 0.515805]\n",
      "epoch:8 step:8031 [D loss: 0.661318, acc.: 55.47%] [G loss: 0.510922]\n",
      "epoch:8 step:8032 [D loss: 0.469253, acc.: 79.69%] [G loss: 0.637385]\n",
      "epoch:8 step:8033 [D loss: 0.571337, acc.: 71.88%] [G loss: 0.481027]\n",
      "epoch:8 step:8034 [D loss: 0.609721, acc.: 64.84%] [G loss: 0.544638]\n",
      "epoch:8 step:8035 [D loss: 0.561996, acc.: 70.31%] [G loss: 0.561123]\n",
      "epoch:8 step:8036 [D loss: 0.561222, acc.: 68.75%] [G loss: 0.563720]\n",
      "epoch:8 step:8037 [D loss: 0.583910, acc.: 62.50%] [G loss: 0.475618]\n",
      "epoch:8 step:8038 [D loss: 0.618600, acc.: 67.97%] [G loss: 0.431920]\n",
      "epoch:8 step:8039 [D loss: 0.617487, acc.: 64.06%] [G loss: 0.471623]\n",
      "epoch:8 step:8040 [D loss: 0.561170, acc.: 64.84%] [G loss: 0.451732]\n",
      "epoch:8 step:8041 [D loss: 0.595989, acc.: 64.06%] [G loss: 0.580107]\n",
      "epoch:8 step:8042 [D loss: 0.527289, acc.: 70.31%] [G loss: 0.541309]\n",
      "epoch:8 step:8043 [D loss: 0.527200, acc.: 76.56%] [G loss: 0.725417]\n",
      "epoch:8 step:8044 [D loss: 0.498752, acc.: 75.00%] [G loss: 0.693820]\n",
      "epoch:8 step:8045 [D loss: 0.538965, acc.: 68.75%] [G loss: 0.707945]\n",
      "epoch:8 step:8046 [D loss: 0.559044, acc.: 70.31%] [G loss: 0.511094]\n",
      "epoch:8 step:8047 [D loss: 0.549186, acc.: 70.31%] [G loss: 0.577106]\n",
      "epoch:8 step:8048 [D loss: 0.534451, acc.: 71.09%] [G loss: 0.512598]\n",
      "epoch:8 step:8049 [D loss: 0.582254, acc.: 69.53%] [G loss: 0.497095]\n",
      "epoch:8 step:8050 [D loss: 0.521550, acc.: 74.22%] [G loss: 0.550593]\n",
      "epoch:8 step:8051 [D loss: 0.508126, acc.: 72.66%] [G loss: 0.528837]\n",
      "epoch:8 step:8052 [D loss: 0.521915, acc.: 71.09%] [G loss: 0.626600]\n",
      "epoch:8 step:8053 [D loss: 0.492728, acc.: 76.56%] [G loss: 0.619485]\n",
      "epoch:8 step:8054 [D loss: 0.475376, acc.: 81.25%] [G loss: 0.589879]\n",
      "epoch:8 step:8055 [D loss: 0.603275, acc.: 64.06%] [G loss: 0.616697]\n",
      "epoch:8 step:8056 [D loss: 0.577897, acc.: 67.19%] [G loss: 0.523708]\n",
      "epoch:8 step:8057 [D loss: 0.531214, acc.: 70.31%] [G loss: 0.530792]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8058 [D loss: 0.601124, acc.: 63.28%] [G loss: 0.461326]\n",
      "epoch:8 step:8059 [D loss: 0.543923, acc.: 68.75%] [G loss: 0.461153]\n",
      "epoch:8 step:8060 [D loss: 0.498036, acc.: 75.78%] [G loss: 0.510310]\n",
      "epoch:8 step:8061 [D loss: 0.584338, acc.: 71.88%] [G loss: 0.579217]\n",
      "epoch:8 step:8062 [D loss: 0.638317, acc.: 64.84%] [G loss: 0.438802]\n",
      "epoch:8 step:8063 [D loss: 0.487022, acc.: 77.34%] [G loss: 0.586112]\n",
      "epoch:8 step:8064 [D loss: 0.533362, acc.: 74.22%] [G loss: 0.631632]\n",
      "epoch:8 step:8065 [D loss: 0.569990, acc.: 74.22%] [G loss: 0.587421]\n",
      "epoch:8 step:8066 [D loss: 0.585030, acc.: 70.31%] [G loss: 0.545824]\n",
      "epoch:8 step:8067 [D loss: 0.505223, acc.: 76.56%] [G loss: 0.665035]\n",
      "epoch:8 step:8068 [D loss: 0.603450, acc.: 67.97%] [G loss: 0.660755]\n",
      "epoch:8 step:8069 [D loss: 0.557924, acc.: 69.53%] [G loss: 0.573761]\n",
      "epoch:8 step:8070 [D loss: 0.510955, acc.: 71.09%] [G loss: 0.777099]\n",
      "epoch:8 step:8071 [D loss: 0.545572, acc.: 72.66%] [G loss: 0.712840]\n",
      "epoch:8 step:8072 [D loss: 0.580080, acc.: 71.09%] [G loss: 0.668429]\n",
      "epoch:8 step:8073 [D loss: 0.589640, acc.: 67.97%] [G loss: 0.586006]\n",
      "epoch:8 step:8074 [D loss: 0.523202, acc.: 71.88%] [G loss: 0.608178]\n",
      "epoch:8 step:8075 [D loss: 0.541901, acc.: 68.75%] [G loss: 0.537099]\n",
      "epoch:8 step:8076 [D loss: 0.542761, acc.: 68.75%] [G loss: 0.565828]\n",
      "epoch:8 step:8077 [D loss: 0.563812, acc.: 68.75%] [G loss: 0.665275]\n",
      "epoch:8 step:8078 [D loss: 0.510544, acc.: 74.22%] [G loss: 0.649908]\n",
      "epoch:8 step:8079 [D loss: 0.600422, acc.: 64.84%] [G loss: 0.646171]\n",
      "epoch:8 step:8080 [D loss: 0.626052, acc.: 61.72%] [G loss: 0.486860]\n",
      "epoch:8 step:8081 [D loss: 0.568063, acc.: 69.53%] [G loss: 0.603085]\n",
      "epoch:8 step:8082 [D loss: 0.570133, acc.: 68.75%] [G loss: 0.446280]\n",
      "epoch:8 step:8083 [D loss: 0.598810, acc.: 58.59%] [G loss: 0.443682]\n",
      "epoch:8 step:8084 [D loss: 0.570242, acc.: 67.19%] [G loss: 0.477106]\n",
      "epoch:8 step:8085 [D loss: 0.478046, acc.: 78.12%] [G loss: 0.632242]\n",
      "epoch:8 step:8086 [D loss: 0.600761, acc.: 67.19%] [G loss: 0.479705]\n",
      "epoch:8 step:8087 [D loss: 0.549352, acc.: 71.09%] [G loss: 0.456636]\n",
      "epoch:8 step:8088 [D loss: 0.506342, acc.: 77.34%] [G loss: 0.547481]\n",
      "epoch:8 step:8089 [D loss: 0.590958, acc.: 67.97%] [G loss: 0.644998]\n",
      "epoch:8 step:8090 [D loss: 0.600378, acc.: 63.28%] [G loss: 0.499690]\n",
      "epoch:8 step:8091 [D loss: 0.527029, acc.: 68.75%] [G loss: 0.579185]\n",
      "epoch:8 step:8092 [D loss: 0.571987, acc.: 70.31%] [G loss: 0.623296]\n",
      "epoch:8 step:8093 [D loss: 0.523991, acc.: 71.09%] [G loss: 0.499680]\n",
      "epoch:8 step:8094 [D loss: 0.531509, acc.: 69.53%] [G loss: 0.597578]\n",
      "epoch:8 step:8095 [D loss: 0.562424, acc.: 64.06%] [G loss: 0.664437]\n",
      "epoch:8 step:8096 [D loss: 0.620947, acc.: 64.84%] [G loss: 0.612077]\n",
      "epoch:8 step:8097 [D loss: 0.513171, acc.: 73.44%] [G loss: 0.603995]\n",
      "epoch:8 step:8098 [D loss: 0.513146, acc.: 73.44%] [G loss: 0.420785]\n",
      "epoch:8 step:8099 [D loss: 0.499133, acc.: 73.44%] [G loss: 0.534823]\n",
      "epoch:8 step:8100 [D loss: 0.577729, acc.: 69.53%] [G loss: 0.544141]\n",
      "epoch:8 step:8101 [D loss: 0.446964, acc.: 80.47%] [G loss: 0.660936]\n",
      "epoch:8 step:8102 [D loss: 0.544268, acc.: 74.22%] [G loss: 0.533503]\n",
      "epoch:8 step:8103 [D loss: 0.556227, acc.: 67.97%] [G loss: 0.450527]\n",
      "epoch:8 step:8104 [D loss: 0.554054, acc.: 73.44%] [G loss: 0.487031]\n",
      "epoch:8 step:8105 [D loss: 0.538200, acc.: 71.88%] [G loss: 0.468825]\n",
      "epoch:8 step:8106 [D loss: 0.578474, acc.: 65.62%] [G loss: 0.434885]\n",
      "epoch:8 step:8107 [D loss: 0.457618, acc.: 79.69%] [G loss: 0.476740]\n",
      "epoch:8 step:8108 [D loss: 0.552882, acc.: 70.31%] [G loss: 0.484526]\n",
      "epoch:8 step:8109 [D loss: 0.497781, acc.: 76.56%] [G loss: 0.471788]\n",
      "epoch:8 step:8110 [D loss: 0.534064, acc.: 70.31%] [G loss: 0.626050]\n",
      "epoch:8 step:8111 [D loss: 0.569652, acc.: 67.19%] [G loss: 0.515414]\n",
      "epoch:8 step:8112 [D loss: 0.602713, acc.: 57.81%] [G loss: 0.637448]\n",
      "epoch:8 step:8113 [D loss: 0.551065, acc.: 70.31%] [G loss: 0.617354]\n",
      "epoch:8 step:8114 [D loss: 0.566446, acc.: 72.66%] [G loss: 0.581424]\n",
      "epoch:8 step:8115 [D loss: 0.573207, acc.: 69.53%] [G loss: 0.551643]\n",
      "epoch:8 step:8116 [D loss: 0.506950, acc.: 77.34%] [G loss: 0.588149]\n",
      "epoch:8 step:8117 [D loss: 0.544082, acc.: 67.97%] [G loss: 0.611165]\n",
      "epoch:8 step:8118 [D loss: 0.595086, acc.: 65.62%] [G loss: 0.463360]\n",
      "epoch:8 step:8119 [D loss: 0.502133, acc.: 75.78%] [G loss: 0.528886]\n",
      "epoch:8 step:8120 [D loss: 0.505006, acc.: 77.34%] [G loss: 0.625474]\n",
      "epoch:8 step:8121 [D loss: 0.637456, acc.: 60.94%] [G loss: 0.568117]\n",
      "epoch:8 step:8122 [D loss: 0.543402, acc.: 68.75%] [G loss: 0.573111]\n",
      "epoch:8 step:8123 [D loss: 0.549119, acc.: 68.75%] [G loss: 0.552618]\n",
      "epoch:8 step:8124 [D loss: 0.576077, acc.: 68.75%] [G loss: 0.520846]\n",
      "epoch:8 step:8125 [D loss: 0.527233, acc.: 75.00%] [G loss: 0.531172]\n",
      "epoch:8 step:8126 [D loss: 0.588608, acc.: 67.97%] [G loss: 0.617636]\n",
      "epoch:8 step:8127 [D loss: 0.487022, acc.: 81.25%] [G loss: 0.686087]\n",
      "epoch:8 step:8128 [D loss: 0.485292, acc.: 78.12%] [G loss: 0.701923]\n",
      "epoch:8 step:8129 [D loss: 0.529132, acc.: 72.66%] [G loss: 0.603596]\n",
      "epoch:8 step:8130 [D loss: 0.492221, acc.: 78.91%] [G loss: 0.563854]\n",
      "epoch:8 step:8131 [D loss: 0.535589, acc.: 71.88%] [G loss: 0.610274]\n",
      "epoch:8 step:8132 [D loss: 0.543689, acc.: 75.00%] [G loss: 0.589760]\n",
      "epoch:8 step:8133 [D loss: 0.567116, acc.: 70.31%] [G loss: 0.508800]\n",
      "epoch:8 step:8134 [D loss: 0.537831, acc.: 70.31%] [G loss: 0.468536]\n",
      "epoch:8 step:8135 [D loss: 0.491804, acc.: 75.78%] [G loss: 0.420032]\n",
      "epoch:8 step:8136 [D loss: 0.550337, acc.: 72.66%] [G loss: 0.503154]\n",
      "epoch:8 step:8137 [D loss: 0.506220, acc.: 75.00%] [G loss: 0.647066]\n",
      "epoch:8 step:8138 [D loss: 0.470980, acc.: 78.12%] [G loss: 0.768587]\n",
      "epoch:8 step:8139 [D loss: 0.508113, acc.: 73.44%] [G loss: 0.833926]\n",
      "epoch:8 step:8140 [D loss: 0.551403, acc.: 71.09%] [G loss: 0.639527]\n",
      "epoch:8 step:8141 [D loss: 0.567375, acc.: 68.75%] [G loss: 0.542980]\n",
      "epoch:8 step:8142 [D loss: 0.525886, acc.: 71.88%] [G loss: 0.676981]\n",
      "epoch:8 step:8143 [D loss: 0.558344, acc.: 72.66%] [G loss: 0.625894]\n",
      "epoch:8 step:8144 [D loss: 0.451427, acc.: 79.69%] [G loss: 0.862259]\n",
      "epoch:8 step:8145 [D loss: 0.443793, acc.: 78.91%] [G loss: 0.819870]\n",
      "epoch:8 step:8146 [D loss: 0.497652, acc.: 75.00%] [G loss: 0.663654]\n",
      "epoch:8 step:8147 [D loss: 0.495519, acc.: 78.91%] [G loss: 0.705947]\n",
      "epoch:8 step:8148 [D loss: 0.655421, acc.: 59.38%] [G loss: 0.454503]\n",
      "epoch:8 step:8149 [D loss: 0.573329, acc.: 67.19%] [G loss: 0.495285]\n",
      "epoch:8 step:8150 [D loss: 0.529300, acc.: 71.88%] [G loss: 0.478840]\n",
      "epoch:8 step:8151 [D loss: 0.521522, acc.: 71.88%] [G loss: 0.681651]\n",
      "epoch:8 step:8152 [D loss: 0.551838, acc.: 72.66%] [G loss: 0.611783]\n",
      "epoch:8 step:8153 [D loss: 0.516339, acc.: 72.66%] [G loss: 0.688292]\n",
      "epoch:8 step:8154 [D loss: 0.607524, acc.: 64.84%] [G loss: 0.557095]\n",
      "epoch:8 step:8155 [D loss: 0.554870, acc.: 71.09%] [G loss: 0.584889]\n",
      "epoch:8 step:8156 [D loss: 0.505158, acc.: 75.78%] [G loss: 0.664517]\n",
      "epoch:8 step:8157 [D loss: 0.516967, acc.: 72.66%] [G loss: 0.672625]\n",
      "epoch:8 step:8158 [D loss: 0.607745, acc.: 67.19%] [G loss: 0.584778]\n",
      "epoch:8 step:8159 [D loss: 0.605350, acc.: 62.50%] [G loss: 0.484082]\n",
      "epoch:8 step:8160 [D loss: 0.573242, acc.: 67.97%] [G loss: 0.744205]\n",
      "epoch:8 step:8161 [D loss: 0.591515, acc.: 65.62%] [G loss: 0.702492]\n",
      "epoch:8 step:8162 [D loss: 0.538439, acc.: 71.88%] [G loss: 0.872573]\n",
      "epoch:8 step:8163 [D loss: 0.551111, acc.: 70.31%] [G loss: 0.703189]\n",
      "epoch:8 step:8164 [D loss: 0.554209, acc.: 75.00%] [G loss: 0.667953]\n",
      "epoch:8 step:8165 [D loss: 0.505825, acc.: 73.44%] [G loss: 0.525734]\n",
      "epoch:8 step:8166 [D loss: 0.548977, acc.: 67.97%] [G loss: 0.510136]\n",
      "epoch:8 step:8167 [D loss: 0.588240, acc.: 63.28%] [G loss: 0.442334]\n",
      "epoch:8 step:8168 [D loss: 0.612591, acc.: 67.97%] [G loss: 0.653609]\n",
      "epoch:8 step:8169 [D loss: 0.597378, acc.: 64.06%] [G loss: 0.551877]\n",
      "epoch:8 step:8170 [D loss: 0.586482, acc.: 67.97%] [G loss: 0.529707]\n",
      "epoch:8 step:8171 [D loss: 0.580926, acc.: 67.97%] [G loss: 0.634589]\n",
      "epoch:8 step:8172 [D loss: 0.534159, acc.: 74.22%] [G loss: 0.522071]\n",
      "epoch:8 step:8173 [D loss: 0.535148, acc.: 71.09%] [G loss: 0.506387]\n",
      "epoch:8 step:8174 [D loss: 0.601486, acc.: 64.84%] [G loss: 0.633069]\n",
      "epoch:8 step:8175 [D loss: 0.517314, acc.: 72.66%] [G loss: 0.447231]\n",
      "epoch:8 step:8176 [D loss: 0.489505, acc.: 74.22%] [G loss: 0.508079]\n",
      "epoch:8 step:8177 [D loss: 0.485172, acc.: 80.47%] [G loss: 0.497040]\n",
      "epoch:8 step:8178 [D loss: 0.557765, acc.: 67.97%] [G loss: 0.476579]\n",
      "epoch:8 step:8179 [D loss: 0.541777, acc.: 72.66%] [G loss: 0.546936]\n",
      "epoch:8 step:8180 [D loss: 0.572632, acc.: 68.75%] [G loss: 0.456001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8181 [D loss: 0.564842, acc.: 72.66%] [G loss: 0.499754]\n",
      "epoch:8 step:8182 [D loss: 0.559679, acc.: 71.88%] [G loss: 0.506447]\n",
      "epoch:8 step:8183 [D loss: 0.512468, acc.: 71.88%] [G loss: 0.505532]\n",
      "epoch:8 step:8184 [D loss: 0.567637, acc.: 71.88%] [G loss: 0.456385]\n",
      "epoch:8 step:8185 [D loss: 0.565771, acc.: 71.09%] [G loss: 0.558857]\n",
      "epoch:8 step:8186 [D loss: 0.566667, acc.: 66.41%] [G loss: 0.575824]\n",
      "epoch:8 step:8187 [D loss: 0.484755, acc.: 78.91%] [G loss: 0.663003]\n",
      "epoch:8 step:8188 [D loss: 0.551598, acc.: 71.88%] [G loss: 0.609289]\n",
      "epoch:8 step:8189 [D loss: 0.500975, acc.: 73.44%] [G loss: 0.683560]\n",
      "epoch:8 step:8190 [D loss: 0.516582, acc.: 73.44%] [G loss: 0.508091]\n",
      "epoch:8 step:8191 [D loss: 0.513500, acc.: 75.78%] [G loss: 0.564512]\n",
      "epoch:8 step:8192 [D loss: 0.653961, acc.: 60.16%] [G loss: 0.410152]\n",
      "epoch:8 step:8193 [D loss: 0.535064, acc.: 68.75%] [G loss: 0.513760]\n",
      "epoch:8 step:8194 [D loss: 0.553179, acc.: 68.75%] [G loss: 0.533584]\n",
      "epoch:8 step:8195 [D loss: 0.504678, acc.: 76.56%] [G loss: 0.641945]\n",
      "epoch:8 step:8196 [D loss: 0.540836, acc.: 74.22%] [G loss: 0.674300]\n",
      "epoch:8 step:8197 [D loss: 0.562808, acc.: 71.09%] [G loss: 0.682979]\n",
      "epoch:8 step:8198 [D loss: 0.606170, acc.: 67.97%] [G loss: 0.572210]\n",
      "epoch:8 step:8199 [D loss: 0.606287, acc.: 64.84%] [G loss: 0.531475]\n",
      "epoch:8 step:8200 [D loss: 0.623063, acc.: 64.06%] [G loss: 0.479362]\n",
      "##############\n",
      "[3.07317494 1.4816718  6.59416916 4.62405036 4.05787638 5.74275593\n",
      " 4.65955356 4.69100316 4.76344594 3.802553  ]\n",
      "##########\n",
      "epoch:8 step:8201 [D loss: 0.503559, acc.: 75.00%] [G loss: 0.498494]\n",
      "epoch:8 step:8202 [D loss: 0.556262, acc.: 69.53%] [G loss: 0.573671]\n",
      "epoch:8 step:8203 [D loss: 0.489740, acc.: 78.12%] [G loss: 0.604383]\n",
      "epoch:8 step:8204 [D loss: 0.483946, acc.: 75.00%] [G loss: 0.720967]\n",
      "epoch:8 step:8205 [D loss: 0.523949, acc.: 70.31%] [G loss: 0.826785]\n",
      "epoch:8 step:8206 [D loss: 0.648952, acc.: 68.75%] [G loss: 0.500005]\n",
      "epoch:8 step:8207 [D loss: 0.636158, acc.: 65.62%] [G loss: 0.510309]\n",
      "epoch:8 step:8208 [D loss: 0.535100, acc.: 71.09%] [G loss: 0.604502]\n",
      "epoch:8 step:8209 [D loss: 0.652073, acc.: 60.94%] [G loss: 0.438677]\n",
      "epoch:8 step:8210 [D loss: 0.546497, acc.: 70.31%] [G loss: 0.455898]\n",
      "epoch:8 step:8211 [D loss: 0.574012, acc.: 71.09%] [G loss: 0.434530]\n",
      "epoch:8 step:8212 [D loss: 0.634989, acc.: 64.84%] [G loss: 0.526881]\n",
      "epoch:8 step:8213 [D loss: 0.578940, acc.: 69.53%] [G loss: 0.511435]\n",
      "epoch:8 step:8214 [D loss: 0.643508, acc.: 58.59%] [G loss: 0.316156]\n",
      "epoch:8 step:8215 [D loss: 0.510510, acc.: 73.44%] [G loss: 0.622509]\n",
      "epoch:8 step:8216 [D loss: 0.604349, acc.: 69.53%] [G loss: 0.558351]\n",
      "epoch:8 step:8217 [D loss: 0.563231, acc.: 69.53%] [G loss: 0.516361]\n",
      "epoch:8 step:8218 [D loss: 0.531528, acc.: 72.66%] [G loss: 0.526296]\n",
      "epoch:8 step:8219 [D loss: 0.563368, acc.: 67.97%] [G loss: 0.511643]\n",
      "epoch:8 step:8220 [D loss: 0.520566, acc.: 73.44%] [G loss: 0.603331]\n",
      "epoch:8 step:8221 [D loss: 0.508940, acc.: 75.78%] [G loss: 0.676951]\n",
      "epoch:8 step:8222 [D loss: 0.560466, acc.: 71.09%] [G loss: 0.590360]\n",
      "epoch:8 step:8223 [D loss: 0.549635, acc.: 73.44%] [G loss: 0.607463]\n",
      "epoch:8 step:8224 [D loss: 0.543526, acc.: 71.09%] [G loss: 0.464210]\n",
      "epoch:8 step:8225 [D loss: 0.553208, acc.: 65.62%] [G loss: 0.445816]\n",
      "epoch:8 step:8226 [D loss: 0.601578, acc.: 62.50%] [G loss: 0.405776]\n",
      "epoch:8 step:8227 [D loss: 0.579838, acc.: 66.41%] [G loss: 0.546327]\n",
      "epoch:8 step:8228 [D loss: 0.530271, acc.: 71.88%] [G loss: 0.526420]\n",
      "epoch:8 step:8229 [D loss: 0.550439, acc.: 70.31%] [G loss: 0.582001]\n",
      "epoch:8 step:8230 [D loss: 0.570365, acc.: 64.84%] [G loss: 0.522872]\n",
      "epoch:8 step:8231 [D loss: 0.541632, acc.: 72.66%] [G loss: 0.714530]\n",
      "epoch:8 step:8232 [D loss: 0.496930, acc.: 72.66%] [G loss: 0.668792]\n",
      "epoch:8 step:8233 [D loss: 0.567281, acc.: 71.88%] [G loss: 0.466457]\n",
      "epoch:8 step:8234 [D loss: 0.580840, acc.: 66.41%] [G loss: 0.461385]\n",
      "epoch:8 step:8235 [D loss: 0.588182, acc.: 66.41%] [G loss: 0.498871]\n",
      "epoch:8 step:8236 [D loss: 0.616538, acc.: 64.06%] [G loss: 0.336539]\n",
      "epoch:8 step:8237 [D loss: 0.596991, acc.: 67.19%] [G loss: 0.498026]\n",
      "epoch:8 step:8238 [D loss: 0.521556, acc.: 72.66%] [G loss: 0.634620]\n",
      "epoch:8 step:8239 [D loss: 0.523838, acc.: 75.00%] [G loss: 0.583055]\n",
      "epoch:8 step:8240 [D loss: 0.585583, acc.: 71.09%] [G loss: 0.672203]\n",
      "epoch:8 step:8241 [D loss: 0.551086, acc.: 68.75%] [G loss: 0.678523]\n",
      "epoch:8 step:8242 [D loss: 0.465680, acc.: 75.78%] [G loss: 0.688473]\n",
      "epoch:8 step:8243 [D loss: 0.509231, acc.: 73.44%] [G loss: 0.581715]\n",
      "epoch:8 step:8244 [D loss: 0.524951, acc.: 71.09%] [G loss: 0.661119]\n",
      "epoch:8 step:8245 [D loss: 0.548188, acc.: 74.22%] [G loss: 0.644742]\n",
      "epoch:8 step:8246 [D loss: 0.468018, acc.: 80.47%] [G loss: 0.592244]\n",
      "epoch:8 step:8247 [D loss: 0.565335, acc.: 69.53%] [G loss: 0.581736]\n",
      "epoch:8 step:8248 [D loss: 0.564716, acc.: 71.09%] [G loss: 0.589629]\n",
      "epoch:8 step:8249 [D loss: 0.540215, acc.: 70.31%] [G loss: 0.603921]\n",
      "epoch:8 step:8250 [D loss: 0.541314, acc.: 68.75%] [G loss: 0.797530]\n",
      "epoch:8 step:8251 [D loss: 0.532024, acc.: 67.97%] [G loss: 0.571192]\n",
      "epoch:8 step:8252 [D loss: 0.546670, acc.: 71.09%] [G loss: 0.539241]\n",
      "epoch:8 step:8253 [D loss: 0.553194, acc.: 71.09%] [G loss: 0.491921]\n",
      "epoch:8 step:8254 [D loss: 0.537320, acc.: 74.22%] [G loss: 0.642886]\n",
      "epoch:8 step:8255 [D loss: 0.554670, acc.: 71.09%] [G loss: 0.504035]\n",
      "epoch:8 step:8256 [D loss: 0.501015, acc.: 74.22%] [G loss: 0.567513]\n",
      "epoch:8 step:8257 [D loss: 0.552973, acc.: 67.97%] [G loss: 0.567272]\n",
      "epoch:8 step:8258 [D loss: 0.575652, acc.: 65.62%] [G loss: 0.464018]\n",
      "epoch:8 step:8259 [D loss: 0.534898, acc.: 74.22%] [G loss: 0.637814]\n",
      "epoch:8 step:8260 [D loss: 0.547086, acc.: 67.97%] [G loss: 0.495746]\n",
      "epoch:8 step:8261 [D loss: 0.625731, acc.: 64.84%] [G loss: 0.446468]\n",
      "epoch:8 step:8262 [D loss: 0.656026, acc.: 59.38%] [G loss: 0.425037]\n",
      "epoch:8 step:8263 [D loss: 0.570128, acc.: 70.31%] [G loss: 0.508585]\n",
      "epoch:8 step:8264 [D loss: 0.516591, acc.: 71.88%] [G loss: 0.515389]\n",
      "epoch:8 step:8265 [D loss: 0.467828, acc.: 79.69%] [G loss: 0.600288]\n",
      "epoch:8 step:8266 [D loss: 0.553023, acc.: 70.31%] [G loss: 0.716613]\n",
      "epoch:8 step:8267 [D loss: 0.510480, acc.: 74.22%] [G loss: 0.768993]\n",
      "epoch:8 step:8268 [D loss: 0.581829, acc.: 65.62%] [G loss: 0.584318]\n",
      "epoch:8 step:8269 [D loss: 0.525161, acc.: 71.09%] [G loss: 0.574684]\n",
      "epoch:8 step:8270 [D loss: 0.616366, acc.: 66.41%] [G loss: 0.468331]\n",
      "epoch:8 step:8271 [D loss: 0.481169, acc.: 75.00%] [G loss: 0.552414]\n",
      "epoch:8 step:8272 [D loss: 0.579558, acc.: 67.97%] [G loss: 0.580733]\n",
      "epoch:8 step:8273 [D loss: 0.584589, acc.: 68.75%] [G loss: 0.508882]\n",
      "epoch:8 step:8274 [D loss: 0.524300, acc.: 73.44%] [G loss: 0.485388]\n",
      "epoch:8 step:8275 [D loss: 0.583063, acc.: 67.19%] [G loss: 0.562065]\n",
      "epoch:8 step:8276 [D loss: 0.590321, acc.: 70.31%] [G loss: 0.416781]\n",
      "epoch:8 step:8277 [D loss: 0.545159, acc.: 67.19%] [G loss: 0.656433]\n",
      "epoch:8 step:8278 [D loss: 0.509973, acc.: 73.44%] [G loss: 0.726385]\n",
      "epoch:8 step:8279 [D loss: 0.550685, acc.: 71.09%] [G loss: 0.623950]\n",
      "epoch:8 step:8280 [D loss: 0.605285, acc.: 64.06%] [G loss: 0.558907]\n",
      "epoch:8 step:8281 [D loss: 0.549299, acc.: 66.41%] [G loss: 0.516152]\n",
      "epoch:8 step:8282 [D loss: 0.505238, acc.: 75.00%] [G loss: 0.521424]\n",
      "epoch:8 step:8283 [D loss: 0.586409, acc.: 71.09%] [G loss: 0.563334]\n",
      "epoch:8 step:8284 [D loss: 0.672376, acc.: 59.38%] [G loss: 0.520120]\n",
      "epoch:8 step:8285 [D loss: 0.571575, acc.: 64.06%] [G loss: 0.436637]\n",
      "epoch:8 step:8286 [D loss: 0.527356, acc.: 75.00%] [G loss: 0.611980]\n",
      "epoch:8 step:8287 [D loss: 0.555594, acc.: 67.97%] [G loss: 0.490654]\n",
      "epoch:8 step:8288 [D loss: 0.482645, acc.: 75.00%] [G loss: 0.640242]\n",
      "epoch:8 step:8289 [D loss: 0.553333, acc.: 67.97%] [G loss: 0.646871]\n",
      "epoch:8 step:8290 [D loss: 0.656085, acc.: 64.84%] [G loss: 0.585630]\n",
      "epoch:8 step:8291 [D loss: 0.555864, acc.: 68.75%] [G loss: 0.481622]\n",
      "epoch:8 step:8292 [D loss: 0.539422, acc.: 70.31%] [G loss: 0.472925]\n",
      "epoch:8 step:8293 [D loss: 0.513989, acc.: 70.31%] [G loss: 0.482462]\n",
      "epoch:8 step:8294 [D loss: 0.573584, acc.: 66.41%] [G loss: 0.512716]\n",
      "epoch:8 step:8295 [D loss: 0.558641, acc.: 74.22%] [G loss: 0.636418]\n",
      "epoch:8 step:8296 [D loss: 0.616447, acc.: 62.50%] [G loss: 0.552120]\n",
      "epoch:8 step:8297 [D loss: 0.548164, acc.: 71.09%] [G loss: 0.524348]\n",
      "epoch:8 step:8298 [D loss: 0.511407, acc.: 75.78%] [G loss: 0.756168]\n",
      "epoch:8 step:8299 [D loss: 0.531607, acc.: 76.56%] [G loss: 0.635043]\n",
      "epoch:8 step:8300 [D loss: 0.551290, acc.: 68.75%] [G loss: 0.476721]\n",
      "epoch:8 step:8301 [D loss: 0.571617, acc.: 70.31%] [G loss: 0.533523]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8302 [D loss: 0.502836, acc.: 75.00%] [G loss: 0.462341]\n",
      "epoch:8 step:8303 [D loss: 0.551913, acc.: 70.31%] [G loss: 0.558596]\n",
      "epoch:8 step:8304 [D loss: 0.560835, acc.: 70.31%] [G loss: 0.504580]\n",
      "epoch:8 step:8305 [D loss: 0.551910, acc.: 71.88%] [G loss: 0.519507]\n",
      "epoch:8 step:8306 [D loss: 0.590183, acc.: 62.50%] [G loss: 0.483473]\n",
      "epoch:8 step:8307 [D loss: 0.534314, acc.: 75.78%] [G loss: 0.650728]\n",
      "epoch:8 step:8308 [D loss: 0.676926, acc.: 58.59%] [G loss: 0.415620]\n",
      "epoch:8 step:8309 [D loss: 0.537583, acc.: 67.97%] [G loss: 0.480693]\n",
      "epoch:8 step:8310 [D loss: 0.486422, acc.: 78.12%] [G loss: 0.658534]\n",
      "epoch:8 step:8311 [D loss: 0.489768, acc.: 78.12%] [G loss: 0.778029]\n",
      "epoch:8 step:8312 [D loss: 0.677801, acc.: 61.72%] [G loss: 0.524348]\n",
      "epoch:8 step:8313 [D loss: 0.633110, acc.: 67.19%] [G loss: 0.628720]\n",
      "epoch:8 step:8314 [D loss: 0.544429, acc.: 67.19%] [G loss: 0.757897]\n",
      "epoch:8 step:8315 [D loss: 0.516674, acc.: 72.66%] [G loss: 0.595396]\n",
      "epoch:8 step:8316 [D loss: 0.583286, acc.: 67.97%] [G loss: 0.484973]\n",
      "epoch:8 step:8317 [D loss: 0.537353, acc.: 72.66%] [G loss: 0.588494]\n",
      "epoch:8 step:8318 [D loss: 0.556104, acc.: 68.75%] [G loss: 0.520909]\n",
      "epoch:8 step:8319 [D loss: 0.422732, acc.: 79.69%] [G loss: 0.626078]\n",
      "epoch:8 step:8320 [D loss: 0.579244, acc.: 67.19%] [G loss: 0.601996]\n",
      "epoch:8 step:8321 [D loss: 0.535021, acc.: 77.34%] [G loss: 0.547162]\n",
      "epoch:8 step:8322 [D loss: 0.588126, acc.: 69.53%] [G loss: 0.501564]\n",
      "epoch:8 step:8323 [D loss: 0.557181, acc.: 67.19%] [G loss: 0.509110]\n",
      "epoch:8 step:8324 [D loss: 0.648092, acc.: 60.16%] [G loss: 0.603409]\n",
      "epoch:8 step:8325 [D loss: 0.501217, acc.: 76.56%] [G loss: 0.545166]\n",
      "epoch:8 step:8326 [D loss: 0.561785, acc.: 69.53%] [G loss: 0.592829]\n",
      "epoch:8 step:8327 [D loss: 0.534400, acc.: 75.00%] [G loss: 0.585063]\n",
      "epoch:8 step:8328 [D loss: 0.558073, acc.: 68.75%] [G loss: 0.516313]\n",
      "epoch:8 step:8329 [D loss: 0.533216, acc.: 75.78%] [G loss: 0.654593]\n",
      "epoch:8 step:8330 [D loss: 0.520364, acc.: 73.44%] [G loss: 0.513438]\n",
      "epoch:8 step:8331 [D loss: 0.503907, acc.: 78.91%] [G loss: 0.617821]\n",
      "epoch:8 step:8332 [D loss: 0.493400, acc.: 75.78%] [G loss: 0.633499]\n",
      "epoch:8 step:8333 [D loss: 0.542281, acc.: 68.75%] [G loss: 0.492210]\n",
      "epoch:8 step:8334 [D loss: 0.483203, acc.: 76.56%] [G loss: 0.572433]\n",
      "epoch:8 step:8335 [D loss: 0.565470, acc.: 64.84%] [G loss: 0.592231]\n",
      "epoch:8 step:8336 [D loss: 0.652407, acc.: 59.38%] [G loss: 0.455932]\n",
      "epoch:8 step:8337 [D loss: 0.589253, acc.: 62.50%] [G loss: 0.428363]\n",
      "epoch:8 step:8338 [D loss: 0.524972, acc.: 73.44%] [G loss: 0.605989]\n",
      "epoch:8 step:8339 [D loss: 0.507001, acc.: 75.00%] [G loss: 0.601942]\n",
      "epoch:8 step:8340 [D loss: 0.574563, acc.: 71.09%] [G loss: 0.611927]\n",
      "epoch:8 step:8341 [D loss: 0.588071, acc.: 69.53%] [G loss: 0.559956]\n",
      "epoch:8 step:8342 [D loss: 0.558435, acc.: 67.97%] [G loss: 0.499751]\n",
      "epoch:8 step:8343 [D loss: 0.595626, acc.: 66.41%] [G loss: 0.452609]\n",
      "epoch:8 step:8344 [D loss: 0.515858, acc.: 75.00%] [G loss: 0.448821]\n",
      "epoch:8 step:8345 [D loss: 0.563502, acc.: 69.53%] [G loss: 0.492076]\n",
      "epoch:8 step:8346 [D loss: 0.552837, acc.: 67.97%] [G loss: 0.450481]\n",
      "epoch:8 step:8347 [D loss: 0.550326, acc.: 73.44%] [G loss: 0.586977]\n",
      "epoch:8 step:8348 [D loss: 0.567201, acc.: 68.75%] [G loss: 0.489235]\n",
      "epoch:8 step:8349 [D loss: 0.494000, acc.: 73.44%] [G loss: 0.664182]\n",
      "epoch:8 step:8350 [D loss: 0.549974, acc.: 65.62%] [G loss: 0.535591]\n",
      "epoch:8 step:8351 [D loss: 0.521615, acc.: 71.88%] [G loss: 0.555406]\n",
      "epoch:8 step:8352 [D loss: 0.622234, acc.: 59.38%] [G loss: 0.609716]\n",
      "epoch:8 step:8353 [D loss: 0.467524, acc.: 78.91%] [G loss: 0.551912]\n",
      "epoch:8 step:8354 [D loss: 0.661165, acc.: 57.81%] [G loss: 0.469119]\n",
      "epoch:8 step:8355 [D loss: 0.610410, acc.: 64.84%] [G loss: 0.684899]\n",
      "epoch:8 step:8356 [D loss: 0.482248, acc.: 75.78%] [G loss: 0.858799]\n",
      "epoch:8 step:8357 [D loss: 0.625893, acc.: 65.62%] [G loss: 0.605078]\n",
      "epoch:8 step:8358 [D loss: 0.586960, acc.: 70.31%] [G loss: 0.582293]\n",
      "epoch:8 step:8359 [D loss: 0.632537, acc.: 61.72%] [G loss: 0.363349]\n",
      "epoch:8 step:8360 [D loss: 0.526622, acc.: 72.66%] [G loss: 0.450171]\n",
      "epoch:8 step:8361 [D loss: 0.533547, acc.: 72.66%] [G loss: 0.529748]\n",
      "epoch:8 step:8362 [D loss: 0.546667, acc.: 69.53%] [G loss: 0.523440]\n",
      "epoch:8 step:8363 [D loss: 0.648052, acc.: 62.50%] [G loss: 0.421922]\n",
      "epoch:8 step:8364 [D loss: 0.477218, acc.: 78.91%] [G loss: 0.498491]\n",
      "epoch:8 step:8365 [D loss: 0.580313, acc.: 67.19%] [G loss: 0.456293]\n",
      "epoch:8 step:8366 [D loss: 0.435947, acc.: 81.25%] [G loss: 0.585711]\n",
      "epoch:8 step:8367 [D loss: 0.515552, acc.: 75.00%] [G loss: 0.501303]\n",
      "epoch:8 step:8368 [D loss: 0.539259, acc.: 67.97%] [G loss: 0.657685]\n",
      "epoch:8 step:8369 [D loss: 0.608372, acc.: 67.19%] [G loss: 0.654169]\n",
      "epoch:8 step:8370 [D loss: 0.577000, acc.: 71.88%] [G loss: 0.486326]\n",
      "epoch:8 step:8371 [D loss: 0.482631, acc.: 76.56%] [G loss: 0.588759]\n",
      "epoch:8 step:8372 [D loss: 0.537037, acc.: 75.00%] [G loss: 0.525866]\n",
      "epoch:8 step:8373 [D loss: 0.561706, acc.: 70.31%] [G loss: 0.486389]\n",
      "epoch:8 step:8374 [D loss: 0.602228, acc.: 65.62%] [G loss: 0.558580]\n",
      "epoch:8 step:8375 [D loss: 0.596707, acc.: 69.53%] [G loss: 0.531547]\n",
      "epoch:8 step:8376 [D loss: 0.662479, acc.: 59.38%] [G loss: 0.389646]\n",
      "epoch:8 step:8377 [D loss: 0.590593, acc.: 64.84%] [G loss: 0.427184]\n",
      "epoch:8 step:8378 [D loss: 0.552489, acc.: 71.09%] [G loss: 0.527283]\n",
      "epoch:8 step:8379 [D loss: 0.537727, acc.: 71.88%] [G loss: 0.495034]\n",
      "epoch:8 step:8380 [D loss: 0.471077, acc.: 81.25%] [G loss: 0.776769]\n",
      "epoch:8 step:8381 [D loss: 0.552492, acc.: 64.84%] [G loss: 0.677781]\n",
      "epoch:8 step:8382 [D loss: 0.565330, acc.: 68.75%] [G loss: 0.705373]\n",
      "epoch:8 step:8383 [D loss: 0.557652, acc.: 70.31%] [G loss: 0.736029]\n",
      "epoch:8 step:8384 [D loss: 0.542246, acc.: 69.53%] [G loss: 0.623934]\n",
      "epoch:8 step:8385 [D loss: 0.547305, acc.: 72.66%] [G loss: 0.546398]\n",
      "epoch:8 step:8386 [D loss: 0.471743, acc.: 81.25%] [G loss: 0.614625]\n",
      "epoch:8 step:8387 [D loss: 0.578976, acc.: 68.75%] [G loss: 0.471542]\n",
      "epoch:8 step:8388 [D loss: 0.570174, acc.: 67.19%] [G loss: 0.579883]\n",
      "epoch:8 step:8389 [D loss: 0.522707, acc.: 75.00%] [G loss: 0.541097]\n",
      "epoch:8 step:8390 [D loss: 0.499814, acc.: 75.78%] [G loss: 0.741332]\n",
      "epoch:8 step:8391 [D loss: 0.533389, acc.: 71.09%] [G loss: 0.730473]\n",
      "epoch:8 step:8392 [D loss: 0.521815, acc.: 71.88%] [G loss: 0.713385]\n",
      "epoch:8 step:8393 [D loss: 0.565162, acc.: 75.00%] [G loss: 0.614814]\n",
      "epoch:8 step:8394 [D loss: 0.519305, acc.: 73.44%] [G loss: 0.649296]\n",
      "epoch:8 step:8395 [D loss: 0.484783, acc.: 75.78%] [G loss: 0.685964]\n",
      "epoch:8 step:8396 [D loss: 0.570160, acc.: 74.22%] [G loss: 0.611918]\n",
      "epoch:8 step:8397 [D loss: 0.543293, acc.: 72.66%] [G loss: 0.617768]\n",
      "epoch:8 step:8398 [D loss: 0.611975, acc.: 67.97%] [G loss: 0.558018]\n",
      "epoch:8 step:8399 [D loss: 0.520328, acc.: 74.22%] [G loss: 0.631551]\n",
      "epoch:8 step:8400 [D loss: 0.592171, acc.: 67.19%] [G loss: 0.505608]\n",
      "##############\n",
      "[3.20096289 1.13866409 6.45648071 5.11674775 4.10790983 5.88406381\n",
      " 4.79804701 4.70970456 4.54515788 3.93379658]\n",
      "##########\n",
      "epoch:8 step:8401 [D loss: 0.606590, acc.: 66.41%] [G loss: 0.478128]\n",
      "epoch:8 step:8402 [D loss: 0.504283, acc.: 75.78%] [G loss: 0.669807]\n",
      "epoch:8 step:8403 [D loss: 0.571254, acc.: 72.66%] [G loss: 0.623147]\n",
      "epoch:8 step:8404 [D loss: 0.477078, acc.: 77.34%] [G loss: 0.632899]\n",
      "epoch:8 step:8405 [D loss: 0.515057, acc.: 71.09%] [G loss: 0.607831]\n",
      "epoch:8 step:8406 [D loss: 0.496706, acc.: 74.22%] [G loss: 0.592199]\n",
      "epoch:8 step:8407 [D loss: 0.463224, acc.: 75.78%] [G loss: 0.783673]\n",
      "epoch:8 step:8408 [D loss: 0.529962, acc.: 73.44%] [G loss: 0.670992]\n",
      "epoch:8 step:8409 [D loss: 0.547477, acc.: 74.22%] [G loss: 0.786500]\n",
      "epoch:8 step:8410 [D loss: 0.426108, acc.: 83.59%] [G loss: 0.785971]\n",
      "epoch:8 step:8411 [D loss: 0.651886, acc.: 60.16%] [G loss: 0.510834]\n",
      "epoch:8 step:8412 [D loss: 0.519430, acc.: 72.66%] [G loss: 0.605691]\n",
      "epoch:8 step:8413 [D loss: 0.594053, acc.: 67.97%] [G loss: 0.516123]\n",
      "epoch:8 step:8414 [D loss: 0.517166, acc.: 73.44%] [G loss: 0.514748]\n",
      "epoch:8 step:8415 [D loss: 0.533089, acc.: 73.44%] [G loss: 0.828206]\n",
      "epoch:8 step:8416 [D loss: 0.717216, acc.: 57.81%] [G loss: 0.669175]\n",
      "epoch:8 step:8417 [D loss: 0.454809, acc.: 78.12%] [G loss: 0.715424]\n",
      "epoch:8 step:8418 [D loss: 0.591272, acc.: 66.41%] [G loss: 0.539699]\n",
      "epoch:8 step:8419 [D loss: 0.458613, acc.: 79.69%] [G loss: 0.555270]\n",
      "epoch:8 step:8420 [D loss: 0.412186, acc.: 84.38%] [G loss: 0.632215]\n",
      "epoch:8 step:8421 [D loss: 0.500059, acc.: 72.66%] [G loss: 0.814213]\n",
      "epoch:8 step:8422 [D loss: 0.456218, acc.: 78.12%] [G loss: 0.849818]\n",
      "epoch:8 step:8423 [D loss: 0.500626, acc.: 74.22%] [G loss: 0.946689]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8424 [D loss: 0.746424, acc.: 63.28%] [G loss: 0.742053]\n",
      "epoch:8 step:8425 [D loss: 0.540711, acc.: 69.53%] [G loss: 0.999982]\n",
      "epoch:8 step:8426 [D loss: 0.481372, acc.: 73.44%] [G loss: 0.804585]\n",
      "epoch:8 step:8427 [D loss: 0.550039, acc.: 71.09%] [G loss: 0.660668]\n",
      "epoch:8 step:8428 [D loss: 0.618690, acc.: 65.62%] [G loss: 0.564894]\n",
      "epoch:8 step:8429 [D loss: 0.499818, acc.: 72.66%] [G loss: 0.653744]\n",
      "epoch:8 step:8430 [D loss: 0.508080, acc.: 71.09%] [G loss: 0.701149]\n",
      "epoch:8 step:8431 [D loss: 0.551020, acc.: 70.31%] [G loss: 0.847529]\n",
      "epoch:8 step:8432 [D loss: 0.374650, acc.: 85.16%] [G loss: 1.046187]\n",
      "epoch:8 step:8433 [D loss: 0.454773, acc.: 77.34%] [G loss: 1.173949]\n",
      "epoch:9 step:8434 [D loss: 0.561269, acc.: 67.97%] [G loss: 0.752330]\n",
      "epoch:9 step:8435 [D loss: 0.532994, acc.: 74.22%] [G loss: 0.966730]\n",
      "epoch:9 step:8436 [D loss: 0.551066, acc.: 70.31%] [G loss: 0.669747]\n",
      "epoch:9 step:8437 [D loss: 0.544023, acc.: 75.00%] [G loss: 0.778173]\n",
      "epoch:9 step:8438 [D loss: 0.586712, acc.: 66.41%] [G loss: 0.730355]\n",
      "epoch:9 step:8439 [D loss: 0.558941, acc.: 71.09%] [G loss: 0.671517]\n",
      "epoch:9 step:8440 [D loss: 0.500516, acc.: 75.00%] [G loss: 0.571026]\n",
      "epoch:9 step:8441 [D loss: 0.529776, acc.: 75.00%] [G loss: 0.771434]\n",
      "epoch:9 step:8442 [D loss: 0.562160, acc.: 71.09%] [G loss: 0.661902]\n",
      "epoch:9 step:8443 [D loss: 0.532357, acc.: 75.78%] [G loss: 0.613344]\n",
      "epoch:9 step:8444 [D loss: 0.484947, acc.: 76.56%] [G loss: 0.675348]\n",
      "epoch:9 step:8445 [D loss: 0.590260, acc.: 63.28%] [G loss: 0.519764]\n",
      "epoch:9 step:8446 [D loss: 0.555634, acc.: 67.97%] [G loss: 0.613585]\n",
      "epoch:9 step:8447 [D loss: 0.565152, acc.: 66.41%] [G loss: 0.585248]\n",
      "epoch:9 step:8448 [D loss: 0.484701, acc.: 75.78%] [G loss: 0.623192]\n",
      "epoch:9 step:8449 [D loss: 0.487533, acc.: 74.22%] [G loss: 0.711913]\n",
      "epoch:9 step:8450 [D loss: 0.573639, acc.: 67.97%] [G loss: 0.653644]\n",
      "epoch:9 step:8451 [D loss: 0.579291, acc.: 71.09%] [G loss: 0.708460]\n",
      "epoch:9 step:8452 [D loss: 0.603216, acc.: 67.19%] [G loss: 0.581719]\n",
      "epoch:9 step:8453 [D loss: 0.641571, acc.: 64.06%] [G loss: 0.457290]\n",
      "epoch:9 step:8454 [D loss: 0.581274, acc.: 67.19%] [G loss: 0.480523]\n",
      "epoch:9 step:8455 [D loss: 0.496120, acc.: 75.78%] [G loss: 0.538097]\n",
      "epoch:9 step:8456 [D loss: 0.434426, acc.: 82.81%] [G loss: 0.626846]\n",
      "epoch:9 step:8457 [D loss: 0.514098, acc.: 75.00%] [G loss: 0.693309]\n",
      "epoch:9 step:8458 [D loss: 0.485253, acc.: 78.91%] [G loss: 0.606270]\n",
      "epoch:9 step:8459 [D loss: 0.581494, acc.: 70.31%] [G loss: 0.492394]\n",
      "epoch:9 step:8460 [D loss: 0.460112, acc.: 75.00%] [G loss: 0.581706]\n",
      "epoch:9 step:8461 [D loss: 0.544064, acc.: 71.09%] [G loss: 0.549739]\n",
      "epoch:9 step:8462 [D loss: 0.497589, acc.: 75.78%] [G loss: 0.524002]\n",
      "epoch:9 step:8463 [D loss: 0.545214, acc.: 73.44%] [G loss: 0.532787]\n",
      "epoch:9 step:8464 [D loss: 0.566326, acc.: 67.19%] [G loss: 0.631016]\n",
      "epoch:9 step:8465 [D loss: 0.582725, acc.: 68.75%] [G loss: 0.467741]\n",
      "epoch:9 step:8466 [D loss: 0.558629, acc.: 71.09%] [G loss: 0.552260]\n",
      "epoch:9 step:8467 [D loss: 0.527443, acc.: 71.88%] [G loss: 0.648969]\n",
      "epoch:9 step:8468 [D loss: 0.546380, acc.: 72.66%] [G loss: 0.602073]\n",
      "epoch:9 step:8469 [D loss: 0.561483, acc.: 68.75%] [G loss: 0.586360]\n",
      "epoch:9 step:8470 [D loss: 0.520798, acc.: 73.44%] [G loss: 0.620022]\n",
      "epoch:9 step:8471 [D loss: 0.604962, acc.: 69.53%] [G loss: 0.588167]\n",
      "epoch:9 step:8472 [D loss: 0.556235, acc.: 75.00%] [G loss: 0.636341]\n",
      "epoch:9 step:8473 [D loss: 0.499247, acc.: 75.00%] [G loss: 0.721547]\n",
      "epoch:9 step:8474 [D loss: 0.543632, acc.: 67.19%] [G loss: 0.616732]\n",
      "epoch:9 step:8475 [D loss: 0.571069, acc.: 71.09%] [G loss: 0.493781]\n",
      "epoch:9 step:8476 [D loss: 0.519704, acc.: 70.31%] [G loss: 0.564519]\n",
      "epoch:9 step:8477 [D loss: 0.589449, acc.: 66.41%] [G loss: 0.572513]\n",
      "epoch:9 step:8478 [D loss: 0.551879, acc.: 71.09%] [G loss: 0.510816]\n",
      "epoch:9 step:8479 [D loss: 0.492536, acc.: 75.00%] [G loss: 0.586409]\n",
      "epoch:9 step:8480 [D loss: 0.543708, acc.: 70.31%] [G loss: 0.531254]\n",
      "epoch:9 step:8481 [D loss: 0.512498, acc.: 77.34%] [G loss: 0.576894]\n",
      "epoch:9 step:8482 [D loss: 0.525631, acc.: 78.91%] [G loss: 0.722206]\n",
      "epoch:9 step:8483 [D loss: 0.527467, acc.: 75.78%] [G loss: 0.605439]\n",
      "epoch:9 step:8484 [D loss: 0.694484, acc.: 59.38%] [G loss: 0.565543]\n",
      "epoch:9 step:8485 [D loss: 0.607792, acc.: 64.84%] [G loss: 0.480830]\n",
      "epoch:9 step:8486 [D loss: 0.550060, acc.: 69.53%] [G loss: 0.529059]\n",
      "epoch:9 step:8487 [D loss: 0.443675, acc.: 80.47%] [G loss: 0.719528]\n",
      "epoch:9 step:8488 [D loss: 0.572421, acc.: 68.75%] [G loss: 0.624192]\n",
      "epoch:9 step:8489 [D loss: 0.562199, acc.: 71.88%] [G loss: 0.568893]\n",
      "epoch:9 step:8490 [D loss: 0.580462, acc.: 67.97%] [G loss: 0.527107]\n",
      "epoch:9 step:8491 [D loss: 0.595899, acc.: 66.41%] [G loss: 0.655360]\n",
      "epoch:9 step:8492 [D loss: 0.513849, acc.: 78.12%] [G loss: 0.631017]\n",
      "epoch:9 step:8493 [D loss: 0.532699, acc.: 71.88%] [G loss: 0.558246]\n",
      "epoch:9 step:8494 [D loss: 0.559140, acc.: 71.88%] [G loss: 0.558628]\n",
      "epoch:9 step:8495 [D loss: 0.566860, acc.: 71.09%] [G loss: 0.477751]\n",
      "epoch:9 step:8496 [D loss: 0.554727, acc.: 69.53%] [G loss: 0.410557]\n",
      "epoch:9 step:8497 [D loss: 0.559472, acc.: 71.88%] [G loss: 0.568785]\n",
      "epoch:9 step:8498 [D loss: 0.502585, acc.: 78.12%] [G loss: 0.498413]\n",
      "epoch:9 step:8499 [D loss: 0.507821, acc.: 76.56%] [G loss: 0.557352]\n",
      "epoch:9 step:8500 [D loss: 0.561636, acc.: 64.06%] [G loss: 0.560408]\n",
      "epoch:9 step:8501 [D loss: 0.537010, acc.: 71.88%] [G loss: 0.580379]\n",
      "epoch:9 step:8502 [D loss: 0.536613, acc.: 71.09%] [G loss: 0.498224]\n",
      "epoch:9 step:8503 [D loss: 0.542870, acc.: 71.88%] [G loss: 0.652207]\n",
      "epoch:9 step:8504 [D loss: 0.547318, acc.: 73.44%] [G loss: 0.627211]\n",
      "epoch:9 step:8505 [D loss: 0.607265, acc.: 64.06%] [G loss: 0.518276]\n",
      "epoch:9 step:8506 [D loss: 0.515166, acc.: 75.00%] [G loss: 0.652338]\n",
      "epoch:9 step:8507 [D loss: 0.530960, acc.: 74.22%] [G loss: 0.604155]\n",
      "epoch:9 step:8508 [D loss: 0.570638, acc.: 71.09%] [G loss: 0.611152]\n",
      "epoch:9 step:8509 [D loss: 0.521667, acc.: 75.00%] [G loss: 0.638791]\n",
      "epoch:9 step:8510 [D loss: 0.447548, acc.: 81.25%] [G loss: 0.721775]\n",
      "epoch:9 step:8511 [D loss: 0.616236, acc.: 67.19%] [G loss: 0.545696]\n",
      "epoch:9 step:8512 [D loss: 0.553534, acc.: 69.53%] [G loss: 0.534505]\n",
      "epoch:9 step:8513 [D loss: 0.563925, acc.: 67.97%] [G loss: 0.636054]\n",
      "epoch:9 step:8514 [D loss: 0.585548, acc.: 64.06%] [G loss: 0.619457]\n",
      "epoch:9 step:8515 [D loss: 0.508849, acc.: 75.00%] [G loss: 0.603409]\n",
      "epoch:9 step:8516 [D loss: 0.503783, acc.: 75.78%] [G loss: 0.638280]\n",
      "epoch:9 step:8517 [D loss: 0.539294, acc.: 73.44%] [G loss: 0.659988]\n",
      "epoch:9 step:8518 [D loss: 0.575887, acc.: 72.66%] [G loss: 0.552280]\n",
      "epoch:9 step:8519 [D loss: 0.542425, acc.: 69.53%] [G loss: 0.357426]\n",
      "epoch:9 step:8520 [D loss: 0.540961, acc.: 70.31%] [G loss: 0.459939]\n",
      "epoch:9 step:8521 [D loss: 0.494733, acc.: 77.34%] [G loss: 0.512178]\n",
      "epoch:9 step:8522 [D loss: 0.505785, acc.: 73.44%] [G loss: 0.533651]\n",
      "epoch:9 step:8523 [D loss: 0.484970, acc.: 76.56%] [G loss: 0.622273]\n",
      "epoch:9 step:8524 [D loss: 0.525204, acc.: 76.56%] [G loss: 0.596525]\n",
      "epoch:9 step:8525 [D loss: 0.510542, acc.: 71.09%] [G loss: 0.680191]\n",
      "epoch:9 step:8526 [D loss: 0.505635, acc.: 76.56%] [G loss: 0.654611]\n",
      "epoch:9 step:8527 [D loss: 0.486588, acc.: 77.34%] [G loss: 0.737489]\n",
      "epoch:9 step:8528 [D loss: 0.556414, acc.: 66.41%] [G loss: 0.599878]\n",
      "epoch:9 step:8529 [D loss: 0.565802, acc.: 70.31%] [G loss: 0.445005]\n",
      "epoch:9 step:8530 [D loss: 0.583097, acc.: 64.84%] [G loss: 0.677381]\n",
      "epoch:9 step:8531 [D loss: 0.567809, acc.: 69.53%] [G loss: 0.575675]\n",
      "epoch:9 step:8532 [D loss: 0.534416, acc.: 70.31%] [G loss: 0.712755]\n",
      "epoch:9 step:8533 [D loss: 0.450412, acc.: 78.12%] [G loss: 0.644768]\n",
      "epoch:9 step:8534 [D loss: 0.529014, acc.: 72.66%] [G loss: 0.574530]\n",
      "epoch:9 step:8535 [D loss: 0.610901, acc.: 70.31%] [G loss: 0.528285]\n",
      "epoch:9 step:8536 [D loss: 0.509318, acc.: 76.56%] [G loss: 0.494686]\n",
      "epoch:9 step:8537 [D loss: 0.557096, acc.: 70.31%] [G loss: 0.629319]\n",
      "epoch:9 step:8538 [D loss: 0.556746, acc.: 70.31%] [G loss: 0.603512]\n",
      "epoch:9 step:8539 [D loss: 0.574347, acc.: 71.09%] [G loss: 0.521768]\n",
      "epoch:9 step:8540 [D loss: 0.565897, acc.: 71.88%] [G loss: 0.575141]\n",
      "epoch:9 step:8541 [D loss: 0.616276, acc.: 62.50%] [G loss: 0.489251]\n",
      "epoch:9 step:8542 [D loss: 0.611595, acc.: 63.28%] [G loss: 0.432124]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8543 [D loss: 0.546913, acc.: 75.00%] [G loss: 0.539695]\n",
      "epoch:9 step:8544 [D loss: 0.495484, acc.: 71.09%] [G loss: 0.737216]\n",
      "epoch:9 step:8545 [D loss: 0.597343, acc.: 69.53%] [G loss: 0.661184]\n",
      "epoch:9 step:8546 [D loss: 0.573733, acc.: 71.88%] [G loss: 0.509722]\n",
      "epoch:9 step:8547 [D loss: 0.631860, acc.: 65.62%] [G loss: 0.581212]\n",
      "epoch:9 step:8548 [D loss: 0.558824, acc.: 72.66%] [G loss: 0.860901]\n",
      "epoch:9 step:8549 [D loss: 0.529931, acc.: 71.09%] [G loss: 0.582630]\n",
      "epoch:9 step:8550 [D loss: 0.576170, acc.: 64.84%] [G loss: 0.655928]\n",
      "epoch:9 step:8551 [D loss: 0.523302, acc.: 69.53%] [G loss: 0.548034]\n",
      "epoch:9 step:8552 [D loss: 0.469035, acc.: 78.91%] [G loss: 0.627561]\n",
      "epoch:9 step:8553 [D loss: 0.612912, acc.: 66.41%] [G loss: 0.611043]\n",
      "epoch:9 step:8554 [D loss: 0.567221, acc.: 67.97%] [G loss: 0.590425]\n",
      "epoch:9 step:8555 [D loss: 0.500443, acc.: 78.91%] [G loss: 0.654707]\n",
      "epoch:9 step:8556 [D loss: 0.545833, acc.: 68.75%] [G loss: 0.570095]\n",
      "epoch:9 step:8557 [D loss: 0.570734, acc.: 68.75%] [G loss: 0.666442]\n",
      "epoch:9 step:8558 [D loss: 0.542081, acc.: 71.09%] [G loss: 0.598383]\n",
      "epoch:9 step:8559 [D loss: 0.510940, acc.: 78.12%] [G loss: 0.556894]\n",
      "epoch:9 step:8560 [D loss: 0.502764, acc.: 73.44%] [G loss: 0.504570]\n",
      "epoch:9 step:8561 [D loss: 0.526212, acc.: 69.53%] [G loss: 0.600710]\n",
      "epoch:9 step:8562 [D loss: 0.578575, acc.: 64.84%] [G loss: 0.480756]\n",
      "epoch:9 step:8563 [D loss: 0.526273, acc.: 75.00%] [G loss: 0.601833]\n",
      "epoch:9 step:8564 [D loss: 0.566679, acc.: 67.97%] [G loss: 0.662624]\n",
      "epoch:9 step:8565 [D loss: 0.572075, acc.: 67.19%] [G loss: 0.516245]\n",
      "epoch:9 step:8566 [D loss: 0.667132, acc.: 59.38%] [G loss: 0.540714]\n",
      "epoch:9 step:8567 [D loss: 0.543784, acc.: 67.97%] [G loss: 0.523304]\n",
      "epoch:9 step:8568 [D loss: 0.543906, acc.: 72.66%] [G loss: 0.465378]\n",
      "epoch:9 step:8569 [D loss: 0.589090, acc.: 66.41%] [G loss: 0.590986]\n",
      "epoch:9 step:8570 [D loss: 0.601729, acc.: 64.06%] [G loss: 0.497676]\n",
      "epoch:9 step:8571 [D loss: 0.581325, acc.: 65.62%] [G loss: 0.520351]\n",
      "epoch:9 step:8572 [D loss: 0.537297, acc.: 75.00%] [G loss: 0.675812]\n",
      "epoch:9 step:8573 [D loss: 0.572807, acc.: 67.19%] [G loss: 0.546542]\n",
      "epoch:9 step:8574 [D loss: 0.597499, acc.: 64.84%] [G loss: 0.454348]\n",
      "epoch:9 step:8575 [D loss: 0.566928, acc.: 69.53%] [G loss: 0.544702]\n",
      "epoch:9 step:8576 [D loss: 0.626408, acc.: 66.41%] [G loss: 0.592281]\n",
      "epoch:9 step:8577 [D loss: 0.512055, acc.: 75.00%] [G loss: 0.565587]\n",
      "epoch:9 step:8578 [D loss: 0.551828, acc.: 69.53%] [G loss: 0.505025]\n",
      "epoch:9 step:8579 [D loss: 0.528091, acc.: 75.78%] [G loss: 0.556471]\n",
      "epoch:9 step:8580 [D loss: 0.625292, acc.: 67.97%] [G loss: 0.565992]\n",
      "epoch:9 step:8581 [D loss: 0.571035, acc.: 65.62%] [G loss: 0.564324]\n",
      "epoch:9 step:8582 [D loss: 0.498234, acc.: 75.00%] [G loss: 0.671854]\n",
      "epoch:9 step:8583 [D loss: 0.601135, acc.: 64.06%] [G loss: 0.437971]\n",
      "epoch:9 step:8584 [D loss: 0.564007, acc.: 72.66%] [G loss: 0.483344]\n",
      "epoch:9 step:8585 [D loss: 0.516986, acc.: 75.78%] [G loss: 0.594576]\n",
      "epoch:9 step:8586 [D loss: 0.608573, acc.: 64.06%] [G loss: 0.392696]\n",
      "epoch:9 step:8587 [D loss: 0.498942, acc.: 74.22%] [G loss: 0.514393]\n",
      "epoch:9 step:8588 [D loss: 0.492336, acc.: 72.66%] [G loss: 0.594947]\n",
      "epoch:9 step:8589 [D loss: 0.529997, acc.: 76.56%] [G loss: 0.669722]\n",
      "epoch:9 step:8590 [D loss: 0.536356, acc.: 68.75%] [G loss: 0.596018]\n",
      "epoch:9 step:8591 [D loss: 0.570392, acc.: 67.97%] [G loss: 0.532933]\n",
      "epoch:9 step:8592 [D loss: 0.545231, acc.: 75.78%] [G loss: 0.565213]\n",
      "epoch:9 step:8593 [D loss: 0.637123, acc.: 61.72%] [G loss: 0.568010]\n",
      "epoch:9 step:8594 [D loss: 0.545542, acc.: 71.09%] [G loss: 0.686778]\n",
      "epoch:9 step:8595 [D loss: 0.514546, acc.: 74.22%] [G loss: 0.774760]\n",
      "epoch:9 step:8596 [D loss: 0.533404, acc.: 71.88%] [G loss: 0.602663]\n",
      "epoch:9 step:8597 [D loss: 0.504333, acc.: 72.66%] [G loss: 0.599430]\n",
      "epoch:9 step:8598 [D loss: 0.544370, acc.: 68.75%] [G loss: 0.598204]\n",
      "epoch:9 step:8599 [D loss: 0.555075, acc.: 70.31%] [G loss: 0.520976]\n",
      "epoch:9 step:8600 [D loss: 0.551100, acc.: 70.31%] [G loss: 0.568157]\n",
      "##############\n",
      "[2.9905807  1.2478961  6.77141928 4.83712569 3.68664975 5.80023927\n",
      " 4.93083899 5.09966541 4.46537262 3.94618395]\n",
      "##########\n",
      "epoch:9 step:8601 [D loss: 0.549778, acc.: 75.00%] [G loss: 0.593027]\n",
      "epoch:9 step:8602 [D loss: 0.556225, acc.: 66.41%] [G loss: 0.552487]\n",
      "epoch:9 step:8603 [D loss: 0.519624, acc.: 71.88%] [G loss: 0.460680]\n",
      "epoch:9 step:8604 [D loss: 0.539673, acc.: 70.31%] [G loss: 0.448946]\n",
      "epoch:9 step:8605 [D loss: 0.536920, acc.: 73.44%] [G loss: 0.601409]\n",
      "epoch:9 step:8606 [D loss: 0.513603, acc.: 74.22%] [G loss: 0.542820]\n",
      "epoch:9 step:8607 [D loss: 0.620618, acc.: 62.50%] [G loss: 0.477678]\n",
      "epoch:9 step:8608 [D loss: 0.573798, acc.: 69.53%] [G loss: 0.523753]\n",
      "epoch:9 step:8609 [D loss: 0.579211, acc.: 71.09%] [G loss: 0.407923]\n",
      "epoch:9 step:8610 [D loss: 0.570552, acc.: 74.22%] [G loss: 0.458705]\n",
      "epoch:9 step:8611 [D loss: 0.531867, acc.: 75.78%] [G loss: 0.657269]\n",
      "epoch:9 step:8612 [D loss: 0.551028, acc.: 69.53%] [G loss: 0.471758]\n",
      "epoch:9 step:8613 [D loss: 0.625817, acc.: 62.50%] [G loss: 0.460912]\n",
      "epoch:9 step:8614 [D loss: 0.568777, acc.: 67.97%] [G loss: 0.542504]\n",
      "epoch:9 step:8615 [D loss: 0.553339, acc.: 70.31%] [G loss: 0.587116]\n",
      "epoch:9 step:8616 [D loss: 0.562506, acc.: 69.53%] [G loss: 0.594091]\n",
      "epoch:9 step:8617 [D loss: 0.611616, acc.: 67.97%] [G loss: 0.528066]\n",
      "epoch:9 step:8618 [D loss: 0.551321, acc.: 71.88%] [G loss: 0.630763]\n",
      "epoch:9 step:8619 [D loss: 0.577956, acc.: 68.75%] [G loss: 0.507502]\n",
      "epoch:9 step:8620 [D loss: 0.596591, acc.: 63.28%] [G loss: 0.476227]\n",
      "epoch:9 step:8621 [D loss: 0.528342, acc.: 70.31%] [G loss: 0.445503]\n",
      "epoch:9 step:8622 [D loss: 0.562138, acc.: 67.97%] [G loss: 0.459979]\n",
      "epoch:9 step:8623 [D loss: 0.460951, acc.: 80.47%] [G loss: 0.504925]\n",
      "epoch:9 step:8624 [D loss: 0.535254, acc.: 71.88%] [G loss: 0.581728]\n",
      "epoch:9 step:8625 [D loss: 0.538641, acc.: 72.66%] [G loss: 0.567462]\n",
      "epoch:9 step:8626 [D loss: 0.584819, acc.: 66.41%] [G loss: 0.488262]\n",
      "epoch:9 step:8627 [D loss: 0.478807, acc.: 79.69%] [G loss: 0.742432]\n",
      "epoch:9 step:8628 [D loss: 0.549836, acc.: 69.53%] [G loss: 0.620297]\n",
      "epoch:9 step:8629 [D loss: 0.548315, acc.: 70.31%] [G loss: 0.635215]\n",
      "epoch:9 step:8630 [D loss: 0.578793, acc.: 68.75%] [G loss: 0.653582]\n",
      "epoch:9 step:8631 [D loss: 0.467535, acc.: 75.78%] [G loss: 0.570907]\n",
      "epoch:9 step:8632 [D loss: 0.567738, acc.: 68.75%] [G loss: 0.654169]\n",
      "epoch:9 step:8633 [D loss: 0.634575, acc.: 61.72%] [G loss: 0.560269]\n",
      "epoch:9 step:8634 [D loss: 0.539615, acc.: 72.66%] [G loss: 0.565444]\n",
      "epoch:9 step:8635 [D loss: 0.580135, acc.: 64.84%] [G loss: 0.605186]\n",
      "epoch:9 step:8636 [D loss: 0.633435, acc.: 65.62%] [G loss: 0.435071]\n",
      "epoch:9 step:8637 [D loss: 0.580853, acc.: 69.53%] [G loss: 0.522339]\n",
      "epoch:9 step:8638 [D loss: 0.564038, acc.: 67.19%] [G loss: 0.517817]\n",
      "epoch:9 step:8639 [D loss: 0.491077, acc.: 77.34%] [G loss: 0.735839]\n",
      "epoch:9 step:8640 [D loss: 0.445852, acc.: 84.38%] [G loss: 0.663957]\n",
      "epoch:9 step:8641 [D loss: 0.408727, acc.: 81.25%] [G loss: 0.784424]\n",
      "epoch:9 step:8642 [D loss: 0.513834, acc.: 74.22%] [G loss: 0.742507]\n",
      "epoch:9 step:8643 [D loss: 0.640409, acc.: 60.94%] [G loss: 0.422406]\n",
      "epoch:9 step:8644 [D loss: 0.630417, acc.: 62.50%] [G loss: 0.452857]\n",
      "epoch:9 step:8645 [D loss: 0.536223, acc.: 72.66%] [G loss: 0.488588]\n",
      "epoch:9 step:8646 [D loss: 0.474140, acc.: 74.22%] [G loss: 0.594325]\n",
      "epoch:9 step:8647 [D loss: 0.679124, acc.: 58.59%] [G loss: 0.476875]\n",
      "epoch:9 step:8648 [D loss: 0.580996, acc.: 65.62%] [G loss: 0.389163]\n",
      "epoch:9 step:8649 [D loss: 0.513865, acc.: 75.00%] [G loss: 0.503536]\n",
      "epoch:9 step:8650 [D loss: 0.514551, acc.: 72.66%] [G loss: 0.643181]\n",
      "epoch:9 step:8651 [D loss: 0.510234, acc.: 76.56%] [G loss: 0.638665]\n",
      "epoch:9 step:8652 [D loss: 0.496517, acc.: 75.78%] [G loss: 0.685978]\n",
      "epoch:9 step:8653 [D loss: 0.625325, acc.: 69.53%] [G loss: 0.492219]\n",
      "epoch:9 step:8654 [D loss: 0.533860, acc.: 71.09%] [G loss: 0.624269]\n",
      "epoch:9 step:8655 [D loss: 0.471917, acc.: 75.00%] [G loss: 0.737354]\n",
      "epoch:9 step:8656 [D loss: 0.512006, acc.: 75.00%] [G loss: 0.638849]\n",
      "epoch:9 step:8657 [D loss: 0.583012, acc.: 68.75%] [G loss: 0.585144]\n",
      "epoch:9 step:8658 [D loss: 0.591136, acc.: 67.19%] [G loss: 0.613723]\n",
      "epoch:9 step:8659 [D loss: 0.591424, acc.: 67.19%] [G loss: 0.434704]\n",
      "epoch:9 step:8660 [D loss: 0.516727, acc.: 75.78%] [G loss: 0.501567]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8661 [D loss: 0.590508, acc.: 64.84%] [G loss: 0.479452]\n",
      "epoch:9 step:8662 [D loss: 0.550747, acc.: 74.22%] [G loss: 0.486289]\n",
      "epoch:9 step:8663 [D loss: 0.543270, acc.: 70.31%] [G loss: 0.560177]\n",
      "epoch:9 step:8664 [D loss: 0.499937, acc.: 71.09%] [G loss: 0.686999]\n",
      "epoch:9 step:8665 [D loss: 0.514634, acc.: 76.56%] [G loss: 0.730882]\n",
      "epoch:9 step:8666 [D loss: 0.563701, acc.: 71.09%] [G loss: 0.572125]\n",
      "epoch:9 step:8667 [D loss: 0.611880, acc.: 64.84%] [G loss: 0.631598]\n",
      "epoch:9 step:8668 [D loss: 0.642902, acc.: 61.72%] [G loss: 0.444435]\n",
      "epoch:9 step:8669 [D loss: 0.546946, acc.: 72.66%] [G loss: 0.610619]\n",
      "epoch:9 step:8670 [D loss: 0.543588, acc.: 64.06%] [G loss: 0.488904]\n",
      "epoch:9 step:8671 [D loss: 0.566401, acc.: 71.09%] [G loss: 0.569437]\n",
      "epoch:9 step:8672 [D loss: 0.518459, acc.: 74.22%] [G loss: 0.570735]\n",
      "epoch:9 step:8673 [D loss: 0.551039, acc.: 73.44%] [G loss: 0.663369]\n",
      "epoch:9 step:8674 [D loss: 0.519181, acc.: 76.56%] [G loss: 0.610422]\n",
      "epoch:9 step:8675 [D loss: 0.511891, acc.: 76.56%] [G loss: 0.606946]\n",
      "epoch:9 step:8676 [D loss: 0.606527, acc.: 64.84%] [G loss: 0.573245]\n",
      "epoch:9 step:8677 [D loss: 0.488654, acc.: 76.56%] [G loss: 0.607977]\n",
      "epoch:9 step:8678 [D loss: 0.515586, acc.: 75.00%] [G loss: 0.567414]\n",
      "epoch:9 step:8679 [D loss: 0.496992, acc.: 75.78%] [G loss: 0.560663]\n",
      "epoch:9 step:8680 [D loss: 0.568114, acc.: 66.41%] [G loss: 0.611443]\n",
      "epoch:9 step:8681 [D loss: 0.570385, acc.: 64.84%] [G loss: 0.623135]\n",
      "epoch:9 step:8682 [D loss: 0.595025, acc.: 67.97%] [G loss: 0.576431]\n",
      "epoch:9 step:8683 [D loss: 0.614753, acc.: 65.62%] [G loss: 0.551359]\n",
      "epoch:9 step:8684 [D loss: 0.643133, acc.: 62.50%] [G loss: 0.514033]\n",
      "epoch:9 step:8685 [D loss: 0.561277, acc.: 73.44%] [G loss: 0.445987]\n",
      "epoch:9 step:8686 [D loss: 0.565871, acc.: 68.75%] [G loss: 0.500536]\n",
      "epoch:9 step:8687 [D loss: 0.531315, acc.: 71.88%] [G loss: 0.546630]\n",
      "epoch:9 step:8688 [D loss: 0.487881, acc.: 75.78%] [G loss: 0.682323]\n",
      "epoch:9 step:8689 [D loss: 0.547171, acc.: 71.88%] [G loss: 0.522890]\n",
      "epoch:9 step:8690 [D loss: 0.563673, acc.: 71.09%] [G loss: 0.491257]\n",
      "epoch:9 step:8691 [D loss: 0.513921, acc.: 73.44%] [G loss: 0.525403]\n",
      "epoch:9 step:8692 [D loss: 0.578305, acc.: 63.28%] [G loss: 0.490632]\n",
      "epoch:9 step:8693 [D loss: 0.612919, acc.: 60.94%] [G loss: 0.544489]\n",
      "epoch:9 step:8694 [D loss: 0.518275, acc.: 73.44%] [G loss: 0.581050]\n",
      "epoch:9 step:8695 [D loss: 0.507414, acc.: 77.34%] [G loss: 0.624362]\n",
      "epoch:9 step:8696 [D loss: 0.618945, acc.: 64.84%] [G loss: 0.401987]\n",
      "epoch:9 step:8697 [D loss: 0.563856, acc.: 70.31%] [G loss: 0.498406]\n",
      "epoch:9 step:8698 [D loss: 0.590935, acc.: 66.41%] [G loss: 0.418232]\n",
      "epoch:9 step:8699 [D loss: 0.582496, acc.: 73.44%] [G loss: 0.705011]\n",
      "epoch:9 step:8700 [D loss: 0.565976, acc.: 67.97%] [G loss: 0.573956]\n",
      "epoch:9 step:8701 [D loss: 0.549803, acc.: 72.66%] [G loss: 0.539984]\n",
      "epoch:9 step:8702 [D loss: 0.598379, acc.: 60.94%] [G loss: 0.576131]\n",
      "epoch:9 step:8703 [D loss: 0.499880, acc.: 77.34%] [G loss: 0.648857]\n",
      "epoch:9 step:8704 [D loss: 0.645596, acc.: 62.50%] [G loss: 0.527566]\n",
      "epoch:9 step:8705 [D loss: 0.489908, acc.: 74.22%] [G loss: 0.680718]\n",
      "epoch:9 step:8706 [D loss: 0.534369, acc.: 71.88%] [G loss: 0.575216]\n",
      "epoch:9 step:8707 [D loss: 0.522994, acc.: 74.22%] [G loss: 0.626993]\n",
      "epoch:9 step:8708 [D loss: 0.591719, acc.: 67.97%] [G loss: 0.523764]\n",
      "epoch:9 step:8709 [D loss: 0.506720, acc.: 71.88%] [G loss: 0.548927]\n",
      "epoch:9 step:8710 [D loss: 0.630484, acc.: 64.84%] [G loss: 0.481333]\n",
      "epoch:9 step:8711 [D loss: 0.599115, acc.: 65.62%] [G loss: 0.457196]\n",
      "epoch:9 step:8712 [D loss: 0.542418, acc.: 71.09%] [G loss: 0.468692]\n",
      "epoch:9 step:8713 [D loss: 0.531795, acc.: 67.97%] [G loss: 0.601571]\n",
      "epoch:9 step:8714 [D loss: 0.602027, acc.: 68.75%] [G loss: 0.535025]\n",
      "epoch:9 step:8715 [D loss: 0.573321, acc.: 66.41%] [G loss: 0.487070]\n",
      "epoch:9 step:8716 [D loss: 0.541506, acc.: 70.31%] [G loss: 0.643044]\n",
      "epoch:9 step:8717 [D loss: 0.529294, acc.: 69.53%] [G loss: 0.593677]\n",
      "epoch:9 step:8718 [D loss: 0.466852, acc.: 76.56%] [G loss: 0.650676]\n",
      "epoch:9 step:8719 [D loss: 0.462508, acc.: 78.91%] [G loss: 0.560456]\n",
      "epoch:9 step:8720 [D loss: 0.557611, acc.: 70.31%] [G loss: 0.552495]\n",
      "epoch:9 step:8721 [D loss: 0.545400, acc.: 71.09%] [G loss: 0.668127]\n",
      "epoch:9 step:8722 [D loss: 0.571425, acc.: 67.97%] [G loss: 0.593111]\n",
      "epoch:9 step:8723 [D loss: 0.560960, acc.: 67.97%] [G loss: 0.538634]\n",
      "epoch:9 step:8724 [D loss: 0.591659, acc.: 65.62%] [G loss: 0.485375]\n",
      "epoch:9 step:8725 [D loss: 0.550159, acc.: 68.75%] [G loss: 0.530396]\n",
      "epoch:9 step:8726 [D loss: 0.552122, acc.: 67.19%] [G loss: 0.461139]\n",
      "epoch:9 step:8727 [D loss: 0.536015, acc.: 75.78%] [G loss: 0.538731]\n",
      "epoch:9 step:8728 [D loss: 0.569070, acc.: 64.84%] [G loss: 0.549570]\n",
      "epoch:9 step:8729 [D loss: 0.487977, acc.: 78.12%] [G loss: 0.473539]\n",
      "epoch:9 step:8730 [D loss: 0.546878, acc.: 73.44%] [G loss: 0.434001]\n",
      "epoch:9 step:8731 [D loss: 0.505744, acc.: 75.78%] [G loss: 0.570054]\n",
      "epoch:9 step:8732 [D loss: 0.498481, acc.: 78.12%] [G loss: 0.561245]\n",
      "epoch:9 step:8733 [D loss: 0.535919, acc.: 74.22%] [G loss: 0.657172]\n",
      "epoch:9 step:8734 [D loss: 0.648858, acc.: 67.19%] [G loss: 0.532837]\n",
      "epoch:9 step:8735 [D loss: 0.550548, acc.: 68.75%] [G loss: 0.585068]\n",
      "epoch:9 step:8736 [D loss: 0.516662, acc.: 76.56%] [G loss: 0.615710]\n",
      "epoch:9 step:8737 [D loss: 0.447925, acc.: 78.91%] [G loss: 0.708885]\n",
      "epoch:9 step:8738 [D loss: 0.518197, acc.: 74.22%] [G loss: 0.636891]\n",
      "epoch:9 step:8739 [D loss: 0.554691, acc.: 67.97%] [G loss: 0.581123]\n",
      "epoch:9 step:8740 [D loss: 0.490952, acc.: 74.22%] [G loss: 0.761436]\n",
      "epoch:9 step:8741 [D loss: 0.557365, acc.: 70.31%] [G loss: 0.507065]\n",
      "epoch:9 step:8742 [D loss: 0.550293, acc.: 64.84%] [G loss: 0.507374]\n",
      "epoch:9 step:8743 [D loss: 0.485252, acc.: 76.56%] [G loss: 0.720011]\n",
      "epoch:9 step:8744 [D loss: 0.530479, acc.: 68.75%] [G loss: 0.558210]\n",
      "epoch:9 step:8745 [D loss: 0.469380, acc.: 76.56%] [G loss: 0.755191]\n",
      "epoch:9 step:8746 [D loss: 0.459349, acc.: 78.12%] [G loss: 0.856556]\n",
      "epoch:9 step:8747 [D loss: 0.443475, acc.: 80.47%] [G loss: 0.854051]\n",
      "epoch:9 step:8748 [D loss: 0.428316, acc.: 82.81%] [G loss: 0.992943]\n",
      "epoch:9 step:8749 [D loss: 0.687997, acc.: 61.72%] [G loss: 0.558234]\n",
      "epoch:9 step:8750 [D loss: 0.586650, acc.: 66.41%] [G loss: 0.502332]\n",
      "epoch:9 step:8751 [D loss: 0.537677, acc.: 71.09%] [G loss: 0.466440]\n",
      "epoch:9 step:8752 [D loss: 0.567652, acc.: 63.28%] [G loss: 0.459563]\n",
      "epoch:9 step:8753 [D loss: 0.539749, acc.: 71.09%] [G loss: 0.629266]\n",
      "epoch:9 step:8754 [D loss: 0.493721, acc.: 73.44%] [G loss: 0.636003]\n",
      "epoch:9 step:8755 [D loss: 0.594915, acc.: 67.19%] [G loss: 0.544073]\n",
      "epoch:9 step:8756 [D loss: 0.618677, acc.: 63.28%] [G loss: 0.597998]\n",
      "epoch:9 step:8757 [D loss: 0.560631, acc.: 70.31%] [G loss: 0.441937]\n",
      "epoch:9 step:8758 [D loss: 0.529284, acc.: 69.53%] [G loss: 0.638063]\n",
      "epoch:9 step:8759 [D loss: 0.537386, acc.: 72.66%] [G loss: 0.507389]\n",
      "epoch:9 step:8760 [D loss: 0.547970, acc.: 75.00%] [G loss: 0.637548]\n",
      "epoch:9 step:8761 [D loss: 0.518179, acc.: 78.91%] [G loss: 0.654812]\n",
      "epoch:9 step:8762 [D loss: 0.516337, acc.: 75.78%] [G loss: 0.737698]\n",
      "epoch:9 step:8763 [D loss: 0.601588, acc.: 63.28%] [G loss: 0.650304]\n",
      "epoch:9 step:8764 [D loss: 0.527118, acc.: 72.66%] [G loss: 0.578643]\n",
      "epoch:9 step:8765 [D loss: 0.494073, acc.: 75.00%] [G loss: 0.627847]\n",
      "epoch:9 step:8766 [D loss: 0.486679, acc.: 79.69%] [G loss: 0.535814]\n",
      "epoch:9 step:8767 [D loss: 0.488126, acc.: 74.22%] [G loss: 0.684653]\n",
      "epoch:9 step:8768 [D loss: 0.527597, acc.: 71.09%] [G loss: 0.623074]\n",
      "epoch:9 step:8769 [D loss: 0.486049, acc.: 77.34%] [G loss: 0.686453]\n",
      "epoch:9 step:8770 [D loss: 0.492337, acc.: 76.56%] [G loss: 0.600074]\n",
      "epoch:9 step:8771 [D loss: 0.551325, acc.: 68.75%] [G loss: 0.615958]\n",
      "epoch:9 step:8772 [D loss: 0.563803, acc.: 69.53%] [G loss: 0.555471]\n",
      "epoch:9 step:8773 [D loss: 0.548577, acc.: 72.66%] [G loss: 0.677906]\n",
      "epoch:9 step:8774 [D loss: 0.576692, acc.: 71.88%] [G loss: 0.615029]\n",
      "epoch:9 step:8775 [D loss: 0.683237, acc.: 58.59%] [G loss: 0.531795]\n",
      "epoch:9 step:8776 [D loss: 0.511569, acc.: 72.66%] [G loss: 0.618967]\n",
      "epoch:9 step:8777 [D loss: 0.491809, acc.: 76.56%] [G loss: 0.697007]\n",
      "epoch:9 step:8778 [D loss: 0.589970, acc.: 72.66%] [G loss: 0.900894]\n",
      "epoch:9 step:8779 [D loss: 0.548029, acc.: 67.19%] [G loss: 0.720644]\n",
      "epoch:9 step:8780 [D loss: 0.488713, acc.: 75.78%] [G loss: 0.910045]\n",
      "epoch:9 step:8781 [D loss: 0.763439, acc.: 54.69%] [G loss: 0.627564]\n",
      "epoch:9 step:8782 [D loss: 0.734412, acc.: 51.56%] [G loss: 0.604124]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8783 [D loss: 0.524662, acc.: 74.22%] [G loss: 0.562513]\n",
      "epoch:9 step:8784 [D loss: 0.531170, acc.: 74.22%] [G loss: 0.582708]\n",
      "epoch:9 step:8785 [D loss: 0.591354, acc.: 67.97%] [G loss: 0.598867]\n",
      "epoch:9 step:8786 [D loss: 0.558547, acc.: 66.41%] [G loss: 0.491829]\n",
      "epoch:9 step:8787 [D loss: 0.454819, acc.: 79.69%] [G loss: 0.605711]\n",
      "epoch:9 step:8788 [D loss: 0.560022, acc.: 67.19%] [G loss: 0.733478]\n",
      "epoch:9 step:8789 [D loss: 0.544560, acc.: 67.19%] [G loss: 0.628212]\n",
      "epoch:9 step:8790 [D loss: 0.465609, acc.: 78.91%] [G loss: 0.677420]\n",
      "epoch:9 step:8791 [D loss: 0.476819, acc.: 78.12%] [G loss: 0.623938]\n",
      "epoch:9 step:8792 [D loss: 0.477187, acc.: 80.47%] [G loss: 0.751536]\n",
      "epoch:9 step:8793 [D loss: 0.501241, acc.: 74.22%] [G loss: 0.804441]\n",
      "epoch:9 step:8794 [D loss: 0.569339, acc.: 70.31%] [G loss: 0.565117]\n",
      "epoch:9 step:8795 [D loss: 0.558108, acc.: 67.19%] [G loss: 0.630281]\n",
      "epoch:9 step:8796 [D loss: 0.555996, acc.: 71.09%] [G loss: 0.673252]\n",
      "epoch:9 step:8797 [D loss: 0.550112, acc.: 71.88%] [G loss: 0.611543]\n",
      "epoch:9 step:8798 [D loss: 0.509326, acc.: 75.00%] [G loss: 0.577814]\n",
      "epoch:9 step:8799 [D loss: 0.509997, acc.: 74.22%] [G loss: 0.575218]\n",
      "epoch:9 step:8800 [D loss: 0.568066, acc.: 75.00%] [G loss: 0.525411]\n",
      "##############\n",
      "[2.95568129 1.5030212  6.39015937 5.18465109 3.96805071 5.85747897\n",
      " 4.78345995 4.77934077 4.59146324 3.51899798]\n",
      "##########\n",
      "epoch:9 step:8801 [D loss: 0.565613, acc.: 75.78%] [G loss: 0.556853]\n",
      "epoch:9 step:8802 [D loss: 0.575194, acc.: 71.88%] [G loss: 0.576500]\n",
      "epoch:9 step:8803 [D loss: 0.537886, acc.: 75.78%] [G loss: 0.595248]\n",
      "epoch:9 step:8804 [D loss: 0.499447, acc.: 78.12%] [G loss: 0.581311]\n",
      "epoch:9 step:8805 [D loss: 0.545773, acc.: 68.75%] [G loss: 0.569893]\n",
      "epoch:9 step:8806 [D loss: 0.592836, acc.: 63.28%] [G loss: 0.696468]\n",
      "epoch:9 step:8807 [D loss: 0.510457, acc.: 67.97%] [G loss: 0.709432]\n",
      "epoch:9 step:8808 [D loss: 0.557675, acc.: 69.53%] [G loss: 0.683806]\n",
      "epoch:9 step:8809 [D loss: 0.706550, acc.: 56.25%] [G loss: 0.376631]\n",
      "epoch:9 step:8810 [D loss: 0.614430, acc.: 64.84%] [G loss: 0.564430]\n",
      "epoch:9 step:8811 [D loss: 0.529757, acc.: 68.75%] [G loss: 0.574959]\n",
      "epoch:9 step:8812 [D loss: 0.557976, acc.: 73.44%] [G loss: 0.507195]\n",
      "epoch:9 step:8813 [D loss: 0.570428, acc.: 71.88%] [G loss: 0.441920]\n",
      "epoch:9 step:8814 [D loss: 0.478779, acc.: 75.78%] [G loss: 0.565523]\n",
      "epoch:9 step:8815 [D loss: 0.562081, acc.: 71.88%] [G loss: 0.513894]\n",
      "epoch:9 step:8816 [D loss: 0.544446, acc.: 71.09%] [G loss: 0.651571]\n",
      "epoch:9 step:8817 [D loss: 0.569179, acc.: 71.88%] [G loss: 0.522668]\n",
      "epoch:9 step:8818 [D loss: 0.564754, acc.: 71.88%] [G loss: 0.621065]\n",
      "epoch:9 step:8819 [D loss: 0.672778, acc.: 60.94%] [G loss: 0.496498]\n",
      "epoch:9 step:8820 [D loss: 0.606760, acc.: 62.50%] [G loss: 0.494251]\n",
      "epoch:9 step:8821 [D loss: 0.559672, acc.: 69.53%] [G loss: 0.629328]\n",
      "epoch:9 step:8822 [D loss: 0.503763, acc.: 76.56%] [G loss: 0.551741]\n",
      "epoch:9 step:8823 [D loss: 0.619437, acc.: 60.94%] [G loss: 0.455983]\n",
      "epoch:9 step:8824 [D loss: 0.594354, acc.: 64.06%] [G loss: 0.546432]\n",
      "epoch:9 step:8825 [D loss: 0.497983, acc.: 75.78%] [G loss: 0.513476]\n",
      "epoch:9 step:8826 [D loss: 0.568311, acc.: 68.75%] [G loss: 0.487981]\n",
      "epoch:9 step:8827 [D loss: 0.608249, acc.: 63.28%] [G loss: 0.393405]\n",
      "epoch:9 step:8828 [D loss: 0.487226, acc.: 80.47%] [G loss: 0.494499]\n",
      "epoch:9 step:8829 [D loss: 0.603691, acc.: 67.19%] [G loss: 0.542924]\n",
      "epoch:9 step:8830 [D loss: 0.536281, acc.: 72.66%] [G loss: 0.615279]\n",
      "epoch:9 step:8831 [D loss: 0.483120, acc.: 73.44%] [G loss: 0.783008]\n",
      "epoch:9 step:8832 [D loss: 0.488545, acc.: 79.69%] [G loss: 0.684669]\n",
      "epoch:9 step:8833 [D loss: 0.675273, acc.: 55.47%] [G loss: 0.422615]\n",
      "epoch:9 step:8834 [D loss: 0.600600, acc.: 67.19%] [G loss: 0.447339]\n",
      "epoch:9 step:8835 [D loss: 0.492970, acc.: 75.78%] [G loss: 0.604877]\n",
      "epoch:9 step:8836 [D loss: 0.504049, acc.: 71.09%] [G loss: 0.643754]\n",
      "epoch:9 step:8837 [D loss: 0.560553, acc.: 69.53%] [G loss: 0.533360]\n",
      "epoch:9 step:8838 [D loss: 0.520898, acc.: 78.12%] [G loss: 0.546326]\n",
      "epoch:9 step:8839 [D loss: 0.546407, acc.: 73.44%] [G loss: 0.661224]\n",
      "epoch:9 step:8840 [D loss: 0.572132, acc.: 67.97%] [G loss: 0.722538]\n",
      "epoch:9 step:8841 [D loss: 0.609997, acc.: 63.28%] [G loss: 0.657117]\n",
      "epoch:9 step:8842 [D loss: 0.551310, acc.: 65.62%] [G loss: 0.442245]\n",
      "epoch:9 step:8843 [D loss: 0.597807, acc.: 64.84%] [G loss: 0.371619]\n",
      "epoch:9 step:8844 [D loss: 0.580648, acc.: 60.94%] [G loss: 0.540870]\n",
      "epoch:9 step:8845 [D loss: 0.611073, acc.: 59.38%] [G loss: 0.546562]\n",
      "epoch:9 step:8846 [D loss: 0.539983, acc.: 74.22%] [G loss: 0.532999]\n",
      "epoch:9 step:8847 [D loss: 0.580965, acc.: 71.09%] [G loss: 0.714765]\n",
      "epoch:9 step:8848 [D loss: 0.512442, acc.: 75.78%] [G loss: 0.647377]\n",
      "epoch:9 step:8849 [D loss: 0.471099, acc.: 82.03%] [G loss: 0.639444]\n",
      "epoch:9 step:8850 [D loss: 0.555833, acc.: 70.31%] [G loss: 0.598185]\n",
      "epoch:9 step:8851 [D loss: 0.630532, acc.: 67.19%] [G loss: 0.549183]\n",
      "epoch:9 step:8852 [D loss: 0.542745, acc.: 73.44%] [G loss: 0.468601]\n",
      "epoch:9 step:8853 [D loss: 0.545545, acc.: 70.31%] [G loss: 0.625450]\n",
      "epoch:9 step:8854 [D loss: 0.568033, acc.: 71.88%] [G loss: 0.596982]\n",
      "epoch:9 step:8855 [D loss: 0.578426, acc.: 68.75%] [G loss: 0.483488]\n",
      "epoch:9 step:8856 [D loss: 0.571204, acc.: 67.97%] [G loss: 0.418871]\n",
      "epoch:9 step:8857 [D loss: 0.563321, acc.: 65.62%] [G loss: 0.455065]\n",
      "epoch:9 step:8858 [D loss: 0.558655, acc.: 72.66%] [G loss: 0.643115]\n",
      "epoch:9 step:8859 [D loss: 0.509034, acc.: 74.22%] [G loss: 0.691237]\n",
      "epoch:9 step:8860 [D loss: 0.541549, acc.: 68.75%] [G loss: 0.672239]\n",
      "epoch:9 step:8861 [D loss: 0.531777, acc.: 75.78%] [G loss: 0.606269]\n",
      "epoch:9 step:8862 [D loss: 0.516408, acc.: 72.66%] [G loss: 0.780151]\n",
      "epoch:9 step:8863 [D loss: 0.512075, acc.: 74.22%] [G loss: 0.584536]\n",
      "epoch:9 step:8864 [D loss: 0.480727, acc.: 75.00%] [G loss: 0.676171]\n",
      "epoch:9 step:8865 [D loss: 0.597330, acc.: 67.19%] [G loss: 0.503842]\n",
      "epoch:9 step:8866 [D loss: 0.548558, acc.: 71.09%] [G loss: 0.545384]\n",
      "epoch:9 step:8867 [D loss: 0.499823, acc.: 78.12%] [G loss: 0.530058]\n",
      "epoch:9 step:8868 [D loss: 0.526432, acc.: 74.22%] [G loss: 0.541670]\n",
      "epoch:9 step:8869 [D loss: 0.523143, acc.: 71.09%] [G loss: 0.651087]\n",
      "epoch:9 step:8870 [D loss: 0.688250, acc.: 60.16%] [G loss: 0.623437]\n",
      "epoch:9 step:8871 [D loss: 0.612524, acc.: 60.94%] [G loss: 0.564865]\n",
      "epoch:9 step:8872 [D loss: 0.513614, acc.: 77.34%] [G loss: 0.531683]\n",
      "epoch:9 step:8873 [D loss: 0.513818, acc.: 72.66%] [G loss: 0.552623]\n",
      "epoch:9 step:8874 [D loss: 0.621108, acc.: 59.38%] [G loss: 0.507562]\n",
      "epoch:9 step:8875 [D loss: 0.601994, acc.: 67.97%] [G loss: 0.598063]\n",
      "epoch:9 step:8876 [D loss: 0.494225, acc.: 76.56%] [G loss: 0.615385]\n",
      "epoch:9 step:8877 [D loss: 0.599363, acc.: 67.19%] [G loss: 0.627451]\n",
      "epoch:9 step:8878 [D loss: 0.564451, acc.: 66.41%] [G loss: 0.594998]\n",
      "epoch:9 step:8879 [D loss: 0.553185, acc.: 69.53%] [G loss: 0.704211]\n",
      "epoch:9 step:8880 [D loss: 0.533452, acc.: 71.88%] [G loss: 0.884323]\n",
      "epoch:9 step:8881 [D loss: 0.591409, acc.: 67.97%] [G loss: 0.560014]\n",
      "epoch:9 step:8882 [D loss: 0.494757, acc.: 75.00%] [G loss: 0.596183]\n",
      "epoch:9 step:8883 [D loss: 0.472062, acc.: 77.34%] [G loss: 0.612788]\n",
      "epoch:9 step:8884 [D loss: 0.427745, acc.: 80.47%] [G loss: 0.900411]\n",
      "epoch:9 step:8885 [D loss: 0.468822, acc.: 76.56%] [G loss: 0.864053]\n",
      "epoch:9 step:8886 [D loss: 0.516699, acc.: 73.44%] [G loss: 0.683422]\n",
      "epoch:9 step:8887 [D loss: 0.523739, acc.: 74.22%] [G loss: 0.625675]\n",
      "epoch:9 step:8888 [D loss: 0.555628, acc.: 72.66%] [G loss: 0.550102]\n",
      "epoch:9 step:8889 [D loss: 0.662768, acc.: 57.81%] [G loss: 0.499325]\n",
      "epoch:9 step:8890 [D loss: 0.500906, acc.: 75.78%] [G loss: 0.805625]\n",
      "epoch:9 step:8891 [D loss: 0.624710, acc.: 58.59%] [G loss: 0.592423]\n",
      "epoch:9 step:8892 [D loss: 0.558605, acc.: 69.53%] [G loss: 0.595424]\n",
      "epoch:9 step:8893 [D loss: 0.506625, acc.: 74.22%] [G loss: 0.669002]\n",
      "epoch:9 step:8894 [D loss: 0.482632, acc.: 77.34%] [G loss: 0.620008]\n",
      "epoch:9 step:8895 [D loss: 0.545691, acc.: 71.09%] [G loss: 0.665483]\n",
      "epoch:9 step:8896 [D loss: 0.554370, acc.: 68.75%] [G loss: 0.478414]\n",
      "epoch:9 step:8897 [D loss: 0.542781, acc.: 69.53%] [G loss: 0.467653]\n",
      "epoch:9 step:8898 [D loss: 0.603082, acc.: 67.19%] [G loss: 0.438765]\n",
      "epoch:9 step:8899 [D loss: 0.569035, acc.: 66.41%] [G loss: 0.586388]\n",
      "epoch:9 step:8900 [D loss: 0.542019, acc.: 67.97%] [G loss: 0.548246]\n",
      "epoch:9 step:8901 [D loss: 0.625145, acc.: 64.84%] [G loss: 0.656312]\n",
      "epoch:9 step:8902 [D loss: 0.556775, acc.: 73.44%] [G loss: 0.724850]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8903 [D loss: 0.522707, acc.: 74.22%] [G loss: 0.712573]\n",
      "epoch:9 step:8904 [D loss: 0.442548, acc.: 84.38%] [G loss: 0.757539]\n",
      "epoch:9 step:8905 [D loss: 0.482064, acc.: 78.12%] [G loss: 0.760038]\n",
      "epoch:9 step:8906 [D loss: 0.615649, acc.: 66.41%] [G loss: 0.588201]\n",
      "epoch:9 step:8907 [D loss: 0.570874, acc.: 68.75%] [G loss: 0.509676]\n",
      "epoch:9 step:8908 [D loss: 0.461555, acc.: 78.91%] [G loss: 0.675366]\n",
      "epoch:9 step:8909 [D loss: 0.556364, acc.: 72.66%] [G loss: 0.678724]\n",
      "epoch:9 step:8910 [D loss: 0.685747, acc.: 56.25%] [G loss: 0.543683]\n",
      "epoch:9 step:8911 [D loss: 0.575071, acc.: 69.53%] [G loss: 0.587554]\n",
      "epoch:9 step:8912 [D loss: 0.573768, acc.: 68.75%] [G loss: 0.445461]\n",
      "epoch:9 step:8913 [D loss: 0.536132, acc.: 77.34%] [G loss: 0.513193]\n",
      "epoch:9 step:8914 [D loss: 0.507040, acc.: 75.78%] [G loss: 0.603269]\n",
      "epoch:9 step:8915 [D loss: 0.584635, acc.: 64.84%] [G loss: 0.581587]\n",
      "epoch:9 step:8916 [D loss: 0.582596, acc.: 66.41%] [G loss: 0.584633]\n",
      "epoch:9 step:8917 [D loss: 0.488304, acc.: 77.34%] [G loss: 0.797498]\n",
      "epoch:9 step:8918 [D loss: 0.547441, acc.: 68.75%] [G loss: 0.671387]\n",
      "epoch:9 step:8919 [D loss: 0.543649, acc.: 74.22%] [G loss: 0.687814]\n",
      "epoch:9 step:8920 [D loss: 0.514465, acc.: 71.88%] [G loss: 0.583131]\n",
      "epoch:9 step:8921 [D loss: 0.541571, acc.: 68.75%] [G loss: 0.519807]\n",
      "epoch:9 step:8922 [D loss: 0.506874, acc.: 71.88%] [G loss: 0.617008]\n",
      "epoch:9 step:8923 [D loss: 0.570294, acc.: 67.19%] [G loss: 0.510190]\n",
      "epoch:9 step:8924 [D loss: 0.553687, acc.: 70.31%] [G loss: 0.548929]\n",
      "epoch:9 step:8925 [D loss: 0.589599, acc.: 63.28%] [G loss: 0.504033]\n",
      "epoch:9 step:8926 [D loss: 0.546108, acc.: 71.09%] [G loss: 0.522874]\n",
      "epoch:9 step:8927 [D loss: 0.643384, acc.: 62.50%] [G loss: 0.468066]\n",
      "epoch:9 step:8928 [D loss: 0.533448, acc.: 71.88%] [G loss: 0.512250]\n",
      "epoch:9 step:8929 [D loss: 0.600450, acc.: 68.75%] [G loss: 0.486366]\n",
      "epoch:9 step:8930 [D loss: 0.588418, acc.: 68.75%] [G loss: 0.579399]\n",
      "epoch:9 step:8931 [D loss: 0.492949, acc.: 75.78%] [G loss: 0.748142]\n",
      "epoch:9 step:8932 [D loss: 0.516277, acc.: 74.22%] [G loss: 0.740075]\n",
      "epoch:9 step:8933 [D loss: 0.576002, acc.: 68.75%] [G loss: 0.703708]\n",
      "epoch:9 step:8934 [D loss: 0.633121, acc.: 67.97%] [G loss: 0.482006]\n",
      "epoch:9 step:8935 [D loss: 0.676854, acc.: 54.69%] [G loss: 0.482402]\n",
      "epoch:9 step:8936 [D loss: 0.506631, acc.: 73.44%] [G loss: 0.621695]\n",
      "epoch:9 step:8937 [D loss: 0.493270, acc.: 75.78%] [G loss: 0.722882]\n",
      "epoch:9 step:8938 [D loss: 0.527948, acc.: 75.00%] [G loss: 0.741499]\n",
      "epoch:9 step:8939 [D loss: 0.546198, acc.: 72.66%] [G loss: 0.681804]\n",
      "epoch:9 step:8940 [D loss: 0.504319, acc.: 76.56%] [G loss: 0.678663]\n",
      "epoch:9 step:8941 [D loss: 0.394644, acc.: 84.38%] [G loss: 0.828091]\n",
      "epoch:9 step:8942 [D loss: 0.490884, acc.: 74.22%] [G loss: 0.742154]\n",
      "epoch:9 step:8943 [D loss: 0.558076, acc.: 68.75%] [G loss: 0.730812]\n",
      "epoch:9 step:8944 [D loss: 0.752627, acc.: 52.34%] [G loss: 0.479158]\n",
      "epoch:9 step:8945 [D loss: 0.590497, acc.: 67.19%] [G loss: 0.429929]\n",
      "epoch:9 step:8946 [D loss: 0.540721, acc.: 69.53%] [G loss: 0.649392]\n",
      "epoch:9 step:8947 [D loss: 0.499203, acc.: 71.88%] [G loss: 0.632843]\n",
      "epoch:9 step:8948 [D loss: 0.519243, acc.: 76.56%] [G loss: 0.590274]\n",
      "epoch:9 step:8949 [D loss: 0.465479, acc.: 76.56%] [G loss: 0.730204]\n",
      "epoch:9 step:8950 [D loss: 0.579145, acc.: 72.66%] [G loss: 0.624514]\n",
      "epoch:9 step:8951 [D loss: 0.549734, acc.: 72.66%] [G loss: 0.587424]\n",
      "epoch:9 step:8952 [D loss: 0.483470, acc.: 74.22%] [G loss: 0.708991]\n",
      "epoch:9 step:8953 [D loss: 0.497132, acc.: 77.34%] [G loss: 0.520786]\n",
      "epoch:9 step:8954 [D loss: 0.539487, acc.: 73.44%] [G loss: 0.547847]\n",
      "epoch:9 step:8955 [D loss: 0.522068, acc.: 72.66%] [G loss: 0.593140]\n",
      "epoch:9 step:8956 [D loss: 0.487185, acc.: 78.91%] [G loss: 0.699169]\n",
      "epoch:9 step:8957 [D loss: 0.537361, acc.: 71.88%] [G loss: 0.615559]\n",
      "epoch:9 step:8958 [D loss: 0.615335, acc.: 65.62%] [G loss: 0.554296]\n",
      "epoch:9 step:8959 [D loss: 0.498143, acc.: 78.91%] [G loss: 0.548095]\n",
      "epoch:9 step:8960 [D loss: 0.592162, acc.: 61.72%] [G loss: 0.675372]\n",
      "epoch:9 step:8961 [D loss: 0.664731, acc.: 60.16%] [G loss: 0.499023]\n",
      "epoch:9 step:8962 [D loss: 0.582420, acc.: 69.53%] [G loss: 0.518766]\n",
      "epoch:9 step:8963 [D loss: 0.608345, acc.: 58.59%] [G loss: 0.581853]\n",
      "epoch:9 step:8964 [D loss: 0.620855, acc.: 66.41%] [G loss: 0.607577]\n",
      "epoch:9 step:8965 [D loss: 0.577115, acc.: 67.19%] [G loss: 0.595371]\n",
      "epoch:9 step:8966 [D loss: 0.525947, acc.: 74.22%] [G loss: 0.564109]\n",
      "epoch:9 step:8967 [D loss: 0.492085, acc.: 74.22%] [G loss: 0.602507]\n",
      "epoch:9 step:8968 [D loss: 0.607517, acc.: 68.75%] [G loss: 0.449718]\n",
      "epoch:9 step:8969 [D loss: 0.497359, acc.: 75.00%] [G loss: 0.433236]\n",
      "epoch:9 step:8970 [D loss: 0.629641, acc.: 64.84%] [G loss: 0.528264]\n",
      "epoch:9 step:8971 [D loss: 0.568086, acc.: 68.75%] [G loss: 0.517021]\n",
      "epoch:9 step:8972 [D loss: 0.577345, acc.: 73.44%] [G loss: 0.608057]\n",
      "epoch:9 step:8973 [D loss: 0.562655, acc.: 64.84%] [G loss: 0.547534]\n",
      "epoch:9 step:8974 [D loss: 0.520020, acc.: 71.09%] [G loss: 0.497029]\n",
      "epoch:9 step:8975 [D loss: 0.624200, acc.: 66.41%] [G loss: 0.402948]\n",
      "epoch:9 step:8976 [D loss: 0.566970, acc.: 67.97%] [G loss: 0.494824]\n",
      "epoch:9 step:8977 [D loss: 0.578646, acc.: 67.97%] [G loss: 0.642031]\n",
      "epoch:9 step:8978 [D loss: 0.592797, acc.: 64.06%] [G loss: 0.467666]\n",
      "epoch:9 step:8979 [D loss: 0.517349, acc.: 77.34%] [G loss: 0.668724]\n",
      "epoch:9 step:8980 [D loss: 0.532724, acc.: 74.22%] [G loss: 0.548100]\n",
      "epoch:9 step:8981 [D loss: 0.502630, acc.: 72.66%] [G loss: 0.633333]\n",
      "epoch:9 step:8982 [D loss: 0.553388, acc.: 70.31%] [G loss: 0.436780]\n",
      "epoch:9 step:8983 [D loss: 0.547021, acc.: 69.53%] [G loss: 0.633593]\n",
      "epoch:9 step:8984 [D loss: 0.503692, acc.: 78.12%] [G loss: 0.619180]\n",
      "epoch:9 step:8985 [D loss: 0.501997, acc.: 75.00%] [G loss: 0.639193]\n",
      "epoch:9 step:8986 [D loss: 0.538990, acc.: 69.53%] [G loss: 0.551270]\n",
      "epoch:9 step:8987 [D loss: 0.503265, acc.: 72.66%] [G loss: 0.603426]\n",
      "epoch:9 step:8988 [D loss: 0.504709, acc.: 74.22%] [G loss: 0.591950]\n",
      "epoch:9 step:8989 [D loss: 0.561347, acc.: 67.19%] [G loss: 0.621715]\n",
      "epoch:9 step:8990 [D loss: 0.516293, acc.: 73.44%] [G loss: 0.539623]\n",
      "epoch:9 step:8991 [D loss: 0.501353, acc.: 79.69%] [G loss: 0.612109]\n",
      "epoch:9 step:8992 [D loss: 0.613201, acc.: 64.84%] [G loss: 0.607381]\n",
      "epoch:9 step:8993 [D loss: 0.559139, acc.: 71.09%] [G loss: 0.520387]\n",
      "epoch:9 step:8994 [D loss: 0.558500, acc.: 74.22%] [G loss: 0.479847]\n",
      "epoch:9 step:8995 [D loss: 0.581508, acc.: 67.97%] [G loss: 0.574683]\n",
      "epoch:9 step:8996 [D loss: 0.556680, acc.: 71.09%] [G loss: 0.499601]\n",
      "epoch:9 step:8997 [D loss: 0.523711, acc.: 71.88%] [G loss: 0.636244]\n",
      "epoch:9 step:8998 [D loss: 0.548708, acc.: 71.88%] [G loss: 0.631228]\n",
      "epoch:9 step:8999 [D loss: 0.663108, acc.: 64.84%] [G loss: 0.618548]\n",
      "epoch:9 step:9000 [D loss: 0.506586, acc.: 76.56%] [G loss: 0.553611]\n",
      "##############\n",
      "[3.33519282 1.36159685 6.37635747 4.82737565 4.09179737 5.86149579\n",
      " 4.80698643 4.9706001  4.55488282 4.13293172]\n",
      "##########\n",
      "epoch:9 step:9001 [D loss: 0.499965, acc.: 77.34%] [G loss: 0.617199]\n",
      "epoch:9 step:9002 [D loss: 0.576594, acc.: 71.88%] [G loss: 0.597518]\n",
      "epoch:9 step:9003 [D loss: 0.572744, acc.: 67.97%] [G loss: 0.476572]\n",
      "epoch:9 step:9004 [D loss: 0.493664, acc.: 77.34%] [G loss: 0.519934]\n",
      "epoch:9 step:9005 [D loss: 0.588175, acc.: 67.97%] [G loss: 0.595485]\n",
      "epoch:9 step:9006 [D loss: 0.552734, acc.: 73.44%] [G loss: 0.647739]\n",
      "epoch:9 step:9007 [D loss: 0.542813, acc.: 70.31%] [G loss: 0.668887]\n",
      "epoch:9 step:9008 [D loss: 0.510480, acc.: 75.78%] [G loss: 0.679591]\n",
      "epoch:9 step:9009 [D loss: 0.645286, acc.: 66.41%] [G loss: 0.554767]\n",
      "epoch:9 step:9010 [D loss: 0.548811, acc.: 71.09%] [G loss: 0.452441]\n",
      "epoch:9 step:9011 [D loss: 0.541852, acc.: 68.75%] [G loss: 0.575023]\n",
      "epoch:9 step:9012 [D loss: 0.504572, acc.: 75.78%] [G loss: 0.516464]\n",
      "epoch:9 step:9013 [D loss: 0.606840, acc.: 67.97%] [G loss: 0.585500]\n",
      "epoch:9 step:9014 [D loss: 0.517798, acc.: 71.09%] [G loss: 0.527968]\n",
      "epoch:9 step:9015 [D loss: 0.448126, acc.: 81.25%] [G loss: 0.963959]\n",
      "epoch:9 step:9016 [D loss: 0.617177, acc.: 63.28%] [G loss: 0.684928]\n",
      "epoch:9 step:9017 [D loss: 0.639245, acc.: 62.50%] [G loss: 0.563039]\n",
      "epoch:9 step:9018 [D loss: 0.533624, acc.: 78.12%] [G loss: 0.641217]\n",
      "epoch:9 step:9019 [D loss: 0.601107, acc.: 62.50%] [G loss: 0.532320]\n",
      "epoch:9 step:9020 [D loss: 0.567642, acc.: 67.19%] [G loss: 0.577373]\n",
      "epoch:9 step:9021 [D loss: 0.602800, acc.: 61.72%] [G loss: 0.658147]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9022 [D loss: 0.497757, acc.: 72.66%] [G loss: 0.577767]\n",
      "epoch:9 step:9023 [D loss: 0.533959, acc.: 71.09%] [G loss: 0.588718]\n",
      "epoch:9 step:9024 [D loss: 0.609620, acc.: 65.62%] [G loss: 0.531988]\n",
      "epoch:9 step:9025 [D loss: 0.500554, acc.: 77.34%] [G loss: 0.728240]\n",
      "epoch:9 step:9026 [D loss: 0.627590, acc.: 64.84%] [G loss: 0.587815]\n",
      "epoch:9 step:9027 [D loss: 0.539497, acc.: 71.09%] [G loss: 0.546006]\n",
      "epoch:9 step:9028 [D loss: 0.568771, acc.: 71.09%] [G loss: 0.483829]\n",
      "epoch:9 step:9029 [D loss: 0.592169, acc.: 67.97%] [G loss: 0.524554]\n",
      "epoch:9 step:9030 [D loss: 0.504708, acc.: 73.44%] [G loss: 0.600728]\n",
      "epoch:9 step:9031 [D loss: 0.505473, acc.: 74.22%] [G loss: 0.631967]\n",
      "epoch:9 step:9032 [D loss: 0.547957, acc.: 71.88%] [G loss: 0.655697]\n",
      "epoch:9 step:9033 [D loss: 0.599429, acc.: 67.97%] [G loss: 0.556536]\n",
      "epoch:9 step:9034 [D loss: 0.545375, acc.: 77.34%] [G loss: 0.655979]\n",
      "epoch:9 step:9035 [D loss: 0.517935, acc.: 73.44%] [G loss: 0.512959]\n",
      "epoch:9 step:9036 [D loss: 0.476719, acc.: 78.12%] [G loss: 0.659289]\n",
      "epoch:9 step:9037 [D loss: 0.610538, acc.: 68.75%] [G loss: 0.703348]\n",
      "epoch:9 step:9038 [D loss: 0.497463, acc.: 76.56%] [G loss: 0.521266]\n",
      "epoch:9 step:9039 [D loss: 0.595335, acc.: 63.28%] [G loss: 0.445369]\n",
      "epoch:9 step:9040 [D loss: 0.580117, acc.: 63.28%] [G loss: 0.470986]\n",
      "epoch:9 step:9041 [D loss: 0.495671, acc.: 76.56%] [G loss: 0.652301]\n",
      "epoch:9 step:9042 [D loss: 0.561838, acc.: 67.97%] [G loss: 0.503826]\n",
      "epoch:9 step:9043 [D loss: 0.544531, acc.: 74.22%] [G loss: 0.529382]\n",
      "epoch:9 step:9044 [D loss: 0.500148, acc.: 76.56%] [G loss: 0.486595]\n",
      "epoch:9 step:9045 [D loss: 0.555447, acc.: 70.31%] [G loss: 0.489044]\n",
      "epoch:9 step:9046 [D loss: 0.449866, acc.: 75.78%] [G loss: 0.587713]\n",
      "epoch:9 step:9047 [D loss: 0.544703, acc.: 69.53%] [G loss: 0.587585]\n",
      "epoch:9 step:9048 [D loss: 0.643073, acc.: 57.81%] [G loss: 0.521899]\n",
      "epoch:9 step:9049 [D loss: 0.563505, acc.: 69.53%] [G loss: 0.569635]\n",
      "epoch:9 step:9050 [D loss: 0.579224, acc.: 65.62%] [G loss: 0.628356]\n",
      "epoch:9 step:9051 [D loss: 0.542839, acc.: 71.88%] [G loss: 0.689698]\n",
      "epoch:9 step:9052 [D loss: 0.551136, acc.: 71.09%] [G loss: 0.404034]\n",
      "epoch:9 step:9053 [D loss: 0.549993, acc.: 69.53%] [G loss: 0.573710]\n",
      "epoch:9 step:9054 [D loss: 0.539896, acc.: 72.66%] [G loss: 0.542218]\n",
      "epoch:9 step:9055 [D loss: 0.601412, acc.: 66.41%] [G loss: 0.526214]\n",
      "epoch:9 step:9056 [D loss: 0.502765, acc.: 78.12%] [G loss: 0.540433]\n",
      "epoch:9 step:9057 [D loss: 0.474090, acc.: 74.22%] [G loss: 0.590196]\n",
      "epoch:9 step:9058 [D loss: 0.597304, acc.: 64.84%] [G loss: 0.498258]\n",
      "epoch:9 step:9059 [D loss: 0.543953, acc.: 67.19%] [G loss: 0.488114]\n",
      "epoch:9 step:9060 [D loss: 0.566831, acc.: 67.97%] [G loss: 0.657809]\n",
      "epoch:9 step:9061 [D loss: 0.566057, acc.: 68.75%] [G loss: 0.489279]\n",
      "epoch:9 step:9062 [D loss: 0.511624, acc.: 75.00%] [G loss: 0.611936]\n",
      "epoch:9 step:9063 [D loss: 0.599569, acc.: 67.97%] [G loss: 0.439509]\n",
      "epoch:9 step:9064 [D loss: 0.514704, acc.: 76.56%] [G loss: 0.765607]\n",
      "epoch:9 step:9065 [D loss: 0.480558, acc.: 80.47%] [G loss: 0.614598]\n",
      "epoch:9 step:9066 [D loss: 0.531939, acc.: 70.31%] [G loss: 0.503166]\n",
      "epoch:9 step:9067 [D loss: 0.485163, acc.: 77.34%] [G loss: 0.586854]\n",
      "epoch:9 step:9068 [D loss: 0.525545, acc.: 74.22%] [G loss: 0.521647]\n",
      "epoch:9 step:9069 [D loss: 0.588937, acc.: 67.97%] [G loss: 0.503623]\n",
      "epoch:9 step:9070 [D loss: 0.575616, acc.: 69.53%] [G loss: 0.496656]\n",
      "epoch:9 step:9071 [D loss: 0.514516, acc.: 71.88%] [G loss: 0.624342]\n",
      "epoch:9 step:9072 [D loss: 0.521116, acc.: 66.41%] [G loss: 0.589205]\n",
      "epoch:9 step:9073 [D loss: 0.515830, acc.: 72.66%] [G loss: 0.630890]\n",
      "epoch:9 step:9074 [D loss: 0.513765, acc.: 72.66%] [G loss: 0.686337]\n",
      "epoch:9 step:9075 [D loss: 0.512062, acc.: 74.22%] [G loss: 0.696808]\n",
      "epoch:9 step:9076 [D loss: 0.535357, acc.: 75.00%] [G loss: 0.640248]\n",
      "epoch:9 step:9077 [D loss: 0.576999, acc.: 65.62%] [G loss: 0.709259]\n",
      "epoch:9 step:9078 [D loss: 0.519505, acc.: 75.00%] [G loss: 0.559177]\n",
      "epoch:9 step:9079 [D loss: 0.565584, acc.: 67.97%] [G loss: 0.531929]\n",
      "epoch:9 step:9080 [D loss: 0.483314, acc.: 78.12%] [G loss: 0.640727]\n",
      "epoch:9 step:9081 [D loss: 0.398537, acc.: 80.47%] [G loss: 0.797929]\n",
      "epoch:9 step:9082 [D loss: 0.492882, acc.: 76.56%] [G loss: 0.810583]\n",
      "epoch:9 step:9083 [D loss: 0.464431, acc.: 79.69%] [G loss: 0.707942]\n",
      "epoch:9 step:9084 [D loss: 0.532555, acc.: 72.66%] [G loss: 0.696378]\n",
      "epoch:9 step:9085 [D loss: 0.641972, acc.: 62.50%] [G loss: 0.466416]\n",
      "epoch:9 step:9086 [D loss: 0.575487, acc.: 67.19%] [G loss: 0.508081]\n",
      "epoch:9 step:9087 [D loss: 0.523073, acc.: 71.88%] [G loss: 0.484806]\n",
      "epoch:9 step:9088 [D loss: 0.575612, acc.: 69.53%] [G loss: 0.538400]\n",
      "epoch:9 step:9089 [D loss: 0.585706, acc.: 66.41%] [G loss: 0.508700]\n",
      "epoch:9 step:9090 [D loss: 0.582470, acc.: 63.28%] [G loss: 0.646197]\n",
      "epoch:9 step:9091 [D loss: 0.582495, acc.: 64.84%] [G loss: 0.635704]\n",
      "epoch:9 step:9092 [D loss: 0.542609, acc.: 70.31%] [G loss: 0.706868]\n",
      "epoch:9 step:9093 [D loss: 0.471023, acc.: 76.56%] [G loss: 0.567100]\n",
      "epoch:9 step:9094 [D loss: 0.527363, acc.: 75.00%] [G loss: 0.661522]\n",
      "epoch:9 step:9095 [D loss: 0.555953, acc.: 67.97%] [G loss: 0.630390]\n",
      "epoch:9 step:9096 [D loss: 0.586860, acc.: 65.62%] [G loss: 0.550399]\n",
      "epoch:9 step:9097 [D loss: 0.557177, acc.: 65.62%] [G loss: 0.711049]\n",
      "epoch:9 step:9098 [D loss: 0.556570, acc.: 67.97%] [G loss: 0.834785]\n",
      "epoch:9 step:9099 [D loss: 0.526192, acc.: 74.22%] [G loss: 0.758516]\n",
      "epoch:9 step:9100 [D loss: 0.564850, acc.: 68.75%] [G loss: 0.663142]\n",
      "epoch:9 step:9101 [D loss: 0.592319, acc.: 69.53%] [G loss: 0.516639]\n",
      "epoch:9 step:9102 [D loss: 0.513349, acc.: 72.66%] [G loss: 0.756368]\n",
      "epoch:9 step:9103 [D loss: 0.574596, acc.: 66.41%] [G loss: 0.567424]\n",
      "epoch:9 step:9104 [D loss: 0.585549, acc.: 67.19%] [G loss: 0.599385]\n",
      "epoch:9 step:9105 [D loss: 0.602949, acc.: 61.72%] [G loss: 0.577569]\n",
      "epoch:9 step:9106 [D loss: 0.611101, acc.: 61.72%] [G loss: 0.495559]\n",
      "epoch:9 step:9107 [D loss: 0.578853, acc.: 72.66%] [G loss: 0.853083]\n",
      "epoch:9 step:9108 [D loss: 0.560155, acc.: 71.88%] [G loss: 0.565457]\n",
      "epoch:9 step:9109 [D loss: 0.574113, acc.: 67.97%] [G loss: 0.554606]\n",
      "epoch:9 step:9110 [D loss: 0.481813, acc.: 75.00%] [G loss: 0.679934]\n",
      "epoch:9 step:9111 [D loss: 0.565502, acc.: 71.09%] [G loss: 0.669300]\n",
      "epoch:9 step:9112 [D loss: 0.491708, acc.: 78.91%] [G loss: 0.573452]\n",
      "epoch:9 step:9113 [D loss: 0.472720, acc.: 78.91%] [G loss: 0.499948]\n",
      "epoch:9 step:9114 [D loss: 0.521115, acc.: 72.66%] [G loss: 0.592949]\n",
      "epoch:9 step:9115 [D loss: 0.577532, acc.: 64.06%] [G loss: 0.456490]\n",
      "epoch:9 step:9116 [D loss: 0.556062, acc.: 71.09%] [G loss: 0.411842]\n",
      "epoch:9 step:9117 [D loss: 0.560347, acc.: 65.62%] [G loss: 0.496111]\n",
      "epoch:9 step:9118 [D loss: 0.542184, acc.: 69.53%] [G loss: 0.539775]\n",
      "epoch:9 step:9119 [D loss: 0.584630, acc.: 69.53%] [G loss: 0.379318]\n",
      "epoch:9 step:9120 [D loss: 0.564778, acc.: 71.09%] [G loss: 0.515419]\n",
      "epoch:9 step:9121 [D loss: 0.549184, acc.: 71.88%] [G loss: 0.525328]\n",
      "epoch:9 step:9122 [D loss: 0.577791, acc.: 67.97%] [G loss: 0.706156]\n",
      "epoch:9 step:9123 [D loss: 0.526206, acc.: 73.44%] [G loss: 0.628594]\n",
      "epoch:9 step:9124 [D loss: 0.504738, acc.: 75.00%] [G loss: 0.557725]\n",
      "epoch:9 step:9125 [D loss: 0.541165, acc.: 71.09%] [G loss: 0.803934]\n",
      "epoch:9 step:9126 [D loss: 0.483648, acc.: 74.22%] [G loss: 0.618431]\n",
      "epoch:9 step:9127 [D loss: 0.515855, acc.: 77.34%] [G loss: 0.630129]\n",
      "epoch:9 step:9128 [D loss: 0.530503, acc.: 74.22%] [G loss: 0.604053]\n",
      "epoch:9 step:9129 [D loss: 0.592666, acc.: 71.09%] [G loss: 0.364579]\n",
      "epoch:9 step:9130 [D loss: 0.537202, acc.: 68.75%] [G loss: 0.594379]\n",
      "epoch:9 step:9131 [D loss: 0.539733, acc.: 71.88%] [G loss: 0.642952]\n",
      "epoch:9 step:9132 [D loss: 0.526008, acc.: 71.09%] [G loss: 0.562534]\n",
      "epoch:9 step:9133 [D loss: 0.578890, acc.: 65.62%] [G loss: 0.586463]\n",
      "epoch:9 step:9134 [D loss: 0.522023, acc.: 73.44%] [G loss: 0.695384]\n",
      "epoch:9 step:9135 [D loss: 0.614532, acc.: 61.72%] [G loss: 0.559245]\n",
      "epoch:9 step:9136 [D loss: 0.613789, acc.: 68.75%] [G loss: 0.537468]\n",
      "epoch:9 step:9137 [D loss: 0.584217, acc.: 70.31%] [G loss: 0.502554]\n",
      "epoch:9 step:9138 [D loss: 0.576771, acc.: 70.31%] [G loss: 0.440912]\n",
      "epoch:9 step:9139 [D loss: 0.520917, acc.: 72.66%] [G loss: 0.610743]\n",
      "epoch:9 step:9140 [D loss: 0.496734, acc.: 82.03%] [G loss: 0.619359]\n",
      "epoch:9 step:9141 [D loss: 0.502159, acc.: 78.91%] [G loss: 0.675049]\n",
      "epoch:9 step:9142 [D loss: 0.502725, acc.: 73.44%] [G loss: 0.752307]\n",
      "epoch:9 step:9143 [D loss: 0.601352, acc.: 69.53%] [G loss: 0.597982]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9144 [D loss: 0.644760, acc.: 62.50%] [G loss: 0.477823]\n",
      "epoch:9 step:9145 [D loss: 0.563293, acc.: 69.53%] [G loss: 0.475224]\n",
      "epoch:9 step:9146 [D loss: 0.577083, acc.: 69.53%] [G loss: 0.553271]\n",
      "epoch:9 step:9147 [D loss: 0.566508, acc.: 65.62%] [G loss: 0.586800]\n",
      "epoch:9 step:9148 [D loss: 0.544266, acc.: 72.66%] [G loss: 0.559676]\n",
      "epoch:9 step:9149 [D loss: 0.624181, acc.: 67.19%] [G loss: 0.482531]\n",
      "epoch:9 step:9150 [D loss: 0.552319, acc.: 68.75%] [G loss: 0.382065]\n",
      "epoch:9 step:9151 [D loss: 0.583002, acc.: 66.41%] [G loss: 0.459413]\n",
      "epoch:9 step:9152 [D loss: 0.494625, acc.: 76.56%] [G loss: 0.619415]\n",
      "epoch:9 step:9153 [D loss: 0.618760, acc.: 65.62%] [G loss: 0.459677]\n",
      "epoch:9 step:9154 [D loss: 0.568125, acc.: 71.88%] [G loss: 0.679974]\n",
      "epoch:9 step:9155 [D loss: 0.567275, acc.: 67.97%] [G loss: 0.594651]\n",
      "epoch:9 step:9156 [D loss: 0.553551, acc.: 71.88%] [G loss: 0.712153]\n",
      "epoch:9 step:9157 [D loss: 0.539478, acc.: 70.31%] [G loss: 0.629988]\n",
      "epoch:9 step:9158 [D loss: 0.525983, acc.: 75.78%] [G loss: 0.556146]\n",
      "epoch:9 step:9159 [D loss: 0.555701, acc.: 69.53%] [G loss: 0.733746]\n",
      "epoch:9 step:9160 [D loss: 0.592747, acc.: 65.62%] [G loss: 0.576304]\n",
      "epoch:9 step:9161 [D loss: 0.504782, acc.: 71.88%] [G loss: 0.665467]\n",
      "epoch:9 step:9162 [D loss: 0.575431, acc.: 71.09%] [G loss: 0.649168]\n",
      "epoch:9 step:9163 [D loss: 0.556620, acc.: 71.09%] [G loss: 0.405745]\n",
      "epoch:9 step:9164 [D loss: 0.581454, acc.: 65.62%] [G loss: 0.639291]\n",
      "epoch:9 step:9165 [D loss: 0.509049, acc.: 75.00%] [G loss: 0.549885]\n",
      "epoch:9 step:9166 [D loss: 0.587817, acc.: 64.06%] [G loss: 0.652893]\n",
      "epoch:9 step:9167 [D loss: 0.520808, acc.: 71.09%] [G loss: 0.531388]\n",
      "epoch:9 step:9168 [D loss: 0.586314, acc.: 64.84%] [G loss: 0.584746]\n",
      "epoch:9 step:9169 [D loss: 0.460417, acc.: 78.91%] [G loss: 0.556452]\n",
      "epoch:9 step:9170 [D loss: 0.621333, acc.: 64.84%] [G loss: 0.494521]\n",
      "epoch:9 step:9171 [D loss: 0.553571, acc.: 68.75%] [G loss: 0.613635]\n",
      "epoch:9 step:9172 [D loss: 0.615230, acc.: 59.38%] [G loss: 0.496851]\n",
      "epoch:9 step:9173 [D loss: 0.596072, acc.: 64.84%] [G loss: 0.443099]\n",
      "epoch:9 step:9174 [D loss: 0.573835, acc.: 68.75%] [G loss: 0.519819]\n",
      "epoch:9 step:9175 [D loss: 0.557793, acc.: 68.75%] [G loss: 0.500321]\n",
      "epoch:9 step:9176 [D loss: 0.505198, acc.: 71.09%] [G loss: 0.610520]\n",
      "epoch:9 step:9177 [D loss: 0.631840, acc.: 71.88%] [G loss: 0.619936]\n",
      "epoch:9 step:9178 [D loss: 0.582936, acc.: 65.62%] [G loss: 0.556743]\n",
      "epoch:9 step:9179 [D loss: 0.493007, acc.: 72.66%] [G loss: 0.627264]\n",
      "epoch:9 step:9180 [D loss: 0.472444, acc.: 75.78%] [G loss: 0.748506]\n",
      "epoch:9 step:9181 [D loss: 0.577302, acc.: 65.62%] [G loss: 0.442442]\n",
      "epoch:9 step:9182 [D loss: 0.523433, acc.: 71.88%] [G loss: 0.626653]\n",
      "epoch:9 step:9183 [D loss: 0.598219, acc.: 71.09%] [G loss: 0.539641]\n",
      "epoch:9 step:9184 [D loss: 0.516400, acc.: 73.44%] [G loss: 0.630765]\n",
      "epoch:9 step:9185 [D loss: 0.519324, acc.: 73.44%] [G loss: 0.576070]\n",
      "epoch:9 step:9186 [D loss: 0.567715, acc.: 71.09%] [G loss: 0.628468]\n",
      "epoch:9 step:9187 [D loss: 0.597054, acc.: 60.94%] [G loss: 0.538076]\n",
      "epoch:9 step:9188 [D loss: 0.561824, acc.: 69.53%] [G loss: 0.566963]\n",
      "epoch:9 step:9189 [D loss: 0.547269, acc.: 70.31%] [G loss: 0.569202]\n",
      "epoch:9 step:9190 [D loss: 0.606992, acc.: 65.62%] [G loss: 0.655827]\n",
      "epoch:9 step:9191 [D loss: 0.566225, acc.: 70.31%] [G loss: 0.486060]\n",
      "epoch:9 step:9192 [D loss: 0.562596, acc.: 68.75%] [G loss: 0.477589]\n",
      "epoch:9 step:9193 [D loss: 0.540036, acc.: 71.88%] [G loss: 0.547894]\n",
      "epoch:9 step:9194 [D loss: 0.539279, acc.: 69.53%] [G loss: 0.500981]\n",
      "epoch:9 step:9195 [D loss: 0.600943, acc.: 63.28%] [G loss: 0.437596]\n",
      "epoch:9 step:9196 [D loss: 0.529628, acc.: 70.31%] [G loss: 0.619434]\n",
      "epoch:9 step:9197 [D loss: 0.560585, acc.: 68.75%] [G loss: 0.538572]\n",
      "epoch:9 step:9198 [D loss: 0.633859, acc.: 65.62%] [G loss: 0.529366]\n",
      "epoch:9 step:9199 [D loss: 0.652373, acc.: 58.59%] [G loss: 0.473088]\n",
      "epoch:9 step:9200 [D loss: 0.545265, acc.: 74.22%] [G loss: 0.616264]\n",
      "##############\n",
      "[2.6286271  0.98624292 6.3511306  4.83822128 3.81369543 5.72203142\n",
      " 4.69055543 4.64482511 4.56408608 3.8839196 ]\n",
      "##########\n",
      "epoch:9 step:9201 [D loss: 0.554070, acc.: 71.88%] [G loss: 0.573115]\n",
      "epoch:9 step:9202 [D loss: 0.477991, acc.: 78.12%] [G loss: 0.815861]\n",
      "epoch:9 step:9203 [D loss: 0.496151, acc.: 75.00%] [G loss: 0.616377]\n",
      "epoch:9 step:9204 [D loss: 0.576684, acc.: 64.06%] [G loss: 0.580928]\n",
      "epoch:9 step:9205 [D loss: 0.537982, acc.: 72.66%] [G loss: 0.650660]\n",
      "epoch:9 step:9206 [D loss: 0.530345, acc.: 71.88%] [G loss: 0.624521]\n",
      "epoch:9 step:9207 [D loss: 0.562498, acc.: 71.88%] [G loss: 0.525722]\n",
      "epoch:9 step:9208 [D loss: 0.557292, acc.: 68.75%] [G loss: 0.526126]\n",
      "epoch:9 step:9209 [D loss: 0.557356, acc.: 68.75%] [G loss: 0.636831]\n",
      "epoch:9 step:9210 [D loss: 0.561782, acc.: 71.09%] [G loss: 0.485847]\n",
      "epoch:9 step:9211 [D loss: 0.569591, acc.: 70.31%] [G loss: 0.499544]\n",
      "epoch:9 step:9212 [D loss: 0.627487, acc.: 61.72%] [G loss: 0.524585]\n",
      "epoch:9 step:9213 [D loss: 0.543785, acc.: 72.66%] [G loss: 0.478092]\n",
      "epoch:9 step:9214 [D loss: 0.502798, acc.: 73.44%] [G loss: 0.759976]\n",
      "epoch:9 step:9215 [D loss: 0.539775, acc.: 70.31%] [G loss: 0.691521]\n",
      "epoch:9 step:9216 [D loss: 0.563630, acc.: 69.53%] [G loss: 0.691777]\n",
      "epoch:9 step:9217 [D loss: 0.598497, acc.: 65.62%] [G loss: 0.516466]\n",
      "epoch:9 step:9218 [D loss: 0.545272, acc.: 67.97%] [G loss: 0.543244]\n",
      "epoch:9 step:9219 [D loss: 0.507315, acc.: 71.88%] [G loss: 0.597726]\n",
      "epoch:9 step:9220 [D loss: 0.590296, acc.: 67.19%] [G loss: 0.601305]\n",
      "epoch:9 step:9221 [D loss: 0.633924, acc.: 64.84%] [G loss: 0.566891]\n",
      "epoch:9 step:9222 [D loss: 0.532401, acc.: 73.44%] [G loss: 0.472642]\n",
      "epoch:9 step:9223 [D loss: 0.523714, acc.: 77.34%] [G loss: 0.437784]\n",
      "epoch:9 step:9224 [D loss: 0.552614, acc.: 71.88%] [G loss: 0.491476]\n",
      "epoch:9 step:9225 [D loss: 0.462572, acc.: 75.78%] [G loss: 0.522929]\n",
      "epoch:9 step:9226 [D loss: 0.609820, acc.: 64.06%] [G loss: 0.633757]\n",
      "epoch:9 step:9227 [D loss: 0.636632, acc.: 58.59%] [G loss: 0.718957]\n",
      "epoch:9 step:9228 [D loss: 0.495639, acc.: 74.22%] [G loss: 0.616501]\n",
      "epoch:9 step:9229 [D loss: 0.593556, acc.: 67.19%] [G loss: 0.652052]\n",
      "epoch:9 step:9230 [D loss: 0.555300, acc.: 68.75%] [G loss: 0.613812]\n",
      "epoch:9 step:9231 [D loss: 0.612224, acc.: 61.72%] [G loss: 0.622878]\n",
      "epoch:9 step:9232 [D loss: 0.571010, acc.: 74.22%] [G loss: 0.593230]\n",
      "epoch:9 step:9233 [D loss: 0.619609, acc.: 63.28%] [G loss: 0.469951]\n",
      "epoch:9 step:9234 [D loss: 0.531524, acc.: 72.66%] [G loss: 0.652527]\n",
      "epoch:9 step:9235 [D loss: 0.509496, acc.: 78.91%] [G loss: 0.873868]\n",
      "epoch:9 step:9236 [D loss: 0.555344, acc.: 74.22%] [G loss: 0.591000]\n",
      "epoch:9 step:9237 [D loss: 0.540343, acc.: 67.19%] [G loss: 0.654645]\n",
      "epoch:9 step:9238 [D loss: 0.559446, acc.: 66.41%] [G loss: 0.519156]\n",
      "epoch:9 step:9239 [D loss: 0.515268, acc.: 71.88%] [G loss: 0.568444]\n",
      "epoch:9 step:9240 [D loss: 0.510291, acc.: 68.75%] [G loss: 0.705279]\n",
      "epoch:9 step:9241 [D loss: 0.513905, acc.: 72.66%] [G loss: 0.630645]\n",
      "epoch:9 step:9242 [D loss: 0.586358, acc.: 69.53%] [G loss: 0.457233]\n",
      "epoch:9 step:9243 [D loss: 0.547885, acc.: 70.31%] [G loss: 0.507232]\n",
      "epoch:9 step:9244 [D loss: 0.560828, acc.: 70.31%] [G loss: 0.531251]\n",
      "epoch:9 step:9245 [D loss: 0.649847, acc.: 62.50%] [G loss: 0.476695]\n",
      "epoch:9 step:9246 [D loss: 0.555884, acc.: 71.09%] [G loss: 0.521087]\n",
      "epoch:9 step:9247 [D loss: 0.505436, acc.: 68.75%] [G loss: 0.651236]\n",
      "epoch:9 step:9248 [D loss: 0.554223, acc.: 74.22%] [G loss: 0.728303]\n",
      "epoch:9 step:9249 [D loss: 0.559233, acc.: 69.53%] [G loss: 0.633397]\n",
      "epoch:9 step:9250 [D loss: 0.597153, acc.: 70.31%] [G loss: 0.687209]\n",
      "epoch:9 step:9251 [D loss: 0.623311, acc.: 62.50%] [G loss: 0.591504]\n",
      "epoch:9 step:9252 [D loss: 0.515390, acc.: 73.44%] [G loss: 0.583670]\n",
      "epoch:9 step:9253 [D loss: 0.642766, acc.: 57.03%] [G loss: 0.568173]\n",
      "epoch:9 step:9254 [D loss: 0.518529, acc.: 76.56%] [G loss: 0.572228]\n",
      "epoch:9 step:9255 [D loss: 0.524446, acc.: 71.88%] [G loss: 0.475499]\n",
      "epoch:9 step:9256 [D loss: 0.499653, acc.: 77.34%] [G loss: 0.513493]\n",
      "epoch:9 step:9257 [D loss: 0.578731, acc.: 69.53%] [G loss: 0.581216]\n",
      "epoch:9 step:9258 [D loss: 0.516039, acc.: 71.88%] [G loss: 0.691388]\n",
      "epoch:9 step:9259 [D loss: 0.591549, acc.: 66.41%] [G loss: 0.645963]\n",
      "epoch:9 step:9260 [D loss: 0.545887, acc.: 71.09%] [G loss: 0.543113]\n",
      "epoch:9 step:9261 [D loss: 0.625976, acc.: 60.94%] [G loss: 0.532445]\n",
      "epoch:9 step:9262 [D loss: 0.481981, acc.: 77.34%] [G loss: 0.648808]\n",
      "epoch:9 step:9263 [D loss: 0.560913, acc.: 67.19%] [G loss: 0.440158]\n",
      "epoch:9 step:9264 [D loss: 0.502031, acc.: 76.56%] [G loss: 0.523830]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9265 [D loss: 0.509631, acc.: 75.00%] [G loss: 0.651830]\n",
      "epoch:9 step:9266 [D loss: 0.509142, acc.: 75.78%] [G loss: 0.528120]\n",
      "epoch:9 step:9267 [D loss: 0.528840, acc.: 73.44%] [G loss: 0.445817]\n",
      "epoch:9 step:9268 [D loss: 0.540348, acc.: 72.66%] [G loss: 0.514035]\n",
      "epoch:9 step:9269 [D loss: 0.570786, acc.: 68.75%] [G loss: 0.401051]\n",
      "epoch:9 step:9270 [D loss: 0.606912, acc.: 64.84%] [G loss: 0.528256]\n",
      "epoch:9 step:9271 [D loss: 0.519091, acc.: 72.66%] [G loss: 0.611674]\n",
      "epoch:9 step:9272 [D loss: 0.568570, acc.: 65.62%] [G loss: 0.505807]\n",
      "epoch:9 step:9273 [D loss: 0.649745, acc.: 61.72%] [G loss: 0.385476]\n",
      "epoch:9 step:9274 [D loss: 0.534013, acc.: 69.53%] [G loss: 0.459642]\n",
      "epoch:9 step:9275 [D loss: 0.528784, acc.: 71.09%] [G loss: 0.475480]\n",
      "epoch:9 step:9276 [D loss: 0.507469, acc.: 73.44%] [G loss: 0.524307]\n",
      "epoch:9 step:9277 [D loss: 0.590882, acc.: 68.75%] [G loss: 0.465376]\n",
      "epoch:9 step:9278 [D loss: 0.586165, acc.: 72.66%] [G loss: 0.500893]\n",
      "epoch:9 step:9279 [D loss: 0.611702, acc.: 61.72%] [G loss: 0.498078]\n",
      "epoch:9 step:9280 [D loss: 0.615415, acc.: 66.41%] [G loss: 0.459400]\n",
      "epoch:9 step:9281 [D loss: 0.544101, acc.: 66.41%] [G loss: 0.484979]\n",
      "epoch:9 step:9282 [D loss: 0.612671, acc.: 61.72%] [G loss: 0.342876]\n",
      "epoch:9 step:9283 [D loss: 0.591251, acc.: 64.06%] [G loss: 0.328729]\n",
      "epoch:9 step:9284 [D loss: 0.563992, acc.: 69.53%] [G loss: 0.584850]\n",
      "epoch:9 step:9285 [D loss: 0.494160, acc.: 75.78%] [G loss: 0.646493]\n",
      "epoch:9 step:9286 [D loss: 0.588612, acc.: 61.72%] [G loss: 0.445782]\n",
      "epoch:9 step:9287 [D loss: 0.521474, acc.: 71.09%] [G loss: 0.495956]\n",
      "epoch:9 step:9288 [D loss: 0.545306, acc.: 68.75%] [G loss: 0.573530]\n",
      "epoch:9 step:9289 [D loss: 0.614720, acc.: 65.62%] [G loss: 0.577422]\n",
      "epoch:9 step:9290 [D loss: 0.498812, acc.: 71.88%] [G loss: 0.595001]\n",
      "epoch:9 step:9291 [D loss: 0.583623, acc.: 67.19%] [G loss: 0.563688]\n",
      "epoch:9 step:9292 [D loss: 0.567244, acc.: 68.75%] [G loss: 0.558551]\n",
      "epoch:9 step:9293 [D loss: 0.455968, acc.: 78.12%] [G loss: 0.637138]\n",
      "epoch:9 step:9294 [D loss: 0.652006, acc.: 62.50%] [G loss: 0.477310]\n",
      "epoch:9 step:9295 [D loss: 0.580721, acc.: 70.31%] [G loss: 0.526831]\n",
      "epoch:9 step:9296 [D loss: 0.615782, acc.: 57.03%] [G loss: 0.451692]\n",
      "epoch:9 step:9297 [D loss: 0.577695, acc.: 68.75%] [G loss: 0.515837]\n",
      "epoch:9 step:9298 [D loss: 0.553728, acc.: 71.09%] [G loss: 0.460406]\n",
      "epoch:9 step:9299 [D loss: 0.521143, acc.: 71.09%] [G loss: 0.493228]\n",
      "epoch:9 step:9300 [D loss: 0.654314, acc.: 62.50%] [G loss: 0.303701]\n",
      "epoch:9 step:9301 [D loss: 0.505571, acc.: 75.00%] [G loss: 0.446906]\n",
      "epoch:9 step:9302 [D loss: 0.656763, acc.: 62.50%] [G loss: 0.350136]\n",
      "epoch:9 step:9303 [D loss: 0.479035, acc.: 75.78%] [G loss: 0.622853]\n",
      "epoch:9 step:9304 [D loss: 0.519860, acc.: 74.22%] [G loss: 0.666858]\n",
      "epoch:9 step:9305 [D loss: 0.567774, acc.: 66.41%] [G loss: 0.469619]\n",
      "epoch:9 step:9306 [D loss: 0.556651, acc.: 71.88%] [G loss: 0.649675]\n",
      "epoch:9 step:9307 [D loss: 0.555929, acc.: 70.31%] [G loss: 0.479733]\n",
      "epoch:9 step:9308 [D loss: 0.512508, acc.: 75.00%] [G loss: 0.497856]\n",
      "epoch:9 step:9309 [D loss: 0.549226, acc.: 68.75%] [G loss: 0.525453]\n",
      "epoch:9 step:9310 [D loss: 0.571444, acc.: 73.44%] [G loss: 0.436774]\n",
      "epoch:9 step:9311 [D loss: 0.602311, acc.: 69.53%] [G loss: 0.394126]\n",
      "epoch:9 step:9312 [D loss: 0.569430, acc.: 67.19%] [G loss: 0.564401]\n",
      "epoch:9 step:9313 [D loss: 0.641123, acc.: 62.50%] [G loss: 0.393218]\n",
      "epoch:9 step:9314 [D loss: 0.579369, acc.: 66.41%] [G loss: 0.503213]\n",
      "epoch:9 step:9315 [D loss: 0.580418, acc.: 67.19%] [G loss: 0.503909]\n",
      "epoch:9 step:9316 [D loss: 0.574707, acc.: 68.75%] [G loss: 0.563338]\n",
      "epoch:9 step:9317 [D loss: 0.468292, acc.: 78.91%] [G loss: 0.662872]\n",
      "epoch:9 step:9318 [D loss: 0.544779, acc.: 64.06%] [G loss: 0.695185]\n",
      "epoch:9 step:9319 [D loss: 0.487233, acc.: 73.44%] [G loss: 0.572011]\n",
      "epoch:9 step:9320 [D loss: 0.585032, acc.: 71.09%] [G loss: 0.607071]\n",
      "epoch:9 step:9321 [D loss: 0.536028, acc.: 70.31%] [G loss: 0.616520]\n",
      "epoch:9 step:9322 [D loss: 0.530189, acc.: 72.66%] [G loss: 0.484589]\n",
      "epoch:9 step:9323 [D loss: 0.494683, acc.: 79.69%] [G loss: 0.584923]\n",
      "epoch:9 step:9324 [D loss: 0.631178, acc.: 67.19%] [G loss: 0.457192]\n",
      "epoch:9 step:9325 [D loss: 0.600638, acc.: 65.62%] [G loss: 0.489824]\n",
      "epoch:9 step:9326 [D loss: 0.566680, acc.: 65.62%] [G loss: 0.467322]\n",
      "epoch:9 step:9327 [D loss: 0.470687, acc.: 75.00%] [G loss: 0.690856]\n",
      "epoch:9 step:9328 [D loss: 0.523197, acc.: 71.09%] [G loss: 0.788367]\n",
      "epoch:9 step:9329 [D loss: 0.531548, acc.: 71.09%] [G loss: 0.715325]\n",
      "epoch:9 step:9330 [D loss: 0.540320, acc.: 76.56%] [G loss: 0.644865]\n",
      "epoch:9 step:9331 [D loss: 0.516569, acc.: 77.34%] [G loss: 0.769365]\n",
      "epoch:9 step:9332 [D loss: 0.522929, acc.: 71.09%] [G loss: 0.683415]\n",
      "epoch:9 step:9333 [D loss: 0.529946, acc.: 69.53%] [G loss: 0.642982]\n",
      "epoch:9 step:9334 [D loss: 0.524319, acc.: 73.44%] [G loss: 0.575949]\n",
      "epoch:9 step:9335 [D loss: 0.582039, acc.: 67.19%] [G loss: 0.444140]\n",
      "epoch:9 step:9336 [D loss: 0.571589, acc.: 70.31%] [G loss: 0.501646]\n",
      "epoch:9 step:9337 [D loss: 0.623865, acc.: 64.06%] [G loss: 0.472889]\n",
      "epoch:9 step:9338 [D loss: 0.609559, acc.: 68.75%] [G loss: 0.564697]\n",
      "epoch:9 step:9339 [D loss: 0.541577, acc.: 70.31%] [G loss: 0.510460]\n",
      "epoch:9 step:9340 [D loss: 0.529353, acc.: 75.00%] [G loss: 0.451106]\n",
      "epoch:9 step:9341 [D loss: 0.544106, acc.: 74.22%] [G loss: 0.579684]\n",
      "epoch:9 step:9342 [D loss: 0.502277, acc.: 73.44%] [G loss: 0.676404]\n",
      "epoch:9 step:9343 [D loss: 0.491721, acc.: 72.66%] [G loss: 0.580510]\n",
      "epoch:9 step:9344 [D loss: 0.478349, acc.: 78.12%] [G loss: 0.651832]\n",
      "epoch:9 step:9345 [D loss: 0.461595, acc.: 79.69%] [G loss: 0.861001]\n",
      "epoch:9 step:9346 [D loss: 0.567217, acc.: 68.75%] [G loss: 0.665522]\n",
      "epoch:9 step:9347 [D loss: 0.496460, acc.: 75.00%] [G loss: 0.809095]\n",
      "epoch:9 step:9348 [D loss: 0.668195, acc.: 60.94%] [G loss: 0.775045]\n",
      "epoch:9 step:9349 [D loss: 0.525807, acc.: 72.66%] [G loss: 0.636446]\n",
      "epoch:9 step:9350 [D loss: 0.626833, acc.: 63.28%] [G loss: 0.670236]\n",
      "epoch:9 step:9351 [D loss: 0.515038, acc.: 75.78%] [G loss: 0.634324]\n",
      "epoch:9 step:9352 [D loss: 0.490069, acc.: 79.69%] [G loss: 0.612521]\n",
      "epoch:9 step:9353 [D loss: 0.723075, acc.: 60.16%] [G loss: 0.609678]\n",
      "epoch:9 step:9354 [D loss: 0.538917, acc.: 70.31%] [G loss: 0.553785]\n",
      "epoch:9 step:9355 [D loss: 0.488397, acc.: 74.22%] [G loss: 0.690340]\n",
      "epoch:9 step:9356 [D loss: 0.470771, acc.: 76.56%] [G loss: 0.659769]\n",
      "epoch:9 step:9357 [D loss: 0.405467, acc.: 85.16%] [G loss: 0.742789]\n",
      "epoch:9 step:9358 [D loss: 0.448776, acc.: 76.56%] [G loss: 0.913870]\n",
      "epoch:9 step:9359 [D loss: 0.423469, acc.: 79.69%] [G loss: 0.936229]\n",
      "epoch:9 step:9360 [D loss: 0.540802, acc.: 73.44%] [G loss: 0.987410]\n",
      "epoch:9 step:9361 [D loss: 0.807345, acc.: 57.03%] [G loss: 0.888437]\n",
      "epoch:9 step:9362 [D loss: 0.558758, acc.: 71.09%] [G loss: 1.104576]\n",
      "epoch:9 step:9363 [D loss: 0.485641, acc.: 75.78%] [G loss: 0.973539]\n",
      "epoch:9 step:9364 [D loss: 0.610275, acc.: 60.94%] [G loss: 0.678995]\n",
      "epoch:9 step:9365 [D loss: 0.638303, acc.: 65.62%] [G loss: 0.607860]\n",
      "epoch:9 step:9366 [D loss: 0.534695, acc.: 71.88%] [G loss: 0.628452]\n",
      "epoch:9 step:9367 [D loss: 0.532870, acc.: 72.66%] [G loss: 0.632822]\n",
      "epoch:9 step:9368 [D loss: 0.522580, acc.: 76.56%] [G loss: 0.848611]\n",
      "epoch:9 step:9369 [D loss: 0.428190, acc.: 79.69%] [G loss: 0.916828]\n",
      "epoch:9 step:9370 [D loss: 0.433514, acc.: 82.03%] [G loss: 0.909104]\n",
      "epoch:10 step:9371 [D loss: 0.594911, acc.: 71.88%] [G loss: 0.972919]\n",
      "epoch:10 step:9372 [D loss: 0.504023, acc.: 77.34%] [G loss: 0.816284]\n",
      "epoch:10 step:9373 [D loss: 0.576821, acc.: 68.75%] [G loss: 0.742384]\n",
      "epoch:10 step:9374 [D loss: 0.516801, acc.: 75.00%] [G loss: 0.605386]\n",
      "epoch:10 step:9375 [D loss: 0.577734, acc.: 68.75%] [G loss: 0.616665]\n",
      "epoch:10 step:9376 [D loss: 0.582437, acc.: 70.31%] [G loss: 0.691614]\n",
      "epoch:10 step:9377 [D loss: 0.476474, acc.: 77.34%] [G loss: 0.744831]\n",
      "epoch:10 step:9378 [D loss: 0.607665, acc.: 67.97%] [G loss: 0.469393]\n",
      "epoch:10 step:9379 [D loss: 0.522419, acc.: 75.78%] [G loss: 0.627110]\n",
      "epoch:10 step:9380 [D loss: 0.573455, acc.: 72.66%] [G loss: 0.572966]\n",
      "epoch:10 step:9381 [D loss: 0.497175, acc.: 75.78%] [G loss: 0.604235]\n",
      "epoch:10 step:9382 [D loss: 0.570828, acc.: 70.31%] [G loss: 0.532769]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9383 [D loss: 0.522872, acc.: 71.09%] [G loss: 0.634640]\n",
      "epoch:10 step:9384 [D loss: 0.568370, acc.: 72.66%] [G loss: 0.527165]\n",
      "epoch:10 step:9385 [D loss: 0.498582, acc.: 75.78%] [G loss: 0.622380]\n",
      "epoch:10 step:9386 [D loss: 0.515938, acc.: 70.31%] [G loss: 0.552208]\n",
      "epoch:10 step:9387 [D loss: 0.583362, acc.: 69.53%] [G loss: 0.515307]\n",
      "epoch:10 step:9388 [D loss: 0.621660, acc.: 64.84%] [G loss: 0.546338]\n",
      "epoch:10 step:9389 [D loss: 0.626060, acc.: 63.28%] [G loss: 0.563711]\n",
      "epoch:10 step:9390 [D loss: 0.669030, acc.: 60.94%] [G loss: 0.598292]\n",
      "epoch:10 step:9391 [D loss: 0.568684, acc.: 67.97%] [G loss: 0.562300]\n",
      "epoch:10 step:9392 [D loss: 0.520528, acc.: 76.56%] [G loss: 0.644434]\n",
      "epoch:10 step:9393 [D loss: 0.541914, acc.: 73.44%] [G loss: 0.585003]\n",
      "epoch:10 step:9394 [D loss: 0.513541, acc.: 75.78%] [G loss: 0.556583]\n",
      "epoch:10 step:9395 [D loss: 0.487045, acc.: 77.34%] [G loss: 0.556297]\n",
      "epoch:10 step:9396 [D loss: 0.571280, acc.: 67.97%] [G loss: 0.555554]\n",
      "epoch:10 step:9397 [D loss: 0.449092, acc.: 80.47%] [G loss: 0.523356]\n",
      "epoch:10 step:9398 [D loss: 0.534994, acc.: 68.75%] [G loss: 0.696651]\n",
      "epoch:10 step:9399 [D loss: 0.493061, acc.: 73.44%] [G loss: 0.524598]\n",
      "epoch:10 step:9400 [D loss: 0.527331, acc.: 73.44%] [G loss: 0.463589]\n",
      "##############\n",
      "[3.14713549 1.46620583 6.43685973 4.49384523 3.76446177 5.8663141\n",
      " 4.80502142 4.92121899 4.62088887 3.93574252]\n",
      "##########\n",
      "epoch:10 step:9401 [D loss: 0.638245, acc.: 60.94%] [G loss: 0.539411]\n",
      "epoch:10 step:9402 [D loss: 0.522085, acc.: 72.66%] [G loss: 0.611052]\n",
      "epoch:10 step:9403 [D loss: 0.620651, acc.: 67.97%] [G loss: 0.550741]\n",
      "epoch:10 step:9404 [D loss: 0.564258, acc.: 69.53%] [G loss: 0.515434]\n",
      "epoch:10 step:9405 [D loss: 0.556193, acc.: 69.53%] [G loss: 0.603105]\n",
      "epoch:10 step:9406 [D loss: 0.522969, acc.: 74.22%] [G loss: 0.800294]\n",
      "epoch:10 step:9407 [D loss: 0.504304, acc.: 75.78%] [G loss: 0.696548]\n",
      "epoch:10 step:9408 [D loss: 0.595001, acc.: 67.19%] [G loss: 0.538799]\n",
      "epoch:10 step:9409 [D loss: 0.572003, acc.: 70.31%] [G loss: 0.442676]\n",
      "epoch:10 step:9410 [D loss: 0.450096, acc.: 79.69%] [G loss: 0.750602]\n",
      "epoch:10 step:9411 [D loss: 0.570200, acc.: 67.19%] [G loss: 0.590131]\n",
      "epoch:10 step:9412 [D loss: 0.536430, acc.: 75.00%] [G loss: 0.535439]\n",
      "epoch:10 step:9413 [D loss: 0.498951, acc.: 73.44%] [G loss: 0.564532]\n",
      "epoch:10 step:9414 [D loss: 0.581868, acc.: 65.62%] [G loss: 0.462917]\n",
      "epoch:10 step:9415 [D loss: 0.547602, acc.: 70.31%] [G loss: 0.487935]\n",
      "epoch:10 step:9416 [D loss: 0.508681, acc.: 72.66%] [G loss: 0.677724]\n",
      "epoch:10 step:9417 [D loss: 0.522682, acc.: 75.00%] [G loss: 0.535396]\n",
      "epoch:10 step:9418 [D loss: 0.552499, acc.: 69.53%] [G loss: 0.542231]\n",
      "epoch:10 step:9419 [D loss: 0.557685, acc.: 71.09%] [G loss: 0.598702]\n",
      "epoch:10 step:9420 [D loss: 0.535177, acc.: 71.88%] [G loss: 0.563545]\n",
      "epoch:10 step:9421 [D loss: 0.620905, acc.: 67.19%] [G loss: 0.450490]\n",
      "epoch:10 step:9422 [D loss: 0.572019, acc.: 69.53%] [G loss: 0.531131]\n",
      "epoch:10 step:9423 [D loss: 0.534006, acc.: 72.66%] [G loss: 0.514636]\n",
      "epoch:10 step:9424 [D loss: 0.456409, acc.: 80.47%] [G loss: 0.687278]\n",
      "epoch:10 step:9425 [D loss: 0.543714, acc.: 71.88%] [G loss: 0.585122]\n",
      "epoch:10 step:9426 [D loss: 0.551958, acc.: 68.75%] [G loss: 0.692745]\n",
      "epoch:10 step:9427 [D loss: 0.524257, acc.: 71.09%] [G loss: 0.648140]\n",
      "epoch:10 step:9428 [D loss: 0.572044, acc.: 67.97%] [G loss: 0.595833]\n",
      "epoch:10 step:9429 [D loss: 0.533545, acc.: 71.09%] [G loss: 0.697496]\n",
      "epoch:10 step:9430 [D loss: 0.544357, acc.: 69.53%] [G loss: 0.593627]\n",
      "epoch:10 step:9431 [D loss: 0.566998, acc.: 68.75%] [G loss: 0.640026]\n",
      "epoch:10 step:9432 [D loss: 0.565580, acc.: 71.88%] [G loss: 0.601070]\n",
      "epoch:10 step:9433 [D loss: 0.591020, acc.: 62.50%] [G loss: 0.464451]\n",
      "epoch:10 step:9434 [D loss: 0.544363, acc.: 71.09%] [G loss: 0.525940]\n",
      "epoch:10 step:9435 [D loss: 0.529724, acc.: 74.22%] [G loss: 0.564725]\n",
      "epoch:10 step:9436 [D loss: 0.483757, acc.: 78.91%] [G loss: 0.551865]\n",
      "epoch:10 step:9437 [D loss: 0.600349, acc.: 67.97%] [G loss: 0.415018]\n",
      "epoch:10 step:9438 [D loss: 0.534933, acc.: 71.09%] [G loss: 0.516302]\n",
      "epoch:10 step:9439 [D loss: 0.557365, acc.: 68.75%] [G loss: 0.536652]\n",
      "epoch:10 step:9440 [D loss: 0.553839, acc.: 74.22%] [G loss: 0.559639]\n",
      "epoch:10 step:9441 [D loss: 0.539902, acc.: 71.09%] [G loss: 0.651278]\n",
      "epoch:10 step:9442 [D loss: 0.554842, acc.: 66.41%] [G loss: 0.507511]\n",
      "epoch:10 step:9443 [D loss: 0.554586, acc.: 70.31%] [G loss: 0.547686]\n",
      "epoch:10 step:9444 [D loss: 0.490200, acc.: 77.34%] [G loss: 0.590235]\n",
      "epoch:10 step:9445 [D loss: 0.594117, acc.: 66.41%] [G loss: 0.559735]\n",
      "epoch:10 step:9446 [D loss: 0.537830, acc.: 67.19%] [G loss: 0.542522]\n",
      "epoch:10 step:9447 [D loss: 0.452023, acc.: 79.69%] [G loss: 0.642581]\n",
      "epoch:10 step:9448 [D loss: 0.551641, acc.: 71.88%] [G loss: 0.558604]\n",
      "epoch:10 step:9449 [D loss: 0.541586, acc.: 71.09%] [G loss: 0.542474]\n",
      "epoch:10 step:9450 [D loss: 0.558324, acc.: 67.19%] [G loss: 0.483264]\n",
      "epoch:10 step:9451 [D loss: 0.529194, acc.: 73.44%] [G loss: 0.504951]\n",
      "epoch:10 step:9452 [D loss: 0.558098, acc.: 68.75%] [G loss: 0.501129]\n",
      "epoch:10 step:9453 [D loss: 0.486406, acc.: 78.91%] [G loss: 0.592342]\n",
      "epoch:10 step:9454 [D loss: 0.527860, acc.: 73.44%] [G loss: 0.606672]\n",
      "epoch:10 step:9455 [D loss: 0.590175, acc.: 67.97%] [G loss: 0.525315]\n",
      "epoch:10 step:9456 [D loss: 0.560476, acc.: 71.09%] [G loss: 0.452375]\n",
      "epoch:10 step:9457 [D loss: 0.559719, acc.: 70.31%] [G loss: 0.629007]\n",
      "epoch:10 step:9458 [D loss: 0.499512, acc.: 75.78%] [G loss: 0.552276]\n",
      "epoch:10 step:9459 [D loss: 0.494272, acc.: 75.78%] [G loss: 0.637442]\n",
      "epoch:10 step:9460 [D loss: 0.549300, acc.: 71.09%] [G loss: 0.641954]\n",
      "epoch:10 step:9461 [D loss: 0.545771, acc.: 72.66%] [G loss: 0.618974]\n",
      "epoch:10 step:9462 [D loss: 0.460689, acc.: 79.69%] [G loss: 0.715469]\n",
      "epoch:10 step:9463 [D loss: 0.528957, acc.: 70.31%] [G loss: 0.675542]\n",
      "epoch:10 step:9464 [D loss: 0.567060, acc.: 67.97%] [G loss: 0.750517]\n",
      "epoch:10 step:9465 [D loss: 0.505698, acc.: 68.75%] [G loss: 0.564349]\n",
      "epoch:10 step:9466 [D loss: 0.507705, acc.: 73.44%] [G loss: 0.471458]\n",
      "epoch:10 step:9467 [D loss: 0.578515, acc.: 67.97%] [G loss: 0.593380]\n",
      "epoch:10 step:9468 [D loss: 0.582469, acc.: 67.97%] [G loss: 0.552309]\n",
      "epoch:10 step:9469 [D loss: 0.553557, acc.: 70.31%] [G loss: 0.674813]\n",
      "epoch:10 step:9470 [D loss: 0.503902, acc.: 77.34%] [G loss: 0.585082]\n",
      "epoch:10 step:9471 [D loss: 0.541810, acc.: 69.53%] [G loss: 0.616745]\n",
      "epoch:10 step:9472 [D loss: 0.627828, acc.: 67.19%] [G loss: 0.540062]\n",
      "epoch:10 step:9473 [D loss: 0.512937, acc.: 69.53%] [G loss: 0.515048]\n",
      "epoch:10 step:9474 [D loss: 0.515532, acc.: 71.88%] [G loss: 0.604389]\n",
      "epoch:10 step:9475 [D loss: 0.570390, acc.: 63.28%] [G loss: 0.475653]\n",
      "epoch:10 step:9476 [D loss: 0.517177, acc.: 72.66%] [G loss: 0.531301]\n",
      "epoch:10 step:9477 [D loss: 0.601350, acc.: 72.66%] [G loss: 0.555323]\n",
      "epoch:10 step:9478 [D loss: 0.653522, acc.: 57.03%] [G loss: 0.662201]\n",
      "epoch:10 step:9479 [D loss: 0.581703, acc.: 67.97%] [G loss: 0.600915]\n",
      "epoch:10 step:9480 [D loss: 0.560050, acc.: 68.75%] [G loss: 0.611910]\n",
      "epoch:10 step:9481 [D loss: 0.536132, acc.: 71.09%] [G loss: 0.485338]\n",
      "epoch:10 step:9482 [D loss: 0.515172, acc.: 71.88%] [G loss: 0.581930]\n",
      "epoch:10 step:9483 [D loss: 0.554406, acc.: 69.53%] [G loss: 0.425899]\n",
      "epoch:10 step:9484 [D loss: 0.563818, acc.: 72.66%] [G loss: 0.629291]\n",
      "epoch:10 step:9485 [D loss: 0.581408, acc.: 65.62%] [G loss: 0.645415]\n",
      "epoch:10 step:9486 [D loss: 0.488697, acc.: 73.44%] [G loss: 0.709222]\n",
      "epoch:10 step:9487 [D loss: 0.520080, acc.: 67.97%] [G loss: 0.525154]\n",
      "epoch:10 step:9488 [D loss: 0.574934, acc.: 67.19%] [G loss: 0.570609]\n",
      "epoch:10 step:9489 [D loss: 0.450097, acc.: 78.91%] [G loss: 0.889469]\n",
      "epoch:10 step:9490 [D loss: 0.641347, acc.: 64.84%] [G loss: 0.653276]\n",
      "epoch:10 step:9491 [D loss: 0.528990, acc.: 74.22%] [G loss: 0.744557]\n",
      "epoch:10 step:9492 [D loss: 0.480168, acc.: 79.69%] [G loss: 0.749991]\n",
      "epoch:10 step:9493 [D loss: 0.505974, acc.: 78.12%] [G loss: 0.634811]\n",
      "epoch:10 step:9494 [D loss: 0.694983, acc.: 64.06%] [G loss: 0.644752]\n",
      "epoch:10 step:9495 [D loss: 0.589281, acc.: 67.19%] [G loss: 0.529285]\n",
      "epoch:10 step:9496 [D loss: 0.499317, acc.: 78.91%] [G loss: 0.541272]\n",
      "epoch:10 step:9497 [D loss: 0.526046, acc.: 70.31%] [G loss: 0.507975]\n",
      "epoch:10 step:9498 [D loss: 0.486716, acc.: 74.22%] [G loss: 0.658122]\n",
      "epoch:10 step:9499 [D loss: 0.640309, acc.: 60.16%] [G loss: 0.416808]\n",
      "epoch:10 step:9500 [D loss: 0.558950, acc.: 65.62%] [G loss: 0.477559]\n",
      "epoch:10 step:9501 [D loss: 0.513105, acc.: 71.88%] [G loss: 0.649196]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9502 [D loss: 0.535667, acc.: 78.12%] [G loss: 0.600837]\n",
      "epoch:10 step:9503 [D loss: 0.627895, acc.: 67.19%] [G loss: 0.579190]\n",
      "epoch:10 step:9504 [D loss: 0.533362, acc.: 70.31%] [G loss: 0.504585]\n",
      "epoch:10 step:9505 [D loss: 0.524082, acc.: 75.00%] [G loss: 0.620065]\n",
      "epoch:10 step:9506 [D loss: 0.547884, acc.: 71.09%] [G loss: 0.620269]\n",
      "epoch:10 step:9507 [D loss: 0.593777, acc.: 65.62%] [G loss: 0.402819]\n",
      "epoch:10 step:9508 [D loss: 0.588504, acc.: 64.06%] [G loss: 0.513852]\n",
      "epoch:10 step:9509 [D loss: 0.625942, acc.: 66.41%] [G loss: 0.622515]\n",
      "epoch:10 step:9510 [D loss: 0.612522, acc.: 64.84%] [G loss: 0.463879]\n",
      "epoch:10 step:9511 [D loss: 0.517926, acc.: 73.44%] [G loss: 0.476740]\n",
      "epoch:10 step:9512 [D loss: 0.559156, acc.: 64.84%] [G loss: 0.458441]\n",
      "epoch:10 step:9513 [D loss: 0.562929, acc.: 67.19%] [G loss: 0.453760]\n",
      "epoch:10 step:9514 [D loss: 0.559615, acc.: 69.53%] [G loss: 0.611895]\n",
      "epoch:10 step:9515 [D loss: 0.532621, acc.: 72.66%] [G loss: 0.660697]\n",
      "epoch:10 step:9516 [D loss: 0.521243, acc.: 73.44%] [G loss: 0.603613]\n",
      "epoch:10 step:9517 [D loss: 0.627648, acc.: 64.06%] [G loss: 0.428605]\n",
      "epoch:10 step:9518 [D loss: 0.555880, acc.: 75.00%] [G loss: 0.614094]\n",
      "epoch:10 step:9519 [D loss: 0.488786, acc.: 79.69%] [G loss: 0.671400]\n",
      "epoch:10 step:9520 [D loss: 0.564679, acc.: 67.97%] [G loss: 0.460232]\n",
      "epoch:10 step:9521 [D loss: 0.591105, acc.: 64.06%] [G loss: 0.515795]\n",
      "epoch:10 step:9522 [D loss: 0.453391, acc.: 77.34%] [G loss: 0.589950]\n",
      "epoch:10 step:9523 [D loss: 0.638536, acc.: 60.94%] [G loss: 0.496460]\n",
      "epoch:10 step:9524 [D loss: 0.463780, acc.: 80.47%] [G loss: 0.591224]\n",
      "epoch:10 step:9525 [D loss: 0.463584, acc.: 79.69%] [G loss: 0.618461]\n",
      "epoch:10 step:9526 [D loss: 0.515425, acc.: 75.78%] [G loss: 0.681942]\n",
      "epoch:10 step:9527 [D loss: 0.533086, acc.: 68.75%] [G loss: 0.630383]\n",
      "epoch:10 step:9528 [D loss: 0.596202, acc.: 66.41%] [G loss: 0.500638]\n",
      "epoch:10 step:9529 [D loss: 0.546116, acc.: 71.09%] [G loss: 0.472332]\n",
      "epoch:10 step:9530 [D loss: 0.635201, acc.: 61.72%] [G loss: 0.562868]\n",
      "epoch:10 step:9531 [D loss: 0.577232, acc.: 67.97%] [G loss: 0.620989]\n",
      "epoch:10 step:9532 [D loss: 0.432449, acc.: 79.69%] [G loss: 0.560143]\n",
      "epoch:10 step:9533 [D loss: 0.519820, acc.: 74.22%] [G loss: 0.669630]\n",
      "epoch:10 step:9534 [D loss: 0.538255, acc.: 71.88%] [G loss: 0.657043]\n",
      "epoch:10 step:9535 [D loss: 0.543392, acc.: 71.09%] [G loss: 0.536923]\n",
      "epoch:10 step:9536 [D loss: 0.576561, acc.: 64.84%] [G loss: 0.612385]\n",
      "epoch:10 step:9537 [D loss: 0.537701, acc.: 72.66%] [G loss: 0.591380]\n",
      "epoch:10 step:9538 [D loss: 0.560678, acc.: 69.53%] [G loss: 0.516858]\n",
      "epoch:10 step:9539 [D loss: 0.612174, acc.: 67.97%] [G loss: 0.547090]\n",
      "epoch:10 step:9540 [D loss: 0.523582, acc.: 72.66%] [G loss: 0.434630]\n",
      "epoch:10 step:9541 [D loss: 0.533594, acc.: 71.88%] [G loss: 0.665530]\n",
      "epoch:10 step:9542 [D loss: 0.539909, acc.: 69.53%] [G loss: 0.627488]\n",
      "epoch:10 step:9543 [D loss: 0.528829, acc.: 74.22%] [G loss: 0.594526]\n",
      "epoch:10 step:9544 [D loss: 0.589988, acc.: 65.62%] [G loss: 0.577187]\n",
      "epoch:10 step:9545 [D loss: 0.594592, acc.: 65.62%] [G loss: 0.451738]\n",
      "epoch:10 step:9546 [D loss: 0.544482, acc.: 71.09%] [G loss: 0.527327]\n",
      "epoch:10 step:9547 [D loss: 0.543027, acc.: 71.88%] [G loss: 0.622897]\n",
      "epoch:10 step:9548 [D loss: 0.546652, acc.: 69.53%] [G loss: 0.527089]\n",
      "epoch:10 step:9549 [D loss: 0.522287, acc.: 72.66%] [G loss: 0.534556]\n",
      "epoch:10 step:9550 [D loss: 0.625391, acc.: 60.94%] [G loss: 0.415464]\n",
      "epoch:10 step:9551 [D loss: 0.649941, acc.: 60.94%] [G loss: 0.336608]\n",
      "epoch:10 step:9552 [D loss: 0.527461, acc.: 73.44%] [G loss: 0.632742]\n",
      "epoch:10 step:9553 [D loss: 0.600922, acc.: 71.88%] [G loss: 0.495216]\n",
      "epoch:10 step:9554 [D loss: 0.563397, acc.: 68.75%] [G loss: 0.647035]\n",
      "epoch:10 step:9555 [D loss: 0.594082, acc.: 61.72%] [G loss: 0.586817]\n",
      "epoch:10 step:9556 [D loss: 0.568425, acc.: 71.88%] [G loss: 0.519183]\n",
      "epoch:10 step:9557 [D loss: 0.628810, acc.: 61.72%] [G loss: 0.459301]\n",
      "epoch:10 step:9558 [D loss: 0.527046, acc.: 67.19%] [G loss: 0.478681]\n",
      "epoch:10 step:9559 [D loss: 0.564828, acc.: 70.31%] [G loss: 0.482879]\n",
      "epoch:10 step:9560 [D loss: 0.490977, acc.: 78.12%] [G loss: 0.516685]\n",
      "epoch:10 step:9561 [D loss: 0.498244, acc.: 75.00%] [G loss: 0.556615]\n",
      "epoch:10 step:9562 [D loss: 0.559209, acc.: 68.75%] [G loss: 0.485140]\n",
      "epoch:10 step:9563 [D loss: 0.533488, acc.: 73.44%] [G loss: 0.433216]\n",
      "epoch:10 step:9564 [D loss: 0.499745, acc.: 75.00%] [G loss: 0.504829]\n",
      "epoch:10 step:9565 [D loss: 0.519132, acc.: 75.00%] [G loss: 0.598206]\n",
      "epoch:10 step:9566 [D loss: 0.566869, acc.: 66.41%] [G loss: 0.509534]\n",
      "epoch:10 step:9567 [D loss: 0.615759, acc.: 66.41%] [G loss: 0.628800]\n",
      "epoch:10 step:9568 [D loss: 0.506275, acc.: 71.88%] [G loss: 0.788716]\n",
      "epoch:10 step:9569 [D loss: 0.554922, acc.: 67.97%] [G loss: 0.458139]\n",
      "epoch:10 step:9570 [D loss: 0.629331, acc.: 60.94%] [G loss: 0.465076]\n",
      "epoch:10 step:9571 [D loss: 0.576656, acc.: 66.41%] [G loss: 0.551003]\n",
      "epoch:10 step:9572 [D loss: 0.563749, acc.: 66.41%] [G loss: 0.509447]\n",
      "epoch:10 step:9573 [D loss: 0.578102, acc.: 71.88%] [G loss: 0.539353]\n",
      "epoch:10 step:9574 [D loss: 0.599374, acc.: 66.41%] [G loss: 0.596135]\n",
      "epoch:10 step:9575 [D loss: 0.539048, acc.: 71.09%] [G loss: 0.438498]\n",
      "epoch:10 step:9576 [D loss: 0.456194, acc.: 77.34%] [G loss: 0.640312]\n",
      "epoch:10 step:9577 [D loss: 0.470614, acc.: 78.12%] [G loss: 0.755129]\n",
      "epoch:10 step:9578 [D loss: 0.467419, acc.: 77.34%] [G loss: 0.852892]\n",
      "epoch:10 step:9579 [D loss: 0.477353, acc.: 75.00%] [G loss: 0.732061]\n",
      "epoch:10 step:9580 [D loss: 0.626477, acc.: 64.84%] [G loss: 0.500442]\n",
      "epoch:10 step:9581 [D loss: 0.597859, acc.: 64.84%] [G loss: 0.445814]\n",
      "epoch:10 step:9582 [D loss: 0.539108, acc.: 71.88%] [G loss: 0.434840]\n",
      "epoch:10 step:9583 [D loss: 0.500942, acc.: 70.31%] [G loss: 0.707832]\n",
      "epoch:10 step:9584 [D loss: 0.598388, acc.: 66.41%] [G loss: 0.506746]\n",
      "epoch:10 step:9585 [D loss: 0.636402, acc.: 64.84%] [G loss: 0.474295]\n",
      "epoch:10 step:9586 [D loss: 0.535023, acc.: 74.22%] [G loss: 0.568449]\n",
      "epoch:10 step:9587 [D loss: 0.506758, acc.: 80.47%] [G loss: 0.651663]\n",
      "epoch:10 step:9588 [D loss: 0.554515, acc.: 67.19%] [G loss: 0.415571]\n",
      "epoch:10 step:9589 [D loss: 0.486121, acc.: 78.12%] [G loss: 0.708846]\n",
      "epoch:10 step:9590 [D loss: 0.602031, acc.: 67.97%] [G loss: 0.528571]\n",
      "epoch:10 step:9591 [D loss: 0.493835, acc.: 72.66%] [G loss: 0.649253]\n",
      "epoch:10 step:9592 [D loss: 0.512435, acc.: 75.00%] [G loss: 0.756640]\n",
      "epoch:10 step:9593 [D loss: 0.484658, acc.: 74.22%] [G loss: 0.719986]\n",
      "epoch:10 step:9594 [D loss: 0.645991, acc.: 67.19%] [G loss: 0.410069]\n",
      "epoch:10 step:9595 [D loss: 0.556822, acc.: 65.62%] [G loss: 0.609411]\n",
      "epoch:10 step:9596 [D loss: 0.571788, acc.: 66.41%] [G loss: 0.420845]\n",
      "epoch:10 step:9597 [D loss: 0.588531, acc.: 64.84%] [G loss: 0.579967]\n",
      "epoch:10 step:9598 [D loss: 0.591709, acc.: 64.84%] [G loss: 0.407105]\n",
      "epoch:10 step:9599 [D loss: 0.587011, acc.: 64.06%] [G loss: 0.493870]\n",
      "epoch:10 step:9600 [D loss: 0.516231, acc.: 73.44%] [G loss: 0.652454]\n",
      "##############\n",
      "[3.29579291 1.45586829 6.29647738 5.01276199 3.8512316  6.03765609\n",
      " 4.94974603 4.7637069  4.72108699 4.00235292]\n",
      "##########\n",
      "epoch:10 step:9601 [D loss: 0.475405, acc.: 75.00%] [G loss: 0.734525]\n",
      "epoch:10 step:9602 [D loss: 0.514767, acc.: 74.22%] [G loss: 0.770927]\n",
      "epoch:10 step:9603 [D loss: 0.606396, acc.: 68.75%] [G loss: 0.788435]\n",
      "epoch:10 step:9604 [D loss: 0.555044, acc.: 71.88%] [G loss: 0.672408]\n",
      "epoch:10 step:9605 [D loss: 0.555963, acc.: 66.41%] [G loss: 0.594134]\n",
      "epoch:10 step:9606 [D loss: 0.526748, acc.: 73.44%] [G loss: 0.549579]\n",
      "epoch:10 step:9607 [D loss: 0.506843, acc.: 71.09%] [G loss: 0.593474]\n",
      "epoch:10 step:9608 [D loss: 0.555677, acc.: 74.22%] [G loss: 0.584164]\n",
      "epoch:10 step:9609 [D loss: 0.518706, acc.: 70.31%] [G loss: 0.576410]\n",
      "epoch:10 step:9610 [D loss: 0.554501, acc.: 74.22%] [G loss: 0.526064]\n",
      "epoch:10 step:9611 [D loss: 0.551055, acc.: 70.31%] [G loss: 0.491870]\n",
      "epoch:10 step:9612 [D loss: 0.508047, acc.: 75.78%] [G loss: 0.606927]\n",
      "epoch:10 step:9613 [D loss: 0.575115, acc.: 64.84%] [G loss: 0.651811]\n",
      "epoch:10 step:9614 [D loss: 0.524322, acc.: 69.53%] [G loss: 0.583626]\n",
      "epoch:10 step:9615 [D loss: 0.515745, acc.: 75.00%] [G loss: 0.674036]\n",
      "epoch:10 step:9616 [D loss: 0.515817, acc.: 73.44%] [G loss: 0.643222]\n",
      "epoch:10 step:9617 [D loss: 0.519595, acc.: 71.88%] [G loss: 0.561348]\n",
      "epoch:10 step:9618 [D loss: 0.490950, acc.: 76.56%] [G loss: 0.672296]\n",
      "epoch:10 step:9619 [D loss: 0.602388, acc.: 66.41%] [G loss: 0.681822]\n",
      "epoch:10 step:9620 [D loss: 0.587942, acc.: 64.06%] [G loss: 0.605536]\n",
      "epoch:10 step:9621 [D loss: 0.619726, acc.: 60.94%] [G loss: 0.512327]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9622 [D loss: 0.565063, acc.: 70.31%] [G loss: 0.464211]\n",
      "epoch:10 step:9623 [D loss: 0.528039, acc.: 77.34%] [G loss: 0.512046]\n",
      "epoch:10 step:9624 [D loss: 0.495421, acc.: 75.78%] [G loss: 0.632978]\n",
      "epoch:10 step:9625 [D loss: 0.506922, acc.: 75.78%] [G loss: 0.552773]\n",
      "epoch:10 step:9626 [D loss: 0.564457, acc.: 67.97%] [G loss: 0.683628]\n",
      "epoch:10 step:9627 [D loss: 0.519074, acc.: 74.22%] [G loss: 0.560059]\n",
      "epoch:10 step:9628 [D loss: 0.516099, acc.: 71.09%] [G loss: 0.587383]\n",
      "epoch:10 step:9629 [D loss: 0.554036, acc.: 65.62%] [G loss: 0.517345]\n",
      "epoch:10 step:9630 [D loss: 0.558707, acc.: 66.41%] [G loss: 0.613819]\n",
      "epoch:10 step:9631 [D loss: 0.608348, acc.: 64.84%] [G loss: 0.587621]\n",
      "epoch:10 step:9632 [D loss: 0.601792, acc.: 66.41%] [G loss: 0.648117]\n",
      "epoch:10 step:9633 [D loss: 0.647188, acc.: 66.41%] [G loss: 0.691168]\n",
      "epoch:10 step:9634 [D loss: 0.507968, acc.: 74.22%] [G loss: 0.665138]\n",
      "epoch:10 step:9635 [D loss: 0.640332, acc.: 67.19%] [G loss: 0.541569]\n",
      "epoch:10 step:9636 [D loss: 0.593390, acc.: 67.97%] [G loss: 0.504102]\n",
      "epoch:10 step:9637 [D loss: 0.559281, acc.: 70.31%] [G loss: 0.575300]\n",
      "epoch:10 step:9638 [D loss: 0.582956, acc.: 68.75%] [G loss: 0.623942]\n",
      "epoch:10 step:9639 [D loss: 0.556882, acc.: 68.75%] [G loss: 0.514568]\n",
      "epoch:10 step:9640 [D loss: 0.534832, acc.: 71.88%] [G loss: 0.538898]\n",
      "epoch:10 step:9641 [D loss: 0.505677, acc.: 72.66%] [G loss: 0.498089]\n",
      "epoch:10 step:9642 [D loss: 0.559738, acc.: 64.84%] [G loss: 0.462121]\n",
      "epoch:10 step:9643 [D loss: 0.517741, acc.: 69.53%] [G loss: 0.535376]\n",
      "epoch:10 step:9644 [D loss: 0.567583, acc.: 70.31%] [G loss: 0.560957]\n",
      "epoch:10 step:9645 [D loss: 0.587834, acc.: 69.53%] [G loss: 0.491727]\n",
      "epoch:10 step:9646 [D loss: 0.550587, acc.: 71.88%] [G loss: 0.524367]\n",
      "epoch:10 step:9647 [D loss: 0.642448, acc.: 63.28%] [G loss: 0.507926]\n",
      "epoch:10 step:9648 [D loss: 0.642728, acc.: 61.72%] [G loss: 0.361406]\n",
      "epoch:10 step:9649 [D loss: 0.562435, acc.: 67.97%] [G loss: 0.434715]\n",
      "epoch:10 step:9650 [D loss: 0.531013, acc.: 78.12%] [G loss: 0.531095]\n",
      "epoch:10 step:9651 [D loss: 0.586138, acc.: 69.53%] [G loss: 0.638445]\n",
      "epoch:10 step:9652 [D loss: 0.540603, acc.: 68.75%] [G loss: 0.554255]\n",
      "epoch:10 step:9653 [D loss: 0.484123, acc.: 79.69%] [G loss: 0.565152]\n",
      "epoch:10 step:9654 [D loss: 0.507238, acc.: 71.88%] [G loss: 0.535211]\n",
      "epoch:10 step:9655 [D loss: 0.515268, acc.: 73.44%] [G loss: 0.557174]\n",
      "epoch:10 step:9656 [D loss: 0.530773, acc.: 70.31%] [G loss: 0.681878]\n",
      "epoch:10 step:9657 [D loss: 0.579690, acc.: 67.97%] [G loss: 0.564934]\n",
      "epoch:10 step:9658 [D loss: 0.588560, acc.: 65.62%] [G loss: 0.576709]\n",
      "epoch:10 step:9659 [D loss: 0.529100, acc.: 71.88%] [G loss: 0.550683]\n",
      "epoch:10 step:9660 [D loss: 0.537333, acc.: 71.09%] [G loss: 0.575841]\n",
      "epoch:10 step:9661 [D loss: 0.585506, acc.: 66.41%] [G loss: 0.449581]\n",
      "epoch:10 step:9662 [D loss: 0.574364, acc.: 67.97%] [G loss: 0.562147]\n",
      "epoch:10 step:9663 [D loss: 0.563142, acc.: 70.31%] [G loss: 0.472174]\n",
      "epoch:10 step:9664 [D loss: 0.624979, acc.: 63.28%] [G loss: 0.463195]\n",
      "epoch:10 step:9665 [D loss: 0.542212, acc.: 71.09%] [G loss: 0.588273]\n",
      "epoch:10 step:9666 [D loss: 0.432982, acc.: 82.81%] [G loss: 0.539154]\n",
      "epoch:10 step:9667 [D loss: 0.586202, acc.: 67.19%] [G loss: 0.568503]\n",
      "epoch:10 step:9668 [D loss: 0.506414, acc.: 76.56%] [G loss: 0.565401]\n",
      "epoch:10 step:9669 [D loss: 0.480786, acc.: 73.44%] [G loss: 0.628014]\n",
      "epoch:10 step:9670 [D loss: 0.508106, acc.: 76.56%] [G loss: 0.550605]\n",
      "epoch:10 step:9671 [D loss: 0.623181, acc.: 67.19%] [G loss: 0.519192]\n",
      "epoch:10 step:9672 [D loss: 0.519466, acc.: 74.22%] [G loss: 0.522828]\n",
      "epoch:10 step:9673 [D loss: 0.567890, acc.: 71.09%] [G loss: 0.477444]\n",
      "epoch:10 step:9674 [D loss: 0.508695, acc.: 71.88%] [G loss: 0.678574]\n",
      "epoch:10 step:9675 [D loss: 0.541642, acc.: 70.31%] [G loss: 0.642247]\n",
      "epoch:10 step:9676 [D loss: 0.551376, acc.: 70.31%] [G loss: 0.548117]\n",
      "epoch:10 step:9677 [D loss: 0.544021, acc.: 75.00%] [G loss: 0.562742]\n",
      "epoch:10 step:9678 [D loss: 0.560238, acc.: 74.22%] [G loss: 0.634086]\n",
      "epoch:10 step:9679 [D loss: 0.494366, acc.: 71.09%] [G loss: 0.557713]\n",
      "epoch:10 step:9680 [D loss: 0.523863, acc.: 74.22%] [G loss: 0.639822]\n",
      "epoch:10 step:9681 [D loss: 0.472151, acc.: 77.34%] [G loss: 0.644752]\n",
      "epoch:10 step:9682 [D loss: 0.482647, acc.: 77.34%] [G loss: 0.770941]\n",
      "epoch:10 step:9683 [D loss: 0.498421, acc.: 77.34%] [G loss: 0.756889]\n",
      "epoch:10 step:9684 [D loss: 0.424747, acc.: 84.38%] [G loss: 0.881438]\n",
      "epoch:10 step:9685 [D loss: 0.468550, acc.: 78.91%] [G loss: 0.919008]\n",
      "epoch:10 step:9686 [D loss: 0.711112, acc.: 60.16%] [G loss: 0.600948]\n",
      "epoch:10 step:9687 [D loss: 0.578936, acc.: 66.41%] [G loss: 0.387331]\n",
      "epoch:10 step:9688 [D loss: 0.544136, acc.: 67.19%] [G loss: 0.491309]\n",
      "epoch:10 step:9689 [D loss: 0.567087, acc.: 66.41%] [G loss: 0.519389]\n",
      "epoch:10 step:9690 [D loss: 0.556510, acc.: 71.09%] [G loss: 0.512052]\n",
      "epoch:10 step:9691 [D loss: 0.505224, acc.: 77.34%] [G loss: 0.692409]\n",
      "epoch:10 step:9692 [D loss: 0.573328, acc.: 71.09%] [G loss: 0.553274]\n",
      "epoch:10 step:9693 [D loss: 0.605273, acc.: 67.19%] [G loss: 0.433629]\n",
      "epoch:10 step:9694 [D loss: 0.597735, acc.: 69.53%] [G loss: 0.354166]\n",
      "epoch:10 step:9695 [D loss: 0.570365, acc.: 69.53%] [G loss: 0.475605]\n",
      "epoch:10 step:9696 [D loss: 0.490481, acc.: 77.34%] [G loss: 0.672399]\n",
      "epoch:10 step:9697 [D loss: 0.486581, acc.: 80.47%] [G loss: 0.565352]\n",
      "epoch:10 step:9698 [D loss: 0.483466, acc.: 74.22%] [G loss: 0.635404]\n",
      "epoch:10 step:9699 [D loss: 0.529547, acc.: 74.22%] [G loss: 0.507645]\n",
      "epoch:10 step:9700 [D loss: 0.576611, acc.: 64.84%] [G loss: 0.617589]\n",
      "epoch:10 step:9701 [D loss: 0.538253, acc.: 74.22%] [G loss: 0.496165]\n",
      "epoch:10 step:9702 [D loss: 0.544165, acc.: 71.09%] [G loss: 0.561187]\n",
      "epoch:10 step:9703 [D loss: 0.493465, acc.: 75.00%] [G loss: 0.590624]\n",
      "epoch:10 step:9704 [D loss: 0.569586, acc.: 71.09%] [G loss: 0.532952]\n",
      "epoch:10 step:9705 [D loss: 0.496457, acc.: 75.78%] [G loss: 0.738592]\n",
      "epoch:10 step:9706 [D loss: 0.530584, acc.: 68.75%] [G loss: 0.608651]\n",
      "epoch:10 step:9707 [D loss: 0.500300, acc.: 75.78%] [G loss: 0.563118]\n",
      "epoch:10 step:9708 [D loss: 0.557645, acc.: 65.62%] [G loss: 0.673935]\n",
      "epoch:10 step:9709 [D loss: 0.573228, acc.: 73.44%] [G loss: 0.607296]\n",
      "epoch:10 step:9710 [D loss: 0.486216, acc.: 77.34%] [G loss: 0.690010]\n",
      "epoch:10 step:9711 [D loss: 0.627157, acc.: 67.19%] [G loss: 0.690223]\n",
      "epoch:10 step:9712 [D loss: 0.620185, acc.: 63.28%] [G loss: 0.466932]\n",
      "epoch:10 step:9713 [D loss: 0.487282, acc.: 78.12%] [G loss: 0.488817]\n",
      "epoch:10 step:9714 [D loss: 0.489591, acc.: 76.56%] [G loss: 0.767142]\n",
      "epoch:10 step:9715 [D loss: 0.541045, acc.: 69.53%] [G loss: 0.770323]\n",
      "epoch:10 step:9716 [D loss: 0.529512, acc.: 73.44%] [G loss: 0.839171]\n",
      "epoch:10 step:9717 [D loss: 0.469885, acc.: 80.47%] [G loss: 1.038591]\n",
      "epoch:10 step:9718 [D loss: 0.642515, acc.: 67.19%] [G loss: 0.779928]\n",
      "epoch:10 step:9719 [D loss: 0.765848, acc.: 52.34%] [G loss: 0.433598]\n",
      "epoch:10 step:9720 [D loss: 0.493382, acc.: 75.78%] [G loss: 0.516832]\n",
      "epoch:10 step:9721 [D loss: 0.572780, acc.: 66.41%] [G loss: 0.747287]\n",
      "epoch:10 step:9722 [D loss: 0.549758, acc.: 71.88%] [G loss: 0.698092]\n",
      "epoch:10 step:9723 [D loss: 0.567964, acc.: 68.75%] [G loss: 0.636005]\n",
      "epoch:10 step:9724 [D loss: 0.431092, acc.: 81.25%] [G loss: 0.686985]\n",
      "epoch:10 step:9725 [D loss: 0.562187, acc.: 67.19%] [G loss: 0.804571]\n",
      "epoch:10 step:9726 [D loss: 0.602135, acc.: 69.53%] [G loss: 0.542757]\n",
      "epoch:10 step:9727 [D loss: 0.500884, acc.: 75.00%] [G loss: 0.544086]\n",
      "epoch:10 step:9728 [D loss: 0.445578, acc.: 81.25%] [G loss: 0.707706]\n",
      "epoch:10 step:9729 [D loss: 0.494232, acc.: 71.88%] [G loss: 0.701877]\n",
      "epoch:10 step:9730 [D loss: 0.488484, acc.: 71.09%] [G loss: 0.618442]\n",
      "epoch:10 step:9731 [D loss: 0.533676, acc.: 74.22%] [G loss: 0.767288]\n",
      "epoch:10 step:9732 [D loss: 0.507053, acc.: 76.56%] [G loss: 0.618868]\n",
      "epoch:10 step:9733 [D loss: 0.587779, acc.: 70.31%] [G loss: 0.555496]\n",
      "epoch:10 step:9734 [D loss: 0.524327, acc.: 71.09%] [G loss: 0.612112]\n",
      "epoch:10 step:9735 [D loss: 0.568943, acc.: 66.41%] [G loss: 0.633699]\n",
      "epoch:10 step:9736 [D loss: 0.527154, acc.: 73.44%] [G loss: 0.609433]\n",
      "epoch:10 step:9737 [D loss: 0.614737, acc.: 67.19%] [G loss: 0.594625]\n",
      "epoch:10 step:9738 [D loss: 0.541839, acc.: 73.44%] [G loss: 0.614474]\n",
      "epoch:10 step:9739 [D loss: 0.571667, acc.: 71.09%] [G loss: 0.621129]\n",
      "epoch:10 step:9740 [D loss: 0.519000, acc.: 74.22%] [G loss: 0.592530]\n",
      "epoch:10 step:9741 [D loss: 0.530337, acc.: 74.22%] [G loss: 0.568038]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9742 [D loss: 0.542135, acc.: 73.44%] [G loss: 0.617742]\n",
      "epoch:10 step:9743 [D loss: 0.511032, acc.: 73.44%] [G loss: 0.690195]\n",
      "epoch:10 step:9744 [D loss: 0.536072, acc.: 69.53%] [G loss: 0.637431]\n",
      "epoch:10 step:9745 [D loss: 0.545870, acc.: 74.22%] [G loss: 0.546445]\n",
      "epoch:10 step:9746 [D loss: 0.745382, acc.: 55.47%] [G loss: 0.418169]\n",
      "epoch:10 step:9747 [D loss: 0.570500, acc.: 69.53%] [G loss: 0.543354]\n",
      "epoch:10 step:9748 [D loss: 0.526249, acc.: 67.19%] [G loss: 0.671054]\n",
      "epoch:10 step:9749 [D loss: 0.584990, acc.: 66.41%] [G loss: 0.496281]\n",
      "epoch:10 step:9750 [D loss: 0.581004, acc.: 66.41%] [G loss: 0.459278]\n",
      "epoch:10 step:9751 [D loss: 0.486495, acc.: 75.00%] [G loss: 0.519004]\n",
      "epoch:10 step:9752 [D loss: 0.561469, acc.: 70.31%] [G loss: 0.587208]\n",
      "epoch:10 step:9753 [D loss: 0.581333, acc.: 68.75%] [G loss: 0.482444]\n",
      "epoch:10 step:9754 [D loss: 0.594432, acc.: 60.16%] [G loss: 0.450724]\n",
      "epoch:10 step:9755 [D loss: 0.536599, acc.: 74.22%] [G loss: 0.483200]\n",
      "epoch:10 step:9756 [D loss: 0.636552, acc.: 62.50%] [G loss: 0.525812]\n",
      "epoch:10 step:9757 [D loss: 0.606969, acc.: 67.19%] [G loss: 0.411982]\n",
      "epoch:10 step:9758 [D loss: 0.568929, acc.: 72.66%] [G loss: 0.553844]\n",
      "epoch:10 step:9759 [D loss: 0.528835, acc.: 71.88%] [G loss: 0.582978]\n",
      "epoch:10 step:9760 [D loss: 0.596059, acc.: 67.19%] [G loss: 0.534877]\n",
      "epoch:10 step:9761 [D loss: 0.536140, acc.: 70.31%] [G loss: 0.528921]\n",
      "epoch:10 step:9762 [D loss: 0.524122, acc.: 69.53%] [G loss: 0.526015]\n",
      "epoch:10 step:9763 [D loss: 0.575331, acc.: 70.31%] [G loss: 0.621404]\n",
      "epoch:10 step:9764 [D loss: 0.570872, acc.: 70.31%] [G loss: 0.491203]\n",
      "epoch:10 step:9765 [D loss: 0.513083, acc.: 74.22%] [G loss: 0.542702]\n",
      "epoch:10 step:9766 [D loss: 0.601858, acc.: 65.62%] [G loss: 0.608901]\n",
      "epoch:10 step:9767 [D loss: 0.565433, acc.: 67.19%] [G loss: 0.560125]\n",
      "epoch:10 step:9768 [D loss: 0.515564, acc.: 73.44%] [G loss: 0.655536]\n",
      "epoch:10 step:9769 [D loss: 0.528438, acc.: 80.47%] [G loss: 0.622025]\n",
      "epoch:10 step:9770 [D loss: 0.615018, acc.: 60.94%] [G loss: 0.550501]\n",
      "epoch:10 step:9771 [D loss: 0.633424, acc.: 60.94%] [G loss: 0.456685]\n",
      "epoch:10 step:9772 [D loss: 0.525723, acc.: 73.44%] [G loss: 0.452528]\n",
      "epoch:10 step:9773 [D loss: 0.509663, acc.: 74.22%] [G loss: 0.596235]\n",
      "epoch:10 step:9774 [D loss: 0.634911, acc.: 67.97%] [G loss: 0.593679]\n",
      "epoch:10 step:9775 [D loss: 0.537610, acc.: 70.31%] [G loss: 0.512303]\n",
      "epoch:10 step:9776 [D loss: 0.509660, acc.: 71.09%] [G loss: 0.657595]\n",
      "epoch:10 step:9777 [D loss: 0.578267, acc.: 69.53%] [G loss: 0.681864]\n",
      "epoch:10 step:9778 [D loss: 0.568241, acc.: 66.41%] [G loss: 0.787524]\n",
      "epoch:10 step:9779 [D loss: 0.611073, acc.: 60.16%] [G loss: 0.610034]\n",
      "epoch:10 step:9780 [D loss: 0.585534, acc.: 64.84%] [G loss: 0.632654]\n",
      "epoch:10 step:9781 [D loss: 0.575181, acc.: 64.06%] [G loss: 0.586428]\n",
      "epoch:10 step:9782 [D loss: 0.599650, acc.: 63.28%] [G loss: 0.601310]\n",
      "epoch:10 step:9783 [D loss: 0.536245, acc.: 72.66%] [G loss: 0.527905]\n",
      "epoch:10 step:9784 [D loss: 0.526310, acc.: 75.00%] [G loss: 0.577015]\n",
      "epoch:10 step:9785 [D loss: 0.591645, acc.: 63.28%] [G loss: 0.696157]\n",
      "epoch:10 step:9786 [D loss: 0.526358, acc.: 71.88%] [G loss: 0.721685]\n",
      "epoch:10 step:9787 [D loss: 0.635310, acc.: 62.50%] [G loss: 0.533720]\n",
      "epoch:10 step:9788 [D loss: 0.652184, acc.: 57.81%] [G loss: 0.484983]\n",
      "epoch:10 step:9789 [D loss: 0.585235, acc.: 67.19%] [G loss: 0.613028]\n",
      "epoch:10 step:9790 [D loss: 0.560833, acc.: 62.50%] [G loss: 0.702231]\n",
      "epoch:10 step:9791 [D loss: 0.577666, acc.: 67.19%] [G loss: 0.569878]\n",
      "epoch:10 step:9792 [D loss: 0.575114, acc.: 67.97%] [G loss: 0.553616]\n",
      "epoch:10 step:9793 [D loss: 0.545792, acc.: 72.66%] [G loss: 0.505401]\n",
      "epoch:10 step:9794 [D loss: 0.620927, acc.: 60.94%] [G loss: 0.517818]\n",
      "epoch:10 step:9795 [D loss: 0.507424, acc.: 78.91%] [G loss: 0.616911]\n",
      "epoch:10 step:9796 [D loss: 0.526122, acc.: 68.75%] [G loss: 0.692991]\n",
      "epoch:10 step:9797 [D loss: 0.472443, acc.: 75.78%] [G loss: 0.801171]\n",
      "epoch:10 step:9798 [D loss: 0.528442, acc.: 73.44%] [G loss: 0.602050]\n",
      "epoch:10 step:9799 [D loss: 0.481612, acc.: 78.91%] [G loss: 0.737170]\n",
      "epoch:10 step:9800 [D loss: 0.548211, acc.: 71.88%] [G loss: 0.708820]\n",
      "##############\n",
      "[3.31729705 1.42917635 6.44760693 5.07080328 4.09166716 5.87217918\n",
      " 4.52970782 4.85249138 4.86670223 4.0257836 ]\n",
      "##########\n",
      "epoch:10 step:9801 [D loss: 0.547349, acc.: 68.75%] [G loss: 0.605667]\n",
      "epoch:10 step:9802 [D loss: 0.544941, acc.: 69.53%] [G loss: 0.568186]\n",
      "epoch:10 step:9803 [D loss: 0.599465, acc.: 67.19%] [G loss: 0.449216]\n",
      "epoch:10 step:9804 [D loss: 0.490524, acc.: 78.12%] [G loss: 0.528579]\n",
      "epoch:10 step:9805 [D loss: 0.547783, acc.: 71.88%] [G loss: 0.520251]\n",
      "epoch:10 step:9806 [D loss: 0.513801, acc.: 76.56%] [G loss: 0.588372]\n",
      "epoch:10 step:9807 [D loss: 0.674030, acc.: 60.94%] [G loss: 0.540705]\n",
      "epoch:10 step:9808 [D loss: 0.587215, acc.: 64.06%] [G loss: 0.445277]\n",
      "epoch:10 step:9809 [D loss: 0.520037, acc.: 73.44%] [G loss: 0.527378]\n",
      "epoch:10 step:9810 [D loss: 0.553197, acc.: 64.84%] [G loss: 0.609033]\n",
      "epoch:10 step:9811 [D loss: 0.557924, acc.: 66.41%] [G loss: 0.647534]\n",
      "epoch:10 step:9812 [D loss: 0.528491, acc.: 71.09%] [G loss: 0.611801]\n",
      "epoch:10 step:9813 [D loss: 0.537694, acc.: 75.00%] [G loss: 0.442977]\n",
      "epoch:10 step:9814 [D loss: 0.593734, acc.: 67.97%] [G loss: 0.675700]\n",
      "epoch:10 step:9815 [D loss: 0.566860, acc.: 66.41%] [G loss: 0.689170]\n",
      "epoch:10 step:9816 [D loss: 0.555988, acc.: 71.88%] [G loss: 0.591189]\n",
      "epoch:10 step:9817 [D loss: 0.546336, acc.: 71.09%] [G loss: 0.576144]\n",
      "epoch:10 step:9818 [D loss: 0.573210, acc.: 67.19%] [G loss: 0.541299]\n",
      "epoch:10 step:9819 [D loss: 0.594834, acc.: 65.62%] [G loss: 0.486020]\n",
      "epoch:10 step:9820 [D loss: 0.533720, acc.: 72.66%] [G loss: 0.470264]\n",
      "epoch:10 step:9821 [D loss: 0.434008, acc.: 77.34%] [G loss: 0.630460]\n",
      "epoch:10 step:9822 [D loss: 0.515658, acc.: 71.88%] [G loss: 0.733675]\n",
      "epoch:10 step:9823 [D loss: 0.561572, acc.: 69.53%] [G loss: 0.778216]\n",
      "epoch:10 step:9824 [D loss: 0.614595, acc.: 67.97%] [G loss: 0.581689]\n",
      "epoch:10 step:9825 [D loss: 0.597684, acc.: 65.62%] [G loss: 0.566114]\n",
      "epoch:10 step:9826 [D loss: 0.640688, acc.: 61.72%] [G loss: 0.501239]\n",
      "epoch:10 step:9827 [D loss: 0.519625, acc.: 73.44%] [G loss: 0.541392]\n",
      "epoch:10 step:9828 [D loss: 0.622246, acc.: 64.06%] [G loss: 0.481418]\n",
      "epoch:10 step:9829 [D loss: 0.536254, acc.: 72.66%] [G loss: 0.561544]\n",
      "epoch:10 step:9830 [D loss: 0.511397, acc.: 75.00%] [G loss: 0.603501]\n",
      "epoch:10 step:9831 [D loss: 0.513688, acc.: 74.22%] [G loss: 0.549548]\n",
      "epoch:10 step:9832 [D loss: 0.537826, acc.: 70.31%] [G loss: 0.613941]\n",
      "epoch:10 step:9833 [D loss: 0.507237, acc.: 75.78%] [G loss: 0.613932]\n",
      "epoch:10 step:9834 [D loss: 0.530001, acc.: 67.97%] [G loss: 0.505395]\n",
      "epoch:10 step:9835 [D loss: 0.632236, acc.: 57.81%] [G loss: 0.502205]\n",
      "epoch:10 step:9836 [D loss: 0.596826, acc.: 58.59%] [G loss: 0.433850]\n",
      "epoch:10 step:9837 [D loss: 0.602382, acc.: 66.41%] [G loss: 0.555740]\n",
      "epoch:10 step:9838 [D loss: 0.580681, acc.: 72.66%] [G loss: 0.577300]\n",
      "epoch:10 step:9839 [D loss: 0.567310, acc.: 68.75%] [G loss: 0.564858]\n",
      "epoch:10 step:9840 [D loss: 0.536241, acc.: 71.09%] [G loss: 0.686169]\n",
      "epoch:10 step:9841 [D loss: 0.474938, acc.: 78.91%] [G loss: 0.807348]\n",
      "epoch:10 step:9842 [D loss: 0.455649, acc.: 79.69%] [G loss: 0.895783]\n",
      "epoch:10 step:9843 [D loss: 0.700834, acc.: 60.94%] [G loss: 0.605575]\n",
      "epoch:10 step:9844 [D loss: 0.566061, acc.: 67.97%] [G loss: 0.594559]\n",
      "epoch:10 step:9845 [D loss: 0.513151, acc.: 69.53%] [G loss: 0.701476]\n",
      "epoch:10 step:9846 [D loss: 0.548386, acc.: 77.34%] [G loss: 0.607638]\n",
      "epoch:10 step:9847 [D loss: 0.662995, acc.: 64.06%] [G loss: 0.573486]\n",
      "epoch:10 step:9848 [D loss: 0.556944, acc.: 71.88%] [G loss: 0.462841]\n",
      "epoch:10 step:9849 [D loss: 0.482494, acc.: 78.12%] [G loss: 0.482830]\n",
      "epoch:10 step:9850 [D loss: 0.560486, acc.: 71.09%] [G loss: 0.482151]\n",
      "epoch:10 step:9851 [D loss: 0.506938, acc.: 79.69%] [G loss: 0.543906]\n",
      "epoch:10 step:9852 [D loss: 0.580363, acc.: 68.75%] [G loss: 0.515601]\n",
      "epoch:10 step:9853 [D loss: 0.572618, acc.: 70.31%] [G loss: 0.519988]\n",
      "epoch:10 step:9854 [D loss: 0.482200, acc.: 75.00%] [G loss: 0.646299]\n",
      "epoch:10 step:9855 [D loss: 0.535342, acc.: 74.22%] [G loss: 0.600213]\n",
      "epoch:10 step:9856 [D loss: 0.522434, acc.: 76.56%] [G loss: 0.484546]\n",
      "epoch:10 step:9857 [D loss: 0.561041, acc.: 68.75%] [G loss: 0.548345]\n",
      "epoch:10 step:9858 [D loss: 0.482322, acc.: 75.78%] [G loss: 0.648613]\n",
      "epoch:10 step:9859 [D loss: 0.569570, acc.: 64.06%] [G loss: 0.651378]\n",
      "epoch:10 step:9860 [D loss: 0.538547, acc.: 74.22%] [G loss: 0.544426]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9861 [D loss: 0.528512, acc.: 71.88%] [G loss: 0.693254]\n",
      "epoch:10 step:9862 [D loss: 0.590623, acc.: 70.31%] [G loss: 0.515494]\n",
      "epoch:10 step:9863 [D loss: 0.522856, acc.: 74.22%] [G loss: 0.502572]\n",
      "epoch:10 step:9864 [D loss: 0.601436, acc.: 67.97%] [G loss: 0.552483]\n",
      "epoch:10 step:9865 [D loss: 0.530421, acc.: 76.56%] [G loss: 0.512118]\n",
      "epoch:10 step:9866 [D loss: 0.595915, acc.: 69.53%] [G loss: 0.560981]\n",
      "epoch:10 step:9867 [D loss: 0.579006, acc.: 70.31%] [G loss: 0.655422]\n",
      "epoch:10 step:9868 [D loss: 0.571646, acc.: 68.75%] [G loss: 0.559750]\n",
      "epoch:10 step:9869 [D loss: 0.479672, acc.: 75.78%] [G loss: 0.762710]\n",
      "epoch:10 step:9870 [D loss: 0.657525, acc.: 60.16%] [G loss: 0.617382]\n",
      "epoch:10 step:9871 [D loss: 0.669967, acc.: 64.84%] [G loss: 0.573447]\n",
      "epoch:10 step:9872 [D loss: 0.649446, acc.: 59.38%] [G loss: 0.453519]\n",
      "epoch:10 step:9873 [D loss: 0.496486, acc.: 79.69%] [G loss: 0.651796]\n",
      "epoch:10 step:9874 [D loss: 0.509881, acc.: 75.00%] [G loss: 0.745490]\n",
      "epoch:10 step:9875 [D loss: 0.524053, acc.: 74.22%] [G loss: 0.750994]\n",
      "epoch:10 step:9876 [D loss: 0.487715, acc.: 74.22%] [G loss: 0.681564]\n",
      "epoch:10 step:9877 [D loss: 0.502993, acc.: 72.66%] [G loss: 0.791250]\n",
      "epoch:10 step:9878 [D loss: 0.415244, acc.: 84.38%] [G loss: 0.730466]\n",
      "epoch:10 step:9879 [D loss: 0.561960, acc.: 70.31%] [G loss: 0.747454]\n",
      "epoch:10 step:9880 [D loss: 0.594828, acc.: 69.53%] [G loss: 0.651647]\n",
      "epoch:10 step:9881 [D loss: 0.651282, acc.: 61.72%] [G loss: 0.540948]\n",
      "epoch:10 step:9882 [D loss: 0.599220, acc.: 62.50%] [G loss: 0.402738]\n",
      "epoch:10 step:9883 [D loss: 0.547532, acc.: 71.09%] [G loss: 0.499079]\n",
      "epoch:10 step:9884 [D loss: 0.483427, acc.: 77.34%] [G loss: 0.625138]\n",
      "epoch:10 step:9885 [D loss: 0.475355, acc.: 75.78%] [G loss: 0.681731]\n",
      "epoch:10 step:9886 [D loss: 0.478451, acc.: 74.22%] [G loss: 0.719895]\n",
      "epoch:10 step:9887 [D loss: 0.521075, acc.: 71.88%] [G loss: 0.816971]\n",
      "epoch:10 step:9888 [D loss: 0.557084, acc.: 73.44%] [G loss: 0.629941]\n",
      "epoch:10 step:9889 [D loss: 0.438067, acc.: 79.69%] [G loss: 0.642491]\n",
      "epoch:10 step:9890 [D loss: 0.531056, acc.: 73.44%] [G loss: 0.667952]\n",
      "epoch:10 step:9891 [D loss: 0.560869, acc.: 67.19%] [G loss: 0.679540]\n",
      "epoch:10 step:9892 [D loss: 0.500203, acc.: 75.00%] [G loss: 0.656998]\n",
      "epoch:10 step:9893 [D loss: 0.536112, acc.: 71.09%] [G loss: 0.821563]\n",
      "epoch:10 step:9894 [D loss: 0.557833, acc.: 67.97%] [G loss: 0.652395]\n",
      "epoch:10 step:9895 [D loss: 0.575238, acc.: 71.88%] [G loss: 0.517946]\n",
      "epoch:10 step:9896 [D loss: 0.523898, acc.: 69.53%] [G loss: 0.558554]\n",
      "epoch:10 step:9897 [D loss: 0.584882, acc.: 66.41%] [G loss: 0.502665]\n",
      "epoch:10 step:9898 [D loss: 0.663386, acc.: 59.38%] [G loss: 0.578632]\n",
      "epoch:10 step:9899 [D loss: 0.612759, acc.: 60.94%] [G loss: 0.559765]\n",
      "epoch:10 step:9900 [D loss: 0.529193, acc.: 72.66%] [G loss: 0.614422]\n",
      "epoch:10 step:9901 [D loss: 0.605524, acc.: 65.62%] [G loss: 0.480282]\n",
      "epoch:10 step:9902 [D loss: 0.579554, acc.: 64.84%] [G loss: 0.509362]\n",
      "epoch:10 step:9903 [D loss: 0.543843, acc.: 71.09%] [G loss: 0.540018]\n",
      "epoch:10 step:9904 [D loss: 0.503122, acc.: 71.09%] [G loss: 0.664239]\n",
      "epoch:10 step:9905 [D loss: 0.615269, acc.: 67.19%] [G loss: 0.518405]\n",
      "epoch:10 step:9906 [D loss: 0.493653, acc.: 77.34%] [G loss: 0.494713]\n",
      "epoch:10 step:9907 [D loss: 0.642898, acc.: 64.06%] [G loss: 0.458353]\n",
      "epoch:10 step:9908 [D loss: 0.533349, acc.: 71.88%] [G loss: 0.578488]\n",
      "epoch:10 step:9909 [D loss: 0.584558, acc.: 65.62%] [G loss: 0.576952]\n",
      "epoch:10 step:9910 [D loss: 0.518505, acc.: 74.22%] [G loss: 0.654018]\n",
      "epoch:10 step:9911 [D loss: 0.542751, acc.: 67.19%] [G loss: 0.528633]\n",
      "epoch:10 step:9912 [D loss: 0.591253, acc.: 61.72%] [G loss: 0.457211]\n",
      "epoch:10 step:9913 [D loss: 0.579088, acc.: 70.31%] [G loss: 0.514879]\n",
      "epoch:10 step:9914 [D loss: 0.558960, acc.: 70.31%] [G loss: 0.553611]\n",
      "epoch:10 step:9915 [D loss: 0.556122, acc.: 71.88%] [G loss: 0.560269]\n",
      "epoch:10 step:9916 [D loss: 0.485267, acc.: 73.44%] [G loss: 0.657144]\n",
      "epoch:10 step:9917 [D loss: 0.499371, acc.: 80.47%] [G loss: 0.602228]\n",
      "epoch:10 step:9918 [D loss: 0.518484, acc.: 72.66%] [G loss: 0.724646]\n",
      "epoch:10 step:9919 [D loss: 0.532751, acc.: 71.09%] [G loss: 0.549351]\n",
      "epoch:10 step:9920 [D loss: 0.608945, acc.: 60.94%] [G loss: 0.579929]\n",
      "epoch:10 step:9921 [D loss: 0.567389, acc.: 67.97%] [G loss: 0.520408]\n",
      "epoch:10 step:9922 [D loss: 0.503544, acc.: 70.31%] [G loss: 0.583520]\n",
      "epoch:10 step:9923 [D loss: 0.558940, acc.: 65.62%] [G loss: 0.644251]\n",
      "epoch:10 step:9924 [D loss: 0.529405, acc.: 76.56%] [G loss: 0.499776]\n",
      "epoch:10 step:9925 [D loss: 0.473808, acc.: 78.12%] [G loss: 0.557962]\n",
      "epoch:10 step:9926 [D loss: 0.524764, acc.: 77.34%] [G loss: 0.544832]\n",
      "epoch:10 step:9927 [D loss: 0.481561, acc.: 76.56%] [G loss: 0.816455]\n",
      "epoch:10 step:9928 [D loss: 0.517320, acc.: 74.22%] [G loss: 0.623497]\n",
      "epoch:10 step:9929 [D loss: 0.623886, acc.: 61.72%] [G loss: 0.634289]\n",
      "epoch:10 step:9930 [D loss: 0.551751, acc.: 69.53%] [G loss: 0.493430]\n",
      "epoch:10 step:9931 [D loss: 0.538699, acc.: 72.66%] [G loss: 0.635626]\n",
      "epoch:10 step:9932 [D loss: 0.625000, acc.: 55.47%] [G loss: 0.519473]\n",
      "epoch:10 step:9933 [D loss: 0.574594, acc.: 71.09%] [G loss: 0.455192]\n",
      "epoch:10 step:9934 [D loss: 0.493380, acc.: 76.56%] [G loss: 0.628066]\n",
      "epoch:10 step:9935 [D loss: 0.550412, acc.: 78.12%] [G loss: 0.728350]\n",
      "epoch:10 step:9936 [D loss: 0.629927, acc.: 65.62%] [G loss: 0.484167]\n",
      "epoch:10 step:9937 [D loss: 0.526248, acc.: 70.31%] [G loss: 0.485131]\n",
      "epoch:10 step:9938 [D loss: 0.530090, acc.: 75.78%] [G loss: 0.620827]\n",
      "epoch:10 step:9939 [D loss: 0.567701, acc.: 71.09%] [G loss: 0.514206]\n",
      "epoch:10 step:9940 [D loss: 0.573127, acc.: 70.31%] [G loss: 0.526909]\n",
      "epoch:10 step:9941 [D loss: 0.515686, acc.: 70.31%] [G loss: 0.597343]\n",
      "epoch:10 step:9942 [D loss: 0.557428, acc.: 71.09%] [G loss: 0.679996]\n",
      "epoch:10 step:9943 [D loss: 0.560660, acc.: 69.53%] [G loss: 0.510988]\n",
      "epoch:10 step:9944 [D loss: 0.457554, acc.: 78.12%] [G loss: 0.707611]\n",
      "epoch:10 step:9945 [D loss: 0.546079, acc.: 72.66%] [G loss: 0.562721]\n",
      "epoch:10 step:9946 [D loss: 0.601774, acc.: 64.06%] [G loss: 0.637241]\n",
      "epoch:10 step:9947 [D loss: 0.557859, acc.: 67.97%] [G loss: 0.574631]\n",
      "epoch:10 step:9948 [D loss: 0.571869, acc.: 64.06%] [G loss: 0.526945]\n",
      "epoch:10 step:9949 [D loss: 0.535558, acc.: 68.75%] [G loss: 0.608189]\n",
      "epoch:10 step:9950 [D loss: 0.569948, acc.: 69.53%] [G loss: 0.616983]\n",
      "epoch:10 step:9951 [D loss: 0.564764, acc.: 64.84%] [G loss: 0.611484]\n",
      "epoch:10 step:9952 [D loss: 0.456277, acc.: 79.69%] [G loss: 0.743921]\n",
      "epoch:10 step:9953 [D loss: 0.577949, acc.: 75.78%] [G loss: 0.858163]\n",
      "epoch:10 step:9954 [D loss: 0.588470, acc.: 60.94%] [G loss: 0.650018]\n",
      "epoch:10 step:9955 [D loss: 0.612987, acc.: 65.62%] [G loss: 0.532452]\n",
      "epoch:10 step:9956 [D loss: 0.612586, acc.: 66.41%] [G loss: 0.570477]\n",
      "epoch:10 step:9957 [D loss: 0.521373, acc.: 70.31%] [G loss: 0.562559]\n",
      "epoch:10 step:9958 [D loss: 0.586877, acc.: 62.50%] [G loss: 0.459347]\n",
      "epoch:10 step:9959 [D loss: 0.506041, acc.: 67.97%] [G loss: 0.655992]\n",
      "epoch:10 step:9960 [D loss: 0.595332, acc.: 67.19%] [G loss: 0.525556]\n",
      "epoch:10 step:9961 [D loss: 0.560340, acc.: 73.44%] [G loss: 0.512529]\n",
      "epoch:10 step:9962 [D loss: 0.548915, acc.: 74.22%] [G loss: 0.568969]\n",
      "epoch:10 step:9963 [D loss: 0.526711, acc.: 70.31%] [G loss: 0.566397]\n",
      "epoch:10 step:9964 [D loss: 0.523380, acc.: 71.88%] [G loss: 0.629902]\n",
      "epoch:10 step:9965 [D loss: 0.549971, acc.: 70.31%] [G loss: 0.534333]\n",
      "epoch:10 step:9966 [D loss: 0.520272, acc.: 72.66%] [G loss: 0.573215]\n",
      "epoch:10 step:9967 [D loss: 0.565888, acc.: 67.19%] [G loss: 0.495692]\n",
      "epoch:10 step:9968 [D loss: 0.558316, acc.: 69.53%] [G loss: 0.449426]\n",
      "epoch:10 step:9969 [D loss: 0.497179, acc.: 71.09%] [G loss: 0.633091]\n",
      "epoch:10 step:9970 [D loss: 0.630655, acc.: 66.41%] [G loss: 0.514493]\n",
      "epoch:10 step:9971 [D loss: 0.543746, acc.: 68.75%] [G loss: 0.428839]\n",
      "epoch:10 step:9972 [D loss: 0.502846, acc.: 75.00%] [G loss: 0.528687]\n",
      "epoch:10 step:9973 [D loss: 0.510490, acc.: 75.78%] [G loss: 0.653425]\n",
      "epoch:10 step:9974 [D loss: 0.601528, acc.: 70.31%] [G loss: 0.550989]\n",
      "epoch:10 step:9975 [D loss: 0.457694, acc.: 81.25%] [G loss: 0.550630]\n",
      "epoch:10 step:9976 [D loss: 0.562576, acc.: 62.50%] [G loss: 0.581438]\n",
      "epoch:10 step:9977 [D loss: 0.530931, acc.: 66.41%] [G loss: 0.503404]\n",
      "epoch:10 step:9978 [D loss: 0.586153, acc.: 64.06%] [G loss: 0.453322]\n",
      "epoch:10 step:9979 [D loss: 0.533017, acc.: 74.22%] [G loss: 0.460374]\n",
      "epoch:10 step:9980 [D loss: 0.576176, acc.: 67.97%] [G loss: 0.445333]\n",
      "epoch:10 step:9981 [D loss: 0.510184, acc.: 74.22%] [G loss: 0.644237]\n",
      "epoch:10 step:9982 [D loss: 0.551507, acc.: 71.88%] [G loss: 0.490697]\n",
      "epoch:10 step:9983 [D loss: 0.472427, acc.: 76.56%] [G loss: 0.513147]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9984 [D loss: 0.581927, acc.: 65.62%] [G loss: 0.462952]\n",
      "epoch:10 step:9985 [D loss: 0.642115, acc.: 60.16%] [G loss: 0.463677]\n",
      "epoch:10 step:9986 [D loss: 0.564754, acc.: 66.41%] [G loss: 0.542419]\n",
      "epoch:10 step:9987 [D loss: 0.558176, acc.: 71.88%] [G loss: 0.607815]\n",
      "epoch:10 step:9988 [D loss: 0.543819, acc.: 71.09%] [G loss: 0.556975]\n",
      "epoch:10 step:9989 [D loss: 0.595321, acc.: 65.62%] [G loss: 0.489935]\n",
      "epoch:10 step:9990 [D loss: 0.551537, acc.: 72.66%] [G loss: 0.640335]\n",
      "epoch:10 step:9991 [D loss: 0.565591, acc.: 72.66%] [G loss: 0.503952]\n",
      "epoch:10 step:9992 [D loss: 0.647274, acc.: 66.41%] [G loss: 0.480741]\n",
      "epoch:10 step:9993 [D loss: 0.485775, acc.: 80.47%] [G loss: 0.549519]\n",
      "epoch:10 step:9994 [D loss: 0.450281, acc.: 80.47%] [G loss: 0.663404]\n",
      "epoch:10 step:9995 [D loss: 0.610981, acc.: 60.16%] [G loss: 0.511877]\n",
      "epoch:10 step:9996 [D loss: 0.518860, acc.: 71.09%] [G loss: 0.433485]\n",
      "epoch:10 step:9997 [D loss: 0.521266, acc.: 67.97%] [G loss: 0.539499]\n",
      "epoch:10 step:9998 [D loss: 0.547528, acc.: 71.88%] [G loss: 0.612560]\n",
      "epoch:10 step:9999 [D loss: 0.561915, acc.: 66.41%] [G loss: 0.563673]\n",
      "epoch:10 step:10000 [D loss: 0.537577, acc.: 69.53%] [G loss: 0.609264]\n",
      "##############\n",
      "[3.11845845 0.87707399 6.42491121 4.88311574 3.82556827 5.72197815\n",
      " 4.81381836 4.6105339  4.74307088 4.05624674]\n",
      "##########\n",
      "epoch:10 step:10001 [D loss: 0.517069, acc.: 72.66%] [G loss: 0.686865]\n",
      "epoch:10 step:10002 [D loss: 0.517268, acc.: 72.66%] [G loss: 0.587326]\n",
      "epoch:10 step:10003 [D loss: 0.515585, acc.: 71.88%] [G loss: 0.603232]\n",
      "epoch:10 step:10004 [D loss: 0.516567, acc.: 72.66%] [G loss: 0.542396]\n",
      "epoch:10 step:10005 [D loss: 0.513380, acc.: 75.00%] [G loss: 0.671794]\n",
      "epoch:10 step:10006 [D loss: 0.618665, acc.: 65.62%] [G loss: 0.495156]\n",
      "epoch:10 step:10007 [D loss: 0.575772, acc.: 67.19%] [G loss: 0.479471]\n",
      "epoch:10 step:10008 [D loss: 0.502595, acc.: 71.09%] [G loss: 0.499285]\n",
      "epoch:10 step:10009 [D loss: 0.530516, acc.: 70.31%] [G loss: 0.584401]\n",
      "epoch:10 step:10010 [D loss: 0.553383, acc.: 67.19%] [G loss: 0.631502]\n",
      "epoch:10 step:10011 [D loss: 0.535539, acc.: 73.44%] [G loss: 0.677337]\n",
      "epoch:10 step:10012 [D loss: 0.459156, acc.: 82.03%] [G loss: 0.751673]\n",
      "epoch:10 step:10013 [D loss: 0.548490, acc.: 72.66%] [G loss: 0.563180]\n",
      "epoch:10 step:10014 [D loss: 0.537615, acc.: 69.53%] [G loss: 0.523077]\n",
      "epoch:10 step:10015 [D loss: 0.515946, acc.: 71.09%] [G loss: 0.582549]\n",
      "epoch:10 step:10016 [D loss: 0.540021, acc.: 73.44%] [G loss: 0.620123]\n",
      "epoch:10 step:10017 [D loss: 0.470300, acc.: 78.12%] [G loss: 0.634358]\n",
      "epoch:10 step:10018 [D loss: 0.417683, acc.: 79.69%] [G loss: 0.840011]\n",
      "epoch:10 step:10019 [D loss: 0.481167, acc.: 75.78%] [G loss: 0.882784]\n",
      "epoch:10 step:10020 [D loss: 0.549211, acc.: 73.44%] [G loss: 0.732469]\n",
      "epoch:10 step:10021 [D loss: 0.533082, acc.: 73.44%] [G loss: 0.826645]\n",
      "epoch:10 step:10022 [D loss: 0.599615, acc.: 67.19%] [G loss: 0.626512]\n",
      "epoch:10 step:10023 [D loss: 0.619255, acc.: 64.84%] [G loss: 0.459250]\n",
      "epoch:10 step:10024 [D loss: 0.483972, acc.: 78.12%] [G loss: 0.492114]\n",
      "epoch:10 step:10025 [D loss: 0.531002, acc.: 76.56%] [G loss: 0.509601]\n",
      "epoch:10 step:10026 [D loss: 0.529771, acc.: 71.88%] [G loss: 0.655859]\n",
      "epoch:10 step:10027 [D loss: 0.502070, acc.: 72.66%] [G loss: 0.725678]\n",
      "epoch:10 step:10028 [D loss: 0.611553, acc.: 65.62%] [G loss: 0.554034]\n",
      "epoch:10 step:10029 [D loss: 0.518628, acc.: 71.09%] [G loss: 0.560016]\n",
      "epoch:10 step:10030 [D loss: 0.502583, acc.: 71.88%] [G loss: 0.739908]\n",
      "epoch:10 step:10031 [D loss: 0.512377, acc.: 74.22%] [G loss: 0.684715]\n",
      "epoch:10 step:10032 [D loss: 0.608379, acc.: 62.50%] [G loss: 0.577411]\n",
      "epoch:10 step:10033 [D loss: 0.548809, acc.: 70.31%] [G loss: 0.535394]\n",
      "epoch:10 step:10034 [D loss: 0.576474, acc.: 67.19%] [G loss: 0.606890]\n",
      "epoch:10 step:10035 [D loss: 0.602979, acc.: 69.53%] [G loss: 0.622802]\n",
      "epoch:10 step:10036 [D loss: 0.499485, acc.: 79.69%] [G loss: 0.609727]\n",
      "epoch:10 step:10037 [D loss: 0.588543, acc.: 70.31%] [G loss: 0.595851]\n",
      "epoch:10 step:10038 [D loss: 0.530016, acc.: 78.12%] [G loss: 0.564425]\n",
      "epoch:10 step:10039 [D loss: 0.549310, acc.: 65.62%] [G loss: 0.647560]\n",
      "epoch:10 step:10040 [D loss: 0.536904, acc.: 71.09%] [G loss: 0.640545]\n",
      "epoch:10 step:10041 [D loss: 0.575909, acc.: 66.41%] [G loss: 0.611932]\n",
      "epoch:10 step:10042 [D loss: 0.561086, acc.: 71.09%] [G loss: 0.538165]\n",
      "epoch:10 step:10043 [D loss: 0.617581, acc.: 63.28%] [G loss: 0.648003]\n",
      "epoch:10 step:10044 [D loss: 0.543111, acc.: 69.53%] [G loss: 0.573541]\n",
      "epoch:10 step:10045 [D loss: 0.574769, acc.: 67.19%] [G loss: 0.578196]\n",
      "epoch:10 step:10046 [D loss: 0.561146, acc.: 69.53%] [G loss: 0.689054]\n",
      "epoch:10 step:10047 [D loss: 0.474333, acc.: 81.25%] [G loss: 0.674796]\n",
      "epoch:10 step:10048 [D loss: 0.607941, acc.: 65.62%] [G loss: 0.647648]\n",
      "epoch:10 step:10049 [D loss: 0.514274, acc.: 73.44%] [G loss: 0.736565]\n",
      "epoch:10 step:10050 [D loss: 0.537162, acc.: 69.53%] [G loss: 0.663146]\n",
      "epoch:10 step:10051 [D loss: 0.510036, acc.: 78.91%] [G loss: 0.581840]\n",
      "epoch:10 step:10052 [D loss: 0.548019, acc.: 68.75%] [G loss: 0.651573]\n",
      "epoch:10 step:10053 [D loss: 0.562820, acc.: 67.19%] [G loss: 0.447528]\n",
      "epoch:10 step:10054 [D loss: 0.620010, acc.: 62.50%] [G loss: 0.477405]\n",
      "epoch:10 step:10055 [D loss: 0.527536, acc.: 71.09%] [G loss: 0.577870]\n",
      "epoch:10 step:10056 [D loss: 0.555174, acc.: 71.09%] [G loss: 0.397062]\n",
      "epoch:10 step:10057 [D loss: 0.541892, acc.: 73.44%] [G loss: 0.461014]\n",
      "epoch:10 step:10058 [D loss: 0.545723, acc.: 71.09%] [G loss: 0.499981]\n",
      "epoch:10 step:10059 [D loss: 0.602080, acc.: 66.41%] [G loss: 0.473751]\n",
      "epoch:10 step:10060 [D loss: 0.557487, acc.: 71.09%] [G loss: 0.601467]\n",
      "epoch:10 step:10061 [D loss: 0.451077, acc.: 80.47%] [G loss: 0.855748]\n",
      "epoch:10 step:10062 [D loss: 0.543000, acc.: 70.31%] [G loss: 0.437977]\n",
      "epoch:10 step:10063 [D loss: 0.498664, acc.: 78.12%] [G loss: 0.589761]\n",
      "epoch:10 step:10064 [D loss: 0.483236, acc.: 75.78%] [G loss: 0.699560]\n",
      "epoch:10 step:10065 [D loss: 0.506608, acc.: 71.88%] [G loss: 0.710997]\n",
      "epoch:10 step:10066 [D loss: 0.603052, acc.: 66.41%] [G loss: 0.586530]\n",
      "epoch:10 step:10067 [D loss: 0.576214, acc.: 63.28%] [G loss: 0.527063]\n",
      "epoch:10 step:10068 [D loss: 0.551995, acc.: 71.88%] [G loss: 0.466755]\n",
      "epoch:10 step:10069 [D loss: 0.511054, acc.: 69.53%] [G loss: 0.688750]\n",
      "epoch:10 step:10070 [D loss: 0.561565, acc.: 71.88%] [G loss: 0.571199]\n",
      "epoch:10 step:10071 [D loss: 0.531342, acc.: 74.22%] [G loss: 0.721584]\n",
      "epoch:10 step:10072 [D loss: 0.548660, acc.: 67.97%] [G loss: 0.647050]\n",
      "epoch:10 step:10073 [D loss: 0.569146, acc.: 69.53%] [G loss: 0.460825]\n",
      "epoch:10 step:10074 [D loss: 0.617509, acc.: 64.84%] [G loss: 0.529608]\n",
      "epoch:10 step:10075 [D loss: 0.503324, acc.: 70.31%] [G loss: 0.607582]\n",
      "epoch:10 step:10076 [D loss: 0.520996, acc.: 75.00%] [G loss: 0.574584]\n",
      "epoch:10 step:10077 [D loss: 0.484286, acc.: 76.56%] [G loss: 0.490341]\n",
      "epoch:10 step:10078 [D loss: 0.465792, acc.: 80.47%] [G loss: 0.680752]\n",
      "epoch:10 step:10079 [D loss: 0.488706, acc.: 75.00%] [G loss: 0.739631]\n",
      "epoch:10 step:10080 [D loss: 0.629113, acc.: 66.41%] [G loss: 0.493842]\n",
      "epoch:10 step:10081 [D loss: 0.589636, acc.: 62.50%] [G loss: 0.605677]\n",
      "epoch:10 step:10082 [D loss: 0.561705, acc.: 68.75%] [G loss: 0.596304]\n",
      "epoch:10 step:10083 [D loss: 0.555603, acc.: 64.84%] [G loss: 0.574455]\n",
      "epoch:10 step:10084 [D loss: 0.532750, acc.: 75.78%] [G loss: 0.659573]\n",
      "epoch:10 step:10085 [D loss: 0.546608, acc.: 77.34%] [G loss: 0.639038]\n",
      "epoch:10 step:10086 [D loss: 0.650264, acc.: 57.81%] [G loss: 0.554873]\n",
      "epoch:10 step:10087 [D loss: 0.607962, acc.: 67.97%] [G loss: 0.483299]\n",
      "epoch:10 step:10088 [D loss: 0.570037, acc.: 67.19%] [G loss: 0.512881]\n",
      "epoch:10 step:10089 [D loss: 0.481580, acc.: 78.91%] [G loss: 0.670152]\n",
      "epoch:10 step:10090 [D loss: 0.658101, acc.: 60.16%] [G loss: 0.572585]\n",
      "epoch:10 step:10091 [D loss: 0.568156, acc.: 69.53%] [G loss: 0.554657]\n",
      "epoch:10 step:10092 [D loss: 0.554572, acc.: 71.09%] [G loss: 0.588777]\n",
      "epoch:10 step:10093 [D loss: 0.561136, acc.: 69.53%] [G loss: 0.598893]\n",
      "epoch:10 step:10094 [D loss: 0.554048, acc.: 66.41%] [G loss: 0.558994]\n",
      "epoch:10 step:10095 [D loss: 0.506517, acc.: 75.78%] [G loss: 0.633068]\n",
      "epoch:10 step:10096 [D loss: 0.551671, acc.: 73.44%] [G loss: 0.640154]\n",
      "epoch:10 step:10097 [D loss: 0.577522, acc.: 67.97%] [G loss: 0.524036]\n",
      "epoch:10 step:10098 [D loss: 0.541718, acc.: 75.78%] [G loss: 0.579205]\n",
      "epoch:10 step:10099 [D loss: 0.589160, acc.: 67.19%] [G loss: 0.567440]\n",
      "epoch:10 step:10100 [D loss: 0.501300, acc.: 79.69%] [G loss: 0.554550]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:10101 [D loss: 0.572985, acc.: 68.75%] [G loss: 0.543110]\n",
      "epoch:10 step:10102 [D loss: 0.505972, acc.: 71.88%] [G loss: 0.571995]\n",
      "epoch:10 step:10103 [D loss: 0.562492, acc.: 69.53%] [G loss: 0.705283]\n",
      "epoch:10 step:10104 [D loss: 0.517495, acc.: 73.44%] [G loss: 0.641569]\n",
      "epoch:10 step:10105 [D loss: 0.544402, acc.: 67.97%] [G loss: 0.648388]\n",
      "epoch:10 step:10106 [D loss: 0.478453, acc.: 75.78%] [G loss: 0.646414]\n",
      "epoch:10 step:10107 [D loss: 0.555519, acc.: 72.66%] [G loss: 0.605081]\n",
      "epoch:10 step:10108 [D loss: 0.561484, acc.: 67.19%] [G loss: 0.608159]\n",
      "epoch:10 step:10109 [D loss: 0.588358, acc.: 72.66%] [G loss: 0.600482]\n",
      "epoch:10 step:10110 [D loss: 0.642889, acc.: 61.72%] [G loss: 0.354886]\n",
      "epoch:10 step:10111 [D loss: 0.551094, acc.: 72.66%] [G loss: 0.466308]\n",
      "epoch:10 step:10112 [D loss: 0.551025, acc.: 68.75%] [G loss: 0.529163]\n",
      "epoch:10 step:10113 [D loss: 0.482410, acc.: 79.69%] [G loss: 0.621119]\n",
      "epoch:10 step:10114 [D loss: 0.536510, acc.: 72.66%] [G loss: 0.683654]\n",
      "epoch:10 step:10115 [D loss: 0.551332, acc.: 67.19%] [G loss: 0.653883]\n",
      "epoch:10 step:10116 [D loss: 0.491014, acc.: 71.88%] [G loss: 0.608140]\n",
      "epoch:10 step:10117 [D loss: 0.440764, acc.: 80.47%] [G loss: 0.768716]\n",
      "epoch:10 step:10118 [D loss: 0.604741, acc.: 65.62%] [G loss: 0.683446]\n",
      "epoch:10 step:10119 [D loss: 0.496508, acc.: 78.12%] [G loss: 0.628872]\n",
      "epoch:10 step:10120 [D loss: 0.511889, acc.: 74.22%] [G loss: 0.651026]\n",
      "epoch:10 step:10121 [D loss: 0.523984, acc.: 72.66%] [G loss: 0.623430]\n",
      "epoch:10 step:10122 [D loss: 0.622781, acc.: 64.06%] [G loss: 0.615514]\n",
      "epoch:10 step:10123 [D loss: 0.557594, acc.: 70.31%] [G loss: 0.627048]\n",
      "epoch:10 step:10124 [D loss: 0.543073, acc.: 67.97%] [G loss: 0.707241]\n",
      "epoch:10 step:10125 [D loss: 0.511323, acc.: 73.44%] [G loss: 0.719153]\n",
      "epoch:10 step:10126 [D loss: 0.578117, acc.: 68.75%] [G loss: 0.544343]\n",
      "epoch:10 step:10127 [D loss: 0.582429, acc.: 67.97%] [G loss: 0.539058]\n",
      "epoch:10 step:10128 [D loss: 0.519666, acc.: 78.12%] [G loss: 0.435912]\n",
      "epoch:10 step:10129 [D loss: 0.553083, acc.: 69.53%] [G loss: 0.486470]\n",
      "epoch:10 step:10130 [D loss: 0.568157, acc.: 68.75%] [G loss: 0.581963]\n",
      "epoch:10 step:10131 [D loss: 0.548712, acc.: 68.75%] [G loss: 0.613878]\n",
      "epoch:10 step:10132 [D loss: 0.591488, acc.: 63.28%] [G loss: 0.466068]\n",
      "epoch:10 step:10133 [D loss: 0.521993, acc.: 72.66%] [G loss: 0.462841]\n",
      "epoch:10 step:10134 [D loss: 0.620239, acc.: 63.28%] [G loss: 0.473258]\n",
      "epoch:10 step:10135 [D loss: 0.611543, acc.: 64.06%] [G loss: 0.575522]\n",
      "epoch:10 step:10136 [D loss: 0.676191, acc.: 58.59%] [G loss: 0.391107]\n",
      "epoch:10 step:10137 [D loss: 0.581237, acc.: 68.75%] [G loss: 0.506168]\n",
      "epoch:10 step:10138 [D loss: 0.518905, acc.: 69.53%] [G loss: 0.551378]\n",
      "epoch:10 step:10139 [D loss: 0.483705, acc.: 77.34%] [G loss: 0.821976]\n",
      "epoch:10 step:10140 [D loss: 0.522334, acc.: 71.88%] [G loss: 0.719851]\n",
      "epoch:10 step:10141 [D loss: 0.521619, acc.: 73.44%] [G loss: 0.874581]\n",
      "epoch:10 step:10142 [D loss: 0.565899, acc.: 65.62%] [G loss: 0.514249]\n",
      "epoch:10 step:10143 [D loss: 0.528543, acc.: 75.00%] [G loss: 0.773993]\n",
      "epoch:10 step:10144 [D loss: 0.553234, acc.: 71.88%] [G loss: 0.704834]\n",
      "epoch:10 step:10145 [D loss: 0.528912, acc.: 71.88%] [G loss: 0.720585]\n",
      "epoch:10 step:10146 [D loss: 0.556217, acc.: 67.97%] [G loss: 0.729320]\n",
      "epoch:10 step:10147 [D loss: 0.566202, acc.: 67.19%] [G loss: 0.666598]\n",
      "epoch:10 step:10148 [D loss: 0.564273, acc.: 67.97%] [G loss: 0.629166]\n",
      "epoch:10 step:10149 [D loss: 0.630865, acc.: 64.06%] [G loss: 0.512395]\n",
      "epoch:10 step:10150 [D loss: 0.512973, acc.: 75.78%] [G loss: 0.724540]\n",
      "epoch:10 step:10151 [D loss: 0.484296, acc.: 74.22%] [G loss: 0.805513]\n",
      "epoch:10 step:10152 [D loss: 0.569454, acc.: 66.41%] [G loss: 0.735502]\n",
      "epoch:10 step:10153 [D loss: 0.597008, acc.: 65.62%] [G loss: 0.740805]\n",
      "epoch:10 step:10154 [D loss: 0.635934, acc.: 66.41%] [G loss: 0.525539]\n",
      "epoch:10 step:10155 [D loss: 0.575166, acc.: 67.97%] [G loss: 0.493048]\n",
      "epoch:10 step:10156 [D loss: 0.511799, acc.: 76.56%] [G loss: 0.537758]\n",
      "epoch:10 step:10157 [D loss: 0.541542, acc.: 71.88%] [G loss: 0.617019]\n",
      "epoch:10 step:10158 [D loss: 0.644857, acc.: 60.94%] [G loss: 0.430020]\n",
      "epoch:10 step:10159 [D loss: 0.519360, acc.: 67.97%] [G loss: 0.536768]\n",
      "epoch:10 step:10160 [D loss: 0.556516, acc.: 71.09%] [G loss: 0.475714]\n",
      "epoch:10 step:10161 [D loss: 0.557194, acc.: 70.31%] [G loss: 0.536361]\n",
      "epoch:10 step:10162 [D loss: 0.458859, acc.: 75.00%] [G loss: 0.624982]\n",
      "epoch:10 step:10163 [D loss: 0.558678, acc.: 69.53%] [G loss: 0.738985]\n",
      "epoch:10 step:10164 [D loss: 0.615806, acc.: 57.81%] [G loss: 0.541981]\n",
      "epoch:10 step:10165 [D loss: 0.522903, acc.: 70.31%] [G loss: 0.559424]\n",
      "epoch:10 step:10166 [D loss: 0.497441, acc.: 76.56%] [G loss: 0.780054]\n",
      "epoch:10 step:10167 [D loss: 0.521572, acc.: 71.88%] [G loss: 0.712171]\n",
      "epoch:10 step:10168 [D loss: 0.529171, acc.: 66.41%] [G loss: 0.651554]\n",
      "epoch:10 step:10169 [D loss: 0.561447, acc.: 70.31%] [G loss: 0.607961]\n",
      "epoch:10 step:10170 [D loss: 0.606673, acc.: 62.50%] [G loss: 0.396701]\n",
      "epoch:10 step:10171 [D loss: 0.509725, acc.: 75.00%] [G loss: 0.598851]\n",
      "epoch:10 step:10172 [D loss: 0.509743, acc.: 71.88%] [G loss: 0.765128]\n",
      "epoch:10 step:10173 [D loss: 0.537689, acc.: 75.78%] [G loss: 0.667605]\n",
      "epoch:10 step:10174 [D loss: 0.535305, acc.: 70.31%] [G loss: 0.598822]\n",
      "epoch:10 step:10175 [D loss: 0.558524, acc.: 65.62%] [G loss: 0.661925]\n",
      "epoch:10 step:10176 [D loss: 0.547406, acc.: 67.19%] [G loss: 0.592625]\n",
      "epoch:10 step:10177 [D loss: 0.570407, acc.: 69.53%] [G loss: 0.635221]\n",
      "epoch:10 step:10178 [D loss: 0.539570, acc.: 71.09%] [G loss: 0.592593]\n",
      "epoch:10 step:10179 [D loss: 0.553174, acc.: 70.31%] [G loss: 0.531810]\n",
      "epoch:10 step:10180 [D loss: 0.546517, acc.: 67.97%] [G loss: 0.423380]\n",
      "epoch:10 step:10181 [D loss: 0.553354, acc.: 69.53%] [G loss: 0.522476]\n",
      "epoch:10 step:10182 [D loss: 0.666384, acc.: 60.94%] [G loss: 0.400873]\n",
      "epoch:10 step:10183 [D loss: 0.533771, acc.: 67.97%] [G loss: 0.492467]\n",
      "epoch:10 step:10184 [D loss: 0.481004, acc.: 76.56%] [G loss: 0.559824]\n",
      "epoch:10 step:10185 [D loss: 0.539267, acc.: 76.56%] [G loss: 0.656895]\n",
      "epoch:10 step:10186 [D loss: 0.553102, acc.: 67.97%] [G loss: 0.562871]\n",
      "epoch:10 step:10187 [D loss: 0.591026, acc.: 64.84%] [G loss: 0.576704]\n",
      "epoch:10 step:10188 [D loss: 0.595558, acc.: 63.28%] [G loss: 0.488654]\n",
      "epoch:10 step:10189 [D loss: 0.517797, acc.: 75.00%] [G loss: 0.562241]\n",
      "epoch:10 step:10190 [D loss: 0.623412, acc.: 59.38%] [G loss: 0.527139]\n",
      "epoch:10 step:10191 [D loss: 0.539757, acc.: 71.88%] [G loss: 0.569708]\n",
      "epoch:10 step:10192 [D loss: 0.528745, acc.: 71.09%] [G loss: 0.512325]\n",
      "epoch:10 step:10193 [D loss: 0.452636, acc.: 79.69%] [G loss: 0.620279]\n",
      "epoch:10 step:10194 [D loss: 0.583933, acc.: 66.41%] [G loss: 0.691305]\n",
      "epoch:10 step:10195 [D loss: 0.550549, acc.: 71.88%] [G loss: 0.565795]\n",
      "epoch:10 step:10196 [D loss: 0.514112, acc.: 72.66%] [G loss: 0.671023]\n",
      "epoch:10 step:10197 [D loss: 0.585624, acc.: 64.06%] [G loss: 0.502231]\n",
      "epoch:10 step:10198 [D loss: 0.659956, acc.: 60.16%] [G loss: 0.444372]\n",
      "epoch:10 step:10199 [D loss: 0.521708, acc.: 69.53%] [G loss: 0.517777]\n",
      "epoch:10 step:10200 [D loss: 0.583929, acc.: 67.97%] [G loss: 0.528334]\n",
      "##############\n",
      "[3.33265128 0.85433818 6.22820986 4.93870762 3.67085798 5.95866434\n",
      " 4.69885974 4.9304237  4.67790169 4.22544419]\n",
      "##########\n",
      "epoch:10 step:10201 [D loss: 0.562370, acc.: 72.66%] [G loss: 0.560051]\n",
      "epoch:10 step:10202 [D loss: 0.551824, acc.: 67.97%] [G loss: 0.643593]\n",
      "epoch:10 step:10203 [D loss: 0.522498, acc.: 74.22%] [G loss: 0.668515]\n",
      "epoch:10 step:10204 [D loss: 0.543225, acc.: 67.97%] [G loss: 0.461731]\n",
      "epoch:10 step:10205 [D loss: 0.527722, acc.: 73.44%] [G loss: 0.498674]\n",
      "epoch:10 step:10206 [D loss: 0.511725, acc.: 73.44%] [G loss: 0.473979]\n",
      "epoch:10 step:10207 [D loss: 0.556682, acc.: 70.31%] [G loss: 0.447602]\n",
      "epoch:10 step:10208 [D loss: 0.530518, acc.: 72.66%] [G loss: 0.517150]\n",
      "epoch:10 step:10209 [D loss: 0.547322, acc.: 71.88%] [G loss: 0.495276]\n",
      "epoch:10 step:10210 [D loss: 0.638453, acc.: 62.50%] [G loss: 0.472377]\n",
      "epoch:10 step:10211 [D loss: 0.540825, acc.: 71.88%] [G loss: 0.418321]\n",
      "epoch:10 step:10212 [D loss: 0.481655, acc.: 77.34%] [G loss: 0.551545]\n",
      "epoch:10 step:10213 [D loss: 0.524905, acc.: 70.31%] [G loss: 0.521729]\n",
      "epoch:10 step:10214 [D loss: 0.584288, acc.: 67.97%] [G loss: 0.486712]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:10215 [D loss: 0.552361, acc.: 67.19%] [G loss: 0.607279]\n",
      "epoch:10 step:10216 [D loss: 0.614674, acc.: 60.16%] [G loss: 0.399882]\n",
      "epoch:10 step:10217 [D loss: 0.611257, acc.: 63.28%] [G loss: 0.440253]\n",
      "epoch:10 step:10218 [D loss: 0.532271, acc.: 70.31%] [G loss: 0.445041]\n",
      "epoch:10 step:10219 [D loss: 0.571796, acc.: 67.19%] [G loss: 0.376456]\n",
      "epoch:10 step:10220 [D loss: 0.548442, acc.: 66.41%] [G loss: 0.545091]\n",
      "epoch:10 step:10221 [D loss: 0.623649, acc.: 62.50%] [G loss: 0.485510]\n",
      "epoch:10 step:10222 [D loss: 0.541129, acc.: 70.31%] [G loss: 0.630361]\n",
      "epoch:10 step:10223 [D loss: 0.545236, acc.: 74.22%] [G loss: 0.582585]\n",
      "epoch:10 step:10224 [D loss: 0.537877, acc.: 68.75%] [G loss: 0.577000]\n",
      "epoch:10 step:10225 [D loss: 0.512168, acc.: 74.22%] [G loss: 0.633321]\n",
      "epoch:10 step:10226 [D loss: 0.582110, acc.: 67.19%] [G loss: 0.540464]\n",
      "epoch:10 step:10227 [D loss: 0.480369, acc.: 75.78%] [G loss: 0.559444]\n",
      "epoch:10 step:10228 [D loss: 0.633077, acc.: 64.84%] [G loss: 0.587157]\n",
      "epoch:10 step:10229 [D loss: 0.525352, acc.: 69.53%] [G loss: 0.671466]\n",
      "epoch:10 step:10230 [D loss: 0.494351, acc.: 72.66%] [G loss: 0.675115]\n",
      "epoch:10 step:10231 [D loss: 0.600657, acc.: 64.84%] [G loss: 0.527555]\n",
      "epoch:10 step:10232 [D loss: 0.578651, acc.: 63.28%] [G loss: 0.455130]\n",
      "epoch:10 step:10233 [D loss: 0.544716, acc.: 71.09%] [G loss: 0.542456]\n",
      "epoch:10 step:10234 [D loss: 0.524899, acc.: 71.09%] [G loss: 0.611408]\n",
      "epoch:10 step:10235 [D loss: 0.575446, acc.: 67.19%] [G loss: 0.400629]\n",
      "epoch:10 step:10236 [D loss: 0.509240, acc.: 74.22%] [G loss: 0.546128]\n",
      "epoch:10 step:10237 [D loss: 0.674648, acc.: 59.38%] [G loss: 0.446703]\n",
      "epoch:10 step:10238 [D loss: 0.530320, acc.: 75.78%] [G loss: 0.501985]\n",
      "epoch:10 step:10239 [D loss: 0.569352, acc.: 68.75%] [G loss: 0.581564]\n",
      "epoch:10 step:10240 [D loss: 0.497215, acc.: 74.22%] [G loss: 0.682976]\n",
      "epoch:10 step:10241 [D loss: 0.531056, acc.: 72.66%] [G loss: 0.620500]\n",
      "epoch:10 step:10242 [D loss: 0.565450, acc.: 67.19%] [G loss: 0.544998]\n",
      "epoch:10 step:10243 [D loss: 0.575319, acc.: 67.97%] [G loss: 0.531276]\n",
      "epoch:10 step:10244 [D loss: 0.581836, acc.: 68.75%] [G loss: 0.520438]\n",
      "epoch:10 step:10245 [D loss: 0.485458, acc.: 77.34%] [G loss: 0.560481]\n",
      "epoch:10 step:10246 [D loss: 0.545139, acc.: 71.09%] [G loss: 0.603319]\n",
      "epoch:10 step:10247 [D loss: 0.549501, acc.: 73.44%] [G loss: 0.470491]\n",
      "epoch:10 step:10248 [D loss: 0.549111, acc.: 68.75%] [G loss: 0.480919]\n",
      "epoch:10 step:10249 [D loss: 0.544935, acc.: 69.53%] [G loss: 0.503701]\n",
      "epoch:10 step:10250 [D loss: 0.586231, acc.: 63.28%] [G loss: 0.533815]\n",
      "epoch:10 step:10251 [D loss: 0.578717, acc.: 71.09%] [G loss: 0.594101]\n",
      "epoch:10 step:10252 [D loss: 0.593823, acc.: 62.50%] [G loss: 0.572808]\n",
      "epoch:10 step:10253 [D loss: 0.545940, acc.: 68.75%] [G loss: 0.489944]\n",
      "epoch:10 step:10254 [D loss: 0.475775, acc.: 77.34%] [G loss: 0.663073]\n",
      "epoch:10 step:10255 [D loss: 0.573050, acc.: 67.19%] [G loss: 0.636971]\n",
      "epoch:10 step:10256 [D loss: 0.595435, acc.: 67.19%] [G loss: 0.762243]\n",
      "epoch:10 step:10257 [D loss: 0.550143, acc.: 67.97%] [G loss: 0.691565]\n",
      "epoch:10 step:10258 [D loss: 0.519299, acc.: 71.09%] [G loss: 0.557032]\n",
      "epoch:10 step:10259 [D loss: 0.513468, acc.: 73.44%] [G loss: 0.741162]\n",
      "epoch:10 step:10260 [D loss: 0.460061, acc.: 80.47%] [G loss: 0.614018]\n",
      "epoch:10 step:10261 [D loss: 0.647736, acc.: 60.16%] [G loss: 0.447829]\n",
      "epoch:10 step:10262 [D loss: 0.616548, acc.: 63.28%] [G loss: 0.515837]\n",
      "epoch:10 step:10263 [D loss: 0.555549, acc.: 69.53%] [G loss: 0.446286]\n",
      "epoch:10 step:10264 [D loss: 0.448984, acc.: 80.47%] [G loss: 0.637878]\n",
      "epoch:10 step:10265 [D loss: 0.526834, acc.: 74.22%] [G loss: 0.663209]\n",
      "epoch:10 step:10266 [D loss: 0.509506, acc.: 76.56%] [G loss: 0.645517]\n",
      "epoch:10 step:10267 [D loss: 0.496606, acc.: 75.78%] [G loss: 0.826421]\n",
      "epoch:10 step:10268 [D loss: 0.508953, acc.: 75.78%] [G loss: 0.713761]\n",
      "epoch:10 step:10269 [D loss: 0.483072, acc.: 76.56%] [G loss: 0.737042]\n",
      "epoch:10 step:10270 [D loss: 0.473180, acc.: 80.47%] [G loss: 0.805549]\n",
      "epoch:10 step:10271 [D loss: 0.569255, acc.: 70.31%] [G loss: 0.673406]\n",
      "epoch:10 step:10272 [D loss: 0.585717, acc.: 67.97%] [G loss: 0.688395]\n",
      "epoch:10 step:10273 [D loss: 0.542175, acc.: 71.88%] [G loss: 0.678700]\n",
      "epoch:10 step:10274 [D loss: 0.635057, acc.: 64.06%] [G loss: 0.605017]\n",
      "epoch:10 step:10275 [D loss: 0.586117, acc.: 69.53%] [G loss: 0.625890]\n",
      "epoch:10 step:10276 [D loss: 0.445735, acc.: 81.25%] [G loss: 0.862628]\n",
      "epoch:10 step:10277 [D loss: 0.576662, acc.: 68.75%] [G loss: 0.728228]\n",
      "epoch:10 step:10278 [D loss: 0.565948, acc.: 75.00%] [G loss: 0.534753]\n",
      "epoch:10 step:10279 [D loss: 0.547786, acc.: 66.41%] [G loss: 0.604942]\n",
      "epoch:10 step:10280 [D loss: 0.532241, acc.: 74.22%] [G loss: 0.613431]\n",
      "epoch:10 step:10281 [D loss: 0.461088, acc.: 79.69%] [G loss: 0.674874]\n",
      "epoch:10 step:10282 [D loss: 0.467107, acc.: 77.34%] [G loss: 0.688235]\n",
      "epoch:10 step:10283 [D loss: 0.499232, acc.: 76.56%] [G loss: 0.733812]\n",
      "epoch:10 step:10284 [D loss: 0.417462, acc.: 81.25%] [G loss: 0.879690]\n",
      "epoch:10 step:10285 [D loss: 0.614883, acc.: 65.62%] [G loss: 0.742803]\n",
      "epoch:10 step:10286 [D loss: 0.495276, acc.: 76.56%] [G loss: 0.800836]\n",
      "epoch:10 step:10287 [D loss: 0.565169, acc.: 64.84%] [G loss: 0.582651]\n",
      "epoch:10 step:10288 [D loss: 0.484528, acc.: 82.81%] [G loss: 0.779921]\n",
      "epoch:10 step:10289 [D loss: 0.453515, acc.: 84.38%] [G loss: 0.812246]\n",
      "epoch:10 step:10290 [D loss: 0.744763, acc.: 56.25%] [G loss: 0.548515]\n",
      "epoch:10 step:10291 [D loss: 0.457434, acc.: 79.69%] [G loss: 0.464357]\n",
      "epoch:10 step:10292 [D loss: 0.455579, acc.: 80.47%] [G loss: 0.647806]\n",
      "epoch:10 step:10293 [D loss: 0.443212, acc.: 80.47%] [G loss: 0.691401]\n",
      "epoch:10 step:10294 [D loss: 0.455541, acc.: 77.34%] [G loss: 0.811827]\n",
      "epoch:10 step:10295 [D loss: 0.412982, acc.: 78.12%] [G loss: 0.993264]\n",
      "epoch:10 step:10296 [D loss: 0.477461, acc.: 73.44%] [G loss: 0.977196]\n",
      "epoch:10 step:10297 [D loss: 0.486743, acc.: 73.44%] [G loss: 1.049567]\n",
      "epoch:10 step:10298 [D loss: 0.749309, acc.: 63.28%] [G loss: 0.755188]\n",
      "epoch:10 step:10299 [D loss: 0.586245, acc.: 67.19%] [G loss: 0.868280]\n",
      "epoch:10 step:10300 [D loss: 0.528688, acc.: 72.66%] [G loss: 1.041711]\n",
      "epoch:10 step:10301 [D loss: 0.494359, acc.: 75.00%] [G loss: 1.006697]\n",
      "epoch:10 step:10302 [D loss: 0.592552, acc.: 67.19%] [G loss: 0.579037]\n",
      "epoch:10 step:10303 [D loss: 0.482704, acc.: 75.00%] [G loss: 0.822993]\n",
      "epoch:10 step:10304 [D loss: 0.608872, acc.: 67.19%] [G loss: 0.709407]\n",
      "epoch:10 step:10305 [D loss: 0.452792, acc.: 80.47%] [G loss: 0.798005]\n",
      "epoch:10 step:10306 [D loss: 0.429677, acc.: 78.12%] [G loss: 1.075083]\n",
      "epoch:10 step:10307 [D loss: 0.423360, acc.: 84.38%] [G loss: 1.091025]\n",
      "epoch:11 step:10308 [D loss: 0.556855, acc.: 71.88%] [G loss: 0.914672]\n",
      "epoch:11 step:10309 [D loss: 0.483353, acc.: 75.78%] [G loss: 0.916237]\n",
      "epoch:11 step:10310 [D loss: 0.626167, acc.: 62.50%] [G loss: 0.653862]\n",
      "epoch:11 step:10311 [D loss: 0.514948, acc.: 70.31%] [G loss: 0.578856]\n",
      "epoch:11 step:10312 [D loss: 0.566087, acc.: 69.53%] [G loss: 0.634279]\n",
      "epoch:11 step:10313 [D loss: 0.589169, acc.: 68.75%] [G loss: 0.601302]\n",
      "epoch:11 step:10314 [D loss: 0.490767, acc.: 76.56%] [G loss: 0.852151]\n",
      "epoch:11 step:10315 [D loss: 0.591012, acc.: 71.88%] [G loss: 0.593747]\n",
      "epoch:11 step:10316 [D loss: 0.544730, acc.: 71.09%] [G loss: 0.699148]\n",
      "epoch:11 step:10317 [D loss: 0.576658, acc.: 69.53%] [G loss: 0.640227]\n",
      "epoch:11 step:10318 [D loss: 0.476810, acc.: 77.34%] [G loss: 0.789071]\n",
      "epoch:11 step:10319 [D loss: 0.570675, acc.: 70.31%] [G loss: 0.684509]\n",
      "epoch:11 step:10320 [D loss: 0.524635, acc.: 71.88%] [G loss: 0.589968]\n",
      "epoch:11 step:10321 [D loss: 0.566095, acc.: 74.22%] [G loss: 0.611719]\n",
      "epoch:11 step:10322 [D loss: 0.525800, acc.: 75.78%] [G loss: 0.535274]\n",
      "epoch:11 step:10323 [D loss: 0.494144, acc.: 77.34%] [G loss: 0.597469]\n",
      "epoch:11 step:10324 [D loss: 0.539158, acc.: 71.09%] [G loss: 0.703689]\n",
      "epoch:11 step:10325 [D loss: 0.602924, acc.: 62.50%] [G loss: 0.499198]\n",
      "epoch:11 step:10326 [D loss: 0.610488, acc.: 65.62%] [G loss: 0.627828]\n",
      "epoch:11 step:10327 [D loss: 0.653900, acc.: 57.03%] [G loss: 0.524277]\n",
      "epoch:11 step:10328 [D loss: 0.608745, acc.: 60.16%] [G loss: 0.472377]\n",
      "epoch:11 step:10329 [D loss: 0.423646, acc.: 81.25%] [G loss: 0.838372]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10330 [D loss: 0.570748, acc.: 67.97%] [G loss: 0.470662]\n",
      "epoch:11 step:10331 [D loss: 0.572282, acc.: 70.31%] [G loss: 0.598397]\n",
      "epoch:11 step:10332 [D loss: 0.507810, acc.: 77.34%] [G loss: 0.460659]\n",
      "epoch:11 step:10333 [D loss: 0.560173, acc.: 67.97%] [G loss: 0.589031]\n",
      "epoch:11 step:10334 [D loss: 0.485843, acc.: 72.66%] [G loss: 0.608646]\n",
      "epoch:11 step:10335 [D loss: 0.582485, acc.: 67.97%] [G loss: 0.513202]\n",
      "epoch:11 step:10336 [D loss: 0.551851, acc.: 71.09%] [G loss: 0.445976]\n",
      "epoch:11 step:10337 [D loss: 0.598647, acc.: 67.19%] [G loss: 0.609307]\n",
      "epoch:11 step:10338 [D loss: 0.564783, acc.: 67.97%] [G loss: 0.584249]\n",
      "epoch:11 step:10339 [D loss: 0.548760, acc.: 71.88%] [G loss: 0.479504]\n",
      "epoch:11 step:10340 [D loss: 0.550352, acc.: 67.19%] [G loss: 0.470274]\n",
      "epoch:11 step:10341 [D loss: 0.515045, acc.: 73.44%] [G loss: 0.670116]\n",
      "epoch:11 step:10342 [D loss: 0.547914, acc.: 67.97%] [G loss: 0.625689]\n",
      "epoch:11 step:10343 [D loss: 0.506793, acc.: 73.44%] [G loss: 0.595672]\n",
      "epoch:11 step:10344 [D loss: 0.513747, acc.: 73.44%] [G loss: 0.566280]\n",
      "epoch:11 step:10345 [D loss: 0.598113, acc.: 71.88%] [G loss: 0.505240]\n",
      "epoch:11 step:10346 [D loss: 0.579543, acc.: 70.31%] [G loss: 0.506614]\n",
      "epoch:11 step:10347 [D loss: 0.475153, acc.: 74.22%] [G loss: 0.642820]\n",
      "epoch:11 step:10348 [D loss: 0.516000, acc.: 71.88%] [G loss: 0.664651]\n",
      "epoch:11 step:10349 [D loss: 0.573652, acc.: 66.41%] [G loss: 0.699725]\n",
      "epoch:11 step:10350 [D loss: 0.578455, acc.: 65.62%] [G loss: 0.493367]\n",
      "epoch:11 step:10351 [D loss: 0.628400, acc.: 63.28%] [G loss: 0.483010]\n",
      "epoch:11 step:10352 [D loss: 0.566801, acc.: 73.44%] [G loss: 0.714399]\n",
      "epoch:11 step:10353 [D loss: 0.445889, acc.: 80.47%] [G loss: 0.747692]\n",
      "epoch:11 step:10354 [D loss: 0.541332, acc.: 71.09%] [G loss: 0.570070]\n",
      "epoch:11 step:10355 [D loss: 0.535452, acc.: 71.09%] [G loss: 0.615360]\n",
      "epoch:11 step:10356 [D loss: 0.501642, acc.: 79.69%] [G loss: 0.788133]\n",
      "epoch:11 step:10357 [D loss: 0.607388, acc.: 64.84%] [G loss: 0.628718]\n",
      "epoch:11 step:10358 [D loss: 0.676589, acc.: 63.28%] [G loss: 0.563602]\n",
      "epoch:11 step:10359 [D loss: 0.562973, acc.: 68.75%] [G loss: 0.642314]\n",
      "epoch:11 step:10360 [D loss: 0.501297, acc.: 75.00%] [G loss: 0.786799]\n",
      "epoch:11 step:10361 [D loss: 0.454627, acc.: 82.03%] [G loss: 0.658912]\n",
      "epoch:11 step:10362 [D loss: 0.528132, acc.: 66.41%] [G loss: 0.750048]\n",
      "epoch:11 step:10363 [D loss: 0.561640, acc.: 70.31%] [G loss: 0.471666]\n",
      "epoch:11 step:10364 [D loss: 0.520135, acc.: 72.66%] [G loss: 0.632667]\n",
      "epoch:11 step:10365 [D loss: 0.553726, acc.: 68.75%] [G loss: 0.492004]\n",
      "epoch:11 step:10366 [D loss: 0.527961, acc.: 71.09%] [G loss: 0.600797]\n",
      "epoch:11 step:10367 [D loss: 0.537582, acc.: 68.75%] [G loss: 0.619900]\n",
      "epoch:11 step:10368 [D loss: 0.581588, acc.: 70.31%] [G loss: 0.502421]\n",
      "epoch:11 step:10369 [D loss: 0.577685, acc.: 67.97%] [G loss: 0.519387]\n",
      "epoch:11 step:10370 [D loss: 0.551669, acc.: 69.53%] [G loss: 0.605652]\n",
      "epoch:11 step:10371 [D loss: 0.569532, acc.: 70.31%] [G loss: 0.605792]\n",
      "epoch:11 step:10372 [D loss: 0.534461, acc.: 70.31%] [G loss: 0.526195]\n",
      "epoch:11 step:10373 [D loss: 0.480269, acc.: 76.56%] [G loss: 0.548295]\n",
      "epoch:11 step:10374 [D loss: 0.570836, acc.: 71.09%] [G loss: 0.574639]\n",
      "epoch:11 step:10375 [D loss: 0.511835, acc.: 71.09%] [G loss: 0.563936]\n",
      "epoch:11 step:10376 [D loss: 0.528868, acc.: 72.66%] [G loss: 0.611068]\n",
      "epoch:11 step:10377 [D loss: 0.531628, acc.: 74.22%] [G loss: 0.559900]\n",
      "epoch:11 step:10378 [D loss: 0.560175, acc.: 65.62%] [G loss: 0.461258]\n",
      "epoch:11 step:10379 [D loss: 0.552106, acc.: 67.19%] [G loss: 0.436098]\n",
      "epoch:11 step:10380 [D loss: 0.564464, acc.: 69.53%] [G loss: 0.496591]\n",
      "epoch:11 step:10381 [D loss: 0.499927, acc.: 79.69%] [G loss: 0.553556]\n",
      "epoch:11 step:10382 [D loss: 0.577791, acc.: 62.50%] [G loss: 0.647805]\n",
      "epoch:11 step:10383 [D loss: 0.549537, acc.: 69.53%] [G loss: 0.703286]\n",
      "epoch:11 step:10384 [D loss: 0.474713, acc.: 74.22%] [G loss: 0.968779]\n",
      "epoch:11 step:10385 [D loss: 0.570734, acc.: 68.75%] [G loss: 0.576420]\n",
      "epoch:11 step:10386 [D loss: 0.527685, acc.: 78.12%] [G loss: 0.555022]\n",
      "epoch:11 step:10387 [D loss: 0.542911, acc.: 67.97%] [G loss: 0.664362]\n",
      "epoch:11 step:10388 [D loss: 0.543290, acc.: 68.75%] [G loss: 0.644163]\n",
      "epoch:11 step:10389 [D loss: 0.528525, acc.: 71.09%] [G loss: 0.590794]\n",
      "epoch:11 step:10390 [D loss: 0.513709, acc.: 71.09%] [G loss: 0.631760]\n",
      "epoch:11 step:10391 [D loss: 0.538273, acc.: 67.97%] [G loss: 0.657070]\n",
      "epoch:11 step:10392 [D loss: 0.578150, acc.: 67.97%] [G loss: 0.542042]\n",
      "epoch:11 step:10393 [D loss: 0.531137, acc.: 71.88%] [G loss: 0.483365]\n",
      "epoch:11 step:10394 [D loss: 0.544177, acc.: 71.88%] [G loss: 0.612964]\n",
      "epoch:11 step:10395 [D loss: 0.509336, acc.: 73.44%] [G loss: 0.513125]\n",
      "epoch:11 step:10396 [D loss: 0.511826, acc.: 71.09%] [G loss: 0.665900]\n",
      "epoch:11 step:10397 [D loss: 0.518299, acc.: 71.88%] [G loss: 0.658929]\n",
      "epoch:11 step:10398 [D loss: 0.551030, acc.: 71.88%] [G loss: 0.734351]\n",
      "epoch:11 step:10399 [D loss: 0.505045, acc.: 76.56%] [G loss: 0.567039]\n",
      "epoch:11 step:10400 [D loss: 0.513571, acc.: 74.22%] [G loss: 0.631710]\n",
      "##############\n",
      "[2.87119186 1.17528131 6.13494012 4.9030349  3.97665027 5.74651411\n",
      " 4.88997126 5.15382722 4.62262117 4.21487783]\n",
      "##########\n",
      "epoch:11 step:10401 [D loss: 0.507535, acc.: 71.09%] [G loss: 0.742899]\n",
      "epoch:11 step:10402 [D loss: 0.561882, acc.: 66.41%] [G loss: 0.613985]\n",
      "epoch:11 step:10403 [D loss: 0.562771, acc.: 69.53%] [G loss: 0.590924]\n",
      "epoch:11 step:10404 [D loss: 0.502738, acc.: 75.00%] [G loss: 0.694038]\n",
      "epoch:11 step:10405 [D loss: 0.563646, acc.: 73.44%] [G loss: 0.702130]\n",
      "epoch:11 step:10406 [D loss: 0.508105, acc.: 75.00%] [G loss: 0.544063]\n",
      "epoch:11 step:10407 [D loss: 0.465165, acc.: 78.91%] [G loss: 0.575045]\n",
      "epoch:11 step:10408 [D loss: 0.458188, acc.: 77.34%] [G loss: 0.699001]\n",
      "epoch:11 step:10409 [D loss: 0.626024, acc.: 60.16%] [G loss: 0.460139]\n",
      "epoch:11 step:10410 [D loss: 0.513248, acc.: 70.31%] [G loss: 0.531571]\n",
      "epoch:11 step:10411 [D loss: 0.490005, acc.: 73.44%] [G loss: 0.628149]\n",
      "epoch:11 step:10412 [D loss: 0.613052, acc.: 63.28%] [G loss: 0.563923]\n",
      "epoch:11 step:10413 [D loss: 0.545363, acc.: 68.75%] [G loss: 0.687649]\n",
      "epoch:11 step:10414 [D loss: 0.577667, acc.: 70.31%] [G loss: 0.615323]\n",
      "epoch:11 step:10415 [D loss: 0.634630, acc.: 65.62%] [G loss: 0.608972]\n",
      "epoch:11 step:10416 [D loss: 0.617688, acc.: 62.50%] [G loss: 0.568694]\n",
      "epoch:11 step:10417 [D loss: 0.583513, acc.: 66.41%] [G loss: 0.576959]\n",
      "epoch:11 step:10418 [D loss: 0.484600, acc.: 74.22%] [G loss: 0.657491]\n",
      "epoch:11 step:10419 [D loss: 0.533186, acc.: 70.31%] [G loss: 0.493864]\n",
      "epoch:11 step:10420 [D loss: 0.554557, acc.: 74.22%] [G loss: 0.540159]\n",
      "epoch:11 step:10421 [D loss: 0.585694, acc.: 67.97%] [G loss: 0.623951]\n",
      "epoch:11 step:10422 [D loss: 0.515524, acc.: 75.78%] [G loss: 0.654125]\n",
      "epoch:11 step:10423 [D loss: 0.543636, acc.: 67.97%] [G loss: 0.610449]\n",
      "epoch:11 step:10424 [D loss: 0.574332, acc.: 66.41%] [G loss: 0.496671]\n",
      "epoch:11 step:10425 [D loss: 0.548741, acc.: 72.66%] [G loss: 0.613839]\n",
      "epoch:11 step:10426 [D loss: 0.524537, acc.: 73.44%] [G loss: 0.673321]\n",
      "epoch:11 step:10427 [D loss: 0.542797, acc.: 70.31%] [G loss: 0.659052]\n",
      "epoch:11 step:10428 [D loss: 0.508965, acc.: 74.22%] [G loss: 0.605418]\n",
      "epoch:11 step:10429 [D loss: 0.477908, acc.: 77.34%] [G loss: 0.664582]\n",
      "epoch:11 step:10430 [D loss: 0.516346, acc.: 75.00%] [G loss: 0.670405]\n",
      "epoch:11 step:10431 [D loss: 0.538369, acc.: 70.31%] [G loss: 0.608032]\n",
      "epoch:11 step:10432 [D loss: 0.533010, acc.: 69.53%] [G loss: 0.695185]\n",
      "epoch:11 step:10433 [D loss: 0.516636, acc.: 73.44%] [G loss: 0.652058]\n",
      "epoch:11 step:10434 [D loss: 0.525682, acc.: 70.31%] [G loss: 0.571135]\n",
      "epoch:11 step:10435 [D loss: 0.499840, acc.: 69.53%] [G loss: 0.527535]\n",
      "epoch:11 step:10436 [D loss: 0.554097, acc.: 71.09%] [G loss: 0.500305]\n",
      "epoch:11 step:10437 [D loss: 0.548321, acc.: 68.75%] [G loss: 0.554478]\n",
      "epoch:11 step:10438 [D loss: 0.492791, acc.: 77.34%] [G loss: 0.702091]\n",
      "epoch:11 step:10439 [D loss: 0.636535, acc.: 62.50%] [G loss: 0.739489]\n",
      "epoch:11 step:10440 [D loss: 0.603206, acc.: 67.97%] [G loss: 0.862288]\n",
      "epoch:11 step:10441 [D loss: 0.542904, acc.: 66.41%] [G loss: 0.683987]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10442 [D loss: 0.550542, acc.: 65.62%] [G loss: 0.534903]\n",
      "epoch:11 step:10443 [D loss: 0.619791, acc.: 67.97%] [G loss: 0.629589]\n",
      "epoch:11 step:10444 [D loss: 0.641165, acc.: 60.16%] [G loss: 0.634001]\n",
      "epoch:11 step:10445 [D loss: 0.560375, acc.: 72.66%] [G loss: 0.544712]\n",
      "epoch:11 step:10446 [D loss: 0.554588, acc.: 66.41%] [G loss: 0.507216]\n",
      "epoch:11 step:10447 [D loss: 0.530584, acc.: 71.09%] [G loss: 0.628758]\n",
      "epoch:11 step:10448 [D loss: 0.515788, acc.: 70.31%] [G loss: 0.529423]\n",
      "epoch:11 step:10449 [D loss: 0.547870, acc.: 67.97%] [G loss: 0.487514]\n",
      "epoch:11 step:10450 [D loss: 0.618338, acc.: 62.50%] [G loss: 0.567815]\n",
      "epoch:11 step:10451 [D loss: 0.516979, acc.: 73.44%] [G loss: 0.442967]\n",
      "epoch:11 step:10452 [D loss: 0.537903, acc.: 70.31%] [G loss: 0.501234]\n",
      "epoch:11 step:10453 [D loss: 0.482930, acc.: 76.56%] [G loss: 0.498519]\n",
      "epoch:11 step:10454 [D loss: 0.638588, acc.: 69.53%] [G loss: 0.524543]\n",
      "epoch:11 step:10455 [D loss: 0.567455, acc.: 67.97%] [G loss: 0.610084]\n",
      "epoch:11 step:10456 [D loss: 0.438219, acc.: 80.47%] [G loss: 0.590863]\n",
      "epoch:11 step:10457 [D loss: 0.617378, acc.: 70.31%] [G loss: 0.648512]\n",
      "epoch:11 step:10458 [D loss: 0.592103, acc.: 69.53%] [G loss: 0.488514]\n",
      "epoch:11 step:10459 [D loss: 0.531326, acc.: 69.53%] [G loss: 0.632703]\n",
      "epoch:11 step:10460 [D loss: 0.553397, acc.: 67.19%] [G loss: 0.651719]\n",
      "epoch:11 step:10461 [D loss: 0.513279, acc.: 73.44%] [G loss: 0.617973]\n",
      "epoch:11 step:10462 [D loss: 0.511705, acc.: 75.78%] [G loss: 0.909744]\n",
      "epoch:11 step:10463 [D loss: 0.543322, acc.: 72.66%] [G loss: 0.725828]\n",
      "epoch:11 step:10464 [D loss: 0.530882, acc.: 71.09%] [G loss: 0.685818]\n",
      "epoch:11 step:10465 [D loss: 0.540451, acc.: 69.53%] [G loss: 0.518121]\n",
      "epoch:11 step:10466 [D loss: 0.565118, acc.: 66.41%] [G loss: 0.702811]\n",
      "epoch:11 step:10467 [D loss: 0.634495, acc.: 64.06%] [G loss: 0.574029]\n",
      "epoch:11 step:10468 [D loss: 0.495530, acc.: 77.34%] [G loss: 0.813897]\n",
      "epoch:11 step:10469 [D loss: 0.471570, acc.: 75.00%] [G loss: 0.762189]\n",
      "epoch:11 step:10470 [D loss: 0.564208, acc.: 68.75%] [G loss: 0.720741]\n",
      "epoch:11 step:10471 [D loss: 0.545291, acc.: 70.31%] [G loss: 0.665816]\n",
      "epoch:11 step:10472 [D loss: 0.501362, acc.: 75.00%] [G loss: 0.510851]\n",
      "epoch:11 step:10473 [D loss: 0.600721, acc.: 65.62%] [G loss: 0.472526]\n",
      "epoch:11 step:10474 [D loss: 0.543981, acc.: 67.19%] [G loss: 0.584805]\n",
      "epoch:11 step:10475 [D loss: 0.536233, acc.: 69.53%] [G loss: 0.533159]\n",
      "epoch:11 step:10476 [D loss: 0.605884, acc.: 64.06%] [G loss: 0.459376]\n",
      "epoch:11 step:10477 [D loss: 0.562545, acc.: 66.41%] [G loss: 0.471382]\n",
      "epoch:11 step:10478 [D loss: 0.511584, acc.: 75.78%] [G loss: 0.509375]\n",
      "epoch:11 step:10479 [D loss: 0.537562, acc.: 72.66%] [G loss: 0.598701]\n",
      "epoch:11 step:10480 [D loss: 0.467591, acc.: 78.91%] [G loss: 0.641938]\n",
      "epoch:11 step:10481 [D loss: 0.580234, acc.: 68.75%] [G loss: 0.538398]\n",
      "epoch:11 step:10482 [D loss: 0.553327, acc.: 71.88%] [G loss: 0.541610]\n",
      "epoch:11 step:10483 [D loss: 0.589211, acc.: 68.75%] [G loss: 0.554878]\n",
      "epoch:11 step:10484 [D loss: 0.542192, acc.: 71.88%] [G loss: 0.610158]\n",
      "epoch:11 step:10485 [D loss: 0.630382, acc.: 61.72%] [G loss: 0.431120]\n",
      "epoch:11 step:10486 [D loss: 0.587643, acc.: 65.62%] [G loss: 0.597376]\n",
      "epoch:11 step:10487 [D loss: 0.605931, acc.: 67.97%] [G loss: 0.508791]\n",
      "epoch:11 step:10488 [D loss: 0.596400, acc.: 66.41%] [G loss: 0.470808]\n",
      "epoch:11 step:10489 [D loss: 0.565020, acc.: 66.41%] [G loss: 0.678469]\n",
      "epoch:11 step:10490 [D loss: 0.659379, acc.: 64.06%] [G loss: 0.611921]\n",
      "epoch:11 step:10491 [D loss: 0.541280, acc.: 70.31%] [G loss: 0.608424]\n",
      "epoch:11 step:10492 [D loss: 0.497896, acc.: 78.12%] [G loss: 0.663209]\n",
      "epoch:11 step:10493 [D loss: 0.510187, acc.: 77.34%] [G loss: 0.478586]\n",
      "epoch:11 step:10494 [D loss: 0.585873, acc.: 65.62%] [G loss: 0.521065]\n",
      "epoch:11 step:10495 [D loss: 0.621852, acc.: 59.38%] [G loss: 0.515679]\n",
      "epoch:11 step:10496 [D loss: 0.599862, acc.: 63.28%] [G loss: 0.491561]\n",
      "epoch:11 step:10497 [D loss: 0.471761, acc.: 78.91%] [G loss: 0.610749]\n",
      "epoch:11 step:10498 [D loss: 0.493645, acc.: 76.56%] [G loss: 0.608746]\n",
      "epoch:11 step:10499 [D loss: 0.520961, acc.: 73.44%] [G loss: 0.581286]\n",
      "epoch:11 step:10500 [D loss: 0.542650, acc.: 71.88%] [G loss: 0.561707]\n",
      "epoch:11 step:10501 [D loss: 0.472089, acc.: 80.47%] [G loss: 0.637935]\n",
      "epoch:11 step:10502 [D loss: 0.583085, acc.: 67.19%] [G loss: 0.662117]\n",
      "epoch:11 step:10503 [D loss: 0.522878, acc.: 68.75%] [G loss: 0.694326]\n",
      "epoch:11 step:10504 [D loss: 0.509048, acc.: 75.00%] [G loss: 0.575117]\n",
      "epoch:11 step:10505 [D loss: 0.465776, acc.: 78.91%] [G loss: 0.555699]\n",
      "epoch:11 step:10506 [D loss: 0.544593, acc.: 67.19%] [G loss: 0.591398]\n",
      "epoch:11 step:10507 [D loss: 0.619040, acc.: 64.84%] [G loss: 0.522142]\n",
      "epoch:11 step:10508 [D loss: 0.578749, acc.: 67.97%] [G loss: 0.554936]\n",
      "epoch:11 step:10509 [D loss: 0.568054, acc.: 69.53%] [G loss: 0.530136]\n",
      "epoch:11 step:10510 [D loss: 0.689626, acc.: 58.59%] [G loss: 0.464048]\n",
      "epoch:11 step:10511 [D loss: 0.568575, acc.: 70.31%] [G loss: 0.527723]\n",
      "epoch:11 step:10512 [D loss: 0.494335, acc.: 72.66%] [G loss: 0.738593]\n",
      "epoch:11 step:10513 [D loss: 0.519551, acc.: 71.09%] [G loss: 0.649968]\n",
      "epoch:11 step:10514 [D loss: 0.486679, acc.: 77.34%] [G loss: 0.711469]\n",
      "epoch:11 step:10515 [D loss: 0.452851, acc.: 78.91%] [G loss: 0.708491]\n",
      "epoch:11 step:10516 [D loss: 0.489246, acc.: 74.22%] [G loss: 0.709032]\n",
      "epoch:11 step:10517 [D loss: 0.601541, acc.: 67.19%] [G loss: 0.517978]\n",
      "epoch:11 step:10518 [D loss: 0.602349, acc.: 64.84%] [G loss: 0.471079]\n",
      "epoch:11 step:10519 [D loss: 0.542460, acc.: 70.31%] [G loss: 0.568377]\n",
      "epoch:11 step:10520 [D loss: 0.512381, acc.: 72.66%] [G loss: 0.570111]\n",
      "epoch:11 step:10521 [D loss: 0.641627, acc.: 64.84%] [G loss: 0.567925]\n",
      "epoch:11 step:10522 [D loss: 0.611724, acc.: 64.06%] [G loss: 0.383761]\n",
      "epoch:11 step:10523 [D loss: 0.556422, acc.: 65.62%] [G loss: 0.511546]\n",
      "epoch:11 step:10524 [D loss: 0.539674, acc.: 73.44%] [G loss: 0.462855]\n",
      "epoch:11 step:10525 [D loss: 0.546710, acc.: 70.31%] [G loss: 0.573578]\n",
      "epoch:11 step:10526 [D loss: 0.500247, acc.: 74.22%] [G loss: 0.456105]\n",
      "epoch:11 step:10527 [D loss: 0.628059, acc.: 64.06%] [G loss: 0.486017]\n",
      "epoch:11 step:10528 [D loss: 0.565668, acc.: 70.31%] [G loss: 0.484076]\n",
      "epoch:11 step:10529 [D loss: 0.493309, acc.: 72.66%] [G loss: 0.697862]\n",
      "epoch:11 step:10530 [D loss: 0.543362, acc.: 72.66%] [G loss: 0.679416]\n",
      "epoch:11 step:10531 [D loss: 0.582352, acc.: 69.53%] [G loss: 0.530575]\n",
      "epoch:11 step:10532 [D loss: 0.560571, acc.: 68.75%] [G loss: 0.625514]\n",
      "epoch:11 step:10533 [D loss: 0.589025, acc.: 65.62%] [G loss: 0.468328]\n",
      "epoch:11 step:10534 [D loss: 0.598794, acc.: 64.06%] [G loss: 0.419101]\n",
      "epoch:11 step:10535 [D loss: 0.587747, acc.: 64.06%] [G loss: 0.468409]\n",
      "epoch:11 step:10536 [D loss: 0.526984, acc.: 75.78%] [G loss: 0.646988]\n",
      "epoch:11 step:10537 [D loss: 0.561282, acc.: 66.41%] [G loss: 0.724347]\n",
      "epoch:11 step:10538 [D loss: 0.459492, acc.: 78.91%] [G loss: 0.852479]\n",
      "epoch:11 step:10539 [D loss: 0.499951, acc.: 75.00%] [G loss: 0.882632]\n",
      "epoch:11 step:10540 [D loss: 0.604145, acc.: 64.84%] [G loss: 0.638818]\n",
      "epoch:11 step:10541 [D loss: 0.545058, acc.: 70.31%] [G loss: 0.662688]\n",
      "epoch:11 step:10542 [D loss: 0.584186, acc.: 68.75%] [G loss: 0.536275]\n",
      "epoch:11 step:10543 [D loss: 0.587892, acc.: 66.41%] [G loss: 0.465974]\n",
      "epoch:11 step:10544 [D loss: 0.562897, acc.: 65.62%] [G loss: 0.525539]\n",
      "epoch:11 step:10545 [D loss: 0.601131, acc.: 67.19%] [G loss: 0.480720]\n",
      "epoch:11 step:10546 [D loss: 0.528489, acc.: 72.66%] [G loss: 0.609756]\n",
      "epoch:11 step:10547 [D loss: 0.557514, acc.: 69.53%] [G loss: 0.540333]\n",
      "epoch:11 step:10548 [D loss: 0.509102, acc.: 74.22%] [G loss: 0.638896]\n",
      "epoch:11 step:10549 [D loss: 0.499922, acc.: 74.22%] [G loss: 0.661023]\n",
      "epoch:11 step:10550 [D loss: 0.586763, acc.: 64.84%] [G loss: 0.664597]\n",
      "epoch:11 step:10551 [D loss: 0.487277, acc.: 70.31%] [G loss: 0.702014]\n",
      "epoch:11 step:10552 [D loss: 0.583638, acc.: 70.31%] [G loss: 0.686519]\n",
      "epoch:11 step:10553 [D loss: 0.541964, acc.: 71.88%] [G loss: 0.688015]\n",
      "epoch:11 step:10554 [D loss: 0.556516, acc.: 71.88%] [G loss: 0.746347]\n",
      "epoch:11 step:10555 [D loss: 0.507931, acc.: 70.31%] [G loss: 0.618939]\n",
      "epoch:11 step:10556 [D loss: 0.591663, acc.: 65.62%] [G loss: 0.661647]\n",
      "epoch:11 step:10557 [D loss: 0.637859, acc.: 61.72%] [G loss: 0.560708]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10558 [D loss: 0.672919, acc.: 56.25%] [G loss: 0.653091]\n",
      "epoch:11 step:10559 [D loss: 0.536211, acc.: 72.66%] [G loss: 0.557403]\n",
      "epoch:11 step:10560 [D loss: 0.581296, acc.: 71.09%] [G loss: 0.588655]\n",
      "epoch:11 step:10561 [D loss: 0.510525, acc.: 71.88%] [G loss: 0.473177]\n",
      "epoch:11 step:10562 [D loss: 0.532341, acc.: 75.78%] [G loss: 0.563452]\n",
      "epoch:11 step:10563 [D loss: 0.580114, acc.: 68.75%] [G loss: 0.594174]\n",
      "epoch:11 step:10564 [D loss: 0.617250, acc.: 59.38%] [G loss: 0.438279]\n",
      "epoch:11 step:10565 [D loss: 0.521994, acc.: 70.31%] [G loss: 0.504835]\n",
      "epoch:11 step:10566 [D loss: 0.528265, acc.: 71.88%] [G loss: 0.555432]\n",
      "epoch:11 step:10567 [D loss: 0.577551, acc.: 71.09%] [G loss: 0.488339]\n",
      "epoch:11 step:10568 [D loss: 0.466418, acc.: 77.34%] [G loss: 0.556104]\n",
      "epoch:11 step:10569 [D loss: 0.560821, acc.: 69.53%] [G loss: 0.565906]\n",
      "epoch:11 step:10570 [D loss: 0.614902, acc.: 64.84%] [G loss: 0.511733]\n",
      "epoch:11 step:10571 [D loss: 0.520286, acc.: 72.66%] [G loss: 0.616925]\n",
      "epoch:11 step:10572 [D loss: 0.519936, acc.: 72.66%] [G loss: 0.602975]\n",
      "epoch:11 step:10573 [D loss: 0.545021, acc.: 75.00%] [G loss: 0.622469]\n",
      "epoch:11 step:10574 [D loss: 0.550802, acc.: 70.31%] [G loss: 0.494162]\n",
      "epoch:11 step:10575 [D loss: 0.562535, acc.: 71.88%] [G loss: 0.516038]\n",
      "epoch:11 step:10576 [D loss: 0.591206, acc.: 65.62%] [G loss: 0.684675]\n",
      "epoch:11 step:10577 [D loss: 0.541893, acc.: 72.66%] [G loss: 0.633255]\n",
      "epoch:11 step:10578 [D loss: 0.535181, acc.: 71.88%] [G loss: 0.512714]\n",
      "epoch:11 step:10579 [D loss: 0.534894, acc.: 70.31%] [G loss: 0.596208]\n",
      "epoch:11 step:10580 [D loss: 0.498124, acc.: 74.22%] [G loss: 0.586664]\n",
      "epoch:11 step:10581 [D loss: 0.530277, acc.: 73.44%] [G loss: 0.592824]\n",
      "epoch:11 step:10582 [D loss: 0.566348, acc.: 68.75%] [G loss: 0.517525]\n",
      "epoch:11 step:10583 [D loss: 0.488003, acc.: 76.56%] [G loss: 0.549364]\n",
      "epoch:11 step:10584 [D loss: 0.669439, acc.: 56.25%] [G loss: 0.452465]\n",
      "epoch:11 step:10585 [D loss: 0.609019, acc.: 64.84%] [G loss: 0.419153]\n",
      "epoch:11 step:10586 [D loss: 0.506791, acc.: 74.22%] [G loss: 0.589344]\n",
      "epoch:11 step:10587 [D loss: 0.522339, acc.: 64.06%] [G loss: 0.616250]\n",
      "epoch:11 step:10588 [D loss: 0.614055, acc.: 67.97%] [G loss: 0.485130]\n",
      "epoch:11 step:10589 [D loss: 0.566327, acc.: 66.41%] [G loss: 0.497403]\n",
      "epoch:11 step:10590 [D loss: 0.490797, acc.: 71.88%] [G loss: 0.615567]\n",
      "epoch:11 step:10591 [D loss: 0.526401, acc.: 71.09%] [G loss: 0.733290]\n",
      "epoch:11 step:10592 [D loss: 0.514823, acc.: 73.44%] [G loss: 0.598226]\n",
      "epoch:11 step:10593 [D loss: 0.497599, acc.: 71.09%] [G loss: 0.675493]\n",
      "epoch:11 step:10594 [D loss: 0.616134, acc.: 60.94%] [G loss: 0.579827]\n",
      "epoch:11 step:10595 [D loss: 0.619976, acc.: 65.62%] [G loss: 0.635894]\n",
      "epoch:11 step:10596 [D loss: 0.525452, acc.: 70.31%] [G loss: 0.704165]\n",
      "epoch:11 step:10597 [D loss: 0.536057, acc.: 73.44%] [G loss: 0.735666]\n",
      "epoch:11 step:10598 [D loss: 0.580751, acc.: 66.41%] [G loss: 0.580199]\n",
      "epoch:11 step:10599 [D loss: 0.535189, acc.: 72.66%] [G loss: 0.493875]\n",
      "epoch:11 step:10600 [D loss: 0.597346, acc.: 65.62%] [G loss: 0.630487]\n",
      "##############\n",
      "[2.99261272 0.50864591 6.36480839 4.84904789 3.88633516 5.84995441\n",
      " 4.70878625 4.88517938 4.7675069  4.18852201]\n",
      "##########\n",
      "epoch:11 step:10601 [D loss: 0.696815, acc.: 60.94%] [G loss: 0.428581]\n",
      "epoch:11 step:10602 [D loss: 0.571700, acc.: 71.88%] [G loss: 0.565754]\n",
      "epoch:11 step:10603 [D loss: 0.470337, acc.: 77.34%] [G loss: 0.550252]\n",
      "epoch:11 step:10604 [D loss: 0.524143, acc.: 75.00%] [G loss: 0.474973]\n",
      "epoch:11 step:10605 [D loss: 0.483759, acc.: 77.34%] [G loss: 0.582989]\n",
      "epoch:11 step:10606 [D loss: 0.497461, acc.: 71.09%] [G loss: 0.781288]\n",
      "epoch:11 step:10607 [D loss: 0.525824, acc.: 72.66%] [G loss: 0.745314]\n",
      "epoch:11 step:10608 [D loss: 0.577936, acc.: 71.88%] [G loss: 0.804882]\n",
      "epoch:11 step:10609 [D loss: 0.580531, acc.: 70.31%] [G loss: 0.543136]\n",
      "epoch:11 step:10610 [D loss: 0.542695, acc.: 73.44%] [G loss: 0.613811]\n",
      "epoch:11 step:10611 [D loss: 0.468779, acc.: 82.81%] [G loss: 0.702942]\n",
      "epoch:11 step:10612 [D loss: 0.533695, acc.: 72.66%] [G loss: 0.636161]\n",
      "epoch:11 step:10613 [D loss: 0.568223, acc.: 64.06%] [G loss: 0.543303]\n",
      "epoch:11 step:10614 [D loss: 0.537728, acc.: 71.88%] [G loss: 0.545946]\n",
      "epoch:11 step:10615 [D loss: 0.565200, acc.: 67.97%] [G loss: 0.634489]\n",
      "epoch:11 step:10616 [D loss: 0.489457, acc.: 73.44%] [G loss: 0.735702]\n",
      "epoch:11 step:10617 [D loss: 0.531567, acc.: 75.00%] [G loss: 0.705566]\n",
      "epoch:11 step:10618 [D loss: 0.447957, acc.: 82.03%] [G loss: 0.684482]\n",
      "epoch:11 step:10619 [D loss: 0.547896, acc.: 72.66%] [G loss: 0.647958]\n",
      "epoch:11 step:10620 [D loss: 0.477330, acc.: 75.78%] [G loss: 0.855842]\n",
      "epoch:11 step:10621 [D loss: 0.417035, acc.: 82.81%] [G loss: 0.968709]\n",
      "epoch:11 step:10622 [D loss: 0.480382, acc.: 76.56%] [G loss: 0.865874]\n",
      "epoch:11 step:10623 [D loss: 0.688922, acc.: 62.50%] [G loss: 0.701804]\n",
      "epoch:11 step:10624 [D loss: 0.544435, acc.: 71.09%] [G loss: 0.533541]\n",
      "epoch:11 step:10625 [D loss: 0.603094, acc.: 66.41%] [G loss: 0.672545]\n",
      "epoch:11 step:10626 [D loss: 0.544885, acc.: 71.88%] [G loss: 0.707883]\n",
      "epoch:11 step:10627 [D loss: 0.595082, acc.: 64.84%] [G loss: 0.547843]\n",
      "epoch:11 step:10628 [D loss: 0.502303, acc.: 76.56%] [G loss: 0.599283]\n",
      "epoch:11 step:10629 [D loss: 0.571955, acc.: 67.97%] [G loss: 0.562742]\n",
      "epoch:11 step:10630 [D loss: 0.606084, acc.: 68.75%] [G loss: 0.485668]\n",
      "epoch:11 step:10631 [D loss: 0.573301, acc.: 69.53%] [G loss: 0.496372]\n",
      "epoch:11 step:10632 [D loss: 0.617472, acc.: 64.84%] [G loss: 0.487402]\n",
      "epoch:11 step:10633 [D loss: 0.511601, acc.: 74.22%] [G loss: 0.554525]\n",
      "epoch:11 step:10634 [D loss: 0.538429, acc.: 72.66%] [G loss: 0.540952]\n",
      "epoch:11 step:10635 [D loss: 0.504723, acc.: 74.22%] [G loss: 0.786361]\n",
      "epoch:11 step:10636 [D loss: 0.520539, acc.: 72.66%] [G loss: 0.610606]\n",
      "epoch:11 step:10637 [D loss: 0.551389, acc.: 65.62%] [G loss: 0.527608]\n",
      "epoch:11 step:10638 [D loss: 0.531273, acc.: 70.31%] [G loss: 0.509767]\n",
      "epoch:11 step:10639 [D loss: 0.539932, acc.: 69.53%] [G loss: 0.481158]\n",
      "epoch:11 step:10640 [D loss: 0.513169, acc.: 72.66%] [G loss: 0.572606]\n",
      "epoch:11 step:10641 [D loss: 0.514569, acc.: 75.00%] [G loss: 0.617339]\n",
      "epoch:11 step:10642 [D loss: 0.540827, acc.: 70.31%] [G loss: 0.652324]\n",
      "epoch:11 step:10643 [D loss: 0.517080, acc.: 76.56%] [G loss: 0.622560]\n",
      "epoch:11 step:10644 [D loss: 0.488351, acc.: 75.00%] [G loss: 0.624293]\n",
      "epoch:11 step:10645 [D loss: 0.535891, acc.: 69.53%] [G loss: 0.629492]\n",
      "epoch:11 step:10646 [D loss: 0.505150, acc.: 81.25%] [G loss: 0.694826]\n",
      "epoch:11 step:10647 [D loss: 0.510490, acc.: 78.12%] [G loss: 0.706771]\n",
      "epoch:11 step:10648 [D loss: 0.629294, acc.: 65.62%] [G loss: 0.643478]\n",
      "epoch:11 step:10649 [D loss: 0.671162, acc.: 60.16%] [G loss: 0.599144]\n",
      "epoch:11 step:10650 [D loss: 0.528095, acc.: 72.66%] [G loss: 0.573058]\n",
      "epoch:11 step:10651 [D loss: 0.475233, acc.: 72.66%] [G loss: 0.665863]\n",
      "epoch:11 step:10652 [D loss: 0.567629, acc.: 65.62%] [G loss: 0.798602]\n",
      "epoch:11 step:10653 [D loss: 0.551012, acc.: 67.19%] [G loss: 0.736025]\n",
      "epoch:11 step:10654 [D loss: 0.481631, acc.: 77.34%] [G loss: 0.907136]\n",
      "epoch:11 step:10655 [D loss: 0.681877, acc.: 62.50%] [G loss: 0.539856]\n",
      "epoch:11 step:10656 [D loss: 0.711074, acc.: 53.91%] [G loss: 0.581834]\n",
      "epoch:11 step:10657 [D loss: 0.523617, acc.: 71.09%] [G loss: 0.510059]\n",
      "epoch:11 step:10658 [D loss: 0.526929, acc.: 74.22%] [G loss: 0.639544]\n",
      "epoch:11 step:10659 [D loss: 0.550964, acc.: 71.09%] [G loss: 0.708827]\n",
      "epoch:11 step:10660 [D loss: 0.609328, acc.: 67.19%] [G loss: 0.748190]\n",
      "epoch:11 step:10661 [D loss: 0.416149, acc.: 79.69%] [G loss: 0.677563]\n",
      "epoch:11 step:10662 [D loss: 0.564083, acc.: 69.53%] [G loss: 0.731566]\n",
      "epoch:11 step:10663 [D loss: 0.567537, acc.: 68.75%] [G loss: 0.549147]\n",
      "epoch:11 step:10664 [D loss: 0.480662, acc.: 76.56%] [G loss: 0.589761]\n",
      "epoch:11 step:10665 [D loss: 0.477520, acc.: 79.69%] [G loss: 0.475302]\n",
      "epoch:11 step:10666 [D loss: 0.481189, acc.: 75.78%] [G loss: 0.741511]\n",
      "epoch:11 step:10667 [D loss: 0.493639, acc.: 74.22%] [G loss: 0.736779]\n",
      "epoch:11 step:10668 [D loss: 0.509751, acc.: 75.78%] [G loss: 0.615331]\n",
      "epoch:11 step:10669 [D loss: 0.557036, acc.: 70.31%] [G loss: 0.582758]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10670 [D loss: 0.506789, acc.: 78.91%] [G loss: 0.625198]\n",
      "epoch:11 step:10671 [D loss: 0.505265, acc.: 71.88%] [G loss: 0.643795]\n",
      "epoch:11 step:10672 [D loss: 0.578164, acc.: 64.84%] [G loss: 0.690994]\n",
      "epoch:11 step:10673 [D loss: 0.527264, acc.: 71.88%] [G loss: 0.551763]\n",
      "epoch:11 step:10674 [D loss: 0.607255, acc.: 63.28%] [G loss: 0.746134]\n",
      "epoch:11 step:10675 [D loss: 0.559304, acc.: 68.75%] [G loss: 0.517395]\n",
      "epoch:11 step:10676 [D loss: 0.588912, acc.: 68.75%] [G loss: 0.590958]\n",
      "epoch:11 step:10677 [D loss: 0.518606, acc.: 76.56%] [G loss: 0.581123]\n",
      "epoch:11 step:10678 [D loss: 0.553567, acc.: 74.22%] [G loss: 0.616135]\n",
      "epoch:11 step:10679 [D loss: 0.516468, acc.: 76.56%] [G loss: 0.667960]\n",
      "epoch:11 step:10680 [D loss: 0.588834, acc.: 69.53%] [G loss: 0.637373]\n",
      "epoch:11 step:10681 [D loss: 0.510037, acc.: 73.44%] [G loss: 0.584721]\n",
      "epoch:11 step:10682 [D loss: 0.563887, acc.: 72.66%] [G loss: 0.543069]\n",
      "epoch:11 step:10683 [D loss: 0.684049, acc.: 59.38%] [G loss: 0.373579]\n",
      "epoch:11 step:10684 [D loss: 0.604272, acc.: 65.62%] [G loss: 0.368577]\n",
      "epoch:11 step:10685 [D loss: 0.512766, acc.: 71.09%] [G loss: 0.560605]\n",
      "epoch:11 step:10686 [D loss: 0.535625, acc.: 75.00%] [G loss: 0.479068]\n",
      "epoch:11 step:10687 [D loss: 0.573656, acc.: 71.09%] [G loss: 0.417818]\n",
      "epoch:11 step:10688 [D loss: 0.470080, acc.: 77.34%] [G loss: 0.670194]\n",
      "epoch:11 step:10689 [D loss: 0.563969, acc.: 71.88%] [G loss: 0.550190]\n",
      "epoch:11 step:10690 [D loss: 0.554456, acc.: 71.09%] [G loss: 0.499371]\n",
      "epoch:11 step:10691 [D loss: 0.534647, acc.: 71.88%] [G loss: 0.662046]\n",
      "epoch:11 step:10692 [D loss: 0.526139, acc.: 71.09%] [G loss: 0.620685]\n",
      "epoch:11 step:10693 [D loss: 0.607733, acc.: 62.50%] [G loss: 0.561842]\n",
      "epoch:11 step:10694 [D loss: 0.616576, acc.: 64.84%] [G loss: 0.461947]\n",
      "epoch:11 step:10695 [D loss: 0.597623, acc.: 67.19%] [G loss: 0.588528]\n",
      "epoch:11 step:10696 [D loss: 0.507620, acc.: 75.00%] [G loss: 0.684423]\n",
      "epoch:11 step:10697 [D loss: 0.625945, acc.: 62.50%] [G loss: 0.540985]\n",
      "epoch:11 step:10698 [D loss: 0.547142, acc.: 68.75%] [G loss: 0.520606]\n",
      "epoch:11 step:10699 [D loss: 0.490449, acc.: 75.00%] [G loss: 0.609721]\n",
      "epoch:11 step:10700 [D loss: 0.615924, acc.: 64.84%] [G loss: 0.490496]\n",
      "epoch:11 step:10701 [D loss: 0.568713, acc.: 64.84%] [G loss: 0.560970]\n",
      "epoch:11 step:10702 [D loss: 0.502708, acc.: 75.78%] [G loss: 0.628049]\n",
      "epoch:11 step:10703 [D loss: 0.637861, acc.: 58.59%] [G loss: 0.561517]\n",
      "epoch:11 step:10704 [D loss: 0.561839, acc.: 72.66%] [G loss: 0.647802]\n",
      "epoch:11 step:10705 [D loss: 0.440063, acc.: 79.69%] [G loss: 0.715138]\n",
      "epoch:11 step:10706 [D loss: 0.561419, acc.: 73.44%] [G loss: 0.801820]\n",
      "epoch:11 step:10707 [D loss: 0.679493, acc.: 53.12%] [G loss: 0.582659]\n",
      "epoch:11 step:10708 [D loss: 0.605251, acc.: 64.84%] [G loss: 0.444751]\n",
      "epoch:11 step:10709 [D loss: 0.510473, acc.: 80.47%] [G loss: 0.483313]\n",
      "epoch:11 step:10710 [D loss: 0.504064, acc.: 73.44%] [G loss: 0.547988]\n",
      "epoch:11 step:10711 [D loss: 0.599809, acc.: 67.19%] [G loss: 0.547135]\n",
      "epoch:11 step:10712 [D loss: 0.556687, acc.: 74.22%] [G loss: 0.659356]\n",
      "epoch:11 step:10713 [D loss: 0.482337, acc.: 76.56%] [G loss: 0.696880]\n",
      "epoch:11 step:10714 [D loss: 0.565311, acc.: 69.53%] [G loss: 0.626359]\n",
      "epoch:11 step:10715 [D loss: 0.539557, acc.: 74.22%] [G loss: 0.565039]\n",
      "epoch:11 step:10716 [D loss: 0.522337, acc.: 70.31%] [G loss: 0.619035]\n",
      "epoch:11 step:10717 [D loss: 0.608021, acc.: 62.50%] [G loss: 0.610718]\n",
      "epoch:11 step:10718 [D loss: 0.564400, acc.: 66.41%] [G loss: 0.435373]\n",
      "epoch:11 step:10719 [D loss: 0.634823, acc.: 62.50%] [G loss: 0.508847]\n",
      "epoch:11 step:10720 [D loss: 0.517524, acc.: 76.56%] [G loss: 0.523810]\n",
      "epoch:11 step:10721 [D loss: 0.553895, acc.: 68.75%] [G loss: 0.582243]\n",
      "epoch:11 step:10722 [D loss: 0.627152, acc.: 63.28%] [G loss: 0.549513]\n",
      "epoch:11 step:10723 [D loss: 0.506183, acc.: 76.56%] [G loss: 0.768983]\n",
      "epoch:11 step:10724 [D loss: 0.531606, acc.: 77.34%] [G loss: 0.552649]\n",
      "epoch:11 step:10725 [D loss: 0.607678, acc.: 67.19%] [G loss: 0.565060]\n",
      "epoch:11 step:10726 [D loss: 0.545267, acc.: 71.88%] [G loss: 0.468085]\n",
      "epoch:11 step:10727 [D loss: 0.603068, acc.: 57.03%] [G loss: 0.546353]\n",
      "epoch:11 step:10728 [D loss: 0.536011, acc.: 69.53%] [G loss: 0.590809]\n",
      "epoch:11 step:10729 [D loss: 0.576872, acc.: 65.62%] [G loss: 0.504925]\n",
      "epoch:11 step:10730 [D loss: 0.550928, acc.: 69.53%] [G loss: 0.485087]\n",
      "epoch:11 step:10731 [D loss: 0.531863, acc.: 71.88%] [G loss: 0.605160]\n",
      "epoch:11 step:10732 [D loss: 0.553195, acc.: 67.97%] [G loss: 0.467545]\n",
      "epoch:11 step:10733 [D loss: 0.492963, acc.: 75.00%] [G loss: 0.663035]\n",
      "epoch:11 step:10734 [D loss: 0.483577, acc.: 74.22%] [G loss: 0.662413]\n",
      "epoch:11 step:10735 [D loss: 0.531985, acc.: 69.53%] [G loss: 0.687173]\n",
      "epoch:11 step:10736 [D loss: 0.490812, acc.: 75.78%] [G loss: 0.706892]\n",
      "epoch:11 step:10737 [D loss: 0.535478, acc.: 75.00%] [G loss: 0.652659]\n",
      "epoch:11 step:10738 [D loss: 0.557366, acc.: 70.31%] [G loss: 0.671228]\n",
      "epoch:11 step:10739 [D loss: 0.571938, acc.: 68.75%] [G loss: 0.704306]\n",
      "epoch:11 step:10740 [D loss: 0.632057, acc.: 66.41%] [G loss: 0.477963]\n",
      "epoch:11 step:10741 [D loss: 0.556015, acc.: 71.09%] [G loss: 0.554085]\n",
      "epoch:11 step:10742 [D loss: 0.550716, acc.: 71.09%] [G loss: 0.513081]\n",
      "epoch:11 step:10743 [D loss: 0.498330, acc.: 75.78%] [G loss: 0.545538]\n",
      "epoch:11 step:10744 [D loss: 0.639917, acc.: 67.19%] [G loss: 0.542266]\n",
      "epoch:11 step:10745 [D loss: 0.543617, acc.: 72.66%] [G loss: 0.577880]\n",
      "epoch:11 step:10746 [D loss: 0.499314, acc.: 73.44%] [G loss: 0.494943]\n",
      "epoch:11 step:10747 [D loss: 0.515518, acc.: 69.53%] [G loss: 0.691857]\n",
      "epoch:11 step:10748 [D loss: 0.549347, acc.: 69.53%] [G loss: 0.601606]\n",
      "epoch:11 step:10749 [D loss: 0.554161, acc.: 72.66%] [G loss: 0.541954]\n",
      "epoch:11 step:10750 [D loss: 0.527964, acc.: 70.31%] [G loss: 0.528104]\n",
      "epoch:11 step:10751 [D loss: 0.492472, acc.: 77.34%] [G loss: 0.669221]\n",
      "epoch:11 step:10752 [D loss: 0.579141, acc.: 66.41%] [G loss: 0.512390]\n",
      "epoch:11 step:10753 [D loss: 0.523288, acc.: 71.09%] [G loss: 0.589431]\n",
      "epoch:11 step:10754 [D loss: 0.522021, acc.: 72.66%] [G loss: 0.665825]\n",
      "epoch:11 step:10755 [D loss: 0.551301, acc.: 75.00%] [G loss: 0.572378]\n",
      "epoch:11 step:10756 [D loss: 0.487615, acc.: 78.12%] [G loss: 0.653666]\n",
      "epoch:11 step:10757 [D loss: 0.510733, acc.: 75.78%] [G loss: 0.552910]\n",
      "epoch:11 step:10758 [D loss: 0.412917, acc.: 80.47%] [G loss: 0.637406]\n",
      "epoch:11 step:10759 [D loss: 0.494939, acc.: 75.78%] [G loss: 0.671883]\n",
      "epoch:11 step:10760 [D loss: 0.578192, acc.: 71.09%] [G loss: 0.650569]\n",
      "epoch:11 step:10761 [D loss: 0.583930, acc.: 68.75%] [G loss: 0.685523]\n",
      "epoch:11 step:10762 [D loss: 0.569799, acc.: 71.09%] [G loss: 0.537517]\n",
      "epoch:11 step:10763 [D loss: 0.585580, acc.: 69.53%] [G loss: 0.499815]\n",
      "epoch:11 step:10764 [D loss: 0.519827, acc.: 71.88%] [G loss: 0.625996]\n",
      "epoch:11 step:10765 [D loss: 0.609255, acc.: 70.31%] [G loss: 0.542807]\n",
      "epoch:11 step:10766 [D loss: 0.533652, acc.: 73.44%] [G loss: 0.495102]\n",
      "epoch:11 step:10767 [D loss: 0.515240, acc.: 70.31%] [G loss: 0.657139]\n",
      "epoch:11 step:10768 [D loss: 0.510702, acc.: 75.78%] [G loss: 0.545201]\n",
      "epoch:11 step:10769 [D loss: 0.538278, acc.: 75.00%] [G loss: 0.660789]\n",
      "epoch:11 step:10770 [D loss: 0.565808, acc.: 68.75%] [G loss: 0.575082]\n",
      "epoch:11 step:10771 [D loss: 0.530645, acc.: 70.31%] [G loss: 0.656877]\n",
      "epoch:11 step:10772 [D loss: 0.616743, acc.: 65.62%] [G loss: 0.579654]\n",
      "epoch:11 step:10773 [D loss: 0.537704, acc.: 68.75%] [G loss: 0.631434]\n",
      "epoch:11 step:10774 [D loss: 0.565079, acc.: 66.41%] [G loss: 0.724540]\n",
      "epoch:11 step:10775 [D loss: 0.565510, acc.: 68.75%] [G loss: 0.636789]\n",
      "epoch:11 step:10776 [D loss: 0.555024, acc.: 71.09%] [G loss: 0.634994]\n",
      "epoch:11 step:10777 [D loss: 0.555099, acc.: 69.53%] [G loss: 0.699226]\n",
      "epoch:11 step:10778 [D loss: 0.433138, acc.: 85.16%] [G loss: 0.738224]\n",
      "epoch:11 step:10779 [D loss: 0.456216, acc.: 81.25%] [G loss: 0.774489]\n",
      "epoch:11 step:10780 [D loss: 0.655611, acc.: 60.94%] [G loss: 0.595342]\n",
      "epoch:11 step:10781 [D loss: 0.559848, acc.: 66.41%] [G loss: 0.607651]\n",
      "epoch:11 step:10782 [D loss: 0.472712, acc.: 78.91%] [G loss: 0.835368]\n",
      "epoch:11 step:10783 [D loss: 0.539457, acc.: 76.56%] [G loss: 0.703362]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10784 [D loss: 0.630558, acc.: 67.19%] [G loss: 0.535403]\n",
      "epoch:11 step:10785 [D loss: 0.592879, acc.: 66.41%] [G loss: 0.550155]\n",
      "epoch:11 step:10786 [D loss: 0.531031, acc.: 70.31%] [G loss: 0.592465]\n",
      "epoch:11 step:10787 [D loss: 0.583850, acc.: 65.62%] [G loss: 0.565473]\n",
      "epoch:11 step:10788 [D loss: 0.539425, acc.: 75.00%] [G loss: 0.519027]\n",
      "epoch:11 step:10789 [D loss: 0.615323, acc.: 64.06%] [G loss: 0.478415]\n",
      "epoch:11 step:10790 [D loss: 0.534498, acc.: 67.97%] [G loss: 0.525546]\n",
      "epoch:11 step:10791 [D loss: 0.501206, acc.: 73.44%] [G loss: 0.626822]\n",
      "epoch:11 step:10792 [D loss: 0.514375, acc.: 75.00%] [G loss: 0.721293]\n",
      "epoch:11 step:10793 [D loss: 0.542326, acc.: 72.66%] [G loss: 0.689058]\n",
      "epoch:11 step:10794 [D loss: 0.534318, acc.: 70.31%] [G loss: 0.655508]\n",
      "epoch:11 step:10795 [D loss: 0.556031, acc.: 63.28%] [G loss: 0.590489]\n",
      "epoch:11 step:10796 [D loss: 0.570008, acc.: 70.31%] [G loss: 0.551509]\n",
      "epoch:11 step:10797 [D loss: 0.524868, acc.: 75.78%] [G loss: 0.565988]\n",
      "epoch:11 step:10798 [D loss: 0.573226, acc.: 71.09%] [G loss: 0.559482]\n",
      "epoch:11 step:10799 [D loss: 0.580473, acc.: 66.41%] [G loss: 0.576240]\n",
      "epoch:11 step:10800 [D loss: 0.585419, acc.: 66.41%] [G loss: 0.552207]\n",
      "##############\n",
      "[2.98211546 1.66609759 6.1362434  4.81416319 3.76389441 5.60520918\n",
      " 4.7996907  4.82291778 4.53828363 3.95011042]\n",
      "##########\n",
      "epoch:11 step:10801 [D loss: 0.596177, acc.: 67.19%] [G loss: 0.480259]\n",
      "epoch:11 step:10802 [D loss: 0.572440, acc.: 67.19%] [G loss: 0.544697]\n",
      "epoch:11 step:10803 [D loss: 0.567887, acc.: 69.53%] [G loss: 0.492171]\n",
      "epoch:11 step:10804 [D loss: 0.582854, acc.: 70.31%] [G loss: 0.671198]\n",
      "epoch:11 step:10805 [D loss: 0.544606, acc.: 70.31%] [G loss: 0.651918]\n",
      "epoch:11 step:10806 [D loss: 0.520578, acc.: 69.53%] [G loss: 0.700926]\n",
      "epoch:11 step:10807 [D loss: 0.612795, acc.: 70.31%] [G loss: 0.709776]\n",
      "epoch:11 step:10808 [D loss: 0.620968, acc.: 70.31%] [G loss: 0.534323]\n",
      "epoch:11 step:10809 [D loss: 0.610466, acc.: 59.38%] [G loss: 0.537315]\n",
      "epoch:11 step:10810 [D loss: 0.508947, acc.: 75.00%] [G loss: 0.624346]\n",
      "epoch:11 step:10811 [D loss: 0.505362, acc.: 72.66%] [G loss: 0.805189]\n",
      "epoch:11 step:10812 [D loss: 0.526840, acc.: 71.09%] [G loss: 0.772956]\n",
      "epoch:11 step:10813 [D loss: 0.502166, acc.: 75.78%] [G loss: 0.695217]\n",
      "epoch:11 step:10814 [D loss: 0.551922, acc.: 71.88%] [G loss: 0.678548]\n",
      "epoch:11 step:10815 [D loss: 0.430286, acc.: 81.25%] [G loss: 0.781288]\n",
      "epoch:11 step:10816 [D loss: 0.504596, acc.: 74.22%] [G loss: 0.797514]\n",
      "epoch:11 step:10817 [D loss: 0.605835, acc.: 65.62%] [G loss: 0.627618]\n",
      "epoch:11 step:10818 [D loss: 0.661405, acc.: 58.59%] [G loss: 0.530212]\n",
      "epoch:11 step:10819 [D loss: 0.577464, acc.: 67.19%] [G loss: 0.545741]\n",
      "epoch:11 step:10820 [D loss: 0.519726, acc.: 76.56%] [G loss: 0.732806]\n",
      "epoch:11 step:10821 [D loss: 0.540295, acc.: 69.53%] [G loss: 0.638765]\n",
      "epoch:11 step:10822 [D loss: 0.481492, acc.: 75.78%] [G loss: 0.635198]\n",
      "epoch:11 step:10823 [D loss: 0.498916, acc.: 78.91%] [G loss: 0.651944]\n",
      "epoch:11 step:10824 [D loss: 0.497824, acc.: 75.78%] [G loss: 0.656062]\n",
      "epoch:11 step:10825 [D loss: 0.567281, acc.: 67.97%] [G loss: 0.628603]\n",
      "epoch:11 step:10826 [D loss: 0.515649, acc.: 71.09%] [G loss: 0.671485]\n",
      "epoch:11 step:10827 [D loss: 0.495448, acc.: 74.22%] [G loss: 0.625975]\n",
      "epoch:11 step:10828 [D loss: 0.552576, acc.: 71.88%] [G loss: 0.601956]\n",
      "epoch:11 step:10829 [D loss: 0.487430, acc.: 78.12%] [G loss: 0.703925]\n",
      "epoch:11 step:10830 [D loss: 0.516844, acc.: 71.88%] [G loss: 0.657156]\n",
      "epoch:11 step:10831 [D loss: 0.568059, acc.: 66.41%] [G loss: 0.463105]\n",
      "epoch:11 step:10832 [D loss: 0.589564, acc.: 63.28%] [G loss: 0.537115]\n",
      "epoch:11 step:10833 [D loss: 0.501302, acc.: 72.66%] [G loss: 0.545239]\n",
      "epoch:11 step:10834 [D loss: 0.591130, acc.: 65.62%] [G loss: 0.640667]\n",
      "epoch:11 step:10835 [D loss: 0.612339, acc.: 66.41%] [G loss: 0.544269]\n",
      "epoch:11 step:10836 [D loss: 0.585872, acc.: 67.97%] [G loss: 0.568498]\n",
      "epoch:11 step:10837 [D loss: 0.553465, acc.: 69.53%] [G loss: 0.668964]\n",
      "epoch:11 step:10838 [D loss: 0.579596, acc.: 65.62%] [G loss: 0.424690]\n",
      "epoch:11 step:10839 [D loss: 0.568383, acc.: 67.19%] [G loss: 0.482061]\n",
      "epoch:11 step:10840 [D loss: 0.565051, acc.: 68.75%] [G loss: 0.681136]\n",
      "epoch:11 step:10841 [D loss: 0.519360, acc.: 74.22%] [G loss: 0.653060]\n",
      "epoch:11 step:10842 [D loss: 0.609866, acc.: 68.75%] [G loss: 0.564633]\n",
      "epoch:11 step:10843 [D loss: 0.494614, acc.: 73.44%] [G loss: 0.532882]\n",
      "epoch:11 step:10844 [D loss: 0.594227, acc.: 63.28%] [G loss: 0.502500]\n",
      "epoch:11 step:10845 [D loss: 0.543654, acc.: 67.97%] [G loss: 0.581004]\n",
      "epoch:11 step:10846 [D loss: 0.522505, acc.: 71.88%] [G loss: 0.669900]\n",
      "epoch:11 step:10847 [D loss: 0.534019, acc.: 70.31%] [G loss: 0.532336]\n",
      "epoch:11 step:10848 [D loss: 0.527866, acc.: 71.09%] [G loss: 0.586819]\n",
      "epoch:11 step:10849 [D loss: 0.562618, acc.: 74.22%] [G loss: 0.619572]\n",
      "epoch:11 step:10850 [D loss: 0.623342, acc.: 59.38%] [G loss: 0.529013]\n",
      "epoch:11 step:10851 [D loss: 0.581219, acc.: 66.41%] [G loss: 0.713313]\n",
      "epoch:11 step:10852 [D loss: 0.518439, acc.: 72.66%] [G loss: 0.685548]\n",
      "epoch:11 step:10853 [D loss: 0.522301, acc.: 70.31%] [G loss: 0.694313]\n",
      "epoch:11 step:10854 [D loss: 0.543547, acc.: 73.44%] [G loss: 0.549475]\n",
      "epoch:11 step:10855 [D loss: 0.461164, acc.: 77.34%] [G loss: 0.629210]\n",
      "epoch:11 step:10856 [D loss: 0.548162, acc.: 70.31%] [G loss: 0.584328]\n",
      "epoch:11 step:10857 [D loss: 0.527021, acc.: 77.34%] [G loss: 0.498475]\n",
      "epoch:11 step:10858 [D loss: 0.539306, acc.: 76.56%] [G loss: 0.561081]\n",
      "epoch:11 step:10859 [D loss: 0.460289, acc.: 78.91%] [G loss: 0.659827]\n",
      "epoch:11 step:10860 [D loss: 0.657545, acc.: 53.91%] [G loss: 0.546311]\n",
      "epoch:11 step:10861 [D loss: 0.464766, acc.: 78.12%] [G loss: 0.636056]\n",
      "epoch:11 step:10862 [D loss: 0.487671, acc.: 72.66%] [G loss: 0.703609]\n",
      "epoch:11 step:10863 [D loss: 0.577517, acc.: 68.75%] [G loss: 0.683264]\n",
      "epoch:11 step:10864 [D loss: 0.515426, acc.: 71.88%] [G loss: 0.677674]\n",
      "epoch:11 step:10865 [D loss: 0.480013, acc.: 75.78%] [G loss: 0.676166]\n",
      "epoch:11 step:10866 [D loss: 0.604437, acc.: 67.19%] [G loss: 0.654855]\n",
      "epoch:11 step:10867 [D loss: 0.533261, acc.: 75.78%] [G loss: 0.633209]\n",
      "epoch:11 step:10868 [D loss: 0.557626, acc.: 70.31%] [G loss: 0.611036]\n",
      "epoch:11 step:10869 [D loss: 0.609978, acc.: 60.16%] [G loss: 0.497585]\n",
      "epoch:11 step:10870 [D loss: 0.531619, acc.: 71.09%] [G loss: 0.496561]\n",
      "epoch:11 step:10871 [D loss: 0.478421, acc.: 72.66%] [G loss: 0.746225]\n",
      "epoch:11 step:10872 [D loss: 0.602063, acc.: 64.06%] [G loss: 0.731487]\n",
      "epoch:11 step:10873 [D loss: 0.684424, acc.: 58.59%] [G loss: 0.495016]\n",
      "epoch:11 step:10874 [D loss: 0.515884, acc.: 71.88%] [G loss: 0.439817]\n",
      "epoch:11 step:10875 [D loss: 0.495415, acc.: 77.34%] [G loss: 0.647388]\n",
      "epoch:11 step:10876 [D loss: 0.557950, acc.: 70.31%] [G loss: 0.604515]\n",
      "epoch:11 step:10877 [D loss: 0.515768, acc.: 73.44%] [G loss: 0.590271]\n",
      "epoch:11 step:10878 [D loss: 0.515759, acc.: 72.66%] [G loss: 0.755494]\n",
      "epoch:11 step:10879 [D loss: 0.587595, acc.: 67.19%] [G loss: 0.631311]\n",
      "epoch:11 step:10880 [D loss: 0.514018, acc.: 74.22%] [G loss: 0.641616]\n",
      "epoch:11 step:10881 [D loss: 0.501672, acc.: 75.78%] [G loss: 0.734586]\n",
      "epoch:11 step:10882 [D loss: 0.492604, acc.: 75.00%] [G loss: 0.609218]\n",
      "epoch:11 step:10883 [D loss: 0.584864, acc.: 67.19%] [G loss: 0.559046]\n",
      "epoch:11 step:10884 [D loss: 0.609390, acc.: 71.09%] [G loss: 0.609109]\n",
      "epoch:11 step:10885 [D loss: 0.526078, acc.: 69.53%] [G loss: 0.461307]\n",
      "epoch:11 step:10886 [D loss: 0.539122, acc.: 68.75%] [G loss: 0.743932]\n",
      "epoch:11 step:10887 [D loss: 0.630325, acc.: 64.84%] [G loss: 0.498843]\n",
      "epoch:11 step:10888 [D loss: 0.542580, acc.: 72.66%] [G loss: 0.592220]\n",
      "epoch:11 step:10889 [D loss: 0.511033, acc.: 78.12%] [G loss: 0.707713]\n",
      "epoch:11 step:10890 [D loss: 0.607049, acc.: 71.88%] [G loss: 0.569008]\n",
      "epoch:11 step:10891 [D loss: 0.614502, acc.: 64.06%] [G loss: 0.546694]\n",
      "epoch:11 step:10892 [D loss: 0.537305, acc.: 71.09%] [G loss: 0.630359]\n",
      "epoch:11 step:10893 [D loss: 0.597762, acc.: 67.97%] [G loss: 0.524117]\n",
      "epoch:11 step:10894 [D loss: 0.590965, acc.: 64.06%] [G loss: 0.554951]\n",
      "epoch:11 step:10895 [D loss: 0.559012, acc.: 67.19%] [G loss: 0.462044]\n",
      "epoch:11 step:10896 [D loss: 0.519484, acc.: 71.09%] [G loss: 0.707836]\n",
      "epoch:11 step:10897 [D loss: 0.574745, acc.: 67.19%] [G loss: 0.577698]\n",
      "epoch:11 step:10898 [D loss: 0.554105, acc.: 67.97%] [G loss: 0.594045]\n",
      "epoch:11 step:10899 [D loss: 0.474483, acc.: 79.69%] [G loss: 0.514414]\n",
      "epoch:11 step:10900 [D loss: 0.525213, acc.: 69.53%] [G loss: 0.534028]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10901 [D loss: 0.554981, acc.: 71.88%] [G loss: 0.700780]\n",
      "epoch:11 step:10902 [D loss: 0.586121, acc.: 70.31%] [G loss: 0.513877]\n",
      "epoch:11 step:10903 [D loss: 0.581019, acc.: 68.75%] [G loss: 0.460856]\n",
      "epoch:11 step:10904 [D loss: 0.525747, acc.: 73.44%] [G loss: 0.596263]\n",
      "epoch:11 step:10905 [D loss: 0.529834, acc.: 74.22%] [G loss: 0.730825]\n",
      "epoch:11 step:10906 [D loss: 0.540068, acc.: 69.53%] [G loss: 0.603746]\n",
      "epoch:11 step:10907 [D loss: 0.589913, acc.: 67.97%] [G loss: 0.614660]\n",
      "epoch:11 step:10908 [D loss: 0.468679, acc.: 77.34%] [G loss: 0.590427]\n",
      "epoch:11 step:10909 [D loss: 0.568950, acc.: 68.75%] [G loss: 0.602300]\n",
      "epoch:11 step:10910 [D loss: 0.456559, acc.: 78.91%] [G loss: 0.775449]\n",
      "epoch:11 step:10911 [D loss: 0.569630, acc.: 70.31%] [G loss: 0.562171]\n",
      "epoch:11 step:10912 [D loss: 0.494109, acc.: 72.66%] [G loss: 0.702961]\n",
      "epoch:11 step:10913 [D loss: 0.616235, acc.: 66.41%] [G loss: 0.536431]\n",
      "epoch:11 step:10914 [D loss: 0.550913, acc.: 67.97%] [G loss: 0.633574]\n",
      "epoch:11 step:10915 [D loss: 0.509872, acc.: 71.09%] [G loss: 0.631911]\n",
      "epoch:11 step:10916 [D loss: 0.526515, acc.: 69.53%] [G loss: 0.569932]\n",
      "epoch:11 step:10917 [D loss: 0.582303, acc.: 67.97%] [G loss: 0.547963]\n",
      "epoch:11 step:10918 [D loss: 0.464712, acc.: 78.12%] [G loss: 0.624063]\n",
      "epoch:11 step:10919 [D loss: 0.565500, acc.: 72.66%] [G loss: 0.498042]\n",
      "epoch:11 step:10920 [D loss: 0.524990, acc.: 72.66%] [G loss: 0.606469]\n",
      "epoch:11 step:10921 [D loss: 0.606542, acc.: 66.41%] [G loss: 0.560386]\n",
      "epoch:11 step:10922 [D loss: 0.613379, acc.: 64.06%] [G loss: 0.636367]\n",
      "epoch:11 step:10923 [D loss: 0.562971, acc.: 67.19%] [G loss: 0.496023]\n",
      "epoch:11 step:10924 [D loss: 0.601631, acc.: 71.09%] [G loss: 0.590119]\n",
      "epoch:11 step:10925 [D loss: 0.510814, acc.: 73.44%] [G loss: 0.643090]\n",
      "epoch:11 step:10926 [D loss: 0.561787, acc.: 66.41%] [G loss: 0.506267]\n",
      "epoch:11 step:10927 [D loss: 0.554376, acc.: 70.31%] [G loss: 0.721996]\n",
      "epoch:11 step:10928 [D loss: 0.564729, acc.: 66.41%] [G loss: 0.576051]\n",
      "epoch:11 step:10929 [D loss: 0.624349, acc.: 69.53%] [G loss: 0.609975]\n",
      "epoch:11 step:10930 [D loss: 0.511407, acc.: 72.66%] [G loss: 0.529674]\n",
      "epoch:11 step:10931 [D loss: 0.517579, acc.: 78.12%] [G loss: 0.675713]\n",
      "epoch:11 step:10932 [D loss: 0.623327, acc.: 64.84%] [G loss: 0.520575]\n",
      "epoch:11 step:10933 [D loss: 0.534214, acc.: 71.09%] [G loss: 0.568815]\n",
      "epoch:11 step:10934 [D loss: 0.571583, acc.: 67.19%] [G loss: 0.572096]\n",
      "epoch:11 step:10935 [D loss: 0.604867, acc.: 67.19%] [G loss: 0.393107]\n",
      "epoch:11 step:10936 [D loss: 0.508944, acc.: 71.88%] [G loss: 0.621756]\n",
      "epoch:11 step:10937 [D loss: 0.586609, acc.: 69.53%] [G loss: 0.503672]\n",
      "epoch:11 step:10938 [D loss: 0.522873, acc.: 75.78%] [G loss: 0.549245]\n",
      "epoch:11 step:10939 [D loss: 0.502049, acc.: 73.44%] [G loss: 0.675907]\n",
      "epoch:11 step:10940 [D loss: 0.569079, acc.: 67.19%] [G loss: 0.590746]\n",
      "epoch:11 step:10941 [D loss: 0.488282, acc.: 79.69%] [G loss: 0.531801]\n",
      "epoch:11 step:10942 [D loss: 0.519240, acc.: 73.44%] [G loss: 0.736840]\n",
      "epoch:11 step:10943 [D loss: 0.545867, acc.: 71.88%] [G loss: 0.602338]\n",
      "epoch:11 step:10944 [D loss: 0.563357, acc.: 71.88%] [G loss: 0.525468]\n",
      "epoch:11 step:10945 [D loss: 0.539272, acc.: 67.97%] [G loss: 0.608047]\n",
      "epoch:11 step:10946 [D loss: 0.500031, acc.: 72.66%] [G loss: 0.558035]\n",
      "epoch:11 step:10947 [D loss: 0.547173, acc.: 69.53%] [G loss: 0.602036]\n",
      "epoch:11 step:10948 [D loss: 0.493628, acc.: 75.78%] [G loss: 0.828466]\n",
      "epoch:11 step:10949 [D loss: 0.496551, acc.: 75.00%] [G loss: 0.712811]\n",
      "epoch:11 step:10950 [D loss: 0.514895, acc.: 74.22%] [G loss: 0.657966]\n",
      "epoch:11 step:10951 [D loss: 0.588668, acc.: 65.62%] [G loss: 0.542411]\n",
      "epoch:11 step:10952 [D loss: 0.512055, acc.: 75.00%] [G loss: 0.576503]\n",
      "epoch:11 step:10953 [D loss: 0.608872, acc.: 68.75%] [G loss: 0.651187]\n",
      "epoch:11 step:10954 [D loss: 0.438742, acc.: 76.56%] [G loss: 0.771319]\n",
      "epoch:11 step:10955 [D loss: 0.479735, acc.: 76.56%] [G loss: 0.944992]\n",
      "epoch:11 step:10956 [D loss: 0.482816, acc.: 76.56%] [G loss: 0.802729]\n",
      "epoch:11 step:10957 [D loss: 0.473860, acc.: 77.34%] [G loss: 0.827322]\n",
      "epoch:11 step:10958 [D loss: 0.544737, acc.: 71.09%] [G loss: 0.684249]\n",
      "epoch:11 step:10959 [D loss: 0.620603, acc.: 65.62%] [G loss: 0.536041]\n",
      "epoch:11 step:10960 [D loss: 0.625680, acc.: 63.28%] [G loss: 0.424282]\n",
      "epoch:11 step:10961 [D loss: 0.491076, acc.: 75.78%] [G loss: 0.563772]\n",
      "epoch:11 step:10962 [D loss: 0.547311, acc.: 72.66%] [G loss: 0.647026]\n",
      "epoch:11 step:10963 [D loss: 0.544135, acc.: 69.53%] [G loss: 0.582497]\n",
      "epoch:11 step:10964 [D loss: 0.514781, acc.: 67.19%] [G loss: 0.573728]\n",
      "epoch:11 step:10965 [D loss: 0.543565, acc.: 67.97%] [G loss: 0.747706]\n",
      "epoch:11 step:10966 [D loss: 0.548757, acc.: 71.88%] [G loss: 0.590560]\n",
      "epoch:11 step:10967 [D loss: 0.528617, acc.: 74.22%] [G loss: 0.674080]\n",
      "epoch:11 step:10968 [D loss: 0.506231, acc.: 71.09%] [G loss: 0.895246]\n",
      "epoch:11 step:10969 [D loss: 0.517791, acc.: 75.78%] [G loss: 0.615392]\n",
      "epoch:11 step:10970 [D loss: 0.563024, acc.: 71.88%] [G loss: 0.631739]\n",
      "epoch:11 step:10971 [D loss: 0.555834, acc.: 68.75%] [G loss: 0.688324]\n",
      "epoch:11 step:10972 [D loss: 0.568470, acc.: 68.75%] [G loss: 0.620021]\n",
      "epoch:11 step:10973 [D loss: 0.507888, acc.: 77.34%] [G loss: 0.690745]\n",
      "epoch:11 step:10974 [D loss: 0.568499, acc.: 68.75%] [G loss: 0.526549]\n",
      "epoch:11 step:10975 [D loss: 0.558837, acc.: 75.78%] [G loss: 0.559855]\n",
      "epoch:11 step:10976 [D loss: 0.533174, acc.: 71.88%] [G loss: 0.609456]\n",
      "epoch:11 step:10977 [D loss: 0.502403, acc.: 70.31%] [G loss: 0.592087]\n",
      "epoch:11 step:10978 [D loss: 0.566928, acc.: 70.31%] [G loss: 0.571497]\n",
      "epoch:11 step:10979 [D loss: 0.577584, acc.: 73.44%] [G loss: 0.618603]\n",
      "epoch:11 step:10980 [D loss: 0.577493, acc.: 67.97%] [G loss: 0.620216]\n",
      "epoch:11 step:10981 [D loss: 0.535059, acc.: 73.44%] [G loss: 0.727910]\n",
      "epoch:11 step:10982 [D loss: 0.596403, acc.: 63.28%] [G loss: 0.463546]\n",
      "epoch:11 step:10983 [D loss: 0.528054, acc.: 70.31%] [G loss: 0.644770]\n",
      "epoch:11 step:10984 [D loss: 0.478401, acc.: 78.12%] [G loss: 0.709250]\n",
      "epoch:11 step:10985 [D loss: 0.579965, acc.: 67.97%] [G loss: 0.601985]\n",
      "epoch:11 step:10986 [D loss: 0.536416, acc.: 72.66%] [G loss: 0.581837]\n",
      "epoch:11 step:10987 [D loss: 0.534886, acc.: 71.09%] [G loss: 0.568372]\n",
      "epoch:11 step:10988 [D loss: 0.521017, acc.: 72.66%] [G loss: 0.660766]\n",
      "epoch:11 step:10989 [D loss: 0.531574, acc.: 72.66%] [G loss: 0.648332]\n",
      "epoch:11 step:10990 [D loss: 0.585796, acc.: 67.97%] [G loss: 0.701116]\n",
      "epoch:11 step:10991 [D loss: 0.645855, acc.: 59.38%] [G loss: 0.374887]\n",
      "epoch:11 step:10992 [D loss: 0.528614, acc.: 74.22%] [G loss: 0.468945]\n",
      "epoch:11 step:10993 [D loss: 0.591609, acc.: 68.75%] [G loss: 0.427827]\n",
      "epoch:11 step:10994 [D loss: 0.528699, acc.: 71.88%] [G loss: 0.522500]\n",
      "epoch:11 step:10995 [D loss: 0.538823, acc.: 73.44%] [G loss: 0.588617]\n",
      "epoch:11 step:10996 [D loss: 0.567466, acc.: 74.22%] [G loss: 0.688110]\n",
      "epoch:11 step:10997 [D loss: 0.545922, acc.: 71.88%] [G loss: 0.657620]\n",
      "epoch:11 step:10998 [D loss: 0.438062, acc.: 82.81%] [G loss: 0.603099]\n",
      "epoch:11 step:10999 [D loss: 0.585178, acc.: 66.41%] [G loss: 0.598587]\n",
      "epoch:11 step:11000 [D loss: 0.472626, acc.: 77.34%] [G loss: 0.597142]\n",
      "##############\n",
      "[2.985668   1.59540068 6.18714466 4.76299755 4.11026185 5.70389439\n",
      " 4.61463509 4.99848032 4.65002576 4.12804552]\n",
      "##########\n",
      "epoch:11 step:11001 [D loss: 0.522530, acc.: 75.00%] [G loss: 0.686672]\n",
      "epoch:11 step:11002 [D loss: 0.540614, acc.: 71.88%] [G loss: 0.755865]\n",
      "epoch:11 step:11003 [D loss: 0.575135, acc.: 64.06%] [G loss: 0.599733]\n",
      "epoch:11 step:11004 [D loss: 0.574871, acc.: 64.84%] [G loss: 0.630113]\n",
      "epoch:11 step:11005 [D loss: 0.588992, acc.: 70.31%] [G loss: 0.471395]\n",
      "epoch:11 step:11006 [D loss: 0.524973, acc.: 72.66%] [G loss: 0.583551]\n",
      "epoch:11 step:11007 [D loss: 0.573973, acc.: 71.09%] [G loss: 0.594169]\n",
      "epoch:11 step:11008 [D loss: 0.521312, acc.: 71.88%] [G loss: 0.656966]\n",
      "epoch:11 step:11009 [D loss: 0.620669, acc.: 60.94%] [G loss: 0.607365]\n",
      "epoch:11 step:11010 [D loss: 0.638993, acc.: 58.59%] [G loss: 0.531149]\n",
      "epoch:11 step:11011 [D loss: 0.612249, acc.: 66.41%] [G loss: 0.588561]\n",
      "epoch:11 step:11012 [D loss: 0.475680, acc.: 80.47%] [G loss: 0.637121]\n",
      "epoch:11 step:11013 [D loss: 0.576292, acc.: 64.84%] [G loss: 0.579249]\n",
      "epoch:11 step:11014 [D loss: 0.501648, acc.: 74.22%] [G loss: 0.522417]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:11015 [D loss: 0.512507, acc.: 75.00%] [G loss: 0.620369]\n",
      "epoch:11 step:11016 [D loss: 0.550408, acc.: 68.75%] [G loss: 0.616525]\n",
      "epoch:11 step:11017 [D loss: 0.650522, acc.: 63.28%] [G loss: 0.451449]\n",
      "epoch:11 step:11018 [D loss: 0.559220, acc.: 67.19%] [G loss: 0.557319]\n",
      "epoch:11 step:11019 [D loss: 0.526353, acc.: 66.41%] [G loss: 0.668951]\n",
      "epoch:11 step:11020 [D loss: 0.586164, acc.: 67.19%] [G loss: 0.600786]\n",
      "epoch:11 step:11021 [D loss: 0.530907, acc.: 76.56%] [G loss: 0.562723]\n",
      "epoch:11 step:11022 [D loss: 0.520751, acc.: 72.66%] [G loss: 0.596089]\n",
      "epoch:11 step:11023 [D loss: 0.624915, acc.: 66.41%] [G loss: 0.550907]\n",
      "epoch:11 step:11024 [D loss: 0.591054, acc.: 66.41%] [G loss: 0.445095]\n",
      "epoch:11 step:11025 [D loss: 0.604787, acc.: 64.06%] [G loss: 0.427859]\n",
      "epoch:11 step:11026 [D loss: 0.502745, acc.: 78.12%] [G loss: 0.643618]\n",
      "epoch:11 step:11027 [D loss: 0.583179, acc.: 65.62%] [G loss: 0.518144]\n",
      "epoch:11 step:11028 [D loss: 0.523559, acc.: 73.44%] [G loss: 0.554517]\n",
      "epoch:11 step:11029 [D loss: 0.536270, acc.: 70.31%] [G loss: 0.553430]\n",
      "epoch:11 step:11030 [D loss: 0.589735, acc.: 68.75%] [G loss: 0.758804]\n",
      "epoch:11 step:11031 [D loss: 0.508852, acc.: 75.00%] [G loss: 0.551230]\n",
      "epoch:11 step:11032 [D loss: 0.510410, acc.: 73.44%] [G loss: 0.725643]\n",
      "epoch:11 step:11033 [D loss: 0.512517, acc.: 75.00%] [G loss: 0.679278]\n",
      "epoch:11 step:11034 [D loss: 0.566976, acc.: 69.53%] [G loss: 0.606130]\n",
      "epoch:11 step:11035 [D loss: 0.517270, acc.: 72.66%] [G loss: 0.650907]\n",
      "epoch:11 step:11036 [D loss: 0.624393, acc.: 69.53%] [G loss: 0.589716]\n",
      "epoch:11 step:11037 [D loss: 0.494052, acc.: 76.56%] [G loss: 0.634320]\n",
      "epoch:11 step:11038 [D loss: 0.582142, acc.: 62.50%] [G loss: 0.481302]\n",
      "epoch:11 step:11039 [D loss: 0.474001, acc.: 78.91%] [G loss: 0.721020]\n",
      "epoch:11 step:11040 [D loss: 0.523797, acc.: 75.00%] [G loss: 0.599836]\n",
      "epoch:11 step:11041 [D loss: 0.572866, acc.: 64.84%] [G loss: 0.632433]\n",
      "epoch:11 step:11042 [D loss: 0.550751, acc.: 69.53%] [G loss: 0.589873]\n",
      "epoch:11 step:11043 [D loss: 0.538347, acc.: 71.88%] [G loss: 0.635366]\n",
      "epoch:11 step:11044 [D loss: 0.490111, acc.: 75.00%] [G loss: 0.699794]\n",
      "epoch:11 step:11045 [D loss: 0.557055, acc.: 68.75%] [G loss: 0.572790]\n",
      "epoch:11 step:11046 [D loss: 0.556520, acc.: 69.53%] [G loss: 0.634026]\n",
      "epoch:11 step:11047 [D loss: 0.610630, acc.: 64.06%] [G loss: 0.384935]\n",
      "epoch:11 step:11048 [D loss: 0.564035, acc.: 70.31%] [G loss: 0.481344]\n",
      "epoch:11 step:11049 [D loss: 0.561692, acc.: 67.19%] [G loss: 0.516906]\n",
      "epoch:11 step:11050 [D loss: 0.506151, acc.: 71.88%] [G loss: 0.702082]\n",
      "epoch:11 step:11051 [D loss: 0.500692, acc.: 78.12%] [G loss: 0.802496]\n",
      "epoch:11 step:11052 [D loss: 0.582438, acc.: 68.75%] [G loss: 0.656287]\n",
      "epoch:11 step:11053 [D loss: 0.442141, acc.: 78.12%] [G loss: 0.846099]\n",
      "epoch:11 step:11054 [D loss: 0.486779, acc.: 75.00%] [G loss: 0.944033]\n",
      "epoch:11 step:11055 [D loss: 0.575377, acc.: 65.62%] [G loss: 0.580449]\n",
      "epoch:11 step:11056 [D loss: 0.574134, acc.: 71.09%] [G loss: 0.668865]\n",
      "epoch:11 step:11057 [D loss: 0.516019, acc.: 71.09%] [G loss: 0.634335]\n",
      "epoch:11 step:11058 [D loss: 0.484087, acc.: 78.91%] [G loss: 0.714233]\n",
      "epoch:11 step:11059 [D loss: 0.542066, acc.: 71.09%] [G loss: 0.609927]\n",
      "epoch:11 step:11060 [D loss: 0.510199, acc.: 71.88%] [G loss: 0.622321]\n",
      "epoch:11 step:11061 [D loss: 0.552703, acc.: 68.75%] [G loss: 0.688997]\n",
      "epoch:11 step:11062 [D loss: 0.491274, acc.: 75.78%] [G loss: 0.713814]\n",
      "epoch:11 step:11063 [D loss: 0.573959, acc.: 65.62%] [G loss: 0.783284]\n",
      "epoch:11 step:11064 [D loss: 0.551083, acc.: 72.66%] [G loss: 0.653861]\n",
      "epoch:11 step:11065 [D loss: 0.571429, acc.: 69.53%] [G loss: 0.469390]\n",
      "epoch:11 step:11066 [D loss: 0.544070, acc.: 72.66%] [G loss: 0.591144]\n",
      "epoch:11 step:11067 [D loss: 0.552180, acc.: 67.19%] [G loss: 0.508675]\n",
      "epoch:11 step:11068 [D loss: 0.569074, acc.: 69.53%] [G loss: 0.598853]\n",
      "epoch:11 step:11069 [D loss: 0.621971, acc.: 65.62%] [G loss: 0.473289]\n",
      "epoch:11 step:11070 [D loss: 0.604486, acc.: 64.84%] [G loss: 0.527486]\n",
      "epoch:11 step:11071 [D loss: 0.605615, acc.: 66.41%] [G loss: 0.520395]\n",
      "epoch:11 step:11072 [D loss: 0.643464, acc.: 63.28%] [G loss: 0.549657]\n",
      "epoch:11 step:11073 [D loss: 0.670269, acc.: 57.81%] [G loss: 0.434113]\n",
      "epoch:11 step:11074 [D loss: 0.552634, acc.: 70.31%] [G loss: 0.512740]\n",
      "epoch:11 step:11075 [D loss: 0.537993, acc.: 68.75%] [G loss: 0.685617]\n",
      "epoch:11 step:11076 [D loss: 0.511718, acc.: 74.22%] [G loss: 0.733079]\n",
      "epoch:11 step:11077 [D loss: 0.558954, acc.: 68.75%] [G loss: 0.751006]\n",
      "epoch:11 step:11078 [D loss: 0.530467, acc.: 71.09%] [G loss: 0.622722]\n",
      "epoch:11 step:11079 [D loss: 0.531419, acc.: 74.22%] [G loss: 0.569512]\n",
      "epoch:11 step:11080 [D loss: 0.509103, acc.: 74.22%] [G loss: 0.622617]\n",
      "epoch:11 step:11081 [D loss: 0.610315, acc.: 64.84%] [G loss: 0.571876]\n",
      "epoch:11 step:11082 [D loss: 0.525978, acc.: 71.88%] [G loss: 0.810390]\n",
      "epoch:11 step:11083 [D loss: 0.582274, acc.: 67.97%] [G loss: 0.577554]\n",
      "epoch:11 step:11084 [D loss: 0.583081, acc.: 65.62%] [G loss: 0.565765]\n",
      "epoch:11 step:11085 [D loss: 0.559734, acc.: 70.31%] [G loss: 0.513055]\n",
      "epoch:11 step:11086 [D loss: 0.603510, acc.: 64.06%] [G loss: 0.557359]\n",
      "epoch:11 step:11087 [D loss: 0.549805, acc.: 69.53%] [G loss: 0.712842]\n",
      "epoch:11 step:11088 [D loss: 0.495836, acc.: 73.44%] [G loss: 0.633823]\n",
      "epoch:11 step:11089 [D loss: 0.542419, acc.: 71.88%] [G loss: 0.652127]\n",
      "epoch:11 step:11090 [D loss: 0.588287, acc.: 63.28%] [G loss: 0.592362]\n",
      "epoch:11 step:11091 [D loss: 0.588349, acc.: 67.97%] [G loss: 0.650518]\n",
      "epoch:11 step:11092 [D loss: 0.571218, acc.: 64.84%] [G loss: 0.530970]\n",
      "epoch:11 step:11093 [D loss: 0.461247, acc.: 85.16%] [G loss: 0.647787]\n",
      "epoch:11 step:11094 [D loss: 0.641369, acc.: 62.50%] [G loss: 0.587184]\n",
      "epoch:11 step:11095 [D loss: 0.679160, acc.: 56.25%] [G loss: 0.513659]\n",
      "epoch:11 step:11096 [D loss: 0.495024, acc.: 73.44%] [G loss: 0.656231]\n",
      "epoch:11 step:11097 [D loss: 0.576950, acc.: 69.53%] [G loss: 0.609944]\n",
      "epoch:11 step:11098 [D loss: 0.578753, acc.: 67.19%] [G loss: 0.497240]\n",
      "epoch:11 step:11099 [D loss: 0.491931, acc.: 76.56%] [G loss: 0.601377]\n",
      "epoch:11 step:11100 [D loss: 0.592768, acc.: 68.75%] [G loss: 0.575066]\n",
      "epoch:11 step:11101 [D loss: 0.634624, acc.: 62.50%] [G loss: 0.677308]\n",
      "epoch:11 step:11102 [D loss: 0.539960, acc.: 66.41%] [G loss: 0.737983]\n",
      "epoch:11 step:11103 [D loss: 0.505540, acc.: 75.00%] [G loss: 0.734393]\n",
      "epoch:11 step:11104 [D loss: 0.548223, acc.: 71.09%] [G loss: 0.835678]\n",
      "epoch:11 step:11105 [D loss: 0.518793, acc.: 71.09%] [G loss: 0.623547]\n",
      "epoch:11 step:11106 [D loss: 0.556612, acc.: 72.66%] [G loss: 0.571962]\n",
      "epoch:11 step:11107 [D loss: 0.605492, acc.: 63.28%] [G loss: 0.593660]\n",
      "epoch:11 step:11108 [D loss: 0.541106, acc.: 70.31%] [G loss: 0.605861]\n",
      "epoch:11 step:11109 [D loss: 0.519651, acc.: 73.44%] [G loss: 0.678559]\n",
      "epoch:11 step:11110 [D loss: 0.542811, acc.: 71.88%] [G loss: 0.699228]\n",
      "epoch:11 step:11111 [D loss: 0.542945, acc.: 71.88%] [G loss: 0.486785]\n",
      "epoch:11 step:11112 [D loss: 0.561403, acc.: 67.19%] [G loss: 0.607882]\n",
      "epoch:11 step:11113 [D loss: 0.579771, acc.: 67.19%] [G loss: 0.454500]\n",
      "epoch:11 step:11114 [D loss: 0.554074, acc.: 72.66%] [G loss: 0.512736]\n",
      "epoch:11 step:11115 [D loss: 0.551696, acc.: 69.53%] [G loss: 0.567725]\n",
      "epoch:11 step:11116 [D loss: 0.535332, acc.: 71.88%] [G loss: 0.636337]\n",
      "epoch:11 step:11117 [D loss: 0.526963, acc.: 74.22%] [G loss: 0.723787]\n",
      "epoch:11 step:11118 [D loss: 0.608341, acc.: 65.62%] [G loss: 0.452057]\n",
      "epoch:11 step:11119 [D loss: 0.637950, acc.: 64.84%] [G loss: 0.501185]\n",
      "epoch:11 step:11120 [D loss: 0.590279, acc.: 67.97%] [G loss: 0.578831]\n",
      "epoch:11 step:11121 [D loss: 0.489971, acc.: 75.00%] [G loss: 0.669268]\n",
      "epoch:11 step:11122 [D loss: 0.508526, acc.: 72.66%] [G loss: 0.822147]\n",
      "epoch:11 step:11123 [D loss: 0.563319, acc.: 67.19%] [G loss: 0.596232]\n",
      "epoch:11 step:11124 [D loss: 0.634155, acc.: 64.06%] [G loss: 0.426579]\n",
      "epoch:11 step:11125 [D loss: 0.586235, acc.: 64.84%] [G loss: 0.386638]\n",
      "epoch:11 step:11126 [D loss: 0.480891, acc.: 78.91%] [G loss: 0.513175]\n",
      "epoch:11 step:11127 [D loss: 0.595083, acc.: 64.84%] [G loss: 0.443956]\n",
      "epoch:11 step:11128 [D loss: 0.574152, acc.: 71.09%] [G loss: 0.552358]\n",
      "epoch:11 step:11129 [D loss: 0.497435, acc.: 78.91%] [G loss: 0.536031]\n",
      "epoch:11 step:11130 [D loss: 0.450655, acc.: 76.56%] [G loss: 0.477791]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:11131 [D loss: 0.594278, acc.: 67.19%] [G loss: 0.521658]\n",
      "epoch:11 step:11132 [D loss: 0.538627, acc.: 69.53%] [G loss: 0.644203]\n",
      "epoch:11 step:11133 [D loss: 0.571644, acc.: 62.50%] [G loss: 0.528037]\n",
      "epoch:11 step:11134 [D loss: 0.562124, acc.: 69.53%] [G loss: 0.547643]\n",
      "epoch:11 step:11135 [D loss: 0.591043, acc.: 67.97%] [G loss: 0.545934]\n",
      "epoch:11 step:11136 [D loss: 0.551446, acc.: 72.66%] [G loss: 0.599227]\n",
      "epoch:11 step:11137 [D loss: 0.519183, acc.: 72.66%] [G loss: 0.467994]\n",
      "epoch:11 step:11138 [D loss: 0.553432, acc.: 73.44%] [G loss: 0.621306]\n",
      "epoch:11 step:11139 [D loss: 0.527831, acc.: 69.53%] [G loss: 0.568886]\n",
      "epoch:11 step:11140 [D loss: 0.546789, acc.: 75.78%] [G loss: 0.580096]\n",
      "epoch:11 step:11141 [D loss: 0.531313, acc.: 75.78%] [G loss: 0.518946]\n",
      "epoch:11 step:11142 [D loss: 0.513055, acc.: 69.53%] [G loss: 0.582850]\n",
      "epoch:11 step:11143 [D loss: 0.511834, acc.: 71.09%] [G loss: 0.556907]\n",
      "epoch:11 step:11144 [D loss: 0.553293, acc.: 71.88%] [G loss: 0.487687]\n",
      "epoch:11 step:11145 [D loss: 0.567396, acc.: 67.97%] [G loss: 0.427238]\n",
      "epoch:11 step:11146 [D loss: 0.552729, acc.: 67.97%] [G loss: 0.577299]\n",
      "epoch:11 step:11147 [D loss: 0.600748, acc.: 69.53%] [G loss: 0.407189]\n",
      "epoch:11 step:11148 [D loss: 0.537285, acc.: 71.09%] [G loss: 0.463242]\n",
      "epoch:11 step:11149 [D loss: 0.518115, acc.: 75.00%] [G loss: 0.536304]\n",
      "epoch:11 step:11150 [D loss: 0.491992, acc.: 78.12%] [G loss: 0.555184]\n",
      "epoch:11 step:11151 [D loss: 0.553168, acc.: 75.00%] [G loss: 0.567421]\n",
      "epoch:11 step:11152 [D loss: 0.611683, acc.: 65.62%] [G loss: 0.499184]\n",
      "epoch:11 step:11153 [D loss: 0.652917, acc.: 56.25%] [G loss: 0.407470]\n",
      "epoch:11 step:11154 [D loss: 0.590965, acc.: 68.75%] [G loss: 0.435777]\n",
      "epoch:11 step:11155 [D loss: 0.517680, acc.: 71.88%] [G loss: 0.461102]\n",
      "epoch:11 step:11156 [D loss: 0.572734, acc.: 69.53%] [G loss: 0.472645]\n",
      "epoch:11 step:11157 [D loss: 0.577429, acc.: 66.41%] [G loss: 0.410803]\n",
      "epoch:11 step:11158 [D loss: 0.594171, acc.: 64.06%] [G loss: 0.463570]\n",
      "epoch:11 step:11159 [D loss: 0.533438, acc.: 70.31%] [G loss: 0.506969]\n",
      "epoch:11 step:11160 [D loss: 0.546317, acc.: 74.22%] [G loss: 0.708501]\n",
      "epoch:11 step:11161 [D loss: 0.538811, acc.: 67.97%] [G loss: 0.496136]\n",
      "epoch:11 step:11162 [D loss: 0.538784, acc.: 71.88%] [G loss: 0.617512]\n",
      "epoch:11 step:11163 [D loss: 0.609301, acc.: 66.41%] [G loss: 0.572862]\n",
      "epoch:11 step:11164 [D loss: 0.444298, acc.: 82.03%] [G loss: 0.600852]\n",
      "epoch:11 step:11165 [D loss: 0.619080, acc.: 66.41%] [G loss: 0.633016]\n",
      "epoch:11 step:11166 [D loss: 0.579478, acc.: 69.53%] [G loss: 0.639383]\n",
      "epoch:11 step:11167 [D loss: 0.493818, acc.: 75.78%] [G loss: 0.825099]\n",
      "epoch:11 step:11168 [D loss: 0.636067, acc.: 61.72%] [G loss: 0.508710]\n",
      "epoch:11 step:11169 [D loss: 0.587186, acc.: 67.97%] [G loss: 0.331205]\n",
      "epoch:11 step:11170 [D loss: 0.606950, acc.: 62.50%] [G loss: 0.409397]\n",
      "epoch:11 step:11171 [D loss: 0.497744, acc.: 74.22%] [G loss: 0.495661]\n",
      "epoch:11 step:11172 [D loss: 0.567078, acc.: 70.31%] [G loss: 0.363130]\n",
      "epoch:11 step:11173 [D loss: 0.537683, acc.: 70.31%] [G loss: 0.414629]\n",
      "epoch:11 step:11174 [D loss: 0.660863, acc.: 62.50%] [G loss: 0.431293]\n",
      "epoch:11 step:11175 [D loss: 0.542042, acc.: 75.00%] [G loss: 0.438407]\n",
      "epoch:11 step:11176 [D loss: 0.587505, acc.: 63.28%] [G loss: 0.534331]\n",
      "epoch:11 step:11177 [D loss: 0.457180, acc.: 78.91%] [G loss: 0.740807]\n",
      "epoch:11 step:11178 [D loss: 0.582346, acc.: 68.75%] [G loss: 0.530977]\n",
      "epoch:11 step:11179 [D loss: 0.575081, acc.: 64.06%] [G loss: 0.528870]\n",
      "epoch:11 step:11180 [D loss: 0.571330, acc.: 67.19%] [G loss: 0.565653]\n",
      "epoch:11 step:11181 [D loss: 0.546440, acc.: 74.22%] [G loss: 0.466401]\n",
      "epoch:11 step:11182 [D loss: 0.488087, acc.: 75.00%] [G loss: 0.618143]\n",
      "epoch:11 step:11183 [D loss: 0.581831, acc.: 65.62%] [G loss: 0.485387]\n",
      "epoch:11 step:11184 [D loss: 0.543175, acc.: 74.22%] [G loss: 0.502167]\n",
      "epoch:11 step:11185 [D loss: 0.530790, acc.: 70.31%] [G loss: 0.561111]\n",
      "epoch:11 step:11186 [D loss: 0.508851, acc.: 76.56%] [G loss: 0.532340]\n",
      "epoch:11 step:11187 [D loss: 0.665068, acc.: 57.03%] [G loss: 0.435778]\n",
      "epoch:11 step:11188 [D loss: 0.543741, acc.: 70.31%] [G loss: 0.474850]\n",
      "epoch:11 step:11189 [D loss: 0.589414, acc.: 67.97%] [G loss: 0.462304]\n",
      "epoch:11 step:11190 [D loss: 0.534198, acc.: 75.78%] [G loss: 0.513609]\n",
      "epoch:11 step:11191 [D loss: 0.467318, acc.: 79.69%] [G loss: 0.570229]\n",
      "epoch:11 step:11192 [D loss: 0.528774, acc.: 71.09%] [G loss: 0.740018]\n",
      "epoch:11 step:11193 [D loss: 0.480808, acc.: 80.47%] [G loss: 0.595835]\n",
      "epoch:11 step:11194 [D loss: 0.570942, acc.: 67.97%] [G loss: 0.610644]\n",
      "epoch:11 step:11195 [D loss: 0.541644, acc.: 71.88%] [G loss: 0.586251]\n",
      "epoch:11 step:11196 [D loss: 0.581596, acc.: 61.72%] [G loss: 0.405433]\n",
      "epoch:11 step:11197 [D loss: 0.500330, acc.: 75.78%] [G loss: 0.673909]\n",
      "epoch:11 step:11198 [D loss: 0.604534, acc.: 67.97%] [G loss: 0.487649]\n",
      "epoch:11 step:11199 [D loss: 0.627259, acc.: 64.06%] [G loss: 0.445652]\n",
      "epoch:11 step:11200 [D loss: 0.561127, acc.: 69.53%] [G loss: 0.613653]\n",
      "##############\n",
      "[2.86203099 0.8688466  6.06158852 4.82272953 3.75034546 5.74799798\n",
      " 4.69323969 4.92787129 4.61231852 3.98623931]\n",
      "##########\n",
      "epoch:11 step:11201 [D loss: 0.458871, acc.: 78.91%] [G loss: 0.599366]\n",
      "epoch:11 step:11202 [D loss: 0.531282, acc.: 72.66%] [G loss: 0.761956]\n",
      "epoch:11 step:11203 [D loss: 0.493717, acc.: 76.56%] [G loss: 0.863958]\n",
      "epoch:11 step:11204 [D loss: 0.506740, acc.: 71.88%] [G loss: 0.700802]\n",
      "epoch:11 step:11205 [D loss: 0.464903, acc.: 78.12%] [G loss: 0.750327]\n",
      "epoch:11 step:11206 [D loss: 0.485386, acc.: 78.12%] [G loss: 0.632761]\n",
      "epoch:11 step:11207 [D loss: 0.543063, acc.: 74.22%] [G loss: 0.895754]\n",
      "epoch:11 step:11208 [D loss: 0.519828, acc.: 71.88%] [G loss: 0.777711]\n",
      "epoch:11 step:11209 [D loss: 0.564944, acc.: 71.09%] [G loss: 0.608849]\n",
      "epoch:11 step:11210 [D loss: 0.528817, acc.: 71.09%] [G loss: 0.630721]\n",
      "epoch:11 step:11211 [D loss: 0.618252, acc.: 62.50%] [G loss: 0.610268]\n",
      "epoch:11 step:11212 [D loss: 0.590317, acc.: 65.62%] [G loss: 0.506558]\n",
      "epoch:11 step:11213 [D loss: 0.471371, acc.: 75.00%] [G loss: 0.563814]\n",
      "epoch:11 step:11214 [D loss: 0.516919, acc.: 74.22%] [G loss: 0.653478]\n",
      "epoch:11 step:11215 [D loss: 0.529721, acc.: 68.75%] [G loss: 0.601314]\n",
      "epoch:11 step:11216 [D loss: 0.522324, acc.: 71.88%] [G loss: 0.662431]\n",
      "epoch:11 step:11217 [D loss: 0.535025, acc.: 69.53%] [G loss: 0.592848]\n",
      "epoch:11 step:11218 [D loss: 0.485688, acc.: 77.34%] [G loss: 0.658994]\n",
      "epoch:11 step:11219 [D loss: 0.474586, acc.: 75.00%] [G loss: 0.712993]\n",
      "epoch:11 step:11220 [D loss: 0.557703, acc.: 71.09%] [G loss: 0.672179]\n",
      "epoch:11 step:11221 [D loss: 0.479918, acc.: 74.22%] [G loss: 0.827915]\n",
      "epoch:11 step:11222 [D loss: 0.644367, acc.: 64.84%] [G loss: 0.537332]\n",
      "epoch:11 step:11223 [D loss: 0.571525, acc.: 66.41%] [G loss: 0.493738]\n",
      "epoch:11 step:11224 [D loss: 0.574852, acc.: 65.62%] [G loss: 0.631034]\n",
      "epoch:11 step:11225 [D loss: 0.500040, acc.: 78.91%] [G loss: 0.693892]\n",
      "epoch:11 step:11226 [D loss: 0.468949, acc.: 78.91%] [G loss: 0.628435]\n",
      "epoch:11 step:11227 [D loss: 0.656006, acc.: 61.72%] [G loss: 0.619828]\n",
      "epoch:11 step:11228 [D loss: 0.515335, acc.: 71.88%] [G loss: 0.577007]\n",
      "epoch:11 step:11229 [D loss: 0.535669, acc.: 71.88%] [G loss: 0.533836]\n",
      "epoch:11 step:11230 [D loss: 0.508150, acc.: 67.97%] [G loss: 0.649555]\n",
      "epoch:11 step:11231 [D loss: 0.457825, acc.: 78.91%] [G loss: 0.834088]\n",
      "epoch:11 step:11232 [D loss: 0.420000, acc.: 78.12%] [G loss: 1.022828]\n",
      "epoch:11 step:11233 [D loss: 0.423126, acc.: 79.69%] [G loss: 0.977585]\n",
      "epoch:11 step:11234 [D loss: 0.517467, acc.: 75.00%] [G loss: 1.053412]\n",
      "epoch:11 step:11235 [D loss: 0.761447, acc.: 60.16%] [G loss: 0.909571]\n",
      "epoch:11 step:11236 [D loss: 0.561391, acc.: 67.19%] [G loss: 0.960769]\n",
      "epoch:11 step:11237 [D loss: 0.493391, acc.: 75.00%] [G loss: 0.995625]\n",
      "epoch:11 step:11238 [D loss: 0.543679, acc.: 69.53%] [G loss: 1.111127]\n",
      "epoch:11 step:11239 [D loss: 0.713194, acc.: 58.59%] [G loss: 0.718315]\n",
      "epoch:11 step:11240 [D loss: 0.514937, acc.: 70.31%] [G loss: 0.723432]\n",
      "epoch:11 step:11241 [D loss: 0.564489, acc.: 67.97%] [G loss: 0.809752]\n",
      "epoch:11 step:11242 [D loss: 0.444619, acc.: 78.91%] [G loss: 0.862987]\n",
      "epoch:11 step:11243 [D loss: 0.388267, acc.: 85.94%] [G loss: 1.081295]\n",
      "epoch:11 step:11244 [D loss: 0.402856, acc.: 81.25%] [G loss: 1.405590]\n",
      "epoch:12 step:11245 [D loss: 0.634624, acc.: 67.97%] [G loss: 0.868148]\n",
      "epoch:12 step:11246 [D loss: 0.467035, acc.: 76.56%] [G loss: 1.205147]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11247 [D loss: 0.541834, acc.: 68.75%] [G loss: 0.824222]\n",
      "epoch:12 step:11248 [D loss: 0.524632, acc.: 72.66%] [G loss: 0.845772]\n",
      "epoch:12 step:11249 [D loss: 0.611836, acc.: 67.19%] [G loss: 0.578031]\n",
      "epoch:12 step:11250 [D loss: 0.582434, acc.: 68.75%] [G loss: 0.768106]\n",
      "epoch:12 step:11251 [D loss: 0.505401, acc.: 75.78%] [G loss: 0.874796]\n",
      "epoch:12 step:11252 [D loss: 0.516661, acc.: 77.34%] [G loss: 0.739363]\n",
      "epoch:12 step:11253 [D loss: 0.534374, acc.: 74.22%] [G loss: 0.683928]\n",
      "epoch:12 step:11254 [D loss: 0.469077, acc.: 77.34%] [G loss: 0.875437]\n",
      "epoch:12 step:11255 [D loss: 0.540766, acc.: 70.31%] [G loss: 0.796298]\n",
      "epoch:12 step:11256 [D loss: 0.605389, acc.: 63.28%] [G loss: 0.600846]\n",
      "epoch:12 step:11257 [D loss: 0.530504, acc.: 71.09%] [G loss: 0.641842]\n",
      "epoch:12 step:11258 [D loss: 0.573179, acc.: 66.41%] [G loss: 0.606510]\n",
      "epoch:12 step:11259 [D loss: 0.512124, acc.: 72.66%] [G loss: 0.660835]\n",
      "epoch:12 step:11260 [D loss: 0.501986, acc.: 77.34%] [G loss: 0.657632]\n",
      "epoch:12 step:11261 [D loss: 0.566719, acc.: 67.97%] [G loss: 0.599829]\n",
      "epoch:12 step:11262 [D loss: 0.598579, acc.: 66.41%] [G loss: 0.718917]\n",
      "epoch:12 step:11263 [D loss: 0.572326, acc.: 68.75%] [G loss: 0.650814]\n",
      "epoch:12 step:11264 [D loss: 0.597214, acc.: 67.97%] [G loss: 0.531914]\n",
      "epoch:12 step:11265 [D loss: 0.570203, acc.: 69.53%] [G loss: 0.600141]\n",
      "epoch:12 step:11266 [D loss: 0.483413, acc.: 76.56%] [G loss: 0.844107]\n",
      "epoch:12 step:11267 [D loss: 0.593711, acc.: 65.62%] [G loss: 0.586829]\n",
      "epoch:12 step:11268 [D loss: 0.527307, acc.: 71.88%] [G loss: 0.629990]\n",
      "epoch:12 step:11269 [D loss: 0.507572, acc.: 75.78%] [G loss: 0.703007]\n",
      "epoch:12 step:11270 [D loss: 0.551568, acc.: 71.88%] [G loss: 0.519667]\n",
      "epoch:12 step:11271 [D loss: 0.501622, acc.: 72.66%] [G loss: 0.622496]\n",
      "epoch:12 step:11272 [D loss: 0.524994, acc.: 73.44%] [G loss: 0.518218]\n",
      "epoch:12 step:11273 [D loss: 0.522243, acc.: 75.00%] [G loss: 0.437707]\n",
      "epoch:12 step:11274 [D loss: 0.579210, acc.: 67.97%] [G loss: 0.538489]\n",
      "epoch:12 step:11275 [D loss: 0.651674, acc.: 60.94%] [G loss: 0.421071]\n",
      "epoch:12 step:11276 [D loss: 0.561243, acc.: 65.62%] [G loss: 0.531392]\n",
      "epoch:12 step:11277 [D loss: 0.554783, acc.: 71.09%] [G loss: 0.536878]\n",
      "epoch:12 step:11278 [D loss: 0.550319, acc.: 69.53%] [G loss: 0.563672]\n",
      "epoch:12 step:11279 [D loss: 0.545785, acc.: 72.66%] [G loss: 0.510198]\n",
      "epoch:12 step:11280 [D loss: 0.534957, acc.: 67.97%] [G loss: 0.804587]\n",
      "epoch:12 step:11281 [D loss: 0.463955, acc.: 80.47%] [G loss: 0.646383]\n",
      "epoch:12 step:11282 [D loss: 0.582869, acc.: 69.53%] [G loss: 0.493993]\n",
      "epoch:12 step:11283 [D loss: 0.540616, acc.: 74.22%] [G loss: 0.577273]\n",
      "epoch:12 step:11284 [D loss: 0.402162, acc.: 85.94%] [G loss: 0.819593]\n",
      "epoch:12 step:11285 [D loss: 0.510632, acc.: 77.34%] [G loss: 0.783842]\n",
      "epoch:12 step:11286 [D loss: 0.498063, acc.: 73.44%] [G loss: 0.613864]\n",
      "epoch:12 step:11287 [D loss: 0.537913, acc.: 71.88%] [G loss: 0.629445]\n",
      "epoch:12 step:11288 [D loss: 0.595685, acc.: 64.84%] [G loss: 0.505830]\n",
      "epoch:12 step:11289 [D loss: 0.471004, acc.: 77.34%] [G loss: 0.721833]\n",
      "epoch:12 step:11290 [D loss: 0.555904, acc.: 68.75%] [G loss: 0.575832]\n",
      "epoch:12 step:11291 [D loss: 0.535876, acc.: 74.22%] [G loss: 0.631840]\n",
      "epoch:12 step:11292 [D loss: 0.539678, acc.: 70.31%] [G loss: 0.623951]\n",
      "epoch:12 step:11293 [D loss: 0.504609, acc.: 76.56%] [G loss: 0.782180]\n",
      "epoch:12 step:11294 [D loss: 0.539862, acc.: 72.66%] [G loss: 0.600155]\n",
      "epoch:12 step:11295 [D loss: 0.618140, acc.: 66.41%] [G loss: 0.503908]\n",
      "epoch:12 step:11296 [D loss: 0.582995, acc.: 71.09%] [G loss: 0.609106]\n",
      "epoch:12 step:11297 [D loss: 0.541765, acc.: 71.09%] [G loss: 0.777493]\n",
      "epoch:12 step:11298 [D loss: 0.498242, acc.: 76.56%] [G loss: 0.878852]\n",
      "epoch:12 step:11299 [D loss: 0.554709, acc.: 68.75%] [G loss: 0.700965]\n",
      "epoch:12 step:11300 [D loss: 0.507658, acc.: 75.00%] [G loss: 0.618438]\n",
      "epoch:12 step:11301 [D loss: 0.515034, acc.: 74.22%] [G loss: 0.667625]\n",
      "epoch:12 step:11302 [D loss: 0.555001, acc.: 66.41%] [G loss: 0.587247]\n",
      "epoch:12 step:11303 [D loss: 0.513390, acc.: 74.22%] [G loss: 0.547374]\n",
      "epoch:12 step:11304 [D loss: 0.527415, acc.: 66.41%] [G loss: 0.745424]\n",
      "epoch:12 step:11305 [D loss: 0.577408, acc.: 64.06%] [G loss: 0.518056]\n",
      "epoch:12 step:11306 [D loss: 0.554515, acc.: 72.66%] [G loss: 0.573177]\n",
      "epoch:12 step:11307 [D loss: 0.549143, acc.: 64.06%] [G loss: 0.607831]\n",
      "epoch:12 step:11308 [D loss: 0.546217, acc.: 72.66%] [G loss: 0.719094]\n",
      "epoch:12 step:11309 [D loss: 0.506991, acc.: 75.78%] [G loss: 0.640612]\n",
      "epoch:12 step:11310 [D loss: 0.486680, acc.: 75.00%] [G loss: 0.718188]\n",
      "epoch:12 step:11311 [D loss: 0.562948, acc.: 70.31%] [G loss: 0.560064]\n",
      "epoch:12 step:11312 [D loss: 0.528809, acc.: 71.09%] [G loss: 0.555198]\n",
      "epoch:12 step:11313 [D loss: 0.473840, acc.: 78.12%] [G loss: 0.787277]\n",
      "epoch:12 step:11314 [D loss: 0.519203, acc.: 73.44%] [G loss: 0.624690]\n",
      "epoch:12 step:11315 [D loss: 0.591035, acc.: 68.75%] [G loss: 0.505292]\n",
      "epoch:12 step:11316 [D loss: 0.530926, acc.: 73.44%] [G loss: 0.492533]\n",
      "epoch:12 step:11317 [D loss: 0.521369, acc.: 72.66%] [G loss: 0.548832]\n",
      "epoch:12 step:11318 [D loss: 0.511691, acc.: 75.78%] [G loss: 0.684782]\n",
      "epoch:12 step:11319 [D loss: 0.581492, acc.: 70.31%] [G loss: 0.728987]\n",
      "epoch:12 step:11320 [D loss: 0.503725, acc.: 71.88%] [G loss: 0.874416]\n",
      "epoch:12 step:11321 [D loss: 0.455072, acc.: 79.69%] [G loss: 0.859669]\n",
      "epoch:12 step:11322 [D loss: 0.579666, acc.: 72.66%] [G loss: 0.598059]\n",
      "epoch:12 step:11323 [D loss: 0.563859, acc.: 66.41%] [G loss: 0.670992]\n",
      "epoch:12 step:11324 [D loss: 0.556294, acc.: 67.97%] [G loss: 0.630719]\n",
      "epoch:12 step:11325 [D loss: 0.571484, acc.: 67.97%] [G loss: 0.637865]\n",
      "epoch:12 step:11326 [D loss: 0.537718, acc.: 70.31%] [G loss: 0.521107]\n",
      "epoch:12 step:11327 [D loss: 0.484159, acc.: 75.00%] [G loss: 0.604349]\n",
      "epoch:12 step:11328 [D loss: 0.546746, acc.: 72.66%] [G loss: 0.627319]\n",
      "epoch:12 step:11329 [D loss: 0.582906, acc.: 70.31%] [G loss: 0.486567]\n",
      "epoch:12 step:11330 [D loss: 0.491653, acc.: 75.00%] [G loss: 0.487671]\n",
      "epoch:12 step:11331 [D loss: 0.529011, acc.: 71.09%] [G loss: 0.595122]\n",
      "epoch:12 step:11332 [D loss: 0.496833, acc.: 76.56%] [G loss: 0.545904]\n",
      "epoch:12 step:11333 [D loss: 0.495691, acc.: 75.00%] [G loss: 0.697927]\n",
      "epoch:12 step:11334 [D loss: 0.522796, acc.: 75.78%] [G loss: 0.742936]\n",
      "epoch:12 step:11335 [D loss: 0.534629, acc.: 71.09%] [G loss: 0.724681]\n",
      "epoch:12 step:11336 [D loss: 0.502560, acc.: 75.78%] [G loss: 0.650593]\n",
      "epoch:12 step:11337 [D loss: 0.493209, acc.: 78.12%] [G loss: 0.709668]\n",
      "epoch:12 step:11338 [D loss: 0.528304, acc.: 67.97%] [G loss: 0.681607]\n",
      "epoch:12 step:11339 [D loss: 0.505086, acc.: 74.22%] [G loss: 0.709232]\n",
      "epoch:12 step:11340 [D loss: 0.572553, acc.: 64.84%] [G loss: 0.606976]\n",
      "epoch:12 step:11341 [D loss: 0.514367, acc.: 73.44%] [G loss: 0.741119]\n",
      "epoch:12 step:11342 [D loss: 0.548072, acc.: 70.31%] [G loss: 0.747699]\n",
      "epoch:12 step:11343 [D loss: 0.524242, acc.: 71.09%] [G loss: 0.604497]\n",
      "epoch:12 step:11344 [D loss: 0.466862, acc.: 75.78%] [G loss: 0.961954]\n",
      "epoch:12 step:11345 [D loss: 0.487102, acc.: 72.66%] [G loss: 0.822692]\n",
      "epoch:12 step:11346 [D loss: 0.648723, acc.: 59.38%] [G loss: 0.646224]\n",
      "epoch:12 step:11347 [D loss: 0.484562, acc.: 75.00%] [G loss: 0.569491]\n",
      "epoch:12 step:11348 [D loss: 0.480721, acc.: 73.44%] [G loss: 0.594405]\n",
      "epoch:12 step:11349 [D loss: 0.571151, acc.: 64.84%] [G loss: 0.550368]\n",
      "epoch:12 step:11350 [D loss: 0.509524, acc.: 73.44%] [G loss: 0.642924]\n",
      "epoch:12 step:11351 [D loss: 0.575452, acc.: 67.19%] [G loss: 0.537409]\n",
      "epoch:12 step:11352 [D loss: 0.627428, acc.: 67.19%] [G loss: 0.651510]\n",
      "epoch:12 step:11353 [D loss: 0.576673, acc.: 66.41%] [G loss: 0.533171]\n",
      "epoch:12 step:11354 [D loss: 0.543872, acc.: 70.31%] [G loss: 0.559339]\n",
      "epoch:12 step:11355 [D loss: 0.548107, acc.: 71.09%] [G loss: 0.531672]\n",
      "epoch:12 step:11356 [D loss: 0.517648, acc.: 73.44%] [G loss: 0.791467]\n",
      "epoch:12 step:11357 [D loss: 0.550313, acc.: 73.44%] [G loss: 0.632537]\n",
      "epoch:12 step:11358 [D loss: 0.554417, acc.: 71.09%] [G loss: 0.666206]\n",
      "epoch:12 step:11359 [D loss: 0.527486, acc.: 78.91%] [G loss: 0.633036]\n",
      "epoch:12 step:11360 [D loss: 0.504501, acc.: 72.66%] [G loss: 0.695212]\n",
      "epoch:12 step:11361 [D loss: 0.550414, acc.: 68.75%] [G loss: 0.630026]\n",
      "epoch:12 step:11362 [D loss: 0.500477, acc.: 68.75%] [G loss: 0.667501]\n",
      "epoch:12 step:11363 [D loss: 0.480011, acc.: 75.00%] [G loss: 0.878326]\n",
      "epoch:12 step:11364 [D loss: 0.547698, acc.: 73.44%] [G loss: 0.794098]\n",
      "epoch:12 step:11365 [D loss: 0.546307, acc.: 71.09%] [G loss: 0.793686]\n",
      "epoch:12 step:11366 [D loss: 0.453159, acc.: 82.81%] [G loss: 0.819042]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11367 [D loss: 0.560136, acc.: 67.19%] [G loss: 0.843585]\n",
      "epoch:12 step:11368 [D loss: 0.581371, acc.: 70.31%] [G loss: 0.663725]\n",
      "epoch:12 step:11369 [D loss: 0.590265, acc.: 67.19%] [G loss: 0.725519]\n",
      "epoch:12 step:11370 [D loss: 0.504272, acc.: 75.00%] [G loss: 0.574285]\n",
      "epoch:12 step:11371 [D loss: 0.488866, acc.: 73.44%] [G loss: 0.752276]\n",
      "epoch:12 step:11372 [D loss: 0.516789, acc.: 75.00%] [G loss: 0.690892]\n",
      "epoch:12 step:11373 [D loss: 0.576465, acc.: 70.31%] [G loss: 0.681959]\n",
      "epoch:12 step:11374 [D loss: 0.476653, acc.: 77.34%] [G loss: 0.684218]\n",
      "epoch:12 step:11375 [D loss: 0.531626, acc.: 71.88%] [G loss: 0.607713]\n",
      "epoch:12 step:11376 [D loss: 0.542349, acc.: 67.19%] [G loss: 0.643372]\n",
      "epoch:12 step:11377 [D loss: 0.509193, acc.: 74.22%] [G loss: 0.672120]\n",
      "epoch:12 step:11378 [D loss: 0.569279, acc.: 69.53%] [G loss: 0.789584]\n",
      "epoch:12 step:11379 [D loss: 0.568803, acc.: 69.53%] [G loss: 0.515922]\n",
      "epoch:12 step:11380 [D loss: 0.535295, acc.: 71.88%] [G loss: 0.632919]\n",
      "epoch:12 step:11381 [D loss: 0.642783, acc.: 60.94%] [G loss: 0.545191]\n",
      "epoch:12 step:11382 [D loss: 0.507639, acc.: 72.66%] [G loss: 0.571647]\n",
      "epoch:12 step:11383 [D loss: 0.574201, acc.: 70.31%] [G loss: 0.581815]\n",
      "epoch:12 step:11384 [D loss: 0.526758, acc.: 71.09%] [G loss: 0.587198]\n",
      "epoch:12 step:11385 [D loss: 0.526483, acc.: 71.88%] [G loss: 0.676051]\n",
      "epoch:12 step:11386 [D loss: 0.569214, acc.: 64.06%] [G loss: 0.541317]\n",
      "epoch:12 step:11387 [D loss: 0.583546, acc.: 71.09%] [G loss: 0.483974]\n",
      "epoch:12 step:11388 [D loss: 0.510529, acc.: 73.44%] [G loss: 0.595854]\n",
      "epoch:12 step:11389 [D loss: 0.581742, acc.: 65.62%] [G loss: 0.579919]\n",
      "epoch:12 step:11390 [D loss: 0.478916, acc.: 79.69%] [G loss: 0.839398]\n",
      "epoch:12 step:11391 [D loss: 0.602002, acc.: 70.31%] [G loss: 0.760564]\n",
      "epoch:12 step:11392 [D loss: 0.574357, acc.: 67.97%] [G loss: 0.564801]\n",
      "epoch:12 step:11393 [D loss: 0.464745, acc.: 75.78%] [G loss: 0.659863]\n",
      "epoch:12 step:11394 [D loss: 0.633600, acc.: 64.84%] [G loss: 0.565611]\n",
      "epoch:12 step:11395 [D loss: 0.529755, acc.: 73.44%] [G loss: 0.682093]\n",
      "epoch:12 step:11396 [D loss: 0.498443, acc.: 76.56%] [G loss: 0.709835]\n",
      "epoch:12 step:11397 [D loss: 0.587002, acc.: 65.62%] [G loss: 0.612711]\n",
      "epoch:12 step:11398 [D loss: 0.560522, acc.: 68.75%] [G loss: 0.546652]\n",
      "epoch:12 step:11399 [D loss: 0.531834, acc.: 71.09%] [G loss: 0.483349]\n",
      "epoch:12 step:11400 [D loss: 0.508370, acc.: 75.00%] [G loss: 0.638820]\n",
      "##############\n",
      "[3.16137325 1.35726486 5.89990733 5.02825356 3.88258649 5.6793532\n",
      " 4.62622785 4.80355429 4.86978902 3.95946059]\n",
      "##########\n",
      "epoch:12 step:11401 [D loss: 0.551283, acc.: 70.31%] [G loss: 0.635921]\n",
      "epoch:12 step:11402 [D loss: 0.554139, acc.: 67.19%] [G loss: 0.571739]\n",
      "epoch:12 step:11403 [D loss: 0.482055, acc.: 78.12%] [G loss: 0.630982]\n",
      "epoch:12 step:11404 [D loss: 0.635352, acc.: 64.06%] [G loss: 0.651531]\n",
      "epoch:12 step:11405 [D loss: 0.562062, acc.: 63.28%] [G loss: 0.562180]\n",
      "epoch:12 step:11406 [D loss: 0.467349, acc.: 79.69%] [G loss: 0.648603]\n",
      "epoch:12 step:11407 [D loss: 0.529484, acc.: 66.41%] [G loss: 0.774042]\n",
      "epoch:12 step:11408 [D loss: 0.559757, acc.: 69.53%] [G loss: 0.621318]\n",
      "epoch:12 step:11409 [D loss: 0.511650, acc.: 74.22%] [G loss: 0.568378]\n",
      "epoch:12 step:11410 [D loss: 0.550393, acc.: 67.19%] [G loss: 0.659890]\n",
      "epoch:12 step:11411 [D loss: 0.527803, acc.: 70.31%] [G loss: 0.664829]\n",
      "epoch:12 step:11412 [D loss: 0.550426, acc.: 68.75%] [G loss: 0.611195]\n",
      "epoch:12 step:11413 [D loss: 0.538275, acc.: 69.53%] [G loss: 0.645591]\n",
      "epoch:12 step:11414 [D loss: 0.540154, acc.: 69.53%] [G loss: 0.549890]\n",
      "epoch:12 step:11415 [D loss: 0.537395, acc.: 71.09%] [G loss: 0.512487]\n",
      "epoch:12 step:11416 [D loss: 0.510567, acc.: 71.88%] [G loss: 0.657355]\n",
      "epoch:12 step:11417 [D loss: 0.508656, acc.: 71.09%] [G loss: 0.578783]\n",
      "epoch:12 step:11418 [D loss: 0.565937, acc.: 71.88%] [G loss: 0.529681]\n",
      "epoch:12 step:11419 [D loss: 0.614093, acc.: 65.62%] [G loss: 0.560449]\n",
      "epoch:12 step:11420 [D loss: 0.556434, acc.: 67.97%] [G loss: 0.502236]\n",
      "epoch:12 step:11421 [D loss: 0.544071, acc.: 74.22%] [G loss: 0.564137]\n",
      "epoch:12 step:11422 [D loss: 0.573811, acc.: 67.97%] [G loss: 0.573055]\n",
      "epoch:12 step:11423 [D loss: 0.572955, acc.: 67.19%] [G loss: 0.473044]\n",
      "epoch:12 step:11424 [D loss: 0.600632, acc.: 66.41%] [G loss: 0.473975]\n",
      "epoch:12 step:11425 [D loss: 0.585135, acc.: 67.19%] [G loss: 0.431233]\n",
      "epoch:12 step:11426 [D loss: 0.529336, acc.: 74.22%] [G loss: 0.546819]\n",
      "epoch:12 step:11427 [D loss: 0.580979, acc.: 70.31%] [G loss: 0.579283]\n",
      "epoch:12 step:11428 [D loss: 0.588107, acc.: 68.75%] [G loss: 0.678672]\n",
      "epoch:12 step:11429 [D loss: 0.567936, acc.: 68.75%] [G loss: 0.682391]\n",
      "epoch:12 step:11430 [D loss: 0.516140, acc.: 73.44%] [G loss: 0.687958]\n",
      "epoch:12 step:11431 [D loss: 0.619783, acc.: 62.50%] [G loss: 0.511065]\n",
      "epoch:12 step:11432 [D loss: 0.536118, acc.: 71.88%] [G loss: 0.596573]\n",
      "epoch:12 step:11433 [D loss: 0.614283, acc.: 62.50%] [G loss: 0.518496]\n",
      "epoch:12 step:11434 [D loss: 0.492087, acc.: 78.12%] [G loss: 0.575058]\n",
      "epoch:12 step:11435 [D loss: 0.521249, acc.: 74.22%] [G loss: 0.677491]\n",
      "epoch:12 step:11436 [D loss: 0.511917, acc.: 74.22%] [G loss: 0.653729]\n",
      "epoch:12 step:11437 [D loss: 0.581653, acc.: 71.09%] [G loss: 0.556858]\n",
      "epoch:12 step:11438 [D loss: 0.476988, acc.: 78.12%] [G loss: 0.612860]\n",
      "epoch:12 step:11439 [D loss: 0.561727, acc.: 73.44%] [G loss: 0.625306]\n",
      "epoch:12 step:11440 [D loss: 0.544406, acc.: 69.53%] [G loss: 0.610307]\n",
      "epoch:12 step:11441 [D loss: 0.527424, acc.: 75.00%] [G loss: 0.647601]\n",
      "epoch:12 step:11442 [D loss: 0.467970, acc.: 77.34%] [G loss: 0.594439]\n",
      "epoch:12 step:11443 [D loss: 0.494837, acc.: 75.00%] [G loss: 0.638868]\n",
      "epoch:12 step:11444 [D loss: 0.629546, acc.: 61.72%] [G loss: 0.516169]\n",
      "epoch:12 step:11445 [D loss: 0.549893, acc.: 73.44%] [G loss: 0.444384]\n",
      "epoch:12 step:11446 [D loss: 0.547274, acc.: 71.88%] [G loss: 0.764702]\n",
      "epoch:12 step:11447 [D loss: 0.601489, acc.: 64.84%] [G loss: 0.524587]\n",
      "epoch:12 step:11448 [D loss: 0.595130, acc.: 67.19%] [G loss: 0.518871]\n",
      "epoch:12 step:11449 [D loss: 0.521773, acc.: 71.88%] [G loss: 0.580648]\n",
      "epoch:12 step:11450 [D loss: 0.529869, acc.: 74.22%] [G loss: 0.745041]\n",
      "epoch:12 step:11451 [D loss: 0.507192, acc.: 75.78%] [G loss: 0.613370]\n",
      "epoch:12 step:11452 [D loss: 0.452956, acc.: 78.12%] [G loss: 0.788452]\n",
      "epoch:12 step:11453 [D loss: 0.491399, acc.: 75.78%] [G loss: 0.735705]\n",
      "epoch:12 step:11454 [D loss: 0.644540, acc.: 62.50%] [G loss: 0.592557]\n",
      "epoch:12 step:11455 [D loss: 0.634704, acc.: 61.72%] [G loss: 0.544716]\n",
      "epoch:12 step:11456 [D loss: 0.544297, acc.: 75.78%] [G loss: 0.598981]\n",
      "epoch:12 step:11457 [D loss: 0.520788, acc.: 71.09%] [G loss: 0.577978]\n",
      "epoch:12 step:11458 [D loss: 0.660918, acc.: 59.38%] [G loss: 0.523371]\n",
      "epoch:12 step:11459 [D loss: 0.565414, acc.: 64.84%] [G loss: 0.530456]\n",
      "epoch:12 step:11460 [D loss: 0.537004, acc.: 74.22%] [G loss: 0.640247]\n",
      "epoch:12 step:11461 [D loss: 0.539592, acc.: 74.22%] [G loss: 0.524320]\n",
      "epoch:12 step:11462 [D loss: 0.586080, acc.: 68.75%] [G loss: 0.592095]\n",
      "epoch:12 step:11463 [D loss: 0.501112, acc.: 77.34%] [G loss: 0.617277]\n",
      "epoch:12 step:11464 [D loss: 0.559071, acc.: 71.09%] [G loss: 0.574952]\n",
      "epoch:12 step:11465 [D loss: 0.566527, acc.: 69.53%] [G loss: 0.457196]\n",
      "epoch:12 step:11466 [D loss: 0.467109, acc.: 76.56%] [G loss: 0.693289]\n",
      "epoch:12 step:11467 [D loss: 0.544143, acc.: 74.22%] [G loss: 0.686941]\n",
      "epoch:12 step:11468 [D loss: 0.568041, acc.: 69.53%] [G loss: 0.603342]\n",
      "epoch:12 step:11469 [D loss: 0.537237, acc.: 71.88%] [G loss: 0.543595]\n",
      "epoch:12 step:11470 [D loss: 0.569186, acc.: 64.06%] [G loss: 0.522076]\n",
      "epoch:12 step:11471 [D loss: 0.497475, acc.: 75.78%] [G loss: 0.576616]\n",
      "epoch:12 step:11472 [D loss: 0.648046, acc.: 60.94%] [G loss: 0.525628]\n",
      "epoch:12 step:11473 [D loss: 0.512941, acc.: 76.56%] [G loss: 0.505750]\n",
      "epoch:12 step:11474 [D loss: 0.508742, acc.: 74.22%] [G loss: 0.656295]\n",
      "epoch:12 step:11475 [D loss: 0.522696, acc.: 71.88%] [G loss: 0.870365]\n",
      "epoch:12 step:11476 [D loss: 0.466495, acc.: 81.25%] [G loss: 0.934589]\n",
      "epoch:12 step:11477 [D loss: 0.564039, acc.: 72.66%] [G loss: 0.648550]\n",
      "epoch:12 step:11478 [D loss: 0.551009, acc.: 73.44%] [G loss: 0.701729]\n",
      "epoch:12 step:11479 [D loss: 0.565630, acc.: 67.97%] [G loss: 0.597407]\n",
      "epoch:12 step:11480 [D loss: 0.509419, acc.: 73.44%] [G loss: 0.388865]\n",
      "epoch:12 step:11481 [D loss: 0.514979, acc.: 71.88%] [G loss: 0.573979]\n",
      "epoch:12 step:11482 [D loss: 0.539344, acc.: 72.66%] [G loss: 0.553830]\n",
      "epoch:12 step:11483 [D loss: 0.519490, acc.: 75.78%] [G loss: 0.551432]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11484 [D loss: 0.572464, acc.: 68.75%] [G loss: 0.535951]\n",
      "epoch:12 step:11485 [D loss: 0.540035, acc.: 73.44%] [G loss: 0.626458]\n",
      "epoch:12 step:11486 [D loss: 0.492530, acc.: 72.66%] [G loss: 0.697111]\n",
      "epoch:12 step:11487 [D loss: 0.571113, acc.: 69.53%] [G loss: 0.639667]\n",
      "epoch:12 step:11488 [D loss: 0.492813, acc.: 74.22%] [G loss: 0.800495]\n",
      "epoch:12 step:11489 [D loss: 0.532014, acc.: 74.22%] [G loss: 0.869368]\n",
      "epoch:12 step:11490 [D loss: 0.502998, acc.: 78.91%] [G loss: 0.703516]\n",
      "epoch:12 step:11491 [D loss: 0.516989, acc.: 73.44%] [G loss: 0.767697]\n",
      "epoch:12 step:11492 [D loss: 0.481030, acc.: 78.91%] [G loss: 0.661472]\n",
      "epoch:12 step:11493 [D loss: 0.605812, acc.: 69.53%] [G loss: 0.554540]\n",
      "epoch:12 step:11494 [D loss: 0.654712, acc.: 65.62%] [G loss: 0.656741]\n",
      "epoch:12 step:11495 [D loss: 0.625513, acc.: 62.50%] [G loss: 0.621492]\n",
      "epoch:12 step:11496 [D loss: 0.583042, acc.: 67.19%] [G loss: 0.754884]\n",
      "epoch:12 step:11497 [D loss: 0.613666, acc.: 64.84%] [G loss: 0.492752]\n",
      "epoch:12 step:11498 [D loss: 0.518393, acc.: 72.66%] [G loss: 0.504692]\n",
      "epoch:12 step:11499 [D loss: 0.533661, acc.: 70.31%] [G loss: 0.493000]\n",
      "epoch:12 step:11500 [D loss: 0.582315, acc.: 61.72%] [G loss: 0.481122]\n",
      "epoch:12 step:11501 [D loss: 0.602971, acc.: 60.16%] [G loss: 0.552618]\n",
      "epoch:12 step:11502 [D loss: 0.541394, acc.: 72.66%] [G loss: 0.580041]\n",
      "epoch:12 step:11503 [D loss: 0.537447, acc.: 74.22%] [G loss: 0.658572]\n",
      "epoch:12 step:11504 [D loss: 0.587022, acc.: 67.19%] [G loss: 0.595973]\n",
      "epoch:12 step:11505 [D loss: 0.529250, acc.: 73.44%] [G loss: 0.680856]\n",
      "epoch:12 step:11506 [D loss: 0.511412, acc.: 71.88%] [G loss: 0.613549]\n",
      "epoch:12 step:11507 [D loss: 0.569681, acc.: 72.66%] [G loss: 0.467530]\n",
      "epoch:12 step:11508 [D loss: 0.516135, acc.: 71.88%] [G loss: 0.510269]\n",
      "epoch:12 step:11509 [D loss: 0.566177, acc.: 68.75%] [G loss: 0.566398]\n",
      "epoch:12 step:11510 [D loss: 0.496181, acc.: 78.12%] [G loss: 0.631139]\n",
      "epoch:12 step:11511 [D loss: 0.502425, acc.: 72.66%] [G loss: 0.707178]\n",
      "epoch:12 step:11512 [D loss: 0.567968, acc.: 67.97%] [G loss: 0.578103]\n",
      "epoch:12 step:11513 [D loss: 0.558379, acc.: 68.75%] [G loss: 0.533342]\n",
      "epoch:12 step:11514 [D loss: 0.541281, acc.: 67.97%] [G loss: 0.539493]\n",
      "epoch:12 step:11515 [D loss: 0.539665, acc.: 70.31%] [G loss: 0.500522]\n",
      "epoch:12 step:11516 [D loss: 0.560662, acc.: 64.84%] [G loss: 0.589419]\n",
      "epoch:12 step:11517 [D loss: 0.477231, acc.: 75.78%] [G loss: 0.610602]\n",
      "epoch:12 step:11518 [D loss: 0.558724, acc.: 70.31%] [G loss: 0.664497]\n",
      "epoch:12 step:11519 [D loss: 0.617924, acc.: 61.72%] [G loss: 0.558121]\n",
      "epoch:12 step:11520 [D loss: 0.471396, acc.: 80.47%] [G loss: 0.606983]\n",
      "epoch:12 step:11521 [D loss: 0.609565, acc.: 65.62%] [G loss: 0.514353]\n",
      "epoch:12 step:11522 [D loss: 0.640094, acc.: 59.38%] [G loss: 0.554712]\n",
      "epoch:12 step:11523 [D loss: 0.470457, acc.: 77.34%] [G loss: 0.675162]\n",
      "epoch:12 step:11524 [D loss: 0.534666, acc.: 71.09%] [G loss: 0.651674]\n",
      "epoch:12 step:11525 [D loss: 0.577473, acc.: 72.66%] [G loss: 0.623815]\n",
      "epoch:12 step:11526 [D loss: 0.595484, acc.: 68.75%] [G loss: 0.692792]\n",
      "epoch:12 step:11527 [D loss: 0.458168, acc.: 80.47%] [G loss: 0.660846]\n",
      "epoch:12 step:11528 [D loss: 0.520141, acc.: 73.44%] [G loss: 0.604985]\n",
      "epoch:12 step:11529 [D loss: 0.501606, acc.: 73.44%] [G loss: 0.684249]\n",
      "epoch:12 step:11530 [D loss: 0.491120, acc.: 71.88%] [G loss: 0.749104]\n",
      "epoch:12 step:11531 [D loss: 0.583617, acc.: 64.84%] [G loss: 0.619593]\n",
      "epoch:12 step:11532 [D loss: 0.571744, acc.: 69.53%] [G loss: 0.572967]\n",
      "epoch:12 step:11533 [D loss: 0.532185, acc.: 71.88%] [G loss: 0.525677]\n",
      "epoch:12 step:11534 [D loss: 0.560028, acc.: 65.62%] [G loss: 0.677778]\n",
      "epoch:12 step:11535 [D loss: 0.553083, acc.: 74.22%] [G loss: 0.534881]\n",
      "epoch:12 step:11536 [D loss: 0.532047, acc.: 72.66%] [G loss: 0.667112]\n",
      "epoch:12 step:11537 [D loss: 0.621525, acc.: 64.84%] [G loss: 0.563324]\n",
      "epoch:12 step:11538 [D loss: 0.573906, acc.: 72.66%] [G loss: 0.514913]\n",
      "epoch:12 step:11539 [D loss: 0.576024, acc.: 60.94%] [G loss: 0.656989]\n",
      "epoch:12 step:11540 [D loss: 0.468772, acc.: 78.91%] [G loss: 0.537537]\n",
      "epoch:12 step:11541 [D loss: 0.528905, acc.: 75.00%] [G loss: 0.587654]\n",
      "epoch:12 step:11542 [D loss: 0.514066, acc.: 75.00%] [G loss: 0.514752]\n",
      "epoch:12 step:11543 [D loss: 0.498493, acc.: 73.44%] [G loss: 0.617724]\n",
      "epoch:12 step:11544 [D loss: 0.493862, acc.: 75.78%] [G loss: 0.756431]\n",
      "epoch:12 step:11545 [D loss: 0.607330, acc.: 65.62%] [G loss: 0.764176]\n",
      "epoch:12 step:11546 [D loss: 0.556090, acc.: 71.09%] [G loss: 0.573372]\n",
      "epoch:12 step:11547 [D loss: 0.487153, acc.: 78.91%] [G loss: 0.715472]\n",
      "epoch:12 step:11548 [D loss: 0.532530, acc.: 68.75%] [G loss: 0.579596]\n",
      "epoch:12 step:11549 [D loss: 0.529481, acc.: 67.97%] [G loss: 0.639132]\n",
      "epoch:12 step:11550 [D loss: 0.560518, acc.: 67.19%] [G loss: 0.738588]\n",
      "epoch:12 step:11551 [D loss: 0.481962, acc.: 76.56%] [G loss: 0.710351]\n",
      "epoch:12 step:11552 [D loss: 0.551334, acc.: 69.53%] [G loss: 0.611814]\n",
      "epoch:12 step:11553 [D loss: 0.492069, acc.: 71.88%] [G loss: 0.702080]\n",
      "epoch:12 step:11554 [D loss: 0.528995, acc.: 71.09%] [G loss: 0.667365]\n",
      "epoch:12 step:11555 [D loss: 0.507571, acc.: 74.22%] [G loss: 0.748944]\n",
      "epoch:12 step:11556 [D loss: 0.521150, acc.: 74.22%] [G loss: 0.875297]\n",
      "epoch:12 step:11557 [D loss: 0.452460, acc.: 82.03%] [G loss: 0.966208]\n",
      "epoch:12 step:11558 [D loss: 0.479652, acc.: 76.56%] [G loss: 0.855821]\n",
      "epoch:12 step:11559 [D loss: 0.474963, acc.: 76.56%] [G loss: 0.789491]\n",
      "epoch:12 step:11560 [D loss: 0.662564, acc.: 61.72%] [G loss: 0.664162]\n",
      "epoch:12 step:11561 [D loss: 0.566593, acc.: 67.97%] [G loss: 0.628355]\n",
      "epoch:12 step:11562 [D loss: 0.530911, acc.: 75.78%] [G loss: 0.669017]\n",
      "epoch:12 step:11563 [D loss: 0.522888, acc.: 72.66%] [G loss: 0.533750]\n",
      "epoch:12 step:11564 [D loss: 0.548202, acc.: 67.19%] [G loss: 0.741934]\n",
      "epoch:12 step:11565 [D loss: 0.467018, acc.: 78.91%] [G loss: 0.663669]\n",
      "epoch:12 step:11566 [D loss: 0.543728, acc.: 71.09%] [G loss: 0.653192]\n",
      "epoch:12 step:11567 [D loss: 0.609066, acc.: 61.72%] [G loss: 0.566286]\n",
      "epoch:12 step:11568 [D loss: 0.552249, acc.: 66.41%] [G loss: 0.483510]\n",
      "epoch:12 step:11569 [D loss: 0.565562, acc.: 71.09%] [G loss: 0.425749]\n",
      "epoch:12 step:11570 [D loss: 0.459402, acc.: 82.03%] [G loss: 0.548735]\n",
      "epoch:12 step:11571 [D loss: 0.508511, acc.: 73.44%] [G loss: 0.631548]\n",
      "epoch:12 step:11572 [D loss: 0.457214, acc.: 81.25%] [G loss: 0.643563]\n",
      "epoch:12 step:11573 [D loss: 0.497187, acc.: 75.00%] [G loss: 0.757425]\n",
      "epoch:12 step:11574 [D loss: 0.634766, acc.: 64.84%] [G loss: 0.496414]\n",
      "epoch:12 step:11575 [D loss: 0.564363, acc.: 67.19%] [G loss: 0.524616]\n",
      "epoch:12 step:11576 [D loss: 0.533324, acc.: 68.75%] [G loss: 0.548710]\n",
      "epoch:12 step:11577 [D loss: 0.479238, acc.: 75.00%] [G loss: 0.691061]\n",
      "epoch:12 step:11578 [D loss: 0.545010, acc.: 72.66%] [G loss: 0.601480]\n",
      "epoch:12 step:11579 [D loss: 0.553687, acc.: 69.53%] [G loss: 0.532564]\n",
      "epoch:12 step:11580 [D loss: 0.516660, acc.: 71.09%] [G loss: 0.522041]\n",
      "epoch:12 step:11581 [D loss: 0.522880, acc.: 74.22%] [G loss: 0.614289]\n",
      "epoch:12 step:11582 [D loss: 0.491437, acc.: 77.34%] [G loss: 0.535341]\n",
      "epoch:12 step:11583 [D loss: 0.564308, acc.: 68.75%] [G loss: 0.430439]\n",
      "epoch:12 step:11584 [D loss: 0.488433, acc.: 78.12%] [G loss: 0.594097]\n",
      "epoch:12 step:11585 [D loss: 0.601646, acc.: 66.41%] [G loss: 0.617373]\n",
      "epoch:12 step:11586 [D loss: 0.740653, acc.: 50.00%] [G loss: 0.498778]\n",
      "epoch:12 step:11587 [D loss: 0.547712, acc.: 67.97%] [G loss: 0.558670]\n",
      "epoch:12 step:11588 [D loss: 0.479664, acc.: 72.66%] [G loss: 0.722519]\n",
      "epoch:12 step:11589 [D loss: 0.531418, acc.: 70.31%] [G loss: 0.817872]\n",
      "epoch:12 step:11590 [D loss: 0.584366, acc.: 67.97%] [G loss: 0.844671]\n",
      "epoch:12 step:11591 [D loss: 0.437077, acc.: 79.69%] [G loss: 0.985224]\n",
      "epoch:12 step:11592 [D loss: 0.656000, acc.: 67.97%] [G loss: 0.646549]\n",
      "epoch:12 step:11593 [D loss: 0.715877, acc.: 56.25%] [G loss: 0.505505]\n",
      "epoch:12 step:11594 [D loss: 0.482809, acc.: 78.91%] [G loss: 0.683671]\n",
      "epoch:12 step:11595 [D loss: 0.539164, acc.: 69.53%] [G loss: 0.592243]\n",
      "epoch:12 step:11596 [D loss: 0.594051, acc.: 68.75%] [G loss: 0.727944]\n",
      "epoch:12 step:11597 [D loss: 0.615300, acc.: 65.62%] [G loss: 0.734898]\n",
      "epoch:12 step:11598 [D loss: 0.410320, acc.: 85.16%] [G loss: 0.871030]\n",
      "epoch:12 step:11599 [D loss: 0.604957, acc.: 65.62%] [G loss: 0.637097]\n",
      "epoch:12 step:11600 [D loss: 0.555927, acc.: 68.75%] [G loss: 0.608928]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[2.79313688 1.28438503 6.12607122 5.12855139 3.89057983 5.80717058\n",
      " 4.57147805 5.05402994 4.85119878 4.2401815 ]\n",
      "##########\n",
      "epoch:12 step:11601 [D loss: 0.523793, acc.: 71.88%] [G loss: 0.689272]\n",
      "epoch:12 step:11602 [D loss: 0.456923, acc.: 78.91%] [G loss: 0.743749]\n",
      "epoch:12 step:11603 [D loss: 0.481342, acc.: 74.22%] [G loss: 0.676611]\n",
      "epoch:12 step:11604 [D loss: 0.486129, acc.: 75.00%] [G loss: 0.731736]\n",
      "epoch:12 step:11605 [D loss: 0.518165, acc.: 75.00%] [G loss: 0.641195]\n",
      "epoch:12 step:11606 [D loss: 0.598141, acc.: 68.75%] [G loss: 0.688755]\n",
      "epoch:12 step:11607 [D loss: 0.618849, acc.: 65.62%] [G loss: 0.535593]\n",
      "epoch:12 step:11608 [D loss: 0.495680, acc.: 75.78%] [G loss: 0.673597]\n",
      "epoch:12 step:11609 [D loss: 0.568235, acc.: 67.19%] [G loss: 0.515228]\n",
      "epoch:12 step:11610 [D loss: 0.504332, acc.: 71.88%] [G loss: 0.506704]\n",
      "epoch:12 step:11611 [D loss: 0.553664, acc.: 69.53%] [G loss: 0.584288]\n",
      "epoch:12 step:11612 [D loss: 0.552057, acc.: 72.66%] [G loss: 0.570440]\n",
      "epoch:12 step:11613 [D loss: 0.522281, acc.: 72.66%] [G loss: 0.507341]\n",
      "epoch:12 step:11614 [D loss: 0.523384, acc.: 73.44%] [G loss: 0.700437]\n",
      "epoch:12 step:11615 [D loss: 0.531399, acc.: 73.44%] [G loss: 0.708033]\n",
      "epoch:12 step:11616 [D loss: 0.532480, acc.: 72.66%] [G loss: 0.655987]\n",
      "epoch:12 step:11617 [D loss: 0.592822, acc.: 68.75%] [G loss: 0.710726]\n",
      "epoch:12 step:11618 [D loss: 0.483466, acc.: 75.78%] [G loss: 0.773673]\n",
      "epoch:12 step:11619 [D loss: 0.558871, acc.: 71.88%] [G loss: 0.707900]\n",
      "epoch:12 step:11620 [D loss: 0.702485, acc.: 58.59%] [G loss: 0.559418]\n",
      "epoch:12 step:11621 [D loss: 0.541000, acc.: 72.66%] [G loss: 0.570059]\n",
      "epoch:12 step:11622 [D loss: 0.563360, acc.: 60.94%] [G loss: 0.626445]\n",
      "epoch:12 step:11623 [D loss: 0.569288, acc.: 71.09%] [G loss: 0.504727]\n",
      "epoch:12 step:11624 [D loss: 0.629075, acc.: 61.72%] [G loss: 0.426216]\n",
      "epoch:12 step:11625 [D loss: 0.459975, acc.: 79.69%] [G loss: 0.450600]\n",
      "epoch:12 step:11626 [D loss: 0.583545, acc.: 66.41%] [G loss: 0.550926]\n",
      "epoch:12 step:11627 [D loss: 0.527800, acc.: 71.88%] [G loss: 0.527467]\n",
      "epoch:12 step:11628 [D loss: 0.574265, acc.: 64.06%] [G loss: 0.553579]\n",
      "epoch:12 step:11629 [D loss: 0.513422, acc.: 74.22%] [G loss: 0.695011]\n",
      "epoch:12 step:11630 [D loss: 0.582409, acc.: 67.97%] [G loss: 0.536082]\n",
      "epoch:12 step:11631 [D loss: 0.537486, acc.: 67.97%] [G loss: 0.620407]\n",
      "epoch:12 step:11632 [D loss: 0.534267, acc.: 71.88%] [G loss: 0.587571]\n",
      "epoch:12 step:11633 [D loss: 0.549703, acc.: 72.66%] [G loss: 0.610062]\n",
      "epoch:12 step:11634 [D loss: 0.603682, acc.: 69.53%] [G loss: 0.573386]\n",
      "epoch:12 step:11635 [D loss: 0.575556, acc.: 64.06%] [G loss: 0.548676]\n",
      "epoch:12 step:11636 [D loss: 0.473445, acc.: 75.78%] [G loss: 0.631279]\n",
      "epoch:12 step:11637 [D loss: 0.569724, acc.: 68.75%] [G loss: 0.603918]\n",
      "epoch:12 step:11638 [D loss: 0.566403, acc.: 71.09%] [G loss: 0.512557]\n",
      "epoch:12 step:11639 [D loss: 0.510131, acc.: 75.00%] [G loss: 0.712455]\n",
      "epoch:12 step:11640 [D loss: 0.564290, acc.: 68.75%] [G loss: 0.569751]\n",
      "epoch:12 step:11641 [D loss: 0.569696, acc.: 67.19%] [G loss: 0.487442]\n",
      "epoch:12 step:11642 [D loss: 0.459042, acc.: 77.34%] [G loss: 0.659700]\n",
      "epoch:12 step:11643 [D loss: 0.495877, acc.: 75.78%] [G loss: 0.751958]\n",
      "epoch:12 step:11644 [D loss: 0.669299, acc.: 53.12%] [G loss: 0.526990]\n",
      "epoch:12 step:11645 [D loss: 0.660770, acc.: 60.94%] [G loss: 0.561014]\n",
      "epoch:12 step:11646 [D loss: 0.496661, acc.: 74.22%] [G loss: 0.618504]\n",
      "epoch:12 step:11647 [D loss: 0.573364, acc.: 64.84%] [G loss: 0.654042]\n",
      "epoch:12 step:11648 [D loss: 0.609265, acc.: 68.75%] [G loss: 0.629979]\n",
      "epoch:12 step:11649 [D loss: 0.629850, acc.: 64.06%] [G loss: 0.599278]\n",
      "epoch:12 step:11650 [D loss: 0.500432, acc.: 73.44%] [G loss: 0.699673]\n",
      "epoch:12 step:11651 [D loss: 0.558475, acc.: 71.09%] [G loss: 0.553755]\n",
      "epoch:12 step:11652 [D loss: 0.567211, acc.: 68.75%] [G loss: 0.624237]\n",
      "epoch:12 step:11653 [D loss: 0.607804, acc.: 61.72%] [G loss: 0.585779]\n",
      "epoch:12 step:11654 [D loss: 0.578549, acc.: 70.31%] [G loss: 0.557415]\n",
      "epoch:12 step:11655 [D loss: 0.549493, acc.: 65.62%] [G loss: 0.528348]\n",
      "epoch:12 step:11656 [D loss: 0.638908, acc.: 62.50%] [G loss: 0.484616]\n",
      "epoch:12 step:11657 [D loss: 0.547256, acc.: 68.75%] [G loss: 0.493732]\n",
      "epoch:12 step:11658 [D loss: 0.545781, acc.: 70.31%] [G loss: 0.649979]\n",
      "epoch:12 step:11659 [D loss: 0.570091, acc.: 66.41%] [G loss: 0.604597]\n",
      "epoch:12 step:11660 [D loss: 0.476349, acc.: 78.91%] [G loss: 0.673114]\n",
      "epoch:12 step:11661 [D loss: 0.580482, acc.: 67.19%] [G loss: 0.621763]\n",
      "epoch:12 step:11662 [D loss: 0.614366, acc.: 68.75%] [G loss: 0.600782]\n",
      "epoch:12 step:11663 [D loss: 0.570264, acc.: 64.84%] [G loss: 0.492505]\n",
      "epoch:12 step:11664 [D loss: 0.635103, acc.: 63.28%] [G loss: 0.591490]\n",
      "epoch:12 step:11665 [D loss: 0.548267, acc.: 72.66%] [G loss: 0.497248]\n",
      "epoch:12 step:11666 [D loss: 0.559222, acc.: 68.75%] [G loss: 0.404468]\n",
      "epoch:12 step:11667 [D loss: 0.557829, acc.: 66.41%] [G loss: 0.586519]\n",
      "epoch:12 step:11668 [D loss: 0.640457, acc.: 62.50%] [G loss: 0.439651]\n",
      "epoch:12 step:11669 [D loss: 0.569896, acc.: 68.75%] [G loss: 0.641521]\n",
      "epoch:12 step:11670 [D loss: 0.499516, acc.: 77.34%] [G loss: 0.597021]\n",
      "epoch:12 step:11671 [D loss: 0.507303, acc.: 75.00%] [G loss: 0.778739]\n",
      "epoch:12 step:11672 [D loss: 0.526206, acc.: 69.53%] [G loss: 0.602065]\n",
      "epoch:12 step:11673 [D loss: 0.464557, acc.: 78.91%] [G loss: 0.763638]\n",
      "epoch:12 step:11674 [D loss: 0.517726, acc.: 70.31%] [G loss: 0.743365]\n",
      "epoch:12 step:11675 [D loss: 0.520653, acc.: 73.44%] [G loss: 0.718047]\n",
      "epoch:12 step:11676 [D loss: 0.563162, acc.: 70.31%] [G loss: 0.518924]\n",
      "epoch:12 step:11677 [D loss: 0.567435, acc.: 71.88%] [G loss: 0.551749]\n",
      "epoch:12 step:11678 [D loss: 0.460062, acc.: 77.34%] [G loss: 0.715022]\n",
      "epoch:12 step:11679 [D loss: 0.539044, acc.: 75.78%] [G loss: 0.631777]\n",
      "epoch:12 step:11680 [D loss: 0.478959, acc.: 78.91%] [G loss: 0.741352]\n",
      "epoch:12 step:11681 [D loss: 0.652762, acc.: 67.97%] [G loss: 0.574596]\n",
      "epoch:12 step:11682 [D loss: 0.565467, acc.: 70.31%] [G loss: 0.504926]\n",
      "epoch:12 step:11683 [D loss: 0.471998, acc.: 76.56%] [G loss: 0.595943]\n",
      "epoch:12 step:11684 [D loss: 0.506057, acc.: 75.78%] [G loss: 0.652546]\n",
      "epoch:12 step:11685 [D loss: 0.520236, acc.: 68.75%] [G loss: 0.621382]\n",
      "epoch:12 step:11686 [D loss: 0.537611, acc.: 71.09%] [G loss: 0.733158]\n",
      "epoch:12 step:11687 [D loss: 0.527940, acc.: 73.44%] [G loss: 0.594450]\n",
      "epoch:12 step:11688 [D loss: 0.525101, acc.: 72.66%] [G loss: 0.695203]\n",
      "epoch:12 step:11689 [D loss: 0.612038, acc.: 67.19%] [G loss: 0.646864]\n",
      "epoch:12 step:11690 [D loss: 0.575884, acc.: 67.19%] [G loss: 0.571417]\n",
      "epoch:12 step:11691 [D loss: 0.563510, acc.: 71.88%] [G loss: 0.744101]\n",
      "epoch:12 step:11692 [D loss: 0.521503, acc.: 69.53%] [G loss: 0.639284]\n",
      "epoch:12 step:11693 [D loss: 0.512782, acc.: 75.78%] [G loss: 0.725989]\n",
      "epoch:12 step:11694 [D loss: 0.524407, acc.: 70.31%] [G loss: 0.566228]\n",
      "epoch:12 step:11695 [D loss: 0.437172, acc.: 79.69%] [G loss: 0.665551]\n",
      "epoch:12 step:11696 [D loss: 0.503566, acc.: 75.78%] [G loss: 0.808950]\n",
      "epoch:12 step:11697 [D loss: 0.592180, acc.: 68.75%] [G loss: 0.718933]\n",
      "epoch:12 step:11698 [D loss: 0.559360, acc.: 71.09%] [G loss: 0.580724]\n",
      "epoch:12 step:11699 [D loss: 0.536366, acc.: 71.09%] [G loss: 0.539268]\n",
      "epoch:12 step:11700 [D loss: 0.597358, acc.: 67.97%] [G loss: 0.529440]\n",
      "epoch:12 step:11701 [D loss: 0.533920, acc.: 73.44%] [G loss: 0.593674]\n",
      "epoch:12 step:11702 [D loss: 0.669999, acc.: 58.59%] [G loss: 0.495139]\n",
      "epoch:12 step:11703 [D loss: 0.551930, acc.: 67.97%] [G loss: 0.507388]\n",
      "epoch:12 step:11704 [D loss: 0.505829, acc.: 76.56%] [G loss: 0.503821]\n",
      "epoch:12 step:11705 [D loss: 0.544980, acc.: 72.66%] [G loss: 0.511799]\n",
      "epoch:12 step:11706 [D loss: 0.613101, acc.: 60.16%] [G loss: 0.471344]\n",
      "epoch:12 step:11707 [D loss: 0.544538, acc.: 67.19%] [G loss: 0.560321]\n",
      "epoch:12 step:11708 [D loss: 0.518852, acc.: 76.56%] [G loss: 0.597288]\n",
      "epoch:12 step:11709 [D loss: 0.597066, acc.: 64.84%] [G loss: 0.570827]\n",
      "epoch:12 step:11710 [D loss: 0.549715, acc.: 61.72%] [G loss: 0.578594]\n",
      "epoch:12 step:11711 [D loss: 0.565847, acc.: 65.62%] [G loss: 0.552324]\n",
      "epoch:12 step:11712 [D loss: 0.521633, acc.: 75.00%] [G loss: 0.760256]\n",
      "epoch:12 step:11713 [D loss: 0.519441, acc.: 71.09%] [G loss: 0.835444]\n",
      "epoch:12 step:11714 [D loss: 0.533290, acc.: 74.22%] [G loss: 0.680473]\n",
      "epoch:12 step:11715 [D loss: 0.460543, acc.: 78.91%] [G loss: 0.865873]\n",
      "epoch:12 step:11716 [D loss: 0.482196, acc.: 77.34%] [G loss: 0.854880]\n",
      "epoch:12 step:11717 [D loss: 0.677351, acc.: 55.47%] [G loss: 0.607760]\n",
      "epoch:12 step:11718 [D loss: 0.576860, acc.: 67.97%] [G loss: 0.613847]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11719 [D loss: 0.452415, acc.: 80.47%] [G loss: 0.905137]\n",
      "epoch:12 step:11720 [D loss: 0.567227, acc.: 71.09%] [G loss: 1.029927]\n",
      "epoch:12 step:11721 [D loss: 0.661997, acc.: 66.41%] [G loss: 0.568184]\n",
      "epoch:12 step:11722 [D loss: 0.585565, acc.: 71.09%] [G loss: 0.417669]\n",
      "epoch:12 step:11723 [D loss: 0.519948, acc.: 72.66%] [G loss: 0.549205]\n",
      "epoch:12 step:11724 [D loss: 0.601708, acc.: 69.53%] [G loss: 0.529029]\n",
      "epoch:12 step:11725 [D loss: 0.512928, acc.: 80.47%] [G loss: 0.673517]\n",
      "epoch:12 step:11726 [D loss: 0.647498, acc.: 64.84%] [G loss: 0.467171]\n",
      "epoch:12 step:11727 [D loss: 0.565377, acc.: 74.22%] [G loss: 0.536092]\n",
      "epoch:12 step:11728 [D loss: 0.526268, acc.: 72.66%] [G loss: 0.577210]\n",
      "epoch:12 step:11729 [D loss: 0.511327, acc.: 73.44%] [G loss: 0.625750]\n",
      "epoch:12 step:11730 [D loss: 0.519945, acc.: 73.44%] [G loss: 0.587315]\n",
      "epoch:12 step:11731 [D loss: 0.600960, acc.: 60.16%] [G loss: 0.530460]\n",
      "epoch:12 step:11732 [D loss: 0.523066, acc.: 72.66%] [G loss: 0.604002]\n",
      "epoch:12 step:11733 [D loss: 0.508202, acc.: 72.66%] [G loss: 0.797751]\n",
      "epoch:12 step:11734 [D loss: 0.597228, acc.: 68.75%] [G loss: 0.572429]\n",
      "epoch:12 step:11735 [D loss: 0.519506, acc.: 73.44%] [G loss: 0.664821]\n",
      "epoch:12 step:11736 [D loss: 0.640199, acc.: 62.50%] [G loss: 0.648550]\n",
      "epoch:12 step:11737 [D loss: 0.552984, acc.: 71.88%] [G loss: 0.375101]\n",
      "epoch:12 step:11738 [D loss: 0.610805, acc.: 65.62%] [G loss: 0.626361]\n",
      "epoch:12 step:11739 [D loss: 0.562675, acc.: 64.84%] [G loss: 0.534673]\n",
      "epoch:12 step:11740 [D loss: 0.578906, acc.: 71.09%] [G loss: 0.472893]\n",
      "epoch:12 step:11741 [D loss: 0.572056, acc.: 67.19%] [G loss: 0.633783]\n",
      "epoch:12 step:11742 [D loss: 0.510442, acc.: 75.00%] [G loss: 0.662118]\n",
      "epoch:12 step:11743 [D loss: 0.518767, acc.: 76.56%] [G loss: 0.846743]\n",
      "epoch:12 step:11744 [D loss: 0.582630, acc.: 69.53%] [G loss: 0.651947]\n",
      "epoch:12 step:11745 [D loss: 0.667985, acc.: 63.28%] [G loss: 0.697156]\n",
      "epoch:12 step:11746 [D loss: 0.592990, acc.: 63.28%] [G loss: 0.463526]\n",
      "epoch:12 step:11747 [D loss: 0.504594, acc.: 71.88%] [G loss: 0.623037]\n",
      "epoch:12 step:11748 [D loss: 0.476277, acc.: 75.78%] [G loss: 0.674393]\n",
      "epoch:12 step:11749 [D loss: 0.507807, acc.: 74.22%] [G loss: 0.646635]\n",
      "epoch:12 step:11750 [D loss: 0.486958, acc.: 75.00%] [G loss: 0.767105]\n",
      "epoch:12 step:11751 [D loss: 0.525799, acc.: 73.44%] [G loss: 0.829749]\n",
      "epoch:12 step:11752 [D loss: 0.440917, acc.: 78.91%] [G loss: 0.823718]\n",
      "epoch:12 step:11753 [D loss: 0.473833, acc.: 77.34%] [G loss: 0.946912]\n",
      "epoch:12 step:11754 [D loss: 0.556282, acc.: 70.31%] [G loss: 0.770513]\n",
      "epoch:12 step:11755 [D loss: 0.682213, acc.: 57.81%] [G loss: 0.518896]\n",
      "epoch:12 step:11756 [D loss: 0.577415, acc.: 67.97%] [G loss: 0.551647]\n",
      "epoch:12 step:11757 [D loss: 0.543825, acc.: 67.97%] [G loss: 0.659480]\n",
      "epoch:12 step:11758 [D loss: 0.548121, acc.: 68.75%] [G loss: 0.560612]\n",
      "epoch:12 step:11759 [D loss: 0.500507, acc.: 78.91%] [G loss: 0.656166]\n",
      "epoch:12 step:11760 [D loss: 0.535086, acc.: 68.75%] [G loss: 0.708192]\n",
      "epoch:12 step:11761 [D loss: 0.511980, acc.: 71.88%] [G loss: 0.804623]\n",
      "epoch:12 step:11762 [D loss: 0.584626, acc.: 66.41%] [G loss: 0.532085]\n",
      "epoch:12 step:11763 [D loss: 0.490657, acc.: 74.22%] [G loss: 0.604351]\n",
      "epoch:12 step:11764 [D loss: 0.526327, acc.: 73.44%] [G loss: 0.483918]\n",
      "epoch:12 step:11765 [D loss: 0.495674, acc.: 74.22%] [G loss: 0.659682]\n",
      "epoch:12 step:11766 [D loss: 0.545170, acc.: 70.31%] [G loss: 0.553422]\n",
      "epoch:12 step:11767 [D loss: 0.552992, acc.: 69.53%] [G loss: 0.653998]\n",
      "epoch:12 step:11768 [D loss: 0.544521, acc.: 70.31%] [G loss: 0.654808]\n",
      "epoch:12 step:11769 [D loss: 0.644372, acc.: 61.72%] [G loss: 0.529486]\n",
      "epoch:12 step:11770 [D loss: 0.534421, acc.: 69.53%] [G loss: 0.454847]\n",
      "epoch:12 step:11771 [D loss: 0.552810, acc.: 64.84%] [G loss: 0.675315]\n",
      "epoch:12 step:11772 [D loss: 0.647647, acc.: 57.81%] [G loss: 0.511344]\n",
      "epoch:12 step:11773 [D loss: 0.638668, acc.: 57.03%] [G loss: 0.620523]\n",
      "epoch:12 step:11774 [D loss: 0.566487, acc.: 67.97%] [G loss: 0.571172]\n",
      "epoch:12 step:11775 [D loss: 0.558869, acc.: 67.19%] [G loss: 0.601813]\n",
      "epoch:12 step:11776 [D loss: 0.580215, acc.: 68.75%] [G loss: 0.565245]\n",
      "epoch:12 step:11777 [D loss: 0.585705, acc.: 67.97%] [G loss: 0.586858]\n",
      "epoch:12 step:11778 [D loss: 0.486426, acc.: 72.66%] [G loss: 0.717334]\n",
      "epoch:12 step:11779 [D loss: 0.626233, acc.: 60.94%] [G loss: 0.462234]\n",
      "epoch:12 step:11780 [D loss: 0.449328, acc.: 76.56%] [G loss: 0.689597]\n",
      "epoch:12 step:11781 [D loss: 0.565462, acc.: 69.53%] [G loss: 0.558934]\n",
      "epoch:12 step:11782 [D loss: 0.552766, acc.: 72.66%] [G loss: 0.553386]\n",
      "epoch:12 step:11783 [D loss: 0.541596, acc.: 75.00%] [G loss: 0.659752]\n",
      "epoch:12 step:11784 [D loss: 0.573193, acc.: 64.84%] [G loss: 0.461166]\n",
      "epoch:12 step:11785 [D loss: 0.542402, acc.: 71.09%] [G loss: 0.499053]\n",
      "epoch:12 step:11786 [D loss: 0.617036, acc.: 69.53%] [G loss: 0.485586]\n",
      "epoch:12 step:11787 [D loss: 0.618343, acc.: 64.84%] [G loss: 0.570891]\n",
      "epoch:12 step:11788 [D loss: 0.498120, acc.: 77.34%] [G loss: 0.658946]\n",
      "epoch:12 step:11789 [D loss: 0.566097, acc.: 69.53%] [G loss: 0.718580]\n",
      "epoch:12 step:11790 [D loss: 0.503785, acc.: 73.44%] [G loss: 0.659068]\n",
      "epoch:12 step:11791 [D loss: 0.551452, acc.: 71.09%] [G loss: 0.629417]\n",
      "epoch:12 step:11792 [D loss: 0.513119, acc.: 74.22%] [G loss: 0.667193]\n",
      "epoch:12 step:11793 [D loss: 0.536424, acc.: 73.44%] [G loss: 0.638451]\n",
      "epoch:12 step:11794 [D loss: 0.532825, acc.: 71.09%] [G loss: 0.549706]\n",
      "epoch:12 step:11795 [D loss: 0.527513, acc.: 74.22%] [G loss: 0.564834]\n",
      "epoch:12 step:11796 [D loss: 0.532612, acc.: 71.09%] [G loss: 0.659852]\n",
      "epoch:12 step:11797 [D loss: 0.600930, acc.: 64.06%] [G loss: 0.584189]\n",
      "epoch:12 step:11798 [D loss: 0.491885, acc.: 78.91%] [G loss: 0.638167]\n",
      "epoch:12 step:11799 [D loss: 0.485716, acc.: 76.56%] [G loss: 0.616905]\n",
      "epoch:12 step:11800 [D loss: 0.558435, acc.: 73.44%] [G loss: 0.522691]\n",
      "##############\n",
      "[2.79092165 1.40214746 6.01090344 4.91261956 3.84334148 5.85296766\n",
      " 4.5992611  4.93780447 4.61245783 4.26658492]\n",
      "##########\n",
      "epoch:12 step:11801 [D loss: 0.491032, acc.: 75.00%] [G loss: 0.652843]\n",
      "epoch:12 step:11802 [D loss: 0.489892, acc.: 75.00%] [G loss: 0.780683]\n",
      "epoch:12 step:11803 [D loss: 0.605870, acc.: 64.84%] [G loss: 0.551463]\n",
      "epoch:12 step:11804 [D loss: 0.548904, acc.: 71.09%] [G loss: 0.463883]\n",
      "epoch:12 step:11805 [D loss: 0.520936, acc.: 72.66%] [G loss: 0.567897]\n",
      "epoch:12 step:11806 [D loss: 0.605040, acc.: 63.28%] [G loss: 0.509083]\n",
      "epoch:12 step:11807 [D loss: 0.543765, acc.: 63.28%] [G loss: 0.557686]\n",
      "epoch:12 step:11808 [D loss: 0.550888, acc.: 72.66%] [G loss: 0.559878]\n",
      "epoch:12 step:11809 [D loss: 0.572250, acc.: 70.31%] [G loss: 0.686386]\n",
      "epoch:12 step:11810 [D loss: 0.668985, acc.: 60.16%] [G loss: 0.629249]\n",
      "epoch:12 step:11811 [D loss: 0.536329, acc.: 68.75%] [G loss: 0.536350]\n",
      "epoch:12 step:11812 [D loss: 0.474863, acc.: 77.34%] [G loss: 0.717090]\n",
      "epoch:12 step:11813 [D loss: 0.571914, acc.: 67.97%] [G loss: 0.592243]\n",
      "epoch:12 step:11814 [D loss: 0.511091, acc.: 71.09%] [G loss: 0.635238]\n",
      "epoch:12 step:11815 [D loss: 0.509539, acc.: 69.53%] [G loss: 0.586750]\n",
      "epoch:12 step:11816 [D loss: 0.554678, acc.: 73.44%] [G loss: 0.580889]\n",
      "epoch:12 step:11817 [D loss: 0.546836, acc.: 71.09%] [G loss: 0.580320]\n",
      "epoch:12 step:11818 [D loss: 0.477473, acc.: 78.12%] [G loss: 0.622683]\n",
      "epoch:12 step:11819 [D loss: 0.481047, acc.: 75.78%] [G loss: 0.765265]\n",
      "epoch:12 step:11820 [D loss: 0.630418, acc.: 64.84%] [G loss: 0.543021]\n",
      "epoch:12 step:11821 [D loss: 0.548922, acc.: 73.44%] [G loss: 0.562207]\n",
      "epoch:12 step:11822 [D loss: 0.531016, acc.: 71.09%] [G loss: 0.613015]\n",
      "epoch:12 step:11823 [D loss: 0.556071, acc.: 69.53%] [G loss: 0.711410]\n",
      "epoch:12 step:11824 [D loss: 0.559476, acc.: 69.53%] [G loss: 0.585570]\n",
      "epoch:12 step:11825 [D loss: 0.552910, acc.: 68.75%] [G loss: 0.632670]\n",
      "epoch:12 step:11826 [D loss: 0.479018, acc.: 75.00%] [G loss: 0.766239]\n",
      "epoch:12 step:11827 [D loss: 0.574092, acc.: 67.97%] [G loss: 0.696541]\n",
      "epoch:12 step:11828 [D loss: 0.646088, acc.: 60.16%] [G loss: 0.552510]\n",
      "epoch:12 step:11829 [D loss: 0.531158, acc.: 71.88%] [G loss: 0.616852]\n",
      "epoch:12 step:11830 [D loss: 0.602736, acc.: 67.19%] [G loss: 0.806147]\n",
      "epoch:12 step:11831 [D loss: 0.587534, acc.: 60.16%] [G loss: 0.706284]\n",
      "epoch:12 step:11832 [D loss: 0.552331, acc.: 65.62%] [G loss: 0.708554]\n",
      "epoch:12 step:11833 [D loss: 0.460818, acc.: 79.69%] [G loss: 0.764555]\n",
      "epoch:12 step:11834 [D loss: 0.600958, acc.: 67.97%] [G loss: 0.689325]\n",
      "epoch:12 step:11835 [D loss: 0.583262, acc.: 72.66%] [G loss: 0.546579]\n",
      "epoch:12 step:11836 [D loss: 0.509800, acc.: 72.66%] [G loss: 0.694924]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11837 [D loss: 0.574084, acc.: 67.97%] [G loss: 0.595029]\n",
      "epoch:12 step:11838 [D loss: 0.506261, acc.: 74.22%] [G loss: 0.640387]\n",
      "epoch:12 step:11839 [D loss: 0.570184, acc.: 72.66%] [G loss: 0.538494]\n",
      "epoch:12 step:11840 [D loss: 0.541937, acc.: 72.66%] [G loss: 0.709184]\n",
      "epoch:12 step:11841 [D loss: 0.558238, acc.: 68.75%] [G loss: 0.622105]\n",
      "epoch:12 step:11842 [D loss: 0.520776, acc.: 71.09%] [G loss: 0.752592]\n",
      "epoch:12 step:11843 [D loss: 0.569827, acc.: 68.75%] [G loss: 0.638170]\n",
      "epoch:12 step:11844 [D loss: 0.580555, acc.: 69.53%] [G loss: 0.608613]\n",
      "epoch:12 step:11845 [D loss: 0.513024, acc.: 74.22%] [G loss: 0.656530]\n",
      "epoch:12 step:11846 [D loss: 0.542054, acc.: 68.75%] [G loss: 0.655822]\n",
      "epoch:12 step:11847 [D loss: 0.459639, acc.: 80.47%] [G loss: 0.774412]\n",
      "epoch:12 step:11848 [D loss: 0.598979, acc.: 67.19%] [G loss: 0.717756]\n",
      "epoch:12 step:11849 [D loss: 0.481757, acc.: 75.00%] [G loss: 0.630090]\n",
      "epoch:12 step:11850 [D loss: 0.675215, acc.: 60.94%] [G loss: 0.571132]\n",
      "epoch:12 step:11851 [D loss: 0.553011, acc.: 71.09%] [G loss: 0.417126]\n",
      "epoch:12 step:11852 [D loss: 0.528716, acc.: 71.09%] [G loss: 0.485094]\n",
      "epoch:12 step:11853 [D loss: 0.533072, acc.: 69.53%] [G loss: 0.610707]\n",
      "epoch:12 step:11854 [D loss: 0.567962, acc.: 71.09%] [G loss: 0.551039]\n",
      "epoch:12 step:11855 [D loss: 0.524554, acc.: 71.09%] [G loss: 0.471334]\n",
      "epoch:12 step:11856 [D loss: 0.589364, acc.: 65.62%] [G loss: 0.536527]\n",
      "epoch:12 step:11857 [D loss: 0.494898, acc.: 75.00%] [G loss: 0.588766]\n",
      "epoch:12 step:11858 [D loss: 0.584696, acc.: 64.84%] [G loss: 0.709180]\n",
      "epoch:12 step:11859 [D loss: 0.605206, acc.: 63.28%] [G loss: 0.535857]\n",
      "epoch:12 step:11860 [D loss: 0.600455, acc.: 67.19%] [G loss: 0.614361]\n",
      "epoch:12 step:11861 [D loss: 0.608838, acc.: 67.19%] [G loss: 0.558358]\n",
      "epoch:12 step:11862 [D loss: 0.526426, acc.: 71.88%] [G loss: 0.618470]\n",
      "epoch:12 step:11863 [D loss: 0.529874, acc.: 72.66%] [G loss: 0.685090]\n",
      "epoch:12 step:11864 [D loss: 0.507769, acc.: 75.00%] [G loss: 0.636602]\n",
      "epoch:12 step:11865 [D loss: 0.517213, acc.: 74.22%] [G loss: 0.569172]\n",
      "epoch:12 step:11866 [D loss: 0.621687, acc.: 64.06%] [G loss: 0.501907]\n",
      "epoch:12 step:11867 [D loss: 0.553241, acc.: 70.31%] [G loss: 0.600587]\n",
      "epoch:12 step:11868 [D loss: 0.467014, acc.: 78.12%] [G loss: 0.631181]\n",
      "epoch:12 step:11869 [D loss: 0.594472, acc.: 65.62%] [G loss: 0.527969]\n",
      "epoch:12 step:11870 [D loss: 0.542852, acc.: 75.00%] [G loss: 0.563953]\n",
      "epoch:12 step:11871 [D loss: 0.534578, acc.: 69.53%] [G loss: 0.565987]\n",
      "epoch:12 step:11872 [D loss: 0.608696, acc.: 65.62%] [G loss: 0.500155]\n",
      "epoch:12 step:11873 [D loss: 0.495483, acc.: 77.34%] [G loss: 0.609602]\n",
      "epoch:12 step:11874 [D loss: 0.541984, acc.: 71.09%] [G loss: 0.653266]\n",
      "epoch:12 step:11875 [D loss: 0.484155, acc.: 78.91%] [G loss: 0.578822]\n",
      "epoch:12 step:11876 [D loss: 0.505849, acc.: 76.56%] [G loss: 0.502650]\n",
      "epoch:12 step:11877 [D loss: 0.558449, acc.: 65.62%] [G loss: 0.605836]\n",
      "epoch:12 step:11878 [D loss: 0.471530, acc.: 79.69%] [G loss: 0.590750]\n",
      "epoch:12 step:11879 [D loss: 0.536722, acc.: 67.97%] [G loss: 0.674395]\n",
      "epoch:12 step:11880 [D loss: 0.583454, acc.: 71.09%] [G loss: 0.555213]\n",
      "epoch:12 step:11881 [D loss: 0.530179, acc.: 73.44%] [G loss: 0.506330]\n",
      "epoch:12 step:11882 [D loss: 0.565505, acc.: 68.75%] [G loss: 0.456630]\n",
      "epoch:12 step:11883 [D loss: 0.482379, acc.: 74.22%] [G loss: 0.675522]\n",
      "epoch:12 step:11884 [D loss: 0.575499, acc.: 65.62%] [G loss: 0.652715]\n",
      "epoch:12 step:11885 [D loss: 0.466942, acc.: 75.00%] [G loss: 0.800296]\n",
      "epoch:12 step:11886 [D loss: 0.531737, acc.: 72.66%] [G loss: 0.908809]\n",
      "epoch:12 step:11887 [D loss: 0.566744, acc.: 70.31%] [G loss: 0.668085]\n",
      "epoch:12 step:11888 [D loss: 0.570023, acc.: 71.88%] [G loss: 0.589942]\n",
      "epoch:12 step:11889 [D loss: 0.510877, acc.: 74.22%] [G loss: 0.763725]\n",
      "epoch:12 step:11890 [D loss: 0.552214, acc.: 70.31%] [G loss: 0.638774]\n",
      "epoch:12 step:11891 [D loss: 0.490842, acc.: 72.66%] [G loss: 0.797937]\n",
      "epoch:12 step:11892 [D loss: 0.472104, acc.: 75.78%] [G loss: 0.837292]\n",
      "epoch:12 step:11893 [D loss: 0.481980, acc.: 78.12%] [G loss: 0.836346]\n",
      "epoch:12 step:11894 [D loss: 0.525126, acc.: 74.22%] [G loss: 0.787281]\n",
      "epoch:12 step:11895 [D loss: 0.503751, acc.: 77.34%] [G loss: 0.750522]\n",
      "epoch:12 step:11896 [D loss: 0.633026, acc.: 59.38%] [G loss: 0.459109]\n",
      "epoch:12 step:11897 [D loss: 0.586322, acc.: 71.88%] [G loss: 0.398932]\n",
      "epoch:12 step:11898 [D loss: 0.473973, acc.: 77.34%] [G loss: 0.639988]\n",
      "epoch:12 step:11899 [D loss: 0.545742, acc.: 72.66%] [G loss: 0.631460]\n",
      "epoch:12 step:11900 [D loss: 0.579888, acc.: 66.41%] [G loss: 0.582456]\n",
      "epoch:12 step:11901 [D loss: 0.517333, acc.: 70.31%] [G loss: 0.546750]\n",
      "epoch:12 step:11902 [D loss: 0.608325, acc.: 61.72%] [G loss: 0.572503]\n",
      "epoch:12 step:11903 [D loss: 0.522467, acc.: 72.66%] [G loss: 0.679175]\n",
      "epoch:12 step:11904 [D loss: 0.529620, acc.: 72.66%] [G loss: 0.666941]\n",
      "epoch:12 step:11905 [D loss: 0.490331, acc.: 77.34%] [G loss: 0.763315]\n",
      "epoch:12 step:11906 [D loss: 0.599272, acc.: 65.62%] [G loss: 0.552247]\n",
      "epoch:12 step:11907 [D loss: 0.592530, acc.: 67.97%] [G loss: 0.599205]\n",
      "epoch:12 step:11908 [D loss: 0.497685, acc.: 75.78%] [G loss: 0.788466]\n",
      "epoch:12 step:11909 [D loss: 0.621783, acc.: 66.41%] [G loss: 0.721127]\n",
      "epoch:12 step:11910 [D loss: 0.479487, acc.: 77.34%] [G loss: 0.782306]\n",
      "epoch:12 step:11911 [D loss: 0.595449, acc.: 64.06%] [G loss: 0.840486]\n",
      "epoch:12 step:11912 [D loss: 0.520492, acc.: 75.00%] [G loss: 0.553234]\n",
      "epoch:12 step:11913 [D loss: 0.511643, acc.: 71.09%] [G loss: 0.755674]\n",
      "epoch:12 step:11914 [D loss: 0.560253, acc.: 69.53%] [G loss: 0.451691]\n",
      "epoch:12 step:11915 [D loss: 0.567652, acc.: 71.88%] [G loss: 0.625421]\n",
      "epoch:12 step:11916 [D loss: 0.554312, acc.: 75.00%] [G loss: 0.457807]\n",
      "epoch:12 step:11917 [D loss: 0.661196, acc.: 64.84%] [G loss: 0.648902]\n",
      "epoch:12 step:11918 [D loss: 0.608020, acc.: 66.41%] [G loss: 0.563689]\n",
      "epoch:12 step:11919 [D loss: 0.591696, acc.: 65.62%] [G loss: 0.750434]\n",
      "epoch:12 step:11920 [D loss: 0.544935, acc.: 65.62%] [G loss: 0.689248]\n",
      "epoch:12 step:11921 [D loss: 0.488065, acc.: 78.91%] [G loss: 0.648688]\n",
      "epoch:12 step:11922 [D loss: 0.583175, acc.: 71.09%] [G loss: 0.672128]\n",
      "epoch:12 step:11923 [D loss: 0.486231, acc.: 80.47%] [G loss: 0.649556]\n",
      "epoch:12 step:11924 [D loss: 0.507060, acc.: 74.22%] [G loss: 0.667292]\n",
      "epoch:12 step:11925 [D loss: 0.463923, acc.: 82.03%] [G loss: 0.573438]\n",
      "epoch:12 step:11926 [D loss: 0.543371, acc.: 73.44%] [G loss: 0.761907]\n",
      "epoch:12 step:11927 [D loss: 0.587963, acc.: 68.75%] [G loss: 0.536918]\n",
      "epoch:12 step:11928 [D loss: 0.591304, acc.: 71.88%] [G loss: 0.483946]\n",
      "epoch:12 step:11929 [D loss: 0.538694, acc.: 75.00%] [G loss: 0.490844]\n",
      "epoch:12 step:11930 [D loss: 0.587891, acc.: 67.97%] [G loss: 0.434703]\n",
      "epoch:12 step:11931 [D loss: 0.542389, acc.: 69.53%] [G loss: 0.465219]\n",
      "epoch:12 step:11932 [D loss: 0.560034, acc.: 67.19%] [G loss: 0.576776]\n",
      "epoch:12 step:11933 [D loss: 0.586273, acc.: 67.19%] [G loss: 0.558043]\n",
      "epoch:12 step:11934 [D loss: 0.531521, acc.: 75.00%] [G loss: 0.637218]\n",
      "epoch:12 step:11935 [D loss: 0.501690, acc.: 79.69%] [G loss: 0.675151]\n",
      "epoch:12 step:11936 [D loss: 0.518727, acc.: 78.91%] [G loss: 0.607440]\n",
      "epoch:12 step:11937 [D loss: 0.496193, acc.: 79.69%] [G loss: 0.644302]\n",
      "epoch:12 step:11938 [D loss: 0.519894, acc.: 69.53%] [G loss: 0.553682]\n",
      "epoch:12 step:11939 [D loss: 0.556489, acc.: 69.53%] [G loss: 0.689882]\n",
      "epoch:12 step:11940 [D loss: 0.589599, acc.: 64.84%] [G loss: 0.504009]\n",
      "epoch:12 step:11941 [D loss: 0.538498, acc.: 67.19%] [G loss: 0.589625]\n",
      "epoch:12 step:11942 [D loss: 0.565657, acc.: 68.75%] [G loss: 0.469698]\n",
      "epoch:12 step:11943 [D loss: 0.504457, acc.: 78.91%] [G loss: 0.553790]\n",
      "epoch:12 step:11944 [D loss: 0.569791, acc.: 71.09%] [G loss: 0.621328]\n",
      "epoch:12 step:11945 [D loss: 0.534283, acc.: 74.22%] [G loss: 0.800030]\n",
      "epoch:12 step:11946 [D loss: 0.585470, acc.: 62.50%] [G loss: 0.734219]\n",
      "epoch:12 step:11947 [D loss: 0.567328, acc.: 68.75%] [G loss: 0.585121]\n",
      "epoch:12 step:11948 [D loss: 0.623993, acc.: 65.62%] [G loss: 0.566817]\n",
      "epoch:12 step:11949 [D loss: 0.521753, acc.: 70.31%] [G loss: 0.587952]\n",
      "epoch:12 step:11950 [D loss: 0.568267, acc.: 63.28%] [G loss: 0.601143]\n",
      "epoch:12 step:11951 [D loss: 0.485087, acc.: 75.00%] [G loss: 0.607913]\n",
      "epoch:12 step:11952 [D loss: 0.471176, acc.: 79.69%] [G loss: 0.552822]\n",
      "epoch:12 step:11953 [D loss: 0.495721, acc.: 73.44%] [G loss: 0.771048]\n",
      "epoch:12 step:11954 [D loss: 0.622898, acc.: 62.50%] [G loss: 0.541728]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11955 [D loss: 0.616599, acc.: 64.06%] [G loss: 0.662559]\n",
      "epoch:12 step:11956 [D loss: 0.567542, acc.: 67.19%] [G loss: 0.586414]\n",
      "epoch:12 step:11957 [D loss: 0.572150, acc.: 67.19%] [G loss: 0.644337]\n",
      "epoch:12 step:11958 [D loss: 0.539989, acc.: 75.78%] [G loss: 0.639944]\n",
      "epoch:12 step:11959 [D loss: 0.565972, acc.: 70.31%] [G loss: 0.556303]\n",
      "epoch:12 step:11960 [D loss: 0.632327, acc.: 60.94%] [G loss: 0.522820]\n",
      "epoch:12 step:11961 [D loss: 0.594397, acc.: 67.97%] [G loss: 0.452181]\n",
      "epoch:12 step:11962 [D loss: 0.580197, acc.: 66.41%] [G loss: 0.524141]\n",
      "epoch:12 step:11963 [D loss: 0.522464, acc.: 71.88%] [G loss: 0.564302]\n",
      "epoch:12 step:11964 [D loss: 0.578230, acc.: 71.09%] [G loss: 0.616329]\n",
      "epoch:12 step:11965 [D loss: 0.555464, acc.: 69.53%] [G loss: 0.600912]\n",
      "epoch:12 step:11966 [D loss: 0.550117, acc.: 73.44%] [G loss: 0.667215]\n",
      "epoch:12 step:11967 [D loss: 0.577422, acc.: 70.31%] [G loss: 0.520402]\n",
      "epoch:12 step:11968 [D loss: 0.527020, acc.: 72.66%] [G loss: 0.547710]\n",
      "epoch:12 step:11969 [D loss: 0.498821, acc.: 77.34%] [G loss: 0.530785]\n",
      "epoch:12 step:11970 [D loss: 0.508763, acc.: 75.00%] [G loss: 0.648175]\n",
      "epoch:12 step:11971 [D loss: 0.613551, acc.: 66.41%] [G loss: 0.506531]\n",
      "epoch:12 step:11972 [D loss: 0.532352, acc.: 71.88%] [G loss: 0.517671]\n",
      "epoch:12 step:11973 [D loss: 0.595756, acc.: 66.41%] [G loss: 0.483551]\n",
      "epoch:12 step:11974 [D loss: 0.497776, acc.: 79.69%] [G loss: 0.513831]\n",
      "epoch:12 step:11975 [D loss: 0.604284, acc.: 63.28%] [G loss: 0.521621]\n",
      "epoch:12 step:11976 [D loss: 0.558791, acc.: 67.97%] [G loss: 0.633601]\n",
      "epoch:12 step:11977 [D loss: 0.538434, acc.: 72.66%] [G loss: 0.678540]\n",
      "epoch:12 step:11978 [D loss: 0.540532, acc.: 67.97%] [G loss: 0.625915]\n",
      "epoch:12 step:11979 [D loss: 0.545895, acc.: 71.09%] [G loss: 0.567573]\n",
      "epoch:12 step:11980 [D loss: 0.511652, acc.: 71.88%] [G loss: 0.611245]\n",
      "epoch:12 step:11981 [D loss: 0.534150, acc.: 70.31%] [G loss: 0.616047]\n",
      "epoch:12 step:11982 [D loss: 0.588409, acc.: 64.84%] [G loss: 0.547793]\n",
      "epoch:12 step:11983 [D loss: 0.558070, acc.: 71.09%] [G loss: 0.637064]\n",
      "epoch:12 step:11984 [D loss: 0.635833, acc.: 64.06%] [G loss: 0.361432]\n",
      "epoch:12 step:11985 [D loss: 0.597989, acc.: 69.53%] [G loss: 0.621452]\n",
      "epoch:12 step:11986 [D loss: 0.547993, acc.: 69.53%] [G loss: 0.602105]\n",
      "epoch:12 step:11987 [D loss: 0.532157, acc.: 67.97%] [G loss: 0.635697]\n",
      "epoch:12 step:11988 [D loss: 0.554969, acc.: 70.31%] [G loss: 0.690063]\n",
      "epoch:12 step:11989 [D loss: 0.541070, acc.: 71.88%] [G loss: 0.600150]\n",
      "epoch:12 step:11990 [D loss: 0.413354, acc.: 79.69%] [G loss: 0.745145]\n",
      "epoch:12 step:11991 [D loss: 0.431554, acc.: 80.47%] [G loss: 0.738479]\n",
      "epoch:12 step:11992 [D loss: 0.609360, acc.: 59.38%] [G loss: 0.572667]\n",
      "epoch:12 step:11993 [D loss: 0.503075, acc.: 78.91%] [G loss: 0.756939]\n",
      "epoch:12 step:11994 [D loss: 0.496689, acc.: 77.34%] [G loss: 0.567217]\n",
      "epoch:12 step:11995 [D loss: 0.522624, acc.: 71.88%] [G loss: 0.719024]\n",
      "epoch:12 step:11996 [D loss: 0.548444, acc.: 70.31%] [G loss: 0.630582]\n",
      "epoch:12 step:11997 [D loss: 0.517636, acc.: 75.00%] [G loss: 0.607270]\n",
      "epoch:12 step:11998 [D loss: 0.513063, acc.: 73.44%] [G loss: 0.570368]\n",
      "epoch:12 step:11999 [D loss: 0.556162, acc.: 66.41%] [G loss: 0.572054]\n",
      "epoch:12 step:12000 [D loss: 0.541140, acc.: 70.31%] [G loss: 0.592306]\n",
      "##############\n",
      "[3.24761678 1.52770837 6.17365723 4.71423143 3.95157119 5.82473722\n",
      " 4.58395907 4.81150485 4.65191792 4.12109396]\n",
      "##########\n",
      "epoch:12 step:12001 [D loss: 0.603297, acc.: 62.50%] [G loss: 0.539983]\n",
      "epoch:12 step:12002 [D loss: 0.506854, acc.: 76.56%] [G loss: 0.671773]\n",
      "epoch:12 step:12003 [D loss: 0.624093, acc.: 60.94%] [G loss: 0.646507]\n",
      "epoch:12 step:12004 [D loss: 0.548032, acc.: 70.31%] [G loss: 0.606702]\n",
      "epoch:12 step:12005 [D loss: 0.540719, acc.: 71.88%] [G loss: 0.664472]\n",
      "epoch:12 step:12006 [D loss: 0.609040, acc.: 64.06%] [G loss: 0.547332]\n",
      "epoch:12 step:12007 [D loss: 0.518298, acc.: 74.22%] [G loss: 0.645853]\n",
      "epoch:12 step:12008 [D loss: 0.574742, acc.: 66.41%] [G loss: 0.534035]\n",
      "epoch:12 step:12009 [D loss: 0.622136, acc.: 61.72%] [G loss: 0.513267]\n",
      "epoch:12 step:12010 [D loss: 0.664088, acc.: 62.50%] [G loss: 0.462661]\n",
      "epoch:12 step:12011 [D loss: 0.509395, acc.: 72.66%] [G loss: 0.595332]\n",
      "epoch:12 step:12012 [D loss: 0.545552, acc.: 69.53%] [G loss: 0.664768]\n",
      "epoch:12 step:12013 [D loss: 0.536838, acc.: 71.88%] [G loss: 0.684609]\n",
      "epoch:12 step:12014 [D loss: 0.563590, acc.: 74.22%] [G loss: 0.758118]\n",
      "epoch:12 step:12015 [D loss: 0.593113, acc.: 67.19%] [G loss: 0.693883]\n",
      "epoch:12 step:12016 [D loss: 0.531350, acc.: 69.53%] [G loss: 0.590235]\n",
      "epoch:12 step:12017 [D loss: 0.548838, acc.: 71.09%] [G loss: 0.643636]\n",
      "epoch:12 step:12018 [D loss: 0.593430, acc.: 67.19%] [G loss: 0.576478]\n",
      "epoch:12 step:12019 [D loss: 0.562535, acc.: 70.31%] [G loss: 0.581101]\n",
      "epoch:12 step:12020 [D loss: 0.612154, acc.: 66.41%] [G loss: 0.634201]\n",
      "epoch:12 step:12021 [D loss: 0.555144, acc.: 70.31%] [G loss: 0.623971]\n",
      "epoch:12 step:12022 [D loss: 0.547682, acc.: 71.09%] [G loss: 0.643680]\n",
      "epoch:12 step:12023 [D loss: 0.565323, acc.: 67.97%] [G loss: 0.568682]\n",
      "epoch:12 step:12024 [D loss: 0.493286, acc.: 76.56%] [G loss: 0.656992]\n",
      "epoch:12 step:12025 [D loss: 0.498691, acc.: 78.12%] [G loss: 0.838884]\n",
      "epoch:12 step:12026 [D loss: 0.512269, acc.: 75.00%] [G loss: 0.809606]\n",
      "epoch:12 step:12027 [D loss: 0.578516, acc.: 73.44%] [G loss: 0.721329]\n",
      "epoch:12 step:12028 [D loss: 0.658697, acc.: 64.84%] [G loss: 0.518832]\n",
      "epoch:12 step:12029 [D loss: 0.547264, acc.: 67.97%] [G loss: 0.482925]\n",
      "epoch:12 step:12030 [D loss: 0.498585, acc.: 75.00%] [G loss: 0.630766]\n",
      "epoch:12 step:12031 [D loss: 0.650705, acc.: 63.28%] [G loss: 0.605222]\n",
      "epoch:12 step:12032 [D loss: 0.683577, acc.: 58.59%] [G loss: 0.502912]\n",
      "epoch:12 step:12033 [D loss: 0.512367, acc.: 77.34%] [G loss: 0.608119]\n",
      "epoch:12 step:12034 [D loss: 0.547318, acc.: 68.75%] [G loss: 0.619215]\n",
      "epoch:12 step:12035 [D loss: 0.522478, acc.: 72.66%] [G loss: 0.660489]\n",
      "epoch:12 step:12036 [D loss: 0.463070, acc.: 79.69%] [G loss: 0.675036]\n",
      "epoch:12 step:12037 [D loss: 0.632056, acc.: 66.41%] [G loss: 0.749805]\n",
      "epoch:12 step:12038 [D loss: 0.638172, acc.: 60.94%] [G loss: 0.626916]\n",
      "epoch:12 step:12039 [D loss: 0.536738, acc.: 65.62%] [G loss: 0.609693]\n",
      "epoch:12 step:12040 [D loss: 0.534837, acc.: 70.31%] [G loss: 0.625982]\n",
      "epoch:12 step:12041 [D loss: 0.522221, acc.: 76.56%] [G loss: 0.481795]\n",
      "epoch:12 step:12042 [D loss: 0.503416, acc.: 69.53%] [G loss: 0.580740]\n",
      "epoch:12 step:12043 [D loss: 0.589152, acc.: 69.53%] [G loss: 0.553293]\n",
      "epoch:12 step:12044 [D loss: 0.594967, acc.: 64.84%] [G loss: 0.659849]\n",
      "epoch:12 step:12045 [D loss: 0.520479, acc.: 71.88%] [G loss: 0.654746]\n",
      "epoch:12 step:12046 [D loss: 0.465205, acc.: 80.47%] [G loss: 0.685467]\n",
      "epoch:12 step:12047 [D loss: 0.520501, acc.: 72.66%] [G loss: 0.778545]\n",
      "epoch:12 step:12048 [D loss: 0.527131, acc.: 73.44%] [G loss: 0.694888]\n",
      "epoch:12 step:12049 [D loss: 0.588315, acc.: 65.62%] [G loss: 0.571602]\n",
      "epoch:12 step:12050 [D loss: 0.569858, acc.: 67.19%] [G loss: 0.508590]\n",
      "epoch:12 step:12051 [D loss: 0.582837, acc.: 68.75%] [G loss: 0.511928]\n",
      "epoch:12 step:12052 [D loss: 0.533626, acc.: 69.53%] [G loss: 0.627322]\n",
      "epoch:12 step:12053 [D loss: 0.590726, acc.: 66.41%] [G loss: 0.485165]\n",
      "epoch:12 step:12054 [D loss: 0.505998, acc.: 74.22%] [G loss: 0.604204]\n",
      "epoch:12 step:12055 [D loss: 0.572006, acc.: 68.75%] [G loss: 0.536206]\n",
      "epoch:12 step:12056 [D loss: 0.642346, acc.: 65.62%] [G loss: 0.468365]\n",
      "epoch:12 step:12057 [D loss: 0.549440, acc.: 69.53%] [G loss: 0.484706]\n",
      "epoch:12 step:12058 [D loss: 0.490081, acc.: 74.22%] [G loss: 0.588997]\n",
      "epoch:12 step:12059 [D loss: 0.576196, acc.: 64.84%] [G loss: 0.723067]\n",
      "epoch:12 step:12060 [D loss: 0.572636, acc.: 72.66%] [G loss: 0.752510]\n",
      "epoch:12 step:12061 [D loss: 0.613850, acc.: 67.97%] [G loss: 0.581964]\n",
      "epoch:12 step:12062 [D loss: 0.536205, acc.: 71.09%] [G loss: 0.673490]\n",
      "epoch:12 step:12063 [D loss: 0.485808, acc.: 77.34%] [G loss: 0.592846]\n",
      "epoch:12 step:12064 [D loss: 0.588851, acc.: 64.84%] [G loss: 0.503283]\n",
      "epoch:12 step:12065 [D loss: 0.533775, acc.: 68.75%] [G loss: 0.463496]\n",
      "epoch:12 step:12066 [D loss: 0.541708, acc.: 67.19%] [G loss: 0.529180]\n",
      "epoch:12 step:12067 [D loss: 0.464737, acc.: 75.00%] [G loss: 0.498630]\n",
      "epoch:12 step:12068 [D loss: 0.587428, acc.: 69.53%] [G loss: 0.527565]\n",
      "epoch:12 step:12069 [D loss: 0.513359, acc.: 75.00%] [G loss: 0.528836]\n",
      "epoch:12 step:12070 [D loss: 0.544401, acc.: 71.88%] [G loss: 0.533869]\n",
      "epoch:12 step:12071 [D loss: 0.589571, acc.: 60.94%] [G loss: 0.583565]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:12072 [D loss: 0.619510, acc.: 63.28%] [G loss: 0.440519]\n",
      "epoch:12 step:12073 [D loss: 0.518435, acc.: 69.53%] [G loss: 0.657445]\n",
      "epoch:12 step:12074 [D loss: 0.573312, acc.: 66.41%] [G loss: 0.663137]\n",
      "epoch:12 step:12075 [D loss: 0.589129, acc.: 68.75%] [G loss: 0.510701]\n",
      "epoch:12 step:12076 [D loss: 0.522813, acc.: 72.66%] [G loss: 0.562163]\n",
      "epoch:12 step:12077 [D loss: 0.502641, acc.: 77.34%] [G loss: 0.522799]\n",
      "epoch:12 step:12078 [D loss: 0.507956, acc.: 74.22%] [G loss: 0.561071]\n",
      "epoch:12 step:12079 [D loss: 0.534177, acc.: 71.88%] [G loss: 0.547234]\n",
      "epoch:12 step:12080 [D loss: 0.532164, acc.: 71.09%] [G loss: 0.587124]\n",
      "epoch:12 step:12081 [D loss: 0.522348, acc.: 71.88%] [G loss: 0.572264]\n",
      "epoch:12 step:12082 [D loss: 0.568915, acc.: 68.75%] [G loss: 0.456390]\n",
      "epoch:12 step:12083 [D loss: 0.584427, acc.: 66.41%] [G loss: 0.419590]\n",
      "epoch:12 step:12084 [D loss: 0.633499, acc.: 63.28%] [G loss: 0.427107]\n",
      "epoch:12 step:12085 [D loss: 0.513233, acc.: 75.78%] [G loss: 0.569730]\n",
      "epoch:12 step:12086 [D loss: 0.494628, acc.: 76.56%] [G loss: 0.550776]\n",
      "epoch:12 step:12087 [D loss: 0.573320, acc.: 64.06%] [G loss: 0.447293]\n",
      "epoch:12 step:12088 [D loss: 0.599168, acc.: 67.97%] [G loss: 0.620386]\n",
      "epoch:12 step:12089 [D loss: 0.580632, acc.: 66.41%] [G loss: 0.546996]\n",
      "epoch:12 step:12090 [D loss: 0.615796, acc.: 57.81%] [G loss: 0.539663]\n",
      "epoch:12 step:12091 [D loss: 0.611493, acc.: 67.97%] [G loss: 0.369595]\n",
      "epoch:12 step:12092 [D loss: 0.560507, acc.: 66.41%] [G loss: 0.412116]\n",
      "epoch:12 step:12093 [D loss: 0.585464, acc.: 70.31%] [G loss: 0.402406]\n",
      "epoch:12 step:12094 [D loss: 0.565001, acc.: 67.19%] [G loss: 0.451528]\n",
      "epoch:12 step:12095 [D loss: 0.579731, acc.: 68.75%] [G loss: 0.456083]\n",
      "epoch:12 step:12096 [D loss: 0.513022, acc.: 77.34%] [G loss: 0.569894]\n",
      "epoch:12 step:12097 [D loss: 0.571518, acc.: 67.97%] [G loss: 0.656166]\n",
      "epoch:12 step:12098 [D loss: 0.484632, acc.: 75.78%] [G loss: 0.592518]\n",
      "epoch:12 step:12099 [D loss: 0.591205, acc.: 66.41%] [G loss: 0.489593]\n",
      "epoch:12 step:12100 [D loss: 0.567147, acc.: 70.31%] [G loss: 0.541843]\n",
      "epoch:12 step:12101 [D loss: 0.459265, acc.: 75.00%] [G loss: 0.635043]\n",
      "epoch:12 step:12102 [D loss: 0.624751, acc.: 67.19%] [G loss: 0.560082]\n",
      "epoch:12 step:12103 [D loss: 0.579603, acc.: 64.06%] [G loss: 0.601764]\n",
      "epoch:12 step:12104 [D loss: 0.521201, acc.: 73.44%] [G loss: 0.569517]\n",
      "epoch:12 step:12105 [D loss: 0.564766, acc.: 71.88%] [G loss: 0.609024]\n",
      "epoch:12 step:12106 [D loss: 0.578062, acc.: 64.84%] [G loss: 0.411903]\n",
      "epoch:12 step:12107 [D loss: 0.556914, acc.: 68.75%] [G loss: 0.623477]\n",
      "epoch:12 step:12108 [D loss: 0.555564, acc.: 67.19%] [G loss: 0.463767]\n",
      "epoch:12 step:12109 [D loss: 0.570635, acc.: 67.97%] [G loss: 0.427760]\n",
      "epoch:12 step:12110 [D loss: 0.511435, acc.: 67.97%] [G loss: 0.497503]\n",
      "epoch:12 step:12111 [D loss: 0.667969, acc.: 59.38%] [G loss: 0.499295]\n",
      "epoch:12 step:12112 [D loss: 0.514177, acc.: 81.25%] [G loss: 0.551042]\n",
      "epoch:12 step:12113 [D loss: 0.584810, acc.: 65.62%] [G loss: 0.454184]\n",
      "epoch:12 step:12114 [D loss: 0.458030, acc.: 76.56%] [G loss: 0.550444]\n",
      "epoch:12 step:12115 [D loss: 0.543513, acc.: 65.62%] [G loss: 0.725423]\n",
      "epoch:12 step:12116 [D loss: 0.550422, acc.: 71.88%] [G loss: 0.703760]\n",
      "epoch:12 step:12117 [D loss: 0.588638, acc.: 67.19%] [G loss: 0.482695]\n",
      "epoch:12 step:12118 [D loss: 0.540913, acc.: 72.66%] [G loss: 0.546646]\n",
      "epoch:12 step:12119 [D loss: 0.491002, acc.: 73.44%] [G loss: 0.623063]\n",
      "epoch:12 step:12120 [D loss: 0.545320, acc.: 69.53%] [G loss: 0.523984]\n",
      "epoch:12 step:12121 [D loss: 0.576872, acc.: 65.62%] [G loss: 0.579467]\n",
      "epoch:12 step:12122 [D loss: 0.534658, acc.: 70.31%] [G loss: 0.448426]\n",
      "epoch:12 step:12123 [D loss: 0.581834, acc.: 75.00%] [G loss: 0.673168]\n",
      "epoch:12 step:12124 [D loss: 0.659111, acc.: 54.69%] [G loss: 0.470938]\n",
      "epoch:12 step:12125 [D loss: 0.565353, acc.: 67.19%] [G loss: 0.403333]\n",
      "epoch:12 step:12126 [D loss: 0.581136, acc.: 66.41%] [G loss: 0.511361]\n",
      "epoch:12 step:12127 [D loss: 0.624511, acc.: 64.06%] [G loss: 0.558738]\n",
      "epoch:12 step:12128 [D loss: 0.481618, acc.: 71.88%] [G loss: 0.643935]\n",
      "epoch:12 step:12129 [D loss: 0.542403, acc.: 69.53%] [G loss: 0.607081]\n",
      "epoch:12 step:12130 [D loss: 0.487629, acc.: 75.78%] [G loss: 0.728650]\n",
      "epoch:12 step:12131 [D loss: 0.557335, acc.: 69.53%] [G loss: 0.636365]\n",
      "epoch:12 step:12132 [D loss: 0.534994, acc.: 71.88%] [G loss: 0.653672]\n",
      "epoch:12 step:12133 [D loss: 0.586428, acc.: 66.41%] [G loss: 0.626425]\n",
      "epoch:12 step:12134 [D loss: 0.503042, acc.: 73.44%] [G loss: 0.634398]\n",
      "epoch:12 step:12135 [D loss: 0.576621, acc.: 67.97%] [G loss: 0.565831]\n",
      "epoch:12 step:12136 [D loss: 0.651766, acc.: 58.59%] [G loss: 0.541650]\n",
      "epoch:12 step:12137 [D loss: 0.577052, acc.: 67.97%] [G loss: 0.491625]\n",
      "epoch:12 step:12138 [D loss: 0.463038, acc.: 75.78%] [G loss: 0.777070]\n",
      "epoch:12 step:12139 [D loss: 0.534775, acc.: 76.56%] [G loss: 0.704887]\n",
      "epoch:12 step:12140 [D loss: 0.513969, acc.: 76.56%] [G loss: 0.636273]\n",
      "epoch:12 step:12141 [D loss: 0.522455, acc.: 71.88%] [G loss: 0.577871]\n",
      "epoch:12 step:12142 [D loss: 0.441166, acc.: 82.81%] [G loss: 0.742489]\n",
      "epoch:12 step:12143 [D loss: 0.500544, acc.: 73.44%] [G loss: 0.772878]\n",
      "epoch:12 step:12144 [D loss: 0.523189, acc.: 78.12%] [G loss: 0.666408]\n",
      "epoch:12 step:12145 [D loss: 0.515592, acc.: 73.44%] [G loss: 0.627510]\n",
      "epoch:12 step:12146 [D loss: 0.625805, acc.: 63.28%] [G loss: 0.512188]\n",
      "epoch:12 step:12147 [D loss: 0.528651, acc.: 67.97%] [G loss: 0.693580]\n",
      "epoch:12 step:12148 [D loss: 0.616933, acc.: 62.50%] [G loss: 0.604700]\n",
      "epoch:12 step:12149 [D loss: 0.555043, acc.: 70.31%] [G loss: 0.629627]\n",
      "epoch:12 step:12150 [D loss: 0.518834, acc.: 69.53%] [G loss: 0.539682]\n",
      "epoch:12 step:12151 [D loss: 0.560824, acc.: 67.97%] [G loss: 0.656213]\n",
      "epoch:12 step:12152 [D loss: 0.555789, acc.: 67.97%] [G loss: 0.613347]\n",
      "epoch:12 step:12153 [D loss: 0.511933, acc.: 69.53%] [G loss: 0.666841]\n",
      "epoch:12 step:12154 [D loss: 0.558126, acc.: 73.44%] [G loss: 0.636134]\n",
      "epoch:12 step:12155 [D loss: 0.459774, acc.: 76.56%] [G loss: 0.922794]\n",
      "epoch:12 step:12156 [D loss: 0.474574, acc.: 79.69%] [G loss: 0.638609]\n",
      "epoch:12 step:12157 [D loss: 0.565413, acc.: 72.66%] [G loss: 0.634913]\n",
      "epoch:12 step:12158 [D loss: 0.456017, acc.: 80.47%] [G loss: 0.833053]\n",
      "epoch:12 step:12159 [D loss: 0.628578, acc.: 63.28%] [G loss: 0.612478]\n",
      "epoch:12 step:12160 [D loss: 0.498340, acc.: 74.22%] [G loss: 0.721439]\n",
      "epoch:12 step:12161 [D loss: 0.603568, acc.: 61.72%] [G loss: 0.599396]\n",
      "epoch:12 step:12162 [D loss: 0.497549, acc.: 74.22%] [G loss: 0.576335]\n",
      "epoch:12 step:12163 [D loss: 0.459207, acc.: 77.34%] [G loss: 0.868902]\n",
      "epoch:12 step:12164 [D loss: 0.714307, acc.: 65.62%] [G loss: 0.762931]\n",
      "epoch:12 step:12165 [D loss: 0.512520, acc.: 71.88%] [G loss: 0.684592]\n",
      "epoch:12 step:12166 [D loss: 0.498884, acc.: 78.12%] [G loss: 0.590759]\n",
      "epoch:12 step:12167 [D loss: 0.486813, acc.: 77.34%] [G loss: 0.652912]\n",
      "epoch:12 step:12168 [D loss: 0.481855, acc.: 72.66%] [G loss: 0.710015]\n",
      "epoch:12 step:12169 [D loss: 0.435764, acc.: 78.91%] [G loss: 0.883422]\n",
      "epoch:12 step:12170 [D loss: 0.401411, acc.: 82.03%] [G loss: 1.117875]\n",
      "epoch:12 step:12171 [D loss: 0.554861, acc.: 75.00%] [G loss: 1.059804]\n",
      "epoch:12 step:12172 [D loss: 0.674059, acc.: 63.28%] [G loss: 0.938431]\n",
      "epoch:12 step:12173 [D loss: 0.538805, acc.: 74.22%] [G loss: 0.808229]\n",
      "epoch:12 step:12174 [D loss: 0.422100, acc.: 77.34%] [G loss: 0.988925]\n",
      "epoch:12 step:12175 [D loss: 0.537388, acc.: 69.53%] [G loss: 0.943235]\n",
      "epoch:12 step:12176 [D loss: 0.604971, acc.: 69.53%] [G loss: 0.788184]\n",
      "epoch:12 step:12177 [D loss: 0.514947, acc.: 71.88%] [G loss: 0.851923]\n",
      "epoch:12 step:12178 [D loss: 0.533089, acc.: 67.19%] [G loss: 0.942741]\n",
      "epoch:12 step:12179 [D loss: 0.490707, acc.: 71.88%] [G loss: 0.962477]\n",
      "epoch:12 step:12180 [D loss: 0.364305, acc.: 82.81%] [G loss: 1.216778]\n",
      "epoch:12 step:12181 [D loss: 0.408918, acc.: 81.25%] [G loss: 1.239661]\n",
      "epoch:13 step:12182 [D loss: 0.604580, acc.: 71.09%] [G loss: 1.042476]\n",
      "epoch:13 step:12183 [D loss: 0.493153, acc.: 74.22%] [G loss: 0.891673]\n",
      "epoch:13 step:12184 [D loss: 0.557692, acc.: 71.88%] [G loss: 0.812402]\n",
      "epoch:13 step:12185 [D loss: 0.620957, acc.: 72.66%] [G loss: 0.733602]\n",
      "epoch:13 step:12186 [D loss: 0.585256, acc.: 71.09%] [G loss: 0.706898]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12187 [D loss: 0.573528, acc.: 68.75%] [G loss: 0.701544]\n",
      "epoch:13 step:12188 [D loss: 0.478105, acc.: 77.34%] [G loss: 0.835643]\n",
      "epoch:13 step:12189 [D loss: 0.515016, acc.: 80.47%] [G loss: 0.659775]\n",
      "epoch:13 step:12190 [D loss: 0.469869, acc.: 76.56%] [G loss: 0.795391]\n",
      "epoch:13 step:12191 [D loss: 0.528799, acc.: 74.22%] [G loss: 0.546028]\n",
      "epoch:13 step:12192 [D loss: 0.492367, acc.: 77.34%] [G loss: 0.670992]\n",
      "epoch:13 step:12193 [D loss: 0.651024, acc.: 64.84%] [G loss: 0.737067]\n",
      "epoch:13 step:12194 [D loss: 0.566388, acc.: 72.66%] [G loss: 0.603202]\n",
      "epoch:13 step:12195 [D loss: 0.615370, acc.: 62.50%] [G loss: 0.550434]\n",
      "epoch:13 step:12196 [D loss: 0.464737, acc.: 77.34%] [G loss: 0.695740]\n",
      "epoch:13 step:12197 [D loss: 0.476423, acc.: 77.34%] [G loss: 0.675708]\n",
      "epoch:13 step:12198 [D loss: 0.571445, acc.: 67.97%] [G loss: 0.687915]\n",
      "epoch:13 step:12199 [D loss: 0.563477, acc.: 72.66%] [G loss: 0.674223]\n",
      "epoch:13 step:12200 [D loss: 0.600224, acc.: 63.28%] [G loss: 0.661738]\n",
      "##############\n",
      "[3.38513685 1.42271049 6.10040694 4.83703355 3.8258681  5.68729298\n",
      " 4.45654052 4.72880359 4.52998281 4.06078011]\n",
      "##########\n",
      "epoch:13 step:12201 [D loss: 0.631938, acc.: 63.28%] [G loss: 0.672651]\n",
      "epoch:13 step:12202 [D loss: 0.607698, acc.: 63.28%] [G loss: 0.562358]\n",
      "epoch:13 step:12203 [D loss: 0.436572, acc.: 82.81%] [G loss: 1.034101]\n",
      "epoch:13 step:12204 [D loss: 0.529811, acc.: 68.75%] [G loss: 0.678183]\n",
      "epoch:13 step:12205 [D loss: 0.603252, acc.: 71.09%] [G loss: 0.716646]\n",
      "epoch:13 step:12206 [D loss: 0.529532, acc.: 70.31%] [G loss: 0.577068]\n",
      "epoch:13 step:12207 [D loss: 0.605717, acc.: 68.75%] [G loss: 0.619239]\n",
      "epoch:13 step:12208 [D loss: 0.526741, acc.: 71.88%] [G loss: 0.583857]\n",
      "epoch:13 step:12209 [D loss: 0.574649, acc.: 61.72%] [G loss: 0.588648]\n",
      "epoch:13 step:12210 [D loss: 0.484894, acc.: 75.78%] [G loss: 0.549477]\n",
      "epoch:13 step:12211 [D loss: 0.541448, acc.: 71.88%] [G loss: 0.553030]\n",
      "epoch:13 step:12212 [D loss: 0.620516, acc.: 67.19%] [G loss: 0.537715]\n",
      "epoch:13 step:12213 [D loss: 0.560649, acc.: 69.53%] [G loss: 0.533754]\n",
      "epoch:13 step:12214 [D loss: 0.518000, acc.: 67.19%] [G loss: 0.570998]\n",
      "epoch:13 step:12215 [D loss: 0.535450, acc.: 70.31%] [G loss: 0.602400]\n",
      "epoch:13 step:12216 [D loss: 0.507294, acc.: 75.00%] [G loss: 0.560254]\n",
      "epoch:13 step:12217 [D loss: 0.527364, acc.: 71.88%] [G loss: 0.599056]\n",
      "epoch:13 step:12218 [D loss: 0.529366, acc.: 77.34%] [G loss: 0.697625]\n",
      "epoch:13 step:12219 [D loss: 0.619441, acc.: 65.62%] [G loss: 0.602453]\n",
      "epoch:13 step:12220 [D loss: 0.490942, acc.: 76.56%] [G loss: 0.715553]\n",
      "epoch:13 step:12221 [D loss: 0.433366, acc.: 81.25%] [G loss: 0.755166]\n",
      "epoch:13 step:12222 [D loss: 0.540019, acc.: 68.75%] [G loss: 0.766111]\n",
      "epoch:13 step:12223 [D loss: 0.542096, acc.: 68.75%] [G loss: 0.579751]\n",
      "epoch:13 step:12224 [D loss: 0.557791, acc.: 71.09%] [G loss: 0.614232]\n",
      "epoch:13 step:12225 [D loss: 0.636887, acc.: 64.06%] [G loss: 0.507151]\n",
      "epoch:13 step:12226 [D loss: 0.539979, acc.: 71.88%] [G loss: 0.600037]\n",
      "epoch:13 step:12227 [D loss: 0.491034, acc.: 77.34%] [G loss: 0.672241]\n",
      "epoch:13 step:12228 [D loss: 0.490239, acc.: 76.56%] [G loss: 0.658233]\n",
      "epoch:13 step:12229 [D loss: 0.525994, acc.: 75.78%] [G loss: 0.830859]\n",
      "epoch:13 step:12230 [D loss: 0.534963, acc.: 72.66%] [G loss: 0.631949]\n",
      "epoch:13 step:12231 [D loss: 0.525508, acc.: 76.56%] [G loss: 0.747265]\n",
      "epoch:13 step:12232 [D loss: 0.674332, acc.: 57.81%] [G loss: 0.542402]\n",
      "epoch:13 step:12233 [D loss: 0.565336, acc.: 68.75%] [G loss: 0.713319]\n",
      "epoch:13 step:12234 [D loss: 0.538962, acc.: 73.44%] [G loss: 0.771947]\n",
      "epoch:13 step:12235 [D loss: 0.507890, acc.: 73.44%] [G loss: 0.770061]\n",
      "epoch:13 step:12236 [D loss: 0.585251, acc.: 69.53%] [G loss: 0.605774]\n",
      "epoch:13 step:12237 [D loss: 0.532488, acc.: 73.44%] [G loss: 0.683938]\n",
      "epoch:13 step:12238 [D loss: 0.568439, acc.: 68.75%] [G loss: 0.721051]\n",
      "epoch:13 step:12239 [D loss: 0.570560, acc.: 67.97%] [G loss: 0.726384]\n",
      "epoch:13 step:12240 [D loss: 0.535169, acc.: 69.53%] [G loss: 0.613832]\n",
      "epoch:13 step:12241 [D loss: 0.562892, acc.: 64.84%] [G loss: 0.691212]\n",
      "epoch:13 step:12242 [D loss: 0.546441, acc.: 67.97%] [G loss: 0.569621]\n",
      "epoch:13 step:12243 [D loss: 0.538601, acc.: 71.09%] [G loss: 0.589045]\n",
      "epoch:13 step:12244 [D loss: 0.548865, acc.: 67.97%] [G loss: 0.563926]\n",
      "epoch:13 step:12245 [D loss: 0.601921, acc.: 65.62%] [G loss: 0.545648]\n",
      "epoch:13 step:12246 [D loss: 0.499803, acc.: 75.78%] [G loss: 0.553465]\n",
      "epoch:13 step:12247 [D loss: 0.502212, acc.: 75.00%] [G loss: 0.524823]\n",
      "epoch:13 step:12248 [D loss: 0.588019, acc.: 67.19%] [G loss: 0.450286]\n",
      "epoch:13 step:12249 [D loss: 0.516033, acc.: 70.31%] [G loss: 0.630023]\n",
      "epoch:13 step:12250 [D loss: 0.505045, acc.: 75.00%] [G loss: 0.595679]\n",
      "epoch:13 step:12251 [D loss: 0.503176, acc.: 73.44%] [G loss: 0.562315]\n",
      "epoch:13 step:12252 [D loss: 0.588693, acc.: 69.53%] [G loss: 0.465565]\n",
      "epoch:13 step:12253 [D loss: 0.530309, acc.: 68.75%] [G loss: 0.628133]\n",
      "epoch:13 step:12254 [D loss: 0.563026, acc.: 68.75%] [G loss: 0.616502]\n",
      "epoch:13 step:12255 [D loss: 0.499885, acc.: 72.66%] [G loss: 0.648682]\n",
      "epoch:13 step:12256 [D loss: 0.503839, acc.: 78.12%] [G loss: 0.652198]\n",
      "epoch:13 step:12257 [D loss: 0.511516, acc.: 77.34%] [G loss: 0.579798]\n",
      "epoch:13 step:12258 [D loss: 0.430741, acc.: 81.25%] [G loss: 0.772633]\n",
      "epoch:13 step:12259 [D loss: 0.578406, acc.: 69.53%] [G loss: 0.657420]\n",
      "epoch:13 step:12260 [D loss: 0.582659, acc.: 68.75%] [G loss: 0.506639]\n",
      "epoch:13 step:12261 [D loss: 0.584981, acc.: 64.84%] [G loss: 0.569981]\n",
      "epoch:13 step:12262 [D loss: 0.533271, acc.: 72.66%] [G loss: 0.705244]\n",
      "epoch:13 step:12263 [D loss: 0.554492, acc.: 66.41%] [G loss: 0.577449]\n",
      "epoch:13 step:12264 [D loss: 0.501500, acc.: 75.00%] [G loss: 0.635012]\n",
      "epoch:13 step:12265 [D loss: 0.526634, acc.: 68.75%] [G loss: 0.738004]\n",
      "epoch:13 step:12266 [D loss: 0.585093, acc.: 69.53%] [G loss: 0.524384]\n",
      "epoch:13 step:12267 [D loss: 0.581752, acc.: 75.00%] [G loss: 0.594818]\n",
      "epoch:13 step:12268 [D loss: 0.498842, acc.: 71.88%] [G loss: 0.699858]\n",
      "epoch:13 step:12269 [D loss: 0.475146, acc.: 78.91%] [G loss: 0.633287]\n",
      "epoch:13 step:12270 [D loss: 0.551693, acc.: 69.53%] [G loss: 0.830202]\n",
      "epoch:13 step:12271 [D loss: 0.513094, acc.: 71.09%] [G loss: 0.605387]\n",
      "epoch:13 step:12272 [D loss: 0.566871, acc.: 69.53%] [G loss: 0.679988]\n",
      "epoch:13 step:12273 [D loss: 0.485812, acc.: 80.47%] [G loss: 0.705968]\n",
      "epoch:13 step:12274 [D loss: 0.520704, acc.: 74.22%] [G loss: 0.748009]\n",
      "epoch:13 step:12275 [D loss: 0.462982, acc.: 75.00%] [G loss: 0.864071]\n",
      "epoch:13 step:12276 [D loss: 0.578373, acc.: 67.97%] [G loss: 0.645909]\n",
      "epoch:13 step:12277 [D loss: 0.502326, acc.: 75.78%] [G loss: 0.694342]\n",
      "epoch:13 step:12278 [D loss: 0.507938, acc.: 73.44%] [G loss: 0.648079]\n",
      "epoch:13 step:12279 [D loss: 0.553507, acc.: 66.41%] [G loss: 0.746641]\n",
      "epoch:13 step:12280 [D loss: 0.566218, acc.: 69.53%] [G loss: 0.487517]\n",
      "epoch:13 step:12281 [D loss: 0.480371, acc.: 70.31%] [G loss: 0.828586]\n",
      "epoch:13 step:12282 [D loss: 0.507599, acc.: 72.66%] [G loss: 0.781850]\n",
      "epoch:13 step:12283 [D loss: 0.597871, acc.: 64.84%] [G loss: 0.528243]\n",
      "epoch:13 step:12284 [D loss: 0.486999, acc.: 71.09%] [G loss: 0.590437]\n",
      "epoch:13 step:12285 [D loss: 0.513731, acc.: 68.75%] [G loss: 0.570495]\n",
      "epoch:13 step:12286 [D loss: 0.581336, acc.: 64.84%] [G loss: 0.540002]\n",
      "epoch:13 step:12287 [D loss: 0.508955, acc.: 70.31%] [G loss: 0.659433]\n",
      "epoch:13 step:12288 [D loss: 0.524604, acc.: 75.78%] [G loss: 0.694903]\n",
      "epoch:13 step:12289 [D loss: 0.638475, acc.: 62.50%] [G loss: 0.609784]\n",
      "epoch:13 step:12290 [D loss: 0.577726, acc.: 66.41%] [G loss: 0.633409]\n",
      "epoch:13 step:12291 [D loss: 0.572909, acc.: 71.88%] [G loss: 0.559751]\n",
      "epoch:13 step:12292 [D loss: 0.467536, acc.: 76.56%] [G loss: 0.654489]\n",
      "epoch:13 step:12293 [D loss: 0.526534, acc.: 74.22%] [G loss: 0.517434]\n",
      "epoch:13 step:12294 [D loss: 0.546270, acc.: 71.09%] [G loss: 0.436873]\n",
      "epoch:13 step:12295 [D loss: 0.532836, acc.: 70.31%] [G loss: 0.581587]\n",
      "epoch:13 step:12296 [D loss: 0.555184, acc.: 74.22%] [G loss: 0.554481]\n",
      "epoch:13 step:12297 [D loss: 0.544669, acc.: 69.53%] [G loss: 0.640210]\n",
      "epoch:13 step:12298 [D loss: 0.536094, acc.: 65.62%] [G loss: 0.649909]\n",
      "epoch:13 step:12299 [D loss: 0.552137, acc.: 65.62%] [G loss: 0.870992]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12300 [D loss: 0.491713, acc.: 74.22%] [G loss: 0.817946]\n",
      "epoch:13 step:12301 [D loss: 0.560194, acc.: 75.00%] [G loss: 0.662717]\n",
      "epoch:13 step:12302 [D loss: 0.518274, acc.: 72.66%] [G loss: 0.549650]\n",
      "epoch:13 step:12303 [D loss: 0.485409, acc.: 80.47%] [G loss: 0.731304]\n",
      "epoch:13 step:12304 [D loss: 0.527785, acc.: 74.22%] [G loss: 0.798285]\n",
      "epoch:13 step:12305 [D loss: 0.573783, acc.: 71.88%] [G loss: 0.694145]\n",
      "epoch:13 step:12306 [D loss: 0.510792, acc.: 71.88%] [G loss: 0.676355]\n",
      "epoch:13 step:12307 [D loss: 0.525187, acc.: 74.22%] [G loss: 0.506718]\n",
      "epoch:13 step:12308 [D loss: 0.451978, acc.: 78.91%] [G loss: 0.603029]\n",
      "epoch:13 step:12309 [D loss: 0.532972, acc.: 71.09%] [G loss: 0.559816]\n",
      "epoch:13 step:12310 [D loss: 0.543679, acc.: 74.22%] [G loss: 0.614874]\n",
      "epoch:13 step:12311 [D loss: 0.516470, acc.: 74.22%] [G loss: 0.551879]\n",
      "epoch:13 step:12312 [D loss: 0.461956, acc.: 79.69%] [G loss: 0.831512]\n",
      "epoch:13 step:12313 [D loss: 0.582415, acc.: 67.97%] [G loss: 0.656176]\n",
      "epoch:13 step:12314 [D loss: 0.566013, acc.: 64.84%] [G loss: 0.628446]\n",
      "epoch:13 step:12315 [D loss: 0.513349, acc.: 71.09%] [G loss: 0.566037]\n",
      "epoch:13 step:12316 [D loss: 0.553826, acc.: 71.88%] [G loss: 0.595544]\n",
      "epoch:13 step:12317 [D loss: 0.535473, acc.: 74.22%] [G loss: 0.556769]\n",
      "epoch:13 step:12318 [D loss: 0.607388, acc.: 64.84%] [G loss: 0.497111]\n",
      "epoch:13 step:12319 [D loss: 0.547324, acc.: 71.09%] [G loss: 0.624646]\n",
      "epoch:13 step:12320 [D loss: 0.522133, acc.: 78.12%] [G loss: 0.578665]\n",
      "epoch:13 step:12321 [D loss: 0.601852, acc.: 60.94%] [G loss: 0.525794]\n",
      "epoch:13 step:12322 [D loss: 0.502180, acc.: 71.09%] [G loss: 0.538459]\n",
      "epoch:13 step:12323 [D loss: 0.550212, acc.: 69.53%] [G loss: 0.576984]\n",
      "epoch:13 step:12324 [D loss: 0.612079, acc.: 59.38%] [G loss: 0.517151]\n",
      "epoch:13 step:12325 [D loss: 0.492115, acc.: 75.78%] [G loss: 0.571396]\n",
      "epoch:13 step:12326 [D loss: 0.559361, acc.: 64.84%] [G loss: 0.598360]\n",
      "epoch:13 step:12327 [D loss: 0.511626, acc.: 75.78%] [G loss: 0.672862]\n",
      "epoch:13 step:12328 [D loss: 0.704228, acc.: 65.62%] [G loss: 0.642697]\n",
      "epoch:13 step:12329 [D loss: 0.546491, acc.: 73.44%] [G loss: 0.770195]\n",
      "epoch:13 step:12330 [D loss: 0.561317, acc.: 70.31%] [G loss: 0.582316]\n",
      "epoch:13 step:12331 [D loss: 0.634468, acc.: 60.16%] [G loss: 0.493595]\n",
      "epoch:13 step:12332 [D loss: 0.563958, acc.: 71.09%] [G loss: 0.538113]\n",
      "epoch:13 step:12333 [D loss: 0.483928, acc.: 73.44%] [G loss: 0.627601]\n",
      "epoch:13 step:12334 [D loss: 0.635342, acc.: 61.72%] [G loss: 0.639069]\n",
      "epoch:13 step:12335 [D loss: 0.536727, acc.: 71.09%] [G loss: 0.570060]\n",
      "epoch:13 step:12336 [D loss: 0.503738, acc.: 74.22%] [G loss: 0.588852]\n",
      "epoch:13 step:12337 [D loss: 0.471668, acc.: 77.34%] [G loss: 0.695277]\n",
      "epoch:13 step:12338 [D loss: 0.536639, acc.: 68.75%] [G loss: 0.633996]\n",
      "epoch:13 step:12339 [D loss: 0.583211, acc.: 69.53%] [G loss: 0.577423]\n",
      "epoch:13 step:12340 [D loss: 0.465110, acc.: 80.47%] [G loss: 0.629713]\n",
      "epoch:13 step:12341 [D loss: 0.630151, acc.: 67.19%] [G loss: 0.720797]\n",
      "epoch:13 step:12342 [D loss: 0.525017, acc.: 71.88%] [G loss: 0.663742]\n",
      "epoch:13 step:12343 [D loss: 0.448506, acc.: 78.12%] [G loss: 0.650757]\n",
      "epoch:13 step:12344 [D loss: 0.543486, acc.: 68.75%] [G loss: 0.764168]\n",
      "epoch:13 step:12345 [D loss: 0.526342, acc.: 75.00%] [G loss: 0.506700]\n",
      "epoch:13 step:12346 [D loss: 0.509079, acc.: 74.22%] [G loss: 0.674303]\n",
      "epoch:13 step:12347 [D loss: 0.551944, acc.: 68.75%] [G loss: 0.552177]\n",
      "epoch:13 step:12348 [D loss: 0.535864, acc.: 73.44%] [G loss: 0.401776]\n",
      "epoch:13 step:12349 [D loss: 0.563569, acc.: 68.75%] [G loss: 0.449437]\n",
      "epoch:13 step:12350 [D loss: 0.593357, acc.: 67.97%] [G loss: 0.475404]\n",
      "epoch:13 step:12351 [D loss: 0.496132, acc.: 71.09%] [G loss: 0.570298]\n",
      "epoch:13 step:12352 [D loss: 0.505144, acc.: 71.88%] [G loss: 0.558273]\n",
      "epoch:13 step:12353 [D loss: 0.512506, acc.: 72.66%] [G loss: 0.599398]\n",
      "epoch:13 step:12354 [D loss: 0.487691, acc.: 76.56%] [G loss: 0.617520]\n",
      "epoch:13 step:12355 [D loss: 0.606391, acc.: 64.84%] [G loss: 0.454517]\n",
      "epoch:13 step:12356 [D loss: 0.570372, acc.: 65.62%] [G loss: 0.628361]\n",
      "epoch:13 step:12357 [D loss: 0.539107, acc.: 70.31%] [G loss: 0.529584]\n",
      "epoch:13 step:12358 [D loss: 0.503994, acc.: 73.44%] [G loss: 0.582664]\n",
      "epoch:13 step:12359 [D loss: 0.596012, acc.: 66.41%] [G loss: 0.447842]\n",
      "epoch:13 step:12360 [D loss: 0.516850, acc.: 71.09%] [G loss: 0.506442]\n",
      "epoch:13 step:12361 [D loss: 0.628917, acc.: 64.84%] [G loss: 0.470159]\n",
      "epoch:13 step:12362 [D loss: 0.626117, acc.: 61.72%] [G loss: 0.369146]\n",
      "epoch:13 step:12363 [D loss: 0.586370, acc.: 67.19%] [G loss: 0.479022]\n",
      "epoch:13 step:12364 [D loss: 0.600273, acc.: 71.09%] [G loss: 0.631672]\n",
      "epoch:13 step:12365 [D loss: 0.630519, acc.: 64.06%] [G loss: 0.621167]\n",
      "epoch:13 step:12366 [D loss: 0.512004, acc.: 75.00%] [G loss: 0.664672]\n",
      "epoch:13 step:12367 [D loss: 0.568883, acc.: 73.44%] [G loss: 0.652038]\n",
      "epoch:13 step:12368 [D loss: 0.638854, acc.: 62.50%] [G loss: 0.514144]\n",
      "epoch:13 step:12369 [D loss: 0.606473, acc.: 66.41%] [G loss: 0.607726]\n",
      "epoch:13 step:12370 [D loss: 0.612209, acc.: 65.62%] [G loss: 0.775759]\n",
      "epoch:13 step:12371 [D loss: 0.532490, acc.: 76.56%] [G loss: 0.466855]\n",
      "epoch:13 step:12372 [D loss: 0.528385, acc.: 74.22%] [G loss: 0.632951]\n",
      "epoch:13 step:12373 [D loss: 0.584162, acc.: 67.97%] [G loss: 0.639990]\n",
      "epoch:13 step:12374 [D loss: 0.576893, acc.: 70.31%] [G loss: 0.670231]\n",
      "epoch:13 step:12375 [D loss: 0.445724, acc.: 80.47%] [G loss: 0.548083]\n",
      "epoch:13 step:12376 [D loss: 0.580732, acc.: 71.09%] [G loss: 0.632227]\n",
      "epoch:13 step:12377 [D loss: 0.565170, acc.: 67.19%] [G loss: 0.526572]\n",
      "epoch:13 step:12378 [D loss: 0.566869, acc.: 69.53%] [G loss: 0.516523]\n",
      "epoch:13 step:12379 [D loss: 0.476644, acc.: 76.56%] [G loss: 0.658592]\n",
      "epoch:13 step:12380 [D loss: 0.521160, acc.: 69.53%] [G loss: 0.722222]\n",
      "epoch:13 step:12381 [D loss: 0.639939, acc.: 62.50%] [G loss: 0.570047]\n",
      "epoch:13 step:12382 [D loss: 0.553267, acc.: 71.88%] [G loss: 0.621312]\n",
      "epoch:13 step:12383 [D loss: 0.573602, acc.: 68.75%] [G loss: 0.698331]\n",
      "epoch:13 step:12384 [D loss: 0.650977, acc.: 62.50%] [G loss: 0.498985]\n",
      "epoch:13 step:12385 [D loss: 0.560149, acc.: 67.19%] [G loss: 0.545118]\n",
      "epoch:13 step:12386 [D loss: 0.554882, acc.: 69.53%] [G loss: 0.541533]\n",
      "epoch:13 step:12387 [D loss: 0.484838, acc.: 76.56%] [G loss: 0.769485]\n",
      "epoch:13 step:12388 [D loss: 0.461854, acc.: 75.00%] [G loss: 0.860124]\n",
      "epoch:13 step:12389 [D loss: 0.483113, acc.: 75.78%] [G loss: 0.780397]\n",
      "epoch:13 step:12390 [D loss: 0.515589, acc.: 75.78%] [G loss: 0.592855]\n",
      "epoch:13 step:12391 [D loss: 0.574077, acc.: 71.88%] [G loss: 0.567612]\n",
      "epoch:13 step:12392 [D loss: 0.622106, acc.: 59.38%] [G loss: 0.373803]\n",
      "epoch:13 step:12393 [D loss: 0.544181, acc.: 72.66%] [G loss: 0.667981]\n",
      "epoch:13 step:12394 [D loss: 0.509288, acc.: 75.00%] [G loss: 0.567756]\n",
      "epoch:13 step:12395 [D loss: 0.665693, acc.: 61.72%] [G loss: 0.525821]\n",
      "epoch:13 step:12396 [D loss: 0.549684, acc.: 67.19%] [G loss: 0.524727]\n",
      "epoch:13 step:12397 [D loss: 0.512950, acc.: 70.31%] [G loss: 0.601080]\n",
      "epoch:13 step:12398 [D loss: 0.530707, acc.: 73.44%] [G loss: 0.616751]\n",
      "epoch:13 step:12399 [D loss: 0.562293, acc.: 69.53%] [G loss: 0.571820]\n",
      "epoch:13 step:12400 [D loss: 0.495817, acc.: 75.00%] [G loss: 0.667047]\n",
      "##############\n",
      "[3.24073033 0.95394066 6.22466166 5.19196058 3.90228321 5.83394859\n",
      " 4.5789171  4.88389228 4.74129768 4.1623837 ]\n",
      "##########\n",
      "epoch:13 step:12401 [D loss: 0.624053, acc.: 65.62%] [G loss: 0.702075]\n",
      "epoch:13 step:12402 [D loss: 0.558097, acc.: 67.19%] [G loss: 0.507987]\n",
      "epoch:13 step:12403 [D loss: 0.467280, acc.: 76.56%] [G loss: 0.680596]\n",
      "epoch:13 step:12404 [D loss: 0.509915, acc.: 75.78%] [G loss: 0.783210]\n",
      "epoch:13 step:12405 [D loss: 0.578731, acc.: 68.75%] [G loss: 0.454365]\n",
      "epoch:13 step:12406 [D loss: 0.527412, acc.: 73.44%] [G loss: 0.649393]\n",
      "epoch:13 step:12407 [D loss: 0.563613, acc.: 69.53%] [G loss: 0.577087]\n",
      "epoch:13 step:12408 [D loss: 0.544292, acc.: 65.62%] [G loss: 0.633554]\n",
      "epoch:13 step:12409 [D loss: 0.590981, acc.: 67.97%] [G loss: 0.617511]\n",
      "epoch:13 step:12410 [D loss: 0.549229, acc.: 74.22%] [G loss: 0.586344]\n",
      "epoch:13 step:12411 [D loss: 0.485767, acc.: 78.12%] [G loss: 0.565987]\n",
      "epoch:13 step:12412 [D loss: 0.534524, acc.: 70.31%] [G loss: 0.752663]\n",
      "epoch:13 step:12413 [D loss: 0.455000, acc.: 81.25%] [G loss: 0.797094]\n",
      "epoch:13 step:12414 [D loss: 0.555977, acc.: 69.53%] [G loss: 0.816479]\n",
      "epoch:13 step:12415 [D loss: 0.609981, acc.: 70.31%] [G loss: 0.564651]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12416 [D loss: 0.585533, acc.: 66.41%] [G loss: 0.526113]\n",
      "epoch:13 step:12417 [D loss: 0.545234, acc.: 73.44%] [G loss: 0.626813]\n",
      "epoch:13 step:12418 [D loss: 0.551611, acc.: 64.84%] [G loss: 0.443058]\n",
      "epoch:13 step:12419 [D loss: 0.566514, acc.: 68.75%] [G loss: 0.588419]\n",
      "epoch:13 step:12420 [D loss: 0.526775, acc.: 72.66%] [G loss: 0.572811]\n",
      "epoch:13 step:12421 [D loss: 0.599966, acc.: 65.62%] [G loss: 0.535069]\n",
      "epoch:13 step:12422 [D loss: 0.518056, acc.: 76.56%] [G loss: 0.642932]\n",
      "epoch:13 step:12423 [D loss: 0.562876, acc.: 68.75%] [G loss: 0.649239]\n",
      "epoch:13 step:12424 [D loss: 0.545607, acc.: 65.62%] [G loss: 0.737219]\n",
      "epoch:13 step:12425 [D loss: 0.515298, acc.: 69.53%] [G loss: 0.916531]\n",
      "epoch:13 step:12426 [D loss: 0.513957, acc.: 76.56%] [G loss: 0.714241]\n",
      "epoch:13 step:12427 [D loss: 0.476461, acc.: 78.91%] [G loss: 0.749586]\n",
      "epoch:13 step:12428 [D loss: 0.530651, acc.: 72.66%] [G loss: 0.765096]\n",
      "epoch:13 step:12429 [D loss: 0.545056, acc.: 71.88%] [G loss: 0.675697]\n",
      "epoch:13 step:12430 [D loss: 0.559692, acc.: 67.97%] [G loss: 0.812885]\n",
      "epoch:13 step:12431 [D loss: 0.649049, acc.: 64.06%] [G loss: 0.614205]\n",
      "epoch:13 step:12432 [D loss: 0.629198, acc.: 58.59%] [G loss: 0.570984]\n",
      "epoch:13 step:12433 [D loss: 0.582174, acc.: 67.97%] [G loss: 0.649492]\n",
      "epoch:13 step:12434 [D loss: 0.602694, acc.: 71.88%] [G loss: 0.545535]\n",
      "epoch:13 step:12435 [D loss: 0.500746, acc.: 70.31%] [G loss: 0.678341]\n",
      "epoch:13 step:12436 [D loss: 0.488599, acc.: 80.47%] [G loss: 0.509511]\n",
      "epoch:13 step:12437 [D loss: 0.516290, acc.: 71.09%] [G loss: 0.530686]\n",
      "epoch:13 step:12438 [D loss: 0.558216, acc.: 64.06%] [G loss: 0.503657]\n",
      "epoch:13 step:12439 [D loss: 0.528317, acc.: 69.53%] [G loss: 0.488052]\n",
      "epoch:13 step:12440 [D loss: 0.531811, acc.: 68.75%] [G loss: 0.541623]\n",
      "epoch:13 step:12441 [D loss: 0.579262, acc.: 67.97%] [G loss: 0.605766]\n",
      "epoch:13 step:12442 [D loss: 0.492601, acc.: 76.56%] [G loss: 0.576764]\n",
      "epoch:13 step:12443 [D loss: 0.559173, acc.: 70.31%] [G loss: 0.475544]\n",
      "epoch:13 step:12444 [D loss: 0.602050, acc.: 64.84%] [G loss: 0.589659]\n",
      "epoch:13 step:12445 [D loss: 0.530774, acc.: 75.00%] [G loss: 0.653476]\n",
      "epoch:13 step:12446 [D loss: 0.539369, acc.: 70.31%] [G loss: 0.625319]\n",
      "epoch:13 step:12447 [D loss: 0.511398, acc.: 75.78%] [G loss: 0.588494]\n",
      "epoch:13 step:12448 [D loss: 0.546001, acc.: 67.97%] [G loss: 0.608231]\n",
      "epoch:13 step:12449 [D loss: 0.565235, acc.: 64.84%] [G loss: 0.571985]\n",
      "epoch:13 step:12450 [D loss: 0.538788, acc.: 74.22%] [G loss: 0.624394]\n",
      "epoch:13 step:12451 [D loss: 0.530904, acc.: 67.97%] [G loss: 0.774177]\n",
      "epoch:13 step:12452 [D loss: 0.540275, acc.: 76.56%] [G loss: 0.707461]\n",
      "epoch:13 step:12453 [D loss: 0.552238, acc.: 67.19%] [G loss: 0.735657]\n",
      "epoch:13 step:12454 [D loss: 0.503870, acc.: 71.09%] [G loss: 0.542801]\n",
      "epoch:13 step:12455 [D loss: 0.567384, acc.: 71.09%] [G loss: 0.603938]\n",
      "epoch:13 step:12456 [D loss: 0.611714, acc.: 68.75%] [G loss: 0.559626]\n",
      "epoch:13 step:12457 [D loss: 0.503675, acc.: 75.78%] [G loss: 0.665182]\n",
      "epoch:13 step:12458 [D loss: 0.680714, acc.: 58.59%] [G loss: 0.518248]\n",
      "epoch:13 step:12459 [D loss: 0.655353, acc.: 58.59%] [G loss: 0.400816]\n",
      "epoch:13 step:12460 [D loss: 0.504349, acc.: 72.66%] [G loss: 0.562401]\n",
      "epoch:13 step:12461 [D loss: 0.536694, acc.: 72.66%] [G loss: 0.520821]\n",
      "epoch:13 step:12462 [D loss: 0.575254, acc.: 64.84%] [G loss: 0.504647]\n",
      "epoch:13 step:12463 [D loss: 0.520775, acc.: 72.66%] [G loss: 0.581049]\n",
      "epoch:13 step:12464 [D loss: 0.514672, acc.: 76.56%] [G loss: 0.499616]\n",
      "epoch:13 step:12465 [D loss: 0.528394, acc.: 71.88%] [G loss: 0.504533]\n",
      "epoch:13 step:12466 [D loss: 0.495351, acc.: 73.44%] [G loss: 0.615561]\n",
      "epoch:13 step:12467 [D loss: 0.516118, acc.: 70.31%] [G loss: 0.556536]\n",
      "epoch:13 step:12468 [D loss: 0.608590, acc.: 62.50%] [G loss: 0.673562]\n",
      "epoch:13 step:12469 [D loss: 0.602738, acc.: 64.06%] [G loss: 0.572435]\n",
      "epoch:13 step:12470 [D loss: 0.563248, acc.: 63.28%] [G loss: 0.645329]\n",
      "epoch:13 step:12471 [D loss: 0.595522, acc.: 59.38%] [G loss: 0.505205]\n",
      "epoch:13 step:12472 [D loss: 0.569869, acc.: 74.22%] [G loss: 0.495101]\n",
      "epoch:13 step:12473 [D loss: 0.578504, acc.: 67.19%] [G loss: 0.603461]\n",
      "epoch:13 step:12474 [D loss: 0.568906, acc.: 65.62%] [G loss: 0.599580]\n",
      "epoch:13 step:12475 [D loss: 0.568578, acc.: 67.19%] [G loss: 0.457062]\n",
      "epoch:13 step:12476 [D loss: 0.561680, acc.: 64.06%] [G loss: 0.516788]\n",
      "epoch:13 step:12477 [D loss: 0.463875, acc.: 78.12%] [G loss: 0.592005]\n",
      "epoch:13 step:12478 [D loss: 0.535393, acc.: 72.66%] [G loss: 0.552074]\n",
      "epoch:13 step:12479 [D loss: 0.497338, acc.: 75.00%] [G loss: 0.625689]\n",
      "epoch:13 step:12480 [D loss: 0.461268, acc.: 81.25%] [G loss: 0.558014]\n",
      "epoch:13 step:12481 [D loss: 0.531094, acc.: 73.44%] [G loss: 0.663125]\n",
      "epoch:13 step:12482 [D loss: 0.628548, acc.: 65.62%] [G loss: 0.478214]\n",
      "epoch:13 step:12483 [D loss: 0.538774, acc.: 66.41%] [G loss: 0.680156]\n",
      "epoch:13 step:12484 [D loss: 0.536014, acc.: 73.44%] [G loss: 0.603698]\n",
      "epoch:13 step:12485 [D loss: 0.485218, acc.: 73.44%] [G loss: 0.679173]\n",
      "epoch:13 step:12486 [D loss: 0.542092, acc.: 71.09%] [G loss: 0.628701]\n",
      "epoch:13 step:12487 [D loss: 0.557767, acc.: 70.31%] [G loss: 0.554932]\n",
      "epoch:13 step:12488 [D loss: 0.502306, acc.: 76.56%] [G loss: 0.556194]\n",
      "epoch:13 step:12489 [D loss: 0.571105, acc.: 64.84%] [G loss: 0.679522]\n",
      "epoch:13 step:12490 [D loss: 0.500906, acc.: 73.44%] [G loss: 0.600301]\n",
      "epoch:13 step:12491 [D loss: 0.534708, acc.: 71.09%] [G loss: 0.650021]\n",
      "epoch:13 step:12492 [D loss: 0.477221, acc.: 75.00%] [G loss: 0.629685]\n",
      "epoch:13 step:12493 [D loss: 0.548944, acc.: 68.75%] [G loss: 0.710463]\n",
      "epoch:13 step:12494 [D loss: 0.485160, acc.: 79.69%] [G loss: 0.848575]\n",
      "epoch:13 step:12495 [D loss: 0.488095, acc.: 76.56%] [G loss: 0.858464]\n",
      "epoch:13 step:12496 [D loss: 0.425858, acc.: 85.16%] [G loss: 1.013629]\n",
      "epoch:13 step:12497 [D loss: 0.701888, acc.: 62.50%] [G loss: 0.511603]\n",
      "epoch:13 step:12498 [D loss: 0.633969, acc.: 64.84%] [G loss: 0.687099]\n",
      "epoch:13 step:12499 [D loss: 0.523786, acc.: 69.53%] [G loss: 0.608756]\n",
      "epoch:13 step:12500 [D loss: 0.553839, acc.: 68.75%] [G loss: 0.615241]\n",
      "epoch:13 step:12501 [D loss: 0.518733, acc.: 71.88%] [G loss: 0.547012]\n",
      "epoch:13 step:12502 [D loss: 0.489745, acc.: 72.66%] [G loss: 0.628486]\n",
      "epoch:13 step:12503 [D loss: 0.592650, acc.: 64.06%] [G loss: 0.585705]\n",
      "epoch:13 step:12504 [D loss: 0.592816, acc.: 66.41%] [G loss: 0.528822]\n",
      "epoch:13 step:12505 [D loss: 0.557799, acc.: 67.97%] [G loss: 0.441199]\n",
      "epoch:13 step:12506 [D loss: 0.554933, acc.: 70.31%] [G loss: 0.505235]\n",
      "epoch:13 step:12507 [D loss: 0.471130, acc.: 76.56%] [G loss: 0.596013]\n",
      "epoch:13 step:12508 [D loss: 0.524109, acc.: 76.56%] [G loss: 0.729328]\n",
      "epoch:13 step:12509 [D loss: 0.457367, acc.: 80.47%] [G loss: 0.697664]\n",
      "epoch:13 step:12510 [D loss: 0.516656, acc.: 72.66%] [G loss: 0.792031]\n",
      "epoch:13 step:12511 [D loss: 0.610850, acc.: 64.06%] [G loss: 0.584198]\n",
      "epoch:13 step:12512 [D loss: 0.547941, acc.: 68.75%] [G loss: 0.586973]\n",
      "epoch:13 step:12513 [D loss: 0.516385, acc.: 71.88%] [G loss: 0.660182]\n",
      "epoch:13 step:12514 [D loss: 0.476812, acc.: 74.22%] [G loss: 0.631182]\n",
      "epoch:13 step:12515 [D loss: 0.495174, acc.: 74.22%] [G loss: 0.716466]\n",
      "epoch:13 step:12516 [D loss: 0.484035, acc.: 71.88%] [G loss: 0.634202]\n",
      "epoch:13 step:12517 [D loss: 0.490346, acc.: 75.78%] [G loss: 0.731514]\n",
      "epoch:13 step:12518 [D loss: 0.542998, acc.: 74.22%] [G loss: 0.645993]\n",
      "epoch:13 step:12519 [D loss: 0.557934, acc.: 69.53%] [G loss: 0.582751]\n",
      "epoch:13 step:12520 [D loss: 0.547480, acc.: 65.62%] [G loss: 0.548015]\n",
      "epoch:13 step:12521 [D loss: 0.461565, acc.: 78.12%] [G loss: 0.747403]\n",
      "epoch:13 step:12522 [D loss: 0.606673, acc.: 62.50%] [G loss: 0.657069]\n",
      "epoch:13 step:12523 [D loss: 0.654804, acc.: 61.72%] [G loss: 0.707966]\n",
      "epoch:13 step:12524 [D loss: 0.534889, acc.: 69.53%] [G loss: 0.696705]\n",
      "epoch:13 step:12525 [D loss: 0.488576, acc.: 75.78%] [G loss: 0.658976]\n",
      "epoch:13 step:12526 [D loss: 0.554475, acc.: 66.41%] [G loss: 0.699844]\n",
      "epoch:13 step:12527 [D loss: 0.534518, acc.: 71.09%] [G loss: 0.673806]\n",
      "epoch:13 step:12528 [D loss: 0.451955, acc.: 82.03%] [G loss: 0.936733]\n",
      "epoch:13 step:12529 [D loss: 0.663598, acc.: 67.19%] [G loss: 0.753405]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12530 [D loss: 0.720565, acc.: 57.03%] [G loss: 0.442234]\n",
      "epoch:13 step:12531 [D loss: 0.467108, acc.: 79.69%] [G loss: 0.700576]\n",
      "epoch:13 step:12532 [D loss: 0.562708, acc.: 67.97%] [G loss: 0.649704]\n",
      "epoch:13 step:12533 [D loss: 0.603680, acc.: 64.84%] [G loss: 0.602233]\n",
      "epoch:13 step:12534 [D loss: 0.608462, acc.: 63.28%] [G loss: 0.606378]\n",
      "epoch:13 step:12535 [D loss: 0.398088, acc.: 85.16%] [G loss: 0.690413]\n",
      "epoch:13 step:12536 [D loss: 0.566732, acc.: 72.66%] [G loss: 0.753928]\n",
      "epoch:13 step:12537 [D loss: 0.595237, acc.: 69.53%] [G loss: 0.529583]\n",
      "epoch:13 step:12538 [D loss: 0.450725, acc.: 79.69%] [G loss: 0.705131]\n",
      "epoch:13 step:12539 [D loss: 0.496310, acc.: 75.00%] [G loss: 0.638154]\n",
      "epoch:13 step:12540 [D loss: 0.502283, acc.: 75.78%] [G loss: 0.799471]\n",
      "epoch:13 step:12541 [D loss: 0.476684, acc.: 77.34%] [G loss: 0.790506]\n",
      "epoch:13 step:12542 [D loss: 0.489204, acc.: 78.12%] [G loss: 0.738873]\n",
      "epoch:13 step:12543 [D loss: 0.538085, acc.: 69.53%] [G loss: 0.632924]\n",
      "epoch:13 step:12544 [D loss: 0.575809, acc.: 67.19%] [G loss: 0.616441]\n",
      "epoch:13 step:12545 [D loss: 0.556539, acc.: 73.44%] [G loss: 0.618100]\n",
      "epoch:13 step:12546 [D loss: 0.549347, acc.: 68.75%] [G loss: 0.640841]\n",
      "epoch:13 step:12547 [D loss: 0.526961, acc.: 74.22%] [G loss: 0.631755]\n",
      "epoch:13 step:12548 [D loss: 0.543211, acc.: 67.97%] [G loss: 0.792283]\n",
      "epoch:13 step:12549 [D loss: 0.534507, acc.: 72.66%] [G loss: 0.587252]\n",
      "epoch:13 step:12550 [D loss: 0.596997, acc.: 68.75%] [G loss: 0.521084]\n",
      "epoch:13 step:12551 [D loss: 0.527353, acc.: 72.66%] [G loss: 0.561371]\n",
      "epoch:13 step:12552 [D loss: 0.540771, acc.: 73.44%] [G loss: 0.651552]\n",
      "epoch:13 step:12553 [D loss: 0.575278, acc.: 69.53%] [G loss: 0.579430]\n",
      "epoch:13 step:12554 [D loss: 0.551583, acc.: 67.97%] [G loss: 0.595256]\n",
      "epoch:13 step:12555 [D loss: 0.531630, acc.: 68.75%] [G loss: 0.586098]\n",
      "epoch:13 step:12556 [D loss: 0.539526, acc.: 73.44%] [G loss: 0.659325]\n",
      "epoch:13 step:12557 [D loss: 0.699604, acc.: 58.59%] [G loss: 0.407342]\n",
      "epoch:13 step:12558 [D loss: 0.584596, acc.: 64.06%] [G loss: 0.454370]\n",
      "epoch:13 step:12559 [D loss: 0.580201, acc.: 67.97%] [G loss: 0.691389]\n",
      "epoch:13 step:12560 [D loss: 0.591264, acc.: 69.53%] [G loss: 0.561940]\n",
      "epoch:13 step:12561 [D loss: 0.594298, acc.: 69.53%] [G loss: 0.505522]\n",
      "epoch:13 step:12562 [D loss: 0.476049, acc.: 80.47%] [G loss: 0.524289]\n",
      "epoch:13 step:12563 [D loss: 0.590459, acc.: 65.62%] [G loss: 0.473800]\n",
      "epoch:13 step:12564 [D loss: 0.548229, acc.: 67.97%] [G loss: 0.656097]\n",
      "epoch:13 step:12565 [D loss: 0.552862, acc.: 71.09%] [G loss: 0.603137]\n",
      "epoch:13 step:12566 [D loss: 0.513043, acc.: 71.88%] [G loss: 0.520922]\n",
      "epoch:13 step:12567 [D loss: 0.613684, acc.: 65.62%] [G loss: 0.492562]\n",
      "epoch:13 step:12568 [D loss: 0.559324, acc.: 66.41%] [G loss: 0.551320]\n",
      "epoch:13 step:12569 [D loss: 0.532929, acc.: 70.31%] [G loss: 0.626939]\n",
      "epoch:13 step:12570 [D loss: 0.584837, acc.: 65.62%] [G loss: 0.561220]\n",
      "epoch:13 step:12571 [D loss: 0.504495, acc.: 78.12%] [G loss: 0.717601]\n",
      "epoch:13 step:12572 [D loss: 0.611115, acc.: 65.62%] [G loss: 0.699512]\n",
      "epoch:13 step:12573 [D loss: 0.498278, acc.: 78.12%] [G loss: 0.627790]\n",
      "epoch:13 step:12574 [D loss: 0.588538, acc.: 64.84%] [G loss: 0.461561]\n",
      "epoch:13 step:12575 [D loss: 0.601045, acc.: 67.19%] [G loss: 0.450774]\n",
      "epoch:13 step:12576 [D loss: 0.518350, acc.: 71.88%] [G loss: 0.581010]\n",
      "epoch:13 step:12577 [D loss: 0.591357, acc.: 65.62%] [G loss: 0.581329]\n",
      "epoch:13 step:12578 [D loss: 0.563373, acc.: 67.19%] [G loss: 0.634307]\n",
      "epoch:13 step:12579 [D loss: 0.510087, acc.: 72.66%] [G loss: 0.681993]\n",
      "epoch:13 step:12580 [D loss: 0.515778, acc.: 77.34%] [G loss: 0.810870]\n",
      "epoch:13 step:12581 [D loss: 0.643029, acc.: 59.38%] [G loss: 0.591861]\n",
      "epoch:13 step:12582 [D loss: 0.656806, acc.: 60.94%] [G loss: 0.423881]\n",
      "epoch:13 step:12583 [D loss: 0.565892, acc.: 65.62%] [G loss: 0.456696]\n",
      "epoch:13 step:12584 [D loss: 0.495334, acc.: 76.56%] [G loss: 0.669665]\n",
      "epoch:13 step:12585 [D loss: 0.582601, acc.: 67.97%] [G loss: 0.526443]\n",
      "epoch:13 step:12586 [D loss: 0.579034, acc.: 73.44%] [G loss: 0.570264]\n",
      "epoch:13 step:12587 [D loss: 0.473268, acc.: 75.78%] [G loss: 0.746600]\n",
      "epoch:13 step:12588 [D loss: 0.611126, acc.: 65.62%] [G loss: 0.609907]\n",
      "epoch:13 step:12589 [D loss: 0.603511, acc.: 62.50%] [G loss: 0.711426]\n",
      "epoch:13 step:12590 [D loss: 0.565130, acc.: 65.62%] [G loss: 0.663026]\n",
      "epoch:13 step:12591 [D loss: 0.551393, acc.: 71.09%] [G loss: 0.705548]\n",
      "epoch:13 step:12592 [D loss: 0.635107, acc.: 60.16%] [G loss: 0.480091]\n",
      "epoch:13 step:12593 [D loss: 0.563288, acc.: 67.19%] [G loss: 0.467700]\n",
      "epoch:13 step:12594 [D loss: 0.531522, acc.: 72.66%] [G loss: 0.590626]\n",
      "epoch:13 step:12595 [D loss: 0.557200, acc.: 70.31%] [G loss: 0.590316]\n",
      "epoch:13 step:12596 [D loss: 0.524393, acc.: 72.66%] [G loss: 0.502670]\n",
      "epoch:13 step:12597 [D loss: 0.468989, acc.: 82.03%] [G loss: 0.640609]\n",
      "epoch:13 step:12598 [D loss: 0.575013, acc.: 67.97%] [G loss: 0.566372]\n",
      "epoch:13 step:12599 [D loss: 0.650926, acc.: 64.06%] [G loss: 0.550736]\n",
      "epoch:13 step:12600 [D loss: 0.592323, acc.: 67.97%] [G loss: 0.494437]\n",
      "##############\n",
      "[3.29393286 1.06470862 6.25604459 4.89934805 3.95155797 5.6510465\n",
      " 4.47388925 4.73421696 4.57157877 4.09972332]\n",
      "##########\n",
      "epoch:13 step:12601 [D loss: 0.595342, acc.: 61.72%] [G loss: 0.556393]\n",
      "epoch:13 step:12602 [D loss: 0.559825, acc.: 70.31%] [G loss: 0.503944]\n",
      "epoch:13 step:12603 [D loss: 0.594288, acc.: 67.19%] [G loss: 0.480305]\n",
      "epoch:13 step:12604 [D loss: 0.554159, acc.: 74.22%] [G loss: 0.562213]\n",
      "epoch:13 step:12605 [D loss: 0.550376, acc.: 67.19%] [G loss: 0.592245]\n",
      "epoch:13 step:12606 [D loss: 0.530306, acc.: 78.12%] [G loss: 0.522065]\n",
      "epoch:13 step:12607 [D loss: 0.508687, acc.: 74.22%] [G loss: 0.662915]\n",
      "epoch:13 step:12608 [D loss: 0.470846, acc.: 75.78%] [G loss: 0.875650]\n",
      "epoch:13 step:12609 [D loss: 0.535551, acc.: 70.31%] [G loss: 0.734946]\n",
      "epoch:13 step:12610 [D loss: 0.506905, acc.: 75.78%] [G loss: 0.712784]\n",
      "epoch:13 step:12611 [D loss: 0.556064, acc.: 67.97%] [G loss: 0.787685]\n",
      "epoch:13 step:12612 [D loss: 0.523620, acc.: 73.44%] [G loss: 0.615095]\n",
      "epoch:13 step:12613 [D loss: 0.590738, acc.: 62.50%] [G loss: 0.519569]\n",
      "epoch:13 step:12614 [D loss: 0.580276, acc.: 66.41%] [G loss: 0.513097]\n",
      "epoch:13 step:12615 [D loss: 0.546980, acc.: 70.31%] [G loss: 0.672689]\n",
      "epoch:13 step:12616 [D loss: 0.513717, acc.: 75.00%] [G loss: 0.695709]\n",
      "epoch:13 step:12617 [D loss: 0.494186, acc.: 77.34%] [G loss: 0.690708]\n",
      "epoch:13 step:12618 [D loss: 0.707473, acc.: 59.38%] [G loss: 0.543603]\n",
      "epoch:13 step:12619 [D loss: 0.572203, acc.: 68.75%] [G loss: 0.452931]\n",
      "epoch:13 step:12620 [D loss: 0.513726, acc.: 75.00%] [G loss: 0.461787]\n",
      "epoch:13 step:12621 [D loss: 0.486515, acc.: 70.31%] [G loss: 0.730866]\n",
      "epoch:13 step:12622 [D loss: 0.560308, acc.: 67.19%] [G loss: 0.681221]\n",
      "epoch:13 step:12623 [D loss: 0.559564, acc.: 69.53%] [G loss: 0.640822]\n",
      "epoch:13 step:12624 [D loss: 0.507508, acc.: 72.66%] [G loss: 0.613529]\n",
      "epoch:13 step:12625 [D loss: 0.505863, acc.: 74.22%] [G loss: 0.673371]\n",
      "epoch:13 step:12626 [D loss: 0.564564, acc.: 68.75%] [G loss: 0.603485]\n",
      "epoch:13 step:12627 [D loss: 0.543038, acc.: 73.44%] [G loss: 0.697978]\n",
      "epoch:13 step:12628 [D loss: 0.574550, acc.: 67.97%] [G loss: 0.814831]\n",
      "epoch:13 step:12629 [D loss: 0.599657, acc.: 69.53%] [G loss: 0.825126]\n",
      "epoch:13 step:12630 [D loss: 0.492198, acc.: 73.44%] [G loss: 0.686828]\n",
      "epoch:13 step:12631 [D loss: 0.510323, acc.: 74.22%] [G loss: 0.688124]\n",
      "epoch:13 step:12632 [D loss: 0.428555, acc.: 81.25%] [G loss: 0.757741]\n",
      "epoch:13 step:12633 [D loss: 0.477829, acc.: 78.12%] [G loss: 0.876112]\n",
      "epoch:13 step:12634 [D loss: 0.563788, acc.: 68.75%] [G loss: 0.671593]\n",
      "epoch:13 step:12635 [D loss: 0.634924, acc.: 64.84%] [G loss: 0.602047]\n",
      "epoch:13 step:12636 [D loss: 0.513275, acc.: 75.00%] [G loss: 0.630819]\n",
      "epoch:13 step:12637 [D loss: 0.666196, acc.: 59.38%] [G loss: 0.567719]\n",
      "epoch:13 step:12638 [D loss: 0.482481, acc.: 78.91%] [G loss: 0.670526]\n",
      "epoch:13 step:12639 [D loss: 0.651869, acc.: 64.84%] [G loss: 0.600855]\n",
      "epoch:13 step:12640 [D loss: 0.564861, acc.: 69.53%] [G loss: 0.560203]\n",
      "epoch:13 step:12641 [D loss: 0.542655, acc.: 69.53%] [G loss: 0.583655]\n",
      "epoch:13 step:12642 [D loss: 0.502472, acc.: 77.34%] [G loss: 0.612191]\n",
      "epoch:13 step:12643 [D loss: 0.599071, acc.: 60.94%] [G loss: 0.647663]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12644 [D loss: 0.577937, acc.: 69.53%] [G loss: 0.466494]\n",
      "epoch:13 step:12645 [D loss: 0.518852, acc.: 73.44%] [G loss: 0.685102]\n",
      "epoch:13 step:12646 [D loss: 0.596165, acc.: 61.72%] [G loss: 0.501294]\n",
      "epoch:13 step:12647 [D loss: 0.610234, acc.: 63.28%] [G loss: 0.439364]\n",
      "epoch:13 step:12648 [D loss: 0.576536, acc.: 60.16%] [G loss: 0.641034]\n",
      "epoch:13 step:12649 [D loss: 0.536644, acc.: 72.66%] [G loss: 0.643515]\n",
      "epoch:13 step:12650 [D loss: 0.600758, acc.: 69.53%] [G loss: 0.815195]\n",
      "epoch:13 step:12651 [D loss: 0.541991, acc.: 70.31%] [G loss: 0.686527]\n",
      "epoch:13 step:12652 [D loss: 0.449880, acc.: 80.47%] [G loss: 0.775113]\n",
      "epoch:13 step:12653 [D loss: 0.497670, acc.: 82.81%] [G loss: 0.839491]\n",
      "epoch:13 step:12654 [D loss: 0.654875, acc.: 59.38%] [G loss: 0.699112]\n",
      "epoch:13 step:12655 [D loss: 0.575601, acc.: 64.84%] [G loss: 0.502206]\n",
      "epoch:13 step:12656 [D loss: 0.468344, acc.: 75.78%] [G loss: 0.798042]\n",
      "epoch:13 step:12657 [D loss: 0.538406, acc.: 76.56%] [G loss: 0.796860]\n",
      "epoch:13 step:12658 [D loss: 0.671148, acc.: 59.38%] [G loss: 0.430915]\n",
      "epoch:13 step:12659 [D loss: 0.547500, acc.: 71.09%] [G loss: 0.534681]\n",
      "epoch:13 step:12660 [D loss: 0.480289, acc.: 78.12%] [G loss: 0.599855]\n",
      "epoch:13 step:12661 [D loss: 0.620201, acc.: 64.06%] [G loss: 0.468201]\n",
      "epoch:13 step:12662 [D loss: 0.466607, acc.: 82.81%] [G loss: 0.741325]\n",
      "epoch:13 step:12663 [D loss: 0.601061, acc.: 64.06%] [G loss: 0.469062]\n",
      "epoch:13 step:12664 [D loss: 0.583370, acc.: 67.97%] [G loss: 0.645722]\n",
      "epoch:13 step:12665 [D loss: 0.487390, acc.: 72.66%] [G loss: 0.715081]\n",
      "epoch:13 step:12666 [D loss: 0.523018, acc.: 72.66%] [G loss: 0.583693]\n",
      "epoch:13 step:12667 [D loss: 0.535136, acc.: 74.22%] [G loss: 0.608952]\n",
      "epoch:13 step:12668 [D loss: 0.572423, acc.: 65.62%] [G loss: 0.591040]\n",
      "epoch:13 step:12669 [D loss: 0.511915, acc.: 73.44%] [G loss: 0.562166]\n",
      "epoch:13 step:12670 [D loss: 0.515265, acc.: 71.09%] [G loss: 0.630897]\n",
      "epoch:13 step:12671 [D loss: 0.502115, acc.: 78.91%] [G loss: 0.606320]\n",
      "epoch:13 step:12672 [D loss: 0.569699, acc.: 71.88%] [G loss: 0.691133]\n",
      "epoch:13 step:12673 [D loss: 0.582787, acc.: 65.62%] [G loss: 0.724007]\n",
      "epoch:13 step:12674 [D loss: 0.575849, acc.: 67.19%] [G loss: 0.601535]\n",
      "epoch:13 step:12675 [D loss: 0.579345, acc.: 67.97%] [G loss: 0.563214]\n",
      "epoch:13 step:12676 [D loss: 0.551340, acc.: 73.44%] [G loss: 0.548655]\n",
      "epoch:13 step:12677 [D loss: 0.555774, acc.: 71.88%] [G loss: 0.603465]\n",
      "epoch:13 step:12678 [D loss: 0.610550, acc.: 67.97%] [G loss: 0.460563]\n",
      "epoch:13 step:12679 [D loss: 0.560430, acc.: 70.31%] [G loss: 0.660784]\n",
      "epoch:13 step:12680 [D loss: 0.520603, acc.: 71.09%] [G loss: 0.931740]\n",
      "epoch:13 step:12681 [D loss: 0.592296, acc.: 67.19%] [G loss: 0.696078]\n",
      "epoch:13 step:12682 [D loss: 0.637118, acc.: 65.62%] [G loss: 0.534398]\n",
      "epoch:13 step:12683 [D loss: 0.637352, acc.: 56.25%] [G loss: 0.531594]\n",
      "epoch:13 step:12684 [D loss: 0.513282, acc.: 78.12%] [G loss: 0.697600]\n",
      "epoch:13 step:12685 [D loss: 0.494463, acc.: 72.66%] [G loss: 0.718710]\n",
      "epoch:13 step:12686 [D loss: 0.551277, acc.: 76.56%] [G loss: 0.769076]\n",
      "epoch:13 step:12687 [D loss: 0.485254, acc.: 75.78%] [G loss: 0.740190]\n",
      "epoch:13 step:12688 [D loss: 0.565777, acc.: 70.31%] [G loss: 0.825868]\n",
      "epoch:13 step:12689 [D loss: 0.397695, acc.: 86.72%] [G loss: 0.817507]\n",
      "epoch:13 step:12690 [D loss: 0.536462, acc.: 72.66%] [G loss: 0.895813]\n",
      "epoch:13 step:12691 [D loss: 0.609081, acc.: 69.53%] [G loss: 0.746727]\n",
      "epoch:13 step:12692 [D loss: 0.637659, acc.: 59.38%] [G loss: 0.478398]\n",
      "epoch:13 step:12693 [D loss: 0.607697, acc.: 57.81%] [G loss: 0.465248]\n",
      "epoch:13 step:12694 [D loss: 0.533439, acc.: 71.88%] [G loss: 0.443357]\n",
      "epoch:13 step:12695 [D loss: 0.512097, acc.: 73.44%] [G loss: 0.630187]\n",
      "epoch:13 step:12696 [D loss: 0.496366, acc.: 75.78%] [G loss: 0.737076]\n",
      "epoch:13 step:12697 [D loss: 0.516966, acc.: 75.78%] [G loss: 0.599230]\n",
      "epoch:13 step:12698 [D loss: 0.519636, acc.: 72.66%] [G loss: 0.733863]\n",
      "epoch:13 step:12699 [D loss: 0.589537, acc.: 70.31%] [G loss: 0.554334]\n",
      "epoch:13 step:12700 [D loss: 0.445719, acc.: 81.25%] [G loss: 0.665404]\n",
      "epoch:13 step:12701 [D loss: 0.526860, acc.: 71.09%] [G loss: 0.733163]\n",
      "epoch:13 step:12702 [D loss: 0.542867, acc.: 71.88%] [G loss: 0.685407]\n",
      "epoch:13 step:12703 [D loss: 0.498896, acc.: 79.69%] [G loss: 0.660481]\n",
      "epoch:13 step:12704 [D loss: 0.548739, acc.: 73.44%] [G loss: 0.554534]\n",
      "epoch:13 step:12705 [D loss: 0.580093, acc.: 67.19%] [G loss: 0.536268]\n",
      "epoch:13 step:12706 [D loss: 0.568450, acc.: 69.53%] [G loss: 0.504615]\n",
      "epoch:13 step:12707 [D loss: 0.546448, acc.: 69.53%] [G loss: 0.595617]\n",
      "epoch:13 step:12708 [D loss: 0.562777, acc.: 63.28%] [G loss: 0.540304]\n",
      "epoch:13 step:12709 [D loss: 0.678966, acc.: 59.38%] [G loss: 0.522301]\n",
      "epoch:13 step:12710 [D loss: 0.591861, acc.: 64.06%] [G loss: 0.550843]\n",
      "epoch:13 step:12711 [D loss: 0.569461, acc.: 67.97%] [G loss: 0.638629]\n",
      "epoch:13 step:12712 [D loss: 0.522425, acc.: 70.31%] [G loss: 0.646270]\n",
      "epoch:13 step:12713 [D loss: 0.508079, acc.: 73.44%] [G loss: 0.488506]\n",
      "epoch:13 step:12714 [D loss: 0.502543, acc.: 74.22%] [G loss: 0.717198]\n",
      "epoch:13 step:12715 [D loss: 0.493348, acc.: 75.00%] [G loss: 0.650124]\n",
      "epoch:13 step:12716 [D loss: 0.645261, acc.: 60.94%] [G loss: 0.482310]\n",
      "epoch:13 step:12717 [D loss: 0.511893, acc.: 71.88%] [G loss: 0.532082]\n",
      "epoch:13 step:12718 [D loss: 0.573960, acc.: 68.75%] [G loss: 0.526677]\n",
      "epoch:13 step:12719 [D loss: 0.531071, acc.: 68.75%] [G loss: 0.562326]\n",
      "epoch:13 step:12720 [D loss: 0.494117, acc.: 78.12%] [G loss: 0.647586]\n",
      "epoch:13 step:12721 [D loss: 0.549281, acc.: 71.09%] [G loss: 0.556244]\n",
      "epoch:13 step:12722 [D loss: 0.531664, acc.: 71.88%] [G loss: 0.620752]\n",
      "epoch:13 step:12723 [D loss: 0.577860, acc.: 71.88%] [G loss: 0.565133]\n",
      "epoch:13 step:12724 [D loss: 0.624776, acc.: 64.06%] [G loss: 0.513856]\n",
      "epoch:13 step:12725 [D loss: 0.594118, acc.: 64.06%] [G loss: 0.528363]\n",
      "epoch:13 step:12726 [D loss: 0.565306, acc.: 69.53%] [G loss: 0.466064]\n",
      "epoch:13 step:12727 [D loss: 0.519501, acc.: 75.00%] [G loss: 0.776747]\n",
      "epoch:13 step:12728 [D loss: 0.581271, acc.: 67.97%] [G loss: 0.588807]\n",
      "epoch:13 step:12729 [D loss: 0.507242, acc.: 74.22%] [G loss: 0.654431]\n",
      "epoch:13 step:12730 [D loss: 0.517002, acc.: 72.66%] [G loss: 0.637217]\n",
      "epoch:13 step:12731 [D loss: 0.523769, acc.: 71.88%] [G loss: 0.547679]\n",
      "epoch:13 step:12732 [D loss: 0.456808, acc.: 82.03%] [G loss: 0.659470]\n",
      "epoch:13 step:12733 [D loss: 0.488920, acc.: 78.91%] [G loss: 0.572217]\n",
      "epoch:13 step:12734 [D loss: 0.617690, acc.: 64.06%] [G loss: 0.475297]\n",
      "epoch:13 step:12735 [D loss: 0.456655, acc.: 78.12%] [G loss: 0.677818]\n",
      "epoch:13 step:12736 [D loss: 0.459373, acc.: 76.56%] [G loss: 0.737657]\n",
      "epoch:13 step:12737 [D loss: 0.549225, acc.: 70.31%] [G loss: 0.697613]\n",
      "epoch:13 step:12738 [D loss: 0.523727, acc.: 73.44%] [G loss: 0.524560]\n",
      "epoch:13 step:12739 [D loss: 0.468980, acc.: 80.47%] [G loss: 0.783114]\n",
      "epoch:13 step:12740 [D loss: 0.575007, acc.: 67.97%] [G loss: 0.642254]\n",
      "epoch:13 step:12741 [D loss: 0.526655, acc.: 71.09%] [G loss: 0.450927]\n",
      "epoch:13 step:12742 [D loss: 0.537077, acc.: 69.53%] [G loss: 0.552326]\n",
      "epoch:13 step:12743 [D loss: 0.576586, acc.: 66.41%] [G loss: 0.523082]\n",
      "epoch:13 step:12744 [D loss: 0.571836, acc.: 67.19%] [G loss: 0.429482]\n",
      "epoch:13 step:12745 [D loss: 0.478749, acc.: 75.00%] [G loss: 0.898320]\n",
      "epoch:13 step:12746 [D loss: 0.522986, acc.: 75.00%] [G loss: 0.622669]\n",
      "epoch:13 step:12747 [D loss: 0.695134, acc.: 61.72%] [G loss: 0.545418]\n",
      "epoch:13 step:12748 [D loss: 0.475219, acc.: 80.47%] [G loss: 0.662783]\n",
      "epoch:13 step:12749 [D loss: 0.495465, acc.: 71.88%] [G loss: 0.623085]\n",
      "epoch:13 step:12750 [D loss: 0.584516, acc.: 64.84%] [G loss: 0.613114]\n",
      "epoch:13 step:12751 [D loss: 0.510227, acc.: 73.44%] [G loss: 0.684740]\n",
      "epoch:13 step:12752 [D loss: 0.543296, acc.: 71.88%] [G loss: 0.626161]\n",
      "epoch:13 step:12753 [D loss: 0.548454, acc.: 69.53%] [G loss: 0.584981]\n",
      "epoch:13 step:12754 [D loss: 0.531501, acc.: 71.09%] [G loss: 0.717532]\n",
      "epoch:13 step:12755 [D loss: 0.499522, acc.: 77.34%] [G loss: 0.671701]\n",
      "epoch:13 step:12756 [D loss: 0.463198, acc.: 75.78%] [G loss: 0.842592]\n",
      "epoch:13 step:12757 [D loss: 0.571994, acc.: 67.97%] [G loss: 0.672574]\n",
      "epoch:13 step:12758 [D loss: 0.527741, acc.: 73.44%] [G loss: 0.601626]\n",
      "epoch:13 step:12759 [D loss: 0.576351, acc.: 67.97%] [G loss: 0.477167]\n",
      "epoch:13 step:12760 [D loss: 0.507308, acc.: 73.44%] [G loss: 0.675046]\n",
      "epoch:13 step:12761 [D loss: 0.537721, acc.: 74.22%] [G loss: 0.710489]\n",
      "epoch:13 step:12762 [D loss: 0.561110, acc.: 72.66%] [G loss: 0.599640]\n",
      "epoch:13 step:12763 [D loss: 0.482015, acc.: 78.91%] [G loss: 0.540968]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12764 [D loss: 0.541314, acc.: 74.22%] [G loss: 0.671965]\n",
      "epoch:13 step:12765 [D loss: 0.625864, acc.: 61.72%] [G loss: 0.486028]\n",
      "epoch:13 step:12766 [D loss: 0.551245, acc.: 71.88%] [G loss: 0.544991]\n",
      "epoch:13 step:12767 [D loss: 0.594936, acc.: 66.41%] [G loss: 0.620863]\n",
      "epoch:13 step:12768 [D loss: 0.595883, acc.: 66.41%] [G loss: 0.480172]\n",
      "epoch:13 step:12769 [D loss: 0.527521, acc.: 74.22%] [G loss: 0.677098]\n",
      "epoch:13 step:12770 [D loss: 0.463770, acc.: 77.34%] [G loss: 0.760762]\n",
      "epoch:13 step:12771 [D loss: 0.580456, acc.: 65.62%] [G loss: 0.569978]\n",
      "epoch:13 step:12772 [D loss: 0.619518, acc.: 64.84%] [G loss: 0.470984]\n",
      "epoch:13 step:12773 [D loss: 0.510965, acc.: 71.09%] [G loss: 0.544516]\n",
      "epoch:13 step:12774 [D loss: 0.519890, acc.: 75.00%] [G loss: 0.628236]\n",
      "epoch:13 step:12775 [D loss: 0.556866, acc.: 71.09%] [G loss: 0.481160]\n",
      "epoch:13 step:12776 [D loss: 0.572856, acc.: 71.09%] [G loss: 0.525364]\n",
      "epoch:13 step:12777 [D loss: 0.557222, acc.: 71.09%] [G loss: 0.508685]\n",
      "epoch:13 step:12778 [D loss: 0.555463, acc.: 71.88%] [G loss: 0.484884]\n",
      "epoch:13 step:12779 [D loss: 0.511601, acc.: 73.44%] [G loss: 0.640649]\n",
      "epoch:13 step:12780 [D loss: 0.473740, acc.: 76.56%] [G loss: 0.801727]\n",
      "epoch:13 step:12781 [D loss: 0.631721, acc.: 63.28%] [G loss: 0.627088]\n",
      "epoch:13 step:12782 [D loss: 0.569076, acc.: 66.41%] [G loss: 0.640540]\n",
      "epoch:13 step:12783 [D loss: 0.497698, acc.: 76.56%] [G loss: 0.516276]\n",
      "epoch:13 step:12784 [D loss: 0.533528, acc.: 67.97%] [G loss: 0.734639]\n",
      "epoch:13 step:12785 [D loss: 0.580279, acc.: 65.62%] [G loss: 0.615271]\n",
      "epoch:13 step:12786 [D loss: 0.483478, acc.: 75.78%] [G loss: 0.627702]\n",
      "epoch:13 step:12787 [D loss: 0.602746, acc.: 65.62%] [G loss: 0.660762]\n",
      "epoch:13 step:12788 [D loss: 0.581040, acc.: 64.06%] [G loss: 0.563189]\n",
      "epoch:13 step:12789 [D loss: 0.540991, acc.: 67.97%] [G loss: 0.537791]\n",
      "epoch:13 step:12790 [D loss: 0.551162, acc.: 66.41%] [G loss: 0.506215]\n",
      "epoch:13 step:12791 [D loss: 0.563027, acc.: 71.09%] [G loss: 0.552973]\n",
      "epoch:13 step:12792 [D loss: 0.446134, acc.: 79.69%] [G loss: 0.600913]\n",
      "epoch:13 step:12793 [D loss: 0.604946, acc.: 68.75%] [G loss: 0.454450]\n",
      "epoch:13 step:12794 [D loss: 0.494556, acc.: 73.44%] [G loss: 0.541876]\n",
      "epoch:13 step:12795 [D loss: 0.582845, acc.: 65.62%] [G loss: 0.529521]\n",
      "epoch:13 step:12796 [D loss: 0.603519, acc.: 66.41%] [G loss: 0.571264]\n",
      "epoch:13 step:12797 [D loss: 0.617530, acc.: 64.06%] [G loss: 0.631016]\n",
      "epoch:13 step:12798 [D loss: 0.564739, acc.: 64.84%] [G loss: 0.711386]\n",
      "epoch:13 step:12799 [D loss: 0.553764, acc.: 74.22%] [G loss: 0.685217]\n",
      "epoch:13 step:12800 [D loss: 0.537081, acc.: 72.66%] [G loss: 0.687989]\n",
      "##############\n",
      "[3.28084641 1.12034251 6.2328673  5.16606835 3.93156627 5.80068786\n",
      " 4.36800574 4.6582172  4.65242469 4.08467889]\n",
      "##########\n",
      "epoch:13 step:12801 [D loss: 0.502935, acc.: 75.00%] [G loss: 0.808392]\n",
      "epoch:13 step:12802 [D loss: 0.551733, acc.: 67.19%] [G loss: 0.633307]\n",
      "epoch:13 step:12803 [D loss: 0.552384, acc.: 71.09%] [G loss: 0.581213]\n",
      "epoch:13 step:12804 [D loss: 0.539520, acc.: 71.09%] [G loss: 0.718210]\n",
      "epoch:13 step:12805 [D loss: 0.452242, acc.: 80.47%] [G loss: 0.808915]\n",
      "epoch:13 step:12806 [D loss: 0.624672, acc.: 60.94%] [G loss: 0.649554]\n",
      "epoch:13 step:12807 [D loss: 0.559809, acc.: 69.53%] [G loss: 0.459647]\n",
      "epoch:13 step:12808 [D loss: 0.538968, acc.: 70.31%] [G loss: 0.538441]\n",
      "epoch:13 step:12809 [D loss: 0.555811, acc.: 70.31%] [G loss: 0.645373]\n",
      "epoch:13 step:12810 [D loss: 0.472969, acc.: 76.56%] [G loss: 0.526113]\n",
      "epoch:13 step:12811 [D loss: 0.581840, acc.: 68.75%] [G loss: 0.553241]\n",
      "epoch:13 step:12812 [D loss: 0.502371, acc.: 77.34%] [G loss: 0.610887]\n",
      "epoch:13 step:12813 [D loss: 0.511624, acc.: 75.78%] [G loss: 0.631917]\n",
      "epoch:13 step:12814 [D loss: 0.555761, acc.: 67.97%] [G loss: 0.740061]\n",
      "epoch:13 step:12815 [D loss: 0.516351, acc.: 78.12%] [G loss: 0.752119]\n",
      "epoch:13 step:12816 [D loss: 0.542556, acc.: 71.88%] [G loss: 0.726417]\n",
      "epoch:13 step:12817 [D loss: 0.612325, acc.: 65.62%] [G loss: 0.535954]\n",
      "epoch:13 step:12818 [D loss: 0.530609, acc.: 71.09%] [G loss: 0.659972]\n",
      "epoch:13 step:12819 [D loss: 0.483323, acc.: 79.69%] [G loss: 0.536592]\n",
      "epoch:13 step:12820 [D loss: 0.509041, acc.: 75.00%] [G loss: 0.593650]\n",
      "epoch:13 step:12821 [D loss: 0.561157, acc.: 71.09%] [G loss: 0.618491]\n",
      "epoch:13 step:12822 [D loss: 0.492251, acc.: 77.34%] [G loss: 0.677255]\n",
      "epoch:13 step:12823 [D loss: 0.499730, acc.: 76.56%] [G loss: 0.863231]\n",
      "epoch:13 step:12824 [D loss: 0.497030, acc.: 75.00%] [G loss: 0.751243]\n",
      "epoch:13 step:12825 [D loss: 0.587368, acc.: 67.19%] [G loss: 0.617514]\n",
      "epoch:13 step:12826 [D loss: 0.522028, acc.: 72.66%] [G loss: 0.603189]\n",
      "epoch:13 step:12827 [D loss: 0.603372, acc.: 59.38%] [G loss: 0.574450]\n",
      "epoch:13 step:12828 [D loss: 0.444648, acc.: 83.59%] [G loss: 0.543924]\n",
      "epoch:13 step:12829 [D loss: 0.465965, acc.: 78.12%] [G loss: 0.881063]\n",
      "epoch:13 step:12830 [D loss: 0.506238, acc.: 76.56%] [G loss: 0.843006]\n",
      "epoch:13 step:12831 [D loss: 0.526662, acc.: 73.44%] [G loss: 0.908264]\n",
      "epoch:13 step:12832 [D loss: 0.587430, acc.: 70.31%] [G loss: 0.722601]\n",
      "epoch:13 step:12833 [D loss: 0.629906, acc.: 63.28%] [G loss: 0.663837]\n",
      "epoch:13 step:12834 [D loss: 0.564010, acc.: 68.75%] [G loss: 0.467782]\n",
      "epoch:13 step:12835 [D loss: 0.503592, acc.: 75.78%] [G loss: 0.560218]\n",
      "epoch:13 step:12836 [D loss: 0.577695, acc.: 72.66%] [G loss: 0.580046]\n",
      "epoch:13 step:12837 [D loss: 0.563016, acc.: 71.88%] [G loss: 0.604730]\n",
      "epoch:13 step:12838 [D loss: 0.517517, acc.: 71.88%] [G loss: 0.671875]\n",
      "epoch:13 step:12839 [D loss: 0.610146, acc.: 64.84%] [G loss: 0.592182]\n",
      "epoch:13 step:12840 [D loss: 0.540724, acc.: 68.75%] [G loss: 0.682799]\n",
      "epoch:13 step:12841 [D loss: 0.533318, acc.: 71.09%] [G loss: 0.645023]\n",
      "epoch:13 step:12842 [D loss: 0.484939, acc.: 75.00%] [G loss: 0.685904]\n",
      "epoch:13 step:12843 [D loss: 0.528390, acc.: 71.09%] [G loss: 0.627549]\n",
      "epoch:13 step:12844 [D loss: 0.561824, acc.: 71.09%] [G loss: 0.556925]\n",
      "epoch:13 step:12845 [D loss: 0.643040, acc.: 64.06%] [G loss: 0.678411]\n",
      "epoch:13 step:12846 [D loss: 0.552561, acc.: 68.75%] [G loss: 0.675937]\n",
      "epoch:13 step:12847 [D loss: 0.514437, acc.: 77.34%] [G loss: 0.708307]\n",
      "epoch:13 step:12848 [D loss: 0.603444, acc.: 64.06%] [G loss: 0.540312]\n",
      "epoch:13 step:12849 [D loss: 0.606342, acc.: 64.06%] [G loss: 0.665633]\n",
      "epoch:13 step:12850 [D loss: 0.578584, acc.: 66.41%] [G loss: 0.564490]\n",
      "epoch:13 step:12851 [D loss: 0.562914, acc.: 62.50%] [G loss: 0.574941]\n",
      "epoch:13 step:12852 [D loss: 0.566584, acc.: 70.31%] [G loss: 0.635498]\n",
      "epoch:13 step:12853 [D loss: 0.577051, acc.: 69.53%] [G loss: 0.668341]\n",
      "epoch:13 step:12854 [D loss: 0.626481, acc.: 63.28%] [G loss: 0.502754]\n",
      "epoch:13 step:12855 [D loss: 0.508139, acc.: 71.09%] [G loss: 0.689419]\n",
      "epoch:13 step:12856 [D loss: 0.598419, acc.: 64.06%] [G loss: 0.592229]\n",
      "epoch:13 step:12857 [D loss: 0.571646, acc.: 66.41%] [G loss: 0.605945]\n",
      "epoch:13 step:12858 [D loss: 0.484297, acc.: 78.91%] [G loss: 0.674189]\n",
      "epoch:13 step:12859 [D loss: 0.592760, acc.: 70.31%] [G loss: 0.677476]\n",
      "epoch:13 step:12860 [D loss: 0.510965, acc.: 75.00%] [G loss: 0.713835]\n",
      "epoch:13 step:12861 [D loss: 0.541275, acc.: 71.88%] [G loss: 0.613756]\n",
      "epoch:13 step:12862 [D loss: 0.535925, acc.: 76.56%] [G loss: 0.720164]\n",
      "epoch:13 step:12863 [D loss: 0.552241, acc.: 70.31%] [G loss: 0.532361]\n",
      "epoch:13 step:12864 [D loss: 0.535346, acc.: 71.88%] [G loss: 0.553800]\n",
      "epoch:13 step:12865 [D loss: 0.644197, acc.: 57.81%] [G loss: 0.413330]\n",
      "epoch:13 step:12866 [D loss: 0.527768, acc.: 72.66%] [G loss: 0.478567]\n",
      "epoch:13 step:12867 [D loss: 0.543759, acc.: 74.22%] [G loss: 0.484969]\n",
      "epoch:13 step:12868 [D loss: 0.563921, acc.: 69.53%] [G loss: 0.646165]\n",
      "epoch:13 step:12869 [D loss: 0.559638, acc.: 71.09%] [G loss: 0.534980]\n",
      "epoch:13 step:12870 [D loss: 0.570617, acc.: 68.75%] [G loss: 0.514553]\n",
      "epoch:13 step:12871 [D loss: 0.549142, acc.: 67.19%] [G loss: 0.531336]\n",
      "epoch:13 step:12872 [D loss: 0.488579, acc.: 75.00%] [G loss: 0.681779]\n",
      "epoch:13 step:12873 [D loss: 0.562510, acc.: 66.41%] [G loss: 0.613144]\n",
      "epoch:13 step:12874 [D loss: 0.493977, acc.: 76.56%] [G loss: 0.573388]\n",
      "epoch:13 step:12875 [D loss: 0.499494, acc.: 74.22%] [G loss: 0.693604]\n",
      "epoch:13 step:12876 [D loss: 0.537165, acc.: 72.66%] [G loss: 0.645666]\n",
      "epoch:13 step:12877 [D loss: 0.607098, acc.: 62.50%] [G loss: 0.543838]\n",
      "epoch:13 step:12878 [D loss: 0.515908, acc.: 71.88%] [G loss: 0.625983]\n",
      "epoch:13 step:12879 [D loss: 0.550133, acc.: 67.97%] [G loss: 0.417144]\n",
      "epoch:13 step:12880 [D loss: 0.489567, acc.: 77.34%] [G loss: 0.562111]\n",
      "epoch:13 step:12881 [D loss: 0.589723, acc.: 67.97%] [G loss: 0.539306]\n",
      "epoch:13 step:12882 [D loss: 0.515549, acc.: 67.97%] [G loss: 0.748951]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12883 [D loss: 0.596884, acc.: 66.41%] [G loss: 0.765298]\n",
      "epoch:13 step:12884 [D loss: 0.631063, acc.: 64.06%] [G loss: 0.535376]\n",
      "epoch:13 step:12885 [D loss: 0.632102, acc.: 58.59%] [G loss: 0.482689]\n",
      "epoch:13 step:12886 [D loss: 0.513761, acc.: 71.88%] [G loss: 0.621810]\n",
      "epoch:13 step:12887 [D loss: 0.559332, acc.: 67.97%] [G loss: 0.525561]\n",
      "epoch:13 step:12888 [D loss: 0.524502, acc.: 70.31%] [G loss: 0.744095]\n",
      "epoch:13 step:12889 [D loss: 0.534377, acc.: 71.88%] [G loss: 0.793464]\n",
      "epoch:13 step:12890 [D loss: 0.551230, acc.: 65.62%] [G loss: 0.641879]\n",
      "epoch:13 step:12891 [D loss: 0.613468, acc.: 70.31%] [G loss: 0.611183]\n",
      "epoch:13 step:12892 [D loss: 0.565059, acc.: 66.41%] [G loss: 0.630991]\n",
      "epoch:13 step:12893 [D loss: 0.506811, acc.: 72.66%] [G loss: 0.592582]\n",
      "epoch:13 step:12894 [D loss: 0.594251, acc.: 62.50%] [G loss: 0.659310]\n",
      "epoch:13 step:12895 [D loss: 0.490610, acc.: 75.00%] [G loss: 0.630151]\n",
      "epoch:13 step:12896 [D loss: 0.547689, acc.: 65.62%] [G loss: 0.606126]\n",
      "epoch:13 step:12897 [D loss: 0.688629, acc.: 58.59%] [G loss: 0.528845]\n",
      "epoch:13 step:12898 [D loss: 0.597603, acc.: 64.84%] [G loss: 0.516101]\n",
      "epoch:13 step:12899 [D loss: 0.593733, acc.: 64.06%] [G loss: 0.609247]\n",
      "epoch:13 step:12900 [D loss: 0.491342, acc.: 78.12%] [G loss: 0.648898]\n",
      "epoch:13 step:12901 [D loss: 0.586439, acc.: 67.97%] [G loss: 0.512741]\n",
      "epoch:13 step:12902 [D loss: 0.588607, acc.: 69.53%] [G loss: 0.571468]\n",
      "epoch:13 step:12903 [D loss: 0.552024, acc.: 71.09%] [G loss: 0.570431]\n",
      "epoch:13 step:12904 [D loss: 0.558140, acc.: 67.19%] [G loss: 0.714910]\n",
      "epoch:13 step:12905 [D loss: 0.497891, acc.: 75.78%] [G loss: 0.626953]\n",
      "epoch:13 step:12906 [D loss: 0.509603, acc.: 72.66%] [G loss: 0.678111]\n",
      "epoch:13 step:12907 [D loss: 0.506283, acc.: 71.88%] [G loss: 0.776504]\n",
      "epoch:13 step:12908 [D loss: 0.566001, acc.: 71.09%] [G loss: 0.552096]\n",
      "epoch:13 step:12909 [D loss: 0.617733, acc.: 63.28%] [G loss: 0.564141]\n",
      "epoch:13 step:12910 [D loss: 0.573732, acc.: 70.31%] [G loss: 0.611167]\n",
      "epoch:13 step:12911 [D loss: 0.556596, acc.: 67.97%] [G loss: 0.501324]\n",
      "epoch:13 step:12912 [D loss: 0.610104, acc.: 63.28%] [G loss: 0.639368]\n",
      "epoch:13 step:12913 [D loss: 0.515490, acc.: 73.44%] [G loss: 0.519979]\n",
      "epoch:13 step:12914 [D loss: 0.521568, acc.: 75.00%] [G loss: 0.591298]\n",
      "epoch:13 step:12915 [D loss: 0.539121, acc.: 69.53%] [G loss: 0.482575]\n",
      "epoch:13 step:12916 [D loss: 0.537480, acc.: 71.09%] [G loss: 0.645700]\n",
      "epoch:13 step:12917 [D loss: 0.482429, acc.: 74.22%] [G loss: 0.718666]\n",
      "epoch:13 step:12918 [D loss: 0.552365, acc.: 70.31%] [G loss: 0.606047]\n",
      "epoch:13 step:12919 [D loss: 0.595560, acc.: 67.19%] [G loss: 0.472093]\n",
      "epoch:13 step:12920 [D loss: 0.563046, acc.: 70.31%] [G loss: 0.461410]\n",
      "epoch:13 step:12921 [D loss: 0.661822, acc.: 60.94%] [G loss: 0.477365]\n",
      "epoch:13 step:12922 [D loss: 0.586068, acc.: 63.28%] [G loss: 0.415270]\n",
      "epoch:13 step:12923 [D loss: 0.548939, acc.: 78.12%] [G loss: 0.538525]\n",
      "epoch:13 step:12924 [D loss: 0.517680, acc.: 75.78%] [G loss: 0.687716]\n",
      "epoch:13 step:12925 [D loss: 0.516194, acc.: 78.12%] [G loss: 0.751834]\n",
      "epoch:13 step:12926 [D loss: 0.598650, acc.: 67.19%] [G loss: 0.581692]\n",
      "epoch:13 step:12927 [D loss: 0.461457, acc.: 79.69%] [G loss: 0.659432]\n",
      "epoch:13 step:12928 [D loss: 0.437774, acc.: 79.69%] [G loss: 0.747780]\n",
      "epoch:13 step:12929 [D loss: 0.543831, acc.: 73.44%] [G loss: 0.778489]\n",
      "epoch:13 step:12930 [D loss: 0.523996, acc.: 74.22%] [G loss: 0.616960]\n",
      "epoch:13 step:12931 [D loss: 0.527389, acc.: 73.44%] [G loss: 0.727542]\n",
      "epoch:13 step:12932 [D loss: 0.481016, acc.: 75.00%] [G loss: 0.622689]\n",
      "epoch:13 step:12933 [D loss: 0.521176, acc.: 71.09%] [G loss: 0.640683]\n",
      "epoch:13 step:12934 [D loss: 0.555468, acc.: 69.53%] [G loss: 0.503944]\n",
      "epoch:13 step:12935 [D loss: 0.569937, acc.: 67.19%] [G loss: 0.569757]\n",
      "epoch:13 step:12936 [D loss: 0.530855, acc.: 70.31%] [G loss: 0.643508]\n",
      "epoch:13 step:12937 [D loss: 0.549058, acc.: 75.00%] [G loss: 0.656052]\n",
      "epoch:13 step:12938 [D loss: 0.594084, acc.: 67.97%] [G loss: 0.433981]\n",
      "epoch:13 step:12939 [D loss: 0.557319, acc.: 69.53%] [G loss: 0.569667]\n",
      "epoch:13 step:12940 [D loss: 0.536094, acc.: 69.53%] [G loss: 0.538001]\n",
      "epoch:13 step:12941 [D loss: 0.507133, acc.: 69.53%] [G loss: 0.567036]\n",
      "epoch:13 step:12942 [D loss: 0.551350, acc.: 68.75%] [G loss: 0.600135]\n",
      "epoch:13 step:12943 [D loss: 0.591031, acc.: 65.62%] [G loss: 0.607749]\n",
      "epoch:13 step:12944 [D loss: 0.613295, acc.: 65.62%] [G loss: 0.516488]\n",
      "epoch:13 step:12945 [D loss: 0.579240, acc.: 67.19%] [G loss: 0.719038]\n",
      "epoch:13 step:12946 [D loss: 0.591763, acc.: 69.53%] [G loss: 0.670512]\n",
      "epoch:13 step:12947 [D loss: 0.649624, acc.: 59.38%] [G loss: 0.472966]\n",
      "epoch:13 step:12948 [D loss: 0.557372, acc.: 68.75%] [G loss: 0.631347]\n",
      "epoch:13 step:12949 [D loss: 0.510425, acc.: 76.56%] [G loss: 0.735655]\n",
      "epoch:13 step:12950 [D loss: 0.485370, acc.: 75.78%] [G loss: 0.760018]\n",
      "epoch:13 step:12951 [D loss: 0.514881, acc.: 72.66%] [G loss: 0.702507]\n",
      "epoch:13 step:12952 [D loss: 0.574664, acc.: 69.53%] [G loss: 0.724833]\n",
      "epoch:13 step:12953 [D loss: 0.514863, acc.: 75.00%] [G loss: 0.632033]\n",
      "epoch:13 step:12954 [D loss: 0.579122, acc.: 69.53%] [G loss: 0.707499]\n",
      "epoch:13 step:12955 [D loss: 0.562830, acc.: 73.44%] [G loss: 0.680235]\n",
      "epoch:13 step:12956 [D loss: 0.512142, acc.: 71.09%] [G loss: 0.669710]\n",
      "epoch:13 step:12957 [D loss: 0.569910, acc.: 68.75%] [G loss: 0.568379]\n",
      "epoch:13 step:12958 [D loss: 0.575348, acc.: 68.75%] [G loss: 0.604668]\n",
      "epoch:13 step:12959 [D loss: 0.549331, acc.: 74.22%] [G loss: 0.556274]\n",
      "epoch:13 step:12960 [D loss: 0.563246, acc.: 71.88%] [G loss: 0.504379]\n",
      "epoch:13 step:12961 [D loss: 0.518467, acc.: 76.56%] [G loss: 0.657447]\n",
      "epoch:13 step:12962 [D loss: 0.489818, acc.: 78.91%] [G loss: 0.670963]\n",
      "epoch:13 step:12963 [D loss: 0.527756, acc.: 74.22%] [G loss: 0.956888]\n",
      "epoch:13 step:12964 [D loss: 0.594154, acc.: 67.19%] [G loss: 0.820013]\n",
      "epoch:13 step:12965 [D loss: 0.606734, acc.: 67.97%] [G loss: 0.618384]\n",
      "epoch:13 step:12966 [D loss: 0.573493, acc.: 66.41%] [G loss: 0.529719]\n",
      "epoch:13 step:12967 [D loss: 0.480316, acc.: 78.91%] [G loss: 0.707834]\n",
      "epoch:13 step:12968 [D loss: 0.586324, acc.: 67.19%] [G loss: 0.599799]\n",
      "epoch:13 step:12969 [D loss: 0.708957, acc.: 57.03%] [G loss: 0.457369]\n",
      "epoch:13 step:12970 [D loss: 0.522489, acc.: 75.00%] [G loss: 0.635391]\n",
      "epoch:13 step:12971 [D loss: 0.515213, acc.: 74.22%] [G loss: 0.560715]\n",
      "epoch:13 step:12972 [D loss: 0.559784, acc.: 69.53%] [G loss: 0.493159]\n",
      "epoch:13 step:12973 [D loss: 0.492277, acc.: 73.44%] [G loss: 0.782327]\n",
      "epoch:13 step:12974 [D loss: 0.579748, acc.: 73.44%] [G loss: 0.661864]\n",
      "epoch:13 step:12975 [D loss: 0.624486, acc.: 61.72%] [G loss: 0.575883]\n",
      "epoch:13 step:12976 [D loss: 0.526265, acc.: 71.88%] [G loss: 0.698556]\n",
      "epoch:13 step:12977 [D loss: 0.535896, acc.: 71.09%] [G loss: 0.744092]\n",
      "epoch:13 step:12978 [D loss: 0.585108, acc.: 65.62%] [G loss: 0.603741]\n",
      "epoch:13 step:12979 [D loss: 0.562037, acc.: 64.06%] [G loss: 0.633949]\n",
      "epoch:13 step:12980 [D loss: 0.574823, acc.: 70.31%] [G loss: 0.580459]\n",
      "epoch:13 step:12981 [D loss: 0.589372, acc.: 64.06%] [G loss: 0.587925]\n",
      "epoch:13 step:12982 [D loss: 0.517360, acc.: 69.53%] [G loss: 0.703148]\n",
      "epoch:13 step:12983 [D loss: 0.515692, acc.: 71.88%] [G loss: 0.940306]\n",
      "epoch:13 step:12984 [D loss: 0.551525, acc.: 75.00%] [G loss: 0.723619]\n",
      "epoch:13 step:12985 [D loss: 0.541032, acc.: 70.31%] [G loss: 0.725917]\n",
      "epoch:13 step:12986 [D loss: 0.560977, acc.: 70.31%] [G loss: 0.599616]\n",
      "epoch:13 step:12987 [D loss: 0.607465, acc.: 65.62%] [G loss: 0.363618]\n",
      "epoch:13 step:12988 [D loss: 0.548161, acc.: 67.97%] [G loss: 0.487006]\n",
      "epoch:13 step:12989 [D loss: 0.532914, acc.: 71.09%] [G loss: 0.491217]\n",
      "epoch:13 step:12990 [D loss: 0.536667, acc.: 75.78%] [G loss: 0.530318]\n",
      "epoch:13 step:12991 [D loss: 0.562413, acc.: 72.66%] [G loss: 0.474611]\n",
      "epoch:13 step:12992 [D loss: 0.596013, acc.: 67.97%] [G loss: 0.499644]\n",
      "epoch:13 step:12993 [D loss: 0.644784, acc.: 58.59%] [G loss: 0.460580]\n",
      "epoch:13 step:12994 [D loss: 0.545945, acc.: 70.31%] [G loss: 0.410684]\n",
      "epoch:13 step:12995 [D loss: 0.543068, acc.: 67.97%] [G loss: 0.543620]\n",
      "epoch:13 step:12996 [D loss: 0.512594, acc.: 73.44%] [G loss: 0.772723]\n",
      "epoch:13 step:12997 [D loss: 0.543596, acc.: 69.53%] [G loss: 0.639976]\n",
      "epoch:13 step:12998 [D loss: 0.582644, acc.: 70.31%] [G loss: 0.731429]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12999 [D loss: 0.618300, acc.: 65.62%] [G loss: 0.611660]\n",
      "epoch:13 step:13000 [D loss: 0.515859, acc.: 71.88%] [G loss: 0.570956]\n",
      "##############\n",
      "[2.96363842 1.30845778 6.14375878 5.01922899 3.88797592 5.96814703\n",
      " 4.6864857  4.83956248 4.71062045 4.18438226]\n",
      "##########\n",
      "epoch:13 step:13001 [D loss: 0.617972, acc.: 63.28%] [G loss: 0.577425]\n",
      "epoch:13 step:13002 [D loss: 0.575555, acc.: 67.97%] [G loss: 0.427583]\n",
      "epoch:13 step:13003 [D loss: 0.562340, acc.: 62.50%] [G loss: 0.550332]\n",
      "epoch:13 step:13004 [D loss: 0.440173, acc.: 77.34%] [G loss: 0.702068]\n",
      "epoch:13 step:13005 [D loss: 0.613466, acc.: 70.31%] [G loss: 0.544440]\n",
      "epoch:13 step:13006 [D loss: 0.534329, acc.: 71.88%] [G loss: 0.587501]\n",
      "epoch:13 step:13007 [D loss: 0.559570, acc.: 68.75%] [G loss: 0.571102]\n",
      "epoch:13 step:13008 [D loss: 0.599099, acc.: 70.31%] [G loss: 0.593346]\n",
      "epoch:13 step:13009 [D loss: 0.666478, acc.: 57.81%] [G loss: 0.526030]\n",
      "epoch:13 step:13010 [D loss: 0.555227, acc.: 67.19%] [G loss: 0.684160]\n",
      "epoch:13 step:13011 [D loss: 0.490599, acc.: 75.00%] [G loss: 0.663634]\n",
      "epoch:13 step:13012 [D loss: 0.610043, acc.: 63.28%] [G loss: 0.729892]\n",
      "epoch:13 step:13013 [D loss: 0.544088, acc.: 67.19%] [G loss: 0.587189]\n",
      "epoch:13 step:13014 [D loss: 0.537095, acc.: 74.22%] [G loss: 0.554350]\n",
      "epoch:13 step:13015 [D loss: 0.530903, acc.: 74.22%] [G loss: 0.512922]\n",
      "epoch:13 step:13016 [D loss: 0.532886, acc.: 73.44%] [G loss: 0.484322]\n",
      "epoch:13 step:13017 [D loss: 0.515246, acc.: 71.88%] [G loss: 0.499726]\n",
      "epoch:13 step:13018 [D loss: 0.533679, acc.: 69.53%] [G loss: 0.519007]\n",
      "epoch:13 step:13019 [D loss: 0.547936, acc.: 69.53%] [G loss: 0.538045]\n",
      "epoch:13 step:13020 [D loss: 0.549492, acc.: 68.75%] [G loss: 0.569506]\n",
      "epoch:13 step:13021 [D loss: 0.591161, acc.: 70.31%] [G loss: 0.419064]\n",
      "epoch:13 step:13022 [D loss: 0.547972, acc.: 69.53%] [G loss: 0.386290]\n",
      "epoch:13 step:13023 [D loss: 0.525170, acc.: 71.88%] [G loss: 0.612859]\n",
      "epoch:13 step:13024 [D loss: 0.523388, acc.: 72.66%] [G loss: 0.735881]\n",
      "epoch:13 step:13025 [D loss: 0.581129, acc.: 71.09%] [G loss: 0.703355]\n",
      "epoch:13 step:13026 [D loss: 0.579805, acc.: 69.53%] [G loss: 0.571949]\n",
      "epoch:13 step:13027 [D loss: 0.595018, acc.: 69.53%] [G loss: 0.515974]\n",
      "epoch:13 step:13028 [D loss: 0.593364, acc.: 67.97%] [G loss: 0.406452]\n",
      "epoch:13 step:13029 [D loss: 0.571592, acc.: 66.41%] [G loss: 0.435151]\n",
      "epoch:13 step:13030 [D loss: 0.566820, acc.: 66.41%] [G loss: 0.465337]\n",
      "epoch:13 step:13031 [D loss: 0.531297, acc.: 68.75%] [G loss: 0.509953]\n",
      "epoch:13 step:13032 [D loss: 0.602770, acc.: 64.06%] [G loss: 0.526733]\n",
      "epoch:13 step:13033 [D loss: 0.534377, acc.: 72.66%] [G loss: 0.538872]\n",
      "epoch:13 step:13034 [D loss: 0.549314, acc.: 66.41%] [G loss: 0.512388]\n",
      "epoch:13 step:13035 [D loss: 0.508961, acc.: 70.31%] [G loss: 0.611326]\n",
      "epoch:13 step:13036 [D loss: 0.552277, acc.: 68.75%] [G loss: 0.543080]\n",
      "epoch:13 step:13037 [D loss: 0.593314, acc.: 67.97%] [G loss: 0.483503]\n",
      "epoch:13 step:13038 [D loss: 0.469334, acc.: 71.88%] [G loss: 0.720309]\n",
      "epoch:13 step:13039 [D loss: 0.632744, acc.: 63.28%] [G loss: 0.590844]\n",
      "epoch:13 step:13040 [D loss: 0.582973, acc.: 68.75%] [G loss: 0.600485]\n",
      "epoch:13 step:13041 [D loss: 0.483495, acc.: 79.69%] [G loss: 0.692533]\n",
      "epoch:13 step:13042 [D loss: 0.554728, acc.: 68.75%] [G loss: 0.563050]\n",
      "epoch:13 step:13043 [D loss: 0.528617, acc.: 72.66%] [G loss: 0.406386]\n",
      "epoch:13 step:13044 [D loss: 0.589415, acc.: 67.19%] [G loss: 0.485502]\n",
      "epoch:13 step:13045 [D loss: 0.538871, acc.: 67.97%] [G loss: 0.557632]\n",
      "epoch:13 step:13046 [D loss: 0.567545, acc.: 67.97%] [G loss: 0.430068]\n",
      "epoch:13 step:13047 [D loss: 0.528681, acc.: 71.88%] [G loss: 0.543259]\n",
      "epoch:13 step:13048 [D loss: 0.679263, acc.: 58.59%] [G loss: 0.386335]\n",
      "epoch:13 step:13049 [D loss: 0.533281, acc.: 69.53%] [G loss: 0.542478]\n",
      "epoch:13 step:13050 [D loss: 0.597141, acc.: 60.16%] [G loss: 0.490277]\n",
      "epoch:13 step:13051 [D loss: 0.416769, acc.: 81.25%] [G loss: 0.665514]\n",
      "epoch:13 step:13052 [D loss: 0.507142, acc.: 76.56%] [G loss: 0.707870]\n",
      "epoch:13 step:13053 [D loss: 0.594191, acc.: 64.84%] [G loss: 0.553554]\n",
      "epoch:13 step:13054 [D loss: 0.583628, acc.: 67.19%] [G loss: 0.441913]\n",
      "epoch:13 step:13055 [D loss: 0.606035, acc.: 64.06%] [G loss: 0.411165]\n",
      "epoch:13 step:13056 [D loss: 0.500285, acc.: 72.66%] [G loss: 0.646010]\n",
      "epoch:13 step:13057 [D loss: 0.588501, acc.: 68.75%] [G loss: 0.517650]\n",
      "epoch:13 step:13058 [D loss: 0.564454, acc.: 68.75%] [G loss: 0.463721]\n",
      "epoch:13 step:13059 [D loss: 0.532116, acc.: 71.88%] [G loss: 0.643220]\n",
      "epoch:13 step:13060 [D loss: 0.559188, acc.: 72.66%] [G loss: 0.475379]\n",
      "epoch:13 step:13061 [D loss: 0.649405, acc.: 58.59%] [G loss: 0.514434]\n",
      "epoch:13 step:13062 [D loss: 0.608778, acc.: 64.84%] [G loss: 0.458443]\n",
      "epoch:13 step:13063 [D loss: 0.567766, acc.: 65.62%] [G loss: 0.334182]\n",
      "epoch:13 step:13064 [D loss: 0.583148, acc.: 67.19%] [G loss: 0.574363]\n",
      "epoch:13 step:13065 [D loss: 0.529754, acc.: 70.31%] [G loss: 0.582182]\n",
      "epoch:13 step:13066 [D loss: 0.560389, acc.: 72.66%] [G loss: 0.693722]\n",
      "epoch:13 step:13067 [D loss: 0.527340, acc.: 70.31%] [G loss: 0.755960]\n",
      "epoch:13 step:13068 [D loss: 0.543455, acc.: 71.09%] [G loss: 0.628380]\n",
      "epoch:13 step:13069 [D loss: 0.556722, acc.: 70.31%] [G loss: 0.632649]\n",
      "epoch:13 step:13070 [D loss: 0.625611, acc.: 60.94%] [G loss: 0.640149]\n",
      "epoch:13 step:13071 [D loss: 0.494425, acc.: 74.22%] [G loss: 0.666406]\n",
      "epoch:13 step:13072 [D loss: 0.576189, acc.: 68.75%] [G loss: 0.514811]\n",
      "epoch:13 step:13073 [D loss: 0.633535, acc.: 59.38%] [G loss: 0.554662]\n",
      "epoch:13 step:13074 [D loss: 0.506757, acc.: 75.00%] [G loss: 0.446141]\n",
      "epoch:13 step:13075 [D loss: 0.502930, acc.: 71.88%] [G loss: 0.742680]\n",
      "epoch:13 step:13076 [D loss: 0.577219, acc.: 65.62%] [G loss: 0.628186]\n",
      "epoch:13 step:13077 [D loss: 0.494643, acc.: 75.00%] [G loss: 0.898167]\n",
      "epoch:13 step:13078 [D loss: 0.488791, acc.: 77.34%] [G loss: 0.671882]\n",
      "epoch:13 step:13079 [D loss: 0.491631, acc.: 76.56%] [G loss: 0.644247]\n",
      "epoch:13 step:13080 [D loss: 0.550777, acc.: 70.31%] [G loss: 0.606055]\n",
      "epoch:13 step:13081 [D loss: 0.539942, acc.: 73.44%] [G loss: 0.468740]\n",
      "epoch:13 step:13082 [D loss: 0.543843, acc.: 68.75%] [G loss: 0.593035]\n",
      "epoch:13 step:13083 [D loss: 0.550211, acc.: 69.53%] [G loss: 0.709272]\n",
      "epoch:13 step:13084 [D loss: 0.550618, acc.: 70.31%] [G loss: 0.600419]\n",
      "epoch:13 step:13085 [D loss: 0.602307, acc.: 64.84%] [G loss: 0.642358]\n",
      "epoch:13 step:13086 [D loss: 0.575673, acc.: 71.88%] [G loss: 0.776608]\n",
      "epoch:13 step:13087 [D loss: 0.512920, acc.: 72.66%] [G loss: 0.697837]\n",
      "epoch:13 step:13088 [D loss: 0.558366, acc.: 67.19%] [G loss: 0.660866]\n",
      "epoch:13 step:13089 [D loss: 0.562481, acc.: 67.19%] [G loss: 0.516891]\n",
      "epoch:13 step:13090 [D loss: 0.522819, acc.: 71.09%] [G loss: 0.623962]\n",
      "epoch:13 step:13091 [D loss: 0.503655, acc.: 71.88%] [G loss: 0.471276]\n",
      "epoch:13 step:13092 [D loss: 0.549934, acc.: 67.97%] [G loss: 0.599621]\n",
      "epoch:13 step:13093 [D loss: 0.490298, acc.: 76.56%] [G loss: 0.711264]\n",
      "epoch:13 step:13094 [D loss: 0.508204, acc.: 78.91%] [G loss: 0.612547]\n",
      "epoch:13 step:13095 [D loss: 0.466094, acc.: 75.78%] [G loss: 0.854713]\n",
      "epoch:13 step:13096 [D loss: 0.596015, acc.: 67.19%] [G loss: 0.621390]\n",
      "epoch:13 step:13097 [D loss: 0.503396, acc.: 74.22%] [G loss: 0.722148]\n",
      "epoch:13 step:13098 [D loss: 0.632746, acc.: 55.47%] [G loss: 0.641601]\n",
      "epoch:13 step:13099 [D loss: 0.490523, acc.: 75.78%] [G loss: 0.794281]\n",
      "epoch:13 step:13100 [D loss: 0.490647, acc.: 79.69%] [G loss: 0.861080]\n",
      "epoch:13 step:13101 [D loss: 0.673637, acc.: 64.06%] [G loss: 0.717427]\n",
      "epoch:13 step:13102 [D loss: 0.467563, acc.: 75.78%] [G loss: 0.689951]\n",
      "epoch:13 step:13103 [D loss: 0.583171, acc.: 67.19%] [G loss: 0.520721]\n",
      "epoch:13 step:13104 [D loss: 0.473690, acc.: 74.22%] [G loss: 0.704050]\n",
      "epoch:13 step:13105 [D loss: 0.483827, acc.: 76.56%] [G loss: 0.750678]\n",
      "epoch:13 step:13106 [D loss: 0.433024, acc.: 78.12%] [G loss: 0.874351]\n",
      "epoch:13 step:13107 [D loss: 0.427796, acc.: 82.03%] [G loss: 0.935716]\n",
      "epoch:13 step:13108 [D loss: 0.520822, acc.: 71.88%] [G loss: 0.953056]\n",
      "epoch:13 step:13109 [D loss: 0.686956, acc.: 64.06%] [G loss: 0.864524]\n",
      "epoch:13 step:13110 [D loss: 0.588721, acc.: 67.97%] [G loss: 1.158319]\n",
      "epoch:13 step:13111 [D loss: 0.562635, acc.: 71.09%] [G loss: 1.117030]\n",
      "epoch:13 step:13112 [D loss: 0.533274, acc.: 74.22%] [G loss: 1.190999]\n",
      "epoch:13 step:13113 [D loss: 0.659819, acc.: 60.16%] [G loss: 0.682695]\n",
      "epoch:13 step:13114 [D loss: 0.543175, acc.: 70.31%] [G loss: 0.884335]\n",
      "epoch:13 step:13115 [D loss: 0.550061, acc.: 70.31%] [G loss: 0.937129]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:13116 [D loss: 0.468378, acc.: 78.91%] [G loss: 0.895815]\n",
      "epoch:13 step:13117 [D loss: 0.451233, acc.: 76.56%] [G loss: 1.102000]\n",
      "epoch:13 step:13118 [D loss: 0.440590, acc.: 79.69%] [G loss: 1.184799]\n",
      "epoch:14 step:13119 [D loss: 0.591465, acc.: 70.31%] [G loss: 1.131101]\n",
      "epoch:14 step:13120 [D loss: 0.503375, acc.: 74.22%] [G loss: 0.876100]\n",
      "epoch:14 step:13121 [D loss: 0.609054, acc.: 68.75%] [G loss: 0.771224]\n",
      "epoch:14 step:13122 [D loss: 0.519465, acc.: 73.44%] [G loss: 0.667187]\n",
      "epoch:14 step:13123 [D loss: 0.547651, acc.: 71.09%] [G loss: 0.602307]\n",
      "epoch:14 step:13124 [D loss: 0.585905, acc.: 67.19%] [G loss: 0.683446]\n",
      "epoch:14 step:13125 [D loss: 0.483748, acc.: 75.78%] [G loss: 0.700250]\n",
      "epoch:14 step:13126 [D loss: 0.615708, acc.: 67.19%] [G loss: 0.670866]\n",
      "epoch:14 step:13127 [D loss: 0.511224, acc.: 75.00%] [G loss: 0.793172]\n",
      "epoch:14 step:13128 [D loss: 0.543184, acc.: 71.88%] [G loss: 0.748634]\n",
      "epoch:14 step:13129 [D loss: 0.467215, acc.: 78.12%] [G loss: 0.770705]\n",
      "epoch:14 step:13130 [D loss: 0.551952, acc.: 69.53%] [G loss: 0.567643]\n",
      "epoch:14 step:13131 [D loss: 0.575898, acc.: 69.53%] [G loss: 0.650568]\n",
      "epoch:14 step:13132 [D loss: 0.543486, acc.: 71.88%] [G loss: 0.647697]\n",
      "epoch:14 step:13133 [D loss: 0.534499, acc.: 73.44%] [G loss: 0.670544]\n",
      "epoch:14 step:13134 [D loss: 0.530580, acc.: 74.22%] [G loss: 0.680157]\n",
      "epoch:14 step:13135 [D loss: 0.580789, acc.: 67.97%] [G loss: 0.579840]\n",
      "epoch:14 step:13136 [D loss: 0.591289, acc.: 67.19%] [G loss: 0.592876]\n",
      "epoch:14 step:13137 [D loss: 0.584222, acc.: 66.41%] [G loss: 0.673238]\n",
      "epoch:14 step:13138 [D loss: 0.689368, acc.: 61.72%] [G loss: 0.710023]\n",
      "epoch:14 step:13139 [D loss: 0.616213, acc.: 71.09%] [G loss: 0.662551]\n",
      "epoch:14 step:13140 [D loss: 0.456217, acc.: 80.47%] [G loss: 0.833874]\n",
      "epoch:14 step:13141 [D loss: 0.590720, acc.: 63.28%] [G loss: 0.569103]\n",
      "epoch:14 step:13142 [D loss: 0.502887, acc.: 72.66%] [G loss: 0.674324]\n",
      "epoch:14 step:13143 [D loss: 0.505173, acc.: 74.22%] [G loss: 0.601955]\n",
      "epoch:14 step:13144 [D loss: 0.625084, acc.: 67.97%] [G loss: 0.484004]\n",
      "epoch:14 step:13145 [D loss: 0.482599, acc.: 78.91%] [G loss: 0.660335]\n",
      "epoch:14 step:13146 [D loss: 0.574856, acc.: 67.97%] [G loss: 0.607060]\n",
      "epoch:14 step:13147 [D loss: 0.483821, acc.: 77.34%] [G loss: 0.773237]\n",
      "epoch:14 step:13148 [D loss: 0.564408, acc.: 70.31%] [G loss: 0.578764]\n",
      "epoch:14 step:13149 [D loss: 0.599712, acc.: 63.28%] [G loss: 0.464732]\n",
      "epoch:14 step:13150 [D loss: 0.598339, acc.: 64.06%] [G loss: 0.505859]\n",
      "epoch:14 step:13151 [D loss: 0.508042, acc.: 78.12%] [G loss: 0.608388]\n",
      "epoch:14 step:13152 [D loss: 0.564867, acc.: 62.50%] [G loss: 0.441013]\n",
      "epoch:14 step:13153 [D loss: 0.598043, acc.: 64.06%] [G loss: 0.576555]\n",
      "epoch:14 step:13154 [D loss: 0.504993, acc.: 73.44%] [G loss: 0.671352]\n",
      "epoch:14 step:13155 [D loss: 0.521613, acc.: 71.88%] [G loss: 0.566367]\n",
      "epoch:14 step:13156 [D loss: 0.624298, acc.: 66.41%] [G loss: 0.635175]\n",
      "epoch:14 step:13157 [D loss: 0.529488, acc.: 71.88%] [G loss: 0.553369]\n",
      "epoch:14 step:13158 [D loss: 0.447804, acc.: 77.34%] [G loss: 0.770180]\n",
      "epoch:14 step:13159 [D loss: 0.523948, acc.: 71.09%] [G loss: 0.693459]\n",
      "epoch:14 step:13160 [D loss: 0.496203, acc.: 73.44%] [G loss: 0.734994]\n",
      "epoch:14 step:13161 [D loss: 0.514186, acc.: 73.44%] [G loss: 0.688933]\n",
      "epoch:14 step:13162 [D loss: 0.646266, acc.: 61.72%] [G loss: 0.540807]\n",
      "epoch:14 step:13163 [D loss: 0.512758, acc.: 70.31%] [G loss: 0.574338]\n",
      "epoch:14 step:13164 [D loss: 0.479585, acc.: 74.22%] [G loss: 0.539131]\n",
      "epoch:14 step:13165 [D loss: 0.495942, acc.: 75.00%] [G loss: 0.506370]\n",
      "epoch:14 step:13166 [D loss: 0.552605, acc.: 70.31%] [G loss: 0.560678]\n",
      "epoch:14 step:13167 [D loss: 0.495687, acc.: 78.91%] [G loss: 0.512502]\n",
      "epoch:14 step:13168 [D loss: 0.569230, acc.: 73.44%] [G loss: 0.690556]\n",
      "epoch:14 step:13169 [D loss: 0.614871, acc.: 64.84%] [G loss: 0.449106]\n",
      "epoch:14 step:13170 [D loss: 0.543566, acc.: 68.75%] [G loss: 0.538357]\n",
      "epoch:14 step:13171 [D loss: 0.461479, acc.: 78.91%] [G loss: 0.597280]\n",
      "epoch:14 step:13172 [D loss: 0.456552, acc.: 77.34%] [G loss: 0.720648]\n",
      "epoch:14 step:13173 [D loss: 0.539488, acc.: 67.97%] [G loss: 0.729714]\n",
      "epoch:14 step:13174 [D loss: 0.504835, acc.: 74.22%] [G loss: 0.729223]\n",
      "epoch:14 step:13175 [D loss: 0.629832, acc.: 64.06%] [G loss: 0.622468]\n",
      "epoch:14 step:13176 [D loss: 0.552164, acc.: 70.31%] [G loss: 0.670991]\n",
      "epoch:14 step:13177 [D loss: 0.482611, acc.: 72.66%] [G loss: 0.750901]\n",
      "epoch:14 step:13178 [D loss: 0.505621, acc.: 75.78%] [G loss: 0.766729]\n",
      "epoch:14 step:13179 [D loss: 0.610514, acc.: 64.06%] [G loss: 0.650264]\n",
      "epoch:14 step:13180 [D loss: 0.560220, acc.: 67.97%] [G loss: 0.783740]\n",
      "epoch:14 step:13181 [D loss: 0.567926, acc.: 69.53%] [G loss: 0.526523]\n",
      "epoch:14 step:13182 [D loss: 0.585068, acc.: 72.66%] [G loss: 0.611634]\n",
      "epoch:14 step:13183 [D loss: 0.515890, acc.: 70.31%] [G loss: 0.542217]\n",
      "epoch:14 step:13184 [D loss: 0.460284, acc.: 74.22%] [G loss: 0.663814]\n",
      "epoch:14 step:13185 [D loss: 0.606193, acc.: 60.94%] [G loss: 0.458832]\n",
      "epoch:14 step:13186 [D loss: 0.528054, acc.: 74.22%] [G loss: 0.616384]\n",
      "epoch:14 step:13187 [D loss: 0.539947, acc.: 67.19%] [G loss: 0.653731]\n",
      "epoch:14 step:13188 [D loss: 0.519423, acc.: 77.34%] [G loss: 0.737731]\n",
      "epoch:14 step:13189 [D loss: 0.552998, acc.: 70.31%] [G loss: 0.756545]\n",
      "epoch:14 step:13190 [D loss: 0.558636, acc.: 67.19%] [G loss: 0.625286]\n",
      "epoch:14 step:13191 [D loss: 0.597127, acc.: 66.41%] [G loss: 0.527347]\n",
      "epoch:14 step:13192 [D loss: 0.461715, acc.: 78.91%] [G loss: 0.611870]\n",
      "epoch:14 step:13193 [D loss: 0.624922, acc.: 68.75%] [G loss: 0.772079]\n",
      "epoch:14 step:13194 [D loss: 0.512266, acc.: 71.88%] [G loss: 0.933848]\n",
      "epoch:14 step:13195 [D loss: 0.440350, acc.: 78.91%] [G loss: 0.780953]\n",
      "epoch:14 step:13196 [D loss: 0.601660, acc.: 67.97%] [G loss: 0.624790]\n",
      "epoch:14 step:13197 [D loss: 0.574227, acc.: 70.31%] [G loss: 0.490429]\n",
      "epoch:14 step:13198 [D loss: 0.537355, acc.: 65.62%] [G loss: 0.570783]\n",
      "epoch:14 step:13199 [D loss: 0.536492, acc.: 69.53%] [G loss: 0.576027]\n",
      "epoch:14 step:13200 [D loss: 0.509797, acc.: 73.44%] [G loss: 0.692088]\n",
      "##############\n",
      "[2.91708374 1.01501874 6.33770335 4.94063492 3.85386054 5.75349362\n",
      " 4.53892619 4.70412739 4.81809359 4.04036463]\n",
      "##########\n",
      "epoch:14 step:13201 [D loss: 0.460243, acc.: 76.56%] [G loss: 0.735305]\n",
      "epoch:14 step:13202 [D loss: 0.564458, acc.: 67.19%] [G loss: 0.793323]\n",
      "epoch:14 step:13203 [D loss: 0.570083, acc.: 70.31%] [G loss: 0.591152]\n",
      "epoch:14 step:13204 [D loss: 0.495975, acc.: 75.78%] [G loss: 0.685003]\n",
      "epoch:14 step:13205 [D loss: 0.495155, acc.: 78.12%] [G loss: 0.595447]\n",
      "epoch:14 step:13206 [D loss: 0.492930, acc.: 74.22%] [G loss: 0.520204]\n",
      "epoch:14 step:13207 [D loss: 0.525466, acc.: 71.09%] [G loss: 0.662296]\n",
      "epoch:14 step:13208 [D loss: 0.479809, acc.: 73.44%] [G loss: 0.738723]\n",
      "epoch:14 step:13209 [D loss: 0.553894, acc.: 71.88%] [G loss: 0.726223]\n",
      "epoch:14 step:13210 [D loss: 0.448150, acc.: 77.34%] [G loss: 0.778082]\n",
      "epoch:14 step:13211 [D loss: 0.534988, acc.: 74.22%] [G loss: 0.766043]\n",
      "epoch:14 step:13212 [D loss: 0.477339, acc.: 73.44%] [G loss: 0.850062]\n",
      "epoch:14 step:13213 [D loss: 0.553216, acc.: 73.44%] [G loss: 0.753434]\n",
      "epoch:14 step:13214 [D loss: 0.515884, acc.: 77.34%] [G loss: 0.613596]\n",
      "epoch:14 step:13215 [D loss: 0.529997, acc.: 72.66%] [G loss: 0.670303]\n",
      "epoch:14 step:13216 [D loss: 0.561669, acc.: 71.88%] [G loss: 0.819300]\n",
      "epoch:14 step:13217 [D loss: 0.504092, acc.: 74.22%] [G loss: 0.726663]\n",
      "epoch:14 step:13218 [D loss: 0.443494, acc.: 75.78%] [G loss: 0.913298]\n",
      "epoch:14 step:13219 [D loss: 0.510485, acc.: 75.00%] [G loss: 0.683199]\n",
      "epoch:14 step:13220 [D loss: 0.596215, acc.: 67.19%] [G loss: 0.587723]\n",
      "epoch:14 step:13221 [D loss: 0.536545, acc.: 71.09%] [G loss: 0.564796]\n",
      "epoch:14 step:13222 [D loss: 0.531485, acc.: 71.88%] [G loss: 0.678386]\n",
      "epoch:14 step:13223 [D loss: 0.555271, acc.: 65.62%] [G loss: 0.782062]\n",
      "epoch:14 step:13224 [D loss: 0.518718, acc.: 66.41%] [G loss: 0.696947]\n",
      "epoch:14 step:13225 [D loss: 0.629529, acc.: 70.31%] [G loss: 0.710863]\n",
      "epoch:14 step:13226 [D loss: 0.608818, acc.: 63.28%] [G loss: 0.682459]\n",
      "epoch:14 step:13227 [D loss: 0.633378, acc.: 61.72%] [G loss: 0.624600]\n",
      "epoch:14 step:13228 [D loss: 0.545542, acc.: 68.75%] [G loss: 0.729440]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13229 [D loss: 0.518200, acc.: 68.75%] [G loss: 0.718643]\n",
      "epoch:14 step:13230 [D loss: 0.506608, acc.: 75.78%] [G loss: 0.644600]\n",
      "epoch:14 step:13231 [D loss: 0.547793, acc.: 73.44%] [G loss: 0.641436]\n",
      "epoch:14 step:13232 [D loss: 0.562796, acc.: 67.97%] [G loss: 0.571961]\n",
      "epoch:14 step:13233 [D loss: 0.561534, acc.: 71.88%] [G loss: 0.547023]\n",
      "epoch:14 step:13234 [D loss: 0.517694, acc.: 68.75%] [G loss: 0.595609]\n",
      "epoch:14 step:13235 [D loss: 0.510449, acc.: 71.88%] [G loss: 0.734598]\n",
      "epoch:14 step:13236 [D loss: 0.518662, acc.: 72.66%] [G loss: 0.923662]\n",
      "epoch:14 step:13237 [D loss: 0.489860, acc.: 71.88%] [G loss: 0.952670]\n",
      "epoch:14 step:13238 [D loss: 0.606241, acc.: 66.41%] [G loss: 0.708485]\n",
      "epoch:14 step:13239 [D loss: 0.524326, acc.: 67.19%] [G loss: 0.579971]\n",
      "epoch:14 step:13240 [D loss: 0.464306, acc.: 81.25%] [G loss: 0.719022]\n",
      "epoch:14 step:13241 [D loss: 0.534994, acc.: 73.44%] [G loss: 0.559924]\n",
      "epoch:14 step:13242 [D loss: 0.583994, acc.: 67.19%] [G loss: 0.649745]\n",
      "epoch:14 step:13243 [D loss: 0.578737, acc.: 66.41%] [G loss: 0.600373]\n",
      "epoch:14 step:13244 [D loss: 0.503352, acc.: 74.22%] [G loss: 0.584750]\n",
      "epoch:14 step:13245 [D loss: 0.496770, acc.: 75.78%] [G loss: 0.628197]\n",
      "epoch:14 step:13246 [D loss: 0.505413, acc.: 71.09%] [G loss: 0.710942]\n",
      "epoch:14 step:13247 [D loss: 0.583505, acc.: 66.41%] [G loss: 0.485081]\n",
      "epoch:14 step:13248 [D loss: 0.554513, acc.: 71.09%] [G loss: 0.618358]\n",
      "epoch:14 step:13249 [D loss: 0.510441, acc.: 77.34%] [G loss: 0.602762]\n",
      "epoch:14 step:13250 [D loss: 0.561904, acc.: 72.66%] [G loss: 0.663916]\n",
      "epoch:14 step:13251 [D loss: 0.564347, acc.: 64.84%] [G loss: 0.575078]\n",
      "epoch:14 step:13252 [D loss: 0.530256, acc.: 68.75%] [G loss: 0.741576]\n",
      "epoch:14 step:13253 [D loss: 0.525145, acc.: 75.00%] [G loss: 0.558433]\n",
      "epoch:14 step:13254 [D loss: 0.557110, acc.: 72.66%] [G loss: 0.600838]\n",
      "epoch:14 step:13255 [D loss: 0.664667, acc.: 60.16%] [G loss: 0.614305]\n",
      "epoch:14 step:13256 [D loss: 0.574311, acc.: 67.97%] [G loss: 0.628594]\n",
      "epoch:14 step:13257 [D loss: 0.583077, acc.: 67.19%] [G loss: 0.468275]\n",
      "epoch:14 step:13258 [D loss: 0.551890, acc.: 68.75%] [G loss: 0.487529]\n",
      "epoch:14 step:13259 [D loss: 0.518870, acc.: 70.31%] [G loss: 0.481205]\n",
      "epoch:14 step:13260 [D loss: 0.569018, acc.: 62.50%] [G loss: 0.624897]\n",
      "epoch:14 step:13261 [D loss: 0.624881, acc.: 60.94%] [G loss: 0.512233]\n",
      "epoch:14 step:13262 [D loss: 0.468406, acc.: 82.81%] [G loss: 0.567369]\n",
      "epoch:14 step:13263 [D loss: 0.524741, acc.: 71.09%] [G loss: 0.674214]\n",
      "epoch:14 step:13264 [D loss: 0.490378, acc.: 72.66%] [G loss: 0.814737]\n",
      "epoch:14 step:13265 [D loss: 0.619309, acc.: 64.84%] [G loss: 0.649264]\n",
      "epoch:14 step:13266 [D loss: 0.552701, acc.: 70.31%] [G loss: 0.586313]\n",
      "epoch:14 step:13267 [D loss: 0.544224, acc.: 71.09%] [G loss: 0.574970]\n",
      "epoch:14 step:13268 [D loss: 0.600406, acc.: 61.72%] [G loss: 0.507174]\n",
      "epoch:14 step:13269 [D loss: 0.563379, acc.: 66.41%] [G loss: 0.507183]\n",
      "epoch:14 step:13270 [D loss: 0.469272, acc.: 75.00%] [G loss: 0.723978]\n",
      "epoch:14 step:13271 [D loss: 0.587359, acc.: 68.75%] [G loss: 0.681564]\n",
      "epoch:14 step:13272 [D loss: 0.514411, acc.: 72.66%] [G loss: 0.610504]\n",
      "epoch:14 step:13273 [D loss: 0.437976, acc.: 75.78%] [G loss: 0.713703]\n",
      "epoch:14 step:13274 [D loss: 0.556598, acc.: 68.75%] [G loss: 0.730644]\n",
      "epoch:14 step:13275 [D loss: 0.557011, acc.: 67.19%] [G loss: 0.622185]\n",
      "epoch:14 step:13276 [D loss: 0.542056, acc.: 69.53%] [G loss: 0.652471]\n",
      "epoch:14 step:13277 [D loss: 0.540261, acc.: 73.44%] [G loss: 0.452538]\n",
      "epoch:14 step:13278 [D loss: 0.610438, acc.: 69.53%] [G loss: 0.622352]\n",
      "epoch:14 step:13279 [D loss: 0.545798, acc.: 69.53%] [G loss: 0.776078]\n",
      "epoch:14 step:13280 [D loss: 0.509760, acc.: 75.00%] [G loss: 0.753050]\n",
      "epoch:14 step:13281 [D loss: 0.574813, acc.: 68.75%] [G loss: 0.615420]\n",
      "epoch:14 step:13282 [D loss: 0.550312, acc.: 72.66%] [G loss: 0.681875]\n",
      "epoch:14 step:13283 [D loss: 0.551043, acc.: 71.88%] [G loss: 0.704670]\n",
      "epoch:14 step:13284 [D loss: 0.533371, acc.: 70.31%] [G loss: 0.570438]\n",
      "epoch:14 step:13285 [D loss: 0.571487, acc.: 67.19%] [G loss: 0.587339]\n",
      "epoch:14 step:13286 [D loss: 0.536163, acc.: 73.44%] [G loss: 0.552058]\n",
      "epoch:14 step:13287 [D loss: 0.589351, acc.: 66.41%] [G loss: 0.614219]\n",
      "epoch:14 step:13288 [D loss: 0.511995, acc.: 71.88%] [G loss: 0.525583]\n",
      "epoch:14 step:13289 [D loss: 0.504905, acc.: 75.00%] [G loss: 0.684254]\n",
      "epoch:14 step:13290 [D loss: 0.531077, acc.: 73.44%] [G loss: 0.739326]\n",
      "epoch:14 step:13291 [D loss: 0.518744, acc.: 71.88%] [G loss: 0.779596]\n",
      "epoch:14 step:13292 [D loss: 0.613237, acc.: 62.50%] [G loss: 0.492968]\n",
      "epoch:14 step:13293 [D loss: 0.594411, acc.: 61.72%] [G loss: 0.480641]\n",
      "epoch:14 step:13294 [D loss: 0.576590, acc.: 68.75%] [G loss: 0.489216]\n",
      "epoch:14 step:13295 [D loss: 0.479679, acc.: 76.56%] [G loss: 0.512698]\n",
      "epoch:14 step:13296 [D loss: 0.602893, acc.: 63.28%] [G loss: 0.366575]\n",
      "epoch:14 step:13297 [D loss: 0.577642, acc.: 67.97%] [G loss: 0.676761]\n",
      "epoch:14 step:13298 [D loss: 0.591026, acc.: 67.19%] [G loss: 0.475875]\n",
      "epoch:14 step:13299 [D loss: 0.567816, acc.: 67.97%] [G loss: 0.526149]\n",
      "epoch:14 step:13300 [D loss: 0.552605, acc.: 70.31%] [G loss: 0.542108]\n",
      "epoch:14 step:13301 [D loss: 0.605765, acc.: 64.84%] [G loss: 0.712237]\n",
      "epoch:14 step:13302 [D loss: 0.532731, acc.: 70.31%] [G loss: 0.761848]\n",
      "epoch:14 step:13303 [D loss: 0.531335, acc.: 72.66%] [G loss: 0.665588]\n",
      "epoch:14 step:13304 [D loss: 0.554034, acc.: 73.44%] [G loss: 0.770274]\n",
      "epoch:14 step:13305 [D loss: 0.664958, acc.: 60.16%] [G loss: 0.564264]\n",
      "epoch:14 step:13306 [D loss: 0.567976, acc.: 65.62%] [G loss: 0.600814]\n",
      "epoch:14 step:13307 [D loss: 0.590428, acc.: 70.31%] [G loss: 0.434361]\n",
      "epoch:14 step:13308 [D loss: 0.540566, acc.: 69.53%] [G loss: 0.622336]\n",
      "epoch:14 step:13309 [D loss: 0.496211, acc.: 79.69%] [G loss: 0.534272]\n",
      "epoch:14 step:13310 [D loss: 0.467026, acc.: 82.03%] [G loss: 0.557209]\n",
      "epoch:14 step:13311 [D loss: 0.559716, acc.: 75.00%] [G loss: 0.617701]\n",
      "epoch:14 step:13312 [D loss: 0.439928, acc.: 80.47%] [G loss: 0.855991]\n",
      "epoch:14 step:13313 [D loss: 0.568305, acc.: 72.66%] [G loss: 0.729565]\n",
      "epoch:14 step:13314 [D loss: 0.569462, acc.: 67.19%] [G loss: 0.501956]\n",
      "epoch:14 step:13315 [D loss: 0.540151, acc.: 75.00%] [G loss: 0.581507]\n",
      "epoch:14 step:13316 [D loss: 0.483392, acc.: 75.78%] [G loss: 0.700380]\n",
      "epoch:14 step:13317 [D loss: 0.526589, acc.: 75.00%] [G loss: 0.561771]\n",
      "epoch:14 step:13318 [D loss: 0.618752, acc.: 64.84%] [G loss: 0.608287]\n",
      "epoch:14 step:13319 [D loss: 0.528162, acc.: 75.78%] [G loss: 0.527788]\n",
      "epoch:14 step:13320 [D loss: 0.570063, acc.: 69.53%] [G loss: 0.639685]\n",
      "epoch:14 step:13321 [D loss: 0.634388, acc.: 60.16%] [G loss: 0.447686]\n",
      "epoch:14 step:13322 [D loss: 0.585600, acc.: 66.41%] [G loss: 0.636871]\n",
      "epoch:14 step:13323 [D loss: 0.476784, acc.: 75.78%] [G loss: 0.684829]\n",
      "epoch:14 step:13324 [D loss: 0.484862, acc.: 73.44%] [G loss: 0.752239]\n",
      "epoch:14 step:13325 [D loss: 0.496954, acc.: 81.25%] [G loss: 0.738373]\n",
      "epoch:14 step:13326 [D loss: 0.420777, acc.: 82.03%] [G loss: 0.859103]\n",
      "epoch:14 step:13327 [D loss: 0.518947, acc.: 76.56%] [G loss: 0.763516]\n",
      "epoch:14 step:13328 [D loss: 0.637352, acc.: 67.97%] [G loss: 0.679475]\n",
      "epoch:14 step:13329 [D loss: 0.665000, acc.: 57.81%] [G loss: 0.408450]\n",
      "epoch:14 step:13330 [D loss: 0.515954, acc.: 71.88%] [G loss: 0.468523]\n",
      "epoch:14 step:13331 [D loss: 0.520938, acc.: 69.53%] [G loss: 0.545240]\n",
      "epoch:14 step:13332 [D loss: 0.645184, acc.: 61.72%] [G loss: 0.508596]\n",
      "epoch:14 step:13333 [D loss: 0.620215, acc.: 64.06%] [G loss: 0.467585]\n",
      "epoch:14 step:13334 [D loss: 0.512560, acc.: 71.09%] [G loss: 0.693244]\n",
      "epoch:14 step:13335 [D loss: 0.527602, acc.: 71.88%] [G loss: 0.546494]\n",
      "epoch:14 step:13336 [D loss: 0.547322, acc.: 71.88%] [G loss: 0.494377]\n",
      "epoch:14 step:13337 [D loss: 0.473770, acc.: 83.59%] [G loss: 0.697423]\n",
      "epoch:14 step:13338 [D loss: 0.626807, acc.: 64.06%] [G loss: 0.627776]\n",
      "epoch:14 step:13339 [D loss: 0.580056, acc.: 67.97%] [G loss: 0.580766]\n",
      "epoch:14 step:13340 [D loss: 0.532756, acc.: 72.66%] [G loss: 0.650545]\n",
      "epoch:14 step:13341 [D loss: 0.493756, acc.: 75.78%] [G loss: 0.780062]\n",
      "epoch:14 step:13342 [D loss: 0.587330, acc.: 69.53%] [G loss: 0.655181]\n",
      "epoch:14 step:13343 [D loss: 0.553704, acc.: 67.97%] [G loss: 0.662195]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13344 [D loss: 0.615312, acc.: 63.28%] [G loss: 0.520338]\n",
      "epoch:14 step:13345 [D loss: 0.532371, acc.: 73.44%] [G loss: 0.579110]\n",
      "epoch:14 step:13346 [D loss: 0.627959, acc.: 57.03%] [G loss: 0.484785]\n",
      "epoch:14 step:13347 [D loss: 0.543642, acc.: 72.66%] [G loss: 0.641644]\n",
      "epoch:14 step:13348 [D loss: 0.500955, acc.: 79.69%] [G loss: 0.542171]\n",
      "epoch:14 step:13349 [D loss: 0.461019, acc.: 81.25%] [G loss: 0.662497]\n",
      "epoch:14 step:13350 [D loss: 0.460589, acc.: 83.59%] [G loss: 0.820603]\n",
      "epoch:14 step:13351 [D loss: 0.575040, acc.: 69.53%] [G loss: 0.770048]\n",
      "epoch:14 step:13352 [D loss: 0.532653, acc.: 75.00%] [G loss: 0.645968]\n",
      "epoch:14 step:13353 [D loss: 0.664697, acc.: 61.72%] [G loss: 0.520784]\n",
      "epoch:14 step:13354 [D loss: 0.534038, acc.: 67.19%] [G loss: 0.655886]\n",
      "epoch:14 step:13355 [D loss: 0.519172, acc.: 71.88%] [G loss: 0.541146]\n",
      "epoch:14 step:13356 [D loss: 0.587822, acc.: 69.53%] [G loss: 0.499468]\n",
      "epoch:14 step:13357 [D loss: 0.528180, acc.: 68.75%] [G loss: 0.689383]\n",
      "epoch:14 step:13358 [D loss: 0.561772, acc.: 65.62%] [G loss: 0.546146]\n",
      "epoch:14 step:13359 [D loss: 0.503824, acc.: 75.78%] [G loss: 0.644304]\n",
      "epoch:14 step:13360 [D loss: 0.515039, acc.: 72.66%] [G loss: 0.571409]\n",
      "epoch:14 step:13361 [D loss: 0.535205, acc.: 66.41%] [G loss: 0.636029]\n",
      "epoch:14 step:13362 [D loss: 0.490656, acc.: 73.44%] [G loss: 0.599550]\n",
      "epoch:14 step:13363 [D loss: 0.513172, acc.: 79.69%] [G loss: 0.680103]\n",
      "epoch:14 step:13364 [D loss: 0.555479, acc.: 70.31%] [G loss: 0.608611]\n",
      "epoch:14 step:13365 [D loss: 0.515009, acc.: 73.44%] [G loss: 0.742871]\n",
      "epoch:14 step:13366 [D loss: 0.522923, acc.: 71.88%] [G loss: 0.666247]\n",
      "epoch:14 step:13367 [D loss: 0.582413, acc.: 71.09%] [G loss: 0.604144]\n",
      "epoch:14 step:13368 [D loss: 0.651728, acc.: 65.62%] [G loss: 0.818628]\n",
      "epoch:14 step:13369 [D loss: 0.654119, acc.: 57.03%] [G loss: 0.512050]\n",
      "epoch:14 step:13370 [D loss: 0.491839, acc.: 76.56%] [G loss: 0.577304]\n",
      "epoch:14 step:13371 [D loss: 0.620799, acc.: 65.62%] [G loss: 0.455965]\n",
      "epoch:14 step:13372 [D loss: 0.518361, acc.: 71.88%] [G loss: 0.638312]\n",
      "epoch:14 step:13373 [D loss: 0.535991, acc.: 71.88%] [G loss: 0.652602]\n",
      "epoch:14 step:13374 [D loss: 0.548150, acc.: 71.88%] [G loss: 0.633688]\n",
      "epoch:14 step:13375 [D loss: 0.548278, acc.: 67.97%] [G loss: 0.529062]\n",
      "epoch:14 step:13376 [D loss: 0.561518, acc.: 64.84%] [G loss: 0.503370]\n",
      "epoch:14 step:13377 [D loss: 0.520819, acc.: 71.09%] [G loss: 0.599008]\n",
      "epoch:14 step:13378 [D loss: 0.589847, acc.: 67.97%] [G loss: 0.616657]\n",
      "epoch:14 step:13379 [D loss: 0.524603, acc.: 70.31%] [G loss: 0.457958]\n",
      "epoch:14 step:13380 [D loss: 0.520453, acc.: 71.88%] [G loss: 0.670758]\n",
      "epoch:14 step:13381 [D loss: 0.619914, acc.: 64.84%] [G loss: 0.570858]\n",
      "epoch:14 step:13382 [D loss: 0.521070, acc.: 71.09%] [G loss: 0.731329]\n",
      "epoch:14 step:13383 [D loss: 0.537320, acc.: 72.66%] [G loss: 0.551833]\n",
      "epoch:14 step:13384 [D loss: 0.537735, acc.: 71.88%] [G loss: 0.572535]\n",
      "epoch:14 step:13385 [D loss: 0.596721, acc.: 65.62%] [G loss: 0.473811]\n",
      "epoch:14 step:13386 [D loss: 0.560617, acc.: 70.31%] [G loss: 0.534311]\n",
      "epoch:14 step:13387 [D loss: 0.517555, acc.: 71.09%] [G loss: 0.589804]\n",
      "epoch:14 step:13388 [D loss: 0.532153, acc.: 71.88%] [G loss: 0.565015]\n",
      "epoch:14 step:13389 [D loss: 0.535203, acc.: 71.88%] [G loss: 0.668220]\n",
      "epoch:14 step:13390 [D loss: 0.528876, acc.: 67.97%] [G loss: 0.642899]\n",
      "epoch:14 step:13391 [D loss: 0.493978, acc.: 75.78%] [G loss: 0.606087]\n",
      "epoch:14 step:13392 [D loss: 0.499325, acc.: 75.78%] [G loss: 0.618436]\n",
      "epoch:14 step:13393 [D loss: 0.580406, acc.: 68.75%] [G loss: 0.523983]\n",
      "epoch:14 step:13394 [D loss: 0.460644, acc.: 77.34%] [G loss: 0.664648]\n",
      "epoch:14 step:13395 [D loss: 0.628671, acc.: 62.50%] [G loss: 0.500030]\n",
      "epoch:14 step:13396 [D loss: 0.571476, acc.: 65.62%] [G loss: 0.503523]\n",
      "epoch:14 step:13397 [D loss: 0.500415, acc.: 72.66%] [G loss: 0.547295]\n",
      "epoch:14 step:13398 [D loss: 0.552199, acc.: 62.50%] [G loss: 0.487045]\n",
      "epoch:14 step:13399 [D loss: 0.579804, acc.: 68.75%] [G loss: 0.616786]\n",
      "epoch:14 step:13400 [D loss: 0.532041, acc.: 78.12%] [G loss: 0.570343]\n",
      "##############\n",
      "[3.18633861 1.29622811 6.48328188 4.89130228 3.72413958 5.81729897\n",
      " 4.60611032 5.05638163 4.65468509 4.21525289]\n",
      "##########\n",
      "epoch:14 step:13401 [D loss: 0.511415, acc.: 76.56%] [G loss: 0.606581]\n",
      "epoch:14 step:13402 [D loss: 0.518347, acc.: 71.88%] [G loss: 0.614662]\n",
      "epoch:14 step:13403 [D loss: 0.550727, acc.: 70.31%] [G loss: 0.674770]\n",
      "epoch:14 step:13404 [D loss: 0.487441, acc.: 78.12%] [G loss: 0.653587]\n",
      "epoch:14 step:13405 [D loss: 0.607320, acc.: 63.28%] [G loss: 0.654354]\n",
      "epoch:14 step:13406 [D loss: 0.560048, acc.: 67.19%] [G loss: 0.609284]\n",
      "epoch:14 step:13407 [D loss: 0.526726, acc.: 71.88%] [G loss: 0.620806]\n",
      "epoch:14 step:13408 [D loss: 0.593504, acc.: 66.41%] [G loss: 0.736371]\n",
      "epoch:14 step:13409 [D loss: 0.603625, acc.: 63.28%] [G loss: 0.422180]\n",
      "epoch:14 step:13410 [D loss: 0.551528, acc.: 69.53%] [G loss: 0.545403]\n",
      "epoch:14 step:13411 [D loss: 0.588233, acc.: 67.97%] [G loss: 0.651875]\n",
      "epoch:14 step:13412 [D loss: 0.635392, acc.: 61.72%] [G loss: 0.473053]\n",
      "epoch:14 step:13413 [D loss: 0.596986, acc.: 63.28%] [G loss: 0.581611]\n",
      "epoch:14 step:13414 [D loss: 0.478637, acc.: 75.00%] [G loss: 0.599845]\n",
      "epoch:14 step:13415 [D loss: 0.564358, acc.: 69.53%] [G loss: 0.596518]\n",
      "epoch:14 step:13416 [D loss: 0.533973, acc.: 69.53%] [G loss: 0.562704]\n",
      "epoch:14 step:13417 [D loss: 0.522474, acc.: 69.53%] [G loss: 0.537728]\n",
      "epoch:14 step:13418 [D loss: 0.518480, acc.: 75.00%] [G loss: 0.648816]\n",
      "epoch:14 step:13419 [D loss: 0.628866, acc.: 66.41%] [G loss: 0.616001]\n",
      "epoch:14 step:13420 [D loss: 0.528152, acc.: 74.22%] [G loss: 0.532338]\n",
      "epoch:14 step:13421 [D loss: 0.532782, acc.: 73.44%] [G loss: 0.649010]\n",
      "epoch:14 step:13422 [D loss: 0.466566, acc.: 81.25%] [G loss: 0.581292]\n",
      "epoch:14 step:13423 [D loss: 0.495555, acc.: 76.56%] [G loss: 0.686290]\n",
      "epoch:14 step:13424 [D loss: 0.531830, acc.: 68.75%] [G loss: 0.699921]\n",
      "epoch:14 step:13425 [D loss: 0.502657, acc.: 77.34%] [G loss: 0.600988]\n",
      "epoch:14 step:13426 [D loss: 0.646494, acc.: 61.72%] [G loss: 0.485573]\n",
      "epoch:14 step:13427 [D loss: 0.537356, acc.: 67.19%] [G loss: 0.586705]\n",
      "epoch:14 step:13428 [D loss: 0.495523, acc.: 79.69%] [G loss: 0.798101]\n",
      "epoch:14 step:13429 [D loss: 0.484037, acc.: 72.66%] [G loss: 0.689956]\n",
      "epoch:14 step:13430 [D loss: 0.455949, acc.: 78.12%] [G loss: 0.823661]\n",
      "epoch:14 step:13431 [D loss: 0.515413, acc.: 77.34%] [G loss: 1.000700]\n",
      "epoch:14 step:13432 [D loss: 0.482506, acc.: 74.22%] [G loss: 0.984765]\n",
      "epoch:14 step:13433 [D loss: 0.471045, acc.: 82.81%] [G loss: 0.886294]\n",
      "epoch:14 step:13434 [D loss: 0.717264, acc.: 59.38%] [G loss: 0.725381]\n",
      "epoch:14 step:13435 [D loss: 0.591645, acc.: 67.19%] [G loss: 0.735240]\n",
      "epoch:14 step:13436 [D loss: 0.532844, acc.: 69.53%] [G loss: 0.663513]\n",
      "epoch:14 step:13437 [D loss: 0.490861, acc.: 73.44%] [G loss: 0.582361]\n",
      "epoch:14 step:13438 [D loss: 0.522569, acc.: 70.31%] [G loss: 0.600574]\n",
      "epoch:14 step:13439 [D loss: 0.496610, acc.: 71.09%] [G loss: 0.588540]\n",
      "epoch:14 step:13440 [D loss: 0.512359, acc.: 75.78%] [G loss: 0.623574]\n",
      "epoch:14 step:13441 [D loss: 0.636103, acc.: 62.50%] [G loss: 0.483322]\n",
      "epoch:14 step:13442 [D loss: 0.523759, acc.: 72.66%] [G loss: 0.700131]\n",
      "epoch:14 step:13443 [D loss: 0.573788, acc.: 64.06%] [G loss: 0.581246]\n",
      "epoch:14 step:13444 [D loss: 0.456676, acc.: 75.78%] [G loss: 0.673022]\n",
      "epoch:14 step:13445 [D loss: 0.567689, acc.: 70.31%] [G loss: 0.783012]\n",
      "epoch:14 step:13446 [D loss: 0.516422, acc.: 76.56%] [G loss: 0.801043]\n",
      "epoch:14 step:13447 [D loss: 0.521679, acc.: 71.88%] [G loss: 0.736643]\n",
      "epoch:14 step:13448 [D loss: 0.574042, acc.: 67.19%] [G loss: 0.530986]\n",
      "epoch:14 step:13449 [D loss: 0.543708, acc.: 73.44%] [G loss: 0.491924]\n",
      "epoch:14 step:13450 [D loss: 0.517940, acc.: 70.31%] [G loss: 0.547281]\n",
      "epoch:14 step:13451 [D loss: 0.478027, acc.: 75.78%] [G loss: 0.731485]\n",
      "epoch:14 step:13452 [D loss: 0.503068, acc.: 72.66%] [G loss: 0.787086]\n",
      "epoch:14 step:13453 [D loss: 0.507515, acc.: 72.66%] [G loss: 0.774141]\n",
      "epoch:14 step:13454 [D loss: 0.508891, acc.: 70.31%] [G loss: 0.760453]\n",
      "epoch:14 step:13455 [D loss: 0.507431, acc.: 73.44%] [G loss: 0.614732]\n",
      "epoch:14 step:13456 [D loss: 0.506054, acc.: 71.88%] [G loss: 0.665371]\n",
      "epoch:14 step:13457 [D loss: 0.588638, acc.: 65.62%] [G loss: 0.559185]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13458 [D loss: 0.482639, acc.: 79.69%] [G loss: 0.768623]\n",
      "epoch:14 step:13459 [D loss: 0.571790, acc.: 71.09%] [G loss: 0.707834]\n",
      "epoch:14 step:13460 [D loss: 0.708686, acc.: 54.69%] [G loss: 0.748065]\n",
      "epoch:14 step:13461 [D loss: 0.488823, acc.: 78.91%] [G loss: 0.621661]\n",
      "epoch:14 step:13462 [D loss: 0.492007, acc.: 71.09%] [G loss: 0.773889]\n",
      "epoch:14 step:13463 [D loss: 0.542995, acc.: 67.97%] [G loss: 0.591028]\n",
      "epoch:14 step:13464 [D loss: 0.526867, acc.: 71.09%] [G loss: 0.761694]\n",
      "epoch:14 step:13465 [D loss: 0.486224, acc.: 78.12%] [G loss: 0.765016]\n",
      "epoch:14 step:13466 [D loss: 0.626334, acc.: 64.84%] [G loss: 0.736145]\n",
      "epoch:14 step:13467 [D loss: 0.739459, acc.: 59.38%] [G loss: 0.570013]\n",
      "epoch:14 step:13468 [D loss: 0.478205, acc.: 76.56%] [G loss: 0.661203]\n",
      "epoch:14 step:13469 [D loss: 0.535098, acc.: 69.53%] [G loss: 0.597046]\n",
      "epoch:14 step:13470 [D loss: 0.601236, acc.: 63.28%] [G loss: 0.619090]\n",
      "epoch:14 step:13471 [D loss: 0.542408, acc.: 73.44%] [G loss: 0.593554]\n",
      "epoch:14 step:13472 [D loss: 0.425342, acc.: 82.03%] [G loss: 0.758819]\n",
      "epoch:14 step:13473 [D loss: 0.544161, acc.: 71.88%] [G loss: 0.650537]\n",
      "epoch:14 step:13474 [D loss: 0.580109, acc.: 64.84%] [G loss: 0.628330]\n",
      "epoch:14 step:13475 [D loss: 0.469047, acc.: 76.56%] [G loss: 0.831710]\n",
      "epoch:14 step:13476 [D loss: 0.485355, acc.: 78.91%] [G loss: 0.659151]\n",
      "epoch:14 step:13477 [D loss: 0.447285, acc.: 75.78%] [G loss: 0.837162]\n",
      "epoch:14 step:13478 [D loss: 0.498662, acc.: 71.88%] [G loss: 0.766037]\n",
      "epoch:14 step:13479 [D loss: 0.487898, acc.: 74.22%] [G loss: 0.560158]\n",
      "epoch:14 step:13480 [D loss: 0.515538, acc.: 76.56%] [G loss: 0.797412]\n",
      "epoch:14 step:13481 [D loss: 0.520818, acc.: 72.66%] [G loss: 0.542958]\n",
      "epoch:14 step:13482 [D loss: 0.511607, acc.: 71.88%] [G loss: 0.568238]\n",
      "epoch:14 step:13483 [D loss: 0.576992, acc.: 71.09%] [G loss: 0.511670]\n",
      "epoch:14 step:13484 [D loss: 0.515489, acc.: 74.22%] [G loss: 0.582304]\n",
      "epoch:14 step:13485 [D loss: 0.608013, acc.: 63.28%] [G loss: 0.627884]\n",
      "epoch:14 step:13486 [D loss: 0.510453, acc.: 71.09%] [G loss: 0.590731]\n",
      "epoch:14 step:13487 [D loss: 0.546492, acc.: 71.88%] [G loss: 0.556500]\n",
      "epoch:14 step:13488 [D loss: 0.534549, acc.: 77.34%] [G loss: 0.745669]\n",
      "epoch:14 step:13489 [D loss: 0.549739, acc.: 74.22%] [G loss: 0.668855]\n",
      "epoch:14 step:13490 [D loss: 0.517350, acc.: 73.44%] [G loss: 0.679907]\n",
      "epoch:14 step:13491 [D loss: 0.542961, acc.: 73.44%] [G loss: 0.678627]\n",
      "epoch:14 step:13492 [D loss: 0.500903, acc.: 76.56%] [G loss: 0.671734]\n",
      "epoch:14 step:13493 [D loss: 0.544709, acc.: 71.09%] [G loss: 0.676215]\n",
      "epoch:14 step:13494 [D loss: 0.715323, acc.: 59.38%] [G loss: 0.477641]\n",
      "epoch:14 step:13495 [D loss: 0.564183, acc.: 70.31%] [G loss: 0.442004]\n",
      "epoch:14 step:13496 [D loss: 0.554633, acc.: 67.97%] [G loss: 0.506979]\n",
      "epoch:14 step:13497 [D loss: 0.628175, acc.: 60.94%] [G loss: 0.591559]\n",
      "epoch:14 step:13498 [D loss: 0.547626, acc.: 67.97%] [G loss: 0.463487]\n",
      "epoch:14 step:13499 [D loss: 0.477946, acc.: 74.22%] [G loss: 0.712811]\n",
      "epoch:14 step:13500 [D loss: 0.536467, acc.: 71.88%] [G loss: 0.746280]\n",
      "epoch:14 step:13501 [D loss: 0.514982, acc.: 73.44%] [G loss: 0.609295]\n",
      "epoch:14 step:13502 [D loss: 0.579625, acc.: 69.53%] [G loss: 0.626468]\n",
      "epoch:14 step:13503 [D loss: 0.528994, acc.: 75.00%] [G loss: 0.765420]\n",
      "epoch:14 step:13504 [D loss: 0.637497, acc.: 64.06%] [G loss: 0.583761]\n",
      "epoch:14 step:13505 [D loss: 0.582470, acc.: 62.50%] [G loss: 0.541715]\n",
      "epoch:14 step:13506 [D loss: 0.567202, acc.: 69.53%] [G loss: 0.589795]\n",
      "epoch:14 step:13507 [D loss: 0.519245, acc.: 73.44%] [G loss: 0.604284]\n",
      "epoch:14 step:13508 [D loss: 0.555560, acc.: 70.31%] [G loss: 0.550662]\n",
      "epoch:14 step:13509 [D loss: 0.558302, acc.: 65.62%] [G loss: 0.435473]\n",
      "epoch:14 step:13510 [D loss: 0.461193, acc.: 75.00%] [G loss: 0.705337]\n",
      "epoch:14 step:13511 [D loss: 0.561248, acc.: 69.53%] [G loss: 0.589288]\n",
      "epoch:14 step:13512 [D loss: 0.596332, acc.: 64.06%] [G loss: 0.527852]\n",
      "epoch:14 step:13513 [D loss: 0.530361, acc.: 71.09%] [G loss: 0.657631]\n",
      "epoch:14 step:13514 [D loss: 0.560776, acc.: 65.62%] [G loss: 0.513422]\n",
      "epoch:14 step:13515 [D loss: 0.603800, acc.: 62.50%] [G loss: 0.506249]\n",
      "epoch:14 step:13516 [D loss: 0.507885, acc.: 72.66%] [G loss: 0.542184]\n",
      "epoch:14 step:13517 [D loss: 0.545998, acc.: 75.78%] [G loss: 0.727194]\n",
      "epoch:14 step:13518 [D loss: 0.666099, acc.: 59.38%] [G loss: 0.691051]\n",
      "epoch:14 step:13519 [D loss: 0.684994, acc.: 57.81%] [G loss: 0.388104]\n",
      "epoch:14 step:13520 [D loss: 0.451304, acc.: 82.81%] [G loss: 0.587907]\n",
      "epoch:14 step:13521 [D loss: 0.589508, acc.: 70.31%] [G loss: 0.465175]\n",
      "epoch:14 step:13522 [D loss: 0.608925, acc.: 64.06%] [G loss: 0.671017]\n",
      "epoch:14 step:13523 [D loss: 0.508637, acc.: 71.09%] [G loss: 0.578419]\n",
      "epoch:14 step:13524 [D loss: 0.504034, acc.: 77.34%] [G loss: 0.621285]\n",
      "epoch:14 step:13525 [D loss: 0.569560, acc.: 71.09%] [G loss: 0.621051]\n",
      "epoch:14 step:13526 [D loss: 0.564446, acc.: 68.75%] [G loss: 0.581071]\n",
      "epoch:14 step:13527 [D loss: 0.573521, acc.: 64.84%] [G loss: 0.529320]\n",
      "epoch:14 step:13528 [D loss: 0.612145, acc.: 63.28%] [G loss: 0.504984]\n",
      "epoch:14 step:13529 [D loss: 0.587070, acc.: 66.41%] [G loss: 0.585252]\n",
      "epoch:14 step:13530 [D loss: 0.609149, acc.: 62.50%] [G loss: 0.586613]\n",
      "epoch:14 step:13531 [D loss: 0.527078, acc.: 70.31%] [G loss: 0.573431]\n",
      "epoch:14 step:13532 [D loss: 0.524030, acc.: 72.66%] [G loss: 0.723356]\n",
      "epoch:14 step:13533 [D loss: 0.662414, acc.: 63.28%] [G loss: 0.722573]\n",
      "epoch:14 step:13534 [D loss: 0.533988, acc.: 72.66%] [G loss: 0.762270]\n",
      "epoch:14 step:13535 [D loss: 0.601528, acc.: 67.19%] [G loss: 0.786233]\n",
      "epoch:14 step:13536 [D loss: 0.632421, acc.: 63.28%] [G loss: 0.647551]\n",
      "epoch:14 step:13537 [D loss: 0.571836, acc.: 65.62%] [G loss: 0.538692]\n",
      "epoch:14 step:13538 [D loss: 0.591148, acc.: 60.16%] [G loss: 0.581283]\n",
      "epoch:14 step:13539 [D loss: 0.542962, acc.: 71.88%] [G loss: 0.492480]\n",
      "epoch:14 step:13540 [D loss: 0.571773, acc.: 65.62%] [G loss: 0.496659]\n",
      "epoch:14 step:13541 [D loss: 0.595744, acc.: 64.84%] [G loss: 0.471543]\n",
      "epoch:14 step:13542 [D loss: 0.585746, acc.: 68.75%] [G loss: 0.605909]\n",
      "epoch:14 step:13543 [D loss: 0.525682, acc.: 72.66%] [G loss: 0.671570]\n",
      "epoch:14 step:13544 [D loss: 0.528984, acc.: 71.09%] [G loss: 0.750302]\n",
      "epoch:14 step:13545 [D loss: 0.495123, acc.: 77.34%] [G loss: 0.715164]\n",
      "epoch:14 step:13546 [D loss: 0.498329, acc.: 75.00%] [G loss: 0.779342]\n",
      "epoch:14 step:13547 [D loss: 0.463343, acc.: 82.03%] [G loss: 0.638812]\n",
      "epoch:14 step:13548 [D loss: 0.475470, acc.: 77.34%] [G loss: 0.758581]\n",
      "epoch:14 step:13549 [D loss: 0.504716, acc.: 74.22%] [G loss: 0.642564]\n",
      "epoch:14 step:13550 [D loss: 0.562744, acc.: 65.62%] [G loss: 0.590538]\n",
      "epoch:14 step:13551 [D loss: 0.574883, acc.: 71.09%] [G loss: 0.542930]\n",
      "epoch:14 step:13552 [D loss: 0.514155, acc.: 73.44%] [G loss: 0.602852]\n",
      "epoch:14 step:13553 [D loss: 0.507597, acc.: 77.34%] [G loss: 0.616217]\n",
      "epoch:14 step:13554 [D loss: 0.561535, acc.: 70.31%] [G loss: 0.706862]\n",
      "epoch:14 step:13555 [D loss: 0.670491, acc.: 64.84%] [G loss: 0.500162]\n",
      "epoch:14 step:13556 [D loss: 0.582649, acc.: 67.97%] [G loss: 0.518071]\n",
      "epoch:14 step:13557 [D loss: 0.483324, acc.: 74.22%] [G loss: 0.603751]\n",
      "epoch:14 step:13558 [D loss: 0.542087, acc.: 68.75%] [G loss: 0.689549]\n",
      "epoch:14 step:13559 [D loss: 0.554085, acc.: 67.97%] [G loss: 0.690118]\n",
      "epoch:14 step:13560 [D loss: 0.588480, acc.: 65.62%] [G loss: 0.612934]\n",
      "epoch:14 step:13561 [D loss: 0.536434, acc.: 71.88%] [G loss: 0.549073]\n",
      "epoch:14 step:13562 [D loss: 0.551421, acc.: 71.88%] [G loss: 0.716070]\n",
      "epoch:14 step:13563 [D loss: 0.593450, acc.: 66.41%] [G loss: 0.517516]\n",
      "epoch:14 step:13564 [D loss: 0.504083, acc.: 75.00%] [G loss: 0.759037]\n",
      "epoch:14 step:13565 [D loss: 0.533865, acc.: 70.31%] [G loss: 0.665976]\n",
      "epoch:14 step:13566 [D loss: 0.546948, acc.: 66.41%] [G loss: 0.827679]\n",
      "epoch:14 step:13567 [D loss: 0.549165, acc.: 75.00%] [G loss: 0.768752]\n",
      "epoch:14 step:13568 [D loss: 0.526025, acc.: 72.66%] [G loss: 0.761703]\n",
      "epoch:14 step:13569 [D loss: 0.403559, acc.: 81.25%] [G loss: 0.846694]\n",
      "epoch:14 step:13570 [D loss: 0.501498, acc.: 73.44%] [G loss: 0.811821]\n",
      "epoch:14 step:13571 [D loss: 0.589167, acc.: 67.19%] [G loss: 0.677703]\n",
      "epoch:14 step:13572 [D loss: 0.559251, acc.: 74.22%] [G loss: 0.678250]\n",
      "epoch:14 step:13573 [D loss: 0.550302, acc.: 70.31%] [G loss: 0.505762]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13574 [D loss: 0.618827, acc.: 64.84%] [G loss: 0.603658]\n",
      "epoch:14 step:13575 [D loss: 0.498508, acc.: 78.12%] [G loss: 0.650380]\n",
      "epoch:14 step:13576 [D loss: 0.599121, acc.: 68.75%] [G loss: 0.622255]\n",
      "epoch:14 step:13577 [D loss: 0.592386, acc.: 66.41%] [G loss: 0.528719]\n",
      "epoch:14 step:13578 [D loss: 0.498174, acc.: 74.22%] [G loss: 0.667706]\n",
      "epoch:14 step:13579 [D loss: 0.520446, acc.: 77.34%] [G loss: 0.791340]\n",
      "epoch:14 step:13580 [D loss: 0.559266, acc.: 70.31%] [G loss: 0.627189]\n",
      "epoch:14 step:13581 [D loss: 0.585889, acc.: 65.62%] [G loss: 0.588249]\n",
      "epoch:14 step:13582 [D loss: 0.547929, acc.: 71.88%] [G loss: 0.605481]\n",
      "epoch:14 step:13583 [D loss: 0.602182, acc.: 65.62%] [G loss: 0.519608]\n",
      "epoch:14 step:13584 [D loss: 0.589925, acc.: 65.62%] [G loss: 0.618397]\n",
      "epoch:14 step:13585 [D loss: 0.544665, acc.: 70.31%] [G loss: 0.640044]\n",
      "epoch:14 step:13586 [D loss: 0.565820, acc.: 69.53%] [G loss: 0.559940]\n",
      "epoch:14 step:13587 [D loss: 0.554952, acc.: 68.75%] [G loss: 0.671277]\n",
      "epoch:14 step:13588 [D loss: 0.527393, acc.: 74.22%] [G loss: 0.649601]\n",
      "epoch:14 step:13589 [D loss: 0.494244, acc.: 76.56%] [G loss: 0.740920]\n",
      "epoch:14 step:13590 [D loss: 0.475808, acc.: 81.25%] [G loss: 0.865395]\n",
      "epoch:14 step:13591 [D loss: 0.628962, acc.: 66.41%] [G loss: 0.587145]\n",
      "epoch:14 step:13592 [D loss: 0.547638, acc.: 68.75%] [G loss: 0.660874]\n",
      "epoch:14 step:13593 [D loss: 0.483365, acc.: 71.88%] [G loss: 0.644599]\n",
      "epoch:14 step:13594 [D loss: 0.554148, acc.: 72.66%] [G loss: 0.769571]\n",
      "epoch:14 step:13595 [D loss: 0.623602, acc.: 69.53%] [G loss: 0.531714]\n",
      "epoch:14 step:13596 [D loss: 0.522580, acc.: 75.00%] [G loss: 0.433722]\n",
      "epoch:14 step:13597 [D loss: 0.557742, acc.: 70.31%] [G loss: 0.510170]\n",
      "epoch:14 step:13598 [D loss: 0.566558, acc.: 74.22%] [G loss: 0.520580]\n",
      "epoch:14 step:13599 [D loss: 0.510099, acc.: 80.47%] [G loss: 0.638394]\n",
      "epoch:14 step:13600 [D loss: 0.598509, acc.: 64.06%] [G loss: 0.577029]\n",
      "##############\n",
      "[3.20364065 1.26428227 6.44649478 5.23871229 3.55740282 5.96786719\n",
      " 4.78974491 4.77085649 4.90444796 4.07306164]\n",
      "##########\n",
      "epoch:14 step:13601 [D loss: 0.582420, acc.: 67.19%] [G loss: 0.572022]\n",
      "epoch:14 step:13602 [D loss: 0.551755, acc.: 64.84%] [G loss: 0.635669]\n",
      "epoch:14 step:13603 [D loss: 0.531173, acc.: 70.31%] [G loss: 0.657127]\n",
      "epoch:14 step:13604 [D loss: 0.521846, acc.: 73.44%] [G loss: 0.582465]\n",
      "epoch:14 step:13605 [D loss: 0.595484, acc.: 63.28%] [G loss: 0.573299]\n",
      "epoch:14 step:13606 [D loss: 0.549913, acc.: 67.19%] [G loss: 0.525631]\n",
      "epoch:14 step:13607 [D loss: 0.506350, acc.: 71.09%] [G loss: 0.824566]\n",
      "epoch:14 step:13608 [D loss: 0.546992, acc.: 71.88%] [G loss: 0.616855]\n",
      "epoch:14 step:13609 [D loss: 0.541149, acc.: 75.00%] [G loss: 0.585817]\n",
      "epoch:14 step:13610 [D loss: 0.598571, acc.: 70.31%] [G loss: 0.554531]\n",
      "epoch:14 step:13611 [D loss: 0.606372, acc.: 69.53%] [G loss: 0.578879]\n",
      "epoch:14 step:13612 [D loss: 0.574897, acc.: 70.31%] [G loss: 0.510095]\n",
      "epoch:14 step:13613 [D loss: 0.501027, acc.: 77.34%] [G loss: 0.535838]\n",
      "epoch:14 step:13614 [D loss: 0.630634, acc.: 71.09%] [G loss: 0.490647]\n",
      "epoch:14 step:13615 [D loss: 0.586825, acc.: 62.50%] [G loss: 0.636986]\n",
      "epoch:14 step:13616 [D loss: 0.518303, acc.: 73.44%] [G loss: 0.861556]\n",
      "epoch:14 step:13617 [D loss: 0.474430, acc.: 75.00%] [G loss: 0.891192]\n",
      "epoch:14 step:13618 [D loss: 0.588678, acc.: 67.97%] [G loss: 0.535589]\n",
      "epoch:14 step:13619 [D loss: 0.622477, acc.: 62.50%] [G loss: 0.582269]\n",
      "epoch:14 step:13620 [D loss: 0.592582, acc.: 64.84%] [G loss: 0.551818]\n",
      "epoch:14 step:13621 [D loss: 0.536509, acc.: 74.22%] [G loss: 0.520887]\n",
      "epoch:14 step:13622 [D loss: 0.489034, acc.: 80.47%] [G loss: 0.701704]\n",
      "epoch:14 step:13623 [D loss: 0.490243, acc.: 75.78%] [G loss: 0.620441]\n",
      "epoch:14 step:13624 [D loss: 0.486566, acc.: 77.34%] [G loss: 0.700913]\n",
      "epoch:14 step:13625 [D loss: 0.495340, acc.: 76.56%] [G loss: 0.833700]\n",
      "epoch:14 step:13626 [D loss: 0.416884, acc.: 81.25%] [G loss: 0.956698]\n",
      "epoch:14 step:13627 [D loss: 0.474583, acc.: 75.00%] [G loss: 0.984483]\n",
      "epoch:14 step:13628 [D loss: 0.605027, acc.: 66.41%] [G loss: 0.693256]\n",
      "epoch:14 step:13629 [D loss: 0.691345, acc.: 57.81%] [G loss: 0.473227]\n",
      "epoch:14 step:13630 [D loss: 0.539774, acc.: 67.19%] [G loss: 0.479345]\n",
      "epoch:14 step:13631 [D loss: 0.578109, acc.: 65.62%] [G loss: 0.613675]\n",
      "epoch:14 step:13632 [D loss: 0.533520, acc.: 71.09%] [G loss: 0.616452]\n",
      "epoch:14 step:13633 [D loss: 0.490068, acc.: 76.56%] [G loss: 0.777681]\n",
      "epoch:14 step:13634 [D loss: 0.425664, acc.: 85.94%] [G loss: 0.743153]\n",
      "epoch:14 step:13635 [D loss: 0.565141, acc.: 69.53%] [G loss: 0.618289]\n",
      "epoch:14 step:13636 [D loss: 0.621845, acc.: 63.28%] [G loss: 0.576651]\n",
      "epoch:14 step:13637 [D loss: 0.516629, acc.: 72.66%] [G loss: 0.691325]\n",
      "epoch:14 step:13638 [D loss: 0.488178, acc.: 75.00%] [G loss: 0.766287]\n",
      "epoch:14 step:13639 [D loss: 0.550150, acc.: 71.88%] [G loss: 0.534127]\n",
      "epoch:14 step:13640 [D loss: 0.501329, acc.: 77.34%] [G loss: 0.674549]\n",
      "epoch:14 step:13641 [D loss: 0.518641, acc.: 70.31%] [G loss: 0.650026]\n",
      "epoch:14 step:13642 [D loss: 0.540877, acc.: 67.19%] [G loss: 0.747104]\n",
      "epoch:14 step:13643 [D loss: 0.609222, acc.: 68.75%] [G loss: 0.583959]\n",
      "epoch:14 step:13644 [D loss: 0.534494, acc.: 71.09%] [G loss: 0.638100]\n",
      "epoch:14 step:13645 [D loss: 0.580278, acc.: 60.94%] [G loss: 0.900634]\n",
      "epoch:14 step:13646 [D loss: 0.665328, acc.: 57.03%] [G loss: 0.561182]\n",
      "epoch:14 step:13647 [D loss: 0.618802, acc.: 60.16%] [G loss: 0.567225]\n",
      "epoch:14 step:13648 [D loss: 0.495213, acc.: 78.91%] [G loss: 0.855447]\n",
      "epoch:14 step:13649 [D loss: 0.544168, acc.: 70.31%] [G loss: 0.774840]\n",
      "epoch:14 step:13650 [D loss: 0.597604, acc.: 66.41%] [G loss: 0.612998]\n",
      "epoch:14 step:13651 [D loss: 0.547632, acc.: 68.75%] [G loss: 0.626830]\n",
      "epoch:14 step:13652 [D loss: 0.494613, acc.: 73.44%] [G loss: 0.698221]\n",
      "epoch:14 step:13653 [D loss: 0.672499, acc.: 57.81%] [G loss: 0.430481]\n",
      "epoch:14 step:13654 [D loss: 0.497929, acc.: 72.66%] [G loss: 0.642863]\n",
      "epoch:14 step:13655 [D loss: 0.586789, acc.: 67.97%] [G loss: 0.508462]\n",
      "epoch:14 step:13656 [D loss: 0.534689, acc.: 72.66%] [G loss: 0.645146]\n",
      "epoch:14 step:13657 [D loss: 0.517732, acc.: 71.09%] [G loss: 0.585400]\n",
      "epoch:14 step:13658 [D loss: 0.550082, acc.: 72.66%] [G loss: 0.543445]\n",
      "epoch:14 step:13659 [D loss: 0.564437, acc.: 69.53%] [G loss: 0.582676]\n",
      "epoch:14 step:13660 [D loss: 0.705496, acc.: 58.59%] [G loss: 0.561702]\n",
      "epoch:14 step:13661 [D loss: 0.607636, acc.: 67.19%] [G loss: 0.477543]\n",
      "epoch:14 step:13662 [D loss: 0.534748, acc.: 71.09%] [G loss: 0.585791]\n",
      "epoch:14 step:13663 [D loss: 0.591558, acc.: 67.97%] [G loss: 0.664410]\n",
      "epoch:14 step:13664 [D loss: 0.526446, acc.: 72.66%] [G loss: 0.643167]\n",
      "epoch:14 step:13665 [D loss: 0.546662, acc.: 73.44%] [G loss: 0.711110]\n",
      "epoch:14 step:13666 [D loss: 0.516735, acc.: 73.44%] [G loss: 0.720911]\n",
      "epoch:14 step:13667 [D loss: 0.550009, acc.: 70.31%] [G loss: 0.617636]\n",
      "epoch:14 step:13668 [D loss: 0.526433, acc.: 71.09%] [G loss: 0.659253]\n",
      "epoch:14 step:13669 [D loss: 0.550777, acc.: 71.09%] [G loss: 0.598725]\n",
      "epoch:14 step:13670 [D loss: 0.478556, acc.: 75.00%] [G loss: 0.665196]\n",
      "epoch:14 step:13671 [D loss: 0.667503, acc.: 59.38%] [G loss: 0.531327]\n",
      "epoch:14 step:13672 [D loss: 0.507350, acc.: 74.22%] [G loss: 0.612144]\n",
      "epoch:14 step:13673 [D loss: 0.505377, acc.: 74.22%] [G loss: 0.553193]\n",
      "epoch:14 step:13674 [D loss: 0.544697, acc.: 66.41%] [G loss: 0.510189]\n",
      "epoch:14 step:13675 [D loss: 0.495784, acc.: 76.56%] [G loss: 0.587665]\n",
      "epoch:14 step:13676 [D loss: 0.479666, acc.: 79.69%] [G loss: 0.596507]\n",
      "epoch:14 step:13677 [D loss: 0.645102, acc.: 59.38%] [G loss: 0.587329]\n",
      "epoch:14 step:13678 [D loss: 0.589611, acc.: 65.62%] [G loss: 0.558752]\n",
      "epoch:14 step:13679 [D loss: 0.556637, acc.: 71.09%] [G loss: 0.659416]\n",
      "epoch:14 step:13680 [D loss: 0.575824, acc.: 64.84%] [G loss: 0.477472]\n",
      "epoch:14 step:13681 [D loss: 0.536807, acc.: 68.75%] [G loss: 0.613753]\n",
      "epoch:14 step:13682 [D loss: 0.523468, acc.: 72.66%] [G loss: 0.704471]\n",
      "epoch:14 step:13683 [D loss: 0.560248, acc.: 70.31%] [G loss: 0.666454]\n",
      "epoch:14 step:13684 [D loss: 0.719065, acc.: 62.50%] [G loss: 0.547903]\n",
      "epoch:14 step:13685 [D loss: 0.532523, acc.: 75.00%] [G loss: 0.485268]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13686 [D loss: 0.500640, acc.: 71.09%] [G loss: 0.651774]\n",
      "epoch:14 step:13687 [D loss: 0.496358, acc.: 75.78%] [G loss: 0.594634]\n",
      "epoch:14 step:13688 [D loss: 0.580186, acc.: 69.53%] [G loss: 0.541115]\n",
      "epoch:14 step:13689 [D loss: 0.529330, acc.: 72.66%] [G loss: 0.684114]\n",
      "epoch:14 step:13690 [D loss: 0.587497, acc.: 68.75%] [G loss: 0.674900]\n",
      "epoch:14 step:13691 [D loss: 0.533367, acc.: 70.31%] [G loss: 0.593637]\n",
      "epoch:14 step:13692 [D loss: 0.481421, acc.: 77.34%] [G loss: 0.661984]\n",
      "epoch:14 step:13693 [D loss: 0.498893, acc.: 74.22%] [G loss: 0.682246]\n",
      "epoch:14 step:13694 [D loss: 0.598098, acc.: 67.97%] [G loss: 0.688332]\n",
      "epoch:14 step:13695 [D loss: 0.544432, acc.: 71.09%] [G loss: 0.590277]\n",
      "epoch:14 step:13696 [D loss: 0.574829, acc.: 67.19%] [G loss: 0.596696]\n",
      "epoch:14 step:13697 [D loss: 0.515693, acc.: 71.88%] [G loss: 0.745401]\n",
      "epoch:14 step:13698 [D loss: 0.622306, acc.: 58.59%] [G loss: 0.553892]\n",
      "epoch:14 step:13699 [D loss: 0.513933, acc.: 74.22%] [G loss: 0.581750]\n",
      "epoch:14 step:13700 [D loss: 0.490621, acc.: 75.78%] [G loss: 0.678126]\n",
      "epoch:14 step:13701 [D loss: 0.604688, acc.: 64.06%] [G loss: 0.571100]\n",
      "epoch:14 step:13702 [D loss: 0.615937, acc.: 64.84%] [G loss: 0.679756]\n",
      "epoch:14 step:13703 [D loss: 0.572724, acc.: 68.75%] [G loss: 0.769968]\n",
      "epoch:14 step:13704 [D loss: 0.603670, acc.: 66.41%] [G loss: 0.591681]\n",
      "epoch:14 step:13705 [D loss: 0.604855, acc.: 64.84%] [G loss: 0.589563]\n",
      "epoch:14 step:13706 [D loss: 0.551210, acc.: 68.75%] [G loss: 0.632918]\n",
      "epoch:14 step:13707 [D loss: 0.518429, acc.: 73.44%] [G loss: 0.666911]\n",
      "epoch:14 step:13708 [D loss: 0.547629, acc.: 71.88%] [G loss: 0.494133]\n",
      "epoch:14 step:13709 [D loss: 0.583820, acc.: 66.41%] [G loss: 0.481057]\n",
      "epoch:14 step:13710 [D loss: 0.551603, acc.: 68.75%] [G loss: 0.510041]\n",
      "epoch:14 step:13711 [D loss: 0.542739, acc.: 69.53%] [G loss: 0.596633]\n",
      "epoch:14 step:13712 [D loss: 0.533127, acc.: 75.78%] [G loss: 0.537797]\n",
      "epoch:14 step:13713 [D loss: 0.537341, acc.: 75.78%] [G loss: 0.556187]\n",
      "epoch:14 step:13714 [D loss: 0.548693, acc.: 71.88%] [G loss: 0.591250]\n",
      "epoch:14 step:13715 [D loss: 0.543962, acc.: 67.97%] [G loss: 0.536440]\n",
      "epoch:14 step:13716 [D loss: 0.508665, acc.: 74.22%] [G loss: 0.681849]\n",
      "epoch:14 step:13717 [D loss: 0.522209, acc.: 75.78%] [G loss: 0.636517]\n",
      "epoch:14 step:13718 [D loss: 0.593463, acc.: 67.97%] [G loss: 0.560232]\n",
      "epoch:14 step:13719 [D loss: 0.489851, acc.: 74.22%] [G loss: 0.593840]\n",
      "epoch:14 step:13720 [D loss: 0.536052, acc.: 68.75%] [G loss: 0.650166]\n",
      "epoch:14 step:13721 [D loss: 0.507240, acc.: 78.12%] [G loss: 0.693139]\n",
      "epoch:14 step:13722 [D loss: 0.609223, acc.: 65.62%] [G loss: 0.649548]\n",
      "epoch:14 step:13723 [D loss: 0.479536, acc.: 76.56%] [G loss: 0.646137]\n",
      "epoch:14 step:13724 [D loss: 0.694835, acc.: 60.94%] [G loss: 0.517320]\n",
      "epoch:14 step:13725 [D loss: 0.564830, acc.: 65.62%] [G loss: 0.628193]\n",
      "epoch:14 step:13726 [D loss: 0.561597, acc.: 61.72%] [G loss: 0.502959]\n",
      "epoch:14 step:13727 [D loss: 0.563251, acc.: 66.41%] [G loss: 0.467853]\n",
      "epoch:14 step:13728 [D loss: 0.589781, acc.: 70.31%] [G loss: 0.445300]\n",
      "epoch:14 step:13729 [D loss: 0.479540, acc.: 80.47%] [G loss: 0.605027]\n",
      "epoch:14 step:13730 [D loss: 0.571282, acc.: 67.19%] [G loss: 0.561740]\n",
      "epoch:14 step:13731 [D loss: 0.457228, acc.: 78.12%] [G loss: 0.605525]\n",
      "epoch:14 step:13732 [D loss: 0.586738, acc.: 64.84%] [G loss: 0.515828]\n",
      "epoch:14 step:13733 [D loss: 0.607353, acc.: 66.41%] [G loss: 0.632091]\n",
      "epoch:14 step:13734 [D loss: 0.586213, acc.: 64.84%] [G loss: 0.643198]\n",
      "epoch:14 step:13735 [D loss: 0.539675, acc.: 71.88%] [G loss: 0.629954]\n",
      "epoch:14 step:13736 [D loss: 0.591880, acc.: 68.75%] [G loss: 0.635772]\n",
      "epoch:14 step:13737 [D loss: 0.474947, acc.: 78.12%] [G loss: 0.633592]\n",
      "epoch:14 step:13738 [D loss: 0.518891, acc.: 71.09%] [G loss: 0.599659]\n",
      "epoch:14 step:13739 [D loss: 0.518899, acc.: 76.56%] [G loss: 0.543299]\n",
      "epoch:14 step:13740 [D loss: 0.601514, acc.: 66.41%] [G loss: 0.596981]\n",
      "epoch:14 step:13741 [D loss: 0.508485, acc.: 71.88%] [G loss: 0.517509]\n",
      "epoch:14 step:13742 [D loss: 0.483775, acc.: 72.66%] [G loss: 0.732862]\n",
      "epoch:14 step:13743 [D loss: 0.598454, acc.: 65.62%] [G loss: 0.534739]\n",
      "epoch:14 step:13744 [D loss: 0.506391, acc.: 75.00%] [G loss: 0.535489]\n",
      "epoch:14 step:13745 [D loss: 0.544737, acc.: 74.22%] [G loss: 0.529602]\n",
      "epoch:14 step:13746 [D loss: 0.558888, acc.: 70.31%] [G loss: 0.563356]\n",
      "epoch:14 step:13747 [D loss: 0.490861, acc.: 72.66%] [G loss: 0.581287]\n",
      "epoch:14 step:13748 [D loss: 0.528702, acc.: 70.31%] [G loss: 0.681042]\n",
      "epoch:14 step:13749 [D loss: 0.495923, acc.: 75.78%] [G loss: 0.654088]\n",
      "epoch:14 step:13750 [D loss: 0.538289, acc.: 73.44%] [G loss: 0.616505]\n",
      "epoch:14 step:13751 [D loss: 0.508785, acc.: 75.78%] [G loss: 0.701815]\n",
      "epoch:14 step:13752 [D loss: 0.497170, acc.: 72.66%] [G loss: 0.766704]\n",
      "epoch:14 step:13753 [D loss: 0.507354, acc.: 75.78%] [G loss: 0.735466]\n",
      "epoch:14 step:13754 [D loss: 0.578644, acc.: 67.19%] [G loss: 0.559016]\n",
      "epoch:14 step:13755 [D loss: 0.559070, acc.: 70.31%] [G loss: 0.574743]\n",
      "epoch:14 step:13756 [D loss: 0.534784, acc.: 69.53%] [G loss: 0.551537]\n",
      "epoch:14 step:13757 [D loss: 0.512609, acc.: 72.66%] [G loss: 0.602148]\n",
      "epoch:14 step:13758 [D loss: 0.600271, acc.: 66.41%] [G loss: 0.705456]\n",
      "epoch:14 step:13759 [D loss: 0.479356, acc.: 78.12%] [G loss: 0.705922]\n",
      "epoch:14 step:13760 [D loss: 0.496030, acc.: 76.56%] [G loss: 0.658766]\n",
      "epoch:14 step:13761 [D loss: 0.536223, acc.: 74.22%] [G loss: 0.710883]\n",
      "epoch:14 step:13762 [D loss: 0.620597, acc.: 61.72%] [G loss: 0.508594]\n",
      "epoch:14 step:13763 [D loss: 0.499284, acc.: 75.00%] [G loss: 0.726533]\n",
      "epoch:14 step:13764 [D loss: 0.526455, acc.: 72.66%] [G loss: 0.663020]\n",
      "epoch:14 step:13765 [D loss: 0.454892, acc.: 83.59%] [G loss: 0.678530]\n",
      "epoch:14 step:13766 [D loss: 0.443783, acc.: 79.69%] [G loss: 0.938712]\n",
      "epoch:14 step:13767 [D loss: 0.473011, acc.: 79.69%] [G loss: 0.840163]\n",
      "epoch:14 step:13768 [D loss: 0.505649, acc.: 75.78%] [G loss: 0.990907]\n",
      "epoch:14 step:13769 [D loss: 0.490730, acc.: 76.56%] [G loss: 0.875094]\n",
      "epoch:14 step:13770 [D loss: 0.624725, acc.: 64.06%] [G loss: 0.622289]\n",
      "epoch:14 step:13771 [D loss: 0.616028, acc.: 65.62%] [G loss: 0.641013]\n",
      "epoch:14 step:13772 [D loss: 0.527749, acc.: 72.66%] [G loss: 0.583362]\n",
      "epoch:14 step:13773 [D loss: 0.547096, acc.: 72.66%] [G loss: 0.494079]\n",
      "epoch:14 step:13774 [D loss: 0.559475, acc.: 70.31%] [G loss: 0.479145]\n",
      "epoch:14 step:13775 [D loss: 0.523947, acc.: 69.53%] [G loss: 0.475783]\n",
      "epoch:14 step:13776 [D loss: 0.571451, acc.: 67.97%] [G loss: 0.575975]\n",
      "epoch:14 step:13777 [D loss: 0.566596, acc.: 67.97%] [G loss: 0.643569]\n",
      "epoch:14 step:13778 [D loss: 0.503354, acc.: 74.22%] [G loss: 0.626813]\n",
      "epoch:14 step:13779 [D loss: 0.477307, acc.: 77.34%] [G loss: 0.811470]\n",
      "epoch:14 step:13780 [D loss: 0.485435, acc.: 75.00%] [G loss: 0.559703]\n",
      "epoch:14 step:13781 [D loss: 0.624256, acc.: 64.06%] [G loss: 0.537336]\n",
      "epoch:14 step:13782 [D loss: 0.623889, acc.: 62.50%] [G loss: 0.631195]\n",
      "epoch:14 step:13783 [D loss: 0.540005, acc.: 69.53%] [G loss: 0.710773]\n",
      "epoch:14 step:13784 [D loss: 0.527907, acc.: 71.88%] [G loss: 0.571082]\n",
      "epoch:14 step:13785 [D loss: 0.591123, acc.: 68.75%] [G loss: 0.686772]\n",
      "epoch:14 step:13786 [D loss: 0.555087, acc.: 71.88%] [G loss: 0.578389]\n",
      "epoch:14 step:13787 [D loss: 0.547939, acc.: 69.53%] [G loss: 0.633113]\n",
      "epoch:14 step:13788 [D loss: 0.544233, acc.: 71.88%] [G loss: 0.661864]\n",
      "epoch:14 step:13789 [D loss: 0.566596, acc.: 69.53%] [G loss: 0.584954]\n",
      "epoch:14 step:13790 [D loss: 0.594180, acc.: 70.31%] [G loss: 0.564902]\n",
      "epoch:14 step:13791 [D loss: 0.568943, acc.: 66.41%] [G loss: 0.760931]\n",
      "epoch:14 step:13792 [D loss: 0.545382, acc.: 70.31%] [G loss: 0.747168]\n",
      "epoch:14 step:13793 [D loss: 0.559495, acc.: 69.53%] [G loss: 0.768845]\n",
      "epoch:14 step:13794 [D loss: 0.566760, acc.: 69.53%] [G loss: 0.663121]\n",
      "epoch:14 step:13795 [D loss: 0.456657, acc.: 83.59%] [G loss: 0.726310]\n",
      "epoch:14 step:13796 [D loss: 0.588273, acc.: 68.75%] [G loss: 0.509579]\n",
      "epoch:14 step:13797 [D loss: 0.496704, acc.: 71.88%] [G loss: 0.768494]\n",
      "epoch:14 step:13798 [D loss: 0.560403, acc.: 71.09%] [G loss: 0.543471]\n",
      "epoch:14 step:13799 [D loss: 0.533611, acc.: 76.56%] [G loss: 0.625336]\n",
      "epoch:14 step:13800 [D loss: 0.522397, acc.: 70.31%] [G loss: 0.646854]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[3.01708023 1.10748796 6.1383334  5.04815218 3.91398442 5.81841606\n",
      " 4.32659996 4.67560928 4.74750551 4.00598224]\n",
      "##########\n",
      "epoch:14 step:13801 [D loss: 0.567137, acc.: 68.75%] [G loss: 0.435893]\n",
      "epoch:14 step:13802 [D loss: 0.573281, acc.: 72.66%] [G loss: 0.437136]\n",
      "epoch:14 step:13803 [D loss: 0.560738, acc.: 71.09%] [G loss: 0.371109]\n",
      "epoch:14 step:13804 [D loss: 0.612173, acc.: 67.97%] [G loss: 0.374169]\n",
      "epoch:14 step:13805 [D loss: 0.571048, acc.: 64.84%] [G loss: 0.530028]\n",
      "epoch:14 step:13806 [D loss: 0.574278, acc.: 71.09%] [G loss: 0.553977]\n",
      "epoch:14 step:13807 [D loss: 0.585445, acc.: 66.41%] [G loss: 0.489705]\n",
      "epoch:14 step:13808 [D loss: 0.516943, acc.: 78.12%] [G loss: 0.580541]\n",
      "epoch:14 step:13809 [D loss: 0.489060, acc.: 78.91%] [G loss: 0.624430]\n",
      "epoch:14 step:13810 [D loss: 0.554300, acc.: 74.22%] [G loss: 0.568960]\n",
      "epoch:14 step:13811 [D loss: 0.505851, acc.: 75.00%] [G loss: 0.636327]\n",
      "epoch:14 step:13812 [D loss: 0.524401, acc.: 69.53%] [G loss: 0.659132]\n",
      "epoch:14 step:13813 [D loss: 0.537360, acc.: 71.09%] [G loss: 0.789285]\n",
      "epoch:14 step:13814 [D loss: 0.591595, acc.: 64.84%] [G loss: 0.507021]\n",
      "epoch:14 step:13815 [D loss: 0.516422, acc.: 72.66%] [G loss: 0.651156]\n",
      "epoch:14 step:13816 [D loss: 0.579956, acc.: 67.97%] [G loss: 0.459076]\n",
      "epoch:14 step:13817 [D loss: 0.534560, acc.: 73.44%] [G loss: 0.656477]\n",
      "epoch:14 step:13818 [D loss: 0.583648, acc.: 67.19%] [G loss: 0.600848]\n",
      "epoch:14 step:13819 [D loss: 0.489841, acc.: 75.00%] [G loss: 0.629477]\n",
      "epoch:14 step:13820 [D loss: 0.590007, acc.: 61.72%] [G loss: 0.773926]\n",
      "epoch:14 step:13821 [D loss: 0.569683, acc.: 67.19%] [G loss: 0.563194]\n",
      "epoch:14 step:13822 [D loss: 0.621726, acc.: 62.50%] [G loss: 0.461705]\n",
      "epoch:14 step:13823 [D loss: 0.482796, acc.: 74.22%] [G loss: 0.713437]\n",
      "epoch:14 step:13824 [D loss: 0.602797, acc.: 64.06%] [G loss: 0.700684]\n",
      "epoch:14 step:13825 [D loss: 0.489452, acc.: 74.22%] [G loss: 0.824712]\n",
      "epoch:14 step:13826 [D loss: 0.487626, acc.: 78.91%] [G loss: 0.748234]\n",
      "epoch:14 step:13827 [D loss: 0.537960, acc.: 67.97%] [G loss: 0.846558]\n",
      "epoch:14 step:13828 [D loss: 0.586139, acc.: 67.97%] [G loss: 0.633663]\n",
      "epoch:14 step:13829 [D loss: 0.551996, acc.: 69.53%] [G loss: 0.542685]\n",
      "epoch:14 step:13830 [D loss: 0.533455, acc.: 70.31%] [G loss: 0.554402]\n",
      "epoch:14 step:13831 [D loss: 0.635383, acc.: 64.84%] [G loss: 0.686131]\n",
      "epoch:14 step:13832 [D loss: 0.526880, acc.: 70.31%] [G loss: 0.550206]\n",
      "epoch:14 step:13833 [D loss: 0.555834, acc.: 71.88%] [G loss: 0.541727]\n",
      "epoch:14 step:13834 [D loss: 0.657338, acc.: 60.16%] [G loss: 0.540380]\n",
      "epoch:14 step:13835 [D loss: 0.586185, acc.: 63.28%] [G loss: 0.559839]\n",
      "epoch:14 step:13836 [D loss: 0.631017, acc.: 58.59%] [G loss: 0.510529]\n",
      "epoch:14 step:13837 [D loss: 0.539337, acc.: 71.88%] [G loss: 0.547928]\n",
      "epoch:14 step:13838 [D loss: 0.576591, acc.: 69.53%] [G loss: 0.599190]\n",
      "epoch:14 step:13839 [D loss: 0.536886, acc.: 74.22%] [G loss: 0.482677]\n",
      "epoch:14 step:13840 [D loss: 0.525595, acc.: 71.88%] [G loss: 0.580160]\n",
      "epoch:14 step:13841 [D loss: 0.535091, acc.: 72.66%] [G loss: 0.531335]\n",
      "epoch:14 step:13842 [D loss: 0.535214, acc.: 71.09%] [G loss: 0.639173]\n",
      "epoch:14 step:13843 [D loss: 0.525067, acc.: 71.88%] [G loss: 0.633743]\n",
      "epoch:14 step:13844 [D loss: 0.500356, acc.: 75.00%] [G loss: 0.621911]\n",
      "epoch:14 step:13845 [D loss: 0.569367, acc.: 67.97%] [G loss: 0.625667]\n",
      "epoch:14 step:13846 [D loss: 0.541024, acc.: 70.31%] [G loss: 0.746550]\n",
      "epoch:14 step:13847 [D loss: 0.583552, acc.: 66.41%] [G loss: 0.661875]\n",
      "epoch:14 step:13848 [D loss: 0.514809, acc.: 74.22%] [G loss: 0.495731]\n",
      "epoch:14 step:13849 [D loss: 0.653461, acc.: 57.03%] [G loss: 0.453493]\n",
      "epoch:14 step:13850 [D loss: 0.530221, acc.: 73.44%] [G loss: 0.479867]\n",
      "epoch:14 step:13851 [D loss: 0.581902, acc.: 67.97%] [G loss: 0.534979]\n",
      "epoch:14 step:13852 [D loss: 0.501574, acc.: 74.22%] [G loss: 0.727097]\n",
      "epoch:14 step:13853 [D loss: 0.552477, acc.: 64.84%] [G loss: 0.704551]\n",
      "epoch:14 step:13854 [D loss: 0.502211, acc.: 73.44%] [G loss: 0.596344]\n",
      "epoch:14 step:13855 [D loss: 0.581475, acc.: 69.53%] [G loss: 0.580271]\n",
      "epoch:14 step:13856 [D loss: 0.548560, acc.: 69.53%] [G loss: 0.587647]\n",
      "epoch:14 step:13857 [D loss: 0.557239, acc.: 69.53%] [G loss: 0.666534]\n",
      "epoch:14 step:13858 [D loss: 0.661620, acc.: 56.25%] [G loss: 0.382640]\n",
      "epoch:14 step:13859 [D loss: 0.605392, acc.: 67.97%] [G loss: 0.511365]\n",
      "epoch:14 step:13860 [D loss: 0.500390, acc.: 79.69%] [G loss: 0.635351]\n",
      "epoch:14 step:13861 [D loss: 0.555134, acc.: 68.75%] [G loss: 0.644518]\n",
      "epoch:14 step:13862 [D loss: 0.518287, acc.: 73.44%] [G loss: 0.767108]\n",
      "epoch:14 step:13863 [D loss: 0.578525, acc.: 65.62%] [G loss: 0.641513]\n",
      "epoch:14 step:13864 [D loss: 0.470243, acc.: 75.00%] [G loss: 0.632294]\n",
      "epoch:14 step:13865 [D loss: 0.409405, acc.: 84.38%] [G loss: 0.739689]\n",
      "epoch:14 step:13866 [D loss: 0.553058, acc.: 71.09%] [G loss: 0.687389]\n",
      "epoch:14 step:13867 [D loss: 0.519689, acc.: 77.34%] [G loss: 0.602529]\n",
      "epoch:14 step:13868 [D loss: 0.554530, acc.: 67.97%] [G loss: 0.615062]\n",
      "epoch:14 step:13869 [D loss: 0.501531, acc.: 76.56%] [G loss: 0.533345]\n",
      "epoch:14 step:13870 [D loss: 0.538023, acc.: 70.31%] [G loss: 0.832761]\n",
      "epoch:14 step:13871 [D loss: 0.571566, acc.: 66.41%] [G loss: 0.609175]\n",
      "epoch:14 step:13872 [D loss: 0.552585, acc.: 71.09%] [G loss: 0.693545]\n",
      "epoch:14 step:13873 [D loss: 0.531125, acc.: 71.09%] [G loss: 0.632052]\n",
      "epoch:14 step:13874 [D loss: 0.560625, acc.: 73.44%] [G loss: 0.676810]\n",
      "epoch:14 step:13875 [D loss: 0.538445, acc.: 73.44%] [G loss: 0.539743]\n",
      "epoch:14 step:13876 [D loss: 0.568685, acc.: 72.66%] [G loss: 0.604900]\n",
      "epoch:14 step:13877 [D loss: 0.559605, acc.: 70.31%] [G loss: 0.586922]\n",
      "epoch:14 step:13878 [D loss: 0.528244, acc.: 69.53%] [G loss: 0.537525]\n",
      "epoch:14 step:13879 [D loss: 0.541162, acc.: 69.53%] [G loss: 0.519904]\n",
      "epoch:14 step:13880 [D loss: 0.579082, acc.: 67.19%] [G loss: 0.544276]\n",
      "epoch:14 step:13881 [D loss: 0.565623, acc.: 70.31%] [G loss: 0.622663]\n",
      "epoch:14 step:13882 [D loss: 0.569953, acc.: 68.75%] [G loss: 0.615751]\n",
      "epoch:14 step:13883 [D loss: 0.599008, acc.: 64.06%] [G loss: 0.585248]\n",
      "epoch:14 step:13884 [D loss: 0.650873, acc.: 56.25%] [G loss: 0.404462]\n",
      "epoch:14 step:13885 [D loss: 0.536678, acc.: 70.31%] [G loss: 0.483137]\n",
      "epoch:14 step:13886 [D loss: 0.510539, acc.: 71.09%] [G loss: 0.632680]\n",
      "epoch:14 step:13887 [D loss: 0.499547, acc.: 78.12%] [G loss: 0.850193]\n",
      "epoch:14 step:13888 [D loss: 0.565031, acc.: 73.44%] [G loss: 0.756301]\n",
      "epoch:14 step:13889 [D loss: 0.522866, acc.: 69.53%] [G loss: 0.872737]\n",
      "epoch:14 step:13890 [D loss: 0.553519, acc.: 67.19%] [G loss: 0.724747]\n",
      "epoch:14 step:13891 [D loss: 0.591543, acc.: 66.41%] [G loss: 0.667818]\n",
      "epoch:14 step:13892 [D loss: 0.561584, acc.: 70.31%] [G loss: 0.727945]\n",
      "epoch:14 step:13893 [D loss: 0.533375, acc.: 72.66%] [G loss: 0.648201]\n",
      "epoch:14 step:13894 [D loss: 0.633724, acc.: 64.84%] [G loss: 0.631692]\n",
      "epoch:14 step:13895 [D loss: 0.537477, acc.: 68.75%] [G loss: 0.587381]\n",
      "epoch:14 step:13896 [D loss: 0.555159, acc.: 67.19%] [G loss: 0.614556]\n",
      "epoch:14 step:13897 [D loss: 0.534399, acc.: 71.09%] [G loss: 0.486627]\n",
      "epoch:14 step:13898 [D loss: 0.516527, acc.: 71.88%] [G loss: 0.784622]\n",
      "epoch:14 step:13899 [D loss: 0.540754, acc.: 71.09%] [G loss: 0.779787]\n",
      "epoch:14 step:13900 [D loss: 0.559349, acc.: 71.09%] [G loss: 0.714551]\n",
      "epoch:14 step:13901 [D loss: 0.536563, acc.: 70.31%] [G loss: 0.898269]\n",
      "epoch:14 step:13902 [D loss: 0.609680, acc.: 67.19%] [G loss: 0.661805]\n",
      "epoch:14 step:13903 [D loss: 0.555599, acc.: 64.84%] [G loss: 0.638414]\n",
      "epoch:14 step:13904 [D loss: 0.517921, acc.: 77.34%] [G loss: 0.686659]\n",
      "epoch:14 step:13905 [D loss: 0.609214, acc.: 62.50%] [G loss: 0.638875]\n",
      "epoch:14 step:13906 [D loss: 0.727258, acc.: 52.34%] [G loss: 0.435052]\n",
      "epoch:14 step:13907 [D loss: 0.473398, acc.: 80.47%] [G loss: 0.627110]\n",
      "epoch:14 step:13908 [D loss: 0.554716, acc.: 67.97%] [G loss: 0.499729]\n",
      "epoch:14 step:13909 [D loss: 0.492501, acc.: 77.34%] [G loss: 0.613950]\n",
      "epoch:14 step:13910 [D loss: 0.499495, acc.: 75.00%] [G loss: 0.779590]\n",
      "epoch:14 step:13911 [D loss: 0.562988, acc.: 74.22%] [G loss: 0.728314]\n",
      "epoch:14 step:13912 [D loss: 0.623742, acc.: 61.72%] [G loss: 0.749495]\n",
      "epoch:14 step:13913 [D loss: 0.512451, acc.: 71.09%] [G loss: 0.592739]\n",
      "epoch:14 step:13914 [D loss: 0.539858, acc.: 71.09%] [G loss: 0.635598]\n",
      "epoch:14 step:13915 [D loss: 0.581434, acc.: 67.19%] [G loss: 0.665354]\n",
      "epoch:14 step:13916 [D loss: 0.539865, acc.: 68.75%] [G loss: 0.651670]\n",
      "epoch:14 step:13917 [D loss: 0.591396, acc.: 68.75%] [G loss: 0.636500]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13918 [D loss: 0.565316, acc.: 69.53%] [G loss: 0.537317]\n",
      "epoch:14 step:13919 [D loss: 0.518030, acc.: 75.78%] [G loss: 0.655451]\n",
      "epoch:14 step:13920 [D loss: 0.466846, acc.: 76.56%] [G loss: 0.740911]\n",
      "epoch:14 step:13921 [D loss: 0.525352, acc.: 73.44%] [G loss: 0.684670]\n",
      "epoch:14 step:13922 [D loss: 0.579568, acc.: 67.97%] [G loss: 0.614067]\n",
      "epoch:14 step:13923 [D loss: 0.568691, acc.: 69.53%] [G loss: 0.568072]\n",
      "epoch:14 step:13924 [D loss: 0.555684, acc.: 68.75%] [G loss: 0.585324]\n",
      "epoch:14 step:13925 [D loss: 0.483565, acc.: 77.34%] [G loss: 0.645644]\n",
      "epoch:14 step:13926 [D loss: 0.547297, acc.: 69.53%] [G loss: 0.629942]\n",
      "epoch:14 step:13927 [D loss: 0.558743, acc.: 71.88%] [G loss: 0.524372]\n",
      "epoch:14 step:13928 [D loss: 0.549542, acc.: 67.19%] [G loss: 0.663367]\n",
      "epoch:14 step:13929 [D loss: 0.548086, acc.: 70.31%] [G loss: 0.593573]\n",
      "epoch:14 step:13930 [D loss: 0.637865, acc.: 63.28%] [G loss: 0.536522]\n",
      "epoch:14 step:13931 [D loss: 0.552920, acc.: 74.22%] [G loss: 0.555208]\n",
      "epoch:14 step:13932 [D loss: 0.523005, acc.: 71.09%] [G loss: 0.549588]\n",
      "epoch:14 step:13933 [D loss: 0.541603, acc.: 70.31%] [G loss: 0.668817]\n",
      "epoch:14 step:13934 [D loss: 0.522896, acc.: 74.22%] [G loss: 0.664503]\n",
      "epoch:14 step:13935 [D loss: 0.613281, acc.: 67.19%] [G loss: 0.787565]\n",
      "epoch:14 step:13936 [D loss: 0.625678, acc.: 61.72%] [G loss: 0.635258]\n",
      "epoch:14 step:13937 [D loss: 0.566804, acc.: 66.41%] [G loss: 0.508500]\n",
      "epoch:14 step:13938 [D loss: 0.662733, acc.: 59.38%] [G loss: 0.667828]\n",
      "epoch:14 step:13939 [D loss: 0.542537, acc.: 70.31%] [G loss: 0.613341]\n",
      "epoch:14 step:13940 [D loss: 0.532386, acc.: 67.97%] [G loss: 0.502217]\n",
      "epoch:14 step:13941 [D loss: 0.446652, acc.: 78.12%] [G loss: 0.688933]\n",
      "epoch:14 step:13942 [D loss: 0.598480, acc.: 64.84%] [G loss: 0.642413]\n",
      "epoch:14 step:13943 [D loss: 0.543201, acc.: 67.97%] [G loss: 0.631911]\n",
      "epoch:14 step:13944 [D loss: 0.520247, acc.: 73.44%] [G loss: 0.687340]\n",
      "epoch:14 step:13945 [D loss: 0.635780, acc.: 60.16%] [G loss: 0.700068]\n",
      "epoch:14 step:13946 [D loss: 0.675104, acc.: 57.81%] [G loss: 0.710610]\n",
      "epoch:14 step:13947 [D loss: 0.529053, acc.: 74.22%] [G loss: 0.632882]\n",
      "epoch:14 step:13948 [D loss: 0.564406, acc.: 67.19%] [G loss: 0.668046]\n",
      "epoch:14 step:13949 [D loss: 0.569857, acc.: 67.97%] [G loss: 0.529499]\n",
      "epoch:14 step:13950 [D loss: 0.543838, acc.: 70.31%] [G loss: 0.715269]\n",
      "epoch:14 step:13951 [D loss: 0.497041, acc.: 78.12%] [G loss: 0.632599]\n",
      "epoch:14 step:13952 [D loss: 0.548693, acc.: 71.88%] [G loss: 0.632641]\n",
      "epoch:14 step:13953 [D loss: 0.512910, acc.: 72.66%] [G loss: 0.521252]\n",
      "epoch:14 step:13954 [D loss: 0.494575, acc.: 73.44%] [G loss: 0.555868]\n",
      "epoch:14 step:13955 [D loss: 0.560256, acc.: 67.19%] [G loss: 0.499842]\n",
      "epoch:14 step:13956 [D loss: 0.564888, acc.: 65.62%] [G loss: 0.469072]\n",
      "epoch:14 step:13957 [D loss: 0.531912, acc.: 71.09%] [G loss: 0.580771]\n",
      "epoch:14 step:13958 [D loss: 0.605434, acc.: 67.97%] [G loss: 0.496040]\n",
      "epoch:14 step:13959 [D loss: 0.542831, acc.: 72.66%] [G loss: 0.554368]\n",
      "epoch:14 step:13960 [D loss: 0.534613, acc.: 65.62%] [G loss: 0.497413]\n",
      "epoch:14 step:13961 [D loss: 0.537739, acc.: 70.31%] [G loss: 0.561700]\n",
      "epoch:14 step:13962 [D loss: 0.600307, acc.: 64.84%] [G loss: 0.622599]\n",
      "epoch:14 step:13963 [D loss: 0.556650, acc.: 69.53%] [G loss: 0.668675]\n",
      "epoch:14 step:13964 [D loss: 0.629520, acc.: 60.94%] [G loss: 0.429139]\n",
      "epoch:14 step:13965 [D loss: 0.628010, acc.: 64.84%] [G loss: 0.414427]\n",
      "epoch:14 step:13966 [D loss: 0.574595, acc.: 64.06%] [G loss: 0.410158]\n",
      "epoch:14 step:13967 [D loss: 0.544406, acc.: 72.66%] [G loss: 0.522733]\n",
      "epoch:14 step:13968 [D loss: 0.514668, acc.: 71.88%] [G loss: 0.412955]\n",
      "epoch:14 step:13969 [D loss: 0.591994, acc.: 68.75%] [G loss: 0.483117]\n",
      "epoch:14 step:13970 [D loss: 0.531362, acc.: 67.19%] [G loss: 0.585078]\n",
      "epoch:14 step:13971 [D loss: 0.562720, acc.: 66.41%] [G loss: 0.535146]\n",
      "epoch:14 step:13972 [D loss: 0.518923, acc.: 69.53%] [G loss: 0.618333]\n",
      "epoch:14 step:13973 [D loss: 0.552620, acc.: 71.09%] [G loss: 0.644098]\n",
      "epoch:14 step:13974 [D loss: 0.585757, acc.: 71.09%] [G loss: 0.691084]\n",
      "epoch:14 step:13975 [D loss: 0.455467, acc.: 78.12%] [G loss: 0.629085]\n",
      "epoch:14 step:13976 [D loss: 0.655332, acc.: 59.38%] [G loss: 0.522082]\n",
      "epoch:14 step:13977 [D loss: 0.559247, acc.: 67.97%] [G loss: 0.601502]\n",
      "epoch:14 step:13978 [D loss: 0.460872, acc.: 79.69%] [G loss: 0.884543]\n",
      "epoch:14 step:13979 [D loss: 0.630120, acc.: 61.72%] [G loss: 0.469108]\n",
      "epoch:14 step:13980 [D loss: 0.549616, acc.: 67.97%] [G loss: 0.546993]\n",
      "epoch:14 step:13981 [D loss: 0.570831, acc.: 64.06%] [G loss: 0.492534]\n",
      "epoch:14 step:13982 [D loss: 0.564823, acc.: 70.31%] [G loss: 0.492157]\n",
      "epoch:14 step:13983 [D loss: 0.608857, acc.: 65.62%] [G loss: 0.510459]\n",
      "epoch:14 step:13984 [D loss: 0.557900, acc.: 68.75%] [G loss: 0.509888]\n",
      "epoch:14 step:13985 [D loss: 0.653837, acc.: 57.81%] [G loss: 0.373312]\n",
      "epoch:14 step:13986 [D loss: 0.548728, acc.: 69.53%] [G loss: 0.508800]\n",
      "epoch:14 step:13987 [D loss: 0.565426, acc.: 70.31%] [G loss: 0.478897]\n",
      "epoch:14 step:13988 [D loss: 0.490319, acc.: 74.22%] [G loss: 0.643704]\n",
      "epoch:14 step:13989 [D loss: 0.518872, acc.: 71.88%] [G loss: 0.668929]\n",
      "epoch:14 step:13990 [D loss: 0.511307, acc.: 75.78%] [G loss: 0.795258]\n",
      "epoch:14 step:13991 [D loss: 0.561686, acc.: 67.19%] [G loss: 0.562714]\n",
      "epoch:14 step:13992 [D loss: 0.566688, acc.: 71.09%] [G loss: 0.635279]\n",
      "epoch:14 step:13993 [D loss: 0.497129, acc.: 74.22%] [G loss: 0.600627]\n",
      "epoch:14 step:13994 [D loss: 0.537740, acc.: 70.31%] [G loss: 0.499373]\n",
      "epoch:14 step:13995 [D loss: 0.575633, acc.: 67.97%] [G loss: 0.436403]\n",
      "epoch:14 step:13996 [D loss: 0.562104, acc.: 67.19%] [G loss: 0.487519]\n",
      "epoch:14 step:13997 [D loss: 0.565061, acc.: 67.19%] [G loss: 0.486460]\n",
      "epoch:14 step:13998 [D loss: 0.695054, acc.: 52.34%] [G loss: 0.537554]\n",
      "epoch:14 step:13999 [D loss: 0.539685, acc.: 75.00%] [G loss: 0.594132]\n",
      "epoch:14 step:14000 [D loss: 0.574249, acc.: 66.41%] [G loss: 0.488010]\n",
      "##############\n",
      "[3.06551942 0.98627862 6.14209293 4.6961034  3.73046324 5.78090428\n",
      " 4.69023101 4.65595014 4.687202   4.14518476]\n",
      "##########\n",
      "epoch:14 step:14001 [D loss: 0.604198, acc.: 67.19%] [G loss: 0.411045]\n",
      "epoch:14 step:14002 [D loss: 0.453440, acc.: 82.03%] [G loss: 0.693294]\n",
      "epoch:14 step:14003 [D loss: 0.538113, acc.: 75.78%] [G loss: 0.747180]\n",
      "epoch:14 step:14004 [D loss: 0.532985, acc.: 68.75%] [G loss: 0.625784]\n",
      "epoch:14 step:14005 [D loss: 0.617862, acc.: 64.06%] [G loss: 0.722206]\n",
      "epoch:14 step:14006 [D loss: 0.543822, acc.: 67.97%] [G loss: 0.675132]\n",
      "epoch:14 step:14007 [D loss: 0.565259, acc.: 64.06%] [G loss: 0.646594]\n",
      "epoch:14 step:14008 [D loss: 0.497685, acc.: 76.56%] [G loss: 0.702569]\n",
      "epoch:14 step:14009 [D loss: 0.609272, acc.: 65.62%] [G loss: 0.580537]\n",
      "epoch:14 step:14010 [D loss: 0.639856, acc.: 63.28%] [G loss: 0.440385]\n",
      "epoch:14 step:14011 [D loss: 0.512407, acc.: 71.88%] [G loss: 0.615061]\n",
      "epoch:14 step:14012 [D loss: 0.482665, acc.: 76.56%] [G loss: 0.644972]\n",
      "epoch:14 step:14013 [D loss: 0.544150, acc.: 67.97%] [G loss: 0.735048]\n",
      "epoch:14 step:14014 [D loss: 0.523562, acc.: 69.53%] [G loss: 0.933384]\n",
      "epoch:14 step:14015 [D loss: 0.510413, acc.: 73.44%] [G loss: 0.813505]\n",
      "epoch:14 step:14016 [D loss: 0.447738, acc.: 79.69%] [G loss: 0.786651]\n",
      "epoch:14 step:14017 [D loss: 0.485613, acc.: 75.78%] [G loss: 0.581975]\n",
      "epoch:14 step:14018 [D loss: 0.559372, acc.: 69.53%] [G loss: 0.716487]\n",
      "epoch:14 step:14019 [D loss: 0.572908, acc.: 65.62%] [G loss: 0.643684]\n",
      "epoch:14 step:14020 [D loss: 0.576557, acc.: 66.41%] [G loss: 0.587016]\n",
      "epoch:14 step:14021 [D loss: 0.554020, acc.: 71.09%] [G loss: 0.565405]\n",
      "epoch:14 step:14022 [D loss: 0.598751, acc.: 66.41%] [G loss: 0.440059]\n",
      "epoch:14 step:14023 [D loss: 0.580464, acc.: 68.75%] [G loss: 0.634173]\n",
      "epoch:14 step:14024 [D loss: 0.479400, acc.: 79.69%] [G loss: 0.730967]\n",
      "epoch:14 step:14025 [D loss: 0.575818, acc.: 67.19%] [G loss: 0.555946]\n",
      "epoch:14 step:14026 [D loss: 0.592757, acc.: 68.75%] [G loss: 0.606888]\n",
      "epoch:14 step:14027 [D loss: 0.553800, acc.: 65.62%] [G loss: 0.656626]\n",
      "epoch:14 step:14028 [D loss: 0.523615, acc.: 71.88%] [G loss: 0.644420]\n",
      "epoch:14 step:14029 [D loss: 0.489086, acc.: 79.69%] [G loss: 0.827347]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:14030 [D loss: 0.469449, acc.: 79.69%] [G loss: 0.742116]\n",
      "epoch:14 step:14031 [D loss: 0.535147, acc.: 71.09%] [G loss: 0.763394]\n",
      "epoch:14 step:14032 [D loss: 0.423846, acc.: 79.69%] [G loss: 0.784470]\n",
      "epoch:14 step:14033 [D loss: 0.643149, acc.: 61.72%] [G loss: 0.736350]\n",
      "epoch:14 step:14034 [D loss: 0.512082, acc.: 71.09%] [G loss: 0.659595]\n",
      "epoch:14 step:14035 [D loss: 0.667797, acc.: 55.47%] [G loss: 0.425001]\n",
      "epoch:14 step:14036 [D loss: 0.515167, acc.: 74.22%] [G loss: 0.744192]\n",
      "epoch:14 step:14037 [D loss: 0.501448, acc.: 76.56%] [G loss: 0.916440]\n",
      "epoch:14 step:14038 [D loss: 0.754545, acc.: 62.50%] [G loss: 0.493122]\n",
      "epoch:14 step:14039 [D loss: 0.525508, acc.: 70.31%] [G loss: 0.711892]\n",
      "epoch:14 step:14040 [D loss: 0.558851, acc.: 67.19%] [G loss: 0.681055]\n",
      "epoch:14 step:14041 [D loss: 0.493769, acc.: 74.22%] [G loss: 0.649957]\n",
      "epoch:14 step:14042 [D loss: 0.453280, acc.: 79.69%] [G loss: 0.664817]\n",
      "epoch:14 step:14043 [D loss: 0.447204, acc.: 81.25%] [G loss: 0.840564]\n",
      "epoch:14 step:14044 [D loss: 0.456647, acc.: 77.34%] [G loss: 1.125939]\n",
      "epoch:14 step:14045 [D loss: 0.530538, acc.: 72.66%] [G loss: 1.118172]\n",
      "epoch:14 step:14046 [D loss: 0.728732, acc.: 58.59%] [G loss: 1.044942]\n",
      "epoch:14 step:14047 [D loss: 0.574002, acc.: 70.31%] [G loss: 1.083788]\n",
      "epoch:14 step:14048 [D loss: 0.519017, acc.: 72.66%] [G loss: 0.869253]\n",
      "epoch:14 step:14049 [D loss: 0.581549, acc.: 66.41%] [G loss: 0.820906]\n",
      "epoch:14 step:14050 [D loss: 0.659475, acc.: 67.97%] [G loss: 0.652049]\n",
      "epoch:14 step:14051 [D loss: 0.501149, acc.: 73.44%] [G loss: 0.720476]\n",
      "epoch:14 step:14052 [D loss: 0.540672, acc.: 67.19%] [G loss: 0.811359]\n",
      "epoch:14 step:14053 [D loss: 0.498108, acc.: 75.78%] [G loss: 0.743546]\n",
      "epoch:14 step:14054 [D loss: 0.420610, acc.: 79.69%] [G loss: 1.078642]\n",
      "epoch:14 step:14055 [D loss: 0.447698, acc.: 79.69%] [G loss: 1.051557]\n",
      "epoch:15 step:14056 [D loss: 0.554189, acc.: 67.19%] [G loss: 1.241115]\n",
      "epoch:15 step:14057 [D loss: 0.508027, acc.: 76.56%] [G loss: 1.095932]\n",
      "epoch:15 step:14058 [D loss: 0.577167, acc.: 69.53%] [G loss: 0.768074]\n",
      "epoch:15 step:14059 [D loss: 0.551191, acc.: 73.44%] [G loss: 0.636665]\n",
      "epoch:15 step:14060 [D loss: 0.537098, acc.: 69.53%] [G loss: 0.635929]\n",
      "epoch:15 step:14061 [D loss: 0.592693, acc.: 70.31%] [G loss: 0.620873]\n",
      "epoch:15 step:14062 [D loss: 0.482603, acc.: 76.56%] [G loss: 0.806855]\n",
      "epoch:15 step:14063 [D loss: 0.569429, acc.: 69.53%] [G loss: 0.625690]\n",
      "epoch:15 step:14064 [D loss: 0.520454, acc.: 71.88%] [G loss: 0.701540]\n",
      "epoch:15 step:14065 [D loss: 0.522514, acc.: 75.00%] [G loss: 0.696243]\n",
      "epoch:15 step:14066 [D loss: 0.504736, acc.: 75.00%] [G loss: 0.608636]\n",
      "epoch:15 step:14067 [D loss: 0.556294, acc.: 70.31%] [G loss: 0.630065]\n",
      "epoch:15 step:14068 [D loss: 0.541466, acc.: 71.88%] [G loss: 0.536634]\n",
      "epoch:15 step:14069 [D loss: 0.591116, acc.: 71.88%] [G loss: 0.529207]\n",
      "epoch:15 step:14070 [D loss: 0.535351, acc.: 72.66%] [G loss: 0.699417]\n",
      "epoch:15 step:14071 [D loss: 0.533082, acc.: 71.88%] [G loss: 0.842216]\n",
      "epoch:15 step:14072 [D loss: 0.578720, acc.: 66.41%] [G loss: 0.713609]\n",
      "epoch:15 step:14073 [D loss: 0.566347, acc.: 70.31%] [G loss: 0.723308]\n",
      "epoch:15 step:14074 [D loss: 0.555525, acc.: 68.75%] [G loss: 0.655929]\n",
      "epoch:15 step:14075 [D loss: 0.643117, acc.: 62.50%] [G loss: 0.524014]\n",
      "epoch:15 step:14076 [D loss: 0.565324, acc.: 67.19%] [G loss: 0.545534]\n",
      "epoch:15 step:14077 [D loss: 0.436650, acc.: 80.47%] [G loss: 0.856983]\n",
      "epoch:15 step:14078 [D loss: 0.565881, acc.: 67.97%] [G loss: 0.683267]\n",
      "epoch:15 step:14079 [D loss: 0.518013, acc.: 71.88%] [G loss: 0.505846]\n",
      "epoch:15 step:14080 [D loss: 0.559312, acc.: 66.41%] [G loss: 0.592867]\n",
      "epoch:15 step:14081 [D loss: 0.591236, acc.: 67.19%] [G loss: 0.532657]\n",
      "epoch:15 step:14082 [D loss: 0.440910, acc.: 78.12%] [G loss: 0.730426]\n",
      "epoch:15 step:14083 [D loss: 0.588963, acc.: 69.53%] [G loss: 0.584629]\n",
      "epoch:15 step:14084 [D loss: 0.516918, acc.: 73.44%] [G loss: 0.670897]\n",
      "epoch:15 step:14085 [D loss: 0.553360, acc.: 71.09%] [G loss: 0.714727]\n",
      "epoch:15 step:14086 [D loss: 0.592144, acc.: 66.41%] [G loss: 0.586297]\n",
      "epoch:15 step:14087 [D loss: 0.535301, acc.: 71.88%] [G loss: 0.514472]\n",
      "epoch:15 step:14088 [D loss: 0.555965, acc.: 70.31%] [G loss: 0.548417]\n",
      "epoch:15 step:14089 [D loss: 0.542487, acc.: 65.62%] [G loss: 0.625001]\n",
      "epoch:15 step:14090 [D loss: 0.581880, acc.: 65.62%] [G loss: 0.611276]\n",
      "epoch:15 step:14091 [D loss: 0.513632, acc.: 75.00%] [G loss: 0.615546]\n",
      "epoch:15 step:14092 [D loss: 0.531842, acc.: 71.09%] [G loss: 0.543234]\n",
      "epoch:15 step:14093 [D loss: 0.574775, acc.: 71.09%] [G loss: 0.605430]\n",
      "epoch:15 step:14094 [D loss: 0.528465, acc.: 69.53%] [G loss: 0.678764]\n",
      "epoch:15 step:14095 [D loss: 0.477716, acc.: 80.47%] [G loss: 0.659106]\n",
      "epoch:15 step:14096 [D loss: 0.534265, acc.: 71.88%] [G loss: 0.666290]\n",
      "epoch:15 step:14097 [D loss: 0.567666, acc.: 67.97%] [G loss: 0.620600]\n",
      "epoch:15 step:14098 [D loss: 0.543442, acc.: 71.09%] [G loss: 0.592543]\n",
      "epoch:15 step:14099 [D loss: 0.595080, acc.: 61.72%] [G loss: 0.741643]\n",
      "epoch:15 step:14100 [D loss: 0.496668, acc.: 75.78%] [G loss: 0.669405]\n",
      "epoch:15 step:14101 [D loss: 0.456679, acc.: 78.12%] [G loss: 0.700529]\n",
      "epoch:15 step:14102 [D loss: 0.555622, acc.: 73.44%] [G loss: 0.506286]\n",
      "epoch:15 step:14103 [D loss: 0.521641, acc.: 74.22%] [G loss: 0.729221]\n",
      "epoch:15 step:14104 [D loss: 0.496902, acc.: 75.78%] [G loss: 0.702145]\n",
      "epoch:15 step:14105 [D loss: 0.559847, acc.: 66.41%] [G loss: 0.634428]\n",
      "epoch:15 step:14106 [D loss: 0.625362, acc.: 64.84%] [G loss: 0.531588]\n",
      "epoch:15 step:14107 [D loss: 0.575668, acc.: 66.41%] [G loss: 0.680013]\n",
      "epoch:15 step:14108 [D loss: 0.536801, acc.: 75.00%] [G loss: 0.702785]\n",
      "epoch:15 step:14109 [D loss: 0.491113, acc.: 78.91%] [G loss: 0.752317]\n",
      "epoch:15 step:14110 [D loss: 0.561697, acc.: 70.31%] [G loss: 0.530426]\n",
      "epoch:15 step:14111 [D loss: 0.552695, acc.: 71.88%] [G loss: 0.687486]\n",
      "epoch:15 step:14112 [D loss: 0.573244, acc.: 70.31%] [G loss: 0.611843]\n",
      "epoch:15 step:14113 [D loss: 0.524931, acc.: 75.00%] [G loss: 0.670663]\n",
      "epoch:15 step:14114 [D loss: 0.521605, acc.: 70.31%] [G loss: 0.818724]\n",
      "epoch:15 step:14115 [D loss: 0.545312, acc.: 69.53%] [G loss: 0.676291]\n",
      "epoch:15 step:14116 [D loss: 0.603809, acc.: 68.75%] [G loss: 0.581699]\n",
      "epoch:15 step:14117 [D loss: 0.554733, acc.: 70.31%] [G loss: 0.606551]\n",
      "epoch:15 step:14118 [D loss: 0.548138, acc.: 70.31%] [G loss: 0.638126]\n",
      "epoch:15 step:14119 [D loss: 0.595381, acc.: 67.19%] [G loss: 0.619174]\n",
      "epoch:15 step:14120 [D loss: 0.488147, acc.: 75.78%] [G loss: 0.694323]\n",
      "epoch:15 step:14121 [D loss: 0.517471, acc.: 71.88%] [G loss: 0.600606]\n",
      "epoch:15 step:14122 [D loss: 0.578288, acc.: 68.75%] [G loss: 0.533758]\n",
      "epoch:15 step:14123 [D loss: 0.540257, acc.: 70.31%] [G loss: 0.531905]\n",
      "epoch:15 step:14124 [D loss: 0.519288, acc.: 74.22%] [G loss: 0.667057]\n",
      "epoch:15 step:14125 [D loss: 0.514337, acc.: 76.56%] [G loss: 0.539787]\n",
      "epoch:15 step:14126 [D loss: 0.544753, acc.: 74.22%] [G loss: 0.670380]\n",
      "epoch:15 step:14127 [D loss: 0.558580, acc.: 71.88%] [G loss: 0.601088]\n",
      "epoch:15 step:14128 [D loss: 0.535634, acc.: 75.00%] [G loss: 0.638941]\n",
      "epoch:15 step:14129 [D loss: 0.480938, acc.: 76.56%] [G loss: 0.646238]\n",
      "epoch:15 step:14130 [D loss: 0.556347, acc.: 64.84%] [G loss: 0.699902]\n",
      "epoch:15 step:14131 [D loss: 0.495566, acc.: 76.56%] [G loss: 0.804720]\n",
      "epoch:15 step:14132 [D loss: 0.457186, acc.: 75.78%] [G loss: 0.932730]\n",
      "epoch:15 step:14133 [D loss: 0.605970, acc.: 71.09%] [G loss: 0.717863]\n",
      "epoch:15 step:14134 [D loss: 0.579924, acc.: 68.75%] [G loss: 0.585802]\n",
      "epoch:15 step:14135 [D loss: 0.546262, acc.: 72.66%] [G loss: 0.677297]\n",
      "epoch:15 step:14136 [D loss: 0.629501, acc.: 65.62%] [G loss: 0.593305]\n",
      "epoch:15 step:14137 [D loss: 0.529203, acc.: 74.22%] [G loss: 0.595997]\n",
      "epoch:15 step:14138 [D loss: 0.472713, acc.: 76.56%] [G loss: 0.651551]\n",
      "epoch:15 step:14139 [D loss: 0.543550, acc.: 70.31%] [G loss: 0.760209]\n",
      "epoch:15 step:14140 [D loss: 0.567923, acc.: 71.88%] [G loss: 0.673183]\n",
      "epoch:15 step:14141 [D loss: 0.531455, acc.: 71.09%] [G loss: 0.661341]\n",
      "epoch:15 step:14142 [D loss: 0.509515, acc.: 72.66%] [G loss: 0.643460]\n",
      "epoch:15 step:14143 [D loss: 0.501363, acc.: 75.78%] [G loss: 0.528899]\n",
      "epoch:15 step:14144 [D loss: 0.496756, acc.: 75.00%] [G loss: 0.627004]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14145 [D loss: 0.517397, acc.: 72.66%] [G loss: 0.637292]\n",
      "epoch:15 step:14146 [D loss: 0.525616, acc.: 75.78%] [G loss: 0.607183]\n",
      "epoch:15 step:14147 [D loss: 0.496175, acc.: 71.88%] [G loss: 0.743497]\n",
      "epoch:15 step:14148 [D loss: 0.522348, acc.: 71.09%] [G loss: 0.650501]\n",
      "epoch:15 step:14149 [D loss: 0.473108, acc.: 75.78%] [G loss: 0.680275]\n",
      "epoch:15 step:14150 [D loss: 0.534903, acc.: 68.75%] [G loss: 0.630389]\n",
      "epoch:15 step:14151 [D loss: 0.557924, acc.: 67.19%] [G loss: 0.599946]\n",
      "epoch:15 step:14152 [D loss: 0.509656, acc.: 75.00%] [G loss: 0.618935]\n",
      "epoch:15 step:14153 [D loss: 0.571047, acc.: 66.41%] [G loss: 0.652557]\n",
      "epoch:15 step:14154 [D loss: 0.551927, acc.: 76.56%] [G loss: 0.665553]\n",
      "epoch:15 step:14155 [D loss: 0.448045, acc.: 78.12%] [G loss: 0.610441]\n",
      "epoch:15 step:14156 [D loss: 0.502252, acc.: 79.69%] [G loss: 0.846038]\n",
      "epoch:15 step:14157 [D loss: 0.614044, acc.: 66.41%] [G loss: 0.566860]\n",
      "epoch:15 step:14158 [D loss: 0.554737, acc.: 69.53%] [G loss: 0.546044]\n",
      "epoch:15 step:14159 [D loss: 0.535217, acc.: 70.31%] [G loss: 0.741513]\n",
      "epoch:15 step:14160 [D loss: 0.579940, acc.: 71.88%] [G loss: 0.709127]\n",
      "epoch:15 step:14161 [D loss: 0.571040, acc.: 68.75%] [G loss: 0.653776]\n",
      "epoch:15 step:14162 [D loss: 0.588565, acc.: 68.75%] [G loss: 0.521012]\n",
      "epoch:15 step:14163 [D loss: 0.602297, acc.: 67.19%] [G loss: 0.577915]\n",
      "epoch:15 step:14164 [D loss: 0.627220, acc.: 60.94%] [G loss: 0.655335]\n",
      "epoch:15 step:14165 [D loss: 0.563745, acc.: 69.53%] [G loss: 0.529990]\n",
      "epoch:15 step:14166 [D loss: 0.483765, acc.: 76.56%] [G loss: 0.742775]\n",
      "epoch:15 step:14167 [D loss: 0.551295, acc.: 69.53%] [G loss: 0.581324]\n",
      "epoch:15 step:14168 [D loss: 0.527288, acc.: 73.44%] [G loss: 0.563780]\n",
      "epoch:15 step:14169 [D loss: 0.557305, acc.: 67.97%] [G loss: 0.565734]\n",
      "epoch:15 step:14170 [D loss: 0.514201, acc.: 68.75%] [G loss: 0.633219]\n",
      "epoch:15 step:14171 [D loss: 0.504219, acc.: 71.88%] [G loss: 0.704966]\n",
      "epoch:15 step:14172 [D loss: 0.529140, acc.: 71.88%] [G loss: 0.670836]\n",
      "epoch:15 step:14173 [D loss: 0.525393, acc.: 67.97%] [G loss: 0.787949]\n",
      "epoch:15 step:14174 [D loss: 0.503359, acc.: 76.56%] [G loss: 0.757320]\n",
      "epoch:15 step:14175 [D loss: 0.600467, acc.: 71.09%] [G loss: 0.625098]\n",
      "epoch:15 step:14176 [D loss: 0.451495, acc.: 78.91%] [G loss: 0.604254]\n",
      "epoch:15 step:14177 [D loss: 0.520581, acc.: 79.69%] [G loss: 0.744046]\n",
      "epoch:15 step:14178 [D loss: 0.535976, acc.: 70.31%] [G loss: 0.667188]\n",
      "epoch:15 step:14179 [D loss: 0.587903, acc.: 69.53%] [G loss: 0.620521]\n",
      "epoch:15 step:14180 [D loss: 0.588238, acc.: 67.19%] [G loss: 0.595985]\n",
      "epoch:15 step:14181 [D loss: 0.483213, acc.: 76.56%] [G loss: 0.611941]\n",
      "epoch:15 step:14182 [D loss: 0.482726, acc.: 75.78%] [G loss: 0.540596]\n",
      "epoch:15 step:14183 [D loss: 0.515362, acc.: 75.78%] [G loss: 0.679092]\n",
      "epoch:15 step:14184 [D loss: 0.574644, acc.: 67.97%] [G loss: 0.631159]\n",
      "epoch:15 step:14185 [D loss: 0.499541, acc.: 78.12%] [G loss: 0.666129]\n",
      "epoch:15 step:14186 [D loss: 0.515126, acc.: 72.66%] [G loss: 0.744495]\n",
      "epoch:15 step:14187 [D loss: 0.585821, acc.: 64.06%] [G loss: 0.690101]\n",
      "epoch:15 step:14188 [D loss: 0.518618, acc.: 72.66%] [G loss: 0.644165]\n",
      "epoch:15 step:14189 [D loss: 0.495397, acc.: 71.09%] [G loss: 0.721148]\n",
      "epoch:15 step:14190 [D loss: 0.540451, acc.: 75.00%] [G loss: 0.679586]\n",
      "epoch:15 step:14191 [D loss: 0.564339, acc.: 72.66%] [G loss: 0.485288]\n",
      "epoch:15 step:14192 [D loss: 0.655131, acc.: 60.16%] [G loss: 0.563800]\n",
      "epoch:15 step:14193 [D loss: 0.505382, acc.: 75.00%] [G loss: 0.660217]\n",
      "epoch:15 step:14194 [D loss: 0.548343, acc.: 75.00%] [G loss: 0.554886]\n",
      "epoch:15 step:14195 [D loss: 0.563784, acc.: 64.84%] [G loss: 0.471710]\n",
      "epoch:15 step:14196 [D loss: 0.501472, acc.: 75.00%] [G loss: 0.659570]\n",
      "epoch:15 step:14197 [D loss: 0.540808, acc.: 69.53%] [G loss: 0.552696]\n",
      "epoch:15 step:14198 [D loss: 0.592102, acc.: 68.75%] [G loss: 0.525341]\n",
      "epoch:15 step:14199 [D loss: 0.538275, acc.: 67.19%] [G loss: 0.506666]\n",
      "epoch:15 step:14200 [D loss: 0.575881, acc.: 65.62%] [G loss: 0.642212]\n",
      "##############\n",
      "[3.15001323 1.27617098 6.19830256 4.8343126  3.91958044 5.99442234\n",
      " 5.04945261 4.8240415  4.57390885 4.24051212]\n",
      "##########\n",
      "epoch:15 step:14201 [D loss: 0.507799, acc.: 68.75%] [G loss: 0.557008]\n",
      "epoch:15 step:14202 [D loss: 0.582915, acc.: 69.53%] [G loss: 0.608637]\n",
      "epoch:15 step:14203 [D loss: 0.573884, acc.: 65.62%] [G loss: 0.565082]\n",
      "epoch:15 step:14204 [D loss: 0.496285, acc.: 78.12%] [G loss: 0.708468]\n",
      "epoch:15 step:14205 [D loss: 0.568544, acc.: 71.09%] [G loss: 0.564383]\n",
      "epoch:15 step:14206 [D loss: 0.596646, acc.: 68.75%] [G loss: 0.472182]\n",
      "epoch:15 step:14207 [D loss: 0.485325, acc.: 74.22%] [G loss: 0.688391]\n",
      "epoch:15 step:14208 [D loss: 0.608157, acc.: 62.50%] [G loss: 0.559375]\n",
      "epoch:15 step:14209 [D loss: 0.539786, acc.: 70.31%] [G loss: 0.499802]\n",
      "epoch:15 step:14210 [D loss: 0.505355, acc.: 75.78%] [G loss: 0.741714]\n",
      "epoch:15 step:14211 [D loss: 0.472373, acc.: 78.91%] [G loss: 0.755140]\n",
      "epoch:15 step:14212 [D loss: 0.588313, acc.: 64.84%] [G loss: 0.595086]\n",
      "epoch:15 step:14213 [D loss: 0.561332, acc.: 69.53%] [G loss: 0.632798]\n",
      "epoch:15 step:14214 [D loss: 0.494339, acc.: 75.00%] [G loss: 0.725799]\n",
      "epoch:15 step:14215 [D loss: 0.612540, acc.: 67.19%] [G loss: 0.643642]\n",
      "epoch:15 step:14216 [D loss: 0.578031, acc.: 69.53%] [G loss: 0.687064]\n",
      "epoch:15 step:14217 [D loss: 0.489597, acc.: 78.12%] [G loss: 0.600405]\n",
      "epoch:15 step:14218 [D loss: 0.542480, acc.: 70.31%] [G loss: 0.621940]\n",
      "epoch:15 step:14219 [D loss: 0.552814, acc.: 70.31%] [G loss: 0.560432]\n",
      "epoch:15 step:14220 [D loss: 0.483835, acc.: 76.56%] [G loss: 0.634415]\n",
      "epoch:15 step:14221 [D loss: 0.539306, acc.: 71.88%] [G loss: 0.568295]\n",
      "epoch:15 step:14222 [D loss: 0.535167, acc.: 73.44%] [G loss: 0.582090]\n",
      "epoch:15 step:14223 [D loss: 0.603471, acc.: 69.53%] [G loss: 0.560935]\n",
      "epoch:15 step:14224 [D loss: 0.616415, acc.: 65.62%] [G loss: 0.447643]\n",
      "epoch:15 step:14225 [D loss: 0.538060, acc.: 70.31%] [G loss: 0.516787]\n",
      "epoch:15 step:14226 [D loss: 0.580956, acc.: 64.84%] [G loss: 0.372888]\n",
      "epoch:15 step:14227 [D loss: 0.499966, acc.: 73.44%] [G loss: 0.669522]\n",
      "epoch:15 step:14228 [D loss: 0.497087, acc.: 73.44%] [G loss: 0.637995]\n",
      "epoch:15 step:14229 [D loss: 0.631026, acc.: 66.41%] [G loss: 0.580878]\n",
      "epoch:15 step:14230 [D loss: 0.623204, acc.: 63.28%] [G loss: 0.480237]\n",
      "epoch:15 step:14231 [D loss: 0.552404, acc.: 69.53%] [G loss: 0.615370]\n",
      "epoch:15 step:14232 [D loss: 0.560649, acc.: 74.22%] [G loss: 0.581774]\n",
      "epoch:15 step:14233 [D loss: 0.569601, acc.: 67.19%] [G loss: 0.527998]\n",
      "epoch:15 step:14234 [D loss: 0.533532, acc.: 70.31%] [G loss: 0.617344]\n",
      "epoch:15 step:14235 [D loss: 0.606427, acc.: 59.38%] [G loss: 0.569034]\n",
      "epoch:15 step:14236 [D loss: 0.563408, acc.: 68.75%] [G loss: 0.566987]\n",
      "epoch:15 step:14237 [D loss: 0.547778, acc.: 67.97%] [G loss: 0.680890]\n",
      "epoch:15 step:14238 [D loss: 0.598257, acc.: 71.88%] [G loss: 0.729380]\n",
      "epoch:15 step:14239 [D loss: 0.541965, acc.: 70.31%] [G loss: 0.647911]\n",
      "epoch:15 step:14240 [D loss: 0.560188, acc.: 64.06%] [G loss: 0.540370]\n",
      "epoch:15 step:14241 [D loss: 0.541735, acc.: 67.19%] [G loss: 0.534446]\n",
      "epoch:15 step:14242 [D loss: 0.612803, acc.: 63.28%] [G loss: 0.587005]\n",
      "epoch:15 step:14243 [D loss: 0.529046, acc.: 69.53%] [G loss: 0.514306]\n",
      "epoch:15 step:14244 [D loss: 0.594870, acc.: 67.97%] [G loss: 0.513217]\n",
      "epoch:15 step:14245 [D loss: 0.485278, acc.: 76.56%] [G loss: 0.584659]\n",
      "epoch:15 step:14246 [D loss: 0.547364, acc.: 69.53%] [G loss: 0.631010]\n",
      "epoch:15 step:14247 [D loss: 0.500805, acc.: 75.78%] [G loss: 0.697174]\n",
      "epoch:15 step:14248 [D loss: 0.516609, acc.: 75.78%] [G loss: 0.712192]\n",
      "epoch:15 step:14249 [D loss: 0.497697, acc.: 76.56%] [G loss: 0.703071]\n",
      "epoch:15 step:14250 [D loss: 0.571323, acc.: 71.88%] [G loss: 0.634915]\n",
      "epoch:15 step:14251 [D loss: 0.536926, acc.: 73.44%] [G loss: 0.596298]\n",
      "epoch:15 step:14252 [D loss: 0.502049, acc.: 75.78%] [G loss: 0.745484]\n",
      "epoch:15 step:14253 [D loss: 0.451346, acc.: 78.12%] [G loss: 0.638707]\n",
      "epoch:15 step:14254 [D loss: 0.484116, acc.: 78.12%] [G loss: 0.634204]\n",
      "epoch:15 step:14255 [D loss: 0.613853, acc.: 67.19%] [G loss: 0.611998]\n",
      "epoch:15 step:14256 [D loss: 0.569158, acc.: 66.41%] [G loss: 0.585534]\n",
      "epoch:15 step:14257 [D loss: 0.562826, acc.: 68.75%] [G loss: 0.569028]\n",
      "epoch:15 step:14258 [D loss: 0.585821, acc.: 68.75%] [G loss: 0.597238]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14259 [D loss: 0.561892, acc.: 69.53%] [G loss: 0.668312]\n",
      "epoch:15 step:14260 [D loss: 0.506534, acc.: 70.31%] [G loss: 0.792464]\n",
      "epoch:15 step:14261 [D loss: 0.542393, acc.: 67.97%] [G loss: 0.711514]\n",
      "epoch:15 step:14262 [D loss: 0.499008, acc.: 75.78%] [G loss: 0.760545]\n",
      "epoch:15 step:14263 [D loss: 0.440132, acc.: 79.69%] [G loss: 0.938749]\n",
      "epoch:15 step:14264 [D loss: 0.542785, acc.: 70.31%] [G loss: 0.633270]\n",
      "epoch:15 step:14265 [D loss: 0.656732, acc.: 62.50%] [G loss: 0.527744]\n",
      "epoch:15 step:14266 [D loss: 0.637921, acc.: 60.16%] [G loss: 0.444474]\n",
      "epoch:15 step:14267 [D loss: 0.560485, acc.: 70.31%] [G loss: 0.540886]\n",
      "epoch:15 step:14268 [D loss: 0.494721, acc.: 74.22%] [G loss: 0.508812]\n",
      "epoch:15 step:14269 [D loss: 0.612300, acc.: 64.06%] [G loss: 0.482154]\n",
      "epoch:15 step:14270 [D loss: 0.595208, acc.: 64.06%] [G loss: 0.468589]\n",
      "epoch:15 step:14271 [D loss: 0.508313, acc.: 75.78%] [G loss: 0.471765]\n",
      "epoch:15 step:14272 [D loss: 0.519284, acc.: 70.31%] [G loss: 0.457798]\n",
      "epoch:15 step:14273 [D loss: 0.513352, acc.: 74.22%] [G loss: 0.524210]\n",
      "epoch:15 step:14274 [D loss: 0.486456, acc.: 78.12%] [G loss: 0.740660]\n",
      "epoch:15 step:14275 [D loss: 0.626296, acc.: 64.06%] [G loss: 0.708755]\n",
      "epoch:15 step:14276 [D loss: 0.531070, acc.: 67.97%] [G loss: 0.543128]\n",
      "epoch:15 step:14277 [D loss: 0.441209, acc.: 79.69%] [G loss: 0.846936]\n",
      "epoch:15 step:14278 [D loss: 0.579802, acc.: 71.09%] [G loss: 0.859460]\n",
      "epoch:15 step:14279 [D loss: 0.598275, acc.: 64.84%] [G loss: 0.582131]\n",
      "epoch:15 step:14280 [D loss: 0.563055, acc.: 70.31%] [G loss: 0.616469]\n",
      "epoch:15 step:14281 [D loss: 0.592245, acc.: 64.06%] [G loss: 0.566195]\n",
      "epoch:15 step:14282 [D loss: 0.548699, acc.: 69.53%] [G loss: 0.522147]\n",
      "epoch:15 step:14283 [D loss: 0.540389, acc.: 69.53%] [G loss: 0.644258]\n",
      "epoch:15 step:14284 [D loss: 0.521923, acc.: 77.34%] [G loss: 0.524051]\n",
      "epoch:15 step:14285 [D loss: 0.508979, acc.: 75.78%] [G loss: 0.753552]\n",
      "epoch:15 step:14286 [D loss: 0.514616, acc.: 74.22%] [G loss: 0.814891]\n",
      "epoch:15 step:14287 [D loss: 0.491117, acc.: 75.78%] [G loss: 0.680527]\n",
      "epoch:15 step:14288 [D loss: 0.605263, acc.: 67.19%] [G loss: 0.974544]\n",
      "epoch:15 step:14289 [D loss: 0.573947, acc.: 74.22%] [G loss: 0.672691]\n",
      "epoch:15 step:14290 [D loss: 0.535585, acc.: 71.88%] [G loss: 0.696323]\n",
      "epoch:15 step:14291 [D loss: 0.512297, acc.: 75.78%] [G loss: 0.710836]\n",
      "epoch:15 step:14292 [D loss: 0.533392, acc.: 68.75%] [G loss: 0.570402]\n",
      "epoch:15 step:14293 [D loss: 0.605806, acc.: 62.50%] [G loss: 0.520000]\n",
      "epoch:15 step:14294 [D loss: 0.572091, acc.: 66.41%] [G loss: 0.653134]\n",
      "epoch:15 step:14295 [D loss: 0.529826, acc.: 75.00%] [G loss: 0.673905]\n",
      "epoch:15 step:14296 [D loss: 0.504670, acc.: 76.56%] [G loss: 0.591269]\n",
      "epoch:15 step:14297 [D loss: 0.575039, acc.: 64.06%] [G loss: 0.652955]\n",
      "epoch:15 step:14298 [D loss: 0.567142, acc.: 66.41%] [G loss: 0.559824]\n",
      "epoch:15 step:14299 [D loss: 0.476518, acc.: 80.47%] [G loss: 0.587646]\n",
      "epoch:15 step:14300 [D loss: 0.524685, acc.: 72.66%] [G loss: 0.623992]\n",
      "epoch:15 step:14301 [D loss: 0.507519, acc.: 78.12%] [G loss: 0.596586]\n",
      "epoch:15 step:14302 [D loss: 0.539835, acc.: 67.97%] [G loss: 0.657801]\n",
      "epoch:15 step:14303 [D loss: 0.485463, acc.: 75.00%] [G loss: 0.691145]\n",
      "epoch:15 step:14304 [D loss: 0.569356, acc.: 72.66%] [G loss: 0.649814]\n",
      "epoch:15 step:14305 [D loss: 0.643678, acc.: 57.03%] [G loss: 0.617997]\n",
      "epoch:15 step:14306 [D loss: 0.620411, acc.: 59.38%] [G loss: 0.644168]\n",
      "epoch:15 step:14307 [D loss: 0.590771, acc.: 70.31%] [G loss: 0.660238]\n",
      "epoch:15 step:14308 [D loss: 0.564940, acc.: 69.53%] [G loss: 0.661767]\n",
      "epoch:15 step:14309 [D loss: 0.532621, acc.: 71.88%] [G loss: 0.681034]\n",
      "epoch:15 step:14310 [D loss: 0.551261, acc.: 71.09%] [G loss: 0.540630]\n",
      "epoch:15 step:14311 [D loss: 0.535373, acc.: 71.88%] [G loss: 0.618837]\n",
      "epoch:15 step:14312 [D loss: 0.584272, acc.: 61.72%] [G loss: 0.528385]\n",
      "epoch:15 step:14313 [D loss: 0.525823, acc.: 70.31%] [G loss: 0.638268]\n",
      "epoch:15 step:14314 [D loss: 0.532133, acc.: 70.31%] [G loss: 0.570883]\n",
      "epoch:15 step:14315 [D loss: 0.558784, acc.: 66.41%] [G loss: 0.522046]\n",
      "epoch:15 step:14316 [D loss: 0.514885, acc.: 75.00%] [G loss: 0.548036]\n",
      "epoch:15 step:14317 [D loss: 0.580516, acc.: 68.75%] [G loss: 0.519493]\n",
      "epoch:15 step:14318 [D loss: 0.613055, acc.: 67.97%] [G loss: 0.588072]\n",
      "epoch:15 step:14319 [D loss: 0.514196, acc.: 71.88%] [G loss: 0.577694]\n",
      "epoch:15 step:14320 [D loss: 0.541645, acc.: 68.75%] [G loss: 0.581154]\n",
      "epoch:15 step:14321 [D loss: 0.498939, acc.: 76.56%] [G loss: 0.667143]\n",
      "epoch:15 step:14322 [D loss: 0.554358, acc.: 67.97%] [G loss: 0.547738]\n",
      "epoch:15 step:14323 [D loss: 0.589318, acc.: 67.19%] [G loss: 0.653329]\n",
      "epoch:15 step:14324 [D loss: 0.565990, acc.: 71.09%] [G loss: 0.579944]\n",
      "epoch:15 step:14325 [D loss: 0.534850, acc.: 70.31%] [G loss: 0.602554]\n",
      "epoch:15 step:14326 [D loss: 0.509721, acc.: 71.88%] [G loss: 0.548304]\n",
      "epoch:15 step:14327 [D loss: 0.579343, acc.: 64.84%] [G loss: 0.518641]\n",
      "epoch:15 step:14328 [D loss: 0.511520, acc.: 74.22%] [G loss: 0.619414]\n",
      "epoch:15 step:14329 [D loss: 0.521655, acc.: 75.78%] [G loss: 0.719231]\n",
      "epoch:15 step:14330 [D loss: 0.598910, acc.: 64.84%] [G loss: 0.598763]\n",
      "epoch:15 step:14331 [D loss: 0.479729, acc.: 81.25%] [G loss: 0.676725]\n",
      "epoch:15 step:14332 [D loss: 0.664957, acc.: 58.59%] [G loss: 0.525000]\n",
      "epoch:15 step:14333 [D loss: 0.621228, acc.: 67.97%] [G loss: 0.442619]\n",
      "epoch:15 step:14334 [D loss: 0.562377, acc.: 68.75%] [G loss: 0.579686]\n",
      "epoch:15 step:14335 [D loss: 0.523850, acc.: 73.44%] [G loss: 0.717314]\n",
      "epoch:15 step:14336 [D loss: 0.544019, acc.: 70.31%] [G loss: 0.481778]\n",
      "epoch:15 step:14337 [D loss: 0.554580, acc.: 72.66%] [G loss: 0.578880]\n",
      "epoch:15 step:14338 [D loss: 0.488609, acc.: 77.34%] [G loss: 0.507193]\n",
      "epoch:15 step:14339 [D loss: 0.531078, acc.: 71.09%] [G loss: 0.659075]\n",
      "epoch:15 step:14340 [D loss: 0.577435, acc.: 67.19%] [G loss: 0.635866]\n",
      "epoch:15 step:14341 [D loss: 0.496335, acc.: 72.66%] [G loss: 0.585661]\n",
      "epoch:15 step:14342 [D loss: 0.608410, acc.: 66.41%] [G loss: 0.562092]\n",
      "epoch:15 step:14343 [D loss: 0.605721, acc.: 62.50%] [G loss: 0.619292]\n",
      "epoch:15 step:14344 [D loss: 0.548196, acc.: 66.41%] [G loss: 0.653425]\n",
      "epoch:15 step:14345 [D loss: 0.606695, acc.: 67.19%] [G loss: 0.555555]\n",
      "epoch:15 step:14346 [D loss: 0.603029, acc.: 64.06%] [G loss: 0.546127]\n",
      "epoch:15 step:14347 [D loss: 0.547199, acc.: 73.44%] [G loss: 0.489621]\n",
      "epoch:15 step:14348 [D loss: 0.553096, acc.: 70.31%] [G loss: 0.570571]\n",
      "epoch:15 step:14349 [D loss: 0.643594, acc.: 56.25%] [G loss: 0.430153]\n",
      "epoch:15 step:14350 [D loss: 0.575654, acc.: 67.97%] [G loss: 0.438101]\n",
      "epoch:15 step:14351 [D loss: 0.487511, acc.: 72.66%] [G loss: 0.415046]\n",
      "epoch:15 step:14352 [D loss: 0.521119, acc.: 72.66%] [G loss: 0.559793]\n",
      "epoch:15 step:14353 [D loss: 0.487071, acc.: 76.56%] [G loss: 0.572449]\n",
      "epoch:15 step:14354 [D loss: 0.475325, acc.: 76.56%] [G loss: 0.620356]\n",
      "epoch:15 step:14355 [D loss: 0.532173, acc.: 75.00%] [G loss: 0.729674]\n",
      "epoch:15 step:14356 [D loss: 0.639776, acc.: 65.62%] [G loss: 0.530793]\n",
      "epoch:15 step:14357 [D loss: 0.528287, acc.: 73.44%] [G loss: 0.516182]\n",
      "epoch:15 step:14358 [D loss: 0.553821, acc.: 67.97%] [G loss: 0.663992]\n",
      "epoch:15 step:14359 [D loss: 0.486873, acc.: 78.91%] [G loss: 0.646048]\n",
      "epoch:15 step:14360 [D loss: 0.522517, acc.: 72.66%] [G loss: 0.668545]\n",
      "epoch:15 step:14361 [D loss: 0.542615, acc.: 69.53%] [G loss: 0.590424]\n",
      "epoch:15 step:14362 [D loss: 0.498817, acc.: 78.12%] [G loss: 0.651357]\n",
      "epoch:15 step:14363 [D loss: 0.581076, acc.: 71.09%] [G loss: 0.611904]\n",
      "epoch:15 step:14364 [D loss: 0.444776, acc.: 75.78%] [G loss: 0.867609]\n",
      "epoch:15 step:14365 [D loss: 0.469494, acc.: 77.34%] [G loss: 0.832839]\n",
      "epoch:15 step:14366 [D loss: 0.453515, acc.: 81.25%] [G loss: 0.821336]\n",
      "epoch:15 step:14367 [D loss: 0.480232, acc.: 75.78%] [G loss: 0.649638]\n",
      "epoch:15 step:14368 [D loss: 0.502839, acc.: 73.44%] [G loss: 0.886399]\n",
      "epoch:15 step:14369 [D loss: 0.439866, acc.: 77.34%] [G loss: 0.808625]\n",
      "epoch:15 step:14370 [D loss: 0.414956, acc.: 81.25%] [G loss: 0.908382]\n",
      "epoch:15 step:14371 [D loss: 0.701248, acc.: 60.16%] [G loss: 0.687646]\n",
      "epoch:15 step:14372 [D loss: 0.673750, acc.: 60.94%] [G loss: 0.560193]\n",
      "epoch:15 step:14373 [D loss: 0.566002, acc.: 71.88%] [G loss: 0.566426]\n",
      "epoch:15 step:14374 [D loss: 0.549285, acc.: 69.53%] [G loss: 0.611127]\n",
      "epoch:15 step:14375 [D loss: 0.508277, acc.: 73.44%] [G loss: 0.672441]\n",
      "epoch:15 step:14376 [D loss: 0.482799, acc.: 82.03%] [G loss: 0.781100]\n",
      "epoch:15 step:14377 [D loss: 0.561522, acc.: 70.31%] [G loss: 0.722083]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14378 [D loss: 0.583042, acc.: 67.97%] [G loss: 0.587903]\n",
      "epoch:15 step:14379 [D loss: 0.563307, acc.: 71.88%] [G loss: 0.545314]\n",
      "epoch:15 step:14380 [D loss: 0.592676, acc.: 66.41%] [G loss: 0.547546]\n",
      "epoch:15 step:14381 [D loss: 0.491999, acc.: 75.78%] [G loss: 0.667207]\n",
      "epoch:15 step:14382 [D loss: 0.621952, acc.: 73.44%] [G loss: 0.537241]\n",
      "epoch:15 step:14383 [D loss: 0.489997, acc.: 75.00%] [G loss: 0.786484]\n",
      "epoch:15 step:14384 [D loss: 0.549077, acc.: 72.66%] [G loss: 0.706762]\n",
      "epoch:15 step:14385 [D loss: 0.570697, acc.: 68.75%] [G loss: 0.643645]\n",
      "epoch:15 step:14386 [D loss: 0.577681, acc.: 67.19%] [G loss: 0.588260]\n",
      "epoch:15 step:14387 [D loss: 0.518379, acc.: 72.66%] [G loss: 0.444686]\n",
      "epoch:15 step:14388 [D loss: 0.490139, acc.: 72.66%] [G loss: 0.615841]\n",
      "epoch:15 step:14389 [D loss: 0.517297, acc.: 75.00%] [G loss: 0.526711]\n",
      "epoch:15 step:14390 [D loss: 0.492235, acc.: 76.56%] [G loss: 0.709310]\n",
      "epoch:15 step:14391 [D loss: 0.529890, acc.: 75.00%] [G loss: 0.574683]\n",
      "epoch:15 step:14392 [D loss: 0.488916, acc.: 77.34%] [G loss: 0.758340]\n",
      "epoch:15 step:14393 [D loss: 0.569238, acc.: 66.41%] [G loss: 0.665898]\n",
      "epoch:15 step:14394 [D loss: 0.510990, acc.: 78.12%] [G loss: 0.645351]\n",
      "epoch:15 step:14395 [D loss: 0.514462, acc.: 72.66%] [G loss: 0.644261]\n",
      "epoch:15 step:14396 [D loss: 0.600766, acc.: 68.75%] [G loss: 0.584397]\n",
      "epoch:15 step:14397 [D loss: 0.696258, acc.: 56.25%] [G loss: 0.725846]\n",
      "epoch:15 step:14398 [D loss: 0.534069, acc.: 67.97%] [G loss: 0.747776]\n",
      "epoch:15 step:14399 [D loss: 0.463513, acc.: 77.34%] [G loss: 0.810977]\n",
      "epoch:15 step:14400 [D loss: 0.568581, acc.: 64.84%] [G loss: 0.683527]\n",
      "##############\n",
      "[3.04729753 1.0720189  5.94978986 4.88763669 3.93930179 5.68690659\n",
      " 4.60672939 4.85298779 4.47169517 4.21090993]\n",
      "##########\n",
      "epoch:15 step:14401 [D loss: 0.503713, acc.: 71.09%] [G loss: 0.873376]\n",
      "epoch:15 step:14402 [D loss: 0.453533, acc.: 78.91%] [G loss: 0.832147]\n",
      "epoch:15 step:14403 [D loss: 0.694608, acc.: 56.25%] [G loss: 0.640179]\n",
      "epoch:15 step:14404 [D loss: 0.671414, acc.: 60.16%] [G loss: 0.646753]\n",
      "epoch:15 step:14405 [D loss: 0.504755, acc.: 68.75%] [G loss: 0.497226]\n",
      "epoch:15 step:14406 [D loss: 0.521522, acc.: 71.88%] [G loss: 0.821183]\n",
      "epoch:15 step:14407 [D loss: 0.582811, acc.: 68.75%] [G loss: 0.788642]\n",
      "epoch:15 step:14408 [D loss: 0.549124, acc.: 70.31%] [G loss: 0.649448]\n",
      "epoch:15 step:14409 [D loss: 0.411575, acc.: 78.91%] [G loss: 0.889437]\n",
      "epoch:15 step:14410 [D loss: 0.547925, acc.: 74.22%] [G loss: 0.623335]\n",
      "epoch:15 step:14411 [D loss: 0.586791, acc.: 68.75%] [G loss: 0.655929]\n",
      "epoch:15 step:14412 [D loss: 0.456802, acc.: 78.12%] [G loss: 0.723555]\n",
      "epoch:15 step:14413 [D loss: 0.465497, acc.: 77.34%] [G loss: 0.737546]\n",
      "epoch:15 step:14414 [D loss: 0.446691, acc.: 78.12%] [G loss: 0.953291]\n",
      "epoch:15 step:14415 [D loss: 0.506205, acc.: 75.00%] [G loss: 0.696900]\n",
      "epoch:15 step:14416 [D loss: 0.500021, acc.: 77.34%] [G loss: 0.827406]\n",
      "epoch:15 step:14417 [D loss: 0.565299, acc.: 68.75%] [G loss: 0.783159]\n",
      "epoch:15 step:14418 [D loss: 0.518229, acc.: 78.12%] [G loss: 0.699014]\n",
      "epoch:15 step:14419 [D loss: 0.534533, acc.: 72.66%] [G loss: 0.741738]\n",
      "epoch:15 step:14420 [D loss: 0.594101, acc.: 67.19%] [G loss: 0.572325]\n",
      "epoch:15 step:14421 [D loss: 0.531667, acc.: 71.88%] [G loss: 0.603315]\n",
      "epoch:15 step:14422 [D loss: 0.585626, acc.: 66.41%] [G loss: 0.516288]\n",
      "epoch:15 step:14423 [D loss: 0.538969, acc.: 71.09%] [G loss: 0.558286]\n",
      "epoch:15 step:14424 [D loss: 0.515624, acc.: 72.66%] [G loss: 0.586617]\n",
      "epoch:15 step:14425 [D loss: 0.540173, acc.: 73.44%] [G loss: 0.565884]\n",
      "epoch:15 step:14426 [D loss: 0.510717, acc.: 74.22%] [G loss: 0.747863]\n",
      "epoch:15 step:14427 [D loss: 0.469142, acc.: 78.91%] [G loss: 0.720303]\n",
      "epoch:15 step:14428 [D loss: 0.542773, acc.: 73.44%] [G loss: 0.719003]\n",
      "epoch:15 step:14429 [D loss: 0.515687, acc.: 71.88%] [G loss: 0.694135]\n",
      "epoch:15 step:14430 [D loss: 0.546753, acc.: 72.66%] [G loss: 0.720575]\n",
      "epoch:15 step:14431 [D loss: 0.703210, acc.: 59.38%] [G loss: 0.539860]\n",
      "epoch:15 step:14432 [D loss: 0.531965, acc.: 72.66%] [G loss: 0.522102]\n",
      "epoch:15 step:14433 [D loss: 0.527707, acc.: 71.88%] [G loss: 0.588037]\n",
      "epoch:15 step:14434 [D loss: 0.564445, acc.: 66.41%] [G loss: 0.556857]\n",
      "epoch:15 step:14435 [D loss: 0.574237, acc.: 70.31%] [G loss: 0.492308]\n",
      "epoch:15 step:14436 [D loss: 0.444904, acc.: 78.12%] [G loss: 0.594509]\n",
      "epoch:15 step:14437 [D loss: 0.563320, acc.: 72.66%] [G loss: 0.569642]\n",
      "epoch:15 step:14438 [D loss: 0.550226, acc.: 72.66%] [G loss: 0.542856]\n",
      "epoch:15 step:14439 [D loss: 0.539578, acc.: 69.53%] [G loss: 0.529410]\n",
      "epoch:15 step:14440 [D loss: 0.489442, acc.: 75.78%] [G loss: 0.621292]\n",
      "epoch:15 step:14441 [D loss: 0.615412, acc.: 63.28%] [G loss: 0.537555]\n",
      "epoch:15 step:14442 [D loss: 0.557805, acc.: 72.66%] [G loss: 0.567318]\n",
      "epoch:15 step:14443 [D loss: 0.533820, acc.: 69.53%] [G loss: 0.627450]\n",
      "epoch:15 step:14444 [D loss: 0.502402, acc.: 75.00%] [G loss: 0.709873]\n",
      "epoch:15 step:14445 [D loss: 0.591088, acc.: 69.53%] [G loss: 0.629137]\n",
      "epoch:15 step:14446 [D loss: 0.524397, acc.: 71.09%] [G loss: 0.731320]\n",
      "epoch:15 step:14447 [D loss: 0.456537, acc.: 78.91%] [G loss: 0.764999]\n",
      "epoch:15 step:14448 [D loss: 0.611721, acc.: 65.62%] [G loss: 0.588365]\n",
      "epoch:15 step:14449 [D loss: 0.565948, acc.: 66.41%] [G loss: 0.467739]\n",
      "epoch:15 step:14450 [D loss: 0.535807, acc.: 70.31%] [G loss: 0.489714]\n",
      "epoch:15 step:14451 [D loss: 0.548512, acc.: 67.19%] [G loss: 0.613940]\n",
      "epoch:15 step:14452 [D loss: 0.571837, acc.: 70.31%] [G loss: 0.612149]\n",
      "epoch:15 step:14453 [D loss: 0.473393, acc.: 78.91%] [G loss: 0.866595]\n",
      "epoch:15 step:14454 [D loss: 0.497586, acc.: 78.12%] [G loss: 0.854739]\n",
      "epoch:15 step:14455 [D loss: 0.693208, acc.: 56.25%] [G loss: 0.446963]\n",
      "epoch:15 step:14456 [D loss: 0.639578, acc.: 63.28%] [G loss: 0.432145]\n",
      "epoch:15 step:14457 [D loss: 0.503784, acc.: 75.78%] [G loss: 0.660763]\n",
      "epoch:15 step:14458 [D loss: 0.554546, acc.: 67.19%] [G loss: 0.691124]\n",
      "epoch:15 step:14459 [D loss: 0.628463, acc.: 59.38%] [G loss: 0.579906]\n",
      "epoch:15 step:14460 [D loss: 0.501650, acc.: 69.53%] [G loss: 0.680977]\n",
      "epoch:15 step:14461 [D loss: 0.504016, acc.: 70.31%] [G loss: 0.709144]\n",
      "epoch:15 step:14462 [D loss: 0.603356, acc.: 67.19%] [G loss: 0.745902]\n",
      "epoch:15 step:14463 [D loss: 0.551273, acc.: 66.41%] [G loss: 0.744459]\n",
      "epoch:15 step:14464 [D loss: 0.501724, acc.: 75.78%] [G loss: 0.618917]\n",
      "epoch:15 step:14465 [D loss: 0.558847, acc.: 71.09%] [G loss: 0.514990]\n",
      "epoch:15 step:14466 [D loss: 0.552827, acc.: 67.19%] [G loss: 0.614607]\n",
      "epoch:15 step:14467 [D loss: 0.562936, acc.: 67.19%] [G loss: 0.566356]\n",
      "epoch:15 step:14468 [D loss: 0.560608, acc.: 67.97%] [G loss: 0.524759]\n",
      "epoch:15 step:14469 [D loss: 0.575008, acc.: 69.53%] [G loss: 0.631860]\n",
      "epoch:15 step:14470 [D loss: 0.548410, acc.: 64.84%] [G loss: 0.605709]\n",
      "epoch:15 step:14471 [D loss: 0.487668, acc.: 78.12%] [G loss: 0.711129]\n",
      "epoch:15 step:14472 [D loss: 0.540691, acc.: 74.22%] [G loss: 0.614879]\n",
      "epoch:15 step:14473 [D loss: 0.597721, acc.: 65.62%] [G loss: 0.563087]\n",
      "epoch:15 step:14474 [D loss: 0.541161, acc.: 70.31%] [G loss: 0.551535]\n",
      "epoch:15 step:14475 [D loss: 0.631604, acc.: 55.47%] [G loss: 0.496145]\n",
      "epoch:15 step:14476 [D loss: 0.558329, acc.: 68.75%] [G loss: 0.524336]\n",
      "epoch:15 step:14477 [D loss: 0.619695, acc.: 58.59%] [G loss: 0.495132]\n",
      "epoch:15 step:14478 [D loss: 0.549866, acc.: 67.97%] [G loss: 0.567234]\n",
      "epoch:15 step:14479 [D loss: 0.593834, acc.: 65.62%] [G loss: 0.545668]\n",
      "epoch:15 step:14480 [D loss: 0.530706, acc.: 74.22%] [G loss: 0.645541]\n",
      "epoch:15 step:14481 [D loss: 0.495750, acc.: 71.09%] [G loss: 0.618090]\n",
      "epoch:15 step:14482 [D loss: 0.503717, acc.: 73.44%] [G loss: 0.784320]\n",
      "epoch:15 step:14483 [D loss: 0.503119, acc.: 73.44%] [G loss: 0.622844]\n",
      "epoch:15 step:14484 [D loss: 0.470067, acc.: 78.91%] [G loss: 0.685878]\n",
      "epoch:15 step:14485 [D loss: 0.530087, acc.: 70.31%] [G loss: 0.668189]\n",
      "epoch:15 step:14486 [D loss: 0.524197, acc.: 72.66%] [G loss: 0.539625]\n",
      "epoch:15 step:14487 [D loss: 0.598513, acc.: 65.62%] [G loss: 0.569054]\n",
      "epoch:15 step:14488 [D loss: 0.582923, acc.: 65.62%] [G loss: 0.693339]\n",
      "epoch:15 step:14489 [D loss: 0.523799, acc.: 74.22%] [G loss: 0.710286]\n",
      "epoch:15 step:14490 [D loss: 0.557106, acc.: 71.09%] [G loss: 0.661955]\n",
      "epoch:15 step:14491 [D loss: 0.473705, acc.: 75.78%] [G loss: 0.775897]\n",
      "epoch:15 step:14492 [D loss: 0.627802, acc.: 64.84%] [G loss: 0.593757]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14493 [D loss: 0.577220, acc.: 67.97%] [G loss: 0.521731]\n",
      "epoch:15 step:14494 [D loss: 0.515075, acc.: 78.91%] [G loss: 0.656289]\n",
      "epoch:15 step:14495 [D loss: 0.538662, acc.: 70.31%] [G loss: 0.622878]\n",
      "epoch:15 step:14496 [D loss: 0.537466, acc.: 68.75%] [G loss: 0.802065]\n",
      "epoch:15 step:14497 [D loss: 0.551248, acc.: 67.19%] [G loss: 0.637341]\n",
      "epoch:15 step:14498 [D loss: 0.569319, acc.: 67.97%] [G loss: 0.666140]\n",
      "epoch:15 step:14499 [D loss: 0.521498, acc.: 73.44%] [G loss: 0.614059]\n",
      "epoch:15 step:14500 [D loss: 0.563271, acc.: 64.84%] [G loss: 0.605296]\n",
      "epoch:15 step:14501 [D loss: 0.549833, acc.: 71.09%] [G loss: 0.583633]\n",
      "epoch:15 step:14502 [D loss: 0.587830, acc.: 65.62%] [G loss: 0.635966]\n",
      "epoch:15 step:14503 [D loss: 0.484987, acc.: 78.12%] [G loss: 0.655907]\n",
      "epoch:15 step:14504 [D loss: 0.474705, acc.: 78.12%] [G loss: 0.637972]\n",
      "epoch:15 step:14505 [D loss: 0.466134, acc.: 75.78%] [G loss: 0.713485]\n",
      "epoch:15 step:14506 [D loss: 0.371969, acc.: 83.59%] [G loss: 0.749041]\n",
      "epoch:15 step:14507 [D loss: 0.515767, acc.: 69.53%] [G loss: 0.736015]\n",
      "epoch:15 step:14508 [D loss: 0.497183, acc.: 74.22%] [G loss: 0.752098]\n",
      "epoch:15 step:14509 [D loss: 0.633186, acc.: 64.84%] [G loss: 0.579567]\n",
      "epoch:15 step:14510 [D loss: 0.574149, acc.: 67.19%] [G loss: 0.479348]\n",
      "epoch:15 step:14511 [D loss: 0.589139, acc.: 67.97%] [G loss: 0.552164]\n",
      "epoch:15 step:14512 [D loss: 0.526677, acc.: 72.66%] [G loss: 0.670500]\n",
      "epoch:15 step:14513 [D loss: 0.588215, acc.: 68.75%] [G loss: 0.684963]\n",
      "epoch:15 step:14514 [D loss: 0.538299, acc.: 71.88%] [G loss: 0.563393]\n",
      "epoch:15 step:14515 [D loss: 0.501028, acc.: 73.44%] [G loss: 0.590981]\n",
      "epoch:15 step:14516 [D loss: 0.502367, acc.: 76.56%] [G loss: 0.544957]\n",
      "epoch:15 step:14517 [D loss: 0.564650, acc.: 71.88%] [G loss: 0.548956]\n",
      "epoch:15 step:14518 [D loss: 0.537491, acc.: 68.75%] [G loss: 0.663057]\n",
      "epoch:15 step:14519 [D loss: 0.544976, acc.: 67.97%] [G loss: 0.530393]\n",
      "epoch:15 step:14520 [D loss: 0.564151, acc.: 69.53%] [G loss: 0.544596]\n",
      "epoch:15 step:14521 [D loss: 0.545214, acc.: 72.66%] [G loss: 0.542068]\n",
      "epoch:15 step:14522 [D loss: 0.539564, acc.: 67.19%] [G loss: 0.621631]\n",
      "epoch:15 step:14523 [D loss: 0.524072, acc.: 71.88%] [G loss: 0.564149]\n",
      "epoch:15 step:14524 [D loss: 0.529419, acc.: 75.00%] [G loss: 0.724659]\n",
      "epoch:15 step:14525 [D loss: 0.523086, acc.: 70.31%] [G loss: 0.775645]\n",
      "epoch:15 step:14526 [D loss: 0.449374, acc.: 80.47%] [G loss: 0.765591]\n",
      "epoch:15 step:14527 [D loss: 0.430335, acc.: 82.81%] [G loss: 0.817529]\n",
      "epoch:15 step:14528 [D loss: 0.653120, acc.: 63.28%] [G loss: 0.743240]\n",
      "epoch:15 step:14529 [D loss: 0.590488, acc.: 61.72%] [G loss: 0.656355]\n",
      "epoch:15 step:14530 [D loss: 0.461426, acc.: 74.22%] [G loss: 0.801841]\n",
      "epoch:15 step:14531 [D loss: 0.581413, acc.: 75.00%] [G loss: 0.704689]\n",
      "epoch:15 step:14532 [D loss: 0.617185, acc.: 68.75%] [G loss: 0.661518]\n",
      "epoch:15 step:14533 [D loss: 0.577228, acc.: 67.97%] [G loss: 0.537233]\n",
      "epoch:15 step:14534 [D loss: 0.571046, acc.: 72.66%] [G loss: 0.539954]\n",
      "epoch:15 step:14535 [D loss: 0.606325, acc.: 66.41%] [G loss: 0.548354]\n",
      "epoch:15 step:14536 [D loss: 0.535452, acc.: 71.88%] [G loss: 0.549184]\n",
      "epoch:15 step:14537 [D loss: 0.590865, acc.: 66.41%] [G loss: 0.650809]\n",
      "epoch:15 step:14538 [D loss: 0.520222, acc.: 74.22%] [G loss: 0.665825]\n",
      "epoch:15 step:14539 [D loss: 0.513377, acc.: 74.22%] [G loss: 0.762172]\n",
      "epoch:15 step:14540 [D loss: 0.534300, acc.: 66.41%] [G loss: 0.756864]\n",
      "epoch:15 step:14541 [D loss: 0.530127, acc.: 71.09%] [G loss: 0.669385]\n",
      "epoch:15 step:14542 [D loss: 0.555147, acc.: 67.97%] [G loss: 0.604506]\n",
      "epoch:15 step:14543 [D loss: 0.539349, acc.: 68.75%] [G loss: 0.583983]\n",
      "epoch:15 step:14544 [D loss: 0.574036, acc.: 66.41%] [G loss: 0.626627]\n",
      "epoch:15 step:14545 [D loss: 0.572122, acc.: 69.53%] [G loss: 0.503790]\n",
      "epoch:15 step:14546 [D loss: 0.559432, acc.: 66.41%] [G loss: 0.586068]\n",
      "epoch:15 step:14547 [D loss: 0.579552, acc.: 67.19%] [G loss: 0.612946]\n",
      "epoch:15 step:14548 [D loss: 0.579405, acc.: 63.28%] [G loss: 0.536506]\n",
      "epoch:15 step:14549 [D loss: 0.550376, acc.: 74.22%] [G loss: 0.631588]\n",
      "epoch:15 step:14550 [D loss: 0.543411, acc.: 75.00%] [G loss: 0.668737]\n",
      "epoch:15 step:14551 [D loss: 0.553070, acc.: 71.09%] [G loss: 0.530018]\n",
      "epoch:15 step:14552 [D loss: 0.584144, acc.: 65.62%] [G loss: 0.587647]\n",
      "epoch:15 step:14553 [D loss: 0.521637, acc.: 74.22%] [G loss: 0.806694]\n",
      "epoch:15 step:14554 [D loss: 0.534648, acc.: 68.75%] [G loss: 0.720584]\n",
      "epoch:15 step:14555 [D loss: 0.576741, acc.: 71.09%] [G loss: 0.642376]\n",
      "epoch:15 step:14556 [D loss: 0.618101, acc.: 65.62%] [G loss: 0.536506]\n",
      "epoch:15 step:14557 [D loss: 0.597631, acc.: 64.06%] [G loss: 0.494688]\n",
      "epoch:15 step:14558 [D loss: 0.528247, acc.: 72.66%] [G loss: 0.636294]\n",
      "epoch:15 step:14559 [D loss: 0.469459, acc.: 77.34%] [G loss: 0.708303]\n",
      "epoch:15 step:14560 [D loss: 0.499685, acc.: 77.34%] [G loss: 0.742770]\n",
      "epoch:15 step:14561 [D loss: 0.438019, acc.: 77.34%] [G loss: 0.820703]\n",
      "epoch:15 step:14562 [D loss: 0.485395, acc.: 77.34%] [G loss: 0.659390]\n",
      "epoch:15 step:14563 [D loss: 0.449094, acc.: 81.25%] [G loss: 0.834357]\n",
      "epoch:15 step:14564 [D loss: 0.518858, acc.: 71.09%] [G loss: 0.866476]\n",
      "epoch:15 step:14565 [D loss: 0.617005, acc.: 70.31%] [G loss: 0.743854]\n",
      "epoch:15 step:14566 [D loss: 0.716450, acc.: 57.81%] [G loss: 0.574195]\n",
      "epoch:15 step:14567 [D loss: 0.565244, acc.: 66.41%] [G loss: 0.447731]\n",
      "epoch:15 step:14568 [D loss: 0.547668, acc.: 68.75%] [G loss: 0.636922]\n",
      "epoch:15 step:14569 [D loss: 0.538707, acc.: 68.75%] [G loss: 0.471925]\n",
      "epoch:15 step:14570 [D loss: 0.538477, acc.: 73.44%] [G loss: 0.649057]\n",
      "epoch:15 step:14571 [D loss: 0.477558, acc.: 76.56%] [G loss: 0.872718]\n",
      "epoch:15 step:14572 [D loss: 0.501710, acc.: 74.22%] [G loss: 0.725558]\n",
      "epoch:15 step:14573 [D loss: 0.586381, acc.: 67.19%] [G loss: 0.710772]\n",
      "epoch:15 step:14574 [D loss: 0.509985, acc.: 75.78%] [G loss: 0.773521]\n",
      "epoch:15 step:14575 [D loss: 0.489563, acc.: 71.88%] [G loss: 0.797182]\n",
      "epoch:15 step:14576 [D loss: 0.521424, acc.: 71.88%] [G loss: 0.576847]\n",
      "epoch:15 step:14577 [D loss: 0.532726, acc.: 71.88%] [G loss: 0.717698]\n",
      "epoch:15 step:14578 [D loss: 0.477890, acc.: 77.34%] [G loss: 0.656311]\n",
      "epoch:15 step:14579 [D loss: 0.560691, acc.: 70.31%] [G loss: 0.647514]\n",
      "epoch:15 step:14580 [D loss: 0.581395, acc.: 64.84%] [G loss: 0.654356]\n",
      "epoch:15 step:14581 [D loss: 0.498819, acc.: 75.78%] [G loss: 0.689134]\n",
      "epoch:15 step:14582 [D loss: 0.546739, acc.: 71.88%] [G loss: 0.581796]\n",
      "epoch:15 step:14583 [D loss: 0.696474, acc.: 56.25%] [G loss: 0.491818]\n",
      "epoch:15 step:14584 [D loss: 0.621360, acc.: 60.94%] [G loss: 0.432186]\n",
      "epoch:15 step:14585 [D loss: 0.498648, acc.: 79.69%] [G loss: 0.644131]\n",
      "epoch:15 step:14586 [D loss: 0.595497, acc.: 63.28%] [G loss: 0.641748]\n",
      "epoch:15 step:14587 [D loss: 0.568935, acc.: 67.19%] [G loss: 0.546599]\n",
      "epoch:15 step:14588 [D loss: 0.544611, acc.: 70.31%] [G loss: 0.792749]\n",
      "epoch:15 step:14589 [D loss: 0.547126, acc.: 68.75%] [G loss: 0.695489]\n",
      "epoch:15 step:14590 [D loss: 0.627781, acc.: 59.38%] [G loss: 0.512142]\n",
      "epoch:15 step:14591 [D loss: 0.498491, acc.: 72.66%] [G loss: 0.677934]\n",
      "epoch:15 step:14592 [D loss: 0.575757, acc.: 71.09%] [G loss: 0.549544]\n",
      "epoch:15 step:14593 [D loss: 0.567867, acc.: 70.31%] [G loss: 0.536073]\n",
      "epoch:15 step:14594 [D loss: 0.589764, acc.: 66.41%] [G loss: 0.563737]\n",
      "epoch:15 step:14595 [D loss: 0.532197, acc.: 71.09%] [G loss: 0.543317]\n",
      "epoch:15 step:14596 [D loss: 0.563854, acc.: 66.41%] [G loss: 0.558297]\n",
      "epoch:15 step:14597 [D loss: 0.652796, acc.: 61.72%] [G loss: 0.446389]\n",
      "epoch:15 step:14598 [D loss: 0.603253, acc.: 64.84%] [G loss: 0.559490]\n",
      "epoch:15 step:14599 [D loss: 0.611766, acc.: 64.84%] [G loss: 0.473753]\n",
      "epoch:15 step:14600 [D loss: 0.540845, acc.: 71.88%] [G loss: 0.731587]\n",
      "##############\n",
      "[3.03342104 1.10263395 6.27040757 5.1280271  3.76878271 5.53113695\n",
      " 4.63619801 4.91488676 4.69621453 4.00203086]\n",
      "##########\n",
      "epoch:15 step:14601 [D loss: 0.521807, acc.: 74.22%] [G loss: 0.638140]\n",
      "epoch:15 step:14602 [D loss: 0.552895, acc.: 69.53%] [G loss: 0.619902]\n",
      "epoch:15 step:14603 [D loss: 0.481310, acc.: 78.91%] [G loss: 0.667112]\n",
      "epoch:15 step:14604 [D loss: 0.534388, acc.: 74.22%] [G loss: 0.617148]\n",
      "epoch:15 step:14605 [D loss: 0.519599, acc.: 71.88%] [G loss: 0.823567]\n",
      "epoch:15 step:14606 [D loss: 0.517987, acc.: 74.22%] [G loss: 0.643031]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14607 [D loss: 0.470038, acc.: 78.12%] [G loss: 0.724293]\n",
      "epoch:15 step:14608 [D loss: 0.521752, acc.: 75.00%] [G loss: 0.631253]\n",
      "epoch:15 step:14609 [D loss: 0.439271, acc.: 78.12%] [G loss: 0.638166]\n",
      "epoch:15 step:14610 [D loss: 0.471394, acc.: 75.00%] [G loss: 0.662665]\n",
      "epoch:15 step:14611 [D loss: 0.583136, acc.: 69.53%] [G loss: 0.499972]\n",
      "epoch:15 step:14612 [D loss: 0.496748, acc.: 75.00%] [G loss: 0.577584]\n",
      "epoch:15 step:14613 [D loss: 0.481998, acc.: 76.56%] [G loss: 0.659016]\n",
      "epoch:15 step:14614 [D loss: 0.560912, acc.: 71.09%] [G loss: 0.773883]\n",
      "epoch:15 step:14615 [D loss: 0.542584, acc.: 72.66%] [G loss: 0.662601]\n",
      "epoch:15 step:14616 [D loss: 0.543014, acc.: 75.00%] [G loss: 0.612465]\n",
      "epoch:15 step:14617 [D loss: 0.596240, acc.: 66.41%] [G loss: 0.487576]\n",
      "epoch:15 step:14618 [D loss: 0.536859, acc.: 72.66%] [G loss: 0.518608]\n",
      "epoch:15 step:14619 [D loss: 0.452994, acc.: 78.12%] [G loss: 0.785243]\n",
      "epoch:15 step:14620 [D loss: 0.516074, acc.: 72.66%] [G loss: 0.671108]\n",
      "epoch:15 step:14621 [D loss: 0.666452, acc.: 58.59%] [G loss: 0.564415]\n",
      "epoch:15 step:14622 [D loss: 0.490474, acc.: 75.00%] [G loss: 0.570268]\n",
      "epoch:15 step:14623 [D loss: 0.514349, acc.: 75.78%] [G loss: 0.633941]\n",
      "epoch:15 step:14624 [D loss: 0.461337, acc.: 82.03%] [G loss: 0.701011]\n",
      "epoch:15 step:14625 [D loss: 0.493731, acc.: 72.66%] [G loss: 0.778366]\n",
      "epoch:15 step:14626 [D loss: 0.586112, acc.: 68.75%] [G loss: 0.549054]\n",
      "epoch:15 step:14627 [D loss: 0.536826, acc.: 75.00%] [G loss: 0.591146]\n",
      "epoch:15 step:14628 [D loss: 0.527746, acc.: 67.97%] [G loss: 0.703797]\n",
      "epoch:15 step:14629 [D loss: 0.546132, acc.: 72.66%] [G loss: 0.750379]\n",
      "epoch:15 step:14630 [D loss: 0.457215, acc.: 79.69%] [G loss: 0.602103]\n",
      "epoch:15 step:14631 [D loss: 0.561910, acc.: 72.66%] [G loss: 0.604097]\n",
      "epoch:15 step:14632 [D loss: 0.580338, acc.: 68.75%] [G loss: 0.795630]\n",
      "epoch:15 step:14633 [D loss: 0.511394, acc.: 70.31%] [G loss: 0.682096]\n",
      "epoch:15 step:14634 [D loss: 0.554409, acc.: 61.72%] [G loss: 0.529685]\n",
      "epoch:15 step:14635 [D loss: 0.557534, acc.: 71.09%] [G loss: 0.600177]\n",
      "epoch:15 step:14636 [D loss: 0.565072, acc.: 66.41%] [G loss: 0.660508]\n",
      "epoch:15 step:14637 [D loss: 0.467182, acc.: 79.69%] [G loss: 0.634841]\n",
      "epoch:15 step:14638 [D loss: 0.588718, acc.: 68.75%] [G loss: 0.616863]\n",
      "epoch:15 step:14639 [D loss: 0.548249, acc.: 70.31%] [G loss: 0.643773]\n",
      "epoch:15 step:14640 [D loss: 0.524119, acc.: 70.31%] [G loss: 0.559628]\n",
      "epoch:15 step:14641 [D loss: 0.650677, acc.: 57.81%] [G loss: 0.470409]\n",
      "epoch:15 step:14642 [D loss: 0.575583, acc.: 64.84%] [G loss: 0.581135]\n",
      "epoch:15 step:14643 [D loss: 0.661847, acc.: 53.12%] [G loss: 0.511576]\n",
      "epoch:15 step:14644 [D loss: 0.552963, acc.: 66.41%] [G loss: 0.698602]\n",
      "epoch:15 step:14645 [D loss: 0.628617, acc.: 66.41%] [G loss: 0.576638]\n",
      "epoch:15 step:14646 [D loss: 0.540334, acc.: 75.00%] [G loss: 0.645802]\n",
      "epoch:15 step:14647 [D loss: 0.497132, acc.: 74.22%] [G loss: 0.704031]\n",
      "epoch:15 step:14648 [D loss: 0.537042, acc.: 69.53%] [G loss: 0.722718]\n",
      "epoch:15 step:14649 [D loss: 0.562731, acc.: 71.88%] [G loss: 0.641633]\n",
      "epoch:15 step:14650 [D loss: 0.577302, acc.: 67.97%] [G loss: 0.645086]\n",
      "epoch:15 step:14651 [D loss: 0.599303, acc.: 67.19%] [G loss: 0.605967]\n",
      "epoch:15 step:14652 [D loss: 0.514995, acc.: 75.00%] [G loss: 0.636098]\n",
      "epoch:15 step:14653 [D loss: 0.487557, acc.: 75.00%] [G loss: 0.715476]\n",
      "epoch:15 step:14654 [D loss: 0.513000, acc.: 73.44%] [G loss: 0.622234]\n",
      "epoch:15 step:14655 [D loss: 0.620861, acc.: 58.59%] [G loss: 0.577518]\n",
      "epoch:15 step:14656 [D loss: 0.509348, acc.: 73.44%] [G loss: 0.696015]\n",
      "epoch:15 step:14657 [D loss: 0.517692, acc.: 72.66%] [G loss: 0.764745]\n",
      "epoch:15 step:14658 [D loss: 0.480497, acc.: 81.25%] [G loss: 0.734988]\n",
      "epoch:15 step:14659 [D loss: 0.555613, acc.: 69.53%] [G loss: 0.651245]\n",
      "epoch:15 step:14660 [D loss: 0.466780, acc.: 79.69%] [G loss: 0.723806]\n",
      "epoch:15 step:14661 [D loss: 0.646334, acc.: 64.84%] [G loss: 0.525865]\n",
      "epoch:15 step:14662 [D loss: 0.562125, acc.: 65.62%] [G loss: 0.533632]\n",
      "epoch:15 step:14663 [D loss: 0.554342, acc.: 64.06%] [G loss: 0.432340]\n",
      "epoch:15 step:14664 [D loss: 0.521923, acc.: 68.75%] [G loss: 0.609089]\n",
      "epoch:15 step:14665 [D loss: 0.607476, acc.: 60.94%] [G loss: 0.487215]\n",
      "epoch:15 step:14666 [D loss: 0.492825, acc.: 74.22%] [G loss: 0.676931]\n",
      "epoch:15 step:14667 [D loss: 0.533128, acc.: 69.53%] [G loss: 0.637061]\n",
      "epoch:15 step:14668 [D loss: 0.530935, acc.: 64.84%] [G loss: 0.527101]\n",
      "epoch:15 step:14669 [D loss: 0.577833, acc.: 65.62%] [G loss: 0.683640]\n",
      "epoch:15 step:14670 [D loss: 0.603758, acc.: 61.72%] [G loss: 0.560871]\n",
      "epoch:15 step:14671 [D loss: 0.615920, acc.: 67.19%] [G loss: 0.619983]\n",
      "epoch:15 step:14672 [D loss: 0.543431, acc.: 69.53%] [G loss: 0.584150]\n",
      "epoch:15 step:14673 [D loss: 0.496697, acc.: 73.44%] [G loss: 0.609373]\n",
      "epoch:15 step:14674 [D loss: 0.576996, acc.: 69.53%] [G loss: 0.663171]\n",
      "epoch:15 step:14675 [D loss: 0.503010, acc.: 73.44%] [G loss: 0.666202]\n",
      "epoch:15 step:14676 [D loss: 0.595261, acc.: 66.41%] [G loss: 0.591144]\n",
      "epoch:15 step:14677 [D loss: 0.586233, acc.: 70.31%] [G loss: 0.539594]\n",
      "epoch:15 step:14678 [D loss: 0.485250, acc.: 76.56%] [G loss: 0.676209]\n",
      "epoch:15 step:14679 [D loss: 0.464970, acc.: 75.00%] [G loss: 0.708042]\n",
      "epoch:15 step:14680 [D loss: 0.577936, acc.: 66.41%] [G loss: 0.647398]\n",
      "epoch:15 step:14681 [D loss: 0.541615, acc.: 67.97%] [G loss: 0.446235]\n",
      "epoch:15 step:14682 [D loss: 0.547266, acc.: 68.75%] [G loss: 0.585128]\n",
      "epoch:15 step:14683 [D loss: 0.580795, acc.: 67.19%] [G loss: 0.557740]\n",
      "epoch:15 step:14684 [D loss: 0.483370, acc.: 71.88%] [G loss: 0.690608]\n",
      "epoch:15 step:14685 [D loss: 0.591184, acc.: 66.41%] [G loss: 0.629894]\n",
      "epoch:15 step:14686 [D loss: 0.446496, acc.: 83.59%] [G loss: 0.692296]\n",
      "epoch:15 step:14687 [D loss: 0.509715, acc.: 74.22%] [G loss: 0.659260]\n",
      "epoch:15 step:14688 [D loss: 0.536297, acc.: 68.75%] [G loss: 0.668069]\n",
      "epoch:15 step:14689 [D loss: 0.505902, acc.: 75.00%] [G loss: 0.784814]\n",
      "epoch:15 step:14690 [D loss: 0.500506, acc.: 75.78%] [G loss: 0.757497]\n",
      "epoch:15 step:14691 [D loss: 0.585356, acc.: 69.53%] [G loss: 0.530989]\n",
      "epoch:15 step:14692 [D loss: 0.552396, acc.: 71.09%] [G loss: 0.522169]\n",
      "epoch:15 step:14693 [D loss: 0.493566, acc.: 73.44%] [G loss: 0.599781]\n",
      "epoch:15 step:14694 [D loss: 0.505690, acc.: 70.31%] [G loss: 0.720013]\n",
      "epoch:15 step:14695 [D loss: 0.545279, acc.: 71.09%] [G loss: 0.782948]\n",
      "epoch:15 step:14696 [D loss: 0.501140, acc.: 75.78%] [G loss: 0.735190]\n",
      "epoch:15 step:14697 [D loss: 0.534061, acc.: 73.44%] [G loss: 0.664883]\n",
      "epoch:15 step:14698 [D loss: 0.525827, acc.: 71.09%] [G loss: 0.772775]\n",
      "epoch:15 step:14699 [D loss: 0.530878, acc.: 68.75%] [G loss: 0.739670]\n",
      "epoch:15 step:14700 [D loss: 0.516866, acc.: 75.78%] [G loss: 0.633253]\n",
      "epoch:15 step:14701 [D loss: 0.566308, acc.: 68.75%] [G loss: 0.677297]\n",
      "epoch:15 step:14702 [D loss: 0.450728, acc.: 80.47%] [G loss: 0.672433]\n",
      "epoch:15 step:14703 [D loss: 0.372660, acc.: 83.59%] [G loss: 1.007949]\n",
      "epoch:15 step:14704 [D loss: 0.469950, acc.: 77.34%] [G loss: 0.945424]\n",
      "epoch:15 step:14705 [D loss: 0.513458, acc.: 78.12%] [G loss: 0.789557]\n",
      "epoch:15 step:14706 [D loss: 0.498575, acc.: 73.44%] [G loss: 0.661848]\n",
      "epoch:15 step:14707 [D loss: 0.598153, acc.: 70.31%] [G loss: 0.685890]\n",
      "epoch:15 step:14708 [D loss: 0.586089, acc.: 67.97%] [G loss: 0.616270]\n",
      "epoch:15 step:14709 [D loss: 0.488557, acc.: 77.34%] [G loss: 0.674166]\n",
      "epoch:15 step:14710 [D loss: 0.545433, acc.: 73.44%] [G loss: 0.522865]\n",
      "epoch:15 step:14711 [D loss: 0.582277, acc.: 67.19%] [G loss: 0.606066]\n",
      "epoch:15 step:14712 [D loss: 0.527193, acc.: 72.66%] [G loss: 0.656005]\n",
      "epoch:15 step:14713 [D loss: 0.591918, acc.: 68.75%] [G loss: 0.611716]\n",
      "epoch:15 step:14714 [D loss: 0.527329, acc.: 73.44%] [G loss: 0.556092]\n",
      "epoch:15 step:14715 [D loss: 0.456144, acc.: 75.78%] [G loss: 0.831675]\n",
      "epoch:15 step:14716 [D loss: 0.494893, acc.: 71.88%] [G loss: 0.720788]\n",
      "epoch:15 step:14717 [D loss: 0.577557, acc.: 67.97%] [G loss: 0.682544]\n",
      "epoch:15 step:14718 [D loss: 0.596389, acc.: 70.31%] [G loss: 0.611994]\n",
      "epoch:15 step:14719 [D loss: 0.601892, acc.: 60.94%] [G loss: 0.653027]\n",
      "epoch:15 step:14720 [D loss: 0.559354, acc.: 64.84%] [G loss: 0.693070]\n",
      "epoch:15 step:14721 [D loss: 0.529860, acc.: 77.34%] [G loss: 0.618236]\n",
      "epoch:15 step:14722 [D loss: 0.557807, acc.: 71.09%] [G loss: 0.694868]\n",
      "epoch:15 step:14723 [D loss: 0.585092, acc.: 67.97%] [G loss: 0.489828]\n",
      "epoch:15 step:14724 [D loss: 0.531157, acc.: 75.00%] [G loss: 0.538136]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14725 [D loss: 0.511638, acc.: 71.88%] [G loss: 0.590757]\n",
      "epoch:15 step:14726 [D loss: 0.574202, acc.: 67.97%] [G loss: 0.562538]\n",
      "epoch:15 step:14727 [D loss: 0.529581, acc.: 74.22%] [G loss: 0.639683]\n",
      "epoch:15 step:14728 [D loss: 0.552615, acc.: 68.75%] [G loss: 0.557781]\n",
      "epoch:15 step:14729 [D loss: 0.501451, acc.: 76.56%] [G loss: 0.705735]\n",
      "epoch:15 step:14730 [D loss: 0.634855, acc.: 62.50%] [G loss: 0.666430]\n",
      "epoch:15 step:14731 [D loss: 0.551792, acc.: 70.31%] [G loss: 0.638684]\n",
      "epoch:15 step:14732 [D loss: 0.473697, acc.: 75.78%] [G loss: 0.691830]\n",
      "epoch:15 step:14733 [D loss: 0.594592, acc.: 65.62%] [G loss: 0.531467]\n",
      "epoch:15 step:14734 [D loss: 0.482208, acc.: 76.56%] [G loss: 0.765177]\n",
      "epoch:15 step:14735 [D loss: 0.531979, acc.: 69.53%] [G loss: 0.729384]\n",
      "epoch:15 step:14736 [D loss: 0.491580, acc.: 77.34%] [G loss: 0.603023]\n",
      "epoch:15 step:14737 [D loss: 0.585359, acc.: 70.31%] [G loss: 0.483061]\n",
      "epoch:15 step:14738 [D loss: 0.558156, acc.: 70.31%] [G loss: 0.600767]\n",
      "epoch:15 step:14739 [D loss: 0.637177, acc.: 57.81%] [G loss: 0.489099]\n",
      "epoch:15 step:14740 [D loss: 0.591316, acc.: 70.31%] [G loss: 0.483747]\n",
      "epoch:15 step:14741 [D loss: 0.520752, acc.: 71.09%] [G loss: 0.586113]\n",
      "epoch:15 step:14742 [D loss: 0.570668, acc.: 62.50%] [G loss: 0.496984]\n",
      "epoch:15 step:14743 [D loss: 0.515167, acc.: 75.78%] [G loss: 0.617883]\n",
      "epoch:15 step:14744 [D loss: 0.550862, acc.: 66.41%] [G loss: 0.571505]\n",
      "epoch:15 step:14745 [D loss: 0.493473, acc.: 77.34%] [G loss: 0.646740]\n",
      "epoch:15 step:14746 [D loss: 0.476150, acc.: 77.34%] [G loss: 0.749522]\n",
      "epoch:15 step:14747 [D loss: 0.549642, acc.: 69.53%] [G loss: 0.584231]\n",
      "epoch:15 step:14748 [D loss: 0.517303, acc.: 78.12%] [G loss: 0.715908]\n",
      "epoch:15 step:14749 [D loss: 0.481469, acc.: 75.78%] [G loss: 0.705217]\n",
      "epoch:15 step:14750 [D loss: 0.516469, acc.: 73.44%] [G loss: 0.583437]\n",
      "epoch:15 step:14751 [D loss: 0.646234, acc.: 59.38%] [G loss: 0.596231]\n",
      "epoch:15 step:14752 [D loss: 0.543221, acc.: 69.53%] [G loss: 0.546354]\n",
      "epoch:15 step:14753 [D loss: 0.575979, acc.: 68.75%] [G loss: 0.525957]\n",
      "epoch:15 step:14754 [D loss: 0.531132, acc.: 70.31%] [G loss: 0.633858]\n",
      "epoch:15 step:14755 [D loss: 0.542001, acc.: 70.31%] [G loss: 0.691606]\n",
      "epoch:15 step:14756 [D loss: 0.496833, acc.: 75.78%] [G loss: 0.715353]\n",
      "epoch:15 step:14757 [D loss: 0.627806, acc.: 61.72%] [G loss: 0.595809]\n",
      "epoch:15 step:14758 [D loss: 0.607247, acc.: 65.62%] [G loss: 0.527372]\n",
      "epoch:15 step:14759 [D loss: 0.602859, acc.: 68.75%] [G loss: 0.536935]\n",
      "epoch:15 step:14760 [D loss: 0.550941, acc.: 69.53%] [G loss: 0.529663]\n",
      "epoch:15 step:14761 [D loss: 0.535538, acc.: 74.22%] [G loss: 0.601441]\n",
      "epoch:15 step:14762 [D loss: 0.534470, acc.: 73.44%] [G loss: 0.505293]\n",
      "epoch:15 step:14763 [D loss: 0.524104, acc.: 79.69%] [G loss: 0.746706]\n",
      "epoch:15 step:14764 [D loss: 0.543630, acc.: 68.75%] [G loss: 0.621807]\n",
      "epoch:15 step:14765 [D loss: 0.557268, acc.: 70.31%] [G loss: 0.682482]\n",
      "epoch:15 step:14766 [D loss: 0.582786, acc.: 64.84%] [G loss: 0.486268]\n",
      "epoch:15 step:14767 [D loss: 0.572592, acc.: 66.41%] [G loss: 0.589713]\n",
      "epoch:15 step:14768 [D loss: 0.617341, acc.: 60.94%] [G loss: 0.531847]\n",
      "epoch:15 step:14769 [D loss: 0.558889, acc.: 69.53%] [G loss: 0.696957]\n",
      "epoch:15 step:14770 [D loss: 0.585481, acc.: 67.97%] [G loss: 0.600614]\n",
      "epoch:15 step:14771 [D loss: 0.620427, acc.: 60.94%] [G loss: 0.515716]\n",
      "epoch:15 step:14772 [D loss: 0.541113, acc.: 72.66%] [G loss: 0.486223]\n",
      "epoch:15 step:14773 [D loss: 0.559195, acc.: 69.53%] [G loss: 0.549956]\n",
      "epoch:15 step:14774 [D loss: 0.487141, acc.: 78.12%] [G loss: 0.571722]\n",
      "epoch:15 step:14775 [D loss: 0.546547, acc.: 71.09%] [G loss: 0.618468]\n",
      "epoch:15 step:14776 [D loss: 0.573823, acc.: 67.19%] [G loss: 0.510150]\n",
      "epoch:15 step:14777 [D loss: 0.556918, acc.: 72.66%] [G loss: 0.565924]\n",
      "epoch:15 step:14778 [D loss: 0.579540, acc.: 69.53%] [G loss: 0.524238]\n",
      "epoch:15 step:14779 [D loss: 0.538729, acc.: 70.31%] [G loss: 0.542005]\n",
      "epoch:15 step:14780 [D loss: 0.490491, acc.: 76.56%] [G loss: 0.720191]\n",
      "epoch:15 step:14781 [D loss: 0.517619, acc.: 72.66%] [G loss: 0.694124]\n",
      "epoch:15 step:14782 [D loss: 0.633478, acc.: 60.94%] [G loss: 0.650824]\n",
      "epoch:15 step:14783 [D loss: 0.541556, acc.: 71.88%] [G loss: 0.608213]\n",
      "epoch:15 step:14784 [D loss: 0.614103, acc.: 64.84%] [G loss: 0.633648]\n",
      "epoch:15 step:14785 [D loss: 0.549465, acc.: 71.09%] [G loss: 0.602694]\n",
      "epoch:15 step:14786 [D loss: 0.585932, acc.: 68.75%] [G loss: 0.548372]\n",
      "epoch:15 step:14787 [D loss: 0.497956, acc.: 74.22%] [G loss: 0.753112]\n",
      "epoch:15 step:14788 [D loss: 0.520141, acc.: 70.31%] [G loss: 0.685637]\n",
      "epoch:15 step:14789 [D loss: 0.567915, acc.: 68.75%] [G loss: 0.492614]\n",
      "epoch:15 step:14790 [D loss: 0.535383, acc.: 67.97%] [G loss: 0.625172]\n",
      "epoch:15 step:14791 [D loss: 0.495096, acc.: 71.88%] [G loss: 0.769216]\n",
      "epoch:15 step:14792 [D loss: 0.598676, acc.: 65.62%] [G loss: 0.743358]\n",
      "epoch:15 step:14793 [D loss: 0.556529, acc.: 70.31%] [G loss: 0.559946]\n",
      "epoch:15 step:14794 [D loss: 0.634266, acc.: 60.94%] [G loss: 0.432292]\n",
      "epoch:15 step:14795 [D loss: 0.642616, acc.: 60.16%] [G loss: 0.310794]\n",
      "epoch:15 step:14796 [D loss: 0.554572, acc.: 70.31%] [G loss: 0.498555]\n",
      "epoch:15 step:14797 [D loss: 0.521219, acc.: 75.00%] [G loss: 0.569649]\n",
      "epoch:15 step:14798 [D loss: 0.535426, acc.: 72.66%] [G loss: 0.764051]\n",
      "epoch:15 step:14799 [D loss: 0.503417, acc.: 78.12%] [G loss: 0.682251]\n",
      "epoch:15 step:14800 [D loss: 0.579322, acc.: 71.09%] [G loss: 0.610233]\n",
      "##############\n",
      "[2.95052689 1.27484637 6.04460776 4.8797275  3.81238422 5.92983615\n",
      " 4.52618547 4.83598362 4.62036685 4.29467511]\n",
      "##########\n",
      "epoch:15 step:14801 [D loss: 0.500324, acc.: 75.00%] [G loss: 0.625534]\n",
      "epoch:15 step:14802 [D loss: 0.447127, acc.: 78.91%] [G loss: 0.752691]\n",
      "epoch:15 step:14803 [D loss: 0.590515, acc.: 66.41%] [G loss: 0.635957]\n",
      "epoch:15 step:14804 [D loss: 0.548308, acc.: 75.78%] [G loss: 0.557589]\n",
      "epoch:15 step:14805 [D loss: 0.515105, acc.: 75.78%] [G loss: 0.595081]\n",
      "epoch:15 step:14806 [D loss: 0.497452, acc.: 74.22%] [G loss: 0.828569]\n",
      "epoch:15 step:14807 [D loss: 0.577070, acc.: 67.97%] [G loss: 0.711454]\n",
      "epoch:15 step:14808 [D loss: 0.509317, acc.: 75.00%] [G loss: 0.833613]\n",
      "epoch:15 step:14809 [D loss: 0.539297, acc.: 70.31%] [G loss: 0.660699]\n",
      "epoch:15 step:14810 [D loss: 0.515269, acc.: 71.88%] [G loss: 0.474845]\n",
      "epoch:15 step:14811 [D loss: 0.557531, acc.: 67.97%] [G loss: 0.723080]\n",
      "epoch:15 step:14812 [D loss: 0.579218, acc.: 64.06%] [G loss: 0.570100]\n",
      "epoch:15 step:14813 [D loss: 0.580377, acc.: 71.88%] [G loss: 0.659106]\n",
      "epoch:15 step:14814 [D loss: 0.590826, acc.: 66.41%] [G loss: 0.617892]\n",
      "epoch:15 step:14815 [D loss: 0.526128, acc.: 72.66%] [G loss: 0.631783]\n",
      "epoch:15 step:14816 [D loss: 0.625944, acc.: 64.84%] [G loss: 0.512695]\n",
      "epoch:15 step:14817 [D loss: 0.601352, acc.: 67.19%] [G loss: 0.554353]\n",
      "epoch:15 step:14818 [D loss: 0.538767, acc.: 69.53%] [G loss: 0.542337]\n",
      "epoch:15 step:14819 [D loss: 0.578223, acc.: 68.75%] [G loss: 0.464898]\n",
      "epoch:15 step:14820 [D loss: 0.663358, acc.: 61.72%] [G loss: 0.438659]\n",
      "epoch:15 step:14821 [D loss: 0.655606, acc.: 60.94%] [G loss: 0.541263]\n",
      "epoch:15 step:14822 [D loss: 0.504876, acc.: 75.00%] [G loss: 0.487595]\n",
      "epoch:15 step:14823 [D loss: 0.565278, acc.: 71.09%] [G loss: 0.638305]\n",
      "epoch:15 step:14824 [D loss: 0.501832, acc.: 79.69%] [G loss: 0.729364]\n",
      "epoch:15 step:14825 [D loss: 0.554158, acc.: 71.88%] [G loss: 0.744377]\n",
      "epoch:15 step:14826 [D loss: 0.517830, acc.: 74.22%] [G loss: 0.717393]\n",
      "epoch:15 step:14827 [D loss: 0.523998, acc.: 73.44%] [G loss: 0.634327]\n",
      "epoch:15 step:14828 [D loss: 0.513058, acc.: 71.88%] [G loss: 0.740783]\n",
      "epoch:15 step:14829 [D loss: 0.554129, acc.: 75.00%] [G loss: 0.682937]\n",
      "epoch:15 step:14830 [D loss: 0.544560, acc.: 72.66%] [G loss: 0.577020]\n",
      "epoch:15 step:14831 [D loss: 0.606405, acc.: 65.62%] [G loss: 0.583696]\n",
      "epoch:15 step:14832 [D loss: 0.607705, acc.: 65.62%] [G loss: 0.574056]\n",
      "epoch:15 step:14833 [D loss: 0.581697, acc.: 69.53%] [G loss: 0.659976]\n",
      "epoch:15 step:14834 [D loss: 0.555987, acc.: 72.66%] [G loss: 0.606821]\n",
      "epoch:15 step:14835 [D loss: 0.540442, acc.: 70.31%] [G loss: 0.619740]\n",
      "epoch:15 step:14836 [D loss: 0.507024, acc.: 70.31%] [G loss: 0.837195]\n",
      "epoch:15 step:14837 [D loss: 0.517281, acc.: 73.44%] [G loss: 0.703185]\n",
      "epoch:15 step:14838 [D loss: 0.566155, acc.: 66.41%] [G loss: 0.760957]\n",
      "epoch:15 step:14839 [D loss: 0.621753, acc.: 63.28%] [G loss: 0.625025]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14840 [D loss: 0.513594, acc.: 73.44%] [G loss: 0.489832]\n",
      "epoch:15 step:14841 [D loss: 0.492770, acc.: 72.66%] [G loss: 0.686830]\n",
      "epoch:15 step:14842 [D loss: 0.572050, acc.: 68.75%] [G loss: 0.658747]\n",
      "epoch:15 step:14843 [D loss: 0.685220, acc.: 59.38%] [G loss: 0.494395]\n",
      "epoch:15 step:14844 [D loss: 0.511136, acc.: 75.00%] [G loss: 0.662689]\n",
      "epoch:15 step:14845 [D loss: 0.636835, acc.: 62.50%] [G loss: 0.546379]\n",
      "epoch:15 step:14846 [D loss: 0.525999, acc.: 74.22%] [G loss: 0.640417]\n",
      "epoch:15 step:14847 [D loss: 0.518232, acc.: 71.09%] [G loss: 0.581549]\n",
      "epoch:15 step:14848 [D loss: 0.554965, acc.: 69.53%] [G loss: 0.775740]\n",
      "epoch:15 step:14849 [D loss: 0.629718, acc.: 63.28%] [G loss: 0.668526]\n",
      "epoch:15 step:14850 [D loss: 0.502970, acc.: 72.66%] [G loss: 0.687403]\n",
      "epoch:15 step:14851 [D loss: 0.498426, acc.: 70.31%] [G loss: 0.776176]\n",
      "epoch:15 step:14852 [D loss: 0.524742, acc.: 71.09%] [G loss: 0.733875]\n",
      "epoch:15 step:14853 [D loss: 0.578028, acc.: 66.41%] [G loss: 0.655671]\n",
      "epoch:15 step:14854 [D loss: 0.538782, acc.: 72.66%] [G loss: 0.785336]\n",
      "epoch:15 step:14855 [D loss: 0.646803, acc.: 60.94%] [G loss: 0.682166]\n",
      "epoch:15 step:14856 [D loss: 0.537177, acc.: 71.09%] [G loss: 0.794066]\n",
      "epoch:15 step:14857 [D loss: 0.493342, acc.: 75.78%] [G loss: 0.792790]\n",
      "epoch:15 step:14858 [D loss: 0.508739, acc.: 75.00%] [G loss: 0.755689]\n",
      "epoch:15 step:14859 [D loss: 0.543205, acc.: 75.00%] [G loss: 0.560612]\n",
      "epoch:15 step:14860 [D loss: 0.535352, acc.: 71.88%] [G loss: 0.523875]\n",
      "epoch:15 step:14861 [D loss: 0.545953, acc.: 72.66%] [G loss: 0.637194]\n",
      "epoch:15 step:14862 [D loss: 0.609284, acc.: 67.97%] [G loss: 0.583276]\n",
      "epoch:15 step:14863 [D loss: 0.494635, acc.: 75.00%] [G loss: 0.523674]\n",
      "epoch:15 step:14864 [D loss: 0.541687, acc.: 70.31%] [G loss: 0.738788]\n",
      "epoch:15 step:14865 [D loss: 0.508151, acc.: 72.66%] [G loss: 0.665394]\n",
      "epoch:15 step:14866 [D loss: 0.580145, acc.: 67.97%] [G loss: 0.569731]\n",
      "epoch:15 step:14867 [D loss: 0.613408, acc.: 65.62%] [G loss: 0.449014]\n",
      "epoch:15 step:14868 [D loss: 0.520924, acc.: 69.53%] [G loss: 0.484072]\n",
      "epoch:15 step:14869 [D loss: 0.481949, acc.: 75.00%] [G loss: 0.554107]\n",
      "epoch:15 step:14870 [D loss: 0.507914, acc.: 71.88%] [G loss: 0.872003]\n",
      "epoch:15 step:14871 [D loss: 0.549503, acc.: 67.97%] [G loss: 0.714428]\n",
      "epoch:15 step:14872 [D loss: 0.641227, acc.: 66.41%] [G loss: 0.729261]\n",
      "epoch:15 step:14873 [D loss: 0.586026, acc.: 66.41%] [G loss: 0.568767]\n",
      "epoch:15 step:14874 [D loss: 0.556477, acc.: 68.75%] [G loss: 0.638191]\n",
      "epoch:15 step:14875 [D loss: 0.643145, acc.: 66.41%] [G loss: 0.559285]\n",
      "epoch:15 step:14876 [D loss: 0.586284, acc.: 63.28%] [G loss: 0.517936]\n",
      "epoch:15 step:14877 [D loss: 0.538874, acc.: 69.53%] [G loss: 0.546013]\n",
      "epoch:15 step:14878 [D loss: 0.468455, acc.: 76.56%] [G loss: 0.684513]\n",
      "epoch:15 step:14879 [D loss: 0.555671, acc.: 68.75%] [G loss: 0.694645]\n",
      "epoch:15 step:14880 [D loss: 0.543178, acc.: 72.66%] [G loss: 0.667585]\n",
      "epoch:15 step:14881 [D loss: 0.620319, acc.: 63.28%] [G loss: 0.479116]\n",
      "epoch:15 step:14882 [D loss: 0.544412, acc.: 71.88%] [G loss: 0.617707]\n",
      "epoch:15 step:14883 [D loss: 0.650072, acc.: 64.06%] [G loss: 0.487003]\n",
      "epoch:15 step:14884 [D loss: 0.559956, acc.: 65.62%] [G loss: 0.414549]\n",
      "epoch:15 step:14885 [D loss: 0.546647, acc.: 71.09%] [G loss: 0.619957]\n",
      "epoch:15 step:14886 [D loss: 0.524667, acc.: 73.44%] [G loss: 0.486833]\n",
      "epoch:15 step:14887 [D loss: 0.492602, acc.: 73.44%] [G loss: 0.563617]\n",
      "epoch:15 step:14888 [D loss: 0.577415, acc.: 71.09%] [G loss: 0.629659]\n",
      "epoch:15 step:14889 [D loss: 0.492555, acc.: 75.00%] [G loss: 0.695180]\n",
      "epoch:15 step:14890 [D loss: 0.525215, acc.: 71.88%] [G loss: 0.505686]\n",
      "epoch:15 step:14891 [D loss: 0.520967, acc.: 75.00%] [G loss: 0.516120]\n",
      "epoch:15 step:14892 [D loss: 0.498700, acc.: 73.44%] [G loss: 0.642049]\n",
      "epoch:15 step:14893 [D loss: 0.586099, acc.: 64.06%] [G loss: 0.609962]\n",
      "epoch:15 step:14894 [D loss: 0.602662, acc.: 63.28%] [G loss: 0.428925]\n",
      "epoch:15 step:14895 [D loss: 0.604879, acc.: 63.28%] [G loss: 0.490096]\n",
      "epoch:15 step:14896 [D loss: 0.531033, acc.: 71.88%] [G loss: 0.482442]\n",
      "epoch:15 step:14897 [D loss: 0.466453, acc.: 78.91%] [G loss: 0.549814]\n",
      "epoch:15 step:14898 [D loss: 0.543489, acc.: 67.97%] [G loss: 0.601823]\n",
      "epoch:15 step:14899 [D loss: 0.625581, acc.: 64.06%] [G loss: 0.485270]\n",
      "epoch:15 step:14900 [D loss: 0.606035, acc.: 63.28%] [G loss: 0.504772]\n",
      "epoch:15 step:14901 [D loss: 0.565421, acc.: 71.09%] [G loss: 0.478896]\n",
      "epoch:15 step:14902 [D loss: 0.600833, acc.: 69.53%] [G loss: 0.483476]\n",
      "epoch:15 step:14903 [D loss: 0.561874, acc.: 64.06%] [G loss: 0.566090]\n",
      "epoch:15 step:14904 [D loss: 0.544266, acc.: 69.53%] [G loss: 0.476929]\n",
      "epoch:15 step:14905 [D loss: 0.532822, acc.: 73.44%] [G loss: 0.464463]\n",
      "epoch:15 step:14906 [D loss: 0.600902, acc.: 62.50%] [G loss: 0.467019]\n",
      "epoch:15 step:14907 [D loss: 0.548234, acc.: 73.44%] [G loss: 0.463154]\n",
      "epoch:15 step:14908 [D loss: 0.518612, acc.: 76.56%] [G loss: 0.578772]\n",
      "epoch:15 step:14909 [D loss: 0.503918, acc.: 71.88%] [G loss: 0.651790]\n",
      "epoch:15 step:14910 [D loss: 0.540680, acc.: 71.09%] [G loss: 0.693954]\n",
      "epoch:15 step:14911 [D loss: 0.610835, acc.: 66.41%] [G loss: 0.739863]\n",
      "epoch:15 step:14912 [D loss: 0.414397, acc.: 78.91%] [G loss: 0.752888]\n",
      "epoch:15 step:14913 [D loss: 0.695221, acc.: 64.06%] [G loss: 0.521139]\n",
      "epoch:15 step:14914 [D loss: 0.565003, acc.: 71.88%] [G loss: 0.652961]\n",
      "epoch:15 step:14915 [D loss: 0.467840, acc.: 75.00%] [G loss: 0.659883]\n",
      "epoch:15 step:14916 [D loss: 0.625832, acc.: 67.19%] [G loss: 0.581369]\n",
      "epoch:15 step:14917 [D loss: 0.585308, acc.: 67.97%] [G loss: 0.464789]\n",
      "epoch:15 step:14918 [D loss: 0.550543, acc.: 65.62%] [G loss: 0.453133]\n",
      "epoch:15 step:14919 [D loss: 0.540348, acc.: 67.97%] [G loss: 0.502794]\n",
      "epoch:15 step:14920 [D loss: 0.580319, acc.: 67.97%] [G loss: 0.449615]\n",
      "epoch:15 step:14921 [D loss: 0.528722, acc.: 71.09%] [G loss: 0.466296]\n",
      "epoch:15 step:14922 [D loss: 0.674589, acc.: 58.59%] [G loss: 0.340050]\n",
      "epoch:15 step:14923 [D loss: 0.548978, acc.: 68.75%] [G loss: 0.474849]\n",
      "epoch:15 step:14924 [D loss: 0.573890, acc.: 63.28%] [G loss: 0.535037]\n",
      "epoch:15 step:14925 [D loss: 0.437259, acc.: 80.47%] [G loss: 0.693099]\n",
      "epoch:15 step:14926 [D loss: 0.564474, acc.: 69.53%] [G loss: 0.613494]\n",
      "epoch:15 step:14927 [D loss: 0.598307, acc.: 63.28%] [G loss: 0.515453]\n",
      "epoch:15 step:14928 [D loss: 0.605220, acc.: 67.19%] [G loss: 0.545424]\n",
      "epoch:15 step:14929 [D loss: 0.548089, acc.: 70.31%] [G loss: 0.497045]\n",
      "epoch:15 step:14930 [D loss: 0.524838, acc.: 67.97%] [G loss: 0.528791]\n",
      "epoch:15 step:14931 [D loss: 0.542262, acc.: 72.66%] [G loss: 0.629902]\n",
      "epoch:15 step:14932 [D loss: 0.564141, acc.: 67.19%] [G loss: 0.565825]\n",
      "epoch:15 step:14933 [D loss: 0.532211, acc.: 75.00%] [G loss: 0.516129]\n",
      "epoch:15 step:14934 [D loss: 0.529053, acc.: 73.44%] [G loss: 0.558348]\n",
      "epoch:15 step:14935 [D loss: 0.669293, acc.: 57.03%] [G loss: 0.404794]\n",
      "epoch:15 step:14936 [D loss: 0.563993, acc.: 66.41%] [G loss: 0.428592]\n",
      "epoch:15 step:14937 [D loss: 0.578105, acc.: 66.41%] [G loss: 0.518168]\n",
      "epoch:15 step:14938 [D loss: 0.664784, acc.: 65.62%] [G loss: 0.602037]\n",
      "epoch:15 step:14939 [D loss: 0.484217, acc.: 79.69%] [G loss: 0.707102]\n",
      "epoch:15 step:14940 [D loss: 0.567343, acc.: 70.31%] [G loss: 0.785355]\n",
      "epoch:15 step:14941 [D loss: 0.528067, acc.: 73.44%] [G loss: 0.715648]\n",
      "epoch:15 step:14942 [D loss: 0.556508, acc.: 71.88%] [G loss: 0.634853]\n",
      "epoch:15 step:14943 [D loss: 0.561228, acc.: 70.31%] [G loss: 0.601430]\n",
      "epoch:15 step:14944 [D loss: 0.583170, acc.: 63.28%] [G loss: 0.549227]\n",
      "epoch:15 step:14945 [D loss: 0.494014, acc.: 74.22%] [G loss: 0.636059]\n",
      "epoch:15 step:14946 [D loss: 0.600485, acc.: 67.97%] [G loss: 0.543344]\n",
      "epoch:15 step:14947 [D loss: 0.658539, acc.: 64.06%] [G loss: 0.501794]\n",
      "epoch:15 step:14948 [D loss: 0.499201, acc.: 78.91%] [G loss: 0.544468]\n",
      "epoch:15 step:14949 [D loss: 0.499455, acc.: 74.22%] [G loss: 0.607180]\n",
      "epoch:15 step:14950 [D loss: 0.611772, acc.: 64.84%] [G loss: 0.741506]\n",
      "epoch:15 step:14951 [D loss: 0.457378, acc.: 80.47%] [G loss: 0.822116]\n",
      "epoch:15 step:14952 [D loss: 0.497421, acc.: 75.00%] [G loss: 0.753474]\n",
      "epoch:15 step:14953 [D loss: 0.491935, acc.: 78.12%] [G loss: 0.804665]\n",
      "epoch:15 step:14954 [D loss: 0.471542, acc.: 78.12%] [G loss: 0.732510]\n",
      "epoch:15 step:14955 [D loss: 0.541979, acc.: 67.19%] [G loss: 0.797417]\n",
      "epoch:15 step:14956 [D loss: 0.543970, acc.: 66.41%] [G loss: 0.776510]\n",
      "epoch:15 step:14957 [D loss: 0.635894, acc.: 66.41%] [G loss: 0.548782]\n",
      "epoch:15 step:14958 [D loss: 0.541863, acc.: 71.09%] [G loss: 0.644255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14959 [D loss: 0.569539, acc.: 71.88%] [G loss: 0.425853]\n",
      "epoch:15 step:14960 [D loss: 0.544943, acc.: 71.09%] [G loss: 0.597999]\n",
      "epoch:15 step:14961 [D loss: 0.454097, acc.: 76.56%] [G loss: 0.731709]\n",
      "epoch:15 step:14962 [D loss: 0.570775, acc.: 67.19%] [G loss: 0.572939]\n",
      "epoch:15 step:14963 [D loss: 0.569940, acc.: 71.88%] [G loss: 0.543185]\n",
      "epoch:15 step:14964 [D loss: 0.520476, acc.: 69.53%] [G loss: 0.554953]\n",
      "epoch:15 step:14965 [D loss: 0.593542, acc.: 67.19%] [G loss: 0.689478]\n",
      "epoch:15 step:14966 [D loss: 0.457358, acc.: 78.12%] [G loss: 0.924563]\n",
      "epoch:15 step:14967 [D loss: 0.525244, acc.: 74.22%] [G loss: 0.887570]\n",
      "epoch:15 step:14968 [D loss: 0.532598, acc.: 78.12%] [G loss: 0.786156]\n",
      "epoch:15 step:14969 [D loss: 0.457106, acc.: 76.56%] [G loss: 0.857258]\n",
      "epoch:15 step:14970 [D loss: 0.650099, acc.: 64.84%] [G loss: 0.691215]\n",
      "epoch:15 step:14971 [D loss: 0.511687, acc.: 70.31%] [G loss: 0.838838]\n",
      "epoch:15 step:14972 [D loss: 0.615755, acc.: 57.81%] [G loss: 0.600349]\n",
      "epoch:15 step:14973 [D loss: 0.494485, acc.: 74.22%] [G loss: 0.703526]\n",
      "epoch:15 step:14974 [D loss: 0.451104, acc.: 84.38%] [G loss: 0.734733]\n",
      "epoch:15 step:14975 [D loss: 0.654610, acc.: 61.72%] [G loss: 0.603461]\n",
      "epoch:15 step:14976 [D loss: 0.488391, acc.: 75.00%] [G loss: 0.733433]\n",
      "epoch:15 step:14977 [D loss: 0.529944, acc.: 75.78%] [G loss: 0.521739]\n",
      "epoch:15 step:14978 [D loss: 0.504598, acc.: 69.53%] [G loss: 0.655496]\n",
      "epoch:15 step:14979 [D loss: 0.447146, acc.: 78.12%] [G loss: 0.682756]\n",
      "epoch:15 step:14980 [D loss: 0.425698, acc.: 80.47%] [G loss: 0.904182]\n",
      "epoch:15 step:14981 [D loss: 0.418658, acc.: 79.69%] [G loss: 0.909558]\n",
      "epoch:15 step:14982 [D loss: 0.534545, acc.: 70.31%] [G loss: 1.297850]\n",
      "epoch:15 step:14983 [D loss: 0.678600, acc.: 61.72%] [G loss: 1.267278]\n",
      "epoch:15 step:14984 [D loss: 0.482009, acc.: 78.12%] [G loss: 1.343403]\n",
      "epoch:15 step:14985 [D loss: 0.418402, acc.: 80.47%] [G loss: 0.858513]\n",
      "epoch:15 step:14986 [D loss: 0.611226, acc.: 66.41%] [G loss: 0.965113]\n",
      "epoch:15 step:14987 [D loss: 0.627257, acc.: 63.28%] [G loss: 0.705190]\n",
      "epoch:15 step:14988 [D loss: 0.509883, acc.: 73.44%] [G loss: 0.678395]\n",
      "epoch:15 step:14989 [D loss: 0.492703, acc.: 70.31%] [G loss: 0.882752]\n",
      "epoch:15 step:14990 [D loss: 0.483562, acc.: 74.22%] [G loss: 1.033947]\n",
      "epoch:15 step:14991 [D loss: 0.415609, acc.: 77.34%] [G loss: 1.095257]\n",
      "epoch:15 step:14992 [D loss: 0.425607, acc.: 82.81%] [G loss: 1.245163]\n",
      "epoch:16 step:14993 [D loss: 0.571668, acc.: 69.53%] [G loss: 1.110178]\n",
      "epoch:16 step:14994 [D loss: 0.462156, acc.: 79.69%] [G loss: 0.941439]\n",
      "epoch:16 step:14995 [D loss: 0.615199, acc.: 60.16%] [G loss: 0.879762]\n",
      "epoch:16 step:14996 [D loss: 0.499348, acc.: 76.56%] [G loss: 0.850026]\n",
      "epoch:16 step:14997 [D loss: 0.556906, acc.: 71.88%] [G loss: 0.626938]\n",
      "epoch:16 step:14998 [D loss: 0.603378, acc.: 67.19%] [G loss: 0.648590]\n",
      "epoch:16 step:14999 [D loss: 0.490528, acc.: 78.12%] [G loss: 0.694715]\n",
      "epoch:16 step:15000 [D loss: 0.519583, acc.: 75.78%] [G loss: 0.577963]\n",
      "##############\n",
      "[2.5379005  0.69832555 6.26492242 4.83247162 3.62652528 5.71066953\n",
      " 4.6657366  4.95514888 4.5282953  4.3170241 ]\n",
      "##########\n",
      "epoch:16 step:15001 [D loss: 0.493217, acc.: 72.66%] [G loss: 0.767680]\n",
      "epoch:16 step:15002 [D loss: 0.515774, acc.: 75.00%] [G loss: 0.745747]\n",
      "epoch:16 step:15003 [D loss: 0.594873, acc.: 69.53%] [G loss: 0.736363]\n",
      "epoch:16 step:15004 [D loss: 0.528410, acc.: 69.53%] [G loss: 0.793295]\n",
      "epoch:16 step:15005 [D loss: 0.570968, acc.: 71.09%] [G loss: 0.492256]\n",
      "epoch:16 step:15006 [D loss: 0.560913, acc.: 68.75%] [G loss: 0.687287]\n",
      "epoch:16 step:15007 [D loss: 0.516161, acc.: 73.44%] [G loss: 0.568894]\n",
      "epoch:16 step:15008 [D loss: 0.468132, acc.: 77.34%] [G loss: 0.783115]\n",
      "epoch:16 step:15009 [D loss: 0.557538, acc.: 70.31%] [G loss: 0.625788]\n",
      "epoch:16 step:15010 [D loss: 0.558466, acc.: 69.53%] [G loss: 0.584528]\n",
      "epoch:16 step:15011 [D loss: 0.591613, acc.: 65.62%] [G loss: 0.748277]\n",
      "epoch:16 step:15012 [D loss: 0.663409, acc.: 62.50%] [G loss: 0.733785]\n",
      "epoch:16 step:15013 [D loss: 0.582760, acc.: 71.09%] [G loss: 0.696531]\n",
      "epoch:16 step:15014 [D loss: 0.483333, acc.: 79.69%] [G loss: 0.878076]\n",
      "epoch:16 step:15015 [D loss: 0.554548, acc.: 71.88%] [G loss: 0.631094]\n",
      "epoch:16 step:15016 [D loss: 0.516849, acc.: 73.44%] [G loss: 0.573738]\n",
      "epoch:16 step:15017 [D loss: 0.493386, acc.: 76.56%] [G loss: 0.639411]\n",
      "epoch:16 step:15018 [D loss: 0.683958, acc.: 61.72%] [G loss: 0.482409]\n",
      "epoch:16 step:15019 [D loss: 0.479069, acc.: 80.47%] [G loss: 0.704080]\n",
      "epoch:16 step:15020 [D loss: 0.608214, acc.: 61.72%] [G loss: 0.697098]\n",
      "epoch:16 step:15021 [D loss: 0.490086, acc.: 75.78%] [G loss: 0.674671]\n",
      "epoch:16 step:15022 [D loss: 0.544464, acc.: 74.22%] [G loss: 0.601922]\n",
      "epoch:16 step:15023 [D loss: 0.620432, acc.: 60.16%] [G loss: 0.534866]\n",
      "epoch:16 step:15024 [D loss: 0.570467, acc.: 71.88%] [G loss: 0.533453]\n",
      "epoch:16 step:15025 [D loss: 0.484744, acc.: 76.56%] [G loss: 0.574094]\n",
      "epoch:16 step:15026 [D loss: 0.521649, acc.: 73.44%] [G loss: 0.695616]\n",
      "epoch:16 step:15027 [D loss: 0.561473, acc.: 65.62%] [G loss: 0.597438]\n",
      "epoch:16 step:15028 [D loss: 0.532399, acc.: 69.53%] [G loss: 0.733934]\n",
      "epoch:16 step:15029 [D loss: 0.498809, acc.: 78.12%] [G loss: 0.703216]\n",
      "epoch:16 step:15030 [D loss: 0.565273, acc.: 71.88%] [G loss: 0.691072]\n",
      "epoch:16 step:15031 [D loss: 0.562013, acc.: 69.53%] [G loss: 0.563345]\n",
      "epoch:16 step:15032 [D loss: 0.420423, acc.: 80.47%] [G loss: 0.781695]\n",
      "epoch:16 step:15033 [D loss: 0.597965, acc.: 67.19%] [G loss: 0.573054]\n",
      "epoch:16 step:15034 [D loss: 0.582250, acc.: 64.84%] [G loss: 0.784167]\n",
      "epoch:16 step:15035 [D loss: 0.551532, acc.: 72.66%] [G loss: 0.616567]\n",
      "epoch:16 step:15036 [D loss: 0.619292, acc.: 66.41%] [G loss: 0.593138]\n",
      "epoch:16 step:15037 [D loss: 0.550446, acc.: 69.53%] [G loss: 0.633417]\n",
      "epoch:16 step:15038 [D loss: 0.470659, acc.: 76.56%] [G loss: 0.695115]\n",
      "epoch:16 step:15039 [D loss: 0.540316, acc.: 67.19%] [G loss: 0.756167]\n",
      "epoch:16 step:15040 [D loss: 0.481372, acc.: 76.56%] [G loss: 0.729112]\n",
      "epoch:16 step:15041 [D loss: 0.554818, acc.: 71.09%] [G loss: 0.621305]\n",
      "epoch:16 step:15042 [D loss: 0.530353, acc.: 70.31%] [G loss: 0.789605]\n",
      "epoch:16 step:15043 [D loss: 0.634659, acc.: 62.50%] [G loss: 0.476213]\n",
      "epoch:16 step:15044 [D loss: 0.556532, acc.: 70.31%] [G loss: 0.606763]\n",
      "epoch:16 step:15045 [D loss: 0.519099, acc.: 77.34%] [G loss: 0.623765]\n",
      "epoch:16 step:15046 [D loss: 0.518381, acc.: 71.88%] [G loss: 0.646131]\n",
      "epoch:16 step:15047 [D loss: 0.529745, acc.: 73.44%] [G loss: 0.699971]\n",
      "epoch:16 step:15048 [D loss: 0.548248, acc.: 73.44%] [G loss: 0.686493]\n",
      "epoch:16 step:15049 [D loss: 0.546942, acc.: 71.09%] [G loss: 0.679655]\n",
      "epoch:16 step:15050 [D loss: 0.549714, acc.: 71.09%] [G loss: 0.716058]\n",
      "epoch:16 step:15051 [D loss: 0.545559, acc.: 71.09%] [G loss: 0.659055]\n",
      "epoch:16 step:15052 [D loss: 0.555474, acc.: 69.53%] [G loss: 0.678604]\n",
      "epoch:16 step:15053 [D loss: 0.581936, acc.: 60.16%] [G loss: 0.574984]\n",
      "epoch:16 step:15054 [D loss: 0.583890, acc.: 73.44%] [G loss: 0.565378]\n",
      "epoch:16 step:15055 [D loss: 0.568685, acc.: 67.19%] [G loss: 0.540130]\n",
      "epoch:16 step:15056 [D loss: 0.639793, acc.: 71.88%] [G loss: 0.688597]\n",
      "epoch:16 step:15057 [D loss: 0.517321, acc.: 71.09%] [G loss: 0.496289]\n",
      "epoch:16 step:15058 [D loss: 0.493017, acc.: 75.78%] [G loss: 0.572593]\n",
      "epoch:16 step:15059 [D loss: 0.561667, acc.: 68.75%] [G loss: 0.481657]\n",
      "epoch:16 step:15060 [D loss: 0.568857, acc.: 68.75%] [G loss: 0.504743]\n",
      "epoch:16 step:15061 [D loss: 0.504170, acc.: 76.56%] [G loss: 0.560239]\n",
      "epoch:16 step:15062 [D loss: 0.477858, acc.: 78.91%] [G loss: 0.730100]\n",
      "epoch:16 step:15063 [D loss: 0.557154, acc.: 70.31%] [G loss: 0.711602]\n",
      "epoch:16 step:15064 [D loss: 0.560118, acc.: 69.53%] [G loss: 0.619869]\n",
      "epoch:16 step:15065 [D loss: 0.578896, acc.: 67.97%] [G loss: 0.556827]\n",
      "epoch:16 step:15066 [D loss: 0.505556, acc.: 72.66%] [G loss: 0.652594]\n",
      "epoch:16 step:15067 [D loss: 0.475680, acc.: 75.78%] [G loss: 0.851803]\n",
      "epoch:16 step:15068 [D loss: 0.499521, acc.: 69.53%] [G loss: 0.786026]\n",
      "epoch:16 step:15069 [D loss: 0.441325, acc.: 81.25%] [G loss: 0.813531]\n",
      "epoch:16 step:15070 [D loss: 0.579186, acc.: 65.62%] [G loss: 0.559436]\n",
      "epoch:16 step:15071 [D loss: 0.542628, acc.: 70.31%] [G loss: 0.564894]\n",
      "epoch:16 step:15072 [D loss: 0.535633, acc.: 74.22%] [G loss: 0.593416]\n",
      "epoch:16 step:15073 [D loss: 0.541084, acc.: 71.09%] [G loss: 0.579181]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15074 [D loss: 0.502590, acc.: 70.31%] [G loss: 0.678437]\n",
      "epoch:16 step:15075 [D loss: 0.469340, acc.: 77.34%] [G loss: 0.719611]\n",
      "epoch:16 step:15076 [D loss: 0.541482, acc.: 69.53%] [G loss: 0.608100]\n",
      "epoch:16 step:15077 [D loss: 0.578350, acc.: 65.62%] [G loss: 0.651976]\n",
      "epoch:16 step:15078 [D loss: 0.509120, acc.: 67.97%] [G loss: 0.690983]\n",
      "epoch:16 step:15079 [D loss: 0.514062, acc.: 71.88%] [G loss: 0.730727]\n",
      "epoch:16 step:15080 [D loss: 0.504772, acc.: 74.22%] [G loss: 0.584662]\n",
      "epoch:16 step:15081 [D loss: 0.522788, acc.: 71.88%] [G loss: 0.527748]\n",
      "epoch:16 step:15082 [D loss: 0.518116, acc.: 72.66%] [G loss: 0.619038]\n",
      "epoch:16 step:15083 [D loss: 0.564336, acc.: 66.41%] [G loss: 0.553355]\n",
      "epoch:16 step:15084 [D loss: 0.480669, acc.: 77.34%] [G loss: 0.668558]\n",
      "epoch:16 step:15085 [D loss: 0.506913, acc.: 73.44%] [G loss: 0.669238]\n",
      "epoch:16 step:15086 [D loss: 0.482843, acc.: 72.66%] [G loss: 0.690680]\n",
      "epoch:16 step:15087 [D loss: 0.537554, acc.: 72.66%] [G loss: 0.721254]\n",
      "epoch:16 step:15088 [D loss: 0.531109, acc.: 71.09%] [G loss: 0.726970]\n",
      "epoch:16 step:15089 [D loss: 0.566286, acc.: 68.75%] [G loss: 0.612145]\n",
      "epoch:16 step:15090 [D loss: 0.554577, acc.: 70.31%] [G loss: 0.802811]\n",
      "epoch:16 step:15091 [D loss: 0.488205, acc.: 78.12%] [G loss: 0.677174]\n",
      "epoch:16 step:15092 [D loss: 0.415349, acc.: 82.03%] [G loss: 0.961517]\n",
      "epoch:16 step:15093 [D loss: 0.530677, acc.: 76.56%] [G loss: 0.754427]\n",
      "epoch:16 step:15094 [D loss: 0.626946, acc.: 67.97%] [G loss: 0.498153]\n",
      "epoch:16 step:15095 [D loss: 0.487499, acc.: 72.66%] [G loss: 0.720675]\n",
      "epoch:16 step:15096 [D loss: 0.508370, acc.: 71.88%] [G loss: 0.612766]\n",
      "epoch:16 step:15097 [D loss: 0.586442, acc.: 65.62%] [G loss: 0.523767]\n",
      "epoch:16 step:15098 [D loss: 0.504804, acc.: 71.88%] [G loss: 0.580760]\n",
      "epoch:16 step:15099 [D loss: 0.591240, acc.: 64.06%] [G loss: 0.642803]\n",
      "epoch:16 step:15100 [D loss: 0.615588, acc.: 64.06%] [G loss: 0.584361]\n",
      "epoch:16 step:15101 [D loss: 0.592756, acc.: 67.97%] [G loss: 0.499328]\n",
      "epoch:16 step:15102 [D loss: 0.584962, acc.: 65.62%] [G loss: 0.542549]\n",
      "epoch:16 step:15103 [D loss: 0.498699, acc.: 74.22%] [G loss: 0.545987]\n",
      "epoch:16 step:15104 [D loss: 0.514947, acc.: 76.56%] [G loss: 0.595042]\n",
      "epoch:16 step:15105 [D loss: 0.573422, acc.: 72.66%] [G loss: 0.566044]\n",
      "epoch:16 step:15106 [D loss: 0.575759, acc.: 67.97%] [G loss: 0.514283]\n",
      "epoch:16 step:15107 [D loss: 0.514941, acc.: 73.44%] [G loss: 0.617291]\n",
      "epoch:16 step:15108 [D loss: 0.523328, acc.: 67.19%] [G loss: 0.717701]\n",
      "epoch:16 step:15109 [D loss: 0.511390, acc.: 70.31%] [G loss: 0.681190]\n",
      "epoch:16 step:15110 [D loss: 0.551209, acc.: 68.75%] [G loss: 0.830245]\n",
      "epoch:16 step:15111 [D loss: 0.472034, acc.: 71.88%] [G loss: 0.996628]\n",
      "epoch:16 step:15112 [D loss: 0.569476, acc.: 73.44%] [G loss: 0.777864]\n",
      "epoch:16 step:15113 [D loss: 0.549619, acc.: 73.44%] [G loss: 0.751416]\n",
      "epoch:16 step:15114 [D loss: 0.508035, acc.: 78.12%] [G loss: 0.827016]\n",
      "epoch:16 step:15115 [D loss: 0.488102, acc.: 76.56%] [G loss: 0.851333]\n",
      "epoch:16 step:15116 [D loss: 0.620851, acc.: 65.62%] [G loss: 0.660152]\n",
      "epoch:16 step:15117 [D loss: 0.583416, acc.: 63.28%] [G loss: 0.484400]\n",
      "epoch:16 step:15118 [D loss: 0.473526, acc.: 78.12%] [G loss: 0.624068]\n",
      "epoch:16 step:15119 [D loss: 0.506820, acc.: 71.88%] [G loss: 0.565230]\n",
      "epoch:16 step:15120 [D loss: 0.492946, acc.: 70.31%] [G loss: 0.613944]\n",
      "epoch:16 step:15121 [D loss: 0.553720, acc.: 69.53%] [G loss: 0.667401]\n",
      "epoch:16 step:15122 [D loss: 0.498813, acc.: 76.56%] [G loss: 0.577512]\n",
      "epoch:16 step:15123 [D loss: 0.503554, acc.: 72.66%] [G loss: 0.599016]\n",
      "epoch:16 step:15124 [D loss: 0.539858, acc.: 73.44%] [G loss: 0.740603]\n",
      "epoch:16 step:15125 [D loss: 0.577763, acc.: 68.75%] [G loss: 0.629648]\n",
      "epoch:16 step:15126 [D loss: 0.501862, acc.: 73.44%] [G loss: 0.926051]\n",
      "epoch:16 step:15127 [D loss: 0.533332, acc.: 71.88%] [G loss: 0.570235]\n",
      "epoch:16 step:15128 [D loss: 0.528761, acc.: 75.00%] [G loss: 0.653406]\n",
      "epoch:16 step:15129 [D loss: 0.640764, acc.: 64.84%] [G loss: 0.565318]\n",
      "epoch:16 step:15130 [D loss: 0.562330, acc.: 67.97%] [G loss: 0.607085]\n",
      "epoch:16 step:15131 [D loss: 0.521653, acc.: 73.44%] [G loss: 0.557971]\n",
      "epoch:16 step:15132 [D loss: 0.582881, acc.: 67.19%] [G loss: 0.584555]\n",
      "epoch:16 step:15133 [D loss: 0.548847, acc.: 66.41%] [G loss: 0.773957]\n",
      "epoch:16 step:15134 [D loss: 0.559220, acc.: 67.97%] [G loss: 0.678801]\n",
      "epoch:16 step:15135 [D loss: 0.603845, acc.: 62.50%] [G loss: 0.597597]\n",
      "epoch:16 step:15136 [D loss: 0.503905, acc.: 76.56%] [G loss: 0.643355]\n",
      "epoch:16 step:15137 [D loss: 0.553586, acc.: 70.31%] [G loss: 0.806450]\n",
      "epoch:16 step:15138 [D loss: 0.553491, acc.: 72.66%] [G loss: 0.755513]\n",
      "epoch:16 step:15139 [D loss: 0.634960, acc.: 68.75%] [G loss: 0.621670]\n",
      "epoch:16 step:15140 [D loss: 0.581755, acc.: 64.84%] [G loss: 0.609080]\n",
      "epoch:16 step:15141 [D loss: 0.562479, acc.: 69.53%] [G loss: 0.475305]\n",
      "epoch:16 step:15142 [D loss: 0.575006, acc.: 67.97%] [G loss: 0.623113]\n",
      "epoch:16 step:15143 [D loss: 0.615729, acc.: 67.19%] [G loss: 0.640734]\n",
      "epoch:16 step:15144 [D loss: 0.466352, acc.: 79.69%] [G loss: 0.819359]\n",
      "epoch:16 step:15145 [D loss: 0.582951, acc.: 68.75%] [G loss: 0.626551]\n",
      "epoch:16 step:15146 [D loss: 0.582990, acc.: 62.50%] [G loss: 0.663914]\n",
      "epoch:16 step:15147 [D loss: 0.459188, acc.: 76.56%] [G loss: 0.769847]\n",
      "epoch:16 step:15148 [D loss: 0.494755, acc.: 75.00%] [G loss: 0.952750]\n",
      "epoch:16 step:15149 [D loss: 0.569458, acc.: 66.41%] [G loss: 0.678148]\n",
      "epoch:16 step:15150 [D loss: 0.581720, acc.: 70.31%] [G loss: 0.677817]\n",
      "epoch:16 step:15151 [D loss: 0.496394, acc.: 73.44%] [G loss: 0.644084]\n",
      "epoch:16 step:15152 [D loss: 0.576490, acc.: 70.31%] [G loss: 0.763597]\n",
      "epoch:16 step:15153 [D loss: 0.582438, acc.: 66.41%] [G loss: 0.674221]\n",
      "epoch:16 step:15154 [D loss: 0.479506, acc.: 78.12%] [G loss: 0.672960]\n",
      "epoch:16 step:15155 [D loss: 0.563741, acc.: 64.84%] [G loss: 0.688433]\n",
      "epoch:16 step:15156 [D loss: 0.585356, acc.: 65.62%] [G loss: 0.769081]\n",
      "epoch:16 step:15157 [D loss: 0.547462, acc.: 71.88%] [G loss: 0.594960]\n",
      "epoch:16 step:15158 [D loss: 0.509000, acc.: 73.44%] [G loss: 0.663333]\n",
      "epoch:16 step:15159 [D loss: 0.534278, acc.: 73.44%] [G loss: 0.538756]\n",
      "epoch:16 step:15160 [D loss: 0.521481, acc.: 75.00%] [G loss: 0.567657]\n",
      "epoch:16 step:15161 [D loss: 0.614397, acc.: 64.06%] [G loss: 0.449832]\n",
      "epoch:16 step:15162 [D loss: 0.531608, acc.: 75.00%] [G loss: 0.509929]\n",
      "epoch:16 step:15163 [D loss: 0.527777, acc.: 72.66%] [G loss: 0.526890]\n",
      "epoch:16 step:15164 [D loss: 0.541816, acc.: 71.09%] [G loss: 0.653227]\n",
      "epoch:16 step:15165 [D loss: 0.493838, acc.: 73.44%] [G loss: 0.655360]\n",
      "epoch:16 step:15166 [D loss: 0.580140, acc.: 64.84%] [G loss: 0.554880]\n",
      "epoch:16 step:15167 [D loss: 0.619748, acc.: 60.94%] [G loss: 0.586634]\n",
      "epoch:16 step:15168 [D loss: 0.524923, acc.: 75.78%] [G loss: 0.515030]\n",
      "epoch:16 step:15169 [D loss: 0.555081, acc.: 69.53%] [G loss: 0.582122]\n",
      "epoch:16 step:15170 [D loss: 0.556767, acc.: 66.41%] [G loss: 0.564588]\n",
      "epoch:16 step:15171 [D loss: 0.542959, acc.: 69.53%] [G loss: 0.562626]\n",
      "epoch:16 step:15172 [D loss: 0.588794, acc.: 68.75%] [G loss: 0.525085]\n",
      "epoch:16 step:15173 [D loss: 0.556539, acc.: 69.53%] [G loss: 0.516340]\n",
      "epoch:16 step:15174 [D loss: 0.515928, acc.: 75.00%] [G loss: 0.534996]\n",
      "epoch:16 step:15175 [D loss: 0.595805, acc.: 67.97%] [G loss: 0.707738]\n",
      "epoch:16 step:15176 [D loss: 0.575993, acc.: 70.31%] [G loss: 0.589081]\n",
      "epoch:16 step:15177 [D loss: 0.537149, acc.: 73.44%] [G loss: 0.598897]\n",
      "epoch:16 step:15178 [D loss: 0.542104, acc.: 65.62%] [G loss: 0.625592]\n",
      "epoch:16 step:15179 [D loss: 0.625356, acc.: 60.94%] [G loss: 0.547134]\n",
      "epoch:16 step:15180 [D loss: 0.580163, acc.: 68.75%] [G loss: 0.664818]\n",
      "epoch:16 step:15181 [D loss: 0.636588, acc.: 64.06%] [G loss: 0.470023]\n",
      "epoch:16 step:15182 [D loss: 0.495572, acc.: 75.00%] [G loss: 0.574923]\n",
      "epoch:16 step:15183 [D loss: 0.492713, acc.: 75.78%] [G loss: 0.633535]\n",
      "epoch:16 step:15184 [D loss: 0.529734, acc.: 78.12%] [G loss: 0.634251]\n",
      "epoch:16 step:15185 [D loss: 0.494861, acc.: 77.34%] [G loss: 0.550490]\n",
      "epoch:16 step:15186 [D loss: 0.447522, acc.: 80.47%] [G loss: 0.735057]\n",
      "epoch:16 step:15187 [D loss: 0.621294, acc.: 67.97%] [G loss: 0.686325]\n",
      "epoch:16 step:15188 [D loss: 0.535608, acc.: 67.97%] [G loss: 0.606644]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15189 [D loss: 0.556837, acc.: 75.78%] [G loss: 0.706704]\n",
      "epoch:16 step:15190 [D loss: 0.458221, acc.: 78.91%] [G loss: 0.639549]\n",
      "epoch:16 step:15191 [D loss: 0.495418, acc.: 72.66%] [G loss: 0.582457]\n",
      "epoch:16 step:15192 [D loss: 0.584190, acc.: 67.97%] [G loss: 0.560617]\n",
      "epoch:16 step:15193 [D loss: 0.516630, acc.: 75.00%] [G loss: 0.563883]\n",
      "epoch:16 step:15194 [D loss: 0.558402, acc.: 70.31%] [G loss: 0.716260]\n",
      "epoch:16 step:15195 [D loss: 0.658900, acc.: 61.72%] [G loss: 0.515662]\n",
      "epoch:16 step:15196 [D loss: 0.606364, acc.: 63.28%] [G loss: 0.549715]\n",
      "epoch:16 step:15197 [D loss: 0.534353, acc.: 69.53%] [G loss: 0.626572]\n",
      "epoch:16 step:15198 [D loss: 0.504729, acc.: 74.22%] [G loss: 0.844662]\n",
      "epoch:16 step:15199 [D loss: 0.475451, acc.: 78.91%] [G loss: 0.797900]\n",
      "epoch:16 step:15200 [D loss: 0.493085, acc.: 76.56%] [G loss: 0.871160]\n",
      "##############\n",
      "[2.97418891 0.99650596 6.35900169 4.8067344  3.70845717 5.87519954\n",
      " 4.36174824 4.92448832 4.39234482 4.13391306]\n",
      "##########\n",
      "epoch:16 step:15201 [D loss: 0.483769, acc.: 75.78%] [G loss: 0.900443]\n",
      "epoch:16 step:15202 [D loss: 0.578392, acc.: 72.66%] [G loss: 0.733735]\n",
      "epoch:16 step:15203 [D loss: 0.587308, acc.: 66.41%] [G loss: 0.595244]\n",
      "epoch:16 step:15204 [D loss: 0.483686, acc.: 79.69%] [G loss: 0.573819]\n",
      "epoch:16 step:15205 [D loss: 0.546681, acc.: 71.09%] [G loss: 0.503225]\n",
      "epoch:16 step:15206 [D loss: 0.632451, acc.: 64.06%] [G loss: 0.557693]\n",
      "epoch:16 step:15207 [D loss: 0.600132, acc.: 64.06%] [G loss: 0.451145]\n",
      "epoch:16 step:15208 [D loss: 0.482720, acc.: 77.34%] [G loss: 0.680233]\n",
      "epoch:16 step:15209 [D loss: 0.535220, acc.: 66.41%] [G loss: 0.652941]\n",
      "epoch:16 step:15210 [D loss: 0.525431, acc.: 71.88%] [G loss: 0.548502]\n",
      "epoch:16 step:15211 [D loss: 0.493015, acc.: 75.00%] [G loss: 0.773104]\n",
      "epoch:16 step:15212 [D loss: 0.605835, acc.: 67.97%] [G loss: 0.600608]\n",
      "epoch:16 step:15213 [D loss: 0.523755, acc.: 73.44%] [G loss: 0.752636]\n",
      "epoch:16 step:15214 [D loss: 0.508072, acc.: 71.09%] [G loss: 0.656030]\n",
      "epoch:16 step:15215 [D loss: 0.517181, acc.: 74.22%] [G loss: 0.682484]\n",
      "epoch:16 step:15216 [D loss: 0.600063, acc.: 67.97%] [G loss: 0.565982]\n",
      "epoch:16 step:15217 [D loss: 0.516833, acc.: 75.00%] [G loss: 0.653914]\n",
      "epoch:16 step:15218 [D loss: 0.602021, acc.: 59.38%] [G loss: 0.570950]\n",
      "epoch:16 step:15219 [D loss: 0.538792, acc.: 70.31%] [G loss: 0.608277]\n",
      "epoch:16 step:15220 [D loss: 0.614363, acc.: 63.28%] [G loss: 0.514732]\n",
      "epoch:16 step:15221 [D loss: 0.553484, acc.: 70.31%] [G loss: 0.424420]\n",
      "epoch:16 step:15222 [D loss: 0.503076, acc.: 73.44%] [G loss: 0.624239]\n",
      "epoch:16 step:15223 [D loss: 0.447531, acc.: 79.69%] [G loss: 0.590371]\n",
      "epoch:16 step:15224 [D loss: 0.474237, acc.: 76.56%] [G loss: 0.801002]\n",
      "epoch:16 step:15225 [D loss: 0.525593, acc.: 75.78%] [G loss: 0.718276]\n",
      "epoch:16 step:15226 [D loss: 0.675394, acc.: 65.62%] [G loss: 0.573152]\n",
      "epoch:16 step:15227 [D loss: 0.531438, acc.: 73.44%] [G loss: 0.629128]\n",
      "epoch:16 step:15228 [D loss: 0.528169, acc.: 73.44%] [G loss: 0.636844]\n",
      "epoch:16 step:15229 [D loss: 0.531271, acc.: 69.53%] [G loss: 0.612560]\n",
      "epoch:16 step:15230 [D loss: 0.545428, acc.: 70.31%] [G loss: 0.502305]\n",
      "epoch:16 step:15231 [D loss: 0.527836, acc.: 71.88%] [G loss: 0.641813]\n",
      "epoch:16 step:15232 [D loss: 0.586287, acc.: 65.62%] [G loss: 0.651235]\n",
      "epoch:16 step:15233 [D loss: 0.517696, acc.: 71.88%] [G loss: 0.684750]\n",
      "epoch:16 step:15234 [D loss: 0.516809, acc.: 71.09%] [G loss: 0.662392]\n",
      "epoch:16 step:15235 [D loss: 0.532276, acc.: 68.75%] [G loss: 0.640142]\n",
      "epoch:16 step:15236 [D loss: 0.498094, acc.: 73.44%] [G loss: 0.781353]\n",
      "epoch:16 step:15237 [D loss: 0.544749, acc.: 72.66%] [G loss: 0.580177]\n",
      "epoch:16 step:15238 [D loss: 0.475146, acc.: 75.78%] [G loss: 0.679080]\n",
      "epoch:16 step:15239 [D loss: 0.565398, acc.: 66.41%] [G loss: 0.837419]\n",
      "epoch:16 step:15240 [D loss: 0.503886, acc.: 76.56%] [G loss: 0.792673]\n",
      "epoch:16 step:15241 [D loss: 0.566285, acc.: 72.66%] [G loss: 0.689677]\n",
      "epoch:16 step:15242 [D loss: 0.618185, acc.: 67.97%] [G loss: 0.601461]\n",
      "epoch:16 step:15243 [D loss: 0.591629, acc.: 62.50%] [G loss: 0.486803]\n",
      "epoch:16 step:15244 [D loss: 0.578128, acc.: 67.97%] [G loss: 0.595092]\n",
      "epoch:16 step:15245 [D loss: 0.577645, acc.: 67.97%] [G loss: 0.591689]\n",
      "epoch:16 step:15246 [D loss: 0.541527, acc.: 70.31%] [G loss: 0.562227]\n",
      "epoch:16 step:15247 [D loss: 0.532869, acc.: 71.88%] [G loss: 0.649906]\n",
      "epoch:16 step:15248 [D loss: 0.553646, acc.: 70.31%] [G loss: 0.647701]\n",
      "epoch:16 step:15249 [D loss: 0.547857, acc.: 68.75%] [G loss: 0.635486]\n",
      "epoch:16 step:15250 [D loss: 0.523133, acc.: 68.75%] [G loss: 0.782032]\n",
      "epoch:16 step:15251 [D loss: 0.529900, acc.: 70.31%] [G loss: 0.622711]\n",
      "epoch:16 step:15252 [D loss: 0.624838, acc.: 66.41%] [G loss: 0.378913]\n",
      "epoch:16 step:15253 [D loss: 0.534827, acc.: 73.44%] [G loss: 0.605000]\n",
      "epoch:16 step:15254 [D loss: 0.551883, acc.: 72.66%] [G loss: 0.594588]\n",
      "epoch:16 step:15255 [D loss: 0.613409, acc.: 60.94%] [G loss: 0.639192]\n",
      "epoch:16 step:15256 [D loss: 0.540205, acc.: 71.09%] [G loss: 0.488017]\n",
      "epoch:16 step:15257 [D loss: 0.633126, acc.: 65.62%] [G loss: 0.447776]\n",
      "epoch:16 step:15258 [D loss: 0.618182, acc.: 67.19%] [G loss: 0.518395]\n",
      "epoch:16 step:15259 [D loss: 0.571973, acc.: 66.41%] [G loss: 0.649976]\n",
      "epoch:16 step:15260 [D loss: 0.548935, acc.: 68.75%] [G loss: 0.642858]\n",
      "epoch:16 step:15261 [D loss: 0.584391, acc.: 70.31%] [G loss: 0.646363]\n",
      "epoch:16 step:15262 [D loss: 0.539431, acc.: 72.66%] [G loss: 0.525281]\n",
      "epoch:16 step:15263 [D loss: 0.487469, acc.: 74.22%] [G loss: 0.732211]\n",
      "epoch:16 step:15264 [D loss: 0.588259, acc.: 64.84%] [G loss: 0.643193]\n",
      "epoch:16 step:15265 [D loss: 0.519669, acc.: 73.44%] [G loss: 0.669568]\n",
      "epoch:16 step:15266 [D loss: 0.554267, acc.: 71.09%] [G loss: 0.634190]\n",
      "epoch:16 step:15267 [D loss: 0.605867, acc.: 67.97%] [G loss: 0.533447]\n",
      "epoch:16 step:15268 [D loss: 0.478230, acc.: 78.91%] [G loss: 0.603131]\n",
      "epoch:16 step:15269 [D loss: 0.659434, acc.: 64.06%] [G loss: 0.480349]\n",
      "epoch:16 step:15270 [D loss: 0.603552, acc.: 68.75%] [G loss: 0.476732]\n",
      "epoch:16 step:15271 [D loss: 0.536501, acc.: 68.75%] [G loss: 0.463453]\n",
      "epoch:16 step:15272 [D loss: 0.533833, acc.: 70.31%] [G loss: 0.435970]\n",
      "epoch:16 step:15273 [D loss: 0.568326, acc.: 71.88%] [G loss: 0.554243]\n",
      "epoch:16 step:15274 [D loss: 0.599515, acc.: 67.19%] [G loss: 0.580023]\n",
      "epoch:16 step:15275 [D loss: 0.500608, acc.: 78.91%] [G loss: 0.570937]\n",
      "epoch:16 step:15276 [D loss: 0.507485, acc.: 72.66%] [G loss: 0.521197]\n",
      "epoch:16 step:15277 [D loss: 0.521502, acc.: 69.53%] [G loss: 0.769869]\n",
      "epoch:16 step:15278 [D loss: 0.523580, acc.: 75.00%] [G loss: 0.689952]\n",
      "epoch:16 step:15279 [D loss: 0.590408, acc.: 67.19%] [G loss: 0.681016]\n",
      "epoch:16 step:15280 [D loss: 0.574365, acc.: 70.31%] [G loss: 0.711283]\n",
      "epoch:16 step:15281 [D loss: 0.567206, acc.: 67.19%] [G loss: 0.640508]\n",
      "epoch:16 step:15282 [D loss: 0.597960, acc.: 67.97%] [G loss: 0.587725]\n",
      "epoch:16 step:15283 [D loss: 0.551775, acc.: 71.88%] [G loss: 0.498148]\n",
      "epoch:16 step:15284 [D loss: 0.539100, acc.: 71.09%] [G loss: 0.668571]\n",
      "epoch:16 step:15285 [D loss: 0.624468, acc.: 66.41%] [G loss: 0.680743]\n",
      "epoch:16 step:15286 [D loss: 0.616562, acc.: 62.50%] [G loss: 0.426998]\n",
      "epoch:16 step:15287 [D loss: 0.587104, acc.: 67.19%] [G loss: 0.519757]\n",
      "epoch:16 step:15288 [D loss: 0.466590, acc.: 75.00%] [G loss: 0.540630]\n",
      "epoch:16 step:15289 [D loss: 0.549798, acc.: 64.06%] [G loss: 0.639216]\n",
      "epoch:16 step:15290 [D loss: 0.482111, acc.: 72.66%] [G loss: 0.589959]\n",
      "epoch:16 step:15291 [D loss: 0.511254, acc.: 73.44%] [G loss: 0.711373]\n",
      "epoch:16 step:15292 [D loss: 0.538821, acc.: 70.31%] [G loss: 0.625450]\n",
      "epoch:16 step:15293 [D loss: 0.598561, acc.: 64.06%] [G loss: 0.697929]\n",
      "epoch:16 step:15294 [D loss: 0.530251, acc.: 72.66%] [G loss: 0.643752]\n",
      "epoch:16 step:15295 [D loss: 0.526698, acc.: 74.22%] [G loss: 0.522823]\n",
      "epoch:16 step:15296 [D loss: 0.493891, acc.: 77.34%] [G loss: 0.579659]\n",
      "epoch:16 step:15297 [D loss: 0.531122, acc.: 72.66%] [G loss: 0.690281]\n",
      "epoch:16 step:15298 [D loss: 0.514323, acc.: 73.44%] [G loss: 0.748915]\n",
      "epoch:16 step:15299 [D loss: 0.499069, acc.: 72.66%] [G loss: 0.699948]\n",
      "epoch:16 step:15300 [D loss: 0.587728, acc.: 64.06%] [G loss: 0.676152]\n",
      "epoch:16 step:15301 [D loss: 0.532392, acc.: 69.53%] [G loss: 0.677956]\n",
      "epoch:16 step:15302 [D loss: 0.556475, acc.: 72.66%] [G loss: 0.665950]\n",
      "epoch:16 step:15303 [D loss: 0.444658, acc.: 80.47%] [G loss: 0.556515]\n",
      "epoch:16 step:15304 [D loss: 0.524669, acc.: 74.22%] [G loss: 0.741141]\n",
      "epoch:16 step:15305 [D loss: 0.524321, acc.: 76.56%] [G loss: 0.962857]\n",
      "epoch:16 step:15306 [D loss: 0.443768, acc.: 79.69%] [G loss: 1.006699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15307 [D loss: 0.451114, acc.: 79.69%] [G loss: 0.988844]\n",
      "epoch:16 step:15308 [D loss: 0.721272, acc.: 62.50%] [G loss: 0.576733]\n",
      "epoch:16 step:15309 [D loss: 0.604915, acc.: 65.62%] [G loss: 0.558217]\n",
      "epoch:16 step:15310 [D loss: 0.622594, acc.: 65.62%] [G loss: 0.510743]\n",
      "epoch:16 step:15311 [D loss: 0.533851, acc.: 68.75%] [G loss: 0.776233]\n",
      "epoch:16 step:15312 [D loss: 0.539698, acc.: 67.19%] [G loss: 0.621609]\n",
      "epoch:16 step:15313 [D loss: 0.540100, acc.: 70.31%] [G loss: 0.744603]\n",
      "epoch:16 step:15314 [D loss: 0.615951, acc.: 65.62%] [G loss: 0.695367]\n",
      "epoch:16 step:15315 [D loss: 0.560495, acc.: 69.53%] [G loss: 0.445032]\n",
      "epoch:16 step:15316 [D loss: 0.581274, acc.: 67.97%] [G loss: 0.510631]\n",
      "epoch:16 step:15317 [D loss: 0.559142, acc.: 68.75%] [G loss: 0.541768]\n",
      "epoch:16 step:15318 [D loss: 0.531577, acc.: 71.88%] [G loss: 0.699484]\n",
      "epoch:16 step:15319 [D loss: 0.540855, acc.: 73.44%] [G loss: 0.544352]\n",
      "epoch:16 step:15320 [D loss: 0.447621, acc.: 82.03%] [G loss: 0.797830]\n",
      "epoch:16 step:15321 [D loss: 0.502941, acc.: 77.34%] [G loss: 0.767081]\n",
      "epoch:16 step:15322 [D loss: 0.579574, acc.: 67.97%] [G loss: 0.625240]\n",
      "epoch:16 step:15323 [D loss: 0.550600, acc.: 71.09%] [G loss: 0.538699]\n",
      "epoch:16 step:15324 [D loss: 0.496922, acc.: 73.44%] [G loss: 0.510859]\n",
      "epoch:16 step:15325 [D loss: 0.475539, acc.: 74.22%] [G loss: 0.645786]\n",
      "epoch:16 step:15326 [D loss: 0.512481, acc.: 68.75%] [G loss: 0.688512]\n",
      "epoch:16 step:15327 [D loss: 0.505645, acc.: 73.44%] [G loss: 0.672298]\n",
      "epoch:16 step:15328 [D loss: 0.505121, acc.: 76.56%] [G loss: 0.668096]\n",
      "epoch:16 step:15329 [D loss: 0.528513, acc.: 68.75%] [G loss: 0.781575]\n",
      "epoch:16 step:15330 [D loss: 0.545819, acc.: 69.53%] [G loss: 0.762491]\n",
      "epoch:16 step:15331 [D loss: 0.531186, acc.: 69.53%] [G loss: 0.642009]\n",
      "epoch:16 step:15332 [D loss: 0.481301, acc.: 74.22%] [G loss: 0.632307]\n",
      "epoch:16 step:15333 [D loss: 0.589320, acc.: 67.97%] [G loss: 0.669100]\n",
      "epoch:16 step:15334 [D loss: 0.652655, acc.: 60.94%] [G loss: 0.717729]\n",
      "epoch:16 step:15335 [D loss: 0.512056, acc.: 71.88%] [G loss: 0.853468]\n",
      "epoch:16 step:15336 [D loss: 0.493961, acc.: 76.56%] [G loss: 0.845954]\n",
      "epoch:16 step:15337 [D loss: 0.671282, acc.: 56.25%] [G loss: 0.705134]\n",
      "epoch:16 step:15338 [D loss: 0.558107, acc.: 67.97%] [G loss: 0.617956]\n",
      "epoch:16 step:15339 [D loss: 0.450982, acc.: 78.12%] [G loss: 0.981494]\n",
      "epoch:16 step:15340 [D loss: 0.716039, acc.: 60.94%] [G loss: 0.592505]\n",
      "epoch:16 step:15341 [D loss: 0.719885, acc.: 57.81%] [G loss: 0.511043]\n",
      "epoch:16 step:15342 [D loss: 0.463000, acc.: 85.16%] [G loss: 0.565532]\n",
      "epoch:16 step:15343 [D loss: 0.569379, acc.: 66.41%] [G loss: 0.660104]\n",
      "epoch:16 step:15344 [D loss: 0.575305, acc.: 66.41%] [G loss: 0.648227]\n",
      "epoch:16 step:15345 [D loss: 0.544477, acc.: 74.22%] [G loss: 0.612838]\n",
      "epoch:16 step:15346 [D loss: 0.375342, acc.: 81.25%] [G loss: 0.941903]\n",
      "epoch:16 step:15347 [D loss: 0.591753, acc.: 72.66%] [G loss: 0.644209]\n",
      "epoch:16 step:15348 [D loss: 0.571466, acc.: 71.09%] [G loss: 0.704827]\n",
      "epoch:16 step:15349 [D loss: 0.439279, acc.: 75.78%] [G loss: 0.742236]\n",
      "epoch:16 step:15350 [D loss: 0.436997, acc.: 80.47%] [G loss: 0.735516]\n",
      "epoch:16 step:15351 [D loss: 0.455889, acc.: 80.47%] [G loss: 0.836536]\n",
      "epoch:16 step:15352 [D loss: 0.453999, acc.: 77.34%] [G loss: 0.864240]\n",
      "epoch:16 step:15353 [D loss: 0.511395, acc.: 71.88%] [G loss: 0.691025]\n",
      "epoch:16 step:15354 [D loss: 0.528191, acc.: 69.53%] [G loss: 0.708271]\n",
      "epoch:16 step:15355 [D loss: 0.540780, acc.: 70.31%] [G loss: 0.648163]\n",
      "epoch:16 step:15356 [D loss: 0.554306, acc.: 70.31%] [G loss: 0.786080]\n",
      "epoch:16 step:15357 [D loss: 0.558305, acc.: 71.88%] [G loss: 0.661536]\n",
      "epoch:16 step:15358 [D loss: 0.538169, acc.: 71.88%] [G loss: 0.636350]\n",
      "epoch:16 step:15359 [D loss: 0.594309, acc.: 66.41%] [G loss: 0.712256]\n",
      "epoch:16 step:15360 [D loss: 0.513135, acc.: 73.44%] [G loss: 0.630245]\n",
      "epoch:16 step:15361 [D loss: 0.561407, acc.: 68.75%] [G loss: 0.571088]\n",
      "epoch:16 step:15362 [D loss: 0.574227, acc.: 67.97%] [G loss: 0.631133]\n",
      "epoch:16 step:15363 [D loss: 0.514248, acc.: 74.22%] [G loss: 0.784705]\n",
      "epoch:16 step:15364 [D loss: 0.563386, acc.: 71.88%] [G loss: 0.606034]\n",
      "epoch:16 step:15365 [D loss: 0.522436, acc.: 74.22%] [G loss: 0.506854]\n",
      "epoch:16 step:15366 [D loss: 0.506514, acc.: 72.66%] [G loss: 0.711562]\n",
      "epoch:16 step:15367 [D loss: 0.575212, acc.: 67.97%] [G loss: 0.611436]\n",
      "epoch:16 step:15368 [D loss: 0.658606, acc.: 65.62%] [G loss: 0.453445]\n",
      "epoch:16 step:15369 [D loss: 0.584485, acc.: 68.75%] [G loss: 0.507306]\n",
      "epoch:16 step:15370 [D loss: 0.575225, acc.: 73.44%] [G loss: 0.465105]\n",
      "epoch:16 step:15371 [D loss: 0.562418, acc.: 68.75%] [G loss: 0.643367]\n",
      "epoch:16 step:15372 [D loss: 0.532240, acc.: 72.66%] [G loss: 0.579047]\n",
      "epoch:16 step:15373 [D loss: 0.467045, acc.: 77.34%] [G loss: 0.640790]\n",
      "epoch:16 step:15374 [D loss: 0.509534, acc.: 71.09%] [G loss: 0.631707]\n",
      "epoch:16 step:15375 [D loss: 0.541890, acc.: 69.53%] [G loss: 0.579538]\n",
      "epoch:16 step:15376 [D loss: 0.554990, acc.: 72.66%] [G loss: 0.500638]\n",
      "epoch:16 step:15377 [D loss: 0.532847, acc.: 77.34%] [G loss: 0.760119]\n",
      "epoch:16 step:15378 [D loss: 0.619313, acc.: 62.50%] [G loss: 0.475154]\n",
      "epoch:16 step:15379 [D loss: 0.614510, acc.: 66.41%] [G loss: 0.563822]\n",
      "epoch:16 step:15380 [D loss: 0.570217, acc.: 67.19%] [G loss: 0.742637]\n",
      "epoch:16 step:15381 [D loss: 0.534756, acc.: 71.88%] [G loss: 0.546015]\n",
      "epoch:16 step:15382 [D loss: 0.563637, acc.: 74.22%] [G loss: 0.602780]\n",
      "epoch:16 step:15383 [D loss: 0.521694, acc.: 71.88%] [G loss: 0.497154]\n",
      "epoch:16 step:15384 [D loss: 0.443324, acc.: 78.91%] [G loss: 0.680101]\n",
      "epoch:16 step:15385 [D loss: 0.596381, acc.: 64.84%] [G loss: 0.536893]\n",
      "epoch:16 step:15386 [D loss: 0.529364, acc.: 70.31%] [G loss: 0.569986]\n",
      "epoch:16 step:15387 [D loss: 0.565639, acc.: 65.62%] [G loss: 0.523136]\n",
      "epoch:16 step:15388 [D loss: 0.542923, acc.: 67.19%] [G loss: 0.658802]\n",
      "epoch:16 step:15389 [D loss: 0.568943, acc.: 69.53%] [G loss: 0.722280]\n",
      "epoch:16 step:15390 [D loss: 0.505326, acc.: 76.56%] [G loss: 0.732823]\n",
      "epoch:16 step:15391 [D loss: 0.473282, acc.: 80.47%] [G loss: 0.829712]\n",
      "epoch:16 step:15392 [D loss: 0.675073, acc.: 60.94%] [G loss: 0.588288]\n",
      "epoch:16 step:15393 [D loss: 0.688517, acc.: 60.16%] [G loss: 0.373090]\n",
      "epoch:16 step:15394 [D loss: 0.521416, acc.: 71.88%] [G loss: 0.615894]\n",
      "epoch:16 step:15395 [D loss: 0.528021, acc.: 71.88%] [G loss: 0.541268]\n",
      "epoch:16 step:15396 [D loss: 0.627554, acc.: 62.50%] [G loss: 0.614854]\n",
      "epoch:16 step:15397 [D loss: 0.549699, acc.: 68.75%] [G loss: 0.608388]\n",
      "epoch:16 step:15398 [D loss: 0.466581, acc.: 80.47%] [G loss: 0.688955]\n",
      "epoch:16 step:15399 [D loss: 0.564072, acc.: 69.53%] [G loss: 0.648095]\n",
      "epoch:16 step:15400 [D loss: 0.540355, acc.: 74.22%] [G loss: 0.703502]\n",
      "##############\n",
      "[2.93106219 0.85957021 6.41017171 4.66936297 3.98279129 5.60544311\n",
      " 4.46055989 4.87876229 4.44055244 4.07053485]\n",
      "##########\n",
      "epoch:16 step:15401 [D loss: 0.598778, acc.: 59.38%] [G loss: 0.598688]\n",
      "epoch:16 step:15402 [D loss: 0.559980, acc.: 71.09%] [G loss: 0.709374]\n",
      "epoch:16 step:15403 [D loss: 0.594376, acc.: 65.62%] [G loss: 0.637793]\n",
      "epoch:16 step:15404 [D loss: 0.610268, acc.: 64.06%] [G loss: 0.545946]\n",
      "epoch:16 step:15405 [D loss: 0.567561, acc.: 71.09%] [G loss: 0.604024]\n",
      "epoch:16 step:15406 [D loss: 0.508236, acc.: 69.53%] [G loss: 0.606206]\n",
      "epoch:16 step:15407 [D loss: 0.553471, acc.: 70.31%] [G loss: 0.686836]\n",
      "epoch:16 step:15408 [D loss: 0.502463, acc.: 78.91%] [G loss: 0.628655]\n",
      "epoch:16 step:15409 [D loss: 0.559658, acc.: 68.75%] [G loss: 0.597178]\n",
      "epoch:16 step:15410 [D loss: 0.585712, acc.: 70.31%] [G loss: 0.766599]\n",
      "epoch:16 step:15411 [D loss: 0.567656, acc.: 65.62%] [G loss: 0.499397]\n",
      "epoch:16 step:15412 [D loss: 0.598921, acc.: 61.72%] [G loss: 0.522249]\n",
      "epoch:16 step:15413 [D loss: 0.616046, acc.: 67.97%] [G loss: 0.422039]\n",
      "epoch:16 step:15414 [D loss: 0.628617, acc.: 64.06%] [G loss: 0.523906]\n",
      "epoch:16 step:15415 [D loss: 0.560241, acc.: 65.62%] [G loss: 0.597980]\n",
      "epoch:16 step:15416 [D loss: 0.544694, acc.: 69.53%] [G loss: 0.599578]\n",
      "epoch:16 step:15417 [D loss: 0.502541, acc.: 78.91%] [G loss: 0.538684]\n",
      "epoch:16 step:15418 [D loss: 0.489785, acc.: 71.88%] [G loss: 0.652546]\n",
      "epoch:16 step:15419 [D loss: 0.540861, acc.: 66.41%] [G loss: 0.833661]\n",
      "epoch:16 step:15420 [D loss: 0.518007, acc.: 71.88%] [G loss: 0.842699]\n",
      "epoch:16 step:15421 [D loss: 0.487219, acc.: 78.12%] [G loss: 0.734171]\n",
      "epoch:16 step:15422 [D loss: 0.488081, acc.: 74.22%] [G loss: 0.819632]\n",
      "epoch:16 step:15423 [D loss: 0.564166, acc.: 71.88%] [G loss: 0.810881]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15424 [D loss: 0.506574, acc.: 75.78%] [G loss: 0.613771]\n",
      "epoch:16 step:15425 [D loss: 0.580193, acc.: 69.53%] [G loss: 0.773577]\n",
      "epoch:16 step:15426 [D loss: 0.530552, acc.: 72.66%] [G loss: 0.561570]\n",
      "epoch:16 step:15427 [D loss: 0.518601, acc.: 75.78%] [G loss: 0.651475]\n",
      "epoch:16 step:15428 [D loss: 0.485916, acc.: 72.66%] [G loss: 0.695039]\n",
      "epoch:16 step:15429 [D loss: 0.679371, acc.: 62.50%] [G loss: 0.642575]\n",
      "epoch:16 step:15430 [D loss: 0.592237, acc.: 64.84%] [G loss: 0.615932]\n",
      "epoch:16 step:15431 [D loss: 0.541655, acc.: 77.34%] [G loss: 0.795848]\n",
      "epoch:16 step:15432 [D loss: 0.539325, acc.: 71.09%] [G loss: 0.733246]\n",
      "epoch:16 step:15433 [D loss: 0.534432, acc.: 66.41%] [G loss: 0.787319]\n",
      "epoch:16 step:15434 [D loss: 0.579991, acc.: 68.75%] [G loss: 0.647987]\n",
      "epoch:16 step:15435 [D loss: 0.565575, acc.: 68.75%] [G loss: 0.686304]\n",
      "epoch:16 step:15436 [D loss: 0.538220, acc.: 74.22%] [G loss: 0.705994]\n",
      "epoch:16 step:15437 [D loss: 0.609521, acc.: 60.16%] [G loss: 0.523358]\n",
      "epoch:16 step:15438 [D loss: 0.519662, acc.: 75.00%] [G loss: 0.680843]\n",
      "epoch:16 step:15439 [D loss: 0.540022, acc.: 69.53%] [G loss: 0.669521]\n",
      "epoch:16 step:15440 [D loss: 0.486256, acc.: 79.69%] [G loss: 0.634857]\n",
      "epoch:16 step:15441 [D loss: 0.519459, acc.: 73.44%] [G loss: 0.685564]\n",
      "epoch:16 step:15442 [D loss: 0.501686, acc.: 75.78%] [G loss: 0.767656]\n",
      "epoch:16 step:15443 [D loss: 0.401411, acc.: 81.25%] [G loss: 0.702079]\n",
      "epoch:16 step:15444 [D loss: 0.515803, acc.: 70.31%] [G loss: 0.676387]\n",
      "epoch:16 step:15445 [D loss: 0.545560, acc.: 67.19%] [G loss: 0.615726]\n",
      "epoch:16 step:15446 [D loss: 0.563466, acc.: 70.31%] [G loss: 0.695022]\n",
      "epoch:16 step:15447 [D loss: 0.568711, acc.: 70.31%] [G loss: 0.523987]\n",
      "epoch:16 step:15448 [D loss: 0.601309, acc.: 65.62%] [G loss: 0.701589]\n",
      "epoch:16 step:15449 [D loss: 0.542452, acc.: 72.66%] [G loss: 0.734424]\n",
      "epoch:16 step:15450 [D loss: 0.623008, acc.: 64.84%] [G loss: 0.550193]\n",
      "epoch:16 step:15451 [D loss: 0.530947, acc.: 71.88%] [G loss: 0.753440]\n",
      "epoch:16 step:15452 [D loss: 0.488622, acc.: 76.56%] [G loss: 0.568304]\n",
      "epoch:16 step:15453 [D loss: 0.552050, acc.: 73.44%] [G loss: 0.702144]\n",
      "epoch:16 step:15454 [D loss: 0.564515, acc.: 69.53%] [G loss: 0.613793]\n",
      "epoch:16 step:15455 [D loss: 0.574683, acc.: 64.84%] [G loss: 0.491656]\n",
      "epoch:16 step:15456 [D loss: 0.563627, acc.: 67.19%] [G loss: 0.526793]\n",
      "epoch:16 step:15457 [D loss: 0.601797, acc.: 65.62%] [G loss: 0.533558]\n",
      "epoch:16 step:15458 [D loss: 0.516172, acc.: 68.75%] [G loss: 0.589116]\n",
      "epoch:16 step:15459 [D loss: 0.582126, acc.: 69.53%] [G loss: 0.464369]\n",
      "epoch:16 step:15460 [D loss: 0.537220, acc.: 71.88%] [G loss: 0.624527]\n",
      "epoch:16 step:15461 [D loss: 0.529373, acc.: 71.09%] [G loss: 0.757324]\n",
      "epoch:16 step:15462 [D loss: 0.567415, acc.: 70.31%] [G loss: 0.756785]\n",
      "epoch:16 step:15463 [D loss: 0.445901, acc.: 82.03%] [G loss: 0.811213]\n",
      "epoch:16 step:15464 [D loss: 0.460462, acc.: 80.47%] [G loss: 0.961457]\n",
      "epoch:16 step:15465 [D loss: 0.675684, acc.: 59.38%] [G loss: 0.694054]\n",
      "epoch:16 step:15466 [D loss: 0.529579, acc.: 72.66%] [G loss: 0.624513]\n",
      "epoch:16 step:15467 [D loss: 0.453893, acc.: 78.91%] [G loss: 0.765952]\n",
      "epoch:16 step:15468 [D loss: 0.543631, acc.: 75.78%] [G loss: 0.678103]\n",
      "epoch:16 step:15469 [D loss: 0.619183, acc.: 67.97%] [G loss: 0.520004]\n",
      "epoch:16 step:15470 [D loss: 0.532430, acc.: 70.31%] [G loss: 0.670480]\n",
      "epoch:16 step:15471 [D loss: 0.530840, acc.: 71.88%] [G loss: 0.536802]\n",
      "epoch:16 step:15472 [D loss: 0.570953, acc.: 73.44%] [G loss: 0.568839]\n",
      "epoch:16 step:15473 [D loss: 0.486182, acc.: 81.25%] [G loss: 0.582102]\n",
      "epoch:16 step:15474 [D loss: 0.598429, acc.: 65.62%] [G loss: 0.501824]\n",
      "epoch:16 step:15475 [D loss: 0.563610, acc.: 67.97%] [G loss: 0.536491]\n",
      "epoch:16 step:15476 [D loss: 0.502126, acc.: 74.22%] [G loss: 0.689514]\n",
      "epoch:16 step:15477 [D loss: 0.565911, acc.: 62.50%] [G loss: 0.640296]\n",
      "epoch:16 step:15478 [D loss: 0.533113, acc.: 74.22%] [G loss: 0.703077]\n",
      "epoch:16 step:15479 [D loss: 0.551005, acc.: 62.50%] [G loss: 0.908339]\n",
      "epoch:16 step:15480 [D loss: 0.534750, acc.: 71.88%] [G loss: 0.582976]\n",
      "epoch:16 step:15481 [D loss: 0.544580, acc.: 73.44%] [G loss: 0.555235]\n",
      "epoch:16 step:15482 [D loss: 0.578881, acc.: 68.75%] [G loss: 0.586573]\n",
      "epoch:16 step:15483 [D loss: 0.528913, acc.: 71.88%] [G loss: 0.644136]\n",
      "epoch:16 step:15484 [D loss: 0.612235, acc.: 68.75%] [G loss: 0.654075]\n",
      "epoch:16 step:15485 [D loss: 0.568580, acc.: 69.53%] [G loss: 0.712930]\n",
      "epoch:16 step:15486 [D loss: 0.573955, acc.: 71.88%] [G loss: 0.595917]\n",
      "epoch:16 step:15487 [D loss: 0.523418, acc.: 75.78%] [G loss: 0.729267]\n",
      "epoch:16 step:15488 [D loss: 0.597597, acc.: 68.75%] [G loss: 0.604131]\n",
      "epoch:16 step:15489 [D loss: 0.533957, acc.: 73.44%] [G loss: 0.662656]\n",
      "epoch:16 step:15490 [D loss: 0.587240, acc.: 60.94%] [G loss: 0.586896]\n",
      "epoch:16 step:15491 [D loss: 0.475883, acc.: 77.34%] [G loss: 0.718709]\n",
      "epoch:16 step:15492 [D loss: 0.577904, acc.: 66.41%] [G loss: 0.758051]\n",
      "epoch:16 step:15493 [D loss: 0.606031, acc.: 68.75%] [G loss: 0.532965]\n",
      "epoch:16 step:15494 [D loss: 0.585532, acc.: 66.41%] [G loss: 0.530281]\n",
      "epoch:16 step:15495 [D loss: 0.520616, acc.: 71.88%] [G loss: 0.561263]\n",
      "epoch:16 step:15496 [D loss: 0.467962, acc.: 78.91%] [G loss: 0.792760]\n",
      "epoch:16 step:15497 [D loss: 0.540246, acc.: 74.22%] [G loss: 0.890545]\n",
      "epoch:16 step:15498 [D loss: 0.466150, acc.: 75.78%] [G loss: 1.000287]\n",
      "epoch:16 step:15499 [D loss: 0.556183, acc.: 71.09%] [G loss: 0.875184]\n",
      "epoch:16 step:15500 [D loss: 0.426937, acc.: 81.25%] [G loss: 1.112871]\n",
      "epoch:16 step:15501 [D loss: 0.516077, acc.: 70.31%] [G loss: 0.868561]\n",
      "epoch:16 step:15502 [D loss: 0.620458, acc.: 67.97%] [G loss: 0.662040]\n",
      "epoch:16 step:15503 [D loss: 0.608647, acc.: 64.06%] [G loss: 0.482659]\n",
      "epoch:16 step:15504 [D loss: 0.601662, acc.: 63.28%] [G loss: 0.403850]\n",
      "epoch:16 step:15505 [D loss: 0.534929, acc.: 71.88%] [G loss: 0.483735]\n",
      "epoch:16 step:15506 [D loss: 0.525190, acc.: 73.44%] [G loss: 0.684004]\n",
      "epoch:16 step:15507 [D loss: 0.533060, acc.: 68.75%] [G loss: 0.636048]\n",
      "epoch:16 step:15508 [D loss: 0.493137, acc.: 74.22%] [G loss: 0.845562]\n",
      "epoch:16 step:15509 [D loss: 0.506181, acc.: 74.22%] [G loss: 0.807133]\n",
      "epoch:16 step:15510 [D loss: 0.545676, acc.: 67.19%] [G loss: 0.722363]\n",
      "epoch:16 step:15511 [D loss: 0.504251, acc.: 73.44%] [G loss: 0.712470]\n",
      "epoch:16 step:15512 [D loss: 0.507806, acc.: 69.53%] [G loss: 0.676130]\n",
      "epoch:16 step:15513 [D loss: 0.540329, acc.: 67.19%] [G loss: 0.617708]\n",
      "epoch:16 step:15514 [D loss: 0.519506, acc.: 75.78%] [G loss: 0.602666]\n",
      "epoch:16 step:15515 [D loss: 0.463275, acc.: 77.34%] [G loss: 0.729986]\n",
      "epoch:16 step:15516 [D loss: 0.527571, acc.: 72.66%] [G loss: 0.574192]\n",
      "epoch:16 step:15517 [D loss: 0.633345, acc.: 63.28%] [G loss: 0.684535]\n",
      "epoch:16 step:15518 [D loss: 0.547534, acc.: 71.09%] [G loss: 0.631657]\n",
      "epoch:16 step:15519 [D loss: 0.536733, acc.: 71.09%] [G loss: 0.619463]\n",
      "epoch:16 step:15520 [D loss: 0.728994, acc.: 53.12%] [G loss: 0.471278]\n",
      "epoch:16 step:15521 [D loss: 0.596831, acc.: 63.28%] [G loss: 0.652425]\n",
      "epoch:16 step:15522 [D loss: 0.530894, acc.: 75.00%] [G loss: 0.734919]\n",
      "epoch:16 step:15523 [D loss: 0.551347, acc.: 72.66%] [G loss: 0.715800]\n",
      "epoch:16 step:15524 [D loss: 0.551780, acc.: 68.75%] [G loss: 0.586487]\n",
      "epoch:16 step:15525 [D loss: 0.513777, acc.: 71.88%] [G loss: 0.575361]\n",
      "epoch:16 step:15526 [D loss: 0.507815, acc.: 74.22%] [G loss: 0.566357]\n",
      "epoch:16 step:15527 [D loss: 0.650455, acc.: 57.03%] [G loss: 0.550498]\n",
      "epoch:16 step:15528 [D loss: 0.480403, acc.: 74.22%] [G loss: 0.669204]\n",
      "epoch:16 step:15529 [D loss: 0.608331, acc.: 63.28%] [G loss: 0.516625]\n",
      "epoch:16 step:15530 [D loss: 0.553856, acc.: 71.88%] [G loss: 0.606514]\n",
      "epoch:16 step:15531 [D loss: 0.556215, acc.: 67.97%] [G loss: 0.527329]\n",
      "epoch:16 step:15532 [D loss: 0.573625, acc.: 65.62%] [G loss: 0.717849]\n",
      "epoch:16 step:15533 [D loss: 0.520952, acc.: 69.53%] [G loss: 0.770598]\n",
      "epoch:16 step:15534 [D loss: 0.706233, acc.: 59.38%] [G loss: 0.555040]\n",
      "epoch:16 step:15535 [D loss: 0.579132, acc.: 63.28%] [G loss: 0.601779]\n",
      "epoch:16 step:15536 [D loss: 0.553919, acc.: 66.41%] [G loss: 0.680976]\n",
      "epoch:16 step:15537 [D loss: 0.529662, acc.: 71.88%] [G loss: 0.721517]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15538 [D loss: 0.529146, acc.: 72.66%] [G loss: 0.729285]\n",
      "epoch:16 step:15539 [D loss: 0.554173, acc.: 67.97%] [G loss: 0.688967]\n",
      "epoch:16 step:15540 [D loss: 0.492953, acc.: 73.44%] [G loss: 0.741342]\n",
      "epoch:16 step:15541 [D loss: 0.568912, acc.: 71.88%] [G loss: 0.800303]\n",
      "epoch:16 step:15542 [D loss: 0.535951, acc.: 71.88%] [G loss: 0.639541]\n",
      "epoch:16 step:15543 [D loss: 0.556610, acc.: 67.19%] [G loss: 0.505435]\n",
      "epoch:16 step:15544 [D loss: 0.505918, acc.: 75.78%] [G loss: 0.589272]\n",
      "epoch:16 step:15545 [D loss: 0.572345, acc.: 69.53%] [G loss: 0.573152]\n",
      "epoch:16 step:15546 [D loss: 0.470998, acc.: 78.12%] [G loss: 0.614354]\n",
      "epoch:16 step:15547 [D loss: 0.459812, acc.: 79.69%] [G loss: 0.707507]\n",
      "epoch:16 step:15548 [D loss: 0.595410, acc.: 66.41%] [G loss: 0.562837]\n",
      "epoch:16 step:15549 [D loss: 0.499536, acc.: 73.44%] [G loss: 0.716037]\n",
      "epoch:16 step:15550 [D loss: 0.505592, acc.: 75.00%] [G loss: 0.745153]\n",
      "epoch:16 step:15551 [D loss: 0.585026, acc.: 64.84%] [G loss: 0.624926]\n",
      "epoch:16 step:15552 [D loss: 0.582165, acc.: 69.53%] [G loss: 0.455884]\n",
      "epoch:16 step:15553 [D loss: 0.566327, acc.: 71.88%] [G loss: 0.621712]\n",
      "epoch:16 step:15554 [D loss: 0.599947, acc.: 65.62%] [G loss: 0.797698]\n",
      "epoch:16 step:15555 [D loss: 0.551140, acc.: 66.41%] [G loss: 0.665021]\n",
      "epoch:16 step:15556 [D loss: 0.501030, acc.: 75.00%] [G loss: 0.827860]\n",
      "epoch:16 step:15557 [D loss: 0.544923, acc.: 74.22%] [G loss: 0.699541]\n",
      "epoch:16 step:15558 [D loss: 0.704530, acc.: 62.50%] [G loss: 0.522263]\n",
      "epoch:16 step:15559 [D loss: 0.506140, acc.: 74.22%] [G loss: 0.655968]\n",
      "epoch:16 step:15560 [D loss: 0.536254, acc.: 71.88%] [G loss: 0.754500]\n",
      "epoch:16 step:15561 [D loss: 0.518648, acc.: 73.44%] [G loss: 0.646806]\n",
      "epoch:16 step:15562 [D loss: 0.527487, acc.: 74.22%] [G loss: 0.745301]\n",
      "epoch:16 step:15563 [D loss: 0.501248, acc.: 72.66%] [G loss: 0.631779]\n",
      "epoch:16 step:15564 [D loss: 0.573409, acc.: 68.75%] [G loss: 0.705384]\n",
      "epoch:16 step:15565 [D loss: 0.529123, acc.: 72.66%] [G loss: 0.682950]\n",
      "epoch:16 step:15566 [D loss: 0.520924, acc.: 79.69%] [G loss: 0.811460]\n",
      "epoch:16 step:15567 [D loss: 0.464188, acc.: 81.25%] [G loss: 0.779333]\n",
      "epoch:16 step:15568 [D loss: 0.549567, acc.: 74.22%] [G loss: 0.750002]\n",
      "epoch:16 step:15569 [D loss: 0.513341, acc.: 75.00%] [G loss: 0.657498]\n",
      "epoch:16 step:15570 [D loss: 0.574429, acc.: 66.41%] [G loss: 0.521546]\n",
      "epoch:16 step:15571 [D loss: 0.523794, acc.: 69.53%] [G loss: 0.549538]\n",
      "epoch:16 step:15572 [D loss: 0.538614, acc.: 72.66%] [G loss: 0.594932]\n",
      "epoch:16 step:15573 [D loss: 0.527949, acc.: 69.53%] [G loss: 0.645700]\n",
      "epoch:16 step:15574 [D loss: 0.495320, acc.: 80.47%] [G loss: 0.744810]\n",
      "epoch:16 step:15575 [D loss: 0.584587, acc.: 71.09%] [G loss: 0.660714]\n",
      "epoch:16 step:15576 [D loss: 0.641428, acc.: 64.84%] [G loss: 0.722502]\n",
      "epoch:16 step:15577 [D loss: 0.509800, acc.: 77.34%] [G loss: 0.538455]\n",
      "epoch:16 step:15578 [D loss: 0.573308, acc.: 67.97%] [G loss: 0.515855]\n",
      "epoch:16 step:15579 [D loss: 0.577672, acc.: 64.06%] [G loss: 0.603263]\n",
      "epoch:16 step:15580 [D loss: 0.563405, acc.: 70.31%] [G loss: 0.520968]\n",
      "epoch:16 step:15581 [D loss: 0.516899, acc.: 69.53%] [G loss: 0.623099]\n",
      "epoch:16 step:15582 [D loss: 0.578836, acc.: 67.19%] [G loss: 0.524132]\n",
      "epoch:16 step:15583 [D loss: 0.547043, acc.: 72.66%] [G loss: 0.557006]\n",
      "epoch:16 step:15584 [D loss: 0.466193, acc.: 78.91%] [G loss: 0.602458]\n",
      "epoch:16 step:15585 [D loss: 0.545405, acc.: 69.53%] [G loss: 0.560440]\n",
      "epoch:16 step:15586 [D loss: 0.538635, acc.: 71.09%] [G loss: 0.512681]\n",
      "epoch:16 step:15587 [D loss: 0.533508, acc.: 70.31%] [G loss: 0.605276]\n",
      "epoch:16 step:15588 [D loss: 0.565804, acc.: 69.53%] [G loss: 0.560536]\n",
      "epoch:16 step:15589 [D loss: 0.522891, acc.: 74.22%] [G loss: 0.518585]\n",
      "epoch:16 step:15590 [D loss: 0.499696, acc.: 80.47%] [G loss: 0.640646]\n",
      "epoch:16 step:15591 [D loss: 0.549377, acc.: 69.53%] [G loss: 0.701658]\n",
      "epoch:16 step:15592 [D loss: 0.550794, acc.: 74.22%] [G loss: 0.570221]\n",
      "epoch:16 step:15593 [D loss: 0.493969, acc.: 70.31%] [G loss: 0.680722]\n",
      "epoch:16 step:15594 [D loss: 0.540764, acc.: 73.44%] [G loss: 0.571189]\n",
      "epoch:16 step:15595 [D loss: 0.472477, acc.: 77.34%] [G loss: 0.748305]\n",
      "epoch:16 step:15596 [D loss: 0.646095, acc.: 60.16%] [G loss: 0.569402]\n",
      "epoch:16 step:15597 [D loss: 0.435234, acc.: 81.25%] [G loss: 0.600650]\n",
      "epoch:16 step:15598 [D loss: 0.674073, acc.: 58.59%] [G loss: 0.693494]\n",
      "epoch:16 step:15599 [D loss: 0.566652, acc.: 69.53%] [G loss: 0.612250]\n",
      "epoch:16 step:15600 [D loss: 0.559990, acc.: 62.50%] [G loss: 0.555555]\n",
      "##############\n",
      "[2.86414598 1.36381303 6.33644019 5.10960651 3.77173734 5.84944791\n",
      " 4.60392045 4.69797093 4.83391315 4.3828464 ]\n",
      "##########\n",
      "epoch:16 step:15601 [D loss: 0.520284, acc.: 71.88%] [G loss: 0.378486]\n",
      "epoch:16 step:15602 [D loss: 0.535377, acc.: 72.66%] [G loss: 0.533895]\n",
      "epoch:16 step:15603 [D loss: 0.511324, acc.: 71.09%] [G loss: 0.524730]\n",
      "epoch:16 step:15604 [D loss: 0.537399, acc.: 69.53%] [G loss: 0.619618]\n",
      "epoch:16 step:15605 [D loss: 0.494460, acc.: 75.00%] [G loss: 0.534840]\n",
      "epoch:16 step:15606 [D loss: 0.547105, acc.: 70.31%] [G loss: 0.609539]\n",
      "epoch:16 step:15607 [D loss: 0.559710, acc.: 69.53%] [G loss: 0.744351]\n",
      "epoch:16 step:15608 [D loss: 0.556679, acc.: 74.22%] [G loss: 0.860120]\n",
      "epoch:16 step:15609 [D loss: 0.515822, acc.: 71.88%] [G loss: 0.628329]\n",
      "epoch:16 step:15610 [D loss: 0.475326, acc.: 80.47%] [G loss: 0.676443]\n",
      "epoch:16 step:15611 [D loss: 0.495564, acc.: 74.22%] [G loss: 0.622775]\n",
      "epoch:16 step:15612 [D loss: 0.549376, acc.: 70.31%] [G loss: 0.740544]\n",
      "epoch:16 step:15613 [D loss: 0.621628, acc.: 70.31%] [G loss: 0.779332]\n",
      "epoch:16 step:15614 [D loss: 0.528407, acc.: 72.66%] [G loss: 0.597390]\n",
      "epoch:16 step:15615 [D loss: 0.461012, acc.: 71.88%] [G loss: 0.637254]\n",
      "epoch:16 step:15616 [D loss: 0.432876, acc.: 78.12%] [G loss: 0.760140]\n",
      "epoch:16 step:15617 [D loss: 0.603469, acc.: 64.06%] [G loss: 0.667868]\n",
      "epoch:16 step:15618 [D loss: 0.532962, acc.: 71.09%] [G loss: 0.619058]\n",
      "epoch:16 step:15619 [D loss: 0.554691, acc.: 71.88%] [G loss: 0.638023]\n",
      "epoch:16 step:15620 [D loss: 0.582986, acc.: 65.62%] [G loss: 0.529550]\n",
      "epoch:16 step:15621 [D loss: 0.485420, acc.: 76.56%] [G loss: 0.580109]\n",
      "epoch:16 step:15622 [D loss: 0.511151, acc.: 71.88%] [G loss: 0.822582]\n",
      "epoch:16 step:15623 [D loss: 0.492908, acc.: 78.91%] [G loss: 0.601243]\n",
      "epoch:16 step:15624 [D loss: 0.487154, acc.: 77.34%] [G loss: 0.533279]\n",
      "epoch:16 step:15625 [D loss: 0.487700, acc.: 75.78%] [G loss: 0.714535]\n",
      "epoch:16 step:15626 [D loss: 0.498813, acc.: 78.12%] [G loss: 0.726801]\n",
      "epoch:16 step:15627 [D loss: 0.516931, acc.: 72.66%] [G loss: 0.762522]\n",
      "epoch:16 step:15628 [D loss: 0.567904, acc.: 70.31%] [G loss: 0.682016]\n",
      "epoch:16 step:15629 [D loss: 0.533579, acc.: 71.88%] [G loss: 0.673571]\n",
      "epoch:16 step:15630 [D loss: 0.477288, acc.: 75.00%] [G loss: 0.599605]\n",
      "epoch:16 step:15631 [D loss: 0.504335, acc.: 71.88%] [G loss: 0.825339]\n",
      "epoch:16 step:15632 [D loss: 0.570353, acc.: 70.31%] [G loss: 0.714378]\n",
      "epoch:16 step:15633 [D loss: 0.490104, acc.: 74.22%] [G loss: 0.737984]\n",
      "epoch:16 step:15634 [D loss: 0.512710, acc.: 74.22%] [G loss: 0.819657]\n",
      "epoch:16 step:15635 [D loss: 0.524166, acc.: 74.22%] [G loss: 0.640871]\n",
      "epoch:16 step:15636 [D loss: 0.570585, acc.: 67.19%] [G loss: 0.580531]\n",
      "epoch:16 step:15637 [D loss: 0.563293, acc.: 66.41%] [G loss: 0.544440]\n",
      "epoch:16 step:15638 [D loss: 0.563931, acc.: 70.31%] [G loss: 0.670335]\n",
      "epoch:16 step:15639 [D loss: 0.468533, acc.: 83.59%] [G loss: 0.724040]\n",
      "epoch:16 step:15640 [D loss: 0.450241, acc.: 81.25%] [G loss: 1.015364]\n",
      "epoch:16 step:15641 [D loss: 0.485663, acc.: 76.56%] [G loss: 0.855178]\n",
      "epoch:16 step:15642 [D loss: 0.522577, acc.: 75.00%] [G loss: 0.828192]\n",
      "epoch:16 step:15643 [D loss: 0.558982, acc.: 70.31%] [G loss: 0.763459]\n",
      "epoch:16 step:15644 [D loss: 0.636477, acc.: 61.72%] [G loss: 0.737942]\n",
      "epoch:16 step:15645 [D loss: 0.538161, acc.: 73.44%] [G loss: 0.684792]\n",
      "epoch:16 step:15646 [D loss: 0.514374, acc.: 67.97%] [G loss: 0.777516]\n",
      "epoch:16 step:15647 [D loss: 0.547065, acc.: 71.09%] [G loss: 0.619799]\n",
      "epoch:16 step:15648 [D loss: 0.580755, acc.: 67.19%] [G loss: 0.560158]\n",
      "epoch:16 step:15649 [D loss: 0.531838, acc.: 68.75%] [G loss: 0.610732]\n",
      "epoch:16 step:15650 [D loss: 0.598709, acc.: 68.75%] [G loss: 0.641565]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15651 [D loss: 0.551431, acc.: 71.09%] [G loss: 0.655392]\n",
      "epoch:16 step:15652 [D loss: 0.495685, acc.: 73.44%] [G loss: 0.840094]\n",
      "epoch:16 step:15653 [D loss: 0.483113, acc.: 75.78%] [G loss: 0.944984]\n",
      "epoch:16 step:15654 [D loss: 0.551504, acc.: 68.75%] [G loss: 0.712864]\n",
      "epoch:16 step:15655 [D loss: 0.557174, acc.: 67.97%] [G loss: 0.641941]\n",
      "epoch:16 step:15656 [D loss: 0.544134, acc.: 67.97%] [G loss: 0.724820]\n",
      "epoch:16 step:15657 [D loss: 0.570596, acc.: 65.62%] [G loss: 0.680017]\n",
      "epoch:16 step:15658 [D loss: 0.533156, acc.: 73.44%] [G loss: 0.681591]\n",
      "epoch:16 step:15659 [D loss: 0.574573, acc.: 72.66%] [G loss: 0.503919]\n",
      "epoch:16 step:15660 [D loss: 0.539292, acc.: 73.44%] [G loss: 0.755596]\n",
      "epoch:16 step:15661 [D loss: 0.593120, acc.: 67.19%] [G loss: 0.530323]\n",
      "epoch:16 step:15662 [D loss: 0.561511, acc.: 69.53%] [G loss: 0.588289]\n",
      "epoch:16 step:15663 [D loss: 0.543356, acc.: 75.00%] [G loss: 0.588274]\n",
      "epoch:16 step:15664 [D loss: 0.559587, acc.: 72.66%] [G loss: 0.545246]\n",
      "epoch:16 step:15665 [D loss: 0.528831, acc.: 72.66%] [G loss: 0.708288]\n",
      "epoch:16 step:15666 [D loss: 0.564834, acc.: 71.09%] [G loss: 0.678015]\n",
      "epoch:16 step:15667 [D loss: 0.619460, acc.: 60.94%] [G loss: 0.697261]\n",
      "epoch:16 step:15668 [D loss: 0.537029, acc.: 72.66%] [G loss: 0.624619]\n",
      "epoch:16 step:15669 [D loss: 0.514565, acc.: 75.00%] [G loss: 0.638385]\n",
      "epoch:16 step:15670 [D loss: 0.589695, acc.: 71.09%] [G loss: 0.595785]\n",
      "epoch:16 step:15671 [D loss: 0.505350, acc.: 75.78%] [G loss: 0.679419]\n",
      "epoch:16 step:15672 [D loss: 0.506621, acc.: 74.22%] [G loss: 0.778538]\n",
      "epoch:16 step:15673 [D loss: 0.531207, acc.: 73.44%] [G loss: 0.533689]\n",
      "epoch:16 step:15674 [D loss: 0.501646, acc.: 75.00%] [G loss: 0.750111]\n",
      "epoch:16 step:15675 [D loss: 0.555248, acc.: 71.88%] [G loss: 0.471284]\n",
      "epoch:16 step:15676 [D loss: 0.621714, acc.: 65.62%] [G loss: 0.612249]\n",
      "epoch:16 step:15677 [D loss: 0.504732, acc.: 75.78%] [G loss: 0.514381]\n",
      "epoch:16 step:15678 [D loss: 0.581718, acc.: 68.75%] [G loss: 0.564779]\n",
      "epoch:16 step:15679 [D loss: 0.569169, acc.: 67.19%] [G loss: 0.602078]\n",
      "epoch:16 step:15680 [D loss: 0.533565, acc.: 66.41%] [G loss: 0.707693]\n",
      "epoch:16 step:15681 [D loss: 0.522321, acc.: 76.56%] [G loss: 0.492295]\n",
      "epoch:16 step:15682 [D loss: 0.517094, acc.: 73.44%] [G loss: 0.640469]\n",
      "epoch:16 step:15683 [D loss: 0.504934, acc.: 78.12%] [G loss: 0.674254]\n",
      "epoch:16 step:15684 [D loss: 0.542116, acc.: 70.31%] [G loss: 0.570838]\n",
      "epoch:16 step:15685 [D loss: 0.476068, acc.: 78.12%] [G loss: 0.682792]\n",
      "epoch:16 step:15686 [D loss: 0.519904, acc.: 71.88%] [G loss: 0.669800]\n",
      "epoch:16 step:15687 [D loss: 0.500196, acc.: 76.56%] [G loss: 0.656549]\n",
      "epoch:16 step:15688 [D loss: 0.583134, acc.: 63.28%] [G loss: 0.543107]\n",
      "epoch:16 step:15689 [D loss: 0.543051, acc.: 67.19%] [G loss: 0.582812]\n",
      "epoch:16 step:15690 [D loss: 0.550312, acc.: 72.66%] [G loss: 0.550937]\n",
      "epoch:16 step:15691 [D loss: 0.488294, acc.: 74.22%] [G loss: 0.622594]\n",
      "epoch:16 step:15692 [D loss: 0.528230, acc.: 70.31%] [G loss: 0.576182]\n",
      "epoch:16 step:15693 [D loss: 0.530309, acc.: 67.97%] [G loss: 0.819136]\n",
      "epoch:16 step:15694 [D loss: 0.608170, acc.: 66.41%] [G loss: 0.578217]\n",
      "epoch:16 step:15695 [D loss: 0.595269, acc.: 67.97%] [G loss: 0.604634]\n",
      "epoch:16 step:15696 [D loss: 0.562818, acc.: 70.31%] [G loss: 0.616700]\n",
      "epoch:16 step:15697 [D loss: 0.494531, acc.: 71.09%] [G loss: 0.616481]\n",
      "epoch:16 step:15698 [D loss: 0.522458, acc.: 75.00%] [G loss: 0.580078]\n",
      "epoch:16 step:15699 [D loss: 0.516112, acc.: 71.09%] [G loss: 0.649810]\n",
      "epoch:16 step:15700 [D loss: 0.476062, acc.: 75.78%] [G loss: 0.775287]\n",
      "epoch:16 step:15701 [D loss: 0.528744, acc.: 74.22%] [G loss: 0.664882]\n",
      "epoch:16 step:15702 [D loss: 0.572139, acc.: 68.75%] [G loss: 0.707796]\n",
      "epoch:16 step:15703 [D loss: 0.596727, acc.: 65.62%] [G loss: 0.514139]\n",
      "epoch:16 step:15704 [D loss: 0.525610, acc.: 66.41%] [G loss: 0.565849]\n",
      "epoch:16 step:15705 [D loss: 0.633351, acc.: 61.72%] [G loss: 0.611423]\n",
      "epoch:16 step:15706 [D loss: 0.506191, acc.: 72.66%] [G loss: 0.724037]\n",
      "epoch:16 step:15707 [D loss: 0.540452, acc.: 70.31%] [G loss: 0.589098]\n",
      "epoch:16 step:15708 [D loss: 0.624766, acc.: 64.06%] [G loss: 0.523347]\n",
      "epoch:16 step:15709 [D loss: 0.563902, acc.: 68.75%] [G loss: 0.575590]\n",
      "epoch:16 step:15710 [D loss: 0.580495, acc.: 68.75%] [G loss: 0.506510]\n",
      "epoch:16 step:15711 [D loss: 0.510122, acc.: 70.31%] [G loss: 0.636604]\n",
      "epoch:16 step:15712 [D loss: 0.596912, acc.: 69.53%] [G loss: 0.545718]\n",
      "epoch:16 step:15713 [D loss: 0.506734, acc.: 75.00%] [G loss: 0.716980]\n",
      "epoch:16 step:15714 [D loss: 0.551382, acc.: 72.66%] [G loss: 0.578322]\n",
      "epoch:16 step:15715 [D loss: 0.577919, acc.: 68.75%] [G loss: 0.593201]\n",
      "epoch:16 step:15716 [D loss: 0.535543, acc.: 71.88%] [G loss: 0.553598]\n",
      "epoch:16 step:15717 [D loss: 0.495827, acc.: 76.56%] [G loss: 0.572444]\n",
      "epoch:16 step:15718 [D loss: 0.490419, acc.: 78.12%] [G loss: 0.671546]\n",
      "epoch:16 step:15719 [D loss: 0.531380, acc.: 71.88%] [G loss: 0.579259]\n",
      "epoch:16 step:15720 [D loss: 0.605050, acc.: 63.28%] [G loss: 0.546480]\n",
      "epoch:16 step:15721 [D loss: 0.540014, acc.: 70.31%] [G loss: 0.553474]\n",
      "epoch:16 step:15722 [D loss: 0.550830, acc.: 74.22%] [G loss: 0.552080]\n",
      "epoch:16 step:15723 [D loss: 0.593603, acc.: 64.06%] [G loss: 0.656847]\n",
      "epoch:16 step:15724 [D loss: 0.548494, acc.: 67.19%] [G loss: 0.582860]\n",
      "epoch:16 step:15725 [D loss: 0.530898, acc.: 74.22%] [G loss: 0.458119]\n",
      "epoch:16 step:15726 [D loss: 0.506487, acc.: 75.78%] [G loss: 0.669502]\n",
      "epoch:16 step:15727 [D loss: 0.584854, acc.: 64.06%] [G loss: 0.578819]\n",
      "epoch:16 step:15728 [D loss: 0.444294, acc.: 79.69%] [G loss: 0.720660]\n",
      "epoch:16 step:15729 [D loss: 0.609272, acc.: 62.50%] [G loss: 0.642964]\n",
      "epoch:16 step:15730 [D loss: 0.563343, acc.: 67.97%] [G loss: 0.577103]\n",
      "epoch:16 step:15731 [D loss: 0.581786, acc.: 66.41%] [G loss: 0.532931]\n",
      "epoch:16 step:15732 [D loss: 0.637440, acc.: 59.38%] [G loss: 0.391286]\n",
      "epoch:16 step:15733 [D loss: 0.572312, acc.: 70.31%] [G loss: 0.452863]\n",
      "epoch:16 step:15734 [D loss: 0.528139, acc.: 69.53%] [G loss: 0.639720]\n",
      "epoch:16 step:15735 [D loss: 0.486081, acc.: 74.22%] [G loss: 0.699126]\n",
      "epoch:16 step:15736 [D loss: 0.524831, acc.: 71.88%] [G loss: 0.696695]\n",
      "epoch:16 step:15737 [D loss: 0.618905, acc.: 64.06%] [G loss: 0.484435]\n",
      "epoch:16 step:15738 [D loss: 0.475557, acc.: 75.00%] [G loss: 0.699605]\n",
      "epoch:16 step:15739 [D loss: 0.490329, acc.: 74.22%] [G loss: 0.711497]\n",
      "epoch:16 step:15740 [D loss: 0.540403, acc.: 72.66%] [G loss: 0.811670]\n",
      "epoch:16 step:15741 [D loss: 0.566028, acc.: 71.09%] [G loss: 0.658973]\n",
      "epoch:16 step:15742 [D loss: 0.538055, acc.: 70.31%] [G loss: 0.598215]\n",
      "epoch:16 step:15743 [D loss: 0.490275, acc.: 77.34%] [G loss: 0.831027]\n",
      "epoch:16 step:15744 [D loss: 0.579877, acc.: 71.88%] [G loss: 0.943981]\n",
      "epoch:16 step:15745 [D loss: 0.476603, acc.: 75.78%] [G loss: 0.902154]\n",
      "epoch:16 step:15746 [D loss: 0.556055, acc.: 67.97%] [G loss: 0.775155]\n",
      "epoch:16 step:15747 [D loss: 0.654555, acc.: 63.28%] [G loss: 0.711528]\n",
      "epoch:16 step:15748 [D loss: 0.520866, acc.: 69.53%] [G loss: 0.795902]\n",
      "epoch:16 step:15749 [D loss: 0.605096, acc.: 64.84%] [G loss: 0.525077]\n",
      "epoch:16 step:15750 [D loss: 0.554683, acc.: 71.88%] [G loss: 0.572930]\n",
      "epoch:16 step:15751 [D loss: 0.591041, acc.: 71.88%] [G loss: 0.561582]\n",
      "epoch:16 step:15752 [D loss: 0.521951, acc.: 71.88%] [G loss: 0.698686]\n",
      "epoch:16 step:15753 [D loss: 0.566517, acc.: 67.97%] [G loss: 0.649756]\n",
      "epoch:16 step:15754 [D loss: 0.644108, acc.: 57.81%] [G loss: 0.746278]\n",
      "epoch:16 step:15755 [D loss: 0.556298, acc.: 68.75%] [G loss: 0.560628]\n",
      "epoch:16 step:15756 [D loss: 0.580701, acc.: 64.84%] [G loss: 0.548660]\n",
      "epoch:16 step:15757 [D loss: 0.585022, acc.: 69.53%] [G loss: 0.636004]\n",
      "epoch:16 step:15758 [D loss: 0.709855, acc.: 57.81%] [G loss: 0.469223]\n",
      "epoch:16 step:15759 [D loss: 0.521791, acc.: 75.00%] [G loss: 0.575288]\n",
      "epoch:16 step:15760 [D loss: 0.550464, acc.: 72.66%] [G loss: 0.642794]\n",
      "epoch:16 step:15761 [D loss: 0.430536, acc.: 82.81%] [G loss: 0.877012]\n",
      "epoch:16 step:15762 [D loss: 0.541318, acc.: 71.88%] [G loss: 0.904278]\n",
      "epoch:16 step:15763 [D loss: 0.534313, acc.: 71.88%] [G loss: 1.052116]\n",
      "epoch:16 step:15764 [D loss: 0.543747, acc.: 75.00%] [G loss: 0.665981]\n",
      "epoch:16 step:15765 [D loss: 0.526056, acc.: 69.53%] [G loss: 0.746270]\n",
      "epoch:16 step:15766 [D loss: 0.553401, acc.: 69.53%] [G loss: 0.643607]\n",
      "epoch:16 step:15767 [D loss: 0.504124, acc.: 73.44%] [G loss: 0.891976]\n",
      "epoch:16 step:15768 [D loss: 0.556165, acc.: 67.97%] [G loss: 0.661464]\n",
      "epoch:16 step:15769 [D loss: 0.563144, acc.: 67.97%] [G loss: 0.604657]\n",
      "epoch:16 step:15770 [D loss: 0.546554, acc.: 74.22%] [G loss: 0.709975]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15771 [D loss: 0.551608, acc.: 67.97%] [G loss: 0.771929]\n",
      "epoch:16 step:15772 [D loss: 0.534371, acc.: 71.88%] [G loss: 0.675835]\n",
      "epoch:16 step:15773 [D loss: 0.487322, acc.: 77.34%] [G loss: 0.740000]\n",
      "epoch:16 step:15774 [D loss: 0.523712, acc.: 75.00%] [G loss: 0.829927]\n",
      "epoch:16 step:15775 [D loss: 0.600966, acc.: 67.19%] [G loss: 0.845000]\n",
      "epoch:16 step:15776 [D loss: 0.629987, acc.: 65.62%] [G loss: 0.485714]\n",
      "epoch:16 step:15777 [D loss: 0.567771, acc.: 66.41%] [G loss: 0.565028]\n",
      "epoch:16 step:15778 [D loss: 0.537986, acc.: 70.31%] [G loss: 0.484912]\n",
      "epoch:16 step:15779 [D loss: 0.580491, acc.: 71.88%] [G loss: 0.488660]\n",
      "epoch:16 step:15780 [D loss: 0.663629, acc.: 53.91%] [G loss: 0.550498]\n",
      "epoch:16 step:15781 [D loss: 0.537690, acc.: 73.44%] [G loss: 0.529881]\n",
      "epoch:16 step:15782 [D loss: 0.540999, acc.: 67.97%] [G loss: 0.602950]\n",
      "epoch:16 step:15783 [D loss: 0.601022, acc.: 67.19%] [G loss: 0.710511]\n",
      "epoch:16 step:15784 [D loss: 0.463039, acc.: 73.44%] [G loss: 0.704687]\n",
      "epoch:16 step:15785 [D loss: 0.591253, acc.: 67.97%] [G loss: 0.712941]\n",
      "epoch:16 step:15786 [D loss: 0.631215, acc.: 63.28%] [G loss: 0.530762]\n",
      "epoch:16 step:15787 [D loss: 0.529705, acc.: 66.41%] [G loss: 0.600425]\n",
      "epoch:16 step:15788 [D loss: 0.526679, acc.: 71.09%] [G loss: 0.764074]\n",
      "epoch:16 step:15789 [D loss: 0.524939, acc.: 75.00%] [G loss: 0.708318]\n",
      "epoch:16 step:15790 [D loss: 0.544003, acc.: 67.19%] [G loss: 0.627221]\n",
      "epoch:16 step:15791 [D loss: 0.574482, acc.: 70.31%] [G loss: 0.723659]\n",
      "epoch:16 step:15792 [D loss: 0.586795, acc.: 64.84%] [G loss: 0.624315]\n",
      "epoch:16 step:15793 [D loss: 0.553790, acc.: 68.75%] [G loss: 0.614561]\n",
      "epoch:16 step:15794 [D loss: 0.427637, acc.: 78.12%] [G loss: 0.776586]\n",
      "epoch:16 step:15795 [D loss: 0.526582, acc.: 75.00%] [G loss: 0.736534]\n",
      "epoch:16 step:15796 [D loss: 0.564566, acc.: 70.31%] [G loss: 0.710598]\n",
      "epoch:16 step:15797 [D loss: 0.556052, acc.: 69.53%] [G loss: 0.644336]\n",
      "epoch:16 step:15798 [D loss: 0.569634, acc.: 66.41%] [G loss: 0.569152]\n",
      "epoch:16 step:15799 [D loss: 0.549391, acc.: 67.19%] [G loss: 0.553609]\n",
      "epoch:16 step:15800 [D loss: 0.520057, acc.: 69.53%] [G loss: 0.677155]\n",
      "##############\n",
      "[3.13879491 1.01149478 5.9536186  4.81457831 3.66418231 5.9864789\n",
      " 4.47795958 5.00444837 4.72216926 4.21590857]\n",
      "##########\n",
      "epoch:16 step:15801 [D loss: 0.517186, acc.: 71.88%] [G loss: 0.630403]\n",
      "epoch:16 step:15802 [D loss: 0.541977, acc.: 69.53%] [G loss: 0.611573]\n",
      "epoch:16 step:15803 [D loss: 0.562457, acc.: 66.41%] [G loss: 0.595838]\n",
      "epoch:16 step:15804 [D loss: 0.604171, acc.: 67.19%] [G loss: 0.441752]\n",
      "epoch:16 step:15805 [D loss: 0.545659, acc.: 74.22%] [G loss: 0.521478]\n",
      "epoch:16 step:15806 [D loss: 0.489751, acc.: 75.78%] [G loss: 0.587178]\n",
      "epoch:16 step:15807 [D loss: 0.511674, acc.: 75.00%] [G loss: 0.892751]\n",
      "epoch:16 step:15808 [D loss: 0.518861, acc.: 73.44%] [G loss: 0.670031]\n",
      "epoch:16 step:15809 [D loss: 0.584910, acc.: 64.84%] [G loss: 0.660587]\n",
      "epoch:16 step:15810 [D loss: 0.543516, acc.: 67.19%] [G loss: 0.609666]\n",
      "epoch:16 step:15811 [D loss: 0.552330, acc.: 74.22%] [G loss: 0.763678]\n",
      "epoch:16 step:15812 [D loss: 0.609686, acc.: 64.84%] [G loss: 0.590227]\n",
      "epoch:16 step:15813 [D loss: 0.567395, acc.: 67.97%] [G loss: 0.575028]\n",
      "epoch:16 step:15814 [D loss: 0.563069, acc.: 67.19%] [G loss: 0.490133]\n",
      "epoch:16 step:15815 [D loss: 0.491014, acc.: 75.00%] [G loss: 0.710123]\n",
      "epoch:16 step:15816 [D loss: 0.578614, acc.: 68.75%] [G loss: 0.732592]\n",
      "epoch:16 step:15817 [D loss: 0.501192, acc.: 75.00%] [G loss: 0.601165]\n",
      "epoch:16 step:15818 [D loss: 0.583412, acc.: 67.19%] [G loss: 0.780751]\n",
      "epoch:16 step:15819 [D loss: 0.593176, acc.: 69.53%] [G loss: 0.440232]\n",
      "epoch:16 step:15820 [D loss: 0.632401, acc.: 67.19%] [G loss: 0.491486]\n",
      "epoch:16 step:15821 [D loss: 0.532076, acc.: 71.88%] [G loss: 0.588526]\n",
      "epoch:16 step:15822 [D loss: 0.556620, acc.: 68.75%] [G loss: 0.682174]\n",
      "epoch:16 step:15823 [D loss: 0.527816, acc.: 72.66%] [G loss: 0.719406]\n",
      "epoch:16 step:15824 [D loss: 0.529400, acc.: 70.31%] [G loss: 0.603959]\n",
      "epoch:16 step:15825 [D loss: 0.533492, acc.: 71.09%] [G loss: 0.698229]\n",
      "epoch:16 step:15826 [D loss: 0.519350, acc.: 71.88%] [G loss: 0.519582]\n",
      "epoch:16 step:15827 [D loss: 0.527467, acc.: 70.31%] [G loss: 0.633486]\n",
      "epoch:16 step:15828 [D loss: 0.534717, acc.: 71.09%] [G loss: 0.608381]\n",
      "epoch:16 step:15829 [D loss: 0.541653, acc.: 73.44%] [G loss: 0.530645]\n",
      "epoch:16 step:15830 [D loss: 0.538292, acc.: 74.22%] [G loss: 0.491843]\n",
      "epoch:16 step:15831 [D loss: 0.538018, acc.: 72.66%] [G loss: 0.520186]\n",
      "epoch:16 step:15832 [D loss: 0.575046, acc.: 72.66%] [G loss: 0.544831]\n",
      "epoch:16 step:15833 [D loss: 0.554066, acc.: 70.31%] [G loss: 0.497472]\n",
      "epoch:16 step:15834 [D loss: 0.554035, acc.: 71.09%] [G loss: 0.561306]\n",
      "epoch:16 step:15835 [D loss: 0.474833, acc.: 76.56%] [G loss: 0.733162]\n",
      "epoch:16 step:15836 [D loss: 0.547920, acc.: 74.22%] [G loss: 0.592469]\n",
      "epoch:16 step:15837 [D loss: 0.556744, acc.: 69.53%] [G loss: 0.634899]\n",
      "epoch:16 step:15838 [D loss: 0.615186, acc.: 66.41%] [G loss: 0.475189]\n",
      "epoch:16 step:15839 [D loss: 0.603906, acc.: 67.97%] [G loss: 0.499673]\n",
      "epoch:16 step:15840 [D loss: 0.562227, acc.: 67.97%] [G loss: 0.455711]\n",
      "epoch:16 step:15841 [D loss: 0.567083, acc.: 70.31%] [G loss: 0.407683]\n",
      "epoch:16 step:15842 [D loss: 0.575399, acc.: 70.31%] [G loss: 0.537629]\n",
      "epoch:16 step:15843 [D loss: 0.552270, acc.: 71.88%] [G loss: 0.565285]\n",
      "epoch:16 step:15844 [D loss: 0.560043, acc.: 68.75%] [G loss: 0.607379]\n",
      "epoch:16 step:15845 [D loss: 0.526715, acc.: 73.44%] [G loss: 0.646162]\n",
      "epoch:16 step:15846 [D loss: 0.448772, acc.: 75.00%] [G loss: 0.774713]\n",
      "epoch:16 step:15847 [D loss: 0.519545, acc.: 75.00%] [G loss: 0.714020]\n",
      "epoch:16 step:15848 [D loss: 0.586376, acc.: 66.41%] [G loss: 0.816262]\n",
      "epoch:16 step:15849 [D loss: 0.445078, acc.: 78.91%] [G loss: 0.654666]\n",
      "epoch:16 step:15850 [D loss: 0.598470, acc.: 63.28%] [G loss: 0.640821]\n",
      "epoch:16 step:15851 [D loss: 0.508335, acc.: 75.00%] [G loss: 0.568150]\n",
      "epoch:16 step:15852 [D loss: 0.513410, acc.: 77.34%] [G loss: 0.754577]\n",
      "epoch:16 step:15853 [D loss: 0.628580, acc.: 60.94%] [G loss: 0.535241]\n",
      "epoch:16 step:15854 [D loss: 0.558512, acc.: 69.53%] [G loss: 0.659978]\n",
      "epoch:16 step:15855 [D loss: 0.551890, acc.: 67.19%] [G loss: 0.511515]\n",
      "epoch:16 step:15856 [D loss: 0.525447, acc.: 68.75%] [G loss: 0.517743]\n",
      "epoch:16 step:15857 [D loss: 0.534022, acc.: 67.19%] [G loss: 0.597210]\n",
      "epoch:16 step:15858 [D loss: 0.553646, acc.: 64.84%] [G loss: 0.575760]\n",
      "epoch:16 step:15859 [D loss: 0.652117, acc.: 63.28%] [G loss: 0.492877]\n",
      "epoch:16 step:15860 [D loss: 0.560017, acc.: 67.97%] [G loss: 0.369470]\n",
      "epoch:16 step:15861 [D loss: 0.544896, acc.: 68.75%] [G loss: 0.517992]\n",
      "epoch:16 step:15862 [D loss: 0.466727, acc.: 78.91%] [G loss: 0.708527]\n",
      "epoch:16 step:15863 [D loss: 0.542479, acc.: 71.09%] [G loss: 0.749511]\n",
      "epoch:16 step:15864 [D loss: 0.536166, acc.: 72.66%] [G loss: 0.662576]\n",
      "epoch:16 step:15865 [D loss: 0.589369, acc.: 70.31%] [G loss: 0.684320]\n",
      "epoch:16 step:15866 [D loss: 0.601107, acc.: 65.62%] [G loss: 0.646662]\n",
      "epoch:16 step:15867 [D loss: 0.463752, acc.: 79.69%] [G loss: 0.663473]\n",
      "epoch:16 step:15868 [D loss: 0.556261, acc.: 70.31%] [G loss: 0.663627]\n",
      "epoch:16 step:15869 [D loss: 0.612765, acc.: 63.28%] [G loss: 0.486459]\n",
      "epoch:16 step:15870 [D loss: 0.501023, acc.: 75.78%] [G loss: 0.704212]\n",
      "epoch:16 step:15871 [D loss: 0.527663, acc.: 70.31%] [G loss: 0.527266]\n",
      "epoch:16 step:15872 [D loss: 0.609433, acc.: 64.06%] [G loss: 0.509829]\n",
      "epoch:16 step:15873 [D loss: 0.602392, acc.: 62.50%] [G loss: 0.422224]\n",
      "epoch:16 step:15874 [D loss: 0.598283, acc.: 60.94%] [G loss: 0.381579]\n",
      "epoch:16 step:15875 [D loss: 0.582316, acc.: 68.75%] [G loss: 0.430904]\n",
      "epoch:16 step:15876 [D loss: 0.489072, acc.: 71.88%] [G loss: 0.604106]\n",
      "epoch:16 step:15877 [D loss: 0.531158, acc.: 76.56%] [G loss: 0.740060]\n",
      "epoch:16 step:15878 [D loss: 0.530525, acc.: 71.09%] [G loss: 0.817638]\n",
      "epoch:16 step:15879 [D loss: 0.575273, acc.: 70.31%] [G loss: 0.803813]\n",
      "epoch:16 step:15880 [D loss: 0.538752, acc.: 71.88%] [G loss: 0.589420]\n",
      "epoch:16 step:15881 [D loss: 0.595172, acc.: 64.06%] [G loss: 0.639886]\n",
      "epoch:16 step:15882 [D loss: 0.534298, acc.: 68.75%] [G loss: 0.574097]\n",
      "epoch:16 step:15883 [D loss: 0.561335, acc.: 67.97%] [G loss: 0.560535]\n",
      "epoch:16 step:15884 [D loss: 0.629224, acc.: 58.59%] [G loss: 0.646706]\n",
      "epoch:16 step:15885 [D loss: 0.491761, acc.: 75.78%] [G loss: 0.619101]\n",
      "epoch:16 step:15886 [D loss: 0.447084, acc.: 79.69%] [G loss: 0.635193]\n",
      "epoch:16 step:15887 [D loss: 0.540205, acc.: 71.88%] [G loss: 0.715178]\n",
      "epoch:16 step:15888 [D loss: 0.487099, acc.: 77.34%] [G loss: 0.651931]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15889 [D loss: 0.477518, acc.: 75.78%] [G loss: 0.750953]\n",
      "epoch:16 step:15890 [D loss: 0.458321, acc.: 82.03%] [G loss: 0.775184]\n",
      "epoch:16 step:15891 [D loss: 0.465679, acc.: 78.91%] [G loss: 0.755979]\n",
      "epoch:16 step:15892 [D loss: 0.512114, acc.: 71.88%] [G loss: 0.696764]\n",
      "epoch:16 step:15893 [D loss: 0.534904, acc.: 69.53%] [G loss: 0.728766]\n",
      "epoch:16 step:15894 [D loss: 0.548599, acc.: 68.75%] [G loss: 0.720440]\n",
      "epoch:16 step:15895 [D loss: 0.512385, acc.: 76.56%] [G loss: 0.546436]\n",
      "epoch:16 step:15896 [D loss: 0.622002, acc.: 64.06%] [G loss: 0.571206]\n",
      "epoch:16 step:15897 [D loss: 0.543309, acc.: 67.97%] [G loss: 0.589271]\n",
      "epoch:16 step:15898 [D loss: 0.477783, acc.: 75.78%] [G loss: 0.579520]\n",
      "epoch:16 step:15899 [D loss: 0.531947, acc.: 71.88%] [G loss: 0.698203]\n",
      "epoch:16 step:15900 [D loss: 0.552034, acc.: 68.75%] [G loss: 0.621027]\n",
      "epoch:16 step:15901 [D loss: 0.466988, acc.: 76.56%] [G loss: 0.929393]\n",
      "epoch:16 step:15902 [D loss: 0.551004, acc.: 65.62%] [G loss: 0.689995]\n",
      "epoch:16 step:15903 [D loss: 0.448351, acc.: 81.25%] [G loss: 0.796272]\n",
      "epoch:16 step:15904 [D loss: 0.471281, acc.: 78.12%] [G loss: 0.917748]\n",
      "epoch:16 step:15905 [D loss: 0.569528, acc.: 73.44%] [G loss: 0.821327]\n",
      "epoch:16 step:15906 [D loss: 0.474771, acc.: 72.66%] [G loss: 0.850174]\n",
      "epoch:16 step:15907 [D loss: 0.606092, acc.: 63.28%] [G loss: 0.801692]\n",
      "epoch:16 step:15908 [D loss: 0.538511, acc.: 68.75%] [G loss: 0.741105]\n",
      "epoch:16 step:15909 [D loss: 0.549571, acc.: 64.06%] [G loss: 0.753026]\n",
      "epoch:16 step:15910 [D loss: 0.506892, acc.: 73.44%] [G loss: 0.772658]\n",
      "epoch:16 step:15911 [D loss: 0.458237, acc.: 78.91%] [G loss: 0.827262]\n",
      "epoch:16 step:15912 [D loss: 0.715019, acc.: 60.94%] [G loss: 0.552970]\n",
      "epoch:16 step:15913 [D loss: 0.417812, acc.: 78.91%] [G loss: 0.842149]\n",
      "epoch:16 step:15914 [D loss: 0.538145, acc.: 71.88%] [G loss: 0.665239]\n",
      "epoch:16 step:15915 [D loss: 0.450989, acc.: 76.56%] [G loss: 0.733545]\n",
      "epoch:16 step:15916 [D loss: 0.416678, acc.: 78.12%] [G loss: 0.825095]\n",
      "epoch:16 step:15917 [D loss: 0.394885, acc.: 82.81%] [G loss: 1.116007]\n",
      "epoch:16 step:15918 [D loss: 0.404910, acc.: 83.59%] [G loss: 1.068246]\n",
      "epoch:16 step:15919 [D loss: 0.494954, acc.: 71.09%] [G loss: 1.058219]\n",
      "epoch:16 step:15920 [D loss: 0.817920, acc.: 56.25%] [G loss: 1.129366]\n",
      "epoch:16 step:15921 [D loss: 0.575352, acc.: 68.75%] [G loss: 1.475784]\n",
      "epoch:16 step:15922 [D loss: 0.428530, acc.: 81.25%] [G loss: 1.371788]\n",
      "epoch:16 step:15923 [D loss: 0.516502, acc.: 71.88%] [G loss: 0.936029]\n",
      "epoch:16 step:15924 [D loss: 0.603277, acc.: 67.19%] [G loss: 0.741343]\n",
      "epoch:16 step:15925 [D loss: 0.505622, acc.: 73.44%] [G loss: 1.017474]\n",
      "epoch:16 step:15926 [D loss: 0.601659, acc.: 67.97%] [G loss: 0.973598]\n",
      "epoch:16 step:15927 [D loss: 0.494192, acc.: 76.56%] [G loss: 0.822923]\n",
      "epoch:16 step:15928 [D loss: 0.419288, acc.: 78.12%] [G loss: 1.142417]\n",
      "epoch:16 step:15929 [D loss: 0.435773, acc.: 82.81%] [G loss: 1.239258]\n",
      "epoch:17 step:15930 [D loss: 0.520986, acc.: 75.00%] [G loss: 0.962452]\n",
      "epoch:17 step:15931 [D loss: 0.515676, acc.: 74.22%] [G loss: 0.907686]\n",
      "epoch:17 step:15932 [D loss: 0.574962, acc.: 68.75%] [G loss: 0.837409]\n",
      "epoch:17 step:15933 [D loss: 0.501820, acc.: 78.12%] [G loss: 0.733531]\n",
      "epoch:17 step:15934 [D loss: 0.567110, acc.: 71.88%] [G loss: 0.692262]\n",
      "epoch:17 step:15935 [D loss: 0.627748, acc.: 60.94%] [G loss: 0.681826]\n",
      "epoch:17 step:15936 [D loss: 0.498989, acc.: 72.66%] [G loss: 0.673250]\n",
      "epoch:17 step:15937 [D loss: 0.490291, acc.: 75.78%] [G loss: 0.800343]\n",
      "epoch:17 step:15938 [D loss: 0.509224, acc.: 72.66%] [G loss: 0.792504]\n",
      "epoch:17 step:15939 [D loss: 0.565101, acc.: 67.19%] [G loss: 0.716882]\n",
      "epoch:17 step:15940 [D loss: 0.464091, acc.: 76.56%] [G loss: 1.012052]\n",
      "epoch:17 step:15941 [D loss: 0.558605, acc.: 72.66%] [G loss: 0.675109]\n",
      "epoch:17 step:15942 [D loss: 0.629234, acc.: 65.62%] [G loss: 0.887358]\n",
      "epoch:17 step:15943 [D loss: 0.552635, acc.: 71.09%] [G loss: 0.675758]\n",
      "epoch:17 step:15944 [D loss: 0.512611, acc.: 72.66%] [G loss: 0.732305]\n",
      "epoch:17 step:15945 [D loss: 0.513192, acc.: 72.66%] [G loss: 0.807043]\n",
      "epoch:17 step:15946 [D loss: 0.507302, acc.: 76.56%] [G loss: 0.659020]\n",
      "epoch:17 step:15947 [D loss: 0.572885, acc.: 67.97%] [G loss: 0.730594]\n",
      "epoch:17 step:15948 [D loss: 0.541215, acc.: 75.78%] [G loss: 0.927851]\n",
      "epoch:17 step:15949 [D loss: 0.726517, acc.: 58.59%] [G loss: 0.608638]\n",
      "epoch:17 step:15950 [D loss: 0.579930, acc.: 65.62%] [G loss: 0.675881]\n",
      "epoch:17 step:15951 [D loss: 0.536216, acc.: 67.97%] [G loss: 1.014283]\n",
      "epoch:17 step:15952 [D loss: 0.587510, acc.: 65.62%] [G loss: 0.603992]\n",
      "epoch:17 step:15953 [D loss: 0.488396, acc.: 77.34%] [G loss: 0.659267]\n",
      "epoch:17 step:15954 [D loss: 0.482656, acc.: 75.00%] [G loss: 0.761429]\n",
      "epoch:17 step:15955 [D loss: 0.594524, acc.: 63.28%] [G loss: 0.521475]\n",
      "epoch:17 step:15956 [D loss: 0.465315, acc.: 78.12%] [G loss: 0.635101]\n",
      "epoch:17 step:15957 [D loss: 0.527093, acc.: 67.97%] [G loss: 0.631801]\n",
      "epoch:17 step:15958 [D loss: 0.519259, acc.: 71.88%] [G loss: 0.620524]\n",
      "epoch:17 step:15959 [D loss: 0.521681, acc.: 70.31%] [G loss: 0.654389]\n",
      "epoch:17 step:15960 [D loss: 0.650645, acc.: 60.16%] [G loss: 0.580876]\n",
      "epoch:17 step:15961 [D loss: 0.578493, acc.: 69.53%] [G loss: 0.603886]\n",
      "epoch:17 step:15962 [D loss: 0.513510, acc.: 73.44%] [G loss: 0.606426]\n",
      "epoch:17 step:15963 [D loss: 0.535784, acc.: 66.41%] [G loss: 0.642575]\n",
      "epoch:17 step:15964 [D loss: 0.576334, acc.: 68.75%] [G loss: 0.788256]\n",
      "epoch:17 step:15965 [D loss: 0.529621, acc.: 72.66%] [G loss: 0.819667]\n",
      "epoch:17 step:15966 [D loss: 0.492770, acc.: 77.34%] [G loss: 0.761217]\n",
      "epoch:17 step:15967 [D loss: 0.609440, acc.: 66.41%] [G loss: 0.556818]\n",
      "epoch:17 step:15968 [D loss: 0.542321, acc.: 71.88%] [G loss: 0.703011]\n",
      "epoch:17 step:15969 [D loss: 0.412778, acc.: 81.25%] [G loss: 0.776464]\n",
      "epoch:17 step:15970 [D loss: 0.503638, acc.: 74.22%] [G loss: 0.730392]\n",
      "epoch:17 step:15971 [D loss: 0.564695, acc.: 69.53%] [G loss: 0.691278]\n",
      "epoch:17 step:15972 [D loss: 0.509591, acc.: 75.78%] [G loss: 0.679913]\n",
      "epoch:17 step:15973 [D loss: 0.616775, acc.: 66.41%] [G loss: 0.633455]\n",
      "epoch:17 step:15974 [D loss: 0.489174, acc.: 79.69%] [G loss: 0.502246]\n",
      "epoch:17 step:15975 [D loss: 0.490553, acc.: 76.56%] [G loss: 0.690419]\n",
      "epoch:17 step:15976 [D loss: 0.532638, acc.: 69.53%] [G loss: 0.617841]\n",
      "epoch:17 step:15977 [D loss: 0.533393, acc.: 68.75%] [G loss: 0.696236]\n",
      "epoch:17 step:15978 [D loss: 0.472106, acc.: 75.00%] [G loss: 0.687275]\n",
      "epoch:17 step:15979 [D loss: 0.552985, acc.: 70.31%] [G loss: 0.692668]\n",
      "epoch:17 step:15980 [D loss: 0.648283, acc.: 60.94%] [G loss: 0.608467]\n",
      "epoch:17 step:15981 [D loss: 0.565347, acc.: 67.19%] [G loss: 0.718666]\n",
      "epoch:17 step:15982 [D loss: 0.508028, acc.: 71.88%] [G loss: 0.853993]\n",
      "epoch:17 step:15983 [D loss: 0.461677, acc.: 73.44%] [G loss: 0.858814]\n",
      "epoch:17 step:15984 [D loss: 0.513494, acc.: 75.00%] [G loss: 0.666070]\n",
      "epoch:17 step:15985 [D loss: 0.544042, acc.: 74.22%] [G loss: 0.718121]\n",
      "epoch:17 step:15986 [D loss: 0.542460, acc.: 67.97%] [G loss: 0.756131]\n",
      "epoch:17 step:15987 [D loss: 0.506069, acc.: 76.56%] [G loss: 0.633986]\n",
      "epoch:17 step:15988 [D loss: 0.503949, acc.: 75.00%] [G loss: 0.808225]\n",
      "epoch:17 step:15989 [D loss: 0.559947, acc.: 60.94%] [G loss: 0.571178]\n",
      "epoch:17 step:15990 [D loss: 0.544779, acc.: 69.53%] [G loss: 0.513692]\n",
      "epoch:17 step:15991 [D loss: 0.517815, acc.: 71.88%] [G loss: 0.620766]\n",
      "epoch:17 step:15992 [D loss: 0.548426, acc.: 71.88%] [G loss: 0.599784]\n",
      "epoch:17 step:15993 [D loss: 0.603116, acc.: 71.09%] [G loss: 0.495601]\n",
      "epoch:17 step:15994 [D loss: 0.478719, acc.: 73.44%] [G loss: 0.600075]\n",
      "epoch:17 step:15995 [D loss: 0.570774, acc.: 67.97%] [G loss: 0.642792]\n",
      "epoch:17 step:15996 [D loss: 0.562090, acc.: 68.75%] [G loss: 0.603280]\n",
      "epoch:17 step:15997 [D loss: 0.528606, acc.: 71.88%] [G loss: 0.650408]\n",
      "epoch:17 step:15998 [D loss: 0.493190, acc.: 74.22%] [G loss: 0.669104]\n",
      "epoch:17 step:15999 [D loss: 0.513336, acc.: 75.00%] [G loss: 0.591798]\n",
      "epoch:17 step:16000 [D loss: 0.481106, acc.: 77.34%] [G loss: 0.712965]\n",
      "##############\n",
      "[3.26282051 1.4283147  6.14389413 4.99362729 3.8156831  5.83307875\n",
      " 4.70776326 5.04063789 4.72763253 4.08307693]\n",
      "##########\n",
      "epoch:17 step:16001 [D loss: 0.541739, acc.: 70.31%] [G loss: 0.568645]\n",
      "epoch:17 step:16002 [D loss: 0.565901, acc.: 70.31%] [G loss: 0.617833]\n",
      "epoch:17 step:16003 [D loss: 0.503876, acc.: 77.34%] [G loss: 0.639387]\n",
      "epoch:17 step:16004 [D loss: 0.518777, acc.: 72.66%] [G loss: 0.586627]\n",
      "epoch:17 step:16005 [D loss: 0.553264, acc.: 71.88%] [G loss: 0.653795]\n",
      "epoch:17 step:16006 [D loss: 0.427775, acc.: 78.91%] [G loss: 0.856779]\n",
      "epoch:17 step:16007 [D loss: 0.572273, acc.: 70.31%] [G loss: 0.715046]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16008 [D loss: 0.558641, acc.: 70.31%] [G loss: 0.618690]\n",
      "epoch:17 step:16009 [D loss: 0.504203, acc.: 77.34%] [G loss: 0.804591]\n",
      "epoch:17 step:16010 [D loss: 0.563561, acc.: 68.75%] [G loss: 0.618425]\n",
      "epoch:17 step:16011 [D loss: 0.528758, acc.: 71.88%] [G loss: 0.697497]\n",
      "epoch:17 step:16012 [D loss: 0.505196, acc.: 70.31%] [G loss: 0.734500]\n",
      "epoch:17 step:16013 [D loss: 0.541580, acc.: 65.62%] [G loss: 0.728517]\n",
      "epoch:17 step:16014 [D loss: 0.552227, acc.: 68.75%] [G loss: 0.712388]\n",
      "epoch:17 step:16015 [D loss: 0.466650, acc.: 79.69%] [G loss: 0.576876]\n",
      "epoch:17 step:16016 [D loss: 0.507776, acc.: 73.44%] [G loss: 0.601012]\n",
      "epoch:17 step:16017 [D loss: 0.493040, acc.: 79.69%] [G loss: 0.619584]\n",
      "epoch:17 step:16018 [D loss: 0.484024, acc.: 75.00%] [G loss: 0.773348]\n",
      "epoch:17 step:16019 [D loss: 0.499134, acc.: 75.78%] [G loss: 0.624269]\n",
      "epoch:17 step:16020 [D loss: 0.573194, acc.: 71.09%] [G loss: 0.607461]\n",
      "epoch:17 step:16021 [D loss: 0.438257, acc.: 82.03%] [G loss: 0.708076]\n",
      "epoch:17 step:16022 [D loss: 0.515308, acc.: 75.00%] [G loss: 0.751201]\n",
      "epoch:17 step:16023 [D loss: 0.546385, acc.: 70.31%] [G loss: 0.783505]\n",
      "epoch:17 step:16024 [D loss: 0.494206, acc.: 75.78%] [G loss: 0.750013]\n",
      "epoch:17 step:16025 [D loss: 0.533635, acc.: 72.66%] [G loss: 0.658778]\n",
      "epoch:17 step:16026 [D loss: 0.461103, acc.: 78.91%] [G loss: 0.801385]\n",
      "epoch:17 step:16027 [D loss: 0.521617, acc.: 71.09%] [G loss: 0.721086]\n",
      "epoch:17 step:16028 [D loss: 0.560022, acc.: 71.88%] [G loss: 0.682607]\n",
      "epoch:17 step:16029 [D loss: 0.444646, acc.: 76.56%] [G loss: 0.715272]\n",
      "epoch:17 step:16030 [D loss: 0.500754, acc.: 71.88%] [G loss: 0.730184]\n",
      "epoch:17 step:16031 [D loss: 0.610170, acc.: 64.84%] [G loss: 0.582687]\n",
      "epoch:17 step:16032 [D loss: 0.520642, acc.: 67.19%] [G loss: 0.634743]\n",
      "epoch:17 step:16033 [D loss: 0.504233, acc.: 74.22%] [G loss: 0.696430]\n",
      "epoch:17 step:16034 [D loss: 0.580766, acc.: 71.09%] [G loss: 0.583634]\n",
      "epoch:17 step:16035 [D loss: 0.566436, acc.: 67.19%] [G loss: 0.560090]\n",
      "epoch:17 step:16036 [D loss: 0.551770, acc.: 71.09%] [G loss: 0.613511]\n",
      "epoch:17 step:16037 [D loss: 0.591416, acc.: 67.97%] [G loss: 0.677152]\n",
      "epoch:17 step:16038 [D loss: 0.561332, acc.: 65.62%] [G loss: 0.538511]\n",
      "epoch:17 step:16039 [D loss: 0.565334, acc.: 68.75%] [G loss: 0.729665]\n",
      "epoch:17 step:16040 [D loss: 0.468256, acc.: 75.00%] [G loss: 0.568451]\n",
      "epoch:17 step:16041 [D loss: 0.524794, acc.: 72.66%] [G loss: 0.660516]\n",
      "epoch:17 step:16042 [D loss: 0.515085, acc.: 77.34%] [G loss: 0.545440]\n",
      "epoch:17 step:16043 [D loss: 0.573296, acc.: 71.09%] [G loss: 0.582287]\n",
      "epoch:17 step:16044 [D loss: 0.559349, acc.: 70.31%] [G loss: 0.585322]\n",
      "epoch:17 step:16045 [D loss: 0.503147, acc.: 71.09%] [G loss: 0.679312]\n",
      "epoch:17 step:16046 [D loss: 0.500245, acc.: 75.00%] [G loss: 0.796056]\n",
      "epoch:17 step:16047 [D loss: 0.518639, acc.: 70.31%] [G loss: 0.867143]\n",
      "epoch:17 step:16048 [D loss: 0.495379, acc.: 73.44%] [G loss: 0.667362]\n",
      "epoch:17 step:16049 [D loss: 0.591728, acc.: 69.53%] [G loss: 0.779286]\n",
      "epoch:17 step:16050 [D loss: 0.495150, acc.: 77.34%] [G loss: 0.764557]\n",
      "epoch:17 step:16051 [D loss: 0.444031, acc.: 76.56%] [G loss: 0.913162]\n",
      "epoch:17 step:16052 [D loss: 0.508668, acc.: 75.78%] [G loss: 0.907969]\n",
      "epoch:17 step:16053 [D loss: 0.579064, acc.: 73.44%] [G loss: 0.823991]\n",
      "epoch:17 step:16054 [D loss: 0.559372, acc.: 67.97%] [G loss: 0.617769]\n",
      "epoch:17 step:16055 [D loss: 0.533591, acc.: 73.44%] [G loss: 0.628647]\n",
      "epoch:17 step:16056 [D loss: 0.492330, acc.: 72.66%] [G loss: 0.702636]\n",
      "epoch:17 step:16057 [D loss: 0.521258, acc.: 75.00%] [G loss: 0.624537]\n",
      "epoch:17 step:16058 [D loss: 0.572062, acc.: 74.22%] [G loss: 0.633310]\n",
      "epoch:17 step:16059 [D loss: 0.467517, acc.: 78.12%] [G loss: 0.692973]\n",
      "epoch:17 step:16060 [D loss: 0.477325, acc.: 77.34%] [G loss: 0.612973]\n",
      "epoch:17 step:16061 [D loss: 0.508273, acc.: 74.22%] [G loss: 0.679202]\n",
      "epoch:17 step:16062 [D loss: 0.534504, acc.: 67.97%] [G loss: 0.697718]\n",
      "epoch:17 step:16063 [D loss: 0.576830, acc.: 70.31%] [G loss: 0.848405]\n",
      "epoch:17 step:16064 [D loss: 0.498047, acc.: 77.34%] [G loss: 0.717683]\n",
      "epoch:17 step:16065 [D loss: 0.483584, acc.: 77.34%] [G loss: 0.731532]\n",
      "epoch:17 step:16066 [D loss: 0.674566, acc.: 62.50%] [G loss: 0.515948]\n",
      "epoch:17 step:16067 [D loss: 0.550914, acc.: 68.75%] [G loss: 0.660130]\n",
      "epoch:17 step:16068 [D loss: 0.559928, acc.: 71.88%] [G loss: 0.700010]\n",
      "epoch:17 step:16069 [D loss: 0.564338, acc.: 64.84%] [G loss: 0.667101]\n",
      "epoch:17 step:16070 [D loss: 0.516124, acc.: 73.44%] [G loss: 0.825287]\n",
      "epoch:17 step:16071 [D loss: 0.548994, acc.: 70.31%] [G loss: 0.668907]\n",
      "epoch:17 step:16072 [D loss: 0.568894, acc.: 67.97%] [G loss: 0.503970]\n",
      "epoch:17 step:16073 [D loss: 0.488289, acc.: 76.56%] [G loss: 0.615517]\n",
      "epoch:17 step:16074 [D loss: 0.548777, acc.: 68.75%] [G loss: 0.790436]\n",
      "epoch:17 step:16075 [D loss: 0.472553, acc.: 83.59%] [G loss: 0.983693]\n",
      "epoch:17 step:16076 [D loss: 0.622126, acc.: 70.31%] [G loss: 0.736813]\n",
      "epoch:17 step:16077 [D loss: 0.559862, acc.: 64.06%] [G loss: 0.664423]\n",
      "epoch:17 step:16078 [D loss: 0.513052, acc.: 76.56%] [G loss: 0.653865]\n",
      "epoch:17 step:16079 [D loss: 0.618530, acc.: 61.72%] [G loss: 0.600738]\n",
      "epoch:17 step:16080 [D loss: 0.598174, acc.: 66.41%] [G loss: 0.614430]\n",
      "epoch:17 step:16081 [D loss: 0.459195, acc.: 75.00%] [G loss: 0.769114]\n",
      "epoch:17 step:16082 [D loss: 0.607934, acc.: 64.84%] [G loss: 0.561265]\n",
      "epoch:17 step:16083 [D loss: 0.537810, acc.: 75.00%] [G loss: 0.815400]\n",
      "epoch:17 step:16084 [D loss: 0.437915, acc.: 80.47%] [G loss: 0.693411]\n",
      "epoch:17 step:16085 [D loss: 0.472789, acc.: 78.12%] [G loss: 0.713557]\n",
      "epoch:17 step:16086 [D loss: 0.512478, acc.: 71.88%] [G loss: 0.644483]\n",
      "epoch:17 step:16087 [D loss: 0.570932, acc.: 68.75%] [G loss: 0.610062]\n",
      "epoch:17 step:16088 [D loss: 0.482524, acc.: 75.00%] [G loss: 0.597274]\n",
      "epoch:17 step:16089 [D loss: 0.663873, acc.: 64.84%] [G loss: 0.641584]\n",
      "epoch:17 step:16090 [D loss: 0.562813, acc.: 69.53%] [G loss: 0.796840]\n",
      "epoch:17 step:16091 [D loss: 0.480439, acc.: 74.22%] [G loss: 0.825117]\n",
      "epoch:17 step:16092 [D loss: 0.546473, acc.: 69.53%] [G loss: 0.579240]\n",
      "epoch:17 step:16093 [D loss: 0.525537, acc.: 71.88%] [G loss: 0.640979]\n",
      "epoch:17 step:16094 [D loss: 0.478163, acc.: 74.22%] [G loss: 0.600213]\n",
      "epoch:17 step:16095 [D loss: 0.532303, acc.: 70.31%] [G loss: 0.613076]\n",
      "epoch:17 step:16096 [D loss: 0.537414, acc.: 72.66%] [G loss: 0.617429]\n",
      "epoch:17 step:16097 [D loss: 0.512721, acc.: 73.44%] [G loss: 0.577006]\n",
      "epoch:17 step:16098 [D loss: 0.592246, acc.: 66.41%] [G loss: 0.457322]\n",
      "epoch:17 step:16099 [D loss: 0.539587, acc.: 73.44%] [G loss: 0.611045]\n",
      "epoch:17 step:16100 [D loss: 0.537037, acc.: 74.22%] [G loss: 0.485529]\n",
      "epoch:17 step:16101 [D loss: 0.514936, acc.: 72.66%] [G loss: 0.519692]\n",
      "epoch:17 step:16102 [D loss: 0.465077, acc.: 73.44%] [G loss: 0.552050]\n",
      "epoch:17 step:16103 [D loss: 0.574931, acc.: 69.53%] [G loss: 0.644053]\n",
      "epoch:17 step:16104 [D loss: 0.552715, acc.: 71.88%] [G loss: 0.554806]\n",
      "epoch:17 step:16105 [D loss: 0.543826, acc.: 69.53%] [G loss: 0.442908]\n",
      "epoch:17 step:16106 [D loss: 0.553043, acc.: 65.62%] [G loss: 0.693727]\n",
      "epoch:17 step:16107 [D loss: 0.559377, acc.: 64.84%] [G loss: 0.652678]\n",
      "epoch:17 step:16108 [D loss: 0.540395, acc.: 69.53%] [G loss: 0.628681]\n",
      "epoch:17 step:16109 [D loss: 0.621473, acc.: 64.84%] [G loss: 0.529986]\n",
      "epoch:17 step:16110 [D loss: 0.552401, acc.: 67.19%] [G loss: 0.495658]\n",
      "epoch:17 step:16111 [D loss: 0.592720, acc.: 67.97%] [G loss: 0.634041]\n",
      "epoch:17 step:16112 [D loss: 0.580433, acc.: 68.75%] [G loss: 0.576980]\n",
      "epoch:17 step:16113 [D loss: 0.497297, acc.: 76.56%] [G loss: 0.689543]\n",
      "epoch:17 step:16114 [D loss: 0.536219, acc.: 68.75%] [G loss: 0.587773]\n",
      "epoch:17 step:16115 [D loss: 0.534323, acc.: 75.00%] [G loss: 0.627936]\n",
      "epoch:17 step:16116 [D loss: 0.618897, acc.: 65.62%] [G loss: 0.521870]\n",
      "epoch:17 step:16117 [D loss: 0.568344, acc.: 67.19%] [G loss: 0.568797]\n",
      "epoch:17 step:16118 [D loss: 0.569606, acc.: 69.53%] [G loss: 0.517621]\n",
      "epoch:17 step:16119 [D loss: 0.511278, acc.: 71.09%] [G loss: 0.571820]\n",
      "epoch:17 step:16120 [D loss: 0.493095, acc.: 75.00%] [G loss: 0.548829]\n",
      "epoch:17 step:16121 [D loss: 0.542171, acc.: 71.88%] [G loss: 0.617666]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16122 [D loss: 0.521854, acc.: 71.88%] [G loss: 0.596246]\n",
      "epoch:17 step:16123 [D loss: 0.458924, acc.: 76.56%] [G loss: 0.563906]\n",
      "epoch:17 step:16124 [D loss: 0.535624, acc.: 71.88%] [G loss: 0.645444]\n",
      "epoch:17 step:16125 [D loss: 0.523094, acc.: 73.44%] [G loss: 0.697694]\n",
      "epoch:17 step:16126 [D loss: 0.519773, acc.: 75.78%] [G loss: 0.732321]\n",
      "epoch:17 step:16127 [D loss: 0.480651, acc.: 78.91%] [G loss: 0.723635]\n",
      "epoch:17 step:16128 [D loss: 0.497058, acc.: 71.09%] [G loss: 0.735162]\n",
      "epoch:17 step:16129 [D loss: 0.652411, acc.: 58.59%] [G loss: 0.426296]\n",
      "epoch:17 step:16130 [D loss: 0.526330, acc.: 69.53%] [G loss: 0.748636]\n",
      "epoch:17 step:16131 [D loss: 0.508051, acc.: 74.22%] [G loss: 0.666690]\n",
      "epoch:17 step:16132 [D loss: 0.668920, acc.: 58.59%] [G loss: 0.460825]\n",
      "epoch:17 step:16133 [D loss: 0.555726, acc.: 72.66%] [G loss: 0.785819]\n",
      "epoch:17 step:16134 [D loss: 0.478968, acc.: 82.03%] [G loss: 0.654847]\n",
      "epoch:17 step:16135 [D loss: 0.512755, acc.: 71.88%] [G loss: 0.852166]\n",
      "epoch:17 step:16136 [D loss: 0.504742, acc.: 75.78%] [G loss: 0.849881]\n",
      "epoch:17 step:16137 [D loss: 0.450110, acc.: 77.34%] [G loss: 0.813345]\n",
      "epoch:17 step:16138 [D loss: 0.542574, acc.: 72.66%] [G loss: 0.671329]\n",
      "epoch:17 step:16139 [D loss: 0.578914, acc.: 69.53%] [G loss: 0.655399]\n",
      "epoch:17 step:16140 [D loss: 0.576808, acc.: 64.84%] [G loss: 0.511570]\n",
      "epoch:17 step:16141 [D loss: 0.527103, acc.: 76.56%] [G loss: 0.592299]\n",
      "epoch:17 step:16142 [D loss: 0.511153, acc.: 67.97%] [G loss: 0.642325]\n",
      "epoch:17 step:16143 [D loss: 0.622579, acc.: 66.41%] [G loss: 0.572269]\n",
      "epoch:17 step:16144 [D loss: 0.589576, acc.: 60.94%] [G loss: 0.590643]\n",
      "epoch:17 step:16145 [D loss: 0.535402, acc.: 71.09%] [G loss: 0.575101]\n",
      "epoch:17 step:16146 [D loss: 0.525137, acc.: 72.66%] [G loss: 0.684004]\n",
      "epoch:17 step:16147 [D loss: 0.534887, acc.: 75.00%] [G loss: 0.582613]\n",
      "epoch:17 step:16148 [D loss: 0.545462, acc.: 71.09%] [G loss: 0.690558]\n",
      "epoch:17 step:16149 [D loss: 0.610651, acc.: 67.97%] [G loss: 0.751693]\n",
      "epoch:17 step:16150 [D loss: 0.550004, acc.: 67.19%] [G loss: 0.580609]\n",
      "epoch:17 step:16151 [D loss: 0.495275, acc.: 75.78%] [G loss: 0.773989]\n",
      "epoch:17 step:16152 [D loss: 0.523746, acc.: 75.78%] [G loss: 0.785088]\n",
      "epoch:17 step:16153 [D loss: 0.554547, acc.: 71.09%] [G loss: 0.617005]\n",
      "epoch:17 step:16154 [D loss: 0.551226, acc.: 66.41%] [G loss: 0.584225]\n",
      "epoch:17 step:16155 [D loss: 0.578050, acc.: 64.06%] [G loss: 0.705627]\n",
      "epoch:17 step:16156 [D loss: 0.539505, acc.: 71.88%] [G loss: 0.485171]\n",
      "epoch:17 step:16157 [D loss: 0.622167, acc.: 62.50%] [G loss: 0.513103]\n",
      "epoch:17 step:16158 [D loss: 0.486909, acc.: 79.69%] [G loss: 0.509974]\n",
      "epoch:17 step:16159 [D loss: 0.507247, acc.: 73.44%] [G loss: 0.708977]\n",
      "epoch:17 step:16160 [D loss: 0.511608, acc.: 74.22%] [G loss: 0.678724]\n",
      "epoch:17 step:16161 [D loss: 0.532961, acc.: 74.22%] [G loss: 0.850427]\n",
      "epoch:17 step:16162 [D loss: 0.547674, acc.: 75.00%] [G loss: 0.778488]\n",
      "epoch:17 step:16163 [D loss: 0.586425, acc.: 70.31%] [G loss: 0.672356]\n",
      "epoch:17 step:16164 [D loss: 0.594883, acc.: 62.50%] [G loss: 0.671408]\n",
      "epoch:17 step:16165 [D loss: 0.505807, acc.: 76.56%] [G loss: 0.602782]\n",
      "epoch:17 step:16166 [D loss: 0.537591, acc.: 70.31%] [G loss: 0.660360]\n",
      "epoch:17 step:16167 [D loss: 0.565868, acc.: 69.53%] [G loss: 0.565774]\n",
      "epoch:17 step:16168 [D loss: 0.541844, acc.: 69.53%] [G loss: 0.565630]\n",
      "epoch:17 step:16169 [D loss: 0.520014, acc.: 76.56%] [G loss: 0.755605]\n",
      "epoch:17 step:16170 [D loss: 0.500313, acc.: 73.44%] [G loss: 0.810954]\n",
      "epoch:17 step:16171 [D loss: 0.508445, acc.: 73.44%] [G loss: 0.712471]\n",
      "epoch:17 step:16172 [D loss: 0.536199, acc.: 65.62%] [G loss: 0.692658]\n",
      "epoch:17 step:16173 [D loss: 0.466358, acc.: 75.78%] [G loss: 0.734436]\n",
      "epoch:17 step:16174 [D loss: 0.513042, acc.: 75.78%] [G loss: 0.701876]\n",
      "epoch:17 step:16175 [D loss: 0.503982, acc.: 70.31%] [G loss: 0.756418]\n",
      "epoch:17 step:16176 [D loss: 0.573869, acc.: 65.62%] [G loss: 0.693521]\n",
      "epoch:17 step:16177 [D loss: 0.508285, acc.: 75.00%] [G loss: 0.714674]\n",
      "epoch:17 step:16178 [D loss: 0.568001, acc.: 75.78%] [G loss: 0.636057]\n",
      "epoch:17 step:16179 [D loss: 0.623969, acc.: 67.19%] [G loss: 0.703876]\n",
      "epoch:17 step:16180 [D loss: 0.567079, acc.: 71.09%] [G loss: 0.706328]\n",
      "epoch:17 step:16181 [D loss: 0.583351, acc.: 68.75%] [G loss: 0.663051]\n",
      "epoch:17 step:16182 [D loss: 0.599214, acc.: 62.50%] [G loss: 0.584429]\n",
      "epoch:17 step:16183 [D loss: 0.508762, acc.: 72.66%] [G loss: 0.626160]\n",
      "epoch:17 step:16184 [D loss: 0.553229, acc.: 67.97%] [G loss: 0.595435]\n",
      "epoch:17 step:16185 [D loss: 0.533298, acc.: 69.53%] [G loss: 0.620772]\n",
      "epoch:17 step:16186 [D loss: 0.554131, acc.: 65.62%] [G loss: 0.724393]\n",
      "epoch:17 step:16187 [D loss: 0.530246, acc.: 69.53%] [G loss: 0.724758]\n",
      "epoch:17 step:16188 [D loss: 0.578309, acc.: 66.41%] [G loss: 0.522744]\n",
      "epoch:17 step:16189 [D loss: 0.587659, acc.: 66.41%] [G loss: 0.563615]\n",
      "epoch:17 step:16190 [D loss: 0.541297, acc.: 68.75%] [G loss: 0.564260]\n",
      "epoch:17 step:16191 [D loss: 0.554527, acc.: 68.75%] [G loss: 0.682571]\n",
      "epoch:17 step:16192 [D loss: 0.589362, acc.: 68.75%] [G loss: 0.625793]\n",
      "epoch:17 step:16193 [D loss: 0.556065, acc.: 67.97%] [G loss: 0.688552]\n",
      "epoch:17 step:16194 [D loss: 0.578287, acc.: 67.97%] [G loss: 0.727223]\n",
      "epoch:17 step:16195 [D loss: 0.535405, acc.: 71.09%] [G loss: 0.670066]\n",
      "epoch:17 step:16196 [D loss: 0.589690, acc.: 69.53%] [G loss: 0.446881]\n",
      "epoch:17 step:16197 [D loss: 0.506810, acc.: 74.22%] [G loss: 0.667141]\n",
      "epoch:17 step:16198 [D loss: 0.502142, acc.: 76.56%] [G loss: 0.605622]\n",
      "epoch:17 step:16199 [D loss: 0.476887, acc.: 75.78%] [G loss: 0.628374]\n",
      "epoch:17 step:16200 [D loss: 0.493886, acc.: 75.78%] [G loss: 0.601402]\n",
      "##############\n",
      "[3.06972201 1.00677085 6.25850404 5.02806183 3.59953047 5.88005476\n",
      " 4.2277581  4.80066868 4.81636665 3.99602044]\n",
      "##########\n",
      "epoch:17 step:16201 [D loss: 0.508218, acc.: 74.22%] [G loss: 0.642514]\n",
      "epoch:17 step:16202 [D loss: 0.495344, acc.: 75.00%] [G loss: 0.740444]\n",
      "epoch:17 step:16203 [D loss: 0.531895, acc.: 73.44%] [G loss: 0.665871]\n",
      "epoch:17 step:16204 [D loss: 0.577195, acc.: 67.97%] [G loss: 0.619485]\n",
      "epoch:17 step:16205 [D loss: 0.469849, acc.: 76.56%] [G loss: 0.813503]\n",
      "epoch:17 step:16206 [D loss: 0.656941, acc.: 63.28%] [G loss: 0.521682]\n",
      "epoch:17 step:16207 [D loss: 0.562012, acc.: 68.75%] [G loss: 0.558289]\n",
      "epoch:17 step:16208 [D loss: 0.564433, acc.: 65.62%] [G loss: 0.613637]\n",
      "epoch:17 step:16209 [D loss: 0.473268, acc.: 81.25%] [G loss: 0.753943]\n",
      "epoch:17 step:16210 [D loss: 0.569644, acc.: 72.66%] [G loss: 0.567840]\n",
      "epoch:17 step:16211 [D loss: 0.601139, acc.: 63.28%] [G loss: 0.534989]\n",
      "epoch:17 step:16212 [D loss: 0.505323, acc.: 75.78%] [G loss: 0.676589]\n",
      "epoch:17 step:16213 [D loss: 0.510439, acc.: 74.22%] [G loss: 0.810453]\n",
      "epoch:17 step:16214 [D loss: 0.502290, acc.: 67.97%] [G loss: 0.677943]\n",
      "epoch:17 step:16215 [D loss: 0.506086, acc.: 73.44%] [G loss: 0.704826]\n",
      "epoch:17 step:16216 [D loss: 0.598857, acc.: 67.19%] [G loss: 0.616058]\n",
      "epoch:17 step:16217 [D loss: 0.582093, acc.: 68.75%] [G loss: 0.543712]\n",
      "epoch:17 step:16218 [D loss: 0.544433, acc.: 67.97%] [G loss: 0.617742]\n",
      "epoch:17 step:16219 [D loss: 0.553004, acc.: 71.88%] [G loss: 0.640192]\n",
      "epoch:17 step:16220 [D loss: 0.582291, acc.: 72.66%] [G loss: 0.479642]\n",
      "epoch:17 step:16221 [D loss: 0.523903, acc.: 70.31%] [G loss: 0.597157]\n",
      "epoch:17 step:16222 [D loss: 0.580484, acc.: 66.41%] [G loss: 0.616247]\n",
      "epoch:17 step:16223 [D loss: 0.618897, acc.: 59.38%] [G loss: 0.503211]\n",
      "epoch:17 step:16224 [D loss: 0.633972, acc.: 59.38%] [G loss: 0.486551]\n",
      "epoch:17 step:16225 [D loss: 0.458103, acc.: 79.69%] [G loss: 0.498501]\n",
      "epoch:17 step:16226 [D loss: 0.548857, acc.: 73.44%] [G loss: 0.526618]\n",
      "epoch:17 step:16227 [D loss: 0.544942, acc.: 72.66%] [G loss: 0.606577]\n",
      "epoch:17 step:16228 [D loss: 0.486665, acc.: 75.78%] [G loss: 0.800265]\n",
      "epoch:17 step:16229 [D loss: 0.524066, acc.: 69.53%] [G loss: 0.811103]\n",
      "epoch:17 step:16230 [D loss: 0.586887, acc.: 70.31%] [G loss: 0.705210]\n",
      "epoch:17 step:16231 [D loss: 0.549311, acc.: 69.53%] [G loss: 0.746319]\n",
      "epoch:17 step:16232 [D loss: 0.561449, acc.: 72.66%] [G loss: 0.635447]\n",
      "epoch:17 step:16233 [D loss: 0.481874, acc.: 78.12%] [G loss: 0.629852]\n",
      "epoch:17 step:16234 [D loss: 0.477055, acc.: 78.91%] [G loss: 0.705122]\n",
      "epoch:17 step:16235 [D loss: 0.527271, acc.: 72.66%] [G loss: 0.595726]\n",
      "epoch:17 step:16236 [D loss: 0.522229, acc.: 75.78%] [G loss: 0.804650]\n",
      "epoch:17 step:16237 [D loss: 0.542805, acc.: 75.00%] [G loss: 0.577241]\n",
      "epoch:17 step:16238 [D loss: 0.488436, acc.: 71.09%] [G loss: 0.725221]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16239 [D loss: 0.540046, acc.: 75.78%] [G loss: 0.717584]\n",
      "epoch:17 step:16240 [D loss: 0.476548, acc.: 77.34%] [G loss: 0.785163]\n",
      "epoch:17 step:16241 [D loss: 0.540670, acc.: 71.09%] [G loss: 0.789924]\n",
      "epoch:17 step:16242 [D loss: 0.499594, acc.: 74.22%] [G loss: 0.778385]\n",
      "epoch:17 step:16243 [D loss: 0.452352, acc.: 82.03%] [G loss: 0.925675]\n",
      "epoch:17 step:16244 [D loss: 0.487850, acc.: 78.12%] [G loss: 1.080764]\n",
      "epoch:17 step:16245 [D loss: 0.686006, acc.: 64.84%] [G loss: 0.635505]\n",
      "epoch:17 step:16246 [D loss: 0.616685, acc.: 65.62%] [G loss: 0.554406]\n",
      "epoch:17 step:16247 [D loss: 0.587403, acc.: 67.19%] [G loss: 0.730377]\n",
      "epoch:17 step:16248 [D loss: 0.560043, acc.: 69.53%] [G loss: 0.511855]\n",
      "epoch:17 step:16249 [D loss: 0.520595, acc.: 67.19%] [G loss: 0.614111]\n",
      "epoch:17 step:16250 [D loss: 0.505969, acc.: 73.44%] [G loss: 0.822438]\n",
      "epoch:17 step:16251 [D loss: 0.560098, acc.: 70.31%] [G loss: 0.750803]\n",
      "epoch:17 step:16252 [D loss: 0.570891, acc.: 72.66%] [G loss: 0.571369]\n",
      "epoch:17 step:16253 [D loss: 0.594526, acc.: 67.19%] [G loss: 0.714593]\n",
      "epoch:17 step:16254 [D loss: 0.555559, acc.: 65.62%] [G loss: 0.595344]\n",
      "epoch:17 step:16255 [D loss: 0.433561, acc.: 76.56%] [G loss: 0.632694]\n",
      "epoch:17 step:16256 [D loss: 0.463611, acc.: 78.91%] [G loss: 0.679576]\n",
      "epoch:17 step:16257 [D loss: 0.505518, acc.: 71.88%] [G loss: 0.726023]\n",
      "epoch:17 step:16258 [D loss: 0.446123, acc.: 77.34%] [G loss: 0.814933]\n",
      "epoch:17 step:16259 [D loss: 0.556079, acc.: 71.09%] [G loss: 0.597819]\n",
      "epoch:17 step:16260 [D loss: 0.535891, acc.: 68.75%] [G loss: 0.534494]\n",
      "epoch:17 step:16261 [D loss: 0.500220, acc.: 75.78%] [G loss: 0.554229]\n",
      "epoch:17 step:16262 [D loss: 0.524027, acc.: 71.88%] [G loss: 0.711250]\n",
      "epoch:17 step:16263 [D loss: 0.507165, acc.: 71.88%] [G loss: 0.723585]\n",
      "epoch:17 step:16264 [D loss: 0.477728, acc.: 76.56%] [G loss: 0.785008]\n",
      "epoch:17 step:16265 [D loss: 0.519703, acc.: 72.66%] [G loss: 0.701978]\n",
      "epoch:17 step:16266 [D loss: 0.516031, acc.: 75.78%] [G loss: 0.835042]\n",
      "epoch:17 step:16267 [D loss: 0.493771, acc.: 70.31%] [G loss: 0.632199]\n",
      "epoch:17 step:16268 [D loss: 0.540689, acc.: 67.97%] [G loss: 0.826757]\n",
      "epoch:17 step:16269 [D loss: 0.530681, acc.: 71.88%] [G loss: 0.856306]\n",
      "epoch:17 step:16270 [D loss: 0.535696, acc.: 76.56%] [G loss: 0.710278]\n",
      "epoch:17 step:16271 [D loss: 0.643871, acc.: 63.28%] [G loss: 0.530181]\n",
      "epoch:17 step:16272 [D loss: 0.536983, acc.: 73.44%] [G loss: 0.677068]\n",
      "epoch:17 step:16273 [D loss: 0.473632, acc.: 75.00%] [G loss: 0.963959]\n",
      "epoch:17 step:16274 [D loss: 0.628229, acc.: 60.94%] [G loss: 0.656177]\n",
      "epoch:17 step:16275 [D loss: 0.571851, acc.: 66.41%] [G loss: 0.698280]\n",
      "epoch:17 step:16276 [D loss: 0.450590, acc.: 79.69%] [G loss: 0.905779]\n",
      "epoch:17 step:16277 [D loss: 0.673780, acc.: 64.06%] [G loss: 0.850130]\n",
      "epoch:17 step:16278 [D loss: 0.711647, acc.: 58.59%] [G loss: 0.582276]\n",
      "epoch:17 step:16279 [D loss: 0.473053, acc.: 79.69%] [G loss: 0.638605]\n",
      "epoch:17 step:16280 [D loss: 0.508809, acc.: 75.78%] [G loss: 0.695326]\n",
      "epoch:17 step:16281 [D loss: 0.611412, acc.: 61.72%] [G loss: 0.626866]\n",
      "epoch:17 step:16282 [D loss: 0.560376, acc.: 70.31%] [G loss: 0.846296]\n",
      "epoch:17 step:16283 [D loss: 0.379400, acc.: 82.03%] [G loss: 0.893485]\n",
      "epoch:17 step:16284 [D loss: 0.557259, acc.: 70.31%] [G loss: 0.753114]\n",
      "epoch:17 step:16285 [D loss: 0.573232, acc.: 69.53%] [G loss: 0.919178]\n",
      "epoch:17 step:16286 [D loss: 0.454830, acc.: 78.91%] [G loss: 0.769029]\n",
      "epoch:17 step:16287 [D loss: 0.441439, acc.: 80.47%] [G loss: 0.776396]\n",
      "epoch:17 step:16288 [D loss: 0.454807, acc.: 78.12%] [G loss: 0.796782]\n",
      "epoch:17 step:16289 [D loss: 0.498997, acc.: 75.78%] [G loss: 0.772693]\n",
      "epoch:17 step:16290 [D loss: 0.487399, acc.: 77.34%] [G loss: 0.727709]\n",
      "epoch:17 step:16291 [D loss: 0.513499, acc.: 74.22%] [G loss: 0.857746]\n",
      "epoch:17 step:16292 [D loss: 0.554056, acc.: 70.31%] [G loss: 0.611829]\n",
      "epoch:17 step:16293 [D loss: 0.537092, acc.: 70.31%] [G loss: 0.610268]\n",
      "epoch:17 step:16294 [D loss: 0.528024, acc.: 72.66%] [G loss: 0.769949]\n",
      "epoch:17 step:16295 [D loss: 0.556807, acc.: 67.19%] [G loss: 0.632471]\n",
      "epoch:17 step:16296 [D loss: 0.584668, acc.: 70.31%] [G loss: 0.738862]\n",
      "epoch:17 step:16297 [D loss: 0.544703, acc.: 71.09%] [G loss: 0.582743]\n",
      "epoch:17 step:16298 [D loss: 0.540376, acc.: 69.53%] [G loss: 0.524701]\n",
      "epoch:17 step:16299 [D loss: 0.540238, acc.: 71.88%] [G loss: 0.556180]\n",
      "epoch:17 step:16300 [D loss: 0.549020, acc.: 72.66%] [G loss: 0.657864]\n",
      "epoch:17 step:16301 [D loss: 0.562588, acc.: 70.31%] [G loss: 0.786982]\n",
      "epoch:17 step:16302 [D loss: 0.520938, acc.: 78.12%] [G loss: 0.648024]\n",
      "epoch:17 step:16303 [D loss: 0.460931, acc.: 74.22%] [G loss: 0.751872]\n",
      "epoch:17 step:16304 [D loss: 0.595532, acc.: 64.06%] [G loss: 0.697698]\n",
      "epoch:17 step:16305 [D loss: 0.691403, acc.: 64.84%] [G loss: 0.517660]\n",
      "epoch:17 step:16306 [D loss: 0.575453, acc.: 68.75%] [G loss: 0.483057]\n",
      "epoch:17 step:16307 [D loss: 0.492330, acc.: 76.56%] [G loss: 0.617256]\n",
      "epoch:17 step:16308 [D loss: 0.593660, acc.: 68.75%] [G loss: 0.644025]\n",
      "epoch:17 step:16309 [D loss: 0.546880, acc.: 67.97%] [G loss: 0.610163]\n",
      "epoch:17 step:16310 [D loss: 0.433165, acc.: 84.38%] [G loss: 0.563709]\n",
      "epoch:17 step:16311 [D loss: 0.554271, acc.: 69.53%] [G loss: 0.695241]\n",
      "epoch:17 step:16312 [D loss: 0.497630, acc.: 76.56%] [G loss: 0.638671]\n",
      "epoch:17 step:16313 [D loss: 0.560277, acc.: 66.41%] [G loss: 0.585416]\n",
      "epoch:17 step:16314 [D loss: 0.512610, acc.: 71.09%] [G loss: 0.570258]\n",
      "epoch:17 step:16315 [D loss: 0.587483, acc.: 65.62%] [G loss: 0.650501]\n",
      "epoch:17 step:16316 [D loss: 0.567569, acc.: 71.88%] [G loss: 0.541145]\n",
      "epoch:17 step:16317 [D loss: 0.529851, acc.: 70.31%] [G loss: 0.591259]\n",
      "epoch:17 step:16318 [D loss: 0.495192, acc.: 75.00%] [G loss: 0.768625]\n",
      "epoch:17 step:16319 [D loss: 0.592097, acc.: 67.97%] [G loss: 0.743017]\n",
      "epoch:17 step:16320 [D loss: 0.543633, acc.: 71.88%] [G loss: 0.691972]\n",
      "epoch:17 step:16321 [D loss: 0.502890, acc.: 74.22%] [G loss: 0.819276]\n",
      "epoch:17 step:16322 [D loss: 0.563653, acc.: 69.53%] [G loss: 0.735785]\n",
      "epoch:17 step:16323 [D loss: 0.609657, acc.: 62.50%] [G loss: 0.507558]\n",
      "epoch:17 step:16324 [D loss: 0.533026, acc.: 71.09%] [G loss: 0.638757]\n",
      "epoch:17 step:16325 [D loss: 0.572213, acc.: 64.84%] [G loss: 0.553702]\n",
      "epoch:17 step:16326 [D loss: 0.587075, acc.: 64.06%] [G loss: 0.578379]\n",
      "epoch:17 step:16327 [D loss: 0.483669, acc.: 77.34%] [G loss: 0.692968]\n",
      "epoch:17 step:16328 [D loss: 0.474955, acc.: 80.47%] [G loss: 0.697679]\n",
      "epoch:17 step:16329 [D loss: 0.622379, acc.: 64.84%] [G loss: 0.585882]\n",
      "epoch:17 step:16330 [D loss: 0.658589, acc.: 63.28%] [G loss: 0.502935]\n",
      "epoch:17 step:16331 [D loss: 0.528787, acc.: 69.53%] [G loss: 0.565586]\n",
      "epoch:17 step:16332 [D loss: 0.481410, acc.: 79.69%] [G loss: 0.709397]\n",
      "epoch:17 step:16333 [D loss: 0.608292, acc.: 64.84%] [G loss: 0.703964]\n",
      "epoch:17 step:16334 [D loss: 0.525462, acc.: 68.75%] [G loss: 0.519789]\n",
      "epoch:17 step:16335 [D loss: 0.497549, acc.: 74.22%] [G loss: 0.723564]\n",
      "epoch:17 step:16336 [D loss: 0.515664, acc.: 69.53%] [G loss: 0.841929]\n",
      "epoch:17 step:16337 [D loss: 0.590312, acc.: 68.75%] [G loss: 0.865767]\n",
      "epoch:17 step:16338 [D loss: 0.577262, acc.: 67.19%] [G loss: 0.739154]\n",
      "epoch:17 step:16339 [D loss: 0.625159, acc.: 63.28%] [G loss: 0.756897]\n",
      "epoch:17 step:16340 [D loss: 0.588617, acc.: 64.84%] [G loss: 0.696101]\n",
      "epoch:17 step:16341 [D loss: 0.605748, acc.: 64.84%] [G loss: 0.558874]\n",
      "epoch:17 step:16342 [D loss: 0.492108, acc.: 75.78%] [G loss: 0.507565]\n",
      "epoch:17 step:16343 [D loss: 0.567976, acc.: 65.62%] [G loss: 0.533050]\n",
      "epoch:17 step:16344 [D loss: 0.520198, acc.: 72.66%] [G loss: 0.703383]\n",
      "epoch:17 step:16345 [D loss: 0.454057, acc.: 82.03%] [G loss: 0.674825]\n",
      "epoch:17 step:16346 [D loss: 0.602766, acc.: 70.31%] [G loss: 0.632795]\n",
      "epoch:17 step:16347 [D loss: 0.623101, acc.: 64.06%] [G loss: 0.587210]\n",
      "epoch:17 step:16348 [D loss: 0.605211, acc.: 64.84%] [G loss: 0.545216]\n",
      "epoch:17 step:16349 [D loss: 0.600684, acc.: 60.16%] [G loss: 0.808891]\n",
      "epoch:17 step:16350 [D loss: 0.582426, acc.: 69.53%] [G loss: 0.624700]\n",
      "epoch:17 step:16351 [D loss: 0.554531, acc.: 75.00%] [G loss: 0.568825]\n",
      "epoch:17 step:16352 [D loss: 0.555110, acc.: 68.75%] [G loss: 0.444221]\n",
      "epoch:17 step:16353 [D loss: 0.556070, acc.: 69.53%] [G loss: 0.665781]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16354 [D loss: 0.525548, acc.: 71.88%] [G loss: 0.623181]\n",
      "epoch:17 step:16355 [D loss: 0.470012, acc.: 74.22%] [G loss: 0.688186]\n",
      "epoch:17 step:16356 [D loss: 0.438990, acc.: 79.69%] [G loss: 0.671224]\n",
      "epoch:17 step:16357 [D loss: 0.492112, acc.: 70.31%] [G loss: 0.721466]\n",
      "epoch:17 step:16358 [D loss: 0.549525, acc.: 71.09%] [G loss: 0.680132]\n",
      "epoch:17 step:16359 [D loss: 0.539721, acc.: 73.44%] [G loss: 0.758651]\n",
      "epoch:17 step:16360 [D loss: 0.546612, acc.: 67.19%] [G loss: 0.671526]\n",
      "epoch:17 step:16361 [D loss: 0.574667, acc.: 71.09%] [G loss: 0.666907]\n",
      "epoch:17 step:16362 [D loss: 0.587887, acc.: 66.41%] [G loss: 0.641357]\n",
      "epoch:17 step:16363 [D loss: 0.535443, acc.: 67.19%] [G loss: 0.632293]\n",
      "epoch:17 step:16364 [D loss: 0.584745, acc.: 71.88%] [G loss: 0.723221]\n",
      "epoch:17 step:16365 [D loss: 0.470716, acc.: 77.34%] [G loss: 0.728124]\n",
      "epoch:17 step:16366 [D loss: 0.708701, acc.: 59.38%] [G loss: 0.615502]\n",
      "epoch:17 step:16367 [D loss: 0.567088, acc.: 68.75%] [G loss: 0.541483]\n",
      "epoch:17 step:16368 [D loss: 0.480078, acc.: 78.12%] [G loss: 0.662502]\n",
      "epoch:17 step:16369 [D loss: 0.516104, acc.: 71.09%] [G loss: 0.698238]\n",
      "epoch:17 step:16370 [D loss: 0.536216, acc.: 69.53%] [G loss: 0.551370]\n",
      "epoch:17 step:16371 [D loss: 0.519020, acc.: 75.00%] [G loss: 0.680937]\n",
      "epoch:17 step:16372 [D loss: 0.538928, acc.: 69.53%] [G loss: 0.682557]\n",
      "epoch:17 step:16373 [D loss: 0.549927, acc.: 70.31%] [G loss: 0.680410]\n",
      "epoch:17 step:16374 [D loss: 0.584780, acc.: 65.62%] [G loss: 0.608408]\n",
      "epoch:17 step:16375 [D loss: 0.523964, acc.: 69.53%] [G loss: 0.674744]\n",
      "epoch:17 step:16376 [D loss: 0.551432, acc.: 66.41%] [G loss: 0.590213]\n",
      "epoch:17 step:16377 [D loss: 0.562612, acc.: 67.19%] [G loss: 0.690786]\n",
      "epoch:17 step:16378 [D loss: 0.513581, acc.: 73.44%] [G loss: 0.577608]\n",
      "epoch:17 step:16379 [D loss: 0.520992, acc.: 75.00%] [G loss: 0.757965]\n",
      "epoch:17 step:16380 [D loss: 0.406964, acc.: 82.03%] [G loss: 0.818670]\n",
      "epoch:17 step:16381 [D loss: 0.462203, acc.: 74.22%] [G loss: 0.906733]\n",
      "epoch:17 step:16382 [D loss: 0.560204, acc.: 68.75%] [G loss: 0.676442]\n",
      "epoch:17 step:16383 [D loss: 0.551612, acc.: 69.53%] [G loss: 0.662672]\n",
      "epoch:17 step:16384 [D loss: 0.526303, acc.: 71.09%] [G loss: 0.563581]\n",
      "epoch:17 step:16385 [D loss: 0.568937, acc.: 65.62%] [G loss: 0.589349]\n",
      "epoch:17 step:16386 [D loss: 0.551815, acc.: 73.44%] [G loss: 0.730573]\n",
      "epoch:17 step:16387 [D loss: 0.599000, acc.: 67.19%] [G loss: 0.538347]\n",
      "epoch:17 step:16388 [D loss: 0.563640, acc.: 71.88%] [G loss: 0.516426]\n",
      "epoch:17 step:16389 [D loss: 0.486640, acc.: 76.56%] [G loss: 0.763644]\n",
      "epoch:17 step:16390 [D loss: 0.518802, acc.: 71.09%] [G loss: 0.637943]\n",
      "epoch:17 step:16391 [D loss: 0.518758, acc.: 71.09%] [G loss: 0.604945]\n",
      "epoch:17 step:16392 [D loss: 0.517470, acc.: 69.53%] [G loss: 0.506410]\n",
      "epoch:17 step:16393 [D loss: 0.508177, acc.: 75.78%] [G loss: 0.538321]\n",
      "epoch:17 step:16394 [D loss: 0.593964, acc.: 67.97%] [G loss: 0.565889]\n",
      "epoch:17 step:16395 [D loss: 0.550262, acc.: 67.19%] [G loss: 0.711958]\n",
      "epoch:17 step:16396 [D loss: 0.562115, acc.: 65.62%] [G loss: 0.596157]\n",
      "epoch:17 step:16397 [D loss: 0.537560, acc.: 71.88%] [G loss: 0.744407]\n",
      "epoch:17 step:16398 [D loss: 0.554597, acc.: 71.09%] [G loss: 0.706656]\n",
      "epoch:17 step:16399 [D loss: 0.500858, acc.: 75.78%] [G loss: 0.815066]\n",
      "epoch:17 step:16400 [D loss: 0.450420, acc.: 79.69%] [G loss: 0.876316]\n",
      "##############\n",
      "[2.93263663 1.17869234 5.94338816 4.9774483  3.72881538 5.79118422\n",
      " 4.62667446 4.83113494 4.55774877 4.07936652]\n",
      "##########\n",
      "epoch:17 step:16401 [D loss: 0.481406, acc.: 81.25%] [G loss: 0.762705]\n",
      "epoch:17 step:16402 [D loss: 0.672270, acc.: 59.38%] [G loss: 0.561649]\n",
      "epoch:17 step:16403 [D loss: 0.560937, acc.: 64.06%] [G loss: 0.732105]\n",
      "epoch:17 step:16404 [D loss: 0.487176, acc.: 79.69%] [G loss: 0.810108]\n",
      "epoch:17 step:16405 [D loss: 0.535946, acc.: 77.34%] [G loss: 0.800416]\n",
      "epoch:17 step:16406 [D loss: 0.734428, acc.: 60.94%] [G loss: 0.577193]\n",
      "epoch:17 step:16407 [D loss: 0.536226, acc.: 71.88%] [G loss: 0.578138]\n",
      "epoch:17 step:16408 [D loss: 0.504129, acc.: 71.09%] [G loss: 0.454382]\n",
      "epoch:17 step:16409 [D loss: 0.562697, acc.: 67.19%] [G loss: 0.592537]\n",
      "epoch:17 step:16410 [D loss: 0.486242, acc.: 78.12%] [G loss: 0.645068]\n",
      "epoch:17 step:16411 [D loss: 0.582468, acc.: 66.41%] [G loss: 0.522582]\n",
      "epoch:17 step:16412 [D loss: 0.571917, acc.: 69.53%] [G loss: 0.643054]\n",
      "epoch:17 step:16413 [D loss: 0.508789, acc.: 76.56%] [G loss: 0.671742]\n",
      "epoch:17 step:16414 [D loss: 0.499116, acc.: 75.00%] [G loss: 0.814672]\n",
      "epoch:17 step:16415 [D loss: 0.534548, acc.: 71.88%] [G loss: 0.694152]\n",
      "epoch:17 step:16416 [D loss: 0.550522, acc.: 67.19%] [G loss: 0.450580]\n",
      "epoch:17 step:16417 [D loss: 0.522647, acc.: 72.66%] [G loss: 0.556440]\n",
      "epoch:17 step:16418 [D loss: 0.512604, acc.: 71.09%] [G loss: 0.686733]\n",
      "epoch:17 step:16419 [D loss: 0.562316, acc.: 68.75%] [G loss: 0.634012]\n",
      "epoch:17 step:16420 [D loss: 0.605404, acc.: 60.94%] [G loss: 0.597835]\n",
      "epoch:17 step:16421 [D loss: 0.572299, acc.: 72.66%] [G loss: 0.536818]\n",
      "epoch:17 step:16422 [D loss: 0.596960, acc.: 62.50%] [G loss: 0.459252]\n",
      "epoch:17 step:16423 [D loss: 0.541933, acc.: 72.66%] [G loss: 0.531029]\n",
      "epoch:17 step:16424 [D loss: 0.484525, acc.: 76.56%] [G loss: 0.543689]\n",
      "epoch:17 step:16425 [D loss: 0.568524, acc.: 71.88%] [G loss: 0.639175]\n",
      "epoch:17 step:16426 [D loss: 0.610258, acc.: 63.28%] [G loss: 0.641928]\n",
      "epoch:17 step:16427 [D loss: 0.503841, acc.: 70.31%] [G loss: 0.778589]\n",
      "epoch:17 step:16428 [D loss: 0.508529, acc.: 73.44%] [G loss: 0.803740]\n",
      "epoch:17 step:16429 [D loss: 0.572379, acc.: 65.62%] [G loss: 0.568976]\n",
      "epoch:17 step:16430 [D loss: 0.633798, acc.: 64.84%] [G loss: 0.606339]\n",
      "epoch:17 step:16431 [D loss: 0.617160, acc.: 60.16%] [G loss: 0.472659]\n",
      "epoch:17 step:16432 [D loss: 0.547568, acc.: 70.31%] [G loss: 0.608600]\n",
      "epoch:17 step:16433 [D loss: 0.506352, acc.: 71.88%] [G loss: 0.740704]\n",
      "epoch:17 step:16434 [D loss: 0.515397, acc.: 73.44%] [G loss: 0.819050]\n",
      "epoch:17 step:16435 [D loss: 0.462919, acc.: 75.78%] [G loss: 0.779419]\n",
      "epoch:17 step:16436 [D loss: 0.531227, acc.: 75.78%] [G loss: 0.844936]\n",
      "epoch:17 step:16437 [D loss: 0.443704, acc.: 84.38%] [G loss: 0.881398]\n",
      "epoch:17 step:16438 [D loss: 0.539320, acc.: 70.31%] [G loss: 0.820810]\n",
      "epoch:17 step:16439 [D loss: 0.626625, acc.: 65.62%] [G loss: 0.627800]\n",
      "epoch:17 step:16440 [D loss: 0.687621, acc.: 54.69%] [G loss: 0.556320]\n",
      "epoch:17 step:16441 [D loss: 0.584127, acc.: 68.75%] [G loss: 0.512364]\n",
      "epoch:17 step:16442 [D loss: 0.574867, acc.: 72.66%] [G loss: 0.515635]\n",
      "epoch:17 step:16443 [D loss: 0.504947, acc.: 71.09%] [G loss: 0.600486]\n",
      "epoch:17 step:16444 [D loss: 0.517928, acc.: 71.88%] [G loss: 0.788150]\n",
      "epoch:17 step:16445 [D loss: 0.457650, acc.: 81.25%] [G loss: 0.680187]\n",
      "epoch:17 step:16446 [D loss: 0.485358, acc.: 76.56%] [G loss: 0.711603]\n",
      "epoch:17 step:16447 [D loss: 0.639261, acc.: 60.94%] [G loss: 0.745440]\n",
      "epoch:17 step:16448 [D loss: 0.494553, acc.: 75.78%] [G loss: 0.775020]\n",
      "epoch:17 step:16449 [D loss: 0.507993, acc.: 72.66%] [G loss: 0.859713]\n",
      "epoch:17 step:16450 [D loss: 0.515400, acc.: 75.00%] [G loss: 0.715343]\n",
      "epoch:17 step:16451 [D loss: 0.486176, acc.: 77.34%] [G loss: 0.782522]\n",
      "epoch:17 step:16452 [D loss: 0.465727, acc.: 75.78%] [G loss: 0.784805]\n",
      "epoch:17 step:16453 [D loss: 0.569320, acc.: 67.97%] [G loss: 0.522571]\n",
      "epoch:17 step:16454 [D loss: 0.574399, acc.: 69.53%] [G loss: 0.696194]\n",
      "epoch:17 step:16455 [D loss: 0.500827, acc.: 75.78%] [G loss: 0.664813]\n",
      "epoch:17 step:16456 [D loss: 0.559877, acc.: 65.62%] [G loss: 0.631675]\n",
      "epoch:17 step:16457 [D loss: 0.660667, acc.: 59.38%] [G loss: 0.558528]\n",
      "epoch:17 step:16458 [D loss: 0.606098, acc.: 60.16%] [G loss: 0.421429]\n",
      "epoch:17 step:16459 [D loss: 0.556768, acc.: 70.31%] [G loss: 0.568961]\n",
      "epoch:17 step:16460 [D loss: 0.524122, acc.: 72.66%] [G loss: 0.593629]\n",
      "epoch:17 step:16461 [D loss: 0.585979, acc.: 64.06%] [G loss: 0.542638]\n",
      "epoch:17 step:16462 [D loss: 0.547495, acc.: 67.97%] [G loss: 0.704111]\n",
      "epoch:17 step:16463 [D loss: 0.546382, acc.: 70.31%] [G loss: 0.652885]\n",
      "epoch:17 step:16464 [D loss: 0.623651, acc.: 60.94%] [G loss: 0.447749]\n",
      "epoch:17 step:16465 [D loss: 0.499834, acc.: 69.53%] [G loss: 0.582764]\n",
      "epoch:17 step:16466 [D loss: 0.563527, acc.: 68.75%] [G loss: 0.557814]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16467 [D loss: 0.543131, acc.: 69.53%] [G loss: 0.628212]\n",
      "epoch:17 step:16468 [D loss: 0.556352, acc.: 70.31%] [G loss: 0.533484]\n",
      "epoch:17 step:16469 [D loss: 0.525154, acc.: 73.44%] [G loss: 0.453419]\n",
      "epoch:17 step:16470 [D loss: 0.539079, acc.: 72.66%] [G loss: 0.549891]\n",
      "epoch:17 step:16471 [D loss: 0.625003, acc.: 60.94%] [G loss: 0.511881]\n",
      "epoch:17 step:16472 [D loss: 0.627258, acc.: 60.94%] [G loss: 0.524772]\n",
      "epoch:17 step:16473 [D loss: 0.582268, acc.: 70.31%] [G loss: 0.625135]\n",
      "epoch:17 step:16474 [D loss: 0.521664, acc.: 73.44%] [G loss: 0.621199]\n",
      "epoch:17 step:16475 [D loss: 0.500652, acc.: 71.88%] [G loss: 0.668773]\n",
      "epoch:17 step:16476 [D loss: 0.537931, acc.: 71.88%] [G loss: 0.834166]\n",
      "epoch:17 step:16477 [D loss: 0.499756, acc.: 74.22%] [G loss: 0.718511]\n",
      "epoch:17 step:16478 [D loss: 0.501666, acc.: 73.44%] [G loss: 0.713963]\n",
      "epoch:17 step:16479 [D loss: 0.604163, acc.: 65.62%] [G loss: 0.654168]\n",
      "epoch:17 step:16480 [D loss: 0.520120, acc.: 71.88%] [G loss: 0.702410]\n",
      "epoch:17 step:16481 [D loss: 0.502437, acc.: 71.09%] [G loss: 0.728553]\n",
      "epoch:17 step:16482 [D loss: 0.569842, acc.: 68.75%] [G loss: 0.649387]\n",
      "epoch:17 step:16483 [D loss: 0.486842, acc.: 78.12%] [G loss: 0.722970]\n",
      "epoch:17 step:16484 [D loss: 0.472118, acc.: 75.00%] [G loss: 0.726141]\n",
      "epoch:17 step:16485 [D loss: 0.577313, acc.: 71.09%] [G loss: 0.753849]\n",
      "epoch:17 step:16486 [D loss: 0.476891, acc.: 77.34%] [G loss: 0.576928]\n",
      "epoch:17 step:16487 [D loss: 0.505512, acc.: 73.44%] [G loss: 0.741819]\n",
      "epoch:17 step:16488 [D loss: 0.568845, acc.: 65.62%] [G loss: 0.786128]\n",
      "epoch:17 step:16489 [D loss: 0.560538, acc.: 69.53%] [G loss: 0.592041]\n",
      "epoch:17 step:16490 [D loss: 0.543878, acc.: 70.31%] [G loss: 0.616286]\n",
      "epoch:17 step:16491 [D loss: 0.601852, acc.: 67.19%] [G loss: 0.503859]\n",
      "epoch:17 step:16492 [D loss: 0.581984, acc.: 64.06%] [G loss: 0.516051]\n",
      "epoch:17 step:16493 [D loss: 0.504101, acc.: 74.22%] [G loss: 0.652065]\n",
      "epoch:17 step:16494 [D loss: 0.566255, acc.: 73.44%] [G loss: 0.711833]\n",
      "epoch:17 step:16495 [D loss: 0.705391, acc.: 63.28%] [G loss: 0.638787]\n",
      "epoch:17 step:16496 [D loss: 0.527271, acc.: 73.44%] [G loss: 0.539678]\n",
      "epoch:17 step:16497 [D loss: 0.482909, acc.: 77.34%] [G loss: 0.824064]\n",
      "epoch:17 step:16498 [D loss: 0.523007, acc.: 71.88%] [G loss: 0.622716]\n",
      "epoch:17 step:16499 [D loss: 0.538160, acc.: 66.41%] [G loss: 0.716696]\n",
      "epoch:17 step:16500 [D loss: 0.523583, acc.: 74.22%] [G loss: 0.582705]\n",
      "epoch:17 step:16501 [D loss: 0.588543, acc.: 67.97%] [G loss: 0.685523]\n",
      "epoch:17 step:16502 [D loss: 0.499976, acc.: 72.66%] [G loss: 0.769658]\n",
      "epoch:17 step:16503 [D loss: 0.553150, acc.: 69.53%] [G loss: 0.759990]\n",
      "epoch:17 step:16504 [D loss: 0.524432, acc.: 74.22%] [G loss: 0.749881]\n",
      "epoch:17 step:16505 [D loss: 0.610158, acc.: 63.28%] [G loss: 0.669339]\n",
      "epoch:17 step:16506 [D loss: 0.556564, acc.: 70.31%] [G loss: 0.619338]\n",
      "epoch:17 step:16507 [D loss: 0.580516, acc.: 67.19%] [G loss: 0.620004]\n",
      "epoch:17 step:16508 [D loss: 0.532612, acc.: 70.31%] [G loss: 0.615866]\n",
      "epoch:17 step:16509 [D loss: 0.564476, acc.: 73.44%] [G loss: 0.490723]\n",
      "epoch:17 step:16510 [D loss: 0.547125, acc.: 70.31%] [G loss: 0.607296]\n",
      "epoch:17 step:16511 [D loss: 0.503119, acc.: 74.22%] [G loss: 0.616703]\n",
      "epoch:17 step:16512 [D loss: 0.528971, acc.: 68.75%] [G loss: 0.807072]\n",
      "epoch:17 step:16513 [D loss: 0.561413, acc.: 68.75%] [G loss: 0.625053]\n",
      "epoch:17 step:16514 [D loss: 0.606264, acc.: 67.19%] [G loss: 0.564063]\n",
      "epoch:17 step:16515 [D loss: 0.555060, acc.: 69.53%] [G loss: 0.554739]\n",
      "epoch:17 step:16516 [D loss: 0.586805, acc.: 65.62%] [G loss: 0.740804]\n",
      "epoch:17 step:16517 [D loss: 0.540107, acc.: 70.31%] [G loss: 0.553585]\n",
      "epoch:17 step:16518 [D loss: 0.544049, acc.: 73.44%] [G loss: 0.766496]\n",
      "epoch:17 step:16519 [D loss: 0.557240, acc.: 72.66%] [G loss: 0.752232]\n",
      "epoch:17 step:16520 [D loss: 0.587653, acc.: 71.88%] [G loss: 0.480540]\n",
      "epoch:17 step:16521 [D loss: 0.490993, acc.: 75.78%] [G loss: 0.733013]\n",
      "epoch:17 step:16522 [D loss: 0.534116, acc.: 67.97%] [G loss: 0.655802]\n",
      "epoch:17 step:16523 [D loss: 0.538138, acc.: 71.09%] [G loss: 0.566840]\n",
      "epoch:17 step:16524 [D loss: 0.538434, acc.: 73.44%] [G loss: 0.549982]\n",
      "epoch:17 step:16525 [D loss: 0.526045, acc.: 71.88%] [G loss: 0.555201]\n",
      "epoch:17 step:16526 [D loss: 0.496033, acc.: 71.88%] [G loss: 0.620521]\n",
      "epoch:17 step:16527 [D loss: 0.525906, acc.: 73.44%] [G loss: 0.551243]\n",
      "epoch:17 step:16528 [D loss: 0.509949, acc.: 74.22%] [G loss: 0.552841]\n",
      "epoch:17 step:16529 [D loss: 0.567625, acc.: 70.31%] [G loss: 0.490937]\n",
      "epoch:17 step:16530 [D loss: 0.473542, acc.: 76.56%] [G loss: 0.638706]\n",
      "epoch:17 step:16531 [D loss: 0.564651, acc.: 68.75%] [G loss: 0.692116]\n",
      "epoch:17 step:16532 [D loss: 0.476513, acc.: 78.91%] [G loss: 0.754226]\n",
      "epoch:17 step:16533 [D loss: 0.571958, acc.: 70.31%] [G loss: 0.686699]\n",
      "epoch:17 step:16534 [D loss: 0.492130, acc.: 75.78%] [G loss: 0.696093]\n",
      "epoch:17 step:16535 [D loss: 0.632255, acc.: 67.19%] [G loss: 0.600163]\n",
      "epoch:17 step:16536 [D loss: 0.563453, acc.: 69.53%] [G loss: 0.537170]\n",
      "epoch:17 step:16537 [D loss: 0.538235, acc.: 73.44%] [G loss: 0.533917]\n",
      "epoch:17 step:16538 [D loss: 0.569141, acc.: 67.97%] [G loss: 0.550667]\n",
      "epoch:17 step:16539 [D loss: 0.568845, acc.: 67.97%] [G loss: 0.453606]\n",
      "epoch:17 step:16540 [D loss: 0.498284, acc.: 75.00%] [G loss: 0.504170]\n",
      "epoch:17 step:16541 [D loss: 0.525019, acc.: 70.31%] [G loss: 0.566929]\n",
      "epoch:17 step:16542 [D loss: 0.483850, acc.: 74.22%] [G loss: 0.624301]\n",
      "epoch:17 step:16543 [D loss: 0.597327, acc.: 67.19%] [G loss: 0.565993]\n",
      "epoch:17 step:16544 [D loss: 0.532099, acc.: 74.22%] [G loss: 0.577290]\n",
      "epoch:17 step:16545 [D loss: 0.589116, acc.: 61.72%] [G loss: 0.626152]\n",
      "epoch:17 step:16546 [D loss: 0.562995, acc.: 65.62%] [G loss: 0.713006]\n",
      "epoch:17 step:16547 [D loss: 0.513855, acc.: 71.88%] [G loss: 0.742568]\n",
      "epoch:17 step:16548 [D loss: 0.589949, acc.: 64.84%] [G loss: 0.569902]\n",
      "epoch:17 step:16549 [D loss: 0.503011, acc.: 74.22%] [G loss: 0.696466]\n",
      "epoch:17 step:16550 [D loss: 0.586179, acc.: 65.62%] [G loss: 0.617591]\n",
      "epoch:17 step:16551 [D loss: 0.559745, acc.: 68.75%] [G loss: 0.450018]\n",
      "epoch:17 step:16552 [D loss: 0.461391, acc.: 74.22%] [G loss: 0.654567]\n",
      "epoch:17 step:16553 [D loss: 0.486531, acc.: 75.78%] [G loss: 0.657317]\n",
      "epoch:17 step:16554 [D loss: 0.579786, acc.: 67.97%] [G loss: 0.445697]\n",
      "epoch:17 step:16555 [D loss: 0.494856, acc.: 75.78%] [G loss: 0.633835]\n",
      "epoch:17 step:16556 [D loss: 0.554457, acc.: 67.97%] [G loss: 0.625757]\n",
      "epoch:17 step:16557 [D loss: 0.548023, acc.: 72.66%] [G loss: 0.572296]\n",
      "epoch:17 step:16558 [D loss: 0.539503, acc.: 72.66%] [G loss: 0.579890]\n",
      "epoch:17 step:16559 [D loss: 0.516912, acc.: 75.00%] [G loss: 0.594383]\n",
      "epoch:17 step:16560 [D loss: 0.459582, acc.: 81.25%] [G loss: 0.681552]\n",
      "epoch:17 step:16561 [D loss: 0.470430, acc.: 75.78%] [G loss: 0.753088]\n",
      "epoch:17 step:16562 [D loss: 0.585904, acc.: 68.75%] [G loss: 0.693086]\n",
      "epoch:17 step:16563 [D loss: 0.501655, acc.: 77.34%] [G loss: 0.782748]\n",
      "epoch:17 step:16564 [D loss: 0.532790, acc.: 71.09%] [G loss: 0.842019]\n",
      "epoch:17 step:16565 [D loss: 0.601915, acc.: 64.06%] [G loss: 0.652500]\n",
      "epoch:17 step:16566 [D loss: 0.495632, acc.: 79.69%] [G loss: 0.573874]\n",
      "epoch:17 step:16567 [D loss: 0.553359, acc.: 67.97%] [G loss: 0.590870]\n",
      "epoch:17 step:16568 [D loss: 0.506739, acc.: 75.00%] [G loss: 0.548384]\n",
      "epoch:17 step:16569 [D loss: 0.648245, acc.: 59.38%] [G loss: 0.490381]\n",
      "epoch:17 step:16570 [D loss: 0.488643, acc.: 75.78%] [G loss: 0.612383]\n",
      "epoch:17 step:16571 [D loss: 0.504735, acc.: 75.00%] [G loss: 0.782295]\n",
      "epoch:17 step:16572 [D loss: 0.541939, acc.: 71.88%] [G loss: 0.791081]\n",
      "epoch:17 step:16573 [D loss: 0.563897, acc.: 67.19%] [G loss: 0.647309]\n",
      "epoch:17 step:16574 [D loss: 0.522088, acc.: 71.88%] [G loss: 0.707321]\n",
      "epoch:17 step:16575 [D loss: 0.549181, acc.: 73.44%] [G loss: 0.609619]\n",
      "epoch:17 step:16576 [D loss: 0.494904, acc.: 77.34%] [G loss: 0.709623]\n",
      "epoch:17 step:16577 [D loss: 0.422015, acc.: 82.81%] [G loss: 0.889993]\n",
      "epoch:17 step:16578 [D loss: 0.512447, acc.: 74.22%] [G loss: 0.824583]\n",
      "epoch:17 step:16579 [D loss: 0.472996, acc.: 74.22%] [G loss: 0.850002]\n",
      "epoch:17 step:16580 [D loss: 0.508395, acc.: 74.22%] [G loss: 0.807936]\n",
      "epoch:17 step:16581 [D loss: 0.592014, acc.: 60.94%] [G loss: 0.595391]\n",
      "epoch:17 step:16582 [D loss: 0.513757, acc.: 71.88%] [G loss: 0.737665]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16583 [D loss: 0.478368, acc.: 75.78%] [G loss: 0.561689]\n",
      "epoch:17 step:16584 [D loss: 0.567033, acc.: 72.66%] [G loss: 0.473742]\n",
      "epoch:17 step:16585 [D loss: 0.564760, acc.: 71.09%] [G loss: 0.603376]\n",
      "epoch:17 step:16586 [D loss: 0.493229, acc.: 72.66%] [G loss: 0.847746]\n",
      "epoch:17 step:16587 [D loss: 0.616266, acc.: 66.41%] [G loss: 0.711432]\n",
      "epoch:17 step:16588 [D loss: 0.523821, acc.: 72.66%] [G loss: 0.609121]\n",
      "epoch:17 step:16589 [D loss: 0.493022, acc.: 74.22%] [G loss: 0.793168]\n",
      "epoch:17 step:16590 [D loss: 0.501639, acc.: 74.22%] [G loss: 0.892830]\n",
      "epoch:17 step:16591 [D loss: 0.521377, acc.: 73.44%] [G loss: 0.779306]\n",
      "epoch:17 step:16592 [D loss: 0.549427, acc.: 71.09%] [G loss: 0.688706]\n",
      "epoch:17 step:16593 [D loss: 0.549544, acc.: 66.41%] [G loss: 0.832692]\n",
      "epoch:17 step:16594 [D loss: 0.551347, acc.: 65.62%] [G loss: 0.725654]\n",
      "epoch:17 step:16595 [D loss: 0.517743, acc.: 71.88%] [G loss: 0.799615]\n",
      "epoch:17 step:16596 [D loss: 0.568444, acc.: 68.75%] [G loss: 0.631356]\n",
      "epoch:17 step:16597 [D loss: 0.533825, acc.: 75.00%] [G loss: 0.760107]\n",
      "epoch:17 step:16598 [D loss: 0.525569, acc.: 72.66%] [G loss: 0.697684]\n",
      "epoch:17 step:16599 [D loss: 0.527019, acc.: 72.66%] [G loss: 0.573760]\n",
      "epoch:17 step:16600 [D loss: 0.535180, acc.: 75.78%] [G loss: 0.617301]\n",
      "##############\n",
      "[2.85195017 1.2722497  6.01041793 4.95995286 3.96875457 5.7289481\n",
      " 4.4076249  4.82070867 4.73410064 4.26293005]\n",
      "##########\n",
      "epoch:17 step:16601 [D loss: 0.616691, acc.: 67.97%] [G loss: 0.691670]\n",
      "epoch:17 step:16602 [D loss: 0.602692, acc.: 64.84%] [G loss: 0.696007]\n",
      "epoch:17 step:16603 [D loss: 0.527089, acc.: 67.97%] [G loss: 0.629738]\n",
      "epoch:17 step:16604 [D loss: 0.589322, acc.: 65.62%] [G loss: 0.536034]\n",
      "epoch:17 step:16605 [D loss: 0.540496, acc.: 69.53%] [G loss: 0.588111]\n",
      "epoch:17 step:16606 [D loss: 0.528629, acc.: 74.22%] [G loss: 0.633371]\n",
      "epoch:17 step:16607 [D loss: 0.559189, acc.: 72.66%] [G loss: 0.693072]\n",
      "epoch:17 step:16608 [D loss: 0.488552, acc.: 78.12%] [G loss: 0.702875]\n",
      "epoch:17 step:16609 [D loss: 0.528361, acc.: 75.78%] [G loss: 0.634788]\n",
      "epoch:17 step:16610 [D loss: 0.509700, acc.: 76.56%] [G loss: 0.731019]\n",
      "epoch:17 step:16611 [D loss: 0.525342, acc.: 71.09%] [G loss: 0.560153]\n",
      "epoch:17 step:16612 [D loss: 0.560242, acc.: 67.19%] [G loss: 0.612825]\n",
      "epoch:17 step:16613 [D loss: 0.639378, acc.: 62.50%] [G loss: 0.502662]\n",
      "epoch:17 step:16614 [D loss: 0.495924, acc.: 75.00%] [G loss: 0.576599]\n",
      "epoch:17 step:16615 [D loss: 0.564271, acc.: 71.09%] [G loss: 0.500866]\n",
      "epoch:17 step:16616 [D loss: 0.554747, acc.: 73.44%] [G loss: 0.642548]\n",
      "epoch:17 step:16617 [D loss: 0.573546, acc.: 67.19%] [G loss: 0.626067]\n",
      "epoch:17 step:16618 [D loss: 0.540720, acc.: 71.09%] [G loss: 0.622658]\n",
      "epoch:17 step:16619 [D loss: 0.515783, acc.: 72.66%] [G loss: 0.855381]\n",
      "epoch:17 step:16620 [D loss: 0.477286, acc.: 75.78%] [G loss: 0.893025]\n",
      "epoch:17 step:16621 [D loss: 0.538141, acc.: 74.22%] [G loss: 0.641756]\n",
      "epoch:17 step:16622 [D loss: 0.499995, acc.: 75.00%] [G loss: 0.839765]\n",
      "epoch:17 step:16623 [D loss: 0.557405, acc.: 73.44%] [G loss: 0.756032]\n",
      "epoch:17 step:16624 [D loss: 0.518728, acc.: 75.00%] [G loss: 0.766493]\n",
      "epoch:17 step:16625 [D loss: 0.574727, acc.: 65.62%] [G loss: 0.642004]\n",
      "epoch:17 step:16626 [D loss: 0.552802, acc.: 64.84%] [G loss: 0.678420]\n",
      "epoch:17 step:16627 [D loss: 0.543777, acc.: 75.00%] [G loss: 0.641447]\n",
      "epoch:17 step:16628 [D loss: 0.474026, acc.: 73.44%] [G loss: 0.637996]\n",
      "epoch:17 step:16629 [D loss: 0.538906, acc.: 73.44%] [G loss: 0.753303]\n",
      "epoch:17 step:16630 [D loss: 0.466845, acc.: 78.12%] [G loss: 0.882844]\n",
      "epoch:17 step:16631 [D loss: 0.602698, acc.: 64.84%] [G loss: 0.735764]\n",
      "epoch:17 step:16632 [D loss: 0.637609, acc.: 60.16%] [G loss: 0.530080]\n",
      "epoch:17 step:16633 [D loss: 0.647611, acc.: 60.16%] [G loss: 0.489220]\n",
      "epoch:17 step:16634 [D loss: 0.501842, acc.: 72.66%] [G loss: 0.567870]\n",
      "epoch:17 step:16635 [D loss: 0.518151, acc.: 71.09%] [G loss: 0.508985]\n",
      "epoch:17 step:16636 [D loss: 0.520068, acc.: 72.66%] [G loss: 0.811395]\n",
      "epoch:17 step:16637 [D loss: 0.454106, acc.: 78.12%] [G loss: 0.806253]\n",
      "epoch:17 step:16638 [D loss: 0.533004, acc.: 68.75%] [G loss: 0.879155]\n",
      "epoch:17 step:16639 [D loss: 0.686015, acc.: 60.94%] [G loss: 0.567628]\n",
      "epoch:17 step:16640 [D loss: 0.542667, acc.: 70.31%] [G loss: 0.706243]\n",
      "epoch:17 step:16641 [D loss: 0.513242, acc.: 71.88%] [G loss: 0.608051]\n",
      "epoch:17 step:16642 [D loss: 0.596230, acc.: 64.06%] [G loss: 0.603979]\n",
      "epoch:17 step:16643 [D loss: 0.573642, acc.: 66.41%] [G loss: 0.671414]\n",
      "epoch:17 step:16644 [D loss: 0.565220, acc.: 71.88%] [G loss: 0.590399]\n",
      "epoch:17 step:16645 [D loss: 0.685784, acc.: 56.25%] [G loss: 0.697148]\n",
      "epoch:17 step:16646 [D loss: 0.565777, acc.: 71.88%] [G loss: 0.596932]\n",
      "epoch:17 step:16647 [D loss: 0.545793, acc.: 72.66%] [G loss: 0.654242]\n",
      "epoch:17 step:16648 [D loss: 0.442927, acc.: 78.12%] [G loss: 0.741560]\n",
      "epoch:17 step:16649 [D loss: 0.594460, acc.: 68.75%] [G loss: 0.623948]\n",
      "epoch:17 step:16650 [D loss: 0.519087, acc.: 74.22%] [G loss: 0.585308]\n",
      "epoch:17 step:16651 [D loss: 0.539159, acc.: 67.97%] [G loss: 0.552798]\n",
      "epoch:17 step:16652 [D loss: 0.570148, acc.: 72.66%] [G loss: 0.551184]\n",
      "epoch:17 step:16653 [D loss: 0.528041, acc.: 74.22%] [G loss: 0.752988]\n",
      "epoch:17 step:16654 [D loss: 0.509634, acc.: 75.78%] [G loss: 0.756762]\n",
      "epoch:17 step:16655 [D loss: 0.505144, acc.: 74.22%] [G loss: 0.727631]\n",
      "epoch:17 step:16656 [D loss: 0.587021, acc.: 65.62%] [G loss: 0.621896]\n",
      "epoch:17 step:16657 [D loss: 0.564355, acc.: 68.75%] [G loss: 0.549414]\n",
      "epoch:17 step:16658 [D loss: 0.550693, acc.: 71.88%] [G loss: 0.620671]\n",
      "epoch:17 step:16659 [D loss: 0.538924, acc.: 75.78%] [G loss: 0.577199]\n",
      "epoch:17 step:16660 [D loss: 0.616883, acc.: 61.72%] [G loss: 0.419245]\n",
      "epoch:17 step:16661 [D loss: 0.492485, acc.: 76.56%] [G loss: 0.478213]\n",
      "epoch:17 step:16662 [D loss: 0.547908, acc.: 70.31%] [G loss: 0.585912]\n",
      "epoch:17 step:16663 [D loss: 0.547421, acc.: 68.75%] [G loss: 0.558318]\n",
      "epoch:17 step:16664 [D loss: 0.542439, acc.: 71.88%] [G loss: 0.687838]\n",
      "epoch:17 step:16665 [D loss: 0.558289, acc.: 68.75%] [G loss: 0.664572]\n",
      "epoch:17 step:16666 [D loss: 0.516615, acc.: 71.88%] [G loss: 0.544609]\n",
      "epoch:17 step:16667 [D loss: 0.614006, acc.: 64.84%] [G loss: 0.540071]\n",
      "epoch:17 step:16668 [D loss: 0.586460, acc.: 66.41%] [G loss: 0.525834]\n",
      "epoch:17 step:16669 [D loss: 0.615948, acc.: 64.06%] [G loss: 0.379699]\n",
      "epoch:17 step:16670 [D loss: 0.561475, acc.: 71.09%] [G loss: 0.440036]\n",
      "epoch:17 step:16671 [D loss: 0.558832, acc.: 69.53%] [G loss: 0.583949]\n",
      "epoch:17 step:16672 [D loss: 0.518799, acc.: 73.44%] [G loss: 0.879273]\n",
      "epoch:17 step:16673 [D loss: 0.537402, acc.: 74.22%] [G loss: 0.788232]\n",
      "epoch:17 step:16674 [D loss: 0.556524, acc.: 67.97%] [G loss: 0.593119]\n",
      "epoch:17 step:16675 [D loss: 0.478682, acc.: 73.44%] [G loss: 0.617215]\n",
      "epoch:17 step:16676 [D loss: 0.440538, acc.: 77.34%] [G loss: 0.732535]\n",
      "epoch:17 step:16677 [D loss: 0.524897, acc.: 74.22%] [G loss: 0.710773]\n",
      "epoch:17 step:16678 [D loss: 0.521752, acc.: 75.78%] [G loss: 0.717282]\n",
      "epoch:17 step:16679 [D loss: 0.494207, acc.: 79.69%] [G loss: 0.618804]\n",
      "epoch:17 step:16680 [D loss: 0.518416, acc.: 72.66%] [G loss: 0.697941]\n",
      "epoch:17 step:16681 [D loss: 0.558421, acc.: 72.66%] [G loss: 0.638188]\n",
      "epoch:17 step:16682 [D loss: 0.524078, acc.: 71.09%] [G loss: 0.725347]\n",
      "epoch:17 step:16683 [D loss: 0.512660, acc.: 72.66%] [G loss: 0.669148]\n",
      "epoch:17 step:16684 [D loss: 0.582104, acc.: 67.19%] [G loss: 0.600866]\n",
      "epoch:17 step:16685 [D loss: 0.521208, acc.: 71.88%] [G loss: 0.604688]\n",
      "epoch:17 step:16686 [D loss: 0.598105, acc.: 65.62%] [G loss: 0.580632]\n",
      "epoch:17 step:16687 [D loss: 0.549743, acc.: 71.88%] [G loss: 0.539494]\n",
      "epoch:17 step:16688 [D loss: 0.537005, acc.: 66.41%] [G loss: 0.525700]\n",
      "epoch:17 step:16689 [D loss: 0.544297, acc.: 69.53%] [G loss: 0.605762]\n",
      "epoch:17 step:16690 [D loss: 0.546573, acc.: 70.31%] [G loss: 0.537819]\n",
      "epoch:17 step:16691 [D loss: 0.650491, acc.: 62.50%] [G loss: 0.432685]\n",
      "epoch:17 step:16692 [D loss: 0.527513, acc.: 75.00%] [G loss: 0.664380]\n",
      "epoch:17 step:16693 [D loss: 0.557074, acc.: 70.31%] [G loss: 0.605720]\n",
      "epoch:17 step:16694 [D loss: 0.616483, acc.: 64.84%] [G loss: 0.546882]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16695 [D loss: 0.648223, acc.: 63.28%] [G loss: 0.675154]\n",
      "epoch:17 step:16696 [D loss: 0.540032, acc.: 75.00%] [G loss: 0.585635]\n",
      "epoch:17 step:16697 [D loss: 0.510137, acc.: 72.66%] [G loss: 0.833751]\n",
      "epoch:17 step:16698 [D loss: 0.497181, acc.: 71.09%] [G loss: 0.768737]\n",
      "epoch:17 step:16699 [D loss: 0.558176, acc.: 68.75%] [G loss: 0.774035]\n",
      "epoch:17 step:16700 [D loss: 0.538842, acc.: 73.44%] [G loss: 0.783760]\n",
      "epoch:17 step:16701 [D loss: 0.520813, acc.: 73.44%] [G loss: 0.604883]\n",
      "epoch:17 step:16702 [D loss: 0.451610, acc.: 81.25%] [G loss: 0.714240]\n",
      "epoch:17 step:16703 [D loss: 0.556629, acc.: 69.53%] [G loss: 0.736575]\n",
      "epoch:17 step:16704 [D loss: 0.513671, acc.: 72.66%] [G loss: 0.560939]\n",
      "epoch:17 step:16705 [D loss: 0.570573, acc.: 69.53%] [G loss: 0.624267]\n",
      "epoch:17 step:16706 [D loss: 0.560345, acc.: 72.66%] [G loss: 0.525380]\n",
      "epoch:17 step:16707 [D loss: 0.543274, acc.: 73.44%] [G loss: 0.686632]\n",
      "epoch:17 step:16708 [D loss: 0.563109, acc.: 72.66%] [G loss: 0.714986]\n",
      "epoch:17 step:16709 [D loss: 0.541030, acc.: 74.22%] [G loss: 0.674760]\n",
      "epoch:17 step:16710 [D loss: 0.493255, acc.: 78.12%] [G loss: 0.901061]\n",
      "epoch:17 step:16711 [D loss: 0.545218, acc.: 72.66%] [G loss: 1.005828]\n",
      "epoch:17 step:16712 [D loss: 0.541079, acc.: 72.66%] [G loss: 0.672004]\n",
      "epoch:17 step:16713 [D loss: 0.605067, acc.: 59.38%] [G loss: 0.697347]\n",
      "epoch:17 step:16714 [D loss: 0.541641, acc.: 68.75%] [G loss: 0.542191]\n",
      "epoch:17 step:16715 [D loss: 0.528524, acc.: 71.88%] [G loss: 0.732089]\n",
      "epoch:17 step:16716 [D loss: 0.593338, acc.: 64.06%] [G loss: 0.515043]\n",
      "epoch:17 step:16717 [D loss: 0.659275, acc.: 62.50%] [G loss: 0.536116]\n",
      "epoch:17 step:16718 [D loss: 0.504293, acc.: 78.91%] [G loss: 0.579448]\n",
      "epoch:17 step:16719 [D loss: 0.558638, acc.: 71.09%] [G loss: 0.712875]\n",
      "epoch:17 step:16720 [D loss: 0.523161, acc.: 73.44%] [G loss: 0.540801]\n",
      "epoch:17 step:16721 [D loss: 0.509923, acc.: 75.78%] [G loss: 0.610219]\n",
      "epoch:17 step:16722 [D loss: 0.543018, acc.: 75.00%] [G loss: 0.590788]\n",
      "epoch:17 step:16723 [D loss: 0.601387, acc.: 65.62%] [G loss: 0.738624]\n",
      "epoch:17 step:16724 [D loss: 0.481440, acc.: 71.88%] [G loss: 0.767340]\n",
      "epoch:17 step:16725 [D loss: 0.512707, acc.: 73.44%] [G loss: 0.776812]\n",
      "epoch:17 step:16726 [D loss: 0.599121, acc.: 64.06%] [G loss: 0.643182]\n",
      "epoch:17 step:16727 [D loss: 0.514462, acc.: 70.31%] [G loss: 0.659638]\n",
      "epoch:17 step:16728 [D loss: 0.542454, acc.: 71.88%] [G loss: 0.698494]\n",
      "epoch:17 step:16729 [D loss: 0.547919, acc.: 71.88%] [G loss: 0.587087]\n",
      "epoch:17 step:16730 [D loss: 0.524487, acc.: 72.66%] [G loss: 0.700549]\n",
      "epoch:17 step:16731 [D loss: 0.485123, acc.: 73.44%] [G loss: 0.737392]\n",
      "epoch:17 step:16732 [D loss: 0.481749, acc.: 75.78%] [G loss: 0.779731]\n",
      "epoch:17 step:16733 [D loss: 0.542173, acc.: 72.66%] [G loss: 0.709208]\n",
      "epoch:17 step:16734 [D loss: 0.580483, acc.: 65.62%] [G loss: 0.469731]\n",
      "epoch:17 step:16735 [D loss: 0.558695, acc.: 67.19%] [G loss: 0.587513]\n",
      "epoch:17 step:16736 [D loss: 0.551183, acc.: 67.19%] [G loss: 0.634491]\n",
      "epoch:17 step:16737 [D loss: 0.558744, acc.: 68.75%] [G loss: 0.527386]\n",
      "epoch:17 step:16738 [D loss: 0.502262, acc.: 75.00%] [G loss: 0.617393]\n",
      "epoch:17 step:16739 [D loss: 0.473672, acc.: 77.34%] [G loss: 0.628798]\n",
      "epoch:17 step:16740 [D loss: 0.569290, acc.: 71.09%] [G loss: 0.445223]\n",
      "epoch:17 step:16741 [D loss: 0.596821, acc.: 67.19%] [G loss: 0.468073]\n",
      "epoch:17 step:16742 [D loss: 0.506478, acc.: 67.97%] [G loss: 0.518329]\n",
      "epoch:17 step:16743 [D loss: 0.458506, acc.: 77.34%] [G loss: 0.604340]\n",
      "epoch:17 step:16744 [D loss: 0.475851, acc.: 75.00%] [G loss: 0.669727]\n",
      "epoch:17 step:16745 [D loss: 0.607457, acc.: 71.88%] [G loss: 0.663592]\n",
      "epoch:17 step:16746 [D loss: 0.615040, acc.: 64.84%] [G loss: 0.678825]\n",
      "epoch:17 step:16747 [D loss: 0.581100, acc.: 62.50%] [G loss: 0.706845]\n",
      "epoch:17 step:16748 [D loss: 0.532324, acc.: 73.44%] [G loss: 0.541243]\n",
      "epoch:17 step:16749 [D loss: 0.644347, acc.: 63.28%] [G loss: 0.585233]\n",
      "epoch:17 step:16750 [D loss: 0.538904, acc.: 72.66%] [G loss: 0.556221]\n",
      "epoch:17 step:16751 [D loss: 0.576434, acc.: 63.28%] [G loss: 0.497391]\n",
      "epoch:17 step:16752 [D loss: 0.459133, acc.: 77.34%] [G loss: 0.713244]\n",
      "epoch:17 step:16753 [D loss: 0.568156, acc.: 70.31%] [G loss: 0.650754]\n",
      "epoch:17 step:16754 [D loss: 0.549918, acc.: 67.97%] [G loss: 0.726873]\n",
      "epoch:17 step:16755 [D loss: 0.562304, acc.: 73.44%] [G loss: 0.599214]\n",
      "epoch:17 step:16756 [D loss: 0.597576, acc.: 69.53%] [G loss: 0.517391]\n",
      "epoch:17 step:16757 [D loss: 0.608334, acc.: 70.31%] [G loss: 0.501579]\n",
      "epoch:17 step:16758 [D loss: 0.482768, acc.: 75.78%] [G loss: 0.703901]\n",
      "epoch:17 step:16759 [D loss: 0.543040, acc.: 70.31%] [G loss: 0.783935]\n",
      "epoch:17 step:16760 [D loss: 0.576163, acc.: 70.31%] [G loss: 0.719687]\n",
      "epoch:17 step:16761 [D loss: 0.504496, acc.: 74.22%] [G loss: 0.573886]\n",
      "epoch:17 step:16762 [D loss: 0.525664, acc.: 75.00%] [G loss: 0.754974]\n",
      "epoch:17 step:16763 [D loss: 0.506997, acc.: 76.56%] [G loss: 0.534017]\n",
      "epoch:17 step:16764 [D loss: 0.496896, acc.: 77.34%] [G loss: 0.732706]\n",
      "epoch:17 step:16765 [D loss: 0.562720, acc.: 67.19%] [G loss: 0.537223]\n",
      "epoch:17 step:16766 [D loss: 0.558272, acc.: 65.62%] [G loss: 0.513992]\n",
      "epoch:17 step:16767 [D loss: 0.552757, acc.: 67.97%] [G loss: 0.795958]\n",
      "epoch:17 step:16768 [D loss: 0.546761, acc.: 67.97%] [G loss: 0.540545]\n",
      "epoch:17 step:16769 [D loss: 0.617459, acc.: 64.06%] [G loss: 0.466382]\n",
      "epoch:17 step:16770 [D loss: 0.530383, acc.: 68.75%] [G loss: 0.614007]\n",
      "epoch:17 step:16771 [D loss: 0.482982, acc.: 79.69%] [G loss: 0.562707]\n",
      "epoch:17 step:16772 [D loss: 0.530375, acc.: 71.09%] [G loss: 0.662934]\n",
      "epoch:17 step:16773 [D loss: 0.645732, acc.: 64.84%] [G loss: 0.474334]\n",
      "epoch:17 step:16774 [D loss: 0.551893, acc.: 71.09%] [G loss: 0.553800]\n",
      "epoch:17 step:16775 [D loss: 0.562453, acc.: 67.19%] [G loss: 0.522123]\n",
      "epoch:17 step:16776 [D loss: 0.582340, acc.: 67.19%] [G loss: 0.508209]\n",
      "epoch:17 step:16777 [D loss: 0.521439, acc.: 74.22%] [G loss: 0.454430]\n",
      "epoch:17 step:16778 [D loss: 0.528944, acc.: 72.66%] [G loss: 0.423314]\n",
      "epoch:17 step:16779 [D loss: 0.543880, acc.: 70.31%] [G loss: 0.456760]\n",
      "epoch:17 step:16780 [D loss: 0.635096, acc.: 59.38%] [G loss: 0.525857]\n",
      "epoch:17 step:16781 [D loss: 0.571553, acc.: 69.53%] [G loss: 0.521355]\n",
      "epoch:17 step:16782 [D loss: 0.538386, acc.: 73.44%] [G loss: 0.646121]\n",
      "epoch:17 step:16783 [D loss: 0.476225, acc.: 70.31%] [G loss: 0.795785]\n",
      "epoch:17 step:16784 [D loss: 0.555077, acc.: 67.19%] [G loss: 0.671381]\n",
      "epoch:17 step:16785 [D loss: 0.611465, acc.: 67.97%] [G loss: 0.592690]\n",
      "epoch:17 step:16786 [D loss: 0.466270, acc.: 75.00%] [G loss: 0.561388]\n",
      "epoch:17 step:16787 [D loss: 0.631418, acc.: 65.62%] [G loss: 0.620068]\n",
      "epoch:17 step:16788 [D loss: 0.503217, acc.: 74.22%] [G loss: 0.732638]\n",
      "epoch:17 step:16789 [D loss: 0.444192, acc.: 82.03%] [G loss: 0.761135]\n",
      "epoch:17 step:16790 [D loss: 0.596533, acc.: 66.41%] [G loss: 0.717674]\n",
      "epoch:17 step:16791 [D loss: 0.606097, acc.: 65.62%] [G loss: 0.462780]\n",
      "epoch:17 step:16792 [D loss: 0.552170, acc.: 69.53%] [G loss: 0.542961]\n",
      "epoch:17 step:16793 [D loss: 0.519374, acc.: 72.66%] [G loss: 0.588820]\n",
      "epoch:17 step:16794 [D loss: 0.580103, acc.: 67.19%] [G loss: 0.435659]\n",
      "epoch:17 step:16795 [D loss: 0.534895, acc.: 72.66%] [G loss: 0.486950]\n",
      "epoch:17 step:16796 [D loss: 0.623680, acc.: 63.28%] [G loss: 0.538481]\n",
      "epoch:17 step:16797 [D loss: 0.484578, acc.: 77.34%] [G loss: 0.514597]\n",
      "epoch:17 step:16798 [D loss: 0.548643, acc.: 66.41%] [G loss: 0.508564]\n",
      "epoch:17 step:16799 [D loss: 0.485020, acc.: 75.00%] [G loss: 0.547551]\n",
      "epoch:17 step:16800 [D loss: 0.553829, acc.: 71.88%] [G loss: 0.595908]\n",
      "##############\n",
      "[2.79800455 1.05202456 6.10152668 4.94094408 3.66434278 5.55753327\n",
      " 4.55881079 4.82427853 4.94361679 4.21986266]\n",
      "##########\n",
      "epoch:17 step:16801 [D loss: 0.504021, acc.: 74.22%] [G loss: 0.651297]\n",
      "epoch:17 step:16802 [D loss: 0.614807, acc.: 64.06%] [G loss: 0.665144]\n",
      "epoch:17 step:16803 [D loss: 0.576246, acc.: 66.41%] [G loss: 0.597971]\n",
      "epoch:17 step:16804 [D loss: 0.512371, acc.: 73.44%] [G loss: 0.593118]\n",
      "epoch:17 step:16805 [D loss: 0.556286, acc.: 69.53%] [G loss: 0.714442]\n",
      "epoch:17 step:16806 [D loss: 0.617020, acc.: 59.38%] [G loss: 0.424715]\n",
      "epoch:17 step:16807 [D loss: 0.549750, acc.: 70.31%] [G loss: 0.494721]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16808 [D loss: 0.523972, acc.: 75.00%] [G loss: 0.635121]\n",
      "epoch:17 step:16809 [D loss: 0.642361, acc.: 64.84%] [G loss: 0.659202]\n",
      "epoch:17 step:16810 [D loss: 0.553770, acc.: 71.09%] [G loss: 0.614202]\n",
      "epoch:17 step:16811 [D loss: 0.635509, acc.: 60.94%] [G loss: 0.469139]\n",
      "epoch:17 step:16812 [D loss: 0.598539, acc.: 64.06%] [G loss: 0.475649]\n",
      "epoch:17 step:16813 [D loss: 0.507097, acc.: 71.88%] [G loss: 0.668344]\n",
      "epoch:17 step:16814 [D loss: 0.547306, acc.: 69.53%] [G loss: 0.766504]\n",
      "epoch:17 step:16815 [D loss: 0.505740, acc.: 74.22%] [G loss: 0.683694]\n",
      "epoch:17 step:16816 [D loss: 0.592065, acc.: 64.84%] [G loss: 0.714504]\n",
      "epoch:17 step:16817 [D loss: 0.529630, acc.: 70.31%] [G loss: 0.762355]\n",
      "epoch:17 step:16818 [D loss: 0.566088, acc.: 67.19%] [G loss: 0.552813]\n",
      "epoch:17 step:16819 [D loss: 0.507234, acc.: 75.00%] [G loss: 0.665879]\n",
      "epoch:17 step:16820 [D loss: 0.583703, acc.: 67.97%] [G loss: 0.732996]\n",
      "epoch:17 step:16821 [D loss: 0.663243, acc.: 60.94%] [G loss: 0.600721]\n",
      "epoch:17 step:16822 [D loss: 0.517564, acc.: 70.31%] [G loss: 0.688415]\n",
      "epoch:17 step:16823 [D loss: 0.510967, acc.: 77.34%] [G loss: 0.700837]\n",
      "epoch:17 step:16824 [D loss: 0.511408, acc.: 75.00%] [G loss: 0.769186]\n",
      "epoch:17 step:16825 [D loss: 0.519872, acc.: 75.78%] [G loss: 0.707689]\n",
      "epoch:17 step:16826 [D loss: 0.466694, acc.: 77.34%] [G loss: 0.727041]\n",
      "epoch:17 step:16827 [D loss: 0.460462, acc.: 82.03%] [G loss: 0.718052]\n",
      "epoch:17 step:16828 [D loss: 0.449447, acc.: 81.25%] [G loss: 0.889678]\n",
      "epoch:17 step:16829 [D loss: 0.556916, acc.: 72.66%] [G loss: 0.856197]\n",
      "epoch:17 step:16830 [D loss: 0.505726, acc.: 72.66%] [G loss: 0.740627]\n",
      "epoch:17 step:16831 [D loss: 0.580078, acc.: 64.84%] [G loss: 0.629067]\n",
      "epoch:17 step:16832 [D loss: 0.544334, acc.: 73.44%] [G loss: 0.599829]\n",
      "epoch:17 step:16833 [D loss: 0.580308, acc.: 68.75%] [G loss: 0.609096]\n",
      "epoch:17 step:16834 [D loss: 0.611771, acc.: 60.16%] [G loss: 0.667180]\n",
      "epoch:17 step:16835 [D loss: 0.541711, acc.: 70.31%] [G loss: 0.764109]\n",
      "epoch:17 step:16836 [D loss: 0.508804, acc.: 74.22%] [G loss: 0.673134]\n",
      "epoch:17 step:16837 [D loss: 0.543015, acc.: 67.19%] [G loss: 0.764986]\n",
      "epoch:17 step:16838 [D loss: 0.513413, acc.: 71.09%] [G loss: 0.642665]\n",
      "epoch:17 step:16839 [D loss: 0.591898, acc.: 64.06%] [G loss: 0.592002]\n",
      "epoch:17 step:16840 [D loss: 0.462708, acc.: 78.12%] [G loss: 0.857263]\n",
      "epoch:17 step:16841 [D loss: 0.467023, acc.: 78.91%] [G loss: 1.002141]\n",
      "epoch:17 step:16842 [D loss: 0.604943, acc.: 71.88%] [G loss: 0.720619]\n",
      "epoch:17 step:16843 [D loss: 0.524795, acc.: 75.78%] [G loss: 0.931515]\n",
      "epoch:17 step:16844 [D loss: 0.629730, acc.: 64.84%] [G loss: 0.653157]\n",
      "epoch:17 step:16845 [D loss: 0.508467, acc.: 72.66%] [G loss: 0.845929]\n",
      "epoch:17 step:16846 [D loss: 0.575626, acc.: 67.97%] [G loss: 0.846542]\n",
      "epoch:17 step:16847 [D loss: 0.505619, acc.: 78.12%] [G loss: 0.783622]\n",
      "epoch:17 step:16848 [D loss: 0.541986, acc.: 67.19%] [G loss: 0.683195]\n",
      "epoch:17 step:16849 [D loss: 0.746872, acc.: 60.16%] [G loss: 0.688557]\n",
      "epoch:17 step:16850 [D loss: 0.505720, acc.: 75.00%] [G loss: 0.603343]\n",
      "epoch:17 step:16851 [D loss: 0.566602, acc.: 66.41%] [G loss: 0.581394]\n",
      "epoch:17 step:16852 [D loss: 0.460687, acc.: 80.47%] [G loss: 0.633490]\n",
      "epoch:17 step:16853 [D loss: 0.477577, acc.: 78.91%] [G loss: 0.702373]\n",
      "epoch:17 step:16854 [D loss: 0.440455, acc.: 75.78%] [G loss: 0.993543]\n",
      "epoch:17 step:16855 [D loss: 0.440155, acc.: 78.12%] [G loss: 1.031828]\n",
      "epoch:17 step:16856 [D loss: 0.513423, acc.: 72.66%] [G loss: 1.015472]\n",
      "epoch:17 step:16857 [D loss: 0.697775, acc.: 67.19%] [G loss: 0.939730]\n",
      "epoch:17 step:16858 [D loss: 0.572336, acc.: 72.66%] [G loss: 1.313232]\n",
      "epoch:17 step:16859 [D loss: 0.441491, acc.: 76.56%] [G loss: 1.225936]\n",
      "epoch:17 step:16860 [D loss: 0.559094, acc.: 68.75%] [G loss: 0.874946]\n",
      "epoch:17 step:16861 [D loss: 0.627889, acc.: 64.84%] [G loss: 0.791214]\n",
      "epoch:17 step:16862 [D loss: 0.464996, acc.: 78.12%] [G loss: 0.944830]\n",
      "epoch:17 step:16863 [D loss: 0.540758, acc.: 71.09%] [G loss: 0.875234]\n",
      "epoch:17 step:16864 [D loss: 0.490010, acc.: 74.22%] [G loss: 0.812889]\n",
      "epoch:17 step:16865 [D loss: 0.400190, acc.: 81.25%] [G loss: 1.005751]\n",
      "epoch:17 step:16866 [D loss: 0.416238, acc.: 82.81%] [G loss: 1.330083]\n",
      "epoch:18 step:16867 [D loss: 0.585646, acc.: 68.75%] [G loss: 1.058145]\n",
      "epoch:18 step:16868 [D loss: 0.461628, acc.: 75.00%] [G loss: 1.124345]\n",
      "epoch:18 step:16869 [D loss: 0.587350, acc.: 69.53%] [G loss: 0.937648]\n",
      "epoch:18 step:16870 [D loss: 0.531239, acc.: 75.00%] [G loss: 0.808099]\n",
      "epoch:18 step:16871 [D loss: 0.548633, acc.: 71.09%] [G loss: 0.748009]\n",
      "epoch:18 step:16872 [D loss: 0.595846, acc.: 70.31%] [G loss: 0.703498]\n",
      "epoch:18 step:16873 [D loss: 0.496854, acc.: 73.44%] [G loss: 0.731666]\n",
      "epoch:18 step:16874 [D loss: 0.539317, acc.: 67.97%] [G loss: 0.756891]\n",
      "epoch:18 step:16875 [D loss: 0.508027, acc.: 77.34%] [G loss: 0.711656]\n",
      "epoch:18 step:16876 [D loss: 0.494637, acc.: 73.44%] [G loss: 0.700698]\n",
      "epoch:18 step:16877 [D loss: 0.463012, acc.: 75.78%] [G loss: 0.812912]\n",
      "epoch:18 step:16878 [D loss: 0.559266, acc.: 68.75%] [G loss: 0.734033]\n",
      "epoch:18 step:16879 [D loss: 0.574616, acc.: 71.09%] [G loss: 0.596182]\n",
      "epoch:18 step:16880 [D loss: 0.520182, acc.: 72.66%] [G loss: 0.561609]\n",
      "epoch:18 step:16881 [D loss: 0.485594, acc.: 74.22%] [G loss: 0.784831]\n",
      "epoch:18 step:16882 [D loss: 0.500695, acc.: 76.56%] [G loss: 0.761378]\n",
      "epoch:18 step:16883 [D loss: 0.554431, acc.: 71.09%] [G loss: 0.787159]\n",
      "epoch:18 step:16884 [D loss: 0.598957, acc.: 66.41%] [G loss: 0.594887]\n",
      "epoch:18 step:16885 [D loss: 0.542963, acc.: 74.22%] [G loss: 0.601620]\n",
      "epoch:18 step:16886 [D loss: 0.667715, acc.: 62.50%] [G loss: 0.687800]\n",
      "epoch:18 step:16887 [D loss: 0.576530, acc.: 67.19%] [G loss: 0.605504]\n",
      "epoch:18 step:16888 [D loss: 0.463797, acc.: 76.56%] [G loss: 0.698807]\n",
      "epoch:18 step:16889 [D loss: 0.540611, acc.: 71.09%] [G loss: 0.602470]\n",
      "epoch:18 step:16890 [D loss: 0.570066, acc.: 66.41%] [G loss: 0.606990]\n",
      "epoch:18 step:16891 [D loss: 0.522711, acc.: 70.31%] [G loss: 0.800612]\n",
      "epoch:18 step:16892 [D loss: 0.555372, acc.: 69.53%] [G loss: 0.562313]\n",
      "epoch:18 step:16893 [D loss: 0.452803, acc.: 76.56%] [G loss: 0.712616]\n",
      "epoch:18 step:16894 [D loss: 0.569667, acc.: 68.75%] [G loss: 0.516692]\n",
      "epoch:18 step:16895 [D loss: 0.510618, acc.: 71.88%] [G loss: 0.655705]\n",
      "epoch:18 step:16896 [D loss: 0.539426, acc.: 72.66%] [G loss: 0.612206]\n",
      "epoch:18 step:16897 [D loss: 0.602244, acc.: 67.19%] [G loss: 0.639202]\n",
      "epoch:18 step:16898 [D loss: 0.553607, acc.: 71.09%] [G loss: 0.599924]\n",
      "epoch:18 step:16899 [D loss: 0.540437, acc.: 71.88%] [G loss: 0.525241]\n",
      "epoch:18 step:16900 [D loss: 0.585189, acc.: 69.53%] [G loss: 0.665542]\n",
      "epoch:18 step:16901 [D loss: 0.558263, acc.: 69.53%] [G loss: 0.524392]\n",
      "epoch:18 step:16902 [D loss: 0.520724, acc.: 73.44%] [G loss: 0.732151]\n",
      "epoch:18 step:16903 [D loss: 0.460420, acc.: 78.12%] [G loss: 0.792863]\n",
      "epoch:18 step:16904 [D loss: 0.605758, acc.: 67.97%] [G loss: 0.572726]\n",
      "epoch:18 step:16905 [D loss: 0.569049, acc.: 67.19%] [G loss: 0.489341]\n",
      "epoch:18 step:16906 [D loss: 0.472907, acc.: 78.12%] [G loss: 0.640767]\n",
      "epoch:18 step:16907 [D loss: 0.550463, acc.: 71.88%] [G loss: 0.737039]\n",
      "epoch:18 step:16908 [D loss: 0.546610, acc.: 70.31%] [G loss: 0.623672]\n",
      "epoch:18 step:16909 [D loss: 0.511413, acc.: 75.00%] [G loss: 0.627834]\n",
      "epoch:18 step:16910 [D loss: 0.617399, acc.: 64.84%] [G loss: 0.569349]\n",
      "epoch:18 step:16911 [D loss: 0.482120, acc.: 77.34%] [G loss: 0.620510]\n",
      "epoch:18 step:16912 [D loss: 0.499239, acc.: 73.44%] [G loss: 0.568082]\n",
      "epoch:18 step:16913 [D loss: 0.580554, acc.: 67.19%] [G loss: 0.653014]\n",
      "epoch:18 step:16914 [D loss: 0.546984, acc.: 73.44%] [G loss: 0.691079]\n",
      "epoch:18 step:16915 [D loss: 0.493389, acc.: 71.09%] [G loss: 0.775704]\n",
      "epoch:18 step:16916 [D loss: 0.541475, acc.: 67.19%] [G loss: 0.589806]\n",
      "epoch:18 step:16917 [D loss: 0.650502, acc.: 58.59%] [G loss: 0.732785]\n",
      "epoch:18 step:16918 [D loss: 0.565523, acc.: 70.31%] [G loss: 0.530503]\n",
      "epoch:18 step:16919 [D loss: 0.512178, acc.: 71.88%] [G loss: 0.634059]\n",
      "epoch:18 step:16920 [D loss: 0.505253, acc.: 78.12%] [G loss: 0.725303]\n",
      "epoch:18 step:16921 [D loss: 0.545476, acc.: 75.78%] [G loss: 0.668224]\n",
      "epoch:18 step:16922 [D loss: 0.486842, acc.: 75.78%] [G loss: 0.804970]\n",
      "epoch:18 step:16923 [D loss: 0.517509, acc.: 73.44%] [G loss: 0.570614]\n",
      "epoch:18 step:16924 [D loss: 0.527298, acc.: 69.53%] [G loss: 0.593642]\n",
      "epoch:18 step:16925 [D loss: 0.508110, acc.: 71.88%] [G loss: 0.738908]\n",
      "epoch:18 step:16926 [D loss: 0.507156, acc.: 72.66%] [G loss: 0.740767]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:16927 [D loss: 0.576478, acc.: 69.53%] [G loss: 0.652743]\n",
      "epoch:18 step:16928 [D loss: 0.573536, acc.: 65.62%] [G loss: 0.560899]\n",
      "epoch:18 step:16929 [D loss: 0.478552, acc.: 72.66%] [G loss: 0.828476]\n",
      "epoch:18 step:16930 [D loss: 0.542511, acc.: 76.56%] [G loss: 0.626696]\n",
      "epoch:18 step:16931 [D loss: 0.489214, acc.: 74.22%] [G loss: 0.581705]\n",
      "epoch:18 step:16932 [D loss: 0.571355, acc.: 70.31%] [G loss: 0.693798]\n",
      "epoch:18 step:16933 [D loss: 0.552486, acc.: 71.09%] [G loss: 0.619608]\n",
      "epoch:18 step:16934 [D loss: 0.563821, acc.: 65.62%] [G loss: 0.605780]\n",
      "epoch:18 step:16935 [D loss: 0.464526, acc.: 78.91%] [G loss: 0.638759]\n",
      "epoch:18 step:16936 [D loss: 0.519267, acc.: 77.34%] [G loss: 0.758611]\n",
      "epoch:18 step:16937 [D loss: 0.513720, acc.: 74.22%] [G loss: 0.662050]\n",
      "epoch:18 step:16938 [D loss: 0.546564, acc.: 67.19%] [G loss: 0.589923]\n",
      "epoch:18 step:16939 [D loss: 0.558186, acc.: 70.31%] [G loss: 0.588821]\n",
      "epoch:18 step:16940 [D loss: 0.484265, acc.: 75.78%] [G loss: 0.699187]\n",
      "epoch:18 step:16941 [D loss: 0.583543, acc.: 67.97%] [G loss: 0.674487]\n",
      "epoch:18 step:16942 [D loss: 0.487593, acc.: 76.56%] [G loss: 0.730060]\n",
      "epoch:18 step:16943 [D loss: 0.400931, acc.: 79.69%] [G loss: 0.790495]\n",
      "epoch:18 step:16944 [D loss: 0.576871, acc.: 69.53%] [G loss: 0.660093]\n",
      "epoch:18 step:16945 [D loss: 0.549402, acc.: 69.53%] [G loss: 0.791115]\n",
      "epoch:18 step:16946 [D loss: 0.492678, acc.: 74.22%] [G loss: 0.660209]\n",
      "epoch:18 step:16947 [D loss: 0.550898, acc.: 68.75%] [G loss: 0.615564]\n",
      "epoch:18 step:16948 [D loss: 0.523477, acc.: 67.19%] [G loss: 0.718518]\n",
      "epoch:18 step:16949 [D loss: 0.523075, acc.: 71.09%] [G loss: 0.884674]\n",
      "epoch:18 step:16950 [D loss: 0.588590, acc.: 70.31%] [G loss: 0.726777]\n",
      "epoch:18 step:16951 [D loss: 0.615821, acc.: 65.62%] [G loss: 0.594332]\n",
      "epoch:18 step:16952 [D loss: 0.567220, acc.: 70.31%] [G loss: 0.744076]\n",
      "epoch:18 step:16953 [D loss: 0.529059, acc.: 70.31%] [G loss: 0.719546]\n",
      "epoch:18 step:16954 [D loss: 0.517048, acc.: 75.78%] [G loss: 0.695182]\n",
      "epoch:18 step:16955 [D loss: 0.561383, acc.: 73.44%] [G loss: 0.735876]\n",
      "epoch:18 step:16956 [D loss: 0.517762, acc.: 70.31%] [G loss: 0.596249]\n",
      "epoch:18 step:16957 [D loss: 0.541635, acc.: 75.00%] [G loss: 0.617330]\n",
      "epoch:18 step:16958 [D loss: 0.431123, acc.: 81.25%] [G loss: 0.766316]\n",
      "epoch:18 step:16959 [D loss: 0.498224, acc.: 73.44%] [G loss: 0.771899]\n",
      "epoch:18 step:16960 [D loss: 0.499485, acc.: 72.66%] [G loss: 0.710778]\n",
      "epoch:18 step:16961 [D loss: 0.519286, acc.: 75.00%] [G loss: 0.648382]\n",
      "epoch:18 step:16962 [D loss: 0.498631, acc.: 75.78%] [G loss: 0.647476]\n",
      "epoch:18 step:16963 [D loss: 0.500615, acc.: 70.31%] [G loss: 0.590300]\n",
      "epoch:18 step:16964 [D loss: 0.555201, acc.: 71.09%] [G loss: 0.690273]\n",
      "epoch:18 step:16965 [D loss: 0.490921, acc.: 76.56%] [G loss: 0.601225]\n",
      "epoch:18 step:16966 [D loss: 0.481839, acc.: 75.78%] [G loss: 0.813454]\n",
      "epoch:18 step:16967 [D loss: 0.523433, acc.: 72.66%] [G loss: 0.805442]\n",
      "epoch:18 step:16968 [D loss: 0.593728, acc.: 68.75%] [G loss: 0.705264]\n",
      "epoch:18 step:16969 [D loss: 0.497129, acc.: 69.53%] [G loss: 0.661984]\n",
      "epoch:18 step:16970 [D loss: 0.487831, acc.: 76.56%] [G loss: 0.771445]\n",
      "epoch:18 step:16971 [D loss: 0.599592, acc.: 65.62%] [G loss: 0.683755]\n",
      "epoch:18 step:16972 [D loss: 0.534797, acc.: 66.41%] [G loss: 0.645629]\n",
      "epoch:18 step:16973 [D loss: 0.524144, acc.: 74.22%] [G loss: 0.651746]\n",
      "epoch:18 step:16974 [D loss: 0.641822, acc.: 62.50%] [G loss: 0.614530]\n",
      "epoch:18 step:16975 [D loss: 0.603209, acc.: 61.72%] [G loss: 0.518710]\n",
      "epoch:18 step:16976 [D loss: 0.559308, acc.: 71.09%] [G loss: 0.551477]\n",
      "epoch:18 step:16977 [D loss: 0.485410, acc.: 75.00%] [G loss: 0.581321]\n",
      "epoch:18 step:16978 [D loss: 0.511227, acc.: 73.44%] [G loss: 0.683977]\n",
      "epoch:18 step:16979 [D loss: 0.535210, acc.: 71.88%] [G loss: 0.661300]\n",
      "epoch:18 step:16980 [D loss: 0.577804, acc.: 71.09%] [G loss: 0.557400]\n",
      "epoch:18 step:16981 [D loss: 0.550772, acc.: 75.00%] [G loss: 0.704512]\n",
      "epoch:18 step:16982 [D loss: 0.520865, acc.: 67.19%] [G loss: 0.687694]\n",
      "epoch:18 step:16983 [D loss: 0.492671, acc.: 75.78%] [G loss: 0.839254]\n",
      "epoch:18 step:16984 [D loss: 0.550874, acc.: 71.88%] [G loss: 0.916874]\n",
      "epoch:18 step:16985 [D loss: 0.483481, acc.: 73.44%] [G loss: 0.953119]\n",
      "epoch:18 step:16986 [D loss: 0.563534, acc.: 71.09%] [G loss: 0.679668]\n",
      "epoch:18 step:16987 [D loss: 0.531860, acc.: 71.88%] [G loss: 0.628209]\n",
      "epoch:18 step:16988 [D loss: 0.464263, acc.: 80.47%] [G loss: 0.883454]\n",
      "epoch:18 step:16989 [D loss: 0.537185, acc.: 75.00%] [G loss: 0.783749]\n",
      "epoch:18 step:16990 [D loss: 0.566164, acc.: 73.44%] [G loss: 0.516207]\n",
      "epoch:18 step:16991 [D loss: 0.543543, acc.: 69.53%] [G loss: 0.708350]\n",
      "epoch:18 step:16992 [D loss: 0.474121, acc.: 78.91%] [G loss: 0.761971]\n",
      "epoch:18 step:16993 [D loss: 0.438683, acc.: 80.47%] [G loss: 0.791376]\n",
      "epoch:18 step:16994 [D loss: 0.485628, acc.: 76.56%] [G loss: 0.663235]\n",
      "epoch:18 step:16995 [D loss: 0.590384, acc.: 67.97%] [G loss: 0.546585]\n",
      "epoch:18 step:16996 [D loss: 0.483915, acc.: 77.34%] [G loss: 0.650904]\n",
      "epoch:18 step:16997 [D loss: 0.474404, acc.: 78.91%] [G loss: 0.634128]\n",
      "epoch:18 step:16998 [D loss: 0.574387, acc.: 71.09%] [G loss: 0.742366]\n",
      "epoch:18 step:16999 [D loss: 0.533263, acc.: 71.88%] [G loss: 0.742430]\n",
      "epoch:18 step:17000 [D loss: 0.568799, acc.: 70.31%] [G loss: 0.875630]\n",
      "##############\n",
      "[3.09346719 1.24151288 6.1704418  4.91133643 3.73159336 5.83937325\n",
      " 5.01145088 4.97707625 4.85769112 4.13677577]\n",
      "##########\n",
      "epoch:18 step:17001 [D loss: 0.502478, acc.: 75.00%] [G loss: 0.963158]\n",
      "epoch:18 step:17002 [D loss: 0.534525, acc.: 70.31%] [G loss: 0.734252]\n",
      "epoch:18 step:17003 [D loss: 0.642754, acc.: 67.19%] [G loss: 0.582985]\n",
      "epoch:18 step:17004 [D loss: 0.573831, acc.: 71.09%] [G loss: 0.664799]\n",
      "epoch:18 step:17005 [D loss: 0.542169, acc.: 69.53%] [G loss: 0.641632]\n",
      "epoch:18 step:17006 [D loss: 0.573402, acc.: 64.84%] [G loss: 0.617953]\n",
      "epoch:18 step:17007 [D loss: 0.534091, acc.: 67.19%] [G loss: 0.711827]\n",
      "epoch:18 step:17008 [D loss: 0.572623, acc.: 67.97%] [G loss: 0.597977]\n",
      "epoch:18 step:17009 [D loss: 0.609473, acc.: 66.41%] [G loss: 0.732990]\n",
      "epoch:18 step:17010 [D loss: 0.511141, acc.: 72.66%] [G loss: 0.613203]\n",
      "epoch:18 step:17011 [D loss: 0.546142, acc.: 71.88%] [G loss: 0.629646]\n",
      "epoch:18 step:17012 [D loss: 0.477344, acc.: 82.03%] [G loss: 0.705340]\n",
      "epoch:18 step:17013 [D loss: 0.625129, acc.: 64.06%] [G loss: 0.511876]\n",
      "epoch:18 step:17014 [D loss: 0.590939, acc.: 67.19%] [G loss: 0.614367]\n",
      "epoch:18 step:17015 [D loss: 0.549769, acc.: 68.75%] [G loss: 0.704314]\n",
      "epoch:18 step:17016 [D loss: 0.564531, acc.: 67.97%] [G loss: 0.632203]\n",
      "epoch:18 step:17017 [D loss: 0.549687, acc.: 73.44%] [G loss: 0.484605]\n",
      "epoch:18 step:17018 [D loss: 0.583601, acc.: 69.53%] [G loss: 0.742086]\n",
      "epoch:18 step:17019 [D loss: 0.556029, acc.: 71.88%] [G loss: 0.628195]\n",
      "epoch:18 step:17020 [D loss: 0.529580, acc.: 73.44%] [G loss: 0.657837]\n",
      "epoch:18 step:17021 [D loss: 0.443953, acc.: 78.12%] [G loss: 0.699320]\n",
      "epoch:18 step:17022 [D loss: 0.483775, acc.: 75.78%] [G loss: 0.768129]\n",
      "epoch:18 step:17023 [D loss: 0.521443, acc.: 70.31%] [G loss: 0.817861]\n",
      "epoch:18 step:17024 [D loss: 0.553422, acc.: 66.41%] [G loss: 0.721102]\n",
      "epoch:18 step:17025 [D loss: 0.477826, acc.: 73.44%] [G loss: 0.724809]\n",
      "epoch:18 step:17026 [D loss: 0.612515, acc.: 64.84%] [G loss: 0.663853]\n",
      "epoch:18 step:17027 [D loss: 0.566012, acc.: 70.31%] [G loss: 0.617494]\n",
      "epoch:18 step:17028 [D loss: 0.479921, acc.: 75.78%] [G loss: 0.672384]\n",
      "epoch:18 step:17029 [D loss: 0.541217, acc.: 67.97%] [G loss: 0.961975]\n",
      "epoch:18 step:17030 [D loss: 0.537973, acc.: 72.66%] [G loss: 0.689237]\n",
      "epoch:18 step:17031 [D loss: 0.501208, acc.: 74.22%] [G loss: 0.580530]\n",
      "epoch:18 step:17032 [D loss: 0.515942, acc.: 72.66%] [G loss: 0.543969]\n",
      "epoch:18 step:17033 [D loss: 0.544569, acc.: 70.31%] [G loss: 0.516502]\n",
      "epoch:18 step:17034 [D loss: 0.567508, acc.: 64.06%] [G loss: 0.493123]\n",
      "epoch:18 step:17035 [D loss: 0.591340, acc.: 71.09%] [G loss: 0.457576]\n",
      "epoch:18 step:17036 [D loss: 0.498734, acc.: 75.00%] [G loss: 0.488732]\n",
      "epoch:18 step:17037 [D loss: 0.487702, acc.: 75.78%] [G loss: 0.578478]\n",
      "epoch:18 step:17038 [D loss: 0.555344, acc.: 66.41%] [G loss: 0.481534]\n",
      "epoch:18 step:17039 [D loss: 0.469197, acc.: 74.22%] [G loss: 0.601175]\n",
      "epoch:18 step:17040 [D loss: 0.576097, acc.: 64.06%] [G loss: 0.514783]\n",
      "epoch:18 step:17041 [D loss: 0.535346, acc.: 69.53%] [G loss: 0.638793]\n",
      "epoch:18 step:17042 [D loss: 0.526568, acc.: 68.75%] [G loss: 0.518338]\n",
      "epoch:18 step:17043 [D loss: 0.508690, acc.: 73.44%] [G loss: 0.517550]\n",
      "epoch:18 step:17044 [D loss: 0.549420, acc.: 70.31%] [G loss: 0.575638]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17045 [D loss: 0.540815, acc.: 67.97%] [G loss: 0.543482]\n",
      "epoch:18 step:17046 [D loss: 0.619221, acc.: 63.28%] [G loss: 0.533569]\n",
      "epoch:18 step:17047 [D loss: 0.563413, acc.: 65.62%] [G loss: 0.457610]\n",
      "epoch:18 step:17048 [D loss: 0.540014, acc.: 68.75%] [G loss: 0.587551]\n",
      "epoch:18 step:17049 [D loss: 0.568715, acc.: 67.19%] [G loss: 0.694440]\n",
      "epoch:18 step:17050 [D loss: 0.588213, acc.: 65.62%] [G loss: 0.530544]\n",
      "epoch:18 step:17051 [D loss: 0.533618, acc.: 69.53%] [G loss: 0.410580]\n",
      "epoch:18 step:17052 [D loss: 0.521796, acc.: 71.88%] [G loss: 0.539795]\n",
      "epoch:18 step:17053 [D loss: 0.629350, acc.: 64.06%] [G loss: 0.501455]\n",
      "epoch:18 step:17054 [D loss: 0.557682, acc.: 67.19%] [G loss: 0.563124]\n",
      "epoch:18 step:17055 [D loss: 0.570228, acc.: 69.53%] [G loss: 0.584808]\n",
      "epoch:18 step:17056 [D loss: 0.496515, acc.: 73.44%] [G loss: 0.674184]\n",
      "epoch:18 step:17057 [D loss: 0.451153, acc.: 78.12%] [G loss: 0.654503]\n",
      "epoch:18 step:17058 [D loss: 0.574333, acc.: 70.31%] [G loss: 0.624887]\n",
      "epoch:18 step:17059 [D loss: 0.571619, acc.: 66.41%] [G loss: 0.585857]\n",
      "epoch:18 step:17060 [D loss: 0.442060, acc.: 78.91%] [G loss: 0.818384]\n",
      "epoch:18 step:17061 [D loss: 0.541836, acc.: 73.44%] [G loss: 0.686503]\n",
      "epoch:18 step:17062 [D loss: 0.532567, acc.: 71.88%] [G loss: 0.588391]\n",
      "epoch:18 step:17063 [D loss: 0.549941, acc.: 70.31%] [G loss: 0.657753]\n",
      "epoch:18 step:17064 [D loss: 0.444925, acc.: 76.56%] [G loss: 0.718078]\n",
      "epoch:18 step:17065 [D loss: 0.492534, acc.: 73.44%] [G loss: 0.722774]\n",
      "epoch:18 step:17066 [D loss: 0.686112, acc.: 63.28%] [G loss: 0.569017]\n",
      "epoch:18 step:17067 [D loss: 0.543038, acc.: 71.09%] [G loss: 0.683840]\n",
      "epoch:18 step:17068 [D loss: 0.524797, acc.: 74.22%] [G loss: 0.677880]\n",
      "epoch:18 step:17069 [D loss: 0.617066, acc.: 64.84%] [G loss: 0.496989]\n",
      "epoch:18 step:17070 [D loss: 0.592843, acc.: 67.97%] [G loss: 0.599115]\n",
      "epoch:18 step:17071 [D loss: 0.516755, acc.: 68.75%] [G loss: 0.755892]\n",
      "epoch:18 step:17072 [D loss: 0.512130, acc.: 76.56%] [G loss: 0.886024]\n",
      "epoch:18 step:17073 [D loss: 0.465612, acc.: 76.56%] [G loss: 0.854099]\n",
      "epoch:18 step:17074 [D loss: 0.411321, acc.: 79.69%] [G loss: 0.939790]\n",
      "epoch:18 step:17075 [D loss: 0.465512, acc.: 78.12%] [G loss: 0.877503]\n",
      "epoch:18 step:17076 [D loss: 0.661587, acc.: 64.06%] [G loss: 0.623625]\n",
      "epoch:18 step:17077 [D loss: 0.580596, acc.: 67.97%] [G loss: 0.491091]\n",
      "epoch:18 step:17078 [D loss: 0.489092, acc.: 78.12%] [G loss: 0.520408]\n",
      "epoch:18 step:17079 [D loss: 0.573778, acc.: 70.31%] [G loss: 0.550492]\n",
      "epoch:18 step:17080 [D loss: 0.654547, acc.: 58.59%] [G loss: 0.624824]\n",
      "epoch:18 step:17081 [D loss: 0.607342, acc.: 63.28%] [G loss: 0.568319]\n",
      "epoch:18 step:17082 [D loss: 0.494782, acc.: 73.44%] [G loss: 0.677443]\n",
      "epoch:18 step:17083 [D loss: 0.518042, acc.: 70.31%] [G loss: 0.737993]\n",
      "epoch:18 step:17084 [D loss: 0.506964, acc.: 75.00%] [G loss: 0.644809]\n",
      "epoch:18 step:17085 [D loss: 0.481599, acc.: 78.12%] [G loss: 0.643846]\n",
      "epoch:18 step:17086 [D loss: 0.677849, acc.: 61.72%] [G loss: 0.568536]\n",
      "epoch:18 step:17087 [D loss: 0.547361, acc.: 70.31%] [G loss: 0.640723]\n",
      "epoch:18 step:17088 [D loss: 0.527487, acc.: 70.31%] [G loss: 0.818238]\n",
      "epoch:18 step:17089 [D loss: 0.538573, acc.: 74.22%] [G loss: 0.917815]\n",
      "epoch:18 step:17090 [D loss: 0.591656, acc.: 62.50%] [G loss: 0.606797]\n",
      "epoch:18 step:17091 [D loss: 0.519842, acc.: 78.12%] [G loss: 0.722206]\n",
      "epoch:18 step:17092 [D loss: 0.572361, acc.: 68.75%] [G loss: 0.720282]\n",
      "epoch:18 step:17093 [D loss: 0.582772, acc.: 67.19%] [G loss: 0.473258]\n",
      "epoch:18 step:17094 [D loss: 0.612493, acc.: 62.50%] [G loss: 0.487230]\n",
      "epoch:18 step:17095 [D loss: 0.543489, acc.: 69.53%] [G loss: 0.739686]\n",
      "epoch:18 step:17096 [D loss: 0.531760, acc.: 72.66%] [G loss: 0.555596]\n",
      "epoch:18 step:17097 [D loss: 0.467201, acc.: 76.56%] [G loss: 0.782603]\n",
      "epoch:18 step:17098 [D loss: 0.442596, acc.: 75.78%] [G loss: 0.853007]\n",
      "epoch:18 step:17099 [D loss: 0.536949, acc.: 71.88%] [G loss: 0.904671]\n",
      "epoch:18 step:17100 [D loss: 0.539361, acc.: 72.66%] [G loss: 0.696289]\n",
      "epoch:18 step:17101 [D loss: 0.547484, acc.: 67.97%] [G loss: 0.603889]\n",
      "epoch:18 step:17102 [D loss: 0.522694, acc.: 71.09%] [G loss: 0.584753]\n",
      "epoch:18 step:17103 [D loss: 0.534145, acc.: 69.53%] [G loss: 0.581593]\n",
      "epoch:18 step:17104 [D loss: 0.579732, acc.: 64.06%] [G loss: 0.524118]\n",
      "epoch:18 step:17105 [D loss: 0.514676, acc.: 74.22%] [G loss: 0.583792]\n",
      "epoch:18 step:17106 [D loss: 0.584816, acc.: 64.06%] [G loss: 0.610331]\n",
      "epoch:18 step:17107 [D loss: 0.508662, acc.: 73.44%] [G loss: 0.659183]\n",
      "epoch:18 step:17108 [D loss: 0.549832, acc.: 69.53%] [G loss: 0.635806]\n",
      "epoch:18 step:17109 [D loss: 0.498518, acc.: 71.88%] [G loss: 0.652820]\n",
      "epoch:18 step:17110 [D loss: 0.447108, acc.: 78.12%] [G loss: 0.646729]\n",
      "epoch:18 step:17111 [D loss: 0.529986, acc.: 72.66%] [G loss: 0.647517]\n",
      "epoch:18 step:17112 [D loss: 0.519875, acc.: 67.19%] [G loss: 0.707726]\n",
      "epoch:18 step:17113 [D loss: 0.596107, acc.: 67.19%] [G loss: 0.583908]\n",
      "epoch:18 step:17114 [D loss: 0.570998, acc.: 68.75%] [G loss: 0.708877]\n",
      "epoch:18 step:17115 [D loss: 0.581306, acc.: 70.31%] [G loss: 0.715745]\n",
      "epoch:18 step:17116 [D loss: 0.653199, acc.: 59.38%] [G loss: 0.557442]\n",
      "epoch:18 step:17117 [D loss: 0.637755, acc.: 58.59%] [G loss: 0.575485]\n",
      "epoch:18 step:17118 [D loss: 0.522076, acc.: 71.88%] [G loss: 0.733401]\n",
      "epoch:18 step:17119 [D loss: 0.535089, acc.: 73.44%] [G loss: 0.666548]\n",
      "epoch:18 step:17120 [D loss: 0.511853, acc.: 70.31%] [G loss: 0.760780]\n",
      "epoch:18 step:17121 [D loss: 0.502042, acc.: 73.44%] [G loss: 0.748900]\n",
      "epoch:18 step:17122 [D loss: 0.575439, acc.: 66.41%] [G loss: 0.527909]\n",
      "epoch:18 step:17123 [D loss: 0.559166, acc.: 64.84%] [G loss: 0.626710]\n",
      "epoch:18 step:17124 [D loss: 0.541431, acc.: 67.19%] [G loss: 0.673137]\n",
      "epoch:18 step:17125 [D loss: 0.544684, acc.: 67.19%] [G loss: 0.533492]\n",
      "epoch:18 step:17126 [D loss: 0.578908, acc.: 69.53%] [G loss: 0.540496]\n",
      "epoch:18 step:17127 [D loss: 0.498332, acc.: 74.22%] [G loss: 0.558434]\n",
      "epoch:18 step:17128 [D loss: 0.535155, acc.: 69.53%] [G loss: 0.487205]\n",
      "epoch:18 step:17129 [D loss: 0.599584, acc.: 70.31%] [G loss: 0.608789]\n",
      "epoch:18 step:17130 [D loss: 0.526109, acc.: 72.66%] [G loss: 0.747775]\n",
      "epoch:18 step:17131 [D loss: 0.538632, acc.: 71.09%] [G loss: 0.574254]\n",
      "epoch:18 step:17132 [D loss: 0.537010, acc.: 73.44%] [G loss: 0.564834]\n",
      "epoch:18 step:17133 [D loss: 0.552054, acc.: 74.22%] [G loss: 0.757713]\n",
      "epoch:18 step:17134 [D loss: 0.555248, acc.: 67.19%] [G loss: 0.642437]\n",
      "epoch:18 step:17135 [D loss: 0.530084, acc.: 69.53%] [G loss: 0.591190]\n",
      "epoch:18 step:17136 [D loss: 0.535849, acc.: 74.22%] [G loss: 0.601071]\n",
      "epoch:18 step:17137 [D loss: 0.472727, acc.: 71.88%] [G loss: 0.654988]\n",
      "epoch:18 step:17138 [D loss: 0.553852, acc.: 68.75%] [G loss: 0.641712]\n",
      "epoch:18 step:17139 [D loss: 0.503104, acc.: 75.78%] [G loss: 0.572611]\n",
      "epoch:18 step:17140 [D loss: 0.550529, acc.: 73.44%] [G loss: 0.647732]\n",
      "epoch:18 step:17141 [D loss: 0.569406, acc.: 71.09%] [G loss: 0.854419]\n",
      "epoch:18 step:17142 [D loss: 0.502615, acc.: 74.22%] [G loss: 0.729941]\n",
      "epoch:18 step:17143 [D loss: 0.668028, acc.: 64.06%] [G loss: 0.515763]\n",
      "epoch:18 step:17144 [D loss: 0.582516, acc.: 68.75%] [G loss: 0.534669]\n",
      "epoch:18 step:17145 [D loss: 0.559030, acc.: 64.84%] [G loss: 0.523694]\n",
      "epoch:18 step:17146 [D loss: 0.488173, acc.: 77.34%] [G loss: 0.672472]\n",
      "epoch:18 step:17147 [D loss: 0.535806, acc.: 70.31%] [G loss: 0.617614]\n",
      "epoch:18 step:17148 [D loss: 0.571039, acc.: 73.44%] [G loss: 0.650406]\n",
      "epoch:18 step:17149 [D loss: 0.512753, acc.: 78.12%] [G loss: 0.742625]\n",
      "epoch:18 step:17150 [D loss: 0.551419, acc.: 70.31%] [G loss: 0.569107]\n",
      "epoch:18 step:17151 [D loss: 0.491177, acc.: 71.88%] [G loss: 0.809085]\n",
      "epoch:18 step:17152 [D loss: 0.519537, acc.: 69.53%] [G loss: 0.689532]\n",
      "epoch:18 step:17153 [D loss: 0.587024, acc.: 61.72%] [G loss: 0.758790]\n",
      "epoch:18 step:17154 [D loss: 0.557858, acc.: 72.66%] [G loss: 0.776772]\n",
      "epoch:18 step:17155 [D loss: 0.544696, acc.: 65.62%] [G loss: 0.667401]\n",
      "epoch:18 step:17156 [D loss: 0.573143, acc.: 71.88%] [G loss: 0.556231]\n",
      "epoch:18 step:17157 [D loss: 0.614439, acc.: 63.28%] [G loss: 0.575974]\n",
      "epoch:18 step:17158 [D loss: 0.505017, acc.: 75.78%] [G loss: 0.614604]\n",
      "epoch:18 step:17159 [D loss: 0.576928, acc.: 70.31%] [G loss: 0.598857]\n",
      "epoch:18 step:17160 [D loss: 0.616720, acc.: 64.06%] [G loss: 0.423349]\n",
      "epoch:18 step:17161 [D loss: 0.552860, acc.: 71.88%] [G loss: 0.626874]\n",
      "epoch:18 step:17162 [D loss: 0.503990, acc.: 71.88%] [G loss: 0.543881]\n",
      "epoch:18 step:17163 [D loss: 0.541914, acc.: 64.84%] [G loss: 0.628063]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17164 [D loss: 0.514404, acc.: 72.66%] [G loss: 0.601633]\n",
      "epoch:18 step:17165 [D loss: 0.521531, acc.: 73.44%] [G loss: 0.549541]\n",
      "epoch:18 step:17166 [D loss: 0.478861, acc.: 73.44%] [G loss: 0.664365]\n",
      "epoch:18 step:17167 [D loss: 0.638693, acc.: 67.19%] [G loss: 0.508460]\n",
      "epoch:18 step:17168 [D loss: 0.557409, acc.: 71.09%] [G loss: 0.572702]\n",
      "epoch:18 step:17169 [D loss: 0.605737, acc.: 63.28%] [G loss: 0.542196]\n",
      "epoch:18 step:17170 [D loss: 0.534031, acc.: 67.97%] [G loss: 0.610576]\n",
      "epoch:18 step:17171 [D loss: 0.500718, acc.: 73.44%] [G loss: 0.811081]\n",
      "epoch:18 step:17172 [D loss: 0.523616, acc.: 72.66%] [G loss: 0.694719]\n",
      "epoch:18 step:17173 [D loss: 0.527337, acc.: 74.22%] [G loss: 0.801095]\n",
      "epoch:18 step:17174 [D loss: 0.511790, acc.: 73.44%] [G loss: 0.624453]\n",
      "epoch:18 step:17175 [D loss: 0.485696, acc.: 75.00%] [G loss: 0.590838]\n",
      "epoch:18 step:17176 [D loss: 0.504022, acc.: 75.78%] [G loss: 0.541393]\n",
      "epoch:18 step:17177 [D loss: 0.475555, acc.: 76.56%] [G loss: 0.813628]\n",
      "epoch:18 step:17178 [D loss: 0.487435, acc.: 78.91%] [G loss: 0.782984]\n",
      "epoch:18 step:17179 [D loss: 0.443329, acc.: 82.81%] [G loss: 0.936286]\n",
      "epoch:18 step:17180 [D loss: 0.416321, acc.: 82.81%] [G loss: 0.815341]\n",
      "epoch:18 step:17181 [D loss: 0.422551, acc.: 84.38%] [G loss: 0.936658]\n",
      "epoch:18 step:17182 [D loss: 0.667659, acc.: 60.94%] [G loss: 0.852046]\n",
      "epoch:18 step:17183 [D loss: 0.639478, acc.: 64.06%] [G loss: 0.564092]\n",
      "epoch:18 step:17184 [D loss: 0.523513, acc.: 69.53%] [G loss: 0.544477]\n",
      "epoch:18 step:17185 [D loss: 0.562577, acc.: 66.41%] [G loss: 0.608833]\n",
      "epoch:18 step:17186 [D loss: 0.608997, acc.: 66.41%] [G loss: 0.581034]\n",
      "epoch:18 step:17187 [D loss: 0.504613, acc.: 73.44%] [G loss: 0.673795]\n",
      "epoch:18 step:17188 [D loss: 0.611165, acc.: 63.28%] [G loss: 0.563902]\n",
      "epoch:18 step:17189 [D loss: 0.596462, acc.: 65.62%] [G loss: 0.553226]\n",
      "epoch:18 step:17190 [D loss: 0.558807, acc.: 71.88%] [G loss: 0.590967]\n",
      "epoch:18 step:17191 [D loss: 0.572113, acc.: 67.97%] [G loss: 0.506338]\n",
      "epoch:18 step:17192 [D loss: 0.482230, acc.: 73.44%] [G loss: 0.658380]\n",
      "epoch:18 step:17193 [D loss: 0.559027, acc.: 71.88%] [G loss: 0.705794]\n",
      "epoch:18 step:17194 [D loss: 0.504488, acc.: 75.00%] [G loss: 0.927618]\n",
      "epoch:18 step:17195 [D loss: 0.513752, acc.: 75.78%] [G loss: 0.698016]\n",
      "epoch:18 step:17196 [D loss: 0.579499, acc.: 67.97%] [G loss: 0.580131]\n",
      "epoch:18 step:17197 [D loss: 0.511180, acc.: 73.44%] [G loss: 0.548472]\n",
      "epoch:18 step:17198 [D loss: 0.538544, acc.: 68.75%] [G loss: 0.570132]\n",
      "epoch:18 step:17199 [D loss: 0.463004, acc.: 78.91%] [G loss: 0.558859]\n",
      "epoch:18 step:17200 [D loss: 0.497984, acc.: 73.44%] [G loss: 0.552575]\n",
      "##############\n",
      "[3.12414428 1.40348886 6.05051167 4.77497365 3.68014797 5.54886458\n",
      " 4.60333136 5.01855456 4.69949973 4.09059166]\n",
      "##########\n",
      "epoch:18 step:17201 [D loss: 0.527060, acc.: 74.22%] [G loss: 0.653345]\n",
      "epoch:18 step:17202 [D loss: 0.493084, acc.: 78.12%] [G loss: 0.742219]\n",
      "epoch:18 step:17203 [D loss: 0.564393, acc.: 70.31%] [G loss: 0.666718]\n",
      "epoch:18 step:17204 [D loss: 0.498695, acc.: 73.44%] [G loss: 0.915782]\n",
      "epoch:18 step:17205 [D loss: 0.534132, acc.: 70.31%] [G loss: 0.791255]\n",
      "epoch:18 step:17206 [D loss: 0.510034, acc.: 75.00%] [G loss: 0.902418]\n",
      "epoch:18 step:17207 [D loss: 0.609819, acc.: 71.09%] [G loss: 0.643748]\n",
      "epoch:18 step:17208 [D loss: 0.694517, acc.: 57.81%] [G loss: 0.593387]\n",
      "epoch:18 step:17209 [D loss: 0.536979, acc.: 71.09%] [G loss: 0.776863]\n",
      "epoch:18 step:17210 [D loss: 0.447827, acc.: 76.56%] [G loss: 0.957874]\n",
      "epoch:18 step:17211 [D loss: 0.649090, acc.: 60.16%] [G loss: 0.537595]\n",
      "epoch:18 step:17212 [D loss: 0.543289, acc.: 72.66%] [G loss: 0.743952]\n",
      "epoch:18 step:17213 [D loss: 0.424047, acc.: 82.81%] [G loss: 0.887425]\n",
      "epoch:18 step:17214 [D loss: 0.640114, acc.: 69.53%] [G loss: 0.652002]\n",
      "epoch:18 step:17215 [D loss: 0.724398, acc.: 53.91%] [G loss: 0.595825]\n",
      "epoch:18 step:17216 [D loss: 0.497205, acc.: 75.78%] [G loss: 0.687953]\n",
      "epoch:18 step:17217 [D loss: 0.564097, acc.: 65.62%] [G loss: 0.680279]\n",
      "epoch:18 step:17218 [D loss: 0.611575, acc.: 65.62%] [G loss: 0.618702]\n",
      "epoch:18 step:17219 [D loss: 0.562149, acc.: 68.75%] [G loss: 0.600965]\n",
      "epoch:18 step:17220 [D loss: 0.419995, acc.: 81.25%] [G loss: 0.771288]\n",
      "epoch:18 step:17221 [D loss: 0.538787, acc.: 71.88%] [G loss: 0.893303]\n",
      "epoch:18 step:17222 [D loss: 0.553622, acc.: 69.53%] [G loss: 0.696057]\n",
      "epoch:18 step:17223 [D loss: 0.474846, acc.: 78.91%] [G loss: 0.677349]\n",
      "epoch:18 step:17224 [D loss: 0.468302, acc.: 78.12%] [G loss: 0.737732]\n",
      "epoch:18 step:17225 [D loss: 0.476954, acc.: 77.34%] [G loss: 0.819055]\n",
      "epoch:18 step:17226 [D loss: 0.473576, acc.: 75.00%] [G loss: 0.811425]\n",
      "epoch:18 step:17227 [D loss: 0.473061, acc.: 81.25%] [G loss: 0.704929]\n",
      "epoch:18 step:17228 [D loss: 0.517485, acc.: 71.09%] [G loss: 0.714670]\n",
      "epoch:18 step:17229 [D loss: 0.578150, acc.: 69.53%] [G loss: 0.653060]\n",
      "epoch:18 step:17230 [D loss: 0.508475, acc.: 74.22%] [G loss: 0.650750]\n",
      "epoch:18 step:17231 [D loss: 0.609717, acc.: 67.19%] [G loss: 0.680401]\n",
      "epoch:18 step:17232 [D loss: 0.514388, acc.: 73.44%] [G loss: 0.668073]\n",
      "epoch:18 step:17233 [D loss: 0.588741, acc.: 67.19%] [G loss: 0.605276]\n",
      "epoch:18 step:17234 [D loss: 0.512557, acc.: 74.22%] [G loss: 0.627862]\n",
      "epoch:18 step:17235 [D loss: 0.516909, acc.: 73.44%] [G loss: 0.632734]\n",
      "epoch:18 step:17236 [D loss: 0.522567, acc.: 78.12%] [G loss: 0.714827]\n",
      "epoch:18 step:17237 [D loss: 0.508865, acc.: 76.56%] [G loss: 0.737502]\n",
      "epoch:18 step:17238 [D loss: 0.513792, acc.: 71.09%] [G loss: 0.693382]\n",
      "epoch:18 step:17239 [D loss: 0.528821, acc.: 71.88%] [G loss: 0.552117]\n",
      "epoch:18 step:17240 [D loss: 0.477386, acc.: 76.56%] [G loss: 0.689483]\n",
      "epoch:18 step:17241 [D loss: 0.526009, acc.: 74.22%] [G loss: 0.724226]\n",
      "epoch:18 step:17242 [D loss: 0.701899, acc.: 63.28%] [G loss: 0.575942]\n",
      "epoch:18 step:17243 [D loss: 0.571465, acc.: 63.28%] [G loss: 0.573311]\n",
      "epoch:18 step:17244 [D loss: 0.551005, acc.: 69.53%] [G loss: 0.625248]\n",
      "epoch:18 step:17245 [D loss: 0.538613, acc.: 74.22%] [G loss: 0.582152]\n",
      "epoch:18 step:17246 [D loss: 0.618839, acc.: 64.84%] [G loss: 0.534944]\n",
      "epoch:18 step:17247 [D loss: 0.504941, acc.: 75.00%] [G loss: 0.616791]\n",
      "epoch:18 step:17248 [D loss: 0.552095, acc.: 68.75%] [G loss: 0.664964]\n",
      "epoch:18 step:17249 [D loss: 0.557077, acc.: 68.75%] [G loss: 0.660856]\n",
      "epoch:18 step:17250 [D loss: 0.586663, acc.: 67.97%] [G loss: 0.608655]\n",
      "epoch:18 step:17251 [D loss: 0.555738, acc.: 67.97%] [G loss: 0.502388]\n",
      "epoch:18 step:17252 [D loss: 0.581836, acc.: 68.75%] [G loss: 0.520489]\n",
      "epoch:18 step:17253 [D loss: 0.573880, acc.: 65.62%] [G loss: 0.560178]\n",
      "epoch:18 step:17254 [D loss: 0.503619, acc.: 78.12%] [G loss: 0.682107]\n",
      "epoch:18 step:17255 [D loss: 0.551522, acc.: 71.88%] [G loss: 0.676654]\n",
      "epoch:18 step:17256 [D loss: 0.602855, acc.: 64.06%] [G loss: 0.531641]\n",
      "epoch:18 step:17257 [D loss: 0.543445, acc.: 70.31%] [G loss: 0.408014]\n",
      "epoch:18 step:17258 [D loss: 0.480192, acc.: 74.22%] [G loss: 0.615143]\n",
      "epoch:18 step:17259 [D loss: 0.549539, acc.: 71.88%] [G loss: 0.606043]\n",
      "epoch:18 step:17260 [D loss: 0.575372, acc.: 68.75%] [G loss: 0.656637]\n",
      "epoch:18 step:17261 [D loss: 0.504332, acc.: 73.44%] [G loss: 0.741974]\n",
      "epoch:18 step:17262 [D loss: 0.526957, acc.: 69.53%] [G loss: 0.635287]\n",
      "epoch:18 step:17263 [D loss: 0.650915, acc.: 57.03%] [G loss: 0.583598]\n",
      "epoch:18 step:17264 [D loss: 0.505125, acc.: 71.09%] [G loss: 0.697889]\n",
      "epoch:18 step:17265 [D loss: 0.515613, acc.: 76.56%] [G loss: 0.853593]\n",
      "epoch:18 step:17266 [D loss: 0.660724, acc.: 62.50%] [G loss: 0.647514]\n",
      "epoch:18 step:17267 [D loss: 0.668073, acc.: 60.16%] [G loss: 0.442993]\n",
      "epoch:18 step:17268 [D loss: 0.507143, acc.: 72.66%] [G loss: 0.574070]\n",
      "epoch:18 step:17269 [D loss: 0.474913, acc.: 75.78%] [G loss: 0.595551]\n",
      "epoch:18 step:17270 [D loss: 0.596407, acc.: 67.19%] [G loss: 0.568072]\n",
      "epoch:18 step:17271 [D loss: 0.550792, acc.: 68.75%] [G loss: 0.578648]\n",
      "epoch:18 step:17272 [D loss: 0.499198, acc.: 75.78%] [G loss: 0.678769]\n",
      "epoch:18 step:17273 [D loss: 0.560617, acc.: 66.41%] [G loss: 0.778053]\n",
      "epoch:18 step:17274 [D loss: 0.548353, acc.: 68.75%] [G loss: 0.714533]\n",
      "epoch:18 step:17275 [D loss: 0.502288, acc.: 68.75%] [G loss: 0.670220]\n",
      "epoch:18 step:17276 [D loss: 0.581495, acc.: 68.75%] [G loss: 0.493611]\n",
      "epoch:18 step:17277 [D loss: 0.550717, acc.: 68.75%] [G loss: 0.561581]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17278 [D loss: 0.629647, acc.: 60.94%] [G loss: 0.480016]\n",
      "epoch:18 step:17279 [D loss: 0.574919, acc.: 68.75%] [G loss: 0.683030]\n",
      "epoch:18 step:17280 [D loss: 0.550557, acc.: 67.97%] [G loss: 0.619823]\n",
      "epoch:18 step:17281 [D loss: 0.517297, acc.: 71.09%] [G loss: 0.703506]\n",
      "epoch:18 step:17282 [D loss: 0.518283, acc.: 74.22%] [G loss: 0.782471]\n",
      "epoch:18 step:17283 [D loss: 0.578249, acc.: 75.00%] [G loss: 0.710843]\n",
      "epoch:18 step:17284 [D loss: 0.624421, acc.: 60.94%] [G loss: 0.744402]\n",
      "epoch:18 step:17285 [D loss: 0.560983, acc.: 67.97%] [G loss: 0.801159]\n",
      "epoch:18 step:17286 [D loss: 0.598193, acc.: 64.84%] [G loss: 0.788402]\n",
      "epoch:18 step:17287 [D loss: 0.606087, acc.: 64.06%] [G loss: 0.542009]\n",
      "epoch:18 step:17288 [D loss: 0.598253, acc.: 64.84%] [G loss: 0.462313]\n",
      "epoch:18 step:17289 [D loss: 0.543782, acc.: 67.19%] [G loss: 0.530830]\n",
      "epoch:18 step:17290 [D loss: 0.585601, acc.: 67.97%] [G loss: 0.649275]\n",
      "epoch:18 step:17291 [D loss: 0.504382, acc.: 75.78%] [G loss: 0.737745]\n",
      "epoch:18 step:17292 [D loss: 0.459176, acc.: 74.22%] [G loss: 0.845231]\n",
      "epoch:18 step:17293 [D loss: 0.505793, acc.: 74.22%] [G loss: 0.870785]\n",
      "epoch:18 step:17294 [D loss: 0.536343, acc.: 67.19%] [G loss: 0.784969]\n",
      "epoch:18 step:17295 [D loss: 0.438731, acc.: 83.59%] [G loss: 0.717116]\n",
      "epoch:18 step:17296 [D loss: 0.532769, acc.: 71.09%] [G loss: 0.609105]\n",
      "epoch:18 step:17297 [D loss: 0.531488, acc.: 71.09%] [G loss: 0.772733]\n",
      "epoch:18 step:17298 [D loss: 0.535321, acc.: 70.31%] [G loss: 0.637854]\n",
      "epoch:18 step:17299 [D loss: 0.570097, acc.: 70.31%] [G loss: 0.790698]\n",
      "epoch:18 step:17300 [D loss: 0.537948, acc.: 75.00%] [G loss: 0.618102]\n",
      "epoch:18 step:17301 [D loss: 0.524773, acc.: 76.56%] [G loss: 0.760004]\n",
      "epoch:18 step:17302 [D loss: 0.493418, acc.: 71.88%] [G loss: 0.781137]\n",
      "epoch:18 step:17303 [D loss: 0.697499, acc.: 63.28%] [G loss: 0.625935]\n",
      "epoch:18 step:17304 [D loss: 0.573109, acc.: 65.62%] [G loss: 0.458598]\n",
      "epoch:18 step:17305 [D loss: 0.498120, acc.: 76.56%] [G loss: 0.670524]\n",
      "epoch:18 step:17306 [D loss: 0.519814, acc.: 69.53%] [G loss: 0.711724]\n",
      "epoch:18 step:17307 [D loss: 0.573476, acc.: 67.19%] [G loss: 0.778258]\n",
      "epoch:18 step:17308 [D loss: 0.568691, acc.: 67.97%] [G loss: 0.672694]\n",
      "epoch:18 step:17309 [D loss: 0.510305, acc.: 78.12%] [G loss: 0.698560]\n",
      "epoch:18 step:17310 [D loss: 0.533610, acc.: 67.97%] [G loss: 0.700161]\n",
      "epoch:18 step:17311 [D loss: 0.586740, acc.: 63.28%] [G loss: 0.606376]\n",
      "epoch:18 step:17312 [D loss: 0.489108, acc.: 75.00%] [G loss: 0.583994]\n",
      "epoch:18 step:17313 [D loss: 0.558506, acc.: 67.97%] [G loss: 0.761675]\n",
      "epoch:18 step:17314 [D loss: 0.562911, acc.: 67.19%] [G loss: 0.552014]\n",
      "epoch:18 step:17315 [D loss: 0.561552, acc.: 68.75%] [G loss: 0.835498]\n",
      "epoch:18 step:17316 [D loss: 0.488675, acc.: 76.56%] [G loss: 0.724586]\n",
      "epoch:18 step:17317 [D loss: 0.433574, acc.: 78.91%] [G loss: 0.850399]\n",
      "epoch:18 step:17318 [D loss: 0.479563, acc.: 75.00%] [G loss: 0.700353]\n",
      "epoch:18 step:17319 [D loss: 0.537309, acc.: 73.44%] [G loss: 0.747877]\n",
      "epoch:18 step:17320 [D loss: 0.572809, acc.: 70.31%] [G loss: 0.589472]\n",
      "epoch:18 step:17321 [D loss: 0.565684, acc.: 66.41%] [G loss: 0.569403]\n",
      "epoch:18 step:17322 [D loss: 0.586429, acc.: 65.62%] [G loss: 0.573248]\n",
      "epoch:18 step:17323 [D loss: 0.475000, acc.: 79.69%] [G loss: 0.654029]\n",
      "epoch:18 step:17324 [D loss: 0.625654, acc.: 61.72%] [G loss: 0.719357]\n",
      "epoch:18 step:17325 [D loss: 0.556009, acc.: 67.97%] [G loss: 0.663291]\n",
      "epoch:18 step:17326 [D loss: 0.487525, acc.: 72.66%] [G loss: 0.613502]\n",
      "epoch:18 step:17327 [D loss: 0.513112, acc.: 77.34%] [G loss: 0.705182]\n",
      "epoch:18 step:17328 [D loss: 0.556504, acc.: 61.72%] [G loss: 0.756747]\n",
      "epoch:18 step:17329 [D loss: 0.553234, acc.: 70.31%] [G loss: 0.563736]\n",
      "epoch:18 step:17330 [D loss: 0.507379, acc.: 76.56%] [G loss: 0.520248]\n",
      "epoch:18 step:17331 [D loss: 0.609499, acc.: 66.41%] [G loss: 0.545852]\n",
      "epoch:18 step:17332 [D loss: 0.490925, acc.: 79.69%] [G loss: 0.562442]\n",
      "epoch:18 step:17333 [D loss: 0.540939, acc.: 66.41%] [G loss: 0.842715]\n",
      "epoch:18 step:17334 [D loss: 0.584900, acc.: 65.62%] [G loss: 0.631090]\n",
      "epoch:18 step:17335 [D loss: 0.588506, acc.: 67.19%] [G loss: 0.688963]\n",
      "epoch:18 step:17336 [D loss: 0.501338, acc.: 78.12%] [G loss: 0.692556]\n",
      "epoch:18 step:17337 [D loss: 0.500443, acc.: 72.66%] [G loss: 0.819463]\n",
      "epoch:18 step:17338 [D loss: 0.463668, acc.: 80.47%] [G loss: 0.879266]\n",
      "epoch:18 step:17339 [D loss: 0.642027, acc.: 62.50%] [G loss: 0.700905]\n",
      "epoch:18 step:17340 [D loss: 0.599947, acc.: 58.59%] [G loss: 0.638102]\n",
      "epoch:18 step:17341 [D loss: 0.458051, acc.: 80.47%] [G loss: 0.802548]\n",
      "epoch:18 step:17342 [D loss: 0.576460, acc.: 74.22%] [G loss: 0.799397]\n",
      "epoch:18 step:17343 [D loss: 0.647845, acc.: 65.62%] [G loss: 0.588422]\n",
      "epoch:18 step:17344 [D loss: 0.584360, acc.: 71.09%] [G loss: 0.433190]\n",
      "epoch:18 step:17345 [D loss: 0.508113, acc.: 74.22%] [G loss: 0.574108]\n",
      "epoch:18 step:17346 [D loss: 0.610681, acc.: 63.28%] [G loss: 0.512909]\n",
      "epoch:18 step:17347 [D loss: 0.506188, acc.: 73.44%] [G loss: 0.517601]\n",
      "epoch:18 step:17348 [D loss: 0.582420, acc.: 65.62%] [G loss: 0.518913]\n",
      "epoch:18 step:17349 [D loss: 0.490035, acc.: 78.91%] [G loss: 0.668415]\n",
      "epoch:18 step:17350 [D loss: 0.526262, acc.: 71.88%] [G loss: 0.595196]\n",
      "epoch:18 step:17351 [D loss: 0.513497, acc.: 77.34%] [G loss: 0.698711]\n",
      "epoch:18 step:17352 [D loss: 0.562586, acc.: 68.75%] [G loss: 0.734969]\n",
      "epoch:18 step:17353 [D loss: 0.554027, acc.: 69.53%] [G loss: 0.714468]\n",
      "epoch:18 step:17354 [D loss: 0.550054, acc.: 68.75%] [G loss: 0.620494]\n",
      "epoch:18 step:17355 [D loss: 0.548197, acc.: 68.75%] [G loss: 0.647619]\n",
      "epoch:18 step:17356 [D loss: 0.546405, acc.: 73.44%] [G loss: 0.568881]\n",
      "epoch:18 step:17357 [D loss: 0.537207, acc.: 70.31%] [G loss: 0.584305]\n",
      "epoch:18 step:17358 [D loss: 0.611562, acc.: 68.75%] [G loss: 0.512260]\n",
      "epoch:18 step:17359 [D loss: 0.570818, acc.: 69.53%] [G loss: 0.640000]\n",
      "epoch:18 step:17360 [D loss: 0.553730, acc.: 73.44%] [G loss: 0.488585]\n",
      "epoch:18 step:17361 [D loss: 0.503154, acc.: 76.56%] [G loss: 0.583426]\n",
      "epoch:18 step:17362 [D loss: 0.558560, acc.: 72.66%] [G loss: 0.572270]\n",
      "epoch:18 step:17363 [D loss: 0.554044, acc.: 74.22%] [G loss: 0.637988]\n",
      "epoch:18 step:17364 [D loss: 0.503685, acc.: 73.44%] [G loss: 0.788197]\n",
      "epoch:18 step:17365 [D loss: 0.480147, acc.: 75.78%] [G loss: 0.822238]\n",
      "epoch:18 step:17366 [D loss: 0.516057, acc.: 76.56%] [G loss: 0.777523]\n",
      "epoch:18 step:17367 [D loss: 0.604216, acc.: 72.66%] [G loss: 0.561060]\n",
      "epoch:18 step:17368 [D loss: 0.583988, acc.: 66.41%] [G loss: 0.490595]\n",
      "epoch:18 step:17369 [D loss: 0.501847, acc.: 73.44%] [G loss: 0.650959]\n",
      "epoch:18 step:17370 [D loss: 0.501321, acc.: 78.91%] [G loss: 0.562248]\n",
      "epoch:18 step:17371 [D loss: 0.515400, acc.: 74.22%] [G loss: 0.581053]\n",
      "epoch:18 step:17372 [D loss: 0.467496, acc.: 76.56%] [G loss: 0.827577]\n",
      "epoch:18 step:17373 [D loss: 0.518431, acc.: 78.91%] [G loss: 0.828022]\n",
      "epoch:18 step:17374 [D loss: 0.435266, acc.: 83.59%] [G loss: 1.074204]\n",
      "epoch:18 step:17375 [D loss: 0.522342, acc.: 76.56%] [G loss: 0.816399]\n",
      "epoch:18 step:17376 [D loss: 0.626422, acc.: 67.19%] [G loss: 0.769632]\n",
      "epoch:18 step:17377 [D loss: 0.648882, acc.: 60.16%] [G loss: 0.411069]\n",
      "epoch:18 step:17378 [D loss: 0.552332, acc.: 66.41%] [G loss: 0.488519]\n",
      "epoch:18 step:17379 [D loss: 0.521277, acc.: 71.88%] [G loss: 0.599513]\n",
      "epoch:18 step:17380 [D loss: 0.526202, acc.: 69.53%] [G loss: 0.595398]\n",
      "epoch:18 step:17381 [D loss: 0.542350, acc.: 71.88%] [G loss: 0.589913]\n",
      "epoch:18 step:17382 [D loss: 0.505781, acc.: 75.00%] [G loss: 0.675255]\n",
      "epoch:18 step:17383 [D loss: 0.487022, acc.: 75.00%] [G loss: 0.608788]\n",
      "epoch:18 step:17384 [D loss: 0.536938, acc.: 69.53%] [G loss: 0.689808]\n",
      "epoch:18 step:17385 [D loss: 0.483508, acc.: 74.22%] [G loss: 0.694623]\n",
      "epoch:18 step:17386 [D loss: 0.453716, acc.: 76.56%] [G loss: 0.705248]\n",
      "epoch:18 step:17387 [D loss: 0.486747, acc.: 78.12%] [G loss: 0.740999]\n",
      "epoch:18 step:17388 [D loss: 0.504815, acc.: 72.66%] [G loss: 0.750811]\n",
      "epoch:18 step:17389 [D loss: 0.506439, acc.: 72.66%] [G loss: 0.796902]\n",
      "epoch:18 step:17390 [D loss: 0.532929, acc.: 71.88%] [G loss: 0.581440]\n",
      "epoch:18 step:17391 [D loss: 0.556681, acc.: 70.31%] [G loss: 0.624554]\n",
      "epoch:18 step:17392 [D loss: 0.549252, acc.: 66.41%] [G loss: 0.519978]\n",
      "epoch:18 step:17393 [D loss: 0.524782, acc.: 71.88%] [G loss: 0.665961]\n",
      "epoch:18 step:17394 [D loss: 0.678936, acc.: 61.72%] [G loss: 0.578567]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17395 [D loss: 0.612498, acc.: 64.06%] [G loss: 0.801029]\n",
      "epoch:18 step:17396 [D loss: 0.562885, acc.: 68.75%] [G loss: 0.547203]\n",
      "epoch:18 step:17397 [D loss: 0.600658, acc.: 64.06%] [G loss: 0.688105]\n",
      "epoch:18 step:17398 [D loss: 0.547877, acc.: 75.00%] [G loss: 0.698219]\n",
      "epoch:18 step:17399 [D loss: 0.546590, acc.: 68.75%] [G loss: 0.689541]\n",
      "epoch:18 step:17400 [D loss: 0.506286, acc.: 74.22%] [G loss: 0.680422]\n",
      "##############\n",
      "[3.33344961 0.75649572 6.03737104 5.06151    3.8201709  5.83471795\n",
      " 4.75663395 4.91773024 4.8102548  4.21131287]\n",
      "##########\n",
      "epoch:18 step:17401 [D loss: 0.603096, acc.: 64.84%] [G loss: 0.597224]\n",
      "epoch:18 step:17402 [D loss: 0.542092, acc.: 67.97%] [G loss: 0.619834]\n",
      "epoch:18 step:17403 [D loss: 0.577504, acc.: 67.19%] [G loss: 0.561349]\n",
      "epoch:18 step:17404 [D loss: 0.548950, acc.: 67.97%] [G loss: 0.529775]\n",
      "epoch:18 step:17405 [D loss: 0.523527, acc.: 69.53%] [G loss: 0.577304]\n",
      "epoch:18 step:17406 [D loss: 0.563562, acc.: 67.19%] [G loss: 0.538952]\n",
      "epoch:18 step:17407 [D loss: 0.528023, acc.: 68.75%] [G loss: 0.414576]\n",
      "epoch:18 step:17408 [D loss: 0.648341, acc.: 57.81%] [G loss: 0.505159]\n",
      "epoch:18 step:17409 [D loss: 0.590221, acc.: 64.06%] [G loss: 0.664967]\n",
      "epoch:18 step:17410 [D loss: 0.600407, acc.: 67.97%] [G loss: 0.774596]\n",
      "epoch:18 step:17411 [D loss: 0.577184, acc.: 64.84%] [G loss: 0.594158]\n",
      "epoch:18 step:17412 [D loss: 0.516243, acc.: 72.66%] [G loss: 0.753583]\n",
      "epoch:18 step:17413 [D loss: 0.577901, acc.: 67.19%] [G loss: 0.628136]\n",
      "epoch:18 step:17414 [D loss: 0.499436, acc.: 76.56%] [G loss: 0.590599]\n",
      "epoch:18 step:17415 [D loss: 0.538930, acc.: 71.88%] [G loss: 0.618644]\n",
      "epoch:18 step:17416 [D loss: 0.543603, acc.: 71.88%] [G loss: 0.632164]\n",
      "epoch:18 step:17417 [D loss: 0.531083, acc.: 71.09%] [G loss: 0.597500]\n",
      "epoch:18 step:17418 [D loss: 0.488570, acc.: 73.44%] [G loss: 0.670885]\n",
      "epoch:18 step:17419 [D loss: 0.601998, acc.: 65.62%] [G loss: 0.603072]\n",
      "epoch:18 step:17420 [D loss: 0.481188, acc.: 76.56%] [G loss: 0.698061]\n",
      "epoch:18 step:17421 [D loss: 0.442941, acc.: 80.47%] [G loss: 0.794504]\n",
      "epoch:18 step:17422 [D loss: 0.565968, acc.: 67.19%] [G loss: 0.634358]\n",
      "epoch:18 step:17423 [D loss: 0.522978, acc.: 75.00%] [G loss: 0.684056]\n",
      "epoch:18 step:17424 [D loss: 0.486229, acc.: 75.78%] [G loss: 0.615341]\n",
      "epoch:18 step:17425 [D loss: 0.591996, acc.: 64.84%] [G loss: 0.629808]\n",
      "epoch:18 step:17426 [D loss: 0.598628, acc.: 67.19%] [G loss: 0.585647]\n",
      "epoch:18 step:17427 [D loss: 0.566077, acc.: 71.88%] [G loss: 0.622569]\n",
      "epoch:18 step:17428 [D loss: 0.600893, acc.: 67.97%] [G loss: 0.499454]\n",
      "epoch:18 step:17429 [D loss: 0.561315, acc.: 66.41%] [G loss: 0.694796]\n",
      "epoch:18 step:17430 [D loss: 0.528613, acc.: 74.22%] [G loss: 0.714802]\n",
      "epoch:18 step:17431 [D loss: 0.502963, acc.: 78.91%] [G loss: 0.689899]\n",
      "epoch:18 step:17432 [D loss: 0.706169, acc.: 62.50%] [G loss: 0.588740]\n",
      "epoch:18 step:17433 [D loss: 0.583906, acc.: 69.53%] [G loss: 0.654330]\n",
      "epoch:18 step:17434 [D loss: 0.493376, acc.: 73.44%] [G loss: 0.715134]\n",
      "epoch:18 step:17435 [D loss: 0.524209, acc.: 75.00%] [G loss: 0.751288]\n",
      "epoch:18 step:17436 [D loss: 0.552840, acc.: 69.53%] [G loss: 0.535833]\n",
      "epoch:18 step:17437 [D loss: 0.516930, acc.: 71.09%] [G loss: 0.732787]\n",
      "epoch:18 step:17438 [D loss: 0.555232, acc.: 72.66%] [G loss: 0.570278]\n",
      "epoch:18 step:17439 [D loss: 0.529693, acc.: 69.53%] [G loss: 0.700425]\n",
      "epoch:18 step:17440 [D loss: 0.516034, acc.: 77.34%] [G loss: 0.682005]\n",
      "epoch:18 step:17441 [D loss: 0.474675, acc.: 78.91%] [G loss: 0.881165]\n",
      "epoch:18 step:17442 [D loss: 0.554590, acc.: 74.22%] [G loss: 0.675328]\n",
      "epoch:18 step:17443 [D loss: 0.566940, acc.: 71.88%] [G loss: 0.673491]\n",
      "epoch:18 step:17444 [D loss: 0.563549, acc.: 68.75%] [G loss: 0.654729]\n",
      "epoch:18 step:17445 [D loss: 0.484876, acc.: 79.69%] [G loss: 0.670847]\n",
      "epoch:18 step:17446 [D loss: 0.515643, acc.: 72.66%] [G loss: 0.725954]\n",
      "epoch:18 step:17447 [D loss: 0.517458, acc.: 71.88%] [G loss: 0.676880]\n",
      "epoch:18 step:17448 [D loss: 0.449954, acc.: 77.34%] [G loss: 0.762005]\n",
      "epoch:18 step:17449 [D loss: 0.543189, acc.: 65.62%] [G loss: 0.752848]\n",
      "epoch:18 step:17450 [D loss: 0.705694, acc.: 59.38%] [G loss: 0.812105]\n",
      "epoch:18 step:17451 [D loss: 0.492380, acc.: 74.22%] [G loss: 0.611113]\n",
      "epoch:18 step:17452 [D loss: 0.564508, acc.: 70.31%] [G loss: 0.627653]\n",
      "epoch:18 step:17453 [D loss: 0.608378, acc.: 61.72%] [G loss: 0.471764]\n",
      "epoch:18 step:17454 [D loss: 0.561317, acc.: 67.97%] [G loss: 0.653345]\n",
      "epoch:18 step:17455 [D loss: 0.523789, acc.: 71.88%] [G loss: 0.686611]\n",
      "epoch:18 step:17456 [D loss: 0.551353, acc.: 67.97%] [G loss: 0.586702]\n",
      "epoch:18 step:17457 [D loss: 0.568313, acc.: 70.31%] [G loss: 0.509250]\n",
      "epoch:18 step:17458 [D loss: 0.502068, acc.: 73.44%] [G loss: 0.583712]\n",
      "epoch:18 step:17459 [D loss: 0.555026, acc.: 65.62%] [G loss: 0.611991]\n",
      "epoch:18 step:17460 [D loss: 0.547913, acc.: 73.44%] [G loss: 0.707134]\n",
      "epoch:18 step:17461 [D loss: 0.514808, acc.: 75.78%] [G loss: 0.612666]\n",
      "epoch:18 step:17462 [D loss: 0.539287, acc.: 74.22%] [G loss: 0.511533]\n",
      "epoch:18 step:17463 [D loss: 0.521621, acc.: 68.75%] [G loss: 0.578835]\n",
      "epoch:18 step:17464 [D loss: 0.464810, acc.: 76.56%] [G loss: 0.717033]\n",
      "epoch:18 step:17465 [D loss: 0.495237, acc.: 74.22%] [G loss: 0.595654]\n",
      "epoch:18 step:17466 [D loss: 0.538056, acc.: 73.44%] [G loss: 0.665405]\n",
      "epoch:18 step:17467 [D loss: 0.466241, acc.: 76.56%] [G loss: 0.723698]\n",
      "epoch:18 step:17468 [D loss: 0.506600, acc.: 75.00%] [G loss: 0.674481]\n",
      "epoch:18 step:17469 [D loss: 0.486583, acc.: 78.91%] [G loss: 0.558041]\n",
      "epoch:18 step:17470 [D loss: 0.568901, acc.: 70.31%] [G loss: 0.796180]\n",
      "epoch:18 step:17471 [D loss: 0.484492, acc.: 76.56%] [G loss: 0.720382]\n",
      "epoch:18 step:17472 [D loss: 0.579852, acc.: 66.41%] [G loss: 0.630830]\n",
      "epoch:18 step:17473 [D loss: 0.531232, acc.: 72.66%] [G loss: 0.525015]\n",
      "epoch:18 step:17474 [D loss: 0.553493, acc.: 68.75%] [G loss: 0.616327]\n",
      "epoch:18 step:17475 [D loss: 0.525801, acc.: 70.31%] [G loss: 0.638065]\n",
      "epoch:18 step:17476 [D loss: 0.546330, acc.: 72.66%] [G loss: 0.506371]\n",
      "epoch:18 step:17477 [D loss: 0.514099, acc.: 71.88%] [G loss: 0.520008]\n",
      "epoch:18 step:17478 [D loss: 0.579510, acc.: 65.62%] [G loss: 0.468772]\n",
      "epoch:18 step:17479 [D loss: 0.483397, acc.: 72.66%] [G loss: 0.664898]\n",
      "epoch:18 step:17480 [D loss: 0.594226, acc.: 67.19%] [G loss: 0.544769]\n",
      "epoch:18 step:17481 [D loss: 0.595339, acc.: 66.41%] [G loss: 0.573813]\n",
      "epoch:18 step:17482 [D loss: 0.613073, acc.: 66.41%] [G loss: 0.734740]\n",
      "epoch:18 step:17483 [D loss: 0.530456, acc.: 71.88%] [G loss: 0.624216]\n",
      "epoch:18 step:17484 [D loss: 0.476662, acc.: 75.78%] [G loss: 0.786933]\n",
      "epoch:18 step:17485 [D loss: 0.542393, acc.: 69.53%] [G loss: 0.590781]\n",
      "epoch:18 step:17486 [D loss: 0.488207, acc.: 75.78%] [G loss: 0.781250]\n",
      "epoch:18 step:17487 [D loss: 0.506884, acc.: 75.00%] [G loss: 0.653029]\n",
      "epoch:18 step:17488 [D loss: 0.511852, acc.: 77.34%] [G loss: 0.565807]\n",
      "epoch:18 step:17489 [D loss: 0.547222, acc.: 72.66%] [G loss: 0.662479]\n",
      "epoch:18 step:17490 [D loss: 0.476738, acc.: 73.44%] [G loss: 0.711639]\n",
      "epoch:18 step:17491 [D loss: 0.663561, acc.: 63.28%] [G loss: 0.573596]\n",
      "epoch:18 step:17492 [D loss: 0.530331, acc.: 66.41%] [G loss: 0.641851]\n",
      "epoch:18 step:17493 [D loss: 0.513555, acc.: 72.66%] [G loss: 0.545845]\n",
      "epoch:18 step:17494 [D loss: 0.619942, acc.: 66.41%] [G loss: 0.443755]\n",
      "epoch:18 step:17495 [D loss: 0.471258, acc.: 78.91%] [G loss: 0.739906]\n",
      "epoch:18 step:17496 [D loss: 0.531710, acc.: 71.09%] [G loss: 0.708903]\n",
      "epoch:18 step:17497 [D loss: 0.460092, acc.: 81.25%] [G loss: 0.707269]\n",
      "epoch:18 step:17498 [D loss: 0.533666, acc.: 74.22%] [G loss: 0.558101]\n",
      "epoch:18 step:17499 [D loss: 0.546272, acc.: 68.75%] [G loss: 0.686478]\n",
      "epoch:18 step:17500 [D loss: 0.472728, acc.: 78.12%] [G loss: 0.781493]\n",
      "epoch:18 step:17501 [D loss: 0.481596, acc.: 77.34%] [G loss: 0.799767]\n",
      "epoch:18 step:17502 [D loss: 0.575593, acc.: 68.75%] [G loss: 0.640906]\n",
      "epoch:18 step:17503 [D loss: 0.588923, acc.: 66.41%] [G loss: 0.563118]\n",
      "epoch:18 step:17504 [D loss: 0.547289, acc.: 69.53%] [G loss: 0.706437]\n",
      "epoch:18 step:17505 [D loss: 0.537418, acc.: 73.44%] [G loss: 0.513060]\n",
      "epoch:18 step:17506 [D loss: 0.570197, acc.: 65.62%] [G loss: 0.789415]\n",
      "epoch:18 step:17507 [D loss: 0.485499, acc.: 73.44%] [G loss: 0.707758]\n",
      "epoch:18 step:17508 [D loss: 0.587626, acc.: 64.84%] [G loss: 0.849677]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17509 [D loss: 0.525564, acc.: 75.00%] [G loss: 0.818117]\n",
      "epoch:18 step:17510 [D loss: 0.521142, acc.: 70.31%] [G loss: 0.643700]\n",
      "epoch:18 step:17511 [D loss: 0.542047, acc.: 72.66%] [G loss: 0.536676]\n",
      "epoch:18 step:17512 [D loss: 0.581492, acc.: 68.75%] [G loss: 0.577662]\n",
      "epoch:18 step:17513 [D loss: 0.457479, acc.: 78.91%] [G loss: 0.705098]\n",
      "epoch:18 step:17514 [D loss: 0.429648, acc.: 82.03%] [G loss: 0.775975]\n",
      "epoch:18 step:17515 [D loss: 0.522039, acc.: 72.66%] [G loss: 0.834239]\n",
      "epoch:18 step:17516 [D loss: 0.508103, acc.: 75.78%] [G loss: 0.879148]\n",
      "epoch:18 step:17517 [D loss: 0.521958, acc.: 71.09%] [G loss: 0.765188]\n",
      "epoch:18 step:17518 [D loss: 0.588954, acc.: 68.75%] [G loss: 0.841527]\n",
      "epoch:18 step:17519 [D loss: 0.599576, acc.: 63.28%] [G loss: 0.696456]\n",
      "epoch:18 step:17520 [D loss: 0.504205, acc.: 74.22%] [G loss: 0.628027]\n",
      "epoch:18 step:17521 [D loss: 0.567775, acc.: 68.75%] [G loss: 0.621578]\n",
      "epoch:18 step:17522 [D loss: 0.587723, acc.: 65.62%] [G loss: 0.604865]\n",
      "epoch:18 step:17523 [D loss: 0.501849, acc.: 73.44%] [G loss: 0.660121]\n",
      "epoch:18 step:17524 [D loss: 0.607344, acc.: 64.06%] [G loss: 0.600834]\n",
      "epoch:18 step:17525 [D loss: 0.542093, acc.: 70.31%] [G loss: 0.621473]\n",
      "epoch:18 step:17526 [D loss: 0.498927, acc.: 74.22%] [G loss: 0.761959]\n",
      "epoch:18 step:17527 [D loss: 0.504133, acc.: 75.00%] [G loss: 0.757629]\n",
      "epoch:18 step:17528 [D loss: 0.560110, acc.: 71.88%] [G loss: 0.640364]\n",
      "epoch:18 step:17529 [D loss: 0.609799, acc.: 64.84%] [G loss: 0.619984]\n",
      "epoch:18 step:17530 [D loss: 0.545563, acc.: 68.75%] [G loss: 0.687171]\n",
      "epoch:18 step:17531 [D loss: 0.548470, acc.: 70.31%] [G loss: 0.793398]\n",
      "epoch:18 step:17532 [D loss: 0.495448, acc.: 78.12%] [G loss: 0.759123]\n",
      "epoch:18 step:17533 [D loss: 0.526177, acc.: 74.22%] [G loss: 0.737194]\n",
      "epoch:18 step:17534 [D loss: 0.557146, acc.: 71.09%] [G loss: 0.540368]\n",
      "epoch:18 step:17535 [D loss: 0.530049, acc.: 68.75%] [G loss: 0.708829]\n",
      "epoch:18 step:17536 [D loss: 0.574787, acc.: 67.19%] [G loss: 0.577840]\n",
      "epoch:18 step:17537 [D loss: 0.559234, acc.: 65.62%] [G loss: 0.634216]\n",
      "epoch:18 step:17538 [D loss: 0.551062, acc.: 69.53%] [G loss: 0.700682]\n",
      "epoch:18 step:17539 [D loss: 0.565406, acc.: 68.75%] [G loss: 0.507706]\n",
      "epoch:18 step:17540 [D loss: 0.524088, acc.: 73.44%] [G loss: 0.771772]\n",
      "epoch:18 step:17541 [D loss: 0.655158, acc.: 61.72%] [G loss: 0.663057]\n",
      "epoch:18 step:17542 [D loss: 0.531457, acc.: 71.09%] [G loss: 0.585110]\n",
      "epoch:18 step:17543 [D loss: 0.472118, acc.: 79.69%] [G loss: 0.697393]\n",
      "epoch:18 step:17544 [D loss: 0.563483, acc.: 67.97%] [G loss: 0.568901]\n",
      "epoch:18 step:17545 [D loss: 0.508362, acc.: 76.56%] [G loss: 0.796001]\n",
      "epoch:18 step:17546 [D loss: 0.597307, acc.: 67.19%] [G loss: 0.490779]\n",
      "epoch:18 step:17547 [D loss: 0.532435, acc.: 74.22%] [G loss: 0.652531]\n",
      "epoch:18 step:17548 [D loss: 0.550220, acc.: 71.09%] [G loss: 0.575951]\n",
      "epoch:18 step:17549 [D loss: 0.579055, acc.: 66.41%] [G loss: 0.553668]\n",
      "epoch:18 step:17550 [D loss: 0.669010, acc.: 64.84%] [G loss: 0.522545]\n",
      "epoch:18 step:17551 [D loss: 0.529874, acc.: 70.31%] [G loss: 0.527037]\n",
      "epoch:18 step:17552 [D loss: 0.569662, acc.: 72.66%] [G loss: 0.596789]\n",
      "epoch:18 step:17553 [D loss: 0.525864, acc.: 71.88%] [G loss: 0.491388]\n",
      "epoch:18 step:17554 [D loss: 0.569437, acc.: 70.31%] [G loss: 0.491262]\n",
      "epoch:18 step:17555 [D loss: 0.539971, acc.: 71.88%] [G loss: 0.548874]\n",
      "epoch:18 step:17556 [D loss: 0.520329, acc.: 75.78%] [G loss: 0.679505]\n",
      "epoch:18 step:17557 [D loss: 0.523594, acc.: 71.09%] [G loss: 0.716324]\n",
      "epoch:18 step:17558 [D loss: 0.519432, acc.: 77.34%] [G loss: 0.652884]\n",
      "epoch:18 step:17559 [D loss: 0.458897, acc.: 82.03%] [G loss: 0.756564]\n",
      "epoch:18 step:17560 [D loss: 0.511739, acc.: 75.00%] [G loss: 0.987999]\n",
      "epoch:18 step:17561 [D loss: 0.518671, acc.: 75.00%] [G loss: 0.793954]\n",
      "epoch:18 step:17562 [D loss: 0.599595, acc.: 64.84%] [G loss: 0.672471]\n",
      "epoch:18 step:17563 [D loss: 0.562291, acc.: 67.19%] [G loss: 0.544091]\n",
      "epoch:18 step:17564 [D loss: 0.587688, acc.: 67.97%] [G loss: 0.457849]\n",
      "epoch:18 step:17565 [D loss: 0.500824, acc.: 75.00%] [G loss: 0.763402]\n",
      "epoch:18 step:17566 [D loss: 0.473955, acc.: 75.78%] [G loss: 0.793288]\n",
      "epoch:18 step:17567 [D loss: 0.485755, acc.: 74.22%] [G loss: 0.974362]\n",
      "epoch:18 step:17568 [D loss: 0.645790, acc.: 60.94%] [G loss: 0.734751]\n",
      "epoch:18 step:17569 [D loss: 0.592833, acc.: 61.72%] [G loss: 0.611219]\n",
      "epoch:18 step:17570 [D loss: 0.602433, acc.: 67.19%] [G loss: 0.617202]\n",
      "epoch:18 step:17571 [D loss: 0.547275, acc.: 75.78%] [G loss: 0.645727]\n",
      "epoch:18 step:17572 [D loss: 0.532145, acc.: 71.09%] [G loss: 0.585389]\n",
      "epoch:18 step:17573 [D loss: 0.535693, acc.: 70.31%] [G loss: 0.687591]\n",
      "epoch:18 step:17574 [D loss: 0.443993, acc.: 79.69%] [G loss: 0.634402]\n",
      "epoch:18 step:17575 [D loss: 0.530662, acc.: 67.19%] [G loss: 0.796736]\n",
      "epoch:18 step:17576 [D loss: 0.591693, acc.: 68.75%] [G loss: 0.609878]\n",
      "epoch:18 step:17577 [D loss: 0.570835, acc.: 65.62%] [G loss: 0.538807]\n",
      "epoch:18 step:17578 [D loss: 0.591570, acc.: 67.19%] [G loss: 0.748181]\n",
      "epoch:18 step:17579 [D loss: 0.571759, acc.: 68.75%] [G loss: 0.665249]\n",
      "epoch:18 step:17580 [D loss: 0.550514, acc.: 74.22%] [G loss: 0.634991]\n",
      "epoch:18 step:17581 [D loss: 0.529396, acc.: 71.88%] [G loss: 0.717521]\n",
      "epoch:18 step:17582 [D loss: 0.573326, acc.: 70.31%] [G loss: 0.706686]\n",
      "epoch:18 step:17583 [D loss: 0.566868, acc.: 70.31%] [G loss: 0.617035]\n",
      "epoch:18 step:17584 [D loss: 0.579990, acc.: 66.41%] [G loss: 0.584695]\n",
      "epoch:18 step:17585 [D loss: 0.471760, acc.: 78.12%] [G loss: 0.707623]\n",
      "epoch:18 step:17586 [D loss: 0.564696, acc.: 69.53%] [G loss: 0.528377]\n",
      "epoch:18 step:17587 [D loss: 0.545748, acc.: 67.19%] [G loss: 0.629120]\n",
      "epoch:18 step:17588 [D loss: 0.519753, acc.: 71.88%] [G loss: 0.610029]\n",
      "epoch:18 step:17589 [D loss: 0.562709, acc.: 74.22%] [G loss: 0.619783]\n",
      "epoch:18 step:17590 [D loss: 0.500329, acc.: 73.44%] [G loss: 0.663717]\n",
      "epoch:18 step:17591 [D loss: 0.504616, acc.: 75.00%] [G loss: 0.668402]\n",
      "epoch:18 step:17592 [D loss: 0.465104, acc.: 78.91%] [G loss: 0.778145]\n",
      "epoch:18 step:17593 [D loss: 0.550157, acc.: 69.53%] [G loss: 0.749330]\n",
      "epoch:18 step:17594 [D loss: 0.541304, acc.: 69.53%] [G loss: 0.605025]\n",
      "epoch:18 step:17595 [D loss: 0.558313, acc.: 67.19%] [G loss: 0.618182]\n",
      "epoch:18 step:17596 [D loss: 0.526632, acc.: 74.22%] [G loss: 0.543365]\n",
      "epoch:18 step:17597 [D loss: 0.606149, acc.: 62.50%] [G loss: 0.460026]\n",
      "epoch:18 step:17598 [D loss: 0.520509, acc.: 67.97%] [G loss: 0.603994]\n",
      "epoch:18 step:17599 [D loss: 0.545311, acc.: 64.84%] [G loss: 0.535322]\n",
      "epoch:18 step:17600 [D loss: 0.538368, acc.: 71.88%] [G loss: 0.595818]\n",
      "##############\n",
      "[2.97953745 0.96194863 6.21825674 5.04669302 3.80140632 5.57657881\n",
      " 4.30953921 4.86393568 4.57053057 4.20191186]\n",
      "##########\n",
      "epoch:18 step:17601 [D loss: 0.525599, acc.: 71.09%] [G loss: 0.676607]\n",
      "epoch:18 step:17602 [D loss: 0.478725, acc.: 77.34%] [G loss: 0.710524]\n",
      "epoch:18 step:17603 [D loss: 0.537532, acc.: 73.44%] [G loss: 0.529629]\n",
      "epoch:18 step:17604 [D loss: 0.604971, acc.: 66.41%] [G loss: 0.596052]\n",
      "epoch:18 step:17605 [D loss: 0.611377, acc.: 67.19%] [G loss: 0.598754]\n",
      "epoch:18 step:17606 [D loss: 0.615136, acc.: 63.28%] [G loss: 0.481777]\n",
      "epoch:18 step:17607 [D loss: 0.571607, acc.: 70.31%] [G loss: 0.547825]\n",
      "epoch:18 step:17608 [D loss: 0.509726, acc.: 72.66%] [G loss: 0.513791]\n",
      "epoch:18 step:17609 [D loss: 0.484209, acc.: 74.22%] [G loss: 0.776603]\n",
      "epoch:18 step:17610 [D loss: 0.574617, acc.: 71.09%] [G loss: 0.707785]\n",
      "epoch:18 step:17611 [D loss: 0.544797, acc.: 70.31%] [G loss: 0.740899]\n",
      "epoch:18 step:17612 [D loss: 0.483981, acc.: 74.22%] [G loss: 0.793998]\n",
      "epoch:18 step:17613 [D loss: 0.431193, acc.: 78.12%] [G loss: 0.758966]\n",
      "epoch:18 step:17614 [D loss: 0.579753, acc.: 67.19%] [G loss: 0.651409]\n",
      "epoch:18 step:17615 [D loss: 0.562752, acc.: 69.53%] [G loss: 0.805279]\n",
      "epoch:18 step:17616 [D loss: 0.494711, acc.: 75.78%] [G loss: 0.671686]\n",
      "epoch:18 step:17617 [D loss: 0.501182, acc.: 75.00%] [G loss: 0.827333]\n",
      "epoch:18 step:17618 [D loss: 0.586068, acc.: 69.53%] [G loss: 0.576455]\n",
      "epoch:18 step:17619 [D loss: 0.477507, acc.: 78.91%] [G loss: 0.926375]\n",
      "epoch:18 step:17620 [D loss: 0.556214, acc.: 67.19%] [G loss: 0.576316]\n",
      "epoch:18 step:17621 [D loss: 0.575135, acc.: 67.19%] [G loss: 0.539025]\n",
      "epoch:18 step:17622 [D loss: 0.543467, acc.: 67.19%] [G loss: 0.662550]\n",
      "epoch:18 step:17623 [D loss: 0.569184, acc.: 71.09%] [G loss: 0.458659]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17624 [D loss: 0.571774, acc.: 68.75%] [G loss: 0.537963]\n",
      "epoch:18 step:17625 [D loss: 0.531370, acc.: 74.22%] [G loss: 0.638721]\n",
      "epoch:18 step:17626 [D loss: 0.507244, acc.: 76.56%] [G loss: 0.654593]\n",
      "epoch:18 step:17627 [D loss: 0.511098, acc.: 75.00%] [G loss: 0.572771]\n",
      "epoch:18 step:17628 [D loss: 0.614245, acc.: 63.28%] [G loss: 0.568333]\n",
      "epoch:18 step:17629 [D loss: 0.568605, acc.: 73.44%] [G loss: 0.593172]\n",
      "epoch:18 step:17630 [D loss: 0.538130, acc.: 68.75%] [G loss: 0.735104]\n",
      "epoch:18 step:17631 [D loss: 0.593857, acc.: 67.97%] [G loss: 0.586947]\n",
      "epoch:18 step:17632 [D loss: 0.622748, acc.: 65.62%] [G loss: 0.503138]\n",
      "epoch:18 step:17633 [D loss: 0.537197, acc.: 68.75%] [G loss: 0.652918]\n",
      "epoch:18 step:17634 [D loss: 0.542170, acc.: 66.41%] [G loss: 0.716080]\n",
      "epoch:18 step:17635 [D loss: 0.500666, acc.: 78.12%] [G loss: 0.916921]\n",
      "epoch:18 step:17636 [D loss: 0.527320, acc.: 73.44%] [G loss: 0.858236]\n",
      "epoch:18 step:17637 [D loss: 0.565251, acc.: 71.88%] [G loss: 0.766176]\n",
      "epoch:18 step:17638 [D loss: 0.598192, acc.: 67.19%] [G loss: 0.832448]\n",
      "epoch:18 step:17639 [D loss: 0.545979, acc.: 72.66%] [G loss: 0.628832]\n",
      "epoch:18 step:17640 [D loss: 0.566430, acc.: 67.19%] [G loss: 0.668574]\n",
      "epoch:18 step:17641 [D loss: 0.518245, acc.: 72.66%] [G loss: 0.633528]\n",
      "epoch:18 step:17642 [D loss: 0.581109, acc.: 62.50%] [G loss: 0.668445]\n",
      "epoch:18 step:17643 [D loss: 0.566879, acc.: 68.75%] [G loss: 0.621453]\n",
      "epoch:18 step:17644 [D loss: 0.554734, acc.: 73.44%] [G loss: 0.713811]\n",
      "epoch:18 step:17645 [D loss: 0.562731, acc.: 71.09%] [G loss: 0.740159]\n",
      "epoch:18 step:17646 [D loss: 0.524086, acc.: 72.66%] [G loss: 0.839120]\n",
      "epoch:18 step:17647 [D loss: 0.516071, acc.: 75.00%] [G loss: 0.906684]\n",
      "epoch:18 step:17648 [D loss: 0.537399, acc.: 71.09%] [G loss: 0.916963]\n",
      "epoch:18 step:17649 [D loss: 0.561113, acc.: 71.88%] [G loss: 0.693533]\n",
      "epoch:18 step:17650 [D loss: 0.609206, acc.: 65.62%] [G loss: 0.721603]\n",
      "epoch:18 step:17651 [D loss: 0.581611, acc.: 64.06%] [G loss: 0.599807]\n",
      "epoch:18 step:17652 [D loss: 0.476385, acc.: 76.56%] [G loss: 0.712624]\n",
      "epoch:18 step:17653 [D loss: 0.565587, acc.: 68.75%] [G loss: 0.573610]\n",
      "epoch:18 step:17654 [D loss: 0.618906, acc.: 61.72%] [G loss: 0.545463]\n",
      "epoch:18 step:17655 [D loss: 0.516764, acc.: 71.88%] [G loss: 0.572431]\n",
      "epoch:18 step:17656 [D loss: 0.522163, acc.: 74.22%] [G loss: 0.593275]\n",
      "epoch:18 step:17657 [D loss: 0.499869, acc.: 77.34%] [G loss: 0.615797]\n",
      "epoch:18 step:17658 [D loss: 0.484882, acc.: 75.78%] [G loss: 0.567589]\n",
      "epoch:18 step:17659 [D loss: 0.574324, acc.: 69.53%] [G loss: 0.688099]\n",
      "epoch:18 step:17660 [D loss: 0.591404, acc.: 62.50%] [G loss: 0.618439]\n",
      "epoch:18 step:17661 [D loss: 0.498614, acc.: 69.53%] [G loss: 0.642769]\n",
      "epoch:18 step:17662 [D loss: 0.553669, acc.: 75.00%] [G loss: 0.800563]\n",
      "epoch:18 step:17663 [D loss: 0.589634, acc.: 65.62%] [G loss: 0.665870]\n",
      "epoch:18 step:17664 [D loss: 0.526022, acc.: 69.53%] [G loss: 0.795406]\n",
      "epoch:18 step:17665 [D loss: 0.585878, acc.: 68.75%] [G loss: 0.644910]\n",
      "epoch:18 step:17666 [D loss: 0.585034, acc.: 67.19%] [G loss: 0.515590]\n",
      "epoch:18 step:17667 [D loss: 0.533263, acc.: 69.53%] [G loss: 0.630837]\n",
      "epoch:18 step:17668 [D loss: 0.459865, acc.: 81.25%] [G loss: 0.730615]\n",
      "epoch:18 step:17669 [D loss: 0.494188, acc.: 75.78%] [G loss: 0.757658]\n",
      "epoch:18 step:17670 [D loss: 0.535784, acc.: 66.41%] [G loss: 0.671087]\n",
      "epoch:18 step:17671 [D loss: 0.544229, acc.: 69.53%] [G loss: 0.579048]\n",
      "epoch:18 step:17672 [D loss: 0.614621, acc.: 63.28%] [G loss: 0.607605]\n",
      "epoch:18 step:17673 [D loss: 0.516946, acc.: 74.22%] [G loss: 0.541256]\n",
      "epoch:18 step:17674 [D loss: 0.552848, acc.: 71.88%] [G loss: 0.551175]\n",
      "epoch:18 step:17675 [D loss: 0.543550, acc.: 70.31%] [G loss: 0.592861]\n",
      "epoch:18 step:17676 [D loss: 0.555157, acc.: 66.41%] [G loss: 0.590918]\n",
      "epoch:18 step:17677 [D loss: 0.548538, acc.: 71.09%] [G loss: 0.653861]\n",
      "epoch:18 step:17678 [D loss: 0.610123, acc.: 64.06%] [G loss: 0.543116]\n",
      "epoch:18 step:17679 [D loss: 0.543840, acc.: 68.75%] [G loss: 0.526276]\n",
      "epoch:18 step:17680 [D loss: 0.506404, acc.: 71.09%] [G loss: 0.632140]\n",
      "epoch:18 step:17681 [D loss: 0.444455, acc.: 78.91%] [G loss: 0.780429]\n",
      "epoch:18 step:17682 [D loss: 0.541183, acc.: 71.09%] [G loss: 0.666928]\n",
      "epoch:18 step:17683 [D loss: 0.637676, acc.: 64.06%] [G loss: 0.606458]\n",
      "epoch:18 step:17684 [D loss: 0.629563, acc.: 58.59%] [G loss: 0.653450]\n",
      "epoch:18 step:17685 [D loss: 0.535707, acc.: 71.88%] [G loss: 0.692434]\n",
      "epoch:18 step:17686 [D loss: 0.618722, acc.: 67.19%] [G loss: 0.587067]\n",
      "epoch:18 step:17687 [D loss: 0.537364, acc.: 70.31%] [G loss: 0.692470]\n",
      "epoch:18 step:17688 [D loss: 0.528603, acc.: 69.53%] [G loss: 0.567788]\n",
      "epoch:18 step:17689 [D loss: 0.449353, acc.: 80.47%] [G loss: 0.735634]\n",
      "epoch:18 step:17690 [D loss: 0.546023, acc.: 70.31%] [G loss: 0.636582]\n",
      "epoch:18 step:17691 [D loss: 0.484076, acc.: 75.78%] [G loss: 0.670597]\n",
      "epoch:18 step:17692 [D loss: 0.499299, acc.: 77.34%] [G loss: 0.696243]\n",
      "epoch:18 step:17693 [D loss: 0.586823, acc.: 68.75%] [G loss: 0.503873]\n",
      "epoch:18 step:17694 [D loss: 0.686486, acc.: 59.38%] [G loss: 0.539671]\n",
      "epoch:18 step:17695 [D loss: 0.541781, acc.: 71.88%] [G loss: 0.667702]\n",
      "epoch:18 step:17696 [D loss: 0.567457, acc.: 66.41%] [G loss: 0.664288]\n",
      "epoch:18 step:17697 [D loss: 0.537890, acc.: 68.75%] [G loss: 0.696661]\n",
      "epoch:18 step:17698 [D loss: 0.500646, acc.: 75.00%] [G loss: 0.690145]\n",
      "epoch:18 step:17699 [D loss: 0.492163, acc.: 75.00%] [G loss: 0.676313]\n",
      "epoch:18 step:17700 [D loss: 0.486782, acc.: 74.22%] [G loss: 0.728745]\n",
      "epoch:18 step:17701 [D loss: 0.501532, acc.: 75.78%] [G loss: 0.610937]\n",
      "epoch:18 step:17702 [D loss: 0.488835, acc.: 77.34%] [G loss: 0.524378]\n",
      "epoch:18 step:17703 [D loss: 0.578171, acc.: 70.31%] [G loss: 0.609027]\n",
      "epoch:18 step:17704 [D loss: 0.510079, acc.: 75.78%] [G loss: 0.610138]\n",
      "epoch:18 step:17705 [D loss: 0.534577, acc.: 70.31%] [G loss: 0.545254]\n",
      "epoch:18 step:17706 [D loss: 0.576982, acc.: 66.41%] [G loss: 0.531334]\n",
      "epoch:18 step:17707 [D loss: 0.559883, acc.: 69.53%] [G loss: 0.469773]\n",
      "epoch:18 step:17708 [D loss: 0.521780, acc.: 71.88%] [G loss: 0.505621]\n",
      "epoch:18 step:17709 [D loss: 0.487970, acc.: 75.00%] [G loss: 0.673695]\n",
      "epoch:18 step:17710 [D loss: 0.572460, acc.: 65.62%] [G loss: 0.642400]\n",
      "epoch:18 step:17711 [D loss: 0.549039, acc.: 74.22%] [G loss: 0.549614]\n",
      "epoch:18 step:17712 [D loss: 0.586212, acc.: 64.84%] [G loss: 0.622975]\n",
      "epoch:18 step:17713 [D loss: 0.612787, acc.: 62.50%] [G loss: 0.564500]\n",
      "epoch:18 step:17714 [D loss: 0.550270, acc.: 68.75%] [G loss: 0.468876]\n",
      "epoch:18 step:17715 [D loss: 0.539438, acc.: 70.31%] [G loss: 0.571323]\n",
      "epoch:18 step:17716 [D loss: 0.538654, acc.: 71.88%] [G loss: 0.528497]\n",
      "epoch:18 step:17717 [D loss: 0.570071, acc.: 64.84%] [G loss: 0.553574]\n",
      "epoch:18 step:17718 [D loss: 0.548921, acc.: 71.88%] [G loss: 0.578510]\n",
      "epoch:18 step:17719 [D loss: 0.564956, acc.: 64.84%] [G loss: 0.475017]\n",
      "epoch:18 step:17720 [D loss: 0.487808, acc.: 69.53%] [G loss: 0.659408]\n",
      "epoch:18 step:17721 [D loss: 0.520907, acc.: 71.88%] [G loss: 0.637141]\n",
      "epoch:18 step:17722 [D loss: 0.592396, acc.: 64.84%] [G loss: 0.570926]\n",
      "epoch:18 step:17723 [D loss: 0.446020, acc.: 77.34%] [G loss: 0.576786]\n",
      "epoch:18 step:17724 [D loss: 0.629457, acc.: 67.19%] [G loss: 0.534019]\n",
      "epoch:18 step:17725 [D loss: 0.538742, acc.: 71.88%] [G loss: 0.641906]\n",
      "epoch:18 step:17726 [D loss: 0.433102, acc.: 81.25%] [G loss: 0.794672]\n",
      "epoch:18 step:17727 [D loss: 0.651531, acc.: 64.06%] [G loss: 0.535755]\n",
      "epoch:18 step:17728 [D loss: 0.584046, acc.: 64.84%] [G loss: 0.544039]\n",
      "epoch:18 step:17729 [D loss: 0.492318, acc.: 75.00%] [G loss: 0.541363]\n",
      "epoch:18 step:17730 [D loss: 0.526015, acc.: 71.09%] [G loss: 0.553940]\n",
      "epoch:18 step:17731 [D loss: 0.598540, acc.: 62.50%] [G loss: 0.451329]\n",
      "epoch:18 step:17732 [D loss: 0.550012, acc.: 67.19%] [G loss: 0.554412]\n",
      "epoch:18 step:17733 [D loss: 0.633219, acc.: 61.72%] [G loss: 0.463296]\n",
      "epoch:18 step:17734 [D loss: 0.565683, acc.: 70.31%] [G loss: 0.553543]\n",
      "epoch:18 step:17735 [D loss: 0.568167, acc.: 71.09%] [G loss: 0.562178]\n",
      "epoch:18 step:17736 [D loss: 0.462923, acc.: 77.34%] [G loss: 0.714196]\n",
      "epoch:18 step:17737 [D loss: 0.578412, acc.: 66.41%] [G loss: 0.607498]\n",
      "epoch:18 step:17738 [D loss: 0.512428, acc.: 71.09%] [G loss: 0.601302]\n",
      "epoch:18 step:17739 [D loss: 0.556789, acc.: 67.19%] [G loss: 0.749353]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17740 [D loss: 0.550761, acc.: 72.66%] [G loss: 0.714237]\n",
      "epoch:18 step:17741 [D loss: 0.526991, acc.: 71.09%] [G loss: 0.575651]\n",
      "epoch:18 step:17742 [D loss: 0.573745, acc.: 65.62%] [G loss: 0.596349]\n",
      "epoch:18 step:17743 [D loss: 0.587390, acc.: 64.06%] [G loss: 0.552919]\n",
      "epoch:18 step:17744 [D loss: 0.542733, acc.: 71.09%] [G loss: 0.518160]\n",
      "epoch:18 step:17745 [D loss: 0.514639, acc.: 73.44%] [G loss: 0.556384]\n",
      "epoch:18 step:17746 [D loss: 0.647932, acc.: 60.94%] [G loss: 0.506381]\n",
      "epoch:18 step:17747 [D loss: 0.580352, acc.: 70.31%] [G loss: 0.623467]\n",
      "epoch:18 step:17748 [D loss: 0.582286, acc.: 69.53%] [G loss: 0.499314]\n",
      "epoch:18 step:17749 [D loss: 0.605253, acc.: 66.41%] [G loss: 0.546893]\n",
      "epoch:18 step:17750 [D loss: 0.468141, acc.: 78.12%] [G loss: 0.635712]\n",
      "epoch:18 step:17751 [D loss: 0.530218, acc.: 68.75%] [G loss: 0.821187]\n",
      "epoch:18 step:17752 [D loss: 0.533288, acc.: 72.66%] [G loss: 0.878208]\n",
      "epoch:18 step:17753 [D loss: 0.526624, acc.: 72.66%] [G loss: 0.653139]\n",
      "epoch:18 step:17754 [D loss: 0.536661, acc.: 69.53%] [G loss: 0.544769]\n",
      "epoch:18 step:17755 [D loss: 0.607124, acc.: 65.62%] [G loss: 0.646929]\n",
      "epoch:18 step:17756 [D loss: 0.504924, acc.: 71.88%] [G loss: 0.648506]\n",
      "epoch:18 step:17757 [D loss: 0.608787, acc.: 64.06%] [G loss: 0.494031]\n",
      "epoch:18 step:17758 [D loss: 0.560228, acc.: 65.62%] [G loss: 0.542797]\n",
      "epoch:18 step:17759 [D loss: 0.568260, acc.: 66.41%] [G loss: 0.592257]\n",
      "epoch:18 step:17760 [D loss: 0.457672, acc.: 80.47%] [G loss: 0.712845]\n",
      "epoch:18 step:17761 [D loss: 0.535960, acc.: 70.31%] [G loss: 0.810126]\n",
      "epoch:18 step:17762 [D loss: 0.508723, acc.: 71.09%] [G loss: 0.864678]\n",
      "epoch:18 step:17763 [D loss: 0.533294, acc.: 71.09%] [G loss: 0.803799]\n",
      "epoch:18 step:17764 [D loss: 0.475908, acc.: 77.34%] [G loss: 0.722103]\n",
      "epoch:18 step:17765 [D loss: 0.464522, acc.: 78.12%] [G loss: 0.832795]\n",
      "epoch:18 step:17766 [D loss: 0.531127, acc.: 71.88%] [G loss: 0.761777]\n",
      "epoch:18 step:17767 [D loss: 0.519346, acc.: 73.44%] [G loss: 0.804291]\n",
      "epoch:18 step:17768 [D loss: 0.575663, acc.: 68.75%] [G loss: 0.721573]\n",
      "epoch:18 step:17769 [D loss: 0.519552, acc.: 71.88%] [G loss: 0.724772]\n",
      "epoch:18 step:17770 [D loss: 0.600325, acc.: 64.06%] [G loss: 0.548341]\n",
      "epoch:18 step:17771 [D loss: 0.567511, acc.: 71.09%] [G loss: 0.707745]\n",
      "epoch:18 step:17772 [D loss: 0.511679, acc.: 72.66%] [G loss: 0.723146]\n",
      "epoch:18 step:17773 [D loss: 0.545479, acc.: 71.88%] [G loss: 0.762452]\n",
      "epoch:18 step:17774 [D loss: 0.558800, acc.: 70.31%] [G loss: 0.663069]\n",
      "epoch:18 step:17775 [D loss: 0.471358, acc.: 75.78%] [G loss: 0.616527]\n",
      "epoch:18 step:17776 [D loss: 0.507214, acc.: 70.31%] [G loss: 0.696557]\n",
      "epoch:18 step:17777 [D loss: 0.484125, acc.: 74.22%] [G loss: 0.736051]\n",
      "epoch:18 step:17778 [D loss: 0.528953, acc.: 73.44%] [G loss: 0.642244]\n",
      "epoch:18 step:17779 [D loss: 0.545742, acc.: 73.44%] [G loss: 0.706827]\n",
      "epoch:18 step:17780 [D loss: 0.461567, acc.: 74.22%] [G loss: 1.014904]\n",
      "epoch:18 step:17781 [D loss: 0.635738, acc.: 62.50%] [G loss: 0.713054]\n",
      "epoch:18 step:17782 [D loss: 0.518421, acc.: 71.88%] [G loss: 0.655410]\n",
      "epoch:18 step:17783 [D loss: 0.594424, acc.: 62.50%] [G loss: 0.767078]\n",
      "epoch:18 step:17784 [D loss: 0.507695, acc.: 78.91%] [G loss: 0.597923]\n",
      "epoch:18 step:17785 [D loss: 0.497482, acc.: 76.56%] [G loss: 0.915341]\n",
      "epoch:18 step:17786 [D loss: 0.678157, acc.: 63.28%] [G loss: 0.802118]\n",
      "epoch:18 step:17787 [D loss: 0.491510, acc.: 77.34%] [G loss: 0.793085]\n",
      "epoch:18 step:17788 [D loss: 0.545695, acc.: 72.66%] [G loss: 0.920251]\n",
      "epoch:18 step:17789 [D loss: 0.462111, acc.: 77.34%] [G loss: 0.723389]\n",
      "epoch:18 step:17790 [D loss: 0.465131, acc.: 78.12%] [G loss: 0.755118]\n",
      "epoch:18 step:17791 [D loss: 0.416639, acc.: 76.56%] [G loss: 1.045413]\n",
      "epoch:18 step:17792 [D loss: 0.462133, acc.: 75.78%] [G loss: 1.104010]\n",
      "epoch:18 step:17793 [D loss: 0.512337, acc.: 74.22%] [G loss: 1.229152]\n",
      "epoch:18 step:17794 [D loss: 0.709088, acc.: 63.28%] [G loss: 1.273477]\n",
      "epoch:18 step:17795 [D loss: 0.617521, acc.: 70.31%] [G loss: 1.478341]\n",
      "epoch:18 step:17796 [D loss: 0.506136, acc.: 72.66%] [G loss: 1.405012]\n",
      "epoch:18 step:17797 [D loss: 0.526872, acc.: 71.88%] [G loss: 0.872942]\n",
      "epoch:18 step:17798 [D loss: 0.601069, acc.: 66.41%] [G loss: 0.653835]\n",
      "epoch:18 step:17799 [D loss: 0.542217, acc.: 67.97%] [G loss: 0.896999]\n",
      "epoch:18 step:17800 [D loss: 0.528535, acc.: 69.53%] [G loss: 0.886683]\n",
      "##############\n",
      "[2.95858869 0.93035432 6.09098699 4.74543825 3.50141518 5.30513445\n",
      " 4.13336877 5.08948553 4.32576476 3.96794519]\n",
      "##########\n",
      "epoch:18 step:17801 [D loss: 0.469518, acc.: 74.22%] [G loss: 0.981203]\n",
      "epoch:18 step:17802 [D loss: 0.409820, acc.: 77.34%] [G loss: 0.884724]\n",
      "epoch:18 step:17803 [D loss: 0.523501, acc.: 73.44%] [G loss: 1.342910]\n",
      "epoch:19 step:17804 [D loss: 0.578860, acc.: 68.75%] [G loss: 1.060917]\n",
      "epoch:19 step:17805 [D loss: 0.486324, acc.: 75.00%] [G loss: 1.065568]\n",
      "epoch:19 step:17806 [D loss: 0.571402, acc.: 68.75%] [G loss: 0.969197]\n",
      "epoch:19 step:17807 [D loss: 0.565766, acc.: 70.31%] [G loss: 0.767335]\n",
      "epoch:19 step:17808 [D loss: 0.589627, acc.: 72.66%] [G loss: 0.632997]\n",
      "epoch:19 step:17809 [D loss: 0.621788, acc.: 67.19%] [G loss: 0.619087]\n",
      "epoch:19 step:17810 [D loss: 0.539431, acc.: 73.44%] [G loss: 0.758422]\n",
      "epoch:19 step:17811 [D loss: 0.498337, acc.: 75.00%] [G loss: 0.696396]\n",
      "epoch:19 step:17812 [D loss: 0.469689, acc.: 78.91%] [G loss: 0.732970]\n",
      "epoch:19 step:17813 [D loss: 0.466903, acc.: 78.12%] [G loss: 0.816089]\n",
      "epoch:19 step:17814 [D loss: 0.444536, acc.: 82.81%] [G loss: 0.883802]\n",
      "epoch:19 step:17815 [D loss: 0.571182, acc.: 64.84%] [G loss: 0.671805]\n",
      "epoch:19 step:17816 [D loss: 0.557694, acc.: 68.75%] [G loss: 0.865961]\n",
      "epoch:19 step:17817 [D loss: 0.524574, acc.: 72.66%] [G loss: 0.617699]\n",
      "epoch:19 step:17818 [D loss: 0.503465, acc.: 77.34%] [G loss: 0.722460]\n",
      "epoch:19 step:17819 [D loss: 0.505135, acc.: 74.22%] [G loss: 0.724451]\n",
      "epoch:19 step:17820 [D loss: 0.548501, acc.: 71.09%] [G loss: 0.564522]\n",
      "epoch:19 step:17821 [D loss: 0.601991, acc.: 67.97%] [G loss: 0.733327]\n",
      "epoch:19 step:17822 [D loss: 0.552015, acc.: 75.78%] [G loss: 0.677748]\n",
      "epoch:19 step:17823 [D loss: 0.624191, acc.: 64.84%] [G loss: 0.509144]\n",
      "epoch:19 step:17824 [D loss: 0.534507, acc.: 74.22%] [G loss: 0.665635]\n",
      "epoch:19 step:17825 [D loss: 0.452748, acc.: 80.47%] [G loss: 0.898918]\n",
      "epoch:19 step:17826 [D loss: 0.640558, acc.: 58.59%] [G loss: 0.588310]\n",
      "epoch:19 step:17827 [D loss: 0.521165, acc.: 71.88%] [G loss: 0.467033]\n",
      "epoch:19 step:17828 [D loss: 0.530466, acc.: 75.78%] [G loss: 0.633816]\n",
      "epoch:19 step:17829 [D loss: 0.545373, acc.: 70.31%] [G loss: 0.649958]\n",
      "epoch:19 step:17830 [D loss: 0.448837, acc.: 76.56%] [G loss: 0.586126]\n",
      "epoch:19 step:17831 [D loss: 0.585375, acc.: 69.53%] [G loss: 0.690688]\n",
      "epoch:19 step:17832 [D loss: 0.530578, acc.: 72.66%] [G loss: 0.696660]\n",
      "epoch:19 step:17833 [D loss: 0.524737, acc.: 75.00%] [G loss: 0.642222]\n",
      "epoch:19 step:17834 [D loss: 0.612134, acc.: 63.28%] [G loss: 0.588567]\n",
      "epoch:19 step:17835 [D loss: 0.533063, acc.: 70.31%] [G loss: 0.699425]\n",
      "epoch:19 step:17836 [D loss: 0.595803, acc.: 64.06%] [G loss: 0.505626]\n",
      "epoch:19 step:17837 [D loss: 0.540114, acc.: 68.75%] [G loss: 0.542251]\n",
      "epoch:19 step:17838 [D loss: 0.547928, acc.: 71.09%] [G loss: 0.482782]\n",
      "epoch:19 step:17839 [D loss: 0.521140, acc.: 70.31%] [G loss: 0.726148]\n",
      "epoch:19 step:17840 [D loss: 0.470234, acc.: 78.12%] [G loss: 0.610466]\n",
      "epoch:19 step:17841 [D loss: 0.617333, acc.: 65.62%] [G loss: 0.657599]\n",
      "epoch:19 step:17842 [D loss: 0.491311, acc.: 75.78%] [G loss: 0.716581]\n",
      "epoch:19 step:17843 [D loss: 0.404296, acc.: 82.81%] [G loss: 0.597547]\n",
      "epoch:19 step:17844 [D loss: 0.534497, acc.: 71.09%] [G loss: 0.743497]\n",
      "epoch:19 step:17845 [D loss: 0.534680, acc.: 69.53%] [G loss: 0.563443]\n",
      "epoch:19 step:17846 [D loss: 0.522623, acc.: 71.88%] [G loss: 0.567552]\n",
      "epoch:19 step:17847 [D loss: 0.607791, acc.: 66.41%] [G loss: 0.513856]\n",
      "epoch:19 step:17848 [D loss: 0.500405, acc.: 72.66%] [G loss: 0.844869]\n",
      "epoch:19 step:17849 [D loss: 0.511604, acc.: 71.88%] [G loss: 0.664844]\n",
      "epoch:19 step:17850 [D loss: 0.539534, acc.: 67.19%] [G loss: 0.674063]\n",
      "epoch:19 step:17851 [D loss: 0.546225, acc.: 76.56%] [G loss: 0.637252]\n",
      "epoch:19 step:17852 [D loss: 0.443119, acc.: 78.12%] [G loss: 0.813380]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:17853 [D loss: 0.549679, acc.: 68.75%] [G loss: 0.688979]\n",
      "epoch:19 step:17854 [D loss: 0.690499, acc.: 56.25%] [G loss: 0.477323]\n",
      "epoch:19 step:17855 [D loss: 0.559702, acc.: 65.62%] [G loss: 0.597885]\n",
      "epoch:19 step:17856 [D loss: 0.524049, acc.: 71.88%] [G loss: 0.704572]\n",
      "epoch:19 step:17857 [D loss: 0.462579, acc.: 77.34%] [G loss: 0.753033]\n",
      "epoch:19 step:17858 [D loss: 0.540174, acc.: 69.53%] [G loss: 0.713027]\n",
      "epoch:19 step:17859 [D loss: 0.485652, acc.: 71.09%] [G loss: 0.721275]\n",
      "epoch:19 step:17860 [D loss: 0.578494, acc.: 65.62%] [G loss: 0.651199]\n",
      "epoch:19 step:17861 [D loss: 0.562063, acc.: 71.09%] [G loss: 0.615403]\n",
      "epoch:19 step:17862 [D loss: 0.491879, acc.: 75.78%] [G loss: 0.781683]\n",
      "epoch:19 step:17863 [D loss: 0.577381, acc.: 64.84%] [G loss: 0.688333]\n",
      "epoch:19 step:17864 [D loss: 0.556907, acc.: 70.31%] [G loss: 0.686261]\n",
      "epoch:19 step:17865 [D loss: 0.573133, acc.: 67.97%] [G loss: 0.517509]\n",
      "epoch:19 step:17866 [D loss: 0.555322, acc.: 70.31%] [G loss: 0.620427]\n",
      "epoch:19 step:17867 [D loss: 0.575716, acc.: 66.41%] [G loss: 0.716506]\n",
      "epoch:19 step:17868 [D loss: 0.504595, acc.: 75.78%] [G loss: 0.519917]\n",
      "epoch:19 step:17869 [D loss: 0.544416, acc.: 69.53%] [G loss: 0.633524]\n",
      "epoch:19 step:17870 [D loss: 0.577365, acc.: 67.19%] [G loss: 0.565836]\n",
      "epoch:19 step:17871 [D loss: 0.531592, acc.: 72.66%] [G loss: 0.592684]\n",
      "epoch:19 step:17872 [D loss: 0.451940, acc.: 82.03%] [G loss: 0.647995]\n",
      "epoch:19 step:17873 [D loss: 0.563704, acc.: 71.88%] [G loss: 0.678350]\n",
      "epoch:19 step:17874 [D loss: 0.515644, acc.: 75.00%] [G loss: 0.725736]\n",
      "epoch:19 step:17875 [D loss: 0.552323, acc.: 69.53%] [G loss: 0.547613]\n",
      "epoch:19 step:17876 [D loss: 0.533614, acc.: 71.09%] [G loss: 0.579784]\n",
      "epoch:19 step:17877 [D loss: 0.533072, acc.: 73.44%] [G loss: 0.586914]\n",
      "epoch:19 step:17878 [D loss: 0.492236, acc.: 74.22%] [G loss: 0.800528]\n",
      "epoch:19 step:17879 [D loss: 0.472711, acc.: 74.22%] [G loss: 0.931066]\n",
      "epoch:19 step:17880 [D loss: 0.415112, acc.: 81.25%] [G loss: 0.844507]\n",
      "epoch:19 step:17881 [D loss: 0.585895, acc.: 70.31%] [G loss: 0.736973]\n",
      "epoch:19 step:17882 [D loss: 0.500232, acc.: 75.78%] [G loss: 0.756527]\n",
      "epoch:19 step:17883 [D loss: 0.550045, acc.: 72.66%] [G loss: 0.613976]\n",
      "epoch:19 step:17884 [D loss: 0.532825, acc.: 71.88%] [G loss: 0.685311]\n",
      "epoch:19 step:17885 [D loss: 0.551705, acc.: 66.41%] [G loss: 0.614890]\n",
      "epoch:19 step:17886 [D loss: 0.454581, acc.: 79.69%] [G loss: 0.833766]\n",
      "epoch:19 step:17887 [D loss: 0.535405, acc.: 69.53%] [G loss: 0.694658]\n",
      "epoch:19 step:17888 [D loss: 0.612974, acc.: 64.84%] [G loss: 0.669750]\n",
      "epoch:19 step:17889 [D loss: 0.487953, acc.: 77.34%] [G loss: 0.757325]\n",
      "epoch:19 step:17890 [D loss: 0.517794, acc.: 73.44%] [G loss: 0.680705]\n",
      "epoch:19 step:17891 [D loss: 0.496467, acc.: 75.78%] [G loss: 0.660532]\n",
      "epoch:19 step:17892 [D loss: 0.495753, acc.: 77.34%] [G loss: 0.761293]\n",
      "epoch:19 step:17893 [D loss: 0.487840, acc.: 75.78%] [G loss: 0.686150]\n",
      "epoch:19 step:17894 [D loss: 0.536717, acc.: 72.66%] [G loss: 0.603341]\n",
      "epoch:19 step:17895 [D loss: 0.430171, acc.: 83.59%] [G loss: 0.795445]\n",
      "epoch:19 step:17896 [D loss: 0.507031, acc.: 72.66%] [G loss: 0.718257]\n",
      "epoch:19 step:17897 [D loss: 0.492298, acc.: 73.44%] [G loss: 0.860964]\n",
      "epoch:19 step:17898 [D loss: 0.526836, acc.: 73.44%] [G loss: 0.945953]\n",
      "epoch:19 step:17899 [D loss: 0.570345, acc.: 65.62%] [G loss: 0.817585]\n",
      "epoch:19 step:17900 [D loss: 0.515566, acc.: 77.34%] [G loss: 0.658001]\n",
      "epoch:19 step:17901 [D loss: 0.519699, acc.: 71.88%] [G loss: 0.634843]\n",
      "epoch:19 step:17902 [D loss: 0.478137, acc.: 76.56%] [G loss: 0.642975]\n",
      "epoch:19 step:17903 [D loss: 0.473906, acc.: 77.34%] [G loss: 1.125459]\n",
      "epoch:19 step:17904 [D loss: 0.563973, acc.: 71.09%] [G loss: 0.922106]\n",
      "epoch:19 step:17905 [D loss: 0.627387, acc.: 67.19%] [G loss: 0.675436]\n",
      "epoch:19 step:17906 [D loss: 0.491427, acc.: 71.88%] [G loss: 0.696760]\n",
      "epoch:19 step:17907 [D loss: 0.486696, acc.: 73.44%] [G loss: 0.743212]\n",
      "epoch:19 step:17908 [D loss: 0.559291, acc.: 67.19%] [G loss: 0.708448]\n",
      "epoch:19 step:17909 [D loss: 0.554770, acc.: 71.09%] [G loss: 0.603504]\n",
      "epoch:19 step:17910 [D loss: 0.541680, acc.: 73.44%] [G loss: 0.681094]\n",
      "epoch:19 step:17911 [D loss: 0.630889, acc.: 62.50%] [G loss: 0.688733]\n",
      "epoch:19 step:17912 [D loss: 0.608973, acc.: 64.84%] [G loss: 0.691556]\n",
      "epoch:19 step:17913 [D loss: 0.631556, acc.: 65.62%] [G loss: 0.636787]\n",
      "epoch:19 step:17914 [D loss: 0.507495, acc.: 70.31%] [G loss: 0.717874]\n",
      "epoch:19 step:17915 [D loss: 0.497418, acc.: 75.78%] [G loss: 0.697057]\n",
      "epoch:19 step:17916 [D loss: 0.521294, acc.: 71.09%] [G loss: 0.711033]\n",
      "epoch:19 step:17917 [D loss: 0.570123, acc.: 70.31%] [G loss: 0.615223]\n",
      "epoch:19 step:17918 [D loss: 0.509438, acc.: 75.00%] [G loss: 0.683226]\n",
      "epoch:19 step:17919 [D loss: 0.463639, acc.: 78.12%] [G loss: 0.792283]\n",
      "epoch:19 step:17920 [D loss: 0.531831, acc.: 69.53%] [G loss: 0.727388]\n",
      "epoch:19 step:17921 [D loss: 0.535706, acc.: 69.53%] [G loss: 0.690795]\n",
      "epoch:19 step:17922 [D loss: 0.478731, acc.: 75.00%] [G loss: 0.892419]\n",
      "epoch:19 step:17923 [D loss: 0.582944, acc.: 71.88%] [G loss: 0.698874]\n",
      "epoch:19 step:17924 [D loss: 0.504082, acc.: 74.22%] [G loss: 0.691589]\n",
      "epoch:19 step:17925 [D loss: 0.501104, acc.: 76.56%] [G loss: 0.877487]\n",
      "epoch:19 step:17926 [D loss: 0.493631, acc.: 75.00%] [G loss: 0.821805]\n",
      "epoch:19 step:17927 [D loss: 0.580759, acc.: 69.53%] [G loss: 0.786666]\n",
      "epoch:19 step:17928 [D loss: 0.577265, acc.: 66.41%] [G loss: 0.697617]\n",
      "epoch:19 step:17929 [D loss: 0.565832, acc.: 66.41%] [G loss: 0.597998]\n",
      "epoch:19 step:17930 [D loss: 0.404090, acc.: 82.03%] [G loss: 0.593226]\n",
      "epoch:19 step:17931 [D loss: 0.504769, acc.: 75.78%] [G loss: 0.667851]\n",
      "epoch:19 step:17932 [D loss: 0.572777, acc.: 75.00%] [G loss: 0.694181]\n",
      "epoch:19 step:17933 [D loss: 0.483814, acc.: 76.56%] [G loss: 0.677877]\n",
      "epoch:19 step:17934 [D loss: 0.534164, acc.: 70.31%] [G loss: 0.684091]\n",
      "epoch:19 step:17935 [D loss: 0.539342, acc.: 74.22%] [G loss: 0.733440]\n",
      "epoch:19 step:17936 [D loss: 0.555518, acc.: 68.75%] [G loss: 0.714169]\n",
      "epoch:19 step:17937 [D loss: 0.529091, acc.: 71.09%] [G loss: 0.901390]\n",
      "epoch:19 step:17938 [D loss: 0.571027, acc.: 71.09%] [G loss: 0.614383]\n",
      "epoch:19 step:17939 [D loss: 0.586811, acc.: 72.66%] [G loss: 0.780150]\n",
      "epoch:19 step:17940 [D loss: 0.625174, acc.: 60.16%] [G loss: 0.663744]\n",
      "epoch:19 step:17941 [D loss: 0.533046, acc.: 70.31%] [G loss: 0.557566]\n",
      "epoch:19 step:17942 [D loss: 0.516078, acc.: 70.31%] [G loss: 0.767786]\n",
      "epoch:19 step:17943 [D loss: 0.547775, acc.: 69.53%] [G loss: 0.624914]\n",
      "epoch:19 step:17944 [D loss: 0.547041, acc.: 69.53%] [G loss: 0.745392]\n",
      "epoch:19 step:17945 [D loss: 0.565487, acc.: 66.41%] [G loss: 0.589344]\n",
      "epoch:19 step:17946 [D loss: 0.574255, acc.: 70.31%] [G loss: 0.631951]\n",
      "epoch:19 step:17947 [D loss: 0.507963, acc.: 74.22%] [G loss: 0.595226]\n",
      "epoch:19 step:17948 [D loss: 0.540629, acc.: 64.84%] [G loss: 0.831938]\n",
      "epoch:19 step:17949 [D loss: 0.465261, acc.: 75.78%] [G loss: 0.651871]\n",
      "epoch:19 step:17950 [D loss: 0.629670, acc.: 67.19%] [G loss: 0.654176]\n",
      "epoch:19 step:17951 [D loss: 0.626712, acc.: 59.38%] [G loss: 0.593405]\n",
      "epoch:19 step:17952 [D loss: 0.468859, acc.: 78.12%] [G loss: 0.832175]\n",
      "epoch:19 step:17953 [D loss: 0.571090, acc.: 71.88%] [G loss: 0.600521]\n",
      "epoch:19 step:17954 [D loss: 0.549132, acc.: 67.97%] [G loss: 0.659606]\n",
      "epoch:19 step:17955 [D loss: 0.431026, acc.: 80.47%] [G loss: 0.784468]\n",
      "epoch:19 step:17956 [D loss: 0.560394, acc.: 67.97%] [G loss: 0.679632]\n",
      "epoch:19 step:17957 [D loss: 0.538257, acc.: 70.31%] [G loss: 0.717740]\n",
      "epoch:19 step:17958 [D loss: 0.483134, acc.: 72.66%] [G loss: 0.885093]\n",
      "epoch:19 step:17959 [D loss: 0.502136, acc.: 74.22%] [G loss: 0.744559]\n",
      "epoch:19 step:17960 [D loss: 0.539689, acc.: 68.75%] [G loss: 0.817642]\n",
      "epoch:19 step:17961 [D loss: 0.562098, acc.: 67.97%] [G loss: 0.739793]\n",
      "epoch:19 step:17962 [D loss: 0.544670, acc.: 69.53%] [G loss: 0.666117]\n",
      "epoch:19 step:17963 [D loss: 0.563876, acc.: 69.53%] [G loss: 0.873920]\n",
      "epoch:19 step:17964 [D loss: 0.594274, acc.: 65.62%] [G loss: 0.840369]\n",
      "epoch:19 step:17965 [D loss: 0.486506, acc.: 78.12%] [G loss: 0.817851]\n",
      "epoch:19 step:17966 [D loss: 0.514827, acc.: 68.75%] [G loss: 0.652777]\n",
      "epoch:19 step:17967 [D loss: 0.508801, acc.: 72.66%] [G loss: 0.644379]\n",
      "epoch:19 step:17968 [D loss: 0.513496, acc.: 71.09%] [G loss: 0.666832]\n",
      "epoch:19 step:17969 [D loss: 0.491444, acc.: 75.00%] [G loss: 0.556023]\n",
      "epoch:19 step:17970 [D loss: 0.561318, acc.: 68.75%] [G loss: 0.616890]\n",
      "epoch:19 step:17971 [D loss: 0.487852, acc.: 78.12%] [G loss: 0.647497]\n",
      "epoch:19 step:17972 [D loss: 0.560237, acc.: 67.19%] [G loss: 0.544425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:17973 [D loss: 0.561226, acc.: 66.41%] [G loss: 0.677740]\n",
      "epoch:19 step:17974 [D loss: 0.555223, acc.: 71.09%] [G loss: 0.617881]\n",
      "epoch:19 step:17975 [D loss: 0.497462, acc.: 74.22%] [G loss: 0.630569]\n",
      "epoch:19 step:17976 [D loss: 0.488658, acc.: 73.44%] [G loss: 0.822603]\n",
      "epoch:19 step:17977 [D loss: 0.548371, acc.: 71.09%] [G loss: 0.663488]\n",
      "epoch:19 step:17978 [D loss: 0.589968, acc.: 63.28%] [G loss: 0.557373]\n",
      "epoch:19 step:17979 [D loss: 0.519983, acc.: 71.88%] [G loss: 0.684259]\n",
      "epoch:19 step:17980 [D loss: 0.520636, acc.: 73.44%] [G loss: 0.715112]\n",
      "epoch:19 step:17981 [D loss: 0.527562, acc.: 71.09%] [G loss: 0.662943]\n",
      "epoch:19 step:17982 [D loss: 0.492219, acc.: 73.44%] [G loss: 0.644875]\n",
      "epoch:19 step:17983 [D loss: 0.578831, acc.: 68.75%] [G loss: 0.470322]\n",
      "epoch:19 step:17984 [D loss: 0.545761, acc.: 69.53%] [G loss: 0.637527]\n",
      "epoch:19 step:17985 [D loss: 0.558048, acc.: 70.31%] [G loss: 0.522538]\n",
      "epoch:19 step:17986 [D loss: 0.586573, acc.: 63.28%] [G loss: 0.557637]\n",
      "epoch:19 step:17987 [D loss: 0.502531, acc.: 74.22%] [G loss: 0.725507]\n",
      "epoch:19 step:17988 [D loss: 0.526167, acc.: 68.75%] [G loss: 0.647204]\n",
      "epoch:19 step:17989 [D loss: 0.523641, acc.: 70.31%] [G loss: 0.655574]\n",
      "epoch:19 step:17990 [D loss: 0.566852, acc.: 67.97%] [G loss: 0.663147]\n",
      "epoch:19 step:17991 [D loss: 0.534592, acc.: 70.31%] [G loss: 0.527337]\n",
      "epoch:19 step:17992 [D loss: 0.607241, acc.: 61.72%] [G loss: 0.703669]\n",
      "epoch:19 step:17993 [D loss: 0.522921, acc.: 73.44%] [G loss: 0.639553]\n",
      "epoch:19 step:17994 [D loss: 0.482869, acc.: 78.12%] [G loss: 0.652406]\n",
      "epoch:19 step:17995 [D loss: 0.522436, acc.: 71.09%] [G loss: 0.683366]\n",
      "epoch:19 step:17996 [D loss: 0.597481, acc.: 67.19%] [G loss: 0.609977]\n",
      "epoch:19 step:17997 [D loss: 0.408105, acc.: 82.81%] [G loss: 0.684535]\n",
      "epoch:19 step:17998 [D loss: 0.601319, acc.: 67.19%] [G loss: 0.626739]\n",
      "epoch:19 step:17999 [D loss: 0.577420, acc.: 64.84%] [G loss: 0.657862]\n",
      "epoch:19 step:18000 [D loss: 0.533003, acc.: 70.31%] [G loss: 0.697876]\n",
      "##############\n",
      "[2.87550012 1.15707828 6.2321001  4.89627802 3.54815347 5.64090228\n",
      " 4.49242333 4.96815469 4.52024113 4.21478693]\n",
      "##########\n",
      "epoch:19 step:18001 [D loss: 0.469556, acc.: 75.78%] [G loss: 0.717031]\n",
      "epoch:19 step:18002 [D loss: 0.526416, acc.: 70.31%] [G loss: 0.763247]\n",
      "epoch:19 step:18003 [D loss: 0.618455, acc.: 62.50%] [G loss: 0.587550]\n",
      "epoch:19 step:18004 [D loss: 0.571747, acc.: 68.75%] [G loss: 0.613173]\n",
      "epoch:19 step:18005 [D loss: 0.584417, acc.: 68.75%] [G loss: 0.561630]\n",
      "epoch:19 step:18006 [D loss: 0.642658, acc.: 61.72%] [G loss: 0.560471]\n",
      "epoch:19 step:18007 [D loss: 0.582234, acc.: 69.53%] [G loss: 0.616970]\n",
      "epoch:19 step:18008 [D loss: 0.542142, acc.: 69.53%] [G loss: 0.726915]\n",
      "epoch:19 step:18009 [D loss: 0.505734, acc.: 74.22%] [G loss: 0.762757]\n",
      "epoch:19 step:18010 [D loss: 0.499657, acc.: 78.12%] [G loss: 0.865775]\n",
      "epoch:19 step:18011 [D loss: 0.485761, acc.: 75.78%] [G loss: 0.774303]\n",
      "epoch:19 step:18012 [D loss: 0.493802, acc.: 74.22%] [G loss: 0.805802]\n",
      "epoch:19 step:18013 [D loss: 0.633522, acc.: 64.06%] [G loss: 0.594118]\n",
      "epoch:19 step:18014 [D loss: 0.656591, acc.: 62.50%] [G loss: 0.453647]\n",
      "epoch:19 step:18015 [D loss: 0.527058, acc.: 73.44%] [G loss: 0.532429]\n",
      "epoch:19 step:18016 [D loss: 0.495134, acc.: 73.44%] [G loss: 0.593483]\n",
      "epoch:19 step:18017 [D loss: 0.682726, acc.: 62.50%] [G loss: 0.610875]\n",
      "epoch:19 step:18018 [D loss: 0.595946, acc.: 67.19%] [G loss: 0.632615]\n",
      "epoch:19 step:18019 [D loss: 0.520957, acc.: 73.44%] [G loss: 0.628373]\n",
      "epoch:19 step:18020 [D loss: 0.495259, acc.: 71.88%] [G loss: 0.691918]\n",
      "epoch:19 step:18021 [D loss: 0.507104, acc.: 69.53%] [G loss: 0.757495]\n",
      "epoch:19 step:18022 [D loss: 0.493956, acc.: 75.00%] [G loss: 0.722940]\n",
      "epoch:19 step:18023 [D loss: 0.585155, acc.: 67.19%] [G loss: 0.714628]\n",
      "epoch:19 step:18024 [D loss: 0.555003, acc.: 65.62%] [G loss: 0.773704]\n",
      "epoch:19 step:18025 [D loss: 0.502769, acc.: 72.66%] [G loss: 0.737679]\n",
      "epoch:19 step:18026 [D loss: 0.546194, acc.: 68.75%] [G loss: 0.953273]\n",
      "epoch:19 step:18027 [D loss: 0.579065, acc.: 68.75%] [G loss: 0.917241]\n",
      "epoch:19 step:18028 [D loss: 0.501353, acc.: 75.00%] [G loss: 0.615815]\n",
      "epoch:19 step:18029 [D loss: 0.623436, acc.: 61.72%] [G loss: 0.606905]\n",
      "epoch:19 step:18030 [D loss: 0.567446, acc.: 68.75%] [G loss: 0.796387]\n",
      "epoch:19 step:18031 [D loss: 0.569695, acc.: 66.41%] [G loss: 0.553181]\n",
      "epoch:19 step:18032 [D loss: 0.564798, acc.: 72.66%] [G loss: 0.541280]\n",
      "epoch:19 step:18033 [D loss: 0.506828, acc.: 74.22%] [G loss: 0.724973]\n",
      "epoch:19 step:18034 [D loss: 0.476353, acc.: 75.78%] [G loss: 0.919689]\n",
      "epoch:19 step:18035 [D loss: 0.505657, acc.: 72.66%] [G loss: 0.902631]\n",
      "epoch:19 step:18036 [D loss: 0.568658, acc.: 68.75%] [G loss: 0.980871]\n",
      "epoch:19 step:18037 [D loss: 0.548883, acc.: 71.09%] [G loss: 0.533452]\n",
      "epoch:19 step:18038 [D loss: 0.553827, acc.: 70.31%] [G loss: 0.716906]\n",
      "epoch:19 step:18039 [D loss: 0.519417, acc.: 74.22%] [G loss: 0.675812]\n",
      "epoch:19 step:18040 [D loss: 0.514333, acc.: 75.78%] [G loss: 0.650134]\n",
      "epoch:19 step:18041 [D loss: 0.593411, acc.: 69.53%] [G loss: 0.732988]\n",
      "epoch:19 step:18042 [D loss: 0.540107, acc.: 67.19%] [G loss: 0.700848]\n",
      "epoch:19 step:18043 [D loss: 0.527262, acc.: 70.31%] [G loss: 0.845657]\n",
      "epoch:19 step:18044 [D loss: 0.498585, acc.: 72.66%] [G loss: 0.855914]\n",
      "epoch:19 step:18045 [D loss: 0.520323, acc.: 74.22%] [G loss: 0.596894]\n",
      "epoch:19 step:18046 [D loss: 0.544903, acc.: 67.19%] [G loss: 0.813085]\n",
      "epoch:19 step:18047 [D loss: 0.482041, acc.: 69.53%] [G loss: 0.715712]\n",
      "epoch:19 step:18048 [D loss: 0.512733, acc.: 73.44%] [G loss: 0.669860]\n",
      "epoch:19 step:18049 [D loss: 0.556492, acc.: 67.97%] [G loss: 0.737934]\n",
      "epoch:19 step:18050 [D loss: 0.523256, acc.: 70.31%] [G loss: 0.663983]\n",
      "epoch:19 step:18051 [D loss: 0.517123, acc.: 72.66%] [G loss: 0.709610]\n",
      "epoch:19 step:18052 [D loss: 0.554352, acc.: 71.09%] [G loss: 0.664873]\n",
      "epoch:19 step:18053 [D loss: 0.599424, acc.: 65.62%] [G loss: 0.586266]\n",
      "epoch:19 step:18054 [D loss: 0.624136, acc.: 60.94%] [G loss: 0.633355]\n",
      "epoch:19 step:18055 [D loss: 0.545501, acc.: 68.75%] [G loss: 0.785341]\n",
      "epoch:19 step:18056 [D loss: 0.562828, acc.: 69.53%] [G loss: 0.642153]\n",
      "epoch:19 step:18057 [D loss: 0.511613, acc.: 75.00%] [G loss: 0.575152]\n",
      "epoch:19 step:18058 [D loss: 0.590153, acc.: 67.19%] [G loss: 0.532067]\n",
      "epoch:19 step:18059 [D loss: 0.548696, acc.: 73.44%] [G loss: 0.599333]\n",
      "epoch:19 step:18060 [D loss: 0.572005, acc.: 63.28%] [G loss: 0.620016]\n",
      "epoch:19 step:18061 [D loss: 0.494466, acc.: 71.88%] [G loss: 0.656910]\n",
      "epoch:19 step:18062 [D loss: 0.524253, acc.: 72.66%] [G loss: 0.654406]\n",
      "epoch:19 step:18063 [D loss: 0.554950, acc.: 67.97%] [G loss: 0.592219]\n",
      "epoch:19 step:18064 [D loss: 0.490823, acc.: 78.12%] [G loss: 0.671395]\n",
      "epoch:19 step:18065 [D loss: 0.527568, acc.: 69.53%] [G loss: 0.655266]\n",
      "epoch:19 step:18066 [D loss: 0.575537, acc.: 69.53%] [G loss: 0.473163]\n",
      "epoch:19 step:18067 [D loss: 0.550045, acc.: 69.53%] [G loss: 0.634646]\n",
      "epoch:19 step:18068 [D loss: 0.524071, acc.: 71.09%] [G loss: 0.643984]\n",
      "epoch:19 step:18069 [D loss: 0.570476, acc.: 71.09%] [G loss: 0.622801]\n",
      "epoch:19 step:18070 [D loss: 0.552397, acc.: 67.97%] [G loss: 0.592195]\n",
      "epoch:19 step:18071 [D loss: 0.543975, acc.: 65.62%] [G loss: 0.713035]\n",
      "epoch:19 step:18072 [D loss: 0.563492, acc.: 67.19%] [G loss: 0.472756]\n",
      "epoch:19 step:18073 [D loss: 0.529551, acc.: 72.66%] [G loss: 0.545186]\n",
      "epoch:19 step:18074 [D loss: 0.473356, acc.: 72.66%] [G loss: 0.818437]\n",
      "epoch:19 step:18075 [D loss: 0.525272, acc.: 70.31%] [G loss: 0.598470]\n",
      "epoch:19 step:18076 [D loss: 0.546753, acc.: 73.44%] [G loss: 0.585593]\n",
      "epoch:19 step:18077 [D loss: 0.536898, acc.: 72.66%] [G loss: 0.761000]\n",
      "epoch:19 step:18078 [D loss: 0.593078, acc.: 70.31%] [G loss: 0.720755]\n",
      "epoch:19 step:18079 [D loss: 0.497524, acc.: 75.78%] [G loss: 0.693705]\n",
      "epoch:19 step:18080 [D loss: 0.656754, acc.: 62.50%] [G loss: 0.443181]\n",
      "epoch:19 step:18081 [D loss: 0.613956, acc.: 63.28%] [G loss: 0.488986]\n",
      "epoch:19 step:18082 [D loss: 0.535253, acc.: 72.66%] [G loss: 0.536155]\n",
      "epoch:19 step:18083 [D loss: 0.534318, acc.: 71.09%] [G loss: 0.631482]\n",
      "epoch:19 step:18084 [D loss: 0.579529, acc.: 69.53%] [G loss: 0.680192]\n",
      "epoch:19 step:18085 [D loss: 0.556197, acc.: 70.31%] [G loss: 0.670920]\n",
      "epoch:19 step:18086 [D loss: 0.493478, acc.: 76.56%] [G loss: 0.632258]\n",
      "epoch:19 step:18087 [D loss: 0.562864, acc.: 68.75%] [G loss: 0.559233]\n",
      "epoch:19 step:18088 [D loss: 0.512602, acc.: 69.53%] [G loss: 0.507457]\n",
      "epoch:19 step:18089 [D loss: 0.488035, acc.: 71.88%] [G loss: 0.741650]\n",
      "epoch:19 step:18090 [D loss: 0.580570, acc.: 64.84%] [G loss: 0.704157]\n",
      "epoch:19 step:18091 [D loss: 0.562976, acc.: 69.53%] [G loss: 0.519189]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18092 [D loss: 0.513294, acc.: 70.31%] [G loss: 0.745716]\n",
      "epoch:19 step:18093 [D loss: 0.529365, acc.: 71.88%] [G loss: 0.645259]\n",
      "epoch:19 step:18094 [D loss: 0.653199, acc.: 62.50%] [G loss: 0.589824]\n",
      "epoch:19 step:18095 [D loss: 0.515532, acc.: 72.66%] [G loss: 0.642708]\n",
      "epoch:19 step:18096 [D loss: 0.545179, acc.: 73.44%] [G loss: 0.659278]\n",
      "epoch:19 step:18097 [D loss: 0.583350, acc.: 69.53%] [G loss: 0.471562]\n",
      "epoch:19 step:18098 [D loss: 0.561154, acc.: 65.62%] [G loss: 0.539217]\n",
      "epoch:19 step:18099 [D loss: 0.439181, acc.: 78.12%] [G loss: 0.548871]\n",
      "epoch:19 step:18100 [D loss: 0.527624, acc.: 73.44%] [G loss: 0.615288]\n",
      "epoch:19 step:18101 [D loss: 0.536940, acc.: 71.88%] [G loss: 0.729737]\n",
      "epoch:19 step:18102 [D loss: 0.479911, acc.: 75.78%] [G loss: 0.596949]\n",
      "epoch:19 step:18103 [D loss: 0.527083, acc.: 75.00%] [G loss: 0.770583]\n",
      "epoch:19 step:18104 [D loss: 0.611205, acc.: 67.97%] [G loss: 0.643781]\n",
      "epoch:19 step:18105 [D loss: 0.518794, acc.: 72.66%] [G loss: 0.698049]\n",
      "epoch:19 step:18106 [D loss: 0.564288, acc.: 71.88%] [G loss: 0.708416]\n",
      "epoch:19 step:18107 [D loss: 0.459789, acc.: 79.69%] [G loss: 0.718499]\n",
      "epoch:19 step:18108 [D loss: 0.567631, acc.: 73.44%] [G loss: 0.676804]\n",
      "epoch:19 step:18109 [D loss: 0.542562, acc.: 71.09%] [G loss: 0.689919]\n",
      "epoch:19 step:18110 [D loss: 0.518270, acc.: 72.66%] [G loss: 0.866751]\n",
      "epoch:19 step:18111 [D loss: 0.570911, acc.: 65.62%] [G loss: 0.754552]\n",
      "epoch:19 step:18112 [D loss: 0.489589, acc.: 76.56%] [G loss: 0.594645]\n",
      "epoch:19 step:18113 [D loss: 0.533260, acc.: 72.66%] [G loss: 0.695983]\n",
      "epoch:19 step:18114 [D loss: 0.455585, acc.: 75.78%] [G loss: 0.656355]\n",
      "epoch:19 step:18115 [D loss: 0.489742, acc.: 76.56%] [G loss: 0.896094]\n",
      "epoch:19 step:18116 [D loss: 0.430528, acc.: 78.91%] [G loss: 1.013600]\n",
      "epoch:19 step:18117 [D loss: 0.446244, acc.: 79.69%] [G loss: 0.944885]\n",
      "epoch:19 step:18118 [D loss: 0.421970, acc.: 81.25%] [G loss: 1.145900]\n",
      "epoch:19 step:18119 [D loss: 0.733294, acc.: 60.16%] [G loss: 0.604811]\n",
      "epoch:19 step:18120 [D loss: 0.616864, acc.: 63.28%] [G loss: 0.699633]\n",
      "epoch:19 step:18121 [D loss: 0.553503, acc.: 66.41%] [G loss: 0.664142]\n",
      "epoch:19 step:18122 [D loss: 0.547483, acc.: 71.88%] [G loss: 0.499048]\n",
      "epoch:19 step:18123 [D loss: 0.539573, acc.: 71.09%] [G loss: 0.692424]\n",
      "epoch:19 step:18124 [D loss: 0.469633, acc.: 82.81%] [G loss: 0.707373]\n",
      "epoch:19 step:18125 [D loss: 0.658167, acc.: 61.72%] [G loss: 0.503312]\n",
      "epoch:19 step:18126 [D loss: 0.558220, acc.: 68.75%] [G loss: 0.651617]\n",
      "epoch:19 step:18127 [D loss: 0.541335, acc.: 72.66%] [G loss: 0.487790]\n",
      "epoch:19 step:18128 [D loss: 0.560182, acc.: 71.09%] [G loss: 0.593772]\n",
      "epoch:19 step:18129 [D loss: 0.474836, acc.: 75.00%] [G loss: 0.726058]\n",
      "epoch:19 step:18130 [D loss: 0.523249, acc.: 74.22%] [G loss: 0.730959]\n",
      "epoch:19 step:18131 [D loss: 0.448993, acc.: 78.12%] [G loss: 0.690897]\n",
      "epoch:19 step:18132 [D loss: 0.514986, acc.: 71.88%] [G loss: 0.665312]\n",
      "epoch:19 step:18133 [D loss: 0.584561, acc.: 68.75%] [G loss: 0.497992]\n",
      "epoch:19 step:18134 [D loss: 0.546306, acc.: 75.00%] [G loss: 0.609097]\n",
      "epoch:19 step:18135 [D loss: 0.525798, acc.: 67.19%] [G loss: 0.496356]\n",
      "epoch:19 step:18136 [D loss: 0.494804, acc.: 72.66%] [G loss: 0.519304]\n",
      "epoch:19 step:18137 [D loss: 0.483427, acc.: 80.47%] [G loss: 0.739686]\n",
      "epoch:19 step:18138 [D loss: 0.529379, acc.: 75.00%] [G loss: 0.627457]\n",
      "epoch:19 step:18139 [D loss: 0.471383, acc.: 79.69%] [G loss: 0.780728]\n",
      "epoch:19 step:18140 [D loss: 0.537458, acc.: 70.31%] [G loss: 0.717321]\n",
      "epoch:19 step:18141 [D loss: 0.522514, acc.: 71.09%] [G loss: 0.588246]\n",
      "epoch:19 step:18142 [D loss: 0.538726, acc.: 69.53%] [G loss: 0.748623]\n",
      "epoch:19 step:18143 [D loss: 0.493429, acc.: 74.22%] [G loss: 0.838213]\n",
      "epoch:19 step:18144 [D loss: 0.566078, acc.: 76.56%] [G loss: 0.765962]\n",
      "epoch:19 step:18145 [D loss: 0.648880, acc.: 58.59%] [G loss: 0.598233]\n",
      "epoch:19 step:18146 [D loss: 0.504788, acc.: 74.22%] [G loss: 0.691870]\n",
      "epoch:19 step:18147 [D loss: 0.462837, acc.: 75.78%] [G loss: 0.932503]\n",
      "epoch:19 step:18148 [D loss: 0.594362, acc.: 67.19%] [G loss: 0.680485]\n",
      "epoch:19 step:18149 [D loss: 0.513727, acc.: 74.22%] [G loss: 0.665755]\n",
      "epoch:19 step:18150 [D loss: 0.434062, acc.: 82.81%] [G loss: 0.895236]\n",
      "epoch:19 step:18151 [D loss: 0.656798, acc.: 64.84%] [G loss: 0.731753]\n",
      "epoch:19 step:18152 [D loss: 0.723181, acc.: 53.91%] [G loss: 0.556333]\n",
      "epoch:19 step:18153 [D loss: 0.517703, acc.: 73.44%] [G loss: 0.588086]\n",
      "epoch:19 step:18154 [D loss: 0.547314, acc.: 64.84%] [G loss: 0.656449]\n",
      "epoch:19 step:18155 [D loss: 0.639824, acc.: 66.41%] [G loss: 0.647485]\n",
      "epoch:19 step:18156 [D loss: 0.600570, acc.: 67.19%] [G loss: 0.740386]\n",
      "epoch:19 step:18157 [D loss: 0.391438, acc.: 82.81%] [G loss: 0.788832]\n",
      "epoch:19 step:18158 [D loss: 0.528629, acc.: 70.31%] [G loss: 0.969095]\n",
      "epoch:19 step:18159 [D loss: 0.596639, acc.: 63.28%] [G loss: 0.653716]\n",
      "epoch:19 step:18160 [D loss: 0.439600, acc.: 79.69%] [G loss: 0.799411]\n",
      "epoch:19 step:18161 [D loss: 0.464287, acc.: 75.00%] [G loss: 0.820514]\n",
      "epoch:19 step:18162 [D loss: 0.473667, acc.: 78.12%] [G loss: 0.861505]\n",
      "epoch:19 step:18163 [D loss: 0.496292, acc.: 71.88%] [G loss: 0.860632]\n",
      "epoch:19 step:18164 [D loss: 0.463097, acc.: 78.12%] [G loss: 0.750179]\n",
      "epoch:19 step:18165 [D loss: 0.545509, acc.: 69.53%] [G loss: 0.750770]\n",
      "epoch:19 step:18166 [D loss: 0.548134, acc.: 68.75%] [G loss: 0.712610]\n",
      "epoch:19 step:18167 [D loss: 0.515662, acc.: 73.44%] [G loss: 0.706795]\n",
      "epoch:19 step:18168 [D loss: 0.561169, acc.: 70.31%] [G loss: 0.625203]\n",
      "epoch:19 step:18169 [D loss: 0.550407, acc.: 70.31%] [G loss: 0.642135]\n",
      "epoch:19 step:18170 [D loss: 0.535590, acc.: 71.09%] [G loss: 0.639491]\n",
      "epoch:19 step:18171 [D loss: 0.548759, acc.: 67.19%] [G loss: 0.555943]\n",
      "epoch:19 step:18172 [D loss: 0.513300, acc.: 69.53%] [G loss: 0.757644]\n",
      "epoch:19 step:18173 [D loss: 0.524572, acc.: 74.22%] [G loss: 0.727032]\n",
      "epoch:19 step:18174 [D loss: 0.506783, acc.: 74.22%] [G loss: 0.818928]\n",
      "epoch:19 step:18175 [D loss: 0.543420, acc.: 75.00%] [G loss: 0.655982]\n",
      "epoch:19 step:18176 [D loss: 0.531238, acc.: 75.00%] [G loss: 0.726221]\n",
      "epoch:19 step:18177 [D loss: 0.517040, acc.: 72.66%] [G loss: 0.614805]\n",
      "epoch:19 step:18178 [D loss: 0.532666, acc.: 70.31%] [G loss: 0.669778]\n",
      "epoch:19 step:18179 [D loss: 0.709327, acc.: 61.72%] [G loss: 0.464128]\n",
      "epoch:19 step:18180 [D loss: 0.591820, acc.: 66.41%] [G loss: 0.595337]\n",
      "epoch:19 step:18181 [D loss: 0.516556, acc.: 73.44%] [G loss: 0.600464]\n",
      "epoch:19 step:18182 [D loss: 0.552359, acc.: 65.62%] [G loss: 0.739523]\n",
      "epoch:19 step:18183 [D loss: 0.563157, acc.: 67.97%] [G loss: 0.709432]\n",
      "epoch:19 step:18184 [D loss: 0.485711, acc.: 72.66%] [G loss: 0.522662]\n",
      "epoch:19 step:18185 [D loss: 0.520831, acc.: 70.31%] [G loss: 0.551806]\n",
      "epoch:19 step:18186 [D loss: 0.558656, acc.: 68.75%] [G loss: 0.574666]\n",
      "epoch:19 step:18187 [D loss: 0.528738, acc.: 71.88%] [G loss: 0.546106]\n",
      "epoch:19 step:18188 [D loss: 0.481572, acc.: 74.22%] [G loss: 0.618018]\n",
      "epoch:19 step:18189 [D loss: 0.635015, acc.: 60.94%] [G loss: 0.497265]\n",
      "epoch:19 step:18190 [D loss: 0.541261, acc.: 71.09%] [G loss: 0.505426]\n",
      "epoch:19 step:18191 [D loss: 0.503323, acc.: 75.78%] [G loss: 0.476680]\n",
      "epoch:19 step:18192 [D loss: 0.550062, acc.: 67.19%] [G loss: 0.696620]\n",
      "epoch:19 step:18193 [D loss: 0.566096, acc.: 69.53%] [G loss: 0.679713]\n",
      "epoch:19 step:18194 [D loss: 0.541994, acc.: 69.53%] [G loss: 0.670742]\n",
      "epoch:19 step:18195 [D loss: 0.542731, acc.: 71.88%] [G loss: 0.656564]\n",
      "epoch:19 step:18196 [D loss: 0.606410, acc.: 64.84%] [G loss: 0.689093]\n",
      "epoch:19 step:18197 [D loss: 0.560344, acc.: 69.53%] [G loss: 0.698911]\n",
      "epoch:19 step:18198 [D loss: 0.555222, acc.: 71.09%] [G loss: 0.705819]\n",
      "epoch:19 step:18199 [D loss: 0.543165, acc.: 71.88%] [G loss: 0.727859]\n",
      "epoch:19 step:18200 [D loss: 0.586535, acc.: 71.88%] [G loss: 0.674785]\n",
      "##############\n",
      "[2.87016157 0.90072356 6.14787264 4.96755446 3.65876978 5.82344978\n",
      " 4.46267974 4.73636127 4.73289896 4.19824497]\n",
      "##########\n",
      "epoch:19 step:18201 [D loss: 0.488989, acc.: 75.78%] [G loss: 0.641929]\n",
      "epoch:19 step:18202 [D loss: 0.490959, acc.: 77.34%] [G loss: 0.803208]\n",
      "epoch:19 step:18203 [D loss: 0.654639, acc.: 61.72%] [G loss: 0.731814]\n",
      "epoch:19 step:18204 [D loss: 0.656358, acc.: 58.59%] [G loss: 0.521215]\n",
      "epoch:19 step:18205 [D loss: 0.489331, acc.: 74.22%] [G loss: 0.721349]\n",
      "epoch:19 step:18206 [D loss: 0.496823, acc.: 75.00%] [G loss: 0.637960]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18207 [D loss: 0.646657, acc.: 57.03%] [G loss: 0.598083]\n",
      "epoch:19 step:18208 [D loss: 0.536470, acc.: 73.44%] [G loss: 0.670378]\n",
      "epoch:19 step:18209 [D loss: 0.469337, acc.: 75.78%] [G loss: 0.789108]\n",
      "epoch:19 step:18210 [D loss: 0.647020, acc.: 64.06%] [G loss: 1.005266]\n",
      "epoch:19 step:18211 [D loss: 0.589105, acc.: 65.62%] [G loss: 0.830919]\n",
      "epoch:19 step:18212 [D loss: 0.542090, acc.: 65.62%] [G loss: 0.819232]\n",
      "epoch:19 step:18213 [D loss: 0.586282, acc.: 69.53%] [G loss: 0.751922]\n",
      "epoch:19 step:18214 [D loss: 0.633149, acc.: 59.38%] [G loss: 0.719263]\n",
      "epoch:19 step:18215 [D loss: 0.605582, acc.: 61.72%] [G loss: 0.545828]\n",
      "epoch:19 step:18216 [D loss: 0.573295, acc.: 69.53%] [G loss: 0.599245]\n",
      "epoch:19 step:18217 [D loss: 0.512078, acc.: 72.66%] [G loss: 0.709652]\n",
      "epoch:19 step:18218 [D loss: 0.522090, acc.: 74.22%] [G loss: 0.706564]\n",
      "epoch:19 step:18219 [D loss: 0.502915, acc.: 75.00%] [G loss: 0.751722]\n",
      "epoch:19 step:18220 [D loss: 0.546613, acc.: 69.53%] [G loss: 0.695598]\n",
      "epoch:19 step:18221 [D loss: 0.637594, acc.: 60.16%] [G loss: 0.747687]\n",
      "epoch:19 step:18222 [D loss: 0.606908, acc.: 65.62%] [G loss: 0.571299]\n",
      "epoch:19 step:18223 [D loss: 0.599077, acc.: 62.50%] [G loss: 0.558134]\n",
      "epoch:19 step:18224 [D loss: 0.559003, acc.: 69.53%] [G loss: 0.594688]\n",
      "epoch:19 step:18225 [D loss: 0.574114, acc.: 63.28%] [G loss: 0.589493]\n",
      "epoch:19 step:18226 [D loss: 0.575496, acc.: 66.41%] [G loss: 0.681680]\n",
      "epoch:19 step:18227 [D loss: 0.574517, acc.: 65.62%] [G loss: 0.620416]\n",
      "epoch:19 step:18228 [D loss: 0.513593, acc.: 74.22%] [G loss: 0.643130]\n",
      "epoch:19 step:18229 [D loss: 0.484145, acc.: 75.00%] [G loss: 0.729050]\n",
      "epoch:19 step:18230 [D loss: 0.483284, acc.: 72.66%] [G loss: 0.727206]\n",
      "epoch:19 step:18231 [D loss: 0.530186, acc.: 70.31%] [G loss: 0.568696]\n",
      "epoch:19 step:18232 [D loss: 0.463973, acc.: 79.69%] [G loss: 0.601274]\n",
      "epoch:19 step:18233 [D loss: 0.441404, acc.: 80.47%] [G loss: 0.824042]\n",
      "epoch:19 step:18234 [D loss: 0.535104, acc.: 71.88%] [G loss: 0.725640]\n",
      "epoch:19 step:18235 [D loss: 0.611776, acc.: 64.06%] [G loss: 0.538946]\n",
      "epoch:19 step:18236 [D loss: 0.522470, acc.: 73.44%] [G loss: 0.654911]\n",
      "epoch:19 step:18237 [D loss: 0.516354, acc.: 71.09%] [G loss: 0.752518]\n",
      "epoch:19 step:18238 [D loss: 0.536967, acc.: 71.09%] [G loss: 0.730462]\n",
      "epoch:19 step:18239 [D loss: 0.478855, acc.: 76.56%] [G loss: 0.713674]\n",
      "epoch:19 step:18240 [D loss: 0.631013, acc.: 63.28%] [G loss: 0.651661]\n",
      "epoch:19 step:18241 [D loss: 0.576713, acc.: 68.75%] [G loss: 0.672951]\n",
      "epoch:19 step:18242 [D loss: 0.529978, acc.: 72.66%] [G loss: 0.553510]\n",
      "epoch:19 step:18243 [D loss: 0.483149, acc.: 78.12%] [G loss: 0.726020]\n",
      "epoch:19 step:18244 [D loss: 0.590837, acc.: 69.53%] [G loss: 0.651423]\n",
      "epoch:19 step:18245 [D loss: 0.645278, acc.: 67.97%] [G loss: 0.838691]\n",
      "epoch:19 step:18246 [D loss: 0.510957, acc.: 77.34%] [G loss: 0.623403]\n",
      "epoch:19 step:18247 [D loss: 0.546545, acc.: 72.66%] [G loss: 0.680954]\n",
      "epoch:19 step:18248 [D loss: 0.560363, acc.: 67.19%] [G loss: 0.716895]\n",
      "epoch:19 step:18249 [D loss: 0.480367, acc.: 77.34%] [G loss: 0.683510]\n",
      "epoch:19 step:18250 [D loss: 0.487386, acc.: 75.78%] [G loss: 0.684618]\n",
      "epoch:19 step:18251 [D loss: 0.504249, acc.: 69.53%] [G loss: 0.830061]\n",
      "epoch:19 step:18252 [D loss: 0.489529, acc.: 73.44%] [G loss: 0.736722]\n",
      "epoch:19 step:18253 [D loss: 0.528476, acc.: 70.31%] [G loss: 0.818706]\n",
      "epoch:19 step:18254 [D loss: 0.397955, acc.: 82.03%] [G loss: 0.909937]\n",
      "epoch:19 step:18255 [D loss: 0.500550, acc.: 71.09%] [G loss: 0.866857]\n",
      "epoch:19 step:18256 [D loss: 0.521902, acc.: 75.78%] [G loss: 0.740114]\n",
      "epoch:19 step:18257 [D loss: 0.602446, acc.: 66.41%] [G loss: 0.641981]\n",
      "epoch:19 step:18258 [D loss: 0.565345, acc.: 69.53%] [G loss: 0.662516]\n",
      "epoch:19 step:18259 [D loss: 0.600353, acc.: 64.06%] [G loss: 0.613960]\n",
      "epoch:19 step:18260 [D loss: 0.496210, acc.: 77.34%] [G loss: 0.636214]\n",
      "epoch:19 step:18261 [D loss: 0.569767, acc.: 69.53%] [G loss: 0.510863]\n",
      "epoch:19 step:18262 [D loss: 0.505592, acc.: 74.22%] [G loss: 0.455787]\n",
      "epoch:19 step:18263 [D loss: 0.557630, acc.: 64.84%] [G loss: 0.570693]\n",
      "epoch:19 step:18264 [D loss: 0.511317, acc.: 73.44%] [G loss: 0.710575]\n",
      "epoch:19 step:18265 [D loss: 0.537205, acc.: 72.66%] [G loss: 0.593538]\n",
      "epoch:19 step:18266 [D loss: 0.569927, acc.: 62.50%] [G loss: 0.651383]\n",
      "epoch:19 step:18267 [D loss: 0.535109, acc.: 71.09%] [G loss: 0.580823]\n",
      "epoch:19 step:18268 [D loss: 0.587685, acc.: 67.19%] [G loss: 0.665019]\n",
      "epoch:19 step:18269 [D loss: 0.514048, acc.: 72.66%] [G loss: 0.582870]\n",
      "epoch:19 step:18270 [D loss: 0.566351, acc.: 65.62%] [G loss: 0.556726]\n",
      "epoch:19 step:18271 [D loss: 0.543107, acc.: 71.88%] [G loss: 0.643890]\n",
      "epoch:19 step:18272 [D loss: 0.528019, acc.: 70.31%] [G loss: 0.633686]\n",
      "epoch:19 step:18273 [D loss: 0.500720, acc.: 78.91%] [G loss: 0.574006]\n",
      "epoch:19 step:18274 [D loss: 0.518583, acc.: 71.88%] [G loss: 0.682446]\n",
      "epoch:19 step:18275 [D loss: 0.466545, acc.: 80.47%] [G loss: 0.802433]\n",
      "epoch:19 step:18276 [D loss: 0.692475, acc.: 64.06%] [G loss: 0.605571]\n",
      "epoch:19 step:18277 [D loss: 0.587943, acc.: 66.41%] [G loss: 0.621919]\n",
      "epoch:19 step:18278 [D loss: 0.447169, acc.: 80.47%] [G loss: 0.735859]\n",
      "epoch:19 step:18279 [D loss: 0.541054, acc.: 77.34%] [G loss: 0.757114]\n",
      "epoch:19 step:18280 [D loss: 0.600760, acc.: 63.28%] [G loss: 0.489413]\n",
      "epoch:19 step:18281 [D loss: 0.548113, acc.: 67.97%] [G loss: 0.488285]\n",
      "epoch:19 step:18282 [D loss: 0.508574, acc.: 77.34%] [G loss: 0.575671]\n",
      "epoch:19 step:18283 [D loss: 0.600683, acc.: 66.41%] [G loss: 0.744002]\n",
      "epoch:19 step:18284 [D loss: 0.510727, acc.: 79.69%] [G loss: 0.588432]\n",
      "epoch:19 step:18285 [D loss: 0.575070, acc.: 66.41%] [G loss: 0.676246]\n",
      "epoch:19 step:18286 [D loss: 0.515319, acc.: 72.66%] [G loss: 0.653450]\n",
      "epoch:19 step:18287 [D loss: 0.472581, acc.: 75.78%] [G loss: 0.662698]\n",
      "epoch:19 step:18288 [D loss: 0.524626, acc.: 77.34%] [G loss: 0.763204]\n",
      "epoch:19 step:18289 [D loss: 0.524071, acc.: 69.53%] [G loss: 0.700934]\n",
      "epoch:19 step:18290 [D loss: 0.558854, acc.: 64.84%] [G loss: 0.686219]\n",
      "epoch:19 step:18291 [D loss: 0.560374, acc.: 69.53%] [G loss: 0.552565]\n",
      "epoch:19 step:18292 [D loss: 0.501715, acc.: 73.44%] [G loss: 0.632888]\n",
      "epoch:19 step:18293 [D loss: 0.566084, acc.: 64.84%] [G loss: 0.623383]\n",
      "epoch:19 step:18294 [D loss: 0.531007, acc.: 72.66%] [G loss: 0.657275]\n",
      "epoch:19 step:18295 [D loss: 0.573291, acc.: 67.19%] [G loss: 0.626337]\n",
      "epoch:19 step:18296 [D loss: 0.524048, acc.: 71.09%] [G loss: 0.604521]\n",
      "epoch:19 step:18297 [D loss: 0.554220, acc.: 70.31%] [G loss: 0.630248]\n",
      "epoch:19 step:18298 [D loss: 0.493118, acc.: 72.66%] [G loss: 0.673618]\n",
      "epoch:19 step:18299 [D loss: 0.536484, acc.: 73.44%] [G loss: 0.674085]\n",
      "epoch:19 step:18300 [D loss: 0.573748, acc.: 67.19%] [G loss: 0.726816]\n",
      "epoch:19 step:18301 [D loss: 0.531235, acc.: 70.31%] [G loss: 0.660344]\n",
      "epoch:19 step:18302 [D loss: 0.466707, acc.: 78.91%] [G loss: 0.725076]\n",
      "epoch:19 step:18303 [D loss: 0.614778, acc.: 66.41%] [G loss: 0.798236]\n",
      "epoch:19 step:18304 [D loss: 0.610985, acc.: 66.41%] [G loss: 0.680086]\n",
      "epoch:19 step:18305 [D loss: 0.593980, acc.: 65.62%] [G loss: 0.656566]\n",
      "epoch:19 step:18306 [D loss: 0.478214, acc.: 75.78%] [G loss: 0.697929]\n",
      "epoch:19 step:18307 [D loss: 0.494371, acc.: 75.78%] [G loss: 0.782949]\n",
      "epoch:19 step:18308 [D loss: 0.510684, acc.: 72.66%] [G loss: 0.738826]\n",
      "epoch:19 step:18309 [D loss: 0.519126, acc.: 71.88%] [G loss: 0.764228]\n",
      "epoch:19 step:18310 [D loss: 0.516911, acc.: 74.22%] [G loss: 0.921210]\n",
      "epoch:19 step:18311 [D loss: 0.420186, acc.: 82.03%] [G loss: 1.017565]\n",
      "epoch:19 step:18312 [D loss: 0.495425, acc.: 75.78%] [G loss: 0.821273]\n",
      "epoch:19 step:18313 [D loss: 0.664709, acc.: 64.06%] [G loss: 0.662278]\n",
      "epoch:19 step:18314 [D loss: 0.670365, acc.: 58.59%] [G loss: 0.511682]\n",
      "epoch:19 step:18315 [D loss: 0.589346, acc.: 69.53%] [G loss: 0.528873]\n",
      "epoch:19 step:18316 [D loss: 0.510836, acc.: 75.78%] [G loss: 0.576807]\n",
      "epoch:19 step:18317 [D loss: 0.489821, acc.: 72.66%] [G loss: 0.571198]\n",
      "epoch:19 step:18318 [D loss: 0.528838, acc.: 76.56%] [G loss: 0.693564]\n",
      "epoch:19 step:18319 [D loss: 0.456798, acc.: 80.47%] [G loss: 0.923143]\n",
      "epoch:19 step:18320 [D loss: 0.514790, acc.: 75.78%] [G loss: 0.716508]\n",
      "epoch:19 step:18321 [D loss: 0.541419, acc.: 66.41%] [G loss: 0.663532]\n",
      "epoch:19 step:18322 [D loss: 0.501651, acc.: 74.22%] [G loss: 0.708614]\n",
      "epoch:19 step:18323 [D loss: 0.477342, acc.: 76.56%] [G loss: 0.855627]\n",
      "epoch:19 step:18324 [D loss: 0.513279, acc.: 78.12%] [G loss: 0.840209]\n",
      "epoch:19 step:18325 [D loss: 0.465462, acc.: 78.91%] [G loss: 0.829181]\n",
      "epoch:19 step:18326 [D loss: 0.472926, acc.: 75.78%] [G loss: 0.790396]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18327 [D loss: 0.583478, acc.: 67.19%] [G loss: 0.763532]\n",
      "epoch:19 step:18328 [D loss: 0.581785, acc.: 65.62%] [G loss: 0.552761]\n",
      "epoch:19 step:18329 [D loss: 0.542339, acc.: 71.88%] [G loss: 0.568192]\n",
      "epoch:19 step:18330 [D loss: 0.542035, acc.: 71.88%] [G loss: 0.812304]\n",
      "epoch:19 step:18331 [D loss: 0.702290, acc.: 56.25%] [G loss: 0.571032]\n",
      "epoch:19 step:18332 [D loss: 0.611887, acc.: 57.03%] [G loss: 0.549642]\n",
      "epoch:19 step:18333 [D loss: 0.536620, acc.: 71.09%] [G loss: 0.695484]\n",
      "epoch:19 step:18334 [D loss: 0.523301, acc.: 68.75%] [G loss: 0.656399]\n",
      "epoch:19 step:18335 [D loss: 0.611014, acc.: 63.28%] [G loss: 0.584101]\n",
      "epoch:19 step:18336 [D loss: 0.558298, acc.: 70.31%] [G loss: 0.763208]\n",
      "epoch:19 step:18337 [D loss: 0.476842, acc.: 75.00%] [G loss: 0.643855]\n",
      "epoch:19 step:18338 [D loss: 0.615150, acc.: 62.50%] [G loss: 0.505784]\n",
      "epoch:19 step:18339 [D loss: 0.523414, acc.: 74.22%] [G loss: 0.450383]\n",
      "epoch:19 step:18340 [D loss: 0.588719, acc.: 65.62%] [G loss: 0.619687]\n",
      "epoch:19 step:18341 [D loss: 0.528331, acc.: 75.00%] [G loss: 0.620869]\n",
      "epoch:19 step:18342 [D loss: 0.529396, acc.: 70.31%] [G loss: 0.685272]\n",
      "epoch:19 step:18343 [D loss: 0.563443, acc.: 69.53%] [G loss: 0.571889]\n",
      "epoch:19 step:18344 [D loss: 0.544291, acc.: 65.62%] [G loss: 0.592438]\n",
      "epoch:19 step:18345 [D loss: 0.623518, acc.: 65.62%] [G loss: 0.492748]\n",
      "epoch:19 step:18346 [D loss: 0.584023, acc.: 67.19%] [G loss: 0.619343]\n",
      "epoch:19 step:18347 [D loss: 0.636809, acc.: 64.06%] [G loss: 0.694466]\n",
      "epoch:19 step:18348 [D loss: 0.524234, acc.: 71.09%] [G loss: 0.684920]\n",
      "epoch:19 step:18349 [D loss: 0.541129, acc.: 76.56%] [G loss: 0.751861]\n",
      "epoch:19 step:18350 [D loss: 0.550177, acc.: 73.44%] [G loss: 0.678410]\n",
      "epoch:19 step:18351 [D loss: 0.487598, acc.: 74.22%] [G loss: 0.791073]\n",
      "epoch:19 step:18352 [D loss: 0.533114, acc.: 70.31%] [G loss: 0.738071]\n",
      "epoch:19 step:18353 [D loss: 0.558288, acc.: 66.41%] [G loss: 0.684775]\n",
      "epoch:19 step:18354 [D loss: 0.500104, acc.: 73.44%] [G loss: 0.667305]\n",
      "epoch:19 step:18355 [D loss: 0.526134, acc.: 71.88%] [G loss: 0.659860]\n",
      "epoch:19 step:18356 [D loss: 0.559308, acc.: 69.53%] [G loss: 0.694467]\n",
      "epoch:19 step:18357 [D loss: 0.470468, acc.: 78.12%] [G loss: 0.754398]\n",
      "epoch:19 step:18358 [D loss: 0.437552, acc.: 82.81%] [G loss: 0.713262]\n",
      "epoch:19 step:18359 [D loss: 0.606874, acc.: 64.84%] [G loss: 0.608596]\n",
      "epoch:19 step:18360 [D loss: 0.546778, acc.: 67.19%] [G loss: 0.626556]\n",
      "epoch:19 step:18361 [D loss: 0.523071, acc.: 69.53%] [G loss: 0.715331]\n",
      "epoch:19 step:18362 [D loss: 0.549627, acc.: 68.75%] [G loss: 0.640718]\n",
      "epoch:19 step:18363 [D loss: 0.594369, acc.: 66.41%] [G loss: 0.502778]\n",
      "epoch:19 step:18364 [D loss: 0.521491, acc.: 76.56%] [G loss: 0.634976]\n",
      "epoch:19 step:18365 [D loss: 0.597891, acc.: 66.41%] [G loss: 0.585338]\n",
      "epoch:19 step:18366 [D loss: 0.538992, acc.: 71.09%] [G loss: 0.620246]\n",
      "epoch:19 step:18367 [D loss: 0.486041, acc.: 80.47%] [G loss: 0.733059]\n",
      "epoch:19 step:18368 [D loss: 0.512923, acc.: 71.88%] [G loss: 0.622479]\n",
      "epoch:19 step:18369 [D loss: 0.714208, acc.: 59.38%] [G loss: 0.523871]\n",
      "epoch:19 step:18370 [D loss: 0.492759, acc.: 71.09%] [G loss: 0.658863]\n",
      "epoch:19 step:18371 [D loss: 0.458070, acc.: 79.69%] [G loss: 0.734942]\n",
      "epoch:19 step:18372 [D loss: 0.538189, acc.: 69.53%] [G loss: 0.657517]\n",
      "epoch:19 step:18373 [D loss: 0.500117, acc.: 71.88%] [G loss: 0.588730]\n",
      "epoch:19 step:18374 [D loss: 0.569740, acc.: 65.62%] [G loss: 0.545887]\n",
      "epoch:19 step:18375 [D loss: 0.609096, acc.: 67.97%] [G loss: 0.713717]\n",
      "epoch:19 step:18376 [D loss: 0.567923, acc.: 69.53%] [G loss: 0.672292]\n",
      "epoch:19 step:18377 [D loss: 0.495703, acc.: 71.88%] [G loss: 0.848573]\n",
      "epoch:19 step:18378 [D loss: 0.491747, acc.: 75.78%] [G loss: 0.802280]\n",
      "epoch:19 step:18379 [D loss: 0.644933, acc.: 62.50%] [G loss: 0.617568]\n",
      "epoch:19 step:18380 [D loss: 0.503151, acc.: 75.00%] [G loss: 0.818477]\n",
      "epoch:19 step:18381 [D loss: 0.530957, acc.: 71.09%] [G loss: 0.760938]\n",
      "epoch:19 step:18382 [D loss: 0.579648, acc.: 67.97%] [G loss: 0.682078]\n",
      "epoch:19 step:18383 [D loss: 0.578593, acc.: 68.75%] [G loss: 0.546683]\n",
      "epoch:19 step:18384 [D loss: 0.539591, acc.: 73.44%] [G loss: 0.623471]\n",
      "epoch:19 step:18385 [D loss: 0.507783, acc.: 75.78%] [G loss: 0.544285]\n",
      "epoch:19 step:18386 [D loss: 0.545904, acc.: 71.09%] [G loss: 0.627250]\n",
      "epoch:19 step:18387 [D loss: 0.627000, acc.: 64.06%] [G loss: 0.659467]\n",
      "epoch:19 step:18388 [D loss: 0.476123, acc.: 77.34%] [G loss: 0.694163]\n",
      "epoch:19 step:18389 [D loss: 0.555932, acc.: 72.66%] [G loss: 0.573949]\n",
      "epoch:19 step:18390 [D loss: 0.599322, acc.: 70.31%] [G loss: 0.466301]\n",
      "epoch:19 step:18391 [D loss: 0.594677, acc.: 64.84%] [G loss: 0.608638]\n",
      "epoch:19 step:18392 [D loss: 0.462459, acc.: 78.12%] [G loss: 0.754951]\n",
      "epoch:19 step:18393 [D loss: 0.546910, acc.: 67.97%] [G loss: 0.714149]\n",
      "epoch:19 step:18394 [D loss: 0.558807, acc.: 71.09%] [G loss: 0.665450]\n",
      "epoch:19 step:18395 [D loss: 0.479753, acc.: 79.69%] [G loss: 0.549565]\n",
      "epoch:19 step:18396 [D loss: 0.473559, acc.: 74.22%] [G loss: 0.747873]\n",
      "epoch:19 step:18397 [D loss: 0.547231, acc.: 69.53%] [G loss: 0.690692]\n",
      "epoch:19 step:18398 [D loss: 0.521351, acc.: 78.91%] [G loss: 0.725525]\n",
      "epoch:19 step:18399 [D loss: 0.505559, acc.: 76.56%] [G loss: 0.623313]\n",
      "epoch:19 step:18400 [D loss: 0.500816, acc.: 73.44%] [G loss: 0.699147]\n",
      "##############\n",
      "[3.0358032  0.91313714 5.77924563 5.02989134 3.74357813 5.76488047\n",
      " 4.58265119 4.82008398 4.7319581  4.12607469]\n",
      "##########\n",
      "epoch:19 step:18401 [D loss: 0.505790, acc.: 72.66%] [G loss: 0.663636]\n",
      "epoch:19 step:18402 [D loss: 0.535630, acc.: 72.66%] [G loss: 0.522432]\n",
      "epoch:19 step:18403 [D loss: 0.575371, acc.: 67.97%] [G loss: 0.562506]\n",
      "epoch:19 step:18404 [D loss: 0.452880, acc.: 77.34%] [G loss: 0.626861]\n",
      "epoch:19 step:18405 [D loss: 0.476111, acc.: 74.22%] [G loss: 0.710877]\n",
      "epoch:19 step:18406 [D loss: 0.548442, acc.: 69.53%] [G loss: 0.720972]\n",
      "epoch:19 step:18407 [D loss: 0.588972, acc.: 68.75%] [G loss: 0.738887]\n",
      "epoch:19 step:18408 [D loss: 0.433424, acc.: 79.69%] [G loss: 1.065018]\n",
      "epoch:19 step:18409 [D loss: 0.569194, acc.: 66.41%] [G loss: 0.760729]\n",
      "epoch:19 step:18410 [D loss: 0.548863, acc.: 70.31%] [G loss: 0.671862]\n",
      "epoch:19 step:18411 [D loss: 0.550301, acc.: 70.31%] [G loss: 0.672494]\n",
      "epoch:19 step:18412 [D loss: 0.503467, acc.: 67.97%] [G loss: 0.562791]\n",
      "epoch:19 step:18413 [D loss: 0.547487, acc.: 70.31%] [G loss: 0.549642]\n",
      "epoch:19 step:18414 [D loss: 0.497176, acc.: 77.34%] [G loss: 0.620924]\n",
      "epoch:19 step:18415 [D loss: 0.529286, acc.: 71.88%] [G loss: 0.641403]\n",
      "epoch:19 step:18416 [D loss: 0.492201, acc.: 68.75%] [G loss: 0.688425]\n",
      "epoch:19 step:18417 [D loss: 0.535838, acc.: 69.53%] [G loss: 0.755314]\n",
      "epoch:19 step:18418 [D loss: 0.552835, acc.: 71.09%] [G loss: 0.605463]\n",
      "epoch:19 step:18419 [D loss: 0.584349, acc.: 69.53%] [G loss: 0.587901]\n",
      "epoch:19 step:18420 [D loss: 0.568605, acc.: 67.97%] [G loss: 0.702766]\n",
      "epoch:19 step:18421 [D loss: 0.569729, acc.: 68.75%] [G loss: 0.691592]\n",
      "epoch:19 step:18422 [D loss: 0.598923, acc.: 64.06%] [G loss: 0.743481]\n",
      "epoch:19 step:18423 [D loss: 0.552184, acc.: 67.19%] [G loss: 0.773012]\n",
      "epoch:19 step:18424 [D loss: 0.534538, acc.: 75.00%] [G loss: 0.679622]\n",
      "epoch:19 step:18425 [D loss: 0.512365, acc.: 73.44%] [G loss: 0.757515]\n",
      "epoch:19 step:18426 [D loss: 0.471201, acc.: 77.34%] [G loss: 0.747438]\n",
      "epoch:19 step:18427 [D loss: 0.462343, acc.: 78.12%] [G loss: 0.764407]\n",
      "epoch:19 step:18428 [D loss: 0.622331, acc.: 67.97%] [G loss: 0.652801]\n",
      "epoch:19 step:18429 [D loss: 0.510431, acc.: 73.44%] [G loss: 0.543058]\n",
      "epoch:19 step:18430 [D loss: 0.543944, acc.: 65.62%] [G loss: 0.500277]\n",
      "epoch:19 step:18431 [D loss: 0.586411, acc.: 65.62%] [G loss: 0.626703]\n",
      "epoch:19 step:18432 [D loss: 0.510647, acc.: 72.66%] [G loss: 0.679728]\n",
      "epoch:19 step:18433 [D loss: 0.529302, acc.: 73.44%] [G loss: 0.500048]\n",
      "epoch:19 step:18434 [D loss: 0.520266, acc.: 75.00%] [G loss: 0.595364]\n",
      "epoch:19 step:18435 [D loss: 0.523642, acc.: 71.09%] [G loss: 0.778980]\n",
      "epoch:19 step:18436 [D loss: 0.539145, acc.: 72.66%] [G loss: 0.725761]\n",
      "epoch:19 step:18437 [D loss: 0.466258, acc.: 79.69%] [G loss: 0.757971]\n",
      "epoch:19 step:18438 [D loss: 0.474914, acc.: 76.56%] [G loss: 0.703179]\n",
      "epoch:19 step:18439 [D loss: 0.597957, acc.: 65.62%] [G loss: 0.538759]\n",
      "epoch:19 step:18440 [D loss: 0.538662, acc.: 69.53%] [G loss: 0.566441]\n",
      "epoch:19 step:18441 [D loss: 0.506065, acc.: 75.78%] [G loss: 0.564138]\n",
      "epoch:19 step:18442 [D loss: 0.515597, acc.: 72.66%] [G loss: 0.652789]\n",
      "epoch:19 step:18443 [D loss: 0.593564, acc.: 68.75%] [G loss: 0.678135]\n",
      "epoch:19 step:18444 [D loss: 0.501187, acc.: 69.53%] [G loss: 1.012835]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18445 [D loss: 0.473667, acc.: 78.12%] [G loss: 1.122711]\n",
      "epoch:19 step:18446 [D loss: 0.513294, acc.: 70.31%] [G loss: 0.690421]\n",
      "epoch:19 step:18447 [D loss: 0.575763, acc.: 65.62%] [G loss: 0.674314]\n",
      "epoch:19 step:18448 [D loss: 0.541300, acc.: 72.66%] [G loss: 0.730129]\n",
      "epoch:19 step:18449 [D loss: 0.563792, acc.: 71.09%] [G loss: 0.669216]\n",
      "epoch:19 step:18450 [D loss: 0.387991, acc.: 82.03%] [G loss: 0.915561]\n",
      "epoch:19 step:18451 [D loss: 0.414024, acc.: 80.47%] [G loss: 1.097575]\n",
      "epoch:19 step:18452 [D loss: 0.456405, acc.: 76.56%] [G loss: 0.923168]\n",
      "epoch:19 step:18453 [D loss: 0.493365, acc.: 76.56%] [G loss: 0.960925]\n",
      "epoch:19 step:18454 [D loss: 0.487324, acc.: 74.22%] [G loss: 0.898253]\n",
      "epoch:19 step:18455 [D loss: 0.622049, acc.: 67.19%] [G loss: 0.759813]\n",
      "epoch:19 step:18456 [D loss: 0.589997, acc.: 70.31%] [G loss: 0.634419]\n",
      "epoch:19 step:18457 [D loss: 0.489874, acc.: 73.44%] [G loss: 0.642360]\n",
      "epoch:19 step:18458 [D loss: 0.552109, acc.: 70.31%] [G loss: 0.573187]\n",
      "epoch:19 step:18459 [D loss: 0.589691, acc.: 66.41%] [G loss: 0.510791]\n",
      "epoch:19 step:18460 [D loss: 0.531054, acc.: 67.97%] [G loss: 0.601897]\n",
      "epoch:19 step:18461 [D loss: 0.607265, acc.: 65.62%] [G loss: 0.603523]\n",
      "epoch:19 step:18462 [D loss: 0.552016, acc.: 67.97%] [G loss: 0.629592]\n",
      "epoch:19 step:18463 [D loss: 0.517120, acc.: 70.31%] [G loss: 0.829939]\n",
      "epoch:19 step:18464 [D loss: 0.467644, acc.: 75.78%] [G loss: 0.960710]\n",
      "epoch:19 step:18465 [D loss: 0.522875, acc.: 73.44%] [G loss: 0.669650]\n",
      "epoch:19 step:18466 [D loss: 0.542228, acc.: 72.66%] [G loss: 0.681213]\n",
      "epoch:19 step:18467 [D loss: 0.529459, acc.: 68.75%] [G loss: 0.631593]\n",
      "epoch:19 step:18468 [D loss: 0.566325, acc.: 68.75%] [G loss: 0.696860]\n",
      "epoch:19 step:18469 [D loss: 0.557791, acc.: 67.19%] [G loss: 0.828908]\n",
      "epoch:19 step:18470 [D loss: 0.588274, acc.: 69.53%] [G loss: 0.700358]\n",
      "epoch:19 step:18471 [D loss: 0.565583, acc.: 72.66%] [G loss: 0.644304]\n",
      "epoch:19 step:18472 [D loss: 0.515487, acc.: 74.22%] [G loss: 0.743549]\n",
      "epoch:19 step:18473 [D loss: 0.537863, acc.: 66.41%] [G loss: 0.703672]\n",
      "epoch:19 step:18474 [D loss: 0.556893, acc.: 73.44%] [G loss: 0.535886]\n",
      "epoch:19 step:18475 [D loss: 0.570314, acc.: 66.41%] [G loss: 0.660107]\n",
      "epoch:19 step:18476 [D loss: 0.553807, acc.: 73.44%] [G loss: 0.680152]\n",
      "epoch:19 step:18477 [D loss: 0.550398, acc.: 69.53%] [G loss: 0.652112]\n",
      "epoch:19 step:18478 [D loss: 0.612159, acc.: 63.28%] [G loss: 0.677601]\n",
      "epoch:19 step:18479 [D loss: 0.560378, acc.: 68.75%] [G loss: 0.592862]\n",
      "epoch:19 step:18480 [D loss: 0.500513, acc.: 70.31%] [G loss: 0.689653]\n",
      "epoch:19 step:18481 [D loss: 0.615286, acc.: 63.28%] [G loss: 0.655524]\n",
      "epoch:19 step:18482 [D loss: 0.521106, acc.: 77.34%] [G loss: 0.531395]\n",
      "epoch:19 step:18483 [D loss: 0.548474, acc.: 74.22%] [G loss: 0.638460]\n",
      "epoch:19 step:18484 [D loss: 0.508486, acc.: 73.44%] [G loss: 0.717032]\n",
      "epoch:19 step:18485 [D loss: 0.525448, acc.: 71.09%] [G loss: 0.722403]\n",
      "epoch:19 step:18486 [D loss: 0.530386, acc.: 72.66%] [G loss: 0.611048]\n",
      "epoch:19 step:18487 [D loss: 0.605876, acc.: 64.84%] [G loss: 0.510145]\n",
      "epoch:19 step:18488 [D loss: 0.509237, acc.: 75.78%] [G loss: 0.571555]\n",
      "epoch:19 step:18489 [D loss: 0.585093, acc.: 66.41%] [G loss: 0.578710]\n",
      "epoch:19 step:18490 [D loss: 0.543912, acc.: 69.53%] [G loss: 0.497852]\n",
      "epoch:19 step:18491 [D loss: 0.519427, acc.: 74.22%] [G loss: 0.549356]\n",
      "epoch:19 step:18492 [D loss: 0.519824, acc.: 71.88%] [G loss: 0.653135]\n",
      "epoch:19 step:18493 [D loss: 0.487541, acc.: 75.00%] [G loss: 0.745664]\n",
      "epoch:19 step:18494 [D loss: 0.455100, acc.: 80.47%] [G loss: 0.773567]\n",
      "epoch:19 step:18495 [D loss: 0.532068, acc.: 73.44%] [G loss: 0.770072]\n",
      "epoch:19 step:18496 [D loss: 0.497856, acc.: 78.12%] [G loss: 0.731860]\n",
      "epoch:19 step:18497 [D loss: 0.469295, acc.: 76.56%] [G loss: 0.828384]\n",
      "epoch:19 step:18498 [D loss: 0.506130, acc.: 74.22%] [G loss: 0.822438]\n",
      "epoch:19 step:18499 [D loss: 0.607210, acc.: 62.50%] [G loss: 0.711448]\n",
      "epoch:19 step:18500 [D loss: 0.555441, acc.: 67.97%] [G loss: 0.543861]\n",
      "epoch:19 step:18501 [D loss: 0.567500, acc.: 67.97%] [G loss: 0.654974]\n",
      "epoch:19 step:18502 [D loss: 0.517475, acc.: 73.44%] [G loss: 0.552129]\n",
      "epoch:19 step:18503 [D loss: 0.513163, acc.: 73.44%] [G loss: 0.766621]\n",
      "epoch:19 step:18504 [D loss: 0.484348, acc.: 74.22%] [G loss: 0.874550]\n",
      "epoch:19 step:18505 [D loss: 0.625953, acc.: 65.62%] [G loss: 0.679743]\n",
      "epoch:19 step:18506 [D loss: 0.580089, acc.: 70.31%] [G loss: 0.534926]\n",
      "epoch:19 step:18507 [D loss: 0.577823, acc.: 65.62%] [G loss: 0.598572]\n",
      "epoch:19 step:18508 [D loss: 0.535458, acc.: 70.31%] [G loss: 0.532162]\n",
      "epoch:19 step:18509 [D loss: 0.529362, acc.: 72.66%] [G loss: 0.549899]\n",
      "epoch:19 step:18510 [D loss: 0.544605, acc.: 67.97%] [G loss: 0.687177]\n",
      "epoch:19 step:18511 [D loss: 0.458649, acc.: 77.34%] [G loss: 0.804029]\n",
      "epoch:19 step:18512 [D loss: 0.498093, acc.: 76.56%] [G loss: 0.946996]\n",
      "epoch:19 step:18513 [D loss: 0.590247, acc.: 69.53%] [G loss: 0.576878]\n",
      "epoch:19 step:18514 [D loss: 0.619969, acc.: 64.84%] [G loss: 0.603852]\n",
      "epoch:19 step:18515 [D loss: 0.535658, acc.: 69.53%] [G loss: 0.591835]\n",
      "epoch:19 step:18516 [D loss: 0.617225, acc.: 66.41%] [G loss: 0.657146]\n",
      "epoch:19 step:18517 [D loss: 0.526891, acc.: 70.31%] [G loss: 0.825338]\n",
      "epoch:19 step:18518 [D loss: 0.555983, acc.: 67.19%] [G loss: 0.637798]\n",
      "epoch:19 step:18519 [D loss: 0.624354, acc.: 64.06%] [G loss: 0.629389]\n",
      "epoch:19 step:18520 [D loss: 0.595593, acc.: 63.28%] [G loss: 0.492554]\n",
      "epoch:19 step:18521 [D loss: 0.551095, acc.: 66.41%] [G loss: 0.570840]\n",
      "epoch:19 step:18522 [D loss: 0.514318, acc.: 70.31%] [G loss: 0.649759]\n",
      "epoch:19 step:18523 [D loss: 0.577577, acc.: 70.31%] [G loss: 0.585254]\n",
      "epoch:19 step:18524 [D loss: 0.589215, acc.: 66.41%] [G loss: 0.621506]\n",
      "epoch:19 step:18525 [D loss: 0.583517, acc.: 67.19%] [G loss: 0.595815]\n",
      "epoch:19 step:18526 [D loss: 0.540489, acc.: 71.88%] [G loss: 0.699847]\n",
      "epoch:19 step:18527 [D loss: 0.520468, acc.: 76.56%] [G loss: 0.586701]\n",
      "epoch:19 step:18528 [D loss: 0.537881, acc.: 71.09%] [G loss: 0.654240]\n",
      "epoch:19 step:18529 [D loss: 0.456519, acc.: 77.34%] [G loss: 0.875055]\n",
      "epoch:19 step:18530 [D loss: 0.549763, acc.: 68.75%] [G loss: 0.601359]\n",
      "epoch:19 step:18531 [D loss: 0.510083, acc.: 72.66%] [G loss: 0.698527]\n",
      "epoch:19 step:18532 [D loss: 0.540952, acc.: 72.66%] [G loss: 0.640172]\n",
      "epoch:19 step:18533 [D loss: 0.550138, acc.: 75.78%] [G loss: 0.476609]\n",
      "epoch:19 step:18534 [D loss: 0.593795, acc.: 65.62%] [G loss: 0.633570]\n",
      "epoch:19 step:18535 [D loss: 0.472666, acc.: 78.12%] [G loss: 0.733339]\n",
      "epoch:19 step:18536 [D loss: 0.519824, acc.: 73.44%] [G loss: 0.725761]\n",
      "epoch:19 step:18537 [D loss: 0.525026, acc.: 74.22%] [G loss: 0.611600]\n",
      "epoch:19 step:18538 [D loss: 0.511594, acc.: 72.66%] [G loss: 0.615644]\n",
      "epoch:19 step:18539 [D loss: 0.540187, acc.: 71.88%] [G loss: 0.586881]\n",
      "epoch:19 step:18540 [D loss: 0.503605, acc.: 74.22%] [G loss: 0.698418]\n",
      "epoch:19 step:18541 [D loss: 0.580141, acc.: 68.75%] [G loss: 0.573239]\n",
      "epoch:19 step:18542 [D loss: 0.587095, acc.: 68.75%] [G loss: 0.652235]\n",
      "epoch:19 step:18543 [D loss: 0.650356, acc.: 60.16%] [G loss: 0.514862]\n",
      "epoch:19 step:18544 [D loss: 0.596166, acc.: 65.62%] [G loss: 0.508526]\n",
      "epoch:19 step:18545 [D loss: 0.492834, acc.: 73.44%] [G loss: 0.667597]\n",
      "epoch:19 step:18546 [D loss: 0.484841, acc.: 71.09%] [G loss: 0.886459]\n",
      "epoch:19 step:18547 [D loss: 0.505741, acc.: 73.44%] [G loss: 0.677141]\n",
      "epoch:19 step:18548 [D loss: 0.598507, acc.: 63.28%] [G loss: 0.656525]\n",
      "epoch:19 step:18549 [D loss: 0.435931, acc.: 84.38%] [G loss: 0.570265]\n",
      "epoch:19 step:18550 [D loss: 0.448210, acc.: 78.12%] [G loss: 0.894658]\n",
      "epoch:19 step:18551 [D loss: 0.538018, acc.: 70.31%] [G loss: 0.736642]\n",
      "epoch:19 step:18552 [D loss: 0.488642, acc.: 75.00%] [G loss: 0.765522]\n",
      "epoch:19 step:18553 [D loss: 0.475185, acc.: 78.12%] [G loss: 0.671175]\n",
      "epoch:19 step:18554 [D loss: 0.522512, acc.: 67.97%] [G loss: 0.642327]\n",
      "epoch:19 step:18555 [D loss: 0.548598, acc.: 68.75%] [G loss: 0.698238]\n",
      "epoch:19 step:18556 [D loss: 0.466006, acc.: 78.12%] [G loss: 0.915611]\n",
      "epoch:19 step:18557 [D loss: 0.540293, acc.: 75.78%] [G loss: 0.715128]\n",
      "epoch:19 step:18558 [D loss: 0.549723, acc.: 65.62%] [G loss: 0.601468]\n",
      "epoch:19 step:18559 [D loss: 0.545882, acc.: 70.31%] [G loss: 0.706787]\n",
      "epoch:19 step:18560 [D loss: 0.567963, acc.: 67.97%] [G loss: 0.740671]\n",
      "epoch:19 step:18561 [D loss: 0.560052, acc.: 67.97%] [G loss: 0.655533]\n",
      "epoch:19 step:18562 [D loss: 0.543229, acc.: 71.09%] [G loss: 0.666042]\n",
      "epoch:19 step:18563 [D loss: 0.537197, acc.: 71.88%] [G loss: 0.523532]\n",
      "epoch:19 step:18564 [D loss: 0.540903, acc.: 68.75%] [G loss: 0.543723]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18565 [D loss: 0.581582, acc.: 65.62%] [G loss: 0.716937]\n",
      "epoch:19 step:18566 [D loss: 0.544906, acc.: 65.62%] [G loss: 0.621045]\n",
      "epoch:19 step:18567 [D loss: 0.578073, acc.: 66.41%] [G loss: 0.703900]\n",
      "epoch:19 step:18568 [D loss: 0.603850, acc.: 65.62%] [G loss: 0.600693]\n",
      "epoch:19 step:18569 [D loss: 0.618814, acc.: 64.06%] [G loss: 0.529583]\n",
      "epoch:19 step:18570 [D loss: 0.572747, acc.: 71.09%] [G loss: 0.539873]\n",
      "epoch:19 step:18571 [D loss: 0.607286, acc.: 66.41%] [G loss: 0.637161]\n",
      "epoch:19 step:18572 [D loss: 0.504868, acc.: 76.56%] [G loss: 0.825187]\n",
      "epoch:19 step:18573 [D loss: 0.510617, acc.: 73.44%] [G loss: 0.735881]\n",
      "epoch:19 step:18574 [D loss: 0.497711, acc.: 78.12%] [G loss: 0.679641]\n",
      "epoch:19 step:18575 [D loss: 0.536047, acc.: 71.09%] [G loss: 0.568376]\n",
      "epoch:19 step:18576 [D loss: 0.558148, acc.: 67.19%] [G loss: 0.632090]\n",
      "epoch:19 step:18577 [D loss: 0.525369, acc.: 74.22%] [G loss: 0.752297]\n",
      "epoch:19 step:18578 [D loss: 0.491966, acc.: 74.22%] [G loss: 0.801744]\n",
      "epoch:19 step:18579 [D loss: 0.587713, acc.: 63.28%] [G loss: 0.581281]\n",
      "epoch:19 step:18580 [D loss: 0.668547, acc.: 63.28%] [G loss: 0.691103]\n",
      "epoch:19 step:18581 [D loss: 0.574854, acc.: 67.19%] [G loss: 0.547682]\n",
      "epoch:19 step:18582 [D loss: 0.576930, acc.: 65.62%] [G loss: 0.699394]\n",
      "epoch:19 step:18583 [D loss: 0.497575, acc.: 78.91%] [G loss: 0.764533]\n",
      "epoch:19 step:18584 [D loss: 0.488835, acc.: 75.78%] [G loss: 0.767769]\n",
      "epoch:19 step:18585 [D loss: 0.515235, acc.: 72.66%] [G loss: 0.852322]\n",
      "epoch:19 step:18586 [D loss: 0.607894, acc.: 64.84%] [G loss: 0.625073]\n",
      "epoch:19 step:18587 [D loss: 0.602368, acc.: 66.41%] [G loss: 0.508434]\n",
      "epoch:19 step:18588 [D loss: 0.530899, acc.: 67.97%] [G loss: 0.553537]\n",
      "epoch:19 step:18589 [D loss: 0.503064, acc.: 75.00%] [G loss: 0.691716]\n",
      "epoch:19 step:18590 [D loss: 0.535250, acc.: 71.09%] [G loss: 0.622374]\n",
      "epoch:19 step:18591 [D loss: 0.662246, acc.: 55.47%] [G loss: 0.506555]\n",
      "epoch:19 step:18592 [D loss: 0.514091, acc.: 71.88%] [G loss: 0.537339]\n",
      "epoch:19 step:18593 [D loss: 0.530281, acc.: 67.19%] [G loss: 0.543082]\n",
      "epoch:19 step:18594 [D loss: 0.498907, acc.: 72.66%] [G loss: 0.639217]\n",
      "epoch:19 step:18595 [D loss: 0.513227, acc.: 73.44%] [G loss: 0.757554]\n",
      "epoch:19 step:18596 [D loss: 0.578779, acc.: 71.88%] [G loss: 0.853805]\n",
      "epoch:19 step:18597 [D loss: 0.654155, acc.: 64.84%] [G loss: 0.721324]\n",
      "epoch:19 step:18598 [D loss: 0.555643, acc.: 71.88%] [G loss: 0.631314]\n",
      "epoch:19 step:18599 [D loss: 0.515593, acc.: 71.88%] [G loss: 0.714420]\n",
      "epoch:19 step:18600 [D loss: 0.582735, acc.: 67.19%] [G loss: 0.701436]\n",
      "##############\n",
      "[3.25182139 0.99271489 6.22173412 4.85485322 4.05601906 5.7229667\n",
      " 4.92261414 4.88441451 4.91534508 4.48082406]\n",
      "##########\n",
      "epoch:19 step:18601 [D loss: 0.522264, acc.: 65.62%] [G loss: 0.634099]\n",
      "epoch:19 step:18602 [D loss: 0.535328, acc.: 75.00%] [G loss: 0.547744]\n",
      "epoch:19 step:18603 [D loss: 0.588450, acc.: 64.06%] [G loss: 0.679242]\n",
      "epoch:19 step:18604 [D loss: 0.463880, acc.: 80.47%] [G loss: 0.820231]\n",
      "epoch:19 step:18605 [D loss: 0.458669, acc.: 75.00%] [G loss: 0.785490]\n",
      "epoch:19 step:18606 [D loss: 0.524238, acc.: 74.22%] [G loss: 1.003206]\n",
      "epoch:19 step:18607 [D loss: 0.516069, acc.: 77.34%] [G loss: 0.779642]\n",
      "epoch:19 step:18608 [D loss: 0.556520, acc.: 67.19%] [G loss: 0.548199]\n",
      "epoch:19 step:18609 [D loss: 0.538666, acc.: 71.88%] [G loss: 0.615404]\n",
      "epoch:19 step:18610 [D loss: 0.540268, acc.: 69.53%] [G loss: 0.587071]\n",
      "epoch:19 step:18611 [D loss: 0.528772, acc.: 72.66%] [G loss: 0.457231]\n",
      "epoch:19 step:18612 [D loss: 0.508115, acc.: 73.44%] [G loss: 0.608089]\n",
      "epoch:19 step:18613 [D loss: 0.511971, acc.: 74.22%] [G loss: 0.587219]\n",
      "epoch:19 step:18614 [D loss: 0.586596, acc.: 66.41%] [G loss: 0.594658]\n",
      "epoch:19 step:18615 [D loss: 0.621096, acc.: 67.19%] [G loss: 0.502488]\n",
      "epoch:19 step:18616 [D loss: 0.492463, acc.: 75.00%] [G loss: 0.603375]\n",
      "epoch:19 step:18617 [D loss: 0.506558, acc.: 71.88%] [G loss: 0.475535]\n",
      "epoch:19 step:18618 [D loss: 0.525614, acc.: 78.12%] [G loss: 0.848022]\n",
      "epoch:19 step:18619 [D loss: 0.561277, acc.: 72.66%] [G loss: 0.819780]\n",
      "epoch:19 step:18620 [D loss: 0.638225, acc.: 64.06%] [G loss: 0.716166]\n",
      "epoch:19 step:18621 [D loss: 0.635077, acc.: 61.72%] [G loss: 0.633142]\n",
      "epoch:19 step:18622 [D loss: 0.499950, acc.: 74.22%] [G loss: 0.635846]\n",
      "epoch:19 step:18623 [D loss: 0.632247, acc.: 60.94%] [G loss: 0.575908]\n",
      "epoch:19 step:18624 [D loss: 0.545400, acc.: 71.09%] [G loss: 0.494952]\n",
      "epoch:19 step:18625 [D loss: 0.561249, acc.: 66.41%] [G loss: 0.613851]\n",
      "epoch:19 step:18626 [D loss: 0.463616, acc.: 75.78%] [G loss: 0.641106]\n",
      "epoch:19 step:18627 [D loss: 0.586452, acc.: 69.53%] [G loss: 0.534600]\n",
      "epoch:19 step:18628 [D loss: 0.489221, acc.: 72.66%] [G loss: 0.854248]\n",
      "epoch:19 step:18629 [D loss: 0.544924, acc.: 71.88%] [G loss: 0.734917]\n",
      "epoch:19 step:18630 [D loss: 0.559797, acc.: 69.53%] [G loss: 0.595135]\n",
      "epoch:19 step:18631 [D loss: 0.587646, acc.: 63.28%] [G loss: 0.603732]\n",
      "epoch:19 step:18632 [D loss: 0.516945, acc.: 71.09%] [G loss: 0.645818]\n",
      "epoch:19 step:18633 [D loss: 0.535707, acc.: 69.53%] [G loss: 0.740737]\n",
      "epoch:19 step:18634 [D loss: 0.563485, acc.: 69.53%] [G loss: 0.616656]\n",
      "epoch:19 step:18635 [D loss: 0.541798, acc.: 69.53%] [G loss: 0.632446]\n",
      "epoch:19 step:18636 [D loss: 0.563379, acc.: 67.97%] [G loss: 0.608695]\n",
      "epoch:19 step:18637 [D loss: 0.507689, acc.: 73.44%] [G loss: 0.578015]\n",
      "epoch:19 step:18638 [D loss: 0.549141, acc.: 74.22%] [G loss: 0.606599]\n",
      "epoch:19 step:18639 [D loss: 0.553292, acc.: 70.31%] [G loss: 0.475247]\n",
      "epoch:19 step:18640 [D loss: 0.526647, acc.: 70.31%] [G loss: 0.470933]\n",
      "epoch:19 step:18641 [D loss: 0.526980, acc.: 71.09%] [G loss: 0.589302]\n",
      "epoch:19 step:18642 [D loss: 0.608280, acc.: 61.72%] [G loss: 0.609125]\n",
      "epoch:19 step:18643 [D loss: 0.588154, acc.: 65.62%] [G loss: 0.486339]\n",
      "epoch:19 step:18644 [D loss: 0.552336, acc.: 68.75%] [G loss: 0.435192]\n",
      "epoch:19 step:18645 [D loss: 0.510487, acc.: 70.31%] [G loss: 0.631854]\n",
      "epoch:19 step:18646 [D loss: 0.507801, acc.: 71.09%] [G loss: 0.594196]\n",
      "epoch:19 step:18647 [D loss: 0.554834, acc.: 73.44%] [G loss: 0.617652]\n",
      "epoch:19 step:18648 [D loss: 0.553194, acc.: 71.09%] [G loss: 0.709891]\n",
      "epoch:19 step:18649 [D loss: 0.573662, acc.: 65.62%] [G loss: 0.515865]\n",
      "epoch:19 step:18650 [D loss: 0.626397, acc.: 62.50%] [G loss: 0.451602]\n",
      "epoch:19 step:18651 [D loss: 0.573255, acc.: 64.84%] [G loss: 0.385204]\n",
      "epoch:19 step:18652 [D loss: 0.546519, acc.: 67.19%] [G loss: 0.458907]\n",
      "epoch:19 step:18653 [D loss: 0.554297, acc.: 71.09%] [G loss: 0.540308]\n",
      "epoch:19 step:18654 [D loss: 0.559918, acc.: 69.53%] [G loss: 0.400229]\n",
      "epoch:19 step:18655 [D loss: 0.556677, acc.: 65.62%] [G loss: 0.453925]\n",
      "epoch:19 step:18656 [D loss: 0.549572, acc.: 71.09%] [G loss: 0.584981]\n",
      "epoch:19 step:18657 [D loss: 0.523968, acc.: 68.75%] [G loss: 0.610606]\n",
      "epoch:19 step:18658 [D loss: 0.580301, acc.: 65.62%] [G loss: 0.667412]\n",
      "epoch:19 step:18659 [D loss: 0.597269, acc.: 67.19%] [G loss: 0.584534]\n",
      "epoch:19 step:18660 [D loss: 0.429260, acc.: 81.25%] [G loss: 0.749317]\n",
      "epoch:19 step:18661 [D loss: 0.612601, acc.: 66.41%] [G loss: 0.566285]\n",
      "epoch:19 step:18662 [D loss: 0.523201, acc.: 71.09%] [G loss: 0.602538]\n",
      "epoch:19 step:18663 [D loss: 0.493805, acc.: 72.66%] [G loss: 0.732469]\n",
      "epoch:19 step:18664 [D loss: 0.684851, acc.: 60.94%] [G loss: 0.528655]\n",
      "epoch:19 step:18665 [D loss: 0.557154, acc.: 69.53%] [G loss: 0.477448]\n",
      "epoch:19 step:18666 [D loss: 0.571261, acc.: 65.62%] [G loss: 0.469556]\n",
      "epoch:19 step:18667 [D loss: 0.492395, acc.: 69.53%] [G loss: 0.618013]\n",
      "epoch:19 step:18668 [D loss: 0.522427, acc.: 71.09%] [G loss: 0.590755]\n",
      "epoch:19 step:18669 [D loss: 0.503793, acc.: 71.88%] [G loss: 0.544197]\n",
      "epoch:19 step:18670 [D loss: 0.587237, acc.: 66.41%] [G loss: 0.571998]\n",
      "epoch:19 step:18671 [D loss: 0.553508, acc.: 69.53%] [G loss: 0.608485]\n",
      "epoch:19 step:18672 [D loss: 0.597236, acc.: 67.97%] [G loss: 0.614759]\n",
      "epoch:19 step:18673 [D loss: 0.451425, acc.: 80.47%] [G loss: 0.719206]\n",
      "epoch:19 step:18674 [D loss: 0.536151, acc.: 73.44%] [G loss: 0.631639]\n",
      "epoch:19 step:18675 [D loss: 0.509610, acc.: 75.78%] [G loss: 0.710019]\n",
      "epoch:19 step:18676 [D loss: 0.523840, acc.: 77.34%] [G loss: 0.748740]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18677 [D loss: 0.502261, acc.: 76.56%] [G loss: 0.725043]\n",
      "epoch:19 step:18678 [D loss: 0.503518, acc.: 75.00%] [G loss: 0.711335]\n",
      "epoch:19 step:18679 [D loss: 0.558427, acc.: 69.53%] [G loss: 0.585877]\n",
      "epoch:19 step:18680 [D loss: 0.608027, acc.: 63.28%] [G loss: 0.551495]\n",
      "epoch:19 step:18681 [D loss: 0.542446, acc.: 71.88%] [G loss: 0.645537]\n",
      "epoch:19 step:18682 [D loss: 0.536200, acc.: 69.53%] [G loss: 0.665073]\n",
      "epoch:19 step:18683 [D loss: 0.667000, acc.: 57.03%] [G loss: 0.444888]\n",
      "epoch:19 step:18684 [D loss: 0.566253, acc.: 71.09%] [G loss: 0.483174]\n",
      "epoch:19 step:18685 [D loss: 0.584129, acc.: 67.19%] [G loss: 0.455376]\n",
      "epoch:19 step:18686 [D loss: 0.597466, acc.: 68.75%] [G loss: 0.585719]\n",
      "epoch:19 step:18687 [D loss: 0.473231, acc.: 80.47%] [G loss: 0.660100]\n",
      "epoch:19 step:18688 [D loss: 0.531730, acc.: 73.44%] [G loss: 0.745616]\n",
      "epoch:19 step:18689 [D loss: 0.520026, acc.: 72.66%] [G loss: 0.894712]\n",
      "epoch:19 step:18690 [D loss: 0.575659, acc.: 65.62%] [G loss: 0.776468]\n",
      "epoch:19 step:18691 [D loss: 0.561086, acc.: 67.97%] [G loss: 0.711878]\n",
      "epoch:19 step:18692 [D loss: 0.611275, acc.: 66.41%] [G loss: 0.587279]\n",
      "epoch:19 step:18693 [D loss: 0.525376, acc.: 71.09%] [G loss: 0.616679]\n",
      "epoch:19 step:18694 [D loss: 0.616754, acc.: 63.28%] [G loss: 0.549032]\n",
      "epoch:19 step:18695 [D loss: 0.607652, acc.: 64.84%] [G loss: 0.567802]\n",
      "epoch:19 step:18696 [D loss: 0.481381, acc.: 77.34%] [G loss: 0.728061]\n",
      "epoch:19 step:18697 [D loss: 0.472674, acc.: 76.56%] [G loss: 0.742951]\n",
      "epoch:19 step:18698 [D loss: 0.542299, acc.: 68.75%] [G loss: 0.697569]\n",
      "epoch:19 step:18699 [D loss: 0.523800, acc.: 73.44%] [G loss: 0.654787]\n",
      "epoch:19 step:18700 [D loss: 0.480030, acc.: 78.12%] [G loss: 0.752685]\n",
      "epoch:19 step:18701 [D loss: 0.471038, acc.: 78.91%] [G loss: 0.969710]\n",
      "epoch:19 step:18702 [D loss: 0.485941, acc.: 77.34%] [G loss: 0.919218]\n",
      "epoch:19 step:18703 [D loss: 0.538927, acc.: 74.22%] [G loss: 0.751945]\n",
      "epoch:19 step:18704 [D loss: 0.543068, acc.: 72.66%] [G loss: 0.850806]\n",
      "epoch:19 step:18705 [D loss: 0.609375, acc.: 67.19%] [G loss: 0.640124]\n",
      "epoch:19 step:18706 [D loss: 0.519497, acc.: 75.78%] [G loss: 0.543468]\n",
      "epoch:19 step:18707 [D loss: 0.626956, acc.: 64.84%] [G loss: 0.689450]\n",
      "epoch:19 step:18708 [D loss: 0.543125, acc.: 69.53%] [G loss: 0.676603]\n",
      "epoch:19 step:18709 [D loss: 0.490665, acc.: 75.78%] [G loss: 0.728784]\n",
      "epoch:19 step:18710 [D loss: 0.542905, acc.: 68.75%] [G loss: 0.629806]\n",
      "epoch:19 step:18711 [D loss: 0.510697, acc.: 72.66%] [G loss: 0.556466]\n",
      "epoch:19 step:18712 [D loss: 0.567975, acc.: 67.97%] [G loss: 0.631612]\n",
      "epoch:19 step:18713 [D loss: 0.494072, acc.: 73.44%] [G loss: 0.692757]\n",
      "epoch:19 step:18714 [D loss: 0.478705, acc.: 75.00%] [G loss: 0.748712]\n",
      "epoch:19 step:18715 [D loss: 0.491004, acc.: 77.34%] [G loss: 0.846176]\n",
      "epoch:19 step:18716 [D loss: 0.549736, acc.: 73.44%] [G loss: 0.748703]\n",
      "epoch:19 step:18717 [D loss: 0.454589, acc.: 76.56%] [G loss: 0.865676]\n",
      "epoch:19 step:18718 [D loss: 0.667577, acc.: 57.03%] [G loss: 0.610715]\n",
      "epoch:19 step:18719 [D loss: 0.508448, acc.: 77.34%] [G loss: 0.685610]\n",
      "epoch:19 step:18720 [D loss: 0.578862, acc.: 65.62%] [G loss: 0.619627]\n",
      "epoch:19 step:18721 [D loss: 0.515298, acc.: 76.56%] [G loss: 0.996524]\n",
      "epoch:19 step:18722 [D loss: 0.518367, acc.: 71.88%] [G loss: 0.937638]\n",
      "epoch:19 step:18723 [D loss: 0.750880, acc.: 57.03%] [G loss: 0.667249]\n",
      "epoch:19 step:18724 [D loss: 0.494340, acc.: 71.88%] [G loss: 0.597474]\n",
      "epoch:19 step:18725 [D loss: 0.510636, acc.: 72.66%] [G loss: 0.770773]\n",
      "epoch:19 step:18726 [D loss: 0.484195, acc.: 72.66%] [G loss: 0.562877]\n",
      "epoch:19 step:18727 [D loss: 0.458344, acc.: 75.78%] [G loss: 0.873232]\n",
      "epoch:19 step:18728 [D loss: 0.429812, acc.: 80.47%] [G loss: 0.967266]\n",
      "epoch:19 step:18729 [D loss: 0.438242, acc.: 75.78%] [G loss: 1.079765]\n",
      "epoch:19 step:18730 [D loss: 0.511046, acc.: 69.53%] [G loss: 1.355128]\n",
      "epoch:19 step:18731 [D loss: 0.744653, acc.: 60.94%] [G loss: 0.840548]\n",
      "epoch:19 step:18732 [D loss: 0.506858, acc.: 77.34%] [G loss: 1.131060]\n",
      "epoch:19 step:18733 [D loss: 0.490562, acc.: 76.56%] [G loss: 1.131849]\n",
      "epoch:19 step:18734 [D loss: 0.472304, acc.: 71.88%] [G loss: 0.953615]\n",
      "epoch:19 step:18735 [D loss: 0.626836, acc.: 64.84%] [G loss: 0.684795]\n",
      "epoch:19 step:18736 [D loss: 0.503634, acc.: 78.12%] [G loss: 0.771142]\n",
      "epoch:19 step:18737 [D loss: 0.537512, acc.: 69.53%] [G loss: 0.821128]\n",
      "epoch:19 step:18738 [D loss: 0.466325, acc.: 75.78%] [G loss: 0.708355]\n",
      "epoch:19 step:18739 [D loss: 0.403266, acc.: 83.59%] [G loss: 0.995141]\n",
      "epoch:19 step:18740 [D loss: 0.476303, acc.: 79.69%] [G loss: 1.327511]\n",
      "epoch:20 step:18741 [D loss: 0.603452, acc.: 68.75%] [G loss: 1.137531]\n",
      "epoch:20 step:18742 [D loss: 0.493759, acc.: 73.44%] [G loss: 0.984139]\n",
      "epoch:20 step:18743 [D loss: 0.564394, acc.: 67.19%] [G loss: 0.932365]\n",
      "epoch:20 step:18744 [D loss: 0.525599, acc.: 72.66%] [G loss: 0.915664]\n",
      "epoch:20 step:18745 [D loss: 0.625465, acc.: 61.72%] [G loss: 0.713806]\n",
      "epoch:20 step:18746 [D loss: 0.575306, acc.: 69.53%] [G loss: 0.661197]\n",
      "epoch:20 step:18747 [D loss: 0.512588, acc.: 75.78%] [G loss: 0.638526]\n",
      "epoch:20 step:18748 [D loss: 0.469836, acc.: 80.47%] [G loss: 0.857297]\n",
      "epoch:20 step:18749 [D loss: 0.508357, acc.: 76.56%] [G loss: 0.964502]\n",
      "epoch:20 step:18750 [D loss: 0.512609, acc.: 75.78%] [G loss: 0.754655]\n",
      "epoch:20 step:18751 [D loss: 0.483882, acc.: 78.12%] [G loss: 0.813865]\n",
      "epoch:20 step:18752 [D loss: 0.621179, acc.: 64.84%] [G loss: 0.655190]\n",
      "epoch:20 step:18753 [D loss: 0.607090, acc.: 66.41%] [G loss: 0.731556]\n",
      "epoch:20 step:18754 [D loss: 0.576352, acc.: 66.41%] [G loss: 0.672663]\n",
      "epoch:20 step:18755 [D loss: 0.489026, acc.: 76.56%] [G loss: 0.752547]\n",
      "epoch:20 step:18756 [D loss: 0.518749, acc.: 74.22%] [G loss: 0.821483]\n",
      "epoch:20 step:18757 [D loss: 0.536254, acc.: 73.44%] [G loss: 0.619391]\n",
      "epoch:20 step:18758 [D loss: 0.576881, acc.: 68.75%] [G loss: 0.600217]\n",
      "epoch:20 step:18759 [D loss: 0.586356, acc.: 67.97%] [G loss: 0.597169]\n",
      "epoch:20 step:18760 [D loss: 0.601566, acc.: 64.84%] [G loss: 0.769406]\n",
      "epoch:20 step:18761 [D loss: 0.593414, acc.: 65.62%] [G loss: 0.632421]\n",
      "epoch:20 step:18762 [D loss: 0.483988, acc.: 76.56%] [G loss: 0.760292]\n",
      "epoch:20 step:18763 [D loss: 0.579647, acc.: 66.41%] [G loss: 0.506830]\n",
      "epoch:20 step:18764 [D loss: 0.517703, acc.: 72.66%] [G loss: 0.660070]\n",
      "epoch:20 step:18765 [D loss: 0.485328, acc.: 78.91%] [G loss: 0.656750]\n",
      "epoch:20 step:18766 [D loss: 0.565839, acc.: 66.41%] [G loss: 0.541041]\n",
      "epoch:20 step:18767 [D loss: 0.431554, acc.: 81.25%] [G loss: 0.645844]\n",
      "epoch:20 step:18768 [D loss: 0.546192, acc.: 71.09%] [G loss: 0.745666]\n",
      "epoch:20 step:18769 [D loss: 0.524196, acc.: 71.88%] [G loss: 0.678278]\n",
      "epoch:20 step:18770 [D loss: 0.556078, acc.: 69.53%] [G loss: 0.679535]\n",
      "epoch:20 step:18771 [D loss: 0.597633, acc.: 66.41%] [G loss: 0.638863]\n",
      "epoch:20 step:18772 [D loss: 0.531530, acc.: 68.75%] [G loss: 0.615629]\n",
      "epoch:20 step:18773 [D loss: 0.531844, acc.: 72.66%] [G loss: 0.573178]\n",
      "epoch:20 step:18774 [D loss: 0.542488, acc.: 67.19%] [G loss: 0.547104]\n",
      "epoch:20 step:18775 [D loss: 0.581136, acc.: 68.75%] [G loss: 0.728839]\n",
      "epoch:20 step:18776 [D loss: 0.527105, acc.: 67.19%] [G loss: 0.653938]\n",
      "epoch:20 step:18777 [D loss: 0.501721, acc.: 75.78%] [G loss: 0.683724]\n",
      "epoch:20 step:18778 [D loss: 0.583883, acc.: 66.41%] [G loss: 0.669325]\n",
      "epoch:20 step:18779 [D loss: 0.552638, acc.: 71.09%] [G loss: 0.813009]\n",
      "epoch:20 step:18780 [D loss: 0.470125, acc.: 75.78%] [G loss: 0.749504]\n",
      "epoch:20 step:18781 [D loss: 0.501408, acc.: 75.00%] [G loss: 0.765315]\n",
      "epoch:20 step:18782 [D loss: 0.469637, acc.: 78.91%] [G loss: 0.705702]\n",
      "epoch:20 step:18783 [D loss: 0.541624, acc.: 68.75%] [G loss: 0.635373]\n",
      "epoch:20 step:18784 [D loss: 0.588386, acc.: 64.84%] [G loss: 0.605992]\n",
      "epoch:20 step:18785 [D loss: 0.477228, acc.: 73.44%] [G loss: 0.617332]\n",
      "epoch:20 step:18786 [D loss: 0.498953, acc.: 75.78%] [G loss: 0.683603]\n",
      "epoch:20 step:18787 [D loss: 0.540437, acc.: 68.75%] [G loss: 0.598401]\n",
      "epoch:20 step:18788 [D loss: 0.555781, acc.: 71.09%] [G loss: 0.719142]\n",
      "epoch:20 step:18789 [D loss: 0.461074, acc.: 77.34%] [G loss: 0.771700]\n",
      "epoch:20 step:18790 [D loss: 0.530277, acc.: 70.31%] [G loss: 0.796416]\n",
      "epoch:20 step:18791 [D loss: 0.621327, acc.: 65.62%] [G loss: 0.685916]\n",
      "epoch:20 step:18792 [D loss: 0.546319, acc.: 65.62%] [G loss: 0.568523]\n",
      "epoch:20 step:18793 [D loss: 0.505623, acc.: 73.44%] [G loss: 0.753177]\n",
      "epoch:20 step:18794 [D loss: 0.465973, acc.: 78.12%] [G loss: 0.809701]\n",
      "epoch:20 step:18795 [D loss: 0.524485, acc.: 75.00%] [G loss: 0.652224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:18796 [D loss: 0.512050, acc.: 71.88%] [G loss: 0.736767]\n",
      "epoch:20 step:18797 [D loss: 0.520597, acc.: 77.34%] [G loss: 0.614393]\n",
      "epoch:20 step:18798 [D loss: 0.538958, acc.: 67.19%] [G loss: 0.724646]\n",
      "epoch:20 step:18799 [D loss: 0.517319, acc.: 73.44%] [G loss: 0.867400]\n",
      "epoch:20 step:18800 [D loss: 0.505137, acc.: 69.53%] [G loss: 0.977588]\n",
      "##############\n",
      "[3.20410132 0.92846623 6.35403709 5.00672397 3.52611518 5.63283652\n",
      " 4.66242673 4.8032646  4.55192693 4.01741447]\n",
      "##########\n",
      "epoch:20 step:18801 [D loss: 0.576438, acc.: 67.19%] [G loss: 0.709256]\n",
      "epoch:20 step:18802 [D loss: 0.546597, acc.: 71.88%] [G loss: 0.638106]\n",
      "epoch:20 step:18803 [D loss: 0.548865, acc.: 68.75%] [G loss: 0.611256]\n",
      "epoch:20 step:18804 [D loss: 0.537886, acc.: 71.09%] [G loss: 0.585151]\n",
      "epoch:20 step:18805 [D loss: 0.543646, acc.: 74.22%] [G loss: 0.671346]\n",
      "epoch:20 step:18806 [D loss: 0.537582, acc.: 68.75%] [G loss: 0.648817]\n",
      "epoch:20 step:18807 [D loss: 0.536224, acc.: 73.44%] [G loss: 0.635947]\n",
      "epoch:20 step:18808 [D loss: 0.543913, acc.: 72.66%] [G loss: 0.568919]\n",
      "epoch:20 step:18809 [D loss: 0.500224, acc.: 78.12%] [G loss: 0.742351]\n",
      "epoch:20 step:18810 [D loss: 0.485527, acc.: 79.69%] [G loss: 0.677881]\n",
      "epoch:20 step:18811 [D loss: 0.516240, acc.: 69.53%] [G loss: 0.594917]\n",
      "epoch:20 step:18812 [D loss: 0.497837, acc.: 75.00%] [G loss: 0.627530]\n",
      "epoch:20 step:18813 [D loss: 0.587838, acc.: 65.62%] [G loss: 0.669188]\n",
      "epoch:20 step:18814 [D loss: 0.503462, acc.: 71.88%] [G loss: 0.578053]\n",
      "epoch:20 step:18815 [D loss: 0.504927, acc.: 71.09%] [G loss: 0.851300]\n",
      "epoch:20 step:18816 [D loss: 0.493585, acc.: 71.88%] [G loss: 0.727732]\n",
      "epoch:20 step:18817 [D loss: 0.449612, acc.: 77.34%] [G loss: 0.860855]\n",
      "epoch:20 step:18818 [D loss: 0.602485, acc.: 65.62%] [G loss: 0.581334]\n",
      "epoch:20 step:18819 [D loss: 0.550993, acc.: 67.97%] [G loss: 0.614479]\n",
      "epoch:20 step:18820 [D loss: 0.479367, acc.: 78.91%] [G loss: 0.710805]\n",
      "epoch:20 step:18821 [D loss: 0.534664, acc.: 71.88%] [G loss: 0.814371]\n",
      "epoch:20 step:18822 [D loss: 0.506493, acc.: 71.09%] [G loss: 0.623635]\n",
      "epoch:20 step:18823 [D loss: 0.483597, acc.: 71.88%] [G loss: 0.641074]\n",
      "epoch:20 step:18824 [D loss: 0.528900, acc.: 70.31%] [G loss: 0.715437]\n",
      "epoch:20 step:18825 [D loss: 0.549485, acc.: 68.75%] [G loss: 0.841818]\n",
      "epoch:20 step:18826 [D loss: 0.466240, acc.: 73.44%] [G loss: 0.692137]\n",
      "epoch:20 step:18827 [D loss: 0.543922, acc.: 68.75%] [G loss: 0.562213]\n",
      "epoch:20 step:18828 [D loss: 0.474532, acc.: 78.12%] [G loss: 0.556248]\n",
      "epoch:20 step:18829 [D loss: 0.521086, acc.: 76.56%] [G loss: 0.567272]\n",
      "epoch:20 step:18830 [D loss: 0.482717, acc.: 78.91%] [G loss: 0.740054]\n",
      "epoch:20 step:18831 [D loss: 0.535466, acc.: 70.31%] [G loss: 0.752802]\n",
      "epoch:20 step:18832 [D loss: 0.466227, acc.: 75.00%] [G loss: 0.646994]\n",
      "epoch:20 step:18833 [D loss: 0.475113, acc.: 75.00%] [G loss: 0.800164]\n",
      "epoch:20 step:18834 [D loss: 0.482651, acc.: 72.66%] [G loss: 0.890393]\n",
      "epoch:20 step:18835 [D loss: 0.578159, acc.: 67.19%] [G loss: 0.697417]\n",
      "epoch:20 step:18836 [D loss: 0.519512, acc.: 71.88%] [G loss: 0.650768]\n",
      "epoch:20 step:18837 [D loss: 0.487745, acc.: 75.78%] [G loss: 0.690793]\n",
      "epoch:20 step:18838 [D loss: 0.562234, acc.: 65.62%] [G loss: 0.686809]\n",
      "epoch:20 step:18839 [D loss: 0.520488, acc.: 73.44%] [G loss: 0.737465]\n",
      "epoch:20 step:18840 [D loss: 0.464874, acc.: 78.91%] [G loss: 0.718577]\n",
      "epoch:20 step:18841 [D loss: 0.461763, acc.: 82.81%] [G loss: 0.732100]\n",
      "epoch:20 step:18842 [D loss: 0.639549, acc.: 64.84%] [G loss: 0.649944]\n",
      "epoch:20 step:18843 [D loss: 0.486888, acc.: 71.88%] [G loss: 0.747729]\n",
      "epoch:20 step:18844 [D loss: 0.509364, acc.: 70.31%] [G loss: 0.824065]\n",
      "epoch:20 step:18845 [D loss: 0.553017, acc.: 68.75%] [G loss: 0.780464]\n",
      "epoch:20 step:18846 [D loss: 0.540122, acc.: 71.88%] [G loss: 0.630963]\n",
      "epoch:20 step:18847 [D loss: 0.564727, acc.: 68.75%] [G loss: 0.678626]\n",
      "epoch:20 step:18848 [D loss: 0.617592, acc.: 64.84%] [G loss: 0.669177]\n",
      "epoch:20 step:18849 [D loss: 0.569006, acc.: 69.53%] [G loss: 0.658706]\n",
      "epoch:20 step:18850 [D loss: 0.548003, acc.: 71.88%] [G loss: 0.595707]\n",
      "epoch:20 step:18851 [D loss: 0.484847, acc.: 75.78%] [G loss: 0.609322]\n",
      "epoch:20 step:18852 [D loss: 0.488080, acc.: 77.34%] [G loss: 0.651812]\n",
      "epoch:20 step:18853 [D loss: 0.494170, acc.: 77.34%] [G loss: 0.637314]\n",
      "epoch:20 step:18854 [D loss: 0.522664, acc.: 71.88%] [G loss: 0.592940]\n",
      "epoch:20 step:18855 [D loss: 0.546827, acc.: 76.56%] [G loss: 0.794921]\n",
      "epoch:20 step:18856 [D loss: 0.502494, acc.: 75.00%] [G loss: 0.725716]\n",
      "epoch:20 step:18857 [D loss: 0.597159, acc.: 67.19%] [G loss: 0.867340]\n",
      "epoch:20 step:18858 [D loss: 0.533922, acc.: 73.44%] [G loss: 0.696974]\n",
      "epoch:20 step:18859 [D loss: 0.486075, acc.: 75.00%] [G loss: 0.827619]\n",
      "epoch:20 step:18860 [D loss: 0.574196, acc.: 67.97%] [G loss: 0.651256]\n",
      "epoch:20 step:18861 [D loss: 0.520710, acc.: 75.78%] [G loss: 0.720513]\n",
      "epoch:20 step:18862 [D loss: 0.475130, acc.: 78.12%] [G loss: 0.762730]\n",
      "epoch:20 step:18863 [D loss: 0.482864, acc.: 76.56%] [G loss: 0.954782]\n",
      "epoch:20 step:18864 [D loss: 0.577581, acc.: 68.75%] [G loss: 0.681811]\n",
      "epoch:20 step:18865 [D loss: 0.535003, acc.: 70.31%] [G loss: 0.625216]\n",
      "epoch:20 step:18866 [D loss: 0.505571, acc.: 71.09%] [G loss: 0.657987]\n",
      "epoch:20 step:18867 [D loss: 0.453578, acc.: 79.69%] [G loss: 0.590442]\n",
      "epoch:20 step:18868 [D loss: 0.500747, acc.: 73.44%] [G loss: 0.772359]\n",
      "epoch:20 step:18869 [D loss: 0.539843, acc.: 72.66%] [G loss: 0.740946]\n",
      "epoch:20 step:18870 [D loss: 0.525583, acc.: 73.44%] [G loss: 0.618916]\n",
      "epoch:20 step:18871 [D loss: 0.528753, acc.: 69.53%] [G loss: 0.513670]\n",
      "epoch:20 step:18872 [D loss: 0.557347, acc.: 73.44%] [G loss: 0.682008]\n",
      "epoch:20 step:18873 [D loss: 0.522249, acc.: 69.53%] [G loss: 0.774095]\n",
      "epoch:20 step:18874 [D loss: 0.550004, acc.: 66.41%] [G loss: 0.858021]\n",
      "epoch:20 step:18875 [D loss: 0.536677, acc.: 73.44%] [G loss: 0.728060]\n",
      "epoch:20 step:18876 [D loss: 0.551497, acc.: 70.31%] [G loss: 0.744060]\n",
      "epoch:20 step:18877 [D loss: 0.630795, acc.: 65.62%] [G loss: 0.607694]\n",
      "epoch:20 step:18878 [D loss: 0.537958, acc.: 71.88%] [G loss: 0.605893]\n",
      "epoch:20 step:18879 [D loss: 0.520108, acc.: 70.31%] [G loss: 0.600533]\n",
      "epoch:20 step:18880 [D loss: 0.597025, acc.: 70.31%] [G loss: 0.773070]\n",
      "epoch:20 step:18881 [D loss: 0.499095, acc.: 71.88%] [G loss: 0.703448]\n",
      "epoch:20 step:18882 [D loss: 0.545595, acc.: 64.06%] [G loss: 0.824690]\n",
      "epoch:20 step:18883 [D loss: 0.549176, acc.: 72.66%] [G loss: 0.697166]\n",
      "epoch:20 step:18884 [D loss: 0.505503, acc.: 74.22%] [G loss: 0.666589]\n",
      "epoch:20 step:18885 [D loss: 0.548662, acc.: 70.31%] [G loss: 0.725048]\n",
      "epoch:20 step:18886 [D loss: 0.435082, acc.: 82.81%] [G loss: 0.787825]\n",
      "epoch:20 step:18887 [D loss: 0.634903, acc.: 67.97%] [G loss: 0.638187]\n",
      "epoch:20 step:18888 [D loss: 0.537259, acc.: 71.88%] [G loss: 0.685651]\n",
      "epoch:20 step:18889 [D loss: 0.539977, acc.: 73.44%] [G loss: 0.579961]\n",
      "epoch:20 step:18890 [D loss: 0.542059, acc.: 73.44%] [G loss: 0.551187]\n",
      "epoch:20 step:18891 [D loss: 0.553908, acc.: 65.62%] [G loss: 0.609435]\n",
      "epoch:20 step:18892 [D loss: 0.525821, acc.: 75.00%] [G loss: 0.764616]\n",
      "epoch:20 step:18893 [D loss: 0.539549, acc.: 73.44%] [G loss: 0.608944]\n",
      "epoch:20 step:18894 [D loss: 0.488336, acc.: 75.78%] [G loss: 0.733865]\n",
      "epoch:20 step:18895 [D loss: 0.467466, acc.: 77.34%] [G loss: 0.920228]\n",
      "epoch:20 step:18896 [D loss: 0.524404, acc.: 74.22%] [G loss: 0.871828]\n",
      "epoch:20 step:18897 [D loss: 0.535421, acc.: 71.88%] [G loss: 0.655125]\n",
      "epoch:20 step:18898 [D loss: 0.591014, acc.: 64.84%] [G loss: 0.699435]\n",
      "epoch:20 step:18899 [D loss: 0.505333, acc.: 79.69%] [G loss: 0.771231]\n",
      "epoch:20 step:18900 [D loss: 0.603091, acc.: 66.41%] [G loss: 0.700483]\n",
      "epoch:20 step:18901 [D loss: 0.512511, acc.: 69.53%] [G loss: 0.730111]\n",
      "epoch:20 step:18902 [D loss: 0.534337, acc.: 72.66%] [G loss: 0.727084]\n",
      "epoch:20 step:18903 [D loss: 0.605917, acc.: 64.06%] [G loss: 0.689793]\n",
      "epoch:20 step:18904 [D loss: 0.529511, acc.: 68.75%] [G loss: 0.851337]\n",
      "epoch:20 step:18905 [D loss: 0.547565, acc.: 68.75%] [G loss: 0.663548]\n",
      "epoch:20 step:18906 [D loss: 0.517818, acc.: 72.66%] [G loss: 0.573141]\n",
      "epoch:20 step:18907 [D loss: 0.509611, acc.: 71.09%] [G loss: 0.571542]\n",
      "epoch:20 step:18908 [D loss: 0.555573, acc.: 68.75%] [G loss: 0.574650]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:18909 [D loss: 0.576513, acc.: 67.97%] [G loss: 0.485472]\n",
      "epoch:20 step:18910 [D loss: 0.565637, acc.: 66.41%] [G loss: 0.585030]\n",
      "epoch:20 step:18911 [D loss: 0.522904, acc.: 73.44%] [G loss: 0.660950]\n",
      "epoch:20 step:18912 [D loss: 0.502771, acc.: 76.56%] [G loss: 0.633573]\n",
      "epoch:20 step:18913 [D loss: 0.464659, acc.: 78.12%] [G loss: 0.711653]\n",
      "epoch:20 step:18914 [D loss: 0.617970, acc.: 60.16%] [G loss: 0.648179]\n",
      "epoch:20 step:18915 [D loss: 0.602879, acc.: 64.84%] [G loss: 0.469051]\n",
      "epoch:20 step:18916 [D loss: 0.556557, acc.: 67.19%] [G loss: 0.576154]\n",
      "epoch:20 step:18917 [D loss: 0.486063, acc.: 75.78%] [G loss: 0.611074]\n",
      "epoch:20 step:18918 [D loss: 0.554918, acc.: 68.75%] [G loss: 0.554621]\n",
      "epoch:20 step:18919 [D loss: 0.489212, acc.: 77.34%] [G loss: 0.606946]\n",
      "epoch:20 step:18920 [D loss: 0.617457, acc.: 60.94%] [G loss: 0.543464]\n",
      "epoch:20 step:18921 [D loss: 0.584071, acc.: 65.62%] [G loss: 0.507757]\n",
      "epoch:20 step:18922 [D loss: 0.539713, acc.: 71.09%] [G loss: 0.719627]\n",
      "epoch:20 step:18923 [D loss: 0.578534, acc.: 68.75%] [G loss: 0.834342]\n",
      "epoch:20 step:18924 [D loss: 0.533047, acc.: 71.88%] [G loss: 0.628646]\n",
      "epoch:20 step:18925 [D loss: 0.565036, acc.: 70.31%] [G loss: 0.521709]\n",
      "epoch:20 step:18926 [D loss: 0.589763, acc.: 70.31%] [G loss: 0.682512]\n",
      "epoch:20 step:18927 [D loss: 0.582845, acc.: 66.41%] [G loss: 0.566923]\n",
      "epoch:20 step:18928 [D loss: 0.554648, acc.: 65.62%] [G loss: 0.665222]\n",
      "epoch:20 step:18929 [D loss: 0.585647, acc.: 66.41%] [G loss: 0.617892]\n",
      "epoch:20 step:18930 [D loss: 0.465715, acc.: 75.78%] [G loss: 0.590410]\n",
      "epoch:20 step:18931 [D loss: 0.504190, acc.: 74.22%] [G loss: 0.643140]\n",
      "epoch:20 step:18932 [D loss: 0.546060, acc.: 70.31%] [G loss: 0.683844]\n",
      "epoch:20 step:18933 [D loss: 0.589677, acc.: 67.97%] [G loss: 0.709290]\n",
      "epoch:20 step:18934 [D loss: 0.421636, acc.: 80.47%] [G loss: 0.699458]\n",
      "epoch:20 step:18935 [D loss: 0.539422, acc.: 74.22%] [G loss: 0.692291]\n",
      "epoch:20 step:18936 [D loss: 0.554764, acc.: 67.19%] [G loss: 0.604724]\n",
      "epoch:20 step:18937 [D loss: 0.525267, acc.: 72.66%] [G loss: 0.596259]\n",
      "epoch:20 step:18938 [D loss: 0.461664, acc.: 83.59%] [G loss: 0.833354]\n",
      "epoch:20 step:18939 [D loss: 0.473999, acc.: 75.00%] [G loss: 0.802911]\n",
      "epoch:20 step:18940 [D loss: 0.622543, acc.: 64.06%] [G loss: 0.553569]\n",
      "epoch:20 step:18941 [D loss: 0.521111, acc.: 74.22%] [G loss: 0.545874]\n",
      "epoch:20 step:18942 [D loss: 0.526166, acc.: 71.88%] [G loss: 0.708606]\n",
      "epoch:20 step:18943 [D loss: 0.623291, acc.: 66.41%] [G loss: 0.561609]\n",
      "epoch:20 step:18944 [D loss: 0.541016, acc.: 74.22%] [G loss: 0.589454]\n",
      "epoch:20 step:18945 [D loss: 0.545004, acc.: 68.75%] [G loss: 0.795264]\n",
      "epoch:20 step:18946 [D loss: 0.459766, acc.: 78.91%] [G loss: 0.810736]\n",
      "epoch:20 step:18947 [D loss: 0.453280, acc.: 76.56%] [G loss: 0.689360]\n",
      "epoch:20 step:18948 [D loss: 0.495800, acc.: 75.00%] [G loss: 0.786514]\n",
      "epoch:20 step:18949 [D loss: 0.509008, acc.: 71.09%] [G loss: 0.656571]\n",
      "epoch:20 step:18950 [D loss: 0.617737, acc.: 68.75%] [G loss: 0.607942]\n",
      "epoch:20 step:18951 [D loss: 0.627095, acc.: 61.72%] [G loss: 0.535226]\n",
      "epoch:20 step:18952 [D loss: 0.507932, acc.: 74.22%] [G loss: 0.825918]\n",
      "epoch:20 step:18953 [D loss: 0.496529, acc.: 73.44%] [G loss: 0.693194]\n",
      "epoch:20 step:18954 [D loss: 0.661497, acc.: 63.28%] [G loss: 0.561371]\n",
      "epoch:20 step:18955 [D loss: 0.573731, acc.: 68.75%] [G loss: 0.466578]\n",
      "epoch:20 step:18956 [D loss: 0.524284, acc.: 69.53%] [G loss: 0.610004]\n",
      "epoch:20 step:18957 [D loss: 0.511155, acc.: 75.78%] [G loss: 0.664518]\n",
      "epoch:20 step:18958 [D loss: 0.526167, acc.: 70.31%] [G loss: 0.653262]\n",
      "epoch:20 step:18959 [D loss: 0.451919, acc.: 79.69%] [G loss: 0.766040]\n",
      "epoch:20 step:18960 [D loss: 0.643248, acc.: 61.72%] [G loss: 0.560118]\n",
      "epoch:20 step:18961 [D loss: 0.504384, acc.: 71.88%] [G loss: 0.587728]\n",
      "epoch:20 step:18962 [D loss: 0.472898, acc.: 74.22%] [G loss: 0.755443]\n",
      "epoch:20 step:18963 [D loss: 0.571314, acc.: 69.53%] [G loss: 0.801828]\n",
      "epoch:20 step:18964 [D loss: 0.594735, acc.: 68.75%] [G loss: 0.612662]\n",
      "epoch:20 step:18965 [D loss: 0.490065, acc.: 76.56%] [G loss: 0.649248]\n",
      "epoch:20 step:18966 [D loss: 0.624159, acc.: 67.19%] [G loss: 0.670984]\n",
      "epoch:20 step:18967 [D loss: 0.558255, acc.: 72.66%] [G loss: 0.536754]\n",
      "epoch:20 step:18968 [D loss: 0.582161, acc.: 64.06%] [G loss: 0.564538]\n",
      "epoch:20 step:18969 [D loss: 0.533012, acc.: 69.53%] [G loss: 0.545460]\n",
      "epoch:20 step:18970 [D loss: 0.501261, acc.: 72.66%] [G loss: 0.808745]\n",
      "epoch:20 step:18971 [D loss: 0.505810, acc.: 67.97%] [G loss: 0.829203]\n",
      "epoch:20 step:18972 [D loss: 0.492523, acc.: 75.78%] [G loss: 0.929189]\n",
      "epoch:20 step:18973 [D loss: 0.519062, acc.: 73.44%] [G loss: 0.753350]\n",
      "epoch:20 step:18974 [D loss: 0.562587, acc.: 68.75%] [G loss: 0.572805]\n",
      "epoch:20 step:18975 [D loss: 0.567572, acc.: 64.84%] [G loss: 0.761768]\n",
      "epoch:20 step:18976 [D loss: 0.524647, acc.: 68.75%] [G loss: 0.596457]\n",
      "epoch:20 step:18977 [D loss: 0.530615, acc.: 69.53%] [G loss: 0.692983]\n",
      "epoch:20 step:18978 [D loss: 0.566159, acc.: 66.41%] [G loss: 0.518022]\n",
      "epoch:20 step:18979 [D loss: 0.522764, acc.: 74.22%] [G loss: 0.580651]\n",
      "epoch:20 step:18980 [D loss: 0.560269, acc.: 67.97%] [G loss: 0.627866]\n",
      "epoch:20 step:18981 [D loss: 0.519525, acc.: 74.22%] [G loss: 0.738085]\n",
      "epoch:20 step:18982 [D loss: 0.521122, acc.: 74.22%] [G loss: 0.518082]\n",
      "epoch:20 step:18983 [D loss: 0.529093, acc.: 69.53%] [G loss: 0.771549]\n",
      "epoch:20 step:18984 [D loss: 0.547154, acc.: 69.53%] [G loss: 0.688969]\n",
      "epoch:20 step:18985 [D loss: 0.540814, acc.: 74.22%] [G loss: 0.741811]\n",
      "epoch:20 step:18986 [D loss: 0.529713, acc.: 73.44%] [G loss: 0.689782]\n",
      "epoch:20 step:18987 [D loss: 0.491858, acc.: 75.78%] [G loss: 0.725443]\n",
      "epoch:20 step:18988 [D loss: 0.498536, acc.: 78.12%] [G loss: 0.810555]\n",
      "epoch:20 step:18989 [D loss: 0.535395, acc.: 73.44%] [G loss: 0.622877]\n",
      "epoch:20 step:18990 [D loss: 0.631393, acc.: 63.28%] [G loss: 0.687505]\n",
      "epoch:20 step:18991 [D loss: 0.678729, acc.: 60.94%] [G loss: 0.784124]\n",
      "epoch:20 step:18992 [D loss: 0.551229, acc.: 71.88%] [G loss: 0.582807]\n",
      "epoch:20 step:18993 [D loss: 0.585792, acc.: 66.41%] [G loss: 0.499472]\n",
      "epoch:20 step:18994 [D loss: 0.510492, acc.: 68.75%] [G loss: 0.559080]\n",
      "epoch:20 step:18995 [D loss: 0.538452, acc.: 70.31%] [G loss: 0.637057]\n",
      "epoch:20 step:18996 [D loss: 0.577059, acc.: 67.97%] [G loss: 0.612957]\n",
      "epoch:20 step:18997 [D loss: 0.581878, acc.: 62.50%] [G loss: 0.589065]\n",
      "epoch:20 step:18998 [D loss: 0.556539, acc.: 66.41%] [G loss: 0.663076]\n",
      "epoch:20 step:18999 [D loss: 0.566066, acc.: 67.97%] [G loss: 0.525435]\n",
      "epoch:20 step:19000 [D loss: 0.612198, acc.: 63.28%] [G loss: 0.501121]\n",
      "##############\n",
      "[3.03286115 0.98680663 6.09932322 4.98930955 3.67561849 5.69608667\n",
      " 4.44943947 5.09015623 4.75243956 4.17570767]\n",
      "##########\n",
      "epoch:20 step:19001 [D loss: 0.533804, acc.: 71.88%] [G loss: 0.516634]\n",
      "epoch:20 step:19002 [D loss: 0.522682, acc.: 67.19%] [G loss: 0.513022]\n",
      "epoch:20 step:19003 [D loss: 0.585979, acc.: 68.75%] [G loss: 0.535910]\n",
      "epoch:20 step:19004 [D loss: 0.527519, acc.: 72.66%] [G loss: 0.638032]\n",
      "epoch:20 step:19005 [D loss: 0.538066, acc.: 71.88%] [G loss: 0.580758]\n",
      "epoch:20 step:19006 [D loss: 0.532882, acc.: 72.66%] [G loss: 0.636622]\n",
      "epoch:20 step:19007 [D loss: 0.566550, acc.: 71.09%] [G loss: 0.539938]\n",
      "epoch:20 step:19008 [D loss: 0.539765, acc.: 66.41%] [G loss: 0.590466]\n",
      "epoch:20 step:19009 [D loss: 0.570764, acc.: 67.97%] [G loss: 0.616631]\n",
      "epoch:20 step:19010 [D loss: 0.507804, acc.: 75.00%] [G loss: 0.596027]\n",
      "epoch:20 step:19011 [D loss: 0.527856, acc.: 66.41%] [G loss: 0.729184]\n",
      "epoch:20 step:19012 [D loss: 0.538359, acc.: 71.88%] [G loss: 0.631940]\n",
      "epoch:20 step:19013 [D loss: 0.506432, acc.: 69.53%] [G loss: 0.598601]\n",
      "epoch:20 step:19014 [D loss: 0.510064, acc.: 74.22%] [G loss: 0.595036]\n",
      "epoch:20 step:19015 [D loss: 0.528918, acc.: 71.09%] [G loss: 0.670092]\n",
      "epoch:20 step:19016 [D loss: 0.497583, acc.: 71.09%] [G loss: 0.635350]\n",
      "epoch:20 step:19017 [D loss: 0.707263, acc.: 58.59%] [G loss: 0.586054]\n",
      "epoch:20 step:19018 [D loss: 0.581264, acc.: 70.31%] [G loss: 0.467179]\n",
      "epoch:20 step:19019 [D loss: 0.568828, acc.: 68.75%] [G loss: 0.546526]\n",
      "epoch:20 step:19020 [D loss: 0.521023, acc.: 72.66%] [G loss: 0.624356]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19021 [D loss: 0.545515, acc.: 70.31%] [G loss: 0.524959]\n",
      "epoch:20 step:19022 [D loss: 0.515958, acc.: 75.78%] [G loss: 0.545851]\n",
      "epoch:20 step:19023 [D loss: 0.489105, acc.: 73.44%] [G loss: 0.567831]\n",
      "epoch:20 step:19024 [D loss: 0.498956, acc.: 77.34%] [G loss: 0.615580]\n",
      "epoch:20 step:19025 [D loss: 0.486809, acc.: 76.56%] [G loss: 0.612361]\n",
      "epoch:20 step:19026 [D loss: 0.533043, acc.: 67.97%] [G loss: 0.624054]\n",
      "epoch:20 step:19027 [D loss: 0.594263, acc.: 63.28%] [G loss: 0.785970]\n",
      "epoch:20 step:19028 [D loss: 0.558254, acc.: 67.97%] [G loss: 0.743903]\n",
      "epoch:20 step:19029 [D loss: 0.514825, acc.: 71.09%] [G loss: 0.687205]\n",
      "epoch:20 step:19030 [D loss: 0.561800, acc.: 67.97%] [G loss: 0.614832]\n",
      "epoch:20 step:19031 [D loss: 0.552849, acc.: 67.19%] [G loss: 0.550833]\n",
      "epoch:20 step:19032 [D loss: 0.512627, acc.: 73.44%] [G loss: 0.478465]\n",
      "epoch:20 step:19033 [D loss: 0.531936, acc.: 71.88%] [G loss: 0.564239]\n",
      "epoch:20 step:19034 [D loss: 0.588434, acc.: 66.41%] [G loss: 0.535453]\n",
      "epoch:20 step:19035 [D loss: 0.586048, acc.: 64.06%] [G loss: 0.500476]\n",
      "epoch:20 step:19036 [D loss: 0.468124, acc.: 73.44%] [G loss: 0.729394]\n",
      "epoch:20 step:19037 [D loss: 0.539404, acc.: 72.66%] [G loss: 0.754350]\n",
      "epoch:20 step:19038 [D loss: 0.507989, acc.: 76.56%] [G loss: 0.754442]\n",
      "epoch:20 step:19039 [D loss: 0.465270, acc.: 75.78%] [G loss: 0.754317]\n",
      "epoch:20 step:19040 [D loss: 0.509665, acc.: 72.66%] [G loss: 0.751772]\n",
      "epoch:20 step:19041 [D loss: 0.662998, acc.: 61.72%] [G loss: 0.590829]\n",
      "epoch:20 step:19042 [D loss: 0.526856, acc.: 74.22%] [G loss: 0.569878]\n",
      "epoch:20 step:19043 [D loss: 0.525903, acc.: 72.66%] [G loss: 0.595033]\n",
      "epoch:20 step:19044 [D loss: 0.516159, acc.: 73.44%] [G loss: 0.594370]\n",
      "epoch:20 step:19045 [D loss: 0.483891, acc.: 73.44%] [G loss: 0.697659]\n",
      "epoch:20 step:19046 [D loss: 0.516022, acc.: 72.66%] [G loss: 0.728867]\n",
      "epoch:20 step:19047 [D loss: 0.519488, acc.: 76.56%] [G loss: 0.633913]\n",
      "epoch:20 step:19048 [D loss: 0.610379, acc.: 62.50%] [G loss: 0.543082]\n",
      "epoch:20 step:19049 [D loss: 0.492791, acc.: 71.88%] [G loss: 0.668772]\n",
      "epoch:20 step:19050 [D loss: 0.513821, acc.: 75.78%] [G loss: 0.720238]\n",
      "epoch:20 step:19051 [D loss: 0.466975, acc.: 79.69%] [G loss: 0.723740]\n",
      "epoch:20 step:19052 [D loss: 0.509971, acc.: 74.22%] [G loss: 0.718490]\n",
      "epoch:20 step:19053 [D loss: 0.517693, acc.: 75.00%] [G loss: 0.872729]\n",
      "epoch:20 step:19054 [D loss: 0.407261, acc.: 83.59%] [G loss: 1.022792]\n",
      "epoch:20 step:19055 [D loss: 0.474296, acc.: 75.00%] [G loss: 1.152294]\n",
      "epoch:20 step:19056 [D loss: 0.646797, acc.: 66.41%] [G loss: 0.676674]\n",
      "epoch:20 step:19057 [D loss: 0.632156, acc.: 62.50%] [G loss: 0.606795]\n",
      "epoch:20 step:19058 [D loss: 0.558598, acc.: 67.19%] [G loss: 0.598299]\n",
      "epoch:20 step:19059 [D loss: 0.570498, acc.: 66.41%] [G loss: 0.491481]\n",
      "epoch:20 step:19060 [D loss: 0.587907, acc.: 63.28%] [G loss: 0.594967]\n",
      "epoch:20 step:19061 [D loss: 0.462610, acc.: 77.34%] [G loss: 0.694497]\n",
      "epoch:20 step:19062 [D loss: 0.597571, acc.: 67.97%] [G loss: 0.546664]\n",
      "epoch:20 step:19063 [D loss: 0.588459, acc.: 70.31%] [G loss: 0.593213]\n",
      "epoch:20 step:19064 [D loss: 0.528844, acc.: 71.88%] [G loss: 0.560913]\n",
      "epoch:20 step:19065 [D loss: 0.536334, acc.: 69.53%] [G loss: 0.685905]\n",
      "epoch:20 step:19066 [D loss: 0.455802, acc.: 77.34%] [G loss: 0.639357]\n",
      "epoch:20 step:19067 [D loss: 0.526651, acc.: 72.66%] [G loss: 0.769558]\n",
      "epoch:20 step:19068 [D loss: 0.452876, acc.: 79.69%] [G loss: 0.698619]\n",
      "epoch:20 step:19069 [D loss: 0.489728, acc.: 74.22%] [G loss: 0.733190]\n",
      "epoch:20 step:19070 [D loss: 0.561113, acc.: 66.41%] [G loss: 0.567000]\n",
      "epoch:20 step:19071 [D loss: 0.544288, acc.: 72.66%] [G loss: 0.614904]\n",
      "epoch:20 step:19072 [D loss: 0.503919, acc.: 71.88%] [G loss: 0.655265]\n",
      "epoch:20 step:19073 [D loss: 0.483157, acc.: 73.44%] [G loss: 0.655938]\n",
      "epoch:20 step:19074 [D loss: 0.496208, acc.: 75.00%] [G loss: 0.759826]\n",
      "epoch:20 step:19075 [D loss: 0.505840, acc.: 77.34%] [G loss: 0.612651]\n",
      "epoch:20 step:19076 [D loss: 0.587244, acc.: 73.44%] [G loss: 0.609433]\n",
      "epoch:20 step:19077 [D loss: 0.522458, acc.: 72.66%] [G loss: 0.757319]\n",
      "epoch:20 step:19078 [D loss: 0.472815, acc.: 78.12%] [G loss: 0.806743]\n",
      "epoch:20 step:19079 [D loss: 0.556118, acc.: 67.97%] [G loss: 0.823217]\n",
      "epoch:20 step:19080 [D loss: 0.509833, acc.: 73.44%] [G loss: 0.794563]\n",
      "epoch:20 step:19081 [D loss: 0.622278, acc.: 67.97%] [G loss: 0.830590]\n",
      "epoch:20 step:19082 [D loss: 0.666416, acc.: 59.38%] [G loss: 0.592609]\n",
      "epoch:20 step:19083 [D loss: 0.504588, acc.: 71.09%] [G loss: 0.851062]\n",
      "epoch:20 step:19084 [D loss: 0.440458, acc.: 80.47%] [G loss: 0.972109]\n",
      "epoch:20 step:19085 [D loss: 0.563395, acc.: 74.22%] [G loss: 0.748284]\n",
      "epoch:20 step:19086 [D loss: 0.475396, acc.: 78.91%] [G loss: 0.631516]\n",
      "epoch:20 step:19087 [D loss: 0.476168, acc.: 76.56%] [G loss: 0.862183]\n",
      "epoch:20 step:19088 [D loss: 0.620803, acc.: 70.31%] [G loss: 0.773387]\n",
      "epoch:20 step:19089 [D loss: 0.735739, acc.: 57.81%] [G loss: 0.653203]\n",
      "epoch:20 step:19090 [D loss: 0.496457, acc.: 74.22%] [G loss: 0.726118]\n",
      "epoch:20 step:19091 [D loss: 0.509783, acc.: 70.31%] [G loss: 0.683988]\n",
      "epoch:20 step:19092 [D loss: 0.628230, acc.: 62.50%] [G loss: 0.763830]\n",
      "epoch:20 step:19093 [D loss: 0.566313, acc.: 70.31%] [G loss: 0.604919]\n",
      "epoch:20 step:19094 [D loss: 0.430134, acc.: 79.69%] [G loss: 0.828613]\n",
      "epoch:20 step:19095 [D loss: 0.528133, acc.: 74.22%] [G loss: 0.852282]\n",
      "epoch:20 step:19096 [D loss: 0.561842, acc.: 70.31%] [G loss: 0.742046]\n",
      "epoch:20 step:19097 [D loss: 0.461470, acc.: 77.34%] [G loss: 0.563854]\n",
      "epoch:20 step:19098 [D loss: 0.477381, acc.: 77.34%] [G loss: 0.867402]\n",
      "epoch:20 step:19099 [D loss: 0.518550, acc.: 74.22%] [G loss: 0.880222]\n",
      "epoch:20 step:19100 [D loss: 0.504884, acc.: 72.66%] [G loss: 0.750034]\n",
      "epoch:20 step:19101 [D loss: 0.467239, acc.: 80.47%] [G loss: 0.753904]\n",
      "epoch:20 step:19102 [D loss: 0.543343, acc.: 67.19%] [G loss: 0.867883]\n",
      "epoch:20 step:19103 [D loss: 0.567170, acc.: 64.84%] [G loss: 0.569774]\n",
      "epoch:20 step:19104 [D loss: 0.514487, acc.: 71.88%] [G loss: 0.731574]\n",
      "epoch:20 step:19105 [D loss: 0.613767, acc.: 61.72%] [G loss: 0.667554]\n",
      "epoch:20 step:19106 [D loss: 0.548091, acc.: 69.53%] [G loss: 0.682675]\n",
      "epoch:20 step:19107 [D loss: 0.596235, acc.: 67.19%] [G loss: 0.691704]\n",
      "epoch:20 step:19108 [D loss: 0.534920, acc.: 68.75%] [G loss: 0.623761]\n",
      "epoch:20 step:19109 [D loss: 0.503224, acc.: 75.00%] [G loss: 0.633331]\n",
      "epoch:20 step:19110 [D loss: 0.544354, acc.: 75.00%] [G loss: 0.712291]\n",
      "epoch:20 step:19111 [D loss: 0.526498, acc.: 71.09%] [G loss: 0.823506]\n",
      "epoch:20 step:19112 [D loss: 0.497248, acc.: 75.78%] [G loss: 0.851233]\n",
      "epoch:20 step:19113 [D loss: 0.545495, acc.: 70.31%] [G loss: 0.758627]\n",
      "epoch:20 step:19114 [D loss: 0.436392, acc.: 79.69%] [G loss: 0.731673]\n",
      "epoch:20 step:19115 [D loss: 0.547414, acc.: 75.00%] [G loss: 0.674289]\n",
      "epoch:20 step:19116 [D loss: 0.716041, acc.: 57.81%] [G loss: 0.622748]\n",
      "epoch:20 step:19117 [D loss: 0.604566, acc.: 64.84%] [G loss: 0.417980]\n",
      "epoch:20 step:19118 [D loss: 0.527448, acc.: 71.88%] [G loss: 0.614338]\n",
      "epoch:20 step:19119 [D loss: 0.603420, acc.: 63.28%] [G loss: 0.562074]\n",
      "epoch:20 step:19120 [D loss: 0.514802, acc.: 78.12%] [G loss: 0.657012]\n",
      "epoch:20 step:19121 [D loss: 0.464741, acc.: 79.69%] [G loss: 0.595372]\n",
      "epoch:20 step:19122 [D loss: 0.526013, acc.: 70.31%] [G loss: 0.658507]\n",
      "epoch:20 step:19123 [D loss: 0.531712, acc.: 67.19%] [G loss: 0.662729]\n",
      "epoch:20 step:19124 [D loss: 0.523131, acc.: 72.66%] [G loss: 0.651140]\n",
      "epoch:20 step:19125 [D loss: 0.506636, acc.: 69.53%] [G loss: 0.767577]\n",
      "epoch:20 step:19126 [D loss: 0.574141, acc.: 64.84%] [G loss: 0.579922]\n",
      "epoch:20 step:19127 [D loss: 0.527108, acc.: 74.22%] [G loss: 0.678400]\n",
      "epoch:20 step:19128 [D loss: 0.550436, acc.: 73.44%] [G loss: 0.678970]\n",
      "epoch:20 step:19129 [D loss: 0.542194, acc.: 71.09%] [G loss: 0.625524]\n",
      "epoch:20 step:19130 [D loss: 0.568262, acc.: 68.75%] [G loss: 0.548476]\n",
      "epoch:20 step:19131 [D loss: 0.547185, acc.: 69.53%] [G loss: 0.751744]\n",
      "epoch:20 step:19132 [D loss: 0.519552, acc.: 73.44%] [G loss: 0.597934]\n",
      "epoch:20 step:19133 [D loss: 0.572098, acc.: 71.09%] [G loss: 0.668564]\n",
      "epoch:20 step:19134 [D loss: 0.580783, acc.: 65.62%] [G loss: 0.536978]\n",
      "epoch:20 step:19135 [D loss: 0.517080, acc.: 69.53%] [G loss: 0.717543]\n",
      "epoch:20 step:19136 [D loss: 0.583495, acc.: 67.97%] [G loss: 0.623171]\n",
      "epoch:20 step:19137 [D loss: 0.561272, acc.: 66.41%] [G loss: 0.560503]\n",
      "epoch:20 step:19138 [D loss: 0.489160, acc.: 78.12%] [G loss: 0.721683]\n",
      "epoch:20 step:19139 [D loss: 0.506267, acc.: 72.66%] [G loss: 0.940374]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19140 [D loss: 0.611621, acc.: 63.28%] [G loss: 0.849962]\n",
      "epoch:20 step:19141 [D loss: 0.614380, acc.: 61.72%] [G loss: 0.450861]\n",
      "epoch:20 step:19142 [D loss: 0.548952, acc.: 69.53%] [G loss: 0.681406]\n",
      "epoch:20 step:19143 [D loss: 0.564809, acc.: 69.53%] [G loss: 0.677015]\n",
      "epoch:20 step:19144 [D loss: 0.614456, acc.: 60.16%] [G loss: 0.690942]\n",
      "epoch:20 step:19145 [D loss: 0.536943, acc.: 67.97%] [G loss: 0.620367]\n",
      "epoch:20 step:19146 [D loss: 0.508157, acc.: 78.91%] [G loss: 0.796709]\n",
      "epoch:20 step:19147 [D loss: 0.606353, acc.: 65.62%] [G loss: 0.556661]\n",
      "epoch:20 step:19148 [D loss: 0.498238, acc.: 78.12%] [G loss: 0.825028]\n",
      "epoch:20 step:19149 [D loss: 0.544113, acc.: 71.09%] [G loss: 0.649198]\n",
      "epoch:20 step:19150 [D loss: 0.577307, acc.: 64.06%] [G loss: 0.547402]\n",
      "epoch:20 step:19151 [D loss: 0.612204, acc.: 60.16%] [G loss: 0.598125]\n",
      "epoch:20 step:19152 [D loss: 0.583743, acc.: 65.62%] [G loss: 0.546451]\n",
      "epoch:20 step:19153 [D loss: 0.559821, acc.: 69.53%] [G loss: 0.529027]\n",
      "epoch:20 step:19154 [D loss: 0.556624, acc.: 71.09%] [G loss: 0.535628]\n",
      "epoch:20 step:19155 [D loss: 0.570833, acc.: 66.41%] [G loss: 0.487121]\n",
      "epoch:20 step:19156 [D loss: 0.486748, acc.: 77.34%] [G loss: 0.746906]\n",
      "epoch:20 step:19157 [D loss: 0.519717, acc.: 75.78%] [G loss: 0.583595]\n",
      "epoch:20 step:19158 [D loss: 0.612569, acc.: 61.72%] [G loss: 0.714274]\n",
      "epoch:20 step:19159 [D loss: 0.552520, acc.: 70.31%] [G loss: 0.690089]\n",
      "epoch:20 step:19160 [D loss: 0.595401, acc.: 62.50%] [G loss: 0.729235]\n",
      "epoch:20 step:19161 [D loss: 0.595671, acc.: 63.28%] [G loss: 0.623328]\n",
      "epoch:20 step:19162 [D loss: 0.613567, acc.: 67.97%] [G loss: 0.528012]\n",
      "epoch:20 step:19163 [D loss: 0.535468, acc.: 67.97%] [G loss: 0.729185]\n",
      "epoch:20 step:19164 [D loss: 0.546553, acc.: 67.97%] [G loss: 0.645423]\n",
      "epoch:20 step:19165 [D loss: 0.495830, acc.: 74.22%] [G loss: 0.742000]\n",
      "epoch:20 step:19166 [D loss: 0.456216, acc.: 80.47%] [G loss: 0.645771]\n",
      "epoch:20 step:19167 [D loss: 0.466453, acc.: 77.34%] [G loss: 0.626441]\n",
      "epoch:20 step:19168 [D loss: 0.530865, acc.: 71.09%] [G loss: 0.865042]\n",
      "epoch:20 step:19169 [D loss: 0.425155, acc.: 81.25%] [G loss: 0.865229]\n",
      "epoch:20 step:19170 [D loss: 0.551627, acc.: 71.09%] [G loss: 0.844897]\n",
      "epoch:20 step:19171 [D loss: 0.512978, acc.: 74.22%] [G loss: 0.707069]\n",
      "epoch:20 step:19172 [D loss: 0.583134, acc.: 70.31%] [G loss: 0.686727]\n",
      "epoch:20 step:19173 [D loss: 0.560767, acc.: 70.31%] [G loss: 0.686881]\n",
      "epoch:20 step:19174 [D loss: 0.525711, acc.: 71.88%] [G loss: 0.550259]\n",
      "epoch:20 step:19175 [D loss: 0.522873, acc.: 75.78%] [G loss: 0.673748]\n",
      "epoch:20 step:19176 [D loss: 0.469376, acc.: 79.69%] [G loss: 0.677411]\n",
      "epoch:20 step:19177 [D loss: 0.622247, acc.: 63.28%] [G loss: 0.685362]\n",
      "epoch:20 step:19178 [D loss: 0.546759, acc.: 71.88%] [G loss: 0.556772]\n",
      "epoch:20 step:19179 [D loss: 0.517408, acc.: 72.66%] [G loss: 0.643512]\n",
      "epoch:20 step:19180 [D loss: 0.523689, acc.: 72.66%] [G loss: 0.589817]\n",
      "epoch:20 step:19181 [D loss: 0.556321, acc.: 66.41%] [G loss: 0.532231]\n",
      "epoch:20 step:19182 [D loss: 0.523672, acc.: 67.97%] [G loss: 0.768523]\n",
      "epoch:20 step:19183 [D loss: 0.523443, acc.: 74.22%] [G loss: 0.544872]\n",
      "epoch:20 step:19184 [D loss: 0.536416, acc.: 71.09%] [G loss: 0.540603]\n",
      "epoch:20 step:19185 [D loss: 0.528858, acc.: 69.53%] [G loss: 0.753880]\n",
      "epoch:20 step:19186 [D loss: 0.521369, acc.: 72.66%] [G loss: 0.722369]\n",
      "epoch:20 step:19187 [D loss: 0.543923, acc.: 64.84%] [G loss: 0.726879]\n",
      "epoch:20 step:19188 [D loss: 0.542555, acc.: 69.53%] [G loss: 0.625436]\n",
      "epoch:20 step:19189 [D loss: 0.532223, acc.: 74.22%] [G loss: 0.900838]\n",
      "epoch:20 step:19190 [D loss: 0.461729, acc.: 78.91%] [G loss: 0.770359]\n",
      "epoch:20 step:19191 [D loss: 0.430610, acc.: 77.34%] [G loss: 0.965347]\n",
      "epoch:20 step:19192 [D loss: 0.480043, acc.: 78.12%] [G loss: 1.059508]\n",
      "epoch:20 step:19193 [D loss: 0.517413, acc.: 74.22%] [G loss: 0.833144]\n",
      "epoch:20 step:19194 [D loss: 0.578575, acc.: 66.41%] [G loss: 0.759412]\n",
      "epoch:20 step:19195 [D loss: 0.611391, acc.: 60.16%] [G loss: 0.564125]\n",
      "epoch:20 step:19196 [D loss: 0.576598, acc.: 69.53%] [G loss: 0.787198]\n",
      "epoch:20 step:19197 [D loss: 0.487544, acc.: 78.12%] [G loss: 0.762100]\n",
      "epoch:20 step:19198 [D loss: 0.623248, acc.: 63.28%] [G loss: 0.610148]\n",
      "epoch:20 step:19199 [D loss: 0.505214, acc.: 72.66%] [G loss: 0.671490]\n",
      "epoch:20 step:19200 [D loss: 0.507133, acc.: 73.44%] [G loss: 0.714597]\n",
      "##############\n",
      "[2.91148567 1.28281634 6.30147824 4.78691283 3.91571505 5.82217376\n",
      " 4.5262853  4.91430944 4.58535183 3.97267048]\n",
      "##########\n",
      "epoch:20 step:19201 [D loss: 0.500553, acc.: 74.22%] [G loss: 0.504187]\n",
      "epoch:20 step:19202 [D loss: 0.553401, acc.: 69.53%] [G loss: 0.557721]\n",
      "epoch:20 step:19203 [D loss: 0.511971, acc.: 67.97%] [G loss: 0.632140]\n",
      "epoch:20 step:19204 [D loss: 0.517846, acc.: 75.00%] [G loss: 0.591698]\n",
      "epoch:20 step:19205 [D loss: 0.570628, acc.: 67.97%] [G loss: 0.637548]\n",
      "epoch:20 step:19206 [D loss: 0.561413, acc.: 67.97%] [G loss: 0.579548]\n",
      "epoch:20 step:19207 [D loss: 0.542571, acc.: 68.75%] [G loss: 0.632295]\n",
      "epoch:20 step:19208 [D loss: 0.562532, acc.: 71.09%] [G loss: 0.723703]\n",
      "epoch:20 step:19209 [D loss: 0.546522, acc.: 67.19%] [G loss: 0.788384]\n",
      "epoch:20 step:19210 [D loss: 0.473972, acc.: 79.69%] [G loss: 0.729173]\n",
      "epoch:20 step:19211 [D loss: 0.471108, acc.: 74.22%] [G loss: 0.821602]\n",
      "epoch:20 step:19212 [D loss: 0.476932, acc.: 78.12%] [G loss: 0.975053]\n",
      "epoch:20 step:19213 [D loss: 0.621239, acc.: 64.06%] [G loss: 0.631451]\n",
      "epoch:20 step:19214 [D loss: 0.590655, acc.: 67.19%] [G loss: 0.726379]\n",
      "epoch:20 step:19215 [D loss: 0.429834, acc.: 79.69%] [G loss: 0.917743]\n",
      "epoch:20 step:19216 [D loss: 0.503933, acc.: 77.34%] [G loss: 0.740589]\n",
      "epoch:20 step:19217 [D loss: 0.641054, acc.: 67.19%] [G loss: 0.559651]\n",
      "epoch:20 step:19218 [D loss: 0.570796, acc.: 64.84%] [G loss: 0.599438]\n",
      "epoch:20 step:19219 [D loss: 0.510970, acc.: 76.56%] [G loss: 0.679776]\n",
      "epoch:20 step:19220 [D loss: 0.557778, acc.: 72.66%] [G loss: 0.587241]\n",
      "epoch:20 step:19221 [D loss: 0.469854, acc.: 80.47%] [G loss: 0.608407]\n",
      "epoch:20 step:19222 [D loss: 0.624344, acc.: 69.53%] [G loss: 0.639122]\n",
      "epoch:20 step:19223 [D loss: 0.525798, acc.: 68.75%] [G loss: 0.579572]\n",
      "epoch:20 step:19224 [D loss: 0.487323, acc.: 76.56%] [G loss: 0.748586]\n",
      "epoch:20 step:19225 [D loss: 0.526415, acc.: 71.88%] [G loss: 0.744234]\n",
      "epoch:20 step:19226 [D loss: 0.518179, acc.: 73.44%] [G loss: 0.680412]\n",
      "epoch:20 step:19227 [D loss: 0.557716, acc.: 64.84%] [G loss: 0.650409]\n",
      "epoch:20 step:19228 [D loss: 0.469569, acc.: 73.44%] [G loss: 0.701952]\n",
      "epoch:20 step:19229 [D loss: 0.535536, acc.: 72.66%] [G loss: 0.538757]\n",
      "epoch:20 step:19230 [D loss: 0.628693, acc.: 60.94%] [G loss: 0.517225]\n",
      "epoch:20 step:19231 [D loss: 0.582096, acc.: 67.19%] [G loss: 0.649725]\n",
      "epoch:20 step:19232 [D loss: 0.580191, acc.: 66.41%] [G loss: 0.511317]\n",
      "epoch:20 step:19233 [D loss: 0.554723, acc.: 69.53%] [G loss: 0.526283]\n",
      "epoch:20 step:19234 [D loss: 0.562036, acc.: 69.53%] [G loss: 0.674530]\n",
      "epoch:20 step:19235 [D loss: 0.492812, acc.: 73.44%] [G loss: 0.759396]\n",
      "epoch:20 step:19236 [D loss: 0.584380, acc.: 70.31%] [G loss: 0.438111]\n",
      "epoch:20 step:19237 [D loss: 0.570847, acc.: 70.31%] [G loss: 0.657101]\n",
      "epoch:20 step:19238 [D loss: 0.519169, acc.: 73.44%] [G loss: 0.757512]\n",
      "epoch:20 step:19239 [D loss: 0.508961, acc.: 71.09%] [G loss: 0.970577]\n",
      "epoch:20 step:19240 [D loss: 0.535870, acc.: 73.44%] [G loss: 0.815916]\n",
      "epoch:20 step:19241 [D loss: 0.596122, acc.: 67.97%] [G loss: 0.689581]\n",
      "epoch:20 step:19242 [D loss: 0.632582, acc.: 62.50%] [G loss: 0.482480]\n",
      "epoch:20 step:19243 [D loss: 0.504634, acc.: 70.31%] [G loss: 0.639914]\n",
      "epoch:20 step:19244 [D loss: 0.449694, acc.: 83.59%] [G loss: 0.596327]\n",
      "epoch:20 step:19245 [D loss: 0.515036, acc.: 72.66%] [G loss: 0.629625]\n",
      "epoch:20 step:19246 [D loss: 0.516748, acc.: 72.66%] [G loss: 0.737267]\n",
      "epoch:20 step:19247 [D loss: 0.493582, acc.: 75.78%] [G loss: 0.905558]\n",
      "epoch:20 step:19248 [D loss: 0.398961, acc.: 84.38%] [G loss: 0.895854]\n",
      "epoch:20 step:19249 [D loss: 0.504651, acc.: 75.78%] [G loss: 0.867978]\n",
      "epoch:20 step:19250 [D loss: 0.680154, acc.: 64.84%] [G loss: 0.628414]\n",
      "epoch:20 step:19251 [D loss: 0.623380, acc.: 63.28%] [G loss: 0.576011]\n",
      "epoch:20 step:19252 [D loss: 0.567391, acc.: 70.31%] [G loss: 0.473966]\n",
      "epoch:20 step:19253 [D loss: 0.548327, acc.: 65.62%] [G loss: 0.522213]\n",
      "epoch:20 step:19254 [D loss: 0.455390, acc.: 79.69%] [G loss: 0.720785]\n",
      "epoch:20 step:19255 [D loss: 0.533794, acc.: 75.78%] [G loss: 0.620740]\n",
      "epoch:20 step:19256 [D loss: 0.448653, acc.: 80.47%] [G loss: 0.710790]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19257 [D loss: 0.521466, acc.: 73.44%] [G loss: 0.802023]\n",
      "epoch:20 step:19258 [D loss: 0.519489, acc.: 71.09%] [G loss: 0.707862]\n",
      "epoch:20 step:19259 [D loss: 0.444411, acc.: 78.91%] [G loss: 0.676062]\n",
      "epoch:20 step:19260 [D loss: 0.538212, acc.: 67.19%] [G loss: 0.639185]\n",
      "epoch:20 step:19261 [D loss: 0.544368, acc.: 68.75%] [G loss: 0.836924]\n",
      "epoch:20 step:19262 [D loss: 0.477651, acc.: 80.47%] [G loss: 0.983996]\n",
      "epoch:20 step:19263 [D loss: 0.486467, acc.: 77.34%] [G loss: 0.746278]\n",
      "epoch:20 step:19264 [D loss: 0.574534, acc.: 69.53%] [G loss: 0.715877]\n",
      "epoch:20 step:19265 [D loss: 0.588168, acc.: 67.19%] [G loss: 0.566881]\n",
      "epoch:20 step:19266 [D loss: 0.557237, acc.: 70.31%] [G loss: 0.651479]\n",
      "epoch:20 step:19267 [D loss: 0.564740, acc.: 64.84%] [G loss: 0.585196]\n",
      "epoch:20 step:19268 [D loss: 0.715732, acc.: 55.47%] [G loss: 0.666068]\n",
      "epoch:20 step:19269 [D loss: 0.607528, acc.: 58.59%] [G loss: 0.829798]\n",
      "epoch:20 step:19270 [D loss: 0.532712, acc.: 70.31%] [G loss: 0.860242]\n",
      "epoch:20 step:19271 [D loss: 0.559768, acc.: 67.19%] [G loss: 0.642698]\n",
      "epoch:20 step:19272 [D loss: 0.546882, acc.: 70.31%] [G loss: 0.796335]\n",
      "epoch:20 step:19273 [D loss: 0.490302, acc.: 74.22%] [G loss: 0.713964]\n",
      "epoch:20 step:19274 [D loss: 0.499032, acc.: 72.66%] [G loss: 0.590656]\n",
      "epoch:20 step:19275 [D loss: 0.650891, acc.: 59.38%] [G loss: 0.487514]\n",
      "epoch:20 step:19276 [D loss: 0.489243, acc.: 68.75%] [G loss: 0.772069]\n",
      "epoch:20 step:19277 [D loss: 0.578913, acc.: 67.19%] [G loss: 0.560778]\n",
      "epoch:20 step:19278 [D loss: 0.531827, acc.: 71.09%] [G loss: 0.727996]\n",
      "epoch:20 step:19279 [D loss: 0.507983, acc.: 75.00%] [G loss: 0.743739]\n",
      "epoch:20 step:19280 [D loss: 0.507901, acc.: 72.66%] [G loss: 0.583568]\n",
      "epoch:20 step:19281 [D loss: 0.552884, acc.: 69.53%] [G loss: 0.620595]\n",
      "epoch:20 step:19282 [D loss: 0.620246, acc.: 64.84%] [G loss: 0.528137]\n",
      "epoch:20 step:19283 [D loss: 0.552551, acc.: 70.31%] [G loss: 0.639611]\n",
      "epoch:20 step:19284 [D loss: 0.524018, acc.: 69.53%] [G loss: 0.517923]\n",
      "epoch:20 step:19285 [D loss: 0.496148, acc.: 72.66%] [G loss: 0.619370]\n",
      "epoch:20 step:19286 [D loss: 0.529227, acc.: 70.31%] [G loss: 0.689752]\n",
      "epoch:20 step:19287 [D loss: 0.535767, acc.: 71.09%] [G loss: 0.828967]\n",
      "epoch:20 step:19288 [D loss: 0.510141, acc.: 71.09%] [G loss: 0.954292]\n",
      "epoch:20 step:19289 [D loss: 0.542727, acc.: 71.09%] [G loss: 0.859212]\n",
      "epoch:20 step:19290 [D loss: 0.496790, acc.: 74.22%] [G loss: 0.852158]\n",
      "epoch:20 step:19291 [D loss: 0.491323, acc.: 72.66%] [G loss: 0.701076]\n",
      "epoch:20 step:19292 [D loss: 0.462771, acc.: 78.91%] [G loss: 0.802695]\n",
      "epoch:20 step:19293 [D loss: 0.594318, acc.: 68.75%] [G loss: 0.728963]\n",
      "epoch:20 step:19294 [D loss: 0.454044, acc.: 78.12%] [G loss: 0.641260]\n",
      "epoch:20 step:19295 [D loss: 0.466850, acc.: 77.34%] [G loss: 0.635943]\n",
      "epoch:20 step:19296 [D loss: 0.575316, acc.: 65.62%] [G loss: 0.766676]\n",
      "epoch:20 step:19297 [D loss: 0.491819, acc.: 72.66%] [G loss: 0.772213]\n",
      "epoch:20 step:19298 [D loss: 0.478766, acc.: 72.66%] [G loss: 0.793643]\n",
      "epoch:20 step:19299 [D loss: 0.574127, acc.: 65.62%] [G loss: 0.687118]\n",
      "epoch:20 step:19300 [D loss: 0.568395, acc.: 67.97%] [G loss: 0.800443]\n",
      "epoch:20 step:19301 [D loss: 0.538137, acc.: 71.88%] [G loss: 0.684369]\n",
      "epoch:20 step:19302 [D loss: 0.541935, acc.: 72.66%] [G loss: 0.620118]\n",
      "epoch:20 step:19303 [D loss: 0.559345, acc.: 67.97%] [G loss: 0.595820]\n",
      "epoch:20 step:19304 [D loss: 0.493286, acc.: 77.34%] [G loss: 0.654860]\n",
      "epoch:20 step:19305 [D loss: 0.535506, acc.: 76.56%] [G loss: 0.617072]\n",
      "epoch:20 step:19306 [D loss: 0.758579, acc.: 51.56%] [G loss: 0.413111]\n",
      "epoch:20 step:19307 [D loss: 0.499934, acc.: 72.66%] [G loss: 0.519708]\n",
      "epoch:20 step:19308 [D loss: 0.468120, acc.: 79.69%] [G loss: 0.814591]\n",
      "epoch:20 step:19309 [D loss: 0.525666, acc.: 75.00%] [G loss: 0.610492]\n",
      "epoch:20 step:19310 [D loss: 0.497999, acc.: 73.44%] [G loss: 0.859742]\n",
      "epoch:20 step:19311 [D loss: 0.513487, acc.: 74.22%] [G loss: 0.733364]\n",
      "epoch:20 step:19312 [D loss: 0.601443, acc.: 63.28%] [G loss: 0.684565]\n",
      "epoch:20 step:19313 [D loss: 0.528049, acc.: 74.22%] [G loss: 0.756160]\n",
      "epoch:20 step:19314 [D loss: 0.477865, acc.: 76.56%] [G loss: 0.852617]\n",
      "epoch:20 step:19315 [D loss: 0.472832, acc.: 76.56%] [G loss: 0.963047]\n",
      "epoch:20 step:19316 [D loss: 0.592036, acc.: 67.97%] [G loss: 0.811612]\n",
      "epoch:20 step:19317 [D loss: 0.522359, acc.: 72.66%] [G loss: 0.774509]\n",
      "epoch:20 step:19318 [D loss: 0.553124, acc.: 67.19%] [G loss: 0.628550]\n",
      "epoch:20 step:19319 [D loss: 0.537870, acc.: 67.19%] [G loss: 0.737768]\n",
      "epoch:20 step:19320 [D loss: 0.553485, acc.: 69.53%] [G loss: 0.772780]\n",
      "epoch:20 step:19321 [D loss: 0.555898, acc.: 66.41%] [G loss: 0.571616]\n",
      "epoch:20 step:19322 [D loss: 0.521169, acc.: 72.66%] [G loss: 0.669034]\n",
      "epoch:20 step:19323 [D loss: 0.569960, acc.: 62.50%] [G loss: 0.774543]\n",
      "epoch:20 step:19324 [D loss: 0.589398, acc.: 65.62%] [G loss: 0.659140]\n",
      "epoch:20 step:19325 [D loss: 0.548918, acc.: 68.75%] [G loss: 0.589259]\n",
      "epoch:20 step:19326 [D loss: 0.539868, acc.: 70.31%] [G loss: 0.631375]\n",
      "epoch:20 step:19327 [D loss: 0.599793, acc.: 64.06%] [G loss: 0.635212]\n",
      "epoch:20 step:19328 [D loss: 0.545608, acc.: 69.53%] [G loss: 0.570529]\n",
      "epoch:20 step:19329 [D loss: 0.516509, acc.: 70.31%] [G loss: 0.876330]\n",
      "epoch:20 step:19330 [D loss: 0.572997, acc.: 71.09%] [G loss: 0.595231]\n",
      "epoch:20 step:19331 [D loss: 0.568979, acc.: 68.75%] [G loss: 0.543700]\n",
      "epoch:20 step:19332 [D loss: 0.481147, acc.: 77.34%] [G loss: 0.633770]\n",
      "epoch:20 step:19333 [D loss: 0.534613, acc.: 71.88%] [G loss: 0.485704]\n",
      "epoch:20 step:19334 [D loss: 0.513153, acc.: 71.09%] [G loss: 0.681590]\n",
      "epoch:20 step:19335 [D loss: 0.523207, acc.: 72.66%] [G loss: 0.551167]\n",
      "epoch:20 step:19336 [D loss: 0.528216, acc.: 71.88%] [G loss: 0.677939]\n",
      "epoch:20 step:19337 [D loss: 0.503560, acc.: 71.88%] [G loss: 0.689899]\n",
      "epoch:20 step:19338 [D loss: 0.492258, acc.: 75.00%] [G loss: 0.491961]\n",
      "epoch:20 step:19339 [D loss: 0.544212, acc.: 67.97%] [G loss: 0.651079]\n",
      "epoch:20 step:19340 [D loss: 0.585050, acc.: 69.53%] [G loss: 0.663316]\n",
      "epoch:20 step:19341 [D loss: 0.512268, acc.: 70.31%] [G loss: 0.673746]\n",
      "epoch:20 step:19342 [D loss: 0.548407, acc.: 72.66%] [G loss: 0.704743]\n",
      "epoch:20 step:19343 [D loss: 0.484047, acc.: 79.69%] [G loss: 0.741435]\n",
      "epoch:20 step:19344 [D loss: 0.585188, acc.: 64.06%] [G loss: 0.586243]\n",
      "epoch:20 step:19345 [D loss: 0.420726, acc.: 82.03%] [G loss: 0.723420]\n",
      "epoch:20 step:19346 [D loss: 0.637540, acc.: 62.50%] [G loss: 0.579279]\n",
      "epoch:20 step:19347 [D loss: 0.539549, acc.: 64.06%] [G loss: 0.667117]\n",
      "epoch:20 step:19348 [D loss: 0.525752, acc.: 71.09%] [G loss: 0.584892]\n",
      "epoch:20 step:19349 [D loss: 0.530492, acc.: 69.53%] [G loss: 0.577453]\n",
      "epoch:20 step:19350 [D loss: 0.521695, acc.: 74.22%] [G loss: 0.501591]\n",
      "epoch:20 step:19351 [D loss: 0.494398, acc.: 78.12%] [G loss: 0.706501]\n",
      "epoch:20 step:19352 [D loss: 0.530800, acc.: 70.31%] [G loss: 0.698214]\n",
      "epoch:20 step:19353 [D loss: 0.496987, acc.: 75.78%] [G loss: 0.698632]\n",
      "epoch:20 step:19354 [D loss: 0.605448, acc.: 67.19%] [G loss: 0.558685]\n",
      "epoch:20 step:19355 [D loss: 0.550548, acc.: 69.53%] [G loss: 0.635629]\n",
      "epoch:20 step:19356 [D loss: 0.562860, acc.: 67.97%] [G loss: 0.637216]\n",
      "epoch:20 step:19357 [D loss: 0.507109, acc.: 73.44%] [G loss: 0.702992]\n",
      "epoch:20 step:19358 [D loss: 0.552315, acc.: 68.75%] [G loss: 0.759928]\n",
      "epoch:20 step:19359 [D loss: 0.489374, acc.: 72.66%] [G loss: 0.726866]\n",
      "epoch:20 step:19360 [D loss: 0.553962, acc.: 69.53%] [G loss: 0.656262]\n",
      "epoch:20 step:19361 [D loss: 0.585749, acc.: 67.19%] [G loss: 0.650513]\n",
      "epoch:20 step:19362 [D loss: 0.506896, acc.: 75.00%] [G loss: 0.838651]\n",
      "epoch:20 step:19363 [D loss: 0.436585, acc.: 75.00%] [G loss: 0.770468]\n",
      "epoch:20 step:19364 [D loss: 0.478626, acc.: 75.78%] [G loss: 0.767670]\n",
      "epoch:20 step:19365 [D loss: 0.615686, acc.: 67.97%] [G loss: 0.648186]\n",
      "epoch:20 step:19366 [D loss: 0.546022, acc.: 67.97%] [G loss: 0.619907]\n",
      "epoch:20 step:19367 [D loss: 0.512782, acc.: 74.22%] [G loss: 0.649825]\n",
      "epoch:20 step:19368 [D loss: 0.601160, acc.: 65.62%] [G loss: 0.569389]\n",
      "epoch:20 step:19369 [D loss: 0.515949, acc.: 73.44%] [G loss: 0.579775]\n",
      "epoch:20 step:19370 [D loss: 0.563666, acc.: 67.97%] [G loss: 0.643234]\n",
      "epoch:20 step:19371 [D loss: 0.467942, acc.: 77.34%] [G loss: 0.601158]\n",
      "epoch:20 step:19372 [D loss: 0.480084, acc.: 77.34%] [G loss: 0.675748]\n",
      "epoch:20 step:19373 [D loss: 0.534090, acc.: 73.44%] [G loss: 0.732763]\n",
      "epoch:20 step:19374 [D loss: 0.501402, acc.: 75.78%] [G loss: 0.765547]\n",
      "epoch:20 step:19375 [D loss: 0.486475, acc.: 70.31%] [G loss: 0.872754]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19376 [D loss: 0.557681, acc.: 68.75%] [G loss: 0.727926]\n",
      "epoch:20 step:19377 [D loss: 0.536583, acc.: 70.31%] [G loss: 0.641085]\n",
      "epoch:20 step:19378 [D loss: 0.495759, acc.: 72.66%] [G loss: 0.514521]\n",
      "epoch:20 step:19379 [D loss: 0.494574, acc.: 70.31%] [G loss: 0.691994]\n",
      "epoch:20 step:19380 [D loss: 0.589948, acc.: 70.31%] [G loss: 0.852879]\n",
      "epoch:20 step:19381 [D loss: 0.480156, acc.: 73.44%] [G loss: 0.804641]\n",
      "epoch:20 step:19382 [D loss: 0.488826, acc.: 77.34%] [G loss: 0.966710]\n",
      "epoch:20 step:19383 [D loss: 0.538324, acc.: 67.19%] [G loss: 0.822355]\n",
      "epoch:20 step:19384 [D loss: 0.576388, acc.: 66.41%] [G loss: 0.584725]\n",
      "epoch:20 step:19385 [D loss: 0.539256, acc.: 70.31%] [G loss: 0.699426]\n",
      "epoch:20 step:19386 [D loss: 0.592381, acc.: 65.62%] [G loss: 0.669600]\n",
      "epoch:20 step:19387 [D loss: 0.436409, acc.: 82.81%] [G loss: 0.886702]\n",
      "epoch:20 step:19388 [D loss: 0.425097, acc.: 79.69%] [G loss: 1.010276]\n",
      "epoch:20 step:19389 [D loss: 0.489036, acc.: 75.00%] [G loss: 0.971807]\n",
      "epoch:20 step:19390 [D loss: 0.515277, acc.: 74.22%] [G loss: 0.976227]\n",
      "epoch:20 step:19391 [D loss: 0.495543, acc.: 76.56%] [G loss: 0.669148]\n",
      "epoch:20 step:19392 [D loss: 0.610657, acc.: 63.28%] [G loss: 0.683080]\n",
      "epoch:20 step:19393 [D loss: 0.556232, acc.: 71.88%] [G loss: 0.533260]\n",
      "epoch:20 step:19394 [D loss: 0.481355, acc.: 75.78%] [G loss: 0.724571]\n",
      "epoch:20 step:19395 [D loss: 0.549815, acc.: 72.66%] [G loss: 0.719957]\n",
      "epoch:20 step:19396 [D loss: 0.505535, acc.: 75.78%] [G loss: 0.744684]\n",
      "epoch:20 step:19397 [D loss: 0.518861, acc.: 68.75%] [G loss: 0.774865]\n",
      "epoch:20 step:19398 [D loss: 0.566044, acc.: 68.75%] [G loss: 0.704136]\n",
      "epoch:20 step:19399 [D loss: 0.506405, acc.: 73.44%] [G loss: 0.797917]\n",
      "epoch:20 step:19400 [D loss: 0.524289, acc.: 73.44%] [G loss: 0.878019]\n",
      "##############\n",
      "[2.69709149 0.94629146 6.02584399 5.05066166 3.73202957 5.77136804\n",
      " 4.42625623 4.85716651 4.76132446 4.30620024]\n",
      "##########\n",
      "epoch:20 step:19401 [D loss: 0.521760, acc.: 70.31%] [G loss: 0.738436]\n",
      "epoch:20 step:19402 [D loss: 0.528286, acc.: 71.09%] [G loss: 0.833779]\n",
      "epoch:20 step:19403 [D loss: 0.566658, acc.: 70.31%] [G loss: 0.618334]\n",
      "epoch:20 step:19404 [D loss: 0.527336, acc.: 67.19%] [G loss: 0.935255]\n",
      "epoch:20 step:19405 [D loss: 0.581850, acc.: 62.50%] [G loss: 0.779244]\n",
      "epoch:20 step:19406 [D loss: 0.521425, acc.: 71.88%] [G loss: 0.824903]\n",
      "epoch:20 step:19407 [D loss: 0.526698, acc.: 74.22%] [G loss: 0.754408]\n",
      "epoch:20 step:19408 [D loss: 0.536578, acc.: 74.22%] [G loss: 0.607233]\n",
      "epoch:20 step:19409 [D loss: 0.621144, acc.: 64.84%] [G loss: 0.746243]\n",
      "epoch:20 step:19410 [D loss: 0.542730, acc.: 69.53%] [G loss: 0.688600]\n",
      "epoch:20 step:19411 [D loss: 0.531460, acc.: 66.41%] [G loss: 0.781654]\n",
      "epoch:20 step:19412 [D loss: 0.535735, acc.: 70.31%] [G loss: 0.667746]\n",
      "epoch:20 step:19413 [D loss: 0.561794, acc.: 71.88%] [G loss: 0.779605]\n",
      "epoch:20 step:19414 [D loss: 0.566184, acc.: 67.97%] [G loss: 0.758807]\n",
      "epoch:20 step:19415 [D loss: 0.564582, acc.: 67.97%] [G loss: 0.646031]\n",
      "epoch:20 step:19416 [D loss: 0.515738, acc.: 75.78%] [G loss: 0.732395]\n",
      "epoch:20 step:19417 [D loss: 0.480344, acc.: 81.25%] [G loss: 0.686415]\n",
      "epoch:20 step:19418 [D loss: 0.561597, acc.: 70.31%] [G loss: 0.585419]\n",
      "epoch:20 step:19419 [D loss: 0.501853, acc.: 74.22%] [G loss: 0.632378]\n",
      "epoch:20 step:19420 [D loss: 0.525067, acc.: 69.53%] [G loss: 0.744521]\n",
      "epoch:20 step:19421 [D loss: 0.491774, acc.: 71.88%] [G loss: 0.829208]\n",
      "epoch:20 step:19422 [D loss: 0.502494, acc.: 75.00%] [G loss: 0.679113]\n",
      "epoch:20 step:19423 [D loss: 0.543356, acc.: 72.66%] [G loss: 0.680631]\n",
      "epoch:20 step:19424 [D loss: 0.603454, acc.: 64.06%] [G loss: 0.487417]\n",
      "epoch:20 step:19425 [D loss: 0.491015, acc.: 76.56%] [G loss: 0.622171]\n",
      "epoch:20 step:19426 [D loss: 0.559224, acc.: 67.97%] [G loss: 0.546301]\n",
      "epoch:20 step:19427 [D loss: 0.575121, acc.: 67.19%] [G loss: 0.577709]\n",
      "epoch:20 step:19428 [D loss: 0.519339, acc.: 75.00%] [G loss: 0.748657]\n",
      "epoch:20 step:19429 [D loss: 0.580579, acc.: 71.09%] [G loss: 0.739001]\n",
      "epoch:20 step:19430 [D loss: 0.533487, acc.: 72.66%] [G loss: 0.756743]\n",
      "epoch:20 step:19431 [D loss: 0.466580, acc.: 78.91%] [G loss: 0.788162]\n",
      "epoch:20 step:19432 [D loss: 0.527146, acc.: 73.44%] [G loss: 0.857454]\n",
      "epoch:20 step:19433 [D loss: 0.514291, acc.: 74.22%] [G loss: 0.570110]\n",
      "epoch:20 step:19434 [D loss: 0.549835, acc.: 71.88%] [G loss: 0.677655]\n",
      "epoch:20 step:19435 [D loss: 0.533434, acc.: 71.09%] [G loss: 0.794773]\n",
      "epoch:20 step:19436 [D loss: 0.570497, acc.: 66.41%] [G loss: 0.659548]\n",
      "epoch:20 step:19437 [D loss: 0.532190, acc.: 69.53%] [G loss: 0.535903]\n",
      "epoch:20 step:19438 [D loss: 0.563857, acc.: 70.31%] [G loss: 0.598214]\n",
      "epoch:20 step:19439 [D loss: 0.467690, acc.: 76.56%] [G loss: 0.752838]\n",
      "epoch:20 step:19440 [D loss: 0.582314, acc.: 73.44%] [G loss: 0.495783]\n",
      "epoch:20 step:19441 [D loss: 0.493311, acc.: 72.66%] [G loss: 0.895314]\n",
      "epoch:20 step:19442 [D loss: 0.574854, acc.: 65.62%] [G loss: 0.726810]\n",
      "epoch:20 step:19443 [D loss: 0.590976, acc.: 64.84%] [G loss: 0.615184]\n",
      "epoch:20 step:19444 [D loss: 0.602883, acc.: 64.84%] [G loss: 0.575382]\n",
      "epoch:20 step:19445 [D loss: 0.460515, acc.: 80.47%] [G loss: 0.610352]\n",
      "epoch:20 step:19446 [D loss: 0.502116, acc.: 73.44%] [G loss: 0.680765]\n",
      "epoch:20 step:19447 [D loss: 0.547412, acc.: 67.97%] [G loss: 0.726820]\n",
      "epoch:20 step:19448 [D loss: 0.475710, acc.: 78.12%] [G loss: 0.733078]\n",
      "epoch:20 step:19449 [D loss: 0.492298, acc.: 72.66%] [G loss: 0.838225]\n",
      "epoch:20 step:19450 [D loss: 0.536461, acc.: 69.53%] [G loss: 0.618743]\n",
      "epoch:20 step:19451 [D loss: 0.566154, acc.: 65.62%] [G loss: 0.593865]\n",
      "epoch:20 step:19452 [D loss: 0.553508, acc.: 69.53%] [G loss: 0.637100]\n",
      "epoch:20 step:19453 [D loss: 0.614367, acc.: 64.84%] [G loss: 0.477676]\n",
      "epoch:20 step:19454 [D loss: 0.531758, acc.: 77.34%] [G loss: 0.698115]\n",
      "epoch:20 step:19455 [D loss: 0.548068, acc.: 66.41%] [G loss: 0.602454]\n",
      "epoch:20 step:19456 [D loss: 0.619363, acc.: 64.06%] [G loss: 0.538974]\n",
      "epoch:20 step:19457 [D loss: 0.553194, acc.: 70.31%] [G loss: 0.608753]\n",
      "epoch:20 step:19458 [D loss: 0.559432, acc.: 68.75%] [G loss: 0.459634]\n",
      "epoch:20 step:19459 [D loss: 0.481620, acc.: 75.78%] [G loss: 0.771187]\n",
      "epoch:20 step:19460 [D loss: 0.581182, acc.: 64.84%] [G loss: 0.780981]\n",
      "epoch:20 step:19461 [D loss: 0.559582, acc.: 70.31%] [G loss: 0.606018]\n",
      "epoch:20 step:19462 [D loss: 0.529456, acc.: 72.66%] [G loss: 0.680090]\n",
      "epoch:20 step:19463 [D loss: 0.509186, acc.: 72.66%] [G loss: 0.668241]\n",
      "epoch:20 step:19464 [D loss: 0.562214, acc.: 72.66%] [G loss: 0.593004]\n",
      "epoch:20 step:19465 [D loss: 0.482410, acc.: 79.69%] [G loss: 0.782974]\n",
      "epoch:20 step:19466 [D loss: 0.515285, acc.: 76.56%] [G loss: 0.783035]\n",
      "epoch:20 step:19467 [D loss: 0.537594, acc.: 69.53%] [G loss: 0.744559]\n",
      "epoch:20 step:19468 [D loss: 0.531975, acc.: 70.31%] [G loss: 0.761711]\n",
      "epoch:20 step:19469 [D loss: 0.530782, acc.: 73.44%] [G loss: 0.683156]\n",
      "epoch:20 step:19470 [D loss: 0.533487, acc.: 75.00%] [G loss: 0.653733]\n",
      "epoch:20 step:19471 [D loss: 0.582343, acc.: 67.19%] [G loss: 0.566330]\n",
      "epoch:20 step:19472 [D loss: 0.482751, acc.: 77.34%] [G loss: 0.647188]\n",
      "epoch:20 step:19473 [D loss: 0.559873, acc.: 71.88%] [G loss: 0.587082]\n",
      "epoch:20 step:19474 [D loss: 0.511984, acc.: 71.09%] [G loss: 0.687294]\n",
      "epoch:20 step:19475 [D loss: 0.533866, acc.: 70.31%] [G loss: 0.688544]\n",
      "epoch:20 step:19476 [D loss: 0.491653, acc.: 72.66%] [G loss: 0.566977]\n",
      "epoch:20 step:19477 [D loss: 0.507480, acc.: 71.88%] [G loss: 0.684702]\n",
      "epoch:20 step:19478 [D loss: 0.541695, acc.: 66.41%] [G loss: 0.734109]\n",
      "epoch:20 step:19479 [D loss: 0.596605, acc.: 66.41%] [G loss: 0.769159]\n",
      "epoch:20 step:19480 [D loss: 0.682587, acc.: 57.03%] [G loss: 0.403153]\n",
      "epoch:20 step:19481 [D loss: 0.551550, acc.: 72.66%] [G loss: 0.596619]\n",
      "epoch:20 step:19482 [D loss: 0.509551, acc.: 69.53%] [G loss: 0.762151]\n",
      "epoch:20 step:19483 [D loss: 0.508866, acc.: 71.09%] [G loss: 0.859577]\n",
      "epoch:20 step:19484 [D loss: 0.524768, acc.: 77.34%] [G loss: 0.758927]\n",
      "epoch:20 step:19485 [D loss: 0.561757, acc.: 67.97%] [G loss: 0.663387]\n",
      "epoch:20 step:19486 [D loss: 0.474386, acc.: 77.34%] [G loss: 0.734311]\n",
      "epoch:20 step:19487 [D loss: 0.457396, acc.: 75.78%] [G loss: 0.776505]\n",
      "epoch:20 step:19488 [D loss: 0.516574, acc.: 70.31%] [G loss: 0.701021]\n",
      "epoch:20 step:19489 [D loss: 0.557589, acc.: 71.88%] [G loss: 0.704191]\n",
      "epoch:20 step:19490 [D loss: 0.508292, acc.: 71.09%] [G loss: 0.862247]\n",
      "epoch:20 step:19491 [D loss: 0.488128, acc.: 72.66%] [G loss: 0.758606]\n",
      "epoch:20 step:19492 [D loss: 0.595427, acc.: 71.88%] [G loss: 0.692666]\n",
      "epoch:20 step:19493 [D loss: 0.500316, acc.: 72.66%] [G loss: 0.856180]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19494 [D loss: 0.599903, acc.: 70.31%] [G loss: 0.725989]\n",
      "epoch:20 step:19495 [D loss: 0.517888, acc.: 73.44%] [G loss: 0.790457]\n",
      "epoch:20 step:19496 [D loss: 0.541831, acc.: 72.66%] [G loss: 0.660535]\n",
      "epoch:20 step:19497 [D loss: 0.537587, acc.: 69.53%] [G loss: 0.773479]\n",
      "epoch:20 step:19498 [D loss: 0.489069, acc.: 75.00%] [G loss: 0.641459]\n",
      "epoch:20 step:19499 [D loss: 0.609616, acc.: 64.84%] [G loss: 0.564513]\n",
      "epoch:20 step:19500 [D loss: 0.487932, acc.: 75.00%] [G loss: 0.626911]\n",
      "epoch:20 step:19501 [D loss: 0.537846, acc.: 69.53%] [G loss: 0.618464]\n",
      "epoch:20 step:19502 [D loss: 0.520983, acc.: 73.44%] [G loss: 0.640903]\n",
      "epoch:20 step:19503 [D loss: 0.529052, acc.: 68.75%] [G loss: 0.535108]\n",
      "epoch:20 step:19504 [D loss: 0.580932, acc.: 63.28%] [G loss: 0.843237]\n",
      "epoch:20 step:19505 [D loss: 0.617581, acc.: 66.41%] [G loss: 0.640342]\n",
      "epoch:20 step:19506 [D loss: 0.639323, acc.: 59.38%] [G loss: 0.684117]\n",
      "epoch:20 step:19507 [D loss: 0.504233, acc.: 69.53%] [G loss: 0.747401]\n",
      "epoch:20 step:19508 [D loss: 0.547249, acc.: 69.53%] [G loss: 0.885022]\n",
      "epoch:20 step:19509 [D loss: 0.543666, acc.: 76.56%] [G loss: 0.833854]\n",
      "epoch:20 step:19510 [D loss: 0.531083, acc.: 75.00%] [G loss: 0.811853]\n",
      "epoch:20 step:19511 [D loss: 0.492656, acc.: 75.78%] [G loss: 0.693420]\n",
      "epoch:20 step:19512 [D loss: 0.521150, acc.: 71.09%] [G loss: 0.692551]\n",
      "epoch:20 step:19513 [D loss: 0.546439, acc.: 70.31%] [G loss: 0.634744]\n",
      "epoch:20 step:19514 [D loss: 0.495805, acc.: 78.12%] [G loss: 0.769525]\n",
      "epoch:20 step:19515 [D loss: 0.512719, acc.: 75.00%] [G loss: 0.769642]\n",
      "epoch:20 step:19516 [D loss: 0.610476, acc.: 64.84%] [G loss: 0.744728]\n",
      "epoch:20 step:19517 [D loss: 0.611522, acc.: 65.62%] [G loss: 0.660111]\n",
      "epoch:20 step:19518 [D loss: 0.554743, acc.: 71.88%] [G loss: 0.601876]\n",
      "epoch:20 step:19519 [D loss: 0.608064, acc.: 64.06%] [G loss: 0.644626]\n",
      "epoch:20 step:19520 [D loss: 0.523218, acc.: 75.78%] [G loss: 0.666028]\n",
      "epoch:20 step:19521 [D loss: 0.510611, acc.: 75.00%] [G loss: 0.853441]\n",
      "epoch:20 step:19522 [D loss: 0.507390, acc.: 72.66%] [G loss: 0.858571]\n",
      "epoch:20 step:19523 [D loss: 0.530234, acc.: 73.44%] [G loss: 0.789561]\n",
      "epoch:20 step:19524 [D loss: 0.580432, acc.: 64.84%] [G loss: 0.746671]\n",
      "epoch:20 step:19525 [D loss: 0.542926, acc.: 73.44%] [G loss: 0.645996]\n",
      "epoch:20 step:19526 [D loss: 0.509284, acc.: 68.75%] [G loss: 0.696803]\n",
      "epoch:20 step:19527 [D loss: 0.611408, acc.: 67.19%] [G loss: 0.861312]\n",
      "epoch:20 step:19528 [D loss: 0.633605, acc.: 63.28%] [G loss: 0.517401]\n",
      "epoch:20 step:19529 [D loss: 0.475609, acc.: 78.12%] [G loss: 0.629142]\n",
      "epoch:20 step:19530 [D loss: 0.538997, acc.: 65.62%] [G loss: 0.647248]\n",
      "epoch:20 step:19531 [D loss: 0.553442, acc.: 70.31%] [G loss: 0.606182]\n",
      "epoch:20 step:19532 [D loss: 0.469846, acc.: 73.44%] [G loss: 0.673239]\n",
      "epoch:20 step:19533 [D loss: 0.570877, acc.: 72.66%] [G loss: 0.706233]\n",
      "epoch:20 step:19534 [D loss: 0.626522, acc.: 58.59%] [G loss: 0.717766]\n",
      "epoch:20 step:19535 [D loss: 0.501828, acc.: 69.53%] [G loss: 0.657102]\n",
      "epoch:20 step:19536 [D loss: 0.504617, acc.: 73.44%] [G loss: 0.750142]\n",
      "epoch:20 step:19537 [D loss: 0.534878, acc.: 75.00%] [G loss: 0.651174]\n",
      "epoch:20 step:19538 [D loss: 0.519794, acc.: 68.75%] [G loss: 0.700762]\n",
      "epoch:20 step:19539 [D loss: 0.600032, acc.: 60.94%] [G loss: 0.614741]\n",
      "epoch:20 step:19540 [D loss: 0.593600, acc.: 64.06%] [G loss: 0.617633]\n",
      "epoch:20 step:19541 [D loss: 0.562513, acc.: 71.09%] [G loss: 0.711258]\n",
      "epoch:20 step:19542 [D loss: 0.506087, acc.: 71.88%] [G loss: 0.773990]\n",
      "epoch:20 step:19543 [D loss: 0.486254, acc.: 77.34%] [G loss: 0.903277]\n",
      "epoch:20 step:19544 [D loss: 0.504926, acc.: 77.34%] [G loss: 0.720606]\n",
      "epoch:20 step:19545 [D loss: 0.577101, acc.: 63.28%] [G loss: 0.611390]\n",
      "epoch:20 step:19546 [D loss: 0.530814, acc.: 72.66%] [G loss: 0.679923]\n",
      "epoch:20 step:19547 [D loss: 0.506229, acc.: 72.66%] [G loss: 0.569782]\n",
      "epoch:20 step:19548 [D loss: 0.534477, acc.: 64.84%] [G loss: 0.656240]\n",
      "epoch:20 step:19549 [D loss: 0.499322, acc.: 78.91%] [G loss: 0.577197]\n",
      "epoch:20 step:19550 [D loss: 0.536346, acc.: 68.75%] [G loss: 0.629011]\n",
      "epoch:20 step:19551 [D loss: 0.569433, acc.: 68.75%] [G loss: 0.627172]\n",
      "epoch:20 step:19552 [D loss: 0.723625, acc.: 57.03%] [G loss: 0.549059]\n",
      "epoch:20 step:19553 [D loss: 0.536824, acc.: 70.31%] [G loss: 0.633217]\n",
      "epoch:20 step:19554 [D loss: 0.487165, acc.: 78.12%] [G loss: 0.632931]\n",
      "epoch:20 step:19555 [D loss: 0.490710, acc.: 75.00%] [G loss: 0.624991]\n",
      "epoch:20 step:19556 [D loss: 0.563552, acc.: 72.66%] [G loss: 0.690045]\n",
      "epoch:20 step:19557 [D loss: 0.569363, acc.: 70.31%] [G loss: 0.665010]\n",
      "epoch:20 step:19558 [D loss: 0.619729, acc.: 63.28%] [G loss: 0.541925]\n",
      "epoch:20 step:19559 [D loss: 0.503754, acc.: 72.66%] [G loss: 0.727717]\n",
      "epoch:20 step:19560 [D loss: 0.619852, acc.: 64.06%] [G loss: 0.529330]\n",
      "epoch:20 step:19561 [D loss: 0.514164, acc.: 69.53%] [G loss: 0.569203]\n",
      "epoch:20 step:19562 [D loss: 0.560010, acc.: 66.41%] [G loss: 0.633687]\n",
      "epoch:20 step:19563 [D loss: 0.430175, acc.: 78.91%] [G loss: 0.802701]\n",
      "epoch:20 step:19564 [D loss: 0.555747, acc.: 70.31%] [G loss: 0.683585]\n",
      "epoch:20 step:19565 [D loss: 0.529270, acc.: 68.75%] [G loss: 0.630016]\n",
      "epoch:20 step:19566 [D loss: 0.498177, acc.: 75.00%] [G loss: 0.752519]\n",
      "epoch:20 step:19567 [D loss: 0.574584, acc.: 68.75%] [G loss: 0.705527]\n",
      "epoch:20 step:19568 [D loss: 0.630363, acc.: 60.94%] [G loss: 0.543829]\n",
      "epoch:20 step:19569 [D loss: 0.534287, acc.: 72.66%] [G loss: 0.796777]\n",
      "epoch:20 step:19570 [D loss: 0.536681, acc.: 75.78%] [G loss: 0.780210]\n",
      "epoch:20 step:19571 [D loss: 0.525904, acc.: 70.31%] [G loss: 0.654061]\n",
      "epoch:20 step:19572 [D loss: 0.478662, acc.: 72.66%] [G loss: 0.745176]\n",
      "epoch:20 step:19573 [D loss: 0.510554, acc.: 78.12%] [G loss: 0.610624]\n",
      "epoch:20 step:19574 [D loss: 0.511492, acc.: 71.88%] [G loss: 0.611397]\n",
      "epoch:20 step:19575 [D loss: 0.528670, acc.: 70.31%] [G loss: 0.446951]\n",
      "epoch:20 step:19576 [D loss: 0.511620, acc.: 73.44%] [G loss: 0.580446]\n",
      "epoch:20 step:19577 [D loss: 0.504860, acc.: 75.00%] [G loss: 0.570354]\n",
      "epoch:20 step:19578 [D loss: 0.540314, acc.: 70.31%] [G loss: 0.752748]\n",
      "epoch:20 step:19579 [D loss: 0.586476, acc.: 67.97%] [G loss: 0.628092]\n",
      "epoch:20 step:19580 [D loss: 0.588825, acc.: 67.19%] [G loss: 0.622655]\n",
      "epoch:20 step:19581 [D loss: 0.493026, acc.: 75.78%] [G loss: 0.660960]\n",
      "epoch:20 step:19582 [D loss: 0.508968, acc.: 71.88%] [G loss: 0.626583]\n",
      "epoch:20 step:19583 [D loss: 0.511317, acc.: 68.75%] [G loss: 0.732638]\n",
      "epoch:20 step:19584 [D loss: 0.526595, acc.: 71.88%] [G loss: 0.693009]\n",
      "epoch:20 step:19585 [D loss: 0.578788, acc.: 64.84%] [G loss: 0.698974]\n",
      "epoch:20 step:19586 [D loss: 0.613220, acc.: 61.72%] [G loss: 0.603390]\n",
      "epoch:20 step:19587 [D loss: 0.600254, acc.: 64.06%] [G loss: 0.485638]\n",
      "epoch:20 step:19588 [D loss: 0.590957, acc.: 62.50%] [G loss: 0.388954]\n",
      "epoch:20 step:19589 [D loss: 0.576212, acc.: 67.97%] [G loss: 0.529333]\n",
      "epoch:20 step:19590 [D loss: 0.514963, acc.: 71.09%] [G loss: 0.638217]\n",
      "epoch:20 step:19591 [D loss: 0.573125, acc.: 68.75%] [G loss: 0.680405]\n",
      "epoch:20 step:19592 [D loss: 0.540678, acc.: 67.97%] [G loss: 0.550730]\n",
      "epoch:20 step:19593 [D loss: 0.523122, acc.: 75.00%] [G loss: 0.653415]\n",
      "epoch:20 step:19594 [D loss: 0.493721, acc.: 67.97%] [G loss: 0.609852]\n",
      "epoch:20 step:19595 [D loss: 0.562563, acc.: 70.31%] [G loss: 0.603688]\n",
      "epoch:20 step:19596 [D loss: 0.616913, acc.: 65.62%] [G loss: 0.559404]\n",
      "epoch:20 step:19597 [D loss: 0.463888, acc.: 75.78%] [G loss: 0.819557]\n",
      "epoch:20 step:19598 [D loss: 0.616643, acc.: 67.19%] [G loss: 0.628792]\n",
      "epoch:20 step:19599 [D loss: 0.545013, acc.: 73.44%] [G loss: 0.650010]\n",
      "epoch:20 step:19600 [D loss: 0.470422, acc.: 74.22%] [G loss: 0.712131]\n",
      "##############\n",
      "[3.02218429 0.89067729 6.01382238 5.03927392 3.94832656 5.66519304\n",
      " 4.68478399 4.77434037 4.65866032 4.26718178]\n",
      "##########\n",
      "epoch:20 step:19601 [D loss: 0.586006, acc.: 67.97%] [G loss: 0.455863]\n",
      "epoch:20 step:19602 [D loss: 0.563151, acc.: 67.97%] [G loss: 0.536334]\n",
      "epoch:20 step:19603 [D loss: 0.538951, acc.: 72.66%] [G loss: 0.519608]\n",
      "epoch:20 step:19604 [D loss: 0.503538, acc.: 71.88%] [G loss: 0.545026]\n",
      "epoch:20 step:19605 [D loss: 0.547141, acc.: 69.53%] [G loss: 0.533412]\n",
      "epoch:20 step:19606 [D loss: 0.522635, acc.: 72.66%] [G loss: 0.604484]\n",
      "epoch:20 step:19607 [D loss: 0.639505, acc.: 62.50%] [G loss: 0.515239]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19608 [D loss: 0.550451, acc.: 70.31%] [G loss: 0.482454]\n",
      "epoch:20 step:19609 [D loss: 0.536027, acc.: 64.06%] [G loss: 0.671843]\n",
      "epoch:20 step:19610 [D loss: 0.428621, acc.: 78.91%] [G loss: 0.809691]\n",
      "epoch:20 step:19611 [D loss: 0.508746, acc.: 72.66%] [G loss: 0.737606]\n",
      "epoch:20 step:19612 [D loss: 0.494463, acc.: 74.22%] [G loss: 0.825406]\n",
      "epoch:20 step:19613 [D loss: 0.566159, acc.: 71.09%] [G loss: 0.649814]\n",
      "epoch:20 step:19614 [D loss: 0.588376, acc.: 65.62%] [G loss: 0.649615]\n",
      "epoch:20 step:19615 [D loss: 0.493209, acc.: 75.00%] [G loss: 0.710150]\n",
      "epoch:20 step:19616 [D loss: 0.534573, acc.: 70.31%] [G loss: 0.797744]\n",
      "epoch:20 step:19617 [D loss: 0.624352, acc.: 66.41%] [G loss: 0.544431]\n",
      "epoch:20 step:19618 [D loss: 0.518778, acc.: 70.31%] [G loss: 0.534120]\n",
      "epoch:20 step:19619 [D loss: 0.587262, acc.: 64.06%] [G loss: 0.577794]\n",
      "epoch:20 step:19620 [D loss: 0.641751, acc.: 53.91%] [G loss: 0.469308]\n",
      "epoch:20 step:19621 [D loss: 0.568557, acc.: 67.97%] [G loss: 0.508726]\n",
      "epoch:20 step:19622 [D loss: 0.556608, acc.: 65.62%] [G loss: 0.599653]\n",
      "epoch:20 step:19623 [D loss: 0.573371, acc.: 72.66%] [G loss: 0.603875]\n",
      "epoch:20 step:19624 [D loss: 0.461008, acc.: 78.91%] [G loss: 0.628808]\n",
      "epoch:20 step:19625 [D loss: 0.513618, acc.: 75.78%] [G loss: 0.669462]\n",
      "epoch:20 step:19626 [D loss: 0.482293, acc.: 76.56%] [G loss: 0.804806]\n",
      "epoch:20 step:19627 [D loss: 0.579181, acc.: 67.97%] [G loss: 0.681560]\n",
      "epoch:20 step:19628 [D loss: 0.554256, acc.: 67.97%] [G loss: 0.692213]\n",
      "epoch:20 step:19629 [D loss: 0.551658, acc.: 64.06%] [G loss: 0.599272]\n",
      "epoch:20 step:19630 [D loss: 0.519703, acc.: 76.56%] [G loss: 0.609341]\n",
      "epoch:20 step:19631 [D loss: 0.514381, acc.: 76.56%] [G loss: 0.588347]\n",
      "epoch:20 step:19632 [D loss: 0.616691, acc.: 64.84%] [G loss: 0.611932]\n",
      "epoch:20 step:19633 [D loss: 0.550324, acc.: 69.53%] [G loss: 0.610439]\n",
      "epoch:20 step:19634 [D loss: 0.431178, acc.: 80.47%] [G loss: 0.793396]\n",
      "epoch:20 step:19635 [D loss: 0.493504, acc.: 76.56%] [G loss: 0.774499]\n",
      "epoch:20 step:19636 [D loss: 0.465321, acc.: 80.47%] [G loss: 0.708650]\n",
      "epoch:20 step:19637 [D loss: 0.516603, acc.: 77.34%] [G loss: 0.724966]\n",
      "epoch:20 step:19638 [D loss: 0.414642, acc.: 82.03%] [G loss: 0.794566]\n",
      "epoch:20 step:19639 [D loss: 0.475639, acc.: 82.81%] [G loss: 1.001072]\n",
      "epoch:20 step:19640 [D loss: 0.544869, acc.: 70.31%] [G loss: 0.830942]\n",
      "epoch:20 step:19641 [D loss: 0.540199, acc.: 71.09%] [G loss: 0.634958]\n",
      "epoch:20 step:19642 [D loss: 0.582132, acc.: 70.31%] [G loss: 0.766676]\n",
      "epoch:20 step:19643 [D loss: 0.506964, acc.: 71.88%] [G loss: 0.883280]\n",
      "epoch:20 step:19644 [D loss: 0.576837, acc.: 68.75%] [G loss: 0.707267]\n",
      "epoch:20 step:19645 [D loss: 0.535759, acc.: 75.00%] [G loss: 0.590220]\n",
      "epoch:20 step:19646 [D loss: 0.517851, acc.: 72.66%] [G loss: 0.795365]\n",
      "epoch:20 step:19647 [D loss: 0.621080, acc.: 64.06%] [G loss: 0.597566]\n",
      "epoch:20 step:19648 [D loss: 0.525822, acc.: 75.00%] [G loss: 0.715307]\n",
      "epoch:20 step:19649 [D loss: 0.521185, acc.: 72.66%] [G loss: 0.570038]\n",
      "epoch:20 step:19650 [D loss: 0.486725, acc.: 70.31%] [G loss: 0.717253]\n",
      "epoch:20 step:19651 [D loss: 0.474734, acc.: 81.25%] [G loss: 0.785154]\n",
      "epoch:20 step:19652 [D loss: 0.484758, acc.: 79.69%] [G loss: 0.906381]\n",
      "epoch:20 step:19653 [D loss: 0.492868, acc.: 74.22%] [G loss: 0.998427]\n",
      "epoch:20 step:19654 [D loss: 0.438942, acc.: 74.22%] [G loss: 1.001782]\n",
      "epoch:20 step:19655 [D loss: 0.566303, acc.: 67.19%] [G loss: 0.777900]\n",
      "epoch:20 step:19656 [D loss: 0.493625, acc.: 69.53%] [G loss: 0.749727]\n",
      "epoch:20 step:19657 [D loss: 0.584969, acc.: 70.31%] [G loss: 0.707142]\n",
      "epoch:20 step:19658 [D loss: 0.480426, acc.: 78.12%] [G loss: 0.790302]\n",
      "epoch:20 step:19659 [D loss: 0.454019, acc.: 78.12%] [G loss: 0.987403]\n",
      "epoch:20 step:19660 [D loss: 0.742275, acc.: 60.16%] [G loss: 0.657982]\n",
      "epoch:20 step:19661 [D loss: 0.518977, acc.: 68.75%] [G loss: 0.844726]\n",
      "epoch:20 step:19662 [D loss: 0.538584, acc.: 75.78%] [G loss: 0.625351]\n",
      "epoch:20 step:19663 [D loss: 0.462267, acc.: 74.22%] [G loss: 0.734105]\n",
      "epoch:20 step:19664 [D loss: 0.455650, acc.: 82.03%] [G loss: 0.877349]\n",
      "epoch:20 step:19665 [D loss: 0.403127, acc.: 78.12%] [G loss: 0.998509]\n",
      "epoch:20 step:19666 [D loss: 0.419819, acc.: 78.12%] [G loss: 1.004775]\n",
      "epoch:20 step:19667 [D loss: 0.509947, acc.: 73.44%] [G loss: 1.161486]\n",
      "epoch:20 step:19668 [D loss: 0.717221, acc.: 58.59%] [G loss: 1.115538]\n",
      "epoch:20 step:19669 [D loss: 0.497657, acc.: 72.66%] [G loss: 1.302223]\n",
      "epoch:20 step:19670 [D loss: 0.501195, acc.: 75.78%] [G loss: 1.423935]\n",
      "epoch:20 step:19671 [D loss: 0.501017, acc.: 73.44%] [G loss: 1.035028]\n",
      "epoch:20 step:19672 [D loss: 0.660812, acc.: 64.84%] [G loss: 0.804478]\n",
      "epoch:20 step:19673 [D loss: 0.484261, acc.: 73.44%] [G loss: 1.024219]\n",
      "epoch:20 step:19674 [D loss: 0.511696, acc.: 70.31%] [G loss: 0.927696]\n",
      "epoch:20 step:19675 [D loss: 0.506490, acc.: 71.09%] [G loss: 0.902489]\n",
      "epoch:20 step:19676 [D loss: 0.416336, acc.: 82.03%] [G loss: 1.013192]\n",
      "epoch:20 step:19677 [D loss: 0.464738, acc.: 75.00%] [G loss: 1.257741]\n",
      "epoch:21 step:19678 [D loss: 0.576968, acc.: 69.53%] [G loss: 1.211930]\n",
      "epoch:21 step:19679 [D loss: 0.444079, acc.: 77.34%] [G loss: 0.956805]\n",
      "epoch:21 step:19680 [D loss: 0.596677, acc.: 72.66%] [G loss: 0.831578]\n",
      "epoch:21 step:19681 [D loss: 0.501471, acc.: 76.56%] [G loss: 0.758420]\n",
      "epoch:21 step:19682 [D loss: 0.529772, acc.: 74.22%] [G loss: 0.816747]\n",
      "epoch:21 step:19683 [D loss: 0.633556, acc.: 60.94%] [G loss: 0.747530]\n",
      "epoch:21 step:19684 [D loss: 0.458635, acc.: 78.91%] [G loss: 0.694731]\n",
      "epoch:21 step:19685 [D loss: 0.492582, acc.: 78.12%] [G loss: 0.745516]\n",
      "epoch:21 step:19686 [D loss: 0.523202, acc.: 75.00%] [G loss: 0.804323]\n",
      "epoch:21 step:19687 [D loss: 0.543248, acc.: 75.00%] [G loss: 0.775138]\n",
      "epoch:21 step:19688 [D loss: 0.451752, acc.: 76.56%] [G loss: 0.897744]\n",
      "epoch:21 step:19689 [D loss: 0.632533, acc.: 63.28%] [G loss: 0.526042]\n",
      "epoch:21 step:19690 [D loss: 0.585987, acc.: 66.41%] [G loss: 0.807421]\n",
      "epoch:21 step:19691 [D loss: 0.539894, acc.: 69.53%] [G loss: 0.825799]\n",
      "epoch:21 step:19692 [D loss: 0.470895, acc.: 78.12%] [G loss: 0.697871]\n",
      "epoch:21 step:19693 [D loss: 0.496362, acc.: 75.78%] [G loss: 0.649851]\n",
      "epoch:21 step:19694 [D loss: 0.552077, acc.: 69.53%] [G loss: 0.790523]\n",
      "epoch:21 step:19695 [D loss: 0.566385, acc.: 67.97%] [G loss: 0.679781]\n",
      "epoch:21 step:19696 [D loss: 0.582237, acc.: 67.19%] [G loss: 0.862607]\n",
      "epoch:21 step:19697 [D loss: 0.627903, acc.: 64.06%] [G loss: 0.614640]\n",
      "epoch:21 step:19698 [D loss: 0.615033, acc.: 63.28%] [G loss: 0.510287]\n",
      "epoch:21 step:19699 [D loss: 0.462708, acc.: 78.12%] [G loss: 0.821771]\n",
      "epoch:21 step:19700 [D loss: 0.523385, acc.: 70.31%] [G loss: 0.746255]\n",
      "epoch:21 step:19701 [D loss: 0.500693, acc.: 74.22%] [G loss: 0.624068]\n",
      "epoch:21 step:19702 [D loss: 0.431119, acc.: 78.12%] [G loss: 0.841999]\n",
      "epoch:21 step:19703 [D loss: 0.613321, acc.: 61.72%] [G loss: 0.661399]\n",
      "epoch:21 step:19704 [D loss: 0.466323, acc.: 77.34%] [G loss: 0.629139]\n",
      "epoch:21 step:19705 [D loss: 0.583185, acc.: 67.97%] [G loss: 0.621365]\n",
      "epoch:21 step:19706 [D loss: 0.473373, acc.: 75.78%] [G loss: 0.588395]\n",
      "epoch:21 step:19707 [D loss: 0.513255, acc.: 68.75%] [G loss: 0.745917]\n",
      "epoch:21 step:19708 [D loss: 0.598034, acc.: 65.62%] [G loss: 0.551080]\n",
      "epoch:21 step:19709 [D loss: 0.514830, acc.: 75.00%] [G loss: 0.652296]\n",
      "epoch:21 step:19710 [D loss: 0.509930, acc.: 74.22%] [G loss: 0.682196]\n",
      "epoch:21 step:19711 [D loss: 0.533316, acc.: 68.75%] [G loss: 0.513761]\n",
      "epoch:21 step:19712 [D loss: 0.577867, acc.: 61.72%] [G loss: 0.762850]\n",
      "epoch:21 step:19713 [D loss: 0.511803, acc.: 71.09%] [G loss: 0.604580]\n",
      "epoch:21 step:19714 [D loss: 0.463215, acc.: 78.91%] [G loss: 0.671528]\n",
      "epoch:21 step:19715 [D loss: 0.594707, acc.: 68.75%] [G loss: 0.610109]\n",
      "epoch:21 step:19716 [D loss: 0.512483, acc.: 72.66%] [G loss: 0.664106]\n",
      "epoch:21 step:19717 [D loss: 0.414761, acc.: 82.03%] [G loss: 0.899511]\n",
      "epoch:21 step:19718 [D loss: 0.564693, acc.: 67.19%] [G loss: 0.823333]\n",
      "epoch:21 step:19719 [D loss: 0.550343, acc.: 71.09%] [G loss: 0.560654]\n",
      "epoch:21 step:19720 [D loss: 0.565741, acc.: 67.97%] [G loss: 0.664051]\n",
      "epoch:21 step:19721 [D loss: 0.596386, acc.: 70.31%] [G loss: 0.564490]\n",
      "epoch:21 step:19722 [D loss: 0.472459, acc.: 75.78%] [G loss: 0.906583]\n",
      "epoch:21 step:19723 [D loss: 0.480403, acc.: 77.34%] [G loss: 0.730942]\n",
      "epoch:21 step:19724 [D loss: 0.522155, acc.: 71.09%] [G loss: 0.657787]\n",
      "epoch:21 step:19725 [D loss: 0.494531, acc.: 75.00%] [G loss: 0.801954]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:19726 [D loss: 0.494511, acc.: 76.56%] [G loss: 0.785084]\n",
      "epoch:21 step:19727 [D loss: 0.522003, acc.: 75.78%] [G loss: 0.698581]\n",
      "epoch:21 step:19728 [D loss: 0.599709, acc.: 67.19%] [G loss: 0.745891]\n",
      "epoch:21 step:19729 [D loss: 0.608239, acc.: 64.84%] [G loss: 0.612309]\n",
      "epoch:21 step:19730 [D loss: 0.475691, acc.: 77.34%] [G loss: 0.758866]\n",
      "epoch:21 step:19731 [D loss: 0.480172, acc.: 75.00%] [G loss: 0.699601]\n",
      "epoch:21 step:19732 [D loss: 0.584266, acc.: 69.53%] [G loss: 0.737988]\n",
      "epoch:21 step:19733 [D loss: 0.457648, acc.: 79.69%] [G loss: 0.752360]\n",
      "epoch:21 step:19734 [D loss: 0.507696, acc.: 72.66%] [G loss: 0.752058]\n",
      "epoch:21 step:19735 [D loss: 0.554388, acc.: 70.31%] [G loss: 0.776896]\n",
      "epoch:21 step:19736 [D loss: 0.515167, acc.: 74.22%] [G loss: 0.704813]\n",
      "epoch:21 step:19737 [D loss: 0.548210, acc.: 71.09%] [G loss: 0.606633]\n",
      "epoch:21 step:19738 [D loss: 0.561234, acc.: 65.62%] [G loss: 0.614609]\n",
      "epoch:21 step:19739 [D loss: 0.569067, acc.: 69.53%] [G loss: 0.531806]\n",
      "epoch:21 step:19740 [D loss: 0.533931, acc.: 69.53%] [G loss: 0.638412]\n",
      "epoch:21 step:19741 [D loss: 0.561702, acc.: 65.62%] [G loss: 0.516544]\n",
      "epoch:21 step:19742 [D loss: 0.549392, acc.: 71.88%] [G loss: 0.556544]\n",
      "epoch:21 step:19743 [D loss: 0.518182, acc.: 72.66%] [G loss: 0.630797]\n",
      "epoch:21 step:19744 [D loss: 0.546166, acc.: 71.88%] [G loss: 0.514531]\n",
      "epoch:21 step:19745 [D loss: 0.524233, acc.: 71.09%] [G loss: 0.707847]\n",
      "epoch:21 step:19746 [D loss: 0.463353, acc.: 77.34%] [G loss: 0.659971]\n",
      "epoch:21 step:19747 [D loss: 0.507412, acc.: 78.12%] [G loss: 0.709828]\n",
      "epoch:21 step:19748 [D loss: 0.556719, acc.: 71.09%] [G loss: 0.724116]\n",
      "epoch:21 step:19749 [D loss: 0.531077, acc.: 74.22%] [G loss: 0.707148]\n",
      "epoch:21 step:19750 [D loss: 0.559807, acc.: 68.75%] [G loss: 0.644882]\n",
      "epoch:21 step:19751 [D loss: 0.497515, acc.: 72.66%] [G loss: 0.734436]\n",
      "epoch:21 step:19752 [D loss: 0.525537, acc.: 72.66%] [G loss: 0.755847]\n",
      "epoch:21 step:19753 [D loss: 0.488195, acc.: 78.12%] [G loss: 0.730657]\n",
      "epoch:21 step:19754 [D loss: 0.443277, acc.: 77.34%] [G loss: 0.884281]\n",
      "epoch:21 step:19755 [D loss: 0.606502, acc.: 67.19%] [G loss: 0.685158]\n",
      "epoch:21 step:19756 [D loss: 0.565269, acc.: 68.75%] [G loss: 0.600531]\n",
      "epoch:21 step:19757 [D loss: 0.542297, acc.: 71.88%] [G loss: 0.759147]\n",
      "epoch:21 step:19758 [D loss: 0.504001, acc.: 78.91%] [G loss: 0.620499]\n",
      "epoch:21 step:19759 [D loss: 0.544387, acc.: 71.09%] [G loss: 0.689688]\n",
      "epoch:21 step:19760 [D loss: 0.419607, acc.: 76.56%] [G loss: 0.902083]\n",
      "epoch:21 step:19761 [D loss: 0.517751, acc.: 74.22%] [G loss: 0.644134]\n",
      "epoch:21 step:19762 [D loss: 0.564373, acc.: 68.75%] [G loss: 0.585764]\n",
      "epoch:21 step:19763 [D loss: 0.495526, acc.: 71.09%] [G loss: 0.712238]\n",
      "epoch:21 step:19764 [D loss: 0.525426, acc.: 69.53%] [G loss: 0.705873]\n",
      "epoch:21 step:19765 [D loss: 0.492655, acc.: 75.78%] [G loss: 0.671312]\n",
      "epoch:21 step:19766 [D loss: 0.519946, acc.: 70.31%] [G loss: 0.705189]\n",
      "epoch:21 step:19767 [D loss: 0.455825, acc.: 78.12%] [G loss: 0.860250]\n",
      "epoch:21 step:19768 [D loss: 0.593912, acc.: 66.41%] [G loss: 0.564347]\n",
      "epoch:21 step:19769 [D loss: 0.442109, acc.: 78.91%] [G loss: 0.690156]\n",
      "epoch:21 step:19770 [D loss: 0.494889, acc.: 73.44%] [G loss: 0.827401]\n",
      "epoch:21 step:19771 [D loss: 0.504507, acc.: 72.66%] [G loss: 0.797143]\n",
      "epoch:21 step:19772 [D loss: 0.522804, acc.: 72.66%] [G loss: 0.825094]\n",
      "epoch:21 step:19773 [D loss: 0.508819, acc.: 71.88%] [G loss: 0.788629]\n",
      "epoch:21 step:19774 [D loss: 0.530768, acc.: 69.53%] [G loss: 0.806914]\n",
      "epoch:21 step:19775 [D loss: 0.490208, acc.: 75.78%] [G loss: 0.787484]\n",
      "epoch:21 step:19776 [D loss: 0.496898, acc.: 75.78%] [G loss: 0.753692]\n",
      "epoch:21 step:19777 [D loss: 0.442466, acc.: 77.34%] [G loss: 1.001912]\n",
      "epoch:21 step:19778 [D loss: 0.536011, acc.: 69.53%] [G loss: 0.793076]\n",
      "epoch:21 step:19779 [D loss: 0.634774, acc.: 64.84%] [G loss: 0.658428]\n",
      "epoch:21 step:19780 [D loss: 0.501970, acc.: 73.44%] [G loss: 0.808132]\n",
      "epoch:21 step:19781 [D loss: 0.477800, acc.: 79.69%] [G loss: 0.656527]\n",
      "epoch:21 step:19782 [D loss: 0.623544, acc.: 60.94%] [G loss: 0.657584]\n",
      "epoch:21 step:19783 [D loss: 0.506997, acc.: 73.44%] [G loss: 0.739451]\n",
      "epoch:21 step:19784 [D loss: 0.515997, acc.: 75.78%] [G loss: 0.708957]\n",
      "epoch:21 step:19785 [D loss: 0.628262, acc.: 64.06%] [G loss: 0.740236]\n",
      "epoch:21 step:19786 [D loss: 0.561273, acc.: 71.88%] [G loss: 0.725264]\n",
      "epoch:21 step:19787 [D loss: 0.558275, acc.: 64.84%] [G loss: 0.650045]\n",
      "epoch:21 step:19788 [D loss: 0.539739, acc.: 71.88%] [G loss: 0.594270]\n",
      "epoch:21 step:19789 [D loss: 0.513220, acc.: 71.88%] [G loss: 0.569602]\n",
      "epoch:21 step:19790 [D loss: 0.544799, acc.: 73.44%] [G loss: 0.500652]\n",
      "epoch:21 step:19791 [D loss: 0.569613, acc.: 67.19%] [G loss: 0.811836]\n",
      "epoch:21 step:19792 [D loss: 0.481920, acc.: 78.91%] [G loss: 0.757609]\n",
      "epoch:21 step:19793 [D loss: 0.452055, acc.: 79.69%] [G loss: 0.949751]\n",
      "epoch:21 step:19794 [D loss: 0.508024, acc.: 67.97%] [G loss: 0.677893]\n",
      "epoch:21 step:19795 [D loss: 0.534369, acc.: 69.53%] [G loss: 0.763463]\n",
      "epoch:21 step:19796 [D loss: 0.490854, acc.: 75.00%] [G loss: 0.995009]\n",
      "epoch:21 step:19797 [D loss: 0.529752, acc.: 76.56%] [G loss: 0.779733]\n",
      "epoch:21 step:19798 [D loss: 0.488931, acc.: 75.00%] [G loss: 0.649090]\n",
      "epoch:21 step:19799 [D loss: 0.447674, acc.: 82.03%] [G loss: 0.811148]\n",
      "epoch:21 step:19800 [D loss: 0.517955, acc.: 74.22%] [G loss: 0.864501]\n",
      "##############\n",
      "[2.91818936 0.9683473  6.06881503 4.89656052 3.88254256 5.89372648\n",
      " 4.69863506 4.78536951 4.62293122 4.16825576]\n",
      "##########\n",
      "epoch:21 step:19801 [D loss: 0.581743, acc.: 69.53%] [G loss: 0.690419]\n",
      "epoch:21 step:19802 [D loss: 0.565543, acc.: 68.75%] [G loss: 0.590853]\n",
      "epoch:21 step:19803 [D loss: 0.500254, acc.: 74.22%] [G loss: 0.627658]\n",
      "epoch:21 step:19804 [D loss: 0.465230, acc.: 77.34%] [G loss: 0.764367]\n",
      "epoch:21 step:19805 [D loss: 0.550762, acc.: 75.00%] [G loss: 0.891339]\n",
      "epoch:21 step:19806 [D loss: 0.582453, acc.: 66.41%] [G loss: 0.592956]\n",
      "epoch:21 step:19807 [D loss: 0.522983, acc.: 67.19%] [G loss: 0.762251]\n",
      "epoch:21 step:19808 [D loss: 0.481973, acc.: 75.00%] [G loss: 0.674399]\n",
      "epoch:21 step:19809 [D loss: 0.567636, acc.: 66.41%] [G loss: 0.659941]\n",
      "epoch:21 step:19810 [D loss: 0.559793, acc.: 70.31%] [G loss: 0.875695]\n",
      "epoch:21 step:19811 [D loss: 0.627138, acc.: 59.38%] [G loss: 0.822588]\n",
      "epoch:21 step:19812 [D loss: 0.482573, acc.: 75.00%] [G loss: 0.776439]\n",
      "epoch:21 step:19813 [D loss: 0.563995, acc.: 64.84%] [G loss: 0.761383]\n",
      "epoch:21 step:19814 [D loss: 0.613940, acc.: 64.84%] [G loss: 0.504164]\n",
      "epoch:21 step:19815 [D loss: 0.555381, acc.: 68.75%] [G loss: 0.626812]\n",
      "epoch:21 step:19816 [D loss: 0.497416, acc.: 75.78%] [G loss: 0.666554]\n",
      "epoch:21 step:19817 [D loss: 0.531629, acc.: 71.88%] [G loss: 0.676784]\n",
      "epoch:21 step:19818 [D loss: 0.523105, acc.: 71.88%] [G loss: 0.692146]\n",
      "epoch:21 step:19819 [D loss: 0.560052, acc.: 67.19%] [G loss: 0.729880]\n",
      "epoch:21 step:19820 [D loss: 0.580088, acc.: 63.28%] [G loss: 0.606638]\n",
      "epoch:21 step:19821 [D loss: 0.478859, acc.: 78.91%] [G loss: 0.760252]\n",
      "epoch:21 step:19822 [D loss: 0.527442, acc.: 72.66%] [G loss: 0.628648]\n",
      "epoch:21 step:19823 [D loss: 0.496010, acc.: 75.00%] [G loss: 1.032414]\n",
      "epoch:21 step:19824 [D loss: 0.630532, acc.: 67.19%] [G loss: 0.678580]\n",
      "epoch:21 step:19825 [D loss: 0.618020, acc.: 64.06%] [G loss: 0.741314]\n",
      "epoch:21 step:19826 [D loss: 0.542048, acc.: 71.09%] [G loss: 0.703111]\n",
      "epoch:21 step:19827 [D loss: 0.572547, acc.: 64.84%] [G loss: 0.479990]\n",
      "epoch:21 step:19828 [D loss: 0.608365, acc.: 61.72%] [G loss: 0.662387]\n",
      "epoch:21 step:19829 [D loss: 0.431924, acc.: 81.25%] [G loss: 0.644719]\n",
      "epoch:21 step:19830 [D loss: 0.606543, acc.: 66.41%] [G loss: 0.719537]\n",
      "epoch:21 step:19831 [D loss: 0.519496, acc.: 69.53%] [G loss: 0.600973]\n",
      "epoch:21 step:19832 [D loss: 0.478932, acc.: 74.22%] [G loss: 0.626580]\n",
      "epoch:21 step:19833 [D loss: 0.487272, acc.: 75.78%] [G loss: 0.665545]\n",
      "epoch:21 step:19834 [D loss: 0.499394, acc.: 72.66%] [G loss: 0.746808]\n",
      "epoch:21 step:19835 [D loss: 0.528476, acc.: 67.97%] [G loss: 0.525605]\n",
      "epoch:21 step:19836 [D loss: 0.483668, acc.: 75.00%] [G loss: 0.736894]\n",
      "epoch:21 step:19837 [D loss: 0.627666, acc.: 67.19%] [G loss: 0.729007]\n",
      "epoch:21 step:19838 [D loss: 0.577692, acc.: 67.97%] [G loss: 0.650607]\n",
      "epoch:21 step:19839 [D loss: 0.517112, acc.: 71.88%] [G loss: 0.716724]\n",
      "epoch:21 step:19840 [D loss: 0.603459, acc.: 64.06%] [G loss: 0.745204]\n",
      "epoch:21 step:19841 [D loss: 0.544898, acc.: 70.31%] [G loss: 0.794964]\n",
      "epoch:21 step:19842 [D loss: 0.450490, acc.: 74.22%] [G loss: 0.565021]\n",
      "epoch:21 step:19843 [D loss: 0.520461, acc.: 70.31%] [G loss: 0.456703]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:19844 [D loss: 0.574803, acc.: 63.28%] [G loss: 0.640652]\n",
      "epoch:21 step:19845 [D loss: 0.532114, acc.: 72.66%] [G loss: 0.667242]\n",
      "epoch:21 step:19846 [D loss: 0.585888, acc.: 67.97%] [G loss: 0.680908]\n",
      "epoch:21 step:19847 [D loss: 0.598543, acc.: 66.41%] [G loss: 0.516201]\n",
      "epoch:21 step:19848 [D loss: 0.521199, acc.: 71.09%] [G loss: 0.823893]\n",
      "epoch:21 step:19849 [D loss: 0.519969, acc.: 69.53%] [G loss: 0.590159]\n",
      "epoch:21 step:19850 [D loss: 0.512378, acc.: 70.31%] [G loss: 0.672765]\n",
      "epoch:21 step:19851 [D loss: 0.607679, acc.: 67.19%] [G loss: 0.700796]\n",
      "epoch:21 step:19852 [D loss: 0.592592, acc.: 64.84%] [G loss: 0.543873]\n",
      "epoch:21 step:19853 [D loss: 0.506890, acc.: 74.22%] [G loss: 0.702329]\n",
      "epoch:21 step:19854 [D loss: 0.507768, acc.: 73.44%] [G loss: 0.616964]\n",
      "epoch:21 step:19855 [D loss: 0.553339, acc.: 71.09%] [G loss: 0.577415]\n",
      "epoch:21 step:19856 [D loss: 0.526780, acc.: 69.53%] [G loss: 0.739570]\n",
      "epoch:21 step:19857 [D loss: 0.583198, acc.: 65.62%] [G loss: 0.738732]\n",
      "epoch:21 step:19858 [D loss: 0.525791, acc.: 71.88%] [G loss: 0.589713]\n",
      "epoch:21 step:19859 [D loss: 0.502765, acc.: 77.34%] [G loss: 0.675131]\n",
      "epoch:21 step:19860 [D loss: 0.595644, acc.: 64.84%] [G loss: 0.647926]\n",
      "epoch:21 step:19861 [D loss: 0.505311, acc.: 73.44%] [G loss: 0.680157]\n",
      "epoch:21 step:19862 [D loss: 0.584899, acc.: 70.31%] [G loss: 0.568421]\n",
      "epoch:21 step:19863 [D loss: 0.532483, acc.: 70.31%] [G loss: 0.598517]\n",
      "epoch:21 step:19864 [D loss: 0.635611, acc.: 62.50%] [G loss: 0.514560]\n",
      "epoch:21 step:19865 [D loss: 0.557907, acc.: 68.75%] [G loss: 0.705660]\n",
      "epoch:21 step:19866 [D loss: 0.558560, acc.: 71.09%] [G loss: 0.532386]\n",
      "epoch:21 step:19867 [D loss: 0.467135, acc.: 76.56%] [G loss: 0.696097]\n",
      "epoch:21 step:19868 [D loss: 0.510579, acc.: 77.34%] [G loss: 0.633009]\n",
      "epoch:21 step:19869 [D loss: 0.511097, acc.: 75.78%] [G loss: 0.515229]\n",
      "epoch:21 step:19870 [D loss: 0.547669, acc.: 67.19%] [G loss: 0.569295]\n",
      "epoch:21 step:19871 [D loss: 0.402474, acc.: 82.03%] [G loss: 0.781629]\n",
      "epoch:21 step:19872 [D loss: 0.525583, acc.: 76.56%] [G loss: 0.815876]\n",
      "epoch:21 step:19873 [D loss: 0.560629, acc.: 63.28%] [G loss: 0.651870]\n",
      "epoch:21 step:19874 [D loss: 0.500381, acc.: 75.78%] [G loss: 0.708942]\n",
      "epoch:21 step:19875 [D loss: 0.459652, acc.: 78.91%] [G loss: 0.765195]\n",
      "epoch:21 step:19876 [D loss: 0.550014, acc.: 66.41%] [G loss: 0.679685]\n",
      "epoch:21 step:19877 [D loss: 0.590618, acc.: 66.41%] [G loss: 0.616555]\n",
      "epoch:21 step:19878 [D loss: 0.566924, acc.: 67.97%] [G loss: 0.660700]\n",
      "epoch:21 step:19879 [D loss: 0.557236, acc.: 69.53%] [G loss: 0.670207]\n",
      "epoch:21 step:19880 [D loss: 0.604859, acc.: 61.72%] [G loss: 0.640279]\n",
      "epoch:21 step:19881 [D loss: 0.562399, acc.: 64.84%] [G loss: 0.558858]\n",
      "epoch:21 step:19882 [D loss: 0.508141, acc.: 71.88%] [G loss: 0.712553]\n",
      "epoch:21 step:19883 [D loss: 0.531465, acc.: 73.44%] [G loss: 0.922239]\n",
      "epoch:21 step:19884 [D loss: 0.497275, acc.: 73.44%] [G loss: 0.735297]\n",
      "epoch:21 step:19885 [D loss: 0.461028, acc.: 79.69%] [G loss: 0.845601]\n",
      "epoch:21 step:19886 [D loss: 0.442048, acc.: 79.69%] [G loss: 0.782600]\n",
      "epoch:21 step:19887 [D loss: 0.653228, acc.: 63.28%] [G loss: 0.617198]\n",
      "epoch:21 step:19888 [D loss: 0.564929, acc.: 67.97%] [G loss: 0.464330]\n",
      "epoch:21 step:19889 [D loss: 0.551734, acc.: 69.53%] [G loss: 0.541198]\n",
      "epoch:21 step:19890 [D loss: 0.494238, acc.: 73.44%] [G loss: 0.754916]\n",
      "epoch:21 step:19891 [D loss: 0.655452, acc.: 58.59%] [G loss: 0.591571]\n",
      "epoch:21 step:19892 [D loss: 0.606745, acc.: 64.06%] [G loss: 0.618365]\n",
      "epoch:21 step:19893 [D loss: 0.489533, acc.: 75.00%] [G loss: 0.641923]\n",
      "epoch:21 step:19894 [D loss: 0.552656, acc.: 70.31%] [G loss: 0.580705]\n",
      "epoch:21 step:19895 [D loss: 0.539090, acc.: 67.97%] [G loss: 0.776913]\n",
      "epoch:21 step:19896 [D loss: 0.496029, acc.: 75.78%] [G loss: 0.816876]\n",
      "epoch:21 step:19897 [D loss: 0.624493, acc.: 66.41%] [G loss: 0.715161]\n",
      "epoch:21 step:19898 [D loss: 0.515332, acc.: 72.66%] [G loss: 0.765942]\n",
      "epoch:21 step:19899 [D loss: 0.493999, acc.: 75.78%] [G loss: 0.810097]\n",
      "epoch:21 step:19900 [D loss: 0.537307, acc.: 73.44%] [G loss: 0.869440]\n",
      "epoch:21 step:19901 [D loss: 0.595134, acc.: 68.75%] [G loss: 0.656308]\n",
      "epoch:21 step:19902 [D loss: 0.521241, acc.: 74.22%] [G loss: 0.558540]\n",
      "epoch:21 step:19903 [D loss: 0.624718, acc.: 60.16%] [G loss: 0.579387]\n",
      "epoch:21 step:19904 [D loss: 0.528017, acc.: 71.09%] [G loss: 0.488746]\n",
      "epoch:21 step:19905 [D loss: 0.532116, acc.: 72.66%] [G loss: 0.600406]\n",
      "epoch:21 step:19906 [D loss: 0.498214, acc.: 79.69%] [G loss: 0.590873]\n",
      "epoch:21 step:19907 [D loss: 0.513799, acc.: 71.88%] [G loss: 0.710171]\n",
      "epoch:21 step:19908 [D loss: 0.451829, acc.: 78.12%] [G loss: 0.830471]\n",
      "epoch:21 step:19909 [D loss: 0.410411, acc.: 81.25%] [G loss: 0.932418]\n",
      "epoch:21 step:19910 [D loss: 0.568784, acc.: 67.19%] [G loss: 0.647051]\n",
      "epoch:21 step:19911 [D loss: 0.598458, acc.: 68.75%] [G loss: 0.771465]\n",
      "epoch:21 step:19912 [D loss: 0.532722, acc.: 66.41%] [G loss: 0.797864]\n",
      "epoch:21 step:19913 [D loss: 0.495010, acc.: 75.00%] [G loss: 0.732565]\n",
      "epoch:21 step:19914 [D loss: 0.468523, acc.: 75.00%] [G loss: 0.866985]\n",
      "epoch:21 step:19915 [D loss: 0.566172, acc.: 68.75%] [G loss: 0.735170]\n",
      "epoch:21 step:19916 [D loss: 0.500257, acc.: 75.78%] [G loss: 0.761399]\n",
      "epoch:21 step:19917 [D loss: 0.546231, acc.: 70.31%] [G loss: 0.689038]\n",
      "epoch:21 step:19918 [D loss: 0.458547, acc.: 78.91%] [G loss: 0.766436]\n",
      "epoch:21 step:19919 [D loss: 0.524475, acc.: 77.34%] [G loss: 0.748024]\n",
      "epoch:21 step:19920 [D loss: 0.511027, acc.: 67.97%] [G loss: 0.797203]\n",
      "epoch:21 step:19921 [D loss: 0.470059, acc.: 76.56%] [G loss: 0.638071]\n",
      "epoch:21 step:19922 [D loss: 0.524733, acc.: 71.09%] [G loss: 0.708693]\n",
      "epoch:21 step:19923 [D loss: 0.516298, acc.: 75.00%] [G loss: 0.632487]\n",
      "epoch:21 step:19924 [D loss: 0.540694, acc.: 71.88%] [G loss: 0.642511]\n",
      "epoch:21 step:19925 [D loss: 0.495811, acc.: 71.88%] [G loss: 0.708534]\n",
      "epoch:21 step:19926 [D loss: 0.594640, acc.: 66.41%] [G loss: 0.928585]\n",
      "epoch:21 step:19927 [D loss: 0.619566, acc.: 66.41%] [G loss: 0.675262]\n",
      "epoch:21 step:19928 [D loss: 0.627578, acc.: 65.62%] [G loss: 0.604500]\n",
      "epoch:21 step:19929 [D loss: 0.539623, acc.: 68.75%] [G loss: 0.686577]\n",
      "epoch:21 step:19930 [D loss: 0.573218, acc.: 66.41%] [G loss: 0.616168]\n",
      "epoch:21 step:19931 [D loss: 0.568664, acc.: 67.97%] [G loss: 0.551418]\n",
      "epoch:21 step:19932 [D loss: 0.545659, acc.: 67.19%] [G loss: 0.587546]\n",
      "epoch:21 step:19933 [D loss: 0.549870, acc.: 72.66%] [G loss: 0.616823]\n",
      "epoch:21 step:19934 [D loss: 0.558211, acc.: 67.97%] [G loss: 0.564892]\n",
      "epoch:21 step:19935 [D loss: 0.502622, acc.: 71.09%] [G loss: 0.593362]\n",
      "epoch:21 step:19936 [D loss: 0.532461, acc.: 71.88%] [G loss: 0.605346]\n",
      "epoch:21 step:19937 [D loss: 0.609292, acc.: 63.28%] [G loss: 0.498516]\n",
      "epoch:21 step:19938 [D loss: 0.552405, acc.: 70.31%] [G loss: 0.729308]\n",
      "epoch:21 step:19939 [D loss: 0.547655, acc.: 70.31%] [G loss: 0.650776]\n",
      "epoch:21 step:19940 [D loss: 0.565593, acc.: 67.19%] [G loss: 0.653391]\n",
      "epoch:21 step:19941 [D loss: 0.540114, acc.: 75.78%] [G loss: 0.559449]\n",
      "epoch:21 step:19942 [D loss: 0.503359, acc.: 73.44%] [G loss: 0.560657]\n",
      "epoch:21 step:19943 [D loss: 0.511788, acc.: 75.78%] [G loss: 0.604017]\n",
      "epoch:21 step:19944 [D loss: 0.549420, acc.: 67.97%] [G loss: 0.536036]\n",
      "epoch:21 step:19945 [D loss: 0.517921, acc.: 67.97%] [G loss: 0.649423]\n",
      "epoch:21 step:19946 [D loss: 0.487000, acc.: 74.22%] [G loss: 0.763862]\n",
      "epoch:21 step:19947 [D loss: 0.506080, acc.: 74.22%] [G loss: 0.789755]\n",
      "epoch:21 step:19948 [D loss: 0.579087, acc.: 65.62%] [G loss: 0.599185]\n",
      "epoch:21 step:19949 [D loss: 0.537917, acc.: 65.62%] [G loss: 0.663486]\n",
      "epoch:21 step:19950 [D loss: 0.482030, acc.: 70.31%] [G loss: 0.703267]\n",
      "epoch:21 step:19951 [D loss: 0.539520, acc.: 72.66%] [G loss: 0.606570]\n",
      "epoch:21 step:19952 [D loss: 0.562810, acc.: 67.97%] [G loss: 0.676409]\n",
      "epoch:21 step:19953 [D loss: 0.458325, acc.: 78.12%] [G loss: 0.610793]\n",
      "epoch:21 step:19954 [D loss: 0.668851, acc.: 62.50%] [G loss: 0.606449]\n",
      "epoch:21 step:19955 [D loss: 0.580861, acc.: 68.75%] [G loss: 0.519884]\n",
      "epoch:21 step:19956 [D loss: 0.580979, acc.: 65.62%] [G loss: 0.641179]\n",
      "epoch:21 step:19957 [D loss: 0.507786, acc.: 72.66%] [G loss: 0.693097]\n",
      "epoch:21 step:19958 [D loss: 0.535745, acc.: 72.66%] [G loss: 0.635147]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:19959 [D loss: 0.596349, acc.: 65.62%] [G loss: 0.517132]\n",
      "epoch:21 step:19960 [D loss: 0.484880, acc.: 76.56%] [G loss: 0.684884]\n",
      "epoch:21 step:19961 [D loss: 0.506719, acc.: 72.66%] [G loss: 0.699373]\n",
      "epoch:21 step:19962 [D loss: 0.481440, acc.: 77.34%] [G loss: 0.713611]\n",
      "epoch:21 step:19963 [D loss: 0.499567, acc.: 76.56%] [G loss: 0.792912]\n",
      "epoch:21 step:19964 [D loss: 0.634467, acc.: 60.94%] [G loss: 0.631991]\n",
      "epoch:21 step:19965 [D loss: 0.546187, acc.: 68.75%] [G loss: 0.827006]\n",
      "epoch:21 step:19966 [D loss: 0.543141, acc.: 69.53%] [G loss: 0.785788]\n",
      "epoch:21 step:19967 [D loss: 0.550650, acc.: 67.19%] [G loss: 0.611020]\n",
      "epoch:21 step:19968 [D loss: 0.565566, acc.: 70.31%] [G loss: 0.611766]\n",
      "epoch:21 step:19969 [D loss: 0.578919, acc.: 67.19%] [G loss: 0.687034]\n",
      "epoch:21 step:19970 [D loss: 0.569820, acc.: 65.62%] [G loss: 0.601310]\n",
      "epoch:21 step:19971 [D loss: 0.626160, acc.: 63.28%] [G loss: 0.483299]\n",
      "epoch:21 step:19972 [D loss: 0.542175, acc.: 69.53%] [G loss: 0.558866]\n",
      "epoch:21 step:19973 [D loss: 0.456510, acc.: 75.00%] [G loss: 0.747722]\n",
      "epoch:21 step:19974 [D loss: 0.550083, acc.: 70.31%] [G loss: 0.636953]\n",
      "epoch:21 step:19975 [D loss: 0.472999, acc.: 77.34%] [G loss: 0.618861]\n",
      "epoch:21 step:19976 [D loss: 0.488412, acc.: 74.22%] [G loss: 0.599301]\n",
      "epoch:21 step:19977 [D loss: 0.484434, acc.: 76.56%] [G loss: 0.620971]\n",
      "epoch:21 step:19978 [D loss: 0.579106, acc.: 70.31%] [G loss: 0.661475]\n",
      "epoch:21 step:19979 [D loss: 0.510304, acc.: 71.88%] [G loss: 0.582374]\n",
      "epoch:21 step:19980 [D loss: 0.556008, acc.: 65.62%] [G loss: 0.836427]\n",
      "epoch:21 step:19981 [D loss: 0.516379, acc.: 75.78%] [G loss: 0.766175]\n",
      "epoch:21 step:19982 [D loss: 0.571120, acc.: 70.31%] [G loss: 0.589731]\n",
      "epoch:21 step:19983 [D loss: 0.473432, acc.: 75.78%] [G loss: 0.730950]\n",
      "epoch:21 step:19984 [D loss: 0.475884, acc.: 73.44%] [G loss: 0.684649]\n",
      "epoch:21 step:19985 [D loss: 0.537742, acc.: 72.66%] [G loss: 0.567482]\n",
      "epoch:21 step:19986 [D loss: 0.515714, acc.: 70.31%] [G loss: 0.611535]\n",
      "epoch:21 step:19987 [D loss: 0.517660, acc.: 74.22%] [G loss: 0.693708]\n",
      "epoch:21 step:19988 [D loss: 0.510838, acc.: 73.44%] [G loss: 0.798087]\n",
      "epoch:21 step:19989 [D loss: 0.473982, acc.: 76.56%] [G loss: 0.966366]\n",
      "epoch:21 step:19990 [D loss: 0.442576, acc.: 77.34%] [G loss: 1.074884]\n",
      "epoch:21 step:19991 [D loss: 0.462875, acc.: 74.22%] [G loss: 0.872844]\n",
      "epoch:21 step:19992 [D loss: 0.430268, acc.: 83.59%] [G loss: 1.116439]\n",
      "epoch:21 step:19993 [D loss: 0.743020, acc.: 56.25%] [G loss: 0.823607]\n",
      "epoch:21 step:19994 [D loss: 0.594259, acc.: 67.19%] [G loss: 0.611480]\n",
      "epoch:21 step:19995 [D loss: 0.500655, acc.: 71.09%] [G loss: 0.739119]\n",
      "epoch:21 step:19996 [D loss: 0.535972, acc.: 71.88%] [G loss: 0.711653]\n",
      "epoch:21 step:19997 [D loss: 0.515473, acc.: 73.44%] [G loss: 0.696293]\n",
      "epoch:21 step:19998 [D loss: 0.507953, acc.: 71.09%] [G loss: 0.671047]\n",
      "epoch:21 step:19999 [D loss: 0.534516, acc.: 73.44%] [G loss: 0.682436]\n",
      "epoch:21 step:20000 [D loss: 0.624560, acc.: 62.50%] [G loss: 0.665581]\n",
      "##############\n",
      "[2.90548844 1.19054817 6.22940967 5.06804776 4.03348702 5.67649966\n",
      " 4.58160044 4.96208571 4.67730845 4.20115345]\n",
      "##########\n",
      "epoch:21 step:20001 [D loss: 0.529938, acc.: 72.66%] [G loss: 0.517916]\n",
      "epoch:21 step:20002 [D loss: 0.519111, acc.: 69.53%] [G loss: 0.662269]\n",
      "epoch:21 step:20003 [D loss: 0.453298, acc.: 74.22%] [G loss: 0.797747]\n",
      "epoch:21 step:20004 [D loss: 0.566090, acc.: 74.22%] [G loss: 0.919610]\n",
      "epoch:21 step:20005 [D loss: 0.463335, acc.: 77.34%] [G loss: 1.078747]\n",
      "epoch:21 step:20006 [D loss: 0.519318, acc.: 72.66%] [G loss: 0.859845]\n",
      "epoch:21 step:20007 [D loss: 0.574565, acc.: 64.84%] [G loss: 0.740537]\n",
      "epoch:21 step:20008 [D loss: 0.534958, acc.: 68.75%] [G loss: 0.591560]\n",
      "epoch:21 step:20009 [D loss: 0.528257, acc.: 71.88%] [G loss: 0.586360]\n",
      "epoch:21 step:20010 [D loss: 0.487322, acc.: 78.12%] [G loss: 0.596192]\n",
      "epoch:21 step:20011 [D loss: 0.496935, acc.: 79.69%] [G loss: 0.931883]\n",
      "epoch:21 step:20012 [D loss: 0.482800, acc.: 75.00%] [G loss: 0.861704]\n",
      "epoch:21 step:20013 [D loss: 0.553952, acc.: 72.66%] [G loss: 0.702473]\n",
      "epoch:21 step:20014 [D loss: 0.544471, acc.: 65.62%] [G loss: 0.697926]\n",
      "epoch:21 step:20015 [D loss: 0.519667, acc.: 70.31%] [G loss: 0.585930]\n",
      "epoch:21 step:20016 [D loss: 0.517784, acc.: 71.09%] [G loss: 0.639582]\n",
      "epoch:21 step:20017 [D loss: 0.474531, acc.: 79.69%] [G loss: 0.708258]\n",
      "epoch:21 step:20018 [D loss: 0.577932, acc.: 67.19%] [G loss: 0.803035]\n",
      "epoch:21 step:20019 [D loss: 0.692124, acc.: 53.12%] [G loss: 0.420099]\n",
      "epoch:21 step:20020 [D loss: 0.516675, acc.: 74.22%] [G loss: 0.665820]\n",
      "epoch:21 step:20021 [D loss: 0.440529, acc.: 78.91%] [G loss: 0.951321]\n",
      "epoch:21 step:20022 [D loss: 0.599318, acc.: 61.72%] [G loss: 0.705841]\n",
      "epoch:21 step:20023 [D loss: 0.533910, acc.: 70.31%] [G loss: 0.734257]\n",
      "epoch:21 step:20024 [D loss: 0.437250, acc.: 81.25%] [G loss: 1.249274]\n",
      "epoch:21 step:20025 [D loss: 0.688891, acc.: 60.16%] [G loss: 0.829437]\n",
      "epoch:21 step:20026 [D loss: 0.702319, acc.: 60.16%] [G loss: 0.489320]\n",
      "epoch:21 step:20027 [D loss: 0.500912, acc.: 75.78%] [G loss: 0.521774]\n",
      "epoch:21 step:20028 [D loss: 0.556283, acc.: 67.19%] [G loss: 0.628460]\n",
      "epoch:21 step:20029 [D loss: 0.548276, acc.: 69.53%] [G loss: 0.847378]\n",
      "epoch:21 step:20030 [D loss: 0.575073, acc.: 70.31%] [G loss: 0.625532]\n",
      "epoch:21 step:20031 [D loss: 0.360207, acc.: 83.59%] [G loss: 0.899849]\n",
      "epoch:21 step:20032 [D loss: 0.491084, acc.: 75.78%] [G loss: 0.987362]\n",
      "epoch:21 step:20033 [D loss: 0.562625, acc.: 70.31%] [G loss: 0.730610]\n",
      "epoch:21 step:20034 [D loss: 0.416799, acc.: 79.69%] [G loss: 0.665944]\n",
      "epoch:21 step:20035 [D loss: 0.436091, acc.: 75.00%] [G loss: 0.863885]\n",
      "epoch:21 step:20036 [D loss: 0.457872, acc.: 81.25%] [G loss: 0.899484]\n",
      "epoch:21 step:20037 [D loss: 0.518811, acc.: 71.09%] [G loss: 0.678102]\n",
      "epoch:21 step:20038 [D loss: 0.492544, acc.: 75.00%] [G loss: 0.814036]\n",
      "epoch:21 step:20039 [D loss: 0.531947, acc.: 70.31%] [G loss: 0.665586]\n",
      "epoch:21 step:20040 [D loss: 0.550416, acc.: 68.75%] [G loss: 0.743500]\n",
      "epoch:21 step:20041 [D loss: 0.531833, acc.: 71.88%] [G loss: 0.654841]\n",
      "epoch:21 step:20042 [D loss: 0.535095, acc.: 70.31%] [G loss: 0.664166]\n",
      "epoch:21 step:20043 [D loss: 0.543703, acc.: 66.41%] [G loss: 0.615264]\n",
      "epoch:21 step:20044 [D loss: 0.566481, acc.: 69.53%] [G loss: 0.609327]\n",
      "epoch:21 step:20045 [D loss: 0.538986, acc.: 67.97%] [G loss: 0.746726]\n",
      "epoch:21 step:20046 [D loss: 0.509043, acc.: 74.22%] [G loss: 0.644138]\n",
      "epoch:21 step:20047 [D loss: 0.550096, acc.: 75.00%] [G loss: 0.550925]\n",
      "epoch:21 step:20048 [D loss: 0.521750, acc.: 70.31%] [G loss: 0.700508]\n",
      "epoch:21 step:20049 [D loss: 0.541406, acc.: 73.44%] [G loss: 0.643602]\n",
      "epoch:21 step:20050 [D loss: 0.488842, acc.: 72.66%] [G loss: 0.833605]\n",
      "epoch:21 step:20051 [D loss: 0.472572, acc.: 74.22%] [G loss: 0.674286]\n",
      "epoch:21 step:20052 [D loss: 0.565426, acc.: 69.53%] [G loss: 0.752925]\n",
      "epoch:21 step:20053 [D loss: 0.652373, acc.: 60.94%] [G loss: 0.609911]\n",
      "epoch:21 step:20054 [D loss: 0.542044, acc.: 67.19%] [G loss: 0.600048]\n",
      "epoch:21 step:20055 [D loss: 0.535352, acc.: 75.78%] [G loss: 0.772526]\n",
      "epoch:21 step:20056 [D loss: 0.546471, acc.: 65.62%] [G loss: 0.614741]\n",
      "epoch:21 step:20057 [D loss: 0.568398, acc.: 74.22%] [G loss: 0.564386]\n",
      "epoch:21 step:20058 [D loss: 0.441451, acc.: 82.03%] [G loss: 0.909086]\n",
      "epoch:21 step:20059 [D loss: 0.559679, acc.: 67.97%] [G loss: 0.682048]\n",
      "epoch:21 step:20060 [D loss: 0.515297, acc.: 73.44%] [G loss: 0.649431]\n",
      "epoch:21 step:20061 [D loss: 0.496339, acc.: 72.66%] [G loss: 0.630206]\n",
      "epoch:21 step:20062 [D loss: 0.482862, acc.: 78.12%] [G loss: 0.672282]\n",
      "epoch:21 step:20063 [D loss: 0.644243, acc.: 62.50%] [G loss: 0.497605]\n",
      "epoch:21 step:20064 [D loss: 0.543332, acc.: 69.53%] [G loss: 0.619404]\n",
      "epoch:21 step:20065 [D loss: 0.527681, acc.: 74.22%] [G loss: 0.767636]\n",
      "epoch:21 step:20066 [D loss: 0.557292, acc.: 71.09%] [G loss: 0.807712]\n",
      "epoch:21 step:20067 [D loss: 0.555351, acc.: 68.75%] [G loss: 0.584524]\n",
      "epoch:21 step:20068 [D loss: 0.512385, acc.: 72.66%] [G loss: 0.630527]\n",
      "epoch:21 step:20069 [D loss: 0.494864, acc.: 71.88%] [G loss: 0.666483]\n",
      "epoch:21 step:20070 [D loss: 0.563083, acc.: 67.97%] [G loss: 0.596919]\n",
      "epoch:21 step:20071 [D loss: 0.556525, acc.: 64.84%] [G loss: 0.729859]\n",
      "epoch:21 step:20072 [D loss: 0.528235, acc.: 72.66%] [G loss: 0.693311]\n",
      "epoch:21 step:20073 [D loss: 0.576805, acc.: 68.75%] [G loss: 0.632624]\n",
      "epoch:21 step:20074 [D loss: 0.559496, acc.: 65.62%] [G loss: 0.910310]\n",
      "epoch:21 step:20075 [D loss: 0.491043, acc.: 75.00%] [G loss: 0.774652]\n",
      "epoch:21 step:20076 [D loss: 0.531776, acc.: 74.22%] [G loss: 0.802947]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20077 [D loss: 0.617079, acc.: 60.94%] [G loss: 0.672327]\n",
      "epoch:21 step:20078 [D loss: 0.633100, acc.: 61.72%] [G loss: 0.466082]\n",
      "epoch:21 step:20079 [D loss: 0.509122, acc.: 73.44%] [G loss: 0.722226]\n",
      "epoch:21 step:20080 [D loss: 0.509864, acc.: 73.44%] [G loss: 0.690830]\n",
      "epoch:21 step:20081 [D loss: 0.614163, acc.: 63.28%] [G loss: 0.549078]\n",
      "epoch:21 step:20082 [D loss: 0.515374, acc.: 73.44%] [G loss: 0.618078]\n",
      "epoch:21 step:20083 [D loss: 0.510587, acc.: 71.88%] [G loss: 0.676097]\n",
      "epoch:21 step:20084 [D loss: 0.536981, acc.: 70.31%] [G loss: 0.879099]\n",
      "epoch:21 step:20085 [D loss: 0.550850, acc.: 72.66%] [G loss: 0.825352]\n",
      "epoch:21 step:20086 [D loss: 0.528135, acc.: 71.88%] [G loss: 0.645268]\n",
      "epoch:21 step:20087 [D loss: 0.560707, acc.: 71.09%] [G loss: 0.677380]\n",
      "epoch:21 step:20088 [D loss: 0.580918, acc.: 64.84%] [G loss: 0.548215]\n",
      "epoch:21 step:20089 [D loss: 0.637051, acc.: 59.38%] [G loss: 0.626767]\n",
      "epoch:21 step:20090 [D loss: 0.530009, acc.: 71.09%] [G loss: 0.520284]\n",
      "epoch:21 step:20091 [D loss: 0.551202, acc.: 64.84%] [G loss: 0.733796]\n",
      "epoch:21 step:20092 [D loss: 0.494170, acc.: 76.56%] [G loss: 0.732808]\n",
      "epoch:21 step:20093 [D loss: 0.515747, acc.: 76.56%] [G loss: 0.801345]\n",
      "epoch:21 step:20094 [D loss: 0.563676, acc.: 70.31%] [G loss: 0.725297]\n",
      "epoch:21 step:20095 [D loss: 0.615868, acc.: 63.28%] [G loss: 0.516300]\n",
      "epoch:21 step:20096 [D loss: 0.533803, acc.: 67.19%] [G loss: 0.655432]\n",
      "epoch:21 step:20097 [D loss: 0.592572, acc.: 64.06%] [G loss: 0.784303]\n",
      "epoch:21 step:20098 [D loss: 0.574250, acc.: 65.62%] [G loss: 0.582139]\n",
      "epoch:21 step:20099 [D loss: 0.605009, acc.: 63.28%] [G loss: 0.583911]\n",
      "epoch:21 step:20100 [D loss: 0.548107, acc.: 73.44%] [G loss: 0.653616]\n",
      "epoch:21 step:20101 [D loss: 0.521687, acc.: 71.88%] [G loss: 0.666711]\n",
      "epoch:21 step:20102 [D loss: 0.481140, acc.: 75.78%] [G loss: 0.745558]\n",
      "epoch:21 step:20103 [D loss: 0.513424, acc.: 72.66%] [G loss: 0.870576]\n",
      "epoch:21 step:20104 [D loss: 0.442904, acc.: 76.56%] [G loss: 0.849386]\n",
      "epoch:21 step:20105 [D loss: 0.565149, acc.: 64.84%] [G loss: 0.839332]\n",
      "epoch:21 step:20106 [D loss: 0.428952, acc.: 81.25%] [G loss: 0.746525]\n",
      "epoch:21 step:20107 [D loss: 0.502869, acc.: 75.00%] [G loss: 1.033499]\n",
      "epoch:21 step:20108 [D loss: 0.493838, acc.: 71.88%] [G loss: 0.904859]\n",
      "epoch:21 step:20109 [D loss: 0.603070, acc.: 63.28%] [G loss: 0.504125]\n",
      "epoch:21 step:20110 [D loss: 0.507918, acc.: 73.44%] [G loss: 0.709277]\n",
      "epoch:21 step:20111 [D loss: 0.516346, acc.: 73.44%] [G loss: 0.593927]\n",
      "epoch:21 step:20112 [D loss: 0.560123, acc.: 69.53%] [G loss: 0.762176]\n",
      "epoch:21 step:20113 [D loss: 0.470764, acc.: 78.12%] [G loss: 0.842139]\n",
      "epoch:21 step:20114 [D loss: 0.639096, acc.: 64.84%] [G loss: 0.680261]\n",
      "epoch:21 step:20115 [D loss: 0.579319, acc.: 67.19%] [G loss: 0.568711]\n",
      "epoch:21 step:20116 [D loss: 0.524873, acc.: 68.75%] [G loss: 0.768363]\n",
      "epoch:21 step:20117 [D loss: 0.467790, acc.: 77.34%] [G loss: 0.847566]\n",
      "epoch:21 step:20118 [D loss: 0.555655, acc.: 67.19%] [G loss: 0.854458]\n",
      "epoch:21 step:20119 [D loss: 0.557076, acc.: 68.75%] [G loss: 0.715774]\n",
      "epoch:21 step:20120 [D loss: 0.484811, acc.: 77.34%] [G loss: 0.705932]\n",
      "epoch:21 step:20121 [D loss: 0.548279, acc.: 72.66%] [G loss: 0.617401]\n",
      "epoch:21 step:20122 [D loss: 0.558526, acc.: 67.97%] [G loss: 0.652856]\n",
      "epoch:21 step:20123 [D loss: 0.496958, acc.: 74.22%] [G loss: 0.739444]\n",
      "epoch:21 step:20124 [D loss: 0.490345, acc.: 76.56%] [G loss: 0.687785]\n",
      "epoch:21 step:20125 [D loss: 0.531327, acc.: 72.66%] [G loss: 0.821548]\n",
      "epoch:21 step:20126 [D loss: 0.512701, acc.: 75.78%] [G loss: 0.749251]\n",
      "epoch:21 step:20127 [D loss: 0.515460, acc.: 75.78%] [G loss: 0.792285]\n",
      "epoch:21 step:20128 [D loss: 0.415466, acc.: 78.12%] [G loss: 0.710516]\n",
      "epoch:21 step:20129 [D loss: 0.480724, acc.: 73.44%] [G loss: 0.801783]\n",
      "epoch:21 step:20130 [D loss: 0.520151, acc.: 71.88%] [G loss: 0.831257]\n",
      "epoch:21 step:20131 [D loss: 0.538131, acc.: 78.91%] [G loss: 0.658639]\n",
      "epoch:21 step:20132 [D loss: 0.560494, acc.: 67.97%] [G loss: 0.621279]\n",
      "epoch:21 step:20133 [D loss: 0.549434, acc.: 74.22%] [G loss: 0.651676]\n",
      "epoch:21 step:20134 [D loss: 0.503336, acc.: 75.78%] [G loss: 0.685356]\n",
      "epoch:21 step:20135 [D loss: 0.611721, acc.: 66.41%] [G loss: 0.637313]\n",
      "epoch:21 step:20136 [D loss: 0.520920, acc.: 71.09%] [G loss: 0.734528]\n",
      "epoch:21 step:20137 [D loss: 0.495611, acc.: 75.00%] [G loss: 0.600780]\n",
      "epoch:21 step:20138 [D loss: 0.504409, acc.: 75.00%] [G loss: 0.637151]\n",
      "epoch:21 step:20139 [D loss: 0.571250, acc.: 67.97%] [G loss: 0.535082]\n",
      "epoch:21 step:20140 [D loss: 0.547801, acc.: 69.53%] [G loss: 0.530769]\n",
      "epoch:21 step:20141 [D loss: 0.530466, acc.: 72.66%] [G loss: 0.526176]\n",
      "epoch:21 step:20142 [D loss: 0.577529, acc.: 67.19%] [G loss: 0.486941]\n",
      "epoch:21 step:20143 [D loss: 0.562162, acc.: 65.62%] [G loss: 0.562449]\n",
      "epoch:21 step:20144 [D loss: 0.524032, acc.: 67.97%] [G loss: 0.548135]\n",
      "epoch:21 step:20145 [D loss: 0.584318, acc.: 65.62%] [G loss: 0.777103]\n",
      "epoch:21 step:20146 [D loss: 0.532833, acc.: 73.44%] [G loss: 0.753715]\n",
      "epoch:21 step:20147 [D loss: 0.508643, acc.: 73.44%] [G loss: 0.872337]\n",
      "epoch:21 step:20148 [D loss: 0.486062, acc.: 78.12%] [G loss: 0.801120]\n",
      "epoch:21 step:20149 [D loss: 0.484528, acc.: 81.25%] [G loss: 0.900600]\n",
      "epoch:21 step:20150 [D loss: 0.602316, acc.: 64.84%] [G loss: 0.728409]\n",
      "epoch:21 step:20151 [D loss: 0.550285, acc.: 65.62%] [G loss: 0.881917]\n",
      "epoch:21 step:20152 [D loss: 0.458727, acc.: 78.12%] [G loss: 0.730794]\n",
      "epoch:21 step:20153 [D loss: 0.554566, acc.: 71.88%] [G loss: 0.734991]\n",
      "epoch:21 step:20154 [D loss: 0.662544, acc.: 62.50%] [G loss: 0.745874]\n",
      "epoch:21 step:20155 [D loss: 0.565864, acc.: 73.44%] [G loss: 0.726423]\n",
      "epoch:21 step:20156 [D loss: 0.525047, acc.: 68.75%] [G loss: 0.578431]\n",
      "epoch:21 step:20157 [D loss: 0.571187, acc.: 67.97%] [G loss: 0.609470]\n",
      "epoch:21 step:20158 [D loss: 0.493279, acc.: 82.03%] [G loss: 0.577171]\n",
      "epoch:21 step:20159 [D loss: 0.602381, acc.: 64.06%] [G loss: 0.495284]\n",
      "epoch:21 step:20160 [D loss: 0.477972, acc.: 75.78%] [G loss: 0.858489]\n",
      "epoch:21 step:20161 [D loss: 0.466886, acc.: 78.91%] [G loss: 0.722134]\n",
      "epoch:21 step:20162 [D loss: 0.505931, acc.: 75.00%] [G loss: 0.787641]\n",
      "epoch:21 step:20163 [D loss: 0.593601, acc.: 66.41%] [G loss: 0.614172]\n",
      "epoch:21 step:20164 [D loss: 0.550627, acc.: 68.75%] [G loss: 0.585162]\n",
      "epoch:21 step:20165 [D loss: 0.519358, acc.: 73.44%] [G loss: 0.637983]\n",
      "epoch:21 step:20166 [D loss: 0.502644, acc.: 75.78%] [G loss: 0.791926]\n",
      "epoch:21 step:20167 [D loss: 0.599051, acc.: 62.50%] [G loss: 0.689407]\n",
      "epoch:21 step:20168 [D loss: 0.553187, acc.: 71.09%] [G loss: 0.641033]\n",
      "epoch:21 step:20169 [D loss: 0.563255, acc.: 67.97%] [G loss: 0.646616]\n",
      "epoch:21 step:20170 [D loss: 0.541623, acc.: 73.44%] [G loss: 0.632226]\n",
      "epoch:21 step:20171 [D loss: 0.571134, acc.: 67.97%] [G loss: 0.509662]\n",
      "epoch:21 step:20172 [D loss: 0.513010, acc.: 75.00%] [G loss: 0.705985]\n",
      "epoch:21 step:20173 [D loss: 0.536758, acc.: 72.66%] [G loss: 0.724319]\n",
      "epoch:21 step:20174 [D loss: 0.544014, acc.: 71.88%] [G loss: 0.703665]\n",
      "epoch:21 step:20175 [D loss: 0.508822, acc.: 72.66%] [G loss: 0.784439]\n",
      "epoch:21 step:20176 [D loss: 0.504832, acc.: 73.44%] [G loss: 0.833521]\n",
      "epoch:21 step:20177 [D loss: 0.554664, acc.: 71.88%] [G loss: 0.591354]\n",
      "epoch:21 step:20178 [D loss: 0.586125, acc.: 70.31%] [G loss: 0.729905]\n",
      "epoch:21 step:20179 [D loss: 0.558168, acc.: 67.19%] [G loss: 0.529822]\n",
      "epoch:21 step:20180 [D loss: 0.529795, acc.: 72.66%] [G loss: 0.541419]\n",
      "epoch:21 step:20181 [D loss: 0.486540, acc.: 72.66%] [G loss: 0.708197]\n",
      "epoch:21 step:20182 [D loss: 0.466808, acc.: 78.91%] [G loss: 0.854899]\n",
      "epoch:21 step:20183 [D loss: 0.467506, acc.: 75.78%] [G loss: 0.939186]\n",
      "epoch:21 step:20184 [D loss: 0.498654, acc.: 76.56%] [G loss: 0.899508]\n",
      "epoch:21 step:20185 [D loss: 0.423231, acc.: 81.25%] [G loss: 0.824883]\n",
      "epoch:21 step:20186 [D loss: 0.509423, acc.: 73.44%] [G loss: 0.800593]\n",
      "epoch:21 step:20187 [D loss: 0.584568, acc.: 67.97%] [G loss: 0.709411]\n",
      "epoch:21 step:20188 [D loss: 0.660361, acc.: 60.16%] [G loss: 0.564821]\n",
      "epoch:21 step:20189 [D loss: 0.560824, acc.: 67.19%] [G loss: 0.573463]\n",
      "epoch:21 step:20190 [D loss: 0.534302, acc.: 74.22%] [G loss: 0.562844]\n",
      "epoch:21 step:20191 [D loss: 0.491951, acc.: 75.00%] [G loss: 0.739837]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20192 [D loss: 0.508700, acc.: 75.78%] [G loss: 0.552775]\n",
      "epoch:21 step:20193 [D loss: 0.485273, acc.: 77.34%] [G loss: 0.754681]\n",
      "epoch:21 step:20194 [D loss: 0.476234, acc.: 74.22%] [G loss: 0.892261]\n",
      "epoch:21 step:20195 [D loss: 0.552485, acc.: 67.97%] [G loss: 0.698558]\n",
      "epoch:21 step:20196 [D loss: 0.498980, acc.: 72.66%] [G loss: 0.755656]\n",
      "epoch:21 step:20197 [D loss: 0.492778, acc.: 72.66%] [G loss: 0.826065]\n",
      "epoch:21 step:20198 [D loss: 0.512859, acc.: 74.22%] [G loss: 0.794548]\n",
      "epoch:21 step:20199 [D loss: 0.494740, acc.: 76.56%] [G loss: 0.677461]\n",
      "epoch:21 step:20200 [D loss: 0.552201, acc.: 71.88%] [G loss: 0.786100]\n",
      "##############\n",
      "[2.81971051 0.87035915 6.07469429 4.90780774 3.84128456 5.63322615\n",
      " 4.3289106  4.78519386 4.74107866 4.18876718]\n",
      "##########\n",
      "epoch:21 step:20201 [D loss: 0.556688, acc.: 64.06%] [G loss: 0.854337]\n",
      "epoch:21 step:20202 [D loss: 0.613260, acc.: 69.53%] [G loss: 0.857563]\n",
      "epoch:21 step:20203 [D loss: 0.497390, acc.: 72.66%] [G loss: 0.725479]\n",
      "epoch:21 step:20204 [D loss: 0.614030, acc.: 61.72%] [G loss: 0.647768]\n",
      "epoch:21 step:20205 [D loss: 0.673331, acc.: 60.16%] [G loss: 0.565358]\n",
      "epoch:21 step:20206 [D loss: 0.577148, acc.: 64.84%] [G loss: 0.697812]\n",
      "epoch:21 step:20207 [D loss: 0.496503, acc.: 72.66%] [G loss: 0.714942]\n",
      "epoch:21 step:20208 [D loss: 0.545101, acc.: 75.00%] [G loss: 0.617810]\n",
      "epoch:21 step:20209 [D loss: 0.540902, acc.: 70.31%] [G loss: 0.699351]\n",
      "epoch:21 step:20210 [D loss: 0.552505, acc.: 65.62%] [G loss: 0.587604]\n",
      "epoch:21 step:20211 [D loss: 0.489506, acc.: 73.44%] [G loss: 0.708201]\n",
      "epoch:21 step:20212 [D loss: 0.651240, acc.: 60.16%] [G loss: 0.491659]\n",
      "epoch:21 step:20213 [D loss: 0.519225, acc.: 72.66%] [G loss: 0.648368]\n",
      "epoch:21 step:20214 [D loss: 0.558839, acc.: 66.41%] [G loss: 0.598634]\n",
      "epoch:21 step:20215 [D loss: 0.539380, acc.: 68.75%] [G loss: 0.459816]\n",
      "epoch:21 step:20216 [D loss: 0.502282, acc.: 74.22%] [G loss: 0.600134]\n",
      "epoch:21 step:20217 [D loss: 0.570731, acc.: 68.75%] [G loss: 0.643115]\n",
      "epoch:21 step:20218 [D loss: 0.568961, acc.: 68.75%] [G loss: 0.617783]\n",
      "epoch:21 step:20219 [D loss: 0.611057, acc.: 67.19%] [G loss: 0.665751]\n",
      "epoch:21 step:20220 [D loss: 0.545577, acc.: 69.53%] [G loss: 0.677489]\n",
      "epoch:21 step:20221 [D loss: 0.516805, acc.: 71.09%] [G loss: 0.490034]\n",
      "epoch:21 step:20222 [D loss: 0.539125, acc.: 70.31%] [G loss: 0.596482]\n",
      "epoch:21 step:20223 [D loss: 0.501978, acc.: 73.44%] [G loss: 0.723024]\n",
      "epoch:21 step:20224 [D loss: 0.519732, acc.: 74.22%] [G loss: 0.728902]\n",
      "epoch:21 step:20225 [D loss: 0.460216, acc.: 78.12%] [G loss: 0.706896]\n",
      "epoch:21 step:20226 [D loss: 0.507966, acc.: 76.56%] [G loss: 0.697650]\n",
      "epoch:21 step:20227 [D loss: 0.508628, acc.: 76.56%] [G loss: 0.610569]\n",
      "epoch:21 step:20228 [D loss: 0.522806, acc.: 71.09%] [G loss: 0.534720]\n",
      "epoch:21 step:20229 [D loss: 0.509187, acc.: 75.00%] [G loss: 0.580693]\n",
      "epoch:21 step:20230 [D loss: 0.530406, acc.: 71.09%] [G loss: 0.749428]\n",
      "epoch:21 step:20231 [D loss: 0.459981, acc.: 78.91%] [G loss: 0.820196]\n",
      "epoch:21 step:20232 [D loss: 0.426752, acc.: 81.25%] [G loss: 0.815857]\n",
      "epoch:21 step:20233 [D loss: 0.605522, acc.: 68.75%] [G loss: 0.936819]\n",
      "epoch:21 step:20234 [D loss: 0.512563, acc.: 71.09%] [G loss: 0.804583]\n",
      "epoch:21 step:20235 [D loss: 0.506456, acc.: 78.91%] [G loss: 0.664245]\n",
      "epoch:21 step:20236 [D loss: 0.585800, acc.: 64.06%] [G loss: 0.606174]\n",
      "epoch:21 step:20237 [D loss: 0.606097, acc.: 63.28%] [G loss: 0.702446]\n",
      "epoch:21 step:20238 [D loss: 0.583921, acc.: 70.31%] [G loss: 0.635170]\n",
      "epoch:21 step:20239 [D loss: 0.560919, acc.: 62.50%] [G loss: 0.607746]\n",
      "epoch:21 step:20240 [D loss: 0.598702, acc.: 61.72%] [G loss: 0.595846]\n",
      "epoch:21 step:20241 [D loss: 0.509866, acc.: 74.22%] [G loss: 0.640474]\n",
      "epoch:21 step:20242 [D loss: 0.530295, acc.: 73.44%] [G loss: 0.766324]\n",
      "epoch:21 step:20243 [D loss: 0.700186, acc.: 60.94%] [G loss: 0.666543]\n",
      "epoch:21 step:20244 [D loss: 0.522317, acc.: 71.09%] [G loss: 0.645239]\n",
      "epoch:21 step:20245 [D loss: 0.513211, acc.: 80.47%] [G loss: 0.685194]\n",
      "epoch:21 step:20246 [D loss: 0.515011, acc.: 69.53%] [G loss: 0.565554]\n",
      "epoch:21 step:20247 [D loss: 0.558508, acc.: 70.31%] [G loss: 0.668430]\n",
      "epoch:21 step:20248 [D loss: 0.507334, acc.: 71.88%] [G loss: 0.731124]\n",
      "epoch:21 step:20249 [D loss: 0.548745, acc.: 73.44%] [G loss: 0.726377]\n",
      "epoch:21 step:20250 [D loss: 0.540184, acc.: 72.66%] [G loss: 0.814888]\n",
      "epoch:21 step:20251 [D loss: 0.494136, acc.: 76.56%] [G loss: 0.768972]\n",
      "epoch:21 step:20252 [D loss: 0.511216, acc.: 75.78%] [G loss: 0.958693]\n",
      "epoch:21 step:20253 [D loss: 0.587615, acc.: 71.09%] [G loss: 0.934142]\n",
      "epoch:21 step:20254 [D loss: 0.521792, acc.: 71.88%] [G loss: 0.790399]\n",
      "epoch:21 step:20255 [D loss: 0.608079, acc.: 63.28%] [G loss: 0.498189]\n",
      "epoch:21 step:20256 [D loss: 0.513984, acc.: 67.97%] [G loss: 0.716169]\n",
      "epoch:21 step:20257 [D loss: 0.557724, acc.: 72.66%] [G loss: 0.648090]\n",
      "epoch:21 step:20258 [D loss: 0.566218, acc.: 68.75%] [G loss: 0.591933]\n",
      "epoch:21 step:20259 [D loss: 0.459301, acc.: 78.91%] [G loss: 0.965344]\n",
      "epoch:21 step:20260 [D loss: 0.549241, acc.: 71.88%] [G loss: 0.840781]\n",
      "epoch:21 step:20261 [D loss: 0.563895, acc.: 67.97%] [G loss: 0.686917]\n",
      "epoch:21 step:20262 [D loss: 0.529056, acc.: 68.75%] [G loss: 0.702930]\n",
      "epoch:21 step:20263 [D loss: 0.603781, acc.: 64.84%] [G loss: 0.612115]\n",
      "epoch:21 step:20264 [D loss: 0.578464, acc.: 68.75%] [G loss: 0.489866]\n",
      "epoch:21 step:20265 [D loss: 0.511728, acc.: 75.00%] [G loss: 0.693558]\n",
      "epoch:21 step:20266 [D loss: 0.509375, acc.: 66.41%] [G loss: 0.925908]\n",
      "epoch:21 step:20267 [D loss: 0.543473, acc.: 72.66%] [G loss: 0.623660]\n",
      "epoch:21 step:20268 [D loss: 0.541792, acc.: 71.09%] [G loss: 0.684370]\n",
      "epoch:21 step:20269 [D loss: 0.468832, acc.: 79.69%] [G loss: 0.630710]\n",
      "epoch:21 step:20270 [D loss: 0.543515, acc.: 67.97%] [G loss: 0.747393]\n",
      "epoch:21 step:20271 [D loss: 0.530193, acc.: 67.97%] [G loss: 0.664346]\n",
      "epoch:21 step:20272 [D loss: 0.516065, acc.: 75.78%] [G loss: 0.643065]\n",
      "epoch:21 step:20273 [D loss: 0.494250, acc.: 73.44%] [G loss: 0.613896]\n",
      "epoch:21 step:20274 [D loss: 0.487586, acc.: 73.44%] [G loss: 0.802809]\n",
      "epoch:21 step:20275 [D loss: 0.580830, acc.: 69.53%] [G loss: 0.769807]\n",
      "epoch:21 step:20276 [D loss: 0.478365, acc.: 75.00%] [G loss: 0.763896]\n",
      "epoch:21 step:20277 [D loss: 0.575408, acc.: 70.31%] [G loss: 0.733410]\n",
      "epoch:21 step:20278 [D loss: 0.482497, acc.: 74.22%] [G loss: 0.762064]\n",
      "epoch:21 step:20279 [D loss: 0.578705, acc.: 71.88%] [G loss: 0.748645]\n",
      "epoch:21 step:20280 [D loss: 0.461082, acc.: 78.91%] [G loss: 0.877489]\n",
      "epoch:21 step:20281 [D loss: 0.544332, acc.: 69.53%] [G loss: 0.808823]\n",
      "epoch:21 step:20282 [D loss: 0.438711, acc.: 80.47%] [G loss: 0.881285]\n",
      "epoch:21 step:20283 [D loss: 0.590051, acc.: 67.19%] [G loss: 0.652292]\n",
      "epoch:21 step:20284 [D loss: 0.583458, acc.: 67.97%] [G loss: 0.667051]\n",
      "epoch:21 step:20285 [D loss: 0.567087, acc.: 67.19%] [G loss: 0.574120]\n",
      "epoch:21 step:20286 [D loss: 0.519162, acc.: 69.53%] [G loss: 0.639350]\n",
      "epoch:21 step:20287 [D loss: 0.536134, acc.: 71.88%] [G loss: 0.697185]\n",
      "epoch:21 step:20288 [D loss: 0.523528, acc.: 72.66%] [G loss: 0.587411]\n",
      "epoch:21 step:20289 [D loss: 0.545616, acc.: 70.31%] [G loss: 0.626437]\n",
      "epoch:21 step:20290 [D loss: 0.481816, acc.: 75.78%] [G loss: 0.777932]\n",
      "epoch:21 step:20291 [D loss: 0.586905, acc.: 66.41%] [G loss: 0.678650]\n",
      "epoch:21 step:20292 [D loss: 0.556218, acc.: 65.62%] [G loss: 0.636594]\n",
      "epoch:21 step:20293 [D loss: 0.589497, acc.: 69.53%] [G loss: 0.760054]\n",
      "epoch:21 step:20294 [D loss: 0.529036, acc.: 72.66%] [G loss: 0.726170]\n",
      "epoch:21 step:20295 [D loss: 0.522677, acc.: 67.97%] [G loss: 0.704146]\n",
      "epoch:21 step:20296 [D loss: 0.495860, acc.: 74.22%] [G loss: 0.688337]\n",
      "epoch:21 step:20297 [D loss: 0.545710, acc.: 70.31%] [G loss: 0.750989]\n",
      "epoch:21 step:20298 [D loss: 0.565762, acc.: 68.75%] [G loss: 0.593254]\n",
      "epoch:21 step:20299 [D loss: 0.569235, acc.: 70.31%] [G loss: 0.623635]\n",
      "epoch:21 step:20300 [D loss: 0.477234, acc.: 74.22%] [G loss: 0.752578]\n",
      "epoch:21 step:20301 [D loss: 0.446316, acc.: 80.47%] [G loss: 0.953356]\n",
      "epoch:21 step:20302 [D loss: 0.627158, acc.: 62.50%] [G loss: 0.615565]\n",
      "epoch:21 step:20303 [D loss: 0.550184, acc.: 68.75%] [G loss: 0.559514]\n",
      "epoch:21 step:20304 [D loss: 0.511178, acc.: 73.44%] [G loss: 0.792185]\n",
      "epoch:21 step:20305 [D loss: 0.566403, acc.: 70.31%] [G loss: 0.582050]\n",
      "epoch:21 step:20306 [D loss: 0.485541, acc.: 75.78%] [G loss: 0.646086]\n",
      "epoch:21 step:20307 [D loss: 0.481272, acc.: 78.91%] [G loss: 0.779508]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20308 [D loss: 0.516617, acc.: 78.12%] [G loss: 0.737713]\n",
      "epoch:21 step:20309 [D loss: 0.511610, acc.: 71.09%] [G loss: 0.642759]\n",
      "epoch:21 step:20310 [D loss: 0.478404, acc.: 78.12%] [G loss: 0.733882]\n",
      "epoch:21 step:20311 [D loss: 0.448624, acc.: 79.69%] [G loss: 0.735226]\n",
      "epoch:21 step:20312 [D loss: 0.492845, acc.: 72.66%] [G loss: 0.776601]\n",
      "epoch:21 step:20313 [D loss: 0.575624, acc.: 64.06%] [G loss: 0.699561]\n",
      "epoch:21 step:20314 [D loss: 0.548700, acc.: 69.53%] [G loss: 0.668522]\n",
      "epoch:21 step:20315 [D loss: 0.515888, acc.: 72.66%] [G loss: 0.712426]\n",
      "epoch:21 step:20316 [D loss: 0.479183, acc.: 77.34%] [G loss: 0.647519]\n",
      "epoch:21 step:20317 [D loss: 0.505813, acc.: 75.78%] [G loss: 0.920660]\n",
      "epoch:21 step:20318 [D loss: 0.499326, acc.: 70.31%] [G loss: 0.741380]\n",
      "epoch:21 step:20319 [D loss: 0.518496, acc.: 71.88%] [G loss: 0.978248]\n",
      "epoch:21 step:20320 [D loss: 0.525772, acc.: 71.88%] [G loss: 0.815893]\n",
      "epoch:21 step:20321 [D loss: 0.571653, acc.: 63.28%] [G loss: 0.629148]\n",
      "epoch:21 step:20322 [D loss: 0.501036, acc.: 75.00%] [G loss: 0.698915]\n",
      "epoch:21 step:20323 [D loss: 0.527447, acc.: 72.66%] [G loss: 0.673756]\n",
      "epoch:21 step:20324 [D loss: 0.458472, acc.: 79.69%] [G loss: 0.804126]\n",
      "epoch:21 step:20325 [D loss: 0.379271, acc.: 83.59%] [G loss: 0.937255]\n",
      "epoch:21 step:20326 [D loss: 0.468609, acc.: 77.34%] [G loss: 0.997037]\n",
      "epoch:21 step:20327 [D loss: 0.528492, acc.: 74.22%] [G loss: 1.057508]\n",
      "epoch:21 step:20328 [D loss: 0.498777, acc.: 73.44%] [G loss: 0.885816]\n",
      "epoch:21 step:20329 [D loss: 0.604778, acc.: 70.31%] [G loss: 0.713145]\n",
      "epoch:21 step:20330 [D loss: 0.562286, acc.: 69.53%] [G loss: 0.769324]\n",
      "epoch:21 step:20331 [D loss: 0.455752, acc.: 78.12%] [G loss: 0.854060]\n",
      "epoch:21 step:20332 [D loss: 0.512890, acc.: 76.56%] [G loss: 0.705739]\n",
      "epoch:21 step:20333 [D loss: 0.538433, acc.: 75.00%] [G loss: 0.599348]\n",
      "epoch:21 step:20334 [D loss: 0.496653, acc.: 71.88%] [G loss: 0.793398]\n",
      "epoch:21 step:20335 [D loss: 0.616151, acc.: 66.41%] [G loss: 0.613247]\n",
      "epoch:21 step:20336 [D loss: 0.507316, acc.: 75.78%] [G loss: 0.806640]\n",
      "epoch:21 step:20337 [D loss: 0.530803, acc.: 69.53%] [G loss: 0.754368]\n",
      "epoch:21 step:20338 [D loss: 0.494024, acc.: 73.44%] [G loss: 0.952154]\n",
      "epoch:21 step:20339 [D loss: 0.552970, acc.: 69.53%] [G loss: 0.738177]\n",
      "epoch:21 step:20340 [D loss: 0.521738, acc.: 73.44%] [G loss: 0.800162]\n",
      "epoch:21 step:20341 [D loss: 0.528633, acc.: 66.41%] [G loss: 0.886656]\n",
      "epoch:21 step:20342 [D loss: 0.569810, acc.: 66.41%] [G loss: 1.222330]\n",
      "epoch:21 step:20343 [D loss: 0.534275, acc.: 71.88%] [G loss: 0.897533]\n",
      "epoch:21 step:20344 [D loss: 0.511397, acc.: 78.91%] [G loss: 0.847318]\n",
      "epoch:21 step:20345 [D loss: 0.544052, acc.: 71.88%] [G loss: 0.634189]\n",
      "epoch:21 step:20346 [D loss: 0.541091, acc.: 68.75%] [G loss: 0.618029]\n",
      "epoch:21 step:20347 [D loss: 0.520326, acc.: 74.22%] [G loss: 0.745999]\n",
      "epoch:21 step:20348 [D loss: 0.611461, acc.: 63.28%] [G loss: 0.586507]\n",
      "epoch:21 step:20349 [D loss: 0.516794, acc.: 72.66%] [G loss: 0.625121]\n",
      "epoch:21 step:20350 [D loss: 0.569535, acc.: 64.84%] [G loss: 0.742101]\n",
      "epoch:21 step:20351 [D loss: 0.517776, acc.: 79.69%] [G loss: 0.764932]\n",
      "epoch:21 step:20352 [D loss: 0.642808, acc.: 60.94%] [G loss: 0.581234]\n",
      "epoch:21 step:20353 [D loss: 0.526016, acc.: 70.31%] [G loss: 0.771575]\n",
      "epoch:21 step:20354 [D loss: 0.463720, acc.: 77.34%] [G loss: 0.799415]\n",
      "epoch:21 step:20355 [D loss: 0.560362, acc.: 71.09%] [G loss: 0.798823]\n",
      "epoch:21 step:20356 [D loss: 0.540852, acc.: 70.31%] [G loss: 0.801654]\n",
      "epoch:21 step:20357 [D loss: 0.520836, acc.: 75.00%] [G loss: 0.592564]\n",
      "epoch:21 step:20358 [D loss: 0.490213, acc.: 73.44%] [G loss: 0.651539]\n",
      "epoch:21 step:20359 [D loss: 0.529437, acc.: 67.19%] [G loss: 0.703069]\n",
      "epoch:21 step:20360 [D loss: 0.520413, acc.: 71.09%] [G loss: 0.765130]\n",
      "epoch:21 step:20361 [D loss: 0.608421, acc.: 64.06%] [G loss: 0.501204]\n",
      "epoch:21 step:20362 [D loss: 0.520977, acc.: 75.78%] [G loss: 0.477308]\n",
      "epoch:21 step:20363 [D loss: 0.584413, acc.: 65.62%] [G loss: 0.531259]\n",
      "epoch:21 step:20364 [D loss: 0.517429, acc.: 75.00%] [G loss: 0.512484]\n",
      "epoch:21 step:20365 [D loss: 0.522524, acc.: 74.22%] [G loss: 0.496445]\n",
      "epoch:21 step:20366 [D loss: 0.558651, acc.: 72.66%] [G loss: 0.567443]\n",
      "epoch:21 step:20367 [D loss: 0.503969, acc.: 72.66%] [G loss: 0.802044]\n",
      "epoch:21 step:20368 [D loss: 0.483218, acc.: 75.00%] [G loss: 0.739615]\n",
      "epoch:21 step:20369 [D loss: 0.596792, acc.: 65.62%] [G loss: 0.623411]\n",
      "epoch:21 step:20370 [D loss: 0.524265, acc.: 71.88%] [G loss: 0.775817]\n",
      "epoch:21 step:20371 [D loss: 0.494777, acc.: 76.56%] [G loss: 0.914885]\n",
      "epoch:21 step:20372 [D loss: 0.484024, acc.: 77.34%] [G loss: 0.711604]\n",
      "epoch:21 step:20373 [D loss: 0.610597, acc.: 60.94%] [G loss: 0.598779]\n",
      "epoch:21 step:20374 [D loss: 0.562233, acc.: 63.28%] [G loss: 0.495111]\n",
      "epoch:21 step:20375 [D loss: 0.560890, acc.: 71.09%] [G loss: 0.708907]\n",
      "epoch:21 step:20376 [D loss: 0.525787, acc.: 67.97%] [G loss: 0.589347]\n",
      "epoch:21 step:20377 [D loss: 0.521448, acc.: 75.78%] [G loss: 0.707885]\n",
      "epoch:21 step:20378 [D loss: 0.497766, acc.: 73.44%] [G loss: 0.915742]\n",
      "epoch:21 step:20379 [D loss: 0.629403, acc.: 64.06%] [G loss: 0.824384]\n",
      "epoch:21 step:20380 [D loss: 0.644763, acc.: 60.16%] [G loss: 0.533743]\n",
      "epoch:21 step:20381 [D loss: 0.605242, acc.: 70.31%] [G loss: 0.663222]\n",
      "epoch:21 step:20382 [D loss: 0.557338, acc.: 68.75%] [G loss: 0.580314]\n",
      "epoch:21 step:20383 [D loss: 0.513202, acc.: 71.88%] [G loss: 0.675813]\n",
      "epoch:21 step:20384 [D loss: 0.516305, acc.: 70.31%] [G loss: 0.684480]\n",
      "epoch:21 step:20385 [D loss: 0.478107, acc.: 75.00%] [G loss: 0.763387]\n",
      "epoch:21 step:20386 [D loss: 0.468520, acc.: 73.44%] [G loss: 0.874034]\n",
      "epoch:21 step:20387 [D loss: 0.555382, acc.: 66.41%] [G loss: 0.567182]\n",
      "epoch:21 step:20388 [D loss: 0.571762, acc.: 67.19%] [G loss: 0.652772]\n",
      "epoch:21 step:20389 [D loss: 0.525916, acc.: 72.66%] [G loss: 0.766408]\n",
      "epoch:21 step:20390 [D loss: 0.609652, acc.: 67.19%] [G loss: 0.687650]\n",
      "epoch:21 step:20391 [D loss: 0.540904, acc.: 70.31%] [G loss: 0.687023]\n",
      "epoch:21 step:20392 [D loss: 0.547929, acc.: 75.00%] [G loss: 0.744986]\n",
      "epoch:21 step:20393 [D loss: 0.629823, acc.: 64.84%] [G loss: 0.563625]\n",
      "epoch:21 step:20394 [D loss: 0.567272, acc.: 67.97%] [G loss: 0.519016]\n",
      "epoch:21 step:20395 [D loss: 0.523638, acc.: 71.88%] [G loss: 0.590475]\n",
      "epoch:21 step:20396 [D loss: 0.494665, acc.: 78.12%] [G loss: 0.577785]\n",
      "epoch:21 step:20397 [D loss: 0.610518, acc.: 66.41%] [G loss: 0.579119]\n",
      "epoch:21 step:20398 [D loss: 0.543847, acc.: 71.88%] [G loss: 0.590889]\n",
      "epoch:21 step:20399 [D loss: 0.523197, acc.: 74.22%] [G loss: 0.577587]\n",
      "epoch:21 step:20400 [D loss: 0.578388, acc.: 69.53%] [G loss: 0.555311]\n",
      "##############\n",
      "[2.79092886 1.17152495 6.15510501 4.89653772 4.08039093 5.56952332\n",
      " 4.49750484 4.89406855 4.7308778  4.32204086]\n",
      "##########\n",
      "epoch:21 step:20401 [D loss: 0.572828, acc.: 69.53%] [G loss: 0.673849]\n",
      "epoch:21 step:20402 [D loss: 0.510915, acc.: 75.78%] [G loss: 0.607783]\n",
      "epoch:21 step:20403 [D loss: 0.506002, acc.: 74.22%] [G loss: 0.672665]\n",
      "epoch:21 step:20404 [D loss: 0.559947, acc.: 67.19%] [G loss: 0.807107]\n",
      "epoch:21 step:20405 [D loss: 0.526507, acc.: 71.88%] [G loss: 0.637509]\n",
      "epoch:21 step:20406 [D loss: 0.593628, acc.: 69.53%] [G loss: 0.603650]\n",
      "epoch:21 step:20407 [D loss: 0.562324, acc.: 73.44%] [G loss: 0.520325]\n",
      "epoch:21 step:20408 [D loss: 0.530832, acc.: 67.97%] [G loss: 0.552983]\n",
      "epoch:21 step:20409 [D loss: 0.559164, acc.: 67.19%] [G loss: 0.553654]\n",
      "epoch:21 step:20410 [D loss: 0.551603, acc.: 70.31%] [G loss: 0.665231]\n",
      "epoch:21 step:20411 [D loss: 0.536061, acc.: 73.44%] [G loss: 0.775887]\n",
      "epoch:21 step:20412 [D loss: 0.528577, acc.: 69.53%] [G loss: 0.665190]\n",
      "epoch:21 step:20413 [D loss: 0.507574, acc.: 75.00%] [G loss: 0.580992]\n",
      "epoch:21 step:20414 [D loss: 0.550481, acc.: 67.97%] [G loss: 0.767449]\n",
      "epoch:21 step:20415 [D loss: 0.567251, acc.: 68.75%] [G loss: 0.549996]\n",
      "epoch:21 step:20416 [D loss: 0.634587, acc.: 61.72%] [G loss: 0.564764]\n",
      "epoch:21 step:20417 [D loss: 0.642304, acc.: 61.72%] [G loss: 0.500804]\n",
      "epoch:21 step:20418 [D loss: 0.566157, acc.: 69.53%] [G loss: 0.495085]\n",
      "epoch:21 step:20419 [D loss: 0.497945, acc.: 80.47%] [G loss: 0.659391]\n",
      "epoch:21 step:20420 [D loss: 0.491966, acc.: 73.44%] [G loss: 0.701116]\n",
      "epoch:21 step:20421 [D loss: 0.569709, acc.: 71.09%] [G loss: 0.682321]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20422 [D loss: 0.582586, acc.: 67.19%] [G loss: 0.583437]\n",
      "epoch:21 step:20423 [D loss: 0.467133, acc.: 76.56%] [G loss: 0.651560]\n",
      "epoch:21 step:20424 [D loss: 0.457033, acc.: 76.56%] [G loss: 0.756846]\n",
      "epoch:21 step:20425 [D loss: 0.515686, acc.: 71.88%] [G loss: 0.641767]\n",
      "epoch:21 step:20426 [D loss: 0.507713, acc.: 74.22%] [G loss: 0.711114]\n",
      "epoch:21 step:20427 [D loss: 0.470613, acc.: 77.34%] [G loss: 0.801921]\n",
      "epoch:21 step:20428 [D loss: 0.495630, acc.: 76.56%] [G loss: 0.808045]\n",
      "epoch:21 step:20429 [D loss: 0.573366, acc.: 68.75%] [G loss: 0.674373]\n",
      "epoch:21 step:20430 [D loss: 0.539954, acc.: 69.53%] [G loss: 0.903904]\n",
      "epoch:21 step:20431 [D loss: 0.530073, acc.: 72.66%] [G loss: 0.757898]\n",
      "epoch:21 step:20432 [D loss: 0.494182, acc.: 71.88%] [G loss: 0.707455]\n",
      "epoch:21 step:20433 [D loss: 0.534204, acc.: 67.19%] [G loss: 0.541269]\n",
      "epoch:21 step:20434 [D loss: 0.586074, acc.: 66.41%] [G loss: 0.613100]\n",
      "epoch:21 step:20435 [D loss: 0.537299, acc.: 74.22%] [G loss: 0.579620]\n",
      "epoch:21 step:20436 [D loss: 0.529593, acc.: 72.66%] [G loss: 0.525763]\n",
      "epoch:21 step:20437 [D loss: 0.516026, acc.: 71.88%] [G loss: 0.667174]\n",
      "epoch:21 step:20438 [D loss: 0.565998, acc.: 64.84%] [G loss: 0.571166]\n",
      "epoch:21 step:20439 [D loss: 0.551182, acc.: 71.88%] [G loss: 0.545160]\n",
      "epoch:21 step:20440 [D loss: 0.518135, acc.: 69.53%] [G loss: 0.568302]\n",
      "epoch:21 step:20441 [D loss: 0.536136, acc.: 69.53%] [G loss: 0.663158]\n",
      "epoch:21 step:20442 [D loss: 0.578802, acc.: 64.84%] [G loss: 0.582923]\n",
      "epoch:21 step:20443 [D loss: 0.623369, acc.: 64.84%] [G loss: 0.428468]\n",
      "epoch:21 step:20444 [D loss: 0.499334, acc.: 71.88%] [G loss: 0.626792]\n",
      "epoch:21 step:20445 [D loss: 0.479404, acc.: 76.56%] [G loss: 0.720291]\n",
      "epoch:21 step:20446 [D loss: 0.538029, acc.: 77.34%] [G loss: 0.946270]\n",
      "epoch:21 step:20447 [D loss: 0.656234, acc.: 64.06%] [G loss: 0.861556]\n",
      "epoch:21 step:20448 [D loss: 0.526979, acc.: 71.88%] [G loss: 0.818249]\n",
      "epoch:21 step:20449 [D loss: 0.553315, acc.: 69.53%] [G loss: 0.716237]\n",
      "epoch:21 step:20450 [D loss: 0.553941, acc.: 69.53%] [G loss: 0.665972]\n",
      "epoch:21 step:20451 [D loss: 0.555142, acc.: 74.22%] [G loss: 0.659214]\n",
      "epoch:21 step:20452 [D loss: 0.528629, acc.: 68.75%] [G loss: 0.704723]\n",
      "epoch:21 step:20453 [D loss: 0.541079, acc.: 71.09%] [G loss: 0.684802]\n",
      "epoch:21 step:20454 [D loss: 0.562933, acc.: 67.97%] [G loss: 0.577699]\n",
      "epoch:21 step:20455 [D loss: 0.532095, acc.: 74.22%] [G loss: 0.573313]\n",
      "epoch:21 step:20456 [D loss: 0.524124, acc.: 75.00%] [G loss: 0.701305]\n",
      "epoch:21 step:20457 [D loss: 0.524163, acc.: 73.44%] [G loss: 0.596354]\n",
      "epoch:21 step:20458 [D loss: 0.459522, acc.: 80.47%] [G loss: 0.927556]\n",
      "epoch:21 step:20459 [D loss: 0.513969, acc.: 75.78%] [G loss: 0.918896]\n",
      "epoch:21 step:20460 [D loss: 0.541176, acc.: 70.31%] [G loss: 0.789188]\n",
      "epoch:21 step:20461 [D loss: 0.635595, acc.: 60.94%] [G loss: 0.750439]\n",
      "epoch:21 step:20462 [D loss: 0.526103, acc.: 73.44%] [G loss: 0.604078]\n",
      "epoch:21 step:20463 [D loss: 0.478908, acc.: 78.91%] [G loss: 0.608834]\n",
      "epoch:21 step:20464 [D loss: 0.576731, acc.: 68.75%] [G loss: 0.752816]\n",
      "epoch:21 step:20465 [D loss: 0.644383, acc.: 57.81%] [G loss: 0.544599]\n",
      "epoch:21 step:20466 [D loss: 0.541237, acc.: 73.44%] [G loss: 0.621443]\n",
      "epoch:21 step:20467 [D loss: 0.526686, acc.: 69.53%] [G loss: 0.742580]\n",
      "epoch:21 step:20468 [D loss: 0.592366, acc.: 70.31%] [G loss: 0.565615]\n",
      "epoch:21 step:20469 [D loss: 0.437474, acc.: 79.69%] [G loss: 0.739450]\n",
      "epoch:21 step:20470 [D loss: 0.556246, acc.: 71.09%] [G loss: 0.712961]\n",
      "epoch:21 step:20471 [D loss: 0.579388, acc.: 67.19%] [G loss: 0.756166]\n",
      "epoch:21 step:20472 [D loss: 0.507549, acc.: 68.75%] [G loss: 0.895723]\n",
      "epoch:21 step:20473 [D loss: 0.503382, acc.: 72.66%] [G loss: 0.895901]\n",
      "epoch:21 step:20474 [D loss: 0.567374, acc.: 65.62%] [G loss: 0.930802]\n",
      "epoch:21 step:20475 [D loss: 0.541830, acc.: 70.31%] [G loss: 0.769368]\n",
      "epoch:21 step:20476 [D loss: 0.584918, acc.: 71.09%] [G loss: 0.842243]\n",
      "epoch:21 step:20477 [D loss: 0.596930, acc.: 64.06%] [G loss: 0.698796]\n",
      "epoch:21 step:20478 [D loss: 0.541130, acc.: 73.44%] [G loss: 0.697638]\n",
      "epoch:21 step:20479 [D loss: 0.513633, acc.: 74.22%] [G loss: 0.860234]\n",
      "epoch:21 step:20480 [D loss: 0.513886, acc.: 74.22%] [G loss: 0.789879]\n",
      "epoch:21 step:20481 [D loss: 0.538625, acc.: 67.97%] [G loss: 0.655917]\n",
      "epoch:21 step:20482 [D loss: 0.518173, acc.: 73.44%] [G loss: 0.645446]\n",
      "epoch:21 step:20483 [D loss: 0.571197, acc.: 63.28%] [G loss: 0.674930]\n",
      "epoch:21 step:20484 [D loss: 0.525821, acc.: 73.44%] [G loss: 0.625093]\n",
      "epoch:21 step:20485 [D loss: 0.455466, acc.: 78.91%] [G loss: 0.717789]\n",
      "epoch:21 step:20486 [D loss: 0.492923, acc.: 76.56%] [G loss: 0.639470]\n",
      "epoch:21 step:20487 [D loss: 0.460099, acc.: 78.91%] [G loss: 0.691779]\n",
      "epoch:21 step:20488 [D loss: 0.526050, acc.: 73.44%] [G loss: 0.502228]\n",
      "epoch:21 step:20489 [D loss: 0.574180, acc.: 70.31%] [G loss: 0.529066]\n",
      "epoch:21 step:20490 [D loss: 0.536627, acc.: 68.75%] [G loss: 0.489257]\n",
      "epoch:21 step:20491 [D loss: 0.507576, acc.: 73.44%] [G loss: 0.742209]\n",
      "epoch:21 step:20492 [D loss: 0.455646, acc.: 79.69%] [G loss: 0.847288]\n",
      "epoch:21 step:20493 [D loss: 0.579953, acc.: 68.75%] [G loss: 0.920855]\n",
      "epoch:21 step:20494 [D loss: 0.595086, acc.: 71.09%] [G loss: 0.782819]\n",
      "epoch:21 step:20495 [D loss: 0.565273, acc.: 68.75%] [G loss: 0.726327]\n",
      "epoch:21 step:20496 [D loss: 0.557619, acc.: 71.09%] [G loss: 0.593505]\n",
      "epoch:21 step:20497 [D loss: 0.653381, acc.: 60.16%] [G loss: 0.547669]\n",
      "epoch:21 step:20498 [D loss: 0.506332, acc.: 76.56%] [G loss: 0.616428]\n",
      "epoch:21 step:20499 [D loss: 0.577910, acc.: 66.41%] [G loss: 0.575009]\n",
      "epoch:21 step:20500 [D loss: 0.424834, acc.: 82.81%] [G loss: 0.682981]\n",
      "epoch:21 step:20501 [D loss: 0.587093, acc.: 69.53%] [G loss: 0.666577]\n",
      "epoch:21 step:20502 [D loss: 0.477749, acc.: 77.34%] [G loss: 0.646691]\n",
      "epoch:21 step:20503 [D loss: 0.523929, acc.: 72.66%] [G loss: 0.707270]\n",
      "epoch:21 step:20504 [D loss: 0.618486, acc.: 65.62%] [G loss: 0.772625]\n",
      "epoch:21 step:20505 [D loss: 0.605199, acc.: 64.06%] [G loss: 0.607212]\n",
      "epoch:21 step:20506 [D loss: 0.562007, acc.: 68.75%] [G loss: 0.498272]\n",
      "epoch:21 step:20507 [D loss: 0.511686, acc.: 75.78%] [G loss: 0.669398]\n",
      "epoch:21 step:20508 [D loss: 0.557080, acc.: 68.75%] [G loss: 0.677278]\n",
      "epoch:21 step:20509 [D loss: 0.532794, acc.: 69.53%] [G loss: 0.663944]\n",
      "epoch:21 step:20510 [D loss: 0.543004, acc.: 69.53%] [G loss: 0.690086]\n",
      "epoch:21 step:20511 [D loss: 0.526981, acc.: 67.97%] [G loss: 0.504701]\n",
      "epoch:21 step:20512 [D loss: 0.522401, acc.: 75.00%] [G loss: 0.549460]\n",
      "epoch:21 step:20513 [D loss: 0.548386, acc.: 69.53%] [G loss: 0.543393]\n",
      "epoch:21 step:20514 [D loss: 0.535341, acc.: 71.09%] [G loss: 0.549593]\n",
      "epoch:21 step:20515 [D loss: 0.525799, acc.: 69.53%] [G loss: 0.628432]\n",
      "epoch:21 step:20516 [D loss: 0.585790, acc.: 71.09%] [G loss: 0.476241]\n",
      "epoch:21 step:20517 [D loss: 0.620790, acc.: 60.94%] [G loss: 0.457799]\n",
      "epoch:21 step:20518 [D loss: 0.520392, acc.: 68.75%] [G loss: 0.580398]\n",
      "epoch:21 step:20519 [D loss: 0.488672, acc.: 75.00%] [G loss: 0.588957]\n",
      "epoch:21 step:20520 [D loss: 0.458291, acc.: 78.91%] [G loss: 0.679530]\n",
      "epoch:21 step:20521 [D loss: 0.544207, acc.: 71.88%] [G loss: 0.884044]\n",
      "epoch:21 step:20522 [D loss: 0.530971, acc.: 73.44%] [G loss: 0.597032]\n",
      "epoch:21 step:20523 [D loss: 0.569784, acc.: 65.62%] [G loss: 0.417859]\n",
      "epoch:21 step:20524 [D loss: 0.618178, acc.: 61.72%] [G loss: 0.497264]\n",
      "epoch:21 step:20525 [D loss: 0.523445, acc.: 73.44%] [G loss: 0.482885]\n",
      "epoch:21 step:20526 [D loss: 0.598541, acc.: 64.84%] [G loss: 0.444299]\n",
      "epoch:21 step:20527 [D loss: 0.557785, acc.: 68.75%] [G loss: 0.466268]\n",
      "epoch:21 step:20528 [D loss: 0.561797, acc.: 68.75%] [G loss: 0.506856]\n",
      "epoch:21 step:20529 [D loss: 0.538583, acc.: 67.97%] [G loss: 0.756247]\n",
      "epoch:21 step:20530 [D loss: 0.564333, acc.: 67.19%] [G loss: 0.622364]\n",
      "epoch:21 step:20531 [D loss: 0.514720, acc.: 69.53%] [G loss: 0.602581]\n",
      "epoch:21 step:20532 [D loss: 0.564146, acc.: 68.75%] [G loss: 0.737886]\n",
      "epoch:21 step:20533 [D loss: 0.625041, acc.: 64.06%] [G loss: 0.676408]\n",
      "epoch:21 step:20534 [D loss: 0.472976, acc.: 76.56%] [G loss: 0.777234]\n",
      "epoch:21 step:20535 [D loss: 0.691595, acc.: 60.16%] [G loss: 0.538391]\n",
      "epoch:21 step:20536 [D loss: 0.527698, acc.: 72.66%] [G loss: 0.647848]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20537 [D loss: 0.438302, acc.: 81.25%] [G loss: 0.693302]\n",
      "epoch:21 step:20538 [D loss: 0.583275, acc.: 68.75%] [G loss: 0.606036]\n",
      "epoch:21 step:20539 [D loss: 0.526956, acc.: 73.44%] [G loss: 0.492561]\n",
      "epoch:21 step:20540 [D loss: 0.604354, acc.: 69.53%] [G loss: 0.560325]\n",
      "epoch:21 step:20541 [D loss: 0.484839, acc.: 75.78%] [G loss: 0.554449]\n",
      "epoch:21 step:20542 [D loss: 0.569421, acc.: 64.06%] [G loss: 0.474137]\n",
      "epoch:21 step:20543 [D loss: 0.513529, acc.: 70.31%] [G loss: 0.495610]\n",
      "epoch:21 step:20544 [D loss: 0.604522, acc.: 70.31%] [G loss: 0.475462]\n",
      "epoch:21 step:20545 [D loss: 0.532506, acc.: 72.66%] [G loss: 0.528942]\n",
      "epoch:21 step:20546 [D loss: 0.551426, acc.: 66.41%] [G loss: 0.520415]\n",
      "epoch:21 step:20547 [D loss: 0.423388, acc.: 80.47%] [G loss: 0.766506]\n",
      "epoch:21 step:20548 [D loss: 0.542500, acc.: 71.09%] [G loss: 0.734657]\n",
      "epoch:21 step:20549 [D loss: 0.564473, acc.: 71.09%] [G loss: 0.648790]\n",
      "epoch:21 step:20550 [D loss: 0.570515, acc.: 67.97%] [G loss: 0.740400]\n",
      "epoch:21 step:20551 [D loss: 0.542610, acc.: 70.31%] [G loss: 0.571533]\n",
      "epoch:21 step:20552 [D loss: 0.492868, acc.: 72.66%] [G loss: 0.678597]\n",
      "epoch:21 step:20553 [D loss: 0.521516, acc.: 73.44%] [G loss: 0.601489]\n",
      "epoch:21 step:20554 [D loss: 0.614702, acc.: 63.28%] [G loss: 0.458502]\n",
      "epoch:21 step:20555 [D loss: 0.476810, acc.: 76.56%] [G loss: 0.622695]\n",
      "epoch:21 step:20556 [D loss: 0.546041, acc.: 68.75%] [G loss: 0.595018]\n",
      "epoch:21 step:20557 [D loss: 0.733418, acc.: 49.22%] [G loss: 0.516930]\n",
      "epoch:21 step:20558 [D loss: 0.536100, acc.: 66.41%] [G loss: 0.623511]\n",
      "epoch:21 step:20559 [D loss: 0.593733, acc.: 64.84%] [G loss: 0.532896]\n",
      "epoch:21 step:20560 [D loss: 0.627244, acc.: 64.06%] [G loss: 0.555041]\n",
      "epoch:21 step:20561 [D loss: 0.456569, acc.: 81.25%] [G loss: 0.709184]\n",
      "epoch:21 step:20562 [D loss: 0.552280, acc.: 66.41%] [G loss: 0.899430]\n",
      "epoch:21 step:20563 [D loss: 0.530969, acc.: 69.53%] [G loss: 0.835562]\n",
      "epoch:21 step:20564 [D loss: 0.520939, acc.: 70.31%] [G loss: 0.816278]\n",
      "epoch:21 step:20565 [D loss: 0.584605, acc.: 68.75%] [G loss: 0.556607]\n",
      "epoch:21 step:20566 [D loss: 0.580467, acc.: 65.62%] [G loss: 0.570692]\n",
      "epoch:21 step:20567 [D loss: 0.481031, acc.: 75.00%] [G loss: 0.758007]\n",
      "epoch:21 step:20568 [D loss: 0.557275, acc.: 71.88%] [G loss: 0.673907]\n",
      "epoch:21 step:20569 [D loss: 0.605066, acc.: 64.84%] [G loss: 0.537023]\n",
      "epoch:21 step:20570 [D loss: 0.534853, acc.: 71.09%] [G loss: 0.568195]\n",
      "epoch:21 step:20571 [D loss: 0.479968, acc.: 77.34%] [G loss: 0.739247]\n",
      "epoch:21 step:20572 [D loss: 0.469326, acc.: 79.69%] [G loss: 0.757962]\n",
      "epoch:21 step:20573 [D loss: 0.502774, acc.: 78.91%] [G loss: 0.802600]\n",
      "epoch:21 step:20574 [D loss: 0.492223, acc.: 75.78%] [G loss: 0.782926]\n",
      "epoch:21 step:20575 [D loss: 0.418248, acc.: 82.81%] [G loss: 0.789397]\n",
      "epoch:21 step:20576 [D loss: 0.479315, acc.: 77.34%] [G loss: 0.807315]\n",
      "epoch:21 step:20577 [D loss: 0.474126, acc.: 80.47%] [G loss: 0.775761]\n",
      "epoch:21 step:20578 [D loss: 0.544805, acc.: 71.88%] [G loss: 0.781526]\n",
      "epoch:21 step:20579 [D loss: 0.566447, acc.: 69.53%] [G loss: 0.859717]\n",
      "epoch:21 step:20580 [D loss: 0.539082, acc.: 71.88%] [G loss: 0.667049]\n",
      "epoch:21 step:20581 [D loss: 0.579363, acc.: 67.97%] [G loss: 0.679601]\n",
      "epoch:21 step:20582 [D loss: 0.535522, acc.: 75.78%] [G loss: 0.658679]\n",
      "epoch:21 step:20583 [D loss: 0.510692, acc.: 75.78%] [G loss: 0.708912]\n",
      "epoch:21 step:20584 [D loss: 0.537718, acc.: 70.31%] [G loss: 0.717790]\n",
      "epoch:21 step:20585 [D loss: 0.555425, acc.: 69.53%] [G loss: 0.664205]\n",
      "epoch:21 step:20586 [D loss: 0.476301, acc.: 76.56%] [G loss: 0.641896]\n",
      "epoch:21 step:20587 [D loss: 0.491470, acc.: 72.66%] [G loss: 0.881882]\n",
      "epoch:21 step:20588 [D loss: 0.428574, acc.: 82.81%] [G loss: 0.788273]\n",
      "epoch:21 step:20589 [D loss: 0.492962, acc.: 76.56%] [G loss: 0.705336]\n",
      "epoch:21 step:20590 [D loss: 0.515005, acc.: 71.88%] [G loss: 0.844391]\n",
      "epoch:21 step:20591 [D loss: 0.455912, acc.: 73.44%] [G loss: 0.850647]\n",
      "epoch:21 step:20592 [D loss: 0.656168, acc.: 59.38%] [G loss: 0.941793]\n",
      "epoch:21 step:20593 [D loss: 0.492900, acc.: 74.22%] [G loss: 0.969363]\n",
      "epoch:21 step:20594 [D loss: 0.616917, acc.: 61.72%] [G loss: 0.946178]\n",
      "epoch:21 step:20595 [D loss: 0.479402, acc.: 74.22%] [G loss: 0.710598]\n",
      "epoch:21 step:20596 [D loss: 0.439651, acc.: 80.47%] [G loss: 0.864508]\n",
      "epoch:21 step:20597 [D loss: 0.665076, acc.: 60.16%] [G loss: 0.611903]\n",
      "epoch:21 step:20598 [D loss: 0.526366, acc.: 71.09%] [G loss: 0.851254]\n",
      "epoch:21 step:20599 [D loss: 0.546382, acc.: 68.75%] [G loss: 0.601297]\n",
      "epoch:21 step:20600 [D loss: 0.431021, acc.: 77.34%] [G loss: 0.887491]\n",
      "##############\n",
      "[2.94127713 1.42615228 6.10556016 4.88292437 4.05785897 6.12106167\n",
      " 4.74610495 4.8589815  4.90987486 4.12572641]\n",
      "##########\n",
      "epoch:21 step:20601 [D loss: 0.444015, acc.: 82.81%] [G loss: 0.736847]\n",
      "epoch:21 step:20602 [D loss: 0.443735, acc.: 78.91%] [G loss: 1.087240]\n",
      "epoch:21 step:20603 [D loss: 0.381904, acc.: 80.47%] [G loss: 1.002192]\n",
      "epoch:21 step:20604 [D loss: 0.496860, acc.: 75.00%] [G loss: 0.979946]\n",
      "epoch:21 step:20605 [D loss: 0.703898, acc.: 64.84%] [G loss: 1.138575]\n",
      "epoch:21 step:20606 [D loss: 0.529418, acc.: 73.44%] [G loss: 1.111288]\n",
      "epoch:21 step:20607 [D loss: 0.413944, acc.: 84.38%] [G loss: 1.069147]\n",
      "epoch:21 step:20608 [D loss: 0.448089, acc.: 75.00%] [G loss: 1.012360]\n",
      "epoch:21 step:20609 [D loss: 0.630084, acc.: 62.50%] [G loss: 0.877464]\n",
      "epoch:21 step:20610 [D loss: 0.437383, acc.: 78.12%] [G loss: 0.971894]\n",
      "epoch:21 step:20611 [D loss: 0.502978, acc.: 71.88%] [G loss: 0.926428]\n",
      "epoch:21 step:20612 [D loss: 0.471970, acc.: 75.78%] [G loss: 0.959311]\n",
      "epoch:21 step:20613 [D loss: 0.365682, acc.: 82.03%] [G loss: 1.489421]\n",
      "epoch:21 step:20614 [D loss: 0.487749, acc.: 72.66%] [G loss: 1.317010]\n",
      "epoch:22 step:20615 [D loss: 0.558562, acc.: 68.75%] [G loss: 1.038882]\n",
      "epoch:22 step:20616 [D loss: 0.502563, acc.: 71.88%] [G loss: 1.001550]\n",
      "epoch:22 step:20617 [D loss: 0.593364, acc.: 67.97%] [G loss: 0.878206]\n",
      "epoch:22 step:20618 [D loss: 0.553931, acc.: 74.22%] [G loss: 1.033608]\n",
      "epoch:22 step:20619 [D loss: 0.541110, acc.: 69.53%] [G loss: 0.651243]\n",
      "epoch:22 step:20620 [D loss: 0.620347, acc.: 66.41%] [G loss: 0.741966]\n",
      "epoch:22 step:20621 [D loss: 0.512833, acc.: 71.09%] [G loss: 0.693701]\n",
      "epoch:22 step:20622 [D loss: 0.440196, acc.: 79.69%] [G loss: 0.876949]\n",
      "epoch:22 step:20623 [D loss: 0.513162, acc.: 71.88%] [G loss: 1.009158]\n",
      "epoch:22 step:20624 [D loss: 0.465603, acc.: 82.03%] [G loss: 0.901234]\n",
      "epoch:22 step:20625 [D loss: 0.478816, acc.: 75.00%] [G loss: 0.996668]\n",
      "epoch:22 step:20626 [D loss: 0.547305, acc.: 70.31%] [G loss: 0.670787]\n",
      "epoch:22 step:20627 [D loss: 0.550878, acc.: 73.44%] [G loss: 0.631041]\n",
      "epoch:22 step:20628 [D loss: 0.529274, acc.: 67.97%] [G loss: 0.647411]\n",
      "epoch:22 step:20629 [D loss: 0.447761, acc.: 79.69%] [G loss: 0.777510]\n",
      "epoch:22 step:20630 [D loss: 0.476765, acc.: 78.12%] [G loss: 0.821569]\n",
      "epoch:22 step:20631 [D loss: 0.586747, acc.: 68.75%] [G loss: 1.095032]\n",
      "epoch:22 step:20632 [D loss: 0.562121, acc.: 71.88%] [G loss: 0.713989]\n",
      "epoch:22 step:20633 [D loss: 0.575333, acc.: 68.75%] [G loss: 0.807315]\n",
      "epoch:22 step:20634 [D loss: 0.586624, acc.: 67.19%] [G loss: 0.750897]\n",
      "epoch:22 step:20635 [D loss: 0.527712, acc.: 68.75%] [G loss: 0.724813]\n",
      "epoch:22 step:20636 [D loss: 0.455990, acc.: 79.69%] [G loss: 0.747334]\n",
      "epoch:22 step:20637 [D loss: 0.520402, acc.: 74.22%] [G loss: 0.732051]\n",
      "epoch:22 step:20638 [D loss: 0.455036, acc.: 77.34%] [G loss: 0.703269]\n",
      "epoch:22 step:20639 [D loss: 0.477095, acc.: 75.78%] [G loss: 0.655635]\n",
      "epoch:22 step:20640 [D loss: 0.553589, acc.: 66.41%] [G loss: 0.657384]\n",
      "epoch:22 step:20641 [D loss: 0.429395, acc.: 78.12%] [G loss: 0.727449]\n",
      "epoch:22 step:20642 [D loss: 0.529001, acc.: 69.53%] [G loss: 0.787487]\n",
      "epoch:22 step:20643 [D loss: 0.487425, acc.: 72.66%] [G loss: 0.700953]\n",
      "epoch:22 step:20644 [D loss: 0.527540, acc.: 74.22%] [G loss: 0.764386]\n",
      "epoch:22 step:20645 [D loss: 0.612702, acc.: 70.31%] [G loss: 0.546332]\n",
      "epoch:22 step:20646 [D loss: 0.539545, acc.: 71.09%] [G loss: 0.651680]\n",
      "epoch:22 step:20647 [D loss: 0.530467, acc.: 74.22%] [G loss: 0.637211]\n",
      "epoch:22 step:20648 [D loss: 0.517326, acc.: 71.09%] [G loss: 0.671331]\n",
      "epoch:22 step:20649 [D loss: 0.560177, acc.: 72.66%] [G loss: 0.481688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20650 [D loss: 0.530512, acc.: 71.09%] [G loss: 0.720840]\n",
      "epoch:22 step:20651 [D loss: 0.498329, acc.: 76.56%] [G loss: 0.717578]\n",
      "epoch:22 step:20652 [D loss: 0.572706, acc.: 67.19%] [G loss: 0.784822]\n",
      "epoch:22 step:20653 [D loss: 0.550370, acc.: 69.53%] [G loss: 0.614013]\n",
      "epoch:22 step:20654 [D loss: 0.422094, acc.: 80.47%] [G loss: 0.848008]\n",
      "epoch:22 step:20655 [D loss: 0.530348, acc.: 71.88%] [G loss: 0.849284]\n",
      "epoch:22 step:20656 [D loss: 0.571886, acc.: 67.97%] [G loss: 0.744487]\n",
      "epoch:22 step:20657 [D loss: 0.488464, acc.: 78.12%] [G loss: 0.670117]\n",
      "epoch:22 step:20658 [D loss: 0.603828, acc.: 67.97%] [G loss: 0.675656]\n",
      "epoch:22 step:20659 [D loss: 0.548731, acc.: 72.66%] [G loss: 0.650927]\n",
      "epoch:22 step:20660 [D loss: 0.491803, acc.: 74.22%] [G loss: 0.763643]\n",
      "epoch:22 step:20661 [D loss: 0.515260, acc.: 74.22%] [G loss: 0.803981]\n",
      "epoch:22 step:20662 [D loss: 0.533741, acc.: 70.31%] [G loss: 0.739673]\n",
      "epoch:22 step:20663 [D loss: 0.517509, acc.: 73.44%] [G loss: 0.731207]\n",
      "epoch:22 step:20664 [D loss: 0.572755, acc.: 69.53%] [G loss: 0.800171]\n",
      "epoch:22 step:20665 [D loss: 0.595237, acc.: 69.53%] [G loss: 0.739164]\n",
      "epoch:22 step:20666 [D loss: 0.567067, acc.: 67.97%] [G loss: 0.771078]\n",
      "epoch:22 step:20667 [D loss: 0.471573, acc.: 77.34%] [G loss: 0.777897]\n",
      "epoch:22 step:20668 [D loss: 0.497445, acc.: 73.44%] [G loss: 0.840526]\n",
      "epoch:22 step:20669 [D loss: 0.548952, acc.: 68.75%] [G loss: 0.711374]\n",
      "epoch:22 step:20670 [D loss: 0.528164, acc.: 71.09%] [G loss: 0.884535]\n",
      "epoch:22 step:20671 [D loss: 0.478679, acc.: 74.22%] [G loss: 0.685003]\n",
      "epoch:22 step:20672 [D loss: 0.594507, acc.: 66.41%] [G loss: 0.638467]\n",
      "epoch:22 step:20673 [D loss: 0.518788, acc.: 74.22%] [G loss: 0.712207]\n",
      "epoch:22 step:20674 [D loss: 0.591994, acc.: 63.28%] [G loss: 0.688413]\n",
      "epoch:22 step:20675 [D loss: 0.511451, acc.: 71.09%] [G loss: 0.580712]\n",
      "epoch:22 step:20676 [D loss: 0.628450, acc.: 68.75%] [G loss: 0.659831]\n",
      "epoch:22 step:20677 [D loss: 0.521879, acc.: 71.88%] [G loss: 0.729197]\n",
      "epoch:22 step:20678 [D loss: 0.527153, acc.: 71.09%] [G loss: 0.718787]\n",
      "epoch:22 step:20679 [D loss: 0.541294, acc.: 71.88%] [G loss: 0.764529]\n",
      "epoch:22 step:20680 [D loss: 0.536527, acc.: 68.75%] [G loss: 0.690215]\n",
      "epoch:22 step:20681 [D loss: 0.598402, acc.: 64.84%] [G loss: 0.591433]\n",
      "epoch:22 step:20682 [D loss: 0.569188, acc.: 72.66%] [G loss: 0.639549]\n",
      "epoch:22 step:20683 [D loss: 0.476014, acc.: 79.69%] [G loss: 0.748033]\n",
      "epoch:22 step:20684 [D loss: 0.509436, acc.: 78.12%] [G loss: 0.678029]\n",
      "epoch:22 step:20685 [D loss: 0.548780, acc.: 70.31%] [G loss: 0.792579]\n",
      "epoch:22 step:20686 [D loss: 0.576426, acc.: 64.84%] [G loss: 0.670846]\n",
      "epoch:22 step:20687 [D loss: 0.594519, acc.: 69.53%] [G loss: 0.653963]\n",
      "epoch:22 step:20688 [D loss: 0.454273, acc.: 77.34%] [G loss: 0.795248]\n",
      "epoch:22 step:20689 [D loss: 0.500899, acc.: 75.78%] [G loss: 0.732169]\n",
      "epoch:22 step:20690 [D loss: 0.509562, acc.: 72.66%] [G loss: 0.823208]\n",
      "epoch:22 step:20691 [D loss: 0.445712, acc.: 76.56%] [G loss: 0.916031]\n",
      "epoch:22 step:20692 [D loss: 0.536201, acc.: 71.88%] [G loss: 0.832915]\n",
      "epoch:22 step:20693 [D loss: 0.555425, acc.: 71.88%] [G loss: 0.671560]\n",
      "epoch:22 step:20694 [D loss: 0.519549, acc.: 72.66%] [G loss: 0.796788]\n",
      "epoch:22 step:20695 [D loss: 0.493794, acc.: 72.66%] [G loss: 0.753950]\n",
      "epoch:22 step:20696 [D loss: 0.524837, acc.: 67.97%] [G loss: 0.800022]\n",
      "epoch:22 step:20697 [D loss: 0.460369, acc.: 80.47%] [G loss: 0.823740]\n",
      "epoch:22 step:20698 [D loss: 0.543311, acc.: 73.44%] [G loss: 0.641662]\n",
      "epoch:22 step:20699 [D loss: 0.567557, acc.: 68.75%] [G loss: 0.634669]\n",
      "epoch:22 step:20700 [D loss: 0.521952, acc.: 71.09%] [G loss: 0.636603]\n",
      "epoch:22 step:20701 [D loss: 0.521253, acc.: 71.88%] [G loss: 0.747991]\n",
      "epoch:22 step:20702 [D loss: 0.484748, acc.: 76.56%] [G loss: 0.701924]\n",
      "epoch:22 step:20703 [D loss: 0.505244, acc.: 70.31%] [G loss: 0.845183]\n",
      "epoch:22 step:20704 [D loss: 0.486539, acc.: 76.56%] [G loss: 0.798526]\n",
      "epoch:22 step:20705 [D loss: 0.522950, acc.: 75.78%] [G loss: 0.696895]\n",
      "epoch:22 step:20706 [D loss: 0.414154, acc.: 82.03%] [G loss: 0.730914]\n",
      "epoch:22 step:20707 [D loss: 0.526893, acc.: 71.09%] [G loss: 0.856069]\n",
      "epoch:22 step:20708 [D loss: 0.478532, acc.: 75.00%] [G loss: 0.849612]\n",
      "epoch:22 step:20709 [D loss: 0.532281, acc.: 68.75%] [G loss: 0.784450]\n",
      "epoch:22 step:20710 [D loss: 0.532643, acc.: 72.66%] [G loss: 0.785946]\n",
      "epoch:22 step:20711 [D loss: 0.582728, acc.: 66.41%] [G loss: 0.774028]\n",
      "epoch:22 step:20712 [D loss: 0.506863, acc.: 75.00%] [G loss: 0.825518]\n",
      "epoch:22 step:20713 [D loss: 0.498107, acc.: 74.22%] [G loss: 0.924656]\n",
      "epoch:22 step:20714 [D loss: 0.460503, acc.: 77.34%] [G loss: 0.848280]\n",
      "epoch:22 step:20715 [D loss: 0.536597, acc.: 69.53%] [G loss: 0.872941]\n",
      "epoch:22 step:20716 [D loss: 0.614438, acc.: 62.50%] [G loss: 0.697822]\n",
      "epoch:22 step:20717 [D loss: 0.520881, acc.: 67.97%] [G loss: 0.642000]\n",
      "epoch:22 step:20718 [D loss: 0.489851, acc.: 77.34%] [G loss: 0.744849]\n",
      "epoch:22 step:20719 [D loss: 0.564562, acc.: 67.97%] [G loss: 0.704967]\n",
      "epoch:22 step:20720 [D loss: 0.523729, acc.: 68.75%] [G loss: 0.843684]\n",
      "epoch:22 step:20721 [D loss: 0.551326, acc.: 72.66%] [G loss: 0.726885]\n",
      "epoch:22 step:20722 [D loss: 0.628199, acc.: 63.28%] [G loss: 0.495697]\n",
      "epoch:22 step:20723 [D loss: 0.606199, acc.: 60.94%] [G loss: 0.509290]\n",
      "epoch:22 step:20724 [D loss: 0.536227, acc.: 67.97%] [G loss: 0.649832]\n",
      "epoch:22 step:20725 [D loss: 0.540029, acc.: 69.53%] [G loss: 0.702586]\n",
      "epoch:22 step:20726 [D loss: 0.504863, acc.: 76.56%] [G loss: 0.757884]\n",
      "epoch:22 step:20727 [D loss: 0.513257, acc.: 71.09%] [G loss: 0.660018]\n",
      "epoch:22 step:20728 [D loss: 0.512716, acc.: 78.12%] [G loss: 0.588000]\n",
      "epoch:22 step:20729 [D loss: 0.518414, acc.: 73.44%] [G loss: 0.681576]\n",
      "epoch:22 step:20730 [D loss: 0.493375, acc.: 77.34%] [G loss: 0.802971]\n",
      "epoch:22 step:20731 [D loss: 0.496855, acc.: 71.09%] [G loss: 0.917144]\n",
      "epoch:22 step:20732 [D loss: 0.588950, acc.: 68.75%] [G loss: 0.886520]\n",
      "epoch:22 step:20733 [D loss: 0.475196, acc.: 77.34%] [G loss: 0.820839]\n",
      "epoch:22 step:20734 [D loss: 0.593614, acc.: 66.41%] [G loss: 0.731558]\n",
      "epoch:22 step:20735 [D loss: 0.518068, acc.: 75.78%] [G loss: 0.761820]\n",
      "epoch:22 step:20736 [D loss: 0.534622, acc.: 78.12%] [G loss: 1.013383]\n",
      "epoch:22 step:20737 [D loss: 0.499601, acc.: 73.44%] [G loss: 0.921143]\n",
      "epoch:22 step:20738 [D loss: 0.580783, acc.: 70.31%] [G loss: 0.736312]\n",
      "epoch:22 step:20739 [D loss: 0.551621, acc.: 68.75%] [G loss: 0.667608]\n",
      "epoch:22 step:20740 [D loss: 0.503211, acc.: 75.78%] [G loss: 0.625273]\n",
      "epoch:22 step:20741 [D loss: 0.455008, acc.: 78.91%] [G loss: 0.721690]\n",
      "epoch:22 step:20742 [D loss: 0.492614, acc.: 71.88%] [G loss: 0.682521]\n",
      "epoch:22 step:20743 [D loss: 0.537348, acc.: 73.44%] [G loss: 0.624575]\n",
      "epoch:22 step:20744 [D loss: 0.505685, acc.: 78.12%] [G loss: 0.698901]\n",
      "epoch:22 step:20745 [D loss: 0.480580, acc.: 75.78%] [G loss: 0.861288]\n",
      "epoch:22 step:20746 [D loss: 0.487308, acc.: 78.91%] [G loss: 0.680615]\n",
      "epoch:22 step:20747 [D loss: 0.514048, acc.: 74.22%] [G loss: 0.634268]\n",
      "epoch:22 step:20748 [D loss: 0.509525, acc.: 71.88%] [G loss: 0.808689]\n",
      "epoch:22 step:20749 [D loss: 0.523179, acc.: 73.44%] [G loss: 0.893493]\n",
      "epoch:22 step:20750 [D loss: 0.513322, acc.: 78.12%] [G loss: 0.771497]\n",
      "epoch:22 step:20751 [D loss: 0.614673, acc.: 67.97%] [G loss: 0.598053]\n",
      "epoch:22 step:20752 [D loss: 0.557484, acc.: 70.31%] [G loss: 0.783997]\n",
      "epoch:22 step:20753 [D loss: 0.544848, acc.: 71.09%] [G loss: 0.810841]\n",
      "epoch:22 step:20754 [D loss: 0.587917, acc.: 68.75%] [G loss: 0.579417]\n",
      "epoch:22 step:20755 [D loss: 0.511380, acc.: 70.31%] [G loss: 0.714547]\n",
      "epoch:22 step:20756 [D loss: 0.605341, acc.: 62.50%] [G loss: 0.678864]\n",
      "epoch:22 step:20757 [D loss: 0.579885, acc.: 67.19%] [G loss: 0.575991]\n",
      "epoch:22 step:20758 [D loss: 0.493785, acc.: 71.88%] [G loss: 0.768283]\n",
      "epoch:22 step:20759 [D loss: 0.578416, acc.: 65.62%] [G loss: 0.631876]\n",
      "epoch:22 step:20760 [D loss: 0.478886, acc.: 76.56%] [G loss: 0.880938]\n",
      "epoch:22 step:20761 [D loss: 0.593342, acc.: 65.62%] [G loss: 0.674228]\n",
      "epoch:22 step:20762 [D loss: 0.582571, acc.: 68.75%] [G loss: 0.578019]\n",
      "epoch:22 step:20763 [D loss: 0.525438, acc.: 71.88%] [G loss: 0.644410]\n",
      "epoch:22 step:20764 [D loss: 0.560145, acc.: 69.53%] [G loss: 0.584634]\n",
      "epoch:22 step:20765 [D loss: 0.555946, acc.: 67.19%] [G loss: 0.696882]\n",
      "epoch:22 step:20766 [D loss: 0.479130, acc.: 77.34%] [G loss: 0.892463]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20767 [D loss: 0.602708, acc.: 64.84%] [G loss: 0.840635]\n",
      "epoch:22 step:20768 [D loss: 0.481426, acc.: 79.69%] [G loss: 0.661026]\n",
      "epoch:22 step:20769 [D loss: 0.482147, acc.: 73.44%] [G loss: 0.585221]\n",
      "epoch:22 step:20770 [D loss: 0.550710, acc.: 68.75%] [G loss: 0.821603]\n",
      "epoch:22 step:20771 [D loss: 0.539142, acc.: 70.31%] [G loss: 0.915492]\n",
      "epoch:22 step:20772 [D loss: 0.592047, acc.: 64.84%] [G loss: 0.653260]\n",
      "epoch:22 step:20773 [D loss: 0.521246, acc.: 71.88%] [G loss: 0.807409]\n",
      "epoch:22 step:20774 [D loss: 0.556713, acc.: 68.75%] [G loss: 0.751987]\n",
      "epoch:22 step:20775 [D loss: 0.494956, acc.: 75.00%] [G loss: 0.726301]\n",
      "epoch:22 step:20776 [D loss: 0.486999, acc.: 78.91%] [G loss: 0.703968]\n",
      "epoch:22 step:20777 [D loss: 0.509813, acc.: 75.00%] [G loss: 0.628591]\n",
      "epoch:22 step:20778 [D loss: 0.531125, acc.: 72.66%] [G loss: 0.650831]\n",
      "epoch:22 step:20779 [D loss: 0.510477, acc.: 71.09%] [G loss: 0.637148]\n",
      "epoch:22 step:20780 [D loss: 0.572984, acc.: 62.50%] [G loss: 0.594979]\n",
      "epoch:22 step:20781 [D loss: 0.556736, acc.: 68.75%] [G loss: 0.567704]\n",
      "epoch:22 step:20782 [D loss: 0.529430, acc.: 74.22%] [G loss: 0.686041]\n",
      "epoch:22 step:20783 [D loss: 0.571403, acc.: 69.53%] [G loss: 0.532762]\n",
      "epoch:22 step:20784 [D loss: 0.494888, acc.: 71.88%] [G loss: 0.611252]\n",
      "epoch:22 step:20785 [D loss: 0.547923, acc.: 69.53%] [G loss: 0.663096]\n",
      "epoch:22 step:20786 [D loss: 0.505683, acc.: 78.12%] [G loss: 0.705186]\n",
      "epoch:22 step:20787 [D loss: 0.506429, acc.: 78.12%] [G loss: 0.735346]\n",
      "epoch:22 step:20788 [D loss: 0.580759, acc.: 61.72%] [G loss: 0.689635]\n",
      "epoch:22 step:20789 [D loss: 0.536961, acc.: 70.31%] [G loss: 0.532032]\n",
      "epoch:22 step:20790 [D loss: 0.517574, acc.: 73.44%] [G loss: 0.584113]\n",
      "epoch:22 step:20791 [D loss: 0.514797, acc.: 71.88%] [G loss: 0.648710]\n",
      "epoch:22 step:20792 [D loss: 0.559463, acc.: 73.44%] [G loss: 0.562910]\n",
      "epoch:22 step:20793 [D loss: 0.535593, acc.: 75.78%] [G loss: 0.680221]\n",
      "epoch:22 step:20794 [D loss: 0.628070, acc.: 64.06%] [G loss: 0.552309]\n",
      "epoch:22 step:20795 [D loss: 0.549390, acc.: 69.53%] [G loss: 0.649189]\n",
      "epoch:22 step:20796 [D loss: 0.516187, acc.: 71.09%] [G loss: 0.699726]\n",
      "epoch:22 step:20797 [D loss: 0.600691, acc.: 67.19%] [G loss: 0.664145]\n",
      "epoch:22 step:20798 [D loss: 0.505054, acc.: 74.22%] [G loss: 0.672222]\n",
      "epoch:22 step:20799 [D loss: 0.487023, acc.: 76.56%] [G loss: 0.556242]\n",
      "epoch:22 step:20800 [D loss: 0.569652, acc.: 70.31%] [G loss: 0.654056]\n",
      "##############\n",
      "[3.4423384  1.67364191 6.44412665 4.90034743 3.77308365 5.78438568\n",
      " 4.5908577  4.95386817 4.6211308  4.3464778 ]\n",
      "##########\n",
      "epoch:22 step:20801 [D loss: 0.588745, acc.: 64.06%] [G loss: 0.637722]\n",
      "epoch:22 step:20802 [D loss: 0.520567, acc.: 67.19%] [G loss: 0.658118]\n",
      "epoch:22 step:20803 [D loss: 0.566060, acc.: 71.88%] [G loss: 0.581022]\n",
      "epoch:22 step:20804 [D loss: 0.486367, acc.: 73.44%] [G loss: 0.527504]\n",
      "epoch:22 step:20805 [D loss: 0.504441, acc.: 73.44%] [G loss: 0.604987]\n",
      "epoch:22 step:20806 [D loss: 0.497209, acc.: 74.22%] [G loss: 0.650571]\n",
      "epoch:22 step:20807 [D loss: 0.537559, acc.: 72.66%] [G loss: 0.571952]\n",
      "epoch:22 step:20808 [D loss: 0.376292, acc.: 85.94%] [G loss: 0.851646]\n",
      "epoch:22 step:20809 [D loss: 0.578337, acc.: 73.44%] [G loss: 0.751525]\n",
      "epoch:22 step:20810 [D loss: 0.568154, acc.: 67.97%] [G loss: 0.662126]\n",
      "epoch:22 step:20811 [D loss: 0.526743, acc.: 75.00%] [G loss: 0.778099]\n",
      "epoch:22 step:20812 [D loss: 0.530965, acc.: 67.19%] [G loss: 0.786236]\n",
      "epoch:22 step:20813 [D loss: 0.486222, acc.: 76.56%] [G loss: 0.800354]\n",
      "epoch:22 step:20814 [D loss: 0.610112, acc.: 65.62%] [G loss: 0.547363]\n",
      "epoch:22 step:20815 [D loss: 0.558969, acc.: 66.41%] [G loss: 0.632513]\n",
      "epoch:22 step:20816 [D loss: 0.553587, acc.: 71.88%] [G loss: 0.592974]\n",
      "epoch:22 step:20817 [D loss: 0.572522, acc.: 67.19%] [G loss: 0.599099]\n",
      "epoch:22 step:20818 [D loss: 0.552832, acc.: 71.09%] [G loss: 0.623044]\n",
      "epoch:22 step:20819 [D loss: 0.467462, acc.: 78.12%] [G loss: 0.686288]\n",
      "epoch:22 step:20820 [D loss: 0.461753, acc.: 78.12%] [G loss: 0.783664]\n",
      "epoch:22 step:20821 [D loss: 0.460219, acc.: 78.12%] [G loss: 0.804379]\n",
      "epoch:22 step:20822 [D loss: 0.425111, acc.: 78.91%] [G loss: 1.040476]\n",
      "epoch:22 step:20823 [D loss: 0.488367, acc.: 75.78%] [G loss: 0.956366]\n",
      "epoch:22 step:20824 [D loss: 0.591511, acc.: 68.75%] [G loss: 0.720559]\n",
      "epoch:22 step:20825 [D loss: 0.652201, acc.: 66.41%] [G loss: 0.517970]\n",
      "epoch:22 step:20826 [D loss: 0.548339, acc.: 69.53%] [G loss: 0.540833]\n",
      "epoch:22 step:20827 [D loss: 0.504065, acc.: 77.34%] [G loss: 0.717801]\n",
      "epoch:22 step:20828 [D loss: 0.622886, acc.: 62.50%] [G loss: 0.555597]\n",
      "epoch:22 step:20829 [D loss: 0.552900, acc.: 65.62%] [G loss: 0.510533]\n",
      "epoch:22 step:20830 [D loss: 0.524145, acc.: 69.53%] [G loss: 0.726935]\n",
      "epoch:22 step:20831 [D loss: 0.492706, acc.: 72.66%] [G loss: 0.837264]\n",
      "epoch:22 step:20832 [D loss: 0.492628, acc.: 77.34%] [G loss: 0.702040]\n",
      "epoch:22 step:20833 [D loss: 0.456793, acc.: 81.25%] [G loss: 0.778791]\n",
      "epoch:22 step:20834 [D loss: 0.646213, acc.: 68.75%] [G loss: 0.671193]\n",
      "epoch:22 step:20835 [D loss: 0.586679, acc.: 66.41%] [G loss: 0.588208]\n",
      "epoch:22 step:20836 [D loss: 0.466720, acc.: 76.56%] [G loss: 0.783293]\n",
      "epoch:22 step:20837 [D loss: 0.507805, acc.: 70.31%] [G loss: 0.866754]\n",
      "epoch:22 step:20838 [D loss: 0.574932, acc.: 67.19%] [G loss: 0.668285]\n",
      "epoch:22 step:20839 [D loss: 0.523908, acc.: 73.44%] [G loss: 0.596529]\n",
      "epoch:22 step:20840 [D loss: 0.602971, acc.: 66.41%] [G loss: 0.634725]\n",
      "epoch:22 step:20841 [D loss: 0.500941, acc.: 71.09%] [G loss: 0.678205]\n",
      "epoch:22 step:20842 [D loss: 0.655647, acc.: 63.28%] [G loss: 0.597602]\n",
      "epoch:22 step:20843 [D loss: 0.525889, acc.: 76.56%] [G loss: 0.631935]\n",
      "epoch:22 step:20844 [D loss: 0.502956, acc.: 72.66%] [G loss: 0.806038]\n",
      "epoch:22 step:20845 [D loss: 0.471150, acc.: 75.00%] [G loss: 0.946239]\n",
      "epoch:22 step:20846 [D loss: 0.440845, acc.: 79.69%] [G loss: 0.883787]\n",
      "epoch:22 step:20847 [D loss: 0.516904, acc.: 74.22%] [G loss: 0.775207]\n",
      "epoch:22 step:20848 [D loss: 0.527870, acc.: 73.44%] [G loss: 0.698390]\n",
      "epoch:22 step:20849 [D loss: 0.585658, acc.: 63.28%] [G loss: 0.693195]\n",
      "epoch:22 step:20850 [D loss: 0.508041, acc.: 68.75%] [G loss: 0.682101]\n",
      "epoch:22 step:20851 [D loss: 0.530230, acc.: 72.66%] [G loss: 0.797850]\n",
      "epoch:22 step:20852 [D loss: 0.592480, acc.: 65.62%] [G loss: 0.567251]\n",
      "epoch:22 step:20853 [D loss: 0.545845, acc.: 69.53%] [G loss: 0.637845]\n",
      "epoch:22 step:20854 [D loss: 0.532774, acc.: 67.19%] [G loss: 0.634415]\n",
      "epoch:22 step:20855 [D loss: 0.519564, acc.: 73.44%] [G loss: 0.708615]\n",
      "epoch:22 step:20856 [D loss: 0.529124, acc.: 73.44%] [G loss: 0.716470]\n",
      "epoch:22 step:20857 [D loss: 0.512380, acc.: 70.31%] [G loss: 0.761006]\n",
      "epoch:22 step:20858 [D loss: 0.525048, acc.: 70.31%] [G loss: 0.730841]\n",
      "epoch:22 step:20859 [D loss: 0.506983, acc.: 77.34%] [G loss: 0.738019]\n",
      "epoch:22 step:20860 [D loss: 0.517207, acc.: 71.88%] [G loss: 0.752147]\n",
      "epoch:22 step:20861 [D loss: 0.512361, acc.: 77.34%] [G loss: 0.717624]\n",
      "epoch:22 step:20862 [D loss: 0.511764, acc.: 75.00%] [G loss: 0.762725]\n",
      "epoch:22 step:20863 [D loss: 0.613541, acc.: 70.31%] [G loss: 0.770107]\n",
      "epoch:22 step:20864 [D loss: 0.605303, acc.: 64.06%] [G loss: 0.855545]\n",
      "epoch:22 step:20865 [D loss: 0.630610, acc.: 61.72%] [G loss: 0.601316]\n",
      "epoch:22 step:20866 [D loss: 0.542983, acc.: 68.75%] [G loss: 0.683256]\n",
      "epoch:22 step:20867 [D loss: 0.551846, acc.: 67.97%] [G loss: 0.644060]\n",
      "epoch:22 step:20868 [D loss: 0.545318, acc.: 65.62%] [G loss: 0.545109]\n",
      "epoch:22 step:20869 [D loss: 0.528237, acc.: 72.66%] [G loss: 0.554577]\n",
      "epoch:22 step:20870 [D loss: 0.550115, acc.: 69.53%] [G loss: 0.687023]\n",
      "epoch:22 step:20871 [D loss: 0.556543, acc.: 67.19%] [G loss: 0.682230]\n",
      "epoch:22 step:20872 [D loss: 0.534002, acc.: 67.19%] [G loss: 0.624542]\n",
      "epoch:22 step:20873 [D loss: 0.527375, acc.: 67.97%] [G loss: 0.785186]\n",
      "epoch:22 step:20874 [D loss: 0.589238, acc.: 63.28%] [G loss: 0.634477]\n",
      "epoch:22 step:20875 [D loss: 0.531858, acc.: 71.09%] [G loss: 0.698651]\n",
      "epoch:22 step:20876 [D loss: 0.501684, acc.: 71.88%] [G loss: 0.783408]\n",
      "epoch:22 step:20877 [D loss: 0.575418, acc.: 69.53%] [G loss: 0.562736]\n",
      "epoch:22 step:20878 [D loss: 0.558514, acc.: 75.78%] [G loss: 0.803877]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20879 [D loss: 0.529411, acc.: 74.22%] [G loss: 0.611722]\n",
      "epoch:22 step:20880 [D loss: 0.537293, acc.: 71.88%] [G loss: 0.602861]\n",
      "epoch:22 step:20881 [D loss: 0.503911, acc.: 73.44%] [G loss: 0.756920]\n",
      "epoch:22 step:20882 [D loss: 0.509016, acc.: 71.09%] [G loss: 0.607991]\n",
      "epoch:22 step:20883 [D loss: 0.543861, acc.: 76.56%] [G loss: 0.580097]\n",
      "epoch:22 step:20884 [D loss: 0.486309, acc.: 75.00%] [G loss: 0.670504]\n",
      "epoch:22 step:20885 [D loss: 0.484266, acc.: 75.00%] [G loss: 0.642683]\n",
      "epoch:22 step:20886 [D loss: 0.529451, acc.: 67.97%] [G loss: 0.635863]\n",
      "epoch:22 step:20887 [D loss: 0.480568, acc.: 77.34%] [G loss: 0.711740]\n",
      "epoch:22 step:20888 [D loss: 0.487388, acc.: 79.69%] [G loss: 0.573070]\n",
      "epoch:22 step:20889 [D loss: 0.521489, acc.: 75.78%] [G loss: 0.641750]\n",
      "epoch:22 step:20890 [D loss: 0.500843, acc.: 75.00%] [G loss: 0.681543]\n",
      "epoch:22 step:20891 [D loss: 0.683090, acc.: 58.59%] [G loss: 0.432818]\n",
      "epoch:22 step:20892 [D loss: 0.705373, acc.: 63.28%] [G loss: 0.514925]\n",
      "epoch:22 step:20893 [D loss: 0.543727, acc.: 66.41%] [G loss: 0.498440]\n",
      "epoch:22 step:20894 [D loss: 0.491872, acc.: 75.00%] [G loss: 0.516251]\n",
      "epoch:22 step:20895 [D loss: 0.571364, acc.: 69.53%] [G loss: 0.591434]\n",
      "epoch:22 step:20896 [D loss: 0.543965, acc.: 74.22%] [G loss: 0.595343]\n",
      "epoch:22 step:20897 [D loss: 0.534817, acc.: 68.75%] [G loss: 0.576779]\n",
      "epoch:22 step:20898 [D loss: 0.514227, acc.: 72.66%] [G loss: 0.652731]\n",
      "epoch:22 step:20899 [D loss: 0.523903, acc.: 69.53%] [G loss: 0.742379]\n",
      "epoch:22 step:20900 [D loss: 0.522773, acc.: 74.22%] [G loss: 0.735191]\n",
      "epoch:22 step:20901 [D loss: 0.579420, acc.: 67.97%] [G loss: 0.587688]\n",
      "epoch:22 step:20902 [D loss: 0.583807, acc.: 64.06%] [G loss: 0.630939]\n",
      "epoch:22 step:20903 [D loss: 0.499496, acc.: 74.22%] [G loss: 0.607682]\n",
      "epoch:22 step:20904 [D loss: 0.498708, acc.: 73.44%] [G loss: 0.662278]\n",
      "epoch:22 step:20905 [D loss: 0.600083, acc.: 65.62%] [G loss: 0.602377]\n",
      "epoch:22 step:20906 [D loss: 0.529179, acc.: 71.09%] [G loss: 0.693600]\n",
      "epoch:22 step:20907 [D loss: 0.512645, acc.: 73.44%] [G loss: 0.681968]\n",
      "epoch:22 step:20908 [D loss: 0.668519, acc.: 58.59%] [G loss: 0.468986]\n",
      "epoch:22 step:20909 [D loss: 0.591139, acc.: 67.97%] [G loss: 0.473349]\n",
      "epoch:22 step:20910 [D loss: 0.442103, acc.: 78.91%] [G loss: 0.684061]\n",
      "epoch:22 step:20911 [D loss: 0.535140, acc.: 68.75%] [G loss: 0.664328]\n",
      "epoch:22 step:20912 [D loss: 0.478774, acc.: 71.09%] [G loss: 0.743502]\n",
      "epoch:22 step:20913 [D loss: 0.491585, acc.: 74.22%] [G loss: 0.614881]\n",
      "epoch:22 step:20914 [D loss: 0.483559, acc.: 75.00%] [G loss: 0.841837]\n",
      "epoch:22 step:20915 [D loss: 0.620921, acc.: 66.41%] [G loss: 0.667985]\n",
      "epoch:22 step:20916 [D loss: 0.521972, acc.: 68.75%] [G loss: 0.606670]\n",
      "epoch:22 step:20917 [D loss: 0.490936, acc.: 74.22%] [G loss: 0.732822]\n",
      "epoch:22 step:20918 [D loss: 0.480269, acc.: 78.12%] [G loss: 0.573174]\n",
      "epoch:22 step:20919 [D loss: 0.518629, acc.: 71.88%] [G loss: 0.663570]\n",
      "epoch:22 step:20920 [D loss: 0.560374, acc.: 75.00%] [G loss: 0.725990]\n",
      "epoch:22 step:20921 [D loss: 0.475893, acc.: 73.44%] [G loss: 0.771632]\n",
      "epoch:22 step:20922 [D loss: 0.551674, acc.: 67.97%] [G loss: 0.680655]\n",
      "epoch:22 step:20923 [D loss: 0.502379, acc.: 71.09%] [G loss: 0.611579]\n",
      "epoch:22 step:20924 [D loss: 0.551231, acc.: 66.41%] [G loss: 0.687231]\n",
      "epoch:22 step:20925 [D loss: 0.484792, acc.: 74.22%] [G loss: 0.662514]\n",
      "epoch:22 step:20926 [D loss: 0.467829, acc.: 79.69%] [G loss: 0.791341]\n",
      "epoch:22 step:20927 [D loss: 0.473384, acc.: 78.91%] [G loss: 0.917766]\n",
      "epoch:22 step:20928 [D loss: 0.425870, acc.: 82.81%] [G loss: 1.066840]\n",
      "epoch:22 step:20929 [D loss: 0.443481, acc.: 80.47%] [G loss: 1.174811]\n",
      "epoch:22 step:20930 [D loss: 0.713344, acc.: 63.28%] [G loss: 0.748305]\n",
      "epoch:22 step:20931 [D loss: 0.582378, acc.: 71.09%] [G loss: 0.664189]\n",
      "epoch:22 step:20932 [D loss: 0.503818, acc.: 72.66%] [G loss: 0.586521]\n",
      "epoch:22 step:20933 [D loss: 0.581181, acc.: 67.19%] [G loss: 0.550511]\n",
      "epoch:22 step:20934 [D loss: 0.561938, acc.: 69.53%] [G loss: 0.572147]\n",
      "epoch:22 step:20935 [D loss: 0.524875, acc.: 71.88%] [G loss: 0.670964]\n",
      "epoch:22 step:20936 [D loss: 0.571270, acc.: 68.75%] [G loss: 0.696074]\n",
      "epoch:22 step:20937 [D loss: 0.552266, acc.: 70.31%] [G loss: 0.609499]\n",
      "epoch:22 step:20938 [D loss: 0.516512, acc.: 70.31%] [G loss: 0.668114]\n",
      "epoch:22 step:20939 [D loss: 0.542132, acc.: 67.19%] [G loss: 0.612813]\n",
      "epoch:22 step:20940 [D loss: 0.449622, acc.: 78.91%] [G loss: 0.738860]\n",
      "epoch:22 step:20941 [D loss: 0.524881, acc.: 69.53%] [G loss: 0.889159]\n",
      "epoch:22 step:20942 [D loss: 0.468872, acc.: 78.91%] [G loss: 0.848650]\n",
      "epoch:22 step:20943 [D loss: 0.543642, acc.: 69.53%] [G loss: 0.680139]\n",
      "epoch:22 step:20944 [D loss: 0.585642, acc.: 67.19%] [G loss: 0.698227]\n",
      "epoch:22 step:20945 [D loss: 0.570212, acc.: 68.75%] [G loss: 0.631113]\n",
      "epoch:22 step:20946 [D loss: 0.494930, acc.: 78.12%] [G loss: 0.614873]\n",
      "epoch:22 step:20947 [D loss: 0.472392, acc.: 75.78%] [G loss: 0.747166]\n",
      "epoch:22 step:20948 [D loss: 0.489608, acc.: 74.22%] [G loss: 0.728176]\n",
      "epoch:22 step:20949 [D loss: 0.494539, acc.: 74.22%] [G loss: 0.741979]\n",
      "epoch:22 step:20950 [D loss: 0.541807, acc.: 71.09%] [G loss: 0.745689]\n",
      "epoch:22 step:20951 [D loss: 0.513920, acc.: 76.56%] [G loss: 0.789310]\n",
      "epoch:22 step:20952 [D loss: 0.580107, acc.: 66.41%] [G loss: 0.611888]\n",
      "epoch:22 step:20953 [D loss: 0.524213, acc.: 67.97%] [G loss: 0.777518]\n",
      "epoch:22 step:20954 [D loss: 0.469419, acc.: 79.69%] [G loss: 0.837918]\n",
      "epoch:22 step:20955 [D loss: 0.552647, acc.: 71.09%] [G loss: 0.666910]\n",
      "epoch:22 step:20956 [D loss: 0.594403, acc.: 67.97%] [G loss: 0.581077]\n",
      "epoch:22 step:20957 [D loss: 0.517720, acc.: 72.66%] [G loss: 0.851051]\n",
      "epoch:22 step:20958 [D loss: 0.432811, acc.: 82.81%] [G loss: 0.896207]\n",
      "epoch:22 step:20959 [D loss: 0.586294, acc.: 68.75%] [G loss: 0.842864]\n",
      "epoch:22 step:20960 [D loss: 0.531413, acc.: 74.22%] [G loss: 0.833105]\n",
      "epoch:22 step:20961 [D loss: 0.469823, acc.: 78.12%] [G loss: 0.710802]\n",
      "epoch:22 step:20962 [D loss: 0.624013, acc.: 65.62%] [G loss: 0.730936]\n",
      "epoch:22 step:20963 [D loss: 0.740046, acc.: 50.78%] [G loss: 0.543785]\n",
      "epoch:22 step:20964 [D loss: 0.501905, acc.: 76.56%] [G loss: 0.658686]\n",
      "epoch:22 step:20965 [D loss: 0.514406, acc.: 74.22%] [G loss: 0.840395]\n",
      "epoch:22 step:20966 [D loss: 0.574770, acc.: 65.62%] [G loss: 0.691581]\n",
      "epoch:22 step:20967 [D loss: 0.551106, acc.: 68.75%] [G loss: 0.711275]\n",
      "epoch:22 step:20968 [D loss: 0.456749, acc.: 79.69%] [G loss: 0.649908]\n",
      "epoch:22 step:20969 [D loss: 0.516481, acc.: 78.91%] [G loss: 0.890027]\n",
      "epoch:22 step:20970 [D loss: 0.622305, acc.: 65.62%] [G loss: 0.781277]\n",
      "epoch:22 step:20971 [D loss: 0.435059, acc.: 80.47%] [G loss: 0.834830]\n",
      "epoch:22 step:20972 [D loss: 0.485325, acc.: 75.78%] [G loss: 0.870058]\n",
      "epoch:22 step:20973 [D loss: 0.476057, acc.: 76.56%] [G loss: 0.881484]\n",
      "epoch:22 step:20974 [D loss: 0.469377, acc.: 73.44%] [G loss: 1.025393]\n",
      "epoch:22 step:20975 [D loss: 0.462605, acc.: 78.91%] [G loss: 0.866298]\n",
      "epoch:22 step:20976 [D loss: 0.570811, acc.: 71.09%] [G loss: 0.722180]\n",
      "epoch:22 step:20977 [D loss: 0.497590, acc.: 75.78%] [G loss: 0.766829]\n",
      "epoch:22 step:20978 [D loss: 0.500684, acc.: 74.22%] [G loss: 0.721858]\n",
      "epoch:22 step:20979 [D loss: 0.556845, acc.: 69.53%] [G loss: 0.579949]\n",
      "epoch:22 step:20980 [D loss: 0.524640, acc.: 73.44%] [G loss: 0.856003]\n",
      "epoch:22 step:20981 [D loss: 0.559883, acc.: 69.53%] [G loss: 0.717422]\n",
      "epoch:22 step:20982 [D loss: 0.544651, acc.: 67.19%] [G loss: 0.573361]\n",
      "epoch:22 step:20983 [D loss: 0.524685, acc.: 70.31%] [G loss: 0.561399]\n",
      "epoch:22 step:20984 [D loss: 0.500292, acc.: 74.22%] [G loss: 0.668409]\n",
      "epoch:22 step:20985 [D loss: 0.502886, acc.: 75.78%] [G loss: 0.709962]\n",
      "epoch:22 step:20986 [D loss: 0.566584, acc.: 69.53%] [G loss: 0.703830]\n",
      "epoch:22 step:20987 [D loss: 0.555034, acc.: 71.09%] [G loss: 0.766666]\n",
      "epoch:22 step:20988 [D loss: 0.462065, acc.: 76.56%] [G loss: 0.821708]\n",
      "epoch:22 step:20989 [D loss: 0.556704, acc.: 72.66%] [G loss: 0.670186]\n",
      "epoch:22 step:20990 [D loss: 0.744106, acc.: 56.25%] [G loss: 0.503077]\n",
      "epoch:22 step:20991 [D loss: 0.556970, acc.: 68.75%] [G loss: 0.516165]\n",
      "epoch:22 step:20992 [D loss: 0.509570, acc.: 74.22%] [G loss: 0.621594]\n",
      "epoch:22 step:20993 [D loss: 0.563355, acc.: 67.97%] [G loss: 0.550211]\n",
      "epoch:22 step:20994 [D loss: 0.564411, acc.: 68.75%] [G loss: 0.535237]\n",
      "epoch:22 step:20995 [D loss: 0.494586, acc.: 77.34%] [G loss: 0.822356]\n",
      "epoch:22 step:20996 [D loss: 0.510641, acc.: 76.56%] [G loss: 0.811313]\n",
      "epoch:22 step:20997 [D loss: 0.558611, acc.: 65.62%] [G loss: 0.701803]\n",
      "epoch:22 step:20998 [D loss: 0.515472, acc.: 73.44%] [G loss: 0.557287]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20999 [D loss: 0.510682, acc.: 72.66%] [G loss: 0.676600]\n",
      "epoch:22 step:21000 [D loss: 0.568354, acc.: 66.41%] [G loss: 0.654409]\n",
      "##############\n",
      "[3.18810128 1.35158308 6.37182605 4.78937988 3.55835105 5.63444512\n",
      " 4.8196754  4.57670264 4.86005865 4.26299607]\n",
      "##########\n",
      "epoch:22 step:21001 [D loss: 0.560347, acc.: 66.41%] [G loss: 0.609002]\n",
      "epoch:22 step:21002 [D loss: 0.583367, acc.: 71.09%] [G loss: 0.529827]\n",
      "epoch:22 step:21003 [D loss: 0.483331, acc.: 77.34%] [G loss: 0.794495]\n",
      "epoch:22 step:21004 [D loss: 0.591969, acc.: 64.84%] [G loss: 0.578884]\n",
      "epoch:22 step:21005 [D loss: 0.502672, acc.: 74.22%] [G loss: 0.662154]\n",
      "epoch:22 step:21006 [D loss: 0.472226, acc.: 77.34%] [G loss: 0.860444]\n",
      "epoch:22 step:21007 [D loss: 0.587684, acc.: 67.19%] [G loss: 0.658325]\n",
      "epoch:22 step:21008 [D loss: 0.552550, acc.: 73.44%] [G loss: 0.586762]\n",
      "epoch:22 step:21009 [D loss: 0.544533, acc.: 72.66%] [G loss: 0.629758]\n",
      "epoch:22 step:21010 [D loss: 0.578946, acc.: 69.53%] [G loss: 0.592906]\n",
      "epoch:22 step:21011 [D loss: 0.564443, acc.: 66.41%] [G loss: 0.542484]\n",
      "epoch:22 step:21012 [D loss: 0.483781, acc.: 76.56%] [G loss: 0.690890]\n",
      "epoch:22 step:21013 [D loss: 0.515665, acc.: 72.66%] [G loss: 0.723701]\n",
      "epoch:22 step:21014 [D loss: 0.617351, acc.: 64.06%] [G loss: 0.596047]\n",
      "epoch:22 step:21015 [D loss: 0.599962, acc.: 68.75%] [G loss: 0.538596]\n",
      "epoch:22 step:21016 [D loss: 0.481005, acc.: 72.66%] [G loss: 0.669364]\n",
      "epoch:22 step:21017 [D loss: 0.542974, acc.: 71.09%] [G loss: 0.710070]\n",
      "epoch:22 step:21018 [D loss: 0.574123, acc.: 67.97%] [G loss: 0.677028]\n",
      "epoch:22 step:21019 [D loss: 0.553956, acc.: 70.31%] [G loss: 0.659645]\n",
      "epoch:22 step:21020 [D loss: 0.504305, acc.: 69.53%] [G loss: 0.824178]\n",
      "epoch:22 step:21021 [D loss: 0.593263, acc.: 64.84%] [G loss: 0.782204]\n",
      "epoch:22 step:21022 [D loss: 0.538539, acc.: 71.09%] [G loss: 0.718305]\n",
      "epoch:22 step:21023 [D loss: 0.594228, acc.: 64.06%] [G loss: 0.673764]\n",
      "epoch:22 step:21024 [D loss: 0.572762, acc.: 70.31%] [G loss: 0.648053]\n",
      "epoch:22 step:21025 [D loss: 0.594814, acc.: 67.19%] [G loss: 0.594435]\n",
      "epoch:22 step:21026 [D loss: 0.640311, acc.: 59.38%] [G loss: 0.518801]\n",
      "epoch:22 step:21027 [D loss: 0.526631, acc.: 72.66%] [G loss: 0.622682]\n",
      "epoch:22 step:21028 [D loss: 0.579122, acc.: 65.62%] [G loss: 0.650756]\n",
      "epoch:22 step:21029 [D loss: 0.544217, acc.: 71.09%] [G loss: 0.617026]\n",
      "epoch:22 step:21030 [D loss: 0.479575, acc.: 80.47%] [G loss: 0.719126]\n",
      "epoch:22 step:21031 [D loss: 0.550899, acc.: 71.09%] [G loss: 0.657449]\n",
      "epoch:22 step:21032 [D loss: 0.559140, acc.: 69.53%] [G loss: 0.551843]\n",
      "epoch:22 step:21033 [D loss: 0.516187, acc.: 73.44%] [G loss: 0.761252]\n",
      "epoch:22 step:21034 [D loss: 0.598768, acc.: 61.72%] [G loss: 0.593871]\n",
      "epoch:22 step:21035 [D loss: 0.517720, acc.: 74.22%] [G loss: 0.798576]\n",
      "epoch:22 step:21036 [D loss: 0.593585, acc.: 67.19%] [G loss: 0.568453]\n",
      "epoch:22 step:21037 [D loss: 0.545615, acc.: 71.88%] [G loss: 0.703520]\n",
      "epoch:22 step:21038 [D loss: 0.561191, acc.: 67.19%] [G loss: 0.754836]\n",
      "epoch:22 step:21039 [D loss: 0.472537, acc.: 78.12%] [G loss: 0.704360]\n",
      "epoch:22 step:21040 [D loss: 0.476807, acc.: 78.12%] [G loss: 0.870916]\n",
      "epoch:22 step:21041 [D loss: 0.505073, acc.: 78.12%] [G loss: 0.872042]\n",
      "epoch:22 step:21042 [D loss: 0.513005, acc.: 71.88%] [G loss: 0.702671]\n",
      "epoch:22 step:21043 [D loss: 0.470602, acc.: 76.56%] [G loss: 0.796789]\n",
      "epoch:22 step:21044 [D loss: 0.539037, acc.: 69.53%] [G loss: 0.736483]\n",
      "epoch:22 step:21045 [D loss: 0.488986, acc.: 75.00%] [G loss: 0.758932]\n",
      "epoch:22 step:21046 [D loss: 0.546416, acc.: 70.31%] [G loss: 0.756625]\n",
      "epoch:22 step:21047 [D loss: 0.560605, acc.: 69.53%] [G loss: 0.646665]\n",
      "epoch:22 step:21048 [D loss: 0.527003, acc.: 70.31%] [G loss: 0.732187]\n",
      "epoch:22 step:21049 [D loss: 0.481321, acc.: 77.34%] [G loss: 0.713365]\n",
      "epoch:22 step:21050 [D loss: 0.464594, acc.: 77.34%] [G loss: 0.830212]\n",
      "epoch:22 step:21051 [D loss: 0.665984, acc.: 61.72%] [G loss: 0.588990]\n",
      "epoch:22 step:21052 [D loss: 0.569254, acc.: 69.53%] [G loss: 0.676357]\n",
      "epoch:22 step:21053 [D loss: 0.539173, acc.: 67.97%] [G loss: 0.683129]\n",
      "epoch:22 step:21054 [D loss: 0.479836, acc.: 76.56%] [G loss: 0.954443]\n",
      "epoch:22 step:21055 [D loss: 0.524873, acc.: 73.44%] [G loss: 0.755570]\n",
      "epoch:22 step:21056 [D loss: 0.628866, acc.: 61.72%] [G loss: 0.581923]\n",
      "epoch:22 step:21057 [D loss: 0.500417, acc.: 75.00%] [G loss: 0.685278]\n",
      "epoch:22 step:21058 [D loss: 0.514708, acc.: 71.09%] [G loss: 0.777689]\n",
      "epoch:22 step:21059 [D loss: 0.569283, acc.: 67.97%] [G loss: 0.566464]\n",
      "epoch:22 step:21060 [D loss: 0.499579, acc.: 74.22%] [G loss: 0.820599]\n",
      "epoch:22 step:21061 [D loss: 0.495571, acc.: 74.22%] [G loss: 0.747178]\n",
      "epoch:22 step:21062 [D loss: 0.566857, acc.: 67.19%] [G loss: 0.735781]\n",
      "epoch:22 step:21063 [D loss: 0.572991, acc.: 71.88%] [G loss: 0.721975]\n",
      "epoch:22 step:21064 [D loss: 0.450921, acc.: 77.34%] [G loss: 0.864683]\n",
      "epoch:22 step:21065 [D loss: 0.447612, acc.: 80.47%] [G loss: 0.798496]\n",
      "epoch:22 step:21066 [D loss: 0.516057, acc.: 70.31%] [G loss: 0.962148]\n",
      "epoch:22 step:21067 [D loss: 0.468812, acc.: 76.56%] [G loss: 0.871775]\n",
      "epoch:22 step:21068 [D loss: 0.592178, acc.: 65.62%] [G loss: 0.695003]\n",
      "epoch:22 step:21069 [D loss: 0.548329, acc.: 68.75%] [G loss: 0.653850]\n",
      "epoch:22 step:21070 [D loss: 0.638152, acc.: 64.84%] [G loss: 0.655583]\n",
      "epoch:22 step:21071 [D loss: 0.519031, acc.: 79.69%] [G loss: 0.873647]\n",
      "epoch:22 step:21072 [D loss: 0.605867, acc.: 67.97%] [G loss: 0.715303]\n",
      "epoch:22 step:21073 [D loss: 0.491076, acc.: 73.44%] [G loss: 0.751830]\n",
      "epoch:22 step:21074 [D loss: 0.521643, acc.: 70.31%] [G loss: 0.703257]\n",
      "epoch:22 step:21075 [D loss: 0.529737, acc.: 72.66%] [G loss: 0.627516]\n",
      "epoch:22 step:21076 [D loss: 0.525857, acc.: 70.31%] [G loss: 0.610140]\n",
      "epoch:22 step:21077 [D loss: 0.564244, acc.: 67.97%] [G loss: 0.589191]\n",
      "epoch:22 step:21078 [D loss: 0.484876, acc.: 74.22%] [G loss: 0.631395]\n",
      "epoch:22 step:21079 [D loss: 0.578277, acc.: 67.19%] [G loss: 0.493133]\n",
      "epoch:22 step:21080 [D loss: 0.497074, acc.: 75.00%] [G loss: 0.679537]\n",
      "epoch:22 step:21081 [D loss: 0.535947, acc.: 71.88%] [G loss: 0.730284]\n",
      "epoch:22 step:21082 [D loss: 0.549479, acc.: 70.31%] [G loss: 0.679107]\n",
      "epoch:22 step:21083 [D loss: 0.522942, acc.: 71.09%] [G loss: 0.738567]\n",
      "epoch:22 step:21084 [D loss: 0.519623, acc.: 74.22%] [G loss: 0.873259]\n",
      "epoch:22 step:21085 [D loss: 0.432077, acc.: 79.69%] [G loss: 0.970460]\n",
      "epoch:22 step:21086 [D loss: 0.452356, acc.: 80.47%] [G loss: 0.949743]\n",
      "epoch:22 step:21087 [D loss: 0.609557, acc.: 62.50%] [G loss: 0.896050]\n",
      "epoch:22 step:21088 [D loss: 0.545873, acc.: 71.88%] [G loss: 0.645479]\n",
      "epoch:22 step:21089 [D loss: 0.493787, acc.: 73.44%] [G loss: 0.821076]\n",
      "epoch:22 step:21090 [D loss: 0.535395, acc.: 78.91%] [G loss: 0.942908]\n",
      "epoch:22 step:21091 [D loss: 0.615496, acc.: 66.41%] [G loss: 0.709350]\n",
      "epoch:22 step:21092 [D loss: 0.553053, acc.: 69.53%] [G loss: 0.619334]\n",
      "epoch:22 step:21093 [D loss: 0.516943, acc.: 76.56%] [G loss: 0.612412]\n",
      "epoch:22 step:21094 [D loss: 0.565794, acc.: 70.31%] [G loss: 0.495361]\n",
      "epoch:22 step:21095 [D loss: 0.503298, acc.: 78.91%] [G loss: 0.718274]\n",
      "epoch:22 step:21096 [D loss: 0.579362, acc.: 71.88%] [G loss: 0.651050]\n",
      "epoch:22 step:21097 [D loss: 0.530442, acc.: 72.66%] [G loss: 0.635819]\n",
      "epoch:22 step:21098 [D loss: 0.485398, acc.: 76.56%] [G loss: 0.694004]\n",
      "epoch:22 step:21099 [D loss: 0.534243, acc.: 73.44%] [G loss: 0.686531]\n",
      "epoch:22 step:21100 [D loss: 0.564782, acc.: 71.09%] [G loss: 0.621657]\n",
      "epoch:22 step:21101 [D loss: 0.542190, acc.: 67.97%] [G loss: 0.716049]\n",
      "epoch:22 step:21102 [D loss: 0.540507, acc.: 62.50%] [G loss: 0.553119]\n",
      "epoch:22 step:21103 [D loss: 0.512815, acc.: 70.31%] [G loss: 0.652721]\n",
      "epoch:22 step:21104 [D loss: 0.532902, acc.: 71.88%] [G loss: 0.650928]\n",
      "epoch:22 step:21105 [D loss: 0.570597, acc.: 67.97%] [G loss: 0.761389]\n",
      "epoch:22 step:21106 [D loss: 0.649710, acc.: 66.41%] [G loss: 0.638454]\n",
      "epoch:22 step:21107 [D loss: 0.569687, acc.: 67.97%] [G loss: 0.492904]\n",
      "epoch:22 step:21108 [D loss: 0.571055, acc.: 69.53%] [G loss: 0.522381]\n",
      "epoch:22 step:21109 [D loss: 0.485994, acc.: 76.56%] [G loss: 0.690551]\n",
      "epoch:22 step:21110 [D loss: 0.520507, acc.: 78.12%] [G loss: 0.724440]\n",
      "epoch:22 step:21111 [D loss: 0.579391, acc.: 67.97%] [G loss: 0.759692]\n",
      "epoch:22 step:21112 [D loss: 0.533532, acc.: 71.09%] [G loss: 0.778167]\n",
      "epoch:22 step:21113 [D loss: 0.463353, acc.: 78.12%] [G loss: 1.061820]\n",
      "epoch:22 step:21114 [D loss: 0.577364, acc.: 70.31%] [G loss: 0.760813]\n",
      "epoch:22 step:21115 [D loss: 0.659116, acc.: 61.72%] [G loss: 0.600458]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21116 [D loss: 0.560408, acc.: 67.19%] [G loss: 0.706137]\n",
      "epoch:22 step:21117 [D loss: 0.492976, acc.: 76.56%] [G loss: 0.721692]\n",
      "epoch:22 step:21118 [D loss: 0.461489, acc.: 77.34%] [G loss: 0.906030]\n",
      "epoch:22 step:21119 [D loss: 0.466064, acc.: 78.12%] [G loss: 1.050735]\n",
      "epoch:22 step:21120 [D loss: 0.488928, acc.: 75.00%] [G loss: 0.968855]\n",
      "epoch:22 step:21121 [D loss: 0.475297, acc.: 76.56%] [G loss: 0.903821]\n",
      "epoch:22 step:21122 [D loss: 0.373867, acc.: 82.81%] [G loss: 0.990777]\n",
      "epoch:22 step:21123 [D loss: 0.538049, acc.: 71.09%] [G loss: 0.886088]\n",
      "epoch:22 step:21124 [D loss: 0.608690, acc.: 64.84%] [G loss: 0.731827]\n",
      "epoch:22 step:21125 [D loss: 0.676943, acc.: 59.38%] [G loss: 0.605493]\n",
      "epoch:22 step:21126 [D loss: 0.588513, acc.: 64.06%] [G loss: 0.663818]\n",
      "epoch:22 step:21127 [D loss: 0.517469, acc.: 73.44%] [G loss: 0.491666]\n",
      "epoch:22 step:21128 [D loss: 0.538088, acc.: 73.44%] [G loss: 0.661013]\n",
      "epoch:22 step:21129 [D loss: 0.533837, acc.: 73.44%] [G loss: 0.710039]\n",
      "epoch:22 step:21130 [D loss: 0.469885, acc.: 75.78%] [G loss: 0.826673]\n",
      "epoch:22 step:21131 [D loss: 0.498500, acc.: 74.22%] [G loss: 0.747563]\n",
      "epoch:22 step:21132 [D loss: 0.481375, acc.: 73.44%] [G loss: 0.942552]\n",
      "epoch:22 step:21133 [D loss: 0.481689, acc.: 76.56%] [G loss: 0.886213]\n",
      "epoch:22 step:21134 [D loss: 0.500746, acc.: 71.88%] [G loss: 0.655284]\n",
      "epoch:22 step:21135 [D loss: 0.529802, acc.: 75.00%] [G loss: 0.621344]\n",
      "epoch:22 step:21136 [D loss: 0.472924, acc.: 79.69%] [G loss: 0.660843]\n",
      "epoch:22 step:21137 [D loss: 0.451614, acc.: 77.34%] [G loss: 0.736649]\n",
      "epoch:22 step:21138 [D loss: 0.568615, acc.: 71.09%] [G loss: 0.738954]\n",
      "epoch:22 step:21139 [D loss: 0.632645, acc.: 67.19%] [G loss: 0.648437]\n",
      "epoch:22 step:21140 [D loss: 0.530180, acc.: 70.31%] [G loss: 0.609579]\n",
      "epoch:22 step:21141 [D loss: 0.563372, acc.: 64.84%] [G loss: 0.730068]\n",
      "epoch:22 step:21142 [D loss: 0.673768, acc.: 60.16%] [G loss: 0.663676]\n",
      "epoch:22 step:21143 [D loss: 0.588635, acc.: 67.97%] [G loss: 0.556516]\n",
      "epoch:22 step:21144 [D loss: 0.488222, acc.: 71.88%] [G loss: 0.726369]\n",
      "epoch:22 step:21145 [D loss: 0.571084, acc.: 69.53%] [G loss: 0.658908]\n",
      "epoch:22 step:21146 [D loss: 0.563784, acc.: 66.41%] [G loss: 0.625938]\n",
      "epoch:22 step:21147 [D loss: 0.497451, acc.: 75.78%] [G loss: 0.791085]\n",
      "epoch:22 step:21148 [D loss: 0.462462, acc.: 76.56%] [G loss: 0.877976]\n",
      "epoch:22 step:21149 [D loss: 0.632098, acc.: 66.41%] [G loss: 0.589946]\n",
      "epoch:22 step:21150 [D loss: 0.518605, acc.: 73.44%] [G loss: 0.588581]\n",
      "epoch:22 step:21151 [D loss: 0.616773, acc.: 66.41%] [G loss: 0.487464]\n",
      "epoch:22 step:21152 [D loss: 0.567245, acc.: 70.31%] [G loss: 0.504936]\n",
      "epoch:22 step:21153 [D loss: 0.519121, acc.: 71.09%] [G loss: 0.686144]\n",
      "epoch:22 step:21154 [D loss: 0.604331, acc.: 64.84%] [G loss: 0.507574]\n",
      "epoch:22 step:21155 [D loss: 0.488351, acc.: 75.00%] [G loss: 0.526762]\n",
      "epoch:22 step:21156 [D loss: 0.579622, acc.: 67.97%] [G loss: 0.595460]\n",
      "epoch:22 step:21157 [D loss: 0.557463, acc.: 67.19%] [G loss: 0.681096]\n",
      "epoch:22 step:21158 [D loss: 0.523784, acc.: 70.31%] [G loss: 0.634776]\n",
      "epoch:22 step:21159 [D loss: 0.582465, acc.: 67.19%] [G loss: 0.758340]\n",
      "epoch:22 step:21160 [D loss: 0.500841, acc.: 71.09%] [G loss: 0.838135]\n",
      "epoch:22 step:21161 [D loss: 0.507470, acc.: 75.78%] [G loss: 0.823872]\n",
      "epoch:22 step:21162 [D loss: 0.494521, acc.: 77.34%] [G loss: 0.715261]\n",
      "epoch:22 step:21163 [D loss: 0.544125, acc.: 71.88%] [G loss: 0.890535]\n",
      "epoch:22 step:21164 [D loss: 0.496792, acc.: 71.88%] [G loss: 0.698461]\n",
      "epoch:22 step:21165 [D loss: 0.563748, acc.: 68.75%] [G loss: 0.614013]\n",
      "epoch:22 step:21166 [D loss: 0.463298, acc.: 78.91%] [G loss: 0.646265]\n",
      "epoch:22 step:21167 [D loss: 0.589714, acc.: 67.19%] [G loss: 0.558078]\n",
      "epoch:22 step:21168 [D loss: 0.457076, acc.: 78.12%] [G loss: 0.706402]\n",
      "epoch:22 step:21169 [D loss: 0.513072, acc.: 75.00%] [G loss: 0.813805]\n",
      "epoch:22 step:21170 [D loss: 0.545829, acc.: 72.66%] [G loss: 0.670037]\n",
      "epoch:22 step:21171 [D loss: 0.487135, acc.: 78.91%] [G loss: 0.745248]\n",
      "epoch:22 step:21172 [D loss: 0.460776, acc.: 78.91%] [G loss: 0.795911]\n",
      "epoch:22 step:21173 [D loss: 0.590267, acc.: 64.84%] [G loss: 0.853531]\n",
      "epoch:22 step:21174 [D loss: 0.603844, acc.: 69.53%] [G loss: 0.514465]\n",
      "epoch:22 step:21175 [D loss: 0.539394, acc.: 71.88%] [G loss: 0.726851]\n",
      "epoch:22 step:21176 [D loss: 0.534667, acc.: 74.22%] [G loss: 0.679935]\n",
      "epoch:22 step:21177 [D loss: 0.534871, acc.: 72.66%] [G loss: 0.629736]\n",
      "epoch:22 step:21178 [D loss: 0.512241, acc.: 73.44%] [G loss: 0.773129]\n",
      "epoch:22 step:21179 [D loss: 0.543492, acc.: 70.31%] [G loss: 0.839618]\n",
      "epoch:22 step:21180 [D loss: 0.730528, acc.: 60.94%] [G loss: 0.582233]\n",
      "epoch:22 step:21181 [D loss: 0.518911, acc.: 70.31%] [G loss: 0.636039]\n",
      "epoch:22 step:21182 [D loss: 0.472945, acc.: 73.44%] [G loss: 0.615018]\n",
      "epoch:22 step:21183 [D loss: 0.495633, acc.: 73.44%] [G loss: 0.508013]\n",
      "epoch:22 step:21184 [D loss: 0.530092, acc.: 75.00%] [G loss: 0.630858]\n",
      "epoch:22 step:21185 [D loss: 0.510162, acc.: 73.44%] [G loss: 0.632983]\n",
      "epoch:22 step:21186 [D loss: 0.514777, acc.: 73.44%] [G loss: 0.863303]\n",
      "epoch:22 step:21187 [D loss: 0.532357, acc.: 74.22%] [G loss: 0.690237]\n",
      "epoch:22 step:21188 [D loss: 0.505654, acc.: 75.00%] [G loss: 0.752434]\n",
      "epoch:22 step:21189 [D loss: 0.412276, acc.: 82.03%] [G loss: 0.849510]\n",
      "epoch:22 step:21190 [D loss: 0.554273, acc.: 73.44%] [G loss: 0.688005]\n",
      "epoch:22 step:21191 [D loss: 0.591959, acc.: 67.97%] [G loss: 0.664790]\n",
      "epoch:22 step:21192 [D loss: 0.536740, acc.: 71.09%] [G loss: 0.663740]\n",
      "epoch:22 step:21193 [D loss: 0.556880, acc.: 71.88%] [G loss: 0.705288]\n",
      "epoch:22 step:21194 [D loss: 0.570057, acc.: 70.31%] [G loss: 0.672687]\n",
      "epoch:22 step:21195 [D loss: 0.508835, acc.: 74.22%] [G loss: 0.600566]\n",
      "epoch:22 step:21196 [D loss: 0.468209, acc.: 78.91%] [G loss: 0.589315]\n",
      "epoch:22 step:21197 [D loss: 0.507506, acc.: 74.22%] [G loss: 0.837450]\n",
      "epoch:22 step:21198 [D loss: 0.550884, acc.: 66.41%] [G loss: 0.556717]\n",
      "epoch:22 step:21199 [D loss: 0.558794, acc.: 63.28%] [G loss: 0.758393]\n",
      "epoch:22 step:21200 [D loss: 0.594101, acc.: 57.81%] [G loss: 0.600934]\n",
      "##############\n",
      "[3.04125058 1.20685622 6.16142316 4.98555605 4.00248158 5.52351332\n",
      " 4.49163155 4.84228853 4.72287091 4.24515372]\n",
      "##########\n",
      "epoch:22 step:21201 [D loss: 0.592258, acc.: 66.41%] [G loss: 0.574658]\n",
      "epoch:22 step:21202 [D loss: 0.568794, acc.: 73.44%] [G loss: 0.732134]\n",
      "epoch:22 step:21203 [D loss: 0.521493, acc.: 67.97%] [G loss: 0.850216]\n",
      "epoch:22 step:21204 [D loss: 0.561867, acc.: 65.62%] [G loss: 0.751544]\n",
      "epoch:22 step:21205 [D loss: 0.558156, acc.: 74.22%] [G loss: 0.610699]\n",
      "epoch:22 step:21206 [D loss: 0.476266, acc.: 78.91%] [G loss: 0.705209]\n",
      "epoch:22 step:21207 [D loss: 0.522864, acc.: 70.31%] [G loss: 0.751594]\n",
      "epoch:22 step:21208 [D loss: 0.547954, acc.: 69.53%] [G loss: 0.756525]\n",
      "epoch:22 step:21209 [D loss: 0.530190, acc.: 72.66%] [G loss: 0.659080]\n",
      "epoch:22 step:21210 [D loss: 0.500445, acc.: 74.22%] [G loss: 0.787068]\n",
      "epoch:22 step:21211 [D loss: 0.500752, acc.: 72.66%] [G loss: 0.580302]\n",
      "epoch:22 step:21212 [D loss: 0.516488, acc.: 77.34%] [G loss: 0.681484]\n",
      "epoch:22 step:21213 [D loss: 0.490425, acc.: 78.12%] [G loss: 0.630961]\n",
      "epoch:22 step:21214 [D loss: 0.542040, acc.: 72.66%] [G loss: 0.646485]\n",
      "epoch:22 step:21215 [D loss: 0.487310, acc.: 74.22%] [G loss: 0.716115]\n",
      "epoch:22 step:21216 [D loss: 0.490695, acc.: 71.88%] [G loss: 0.780710]\n",
      "epoch:22 step:21217 [D loss: 0.515827, acc.: 78.91%] [G loss: 0.696640]\n",
      "epoch:22 step:21218 [D loss: 0.584813, acc.: 65.62%] [G loss: 0.729030]\n",
      "epoch:22 step:21219 [D loss: 0.436228, acc.: 82.03%] [G loss: 0.835697]\n",
      "epoch:22 step:21220 [D loss: 0.627776, acc.: 67.97%] [G loss: 0.504863]\n",
      "epoch:22 step:21221 [D loss: 0.551115, acc.: 71.09%] [G loss: 0.596694]\n",
      "epoch:22 step:21222 [D loss: 0.521809, acc.: 72.66%] [G loss: 0.608749]\n",
      "epoch:22 step:21223 [D loss: 0.540004, acc.: 70.31%] [G loss: 0.521556]\n",
      "epoch:22 step:21224 [D loss: 0.585317, acc.: 69.53%] [G loss: 0.486828]\n",
      "epoch:22 step:21225 [D loss: 0.469441, acc.: 78.12%] [G loss: 0.677705]\n",
      "epoch:22 step:21226 [D loss: 0.537389, acc.: 68.75%] [G loss: 0.647925]\n",
      "epoch:22 step:21227 [D loss: 0.482797, acc.: 72.66%] [G loss: 0.667369]\n",
      "epoch:22 step:21228 [D loss: 0.529193, acc.: 73.44%] [G loss: 0.663416]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21229 [D loss: 0.596984, acc.: 64.84%] [G loss: 0.649410]\n",
      "epoch:22 step:21230 [D loss: 0.553142, acc.: 71.09%] [G loss: 0.629579]\n",
      "epoch:22 step:21231 [D loss: 0.582523, acc.: 70.31%] [G loss: 0.645396]\n",
      "epoch:22 step:21232 [D loss: 0.547226, acc.: 68.75%] [G loss: 0.623810]\n",
      "epoch:22 step:21233 [D loss: 0.554721, acc.: 71.09%] [G loss: 0.650453]\n",
      "epoch:22 step:21234 [D loss: 0.534109, acc.: 70.31%] [G loss: 0.870052]\n",
      "epoch:22 step:21235 [D loss: 0.524017, acc.: 74.22%] [G loss: 0.603243]\n",
      "epoch:22 step:21236 [D loss: 0.553261, acc.: 71.88%] [G loss: 0.624066]\n",
      "epoch:22 step:21237 [D loss: 0.517203, acc.: 73.44%] [G loss: 0.616483]\n",
      "epoch:22 step:21238 [D loss: 0.442228, acc.: 82.03%] [G loss: 0.636985]\n",
      "epoch:22 step:21239 [D loss: 0.613974, acc.: 67.19%] [G loss: 0.587287]\n",
      "epoch:22 step:21240 [D loss: 0.536318, acc.: 69.53%] [G loss: 0.585095]\n",
      "epoch:22 step:21241 [D loss: 0.490697, acc.: 75.78%] [G loss: 0.766703]\n",
      "epoch:22 step:21242 [D loss: 0.602429, acc.: 63.28%] [G loss: 0.661742]\n",
      "epoch:22 step:21243 [D loss: 0.478124, acc.: 74.22%] [G loss: 0.670886]\n",
      "epoch:22 step:21244 [D loss: 0.525207, acc.: 75.00%] [G loss: 0.665267]\n",
      "epoch:22 step:21245 [D loss: 0.515031, acc.: 77.34%] [G loss: 0.708206]\n",
      "epoch:22 step:21246 [D loss: 0.479709, acc.: 78.12%] [G loss: 0.723812]\n",
      "epoch:22 step:21247 [D loss: 0.522081, acc.: 75.00%] [G loss: 0.628348]\n",
      "epoch:22 step:21248 [D loss: 0.483672, acc.: 76.56%] [G loss: 0.788885]\n",
      "epoch:22 step:21249 [D loss: 0.542877, acc.: 67.19%] [G loss: 0.804161]\n",
      "epoch:22 step:21250 [D loss: 0.558173, acc.: 74.22%] [G loss: 0.752971]\n",
      "epoch:22 step:21251 [D loss: 0.560166, acc.: 69.53%] [G loss: 0.606582]\n",
      "epoch:22 step:21252 [D loss: 0.484194, acc.: 76.56%] [G loss: 0.724329]\n",
      "epoch:22 step:21253 [D loss: 0.543843, acc.: 68.75%] [G loss: 0.579753]\n",
      "epoch:22 step:21254 [D loss: 0.570137, acc.: 70.31%] [G loss: 0.752242]\n",
      "epoch:22 step:21255 [D loss: 0.476066, acc.: 72.66%] [G loss: 0.918197]\n",
      "epoch:22 step:21256 [D loss: 0.494970, acc.: 73.44%] [G loss: 0.805240]\n",
      "epoch:22 step:21257 [D loss: 0.515101, acc.: 75.78%] [G loss: 0.865585]\n",
      "epoch:22 step:21258 [D loss: 0.550384, acc.: 64.84%] [G loss: 0.737005]\n",
      "epoch:22 step:21259 [D loss: 0.497667, acc.: 74.22%] [G loss: 0.790047]\n",
      "epoch:22 step:21260 [D loss: 0.556906, acc.: 70.31%] [G loss: 0.638641]\n",
      "epoch:22 step:21261 [D loss: 0.476188, acc.: 79.69%] [G loss: 0.728462]\n",
      "epoch:22 step:21262 [D loss: 0.398773, acc.: 82.81%] [G loss: 0.972339]\n",
      "epoch:22 step:21263 [D loss: 0.485967, acc.: 75.00%] [G loss: 0.936615]\n",
      "epoch:22 step:21264 [D loss: 0.441492, acc.: 80.47%] [G loss: 0.937241]\n",
      "epoch:22 step:21265 [D loss: 0.465407, acc.: 76.56%] [G loss: 0.880638]\n",
      "epoch:22 step:21266 [D loss: 0.633755, acc.: 60.94%] [G loss: 0.658284]\n",
      "epoch:22 step:21267 [D loss: 0.556223, acc.: 71.09%] [G loss: 0.593663]\n",
      "epoch:22 step:21268 [D loss: 0.482639, acc.: 77.34%] [G loss: 0.723709]\n",
      "epoch:22 step:21269 [D loss: 0.505490, acc.: 75.78%] [G loss: 0.728551]\n",
      "epoch:22 step:21270 [D loss: 0.535594, acc.: 69.53%] [G loss: 0.695964]\n",
      "epoch:22 step:21271 [D loss: 0.478393, acc.: 74.22%] [G loss: 0.634134]\n",
      "epoch:22 step:21272 [D loss: 0.522645, acc.: 71.88%] [G loss: 0.809286]\n",
      "epoch:22 step:21273 [D loss: 0.535842, acc.: 69.53%] [G loss: 0.883710]\n",
      "epoch:22 step:21274 [D loss: 0.550249, acc.: 70.31%] [G loss: 0.751903]\n",
      "epoch:22 step:21275 [D loss: 0.476721, acc.: 74.22%] [G loss: 0.922182]\n",
      "epoch:22 step:21276 [D loss: 0.464235, acc.: 76.56%] [G loss: 0.719427]\n",
      "epoch:22 step:21277 [D loss: 0.536315, acc.: 68.75%] [G loss: 0.796532]\n",
      "epoch:22 step:21278 [D loss: 0.565192, acc.: 67.19%] [G loss: 0.827137]\n",
      "epoch:22 step:21279 [D loss: 0.548314, acc.: 68.75%] [G loss: 0.750370]\n",
      "epoch:22 step:21280 [D loss: 0.516285, acc.: 71.88%] [G loss: 0.916607]\n",
      "epoch:22 step:21281 [D loss: 0.515641, acc.: 73.44%] [G loss: 0.805258]\n",
      "epoch:22 step:21282 [D loss: 0.539574, acc.: 68.75%] [G loss: 0.833572]\n",
      "epoch:22 step:21283 [D loss: 0.540675, acc.: 71.09%] [G loss: 0.764338]\n",
      "epoch:22 step:21284 [D loss: 0.522460, acc.: 68.75%] [G loss: 0.647538]\n",
      "epoch:22 step:21285 [D loss: 0.542614, acc.: 69.53%] [G loss: 0.718849]\n",
      "epoch:22 step:21286 [D loss: 0.533716, acc.: 71.09%] [G loss: 0.733613]\n",
      "epoch:22 step:21287 [D loss: 0.513011, acc.: 72.66%] [G loss: 0.696903]\n",
      "epoch:22 step:21288 [D loss: 0.503581, acc.: 75.78%] [G loss: 0.948900]\n",
      "epoch:22 step:21289 [D loss: 0.582719, acc.: 64.84%] [G loss: 0.626651]\n",
      "epoch:22 step:21290 [D loss: 0.503546, acc.: 70.31%] [G loss: 0.739184]\n",
      "epoch:22 step:21291 [D loss: 0.546705, acc.: 69.53%] [G loss: 0.707080]\n",
      "epoch:22 step:21292 [D loss: 0.567489, acc.: 71.09%] [G loss: 0.715172]\n",
      "epoch:22 step:21293 [D loss: 0.520825, acc.: 68.75%] [G loss: 0.543284]\n",
      "epoch:22 step:21294 [D loss: 0.521001, acc.: 74.22%] [G loss: 0.624666]\n",
      "epoch:22 step:21295 [D loss: 0.488500, acc.: 72.66%] [G loss: 0.732397]\n",
      "epoch:22 step:21296 [D loss: 0.540844, acc.: 69.53%] [G loss: 0.736908]\n",
      "epoch:22 step:21297 [D loss: 0.501018, acc.: 75.00%] [G loss: 0.740262]\n",
      "epoch:22 step:21298 [D loss: 0.610757, acc.: 67.97%] [G loss: 0.502738]\n",
      "epoch:22 step:21299 [D loss: 0.506621, acc.: 73.44%] [G loss: 0.616310]\n",
      "epoch:22 step:21300 [D loss: 0.546707, acc.: 71.88%] [G loss: 0.694496]\n",
      "epoch:22 step:21301 [D loss: 0.523067, acc.: 68.75%] [G loss: 0.696717]\n",
      "epoch:22 step:21302 [D loss: 0.516351, acc.: 73.44%] [G loss: 0.555650]\n",
      "epoch:22 step:21303 [D loss: 0.532105, acc.: 67.97%] [G loss: 0.614652]\n",
      "epoch:22 step:21304 [D loss: 0.485213, acc.: 75.78%] [G loss: 0.665086]\n",
      "epoch:22 step:21305 [D loss: 0.525945, acc.: 71.88%] [G loss: 0.787965]\n",
      "epoch:22 step:21306 [D loss: 0.530816, acc.: 75.78%] [G loss: 0.723719]\n",
      "epoch:22 step:21307 [D loss: 0.450273, acc.: 76.56%] [G loss: 0.889211]\n",
      "epoch:22 step:21308 [D loss: 0.501519, acc.: 75.78%] [G loss: 0.842132]\n",
      "epoch:22 step:21309 [D loss: 0.503540, acc.: 78.12%] [G loss: 0.793324]\n",
      "epoch:22 step:21310 [D loss: 0.612249, acc.: 61.72%] [G loss: 0.562607]\n",
      "epoch:22 step:21311 [D loss: 0.586151, acc.: 63.28%] [G loss: 0.454220]\n",
      "epoch:22 step:21312 [D loss: 0.598859, acc.: 67.19%] [G loss: 0.622667]\n",
      "epoch:22 step:21313 [D loss: 0.457414, acc.: 80.47%] [G loss: 0.717773]\n",
      "epoch:22 step:21314 [D loss: 0.531668, acc.: 71.88%] [G loss: 0.682113]\n",
      "epoch:22 step:21315 [D loss: 0.498662, acc.: 73.44%] [G loss: 0.670723]\n",
      "epoch:22 step:21316 [D loss: 0.558766, acc.: 69.53%] [G loss: 0.706840]\n",
      "epoch:22 step:21317 [D loss: 0.631496, acc.: 58.59%] [G loss: 0.548449]\n",
      "epoch:22 step:21318 [D loss: 0.637838, acc.: 67.19%] [G loss: 0.612902]\n",
      "epoch:22 step:21319 [D loss: 0.523447, acc.: 69.53%] [G loss: 0.767447]\n",
      "epoch:22 step:21320 [D loss: 0.526985, acc.: 70.31%] [G loss: 0.711141]\n",
      "epoch:22 step:21321 [D loss: 0.514313, acc.: 67.97%] [G loss: 1.111341]\n",
      "epoch:22 step:21322 [D loss: 0.498129, acc.: 76.56%] [G loss: 0.995321]\n",
      "epoch:22 step:21323 [D loss: 0.470622, acc.: 77.34%] [G loss: 0.837152]\n",
      "epoch:22 step:21324 [D loss: 0.578458, acc.: 68.75%] [G loss: 0.741475]\n",
      "epoch:22 step:21325 [D loss: 0.583273, acc.: 67.19%] [G loss: 0.707756]\n",
      "epoch:22 step:21326 [D loss: 0.553515, acc.: 70.31%] [G loss: 0.624012]\n",
      "epoch:22 step:21327 [D loss: 0.558425, acc.: 71.88%] [G loss: 0.660679]\n",
      "epoch:22 step:21328 [D loss: 0.545957, acc.: 69.53%] [G loss: 0.608853]\n",
      "epoch:22 step:21329 [D loss: 0.574366, acc.: 69.53%] [G loss: 0.644971]\n",
      "epoch:22 step:21330 [D loss: 0.626500, acc.: 64.84%] [G loss: 0.578869]\n",
      "epoch:22 step:21331 [D loss: 0.570226, acc.: 66.41%] [G loss: 0.691073]\n",
      "epoch:22 step:21332 [D loss: 0.575281, acc.: 67.19%] [G loss: 0.739879]\n",
      "epoch:22 step:21333 [D loss: 0.476460, acc.: 81.25%] [G loss: 0.755582]\n",
      "epoch:22 step:21334 [D loss: 0.570480, acc.: 67.19%] [G loss: 0.701920]\n",
      "epoch:22 step:21335 [D loss: 0.534919, acc.: 70.31%] [G loss: 0.555882]\n",
      "epoch:22 step:21336 [D loss: 0.607563, acc.: 66.41%] [G loss: 0.654452]\n",
      "epoch:22 step:21337 [D loss: 0.576770, acc.: 69.53%] [G loss: 0.661621]\n",
      "epoch:22 step:21338 [D loss: 0.456773, acc.: 77.34%] [G loss: 0.855012]\n",
      "epoch:22 step:21339 [D loss: 0.523991, acc.: 72.66%] [G loss: 0.739938]\n",
      "epoch:22 step:21340 [D loss: 0.498474, acc.: 74.22%] [G loss: 0.860150]\n",
      "epoch:22 step:21341 [D loss: 0.588671, acc.: 65.62%] [G loss: 0.591046]\n",
      "epoch:22 step:21342 [D loss: 0.570384, acc.: 69.53%] [G loss: 0.518299]\n",
      "epoch:22 step:21343 [D loss: 0.536857, acc.: 72.66%] [G loss: 0.647639]\n",
      "epoch:22 step:21344 [D loss: 0.527840, acc.: 73.44%] [G loss: 0.575900]\n",
      "epoch:22 step:21345 [D loss: 0.570864, acc.: 67.19%] [G loss: 0.614484]\n",
      "epoch:22 step:21346 [D loss: 0.488872, acc.: 73.44%] [G loss: 0.647349]\n",
      "epoch:22 step:21347 [D loss: 0.533198, acc.: 73.44%] [G loss: 0.748416]\n",
      "epoch:22 step:21348 [D loss: 0.508883, acc.: 72.66%] [G loss: 0.611119]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21349 [D loss: 0.546624, acc.: 65.62%] [G loss: 0.618635]\n",
      "epoch:22 step:21350 [D loss: 0.507311, acc.: 70.31%] [G loss: 0.670716]\n",
      "epoch:22 step:21351 [D loss: 0.499696, acc.: 75.00%] [G loss: 0.759443]\n",
      "epoch:22 step:21352 [D loss: 0.568018, acc.: 68.75%] [G loss: 0.577200]\n",
      "epoch:22 step:21353 [D loss: 0.623829, acc.: 64.84%] [G loss: 0.549354]\n",
      "epoch:22 step:21354 [D loss: 0.670113, acc.: 53.91%] [G loss: 0.421861]\n",
      "epoch:22 step:21355 [D loss: 0.517521, acc.: 75.78%] [G loss: 0.577658]\n",
      "epoch:22 step:21356 [D loss: 0.483257, acc.: 73.44%] [G loss: 0.631550]\n",
      "epoch:22 step:21357 [D loss: 0.509518, acc.: 75.00%] [G loss: 0.778436]\n",
      "epoch:22 step:21358 [D loss: 0.495147, acc.: 73.44%] [G loss: 0.762223]\n",
      "epoch:22 step:21359 [D loss: 0.568748, acc.: 69.53%] [G loss: 0.661276]\n",
      "epoch:22 step:21360 [D loss: 0.460755, acc.: 76.56%] [G loss: 0.722493]\n",
      "epoch:22 step:21361 [D loss: 0.418463, acc.: 78.12%] [G loss: 0.934025]\n",
      "epoch:22 step:21362 [D loss: 0.568138, acc.: 67.19%] [G loss: 0.798377]\n",
      "epoch:22 step:21363 [D loss: 0.512121, acc.: 74.22%] [G loss: 0.789115]\n",
      "epoch:22 step:21364 [D loss: 0.503345, acc.: 71.88%] [G loss: 0.973733]\n",
      "epoch:22 step:21365 [D loss: 0.548402, acc.: 66.41%] [G loss: 0.891501]\n",
      "epoch:22 step:21366 [D loss: 0.546286, acc.: 67.97%] [G loss: 0.714565]\n",
      "epoch:22 step:21367 [D loss: 0.525913, acc.: 74.22%] [G loss: 0.800421]\n",
      "epoch:22 step:21368 [D loss: 0.583726, acc.: 64.84%] [G loss: 0.715207]\n",
      "epoch:22 step:21369 [D loss: 0.542686, acc.: 67.97%] [G loss: 0.675118]\n",
      "epoch:22 step:21370 [D loss: 0.556514, acc.: 67.19%] [G loss: 0.689453]\n",
      "epoch:22 step:21371 [D loss: 0.535118, acc.: 66.41%] [G loss: 0.683197]\n",
      "epoch:22 step:21372 [D loss: 0.543458, acc.: 71.88%] [G loss: 0.639809]\n",
      "epoch:22 step:21373 [D loss: 0.572868, acc.: 66.41%] [G loss: 0.570855]\n",
      "epoch:22 step:21374 [D loss: 0.568345, acc.: 67.97%] [G loss: 0.618651]\n",
      "epoch:22 step:21375 [D loss: 0.569477, acc.: 66.41%] [G loss: 0.647004]\n",
      "epoch:22 step:21376 [D loss: 0.570189, acc.: 66.41%] [G loss: 0.567319]\n",
      "epoch:22 step:21377 [D loss: 0.573647, acc.: 67.97%] [G loss: 0.687775]\n",
      "epoch:22 step:21378 [D loss: 0.537194, acc.: 67.97%] [G loss: 0.652272]\n",
      "epoch:22 step:21379 [D loss: 0.629845, acc.: 60.16%] [G loss: 0.531690]\n",
      "epoch:22 step:21380 [D loss: 0.666089, acc.: 56.25%] [G loss: 0.584366]\n",
      "epoch:22 step:21381 [D loss: 0.496459, acc.: 74.22%] [G loss: 0.679675]\n",
      "epoch:22 step:21382 [D loss: 0.547167, acc.: 68.75%] [G loss: 0.685714]\n",
      "epoch:22 step:21383 [D loss: 0.471965, acc.: 78.91%] [G loss: 0.942464]\n",
      "epoch:22 step:21384 [D loss: 0.552779, acc.: 67.19%] [G loss: 0.982778]\n",
      "epoch:22 step:21385 [D loss: 0.569793, acc.: 66.41%] [G loss: 0.749434]\n",
      "epoch:22 step:21386 [D loss: 0.532007, acc.: 71.88%] [G loss: 0.746444]\n",
      "epoch:22 step:21387 [D loss: 0.557971, acc.: 70.31%] [G loss: 0.800290]\n",
      "epoch:22 step:21388 [D loss: 0.516132, acc.: 75.78%] [G loss: 0.758838]\n",
      "epoch:22 step:21389 [D loss: 0.552958, acc.: 68.75%] [G loss: 0.839315]\n",
      "epoch:22 step:21390 [D loss: 0.585018, acc.: 69.53%] [G loss: 0.630636]\n",
      "epoch:22 step:21391 [D loss: 0.556691, acc.: 67.19%] [G loss: 0.622667]\n",
      "epoch:22 step:21392 [D loss: 0.555066, acc.: 71.09%] [G loss: 0.543129]\n",
      "epoch:22 step:21393 [D loss: 0.546966, acc.: 71.09%] [G loss: 0.636653]\n",
      "epoch:22 step:21394 [D loss: 0.545736, acc.: 76.56%] [G loss: 0.609175]\n",
      "epoch:22 step:21395 [D loss: 0.486075, acc.: 78.12%] [G loss: 0.782680]\n",
      "epoch:22 step:21396 [D loss: 0.510888, acc.: 75.00%] [G loss: 0.845483]\n",
      "epoch:22 step:21397 [D loss: 0.556714, acc.: 68.75%] [G loss: 0.785550]\n",
      "epoch:22 step:21398 [D loss: 0.568513, acc.: 67.97%] [G loss: 0.751605]\n",
      "epoch:22 step:21399 [D loss: 0.510496, acc.: 75.00%] [G loss: 0.658452]\n",
      "epoch:22 step:21400 [D loss: 0.559234, acc.: 71.09%] [G loss: 0.662904]\n",
      "##############\n",
      "[3.20828425 1.46621766 6.46483118 5.04679292 3.68489355 5.8802679\n",
      " 4.63002169 4.80222847 4.90148172 4.22546318]\n",
      "##########\n",
      "epoch:22 step:21401 [D loss: 0.595573, acc.: 65.62%] [G loss: 0.596187]\n",
      "epoch:22 step:21402 [D loss: 0.640704, acc.: 59.38%] [G loss: 0.580446]\n",
      "epoch:22 step:21403 [D loss: 0.517487, acc.: 71.88%] [G loss: 0.555246]\n",
      "epoch:22 step:21404 [D loss: 0.505214, acc.: 70.31%] [G loss: 0.606156]\n",
      "epoch:22 step:21405 [D loss: 0.565624, acc.: 71.88%] [G loss: 0.709127]\n",
      "epoch:22 step:21406 [D loss: 0.430818, acc.: 77.34%] [G loss: 0.683707]\n",
      "epoch:22 step:21407 [D loss: 0.613276, acc.: 66.41%] [G loss: 0.711577]\n",
      "epoch:22 step:21408 [D loss: 0.627845, acc.: 64.06%] [G loss: 0.655840]\n",
      "epoch:22 step:21409 [D loss: 0.509862, acc.: 71.88%] [G loss: 0.666764]\n",
      "epoch:22 step:21410 [D loss: 0.534776, acc.: 71.09%] [G loss: 0.819039]\n",
      "epoch:22 step:21411 [D loss: 0.513466, acc.: 75.00%] [G loss: 0.639066]\n",
      "epoch:22 step:21412 [D loss: 0.498996, acc.: 73.44%] [G loss: 0.613663]\n",
      "epoch:22 step:21413 [D loss: 0.505829, acc.: 74.22%] [G loss: 0.784879]\n",
      "epoch:22 step:21414 [D loss: 0.570371, acc.: 71.88%] [G loss: 0.708020]\n",
      "epoch:22 step:21415 [D loss: 0.500587, acc.: 78.91%] [G loss: 0.720314]\n",
      "epoch:22 step:21416 [D loss: 0.464610, acc.: 79.69%] [G loss: 0.844337]\n",
      "epoch:22 step:21417 [D loss: 0.509202, acc.: 75.00%] [G loss: 0.863262]\n",
      "epoch:22 step:21418 [D loss: 0.517758, acc.: 70.31%] [G loss: 0.689176]\n",
      "epoch:22 step:21419 [D loss: 0.532099, acc.: 72.66%] [G loss: 0.581194]\n",
      "epoch:22 step:21420 [D loss: 0.460508, acc.: 78.12%] [G loss: 0.734671]\n",
      "epoch:22 step:21421 [D loss: 0.515118, acc.: 72.66%] [G loss: 0.575972]\n",
      "epoch:22 step:21422 [D loss: 0.467575, acc.: 75.78%] [G loss: 0.707902]\n",
      "epoch:22 step:21423 [D loss: 0.511131, acc.: 72.66%] [G loss: 0.651379]\n",
      "epoch:22 step:21424 [D loss: 0.529923, acc.: 72.66%] [G loss: 0.441900]\n",
      "epoch:22 step:21425 [D loss: 0.573133, acc.: 67.19%] [G loss: 0.655210]\n",
      "epoch:22 step:21426 [D loss: 0.587772, acc.: 64.06%] [G loss: 0.583578]\n",
      "epoch:22 step:21427 [D loss: 0.555404, acc.: 67.19%] [G loss: 0.456774]\n",
      "epoch:22 step:21428 [D loss: 0.445349, acc.: 78.91%] [G loss: 0.785575]\n",
      "epoch:22 step:21429 [D loss: 0.488742, acc.: 71.88%] [G loss: 0.768898]\n",
      "epoch:22 step:21430 [D loss: 0.588170, acc.: 67.97%] [G loss: 0.899777]\n",
      "epoch:22 step:21431 [D loss: 0.562193, acc.: 70.31%] [G loss: 0.824633]\n",
      "epoch:22 step:21432 [D loss: 0.558288, acc.: 71.88%] [G loss: 0.685244]\n",
      "epoch:22 step:21433 [D loss: 0.487271, acc.: 75.00%] [G loss: 0.644768]\n",
      "epoch:22 step:21434 [D loss: 0.634565, acc.: 66.41%] [G loss: 0.615580]\n",
      "epoch:22 step:21435 [D loss: 0.509864, acc.: 75.78%] [G loss: 0.510834]\n",
      "epoch:22 step:21436 [D loss: 0.521869, acc.: 71.09%] [G loss: 0.659028]\n",
      "epoch:22 step:21437 [D loss: 0.448808, acc.: 75.78%] [G loss: 0.645396]\n",
      "epoch:22 step:21438 [D loss: 0.526460, acc.: 71.09%] [G loss: 0.722907]\n",
      "epoch:22 step:21439 [D loss: 0.484006, acc.: 75.00%] [G loss: 0.703507]\n",
      "epoch:22 step:21440 [D loss: 0.527583, acc.: 73.44%] [G loss: 0.612152]\n",
      "epoch:22 step:21441 [D loss: 0.571472, acc.: 71.09%] [G loss: 0.619687]\n",
      "epoch:22 step:21442 [D loss: 0.620203, acc.: 64.06%] [G loss: 0.611058]\n",
      "epoch:22 step:21443 [D loss: 0.536663, acc.: 72.66%] [G loss: 0.684333]\n",
      "epoch:22 step:21444 [D loss: 0.482779, acc.: 75.78%] [G loss: 0.788457]\n",
      "epoch:22 step:21445 [D loss: 0.542050, acc.: 69.53%] [G loss: 0.630329]\n",
      "epoch:22 step:21446 [D loss: 0.558920, acc.: 69.53%] [G loss: 0.732659]\n",
      "epoch:22 step:21447 [D loss: 0.562604, acc.: 68.75%] [G loss: 0.588316]\n",
      "epoch:22 step:21448 [D loss: 0.511307, acc.: 73.44%] [G loss: 0.577858]\n",
      "epoch:22 step:21449 [D loss: 0.549367, acc.: 71.88%] [G loss: 0.512355]\n",
      "epoch:22 step:21450 [D loss: 0.537541, acc.: 68.75%] [G loss: 0.529119]\n",
      "epoch:22 step:21451 [D loss: 0.586839, acc.: 67.97%] [G loss: 0.595785]\n",
      "epoch:22 step:21452 [D loss: 0.496308, acc.: 75.78%] [G loss: 0.586639]\n",
      "epoch:22 step:21453 [D loss: 0.570806, acc.: 68.75%] [G loss: 0.585454]\n",
      "epoch:22 step:21454 [D loss: 0.625560, acc.: 64.84%] [G loss: 0.455459]\n",
      "epoch:22 step:21455 [D loss: 0.563760, acc.: 70.31%] [G loss: 0.642995]\n",
      "epoch:22 step:21456 [D loss: 0.482785, acc.: 78.12%] [G loss: 0.524163]\n",
      "epoch:22 step:21457 [D loss: 0.494638, acc.: 75.00%] [G loss: 0.792927]\n",
      "epoch:22 step:21458 [D loss: 0.566320, acc.: 68.75%] [G loss: 0.658236]\n",
      "epoch:22 step:21459 [D loss: 0.553614, acc.: 67.97%] [G loss: 0.684377]\n",
      "epoch:22 step:21460 [D loss: 0.580200, acc.: 63.28%] [G loss: 0.711566]\n",
      "epoch:22 step:21461 [D loss: 0.584584, acc.: 66.41%] [G loss: 0.459174]\n",
      "epoch:22 step:21462 [D loss: 0.635850, acc.: 63.28%] [G loss: 0.568314]\n",
      "epoch:22 step:21463 [D loss: 0.554415, acc.: 64.84%] [G loss: 0.569004]\n",
      "epoch:22 step:21464 [D loss: 0.523620, acc.: 75.78%] [G loss: 0.584467]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21465 [D loss: 0.521989, acc.: 68.75%] [G loss: 0.636672]\n",
      "epoch:22 step:21466 [D loss: 0.510438, acc.: 71.88%] [G loss: 0.526597]\n",
      "epoch:22 step:21467 [D loss: 0.546166, acc.: 73.44%] [G loss: 0.645638]\n",
      "epoch:22 step:21468 [D loss: 0.546168, acc.: 69.53%] [G loss: 0.537101]\n",
      "epoch:22 step:21469 [D loss: 0.567833, acc.: 66.41%] [G loss: 0.543658]\n",
      "epoch:22 step:21470 [D loss: 0.626916, acc.: 64.06%] [G loss: 0.623283]\n",
      "epoch:22 step:21471 [D loss: 0.451528, acc.: 78.12%] [G loss: 0.756622]\n",
      "epoch:22 step:21472 [D loss: 0.552727, acc.: 71.09%] [G loss: 0.682917]\n",
      "epoch:22 step:21473 [D loss: 0.494085, acc.: 75.00%] [G loss: 0.749311]\n",
      "epoch:22 step:21474 [D loss: 0.468568, acc.: 80.47%] [G loss: 0.714474]\n",
      "epoch:22 step:21475 [D loss: 0.620579, acc.: 65.62%] [G loss: 0.652629]\n",
      "epoch:22 step:21476 [D loss: 0.539951, acc.: 67.97%] [G loss: 0.494585]\n",
      "epoch:22 step:21477 [D loss: 0.555481, acc.: 67.19%] [G loss: 0.483643]\n",
      "epoch:22 step:21478 [D loss: 0.536428, acc.: 67.19%] [G loss: 0.537895]\n",
      "epoch:22 step:21479 [D loss: 0.540232, acc.: 70.31%] [G loss: 0.509798]\n",
      "epoch:22 step:21480 [D loss: 0.503166, acc.: 67.19%] [G loss: 0.621482]\n",
      "epoch:22 step:21481 [D loss: 0.619377, acc.: 64.06%] [G loss: 0.527569]\n",
      "epoch:22 step:21482 [D loss: 0.511094, acc.: 72.66%] [G loss: 0.608761]\n",
      "epoch:22 step:21483 [D loss: 0.552457, acc.: 66.41%] [G loss: 0.519225]\n",
      "epoch:22 step:21484 [D loss: 0.490069, acc.: 78.12%] [G loss: 0.705945]\n",
      "epoch:22 step:21485 [D loss: 0.513452, acc.: 73.44%] [G loss: 0.724541]\n",
      "epoch:22 step:21486 [D loss: 0.504714, acc.: 75.78%] [G loss: 0.669712]\n",
      "epoch:22 step:21487 [D loss: 0.578067, acc.: 65.62%] [G loss: 0.701086]\n",
      "epoch:22 step:21488 [D loss: 0.554523, acc.: 68.75%] [G loss: 0.628954]\n",
      "epoch:22 step:21489 [D loss: 0.436374, acc.: 80.47%] [G loss: 0.735157]\n",
      "epoch:22 step:21490 [D loss: 0.521677, acc.: 75.78%] [G loss: 0.668534]\n",
      "epoch:22 step:21491 [D loss: 0.576954, acc.: 63.28%] [G loss: 0.589936]\n",
      "epoch:22 step:21492 [D loss: 0.488559, acc.: 75.78%] [G loss: 0.668228]\n",
      "epoch:22 step:21493 [D loss: 0.558089, acc.: 64.84%] [G loss: 0.560847]\n",
      "epoch:22 step:21494 [D loss: 0.615276, acc.: 62.50%] [G loss: 0.480920]\n",
      "epoch:22 step:21495 [D loss: 0.541919, acc.: 71.88%] [G loss: 0.469151]\n",
      "epoch:22 step:21496 [D loss: 0.590411, acc.: 62.50%] [G loss: 0.547620]\n",
      "epoch:22 step:21497 [D loss: 0.560260, acc.: 67.97%] [G loss: 0.645427]\n",
      "epoch:22 step:21498 [D loss: 0.483179, acc.: 74.22%] [G loss: 0.697803]\n",
      "epoch:22 step:21499 [D loss: 0.506262, acc.: 74.22%] [G loss: 0.817120]\n",
      "epoch:22 step:21500 [D loss: 0.522969, acc.: 69.53%] [G loss: 0.800200]\n",
      "epoch:22 step:21501 [D loss: 0.583079, acc.: 67.19%] [G loss: 0.687145]\n",
      "epoch:22 step:21502 [D loss: 0.533689, acc.: 68.75%] [G loss: 0.616938]\n",
      "epoch:22 step:21503 [D loss: 0.575623, acc.: 66.41%] [G loss: 0.643189]\n",
      "epoch:22 step:21504 [D loss: 0.503858, acc.: 75.78%] [G loss: 0.656614]\n",
      "epoch:22 step:21505 [D loss: 0.511237, acc.: 70.31%] [G loss: 0.788047]\n",
      "epoch:22 step:21506 [D loss: 0.616954, acc.: 64.84%] [G loss: 0.566810]\n",
      "epoch:22 step:21507 [D loss: 0.551590, acc.: 71.88%] [G loss: 0.450334]\n",
      "epoch:22 step:21508 [D loss: 0.472881, acc.: 73.44%] [G loss: 0.522313]\n",
      "epoch:22 step:21509 [D loss: 0.545994, acc.: 71.88%] [G loss: 0.560265]\n",
      "epoch:22 step:21510 [D loss: 0.519119, acc.: 73.44%] [G loss: 0.877817]\n",
      "epoch:22 step:21511 [D loss: 0.496675, acc.: 75.78%] [G loss: 0.732125]\n",
      "epoch:22 step:21512 [D loss: 0.456505, acc.: 78.12%] [G loss: 0.897021]\n",
      "epoch:22 step:21513 [D loss: 0.488559, acc.: 75.78%] [G loss: 0.819507]\n",
      "epoch:22 step:21514 [D loss: 0.484749, acc.: 77.34%] [G loss: 0.735222]\n",
      "epoch:22 step:21515 [D loss: 0.545925, acc.: 73.44%] [G loss: 0.733710]\n",
      "epoch:22 step:21516 [D loss: 0.594954, acc.: 67.97%] [G loss: 0.763955]\n",
      "epoch:22 step:21517 [D loss: 0.515017, acc.: 76.56%] [G loss: 0.666876]\n",
      "epoch:22 step:21518 [D loss: 0.559451, acc.: 66.41%] [G loss: 0.748797]\n",
      "epoch:22 step:21519 [D loss: 0.552464, acc.: 70.31%] [G loss: 0.691190]\n",
      "epoch:22 step:21520 [D loss: 0.526149, acc.: 70.31%] [G loss: 0.725390]\n",
      "epoch:22 step:21521 [D loss: 0.509375, acc.: 71.88%] [G loss: 0.787640]\n",
      "epoch:22 step:21522 [D loss: 0.565608, acc.: 67.19%] [G loss: 0.617979]\n",
      "epoch:22 step:21523 [D loss: 0.488707, acc.: 75.78%] [G loss: 0.722006]\n",
      "epoch:22 step:21524 [D loss: 0.503976, acc.: 75.00%] [G loss: 0.735651]\n",
      "epoch:22 step:21525 [D loss: 0.485356, acc.: 75.00%] [G loss: 0.775143]\n",
      "epoch:22 step:21526 [D loss: 0.497635, acc.: 77.34%] [G loss: 0.899393]\n",
      "epoch:22 step:21527 [D loss: 0.515783, acc.: 75.78%] [G loss: 0.968896]\n",
      "epoch:22 step:21528 [D loss: 0.556408, acc.: 68.75%] [G loss: 0.800019]\n",
      "epoch:22 step:21529 [D loss: 0.618613, acc.: 63.28%] [G loss: 0.622178]\n",
      "epoch:22 step:21530 [D loss: 0.488703, acc.: 78.12%] [G loss: 0.657781]\n",
      "epoch:22 step:21531 [D loss: 0.561372, acc.: 66.41%] [G loss: 0.639300]\n",
      "epoch:22 step:21532 [D loss: 0.482824, acc.: 79.69%] [G loss: 0.615735]\n",
      "epoch:22 step:21533 [D loss: 0.462740, acc.: 83.59%] [G loss: 0.920232]\n",
      "epoch:22 step:21534 [D loss: 0.742464, acc.: 60.94%] [G loss: 0.735351]\n",
      "epoch:22 step:21535 [D loss: 0.499232, acc.: 74.22%] [G loss: 0.675104]\n",
      "epoch:22 step:21536 [D loss: 0.584943, acc.: 63.28%] [G loss: 0.645161]\n",
      "epoch:22 step:21537 [D loss: 0.422352, acc.: 82.81%] [G loss: 0.776264]\n",
      "epoch:22 step:21538 [D loss: 0.420635, acc.: 84.38%] [G loss: 0.991828]\n",
      "epoch:22 step:21539 [D loss: 0.434655, acc.: 78.12%] [G loss: 1.184932]\n",
      "epoch:22 step:21540 [D loss: 0.444977, acc.: 75.78%] [G loss: 1.232862]\n",
      "epoch:22 step:21541 [D loss: 0.469280, acc.: 77.34%] [G loss: 1.081841]\n",
      "epoch:22 step:21542 [D loss: 0.680328, acc.: 62.50%] [G loss: 0.965001]\n",
      "epoch:22 step:21543 [D loss: 0.492741, acc.: 74.22%] [G loss: 1.253125]\n",
      "epoch:22 step:21544 [D loss: 0.451444, acc.: 75.78%] [G loss: 1.289392]\n",
      "epoch:22 step:21545 [D loss: 0.549138, acc.: 67.19%] [G loss: 0.928590]\n",
      "epoch:22 step:21546 [D loss: 0.615396, acc.: 64.84%] [G loss: 0.810681]\n",
      "epoch:22 step:21547 [D loss: 0.469130, acc.: 78.91%] [G loss: 0.947296]\n",
      "epoch:22 step:21548 [D loss: 0.570633, acc.: 63.28%] [G loss: 0.952813]\n",
      "epoch:22 step:21549 [D loss: 0.466052, acc.: 75.00%] [G loss: 0.974290]\n",
      "epoch:22 step:21550 [D loss: 0.391271, acc.: 80.47%] [G loss: 0.979287]\n",
      "epoch:22 step:21551 [D loss: 0.406625, acc.: 85.16%] [G loss: 1.066381]\n",
      "epoch:23 step:21552 [D loss: 0.620439, acc.: 68.75%] [G loss: 1.126229]\n",
      "epoch:23 step:21553 [D loss: 0.490202, acc.: 72.66%] [G loss: 1.126697]\n",
      "epoch:23 step:21554 [D loss: 0.562176, acc.: 71.09%] [G loss: 0.957719]\n",
      "epoch:23 step:21555 [D loss: 0.548296, acc.: 68.75%] [G loss: 0.836416]\n",
      "epoch:23 step:21556 [D loss: 0.558614, acc.: 71.09%] [G loss: 0.710126]\n",
      "epoch:23 step:21557 [D loss: 0.617050, acc.: 64.06%] [G loss: 0.657520]\n",
      "epoch:23 step:21558 [D loss: 0.505333, acc.: 76.56%] [G loss: 0.701018]\n",
      "epoch:23 step:21559 [D loss: 0.483144, acc.: 78.91%] [G loss: 0.744786]\n",
      "epoch:23 step:21560 [D loss: 0.501902, acc.: 71.88%] [G loss: 0.731449]\n",
      "epoch:23 step:21561 [D loss: 0.526110, acc.: 72.66%] [G loss: 0.687761]\n",
      "epoch:23 step:21562 [D loss: 0.474139, acc.: 78.91%] [G loss: 0.836053]\n",
      "epoch:23 step:21563 [D loss: 0.564554, acc.: 68.75%] [G loss: 0.607931]\n",
      "epoch:23 step:21564 [D loss: 0.541356, acc.: 71.09%] [G loss: 0.576344]\n",
      "epoch:23 step:21565 [D loss: 0.520485, acc.: 75.78%] [G loss: 0.598175]\n",
      "epoch:23 step:21566 [D loss: 0.490886, acc.: 78.91%] [G loss: 0.776807]\n",
      "epoch:23 step:21567 [D loss: 0.512697, acc.: 75.00%] [G loss: 1.034380]\n",
      "epoch:23 step:21568 [D loss: 0.576621, acc.: 67.19%] [G loss: 0.820823]\n",
      "epoch:23 step:21569 [D loss: 0.561898, acc.: 67.19%] [G loss: 0.768667]\n",
      "epoch:23 step:21570 [D loss: 0.512734, acc.: 72.66%] [G loss: 0.856237]\n",
      "epoch:23 step:21571 [D loss: 0.641558, acc.: 56.25%] [G loss: 0.672706]\n",
      "epoch:23 step:21572 [D loss: 0.567111, acc.: 69.53%] [G loss: 0.704321]\n",
      "epoch:23 step:21573 [D loss: 0.424377, acc.: 84.38%] [G loss: 0.766266]\n",
      "epoch:23 step:21574 [D loss: 0.541748, acc.: 69.53%] [G loss: 0.778912]\n",
      "epoch:23 step:21575 [D loss: 0.516996, acc.: 69.53%] [G loss: 0.750671]\n",
      "epoch:23 step:21576 [D loss: 0.497691, acc.: 73.44%] [G loss: 0.827605]\n",
      "epoch:23 step:21577 [D loss: 0.567478, acc.: 68.75%] [G loss: 0.548278]\n",
      "epoch:23 step:21578 [D loss: 0.455088, acc.: 75.78%] [G loss: 0.698540]\n",
      "epoch:23 step:21579 [D loss: 0.580090, acc.: 64.84%] [G loss: 0.712819]\n",
      "epoch:23 step:21580 [D loss: 0.476659, acc.: 75.00%] [G loss: 0.735958]\n",
      "epoch:23 step:21581 [D loss: 0.510819, acc.: 74.22%] [G loss: 0.647834]\n",
      "epoch:23 step:21582 [D loss: 0.647330, acc.: 64.84%] [G loss: 0.616022]\n",
      "epoch:23 step:21583 [D loss: 0.537577, acc.: 67.97%] [G loss: 0.784942]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21584 [D loss: 0.516856, acc.: 76.56%] [G loss: 0.675413]\n",
      "epoch:23 step:21585 [D loss: 0.530299, acc.: 67.19%] [G loss: 0.682679]\n",
      "epoch:23 step:21586 [D loss: 0.543735, acc.: 68.75%] [G loss: 0.663534]\n",
      "epoch:23 step:21587 [D loss: 0.534465, acc.: 71.88%] [G loss: 0.829465]\n",
      "epoch:23 step:21588 [D loss: 0.494779, acc.: 71.88%] [G loss: 0.685502]\n",
      "epoch:23 step:21589 [D loss: 0.561890, acc.: 72.66%] [G loss: 0.563619]\n",
      "epoch:23 step:21590 [D loss: 0.542707, acc.: 72.66%] [G loss: 0.658870]\n",
      "epoch:23 step:21591 [D loss: 0.474127, acc.: 79.69%] [G loss: 0.642133]\n",
      "epoch:23 step:21592 [D loss: 0.513966, acc.: 75.78%] [G loss: 0.707756]\n",
      "epoch:23 step:21593 [D loss: 0.545008, acc.: 69.53%] [G loss: 0.717663]\n",
      "epoch:23 step:21594 [D loss: 0.534253, acc.: 70.31%] [G loss: 0.663318]\n",
      "epoch:23 step:21595 [D loss: 0.626664, acc.: 60.94%] [G loss: 0.587552]\n",
      "epoch:23 step:21596 [D loss: 0.577941, acc.: 67.97%] [G loss: 0.941782]\n",
      "epoch:23 step:21597 [D loss: 0.469600, acc.: 77.34%] [G loss: 0.799096]\n",
      "epoch:23 step:21598 [D loss: 0.576382, acc.: 64.84%] [G loss: 0.844884]\n",
      "epoch:23 step:21599 [D loss: 0.530385, acc.: 71.88%] [G loss: 0.776505]\n",
      "epoch:23 step:21600 [D loss: 0.459573, acc.: 77.34%] [G loss: 0.819074]\n",
      "##############\n",
      "[2.76496039 1.40306481 6.32774302 4.84005151 3.61043922 5.62641868\n",
      " 4.2606355  4.85001255 4.87053414 4.25468138]\n",
      "##########\n",
      "epoch:23 step:21601 [D loss: 0.520372, acc.: 71.09%] [G loss: 0.710717]\n",
      "epoch:23 step:21602 [D loss: 0.602106, acc.: 62.50%] [G loss: 0.569090]\n",
      "epoch:23 step:21603 [D loss: 0.564081, acc.: 69.53%] [G loss: 0.828709]\n",
      "epoch:23 step:21604 [D loss: 0.489561, acc.: 77.34%] [G loss: 0.693931]\n",
      "epoch:23 step:21605 [D loss: 0.506610, acc.: 71.09%] [G loss: 0.920282]\n",
      "epoch:23 step:21606 [D loss: 0.548637, acc.: 75.00%] [G loss: 0.840270]\n",
      "epoch:23 step:21607 [D loss: 0.523275, acc.: 75.78%] [G loss: 0.703620]\n",
      "epoch:23 step:21608 [D loss: 0.573357, acc.: 69.53%] [G loss: 0.618587]\n",
      "epoch:23 step:21609 [D loss: 0.573200, acc.: 71.88%] [G loss: 0.603468]\n",
      "epoch:23 step:21610 [D loss: 0.488266, acc.: 74.22%] [G loss: 0.734620]\n",
      "epoch:23 step:21611 [D loss: 0.545443, acc.: 66.41%] [G loss: 0.680130]\n",
      "epoch:23 step:21612 [D loss: 0.580960, acc.: 66.41%] [G loss: 0.594447]\n",
      "epoch:23 step:21613 [D loss: 0.581460, acc.: 65.62%] [G loss: 0.627316]\n",
      "epoch:23 step:21614 [D loss: 0.504170, acc.: 71.88%] [G loss: 0.809080]\n",
      "epoch:23 step:21615 [D loss: 0.564582, acc.: 69.53%] [G loss: 0.705004]\n",
      "epoch:23 step:21616 [D loss: 0.504057, acc.: 75.78%] [G loss: 0.716300]\n",
      "epoch:23 step:21617 [D loss: 0.559938, acc.: 71.88%] [G loss: 0.538178]\n",
      "epoch:23 step:21618 [D loss: 0.536651, acc.: 71.09%] [G loss: 0.724527]\n",
      "epoch:23 step:21619 [D loss: 0.540006, acc.: 73.44%] [G loss: 0.692026]\n",
      "epoch:23 step:21620 [D loss: 0.470834, acc.: 76.56%] [G loss: 0.717983]\n",
      "epoch:23 step:21621 [D loss: 0.531151, acc.: 75.78%] [G loss: 0.721302]\n",
      "epoch:23 step:21622 [D loss: 0.561497, acc.: 68.75%] [G loss: 0.590398]\n",
      "epoch:23 step:21623 [D loss: 0.556147, acc.: 71.88%] [G loss: 0.548508]\n",
      "epoch:23 step:21624 [D loss: 0.559998, acc.: 70.31%] [G loss: 0.716286]\n",
      "epoch:23 step:21625 [D loss: 0.481086, acc.: 76.56%] [G loss: 0.671607]\n",
      "epoch:23 step:21626 [D loss: 0.557444, acc.: 69.53%] [G loss: 0.748217]\n",
      "epoch:23 step:21627 [D loss: 0.511846, acc.: 71.09%] [G loss: 0.719355]\n",
      "epoch:23 step:21628 [D loss: 0.435515, acc.: 77.34%] [G loss: 0.849742]\n",
      "epoch:23 step:21629 [D loss: 0.555437, acc.: 70.31%] [G loss: 0.667118]\n",
      "epoch:23 step:21630 [D loss: 0.521655, acc.: 75.00%] [G loss: 0.633607]\n",
      "epoch:23 step:21631 [D loss: 0.464907, acc.: 77.34%] [G loss: 0.666137]\n",
      "epoch:23 step:21632 [D loss: 0.515711, acc.: 72.66%] [G loss: 0.735093]\n",
      "epoch:23 step:21633 [D loss: 0.539477, acc.: 71.09%] [G loss: 0.557510]\n",
      "epoch:23 step:21634 [D loss: 0.424167, acc.: 81.25%] [G loss: 0.837830]\n",
      "epoch:23 step:21635 [D loss: 0.528178, acc.: 69.53%] [G loss: 0.744211]\n",
      "epoch:23 step:21636 [D loss: 0.636040, acc.: 59.38%] [G loss: 0.600379]\n",
      "epoch:23 step:21637 [D loss: 0.508787, acc.: 76.56%] [G loss: 0.693378]\n",
      "epoch:23 step:21638 [D loss: 0.500343, acc.: 75.78%] [G loss: 0.719751]\n",
      "epoch:23 step:21639 [D loss: 0.491121, acc.: 74.22%] [G loss: 0.703824]\n",
      "epoch:23 step:21640 [D loss: 0.480549, acc.: 73.44%] [G loss: 0.787598]\n",
      "epoch:23 step:21641 [D loss: 0.454983, acc.: 77.34%] [G loss: 0.777020]\n",
      "epoch:23 step:21642 [D loss: 0.568269, acc.: 71.88%] [G loss: 0.874071]\n",
      "epoch:23 step:21643 [D loss: 0.481302, acc.: 72.66%] [G loss: 0.923277]\n",
      "epoch:23 step:21644 [D loss: 0.526896, acc.: 69.53%] [G loss: 0.745971]\n",
      "epoch:23 step:21645 [D loss: 0.527126, acc.: 68.75%] [G loss: 0.741383]\n",
      "epoch:23 step:21646 [D loss: 0.574856, acc.: 65.62%] [G loss: 0.977439]\n",
      "epoch:23 step:21647 [D loss: 0.555094, acc.: 71.88%] [G loss: 0.721146]\n",
      "epoch:23 step:21648 [D loss: 0.494175, acc.: 76.56%] [G loss: 0.796025]\n",
      "epoch:23 step:21649 [D loss: 0.571308, acc.: 66.41%] [G loss: 0.873773]\n",
      "epoch:23 step:21650 [D loss: 0.575195, acc.: 75.78%] [G loss: 0.725945]\n",
      "epoch:23 step:21651 [D loss: 0.465543, acc.: 78.12%] [G loss: 0.903176]\n",
      "epoch:23 step:21652 [D loss: 0.469157, acc.: 78.91%] [G loss: 0.967136]\n",
      "epoch:23 step:21653 [D loss: 0.588262, acc.: 65.62%] [G loss: 0.689855]\n",
      "epoch:23 step:21654 [D loss: 0.497312, acc.: 77.34%] [G loss: 0.706409]\n",
      "epoch:23 step:21655 [D loss: 0.493596, acc.: 73.44%] [G loss: 0.749946]\n",
      "epoch:23 step:21656 [D loss: 0.556983, acc.: 73.44%] [G loss: 0.786693]\n",
      "epoch:23 step:21657 [D loss: 0.492345, acc.: 72.66%] [G loss: 0.631896]\n",
      "epoch:23 step:21658 [D loss: 0.491579, acc.: 78.12%] [G loss: 0.758511]\n",
      "epoch:23 step:21659 [D loss: 0.590007, acc.: 67.19%] [G loss: 0.622274]\n",
      "epoch:23 step:21660 [D loss: 0.530284, acc.: 76.56%] [G loss: 0.729551]\n",
      "epoch:23 step:21661 [D loss: 0.590933, acc.: 71.09%] [G loss: 0.688404]\n",
      "epoch:23 step:21662 [D loss: 0.494588, acc.: 74.22%] [G loss: 0.605153]\n",
      "epoch:23 step:21663 [D loss: 0.516717, acc.: 74.22%] [G loss: 0.648029]\n",
      "epoch:23 step:21664 [D loss: 0.485314, acc.: 74.22%] [G loss: 0.721107]\n",
      "epoch:23 step:21665 [D loss: 0.530132, acc.: 70.31%] [G loss: 0.672266]\n",
      "epoch:23 step:21666 [D loss: 0.600382, acc.: 68.75%] [G loss: 0.611607]\n",
      "epoch:23 step:21667 [D loss: 0.527171, acc.: 67.19%] [G loss: 0.725154]\n",
      "epoch:23 step:21668 [D loss: 0.535511, acc.: 72.66%] [G loss: 0.879783]\n",
      "epoch:23 step:21669 [D loss: 0.553697, acc.: 67.19%] [G loss: 0.765340]\n",
      "epoch:23 step:21670 [D loss: 0.472938, acc.: 80.47%] [G loss: 0.815688]\n",
      "epoch:23 step:21671 [D loss: 0.560528, acc.: 69.53%] [G loss: 0.682290]\n",
      "epoch:23 step:21672 [D loss: 0.528462, acc.: 73.44%] [G loss: 0.763622]\n",
      "epoch:23 step:21673 [D loss: 0.472995, acc.: 78.91%] [G loss: 0.872595]\n",
      "epoch:23 step:21674 [D loss: 0.461506, acc.: 74.22%] [G loss: 0.795819]\n",
      "epoch:23 step:21675 [D loss: 0.628343, acc.: 64.06%] [G loss: 0.636565]\n",
      "epoch:23 step:21676 [D loss: 0.568226, acc.: 70.31%] [G loss: 0.735110]\n",
      "epoch:23 step:21677 [D loss: 0.505743, acc.: 73.44%] [G loss: 0.743647]\n",
      "epoch:23 step:21678 [D loss: 0.457534, acc.: 75.00%] [G loss: 0.730914]\n",
      "epoch:23 step:21679 [D loss: 0.519819, acc.: 70.31%] [G loss: 0.849552]\n",
      "epoch:23 step:21680 [D loss: 0.566271, acc.: 67.97%] [G loss: 0.779210]\n",
      "epoch:23 step:21681 [D loss: 0.459760, acc.: 78.12%] [G loss: 0.836577]\n",
      "epoch:23 step:21682 [D loss: 0.478169, acc.: 75.78%] [G loss: 0.626880]\n",
      "epoch:23 step:21683 [D loss: 0.488640, acc.: 75.78%] [G loss: 0.689441]\n",
      "epoch:23 step:21684 [D loss: 0.541571, acc.: 73.44%] [G loss: 0.695917]\n",
      "epoch:23 step:21685 [D loss: 0.488158, acc.: 70.31%] [G loss: 0.857125]\n",
      "epoch:23 step:21686 [D loss: 0.536942, acc.: 70.31%] [G loss: 0.767507]\n",
      "epoch:23 step:21687 [D loss: 0.491589, acc.: 75.00%] [G loss: 0.875948]\n",
      "epoch:23 step:21688 [D loss: 0.670772, acc.: 58.59%] [G loss: 0.590204]\n",
      "epoch:23 step:21689 [D loss: 0.558224, acc.: 70.31%] [G loss: 0.800561]\n",
      "epoch:23 step:21690 [D loss: 0.534574, acc.: 71.09%] [G loss: 0.694016]\n",
      "epoch:23 step:21691 [D loss: 0.588518, acc.: 67.19%] [G loss: 0.733764]\n",
      "epoch:23 step:21692 [D loss: 0.521733, acc.: 73.44%] [G loss: 0.713183]\n",
      "epoch:23 step:21693 [D loss: 0.606339, acc.: 63.28%] [G loss: 0.650249]\n",
      "epoch:23 step:21694 [D loss: 0.606703, acc.: 63.28%] [G loss: 0.666215]\n",
      "epoch:23 step:21695 [D loss: 0.482311, acc.: 75.00%] [G loss: 0.760077]\n",
      "epoch:23 step:21696 [D loss: 0.534646, acc.: 70.31%] [G loss: 0.636349]\n",
      "epoch:23 step:21697 [D loss: 0.468826, acc.: 75.78%] [G loss: 0.943993]\n",
      "epoch:23 step:21698 [D loss: 0.625266, acc.: 64.84%] [G loss: 0.744228]\n",
      "epoch:23 step:21699 [D loss: 0.572342, acc.: 68.75%] [G loss: 0.673370]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21700 [D loss: 0.544163, acc.: 74.22%] [G loss: 0.734771]\n",
      "epoch:23 step:21701 [D loss: 0.628776, acc.: 61.72%] [G loss: 0.655399]\n",
      "epoch:23 step:21702 [D loss: 0.560931, acc.: 70.31%] [G loss: 0.625437]\n",
      "epoch:23 step:21703 [D loss: 0.475033, acc.: 75.78%] [G loss: 0.739645]\n",
      "epoch:23 step:21704 [D loss: 0.578227, acc.: 63.28%] [G loss: 0.661416]\n",
      "epoch:23 step:21705 [D loss: 0.508037, acc.: 72.66%] [G loss: 0.689740]\n",
      "epoch:23 step:21706 [D loss: 0.440667, acc.: 79.69%] [G loss: 0.874773]\n",
      "epoch:23 step:21707 [D loss: 0.506093, acc.: 76.56%] [G loss: 0.977651]\n",
      "epoch:23 step:21708 [D loss: 0.515143, acc.: 72.66%] [G loss: 0.757550]\n",
      "epoch:23 step:21709 [D loss: 0.559599, acc.: 67.19%] [G loss: 0.797682]\n",
      "epoch:23 step:21710 [D loss: 0.456982, acc.: 78.91%] [G loss: 0.791543]\n",
      "epoch:23 step:21711 [D loss: 0.545824, acc.: 74.22%] [G loss: 0.708184]\n",
      "epoch:23 step:21712 [D loss: 0.510018, acc.: 75.78%] [G loss: 0.833687]\n",
      "epoch:23 step:21713 [D loss: 0.489224, acc.: 77.34%] [G loss: 0.801856]\n",
      "epoch:23 step:21714 [D loss: 0.519302, acc.: 70.31%] [G loss: 0.765445]\n",
      "epoch:23 step:21715 [D loss: 0.577704, acc.: 66.41%] [G loss: 0.542765]\n",
      "epoch:23 step:21716 [D loss: 0.523964, acc.: 71.09%] [G loss: 0.603685]\n",
      "epoch:23 step:21717 [D loss: 0.536075, acc.: 74.22%] [G loss: 0.602940]\n",
      "epoch:23 step:21718 [D loss: 0.558401, acc.: 66.41%] [G loss: 0.704208]\n",
      "epoch:23 step:21719 [D loss: 0.525238, acc.: 74.22%] [G loss: 0.679393]\n",
      "epoch:23 step:21720 [D loss: 0.555956, acc.: 68.75%] [G loss: 0.587018]\n",
      "epoch:23 step:21721 [D loss: 0.529515, acc.: 72.66%] [G loss: 0.630129]\n",
      "epoch:23 step:21722 [D loss: 0.545007, acc.: 69.53%] [G loss: 0.707069]\n",
      "epoch:23 step:21723 [D loss: 0.495513, acc.: 75.00%] [G loss: 0.647246]\n",
      "epoch:23 step:21724 [D loss: 0.488818, acc.: 75.00%] [G loss: 0.797795]\n",
      "epoch:23 step:21725 [D loss: 0.584025, acc.: 64.84%] [G loss: 0.712433]\n",
      "epoch:23 step:21726 [D loss: 0.575868, acc.: 66.41%] [G loss: 0.614674]\n",
      "epoch:23 step:21727 [D loss: 0.479572, acc.: 75.78%] [G loss: 0.640835]\n",
      "epoch:23 step:21728 [D loss: 0.471141, acc.: 78.12%] [G loss: 0.782880]\n",
      "epoch:23 step:21729 [D loss: 0.605773, acc.: 65.62%] [G loss: 0.555781]\n",
      "epoch:23 step:21730 [D loss: 0.490466, acc.: 74.22%] [G loss: 0.627052]\n",
      "epoch:23 step:21731 [D loss: 0.587233, acc.: 64.06%] [G loss: 0.567928]\n",
      "epoch:23 step:21732 [D loss: 0.597307, acc.: 71.09%] [G loss: 0.480908]\n",
      "epoch:23 step:21733 [D loss: 0.482017, acc.: 76.56%] [G loss: 0.750315]\n",
      "epoch:23 step:21734 [D loss: 0.593391, acc.: 66.41%] [G loss: 0.754305]\n",
      "epoch:23 step:21735 [D loss: 0.549679, acc.: 72.66%] [G loss: 0.668268]\n",
      "epoch:23 step:21736 [D loss: 0.577913, acc.: 67.97%] [G loss: 0.700798]\n",
      "epoch:23 step:21737 [D loss: 0.567492, acc.: 68.75%] [G loss: 0.622414]\n",
      "epoch:23 step:21738 [D loss: 0.582796, acc.: 69.53%] [G loss: 0.549666]\n",
      "epoch:23 step:21739 [D loss: 0.538324, acc.: 68.75%] [G loss: 0.595115]\n",
      "epoch:23 step:21740 [D loss: 0.543009, acc.: 68.75%] [G loss: 0.667367]\n",
      "epoch:23 step:21741 [D loss: 0.470666, acc.: 79.69%] [G loss: 0.560709]\n",
      "epoch:23 step:21742 [D loss: 0.509265, acc.: 71.88%] [G loss: 0.648653]\n",
      "epoch:23 step:21743 [D loss: 0.512001, acc.: 72.66%] [G loss: 0.701158]\n",
      "epoch:23 step:21744 [D loss: 0.602962, acc.: 68.75%] [G loss: 0.640505]\n",
      "epoch:23 step:21745 [D loss: 0.393889, acc.: 84.38%] [G loss: 0.776666]\n",
      "epoch:23 step:21746 [D loss: 0.587110, acc.: 67.97%] [G loss: 0.611295]\n",
      "epoch:23 step:21747 [D loss: 0.520566, acc.: 73.44%] [G loss: 0.643862]\n",
      "epoch:23 step:21748 [D loss: 0.520379, acc.: 78.12%] [G loss: 0.657508]\n",
      "epoch:23 step:21749 [D loss: 0.438267, acc.: 80.47%] [G loss: 0.732748]\n",
      "epoch:23 step:21750 [D loss: 0.490430, acc.: 74.22%] [G loss: 0.613085]\n",
      "epoch:23 step:21751 [D loss: 0.622753, acc.: 67.97%] [G loss: 0.579246]\n",
      "epoch:23 step:21752 [D loss: 0.580475, acc.: 69.53%] [G loss: 0.647406]\n",
      "epoch:23 step:21753 [D loss: 0.540829, acc.: 71.88%] [G loss: 0.741162]\n",
      "epoch:23 step:21754 [D loss: 0.616616, acc.: 68.75%] [G loss: 0.534797]\n",
      "epoch:23 step:21755 [D loss: 0.524382, acc.: 69.53%] [G loss: 0.707479]\n",
      "epoch:23 step:21756 [D loss: 0.507373, acc.: 74.22%] [G loss: 0.715307]\n",
      "epoch:23 step:21757 [D loss: 0.525300, acc.: 71.09%] [G loss: 0.986727]\n",
      "epoch:23 step:21758 [D loss: 0.517797, acc.: 71.88%] [G loss: 0.698784]\n",
      "epoch:23 step:21759 [D loss: 0.439446, acc.: 76.56%] [G loss: 0.952251]\n",
      "epoch:23 step:21760 [D loss: 0.511853, acc.: 73.44%] [G loss: 1.023327]\n",
      "epoch:23 step:21761 [D loss: 0.620249, acc.: 67.19%] [G loss: 0.728932]\n",
      "epoch:23 step:21762 [D loss: 0.568424, acc.: 66.41%] [G loss: 0.524082]\n",
      "epoch:23 step:21763 [D loss: 0.559287, acc.: 71.09%] [G loss: 0.521167]\n",
      "epoch:23 step:21764 [D loss: 0.514647, acc.: 72.66%] [G loss: 0.528176]\n",
      "epoch:23 step:21765 [D loss: 0.604208, acc.: 64.84%] [G loss: 0.701641]\n",
      "epoch:23 step:21766 [D loss: 0.548986, acc.: 70.31%] [G loss: 0.639956]\n",
      "epoch:23 step:21767 [D loss: 0.529073, acc.: 65.62%] [G loss: 0.676355]\n",
      "epoch:23 step:21768 [D loss: 0.493145, acc.: 73.44%] [G loss: 0.630538]\n",
      "epoch:23 step:21769 [D loss: 0.512880, acc.: 75.78%] [G loss: 0.729856]\n",
      "epoch:23 step:21770 [D loss: 0.481220, acc.: 78.91%] [G loss: 0.811767]\n",
      "epoch:23 step:21771 [D loss: 0.621552, acc.: 66.41%] [G loss: 0.684620]\n",
      "epoch:23 step:21772 [D loss: 0.538073, acc.: 71.09%] [G loss: 0.754398]\n",
      "epoch:23 step:21773 [D loss: 0.489206, acc.: 75.78%] [G loss: 0.708064]\n",
      "epoch:23 step:21774 [D loss: 0.489724, acc.: 77.34%] [G loss: 0.818697]\n",
      "epoch:23 step:21775 [D loss: 0.561054, acc.: 69.53%] [G loss: 0.717525]\n",
      "epoch:23 step:21776 [D loss: 0.608857, acc.: 68.75%] [G loss: 0.665155]\n",
      "epoch:23 step:21777 [D loss: 0.575890, acc.: 65.62%] [G loss: 0.699953]\n",
      "epoch:23 step:21778 [D loss: 0.538390, acc.: 66.41%] [G loss: 0.650765]\n",
      "epoch:23 step:21779 [D loss: 0.535427, acc.: 69.53%] [G loss: 0.561411]\n",
      "epoch:23 step:21780 [D loss: 0.562141, acc.: 71.09%] [G loss: 0.639824]\n",
      "epoch:23 step:21781 [D loss: 0.487230, acc.: 76.56%] [G loss: 0.777970]\n",
      "epoch:23 step:21782 [D loss: 0.477813, acc.: 75.78%] [G loss: 0.836889]\n",
      "epoch:23 step:21783 [D loss: 0.459716, acc.: 78.91%] [G loss: 0.782372]\n",
      "epoch:23 step:21784 [D loss: 0.541456, acc.: 71.88%] [G loss: 0.722719]\n",
      "epoch:23 step:21785 [D loss: 0.557265, acc.: 68.75%] [G loss: 0.805400]\n",
      "epoch:23 step:21786 [D loss: 0.579423, acc.: 70.31%] [G loss: 0.721989]\n",
      "epoch:23 step:21787 [D loss: 0.548084, acc.: 68.75%] [G loss: 0.597707]\n",
      "epoch:23 step:21788 [D loss: 0.509978, acc.: 72.66%] [G loss: 0.658724]\n",
      "epoch:23 step:21789 [D loss: 0.558315, acc.: 71.88%] [G loss: 0.574876]\n",
      "epoch:23 step:21790 [D loss: 0.566565, acc.: 70.31%] [G loss: 0.613501]\n",
      "epoch:23 step:21791 [D loss: 0.510073, acc.: 72.66%] [G loss: 0.788641]\n",
      "epoch:23 step:21792 [D loss: 0.539134, acc.: 70.31%] [G loss: 0.685751]\n",
      "epoch:23 step:21793 [D loss: 0.540256, acc.: 71.88%] [G loss: 0.827793]\n",
      "epoch:23 step:21794 [D loss: 0.513836, acc.: 71.88%] [G loss: 0.803685]\n",
      "epoch:23 step:21795 [D loss: 0.483880, acc.: 71.09%] [G loss: 0.787749]\n",
      "epoch:23 step:21796 [D loss: 0.553628, acc.: 71.09%] [G loss: 0.757461]\n",
      "epoch:23 step:21797 [D loss: 0.529046, acc.: 70.31%] [G loss: 0.596398]\n",
      "epoch:23 step:21798 [D loss: 0.473265, acc.: 75.78%] [G loss: 0.797285]\n",
      "epoch:23 step:21799 [D loss: 0.497249, acc.: 75.78%] [G loss: 0.860978]\n",
      "epoch:23 step:21800 [D loss: 0.558414, acc.: 71.09%] [G loss: 0.898431]\n",
      "##############\n",
      "[3.0916692  0.35188739 6.04211965 5.09183522 3.49300463 5.72512401\n",
      " 4.75573226 4.51440916 4.63394498 4.02108505]\n",
      "##########\n",
      "epoch:23 step:21801 [D loss: 0.548649, acc.: 70.31%] [G loss: 0.844452]\n",
      "epoch:23 step:21802 [D loss: 0.599417, acc.: 70.31%] [G loss: 0.829459]\n",
      "epoch:23 step:21803 [D loss: 0.552425, acc.: 73.44%] [G loss: 0.659558]\n",
      "epoch:23 step:21804 [D loss: 0.596948, acc.: 67.19%] [G loss: 0.610593]\n",
      "epoch:23 step:21805 [D loss: 0.542395, acc.: 69.53%] [G loss: 0.586126]\n",
      "epoch:23 step:21806 [D loss: 0.536618, acc.: 70.31%] [G loss: 0.721593]\n",
      "epoch:23 step:21807 [D loss: 0.487648, acc.: 74.22%] [G loss: 0.640797]\n",
      "epoch:23 step:21808 [D loss: 0.569830, acc.: 66.41%] [G loss: 0.648088]\n",
      "epoch:23 step:21809 [D loss: 0.560465, acc.: 67.19%] [G loss: 0.605414]\n",
      "epoch:23 step:21810 [D loss: 0.543226, acc.: 69.53%] [G loss: 0.541979]\n",
      "epoch:23 step:21811 [D loss: 0.635018, acc.: 58.59%] [G loss: 0.525398]\n",
      "epoch:23 step:21812 [D loss: 0.495083, acc.: 73.44%] [G loss: 0.591563]\n",
      "epoch:23 step:21813 [D loss: 0.518372, acc.: 72.66%] [G loss: 0.821284]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21814 [D loss: 0.590580, acc.: 67.97%] [G loss: 0.582455]\n",
      "epoch:23 step:21815 [D loss: 0.510560, acc.: 74.22%] [G loss: 0.582274]\n",
      "epoch:23 step:21816 [D loss: 0.504506, acc.: 74.22%] [G loss: 0.629718]\n",
      "epoch:23 step:21817 [D loss: 0.569463, acc.: 67.97%] [G loss: 0.718647]\n",
      "epoch:23 step:21818 [D loss: 0.588635, acc.: 67.19%] [G loss: 0.629523]\n",
      "epoch:23 step:21819 [D loss: 0.529641, acc.: 70.31%] [G loss: 0.719802]\n",
      "epoch:23 step:21820 [D loss: 0.499651, acc.: 74.22%] [G loss: 0.657953]\n",
      "epoch:23 step:21821 [D loss: 0.503056, acc.: 73.44%] [G loss: 0.852820]\n",
      "epoch:23 step:21822 [D loss: 0.515286, acc.: 71.88%] [G loss: 0.697917]\n",
      "epoch:23 step:21823 [D loss: 0.556530, acc.: 66.41%] [G loss: 0.650384]\n",
      "epoch:23 step:21824 [D loss: 0.485406, acc.: 78.12%] [G loss: 0.716580]\n",
      "epoch:23 step:21825 [D loss: 0.500521, acc.: 75.78%] [G loss: 0.673371]\n",
      "epoch:23 step:21826 [D loss: 0.558980, acc.: 71.09%] [G loss: 0.527681]\n",
      "epoch:23 step:21827 [D loss: 0.466626, acc.: 79.69%] [G loss: 0.773693]\n",
      "epoch:23 step:21828 [D loss: 0.614212, acc.: 63.28%] [G loss: 0.688527]\n",
      "epoch:23 step:21829 [D loss: 0.633951, acc.: 64.06%] [G loss: 0.500700]\n",
      "epoch:23 step:21830 [D loss: 0.553054, acc.: 65.62%] [G loss: 0.672476]\n",
      "epoch:23 step:21831 [D loss: 0.589608, acc.: 66.41%] [G loss: 0.752693]\n",
      "epoch:23 step:21832 [D loss: 0.547287, acc.: 68.75%] [G loss: 0.733365]\n",
      "epoch:23 step:21833 [D loss: 0.534442, acc.: 71.88%] [G loss: 0.785423]\n",
      "epoch:23 step:21834 [D loss: 0.500392, acc.: 71.09%] [G loss: 0.764362]\n",
      "epoch:23 step:21835 [D loss: 0.542959, acc.: 72.66%] [G loss: 0.655343]\n",
      "epoch:23 step:21836 [D loss: 0.445414, acc.: 78.12%] [G loss: 0.906605]\n",
      "epoch:23 step:21837 [D loss: 0.495135, acc.: 76.56%] [G loss: 0.859715]\n",
      "epoch:23 step:21838 [D loss: 0.579084, acc.: 63.28%] [G loss: 0.822909]\n",
      "epoch:23 step:21839 [D loss: 0.566056, acc.: 67.19%] [G loss: 0.654970]\n",
      "epoch:23 step:21840 [D loss: 0.543415, acc.: 71.88%] [G loss: 0.799025]\n",
      "epoch:23 step:21841 [D loss: 0.559953, acc.: 68.75%] [G loss: 0.694919]\n",
      "epoch:23 step:21842 [D loss: 0.551413, acc.: 68.75%] [G loss: 0.704563]\n",
      "epoch:23 step:21843 [D loss: 0.496879, acc.: 71.88%] [G loss: 0.735832]\n",
      "epoch:23 step:21844 [D loss: 0.515397, acc.: 71.09%] [G loss: 0.824607]\n",
      "epoch:23 step:21845 [D loss: 0.613454, acc.: 64.84%] [G loss: 0.530195]\n",
      "epoch:23 step:21846 [D loss: 0.568044, acc.: 67.97%] [G loss: 0.554487]\n",
      "epoch:23 step:21847 [D loss: 0.451799, acc.: 76.56%] [G loss: 0.575370]\n",
      "epoch:23 step:21848 [D loss: 0.550286, acc.: 71.88%] [G loss: 0.549294]\n",
      "epoch:23 step:21849 [D loss: 0.525677, acc.: 73.44%] [G loss: 0.584274]\n",
      "epoch:23 step:21850 [D loss: 0.468403, acc.: 72.66%] [G loss: 0.976786]\n",
      "epoch:23 step:21851 [D loss: 0.517529, acc.: 75.78%] [G loss: 0.740366]\n",
      "epoch:23 step:21852 [D loss: 0.583835, acc.: 71.09%] [G loss: 0.680382]\n",
      "epoch:23 step:21853 [D loss: 0.529444, acc.: 74.22%] [G loss: 0.597086]\n",
      "epoch:23 step:21854 [D loss: 0.501599, acc.: 75.78%] [G loss: 0.718374]\n",
      "epoch:23 step:21855 [D loss: 0.461264, acc.: 81.25%] [G loss: 0.674717]\n",
      "epoch:23 step:21856 [D loss: 0.543560, acc.: 68.75%] [G loss: 0.645718]\n",
      "epoch:23 step:21857 [D loss: 0.551117, acc.: 67.19%] [G loss: 0.662202]\n",
      "epoch:23 step:21858 [D loss: 0.466877, acc.: 81.25%] [G loss: 0.772475]\n",
      "epoch:23 step:21859 [D loss: 0.604200, acc.: 59.38%] [G loss: 0.692051]\n",
      "epoch:23 step:21860 [D loss: 0.469293, acc.: 76.56%] [G loss: 0.836343]\n",
      "epoch:23 step:21861 [D loss: 0.550925, acc.: 69.53%] [G loss: 0.799956]\n",
      "epoch:23 step:21862 [D loss: 0.450454, acc.: 76.56%] [G loss: 0.883260]\n",
      "epoch:23 step:21863 [D loss: 0.486796, acc.: 79.69%] [G loss: 0.867691]\n",
      "epoch:23 step:21864 [D loss: 0.450500, acc.: 81.25%] [G loss: 0.964386]\n",
      "epoch:23 step:21865 [D loss: 0.413947, acc.: 79.69%] [G loss: 1.215625]\n",
      "epoch:23 step:21866 [D loss: 0.439130, acc.: 82.81%] [G loss: 0.919458]\n",
      "epoch:23 step:21867 [D loss: 0.700191, acc.: 64.06%] [G loss: 0.854046]\n",
      "epoch:23 step:21868 [D loss: 0.695844, acc.: 64.06%] [G loss: 0.618108]\n",
      "epoch:23 step:21869 [D loss: 0.514207, acc.: 67.97%] [G loss: 0.741220]\n",
      "epoch:23 step:21870 [D loss: 0.578304, acc.: 70.31%] [G loss: 0.726548]\n",
      "epoch:23 step:21871 [D loss: 0.541865, acc.: 70.31%] [G loss: 0.688099]\n",
      "epoch:23 step:21872 [D loss: 0.467454, acc.: 73.44%] [G loss: 0.821894]\n",
      "epoch:23 step:21873 [D loss: 0.503092, acc.: 73.44%] [G loss: 0.720478]\n",
      "epoch:23 step:21874 [D loss: 0.584819, acc.: 70.31%] [G loss: 0.626262]\n",
      "epoch:23 step:21875 [D loss: 0.529179, acc.: 69.53%] [G loss: 0.652693]\n",
      "epoch:23 step:21876 [D loss: 0.558183, acc.: 68.75%] [G loss: 0.634283]\n",
      "epoch:23 step:21877 [D loss: 0.459409, acc.: 76.56%] [G loss: 0.714665]\n",
      "epoch:23 step:21878 [D loss: 0.515175, acc.: 69.53%] [G loss: 0.758651]\n",
      "epoch:23 step:21879 [D loss: 0.460544, acc.: 78.12%] [G loss: 0.989628]\n",
      "epoch:23 step:21880 [D loss: 0.484200, acc.: 75.78%] [G loss: 0.820994]\n",
      "epoch:23 step:21881 [D loss: 0.552569, acc.: 69.53%] [G loss: 0.710760]\n",
      "epoch:23 step:21882 [D loss: 0.573245, acc.: 64.84%] [G loss: 0.577138]\n",
      "epoch:23 step:21883 [D loss: 0.529436, acc.: 70.31%] [G loss: 0.557358]\n",
      "epoch:23 step:21884 [D loss: 0.466643, acc.: 76.56%] [G loss: 0.779290]\n",
      "epoch:23 step:21885 [D loss: 0.459419, acc.: 75.78%] [G loss: 0.769122]\n",
      "epoch:23 step:21886 [D loss: 0.482260, acc.: 75.00%] [G loss: 0.889791]\n",
      "epoch:23 step:21887 [D loss: 0.493551, acc.: 75.78%] [G loss: 0.819889]\n",
      "epoch:23 step:21888 [D loss: 0.484573, acc.: 77.34%] [G loss: 0.804358]\n",
      "epoch:23 step:21889 [D loss: 0.510812, acc.: 72.66%] [G loss: 0.767614]\n",
      "epoch:23 step:21890 [D loss: 0.575530, acc.: 66.41%] [G loss: 0.678946]\n",
      "epoch:23 step:21891 [D loss: 0.478949, acc.: 77.34%] [G loss: 0.784332]\n",
      "epoch:23 step:21892 [D loss: 0.597811, acc.: 69.53%] [G loss: 0.764891]\n",
      "epoch:23 step:21893 [D loss: 0.683945, acc.: 60.16%] [G loss: 0.544954]\n",
      "epoch:23 step:21894 [D loss: 0.492669, acc.: 75.00%] [G loss: 0.855566]\n",
      "epoch:23 step:21895 [D loss: 0.448659, acc.: 80.47%] [G loss: 0.820167]\n",
      "epoch:23 step:21896 [D loss: 0.579232, acc.: 66.41%] [G loss: 0.760591]\n",
      "epoch:23 step:21897 [D loss: 0.524558, acc.: 73.44%] [G loss: 0.815726]\n",
      "epoch:23 step:21898 [D loss: 0.453381, acc.: 80.47%] [G loss: 0.943000]\n",
      "epoch:23 step:21899 [D loss: 0.678447, acc.: 62.50%] [G loss: 0.829864]\n",
      "epoch:23 step:21900 [D loss: 0.730904, acc.: 55.47%] [G loss: 0.515362]\n",
      "epoch:23 step:21901 [D loss: 0.505270, acc.: 73.44%] [G loss: 0.723596]\n",
      "epoch:23 step:21902 [D loss: 0.539164, acc.: 72.66%] [G loss: 0.766978]\n",
      "epoch:23 step:21903 [D loss: 0.592717, acc.: 66.41%] [G loss: 0.694021]\n",
      "epoch:23 step:21904 [D loss: 0.560649, acc.: 72.66%] [G loss: 0.699262]\n",
      "epoch:23 step:21905 [D loss: 0.383279, acc.: 84.38%] [G loss: 0.760088]\n",
      "epoch:23 step:21906 [D loss: 0.514551, acc.: 74.22%] [G loss: 0.992582]\n",
      "epoch:23 step:21907 [D loss: 0.541275, acc.: 73.44%] [G loss: 0.657486]\n",
      "epoch:23 step:21908 [D loss: 0.469218, acc.: 78.91%] [G loss: 0.702187]\n",
      "epoch:23 step:21909 [D loss: 0.424939, acc.: 78.12%] [G loss: 0.783561]\n",
      "epoch:23 step:21910 [D loss: 0.486926, acc.: 75.00%] [G loss: 0.798455]\n",
      "epoch:23 step:21911 [D loss: 0.510624, acc.: 73.44%] [G loss: 0.835969]\n",
      "epoch:23 step:21912 [D loss: 0.506481, acc.: 72.66%] [G loss: 0.776208]\n",
      "epoch:23 step:21913 [D loss: 0.529190, acc.: 71.09%] [G loss: 0.804580]\n",
      "epoch:23 step:21914 [D loss: 0.536861, acc.: 69.53%] [G loss: 0.703570]\n",
      "epoch:23 step:21915 [D loss: 0.533809, acc.: 75.78%] [G loss: 0.657280]\n",
      "epoch:23 step:21916 [D loss: 0.553995, acc.: 64.84%] [G loss: 0.669176]\n",
      "epoch:23 step:21917 [D loss: 0.537185, acc.: 71.88%] [G loss: 0.675007]\n",
      "epoch:23 step:21918 [D loss: 0.547031, acc.: 68.75%] [G loss: 0.631929]\n",
      "epoch:23 step:21919 [D loss: 0.543463, acc.: 70.31%] [G loss: 0.527625]\n",
      "epoch:23 step:21920 [D loss: 0.524238, acc.: 71.88%] [G loss: 0.654518]\n",
      "epoch:23 step:21921 [D loss: 0.499811, acc.: 71.88%] [G loss: 0.621137]\n",
      "epoch:23 step:21922 [D loss: 0.489915, acc.: 74.22%] [G loss: 0.802415]\n",
      "epoch:23 step:21923 [D loss: 0.526078, acc.: 71.09%] [G loss: 0.747214]\n",
      "epoch:23 step:21924 [D loss: 0.560741, acc.: 70.31%] [G loss: 0.589501]\n",
      "epoch:23 step:21925 [D loss: 0.449665, acc.: 78.12%] [G loss: 0.737243]\n",
      "epoch:23 step:21926 [D loss: 0.519088, acc.: 71.88%] [G loss: 0.711553]\n",
      "epoch:23 step:21927 [D loss: 0.692606, acc.: 59.38%] [G loss: 0.597652]\n",
      "epoch:23 step:21928 [D loss: 0.549281, acc.: 69.53%] [G loss: 0.491806]\n",
      "epoch:23 step:21929 [D loss: 0.515936, acc.: 76.56%] [G loss: 0.692473]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21930 [D loss: 0.580627, acc.: 64.84%] [G loss: 0.656481]\n",
      "epoch:23 step:21931 [D loss: 0.569617, acc.: 66.41%] [G loss: 0.471193]\n",
      "epoch:23 step:21932 [D loss: 0.416132, acc.: 78.12%] [G loss: 0.755371]\n",
      "epoch:23 step:21933 [D loss: 0.558474, acc.: 75.00%] [G loss: 0.672811]\n",
      "epoch:23 step:21934 [D loss: 0.532424, acc.: 71.88%] [G loss: 0.638848]\n",
      "epoch:23 step:21935 [D loss: 0.516637, acc.: 70.31%] [G loss: 0.682331]\n",
      "epoch:23 step:21936 [D loss: 0.477893, acc.: 78.91%] [G loss: 0.740848]\n",
      "epoch:23 step:21937 [D loss: 0.620325, acc.: 67.97%] [G loss: 0.776512]\n",
      "epoch:23 step:21938 [D loss: 0.538958, acc.: 71.09%] [G loss: 0.575227]\n",
      "epoch:23 step:21939 [D loss: 0.528693, acc.: 74.22%] [G loss: 0.739866]\n",
      "epoch:23 step:21940 [D loss: 0.511927, acc.: 72.66%] [G loss: 0.801175]\n",
      "epoch:23 step:21941 [D loss: 0.587496, acc.: 71.88%] [G loss: 0.534509]\n",
      "epoch:23 step:21942 [D loss: 0.540017, acc.: 74.22%] [G loss: 0.685578]\n",
      "epoch:23 step:21943 [D loss: 0.528971, acc.: 67.19%] [G loss: 0.598441]\n",
      "epoch:23 step:21944 [D loss: 0.570753, acc.: 66.41%] [G loss: 0.648127]\n",
      "epoch:23 step:21945 [D loss: 0.557114, acc.: 71.88%] [G loss: 0.565431]\n",
      "epoch:23 step:21946 [D loss: 0.583126, acc.: 61.72%] [G loss: 0.571062]\n",
      "epoch:23 step:21947 [D loss: 0.572770, acc.: 65.62%] [G loss: 0.589532]\n",
      "epoch:23 step:21948 [D loss: 0.555171, acc.: 67.97%] [G loss: 0.698681]\n",
      "epoch:23 step:21949 [D loss: 0.503052, acc.: 71.88%] [G loss: 0.859025]\n",
      "epoch:23 step:21950 [D loss: 0.550944, acc.: 74.22%] [G loss: 0.781817]\n",
      "epoch:23 step:21951 [D loss: 0.610869, acc.: 64.06%] [G loss: 0.673574]\n",
      "epoch:23 step:21952 [D loss: 0.636770, acc.: 57.03%] [G loss: 0.538290]\n",
      "epoch:23 step:21953 [D loss: 0.527563, acc.: 68.75%] [G loss: 0.565147]\n",
      "epoch:23 step:21954 [D loss: 0.497532, acc.: 76.56%] [G loss: 0.659307]\n",
      "epoch:23 step:21955 [D loss: 0.570531, acc.: 69.53%] [G loss: 0.681514]\n",
      "epoch:23 step:21956 [D loss: 0.525593, acc.: 71.09%] [G loss: 0.748971]\n",
      "epoch:23 step:21957 [D loss: 0.466095, acc.: 75.00%] [G loss: 0.707373]\n",
      "epoch:23 step:21958 [D loss: 0.519855, acc.: 72.66%] [G loss: 0.843937]\n",
      "epoch:23 step:21959 [D loss: 0.521660, acc.: 72.66%] [G loss: 0.835032]\n",
      "epoch:23 step:21960 [D loss: 0.549402, acc.: 65.62%] [G loss: 0.731056]\n",
      "epoch:23 step:21961 [D loss: 0.573917, acc.: 72.66%] [G loss: 0.681991]\n",
      "epoch:23 step:21962 [D loss: 0.611903, acc.: 59.38%] [G loss: 0.655057]\n",
      "epoch:23 step:21963 [D loss: 0.587494, acc.: 67.19%] [G loss: 0.661183]\n",
      "epoch:23 step:21964 [D loss: 0.552074, acc.: 66.41%] [G loss: 0.762390]\n",
      "epoch:23 step:21965 [D loss: 0.509840, acc.: 72.66%] [G loss: 0.623289]\n",
      "epoch:23 step:21966 [D loss: 0.504410, acc.: 77.34%] [G loss: 0.750707]\n",
      "epoch:23 step:21967 [D loss: 0.485674, acc.: 75.00%] [G loss: 0.871473]\n",
      "epoch:23 step:21968 [D loss: 0.578600, acc.: 71.88%] [G loss: 0.724999]\n",
      "epoch:23 step:21969 [D loss: 0.656289, acc.: 60.94%] [G loss: 0.633195]\n",
      "epoch:23 step:21970 [D loss: 0.567833, acc.: 64.06%] [G loss: 0.697657]\n",
      "epoch:23 step:21971 [D loss: 0.610494, acc.: 67.19%] [G loss: 0.550111]\n",
      "epoch:23 step:21972 [D loss: 0.579721, acc.: 62.50%] [G loss: 0.638101]\n",
      "epoch:23 step:21973 [D loss: 0.604678, acc.: 67.19%] [G loss: 0.532828]\n",
      "epoch:23 step:21974 [D loss: 0.531077, acc.: 71.88%] [G loss: 0.587490]\n",
      "epoch:23 step:21975 [D loss: 0.541089, acc.: 70.31%] [G loss: 0.612590]\n",
      "epoch:23 step:21976 [D loss: 0.485161, acc.: 72.66%] [G loss: 0.801532]\n",
      "epoch:23 step:21977 [D loss: 0.451179, acc.: 75.00%] [G loss: 0.651719]\n",
      "epoch:23 step:21978 [D loss: 0.494213, acc.: 73.44%] [G loss: 0.715517]\n",
      "epoch:23 step:21979 [D loss: 0.488989, acc.: 72.66%] [G loss: 0.750893]\n",
      "epoch:23 step:21980 [D loss: 0.446219, acc.: 76.56%] [G loss: 0.772851]\n",
      "epoch:23 step:21981 [D loss: 0.499573, acc.: 75.78%] [G loss: 0.922453]\n",
      "epoch:23 step:21982 [D loss: 0.535824, acc.: 71.88%] [G loss: 0.657871]\n",
      "epoch:23 step:21983 [D loss: 0.572304, acc.: 64.06%] [G loss: 0.689374]\n",
      "epoch:23 step:21984 [D loss: 0.553312, acc.: 71.09%] [G loss: 0.646500]\n",
      "epoch:23 step:21985 [D loss: 0.519972, acc.: 72.66%] [G loss: 0.800540]\n",
      "epoch:23 step:21986 [D loss: 0.555964, acc.: 67.19%] [G loss: 0.617514]\n",
      "epoch:23 step:21987 [D loss: 0.470085, acc.: 78.12%] [G loss: 0.661864]\n",
      "epoch:23 step:21988 [D loss: 0.631555, acc.: 64.06%] [G loss: 0.609703]\n",
      "epoch:23 step:21989 [D loss: 0.579089, acc.: 66.41%] [G loss: 0.689289]\n",
      "epoch:23 step:21990 [D loss: 0.511490, acc.: 71.09%] [G loss: 0.806911]\n",
      "epoch:23 step:21991 [D loss: 0.499290, acc.: 75.00%] [G loss: 0.681661]\n",
      "epoch:23 step:21992 [D loss: 0.609683, acc.: 60.94%] [G loss: 0.725263]\n",
      "epoch:23 step:21993 [D loss: 0.558141, acc.: 69.53%] [G loss: 0.634370]\n",
      "epoch:23 step:21994 [D loss: 0.507727, acc.: 75.00%] [G loss: 0.734049]\n",
      "epoch:23 step:21995 [D loss: 0.534335, acc.: 66.41%] [G loss: 0.864746]\n",
      "epoch:23 step:21996 [D loss: 0.521651, acc.: 67.97%] [G loss: 0.778341]\n",
      "epoch:23 step:21997 [D loss: 0.545979, acc.: 66.41%] [G loss: 0.542930]\n",
      "epoch:23 step:21998 [D loss: 0.499104, acc.: 73.44%] [G loss: 0.694061]\n",
      "epoch:23 step:21999 [D loss: 0.517345, acc.: 74.22%] [G loss: 0.772720]\n",
      "epoch:23 step:22000 [D loss: 0.575435, acc.: 65.62%] [G loss: 0.630491]\n",
      "##############\n",
      "[2.76289455 0.6948284  5.95183711 4.86437523 3.69500115 5.66960471\n",
      " 4.47166807 4.93497184 4.61764386 4.21446738]\n",
      "##########\n",
      "epoch:23 step:22001 [D loss: 0.518968, acc.: 75.00%] [G loss: 0.711659]\n",
      "epoch:23 step:22002 [D loss: 0.418754, acc.: 81.25%] [G loss: 0.719284]\n",
      "epoch:23 step:22003 [D loss: 0.484764, acc.: 77.34%] [G loss: 0.732698]\n",
      "epoch:23 step:22004 [D loss: 0.546559, acc.: 65.62%] [G loss: 0.748074]\n",
      "epoch:23 step:22005 [D loss: 0.509684, acc.: 72.66%] [G loss: 0.698504]\n",
      "epoch:23 step:22006 [D loss: 0.592396, acc.: 67.97%] [G loss: 0.616367]\n",
      "epoch:23 step:22007 [D loss: 0.600128, acc.: 64.06%] [G loss: 0.699362]\n",
      "epoch:23 step:22008 [D loss: 0.455914, acc.: 81.25%] [G loss: 0.868404]\n",
      "epoch:23 step:22009 [D loss: 0.629698, acc.: 66.41%] [G loss: 0.647628]\n",
      "epoch:23 step:22010 [D loss: 0.572846, acc.: 63.28%] [G loss: 0.691167]\n",
      "epoch:23 step:22011 [D loss: 0.475987, acc.: 74.22%] [G loss: 0.662880]\n",
      "epoch:23 step:22012 [D loss: 0.489696, acc.: 75.00%] [G loss: 0.752396]\n",
      "epoch:23 step:22013 [D loss: 0.501363, acc.: 71.88%] [G loss: 0.709959]\n",
      "epoch:23 step:22014 [D loss: 0.577234, acc.: 64.06%] [G loss: 0.674470]\n",
      "epoch:23 step:22015 [D loss: 0.523020, acc.: 75.78%] [G loss: 0.541359]\n",
      "epoch:23 step:22016 [D loss: 0.575749, acc.: 70.31%] [G loss: 0.559699]\n",
      "epoch:23 step:22017 [D loss: 0.561297, acc.: 65.62%] [G loss: 0.648106]\n",
      "epoch:23 step:22018 [D loss: 0.479879, acc.: 78.12%] [G loss: 0.634726]\n",
      "epoch:23 step:22019 [D loss: 0.597720, acc.: 64.84%] [G loss: 0.719973]\n",
      "epoch:23 step:22020 [D loss: 0.491180, acc.: 78.12%] [G loss: 0.676500]\n",
      "epoch:23 step:22021 [D loss: 0.506938, acc.: 72.66%] [G loss: 0.760802]\n",
      "epoch:23 step:22022 [D loss: 0.418153, acc.: 80.47%] [G loss: 0.749236]\n",
      "epoch:23 step:22023 [D loss: 0.418747, acc.: 81.25%] [G loss: 0.959417]\n",
      "epoch:23 step:22024 [D loss: 0.621969, acc.: 64.84%] [G loss: 0.706217]\n",
      "epoch:23 step:22025 [D loss: 0.639337, acc.: 62.50%] [G loss: 0.707169]\n",
      "epoch:23 step:22026 [D loss: 0.495458, acc.: 75.78%] [G loss: 0.661654]\n",
      "epoch:23 step:22027 [D loss: 0.556697, acc.: 71.88%] [G loss: 0.614352]\n",
      "epoch:23 step:22028 [D loss: 0.635477, acc.: 64.06%] [G loss: 0.490333]\n",
      "epoch:23 step:22029 [D loss: 0.536203, acc.: 68.75%] [G loss: 0.540856]\n",
      "epoch:23 step:22030 [D loss: 0.494151, acc.: 77.34%] [G loss: 0.562840]\n",
      "epoch:23 step:22031 [D loss: 0.554781, acc.: 68.75%] [G loss: 0.713962]\n",
      "epoch:23 step:22032 [D loss: 0.525686, acc.: 75.78%] [G loss: 0.788864]\n",
      "epoch:23 step:22033 [D loss: 0.637190, acc.: 65.62%] [G loss: 0.663515]\n",
      "epoch:23 step:22034 [D loss: 0.519393, acc.: 71.09%] [G loss: 0.696894]\n",
      "epoch:23 step:22035 [D loss: 0.490475, acc.: 75.00%] [G loss: 0.847876]\n",
      "epoch:23 step:22036 [D loss: 0.536002, acc.: 75.00%] [G loss: 0.708546]\n",
      "epoch:23 step:22037 [D loss: 0.576988, acc.: 65.62%] [G loss: 0.648633]\n",
      "epoch:23 step:22038 [D loss: 0.557699, acc.: 66.41%] [G loss: 0.635515]\n",
      "epoch:23 step:22039 [D loss: 0.509949, acc.: 70.31%] [G loss: 0.652341]\n",
      "epoch:23 step:22040 [D loss: 0.541699, acc.: 67.19%] [G loss: 0.578129]\n",
      "epoch:23 step:22041 [D loss: 0.570730, acc.: 71.09%] [G loss: 0.626035]\n",
      "epoch:23 step:22042 [D loss: 0.529546, acc.: 71.09%] [G loss: 0.553217]\n",
      "epoch:23 step:22043 [D loss: 0.600776, acc.: 61.72%] [G loss: 0.554893]\n",
      "epoch:23 step:22044 [D loss: 0.554965, acc.: 69.53%] [G loss: 0.669906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22045 [D loss: 0.552662, acc.: 70.31%] [G loss: 0.747264]\n",
      "epoch:23 step:22046 [D loss: 0.485922, acc.: 75.00%] [G loss: 0.769013]\n",
      "epoch:23 step:22047 [D loss: 0.532950, acc.: 70.31%] [G loss: 0.823788]\n",
      "epoch:23 step:22048 [D loss: 0.574558, acc.: 67.19%] [G loss: 0.740854]\n",
      "epoch:23 step:22049 [D loss: 0.490248, acc.: 71.09%] [G loss: 0.740669]\n",
      "epoch:23 step:22050 [D loss: 0.449702, acc.: 80.47%] [G loss: 0.772661]\n",
      "epoch:23 step:22051 [D loss: 0.565885, acc.: 68.75%] [G loss: 0.695711]\n",
      "epoch:23 step:22052 [D loss: 0.619140, acc.: 67.97%] [G loss: 0.567145]\n",
      "epoch:23 step:22053 [D loss: 0.594818, acc.: 66.41%] [G loss: 0.597690]\n",
      "epoch:23 step:22054 [D loss: 0.516224, acc.: 71.09%] [G loss: 0.463492]\n",
      "epoch:23 step:22055 [D loss: 0.455765, acc.: 78.91%] [G loss: 0.671058]\n",
      "epoch:23 step:22056 [D loss: 0.493203, acc.: 71.88%] [G loss: 0.834026]\n",
      "epoch:23 step:22057 [D loss: 0.477292, acc.: 76.56%] [G loss: 1.041413]\n",
      "epoch:23 step:22058 [D loss: 0.498966, acc.: 76.56%] [G loss: 1.046717]\n",
      "epoch:23 step:22059 [D loss: 0.416951, acc.: 81.25%] [G loss: 1.051142]\n",
      "epoch:23 step:22060 [D loss: 0.493124, acc.: 75.78%] [G loss: 1.070258]\n",
      "epoch:23 step:22061 [D loss: 0.604784, acc.: 67.19%] [G loss: 0.741530]\n",
      "epoch:23 step:22062 [D loss: 0.676781, acc.: 59.38%] [G loss: 0.505176]\n",
      "epoch:23 step:22063 [D loss: 0.556993, acc.: 70.31%] [G loss: 0.489190]\n",
      "epoch:23 step:22064 [D loss: 0.539942, acc.: 70.31%] [G loss: 0.504951]\n",
      "epoch:23 step:22065 [D loss: 0.464392, acc.: 74.22%] [G loss: 0.735470]\n",
      "epoch:23 step:22066 [D loss: 0.531881, acc.: 71.88%] [G loss: 0.608186]\n",
      "epoch:23 step:22067 [D loss: 0.522247, acc.: 71.09%] [G loss: 0.787596]\n",
      "epoch:23 step:22068 [D loss: 0.485632, acc.: 75.00%] [G loss: 0.603675]\n",
      "epoch:23 step:22069 [D loss: 0.551778, acc.: 71.09%] [G loss: 0.656241]\n",
      "epoch:23 step:22070 [D loss: 0.460813, acc.: 75.00%] [G loss: 0.828752]\n",
      "epoch:23 step:22071 [D loss: 0.497422, acc.: 68.75%] [G loss: 0.761579]\n",
      "epoch:23 step:22072 [D loss: 0.517016, acc.: 71.88%] [G loss: 0.671111]\n",
      "epoch:23 step:22073 [D loss: 0.511832, acc.: 75.78%] [G loss: 0.658401]\n",
      "epoch:23 step:22074 [D loss: 0.455935, acc.: 75.00%] [G loss: 0.843940]\n",
      "epoch:23 step:22075 [D loss: 0.491827, acc.: 74.22%] [G loss: 0.735956]\n",
      "epoch:23 step:22076 [D loss: 0.598513, acc.: 65.62%] [G loss: 0.642462]\n",
      "epoch:23 step:22077 [D loss: 0.509890, acc.: 73.44%] [G loss: 0.746253]\n",
      "epoch:23 step:22078 [D loss: 0.535358, acc.: 71.09%] [G loss: 0.705932]\n",
      "epoch:23 step:22079 [D loss: 0.672056, acc.: 60.94%] [G loss: 0.581459]\n",
      "epoch:23 step:22080 [D loss: 0.570604, acc.: 64.84%] [G loss: 0.628333]\n",
      "epoch:23 step:22081 [D loss: 0.533905, acc.: 70.31%] [G loss: 0.688349]\n",
      "epoch:23 step:22082 [D loss: 0.577491, acc.: 64.84%] [G loss: 0.634472]\n",
      "epoch:23 step:22083 [D loss: 0.529598, acc.: 71.88%] [G loss: 0.539730]\n",
      "epoch:23 step:22084 [D loss: 0.512407, acc.: 76.56%] [G loss: 0.917708]\n",
      "epoch:23 step:22085 [D loss: 0.459493, acc.: 75.00%] [G loss: 0.771874]\n",
      "epoch:23 step:22086 [D loss: 0.630623, acc.: 65.62%] [G loss: 0.664937]\n",
      "epoch:23 step:22087 [D loss: 0.509372, acc.: 70.31%] [G loss: 0.456604]\n",
      "epoch:23 step:22088 [D loss: 0.572125, acc.: 67.97%] [G loss: 0.560769]\n",
      "epoch:23 step:22089 [D loss: 0.561497, acc.: 71.09%] [G loss: 0.512527]\n",
      "epoch:23 step:22090 [D loss: 0.500450, acc.: 78.12%] [G loss: 0.629860]\n",
      "epoch:23 step:22091 [D loss: 0.530691, acc.: 74.22%] [G loss: 0.719230]\n",
      "epoch:23 step:22092 [D loss: 0.541872, acc.: 67.97%] [G loss: 0.586302]\n",
      "epoch:23 step:22093 [D loss: 0.611512, acc.: 63.28%] [G loss: 0.581820]\n",
      "epoch:23 step:22094 [D loss: 0.588239, acc.: 65.62%] [G loss: 0.417034]\n",
      "epoch:23 step:22095 [D loss: 0.490434, acc.: 76.56%] [G loss: 0.742372]\n",
      "epoch:23 step:22096 [D loss: 0.493127, acc.: 71.88%] [G loss: 0.616689]\n",
      "epoch:23 step:22097 [D loss: 0.513379, acc.: 76.56%] [G loss: 0.700920]\n",
      "epoch:23 step:22098 [D loss: 0.543159, acc.: 71.88%] [G loss: 0.790858]\n",
      "epoch:23 step:22099 [D loss: 0.545414, acc.: 70.31%] [G loss: 0.708785]\n",
      "epoch:23 step:22100 [D loss: 0.512329, acc.: 71.88%] [G loss: 0.761324]\n",
      "epoch:23 step:22101 [D loss: 0.493892, acc.: 71.88%] [G loss: 0.812490]\n",
      "epoch:23 step:22102 [D loss: 0.478038, acc.: 78.91%] [G loss: 0.816996]\n",
      "epoch:23 step:22103 [D loss: 0.445105, acc.: 79.69%] [G loss: 0.765667]\n",
      "epoch:23 step:22104 [D loss: 0.575757, acc.: 69.53%] [G loss: 0.584856]\n",
      "epoch:23 step:22105 [D loss: 0.434793, acc.: 78.12%] [G loss: 0.688352]\n",
      "epoch:23 step:22106 [D loss: 0.492379, acc.: 73.44%] [G loss: 0.721365]\n",
      "epoch:23 step:22107 [D loss: 0.522736, acc.: 73.44%] [G loss: 0.747272]\n",
      "epoch:23 step:22108 [D loss: 0.478001, acc.: 79.69%] [G loss: 0.608481]\n",
      "epoch:23 step:22109 [D loss: 0.485608, acc.: 75.00%] [G loss: 0.783869]\n",
      "epoch:23 step:22110 [D loss: 0.622782, acc.: 60.94%] [G loss: 0.574094]\n",
      "epoch:23 step:22111 [D loss: 0.567772, acc.: 71.88%] [G loss: 0.531912]\n",
      "epoch:23 step:22112 [D loss: 0.504675, acc.: 72.66%] [G loss: 0.693003]\n",
      "epoch:23 step:22113 [D loss: 0.598521, acc.: 65.62%] [G loss: 0.608198]\n",
      "epoch:23 step:22114 [D loss: 0.521854, acc.: 74.22%] [G loss: 0.744758]\n",
      "epoch:23 step:22115 [D loss: 0.525063, acc.: 75.00%] [G loss: 0.642731]\n",
      "epoch:23 step:22116 [D loss: 0.516964, acc.: 75.78%] [G loss: 0.683884]\n",
      "epoch:23 step:22117 [D loss: 0.717377, acc.: 57.03%] [G loss: 0.494397]\n",
      "epoch:23 step:22118 [D loss: 0.508709, acc.: 72.66%] [G loss: 0.749244]\n",
      "epoch:23 step:22119 [D loss: 0.480762, acc.: 76.56%] [G loss: 0.643743]\n",
      "epoch:23 step:22120 [D loss: 0.516613, acc.: 72.66%] [G loss: 0.613628]\n",
      "epoch:23 step:22121 [D loss: 0.494385, acc.: 75.00%] [G loss: 0.782268]\n",
      "epoch:23 step:22122 [D loss: 0.532460, acc.: 71.09%] [G loss: 0.551797]\n",
      "epoch:23 step:22123 [D loss: 0.547985, acc.: 69.53%] [G loss: 0.797446]\n",
      "epoch:23 step:22124 [D loss: 0.522899, acc.: 71.09%] [G loss: 0.666812]\n",
      "epoch:23 step:22125 [D loss: 0.459819, acc.: 76.56%] [G loss: 0.832206]\n",
      "epoch:23 step:22126 [D loss: 0.524743, acc.: 74.22%] [G loss: 0.822084]\n",
      "epoch:23 step:22127 [D loss: 0.562603, acc.: 70.31%] [G loss: 0.742414]\n",
      "epoch:23 step:22128 [D loss: 0.543146, acc.: 70.31%] [G loss: 0.696890]\n",
      "epoch:23 step:22129 [D loss: 0.614782, acc.: 66.41%] [G loss: 0.594583]\n",
      "epoch:23 step:22130 [D loss: 0.549484, acc.: 67.19%] [G loss: 0.616283]\n",
      "epoch:23 step:22131 [D loss: 0.596355, acc.: 67.97%] [G loss: 0.494601]\n",
      "epoch:23 step:22132 [D loss: 0.538844, acc.: 70.31%] [G loss: 0.631706]\n",
      "epoch:23 step:22133 [D loss: 0.499869, acc.: 74.22%] [G loss: 0.643350]\n",
      "epoch:23 step:22134 [D loss: 0.528035, acc.: 70.31%] [G loss: 0.755054]\n",
      "epoch:23 step:22135 [D loss: 0.577549, acc.: 64.06%] [G loss: 0.661569]\n",
      "epoch:23 step:22136 [D loss: 0.475287, acc.: 71.88%] [G loss: 0.892521]\n",
      "epoch:23 step:22137 [D loss: 0.580689, acc.: 65.62%] [G loss: 0.690271]\n",
      "epoch:23 step:22138 [D loss: 0.575222, acc.: 67.19%] [G loss: 0.487366]\n",
      "epoch:23 step:22139 [D loss: 0.530548, acc.: 72.66%] [G loss: 0.699259]\n",
      "epoch:23 step:22140 [D loss: 0.514815, acc.: 69.53%] [G loss: 0.918197]\n",
      "epoch:23 step:22141 [D loss: 0.609263, acc.: 65.62%] [G loss: 0.579560]\n",
      "epoch:23 step:22142 [D loss: 0.569590, acc.: 67.19%] [G loss: 0.585509]\n",
      "epoch:23 step:22143 [D loss: 0.459154, acc.: 80.47%] [G loss: 0.608730]\n",
      "epoch:23 step:22144 [D loss: 0.479465, acc.: 77.34%] [G loss: 0.718049]\n",
      "epoch:23 step:22145 [D loss: 0.566169, acc.: 67.19%] [G loss: 0.640716]\n",
      "epoch:23 step:22146 [D loss: 0.546825, acc.: 72.66%] [G loss: 0.618452]\n",
      "epoch:23 step:22147 [D loss: 0.532789, acc.: 71.09%] [G loss: 0.707423]\n",
      "epoch:23 step:22148 [D loss: 0.461652, acc.: 75.78%] [G loss: 0.727519]\n",
      "epoch:23 step:22149 [D loss: 0.507430, acc.: 78.91%] [G loss: 0.636401]\n",
      "epoch:23 step:22150 [D loss: 0.541436, acc.: 71.09%] [G loss: 0.632632]\n",
      "epoch:23 step:22151 [D loss: 0.563947, acc.: 70.31%] [G loss: 0.519990]\n",
      "epoch:23 step:22152 [D loss: 0.489618, acc.: 74.22%] [G loss: 0.770629]\n",
      "epoch:23 step:22153 [D loss: 0.563197, acc.: 69.53%] [G loss: 0.616781]\n",
      "epoch:23 step:22154 [D loss: 0.429568, acc.: 82.81%] [G loss: 0.733884]\n",
      "epoch:23 step:22155 [D loss: 0.600371, acc.: 66.41%] [G loss: 0.683214]\n",
      "epoch:23 step:22156 [D loss: 0.446458, acc.: 79.69%] [G loss: 0.861821]\n",
      "epoch:23 step:22157 [D loss: 0.625058, acc.: 68.75%] [G loss: 0.560422]\n",
      "epoch:23 step:22158 [D loss: 0.544148, acc.: 64.84%] [G loss: 0.575185]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22159 [D loss: 0.524567, acc.: 69.53%] [G loss: 0.753711]\n",
      "epoch:23 step:22160 [D loss: 0.513421, acc.: 74.22%] [G loss: 0.669441]\n",
      "epoch:23 step:22161 [D loss: 0.560935, acc.: 64.84%] [G loss: 0.596165]\n",
      "epoch:23 step:22162 [D loss: 0.445613, acc.: 81.25%] [G loss: 0.681871]\n",
      "epoch:23 step:22163 [D loss: 0.568641, acc.: 67.97%] [G loss: 0.735010]\n",
      "epoch:23 step:22164 [D loss: 0.463067, acc.: 76.56%] [G loss: 0.598100]\n",
      "epoch:23 step:22165 [D loss: 0.572489, acc.: 68.75%] [G loss: 0.658874]\n",
      "epoch:23 step:22166 [D loss: 0.616510, acc.: 66.41%] [G loss: 0.689587]\n",
      "epoch:23 step:22167 [D loss: 0.557016, acc.: 67.19%] [G loss: 0.740996]\n",
      "epoch:23 step:22168 [D loss: 0.585982, acc.: 72.66%] [G loss: 0.666911]\n",
      "epoch:23 step:22169 [D loss: 0.624357, acc.: 61.72%] [G loss: 0.668067]\n",
      "epoch:23 step:22170 [D loss: 0.508439, acc.: 71.88%] [G loss: 0.763568]\n",
      "epoch:23 step:22171 [D loss: 0.489224, acc.: 77.34%] [G loss: 0.698138]\n",
      "epoch:23 step:22172 [D loss: 0.536981, acc.: 71.09%] [G loss: 0.634747]\n",
      "epoch:23 step:22173 [D loss: 0.544036, acc.: 72.66%] [G loss: 0.571368]\n",
      "epoch:23 step:22174 [D loss: 0.481077, acc.: 78.91%] [G loss: 0.602378]\n",
      "epoch:23 step:22175 [D loss: 0.451574, acc.: 82.03%] [G loss: 0.755429]\n",
      "epoch:23 step:22176 [D loss: 0.600633, acc.: 64.84%] [G loss: 0.746387]\n",
      "epoch:23 step:22177 [D loss: 0.494909, acc.: 73.44%] [G loss: 0.666376]\n",
      "epoch:23 step:22178 [D loss: 0.488153, acc.: 78.12%] [G loss: 0.593739]\n",
      "epoch:23 step:22179 [D loss: 0.566782, acc.: 67.19%] [G loss: 0.706279]\n",
      "epoch:23 step:22180 [D loss: 0.486776, acc.: 75.78%] [G loss: 0.670733]\n",
      "epoch:23 step:22181 [D loss: 0.560123, acc.: 70.31%] [G loss: 0.648289]\n",
      "epoch:23 step:22182 [D loss: 0.463974, acc.: 78.12%] [G loss: 0.739437]\n",
      "epoch:23 step:22183 [D loss: 0.482809, acc.: 77.34%] [G loss: 0.906696]\n",
      "epoch:23 step:22184 [D loss: 0.534490, acc.: 68.75%] [G loss: 0.888240]\n",
      "epoch:23 step:22185 [D loss: 0.446396, acc.: 82.03%] [G loss: 0.907743]\n",
      "epoch:23 step:22186 [D loss: 0.473302, acc.: 76.56%] [G loss: 0.822291]\n",
      "epoch:23 step:22187 [D loss: 0.630761, acc.: 64.06%] [G loss: 0.509797]\n",
      "epoch:23 step:22188 [D loss: 0.547828, acc.: 68.75%] [G loss: 0.635750]\n",
      "epoch:23 step:22189 [D loss: 0.458956, acc.: 77.34%] [G loss: 0.627462]\n",
      "epoch:23 step:22190 [D loss: 0.491161, acc.: 73.44%] [G loss: 0.770701]\n",
      "epoch:23 step:22191 [D loss: 0.543789, acc.: 72.66%] [G loss: 0.865095]\n",
      "epoch:23 step:22192 [D loss: 0.433877, acc.: 76.56%] [G loss: 0.895804]\n",
      "epoch:23 step:22193 [D loss: 0.496460, acc.: 74.22%] [G loss: 0.963650]\n",
      "epoch:23 step:22194 [D loss: 0.559499, acc.: 66.41%] [G loss: 0.921616]\n",
      "epoch:23 step:22195 [D loss: 0.565328, acc.: 67.19%] [G loss: 0.783782]\n",
      "epoch:23 step:22196 [D loss: 0.519433, acc.: 74.22%] [G loss: 0.670290]\n",
      "epoch:23 step:22197 [D loss: 0.548827, acc.: 70.31%] [G loss: 0.687802]\n",
      "epoch:23 step:22198 [D loss: 0.449562, acc.: 79.69%] [G loss: 0.654076]\n",
      "epoch:23 step:22199 [D loss: 0.400928, acc.: 85.16%] [G loss: 0.929286]\n",
      "epoch:23 step:22200 [D loss: 0.447589, acc.: 80.47%] [G loss: 0.974787]\n",
      "##############\n",
      "[2.75850292 1.11685619 6.02907099 4.93892568 3.7197255  5.73363496\n",
      " 4.55554466 5.09213291 4.90300974 4.2188151 ]\n",
      "##########\n",
      "epoch:23 step:22201 [D loss: 0.464432, acc.: 80.47%] [G loss: 0.975680]\n",
      "epoch:23 step:22202 [D loss: 0.443166, acc.: 77.34%] [G loss: 0.852825]\n",
      "epoch:23 step:22203 [D loss: 0.569286, acc.: 67.97%] [G loss: 0.685434]\n",
      "epoch:23 step:22204 [D loss: 0.512332, acc.: 74.22%] [G loss: 0.738350]\n",
      "epoch:23 step:22205 [D loss: 0.446307, acc.: 78.91%] [G loss: 0.857072]\n",
      "epoch:23 step:22206 [D loss: 0.541869, acc.: 74.22%] [G loss: 0.645301]\n",
      "epoch:23 step:22207 [D loss: 0.525281, acc.: 72.66%] [G loss: 0.769913]\n",
      "epoch:23 step:22208 [D loss: 0.512513, acc.: 73.44%] [G loss: 0.817882]\n",
      "epoch:23 step:22209 [D loss: 0.542021, acc.: 72.66%] [G loss: 0.839822]\n",
      "epoch:23 step:22210 [D loss: 0.511984, acc.: 75.00%] [G loss: 0.880676]\n",
      "epoch:23 step:22211 [D loss: 0.535461, acc.: 69.53%] [G loss: 0.818733]\n",
      "epoch:23 step:22212 [D loss: 0.501550, acc.: 75.78%] [G loss: 0.802699]\n",
      "epoch:23 step:22213 [D loss: 0.488595, acc.: 75.78%] [G loss: 0.882626]\n",
      "epoch:23 step:22214 [D loss: 0.587683, acc.: 66.41%] [G loss: 0.608029]\n",
      "epoch:23 step:22215 [D loss: 0.506678, acc.: 74.22%] [G loss: 0.777663]\n",
      "epoch:23 step:22216 [D loss: 0.548694, acc.: 69.53%] [G loss: 0.920697]\n",
      "epoch:23 step:22217 [D loss: 0.488954, acc.: 77.34%] [G loss: 0.657999]\n",
      "epoch:23 step:22218 [D loss: 0.532953, acc.: 72.66%] [G loss: 0.681169]\n",
      "epoch:23 step:22219 [D loss: 0.563589, acc.: 71.09%] [G loss: 0.638582]\n",
      "epoch:23 step:22220 [D loss: 0.509667, acc.: 72.66%] [G loss: 0.643416]\n",
      "epoch:23 step:22221 [D loss: 0.651301, acc.: 54.69%] [G loss: 0.556949]\n",
      "epoch:23 step:22222 [D loss: 0.527393, acc.: 69.53%] [G loss: 0.791611]\n",
      "epoch:23 step:22223 [D loss: 0.547758, acc.: 71.88%] [G loss: 0.760027]\n",
      "epoch:23 step:22224 [D loss: 0.581072, acc.: 62.50%] [G loss: 0.810283]\n",
      "epoch:23 step:22225 [D loss: 0.493990, acc.: 75.78%] [G loss: 0.722771]\n",
      "epoch:23 step:22226 [D loss: 0.591161, acc.: 59.38%] [G loss: 0.696172]\n",
      "epoch:23 step:22227 [D loss: 0.523211, acc.: 71.09%] [G loss: 0.673639]\n",
      "epoch:23 step:22228 [D loss: 0.508494, acc.: 73.44%] [G loss: 0.733733]\n",
      "epoch:23 step:22229 [D loss: 0.529662, acc.: 74.22%] [G loss: 0.660977]\n",
      "epoch:23 step:22230 [D loss: 0.452037, acc.: 78.12%] [G loss: 0.781107]\n",
      "epoch:23 step:22231 [D loss: 0.519379, acc.: 72.66%] [G loss: 0.710391]\n",
      "epoch:23 step:22232 [D loss: 0.509601, acc.: 75.00%] [G loss: 0.726398]\n",
      "epoch:23 step:22233 [D loss: 0.517633, acc.: 75.00%] [G loss: 0.705498]\n",
      "epoch:23 step:22234 [D loss: 0.524609, acc.: 73.44%] [G loss: 0.621334]\n",
      "epoch:23 step:22235 [D loss: 0.653876, acc.: 58.59%] [G loss: 0.557663]\n",
      "epoch:23 step:22236 [D loss: 0.499471, acc.: 77.34%] [G loss: 0.610790]\n",
      "epoch:23 step:22237 [D loss: 0.504347, acc.: 74.22%] [G loss: 0.684838]\n",
      "epoch:23 step:22238 [D loss: 0.536460, acc.: 68.75%] [G loss: 0.541460]\n",
      "epoch:23 step:22239 [D loss: 0.530585, acc.: 78.12%] [G loss: 0.488655]\n",
      "epoch:23 step:22240 [D loss: 0.530251, acc.: 74.22%] [G loss: 0.605824]\n",
      "epoch:23 step:22241 [D loss: 0.470437, acc.: 77.34%] [G loss: 0.777609]\n",
      "epoch:23 step:22242 [D loss: 0.499604, acc.: 75.78%] [G loss: 0.541457]\n",
      "epoch:23 step:22243 [D loss: 0.534766, acc.: 73.44%] [G loss: 0.541850]\n",
      "epoch:23 step:22244 [D loss: 0.438302, acc.: 78.12%] [G loss: 0.764051]\n",
      "epoch:23 step:22245 [D loss: 0.515850, acc.: 69.53%] [G loss: 0.816950]\n",
      "epoch:23 step:22246 [D loss: 0.559786, acc.: 68.75%] [G loss: 0.680097]\n",
      "epoch:23 step:22247 [D loss: 0.617906, acc.: 67.19%] [G loss: 0.685599]\n",
      "epoch:23 step:22248 [D loss: 0.569448, acc.: 64.84%] [G loss: 0.681855]\n",
      "epoch:23 step:22249 [D loss: 0.570096, acc.: 68.75%] [G loss: 0.575054]\n",
      "epoch:23 step:22250 [D loss: 0.479185, acc.: 74.22%] [G loss: 0.693846]\n",
      "epoch:23 step:22251 [D loss: 0.515443, acc.: 76.56%] [G loss: 0.874218]\n",
      "epoch:23 step:22252 [D loss: 0.504226, acc.: 72.66%] [G loss: 0.983553]\n",
      "epoch:23 step:22253 [D loss: 0.566545, acc.: 73.44%] [G loss: 0.867498]\n",
      "epoch:23 step:22254 [D loss: 0.612696, acc.: 64.06%] [G loss: 0.590139]\n",
      "epoch:23 step:22255 [D loss: 0.600344, acc.: 64.06%] [G loss: 0.571065]\n",
      "epoch:23 step:22256 [D loss: 0.518686, acc.: 71.09%] [G loss: 0.662763]\n",
      "epoch:23 step:22257 [D loss: 0.611782, acc.: 71.09%] [G loss: 0.680327]\n",
      "epoch:23 step:22258 [D loss: 0.498168, acc.: 68.75%] [G loss: 0.955473]\n",
      "epoch:23 step:22259 [D loss: 0.482774, acc.: 76.56%] [G loss: 0.904205]\n",
      "epoch:23 step:22260 [D loss: 0.583698, acc.: 64.84%] [G loss: 0.814745]\n",
      "epoch:23 step:22261 [D loss: 0.605193, acc.: 63.28%] [G loss: 0.560076]\n",
      "epoch:23 step:22262 [D loss: 0.585464, acc.: 65.62%] [G loss: 0.666313]\n",
      "epoch:23 step:22263 [D loss: 0.571285, acc.: 62.50%] [G loss: 0.725585]\n",
      "epoch:23 step:22264 [D loss: 0.577068, acc.: 66.41%] [G loss: 0.727619]\n",
      "epoch:23 step:22265 [D loss: 0.551681, acc.: 71.88%] [G loss: 0.600566]\n",
      "epoch:23 step:22266 [D loss: 0.600637, acc.: 66.41%] [G loss: 0.641471]\n",
      "epoch:23 step:22267 [D loss: 0.611308, acc.: 62.50%] [G loss: 0.519086]\n",
      "epoch:23 step:22268 [D loss: 0.544726, acc.: 70.31%] [G loss: 0.484206]\n",
      "epoch:23 step:22269 [D loss: 0.555406, acc.: 66.41%] [G loss: 0.518423]\n",
      "epoch:23 step:22270 [D loss: 0.453906, acc.: 75.78%] [G loss: 0.667427]\n",
      "epoch:23 step:22271 [D loss: 0.577464, acc.: 67.97%] [G loss: 0.631825]\n",
      "epoch:23 step:22272 [D loss: 0.505093, acc.: 73.44%] [G loss: 0.677167]\n",
      "epoch:23 step:22273 [D loss: 0.531228, acc.: 68.75%] [G loss: 0.640148]\n",
      "epoch:23 step:22274 [D loss: 0.600159, acc.: 65.62%] [G loss: 0.504174]\n",
      "epoch:23 step:22275 [D loss: 0.502656, acc.: 76.56%] [G loss: 0.672793]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22276 [D loss: 0.528958, acc.: 73.44%] [G loss: 0.621721]\n",
      "epoch:23 step:22277 [D loss: 0.496557, acc.: 75.78%] [G loss: 0.591183]\n",
      "epoch:23 step:22278 [D loss: 0.524470, acc.: 66.41%] [G loss: 0.653715]\n",
      "epoch:23 step:22279 [D loss: 0.527730, acc.: 69.53%] [G loss: 0.706702]\n",
      "epoch:23 step:22280 [D loss: 0.568383, acc.: 66.41%] [G loss: 0.712831]\n",
      "epoch:23 step:22281 [D loss: 0.552006, acc.: 70.31%] [G loss: 0.542409]\n",
      "epoch:23 step:22282 [D loss: 0.583621, acc.: 69.53%] [G loss: 0.583933]\n",
      "epoch:23 step:22283 [D loss: 0.568518, acc.: 70.31%] [G loss: 0.522382]\n",
      "epoch:23 step:22284 [D loss: 0.498541, acc.: 76.56%] [G loss: 0.612692]\n",
      "epoch:23 step:22285 [D loss: 0.478308, acc.: 78.12%] [G loss: 0.721193]\n",
      "epoch:23 step:22286 [D loss: 0.548440, acc.: 67.19%] [G loss: 0.775937]\n",
      "epoch:23 step:22287 [D loss: 0.458467, acc.: 80.47%] [G loss: 0.696073]\n",
      "epoch:23 step:22288 [D loss: 0.561746, acc.: 65.62%] [G loss: 0.599027]\n",
      "epoch:23 step:22289 [D loss: 0.530960, acc.: 68.75%] [G loss: 0.639992]\n",
      "epoch:23 step:22290 [D loss: 0.617032, acc.: 60.94%] [G loss: 0.785772]\n",
      "epoch:23 step:22291 [D loss: 0.608703, acc.: 59.38%] [G loss: 0.506097]\n",
      "epoch:23 step:22292 [D loss: 0.574712, acc.: 68.75%] [G loss: 0.513293]\n",
      "epoch:23 step:22293 [D loss: 0.542858, acc.: 70.31%] [G loss: 0.685463]\n",
      "epoch:23 step:22294 [D loss: 0.518771, acc.: 69.53%] [G loss: 0.760835]\n",
      "epoch:23 step:22295 [D loss: 0.585559, acc.: 75.00%] [G loss: 0.889096]\n",
      "epoch:23 step:22296 [D loss: 0.605265, acc.: 65.62%] [G loss: 0.710011]\n",
      "epoch:23 step:22297 [D loss: 0.462482, acc.: 77.34%] [G loss: 0.706301]\n",
      "epoch:23 step:22298 [D loss: 0.421872, acc.: 78.91%] [G loss: 0.733890]\n",
      "epoch:23 step:22299 [D loss: 0.549883, acc.: 67.97%] [G loss: 0.720474]\n",
      "epoch:23 step:22300 [D loss: 0.512012, acc.: 72.66%] [G loss: 0.811690]\n",
      "epoch:23 step:22301 [D loss: 0.496854, acc.: 73.44%] [G loss: 0.787143]\n",
      "epoch:23 step:22302 [D loss: 0.530024, acc.: 70.31%] [G loss: 0.732876]\n",
      "epoch:23 step:22303 [D loss: 0.558936, acc.: 66.41%] [G loss: 0.684005]\n",
      "epoch:23 step:22304 [D loss: 0.522200, acc.: 77.34%] [G loss: 0.719928]\n",
      "epoch:23 step:22305 [D loss: 0.604871, acc.: 65.62%] [G loss: 0.640349]\n",
      "epoch:23 step:22306 [D loss: 0.537009, acc.: 67.97%] [G loss: 0.665830]\n",
      "epoch:23 step:22307 [D loss: 0.516429, acc.: 73.44%] [G loss: 0.734987]\n",
      "epoch:23 step:22308 [D loss: 0.522202, acc.: 71.88%] [G loss: 0.632426]\n",
      "epoch:23 step:22309 [D loss: 0.524549, acc.: 73.44%] [G loss: 0.633840]\n",
      "epoch:23 step:22310 [D loss: 0.593518, acc.: 67.19%] [G loss: 0.620269]\n",
      "epoch:23 step:22311 [D loss: 0.499338, acc.: 72.66%] [G loss: 0.655298]\n",
      "epoch:23 step:22312 [D loss: 0.557326, acc.: 67.97%] [G loss: 0.604456]\n",
      "epoch:23 step:22313 [D loss: 0.600652, acc.: 64.06%] [G loss: 0.593475]\n",
      "epoch:23 step:22314 [D loss: 0.513087, acc.: 75.00%] [G loss: 0.534290]\n",
      "epoch:23 step:22315 [D loss: 0.563454, acc.: 64.84%] [G loss: 0.738993]\n",
      "epoch:23 step:22316 [D loss: 0.667894, acc.: 65.62%] [G loss: 0.643279]\n",
      "epoch:23 step:22317 [D loss: 0.673345, acc.: 56.25%] [G loss: 0.499978]\n",
      "epoch:23 step:22318 [D loss: 0.500814, acc.: 71.88%] [G loss: 0.640502]\n",
      "epoch:23 step:22319 [D loss: 0.538261, acc.: 74.22%] [G loss: 0.889386]\n",
      "epoch:23 step:22320 [D loss: 0.473269, acc.: 78.91%] [G loss: 1.045858]\n",
      "epoch:23 step:22321 [D loss: 0.540490, acc.: 68.75%] [G loss: 0.842152]\n",
      "epoch:23 step:22322 [D loss: 0.570954, acc.: 69.53%] [G loss: 0.913886]\n",
      "epoch:23 step:22323 [D loss: 0.597165, acc.: 63.28%] [G loss: 0.737622]\n",
      "epoch:23 step:22324 [D loss: 0.499982, acc.: 75.78%] [G loss: 0.724440]\n",
      "epoch:23 step:22325 [D loss: 0.518162, acc.: 78.91%] [G loss: 0.803029]\n",
      "epoch:23 step:22326 [D loss: 0.543906, acc.: 71.09%] [G loss: 0.691429]\n",
      "epoch:23 step:22327 [D loss: 0.554425, acc.: 69.53%] [G loss: 0.636187]\n",
      "epoch:23 step:22328 [D loss: 0.541655, acc.: 71.88%] [G loss: 0.643378]\n",
      "epoch:23 step:22329 [D loss: 0.536056, acc.: 73.44%] [G loss: 0.669157]\n",
      "epoch:23 step:22330 [D loss: 0.601827, acc.: 66.41%] [G loss: 0.629962]\n",
      "epoch:23 step:22331 [D loss: 0.493324, acc.: 78.12%] [G loss: 0.671069]\n",
      "epoch:23 step:22332 [D loss: 0.468034, acc.: 78.12%] [G loss: 0.673105]\n",
      "epoch:23 step:22333 [D loss: 0.517583, acc.: 75.00%] [G loss: 0.924904]\n",
      "epoch:23 step:22334 [D loss: 0.504154, acc.: 77.34%] [G loss: 0.738885]\n",
      "epoch:23 step:22335 [D loss: 0.569991, acc.: 71.09%] [G loss: 0.585986]\n",
      "epoch:23 step:22336 [D loss: 0.525114, acc.: 72.66%] [G loss: 0.776080]\n",
      "epoch:23 step:22337 [D loss: 0.465023, acc.: 79.69%] [G loss: 0.636977]\n",
      "epoch:23 step:22338 [D loss: 0.575677, acc.: 66.41%] [G loss: 0.616584]\n",
      "epoch:23 step:22339 [D loss: 0.700883, acc.: 53.12%] [G loss: 0.635857]\n",
      "epoch:23 step:22340 [D loss: 0.543574, acc.: 64.06%] [G loss: 0.604929]\n",
      "epoch:23 step:22341 [D loss: 0.552155, acc.: 68.75%] [G loss: 0.579202]\n",
      "epoch:23 step:22342 [D loss: 0.561373, acc.: 66.41%] [G loss: 0.595462]\n",
      "epoch:23 step:22343 [D loss: 0.487374, acc.: 68.75%] [G loss: 0.718759]\n",
      "epoch:23 step:22344 [D loss: 0.603372, acc.: 68.75%] [G loss: 0.817801]\n",
      "epoch:23 step:22345 [D loss: 0.638795, acc.: 62.50%] [G loss: 0.781247]\n",
      "epoch:23 step:22346 [D loss: 0.541641, acc.: 67.19%] [G loss: 0.787570]\n",
      "epoch:23 step:22347 [D loss: 0.576545, acc.: 70.31%] [G loss: 0.794091]\n",
      "epoch:23 step:22348 [D loss: 0.558675, acc.: 68.75%] [G loss: 0.840393]\n",
      "epoch:23 step:22349 [D loss: 0.534020, acc.: 65.62%] [G loss: 0.788027]\n",
      "epoch:23 step:22350 [D loss: 0.563934, acc.: 66.41%] [G loss: 0.565278]\n",
      "epoch:23 step:22351 [D loss: 0.589111, acc.: 66.41%] [G loss: 0.651158]\n",
      "epoch:23 step:22352 [D loss: 0.547959, acc.: 72.66%] [G loss: 0.673628]\n",
      "epoch:23 step:22353 [D loss: 0.456167, acc.: 75.78%] [G loss: 0.909077]\n",
      "epoch:23 step:22354 [D loss: 0.482200, acc.: 78.91%] [G loss: 0.821402]\n",
      "epoch:23 step:22355 [D loss: 0.565366, acc.: 68.75%] [G loss: 0.556702]\n",
      "epoch:23 step:22356 [D loss: 0.527619, acc.: 71.09%] [G loss: 0.604912]\n",
      "epoch:23 step:22357 [D loss: 0.571755, acc.: 66.41%] [G loss: 0.523854]\n",
      "epoch:23 step:22358 [D loss: 0.503206, acc.: 73.44%] [G loss: 0.575748]\n",
      "epoch:23 step:22359 [D loss: 0.495928, acc.: 74.22%] [G loss: 0.625059]\n",
      "epoch:23 step:22360 [D loss: 0.506160, acc.: 72.66%] [G loss: 0.766885]\n",
      "epoch:23 step:22361 [D loss: 0.567558, acc.: 64.84%] [G loss: 0.563995]\n",
      "epoch:23 step:22362 [D loss: 0.563880, acc.: 71.88%] [G loss: 0.653040]\n",
      "epoch:23 step:22363 [D loss: 0.600760, acc.: 67.97%] [G loss: 0.674763]\n",
      "epoch:23 step:22364 [D loss: 0.599840, acc.: 65.62%] [G loss: 0.496380]\n",
      "epoch:23 step:22365 [D loss: 0.493365, acc.: 70.31%] [G loss: 0.574189]\n",
      "epoch:23 step:22366 [D loss: 0.521210, acc.: 73.44%] [G loss: 1.045198]\n",
      "epoch:23 step:22367 [D loss: 0.514818, acc.: 71.88%] [G loss: 0.799591]\n",
      "epoch:23 step:22368 [D loss: 0.616358, acc.: 65.62%] [G loss: 0.687002]\n",
      "epoch:23 step:22369 [D loss: 0.558967, acc.: 73.44%] [G loss: 0.522370]\n",
      "epoch:23 step:22370 [D loss: 0.510160, acc.: 70.31%] [G loss: 0.490058]\n",
      "epoch:23 step:22371 [D loss: 0.612528, acc.: 67.19%] [G loss: 0.536002]\n",
      "epoch:23 step:22372 [D loss: 0.519883, acc.: 68.75%] [G loss: 0.457215]\n",
      "epoch:23 step:22373 [D loss: 0.596144, acc.: 65.62%] [G loss: 0.623470]\n",
      "epoch:23 step:22374 [D loss: 0.417331, acc.: 81.25%] [G loss: 0.702479]\n",
      "epoch:23 step:22375 [D loss: 0.555848, acc.: 69.53%] [G loss: 0.778798]\n",
      "epoch:23 step:22376 [D loss: 0.562161, acc.: 66.41%] [G loss: 0.698008]\n",
      "epoch:23 step:22377 [D loss: 0.504817, acc.: 72.66%] [G loss: 0.698875]\n",
      "epoch:23 step:22378 [D loss: 0.550561, acc.: 71.09%] [G loss: 0.589853]\n",
      "epoch:23 step:22379 [D loss: 0.604123, acc.: 67.19%] [G loss: 0.735885]\n",
      "epoch:23 step:22380 [D loss: 0.547532, acc.: 71.88%] [G loss: 0.569752]\n",
      "epoch:23 step:22381 [D loss: 0.530273, acc.: 76.56%] [G loss: 0.666192]\n",
      "epoch:23 step:22382 [D loss: 0.499874, acc.: 79.69%] [G loss: 0.547987]\n",
      "epoch:23 step:22383 [D loss: 0.510972, acc.: 71.88%] [G loss: 0.621612]\n",
      "epoch:23 step:22384 [D loss: 0.512094, acc.: 74.22%] [G loss: 0.688782]\n",
      "epoch:23 step:22385 [D loss: 0.487368, acc.: 74.22%] [G loss: 0.628932]\n",
      "epoch:23 step:22386 [D loss: 0.533749, acc.: 68.75%] [G loss: 0.552981]\n",
      "epoch:23 step:22387 [D loss: 0.518056, acc.: 71.88%] [G loss: 0.722236]\n",
      "epoch:23 step:22388 [D loss: 0.608666, acc.: 63.28%] [G loss: 0.681550]\n",
      "epoch:23 step:22389 [D loss: 0.511463, acc.: 76.56%] [G loss: 0.718667]\n",
      "epoch:23 step:22390 [D loss: 0.571260, acc.: 67.97%] [G loss: 0.615742]\n",
      "epoch:23 step:22391 [D loss: 0.605650, acc.: 67.97%] [G loss: 0.530770]\n",
      "epoch:23 step:22392 [D loss: 0.559647, acc.: 69.53%] [G loss: 0.576388]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22393 [D loss: 0.494889, acc.: 74.22%] [G loss: 0.691851]\n",
      "epoch:23 step:22394 [D loss: 0.505727, acc.: 75.00%] [G loss: 0.629698]\n",
      "epoch:23 step:22395 [D loss: 0.565946, acc.: 69.53%] [G loss: 0.733924]\n",
      "epoch:23 step:22396 [D loss: 0.530836, acc.: 71.88%] [G loss: 0.644835]\n",
      "epoch:23 step:22397 [D loss: 0.552727, acc.: 68.75%] [G loss: 0.584041]\n",
      "epoch:23 step:22398 [D loss: 0.618081, acc.: 61.72%] [G loss: 0.491885]\n",
      "epoch:23 step:22399 [D loss: 0.507984, acc.: 71.09%] [G loss: 0.578494]\n",
      "epoch:23 step:22400 [D loss: 0.583109, acc.: 64.84%] [G loss: 0.469753]\n",
      "##############\n",
      "[2.64882998 0.60908451 6.0692538  4.97628358 3.66301164 5.72930116\n",
      " 4.33075532 4.79201792 4.63227544 4.14754557]\n",
      "##########\n",
      "epoch:23 step:22401 [D loss: 0.571050, acc.: 73.44%] [G loss: 0.735087]\n",
      "epoch:23 step:22402 [D loss: 0.594275, acc.: 66.41%] [G loss: 0.512791]\n",
      "epoch:23 step:22403 [D loss: 0.523669, acc.: 74.22%] [G loss: 0.641144]\n",
      "epoch:23 step:22404 [D loss: 0.536743, acc.: 71.09%] [G loss: 0.691100]\n",
      "epoch:23 step:22405 [D loss: 0.499138, acc.: 71.88%] [G loss: 0.799618]\n",
      "epoch:23 step:22406 [D loss: 0.597632, acc.: 63.28%] [G loss: 0.554745]\n",
      "epoch:23 step:22407 [D loss: 0.609772, acc.: 67.97%] [G loss: 0.701061]\n",
      "epoch:23 step:22408 [D loss: 0.484733, acc.: 79.69%] [G loss: 0.629498]\n",
      "epoch:23 step:22409 [D loss: 0.656662, acc.: 64.84%] [G loss: 0.535236]\n",
      "epoch:23 step:22410 [D loss: 0.567219, acc.: 71.88%] [G loss: 0.548596]\n",
      "epoch:23 step:22411 [D loss: 0.475267, acc.: 74.22%] [G loss: 0.683563]\n",
      "epoch:23 step:22412 [D loss: 0.614399, acc.: 64.84%] [G loss: 0.570015]\n",
      "epoch:23 step:22413 [D loss: 0.564035, acc.: 68.75%] [G loss: 0.646790]\n",
      "epoch:23 step:22414 [D loss: 0.536608, acc.: 67.97%] [G loss: 0.400825]\n",
      "epoch:23 step:22415 [D loss: 0.501323, acc.: 71.88%] [G loss: 0.568785]\n",
      "epoch:23 step:22416 [D loss: 0.533445, acc.: 69.53%] [G loss: 0.531623]\n",
      "epoch:23 step:22417 [D loss: 0.461639, acc.: 75.78%] [G loss: 0.537026]\n",
      "epoch:23 step:22418 [D loss: 0.652336, acc.: 63.28%] [G loss: 0.351852]\n",
      "epoch:23 step:22419 [D loss: 0.556245, acc.: 71.88%] [G loss: 0.609869]\n",
      "epoch:23 step:22420 [D loss: 0.568734, acc.: 61.72%] [G loss: 0.642977]\n",
      "epoch:23 step:22421 [D loss: 0.435737, acc.: 80.47%] [G loss: 1.085228]\n",
      "epoch:23 step:22422 [D loss: 0.570309, acc.: 66.41%] [G loss: 0.620067]\n",
      "epoch:23 step:22423 [D loss: 0.557928, acc.: 67.19%] [G loss: 0.642478]\n",
      "epoch:23 step:22424 [D loss: 0.565674, acc.: 67.97%] [G loss: 0.611850]\n",
      "epoch:23 step:22425 [D loss: 0.602974, acc.: 67.97%] [G loss: 0.765163]\n",
      "epoch:23 step:22426 [D loss: 0.512992, acc.: 74.22%] [G loss: 0.647872]\n",
      "epoch:23 step:22427 [D loss: 0.533683, acc.: 72.66%] [G loss: 0.716370]\n",
      "epoch:23 step:22428 [D loss: 0.625839, acc.: 62.50%] [G loss: 0.611489]\n",
      "epoch:23 step:22429 [D loss: 0.487920, acc.: 74.22%] [G loss: 0.527904]\n",
      "epoch:23 step:22430 [D loss: 0.518009, acc.: 75.00%] [G loss: 0.615729]\n",
      "epoch:23 step:22431 [D loss: 0.622394, acc.: 57.03%] [G loss: 0.574266]\n",
      "epoch:23 step:22432 [D loss: 0.535190, acc.: 68.75%] [G loss: 0.470348]\n",
      "epoch:23 step:22433 [D loss: 0.592186, acc.: 64.06%] [G loss: 0.434563]\n",
      "epoch:23 step:22434 [D loss: 0.554010, acc.: 72.66%] [G loss: 0.669952]\n",
      "epoch:23 step:22435 [D loss: 0.482011, acc.: 75.78%] [G loss: 0.740671]\n",
      "epoch:23 step:22436 [D loss: 0.512355, acc.: 74.22%] [G loss: 0.670438]\n",
      "epoch:23 step:22437 [D loss: 0.548690, acc.: 71.09%] [G loss: 0.820261]\n",
      "epoch:23 step:22438 [D loss: 0.553226, acc.: 71.09%] [G loss: 0.659740]\n",
      "epoch:23 step:22439 [D loss: 0.537741, acc.: 67.97%] [G loss: 0.775726]\n",
      "epoch:23 step:22440 [D loss: 0.595714, acc.: 64.06%] [G loss: 0.678094]\n",
      "epoch:23 step:22441 [D loss: 0.510390, acc.: 72.66%] [G loss: 0.654008]\n",
      "epoch:23 step:22442 [D loss: 0.550502, acc.: 67.97%] [G loss: 0.627601]\n",
      "epoch:23 step:22443 [D loss: 0.665066, acc.: 60.94%] [G loss: 0.572101]\n",
      "epoch:23 step:22444 [D loss: 0.535910, acc.: 71.88%] [G loss: 0.730343]\n",
      "epoch:23 step:22445 [D loss: 0.417513, acc.: 78.12%] [G loss: 0.811277]\n",
      "epoch:23 step:22446 [D loss: 0.483996, acc.: 75.00%] [G loss: 0.956535]\n",
      "epoch:23 step:22447 [D loss: 0.465708, acc.: 78.12%] [G loss: 0.893913]\n",
      "epoch:23 step:22448 [D loss: 0.520591, acc.: 73.44%] [G loss: 0.943630]\n",
      "epoch:23 step:22449 [D loss: 0.484233, acc.: 74.22%] [G loss: 0.898673]\n",
      "epoch:23 step:22450 [D loss: 0.487594, acc.: 78.12%] [G loss: 0.777763]\n",
      "epoch:23 step:22451 [D loss: 0.523512, acc.: 71.88%] [G loss: 0.740204]\n",
      "epoch:23 step:22452 [D loss: 0.547059, acc.: 70.31%] [G loss: 0.718007]\n",
      "epoch:23 step:22453 [D loss: 0.598909, acc.: 67.97%] [G loss: 0.658431]\n",
      "epoch:23 step:22454 [D loss: 0.541986, acc.: 69.53%] [G loss: 0.594715]\n",
      "epoch:23 step:22455 [D loss: 0.570945, acc.: 67.19%] [G loss: 0.649943]\n",
      "epoch:23 step:22456 [D loss: 0.565754, acc.: 72.66%] [G loss: 0.745262]\n",
      "epoch:23 step:22457 [D loss: 0.517000, acc.: 71.09%] [G loss: 0.894551]\n",
      "epoch:23 step:22458 [D loss: 0.480256, acc.: 76.56%] [G loss: 0.714655]\n",
      "epoch:23 step:22459 [D loss: 0.529387, acc.: 72.66%] [G loss: 0.740751]\n",
      "epoch:23 step:22460 [D loss: 0.447722, acc.: 78.91%] [G loss: 0.732183]\n",
      "epoch:23 step:22461 [D loss: 0.519195, acc.: 75.78%] [G loss: 0.681929]\n",
      "epoch:23 step:22462 [D loss: 0.463972, acc.: 80.47%] [G loss: 0.737782]\n",
      "epoch:23 step:22463 [D loss: 0.571263, acc.: 68.75%] [G loss: 0.714184]\n",
      "epoch:23 step:22464 [D loss: 0.528276, acc.: 75.78%] [G loss: 0.833216]\n",
      "epoch:23 step:22465 [D loss: 0.521290, acc.: 68.75%] [G loss: 0.899360]\n",
      "epoch:23 step:22466 [D loss: 0.625799, acc.: 66.41%] [G loss: 0.724720]\n",
      "epoch:23 step:22467 [D loss: 0.488107, acc.: 74.22%] [G loss: 0.707723]\n",
      "epoch:23 step:22468 [D loss: 0.571927, acc.: 64.84%] [G loss: 0.666116]\n",
      "epoch:23 step:22469 [D loss: 0.450394, acc.: 78.91%] [G loss: 0.709942]\n",
      "epoch:23 step:22470 [D loss: 0.492301, acc.: 80.47%] [G loss: 0.842818]\n",
      "epoch:23 step:22471 [D loss: 0.635495, acc.: 68.75%] [G loss: 0.924405]\n",
      "epoch:23 step:22472 [D loss: 0.490351, acc.: 74.22%] [G loss: 0.664997]\n",
      "epoch:23 step:22473 [D loss: 0.569504, acc.: 68.75%] [G loss: 0.668595]\n",
      "epoch:23 step:22474 [D loss: 0.452603, acc.: 75.00%] [G loss: 0.696130]\n",
      "epoch:23 step:22475 [D loss: 0.436628, acc.: 77.34%] [G loss: 0.870171]\n",
      "epoch:23 step:22476 [D loss: 0.442267, acc.: 82.03%] [G loss: 0.921353]\n",
      "epoch:23 step:22477 [D loss: 0.466719, acc.: 71.09%] [G loss: 1.163545]\n",
      "epoch:23 step:22478 [D loss: 0.472540, acc.: 80.47%] [G loss: 1.160181]\n",
      "epoch:23 step:22479 [D loss: 0.639601, acc.: 69.53%] [G loss: 0.987318]\n",
      "epoch:23 step:22480 [D loss: 0.540992, acc.: 71.88%] [G loss: 1.217763]\n",
      "epoch:23 step:22481 [D loss: 0.451785, acc.: 78.12%] [G loss: 1.072553]\n",
      "epoch:23 step:22482 [D loss: 0.489245, acc.: 75.00%] [G loss: 0.923064]\n",
      "epoch:23 step:22483 [D loss: 0.514490, acc.: 74.22%] [G loss: 0.928472]\n",
      "epoch:23 step:22484 [D loss: 0.510252, acc.: 73.44%] [G loss: 0.983914]\n",
      "epoch:23 step:22485 [D loss: 0.528534, acc.: 73.44%] [G loss: 1.004758]\n",
      "epoch:23 step:22486 [D loss: 0.464312, acc.: 75.00%] [G loss: 1.014375]\n",
      "epoch:23 step:22487 [D loss: 0.412380, acc.: 80.47%] [G loss: 1.172778]\n",
      "epoch:23 step:22488 [D loss: 0.472881, acc.: 78.91%] [G loss: 1.039221]\n",
      "epoch:24 step:22489 [D loss: 0.582436, acc.: 68.75%] [G loss: 1.375782]\n",
      "epoch:24 step:22490 [D loss: 0.465476, acc.: 77.34%] [G loss: 1.075796]\n",
      "epoch:24 step:22491 [D loss: 0.590663, acc.: 72.66%] [G loss: 0.969030]\n",
      "epoch:24 step:22492 [D loss: 0.550158, acc.: 68.75%] [G loss: 0.711055]\n",
      "epoch:24 step:22493 [D loss: 0.580674, acc.: 68.75%] [G loss: 0.782964]\n",
      "epoch:24 step:22494 [D loss: 0.578735, acc.: 72.66%] [G loss: 0.644680]\n",
      "epoch:24 step:22495 [D loss: 0.493977, acc.: 78.12%] [G loss: 0.766393]\n",
      "epoch:24 step:22496 [D loss: 0.481261, acc.: 75.00%] [G loss: 0.775220]\n",
      "epoch:24 step:22497 [D loss: 0.515790, acc.: 71.09%] [G loss: 0.762413]\n",
      "epoch:24 step:22498 [D loss: 0.533025, acc.: 74.22%] [G loss: 0.704703]\n",
      "epoch:24 step:22499 [D loss: 0.438043, acc.: 81.25%] [G loss: 0.656989]\n",
      "epoch:24 step:22500 [D loss: 0.578762, acc.: 67.19%] [G loss: 0.736529]\n",
      "epoch:24 step:22501 [D loss: 0.517117, acc.: 72.66%] [G loss: 0.730817]\n",
      "epoch:24 step:22502 [D loss: 0.526520, acc.: 73.44%] [G loss: 0.730326]\n",
      "epoch:24 step:22503 [D loss: 0.467337, acc.: 76.56%] [G loss: 0.807440]\n",
      "epoch:24 step:22504 [D loss: 0.557859, acc.: 72.66%] [G loss: 0.791175]\n",
      "epoch:24 step:22505 [D loss: 0.578004, acc.: 68.75%] [G loss: 0.706390]\n",
      "epoch:24 step:22506 [D loss: 0.573841, acc.: 74.22%] [G loss: 0.918080]\n",
      "epoch:24 step:22507 [D loss: 0.573791, acc.: 66.41%] [G loss: 0.667790]\n",
      "epoch:24 step:22508 [D loss: 0.602755, acc.: 64.84%] [G loss: 0.974012]\n",
      "epoch:24 step:22509 [D loss: 0.594554, acc.: 67.19%] [G loss: 0.616099]\n",
      "epoch:24 step:22510 [D loss: 0.450870, acc.: 78.12%] [G loss: 0.881210]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22511 [D loss: 0.588687, acc.: 64.06%] [G loss: 0.774070]\n",
      "epoch:24 step:22512 [D loss: 0.518395, acc.: 71.88%] [G loss: 0.742264]\n",
      "epoch:24 step:22513 [D loss: 0.460375, acc.: 78.12%] [G loss: 0.755084]\n",
      "epoch:24 step:22514 [D loss: 0.614522, acc.: 66.41%] [G loss: 0.660127]\n",
      "epoch:24 step:22515 [D loss: 0.461684, acc.: 73.44%] [G loss: 0.736179]\n",
      "epoch:24 step:22516 [D loss: 0.546098, acc.: 69.53%] [G loss: 0.740076]\n",
      "epoch:24 step:22517 [D loss: 0.508503, acc.: 76.56%] [G loss: 0.701313]\n",
      "epoch:24 step:22518 [D loss: 0.492132, acc.: 75.78%] [G loss: 0.685781]\n",
      "epoch:24 step:22519 [D loss: 0.605145, acc.: 67.97%] [G loss: 0.600034]\n",
      "epoch:24 step:22520 [D loss: 0.589109, acc.: 66.41%] [G loss: 0.587726]\n",
      "epoch:24 step:22521 [D loss: 0.495015, acc.: 76.56%] [G loss: 0.688526]\n",
      "epoch:24 step:22522 [D loss: 0.518202, acc.: 71.88%] [G loss: 0.633949]\n",
      "epoch:24 step:22523 [D loss: 0.576704, acc.: 64.06%] [G loss: 0.561755]\n",
      "epoch:24 step:22524 [D loss: 0.499678, acc.: 69.53%] [G loss: 0.681824]\n",
      "epoch:24 step:22525 [D loss: 0.475863, acc.: 73.44%] [G loss: 0.634705]\n",
      "epoch:24 step:22526 [D loss: 0.569889, acc.: 67.19%] [G loss: 0.618875]\n",
      "epoch:24 step:22527 [D loss: 0.523125, acc.: 75.00%] [G loss: 0.686438]\n",
      "epoch:24 step:22528 [D loss: 0.478315, acc.: 76.56%] [G loss: 0.736023]\n",
      "epoch:24 step:22529 [D loss: 0.499911, acc.: 72.66%] [G loss: 0.841629]\n",
      "epoch:24 step:22530 [D loss: 0.522615, acc.: 72.66%] [G loss: 0.713539]\n",
      "epoch:24 step:22531 [D loss: 0.552349, acc.: 67.97%] [G loss: 0.535986]\n",
      "epoch:24 step:22532 [D loss: 0.607803, acc.: 67.19%] [G loss: 0.624633]\n",
      "epoch:24 step:22533 [D loss: 0.513084, acc.: 73.44%] [G loss: 0.739510]\n",
      "epoch:24 step:22534 [D loss: 0.521859, acc.: 75.00%] [G loss: 0.749225]\n",
      "epoch:24 step:22535 [D loss: 0.529684, acc.: 70.31%] [G loss: 0.979825]\n",
      "epoch:24 step:22536 [D loss: 0.543328, acc.: 75.00%] [G loss: 0.973944]\n",
      "epoch:24 step:22537 [D loss: 0.466217, acc.: 76.56%] [G loss: 0.807940]\n",
      "epoch:24 step:22538 [D loss: 0.554886, acc.: 66.41%] [G loss: 0.679354]\n",
      "epoch:24 step:22539 [D loss: 0.645153, acc.: 61.72%] [G loss: 0.510969]\n",
      "epoch:24 step:22540 [D loss: 0.557904, acc.: 67.97%] [G loss: 0.756379]\n",
      "epoch:24 step:22541 [D loss: 0.473428, acc.: 78.12%] [G loss: 0.769397]\n",
      "epoch:24 step:22542 [D loss: 0.493217, acc.: 70.31%] [G loss: 0.805590]\n",
      "epoch:24 step:22543 [D loss: 0.532003, acc.: 72.66%] [G loss: 0.738021]\n",
      "epoch:24 step:22544 [D loss: 0.499495, acc.: 77.34%] [G loss: 0.788192]\n",
      "epoch:24 step:22545 [D loss: 0.544346, acc.: 71.88%] [G loss: 0.723679]\n",
      "epoch:24 step:22546 [D loss: 0.541829, acc.: 71.88%] [G loss: 0.703925]\n",
      "epoch:24 step:22547 [D loss: 0.520252, acc.: 72.66%] [G loss: 0.668376]\n",
      "epoch:24 step:22548 [D loss: 0.599274, acc.: 68.75%] [G loss: 0.897213]\n",
      "epoch:24 step:22549 [D loss: 0.532058, acc.: 73.44%] [G loss: 0.713817]\n",
      "epoch:24 step:22550 [D loss: 0.615494, acc.: 68.75%] [G loss: 0.747539]\n",
      "epoch:24 step:22551 [D loss: 0.546631, acc.: 66.41%] [G loss: 0.938704]\n",
      "epoch:24 step:22552 [D loss: 0.607051, acc.: 72.66%] [G loss: 0.649346]\n",
      "epoch:24 step:22553 [D loss: 0.528481, acc.: 71.88%] [G loss: 0.665608]\n",
      "epoch:24 step:22554 [D loss: 0.516135, acc.: 76.56%] [G loss: 0.655000]\n",
      "epoch:24 step:22555 [D loss: 0.580041, acc.: 62.50%] [G loss: 0.698525]\n",
      "epoch:24 step:22556 [D loss: 0.564579, acc.: 66.41%] [G loss: 0.747182]\n",
      "epoch:24 step:22557 [D loss: 0.473875, acc.: 78.91%] [G loss: 0.807923]\n",
      "epoch:24 step:22558 [D loss: 0.501113, acc.: 76.56%] [G loss: 0.743918]\n",
      "epoch:24 step:22559 [D loss: 0.494212, acc.: 74.22%] [G loss: 0.556244]\n",
      "epoch:24 step:22560 [D loss: 0.515899, acc.: 75.00%] [G loss: 0.638881]\n",
      "epoch:24 step:22561 [D loss: 0.598981, acc.: 67.19%] [G loss: 0.580974]\n",
      "epoch:24 step:22562 [D loss: 0.448116, acc.: 82.81%] [G loss: 0.660411]\n",
      "epoch:24 step:22563 [D loss: 0.511141, acc.: 70.31%] [G loss: 0.709920]\n",
      "epoch:24 step:22564 [D loss: 0.500332, acc.: 70.31%] [G loss: 0.735581]\n",
      "epoch:24 step:22565 [D loss: 0.423098, acc.: 81.25%] [G loss: 0.839902]\n",
      "epoch:24 step:22566 [D loss: 0.579126, acc.: 69.53%] [G loss: 0.900946]\n",
      "epoch:24 step:22567 [D loss: 0.537571, acc.: 75.78%] [G loss: 0.835772]\n",
      "epoch:24 step:22568 [D loss: 0.507459, acc.: 74.22%] [G loss: 0.956327]\n",
      "epoch:24 step:22569 [D loss: 0.507493, acc.: 77.34%] [G loss: 0.727451]\n",
      "epoch:24 step:22570 [D loss: 0.490615, acc.: 75.78%] [G loss: 0.822469]\n",
      "epoch:24 step:22571 [D loss: 0.488177, acc.: 72.66%] [G loss: 0.721340]\n",
      "epoch:24 step:22572 [D loss: 0.550620, acc.: 68.75%] [G loss: 0.630049]\n",
      "epoch:24 step:22573 [D loss: 0.581235, acc.: 67.97%] [G loss: 0.665218]\n",
      "epoch:24 step:22574 [D loss: 0.527088, acc.: 73.44%] [G loss: 0.729292]\n",
      "epoch:24 step:22575 [D loss: 0.579913, acc.: 65.62%] [G loss: 0.564964]\n",
      "epoch:24 step:22576 [D loss: 0.483580, acc.: 78.12%] [G loss: 0.694385]\n",
      "epoch:24 step:22577 [D loss: 0.537654, acc.: 71.09%] [G loss: 0.695552]\n",
      "epoch:24 step:22578 [D loss: 0.534366, acc.: 72.66%] [G loss: 0.694829]\n",
      "epoch:24 step:22579 [D loss: 0.542820, acc.: 71.88%] [G loss: 0.748117]\n",
      "epoch:24 step:22580 [D loss: 0.457209, acc.: 76.56%] [G loss: 0.694212]\n",
      "epoch:24 step:22581 [D loss: 0.501011, acc.: 73.44%] [G loss: 0.822479]\n",
      "epoch:24 step:22582 [D loss: 0.501579, acc.: 72.66%] [G loss: 0.713748]\n",
      "epoch:24 step:22583 [D loss: 0.561548, acc.: 68.75%] [G loss: 0.626652]\n",
      "epoch:24 step:22584 [D loss: 0.516212, acc.: 71.88%] [G loss: 0.630129]\n",
      "epoch:24 step:22585 [D loss: 0.496589, acc.: 75.78%] [G loss: 0.880461]\n",
      "epoch:24 step:22586 [D loss: 0.507569, acc.: 75.78%] [G loss: 0.755279]\n",
      "epoch:24 step:22587 [D loss: 0.529953, acc.: 77.34%] [G loss: 0.794195]\n",
      "epoch:24 step:22588 [D loss: 0.457749, acc.: 75.78%] [G loss: 0.974843]\n",
      "epoch:24 step:22589 [D loss: 0.489550, acc.: 81.25%] [G loss: 0.889743]\n",
      "epoch:24 step:22590 [D loss: 0.653150, acc.: 60.94%] [G loss: 0.670298]\n",
      "epoch:24 step:22591 [D loss: 0.522417, acc.: 71.09%] [G loss: 0.606579]\n",
      "epoch:24 step:22592 [D loss: 0.481115, acc.: 75.78%] [G loss: 0.666245]\n",
      "epoch:24 step:22593 [D loss: 0.523559, acc.: 68.75%] [G loss: 0.785119]\n",
      "epoch:24 step:22594 [D loss: 0.512281, acc.: 71.88%] [G loss: 0.548088]\n",
      "epoch:24 step:22595 [D loss: 0.524269, acc.: 69.53%] [G loss: 0.718047]\n",
      "epoch:24 step:22596 [D loss: 0.640268, acc.: 63.28%] [G loss: 0.722563]\n",
      "epoch:24 step:22597 [D loss: 0.585485, acc.: 62.50%] [G loss: 0.849963]\n",
      "epoch:24 step:22598 [D loss: 0.545710, acc.: 71.09%] [G loss: 0.704866]\n",
      "epoch:24 step:22599 [D loss: 0.511020, acc.: 68.75%] [G loss: 0.751751]\n",
      "epoch:24 step:22600 [D loss: 0.512414, acc.: 79.69%] [G loss: 0.648785]\n",
      "##############\n",
      "[3.01317459 0.88812643 5.96000747 5.03461778 3.82965487 5.73963955\n",
      " 4.52963216 4.83846316 4.48818135 4.22151634]\n",
      "##########\n",
      "epoch:24 step:22601 [D loss: 0.559129, acc.: 64.06%] [G loss: 0.648797]\n",
      "epoch:24 step:22602 [D loss: 0.502433, acc.: 78.12%] [G loss: 0.788835]\n",
      "epoch:24 step:22603 [D loss: 0.505165, acc.: 77.34%] [G loss: 0.844776]\n",
      "epoch:24 step:22604 [D loss: 0.522018, acc.: 69.53%] [G loss: 0.701572]\n",
      "epoch:24 step:22605 [D loss: 0.498967, acc.: 74.22%] [G loss: 0.801393]\n",
      "epoch:24 step:22606 [D loss: 0.518846, acc.: 73.44%] [G loss: 0.840693]\n",
      "epoch:24 step:22607 [D loss: 0.489641, acc.: 77.34%] [G loss: 1.049122]\n",
      "epoch:24 step:22608 [D loss: 0.525846, acc.: 75.00%] [G loss: 0.930240]\n",
      "epoch:24 step:22609 [D loss: 0.497247, acc.: 75.78%] [G loss: 0.744988]\n",
      "epoch:24 step:22610 [D loss: 0.443050, acc.: 82.81%] [G loss: 0.950875]\n",
      "epoch:24 step:22611 [D loss: 0.454874, acc.: 76.56%] [G loss: 0.855835]\n",
      "epoch:24 step:22612 [D loss: 0.546215, acc.: 72.66%] [G loss: 0.772613]\n",
      "epoch:24 step:22613 [D loss: 0.540059, acc.: 72.66%] [G loss: 0.568760]\n",
      "epoch:24 step:22614 [D loss: 0.479427, acc.: 74.22%] [G loss: 0.746191]\n",
      "epoch:24 step:22615 [D loss: 0.469015, acc.: 76.56%] [G loss: 0.672415]\n",
      "epoch:24 step:22616 [D loss: 0.574570, acc.: 68.75%] [G loss: 0.616987]\n",
      "epoch:24 step:22617 [D loss: 0.565437, acc.: 70.31%] [G loss: 0.737986]\n",
      "epoch:24 step:22618 [D loss: 0.524943, acc.: 72.66%] [G loss: 0.676689]\n",
      "epoch:24 step:22619 [D loss: 0.515923, acc.: 72.66%] [G loss: 0.661263]\n",
      "epoch:24 step:22620 [D loss: 0.521589, acc.: 72.66%] [G loss: 0.689194]\n",
      "epoch:24 step:22621 [D loss: 0.556417, acc.: 70.31%] [G loss: 0.714023]\n",
      "epoch:24 step:22622 [D loss: 0.568375, acc.: 65.62%] [G loss: 0.847685]\n",
      "epoch:24 step:22623 [D loss: 0.518032, acc.: 68.75%] [G loss: 0.895866]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22624 [D loss: 0.516266, acc.: 75.78%] [G loss: 0.734579]\n",
      "epoch:24 step:22625 [D loss: 0.578338, acc.: 66.41%] [G loss: 0.797301]\n",
      "epoch:24 step:22626 [D loss: 0.518181, acc.: 72.66%] [G loss: 0.557114]\n",
      "epoch:24 step:22627 [D loss: 0.550946, acc.: 73.44%] [G loss: 0.745426]\n",
      "epoch:24 step:22628 [D loss: 0.519370, acc.: 72.66%] [G loss: 0.762894]\n",
      "epoch:24 step:22629 [D loss: 0.531481, acc.: 73.44%] [G loss: 0.734882]\n",
      "epoch:24 step:22630 [D loss: 0.588063, acc.: 64.06%] [G loss: 0.611781]\n",
      "epoch:24 step:22631 [D loss: 0.559154, acc.: 68.75%] [G loss: 0.730136]\n",
      "epoch:24 step:22632 [D loss: 0.460459, acc.: 79.69%] [G loss: 0.685505]\n",
      "epoch:24 step:22633 [D loss: 0.544273, acc.: 69.53%] [G loss: 0.811034]\n",
      "epoch:24 step:22634 [D loss: 0.444830, acc.: 79.69%] [G loss: 0.821915]\n",
      "epoch:24 step:22635 [D loss: 0.600715, acc.: 64.84%] [G loss: 0.635890]\n",
      "epoch:24 step:22636 [D loss: 0.580181, acc.: 63.28%] [G loss: 0.631517]\n",
      "epoch:24 step:22637 [D loss: 0.482856, acc.: 73.44%] [G loss: 0.634677]\n",
      "epoch:24 step:22638 [D loss: 0.582581, acc.: 67.97%] [G loss: 0.769324]\n",
      "epoch:24 step:22639 [D loss: 0.544216, acc.: 69.53%] [G loss: 0.509921]\n",
      "epoch:24 step:22640 [D loss: 0.438021, acc.: 80.47%] [G loss: 0.757706]\n",
      "epoch:24 step:22641 [D loss: 0.559285, acc.: 66.41%] [G loss: 0.813617]\n",
      "epoch:24 step:22642 [D loss: 0.553112, acc.: 67.97%] [G loss: 0.611578]\n",
      "epoch:24 step:22643 [D loss: 0.473847, acc.: 75.00%] [G loss: 0.760306]\n",
      "epoch:24 step:22644 [D loss: 0.479450, acc.: 80.47%] [G loss: 0.944666]\n",
      "epoch:24 step:22645 [D loss: 0.540775, acc.: 70.31%] [G loss: 0.772675]\n",
      "epoch:24 step:22646 [D loss: 0.565389, acc.: 67.19%] [G loss: 0.597002]\n",
      "epoch:24 step:22647 [D loss: 0.474060, acc.: 72.66%] [G loss: 0.746038]\n",
      "epoch:24 step:22648 [D loss: 0.628490, acc.: 64.84%] [G loss: 0.753415]\n",
      "epoch:24 step:22649 [D loss: 0.521484, acc.: 75.00%] [G loss: 0.802241]\n",
      "epoch:24 step:22650 [D loss: 0.497947, acc.: 75.00%] [G loss: 0.834546]\n",
      "epoch:24 step:22651 [D loss: 0.544597, acc.: 72.66%] [G loss: 0.703314]\n",
      "epoch:24 step:22652 [D loss: 0.505680, acc.: 72.66%] [G loss: 0.942004]\n",
      "epoch:24 step:22653 [D loss: 0.519766, acc.: 68.75%] [G loss: 0.704011]\n",
      "epoch:24 step:22654 [D loss: 0.550576, acc.: 66.41%] [G loss: 0.568440]\n",
      "epoch:24 step:22655 [D loss: 0.521029, acc.: 71.88%] [G loss: 0.576071]\n",
      "epoch:24 step:22656 [D loss: 0.536150, acc.: 71.09%] [G loss: 0.452423]\n",
      "epoch:24 step:22657 [D loss: 0.575866, acc.: 65.62%] [G loss: 0.459962]\n",
      "epoch:24 step:22658 [D loss: 0.553824, acc.: 71.09%] [G loss: 0.546884]\n",
      "epoch:24 step:22659 [D loss: 0.553158, acc.: 71.09%] [G loss: 0.761283]\n",
      "epoch:24 step:22660 [D loss: 0.535611, acc.: 71.09%] [G loss: 0.664331]\n",
      "epoch:24 step:22661 [D loss: 0.475546, acc.: 75.78%] [G loss: 0.726046]\n",
      "epoch:24 step:22662 [D loss: 0.536385, acc.: 71.88%] [G loss: 0.775435]\n",
      "epoch:24 step:22663 [D loss: 0.564164, acc.: 68.75%] [G loss: 0.671693]\n",
      "epoch:24 step:22664 [D loss: 0.507075, acc.: 75.00%] [G loss: 0.607535]\n",
      "epoch:24 step:22665 [D loss: 0.486024, acc.: 73.44%] [G loss: 0.667458]\n",
      "epoch:24 step:22666 [D loss: 0.557225, acc.: 68.75%] [G loss: 0.578457]\n",
      "epoch:24 step:22667 [D loss: 0.522061, acc.: 69.53%] [G loss: 0.720173]\n",
      "epoch:24 step:22668 [D loss: 0.604957, acc.: 64.06%] [G loss: 0.506430]\n",
      "epoch:24 step:22669 [D loss: 0.607153, acc.: 65.62%] [G loss: 0.572685]\n",
      "epoch:24 step:22670 [D loss: 0.559022, acc.: 74.22%] [G loss: 0.660409]\n",
      "epoch:24 step:22671 [D loss: 0.625371, acc.: 63.28%] [G loss: 0.786341]\n",
      "epoch:24 step:22672 [D loss: 0.510660, acc.: 72.66%] [G loss: 0.788940]\n",
      "epoch:24 step:22673 [D loss: 0.605274, acc.: 66.41%] [G loss: 0.649346]\n",
      "epoch:24 step:22674 [D loss: 0.539126, acc.: 73.44%] [G loss: 0.672854]\n",
      "epoch:24 step:22675 [D loss: 0.554873, acc.: 67.97%] [G loss: 0.683044]\n",
      "epoch:24 step:22676 [D loss: 0.572634, acc.: 61.72%] [G loss: 0.448938]\n",
      "epoch:24 step:22677 [D loss: 0.556556, acc.: 70.31%] [G loss: 0.681501]\n",
      "epoch:24 step:22678 [D loss: 0.501328, acc.: 78.12%] [G loss: 0.661348]\n",
      "epoch:24 step:22679 [D loss: 0.471536, acc.: 79.69%] [G loss: 0.623505]\n",
      "epoch:24 step:22680 [D loss: 0.528312, acc.: 74.22%] [G loss: 0.593908]\n",
      "epoch:24 step:22681 [D loss: 0.548879, acc.: 70.31%] [G loss: 0.655647]\n",
      "epoch:24 step:22682 [D loss: 0.431792, acc.: 82.03%] [G loss: 0.743170]\n",
      "epoch:24 step:22683 [D loss: 0.530603, acc.: 75.00%] [G loss: 0.615418]\n",
      "epoch:24 step:22684 [D loss: 0.519292, acc.: 73.44%] [G loss: 0.701106]\n",
      "epoch:24 step:22685 [D loss: 0.473473, acc.: 78.12%] [G loss: 0.686688]\n",
      "epoch:24 step:22686 [D loss: 0.467738, acc.: 75.78%] [G loss: 0.781126]\n",
      "epoch:24 step:22687 [D loss: 0.521021, acc.: 76.56%] [G loss: 0.966989]\n",
      "epoch:24 step:22688 [D loss: 0.661032, acc.: 60.16%] [G loss: 0.590025]\n",
      "epoch:24 step:22689 [D loss: 0.516355, acc.: 73.44%] [G loss: 0.660290]\n",
      "epoch:24 step:22690 [D loss: 0.547809, acc.: 74.22%] [G loss: 0.655685]\n",
      "epoch:24 step:22691 [D loss: 0.667853, acc.: 61.72%] [G loss: 0.621733]\n",
      "epoch:24 step:22692 [D loss: 0.561677, acc.: 73.44%] [G loss: 0.530845]\n",
      "epoch:24 step:22693 [D loss: 0.580437, acc.: 70.31%] [G loss: 0.850867]\n",
      "epoch:24 step:22694 [D loss: 0.434283, acc.: 80.47%] [G loss: 0.787076]\n",
      "epoch:24 step:22695 [D loss: 0.442401, acc.: 77.34%] [G loss: 0.831912]\n",
      "epoch:24 step:22696 [D loss: 0.424363, acc.: 82.03%] [G loss: 0.793956]\n",
      "epoch:24 step:22697 [D loss: 0.508144, acc.: 75.00%] [G loss: 0.866503]\n",
      "epoch:24 step:22698 [D loss: 0.632417, acc.: 63.28%] [G loss: 0.706988]\n",
      "epoch:24 step:22699 [D loss: 0.630796, acc.: 61.72%] [G loss: 0.645075]\n",
      "epoch:24 step:22700 [D loss: 0.549904, acc.: 69.53%] [G loss: 0.741070]\n",
      "epoch:24 step:22701 [D loss: 0.528934, acc.: 73.44%] [G loss: 0.729224]\n",
      "epoch:24 step:22702 [D loss: 0.675623, acc.: 60.16%] [G loss: 0.646627]\n",
      "epoch:24 step:22703 [D loss: 0.603297, acc.: 64.84%] [G loss: 0.546993]\n",
      "epoch:24 step:22704 [D loss: 0.506320, acc.: 68.75%] [G loss: 0.744483]\n",
      "epoch:24 step:22705 [D loss: 0.510618, acc.: 73.44%] [G loss: 0.742672]\n",
      "epoch:24 step:22706 [D loss: 0.450999, acc.: 82.81%] [G loss: 0.765250]\n",
      "epoch:24 step:22707 [D loss: 0.461511, acc.: 77.34%] [G loss: 0.739321]\n",
      "epoch:24 step:22708 [D loss: 0.636199, acc.: 64.06%] [G loss: 0.784780]\n",
      "epoch:24 step:22709 [D loss: 0.537923, acc.: 67.97%] [G loss: 0.711151]\n",
      "epoch:24 step:22710 [D loss: 0.542213, acc.: 71.09%] [G loss: 0.706442]\n",
      "epoch:24 step:22711 [D loss: 0.530455, acc.: 72.66%] [G loss: 0.780300]\n",
      "epoch:24 step:22712 [D loss: 0.540551, acc.: 67.97%] [G loss: 0.752865]\n",
      "epoch:24 step:22713 [D loss: 0.535276, acc.: 74.22%] [G loss: 0.710606]\n",
      "epoch:24 step:22714 [D loss: 0.574178, acc.: 67.19%] [G loss: 0.803991]\n",
      "epoch:24 step:22715 [D loss: 0.577853, acc.: 64.84%] [G loss: 0.654853]\n",
      "epoch:24 step:22716 [D loss: 0.550542, acc.: 72.66%] [G loss: 0.690783]\n",
      "epoch:24 step:22717 [D loss: 0.515934, acc.: 74.22%] [G loss: 0.605624]\n",
      "epoch:24 step:22718 [D loss: 0.477636, acc.: 78.91%] [G loss: 0.887281]\n",
      "epoch:24 step:22719 [D loss: 0.465441, acc.: 77.34%] [G loss: 0.853580]\n",
      "epoch:24 step:22720 [D loss: 0.475483, acc.: 77.34%] [G loss: 1.079607]\n",
      "epoch:24 step:22721 [D loss: 0.584458, acc.: 64.06%] [G loss: 0.834858]\n",
      "epoch:24 step:22722 [D loss: 0.538538, acc.: 73.44%] [G loss: 0.793866]\n",
      "epoch:24 step:22723 [D loss: 0.529042, acc.: 69.53%] [G loss: 0.905995]\n",
      "epoch:24 step:22724 [D loss: 0.465738, acc.: 75.00%] [G loss: 0.865463]\n",
      "epoch:24 step:22725 [D loss: 0.525799, acc.: 74.22%] [G loss: 0.633130]\n",
      "epoch:24 step:22726 [D loss: 0.579940, acc.: 67.19%] [G loss: 0.649865]\n",
      "epoch:24 step:22727 [D loss: 0.536013, acc.: 71.09%] [G loss: 0.562513]\n",
      "epoch:24 step:22728 [D loss: 0.548484, acc.: 72.66%] [G loss: 0.604648]\n",
      "epoch:24 step:22729 [D loss: 0.504243, acc.: 76.56%] [G loss: 0.565896]\n",
      "epoch:24 step:22730 [D loss: 0.504354, acc.: 71.88%] [G loss: 0.808792]\n",
      "epoch:24 step:22731 [D loss: 0.499077, acc.: 73.44%] [G loss: 0.705032]\n",
      "epoch:24 step:22732 [D loss: 0.433915, acc.: 85.16%] [G loss: 0.792708]\n",
      "epoch:24 step:22733 [D loss: 0.579085, acc.: 68.75%] [G loss: 0.653273]\n",
      "epoch:24 step:22734 [D loss: 0.502378, acc.: 76.56%] [G loss: 0.728222]\n",
      "epoch:24 step:22735 [D loss: 0.499359, acc.: 80.47%] [G loss: 0.708044]\n",
      "epoch:24 step:22736 [D loss: 0.536411, acc.: 71.88%] [G loss: 0.893041]\n",
      "epoch:24 step:22737 [D loss: 0.607669, acc.: 68.75%] [G loss: 0.755177]\n",
      "epoch:24 step:22738 [D loss: 0.584069, acc.: 67.97%] [G loss: 0.811086]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22739 [D loss: 0.703958, acc.: 63.28%] [G loss: 0.910503]\n",
      "epoch:24 step:22740 [D loss: 0.510121, acc.: 75.00%] [G loss: 0.635426]\n",
      "epoch:24 step:22741 [D loss: 0.615809, acc.: 64.84%] [G loss: 0.630282]\n",
      "epoch:24 step:22742 [D loss: 0.522893, acc.: 70.31%] [G loss: 0.603757]\n",
      "epoch:24 step:22743 [D loss: 0.539361, acc.: 68.75%] [G loss: 0.658565]\n",
      "epoch:24 step:22744 [D loss: 0.561223, acc.: 68.75%] [G loss: 0.682789]\n",
      "epoch:24 step:22745 [D loss: 0.577900, acc.: 65.62%] [G loss: 0.539952]\n",
      "epoch:24 step:22746 [D loss: 0.517178, acc.: 68.75%] [G loss: 0.725246]\n",
      "epoch:24 step:22747 [D loss: 0.529661, acc.: 72.66%] [G loss: 0.619667]\n",
      "epoch:24 step:22748 [D loss: 0.618547, acc.: 59.38%] [G loss: 0.596844]\n",
      "epoch:24 step:22749 [D loss: 0.524789, acc.: 69.53%] [G loss: 0.597037]\n",
      "epoch:24 step:22750 [D loss: 0.499754, acc.: 75.78%] [G loss: 0.768408]\n",
      "epoch:24 step:22751 [D loss: 0.591584, acc.: 67.97%] [G loss: 0.506517]\n",
      "epoch:24 step:22752 [D loss: 0.559858, acc.: 71.09%] [G loss: 0.561264]\n",
      "epoch:24 step:22753 [D loss: 0.492050, acc.: 73.44%] [G loss: 0.647665]\n",
      "epoch:24 step:22754 [D loss: 0.580172, acc.: 71.09%] [G loss: 0.633765]\n",
      "epoch:24 step:22755 [D loss: 0.522495, acc.: 70.31%] [G loss: 0.646548]\n",
      "epoch:24 step:22756 [D loss: 0.517290, acc.: 72.66%] [G loss: 0.647812]\n",
      "epoch:24 step:22757 [D loss: 0.488697, acc.: 75.00%] [G loss: 0.670250]\n",
      "epoch:24 step:22758 [D loss: 0.481470, acc.: 78.12%] [G loss: 0.797372]\n",
      "epoch:24 step:22759 [D loss: 0.555632, acc.: 71.09%] [G loss: 0.717676]\n",
      "epoch:24 step:22760 [D loss: 0.570768, acc.: 64.06%] [G loss: 0.661799]\n",
      "epoch:24 step:22761 [D loss: 0.460269, acc.: 78.12%] [G loss: 0.812423]\n",
      "epoch:24 step:22762 [D loss: 0.517267, acc.: 72.66%] [G loss: 0.614892]\n",
      "epoch:24 step:22763 [D loss: 0.554627, acc.: 68.75%] [G loss: 0.579936]\n",
      "epoch:24 step:22764 [D loss: 0.453507, acc.: 81.25%] [G loss: 0.782946]\n",
      "epoch:24 step:22765 [D loss: 0.593155, acc.: 70.31%] [G loss: 0.464771]\n",
      "epoch:24 step:22766 [D loss: 0.665226, acc.: 60.16%] [G loss: 0.587076]\n",
      "epoch:24 step:22767 [D loss: 0.512201, acc.: 73.44%] [G loss: 0.636278]\n",
      "epoch:24 step:22768 [D loss: 0.524125, acc.: 71.88%] [G loss: 0.788369]\n",
      "epoch:24 step:22769 [D loss: 0.573796, acc.: 68.75%] [G loss: 0.599909]\n",
      "epoch:24 step:22770 [D loss: 0.583699, acc.: 66.41%] [G loss: 0.480743]\n",
      "epoch:24 step:22771 [D loss: 0.490082, acc.: 73.44%] [G loss: 0.589947]\n",
      "epoch:24 step:22772 [D loss: 0.528219, acc.: 71.09%] [G loss: 0.652877]\n",
      "epoch:24 step:22773 [D loss: 0.506184, acc.: 71.88%] [G loss: 0.565287]\n",
      "epoch:24 step:22774 [D loss: 0.492391, acc.: 68.75%] [G loss: 0.655504]\n",
      "epoch:24 step:22775 [D loss: 0.557586, acc.: 65.62%] [G loss: 0.622993]\n",
      "epoch:24 step:22776 [D loss: 0.549406, acc.: 68.75%] [G loss: 0.591550]\n",
      "epoch:24 step:22777 [D loss: 0.486543, acc.: 74.22%] [G loss: 0.723540]\n",
      "epoch:24 step:22778 [D loss: 0.595949, acc.: 65.62%] [G loss: 0.746921]\n",
      "epoch:24 step:22779 [D loss: 0.547370, acc.: 67.97%] [G loss: 0.590056]\n",
      "epoch:24 step:22780 [D loss: 0.544980, acc.: 71.09%] [G loss: 0.599370]\n",
      "epoch:24 step:22781 [D loss: 0.554234, acc.: 69.53%] [G loss: 0.611181]\n",
      "epoch:24 step:22782 [D loss: 0.666206, acc.: 58.59%] [G loss: 0.480638]\n",
      "epoch:24 step:22783 [D loss: 0.545361, acc.: 67.19%] [G loss: 0.697559]\n",
      "epoch:24 step:22784 [D loss: 0.445276, acc.: 78.91%] [G loss: 0.671722]\n",
      "epoch:24 step:22785 [D loss: 0.546445, acc.: 71.88%] [G loss: 0.723143]\n",
      "epoch:24 step:22786 [D loss: 0.530419, acc.: 77.34%] [G loss: 0.696796]\n",
      "epoch:24 step:22787 [D loss: 0.483389, acc.: 72.66%] [G loss: 0.679377]\n",
      "epoch:24 step:22788 [D loss: 0.556315, acc.: 67.97%] [G loss: 0.679213]\n",
      "epoch:24 step:22789 [D loss: 0.602684, acc.: 68.75%] [G loss: 0.638484]\n",
      "epoch:24 step:22790 [D loss: 0.517249, acc.: 71.09%] [G loss: 0.603127]\n",
      "epoch:24 step:22791 [D loss: 0.524163, acc.: 72.66%] [G loss: 0.576637]\n",
      "epoch:24 step:22792 [D loss: 0.502257, acc.: 74.22%] [G loss: 0.781812]\n",
      "epoch:24 step:22793 [D loss: 0.518698, acc.: 74.22%] [G loss: 0.774261]\n",
      "epoch:24 step:22794 [D loss: 0.512514, acc.: 69.53%] [G loss: 0.779454]\n",
      "epoch:24 step:22795 [D loss: 0.516034, acc.: 75.00%] [G loss: 0.803129]\n",
      "epoch:24 step:22796 [D loss: 0.589331, acc.: 68.75%] [G loss: 0.808617]\n",
      "epoch:24 step:22797 [D loss: 0.470935, acc.: 75.00%] [G loss: 0.643962]\n",
      "epoch:24 step:22798 [D loss: 0.567665, acc.: 67.97%] [G loss: 0.883436]\n",
      "epoch:24 step:22799 [D loss: 0.469694, acc.: 77.34%] [G loss: 0.709617]\n",
      "epoch:24 step:22800 [D loss: 0.421862, acc.: 85.16%] [G loss: 1.021227]\n",
      "##############\n",
      "[2.90746285 1.0344833  6.0699758  4.69602034 3.73512211 5.83751882\n",
      " 4.33492326 4.64713044 4.61807416 3.96285241]\n",
      "##########\n",
      "epoch:24 step:22801 [D loss: 0.510120, acc.: 75.00%] [G loss: 1.018690]\n",
      "epoch:24 step:22802 [D loss: 0.426421, acc.: 80.47%] [G loss: 0.959351]\n",
      "epoch:24 step:22803 [D loss: 0.416361, acc.: 83.59%] [G loss: 0.987878]\n",
      "epoch:24 step:22804 [D loss: 0.720397, acc.: 59.38%] [G loss: 0.693208]\n",
      "epoch:24 step:22805 [D loss: 0.543769, acc.: 72.66%] [G loss: 0.546563]\n",
      "epoch:24 step:22806 [D loss: 0.571907, acc.: 68.75%] [G loss: 0.698744]\n",
      "epoch:24 step:22807 [D loss: 0.535503, acc.: 75.00%] [G loss: 0.667701]\n",
      "epoch:24 step:22808 [D loss: 0.516937, acc.: 75.00%] [G loss: 0.690506]\n",
      "epoch:24 step:22809 [D loss: 0.536293, acc.: 71.88%] [G loss: 0.704606]\n",
      "epoch:24 step:22810 [D loss: 0.575274, acc.: 68.75%] [G loss: 0.762549]\n",
      "epoch:24 step:22811 [D loss: 0.590192, acc.: 70.31%] [G loss: 0.572358]\n",
      "epoch:24 step:22812 [D loss: 0.520654, acc.: 74.22%] [G loss: 0.696627]\n",
      "epoch:24 step:22813 [D loss: 0.543769, acc.: 69.53%] [G loss: 0.677834]\n",
      "epoch:24 step:22814 [D loss: 0.468029, acc.: 78.12%] [G loss: 0.679480]\n",
      "epoch:24 step:22815 [D loss: 0.543203, acc.: 69.53%] [G loss: 0.617126]\n",
      "epoch:24 step:22816 [D loss: 0.442140, acc.: 77.34%] [G loss: 0.849445]\n",
      "epoch:24 step:22817 [D loss: 0.457828, acc.: 75.00%] [G loss: 0.910175]\n",
      "epoch:24 step:22818 [D loss: 0.619918, acc.: 63.28%] [G loss: 0.560079]\n",
      "epoch:24 step:22819 [D loss: 0.578557, acc.: 70.31%] [G loss: 0.490360]\n",
      "epoch:24 step:22820 [D loss: 0.490782, acc.: 75.00%] [G loss: 0.611464]\n",
      "epoch:24 step:22821 [D loss: 0.444193, acc.: 78.91%] [G loss: 0.771051]\n",
      "epoch:24 step:22822 [D loss: 0.499822, acc.: 73.44%] [G loss: 0.743684]\n",
      "epoch:24 step:22823 [D loss: 0.497869, acc.: 76.56%] [G loss: 0.791425]\n",
      "epoch:24 step:22824 [D loss: 0.485919, acc.: 76.56%] [G loss: 0.781606]\n",
      "epoch:24 step:22825 [D loss: 0.464572, acc.: 77.34%] [G loss: 0.849883]\n",
      "epoch:24 step:22826 [D loss: 0.557964, acc.: 67.97%] [G loss: 0.758542]\n",
      "epoch:24 step:22827 [D loss: 0.551679, acc.: 64.84%] [G loss: 0.540119]\n",
      "epoch:24 step:22828 [D loss: 0.509924, acc.: 78.12%] [G loss: 0.803243]\n",
      "epoch:24 step:22829 [D loss: 0.608221, acc.: 65.62%] [G loss: 0.774096]\n",
      "epoch:24 step:22830 [D loss: 0.656620, acc.: 60.94%] [G loss: 0.726331]\n",
      "epoch:24 step:22831 [D loss: 0.524842, acc.: 72.66%] [G loss: 0.740948]\n",
      "epoch:24 step:22832 [D loss: 0.461384, acc.: 77.34%] [G loss: 1.136166]\n",
      "epoch:24 step:22833 [D loss: 0.647280, acc.: 60.16%] [G loss: 0.743853]\n",
      "epoch:24 step:22834 [D loss: 0.550945, acc.: 71.09%] [G loss: 0.718708]\n",
      "epoch:24 step:22835 [D loss: 0.459462, acc.: 80.47%] [G loss: 0.891149]\n",
      "epoch:24 step:22836 [D loss: 0.687574, acc.: 57.03%] [G loss: 0.688543]\n",
      "epoch:24 step:22837 [D loss: 0.711580, acc.: 57.81%] [G loss: 0.619436]\n",
      "epoch:24 step:22838 [D loss: 0.460817, acc.: 82.03%] [G loss: 0.515107]\n",
      "epoch:24 step:22839 [D loss: 0.481466, acc.: 77.34%] [G loss: 0.689324]\n",
      "epoch:24 step:22840 [D loss: 0.589608, acc.: 69.53%] [G loss: 0.660881]\n",
      "epoch:24 step:22841 [D loss: 0.556394, acc.: 68.75%] [G loss: 0.771949]\n",
      "epoch:24 step:22842 [D loss: 0.414495, acc.: 82.81%] [G loss: 0.804682]\n",
      "epoch:24 step:22843 [D loss: 0.509046, acc.: 73.44%] [G loss: 0.715443]\n",
      "epoch:24 step:22844 [D loss: 0.539809, acc.: 70.31%] [G loss: 0.743205]\n",
      "epoch:24 step:22845 [D loss: 0.447809, acc.: 78.91%] [G loss: 0.731330]\n",
      "epoch:24 step:22846 [D loss: 0.457268, acc.: 78.91%] [G loss: 0.728188]\n",
      "epoch:24 step:22847 [D loss: 0.479255, acc.: 75.00%] [G loss: 0.844656]\n",
      "epoch:24 step:22848 [D loss: 0.491058, acc.: 71.88%] [G loss: 0.729772]\n",
      "epoch:24 step:22849 [D loss: 0.534388, acc.: 74.22%] [G loss: 0.728765]\n",
      "epoch:24 step:22850 [D loss: 0.485662, acc.: 77.34%] [G loss: 0.879427]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22851 [D loss: 0.560905, acc.: 69.53%] [G loss: 0.862592]\n",
      "epoch:24 step:22852 [D loss: 0.505518, acc.: 70.31%] [G loss: 0.845927]\n",
      "epoch:24 step:22853 [D loss: 0.557389, acc.: 67.97%] [G loss: 0.681997]\n",
      "epoch:24 step:22854 [D loss: 0.514237, acc.: 77.34%] [G loss: 0.649610]\n",
      "epoch:24 step:22855 [D loss: 0.628207, acc.: 67.97%] [G loss: 0.620267]\n",
      "epoch:24 step:22856 [D loss: 0.545685, acc.: 66.41%] [G loss: 0.668700]\n",
      "epoch:24 step:22857 [D loss: 0.545960, acc.: 73.44%] [G loss: 0.775224]\n",
      "epoch:24 step:22858 [D loss: 0.550266, acc.: 71.09%] [G loss: 0.702996]\n",
      "epoch:24 step:22859 [D loss: 0.515888, acc.: 74.22%] [G loss: 0.669640]\n",
      "epoch:24 step:22860 [D loss: 0.559950, acc.: 69.53%] [G loss: 0.692115]\n",
      "epoch:24 step:22861 [D loss: 0.553020, acc.: 68.75%] [G loss: 0.602998]\n",
      "epoch:24 step:22862 [D loss: 0.460597, acc.: 78.91%] [G loss: 0.704170]\n",
      "epoch:24 step:22863 [D loss: 0.544869, acc.: 71.88%] [G loss: 0.743864]\n",
      "epoch:24 step:22864 [D loss: 0.631186, acc.: 64.84%] [G loss: 0.646442]\n",
      "epoch:24 step:22865 [D loss: 0.555709, acc.: 69.53%] [G loss: 0.482709]\n",
      "epoch:24 step:22866 [D loss: 0.528695, acc.: 71.88%] [G loss: 0.750122]\n",
      "epoch:24 step:22867 [D loss: 0.544892, acc.: 72.66%] [G loss: 0.719423]\n",
      "epoch:24 step:22868 [D loss: 0.589453, acc.: 63.28%] [G loss: 0.607974]\n",
      "epoch:24 step:22869 [D loss: 0.451805, acc.: 78.12%] [G loss: 0.746737]\n",
      "epoch:24 step:22870 [D loss: 0.497898, acc.: 77.34%] [G loss: 0.772910]\n",
      "epoch:24 step:22871 [D loss: 0.515207, acc.: 71.88%] [G loss: 0.577254]\n",
      "epoch:24 step:22872 [D loss: 0.540408, acc.: 74.22%] [G loss: 0.607294]\n",
      "epoch:24 step:22873 [D loss: 0.471791, acc.: 72.66%] [G loss: 0.814859]\n",
      "epoch:24 step:22874 [D loss: 0.675058, acc.: 60.94%] [G loss: 0.538319]\n",
      "epoch:24 step:22875 [D loss: 0.570398, acc.: 66.41%] [G loss: 0.586271]\n",
      "epoch:24 step:22876 [D loss: 0.511817, acc.: 70.31%] [G loss: 0.732044]\n",
      "epoch:24 step:22877 [D loss: 0.551742, acc.: 66.41%] [G loss: 0.620575]\n",
      "epoch:24 step:22878 [D loss: 0.550918, acc.: 69.53%] [G loss: 0.755613]\n",
      "epoch:24 step:22879 [D loss: 0.517269, acc.: 70.31%] [G loss: 0.641530]\n",
      "epoch:24 step:22880 [D loss: 0.491722, acc.: 70.31%] [G loss: 0.661564]\n",
      "epoch:24 step:22881 [D loss: 0.604518, acc.: 61.72%] [G loss: 0.652593]\n",
      "epoch:24 step:22882 [D loss: 0.586074, acc.: 71.09%] [G loss: 0.549677]\n",
      "epoch:24 step:22883 [D loss: 0.533553, acc.: 73.44%] [G loss: 0.580783]\n",
      "epoch:24 step:22884 [D loss: 0.530545, acc.: 71.88%] [G loss: 0.752929]\n",
      "epoch:24 step:22885 [D loss: 0.538378, acc.: 67.19%] [G loss: 0.779218]\n",
      "epoch:24 step:22886 [D loss: 0.481063, acc.: 76.56%] [G loss: 0.792508]\n",
      "epoch:24 step:22887 [D loss: 0.510305, acc.: 75.00%] [G loss: 0.902722]\n",
      "epoch:24 step:22888 [D loss: 0.629337, acc.: 57.81%] [G loss: 0.634357]\n",
      "epoch:24 step:22889 [D loss: 0.630616, acc.: 64.06%] [G loss: 0.550665]\n",
      "epoch:24 step:22890 [D loss: 0.482254, acc.: 75.00%] [G loss: 0.626389]\n",
      "epoch:24 step:22891 [D loss: 0.489631, acc.: 71.88%] [G loss: 0.701015]\n",
      "epoch:24 step:22892 [D loss: 0.627135, acc.: 60.16%] [G loss: 0.636816]\n",
      "epoch:24 step:22893 [D loss: 0.543225, acc.: 69.53%] [G loss: 0.758743]\n",
      "epoch:24 step:22894 [D loss: 0.536635, acc.: 69.53%] [G loss: 0.746316]\n",
      "epoch:24 step:22895 [D loss: 0.598580, acc.: 64.84%] [G loss: 0.702165]\n",
      "epoch:24 step:22896 [D loss: 0.552705, acc.: 73.44%] [G loss: 0.778976]\n",
      "epoch:24 step:22897 [D loss: 0.536774, acc.: 67.19%] [G loss: 0.778974]\n",
      "epoch:24 step:22898 [D loss: 0.525828, acc.: 70.31%] [G loss: 0.737896]\n",
      "epoch:24 step:22899 [D loss: 0.612051, acc.: 64.06%] [G loss: 0.576601]\n",
      "epoch:24 step:22900 [D loss: 0.651162, acc.: 62.50%] [G loss: 0.587975]\n",
      "epoch:24 step:22901 [D loss: 0.515225, acc.: 72.66%] [G loss: 0.610062]\n",
      "epoch:24 step:22902 [D loss: 0.479031, acc.: 75.00%] [G loss: 0.822864]\n",
      "epoch:24 step:22903 [D loss: 0.567103, acc.: 63.28%] [G loss: 0.556814]\n",
      "epoch:24 step:22904 [D loss: 0.466094, acc.: 79.69%] [G loss: 0.844297]\n",
      "epoch:24 step:22905 [D loss: 0.525868, acc.: 71.88%] [G loss: 0.702981]\n",
      "epoch:24 step:22906 [D loss: 0.582461, acc.: 73.44%] [G loss: 0.626324]\n",
      "epoch:24 step:22907 [D loss: 0.537449, acc.: 67.97%] [G loss: 0.616336]\n",
      "epoch:24 step:22908 [D loss: 0.589262, acc.: 64.06%] [G loss: 0.722870]\n",
      "epoch:24 step:22909 [D loss: 0.572452, acc.: 67.97%] [G loss: 0.630642]\n",
      "epoch:24 step:22910 [D loss: 0.630167, acc.: 60.94%] [G loss: 0.507891]\n",
      "epoch:24 step:22911 [D loss: 0.523986, acc.: 70.31%] [G loss: 0.579909]\n",
      "epoch:24 step:22912 [D loss: 0.571588, acc.: 71.88%] [G loss: 0.566278]\n",
      "epoch:24 step:22913 [D loss: 0.532434, acc.: 71.88%] [G loss: 0.455787]\n",
      "epoch:24 step:22914 [D loss: 0.453563, acc.: 75.78%] [G loss: 0.731351]\n",
      "epoch:24 step:22915 [D loss: 0.435796, acc.: 77.34%] [G loss: 0.780618]\n",
      "epoch:24 step:22916 [D loss: 0.502318, acc.: 73.44%] [G loss: 0.806644]\n",
      "epoch:24 step:22917 [D loss: 0.464809, acc.: 75.00%] [G loss: 0.886980]\n",
      "epoch:24 step:22918 [D loss: 0.495315, acc.: 76.56%] [G loss: 0.990215]\n",
      "epoch:24 step:22919 [D loss: 0.527643, acc.: 66.41%] [G loss: 0.981904]\n",
      "epoch:24 step:22920 [D loss: 0.600984, acc.: 65.62%] [G loss: 0.749514]\n",
      "epoch:24 step:22921 [D loss: 0.506748, acc.: 74.22%] [G loss: 0.677443]\n",
      "epoch:24 step:22922 [D loss: 0.534868, acc.: 75.00%] [G loss: 0.642094]\n",
      "epoch:24 step:22923 [D loss: 0.517826, acc.: 75.00%] [G loss: 0.797469]\n",
      "epoch:24 step:22924 [D loss: 0.498003, acc.: 74.22%] [G loss: 0.811018]\n",
      "epoch:24 step:22925 [D loss: 0.635812, acc.: 63.28%] [G loss: 0.630444]\n",
      "epoch:24 step:22926 [D loss: 0.556450, acc.: 67.19%] [G loss: 0.633509]\n",
      "epoch:24 step:22927 [D loss: 0.484308, acc.: 74.22%] [G loss: 0.733293]\n",
      "epoch:24 step:22928 [D loss: 0.489140, acc.: 75.78%] [G loss: 0.651228]\n",
      "epoch:24 step:22929 [D loss: 0.520366, acc.: 72.66%] [G loss: 0.650286]\n",
      "epoch:24 step:22930 [D loss: 0.563087, acc.: 69.53%] [G loss: 0.726246]\n",
      "epoch:24 step:22931 [D loss: 0.567096, acc.: 65.62%] [G loss: 0.712445]\n",
      "epoch:24 step:22932 [D loss: 0.477378, acc.: 77.34%] [G loss: 0.780916]\n",
      "epoch:24 step:22933 [D loss: 0.570351, acc.: 60.94%] [G loss: 0.703127]\n",
      "epoch:24 step:22934 [D loss: 0.551142, acc.: 67.97%] [G loss: 0.827211]\n",
      "epoch:24 step:22935 [D loss: 0.496075, acc.: 71.09%] [G loss: 0.754694]\n",
      "epoch:24 step:22936 [D loss: 0.569541, acc.: 69.53%] [G loss: 0.834904]\n",
      "epoch:24 step:22937 [D loss: 0.510100, acc.: 71.88%] [G loss: 0.587962]\n",
      "epoch:24 step:22938 [D loss: 0.494491, acc.: 77.34%] [G loss: 0.741432]\n",
      "epoch:24 step:22939 [D loss: 0.388152, acc.: 85.94%] [G loss: 0.684848]\n",
      "epoch:24 step:22940 [D loss: 0.511981, acc.: 69.53%] [G loss: 0.738636]\n",
      "epoch:24 step:22941 [D loss: 0.492223, acc.: 75.78%] [G loss: 0.684739]\n",
      "epoch:24 step:22942 [D loss: 0.572694, acc.: 67.19%] [G loss: 0.669457]\n",
      "epoch:24 step:22943 [D loss: 0.567469, acc.: 64.84%] [G loss: 0.692069]\n",
      "epoch:24 step:22944 [D loss: 0.555739, acc.: 71.09%] [G loss: 0.690759]\n",
      "epoch:24 step:22945 [D loss: 0.496333, acc.: 76.56%] [G loss: 0.736527]\n",
      "epoch:24 step:22946 [D loss: 0.601318, acc.: 64.06%] [G loss: 0.694363]\n",
      "epoch:24 step:22947 [D loss: 0.516742, acc.: 69.53%] [G loss: 0.692692]\n",
      "epoch:24 step:22948 [D loss: 0.524816, acc.: 67.97%] [G loss: 0.759305]\n",
      "epoch:24 step:22949 [D loss: 0.481391, acc.: 78.91%] [G loss: 0.884176]\n",
      "epoch:24 step:22950 [D loss: 0.513316, acc.: 73.44%] [G loss: 0.769585]\n",
      "epoch:24 step:22951 [D loss: 0.570025, acc.: 68.75%] [G loss: 0.514042]\n",
      "epoch:24 step:22952 [D loss: 0.487966, acc.: 73.44%] [G loss: 0.501572]\n",
      "epoch:24 step:22953 [D loss: 0.578640, acc.: 68.75%] [G loss: 0.545992]\n",
      "epoch:24 step:22954 [D loss: 0.525529, acc.: 75.78%] [G loss: 0.592631]\n",
      "epoch:24 step:22955 [D loss: 0.538839, acc.: 67.97%] [G loss: 0.604642]\n",
      "epoch:24 step:22956 [D loss: 0.524112, acc.: 71.88%] [G loss: 0.805508]\n",
      "epoch:24 step:22957 [D loss: 0.548216, acc.: 70.31%] [G loss: 0.613389]\n",
      "epoch:24 step:22958 [D loss: 0.524506, acc.: 72.66%] [G loss: 0.660181]\n",
      "epoch:24 step:22959 [D loss: 0.478104, acc.: 82.03%] [G loss: 0.741086]\n",
      "epoch:24 step:22960 [D loss: 0.427349, acc.: 82.03%] [G loss: 0.864125]\n",
      "epoch:24 step:22961 [D loss: 0.660380, acc.: 56.25%] [G loss: 0.627152]\n",
      "epoch:24 step:22962 [D loss: 0.584579, acc.: 66.41%] [G loss: 0.533870]\n",
      "epoch:24 step:22963 [D loss: 0.484065, acc.: 73.44%] [G loss: 0.594660]\n",
      "epoch:24 step:22964 [D loss: 0.541115, acc.: 73.44%] [G loss: 0.755690]\n",
      "epoch:24 step:22965 [D loss: 0.623734, acc.: 66.41%] [G loss: 0.659474]\n",
      "epoch:24 step:22966 [D loss: 0.554706, acc.: 71.09%] [G loss: 0.477854]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22967 [D loss: 0.532278, acc.: 73.44%] [G loss: 0.641618]\n",
      "epoch:24 step:22968 [D loss: 0.540857, acc.: 71.09%] [G loss: 0.662477]\n",
      "epoch:24 step:22969 [D loss: 0.496177, acc.: 79.69%] [G loss: 0.676562]\n",
      "epoch:24 step:22970 [D loss: 0.587482, acc.: 67.97%] [G loss: 0.678010]\n",
      "epoch:24 step:22971 [D loss: 0.512811, acc.: 71.88%] [G loss: 0.581255]\n",
      "epoch:24 step:22972 [D loss: 0.506059, acc.: 73.44%] [G loss: 0.881631]\n",
      "epoch:24 step:22973 [D loss: 0.498084, acc.: 73.44%] [G loss: 0.863373]\n",
      "epoch:24 step:22974 [D loss: 0.533020, acc.: 71.88%] [G loss: 0.594559]\n",
      "epoch:24 step:22975 [D loss: 0.546593, acc.: 66.41%] [G loss: 0.619145]\n",
      "epoch:24 step:22976 [D loss: 0.483711, acc.: 72.66%] [G loss: 0.740094]\n",
      "epoch:24 step:22977 [D loss: 0.506999, acc.: 74.22%] [G loss: 0.555116]\n",
      "epoch:24 step:22978 [D loss: 0.556526, acc.: 71.09%] [G loss: 0.629723]\n",
      "epoch:24 step:22979 [D loss: 0.577973, acc.: 67.19%] [G loss: 0.594001]\n",
      "epoch:24 step:22980 [D loss: 0.569500, acc.: 69.53%] [G loss: 0.691137]\n",
      "epoch:24 step:22981 [D loss: 0.519899, acc.: 70.31%] [G loss: 0.613435]\n",
      "epoch:24 step:22982 [D loss: 0.543855, acc.: 71.88%] [G loss: 0.625109]\n",
      "epoch:24 step:22983 [D loss: 0.474355, acc.: 78.12%] [G loss: 0.739523]\n",
      "epoch:24 step:22984 [D loss: 0.515849, acc.: 74.22%] [G loss: 0.834326]\n",
      "epoch:24 step:22985 [D loss: 0.625236, acc.: 64.06%] [G loss: 0.738015]\n",
      "epoch:24 step:22986 [D loss: 0.615947, acc.: 63.28%] [G loss: 0.743764]\n",
      "epoch:24 step:22987 [D loss: 0.452892, acc.: 80.47%] [G loss: 0.794449]\n",
      "epoch:24 step:22988 [D loss: 0.614531, acc.: 64.06%] [G loss: 0.668798]\n",
      "epoch:24 step:22989 [D loss: 0.588670, acc.: 68.75%] [G loss: 0.844321]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if not os.path.isdir('saved_models_{}'.format('bgan')):\n",
    "    os.mkdir('saved_models_{}'.format('bgan'))\n",
    "f = open('saved_models_{}/log_collapse1.txt'.format('bgan'), mode='w')\n",
    "import torch.utils.data as Data\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "class BGAN():\n",
    "    \"\"\"Reference: https://wiseodd.github.io/techblog/2017/03/07/boundary-seeking-gan/\"\"\"\n",
    "    def __init__(self):\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.latent_dim = 100\n",
    "        self.x = []\n",
    "        self.y = np.zeros((31, 1), dtype=np.int)\n",
    "        self.y = list(self.y)\n",
    "        for i in range(31):\n",
    "            self.y[i] = []\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generated imgs\n",
    "        z = Input(shape=(self.latent_dim,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The valid takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss=self.boundary_loss, optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(256, input_dim=self.latent_dim))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Flatten(input_shape=self.img_shape))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def boundary_loss(self, y_true, y_pred):\n",
    "        \"\"\"\n",
    "        Boundary seeking loss.\n",
    "        Reference: https://wiseodd.github.io/techblog/2017/03/07/boundary-seeking-gan/\n",
    "        \"\"\"\n",
    "        return 0.5 * K.mean((K.log(y_pred) - K.log(1 - y_pred))**2)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, _), (X_test,y_test) = mnist.load_data()\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "        X_train = X_train / 127.5 - 1.\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "        X_test = (X_test.astype(np.float32) - 127.5) / 127.5\n",
    "        # X_test = X_test / 127.5 - 1.\n",
    "        X_test = np.expand_dims(X_test, axis=3)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "        nb_batches = int(X_train.shape[0] / batch_size)\n",
    "        global_step = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random batch of images\n",
    "            # idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "            for index in range(nb_batches):\n",
    "                global_step += 1\n",
    "                # progress_bar.update(index)\n",
    "\n",
    "                # get a batch of real images\n",
    "                image_batch = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "\n",
    "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "                # Generate a batch of new images\n",
    "                gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "                # Train the discriminator\n",
    "                d_loss_real = self.discriminator.train_on_batch(image_batch, valid)\n",
    "                d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Generator\n",
    "                # ---------------------\n",
    "\n",
    "                g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "                # Plot the progress\n",
    "                print(\"epoch:%d step:%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch,global_step, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "                sampleSize = 5000\n",
    "                # If at save interval => save generated image samples\n",
    "                if global_step % sample_interval == 0:\n",
    "                    s = self.sample_images(global_step, X_test,y_test, sampleSize)\n",
    "    def sample_images(self, epoch,x_test,y_test,sample_num):\n",
    "        r, c = sample_num//10, 10\n",
    "        noise = np.random.normal(0, 1, (r * c, 100))\n",
    "#         sampled_labels = np.array([num for _ in range(r) for num in range(c)])\n",
    "        gen_imgs = self.generator.predict([noise])\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        labels = np.squeeze(y_test[:sample_num])\n",
    "        labels = np.squeeze(labels)\n",
    "        dis_real = cal_distance_image_real(x_test[:sample_num], labels)\n",
    "        dis_fake = cal_distance_image_fake(gen_imgs)\n",
    "        dis_cha = dis_real - dis_fake\n",
    "        print('##############')\n",
    "        # print(dis_real)\n",
    "        # print(dis_fake)\n",
    "        print(dis_cha)\n",
    "        print('##########')\n",
    "        f.writelines('\\n')\n",
    "        f.writelines('epoch:' + str(epoch))\n",
    "        f.writelines('\\n')\n",
    "        f.writelines('紧度')\n",
    "        f.writelines('\\n')\n",
    "        f.writelines(' %.8f ' % (i) for i in dis_cha)\n",
    "        f.writelines('\\n')\n",
    "        \n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    bgan = BGAN()\n",
    "    bgan.train(epochs=30, batch_size=64, sample_interval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pppppppp [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
