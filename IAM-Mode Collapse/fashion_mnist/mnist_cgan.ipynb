{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*-coding:utf-8-*-\n",
    "import util\n",
    "import tensorflow as tf\n",
    "MNIST_CLASSIFIER_FROZEN_GRAPH = './classify_mnist_graph_def.pb'\n",
    "INPUT_TENSOR = 'inputs:0'\n",
    "OUTPUT_TENSOR = 'logits:0'\n",
    "def EuclideanDistances(A, B):\n",
    "\n",
    "    BT = B.transpose()\n",
    "    # vecProd = A * BT\n",
    "    vecProd = np.dot(A, BT)\n",
    "    # print(vecProd)\n",
    "    SqA = A ** 2\n",
    "    # print(SqA)\n",
    "    sumSqA = np.matrix(np.sum(SqA, axis=1))\n",
    "    sumSqAEx = np.tile(sumSqA.transpose(), (1, vecProd.shape[1]))\n",
    "    # print(sumSqAEx)\n",
    "\n",
    "    SqB = B ** 2\n",
    "    sumSqB = np.sum(SqB, axis=1)\n",
    "    sumSqBEx = np.tile(sumSqB, (vecProd.shape[0], 1))\n",
    "    SqED = sumSqBEx + sumSqAEx - 2 * vecProd\n",
    "    SqED[SqED < 0] = 0.0\n",
    "    ED = np.sqrt(SqED)\n",
    "    return np.divide(ED.sum(),ED.shape[0]*ED.shape[1])\n",
    "def cal_distance_image_real(images,labels):\n",
    "    eval_images=tf.convert_to_tensor(images)\n",
    "    y_logits=util.mnist_logits(eval_images, MNIST_CLASSIFIER_FROZEN_GRAPH, INPUT_TENSOR, OUTPUT_TENSOR)\n",
    "    y_logits=tf.Session().run(y_logits)\n",
    "    dict={}\n",
    "    all_dis=[]\n",
    "    for i in range(10):\n",
    "        dict[i]=[]\n",
    "    for i in range(len(labels)):\n",
    "        dict[labels[i]].append(y_logits[i])\n",
    "    for i in range(10):\n",
    "        dict[i]=np.array(dict[i])\n",
    "        if len(dict[i]):\n",
    "            dis = EuclideanDistances(dict[i], dict[i])  # 生成图片的紧度\n",
    "        else:\n",
    "            dis = -1\n",
    "        all_dis.append(dis)\n",
    "    return np.array(all_dis)\n",
    "def cal_distance_image_fake(images):\n",
    "    eval_images=tf.convert_to_tensor(images)\n",
    "    y_logits=util.mnist_logits(eval_images, MNIST_CLASSIFIER_FROZEN_GRAPH, INPUT_TENSOR, OUTPUT_TENSOR)\n",
    "    y_logits=tf.Session().run(y_logits)\n",
    "    labels = tf.Session().run(tf.argmax(y_logits, 1))\n",
    "    dict={}\n",
    "    all_dis=[]\n",
    "    for i in range(10):\n",
    "        dict[i]=[]\n",
    "    for i in range(len(labels)):\n",
    "        dict[labels[i]].append(y_logits[i])\n",
    "    for i in range(10):\n",
    "        dict[i]=np.array(dict[i])\n",
    "        if len(dict[i]):\n",
    "            dis = EuclideanDistances(dict[i], dict[i])  # 生成图片的紧度\n",
    "        else:\n",
    "            dis = -1\n",
    "        all_dis.append(dis)\n",
    "    return np.array(all_dis)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_7 (Dense)              (None, 784)               615440    \n",
      "_________________________________________________________________\n",
      "reshape_5 (Reshape)          (None, 28, 28, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 14, 14, 64)        640       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 14, 14, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 7, 7, 128)         73856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 7, 7, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 4, 4, 256)         295168    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 4, 4, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 4, 4, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 8193      \n",
      "=================================================================\n",
      "Total params: 2,175,249\n",
      "Trainable params: 2,174,353\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 25088)             2533888   \n",
      "_________________________________________________________________\n",
      "reshape_6 (Reshape)          (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 7, 7, 512)         2048      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_7 (UpSampling2 (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 14, 14, 256)       1179904   \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 14, 14, 256)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 14, 14, 256)       1024      \n",
      "_________________________________________________________________\n",
      "up_sampling2d_8 (UpSampling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 28, 28, 128)       295040    \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 28, 28, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "up_sampling2d_9 (UpSampling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 56, 56, 64)        73792     \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 56, 56, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 28, 28, 1)         577       \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 4,086,785\n",
      "Trainable params: 4,084,993\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "epoch:0 step:1 [D loss: 1.320752, acc.: 7.03%] [G loss: 0.155824]\n",
      "epoch:0 step:2 [D loss: 1.684456, acc.: 50.00%] [G loss: 0.507857]\n",
      "epoch:0 step:3 [D loss: 0.832603, acc.: 60.16%] [G loss: 2.052783]\n",
      "epoch:0 step:4 [D loss: 1.031343, acc.: 40.62%] [G loss: 1.787306]\n",
      "epoch:0 step:5 [D loss: 0.905340, acc.: 45.31%] [G loss: 2.261748]\n",
      "epoch:0 step:6 [D loss: 0.493728, acc.: 75.78%] [G loss: 2.354007]\n",
      "epoch:0 step:7 [D loss: 0.651646, acc.: 60.16%] [G loss: 2.064821]\n",
      "epoch:0 step:8 [D loss: 0.453107, acc.: 75.78%] [G loss: 2.166965]\n",
      "epoch:0 step:9 [D loss: 0.547688, acc.: 69.53%] [G loss: 2.747418]\n",
      "epoch:0 step:10 [D loss: 0.516874, acc.: 78.12%] [G loss: 3.002365]\n",
      "epoch:0 step:11 [D loss: 0.820320, acc.: 67.97%] [G loss: 2.870950]\n",
      "epoch:0 step:12 [D loss: 1.014745, acc.: 63.28%] [G loss: 3.241246]\n",
      "epoch:0 step:13 [D loss: 0.880680, acc.: 65.62%] [G loss: 2.692592]\n",
      "epoch:0 step:14 [D loss: 0.724028, acc.: 65.62%] [G loss: 2.792769]\n",
      "epoch:0 step:15 [D loss: 0.819538, acc.: 57.03%] [G loss: 3.548158]\n",
      "epoch:0 step:16 [D loss: 0.945607, acc.: 69.53%] [G loss: 3.003651]\n",
      "epoch:0 step:17 [D loss: 0.657534, acc.: 64.84%] [G loss: 3.127737]\n",
      "epoch:0 step:18 [D loss: 0.664777, acc.: 67.19%] [G loss: 3.537547]\n",
      "epoch:0 step:19 [D loss: 0.377967, acc.: 83.59%] [G loss: 3.027743]\n",
      "epoch:0 step:20 [D loss: 0.787237, acc.: 66.41%] [G loss: 3.430848]\n",
      "epoch:0 step:21 [D loss: 0.666862, acc.: 64.84%] [G loss: 3.667356]\n",
      "epoch:0 step:22 [D loss: 0.600790, acc.: 65.62%] [G loss: 4.184875]\n",
      "epoch:0 step:23 [D loss: 0.737917, acc.: 66.41%] [G loss: 4.804244]\n",
      "epoch:0 step:24 [D loss: 0.380070, acc.: 85.16%] [G loss: 3.677531]\n",
      "epoch:0 step:25 [D loss: 0.192427, acc.: 93.75%] [G loss: 2.899815]\n",
      "epoch:0 step:26 [D loss: 0.296713, acc.: 85.16%] [G loss: 3.777950]\n",
      "epoch:0 step:27 [D loss: 0.192143, acc.: 90.62%] [G loss: 4.977034]\n",
      "epoch:0 step:28 [D loss: 0.369371, acc.: 85.94%] [G loss: 4.542407]\n",
      "epoch:0 step:29 [D loss: 0.437627, acc.: 80.47%] [G loss: 4.836956]\n",
      "epoch:0 step:30 [D loss: 0.683605, acc.: 71.88%] [G loss: 6.302313]\n",
      "epoch:0 step:31 [D loss: 0.435489, acc.: 80.47%] [G loss: 3.962071]\n",
      "epoch:0 step:32 [D loss: 0.743557, acc.: 70.31%] [G loss: 3.635392]\n",
      "epoch:0 step:33 [D loss: 0.262082, acc.: 89.06%] [G loss: 4.811673]\n",
      "epoch:0 step:34 [D loss: 0.122019, acc.: 97.66%] [G loss: 4.494036]\n",
      "epoch:0 step:35 [D loss: 0.457913, acc.: 80.47%] [G loss: 4.444258]\n",
      "epoch:0 step:36 [D loss: 0.308683, acc.: 89.06%] [G loss: 4.330305]\n",
      "epoch:0 step:37 [D loss: 0.180289, acc.: 96.09%] [G loss: 3.560049]\n",
      "epoch:0 step:38 [D loss: 0.424806, acc.: 76.56%] [G loss: 5.044812]\n",
      "epoch:0 step:39 [D loss: 0.563544, acc.: 81.25%] [G loss: 5.010561]\n",
      "epoch:0 step:40 [D loss: 0.490001, acc.: 78.91%] [G loss: 5.840357]\n",
      "epoch:0 step:41 [D loss: 0.410279, acc.: 84.38%] [G loss: 4.164123]\n",
      "epoch:0 step:42 [D loss: 0.514478, acc.: 78.91%] [G loss: 3.809112]\n",
      "epoch:0 step:43 [D loss: 0.360103, acc.: 82.03%] [G loss: 4.713454]\n",
      "epoch:0 step:44 [D loss: 0.205019, acc.: 93.75%] [G loss: 5.003965]\n",
      "epoch:0 step:45 [D loss: 0.069871, acc.: 99.22%] [G loss: 4.457843]\n",
      "epoch:0 step:46 [D loss: 0.181087, acc.: 94.53%] [G loss: 4.579127]\n",
      "epoch:0 step:47 [D loss: 0.094483, acc.: 96.88%] [G loss: 3.907674]\n",
      "epoch:0 step:48 [D loss: 0.200434, acc.: 92.97%] [G loss: 3.787785]\n",
      "epoch:0 step:49 [D loss: 0.136751, acc.: 94.53%] [G loss: 4.885154]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:50 [D loss: 0.104004, acc.: 97.66%] [G loss: 4.518100]\n",
      "epoch:0 step:51 [D loss: 0.082686, acc.: 100.00%] [G loss: 3.170596]\n",
      "epoch:0 step:52 [D loss: 0.209872, acc.: 92.97%] [G loss: 4.259185]\n",
      "epoch:0 step:53 [D loss: 0.196986, acc.: 90.62%] [G loss: 4.931921]\n",
      "epoch:0 step:54 [D loss: 0.306104, acc.: 84.38%] [G loss: 5.235296]\n",
      "epoch:0 step:55 [D loss: 0.334466, acc.: 83.59%] [G loss: 5.417354]\n",
      "epoch:0 step:56 [D loss: 0.253565, acc.: 91.41%] [G loss: 4.505440]\n",
      "epoch:0 step:57 [D loss: 0.140960, acc.: 95.31%] [G loss: 4.404570]\n",
      "epoch:0 step:58 [D loss: 0.307718, acc.: 89.84%] [G loss: 4.663148]\n",
      "epoch:0 step:59 [D loss: 0.218102, acc.: 90.62%] [G loss: 4.825623]\n",
      "epoch:0 step:60 [D loss: 0.093966, acc.: 97.66%] [G loss: 4.887771]\n",
      "epoch:0 step:61 [D loss: 0.049815, acc.: 98.44%] [G loss: 4.508162]\n",
      "epoch:0 step:62 [D loss: 0.061797, acc.: 99.22%] [G loss: 4.348686]\n",
      "epoch:0 step:63 [D loss: 0.065821, acc.: 100.00%] [G loss: 4.944210]\n",
      "epoch:0 step:64 [D loss: 0.088221, acc.: 99.22%] [G loss: 4.654322]\n",
      "epoch:0 step:65 [D loss: 0.113680, acc.: 98.44%] [G loss: 4.400110]\n",
      "epoch:0 step:66 [D loss: 0.083469, acc.: 99.22%] [G loss: 5.061972]\n",
      "epoch:0 step:67 [D loss: 0.178235, acc.: 93.75%] [G loss: 5.887081]\n",
      "epoch:0 step:68 [D loss: 0.124413, acc.: 97.66%] [G loss: 5.161996]\n",
      "epoch:0 step:69 [D loss: 0.120539, acc.: 98.44%] [G loss: 4.669044]\n",
      "epoch:0 step:70 [D loss: 0.150029, acc.: 95.31%] [G loss: 5.463798]\n",
      "epoch:0 step:71 [D loss: 0.077251, acc.: 98.44%] [G loss: 5.263037]\n",
      "epoch:0 step:72 [D loss: 0.035754, acc.: 100.00%] [G loss: 4.838958]\n",
      "epoch:0 step:73 [D loss: 0.126252, acc.: 95.31%] [G loss: 3.172728]\n",
      "epoch:0 step:74 [D loss: 0.077678, acc.: 98.44%] [G loss: 3.990928]\n",
      "epoch:0 step:75 [D loss: 0.121899, acc.: 96.09%] [G loss: 5.041360]\n",
      "epoch:0 step:76 [D loss: 0.116899, acc.: 94.53%] [G loss: 5.681919]\n",
      "epoch:0 step:77 [D loss: 0.056912, acc.: 100.00%] [G loss: 5.283605]\n",
      "epoch:0 step:78 [D loss: 0.045894, acc.: 100.00%] [G loss: 4.308304]\n",
      "epoch:0 step:79 [D loss: 0.043462, acc.: 99.22%] [G loss: 5.015051]\n",
      "epoch:0 step:80 [D loss: 0.083114, acc.: 97.66%] [G loss: 4.308373]\n",
      "epoch:0 step:81 [D loss: 0.060983, acc.: 99.22%] [G loss: 4.322825]\n",
      "epoch:0 step:82 [D loss: 0.020430, acc.: 100.00%] [G loss: 4.495243]\n",
      "epoch:0 step:83 [D loss: 0.406807, acc.: 89.84%] [G loss: 5.112388]\n",
      "epoch:0 step:84 [D loss: 0.584574, acc.: 93.75%] [G loss: 5.523654]\n",
      "epoch:0 step:85 [D loss: 0.060175, acc.: 98.44%] [G loss: 4.639539]\n",
      "epoch:0 step:86 [D loss: 0.072442, acc.: 96.88%] [G loss: 4.728919]\n",
      "epoch:0 step:87 [D loss: 0.065639, acc.: 97.66%] [G loss: 5.400888]\n",
      "epoch:0 step:88 [D loss: 0.141220, acc.: 93.75%] [G loss: 5.974221]\n",
      "epoch:0 step:89 [D loss: 0.216645, acc.: 94.53%] [G loss: 6.670499]\n",
      "epoch:0 step:90 [D loss: 1.015070, acc.: 81.25%] [G loss: 7.167525]\n",
      "epoch:0 step:91 [D loss: 0.287222, acc.: 89.06%] [G loss: 4.892113]\n",
      "epoch:0 step:92 [D loss: 0.834181, acc.: 82.03%] [G loss: 5.314398]\n",
      "epoch:0 step:93 [D loss: 0.129256, acc.: 96.09%] [G loss: 6.162257]\n",
      "epoch:0 step:94 [D loss: 0.244257, acc.: 92.19%] [G loss: 4.718414]\n",
      "epoch:0 step:95 [D loss: 0.362257, acc.: 89.06%] [G loss: 6.334348]\n",
      "epoch:0 step:96 [D loss: 0.408957, acc.: 86.72%] [G loss: 5.787787]\n",
      "epoch:0 step:97 [D loss: 0.253106, acc.: 95.31%] [G loss: 5.369624]\n",
      "epoch:0 step:98 [D loss: 0.198910, acc.: 93.75%] [G loss: 4.273117]\n",
      "epoch:0 step:99 [D loss: 0.554715, acc.: 83.59%] [G loss: 5.970387]\n",
      "epoch:0 step:100 [D loss: 0.620877, acc.: 89.84%] [G loss: 7.447333]\n",
      "epoch:0 step:101 [D loss: 0.639267, acc.: 92.97%] [G loss: 6.068493]\n",
      "epoch:0 step:102 [D loss: 0.375304, acc.: 86.72%] [G loss: 5.403567]\n",
      "epoch:0 step:103 [D loss: 0.069537, acc.: 99.22%] [G loss: 6.960964]\n",
      "epoch:0 step:104 [D loss: 0.281980, acc.: 86.72%] [G loss: 4.251003]\n",
      "epoch:0 step:105 [D loss: 0.633018, acc.: 78.91%] [G loss: 5.360147]\n",
      "epoch:0 step:106 [D loss: 0.269132, acc.: 89.06%] [G loss: 8.398463]\n",
      "epoch:0 step:107 [D loss: 0.645142, acc.: 74.22%] [G loss: 5.178767]\n",
      "epoch:0 step:108 [D loss: 0.467907, acc.: 78.91%] [G loss: 8.075069]\n",
      "epoch:0 step:109 [D loss: 0.444367, acc.: 87.50%] [G loss: 6.713012]\n",
      "epoch:0 step:110 [D loss: 0.634297, acc.: 82.81%] [G loss: 3.550409]\n",
      "epoch:0 step:111 [D loss: 0.883663, acc.: 77.34%] [G loss: 7.194593]\n",
      "epoch:0 step:112 [D loss: 0.440547, acc.: 81.25%] [G loss: 6.362902]\n",
      "epoch:0 step:113 [D loss: 0.324020, acc.: 85.16%] [G loss: 5.648916]\n",
      "epoch:0 step:114 [D loss: 0.416168, acc.: 81.25%] [G loss: 4.461357]\n",
      "epoch:0 step:115 [D loss: 0.094699, acc.: 97.66%] [G loss: 5.990664]\n",
      "epoch:0 step:116 [D loss: 0.106687, acc.: 95.31%] [G loss: 4.991334]\n",
      "epoch:0 step:117 [D loss: 0.051408, acc.: 100.00%] [G loss: 4.161851]\n",
      "epoch:0 step:118 [D loss: 0.154308, acc.: 94.53%] [G loss: 5.246436]\n",
      "epoch:0 step:119 [D loss: 0.181122, acc.: 93.75%] [G loss: 6.925460]\n",
      "epoch:0 step:120 [D loss: 0.221464, acc.: 93.75%] [G loss: 5.684613]\n",
      "epoch:0 step:121 [D loss: 0.274237, acc.: 94.53%] [G loss: 3.767328]\n",
      "epoch:0 step:122 [D loss: 0.139430, acc.: 95.31%] [G loss: 5.659691]\n",
      "epoch:0 step:123 [D loss: 0.083158, acc.: 98.44%] [G loss: 5.326169]\n",
      "epoch:0 step:124 [D loss: 0.236722, acc.: 88.28%] [G loss: 6.441066]\n",
      "epoch:0 step:125 [D loss: 0.198435, acc.: 92.19%] [G loss: 6.604517]\n",
      "epoch:0 step:126 [D loss: 0.055936, acc.: 98.44%] [G loss: 6.812999]\n",
      "epoch:0 step:127 [D loss: 0.110087, acc.: 97.66%] [G loss: 4.281402]\n",
      "epoch:0 step:128 [D loss: 0.070839, acc.: 100.00%] [G loss: 5.758181]\n",
      "epoch:0 step:129 [D loss: 0.300269, acc.: 89.06%] [G loss: 5.525655]\n",
      "epoch:0 step:130 [D loss: 0.188300, acc.: 92.97%] [G loss: 6.004244]\n",
      "epoch:0 step:131 [D loss: 0.154185, acc.: 93.75%] [G loss: 5.894483]\n",
      "epoch:0 step:132 [D loss: 0.181480, acc.: 92.97%] [G loss: 3.851694]\n",
      "epoch:0 step:133 [D loss: 0.375213, acc.: 83.59%] [G loss: 7.064439]\n",
      "epoch:0 step:134 [D loss: 0.083628, acc.: 96.88%] [G loss: 8.284528]\n",
      "epoch:0 step:135 [D loss: 0.207614, acc.: 92.19%] [G loss: 4.540450]\n",
      "epoch:0 step:136 [D loss: 0.311406, acc.: 90.62%] [G loss: 4.568627]\n",
      "epoch:0 step:137 [D loss: 0.364800, acc.: 85.16%] [G loss: 6.424729]\n",
      "epoch:0 step:138 [D loss: 0.043854, acc.: 98.44%] [G loss: 5.010907]\n",
      "epoch:0 step:139 [D loss: 2.274936, acc.: 37.50%] [G loss: 6.515459]\n",
      "epoch:0 step:140 [D loss: 0.258926, acc.: 87.50%] [G loss: 6.731031]\n",
      "epoch:0 step:141 [D loss: 0.611886, acc.: 78.12%] [G loss: 7.149243]\n",
      "epoch:0 step:142 [D loss: 0.402679, acc.: 85.94%] [G loss: 6.243763]\n",
      "epoch:0 step:143 [D loss: 0.788077, acc.: 62.50%] [G loss: 4.371994]\n",
      "epoch:0 step:144 [D loss: 0.275837, acc.: 90.62%] [G loss: 4.662809]\n",
      "epoch:0 step:145 [D loss: 0.376720, acc.: 81.25%] [G loss: 4.678833]\n",
      "epoch:0 step:146 [D loss: 0.570663, acc.: 74.22%] [G loss: 7.924613]\n",
      "epoch:0 step:147 [D loss: 0.332223, acc.: 86.72%] [G loss: 3.864284]\n",
      "epoch:0 step:148 [D loss: 0.955842, acc.: 67.97%] [G loss: 7.121470]\n",
      "epoch:0 step:149 [D loss: 0.894182, acc.: 59.38%] [G loss: 6.930960]\n",
      "epoch:0 step:150 [D loss: 0.696864, acc.: 75.78%] [G loss: 4.609793]\n",
      "epoch:0 step:151 [D loss: 0.198480, acc.: 90.62%] [G loss: 3.203832]\n",
      "epoch:0 step:152 [D loss: 0.398641, acc.: 80.47%] [G loss: 5.261204]\n",
      "epoch:0 step:153 [D loss: 1.039075, acc.: 62.50%] [G loss: 5.593661]\n",
      "epoch:0 step:154 [D loss: 0.690098, acc.: 74.22%] [G loss: 6.327183]\n",
      "epoch:0 step:155 [D loss: 0.400873, acc.: 84.38%] [G loss: 6.146107]\n",
      "epoch:0 step:156 [D loss: 0.494201, acc.: 75.78%] [G loss: 5.999303]\n",
      "epoch:0 step:157 [D loss: 0.201636, acc.: 91.41%] [G loss: 5.407756]\n",
      "epoch:0 step:158 [D loss: 0.337838, acc.: 85.16%] [G loss: 4.836638]\n",
      "epoch:0 step:159 [D loss: 0.371033, acc.: 84.38%] [G loss: 6.191566]\n",
      "epoch:0 step:160 [D loss: 0.778985, acc.: 67.19%] [G loss: 1.714304]\n",
      "epoch:0 step:161 [D loss: 0.685300, acc.: 67.97%] [G loss: 5.772692]\n",
      "epoch:0 step:162 [D loss: 0.423135, acc.: 82.81%] [G loss: 5.963967]\n",
      "epoch:0 step:163 [D loss: 0.335517, acc.: 82.81%] [G loss: 4.172863]\n",
      "epoch:0 step:164 [D loss: 0.593486, acc.: 70.31%] [G loss: 5.317416]\n",
      "epoch:0 step:165 [D loss: 0.109316, acc.: 96.88%] [G loss: 5.050718]\n",
      "epoch:0 step:166 [D loss: 0.428092, acc.: 80.47%] [G loss: 3.969520]\n",
      "epoch:0 step:167 [D loss: 0.800133, acc.: 59.38%] [G loss: 5.398460]\n",
      "epoch:0 step:168 [D loss: 0.675218, acc.: 75.78%] [G loss: 2.326879]\n",
      "epoch:0 step:169 [D loss: 0.267793, acc.: 89.84%] [G loss: 4.334178]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:170 [D loss: 0.264798, acc.: 89.84%] [G loss: 4.689801]\n",
      "epoch:0 step:171 [D loss: 0.289368, acc.: 91.41%] [G loss: 4.260958]\n",
      "epoch:0 step:172 [D loss: 0.403678, acc.: 78.91%] [G loss: 6.003686]\n",
      "epoch:0 step:173 [D loss: 0.444677, acc.: 81.25%] [G loss: 4.809316]\n",
      "epoch:0 step:174 [D loss: 1.057758, acc.: 50.00%] [G loss: 2.552339]\n",
      "epoch:0 step:175 [D loss: 0.388083, acc.: 77.34%] [G loss: 5.243370]\n",
      "epoch:0 step:176 [D loss: 0.848876, acc.: 58.59%] [G loss: 3.920119]\n",
      "epoch:0 step:177 [D loss: 0.839895, acc.: 68.75%] [G loss: 6.220595]\n",
      "epoch:0 step:178 [D loss: 1.259574, acc.: 38.28%] [G loss: 5.254566]\n",
      "epoch:0 step:179 [D loss: 0.543052, acc.: 78.12%] [G loss: 4.138112]\n",
      "epoch:0 step:180 [D loss: 0.804387, acc.: 55.47%] [G loss: 2.534793]\n",
      "epoch:0 step:181 [D loss: 1.264817, acc.: 44.53%] [G loss: 5.989539]\n",
      "epoch:0 step:182 [D loss: 2.097335, acc.: 19.53%] [G loss: 5.097589]\n",
      "epoch:0 step:183 [D loss: 2.009154, acc.: 34.38%] [G loss: 4.414429]\n",
      "epoch:0 step:184 [D loss: 1.271578, acc.: 47.66%] [G loss: 3.310747]\n",
      "epoch:0 step:185 [D loss: 0.969852, acc.: 53.91%] [G loss: 3.091568]\n",
      "epoch:0 step:186 [D loss: 0.816959, acc.: 64.06%] [G loss: 3.056925]\n",
      "epoch:0 step:187 [D loss: 0.976321, acc.: 50.00%] [G loss: 3.891193]\n",
      "epoch:0 step:188 [D loss: 0.718570, acc.: 71.88%] [G loss: 3.171491]\n",
      "epoch:0 step:189 [D loss: 0.627853, acc.: 67.19%] [G loss: 4.542072]\n",
      "epoch:0 step:190 [D loss: 0.449955, acc.: 81.25%] [G loss: 4.032945]\n",
      "epoch:0 step:191 [D loss: 0.747547, acc.: 62.50%] [G loss: 4.051753]\n",
      "epoch:0 step:192 [D loss: 0.767271, acc.: 67.19%] [G loss: 2.813686]\n",
      "epoch:0 step:193 [D loss: 1.410450, acc.: 47.66%] [G loss: 3.352141]\n",
      "epoch:0 step:194 [D loss: 0.734622, acc.: 64.84%] [G loss: 5.450147]\n",
      "epoch:0 step:195 [D loss: 1.283505, acc.: 52.34%] [G loss: 3.893368]\n",
      "epoch:0 step:196 [D loss: 1.195193, acc.: 46.88%] [G loss: 2.576595]\n",
      "epoch:0 step:197 [D loss: 0.633591, acc.: 67.97%] [G loss: 2.621588]\n",
      "epoch:0 step:198 [D loss: 0.596567, acc.: 70.31%] [G loss: 3.704737]\n",
      "epoch:0 step:199 [D loss: 0.861676, acc.: 64.06%] [G loss: 3.483836]\n",
      "epoch:0 step:200 [D loss: 0.782000, acc.: 57.03%] [G loss: 2.529470]\n",
      "WARNING:tensorflow:From /home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/contrib/gan/python/eval/python/classifier_metrics_impl.py:185: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      "##############\n",
      "[7.25912414 1.99944804 8.44334961 6.44984864 5.84221665 7.25088756\n",
      " 7.0536557  6.61218872 6.01579631 5.58036308]\n",
      "##########\n",
      "epoch:0 step:201 [D loss: 0.893307, acc.: 63.28%] [G loss: 1.931940]\n",
      "epoch:0 step:202 [D loss: 0.524217, acc.: 72.66%] [G loss: 3.290303]\n",
      "epoch:0 step:203 [D loss: 1.127766, acc.: 41.41%] [G loss: 2.416370]\n",
      "epoch:0 step:204 [D loss: 0.841074, acc.: 59.38%] [G loss: 3.062379]\n",
      "epoch:0 step:205 [D loss: 0.689016, acc.: 60.16%] [G loss: 2.656065]\n",
      "epoch:0 step:206 [D loss: 0.789313, acc.: 64.06%] [G loss: 3.088106]\n",
      "epoch:0 step:207 [D loss: 0.917257, acc.: 48.44%] [G loss: 3.539312]\n",
      "epoch:0 step:208 [D loss: 0.946999, acc.: 50.00%] [G loss: 4.209740]\n",
      "epoch:0 step:209 [D loss: 0.826887, acc.: 62.50%] [G loss: 3.804812]\n",
      "epoch:0 step:210 [D loss: 0.741281, acc.: 67.19%] [G loss: 2.255348]\n",
      "epoch:0 step:211 [D loss: 0.657871, acc.: 69.53%] [G loss: 2.731622]\n",
      "epoch:0 step:212 [D loss: 0.693586, acc.: 63.28%] [G loss: 2.180769]\n",
      "epoch:0 step:213 [D loss: 0.364492, acc.: 86.72%] [G loss: 2.636060]\n",
      "epoch:0 step:214 [D loss: 1.132975, acc.: 43.75%] [G loss: 2.014864]\n",
      "epoch:0 step:215 [D loss: 0.831334, acc.: 52.34%] [G loss: 3.472267]\n",
      "epoch:0 step:216 [D loss: 0.479916, acc.: 75.00%] [G loss: 3.746456]\n",
      "epoch:0 step:217 [D loss: 0.743255, acc.: 52.34%] [G loss: 3.095081]\n",
      "epoch:0 step:218 [D loss: 0.829401, acc.: 57.81%] [G loss: 3.069678]\n",
      "epoch:0 step:219 [D loss: 1.137201, acc.: 34.38%] [G loss: 2.407158]\n",
      "epoch:0 step:220 [D loss: 1.118291, acc.: 39.84%] [G loss: 2.867220]\n",
      "epoch:0 step:221 [D loss: 0.841302, acc.: 60.16%] [G loss: 2.964792]\n",
      "epoch:0 step:222 [D loss: 0.851937, acc.: 56.25%] [G loss: 3.225478]\n",
      "epoch:0 step:223 [D loss: 0.641832, acc.: 71.09%] [G loss: 3.578118]\n",
      "epoch:0 step:224 [D loss: 1.119875, acc.: 56.25%] [G loss: 2.022025]\n",
      "epoch:0 step:225 [D loss: 1.315884, acc.: 45.31%] [G loss: 2.051643]\n",
      "epoch:0 step:226 [D loss: 0.625650, acc.: 68.75%] [G loss: 2.726634]\n",
      "epoch:0 step:227 [D loss: 0.744049, acc.: 65.62%] [G loss: 2.937947]\n",
      "epoch:0 step:228 [D loss: 0.810335, acc.: 54.69%] [G loss: 2.055283]\n",
      "epoch:0 step:229 [D loss: 1.185305, acc.: 39.84%] [G loss: 1.752075]\n",
      "epoch:0 step:230 [D loss: 0.784415, acc.: 55.47%] [G loss: 2.483540]\n",
      "epoch:0 step:231 [D loss: 0.748082, acc.: 60.16%] [G loss: 2.445840]\n",
      "epoch:0 step:232 [D loss: 0.577289, acc.: 72.66%] [G loss: 2.185095]\n",
      "epoch:0 step:233 [D loss: 0.838253, acc.: 61.72%] [G loss: 3.026330]\n",
      "epoch:0 step:234 [D loss: 1.221569, acc.: 46.09%] [G loss: 2.260683]\n",
      "epoch:0 step:235 [D loss: 0.909209, acc.: 50.00%] [G loss: 2.243082]\n",
      "epoch:0 step:236 [D loss: 0.972772, acc.: 60.16%] [G loss: 2.271302]\n",
      "epoch:0 step:237 [D loss: 0.954730, acc.: 47.66%] [G loss: 2.401660]\n",
      "epoch:0 step:238 [D loss: 0.655294, acc.: 64.06%] [G loss: 2.853623]\n",
      "epoch:0 step:239 [D loss: 0.642871, acc.: 69.53%] [G loss: 2.495451]\n",
      "epoch:0 step:240 [D loss: 0.609327, acc.: 64.06%] [G loss: 2.651229]\n",
      "epoch:0 step:241 [D loss: 0.608112, acc.: 64.84%] [G loss: 3.210303]\n",
      "epoch:0 step:242 [D loss: 0.470787, acc.: 77.34%] [G loss: 2.265718]\n",
      "epoch:0 step:243 [D loss: 0.780373, acc.: 55.47%] [G loss: 2.608263]\n",
      "epoch:0 step:244 [D loss: 0.633421, acc.: 68.75%] [G loss: 2.429801]\n",
      "epoch:0 step:245 [D loss: 0.636629, acc.: 67.19%] [G loss: 2.299801]\n",
      "epoch:0 step:246 [D loss: 0.842005, acc.: 50.78%] [G loss: 2.609324]\n",
      "epoch:0 step:247 [D loss: 0.832624, acc.: 53.12%] [G loss: 2.072729]\n",
      "epoch:0 step:248 [D loss: 0.676129, acc.: 64.84%] [G loss: 2.463955]\n",
      "epoch:0 step:249 [D loss: 0.878181, acc.: 53.12%] [G loss: 2.217702]\n",
      "epoch:0 step:250 [D loss: 0.757975, acc.: 59.38%] [G loss: 2.768365]\n",
      "epoch:0 step:251 [D loss: 0.777677, acc.: 60.16%] [G loss: 2.770742]\n",
      "epoch:0 step:252 [D loss: 0.643116, acc.: 70.31%] [G loss: 2.826298]\n",
      "epoch:0 step:253 [D loss: 0.483600, acc.: 75.78%] [G loss: 2.270444]\n",
      "epoch:0 step:254 [D loss: 0.587742, acc.: 70.31%] [G loss: 2.576388]\n",
      "epoch:0 step:255 [D loss: 0.701873, acc.: 65.62%] [G loss: 2.979360]\n",
      "epoch:0 step:256 [D loss: 0.748052, acc.: 67.19%] [G loss: 2.625935]\n",
      "epoch:0 step:257 [D loss: 0.668515, acc.: 61.72%] [G loss: 2.508014]\n",
      "epoch:0 step:258 [D loss: 0.688085, acc.: 64.84%] [G loss: 2.698843]\n",
      "epoch:0 step:259 [D loss: 0.591362, acc.: 67.19%] [G loss: 2.477226]\n",
      "epoch:0 step:260 [D loss: 0.713870, acc.: 57.03%] [G loss: 2.116112]\n",
      "epoch:0 step:261 [D loss: 0.679636, acc.: 57.81%] [G loss: 2.817364]\n",
      "epoch:0 step:262 [D loss: 0.582527, acc.: 71.09%] [G loss: 2.605432]\n",
      "epoch:0 step:263 [D loss: 0.950681, acc.: 47.66%] [G loss: 2.523168]\n",
      "epoch:0 step:264 [D loss: 0.727312, acc.: 63.28%] [G loss: 2.215769]\n",
      "epoch:0 step:265 [D loss: 1.021050, acc.: 42.97%] [G loss: 2.814529]\n",
      "epoch:0 step:266 [D loss: 0.728098, acc.: 57.03%] [G loss: 2.961009]\n",
      "epoch:0 step:267 [D loss: 0.813303, acc.: 63.28%] [G loss: 2.344893]\n",
      "epoch:0 step:268 [D loss: 0.633839, acc.: 69.53%] [G loss: 1.956734]\n",
      "epoch:0 step:269 [D loss: 0.565454, acc.: 73.44%] [G loss: 2.257414]\n",
      "epoch:0 step:270 [D loss: 0.663888, acc.: 64.06%] [G loss: 2.006738]\n",
      "epoch:0 step:271 [D loss: 0.698206, acc.: 67.97%] [G loss: 2.307699]\n",
      "epoch:0 step:272 [D loss: 0.934022, acc.: 49.22%] [G loss: 2.445698]\n",
      "epoch:0 step:273 [D loss: 0.801721, acc.: 51.56%] [G loss: 2.791027]\n",
      "epoch:0 step:274 [D loss: 0.813135, acc.: 56.25%] [G loss: 2.735030]\n",
      "epoch:0 step:275 [D loss: 0.912688, acc.: 50.78%] [G loss: 2.112386]\n",
      "epoch:0 step:276 [D loss: 0.596046, acc.: 66.41%] [G loss: 2.213819]\n",
      "epoch:0 step:277 [D loss: 0.823909, acc.: 57.81%] [G loss: 2.301660]\n",
      "epoch:0 step:278 [D loss: 0.944901, acc.: 48.44%] [G loss: 2.207378]\n",
      "epoch:0 step:279 [D loss: 0.970287, acc.: 50.00%] [G loss: 2.630691]\n",
      "epoch:0 step:280 [D loss: 0.566422, acc.: 73.44%] [G loss: 1.983286]\n",
      "epoch:0 step:281 [D loss: 0.653985, acc.: 70.31%] [G loss: 1.758237]\n",
      "epoch:0 step:282 [D loss: 0.494714, acc.: 78.91%] [G loss: 2.155309]\n",
      "epoch:0 step:283 [D loss: 0.487643, acc.: 75.78%] [G loss: 2.127458]\n",
      "epoch:0 step:284 [D loss: 0.491048, acc.: 72.66%] [G loss: 1.814084]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:285 [D loss: 0.682873, acc.: 64.84%] [G loss: 2.108847]\n",
      "epoch:0 step:286 [D loss: 0.736320, acc.: 65.62%] [G loss: 2.304558]\n",
      "epoch:0 step:287 [D loss: 0.815538, acc.: 54.69%] [G loss: 2.801808]\n",
      "epoch:0 step:288 [D loss: 0.713849, acc.: 61.72%] [G loss: 2.691988]\n",
      "epoch:0 step:289 [D loss: 0.673174, acc.: 70.31%] [G loss: 1.927753]\n",
      "epoch:0 step:290 [D loss: 0.765440, acc.: 53.12%] [G loss: 1.882991]\n",
      "epoch:0 step:291 [D loss: 1.078601, acc.: 48.44%] [G loss: 1.980667]\n",
      "epoch:0 step:292 [D loss: 0.606881, acc.: 61.72%] [G loss: 2.322834]\n",
      "epoch:0 step:293 [D loss: 0.459010, acc.: 79.69%] [G loss: 2.686099]\n",
      "epoch:0 step:294 [D loss: 0.734033, acc.: 60.16%] [G loss: 2.320488]\n",
      "epoch:0 step:295 [D loss: 0.643704, acc.: 63.28%] [G loss: 1.966963]\n",
      "epoch:0 step:296 [D loss: 0.497332, acc.: 75.78%] [G loss: 2.547417]\n",
      "epoch:0 step:297 [D loss: 0.782868, acc.: 58.59%] [G loss: 1.675955]\n",
      "epoch:0 step:298 [D loss: 0.681166, acc.: 64.84%] [G loss: 2.079528]\n",
      "epoch:0 step:299 [D loss: 0.653427, acc.: 60.16%] [G loss: 2.022033]\n",
      "epoch:0 step:300 [D loss: 0.646282, acc.: 64.84%] [G loss: 2.527129]\n",
      "epoch:0 step:301 [D loss: 0.639269, acc.: 63.28%] [G loss: 1.971878]\n",
      "epoch:0 step:302 [D loss: 0.595798, acc.: 65.62%] [G loss: 1.620673]\n",
      "epoch:0 step:303 [D loss: 0.655368, acc.: 62.50%] [G loss: 2.061044]\n",
      "epoch:0 step:304 [D loss: 0.576036, acc.: 67.19%] [G loss: 2.390992]\n",
      "epoch:0 step:305 [D loss: 0.674809, acc.: 59.38%] [G loss: 1.882969]\n",
      "epoch:0 step:306 [D loss: 0.865823, acc.: 53.12%] [G loss: 1.840465]\n",
      "epoch:0 step:307 [D loss: 0.577416, acc.: 70.31%] [G loss: 2.409902]\n",
      "epoch:0 step:308 [D loss: 0.669572, acc.: 66.41%] [G loss: 2.111333]\n",
      "epoch:0 step:309 [D loss: 0.675999, acc.: 61.72%] [G loss: 2.209168]\n",
      "epoch:0 step:310 [D loss: 0.762775, acc.: 57.03%] [G loss: 2.288695]\n",
      "epoch:0 step:311 [D loss: 0.856439, acc.: 57.03%] [G loss: 2.318531]\n",
      "epoch:0 step:312 [D loss: 0.642223, acc.: 71.09%] [G loss: 2.758958]\n",
      "epoch:0 step:313 [D loss: 0.600198, acc.: 71.09%] [G loss: 2.052260]\n",
      "epoch:0 step:314 [D loss: 0.471633, acc.: 78.12%] [G loss: 2.303341]\n",
      "epoch:0 step:315 [D loss: 0.793054, acc.: 60.16%] [G loss: 2.447269]\n",
      "epoch:0 step:316 [D loss: 1.490210, acc.: 28.12%] [G loss: 2.428883]\n",
      "epoch:0 step:317 [D loss: 0.856094, acc.: 50.78%] [G loss: 2.448443]\n",
      "epoch:0 step:318 [D loss: 0.711487, acc.: 61.72%] [G loss: 2.161733]\n",
      "epoch:0 step:319 [D loss: 0.570168, acc.: 71.88%] [G loss: 2.090286]\n",
      "epoch:0 step:320 [D loss: 0.745664, acc.: 60.94%] [G loss: 1.874289]\n",
      "epoch:0 step:321 [D loss: 0.460684, acc.: 81.25%] [G loss: 2.010869]\n",
      "epoch:0 step:322 [D loss: 0.703476, acc.: 61.72%] [G loss: 1.855116]\n",
      "epoch:0 step:323 [D loss: 0.820265, acc.: 53.12%] [G loss: 1.977644]\n",
      "epoch:0 step:324 [D loss: 0.561721, acc.: 70.31%] [G loss: 2.010577]\n",
      "epoch:0 step:325 [D loss: 0.600344, acc.: 67.19%] [G loss: 1.875485]\n",
      "epoch:0 step:326 [D loss: 0.806700, acc.: 52.34%] [G loss: 1.994171]\n",
      "epoch:0 step:327 [D loss: 0.860199, acc.: 50.00%] [G loss: 1.811152]\n",
      "epoch:0 step:328 [D loss: 0.581733, acc.: 71.09%] [G loss: 2.148438]\n",
      "epoch:0 step:329 [D loss: 0.734075, acc.: 57.81%] [G loss: 2.016551]\n",
      "epoch:0 step:330 [D loss: 0.719212, acc.: 59.38%] [G loss: 1.842363]\n",
      "epoch:0 step:331 [D loss: 0.624656, acc.: 66.41%] [G loss: 1.360043]\n",
      "epoch:0 step:332 [D loss: 0.791181, acc.: 53.91%] [G loss: 2.085362]\n",
      "epoch:0 step:333 [D loss: 0.778364, acc.: 57.81%] [G loss: 1.854493]\n",
      "epoch:0 step:334 [D loss: 0.834496, acc.: 49.22%] [G loss: 1.696039]\n",
      "epoch:0 step:335 [D loss: 0.607565, acc.: 65.62%] [G loss: 2.033745]\n",
      "epoch:0 step:336 [D loss: 0.503807, acc.: 81.25%] [G loss: 2.072109]\n",
      "epoch:0 step:337 [D loss: 0.598995, acc.: 65.62%] [G loss: 2.019377]\n",
      "epoch:0 step:338 [D loss: 0.584562, acc.: 65.62%] [G loss: 1.362366]\n",
      "epoch:0 step:339 [D loss: 0.724264, acc.: 62.50%] [G loss: 1.869467]\n",
      "epoch:0 step:340 [D loss: 0.738991, acc.: 56.25%] [G loss: 2.215165]\n",
      "epoch:0 step:341 [D loss: 0.721859, acc.: 64.84%] [G loss: 2.284428]\n",
      "epoch:0 step:342 [D loss: 0.614334, acc.: 65.62%] [G loss: 1.772618]\n",
      "epoch:0 step:343 [D loss: 0.572095, acc.: 66.41%] [G loss: 2.183690]\n",
      "epoch:0 step:344 [D loss: 0.760568, acc.: 55.47%] [G loss: 2.386745]\n",
      "epoch:0 step:345 [D loss: 0.650660, acc.: 60.94%] [G loss: 1.919709]\n",
      "epoch:0 step:346 [D loss: 0.626659, acc.: 65.62%] [G loss: 1.701499]\n",
      "epoch:0 step:347 [D loss: 0.589784, acc.: 69.53%] [G loss: 1.969501]\n",
      "epoch:0 step:348 [D loss: 0.878030, acc.: 51.56%] [G loss: 1.936327]\n",
      "epoch:0 step:349 [D loss: 1.096501, acc.: 42.19%] [G loss: 1.849451]\n",
      "epoch:0 step:350 [D loss: 0.552395, acc.: 74.22%] [G loss: 2.252613]\n",
      "epoch:0 step:351 [D loss: 0.705594, acc.: 61.72%] [G loss: 2.506176]\n",
      "epoch:0 step:352 [D loss: 0.725861, acc.: 62.50%] [G loss: 2.554288]\n",
      "epoch:0 step:353 [D loss: 0.758273, acc.: 59.38%] [G loss: 2.100315]\n",
      "epoch:0 step:354 [D loss: 0.637114, acc.: 67.19%] [G loss: 2.458642]\n",
      "epoch:0 step:355 [D loss: 0.693049, acc.: 64.06%] [G loss: 2.483294]\n",
      "epoch:0 step:356 [D loss: 0.656851, acc.: 58.59%] [G loss: 1.927082]\n",
      "epoch:0 step:357 [D loss: 0.655708, acc.: 62.50%] [G loss: 2.035071]\n",
      "epoch:0 step:358 [D loss: 0.583679, acc.: 70.31%] [G loss: 1.968141]\n",
      "epoch:0 step:359 [D loss: 0.569653, acc.: 71.09%] [G loss: 2.086061]\n",
      "epoch:0 step:360 [D loss: 0.598221, acc.: 69.53%] [G loss: 2.099619]\n",
      "epoch:0 step:361 [D loss: 0.760705, acc.: 59.38%] [G loss: 1.676383]\n",
      "epoch:0 step:362 [D loss: 0.646210, acc.: 63.28%] [G loss: 1.988403]\n",
      "epoch:0 step:363 [D loss: 0.612429, acc.: 67.19%] [G loss: 2.132407]\n",
      "epoch:0 step:364 [D loss: 0.679735, acc.: 60.94%] [G loss: 2.115676]\n",
      "epoch:0 step:365 [D loss: 0.735136, acc.: 62.50%] [G loss: 1.839499]\n",
      "epoch:0 step:366 [D loss: 0.764431, acc.: 54.69%] [G loss: 1.759705]\n",
      "epoch:0 step:367 [D loss: 0.763831, acc.: 51.56%] [G loss: 2.042405]\n",
      "epoch:0 step:368 [D loss: 0.525358, acc.: 71.09%] [G loss: 1.951885]\n",
      "epoch:0 step:369 [D loss: 0.636847, acc.: 66.41%] [G loss: 1.948627]\n",
      "epoch:0 step:370 [D loss: 0.722585, acc.: 60.94%] [G loss: 1.604023]\n",
      "epoch:0 step:371 [D loss: 0.721479, acc.: 55.47%] [G loss: 1.587251]\n",
      "epoch:0 step:372 [D loss: 0.704424, acc.: 60.16%] [G loss: 1.954336]\n",
      "epoch:0 step:373 [D loss: 0.704055, acc.: 61.72%] [G loss: 1.855959]\n",
      "epoch:0 step:374 [D loss: 0.810570, acc.: 54.69%] [G loss: 1.766581]\n",
      "epoch:0 step:375 [D loss: 0.692257, acc.: 64.06%] [G loss: 1.726637]\n",
      "epoch:0 step:376 [D loss: 1.032452, acc.: 39.06%] [G loss: 1.303809]\n",
      "epoch:0 step:377 [D loss: 0.960449, acc.: 49.22%] [G loss: 1.670576]\n",
      "epoch:0 step:378 [D loss: 0.668990, acc.: 64.06%] [G loss: 1.921486]\n",
      "epoch:0 step:379 [D loss: 0.784607, acc.: 52.34%] [G loss: 1.683590]\n",
      "epoch:0 step:380 [D loss: 0.850321, acc.: 51.56%] [G loss: 1.429505]\n",
      "epoch:0 step:381 [D loss: 0.666216, acc.: 58.59%] [G loss: 1.836959]\n",
      "epoch:0 step:382 [D loss: 0.721277, acc.: 61.72%] [G loss: 1.672908]\n",
      "epoch:0 step:383 [D loss: 0.713107, acc.: 62.50%] [G loss: 1.588812]\n",
      "epoch:0 step:384 [D loss: 0.768557, acc.: 56.25%] [G loss: 1.745909]\n",
      "epoch:0 step:385 [D loss: 0.711816, acc.: 58.59%] [G loss: 1.791544]\n",
      "epoch:0 step:386 [D loss: 0.860333, acc.: 50.00%] [G loss: 1.890257]\n",
      "epoch:0 step:387 [D loss: 0.679555, acc.: 58.59%] [G loss: 1.667926]\n",
      "epoch:0 step:388 [D loss: 0.639417, acc.: 63.28%] [G loss: 1.590692]\n",
      "epoch:0 step:389 [D loss: 0.607981, acc.: 67.19%] [G loss: 1.696683]\n",
      "epoch:0 step:390 [D loss: 0.842394, acc.: 53.91%] [G loss: 1.866682]\n",
      "epoch:0 step:391 [D loss: 0.602928, acc.: 62.50%] [G loss: 1.565792]\n",
      "epoch:0 step:392 [D loss: 0.741893, acc.: 57.03%] [G loss: 1.783369]\n",
      "epoch:0 step:393 [D loss: 0.751690, acc.: 50.00%] [G loss: 1.588398]\n",
      "epoch:0 step:394 [D loss: 0.729268, acc.: 57.03%] [G loss: 1.823823]\n",
      "epoch:0 step:395 [D loss: 0.620201, acc.: 66.41%] [G loss: 1.846750]\n",
      "epoch:0 step:396 [D loss: 0.483683, acc.: 75.78%] [G loss: 2.121814]\n",
      "epoch:0 step:397 [D loss: 0.443796, acc.: 78.12%] [G loss: 1.827563]\n",
      "epoch:0 step:398 [D loss: 0.439663, acc.: 78.91%] [G loss: 2.123557]\n",
      "epoch:0 step:399 [D loss: 0.689836, acc.: 61.72%] [G loss: 1.585609]\n",
      "epoch:0 step:400 [D loss: 0.914960, acc.: 47.66%] [G loss: 1.694439]\n",
      "##############\n",
      "[4.99958107 1.2291189  7.07048966 5.40662837 3.92104186 5.49333833\n",
      " 5.21353555 4.67258993 5.14107098 4.35704803]\n",
      "##########\n",
      "epoch:0 step:401 [D loss: 0.802065, acc.: 54.69%] [G loss: 1.370810]\n",
      "epoch:0 step:402 [D loss: 0.620972, acc.: 61.72%] [G loss: 1.758313]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:403 [D loss: 0.717385, acc.: 59.38%] [G loss: 1.717747]\n",
      "epoch:0 step:404 [D loss: 0.746324, acc.: 54.69%] [G loss: 1.436246]\n",
      "epoch:0 step:405 [D loss: 0.639647, acc.: 61.72%] [G loss: 1.395625]\n",
      "epoch:0 step:406 [D loss: 0.642713, acc.: 67.19%] [G loss: 1.781107]\n",
      "epoch:0 step:407 [D loss: 0.689210, acc.: 64.06%] [G loss: 1.578618]\n",
      "epoch:0 step:408 [D loss: 0.611341, acc.: 68.75%] [G loss: 2.007642]\n",
      "epoch:0 step:409 [D loss: 0.577578, acc.: 67.19%] [G loss: 1.834393]\n",
      "epoch:0 step:410 [D loss: 0.703861, acc.: 59.38%] [G loss: 1.726760]\n",
      "epoch:0 step:411 [D loss: 0.657081, acc.: 63.28%] [G loss: 1.695038]\n",
      "epoch:0 step:412 [D loss: 0.772018, acc.: 59.38%] [G loss: 1.511638]\n",
      "epoch:0 step:413 [D loss: 0.961374, acc.: 43.75%] [G loss: 1.612596]\n",
      "epoch:0 step:414 [D loss: 0.843562, acc.: 49.22%] [G loss: 1.552475]\n",
      "epoch:0 step:415 [D loss: 0.812754, acc.: 46.88%] [G loss: 1.601803]\n",
      "epoch:0 step:416 [D loss: 0.619324, acc.: 66.41%] [G loss: 1.748305]\n",
      "epoch:0 step:417 [D loss: 0.823094, acc.: 45.31%] [G loss: 1.254965]\n",
      "epoch:0 step:418 [D loss: 0.869536, acc.: 50.00%] [G loss: 1.742150]\n",
      "epoch:0 step:419 [D loss: 0.652961, acc.: 60.16%] [G loss: 1.944296]\n",
      "epoch:0 step:420 [D loss: 0.813840, acc.: 56.25%] [G loss: 1.806510]\n",
      "epoch:0 step:421 [D loss: 0.798119, acc.: 57.03%] [G loss: 1.399729]\n",
      "epoch:0 step:422 [D loss: 0.903995, acc.: 42.97%] [G loss: 1.514306]\n",
      "epoch:0 step:423 [D loss: 0.706779, acc.: 62.50%] [G loss: 1.711537]\n",
      "epoch:0 step:424 [D loss: 0.743802, acc.: 54.69%] [G loss: 1.597322]\n",
      "epoch:0 step:425 [D loss: 0.602193, acc.: 68.75%] [G loss: 1.599711]\n",
      "epoch:0 step:426 [D loss: 0.579373, acc.: 71.88%] [G loss: 1.692689]\n",
      "epoch:0 step:427 [D loss: 0.671071, acc.: 62.50%] [G loss: 1.594937]\n",
      "epoch:0 step:428 [D loss: 0.630693, acc.: 64.84%] [G loss: 1.618225]\n",
      "epoch:0 step:429 [D loss: 0.817051, acc.: 55.47%] [G loss: 1.394126]\n",
      "epoch:0 step:430 [D loss: 0.593120, acc.: 64.84%] [G loss: 1.715907]\n",
      "epoch:0 step:431 [D loss: 0.757906, acc.: 55.47%] [G loss: 1.413040]\n",
      "epoch:0 step:432 [D loss: 0.860444, acc.: 42.97%] [G loss: 1.431961]\n",
      "epoch:0 step:433 [D loss: 0.831222, acc.: 53.12%] [G loss: 1.549066]\n",
      "epoch:0 step:434 [D loss: 0.675480, acc.: 67.19%] [G loss: 1.544090]\n",
      "epoch:0 step:435 [D loss: 0.655485, acc.: 57.03%] [G loss: 1.626711]\n",
      "epoch:0 step:436 [D loss: 0.636567, acc.: 66.41%] [G loss: 1.443949]\n",
      "epoch:0 step:437 [D loss: 0.633111, acc.: 64.06%] [G loss: 1.191515]\n",
      "epoch:0 step:438 [D loss: 0.645952, acc.: 67.97%] [G loss: 1.552081]\n",
      "epoch:0 step:439 [D loss: 0.609478, acc.: 69.53%] [G loss: 1.651677]\n",
      "epoch:0 step:440 [D loss: 0.595051, acc.: 68.75%] [G loss: 1.691314]\n",
      "epoch:0 step:441 [D loss: 0.726306, acc.: 60.16%] [G loss: 1.689477]\n",
      "epoch:0 step:442 [D loss: 0.694855, acc.: 60.16%] [G loss: 1.924991]\n",
      "epoch:0 step:443 [D loss: 0.676646, acc.: 68.75%] [G loss: 1.683575]\n",
      "epoch:0 step:444 [D loss: 0.913636, acc.: 47.66%] [G loss: 1.459199]\n",
      "epoch:0 step:445 [D loss: 0.731196, acc.: 64.06%] [G loss: 1.514557]\n",
      "epoch:0 step:446 [D loss: 0.669700, acc.: 59.38%] [G loss: 1.374167]\n",
      "epoch:0 step:447 [D loss: 0.544829, acc.: 69.53%] [G loss: 1.505589]\n",
      "epoch:0 step:448 [D loss: 0.888966, acc.: 50.78%] [G loss: 1.025181]\n",
      "epoch:0 step:449 [D loss: 0.771576, acc.: 57.81%] [G loss: 1.521468]\n",
      "epoch:0 step:450 [D loss: 0.661954, acc.: 63.28%] [G loss: 1.730654]\n",
      "epoch:0 step:451 [D loss: 0.685358, acc.: 63.28%] [G loss: 1.769752]\n",
      "epoch:0 step:452 [D loss: 0.796899, acc.: 53.91%] [G loss: 1.705337]\n",
      "epoch:0 step:453 [D loss: 0.716680, acc.: 60.94%] [G loss: 1.556014]\n",
      "epoch:0 step:454 [D loss: 0.743424, acc.: 61.72%] [G loss: 1.592555]\n",
      "epoch:0 step:455 [D loss: 0.682151, acc.: 58.59%] [G loss: 1.424708]\n",
      "epoch:0 step:456 [D loss: 0.794543, acc.: 52.34%] [G loss: 1.550039]\n",
      "epoch:0 step:457 [D loss: 0.848008, acc.: 52.34%] [G loss: 1.630556]\n",
      "epoch:0 step:458 [D loss: 0.816504, acc.: 57.03%] [G loss: 1.615581]\n",
      "epoch:0 step:459 [D loss: 0.674685, acc.: 60.16%] [G loss: 1.511324]\n",
      "epoch:0 step:460 [D loss: 0.611064, acc.: 73.44%] [G loss: 1.774359]\n",
      "epoch:0 step:461 [D loss: 0.666970, acc.: 65.62%] [G loss: 1.823042]\n",
      "epoch:0 step:462 [D loss: 0.728874, acc.: 53.12%] [G loss: 1.354281]\n",
      "epoch:0 step:463 [D loss: 0.644180, acc.: 65.62%] [G loss: 1.394566]\n",
      "epoch:0 step:464 [D loss: 0.797917, acc.: 57.03%] [G loss: 1.377143]\n",
      "epoch:0 step:465 [D loss: 0.777827, acc.: 55.47%] [G loss: 1.502972]\n",
      "epoch:0 step:466 [D loss: 0.772084, acc.: 57.81%] [G loss: 1.577426]\n",
      "epoch:0 step:467 [D loss: 0.590220, acc.: 68.75%] [G loss: 1.725947]\n",
      "epoch:0 step:468 [D loss: 0.727443, acc.: 59.38%] [G loss: 1.678920]\n",
      "epoch:0 step:469 [D loss: 0.767333, acc.: 54.69%] [G loss: 1.486194]\n",
      "epoch:0 step:470 [D loss: 0.724239, acc.: 62.50%] [G loss: 1.395776]\n",
      "epoch:0 step:471 [D loss: 0.841612, acc.: 56.25%] [G loss: 1.555211]\n",
      "epoch:0 step:472 [D loss: 0.795000, acc.: 55.47%] [G loss: 1.735357]\n",
      "epoch:0 step:473 [D loss: 0.879262, acc.: 47.66%] [G loss: 1.790878]\n",
      "epoch:0 step:474 [D loss: 0.668243, acc.: 71.09%] [G loss: 1.782204]\n",
      "epoch:0 step:475 [D loss: 0.630816, acc.: 64.84%] [G loss: 1.862897]\n",
      "epoch:0 step:476 [D loss: 0.502777, acc.: 73.44%] [G loss: 1.862932]\n",
      "epoch:0 step:477 [D loss: 0.669560, acc.: 60.94%] [G loss: 1.375218]\n",
      "epoch:0 step:478 [D loss: 0.791091, acc.: 53.12%] [G loss: 1.112327]\n",
      "epoch:0 step:479 [D loss: 0.937276, acc.: 38.28%] [G loss: 1.035163]\n",
      "epoch:0 step:480 [D loss: 0.845503, acc.: 49.22%] [G loss: 1.343473]\n",
      "epoch:0 step:481 [D loss: 0.620008, acc.: 67.97%] [G loss: 1.716746]\n",
      "epoch:0 step:482 [D loss: 0.847062, acc.: 48.44%] [G loss: 1.135912]\n",
      "epoch:0 step:483 [D loss: 0.585219, acc.: 67.19%] [G loss: 1.434021]\n",
      "epoch:0 step:484 [D loss: 0.750703, acc.: 60.16%] [G loss: 1.318973]\n",
      "epoch:0 step:485 [D loss: 0.755212, acc.: 56.25%] [G loss: 1.425777]\n",
      "epoch:0 step:486 [D loss: 0.831513, acc.: 51.56%] [G loss: 1.367992]\n",
      "epoch:0 step:487 [D loss: 0.820952, acc.: 45.31%] [G loss: 1.251710]\n",
      "epoch:0 step:488 [D loss: 0.819840, acc.: 49.22%] [G loss: 1.356212]\n",
      "epoch:0 step:489 [D loss: 0.705195, acc.: 57.81%] [G loss: 1.339921]\n",
      "epoch:0 step:490 [D loss: 0.795266, acc.: 50.78%] [G loss: 1.370123]\n",
      "epoch:0 step:491 [D loss: 0.705819, acc.: 61.72%] [G loss: 1.522474]\n",
      "epoch:0 step:492 [D loss: 0.784383, acc.: 49.22%] [G loss: 1.326669]\n",
      "epoch:0 step:493 [D loss: 0.813761, acc.: 46.88%] [G loss: 1.076638]\n",
      "epoch:0 step:494 [D loss: 0.732384, acc.: 58.59%] [G loss: 1.293104]\n",
      "epoch:0 step:495 [D loss: 0.576881, acc.: 68.75%] [G loss: 1.202124]\n",
      "epoch:0 step:496 [D loss: 0.855518, acc.: 47.66%] [G loss: 1.306684]\n",
      "epoch:0 step:497 [D loss: 0.625967, acc.: 59.38%] [G loss: 1.526891]\n",
      "epoch:0 step:498 [D loss: 0.612484, acc.: 70.31%] [G loss: 1.609377]\n",
      "epoch:0 step:499 [D loss: 0.629813, acc.: 62.50%] [G loss: 1.425549]\n",
      "epoch:0 step:500 [D loss: 0.842807, acc.: 47.66%] [G loss: 1.206265]\n",
      "epoch:0 step:501 [D loss: 0.913996, acc.: 43.75%] [G loss: 1.113692]\n",
      "epoch:0 step:502 [D loss: 0.817142, acc.: 51.56%] [G loss: 1.228460]\n",
      "epoch:0 step:503 [D loss: 0.796951, acc.: 50.78%] [G loss: 1.384631]\n",
      "epoch:0 step:504 [D loss: 0.580967, acc.: 69.53%] [G loss: 1.344461]\n",
      "epoch:0 step:505 [D loss: 0.651943, acc.: 64.84%] [G loss: 1.393958]\n",
      "epoch:0 step:506 [D loss: 0.737848, acc.: 53.91%] [G loss: 1.208762]\n",
      "epoch:0 step:507 [D loss: 0.714617, acc.: 57.03%] [G loss: 1.164490]\n",
      "epoch:0 step:508 [D loss: 0.556059, acc.: 72.66%] [G loss: 1.318688]\n",
      "epoch:0 step:509 [D loss: 0.687728, acc.: 57.81%] [G loss: 1.320279]\n",
      "epoch:0 step:510 [D loss: 0.747611, acc.: 56.25%] [G loss: 1.187077]\n",
      "epoch:0 step:511 [D loss: 0.840146, acc.: 40.62%] [G loss: 1.271976]\n",
      "epoch:0 step:512 [D loss: 0.695587, acc.: 61.72%] [G loss: 1.431654]\n",
      "epoch:0 step:513 [D loss: 0.704677, acc.: 58.59%] [G loss: 1.420272]\n",
      "epoch:0 step:514 [D loss: 0.665211, acc.: 67.97%] [G loss: 1.358270]\n",
      "epoch:0 step:515 [D loss: 0.535804, acc.: 74.22%] [G loss: 1.293159]\n",
      "epoch:0 step:516 [D loss: 0.653976, acc.: 64.06%] [G loss: 1.402366]\n",
      "epoch:0 step:517 [D loss: 0.696887, acc.: 58.59%] [G loss: 1.357307]\n",
      "epoch:0 step:518 [D loss: 0.691302, acc.: 60.16%] [G loss: 1.528120]\n",
      "epoch:0 step:519 [D loss: 0.619387, acc.: 68.75%] [G loss: 1.402093]\n",
      "epoch:0 step:520 [D loss: 0.675082, acc.: 60.16%] [G loss: 1.504978]\n",
      "epoch:0 step:521 [D loss: 0.679418, acc.: 61.72%] [G loss: 1.380542]\n",
      "epoch:0 step:522 [D loss: 0.641815, acc.: 69.53%] [G loss: 1.336252]\n",
      "epoch:0 step:523 [D loss: 0.672306, acc.: 60.94%] [G loss: 1.452580]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:524 [D loss: 0.925295, acc.: 40.62%] [G loss: 1.247818]\n",
      "epoch:0 step:525 [D loss: 0.806517, acc.: 49.22%] [G loss: 1.170649]\n",
      "epoch:0 step:526 [D loss: 0.745082, acc.: 57.03%] [G loss: 1.277666]\n",
      "epoch:0 step:527 [D loss: 0.698325, acc.: 56.25%] [G loss: 1.424925]\n",
      "epoch:0 step:528 [D loss: 0.892142, acc.: 45.31%] [G loss: 1.337242]\n",
      "epoch:0 step:529 [D loss: 0.725078, acc.: 54.69%] [G loss: 1.210642]\n",
      "epoch:0 step:530 [D loss: 0.764995, acc.: 52.34%] [G loss: 1.279660]\n",
      "epoch:0 step:531 [D loss: 0.694312, acc.: 61.72%] [G loss: 1.121397]\n",
      "epoch:0 step:532 [D loss: 0.814815, acc.: 49.22%] [G loss: 1.164724]\n",
      "epoch:0 step:533 [D loss: 0.651377, acc.: 60.16%] [G loss: 1.338800]\n",
      "epoch:0 step:534 [D loss: 0.658575, acc.: 63.28%] [G loss: 1.408483]\n",
      "epoch:0 step:535 [D loss: 0.780995, acc.: 53.91%] [G loss: 1.166743]\n",
      "epoch:0 step:536 [D loss: 0.806029, acc.: 50.78%] [G loss: 1.190088]\n",
      "epoch:0 step:537 [D loss: 0.813239, acc.: 54.69%] [G loss: 1.291651]\n",
      "epoch:0 step:538 [D loss: 0.973115, acc.: 40.62%] [G loss: 1.210639]\n",
      "epoch:0 step:539 [D loss: 0.757383, acc.: 53.91%] [G loss: 1.110864]\n",
      "epoch:0 step:540 [D loss: 0.844059, acc.: 45.31%] [G loss: 1.207949]\n",
      "epoch:0 step:541 [D loss: 0.785439, acc.: 46.88%] [G loss: 1.212338]\n",
      "epoch:0 step:542 [D loss: 0.807094, acc.: 46.09%] [G loss: 1.115641]\n",
      "epoch:0 step:543 [D loss: 0.772003, acc.: 55.47%] [G loss: 1.167120]\n",
      "epoch:0 step:544 [D loss: 0.714901, acc.: 53.12%] [G loss: 1.198854]\n",
      "epoch:0 step:545 [D loss: 0.689718, acc.: 60.16%] [G loss: 1.221974]\n",
      "epoch:0 step:546 [D loss: 0.619297, acc.: 65.62%] [G loss: 1.390730]\n",
      "epoch:0 step:547 [D loss: 0.698938, acc.: 61.72%] [G loss: 1.356598]\n",
      "epoch:0 step:548 [D loss: 0.647186, acc.: 64.06%] [G loss: 1.478484]\n",
      "epoch:0 step:549 [D loss: 0.730584, acc.: 57.81%] [G loss: 1.154105]\n",
      "epoch:0 step:550 [D loss: 0.853706, acc.: 39.84%] [G loss: 1.219653]\n",
      "epoch:0 step:551 [D loss: 0.691095, acc.: 59.38%] [G loss: 1.435937]\n",
      "epoch:0 step:552 [D loss: 0.722359, acc.: 54.69%] [G loss: 1.339338]\n",
      "epoch:0 step:553 [D loss: 0.783374, acc.: 53.91%] [G loss: 1.470454]\n",
      "epoch:0 step:554 [D loss: 0.655774, acc.: 62.50%] [G loss: 1.256876]\n",
      "epoch:0 step:555 [D loss: 0.708903, acc.: 57.03%] [G loss: 1.120481]\n",
      "epoch:0 step:556 [D loss: 0.726874, acc.: 56.25%] [G loss: 1.317756]\n",
      "epoch:0 step:557 [D loss: 0.695742, acc.: 58.59%] [G loss: 1.422300]\n",
      "epoch:0 step:558 [D loss: 0.669165, acc.: 60.94%] [G loss: 1.316957]\n",
      "epoch:0 step:559 [D loss: 0.766482, acc.: 46.09%] [G loss: 1.229975]\n",
      "epoch:0 step:560 [D loss: 0.792852, acc.: 50.78%] [G loss: 1.107066]\n",
      "epoch:0 step:561 [D loss: 0.612692, acc.: 67.97%] [G loss: 1.359609]\n",
      "epoch:0 step:562 [D loss: 0.727972, acc.: 59.38%] [G loss: 1.269473]\n",
      "epoch:0 step:563 [D loss: 0.682046, acc.: 62.50%] [G loss: 1.125703]\n",
      "epoch:0 step:564 [D loss: 0.676180, acc.: 57.81%] [G loss: 1.274863]\n",
      "epoch:0 step:565 [D loss: 0.822191, acc.: 45.31%] [G loss: 1.254231]\n",
      "epoch:0 step:566 [D loss: 0.806137, acc.: 50.00%] [G loss: 1.496593]\n",
      "epoch:0 step:567 [D loss: 0.708604, acc.: 57.03%] [G loss: 1.691315]\n",
      "epoch:0 step:568 [D loss: 0.557646, acc.: 71.88%] [G loss: 1.536008]\n",
      "epoch:0 step:569 [D loss: 0.801378, acc.: 52.34%] [G loss: 1.208200]\n",
      "epoch:0 step:570 [D loss: 0.676454, acc.: 63.28%] [G loss: 1.161700]\n",
      "epoch:0 step:571 [D loss: 0.762766, acc.: 47.66%] [G loss: 1.221599]\n",
      "epoch:0 step:572 [D loss: 0.698976, acc.: 60.94%] [G loss: 1.163175]\n",
      "epoch:0 step:573 [D loss: 0.733391, acc.: 53.12%] [G loss: 1.283514]\n",
      "epoch:0 step:574 [D loss: 0.655365, acc.: 62.50%] [G loss: 1.213945]\n",
      "epoch:0 step:575 [D loss: 0.818927, acc.: 47.66%] [G loss: 1.271492]\n",
      "epoch:0 step:576 [D loss: 0.823884, acc.: 47.66%] [G loss: 1.302917]\n",
      "epoch:0 step:577 [D loss: 0.704655, acc.: 59.38%] [G loss: 1.349947]\n",
      "epoch:0 step:578 [D loss: 0.708625, acc.: 59.38%] [G loss: 1.295671]\n",
      "epoch:0 step:579 [D loss: 0.699506, acc.: 57.03%] [G loss: 1.314109]\n",
      "epoch:0 step:580 [D loss: 0.719069, acc.: 55.47%] [G loss: 1.226691]\n",
      "epoch:0 step:581 [D loss: 0.723117, acc.: 58.59%] [G loss: 1.101239]\n",
      "epoch:0 step:582 [D loss: 0.725110, acc.: 59.38%] [G loss: 1.257555]\n",
      "epoch:0 step:583 [D loss: 0.771510, acc.: 52.34%] [G loss: 1.231666]\n",
      "epoch:0 step:584 [D loss: 0.666497, acc.: 63.28%] [G loss: 1.222435]\n",
      "epoch:0 step:585 [D loss: 0.775135, acc.: 53.91%] [G loss: 1.073820]\n",
      "epoch:0 step:586 [D loss: 0.640656, acc.: 63.28%] [G loss: 1.207875]\n",
      "epoch:0 step:587 [D loss: 0.648699, acc.: 60.16%] [G loss: 1.403378]\n",
      "epoch:0 step:588 [D loss: 0.709115, acc.: 57.81%] [G loss: 1.307735]\n",
      "epoch:0 step:589 [D loss: 0.560109, acc.: 68.75%] [G loss: 1.591315]\n",
      "epoch:0 step:590 [D loss: 0.803568, acc.: 53.91%] [G loss: 1.351601]\n",
      "epoch:0 step:591 [D loss: 0.673516, acc.: 61.72%] [G loss: 1.525287]\n",
      "epoch:0 step:592 [D loss: 0.669524, acc.: 69.53%] [G loss: 1.164231]\n",
      "epoch:0 step:593 [D loss: 0.771691, acc.: 53.91%] [G loss: 1.280715]\n",
      "epoch:0 step:594 [D loss: 0.777864, acc.: 46.88%] [G loss: 1.368647]\n",
      "epoch:0 step:595 [D loss: 0.724172, acc.: 55.47%] [G loss: 1.090394]\n",
      "epoch:0 step:596 [D loss: 0.818230, acc.: 51.56%] [G loss: 1.201952]\n",
      "epoch:0 step:597 [D loss: 0.847180, acc.: 45.31%] [G loss: 1.199819]\n",
      "epoch:0 step:598 [D loss: 0.701372, acc.: 60.16%] [G loss: 1.176764]\n",
      "epoch:0 step:599 [D loss: 0.792585, acc.: 45.31%] [G loss: 1.142739]\n",
      "epoch:0 step:600 [D loss: 0.828328, acc.: 48.44%] [G loss: 1.197307]\n",
      "##############\n",
      "[4.25151213 2.37304618 6.59233457 5.6168622  4.69403129 6.16897699\n",
      " 5.3444567  5.30235704 5.01683604 4.65103381]\n",
      "##########\n",
      "epoch:0 step:601 [D loss: 0.779457, acc.: 44.53%] [G loss: 1.393741]\n",
      "epoch:0 step:602 [D loss: 0.689074, acc.: 60.16%] [G loss: 1.333517]\n",
      "epoch:0 step:603 [D loss: 0.718437, acc.: 57.03%] [G loss: 1.164932]\n",
      "epoch:0 step:604 [D loss: 0.772277, acc.: 51.56%] [G loss: 1.129971]\n",
      "epoch:0 step:605 [D loss: 0.686978, acc.: 61.72%] [G loss: 1.481528]\n",
      "epoch:0 step:606 [D loss: 0.809790, acc.: 42.97%] [G loss: 1.178224]\n",
      "epoch:0 step:607 [D loss: 0.804644, acc.: 46.88%] [G loss: 1.125919]\n",
      "epoch:0 step:608 [D loss: 0.739063, acc.: 57.03%] [G loss: 1.105621]\n",
      "epoch:0 step:609 [D loss: 0.732779, acc.: 53.12%] [G loss: 1.224531]\n",
      "epoch:0 step:610 [D loss: 0.688086, acc.: 57.81%] [G loss: 1.350920]\n",
      "epoch:0 step:611 [D loss: 0.647247, acc.: 59.38%] [G loss: 1.182060]\n",
      "epoch:0 step:612 [D loss: 0.638527, acc.: 65.62%] [G loss: 1.076096]\n",
      "epoch:0 step:613 [D loss: 0.714656, acc.: 52.34%] [G loss: 1.130086]\n",
      "epoch:0 step:614 [D loss: 0.736365, acc.: 55.47%] [G loss: 1.093906]\n",
      "epoch:0 step:615 [D loss: 0.777903, acc.: 50.78%] [G loss: 1.116274]\n",
      "epoch:0 step:616 [D loss: 0.794897, acc.: 53.91%] [G loss: 1.143680]\n",
      "epoch:0 step:617 [D loss: 0.717072, acc.: 61.72%] [G loss: 1.217037]\n",
      "epoch:0 step:618 [D loss: 0.710571, acc.: 57.81%] [G loss: 1.087538]\n",
      "epoch:0 step:619 [D loss: 0.704781, acc.: 61.72%] [G loss: 1.270460]\n",
      "epoch:0 step:620 [D loss: 0.673029, acc.: 58.59%] [G loss: 1.376656]\n",
      "epoch:0 step:621 [D loss: 0.768191, acc.: 51.56%] [G loss: 1.083954]\n",
      "epoch:0 step:622 [D loss: 0.769337, acc.: 51.56%] [G loss: 1.092948]\n",
      "epoch:0 step:623 [D loss: 0.738155, acc.: 50.78%] [G loss: 1.109845]\n",
      "epoch:0 step:624 [D loss: 0.605000, acc.: 65.62%] [G loss: 1.173844]\n",
      "epoch:0 step:625 [D loss: 0.786597, acc.: 55.47%] [G loss: 0.976277]\n",
      "epoch:0 step:626 [D loss: 0.747516, acc.: 52.34%] [G loss: 1.208362]\n",
      "epoch:0 step:627 [D loss: 0.656735, acc.: 60.94%] [G loss: 1.373618]\n",
      "epoch:0 step:628 [D loss: 0.686196, acc.: 59.38%] [G loss: 1.403536]\n",
      "epoch:0 step:629 [D loss: 0.773692, acc.: 54.69%] [G loss: 1.268232]\n",
      "epoch:0 step:630 [D loss: 0.645437, acc.: 60.94%] [G loss: 1.248734]\n",
      "epoch:0 step:631 [D loss: 0.683915, acc.: 63.28%] [G loss: 1.342600]\n",
      "epoch:0 step:632 [D loss: 0.652921, acc.: 64.06%] [G loss: 1.357667]\n",
      "epoch:0 step:633 [D loss: 0.588374, acc.: 69.53%] [G loss: 1.398289]\n",
      "epoch:0 step:634 [D loss: 0.698202, acc.: 62.50%] [G loss: 1.150910]\n",
      "epoch:0 step:635 [D loss: 0.725142, acc.: 53.91%] [G loss: 1.073392]\n",
      "epoch:0 step:636 [D loss: 0.776908, acc.: 55.47%] [G loss: 1.239704]\n",
      "epoch:0 step:637 [D loss: 0.732791, acc.: 56.25%] [G loss: 1.088302]\n",
      "epoch:0 step:638 [D loss: 0.805212, acc.: 50.00%] [G loss: 1.183821]\n",
      "epoch:0 step:639 [D loss: 0.771379, acc.: 53.91%] [G loss: 1.363140]\n",
      "epoch:0 step:640 [D loss: 0.828419, acc.: 44.53%] [G loss: 1.192739]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:641 [D loss: 0.770862, acc.: 55.47%] [G loss: 1.327216]\n",
      "epoch:0 step:642 [D loss: 0.718242, acc.: 57.81%] [G loss: 1.267416]\n",
      "epoch:0 step:643 [D loss: 0.799421, acc.: 51.56%] [G loss: 1.225229]\n",
      "epoch:0 step:644 [D loss: 0.774315, acc.: 60.16%] [G loss: 1.093960]\n",
      "epoch:0 step:645 [D loss: 0.783470, acc.: 47.66%] [G loss: 1.102951]\n",
      "epoch:0 step:646 [D loss: 0.669821, acc.: 53.91%] [G loss: 1.425674]\n",
      "epoch:0 step:647 [D loss: 0.742266, acc.: 57.03%] [G loss: 1.287320]\n",
      "epoch:0 step:648 [D loss: 0.651742, acc.: 58.59%] [G loss: 1.198528]\n",
      "epoch:0 step:649 [D loss: 0.696305, acc.: 59.38%] [G loss: 1.088075]\n",
      "epoch:0 step:650 [D loss: 0.625568, acc.: 62.50%] [G loss: 1.162708]\n",
      "epoch:0 step:651 [D loss: 0.731089, acc.: 57.03%] [G loss: 1.262030]\n",
      "epoch:0 step:652 [D loss: 0.878367, acc.: 39.84%] [G loss: 1.116667]\n",
      "epoch:0 step:653 [D loss: 0.807914, acc.: 42.97%] [G loss: 1.214954]\n",
      "epoch:0 step:654 [D loss: 0.646982, acc.: 61.72%] [G loss: 1.368201]\n",
      "epoch:0 step:655 [D loss: 0.667102, acc.: 59.38%] [G loss: 1.444875]\n",
      "epoch:0 step:656 [D loss: 0.767735, acc.: 50.00%] [G loss: 1.158441]\n",
      "epoch:0 step:657 [D loss: 0.609254, acc.: 70.31%] [G loss: 1.310622]\n",
      "epoch:0 step:658 [D loss: 0.667165, acc.: 58.59%] [G loss: 1.195814]\n",
      "epoch:0 step:659 [D loss: 0.663619, acc.: 64.84%] [G loss: 1.017656]\n",
      "epoch:0 step:660 [D loss: 0.797141, acc.: 49.22%] [G loss: 1.221506]\n",
      "epoch:0 step:661 [D loss: 0.671005, acc.: 64.06%] [G loss: 1.307178]\n",
      "epoch:0 step:662 [D loss: 0.826090, acc.: 51.56%] [G loss: 1.131196]\n",
      "epoch:0 step:663 [D loss: 0.760040, acc.: 54.69%] [G loss: 1.341488]\n",
      "epoch:0 step:664 [D loss: 0.706353, acc.: 56.25%] [G loss: 1.269746]\n",
      "epoch:0 step:665 [D loss: 0.701605, acc.: 64.06%] [G loss: 1.218388]\n",
      "epoch:0 step:666 [D loss: 0.794738, acc.: 57.03%] [G loss: 0.969475]\n",
      "epoch:0 step:667 [D loss: 0.778352, acc.: 50.78%] [G loss: 1.053873]\n",
      "epoch:0 step:668 [D loss: 0.739792, acc.: 53.12%] [G loss: 1.135845]\n",
      "epoch:0 step:669 [D loss: 0.718622, acc.: 49.22%] [G loss: 1.053169]\n",
      "epoch:0 step:670 [D loss: 0.770612, acc.: 51.56%] [G loss: 1.107162]\n",
      "epoch:0 step:671 [D loss: 0.693323, acc.: 60.16%] [G loss: 1.158583]\n",
      "epoch:0 step:672 [D loss: 0.691732, acc.: 59.38%] [G loss: 1.223428]\n",
      "epoch:0 step:673 [D loss: 0.665120, acc.: 61.72%] [G loss: 1.245486]\n",
      "epoch:0 step:674 [D loss: 0.680070, acc.: 58.59%] [G loss: 1.140215]\n",
      "epoch:0 step:675 [D loss: 0.732347, acc.: 54.69%] [G loss: 1.269998]\n",
      "epoch:0 step:676 [D loss: 0.709405, acc.: 58.59%] [G loss: 1.079365]\n",
      "epoch:0 step:677 [D loss: 0.647692, acc.: 65.62%] [G loss: 1.083651]\n",
      "epoch:0 step:678 [D loss: 0.769981, acc.: 46.88%] [G loss: 1.238402]\n",
      "epoch:0 step:679 [D loss: 0.698251, acc.: 57.81%] [G loss: 1.275408]\n",
      "epoch:0 step:680 [D loss: 0.794366, acc.: 46.88%] [G loss: 1.081278]\n",
      "epoch:0 step:681 [D loss: 0.818600, acc.: 52.34%] [G loss: 1.168232]\n",
      "epoch:0 step:682 [D loss: 0.816919, acc.: 53.12%] [G loss: 1.139812]\n",
      "epoch:0 step:683 [D loss: 0.682065, acc.: 61.72%] [G loss: 1.044286]\n",
      "epoch:0 step:684 [D loss: 0.656632, acc.: 62.50%] [G loss: 1.167772]\n",
      "epoch:0 step:685 [D loss: 0.696712, acc.: 62.50%] [G loss: 1.186521]\n",
      "epoch:0 step:686 [D loss: 0.748171, acc.: 51.56%] [G loss: 1.129024]\n",
      "epoch:0 step:687 [D loss: 0.701853, acc.: 61.72%] [G loss: 1.109550]\n",
      "epoch:0 step:688 [D loss: 0.628951, acc.: 61.72%] [G loss: 1.247763]\n",
      "epoch:0 step:689 [D loss: 0.767124, acc.: 53.91%] [G loss: 1.088977]\n",
      "epoch:0 step:690 [D loss: 0.711788, acc.: 51.56%] [G loss: 1.165833]\n",
      "epoch:0 step:691 [D loss: 0.751734, acc.: 53.91%] [G loss: 1.165320]\n",
      "epoch:0 step:692 [D loss: 0.726946, acc.: 55.47%] [G loss: 1.054166]\n",
      "epoch:0 step:693 [D loss: 0.687674, acc.: 60.16%] [G loss: 1.294488]\n",
      "epoch:0 step:694 [D loss: 0.671675, acc.: 53.91%] [G loss: 1.277565]\n",
      "epoch:0 step:695 [D loss: 0.772671, acc.: 57.03%] [G loss: 1.353412]\n",
      "epoch:0 step:696 [D loss: 0.765926, acc.: 49.22%] [G loss: 1.190220]\n",
      "epoch:0 step:697 [D loss: 0.690444, acc.: 59.38%] [G loss: 1.190587]\n",
      "epoch:0 step:698 [D loss: 0.685415, acc.: 60.94%] [G loss: 1.206410]\n",
      "epoch:0 step:699 [D loss: 0.753565, acc.: 50.00%] [G loss: 1.147989]\n",
      "epoch:0 step:700 [D loss: 0.733907, acc.: 46.88%] [G loss: 0.967900]\n",
      "epoch:0 step:701 [D loss: 0.718575, acc.: 57.81%] [G loss: 1.101187]\n",
      "epoch:0 step:702 [D loss: 0.760361, acc.: 49.22%] [G loss: 1.219376]\n",
      "epoch:0 step:703 [D loss: 0.828978, acc.: 50.00%] [G loss: 1.129044]\n",
      "epoch:0 step:704 [D loss: 0.712276, acc.: 53.12%] [G loss: 0.947490]\n",
      "epoch:0 step:705 [D loss: 0.669594, acc.: 58.59%] [G loss: 1.224681]\n",
      "epoch:0 step:706 [D loss: 0.707364, acc.: 57.81%] [G loss: 1.088991]\n",
      "epoch:0 step:707 [D loss: 0.674728, acc.: 59.38%] [G loss: 1.190248]\n",
      "epoch:0 step:708 [D loss: 0.619802, acc.: 67.97%] [G loss: 1.231238]\n",
      "epoch:0 step:709 [D loss: 0.681815, acc.: 60.16%] [G loss: 1.234417]\n",
      "epoch:0 step:710 [D loss: 0.776058, acc.: 52.34%] [G loss: 1.120942]\n",
      "epoch:0 step:711 [D loss: 0.746690, acc.: 54.69%] [G loss: 1.070662]\n",
      "epoch:0 step:712 [D loss: 0.713617, acc.: 51.56%] [G loss: 1.041597]\n",
      "epoch:0 step:713 [D loss: 0.780189, acc.: 53.12%] [G loss: 1.091879]\n",
      "epoch:0 step:714 [D loss: 0.698863, acc.: 57.81%] [G loss: 1.295682]\n",
      "epoch:0 step:715 [D loss: 0.787683, acc.: 53.91%] [G loss: 1.247743]\n",
      "epoch:0 step:716 [D loss: 0.761460, acc.: 50.00%] [G loss: 1.126409]\n",
      "epoch:0 step:717 [D loss: 0.725998, acc.: 60.16%] [G loss: 1.255501]\n",
      "epoch:0 step:718 [D loss: 0.678608, acc.: 55.47%] [G loss: 1.314202]\n",
      "epoch:0 step:719 [D loss: 0.772418, acc.: 53.12%] [G loss: 1.161404]\n",
      "epoch:0 step:720 [D loss: 0.761580, acc.: 50.00%] [G loss: 1.103633]\n",
      "epoch:0 step:721 [D loss: 0.759198, acc.: 51.56%] [G loss: 0.998274]\n",
      "epoch:0 step:722 [D loss: 0.849768, acc.: 40.62%] [G loss: 1.215235]\n",
      "epoch:0 step:723 [D loss: 0.734776, acc.: 50.00%] [G loss: 1.176831]\n",
      "epoch:0 step:724 [D loss: 0.677868, acc.: 57.03%] [G loss: 1.152347]\n",
      "epoch:0 step:725 [D loss: 0.740052, acc.: 52.34%] [G loss: 1.305555]\n",
      "epoch:0 step:726 [D loss: 0.630637, acc.: 60.16%] [G loss: 1.317846]\n",
      "epoch:0 step:727 [D loss: 0.680296, acc.: 57.81%] [G loss: 1.226629]\n",
      "epoch:0 step:728 [D loss: 0.654378, acc.: 61.72%] [G loss: 1.213795]\n",
      "epoch:0 step:729 [D loss: 0.570831, acc.: 71.09%] [G loss: 1.255841]\n",
      "epoch:0 step:730 [D loss: 0.641868, acc.: 67.97%] [G loss: 1.201099]\n",
      "epoch:0 step:731 [D loss: 0.738660, acc.: 56.25%] [G loss: 1.253946]\n",
      "epoch:0 step:732 [D loss: 0.679752, acc.: 60.16%] [G loss: 1.213651]\n",
      "epoch:0 step:733 [D loss: 0.644523, acc.: 66.41%] [G loss: 1.133587]\n",
      "epoch:0 step:734 [D loss: 0.781998, acc.: 52.34%] [G loss: 1.005830]\n",
      "epoch:0 step:735 [D loss: 0.879988, acc.: 39.84%] [G loss: 0.942358]\n",
      "epoch:0 step:736 [D loss: 0.813820, acc.: 42.19%] [G loss: 0.912961]\n",
      "epoch:0 step:737 [D loss: 0.675732, acc.: 59.38%] [G loss: 1.078743]\n",
      "epoch:0 step:738 [D loss: 0.722385, acc.: 55.47%] [G loss: 1.097557]\n",
      "epoch:0 step:739 [D loss: 0.739466, acc.: 52.34%] [G loss: 1.200976]\n",
      "epoch:0 step:740 [D loss: 0.711884, acc.: 58.59%] [G loss: 1.156821]\n",
      "epoch:0 step:741 [D loss: 0.735866, acc.: 53.12%] [G loss: 1.082639]\n",
      "epoch:0 step:742 [D loss: 0.797082, acc.: 51.56%] [G loss: 1.059644]\n",
      "epoch:0 step:743 [D loss: 0.680331, acc.: 60.16%] [G loss: 1.043354]\n",
      "epoch:0 step:744 [D loss: 0.717936, acc.: 53.12%] [G loss: 1.011421]\n",
      "epoch:0 step:745 [D loss: 0.810264, acc.: 43.75%] [G loss: 1.142401]\n",
      "epoch:0 step:746 [D loss: 0.769636, acc.: 50.00%] [G loss: 1.218339]\n",
      "epoch:0 step:747 [D loss: 0.644248, acc.: 65.62%] [G loss: 1.256834]\n",
      "epoch:0 step:748 [D loss: 0.778783, acc.: 53.91%] [G loss: 1.198919]\n",
      "epoch:0 step:749 [D loss: 0.649156, acc.: 62.50%] [G loss: 1.323536]\n",
      "epoch:0 step:750 [D loss: 0.766049, acc.: 54.69%] [G loss: 1.123025]\n",
      "epoch:0 step:751 [D loss: 0.672446, acc.: 55.47%] [G loss: 1.090470]\n",
      "epoch:0 step:752 [D loss: 0.765888, acc.: 50.00%] [G loss: 1.035652]\n",
      "epoch:0 step:753 [D loss: 0.688000, acc.: 57.03%] [G loss: 1.135913]\n",
      "epoch:0 step:754 [D loss: 0.701826, acc.: 55.47%] [G loss: 1.211445]\n",
      "epoch:0 step:755 [D loss: 0.656959, acc.: 55.47%] [G loss: 1.235242]\n",
      "epoch:0 step:756 [D loss: 0.684409, acc.: 60.94%] [G loss: 1.156001]\n",
      "epoch:0 step:757 [D loss: 0.668505, acc.: 55.47%] [G loss: 1.213846]\n",
      "epoch:0 step:758 [D loss: 0.698178, acc.: 58.59%] [G loss: 0.901800]\n",
      "epoch:0 step:759 [D loss: 0.781905, acc.: 48.44%] [G loss: 1.265730]\n",
      "epoch:0 step:760 [D loss: 0.822251, acc.: 48.44%] [G loss: 1.071596]\n",
      "epoch:0 step:761 [D loss: 0.762540, acc.: 49.22%] [G loss: 1.022211]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:762 [D loss: 0.757184, acc.: 49.22%] [G loss: 1.044595]\n",
      "epoch:0 step:763 [D loss: 0.746400, acc.: 55.47%] [G loss: 1.036877]\n",
      "epoch:0 step:764 [D loss: 0.691395, acc.: 54.69%] [G loss: 1.334570]\n",
      "epoch:0 step:765 [D loss: 0.681881, acc.: 58.59%] [G loss: 1.156225]\n",
      "epoch:0 step:766 [D loss: 0.766417, acc.: 47.66%] [G loss: 1.120855]\n",
      "epoch:0 step:767 [D loss: 0.728676, acc.: 59.38%] [G loss: 1.202816]\n",
      "epoch:0 step:768 [D loss: 0.745723, acc.: 53.12%] [G loss: 1.157354]\n",
      "epoch:0 step:769 [D loss: 0.759093, acc.: 47.66%] [G loss: 1.154902]\n",
      "epoch:0 step:770 [D loss: 0.790047, acc.: 54.69%] [G loss: 1.108508]\n",
      "epoch:0 step:771 [D loss: 0.778085, acc.: 49.22%] [G loss: 1.173944]\n",
      "epoch:0 step:772 [D loss: 0.722952, acc.: 55.47%] [G loss: 1.139531]\n",
      "epoch:0 step:773 [D loss: 0.702801, acc.: 59.38%] [G loss: 1.060403]\n",
      "epoch:0 step:774 [D loss: 0.712125, acc.: 53.12%] [G loss: 1.153224]\n",
      "epoch:0 step:775 [D loss: 0.647403, acc.: 63.28%] [G loss: 1.219520]\n",
      "epoch:0 step:776 [D loss: 0.783913, acc.: 51.56%] [G loss: 0.933926]\n",
      "epoch:0 step:777 [D loss: 0.762011, acc.: 44.53%] [G loss: 0.896672]\n",
      "epoch:0 step:778 [D loss: 0.733984, acc.: 53.91%] [G loss: 0.985263]\n",
      "epoch:0 step:779 [D loss: 0.774039, acc.: 53.12%] [G loss: 1.155178]\n",
      "epoch:0 step:780 [D loss: 0.782791, acc.: 51.56%] [G loss: 1.029052]\n",
      "epoch:0 step:781 [D loss: 0.629918, acc.: 68.75%] [G loss: 1.312077]\n",
      "epoch:0 step:782 [D loss: 0.619036, acc.: 67.97%] [G loss: 1.273649]\n",
      "epoch:0 step:783 [D loss: 0.766976, acc.: 53.12%] [G loss: 1.227788]\n",
      "epoch:0 step:784 [D loss: 0.765312, acc.: 52.34%] [G loss: 1.030393]\n",
      "epoch:0 step:785 [D loss: 0.625079, acc.: 64.06%] [G loss: 1.160914]\n",
      "epoch:0 step:786 [D loss: 0.588881, acc.: 71.88%] [G loss: 1.092295]\n",
      "epoch:0 step:787 [D loss: 0.693698, acc.: 59.38%] [G loss: 1.296978]\n",
      "epoch:0 step:788 [D loss: 0.702084, acc.: 57.81%] [G loss: 1.179936]\n",
      "epoch:0 step:789 [D loss: 0.789359, acc.: 49.22%] [G loss: 1.180444]\n",
      "epoch:0 step:790 [D loss: 0.692851, acc.: 52.34%] [G loss: 1.298052]\n",
      "epoch:0 step:791 [D loss: 0.880712, acc.: 39.06%] [G loss: 1.191313]\n",
      "epoch:0 step:792 [D loss: 0.675386, acc.: 61.72%] [G loss: 1.195800]\n",
      "epoch:0 step:793 [D loss: 0.794275, acc.: 49.22%] [G loss: 1.129835]\n",
      "epoch:0 step:794 [D loss: 0.722654, acc.: 54.69%] [G loss: 1.188058]\n",
      "epoch:0 step:795 [D loss: 0.627880, acc.: 64.06%] [G loss: 1.335979]\n",
      "epoch:0 step:796 [D loss: 0.673334, acc.: 60.94%] [G loss: 1.176682]\n",
      "epoch:0 step:797 [D loss: 0.838743, acc.: 42.19%] [G loss: 1.003573]\n",
      "epoch:0 step:798 [D loss: 0.720445, acc.: 54.69%] [G loss: 1.168858]\n",
      "epoch:0 step:799 [D loss: 0.763646, acc.: 49.22%] [G loss: 1.180894]\n",
      "epoch:0 step:800 [D loss: 0.817798, acc.: 44.53%] [G loss: 0.987863]\n",
      "##############\n",
      "[4.02815024 2.2470761  6.48909687 5.612714   4.1383542  6.02454179\n",
      " 5.50179921 4.88983116 5.18610807 4.56128481]\n",
      "##########\n",
      "epoch:0 step:801 [D loss: 0.790399, acc.: 46.88%] [G loss: 0.975364]\n",
      "epoch:0 step:802 [D loss: 0.637348, acc.: 64.06%] [G loss: 1.292366]\n",
      "epoch:0 step:803 [D loss: 0.716086, acc.: 54.69%] [G loss: 1.161602]\n",
      "epoch:0 step:804 [D loss: 0.741565, acc.: 52.34%] [G loss: 1.063302]\n",
      "epoch:0 step:805 [D loss: 0.616245, acc.: 64.06%] [G loss: 1.199409]\n",
      "epoch:0 step:806 [D loss: 0.644962, acc.: 60.94%] [G loss: 1.071793]\n",
      "epoch:0 step:807 [D loss: 0.715528, acc.: 57.03%] [G loss: 1.249315]\n",
      "epoch:0 step:808 [D loss: 0.822148, acc.: 47.66%] [G loss: 1.009075]\n",
      "epoch:0 step:809 [D loss: 0.752594, acc.: 51.56%] [G loss: 1.172437]\n",
      "epoch:0 step:810 [D loss: 0.692355, acc.: 59.38%] [G loss: 1.254875]\n",
      "epoch:0 step:811 [D loss: 0.846280, acc.: 42.97%] [G loss: 1.033161]\n",
      "epoch:0 step:812 [D loss: 0.740858, acc.: 51.56%] [G loss: 0.967564]\n",
      "epoch:0 step:813 [D loss: 0.801561, acc.: 46.88%] [G loss: 0.992919]\n",
      "epoch:0 step:814 [D loss: 0.773299, acc.: 55.47%] [G loss: 1.073623]\n",
      "epoch:0 step:815 [D loss: 0.728999, acc.: 52.34%] [G loss: 1.065254]\n",
      "epoch:0 step:816 [D loss: 0.762215, acc.: 57.03%] [G loss: 1.038779]\n",
      "epoch:0 step:817 [D loss: 0.749068, acc.: 53.12%] [G loss: 1.036207]\n",
      "epoch:0 step:818 [D loss: 0.814571, acc.: 47.66%] [G loss: 1.071430]\n",
      "epoch:0 step:819 [D loss: 0.748170, acc.: 53.91%] [G loss: 1.089434]\n",
      "epoch:0 step:820 [D loss: 0.654077, acc.: 65.62%] [G loss: 1.088767]\n",
      "epoch:0 step:821 [D loss: 0.674806, acc.: 51.56%] [G loss: 1.124538]\n",
      "epoch:0 step:822 [D loss: 0.663445, acc.: 62.50%] [G loss: 1.124176]\n",
      "epoch:0 step:823 [D loss: 0.688556, acc.: 60.16%] [G loss: 1.083881]\n",
      "epoch:0 step:824 [D loss: 0.821623, acc.: 34.38%] [G loss: 1.139678]\n",
      "epoch:0 step:825 [D loss: 0.739232, acc.: 56.25%] [G loss: 1.025648]\n",
      "epoch:0 step:826 [D loss: 0.742610, acc.: 46.88%] [G loss: 1.083180]\n",
      "epoch:0 step:827 [D loss: 0.713089, acc.: 51.56%] [G loss: 1.140736]\n",
      "epoch:0 step:828 [D loss: 0.761439, acc.: 50.78%] [G loss: 1.120423]\n",
      "epoch:0 step:829 [D loss: 0.664324, acc.: 60.16%] [G loss: 1.032500]\n",
      "epoch:0 step:830 [D loss: 0.743881, acc.: 53.12%] [G loss: 0.952079]\n",
      "epoch:0 step:831 [D loss: 0.746505, acc.: 48.44%] [G loss: 1.063088]\n",
      "epoch:0 step:832 [D loss: 0.705886, acc.: 59.38%] [G loss: 1.130979]\n",
      "epoch:0 step:833 [D loss: 0.740554, acc.: 54.69%] [G loss: 1.187236]\n",
      "epoch:0 step:834 [D loss: 0.711787, acc.: 55.47%] [G loss: 0.984661]\n",
      "epoch:0 step:835 [D loss: 0.700695, acc.: 57.03%] [G loss: 1.134338]\n",
      "epoch:0 step:836 [D loss: 0.684204, acc.: 59.38%] [G loss: 1.141020]\n",
      "epoch:0 step:837 [D loss: 0.621390, acc.: 63.28%] [G loss: 1.194180]\n",
      "epoch:0 step:838 [D loss: 0.656397, acc.: 63.28%] [G loss: 1.182421]\n",
      "epoch:0 step:839 [D loss: 0.757860, acc.: 52.34%] [G loss: 1.198498]\n",
      "epoch:0 step:840 [D loss: 0.779111, acc.: 52.34%] [G loss: 0.924146]\n",
      "epoch:0 step:841 [D loss: 0.786568, acc.: 47.66%] [G loss: 0.926877]\n",
      "epoch:0 step:842 [D loss: 0.726876, acc.: 56.25%] [G loss: 1.065201]\n",
      "epoch:0 step:843 [D loss: 0.780227, acc.: 53.12%] [G loss: 1.049281]\n",
      "epoch:0 step:844 [D loss: 0.728181, acc.: 54.69%] [G loss: 1.108289]\n",
      "epoch:0 step:845 [D loss: 0.680535, acc.: 60.94%] [G loss: 1.117682]\n",
      "epoch:0 step:846 [D loss: 0.628070, acc.: 62.50%] [G loss: 1.278841]\n",
      "epoch:0 step:847 [D loss: 0.665637, acc.: 61.72%] [G loss: 1.120017]\n",
      "epoch:0 step:848 [D loss: 0.712430, acc.: 49.22%] [G loss: 0.984040]\n",
      "epoch:0 step:849 [D loss: 0.751723, acc.: 49.22%] [G loss: 0.942526]\n",
      "epoch:0 step:850 [D loss: 0.798334, acc.: 43.75%] [G loss: 1.087071]\n",
      "epoch:0 step:851 [D loss: 0.715322, acc.: 57.03%] [G loss: 1.067317]\n",
      "epoch:0 step:852 [D loss: 0.783614, acc.: 48.44%] [G loss: 1.102286]\n",
      "epoch:0 step:853 [D loss: 0.705671, acc.: 49.22%] [G loss: 1.251072]\n",
      "epoch:0 step:854 [D loss: 0.754730, acc.: 50.78%] [G loss: 1.000599]\n",
      "epoch:0 step:855 [D loss: 0.733568, acc.: 54.69%] [G loss: 1.001087]\n",
      "epoch:0 step:856 [D loss: 0.742566, acc.: 51.56%] [G loss: 1.069983]\n",
      "epoch:0 step:857 [D loss: 0.689391, acc.: 58.59%] [G loss: 1.081852]\n",
      "epoch:0 step:858 [D loss: 0.754513, acc.: 52.34%] [G loss: 1.195522]\n",
      "epoch:0 step:859 [D loss: 0.823296, acc.: 45.31%] [G loss: 1.067993]\n",
      "epoch:0 step:860 [D loss: 0.695905, acc.: 60.94%] [G loss: 1.096180]\n",
      "epoch:0 step:861 [D loss: 0.746982, acc.: 51.56%] [G loss: 1.120933]\n",
      "epoch:0 step:862 [D loss: 0.743982, acc.: 50.00%] [G loss: 1.104517]\n",
      "epoch:0 step:863 [D loss: 0.649462, acc.: 65.62%] [G loss: 1.026269]\n",
      "epoch:0 step:864 [D loss: 0.651316, acc.: 64.84%] [G loss: 1.069349]\n",
      "epoch:0 step:865 [D loss: 0.723149, acc.: 57.81%] [G loss: 1.051291]\n",
      "epoch:0 step:866 [D loss: 0.716504, acc.: 57.03%] [G loss: 1.091470]\n",
      "epoch:0 step:867 [D loss: 0.730328, acc.: 52.34%] [G loss: 1.054563]\n",
      "epoch:0 step:868 [D loss: 0.699132, acc.: 58.59%] [G loss: 1.011300]\n",
      "epoch:0 step:869 [D loss: 0.729178, acc.: 54.69%] [G loss: 1.029110]\n",
      "epoch:0 step:870 [D loss: 0.738673, acc.: 57.03%] [G loss: 1.157203]\n",
      "epoch:0 step:871 [D loss: 0.629643, acc.: 71.09%] [G loss: 1.026432]\n",
      "epoch:0 step:872 [D loss: 0.718753, acc.: 56.25%] [G loss: 1.128105]\n",
      "epoch:0 step:873 [D loss: 0.727681, acc.: 57.03%] [G loss: 1.139179]\n",
      "epoch:0 step:874 [D loss: 0.752783, acc.: 50.78%] [G loss: 1.037979]\n",
      "epoch:0 step:875 [D loss: 0.682215, acc.: 59.38%] [G loss: 1.200557]\n",
      "epoch:0 step:876 [D loss: 0.800828, acc.: 43.75%] [G loss: 1.192927]\n",
      "epoch:0 step:877 [D loss: 0.686890, acc.: 53.91%] [G loss: 1.050817]\n",
      "epoch:0 step:878 [D loss: 0.671449, acc.: 57.03%] [G loss: 1.169621]\n",
      "epoch:0 step:879 [D loss: 0.703323, acc.: 55.47%] [G loss: 1.136719]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:880 [D loss: 0.707518, acc.: 60.16%] [G loss: 1.056620]\n",
      "epoch:0 step:881 [D loss: 0.647230, acc.: 57.03%] [G loss: 1.109955]\n",
      "epoch:0 step:882 [D loss: 0.715517, acc.: 53.12%] [G loss: 0.984640]\n",
      "epoch:0 step:883 [D loss: 0.718442, acc.: 57.81%] [G loss: 1.153935]\n",
      "epoch:0 step:884 [D loss: 0.718768, acc.: 57.03%] [G loss: 1.088717]\n",
      "epoch:0 step:885 [D loss: 0.746090, acc.: 55.47%] [G loss: 1.060833]\n",
      "epoch:0 step:886 [D loss: 0.727068, acc.: 53.91%] [G loss: 1.087690]\n",
      "epoch:0 step:887 [D loss: 0.726428, acc.: 61.72%] [G loss: 1.120465]\n",
      "epoch:0 step:888 [D loss: 0.840517, acc.: 45.31%] [G loss: 1.203118]\n",
      "epoch:0 step:889 [D loss: 0.594769, acc.: 67.97%] [G loss: 1.492535]\n",
      "epoch:0 step:890 [D loss: 0.613385, acc.: 67.19%] [G loss: 1.251082]\n",
      "epoch:0 step:891 [D loss: 0.872960, acc.: 41.41%] [G loss: 1.047810]\n",
      "epoch:0 step:892 [D loss: 0.961490, acc.: 35.16%] [G loss: 0.904836]\n",
      "epoch:0 step:893 [D loss: 0.698378, acc.: 53.91%] [G loss: 1.111172]\n",
      "epoch:0 step:894 [D loss: 0.763998, acc.: 50.00%] [G loss: 0.968303]\n",
      "epoch:0 step:895 [D loss: 0.750003, acc.: 49.22%] [G loss: 0.915703]\n",
      "epoch:0 step:896 [D loss: 0.746522, acc.: 59.38%] [G loss: 1.019122]\n",
      "epoch:0 step:897 [D loss: 0.721870, acc.: 57.81%] [G loss: 1.063513]\n",
      "epoch:0 step:898 [D loss: 0.711414, acc.: 53.91%] [G loss: 1.117872]\n",
      "epoch:0 step:899 [D loss: 0.687291, acc.: 64.06%] [G loss: 1.091072]\n",
      "epoch:0 step:900 [D loss: 0.714813, acc.: 56.25%] [G loss: 1.142399]\n",
      "epoch:0 step:901 [D loss: 0.732513, acc.: 57.03%] [G loss: 1.220795]\n",
      "epoch:0 step:902 [D loss: 0.666473, acc.: 60.94%] [G loss: 1.046837]\n",
      "epoch:0 step:903 [D loss: 0.696680, acc.: 60.16%] [G loss: 1.168787]\n",
      "epoch:0 step:904 [D loss: 0.758898, acc.: 50.00%] [G loss: 0.959391]\n",
      "epoch:0 step:905 [D loss: 0.722883, acc.: 55.47%] [G loss: 1.003124]\n",
      "epoch:0 step:906 [D loss: 0.721568, acc.: 50.78%] [G loss: 1.068305]\n",
      "epoch:0 step:907 [D loss: 0.721950, acc.: 52.34%] [G loss: 1.060303]\n",
      "epoch:0 step:908 [D loss: 0.711936, acc.: 51.56%] [G loss: 1.146388]\n",
      "epoch:0 step:909 [D loss: 0.722326, acc.: 50.78%] [G loss: 1.052969]\n",
      "epoch:0 step:910 [D loss: 0.795328, acc.: 48.44%] [G loss: 1.171403]\n",
      "epoch:0 step:911 [D loss: 0.754919, acc.: 53.12%] [G loss: 1.056692]\n",
      "epoch:0 step:912 [D loss: 0.792740, acc.: 43.75%] [G loss: 1.170377]\n",
      "epoch:0 step:913 [D loss: 0.622088, acc.: 64.84%] [G loss: 1.032517]\n",
      "epoch:0 step:914 [D loss: 0.652614, acc.: 57.03%] [G loss: 1.235167]\n",
      "epoch:0 step:915 [D loss: 0.811190, acc.: 46.09%] [G loss: 1.045210]\n",
      "epoch:0 step:916 [D loss: 0.837782, acc.: 46.09%] [G loss: 0.998345]\n",
      "epoch:0 step:917 [D loss: 0.770509, acc.: 46.09%] [G loss: 0.952808]\n",
      "epoch:0 step:918 [D loss: 0.703534, acc.: 57.81%] [G loss: 1.124166]\n",
      "epoch:0 step:919 [D loss: 0.702773, acc.: 60.16%] [G loss: 1.082054]\n",
      "epoch:0 step:920 [D loss: 0.814351, acc.: 46.09%] [G loss: 1.035975]\n",
      "epoch:0 step:921 [D loss: 0.638960, acc.: 64.06%] [G loss: 1.110208]\n",
      "epoch:0 step:922 [D loss: 0.772919, acc.: 49.22%] [G loss: 1.014455]\n",
      "epoch:0 step:923 [D loss: 0.676644, acc.: 62.50%] [G loss: 1.014883]\n",
      "epoch:0 step:924 [D loss: 0.653466, acc.: 64.84%] [G loss: 1.085977]\n",
      "epoch:0 step:925 [D loss: 0.598764, acc.: 67.19%] [G loss: 1.123963]\n",
      "epoch:0 step:926 [D loss: 0.647626, acc.: 63.28%] [G loss: 1.022928]\n",
      "epoch:0 step:927 [D loss: 0.821796, acc.: 45.31%] [G loss: 1.117195]\n",
      "epoch:0 step:928 [D loss: 0.914997, acc.: 41.41%] [G loss: 1.176580]\n",
      "epoch:0 step:929 [D loss: 0.722419, acc.: 54.69%] [G loss: 1.201870]\n",
      "epoch:0 step:930 [D loss: 0.618066, acc.: 65.62%] [G loss: 1.234445]\n",
      "epoch:0 step:931 [D loss: 0.703953, acc.: 54.69%] [G loss: 1.065682]\n",
      "epoch:0 step:932 [D loss: 0.759169, acc.: 52.34%] [G loss: 0.980934]\n",
      "epoch:0 step:933 [D loss: 0.736697, acc.: 53.91%] [G loss: 1.057863]\n",
      "epoch:0 step:934 [D loss: 0.821057, acc.: 35.94%] [G loss: 0.973369]\n",
      "epoch:0 step:935 [D loss: 0.716987, acc.: 55.47%] [G loss: 1.037223]\n",
      "epoch:0 step:936 [D loss: 0.610023, acc.: 70.31%] [G loss: 1.177862]\n",
      "epoch:0 step:937 [D loss: 0.640135, acc.: 67.19%] [G loss: 1.062651]\n",
      "epoch:1 step:938 [D loss: 0.740405, acc.: 57.81%] [G loss: 1.054154]\n",
      "epoch:1 step:939 [D loss: 0.783635, acc.: 46.88%] [G loss: 1.008195]\n",
      "epoch:1 step:940 [D loss: 0.744491, acc.: 57.81%] [G loss: 1.186149]\n",
      "epoch:1 step:941 [D loss: 0.795752, acc.: 42.19%] [G loss: 1.013122]\n",
      "epoch:1 step:942 [D loss: 0.732866, acc.: 55.47%] [G loss: 0.998183]\n",
      "epoch:1 step:943 [D loss: 0.767689, acc.: 49.22%] [G loss: 1.085539]\n",
      "epoch:1 step:944 [D loss: 0.715567, acc.: 56.25%] [G loss: 1.161901]\n",
      "epoch:1 step:945 [D loss: 0.754577, acc.: 50.78%] [G loss: 1.108723]\n",
      "epoch:1 step:946 [D loss: 0.729721, acc.: 55.47%] [G loss: 1.190213]\n",
      "epoch:1 step:947 [D loss: 0.800454, acc.: 42.19%] [G loss: 1.065818]\n",
      "epoch:1 step:948 [D loss: 0.767490, acc.: 46.88%] [G loss: 1.038852]\n",
      "epoch:1 step:949 [D loss: 0.797300, acc.: 47.66%] [G loss: 1.165581]\n",
      "epoch:1 step:950 [D loss: 0.575150, acc.: 68.75%] [G loss: 1.408554]\n",
      "epoch:1 step:951 [D loss: 0.611997, acc.: 69.53%] [G loss: 1.524270]\n",
      "epoch:1 step:952 [D loss: 0.607993, acc.: 69.53%] [G loss: 1.187964]\n",
      "epoch:1 step:953 [D loss: 0.748911, acc.: 51.56%] [G loss: 1.113615]\n",
      "epoch:1 step:954 [D loss: 0.856333, acc.: 39.06%] [G loss: 1.169744]\n",
      "epoch:1 step:955 [D loss: 0.836262, acc.: 40.62%] [G loss: 1.058573]\n",
      "epoch:1 step:956 [D loss: 0.699151, acc.: 55.47%] [G loss: 0.972438]\n",
      "epoch:1 step:957 [D loss: 0.707758, acc.: 54.69%] [G loss: 1.141556]\n",
      "epoch:1 step:958 [D loss: 0.721798, acc.: 56.25%] [G loss: 1.149396]\n",
      "epoch:1 step:959 [D loss: 0.763837, acc.: 46.88%] [G loss: 1.072360]\n",
      "epoch:1 step:960 [D loss: 0.716807, acc.: 51.56%] [G loss: 1.158968]\n",
      "epoch:1 step:961 [D loss: 0.695684, acc.: 57.81%] [G loss: 1.029571]\n",
      "epoch:1 step:962 [D loss: 0.550456, acc.: 69.53%] [G loss: 1.265715]\n",
      "epoch:1 step:963 [D loss: 0.661340, acc.: 61.72%] [G loss: 1.162666]\n",
      "epoch:1 step:964 [D loss: 0.634166, acc.: 61.72%] [G loss: 1.105968]\n",
      "epoch:1 step:965 [D loss: 0.631528, acc.: 67.19%] [G loss: 1.059714]\n",
      "epoch:1 step:966 [D loss: 0.687519, acc.: 58.59%] [G loss: 1.175225]\n",
      "epoch:1 step:967 [D loss: 0.828174, acc.: 43.75%] [G loss: 1.109999]\n",
      "epoch:1 step:968 [D loss: 0.762184, acc.: 53.91%] [G loss: 1.201542]\n",
      "epoch:1 step:969 [D loss: 0.698960, acc.: 55.47%] [G loss: 1.128707]\n",
      "epoch:1 step:970 [D loss: 0.666904, acc.: 62.50%] [G loss: 1.092690]\n",
      "epoch:1 step:971 [D loss: 0.688737, acc.: 57.81%] [G loss: 1.062490]\n",
      "epoch:1 step:972 [D loss: 0.713384, acc.: 58.59%] [G loss: 1.032729]\n",
      "epoch:1 step:973 [D loss: 0.668618, acc.: 62.50%] [G loss: 1.042667]\n",
      "epoch:1 step:974 [D loss: 0.845445, acc.: 50.78%] [G loss: 1.120472]\n",
      "epoch:1 step:975 [D loss: 0.766716, acc.: 48.44%] [G loss: 1.061825]\n",
      "epoch:1 step:976 [D loss: 0.691803, acc.: 56.25%] [G loss: 1.061180]\n",
      "epoch:1 step:977 [D loss: 0.619144, acc.: 62.50%] [G loss: 1.148080]\n",
      "epoch:1 step:978 [D loss: 0.721737, acc.: 54.69%] [G loss: 0.995844]\n",
      "epoch:1 step:979 [D loss: 0.672608, acc.: 59.38%] [G loss: 1.191577]\n",
      "epoch:1 step:980 [D loss: 0.673623, acc.: 60.94%] [G loss: 1.096948]\n",
      "epoch:1 step:981 [D loss: 0.804387, acc.: 50.00%] [G loss: 1.026552]\n",
      "epoch:1 step:982 [D loss: 0.743982, acc.: 51.56%] [G loss: 0.929667]\n",
      "epoch:1 step:983 [D loss: 0.731734, acc.: 50.78%] [G loss: 1.024476]\n",
      "epoch:1 step:984 [D loss: 0.642345, acc.: 67.97%] [G loss: 1.084310]\n",
      "epoch:1 step:985 [D loss: 0.615952, acc.: 68.75%] [G loss: 1.119808]\n",
      "epoch:1 step:986 [D loss: 0.672886, acc.: 56.25%] [G loss: 1.048653]\n",
      "epoch:1 step:987 [D loss: 0.661196, acc.: 63.28%] [G loss: 1.152273]\n",
      "epoch:1 step:988 [D loss: 0.870610, acc.: 36.72%] [G loss: 1.000179]\n",
      "epoch:1 step:989 [D loss: 0.678768, acc.: 62.50%] [G loss: 1.151219]\n",
      "epoch:1 step:990 [D loss: 0.702801, acc.: 57.81%] [G loss: 1.133191]\n",
      "epoch:1 step:991 [D loss: 0.712465, acc.: 56.25%] [G loss: 1.176608]\n",
      "epoch:1 step:992 [D loss: 0.739473, acc.: 49.22%] [G loss: 1.165526]\n",
      "epoch:1 step:993 [D loss: 0.738187, acc.: 56.25%] [G loss: 1.084199]\n",
      "epoch:1 step:994 [D loss: 0.686956, acc.: 61.72%] [G loss: 1.095621]\n",
      "epoch:1 step:995 [D loss: 0.748871, acc.: 54.69%] [G loss: 1.148761]\n",
      "epoch:1 step:996 [D loss: 0.699556, acc.: 57.03%] [G loss: 1.157994]\n",
      "epoch:1 step:997 [D loss: 0.740004, acc.: 47.66%] [G loss: 0.978161]\n",
      "epoch:1 step:998 [D loss: 0.762783, acc.: 49.22%] [G loss: 0.927699]\n",
      "epoch:1 step:999 [D loss: 0.769112, acc.: 50.00%] [G loss: 0.976178]\n",
      "epoch:1 step:1000 [D loss: 0.661365, acc.: 60.16%] [G loss: 1.198541]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[3.74349296 2.37603059 6.67693523 5.25542759 4.13852613 5.73514503\n",
      " 5.12704302 4.96662376 5.67069153 4.74159073]\n",
      "##########\n",
      "epoch:1 step:1001 [D loss: 0.734539, acc.: 50.78%] [G loss: 0.975912]\n",
      "epoch:1 step:1002 [D loss: 0.741003, acc.: 54.69%] [G loss: 0.980721]\n",
      "epoch:1 step:1003 [D loss: 0.711864, acc.: 52.34%] [G loss: 1.055143]\n",
      "epoch:1 step:1004 [D loss: 0.732426, acc.: 55.47%] [G loss: 1.047282]\n",
      "epoch:1 step:1005 [D loss: 0.769084, acc.: 46.09%] [G loss: 0.930788]\n",
      "epoch:1 step:1006 [D loss: 0.716480, acc.: 56.25%] [G loss: 0.991354]\n",
      "epoch:1 step:1007 [D loss: 0.682017, acc.: 60.16%] [G loss: 1.024023]\n",
      "epoch:1 step:1008 [D loss: 0.805370, acc.: 45.31%] [G loss: 1.040256]\n",
      "epoch:1 step:1009 [D loss: 0.710661, acc.: 51.56%] [G loss: 0.941560]\n",
      "epoch:1 step:1010 [D loss: 0.714707, acc.: 50.78%] [G loss: 0.980949]\n",
      "epoch:1 step:1011 [D loss: 0.645273, acc.: 59.38%] [G loss: 0.974014]\n",
      "epoch:1 step:1012 [D loss: 0.693262, acc.: 53.91%] [G loss: 0.976033]\n",
      "epoch:1 step:1013 [D loss: 0.642307, acc.: 61.72%] [G loss: 1.064717]\n",
      "epoch:1 step:1014 [D loss: 0.650808, acc.: 67.19%] [G loss: 1.007872]\n",
      "epoch:1 step:1015 [D loss: 0.752525, acc.: 46.88%] [G loss: 1.021628]\n",
      "epoch:1 step:1016 [D loss: 0.759707, acc.: 51.56%] [G loss: 0.978411]\n",
      "epoch:1 step:1017 [D loss: 0.665884, acc.: 59.38%] [G loss: 1.006426]\n",
      "epoch:1 step:1018 [D loss: 0.742484, acc.: 50.78%] [G loss: 1.014508]\n",
      "epoch:1 step:1019 [D loss: 0.775845, acc.: 46.88%] [G loss: 0.937940]\n",
      "epoch:1 step:1020 [D loss: 0.639652, acc.: 64.06%] [G loss: 0.964429]\n",
      "epoch:1 step:1021 [D loss: 0.692425, acc.: 55.47%] [G loss: 1.058948]\n",
      "epoch:1 step:1022 [D loss: 0.642926, acc.: 65.62%] [G loss: 1.044107]\n",
      "epoch:1 step:1023 [D loss: 0.676763, acc.: 63.28%] [G loss: 1.003072]\n",
      "epoch:1 step:1024 [D loss: 0.726661, acc.: 54.69%] [G loss: 0.943181]\n",
      "epoch:1 step:1025 [D loss: 0.677764, acc.: 60.16%] [G loss: 1.090604]\n",
      "epoch:1 step:1026 [D loss: 0.690867, acc.: 54.69%] [G loss: 1.106569]\n",
      "epoch:1 step:1027 [D loss: 0.641460, acc.: 65.62%] [G loss: 1.064745]\n",
      "epoch:1 step:1028 [D loss: 0.673090, acc.: 53.91%] [G loss: 1.049948]\n",
      "epoch:1 step:1029 [D loss: 0.674518, acc.: 59.38%] [G loss: 1.044077]\n",
      "epoch:1 step:1030 [D loss: 0.672001, acc.: 59.38%] [G loss: 1.078102]\n",
      "epoch:1 step:1031 [D loss: 0.748241, acc.: 56.25%] [G loss: 1.024711]\n",
      "epoch:1 step:1032 [D loss: 0.671703, acc.: 56.25%] [G loss: 1.061188]\n",
      "epoch:1 step:1033 [D loss: 0.606088, acc.: 65.62%] [G loss: 1.053983]\n",
      "epoch:1 step:1034 [D loss: 0.636696, acc.: 64.84%] [G loss: 1.226910]\n",
      "epoch:1 step:1035 [D loss: 0.733871, acc.: 53.91%] [G loss: 1.115903]\n",
      "epoch:1 step:1036 [D loss: 0.737282, acc.: 49.22%] [G loss: 1.185780]\n",
      "epoch:1 step:1037 [D loss: 0.656798, acc.: 59.38%] [G loss: 1.216722]\n",
      "epoch:1 step:1038 [D loss: 0.767649, acc.: 50.78%] [G loss: 1.130056]\n",
      "epoch:1 step:1039 [D loss: 0.697833, acc.: 54.69%] [G loss: 0.952845]\n",
      "epoch:1 step:1040 [D loss: 0.790597, acc.: 46.09%] [G loss: 1.084459]\n",
      "epoch:1 step:1041 [D loss: 0.691476, acc.: 60.16%] [G loss: 1.011886]\n",
      "epoch:1 step:1042 [D loss: 0.708703, acc.: 49.22%] [G loss: 1.012319]\n",
      "epoch:1 step:1043 [D loss: 0.707792, acc.: 58.59%] [G loss: 1.105852]\n",
      "epoch:1 step:1044 [D loss: 0.572221, acc.: 71.88%] [G loss: 1.269334]\n",
      "epoch:1 step:1045 [D loss: 0.764597, acc.: 55.47%] [G loss: 1.157666]\n",
      "epoch:1 step:1046 [D loss: 0.756850, acc.: 53.12%] [G loss: 0.949577]\n",
      "epoch:1 step:1047 [D loss: 0.742344, acc.: 49.22%] [G loss: 1.066223]\n",
      "epoch:1 step:1048 [D loss: 0.724133, acc.: 55.47%] [G loss: 1.005206]\n",
      "epoch:1 step:1049 [D loss: 0.657441, acc.: 64.84%] [G loss: 0.988670]\n",
      "epoch:1 step:1050 [D loss: 0.702901, acc.: 60.16%] [G loss: 1.038318]\n",
      "epoch:1 step:1051 [D loss: 0.705043, acc.: 55.47%] [G loss: 0.984457]\n",
      "epoch:1 step:1052 [D loss: 0.713107, acc.: 57.03%] [G loss: 1.086402]\n",
      "epoch:1 step:1053 [D loss: 0.767130, acc.: 47.66%] [G loss: 1.101188]\n",
      "epoch:1 step:1054 [D loss: 0.836440, acc.: 46.88%] [G loss: 1.062821]\n",
      "epoch:1 step:1055 [D loss: 0.654871, acc.: 60.94%] [G loss: 1.209084]\n",
      "epoch:1 step:1056 [D loss: 0.654599, acc.: 61.72%] [G loss: 1.407982]\n",
      "epoch:1 step:1057 [D loss: 0.682329, acc.: 61.72%] [G loss: 1.313520]\n",
      "epoch:1 step:1058 [D loss: 0.699937, acc.: 57.03%] [G loss: 1.176893]\n",
      "epoch:1 step:1059 [D loss: 0.677686, acc.: 62.50%] [G loss: 1.065379]\n",
      "epoch:1 step:1060 [D loss: 0.574413, acc.: 67.19%] [G loss: 1.053649]\n",
      "epoch:1 step:1061 [D loss: 0.654313, acc.: 64.06%] [G loss: 0.958854]\n",
      "epoch:1 step:1062 [D loss: 0.697951, acc.: 54.69%] [G loss: 1.063396]\n",
      "epoch:1 step:1063 [D loss: 0.662010, acc.: 64.06%] [G loss: 0.955010]\n",
      "epoch:1 step:1064 [D loss: 0.729305, acc.: 53.91%] [G loss: 1.026487]\n",
      "epoch:1 step:1065 [D loss: 0.730561, acc.: 49.22%] [G loss: 0.994065]\n",
      "epoch:1 step:1066 [D loss: 0.800682, acc.: 44.53%] [G loss: 1.121413]\n",
      "epoch:1 step:1067 [D loss: 0.673716, acc.: 57.81%] [G loss: 1.036955]\n",
      "epoch:1 step:1068 [D loss: 0.722351, acc.: 55.47%] [G loss: 1.059038]\n",
      "epoch:1 step:1069 [D loss: 0.674095, acc.: 60.16%] [G loss: 1.135365]\n",
      "epoch:1 step:1070 [D loss: 0.844816, acc.: 45.31%] [G loss: 0.940902]\n",
      "epoch:1 step:1071 [D loss: 0.865893, acc.: 43.75%] [G loss: 0.947568]\n",
      "epoch:1 step:1072 [D loss: 0.757072, acc.: 50.00%] [G loss: 0.949827]\n",
      "epoch:1 step:1073 [D loss: 0.748864, acc.: 50.78%] [G loss: 1.113791]\n",
      "epoch:1 step:1074 [D loss: 0.776444, acc.: 45.31%] [G loss: 1.057512]\n",
      "epoch:1 step:1075 [D loss: 0.702326, acc.: 53.12%] [G loss: 1.097375]\n",
      "epoch:1 step:1076 [D loss: 0.673306, acc.: 58.59%] [G loss: 1.051691]\n",
      "epoch:1 step:1077 [D loss: 0.787154, acc.: 49.22%] [G loss: 1.082428]\n",
      "epoch:1 step:1078 [D loss: 0.743018, acc.: 51.56%] [G loss: 1.032486]\n",
      "epoch:1 step:1079 [D loss: 0.655838, acc.: 60.16%] [G loss: 1.143048]\n",
      "epoch:1 step:1080 [D loss: 0.704798, acc.: 56.25%] [G loss: 1.071910]\n",
      "epoch:1 step:1081 [D loss: 0.642206, acc.: 64.06%] [G loss: 0.963192]\n",
      "epoch:1 step:1082 [D loss: 0.619939, acc.: 63.28%] [G loss: 1.118123]\n",
      "epoch:1 step:1083 [D loss: 0.709901, acc.: 57.81%] [G loss: 1.004168]\n",
      "epoch:1 step:1084 [D loss: 0.803426, acc.: 46.88%] [G loss: 1.046457]\n",
      "epoch:1 step:1085 [D loss: 0.704746, acc.: 55.47%] [G loss: 1.097486]\n",
      "epoch:1 step:1086 [D loss: 0.722997, acc.: 54.69%] [G loss: 1.019668]\n",
      "epoch:1 step:1087 [D loss: 0.697558, acc.: 54.69%] [G loss: 1.027914]\n",
      "epoch:1 step:1088 [D loss: 0.673087, acc.: 65.62%] [G loss: 0.974113]\n",
      "epoch:1 step:1089 [D loss: 0.700904, acc.: 59.38%] [G loss: 1.085723]\n",
      "epoch:1 step:1090 [D loss: 0.791171, acc.: 51.56%] [G loss: 1.018463]\n",
      "epoch:1 step:1091 [D loss: 0.740917, acc.: 51.56%] [G loss: 0.930438]\n",
      "epoch:1 step:1092 [D loss: 0.648034, acc.: 60.94%] [G loss: 1.035277]\n",
      "epoch:1 step:1093 [D loss: 0.658826, acc.: 60.94%] [G loss: 0.970844]\n",
      "epoch:1 step:1094 [D loss: 0.714745, acc.: 52.34%] [G loss: 0.973748]\n",
      "epoch:1 step:1095 [D loss: 0.662796, acc.: 60.16%] [G loss: 0.977175]\n",
      "epoch:1 step:1096 [D loss: 0.685748, acc.: 59.38%] [G loss: 1.006082]\n",
      "epoch:1 step:1097 [D loss: 0.688330, acc.: 57.81%] [G loss: 1.045543]\n",
      "epoch:1 step:1098 [D loss: 0.665110, acc.: 53.91%] [G loss: 0.964100]\n",
      "epoch:1 step:1099 [D loss: 0.725472, acc.: 46.88%] [G loss: 1.027899]\n",
      "epoch:1 step:1100 [D loss: 0.728099, acc.: 52.34%] [G loss: 1.020783]\n",
      "epoch:1 step:1101 [D loss: 0.701925, acc.: 53.12%] [G loss: 0.908174]\n",
      "epoch:1 step:1102 [D loss: 0.658544, acc.: 64.06%] [G loss: 0.975781]\n",
      "epoch:1 step:1103 [D loss: 0.759554, acc.: 50.00%] [G loss: 0.975781]\n",
      "epoch:1 step:1104 [D loss: 0.776748, acc.: 39.06%] [G loss: 1.004338]\n",
      "epoch:1 step:1105 [D loss: 0.640811, acc.: 59.38%] [G loss: 0.941580]\n",
      "epoch:1 step:1106 [D loss: 0.672394, acc.: 55.47%] [G loss: 1.029569]\n",
      "epoch:1 step:1107 [D loss: 0.699289, acc.: 53.91%] [G loss: 0.949341]\n",
      "epoch:1 step:1108 [D loss: 0.692901, acc.: 53.91%] [G loss: 0.985104]\n",
      "epoch:1 step:1109 [D loss: 0.709917, acc.: 53.91%] [G loss: 1.071859]\n",
      "epoch:1 step:1110 [D loss: 0.705507, acc.: 57.81%] [G loss: 0.978681]\n",
      "epoch:1 step:1111 [D loss: 0.706007, acc.: 50.78%] [G loss: 0.931438]\n",
      "epoch:1 step:1112 [D loss: 0.726442, acc.: 49.22%] [G loss: 0.985400]\n",
      "epoch:1 step:1113 [D loss: 0.725697, acc.: 50.78%] [G loss: 0.990918]\n",
      "epoch:1 step:1114 [D loss: 0.727301, acc.: 54.69%] [G loss: 0.966193]\n",
      "epoch:1 step:1115 [D loss: 0.794134, acc.: 39.84%] [G loss: 0.951100]\n",
      "epoch:1 step:1116 [D loss: 0.723807, acc.: 48.44%] [G loss: 1.028540]\n",
      "epoch:1 step:1117 [D loss: 0.724641, acc.: 48.44%] [G loss: 0.971098]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1118 [D loss: 0.763611, acc.: 46.09%] [G loss: 1.019987]\n",
      "epoch:1 step:1119 [D loss: 0.694908, acc.: 57.03%] [G loss: 1.034415]\n",
      "epoch:1 step:1120 [D loss: 0.782475, acc.: 45.31%] [G loss: 0.992644]\n",
      "epoch:1 step:1121 [D loss: 0.655715, acc.: 57.81%] [G loss: 1.061313]\n",
      "epoch:1 step:1122 [D loss: 0.777511, acc.: 46.88%] [G loss: 1.038617]\n",
      "epoch:1 step:1123 [D loss: 0.732786, acc.: 43.75%] [G loss: 0.999010]\n",
      "epoch:1 step:1124 [D loss: 0.695996, acc.: 58.59%] [G loss: 0.940606]\n",
      "epoch:1 step:1125 [D loss: 0.757102, acc.: 48.44%] [G loss: 0.993125]\n",
      "epoch:1 step:1126 [D loss: 0.815214, acc.: 34.38%] [G loss: 0.901278]\n",
      "epoch:1 step:1127 [D loss: 0.682067, acc.: 57.03%] [G loss: 1.058739]\n",
      "epoch:1 step:1128 [D loss: 0.715825, acc.: 56.25%] [G loss: 1.104801]\n",
      "epoch:1 step:1129 [D loss: 0.688971, acc.: 54.69%] [G loss: 1.006323]\n",
      "epoch:1 step:1130 [D loss: 0.664949, acc.: 59.38%] [G loss: 1.034734]\n",
      "epoch:1 step:1131 [D loss: 0.653282, acc.: 61.72%] [G loss: 1.053003]\n",
      "epoch:1 step:1132 [D loss: 0.623050, acc.: 62.50%] [G loss: 1.075127]\n",
      "epoch:1 step:1133 [D loss: 0.683978, acc.: 53.91%] [G loss: 1.087531]\n",
      "epoch:1 step:1134 [D loss: 0.611737, acc.: 61.72%] [G loss: 1.038847]\n",
      "epoch:1 step:1135 [D loss: 0.747314, acc.: 44.53%] [G loss: 0.988563]\n",
      "epoch:1 step:1136 [D loss: 0.713412, acc.: 58.59%] [G loss: 1.072924]\n",
      "epoch:1 step:1137 [D loss: 0.773538, acc.: 49.22%] [G loss: 0.933082]\n",
      "epoch:1 step:1138 [D loss: 0.710932, acc.: 56.25%] [G loss: 1.020902]\n",
      "epoch:1 step:1139 [D loss: 0.738577, acc.: 53.91%] [G loss: 1.117676]\n",
      "epoch:1 step:1140 [D loss: 0.834769, acc.: 46.88%] [G loss: 1.118223]\n",
      "epoch:1 step:1141 [D loss: 0.763726, acc.: 46.88%] [G loss: 1.023946]\n",
      "epoch:1 step:1142 [D loss: 0.687889, acc.: 57.81%] [G loss: 1.164837]\n",
      "epoch:1 step:1143 [D loss: 0.609152, acc.: 64.06%] [G loss: 1.066991]\n",
      "epoch:1 step:1144 [D loss: 0.712762, acc.: 53.12%] [G loss: 1.149156]\n",
      "epoch:1 step:1145 [D loss: 0.744869, acc.: 52.34%] [G loss: 0.960540]\n",
      "epoch:1 step:1146 [D loss: 0.654636, acc.: 58.59%] [G loss: 0.945308]\n",
      "epoch:1 step:1147 [D loss: 0.778002, acc.: 46.88%] [G loss: 0.928299]\n",
      "epoch:1 step:1148 [D loss: 0.782751, acc.: 48.44%] [G loss: 0.973602]\n",
      "epoch:1 step:1149 [D loss: 0.710560, acc.: 52.34%] [G loss: 0.995522]\n",
      "epoch:1 step:1150 [D loss: 0.797584, acc.: 40.62%] [G loss: 0.942166]\n",
      "epoch:1 step:1151 [D loss: 0.816963, acc.: 40.62%] [G loss: 1.004381]\n",
      "epoch:1 step:1152 [D loss: 0.838721, acc.: 35.94%] [G loss: 0.947467]\n",
      "epoch:1 step:1153 [D loss: 0.697637, acc.: 57.81%] [G loss: 1.025633]\n",
      "epoch:1 step:1154 [D loss: 0.734174, acc.: 48.44%] [G loss: 1.020337]\n",
      "epoch:1 step:1155 [D loss: 0.664755, acc.: 61.72%] [G loss: 1.018961]\n",
      "epoch:1 step:1156 [D loss: 0.629380, acc.: 67.97%] [G loss: 0.929193]\n",
      "epoch:1 step:1157 [D loss: 0.781912, acc.: 43.75%] [G loss: 0.898831]\n",
      "epoch:1 step:1158 [D loss: 0.662208, acc.: 60.94%] [G loss: 1.037056]\n",
      "epoch:1 step:1159 [D loss: 0.680146, acc.: 52.34%] [G loss: 1.067577]\n",
      "epoch:1 step:1160 [D loss: 0.614025, acc.: 68.75%] [G loss: 1.066380]\n",
      "epoch:1 step:1161 [D loss: 0.761942, acc.: 50.78%] [G loss: 0.963661]\n",
      "epoch:1 step:1162 [D loss: 0.768683, acc.: 47.66%] [G loss: 0.938266]\n",
      "epoch:1 step:1163 [D loss: 0.751513, acc.: 43.75%] [G loss: 1.076221]\n",
      "epoch:1 step:1164 [D loss: 0.720386, acc.: 50.00%] [G loss: 1.051425]\n",
      "epoch:1 step:1165 [D loss: 0.708147, acc.: 56.25%] [G loss: 0.925245]\n",
      "epoch:1 step:1166 [D loss: 0.685746, acc.: 55.47%] [G loss: 0.950696]\n",
      "epoch:1 step:1167 [D loss: 0.644911, acc.: 58.59%] [G loss: 0.935963]\n",
      "epoch:1 step:1168 [D loss: 0.646384, acc.: 63.28%] [G loss: 1.073387]\n",
      "epoch:1 step:1169 [D loss: 0.645254, acc.: 64.06%] [G loss: 1.066584]\n",
      "epoch:1 step:1170 [D loss: 0.776928, acc.: 50.00%] [G loss: 0.945502]\n",
      "epoch:1 step:1171 [D loss: 0.789408, acc.: 42.97%] [G loss: 0.820076]\n",
      "epoch:1 step:1172 [D loss: 0.739224, acc.: 46.88%] [G loss: 0.974160]\n",
      "epoch:1 step:1173 [D loss: 0.729115, acc.: 53.91%] [G loss: 0.990157]\n",
      "epoch:1 step:1174 [D loss: 0.760524, acc.: 46.09%] [G loss: 0.944200]\n",
      "epoch:1 step:1175 [D loss: 0.733254, acc.: 48.44%] [G loss: 0.942685]\n",
      "epoch:1 step:1176 [D loss: 0.745880, acc.: 50.78%] [G loss: 0.891990]\n",
      "epoch:1 step:1177 [D loss: 0.679190, acc.: 62.50%] [G loss: 0.990459]\n",
      "epoch:1 step:1178 [D loss: 0.700389, acc.: 57.03%] [G loss: 1.025178]\n",
      "epoch:1 step:1179 [D loss: 0.634967, acc.: 63.28%] [G loss: 1.066513]\n",
      "epoch:1 step:1180 [D loss: 0.684722, acc.: 57.81%] [G loss: 0.995280]\n",
      "epoch:1 step:1181 [D loss: 0.683503, acc.: 54.69%] [G loss: 0.968903]\n",
      "epoch:1 step:1182 [D loss: 0.662482, acc.: 62.50%] [G loss: 0.960060]\n",
      "epoch:1 step:1183 [D loss: 0.725637, acc.: 48.44%] [G loss: 1.005840]\n",
      "epoch:1 step:1184 [D loss: 0.675452, acc.: 63.28%] [G loss: 1.039266]\n",
      "epoch:1 step:1185 [D loss: 0.645673, acc.: 62.50%] [G loss: 0.918706]\n",
      "epoch:1 step:1186 [D loss: 0.801466, acc.: 41.41%] [G loss: 0.967657]\n",
      "epoch:1 step:1187 [D loss: 0.739700, acc.: 49.22%] [G loss: 0.972371]\n",
      "epoch:1 step:1188 [D loss: 0.736136, acc.: 53.12%] [G loss: 0.915586]\n",
      "epoch:1 step:1189 [D loss: 0.709779, acc.: 58.59%] [G loss: 1.128743]\n",
      "epoch:1 step:1190 [D loss: 0.679557, acc.: 55.47%] [G loss: 1.047545]\n",
      "epoch:1 step:1191 [D loss: 0.704877, acc.: 53.91%] [G loss: 1.081717]\n",
      "epoch:1 step:1192 [D loss: 0.661075, acc.: 57.03%] [G loss: 0.941712]\n",
      "epoch:1 step:1193 [D loss: 0.706321, acc.: 50.00%] [G loss: 0.962433]\n",
      "epoch:1 step:1194 [D loss: 0.723639, acc.: 51.56%] [G loss: 0.840079]\n",
      "epoch:1 step:1195 [D loss: 0.691552, acc.: 56.25%] [G loss: 0.943254]\n",
      "epoch:1 step:1196 [D loss: 0.655818, acc.: 60.16%] [G loss: 0.912840]\n",
      "epoch:1 step:1197 [D loss: 0.788406, acc.: 50.00%] [G loss: 0.847245]\n",
      "epoch:1 step:1198 [D loss: 0.667648, acc.: 57.03%] [G loss: 0.960734]\n",
      "epoch:1 step:1199 [D loss: 0.687824, acc.: 59.38%] [G loss: 0.976969]\n",
      "epoch:1 step:1200 [D loss: 0.792867, acc.: 50.00%] [G loss: 0.977111]\n",
      "##############\n",
      "[3.85408372 2.15967487 6.36619064 5.09217151 4.10355656 5.43297129\n",
      " 5.41009892 5.10571056 5.44456918 4.68549727]\n",
      "##########\n",
      "epoch:1 step:1201 [D loss: 0.649575, acc.: 63.28%] [G loss: 1.048555]\n",
      "epoch:1 step:1202 [D loss: 0.726453, acc.: 49.22%] [G loss: 0.873598]\n",
      "epoch:1 step:1203 [D loss: 0.757086, acc.: 53.12%] [G loss: 1.015159]\n",
      "epoch:1 step:1204 [D loss: 0.687719, acc.: 53.12%] [G loss: 0.964015]\n",
      "epoch:1 step:1205 [D loss: 0.733257, acc.: 50.78%] [G loss: 0.975451]\n",
      "epoch:1 step:1206 [D loss: 0.701850, acc.: 53.12%] [G loss: 0.909181]\n",
      "epoch:1 step:1207 [D loss: 0.719336, acc.: 52.34%] [G loss: 1.050665]\n",
      "epoch:1 step:1208 [D loss: 0.656922, acc.: 56.25%] [G loss: 1.021948]\n",
      "epoch:1 step:1209 [D loss: 0.721000, acc.: 50.78%] [G loss: 1.041382]\n",
      "epoch:1 step:1210 [D loss: 0.651720, acc.: 63.28%] [G loss: 0.956464]\n",
      "epoch:1 step:1211 [D loss: 0.628145, acc.: 66.41%] [G loss: 1.053595]\n",
      "epoch:1 step:1212 [D loss: 0.703319, acc.: 63.28%] [G loss: 1.076563]\n",
      "epoch:1 step:1213 [D loss: 0.695065, acc.: 56.25%] [G loss: 1.005486]\n",
      "epoch:1 step:1214 [D loss: 0.735606, acc.: 46.88%] [G loss: 0.908707]\n",
      "epoch:1 step:1215 [D loss: 0.741167, acc.: 47.66%] [G loss: 0.933253]\n",
      "epoch:1 step:1216 [D loss: 0.770737, acc.: 42.97%] [G loss: 0.845566]\n",
      "epoch:1 step:1217 [D loss: 0.749208, acc.: 46.88%] [G loss: 0.892868]\n",
      "epoch:1 step:1218 [D loss: 0.741332, acc.: 51.56%] [G loss: 0.830518]\n",
      "epoch:1 step:1219 [D loss: 0.749719, acc.: 46.88%] [G loss: 0.920125]\n",
      "epoch:1 step:1220 [D loss: 0.693373, acc.: 53.12%] [G loss: 0.970660]\n",
      "epoch:1 step:1221 [D loss: 0.644692, acc.: 61.72%] [G loss: 1.022749]\n",
      "epoch:1 step:1222 [D loss: 0.662467, acc.: 61.72%] [G loss: 0.867166]\n",
      "epoch:1 step:1223 [D loss: 0.669489, acc.: 61.72%] [G loss: 0.972522]\n",
      "epoch:1 step:1224 [D loss: 0.722751, acc.: 53.12%] [G loss: 0.919583]\n",
      "epoch:1 step:1225 [D loss: 0.688791, acc.: 63.28%] [G loss: 0.914089]\n",
      "epoch:1 step:1226 [D loss: 0.653460, acc.: 62.50%] [G loss: 0.940699]\n",
      "epoch:1 step:1227 [D loss: 0.690937, acc.: 57.81%] [G loss: 0.969101]\n",
      "epoch:1 step:1228 [D loss: 0.800737, acc.: 46.88%] [G loss: 0.941458]\n",
      "epoch:1 step:1229 [D loss: 0.722452, acc.: 52.34%] [G loss: 0.939848]\n",
      "epoch:1 step:1230 [D loss: 0.704187, acc.: 54.69%] [G loss: 1.005264]\n",
      "epoch:1 step:1231 [D loss: 0.765438, acc.: 47.66%] [G loss: 1.018181]\n",
      "epoch:1 step:1232 [D loss: 0.744837, acc.: 42.97%] [G loss: 0.910543]\n",
      "epoch:1 step:1233 [D loss: 0.708923, acc.: 52.34%] [G loss: 0.811714]\n",
      "epoch:1 step:1234 [D loss: 0.689080, acc.: 58.59%] [G loss: 0.904461]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1235 [D loss: 0.628768, acc.: 64.06%] [G loss: 0.917770]\n",
      "epoch:1 step:1236 [D loss: 0.679810, acc.: 55.47%] [G loss: 0.877533]\n",
      "epoch:1 step:1237 [D loss: 0.677622, acc.: 57.81%] [G loss: 0.893209]\n",
      "epoch:1 step:1238 [D loss: 0.702417, acc.: 53.91%] [G loss: 0.909984]\n",
      "epoch:1 step:1239 [D loss: 0.715236, acc.: 53.12%] [G loss: 0.971868]\n",
      "epoch:1 step:1240 [D loss: 0.674002, acc.: 53.12%] [G loss: 1.004823]\n",
      "epoch:1 step:1241 [D loss: 0.763329, acc.: 46.09%] [G loss: 0.917553]\n",
      "epoch:1 step:1242 [D loss: 0.745631, acc.: 42.97%] [G loss: 1.017546]\n",
      "epoch:1 step:1243 [D loss: 0.761365, acc.: 43.75%] [G loss: 0.964764]\n",
      "epoch:1 step:1244 [D loss: 0.729692, acc.: 54.69%] [G loss: 0.941585]\n",
      "epoch:1 step:1245 [D loss: 0.689953, acc.: 58.59%] [G loss: 0.930859]\n",
      "epoch:1 step:1246 [D loss: 0.721623, acc.: 49.22%] [G loss: 0.951606]\n",
      "epoch:1 step:1247 [D loss: 0.700221, acc.: 52.34%] [G loss: 1.012174]\n",
      "epoch:1 step:1248 [D loss: 0.700975, acc.: 60.16%] [G loss: 0.979374]\n",
      "epoch:1 step:1249 [D loss: 0.711104, acc.: 56.25%] [G loss: 0.946285]\n",
      "epoch:1 step:1250 [D loss: 0.602004, acc.: 73.44%] [G loss: 0.985504]\n",
      "epoch:1 step:1251 [D loss: 0.636543, acc.: 66.41%] [G loss: 1.080272]\n",
      "epoch:1 step:1252 [D loss: 0.629414, acc.: 64.06%] [G loss: 1.045280]\n",
      "epoch:1 step:1253 [D loss: 0.787538, acc.: 51.56%] [G loss: 1.020812]\n",
      "epoch:1 step:1254 [D loss: 0.694676, acc.: 55.47%] [G loss: 0.987047]\n",
      "epoch:1 step:1255 [D loss: 0.681692, acc.: 58.59%] [G loss: 0.916808]\n",
      "epoch:1 step:1256 [D loss: 0.781998, acc.: 43.75%] [G loss: 0.852031]\n",
      "epoch:1 step:1257 [D loss: 0.732033, acc.: 52.34%] [G loss: 0.929843]\n",
      "epoch:1 step:1258 [D loss: 0.680358, acc.: 56.25%] [G loss: 0.987110]\n",
      "epoch:1 step:1259 [D loss: 0.715894, acc.: 53.91%] [G loss: 1.049480]\n",
      "epoch:1 step:1260 [D loss: 0.759282, acc.: 42.97%] [G loss: 0.986995]\n",
      "epoch:1 step:1261 [D loss: 0.678767, acc.: 60.94%] [G loss: 0.994469]\n",
      "epoch:1 step:1262 [D loss: 0.670831, acc.: 59.38%] [G loss: 0.996037]\n",
      "epoch:1 step:1263 [D loss: 0.687862, acc.: 60.94%] [G loss: 0.945446]\n",
      "epoch:1 step:1264 [D loss: 0.636323, acc.: 67.97%] [G loss: 0.982919]\n",
      "epoch:1 step:1265 [D loss: 0.714088, acc.: 51.56%] [G loss: 0.863493]\n",
      "epoch:1 step:1266 [D loss: 0.782172, acc.: 46.88%] [G loss: 0.905444]\n",
      "epoch:1 step:1267 [D loss: 0.659261, acc.: 59.38%] [G loss: 0.871429]\n",
      "epoch:1 step:1268 [D loss: 0.706844, acc.: 60.94%] [G loss: 1.029133]\n",
      "epoch:1 step:1269 [D loss: 0.684539, acc.: 59.38%] [G loss: 0.917790]\n",
      "epoch:1 step:1270 [D loss: 0.701956, acc.: 51.56%] [G loss: 0.859743]\n",
      "epoch:1 step:1271 [D loss: 0.687285, acc.: 56.25%] [G loss: 0.981067]\n",
      "epoch:1 step:1272 [D loss: 0.677342, acc.: 62.50%] [G loss: 1.039767]\n",
      "epoch:1 step:1273 [D loss: 0.654174, acc.: 63.28%] [G loss: 1.040177]\n",
      "epoch:1 step:1274 [D loss: 0.702429, acc.: 52.34%] [G loss: 1.021719]\n",
      "epoch:1 step:1275 [D loss: 0.710397, acc.: 57.81%] [G loss: 1.036749]\n",
      "epoch:1 step:1276 [D loss: 0.707181, acc.: 57.81%] [G loss: 0.942407]\n",
      "epoch:1 step:1277 [D loss: 0.735556, acc.: 46.88%] [G loss: 0.864590]\n",
      "epoch:1 step:1278 [D loss: 0.679367, acc.: 53.91%] [G loss: 0.899693]\n",
      "epoch:1 step:1279 [D loss: 0.782132, acc.: 39.84%] [G loss: 0.846467]\n",
      "epoch:1 step:1280 [D loss: 0.631005, acc.: 67.19%] [G loss: 0.969012]\n",
      "epoch:1 step:1281 [D loss: 0.631205, acc.: 58.59%] [G loss: 0.903706]\n",
      "epoch:1 step:1282 [D loss: 0.708412, acc.: 51.56%] [G loss: 0.940980]\n",
      "epoch:1 step:1283 [D loss: 0.686059, acc.: 57.03%] [G loss: 1.088725]\n",
      "epoch:1 step:1284 [D loss: 0.557116, acc.: 71.88%] [G loss: 1.106221]\n",
      "epoch:1 step:1285 [D loss: 0.759755, acc.: 55.47%] [G loss: 0.927890]\n",
      "epoch:1 step:1286 [D loss: 0.852229, acc.: 30.47%] [G loss: 0.976691]\n",
      "epoch:1 step:1287 [D loss: 0.689834, acc.: 57.81%] [G loss: 0.956384]\n",
      "epoch:1 step:1288 [D loss: 0.713851, acc.: 53.91%] [G loss: 0.935922]\n",
      "epoch:1 step:1289 [D loss: 0.709810, acc.: 46.09%] [G loss: 0.947452]\n",
      "epoch:1 step:1290 [D loss: 0.672272, acc.: 54.69%] [G loss: 1.073218]\n",
      "epoch:1 step:1291 [D loss: 0.628733, acc.: 63.28%] [G loss: 0.918866]\n",
      "epoch:1 step:1292 [D loss: 0.702438, acc.: 56.25%] [G loss: 0.952704]\n",
      "epoch:1 step:1293 [D loss: 0.639143, acc.: 62.50%] [G loss: 0.969093]\n",
      "epoch:1 step:1294 [D loss: 0.765801, acc.: 53.12%] [G loss: 0.884330]\n",
      "epoch:1 step:1295 [D loss: 0.696396, acc.: 59.38%] [G loss: 0.924660]\n",
      "epoch:1 step:1296 [D loss: 0.731680, acc.: 53.91%] [G loss: 0.974386]\n",
      "epoch:1 step:1297 [D loss: 0.697620, acc.: 57.81%] [G loss: 0.921640]\n",
      "epoch:1 step:1298 [D loss: 0.676386, acc.: 60.16%] [G loss: 0.995970]\n",
      "epoch:1 step:1299 [D loss: 0.747248, acc.: 53.12%] [G loss: 0.868316]\n",
      "epoch:1 step:1300 [D loss: 0.792259, acc.: 41.41%] [G loss: 0.874214]\n",
      "epoch:1 step:1301 [D loss: 0.658575, acc.: 60.16%] [G loss: 0.826112]\n",
      "epoch:1 step:1302 [D loss: 0.727527, acc.: 50.00%] [G loss: 0.880263]\n",
      "epoch:1 step:1303 [D loss: 0.742020, acc.: 46.09%] [G loss: 0.983371]\n",
      "epoch:1 step:1304 [D loss: 0.681377, acc.: 54.69%] [G loss: 0.960930]\n",
      "epoch:1 step:1305 [D loss: 0.694327, acc.: 53.91%] [G loss: 0.890083]\n",
      "epoch:1 step:1306 [D loss: 0.674347, acc.: 60.94%] [G loss: 0.966904]\n",
      "epoch:1 step:1307 [D loss: 0.659650, acc.: 63.28%] [G loss: 0.867816]\n",
      "epoch:1 step:1308 [D loss: 0.625229, acc.: 63.28%] [G loss: 0.957379]\n",
      "epoch:1 step:1309 [D loss: 0.740297, acc.: 47.66%] [G loss: 0.976697]\n",
      "epoch:1 step:1310 [D loss: 0.756753, acc.: 42.97%] [G loss: 0.911724]\n",
      "epoch:1 step:1311 [D loss: 0.631863, acc.: 62.50%] [G loss: 0.952752]\n",
      "epoch:1 step:1312 [D loss: 0.738193, acc.: 53.91%] [G loss: 0.896229]\n",
      "epoch:1 step:1313 [D loss: 0.785316, acc.: 48.44%] [G loss: 0.865663]\n",
      "epoch:1 step:1314 [D loss: 0.777727, acc.: 42.19%] [G loss: 0.834801]\n",
      "epoch:1 step:1315 [D loss: 0.628742, acc.: 68.75%] [G loss: 0.895419]\n",
      "epoch:1 step:1316 [D loss: 0.666603, acc.: 64.06%] [G loss: 1.012015]\n",
      "epoch:1 step:1317 [D loss: 0.692541, acc.: 54.69%] [G loss: 1.028317]\n",
      "epoch:1 step:1318 [D loss: 0.724794, acc.: 50.78%] [G loss: 0.808475]\n",
      "epoch:1 step:1319 [D loss: 0.674274, acc.: 60.94%] [G loss: 0.846918]\n",
      "epoch:1 step:1320 [D loss: 0.726942, acc.: 50.78%] [G loss: 0.862388]\n",
      "epoch:1 step:1321 [D loss: 0.771720, acc.: 41.41%] [G loss: 0.827598]\n",
      "epoch:1 step:1322 [D loss: 0.741258, acc.: 50.78%] [G loss: 0.879416]\n",
      "epoch:1 step:1323 [D loss: 0.734188, acc.: 51.56%] [G loss: 0.890539]\n",
      "epoch:1 step:1324 [D loss: 0.740700, acc.: 50.00%] [G loss: 0.841509]\n",
      "epoch:1 step:1325 [D loss: 0.691378, acc.: 57.03%] [G loss: 0.945442]\n",
      "epoch:1 step:1326 [D loss: 0.723031, acc.: 48.44%] [G loss: 0.900557]\n",
      "epoch:1 step:1327 [D loss: 0.742414, acc.: 50.78%] [G loss: 0.867694]\n",
      "epoch:1 step:1328 [D loss: 0.680155, acc.: 59.38%] [G loss: 0.910348]\n",
      "epoch:1 step:1329 [D loss: 0.698983, acc.: 57.81%] [G loss: 0.973632]\n",
      "epoch:1 step:1330 [D loss: 0.680203, acc.: 57.81%] [G loss: 0.820866]\n",
      "epoch:1 step:1331 [D loss: 0.670562, acc.: 57.03%] [G loss: 0.837320]\n",
      "epoch:1 step:1332 [D loss: 0.691252, acc.: 52.34%] [G loss: 0.802944]\n",
      "epoch:1 step:1333 [D loss: 0.772225, acc.: 47.66%] [G loss: 0.796421]\n",
      "epoch:1 step:1334 [D loss: 0.733231, acc.: 47.66%] [G loss: 0.869544]\n",
      "epoch:1 step:1335 [D loss: 0.679811, acc.: 49.22%] [G loss: 0.885353]\n",
      "epoch:1 step:1336 [D loss: 0.637535, acc.: 64.06%] [G loss: 0.888443]\n",
      "epoch:1 step:1337 [D loss: 0.723338, acc.: 49.22%] [G loss: 0.966516]\n",
      "epoch:1 step:1338 [D loss: 0.716919, acc.: 53.91%] [G loss: 0.905471]\n",
      "epoch:1 step:1339 [D loss: 0.678399, acc.: 58.59%] [G loss: 0.959605]\n",
      "epoch:1 step:1340 [D loss: 0.752447, acc.: 47.66%] [G loss: 0.949304]\n",
      "epoch:1 step:1341 [D loss: 0.691711, acc.: 53.91%] [G loss: 0.870896]\n",
      "epoch:1 step:1342 [D loss: 0.701669, acc.: 53.12%] [G loss: 0.880834]\n",
      "epoch:1 step:1343 [D loss: 0.711770, acc.: 58.59%] [G loss: 0.820554]\n",
      "epoch:1 step:1344 [D loss: 0.733047, acc.: 49.22%] [G loss: 0.915923]\n",
      "epoch:1 step:1345 [D loss: 0.753731, acc.: 46.09%] [G loss: 0.896258]\n",
      "epoch:1 step:1346 [D loss: 0.717842, acc.: 46.88%] [G loss: 0.944158]\n",
      "epoch:1 step:1347 [D loss: 0.729444, acc.: 47.66%] [G loss: 0.880576]\n",
      "epoch:1 step:1348 [D loss: 0.739730, acc.: 49.22%] [G loss: 0.909862]\n",
      "epoch:1 step:1349 [D loss: 0.717229, acc.: 55.47%] [G loss: 0.898097]\n",
      "epoch:1 step:1350 [D loss: 0.724291, acc.: 53.12%] [G loss: 0.926462]\n",
      "epoch:1 step:1351 [D loss: 0.744921, acc.: 40.62%] [G loss: 0.837309]\n",
      "epoch:1 step:1352 [D loss: 0.645924, acc.: 64.06%] [G loss: 0.922324]\n",
      "epoch:1 step:1353 [D loss: 0.656371, acc.: 64.06%] [G loss: 0.895399]\n",
      "epoch:1 step:1354 [D loss: 0.714119, acc.: 57.81%] [G loss: 0.971234]\n",
      "epoch:1 step:1355 [D loss: 0.759009, acc.: 43.75%] [G loss: 0.913676]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1356 [D loss: 0.667008, acc.: 51.56%] [G loss: 0.803141]\n",
      "epoch:1 step:1357 [D loss: 0.703270, acc.: 46.88%] [G loss: 0.855372]\n",
      "epoch:1 step:1358 [D loss: 0.704833, acc.: 57.81%] [G loss: 0.899320]\n",
      "epoch:1 step:1359 [D loss: 0.744251, acc.: 46.88%] [G loss: 0.920721]\n",
      "epoch:1 step:1360 [D loss: 0.684638, acc.: 53.12%] [G loss: 0.960415]\n",
      "epoch:1 step:1361 [D loss: 0.668623, acc.: 61.72%] [G loss: 0.938594]\n",
      "epoch:1 step:1362 [D loss: 0.646731, acc.: 60.16%] [G loss: 0.900720]\n",
      "epoch:1 step:1363 [D loss: 0.629479, acc.: 66.41%] [G loss: 0.963535]\n",
      "epoch:1 step:1364 [D loss: 0.673735, acc.: 57.81%] [G loss: 1.021502]\n",
      "epoch:1 step:1365 [D loss: 0.614579, acc.: 69.53%] [G loss: 0.997973]\n",
      "epoch:1 step:1366 [D loss: 0.673917, acc.: 62.50%] [G loss: 0.928522]\n",
      "epoch:1 step:1367 [D loss: 0.666228, acc.: 62.50%] [G loss: 0.960048]\n",
      "epoch:1 step:1368 [D loss: 0.713556, acc.: 50.00%] [G loss: 0.935252]\n",
      "epoch:1 step:1369 [D loss: 0.736854, acc.: 48.44%] [G loss: 0.878601]\n",
      "epoch:1 step:1370 [D loss: 0.824307, acc.: 32.81%] [G loss: 0.855389]\n",
      "epoch:1 step:1371 [D loss: 0.696683, acc.: 53.91%] [G loss: 0.785414]\n",
      "epoch:1 step:1372 [D loss: 0.720654, acc.: 50.00%] [G loss: 0.901689]\n",
      "epoch:1 step:1373 [D loss: 0.682860, acc.: 57.03%] [G loss: 0.951916]\n",
      "epoch:1 step:1374 [D loss: 0.710602, acc.: 50.78%] [G loss: 1.000932]\n",
      "epoch:1 step:1375 [D loss: 0.695679, acc.: 60.16%] [G loss: 0.924081]\n",
      "epoch:1 step:1376 [D loss: 0.691366, acc.: 52.34%] [G loss: 1.014802]\n",
      "epoch:1 step:1377 [D loss: 0.683989, acc.: 53.91%] [G loss: 0.920030]\n",
      "epoch:1 step:1378 [D loss: 0.683161, acc.: 56.25%] [G loss: 0.952580]\n",
      "epoch:1 step:1379 [D loss: 0.696333, acc.: 53.91%] [G loss: 0.787698]\n",
      "epoch:1 step:1380 [D loss: 0.716804, acc.: 46.88%] [G loss: 0.813902]\n",
      "epoch:1 step:1381 [D loss: 0.661230, acc.: 60.16%] [G loss: 0.929886]\n",
      "epoch:1 step:1382 [D loss: 0.693328, acc.: 55.47%] [G loss: 0.884943]\n",
      "epoch:1 step:1383 [D loss: 0.735530, acc.: 46.88%] [G loss: 0.856048]\n",
      "epoch:1 step:1384 [D loss: 0.683625, acc.: 54.69%] [G loss: 0.940808]\n",
      "epoch:1 step:1385 [D loss: 0.769004, acc.: 42.19%] [G loss: 0.870027]\n",
      "epoch:1 step:1386 [D loss: 0.748097, acc.: 44.53%] [G loss: 0.900715]\n",
      "epoch:1 step:1387 [D loss: 0.652295, acc.: 55.47%] [G loss: 0.973671]\n",
      "epoch:1 step:1388 [D loss: 0.661614, acc.: 60.94%] [G loss: 1.033917]\n",
      "epoch:1 step:1389 [D loss: 0.673536, acc.: 56.25%] [G loss: 1.020539]\n",
      "epoch:1 step:1390 [D loss: 0.684158, acc.: 53.12%] [G loss: 1.078627]\n",
      "epoch:1 step:1391 [D loss: 0.637643, acc.: 68.75%] [G loss: 0.915033]\n",
      "epoch:1 step:1392 [D loss: 0.644575, acc.: 62.50%] [G loss: 0.991639]\n",
      "epoch:1 step:1393 [D loss: 0.672319, acc.: 60.16%] [G loss: 0.941476]\n",
      "epoch:1 step:1394 [D loss: 0.717583, acc.: 56.25%] [G loss: 0.918683]\n",
      "epoch:1 step:1395 [D loss: 0.863151, acc.: 40.62%] [G loss: 0.856178]\n",
      "epoch:1 step:1396 [D loss: 0.754616, acc.: 43.75%] [G loss: 0.833913]\n",
      "epoch:1 step:1397 [D loss: 0.696494, acc.: 50.00%] [G loss: 0.890431]\n",
      "epoch:1 step:1398 [D loss: 0.696839, acc.: 54.69%] [G loss: 0.906725]\n",
      "epoch:1 step:1399 [D loss: 0.694362, acc.: 49.22%] [G loss: 0.891163]\n",
      "epoch:1 step:1400 [D loss: 0.678381, acc.: 58.59%] [G loss: 0.953961]\n",
      "##############\n",
      "[3.86694981 2.34747589 5.89133505 5.02395097 4.23765621 5.96049978\n",
      " 4.85714579 5.58381894 5.06253122 4.31225452]\n",
      "##########\n",
      "epoch:1 step:1401 [D loss: 0.671771, acc.: 63.28%] [G loss: 0.916679]\n",
      "epoch:1 step:1402 [D loss: 0.705448, acc.: 53.12%] [G loss: 0.875876]\n",
      "epoch:1 step:1403 [D loss: 0.687139, acc.: 58.59%] [G loss: 0.878990]\n",
      "epoch:1 step:1404 [D loss: 0.672321, acc.: 57.03%] [G loss: 0.848924]\n",
      "epoch:1 step:1405 [D loss: 0.700806, acc.: 50.00%] [G loss: 0.915135]\n",
      "epoch:1 step:1406 [D loss: 0.710662, acc.: 53.12%] [G loss: 0.898117]\n",
      "epoch:1 step:1407 [D loss: 0.699183, acc.: 53.12%] [G loss: 0.899964]\n",
      "epoch:1 step:1408 [D loss: 0.632867, acc.: 64.84%] [G loss: 0.912813]\n",
      "epoch:1 step:1409 [D loss: 0.654737, acc.: 60.94%] [G loss: 0.973724]\n",
      "epoch:1 step:1410 [D loss: 0.810381, acc.: 39.06%] [G loss: 0.879778]\n",
      "epoch:1 step:1411 [D loss: 0.701458, acc.: 53.12%] [G loss: 0.923839]\n",
      "epoch:1 step:1412 [D loss: 0.664823, acc.: 57.03%] [G loss: 0.913501]\n",
      "epoch:1 step:1413 [D loss: 0.713731, acc.: 55.47%] [G loss: 0.972293]\n",
      "epoch:1 step:1414 [D loss: 0.722184, acc.: 53.12%] [G loss: 0.831388]\n",
      "epoch:1 step:1415 [D loss: 0.687352, acc.: 56.25%] [G loss: 0.875950]\n",
      "epoch:1 step:1416 [D loss: 0.722540, acc.: 53.12%] [G loss: 0.897343]\n",
      "epoch:1 step:1417 [D loss: 0.687307, acc.: 53.91%] [G loss: 0.912186]\n",
      "epoch:1 step:1418 [D loss: 0.705975, acc.: 51.56%] [G loss: 0.906894]\n",
      "epoch:1 step:1419 [D loss: 0.765782, acc.: 42.19%] [G loss: 0.904519]\n",
      "epoch:1 step:1420 [D loss: 0.626437, acc.: 62.50%] [G loss: 0.882207]\n",
      "epoch:1 step:1421 [D loss: 0.668227, acc.: 57.81%] [G loss: 0.952529]\n",
      "epoch:1 step:1422 [D loss: 0.668995, acc.: 57.81%] [G loss: 0.980999]\n",
      "epoch:1 step:1423 [D loss: 0.758090, acc.: 46.09%] [G loss: 0.841192]\n",
      "epoch:1 step:1424 [D loss: 0.774297, acc.: 44.53%] [G loss: 0.843889]\n",
      "epoch:1 step:1425 [D loss: 0.698737, acc.: 46.88%] [G loss: 0.907463]\n",
      "epoch:1 step:1426 [D loss: 0.770023, acc.: 46.88%] [G loss: 0.868801]\n",
      "epoch:1 step:1427 [D loss: 0.715768, acc.: 52.34%] [G loss: 0.886092]\n",
      "epoch:1 step:1428 [D loss: 0.658686, acc.: 59.38%] [G loss: 0.836614]\n",
      "epoch:1 step:1429 [D loss: 0.709062, acc.: 49.22%] [G loss: 0.888805]\n",
      "epoch:1 step:1430 [D loss: 0.718164, acc.: 49.22%] [G loss: 0.861126]\n",
      "epoch:1 step:1431 [D loss: 0.713669, acc.: 58.59%] [G loss: 0.898345]\n",
      "epoch:1 step:1432 [D loss: 0.686753, acc.: 59.38%] [G loss: 0.821644]\n",
      "epoch:1 step:1433 [D loss: 0.647597, acc.: 63.28%] [G loss: 0.862598]\n",
      "epoch:1 step:1434 [D loss: 0.641526, acc.: 62.50%] [G loss: 0.877709]\n",
      "epoch:1 step:1435 [D loss: 0.738972, acc.: 46.09%] [G loss: 0.894343]\n",
      "epoch:1 step:1436 [D loss: 0.649066, acc.: 60.16%] [G loss: 0.863627]\n",
      "epoch:1 step:1437 [D loss: 0.760798, acc.: 45.31%] [G loss: 0.858507]\n",
      "epoch:1 step:1438 [D loss: 0.801382, acc.: 38.28%] [G loss: 0.756382]\n",
      "epoch:1 step:1439 [D loss: 0.750384, acc.: 46.88%] [G loss: 0.918383]\n",
      "epoch:1 step:1440 [D loss: 0.665832, acc.: 57.03%] [G loss: 0.939346]\n",
      "epoch:1 step:1441 [D loss: 0.648104, acc.: 59.38%] [G loss: 0.930092]\n",
      "epoch:1 step:1442 [D loss: 0.661045, acc.: 63.28%] [G loss: 0.996109]\n",
      "epoch:1 step:1443 [D loss: 0.686638, acc.: 53.12%] [G loss: 0.920846]\n",
      "epoch:1 step:1444 [D loss: 0.694616, acc.: 57.81%] [G loss: 0.915201]\n",
      "epoch:1 step:1445 [D loss: 0.697268, acc.: 54.69%] [G loss: 0.946655]\n",
      "epoch:1 step:1446 [D loss: 0.751299, acc.: 52.34%] [G loss: 0.890711]\n",
      "epoch:1 step:1447 [D loss: 0.751705, acc.: 45.31%] [G loss: 0.793336]\n",
      "epoch:1 step:1448 [D loss: 0.775144, acc.: 38.28%] [G loss: 0.779863]\n",
      "epoch:1 step:1449 [D loss: 0.720016, acc.: 46.09%] [G loss: 0.834834]\n",
      "epoch:1 step:1450 [D loss: 0.697671, acc.: 50.78%] [G loss: 0.842967]\n",
      "epoch:1 step:1451 [D loss: 0.710538, acc.: 50.00%] [G loss: 0.853926]\n",
      "epoch:1 step:1452 [D loss: 0.640948, acc.: 60.94%] [G loss: 0.897842]\n",
      "epoch:1 step:1453 [D loss: 0.669631, acc.: 62.50%] [G loss: 0.907564]\n",
      "epoch:1 step:1454 [D loss: 0.713390, acc.: 53.12%] [G loss: 0.913598]\n",
      "epoch:1 step:1455 [D loss: 0.733221, acc.: 45.31%] [G loss: 0.845175]\n",
      "epoch:1 step:1456 [D loss: 0.673498, acc.: 52.34%] [G loss: 0.884504]\n",
      "epoch:1 step:1457 [D loss: 0.701888, acc.: 54.69%] [G loss: 0.887400]\n",
      "epoch:1 step:1458 [D loss: 0.659695, acc.: 63.28%] [G loss: 0.840495]\n",
      "epoch:1 step:1459 [D loss: 0.668626, acc.: 58.59%] [G loss: 0.900137]\n",
      "epoch:1 step:1460 [D loss: 0.698993, acc.: 53.12%] [G loss: 0.858258]\n",
      "epoch:1 step:1461 [D loss: 0.654469, acc.: 63.28%] [G loss: 0.830423]\n",
      "epoch:1 step:1462 [D loss: 0.713853, acc.: 49.22%] [G loss: 0.947776]\n",
      "epoch:1 step:1463 [D loss: 0.752609, acc.: 49.22%] [G loss: 0.789019]\n",
      "epoch:1 step:1464 [D loss: 0.742464, acc.: 49.22%] [G loss: 0.832393]\n",
      "epoch:1 step:1465 [D loss: 0.794847, acc.: 40.62%] [G loss: 0.907027]\n",
      "epoch:1 step:1466 [D loss: 0.769968, acc.: 42.97%] [G loss: 0.928851]\n",
      "epoch:1 step:1467 [D loss: 0.676927, acc.: 55.47%] [G loss: 0.906706]\n",
      "epoch:1 step:1468 [D loss: 0.666746, acc.: 60.16%] [G loss: 0.962206]\n",
      "epoch:1 step:1469 [D loss: 0.639717, acc.: 67.19%] [G loss: 0.883514]\n",
      "epoch:1 step:1470 [D loss: 0.698696, acc.: 54.69%] [G loss: 0.814728]\n",
      "epoch:1 step:1471 [D loss: 0.660783, acc.: 61.72%] [G loss: 0.819141]\n",
      "epoch:1 step:1472 [D loss: 0.731870, acc.: 45.31%] [G loss: 0.762876]\n",
      "epoch:1 step:1473 [D loss: 0.726453, acc.: 50.00%] [G loss: 0.818310]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1474 [D loss: 0.668911, acc.: 64.06%] [G loss: 0.831456]\n",
      "epoch:1 step:1475 [D loss: 0.726467, acc.: 49.22%] [G loss: 0.878548]\n",
      "epoch:1 step:1476 [D loss: 0.762824, acc.: 46.88%] [G loss: 0.872116]\n",
      "epoch:1 step:1477 [D loss: 0.726196, acc.: 53.12%] [G loss: 0.815838]\n",
      "epoch:1 step:1478 [D loss: 0.668406, acc.: 60.16%] [G loss: 0.837323]\n",
      "epoch:1 step:1479 [D loss: 0.753289, acc.: 49.22%] [G loss: 0.912147]\n",
      "epoch:1 step:1480 [D loss: 0.774918, acc.: 46.09%] [G loss: 0.836193]\n",
      "epoch:1 step:1481 [D loss: 0.719603, acc.: 44.53%] [G loss: 0.872248]\n",
      "epoch:1 step:1482 [D loss: 0.682013, acc.: 55.47%] [G loss: 0.813171]\n",
      "epoch:1 step:1483 [D loss: 0.690728, acc.: 55.47%] [G loss: 0.918151]\n",
      "epoch:1 step:1484 [D loss: 0.720517, acc.: 49.22%] [G loss: 0.863704]\n",
      "epoch:1 step:1485 [D loss: 0.683229, acc.: 54.69%] [G loss: 0.938345]\n",
      "epoch:1 step:1486 [D loss: 0.700452, acc.: 53.12%] [G loss: 0.850760]\n",
      "epoch:1 step:1487 [D loss: 0.663656, acc.: 56.25%] [G loss: 0.786752]\n",
      "epoch:1 step:1488 [D loss: 0.664944, acc.: 62.50%] [G loss: 0.881904]\n",
      "epoch:1 step:1489 [D loss: 0.668174, acc.: 59.38%] [G loss: 0.963843]\n",
      "epoch:1 step:1490 [D loss: 0.756755, acc.: 41.41%] [G loss: 0.880573]\n",
      "epoch:1 step:1491 [D loss: 0.688838, acc.: 63.28%] [G loss: 0.853308]\n",
      "epoch:1 step:1492 [D loss: 0.683980, acc.: 52.34%] [G loss: 0.823400]\n",
      "epoch:1 step:1493 [D loss: 0.695385, acc.: 57.03%] [G loss: 0.844656]\n",
      "epoch:1 step:1494 [D loss: 0.676809, acc.: 52.34%] [G loss: 0.887620]\n",
      "epoch:1 step:1495 [D loss: 0.691666, acc.: 57.03%] [G loss: 0.833393]\n",
      "epoch:1 step:1496 [D loss: 0.739909, acc.: 44.53%] [G loss: 0.868816]\n",
      "epoch:1 step:1497 [D loss: 0.728585, acc.: 49.22%] [G loss: 0.891980]\n",
      "epoch:1 step:1498 [D loss: 0.670005, acc.: 54.69%] [G loss: 0.947002]\n",
      "epoch:1 step:1499 [D loss: 0.699831, acc.: 53.12%] [G loss: 0.934709]\n",
      "epoch:1 step:1500 [D loss: 0.726073, acc.: 51.56%] [G loss: 0.808998]\n",
      "epoch:1 step:1501 [D loss: 0.706190, acc.: 55.47%] [G loss: 0.870029]\n",
      "epoch:1 step:1502 [D loss: 0.654510, acc.: 61.72%] [G loss: 0.836126]\n",
      "epoch:1 step:1503 [D loss: 0.701329, acc.: 52.34%] [G loss: 0.861331]\n",
      "epoch:1 step:1504 [D loss: 0.684940, acc.: 52.34%] [G loss: 0.892612]\n",
      "epoch:1 step:1505 [D loss: 0.635847, acc.: 63.28%] [G loss: 0.841121]\n",
      "epoch:1 step:1506 [D loss: 0.750051, acc.: 42.97%] [G loss: 0.853897]\n",
      "epoch:1 step:1507 [D loss: 0.710680, acc.: 50.78%] [G loss: 0.847901]\n",
      "epoch:1 step:1508 [D loss: 0.693187, acc.: 50.00%] [G loss: 0.832318]\n",
      "epoch:1 step:1509 [D loss: 0.687460, acc.: 54.69%] [G loss: 0.888006]\n",
      "epoch:1 step:1510 [D loss: 0.692940, acc.: 57.81%] [G loss: 0.776898]\n",
      "epoch:1 step:1511 [D loss: 0.648893, acc.: 59.38%] [G loss: 0.905291]\n",
      "epoch:1 step:1512 [D loss: 0.692420, acc.: 53.91%] [G loss: 0.815849]\n",
      "epoch:1 step:1513 [D loss: 0.731476, acc.: 46.09%] [G loss: 0.873238]\n",
      "epoch:1 step:1514 [D loss: 0.753912, acc.: 40.62%] [G loss: 0.820862]\n",
      "epoch:1 step:1515 [D loss: 0.667922, acc.: 63.28%] [G loss: 0.938523]\n",
      "epoch:1 step:1516 [D loss: 0.643904, acc.: 59.38%] [G loss: 0.943058]\n",
      "epoch:1 step:1517 [D loss: 0.712126, acc.: 53.12%] [G loss: 0.855665]\n",
      "epoch:1 step:1518 [D loss: 0.689269, acc.: 49.22%] [G loss: 0.832223]\n",
      "epoch:1 step:1519 [D loss: 0.703591, acc.: 53.12%] [G loss: 0.882045]\n",
      "epoch:1 step:1520 [D loss: 0.706910, acc.: 51.56%] [G loss: 0.855994]\n",
      "epoch:1 step:1521 [D loss: 0.754059, acc.: 46.88%] [G loss: 0.891240]\n",
      "epoch:1 step:1522 [D loss: 0.656581, acc.: 59.38%] [G loss: 0.881047]\n",
      "epoch:1 step:1523 [D loss: 0.671501, acc.: 58.59%] [G loss: 0.850951]\n",
      "epoch:1 step:1524 [D loss: 0.697784, acc.: 54.69%] [G loss: 0.857340]\n",
      "epoch:1 step:1525 [D loss: 0.693898, acc.: 53.91%] [G loss: 0.856939]\n",
      "epoch:1 step:1526 [D loss: 0.674918, acc.: 55.47%] [G loss: 0.888615]\n",
      "epoch:1 step:1527 [D loss: 0.708201, acc.: 53.12%] [G loss: 0.954920]\n",
      "epoch:1 step:1528 [D loss: 0.733444, acc.: 46.09%] [G loss: 0.836758]\n",
      "epoch:1 step:1529 [D loss: 0.698355, acc.: 54.69%] [G loss: 0.981992]\n",
      "epoch:1 step:1530 [D loss: 0.665244, acc.: 64.06%] [G loss: 0.862231]\n",
      "epoch:1 step:1531 [D loss: 0.691790, acc.: 57.03%] [G loss: 0.826878]\n",
      "epoch:1 step:1532 [D loss: 0.679073, acc.: 57.03%] [G loss: 0.844907]\n",
      "epoch:1 step:1533 [D loss: 0.714167, acc.: 54.69%] [G loss: 0.906948]\n",
      "epoch:1 step:1534 [D loss: 0.716156, acc.: 52.34%] [G loss: 0.869489]\n",
      "epoch:1 step:1535 [D loss: 0.702589, acc.: 50.00%] [G loss: 0.836606]\n",
      "epoch:1 step:1536 [D loss: 0.708568, acc.: 48.44%] [G loss: 0.879653]\n",
      "epoch:1 step:1537 [D loss: 0.710532, acc.: 45.31%] [G loss: 0.916862]\n",
      "epoch:1 step:1538 [D loss: 0.708941, acc.: 53.12%] [G loss: 0.832324]\n",
      "epoch:1 step:1539 [D loss: 0.704033, acc.: 53.91%] [G loss: 0.809828]\n",
      "epoch:1 step:1540 [D loss: 0.688229, acc.: 60.16%] [G loss: 0.845992]\n",
      "epoch:1 step:1541 [D loss: 0.725880, acc.: 53.91%] [G loss: 0.849846]\n",
      "epoch:1 step:1542 [D loss: 0.708571, acc.: 51.56%] [G loss: 0.867374]\n",
      "epoch:1 step:1543 [D loss: 0.697515, acc.: 54.69%] [G loss: 0.867329]\n",
      "epoch:1 step:1544 [D loss: 0.725651, acc.: 46.09%] [G loss: 0.811744]\n",
      "epoch:1 step:1545 [D loss: 0.709632, acc.: 53.91%] [G loss: 0.829031]\n",
      "epoch:1 step:1546 [D loss: 0.700760, acc.: 57.03%] [G loss: 0.778456]\n",
      "epoch:1 step:1547 [D loss: 0.716263, acc.: 50.78%] [G loss: 0.776947]\n",
      "epoch:1 step:1548 [D loss: 0.713727, acc.: 46.88%] [G loss: 0.824935]\n",
      "epoch:1 step:1549 [D loss: 0.720833, acc.: 51.56%] [G loss: 0.840700]\n",
      "epoch:1 step:1550 [D loss: 0.685359, acc.: 57.81%] [G loss: 0.816467]\n",
      "epoch:1 step:1551 [D loss: 0.713878, acc.: 48.44%] [G loss: 0.804348]\n",
      "epoch:1 step:1552 [D loss: 0.698257, acc.: 53.12%] [G loss: 0.797252]\n",
      "epoch:1 step:1553 [D loss: 0.711668, acc.: 51.56%] [G loss: 0.753146]\n",
      "epoch:1 step:1554 [D loss: 0.658388, acc.: 60.94%] [G loss: 0.755711]\n",
      "epoch:1 step:1555 [D loss: 0.721078, acc.: 48.44%] [G loss: 0.806899]\n",
      "epoch:1 step:1556 [D loss: 0.710795, acc.: 56.25%] [G loss: 0.813783]\n",
      "epoch:1 step:1557 [D loss: 0.671278, acc.: 53.12%] [G loss: 0.945253]\n",
      "epoch:1 step:1558 [D loss: 0.700786, acc.: 55.47%] [G loss: 0.834777]\n",
      "epoch:1 step:1559 [D loss: 0.689587, acc.: 50.78%] [G loss: 0.819531]\n",
      "epoch:1 step:1560 [D loss: 0.706008, acc.: 51.56%] [G loss: 0.855471]\n",
      "epoch:1 step:1561 [D loss: 0.717022, acc.: 56.25%] [G loss: 0.884586]\n",
      "epoch:1 step:1562 [D loss: 0.744817, acc.: 39.84%] [G loss: 0.866912]\n",
      "epoch:1 step:1563 [D loss: 0.666524, acc.: 65.62%] [G loss: 0.902212]\n",
      "epoch:1 step:1564 [D loss: 0.711326, acc.: 50.00%] [G loss: 0.854909]\n",
      "epoch:1 step:1565 [D loss: 0.676625, acc.: 56.25%] [G loss: 0.831285]\n",
      "epoch:1 step:1566 [D loss: 0.678354, acc.: 57.03%] [G loss: 0.844731]\n",
      "epoch:1 step:1567 [D loss: 0.658979, acc.: 57.03%] [G loss: 0.863685]\n",
      "epoch:1 step:1568 [D loss: 0.671793, acc.: 60.16%] [G loss: 0.909882]\n",
      "epoch:1 step:1569 [D loss: 0.696080, acc.: 54.69%] [G loss: 0.883093]\n",
      "epoch:1 step:1570 [D loss: 0.689304, acc.: 59.38%] [G loss: 0.846986]\n",
      "epoch:1 step:1571 [D loss: 0.758722, acc.: 47.66%] [G loss: 0.919823]\n",
      "epoch:1 step:1572 [D loss: 0.733922, acc.: 46.09%] [G loss: 0.853725]\n",
      "epoch:1 step:1573 [D loss: 0.721194, acc.: 48.44%] [G loss: 0.877002]\n",
      "epoch:1 step:1574 [D loss: 0.681089, acc.: 55.47%] [G loss: 0.892840]\n",
      "epoch:1 step:1575 [D loss: 0.685704, acc.: 54.69%] [G loss: 0.902133]\n",
      "epoch:1 step:1576 [D loss: 0.695939, acc.: 52.34%] [G loss: 0.897219]\n",
      "epoch:1 step:1577 [D loss: 0.718569, acc.: 43.75%] [G loss: 0.807217]\n",
      "epoch:1 step:1578 [D loss: 0.704112, acc.: 47.66%] [G loss: 0.838257]\n",
      "epoch:1 step:1579 [D loss: 0.690278, acc.: 54.69%] [G loss: 0.835227]\n",
      "epoch:1 step:1580 [D loss: 0.716534, acc.: 51.56%] [G loss: 0.792030]\n",
      "epoch:1 step:1581 [D loss: 0.684887, acc.: 47.66%] [G loss: 0.806676]\n",
      "epoch:1 step:1582 [D loss: 0.714506, acc.: 52.34%] [G loss: 0.815683]\n",
      "epoch:1 step:1583 [D loss: 0.680672, acc.: 55.47%] [G loss: 0.796605]\n",
      "epoch:1 step:1584 [D loss: 0.719404, acc.: 45.31%] [G loss: 0.877823]\n",
      "epoch:1 step:1585 [D loss: 0.651877, acc.: 58.59%] [G loss: 0.828492]\n",
      "epoch:1 step:1586 [D loss: 0.665799, acc.: 63.28%] [G loss: 0.866804]\n",
      "epoch:1 step:1587 [D loss: 0.638340, acc.: 62.50%] [G loss: 0.918514]\n",
      "epoch:1 step:1588 [D loss: 0.715342, acc.: 53.91%] [G loss: 0.810202]\n",
      "epoch:1 step:1589 [D loss: 0.710857, acc.: 47.66%] [G loss: 0.848250]\n",
      "epoch:1 step:1590 [D loss: 0.748015, acc.: 43.75%] [G loss: 0.825546]\n",
      "epoch:1 step:1591 [D loss: 0.723790, acc.: 48.44%] [G loss: 0.817500]\n",
      "epoch:1 step:1592 [D loss: 0.703126, acc.: 55.47%] [G loss: 0.804400]\n",
      "epoch:1 step:1593 [D loss: 0.751046, acc.: 47.66%] [G loss: 0.811515]\n",
      "epoch:1 step:1594 [D loss: 0.718186, acc.: 53.12%] [G loss: 0.873405]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1595 [D loss: 0.725810, acc.: 44.53%] [G loss: 0.806563]\n",
      "epoch:1 step:1596 [D loss: 0.633697, acc.: 60.94%] [G loss: 0.891210]\n",
      "epoch:1 step:1597 [D loss: 0.630862, acc.: 64.06%] [G loss: 0.903538]\n",
      "epoch:1 step:1598 [D loss: 0.649290, acc.: 57.03%] [G loss: 0.895439]\n",
      "epoch:1 step:1599 [D loss: 0.685317, acc.: 53.12%] [G loss: 0.901491]\n",
      "epoch:1 step:1600 [D loss: 0.695081, acc.: 50.78%] [G loss: 0.896211]\n",
      "##############\n",
      "[3.28507067 2.07662348 6.39332297 5.61267141 4.24561549 6.44218857\n",
      " 5.4167647  5.10862045 5.16412006 4.81946018]\n",
      "##########\n",
      "epoch:1 step:1601 [D loss: 0.672243, acc.: 55.47%] [G loss: 0.907655]\n",
      "epoch:1 step:1602 [D loss: 0.728495, acc.: 52.34%] [G loss: 0.880307]\n",
      "epoch:1 step:1603 [D loss: 0.694736, acc.: 51.56%] [G loss: 0.870482]\n",
      "epoch:1 step:1604 [D loss: 0.696906, acc.: 51.56%] [G loss: 0.849829]\n",
      "epoch:1 step:1605 [D loss: 0.719143, acc.: 51.56%] [G loss: 0.863205]\n",
      "epoch:1 step:1606 [D loss: 0.719953, acc.: 45.31%] [G loss: 0.837845]\n",
      "epoch:1 step:1607 [D loss: 0.724960, acc.: 48.44%] [G loss: 0.782246]\n",
      "epoch:1 step:1608 [D loss: 0.768640, acc.: 41.41%] [G loss: 0.774508]\n",
      "epoch:1 step:1609 [D loss: 0.734472, acc.: 42.97%] [G loss: 0.840922]\n",
      "epoch:1 step:1610 [D loss: 0.699184, acc.: 52.34%] [G loss: 0.880622]\n",
      "epoch:1 step:1611 [D loss: 0.636738, acc.: 66.41%] [G loss: 0.911422]\n",
      "epoch:1 step:1612 [D loss: 0.678550, acc.: 52.34%] [G loss: 0.929542]\n",
      "epoch:1 step:1613 [D loss: 0.668687, acc.: 61.72%] [G loss: 0.932895]\n",
      "epoch:1 step:1614 [D loss: 0.650830, acc.: 61.72%] [G loss: 0.955159]\n",
      "epoch:1 step:1615 [D loss: 0.744245, acc.: 47.66%] [G loss: 0.899298]\n",
      "epoch:1 step:1616 [D loss: 0.695814, acc.: 53.12%] [G loss: 0.817846]\n",
      "epoch:1 step:1617 [D loss: 0.687196, acc.: 56.25%] [G loss: 0.871030]\n",
      "epoch:1 step:1618 [D loss: 0.687708, acc.: 55.47%] [G loss: 0.801724]\n",
      "epoch:1 step:1619 [D loss: 0.739040, acc.: 50.00%] [G loss: 0.750228]\n",
      "epoch:1 step:1620 [D loss: 0.758127, acc.: 36.72%] [G loss: 0.743947]\n",
      "epoch:1 step:1621 [D loss: 0.694139, acc.: 51.56%] [G loss: 0.771317]\n",
      "epoch:1 step:1622 [D loss: 0.698420, acc.: 57.81%] [G loss: 0.794792]\n",
      "epoch:1 step:1623 [D loss: 0.734272, acc.: 48.44%] [G loss: 0.840118]\n",
      "epoch:1 step:1624 [D loss: 0.747986, acc.: 46.09%] [G loss: 0.816186]\n",
      "epoch:1 step:1625 [D loss: 0.675804, acc.: 60.94%] [G loss: 0.892526]\n",
      "epoch:1 step:1626 [D loss: 0.712023, acc.: 51.56%] [G loss: 0.862058]\n",
      "epoch:1 step:1627 [D loss: 0.689566, acc.: 55.47%] [G loss: 0.823963]\n",
      "epoch:1 step:1628 [D loss: 0.716523, acc.: 50.00%] [G loss: 0.798811]\n",
      "epoch:1 step:1629 [D loss: 0.687523, acc.: 56.25%] [G loss: 0.861131]\n",
      "epoch:1 step:1630 [D loss: 0.694931, acc.: 57.03%] [G loss: 0.775427]\n",
      "epoch:1 step:1631 [D loss: 0.736308, acc.: 52.34%] [G loss: 0.880836]\n",
      "epoch:1 step:1632 [D loss: 0.673865, acc.: 60.94%] [G loss: 0.801833]\n",
      "epoch:1 step:1633 [D loss: 0.718013, acc.: 50.00%] [G loss: 0.773028]\n",
      "epoch:1 step:1634 [D loss: 0.697927, acc.: 50.78%] [G loss: 0.790015]\n",
      "epoch:1 step:1635 [D loss: 0.716152, acc.: 50.00%] [G loss: 0.798730]\n",
      "epoch:1 step:1636 [D loss: 0.702120, acc.: 56.25%] [G loss: 0.790975]\n",
      "epoch:1 step:1637 [D loss: 0.686469, acc.: 57.03%] [G loss: 0.785855]\n",
      "epoch:1 step:1638 [D loss: 0.721624, acc.: 51.56%] [G loss: 0.831601]\n",
      "epoch:1 step:1639 [D loss: 0.690118, acc.: 55.47%] [G loss: 0.851785]\n",
      "epoch:1 step:1640 [D loss: 0.711446, acc.: 51.56%] [G loss: 0.804047]\n",
      "epoch:1 step:1641 [D loss: 0.720876, acc.: 40.62%] [G loss: 0.822350]\n",
      "epoch:1 step:1642 [D loss: 0.685929, acc.: 62.50%] [G loss: 0.782124]\n",
      "epoch:1 step:1643 [D loss: 0.698080, acc.: 52.34%] [G loss: 0.841779]\n",
      "epoch:1 step:1644 [D loss: 0.670551, acc.: 60.94%] [G loss: 0.930166]\n",
      "epoch:1 step:1645 [D loss: 0.661309, acc.: 60.16%] [G loss: 0.850225]\n",
      "epoch:1 step:1646 [D loss: 0.655980, acc.: 57.81%] [G loss: 0.893371]\n",
      "epoch:1 step:1647 [D loss: 0.792246, acc.: 41.41%] [G loss: 0.835989]\n",
      "epoch:1 step:1648 [D loss: 0.691156, acc.: 47.66%] [G loss: 0.842401]\n",
      "epoch:1 step:1649 [D loss: 0.661939, acc.: 62.50%] [G loss: 0.851482]\n",
      "epoch:1 step:1650 [D loss: 0.688109, acc.: 57.81%] [G loss: 0.808628]\n",
      "epoch:1 step:1651 [D loss: 0.668933, acc.: 63.28%] [G loss: 0.857242]\n",
      "epoch:1 step:1652 [D loss: 0.754805, acc.: 43.75%] [G loss: 0.774711]\n",
      "epoch:1 step:1653 [D loss: 0.742038, acc.: 41.41%] [G loss: 0.807711]\n",
      "epoch:1 step:1654 [D loss: 0.751620, acc.: 39.84%] [G loss: 0.837138]\n",
      "epoch:1 step:1655 [D loss: 0.701229, acc.: 48.44%] [G loss: 0.813144]\n",
      "epoch:1 step:1656 [D loss: 0.691247, acc.: 54.69%] [G loss: 0.840157]\n",
      "epoch:1 step:1657 [D loss: 0.666966, acc.: 54.69%] [G loss: 0.830349]\n",
      "epoch:1 step:1658 [D loss: 0.708868, acc.: 52.34%] [G loss: 0.872060]\n",
      "epoch:1 step:1659 [D loss: 0.727957, acc.: 48.44%] [G loss: 0.825591]\n",
      "epoch:1 step:1660 [D loss: 0.691281, acc.: 51.56%] [G loss: 0.836699]\n",
      "epoch:1 step:1661 [D loss: 0.685811, acc.: 55.47%] [G loss: 0.875804]\n",
      "epoch:1 step:1662 [D loss: 0.687278, acc.: 53.91%] [G loss: 0.843780]\n",
      "epoch:1 step:1663 [D loss: 0.681547, acc.: 56.25%] [G loss: 0.856886]\n",
      "epoch:1 step:1664 [D loss: 0.704725, acc.: 52.34%] [G loss: 0.830080]\n",
      "epoch:1 step:1665 [D loss: 0.708878, acc.: 51.56%] [G loss: 0.912676]\n",
      "epoch:1 step:1666 [D loss: 0.690117, acc.: 55.47%] [G loss: 0.891471]\n",
      "epoch:1 step:1667 [D loss: 0.647767, acc.: 64.84%] [G loss: 0.859376]\n",
      "epoch:1 step:1668 [D loss: 0.673698, acc.: 54.69%] [G loss: 0.849820]\n",
      "epoch:1 step:1669 [D loss: 0.666010, acc.: 57.03%] [G loss: 0.851166]\n",
      "epoch:1 step:1670 [D loss: 0.661949, acc.: 60.94%] [G loss: 0.863220]\n",
      "epoch:1 step:1671 [D loss: 0.691634, acc.: 57.03%] [G loss: 0.818143]\n",
      "epoch:1 step:1672 [D loss: 0.757417, acc.: 43.75%] [G loss: 0.843961]\n",
      "epoch:1 step:1673 [D loss: 0.715458, acc.: 50.00%] [G loss: 0.814043]\n",
      "epoch:1 step:1674 [D loss: 0.726471, acc.: 49.22%] [G loss: 0.757379]\n",
      "epoch:1 step:1675 [D loss: 0.744873, acc.: 48.44%] [G loss: 0.835227]\n",
      "epoch:1 step:1676 [D loss: 0.734636, acc.: 45.31%] [G loss: 0.904392]\n",
      "epoch:1 step:1677 [D loss: 0.708921, acc.: 49.22%] [G loss: 0.854004]\n",
      "epoch:1 step:1678 [D loss: 0.712423, acc.: 44.53%] [G loss: 0.846262]\n",
      "epoch:1 step:1679 [D loss: 0.708205, acc.: 46.09%] [G loss: 0.864474]\n",
      "epoch:1 step:1680 [D loss: 0.672799, acc.: 52.34%] [G loss: 0.905650]\n",
      "epoch:1 step:1681 [D loss: 0.686462, acc.: 54.69%] [G loss: 0.858387]\n",
      "epoch:1 step:1682 [D loss: 0.705715, acc.: 45.31%] [G loss: 0.904724]\n",
      "epoch:1 step:1683 [D loss: 0.682658, acc.: 58.59%] [G loss: 0.774587]\n",
      "epoch:1 step:1684 [D loss: 0.664172, acc.: 59.38%] [G loss: 0.803481]\n",
      "epoch:1 step:1685 [D loss: 0.789201, acc.: 35.16%] [G loss: 0.773770]\n",
      "epoch:1 step:1686 [D loss: 0.752947, acc.: 40.62%] [G loss: 0.751143]\n",
      "epoch:1 step:1687 [D loss: 0.716785, acc.: 47.66%] [G loss: 0.794986]\n",
      "epoch:1 step:1688 [D loss: 0.732424, acc.: 41.41%] [G loss: 0.763552]\n",
      "epoch:1 step:1689 [D loss: 0.715086, acc.: 48.44%] [G loss: 0.746249]\n",
      "epoch:1 step:1690 [D loss: 0.708488, acc.: 48.44%] [G loss: 0.817640]\n",
      "epoch:1 step:1691 [D loss: 0.721419, acc.: 42.19%] [G loss: 0.762146]\n",
      "epoch:1 step:1692 [D loss: 0.661519, acc.: 63.28%] [G loss: 0.811539]\n",
      "epoch:1 step:1693 [D loss: 0.628759, acc.: 70.31%] [G loss: 0.875218]\n",
      "epoch:1 step:1694 [D loss: 0.688335, acc.: 56.25%] [G loss: 0.811862]\n",
      "epoch:1 step:1695 [D loss: 0.705345, acc.: 45.31%] [G loss: 0.821949]\n",
      "epoch:1 step:1696 [D loss: 0.758347, acc.: 42.19%] [G loss: 0.771729]\n",
      "epoch:1 step:1697 [D loss: 0.714558, acc.: 42.97%] [G loss: 0.777806]\n",
      "epoch:1 step:1698 [D loss: 0.712937, acc.: 44.53%] [G loss: 0.760008]\n",
      "epoch:1 step:1699 [D loss: 0.700965, acc.: 50.00%] [G loss: 0.765258]\n",
      "epoch:1 step:1700 [D loss: 0.670698, acc.: 57.81%] [G loss: 0.842367]\n",
      "epoch:1 step:1701 [D loss: 0.702251, acc.: 52.34%] [G loss: 0.751260]\n",
      "epoch:1 step:1702 [D loss: 0.710454, acc.: 45.31%] [G loss: 0.820295]\n",
      "epoch:1 step:1703 [D loss: 0.683578, acc.: 52.34%] [G loss: 0.865985]\n",
      "epoch:1 step:1704 [D loss: 0.697642, acc.: 56.25%] [G loss: 0.801269]\n",
      "epoch:1 step:1705 [D loss: 0.689530, acc.: 53.91%] [G loss: 0.805094]\n",
      "epoch:1 step:1706 [D loss: 0.691925, acc.: 50.00%] [G loss: 0.799823]\n",
      "epoch:1 step:1707 [D loss: 0.685461, acc.: 60.16%] [G loss: 0.804386]\n",
      "epoch:1 step:1708 [D loss: 0.661538, acc.: 57.81%] [G loss: 0.847899]\n",
      "epoch:1 step:1709 [D loss: 0.717700, acc.: 51.56%] [G loss: 0.757803]\n",
      "epoch:1 step:1710 [D loss: 0.712250, acc.: 48.44%] [G loss: 0.755342]\n",
      "epoch:1 step:1711 [D loss: 0.713076, acc.: 49.22%] [G loss: 0.793510]\n",
      "epoch:1 step:1712 [D loss: 0.702929, acc.: 53.91%] [G loss: 0.771402]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1713 [D loss: 0.727321, acc.: 46.88%] [G loss: 0.794469]\n",
      "epoch:1 step:1714 [D loss: 0.729602, acc.: 49.22%] [G loss: 0.792581]\n",
      "epoch:1 step:1715 [D loss: 0.701670, acc.: 53.91%] [G loss: 0.912058]\n",
      "epoch:1 step:1716 [D loss: 0.712795, acc.: 47.66%] [G loss: 0.789017]\n",
      "epoch:1 step:1717 [D loss: 0.703295, acc.: 53.12%] [G loss: 0.858658]\n",
      "epoch:1 step:1718 [D loss: 0.701266, acc.: 50.00%] [G loss: 0.874816]\n",
      "epoch:1 step:1719 [D loss: 0.608938, acc.: 66.41%] [G loss: 0.948982]\n",
      "epoch:1 step:1720 [D loss: 0.704671, acc.: 53.91%] [G loss: 0.914123]\n",
      "epoch:1 step:1721 [D loss: 0.673988, acc.: 52.34%] [G loss: 0.950327]\n",
      "epoch:1 step:1722 [D loss: 0.665241, acc.: 64.06%] [G loss: 0.868745]\n",
      "epoch:1 step:1723 [D loss: 0.688621, acc.: 62.50%] [G loss: 0.871581]\n",
      "epoch:1 step:1724 [D loss: 0.724901, acc.: 50.78%] [G loss: 0.798708]\n",
      "epoch:1 step:1725 [D loss: 0.759465, acc.: 49.22%] [G loss: 0.766337]\n",
      "epoch:1 step:1726 [D loss: 0.735788, acc.: 42.97%] [G loss: 0.769240]\n",
      "epoch:1 step:1727 [D loss: 0.709204, acc.: 50.00%] [G loss: 0.822880]\n",
      "epoch:1 step:1728 [D loss: 0.701801, acc.: 48.44%] [G loss: 0.776794]\n",
      "epoch:1 step:1729 [D loss: 0.683074, acc.: 51.56%] [G loss: 0.809904]\n",
      "epoch:1 step:1730 [D loss: 0.695085, acc.: 51.56%] [G loss: 0.782897]\n",
      "epoch:1 step:1731 [D loss: 0.705910, acc.: 50.78%] [G loss: 0.748798]\n",
      "epoch:1 step:1732 [D loss: 0.660318, acc.: 60.94%] [G loss: 0.840818]\n",
      "epoch:1 step:1733 [D loss: 0.672856, acc.: 56.25%] [G loss: 0.809504]\n",
      "epoch:1 step:1734 [D loss: 0.755577, acc.: 35.94%] [G loss: 0.803238]\n",
      "epoch:1 step:1735 [D loss: 0.709053, acc.: 48.44%] [G loss: 0.802060]\n",
      "epoch:1 step:1736 [D loss: 0.673561, acc.: 56.25%] [G loss: 0.796204]\n",
      "epoch:1 step:1737 [D loss: 0.733804, acc.: 44.53%] [G loss: 0.814722]\n",
      "epoch:1 step:1738 [D loss: 0.733697, acc.: 46.88%] [G loss: 0.757404]\n",
      "epoch:1 step:1739 [D loss: 0.643327, acc.: 62.50%] [G loss: 0.811486]\n",
      "epoch:1 step:1740 [D loss: 0.660333, acc.: 60.94%] [G loss: 0.796566]\n",
      "epoch:1 step:1741 [D loss: 0.703723, acc.: 53.12%] [G loss: 0.823771]\n",
      "epoch:1 step:1742 [D loss: 0.738151, acc.: 47.66%] [G loss: 0.789222]\n",
      "epoch:1 step:1743 [D loss: 0.676447, acc.: 53.12%] [G loss: 0.861581]\n",
      "epoch:1 step:1744 [D loss: 0.697913, acc.: 52.34%] [G loss: 0.817621]\n",
      "epoch:1 step:1745 [D loss: 0.728256, acc.: 46.09%] [G loss: 0.794970]\n",
      "epoch:1 step:1746 [D loss: 0.704779, acc.: 51.56%] [G loss: 0.773373]\n",
      "epoch:1 step:1747 [D loss: 0.706588, acc.: 52.34%] [G loss: 0.788682]\n",
      "epoch:1 step:1748 [D loss: 0.704053, acc.: 53.91%] [G loss: 0.799386]\n",
      "epoch:1 step:1749 [D loss: 0.731073, acc.: 47.66%] [G loss: 0.824944]\n",
      "epoch:1 step:1750 [D loss: 0.699299, acc.: 53.12%] [G loss: 0.771887]\n",
      "epoch:1 step:1751 [D loss: 0.695797, acc.: 51.56%] [G loss: 0.772869]\n",
      "epoch:1 step:1752 [D loss: 0.700890, acc.: 53.91%] [G loss: 0.797110]\n",
      "epoch:1 step:1753 [D loss: 0.696554, acc.: 54.69%] [G loss: 0.817899]\n",
      "epoch:1 step:1754 [D loss: 0.690597, acc.: 58.59%] [G loss: 0.810951]\n",
      "epoch:1 step:1755 [D loss: 0.690578, acc.: 55.47%] [G loss: 0.801002]\n",
      "epoch:1 step:1756 [D loss: 0.675275, acc.: 55.47%] [G loss: 0.818655]\n",
      "epoch:1 step:1757 [D loss: 0.724991, acc.: 42.97%] [G loss: 0.820782]\n",
      "epoch:1 step:1758 [D loss: 0.678455, acc.: 57.03%] [G loss: 0.837421]\n",
      "epoch:1 step:1759 [D loss: 0.688553, acc.: 53.91%] [G loss: 0.810007]\n",
      "epoch:1 step:1760 [D loss: 0.680141, acc.: 56.25%] [G loss: 0.784555]\n",
      "epoch:1 step:1761 [D loss: 0.707090, acc.: 48.44%] [G loss: 0.807443]\n",
      "epoch:1 step:1762 [D loss: 0.659113, acc.: 60.16%] [G loss: 0.766837]\n",
      "epoch:1 step:1763 [D loss: 0.696481, acc.: 50.00%] [G loss: 0.805921]\n",
      "epoch:1 step:1764 [D loss: 0.723635, acc.: 49.22%] [G loss: 0.810689]\n",
      "epoch:1 step:1765 [D loss: 0.713057, acc.: 51.56%] [G loss: 0.777000]\n",
      "epoch:1 step:1766 [D loss: 0.660328, acc.: 62.50%] [G loss: 0.792713]\n",
      "epoch:1 step:1767 [D loss: 0.707296, acc.: 49.22%] [G loss: 0.794909]\n",
      "epoch:1 step:1768 [D loss: 0.688361, acc.: 60.94%] [G loss: 0.797157]\n",
      "epoch:1 step:1769 [D loss: 0.668177, acc.: 56.25%] [G loss: 0.783928]\n",
      "epoch:1 step:1770 [D loss: 0.726883, acc.: 46.09%] [G loss: 0.802879]\n",
      "epoch:1 step:1771 [D loss: 0.713883, acc.: 46.09%] [G loss: 0.733202]\n",
      "epoch:1 step:1772 [D loss: 0.721617, acc.: 48.44%] [G loss: 0.757736]\n",
      "epoch:1 step:1773 [D loss: 0.690052, acc.: 50.78%] [G loss: 0.803711]\n",
      "epoch:1 step:1774 [D loss: 0.669002, acc.: 56.25%] [G loss: 0.780220]\n",
      "epoch:1 step:1775 [D loss: 0.674991, acc.: 56.25%] [G loss: 0.812246]\n",
      "epoch:1 step:1776 [D loss: 0.698510, acc.: 53.91%] [G loss: 0.840038]\n",
      "epoch:1 step:1777 [D loss: 0.726844, acc.: 49.22%] [G loss: 0.800956]\n",
      "epoch:1 step:1778 [D loss: 0.690256, acc.: 53.91%] [G loss: 0.789870]\n",
      "epoch:1 step:1779 [D loss: 0.658185, acc.: 62.50%] [G loss: 0.789773]\n",
      "epoch:1 step:1780 [D loss: 0.752461, acc.: 42.97%] [G loss: 0.789067]\n",
      "epoch:1 step:1781 [D loss: 0.688499, acc.: 50.78%] [G loss: 0.820357]\n",
      "epoch:1 step:1782 [D loss: 0.710954, acc.: 54.69%] [G loss: 0.802421]\n",
      "epoch:1 step:1783 [D loss: 0.698969, acc.: 53.12%] [G loss: 0.812607]\n",
      "epoch:1 step:1784 [D loss: 0.717071, acc.: 47.66%] [G loss: 0.842112]\n",
      "epoch:1 step:1785 [D loss: 0.734293, acc.: 46.09%] [G loss: 0.734112]\n",
      "epoch:1 step:1786 [D loss: 0.718932, acc.: 48.44%] [G loss: 0.759452]\n",
      "epoch:1 step:1787 [D loss: 0.728712, acc.: 49.22%] [G loss: 0.777237]\n",
      "epoch:1 step:1788 [D loss: 0.702789, acc.: 53.91%] [G loss: 0.810742]\n",
      "epoch:1 step:1789 [D loss: 0.675177, acc.: 60.94%] [G loss: 0.819824]\n",
      "epoch:1 step:1790 [D loss: 0.660802, acc.: 61.72%] [G loss: 0.853081]\n",
      "epoch:1 step:1791 [D loss: 0.697527, acc.: 57.03%] [G loss: 0.831442]\n",
      "epoch:1 step:1792 [D loss: 0.681750, acc.: 53.91%] [G loss: 0.857111]\n",
      "epoch:1 step:1793 [D loss: 0.667752, acc.: 64.84%] [G loss: 0.830837]\n",
      "epoch:1 step:1794 [D loss: 0.665829, acc.: 59.38%] [G loss: 0.854226]\n",
      "epoch:1 step:1795 [D loss: 0.722441, acc.: 48.44%] [G loss: 0.755970]\n",
      "epoch:1 step:1796 [D loss: 0.753116, acc.: 46.88%] [G loss: 0.811870]\n",
      "epoch:1 step:1797 [D loss: 0.704981, acc.: 50.00%] [G loss: 0.791166]\n",
      "epoch:1 step:1798 [D loss: 0.702997, acc.: 51.56%] [G loss: 0.758039]\n",
      "epoch:1 step:1799 [D loss: 0.728617, acc.: 42.19%] [G loss: 0.775283]\n",
      "epoch:1 step:1800 [D loss: 0.705035, acc.: 51.56%] [G loss: 0.753668]\n",
      "##############\n",
      "[3.8846944  2.22310307 6.25813121 5.61202296 4.15371592 5.61212231\n",
      " 5.64885421 5.34667551 5.3466838  4.86817548]\n",
      "##########\n",
      "epoch:1 step:1801 [D loss: 0.693874, acc.: 50.78%] [G loss: 0.779124]\n",
      "epoch:1 step:1802 [D loss: 0.694487, acc.: 57.81%] [G loss: 0.772784]\n",
      "epoch:1 step:1803 [D loss: 0.682165, acc.: 50.78%] [G loss: 0.734379]\n",
      "epoch:1 step:1804 [D loss: 0.708964, acc.: 53.91%] [G loss: 0.777771]\n",
      "epoch:1 step:1805 [D loss: 0.690744, acc.: 54.69%] [G loss: 0.802271]\n",
      "epoch:1 step:1806 [D loss: 0.687963, acc.: 57.81%] [G loss: 0.796279]\n",
      "epoch:1 step:1807 [D loss: 0.682171, acc.: 56.25%] [G loss: 0.833636]\n",
      "epoch:1 step:1808 [D loss: 0.714849, acc.: 48.44%] [G loss: 0.784798]\n",
      "epoch:1 step:1809 [D loss: 0.707719, acc.: 51.56%] [G loss: 0.784481]\n",
      "epoch:1 step:1810 [D loss: 0.690973, acc.: 53.12%] [G loss: 0.784821]\n",
      "epoch:1 step:1811 [D loss: 0.700995, acc.: 52.34%] [G loss: 0.807628]\n",
      "epoch:1 step:1812 [D loss: 0.678971, acc.: 54.69%] [G loss: 0.784703]\n",
      "epoch:1 step:1813 [D loss: 0.741929, acc.: 46.09%] [G loss: 0.770907]\n",
      "epoch:1 step:1814 [D loss: 0.699504, acc.: 50.78%] [G loss: 0.747612]\n",
      "epoch:1 step:1815 [D loss: 0.699952, acc.: 50.00%] [G loss: 0.802324]\n",
      "epoch:1 step:1816 [D loss: 0.718537, acc.: 51.56%] [G loss: 0.756624]\n",
      "epoch:1 step:1817 [D loss: 0.717068, acc.: 52.34%] [G loss: 0.797714]\n",
      "epoch:1 step:1818 [D loss: 0.690868, acc.: 50.00%] [G loss: 0.775394]\n",
      "epoch:1 step:1819 [D loss: 0.708391, acc.: 51.56%] [G loss: 0.807414]\n",
      "epoch:1 step:1820 [D loss: 0.681191, acc.: 57.81%] [G loss: 0.799505]\n",
      "epoch:1 step:1821 [D loss: 0.668445, acc.: 57.81%] [G loss: 0.799352]\n",
      "epoch:1 step:1822 [D loss: 0.673410, acc.: 58.59%] [G loss: 0.794145]\n",
      "epoch:1 step:1823 [D loss: 0.697130, acc.: 53.12%] [G loss: 0.781191]\n",
      "epoch:1 step:1824 [D loss: 0.688887, acc.: 55.47%] [G loss: 0.800387]\n",
      "epoch:1 step:1825 [D loss: 0.705788, acc.: 50.00%] [G loss: 0.834156]\n",
      "epoch:1 step:1826 [D loss: 0.703347, acc.: 52.34%] [G loss: 0.832037]\n",
      "epoch:1 step:1827 [D loss: 0.668049, acc.: 61.72%] [G loss: 0.859896]\n",
      "epoch:1 step:1828 [D loss: 0.740946, acc.: 43.75%] [G loss: 0.830299]\n",
      "epoch:1 step:1829 [D loss: 0.761796, acc.: 39.84%] [G loss: 0.803903]\n",
      "epoch:1 step:1830 [D loss: 0.745291, acc.: 40.62%] [G loss: 0.782683]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1831 [D loss: 0.712407, acc.: 47.66%] [G loss: 0.818495]\n",
      "epoch:1 step:1832 [D loss: 0.754088, acc.: 36.72%] [G loss: 0.743971]\n",
      "epoch:1 step:1833 [D loss: 0.687552, acc.: 50.78%] [G loss: 0.789231]\n",
      "epoch:1 step:1834 [D loss: 0.694805, acc.: 50.78%] [G loss: 0.771342]\n",
      "epoch:1 step:1835 [D loss: 0.697543, acc.: 54.69%] [G loss: 0.830519]\n",
      "epoch:1 step:1836 [D loss: 0.661198, acc.: 64.84%] [G loss: 0.801719]\n",
      "epoch:1 step:1837 [D loss: 0.675532, acc.: 59.38%] [G loss: 0.853771]\n",
      "epoch:1 step:1838 [D loss: 0.685180, acc.: 53.12%] [G loss: 0.808095]\n",
      "epoch:1 step:1839 [D loss: 0.720895, acc.: 50.78%] [G loss: 0.821512]\n",
      "epoch:1 step:1840 [D loss: 0.705689, acc.: 53.91%] [G loss: 0.772068]\n",
      "epoch:1 step:1841 [D loss: 0.753544, acc.: 36.72%] [G loss: 0.808561]\n",
      "epoch:1 step:1842 [D loss: 0.716643, acc.: 47.66%] [G loss: 0.786404]\n",
      "epoch:1 step:1843 [D loss: 0.721225, acc.: 42.97%] [G loss: 0.741058]\n",
      "epoch:1 step:1844 [D loss: 0.707522, acc.: 47.66%] [G loss: 0.775387]\n",
      "epoch:1 step:1845 [D loss: 0.675353, acc.: 53.91%] [G loss: 0.771989]\n",
      "epoch:1 step:1846 [D loss: 0.689769, acc.: 54.69%] [G loss: 0.821622]\n",
      "epoch:1 step:1847 [D loss: 0.718159, acc.: 47.66%] [G loss: 0.819373]\n",
      "epoch:1 step:1848 [D loss: 0.668330, acc.: 60.16%] [G loss: 0.799746]\n",
      "epoch:1 step:1849 [D loss: 0.678729, acc.: 55.47%] [G loss: 0.773837]\n",
      "epoch:1 step:1850 [D loss: 0.690087, acc.: 50.78%] [G loss: 0.759326]\n",
      "epoch:1 step:1851 [D loss: 0.707052, acc.: 49.22%] [G loss: 0.802333]\n",
      "epoch:1 step:1852 [D loss: 0.683087, acc.: 56.25%] [G loss: 0.768351]\n",
      "epoch:1 step:1853 [D loss: 0.726204, acc.: 45.31%] [G loss: 0.782657]\n",
      "epoch:1 step:1854 [D loss: 0.736290, acc.: 44.53%] [G loss: 0.714592]\n",
      "epoch:1 step:1855 [D loss: 0.694441, acc.: 50.78%] [G loss: 0.783137]\n",
      "epoch:1 step:1856 [D loss: 0.704166, acc.: 50.00%] [G loss: 0.832321]\n",
      "epoch:1 step:1857 [D loss: 0.756696, acc.: 32.03%] [G loss: 0.805870]\n",
      "epoch:1 step:1858 [D loss: 0.704060, acc.: 50.00%] [G loss: 0.780740]\n",
      "epoch:1 step:1859 [D loss: 0.700816, acc.: 50.78%] [G loss: 0.737557]\n",
      "epoch:1 step:1860 [D loss: 0.685640, acc.: 50.78%] [G loss: 0.797592]\n",
      "epoch:1 step:1861 [D loss: 0.655045, acc.: 59.38%] [G loss: 0.820934]\n",
      "epoch:1 step:1862 [D loss: 0.657978, acc.: 60.94%] [G loss: 0.756014]\n",
      "epoch:1 step:1863 [D loss: 0.655109, acc.: 60.16%] [G loss: 0.812362]\n",
      "epoch:1 step:1864 [D loss: 0.673241, acc.: 57.81%] [G loss: 0.757578]\n",
      "epoch:1 step:1865 [D loss: 0.726048, acc.: 49.22%] [G loss: 0.784213]\n",
      "epoch:1 step:1866 [D loss: 0.672194, acc.: 55.47%] [G loss: 0.826462]\n",
      "epoch:1 step:1867 [D loss: 0.620449, acc.: 71.88%] [G loss: 0.850068]\n",
      "epoch:1 step:1868 [D loss: 0.658153, acc.: 65.62%] [G loss: 0.842316]\n",
      "epoch:1 step:1869 [D loss: 0.727878, acc.: 48.44%] [G loss: 0.781310]\n",
      "epoch:1 step:1870 [D loss: 0.691764, acc.: 52.34%] [G loss: 0.825475]\n",
      "epoch:1 step:1871 [D loss: 0.747103, acc.: 41.41%] [G loss: 0.768136]\n",
      "epoch:1 step:1872 [D loss: 0.659395, acc.: 62.50%] [G loss: 0.728596]\n",
      "epoch:1 step:1873 [D loss: 0.641267, acc.: 61.72%] [G loss: 0.744838]\n",
      "epoch:1 step:1874 [D loss: 0.693958, acc.: 50.00%] [G loss: 0.843211]\n",
      "epoch:2 step:1875 [D loss: 0.748308, acc.: 51.56%] [G loss: 0.878655]\n",
      "epoch:2 step:1876 [D loss: 0.743024, acc.: 46.88%] [G loss: 0.793444]\n",
      "epoch:2 step:1877 [D loss: 0.746917, acc.: 46.88%] [G loss: 0.869452]\n",
      "epoch:2 step:1878 [D loss: 0.699130, acc.: 47.66%] [G loss: 0.833541]\n",
      "epoch:2 step:1879 [D loss: 0.708606, acc.: 54.69%] [G loss: 0.787627]\n",
      "epoch:2 step:1880 [D loss: 0.711714, acc.: 48.44%] [G loss: 0.809365]\n",
      "epoch:2 step:1881 [D loss: 0.665807, acc.: 55.47%] [G loss: 0.843144]\n",
      "epoch:2 step:1882 [D loss: 0.689404, acc.: 60.16%] [G loss: 0.831769]\n",
      "epoch:2 step:1883 [D loss: 0.663838, acc.: 60.16%] [G loss: 0.815011]\n",
      "epoch:2 step:1884 [D loss: 0.679040, acc.: 56.25%] [G loss: 0.855668]\n",
      "epoch:2 step:1885 [D loss: 0.732791, acc.: 48.44%] [G loss: 0.834111]\n",
      "epoch:2 step:1886 [D loss: 0.743222, acc.: 46.09%] [G loss: 0.769083]\n",
      "epoch:2 step:1887 [D loss: 0.674001, acc.: 54.69%] [G loss: 0.751026]\n",
      "epoch:2 step:1888 [D loss: 0.680966, acc.: 56.25%] [G loss: 0.812090]\n",
      "epoch:2 step:1889 [D loss: 0.654421, acc.: 67.19%] [G loss: 0.782778]\n",
      "epoch:2 step:1890 [D loss: 0.680084, acc.: 57.03%] [G loss: 0.846746]\n",
      "epoch:2 step:1891 [D loss: 0.683632, acc.: 58.59%] [G loss: 0.831617]\n",
      "epoch:2 step:1892 [D loss: 0.677217, acc.: 57.81%] [G loss: 0.823788]\n",
      "epoch:2 step:1893 [D loss: 0.739312, acc.: 44.53%] [G loss: 0.795017]\n",
      "epoch:2 step:1894 [D loss: 0.695617, acc.: 51.56%] [G loss: 0.804072]\n",
      "epoch:2 step:1895 [D loss: 0.705044, acc.: 55.47%] [G loss: 0.850774]\n",
      "epoch:2 step:1896 [D loss: 0.638770, acc.: 62.50%] [G loss: 0.918553]\n",
      "epoch:2 step:1897 [D loss: 0.693884, acc.: 53.12%] [G loss: 0.877780]\n",
      "epoch:2 step:1898 [D loss: 0.714640, acc.: 48.44%] [G loss: 0.863891]\n",
      "epoch:2 step:1899 [D loss: 0.646192, acc.: 59.38%] [G loss: 0.813071]\n",
      "epoch:2 step:1900 [D loss: 0.715657, acc.: 47.66%] [G loss: 0.791780]\n",
      "epoch:2 step:1901 [D loss: 0.734098, acc.: 44.53%] [G loss: 0.738299]\n",
      "epoch:2 step:1902 [D loss: 0.766641, acc.: 37.50%] [G loss: 0.776286]\n",
      "epoch:2 step:1903 [D loss: 0.722905, acc.: 47.66%] [G loss: 0.815351]\n",
      "epoch:2 step:1904 [D loss: 0.697311, acc.: 51.56%] [G loss: 0.766197]\n",
      "epoch:2 step:1905 [D loss: 0.743598, acc.: 43.75%] [G loss: 0.802402]\n",
      "epoch:2 step:1906 [D loss: 0.704950, acc.: 45.31%] [G loss: 0.810402]\n",
      "epoch:2 step:1907 [D loss: 0.747994, acc.: 47.66%] [G loss: 0.777642]\n",
      "epoch:2 step:1908 [D loss: 0.671976, acc.: 56.25%] [G loss: 0.799489]\n",
      "epoch:2 step:1909 [D loss: 0.653208, acc.: 64.06%] [G loss: 0.883991]\n",
      "epoch:2 step:1910 [D loss: 0.648926, acc.: 64.06%] [G loss: 0.839287]\n",
      "epoch:2 step:1911 [D loss: 0.687033, acc.: 60.16%] [G loss: 0.861435]\n",
      "epoch:2 step:1912 [D loss: 0.719850, acc.: 50.00%] [G loss: 0.838008]\n",
      "epoch:2 step:1913 [D loss: 0.693693, acc.: 54.69%] [G loss: 0.809043]\n",
      "epoch:2 step:1914 [D loss: 0.677327, acc.: 57.03%] [G loss: 0.829907]\n",
      "epoch:2 step:1915 [D loss: 0.728779, acc.: 41.41%] [G loss: 0.761723]\n",
      "epoch:2 step:1916 [D loss: 0.698300, acc.: 54.69%] [G loss: 0.748860]\n",
      "epoch:2 step:1917 [D loss: 0.698029, acc.: 53.12%] [G loss: 0.756748]\n",
      "epoch:2 step:1918 [D loss: 0.748445, acc.: 45.31%] [G loss: 0.714239]\n",
      "epoch:2 step:1919 [D loss: 0.729835, acc.: 41.41%] [G loss: 0.733397]\n",
      "epoch:2 step:1920 [D loss: 0.711842, acc.: 45.31%] [G loss: 0.787170]\n",
      "epoch:2 step:1921 [D loss: 0.723370, acc.: 48.44%] [G loss: 0.786197]\n",
      "epoch:2 step:1922 [D loss: 0.692980, acc.: 55.47%] [G loss: 0.775263]\n",
      "epoch:2 step:1923 [D loss: 0.696787, acc.: 47.66%] [G loss: 0.769386]\n",
      "epoch:2 step:1924 [D loss: 0.717246, acc.: 47.66%] [G loss: 0.786149]\n",
      "epoch:2 step:1925 [D loss: 0.705062, acc.: 51.56%] [G loss: 0.785043]\n",
      "epoch:2 step:1926 [D loss: 0.669659, acc.: 53.12%] [G loss: 0.829890]\n",
      "epoch:2 step:1927 [D loss: 0.656350, acc.: 58.59%] [G loss: 0.811535]\n",
      "epoch:2 step:1928 [D loss: 0.691518, acc.: 55.47%] [G loss: 0.784649]\n",
      "epoch:2 step:1929 [D loss: 0.676467, acc.: 55.47%] [G loss: 0.816035]\n",
      "epoch:2 step:1930 [D loss: 0.672008, acc.: 56.25%] [G loss: 0.785931]\n",
      "epoch:2 step:1931 [D loss: 0.697949, acc.: 53.12%] [G loss: 0.793342]\n",
      "epoch:2 step:1932 [D loss: 0.701568, acc.: 49.22%] [G loss: 0.801942]\n",
      "epoch:2 step:1933 [D loss: 0.702927, acc.: 46.09%] [G loss: 0.764787]\n",
      "epoch:2 step:1934 [D loss: 0.703502, acc.: 55.47%] [G loss: 0.805928]\n",
      "epoch:2 step:1935 [D loss: 0.683055, acc.: 56.25%] [G loss: 0.744542]\n",
      "epoch:2 step:1936 [D loss: 0.687042, acc.: 50.78%] [G loss: 0.754492]\n",
      "epoch:2 step:1937 [D loss: 0.694124, acc.: 49.22%] [G loss: 0.748347]\n",
      "epoch:2 step:1938 [D loss: 0.706282, acc.: 51.56%] [G loss: 0.792945]\n",
      "epoch:2 step:1939 [D loss: 0.711554, acc.: 47.66%] [G loss: 0.789501]\n",
      "epoch:2 step:1940 [D loss: 0.711312, acc.: 50.78%] [G loss: 0.745369]\n",
      "epoch:2 step:1941 [D loss: 0.693228, acc.: 50.00%] [G loss: 0.812153]\n",
      "epoch:2 step:1942 [D loss: 0.702732, acc.: 49.22%] [G loss: 0.823816]\n",
      "epoch:2 step:1943 [D loss: 0.648881, acc.: 60.94%] [G loss: 0.815975]\n",
      "epoch:2 step:1944 [D loss: 0.661887, acc.: 62.50%] [G loss: 0.820684]\n",
      "epoch:2 step:1945 [D loss: 0.706120, acc.: 46.09%] [G loss: 0.832364]\n",
      "epoch:2 step:1946 [D loss: 0.716843, acc.: 44.53%] [G loss: 0.783690]\n",
      "epoch:2 step:1947 [D loss: 0.729342, acc.: 50.00%] [G loss: 0.800467]\n",
      "epoch:2 step:1948 [D loss: 0.673704, acc.: 59.38%] [G loss: 0.777123]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:1949 [D loss: 0.687448, acc.: 58.59%] [G loss: 0.815647]\n",
      "epoch:2 step:1950 [D loss: 0.672871, acc.: 55.47%] [G loss: 0.786999]\n",
      "epoch:2 step:1951 [D loss: 0.699617, acc.: 52.34%] [G loss: 0.826582]\n",
      "epoch:2 step:1952 [D loss: 0.723267, acc.: 47.66%] [G loss: 0.865330]\n",
      "epoch:2 step:1953 [D loss: 0.716116, acc.: 46.09%] [G loss: 0.772618]\n",
      "epoch:2 step:1954 [D loss: 0.707034, acc.: 51.56%] [G loss: 0.774046]\n",
      "epoch:2 step:1955 [D loss: 0.698639, acc.: 53.91%] [G loss: 0.773227]\n",
      "epoch:2 step:1956 [D loss: 0.698740, acc.: 54.69%] [G loss: 0.801198]\n",
      "epoch:2 step:1957 [D loss: 0.675942, acc.: 54.69%] [G loss: 0.732881]\n",
      "epoch:2 step:1958 [D loss: 0.667432, acc.: 56.25%] [G loss: 0.801637]\n",
      "epoch:2 step:1959 [D loss: 0.695043, acc.: 49.22%] [G loss: 0.753467]\n",
      "epoch:2 step:1960 [D loss: 0.684357, acc.: 57.81%] [G loss: 0.775655]\n",
      "epoch:2 step:1961 [D loss: 0.690531, acc.: 57.03%] [G loss: 0.809216]\n",
      "epoch:2 step:1962 [D loss: 0.671173, acc.: 61.72%] [G loss: 0.789410]\n",
      "epoch:2 step:1963 [D loss: 0.660978, acc.: 60.16%] [G loss: 0.811195]\n",
      "epoch:2 step:1964 [D loss: 0.657000, acc.: 62.50%] [G loss: 0.773313]\n",
      "epoch:2 step:1965 [D loss: 0.718655, acc.: 48.44%] [G loss: 0.739948]\n",
      "epoch:2 step:1966 [D loss: 0.678369, acc.: 55.47%] [G loss: 0.728444]\n",
      "epoch:2 step:1967 [D loss: 0.656227, acc.: 58.59%] [G loss: 0.773053]\n",
      "epoch:2 step:1968 [D loss: 0.668029, acc.: 61.72%] [G loss: 0.796580]\n",
      "epoch:2 step:1969 [D loss: 0.689058, acc.: 52.34%] [G loss: 0.769631]\n",
      "epoch:2 step:1970 [D loss: 0.721598, acc.: 47.66%] [G loss: 0.730752]\n",
      "epoch:2 step:1971 [D loss: 0.691859, acc.: 52.34%] [G loss: 0.740907]\n",
      "epoch:2 step:1972 [D loss: 0.697593, acc.: 49.22%] [G loss: 0.755351]\n",
      "epoch:2 step:1973 [D loss: 0.742845, acc.: 46.09%] [G loss: 0.778961]\n",
      "epoch:2 step:1974 [D loss: 0.673317, acc.: 60.94%] [G loss: 0.758732]\n",
      "epoch:2 step:1975 [D loss: 0.724211, acc.: 52.34%] [G loss: 0.787135]\n",
      "epoch:2 step:1976 [D loss: 0.719151, acc.: 52.34%] [G loss: 0.814157]\n",
      "epoch:2 step:1977 [D loss: 0.697149, acc.: 51.56%] [G loss: 0.821285]\n",
      "epoch:2 step:1978 [D loss: 0.662046, acc.: 57.03%] [G loss: 0.876637]\n",
      "epoch:2 step:1979 [D loss: 0.670769, acc.: 57.03%] [G loss: 0.807390]\n",
      "epoch:2 step:1980 [D loss: 0.680446, acc.: 57.81%] [G loss: 0.828890]\n",
      "epoch:2 step:1981 [D loss: 0.652320, acc.: 63.28%] [G loss: 0.779352]\n",
      "epoch:2 step:1982 [D loss: 0.711776, acc.: 55.47%] [G loss: 0.780685]\n",
      "epoch:2 step:1983 [D loss: 0.665953, acc.: 57.81%] [G loss: 0.818409]\n",
      "epoch:2 step:1984 [D loss: 0.702881, acc.: 53.12%] [G loss: 0.789895]\n",
      "epoch:2 step:1985 [D loss: 0.694699, acc.: 53.12%] [G loss: 0.756009]\n",
      "epoch:2 step:1986 [D loss: 0.704074, acc.: 49.22%] [G loss: 0.818750]\n",
      "epoch:2 step:1987 [D loss: 0.674081, acc.: 53.91%] [G loss: 0.813182]\n",
      "epoch:2 step:1988 [D loss: 0.677865, acc.: 55.47%] [G loss: 0.770958]\n",
      "epoch:2 step:1989 [D loss: 0.678427, acc.: 57.03%] [G loss: 0.802439]\n",
      "epoch:2 step:1990 [D loss: 0.715645, acc.: 43.75%] [G loss: 0.781096]\n",
      "epoch:2 step:1991 [D loss: 0.706264, acc.: 45.31%] [G loss: 0.796272]\n",
      "epoch:2 step:1992 [D loss: 0.706690, acc.: 48.44%] [G loss: 0.836248]\n",
      "epoch:2 step:1993 [D loss: 0.688324, acc.: 53.91%] [G loss: 0.875680]\n",
      "epoch:2 step:1994 [D loss: 0.728391, acc.: 46.88%] [G loss: 0.830774]\n",
      "epoch:2 step:1995 [D loss: 0.734201, acc.: 47.66%] [G loss: 0.886693]\n",
      "epoch:2 step:1996 [D loss: 0.693434, acc.: 57.03%] [G loss: 0.902513]\n",
      "epoch:2 step:1997 [D loss: 0.663619, acc.: 60.16%] [G loss: 0.950882]\n",
      "epoch:2 step:1998 [D loss: 0.660710, acc.: 61.72%] [G loss: 1.026372]\n",
      "epoch:2 step:1999 [D loss: 0.611398, acc.: 66.41%] [G loss: 1.006916]\n",
      "epoch:2 step:2000 [D loss: 0.627505, acc.: 67.19%] [G loss: 0.926034]\n",
      "##############\n",
      "[3.68905443 2.24459474 6.88577697 5.46096522 4.02318237 6.2894407\n",
      " 5.67690869 5.29518609 5.38583764 5.13567767]\n",
      "##########\n",
      "epoch:2 step:2001 [D loss: 0.644375, acc.: 65.62%] [G loss: 0.973660]\n",
      "epoch:2 step:2002 [D loss: 0.734659, acc.: 41.41%] [G loss: 0.803630]\n",
      "epoch:2 step:2003 [D loss: 0.792615, acc.: 37.50%] [G loss: 0.783982]\n",
      "epoch:2 step:2004 [D loss: 0.696412, acc.: 53.12%] [G loss: 0.735543]\n",
      "epoch:2 step:2005 [D loss: 0.701152, acc.: 50.78%] [G loss: 0.726734]\n",
      "epoch:2 step:2006 [D loss: 0.728009, acc.: 47.66%] [G loss: 0.699171]\n",
      "epoch:2 step:2007 [D loss: 0.729004, acc.: 39.06%] [G loss: 0.785334]\n",
      "epoch:2 step:2008 [D loss: 0.721814, acc.: 43.75%] [G loss: 0.748326]\n",
      "epoch:2 step:2009 [D loss: 0.699216, acc.: 52.34%] [G loss: 0.808309]\n",
      "epoch:2 step:2010 [D loss: 0.707609, acc.: 54.69%] [G loss: 0.785993]\n",
      "epoch:2 step:2011 [D loss: 0.713604, acc.: 49.22%] [G loss: 0.797230]\n",
      "epoch:2 step:2012 [D loss: 0.697744, acc.: 57.03%] [G loss: 0.798436]\n",
      "epoch:2 step:2013 [D loss: 0.658731, acc.: 63.28%] [G loss: 0.853351]\n",
      "epoch:2 step:2014 [D loss: 0.703241, acc.: 43.75%] [G loss: 0.839003]\n",
      "epoch:2 step:2015 [D loss: 0.671875, acc.: 55.47%] [G loss: 0.817500]\n",
      "epoch:2 step:2016 [D loss: 0.676078, acc.: 53.12%] [G loss: 0.986994]\n",
      "epoch:2 step:2017 [D loss: 0.684345, acc.: 57.81%] [G loss: 0.874041]\n",
      "epoch:2 step:2018 [D loss: 0.656792, acc.: 62.50%] [G loss: 0.820687]\n",
      "epoch:2 step:2019 [D loss: 0.650475, acc.: 67.19%] [G loss: 0.820485]\n",
      "epoch:2 step:2020 [D loss: 0.703266, acc.: 52.34%] [G loss: 0.774963]\n",
      "epoch:2 step:2021 [D loss: 0.762859, acc.: 44.53%] [G loss: 0.735964]\n",
      "epoch:2 step:2022 [D loss: 0.774796, acc.: 37.50%] [G loss: 0.751496]\n",
      "epoch:2 step:2023 [D loss: 0.715996, acc.: 44.53%] [G loss: 0.715945]\n",
      "epoch:2 step:2024 [D loss: 0.700168, acc.: 50.00%] [G loss: 0.762724]\n",
      "epoch:2 step:2025 [D loss: 0.735001, acc.: 41.41%] [G loss: 0.772554]\n",
      "epoch:2 step:2026 [D loss: 0.694979, acc.: 53.12%] [G loss: 0.807316]\n",
      "epoch:2 step:2027 [D loss: 0.697575, acc.: 55.47%] [G loss: 0.806638]\n",
      "epoch:2 step:2028 [D loss: 0.677963, acc.: 60.94%] [G loss: 0.858329]\n",
      "epoch:2 step:2029 [D loss: 0.664275, acc.: 58.59%] [G loss: 0.800274]\n",
      "epoch:2 step:2030 [D loss: 0.682564, acc.: 54.69%] [G loss: 0.805242]\n",
      "epoch:2 step:2031 [D loss: 0.673177, acc.: 62.50%] [G loss: 0.799351]\n",
      "epoch:2 step:2032 [D loss: 0.694607, acc.: 51.56%] [G loss: 0.806385]\n",
      "epoch:2 step:2033 [D loss: 0.717212, acc.: 48.44%] [G loss: 0.787609]\n",
      "epoch:2 step:2034 [D loss: 0.680194, acc.: 50.78%] [G loss: 0.780745]\n",
      "epoch:2 step:2035 [D loss: 0.668085, acc.: 57.03%] [G loss: 0.781970]\n",
      "epoch:2 step:2036 [D loss: 0.685906, acc.: 58.59%] [G loss: 0.787740]\n",
      "epoch:2 step:2037 [D loss: 0.690310, acc.: 56.25%] [G loss: 0.822880]\n",
      "epoch:2 step:2038 [D loss: 0.708020, acc.: 53.12%] [G loss: 0.755162]\n",
      "epoch:2 step:2039 [D loss: 0.722704, acc.: 51.56%] [G loss: 0.738764]\n",
      "epoch:2 step:2040 [D loss: 0.753953, acc.: 36.72%] [G loss: 0.726979]\n",
      "epoch:2 step:2041 [D loss: 0.737505, acc.: 43.75%] [G loss: 0.752047]\n",
      "epoch:2 step:2042 [D loss: 0.691579, acc.: 53.91%] [G loss: 0.733514]\n",
      "epoch:2 step:2043 [D loss: 0.706289, acc.: 50.78%] [G loss: 0.766737]\n",
      "epoch:2 step:2044 [D loss: 0.687925, acc.: 53.91%] [G loss: 0.812164]\n",
      "epoch:2 step:2045 [D loss: 0.674981, acc.: 57.03%] [G loss: 0.782308]\n",
      "epoch:2 step:2046 [D loss: 0.654960, acc.: 67.19%] [G loss: 0.817856]\n",
      "epoch:2 step:2047 [D loss: 0.698872, acc.: 50.78%] [G loss: 0.819635]\n",
      "epoch:2 step:2048 [D loss: 0.677485, acc.: 64.06%] [G loss: 0.829309]\n",
      "epoch:2 step:2049 [D loss: 0.681451, acc.: 54.69%] [G loss: 0.846278]\n",
      "epoch:2 step:2050 [D loss: 0.637007, acc.: 64.84%] [G loss: 0.805473]\n",
      "epoch:2 step:2051 [D loss: 0.708525, acc.: 46.88%] [G loss: 0.761474]\n",
      "epoch:2 step:2052 [D loss: 0.726330, acc.: 42.19%] [G loss: 0.785946]\n",
      "epoch:2 step:2053 [D loss: 0.704176, acc.: 50.78%] [G loss: 0.745038]\n",
      "epoch:2 step:2054 [D loss: 0.711782, acc.: 53.12%] [G loss: 0.758420]\n",
      "epoch:2 step:2055 [D loss: 0.718230, acc.: 45.31%] [G loss: 0.749529]\n",
      "epoch:2 step:2056 [D loss: 0.675575, acc.: 63.28%] [G loss: 0.776040]\n",
      "epoch:2 step:2057 [D loss: 0.693195, acc.: 56.25%] [G loss: 0.776102]\n",
      "epoch:2 step:2058 [D loss: 0.701263, acc.: 50.00%] [G loss: 0.757067]\n",
      "epoch:2 step:2059 [D loss: 0.702980, acc.: 57.03%] [G loss: 0.740927]\n",
      "epoch:2 step:2060 [D loss: 0.706960, acc.: 48.44%] [G loss: 0.757278]\n",
      "epoch:2 step:2061 [D loss: 0.699596, acc.: 56.25%] [G loss: 0.760137]\n",
      "epoch:2 step:2062 [D loss: 0.696050, acc.: 52.34%] [G loss: 0.820900]\n",
      "epoch:2 step:2063 [D loss: 0.695045, acc.: 48.44%] [G loss: 0.802550]\n",
      "epoch:2 step:2064 [D loss: 0.650282, acc.: 61.72%] [G loss: 0.845315]\n",
      "epoch:2 step:2065 [D loss: 0.647731, acc.: 59.38%] [G loss: 0.863351]\n",
      "epoch:2 step:2066 [D loss: 0.704599, acc.: 55.47%] [G loss: 0.802409]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2067 [D loss: 0.720353, acc.: 45.31%] [G loss: 0.753892]\n",
      "epoch:2 step:2068 [D loss: 0.702166, acc.: 49.22%] [G loss: 0.949398]\n",
      "epoch:2 step:2069 [D loss: 0.679303, acc.: 59.38%] [G loss: 0.752329]\n",
      "epoch:2 step:2070 [D loss: 0.699551, acc.: 50.78%] [G loss: 0.786958]\n",
      "epoch:2 step:2071 [D loss: 0.700332, acc.: 54.69%] [G loss: 0.832722]\n",
      "epoch:2 step:2072 [D loss: 0.681168, acc.: 53.12%] [G loss: 0.855379]\n",
      "epoch:2 step:2073 [D loss: 0.698019, acc.: 50.78%] [G loss: 0.813598]\n",
      "epoch:2 step:2074 [D loss: 0.713363, acc.: 53.91%] [G loss: 0.796408]\n",
      "epoch:2 step:2075 [D loss: 0.720782, acc.: 49.22%] [G loss: 0.822186]\n",
      "epoch:2 step:2076 [D loss: 0.671958, acc.: 60.16%] [G loss: 0.804202]\n",
      "epoch:2 step:2077 [D loss: 0.686645, acc.: 55.47%] [G loss: 0.808441]\n",
      "epoch:2 step:2078 [D loss: 0.695870, acc.: 53.91%] [G loss: 0.808833]\n",
      "epoch:2 step:2079 [D loss: 0.676311, acc.: 59.38%] [G loss: 0.837327]\n",
      "epoch:2 step:2080 [D loss: 0.631156, acc.: 63.28%] [G loss: 0.814674]\n",
      "epoch:2 step:2081 [D loss: 0.657752, acc.: 57.81%] [G loss: 0.831579]\n",
      "epoch:2 step:2082 [D loss: 0.688003, acc.: 54.69%] [G loss: 0.773013]\n",
      "epoch:2 step:2083 [D loss: 0.672506, acc.: 55.47%] [G loss: 0.752601]\n",
      "epoch:2 step:2084 [D loss: 0.713121, acc.: 46.88%] [G loss: 0.780001]\n",
      "epoch:2 step:2085 [D loss: 0.739020, acc.: 48.44%] [G loss: 0.781186]\n",
      "epoch:2 step:2086 [D loss: 0.688555, acc.: 53.12%] [G loss: 0.755349]\n",
      "epoch:2 step:2087 [D loss: 0.690925, acc.: 48.44%] [G loss: 0.753322]\n",
      "epoch:2 step:2088 [D loss: 0.737932, acc.: 42.97%] [G loss: 0.725502]\n",
      "epoch:2 step:2089 [D loss: 0.747091, acc.: 37.50%] [G loss: 0.755765]\n",
      "epoch:2 step:2090 [D loss: 0.740009, acc.: 40.62%] [G loss: 0.749155]\n",
      "epoch:2 step:2091 [D loss: 0.694914, acc.: 53.12%] [G loss: 0.807138]\n",
      "epoch:2 step:2092 [D loss: 0.694443, acc.: 50.78%] [G loss: 0.770435]\n",
      "epoch:2 step:2093 [D loss: 0.688311, acc.: 53.91%] [G loss: 0.783859]\n",
      "epoch:2 step:2094 [D loss: 0.731251, acc.: 39.06%] [G loss: 0.767394]\n",
      "epoch:2 step:2095 [D loss: 0.658846, acc.: 60.16%] [G loss: 0.817556]\n",
      "epoch:2 step:2096 [D loss: 0.631106, acc.: 61.72%] [G loss: 0.799714]\n",
      "epoch:2 step:2097 [D loss: 0.646900, acc.: 64.06%] [G loss: 0.892113]\n",
      "epoch:2 step:2098 [D loss: 0.695553, acc.: 53.91%] [G loss: 0.870582]\n",
      "epoch:2 step:2099 [D loss: 0.685793, acc.: 50.00%] [G loss: 0.809748]\n",
      "epoch:2 step:2100 [D loss: 0.725317, acc.: 44.53%] [G loss: 0.771310]\n",
      "epoch:2 step:2101 [D loss: 0.702895, acc.: 52.34%] [G loss: 0.771462]\n",
      "epoch:2 step:2102 [D loss: 0.700400, acc.: 50.78%] [G loss: 0.736351]\n",
      "epoch:2 step:2103 [D loss: 0.699189, acc.: 53.12%] [G loss: 0.775225]\n",
      "epoch:2 step:2104 [D loss: 0.670385, acc.: 55.47%] [G loss: 0.800412]\n",
      "epoch:2 step:2105 [D loss: 0.629049, acc.: 64.06%] [G loss: 0.809155]\n",
      "epoch:2 step:2106 [D loss: 0.607547, acc.: 67.19%] [G loss: 0.897743]\n",
      "epoch:2 step:2107 [D loss: 0.706494, acc.: 52.34%] [G loss: 0.931636]\n",
      "epoch:2 step:2108 [D loss: 0.686441, acc.: 57.03%] [G loss: 0.794436]\n",
      "epoch:2 step:2109 [D loss: 0.657600, acc.: 59.38%] [G loss: 0.890114]\n",
      "epoch:2 step:2110 [D loss: 0.707819, acc.: 46.88%] [G loss: 0.828574]\n",
      "epoch:2 step:2111 [D loss: 0.696553, acc.: 55.47%] [G loss: 0.773878]\n",
      "epoch:2 step:2112 [D loss: 0.720642, acc.: 50.78%] [G loss: 0.739182]\n",
      "epoch:2 step:2113 [D loss: 0.691780, acc.: 53.12%] [G loss: 0.835577]\n",
      "epoch:2 step:2114 [D loss: 0.703140, acc.: 57.03%] [G loss: 0.723946]\n",
      "epoch:2 step:2115 [D loss: 0.698515, acc.: 52.34%] [G loss: 0.768456]\n",
      "epoch:2 step:2116 [D loss: 0.705937, acc.: 53.91%] [G loss: 0.782071]\n",
      "epoch:2 step:2117 [D loss: 0.712379, acc.: 49.22%] [G loss: 0.789422]\n",
      "epoch:2 step:2118 [D loss: 0.729100, acc.: 42.97%] [G loss: 0.763865]\n",
      "epoch:2 step:2119 [D loss: 0.713592, acc.: 50.78%] [G loss: 0.763799]\n",
      "epoch:2 step:2120 [D loss: 0.706721, acc.: 52.34%] [G loss: 0.778528]\n",
      "epoch:2 step:2121 [D loss: 0.712384, acc.: 46.88%] [G loss: 0.764077]\n",
      "epoch:2 step:2122 [D loss: 0.674593, acc.: 58.59%] [G loss: 0.790756]\n",
      "epoch:2 step:2123 [D loss: 0.704598, acc.: 45.31%] [G loss: 0.824215]\n",
      "epoch:2 step:2124 [D loss: 0.700033, acc.: 47.66%] [G loss: 0.827698]\n",
      "epoch:2 step:2125 [D loss: 0.709742, acc.: 49.22%] [G loss: 0.795837]\n",
      "epoch:2 step:2126 [D loss: 0.680546, acc.: 56.25%] [G loss: 0.789722]\n",
      "epoch:2 step:2127 [D loss: 0.685670, acc.: 55.47%] [G loss: 0.837304]\n",
      "epoch:2 step:2128 [D loss: 0.669573, acc.: 57.03%] [G loss: 0.845190]\n",
      "epoch:2 step:2129 [D loss: 0.670907, acc.: 60.94%] [G loss: 0.860289]\n",
      "epoch:2 step:2130 [D loss: 0.695927, acc.: 57.03%] [G loss: 0.787190]\n",
      "epoch:2 step:2131 [D loss: 0.690675, acc.: 54.69%] [G loss: 0.779430]\n",
      "epoch:2 step:2132 [D loss: 0.713725, acc.: 53.12%] [G loss: 0.792544]\n",
      "epoch:2 step:2133 [D loss: 0.706401, acc.: 49.22%] [G loss: 0.740526]\n",
      "epoch:2 step:2134 [D loss: 0.718384, acc.: 50.00%] [G loss: 0.745231]\n",
      "epoch:2 step:2135 [D loss: 0.706307, acc.: 53.91%] [G loss: 0.765430]\n",
      "epoch:2 step:2136 [D loss: 0.675231, acc.: 62.50%] [G loss: 0.783126]\n",
      "epoch:2 step:2137 [D loss: 0.730123, acc.: 44.53%] [G loss: 0.825987]\n",
      "epoch:2 step:2138 [D loss: 0.684770, acc.: 53.12%] [G loss: 0.863858]\n",
      "epoch:2 step:2139 [D loss: 0.662241, acc.: 57.81%] [G loss: 0.825690]\n",
      "epoch:2 step:2140 [D loss: 0.660662, acc.: 57.81%] [G loss: 0.879797]\n",
      "epoch:2 step:2141 [D loss: 0.669991, acc.: 64.06%] [G loss: 0.811559]\n",
      "epoch:2 step:2142 [D loss: 0.646655, acc.: 60.94%] [G loss: 0.810720]\n",
      "epoch:2 step:2143 [D loss: 0.672481, acc.: 52.34%] [G loss: 0.830758]\n",
      "epoch:2 step:2144 [D loss: 0.694400, acc.: 50.78%] [G loss: 0.811785]\n",
      "epoch:2 step:2145 [D loss: 0.669975, acc.: 60.94%] [G loss: 0.827021]\n",
      "epoch:2 step:2146 [D loss: 0.688057, acc.: 53.91%] [G loss: 0.826024]\n",
      "epoch:2 step:2147 [D loss: 0.698671, acc.: 50.78%] [G loss: 0.809993]\n",
      "epoch:2 step:2148 [D loss: 0.662224, acc.: 61.72%] [G loss: 0.851722]\n",
      "epoch:2 step:2149 [D loss: 0.683865, acc.: 56.25%] [G loss: 0.817849]\n",
      "epoch:2 step:2150 [D loss: 0.657982, acc.: 59.38%] [G loss: 0.831913]\n",
      "epoch:2 step:2151 [D loss: 0.725322, acc.: 50.78%] [G loss: 0.780408]\n",
      "epoch:2 step:2152 [D loss: 0.733737, acc.: 46.88%] [G loss: 0.811117]\n",
      "epoch:2 step:2153 [D loss: 0.730113, acc.: 39.84%] [G loss: 0.788452]\n",
      "epoch:2 step:2154 [D loss: 0.719642, acc.: 50.78%] [G loss: 0.799304]\n",
      "epoch:2 step:2155 [D loss: 0.727962, acc.: 44.53%] [G loss: 0.780465]\n",
      "epoch:2 step:2156 [D loss: 0.717443, acc.: 46.88%] [G loss: 0.769062]\n",
      "epoch:2 step:2157 [D loss: 0.703907, acc.: 50.00%] [G loss: 0.798498]\n",
      "epoch:2 step:2158 [D loss: 0.668836, acc.: 61.72%] [G loss: 0.754481]\n",
      "epoch:2 step:2159 [D loss: 0.666677, acc.: 60.94%] [G loss: 0.834933]\n",
      "epoch:2 step:2160 [D loss: 0.641882, acc.: 60.94%] [G loss: 0.796956]\n",
      "epoch:2 step:2161 [D loss: 0.684865, acc.: 56.25%] [G loss: 0.790007]\n",
      "epoch:2 step:2162 [D loss: 0.733327, acc.: 44.53%] [G loss: 0.827051]\n",
      "epoch:2 step:2163 [D loss: 0.666110, acc.: 56.25%] [G loss: 0.762219]\n",
      "epoch:2 step:2164 [D loss: 0.693699, acc.: 51.56%] [G loss: 0.793491]\n",
      "epoch:2 step:2165 [D loss: 0.766831, acc.: 46.09%] [G loss: 0.774602]\n",
      "epoch:2 step:2166 [D loss: 0.694281, acc.: 50.00%] [G loss: 0.794194]\n",
      "epoch:2 step:2167 [D loss: 0.716510, acc.: 51.56%] [G loss: 0.821146]\n",
      "epoch:2 step:2168 [D loss: 0.726335, acc.: 46.88%] [G loss: 0.759816]\n",
      "epoch:2 step:2169 [D loss: 0.761922, acc.: 41.41%] [G loss: 0.773711]\n",
      "epoch:2 step:2170 [D loss: 0.711121, acc.: 49.22%] [G loss: 0.746592]\n",
      "epoch:2 step:2171 [D loss: 0.701680, acc.: 50.00%] [G loss: 0.814415]\n",
      "epoch:2 step:2172 [D loss: 0.705812, acc.: 53.91%] [G loss: 0.749021]\n",
      "epoch:2 step:2173 [D loss: 0.684108, acc.: 52.34%] [G loss: 0.771672]\n",
      "epoch:2 step:2174 [D loss: 0.687872, acc.: 55.47%] [G loss: 0.823237]\n",
      "epoch:2 step:2175 [D loss: 0.690124, acc.: 53.91%] [G loss: 0.753529]\n",
      "epoch:2 step:2176 [D loss: 0.677980, acc.: 53.91%] [G loss: 0.749780]\n",
      "epoch:2 step:2177 [D loss: 0.710767, acc.: 52.34%] [G loss: 0.797280]\n",
      "epoch:2 step:2178 [D loss: 0.685900, acc.: 55.47%] [G loss: 0.798987]\n",
      "epoch:2 step:2179 [D loss: 0.692041, acc.: 56.25%] [G loss: 0.781139]\n",
      "epoch:2 step:2180 [D loss: 0.661988, acc.: 60.16%] [G loss: 0.789746]\n",
      "epoch:2 step:2181 [D loss: 0.690376, acc.: 51.56%] [G loss: 0.777716]\n",
      "epoch:2 step:2182 [D loss: 0.697024, acc.: 50.78%] [G loss: 0.773439]\n",
      "epoch:2 step:2183 [D loss: 0.683085, acc.: 51.56%] [G loss: 0.753173]\n",
      "epoch:2 step:2184 [D loss: 0.701033, acc.: 49.22%] [G loss: 0.790496]\n",
      "epoch:2 step:2185 [D loss: 0.663454, acc.: 57.03%] [G loss: 0.791099]\n",
      "epoch:2 step:2186 [D loss: 0.660515, acc.: 62.50%] [G loss: 0.827245]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2187 [D loss: 0.664760, acc.: 57.81%] [G loss: 0.857087]\n",
      "epoch:2 step:2188 [D loss: 0.650164, acc.: 64.84%] [G loss: 0.800166]\n",
      "epoch:2 step:2189 [D loss: 0.680420, acc.: 59.38%] [G loss: 0.753438]\n",
      "epoch:2 step:2190 [D loss: 0.721379, acc.: 49.22%] [G loss: 0.813652]\n",
      "epoch:2 step:2191 [D loss: 0.731042, acc.: 44.53%] [G loss: 0.784686]\n",
      "epoch:2 step:2192 [D loss: 0.701758, acc.: 53.12%] [G loss: 0.764992]\n",
      "epoch:2 step:2193 [D loss: 0.727471, acc.: 45.31%] [G loss: 0.736199]\n",
      "epoch:2 step:2194 [D loss: 0.734831, acc.: 42.19%] [G loss: 0.775683]\n",
      "epoch:2 step:2195 [D loss: 0.770179, acc.: 38.28%] [G loss: 0.749382]\n",
      "epoch:2 step:2196 [D loss: 0.690360, acc.: 57.03%] [G loss: 0.741532]\n",
      "epoch:2 step:2197 [D loss: 0.689640, acc.: 52.34%] [G loss: 0.749464]\n",
      "epoch:2 step:2198 [D loss: 0.684942, acc.: 48.44%] [G loss: 0.750242]\n",
      "epoch:2 step:2199 [D loss: 0.689866, acc.: 52.34%] [G loss: 0.779149]\n",
      "epoch:2 step:2200 [D loss: 0.711264, acc.: 44.53%] [G loss: 0.798002]\n",
      "##############\n",
      "[3.72762465 2.01556614 6.04111087 5.39670752 3.7654872  5.83605347\n",
      " 4.95750594 5.02550917 4.93268071 4.61575138]\n",
      "##########\n",
      "epoch:2 step:2201 [D loss: 0.668569, acc.: 61.72%] [G loss: 0.799793]\n",
      "epoch:2 step:2202 [D loss: 0.682746, acc.: 55.47%] [G loss: 0.780139]\n",
      "epoch:2 step:2203 [D loss: 0.679900, acc.: 51.56%] [G loss: 0.761084]\n",
      "epoch:2 step:2204 [D loss: 0.711814, acc.: 45.31%] [G loss: 0.752408]\n",
      "epoch:2 step:2205 [D loss: 0.685115, acc.: 55.47%] [G loss: 0.811948]\n",
      "epoch:2 step:2206 [D loss: 0.698614, acc.: 53.12%] [G loss: 0.760955]\n",
      "epoch:2 step:2207 [D loss: 0.724230, acc.: 47.66%] [G loss: 0.771811]\n",
      "epoch:2 step:2208 [D loss: 0.701414, acc.: 53.12%] [G loss: 0.745316]\n",
      "epoch:2 step:2209 [D loss: 0.693913, acc.: 57.81%] [G loss: 0.808998]\n",
      "epoch:2 step:2210 [D loss: 0.696575, acc.: 53.91%] [G loss: 0.755627]\n",
      "epoch:2 step:2211 [D loss: 0.686822, acc.: 57.03%] [G loss: 0.789183]\n",
      "epoch:2 step:2212 [D loss: 0.664662, acc.: 60.16%] [G loss: 0.820441]\n",
      "epoch:2 step:2213 [D loss: 0.680340, acc.: 55.47%] [G loss: 0.781045]\n",
      "epoch:2 step:2214 [D loss: 0.677676, acc.: 60.16%] [G loss: 0.797860]\n",
      "epoch:2 step:2215 [D loss: 0.692712, acc.: 56.25%] [G loss: 0.785406]\n",
      "epoch:2 step:2216 [D loss: 0.679219, acc.: 53.12%] [G loss: 0.802360]\n",
      "epoch:2 step:2217 [D loss: 0.677236, acc.: 58.59%] [G loss: 0.784846]\n",
      "epoch:2 step:2218 [D loss: 0.651566, acc.: 60.16%] [G loss: 0.866274]\n",
      "epoch:2 step:2219 [D loss: 0.714051, acc.: 51.56%] [G loss: 0.766579]\n",
      "epoch:2 step:2220 [D loss: 0.683568, acc.: 53.12%] [G loss: 0.802433]\n",
      "epoch:2 step:2221 [D loss: 0.651133, acc.: 65.62%] [G loss: 0.831515]\n",
      "epoch:2 step:2222 [D loss: 0.703416, acc.: 49.22%] [G loss: 0.866454]\n",
      "epoch:2 step:2223 [D loss: 0.697134, acc.: 50.78%] [G loss: 0.817526]\n",
      "epoch:2 step:2224 [D loss: 0.707243, acc.: 47.66%] [G loss: 0.748521]\n",
      "epoch:2 step:2225 [D loss: 0.709937, acc.: 53.12%] [G loss: 0.780695]\n",
      "epoch:2 step:2226 [D loss: 0.714357, acc.: 49.22%] [G loss: 0.811384]\n",
      "epoch:2 step:2227 [D loss: 0.709497, acc.: 52.34%] [G loss: 0.704168]\n",
      "epoch:2 step:2228 [D loss: 0.697491, acc.: 53.12%] [G loss: 0.784085]\n",
      "epoch:2 step:2229 [D loss: 0.736426, acc.: 39.84%] [G loss: 0.757022]\n",
      "epoch:2 step:2230 [D loss: 0.692140, acc.: 55.47%] [G loss: 0.779656]\n",
      "epoch:2 step:2231 [D loss: 0.724711, acc.: 42.19%] [G loss: 0.749825]\n",
      "epoch:2 step:2232 [D loss: 0.682387, acc.: 55.47%] [G loss: 0.764236]\n",
      "epoch:2 step:2233 [D loss: 0.683369, acc.: 54.69%] [G loss: 0.754310]\n",
      "epoch:2 step:2234 [D loss: 0.670166, acc.: 57.03%] [G loss: 0.806101]\n",
      "epoch:2 step:2235 [D loss: 0.710136, acc.: 46.09%] [G loss: 0.745229]\n",
      "epoch:2 step:2236 [D loss: 0.710364, acc.: 48.44%] [G loss: 0.781047]\n",
      "epoch:2 step:2237 [D loss: 0.710559, acc.: 46.88%] [G loss: 0.781771]\n",
      "epoch:2 step:2238 [D loss: 0.674009, acc.: 51.56%] [G loss: 0.769936]\n",
      "epoch:2 step:2239 [D loss: 0.705963, acc.: 47.66%] [G loss: 0.784755]\n",
      "epoch:2 step:2240 [D loss: 0.696921, acc.: 50.00%] [G loss: 0.805381]\n",
      "epoch:2 step:2241 [D loss: 0.676681, acc.: 57.03%] [G loss: 0.804654]\n",
      "epoch:2 step:2242 [D loss: 0.692344, acc.: 51.56%] [G loss: 0.853538]\n",
      "epoch:2 step:2243 [D loss: 0.686798, acc.: 55.47%] [G loss: 0.787478]\n",
      "epoch:2 step:2244 [D loss: 0.676580, acc.: 59.38%] [G loss: 0.823977]\n",
      "epoch:2 step:2245 [D loss: 0.652875, acc.: 62.50%] [G loss: 0.806308]\n",
      "epoch:2 step:2246 [D loss: 0.676816, acc.: 53.12%] [G loss: 0.769490]\n",
      "epoch:2 step:2247 [D loss: 0.695473, acc.: 51.56%] [G loss: 0.776136]\n",
      "epoch:2 step:2248 [D loss: 0.690998, acc.: 53.12%] [G loss: 0.818444]\n",
      "epoch:2 step:2249 [D loss: 0.683258, acc.: 54.69%] [G loss: 0.788550]\n",
      "epoch:2 step:2250 [D loss: 0.721826, acc.: 44.53%] [G loss: 0.776171]\n",
      "epoch:2 step:2251 [D loss: 0.725711, acc.: 42.19%] [G loss: 0.737671]\n",
      "epoch:2 step:2252 [D loss: 0.693221, acc.: 51.56%] [G loss: 0.744178]\n",
      "epoch:2 step:2253 [D loss: 0.672230, acc.: 57.81%] [G loss: 0.718835]\n",
      "epoch:2 step:2254 [D loss: 0.702806, acc.: 53.12%] [G loss: 0.769536]\n",
      "epoch:2 step:2255 [D loss: 0.699790, acc.: 50.78%] [G loss: 0.782764]\n",
      "epoch:2 step:2256 [D loss: 0.713607, acc.: 51.56%] [G loss: 0.756603]\n",
      "epoch:2 step:2257 [D loss: 0.695524, acc.: 52.34%] [G loss: 0.811109]\n",
      "epoch:2 step:2258 [D loss: 0.708815, acc.: 49.22%] [G loss: 0.810537]\n",
      "epoch:2 step:2259 [D loss: 0.699430, acc.: 45.31%] [G loss: 0.728727]\n",
      "epoch:2 step:2260 [D loss: 0.714756, acc.: 47.66%] [G loss: 0.787945]\n",
      "epoch:2 step:2261 [D loss: 0.694322, acc.: 52.34%] [G loss: 0.800115]\n",
      "epoch:2 step:2262 [D loss: 0.676335, acc.: 55.47%] [G loss: 0.786462]\n",
      "epoch:2 step:2263 [D loss: 0.693216, acc.: 51.56%] [G loss: 0.761169]\n",
      "epoch:2 step:2264 [D loss: 0.752098, acc.: 37.50%] [G loss: 0.763559]\n",
      "epoch:2 step:2265 [D loss: 0.730523, acc.: 46.09%] [G loss: 0.744707]\n",
      "epoch:2 step:2266 [D loss: 0.725150, acc.: 39.84%] [G loss: 0.742747]\n",
      "epoch:2 step:2267 [D loss: 0.690522, acc.: 49.22%] [G loss: 0.772305]\n",
      "epoch:2 step:2268 [D loss: 0.706129, acc.: 46.88%] [G loss: 0.725851]\n",
      "epoch:2 step:2269 [D loss: 0.696817, acc.: 45.31%] [G loss: 0.738345]\n",
      "epoch:2 step:2270 [D loss: 0.695191, acc.: 50.78%] [G loss: 0.772419]\n",
      "epoch:2 step:2271 [D loss: 0.687108, acc.: 53.91%] [G loss: 0.777988]\n",
      "epoch:2 step:2272 [D loss: 0.655762, acc.: 63.28%] [G loss: 0.793926]\n",
      "epoch:2 step:2273 [D loss: 0.657381, acc.: 60.94%] [G loss: 0.801366]\n",
      "epoch:2 step:2274 [D loss: 0.698238, acc.: 56.25%] [G loss: 0.797632]\n",
      "epoch:2 step:2275 [D loss: 0.698077, acc.: 51.56%] [G loss: 0.782504]\n",
      "epoch:2 step:2276 [D loss: 0.674587, acc.: 58.59%] [G loss: 0.810715]\n",
      "epoch:2 step:2277 [D loss: 0.685173, acc.: 57.03%] [G loss: 0.772215]\n",
      "epoch:2 step:2278 [D loss: 0.687725, acc.: 53.12%] [G loss: 0.818755]\n",
      "epoch:2 step:2279 [D loss: 0.678842, acc.: 60.16%] [G loss: 0.733943]\n",
      "epoch:2 step:2280 [D loss: 0.668859, acc.: 55.47%] [G loss: 0.809560]\n",
      "epoch:2 step:2281 [D loss: 0.693613, acc.: 53.91%] [G loss: 0.758206]\n",
      "epoch:2 step:2282 [D loss: 0.689415, acc.: 54.69%] [G loss: 0.810123]\n",
      "epoch:2 step:2283 [D loss: 0.688895, acc.: 50.78%] [G loss: 0.735240]\n",
      "epoch:2 step:2284 [D loss: 0.719326, acc.: 51.56%] [G loss: 0.724503]\n",
      "epoch:2 step:2285 [D loss: 0.742218, acc.: 38.28%] [G loss: 0.734620]\n",
      "epoch:2 step:2286 [D loss: 0.695199, acc.: 50.00%] [G loss: 0.742896]\n",
      "epoch:2 step:2287 [D loss: 0.694046, acc.: 54.69%] [G loss: 0.739078]\n",
      "epoch:2 step:2288 [D loss: 0.697776, acc.: 51.56%] [G loss: 0.780538]\n",
      "epoch:2 step:2289 [D loss: 0.674629, acc.: 64.06%] [G loss: 0.776708]\n",
      "epoch:2 step:2290 [D loss: 0.708575, acc.: 46.88%] [G loss: 0.769399]\n",
      "epoch:2 step:2291 [D loss: 0.707407, acc.: 49.22%] [G loss: 0.813226]\n",
      "epoch:2 step:2292 [D loss: 0.688488, acc.: 50.78%] [G loss: 0.821510]\n",
      "epoch:2 step:2293 [D loss: 0.682635, acc.: 53.12%] [G loss: 0.784773]\n",
      "epoch:2 step:2294 [D loss: 0.680702, acc.: 56.25%] [G loss: 0.800669]\n",
      "epoch:2 step:2295 [D loss: 0.704262, acc.: 47.66%] [G loss: 0.825525]\n",
      "epoch:2 step:2296 [D loss: 0.678868, acc.: 58.59%] [G loss: 0.854699]\n",
      "epoch:2 step:2297 [D loss: 0.693633, acc.: 53.12%] [G loss: 0.889729]\n",
      "epoch:2 step:2298 [D loss: 0.685391, acc.: 53.12%] [G loss: 0.842279]\n",
      "epoch:2 step:2299 [D loss: 0.663825, acc.: 60.16%] [G loss: 0.805694]\n",
      "epoch:2 step:2300 [D loss: 0.667415, acc.: 55.47%] [G loss: 0.839996]\n",
      "epoch:2 step:2301 [D loss: 0.677998, acc.: 60.16%] [G loss: 0.770539]\n",
      "epoch:2 step:2302 [D loss: 0.659975, acc.: 62.50%] [G loss: 0.768366]\n",
      "epoch:2 step:2303 [D loss: 0.703001, acc.: 52.34%] [G loss: 0.806176]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2304 [D loss: 0.702573, acc.: 54.69%] [G loss: 0.776240]\n",
      "epoch:2 step:2305 [D loss: 0.722675, acc.: 46.09%] [G loss: 0.765995]\n",
      "epoch:2 step:2306 [D loss: 0.747920, acc.: 40.62%] [G loss: 0.782292]\n",
      "epoch:2 step:2307 [D loss: 0.735497, acc.: 40.62%] [G loss: 0.753172]\n",
      "epoch:2 step:2308 [D loss: 0.686937, acc.: 56.25%] [G loss: 0.740180]\n",
      "epoch:2 step:2309 [D loss: 0.718997, acc.: 45.31%] [G loss: 0.737122]\n",
      "epoch:2 step:2310 [D loss: 0.686599, acc.: 54.69%] [G loss: 0.761432]\n",
      "epoch:2 step:2311 [D loss: 0.718559, acc.: 50.78%] [G loss: 0.762371]\n",
      "epoch:2 step:2312 [D loss: 0.700943, acc.: 44.53%] [G loss: 0.769762]\n",
      "epoch:2 step:2313 [D loss: 0.684282, acc.: 55.47%] [G loss: 0.772378]\n",
      "epoch:2 step:2314 [D loss: 0.673878, acc.: 60.16%] [G loss: 0.798205]\n",
      "epoch:2 step:2315 [D loss: 0.714255, acc.: 46.88%] [G loss: 0.756792]\n",
      "epoch:2 step:2316 [D loss: 0.689962, acc.: 52.34%] [G loss: 0.751551]\n",
      "epoch:2 step:2317 [D loss: 0.704962, acc.: 47.66%] [G loss: 0.763004]\n",
      "epoch:2 step:2318 [D loss: 0.688710, acc.: 53.12%] [G loss: 0.735553]\n",
      "epoch:2 step:2319 [D loss: 0.715232, acc.: 52.34%] [G loss: 0.751272]\n",
      "epoch:2 step:2320 [D loss: 0.707139, acc.: 51.56%] [G loss: 0.779988]\n",
      "epoch:2 step:2321 [D loss: 0.699546, acc.: 53.12%] [G loss: 0.724221]\n",
      "epoch:2 step:2322 [D loss: 0.705572, acc.: 49.22%] [G loss: 0.758545]\n",
      "epoch:2 step:2323 [D loss: 0.700399, acc.: 50.00%] [G loss: 0.747499]\n",
      "epoch:2 step:2324 [D loss: 0.683936, acc.: 53.12%] [G loss: 0.767016]\n",
      "epoch:2 step:2325 [D loss: 0.685444, acc.: 57.03%] [G loss: 0.762701]\n",
      "epoch:2 step:2326 [D loss: 0.685516, acc.: 53.91%] [G loss: 0.760388]\n",
      "epoch:2 step:2327 [D loss: 0.699386, acc.: 46.88%] [G loss: 0.753302]\n",
      "epoch:2 step:2328 [D loss: 0.693639, acc.: 56.25%] [G loss: 0.756581]\n",
      "epoch:2 step:2329 [D loss: 0.668670, acc.: 59.38%] [G loss: 0.827297]\n",
      "epoch:2 step:2330 [D loss: 0.673217, acc.: 58.59%] [G loss: 0.769802]\n",
      "epoch:2 step:2331 [D loss: 0.675195, acc.: 63.28%] [G loss: 0.781801]\n",
      "epoch:2 step:2332 [D loss: 0.693469, acc.: 56.25%] [G loss: 0.728417]\n",
      "epoch:2 step:2333 [D loss: 0.696117, acc.: 51.56%] [G loss: 0.747621]\n",
      "epoch:2 step:2334 [D loss: 0.673349, acc.: 52.34%] [G loss: 0.749905]\n",
      "epoch:2 step:2335 [D loss: 0.710693, acc.: 50.78%] [G loss: 0.770166]\n",
      "epoch:2 step:2336 [D loss: 0.704903, acc.: 50.78%] [G loss: 0.761300]\n",
      "epoch:2 step:2337 [D loss: 0.686352, acc.: 53.12%] [G loss: 0.769367]\n",
      "epoch:2 step:2338 [D loss: 0.701660, acc.: 49.22%] [G loss: 0.764100]\n",
      "epoch:2 step:2339 [D loss: 0.683784, acc.: 60.94%] [G loss: 0.741960]\n",
      "epoch:2 step:2340 [D loss: 0.670953, acc.: 64.06%] [G loss: 0.774557]\n",
      "epoch:2 step:2341 [D loss: 0.697574, acc.: 60.16%] [G loss: 0.787809]\n",
      "epoch:2 step:2342 [D loss: 0.675178, acc.: 62.50%] [G loss: 0.770913]\n",
      "epoch:2 step:2343 [D loss: 0.707661, acc.: 51.56%] [G loss: 0.772275]\n",
      "epoch:2 step:2344 [D loss: 0.689982, acc.: 57.81%] [G loss: 0.768117]\n",
      "epoch:2 step:2345 [D loss: 0.702072, acc.: 50.00%] [G loss: 0.740119]\n",
      "epoch:2 step:2346 [D loss: 0.680489, acc.: 52.34%] [G loss: 0.762938]\n",
      "epoch:2 step:2347 [D loss: 0.729310, acc.: 51.56%] [G loss: 0.740569]\n",
      "epoch:2 step:2348 [D loss: 0.688726, acc.: 51.56%] [G loss: 0.787738]\n",
      "epoch:2 step:2349 [D loss: 0.685034, acc.: 53.12%] [G loss: 0.764899]\n",
      "epoch:2 step:2350 [D loss: 0.671503, acc.: 59.38%] [G loss: 0.812228]\n",
      "epoch:2 step:2351 [D loss: 0.677053, acc.: 55.47%] [G loss: 0.797539]\n",
      "epoch:2 step:2352 [D loss: 0.668400, acc.: 61.72%] [G loss: 0.793034]\n",
      "epoch:2 step:2353 [D loss: 0.707052, acc.: 50.00%] [G loss: 0.782336]\n",
      "epoch:2 step:2354 [D loss: 0.721330, acc.: 43.75%] [G loss: 0.739204]\n",
      "epoch:2 step:2355 [D loss: 0.654100, acc.: 60.94%] [G loss: 0.773350]\n",
      "epoch:2 step:2356 [D loss: 0.721765, acc.: 50.78%] [G loss: 0.742183]\n",
      "epoch:2 step:2357 [D loss: 0.699094, acc.: 51.56%] [G loss: 0.753995]\n",
      "epoch:2 step:2358 [D loss: 0.698901, acc.: 58.59%] [G loss: 0.745803]\n",
      "epoch:2 step:2359 [D loss: 0.689933, acc.: 50.00%] [G loss: 0.791128]\n",
      "epoch:2 step:2360 [D loss: 0.716126, acc.: 43.75%] [G loss: 0.740820]\n",
      "epoch:2 step:2361 [D loss: 0.724426, acc.: 44.53%] [G loss: 0.712848]\n",
      "epoch:2 step:2362 [D loss: 0.675535, acc.: 57.03%] [G loss: 0.756955]\n",
      "epoch:2 step:2363 [D loss: 0.691728, acc.: 55.47%] [G loss: 0.747245]\n",
      "epoch:2 step:2364 [D loss: 0.691783, acc.: 55.47%] [G loss: 0.766291]\n",
      "epoch:2 step:2365 [D loss: 0.679363, acc.: 57.03%] [G loss: 0.769460]\n",
      "epoch:2 step:2366 [D loss: 0.691800, acc.: 50.78%] [G loss: 0.753123]\n",
      "epoch:2 step:2367 [D loss: 0.690882, acc.: 57.81%] [G loss: 0.771970]\n",
      "epoch:2 step:2368 [D loss: 0.662741, acc.: 57.03%] [G loss: 0.787372]\n",
      "epoch:2 step:2369 [D loss: 0.687446, acc.: 55.47%] [G loss: 0.737309]\n",
      "epoch:2 step:2370 [D loss: 0.675876, acc.: 56.25%] [G loss: 0.787589]\n",
      "epoch:2 step:2371 [D loss: 0.672819, acc.: 59.38%] [G loss: 0.767071]\n",
      "epoch:2 step:2372 [D loss: 0.677660, acc.: 54.69%] [G loss: 0.802534]\n",
      "epoch:2 step:2373 [D loss: 0.689085, acc.: 56.25%] [G loss: 0.748635]\n",
      "epoch:2 step:2374 [D loss: 0.731393, acc.: 45.31%] [G loss: 0.752941]\n",
      "epoch:2 step:2375 [D loss: 0.728066, acc.: 43.75%] [G loss: 0.730919]\n",
      "epoch:2 step:2376 [D loss: 0.727130, acc.: 50.78%] [G loss: 0.776241]\n",
      "epoch:2 step:2377 [D loss: 0.686359, acc.: 51.56%] [G loss: 0.777857]\n",
      "epoch:2 step:2378 [D loss: 0.685810, acc.: 50.78%] [G loss: 0.755128]\n",
      "epoch:2 step:2379 [D loss: 0.657663, acc.: 64.06%] [G loss: 0.798602]\n",
      "epoch:2 step:2380 [D loss: 0.678703, acc.: 56.25%] [G loss: 0.777923]\n",
      "epoch:2 step:2381 [D loss: 0.645780, acc.: 65.62%] [G loss: 0.818425]\n",
      "epoch:2 step:2382 [D loss: 0.638725, acc.: 67.19%] [G loss: 0.748627]\n",
      "epoch:2 step:2383 [D loss: 0.683151, acc.: 50.00%] [G loss: 0.768739]\n",
      "epoch:2 step:2384 [D loss: 0.724611, acc.: 50.00%] [G loss: 0.783940]\n",
      "epoch:2 step:2385 [D loss: 0.743344, acc.: 39.84%] [G loss: 0.732380]\n",
      "epoch:2 step:2386 [D loss: 0.752761, acc.: 33.59%] [G loss: 0.765174]\n",
      "epoch:2 step:2387 [D loss: 0.658499, acc.: 60.94%] [G loss: 0.771527]\n",
      "epoch:2 step:2388 [D loss: 0.716236, acc.: 42.19%] [G loss: 0.741293]\n",
      "epoch:2 step:2389 [D loss: 0.682117, acc.: 60.16%] [G loss: 0.820308]\n",
      "epoch:2 step:2390 [D loss: 0.666510, acc.: 60.16%] [G loss: 0.752659]\n",
      "epoch:2 step:2391 [D loss: 0.679472, acc.: 59.38%] [G loss: 0.759109]\n",
      "epoch:2 step:2392 [D loss: 0.691968, acc.: 51.56%] [G loss: 0.767023]\n",
      "epoch:2 step:2393 [D loss: 0.662809, acc.: 57.81%] [G loss: 0.783918]\n",
      "epoch:2 step:2394 [D loss: 0.663522, acc.: 60.16%] [G loss: 0.811498]\n",
      "epoch:2 step:2395 [D loss: 0.681163, acc.: 58.59%] [G loss: 0.818914]\n",
      "epoch:2 step:2396 [D loss: 0.657056, acc.: 64.84%] [G loss: 0.835995]\n",
      "epoch:2 step:2397 [D loss: 0.678363, acc.: 57.81%] [G loss: 0.836800]\n",
      "epoch:2 step:2398 [D loss: 0.698343, acc.: 51.56%] [G loss: 0.723236]\n",
      "epoch:2 step:2399 [D loss: 0.705774, acc.: 46.88%] [G loss: 0.761610]\n",
      "epoch:2 step:2400 [D loss: 0.696962, acc.: 53.91%] [G loss: 0.772031]\n",
      "##############\n",
      "[3.5185758  2.31871009 5.98881324 5.33890325 4.25191487 5.87903598\n",
      " 5.26506944 5.24417508 5.38499751 4.65956445]\n",
      "##########\n",
      "epoch:2 step:2401 [D loss: 0.729940, acc.: 51.56%] [G loss: 0.764436]\n",
      "epoch:2 step:2402 [D loss: 0.781988, acc.: 32.03%] [G loss: 0.685693]\n",
      "epoch:2 step:2403 [D loss: 0.756507, acc.: 35.16%] [G loss: 0.746278]\n",
      "epoch:2 step:2404 [D loss: 0.715643, acc.: 46.88%] [G loss: 0.740921]\n",
      "epoch:2 step:2405 [D loss: 0.674088, acc.: 58.59%] [G loss: 0.804929]\n",
      "epoch:2 step:2406 [D loss: 0.685396, acc.: 57.03%] [G loss: 0.755845]\n",
      "epoch:2 step:2407 [D loss: 0.702911, acc.: 50.00%] [G loss: 0.781497]\n",
      "epoch:2 step:2408 [D loss: 0.692015, acc.: 56.25%] [G loss: 0.830320]\n",
      "epoch:2 step:2409 [D loss: 0.711748, acc.: 51.56%] [G loss: 0.761379]\n",
      "epoch:2 step:2410 [D loss: 0.672617, acc.: 60.94%] [G loss: 0.737068]\n",
      "epoch:2 step:2411 [D loss: 0.675624, acc.: 56.25%] [G loss: 0.767143]\n",
      "epoch:2 step:2412 [D loss: 0.686376, acc.: 59.38%] [G loss: 0.752394]\n",
      "epoch:2 step:2413 [D loss: 0.700884, acc.: 49.22%] [G loss: 0.770952]\n",
      "epoch:2 step:2414 [D loss: 0.691499, acc.: 57.03%] [G loss: 0.780488]\n",
      "epoch:2 step:2415 [D loss: 0.676981, acc.: 60.94%] [G loss: 0.768000]\n",
      "epoch:2 step:2416 [D loss: 0.744874, acc.: 36.72%] [G loss: 0.761011]\n",
      "epoch:2 step:2417 [D loss: 0.725946, acc.: 42.97%] [G loss: 0.779673]\n",
      "epoch:2 step:2418 [D loss: 0.689120, acc.: 48.44%] [G loss: 0.739061]\n",
      "epoch:2 step:2419 [D loss: 0.698006, acc.: 51.56%] [G loss: 0.770719]\n",
      "epoch:2 step:2420 [D loss: 0.674164, acc.: 58.59%] [G loss: 0.752445]\n",
      "epoch:2 step:2421 [D loss: 0.663157, acc.: 63.28%] [G loss: 0.746299]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2422 [D loss: 0.661320, acc.: 61.72%] [G loss: 0.732288]\n",
      "epoch:2 step:2423 [D loss: 0.701990, acc.: 53.91%] [G loss: 0.801006]\n",
      "epoch:2 step:2424 [D loss: 0.697069, acc.: 49.22%] [G loss: 0.751278]\n",
      "epoch:2 step:2425 [D loss: 0.701168, acc.: 53.91%] [G loss: 0.745773]\n",
      "epoch:2 step:2426 [D loss: 0.669847, acc.: 56.25%] [G loss: 0.746924]\n",
      "epoch:2 step:2427 [D loss: 0.706120, acc.: 50.78%] [G loss: 0.733493]\n",
      "epoch:2 step:2428 [D loss: 0.661891, acc.: 58.59%] [G loss: 0.814629]\n",
      "epoch:2 step:2429 [D loss: 0.691272, acc.: 57.81%] [G loss: 0.763267]\n",
      "epoch:2 step:2430 [D loss: 0.677507, acc.: 58.59%] [G loss: 0.774922]\n",
      "epoch:2 step:2431 [D loss: 0.665449, acc.: 59.38%] [G loss: 0.818651]\n",
      "epoch:2 step:2432 [D loss: 0.663991, acc.: 60.94%] [G loss: 0.756201]\n",
      "epoch:2 step:2433 [D loss: 0.718586, acc.: 52.34%] [G loss: 0.813286]\n",
      "epoch:2 step:2434 [D loss: 0.725930, acc.: 47.66%] [G loss: 0.776547]\n",
      "epoch:2 step:2435 [D loss: 0.686421, acc.: 50.78%] [G loss: 0.798788]\n",
      "epoch:2 step:2436 [D loss: 0.685802, acc.: 58.59%] [G loss: 0.780507]\n",
      "epoch:2 step:2437 [D loss: 0.683847, acc.: 52.34%] [G loss: 0.758440]\n",
      "epoch:2 step:2438 [D loss: 0.675166, acc.: 53.91%] [G loss: 0.781437]\n",
      "epoch:2 step:2439 [D loss: 0.689701, acc.: 49.22%] [G loss: 0.789094]\n",
      "epoch:2 step:2440 [D loss: 0.687836, acc.: 51.56%] [G loss: 0.782739]\n",
      "epoch:2 step:2441 [D loss: 0.663465, acc.: 57.03%] [G loss: 0.861559]\n",
      "epoch:2 step:2442 [D loss: 0.651291, acc.: 64.84%] [G loss: 0.886354]\n",
      "epoch:2 step:2443 [D loss: 0.719981, acc.: 47.66%] [G loss: 0.786765]\n",
      "epoch:2 step:2444 [D loss: 0.699461, acc.: 53.12%] [G loss: 0.824482]\n",
      "epoch:2 step:2445 [D loss: 0.726849, acc.: 41.41%] [G loss: 0.768506]\n",
      "epoch:2 step:2446 [D loss: 0.717487, acc.: 52.34%] [G loss: 0.768394]\n",
      "epoch:2 step:2447 [D loss: 0.698777, acc.: 57.81%] [G loss: 0.787656]\n",
      "epoch:2 step:2448 [D loss: 0.642868, acc.: 63.28%] [G loss: 0.842700]\n",
      "epoch:2 step:2449 [D loss: 0.668360, acc.: 62.50%] [G loss: 0.776093]\n",
      "epoch:2 step:2450 [D loss: 0.702997, acc.: 50.78%] [G loss: 0.760983]\n",
      "epoch:2 step:2451 [D loss: 0.703433, acc.: 55.47%] [G loss: 0.741861]\n",
      "epoch:2 step:2452 [D loss: 0.719818, acc.: 44.53%] [G loss: 0.747253]\n",
      "epoch:2 step:2453 [D loss: 0.707885, acc.: 50.78%] [G loss: 0.720299]\n",
      "epoch:2 step:2454 [D loss: 0.696642, acc.: 51.56%] [G loss: 0.799648]\n",
      "epoch:2 step:2455 [D loss: 0.671921, acc.: 51.56%] [G loss: 0.763730]\n",
      "epoch:2 step:2456 [D loss: 0.674782, acc.: 55.47%] [G loss: 0.761092]\n",
      "epoch:2 step:2457 [D loss: 0.697929, acc.: 49.22%] [G loss: 0.745324]\n",
      "epoch:2 step:2458 [D loss: 0.737277, acc.: 42.97%] [G loss: 0.763711]\n",
      "epoch:2 step:2459 [D loss: 0.690151, acc.: 53.91%] [G loss: 0.800238]\n",
      "epoch:2 step:2460 [D loss: 0.688150, acc.: 57.03%] [G loss: 0.832880]\n",
      "epoch:2 step:2461 [D loss: 0.689860, acc.: 51.56%] [G loss: 0.841276]\n",
      "epoch:2 step:2462 [D loss: 0.662745, acc.: 53.12%] [G loss: 0.827105]\n",
      "epoch:2 step:2463 [D loss: 0.665934, acc.: 64.84%] [G loss: 0.823735]\n",
      "epoch:2 step:2464 [D loss: 0.687442, acc.: 53.91%] [G loss: 0.834716]\n",
      "epoch:2 step:2465 [D loss: 0.658560, acc.: 67.19%] [G loss: 0.819851]\n",
      "epoch:2 step:2466 [D loss: 0.663043, acc.: 62.50%] [G loss: 0.779140]\n",
      "epoch:2 step:2467 [D loss: 0.664641, acc.: 63.28%] [G loss: 0.825474]\n",
      "epoch:2 step:2468 [D loss: 0.737188, acc.: 43.75%] [G loss: 0.757332]\n",
      "epoch:2 step:2469 [D loss: 0.648696, acc.: 64.06%] [G loss: 0.828957]\n",
      "epoch:2 step:2470 [D loss: 0.700859, acc.: 54.69%] [G loss: 0.782373]\n",
      "epoch:2 step:2471 [D loss: 0.725240, acc.: 42.97%] [G loss: 0.747354]\n",
      "epoch:2 step:2472 [D loss: 0.697943, acc.: 53.12%] [G loss: 0.713219]\n",
      "epoch:2 step:2473 [D loss: 0.709234, acc.: 45.31%] [G loss: 0.750898]\n",
      "epoch:2 step:2474 [D loss: 0.696196, acc.: 52.34%] [G loss: 0.797991]\n",
      "epoch:2 step:2475 [D loss: 0.702586, acc.: 47.66%] [G loss: 0.757340]\n",
      "epoch:2 step:2476 [D loss: 0.672450, acc.: 60.94%] [G loss: 0.784598]\n",
      "epoch:2 step:2477 [D loss: 0.690998, acc.: 51.56%] [G loss: 0.888714]\n",
      "epoch:2 step:2478 [D loss: 0.726634, acc.: 43.75%] [G loss: 0.854508]\n",
      "epoch:2 step:2479 [D loss: 0.679185, acc.: 53.91%] [G loss: 0.868681]\n",
      "epoch:2 step:2480 [D loss: 0.662258, acc.: 60.16%] [G loss: 0.909594]\n",
      "epoch:2 step:2481 [D loss: 0.684705, acc.: 52.34%] [G loss: 0.821492]\n",
      "epoch:2 step:2482 [D loss: 0.695424, acc.: 50.00%] [G loss: 0.792487]\n",
      "epoch:2 step:2483 [D loss: 0.716958, acc.: 55.47%] [G loss: 0.803690]\n",
      "epoch:2 step:2484 [D loss: 0.727174, acc.: 44.53%] [G loss: 0.790732]\n",
      "epoch:2 step:2485 [D loss: 0.705480, acc.: 46.88%] [G loss: 0.729870]\n",
      "epoch:2 step:2486 [D loss: 0.719379, acc.: 43.75%] [G loss: 0.741956]\n",
      "epoch:2 step:2487 [D loss: 0.685684, acc.: 53.91%] [G loss: 0.729085]\n",
      "epoch:2 step:2488 [D loss: 0.711532, acc.: 42.19%] [G loss: 0.719719]\n",
      "epoch:2 step:2489 [D loss: 0.739086, acc.: 41.41%] [G loss: 0.727267]\n",
      "epoch:2 step:2490 [D loss: 0.721982, acc.: 40.62%] [G loss: 0.701822]\n",
      "epoch:2 step:2491 [D loss: 0.700783, acc.: 48.44%] [G loss: 0.764982]\n",
      "epoch:2 step:2492 [D loss: 0.719757, acc.: 46.88%] [G loss: 0.724159]\n",
      "epoch:2 step:2493 [D loss: 0.703723, acc.: 46.09%] [G loss: 0.749856]\n",
      "epoch:2 step:2494 [D loss: 0.671934, acc.: 62.50%] [G loss: 0.752388]\n",
      "epoch:2 step:2495 [D loss: 0.698599, acc.: 50.78%] [G loss: 0.799789]\n",
      "epoch:2 step:2496 [D loss: 0.713811, acc.: 46.88%] [G loss: 0.804809]\n",
      "epoch:2 step:2497 [D loss: 0.685370, acc.: 56.25%] [G loss: 0.771646]\n",
      "epoch:2 step:2498 [D loss: 0.655420, acc.: 53.91%] [G loss: 0.788747]\n",
      "epoch:2 step:2499 [D loss: 0.680668, acc.: 54.69%] [G loss: 0.795616]\n",
      "epoch:2 step:2500 [D loss: 0.688707, acc.: 52.34%] [G loss: 0.800260]\n",
      "epoch:2 step:2501 [D loss: 0.670917, acc.: 55.47%] [G loss: 0.821360]\n",
      "epoch:2 step:2502 [D loss: 0.694572, acc.: 52.34%] [G loss: 0.785079]\n",
      "epoch:2 step:2503 [D loss: 0.689552, acc.: 50.78%] [G loss: 0.780016]\n",
      "epoch:2 step:2504 [D loss: 0.667507, acc.: 56.25%] [G loss: 0.782852]\n",
      "epoch:2 step:2505 [D loss: 0.697527, acc.: 47.66%] [G loss: 0.769125]\n",
      "epoch:2 step:2506 [D loss: 0.702936, acc.: 50.78%] [G loss: 0.761972]\n",
      "epoch:2 step:2507 [D loss: 0.726330, acc.: 44.53%] [G loss: 0.780323]\n",
      "epoch:2 step:2508 [D loss: 0.697276, acc.: 51.56%] [G loss: 0.707316]\n",
      "epoch:2 step:2509 [D loss: 0.702334, acc.: 50.78%] [G loss: 0.703126]\n",
      "epoch:2 step:2510 [D loss: 0.690709, acc.: 52.34%] [G loss: 0.721838]\n",
      "epoch:2 step:2511 [D loss: 0.682864, acc.: 57.03%] [G loss: 0.754832]\n",
      "epoch:2 step:2512 [D loss: 0.693267, acc.: 46.88%] [G loss: 0.753095]\n",
      "epoch:2 step:2513 [D loss: 0.709814, acc.: 45.31%] [G loss: 0.748324]\n",
      "epoch:2 step:2514 [D loss: 0.701383, acc.: 49.22%] [G loss: 0.754296]\n",
      "epoch:2 step:2515 [D loss: 0.692099, acc.: 47.66%] [G loss: 0.754763]\n",
      "epoch:2 step:2516 [D loss: 0.679606, acc.: 53.12%] [G loss: 0.778898]\n",
      "epoch:2 step:2517 [D loss: 0.681272, acc.: 57.81%] [G loss: 0.794727]\n",
      "epoch:2 step:2518 [D loss: 0.678648, acc.: 55.47%] [G loss: 0.768360]\n",
      "epoch:2 step:2519 [D loss: 0.674122, acc.: 62.50%] [G loss: 0.724593]\n",
      "epoch:2 step:2520 [D loss: 0.678289, acc.: 58.59%] [G loss: 0.790434]\n",
      "epoch:2 step:2521 [D loss: 0.713424, acc.: 51.56%] [G loss: 0.757641]\n",
      "epoch:2 step:2522 [D loss: 0.670211, acc.: 60.16%] [G loss: 0.738056]\n",
      "epoch:2 step:2523 [D loss: 0.696328, acc.: 57.03%] [G loss: 0.751264]\n",
      "epoch:2 step:2524 [D loss: 0.670736, acc.: 57.03%] [G loss: 0.758638]\n",
      "epoch:2 step:2525 [D loss: 0.680649, acc.: 53.12%] [G loss: 0.749247]\n",
      "epoch:2 step:2526 [D loss: 0.705663, acc.: 46.88%] [G loss: 0.738549]\n",
      "epoch:2 step:2527 [D loss: 0.751237, acc.: 39.84%] [G loss: 0.770022]\n",
      "epoch:2 step:2528 [D loss: 0.691221, acc.: 53.12%] [G loss: 0.737029]\n",
      "epoch:2 step:2529 [D loss: 0.668998, acc.: 64.84%] [G loss: 0.716650]\n",
      "epoch:2 step:2530 [D loss: 0.705302, acc.: 50.00%] [G loss: 0.774106]\n",
      "epoch:2 step:2531 [D loss: 0.696154, acc.: 56.25%] [G loss: 0.776224]\n",
      "epoch:2 step:2532 [D loss: 0.707979, acc.: 47.66%] [G loss: 0.768595]\n",
      "epoch:2 step:2533 [D loss: 0.665308, acc.: 59.38%] [G loss: 0.740581]\n",
      "epoch:2 step:2534 [D loss: 0.666345, acc.: 58.59%] [G loss: 0.697334]\n",
      "epoch:2 step:2535 [D loss: 0.669280, acc.: 57.03%] [G loss: 0.729836]\n",
      "epoch:2 step:2536 [D loss: 0.705166, acc.: 49.22%] [G loss: 0.714238]\n",
      "epoch:2 step:2537 [D loss: 0.729777, acc.: 43.75%] [G loss: 0.721800]\n",
      "epoch:2 step:2538 [D loss: 0.714123, acc.: 45.31%] [G loss: 0.726469]\n",
      "epoch:2 step:2539 [D loss: 0.728285, acc.: 39.84%] [G loss: 0.774594]\n",
      "epoch:2 step:2540 [D loss: 0.700242, acc.: 51.56%] [G loss: 0.740600]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2541 [D loss: 0.706290, acc.: 46.09%] [G loss: 0.738967]\n",
      "epoch:2 step:2542 [D loss: 0.683470, acc.: 56.25%] [G loss: 0.700360]\n",
      "epoch:2 step:2543 [D loss: 0.718279, acc.: 50.78%] [G loss: 0.749502]\n",
      "epoch:2 step:2544 [D loss: 0.706130, acc.: 46.88%] [G loss: 0.747786]\n",
      "epoch:2 step:2545 [D loss: 0.699413, acc.: 52.34%] [G loss: 0.719092]\n",
      "epoch:2 step:2546 [D loss: 0.705827, acc.: 46.88%] [G loss: 0.735918]\n",
      "epoch:2 step:2547 [D loss: 0.687608, acc.: 51.56%] [G loss: 0.720426]\n",
      "epoch:2 step:2548 [D loss: 0.685060, acc.: 50.78%] [G loss: 0.768950]\n",
      "epoch:2 step:2549 [D loss: 0.705618, acc.: 51.56%] [G loss: 0.761129]\n",
      "epoch:2 step:2550 [D loss: 0.691634, acc.: 54.69%] [G loss: 0.747155]\n",
      "epoch:2 step:2551 [D loss: 0.681306, acc.: 51.56%] [G loss: 0.749763]\n",
      "epoch:2 step:2552 [D loss: 0.693199, acc.: 52.34%] [G loss: 0.748105]\n",
      "epoch:2 step:2553 [D loss: 0.685349, acc.: 53.12%] [G loss: 0.793926]\n",
      "epoch:2 step:2554 [D loss: 0.690276, acc.: 55.47%] [G loss: 0.754496]\n",
      "epoch:2 step:2555 [D loss: 0.672015, acc.: 57.81%] [G loss: 0.750277]\n",
      "epoch:2 step:2556 [D loss: 0.716975, acc.: 47.66%] [G loss: 0.731947]\n",
      "epoch:2 step:2557 [D loss: 0.682003, acc.: 57.03%] [G loss: 0.755036]\n",
      "epoch:2 step:2558 [D loss: 0.699932, acc.: 47.66%] [G loss: 0.794400]\n",
      "epoch:2 step:2559 [D loss: 0.699964, acc.: 51.56%] [G loss: 0.721888]\n",
      "epoch:2 step:2560 [D loss: 0.707254, acc.: 49.22%] [G loss: 0.710554]\n",
      "epoch:2 step:2561 [D loss: 0.705116, acc.: 52.34%] [G loss: 0.776776]\n",
      "epoch:2 step:2562 [D loss: 0.699414, acc.: 47.66%] [G loss: 0.716979]\n",
      "epoch:2 step:2563 [D loss: 0.702875, acc.: 46.09%] [G loss: 0.770909]\n",
      "epoch:2 step:2564 [D loss: 0.689676, acc.: 53.91%] [G loss: 0.748220]\n",
      "epoch:2 step:2565 [D loss: 0.690657, acc.: 55.47%] [G loss: 0.733677]\n",
      "epoch:2 step:2566 [D loss: 0.683946, acc.: 57.81%] [G loss: 0.708546]\n",
      "epoch:2 step:2567 [D loss: 0.671003, acc.: 59.38%] [G loss: 0.723259]\n",
      "epoch:2 step:2568 [D loss: 0.688759, acc.: 53.12%] [G loss: 0.777213]\n",
      "epoch:2 step:2569 [D loss: 0.712159, acc.: 53.91%] [G loss: 0.761913]\n",
      "epoch:2 step:2570 [D loss: 0.713983, acc.: 44.53%] [G loss: 0.729026]\n",
      "epoch:2 step:2571 [D loss: 0.702450, acc.: 44.53%] [G loss: 0.763171]\n",
      "epoch:2 step:2572 [D loss: 0.701429, acc.: 48.44%] [G loss: 0.726331]\n",
      "epoch:2 step:2573 [D loss: 0.706440, acc.: 51.56%] [G loss: 0.762407]\n",
      "epoch:2 step:2574 [D loss: 0.694395, acc.: 48.44%] [G loss: 0.772157]\n",
      "epoch:2 step:2575 [D loss: 0.702841, acc.: 48.44%] [G loss: 0.751156]\n",
      "epoch:2 step:2576 [D loss: 0.690395, acc.: 55.47%] [G loss: 0.762133]\n",
      "epoch:2 step:2577 [D loss: 0.700848, acc.: 53.91%] [G loss: 0.770526]\n",
      "epoch:2 step:2578 [D loss: 0.692834, acc.: 52.34%] [G loss: 0.798723]\n",
      "epoch:2 step:2579 [D loss: 0.672280, acc.: 59.38%] [G loss: 0.755556]\n",
      "epoch:2 step:2580 [D loss: 0.667765, acc.: 59.38%] [G loss: 0.760058]\n",
      "epoch:2 step:2581 [D loss: 0.669799, acc.: 61.72%] [G loss: 0.750374]\n",
      "epoch:2 step:2582 [D loss: 0.684480, acc.: 55.47%] [G loss: 0.776135]\n",
      "epoch:2 step:2583 [D loss: 0.663190, acc.: 64.84%] [G loss: 0.768609]\n",
      "epoch:2 step:2584 [D loss: 0.732528, acc.: 41.41%] [G loss: 0.761197]\n",
      "epoch:2 step:2585 [D loss: 0.707652, acc.: 50.00%] [G loss: 0.744967]\n",
      "epoch:2 step:2586 [D loss: 0.674933, acc.: 55.47%] [G loss: 0.749132]\n",
      "epoch:2 step:2587 [D loss: 0.675676, acc.: 61.72%] [G loss: 0.718562]\n",
      "epoch:2 step:2588 [D loss: 0.685009, acc.: 53.91%] [G loss: 0.762421]\n",
      "epoch:2 step:2589 [D loss: 0.704066, acc.: 51.56%] [G loss: 0.817202]\n",
      "epoch:2 step:2590 [D loss: 0.706333, acc.: 51.56%] [G loss: 0.736350]\n",
      "epoch:2 step:2591 [D loss: 0.704692, acc.: 48.44%] [G loss: 0.721942]\n",
      "epoch:2 step:2592 [D loss: 0.703750, acc.: 50.78%] [G loss: 0.709635]\n",
      "epoch:2 step:2593 [D loss: 0.670224, acc.: 56.25%] [G loss: 0.760149]\n",
      "epoch:2 step:2594 [D loss: 0.649183, acc.: 62.50%] [G loss: 0.786173]\n",
      "epoch:2 step:2595 [D loss: 0.701400, acc.: 52.34%] [G loss: 0.753367]\n",
      "epoch:2 step:2596 [D loss: 0.705626, acc.: 47.66%] [G loss: 0.762049]\n",
      "epoch:2 step:2597 [D loss: 0.681411, acc.: 53.91%] [G loss: 0.792475]\n",
      "epoch:2 step:2598 [D loss: 0.668671, acc.: 60.16%] [G loss: 0.832654]\n",
      "epoch:2 step:2599 [D loss: 0.652251, acc.: 61.72%] [G loss: 0.775284]\n",
      "epoch:2 step:2600 [D loss: 0.686830, acc.: 57.81%] [G loss: 0.798642]\n",
      "##############\n",
      "[3.76215093 2.28506317 6.19182477 5.572345   3.94617982 5.68675773\n",
      " 5.32967631 5.02475391 5.09837061 4.55808629]\n",
      "##########\n",
      "epoch:2 step:2601 [D loss: 0.672079, acc.: 58.59%] [G loss: 0.857596]\n",
      "epoch:2 step:2602 [D loss: 0.695696, acc.: 53.12%] [G loss: 0.802491]\n",
      "epoch:2 step:2603 [D loss: 0.708906, acc.: 50.78%] [G loss: 0.757929]\n",
      "epoch:2 step:2604 [D loss: 0.681060, acc.: 54.69%] [G loss: 0.767402]\n",
      "epoch:2 step:2605 [D loss: 0.682922, acc.: 52.34%] [G loss: 0.824724]\n",
      "epoch:2 step:2606 [D loss: 0.656388, acc.: 64.84%] [G loss: 0.766845]\n",
      "epoch:2 step:2607 [D loss: 0.681080, acc.: 55.47%] [G loss: 0.768673]\n",
      "epoch:2 step:2608 [D loss: 0.701380, acc.: 53.91%] [G loss: 0.782601]\n",
      "epoch:2 step:2609 [D loss: 0.709891, acc.: 50.78%] [G loss: 0.820311]\n",
      "epoch:2 step:2610 [D loss: 0.712849, acc.: 46.09%] [G loss: 0.773818]\n",
      "epoch:2 step:2611 [D loss: 0.689025, acc.: 51.56%] [G loss: 0.747811]\n",
      "epoch:2 step:2612 [D loss: 0.722000, acc.: 42.97%] [G loss: 0.729203]\n",
      "epoch:2 step:2613 [D loss: 0.703100, acc.: 50.78%] [G loss: 0.747411]\n",
      "epoch:2 step:2614 [D loss: 0.730274, acc.: 42.19%] [G loss: 0.717967]\n",
      "epoch:2 step:2615 [D loss: 0.697650, acc.: 44.53%] [G loss: 0.709329]\n",
      "epoch:2 step:2616 [D loss: 0.743042, acc.: 39.06%] [G loss: 0.711227]\n",
      "epoch:2 step:2617 [D loss: 0.703545, acc.: 48.44%] [G loss: 0.716475]\n",
      "epoch:2 step:2618 [D loss: 0.718552, acc.: 44.53%] [G loss: 0.708938]\n",
      "epoch:2 step:2619 [D loss: 0.702136, acc.: 49.22%] [G loss: 0.731839]\n",
      "epoch:2 step:2620 [D loss: 0.689168, acc.: 54.69%] [G loss: 0.728487]\n",
      "epoch:2 step:2621 [D loss: 0.677639, acc.: 58.59%] [G loss: 0.779534]\n",
      "epoch:2 step:2622 [D loss: 0.704467, acc.: 48.44%] [G loss: 0.757366]\n",
      "epoch:2 step:2623 [D loss: 0.711010, acc.: 46.88%] [G loss: 0.783053]\n",
      "epoch:2 step:2624 [D loss: 0.681950, acc.: 63.28%] [G loss: 0.769323]\n",
      "epoch:2 step:2625 [D loss: 0.696950, acc.: 51.56%] [G loss: 0.745793]\n",
      "epoch:2 step:2626 [D loss: 0.704442, acc.: 47.66%] [G loss: 0.819478]\n",
      "epoch:2 step:2627 [D loss: 0.711239, acc.: 43.75%] [G loss: 0.724478]\n",
      "epoch:2 step:2628 [D loss: 0.712078, acc.: 49.22%] [G loss: 0.759125]\n",
      "epoch:2 step:2629 [D loss: 0.677078, acc.: 53.12%] [G loss: 0.724651]\n",
      "epoch:2 step:2630 [D loss: 0.672358, acc.: 64.06%] [G loss: 0.734664]\n",
      "epoch:2 step:2631 [D loss: 0.695021, acc.: 49.22%] [G loss: 0.753651]\n",
      "epoch:2 step:2632 [D loss: 0.694712, acc.: 53.12%] [G loss: 0.722707]\n",
      "epoch:2 step:2633 [D loss: 0.715089, acc.: 44.53%] [G loss: 0.738902]\n",
      "epoch:2 step:2634 [D loss: 0.690482, acc.: 49.22%] [G loss: 0.709024]\n",
      "epoch:2 step:2635 [D loss: 0.687487, acc.: 51.56%] [G loss: 0.749023]\n",
      "epoch:2 step:2636 [D loss: 0.703918, acc.: 46.88%] [G loss: 0.757407]\n",
      "epoch:2 step:2637 [D loss: 0.684462, acc.: 50.00%] [G loss: 0.749967]\n",
      "epoch:2 step:2638 [D loss: 0.686828, acc.: 60.16%] [G loss: 0.706874]\n",
      "epoch:2 step:2639 [D loss: 0.704757, acc.: 52.34%] [G loss: 0.739412]\n",
      "epoch:2 step:2640 [D loss: 0.710549, acc.: 50.00%] [G loss: 0.753716]\n",
      "epoch:2 step:2641 [D loss: 0.686640, acc.: 49.22%] [G loss: 0.728705]\n",
      "epoch:2 step:2642 [D loss: 0.702296, acc.: 48.44%] [G loss: 0.727697]\n",
      "epoch:2 step:2643 [D loss: 0.698517, acc.: 50.00%] [G loss: 0.755278]\n",
      "epoch:2 step:2644 [D loss: 0.668572, acc.: 62.50%] [G loss: 0.728887]\n",
      "epoch:2 step:2645 [D loss: 0.694412, acc.: 56.25%] [G loss: 0.774948]\n",
      "epoch:2 step:2646 [D loss: 0.679754, acc.: 57.81%] [G loss: 0.747684]\n",
      "epoch:2 step:2647 [D loss: 0.695710, acc.: 50.78%] [G loss: 0.746976]\n",
      "epoch:2 step:2648 [D loss: 0.695917, acc.: 52.34%] [G loss: 0.745712]\n",
      "epoch:2 step:2649 [D loss: 0.662799, acc.: 60.16%] [G loss: 0.746170]\n",
      "epoch:2 step:2650 [D loss: 0.686848, acc.: 50.00%] [G loss: 0.776936]\n",
      "epoch:2 step:2651 [D loss: 0.688203, acc.: 57.03%] [G loss: 0.756059]\n",
      "epoch:2 step:2652 [D loss: 0.692992, acc.: 55.47%] [G loss: 0.782440]\n",
      "epoch:2 step:2653 [D loss: 0.695838, acc.: 50.78%] [G loss: 0.736596]\n",
      "epoch:2 step:2654 [D loss: 0.693716, acc.: 53.91%] [G loss: 0.766709]\n",
      "epoch:2 step:2655 [D loss: 0.693208, acc.: 50.78%] [G loss: 0.739612]\n",
      "epoch:2 step:2656 [D loss: 0.687302, acc.: 54.69%] [G loss: 0.745551]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2657 [D loss: 0.697384, acc.: 53.12%] [G loss: 0.777507]\n",
      "epoch:2 step:2658 [D loss: 0.730476, acc.: 42.19%] [G loss: 0.742568]\n",
      "epoch:2 step:2659 [D loss: 0.674064, acc.: 62.50%] [G loss: 0.754324]\n",
      "epoch:2 step:2660 [D loss: 0.688979, acc.: 53.91%] [G loss: 0.723598]\n",
      "epoch:2 step:2661 [D loss: 0.705507, acc.: 46.09%] [G loss: 0.761211]\n",
      "epoch:2 step:2662 [D loss: 0.719934, acc.: 46.88%] [G loss: 0.701082]\n",
      "epoch:2 step:2663 [D loss: 0.719196, acc.: 41.41%] [G loss: 0.739402]\n",
      "epoch:2 step:2664 [D loss: 0.709293, acc.: 46.88%] [G loss: 0.719997]\n",
      "epoch:2 step:2665 [D loss: 0.691996, acc.: 48.44%] [G loss: 0.745637]\n",
      "epoch:2 step:2666 [D loss: 0.678306, acc.: 57.03%] [G loss: 0.731864]\n",
      "epoch:2 step:2667 [D loss: 0.694225, acc.: 53.12%] [G loss: 0.733801]\n",
      "epoch:2 step:2668 [D loss: 0.694019, acc.: 46.88%] [G loss: 0.745842]\n",
      "epoch:2 step:2669 [D loss: 0.691118, acc.: 50.78%] [G loss: 0.737192]\n",
      "epoch:2 step:2670 [D loss: 0.684723, acc.: 52.34%] [G loss: 0.752908]\n",
      "epoch:2 step:2671 [D loss: 0.700825, acc.: 48.44%] [G loss: 0.753745]\n",
      "epoch:2 step:2672 [D loss: 0.700234, acc.: 46.88%] [G loss: 0.744777]\n",
      "epoch:2 step:2673 [D loss: 0.692796, acc.: 55.47%] [G loss: 0.734013]\n",
      "epoch:2 step:2674 [D loss: 0.720087, acc.: 43.75%] [G loss: 0.760245]\n",
      "epoch:2 step:2675 [D loss: 0.714418, acc.: 41.41%] [G loss: 0.743719]\n",
      "epoch:2 step:2676 [D loss: 0.679686, acc.: 56.25%] [G loss: 0.749466]\n",
      "epoch:2 step:2677 [D loss: 0.665777, acc.: 60.16%] [G loss: 0.730594]\n",
      "epoch:2 step:2678 [D loss: 0.697275, acc.: 47.66%] [G loss: 0.756329]\n",
      "epoch:2 step:2679 [D loss: 0.703844, acc.: 50.00%] [G loss: 0.779620]\n",
      "epoch:2 step:2680 [D loss: 0.677615, acc.: 57.03%] [G loss: 0.777329]\n",
      "epoch:2 step:2681 [D loss: 0.689482, acc.: 57.81%] [G loss: 0.786034]\n",
      "epoch:2 step:2682 [D loss: 0.710559, acc.: 46.09%] [G loss: 0.770235]\n",
      "epoch:2 step:2683 [D loss: 0.710560, acc.: 44.53%] [G loss: 0.753054]\n",
      "epoch:2 step:2684 [D loss: 0.690582, acc.: 55.47%] [G loss: 0.746932]\n",
      "epoch:2 step:2685 [D loss: 0.692792, acc.: 55.47%] [G loss: 0.739214]\n",
      "epoch:2 step:2686 [D loss: 0.692873, acc.: 50.78%] [G loss: 0.739856]\n",
      "epoch:2 step:2687 [D loss: 0.696205, acc.: 54.69%] [G loss: 0.739688]\n",
      "epoch:2 step:2688 [D loss: 0.701905, acc.: 51.56%] [G loss: 0.768491]\n",
      "epoch:2 step:2689 [D loss: 0.681185, acc.: 60.94%] [G loss: 0.717999]\n",
      "epoch:2 step:2690 [D loss: 0.690654, acc.: 48.44%] [G loss: 0.717555]\n",
      "epoch:2 step:2691 [D loss: 0.677570, acc.: 57.81%] [G loss: 0.737070]\n",
      "epoch:2 step:2692 [D loss: 0.698818, acc.: 49.22%] [G loss: 0.755793]\n",
      "epoch:2 step:2693 [D loss: 0.703813, acc.: 47.66%] [G loss: 0.686923]\n",
      "epoch:2 step:2694 [D loss: 0.712870, acc.: 43.75%] [G loss: 0.722417]\n",
      "epoch:2 step:2695 [D loss: 0.697947, acc.: 46.09%] [G loss: 0.730838]\n",
      "epoch:2 step:2696 [D loss: 0.719304, acc.: 50.78%] [G loss: 0.755268]\n",
      "epoch:2 step:2697 [D loss: 0.679421, acc.: 59.38%] [G loss: 0.754838]\n",
      "epoch:2 step:2698 [D loss: 0.698967, acc.: 50.78%] [G loss: 0.763078]\n",
      "epoch:2 step:2699 [D loss: 0.671278, acc.: 61.72%] [G loss: 0.771178]\n",
      "epoch:2 step:2700 [D loss: 0.678767, acc.: 54.69%] [G loss: 0.786775]\n",
      "epoch:2 step:2701 [D loss: 0.685180, acc.: 57.03%] [G loss: 0.783291]\n",
      "epoch:2 step:2702 [D loss: 0.683292, acc.: 57.03%] [G loss: 0.761645]\n",
      "epoch:2 step:2703 [D loss: 0.664429, acc.: 60.94%] [G loss: 0.753095]\n",
      "epoch:2 step:2704 [D loss: 0.681291, acc.: 60.16%] [G loss: 0.751945]\n",
      "epoch:2 step:2705 [D loss: 0.710138, acc.: 48.44%] [G loss: 0.782720]\n",
      "epoch:2 step:2706 [D loss: 0.682235, acc.: 54.69%] [G loss: 0.738295]\n",
      "epoch:2 step:2707 [D loss: 0.724881, acc.: 46.09%] [G loss: 0.748254]\n",
      "epoch:2 step:2708 [D loss: 0.728625, acc.: 40.62%] [G loss: 0.727670]\n",
      "epoch:2 step:2709 [D loss: 0.708817, acc.: 47.66%] [G loss: 0.705683]\n",
      "epoch:2 step:2710 [D loss: 0.699916, acc.: 50.78%] [G loss: 0.711511]\n",
      "epoch:2 step:2711 [D loss: 0.713476, acc.: 51.56%] [G loss: 0.745619]\n",
      "epoch:2 step:2712 [D loss: 0.700605, acc.: 46.09%] [G loss: 0.743342]\n",
      "epoch:2 step:2713 [D loss: 0.689735, acc.: 53.12%] [G loss: 0.750678]\n",
      "epoch:2 step:2714 [D loss: 0.699536, acc.: 55.47%] [G loss: 0.791481]\n",
      "epoch:2 step:2715 [D loss: 0.702279, acc.: 44.53%] [G loss: 0.753220]\n",
      "epoch:2 step:2716 [D loss: 0.675291, acc.: 57.81%] [G loss: 0.797385]\n",
      "epoch:2 step:2717 [D loss: 0.710444, acc.: 50.78%] [G loss: 0.801586]\n",
      "epoch:2 step:2718 [D loss: 0.672828, acc.: 60.94%] [G loss: 0.794400]\n",
      "epoch:2 step:2719 [D loss: 0.693959, acc.: 54.69%] [G loss: 0.772376]\n",
      "epoch:2 step:2720 [D loss: 0.682064, acc.: 51.56%] [G loss: 0.767103]\n",
      "epoch:2 step:2721 [D loss: 0.700279, acc.: 46.09%] [G loss: 0.776195]\n",
      "epoch:2 step:2722 [D loss: 0.700869, acc.: 53.12%] [G loss: 0.767202]\n",
      "epoch:2 step:2723 [D loss: 0.699671, acc.: 53.91%] [G loss: 0.741107]\n",
      "epoch:2 step:2724 [D loss: 0.726578, acc.: 36.72%] [G loss: 0.715956]\n",
      "epoch:2 step:2725 [D loss: 0.692112, acc.: 47.66%] [G loss: 0.718182]\n",
      "epoch:2 step:2726 [D loss: 0.691922, acc.: 48.44%] [G loss: 0.713263]\n",
      "epoch:2 step:2727 [D loss: 0.668596, acc.: 57.03%] [G loss: 0.757829]\n",
      "epoch:2 step:2728 [D loss: 0.714112, acc.: 45.31%] [G loss: 0.772452]\n",
      "epoch:2 step:2729 [D loss: 0.694818, acc.: 48.44%] [G loss: 0.775255]\n",
      "epoch:2 step:2730 [D loss: 0.683523, acc.: 57.03%] [G loss: 0.793576]\n",
      "epoch:2 step:2731 [D loss: 0.667331, acc.: 58.59%] [G loss: 0.748111]\n",
      "epoch:2 step:2732 [D loss: 0.724495, acc.: 47.66%] [G loss: 0.771834]\n",
      "epoch:2 step:2733 [D loss: 0.706528, acc.: 50.00%] [G loss: 0.752163]\n",
      "epoch:2 step:2734 [D loss: 0.692627, acc.: 52.34%] [G loss: 0.814098]\n",
      "epoch:2 step:2735 [D loss: 0.680806, acc.: 58.59%] [G loss: 0.731370]\n",
      "epoch:2 step:2736 [D loss: 0.700979, acc.: 55.47%] [G loss: 0.747020]\n",
      "epoch:2 step:2737 [D loss: 0.693533, acc.: 51.56%] [G loss: 0.724778]\n",
      "epoch:2 step:2738 [D loss: 0.689764, acc.: 52.34%] [G loss: 0.705890]\n",
      "epoch:2 step:2739 [D loss: 0.712714, acc.: 47.66%] [G loss: 0.713680]\n",
      "epoch:2 step:2740 [D loss: 0.691391, acc.: 52.34%] [G loss: 0.707254]\n",
      "epoch:2 step:2741 [D loss: 0.739059, acc.: 49.22%] [G loss: 0.716348]\n",
      "epoch:2 step:2742 [D loss: 0.705943, acc.: 49.22%] [G loss: 0.725134]\n",
      "epoch:2 step:2743 [D loss: 0.707445, acc.: 43.75%] [G loss: 0.729755]\n",
      "epoch:2 step:2744 [D loss: 0.690056, acc.: 55.47%] [G loss: 0.721255]\n",
      "epoch:2 step:2745 [D loss: 0.692632, acc.: 49.22%] [G loss: 0.715917]\n",
      "epoch:2 step:2746 [D loss: 0.687115, acc.: 54.69%] [G loss: 0.711595]\n",
      "epoch:2 step:2747 [D loss: 0.702019, acc.: 48.44%] [G loss: 0.737953]\n",
      "epoch:2 step:2748 [D loss: 0.730257, acc.: 43.75%] [G loss: 0.718436]\n",
      "epoch:2 step:2749 [D loss: 0.693203, acc.: 53.12%] [G loss: 0.740644]\n",
      "epoch:2 step:2750 [D loss: 0.702817, acc.: 45.31%] [G loss: 0.744854]\n",
      "epoch:2 step:2751 [D loss: 0.688240, acc.: 53.91%] [G loss: 0.782076]\n",
      "epoch:2 step:2752 [D loss: 0.701357, acc.: 52.34%] [G loss: 0.743141]\n",
      "epoch:2 step:2753 [D loss: 0.690820, acc.: 55.47%] [G loss: 0.773339]\n",
      "epoch:2 step:2754 [D loss: 0.692691, acc.: 53.12%] [G loss: 0.747300]\n",
      "epoch:2 step:2755 [D loss: 0.692586, acc.: 55.47%] [G loss: 0.767611]\n",
      "epoch:2 step:2756 [D loss: 0.707423, acc.: 46.09%] [G loss: 0.733794]\n",
      "epoch:2 step:2757 [D loss: 0.681904, acc.: 53.91%] [G loss: 0.762659]\n",
      "epoch:2 step:2758 [D loss: 0.678123, acc.: 57.81%] [G loss: 0.769677]\n",
      "epoch:2 step:2759 [D loss: 0.687884, acc.: 53.91%] [G loss: 0.779638]\n",
      "epoch:2 step:2760 [D loss: 0.676240, acc.: 55.47%] [G loss: 0.736632]\n",
      "epoch:2 step:2761 [D loss: 0.703294, acc.: 50.00%] [G loss: 0.771211]\n",
      "epoch:2 step:2762 [D loss: 0.699176, acc.: 48.44%] [G loss: 0.742795]\n",
      "epoch:2 step:2763 [D loss: 0.684831, acc.: 56.25%] [G loss: 0.734998]\n",
      "epoch:2 step:2764 [D loss: 0.676031, acc.: 58.59%] [G loss: 0.735338]\n",
      "epoch:2 step:2765 [D loss: 0.697205, acc.: 53.12%] [G loss: 0.734201]\n",
      "epoch:2 step:2766 [D loss: 0.721484, acc.: 48.44%] [G loss: 0.732060]\n",
      "epoch:2 step:2767 [D loss: 0.735038, acc.: 38.28%] [G loss: 0.708948]\n",
      "epoch:2 step:2768 [D loss: 0.695253, acc.: 48.44%] [G loss: 0.706449]\n",
      "epoch:2 step:2769 [D loss: 0.708090, acc.: 50.00%] [G loss: 0.710939]\n",
      "epoch:2 step:2770 [D loss: 0.710035, acc.: 49.22%] [G loss: 0.746310]\n",
      "epoch:2 step:2771 [D loss: 0.693820, acc.: 50.00%] [G loss: 0.738227]\n",
      "epoch:2 step:2772 [D loss: 0.695567, acc.: 52.34%] [G loss: 0.729270]\n",
      "epoch:2 step:2773 [D loss: 0.691454, acc.: 52.34%] [G loss: 0.754120]\n",
      "epoch:2 step:2774 [D loss: 0.679755, acc.: 51.56%] [G loss: 0.766940]\n",
      "epoch:2 step:2775 [D loss: 0.674044, acc.: 57.03%] [G loss: 0.796679]\n",
      "epoch:2 step:2776 [D loss: 0.691281, acc.: 52.34%] [G loss: 0.744583]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2777 [D loss: 0.694055, acc.: 54.69%] [G loss: 0.753690]\n",
      "epoch:2 step:2778 [D loss: 0.715143, acc.: 41.41%] [G loss: 0.756269]\n",
      "epoch:2 step:2779 [D loss: 0.707612, acc.: 42.19%] [G loss: 0.735348]\n",
      "epoch:2 step:2780 [D loss: 0.702546, acc.: 48.44%] [G loss: 0.695688]\n",
      "epoch:2 step:2781 [D loss: 0.704467, acc.: 48.44%] [G loss: 0.720849]\n",
      "epoch:2 step:2782 [D loss: 0.710512, acc.: 41.41%] [G loss: 0.727744]\n",
      "epoch:2 step:2783 [D loss: 0.706125, acc.: 42.97%] [G loss: 0.733786]\n",
      "epoch:2 step:2784 [D loss: 0.715873, acc.: 40.62%] [G loss: 0.707142]\n",
      "epoch:2 step:2785 [D loss: 0.703974, acc.: 42.97%] [G loss: 0.697455]\n",
      "epoch:2 step:2786 [D loss: 0.681558, acc.: 55.47%] [G loss: 0.750802]\n",
      "epoch:2 step:2787 [D loss: 0.679296, acc.: 54.69%] [G loss: 0.748695]\n",
      "epoch:2 step:2788 [D loss: 0.696147, acc.: 50.00%] [G loss: 0.719614]\n",
      "epoch:2 step:2789 [D loss: 0.716270, acc.: 47.66%] [G loss: 0.712938]\n",
      "epoch:2 step:2790 [D loss: 0.711325, acc.: 46.09%] [G loss: 0.733283]\n",
      "epoch:2 step:2791 [D loss: 0.705781, acc.: 50.00%] [G loss: 0.746196]\n",
      "epoch:2 step:2792 [D loss: 0.697309, acc.: 50.78%] [G loss: 0.733403]\n",
      "epoch:2 step:2793 [D loss: 0.675185, acc.: 59.38%] [G loss: 0.746462]\n",
      "epoch:2 step:2794 [D loss: 0.734634, acc.: 39.06%] [G loss: 0.736516]\n",
      "epoch:2 step:2795 [D loss: 0.687480, acc.: 60.94%] [G loss: 0.780425]\n",
      "epoch:2 step:2796 [D loss: 0.688169, acc.: 52.34%] [G loss: 0.760893]\n",
      "epoch:2 step:2797 [D loss: 0.672085, acc.: 60.16%] [G loss: 0.740980]\n",
      "epoch:2 step:2798 [D loss: 0.671769, acc.: 57.03%] [G loss: 0.744748]\n",
      "epoch:2 step:2799 [D loss: 0.647089, acc.: 64.84%] [G loss: 0.777643]\n",
      "epoch:2 step:2800 [D loss: 0.648684, acc.: 65.62%] [G loss: 0.763060]\n",
      "##############\n",
      "[4.07417418 2.51187456 6.24377481 5.5747028  4.46099283 6.33374389\n",
      " 5.93055381 5.238879   5.6161764  4.70568621]\n",
      "##########\n",
      "epoch:2 step:2801 [D loss: 0.655781, acc.: 62.50%] [G loss: 0.779705]\n",
      "epoch:2 step:2802 [D loss: 0.708221, acc.: 52.34%] [G loss: 0.808176]\n",
      "epoch:2 step:2803 [D loss: 0.732772, acc.: 41.41%] [G loss: 0.795261]\n",
      "epoch:2 step:2804 [D loss: 0.674887, acc.: 59.38%] [G loss: 0.751121]\n",
      "epoch:2 step:2805 [D loss: 0.686895, acc.: 53.91%] [G loss: 0.744101]\n",
      "epoch:2 step:2806 [D loss: 0.687031, acc.: 56.25%] [G loss: 0.793246]\n",
      "epoch:2 step:2807 [D loss: 0.692475, acc.: 57.03%] [G loss: 0.746423]\n",
      "epoch:2 step:2808 [D loss: 0.679880, acc.: 60.94%] [G loss: 0.735957]\n",
      "epoch:2 step:2809 [D loss: 0.680374, acc.: 57.81%] [G loss: 0.755481]\n",
      "epoch:2 step:2810 [D loss: 0.622653, acc.: 67.19%] [G loss: 0.745708]\n",
      "epoch:2 step:2811 [D loss: 0.713815, acc.: 53.12%] [G loss: 0.733620]\n",
      "epoch:3 step:2812 [D loss: 0.715306, acc.: 48.44%] [G loss: 0.752579]\n",
      "epoch:3 step:2813 [D loss: 0.733850, acc.: 45.31%] [G loss: 0.720415]\n",
      "epoch:3 step:2814 [D loss: 0.721793, acc.: 41.41%] [G loss: 0.750458]\n",
      "epoch:3 step:2815 [D loss: 0.694617, acc.: 53.12%] [G loss: 0.749204]\n",
      "epoch:3 step:2816 [D loss: 0.700193, acc.: 54.69%] [G loss: 0.710538]\n",
      "epoch:3 step:2817 [D loss: 0.712200, acc.: 45.31%] [G loss: 0.702943]\n",
      "epoch:3 step:2818 [D loss: 0.689097, acc.: 53.91%] [G loss: 0.748874]\n",
      "epoch:3 step:2819 [D loss: 0.702517, acc.: 48.44%] [G loss: 0.745320]\n",
      "epoch:3 step:2820 [D loss: 0.697544, acc.: 50.78%] [G loss: 0.747538]\n",
      "epoch:3 step:2821 [D loss: 0.686839, acc.: 53.91%] [G loss: 0.758431]\n",
      "epoch:3 step:2822 [D loss: 0.679626, acc.: 51.56%] [G loss: 0.736901]\n",
      "epoch:3 step:2823 [D loss: 0.711874, acc.: 50.78%] [G loss: 0.733550]\n",
      "epoch:3 step:2824 [D loss: 0.700270, acc.: 56.25%] [G loss: 0.740673]\n",
      "epoch:3 step:2825 [D loss: 0.686911, acc.: 55.47%] [G loss: 0.766558]\n",
      "epoch:3 step:2826 [D loss: 0.697216, acc.: 53.91%] [G loss: 0.786505]\n",
      "epoch:3 step:2827 [D loss: 0.679995, acc.: 62.50%] [G loss: 0.767591]\n",
      "epoch:3 step:2828 [D loss: 0.685903, acc.: 51.56%] [G loss: 0.731616]\n",
      "epoch:3 step:2829 [D loss: 0.689925, acc.: 55.47%] [G loss: 0.780151]\n",
      "epoch:3 step:2830 [D loss: 0.697869, acc.: 52.34%] [G loss: 0.763474]\n",
      "epoch:3 step:2831 [D loss: 0.703800, acc.: 45.31%] [G loss: 0.738936]\n",
      "epoch:3 step:2832 [D loss: 0.682816, acc.: 55.47%] [G loss: 0.770841]\n",
      "epoch:3 step:2833 [D loss: 0.674359, acc.: 60.94%] [G loss: 0.798598]\n",
      "epoch:3 step:2834 [D loss: 0.675729, acc.: 55.47%] [G loss: 0.767178]\n",
      "epoch:3 step:2835 [D loss: 0.685302, acc.: 57.81%] [G loss: 0.815879]\n",
      "epoch:3 step:2836 [D loss: 0.661672, acc.: 66.41%] [G loss: 0.794309]\n",
      "epoch:3 step:2837 [D loss: 0.674933, acc.: 59.38%] [G loss: 0.768059]\n",
      "epoch:3 step:2838 [D loss: 0.672365, acc.: 54.69%] [G loss: 0.801773]\n",
      "epoch:3 step:2839 [D loss: 0.696753, acc.: 52.34%] [G loss: 0.799602]\n",
      "epoch:3 step:2840 [D loss: 0.655931, acc.: 64.06%] [G loss: 0.759515]\n",
      "epoch:3 step:2841 [D loss: 0.672021, acc.: 50.78%] [G loss: 0.764840]\n",
      "epoch:3 step:2842 [D loss: 0.713369, acc.: 47.66%] [G loss: 0.729094]\n",
      "epoch:3 step:2843 [D loss: 0.689293, acc.: 55.47%] [G loss: 0.780120]\n",
      "epoch:3 step:2844 [D loss: 0.712457, acc.: 47.66%] [G loss: 0.756942]\n",
      "epoch:3 step:2845 [D loss: 0.695457, acc.: 56.25%] [G loss: 0.763375]\n",
      "epoch:3 step:2846 [D loss: 0.709465, acc.: 55.47%] [G loss: 0.741359]\n",
      "epoch:3 step:2847 [D loss: 0.707429, acc.: 48.44%] [G loss: 0.742298]\n",
      "epoch:3 step:2848 [D loss: 0.738534, acc.: 39.06%] [G loss: 0.714467]\n",
      "epoch:3 step:2849 [D loss: 0.753263, acc.: 32.03%] [G loss: 0.732657]\n",
      "epoch:3 step:2850 [D loss: 0.751274, acc.: 35.94%] [G loss: 0.722788]\n",
      "epoch:3 step:2851 [D loss: 0.695719, acc.: 50.78%] [G loss: 0.744614]\n",
      "epoch:3 step:2852 [D loss: 0.689912, acc.: 51.56%] [G loss: 0.755629]\n",
      "epoch:3 step:2853 [D loss: 0.672592, acc.: 54.69%] [G loss: 0.757460]\n",
      "epoch:3 step:2854 [D loss: 0.685218, acc.: 51.56%] [G loss: 0.793886]\n",
      "epoch:3 step:2855 [D loss: 0.687721, acc.: 54.69%] [G loss: 0.801158]\n",
      "epoch:3 step:2856 [D loss: 0.692177, acc.: 46.88%] [G loss: 0.769472]\n",
      "epoch:3 step:2857 [D loss: 0.679824, acc.: 54.69%] [G loss: 0.765075]\n",
      "epoch:3 step:2858 [D loss: 0.680357, acc.: 50.00%] [G loss: 0.745176]\n",
      "epoch:3 step:2859 [D loss: 0.680640, acc.: 58.59%] [G loss: 0.763444]\n",
      "epoch:3 step:2860 [D loss: 0.667630, acc.: 60.16%] [G loss: 0.771987]\n",
      "epoch:3 step:2861 [D loss: 0.682860, acc.: 55.47%] [G loss: 0.737967]\n",
      "epoch:3 step:2862 [D loss: 0.711357, acc.: 46.09%] [G loss: 0.742289]\n",
      "epoch:3 step:2863 [D loss: 0.692420, acc.: 53.91%] [G loss: 0.710855]\n",
      "epoch:3 step:2864 [D loss: 0.695499, acc.: 51.56%] [G loss: 0.728474]\n",
      "epoch:3 step:2865 [D loss: 0.699062, acc.: 50.78%] [G loss: 0.750458]\n",
      "epoch:3 step:2866 [D loss: 0.703720, acc.: 48.44%] [G loss: 0.730181]\n",
      "epoch:3 step:2867 [D loss: 0.716529, acc.: 45.31%] [G loss: 0.748685]\n",
      "epoch:3 step:2868 [D loss: 0.717599, acc.: 38.28%] [G loss: 0.757470]\n",
      "epoch:3 step:2869 [D loss: 0.735683, acc.: 37.50%] [G loss: 0.781925]\n",
      "epoch:3 step:2870 [D loss: 0.703790, acc.: 48.44%] [G loss: 0.791837]\n",
      "epoch:3 step:2871 [D loss: 0.685505, acc.: 55.47%] [G loss: 0.752516]\n",
      "epoch:3 step:2872 [D loss: 0.683112, acc.: 57.81%] [G loss: 0.790690]\n",
      "epoch:3 step:2873 [D loss: 0.674011, acc.: 59.38%] [G loss: 0.773843]\n",
      "epoch:3 step:2874 [D loss: 0.669636, acc.: 58.59%] [G loss: 0.780872]\n",
      "epoch:3 step:2875 [D loss: 0.668962, acc.: 63.28%] [G loss: 0.765960]\n",
      "epoch:3 step:2876 [D loss: 0.670789, acc.: 59.38%] [G loss: 0.782779]\n",
      "epoch:3 step:2877 [D loss: 0.690280, acc.: 53.91%] [G loss: 0.766224]\n",
      "epoch:3 step:2878 [D loss: 0.712436, acc.: 57.03%] [G loss: 0.757030]\n",
      "epoch:3 step:2879 [D loss: 0.697938, acc.: 55.47%] [G loss: 0.751976]\n",
      "epoch:3 step:2880 [D loss: 0.709821, acc.: 47.66%] [G loss: 0.727054]\n",
      "epoch:3 step:2881 [D loss: 0.704699, acc.: 47.66%] [G loss: 0.692593]\n",
      "epoch:3 step:2882 [D loss: 0.709387, acc.: 42.97%] [G loss: 0.718645]\n",
      "epoch:3 step:2883 [D loss: 0.712061, acc.: 43.75%] [G loss: 0.726397]\n",
      "epoch:3 step:2884 [D loss: 0.694056, acc.: 48.44%] [G loss: 0.729960]\n",
      "epoch:3 step:2885 [D loss: 0.668695, acc.: 60.16%] [G loss: 0.717914]\n",
      "epoch:3 step:2886 [D loss: 0.692589, acc.: 51.56%] [G loss: 0.749485]\n",
      "epoch:3 step:2887 [D loss: 0.686178, acc.: 51.56%] [G loss: 0.744919]\n",
      "epoch:3 step:2888 [D loss: 0.678663, acc.: 57.03%] [G loss: 0.770891]\n",
      "epoch:3 step:2889 [D loss: 0.705079, acc.: 49.22%] [G loss: 0.785716]\n",
      "epoch:3 step:2890 [D loss: 0.723666, acc.: 44.53%] [G loss: 0.749101]\n",
      "epoch:3 step:2891 [D loss: 0.716436, acc.: 46.09%] [G loss: 0.701521]\n",
      "epoch:3 step:2892 [D loss: 0.697959, acc.: 50.00%] [G loss: 0.728117]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2893 [D loss: 0.713695, acc.: 42.19%] [G loss: 0.717555]\n",
      "epoch:3 step:2894 [D loss: 0.686177, acc.: 53.91%] [G loss: 0.707996]\n",
      "epoch:3 step:2895 [D loss: 0.696175, acc.: 51.56%] [G loss: 0.754091]\n",
      "epoch:3 step:2896 [D loss: 0.708048, acc.: 45.31%] [G loss: 0.748060]\n",
      "epoch:3 step:2897 [D loss: 0.714070, acc.: 39.06%] [G loss: 0.720424]\n",
      "epoch:3 step:2898 [D loss: 0.683091, acc.: 57.81%] [G loss: 0.764609]\n",
      "epoch:3 step:2899 [D loss: 0.682233, acc.: 54.69%] [G loss: 0.728780]\n",
      "epoch:3 step:2900 [D loss: 0.679685, acc.: 64.84%] [G loss: 0.765044]\n",
      "epoch:3 step:2901 [D loss: 0.686898, acc.: 53.91%] [G loss: 0.745721]\n",
      "epoch:3 step:2902 [D loss: 0.677518, acc.: 58.59%] [G loss: 0.751996]\n",
      "epoch:3 step:2903 [D loss: 0.664829, acc.: 57.03%] [G loss: 0.741669]\n",
      "epoch:3 step:2904 [D loss: 0.650217, acc.: 64.84%] [G loss: 0.766952]\n",
      "epoch:3 step:2905 [D loss: 0.693771, acc.: 50.00%] [G loss: 0.749304]\n",
      "epoch:3 step:2906 [D loss: 0.682717, acc.: 58.59%] [G loss: 0.736563]\n",
      "epoch:3 step:2907 [D loss: 0.698112, acc.: 52.34%] [G loss: 0.799907]\n",
      "epoch:3 step:2908 [D loss: 0.668352, acc.: 62.50%] [G loss: 0.749021]\n",
      "epoch:3 step:2909 [D loss: 0.692355, acc.: 53.12%] [G loss: 0.760386]\n",
      "epoch:3 step:2910 [D loss: 0.661644, acc.: 64.06%] [G loss: 0.746319]\n",
      "epoch:3 step:2911 [D loss: 0.671397, acc.: 60.16%] [G loss: 0.778024]\n",
      "epoch:3 step:2912 [D loss: 0.685828, acc.: 51.56%] [G loss: 0.764361]\n",
      "epoch:3 step:2913 [D loss: 0.716358, acc.: 48.44%] [G loss: 0.745471]\n",
      "epoch:3 step:2914 [D loss: 0.692624, acc.: 55.47%] [G loss: 0.716296]\n",
      "epoch:3 step:2915 [D loss: 0.730555, acc.: 40.62%] [G loss: 0.790590]\n",
      "epoch:3 step:2916 [D loss: 0.727241, acc.: 42.97%] [G loss: 0.725986]\n",
      "epoch:3 step:2917 [D loss: 0.692514, acc.: 50.00%] [G loss: 0.733181]\n",
      "epoch:3 step:2918 [D loss: 0.685814, acc.: 55.47%] [G loss: 0.764089]\n",
      "epoch:3 step:2919 [D loss: 0.698488, acc.: 49.22%] [G loss: 0.748443]\n",
      "epoch:3 step:2920 [D loss: 0.692428, acc.: 57.03%] [G loss: 0.770029]\n",
      "epoch:3 step:2921 [D loss: 0.677271, acc.: 58.59%] [G loss: 0.747268]\n",
      "epoch:3 step:2922 [D loss: 0.701247, acc.: 50.00%] [G loss: 0.737034]\n",
      "epoch:3 step:2923 [D loss: 0.678452, acc.: 57.03%] [G loss: 0.766631]\n",
      "epoch:3 step:2924 [D loss: 0.678133, acc.: 57.81%] [G loss: 0.757377]\n",
      "epoch:3 step:2925 [D loss: 0.663680, acc.: 64.84%] [G loss: 0.796605]\n",
      "epoch:3 step:2926 [D loss: 0.678894, acc.: 60.16%] [G loss: 0.767081]\n",
      "epoch:3 step:2927 [D loss: 0.695137, acc.: 49.22%] [G loss: 0.755991]\n",
      "epoch:3 step:2928 [D loss: 0.671109, acc.: 50.78%] [G loss: 0.763531]\n",
      "epoch:3 step:2929 [D loss: 0.674604, acc.: 53.12%] [G loss: 0.746878]\n",
      "epoch:3 step:2930 [D loss: 0.682595, acc.: 57.03%] [G loss: 0.776414]\n",
      "epoch:3 step:2931 [D loss: 0.731551, acc.: 39.06%] [G loss: 0.733849]\n",
      "epoch:3 step:2932 [D loss: 0.737396, acc.: 41.41%] [G loss: 0.781473]\n",
      "epoch:3 step:2933 [D loss: 0.723736, acc.: 42.97%] [G loss: 0.769809]\n",
      "epoch:3 step:2934 [D loss: 0.700949, acc.: 48.44%] [G loss: 0.780845]\n",
      "epoch:3 step:2935 [D loss: 0.692919, acc.: 48.44%] [G loss: 0.805737]\n",
      "epoch:3 step:2936 [D loss: 0.670444, acc.: 54.69%] [G loss: 0.829244]\n",
      "epoch:3 step:2937 [D loss: 0.634590, acc.: 66.41%] [G loss: 0.833187]\n",
      "epoch:3 step:2938 [D loss: 0.651177, acc.: 65.62%] [G loss: 0.854165]\n",
      "epoch:3 step:2939 [D loss: 0.665775, acc.: 58.59%] [G loss: 0.879384]\n",
      "epoch:3 step:2940 [D loss: 0.712493, acc.: 49.22%] [G loss: 0.883248]\n",
      "epoch:3 step:2941 [D loss: 0.668091, acc.: 57.81%] [G loss: 0.817099]\n",
      "epoch:3 step:2942 [D loss: 0.675198, acc.: 60.16%] [G loss: 0.786681]\n",
      "epoch:3 step:2943 [D loss: 0.696493, acc.: 53.12%] [G loss: 0.729663]\n",
      "epoch:3 step:2944 [D loss: 0.671931, acc.: 57.03%] [G loss: 0.756055]\n",
      "epoch:3 step:2945 [D loss: 0.693994, acc.: 53.91%] [G loss: 0.725377]\n",
      "epoch:3 step:2946 [D loss: 0.692324, acc.: 50.00%] [G loss: 0.701462]\n",
      "epoch:3 step:2947 [D loss: 0.732625, acc.: 42.19%] [G loss: 0.700906]\n",
      "epoch:3 step:2948 [D loss: 0.773230, acc.: 38.28%] [G loss: 0.704762]\n",
      "epoch:3 step:2949 [D loss: 0.733072, acc.: 33.59%] [G loss: 0.684610]\n",
      "epoch:3 step:2950 [D loss: 0.698969, acc.: 43.75%] [G loss: 0.726832]\n",
      "epoch:3 step:2951 [D loss: 0.737731, acc.: 32.81%] [G loss: 0.747939]\n",
      "epoch:3 step:2952 [D loss: 0.726871, acc.: 39.06%] [G loss: 0.760004]\n",
      "epoch:3 step:2953 [D loss: 0.701435, acc.: 47.66%] [G loss: 0.792714]\n",
      "epoch:3 step:2954 [D loss: 0.688578, acc.: 45.31%] [G loss: 0.836037]\n",
      "epoch:3 step:2955 [D loss: 0.647759, acc.: 63.28%] [G loss: 0.839630]\n",
      "epoch:3 step:2956 [D loss: 0.655082, acc.: 64.06%] [G loss: 0.843282]\n",
      "epoch:3 step:2957 [D loss: 0.650565, acc.: 64.06%] [G loss: 0.824773]\n",
      "epoch:3 step:2958 [D loss: 0.690490, acc.: 57.03%] [G loss: 0.848519]\n",
      "epoch:3 step:2959 [D loss: 0.650585, acc.: 67.19%] [G loss: 0.789190]\n",
      "epoch:3 step:2960 [D loss: 0.704432, acc.: 53.91%] [G loss: 0.777197]\n",
      "epoch:3 step:2961 [D loss: 0.697032, acc.: 51.56%] [G loss: 0.764914]\n",
      "epoch:3 step:2962 [D loss: 0.705752, acc.: 52.34%] [G loss: 0.719655]\n",
      "epoch:3 step:2963 [D loss: 0.686457, acc.: 57.81%] [G loss: 0.723026]\n",
      "epoch:3 step:2964 [D loss: 0.721950, acc.: 47.66%] [G loss: 0.731455]\n",
      "epoch:3 step:2965 [D loss: 0.697845, acc.: 54.69%] [G loss: 0.717733]\n",
      "epoch:3 step:2966 [D loss: 0.716291, acc.: 43.75%] [G loss: 0.691901]\n",
      "epoch:3 step:2967 [D loss: 0.692986, acc.: 51.56%] [G loss: 0.710955]\n",
      "epoch:3 step:2968 [D loss: 0.707856, acc.: 47.66%] [G loss: 0.721756]\n",
      "epoch:3 step:2969 [D loss: 0.699355, acc.: 50.78%] [G loss: 0.738629]\n",
      "epoch:3 step:2970 [D loss: 0.698090, acc.: 53.91%] [G loss: 0.737423]\n",
      "epoch:3 step:2971 [D loss: 0.713525, acc.: 46.09%] [G loss: 0.733278]\n",
      "epoch:3 step:2972 [D loss: 0.697895, acc.: 49.22%] [G loss: 0.775242]\n",
      "epoch:3 step:2973 [D loss: 0.688495, acc.: 53.12%] [G loss: 0.788518]\n",
      "epoch:3 step:2974 [D loss: 0.685228, acc.: 53.12%] [G loss: 0.777954]\n",
      "epoch:3 step:2975 [D loss: 0.674172, acc.: 56.25%] [G loss: 0.742565]\n",
      "epoch:3 step:2976 [D loss: 0.692421, acc.: 50.78%] [G loss: 0.734175]\n",
      "epoch:3 step:2977 [D loss: 0.698201, acc.: 50.78%] [G loss: 0.720988]\n",
      "epoch:3 step:2978 [D loss: 0.719228, acc.: 42.19%] [G loss: 0.727856]\n",
      "epoch:3 step:2979 [D loss: 0.716308, acc.: 47.66%] [G loss: 0.702572]\n",
      "epoch:3 step:2980 [D loss: 0.710885, acc.: 45.31%] [G loss: 0.707518]\n",
      "epoch:3 step:2981 [D loss: 0.693751, acc.: 52.34%] [G loss: 0.720315]\n",
      "epoch:3 step:2982 [D loss: 0.695376, acc.: 57.03%] [G loss: 0.714209]\n",
      "epoch:3 step:2983 [D loss: 0.702442, acc.: 45.31%] [G loss: 0.738093]\n",
      "epoch:3 step:2984 [D loss: 0.701499, acc.: 43.75%] [G loss: 0.732143]\n",
      "epoch:3 step:2985 [D loss: 0.719388, acc.: 43.75%] [G loss: 0.701452]\n",
      "epoch:3 step:2986 [D loss: 0.720442, acc.: 44.53%] [G loss: 0.722930]\n",
      "epoch:3 step:2987 [D loss: 0.679393, acc.: 55.47%] [G loss: 0.705094]\n",
      "epoch:3 step:2988 [D loss: 0.715585, acc.: 37.50%] [G loss: 0.718684]\n",
      "epoch:3 step:2989 [D loss: 0.694902, acc.: 50.00%] [G loss: 0.720177]\n",
      "epoch:3 step:2990 [D loss: 0.692772, acc.: 54.69%] [G loss: 0.718156]\n",
      "epoch:3 step:2991 [D loss: 0.710521, acc.: 45.31%] [G loss: 0.743351]\n",
      "epoch:3 step:2992 [D loss: 0.685068, acc.: 60.94%] [G loss: 0.754176]\n",
      "epoch:3 step:2993 [D loss: 0.690879, acc.: 46.88%] [G loss: 0.740442]\n",
      "epoch:3 step:2994 [D loss: 0.690337, acc.: 45.31%] [G loss: 0.751585]\n",
      "epoch:3 step:2995 [D loss: 0.652643, acc.: 62.50%] [G loss: 0.742630]\n",
      "epoch:3 step:2996 [D loss: 0.693934, acc.: 46.88%] [G loss: 0.731573]\n",
      "epoch:3 step:2997 [D loss: 0.693359, acc.: 52.34%] [G loss: 0.756814]\n",
      "epoch:3 step:2998 [D loss: 0.682282, acc.: 50.78%] [G loss: 0.743662]\n",
      "epoch:3 step:2999 [D loss: 0.707532, acc.: 50.00%] [G loss: 0.728671]\n",
      "epoch:3 step:3000 [D loss: 0.698362, acc.: 46.09%] [G loss: 0.715839]\n",
      "##############\n",
      "[3.72623489 2.81827298 6.77977766 5.57676797 4.35879757 6.24112436\n",
      " 5.52660935 5.57960868 5.60521049 5.00930318]\n",
      "##########\n",
      "epoch:3 step:3001 [D loss: 0.683008, acc.: 53.12%] [G loss: 0.714007]\n",
      "epoch:3 step:3002 [D loss: 0.692144, acc.: 50.78%] [G loss: 0.721119]\n",
      "epoch:3 step:3003 [D loss: 0.681527, acc.: 55.47%] [G loss: 0.726471]\n",
      "epoch:3 step:3004 [D loss: 0.706080, acc.: 55.47%] [G loss: 0.713165]\n",
      "epoch:3 step:3005 [D loss: 0.699492, acc.: 50.00%] [G loss: 0.752658]\n",
      "epoch:3 step:3006 [D loss: 0.685042, acc.: 55.47%] [G loss: 0.737340]\n",
      "epoch:3 step:3007 [D loss: 0.681093, acc.: 55.47%] [G loss: 0.763123]\n",
      "epoch:3 step:3008 [D loss: 0.671427, acc.: 57.03%] [G loss: 0.749776]\n",
      "epoch:3 step:3009 [D loss: 0.671861, acc.: 63.28%] [G loss: 0.766454]\n",
      "epoch:3 step:3010 [D loss: 0.690565, acc.: 54.69%] [G loss: 0.776214]\n",
      "epoch:3 step:3011 [D loss: 0.700595, acc.: 51.56%] [G loss: 0.796191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3012 [D loss: 0.687769, acc.: 52.34%] [G loss: 0.791301]\n",
      "epoch:3 step:3013 [D loss: 0.682615, acc.: 61.72%] [G loss: 0.761776]\n",
      "epoch:3 step:3014 [D loss: 0.683779, acc.: 57.81%] [G loss: 0.753629]\n",
      "epoch:3 step:3015 [D loss: 0.691460, acc.: 57.03%] [G loss: 0.783997]\n",
      "epoch:3 step:3016 [D loss: 0.668120, acc.: 67.19%] [G loss: 0.788225]\n",
      "epoch:3 step:3017 [D loss: 0.663860, acc.: 59.38%] [G loss: 0.769636]\n",
      "epoch:3 step:3018 [D loss: 0.732810, acc.: 48.44%] [G loss: 0.767655]\n",
      "epoch:3 step:3019 [D loss: 0.676463, acc.: 49.22%] [G loss: 0.743495]\n",
      "epoch:3 step:3020 [D loss: 0.704080, acc.: 56.25%] [G loss: 0.735475]\n",
      "epoch:3 step:3021 [D loss: 0.691609, acc.: 53.12%] [G loss: 0.749279]\n",
      "epoch:3 step:3022 [D loss: 0.707902, acc.: 44.53%] [G loss: 0.760804]\n",
      "epoch:3 step:3023 [D loss: 0.675527, acc.: 60.94%] [G loss: 0.752899]\n",
      "epoch:3 step:3024 [D loss: 0.686011, acc.: 48.44%] [G loss: 0.763238]\n",
      "epoch:3 step:3025 [D loss: 0.747306, acc.: 37.50%] [G loss: 0.745882]\n",
      "epoch:3 step:3026 [D loss: 0.746261, acc.: 34.38%] [G loss: 0.749104]\n",
      "epoch:3 step:3027 [D loss: 0.701494, acc.: 50.00%] [G loss: 0.745348]\n",
      "epoch:3 step:3028 [D loss: 0.693082, acc.: 52.34%] [G loss: 0.727590]\n",
      "epoch:3 step:3029 [D loss: 0.673774, acc.: 57.03%] [G loss: 0.732073]\n",
      "epoch:3 step:3030 [D loss: 0.661587, acc.: 58.59%] [G loss: 0.774164]\n",
      "epoch:3 step:3031 [D loss: 0.732568, acc.: 35.16%] [G loss: 0.755597]\n",
      "epoch:3 step:3032 [D loss: 0.706298, acc.: 48.44%] [G loss: 0.747730]\n",
      "epoch:3 step:3033 [D loss: 0.666232, acc.: 58.59%] [G loss: 0.773442]\n",
      "epoch:3 step:3034 [D loss: 0.671278, acc.: 60.16%] [G loss: 0.767024]\n",
      "epoch:3 step:3035 [D loss: 0.670800, acc.: 57.03%] [G loss: 0.768678]\n",
      "epoch:3 step:3036 [D loss: 0.692549, acc.: 50.78%] [G loss: 0.747709]\n",
      "epoch:3 step:3037 [D loss: 0.697142, acc.: 49.22%] [G loss: 0.717928]\n",
      "epoch:3 step:3038 [D loss: 0.686849, acc.: 51.56%] [G loss: 0.739080]\n",
      "epoch:3 step:3039 [D loss: 0.697021, acc.: 46.88%] [G loss: 0.719140]\n",
      "epoch:3 step:3040 [D loss: 0.698269, acc.: 51.56%] [G loss: 0.714580]\n",
      "epoch:3 step:3041 [D loss: 0.670120, acc.: 59.38%] [G loss: 0.760513]\n",
      "epoch:3 step:3042 [D loss: 0.661868, acc.: 60.16%] [G loss: 0.742204]\n",
      "epoch:3 step:3043 [D loss: 0.647036, acc.: 64.84%] [G loss: 0.769538]\n",
      "epoch:3 step:3044 [D loss: 0.735364, acc.: 35.16%] [G loss: 0.742193]\n",
      "epoch:3 step:3045 [D loss: 0.720030, acc.: 39.84%] [G loss: 0.742689]\n",
      "epoch:3 step:3046 [D loss: 0.691943, acc.: 47.66%] [G loss: 0.774183]\n",
      "epoch:3 step:3047 [D loss: 0.715267, acc.: 42.19%] [G loss: 0.748763]\n",
      "epoch:3 step:3048 [D loss: 0.679103, acc.: 52.34%] [G loss: 0.758448]\n",
      "epoch:3 step:3049 [D loss: 0.712663, acc.: 46.88%] [G loss: 0.808184]\n",
      "epoch:3 step:3050 [D loss: 0.692064, acc.: 47.66%] [G loss: 0.769928]\n",
      "epoch:3 step:3051 [D loss: 0.708103, acc.: 42.19%] [G loss: 0.750161]\n",
      "epoch:3 step:3052 [D loss: 0.695561, acc.: 58.59%] [G loss: 0.782617]\n",
      "epoch:3 step:3053 [D loss: 0.686443, acc.: 56.25%] [G loss: 0.815772]\n",
      "epoch:3 step:3054 [D loss: 0.701976, acc.: 46.88%] [G loss: 0.743221]\n",
      "epoch:3 step:3055 [D loss: 0.697018, acc.: 49.22%] [G loss: 0.736021]\n",
      "epoch:3 step:3056 [D loss: 0.691094, acc.: 50.78%] [G loss: 0.768023]\n",
      "epoch:3 step:3057 [D loss: 0.689471, acc.: 53.91%] [G loss: 0.739259]\n",
      "epoch:3 step:3058 [D loss: 0.698020, acc.: 49.22%] [G loss: 0.748252]\n",
      "epoch:3 step:3059 [D loss: 0.666208, acc.: 57.81%] [G loss: 0.720762]\n",
      "epoch:3 step:3060 [D loss: 0.685262, acc.: 48.44%] [G loss: 0.746505]\n",
      "epoch:3 step:3061 [D loss: 0.700282, acc.: 48.44%] [G loss: 0.731086]\n",
      "epoch:3 step:3062 [D loss: 0.704310, acc.: 50.00%] [G loss: 0.733770]\n",
      "epoch:3 step:3063 [D loss: 0.700584, acc.: 50.00%] [G loss: 0.725119]\n",
      "epoch:3 step:3064 [D loss: 0.701427, acc.: 50.00%] [G loss: 0.733334]\n",
      "epoch:3 step:3065 [D loss: 0.700373, acc.: 49.22%] [G loss: 0.718803]\n",
      "epoch:3 step:3066 [D loss: 0.699674, acc.: 48.44%] [G loss: 0.741855]\n",
      "epoch:3 step:3067 [D loss: 0.710523, acc.: 49.22%] [G loss: 0.743114]\n",
      "epoch:3 step:3068 [D loss: 0.690194, acc.: 55.47%] [G loss: 0.719070]\n",
      "epoch:3 step:3069 [D loss: 0.713302, acc.: 44.53%] [G loss: 0.714145]\n",
      "epoch:3 step:3070 [D loss: 0.705566, acc.: 51.56%] [G loss: 0.724640]\n",
      "epoch:3 step:3071 [D loss: 0.704422, acc.: 49.22%] [G loss: 0.709938]\n",
      "epoch:3 step:3072 [D loss: 0.698531, acc.: 51.56%] [G loss: 0.751309]\n",
      "epoch:3 step:3073 [D loss: 0.691599, acc.: 53.12%] [G loss: 0.734262]\n",
      "epoch:3 step:3074 [D loss: 0.707816, acc.: 50.00%] [G loss: 0.751703]\n",
      "epoch:3 step:3075 [D loss: 0.700955, acc.: 49.22%] [G loss: 0.721880]\n",
      "epoch:3 step:3076 [D loss: 0.702201, acc.: 46.09%] [G loss: 0.784855]\n",
      "epoch:3 step:3077 [D loss: 0.714728, acc.: 44.53%] [G loss: 0.761297]\n",
      "epoch:3 step:3078 [D loss: 0.702460, acc.: 45.31%] [G loss: 0.736828]\n",
      "epoch:3 step:3079 [D loss: 0.693738, acc.: 48.44%] [G loss: 0.716365]\n",
      "epoch:3 step:3080 [D loss: 0.706519, acc.: 49.22%] [G loss: 0.737106]\n",
      "epoch:3 step:3081 [D loss: 0.698455, acc.: 46.09%] [G loss: 0.705773]\n",
      "epoch:3 step:3082 [D loss: 0.703280, acc.: 51.56%] [G loss: 0.736697]\n",
      "epoch:3 step:3083 [D loss: 0.694862, acc.: 46.09%] [G loss: 0.741609]\n",
      "epoch:3 step:3084 [D loss: 0.709902, acc.: 38.28%] [G loss: 0.735895]\n",
      "epoch:3 step:3085 [D loss: 0.669345, acc.: 62.50%] [G loss: 0.741367]\n",
      "epoch:3 step:3086 [D loss: 0.683815, acc.: 50.78%] [G loss: 0.725012]\n",
      "epoch:3 step:3087 [D loss: 0.685742, acc.: 57.81%] [G loss: 0.748024]\n",
      "epoch:3 step:3088 [D loss: 0.678974, acc.: 63.28%] [G loss: 0.758997]\n",
      "epoch:3 step:3089 [D loss: 0.691522, acc.: 49.22%] [G loss: 0.737707]\n",
      "epoch:3 step:3090 [D loss: 0.690040, acc.: 54.69%] [G loss: 0.735346]\n",
      "epoch:3 step:3091 [D loss: 0.680187, acc.: 59.38%] [G loss: 0.740087]\n",
      "epoch:3 step:3092 [D loss: 0.699737, acc.: 49.22%] [G loss: 0.751332]\n",
      "epoch:3 step:3093 [D loss: 0.691565, acc.: 59.38%] [G loss: 0.753673]\n",
      "epoch:3 step:3094 [D loss: 0.682600, acc.: 57.81%] [G loss: 0.773723]\n",
      "epoch:3 step:3095 [D loss: 0.659723, acc.: 67.97%] [G loss: 0.719934]\n",
      "epoch:3 step:3096 [D loss: 0.658460, acc.: 63.28%] [G loss: 0.768142]\n",
      "epoch:3 step:3097 [D loss: 0.667058, acc.: 60.16%] [G loss: 0.735806]\n",
      "epoch:3 step:3098 [D loss: 0.713819, acc.: 46.09%] [G loss: 0.732807]\n",
      "epoch:3 step:3099 [D loss: 0.712926, acc.: 44.53%] [G loss: 0.740038]\n",
      "epoch:3 step:3100 [D loss: 0.678542, acc.: 56.25%] [G loss: 0.732808]\n",
      "epoch:3 step:3101 [D loss: 0.691029, acc.: 53.12%] [G loss: 0.710276]\n",
      "epoch:3 step:3102 [D loss: 0.747344, acc.: 42.97%] [G loss: 0.740874]\n",
      "epoch:3 step:3103 [D loss: 0.690167, acc.: 51.56%] [G loss: 0.742457]\n",
      "epoch:3 step:3104 [D loss: 0.693231, acc.: 54.69%] [G loss: 0.697372]\n",
      "epoch:3 step:3105 [D loss: 0.705703, acc.: 49.22%] [G loss: 0.710451]\n",
      "epoch:3 step:3106 [D loss: 0.716388, acc.: 42.19%] [G loss: 0.728261]\n",
      "epoch:3 step:3107 [D loss: 0.699800, acc.: 49.22%] [G loss: 0.743228]\n",
      "epoch:3 step:3108 [D loss: 0.710411, acc.: 45.31%] [G loss: 0.750010]\n",
      "epoch:3 step:3109 [D loss: 0.714399, acc.: 43.75%] [G loss: 0.742759]\n",
      "epoch:3 step:3110 [D loss: 0.691793, acc.: 57.03%] [G loss: 0.747250]\n",
      "epoch:3 step:3111 [D loss: 0.678425, acc.: 56.25%] [G loss: 0.751954]\n",
      "epoch:3 step:3112 [D loss: 0.714048, acc.: 47.66%] [G loss: 0.766426]\n",
      "epoch:3 step:3113 [D loss: 0.691341, acc.: 50.78%] [G loss: 0.784452]\n",
      "epoch:3 step:3114 [D loss: 0.687801, acc.: 50.00%] [G loss: 0.769601]\n",
      "epoch:3 step:3115 [D loss: 0.703277, acc.: 48.44%] [G loss: 0.719611]\n",
      "epoch:3 step:3116 [D loss: 0.703291, acc.: 53.12%] [G loss: 0.726958]\n",
      "epoch:3 step:3117 [D loss: 0.712663, acc.: 46.88%] [G loss: 0.724564]\n",
      "epoch:3 step:3118 [D loss: 0.700981, acc.: 46.09%] [G loss: 0.728937]\n",
      "epoch:3 step:3119 [D loss: 0.694564, acc.: 51.56%] [G loss: 0.729196]\n",
      "epoch:3 step:3120 [D loss: 0.690367, acc.: 50.78%] [G loss: 0.733689]\n",
      "epoch:3 step:3121 [D loss: 0.673503, acc.: 57.03%] [G loss: 0.763165]\n",
      "epoch:3 step:3122 [D loss: 0.689174, acc.: 53.91%] [G loss: 0.752906]\n",
      "epoch:3 step:3123 [D loss: 0.679152, acc.: 57.81%] [G loss: 0.734009]\n",
      "epoch:3 step:3124 [D loss: 0.672580, acc.: 55.47%] [G loss: 0.737697]\n",
      "epoch:3 step:3125 [D loss: 0.679870, acc.: 58.59%] [G loss: 0.727461]\n",
      "epoch:3 step:3126 [D loss: 0.671233, acc.: 60.94%] [G loss: 0.744491]\n",
      "epoch:3 step:3127 [D loss: 0.714609, acc.: 48.44%] [G loss: 0.746211]\n",
      "epoch:3 step:3128 [D loss: 0.698174, acc.: 53.91%] [G loss: 0.762846]\n",
      "epoch:3 step:3129 [D loss: 0.688908, acc.: 47.66%] [G loss: 0.737731]\n",
      "epoch:3 step:3130 [D loss: 0.677322, acc.: 55.47%] [G loss: 0.730484]\n",
      "epoch:3 step:3131 [D loss: 0.712355, acc.: 39.84%] [G loss: 0.725700]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3132 [D loss: 0.725320, acc.: 46.88%] [G loss: 0.726717]\n",
      "epoch:3 step:3133 [D loss: 0.685011, acc.: 54.69%] [G loss: 0.714736]\n",
      "epoch:3 step:3134 [D loss: 0.695856, acc.: 50.78%] [G loss: 0.751827]\n",
      "epoch:3 step:3135 [D loss: 0.678851, acc.: 57.81%] [G loss: 0.751311]\n",
      "epoch:3 step:3136 [D loss: 0.691210, acc.: 50.78%] [G loss: 0.771069]\n",
      "epoch:3 step:3137 [D loss: 0.688269, acc.: 53.12%] [G loss: 0.755133]\n",
      "epoch:3 step:3138 [D loss: 0.670906, acc.: 64.84%] [G loss: 0.757558]\n",
      "epoch:3 step:3139 [D loss: 0.682384, acc.: 57.03%] [G loss: 0.724365]\n",
      "epoch:3 step:3140 [D loss: 0.691916, acc.: 55.47%] [G loss: 0.780149]\n",
      "epoch:3 step:3141 [D loss: 0.693690, acc.: 47.66%] [G loss: 0.745045]\n",
      "epoch:3 step:3142 [D loss: 0.694838, acc.: 46.88%] [G loss: 0.762960]\n",
      "epoch:3 step:3143 [D loss: 0.683592, acc.: 52.34%] [G loss: 0.736202]\n",
      "epoch:3 step:3144 [D loss: 0.702077, acc.: 50.00%] [G loss: 0.745265]\n",
      "epoch:3 step:3145 [D loss: 0.705086, acc.: 51.56%] [G loss: 0.693073]\n",
      "epoch:3 step:3146 [D loss: 0.715041, acc.: 50.78%] [G loss: 0.768473]\n",
      "epoch:3 step:3147 [D loss: 0.695627, acc.: 54.69%] [G loss: 0.747008]\n",
      "epoch:3 step:3148 [D loss: 0.699284, acc.: 53.12%] [G loss: 0.706056]\n",
      "epoch:3 step:3149 [D loss: 0.682786, acc.: 54.69%] [G loss: 0.723206]\n",
      "epoch:3 step:3150 [D loss: 0.674515, acc.: 60.16%] [G loss: 0.734677]\n",
      "epoch:3 step:3151 [D loss: 0.706071, acc.: 47.66%] [G loss: 0.738510]\n",
      "epoch:3 step:3152 [D loss: 0.710928, acc.: 45.31%] [G loss: 0.752049]\n",
      "epoch:3 step:3153 [D loss: 0.691112, acc.: 50.00%] [G loss: 0.746757]\n",
      "epoch:3 step:3154 [D loss: 0.686613, acc.: 55.47%] [G loss: 0.769676]\n",
      "epoch:3 step:3155 [D loss: 0.659090, acc.: 60.16%] [G loss: 0.764711]\n",
      "epoch:3 step:3156 [D loss: 0.689197, acc.: 56.25%] [G loss: 0.804821]\n",
      "epoch:3 step:3157 [D loss: 0.686753, acc.: 57.03%] [G loss: 0.763949]\n",
      "epoch:3 step:3158 [D loss: 0.680817, acc.: 60.94%] [G loss: 0.752502]\n",
      "epoch:3 step:3159 [D loss: 0.686534, acc.: 58.59%] [G loss: 0.769477]\n",
      "epoch:3 step:3160 [D loss: 0.703821, acc.: 53.12%] [G loss: 0.768935]\n",
      "epoch:3 step:3161 [D loss: 0.706891, acc.: 55.47%] [G loss: 0.757717]\n",
      "epoch:3 step:3162 [D loss: 0.721237, acc.: 41.41%] [G loss: 0.732551]\n",
      "epoch:3 step:3163 [D loss: 0.701927, acc.: 44.53%] [G loss: 0.732381]\n",
      "epoch:3 step:3164 [D loss: 0.711277, acc.: 46.88%] [G loss: 0.742945]\n",
      "epoch:3 step:3165 [D loss: 0.711283, acc.: 44.53%] [G loss: 0.745333]\n",
      "epoch:3 step:3166 [D loss: 0.712514, acc.: 48.44%] [G loss: 0.735741]\n",
      "epoch:3 step:3167 [D loss: 0.678530, acc.: 55.47%] [G loss: 0.763287]\n",
      "epoch:3 step:3168 [D loss: 0.690905, acc.: 51.56%] [G loss: 0.724520]\n",
      "epoch:3 step:3169 [D loss: 0.692704, acc.: 52.34%] [G loss: 0.744106]\n",
      "epoch:3 step:3170 [D loss: 0.693332, acc.: 45.31%] [G loss: 0.726097]\n",
      "epoch:3 step:3171 [D loss: 0.688751, acc.: 49.22%] [G loss: 0.777125]\n",
      "epoch:3 step:3172 [D loss: 0.683401, acc.: 56.25%] [G loss: 0.749418]\n",
      "epoch:3 step:3173 [D loss: 0.683888, acc.: 55.47%] [G loss: 0.754293]\n",
      "epoch:3 step:3174 [D loss: 0.715876, acc.: 44.53%] [G loss: 0.749220]\n",
      "epoch:3 step:3175 [D loss: 0.691677, acc.: 51.56%] [G loss: 0.715472]\n",
      "epoch:3 step:3176 [D loss: 0.702657, acc.: 50.00%] [G loss: 0.719096]\n",
      "epoch:3 step:3177 [D loss: 0.702622, acc.: 50.78%] [G loss: 0.726862]\n",
      "epoch:3 step:3178 [D loss: 0.697048, acc.: 50.00%] [G loss: 0.753879]\n",
      "epoch:3 step:3179 [D loss: 0.708353, acc.: 43.75%] [G loss: 0.759555]\n",
      "epoch:3 step:3180 [D loss: 0.691905, acc.: 53.91%] [G loss: 0.724650]\n",
      "epoch:3 step:3181 [D loss: 0.676147, acc.: 60.16%] [G loss: 0.745480]\n",
      "epoch:3 step:3182 [D loss: 0.694855, acc.: 54.69%] [G loss: 0.741777]\n",
      "epoch:3 step:3183 [D loss: 0.679110, acc.: 61.72%] [G loss: 0.749161]\n",
      "epoch:3 step:3184 [D loss: 0.691088, acc.: 53.91%] [G loss: 0.775758]\n",
      "epoch:3 step:3185 [D loss: 0.677898, acc.: 54.69%] [G loss: 0.761312]\n",
      "epoch:3 step:3186 [D loss: 0.673834, acc.: 53.12%] [G loss: 0.738123]\n",
      "epoch:3 step:3187 [D loss: 0.708938, acc.: 57.81%] [G loss: 0.716552]\n",
      "epoch:3 step:3188 [D loss: 0.694602, acc.: 45.31%] [G loss: 0.750808]\n",
      "epoch:3 step:3189 [D loss: 0.681615, acc.: 53.91%] [G loss: 0.731905]\n",
      "epoch:3 step:3190 [D loss: 0.697986, acc.: 55.47%] [G loss: 0.714529]\n",
      "epoch:3 step:3191 [D loss: 0.690414, acc.: 53.12%] [G loss: 0.732070]\n",
      "epoch:3 step:3192 [D loss: 0.694135, acc.: 54.69%] [G loss: 0.741704]\n",
      "epoch:3 step:3193 [D loss: 0.715893, acc.: 50.00%] [G loss: 0.718111]\n",
      "epoch:3 step:3194 [D loss: 0.706260, acc.: 46.09%] [G loss: 0.707732]\n",
      "epoch:3 step:3195 [D loss: 0.719186, acc.: 40.62%] [G loss: 0.745853]\n",
      "epoch:3 step:3196 [D loss: 0.683059, acc.: 47.66%] [G loss: 0.719960]\n",
      "epoch:3 step:3197 [D loss: 0.686545, acc.: 57.81%] [G loss: 0.715941]\n",
      "epoch:3 step:3198 [D loss: 0.678323, acc.: 63.28%] [G loss: 0.733881]\n",
      "epoch:3 step:3199 [D loss: 0.669778, acc.: 64.06%] [G loss: 0.753928]\n",
      "epoch:3 step:3200 [D loss: 0.685619, acc.: 57.81%] [G loss: 0.743389]\n",
      "##############\n",
      "[3.52862306 2.47855639 6.37998849 5.39349308 4.23249378 5.88685011\n",
      " 5.12129548 5.40559256 5.49811994 4.83713633]\n",
      "##########\n",
      "epoch:3 step:3201 [D loss: 0.698966, acc.: 53.91%] [G loss: 0.737864]\n",
      "epoch:3 step:3202 [D loss: 0.705482, acc.: 46.09%] [G loss: 0.717125]\n",
      "epoch:3 step:3203 [D loss: 0.707094, acc.: 46.09%] [G loss: 0.699746]\n",
      "epoch:3 step:3204 [D loss: 0.704712, acc.: 44.53%] [G loss: 0.709026]\n",
      "epoch:3 step:3205 [D loss: 0.694117, acc.: 47.66%] [G loss: 0.727664]\n",
      "epoch:3 step:3206 [D loss: 0.719337, acc.: 42.19%] [G loss: 0.726051]\n",
      "epoch:3 step:3207 [D loss: 0.690889, acc.: 50.78%] [G loss: 0.721591]\n",
      "epoch:3 step:3208 [D loss: 0.685946, acc.: 50.78%] [G loss: 0.714108]\n",
      "epoch:3 step:3209 [D loss: 0.676633, acc.: 56.25%] [G loss: 0.742006]\n",
      "epoch:3 step:3210 [D loss: 0.678406, acc.: 55.47%] [G loss: 0.732045]\n",
      "epoch:3 step:3211 [D loss: 0.722716, acc.: 43.75%] [G loss: 0.708284]\n",
      "epoch:3 step:3212 [D loss: 0.711910, acc.: 45.31%] [G loss: 0.735739]\n",
      "epoch:3 step:3213 [D loss: 0.682912, acc.: 58.59%] [G loss: 0.788276]\n",
      "epoch:3 step:3214 [D loss: 0.692919, acc.: 53.91%] [G loss: 0.714337]\n",
      "epoch:3 step:3215 [D loss: 0.690893, acc.: 52.34%] [G loss: 0.749153]\n",
      "epoch:3 step:3216 [D loss: 0.691937, acc.: 53.91%] [G loss: 0.792657]\n",
      "epoch:3 step:3217 [D loss: 0.695734, acc.: 53.12%] [G loss: 0.776204]\n",
      "epoch:3 step:3218 [D loss: 0.690435, acc.: 48.44%] [G loss: 0.758189]\n",
      "epoch:3 step:3219 [D loss: 0.680775, acc.: 58.59%] [G loss: 0.753153]\n",
      "epoch:3 step:3220 [D loss: 0.679603, acc.: 55.47%] [G loss: 0.761185]\n",
      "epoch:3 step:3221 [D loss: 0.702203, acc.: 53.12%] [G loss: 0.772501]\n",
      "epoch:3 step:3222 [D loss: 0.717219, acc.: 43.75%] [G loss: 0.748057]\n",
      "epoch:3 step:3223 [D loss: 0.701231, acc.: 48.44%] [G loss: 0.720960]\n",
      "epoch:3 step:3224 [D loss: 0.685393, acc.: 57.03%] [G loss: 0.729598]\n",
      "epoch:3 step:3225 [D loss: 0.682767, acc.: 60.94%] [G loss: 0.767774]\n",
      "epoch:3 step:3226 [D loss: 0.661622, acc.: 64.06%] [G loss: 0.738201]\n",
      "epoch:3 step:3227 [D loss: 0.662102, acc.: 61.72%] [G loss: 0.709479]\n",
      "epoch:3 step:3228 [D loss: 0.715040, acc.: 48.44%] [G loss: 0.741307]\n",
      "epoch:3 step:3229 [D loss: 0.710276, acc.: 47.66%] [G loss: 0.736872]\n",
      "epoch:3 step:3230 [D loss: 0.711094, acc.: 50.78%] [G loss: 0.734084]\n",
      "epoch:3 step:3231 [D loss: 0.701971, acc.: 47.66%] [G loss: 0.728007]\n",
      "epoch:3 step:3232 [D loss: 0.713379, acc.: 42.97%] [G loss: 0.764003]\n",
      "epoch:3 step:3233 [D loss: 0.703798, acc.: 56.25%] [G loss: 0.757166]\n",
      "epoch:3 step:3234 [D loss: 0.704429, acc.: 46.88%] [G loss: 0.748287]\n",
      "epoch:3 step:3235 [D loss: 0.679593, acc.: 55.47%] [G loss: 0.749127]\n",
      "epoch:3 step:3236 [D loss: 0.686375, acc.: 50.78%] [G loss: 0.733951]\n",
      "epoch:3 step:3237 [D loss: 0.672722, acc.: 59.38%] [G loss: 0.742534]\n",
      "epoch:3 step:3238 [D loss: 0.688333, acc.: 52.34%] [G loss: 0.752626]\n",
      "epoch:3 step:3239 [D loss: 0.673678, acc.: 54.69%] [G loss: 0.770844]\n",
      "epoch:3 step:3240 [D loss: 0.674515, acc.: 54.69%] [G loss: 0.741121]\n",
      "epoch:3 step:3241 [D loss: 0.687402, acc.: 57.03%] [G loss: 0.803014]\n",
      "epoch:3 step:3242 [D loss: 0.700930, acc.: 54.69%] [G loss: 0.797756]\n",
      "epoch:3 step:3243 [D loss: 0.727426, acc.: 34.38%] [G loss: 0.731191]\n",
      "epoch:3 step:3244 [D loss: 0.723057, acc.: 45.31%] [G loss: 0.731029]\n",
      "epoch:3 step:3245 [D loss: 0.705420, acc.: 46.88%] [G loss: 0.758121]\n",
      "epoch:3 step:3246 [D loss: 0.703095, acc.: 46.88%] [G loss: 0.701460]\n",
      "epoch:3 step:3247 [D loss: 0.686889, acc.: 53.12%] [G loss: 0.735211]\n",
      "epoch:3 step:3248 [D loss: 0.685301, acc.: 56.25%] [G loss: 0.753810]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3249 [D loss: 0.681511, acc.: 54.69%] [G loss: 0.720885]\n",
      "epoch:3 step:3250 [D loss: 0.698632, acc.: 46.88%] [G loss: 0.726637]\n",
      "epoch:3 step:3251 [D loss: 0.675949, acc.: 60.16%] [G loss: 0.732268]\n",
      "epoch:3 step:3252 [D loss: 0.692589, acc.: 47.66%] [G loss: 0.764093]\n",
      "epoch:3 step:3253 [D loss: 0.699894, acc.: 50.00%] [G loss: 0.741798]\n",
      "epoch:3 step:3254 [D loss: 0.703845, acc.: 51.56%] [G loss: 0.761753]\n",
      "epoch:3 step:3255 [D loss: 0.690562, acc.: 57.81%] [G loss: 0.750182]\n",
      "epoch:3 step:3256 [D loss: 0.708089, acc.: 46.88%] [G loss: 0.727520]\n",
      "epoch:3 step:3257 [D loss: 0.696430, acc.: 48.44%] [G loss: 0.726875]\n",
      "epoch:3 step:3258 [D loss: 0.684340, acc.: 56.25%] [G loss: 0.741892]\n",
      "epoch:3 step:3259 [D loss: 0.712844, acc.: 41.41%] [G loss: 0.718106]\n",
      "epoch:3 step:3260 [D loss: 0.689057, acc.: 53.91%] [G loss: 0.760604]\n",
      "epoch:3 step:3261 [D loss: 0.687981, acc.: 54.69%] [G loss: 0.772636]\n",
      "epoch:3 step:3262 [D loss: 0.679600, acc.: 52.34%] [G loss: 0.748026]\n",
      "epoch:3 step:3263 [D loss: 0.672548, acc.: 56.25%] [G loss: 0.777874]\n",
      "epoch:3 step:3264 [D loss: 0.687107, acc.: 56.25%] [G loss: 0.748300]\n",
      "epoch:3 step:3265 [D loss: 0.646904, acc.: 69.53%] [G loss: 0.751686]\n",
      "epoch:3 step:3266 [D loss: 0.679190, acc.: 56.25%] [G loss: 0.750277]\n",
      "epoch:3 step:3267 [D loss: 0.670531, acc.: 56.25%] [G loss: 0.720162]\n",
      "epoch:3 step:3268 [D loss: 0.669119, acc.: 57.81%] [G loss: 0.724639]\n",
      "epoch:3 step:3269 [D loss: 0.735064, acc.: 45.31%] [G loss: 0.718755]\n",
      "epoch:3 step:3270 [D loss: 0.698523, acc.: 51.56%] [G loss: 0.745921]\n",
      "epoch:3 step:3271 [D loss: 0.686990, acc.: 53.12%] [G loss: 0.733295]\n",
      "epoch:3 step:3272 [D loss: 0.693806, acc.: 49.22%] [G loss: 0.726426]\n",
      "epoch:3 step:3273 [D loss: 0.701894, acc.: 49.22%] [G loss: 0.749871]\n",
      "epoch:3 step:3274 [D loss: 0.687629, acc.: 52.34%] [G loss: 0.735086]\n",
      "epoch:3 step:3275 [D loss: 0.696108, acc.: 53.91%] [G loss: 0.752838]\n",
      "epoch:3 step:3276 [D loss: 0.689548, acc.: 54.69%] [G loss: 0.749417]\n",
      "epoch:3 step:3277 [D loss: 0.678915, acc.: 55.47%] [G loss: 0.775347]\n",
      "epoch:3 step:3278 [D loss: 0.675065, acc.: 64.06%] [G loss: 0.729194]\n",
      "epoch:3 step:3279 [D loss: 0.686574, acc.: 57.03%] [G loss: 0.714432]\n",
      "epoch:3 step:3280 [D loss: 0.711464, acc.: 44.53%] [G loss: 0.750279]\n",
      "epoch:3 step:3281 [D loss: 0.686693, acc.: 54.69%] [G loss: 0.760584]\n",
      "epoch:3 step:3282 [D loss: 0.682613, acc.: 55.47%] [G loss: 0.743782]\n",
      "epoch:3 step:3283 [D loss: 0.672164, acc.: 60.94%] [G loss: 0.771932]\n",
      "epoch:3 step:3284 [D loss: 0.713508, acc.: 43.75%] [G loss: 0.758745]\n",
      "epoch:3 step:3285 [D loss: 0.694203, acc.: 53.12%] [G loss: 0.760249]\n",
      "epoch:3 step:3286 [D loss: 0.669076, acc.: 57.03%] [G loss: 0.734685]\n",
      "epoch:3 step:3287 [D loss: 0.677820, acc.: 54.69%] [G loss: 0.750753]\n",
      "epoch:3 step:3288 [D loss: 0.697466, acc.: 53.91%] [G loss: 0.740318]\n",
      "epoch:3 step:3289 [D loss: 0.716722, acc.: 42.97%] [G loss: 0.743018]\n",
      "epoch:3 step:3290 [D loss: 0.715445, acc.: 45.31%] [G loss: 0.732821]\n",
      "epoch:3 step:3291 [D loss: 0.710157, acc.: 48.44%] [G loss: 0.723335]\n",
      "epoch:3 step:3292 [D loss: 0.704406, acc.: 43.75%] [G loss: 0.722158]\n",
      "epoch:3 step:3293 [D loss: 0.715255, acc.: 46.88%] [G loss: 0.692103]\n",
      "epoch:3 step:3294 [D loss: 0.716879, acc.: 35.94%] [G loss: 0.770198]\n",
      "epoch:3 step:3295 [D loss: 0.683858, acc.: 53.91%] [G loss: 0.718593]\n",
      "epoch:3 step:3296 [D loss: 0.697561, acc.: 50.78%] [G loss: 0.737344]\n",
      "epoch:3 step:3297 [D loss: 0.701397, acc.: 42.19%] [G loss: 0.745418]\n",
      "epoch:3 step:3298 [D loss: 0.701018, acc.: 50.78%] [G loss: 0.749101]\n",
      "epoch:3 step:3299 [D loss: 0.701849, acc.: 48.44%] [G loss: 0.737752]\n",
      "epoch:3 step:3300 [D loss: 0.689219, acc.: 53.91%] [G loss: 0.732303]\n",
      "epoch:3 step:3301 [D loss: 0.688601, acc.: 52.34%] [G loss: 0.735432]\n",
      "epoch:3 step:3302 [D loss: 0.680534, acc.: 58.59%] [G loss: 0.750018]\n",
      "epoch:3 step:3303 [D loss: 0.695716, acc.: 46.09%] [G loss: 0.728128]\n",
      "epoch:3 step:3304 [D loss: 0.708889, acc.: 45.31%] [G loss: 0.773454]\n",
      "epoch:3 step:3305 [D loss: 0.711808, acc.: 42.97%] [G loss: 0.702767]\n",
      "epoch:3 step:3306 [D loss: 0.683513, acc.: 53.91%] [G loss: 0.743002]\n",
      "epoch:3 step:3307 [D loss: 0.681809, acc.: 57.81%] [G loss: 0.719864]\n",
      "epoch:3 step:3308 [D loss: 0.677698, acc.: 60.16%] [G loss: 0.732992]\n",
      "epoch:3 step:3309 [D loss: 0.705369, acc.: 50.00%] [G loss: 0.736004]\n",
      "epoch:3 step:3310 [D loss: 0.670446, acc.: 54.69%] [G loss: 0.762916]\n",
      "epoch:3 step:3311 [D loss: 0.700605, acc.: 51.56%] [G loss: 0.757216]\n",
      "epoch:3 step:3312 [D loss: 0.711763, acc.: 46.09%] [G loss: 0.755953]\n",
      "epoch:3 step:3313 [D loss: 0.706906, acc.: 44.53%] [G loss: 0.719902]\n",
      "epoch:3 step:3314 [D loss: 0.692411, acc.: 50.00%] [G loss: 0.735723]\n",
      "epoch:3 step:3315 [D loss: 0.673540, acc.: 60.94%] [G loss: 0.765196]\n",
      "epoch:3 step:3316 [D loss: 0.666070, acc.: 60.94%] [G loss: 0.763686]\n",
      "epoch:3 step:3317 [D loss: 0.679198, acc.: 52.34%] [G loss: 0.730273]\n",
      "epoch:3 step:3318 [D loss: 0.658167, acc.: 64.06%] [G loss: 0.744810]\n",
      "epoch:3 step:3319 [D loss: 0.645991, acc.: 64.06%] [G loss: 0.728436]\n",
      "epoch:3 step:3320 [D loss: 0.713943, acc.: 48.44%] [G loss: 0.757045]\n",
      "epoch:3 step:3321 [D loss: 0.711506, acc.: 51.56%] [G loss: 0.751813]\n",
      "epoch:3 step:3322 [D loss: 0.711011, acc.: 46.88%] [G loss: 0.751563]\n",
      "epoch:3 step:3323 [D loss: 0.710011, acc.: 46.09%] [G loss: 0.763240]\n",
      "epoch:3 step:3324 [D loss: 0.671186, acc.: 58.59%] [G loss: 0.760210]\n",
      "epoch:3 step:3325 [D loss: 0.709996, acc.: 43.75%] [G loss: 0.726114]\n",
      "epoch:3 step:3326 [D loss: 0.674652, acc.: 63.28%] [G loss: 0.745343]\n",
      "epoch:3 step:3327 [D loss: 0.700748, acc.: 48.44%] [G loss: 0.740873]\n",
      "epoch:3 step:3328 [D loss: 0.700412, acc.: 47.66%] [G loss: 0.746668]\n",
      "epoch:3 step:3329 [D loss: 0.668456, acc.: 60.94%] [G loss: 0.754409]\n",
      "epoch:3 step:3330 [D loss: 0.690831, acc.: 50.00%] [G loss: 0.757616]\n",
      "epoch:3 step:3331 [D loss: 0.658618, acc.: 66.41%] [G loss: 0.735847]\n",
      "epoch:3 step:3332 [D loss: 0.699487, acc.: 48.44%] [G loss: 0.768195]\n",
      "epoch:3 step:3333 [D loss: 0.679493, acc.: 57.03%] [G loss: 0.765830]\n",
      "epoch:3 step:3334 [D loss: 0.703559, acc.: 52.34%] [G loss: 0.733882]\n",
      "epoch:3 step:3335 [D loss: 0.663890, acc.: 60.16%] [G loss: 0.725065]\n",
      "epoch:3 step:3336 [D loss: 0.699916, acc.: 53.12%] [G loss: 0.774200]\n",
      "epoch:3 step:3337 [D loss: 0.686824, acc.: 56.25%] [G loss: 0.743659]\n",
      "epoch:3 step:3338 [D loss: 0.707829, acc.: 52.34%] [G loss: 0.747255]\n",
      "epoch:3 step:3339 [D loss: 0.712756, acc.: 46.88%] [G loss: 0.718057]\n",
      "epoch:3 step:3340 [D loss: 0.723934, acc.: 42.19%] [G loss: 0.721667]\n",
      "epoch:3 step:3341 [D loss: 0.692780, acc.: 53.12%] [G loss: 0.753728]\n",
      "epoch:3 step:3342 [D loss: 0.700900, acc.: 52.34%] [G loss: 0.708366]\n",
      "epoch:3 step:3343 [D loss: 0.698935, acc.: 53.12%] [G loss: 0.722799]\n",
      "epoch:3 step:3344 [D loss: 0.722175, acc.: 48.44%] [G loss: 0.736267]\n",
      "epoch:3 step:3345 [D loss: 0.686249, acc.: 59.38%] [G loss: 0.718245]\n",
      "epoch:3 step:3346 [D loss: 0.707824, acc.: 43.75%] [G loss: 0.716005]\n",
      "epoch:3 step:3347 [D loss: 0.686424, acc.: 54.69%] [G loss: 0.735803]\n",
      "epoch:3 step:3348 [D loss: 0.685080, acc.: 57.03%] [G loss: 0.729246]\n",
      "epoch:3 step:3349 [D loss: 0.681748, acc.: 58.59%] [G loss: 0.717670]\n",
      "epoch:3 step:3350 [D loss: 0.712981, acc.: 47.66%] [G loss: 0.748503]\n",
      "epoch:3 step:3351 [D loss: 0.692477, acc.: 51.56%] [G loss: 0.739090]\n",
      "epoch:3 step:3352 [D loss: 0.683389, acc.: 58.59%] [G loss: 0.754565]\n",
      "epoch:3 step:3353 [D loss: 0.719677, acc.: 39.06%] [G loss: 0.739276]\n",
      "epoch:3 step:3354 [D loss: 0.715306, acc.: 42.19%] [G loss: 0.731081]\n",
      "epoch:3 step:3355 [D loss: 0.688802, acc.: 55.47%] [G loss: 0.727857]\n",
      "epoch:3 step:3356 [D loss: 0.700291, acc.: 46.09%] [G loss: 0.704582]\n",
      "epoch:3 step:3357 [D loss: 0.704832, acc.: 44.53%] [G loss: 0.731267]\n",
      "epoch:3 step:3358 [D loss: 0.697912, acc.: 45.31%] [G loss: 0.733912]\n",
      "epoch:3 step:3359 [D loss: 0.695079, acc.: 50.00%] [G loss: 0.722890]\n",
      "epoch:3 step:3360 [D loss: 0.672541, acc.: 56.25%] [G loss: 0.749437]\n",
      "epoch:3 step:3361 [D loss: 0.680702, acc.: 59.38%] [G loss: 0.725151]\n",
      "epoch:3 step:3362 [D loss: 0.680378, acc.: 52.34%] [G loss: 0.758104]\n",
      "epoch:3 step:3363 [D loss: 0.680370, acc.: 55.47%] [G loss: 0.741073]\n",
      "epoch:3 step:3364 [D loss: 0.700915, acc.: 53.12%] [G loss: 0.719195]\n",
      "epoch:3 step:3365 [D loss: 0.685412, acc.: 52.34%] [G loss: 0.721668]\n",
      "epoch:3 step:3366 [D loss: 0.678128, acc.: 59.38%] [G loss: 0.752509]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3367 [D loss: 0.676072, acc.: 57.81%] [G loss: 0.732088]\n",
      "epoch:3 step:3368 [D loss: 0.683109, acc.: 54.69%] [G loss: 0.770042]\n",
      "epoch:3 step:3369 [D loss: 0.674713, acc.: 60.16%] [G loss: 0.756223]\n",
      "epoch:3 step:3370 [D loss: 0.694091, acc.: 48.44%] [G loss: 0.758132]\n",
      "epoch:3 step:3371 [D loss: 0.695339, acc.: 50.78%] [G loss: 0.759287]\n",
      "epoch:3 step:3372 [D loss: 0.679172, acc.: 51.56%] [G loss: 0.757195]\n",
      "epoch:3 step:3373 [D loss: 0.663067, acc.: 58.59%] [G loss: 0.790945]\n",
      "epoch:3 step:3374 [D loss: 0.680481, acc.: 55.47%] [G loss: 0.781296]\n",
      "epoch:3 step:3375 [D loss: 0.670265, acc.: 57.03%] [G loss: 0.769344]\n",
      "epoch:3 step:3376 [D loss: 0.668114, acc.: 58.59%] [G loss: 0.878868]\n",
      "epoch:3 step:3377 [D loss: 0.724643, acc.: 46.88%] [G loss: 0.757286]\n",
      "epoch:3 step:3378 [D loss: 0.691178, acc.: 52.34%] [G loss: 0.775703]\n",
      "epoch:3 step:3379 [D loss: 0.688161, acc.: 53.91%] [G loss: 0.781506]\n",
      "epoch:3 step:3380 [D loss: 0.707147, acc.: 48.44%] [G loss: 0.791476]\n",
      "epoch:3 step:3381 [D loss: 0.697128, acc.: 50.00%] [G loss: 0.781784]\n",
      "epoch:3 step:3382 [D loss: 0.703776, acc.: 47.66%] [G loss: 0.766000]\n",
      "epoch:3 step:3383 [D loss: 0.699470, acc.: 52.34%] [G loss: 0.730246]\n",
      "epoch:3 step:3384 [D loss: 0.691769, acc.: 55.47%] [G loss: 0.732356]\n",
      "epoch:3 step:3385 [D loss: 0.662298, acc.: 59.38%] [G loss: 0.742732]\n",
      "epoch:3 step:3386 [D loss: 0.664665, acc.: 58.59%] [G loss: 0.793912]\n",
      "epoch:3 step:3387 [D loss: 0.708128, acc.: 43.75%] [G loss: 0.746902]\n",
      "epoch:3 step:3388 [D loss: 0.702395, acc.: 42.97%] [G loss: 0.734471]\n",
      "epoch:3 step:3389 [D loss: 0.696349, acc.: 49.22%] [G loss: 0.736464]\n",
      "epoch:3 step:3390 [D loss: 0.721861, acc.: 36.72%] [G loss: 0.756182]\n",
      "epoch:3 step:3391 [D loss: 0.703807, acc.: 53.91%] [G loss: 0.722000]\n",
      "epoch:3 step:3392 [D loss: 0.672513, acc.: 55.47%] [G loss: 0.744101]\n",
      "epoch:3 step:3393 [D loss: 0.669306, acc.: 56.25%] [G loss: 0.753314]\n",
      "epoch:3 step:3394 [D loss: 0.715704, acc.: 47.66%] [G loss: 0.766564]\n",
      "epoch:3 step:3395 [D loss: 0.694880, acc.: 52.34%] [G loss: 0.818839]\n",
      "epoch:3 step:3396 [D loss: 0.682343, acc.: 51.56%] [G loss: 0.746485]\n",
      "epoch:3 step:3397 [D loss: 0.655110, acc.: 60.16%] [G loss: 0.808691]\n",
      "epoch:3 step:3398 [D loss: 0.700311, acc.: 47.66%] [G loss: 0.782380]\n",
      "epoch:3 step:3399 [D loss: 0.651854, acc.: 57.03%] [G loss: 0.788352]\n",
      "epoch:3 step:3400 [D loss: 0.691640, acc.: 53.91%] [G loss: 0.817155]\n",
      "##############\n",
      "[4.05733343 2.533602   6.56512967 5.40962418 3.93556776 6.37634902\n",
      " 5.41571134 5.19131097 5.38020352 5.01617387]\n",
      "##########\n",
      "epoch:3 step:3401 [D loss: 0.705380, acc.: 50.00%] [G loss: 0.857488]\n",
      "epoch:3 step:3402 [D loss: 0.698958, acc.: 55.47%] [G loss: 0.759176]\n",
      "epoch:3 step:3403 [D loss: 0.704021, acc.: 51.56%] [G loss: 0.693104]\n",
      "epoch:3 step:3404 [D loss: 0.703009, acc.: 46.09%] [G loss: 0.689111]\n",
      "epoch:3 step:3405 [D loss: 0.726617, acc.: 34.38%] [G loss: 0.705610]\n",
      "epoch:3 step:3406 [D loss: 0.704026, acc.: 53.12%] [G loss: 0.718812]\n",
      "epoch:3 step:3407 [D loss: 0.709349, acc.: 47.66%] [G loss: 0.687231]\n",
      "epoch:3 step:3408 [D loss: 0.702055, acc.: 46.88%] [G loss: 0.713889]\n",
      "epoch:3 step:3409 [D loss: 0.691132, acc.: 57.03%] [G loss: 0.747561]\n",
      "epoch:3 step:3410 [D loss: 0.688911, acc.: 55.47%] [G loss: 0.755686]\n",
      "epoch:3 step:3411 [D loss: 0.673457, acc.: 57.81%] [G loss: 0.742212]\n",
      "epoch:3 step:3412 [D loss: 0.686514, acc.: 50.78%] [G loss: 0.772400]\n",
      "epoch:3 step:3413 [D loss: 0.691878, acc.: 50.78%] [G loss: 0.784438]\n",
      "epoch:3 step:3414 [D loss: 0.691523, acc.: 46.88%] [G loss: 0.778395]\n",
      "epoch:3 step:3415 [D loss: 0.693380, acc.: 57.03%] [G loss: 0.828109]\n",
      "epoch:3 step:3416 [D loss: 0.683970, acc.: 57.03%] [G loss: 0.824078]\n",
      "epoch:3 step:3417 [D loss: 0.671819, acc.: 62.50%] [G loss: 0.833920]\n",
      "epoch:3 step:3418 [D loss: 0.693404, acc.: 51.56%] [G loss: 0.787351]\n",
      "epoch:3 step:3419 [D loss: 0.675527, acc.: 57.03%] [G loss: 0.796493]\n",
      "epoch:3 step:3420 [D loss: 0.706371, acc.: 43.75%] [G loss: 0.773329]\n",
      "epoch:3 step:3421 [D loss: 0.696647, acc.: 52.34%] [G loss: 0.749724]\n",
      "epoch:3 step:3422 [D loss: 0.696599, acc.: 50.78%] [G loss: 0.713904]\n",
      "epoch:3 step:3423 [D loss: 0.685323, acc.: 53.91%] [G loss: 0.719239]\n",
      "epoch:3 step:3424 [D loss: 0.664330, acc.: 60.94%] [G loss: 0.719994]\n",
      "epoch:3 step:3425 [D loss: 0.700990, acc.: 45.31%] [G loss: 0.729467]\n",
      "epoch:3 step:3426 [D loss: 0.736936, acc.: 42.19%] [G loss: 0.711319]\n",
      "epoch:3 step:3427 [D loss: 0.721292, acc.: 46.09%] [G loss: 0.715807]\n",
      "epoch:3 step:3428 [D loss: 0.726822, acc.: 39.84%] [G loss: 0.713490]\n",
      "epoch:3 step:3429 [D loss: 0.700280, acc.: 51.56%] [G loss: 0.725493]\n",
      "epoch:3 step:3430 [D loss: 0.693959, acc.: 51.56%] [G loss: 0.741625]\n",
      "epoch:3 step:3431 [D loss: 0.681919, acc.: 57.03%] [G loss: 0.718027]\n",
      "epoch:3 step:3432 [D loss: 0.712962, acc.: 39.06%] [G loss: 0.742515]\n",
      "epoch:3 step:3433 [D loss: 0.702923, acc.: 45.31%] [G loss: 0.761775]\n",
      "epoch:3 step:3434 [D loss: 0.688838, acc.: 44.53%] [G loss: 0.817156]\n",
      "epoch:3 step:3435 [D loss: 0.666302, acc.: 61.72%] [G loss: 0.795689]\n",
      "epoch:3 step:3436 [D loss: 0.692192, acc.: 47.66%] [G loss: 0.815200]\n",
      "epoch:3 step:3437 [D loss: 0.692166, acc.: 57.81%] [G loss: 0.765399]\n",
      "epoch:3 step:3438 [D loss: 0.688415, acc.: 57.81%] [G loss: 0.757042]\n",
      "epoch:3 step:3439 [D loss: 0.702458, acc.: 50.78%] [G loss: 0.734167]\n",
      "epoch:3 step:3440 [D loss: 0.691875, acc.: 52.34%] [G loss: 0.731843]\n",
      "epoch:3 step:3441 [D loss: 0.684867, acc.: 57.81%] [G loss: 0.733780]\n",
      "epoch:3 step:3442 [D loss: 0.691022, acc.: 47.66%] [G loss: 0.719853]\n",
      "epoch:3 step:3443 [D loss: 0.693316, acc.: 53.12%] [G loss: 0.717964]\n",
      "epoch:3 step:3444 [D loss: 0.692486, acc.: 49.22%] [G loss: 0.723488]\n",
      "epoch:3 step:3445 [D loss: 0.712284, acc.: 46.88%] [G loss: 0.708513]\n",
      "epoch:3 step:3446 [D loss: 0.683812, acc.: 58.59%] [G loss: 0.712247]\n",
      "epoch:3 step:3447 [D loss: 0.682554, acc.: 51.56%] [G loss: 0.742247]\n",
      "epoch:3 step:3448 [D loss: 0.690867, acc.: 50.78%] [G loss: 0.716243]\n",
      "epoch:3 step:3449 [D loss: 0.704197, acc.: 40.62%] [G loss: 0.726349]\n",
      "epoch:3 step:3450 [D loss: 0.707366, acc.: 47.66%] [G loss: 0.733160]\n",
      "epoch:3 step:3451 [D loss: 0.695550, acc.: 51.56%] [G loss: 0.755927]\n",
      "epoch:3 step:3452 [D loss: 0.674210, acc.: 60.16%] [G loss: 0.731598]\n",
      "epoch:3 step:3453 [D loss: 0.676724, acc.: 62.50%] [G loss: 0.748458]\n",
      "epoch:3 step:3454 [D loss: 0.683605, acc.: 52.34%] [G loss: 0.759955]\n",
      "epoch:3 step:3455 [D loss: 0.688172, acc.: 52.34%] [G loss: 0.754060]\n",
      "epoch:3 step:3456 [D loss: 0.697410, acc.: 46.09%] [G loss: 0.747291]\n",
      "epoch:3 step:3457 [D loss: 0.689366, acc.: 50.78%] [G loss: 0.720275]\n",
      "epoch:3 step:3458 [D loss: 0.690544, acc.: 55.47%] [G loss: 0.760239]\n",
      "epoch:3 step:3459 [D loss: 0.689752, acc.: 49.22%] [G loss: 0.736908]\n",
      "epoch:3 step:3460 [D loss: 0.701461, acc.: 45.31%] [G loss: 0.730088]\n",
      "epoch:3 step:3461 [D loss: 0.680294, acc.: 54.69%] [G loss: 0.723668]\n",
      "epoch:3 step:3462 [D loss: 0.691097, acc.: 53.91%] [G loss: 0.709138]\n",
      "epoch:3 step:3463 [D loss: 0.697764, acc.: 53.91%] [G loss: 0.704020]\n",
      "epoch:3 step:3464 [D loss: 0.706143, acc.: 49.22%] [G loss: 0.728235]\n",
      "epoch:3 step:3465 [D loss: 0.696885, acc.: 53.12%] [G loss: 0.746557]\n",
      "epoch:3 step:3466 [D loss: 0.705684, acc.: 45.31%] [G loss: 0.719934]\n",
      "epoch:3 step:3467 [D loss: 0.710476, acc.: 45.31%] [G loss: 0.702488]\n",
      "epoch:3 step:3468 [D loss: 0.692602, acc.: 51.56%] [G loss: 0.699112]\n",
      "epoch:3 step:3469 [D loss: 0.708278, acc.: 51.56%] [G loss: 0.731990]\n",
      "epoch:3 step:3470 [D loss: 0.682334, acc.: 56.25%] [G loss: 0.690800]\n",
      "epoch:3 step:3471 [D loss: 0.677007, acc.: 55.47%] [G loss: 0.709556]\n",
      "epoch:3 step:3472 [D loss: 0.662675, acc.: 60.16%] [G loss: 0.717259]\n",
      "epoch:3 step:3473 [D loss: 0.700054, acc.: 46.88%] [G loss: 0.747048]\n",
      "epoch:3 step:3474 [D loss: 0.707240, acc.: 47.66%] [G loss: 0.712229]\n",
      "epoch:3 step:3475 [D loss: 0.692294, acc.: 46.88%] [G loss: 0.734417]\n",
      "epoch:3 step:3476 [D loss: 0.702450, acc.: 45.31%] [G loss: 0.734339]\n",
      "epoch:3 step:3477 [D loss: 0.673711, acc.: 59.38%] [G loss: 0.723632]\n",
      "epoch:3 step:3478 [D loss: 0.685514, acc.: 51.56%] [G loss: 0.749446]\n",
      "epoch:3 step:3479 [D loss: 0.670505, acc.: 63.28%] [G loss: 0.721514]\n",
      "epoch:3 step:3480 [D loss: 0.702113, acc.: 50.00%] [G loss: 0.759531]\n",
      "epoch:3 step:3481 [D loss: 0.719681, acc.: 40.62%] [G loss: 0.733493]\n",
      "epoch:3 step:3482 [D loss: 0.700813, acc.: 45.31%] [G loss: 0.739589]\n",
      "epoch:3 step:3483 [D loss: 0.709474, acc.: 46.88%] [G loss: 0.708647]\n",
      "epoch:3 step:3484 [D loss: 0.699168, acc.: 45.31%] [G loss: 0.726151]\n",
      "epoch:3 step:3485 [D loss: 0.690338, acc.: 54.69%] [G loss: 0.709892]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3486 [D loss: 0.701440, acc.: 53.12%] [G loss: 0.725725]\n",
      "epoch:3 step:3487 [D loss: 0.682189, acc.: 57.03%] [G loss: 0.749254]\n",
      "epoch:3 step:3488 [D loss: 0.691666, acc.: 49.22%] [G loss: 0.735799]\n",
      "epoch:3 step:3489 [D loss: 0.697707, acc.: 50.00%] [G loss: 0.722899]\n",
      "epoch:3 step:3490 [D loss: 0.699560, acc.: 48.44%] [G loss: 0.721421]\n",
      "epoch:3 step:3491 [D loss: 0.695613, acc.: 52.34%] [G loss: 0.714212]\n",
      "epoch:3 step:3492 [D loss: 0.691857, acc.: 47.66%] [G loss: 0.746727]\n",
      "epoch:3 step:3493 [D loss: 0.700202, acc.: 47.66%] [G loss: 0.706665]\n",
      "epoch:3 step:3494 [D loss: 0.694436, acc.: 51.56%] [G loss: 0.728693]\n",
      "epoch:3 step:3495 [D loss: 0.684251, acc.: 59.38%] [G loss: 0.750249]\n",
      "epoch:3 step:3496 [D loss: 0.699307, acc.: 49.22%] [G loss: 0.721221]\n",
      "epoch:3 step:3497 [D loss: 0.692253, acc.: 49.22%] [G loss: 0.768085]\n",
      "epoch:3 step:3498 [D loss: 0.686047, acc.: 50.00%] [G loss: 0.737157]\n",
      "epoch:3 step:3499 [D loss: 0.690662, acc.: 52.34%] [G loss: 0.728462]\n",
      "epoch:3 step:3500 [D loss: 0.692133, acc.: 52.34%] [G loss: 0.718589]\n",
      "epoch:3 step:3501 [D loss: 0.693515, acc.: 50.00%] [G loss: 0.758234]\n",
      "epoch:3 step:3502 [D loss: 0.678433, acc.: 53.91%] [G loss: 0.746218]\n",
      "epoch:3 step:3503 [D loss: 0.697299, acc.: 49.22%] [G loss: 0.739362]\n",
      "epoch:3 step:3504 [D loss: 0.686142, acc.: 50.78%] [G loss: 0.731686]\n",
      "epoch:3 step:3505 [D loss: 0.679093, acc.: 58.59%] [G loss: 0.714918]\n",
      "epoch:3 step:3506 [D loss: 0.707211, acc.: 46.88%] [G loss: 0.715202]\n",
      "epoch:3 step:3507 [D loss: 0.694391, acc.: 52.34%] [G loss: 0.722319]\n",
      "epoch:3 step:3508 [D loss: 0.709478, acc.: 42.19%] [G loss: 0.738228]\n",
      "epoch:3 step:3509 [D loss: 0.694078, acc.: 54.69%] [G loss: 0.725363]\n",
      "epoch:3 step:3510 [D loss: 0.682596, acc.: 57.03%] [G loss: 0.786197]\n",
      "epoch:3 step:3511 [D loss: 0.691839, acc.: 53.91%] [G loss: 0.751213]\n",
      "epoch:3 step:3512 [D loss: 0.697117, acc.: 49.22%] [G loss: 0.764750]\n",
      "epoch:3 step:3513 [D loss: 0.680489, acc.: 55.47%] [G loss: 0.743461]\n",
      "epoch:3 step:3514 [D loss: 0.688649, acc.: 54.69%] [G loss: 0.762173]\n",
      "epoch:3 step:3515 [D loss: 0.695522, acc.: 50.78%] [G loss: 0.788492]\n",
      "epoch:3 step:3516 [D loss: 0.688191, acc.: 60.16%] [G loss: 0.799337]\n",
      "epoch:3 step:3517 [D loss: 0.684760, acc.: 58.59%] [G loss: 0.735721]\n",
      "epoch:3 step:3518 [D loss: 0.696402, acc.: 52.34%] [G loss: 0.768537]\n",
      "epoch:3 step:3519 [D loss: 0.678904, acc.: 53.91%] [G loss: 0.774038]\n",
      "epoch:3 step:3520 [D loss: 0.662997, acc.: 59.38%] [G loss: 0.736277]\n",
      "epoch:3 step:3521 [D loss: 0.733897, acc.: 45.31%] [G loss: 0.757334]\n",
      "epoch:3 step:3522 [D loss: 0.710987, acc.: 48.44%] [G loss: 0.764189]\n",
      "epoch:3 step:3523 [D loss: 0.681149, acc.: 56.25%] [G loss: 0.769210]\n",
      "epoch:3 step:3524 [D loss: 0.679577, acc.: 55.47%] [G loss: 0.743348]\n",
      "epoch:3 step:3525 [D loss: 0.682594, acc.: 50.78%] [G loss: 0.739704]\n",
      "epoch:3 step:3526 [D loss: 0.717482, acc.: 43.75%] [G loss: 0.808369]\n",
      "epoch:3 step:3527 [D loss: 0.695206, acc.: 53.91%] [G loss: 0.739424]\n",
      "epoch:3 step:3528 [D loss: 0.721151, acc.: 44.53%] [G loss: 0.711785]\n",
      "epoch:3 step:3529 [D loss: 0.711244, acc.: 46.88%] [G loss: 0.723281]\n",
      "epoch:3 step:3530 [D loss: 0.699338, acc.: 45.31%] [G loss: 0.754010]\n",
      "epoch:3 step:3531 [D loss: 0.687286, acc.: 48.44%] [G loss: 0.708683]\n",
      "epoch:3 step:3532 [D loss: 0.694555, acc.: 48.44%] [G loss: 0.732746]\n",
      "epoch:3 step:3533 [D loss: 0.701545, acc.: 47.66%] [G loss: 0.741117]\n",
      "epoch:3 step:3534 [D loss: 0.684735, acc.: 50.00%] [G loss: 0.739757]\n",
      "epoch:3 step:3535 [D loss: 0.696458, acc.: 51.56%] [G loss: 0.718358]\n",
      "epoch:3 step:3536 [D loss: 0.685127, acc.: 53.12%] [G loss: 0.753399]\n",
      "epoch:3 step:3537 [D loss: 0.698870, acc.: 45.31%] [G loss: 0.733357]\n",
      "epoch:3 step:3538 [D loss: 0.696547, acc.: 46.88%] [G loss: 0.718995]\n",
      "epoch:3 step:3539 [D loss: 0.695919, acc.: 56.25%] [G loss: 0.735802]\n",
      "epoch:3 step:3540 [D loss: 0.698712, acc.: 53.12%] [G loss: 0.746510]\n",
      "epoch:3 step:3541 [D loss: 0.696134, acc.: 49.22%] [G loss: 0.731187]\n",
      "epoch:3 step:3542 [D loss: 0.683679, acc.: 60.16%] [G loss: 0.741206]\n",
      "epoch:3 step:3543 [D loss: 0.674875, acc.: 60.94%] [G loss: 0.747862]\n",
      "epoch:3 step:3544 [D loss: 0.678908, acc.: 62.50%] [G loss: 0.746025]\n",
      "epoch:3 step:3545 [D loss: 0.684195, acc.: 60.16%] [G loss: 0.744571]\n",
      "epoch:3 step:3546 [D loss: 0.713597, acc.: 45.31%] [G loss: 0.770638]\n",
      "epoch:3 step:3547 [D loss: 0.692346, acc.: 50.00%] [G loss: 0.735233]\n",
      "epoch:3 step:3548 [D loss: 0.675517, acc.: 59.38%] [G loss: 0.750453]\n",
      "epoch:3 step:3549 [D loss: 0.688967, acc.: 48.44%] [G loss: 0.767987]\n",
      "epoch:3 step:3550 [D loss: 0.683193, acc.: 60.94%] [G loss: 0.746694]\n",
      "epoch:3 step:3551 [D loss: 0.692109, acc.: 55.47%] [G loss: 0.755589]\n",
      "epoch:3 step:3552 [D loss: 0.702518, acc.: 49.22%] [G loss: 0.738261]\n",
      "epoch:3 step:3553 [D loss: 0.705773, acc.: 44.53%] [G loss: 0.710878]\n",
      "epoch:3 step:3554 [D loss: 0.700394, acc.: 46.88%] [G loss: 0.736577]\n",
      "epoch:3 step:3555 [D loss: 0.690744, acc.: 52.34%] [G loss: 0.736585]\n",
      "epoch:3 step:3556 [D loss: 0.689810, acc.: 55.47%] [G loss: 0.725947]\n",
      "epoch:3 step:3557 [D loss: 0.691788, acc.: 53.91%] [G loss: 0.713552]\n",
      "epoch:3 step:3558 [D loss: 0.686930, acc.: 56.25%] [G loss: 0.680387]\n",
      "epoch:3 step:3559 [D loss: 0.717676, acc.: 40.62%] [G loss: 0.721651]\n",
      "epoch:3 step:3560 [D loss: 0.697444, acc.: 44.53%] [G loss: 0.696347]\n",
      "epoch:3 step:3561 [D loss: 0.687978, acc.: 53.12%] [G loss: 0.721240]\n",
      "epoch:3 step:3562 [D loss: 0.697822, acc.: 50.00%] [G loss: 0.690992]\n",
      "epoch:3 step:3563 [D loss: 0.706161, acc.: 44.53%] [G loss: 0.705053]\n",
      "epoch:3 step:3564 [D loss: 0.704813, acc.: 45.31%] [G loss: 0.719095]\n",
      "epoch:3 step:3565 [D loss: 0.689056, acc.: 53.91%] [G loss: 0.719278]\n",
      "epoch:3 step:3566 [D loss: 0.694368, acc.: 57.03%] [G loss: 0.727085]\n",
      "epoch:3 step:3567 [D loss: 0.680080, acc.: 54.69%] [G loss: 0.714456]\n",
      "epoch:3 step:3568 [D loss: 0.692770, acc.: 57.03%] [G loss: 0.743117]\n",
      "epoch:3 step:3569 [D loss: 0.704995, acc.: 47.66%] [G loss: 0.731005]\n",
      "epoch:3 step:3570 [D loss: 0.698140, acc.: 45.31%] [G loss: 0.738040]\n",
      "epoch:3 step:3571 [D loss: 0.704883, acc.: 44.53%] [G loss: 0.715938]\n",
      "epoch:3 step:3572 [D loss: 0.682780, acc.: 57.81%] [G loss: 0.741217]\n",
      "epoch:3 step:3573 [D loss: 0.687582, acc.: 53.91%] [G loss: 0.741409]\n",
      "epoch:3 step:3574 [D loss: 0.699803, acc.: 50.00%] [G loss: 0.741207]\n",
      "epoch:3 step:3575 [D loss: 0.679266, acc.: 57.81%] [G loss: 0.740126]\n",
      "epoch:3 step:3576 [D loss: 0.697645, acc.: 52.34%] [G loss: 0.746588]\n",
      "epoch:3 step:3577 [D loss: 0.689262, acc.: 56.25%] [G loss: 0.735130]\n",
      "epoch:3 step:3578 [D loss: 0.674862, acc.: 65.62%] [G loss: 0.744637]\n",
      "epoch:3 step:3579 [D loss: 0.703966, acc.: 44.53%] [G loss: 0.754232]\n",
      "epoch:3 step:3580 [D loss: 0.689243, acc.: 51.56%] [G loss: 0.725081]\n",
      "epoch:3 step:3581 [D loss: 0.681146, acc.: 59.38%] [G loss: 0.729750]\n",
      "epoch:3 step:3582 [D loss: 0.690294, acc.: 51.56%] [G loss: 0.729889]\n",
      "epoch:3 step:3583 [D loss: 0.696979, acc.: 53.91%] [G loss: 0.739769]\n",
      "epoch:3 step:3584 [D loss: 0.699758, acc.: 52.34%] [G loss: 0.715179]\n",
      "epoch:3 step:3585 [D loss: 0.702389, acc.: 46.09%] [G loss: 0.716153]\n",
      "epoch:3 step:3586 [D loss: 0.684933, acc.: 46.09%] [G loss: 0.730917]\n",
      "epoch:3 step:3587 [D loss: 0.700439, acc.: 49.22%] [G loss: 0.706926]\n",
      "epoch:3 step:3588 [D loss: 0.695380, acc.: 54.69%] [G loss: 0.735021]\n",
      "epoch:3 step:3589 [D loss: 0.698982, acc.: 56.25%] [G loss: 0.733368]\n",
      "epoch:3 step:3590 [D loss: 0.697377, acc.: 50.00%] [G loss: 0.734967]\n",
      "epoch:3 step:3591 [D loss: 0.702559, acc.: 50.78%] [G loss: 0.758147]\n",
      "epoch:3 step:3592 [D loss: 0.706819, acc.: 43.75%] [G loss: 0.742889]\n",
      "epoch:3 step:3593 [D loss: 0.680230, acc.: 55.47%] [G loss: 0.766657]\n",
      "epoch:3 step:3594 [D loss: 0.692103, acc.: 50.00%] [G loss: 0.773286]\n",
      "epoch:3 step:3595 [D loss: 0.682638, acc.: 53.91%] [G loss: 0.759577]\n",
      "epoch:3 step:3596 [D loss: 0.684411, acc.: 53.91%] [G loss: 0.771377]\n",
      "epoch:3 step:3597 [D loss: 0.700747, acc.: 44.53%] [G loss: 0.753790]\n",
      "epoch:3 step:3598 [D loss: 0.691099, acc.: 50.00%] [G loss: 0.762858]\n",
      "epoch:3 step:3599 [D loss: 0.716422, acc.: 52.34%] [G loss: 0.766103]\n",
      "epoch:3 step:3600 [D loss: 0.710525, acc.: 39.84%] [G loss: 0.757019]\n",
      "##############\n",
      "[4.12457827 2.75427418 6.41819838 5.50330056 4.14895533 5.82688957\n",
      " 5.06473131 5.27378339 5.29101255 4.61330003]\n",
      "##########\n",
      "epoch:3 step:3601 [D loss: 0.686709, acc.: 54.69%] [G loss: 0.748638]\n",
      "epoch:3 step:3602 [D loss: 0.689110, acc.: 53.12%] [G loss: 0.736124]\n",
      "epoch:3 step:3603 [D loss: 0.684821, acc.: 55.47%] [G loss: 0.739308]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3604 [D loss: 0.686449, acc.: 56.25%] [G loss: 0.718854]\n",
      "epoch:3 step:3605 [D loss: 0.679684, acc.: 55.47%] [G loss: 0.712873]\n",
      "epoch:3 step:3606 [D loss: 0.692248, acc.: 51.56%] [G loss: 0.729437]\n",
      "epoch:3 step:3607 [D loss: 0.675563, acc.: 58.59%] [G loss: 0.717388]\n",
      "epoch:3 step:3608 [D loss: 0.704359, acc.: 42.97%] [G loss: 0.707269]\n",
      "epoch:3 step:3609 [D loss: 0.681128, acc.: 56.25%] [G loss: 0.731187]\n",
      "epoch:3 step:3610 [D loss: 0.684525, acc.: 53.91%] [G loss: 0.768161]\n",
      "epoch:3 step:3611 [D loss: 0.720197, acc.: 39.06%] [G loss: 0.737611]\n",
      "epoch:3 step:3612 [D loss: 0.695102, acc.: 53.91%] [G loss: 0.736213]\n",
      "epoch:3 step:3613 [D loss: 0.676471, acc.: 60.94%] [G loss: 0.743031]\n",
      "epoch:3 step:3614 [D loss: 0.685121, acc.: 56.25%] [G loss: 0.738996]\n",
      "epoch:3 step:3615 [D loss: 0.677943, acc.: 57.81%] [G loss: 0.759530]\n",
      "epoch:3 step:3616 [D loss: 0.698372, acc.: 53.12%] [G loss: 0.776982]\n",
      "epoch:3 step:3617 [D loss: 0.678519, acc.: 57.81%] [G loss: 0.785186]\n",
      "epoch:3 step:3618 [D loss: 0.677169, acc.: 54.69%] [G loss: 0.768601]\n",
      "epoch:3 step:3619 [D loss: 0.706471, acc.: 43.75%] [G loss: 0.752538]\n",
      "epoch:3 step:3620 [D loss: 0.681526, acc.: 60.16%] [G loss: 0.763784]\n",
      "epoch:3 step:3621 [D loss: 0.686303, acc.: 50.00%] [G loss: 0.745057]\n",
      "epoch:3 step:3622 [D loss: 0.709497, acc.: 48.44%] [G loss: 0.733968]\n",
      "epoch:3 step:3623 [D loss: 0.712415, acc.: 46.09%] [G loss: 0.733719]\n",
      "epoch:3 step:3624 [D loss: 0.695406, acc.: 53.91%] [G loss: 0.702430]\n",
      "epoch:3 step:3625 [D loss: 0.717019, acc.: 42.19%] [G loss: 0.705259]\n",
      "epoch:3 step:3626 [D loss: 0.688300, acc.: 46.09%] [G loss: 0.722052]\n",
      "epoch:3 step:3627 [D loss: 0.699673, acc.: 49.22%] [G loss: 0.692602]\n",
      "epoch:3 step:3628 [D loss: 0.689005, acc.: 47.66%] [G loss: 0.709764]\n",
      "epoch:3 step:3629 [D loss: 0.698397, acc.: 50.78%] [G loss: 0.721185]\n",
      "epoch:3 step:3630 [D loss: 0.686700, acc.: 48.44%] [G loss: 0.768169]\n",
      "epoch:3 step:3631 [D loss: 0.708912, acc.: 39.84%] [G loss: 0.742300]\n",
      "epoch:3 step:3632 [D loss: 0.700438, acc.: 47.66%] [G loss: 0.720755]\n",
      "epoch:3 step:3633 [D loss: 0.684325, acc.: 61.72%] [G loss: 0.742267]\n",
      "epoch:3 step:3634 [D loss: 0.678589, acc.: 58.59%] [G loss: 0.723904]\n",
      "epoch:3 step:3635 [D loss: 0.701530, acc.: 53.12%] [G loss: 0.735968]\n",
      "epoch:3 step:3636 [D loss: 0.687903, acc.: 53.91%] [G loss: 0.731179]\n",
      "epoch:3 step:3637 [D loss: 0.690776, acc.: 50.78%] [G loss: 0.749861]\n",
      "epoch:3 step:3638 [D loss: 0.696187, acc.: 55.47%] [G loss: 0.731982]\n",
      "epoch:3 step:3639 [D loss: 0.698502, acc.: 53.12%] [G loss: 0.733362]\n",
      "epoch:3 step:3640 [D loss: 0.681913, acc.: 57.03%] [G loss: 0.737026]\n",
      "epoch:3 step:3641 [D loss: 0.693347, acc.: 49.22%] [G loss: 0.736667]\n",
      "epoch:3 step:3642 [D loss: 0.695511, acc.: 48.44%] [G loss: 0.732749]\n",
      "epoch:3 step:3643 [D loss: 0.691403, acc.: 57.03%] [G loss: 0.718738]\n",
      "epoch:3 step:3644 [D loss: 0.696005, acc.: 52.34%] [G loss: 0.706720]\n",
      "epoch:3 step:3645 [D loss: 0.697300, acc.: 51.56%] [G loss: 0.744997]\n",
      "epoch:3 step:3646 [D loss: 0.698989, acc.: 50.00%] [G loss: 0.715563]\n",
      "epoch:3 step:3647 [D loss: 0.691614, acc.: 56.25%] [G loss: 0.741724]\n",
      "epoch:3 step:3648 [D loss: 0.674913, acc.: 58.59%] [G loss: 0.752068]\n",
      "epoch:3 step:3649 [D loss: 0.675735, acc.: 57.81%] [G loss: 0.728644]\n",
      "epoch:3 step:3650 [D loss: 0.703087, acc.: 52.34%] [G loss: 0.753895]\n",
      "epoch:3 step:3651 [D loss: 0.686803, acc.: 56.25%] [G loss: 0.741994]\n",
      "epoch:3 step:3652 [D loss: 0.679770, acc.: 56.25%] [G loss: 0.763692]\n",
      "epoch:3 step:3653 [D loss: 0.683179, acc.: 58.59%] [G loss: 0.754817]\n",
      "epoch:3 step:3654 [D loss: 0.714913, acc.: 49.22%] [G loss: 0.735954]\n",
      "epoch:3 step:3655 [D loss: 0.706888, acc.: 46.88%] [G loss: 0.728217]\n",
      "epoch:3 step:3656 [D loss: 0.694701, acc.: 46.88%] [G loss: 0.715685]\n",
      "epoch:3 step:3657 [D loss: 0.708035, acc.: 46.09%] [G loss: 0.702699]\n",
      "epoch:3 step:3658 [D loss: 0.714657, acc.: 45.31%] [G loss: 0.711546]\n",
      "epoch:3 step:3659 [D loss: 0.719642, acc.: 46.09%] [G loss: 0.712140]\n",
      "epoch:3 step:3660 [D loss: 0.698450, acc.: 51.56%] [G loss: 0.722131]\n",
      "epoch:3 step:3661 [D loss: 0.711871, acc.: 39.06%] [G loss: 0.715653]\n",
      "epoch:3 step:3662 [D loss: 0.691139, acc.: 48.44%] [G loss: 0.731524]\n",
      "epoch:3 step:3663 [D loss: 0.692168, acc.: 52.34%] [G loss: 0.717889]\n",
      "epoch:3 step:3664 [D loss: 0.684764, acc.: 50.78%] [G loss: 0.735108]\n",
      "epoch:3 step:3665 [D loss: 0.686971, acc.: 52.34%] [G loss: 0.732050]\n",
      "epoch:3 step:3666 [D loss: 0.692443, acc.: 48.44%] [G loss: 0.774187]\n",
      "epoch:3 step:3667 [D loss: 0.678008, acc.: 55.47%] [G loss: 0.779454]\n",
      "epoch:3 step:3668 [D loss: 0.682075, acc.: 57.81%] [G loss: 0.759173]\n",
      "epoch:3 step:3669 [D loss: 0.705983, acc.: 51.56%] [G loss: 0.806178]\n",
      "epoch:3 step:3670 [D loss: 0.712183, acc.: 46.88%] [G loss: 0.791720]\n",
      "epoch:3 step:3671 [D loss: 0.699768, acc.: 50.00%] [G loss: 0.755987]\n",
      "epoch:3 step:3672 [D loss: 0.689445, acc.: 53.91%] [G loss: 0.741000]\n",
      "epoch:3 step:3673 [D loss: 0.697612, acc.: 52.34%] [G loss: 0.744534]\n",
      "epoch:3 step:3674 [D loss: 0.682685, acc.: 54.69%] [G loss: 0.816796]\n",
      "epoch:3 step:3675 [D loss: 0.695026, acc.: 53.12%] [G loss: 0.735706]\n",
      "epoch:3 step:3676 [D loss: 0.684348, acc.: 56.25%] [G loss: 0.762541]\n",
      "epoch:3 step:3677 [D loss: 0.694167, acc.: 55.47%] [G loss: 0.735659]\n",
      "epoch:3 step:3678 [D loss: 0.712112, acc.: 46.88%] [G loss: 0.717978]\n",
      "epoch:3 step:3679 [D loss: 0.691205, acc.: 50.00%] [G loss: 0.719432]\n",
      "epoch:3 step:3680 [D loss: 0.695061, acc.: 46.88%] [G loss: 0.729720]\n",
      "epoch:3 step:3681 [D loss: 0.698865, acc.: 46.88%] [G loss: 0.714134]\n",
      "epoch:3 step:3682 [D loss: 0.671844, acc.: 54.69%] [G loss: 0.751131]\n",
      "epoch:3 step:3683 [D loss: 0.687788, acc.: 54.69%] [G loss: 0.743569]\n",
      "epoch:3 step:3684 [D loss: 0.700177, acc.: 48.44%] [G loss: 0.704568]\n",
      "epoch:3 step:3685 [D loss: 0.709703, acc.: 46.88%] [G loss: 0.733577]\n",
      "epoch:3 step:3686 [D loss: 0.697061, acc.: 51.56%] [G loss: 0.739455]\n",
      "epoch:3 step:3687 [D loss: 0.688901, acc.: 51.56%] [G loss: 0.729411]\n",
      "epoch:3 step:3688 [D loss: 0.682280, acc.: 53.91%] [G loss: 0.738823]\n",
      "epoch:3 step:3689 [D loss: 0.687753, acc.: 50.00%] [G loss: 0.738984]\n",
      "epoch:3 step:3690 [D loss: 0.684269, acc.: 50.78%] [G loss: 0.712227]\n",
      "epoch:3 step:3691 [D loss: 0.681226, acc.: 53.12%] [G loss: 0.731652]\n",
      "epoch:3 step:3692 [D loss: 0.688947, acc.: 52.34%] [G loss: 0.710059]\n",
      "epoch:3 step:3693 [D loss: 0.684828, acc.: 58.59%] [G loss: 0.720764]\n",
      "epoch:3 step:3694 [D loss: 0.682811, acc.: 57.03%] [G loss: 0.747431]\n",
      "epoch:3 step:3695 [D loss: 0.699253, acc.: 45.31%] [G loss: 0.744486]\n",
      "epoch:3 step:3696 [D loss: 0.680130, acc.: 60.16%] [G loss: 0.713263]\n",
      "epoch:3 step:3697 [D loss: 0.671370, acc.: 63.28%] [G loss: 0.716151]\n",
      "epoch:3 step:3698 [D loss: 0.707683, acc.: 53.12%] [G loss: 0.714186]\n",
      "epoch:3 step:3699 [D loss: 0.724489, acc.: 41.41%] [G loss: 0.685221]\n",
      "epoch:3 step:3700 [D loss: 0.705313, acc.: 52.34%] [G loss: 0.736396]\n",
      "epoch:3 step:3701 [D loss: 0.698784, acc.: 50.78%] [G loss: 0.725968]\n",
      "epoch:3 step:3702 [D loss: 0.716397, acc.: 42.19%] [G loss: 0.737387]\n",
      "epoch:3 step:3703 [D loss: 0.718613, acc.: 42.97%] [G loss: 0.744962]\n",
      "epoch:3 step:3704 [D loss: 0.707846, acc.: 44.53%] [G loss: 0.726356]\n",
      "epoch:3 step:3705 [D loss: 0.700032, acc.: 51.56%] [G loss: 0.741933]\n",
      "epoch:3 step:3706 [D loss: 0.702604, acc.: 50.78%] [G loss: 0.750190]\n",
      "epoch:3 step:3707 [D loss: 0.699185, acc.: 49.22%] [G loss: 0.745882]\n",
      "epoch:3 step:3708 [D loss: 0.686369, acc.: 50.00%] [G loss: 0.751345]\n",
      "epoch:3 step:3709 [D loss: 0.701709, acc.: 50.00%] [G loss: 0.764171]\n",
      "epoch:3 step:3710 [D loss: 0.695585, acc.: 53.12%] [G loss: 0.766204]\n",
      "epoch:3 step:3711 [D loss: 0.668391, acc.: 55.47%] [G loss: 0.768301]\n",
      "epoch:3 step:3712 [D loss: 0.692366, acc.: 50.78%] [G loss: 0.742070]\n",
      "epoch:3 step:3713 [D loss: 0.692140, acc.: 51.56%] [G loss: 0.738919]\n",
      "epoch:3 step:3714 [D loss: 0.694773, acc.: 55.47%] [G loss: 0.722903]\n",
      "epoch:3 step:3715 [D loss: 0.718680, acc.: 35.94%] [G loss: 0.716448]\n",
      "epoch:3 step:3716 [D loss: 0.712378, acc.: 40.62%] [G loss: 0.712408]\n",
      "epoch:3 step:3717 [D loss: 0.707382, acc.: 42.97%] [G loss: 0.702583]\n",
      "epoch:3 step:3718 [D loss: 0.692527, acc.: 50.00%] [G loss: 0.700924]\n",
      "epoch:3 step:3719 [D loss: 0.702291, acc.: 39.84%] [G loss: 0.713029]\n",
      "epoch:3 step:3720 [D loss: 0.699334, acc.: 47.66%] [G loss: 0.709864]\n",
      "epoch:3 step:3721 [D loss: 0.708032, acc.: 39.84%] [G loss: 0.723531]\n",
      "epoch:3 step:3722 [D loss: 0.690251, acc.: 50.00%] [G loss: 0.707754]\n",
      "epoch:3 step:3723 [D loss: 0.672199, acc.: 53.91%] [G loss: 0.715422]\n",
      "epoch:3 step:3724 [D loss: 0.685249, acc.: 53.12%] [G loss: 0.713688]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3725 [D loss: 0.693497, acc.: 47.66%] [G loss: 0.702179]\n",
      "epoch:3 step:3726 [D loss: 0.717919, acc.: 45.31%] [G loss: 0.692899]\n",
      "epoch:3 step:3727 [D loss: 0.703481, acc.: 37.50%] [G loss: 0.726598]\n",
      "epoch:3 step:3728 [D loss: 0.692037, acc.: 50.00%] [G loss: 0.747713]\n",
      "epoch:3 step:3729 [D loss: 0.667787, acc.: 69.53%] [G loss: 0.724261]\n",
      "epoch:3 step:3730 [D loss: 0.670169, acc.: 63.28%] [G loss: 0.692303]\n",
      "epoch:3 step:3731 [D loss: 0.712031, acc.: 46.88%] [G loss: 0.741275]\n",
      "epoch:3 step:3732 [D loss: 0.698154, acc.: 51.56%] [G loss: 0.740892]\n",
      "epoch:3 step:3733 [D loss: 0.691446, acc.: 49.22%] [G loss: 0.705856]\n",
      "epoch:3 step:3734 [D loss: 0.668069, acc.: 64.06%] [G loss: 0.706300]\n",
      "epoch:3 step:3735 [D loss: 0.681548, acc.: 60.16%] [G loss: 0.719606]\n",
      "epoch:3 step:3736 [D loss: 0.682691, acc.: 53.91%] [G loss: 0.723943]\n",
      "epoch:3 step:3737 [D loss: 0.674146, acc.: 55.47%] [G loss: 0.742236]\n",
      "epoch:3 step:3738 [D loss: 0.618181, acc.: 70.31%] [G loss: 0.763272]\n",
      "epoch:3 step:3739 [D loss: 0.715015, acc.: 52.34%] [G loss: 0.763526]\n",
      "epoch:3 step:3740 [D loss: 0.684769, acc.: 59.38%] [G loss: 0.802244]\n",
      "epoch:3 step:3741 [D loss: 0.654247, acc.: 59.38%] [G loss: 0.806888]\n",
      "epoch:3 step:3742 [D loss: 0.684032, acc.: 52.34%] [G loss: 0.773847]\n",
      "epoch:3 step:3743 [D loss: 0.689477, acc.: 50.78%] [G loss: 0.706058]\n",
      "epoch:3 step:3744 [D loss: 0.663041, acc.: 64.06%] [G loss: 0.700867]\n",
      "epoch:3 step:3745 [D loss: 0.726455, acc.: 49.22%] [G loss: 0.718645]\n",
      "epoch:3 step:3746 [D loss: 0.651317, acc.: 64.84%] [G loss: 0.639677]\n",
      "epoch:3 step:3747 [D loss: 0.674716, acc.: 58.59%] [G loss: 0.708659]\n",
      "epoch:3 step:3748 [D loss: 0.720053, acc.: 50.00%] [G loss: 0.688632]\n",
      "epoch:4 step:3749 [D loss: 0.714303, acc.: 46.09%] [G loss: 0.697720]\n",
      "epoch:4 step:3750 [D loss: 0.724159, acc.: 42.97%] [G loss: 0.711472]\n",
      "epoch:4 step:3751 [D loss: 0.729445, acc.: 40.62%] [G loss: 0.703586]\n",
      "epoch:4 step:3752 [D loss: 0.704400, acc.: 46.88%] [G loss: 0.703175]\n",
      "epoch:4 step:3753 [D loss: 0.686961, acc.: 57.81%] [G loss: 0.747872]\n",
      "epoch:4 step:3754 [D loss: 0.704780, acc.: 44.53%] [G loss: 0.747782]\n",
      "epoch:4 step:3755 [D loss: 0.691833, acc.: 52.34%] [G loss: 0.734783]\n",
      "epoch:4 step:3756 [D loss: 0.684785, acc.: 53.91%] [G loss: 0.717766]\n",
      "epoch:4 step:3757 [D loss: 0.676786, acc.: 57.81%] [G loss: 0.764840]\n",
      "epoch:4 step:3758 [D loss: 0.683639, acc.: 57.03%] [G loss: 0.721047]\n",
      "epoch:4 step:3759 [D loss: 0.719768, acc.: 44.53%] [G loss: 0.743200]\n",
      "epoch:4 step:3760 [D loss: 0.717866, acc.: 50.78%] [G loss: 0.727005]\n",
      "epoch:4 step:3761 [D loss: 0.687783, acc.: 57.03%] [G loss: 0.707153]\n",
      "epoch:4 step:3762 [D loss: 0.686148, acc.: 54.69%] [G loss: 0.709186]\n",
      "epoch:4 step:3763 [D loss: 0.712340, acc.: 49.22%] [G loss: 0.737836]\n",
      "epoch:4 step:3764 [D loss: 0.696366, acc.: 50.78%] [G loss: 0.744388]\n",
      "epoch:4 step:3765 [D loss: 0.715283, acc.: 40.62%] [G loss: 0.754055]\n",
      "epoch:4 step:3766 [D loss: 0.708221, acc.: 42.19%] [G loss: 0.747708]\n",
      "epoch:4 step:3767 [D loss: 0.710670, acc.: 45.31%] [G loss: 0.777029]\n",
      "epoch:4 step:3768 [D loss: 0.694619, acc.: 47.66%] [G loss: 0.790330]\n",
      "epoch:4 step:3769 [D loss: 0.690633, acc.: 53.12%] [G loss: 0.785563]\n",
      "epoch:4 step:3770 [D loss: 0.671109, acc.: 61.72%] [G loss: 0.815151]\n",
      "epoch:4 step:3771 [D loss: 0.681858, acc.: 53.12%] [G loss: 0.812515]\n",
      "epoch:4 step:3772 [D loss: 0.685692, acc.: 58.59%] [G loss: 0.801007]\n",
      "epoch:4 step:3773 [D loss: 0.667213, acc.: 59.38%] [G loss: 0.801994]\n",
      "epoch:4 step:3774 [D loss: 0.679356, acc.: 53.12%] [G loss: 0.805400]\n",
      "epoch:4 step:3775 [D loss: 0.690569, acc.: 46.09%] [G loss: 0.784436]\n",
      "epoch:4 step:3776 [D loss: 0.695657, acc.: 53.12%] [G loss: 0.779937]\n",
      "epoch:4 step:3777 [D loss: 0.684755, acc.: 56.25%] [G loss: 0.741588]\n",
      "epoch:4 step:3778 [D loss: 0.689930, acc.: 53.12%] [G loss: 0.730754]\n",
      "epoch:4 step:3779 [D loss: 0.720949, acc.: 51.56%] [G loss: 0.738927]\n",
      "epoch:4 step:3780 [D loss: 0.671207, acc.: 62.50%] [G loss: 0.728192]\n",
      "epoch:4 step:3781 [D loss: 0.701477, acc.: 52.34%] [G loss: 0.771162]\n",
      "epoch:4 step:3782 [D loss: 0.686732, acc.: 57.81%] [G loss: 0.746946]\n",
      "epoch:4 step:3783 [D loss: 0.702197, acc.: 48.44%] [G loss: 0.745444]\n",
      "epoch:4 step:3784 [D loss: 0.704898, acc.: 46.88%] [G loss: 0.730562]\n",
      "epoch:4 step:3785 [D loss: 0.700995, acc.: 55.47%] [G loss: 0.778836]\n",
      "epoch:4 step:3786 [D loss: 0.752020, acc.: 40.62%] [G loss: 0.713961]\n",
      "epoch:4 step:3787 [D loss: 0.723641, acc.: 42.97%] [G loss: 0.735972]\n",
      "epoch:4 step:3788 [D loss: 0.703768, acc.: 50.00%] [G loss: 0.762785]\n",
      "epoch:4 step:3789 [D loss: 0.689813, acc.: 46.88%] [G loss: 0.740431]\n",
      "epoch:4 step:3790 [D loss: 0.682081, acc.: 60.16%] [G loss: 0.758116]\n",
      "epoch:4 step:3791 [D loss: 0.681029, acc.: 56.25%] [G loss: 0.761803]\n",
      "epoch:4 step:3792 [D loss: 0.683391, acc.: 55.47%] [G loss: 0.835542]\n",
      "epoch:4 step:3793 [D loss: 0.695021, acc.: 50.00%] [G loss: 0.765998]\n",
      "epoch:4 step:3794 [D loss: 0.696308, acc.: 53.12%] [G loss: 0.752021]\n",
      "epoch:4 step:3795 [D loss: 0.683628, acc.: 53.91%] [G loss: 0.759901]\n",
      "epoch:4 step:3796 [D loss: 0.688222, acc.: 54.69%] [G loss: 0.758916]\n",
      "epoch:4 step:3797 [D loss: 0.693305, acc.: 55.47%] [G loss: 0.696917]\n",
      "epoch:4 step:3798 [D loss: 0.685067, acc.: 54.69%] [G loss: 0.721601]\n",
      "epoch:4 step:3799 [D loss: 0.697771, acc.: 53.12%] [G loss: 0.719496]\n",
      "epoch:4 step:3800 [D loss: 0.679878, acc.: 60.94%] [G loss: 0.732985]\n",
      "##############\n",
      "[4.15265753 2.84112032 6.45307025 5.62435685 3.94264079 6.14736305\n",
      " 5.32624499 5.39979294 5.38741624 4.59370264]\n",
      "##########\n",
      "epoch:4 step:3801 [D loss: 0.683647, acc.: 53.12%] [G loss: 0.722538]\n",
      "epoch:4 step:3802 [D loss: 0.695358, acc.: 52.34%] [G loss: 0.716083]\n",
      "epoch:4 step:3803 [D loss: 0.705480, acc.: 41.41%] [G loss: 0.694195]\n",
      "epoch:4 step:3804 [D loss: 0.684056, acc.: 57.03%] [G loss: 0.716121]\n",
      "epoch:4 step:3805 [D loss: 0.705088, acc.: 46.88%] [G loss: 0.763528]\n",
      "epoch:4 step:3806 [D loss: 0.735126, acc.: 44.53%] [G loss: 0.733633]\n",
      "epoch:4 step:3807 [D loss: 0.690220, acc.: 53.12%] [G loss: 0.731257]\n",
      "epoch:4 step:3808 [D loss: 0.696575, acc.: 57.03%] [G loss: 0.731109]\n",
      "epoch:4 step:3809 [D loss: 0.708714, acc.: 46.88%] [G loss: 0.734251]\n",
      "epoch:4 step:3810 [D loss: 0.692551, acc.: 54.69%] [G loss: 0.733019]\n",
      "epoch:4 step:3811 [D loss: 0.688430, acc.: 53.12%] [G loss: 0.749371]\n",
      "epoch:4 step:3812 [D loss: 0.682906, acc.: 56.25%] [G loss: 0.756218]\n",
      "epoch:4 step:3813 [D loss: 0.693023, acc.: 55.47%] [G loss: 0.736962]\n",
      "epoch:4 step:3814 [D loss: 0.695704, acc.: 50.78%] [G loss: 0.742374]\n",
      "epoch:4 step:3815 [D loss: 0.673767, acc.: 62.50%] [G loss: 0.752448]\n",
      "epoch:4 step:3816 [D loss: 0.695664, acc.: 50.78%] [G loss: 0.756578]\n",
      "epoch:4 step:3817 [D loss: 0.682944, acc.: 57.03%] [G loss: 0.748292]\n",
      "epoch:4 step:3818 [D loss: 0.688320, acc.: 57.03%] [G loss: 0.721478]\n",
      "epoch:4 step:3819 [D loss: 0.704710, acc.: 53.12%] [G loss: 0.701149]\n",
      "epoch:4 step:3820 [D loss: 0.689690, acc.: 52.34%] [G loss: 0.718313]\n",
      "epoch:4 step:3821 [D loss: 0.687449, acc.: 58.59%] [G loss: 0.695127]\n",
      "epoch:4 step:3822 [D loss: 0.698418, acc.: 53.12%] [G loss: 0.699168]\n",
      "epoch:4 step:3823 [D loss: 0.714068, acc.: 38.28%] [G loss: 0.693755]\n",
      "epoch:4 step:3824 [D loss: 0.688516, acc.: 53.91%] [G loss: 0.717383]\n",
      "epoch:4 step:3825 [D loss: 0.696831, acc.: 51.56%] [G loss: 0.729479]\n",
      "epoch:4 step:3826 [D loss: 0.692786, acc.: 51.56%] [G loss: 0.719545]\n",
      "epoch:4 step:3827 [D loss: 0.703762, acc.: 48.44%] [G loss: 0.737633]\n",
      "epoch:4 step:3828 [D loss: 0.703089, acc.: 47.66%] [G loss: 0.721591]\n",
      "epoch:4 step:3829 [D loss: 0.691046, acc.: 53.91%] [G loss: 0.710756]\n",
      "epoch:4 step:3830 [D loss: 0.701343, acc.: 43.75%] [G loss: 0.716233]\n",
      "epoch:4 step:3831 [D loss: 0.693584, acc.: 55.47%] [G loss: 0.721545]\n",
      "epoch:4 step:3832 [D loss: 0.692075, acc.: 55.47%] [G loss: 0.738170]\n",
      "epoch:4 step:3833 [D loss: 0.689816, acc.: 53.12%] [G loss: 0.703860]\n",
      "epoch:4 step:3834 [D loss: 0.701965, acc.: 50.00%] [G loss: 0.712360]\n",
      "epoch:4 step:3835 [D loss: 0.693051, acc.: 47.66%] [G loss: 0.715769]\n",
      "epoch:4 step:3836 [D loss: 0.690068, acc.: 57.03%] [G loss: 0.731176]\n",
      "epoch:4 step:3837 [D loss: 0.677871, acc.: 60.16%] [G loss: 0.715961]\n",
      "epoch:4 step:3838 [D loss: 0.690614, acc.: 62.50%] [G loss: 0.727129]\n",
      "epoch:4 step:3839 [D loss: 0.691321, acc.: 54.69%] [G loss: 0.733850]\n",
      "epoch:4 step:3840 [D loss: 0.674125, acc.: 62.50%] [G loss: 0.748500]\n",
      "epoch:4 step:3841 [D loss: 0.654152, acc.: 62.50%] [G loss: 0.747120]\n",
      "epoch:4 step:3842 [D loss: 0.691423, acc.: 53.12%] [G loss: 0.720355]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3843 [D loss: 0.713572, acc.: 46.88%] [G loss: 0.710764]\n",
      "epoch:4 step:3844 [D loss: 0.704581, acc.: 44.53%] [G loss: 0.700023]\n",
      "epoch:4 step:3845 [D loss: 0.704190, acc.: 47.66%] [G loss: 0.710704]\n",
      "epoch:4 step:3846 [D loss: 0.697899, acc.: 46.09%] [G loss: 0.717490]\n",
      "epoch:4 step:3847 [D loss: 0.678333, acc.: 57.81%] [G loss: 0.729515]\n",
      "epoch:4 step:3848 [D loss: 0.685301, acc.: 55.47%] [G loss: 0.725611]\n",
      "epoch:4 step:3849 [D loss: 0.694996, acc.: 52.34%] [G loss: 0.725891]\n",
      "epoch:4 step:3850 [D loss: 0.682620, acc.: 61.72%] [G loss: 0.693994]\n",
      "epoch:4 step:3851 [D loss: 0.694752, acc.: 49.22%] [G loss: 0.745672]\n",
      "epoch:4 step:3852 [D loss: 0.698142, acc.: 49.22%] [G loss: 0.775015]\n",
      "epoch:4 step:3853 [D loss: 0.701712, acc.: 46.09%] [G loss: 0.755616]\n",
      "epoch:4 step:3854 [D loss: 0.672412, acc.: 62.50%] [G loss: 0.753155]\n",
      "epoch:4 step:3855 [D loss: 0.698690, acc.: 50.78%] [G loss: 0.740324]\n",
      "epoch:4 step:3856 [D loss: 0.696846, acc.: 49.22%] [G loss: 0.758575]\n",
      "epoch:4 step:3857 [D loss: 0.686476, acc.: 50.00%] [G loss: 0.736600]\n",
      "epoch:4 step:3858 [D loss: 0.698180, acc.: 49.22%] [G loss: 0.771986]\n",
      "epoch:4 step:3859 [D loss: 0.706405, acc.: 47.66%] [G loss: 0.742389]\n",
      "epoch:4 step:3860 [D loss: 0.683903, acc.: 50.78%] [G loss: 0.728404]\n",
      "epoch:4 step:3861 [D loss: 0.709100, acc.: 46.88%] [G loss: 0.720238]\n",
      "epoch:4 step:3862 [D loss: 0.707265, acc.: 46.88%] [G loss: 0.763228]\n",
      "epoch:4 step:3863 [D loss: 0.697199, acc.: 52.34%] [G loss: 0.717814]\n",
      "epoch:4 step:3864 [D loss: 0.701479, acc.: 47.66%] [G loss: 0.729485]\n",
      "epoch:4 step:3865 [D loss: 0.689330, acc.: 57.03%] [G loss: 0.724472]\n",
      "epoch:4 step:3866 [D loss: 0.669736, acc.: 64.06%] [G loss: 0.730826]\n",
      "epoch:4 step:3867 [D loss: 0.678358, acc.: 57.03%] [G loss: 0.746150]\n",
      "epoch:4 step:3868 [D loss: 0.709425, acc.: 46.88%] [G loss: 0.743349]\n",
      "epoch:4 step:3869 [D loss: 0.711421, acc.: 46.09%] [G loss: 0.757781]\n",
      "epoch:4 step:3870 [D loss: 0.703380, acc.: 46.09%] [G loss: 0.743102]\n",
      "epoch:4 step:3871 [D loss: 0.697260, acc.: 50.00%] [G loss: 0.733243]\n",
      "epoch:4 step:3872 [D loss: 0.709893, acc.: 49.22%] [G loss: 0.752869]\n",
      "epoch:4 step:3873 [D loss: 0.702828, acc.: 42.97%] [G loss: 0.736861]\n",
      "epoch:4 step:3874 [D loss: 0.674788, acc.: 62.50%] [G loss: 0.750590]\n",
      "epoch:4 step:3875 [D loss: 0.687560, acc.: 57.81%] [G loss: 0.759715]\n",
      "epoch:4 step:3876 [D loss: 0.694296, acc.: 46.88%] [G loss: 0.774174]\n",
      "epoch:4 step:3877 [D loss: 0.684609, acc.: 58.59%] [G loss: 0.782013]\n",
      "epoch:4 step:3878 [D loss: 0.667000, acc.: 54.69%] [G loss: 0.773266]\n",
      "epoch:4 step:3879 [D loss: 0.671868, acc.: 63.28%] [G loss: 0.774019]\n",
      "epoch:4 step:3880 [D loss: 0.696219, acc.: 50.78%] [G loss: 0.791631]\n",
      "epoch:4 step:3881 [D loss: 0.666505, acc.: 62.50%] [G loss: 0.732457]\n",
      "epoch:4 step:3882 [D loss: 0.688412, acc.: 55.47%] [G loss: 0.745566]\n",
      "epoch:4 step:3883 [D loss: 0.674168, acc.: 55.47%] [G loss: 0.726117]\n",
      "epoch:4 step:3884 [D loss: 0.704269, acc.: 53.12%] [G loss: 0.691450]\n",
      "epoch:4 step:3885 [D loss: 0.747585, acc.: 41.41%] [G loss: 0.696931]\n",
      "epoch:4 step:3886 [D loss: 0.731331, acc.: 37.50%] [G loss: 0.705406]\n",
      "epoch:4 step:3887 [D loss: 0.699602, acc.: 46.88%] [G loss: 0.712230]\n",
      "epoch:4 step:3888 [D loss: 0.712566, acc.: 39.84%] [G loss: 0.722196]\n",
      "epoch:4 step:3889 [D loss: 0.706564, acc.: 40.62%] [G loss: 0.738880]\n",
      "epoch:4 step:3890 [D loss: 0.686154, acc.: 50.78%] [G loss: 0.752005]\n",
      "epoch:4 step:3891 [D loss: 0.685719, acc.: 51.56%] [G loss: 0.841132]\n",
      "epoch:4 step:3892 [D loss: 0.656751, acc.: 60.16%] [G loss: 0.771028]\n",
      "epoch:4 step:3893 [D loss: 0.651547, acc.: 64.06%] [G loss: 0.843131]\n",
      "epoch:4 step:3894 [D loss: 0.670685, acc.: 56.25%] [G loss: 0.892549]\n",
      "epoch:4 step:3895 [D loss: 0.701219, acc.: 45.31%] [G loss: 0.781749]\n",
      "epoch:4 step:3896 [D loss: 0.683780, acc.: 58.59%] [G loss: 0.759158]\n",
      "epoch:4 step:3897 [D loss: 0.695655, acc.: 53.12%] [G loss: 0.730170]\n",
      "epoch:4 step:3898 [D loss: 0.708383, acc.: 43.75%] [G loss: 0.684172]\n",
      "epoch:4 step:3899 [D loss: 0.704235, acc.: 50.78%] [G loss: 0.709701]\n",
      "epoch:4 step:3900 [D loss: 0.707520, acc.: 50.00%] [G loss: 0.700416]\n",
      "epoch:4 step:3901 [D loss: 0.732028, acc.: 41.41%] [G loss: 0.693327]\n",
      "epoch:4 step:3902 [D loss: 0.702967, acc.: 51.56%] [G loss: 0.669221]\n",
      "epoch:4 step:3903 [D loss: 0.706679, acc.: 46.09%] [G loss: 0.703386]\n",
      "epoch:4 step:3904 [D loss: 0.700507, acc.: 50.00%] [G loss: 0.704941]\n",
      "epoch:4 step:3905 [D loss: 0.697828, acc.: 50.00%] [G loss: 0.710109]\n",
      "epoch:4 step:3906 [D loss: 0.692993, acc.: 51.56%] [G loss: 0.733647]\n",
      "epoch:4 step:3907 [D loss: 0.691118, acc.: 51.56%] [G loss: 0.736179]\n",
      "epoch:4 step:3908 [D loss: 0.694351, acc.: 45.31%] [G loss: 0.725895]\n",
      "epoch:4 step:3909 [D loss: 0.704920, acc.: 46.88%] [G loss: 0.776826]\n",
      "epoch:4 step:3910 [D loss: 0.678169, acc.: 60.94%] [G loss: 0.748935]\n",
      "epoch:4 step:3911 [D loss: 0.687396, acc.: 53.12%] [G loss: 0.796230]\n",
      "epoch:4 step:3912 [D loss: 0.662406, acc.: 60.94%] [G loss: 0.742255]\n",
      "epoch:4 step:3913 [D loss: 0.676908, acc.: 53.12%] [G loss: 0.761299]\n",
      "epoch:4 step:3914 [D loss: 0.676802, acc.: 57.81%] [G loss: 0.737349]\n",
      "epoch:4 step:3915 [D loss: 0.698310, acc.: 46.09%] [G loss: 0.697770]\n",
      "epoch:4 step:3916 [D loss: 0.713891, acc.: 48.44%] [G loss: 0.706318]\n",
      "epoch:4 step:3917 [D loss: 0.700392, acc.: 48.44%] [G loss: 0.690655]\n",
      "epoch:4 step:3918 [D loss: 0.685713, acc.: 57.81%] [G loss: 0.718709]\n",
      "epoch:4 step:3919 [D loss: 0.705510, acc.: 49.22%] [G loss: 0.681171]\n",
      "epoch:4 step:3920 [D loss: 0.707305, acc.: 50.78%] [G loss: 0.699250]\n",
      "epoch:4 step:3921 [D loss: 0.703677, acc.: 46.09%] [G loss: 0.690599]\n",
      "epoch:4 step:3922 [D loss: 0.715648, acc.: 46.88%] [G loss: 0.694641]\n",
      "epoch:4 step:3923 [D loss: 0.695452, acc.: 53.91%] [G loss: 0.719413]\n",
      "epoch:4 step:3924 [D loss: 0.682472, acc.: 52.34%] [G loss: 0.734817]\n",
      "epoch:4 step:3925 [D loss: 0.684188, acc.: 56.25%] [G loss: 0.743993]\n",
      "epoch:4 step:3926 [D loss: 0.669105, acc.: 61.72%] [G loss: 0.776576]\n",
      "epoch:4 step:3927 [D loss: 0.687778, acc.: 46.09%] [G loss: 0.777587]\n",
      "epoch:4 step:3928 [D loss: 0.687510, acc.: 58.59%] [G loss: 0.817034]\n",
      "epoch:4 step:3929 [D loss: 0.664897, acc.: 57.03%] [G loss: 0.778133]\n",
      "epoch:4 step:3930 [D loss: 0.670396, acc.: 64.06%] [G loss: 0.780288]\n",
      "epoch:4 step:3931 [D loss: 0.704360, acc.: 46.88%] [G loss: 0.783290]\n",
      "epoch:4 step:3932 [D loss: 0.673475, acc.: 58.59%] [G loss: 0.758091]\n",
      "epoch:4 step:3933 [D loss: 0.705438, acc.: 44.53%] [G loss: 0.746040]\n",
      "epoch:4 step:3934 [D loss: 0.711164, acc.: 47.66%] [G loss: 0.733522]\n",
      "epoch:4 step:3935 [D loss: 0.696117, acc.: 53.12%] [G loss: 0.733475]\n",
      "epoch:4 step:3936 [D loss: 0.704523, acc.: 43.75%] [G loss: 0.708643]\n",
      "epoch:4 step:3937 [D loss: 0.719451, acc.: 39.84%] [G loss: 0.724827]\n",
      "epoch:4 step:3938 [D loss: 0.695126, acc.: 45.31%] [G loss: 0.714502]\n",
      "epoch:4 step:3939 [D loss: 0.683967, acc.: 54.69%] [G loss: 0.727749]\n",
      "epoch:4 step:3940 [D loss: 0.672218, acc.: 61.72%] [G loss: 0.725702]\n",
      "epoch:4 step:3941 [D loss: 0.678398, acc.: 55.47%] [G loss: 0.759926]\n",
      "epoch:4 step:3942 [D loss: 0.676896, acc.: 53.12%] [G loss: 0.767872]\n",
      "epoch:4 step:3943 [D loss: 0.665757, acc.: 60.16%] [G loss: 0.755126]\n",
      "epoch:4 step:3944 [D loss: 0.667698, acc.: 60.16%] [G loss: 0.772812]\n",
      "epoch:4 step:3945 [D loss: 0.672570, acc.: 56.25%] [G loss: 0.780409]\n",
      "epoch:4 step:3946 [D loss: 0.674912, acc.: 60.94%] [G loss: 0.767995]\n",
      "epoch:4 step:3947 [D loss: 0.693298, acc.: 56.25%] [G loss: 0.742286]\n",
      "epoch:4 step:3948 [D loss: 0.726029, acc.: 48.44%] [G loss: 0.743807]\n",
      "epoch:4 step:3949 [D loss: 0.715545, acc.: 40.62%] [G loss: 0.736077]\n",
      "epoch:4 step:3950 [D loss: 0.682695, acc.: 53.91%] [G loss: 0.750295]\n",
      "epoch:4 step:3951 [D loss: 0.693225, acc.: 47.66%] [G loss: 0.717947]\n",
      "epoch:4 step:3952 [D loss: 0.677050, acc.: 55.47%] [G loss: 0.734485]\n",
      "epoch:4 step:3953 [D loss: 0.691470, acc.: 57.03%] [G loss: 0.676809]\n",
      "epoch:4 step:3954 [D loss: 0.678473, acc.: 57.81%] [G loss: 0.660121]\n",
      "epoch:4 step:3955 [D loss: 0.687544, acc.: 52.34%] [G loss: 0.730990]\n",
      "epoch:4 step:3956 [D loss: 0.692149, acc.: 50.78%] [G loss: 0.659776]\n",
      "epoch:4 step:3957 [D loss: 0.691072, acc.: 48.44%] [G loss: 0.684358]\n",
      "epoch:4 step:3958 [D loss: 0.724249, acc.: 50.00%] [G loss: 0.730076]\n",
      "epoch:4 step:3959 [D loss: 0.708278, acc.: 38.28%] [G loss: 0.695447]\n",
      "epoch:4 step:3960 [D loss: 0.701718, acc.: 44.53%] [G loss: 0.739245]\n",
      "epoch:4 step:3961 [D loss: 0.697244, acc.: 45.31%] [G loss: 0.757032]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3962 [D loss: 0.681880, acc.: 54.69%] [G loss: 0.744019]\n",
      "epoch:4 step:3963 [D loss: 0.692240, acc.: 51.56%] [G loss: 0.722634]\n",
      "epoch:4 step:3964 [D loss: 0.679122, acc.: 55.47%] [G loss: 0.760629]\n",
      "epoch:4 step:3965 [D loss: 0.684429, acc.: 55.47%] [G loss: 0.770211]\n",
      "epoch:4 step:3966 [D loss: 0.677285, acc.: 57.81%] [G loss: 0.736673]\n",
      "epoch:4 step:3967 [D loss: 0.656242, acc.: 66.41%] [G loss: 0.781910]\n",
      "epoch:4 step:3968 [D loss: 0.733144, acc.: 42.19%] [G loss: 0.729823]\n",
      "epoch:4 step:3969 [D loss: 0.707330, acc.: 42.97%] [G loss: 0.738849]\n",
      "epoch:4 step:3970 [D loss: 0.687398, acc.: 48.44%] [G loss: 0.732400]\n",
      "epoch:4 step:3971 [D loss: 0.695505, acc.: 47.66%] [G loss: 0.722686]\n",
      "epoch:4 step:3972 [D loss: 0.712183, acc.: 48.44%] [G loss: 0.736239]\n",
      "epoch:4 step:3973 [D loss: 0.699972, acc.: 44.53%] [G loss: 0.722822]\n",
      "epoch:4 step:3974 [D loss: 0.701214, acc.: 50.78%] [G loss: 0.739328]\n",
      "epoch:4 step:3975 [D loss: 0.705517, acc.: 44.53%] [G loss: 0.776181]\n",
      "epoch:4 step:3976 [D loss: 0.694029, acc.: 49.22%] [G loss: 0.752167]\n",
      "epoch:4 step:3977 [D loss: 0.679761, acc.: 59.38%] [G loss: 0.751983]\n",
      "epoch:4 step:3978 [D loss: 0.655580, acc.: 71.88%] [G loss: 0.789602]\n",
      "epoch:4 step:3979 [D loss: 0.679916, acc.: 57.81%] [G loss: 0.732566]\n",
      "epoch:4 step:3980 [D loss: 0.649118, acc.: 60.94%] [G loss: 0.801463]\n",
      "epoch:4 step:3981 [D loss: 0.722267, acc.: 39.06%] [G loss: 0.717586]\n",
      "epoch:4 step:3982 [D loss: 0.707245, acc.: 48.44%] [G loss: 0.755597]\n",
      "epoch:4 step:3983 [D loss: 0.697448, acc.: 54.69%] [G loss: 0.750012]\n",
      "epoch:4 step:3984 [D loss: 0.704875, acc.: 52.34%] [G loss: 0.719675]\n",
      "epoch:4 step:3985 [D loss: 0.709833, acc.: 43.75%] [G loss: 0.716541]\n",
      "epoch:4 step:3986 [D loss: 0.700242, acc.: 50.78%] [G loss: 0.725776]\n",
      "epoch:4 step:3987 [D loss: 0.704694, acc.: 46.88%] [G loss: 0.726319]\n",
      "epoch:4 step:3988 [D loss: 0.712296, acc.: 44.53%] [G loss: 0.717318]\n",
      "epoch:4 step:3989 [D loss: 0.709207, acc.: 45.31%] [G loss: 0.731071]\n",
      "epoch:4 step:3990 [D loss: 0.685755, acc.: 53.91%] [G loss: 0.733560]\n",
      "epoch:4 step:3991 [D loss: 0.686282, acc.: 59.38%] [G loss: 0.745486]\n",
      "epoch:4 step:3992 [D loss: 0.694563, acc.: 53.12%] [G loss: 0.761343]\n",
      "epoch:4 step:3993 [D loss: 0.692534, acc.: 51.56%] [G loss: 0.732726]\n",
      "epoch:4 step:3994 [D loss: 0.695256, acc.: 48.44%] [G loss: 0.759970]\n",
      "epoch:4 step:3995 [D loss: 0.681903, acc.: 60.16%] [G loss: 0.748102]\n",
      "epoch:4 step:3996 [D loss: 0.682107, acc.: 53.91%] [G loss: 0.732759]\n",
      "epoch:4 step:3997 [D loss: 0.703359, acc.: 46.09%] [G loss: 0.734034]\n",
      "epoch:4 step:3998 [D loss: 0.701541, acc.: 46.09%] [G loss: 0.724843]\n",
      "epoch:4 step:3999 [D loss: 0.710452, acc.: 34.38%] [G loss: 0.720058]\n",
      "epoch:4 step:4000 [D loss: 0.702503, acc.: 45.31%] [G loss: 0.726402]\n",
      "##############\n",
      "[3.49799717 2.30141896 6.27891274 5.14152008 4.45626807 6.03234556\n",
      " 5.19031383 5.52371523 5.27396771 4.47757157]\n",
      "##########\n",
      "epoch:4 step:4001 [D loss: 0.695017, acc.: 51.56%] [G loss: 0.715787]\n",
      "epoch:4 step:4002 [D loss: 0.703548, acc.: 44.53%] [G loss: 0.719698]\n",
      "epoch:4 step:4003 [D loss: 0.702544, acc.: 40.62%] [G loss: 0.725402]\n",
      "epoch:4 step:4004 [D loss: 0.696972, acc.: 54.69%] [G loss: 0.706282]\n",
      "epoch:4 step:4005 [D loss: 0.696044, acc.: 53.91%] [G loss: 0.718129]\n",
      "epoch:4 step:4006 [D loss: 0.687968, acc.: 50.00%] [G loss: 0.726035]\n",
      "epoch:4 step:4007 [D loss: 0.687493, acc.: 53.91%] [G loss: 0.728505]\n",
      "epoch:4 step:4008 [D loss: 0.690165, acc.: 50.00%] [G loss: 0.728890]\n",
      "epoch:4 step:4009 [D loss: 0.700667, acc.: 51.56%] [G loss: 0.748365]\n",
      "epoch:4 step:4010 [D loss: 0.682919, acc.: 58.59%] [G loss: 0.742091]\n",
      "epoch:4 step:4011 [D loss: 0.732197, acc.: 37.50%] [G loss: 0.735395]\n",
      "epoch:4 step:4012 [D loss: 0.696179, acc.: 53.91%] [G loss: 0.734339]\n",
      "epoch:4 step:4013 [D loss: 0.704019, acc.: 45.31%] [G loss: 0.729477]\n",
      "epoch:4 step:4014 [D loss: 0.697033, acc.: 43.75%] [G loss: 0.729136]\n",
      "epoch:4 step:4015 [D loss: 0.689468, acc.: 51.56%] [G loss: 0.723060]\n",
      "epoch:4 step:4016 [D loss: 0.688294, acc.: 55.47%] [G loss: 0.712435]\n",
      "epoch:4 step:4017 [D loss: 0.678855, acc.: 57.03%] [G loss: 0.742228]\n",
      "epoch:4 step:4018 [D loss: 0.690030, acc.: 57.81%] [G loss: 0.712631]\n",
      "epoch:4 step:4019 [D loss: 0.676244, acc.: 60.16%] [G loss: 0.700342]\n",
      "epoch:4 step:4020 [D loss: 0.700809, acc.: 46.09%] [G loss: 0.732302]\n",
      "epoch:4 step:4021 [D loss: 0.703686, acc.: 46.09%] [G loss: 0.717279]\n",
      "epoch:4 step:4022 [D loss: 0.671406, acc.: 57.03%] [G loss: 0.732715]\n",
      "epoch:4 step:4023 [D loss: 0.700416, acc.: 50.00%] [G loss: 0.732617]\n",
      "epoch:4 step:4024 [D loss: 0.675287, acc.: 52.34%] [G loss: 0.733323]\n",
      "epoch:4 step:4025 [D loss: 0.685704, acc.: 54.69%] [G loss: 0.716571]\n",
      "epoch:4 step:4026 [D loss: 0.701875, acc.: 50.78%] [G loss: 0.745692]\n",
      "epoch:4 step:4027 [D loss: 0.698588, acc.: 49.22%] [G loss: 0.712076]\n",
      "epoch:4 step:4028 [D loss: 0.706113, acc.: 46.88%] [G loss: 0.701825]\n",
      "epoch:4 step:4029 [D loss: 0.727243, acc.: 41.41%] [G loss: 0.709033]\n",
      "epoch:4 step:4030 [D loss: 0.704613, acc.: 41.41%] [G loss: 0.739204]\n",
      "epoch:4 step:4031 [D loss: 0.694667, acc.: 50.78%] [G loss: 0.735784]\n",
      "epoch:4 step:4032 [D loss: 0.691761, acc.: 50.78%] [G loss: 0.753469]\n",
      "epoch:4 step:4033 [D loss: 0.677943, acc.: 58.59%] [G loss: 0.744842]\n",
      "epoch:4 step:4034 [D loss: 0.679125, acc.: 62.50%] [G loss: 0.751198]\n",
      "epoch:4 step:4035 [D loss: 0.692798, acc.: 51.56%] [G loss: 0.750100]\n",
      "epoch:4 step:4036 [D loss: 0.703154, acc.: 52.34%] [G loss: 0.735495]\n",
      "epoch:4 step:4037 [D loss: 0.682336, acc.: 57.03%] [G loss: 0.731560]\n",
      "epoch:4 step:4038 [D loss: 0.668309, acc.: 55.47%] [G loss: 0.720601]\n",
      "epoch:4 step:4039 [D loss: 0.713681, acc.: 43.75%] [G loss: 0.756727]\n",
      "epoch:4 step:4040 [D loss: 0.697397, acc.: 53.91%] [G loss: 0.746057]\n",
      "epoch:4 step:4041 [D loss: 0.695430, acc.: 48.44%] [G loss: 0.734880]\n",
      "epoch:4 step:4042 [D loss: 0.699446, acc.: 50.00%] [G loss: 0.745367]\n",
      "epoch:4 step:4043 [D loss: 0.726115, acc.: 39.06%] [G loss: 0.726511]\n",
      "epoch:4 step:4044 [D loss: 0.696457, acc.: 58.59%] [G loss: 0.738171]\n",
      "epoch:4 step:4045 [D loss: 0.727405, acc.: 33.59%] [G loss: 0.704821]\n",
      "epoch:4 step:4046 [D loss: 0.705341, acc.: 42.19%] [G loss: 0.692470]\n",
      "epoch:4 step:4047 [D loss: 0.699100, acc.: 48.44%] [G loss: 0.698821]\n",
      "epoch:4 step:4048 [D loss: 0.696814, acc.: 42.19%] [G loss: 0.712587]\n",
      "epoch:4 step:4049 [D loss: 0.687463, acc.: 48.44%] [G loss: 0.709588]\n",
      "epoch:4 step:4050 [D loss: 0.696532, acc.: 52.34%] [G loss: 0.707876]\n",
      "epoch:4 step:4051 [D loss: 0.687998, acc.: 53.91%] [G loss: 0.725764]\n",
      "epoch:4 step:4052 [D loss: 0.693753, acc.: 44.53%] [G loss: 0.716734]\n",
      "epoch:4 step:4053 [D loss: 0.684118, acc.: 60.16%] [G loss: 0.717734]\n",
      "epoch:4 step:4054 [D loss: 0.676197, acc.: 57.81%] [G loss: 0.711846]\n",
      "epoch:4 step:4055 [D loss: 0.680816, acc.: 56.25%] [G loss: 0.731664]\n",
      "epoch:4 step:4056 [D loss: 0.690289, acc.: 53.91%] [G loss: 0.719860]\n",
      "epoch:4 step:4057 [D loss: 0.686936, acc.: 58.59%] [G loss: 0.700312]\n",
      "epoch:4 step:4058 [D loss: 0.671551, acc.: 57.03%] [G loss: 0.734156]\n",
      "epoch:4 step:4059 [D loss: 0.697482, acc.: 52.34%] [G loss: 0.715116]\n",
      "epoch:4 step:4060 [D loss: 0.696097, acc.: 53.12%] [G loss: 0.714904]\n",
      "epoch:4 step:4061 [D loss: 0.659799, acc.: 62.50%] [G loss: 0.744094]\n",
      "epoch:4 step:4062 [D loss: 0.670552, acc.: 57.03%] [G loss: 0.723190]\n",
      "epoch:4 step:4063 [D loss: 0.682853, acc.: 51.56%] [G loss: 0.734729]\n",
      "epoch:4 step:4064 [D loss: 0.722726, acc.: 44.53%] [G loss: 0.766917]\n",
      "epoch:4 step:4065 [D loss: 0.685938, acc.: 54.69%] [G loss: 0.765320]\n",
      "epoch:4 step:4066 [D loss: 0.673517, acc.: 62.50%] [G loss: 0.736911]\n",
      "epoch:4 step:4067 [D loss: 0.696527, acc.: 50.78%] [G loss: 0.764087]\n",
      "epoch:4 step:4068 [D loss: 0.707657, acc.: 44.53%] [G loss: 0.770314]\n",
      "epoch:4 step:4069 [D loss: 0.738271, acc.: 39.84%] [G loss: 0.742309]\n",
      "epoch:4 step:4070 [D loss: 0.680763, acc.: 57.03%] [G loss: 0.779204]\n",
      "epoch:4 step:4071 [D loss: 0.713790, acc.: 47.66%] [G loss: 0.730895]\n",
      "epoch:4 step:4072 [D loss: 0.687514, acc.: 54.69%] [G loss: 0.728899]\n",
      "epoch:4 step:4073 [D loss: 0.668309, acc.: 64.06%] [G loss: 0.753955]\n",
      "epoch:4 step:4074 [D loss: 0.679480, acc.: 50.00%] [G loss: 0.737317]\n",
      "epoch:4 step:4075 [D loss: 0.674441, acc.: 60.94%] [G loss: 0.743096]\n",
      "epoch:4 step:4076 [D loss: 0.682235, acc.: 55.47%] [G loss: 0.770446]\n",
      "epoch:4 step:4077 [D loss: 0.697644, acc.: 50.00%] [G loss: 0.767755]\n",
      "epoch:4 step:4078 [D loss: 0.699619, acc.: 46.09%] [G loss: 0.742558]\n",
      "epoch:4 step:4079 [D loss: 0.697518, acc.: 50.78%] [G loss: 0.717297]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4080 [D loss: 0.676599, acc.: 58.59%] [G loss: 0.747945]\n",
      "epoch:4 step:4081 [D loss: 0.699907, acc.: 56.25%] [G loss: 0.763748]\n",
      "epoch:4 step:4082 [D loss: 0.696687, acc.: 47.66%] [G loss: 0.736182]\n",
      "epoch:4 step:4083 [D loss: 0.707504, acc.: 43.75%] [G loss: 0.740424]\n",
      "epoch:4 step:4084 [D loss: 0.681682, acc.: 61.72%] [G loss: 0.748145]\n",
      "epoch:4 step:4085 [D loss: 0.691473, acc.: 53.12%] [G loss: 0.777875]\n",
      "epoch:4 step:4086 [D loss: 0.682009, acc.: 55.47%] [G loss: 0.726976]\n",
      "epoch:4 step:4087 [D loss: 0.690268, acc.: 51.56%] [G loss: 0.755652]\n",
      "epoch:4 step:4088 [D loss: 0.704960, acc.: 51.56%] [G loss: 0.723827]\n",
      "epoch:4 step:4089 [D loss: 0.687104, acc.: 53.91%] [G loss: 0.727422]\n",
      "epoch:4 step:4090 [D loss: 0.693217, acc.: 56.25%] [G loss: 0.738875]\n",
      "epoch:4 step:4091 [D loss: 0.689368, acc.: 51.56%] [G loss: 0.741890]\n",
      "epoch:4 step:4092 [D loss: 0.665084, acc.: 64.06%] [G loss: 0.739951]\n",
      "epoch:4 step:4093 [D loss: 0.719793, acc.: 41.41%] [G loss: 0.729644]\n",
      "epoch:4 step:4094 [D loss: 0.706878, acc.: 42.19%] [G loss: 0.744391]\n",
      "epoch:4 step:4095 [D loss: 0.664564, acc.: 64.84%] [G loss: 0.763891]\n",
      "epoch:4 step:4096 [D loss: 0.705985, acc.: 48.44%] [G loss: 0.758227]\n",
      "epoch:4 step:4097 [D loss: 0.713462, acc.: 44.53%] [G loss: 0.745365]\n",
      "epoch:4 step:4098 [D loss: 0.692776, acc.: 51.56%] [G loss: 0.778948]\n",
      "epoch:4 step:4099 [D loss: 0.693312, acc.: 54.69%] [G loss: 0.777887]\n",
      "epoch:4 step:4100 [D loss: 0.695357, acc.: 51.56%] [G loss: 0.821906]\n",
      "epoch:4 step:4101 [D loss: 0.707964, acc.: 46.09%] [G loss: 0.759466]\n",
      "epoch:4 step:4102 [D loss: 0.701242, acc.: 50.78%] [G loss: 0.748823]\n",
      "epoch:4 step:4103 [D loss: 0.695062, acc.: 46.88%] [G loss: 0.757954]\n",
      "epoch:4 step:4104 [D loss: 0.695718, acc.: 47.66%] [G loss: 0.731899]\n",
      "epoch:4 step:4105 [D loss: 0.699145, acc.: 47.66%] [G loss: 0.714949]\n",
      "epoch:4 step:4106 [D loss: 0.686293, acc.: 57.81%] [G loss: 0.740100]\n",
      "epoch:4 step:4107 [D loss: 0.690681, acc.: 48.44%] [G loss: 0.754446]\n",
      "epoch:4 step:4108 [D loss: 0.683605, acc.: 54.69%] [G loss: 0.750302]\n",
      "epoch:4 step:4109 [D loss: 0.688501, acc.: 53.12%] [G loss: 0.768179]\n",
      "epoch:4 step:4110 [D loss: 0.678257, acc.: 60.94%] [G loss: 0.742802]\n",
      "epoch:4 step:4111 [D loss: 0.692661, acc.: 46.09%] [G loss: 0.741016]\n",
      "epoch:4 step:4112 [D loss: 0.660789, acc.: 57.03%] [G loss: 0.790349]\n",
      "epoch:4 step:4113 [D loss: 0.681680, acc.: 57.03%] [G loss: 0.779911]\n",
      "epoch:4 step:4114 [D loss: 0.676507, acc.: 54.69%] [G loss: 0.757294]\n",
      "epoch:4 step:4115 [D loss: 0.701540, acc.: 52.34%] [G loss: 0.756434]\n",
      "epoch:4 step:4116 [D loss: 0.700408, acc.: 45.31%] [G loss: 0.721597]\n",
      "epoch:4 step:4117 [D loss: 0.713420, acc.: 43.75%] [G loss: 0.745109]\n",
      "epoch:4 step:4118 [D loss: 0.705573, acc.: 50.78%] [G loss: 0.719071]\n",
      "epoch:4 step:4119 [D loss: 0.719116, acc.: 43.75%] [G loss: 0.689177]\n",
      "epoch:4 step:4120 [D loss: 0.715033, acc.: 42.97%] [G loss: 0.694807]\n",
      "epoch:4 step:4121 [D loss: 0.691919, acc.: 48.44%] [G loss: 0.695563]\n",
      "epoch:4 step:4122 [D loss: 0.693485, acc.: 53.12%] [G loss: 0.708609]\n",
      "epoch:4 step:4123 [D loss: 0.692932, acc.: 53.91%] [G loss: 0.720766]\n",
      "epoch:4 step:4124 [D loss: 0.691714, acc.: 47.66%] [G loss: 0.722924]\n",
      "epoch:4 step:4125 [D loss: 0.692215, acc.: 47.66%] [G loss: 0.709890]\n",
      "epoch:4 step:4126 [D loss: 0.681621, acc.: 58.59%] [G loss: 0.730244]\n",
      "epoch:4 step:4127 [D loss: 0.691454, acc.: 51.56%] [G loss: 0.735907]\n",
      "epoch:4 step:4128 [D loss: 0.674334, acc.: 57.81%] [G loss: 0.739172]\n",
      "epoch:4 step:4129 [D loss: 0.672486, acc.: 63.28%] [G loss: 0.737820]\n",
      "epoch:4 step:4130 [D loss: 0.681574, acc.: 54.69%] [G loss: 0.747284]\n",
      "epoch:4 step:4131 [D loss: 0.693536, acc.: 53.12%] [G loss: 0.754064]\n",
      "epoch:4 step:4132 [D loss: 0.699307, acc.: 51.56%] [G loss: 0.725313]\n",
      "epoch:4 step:4133 [D loss: 0.687890, acc.: 54.69%] [G loss: 0.706223]\n",
      "epoch:4 step:4134 [D loss: 0.723744, acc.: 39.84%] [G loss: 0.702810]\n",
      "epoch:4 step:4135 [D loss: 0.702639, acc.: 47.66%] [G loss: 0.692057]\n",
      "epoch:4 step:4136 [D loss: 0.694050, acc.: 50.00%] [G loss: 0.703100]\n",
      "epoch:4 step:4137 [D loss: 0.712018, acc.: 47.66%] [G loss: 0.614375]\n",
      "epoch:4 step:4138 [D loss: 0.709965, acc.: 40.62%] [G loss: 0.690465]\n",
      "epoch:4 step:4139 [D loss: 0.711028, acc.: 48.44%] [G loss: 0.688505]\n",
      "epoch:4 step:4140 [D loss: 0.710899, acc.: 38.28%] [G loss: 0.701950]\n",
      "epoch:4 step:4141 [D loss: 0.696773, acc.: 46.09%] [G loss: 0.717896]\n",
      "epoch:4 step:4142 [D loss: 0.694348, acc.: 53.91%] [G loss: 0.724940]\n",
      "epoch:4 step:4143 [D loss: 0.700600, acc.: 39.84%] [G loss: 0.722694]\n",
      "epoch:4 step:4144 [D loss: 0.697980, acc.: 46.88%] [G loss: 0.731706]\n",
      "epoch:4 step:4145 [D loss: 0.671995, acc.: 65.62%] [G loss: 0.753412]\n",
      "epoch:4 step:4146 [D loss: 0.673446, acc.: 60.94%] [G loss: 0.783955]\n",
      "epoch:4 step:4147 [D loss: 0.668501, acc.: 64.84%] [G loss: 0.752896]\n",
      "epoch:4 step:4148 [D loss: 0.677616, acc.: 67.19%] [G loss: 0.749208]\n",
      "epoch:4 step:4149 [D loss: 0.689257, acc.: 52.34%] [G loss: 0.753701]\n",
      "epoch:4 step:4150 [D loss: 0.674010, acc.: 61.72%] [G loss: 0.754846]\n",
      "epoch:4 step:4151 [D loss: 0.693578, acc.: 43.75%] [G loss: 0.744514]\n",
      "epoch:4 step:4152 [D loss: 0.708753, acc.: 45.31%] [G loss: 0.727911]\n",
      "epoch:4 step:4153 [D loss: 0.689853, acc.: 54.69%] [G loss: 0.722957]\n",
      "epoch:4 step:4154 [D loss: 0.688433, acc.: 52.34%] [G loss: 0.762979]\n",
      "epoch:4 step:4155 [D loss: 0.671086, acc.: 60.94%] [G loss: 0.726652]\n",
      "epoch:4 step:4156 [D loss: 0.689940, acc.: 52.34%] [G loss: 0.735481]\n",
      "epoch:4 step:4157 [D loss: 0.684797, acc.: 52.34%] [G loss: 0.828310]\n",
      "epoch:4 step:4158 [D loss: 0.701665, acc.: 51.56%] [G loss: 0.731565]\n",
      "epoch:4 step:4159 [D loss: 0.734215, acc.: 39.06%] [G loss: 0.719620]\n",
      "epoch:4 step:4160 [D loss: 0.710317, acc.: 44.53%] [G loss: 0.710085]\n",
      "epoch:4 step:4161 [D loss: 0.673560, acc.: 62.50%] [G loss: 0.773408]\n",
      "epoch:4 step:4162 [D loss: 0.691417, acc.: 53.12%] [G loss: 0.743242]\n",
      "epoch:4 step:4163 [D loss: 0.662972, acc.: 59.38%] [G loss: 0.733138]\n",
      "epoch:4 step:4164 [D loss: 0.663698, acc.: 60.94%] [G loss: 0.758495]\n",
      "epoch:4 step:4165 [D loss: 0.723509, acc.: 44.53%] [G loss: 0.732634]\n",
      "epoch:4 step:4166 [D loss: 0.704123, acc.: 46.09%] [G loss: 0.714670]\n",
      "epoch:4 step:4167 [D loss: 0.703545, acc.: 47.66%] [G loss: 0.719223]\n",
      "epoch:4 step:4168 [D loss: 0.703202, acc.: 50.78%] [G loss: 0.708675]\n",
      "epoch:4 step:4169 [D loss: 0.714715, acc.: 42.97%] [G loss: 0.720079]\n",
      "epoch:4 step:4170 [D loss: 0.709157, acc.: 47.66%] [G loss: 0.721797]\n",
      "epoch:4 step:4171 [D loss: 0.698994, acc.: 48.44%] [G loss: 0.720330]\n",
      "epoch:4 step:4172 [D loss: 0.684112, acc.: 57.81%] [G loss: 0.739254]\n",
      "epoch:4 step:4173 [D loss: 0.685555, acc.: 57.81%] [G loss: 0.741509]\n",
      "epoch:4 step:4174 [D loss: 0.667910, acc.: 60.94%] [G loss: 0.774408]\n",
      "epoch:4 step:4175 [D loss: 0.682213, acc.: 57.03%] [G loss: 0.816321]\n",
      "epoch:4 step:4176 [D loss: 0.676054, acc.: 57.81%] [G loss: 0.759281]\n",
      "epoch:4 step:4177 [D loss: 0.683464, acc.: 60.16%] [G loss: 0.799459]\n",
      "epoch:4 step:4178 [D loss: 0.684868, acc.: 53.91%] [G loss: 0.763809]\n",
      "epoch:4 step:4179 [D loss: 0.698143, acc.: 52.34%] [G loss: 0.764801]\n",
      "epoch:4 step:4180 [D loss: 0.703632, acc.: 50.00%] [G loss: 0.750121]\n",
      "epoch:4 step:4181 [D loss: 0.708963, acc.: 47.66%] [G loss: 0.733478]\n",
      "epoch:4 step:4182 [D loss: 0.717385, acc.: 42.97%] [G loss: 0.743339]\n",
      "epoch:4 step:4183 [D loss: 0.699641, acc.: 46.88%] [G loss: 0.727545]\n",
      "epoch:4 step:4184 [D loss: 0.692213, acc.: 50.78%] [G loss: 0.709103]\n",
      "epoch:4 step:4185 [D loss: 0.687708, acc.: 53.12%] [G loss: 0.741960]\n",
      "epoch:4 step:4186 [D loss: 0.685487, acc.: 53.91%] [G loss: 0.732197]\n",
      "epoch:4 step:4187 [D loss: 0.701946, acc.: 51.56%] [G loss: 0.731430]\n",
      "epoch:4 step:4188 [D loss: 0.687912, acc.: 55.47%] [G loss: 0.717131]\n",
      "epoch:4 step:4189 [D loss: 0.688500, acc.: 50.78%] [G loss: 0.758290]\n",
      "epoch:4 step:4190 [D loss: 0.685740, acc.: 53.91%] [G loss: 0.708463]\n",
      "epoch:4 step:4191 [D loss: 0.695856, acc.: 49.22%] [G loss: 0.689539]\n",
      "epoch:4 step:4192 [D loss: 0.693486, acc.: 45.31%] [G loss: 0.686767]\n",
      "epoch:4 step:4193 [D loss: 0.718790, acc.: 48.44%] [G loss: 0.706307]\n",
      "epoch:4 step:4194 [D loss: 0.693967, acc.: 49.22%] [G loss: 0.712629]\n",
      "epoch:4 step:4195 [D loss: 0.696649, acc.: 50.00%] [G loss: 0.735163]\n",
      "epoch:4 step:4196 [D loss: 0.710662, acc.: 41.41%] [G loss: 0.718450]\n",
      "epoch:4 step:4197 [D loss: 0.704361, acc.: 49.22%] [G loss: 0.718770]\n",
      "epoch:4 step:4198 [D loss: 0.686518, acc.: 49.22%] [G loss: 0.752454]\n",
      "epoch:4 step:4199 [D loss: 0.687401, acc.: 53.12%] [G loss: 0.743549]\n",
      "epoch:4 step:4200 [D loss: 0.685316, acc.: 56.25%] [G loss: 0.744240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[4.34191214 2.48049432 6.99592237 5.56306028 4.25851714 6.03267722\n",
      " 5.27750614 4.94394189 5.62650165 4.9962681 ]\n",
      "##########\n",
      "epoch:4 step:4201 [D loss: 0.665247, acc.: 60.16%] [G loss: 0.770784]\n",
      "epoch:4 step:4202 [D loss: 0.661996, acc.: 63.28%] [G loss: 0.740533]\n",
      "epoch:4 step:4203 [D loss: 0.661742, acc.: 64.84%] [G loss: 0.771281]\n",
      "epoch:4 step:4204 [D loss: 0.649302, acc.: 58.59%] [G loss: 0.744049]\n",
      "epoch:4 step:4205 [D loss: 0.664016, acc.: 60.94%] [G loss: 0.757905]\n",
      "epoch:4 step:4206 [D loss: 0.742786, acc.: 45.31%] [G loss: 0.709456]\n",
      "epoch:4 step:4207 [D loss: 0.723590, acc.: 46.88%] [G loss: 0.714067]\n",
      "epoch:4 step:4208 [D loss: 0.728253, acc.: 40.62%] [G loss: 0.724842]\n",
      "epoch:4 step:4209 [D loss: 0.727815, acc.: 44.53%] [G loss: 0.714822]\n",
      "epoch:4 step:4210 [D loss: 0.709506, acc.: 43.75%] [G loss: 0.734807]\n",
      "epoch:4 step:4211 [D loss: 0.690195, acc.: 50.00%] [G loss: 0.752670]\n",
      "epoch:4 step:4212 [D loss: 0.681466, acc.: 52.34%] [G loss: 0.755074]\n",
      "epoch:4 step:4213 [D loss: 0.674114, acc.: 57.03%] [G loss: 0.757957]\n",
      "epoch:4 step:4214 [D loss: 0.663551, acc.: 58.59%] [G loss: 0.780413]\n",
      "epoch:4 step:4215 [D loss: 0.678461, acc.: 58.59%] [G loss: 0.813326]\n",
      "epoch:4 step:4216 [D loss: 0.657447, acc.: 64.06%] [G loss: 0.813881]\n",
      "epoch:4 step:4217 [D loss: 0.685714, acc.: 51.56%] [G loss: 0.836313]\n",
      "epoch:4 step:4218 [D loss: 0.643400, acc.: 67.97%] [G loss: 0.764055]\n",
      "epoch:4 step:4219 [D loss: 0.677800, acc.: 56.25%] [G loss: 0.775991]\n",
      "epoch:4 step:4220 [D loss: 0.685418, acc.: 50.78%] [G loss: 0.706560]\n",
      "epoch:4 step:4221 [D loss: 0.728289, acc.: 43.75%] [G loss: 0.724748]\n",
      "epoch:4 step:4222 [D loss: 0.703723, acc.: 47.66%] [G loss: 0.704595]\n",
      "epoch:4 step:4223 [D loss: 0.694570, acc.: 55.47%] [G loss: 0.719956]\n",
      "epoch:4 step:4224 [D loss: 0.683376, acc.: 53.91%] [G loss: 0.726819]\n",
      "epoch:4 step:4225 [D loss: 0.694778, acc.: 49.22%] [G loss: 0.739374]\n",
      "epoch:4 step:4226 [D loss: 0.718881, acc.: 42.19%] [G loss: 0.707149]\n",
      "epoch:4 step:4227 [D loss: 0.720545, acc.: 40.62%] [G loss: 0.729877]\n",
      "epoch:4 step:4228 [D loss: 0.725388, acc.: 46.88%] [G loss: 0.729066]\n",
      "epoch:4 step:4229 [D loss: 0.675566, acc.: 62.50%] [G loss: 0.722745]\n",
      "epoch:4 step:4230 [D loss: 0.701094, acc.: 42.97%] [G loss: 0.747861]\n",
      "epoch:4 step:4231 [D loss: 0.694672, acc.: 50.78%] [G loss: 0.757920]\n",
      "epoch:4 step:4232 [D loss: 0.682227, acc.: 56.25%] [G loss: 0.761372]\n",
      "epoch:4 step:4233 [D loss: 0.688312, acc.: 46.09%] [G loss: 0.747423]\n",
      "epoch:4 step:4234 [D loss: 0.692172, acc.: 51.56%] [G loss: 0.735221]\n",
      "epoch:4 step:4235 [D loss: 0.683411, acc.: 53.91%] [G loss: 0.714486]\n",
      "epoch:4 step:4236 [D loss: 0.666316, acc.: 60.16%] [G loss: 0.726042]\n",
      "epoch:4 step:4237 [D loss: 0.700767, acc.: 49.22%] [G loss: 0.746234]\n",
      "epoch:4 step:4238 [D loss: 0.695422, acc.: 48.44%] [G loss: 0.742128]\n",
      "epoch:4 step:4239 [D loss: 0.704211, acc.: 46.88%] [G loss: 0.721377]\n",
      "epoch:4 step:4240 [D loss: 0.728920, acc.: 39.84%] [G loss: 0.687981]\n",
      "epoch:4 step:4241 [D loss: 0.705368, acc.: 49.22%] [G loss: 0.712982]\n",
      "epoch:4 step:4242 [D loss: 0.706318, acc.: 39.06%] [G loss: 0.704890]\n",
      "epoch:4 step:4243 [D loss: 0.686369, acc.: 53.12%] [G loss: 0.716240]\n",
      "epoch:4 step:4244 [D loss: 0.696532, acc.: 53.12%] [G loss: 0.716649]\n",
      "epoch:4 step:4245 [D loss: 0.698439, acc.: 45.31%] [G loss: 0.710155]\n",
      "epoch:4 step:4246 [D loss: 0.703487, acc.: 47.66%] [G loss: 0.722406]\n",
      "epoch:4 step:4247 [D loss: 0.689221, acc.: 60.16%] [G loss: 0.737765]\n",
      "epoch:4 step:4248 [D loss: 0.691738, acc.: 52.34%] [G loss: 0.745004]\n",
      "epoch:4 step:4249 [D loss: 0.697212, acc.: 51.56%] [G loss: 0.753964]\n",
      "epoch:4 step:4250 [D loss: 0.697223, acc.: 51.56%] [G loss: 0.764407]\n",
      "epoch:4 step:4251 [D loss: 0.695492, acc.: 50.78%] [G loss: 0.761501]\n",
      "epoch:4 step:4252 [D loss: 0.691999, acc.: 51.56%] [G loss: 0.765836]\n",
      "epoch:4 step:4253 [D loss: 0.666681, acc.: 59.38%] [G loss: 0.757817]\n",
      "epoch:4 step:4254 [D loss: 0.680263, acc.: 57.03%] [G loss: 0.751736]\n",
      "epoch:4 step:4255 [D loss: 0.654976, acc.: 65.62%] [G loss: 0.745334]\n",
      "epoch:4 step:4256 [D loss: 0.665189, acc.: 60.16%] [G loss: 0.776513]\n",
      "epoch:4 step:4257 [D loss: 0.679774, acc.: 53.12%] [G loss: 0.743217]\n",
      "epoch:4 step:4258 [D loss: 0.708733, acc.: 48.44%] [G loss: 0.750126]\n",
      "epoch:4 step:4259 [D loss: 0.717521, acc.: 47.66%] [G loss: 0.759772]\n",
      "epoch:4 step:4260 [D loss: 0.717972, acc.: 39.06%] [G loss: 0.740413]\n",
      "epoch:4 step:4261 [D loss: 0.679936, acc.: 53.91%] [G loss: 0.729009]\n",
      "epoch:4 step:4262 [D loss: 0.691136, acc.: 56.25%] [G loss: 0.727686]\n",
      "epoch:4 step:4263 [D loss: 0.693957, acc.: 51.56%] [G loss: 0.717350]\n",
      "epoch:4 step:4264 [D loss: 0.697797, acc.: 53.91%] [G loss: 0.739854]\n",
      "epoch:4 step:4265 [D loss: 0.704515, acc.: 49.22%] [G loss: 0.730697]\n",
      "epoch:4 step:4266 [D loss: 0.691554, acc.: 45.31%] [G loss: 0.715865]\n",
      "epoch:4 step:4267 [D loss: 0.701529, acc.: 48.44%] [G loss: 0.728483]\n",
      "epoch:4 step:4268 [D loss: 0.680626, acc.: 55.47%] [G loss: 0.747348]\n",
      "epoch:4 step:4269 [D loss: 0.682327, acc.: 50.00%] [G loss: 0.744629]\n",
      "epoch:4 step:4270 [D loss: 0.676350, acc.: 56.25%] [G loss: 0.740936]\n",
      "epoch:4 step:4271 [D loss: 0.669476, acc.: 63.28%] [G loss: 0.765524]\n",
      "epoch:4 step:4272 [D loss: 0.672204, acc.: 65.62%] [G loss: 0.784360]\n",
      "epoch:4 step:4273 [D loss: 0.675863, acc.: 55.47%] [G loss: 0.824228]\n",
      "epoch:4 step:4274 [D loss: 0.674592, acc.: 59.38%] [G loss: 0.749226]\n",
      "epoch:4 step:4275 [D loss: 0.736386, acc.: 46.09%] [G loss: 0.759163]\n",
      "epoch:4 step:4276 [D loss: 0.760086, acc.: 35.94%] [G loss: 0.729876]\n",
      "epoch:4 step:4277 [D loss: 0.742977, acc.: 34.38%] [G loss: 0.731263]\n",
      "epoch:4 step:4278 [D loss: 0.711693, acc.: 42.97%] [G loss: 0.733655]\n",
      "epoch:4 step:4279 [D loss: 0.711366, acc.: 42.97%] [G loss: 0.713041]\n",
      "epoch:4 step:4280 [D loss: 0.694598, acc.: 56.25%] [G loss: 0.721917]\n",
      "epoch:4 step:4281 [D loss: 0.694192, acc.: 53.12%] [G loss: 0.724337]\n",
      "epoch:4 step:4282 [D loss: 0.681286, acc.: 56.25%] [G loss: 0.744549]\n",
      "epoch:4 step:4283 [D loss: 0.698031, acc.: 48.44%] [G loss: 0.730754]\n",
      "epoch:4 step:4284 [D loss: 0.692191, acc.: 57.81%] [G loss: 0.722495]\n",
      "epoch:4 step:4285 [D loss: 0.679482, acc.: 60.16%] [G loss: 0.719765]\n",
      "epoch:4 step:4286 [D loss: 0.690360, acc.: 52.34%] [G loss: 0.752005]\n",
      "epoch:4 step:4287 [D loss: 0.687809, acc.: 56.25%] [G loss: 0.740449]\n",
      "epoch:4 step:4288 [D loss: 0.683281, acc.: 54.69%] [G loss: 0.741351]\n",
      "epoch:4 step:4289 [D loss: 0.685787, acc.: 55.47%] [G loss: 0.744814]\n",
      "epoch:4 step:4290 [D loss: 0.710141, acc.: 47.66%] [G loss: 0.715035]\n",
      "epoch:4 step:4291 [D loss: 0.699732, acc.: 49.22%] [G loss: 0.707388]\n",
      "epoch:4 step:4292 [D loss: 0.685576, acc.: 58.59%] [G loss: 0.710419]\n",
      "epoch:4 step:4293 [D loss: 0.689189, acc.: 54.69%] [G loss: 0.705850]\n",
      "epoch:4 step:4294 [D loss: 0.690807, acc.: 49.22%] [G loss: 0.716387]\n",
      "epoch:4 step:4295 [D loss: 0.707011, acc.: 44.53%] [G loss: 0.697527]\n",
      "epoch:4 step:4296 [D loss: 0.676694, acc.: 54.69%] [G loss: 0.685197]\n",
      "epoch:4 step:4297 [D loss: 0.691285, acc.: 54.69%] [G loss: 0.687427]\n",
      "epoch:4 step:4298 [D loss: 0.677433, acc.: 57.81%] [G loss: 0.696340]\n",
      "epoch:4 step:4299 [D loss: 0.689255, acc.: 52.34%] [G loss: 0.711898]\n",
      "epoch:4 step:4300 [D loss: 0.664633, acc.: 62.50%] [G loss: 0.724242]\n",
      "epoch:4 step:4301 [D loss: 0.703465, acc.: 43.75%] [G loss: 0.700590]\n",
      "epoch:4 step:4302 [D loss: 0.658060, acc.: 62.50%] [G loss: 0.705935]\n",
      "epoch:4 step:4303 [D loss: 0.699091, acc.: 54.69%] [G loss: 0.753005]\n",
      "epoch:4 step:4304 [D loss: 0.668215, acc.: 54.69%] [G loss: 0.723158]\n",
      "epoch:4 step:4305 [D loss: 0.666548, acc.: 57.81%] [G loss: 0.742430]\n",
      "epoch:4 step:4306 [D loss: 0.666593, acc.: 63.28%] [G loss: 0.731705]\n",
      "epoch:4 step:4307 [D loss: 0.712015, acc.: 44.53%] [G loss: 0.729689]\n",
      "epoch:4 step:4308 [D loss: 0.694087, acc.: 48.44%] [G loss: 0.739535]\n",
      "epoch:4 step:4309 [D loss: 0.692642, acc.: 53.91%] [G loss: 0.735928]\n",
      "epoch:4 step:4310 [D loss: 0.690454, acc.: 48.44%] [G loss: 0.761117]\n",
      "epoch:4 step:4311 [D loss: 0.675070, acc.: 58.59%] [G loss: 0.739869]\n",
      "epoch:4 step:4312 [D loss: 0.670497, acc.: 61.72%] [G loss: 0.748635]\n",
      "epoch:4 step:4313 [D loss: 0.682752, acc.: 54.69%] [G loss: 0.769531]\n",
      "epoch:4 step:4314 [D loss: 0.748343, acc.: 43.75%] [G loss: 0.758484]\n",
      "epoch:4 step:4315 [D loss: 0.712550, acc.: 41.41%] [G loss: 0.796176]\n",
      "epoch:4 step:4316 [D loss: 0.679744, acc.: 52.34%] [G loss: 0.755784]\n",
      "epoch:4 step:4317 [D loss: 0.700907, acc.: 49.22%] [G loss: 0.851316]\n",
      "epoch:4 step:4318 [D loss: 0.686139, acc.: 51.56%] [G loss: 0.770800]\n",
      "epoch:4 step:4319 [D loss: 0.682619, acc.: 54.69%] [G loss: 0.759516]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4320 [D loss: 0.695210, acc.: 53.12%] [G loss: 0.774571]\n",
      "epoch:4 step:4321 [D loss: 0.674624, acc.: 57.81%] [G loss: 0.775109]\n",
      "epoch:4 step:4322 [D loss: 0.646469, acc.: 64.84%] [G loss: 0.795972]\n",
      "epoch:4 step:4323 [D loss: 0.661487, acc.: 65.62%] [G loss: 0.850534]\n",
      "epoch:4 step:4324 [D loss: 0.699130, acc.: 53.12%] [G loss: 0.825611]\n",
      "epoch:4 step:4325 [D loss: 0.708182, acc.: 44.53%] [G loss: 0.732184]\n",
      "epoch:4 step:4326 [D loss: 0.704848, acc.: 49.22%] [G loss: 0.699554]\n",
      "epoch:4 step:4327 [D loss: 0.700374, acc.: 50.78%] [G loss: 0.751410]\n",
      "epoch:4 step:4328 [D loss: 0.719664, acc.: 42.97%] [G loss: 0.718161]\n",
      "epoch:4 step:4329 [D loss: 0.689349, acc.: 50.78%] [G loss: 0.700210]\n",
      "epoch:4 step:4330 [D loss: 0.702857, acc.: 42.97%] [G loss: 0.702587]\n",
      "epoch:4 step:4331 [D loss: 0.714621, acc.: 43.75%] [G loss: 0.715152]\n",
      "epoch:4 step:4332 [D loss: 0.710298, acc.: 43.75%] [G loss: 0.723005]\n",
      "epoch:4 step:4333 [D loss: 0.681480, acc.: 56.25%] [G loss: 0.747281]\n",
      "epoch:4 step:4334 [D loss: 0.683536, acc.: 57.03%] [G loss: 0.741230]\n",
      "epoch:4 step:4335 [D loss: 0.698139, acc.: 49.22%] [G loss: 0.731825]\n",
      "epoch:4 step:4336 [D loss: 0.665982, acc.: 61.72%] [G loss: 0.745943]\n",
      "epoch:4 step:4337 [D loss: 0.644749, acc.: 67.97%] [G loss: 0.771027]\n",
      "epoch:4 step:4338 [D loss: 0.682922, acc.: 50.00%] [G loss: 0.799301]\n",
      "epoch:4 step:4339 [D loss: 0.663367, acc.: 59.38%] [G loss: 0.791503]\n",
      "epoch:4 step:4340 [D loss: 0.678504, acc.: 53.12%] [G loss: 0.779491]\n",
      "epoch:4 step:4341 [D loss: 0.699700, acc.: 51.56%] [G loss: 0.765666]\n",
      "epoch:4 step:4342 [D loss: 0.699805, acc.: 52.34%] [G loss: 0.749925]\n",
      "epoch:4 step:4343 [D loss: 0.686248, acc.: 60.16%] [G loss: 0.723968]\n",
      "epoch:4 step:4344 [D loss: 0.733378, acc.: 48.44%] [G loss: 0.733454]\n",
      "epoch:4 step:4345 [D loss: 0.722954, acc.: 41.41%] [G loss: 0.707737]\n",
      "epoch:4 step:4346 [D loss: 0.711842, acc.: 45.31%] [G loss: 0.726780]\n",
      "epoch:4 step:4347 [D loss: 0.689139, acc.: 52.34%] [G loss: 0.731010]\n",
      "epoch:4 step:4348 [D loss: 0.694307, acc.: 45.31%] [G loss: 0.725102]\n",
      "epoch:4 step:4349 [D loss: 0.685232, acc.: 53.12%] [G loss: 0.748062]\n",
      "epoch:4 step:4350 [D loss: 0.688047, acc.: 53.12%] [G loss: 0.778359]\n",
      "epoch:4 step:4351 [D loss: 0.680851, acc.: 52.34%] [G loss: 0.752540]\n",
      "epoch:4 step:4352 [D loss: 0.712471, acc.: 46.09%] [G loss: 0.765835]\n",
      "epoch:4 step:4353 [D loss: 0.677159, acc.: 64.06%] [G loss: 0.764906]\n",
      "epoch:4 step:4354 [D loss: 0.682933, acc.: 58.59%] [G loss: 0.730558]\n",
      "epoch:4 step:4355 [D loss: 0.697818, acc.: 53.12%] [G loss: 0.721208]\n",
      "epoch:4 step:4356 [D loss: 0.705798, acc.: 51.56%] [G loss: 0.725282]\n",
      "epoch:4 step:4357 [D loss: 0.710709, acc.: 42.19%] [G loss: 0.692328]\n",
      "epoch:4 step:4358 [D loss: 0.705404, acc.: 46.09%] [G loss: 0.718886]\n",
      "epoch:4 step:4359 [D loss: 0.702571, acc.: 47.66%] [G loss: 0.685768]\n",
      "epoch:4 step:4360 [D loss: 0.699519, acc.: 48.44%] [G loss: 0.688016]\n",
      "epoch:4 step:4361 [D loss: 0.697000, acc.: 45.31%] [G loss: 0.696351]\n",
      "epoch:4 step:4362 [D loss: 0.717452, acc.: 37.50%] [G loss: 0.692825]\n",
      "epoch:4 step:4363 [D loss: 0.720351, acc.: 38.28%] [G loss: 0.718300]\n",
      "epoch:4 step:4364 [D loss: 0.690112, acc.: 47.66%] [G loss: 0.739621]\n",
      "epoch:4 step:4365 [D loss: 0.679561, acc.: 57.03%] [G loss: 0.740808]\n",
      "epoch:4 step:4366 [D loss: 0.688219, acc.: 50.00%] [G loss: 0.726054]\n",
      "epoch:4 step:4367 [D loss: 0.689217, acc.: 50.78%] [G loss: 0.739275]\n",
      "epoch:4 step:4368 [D loss: 0.681591, acc.: 57.03%] [G loss: 0.732465]\n",
      "epoch:4 step:4369 [D loss: 0.683409, acc.: 50.78%] [G loss: 0.746942]\n",
      "epoch:4 step:4370 [D loss: 0.693977, acc.: 46.88%] [G loss: 0.771330]\n",
      "epoch:4 step:4371 [D loss: 0.697742, acc.: 45.31%] [G loss: 0.754919]\n",
      "epoch:4 step:4372 [D loss: 0.675142, acc.: 58.59%] [G loss: 0.752374]\n",
      "epoch:4 step:4373 [D loss: 0.694583, acc.: 51.56%] [G loss: 0.758554]\n",
      "epoch:4 step:4374 [D loss: 0.703734, acc.: 48.44%] [G loss: 0.754068]\n",
      "epoch:4 step:4375 [D loss: 0.694809, acc.: 50.78%] [G loss: 0.721187]\n",
      "epoch:4 step:4376 [D loss: 0.704596, acc.: 43.75%] [G loss: 0.722657]\n",
      "epoch:4 step:4377 [D loss: 0.694644, acc.: 45.31%] [G loss: 0.717008]\n",
      "epoch:4 step:4378 [D loss: 0.696123, acc.: 53.12%] [G loss: 0.729546]\n",
      "epoch:4 step:4379 [D loss: 0.695057, acc.: 50.78%] [G loss: 0.722750]\n",
      "epoch:4 step:4380 [D loss: 0.696194, acc.: 48.44%] [G loss: 0.730299]\n",
      "epoch:4 step:4381 [D loss: 0.700814, acc.: 44.53%] [G loss: 0.747503]\n",
      "epoch:4 step:4382 [D loss: 0.689398, acc.: 50.00%] [G loss: 0.748836]\n",
      "epoch:4 step:4383 [D loss: 0.680858, acc.: 55.47%] [G loss: 0.735669]\n",
      "epoch:4 step:4384 [D loss: 0.693162, acc.: 51.56%] [G loss: 0.720339]\n",
      "epoch:4 step:4385 [D loss: 0.690100, acc.: 50.00%] [G loss: 0.743128]\n",
      "epoch:4 step:4386 [D loss: 0.673757, acc.: 58.59%] [G loss: 0.758398]\n",
      "epoch:4 step:4387 [D loss: 0.692866, acc.: 49.22%] [G loss: 0.727175]\n",
      "epoch:4 step:4388 [D loss: 0.685497, acc.: 48.44%] [G loss: 0.756858]\n",
      "epoch:4 step:4389 [D loss: 0.694889, acc.: 46.09%] [G loss: 0.733418]\n",
      "epoch:4 step:4390 [D loss: 0.676197, acc.: 49.22%] [G loss: 0.742239]\n",
      "epoch:4 step:4391 [D loss: 0.683637, acc.: 50.00%] [G loss: 0.775793]\n",
      "epoch:4 step:4392 [D loss: 0.700299, acc.: 48.44%] [G loss: 0.723512]\n",
      "epoch:4 step:4393 [D loss: 0.703612, acc.: 48.44%] [G loss: 0.692697]\n",
      "epoch:4 step:4394 [D loss: 0.704099, acc.: 50.00%] [G loss: 0.713390]\n",
      "epoch:4 step:4395 [D loss: 0.708896, acc.: 36.72%] [G loss: 0.705301]\n",
      "epoch:4 step:4396 [D loss: 0.694659, acc.: 51.56%] [G loss: 0.698918]\n",
      "epoch:4 step:4397 [D loss: 0.687597, acc.: 50.78%] [G loss: 0.715106]\n",
      "epoch:4 step:4398 [D loss: 0.683693, acc.: 58.59%] [G loss: 0.714929]\n",
      "epoch:4 step:4399 [D loss: 0.676003, acc.: 55.47%] [G loss: 0.715146]\n",
      "epoch:4 step:4400 [D loss: 0.722556, acc.: 41.41%] [G loss: 0.727239]\n",
      "##############\n",
      "[3.69409485 1.84570847 6.00788679 5.02969108 4.14636803 5.71007776\n",
      " 5.13186914 5.14033208 5.38284752 4.71441948]\n",
      "##########\n",
      "epoch:4 step:4401 [D loss: 0.693516, acc.: 49.22%] [G loss: 0.731013]\n",
      "epoch:4 step:4402 [D loss: 0.704397, acc.: 50.78%] [G loss: 0.719468]\n",
      "epoch:4 step:4403 [D loss: 0.683099, acc.: 54.69%] [G loss: 0.714558]\n",
      "epoch:4 step:4404 [D loss: 0.698983, acc.: 46.88%] [G loss: 0.705094]\n",
      "epoch:4 step:4405 [D loss: 0.715039, acc.: 40.62%] [G loss: 0.724347]\n",
      "epoch:4 step:4406 [D loss: 0.706688, acc.: 48.44%] [G loss: 0.719778]\n",
      "epoch:4 step:4407 [D loss: 0.683998, acc.: 50.00%] [G loss: 0.685737]\n",
      "epoch:4 step:4408 [D loss: 0.687795, acc.: 55.47%] [G loss: 0.722088]\n",
      "epoch:4 step:4409 [D loss: 0.688601, acc.: 51.56%] [G loss: 0.725674]\n",
      "epoch:4 step:4410 [D loss: 0.693467, acc.: 49.22%] [G loss: 0.727960]\n",
      "epoch:4 step:4411 [D loss: 0.705636, acc.: 39.84%] [G loss: 0.724517]\n",
      "epoch:4 step:4412 [D loss: 0.685123, acc.: 51.56%] [G loss: 0.718566]\n",
      "epoch:4 step:4413 [D loss: 0.692066, acc.: 53.12%] [G loss: 0.772079]\n",
      "epoch:4 step:4414 [D loss: 0.686563, acc.: 55.47%] [G loss: 0.768698]\n",
      "epoch:4 step:4415 [D loss: 0.697580, acc.: 49.22%] [G loss: 0.737886]\n",
      "epoch:4 step:4416 [D loss: 0.680144, acc.: 53.12%] [G loss: 0.774065]\n",
      "epoch:4 step:4417 [D loss: 0.698917, acc.: 50.00%] [G loss: 0.748511]\n",
      "epoch:4 step:4418 [D loss: 0.705391, acc.: 50.00%] [G loss: 0.720264]\n",
      "epoch:4 step:4419 [D loss: 0.692441, acc.: 53.12%] [G loss: 0.744505]\n",
      "epoch:4 step:4420 [D loss: 0.691179, acc.: 48.44%] [G loss: 0.743487]\n",
      "epoch:4 step:4421 [D loss: 0.696057, acc.: 50.00%] [G loss: 0.778081]\n",
      "epoch:4 step:4422 [D loss: 0.692442, acc.: 49.22%] [G loss: 0.725620]\n",
      "epoch:4 step:4423 [D loss: 0.708039, acc.: 46.09%] [G loss: 0.712641]\n",
      "epoch:4 step:4424 [D loss: 0.703058, acc.: 52.34%] [G loss: 0.722134]\n",
      "epoch:4 step:4425 [D loss: 0.699354, acc.: 46.09%] [G loss: 0.721511]\n",
      "epoch:4 step:4426 [D loss: 0.710266, acc.: 41.41%] [G loss: 0.711076]\n",
      "epoch:4 step:4427 [D loss: 0.694322, acc.: 52.34%] [G loss: 0.708052]\n",
      "epoch:4 step:4428 [D loss: 0.690244, acc.: 52.34%] [G loss: 0.735814]\n",
      "epoch:4 step:4429 [D loss: 0.688072, acc.: 53.12%] [G loss: 0.712816]\n",
      "epoch:4 step:4430 [D loss: 0.681847, acc.: 57.81%] [G loss: 0.739401]\n",
      "epoch:4 step:4431 [D loss: 0.681832, acc.: 56.25%] [G loss: 0.731339]\n",
      "epoch:4 step:4432 [D loss: 0.675354, acc.: 63.28%] [G loss: 0.723341]\n",
      "epoch:4 step:4433 [D loss: 0.689570, acc.: 53.12%] [G loss: 0.750200]\n",
      "epoch:4 step:4434 [D loss: 0.686266, acc.: 55.47%] [G loss: 0.721624]\n",
      "epoch:4 step:4435 [D loss: 0.689335, acc.: 50.78%] [G loss: 0.728632]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4436 [D loss: 0.695510, acc.: 53.91%] [G loss: 0.740443]\n",
      "epoch:4 step:4437 [D loss: 0.690249, acc.: 56.25%] [G loss: 0.722415]\n",
      "epoch:4 step:4438 [D loss: 0.680757, acc.: 59.38%] [G loss: 0.706374]\n",
      "epoch:4 step:4439 [D loss: 0.699345, acc.: 55.47%] [G loss: 0.715095]\n",
      "epoch:4 step:4440 [D loss: 0.690250, acc.: 53.12%] [G loss: 0.694021]\n",
      "epoch:4 step:4441 [D loss: 0.701419, acc.: 47.66%] [G loss: 0.699882]\n",
      "epoch:4 step:4442 [D loss: 0.693213, acc.: 47.66%] [G loss: 0.720168]\n",
      "epoch:4 step:4443 [D loss: 0.700377, acc.: 53.12%] [G loss: 0.723995]\n",
      "epoch:4 step:4444 [D loss: 0.719802, acc.: 43.75%] [G loss: 0.716485]\n",
      "epoch:4 step:4445 [D loss: 0.712468, acc.: 40.62%] [G loss: 0.722213]\n",
      "epoch:4 step:4446 [D loss: 0.693924, acc.: 50.00%] [G loss: 0.714271]\n",
      "epoch:4 step:4447 [D loss: 0.693349, acc.: 53.12%] [G loss: 0.748384]\n",
      "epoch:4 step:4448 [D loss: 0.686014, acc.: 50.00%] [G loss: 0.750618]\n",
      "epoch:4 step:4449 [D loss: 0.685860, acc.: 55.47%] [G loss: 0.753407]\n",
      "epoch:4 step:4450 [D loss: 0.690335, acc.: 50.78%] [G loss: 0.773005]\n",
      "epoch:4 step:4451 [D loss: 0.679643, acc.: 64.84%] [G loss: 0.766218]\n",
      "epoch:4 step:4452 [D loss: 0.683634, acc.: 53.12%] [G loss: 0.783128]\n",
      "epoch:4 step:4453 [D loss: 0.688330, acc.: 52.34%] [G loss: 0.773526]\n",
      "epoch:4 step:4454 [D loss: 0.671706, acc.: 54.69%] [G loss: 0.745622]\n",
      "epoch:4 step:4455 [D loss: 0.683586, acc.: 51.56%] [G loss: 0.786669]\n",
      "epoch:4 step:4456 [D loss: 0.699129, acc.: 45.31%] [G loss: 0.744460]\n",
      "epoch:4 step:4457 [D loss: 0.679496, acc.: 52.34%] [G loss: 0.722507]\n",
      "epoch:4 step:4458 [D loss: 0.752069, acc.: 35.94%] [G loss: 0.742861]\n",
      "epoch:4 step:4459 [D loss: 0.720942, acc.: 41.41%] [G loss: 0.724079]\n",
      "epoch:4 step:4460 [D loss: 0.695525, acc.: 59.38%] [G loss: 0.730357]\n",
      "epoch:4 step:4461 [D loss: 0.673547, acc.: 59.38%] [G loss: 0.734426]\n",
      "epoch:4 step:4462 [D loss: 0.698193, acc.: 46.88%] [G loss: 0.719959]\n",
      "epoch:4 step:4463 [D loss: 0.705260, acc.: 44.53%] [G loss: 0.719281]\n",
      "epoch:4 step:4464 [D loss: 0.704286, acc.: 46.88%] [G loss: 0.720265]\n",
      "epoch:4 step:4465 [D loss: 0.704536, acc.: 47.66%] [G loss: 0.730819]\n",
      "epoch:4 step:4466 [D loss: 0.689886, acc.: 48.44%] [G loss: 0.727178]\n",
      "epoch:4 step:4467 [D loss: 0.675255, acc.: 56.25%] [G loss: 0.733915]\n",
      "epoch:4 step:4468 [D loss: 0.679713, acc.: 49.22%] [G loss: 0.722705]\n",
      "epoch:4 step:4469 [D loss: 0.677512, acc.: 56.25%] [G loss: 0.766403]\n",
      "epoch:4 step:4470 [D loss: 0.695444, acc.: 50.00%] [G loss: 0.751431]\n",
      "epoch:4 step:4471 [D loss: 0.682094, acc.: 52.34%] [G loss: 0.749626]\n",
      "epoch:4 step:4472 [D loss: 0.688360, acc.: 55.47%] [G loss: 0.727080]\n",
      "epoch:4 step:4473 [D loss: 0.691448, acc.: 50.78%] [G loss: 0.717615]\n",
      "epoch:4 step:4474 [D loss: 0.702670, acc.: 47.66%] [G loss: 0.733755]\n",
      "epoch:4 step:4475 [D loss: 0.705142, acc.: 45.31%] [G loss: 0.719703]\n",
      "epoch:4 step:4476 [D loss: 0.710984, acc.: 43.75%] [G loss: 0.708194]\n",
      "epoch:4 step:4477 [D loss: 0.701370, acc.: 46.09%] [G loss: 0.711269]\n",
      "epoch:4 step:4478 [D loss: 0.690456, acc.: 52.34%] [G loss: 0.722402]\n",
      "epoch:4 step:4479 [D loss: 0.688377, acc.: 53.12%] [G loss: 0.725416]\n",
      "epoch:4 step:4480 [D loss: 0.692184, acc.: 53.91%] [G loss: 0.722032]\n",
      "epoch:4 step:4481 [D loss: 0.695560, acc.: 53.91%] [G loss: 0.743138]\n",
      "epoch:4 step:4482 [D loss: 0.690583, acc.: 52.34%] [G loss: 0.733178]\n",
      "epoch:4 step:4483 [D loss: 0.709987, acc.: 47.66%] [G loss: 0.755521]\n",
      "epoch:4 step:4484 [D loss: 0.680469, acc.: 57.03%] [G loss: 0.766008]\n",
      "epoch:4 step:4485 [D loss: 0.687091, acc.: 56.25%] [G loss: 0.774799]\n",
      "epoch:4 step:4486 [D loss: 0.683445, acc.: 50.00%] [G loss: 0.736976]\n",
      "epoch:4 step:4487 [D loss: 0.709074, acc.: 39.06%] [G loss: 0.738799]\n",
      "epoch:4 step:4488 [D loss: 0.701236, acc.: 46.88%] [G loss: 0.737077]\n",
      "epoch:4 step:4489 [D loss: 0.701790, acc.: 45.31%] [G loss: 0.709677]\n",
      "epoch:4 step:4490 [D loss: 0.687386, acc.: 57.03%] [G loss: 0.696751]\n",
      "epoch:4 step:4491 [D loss: 0.691615, acc.: 51.56%] [G loss: 0.716811]\n",
      "epoch:4 step:4492 [D loss: 0.687101, acc.: 53.91%] [G loss: 0.709118]\n",
      "epoch:4 step:4493 [D loss: 0.703107, acc.: 46.09%] [G loss: 0.716281]\n",
      "epoch:4 step:4494 [D loss: 0.703515, acc.: 47.66%] [G loss: 0.727700]\n",
      "epoch:4 step:4495 [D loss: 0.684910, acc.: 56.25%] [G loss: 0.726857]\n",
      "epoch:4 step:4496 [D loss: 0.695176, acc.: 48.44%] [G loss: 0.716538]\n",
      "epoch:4 step:4497 [D loss: 0.700186, acc.: 45.31%] [G loss: 0.691802]\n",
      "epoch:4 step:4498 [D loss: 0.695857, acc.: 49.22%] [G loss: 0.712728]\n",
      "epoch:4 step:4499 [D loss: 0.686820, acc.: 54.69%] [G loss: 0.725797]\n",
      "epoch:4 step:4500 [D loss: 0.707302, acc.: 43.75%] [G loss: 0.719364]\n",
      "epoch:4 step:4501 [D loss: 0.684212, acc.: 50.00%] [G loss: 0.729589]\n",
      "epoch:4 step:4502 [D loss: 0.687574, acc.: 54.69%] [G loss: 0.718166]\n",
      "epoch:4 step:4503 [D loss: 0.694331, acc.: 50.00%] [G loss: 0.714399]\n",
      "epoch:4 step:4504 [D loss: 0.687387, acc.: 58.59%] [G loss: 0.717632]\n",
      "epoch:4 step:4505 [D loss: 0.691785, acc.: 52.34%] [G loss: 0.701815]\n",
      "epoch:4 step:4506 [D loss: 0.687346, acc.: 53.91%] [G loss: 0.722532]\n",
      "epoch:4 step:4507 [D loss: 0.698615, acc.: 50.00%] [G loss: 0.715101]\n",
      "epoch:4 step:4508 [D loss: 0.693320, acc.: 49.22%] [G loss: 0.766488]\n",
      "epoch:4 step:4509 [D loss: 0.698678, acc.: 51.56%] [G loss: 0.722753]\n",
      "epoch:4 step:4510 [D loss: 0.685105, acc.: 51.56%] [G loss: 0.741842]\n",
      "epoch:4 step:4511 [D loss: 0.705555, acc.: 45.31%] [G loss: 0.706146]\n",
      "epoch:4 step:4512 [D loss: 0.698863, acc.: 50.00%] [G loss: 0.715133]\n",
      "epoch:4 step:4513 [D loss: 0.689839, acc.: 60.16%] [G loss: 0.719123]\n",
      "epoch:4 step:4514 [D loss: 0.685433, acc.: 51.56%] [G loss: 0.728805]\n",
      "epoch:4 step:4515 [D loss: 0.674206, acc.: 59.38%] [G loss: 0.744057]\n",
      "epoch:4 step:4516 [D loss: 0.704289, acc.: 45.31%] [G loss: 0.731398]\n",
      "epoch:4 step:4517 [D loss: 0.685987, acc.: 57.81%] [G loss: 0.724978]\n",
      "epoch:4 step:4518 [D loss: 0.686020, acc.: 56.25%] [G loss: 0.732543]\n",
      "epoch:4 step:4519 [D loss: 0.701544, acc.: 49.22%] [G loss: 0.717303]\n",
      "epoch:4 step:4520 [D loss: 0.697524, acc.: 49.22%] [G loss: 0.739604]\n",
      "epoch:4 step:4521 [D loss: 0.676111, acc.: 57.03%] [G loss: 0.733473]\n",
      "epoch:4 step:4522 [D loss: 0.718532, acc.: 39.84%] [G loss: 0.713517]\n",
      "epoch:4 step:4523 [D loss: 0.680602, acc.: 57.03%] [G loss: 0.755240]\n",
      "epoch:4 step:4524 [D loss: 0.714617, acc.: 46.88%] [G loss: 0.732386]\n",
      "epoch:4 step:4525 [D loss: 0.691285, acc.: 50.00%] [G loss: 0.753345]\n",
      "epoch:4 step:4526 [D loss: 0.706231, acc.: 42.97%] [G loss: 0.735315]\n",
      "epoch:4 step:4527 [D loss: 0.689336, acc.: 60.16%] [G loss: 0.759012]\n",
      "epoch:4 step:4528 [D loss: 0.686049, acc.: 58.59%] [G loss: 0.776891]\n",
      "epoch:4 step:4529 [D loss: 0.683489, acc.: 50.78%] [G loss: 0.778301]\n",
      "epoch:4 step:4530 [D loss: 0.660403, acc.: 69.53%] [G loss: 0.759606]\n",
      "epoch:4 step:4531 [D loss: 0.679331, acc.: 60.16%] [G loss: 0.807817]\n",
      "epoch:4 step:4532 [D loss: 0.671415, acc.: 59.38%] [G loss: 0.824968]\n",
      "epoch:4 step:4533 [D loss: 0.681924, acc.: 55.47%] [G loss: 0.799529]\n",
      "epoch:4 step:4534 [D loss: 0.678766, acc.: 60.94%] [G loss: 0.748888]\n",
      "epoch:4 step:4535 [D loss: 0.713700, acc.: 45.31%] [G loss: 0.752251]\n",
      "epoch:4 step:4536 [D loss: 0.751538, acc.: 41.41%] [G loss: 0.697720]\n",
      "epoch:4 step:4537 [D loss: 0.714993, acc.: 42.97%] [G loss: 0.678224]\n",
      "epoch:4 step:4538 [D loss: 0.704386, acc.: 49.22%] [G loss: 0.682343]\n",
      "epoch:4 step:4539 [D loss: 0.704673, acc.: 45.31%] [G loss: 0.694966]\n",
      "epoch:4 step:4540 [D loss: 0.697680, acc.: 45.31%] [G loss: 0.697895]\n",
      "epoch:4 step:4541 [D loss: 0.689524, acc.: 60.94%] [G loss: 0.705101]\n",
      "epoch:4 step:4542 [D loss: 0.680118, acc.: 54.69%] [G loss: 0.721337]\n",
      "epoch:4 step:4543 [D loss: 0.686751, acc.: 56.25%] [G loss: 0.725151]\n",
      "epoch:4 step:4544 [D loss: 0.680312, acc.: 61.72%] [G loss: 0.739874]\n",
      "epoch:4 step:4545 [D loss: 0.687627, acc.: 54.69%] [G loss: 0.731664]\n",
      "epoch:4 step:4546 [D loss: 0.680048, acc.: 56.25%] [G loss: 0.743399]\n",
      "epoch:4 step:4547 [D loss: 0.694412, acc.: 44.53%] [G loss: 0.740603]\n",
      "epoch:4 step:4548 [D loss: 0.710394, acc.: 56.25%] [G loss: 0.738832]\n",
      "epoch:4 step:4549 [D loss: 0.704748, acc.: 48.44%] [G loss: 0.743392]\n",
      "epoch:4 step:4550 [D loss: 0.661690, acc.: 58.59%] [G loss: 0.737660]\n",
      "epoch:4 step:4551 [D loss: 0.676860, acc.: 58.59%] [G loss: 0.738727]\n",
      "epoch:4 step:4552 [D loss: 0.695715, acc.: 57.03%] [G loss: 0.715738]\n",
      "epoch:4 step:4553 [D loss: 0.691185, acc.: 59.38%] [G loss: 0.727167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4554 [D loss: 0.693060, acc.: 51.56%] [G loss: 0.702677]\n",
      "epoch:4 step:4555 [D loss: 0.691929, acc.: 55.47%] [G loss: 0.687986]\n",
      "epoch:4 step:4556 [D loss: 0.704591, acc.: 46.88%] [G loss: 0.707877]\n",
      "epoch:4 step:4557 [D loss: 0.694202, acc.: 47.66%] [G loss: 0.720066]\n",
      "epoch:4 step:4558 [D loss: 0.692985, acc.: 56.25%] [G loss: 0.714575]\n",
      "epoch:4 step:4559 [D loss: 0.691448, acc.: 57.81%] [G loss: 0.716758]\n",
      "epoch:4 step:4560 [D loss: 0.713507, acc.: 45.31%] [G loss: 0.703307]\n",
      "epoch:4 step:4561 [D loss: 0.694496, acc.: 51.56%] [G loss: 0.721470]\n",
      "epoch:4 step:4562 [D loss: 0.691708, acc.: 48.44%] [G loss: 0.723384]\n",
      "epoch:4 step:4563 [D loss: 0.660508, acc.: 66.41%] [G loss: 0.708066]\n",
      "epoch:4 step:4564 [D loss: 0.674864, acc.: 60.94%] [G loss: 0.707432]\n",
      "epoch:4 step:4565 [D loss: 0.694213, acc.: 47.66%] [G loss: 0.708439]\n",
      "epoch:4 step:4566 [D loss: 0.693833, acc.: 50.78%] [G loss: 0.713466]\n",
      "epoch:4 step:4567 [D loss: 0.690559, acc.: 48.44%] [G loss: 0.716473]\n",
      "epoch:4 step:4568 [D loss: 0.699251, acc.: 48.44%] [G loss: 0.725120]\n",
      "epoch:4 step:4569 [D loss: 0.692230, acc.: 52.34%] [G loss: 0.748351]\n",
      "epoch:4 step:4570 [D loss: 0.692593, acc.: 53.12%] [G loss: 0.767251]\n",
      "epoch:4 step:4571 [D loss: 0.674547, acc.: 57.81%] [G loss: 0.771121]\n",
      "epoch:4 step:4572 [D loss: 0.691164, acc.: 52.34%] [G loss: 0.748609]\n",
      "epoch:4 step:4573 [D loss: 0.684817, acc.: 57.03%] [G loss: 0.750895]\n",
      "epoch:4 step:4574 [D loss: 0.683311, acc.: 52.34%] [G loss: 0.760768]\n",
      "epoch:4 step:4575 [D loss: 0.697288, acc.: 53.12%] [G loss: 0.710623]\n",
      "epoch:4 step:4576 [D loss: 0.703393, acc.: 55.47%] [G loss: 0.715696]\n",
      "epoch:4 step:4577 [D loss: 0.691415, acc.: 53.91%] [G loss: 0.726692]\n",
      "epoch:4 step:4578 [D loss: 0.706649, acc.: 49.22%] [G loss: 0.717179]\n",
      "epoch:4 step:4579 [D loss: 0.703270, acc.: 47.66%] [G loss: 0.697713]\n",
      "epoch:4 step:4580 [D loss: 0.682439, acc.: 55.47%] [G loss: 0.707773]\n",
      "epoch:4 step:4581 [D loss: 0.690406, acc.: 50.00%] [G loss: 0.713721]\n",
      "epoch:4 step:4582 [D loss: 0.705380, acc.: 46.88%] [G loss: 0.754650]\n",
      "epoch:4 step:4583 [D loss: 0.692460, acc.: 55.47%] [G loss: 0.743631]\n",
      "epoch:4 step:4584 [D loss: 0.695727, acc.: 51.56%] [G loss: 0.773103]\n",
      "epoch:4 step:4585 [D loss: 0.681669, acc.: 53.12%] [G loss: 0.743605]\n",
      "epoch:4 step:4586 [D loss: 0.693877, acc.: 47.66%] [G loss: 0.743549]\n",
      "epoch:4 step:4587 [D loss: 0.679471, acc.: 60.16%] [G loss: 0.755472]\n",
      "epoch:4 step:4588 [D loss: 0.669445, acc.: 61.72%] [G loss: 0.734373]\n",
      "epoch:4 step:4589 [D loss: 0.684516, acc.: 54.69%] [G loss: 0.741657]\n",
      "epoch:4 step:4590 [D loss: 0.668887, acc.: 61.72%] [G loss: 0.694006]\n",
      "epoch:4 step:4591 [D loss: 0.736396, acc.: 39.84%] [G loss: 0.693111]\n",
      "epoch:4 step:4592 [D loss: 0.710854, acc.: 42.97%] [G loss: 0.688679]\n",
      "epoch:4 step:4593 [D loss: 0.683925, acc.: 59.38%] [G loss: 0.705502]\n",
      "epoch:4 step:4594 [D loss: 0.700616, acc.: 46.88%] [G loss: 0.711028]\n",
      "epoch:4 step:4595 [D loss: 0.707361, acc.: 40.62%] [G loss: 0.710869]\n",
      "epoch:4 step:4596 [D loss: 0.703369, acc.: 47.66%] [G loss: 0.729912]\n",
      "epoch:4 step:4597 [D loss: 0.684183, acc.: 55.47%] [G loss: 0.735615]\n",
      "epoch:4 step:4598 [D loss: 0.704401, acc.: 40.62%] [G loss: 0.772922]\n",
      "epoch:4 step:4599 [D loss: 0.681830, acc.: 60.16%] [G loss: 0.732464]\n",
      "epoch:4 step:4600 [D loss: 0.668591, acc.: 58.59%] [G loss: 0.786340]\n",
      "##############\n",
      "[3.66949084 2.77030544 6.30947794 5.16303153 4.29226627 6.40923327\n",
      " 4.86227214 5.1859386  5.78187492 4.8482866 ]\n",
      "##########\n",
      "epoch:4 step:4601 [D loss: 0.663073, acc.: 66.41%] [G loss: 0.801768]\n",
      "epoch:4 step:4602 [D loss: 0.657602, acc.: 64.84%] [G loss: 0.812476]\n",
      "epoch:4 step:4603 [D loss: 0.666145, acc.: 64.06%] [G loss: 0.828452]\n",
      "epoch:4 step:4604 [D loss: 0.659230, acc.: 62.50%] [G loss: 0.841827]\n",
      "epoch:4 step:4605 [D loss: 0.696074, acc.: 57.81%] [G loss: 0.754938]\n",
      "epoch:4 step:4606 [D loss: 0.746189, acc.: 40.62%] [G loss: 0.704946]\n",
      "epoch:4 step:4607 [D loss: 0.713631, acc.: 42.19%] [G loss: 0.715247]\n",
      "epoch:4 step:4608 [D loss: 0.705573, acc.: 47.66%] [G loss: 0.717094]\n",
      "epoch:4 step:4609 [D loss: 0.701425, acc.: 51.56%] [G loss: 0.711218]\n",
      "epoch:4 step:4610 [D loss: 0.724040, acc.: 38.28%] [G loss: 0.726384]\n",
      "epoch:4 step:4611 [D loss: 0.689493, acc.: 50.78%] [G loss: 0.699687]\n",
      "epoch:4 step:4612 [D loss: 0.689009, acc.: 51.56%] [G loss: 0.711751]\n",
      "epoch:4 step:4613 [D loss: 0.685026, acc.: 53.91%] [G loss: 0.734728]\n",
      "epoch:4 step:4614 [D loss: 0.688299, acc.: 53.12%] [G loss: 0.717636]\n",
      "epoch:4 step:4615 [D loss: 0.705119, acc.: 50.00%] [G loss: 0.708035]\n",
      "epoch:4 step:4616 [D loss: 0.689507, acc.: 53.12%] [G loss: 0.717738]\n",
      "epoch:4 step:4617 [D loss: 0.683349, acc.: 50.00%] [G loss: 0.727822]\n",
      "epoch:4 step:4618 [D loss: 0.706937, acc.: 44.53%] [G loss: 0.698918]\n",
      "epoch:4 step:4619 [D loss: 0.696132, acc.: 54.69%] [G loss: 0.719844]\n",
      "epoch:4 step:4620 [D loss: 0.703712, acc.: 46.88%] [G loss: 0.689019]\n",
      "epoch:4 step:4621 [D loss: 0.686991, acc.: 57.03%] [G loss: 0.717566]\n",
      "epoch:4 step:4622 [D loss: 0.705998, acc.: 49.22%] [G loss: 0.706285]\n",
      "epoch:4 step:4623 [D loss: 0.685732, acc.: 56.25%] [G loss: 0.731722]\n",
      "epoch:4 step:4624 [D loss: 0.700452, acc.: 46.09%] [G loss: 0.703750]\n",
      "epoch:4 step:4625 [D loss: 0.693502, acc.: 53.12%] [G loss: 0.713919]\n",
      "epoch:4 step:4626 [D loss: 0.689999, acc.: 51.56%] [G loss: 0.696379]\n",
      "epoch:4 step:4627 [D loss: 0.702819, acc.: 42.19%] [G loss: 0.716510]\n",
      "epoch:4 step:4628 [D loss: 0.695842, acc.: 47.66%] [G loss: 0.703971]\n",
      "epoch:4 step:4629 [D loss: 0.702210, acc.: 53.12%] [G loss: 0.692550]\n",
      "epoch:4 step:4630 [D loss: 0.706703, acc.: 44.53%] [G loss: 0.702586]\n",
      "epoch:4 step:4631 [D loss: 0.687588, acc.: 53.12%] [G loss: 0.737966]\n",
      "epoch:4 step:4632 [D loss: 0.691156, acc.: 46.88%] [G loss: 0.730627]\n",
      "epoch:4 step:4633 [D loss: 0.684663, acc.: 57.81%] [G loss: 0.719298]\n",
      "epoch:4 step:4634 [D loss: 0.690537, acc.: 56.25%] [G loss: 0.723573]\n",
      "epoch:4 step:4635 [D loss: 0.684023, acc.: 55.47%] [G loss: 0.730047]\n",
      "epoch:4 step:4636 [D loss: 0.681355, acc.: 53.91%] [G loss: 0.733917]\n",
      "epoch:4 step:4637 [D loss: 0.677892, acc.: 56.25%] [G loss: 0.765822]\n",
      "epoch:4 step:4638 [D loss: 0.667426, acc.: 63.28%] [G loss: 0.765114]\n",
      "epoch:4 step:4639 [D loss: 0.723304, acc.: 39.06%] [G loss: 0.740029]\n",
      "epoch:4 step:4640 [D loss: 0.694317, acc.: 50.78%] [G loss: 0.748447]\n",
      "epoch:4 step:4641 [D loss: 0.729753, acc.: 38.28%] [G loss: 0.721128]\n",
      "epoch:4 step:4642 [D loss: 0.692426, acc.: 48.44%] [G loss: 0.717640]\n",
      "epoch:4 step:4643 [D loss: 0.713485, acc.: 46.88%] [G loss: 0.720358]\n",
      "epoch:4 step:4644 [D loss: 0.699663, acc.: 48.44%] [G loss: 0.712447]\n",
      "epoch:4 step:4645 [D loss: 0.689455, acc.: 46.88%] [G loss: 0.727346]\n",
      "epoch:4 step:4646 [D loss: 0.690189, acc.: 55.47%] [G loss: 0.747613]\n",
      "epoch:4 step:4647 [D loss: 0.680891, acc.: 55.47%] [G loss: 0.723280]\n",
      "epoch:4 step:4648 [D loss: 0.659296, acc.: 67.19%] [G loss: 0.730747]\n",
      "epoch:4 step:4649 [D loss: 0.680444, acc.: 57.03%] [G loss: 0.735725]\n",
      "epoch:4 step:4650 [D loss: 0.673155, acc.: 64.06%] [G loss: 0.724690]\n",
      "epoch:4 step:4651 [D loss: 0.683901, acc.: 53.91%] [G loss: 0.715528]\n",
      "epoch:4 step:4652 [D loss: 0.717190, acc.: 35.94%] [G loss: 0.699544]\n",
      "epoch:4 step:4653 [D loss: 0.714052, acc.: 48.44%] [G loss: 0.700844]\n",
      "epoch:4 step:4654 [D loss: 0.708125, acc.: 40.62%] [G loss: 0.708020]\n",
      "epoch:4 step:4655 [D loss: 0.706883, acc.: 46.09%] [G loss: 0.704292]\n",
      "epoch:4 step:4656 [D loss: 0.696107, acc.: 46.88%] [G loss: 0.707025]\n",
      "epoch:4 step:4657 [D loss: 0.695176, acc.: 50.00%] [G loss: 0.704831]\n",
      "epoch:4 step:4658 [D loss: 0.692896, acc.: 47.66%] [G loss: 0.709363]\n",
      "epoch:4 step:4659 [D loss: 0.697266, acc.: 46.09%] [G loss: 0.714298]\n",
      "epoch:4 step:4660 [D loss: 0.651897, acc.: 66.41%] [G loss: 0.686227]\n",
      "epoch:4 step:4661 [D loss: 0.713965, acc.: 40.62%] [G loss: 0.728972]\n",
      "epoch:4 step:4662 [D loss: 0.682958, acc.: 52.34%] [G loss: 0.748692]\n",
      "epoch:4 step:4663 [D loss: 0.723750, acc.: 42.97%] [G loss: 0.724031]\n",
      "epoch:4 step:4664 [D loss: 0.692889, acc.: 46.09%] [G loss: 0.730934]\n",
      "epoch:4 step:4665 [D loss: 0.683009, acc.: 54.69%] [G loss: 0.729941]\n",
      "epoch:4 step:4666 [D loss: 0.682052, acc.: 58.59%] [G loss: 0.730314]\n",
      "epoch:4 step:4667 [D loss: 0.686660, acc.: 57.81%] [G loss: 0.738894]\n",
      "epoch:4 step:4668 [D loss: 0.716263, acc.: 43.75%] [G loss: 0.717011]\n",
      "epoch:4 step:4669 [D loss: 0.685021, acc.: 57.03%] [G loss: 0.741719]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4670 [D loss: 0.690566, acc.: 61.72%] [G loss: 0.737962]\n",
      "epoch:4 step:4671 [D loss: 0.676277, acc.: 56.25%] [G loss: 0.726671]\n",
      "epoch:4 step:4672 [D loss: 0.677586, acc.: 54.69%] [G loss: 0.738149]\n",
      "epoch:4 step:4673 [D loss: 0.642613, acc.: 65.62%] [G loss: 0.680434]\n",
      "epoch:4 step:4674 [D loss: 0.647337, acc.: 60.16%] [G loss: 0.656449]\n",
      "epoch:4 step:4675 [D loss: 0.707080, acc.: 54.69%] [G loss: 0.729089]\n",
      "epoch:4 step:4676 [D loss: 0.705124, acc.: 49.22%] [G loss: 0.734179]\n",
      "epoch:4 step:4677 [D loss: 0.724816, acc.: 40.62%] [G loss: 0.752046]\n",
      "epoch:4 step:4678 [D loss: 0.678296, acc.: 56.25%] [G loss: 0.741513]\n",
      "epoch:4 step:4679 [D loss: 0.676581, acc.: 56.25%] [G loss: 0.702344]\n",
      "epoch:4 step:4680 [D loss: 0.693117, acc.: 53.12%] [G loss: 0.716818]\n",
      "epoch:4 step:4681 [D loss: 0.673591, acc.: 57.03%] [G loss: 0.700907]\n",
      "epoch:4 step:4682 [D loss: 0.669913, acc.: 51.56%] [G loss: 0.612687]\n",
      "epoch:4 step:4683 [D loss: 0.705994, acc.: 49.22%] [G loss: 0.661702]\n",
      "epoch:4 step:4684 [D loss: 0.537656, acc.: 71.88%] [G loss: 0.722447]\n",
      "epoch:4 step:4685 [D loss: 0.599917, acc.: 57.81%] [G loss: 0.603910]\n",
      "epoch:5 step:4686 [D loss: 0.736624, acc.: 48.44%] [G loss: 0.735911]\n",
      "epoch:5 step:4687 [D loss: 0.739493, acc.: 32.81%] [G loss: 0.788039]\n",
      "epoch:5 step:4688 [D loss: 0.697282, acc.: 46.88%] [G loss: 0.783602]\n",
      "epoch:5 step:4689 [D loss: 0.699454, acc.: 46.09%] [G loss: 0.802415]\n",
      "epoch:5 step:4690 [D loss: 0.687597, acc.: 52.34%] [G loss: 0.777932]\n",
      "epoch:5 step:4691 [D loss: 0.771820, acc.: 31.25%] [G loss: 0.839827]\n",
      "epoch:5 step:4692 [D loss: 0.671002, acc.: 58.59%] [G loss: 0.906783]\n",
      "epoch:5 step:4693 [D loss: 0.681679, acc.: 53.12%] [G loss: 0.880511]\n",
      "epoch:5 step:4694 [D loss: 0.701747, acc.: 50.00%] [G loss: 0.791987]\n",
      "epoch:5 step:4695 [D loss: 0.717613, acc.: 48.44%] [G loss: 0.763098]\n",
      "epoch:5 step:4696 [D loss: 0.712076, acc.: 52.34%] [G loss: 0.764654]\n",
      "epoch:5 step:4697 [D loss: 0.739157, acc.: 42.19%] [G loss: 0.715158]\n",
      "epoch:5 step:4698 [D loss: 0.715785, acc.: 45.31%] [G loss: 0.740479]\n",
      "epoch:5 step:4699 [D loss: 0.708968, acc.: 45.31%] [G loss: 0.723255]\n",
      "epoch:5 step:4700 [D loss: 0.720795, acc.: 34.38%] [G loss: 0.721130]\n",
      "epoch:5 step:4701 [D loss: 0.700106, acc.: 49.22%] [G loss: 0.727831]\n",
      "epoch:5 step:4702 [D loss: 0.708932, acc.: 35.94%] [G loss: 0.715409]\n",
      "epoch:5 step:4703 [D loss: 0.703752, acc.: 37.50%] [G loss: 0.760880]\n",
      "epoch:5 step:4704 [D loss: 0.698027, acc.: 44.53%] [G loss: 0.719368]\n",
      "epoch:5 step:4705 [D loss: 0.686255, acc.: 50.00%] [G loss: 0.730502]\n",
      "epoch:5 step:4706 [D loss: 0.692713, acc.: 52.34%] [G loss: 0.734535]\n",
      "epoch:5 step:4707 [D loss: 0.674127, acc.: 60.16%] [G loss: 0.735875]\n",
      "epoch:5 step:4708 [D loss: 0.685221, acc.: 53.91%] [G loss: 0.750925]\n",
      "epoch:5 step:4709 [D loss: 0.692245, acc.: 50.00%] [G loss: 0.745282]\n",
      "epoch:5 step:4710 [D loss: 0.687194, acc.: 57.81%] [G loss: 0.749967]\n",
      "epoch:5 step:4711 [D loss: 0.693466, acc.: 54.69%] [G loss: 0.749000]\n",
      "epoch:5 step:4712 [D loss: 0.710823, acc.: 37.50%] [G loss: 0.721613]\n",
      "epoch:5 step:4713 [D loss: 0.713184, acc.: 41.41%] [G loss: 0.711942]\n",
      "epoch:5 step:4714 [D loss: 0.689911, acc.: 52.34%] [G loss: 0.716857]\n",
      "epoch:5 step:4715 [D loss: 0.691404, acc.: 50.78%] [G loss: 0.705895]\n",
      "epoch:5 step:4716 [D loss: 0.691271, acc.: 52.34%] [G loss: 0.702752]\n",
      "epoch:5 step:4717 [D loss: 0.688129, acc.: 53.12%] [G loss: 0.704249]\n",
      "epoch:5 step:4718 [D loss: 0.706836, acc.: 43.75%] [G loss: 0.696866]\n",
      "epoch:5 step:4719 [D loss: 0.700741, acc.: 43.75%] [G loss: 0.708541]\n",
      "epoch:5 step:4720 [D loss: 0.696258, acc.: 48.44%] [G loss: 0.694129]\n",
      "epoch:5 step:4721 [D loss: 0.700375, acc.: 57.81%] [G loss: 0.700239]\n",
      "epoch:5 step:4722 [D loss: 0.706205, acc.: 43.75%] [G loss: 0.691636]\n",
      "epoch:5 step:4723 [D loss: 0.717357, acc.: 35.94%] [G loss: 0.700325]\n",
      "epoch:5 step:4724 [D loss: 0.704329, acc.: 45.31%] [G loss: 0.707686]\n",
      "epoch:5 step:4725 [D loss: 0.703274, acc.: 46.88%] [G loss: 0.710106]\n",
      "epoch:5 step:4726 [D loss: 0.702660, acc.: 47.66%] [G loss: 0.632997]\n",
      "epoch:5 step:4727 [D loss: 0.690205, acc.: 53.12%] [G loss: 0.719792]\n",
      "epoch:5 step:4728 [D loss: 0.697570, acc.: 42.97%] [G loss: 0.707586]\n",
      "epoch:5 step:4729 [D loss: 0.694736, acc.: 44.53%] [G loss: 0.725771]\n",
      "epoch:5 step:4730 [D loss: 0.693986, acc.: 53.91%] [G loss: 0.722862]\n",
      "epoch:5 step:4731 [D loss: 0.695118, acc.: 47.66%] [G loss: 0.708588]\n",
      "epoch:5 step:4732 [D loss: 0.687001, acc.: 49.22%] [G loss: 0.724280]\n",
      "epoch:5 step:4733 [D loss: 0.676764, acc.: 60.94%] [G loss: 0.731118]\n",
      "epoch:5 step:4734 [D loss: 0.686747, acc.: 55.47%] [G loss: 0.731985]\n",
      "epoch:5 step:4735 [D loss: 0.677246, acc.: 55.47%] [G loss: 0.735311]\n",
      "epoch:5 step:4736 [D loss: 0.692658, acc.: 51.56%] [G loss: 0.739127]\n",
      "epoch:5 step:4737 [D loss: 0.691450, acc.: 50.00%] [G loss: 0.709930]\n",
      "epoch:5 step:4738 [D loss: 0.687459, acc.: 62.50%] [G loss: 0.708437]\n",
      "epoch:5 step:4739 [D loss: 0.683131, acc.: 53.91%] [G loss: 0.750444]\n",
      "epoch:5 step:4740 [D loss: 0.683815, acc.: 57.81%] [G loss: 0.704054]\n",
      "epoch:5 step:4741 [D loss: 0.698452, acc.: 53.12%] [G loss: 0.711139]\n",
      "epoch:5 step:4742 [D loss: 0.711149, acc.: 37.50%] [G loss: 0.702129]\n",
      "epoch:5 step:4743 [D loss: 0.712902, acc.: 39.06%] [G loss: 0.718082]\n",
      "epoch:5 step:4744 [D loss: 0.708480, acc.: 47.66%] [G loss: 0.706554]\n",
      "epoch:5 step:4745 [D loss: 0.722109, acc.: 42.97%] [G loss: 0.690008]\n",
      "epoch:5 step:4746 [D loss: 0.701039, acc.: 50.00%] [G loss: 0.703825]\n",
      "epoch:5 step:4747 [D loss: 0.701255, acc.: 48.44%] [G loss: 0.704921]\n",
      "epoch:5 step:4748 [D loss: 0.693148, acc.: 49.22%] [G loss: 0.726769]\n",
      "epoch:5 step:4749 [D loss: 0.679964, acc.: 61.72%] [G loss: 0.724360]\n",
      "epoch:5 step:4750 [D loss: 0.691808, acc.: 54.69%] [G loss: 0.722705]\n",
      "epoch:5 step:4751 [D loss: 0.685802, acc.: 53.91%] [G loss: 0.738740]\n",
      "epoch:5 step:4752 [D loss: 0.672558, acc.: 71.09%] [G loss: 0.748572]\n",
      "epoch:5 step:4753 [D loss: 0.681064, acc.: 61.72%] [G loss: 0.777783]\n",
      "epoch:5 step:4754 [D loss: 0.675376, acc.: 60.16%] [G loss: 0.777176]\n",
      "epoch:5 step:4755 [D loss: 0.693627, acc.: 53.91%] [G loss: 0.743743]\n",
      "epoch:5 step:4756 [D loss: 0.693078, acc.: 56.25%] [G loss: 0.702535]\n",
      "epoch:5 step:4757 [D loss: 0.683829, acc.: 58.59%] [G loss: 0.717333]\n",
      "epoch:5 step:4758 [D loss: 0.698875, acc.: 50.78%] [G loss: 0.713495]\n",
      "epoch:5 step:4759 [D loss: 0.684757, acc.: 57.81%] [G loss: 0.730544]\n",
      "epoch:5 step:4760 [D loss: 0.698849, acc.: 53.12%] [G loss: 0.716793]\n",
      "epoch:5 step:4761 [D loss: 0.684839, acc.: 50.00%] [G loss: 0.720807]\n",
      "epoch:5 step:4762 [D loss: 0.672217, acc.: 64.06%] [G loss: 0.738591]\n",
      "epoch:5 step:4763 [D loss: 0.709033, acc.: 46.88%] [G loss: 0.722919]\n",
      "epoch:5 step:4764 [D loss: 0.714582, acc.: 39.84%] [G loss: 0.721324]\n",
      "epoch:5 step:4765 [D loss: 0.712758, acc.: 39.84%] [G loss: 0.707380]\n",
      "epoch:5 step:4766 [D loss: 0.697703, acc.: 44.53%] [G loss: 0.701228]\n",
      "epoch:5 step:4767 [D loss: 0.699817, acc.: 45.31%] [G loss: 0.711711]\n",
      "epoch:5 step:4768 [D loss: 0.695836, acc.: 52.34%] [G loss: 0.721424]\n",
      "epoch:5 step:4769 [D loss: 0.707827, acc.: 46.09%] [G loss: 0.715840]\n",
      "epoch:5 step:4770 [D loss: 0.672441, acc.: 61.72%] [G loss: 0.710392]\n",
      "epoch:5 step:4771 [D loss: 0.691664, acc.: 53.91%] [G loss: 0.669384]\n",
      "epoch:5 step:4772 [D loss: 0.692752, acc.: 49.22%] [G loss: 0.708060]\n",
      "epoch:5 step:4773 [D loss: 0.687470, acc.: 52.34%] [G loss: 0.712632]\n",
      "epoch:5 step:4774 [D loss: 0.665640, acc.: 64.06%] [G loss: 0.692049]\n",
      "epoch:5 step:4775 [D loss: 0.693191, acc.: 51.56%] [G loss: 0.719456]\n",
      "epoch:5 step:4776 [D loss: 0.678118, acc.: 55.47%] [G loss: 0.721301]\n",
      "epoch:5 step:4777 [D loss: 0.673392, acc.: 60.16%] [G loss: 0.699781]\n",
      "epoch:5 step:4778 [D loss: 0.675991, acc.: 60.94%] [G loss: 0.723076]\n",
      "epoch:5 step:4779 [D loss: 0.693028, acc.: 53.12%] [G loss: 0.725114]\n",
      "epoch:5 step:4780 [D loss: 0.718883, acc.: 42.19%] [G loss: 0.730378]\n",
      "epoch:5 step:4781 [D loss: 0.715617, acc.: 46.88%] [G loss: 0.703408]\n",
      "epoch:5 step:4782 [D loss: 0.693796, acc.: 57.03%] [G loss: 0.717325]\n",
      "epoch:5 step:4783 [D loss: 0.701563, acc.: 47.66%] [G loss: 0.724195]\n",
      "epoch:5 step:4784 [D loss: 0.697772, acc.: 48.44%] [G loss: 0.714615]\n",
      "epoch:5 step:4785 [D loss: 0.696902, acc.: 52.34%] [G loss: 0.696793]\n",
      "epoch:5 step:4786 [D loss: 0.694663, acc.: 56.25%] [G loss: 0.716302]\n",
      "epoch:5 step:4787 [D loss: 0.863276, acc.: 40.62%] [G loss: 0.765507]\n",
      "epoch:5 step:4788 [D loss: 0.694578, acc.: 58.59%] [G loss: 0.856309]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4789 [D loss: 0.682902, acc.: 56.25%] [G loss: 0.804814]\n",
      "epoch:5 step:4790 [D loss: 0.683405, acc.: 60.94%] [G loss: 0.796024]\n",
      "epoch:5 step:4791 [D loss: 0.739044, acc.: 37.50%] [G loss: 0.769767]\n",
      "epoch:5 step:4792 [D loss: 0.684121, acc.: 53.12%] [G loss: 0.723968]\n",
      "epoch:5 step:4793 [D loss: 0.707869, acc.: 48.44%] [G loss: 0.725697]\n",
      "epoch:5 step:4794 [D loss: 0.697553, acc.: 48.44%] [G loss: 0.729922]\n",
      "epoch:5 step:4795 [D loss: 0.699417, acc.: 50.78%] [G loss: 0.721642]\n",
      "epoch:5 step:4796 [D loss: 0.704870, acc.: 45.31%] [G loss: 0.736378]\n",
      "epoch:5 step:4797 [D loss: 0.699911, acc.: 45.31%] [G loss: 0.710420]\n",
      "epoch:5 step:4798 [D loss: 0.733136, acc.: 31.25%] [G loss: 0.714255]\n",
      "epoch:5 step:4799 [D loss: 0.698200, acc.: 48.44%] [G loss: 0.699102]\n",
      "epoch:5 step:4800 [D loss: 0.694559, acc.: 52.34%] [G loss: 0.694249]\n",
      "##############\n",
      "[4.1451352  2.32621577 6.79529764 5.68789181 4.09761702 6.34615218\n",
      " 5.47046867 5.23715965 5.7475123  5.03915558]\n",
      "##########\n",
      "epoch:5 step:4801 [D loss: 0.690439, acc.: 51.56%] [G loss: 0.710085]\n",
      "epoch:5 step:4802 [D loss: 0.687875, acc.: 50.00%] [G loss: 0.716276]\n",
      "epoch:5 step:4803 [D loss: 0.689276, acc.: 52.34%] [G loss: 0.697073]\n",
      "epoch:5 step:4804 [D loss: 0.692041, acc.: 52.34%] [G loss: 0.694281]\n",
      "epoch:5 step:4805 [D loss: 0.704652, acc.: 39.84%] [G loss: 0.687580]\n",
      "epoch:5 step:4806 [D loss: 0.725723, acc.: 43.75%] [G loss: 0.689872]\n",
      "epoch:5 step:4807 [D loss: 0.702904, acc.: 47.66%] [G loss: 0.694258]\n",
      "epoch:5 step:4808 [D loss: 0.703133, acc.: 44.53%] [G loss: 0.690788]\n",
      "epoch:5 step:4809 [D loss: 0.702100, acc.: 45.31%] [G loss: 0.696519]\n",
      "epoch:5 step:4810 [D loss: 0.712603, acc.: 42.97%] [G loss: 0.699798]\n",
      "epoch:5 step:4811 [D loss: 0.709859, acc.: 40.62%] [G loss: 0.709705]\n",
      "epoch:5 step:4812 [D loss: 0.685754, acc.: 53.12%] [G loss: 0.729267]\n",
      "epoch:5 step:4813 [D loss: 0.692274, acc.: 57.03%] [G loss: 0.708323]\n",
      "epoch:5 step:4814 [D loss: 0.687144, acc.: 54.69%] [G loss: 0.727991]\n",
      "epoch:5 step:4815 [D loss: 0.683318, acc.: 48.44%] [G loss: 0.723602]\n",
      "epoch:5 step:4816 [D loss: 0.683578, acc.: 57.03%] [G loss: 0.732492]\n",
      "epoch:5 step:4817 [D loss: 0.684640, acc.: 54.69%] [G loss: 0.740516]\n",
      "epoch:5 step:4818 [D loss: 0.688238, acc.: 58.59%] [G loss: 0.767951]\n",
      "epoch:5 step:4819 [D loss: 0.681552, acc.: 61.72%] [G loss: 0.747622]\n",
      "epoch:5 step:4820 [D loss: 0.670799, acc.: 62.50%] [G loss: 0.749378]\n",
      "epoch:5 step:4821 [D loss: 0.660385, acc.: 66.41%] [G loss: 0.777586]\n",
      "epoch:5 step:4822 [D loss: 0.678252, acc.: 57.81%] [G loss: 0.764305]\n",
      "epoch:5 step:4823 [D loss: 0.659932, acc.: 64.84%] [G loss: 0.762150]\n",
      "epoch:5 step:4824 [D loss: 0.678797, acc.: 57.03%] [G loss: 0.769280]\n",
      "epoch:5 step:4825 [D loss: 0.699800, acc.: 49.22%] [G loss: 0.743464]\n",
      "epoch:5 step:4826 [D loss: 0.732792, acc.: 46.88%] [G loss: 0.669503]\n",
      "epoch:5 step:4827 [D loss: 0.718212, acc.: 38.28%] [G loss: 0.702530]\n",
      "epoch:5 step:4828 [D loss: 0.729127, acc.: 34.38%] [G loss: 0.705875]\n",
      "epoch:5 step:4829 [D loss: 0.713443, acc.: 41.41%] [G loss: 0.686784]\n",
      "epoch:5 step:4830 [D loss: 0.709699, acc.: 36.72%] [G loss: 0.715901]\n",
      "epoch:5 step:4831 [D loss: 0.688018, acc.: 51.56%] [G loss: 0.716072]\n",
      "epoch:5 step:4832 [D loss: 0.688625, acc.: 52.34%] [G loss: 0.710858]\n",
      "epoch:5 step:4833 [D loss: 0.693341, acc.: 53.91%] [G loss: 0.715387]\n",
      "epoch:5 step:4834 [D loss: 0.693945, acc.: 53.91%] [G loss: 0.704434]\n",
      "epoch:5 step:4835 [D loss: 0.694042, acc.: 53.91%] [G loss: 0.724225]\n",
      "epoch:5 step:4836 [D loss: 0.683649, acc.: 57.81%] [G loss: 0.736474]\n",
      "epoch:5 step:4837 [D loss: 0.688233, acc.: 51.56%] [G loss: 0.747717]\n",
      "epoch:5 step:4838 [D loss: 0.681562, acc.: 58.59%] [G loss: 0.743174]\n",
      "epoch:5 step:4839 [D loss: 0.670268, acc.: 62.50%] [G loss: 0.734805]\n",
      "epoch:5 step:4840 [D loss: 0.683959, acc.: 53.12%] [G loss: 0.731275]\n",
      "epoch:5 step:4841 [D loss: 0.675145, acc.: 62.50%] [G loss: 0.772923]\n",
      "epoch:5 step:4842 [D loss: 0.695298, acc.: 50.78%] [G loss: 0.715779]\n",
      "epoch:5 step:4843 [D loss: 0.699652, acc.: 52.34%] [G loss: 0.711812]\n",
      "epoch:5 step:4844 [D loss: 0.696781, acc.: 53.12%] [G loss: 0.693493]\n",
      "epoch:5 step:4845 [D loss: 0.768685, acc.: 35.94%] [G loss: 0.708014]\n",
      "epoch:5 step:4846 [D loss: 0.732878, acc.: 35.94%] [G loss: 0.719404]\n",
      "epoch:5 step:4847 [D loss: 0.700185, acc.: 49.22%] [G loss: 0.725775]\n",
      "epoch:5 step:4848 [D loss: 0.695932, acc.: 50.00%] [G loss: 0.734295]\n",
      "epoch:5 step:4849 [D loss: 0.672857, acc.: 63.28%] [G loss: 0.730379]\n",
      "epoch:5 step:4850 [D loss: 0.679839, acc.: 56.25%] [G loss: 0.735566]\n",
      "epoch:5 step:4851 [D loss: 0.671842, acc.: 59.38%] [G loss: 0.745158]\n",
      "epoch:5 step:4852 [D loss: 0.685401, acc.: 48.44%] [G loss: 0.749045]\n",
      "epoch:5 step:4853 [D loss: 0.670209, acc.: 60.16%] [G loss: 0.745161]\n",
      "epoch:5 step:4854 [D loss: 0.710141, acc.: 48.44%] [G loss: 0.740646]\n",
      "epoch:5 step:4855 [D loss: 0.685378, acc.: 53.12%] [G loss: 0.760519]\n",
      "epoch:5 step:4856 [D loss: 0.691133, acc.: 50.00%] [G loss: 0.699625]\n",
      "epoch:5 step:4857 [D loss: 0.685124, acc.: 55.47%] [G loss: 0.722639]\n",
      "epoch:5 step:4858 [D loss: 0.724231, acc.: 46.88%] [G loss: 0.711544]\n",
      "epoch:5 step:4859 [D loss: 0.692267, acc.: 49.22%] [G loss: 0.698841]\n",
      "epoch:5 step:4860 [D loss: 0.706558, acc.: 46.09%] [G loss: 0.701860]\n",
      "epoch:5 step:4861 [D loss: 0.691939, acc.: 50.78%] [G loss: 0.687924]\n",
      "epoch:5 step:4862 [D loss: 0.704128, acc.: 44.53%] [G loss: 0.702651]\n",
      "epoch:5 step:4863 [D loss: 0.699913, acc.: 46.88%] [G loss: 0.697457]\n",
      "epoch:5 step:4864 [D loss: 0.698405, acc.: 50.00%] [G loss: 0.710977]\n",
      "epoch:5 step:4865 [D loss: 0.706028, acc.: 40.62%] [G loss: 0.705232]\n",
      "epoch:5 step:4866 [D loss: 0.683504, acc.: 46.88%] [G loss: 0.724804]\n",
      "epoch:5 step:4867 [D loss: 0.690927, acc.: 57.81%] [G loss: 0.730808]\n",
      "epoch:5 step:4868 [D loss: 0.689891, acc.: 56.25%] [G loss: 0.734089]\n",
      "epoch:5 step:4869 [D loss: 0.673617, acc.: 60.94%] [G loss: 0.739665]\n",
      "epoch:5 step:4870 [D loss: 0.687129, acc.: 55.47%] [G loss: 0.731238]\n",
      "epoch:5 step:4871 [D loss: 0.688555, acc.: 53.12%] [G loss: 0.721784]\n",
      "epoch:5 step:4872 [D loss: 0.650792, acc.: 64.84%] [G loss: 0.717291]\n",
      "epoch:5 step:4873 [D loss: 0.677334, acc.: 61.72%] [G loss: 0.728446]\n",
      "epoch:5 step:4874 [D loss: 0.694808, acc.: 51.56%] [G loss: 0.712230]\n",
      "epoch:5 step:4875 [D loss: 0.695483, acc.: 47.66%] [G loss: 0.701513]\n",
      "epoch:5 step:4876 [D loss: 0.688354, acc.: 54.69%] [G loss: 0.696983]\n",
      "epoch:5 step:4877 [D loss: 0.679290, acc.: 56.25%] [G loss: 0.683813]\n",
      "epoch:5 step:4878 [D loss: 0.680292, acc.: 56.25%] [G loss: 0.700852]\n",
      "epoch:5 step:4879 [D loss: 0.687753, acc.: 52.34%] [G loss: 0.688575]\n",
      "epoch:5 step:4880 [D loss: 0.689203, acc.: 48.44%] [G loss: 0.689109]\n",
      "epoch:5 step:4881 [D loss: 0.700068, acc.: 45.31%] [G loss: 0.712059]\n",
      "epoch:5 step:4882 [D loss: 0.728014, acc.: 48.44%] [G loss: 0.701723]\n",
      "epoch:5 step:4883 [D loss: 0.689513, acc.: 53.12%] [G loss: 0.730854]\n",
      "epoch:5 step:4884 [D loss: 0.702063, acc.: 47.66%] [G loss: 0.712306]\n",
      "epoch:5 step:4885 [D loss: 0.711033, acc.: 48.44%] [G loss: 0.744657]\n",
      "epoch:5 step:4886 [D loss: 0.691001, acc.: 52.34%] [G loss: 0.752686]\n",
      "epoch:5 step:4887 [D loss: 0.678712, acc.: 57.81%] [G loss: 0.762219]\n",
      "epoch:5 step:4888 [D loss: 0.696368, acc.: 53.91%] [G loss: 0.762061]\n",
      "epoch:5 step:4889 [D loss: 0.668886, acc.: 60.16%] [G loss: 0.737976]\n",
      "epoch:5 step:4890 [D loss: 0.686805, acc.: 55.47%] [G loss: 0.742730]\n",
      "epoch:5 step:4891 [D loss: 0.678110, acc.: 56.25%] [G loss: 0.750430]\n",
      "epoch:5 step:4892 [D loss: 0.691625, acc.: 48.44%] [G loss: 0.729662]\n",
      "epoch:5 step:4893 [D loss: 0.693408, acc.: 61.72%] [G loss: 0.747939]\n",
      "epoch:5 step:4894 [D loss: 0.719988, acc.: 52.34%] [G loss: 0.751381]\n",
      "epoch:5 step:4895 [D loss: 0.691027, acc.: 49.22%] [G loss: 0.679857]\n",
      "epoch:5 step:4896 [D loss: 0.697184, acc.: 50.00%] [G loss: 0.733503]\n",
      "epoch:5 step:4897 [D loss: 0.731933, acc.: 31.25%] [G loss: 0.739839]\n",
      "epoch:5 step:4898 [D loss: 0.697004, acc.: 46.88%] [G loss: 0.714193]\n",
      "epoch:5 step:4899 [D loss: 0.704051, acc.: 49.22%] [G loss: 0.736425]\n",
      "epoch:5 step:4900 [D loss: 0.710544, acc.: 39.06%] [G loss: 0.685133]\n",
      "epoch:5 step:4901 [D loss: 0.699017, acc.: 46.88%] [G loss: 0.737142]\n",
      "epoch:5 step:4902 [D loss: 0.721801, acc.: 39.84%] [G loss: 0.743604]\n",
      "epoch:5 step:4903 [D loss: 0.689612, acc.: 58.59%] [G loss: 0.686744]\n",
      "epoch:5 step:4904 [D loss: 0.694591, acc.: 47.66%] [G loss: 0.689870]\n",
      "epoch:5 step:4905 [D loss: 0.715620, acc.: 37.50%] [G loss: 0.724357]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4906 [D loss: 0.699789, acc.: 39.84%] [G loss: 0.730482]\n",
      "epoch:5 step:4907 [D loss: 0.692896, acc.: 43.75%] [G loss: 0.729131]\n",
      "epoch:5 step:4908 [D loss: 0.690813, acc.: 50.00%] [G loss: 0.743728]\n",
      "epoch:5 step:4909 [D loss: 0.689969, acc.: 49.22%] [G loss: 0.726946]\n",
      "epoch:5 step:4910 [D loss: 0.680053, acc.: 53.91%] [G loss: 0.736911]\n",
      "epoch:5 step:4911 [D loss: 0.688930, acc.: 53.12%] [G loss: 0.747218]\n",
      "epoch:5 step:4912 [D loss: 0.684592, acc.: 53.91%] [G loss: 0.748451]\n",
      "epoch:5 step:4913 [D loss: 0.688489, acc.: 55.47%] [G loss: 0.748306]\n",
      "epoch:5 step:4914 [D loss: 0.674488, acc.: 62.50%] [G loss: 0.745683]\n",
      "epoch:5 step:4915 [D loss: 0.682176, acc.: 55.47%] [G loss: 0.758698]\n",
      "epoch:5 step:4916 [D loss: 0.659258, acc.: 71.09%] [G loss: 1.076160]\n",
      "epoch:5 step:4917 [D loss: 0.662727, acc.: 65.62%] [G loss: 0.780390]\n",
      "epoch:5 step:4918 [D loss: 0.727956, acc.: 39.06%] [G loss: 0.754332]\n",
      "epoch:5 step:4919 [D loss: 0.714268, acc.: 42.19%] [G loss: 0.764665]\n",
      "epoch:5 step:4920 [D loss: 0.703607, acc.: 42.19%] [G loss: 0.724329]\n",
      "epoch:5 step:4921 [D loss: 0.715900, acc.: 37.50%] [G loss: 0.733026]\n",
      "epoch:5 step:4922 [D loss: 0.697866, acc.: 47.66%] [G loss: 0.742976]\n",
      "epoch:5 step:4923 [D loss: 0.704306, acc.: 50.78%] [G loss: 0.743236]\n",
      "epoch:5 step:4924 [D loss: 0.696343, acc.: 48.44%] [G loss: 0.781484]\n",
      "epoch:5 step:4925 [D loss: 0.696117, acc.: 46.09%] [G loss: 0.751630]\n",
      "epoch:5 step:4926 [D loss: 0.682699, acc.: 56.25%] [G loss: 0.763223]\n",
      "epoch:5 step:4927 [D loss: 0.683677, acc.: 54.69%] [G loss: 0.796949]\n",
      "epoch:5 step:4928 [D loss: 0.695377, acc.: 50.00%] [G loss: 0.777696]\n",
      "epoch:5 step:4929 [D loss: 0.677824, acc.: 57.81%] [G loss: 0.775471]\n",
      "epoch:5 step:4930 [D loss: 0.700559, acc.: 45.31%] [G loss: 0.776709]\n",
      "epoch:5 step:4931 [D loss: 0.696173, acc.: 55.47%] [G loss: 0.742507]\n",
      "epoch:5 step:4932 [D loss: 0.683050, acc.: 57.81%] [G loss: 0.758794]\n",
      "epoch:5 step:4933 [D loss: 0.664433, acc.: 67.19%] [G loss: 0.806634]\n",
      "epoch:5 step:4934 [D loss: 0.683703, acc.: 57.81%] [G loss: 0.724097]\n",
      "epoch:5 step:4935 [D loss: 0.699748, acc.: 50.78%] [G loss: 0.708630]\n",
      "epoch:5 step:4936 [D loss: 0.701095, acc.: 42.97%] [G loss: 0.736526]\n",
      "epoch:5 step:4937 [D loss: 0.683508, acc.: 50.00%] [G loss: 0.713891]\n",
      "epoch:5 step:4938 [D loss: 0.703074, acc.: 46.09%] [G loss: 0.699193]\n",
      "epoch:5 step:4939 [D loss: 0.715421, acc.: 44.53%] [G loss: 0.715967]\n",
      "epoch:5 step:4940 [D loss: 0.704278, acc.: 43.75%] [G loss: 0.681231]\n",
      "epoch:5 step:4941 [D loss: 0.699590, acc.: 43.75%] [G loss: 0.701468]\n",
      "epoch:5 step:4942 [D loss: 0.700778, acc.: 47.66%] [G loss: 0.700604]\n",
      "epoch:5 step:4943 [D loss: 0.684604, acc.: 57.03%] [G loss: 0.706400]\n",
      "epoch:5 step:4944 [D loss: 0.682567, acc.: 57.81%] [G loss: 0.722132]\n",
      "epoch:5 step:4945 [D loss: 0.687722, acc.: 53.12%] [G loss: 0.717109]\n",
      "epoch:5 step:4946 [D loss: 0.682734, acc.: 60.94%] [G loss: 0.720440]\n",
      "epoch:5 step:4947 [D loss: 0.680346, acc.: 57.81%] [G loss: 0.745765]\n",
      "epoch:5 step:4948 [D loss: 0.686249, acc.: 53.12%] [G loss: 0.746332]\n",
      "epoch:5 step:4949 [D loss: 0.677455, acc.: 55.47%] [G loss: 0.752309]\n",
      "epoch:5 step:4950 [D loss: 0.707473, acc.: 47.66%] [G loss: 0.703429]\n",
      "epoch:5 step:4951 [D loss: 0.694592, acc.: 48.44%] [G loss: 0.704571]\n",
      "epoch:5 step:4952 [D loss: 0.695398, acc.: 53.12%] [G loss: 0.692500]\n",
      "epoch:5 step:4953 [D loss: 0.693487, acc.: 57.81%] [G loss: 0.705907]\n",
      "epoch:5 step:4954 [D loss: 0.690626, acc.: 53.12%] [G loss: 0.703856]\n",
      "epoch:5 step:4955 [D loss: 0.699495, acc.: 47.66%] [G loss: 0.680465]\n",
      "epoch:5 step:4956 [D loss: 0.692960, acc.: 49.22%] [G loss: 0.733325]\n",
      "epoch:5 step:4957 [D loss: 0.706635, acc.: 49.22%] [G loss: 0.729390]\n",
      "epoch:5 step:4958 [D loss: 0.693801, acc.: 56.25%] [G loss: 0.733578]\n",
      "epoch:5 step:4959 [D loss: 0.680522, acc.: 57.03%] [G loss: 0.726897]\n",
      "epoch:5 step:4960 [D loss: 0.688884, acc.: 57.81%] [G loss: 0.741242]\n",
      "epoch:5 step:4961 [D loss: 0.686119, acc.: 53.12%] [G loss: 0.720563]\n",
      "epoch:5 step:4962 [D loss: 0.700805, acc.: 47.66%] [G loss: 0.736323]\n",
      "epoch:5 step:4963 [D loss: 0.695777, acc.: 50.78%] [G loss: 0.754839]\n",
      "epoch:5 step:4964 [D loss: 0.716048, acc.: 38.28%] [G loss: 0.714576]\n",
      "epoch:5 step:4965 [D loss: 0.702776, acc.: 48.44%] [G loss: 0.714977]\n",
      "epoch:5 step:4966 [D loss: 0.713824, acc.: 42.19%] [G loss: 0.710986]\n",
      "epoch:5 step:4967 [D loss: 0.701839, acc.: 44.53%] [G loss: 0.730411]\n",
      "epoch:5 step:4968 [D loss: 0.698100, acc.: 47.66%] [G loss: 0.711341]\n",
      "epoch:5 step:4969 [D loss: 0.685209, acc.: 58.59%] [G loss: 0.723252]\n",
      "epoch:5 step:4970 [D loss: 0.701241, acc.: 44.53%] [G loss: 0.723569]\n",
      "epoch:5 step:4971 [D loss: 0.689681, acc.: 51.56%] [G loss: 0.720047]\n",
      "epoch:5 step:4972 [D loss: 0.694896, acc.: 46.09%] [G loss: 0.712793]\n",
      "epoch:5 step:4973 [D loss: 0.697120, acc.: 49.22%] [G loss: 0.719127]\n",
      "epoch:5 step:4974 [D loss: 0.686619, acc.: 54.69%] [G loss: 0.710955]\n",
      "epoch:5 step:4975 [D loss: 0.689698, acc.: 47.66%] [G loss: 0.713729]\n",
      "epoch:5 step:4976 [D loss: 0.713665, acc.: 38.28%] [G loss: 0.736962]\n",
      "epoch:5 step:4977 [D loss: 0.694658, acc.: 54.69%] [G loss: 0.723818]\n",
      "epoch:5 step:4978 [D loss: 0.693739, acc.: 50.00%] [G loss: 0.729777]\n",
      "epoch:5 step:4979 [D loss: 0.699254, acc.: 46.88%] [G loss: 0.720491]\n",
      "epoch:5 step:4980 [D loss: 0.700091, acc.: 46.88%] [G loss: 0.743355]\n",
      "epoch:5 step:4981 [D loss: 0.690420, acc.: 55.47%] [G loss: 0.724842]\n",
      "epoch:5 step:4982 [D loss: 0.695668, acc.: 46.88%] [G loss: 0.736650]\n",
      "epoch:5 step:4983 [D loss: 0.698271, acc.: 48.44%] [G loss: 0.732870]\n",
      "epoch:5 step:4984 [D loss: 0.690271, acc.: 51.56%] [G loss: 0.735481]\n",
      "epoch:5 step:4985 [D loss: 0.691728, acc.: 56.25%] [G loss: 0.718326]\n",
      "epoch:5 step:4986 [D loss: 0.701709, acc.: 49.22%] [G loss: 0.729790]\n",
      "epoch:5 step:4987 [D loss: 0.706802, acc.: 49.22%] [G loss: 0.714379]\n",
      "epoch:5 step:4988 [D loss: 0.697685, acc.: 50.00%] [G loss: 0.716314]\n",
      "epoch:5 step:4989 [D loss: 0.693984, acc.: 50.00%] [G loss: 0.723701]\n",
      "epoch:5 step:4990 [D loss: 0.690427, acc.: 57.03%] [G loss: 0.707970]\n",
      "epoch:5 step:4991 [D loss: 0.693203, acc.: 43.75%] [G loss: 0.715863]\n",
      "epoch:5 step:4992 [D loss: 0.696430, acc.: 52.34%] [G loss: 0.694486]\n",
      "epoch:5 step:4993 [D loss: 0.697842, acc.: 46.09%] [G loss: 0.697638]\n",
      "epoch:5 step:4994 [D loss: 0.690375, acc.: 53.12%] [G loss: 0.712861]\n",
      "epoch:5 step:4995 [D loss: 0.678421, acc.: 59.38%] [G loss: 0.708337]\n",
      "epoch:5 step:4996 [D loss: 0.672698, acc.: 59.38%] [G loss: 0.716605]\n",
      "epoch:5 step:4997 [D loss: 0.681439, acc.: 52.34%] [G loss: 0.709540]\n",
      "epoch:5 step:4998 [D loss: 0.678795, acc.: 57.03%] [G loss: 0.724461]\n",
      "epoch:5 step:4999 [D loss: 0.686975, acc.: 57.81%] [G loss: 0.741077]\n",
      "epoch:5 step:5000 [D loss: 0.680317, acc.: 56.25%] [G loss: 0.738219]\n",
      "##############\n",
      "[3.98374791 1.60921082 6.27938758 5.35684914 4.01380595 5.81659004\n",
      " 5.12900697 4.68886285 5.2535066  4.36481178]\n",
      "##########\n",
      "epoch:5 step:5001 [D loss: 0.705973, acc.: 50.00%] [G loss: 0.735763]\n",
      "epoch:5 step:5002 [D loss: 0.699244, acc.: 53.12%] [G loss: 0.730633]\n",
      "epoch:5 step:5003 [D loss: 0.693165, acc.: 48.44%] [G loss: 0.741349]\n",
      "epoch:5 step:5004 [D loss: 0.687824, acc.: 52.34%] [G loss: 0.754992]\n",
      "epoch:5 step:5005 [D loss: 0.703222, acc.: 47.66%] [G loss: 0.706842]\n",
      "epoch:5 step:5006 [D loss: 0.699606, acc.: 42.97%] [G loss: 0.746614]\n",
      "epoch:5 step:5007 [D loss: 0.674998, acc.: 61.72%] [G loss: 0.722340]\n",
      "epoch:5 step:5008 [D loss: 0.701647, acc.: 47.66%] [G loss: 0.729160]\n",
      "epoch:5 step:5009 [D loss: 0.699524, acc.: 45.31%] [G loss: 0.724294]\n",
      "epoch:5 step:5010 [D loss: 0.689978, acc.: 58.59%] [G loss: 0.715735]\n",
      "epoch:5 step:5011 [D loss: 0.677585, acc.: 58.59%] [G loss: 0.723402]\n",
      "epoch:5 step:5012 [D loss: 0.686000, acc.: 53.91%] [G loss: 0.719375]\n",
      "epoch:5 step:5013 [D loss: 0.681078, acc.: 60.16%] [G loss: 0.765931]\n",
      "epoch:5 step:5014 [D loss: 0.692900, acc.: 55.47%] [G loss: 0.725826]\n",
      "epoch:5 step:5015 [D loss: 0.683957, acc.: 53.91%] [G loss: 0.765530]\n",
      "epoch:5 step:5016 [D loss: 0.687215, acc.: 58.59%] [G loss: 0.749297]\n",
      "epoch:5 step:5017 [D loss: 0.691750, acc.: 46.88%] [G loss: 0.718802]\n",
      "epoch:5 step:5018 [D loss: 0.695360, acc.: 52.34%] [G loss: 0.736826]\n",
      "epoch:5 step:5019 [D loss: 0.682186, acc.: 53.91%] [G loss: 0.730112]\n",
      "epoch:5 step:5020 [D loss: 0.692751, acc.: 53.12%] [G loss: 0.733037]\n",
      "epoch:5 step:5021 [D loss: 0.684638, acc.: 54.69%] [G loss: 0.723830]\n",
      "epoch:5 step:5022 [D loss: 0.677391, acc.: 61.72%] [G loss: 0.746661]\n",
      "epoch:5 step:5023 [D loss: 0.695875, acc.: 55.47%] [G loss: 0.728020]\n",
      "epoch:5 step:5024 [D loss: 0.688232, acc.: 51.56%] [G loss: 0.719761]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5025 [D loss: 0.702488, acc.: 47.66%] [G loss: 0.739042]\n",
      "epoch:5 step:5026 [D loss: 0.671137, acc.: 61.72%] [G loss: 0.724088]\n",
      "epoch:5 step:5027 [D loss: 0.683788, acc.: 53.91%] [G loss: 0.715208]\n",
      "epoch:5 step:5028 [D loss: 0.699241, acc.: 50.00%] [G loss: 0.718028]\n",
      "epoch:5 step:5029 [D loss: 0.673012, acc.: 60.94%] [G loss: 0.738326]\n",
      "epoch:5 step:5030 [D loss: 0.733293, acc.: 35.94%] [G loss: 0.720949]\n",
      "epoch:5 step:5031 [D loss: 0.706498, acc.: 44.53%] [G loss: 0.733575]\n",
      "epoch:5 step:5032 [D loss: 0.678215, acc.: 64.84%] [G loss: 0.715870]\n",
      "epoch:5 step:5033 [D loss: 0.700456, acc.: 50.78%] [G loss: 0.805226]\n",
      "epoch:5 step:5034 [D loss: 0.704534, acc.: 40.62%] [G loss: 0.734837]\n",
      "epoch:5 step:5035 [D loss: 0.660660, acc.: 59.38%] [G loss: 0.744004]\n",
      "epoch:5 step:5036 [D loss: 0.702999, acc.: 52.34%] [G loss: 0.740620]\n",
      "epoch:5 step:5037 [D loss: 0.684734, acc.: 50.78%] [G loss: 0.754229]\n",
      "epoch:5 step:5038 [D loss: 0.700870, acc.: 52.34%] [G loss: 0.733971]\n",
      "epoch:5 step:5039 [D loss: 0.681882, acc.: 57.81%] [G loss: 0.744845]\n",
      "epoch:5 step:5040 [D loss: 0.693402, acc.: 53.91%] [G loss: 0.825247]\n",
      "epoch:5 step:5041 [D loss: 0.687187, acc.: 44.53%] [G loss: 0.727258]\n",
      "epoch:5 step:5042 [D loss: 0.709692, acc.: 47.66%] [G loss: 0.732220]\n",
      "epoch:5 step:5043 [D loss: 0.697760, acc.: 50.78%] [G loss: 0.715438]\n",
      "epoch:5 step:5044 [D loss: 0.712342, acc.: 43.75%] [G loss: 0.683031]\n",
      "epoch:5 step:5045 [D loss: 0.680143, acc.: 53.91%] [G loss: 0.749320]\n",
      "epoch:5 step:5046 [D loss: 0.697971, acc.: 53.91%] [G loss: 0.734438]\n",
      "epoch:5 step:5047 [D loss: 0.698218, acc.: 50.00%] [G loss: 0.720675]\n",
      "epoch:5 step:5048 [D loss: 0.713556, acc.: 39.06%] [G loss: 0.719594]\n",
      "epoch:5 step:5049 [D loss: 0.677927, acc.: 57.03%] [G loss: 0.734443]\n",
      "epoch:5 step:5050 [D loss: 0.697611, acc.: 51.56%] [G loss: 0.714123]\n",
      "epoch:5 step:5051 [D loss: 0.686267, acc.: 50.00%] [G loss: 0.725847]\n",
      "epoch:5 step:5052 [D loss: 0.700167, acc.: 49.22%] [G loss: 0.711600]\n",
      "epoch:5 step:5053 [D loss: 0.694589, acc.: 49.22%] [G loss: 0.716615]\n",
      "epoch:5 step:5054 [D loss: 0.714243, acc.: 39.06%] [G loss: 0.721327]\n",
      "epoch:5 step:5055 [D loss: 0.695225, acc.: 53.12%] [G loss: 0.714710]\n",
      "epoch:5 step:5056 [D loss: 0.703531, acc.: 49.22%] [G loss: 0.717681]\n",
      "epoch:5 step:5057 [D loss: 0.695207, acc.: 50.00%] [G loss: 0.720963]\n",
      "epoch:5 step:5058 [D loss: 0.693127, acc.: 51.56%] [G loss: 0.721853]\n",
      "epoch:5 step:5059 [D loss: 0.688907, acc.: 53.12%] [G loss: 0.681314]\n",
      "epoch:5 step:5060 [D loss: 0.686385, acc.: 53.91%] [G loss: 0.707307]\n",
      "epoch:5 step:5061 [D loss: 0.687099, acc.: 57.03%] [G loss: 0.745072]\n",
      "epoch:5 step:5062 [D loss: 0.688878, acc.: 52.34%] [G loss: 0.718113]\n",
      "epoch:5 step:5063 [D loss: 0.689595, acc.: 49.22%] [G loss: 0.720013]\n",
      "epoch:5 step:5064 [D loss: 0.692438, acc.: 53.12%] [G loss: 0.721473]\n",
      "epoch:5 step:5065 [D loss: 0.672095, acc.: 62.50%] [G loss: 0.722606]\n",
      "epoch:5 step:5066 [D loss: 0.686633, acc.: 53.91%] [G loss: 0.705433]\n",
      "epoch:5 step:5067 [D loss: 0.695561, acc.: 50.78%] [G loss: 0.715752]\n",
      "epoch:5 step:5068 [D loss: 0.699069, acc.: 42.97%] [G loss: 0.688926]\n",
      "epoch:5 step:5069 [D loss: 0.698006, acc.: 50.00%] [G loss: 0.714090]\n",
      "epoch:5 step:5070 [D loss: 0.695230, acc.: 50.78%] [G loss: 0.696571]\n",
      "epoch:5 step:5071 [D loss: 0.747572, acc.: 39.84%] [G loss: 0.693734]\n",
      "epoch:5 step:5072 [D loss: 0.694923, acc.: 50.00%] [G loss: 0.721968]\n",
      "epoch:5 step:5073 [D loss: 0.694367, acc.: 49.22%] [G loss: 0.716526]\n",
      "epoch:5 step:5074 [D loss: 0.699246, acc.: 46.88%] [G loss: 0.712183]\n",
      "epoch:5 step:5075 [D loss: 0.696681, acc.: 49.22%] [G loss: 0.713268]\n",
      "epoch:5 step:5076 [D loss: 0.685295, acc.: 55.47%] [G loss: 0.720581]\n",
      "epoch:5 step:5077 [D loss: 0.702008, acc.: 49.22%] [G loss: 0.702923]\n",
      "epoch:5 step:5078 [D loss: 0.691665, acc.: 50.78%] [G loss: 0.722096]\n",
      "epoch:5 step:5079 [D loss: 0.687181, acc.: 52.34%] [G loss: 0.727511]\n",
      "epoch:5 step:5080 [D loss: 0.688788, acc.: 51.56%] [G loss: 0.748148]\n",
      "epoch:5 step:5081 [D loss: 0.693543, acc.: 50.78%] [G loss: 0.738868]\n",
      "epoch:5 step:5082 [D loss: 0.675378, acc.: 63.28%] [G loss: 0.721799]\n",
      "epoch:5 step:5083 [D loss: 0.679479, acc.: 56.25%] [G loss: 0.746287]\n",
      "epoch:5 step:5084 [D loss: 0.665987, acc.: 70.31%] [G loss: 0.783465]\n",
      "epoch:5 step:5085 [D loss: 0.688388, acc.: 53.91%] [G loss: 0.749389]\n",
      "epoch:5 step:5086 [D loss: 0.686023, acc.: 55.47%] [G loss: 0.748438]\n",
      "epoch:5 step:5087 [D loss: 0.675401, acc.: 62.50%] [G loss: 0.765233]\n",
      "epoch:5 step:5088 [D loss: 0.693927, acc.: 50.00%] [G loss: 0.735265]\n",
      "epoch:5 step:5089 [D loss: 0.696328, acc.: 55.47%] [G loss: 0.760442]\n",
      "epoch:5 step:5090 [D loss: 0.700322, acc.: 53.12%] [G loss: 0.721140]\n",
      "epoch:5 step:5091 [D loss: 0.697340, acc.: 51.56%] [G loss: 0.714800]\n",
      "epoch:5 step:5092 [D loss: 0.677475, acc.: 55.47%] [G loss: 0.686403]\n",
      "epoch:5 step:5093 [D loss: 0.676866, acc.: 63.28%] [G loss: 0.747122]\n",
      "epoch:5 step:5094 [D loss: 0.684035, acc.: 56.25%] [G loss: 0.735078]\n",
      "epoch:5 step:5095 [D loss: 0.678615, acc.: 57.81%] [G loss: 0.696320]\n",
      "epoch:5 step:5096 [D loss: 0.729919, acc.: 39.06%] [G loss: 0.747179]\n",
      "epoch:5 step:5097 [D loss: 0.687802, acc.: 51.56%] [G loss: 0.731595]\n",
      "epoch:5 step:5098 [D loss: 0.688831, acc.: 55.47%] [G loss: 0.711605]\n",
      "epoch:5 step:5099 [D loss: 0.676190, acc.: 60.94%] [G loss: 0.726859]\n",
      "epoch:5 step:5100 [D loss: 0.685910, acc.: 54.69%] [G loss: 0.766656]\n",
      "epoch:5 step:5101 [D loss: 0.687195, acc.: 52.34%] [G loss: 0.727470]\n",
      "epoch:5 step:5102 [D loss: 0.674758, acc.: 55.47%] [G loss: 0.745691]\n",
      "epoch:5 step:5103 [D loss: 0.696940, acc.: 53.91%] [G loss: 0.726113]\n",
      "epoch:5 step:5104 [D loss: 0.708155, acc.: 47.66%] [G loss: 0.744736]\n",
      "epoch:5 step:5105 [D loss: 0.696477, acc.: 46.88%] [G loss: 0.744165]\n",
      "epoch:5 step:5106 [D loss: 0.706347, acc.: 44.53%] [G loss: 1.148498]\n",
      "epoch:5 step:5107 [D loss: 0.699042, acc.: 55.47%] [G loss: 0.736791]\n",
      "epoch:5 step:5108 [D loss: 0.677760, acc.: 60.16%] [G loss: 0.894483]\n",
      "epoch:5 step:5109 [D loss: 0.706632, acc.: 42.97%] [G loss: 0.797205]\n",
      "epoch:5 step:5110 [D loss: 0.703635, acc.: 39.06%] [G loss: 0.746736]\n",
      "epoch:5 step:5111 [D loss: 0.671467, acc.: 61.72%] [G loss: 0.746386]\n",
      "epoch:5 step:5112 [D loss: 0.694600, acc.: 53.91%] [G loss: 0.740233]\n",
      "epoch:5 step:5113 [D loss: 0.675846, acc.: 60.16%] [G loss: 0.757683]\n",
      "epoch:5 step:5114 [D loss: 0.681487, acc.: 57.03%] [G loss: 0.768635]\n",
      "epoch:5 step:5115 [D loss: 0.670827, acc.: 60.94%] [G loss: 0.789814]\n",
      "epoch:5 step:5116 [D loss: 0.692588, acc.: 54.69%] [G loss: 0.756043]\n",
      "epoch:5 step:5117 [D loss: 0.692177, acc.: 48.44%] [G loss: 0.741403]\n",
      "epoch:5 step:5118 [D loss: 0.696420, acc.: 53.12%] [G loss: 0.751108]\n",
      "epoch:5 step:5119 [D loss: 0.686269, acc.: 60.94%] [G loss: 0.720616]\n",
      "epoch:5 step:5120 [D loss: 0.682410, acc.: 57.81%] [G loss: 0.722376]\n",
      "epoch:5 step:5121 [D loss: 0.685615, acc.: 57.81%] [G loss: 0.741417]\n",
      "epoch:5 step:5122 [D loss: 0.724026, acc.: 45.31%] [G loss: 0.712731]\n",
      "epoch:5 step:5123 [D loss: 0.711243, acc.: 47.66%] [G loss: 0.698691]\n",
      "epoch:5 step:5124 [D loss: 0.714055, acc.: 41.41%] [G loss: 0.735572]\n",
      "epoch:5 step:5125 [D loss: 0.685490, acc.: 54.69%] [G loss: 0.727788]\n",
      "epoch:5 step:5126 [D loss: 0.694911, acc.: 45.31%] [G loss: 0.729446]\n",
      "epoch:5 step:5127 [D loss: 0.687545, acc.: 50.78%] [G loss: 0.744229]\n",
      "epoch:5 step:5128 [D loss: 0.682441, acc.: 57.81%] [G loss: 0.714789]\n",
      "epoch:5 step:5129 [D loss: 0.687331, acc.: 52.34%] [G loss: 0.765821]\n",
      "epoch:5 step:5130 [D loss: 0.685570, acc.: 53.91%] [G loss: 0.750199]\n",
      "epoch:5 step:5131 [D loss: 0.681317, acc.: 57.03%] [G loss: 0.744059]\n",
      "epoch:5 step:5132 [D loss: 0.682100, acc.: 55.47%] [G loss: 0.770239]\n",
      "epoch:5 step:5133 [D loss: 0.685639, acc.: 55.47%] [G loss: 0.794176]\n",
      "epoch:5 step:5134 [D loss: 0.686650, acc.: 48.44%] [G loss: 0.773270]\n",
      "epoch:5 step:5135 [D loss: 0.654266, acc.: 66.41%] [G loss: 0.766317]\n",
      "epoch:5 step:5136 [D loss: 0.646385, acc.: 64.06%] [G loss: 0.798396]\n",
      "epoch:5 step:5137 [D loss: 0.634915, acc.: 69.53%] [G loss: 0.730585]\n",
      "epoch:5 step:5138 [D loss: 0.662580, acc.: 58.59%] [G loss: 0.710527]\n",
      "epoch:5 step:5139 [D loss: 0.761098, acc.: 46.09%] [G loss: 0.771507]\n",
      "epoch:5 step:5140 [D loss: 0.674357, acc.: 55.47%] [G loss: 0.772572]\n",
      "epoch:5 step:5141 [D loss: 0.579007, acc.: 67.19%] [G loss: 0.767849]\n",
      "epoch:5 step:5142 [D loss: 0.671083, acc.: 60.16%] [G loss: 0.755928]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5143 [D loss: 0.748578, acc.: 33.59%] [G loss: 0.780253]\n",
      "epoch:5 step:5144 [D loss: 0.667595, acc.: 60.16%] [G loss: 0.764615]\n",
      "epoch:5 step:5145 [D loss: 0.682455, acc.: 53.91%] [G loss: 0.747307]\n",
      "epoch:5 step:5146 [D loss: 0.711379, acc.: 41.41%] [G loss: 0.768856]\n",
      "epoch:5 step:5147 [D loss: 0.711105, acc.: 42.97%] [G loss: 0.788522]\n",
      "epoch:5 step:5148 [D loss: 0.665082, acc.: 65.62%] [G loss: 0.812583]\n",
      "epoch:5 step:5149 [D loss: 0.683179, acc.: 50.78%] [G loss: 0.785060]\n",
      "epoch:5 step:5150 [D loss: 0.702773, acc.: 55.47%] [G loss: 0.822653]\n",
      "epoch:5 step:5151 [D loss: 0.692188, acc.: 52.34%] [G loss: 0.819152]\n",
      "epoch:5 step:5152 [D loss: 0.656072, acc.: 58.59%] [G loss: 0.813688]\n",
      "epoch:5 step:5153 [D loss: 0.706297, acc.: 54.69%] [G loss: 0.745226]\n",
      "epoch:5 step:5154 [D loss: 0.690593, acc.: 53.12%] [G loss: 0.694694]\n",
      "epoch:5 step:5155 [D loss: 0.684012, acc.: 54.69%] [G loss: 0.706070]\n",
      "epoch:5 step:5156 [D loss: 0.701662, acc.: 47.66%] [G loss: 0.757195]\n",
      "epoch:5 step:5157 [D loss: 0.706795, acc.: 48.44%] [G loss: 0.727174]\n",
      "epoch:5 step:5158 [D loss: 0.695927, acc.: 48.44%] [G loss: 0.688708]\n",
      "epoch:5 step:5159 [D loss: 0.692319, acc.: 55.47%] [G loss: 0.691671]\n",
      "epoch:5 step:5160 [D loss: 0.705582, acc.: 50.00%] [G loss: 0.757882]\n",
      "epoch:5 step:5161 [D loss: 0.708680, acc.: 41.41%] [G loss: 0.836735]\n",
      "epoch:5 step:5162 [D loss: 0.697600, acc.: 53.12%] [G loss: 0.853349]\n",
      "epoch:5 step:5163 [D loss: 0.665576, acc.: 60.16%] [G loss: 0.871219]\n",
      "epoch:5 step:5164 [D loss: 0.688232, acc.: 48.44%] [G loss: 0.856559]\n",
      "epoch:5 step:5165 [D loss: 0.738186, acc.: 39.84%] [G loss: 0.761770]\n",
      "epoch:5 step:5166 [D loss: 0.682822, acc.: 56.25%] [G loss: 0.759609]\n",
      "epoch:5 step:5167 [D loss: 0.687071, acc.: 57.03%] [G loss: 0.731927]\n",
      "epoch:5 step:5168 [D loss: 0.706520, acc.: 49.22%] [G loss: 0.707173]\n",
      "epoch:5 step:5169 [D loss: 0.676066, acc.: 56.25%] [G loss: 0.729943]\n",
      "epoch:5 step:5170 [D loss: 0.682212, acc.: 54.69%] [G loss: 0.764006]\n",
      "epoch:5 step:5171 [D loss: 0.697084, acc.: 50.78%] [G loss: 0.750047]\n",
      "epoch:5 step:5172 [D loss: 0.704738, acc.: 48.44%] [G loss: 0.731412]\n",
      "epoch:5 step:5173 [D loss: 0.689127, acc.: 54.69%] [G loss: 0.721369]\n",
      "epoch:5 step:5174 [D loss: 0.706987, acc.: 46.09%] [G loss: 0.733981]\n",
      "epoch:5 step:5175 [D loss: 0.705909, acc.: 46.88%] [G loss: 0.716706]\n",
      "epoch:5 step:5176 [D loss: 0.708850, acc.: 44.53%] [G loss: 0.716768]\n",
      "epoch:5 step:5177 [D loss: 0.705689, acc.: 43.75%] [G loss: 0.715576]\n",
      "epoch:5 step:5178 [D loss: 0.697874, acc.: 39.84%] [G loss: 0.710236]\n",
      "epoch:5 step:5179 [D loss: 0.692099, acc.: 49.22%] [G loss: 0.725696]\n",
      "epoch:5 step:5180 [D loss: 0.679110, acc.: 60.16%] [G loss: 0.731412]\n",
      "epoch:5 step:5181 [D loss: 0.689652, acc.: 51.56%] [G loss: 0.739279]\n",
      "epoch:5 step:5182 [D loss: 0.679844, acc.: 61.72%] [G loss: 0.746943]\n",
      "epoch:5 step:5183 [D loss: 0.687003, acc.: 57.03%] [G loss: 0.732901]\n",
      "epoch:5 step:5184 [D loss: 0.678234, acc.: 52.34%] [G loss: 0.720383]\n",
      "epoch:5 step:5185 [D loss: 0.715249, acc.: 44.53%] [G loss: 0.725401]\n",
      "epoch:5 step:5186 [D loss: 0.736284, acc.: 35.94%] [G loss: 0.709279]\n",
      "epoch:5 step:5187 [D loss: 0.708492, acc.: 39.06%] [G loss: 0.727960]\n",
      "epoch:5 step:5188 [D loss: 0.714341, acc.: 42.19%] [G loss: 0.721639]\n",
      "epoch:5 step:5189 [D loss: 0.683720, acc.: 54.69%] [G loss: 0.729208]\n",
      "epoch:5 step:5190 [D loss: 0.676640, acc.: 58.59%] [G loss: 0.729501]\n",
      "epoch:5 step:5191 [D loss: 0.707552, acc.: 50.78%] [G loss: 0.724045]\n",
      "epoch:5 step:5192 [D loss: 0.669072, acc.: 62.50%] [G loss: 0.741039]\n",
      "epoch:5 step:5193 [D loss: 0.664225, acc.: 67.97%] [G loss: 0.738733]\n",
      "epoch:5 step:5194 [D loss: 0.699137, acc.: 55.47%] [G loss: 0.729153]\n",
      "epoch:5 step:5195 [D loss: 0.706406, acc.: 42.19%] [G loss: 0.726432]\n",
      "epoch:5 step:5196 [D loss: 0.705933, acc.: 42.97%] [G loss: 0.727353]\n",
      "epoch:5 step:5197 [D loss: 0.701890, acc.: 46.09%] [G loss: 0.739158]\n",
      "epoch:5 step:5198 [D loss: 0.697734, acc.: 46.88%] [G loss: 0.742808]\n",
      "epoch:5 step:5199 [D loss: 0.700251, acc.: 47.66%] [G loss: 0.728121]\n",
      "epoch:5 step:5200 [D loss: 0.689262, acc.: 51.56%] [G loss: 0.721563]\n",
      "##############\n",
      "[3.60650112 1.87614639 6.133901   5.1107804  4.2316149  5.95337121\n",
      " 4.72249102 5.30249513 5.20929475 4.88759609]\n",
      "##########\n",
      "epoch:5 step:5201 [D loss: 0.683075, acc.: 53.12%] [G loss: 0.726701]\n",
      "epoch:5 step:5202 [D loss: 0.688534, acc.: 50.78%] [G loss: 0.715244]\n",
      "epoch:5 step:5203 [D loss: 0.684408, acc.: 57.81%] [G loss: 0.688061]\n",
      "epoch:5 step:5204 [D loss: 0.680301, acc.: 56.25%] [G loss: 0.725611]\n",
      "epoch:5 step:5205 [D loss: 0.685215, acc.: 58.59%] [G loss: 0.734403]\n",
      "epoch:5 step:5206 [D loss: 0.676711, acc.: 59.38%] [G loss: 0.734581]\n",
      "epoch:5 step:5207 [D loss: 0.669746, acc.: 64.84%] [G loss: 0.727831]\n",
      "epoch:5 step:5208 [D loss: 0.669088, acc.: 60.94%] [G loss: 0.748639]\n",
      "epoch:5 step:5209 [D loss: 0.713469, acc.: 43.75%] [G loss: 0.722380]\n",
      "epoch:5 step:5210 [D loss: 0.706227, acc.: 45.31%] [G loss: 0.715978]\n",
      "epoch:5 step:5211 [D loss: 0.700357, acc.: 40.62%] [G loss: 0.721893]\n",
      "epoch:5 step:5212 [D loss: 0.700888, acc.: 45.31%] [G loss: 0.698749]\n",
      "epoch:5 step:5213 [D loss: 0.705229, acc.: 49.22%] [G loss: 0.728248]\n",
      "epoch:5 step:5214 [D loss: 0.709850, acc.: 53.91%] [G loss: 0.735558]\n",
      "epoch:5 step:5215 [D loss: 0.688756, acc.: 50.00%] [G loss: 0.702024]\n",
      "epoch:5 step:5216 [D loss: 0.683768, acc.: 53.12%] [G loss: 0.716729]\n",
      "epoch:5 step:5217 [D loss: 0.702435, acc.: 52.34%] [G loss: 0.772564]\n",
      "epoch:5 step:5218 [D loss: 0.698362, acc.: 55.47%] [G loss: 0.710601]\n",
      "epoch:5 step:5219 [D loss: 0.695653, acc.: 51.56%] [G loss: 0.768527]\n",
      "epoch:5 step:5220 [D loss: 0.704156, acc.: 48.44%] [G loss: 0.708822]\n",
      "epoch:5 step:5221 [D loss: 0.689596, acc.: 54.69%] [G loss: 0.744065]\n",
      "epoch:5 step:5222 [D loss: 0.681246, acc.: 60.94%] [G loss: 0.732862]\n",
      "epoch:5 step:5223 [D loss: 0.697413, acc.: 53.12%] [G loss: 0.710904]\n",
      "epoch:5 step:5224 [D loss: 0.687411, acc.: 56.25%] [G loss: 0.734257]\n",
      "epoch:5 step:5225 [D loss: 0.684936, acc.: 56.25%] [G loss: 0.746152]\n",
      "epoch:5 step:5226 [D loss: 0.677582, acc.: 64.06%] [G loss: 0.729500]\n",
      "epoch:5 step:5227 [D loss: 0.717552, acc.: 42.19%] [G loss: 0.708350]\n",
      "epoch:5 step:5228 [D loss: 0.718294, acc.: 46.88%] [G loss: 0.721895]\n",
      "epoch:5 step:5229 [D loss: 0.695113, acc.: 53.91%] [G loss: 0.726244]\n",
      "epoch:5 step:5230 [D loss: 0.685340, acc.: 57.03%] [G loss: 0.671203]\n",
      "epoch:5 step:5231 [D loss: 0.685410, acc.: 59.38%] [G loss: 0.708642]\n",
      "epoch:5 step:5232 [D loss: 0.717116, acc.: 45.31%] [G loss: 0.704846]\n",
      "epoch:5 step:5233 [D loss: 0.676861, acc.: 60.16%] [G loss: 0.722743]\n",
      "epoch:5 step:5234 [D loss: 0.680696, acc.: 56.25%] [G loss: 0.718647]\n",
      "epoch:5 step:5235 [D loss: 0.620269, acc.: 65.62%] [G loss: 0.690258]\n",
      "epoch:5 step:5236 [D loss: 0.687575, acc.: 53.12%] [G loss: 0.651196]\n",
      "epoch:5 step:5237 [D loss: 0.706314, acc.: 46.88%] [G loss: 0.713274]\n",
      "epoch:5 step:5238 [D loss: 0.703745, acc.: 47.66%] [G loss: 0.691412]\n",
      "epoch:5 step:5239 [D loss: 0.665215, acc.: 59.38%] [G loss: 0.656102]\n",
      "epoch:5 step:5240 [D loss: 0.699340, acc.: 50.78%] [G loss: 0.707778]\n",
      "epoch:5 step:5241 [D loss: 0.675273, acc.: 52.34%] [G loss: 0.764637]\n",
      "epoch:5 step:5242 [D loss: 0.717873, acc.: 52.34%] [G loss: 0.716423]\n",
      "epoch:5 step:5243 [D loss: 0.657949, acc.: 64.06%] [G loss: 0.744068]\n",
      "epoch:5 step:5244 [D loss: 0.725280, acc.: 36.72%] [G loss: 0.703690]\n",
      "epoch:5 step:5245 [D loss: 0.744462, acc.: 33.59%] [G loss: 0.730222]\n",
      "epoch:5 step:5246 [D loss: 0.703835, acc.: 43.75%] [G loss: 0.751815]\n",
      "epoch:5 step:5247 [D loss: 0.699172, acc.: 50.78%] [G loss: 0.745309]\n",
      "epoch:5 step:5248 [D loss: 0.683882, acc.: 57.03%] [G loss: 0.783866]\n",
      "epoch:5 step:5249 [D loss: 0.685983, acc.: 55.47%] [G loss: 0.758972]\n",
      "epoch:5 step:5250 [D loss: 0.684740, acc.: 51.56%] [G loss: 0.761047]\n",
      "epoch:5 step:5251 [D loss: 0.696553, acc.: 46.88%] [G loss: 0.763201]\n",
      "epoch:5 step:5252 [D loss: 0.686473, acc.: 57.03%] [G loss: 0.785849]\n",
      "epoch:5 step:5253 [D loss: 0.661278, acc.: 57.03%] [G loss: 0.838578]\n",
      "epoch:5 step:5254 [D loss: 0.703601, acc.: 48.44%] [G loss: 0.871799]\n",
      "epoch:5 step:5255 [D loss: 0.688448, acc.: 53.12%] [G loss: 0.751132]\n",
      "epoch:5 step:5256 [D loss: 0.707417, acc.: 46.88%] [G loss: 0.780535]\n",
      "epoch:5 step:5257 [D loss: 0.729536, acc.: 39.84%] [G loss: 0.709111]\n",
      "epoch:5 step:5258 [D loss: 0.691735, acc.: 53.91%] [G loss: 0.701787]\n",
      "epoch:5 step:5259 [D loss: 0.684867, acc.: 53.91%] [G loss: 0.685755]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5260 [D loss: 0.700541, acc.: 49.22%] [G loss: 0.691125]\n",
      "epoch:5 step:5261 [D loss: 0.709535, acc.: 37.50%] [G loss: 0.684428]\n",
      "epoch:5 step:5262 [D loss: 0.707698, acc.: 45.31%] [G loss: 0.683324]\n",
      "epoch:5 step:5263 [D loss: 0.687217, acc.: 57.81%] [G loss: 0.720952]\n",
      "epoch:5 step:5264 [D loss: 0.685614, acc.: 59.38%] [G loss: 0.691428]\n",
      "epoch:5 step:5265 [D loss: 0.705199, acc.: 52.34%] [G loss: 0.723773]\n",
      "epoch:5 step:5266 [D loss: 0.702422, acc.: 46.88%] [G loss: 0.686153]\n",
      "epoch:5 step:5267 [D loss: 0.700824, acc.: 50.78%] [G loss: 0.717970]\n",
      "epoch:5 step:5268 [D loss: 0.695522, acc.: 50.00%] [G loss: 0.717797]\n",
      "epoch:5 step:5269 [D loss: 0.704412, acc.: 50.00%] [G loss: 0.748988]\n",
      "epoch:5 step:5270 [D loss: 0.684890, acc.: 57.81%] [G loss: 0.766394]\n",
      "epoch:5 step:5271 [D loss: 0.670938, acc.: 64.84%] [G loss: 0.777844]\n",
      "epoch:5 step:5272 [D loss: 0.675555, acc.: 65.62%] [G loss: 0.770065]\n",
      "epoch:5 step:5273 [D loss: 0.656226, acc.: 59.38%] [G loss: 0.774060]\n",
      "epoch:5 step:5274 [D loss: 0.678626, acc.: 56.25%] [G loss: 0.781805]\n",
      "epoch:5 step:5275 [D loss: 0.718086, acc.: 46.09%] [G loss: 0.749996]\n",
      "epoch:5 step:5276 [D loss: 0.713915, acc.: 46.09%] [G loss: 0.724709]\n",
      "epoch:5 step:5277 [D loss: 0.691127, acc.: 48.44%] [G loss: 0.720734]\n",
      "epoch:5 step:5278 [D loss: 0.707182, acc.: 44.53%] [G loss: 0.695937]\n",
      "epoch:5 step:5279 [D loss: 0.701352, acc.: 46.09%] [G loss: 0.725941]\n",
      "epoch:5 step:5280 [D loss: 0.703324, acc.: 51.56%] [G loss: 0.701297]\n",
      "epoch:5 step:5281 [D loss: 0.703168, acc.: 53.12%] [G loss: 0.697110]\n",
      "epoch:5 step:5282 [D loss: 0.695294, acc.: 53.12%] [G loss: 0.706363]\n",
      "epoch:5 step:5283 [D loss: 0.684710, acc.: 62.50%] [G loss: 0.648412]\n",
      "epoch:5 step:5284 [D loss: 0.692978, acc.: 47.66%] [G loss: 0.720058]\n",
      "epoch:5 step:5285 [D loss: 0.694896, acc.: 46.88%] [G loss: 0.697601]\n",
      "epoch:5 step:5286 [D loss: 0.692981, acc.: 51.56%] [G loss: 0.722754]\n",
      "epoch:5 step:5287 [D loss: 0.685322, acc.: 60.16%] [G loss: 0.765314]\n",
      "epoch:5 step:5288 [D loss: 0.692170, acc.: 52.34%] [G loss: 0.729594]\n",
      "epoch:5 step:5289 [D loss: 0.680197, acc.: 51.56%] [G loss: 0.757879]\n",
      "epoch:5 step:5290 [D loss: 0.683044, acc.: 64.84%] [G loss: 0.732229]\n",
      "epoch:5 step:5291 [D loss: 0.692880, acc.: 55.47%] [G loss: 0.712307]\n",
      "epoch:5 step:5292 [D loss: 0.686393, acc.: 57.03%] [G loss: 0.715963]\n",
      "epoch:5 step:5293 [D loss: 0.689180, acc.: 55.47%] [G loss: 0.732730]\n",
      "epoch:5 step:5294 [D loss: 0.707083, acc.: 44.53%] [G loss: 0.726431]\n",
      "epoch:5 step:5295 [D loss: 0.701595, acc.: 50.00%] [G loss: 0.719209]\n",
      "epoch:5 step:5296 [D loss: 0.686125, acc.: 50.00%] [G loss: 0.714440]\n",
      "epoch:5 step:5297 [D loss: 0.684691, acc.: 53.12%] [G loss: 0.706682]\n",
      "epoch:5 step:5298 [D loss: 0.710736, acc.: 45.31%] [G loss: 0.684308]\n",
      "epoch:5 step:5299 [D loss: 0.717688, acc.: 39.84%] [G loss: 0.717223]\n",
      "epoch:5 step:5300 [D loss: 0.703740, acc.: 48.44%] [G loss: 0.730240]\n",
      "epoch:5 step:5301 [D loss: 0.707259, acc.: 47.66%] [G loss: 0.722865]\n",
      "epoch:5 step:5302 [D loss: 0.697230, acc.: 51.56%] [G loss: 0.732484]\n",
      "epoch:5 step:5303 [D loss: 0.690955, acc.: 55.47%] [G loss: 0.732981]\n",
      "epoch:5 step:5304 [D loss: 0.689084, acc.: 48.44%] [G loss: 0.736846]\n",
      "epoch:5 step:5305 [D loss: 0.659408, acc.: 62.50%] [G loss: 0.731469]\n",
      "epoch:5 step:5306 [D loss: 0.673755, acc.: 62.50%] [G loss: 0.845786]\n",
      "epoch:5 step:5307 [D loss: 0.660039, acc.: 54.69%] [G loss: 0.852524]\n",
      "epoch:5 step:5308 [D loss: 0.674824, acc.: 57.81%] [G loss: 0.803341]\n",
      "epoch:5 step:5309 [D loss: 0.686349, acc.: 57.81%] [G loss: 0.773179]\n",
      "epoch:5 step:5310 [D loss: 0.739762, acc.: 34.38%] [G loss: 0.722124]\n",
      "epoch:5 step:5311 [D loss: 0.713478, acc.: 45.31%] [G loss: 0.691010]\n",
      "epoch:5 step:5312 [D loss: 0.714112, acc.: 43.75%] [G loss: 0.706964]\n",
      "epoch:5 step:5313 [D loss: 0.720307, acc.: 34.38%] [G loss: 0.688156]\n",
      "epoch:5 step:5314 [D loss: 0.687120, acc.: 53.91%] [G loss: 0.704652]\n",
      "epoch:5 step:5315 [D loss: 0.683676, acc.: 51.56%] [G loss: 0.720518]\n",
      "epoch:5 step:5316 [D loss: 0.685736, acc.: 59.38%] [G loss: 0.725937]\n",
      "epoch:5 step:5317 [D loss: 0.686917, acc.: 50.78%] [G loss: 0.694239]\n",
      "epoch:5 step:5318 [D loss: 0.688444, acc.: 53.12%] [G loss: 0.749505]\n",
      "epoch:5 step:5319 [D loss: 0.668157, acc.: 60.16%] [G loss: 0.804400]\n",
      "epoch:5 step:5320 [D loss: 0.697117, acc.: 47.66%] [G loss: 0.753760]\n",
      "epoch:5 step:5321 [D loss: 0.699744, acc.: 43.75%] [G loss: 0.741030]\n",
      "epoch:5 step:5322 [D loss: 0.703194, acc.: 46.88%] [G loss: 0.736674]\n",
      "epoch:5 step:5323 [D loss: 0.695160, acc.: 52.34%] [G loss: 0.753789]\n",
      "epoch:5 step:5324 [D loss: 0.709566, acc.: 45.31%] [G loss: 0.738463]\n",
      "epoch:5 step:5325 [D loss: 0.692612, acc.: 53.12%] [G loss: 0.737368]\n",
      "epoch:5 step:5326 [D loss: 0.688643, acc.: 55.47%] [G loss: 0.743573]\n",
      "epoch:5 step:5327 [D loss: 0.669410, acc.: 65.62%] [G loss: 0.772815]\n",
      "epoch:5 step:5328 [D loss: 0.688036, acc.: 52.34%] [G loss: 0.777103]\n",
      "epoch:5 step:5329 [D loss: 0.705099, acc.: 45.31%] [G loss: 0.765873]\n",
      "epoch:5 step:5330 [D loss: 0.693521, acc.: 51.56%] [G loss: 0.751333]\n",
      "epoch:5 step:5331 [D loss: 0.687309, acc.: 50.78%] [G loss: 0.753380]\n",
      "epoch:5 step:5332 [D loss: 0.683015, acc.: 53.91%] [G loss: 0.739791]\n",
      "epoch:5 step:5333 [D loss: 0.673745, acc.: 62.50%] [G loss: 0.768187]\n",
      "epoch:5 step:5334 [D loss: 0.681257, acc.: 55.47%] [G loss: 0.756942]\n",
      "epoch:5 step:5335 [D loss: 0.668437, acc.: 64.84%] [G loss: 0.754929]\n",
      "epoch:5 step:5336 [D loss: 0.678545, acc.: 56.25%] [G loss: 0.767673]\n",
      "epoch:5 step:5337 [D loss: 0.677015, acc.: 63.28%] [G loss: 0.762052]\n",
      "epoch:5 step:5338 [D loss: 0.700602, acc.: 53.91%] [G loss: 0.722165]\n",
      "epoch:5 step:5339 [D loss: 0.681503, acc.: 61.72%] [G loss: 0.727476]\n",
      "epoch:5 step:5340 [D loss: 0.736870, acc.: 39.06%] [G loss: 0.682458]\n",
      "epoch:5 step:5341 [D loss: 0.701713, acc.: 47.66%] [G loss: 0.715261]\n",
      "epoch:5 step:5342 [D loss: 0.728544, acc.: 42.19%] [G loss: 0.709010]\n",
      "epoch:5 step:5343 [D loss: 0.730017, acc.: 41.41%] [G loss: 0.750267]\n",
      "epoch:5 step:5344 [D loss: 0.674301, acc.: 57.03%] [G loss: 0.768575]\n",
      "epoch:5 step:5345 [D loss: 0.672639, acc.: 58.59%] [G loss: 0.753470]\n",
      "epoch:5 step:5346 [D loss: 0.644486, acc.: 68.75%] [G loss: 0.789223]\n",
      "epoch:5 step:5347 [D loss: 0.683575, acc.: 50.78%] [G loss: 0.788781]\n",
      "epoch:5 step:5348 [D loss: 0.687491, acc.: 50.00%] [G loss: 0.798569]\n",
      "epoch:5 step:5349 [D loss: 0.709012, acc.: 52.34%] [G loss: 0.796185]\n",
      "epoch:5 step:5350 [D loss: 0.728546, acc.: 42.19%] [G loss: 0.750765]\n",
      "epoch:5 step:5351 [D loss: 0.674947, acc.: 59.38%] [G loss: 0.744787]\n",
      "epoch:5 step:5352 [D loss: 0.693446, acc.: 56.25%] [G loss: 0.707523]\n",
      "epoch:5 step:5353 [D loss: 0.711718, acc.: 45.31%] [G loss: 0.740590]\n",
      "epoch:5 step:5354 [D loss: 0.703607, acc.: 51.56%] [G loss: 0.694671]\n",
      "epoch:5 step:5355 [D loss: 0.724959, acc.: 34.38%] [G loss: 0.691484]\n",
      "epoch:5 step:5356 [D loss: 0.723890, acc.: 42.19%] [G loss: 0.675456]\n",
      "epoch:5 step:5357 [D loss: 0.724202, acc.: 32.81%] [G loss: 0.710837]\n",
      "epoch:5 step:5358 [D loss: 0.711318, acc.: 40.62%] [G loss: 0.709044]\n",
      "epoch:5 step:5359 [D loss: 0.702070, acc.: 43.75%] [G loss: 0.705352]\n",
      "epoch:5 step:5360 [D loss: 0.681291, acc.: 64.84%] [G loss: 0.707190]\n",
      "epoch:5 step:5361 [D loss: 0.683852, acc.: 54.69%] [G loss: 0.737061]\n",
      "epoch:5 step:5362 [D loss: 0.669058, acc.: 65.62%] [G loss: 0.726311]\n",
      "epoch:5 step:5363 [D loss: 0.678596, acc.: 60.94%] [G loss: 0.746377]\n",
      "epoch:5 step:5364 [D loss: 0.693621, acc.: 49.22%] [G loss: 0.738354]\n",
      "epoch:5 step:5365 [D loss: 0.682856, acc.: 53.91%] [G loss: 0.731766]\n",
      "epoch:5 step:5366 [D loss: 0.670244, acc.: 61.72%] [G loss: 0.761696]\n",
      "epoch:5 step:5367 [D loss: 0.700665, acc.: 50.78%] [G loss: 0.765925]\n",
      "epoch:5 step:5368 [D loss: 0.664835, acc.: 58.59%] [G loss: 0.735547]\n",
      "epoch:5 step:5369 [D loss: 0.719490, acc.: 46.09%] [G loss: 0.720365]\n",
      "epoch:5 step:5370 [D loss: 0.705707, acc.: 51.56%] [G loss: 0.698541]\n",
      "epoch:5 step:5371 [D loss: 0.714778, acc.: 45.31%] [G loss: 0.689562]\n",
      "epoch:5 step:5372 [D loss: 0.717312, acc.: 42.19%] [G loss: 0.681387]\n",
      "epoch:5 step:5373 [D loss: 0.692025, acc.: 46.09%] [G loss: 0.694249]\n",
      "epoch:5 step:5374 [D loss: 0.695792, acc.: 53.12%] [G loss: 0.695452]\n",
      "epoch:5 step:5375 [D loss: 0.699085, acc.: 49.22%] [G loss: 0.695710]\n",
      "epoch:5 step:5376 [D loss: 0.713805, acc.: 37.50%] [G loss: 0.701479]\n",
      "epoch:5 step:5377 [D loss: 0.694316, acc.: 50.78%] [G loss: 0.719220]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5378 [D loss: 0.681994, acc.: 58.59%] [G loss: 0.749345]\n",
      "epoch:5 step:5379 [D loss: 0.678850, acc.: 57.03%] [G loss: 0.745879]\n",
      "epoch:5 step:5380 [D loss: 0.682336, acc.: 57.81%] [G loss: 0.745407]\n",
      "epoch:5 step:5381 [D loss: 0.675347, acc.: 59.38%] [G loss: 0.772743]\n",
      "epoch:5 step:5382 [D loss: 0.669866, acc.: 64.06%] [G loss: 1.018738]\n",
      "epoch:5 step:5383 [D loss: 0.672344, acc.: 61.72%] [G loss: 0.811813]\n",
      "epoch:5 step:5384 [D loss: 0.690303, acc.: 53.12%] [G loss: 0.753572]\n",
      "epoch:5 step:5385 [D loss: 0.684061, acc.: 56.25%] [G loss: 0.783804]\n",
      "epoch:5 step:5386 [D loss: 0.694375, acc.: 52.34%] [G loss: 0.739995]\n",
      "epoch:5 step:5387 [D loss: 0.691111, acc.: 54.69%] [G loss: 0.770113]\n",
      "epoch:5 step:5388 [D loss: 0.687788, acc.: 60.16%] [G loss: 0.764068]\n",
      "epoch:5 step:5389 [D loss: 0.706137, acc.: 50.00%] [G loss: 0.711949]\n",
      "epoch:5 step:5390 [D loss: 0.700945, acc.: 46.88%] [G loss: 0.742317]\n",
      "epoch:5 step:5391 [D loss: 0.696602, acc.: 46.88%] [G loss: 0.746968]\n",
      "epoch:5 step:5392 [D loss: 0.679662, acc.: 59.38%] [G loss: 0.708441]\n",
      "epoch:5 step:5393 [D loss: 0.687372, acc.: 50.00%] [G loss: 0.730664]\n",
      "epoch:5 step:5394 [D loss: 0.679220, acc.: 57.81%] [G loss: 0.706362]\n",
      "epoch:5 step:5395 [D loss: 0.745211, acc.: 31.25%] [G loss: 0.697376]\n",
      "epoch:5 step:5396 [D loss: 0.706468, acc.: 45.31%] [G loss: 0.711729]\n",
      "epoch:5 step:5397 [D loss: 0.687109, acc.: 56.25%] [G loss: 0.726735]\n",
      "epoch:5 step:5398 [D loss: 0.681068, acc.: 63.28%] [G loss: 0.733111]\n",
      "epoch:5 step:5399 [D loss: 0.687558, acc.: 58.59%] [G loss: 0.696601]\n",
      "epoch:5 step:5400 [D loss: 0.715884, acc.: 42.97%] [G loss: 0.705829]\n",
      "##############\n",
      "[4.13935121 1.93612226 6.58717089 5.68212658 4.16576088 6.07593468\n",
      " 5.57216194 4.92205273 5.54919555 4.68808161]\n",
      "##########\n",
      "epoch:5 step:5401 [D loss: 0.697241, acc.: 50.78%] [G loss: 0.703149]\n",
      "epoch:5 step:5402 [D loss: 0.672359, acc.: 57.81%] [G loss: 0.716727]\n",
      "epoch:5 step:5403 [D loss: 0.689768, acc.: 50.78%] [G loss: 0.717931]\n",
      "epoch:5 step:5404 [D loss: 0.673756, acc.: 57.81%] [G loss: 0.720584]\n",
      "epoch:5 step:5405 [D loss: 0.694308, acc.: 48.44%] [G loss: 0.717704]\n",
      "epoch:5 step:5406 [D loss: 0.675916, acc.: 58.59%] [G loss: 0.712999]\n",
      "epoch:5 step:5407 [D loss: 0.703831, acc.: 45.31%] [G loss: 0.708023]\n",
      "epoch:5 step:5408 [D loss: 0.698449, acc.: 48.44%] [G loss: 0.712726]\n",
      "epoch:5 step:5409 [D loss: 0.685840, acc.: 52.34%] [G loss: 0.736019]\n",
      "epoch:5 step:5410 [D loss: 0.692015, acc.: 52.34%] [G loss: 0.729853]\n",
      "epoch:5 step:5411 [D loss: 0.687411, acc.: 55.47%] [G loss: 0.718915]\n",
      "epoch:5 step:5412 [D loss: 0.707968, acc.: 39.84%] [G loss: 0.734076]\n",
      "epoch:5 step:5413 [D loss: 0.711477, acc.: 46.09%] [G loss: 0.738179]\n",
      "epoch:5 step:5414 [D loss: 0.699226, acc.: 49.22%] [G loss: 0.743693]\n",
      "epoch:5 step:5415 [D loss: 0.683663, acc.: 52.34%] [G loss: 0.739553]\n",
      "epoch:5 step:5416 [D loss: 0.677864, acc.: 62.50%] [G loss: 0.757386]\n",
      "epoch:5 step:5417 [D loss: 0.671194, acc.: 61.72%] [G loss: 0.768219]\n",
      "epoch:5 step:5418 [D loss: 0.675288, acc.: 59.38%] [G loss: 0.775814]\n",
      "epoch:5 step:5419 [D loss: 0.690794, acc.: 53.12%] [G loss: 0.727564]\n",
      "epoch:5 step:5420 [D loss: 0.705224, acc.: 54.69%] [G loss: 0.737196]\n",
      "epoch:5 step:5421 [D loss: 0.688978, acc.: 53.12%] [G loss: 0.741681]\n",
      "epoch:5 step:5422 [D loss: 0.668209, acc.: 59.38%] [G loss: 0.744563]\n",
      "epoch:5 step:5423 [D loss: 0.712940, acc.: 41.41%] [G loss: 0.719229]\n",
      "epoch:5 step:5424 [D loss: 0.719358, acc.: 46.09%] [G loss: 0.710522]\n",
      "epoch:5 step:5425 [D loss: 0.714509, acc.: 40.62%] [G loss: 0.702182]\n",
      "epoch:5 step:5426 [D loss: 0.703240, acc.: 46.88%] [G loss: 0.713155]\n",
      "epoch:5 step:5427 [D loss: 0.691434, acc.: 47.66%] [G loss: 0.701135]\n",
      "epoch:5 step:5428 [D loss: 0.699720, acc.: 43.75%] [G loss: 0.692357]\n",
      "epoch:5 step:5429 [D loss: 0.702749, acc.: 50.00%] [G loss: 0.706591]\n",
      "epoch:5 step:5430 [D loss: 0.693030, acc.: 53.91%] [G loss: 0.715752]\n",
      "epoch:5 step:5431 [D loss: 0.690775, acc.: 50.78%] [G loss: 0.730292]\n",
      "epoch:5 step:5432 [D loss: 0.693464, acc.: 54.69%] [G loss: 0.706174]\n",
      "epoch:5 step:5433 [D loss: 0.698249, acc.: 53.12%] [G loss: 0.710199]\n",
      "epoch:5 step:5434 [D loss: 0.701998, acc.: 50.00%] [G loss: 0.712424]\n",
      "epoch:5 step:5435 [D loss: 0.687449, acc.: 49.22%] [G loss: 0.712358]\n",
      "epoch:5 step:5436 [D loss: 0.709899, acc.: 40.62%] [G loss: 0.712245]\n",
      "epoch:5 step:5437 [D loss: 0.705501, acc.: 40.62%] [G loss: 0.714974]\n",
      "epoch:5 step:5438 [D loss: 0.692852, acc.: 49.22%] [G loss: 0.734968]\n",
      "epoch:5 step:5439 [D loss: 0.686049, acc.: 56.25%] [G loss: 0.726752]\n",
      "epoch:5 step:5440 [D loss: 0.687264, acc.: 55.47%] [G loss: 0.715993]\n",
      "epoch:5 step:5441 [D loss: 0.687841, acc.: 51.56%] [G loss: 0.698051]\n",
      "epoch:5 step:5442 [D loss: 0.684614, acc.: 56.25%] [G loss: 0.715904]\n",
      "epoch:5 step:5443 [D loss: 0.696158, acc.: 52.34%] [G loss: 0.735034]\n",
      "epoch:5 step:5444 [D loss: 0.687404, acc.: 54.69%] [G loss: 0.730389]\n",
      "epoch:5 step:5445 [D loss: 0.694856, acc.: 53.91%] [G loss: 0.725752]\n",
      "epoch:5 step:5446 [D loss: 0.687410, acc.: 46.88%] [G loss: 0.723304]\n",
      "epoch:5 step:5447 [D loss: 0.690420, acc.: 50.00%] [G loss: 0.723349]\n",
      "epoch:5 step:5448 [D loss: 0.691449, acc.: 53.91%] [G loss: 0.721915]\n",
      "epoch:5 step:5449 [D loss: 0.684660, acc.: 52.34%] [G loss: 0.736934]\n",
      "epoch:5 step:5450 [D loss: 0.687577, acc.: 53.12%] [G loss: 0.733846]\n",
      "epoch:5 step:5451 [D loss: 0.692318, acc.: 50.78%] [G loss: 0.737950]\n",
      "epoch:5 step:5452 [D loss: 0.687427, acc.: 53.12%] [G loss: 0.722801]\n",
      "epoch:5 step:5453 [D loss: 0.715470, acc.: 41.41%] [G loss: 0.727330]\n",
      "epoch:5 step:5454 [D loss: 0.702538, acc.: 44.53%] [G loss: 0.704750]\n",
      "epoch:5 step:5455 [D loss: 0.694769, acc.: 52.34%] [G loss: 0.712512]\n",
      "epoch:5 step:5456 [D loss: 0.686588, acc.: 57.03%] [G loss: 0.704579]\n",
      "epoch:5 step:5457 [D loss: 0.699054, acc.: 53.12%] [G loss: 0.734656]\n",
      "epoch:5 step:5458 [D loss: 0.689811, acc.: 51.56%] [G loss: 0.715562]\n",
      "epoch:5 step:5459 [D loss: 0.707775, acc.: 49.22%] [G loss: 0.697256]\n",
      "epoch:5 step:5460 [D loss: 0.686011, acc.: 54.69%] [G loss: 0.714459]\n",
      "epoch:5 step:5461 [D loss: 0.693779, acc.: 54.69%] [G loss: 0.712830]\n",
      "epoch:5 step:5462 [D loss: 0.693823, acc.: 47.66%] [G loss: 0.743092]\n",
      "epoch:5 step:5463 [D loss: 0.697377, acc.: 50.78%] [G loss: 0.720420]\n",
      "epoch:5 step:5464 [D loss: 0.701174, acc.: 49.22%] [G loss: 0.726218]\n",
      "epoch:5 step:5465 [D loss: 0.692347, acc.: 53.12%] [G loss: 0.706890]\n",
      "epoch:5 step:5466 [D loss: 0.691324, acc.: 53.12%] [G loss: 0.724249]\n",
      "epoch:5 step:5467 [D loss: 0.672444, acc.: 61.72%] [G loss: 0.722609]\n",
      "epoch:5 step:5468 [D loss: 0.688994, acc.: 52.34%] [G loss: 0.756683]\n",
      "epoch:5 step:5469 [D loss: 0.704223, acc.: 50.00%] [G loss: 0.725723]\n",
      "epoch:5 step:5470 [D loss: 0.690834, acc.: 56.25%] [G loss: 0.712859]\n",
      "epoch:5 step:5471 [D loss: 0.693869, acc.: 48.44%] [G loss: 0.770967]\n",
      "epoch:5 step:5472 [D loss: 0.700419, acc.: 51.56%] [G loss: 0.716487]\n",
      "epoch:5 step:5473 [D loss: 0.703840, acc.: 45.31%] [G loss: 0.723819]\n",
      "epoch:5 step:5474 [D loss: 0.702356, acc.: 44.53%] [G loss: 0.711570]\n",
      "epoch:5 step:5475 [D loss: 0.685073, acc.: 63.28%] [G loss: 0.715481]\n",
      "epoch:5 step:5476 [D loss: 0.688577, acc.: 55.47%] [G loss: 0.718124]\n",
      "epoch:5 step:5477 [D loss: 0.672882, acc.: 60.16%] [G loss: 0.726165]\n",
      "epoch:5 step:5478 [D loss: 0.683125, acc.: 56.25%] [G loss: 0.723199]\n",
      "epoch:5 step:5479 [D loss: 0.680230, acc.: 53.91%] [G loss: 0.723494]\n",
      "epoch:5 step:5480 [D loss: 0.695207, acc.: 55.47%] [G loss: 0.723740]\n",
      "epoch:5 step:5481 [D loss: 0.684202, acc.: 57.81%] [G loss: 0.711004]\n",
      "epoch:5 step:5482 [D loss: 0.683962, acc.: 53.91%] [G loss: 0.730691]\n",
      "epoch:5 step:5483 [D loss: 0.695674, acc.: 47.66%] [G loss: 0.708141]\n",
      "epoch:5 step:5484 [D loss: 0.693226, acc.: 52.34%] [G loss: 0.712283]\n",
      "epoch:5 step:5485 [D loss: 0.709799, acc.: 36.72%] [G loss: 0.754611]\n",
      "epoch:5 step:5486 [D loss: 0.702064, acc.: 51.56%] [G loss: 0.720369]\n",
      "epoch:5 step:5487 [D loss: 0.630118, acc.: 57.03%] [G loss: 0.734125]\n",
      "epoch:5 step:5488 [D loss: 0.688706, acc.: 55.47%] [G loss: 0.738329]\n",
      "epoch:5 step:5489 [D loss: 0.718503, acc.: 50.78%] [G loss: 0.709860]\n",
      "epoch:5 step:5490 [D loss: 0.716201, acc.: 42.97%] [G loss: 0.738263]\n",
      "epoch:5 step:5491 [D loss: 0.703937, acc.: 47.66%] [G loss: 0.714949]\n",
      "epoch:5 step:5492 [D loss: 0.683856, acc.: 50.78%] [G loss: 0.706191]\n",
      "epoch:5 step:5493 [D loss: 0.690004, acc.: 56.25%] [G loss: 0.729084]\n",
      "epoch:5 step:5494 [D loss: 0.673024, acc.: 60.16%] [G loss: 0.722239]\n",
      "epoch:5 step:5495 [D loss: 0.688218, acc.: 57.81%] [G loss: 0.732850]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5496 [D loss: 0.731946, acc.: 38.28%] [G loss: 0.712204]\n",
      "epoch:5 step:5497 [D loss: 0.705020, acc.: 44.53%] [G loss: 0.702538]\n",
      "epoch:5 step:5498 [D loss: 0.739153, acc.: 45.31%] [G loss: 0.741542]\n",
      "epoch:5 step:5499 [D loss: 0.702818, acc.: 52.34%] [G loss: 0.741919]\n",
      "epoch:5 step:5500 [D loss: 0.672047, acc.: 60.16%] [G loss: 0.735017]\n",
      "epoch:5 step:5501 [D loss: 0.689598, acc.: 54.69%] [G loss: 0.753822]\n",
      "epoch:5 step:5502 [D loss: 0.685287, acc.: 50.78%] [G loss: 0.748979]\n",
      "epoch:5 step:5503 [D loss: 0.708820, acc.: 46.88%] [G loss: 0.744053]\n",
      "epoch:5 step:5504 [D loss: 0.696972, acc.: 51.56%] [G loss: 0.742588]\n",
      "epoch:5 step:5505 [D loss: 0.697032, acc.: 45.31%] [G loss: 0.767713]\n",
      "epoch:5 step:5506 [D loss: 0.691362, acc.: 46.09%] [G loss: 0.765192]\n",
      "epoch:5 step:5507 [D loss: 0.684901, acc.: 54.69%] [G loss: 0.770032]\n",
      "epoch:5 step:5508 [D loss: 0.685089, acc.: 53.91%] [G loss: 0.799592]\n",
      "epoch:5 step:5509 [D loss: 0.672162, acc.: 62.50%] [G loss: 0.782152]\n",
      "epoch:5 step:5510 [D loss: 0.682989, acc.: 57.03%] [G loss: 0.801998]\n",
      "epoch:5 step:5511 [D loss: 0.640789, acc.: 61.72%] [G loss: 0.812769]\n",
      "epoch:5 step:5512 [D loss: 0.684692, acc.: 51.56%] [G loss: 0.861672]\n",
      "epoch:5 step:5513 [D loss: 0.681965, acc.: 56.25%] [G loss: 0.795122]\n",
      "epoch:5 step:5514 [D loss: 0.662688, acc.: 65.62%] [G loss: 0.793793]\n",
      "epoch:5 step:5515 [D loss: 0.674792, acc.: 59.38%] [G loss: 0.829047]\n",
      "epoch:5 step:5516 [D loss: 0.722148, acc.: 39.06%] [G loss: 0.754999]\n",
      "epoch:5 step:5517 [D loss: 0.757745, acc.: 39.84%] [G loss: 0.664402]\n",
      "epoch:5 step:5518 [D loss: 0.748194, acc.: 33.59%] [G loss: 0.704992]\n",
      "epoch:5 step:5519 [D loss: 0.717346, acc.: 39.84%] [G loss: 0.697365]\n",
      "epoch:5 step:5520 [D loss: 0.705148, acc.: 49.22%] [G loss: 0.701372]\n",
      "epoch:5 step:5521 [D loss: 0.695933, acc.: 44.53%] [G loss: 0.700548]\n",
      "epoch:5 step:5522 [D loss: 0.688182, acc.: 58.59%] [G loss: 0.718256]\n",
      "epoch:5 step:5523 [D loss: 0.681075, acc.: 61.72%] [G loss: 0.738114]\n",
      "epoch:5 step:5524 [D loss: 0.673225, acc.: 60.94%] [G loss: 0.743302]\n",
      "epoch:5 step:5525 [D loss: 0.677908, acc.: 58.59%] [G loss: 0.760681]\n",
      "epoch:5 step:5526 [D loss: 0.654991, acc.: 71.09%] [G loss: 0.768841]\n",
      "epoch:5 step:5527 [D loss: 0.655761, acc.: 61.72%] [G loss: 0.761494]\n",
      "epoch:5 step:5528 [D loss: 0.681347, acc.: 54.69%] [G loss: 0.778167]\n",
      "epoch:5 step:5529 [D loss: 0.680800, acc.: 58.59%] [G loss: 0.765216]\n",
      "epoch:5 step:5530 [D loss: 0.656580, acc.: 59.38%] [G loss: 0.728279]\n",
      "epoch:5 step:5531 [D loss: 0.728659, acc.: 51.56%] [G loss: 0.694824]\n",
      "epoch:5 step:5532 [D loss: 0.728411, acc.: 36.72%] [G loss: 0.703685]\n",
      "epoch:5 step:5533 [D loss: 0.734473, acc.: 41.41%] [G loss: 0.705821]\n",
      "epoch:5 step:5534 [D loss: 0.708847, acc.: 46.88%] [G loss: 0.700268]\n",
      "epoch:5 step:5535 [D loss: 0.709579, acc.: 46.88%] [G loss: 0.733615]\n",
      "epoch:5 step:5536 [D loss: 0.688587, acc.: 54.69%] [G loss: 0.731529]\n",
      "epoch:5 step:5537 [D loss: 0.688797, acc.: 55.47%] [G loss: 0.758485]\n",
      "epoch:5 step:5538 [D loss: 0.669883, acc.: 60.94%] [G loss: 0.740419]\n",
      "epoch:5 step:5539 [D loss: 0.671864, acc.: 58.59%] [G loss: 0.774850]\n",
      "epoch:5 step:5540 [D loss: 0.660973, acc.: 67.19%] [G loss: 0.844033]\n",
      "epoch:5 step:5541 [D loss: 0.667066, acc.: 57.81%] [G loss: 0.786287]\n",
      "epoch:5 step:5542 [D loss: 0.669074, acc.: 64.06%] [G loss: 0.821811]\n",
      "epoch:5 step:5543 [D loss: 0.710842, acc.: 48.44%] [G loss: 0.832508]\n",
      "epoch:5 step:5544 [D loss: 0.712206, acc.: 42.97%] [G loss: 0.764860]\n",
      "epoch:5 step:5545 [D loss: 0.705785, acc.: 47.66%] [G loss: 0.722828]\n",
      "epoch:5 step:5546 [D loss: 0.717909, acc.: 40.62%] [G loss: 0.701435]\n",
      "epoch:5 step:5547 [D loss: 0.719097, acc.: 46.88%] [G loss: 0.723066]\n",
      "epoch:5 step:5548 [D loss: 0.708030, acc.: 43.75%] [G loss: 0.696885]\n",
      "epoch:5 step:5549 [D loss: 0.704880, acc.: 50.00%] [G loss: 0.712072]\n",
      "epoch:5 step:5550 [D loss: 0.702679, acc.: 46.88%] [G loss: 0.697505]\n",
      "epoch:5 step:5551 [D loss: 0.700710, acc.: 46.88%] [G loss: 0.695304]\n",
      "epoch:5 step:5552 [D loss: 0.704695, acc.: 45.31%] [G loss: 0.697423]\n",
      "epoch:5 step:5553 [D loss: 0.704954, acc.: 42.19%] [G loss: 0.713431]\n",
      "epoch:5 step:5554 [D loss: 0.699041, acc.: 48.44%] [G loss: 0.699223]\n",
      "epoch:5 step:5555 [D loss: 0.693858, acc.: 44.53%] [G loss: 0.714324]\n",
      "epoch:5 step:5556 [D loss: 0.683716, acc.: 57.03%] [G loss: 0.705566]\n",
      "epoch:5 step:5557 [D loss: 0.686492, acc.: 57.03%] [G loss: 0.741971]\n",
      "epoch:5 step:5558 [D loss: 0.677970, acc.: 67.19%] [G loss: 0.725406]\n",
      "epoch:5 step:5559 [D loss: 0.685366, acc.: 51.56%] [G loss: 0.708305]\n",
      "epoch:5 step:5560 [D loss: 0.690857, acc.: 53.12%] [G loss: 0.725627]\n",
      "epoch:5 step:5561 [D loss: 0.698532, acc.: 53.12%] [G loss: 0.705323]\n",
      "epoch:5 step:5562 [D loss: 0.695734, acc.: 51.56%] [G loss: 0.690517]\n",
      "epoch:5 step:5563 [D loss: 0.692820, acc.: 52.34%] [G loss: 0.715034]\n",
      "epoch:5 step:5564 [D loss: 0.698439, acc.: 50.00%] [G loss: 0.724839]\n",
      "epoch:5 step:5565 [D loss: 0.701647, acc.: 49.22%] [G loss: 0.707621]\n",
      "epoch:5 step:5566 [D loss: 0.696710, acc.: 53.12%] [G loss: 0.720671]\n",
      "epoch:5 step:5567 [D loss: 0.697106, acc.: 49.22%] [G loss: 0.697789]\n",
      "epoch:5 step:5568 [D loss: 0.698036, acc.: 53.91%] [G loss: 0.712052]\n",
      "epoch:5 step:5569 [D loss: 0.679384, acc.: 59.38%] [G loss: 0.714193]\n",
      "epoch:5 step:5570 [D loss: 0.680040, acc.: 61.72%] [G loss: 0.692031]\n",
      "epoch:5 step:5571 [D loss: 0.677375, acc.: 64.06%] [G loss: 0.709519]\n",
      "epoch:5 step:5572 [D loss: 0.707875, acc.: 45.31%] [G loss: 0.738283]\n",
      "epoch:5 step:5573 [D loss: 0.684647, acc.: 56.25%] [G loss: 0.724536]\n",
      "epoch:5 step:5574 [D loss: 0.688646, acc.: 51.56%] [G loss: 0.717445]\n",
      "epoch:5 step:5575 [D loss: 0.692879, acc.: 55.47%] [G loss: 0.736398]\n",
      "epoch:5 step:5576 [D loss: 0.713172, acc.: 40.62%] [G loss: 0.715809]\n",
      "epoch:5 step:5577 [D loss: 0.714422, acc.: 44.53%] [G loss: 0.728866]\n",
      "epoch:5 step:5578 [D loss: 0.701811, acc.: 53.12%] [G loss: 0.713237]\n",
      "epoch:5 step:5579 [D loss: 0.684006, acc.: 57.03%] [G loss: 0.724031]\n",
      "epoch:5 step:5580 [D loss: 0.702356, acc.: 40.62%] [G loss: 0.700934]\n",
      "epoch:5 step:5581 [D loss: 0.686725, acc.: 53.12%] [G loss: 0.722829]\n",
      "epoch:5 step:5582 [D loss: 0.701972, acc.: 48.44%] [G loss: 0.725508]\n",
      "epoch:5 step:5583 [D loss: 0.690571, acc.: 54.69%] [G loss: 0.772620]\n",
      "epoch:5 step:5584 [D loss: 0.650428, acc.: 63.28%] [G loss: 0.739934]\n",
      "epoch:5 step:5585 [D loss: 0.666327, acc.: 60.16%] [G loss: 0.753858]\n",
      "epoch:5 step:5586 [D loss: 0.682738, acc.: 63.28%] [G loss: 0.735514]\n",
      "epoch:5 step:5587 [D loss: 0.682526, acc.: 62.50%] [G loss: 0.726180]\n",
      "epoch:5 step:5588 [D loss: 0.691714, acc.: 58.59%] [G loss: 0.715826]\n",
      "epoch:5 step:5589 [D loss: 0.720170, acc.: 35.16%] [G loss: 0.720901]\n",
      "epoch:5 step:5590 [D loss: 0.708424, acc.: 45.31%] [G loss: 0.721914]\n",
      "epoch:5 step:5591 [D loss: 0.705268, acc.: 39.06%] [G loss: 0.721600]\n",
      "epoch:5 step:5592 [D loss: 0.693773, acc.: 47.66%] [G loss: 0.707432]\n",
      "epoch:5 step:5593 [D loss: 0.697724, acc.: 50.78%] [G loss: 0.718349]\n",
      "epoch:5 step:5594 [D loss: 0.683873, acc.: 62.50%] [G loss: 0.712737]\n",
      "epoch:5 step:5595 [D loss: 0.708382, acc.: 45.31%] [G loss: 0.705718]\n",
      "epoch:5 step:5596 [D loss: 0.710348, acc.: 48.44%] [G loss: 0.727519]\n",
      "epoch:5 step:5597 [D loss: 0.563150, acc.: 68.75%] [G loss: 0.772909]\n",
      "epoch:5 step:5598 [D loss: 0.707860, acc.: 52.34%] [G loss: 0.724136]\n",
      "epoch:5 step:5599 [D loss: 0.712556, acc.: 53.91%] [G loss: 0.726165]\n",
      "epoch:5 step:5600 [D loss: 0.728851, acc.: 41.41%] [G loss: 0.735911]\n",
      "##############\n",
      "[3.93603578 2.49291297 6.51933011 4.96955366 4.14126145 6.16897285\n",
      " 5.39258689 5.38401906 5.87295125 4.85195529]\n",
      "##########\n",
      "epoch:5 step:5601 [D loss: 0.707392, acc.: 44.53%] [G loss: 0.734272]\n",
      "epoch:5 step:5602 [D loss: 0.692386, acc.: 52.34%] [G loss: 0.716626]\n",
      "epoch:5 step:5603 [D loss: 0.689458, acc.: 53.12%] [G loss: 0.720968]\n",
      "epoch:5 step:5604 [D loss: 0.674862, acc.: 57.03%] [G loss: 0.718163]\n",
      "epoch:5 step:5605 [D loss: 0.697735, acc.: 52.34%] [G loss: 0.719764]\n",
      "epoch:5 step:5606 [D loss: 0.713773, acc.: 43.75%] [G loss: 0.729260]\n",
      "epoch:5 step:5607 [D loss: 0.692244, acc.: 53.91%] [G loss: 0.728277]\n",
      "epoch:5 step:5608 [D loss: 0.686860, acc.: 53.12%] [G loss: 0.725353]\n",
      "epoch:5 step:5609 [D loss: 0.621313, acc.: 69.53%] [G loss: 0.688431]\n",
      "epoch:5 step:5610 [D loss: 0.598731, acc.: 64.84%] [G loss: 0.695551]\n",
      "epoch:5 step:5611 [D loss: 0.475912, acc.: 64.06%] [G loss: 0.678978]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5612 [D loss: 0.421930, acc.: 64.84%] [G loss: 0.762171]\n",
      "epoch:5 step:5613 [D loss: 0.743564, acc.: 40.62%] [G loss: 0.792549]\n",
      "epoch:5 step:5614 [D loss: 0.762216, acc.: 25.78%] [G loss: 0.737122]\n",
      "epoch:5 step:5615 [D loss: 0.691007, acc.: 50.78%] [G loss: 0.796980]\n",
      "epoch:5 step:5616 [D loss: 0.661473, acc.: 64.84%] [G loss: 0.801016]\n",
      "epoch:5 step:5617 [D loss: 0.649679, acc.: 70.31%] [G loss: 0.429285]\n",
      "epoch:5 step:5618 [D loss: 0.589269, acc.: 55.47%] [G loss: 0.550888]\n",
      "epoch:5 step:5619 [D loss: 0.556895, acc.: 64.84%] [G loss: 0.433220]\n",
      "epoch:5 step:5620 [D loss: 0.807684, acc.: 49.22%] [G loss: 0.625279]\n",
      "epoch:5 step:5621 [D loss: 1.195438, acc.: 50.00%] [G loss: 1.085848]\n",
      "epoch:5 step:5622 [D loss: 0.756775, acc.: 50.00%] [G loss: 0.896219]\n",
      "epoch:6 step:5623 [D loss: 0.667664, acc.: 44.53%] [G loss: 0.781353]\n",
      "epoch:6 step:5624 [D loss: 0.715213, acc.: 50.00%] [G loss: 0.791927]\n",
      "epoch:6 step:5625 [D loss: 0.688444, acc.: 54.69%] [G loss: 0.976346]\n",
      "epoch:6 step:5626 [D loss: 0.674038, acc.: 54.69%] [G loss: 0.772477]\n",
      "epoch:6 step:5627 [D loss: 0.692445, acc.: 51.56%] [G loss: 0.781710]\n",
      "epoch:6 step:5628 [D loss: 0.695905, acc.: 46.09%] [G loss: 0.742378]\n",
      "epoch:6 step:5629 [D loss: 0.678888, acc.: 63.28%] [G loss: 0.749313]\n",
      "epoch:6 step:5630 [D loss: 0.701316, acc.: 51.56%] [G loss: 0.727871]\n",
      "epoch:6 step:5631 [D loss: 0.669016, acc.: 60.94%] [G loss: 1.090093]\n",
      "epoch:6 step:5632 [D loss: 0.696604, acc.: 48.44%] [G loss: 0.745966]\n",
      "epoch:6 step:5633 [D loss: 0.698511, acc.: 46.09%] [G loss: 0.733179]\n",
      "epoch:6 step:5634 [D loss: 0.681626, acc.: 53.12%] [G loss: 0.786332]\n",
      "epoch:6 step:5635 [D loss: 0.704361, acc.: 43.75%] [G loss: 0.758016]\n",
      "epoch:6 step:5636 [D loss: 0.691938, acc.: 57.03%] [G loss: 0.758284]\n",
      "epoch:6 step:5637 [D loss: 0.679811, acc.: 48.44%] [G loss: 1.006755]\n",
      "epoch:6 step:5638 [D loss: 0.690944, acc.: 60.16%] [G loss: 0.702981]\n",
      "epoch:6 step:5639 [D loss: 0.697809, acc.: 53.12%] [G loss: 0.733700]\n",
      "epoch:6 step:5640 [D loss: 0.687491, acc.: 53.12%] [G loss: 0.751509]\n",
      "epoch:6 step:5641 [D loss: 0.699914, acc.: 54.69%] [G loss: 0.679834]\n",
      "epoch:6 step:5642 [D loss: 0.713456, acc.: 42.97%] [G loss: 0.714332]\n",
      "epoch:6 step:5643 [D loss: 0.679593, acc.: 42.97%] [G loss: 0.747258]\n",
      "epoch:6 step:5644 [D loss: 0.684776, acc.: 53.91%] [G loss: 0.730767]\n",
      "epoch:6 step:5645 [D loss: 0.698593, acc.: 51.56%] [G loss: 0.703806]\n",
      "epoch:6 step:5646 [D loss: 0.670235, acc.: 60.16%] [G loss: 0.691015]\n",
      "epoch:6 step:5647 [D loss: 0.686455, acc.: 55.47%] [G loss: 0.658836]\n",
      "epoch:6 step:5648 [D loss: 0.702539, acc.: 53.12%] [G loss: 0.713124]\n",
      "epoch:6 step:5649 [D loss: 0.749465, acc.: 31.25%] [G loss: 0.650165]\n",
      "epoch:6 step:5650 [D loss: 0.713998, acc.: 48.44%] [G loss: 0.596835]\n",
      "epoch:6 step:5651 [D loss: 0.757564, acc.: 42.97%] [G loss: 0.708636]\n",
      "epoch:6 step:5652 [D loss: 0.677817, acc.: 64.06%] [G loss: 0.725611]\n",
      "epoch:6 step:5653 [D loss: 0.711438, acc.: 36.72%] [G loss: 0.724843]\n",
      "epoch:6 step:5654 [D loss: 0.676327, acc.: 50.78%] [G loss: 0.748271]\n",
      "epoch:6 step:5655 [D loss: 0.685490, acc.: 57.03%] [G loss: 0.750397]\n",
      "epoch:6 step:5656 [D loss: 0.672525, acc.: 66.41%] [G loss: 0.787158]\n",
      "epoch:6 step:5657 [D loss: 0.671293, acc.: 62.50%] [G loss: 0.747107]\n",
      "epoch:6 step:5658 [D loss: 0.646532, acc.: 61.72%] [G loss: 0.765166]\n",
      "epoch:6 step:5659 [D loss: 0.692190, acc.: 59.38%] [G loss: 0.780524]\n",
      "epoch:6 step:5660 [D loss: 0.789062, acc.: 39.84%] [G loss: 0.744561]\n",
      "epoch:6 step:5661 [D loss: 0.712067, acc.: 44.53%] [G loss: 0.718607]\n",
      "epoch:6 step:5662 [D loss: 0.678547, acc.: 56.25%] [G loss: 0.731196]\n",
      "epoch:6 step:5663 [D loss: 0.694743, acc.: 47.66%] [G loss: 0.705905]\n",
      "epoch:6 step:5664 [D loss: 0.688402, acc.: 49.22%] [G loss: 0.523342]\n",
      "epoch:6 step:5665 [D loss: 0.686442, acc.: 50.00%] [G loss: 0.704927]\n",
      "epoch:6 step:5666 [D loss: 0.696991, acc.: 47.66%] [G loss: 0.697783]\n",
      "epoch:6 step:5667 [D loss: 0.695945, acc.: 52.34%] [G loss: 0.604408]\n",
      "epoch:6 step:5668 [D loss: 0.702373, acc.: 45.31%] [G loss: 0.693334]\n",
      "epoch:6 step:5669 [D loss: 0.729672, acc.: 47.66%] [G loss: 0.730622]\n",
      "epoch:6 step:5670 [D loss: 0.674161, acc.: 59.38%] [G loss: 0.723911]\n",
      "epoch:6 step:5671 [D loss: 0.697507, acc.: 50.78%] [G loss: 0.749964]\n",
      "epoch:6 step:5672 [D loss: 0.646595, acc.: 60.94%] [G loss: 0.644988]\n",
      "epoch:6 step:5673 [D loss: 0.688327, acc.: 53.12%] [G loss: 0.727083]\n",
      "epoch:6 step:5674 [D loss: 0.680464, acc.: 57.81%] [G loss: 0.716601]\n",
      "epoch:6 step:5675 [D loss: 0.697411, acc.: 57.81%] [G loss: 0.746180]\n",
      "epoch:6 step:5676 [D loss: 0.686375, acc.: 50.78%] [G loss: 0.733965]\n",
      "epoch:6 step:5677 [D loss: 0.668695, acc.: 65.62%] [G loss: 0.758390]\n",
      "epoch:6 step:5678 [D loss: 0.706549, acc.: 48.44%] [G loss: 0.758509]\n",
      "epoch:6 step:5679 [D loss: 0.688469, acc.: 54.69%] [G loss: 0.784057]\n",
      "epoch:6 step:5680 [D loss: 0.701406, acc.: 49.22%] [G loss: 0.747844]\n",
      "epoch:6 step:5681 [D loss: 0.707856, acc.: 42.97%] [G loss: 0.779006]\n",
      "epoch:6 step:5682 [D loss: 0.686668, acc.: 54.69%] [G loss: 0.771878]\n",
      "epoch:6 step:5683 [D loss: 0.683980, acc.: 51.56%] [G loss: 0.771700]\n",
      "epoch:6 step:5684 [D loss: 0.681461, acc.: 55.47%] [G loss: 0.753746]\n",
      "epoch:6 step:5685 [D loss: 0.685260, acc.: 50.00%] [G loss: 0.752614]\n",
      "epoch:6 step:5686 [D loss: 0.698081, acc.: 48.44%] [G loss: 0.749404]\n",
      "epoch:6 step:5687 [D loss: 0.694092, acc.: 46.09%] [G loss: 0.727451]\n",
      "epoch:6 step:5688 [D loss: 0.695447, acc.: 50.00%] [G loss: 0.733062]\n",
      "epoch:6 step:5689 [D loss: 0.683183, acc.: 53.12%] [G loss: 0.793116]\n",
      "epoch:6 step:5690 [D loss: 0.692146, acc.: 53.12%] [G loss: 0.751238]\n",
      "epoch:6 step:5691 [D loss: 0.682927, acc.: 51.56%] [G loss: 0.750504]\n",
      "epoch:6 step:5692 [D loss: 0.684745, acc.: 56.25%] [G loss: 0.741270]\n",
      "epoch:6 step:5693 [D loss: 0.703018, acc.: 46.88%] [G loss: 0.735395]\n",
      "epoch:6 step:5694 [D loss: 0.690716, acc.: 51.56%] [G loss: 0.744452]\n",
      "epoch:6 step:5695 [D loss: 0.692170, acc.: 48.44%] [G loss: 0.716188]\n",
      "epoch:6 step:5696 [D loss: 0.674024, acc.: 68.75%] [G loss: 0.739375]\n",
      "epoch:6 step:5697 [D loss: 0.675605, acc.: 57.81%] [G loss: 0.741125]\n",
      "epoch:6 step:5698 [D loss: 0.673021, acc.: 63.28%] [G loss: 0.734270]\n",
      "epoch:6 step:5699 [D loss: 0.659091, acc.: 64.84%] [G loss: 0.772974]\n",
      "epoch:6 step:5700 [D loss: 0.720711, acc.: 43.75%] [G loss: 0.723488]\n",
      "epoch:6 step:5701 [D loss: 0.707398, acc.: 39.06%] [G loss: 0.747823]\n",
      "epoch:6 step:5702 [D loss: 0.718562, acc.: 37.50%] [G loss: 0.725457]\n",
      "epoch:6 step:5703 [D loss: 0.723019, acc.: 39.84%] [G loss: 0.728137]\n",
      "epoch:6 step:5704 [D loss: 0.719382, acc.: 42.19%] [G loss: 0.740735]\n",
      "epoch:6 step:5705 [D loss: 0.706223, acc.: 46.09%] [G loss: 0.724009]\n",
      "epoch:6 step:5706 [D loss: 0.719707, acc.: 45.31%] [G loss: 0.720865]\n",
      "epoch:6 step:5707 [D loss: 0.677329, acc.: 54.69%] [G loss: 0.745103]\n",
      "epoch:6 step:5708 [D loss: 0.687113, acc.: 57.81%] [G loss: 0.742975]\n",
      "epoch:6 step:5709 [D loss: 0.680277, acc.: 58.59%] [G loss: 0.737942]\n",
      "epoch:6 step:5710 [D loss: 0.679782, acc.: 55.47%] [G loss: 0.720945]\n",
      "epoch:6 step:5711 [D loss: 0.666791, acc.: 63.28%] [G loss: 0.711331]\n",
      "epoch:6 step:5712 [D loss: 0.679111, acc.: 61.72%] [G loss: 0.728972]\n",
      "epoch:6 step:5713 [D loss: 0.680465, acc.: 57.03%] [G loss: 0.724044]\n",
      "epoch:6 step:5714 [D loss: 0.684210, acc.: 66.41%] [G loss: 0.708997]\n",
      "epoch:6 step:5715 [D loss: 0.696676, acc.: 55.47%] [G loss: 0.683308]\n",
      "epoch:6 step:5716 [D loss: 0.689502, acc.: 53.91%] [G loss: 0.704993]\n",
      "epoch:6 step:5717 [D loss: 0.676262, acc.: 61.72%] [G loss: 0.717674]\n",
      "epoch:6 step:5718 [D loss: 0.702583, acc.: 52.34%] [G loss: 0.445576]\n",
      "epoch:6 step:5719 [D loss: 0.683208, acc.: 52.34%] [G loss: 0.663931]\n",
      "epoch:6 step:5720 [D loss: 0.687142, acc.: 59.38%] [G loss: 0.683375]\n",
      "epoch:6 step:5721 [D loss: 0.708805, acc.: 46.88%] [G loss: 0.716063]\n",
      "epoch:6 step:5722 [D loss: 0.700939, acc.: 48.44%] [G loss: 0.712871]\n",
      "epoch:6 step:5723 [D loss: 0.684522, acc.: 50.00%] [G loss: 0.741453]\n",
      "epoch:6 step:5724 [D loss: 0.701644, acc.: 47.66%] [G loss: 0.743609]\n",
      "epoch:6 step:5725 [D loss: 0.691540, acc.: 49.22%] [G loss: 0.754443]\n",
      "epoch:6 step:5726 [D loss: 0.681691, acc.: 55.47%] [G loss: 0.793960]\n",
      "epoch:6 step:5727 [D loss: 0.673197, acc.: 58.59%] [G loss: 0.863742]\n",
      "epoch:6 step:5728 [D loss: 0.671716, acc.: 62.50%] [G loss: 0.850831]\n",
      "epoch:6 step:5729 [D loss: 0.655235, acc.: 64.06%] [G loss: 0.858397]\n",
      "epoch:6 step:5730 [D loss: 0.728715, acc.: 44.53%] [G loss: 0.755247]\n",
      "epoch:6 step:5731 [D loss: 0.743115, acc.: 41.41%] [G loss: 0.741404]\n",
      "epoch:6 step:5732 [D loss: 0.717986, acc.: 42.97%] [G loss: 0.725037]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5733 [D loss: 0.699006, acc.: 47.66%] [G loss: 0.706615]\n",
      "epoch:6 step:5734 [D loss: 0.688581, acc.: 48.44%] [G loss: 0.713567]\n",
      "epoch:6 step:5735 [D loss: 0.690577, acc.: 53.12%] [G loss: 0.723139]\n",
      "epoch:6 step:5736 [D loss: 0.703837, acc.: 44.53%] [G loss: 0.722044]\n",
      "epoch:6 step:5737 [D loss: 0.680421, acc.: 61.72%] [G loss: 0.738364]\n",
      "epoch:6 step:5738 [D loss: 0.691386, acc.: 51.56%] [G loss: 0.729494]\n",
      "epoch:6 step:5739 [D loss: 0.697287, acc.: 43.75%] [G loss: 0.736409]\n",
      "epoch:6 step:5740 [D loss: 0.691147, acc.: 42.97%] [G loss: 0.745347]\n",
      "epoch:6 step:5741 [D loss: 0.686453, acc.: 52.34%] [G loss: 0.739955]\n",
      "epoch:6 step:5742 [D loss: 0.690742, acc.: 51.56%] [G loss: 0.800341]\n",
      "epoch:6 step:5743 [D loss: 0.685838, acc.: 53.91%] [G loss: 0.764406]\n",
      "epoch:6 step:5744 [D loss: 0.691781, acc.: 50.78%] [G loss: 0.775775]\n",
      "epoch:6 step:5745 [D loss: 0.687319, acc.: 52.34%] [G loss: 0.778278]\n",
      "epoch:6 step:5746 [D loss: 0.660857, acc.: 69.53%] [G loss: 0.788063]\n",
      "epoch:6 step:5747 [D loss: 0.661130, acc.: 66.41%] [G loss: 0.791884]\n",
      "epoch:6 step:5748 [D loss: 0.687507, acc.: 53.12%] [G loss: 0.858981]\n",
      "epoch:6 step:5749 [D loss: 0.687360, acc.: 52.34%] [G loss: 0.737966]\n",
      "epoch:6 step:5750 [D loss: 0.729747, acc.: 35.16%] [G loss: 0.722062]\n",
      "epoch:6 step:5751 [D loss: 0.726598, acc.: 29.69%] [G loss: 0.702402]\n",
      "epoch:6 step:5752 [D loss: 0.678923, acc.: 58.59%] [G loss: 0.732773]\n",
      "epoch:6 step:5753 [D loss: 0.705736, acc.: 50.00%] [G loss: 0.713620]\n",
      "epoch:6 step:5754 [D loss: 0.707963, acc.: 46.09%] [G loss: 0.718844]\n",
      "epoch:6 step:5755 [D loss: 0.697797, acc.: 48.44%] [G loss: 0.723090]\n",
      "epoch:6 step:5756 [D loss: 0.684198, acc.: 52.34%] [G loss: 0.708346]\n",
      "epoch:6 step:5757 [D loss: 0.682442, acc.: 59.38%] [G loss: 0.729707]\n",
      "epoch:6 step:5758 [D loss: 0.693110, acc.: 57.81%] [G loss: 0.722719]\n",
      "epoch:6 step:5759 [D loss: 0.789222, acc.: 41.41%] [G loss: 0.763016]\n",
      "epoch:6 step:5760 [D loss: 0.697125, acc.: 55.47%] [G loss: 0.785492]\n",
      "epoch:6 step:5761 [D loss: 0.656999, acc.: 64.84%] [G loss: 0.803581]\n",
      "epoch:6 step:5762 [D loss: 0.712826, acc.: 50.78%] [G loss: 0.775392]\n",
      "epoch:6 step:5763 [D loss: 0.694353, acc.: 47.66%] [G loss: 0.758681]\n",
      "epoch:6 step:5764 [D loss: 0.700020, acc.: 51.56%] [G loss: 0.753473]\n",
      "epoch:6 step:5765 [D loss: 0.692882, acc.: 46.88%] [G loss: 0.742355]\n",
      "epoch:6 step:5766 [D loss: 0.676207, acc.: 57.03%] [G loss: 0.722884]\n",
      "epoch:6 step:5767 [D loss: 0.688093, acc.: 55.47%] [G loss: 0.730213]\n",
      "epoch:6 step:5768 [D loss: 0.711618, acc.: 48.44%] [G loss: 0.704180]\n",
      "epoch:6 step:5769 [D loss: 0.699646, acc.: 41.41%] [G loss: 0.687340]\n",
      "epoch:6 step:5770 [D loss: 0.705459, acc.: 47.66%] [G loss: 0.707360]\n",
      "epoch:6 step:5771 [D loss: 0.691709, acc.: 57.81%] [G loss: 0.719809]\n",
      "epoch:6 step:5772 [D loss: 0.695756, acc.: 45.31%] [G loss: 0.960071]\n",
      "epoch:6 step:5773 [D loss: 0.677657, acc.: 64.06%] [G loss: 0.751597]\n",
      "epoch:6 step:5774 [D loss: 0.676264, acc.: 61.72%] [G loss: 0.846865]\n",
      "epoch:6 step:5775 [D loss: 0.720609, acc.: 46.09%] [G loss: 0.786005]\n",
      "epoch:6 step:5776 [D loss: 0.674721, acc.: 58.59%] [G loss: 0.753826]\n",
      "epoch:6 step:5777 [D loss: 0.709799, acc.: 47.66%] [G loss: 0.750996]\n",
      "epoch:6 step:5778 [D loss: 0.707962, acc.: 50.78%] [G loss: 0.736171]\n",
      "epoch:6 step:5779 [D loss: 0.685297, acc.: 53.91%] [G loss: 0.738437]\n",
      "epoch:6 step:5780 [D loss: 0.720039, acc.: 51.56%] [G loss: 0.883170]\n",
      "epoch:6 step:5781 [D loss: 0.715770, acc.: 37.50%] [G loss: 1.183488]\n",
      "epoch:6 step:5782 [D loss: 0.693723, acc.: 49.22%] [G loss: 0.731601]\n",
      "epoch:6 step:5783 [D loss: 0.685884, acc.: 56.25%] [G loss: 0.726727]\n",
      "epoch:6 step:5784 [D loss: 0.697670, acc.: 49.22%] [G loss: 0.720072]\n",
      "epoch:6 step:5785 [D loss: 0.691691, acc.: 47.66%] [G loss: 0.710801]\n",
      "epoch:6 step:5786 [D loss: 0.685388, acc.: 51.56%] [G loss: 0.724517]\n",
      "epoch:6 step:5787 [D loss: 0.684235, acc.: 54.69%] [G loss: 0.737225]\n",
      "epoch:6 step:5788 [D loss: 0.685585, acc.: 50.78%] [G loss: 0.732276]\n",
      "epoch:6 step:5789 [D loss: 0.683076, acc.: 50.78%] [G loss: 0.767131]\n",
      "epoch:6 step:5790 [D loss: 0.678137, acc.: 55.47%] [G loss: 0.754112]\n",
      "epoch:6 step:5791 [D loss: 0.701722, acc.: 49.22%] [G loss: 0.765102]\n",
      "epoch:6 step:5792 [D loss: 0.697348, acc.: 56.25%] [G loss: 0.726366]\n",
      "epoch:6 step:5793 [D loss: 0.670239, acc.: 67.97%] [G loss: 0.736984]\n",
      "epoch:6 step:5794 [D loss: 0.680223, acc.: 57.81%] [G loss: 0.738209]\n",
      "epoch:6 step:5795 [D loss: 0.676559, acc.: 53.12%] [G loss: 0.723470]\n",
      "epoch:6 step:5796 [D loss: 0.681996, acc.: 53.91%] [G loss: 0.748206]\n",
      "epoch:6 step:5797 [D loss: 0.709889, acc.: 50.78%] [G loss: 0.723103]\n",
      "epoch:6 step:5798 [D loss: 0.684149, acc.: 60.94%] [G loss: 0.751899]\n",
      "epoch:6 step:5799 [D loss: 0.701231, acc.: 52.34%] [G loss: 0.715688]\n",
      "epoch:6 step:5800 [D loss: 0.696814, acc.: 50.78%] [G loss: 0.736080]\n",
      "##############\n",
      "[4.28900905 2.73078431 6.43419669 5.48700873 3.97133935 6.16919869\n",
      " 5.04064625 5.24394175 5.40728595 4.87408448]\n",
      "##########\n",
      "epoch:6 step:5801 [D loss: 0.697061, acc.: 45.31%] [G loss: 0.723731]\n",
      "epoch:6 step:5802 [D loss: 0.694248, acc.: 47.66%] [G loss: 0.735768]\n",
      "epoch:6 step:5803 [D loss: 0.680739, acc.: 56.25%] [G loss: 0.727501]\n",
      "epoch:6 step:5804 [D loss: 0.691811, acc.: 51.56%] [G loss: 0.719365]\n",
      "epoch:6 step:5805 [D loss: 0.688281, acc.: 51.56%] [G loss: 0.724611]\n",
      "epoch:6 step:5806 [D loss: 0.670147, acc.: 61.72%] [G loss: 0.739400]\n",
      "epoch:6 step:5807 [D loss: 0.682729, acc.: 58.59%] [G loss: 0.722743]\n",
      "epoch:6 step:5808 [D loss: 0.683169, acc.: 59.38%] [G loss: 0.730779]\n",
      "epoch:6 step:5809 [D loss: 0.651139, acc.: 58.59%] [G loss: 0.713437]\n",
      "epoch:6 step:5810 [D loss: 0.678417, acc.: 50.00%] [G loss: 0.730922]\n",
      "epoch:6 step:5811 [D loss: 0.689065, acc.: 50.78%] [G loss: 0.654575]\n",
      "epoch:6 step:5812 [D loss: 0.665874, acc.: 62.50%] [G loss: 0.746028]\n",
      "epoch:6 step:5813 [D loss: 0.650116, acc.: 64.84%] [G loss: 0.714744]\n",
      "epoch:6 step:5814 [D loss: 0.712272, acc.: 50.78%] [G loss: 0.757394]\n",
      "epoch:6 step:5815 [D loss: 0.704086, acc.: 48.44%] [G loss: 0.777290]\n",
      "epoch:6 step:5816 [D loss: 0.687749, acc.: 51.56%] [G loss: 0.746811]\n",
      "epoch:6 step:5817 [D loss: 0.681235, acc.: 53.91%] [G loss: 0.739980]\n",
      "epoch:6 step:5818 [D loss: 0.687299, acc.: 57.03%] [G loss: 0.755992]\n",
      "epoch:6 step:5819 [D loss: 0.701555, acc.: 54.69%] [G loss: 0.768266]\n",
      "epoch:6 step:5820 [D loss: 0.686170, acc.: 52.34%] [G loss: 0.745993]\n",
      "epoch:6 step:5821 [D loss: 0.702600, acc.: 48.44%] [G loss: 0.770198]\n",
      "epoch:6 step:5822 [D loss: 0.714732, acc.: 42.19%] [G loss: 0.808150]\n",
      "epoch:6 step:5823 [D loss: 0.682282, acc.: 50.78%] [G loss: 0.794468]\n",
      "epoch:6 step:5824 [D loss: 0.678657, acc.: 52.34%] [G loss: 0.840478]\n",
      "epoch:6 step:5825 [D loss: 0.720485, acc.: 50.78%] [G loss: 0.791887]\n",
      "epoch:6 step:5826 [D loss: 0.761912, acc.: 44.53%] [G loss: 0.746059]\n",
      "epoch:6 step:5827 [D loss: 0.683045, acc.: 57.03%] [G loss: 0.732944]\n",
      "epoch:6 step:5828 [D loss: 0.684835, acc.: 57.81%] [G loss: 0.705977]\n",
      "epoch:6 step:5829 [D loss: 0.545910, acc.: 68.75%] [G loss: 0.774356]\n",
      "epoch:6 step:5830 [D loss: 0.673021, acc.: 59.38%] [G loss: 0.741319]\n",
      "epoch:6 step:5831 [D loss: 0.660296, acc.: 62.50%] [G loss: 0.732850]\n",
      "epoch:6 step:5832 [D loss: 0.687526, acc.: 53.91%] [G loss: 0.758997]\n",
      "epoch:6 step:5833 [D loss: 0.688939, acc.: 50.78%] [G loss: 0.752584]\n",
      "epoch:6 step:5834 [D loss: 0.649764, acc.: 71.09%] [G loss: 0.718596]\n",
      "epoch:6 step:5835 [D loss: 0.679753, acc.: 57.03%] [G loss: 0.741931]\n",
      "epoch:6 step:5836 [D loss: 0.778409, acc.: 36.72%] [G loss: 0.762538]\n",
      "epoch:6 step:5837 [D loss: 0.684989, acc.: 53.12%] [G loss: 0.755409]\n",
      "epoch:6 step:5838 [D loss: 0.563026, acc.: 70.31%] [G loss: 0.745331]\n",
      "epoch:6 step:5839 [D loss: 0.680872, acc.: 57.03%] [G loss: 0.791150]\n",
      "epoch:6 step:5840 [D loss: 0.760425, acc.: 32.03%] [G loss: 0.736137]\n",
      "epoch:6 step:5841 [D loss: 0.689348, acc.: 55.47%] [G loss: 0.730917]\n",
      "epoch:6 step:5842 [D loss: 0.740047, acc.: 30.47%] [G loss: 0.750727]\n",
      "epoch:6 step:5843 [D loss: 0.716931, acc.: 39.06%] [G loss: 0.704874]\n",
      "epoch:6 step:5844 [D loss: 0.704266, acc.: 42.97%] [G loss: 0.769464]\n",
      "epoch:6 step:5845 [D loss: 0.688968, acc.: 45.31%] [G loss: 0.697831]\n",
      "epoch:6 step:5846 [D loss: 0.697030, acc.: 53.91%] [G loss: 0.755444]\n",
      "epoch:6 step:5847 [D loss: 0.674438, acc.: 54.69%] [G loss: 0.761780]\n",
      "epoch:6 step:5848 [D loss: 0.704237, acc.: 46.09%] [G loss: 0.747881]\n",
      "epoch:6 step:5849 [D loss: 0.743996, acc.: 21.88%] [G loss: 0.740882]\n",
      "epoch:6 step:5850 [D loss: 0.701672, acc.: 50.00%] [G loss: 0.765436]\n",
      "epoch:6 step:5851 [D loss: 0.682272, acc.: 53.12%] [G loss: 0.762308]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5852 [D loss: 0.676636, acc.: 53.91%] [G loss: 0.749687]\n",
      "epoch:6 step:5853 [D loss: 0.678377, acc.: 58.59%] [G loss: 0.790034]\n",
      "epoch:6 step:5854 [D loss: 0.665772, acc.: 60.16%] [G loss: 0.789601]\n",
      "epoch:6 step:5855 [D loss: 0.674612, acc.: 55.47%] [G loss: 0.800303]\n",
      "epoch:6 step:5856 [D loss: 0.678152, acc.: 48.44%] [G loss: 0.787054]\n",
      "epoch:6 step:5857 [D loss: 0.656574, acc.: 64.84%] [G loss: 0.783069]\n",
      "epoch:6 step:5858 [D loss: 0.693246, acc.: 50.78%] [G loss: 0.770932]\n",
      "epoch:6 step:5859 [D loss: 0.668188, acc.: 55.47%] [G loss: 0.803336]\n",
      "epoch:6 step:5860 [D loss: 0.703775, acc.: 47.66%] [G loss: 0.765797]\n",
      "epoch:6 step:5861 [D loss: 0.710013, acc.: 53.91%] [G loss: 0.795093]\n",
      "epoch:6 step:5862 [D loss: 0.710235, acc.: 46.88%] [G loss: 0.777330]\n",
      "epoch:6 step:5863 [D loss: 0.717561, acc.: 43.75%] [G loss: 0.774944]\n",
      "epoch:6 step:5864 [D loss: 0.699949, acc.: 53.91%] [G loss: 0.739490]\n",
      "epoch:6 step:5865 [D loss: 0.668406, acc.: 62.50%] [G loss: 0.777760]\n",
      "epoch:6 step:5866 [D loss: 0.683872, acc.: 57.81%] [G loss: 0.750536]\n",
      "epoch:6 step:5867 [D loss: 0.693489, acc.: 57.03%] [G loss: 0.755713]\n",
      "epoch:6 step:5868 [D loss: 0.691401, acc.: 53.12%] [G loss: 0.761835]\n",
      "epoch:6 step:5869 [D loss: 0.683452, acc.: 56.25%] [G loss: 0.748645]\n",
      "epoch:6 step:5870 [D loss: 0.674558, acc.: 55.47%] [G loss: 0.755988]\n",
      "epoch:6 step:5871 [D loss: 0.702168, acc.: 46.88%] [G loss: 0.753653]\n",
      "epoch:6 step:5872 [D loss: 0.700132, acc.: 53.91%] [G loss: 0.735913]\n",
      "epoch:6 step:5873 [D loss: 0.711373, acc.: 37.50%] [G loss: 0.737820]\n",
      "epoch:6 step:5874 [D loss: 0.696714, acc.: 51.56%] [G loss: 0.743246]\n",
      "epoch:6 step:5875 [D loss: 0.708068, acc.: 43.75%] [G loss: 0.727771]\n",
      "epoch:6 step:5876 [D loss: 0.702400, acc.: 47.66%] [G loss: 0.710896]\n",
      "epoch:6 step:5877 [D loss: 0.703957, acc.: 53.91%] [G loss: 0.727219]\n",
      "epoch:6 step:5878 [D loss: 0.700616, acc.: 45.31%] [G loss: 0.711181]\n",
      "epoch:6 step:5879 [D loss: 0.684223, acc.: 58.59%] [G loss: 0.710203]\n",
      "epoch:6 step:5880 [D loss: 0.693734, acc.: 50.78%] [G loss: 0.708325]\n",
      "epoch:6 step:5881 [D loss: 0.702951, acc.: 45.31%] [G loss: 0.720932]\n",
      "epoch:6 step:5882 [D loss: 0.696735, acc.: 50.00%] [G loss: 0.713902]\n",
      "epoch:6 step:5883 [D loss: 0.695131, acc.: 46.88%] [G loss: 0.717740]\n",
      "epoch:6 step:5884 [D loss: 0.678366, acc.: 58.59%] [G loss: 0.721529]\n",
      "epoch:6 step:5885 [D loss: 0.670341, acc.: 50.78%] [G loss: 0.731766]\n",
      "epoch:6 step:5886 [D loss: 0.696428, acc.: 46.88%] [G loss: 0.750327]\n",
      "epoch:6 step:5887 [D loss: 0.699916, acc.: 50.00%] [G loss: 0.700755]\n",
      "epoch:6 step:5888 [D loss: 0.698287, acc.: 48.44%] [G loss: 0.717200]\n",
      "epoch:6 step:5889 [D loss: 0.678169, acc.: 57.03%] [G loss: 0.731615]\n",
      "epoch:6 step:5890 [D loss: 0.688789, acc.: 57.03%] [G loss: 0.719543]\n",
      "epoch:6 step:5891 [D loss: 0.685860, acc.: 57.03%] [G loss: 0.735888]\n",
      "epoch:6 step:5892 [D loss: 0.698491, acc.: 47.66%] [G loss: 0.739432]\n",
      "epoch:6 step:5893 [D loss: 0.672532, acc.: 63.28%] [G loss: 0.762644]\n",
      "epoch:6 step:5894 [D loss: 0.729603, acc.: 42.19%] [G loss: 0.755913]\n",
      "epoch:6 step:5895 [D loss: 0.688093, acc.: 57.81%] [G loss: 0.774473]\n",
      "epoch:6 step:5896 [D loss: 0.674101, acc.: 60.16%] [G loss: 0.738486]\n",
      "epoch:6 step:5897 [D loss: 0.678282, acc.: 57.81%] [G loss: 0.762434]\n",
      "epoch:6 step:5898 [D loss: 0.683242, acc.: 56.25%] [G loss: 0.743245]\n",
      "epoch:6 step:5899 [D loss: 0.697087, acc.: 53.91%] [G loss: 0.725160]\n",
      "epoch:6 step:5900 [D loss: 0.692083, acc.: 50.78%] [G loss: 0.735502]\n",
      "epoch:6 step:5901 [D loss: 0.709749, acc.: 44.53%] [G loss: 0.728486]\n",
      "epoch:6 step:5902 [D loss: 0.693110, acc.: 52.34%] [G loss: 0.726878]\n",
      "epoch:6 step:5903 [D loss: 0.709441, acc.: 46.88%] [G loss: 0.741709]\n",
      "epoch:6 step:5904 [D loss: 0.696513, acc.: 45.31%] [G loss: 0.728094]\n",
      "epoch:6 step:5905 [D loss: 0.696564, acc.: 54.69%] [G loss: 0.739624]\n",
      "epoch:6 step:5906 [D loss: 0.717377, acc.: 43.75%] [G loss: 0.731699]\n",
      "epoch:6 step:5907 [D loss: 0.689743, acc.: 60.94%] [G loss: 0.724424]\n",
      "epoch:6 step:5908 [D loss: 0.685455, acc.: 60.94%] [G loss: 0.734187]\n",
      "epoch:6 step:5909 [D loss: 0.687900, acc.: 56.25%] [G loss: 0.745030]\n",
      "epoch:6 step:5910 [D loss: 0.686315, acc.: 54.69%] [G loss: 0.742575]\n",
      "epoch:6 step:5911 [D loss: 0.676707, acc.: 54.69%] [G loss: 0.770645]\n",
      "epoch:6 step:5912 [D loss: 0.669822, acc.: 63.28%] [G loss: 0.749568]\n",
      "epoch:6 step:5913 [D loss: 0.691724, acc.: 52.34%] [G loss: 0.717298]\n",
      "epoch:6 step:5914 [D loss: 0.684051, acc.: 56.25%] [G loss: 0.771628]\n",
      "epoch:6 step:5915 [D loss: 0.690472, acc.: 50.00%] [G loss: 0.742184]\n",
      "epoch:6 step:5916 [D loss: 0.684906, acc.: 50.78%] [G loss: 0.739440]\n",
      "epoch:6 step:5917 [D loss: 0.703771, acc.: 44.53%] [G loss: 0.728578]\n",
      "epoch:6 step:5918 [D loss: 0.700997, acc.: 43.75%] [G loss: 0.710625]\n",
      "epoch:6 step:5919 [D loss: 0.710332, acc.: 46.09%] [G loss: 0.701561]\n",
      "epoch:6 step:5920 [D loss: 0.700716, acc.: 50.78%] [G loss: 0.760188]\n",
      "epoch:6 step:5921 [D loss: 0.696103, acc.: 47.66%] [G loss: 0.739914]\n",
      "epoch:6 step:5922 [D loss: 0.680514, acc.: 59.38%] [G loss: 0.722204]\n",
      "epoch:6 step:5923 [D loss: 0.701538, acc.: 46.09%] [G loss: 0.729321]\n",
      "epoch:6 step:5924 [D loss: 0.696845, acc.: 53.91%] [G loss: 0.707883]\n",
      "epoch:6 step:5925 [D loss: 0.703907, acc.: 42.97%] [G loss: 0.733061]\n",
      "epoch:6 step:5926 [D loss: 0.704635, acc.: 48.44%] [G loss: 0.712137]\n",
      "epoch:6 step:5927 [D loss: 0.695207, acc.: 46.88%] [G loss: 0.717098]\n",
      "epoch:6 step:5928 [D loss: 0.689952, acc.: 51.56%] [G loss: 0.716026]\n",
      "epoch:6 step:5929 [D loss: 0.697285, acc.: 50.00%] [G loss: 0.731323]\n",
      "epoch:6 step:5930 [D loss: 0.693346, acc.: 53.91%] [G loss: 0.718183]\n",
      "epoch:6 step:5931 [D loss: 0.691908, acc.: 54.69%] [G loss: 0.717670]\n",
      "epoch:6 step:5932 [D loss: 0.686187, acc.: 52.34%] [G loss: 0.716426]\n",
      "epoch:6 step:5933 [D loss: 0.669999, acc.: 62.50%] [G loss: 0.718343]\n",
      "epoch:6 step:5934 [D loss: 0.675518, acc.: 61.72%] [G loss: 0.725982]\n",
      "epoch:6 step:5935 [D loss: 0.668276, acc.: 65.62%] [G loss: 0.705249]\n",
      "epoch:6 step:5936 [D loss: 0.647465, acc.: 66.41%] [G loss: 0.696197]\n",
      "epoch:6 step:5937 [D loss: 0.678521, acc.: 60.16%] [G loss: 0.703011]\n",
      "epoch:6 step:5938 [D loss: 0.715037, acc.: 45.31%] [G loss: 0.740185]\n",
      "epoch:6 step:5939 [D loss: 0.713362, acc.: 49.22%] [G loss: 0.733770]\n",
      "epoch:6 step:5940 [D loss: 0.693967, acc.: 53.12%] [G loss: 0.710398]\n",
      "epoch:6 step:5941 [D loss: 0.702081, acc.: 45.31%] [G loss: 0.698991]\n",
      "epoch:6 step:5942 [D loss: 0.721592, acc.: 38.28%] [G loss: 0.696573]\n",
      "epoch:6 step:5943 [D loss: 0.702245, acc.: 50.00%] [G loss: 0.704643]\n",
      "epoch:6 step:5944 [D loss: 0.694987, acc.: 52.34%] [G loss: 0.717764]\n",
      "epoch:6 step:5945 [D loss: 0.687325, acc.: 60.94%] [G loss: 0.718686]\n",
      "epoch:6 step:5946 [D loss: 0.673563, acc.: 65.62%] [G loss: 0.722228]\n",
      "epoch:6 step:5947 [D loss: 0.681191, acc.: 51.56%] [G loss: 0.737706]\n",
      "epoch:6 step:5948 [D loss: 0.710366, acc.: 46.88%] [G loss: 0.741920]\n",
      "epoch:6 step:5949 [D loss: 0.673892, acc.: 57.81%] [G loss: 0.757571]\n",
      "epoch:6 step:5950 [D loss: 0.664815, acc.: 64.06%] [G loss: 0.789023]\n",
      "epoch:6 step:5951 [D loss: 0.695078, acc.: 53.91%] [G loss: 0.738962]\n",
      "epoch:6 step:5952 [D loss: 0.678990, acc.: 55.47%] [G loss: 0.754695]\n",
      "epoch:6 step:5953 [D loss: 0.684704, acc.: 58.59%] [G loss: 0.754376]\n",
      "epoch:6 step:5954 [D loss: 0.695271, acc.: 53.91%] [G loss: 0.720556]\n",
      "epoch:6 step:5955 [D loss: 0.700791, acc.: 50.00%] [G loss: 0.742272]\n",
      "epoch:6 step:5956 [D loss: 0.667963, acc.: 59.38%] [G loss: 0.723155]\n",
      "epoch:6 step:5957 [D loss: 0.707449, acc.: 48.44%] [G loss: 0.713007]\n",
      "epoch:6 step:5958 [D loss: 0.679864, acc.: 60.16%] [G loss: 0.718256]\n",
      "epoch:6 step:5959 [D loss: 0.669207, acc.: 56.25%] [G loss: 0.769922]\n",
      "epoch:6 step:5960 [D loss: 0.672307, acc.: 58.59%] [G loss: 0.777631]\n",
      "epoch:6 step:5961 [D loss: 0.676295, acc.: 54.69%] [G loss: 0.776230]\n",
      "epoch:6 step:5962 [D loss: 0.714384, acc.: 45.31%] [G loss: 0.749345]\n",
      "epoch:6 step:5963 [D loss: 0.698008, acc.: 52.34%] [G loss: 0.746467]\n",
      "epoch:6 step:5964 [D loss: 0.666446, acc.: 64.06%] [G loss: 0.726981]\n",
      "epoch:6 step:5965 [D loss: 0.671464, acc.: 65.62%] [G loss: 0.759915]\n",
      "epoch:6 step:5966 [D loss: 0.670432, acc.: 60.16%] [G loss: 0.779757]\n",
      "epoch:6 step:5967 [D loss: 0.703560, acc.: 47.66%] [G loss: 0.773546]\n",
      "epoch:6 step:5968 [D loss: 0.694810, acc.: 52.34%] [G loss: 0.777587]\n",
      "epoch:6 step:5969 [D loss: 0.672754, acc.: 58.59%] [G loss: 0.733528]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5970 [D loss: 0.706121, acc.: 50.00%] [G loss: 0.754347]\n",
      "epoch:6 step:5971 [D loss: 0.746899, acc.: 36.72%] [G loss: 0.713846]\n",
      "epoch:6 step:5972 [D loss: 0.710629, acc.: 42.97%] [G loss: 0.748684]\n",
      "epoch:6 step:5973 [D loss: 0.705486, acc.: 45.31%] [G loss: 0.750354]\n",
      "epoch:6 step:5974 [D loss: 0.678548, acc.: 56.25%] [G loss: 0.775361]\n",
      "epoch:6 step:5975 [D loss: 0.678238, acc.: 63.28%] [G loss: 0.752975]\n",
      "epoch:6 step:5976 [D loss: 0.662066, acc.: 66.41%] [G loss: 0.747666]\n",
      "epoch:6 step:5977 [D loss: 0.660314, acc.: 63.28%] [G loss: 0.761885]\n",
      "epoch:6 step:5978 [D loss: 0.697179, acc.: 54.69%] [G loss: 0.738431]\n",
      "epoch:6 step:5979 [D loss: 0.693825, acc.: 51.56%] [G loss: 0.730617]\n",
      "epoch:6 step:5980 [D loss: 0.683853, acc.: 53.12%] [G loss: 0.719799]\n",
      "epoch:6 step:5981 [D loss: 0.686843, acc.: 53.12%] [G loss: 0.752194]\n",
      "epoch:6 step:5982 [D loss: 0.682438, acc.: 51.56%] [G loss: 0.750148]\n",
      "epoch:6 step:5983 [D loss: 0.684554, acc.: 51.56%] [G loss: 0.791952]\n",
      "epoch:6 step:5984 [D loss: 0.682002, acc.: 60.16%] [G loss: 0.782954]\n",
      "epoch:6 step:5985 [D loss: 0.700319, acc.: 50.00%] [G loss: 0.779517]\n",
      "epoch:6 step:5986 [D loss: 0.657215, acc.: 59.38%] [G loss: 0.808308]\n",
      "epoch:6 step:5987 [D loss: 0.664603, acc.: 56.25%] [G loss: 0.800026]\n",
      "epoch:6 step:5988 [D loss: 0.699227, acc.: 48.44%] [G loss: 0.776406]\n",
      "epoch:6 step:5989 [D loss: 0.735346, acc.: 45.31%] [G loss: 0.725132]\n",
      "epoch:6 step:5990 [D loss: 0.702466, acc.: 53.12%] [G loss: 0.734472]\n",
      "epoch:6 step:5991 [D loss: 0.726716, acc.: 39.84%] [G loss: 0.709804]\n",
      "epoch:6 step:5992 [D loss: 0.730039, acc.: 34.38%] [G loss: 0.707485]\n",
      "epoch:6 step:5993 [D loss: 0.686187, acc.: 50.00%] [G loss: 0.737262]\n",
      "epoch:6 step:5994 [D loss: 0.687828, acc.: 55.47%] [G loss: 0.736459]\n",
      "epoch:6 step:5995 [D loss: 0.708768, acc.: 49.22%] [G loss: 0.718179]\n",
      "epoch:6 step:5996 [D loss: 0.677010, acc.: 56.25%] [G loss: 0.741695]\n",
      "epoch:6 step:5997 [D loss: 0.689573, acc.: 49.22%] [G loss: 0.755053]\n",
      "epoch:6 step:5998 [D loss: 0.940588, acc.: 43.75%] [G loss: 0.779808]\n",
      "epoch:6 step:5999 [D loss: 0.705060, acc.: 56.25%] [G loss: 0.775063]\n",
      "epoch:6 step:6000 [D loss: 0.702234, acc.: 55.47%] [G loss: 0.767960]\n",
      "##############\n",
      "[3.86952244 2.19069841 6.12327881 5.21468693 3.82444038 5.75718165\n",
      " 4.91576153 4.85074975 5.17605113 4.57068105]\n",
      "##########\n",
      "epoch:6 step:6001 [D loss: 0.687392, acc.: 53.12%] [G loss: 0.804568]\n",
      "epoch:6 step:6002 [D loss: 0.691542, acc.: 51.56%] [G loss: 0.753717]\n",
      "epoch:6 step:6003 [D loss: 0.699646, acc.: 49.22%] [G loss: 0.732564]\n",
      "epoch:6 step:6004 [D loss: 0.707964, acc.: 41.41%] [G loss: 0.744270]\n",
      "epoch:6 step:6005 [D loss: 0.695387, acc.: 45.31%] [G loss: 0.731056]\n",
      "epoch:6 step:6006 [D loss: 0.692124, acc.: 54.69%] [G loss: 0.697240]\n",
      "epoch:6 step:6007 [D loss: 0.696357, acc.: 46.88%] [G loss: 0.705820]\n",
      "epoch:6 step:6008 [D loss: 0.697756, acc.: 51.56%] [G loss: 0.729639]\n",
      "epoch:6 step:6009 [D loss: 0.686116, acc.: 50.00%] [G loss: 0.741995]\n",
      "epoch:6 step:6010 [D loss: 0.679279, acc.: 50.78%] [G loss: 0.753866]\n",
      "epoch:6 step:6011 [D loss: 0.703061, acc.: 56.25%] [G loss: 0.752315]\n",
      "epoch:6 step:6012 [D loss: 0.704601, acc.: 46.09%] [G loss: 0.743815]\n",
      "epoch:6 step:6013 [D loss: 0.702046, acc.: 48.44%] [G loss: 0.709227]\n",
      "epoch:6 step:6014 [D loss: 0.698524, acc.: 50.00%] [G loss: 0.728289]\n",
      "epoch:6 step:6015 [D loss: 0.698590, acc.: 53.91%] [G loss: 0.725520]\n",
      "epoch:6 step:6016 [D loss: 0.685520, acc.: 49.22%] [G loss: 0.744352]\n",
      "epoch:6 step:6017 [D loss: 0.684848, acc.: 53.12%] [G loss: 0.734188]\n",
      "epoch:6 step:6018 [D loss: 0.700077, acc.: 52.34%] [G loss: 0.750887]\n",
      "epoch:6 step:6019 [D loss: 0.680702, acc.: 58.59%] [G loss: 0.712885]\n",
      "epoch:6 step:6020 [D loss: 0.669324, acc.: 69.53%] [G loss: 0.703880]\n",
      "epoch:6 step:6021 [D loss: 0.669015, acc.: 65.62%] [G loss: 0.768955]\n",
      "epoch:6 step:6022 [D loss: 0.687758, acc.: 57.81%] [G loss: 0.741272]\n",
      "epoch:6 step:6023 [D loss: 0.698991, acc.: 53.12%] [G loss: 0.757174]\n",
      "epoch:6 step:6024 [D loss: 0.696025, acc.: 47.66%] [G loss: 0.742090]\n",
      "epoch:6 step:6025 [D loss: 0.702408, acc.: 50.00%] [G loss: 0.693768]\n",
      "epoch:6 step:6026 [D loss: 0.707045, acc.: 36.72%] [G loss: 0.698048]\n",
      "epoch:6 step:6027 [D loss: 0.688518, acc.: 53.12%] [G loss: 0.715101]\n",
      "epoch:6 step:6028 [D loss: 0.676602, acc.: 60.16%] [G loss: 0.724753]\n",
      "epoch:6 step:6029 [D loss: 0.679850, acc.: 57.03%] [G loss: 0.736720]\n",
      "epoch:6 step:6030 [D loss: 0.671573, acc.: 62.50%] [G loss: 0.722471]\n",
      "epoch:6 step:6031 [D loss: 0.670559, acc.: 62.50%] [G loss: 0.731106]\n",
      "epoch:6 step:6032 [D loss: 0.707837, acc.: 51.56%] [G loss: 0.760899]\n",
      "epoch:6 step:6033 [D loss: 0.709870, acc.: 44.53%] [G loss: 0.717145]\n",
      "epoch:6 step:6034 [D loss: 0.672589, acc.: 60.94%] [G loss: 0.741482]\n",
      "epoch:6 step:6035 [D loss: 0.678016, acc.: 60.16%] [G loss: 0.735098]\n",
      "epoch:6 step:6036 [D loss: 0.675660, acc.: 56.25%] [G loss: 0.730223]\n",
      "epoch:6 step:6037 [D loss: 0.687248, acc.: 57.03%] [G loss: 0.739740]\n",
      "epoch:6 step:6038 [D loss: 0.675650, acc.: 57.81%] [G loss: 0.691121]\n",
      "epoch:6 step:6039 [D loss: 0.699398, acc.: 50.00%] [G loss: 0.729717]\n",
      "epoch:6 step:6040 [D loss: 0.716651, acc.: 42.19%] [G loss: 0.706107]\n",
      "epoch:6 step:6041 [D loss: 0.719294, acc.: 42.97%] [G loss: 0.699042]\n",
      "epoch:6 step:6042 [D loss: 0.699156, acc.: 52.34%] [G loss: 0.706800]\n",
      "epoch:6 step:6043 [D loss: 0.696967, acc.: 50.00%] [G loss: 0.714641]\n",
      "epoch:6 step:6044 [D loss: 0.678890, acc.: 52.34%] [G loss: 0.819041]\n",
      "epoch:6 step:6045 [D loss: 0.678269, acc.: 57.03%] [G loss: 0.761145]\n",
      "epoch:6 step:6046 [D loss: 0.680335, acc.: 57.03%] [G loss: 0.788605]\n",
      "epoch:6 step:6047 [D loss: 0.677316, acc.: 64.84%] [G loss: 0.759821]\n",
      "epoch:6 step:6048 [D loss: 0.689591, acc.: 61.72%] [G loss: 0.764494]\n",
      "epoch:6 step:6049 [D loss: 0.698609, acc.: 53.91%] [G loss: 0.750235]\n",
      "epoch:6 step:6050 [D loss: 0.689108, acc.: 52.34%] [G loss: 0.722918]\n",
      "epoch:6 step:6051 [D loss: 0.701794, acc.: 47.66%] [G loss: 0.731163]\n",
      "epoch:6 step:6052 [D loss: 0.694402, acc.: 53.12%] [G loss: 0.741671]\n",
      "epoch:6 step:6053 [D loss: 0.713975, acc.: 43.75%] [G loss: 0.693571]\n",
      "epoch:6 step:6054 [D loss: 0.729422, acc.: 41.41%] [G loss: 0.756142]\n",
      "epoch:6 step:6055 [D loss: 0.697307, acc.: 54.69%] [G loss: 0.741497]\n",
      "epoch:6 step:6056 [D loss: 0.707861, acc.: 43.75%] [G loss: 0.729514]\n",
      "epoch:6 step:6057 [D loss: 0.682077, acc.: 61.72%] [G loss: 0.720302]\n",
      "epoch:6 step:6058 [D loss: 0.665498, acc.: 64.06%] [G loss: 0.760671]\n",
      "epoch:6 step:6059 [D loss: 0.696929, acc.: 50.78%] [G loss: 0.726592]\n",
      "epoch:6 step:6060 [D loss: 0.690574, acc.: 59.38%] [G loss: 0.735769]\n",
      "epoch:6 step:6061 [D loss: 0.702791, acc.: 50.00%] [G loss: 0.727956]\n",
      "epoch:6 step:6062 [D loss: 0.679839, acc.: 58.59%] [G loss: 0.745246]\n",
      "epoch:6 step:6063 [D loss: 0.693812, acc.: 53.12%] [G loss: 0.700657]\n",
      "epoch:6 step:6064 [D loss: 0.701268, acc.: 50.78%] [G loss: 0.734835]\n",
      "epoch:6 step:6065 [D loss: 0.684282, acc.: 53.12%] [G loss: 0.741995]\n",
      "epoch:6 step:6066 [D loss: 0.693051, acc.: 50.00%] [G loss: 0.749424]\n",
      "epoch:6 step:6067 [D loss: 0.662259, acc.: 65.62%] [G loss: 0.749733]\n",
      "epoch:6 step:6068 [D loss: 0.675700, acc.: 63.28%] [G loss: 0.728858]\n",
      "epoch:6 step:6069 [D loss: 0.676635, acc.: 53.12%] [G loss: 0.761078]\n",
      "epoch:6 step:6070 [D loss: 0.687938, acc.: 50.00%] [G loss: 0.734408]\n",
      "epoch:6 step:6071 [D loss: 0.681808, acc.: 53.12%] [G loss: 0.771169]\n",
      "epoch:6 step:6072 [D loss: 0.675864, acc.: 56.25%] [G loss: 0.742437]\n",
      "epoch:6 step:6073 [D loss: 0.651447, acc.: 61.72%] [G loss: 0.741266]\n",
      "epoch:6 step:6074 [D loss: 0.650507, acc.: 58.59%] [G loss: 0.744922]\n",
      "epoch:6 step:6075 [D loss: 0.673370, acc.: 53.12%] [G loss: 0.704900]\n",
      "epoch:6 step:6076 [D loss: 0.682704, acc.: 55.47%] [G loss: 0.762010]\n",
      "epoch:6 step:6077 [D loss: 0.673506, acc.: 57.03%] [G loss: 0.736769]\n",
      "epoch:6 step:6078 [D loss: 0.631489, acc.: 53.91%] [G loss: 0.773363]\n",
      "epoch:6 step:6079 [D loss: 0.666104, acc.: 57.81%] [G loss: 0.751638]\n",
      "epoch:6 step:6080 [D loss: 0.700232, acc.: 56.25%] [G loss: 0.740926]\n",
      "epoch:6 step:6081 [D loss: 0.631488, acc.: 62.50%] [G loss: 0.776977]\n",
      "epoch:6 step:6082 [D loss: 0.667343, acc.: 60.16%] [G loss: 0.742504]\n",
      "epoch:6 step:6083 [D loss: 0.698978, acc.: 46.88%] [G loss: 0.731121]\n",
      "epoch:6 step:6084 [D loss: 0.739674, acc.: 40.62%] [G loss: 0.783649]\n",
      "epoch:6 step:6085 [D loss: 0.698055, acc.: 53.12%] [G loss: 0.761913]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6086 [D loss: 0.741841, acc.: 34.38%] [G loss: 0.769186]\n",
      "epoch:6 step:6087 [D loss: 0.681918, acc.: 55.47%] [G loss: 0.758963]\n",
      "epoch:6 step:6088 [D loss: 0.685946, acc.: 60.94%] [G loss: 0.742435]\n",
      "epoch:6 step:6089 [D loss: 0.647740, acc.: 65.62%] [G loss: 0.639137]\n",
      "epoch:6 step:6090 [D loss: 0.695315, acc.: 55.47%] [G loss: 0.798068]\n",
      "epoch:6 step:6091 [D loss: 0.697123, acc.: 49.22%] [G loss: 0.810052]\n",
      "epoch:6 step:6092 [D loss: 0.654099, acc.: 60.16%] [G loss: 0.606436]\n",
      "epoch:6 step:6093 [D loss: 0.654255, acc.: 68.75%] [G loss: 0.729028]\n",
      "epoch:6 step:6094 [D loss: 0.753072, acc.: 35.94%] [G loss: 0.683579]\n",
      "epoch:6 step:6095 [D loss: 0.744129, acc.: 25.78%] [G loss: 0.734899]\n",
      "epoch:6 step:6096 [D loss: 0.704384, acc.: 46.88%] [G loss: 0.772506]\n",
      "epoch:6 step:6097 [D loss: 0.688414, acc.: 46.88%] [G loss: 0.841433]\n",
      "epoch:6 step:6098 [D loss: 0.662704, acc.: 62.50%] [G loss: 0.918694]\n",
      "epoch:6 step:6099 [D loss: 0.687042, acc.: 51.56%] [G loss: 0.945462]\n",
      "epoch:6 step:6100 [D loss: 0.659818, acc.: 57.81%] [G loss: 0.970618]\n",
      "epoch:6 step:6101 [D loss: 0.697964, acc.: 53.12%] [G loss: 0.904442]\n",
      "epoch:6 step:6102 [D loss: 0.724983, acc.: 47.66%] [G loss: 0.809197]\n",
      "epoch:6 step:6103 [D loss: 0.695957, acc.: 49.22%] [G loss: 0.796556]\n",
      "epoch:6 step:6104 [D loss: 0.706265, acc.: 46.88%] [G loss: 0.788188]\n",
      "epoch:6 step:6105 [D loss: 0.688116, acc.: 55.47%] [G loss: 0.771943]\n",
      "epoch:6 step:6106 [D loss: 0.674918, acc.: 58.59%] [G loss: 0.760218]\n",
      "epoch:6 step:6107 [D loss: 0.671013, acc.: 64.84%] [G loss: 0.759786]\n",
      "epoch:6 step:6108 [D loss: 0.675251, acc.: 55.47%] [G loss: 0.782992]\n",
      "epoch:6 step:6109 [D loss: 0.684886, acc.: 57.03%] [G loss: 0.756852]\n",
      "epoch:6 step:6110 [D loss: 0.665533, acc.: 64.06%] [G loss: 0.811897]\n",
      "epoch:6 step:6111 [D loss: 0.701696, acc.: 52.34%] [G loss: 0.736894]\n",
      "epoch:6 step:6112 [D loss: 0.699713, acc.: 42.97%] [G loss: 0.781743]\n",
      "epoch:6 step:6113 [D loss: 0.690481, acc.: 55.47%] [G loss: 0.759106]\n",
      "epoch:6 step:6114 [D loss: 0.727391, acc.: 42.19%] [G loss: 0.763159]\n",
      "epoch:6 step:6115 [D loss: 0.688067, acc.: 54.69%] [G loss: 0.721178]\n",
      "epoch:6 step:6116 [D loss: 0.696887, acc.: 50.78%] [G loss: 0.742057]\n",
      "epoch:6 step:6117 [D loss: 0.653363, acc.: 60.94%] [G loss: 0.762656]\n",
      "epoch:6 step:6118 [D loss: 0.691503, acc.: 51.56%] [G loss: 0.753134]\n",
      "epoch:6 step:6119 [D loss: 0.665364, acc.: 63.28%] [G loss: 0.768095]\n",
      "epoch:6 step:6120 [D loss: 0.694911, acc.: 52.34%] [G loss: 0.774525]\n",
      "epoch:6 step:6121 [D loss: 0.659163, acc.: 61.72%] [G loss: 0.819968]\n",
      "epoch:6 step:6122 [D loss: 0.727093, acc.: 47.66%] [G loss: 0.840717]\n",
      "epoch:6 step:6123 [D loss: 0.724680, acc.: 48.44%] [G loss: 0.762028]\n",
      "epoch:6 step:6124 [D loss: 0.702418, acc.: 43.75%] [G loss: 0.766438]\n",
      "epoch:6 step:6125 [D loss: 0.735580, acc.: 42.97%] [G loss: 0.732238]\n",
      "epoch:6 step:6126 [D loss: 0.680964, acc.: 52.34%] [G loss: 0.747840]\n",
      "epoch:6 step:6127 [D loss: 0.691707, acc.: 54.69%] [G loss: 0.729919]\n",
      "epoch:6 step:6128 [D loss: 0.686041, acc.: 57.81%] [G loss: 0.743179]\n",
      "epoch:6 step:6129 [D loss: 0.672288, acc.: 60.16%] [G loss: 0.758453]\n",
      "epoch:6 step:6130 [D loss: 0.680507, acc.: 59.38%] [G loss: 0.740007]\n",
      "epoch:6 step:6131 [D loss: 0.704354, acc.: 45.31%] [G loss: 0.749856]\n",
      "epoch:6 step:6132 [D loss: 0.716697, acc.: 41.41%] [G loss: 0.718723]\n",
      "epoch:6 step:6133 [D loss: 0.697259, acc.: 48.44%] [G loss: 0.726491]\n",
      "epoch:6 step:6134 [D loss: 0.691818, acc.: 46.88%] [G loss: 0.743889]\n",
      "epoch:6 step:6135 [D loss: 0.685245, acc.: 57.03%] [G loss: 0.720847]\n",
      "epoch:6 step:6136 [D loss: 0.677997, acc.: 59.38%] [G loss: 0.718968]\n",
      "epoch:6 step:6137 [D loss: 0.672068, acc.: 60.16%] [G loss: 0.734493]\n",
      "epoch:6 step:6138 [D loss: 0.681700, acc.: 62.50%] [G loss: 0.714022]\n",
      "epoch:6 step:6139 [D loss: 0.722666, acc.: 42.97%] [G loss: 0.701697]\n",
      "epoch:6 step:6140 [D loss: 0.683043, acc.: 49.22%] [G loss: 0.720774]\n",
      "epoch:6 step:6141 [D loss: 0.703090, acc.: 50.00%] [G loss: 0.707369]\n",
      "epoch:6 step:6142 [D loss: 0.673366, acc.: 60.16%] [G loss: 0.728415]\n",
      "epoch:6 step:6143 [D loss: 0.684288, acc.: 58.59%] [G loss: 0.699727]\n",
      "epoch:6 step:6144 [D loss: 0.669991, acc.: 62.50%] [G loss: 0.723591]\n",
      "epoch:6 step:6145 [D loss: 0.673759, acc.: 61.72%] [G loss: 0.701141]\n",
      "epoch:6 step:6146 [D loss: 0.672387, acc.: 62.50%] [G loss: 0.729564]\n",
      "epoch:6 step:6147 [D loss: 0.671824, acc.: 57.81%] [G loss: 0.707958]\n",
      "epoch:6 step:6148 [D loss: 0.691605, acc.: 50.78%] [G loss: 0.701130]\n",
      "epoch:6 step:6149 [D loss: 0.702287, acc.: 52.34%] [G loss: 0.684907]\n",
      "epoch:6 step:6150 [D loss: 0.738446, acc.: 35.94%] [G loss: 0.671439]\n",
      "epoch:6 step:6151 [D loss: 0.729617, acc.: 39.06%] [G loss: 0.696580]\n",
      "epoch:6 step:6152 [D loss: 0.703086, acc.: 42.97%] [G loss: 0.701721]\n",
      "epoch:6 step:6153 [D loss: 0.709641, acc.: 46.88%] [G loss: 0.708980]\n",
      "epoch:6 step:6154 [D loss: 0.691975, acc.: 52.34%] [G loss: 0.746330]\n",
      "epoch:6 step:6155 [D loss: 0.690164, acc.: 57.03%] [G loss: 0.731496]\n",
      "epoch:6 step:6156 [D loss: 0.695420, acc.: 53.12%] [G loss: 0.755007]\n",
      "epoch:6 step:6157 [D loss: 0.685812, acc.: 51.56%] [G loss: 0.761221]\n",
      "epoch:6 step:6158 [D loss: 0.687120, acc.: 57.81%] [G loss: 0.770092]\n",
      "epoch:6 step:6159 [D loss: 0.675606, acc.: 59.38%] [G loss: 0.766696]\n",
      "epoch:6 step:6160 [D loss: 0.674277, acc.: 59.38%] [G loss: 0.801794]\n",
      "epoch:6 step:6161 [D loss: 0.694944, acc.: 53.12%] [G loss: 0.756405]\n",
      "epoch:6 step:6162 [D loss: 0.668369, acc.: 59.38%] [G loss: 0.747520]\n",
      "epoch:6 step:6163 [D loss: 0.656014, acc.: 67.19%] [G loss: 0.762919]\n",
      "epoch:6 step:6164 [D loss: 0.705763, acc.: 48.44%] [G loss: 0.762456]\n",
      "epoch:6 step:6165 [D loss: 0.598500, acc.: 61.72%] [G loss: 0.784476]\n",
      "epoch:6 step:6166 [D loss: 0.712130, acc.: 52.34%] [G loss: 0.681854]\n",
      "epoch:6 step:6167 [D loss: 0.691378, acc.: 54.69%] [G loss: 0.729851]\n",
      "epoch:6 step:6168 [D loss: 0.708233, acc.: 47.66%] [G loss: 0.713478]\n",
      "epoch:6 step:6169 [D loss: 0.721098, acc.: 36.72%] [G loss: 0.730504]\n",
      "epoch:6 step:6170 [D loss: 0.693215, acc.: 50.00%] [G loss: 0.741938]\n",
      "epoch:6 step:6171 [D loss: 0.689350, acc.: 54.69%] [G loss: 0.742341]\n",
      "epoch:6 step:6172 [D loss: 0.447079, acc.: 75.00%] [G loss: 0.762803]\n",
      "epoch:6 step:6173 [D loss: 0.740396, acc.: 42.19%] [G loss: 0.722259]\n",
      "epoch:6 step:6174 [D loss: 0.665066, acc.: 63.28%] [G loss: 0.775435]\n",
      "epoch:6 step:6175 [D loss: 0.696537, acc.: 53.91%] [G loss: 0.756980]\n",
      "epoch:6 step:6176 [D loss: 0.658714, acc.: 68.75%] [G loss: 0.752701]\n",
      "epoch:6 step:6177 [D loss: 0.681969, acc.: 63.28%] [G loss: 0.800735]\n",
      "epoch:6 step:6178 [D loss: 0.663275, acc.: 64.84%] [G loss: 0.759109]\n",
      "epoch:6 step:6179 [D loss: 0.672048, acc.: 51.56%] [G loss: 0.785956]\n",
      "epoch:6 step:6180 [D loss: 0.652073, acc.: 60.16%] [G loss: 0.747570]\n",
      "epoch:6 step:6181 [D loss: 0.706118, acc.: 47.66%] [G loss: 0.783455]\n",
      "epoch:6 step:6182 [D loss: 0.724867, acc.: 42.97%] [G loss: 0.729901]\n",
      "epoch:6 step:6183 [D loss: 0.701326, acc.: 50.78%] [G loss: 0.749894]\n",
      "epoch:6 step:6184 [D loss: 0.692281, acc.: 53.91%] [G loss: 0.779289]\n",
      "epoch:6 step:6185 [D loss: 0.674918, acc.: 60.94%] [G loss: 0.732089]\n",
      "epoch:6 step:6186 [D loss: 0.692074, acc.: 56.25%] [G loss: 0.737355]\n",
      "epoch:6 step:6187 [D loss: 0.695467, acc.: 52.34%] [G loss: 0.620367]\n",
      "epoch:6 step:6188 [D loss: 0.755744, acc.: 34.38%] [G loss: 0.651961]\n",
      "epoch:6 step:6189 [D loss: 0.677765, acc.: 51.56%] [G loss: 0.997160]\n",
      "epoch:6 step:6190 [D loss: 0.646027, acc.: 60.94%] [G loss: 0.974014]\n",
      "epoch:6 step:6191 [D loss: 0.666918, acc.: 56.25%] [G loss: 1.023219]\n",
      "epoch:6 step:6192 [D loss: 0.648948, acc.: 64.84%] [G loss: 0.932428]\n",
      "epoch:6 step:6193 [D loss: 0.669470, acc.: 54.69%] [G loss: 0.877263]\n",
      "epoch:6 step:6194 [D loss: 0.699869, acc.: 56.25%] [G loss: 0.745402]\n",
      "epoch:6 step:6195 [D loss: 0.671434, acc.: 63.28%] [G loss: 0.762118]\n",
      "epoch:6 step:6196 [D loss: 0.640128, acc.: 61.72%] [G loss: 0.752299]\n",
      "epoch:6 step:6197 [D loss: 0.673167, acc.: 60.16%] [G loss: 0.734417]\n",
      "epoch:6 step:6198 [D loss: 0.734876, acc.: 37.50%] [G loss: 0.686532]\n",
      "epoch:6 step:6199 [D loss: 0.722108, acc.: 48.44%] [G loss: 0.686351]\n",
      "epoch:6 step:6200 [D loss: 0.686330, acc.: 50.00%] [G loss: 0.685105]\n",
      "##############\n",
      "[4.80202684 1.73842087 7.03715601 5.65987626 3.84281023 6.39980741\n",
      " 5.564339   4.53702875 6.46502675 4.87981102]\n",
      "##########\n",
      "epoch:6 step:6201 [D loss: 0.681863, acc.: 53.91%] [G loss: 0.700767]\n",
      "epoch:6 step:6202 [D loss: 0.701541, acc.: 53.12%] [G loss: 0.734919]\n",
      "epoch:6 step:6203 [D loss: 0.667073, acc.: 57.81%] [G loss: 0.749344]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6204 [D loss: 0.685555, acc.: 55.47%] [G loss: 0.814684]\n",
      "epoch:6 step:6205 [D loss: 0.687048, acc.: 53.12%] [G loss: 0.829615]\n",
      "epoch:6 step:6206 [D loss: 0.691603, acc.: 51.56%] [G loss: 0.730044]\n",
      "epoch:6 step:6207 [D loss: 0.700635, acc.: 50.00%] [G loss: 0.749171]\n",
      "epoch:6 step:6208 [D loss: 0.681017, acc.: 59.38%] [G loss: 0.712309]\n",
      "epoch:6 step:6209 [D loss: 0.684384, acc.: 56.25%] [G loss: 0.753960]\n",
      "epoch:6 step:6210 [D loss: 0.675260, acc.: 55.47%] [G loss: 0.728861]\n",
      "epoch:6 step:6211 [D loss: 0.646253, acc.: 66.41%] [G loss: 0.767630]\n",
      "epoch:6 step:6212 [D loss: 0.715538, acc.: 45.31%] [G loss: 0.749482]\n",
      "epoch:6 step:6213 [D loss: 0.719217, acc.: 47.66%] [G loss: 0.777186]\n",
      "epoch:6 step:6214 [D loss: 0.693488, acc.: 54.69%] [G loss: 0.750093]\n",
      "epoch:6 step:6215 [D loss: 0.697758, acc.: 52.34%] [G loss: 0.774370]\n",
      "epoch:6 step:6216 [D loss: 0.710559, acc.: 44.53%] [G loss: 0.763961]\n",
      "epoch:6 step:6217 [D loss: 0.691210, acc.: 54.69%] [G loss: 0.755388]\n",
      "epoch:6 step:6218 [D loss: 0.683956, acc.: 50.00%] [G loss: 0.731472]\n",
      "epoch:6 step:6219 [D loss: 0.711425, acc.: 52.34%] [G loss: 0.725913]\n",
      "epoch:6 step:6220 [D loss: 0.681073, acc.: 58.59%] [G loss: 0.776141]\n",
      "epoch:6 step:6221 [D loss: 0.698755, acc.: 50.78%] [G loss: 0.747632]\n",
      "epoch:6 step:6222 [D loss: 0.694733, acc.: 48.44%] [G loss: 0.712224]\n",
      "epoch:6 step:6223 [D loss: 0.696760, acc.: 52.34%] [G loss: 0.755901]\n",
      "epoch:6 step:6224 [D loss: 0.698219, acc.: 46.09%] [G loss: 0.741076]\n",
      "epoch:6 step:6225 [D loss: 0.704512, acc.: 46.88%] [G loss: 0.727526]\n",
      "epoch:6 step:6226 [D loss: 0.546839, acc.: 60.94%] [G loss: 0.771358]\n",
      "epoch:6 step:6227 [D loss: 0.690416, acc.: 56.25%] [G loss: 0.777843]\n",
      "epoch:6 step:6228 [D loss: 0.703594, acc.: 51.56%] [G loss: 0.741330]\n",
      "epoch:6 step:6229 [D loss: 0.684308, acc.: 53.91%] [G loss: 0.730947]\n",
      "epoch:6 step:6230 [D loss: 0.728200, acc.: 40.62%] [G loss: 0.688411]\n",
      "epoch:6 step:6231 [D loss: 0.689363, acc.: 57.03%] [G loss: 0.743368]\n",
      "epoch:6 step:6232 [D loss: 0.694303, acc.: 51.56%] [G loss: 0.777261]\n",
      "epoch:6 step:6233 [D loss: 0.695607, acc.: 56.25%] [G loss: 0.681641]\n",
      "epoch:6 step:6234 [D loss: 0.684187, acc.: 57.03%] [G loss: 0.727117]\n",
      "epoch:6 step:6235 [D loss: 0.693866, acc.: 52.34%] [G loss: 0.752741]\n",
      "epoch:6 step:6236 [D loss: 0.697207, acc.: 51.56%] [G loss: 0.763891]\n",
      "epoch:6 step:6237 [D loss: 0.705263, acc.: 53.12%] [G loss: 0.745894]\n",
      "epoch:6 step:6238 [D loss: 0.696959, acc.: 48.44%] [G loss: 0.772469]\n",
      "epoch:6 step:6239 [D loss: 0.680018, acc.: 56.25%] [G loss: 0.735633]\n",
      "epoch:6 step:6240 [D loss: 0.689281, acc.: 49.22%] [G loss: 0.434605]\n",
      "epoch:6 step:6241 [D loss: 1.268736, acc.: 26.56%] [G loss: 0.826635]\n",
      "epoch:6 step:6242 [D loss: 0.671759, acc.: 63.28%] [G loss: 0.839164]\n",
      "epoch:6 step:6243 [D loss: 0.695468, acc.: 47.66%] [G loss: 0.845418]\n",
      "epoch:6 step:6244 [D loss: 0.700933, acc.: 50.00%] [G loss: 0.787546]\n",
      "epoch:6 step:6245 [D loss: 0.712351, acc.: 44.53%] [G loss: 0.783386]\n",
      "epoch:6 step:6246 [D loss: 0.690897, acc.: 52.34%] [G loss: 0.781980]\n",
      "epoch:6 step:6247 [D loss: 0.700933, acc.: 50.00%] [G loss: 0.763236]\n",
      "epoch:6 step:6248 [D loss: 0.698990, acc.: 55.47%] [G loss: 0.805628]\n",
      "epoch:6 step:6249 [D loss: 0.684999, acc.: 55.47%] [G loss: 0.764339]\n",
      "epoch:6 step:6250 [D loss: 0.688302, acc.: 53.91%] [G loss: 0.767200]\n",
      "epoch:6 step:6251 [D loss: 0.697736, acc.: 50.78%] [G loss: 0.726017]\n",
      "epoch:6 step:6252 [D loss: 0.693832, acc.: 50.00%] [G loss: 0.742680]\n",
      "epoch:6 step:6253 [D loss: 0.690724, acc.: 52.34%] [G loss: 0.781034]\n",
      "epoch:6 step:6254 [D loss: 0.671518, acc.: 60.16%] [G loss: 0.724211]\n",
      "epoch:6 step:6255 [D loss: 0.694364, acc.: 52.34%] [G loss: 0.725636]\n",
      "epoch:6 step:6256 [D loss: 0.682896, acc.: 57.03%] [G loss: 0.743148]\n",
      "epoch:6 step:6257 [D loss: 0.699957, acc.: 46.09%] [G loss: 0.730161]\n",
      "epoch:6 step:6258 [D loss: 0.697692, acc.: 50.00%] [G loss: 0.712496]\n",
      "epoch:6 step:6259 [D loss: 0.697038, acc.: 54.69%] [G loss: 0.725310]\n",
      "epoch:6 step:6260 [D loss: 0.697584, acc.: 51.56%] [G loss: 0.723697]\n",
      "epoch:6 step:6261 [D loss: 0.695047, acc.: 41.41%] [G loss: 0.704867]\n",
      "epoch:6 step:6262 [D loss: 0.710380, acc.: 50.00%] [G loss: 0.715300]\n",
      "epoch:6 step:6263 [D loss: 0.694093, acc.: 51.56%] [G loss: 0.706127]\n",
      "epoch:6 step:6264 [D loss: 0.696091, acc.: 49.22%] [G loss: 0.715334]\n",
      "epoch:6 step:6265 [D loss: 0.695855, acc.: 53.91%] [G loss: 0.715079]\n",
      "epoch:6 step:6266 [D loss: 0.689736, acc.: 56.25%] [G loss: 0.709710]\n",
      "epoch:6 step:6267 [D loss: 0.694303, acc.: 51.56%] [G loss: 0.714067]\n",
      "epoch:6 step:6268 [D loss: 0.692490, acc.: 50.00%] [G loss: 0.716409]\n",
      "epoch:6 step:6269 [D loss: 0.682817, acc.: 53.12%] [G loss: 0.727283]\n",
      "epoch:6 step:6270 [D loss: 0.674611, acc.: 63.28%] [G loss: 0.723406]\n",
      "epoch:6 step:6271 [D loss: 0.680123, acc.: 58.59%] [G loss: 0.748290]\n",
      "epoch:6 step:6272 [D loss: 0.673052, acc.: 60.16%] [G loss: 0.751704]\n",
      "epoch:6 step:6273 [D loss: 0.685512, acc.: 56.25%] [G loss: 0.750689]\n",
      "epoch:6 step:6274 [D loss: 0.689269, acc.: 57.03%] [G loss: 0.723604]\n",
      "epoch:6 step:6275 [D loss: 0.708835, acc.: 45.31%] [G loss: 0.715290]\n",
      "epoch:6 step:6276 [D loss: 0.688243, acc.: 56.25%] [G loss: 0.712052]\n",
      "epoch:6 step:6277 [D loss: 0.699265, acc.: 48.44%] [G loss: 0.731425]\n",
      "epoch:6 step:6278 [D loss: 0.691252, acc.: 50.00%] [G loss: 0.726943]\n",
      "epoch:6 step:6279 [D loss: 0.690452, acc.: 50.78%] [G loss: 0.743446]\n",
      "epoch:6 step:6280 [D loss: 0.670487, acc.: 60.16%] [G loss: 0.753720]\n",
      "epoch:6 step:6281 [D loss: 0.644572, acc.: 60.94%] [G loss: 0.766715]\n",
      "epoch:6 step:6282 [D loss: 0.668851, acc.: 57.81%] [G loss: 0.779128]\n",
      "epoch:6 step:6283 [D loss: 0.668765, acc.: 57.81%] [G loss: 0.782577]\n",
      "epoch:6 step:6284 [D loss: 0.687401, acc.: 45.31%] [G loss: 0.754043]\n",
      "epoch:6 step:6285 [D loss: 0.695273, acc.: 50.78%] [G loss: 0.728881]\n",
      "epoch:6 step:6286 [D loss: 0.716345, acc.: 44.53%] [G loss: 0.717627]\n",
      "epoch:6 step:6287 [D loss: 0.691306, acc.: 46.09%] [G loss: 0.744946]\n",
      "epoch:6 step:6288 [D loss: 0.657895, acc.: 60.16%] [G loss: 0.738532]\n",
      "epoch:6 step:6289 [D loss: 0.701514, acc.: 50.00%] [G loss: 0.726591]\n",
      "epoch:6 step:6290 [D loss: 0.734934, acc.: 42.19%] [G loss: 0.733746]\n",
      "epoch:6 step:6291 [D loss: 0.688732, acc.: 50.78%] [G loss: 0.736546]\n",
      "epoch:6 step:6292 [D loss: 0.719968, acc.: 50.78%] [G loss: 0.743659]\n",
      "epoch:6 step:6293 [D loss: 0.688936, acc.: 56.25%] [G loss: 0.768499]\n",
      "epoch:6 step:6294 [D loss: 0.707723, acc.: 42.97%] [G loss: 0.748420]\n",
      "epoch:6 step:6295 [D loss: 0.695807, acc.: 53.12%] [G loss: 0.755663]\n",
      "epoch:6 step:6296 [D loss: 0.667742, acc.: 60.94%] [G loss: 0.752341]\n",
      "epoch:6 step:6297 [D loss: 0.707110, acc.: 46.88%] [G loss: 0.728895]\n",
      "epoch:6 step:6298 [D loss: 0.677239, acc.: 61.72%] [G loss: 0.738342]\n",
      "epoch:6 step:6299 [D loss: 0.691265, acc.: 53.12%] [G loss: 0.731760]\n",
      "epoch:6 step:6300 [D loss: 0.699861, acc.: 48.44%] [G loss: 0.723349]\n",
      "epoch:6 step:6301 [D loss: 0.687256, acc.: 57.81%] [G loss: 0.730341]\n",
      "epoch:6 step:6302 [D loss: 0.711900, acc.: 49.22%] [G loss: 0.728639]\n",
      "epoch:6 step:6303 [D loss: 0.684953, acc.: 54.69%] [G loss: 0.744041]\n",
      "epoch:6 step:6304 [D loss: 0.697653, acc.: 52.34%] [G loss: 0.740126]\n",
      "epoch:6 step:6305 [D loss: 0.689236, acc.: 54.69%] [G loss: 0.730888]\n",
      "epoch:6 step:6306 [D loss: 0.677404, acc.: 63.28%] [G loss: 0.694858]\n",
      "epoch:6 step:6307 [D loss: 0.682050, acc.: 54.69%] [G loss: 0.727945]\n",
      "epoch:6 step:6308 [D loss: 0.690909, acc.: 51.56%] [G loss: 0.754848]\n",
      "epoch:6 step:6309 [D loss: 0.678007, acc.: 59.38%] [G loss: 0.772041]\n",
      "epoch:6 step:6310 [D loss: 0.678483, acc.: 60.94%] [G loss: 0.735192]\n",
      "epoch:6 step:6311 [D loss: 0.697543, acc.: 51.56%] [G loss: 0.742932]\n",
      "epoch:6 step:6312 [D loss: 0.684904, acc.: 59.38%] [G loss: 0.737121]\n",
      "epoch:6 step:6313 [D loss: 0.703645, acc.: 44.53%] [G loss: 0.735679]\n",
      "epoch:6 step:6314 [D loss: 0.676054, acc.: 54.69%] [G loss: 0.762558]\n",
      "epoch:6 step:6315 [D loss: 0.697481, acc.: 54.69%] [G loss: 0.737218]\n",
      "epoch:6 step:6316 [D loss: 0.673956, acc.: 56.25%] [G loss: 0.682943]\n",
      "epoch:6 step:6317 [D loss: 0.683997, acc.: 57.03%] [G loss: 0.736004]\n",
      "epoch:6 step:6318 [D loss: 0.708127, acc.: 49.22%] [G loss: 0.749516]\n",
      "epoch:6 step:6319 [D loss: 0.748693, acc.: 46.09%] [G loss: 0.785704]\n",
      "epoch:6 step:6320 [D loss: 0.665347, acc.: 64.84%] [G loss: 0.802085]\n",
      "epoch:6 step:6321 [D loss: 0.671547, acc.: 61.72%] [G loss: 0.867397]\n",
      "epoch:6 step:6322 [D loss: 0.680335, acc.: 53.12%] [G loss: 0.741004]\n",
      "epoch:6 step:6323 [D loss: 0.664013, acc.: 67.97%] [G loss: 0.810125]\n",
      "epoch:6 step:6324 [D loss: 0.697468, acc.: 52.34%] [G loss: 0.801186]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6325 [D loss: 0.685227, acc.: 53.12%] [G loss: 0.748635]\n",
      "epoch:6 step:6326 [D loss: 0.695374, acc.: 51.56%] [G loss: 0.741225]\n",
      "epoch:6 step:6327 [D loss: 0.707181, acc.: 42.97%] [G loss: 0.740752]\n",
      "epoch:6 step:6328 [D loss: 0.682613, acc.: 59.38%] [G loss: 0.720390]\n",
      "epoch:6 step:6329 [D loss: 0.685665, acc.: 55.47%] [G loss: 0.723204]\n",
      "epoch:6 step:6330 [D loss: 0.663672, acc.: 60.94%] [G loss: 0.731999]\n",
      "epoch:6 step:6331 [D loss: 0.664208, acc.: 62.50%] [G loss: 0.803755]\n",
      "epoch:6 step:6332 [D loss: 0.706750, acc.: 50.00%] [G loss: 0.732956]\n",
      "epoch:6 step:6333 [D loss: 0.700839, acc.: 53.12%] [G loss: 0.753726]\n",
      "epoch:6 step:6334 [D loss: 0.692767, acc.: 50.78%] [G loss: 0.742276]\n",
      "epoch:6 step:6335 [D loss: 0.690873, acc.: 53.12%] [G loss: 0.708624]\n",
      "epoch:6 step:6336 [D loss: 0.689150, acc.: 54.69%] [G loss: 0.697814]\n",
      "epoch:6 step:6337 [D loss: 0.716159, acc.: 43.75%] [G loss: 0.702042]\n",
      "epoch:6 step:6338 [D loss: 0.720154, acc.: 36.72%] [G loss: 0.704955]\n",
      "epoch:6 step:6339 [D loss: 0.720470, acc.: 40.62%] [G loss: 0.724546]\n",
      "epoch:6 step:6340 [D loss: 0.693303, acc.: 53.12%] [G loss: 0.725361]\n",
      "epoch:6 step:6341 [D loss: 0.683224, acc.: 60.16%] [G loss: 0.753772]\n",
      "epoch:6 step:6342 [D loss: 0.683753, acc.: 52.34%] [G loss: 0.751484]\n",
      "epoch:6 step:6343 [D loss: 0.676117, acc.: 60.16%] [G loss: 0.747209]\n",
      "epoch:6 step:6344 [D loss: 0.686722, acc.: 54.69%] [G loss: 0.784954]\n",
      "epoch:6 step:6345 [D loss: 0.678345, acc.: 56.25%] [G loss: 0.770034]\n",
      "epoch:6 step:6346 [D loss: 0.694111, acc.: 51.56%] [G loss: 0.781626]\n",
      "epoch:6 step:6347 [D loss: 0.682687, acc.: 53.91%] [G loss: 0.759306]\n",
      "epoch:6 step:6348 [D loss: 0.695086, acc.: 58.59%] [G loss: 0.760639]\n",
      "epoch:6 step:6349 [D loss: 0.708717, acc.: 46.88%] [G loss: 0.755871]\n",
      "epoch:6 step:6350 [D loss: 0.713731, acc.: 38.28%] [G loss: 0.744453]\n",
      "epoch:6 step:6351 [D loss: 0.684108, acc.: 51.56%] [G loss: 0.772589]\n",
      "epoch:6 step:6352 [D loss: 0.676297, acc.: 61.72%] [G loss: 0.761312]\n",
      "epoch:6 step:6353 [D loss: 0.668017, acc.: 62.50%] [G loss: 0.762366]\n",
      "epoch:6 step:6354 [D loss: 0.680881, acc.: 54.69%] [G loss: 0.738917]\n",
      "epoch:6 step:6355 [D loss: 0.670732, acc.: 58.59%] [G loss: 0.693901]\n",
      "epoch:6 step:6356 [D loss: 0.688808, acc.: 48.44%] [G loss: 0.778841]\n",
      "epoch:6 step:6357 [D loss: 0.748486, acc.: 34.38%] [G loss: 0.708969]\n",
      "epoch:6 step:6358 [D loss: 0.717787, acc.: 39.84%] [G loss: 0.714553]\n",
      "epoch:6 step:6359 [D loss: 0.692743, acc.: 52.34%] [G loss: 0.734293]\n",
      "epoch:6 step:6360 [D loss: 0.700852, acc.: 46.09%] [G loss: 0.727745]\n",
      "epoch:6 step:6361 [D loss: 0.688951, acc.: 54.69%] [G loss: 0.721976]\n",
      "epoch:6 step:6362 [D loss: 0.672738, acc.: 58.59%] [G loss: 0.729908]\n",
      "epoch:6 step:6363 [D loss: 0.688026, acc.: 54.69%] [G loss: 0.715930]\n",
      "epoch:6 step:6364 [D loss: 0.699946, acc.: 42.97%] [G loss: 0.719713]\n",
      "epoch:6 step:6365 [D loss: 0.705446, acc.: 43.75%] [G loss: 0.708279]\n",
      "epoch:6 step:6366 [D loss: 0.692859, acc.: 48.44%] [G loss: 0.735840]\n",
      "epoch:6 step:6367 [D loss: 0.693526, acc.: 54.69%] [G loss: 0.745519]\n",
      "epoch:6 step:6368 [D loss: 0.719123, acc.: 42.19%] [G loss: 0.713492]\n",
      "epoch:6 step:6369 [D loss: 0.701086, acc.: 55.47%] [G loss: 0.710569]\n",
      "epoch:6 step:6370 [D loss: 0.696871, acc.: 50.00%] [G loss: 0.711633]\n",
      "epoch:6 step:6371 [D loss: 0.680174, acc.: 57.81%] [G loss: 0.717963]\n",
      "epoch:6 step:6372 [D loss: 0.686537, acc.: 56.25%] [G loss: 0.723890]\n",
      "epoch:6 step:6373 [D loss: 0.691840, acc.: 50.00%] [G loss: 0.743468]\n",
      "epoch:6 step:6374 [D loss: 0.696107, acc.: 53.91%] [G loss: 0.730422]\n",
      "epoch:6 step:6375 [D loss: 0.692213, acc.: 55.47%] [G loss: 0.747611]\n",
      "epoch:6 step:6376 [D loss: 0.689634, acc.: 52.34%] [G loss: 0.723841]\n",
      "epoch:6 step:6377 [D loss: 0.681570, acc.: 57.81%] [G loss: 0.716359]\n",
      "epoch:6 step:6378 [D loss: 0.682705, acc.: 57.03%] [G loss: 0.718424]\n",
      "epoch:6 step:6379 [D loss: 0.702875, acc.: 49.22%] [G loss: 0.714913]\n",
      "epoch:6 step:6380 [D loss: 0.695371, acc.: 49.22%] [G loss: 0.714689]\n",
      "epoch:6 step:6381 [D loss: 0.698146, acc.: 49.22%] [G loss: 0.712564]\n",
      "epoch:6 step:6382 [D loss: 0.709053, acc.: 42.97%] [G loss: 0.719672]\n",
      "epoch:6 step:6383 [D loss: 0.701798, acc.: 45.31%] [G loss: 0.738053]\n",
      "epoch:6 step:6384 [D loss: 0.697650, acc.: 47.66%] [G loss: 0.727788]\n",
      "epoch:6 step:6385 [D loss: 0.680236, acc.: 53.91%] [G loss: 0.764328]\n",
      "epoch:6 step:6386 [D loss: 0.669816, acc.: 63.28%] [G loss: 0.740086]\n",
      "epoch:6 step:6387 [D loss: 0.673976, acc.: 61.72%] [G loss: 0.786344]\n",
      "epoch:6 step:6388 [D loss: 0.669375, acc.: 63.28%] [G loss: 0.746171]\n",
      "epoch:6 step:6389 [D loss: 0.666584, acc.: 61.72%] [G loss: 0.753274]\n",
      "epoch:6 step:6390 [D loss: 0.682193, acc.: 53.12%] [G loss: 0.786121]\n",
      "epoch:6 step:6391 [D loss: 0.674491, acc.: 60.16%] [G loss: 0.741148]\n",
      "epoch:6 step:6392 [D loss: 0.678125, acc.: 53.91%] [G loss: 0.698198]\n",
      "epoch:6 step:6393 [D loss: 0.690221, acc.: 58.59%] [G loss: 0.691077]\n",
      "epoch:6 step:6394 [D loss: 0.719212, acc.: 47.66%] [G loss: 0.704207]\n",
      "epoch:6 step:6395 [D loss: 0.695722, acc.: 44.53%] [G loss: 0.692212]\n",
      "epoch:6 step:6396 [D loss: 0.681075, acc.: 55.47%] [G loss: 0.713854]\n",
      "epoch:6 step:6397 [D loss: 0.703944, acc.: 51.56%] [G loss: 0.743114]\n",
      "epoch:6 step:6398 [D loss: 0.705491, acc.: 49.22%] [G loss: 0.748625]\n",
      "epoch:6 step:6399 [D loss: 0.690571, acc.: 53.91%] [G loss: 0.784768]\n",
      "epoch:6 step:6400 [D loss: 0.692331, acc.: 49.22%] [G loss: 0.832809]\n",
      "##############\n",
      "[3.65378665 2.92484692 6.90107975 6.14441471 4.14259072 6.76312967\n",
      " 5.14245365 5.43491861 5.48414476 4.71617042]\n",
      "##########\n",
      "epoch:6 step:6401 [D loss: 0.680409, acc.: 51.56%] [G loss: 0.817418]\n",
      "epoch:6 step:6402 [D loss: 0.676702, acc.: 54.69%] [G loss: 0.880361]\n",
      "epoch:6 step:6403 [D loss: 0.668845, acc.: 57.81%] [G loss: 0.788704]\n",
      "epoch:6 step:6404 [D loss: 0.666407, acc.: 63.28%] [G loss: 0.795868]\n",
      "epoch:6 step:6405 [D loss: 0.681956, acc.: 59.38%] [G loss: 0.797505]\n",
      "epoch:6 step:6406 [D loss: 0.715667, acc.: 39.06%] [G loss: 0.710118]\n",
      "epoch:6 step:6407 [D loss: 0.688307, acc.: 50.78%] [G loss: 0.703565]\n",
      "epoch:6 step:6408 [D loss: 0.687754, acc.: 60.16%] [G loss: 0.762290]\n",
      "epoch:6 step:6409 [D loss: 0.740921, acc.: 34.38%] [G loss: 0.699450]\n",
      "epoch:6 step:6410 [D loss: 0.713937, acc.: 39.06%] [G loss: 0.711284]\n",
      "epoch:6 step:6411 [D loss: 0.719334, acc.: 44.53%] [G loss: 0.690779]\n",
      "epoch:6 step:6412 [D loss: 0.703080, acc.: 50.00%] [G loss: 0.697624]\n",
      "epoch:6 step:6413 [D loss: 0.700948, acc.: 46.88%] [G loss: 0.703449]\n",
      "epoch:6 step:6414 [D loss: 0.690522, acc.: 52.34%] [G loss: 0.726736]\n",
      "epoch:6 step:6415 [D loss: 0.694473, acc.: 53.91%] [G loss: 0.715878]\n",
      "epoch:6 step:6416 [D loss: 0.695221, acc.: 48.44%] [G loss: 0.730182]\n",
      "epoch:6 step:6417 [D loss: 0.682412, acc.: 60.94%] [G loss: 0.737016]\n",
      "epoch:6 step:6418 [D loss: 0.670398, acc.: 64.06%] [G loss: 0.739660]\n",
      "epoch:6 step:6419 [D loss: 0.678596, acc.: 53.12%] [G loss: 0.726316]\n",
      "epoch:6 step:6420 [D loss: 0.694082, acc.: 49.22%] [G loss: 0.711812]\n",
      "epoch:6 step:6421 [D loss: 0.682996, acc.: 60.94%] [G loss: 0.698184]\n",
      "epoch:6 step:6422 [D loss: 0.696627, acc.: 47.66%] [G loss: 0.741132]\n",
      "epoch:6 step:6423 [D loss: 0.681892, acc.: 60.16%] [G loss: 0.729381]\n",
      "epoch:6 step:6424 [D loss: 0.597117, acc.: 61.72%] [G loss: 0.746853]\n",
      "epoch:6 step:6425 [D loss: 0.692257, acc.: 58.59%] [G loss: 0.722268]\n",
      "epoch:6 step:6426 [D loss: 0.705488, acc.: 53.91%] [G loss: 0.741972]\n",
      "epoch:6 step:6427 [D loss: 0.691435, acc.: 55.47%] [G loss: 0.739497]\n",
      "epoch:6 step:6428 [D loss: 0.687526, acc.: 53.12%] [G loss: 0.719852]\n",
      "epoch:6 step:6429 [D loss: 0.706236, acc.: 44.53%] [G loss: 0.761220]\n",
      "epoch:6 step:6430 [D loss: 0.691455, acc.: 53.91%] [G loss: 0.686695]\n",
      "epoch:6 step:6431 [D loss: 0.686277, acc.: 53.12%] [G loss: 0.740999]\n",
      "epoch:6 step:6432 [D loss: 0.660890, acc.: 64.84%] [G loss: 0.740165]\n",
      "epoch:6 step:6433 [D loss: 0.699768, acc.: 50.00%] [G loss: 0.754180]\n",
      "epoch:6 step:6434 [D loss: 0.688651, acc.: 53.91%] [G loss: 0.744622]\n",
      "epoch:6 step:6435 [D loss: 0.681807, acc.: 59.38%] [G loss: 0.718608]\n",
      "epoch:6 step:6436 [D loss: 0.709548, acc.: 46.09%] [G loss: 0.726158]\n",
      "epoch:6 step:6437 [D loss: 0.683775, acc.: 53.12%] [G loss: 0.718778]\n",
      "epoch:6 step:6438 [D loss: 0.681452, acc.: 55.47%] [G loss: 0.706003]\n",
      "epoch:6 step:6439 [D loss: 0.712381, acc.: 44.53%] [G loss: 0.715999]\n",
      "epoch:6 step:6440 [D loss: 0.694412, acc.: 56.25%] [G loss: 0.744709]\n",
      "epoch:6 step:6441 [D loss: 0.686768, acc.: 54.69%] [G loss: 0.671029]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6442 [D loss: 0.715189, acc.: 43.75%] [G loss: 0.739167]\n",
      "epoch:6 step:6443 [D loss: 0.724604, acc.: 38.28%] [G loss: 0.705430]\n",
      "epoch:6 step:6444 [D loss: 0.690166, acc.: 49.22%] [G loss: 0.733834]\n",
      "epoch:6 step:6445 [D loss: 0.701990, acc.: 49.22%] [G loss: 0.718506]\n",
      "epoch:6 step:6446 [D loss: 0.681326, acc.: 57.03%] [G loss: 0.705463]\n",
      "epoch:6 step:6447 [D loss: 0.679586, acc.: 60.94%] [G loss: 0.730502]\n",
      "epoch:6 step:6448 [D loss: 0.672325, acc.: 57.81%] [G loss: 0.739562]\n",
      "epoch:6 step:6449 [D loss: 0.683594, acc.: 53.91%] [G loss: 0.746859]\n",
      "epoch:6 step:6450 [D loss: 0.700776, acc.: 48.44%] [G loss: 0.729725]\n",
      "epoch:6 step:6451 [D loss: 0.676491, acc.: 56.25%] [G loss: 0.743352]\n",
      "epoch:6 step:6452 [D loss: 0.672516, acc.: 59.38%] [G loss: 0.710899]\n",
      "epoch:6 step:6453 [D loss: 0.692998, acc.: 49.22%] [G loss: 0.722194]\n",
      "epoch:6 step:6454 [D loss: 0.690707, acc.: 56.25%] [G loss: 0.746916]\n",
      "epoch:6 step:6455 [D loss: 0.722877, acc.: 41.41%] [G loss: 0.755651]\n",
      "epoch:6 step:6456 [D loss: 0.714764, acc.: 50.00%] [G loss: 0.738103]\n",
      "epoch:6 step:6457 [D loss: 0.687527, acc.: 57.03%] [G loss: 0.744405]\n",
      "epoch:6 step:6458 [D loss: 0.694954, acc.: 52.34%] [G loss: 0.760846]\n",
      "epoch:6 step:6459 [D loss: 0.668709, acc.: 58.59%] [G loss: 0.772913]\n",
      "epoch:6 step:6460 [D loss: 0.673839, acc.: 60.94%] [G loss: 0.777662]\n",
      "epoch:6 step:6461 [D loss: 0.681203, acc.: 57.81%] [G loss: 0.768879]\n",
      "epoch:6 step:6462 [D loss: 0.721969, acc.: 44.53%] [G loss: 0.751741]\n",
      "epoch:6 step:6463 [D loss: 0.669890, acc.: 57.81%] [G loss: 0.727459]\n",
      "epoch:6 step:6464 [D loss: 0.657961, acc.: 65.62%] [G loss: 0.762983]\n",
      "epoch:6 step:6465 [D loss: 0.741094, acc.: 39.06%] [G loss: 0.723827]\n",
      "epoch:6 step:6466 [D loss: 0.710033, acc.: 47.66%] [G loss: 0.737871]\n",
      "epoch:6 step:6467 [D loss: 0.629037, acc.: 64.84%] [G loss: 0.760409]\n",
      "epoch:6 step:6468 [D loss: 0.680264, acc.: 53.91%] [G loss: 0.732228]\n",
      "epoch:6 step:6469 [D loss: 0.719493, acc.: 42.19%] [G loss: 0.735005]\n",
      "epoch:6 step:6470 [D loss: 0.722301, acc.: 44.53%] [G loss: 0.728394]\n",
      "epoch:6 step:6471 [D loss: 0.693037, acc.: 51.56%] [G loss: 0.704615]\n",
      "epoch:6 step:6472 [D loss: 0.702689, acc.: 49.22%] [G loss: 0.736550]\n",
      "epoch:6 step:6473 [D loss: 0.708705, acc.: 47.66%] [G loss: 0.732381]\n",
      "epoch:6 step:6474 [D loss: 0.691617, acc.: 55.47%] [G loss: 0.737190]\n",
      "epoch:6 step:6475 [D loss: 0.677574, acc.: 63.28%] [G loss: 0.739171]\n",
      "epoch:6 step:6476 [D loss: 0.679733, acc.: 54.69%] [G loss: 0.761469]\n",
      "epoch:6 step:6477 [D loss: 0.668527, acc.: 62.50%] [G loss: 0.725903]\n",
      "epoch:6 step:6478 [D loss: 0.662995, acc.: 62.50%] [G loss: 0.789600]\n",
      "epoch:6 step:6479 [D loss: 0.642687, acc.: 67.97%] [G loss: 0.799529]\n",
      "epoch:6 step:6480 [D loss: 0.711164, acc.: 42.97%] [G loss: 0.792906]\n",
      "epoch:6 step:6481 [D loss: 0.698637, acc.: 53.91%] [G loss: 0.804217]\n",
      "epoch:6 step:6482 [D loss: 0.676941, acc.: 59.38%] [G loss: 0.814144]\n",
      "epoch:6 step:6483 [D loss: 0.700577, acc.: 50.00%] [G loss: 0.850410]\n",
      "epoch:6 step:6484 [D loss: 0.727358, acc.: 48.44%] [G loss: 0.735962]\n",
      "epoch:6 step:6485 [D loss: 0.711884, acc.: 45.31%] [G loss: 0.702165]\n",
      "epoch:6 step:6486 [D loss: 0.723648, acc.: 38.28%] [G loss: 0.715983]\n",
      "epoch:6 step:6487 [D loss: 0.711588, acc.: 47.66%] [G loss: 0.712649]\n",
      "epoch:6 step:6488 [D loss: 0.679294, acc.: 56.25%] [G loss: 0.717663]\n",
      "epoch:6 step:6489 [D loss: 0.700191, acc.: 51.56%] [G loss: 0.701194]\n",
      "epoch:6 step:6490 [D loss: 0.700295, acc.: 48.44%] [G loss: 0.763429]\n",
      "epoch:6 step:6491 [D loss: 0.676448, acc.: 57.03%] [G loss: 0.761461]\n",
      "epoch:6 step:6492 [D loss: 0.679841, acc.: 57.03%] [G loss: 0.789021]\n",
      "epoch:6 step:6493 [D loss: 0.684195, acc.: 53.91%] [G loss: 0.760802]\n",
      "epoch:6 step:6494 [D loss: 0.675781, acc.: 57.81%] [G loss: 0.737128]\n",
      "epoch:6 step:6495 [D loss: 0.698303, acc.: 53.91%] [G loss: 0.739849]\n",
      "epoch:6 step:6496 [D loss: 0.686559, acc.: 52.34%] [G loss: 0.776995]\n",
      "epoch:6 step:6497 [D loss: 0.654167, acc.: 67.19%] [G loss: 0.746284]\n",
      "epoch:6 step:6498 [D loss: 0.698647, acc.: 49.22%] [G loss: 0.752183]\n",
      "epoch:6 step:6499 [D loss: 0.693560, acc.: 49.22%] [G loss: 0.713473]\n",
      "epoch:6 step:6500 [D loss: 0.698997, acc.: 44.53%] [G loss: 0.742331]\n",
      "epoch:6 step:6501 [D loss: 0.720609, acc.: 47.66%] [G loss: 0.715259]\n",
      "epoch:6 step:6502 [D loss: 0.707567, acc.: 46.09%] [G loss: 0.707587]\n",
      "epoch:6 step:6503 [D loss: 0.707010, acc.: 47.66%] [G loss: 0.714017]\n",
      "epoch:6 step:6504 [D loss: 0.698210, acc.: 50.00%] [G loss: 0.729226]\n",
      "epoch:6 step:6505 [D loss: 0.678831, acc.: 61.72%] [G loss: 0.709424]\n",
      "epoch:6 step:6506 [D loss: 0.679619, acc.: 57.03%] [G loss: 0.744303]\n",
      "epoch:6 step:6507 [D loss: 0.690270, acc.: 52.34%] [G loss: 0.743918]\n",
      "epoch:6 step:6508 [D loss: 0.672385, acc.: 60.94%] [G loss: 0.774242]\n",
      "epoch:6 step:6509 [D loss: 0.667154, acc.: 63.28%] [G loss: 0.740692]\n",
      "epoch:6 step:6510 [D loss: 0.669188, acc.: 57.81%] [G loss: 0.756688]\n",
      "epoch:6 step:6511 [D loss: 0.685205, acc.: 62.50%] [G loss: 0.733733]\n",
      "epoch:6 step:6512 [D loss: 0.677465, acc.: 60.16%] [G loss: 0.730146]\n",
      "epoch:6 step:6513 [D loss: 0.726193, acc.: 42.97%] [G loss: 0.733225]\n",
      "epoch:6 step:6514 [D loss: 0.735714, acc.: 34.38%] [G loss: 0.696885]\n",
      "epoch:6 step:6515 [D loss: 0.734145, acc.: 46.88%] [G loss: 0.729494]\n",
      "epoch:6 step:6516 [D loss: 0.696155, acc.: 54.69%] [G loss: 0.711696]\n",
      "epoch:6 step:6517 [D loss: 0.696508, acc.: 50.78%] [G loss: 0.755700]\n",
      "epoch:6 step:6518 [D loss: 0.687524, acc.: 54.69%] [G loss: 0.735274]\n",
      "epoch:6 step:6519 [D loss: 0.674524, acc.: 57.81%] [G loss: 0.751138]\n",
      "epoch:6 step:6520 [D loss: 0.691748, acc.: 54.69%] [G loss: 0.761418]\n",
      "epoch:6 step:6521 [D loss: 0.596442, acc.: 74.22%] [G loss: 0.551508]\n",
      "epoch:6 step:6522 [D loss: 0.659001, acc.: 57.03%] [G loss: 0.733446]\n",
      "epoch:6 step:6523 [D loss: 0.693172, acc.: 48.44%] [G loss: 0.704452]\n",
      "epoch:6 step:6524 [D loss: 0.692015, acc.: 55.47%] [G loss: 0.751468]\n",
      "epoch:6 step:6525 [D loss: 0.696617, acc.: 48.44%] [G loss: 0.725132]\n",
      "epoch:6 step:6526 [D loss: 0.724639, acc.: 38.28%] [G loss: 0.646047]\n",
      "epoch:6 step:6527 [D loss: 0.719627, acc.: 43.75%] [G loss: 0.740204]\n",
      "epoch:6 step:6528 [D loss: 0.705231, acc.: 48.44%] [G loss: 0.727230]\n",
      "epoch:6 step:6529 [D loss: 0.682581, acc.: 55.47%] [G loss: 0.752983]\n",
      "epoch:6 step:6530 [D loss: 0.677002, acc.: 57.03%] [G loss: 0.752779]\n",
      "epoch:6 step:6531 [D loss: 0.655243, acc.: 67.97%] [G loss: 0.735567]\n",
      "epoch:6 step:6532 [D loss: 0.702227, acc.: 55.47%] [G loss: 0.740985]\n",
      "epoch:6 step:6533 [D loss: 0.698984, acc.: 53.12%] [G loss: 0.742263]\n",
      "epoch:6 step:6534 [D loss: 0.522370, acc.: 71.09%] [G loss: 0.700244]\n",
      "epoch:6 step:6535 [D loss: 0.716294, acc.: 50.78%] [G loss: 0.763267]\n",
      "epoch:6 step:6536 [D loss: 0.682215, acc.: 56.25%] [G loss: 0.758682]\n",
      "epoch:6 step:6537 [D loss: 0.695120, acc.: 48.44%] [G loss: 0.749975]\n",
      "epoch:6 step:6538 [D loss: 0.688435, acc.: 49.22%] [G loss: 0.781758]\n",
      "epoch:6 step:6539 [D loss: 0.697310, acc.: 46.88%] [G loss: 0.744737]\n",
      "epoch:6 step:6540 [D loss: 0.660974, acc.: 62.50%] [G loss: 0.760815]\n",
      "epoch:6 step:6541 [D loss: 0.709459, acc.: 50.00%] [G loss: 0.734246]\n",
      "epoch:6 step:6542 [D loss: 0.681387, acc.: 60.94%] [G loss: 0.744995]\n",
      "epoch:6 step:6543 [D loss: 0.651542, acc.: 64.06%] [G loss: 0.796809]\n",
      "epoch:6 step:6544 [D loss: 0.672662, acc.: 60.94%] [G loss: 0.770595]\n",
      "epoch:6 step:6545 [D loss: 0.683678, acc.: 55.47%] [G loss: 0.763254]\n",
      "epoch:6 step:6546 [D loss: 0.597134, acc.: 65.62%] [G loss: 0.736917]\n",
      "epoch:6 step:6547 [D loss: 0.581082, acc.: 64.84%] [G loss: 0.713105]\n",
      "epoch:6 step:6548 [D loss: 0.477231, acc.: 60.16%] [G loss: 0.739833]\n",
      "epoch:6 step:6549 [D loss: 0.493372, acc.: 59.38%] [G loss: 0.819865]\n",
      "epoch:6 step:6550 [D loss: 0.744859, acc.: 42.97%] [G loss: 0.790193]\n",
      "epoch:6 step:6551 [D loss: 0.687709, acc.: 53.91%] [G loss: 0.802352]\n",
      "epoch:6 step:6552 [D loss: 0.676615, acc.: 58.59%] [G loss: 0.783117]\n",
      "epoch:6 step:6553 [D loss: 0.672473, acc.: 59.38%] [G loss: 0.786546]\n",
      "epoch:6 step:6554 [D loss: 0.876887, acc.: 31.25%] [G loss: 0.790568]\n",
      "epoch:6 step:6555 [D loss: 0.553698, acc.: 88.28%] [G loss: 0.801276]\n",
      "epoch:6 step:6556 [D loss: 0.587926, acc.: 82.03%] [G loss: 0.803685]\n",
      "epoch:6 step:6557 [D loss: 0.688281, acc.: 54.69%] [G loss: 0.790444]\n",
      "epoch:6 step:6558 [D loss: 0.385622, acc.: 76.56%] [G loss: 0.830134]\n",
      "epoch:6 step:6559 [D loss: 0.365618, acc.: 85.94%] [G loss: 0.836876]\n",
      "epoch:7 step:6560 [D loss: 0.750936, acc.: 40.62%] [G loss: 0.832310]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6561 [D loss: 0.767369, acc.: 32.81%] [G loss: 0.761813]\n",
      "epoch:7 step:6562 [D loss: 0.761438, acc.: 31.25%] [G loss: 0.612241]\n",
      "epoch:7 step:6563 [D loss: 0.749715, acc.: 35.94%] [G loss: 0.821584]\n",
      "epoch:7 step:6564 [D loss: 0.729633, acc.: 43.75%] [G loss: 0.592641]\n",
      "epoch:7 step:6565 [D loss: 1.121983, acc.: 6.25%] [G loss: 1.426407]\n",
      "epoch:7 step:6566 [D loss: 0.571047, acc.: 50.00%] [G loss: 2.033022]\n",
      "epoch:7 step:6567 [D loss: 0.615261, acc.: 57.03%] [G loss: 1.604866]\n",
      "epoch:7 step:6568 [D loss: 0.716953, acc.: 46.88%] [G loss: 0.925958]\n",
      "epoch:7 step:6569 [D loss: 0.744306, acc.: 50.78%] [G loss: 0.849944]\n",
      "epoch:7 step:6570 [D loss: 0.663125, acc.: 63.28%] [G loss: 0.928137]\n",
      "epoch:7 step:6571 [D loss: 0.642214, acc.: 63.28%] [G loss: 1.103662]\n",
      "epoch:7 step:6572 [D loss: 0.593868, acc.: 78.12%] [G loss: 1.141191]\n",
      "epoch:7 step:6573 [D loss: 0.579906, acc.: 76.56%] [G loss: 1.061767]\n",
      "epoch:7 step:6574 [D loss: 0.550491, acc.: 82.81%] [G loss: 1.436971]\n",
      "epoch:7 step:6575 [D loss: 0.610911, acc.: 65.62%] [G loss: 1.277013]\n",
      "epoch:7 step:6576 [D loss: 0.659126, acc.: 57.03%] [G loss: 0.984051]\n",
      "epoch:7 step:6577 [D loss: 0.586854, acc.: 77.34%] [G loss: 1.080230]\n",
      "epoch:7 step:6578 [D loss: 0.669256, acc.: 65.62%] [G loss: 0.728111]\n",
      "epoch:7 step:6579 [D loss: 0.792608, acc.: 38.28%] [G loss: 0.835278]\n",
      "epoch:7 step:6580 [D loss: 0.562378, acc.: 65.62%] [G loss: 1.098141]\n",
      "epoch:7 step:6581 [D loss: 0.660361, acc.: 61.72%] [G loss: 0.670498]\n",
      "epoch:7 step:6582 [D loss: 0.629152, acc.: 75.00%] [G loss: 0.846420]\n",
      "epoch:7 step:6583 [D loss: 0.635273, acc.: 71.09%] [G loss: 0.881564]\n",
      "epoch:7 step:6584 [D loss: 0.401402, acc.: 90.62%] [G loss: 0.779717]\n",
      "epoch:7 step:6585 [D loss: 0.661810, acc.: 63.28%] [G loss: 0.788928]\n",
      "epoch:7 step:6586 [D loss: 0.796609, acc.: 32.03%] [G loss: 0.722539]\n",
      "epoch:7 step:6587 [D loss: 0.788084, acc.: 33.59%] [G loss: 0.721777]\n",
      "epoch:7 step:6588 [D loss: 0.751541, acc.: 44.53%] [G loss: 0.648362]\n",
      "epoch:7 step:6589 [D loss: 0.691709, acc.: 50.78%] [G loss: 1.340061]\n",
      "epoch:7 step:6590 [D loss: 0.696083, acc.: 51.56%] [G loss: 0.706414]\n",
      "epoch:7 step:6591 [D loss: 0.643840, acc.: 67.97%] [G loss: 0.805888]\n",
      "epoch:7 step:6592 [D loss: 0.623790, acc.: 66.41%] [G loss: 0.958053]\n",
      "epoch:7 step:6593 [D loss: 0.649767, acc.: 64.84%] [G loss: 1.038885]\n",
      "epoch:7 step:6594 [D loss: 0.684783, acc.: 57.81%] [G loss: 1.037378]\n",
      "epoch:7 step:6595 [D loss: 0.668306, acc.: 55.47%] [G loss: 1.044900]\n",
      "epoch:7 step:6596 [D loss: 0.747362, acc.: 50.00%] [G loss: 0.851356]\n",
      "epoch:7 step:6597 [D loss: 0.860700, acc.: 25.00%] [G loss: 0.700001]\n",
      "epoch:7 step:6598 [D loss: 0.649908, acc.: 64.06%] [G loss: 0.862570]\n",
      "epoch:7 step:6599 [D loss: 0.747311, acc.: 44.53%] [G loss: 0.784925]\n",
      "epoch:7 step:6600 [D loss: 0.657461, acc.: 59.38%] [G loss: 0.725515]\n",
      "##############\n",
      "[3.73087944 1.61948066 7.28497859 5.88093414 4.03500092 6.34347654\n",
      " 5.17780762 5.1297459  5.31246073 3.98756943]\n",
      "##########\n",
      "epoch:7 step:6601 [D loss: 0.668686, acc.: 57.03%] [G loss: 0.755047]\n",
      "epoch:7 step:6602 [D loss: 0.696911, acc.: 43.75%] [G loss: 0.850210]\n",
      "epoch:7 step:6603 [D loss: 0.733941, acc.: 39.84%] [G loss: 0.698259]\n",
      "epoch:7 step:6604 [D loss: 0.730956, acc.: 50.78%] [G loss: 0.770590]\n",
      "epoch:7 step:6605 [D loss: 0.670339, acc.: 59.38%] [G loss: 0.746208]\n",
      "epoch:7 step:6606 [D loss: 0.646517, acc.: 64.84%] [G loss: 0.751703]\n",
      "epoch:7 step:6607 [D loss: 0.674547, acc.: 56.25%] [G loss: 0.850543]\n",
      "epoch:7 step:6608 [D loss: 0.633890, acc.: 68.75%] [G loss: 0.817906]\n",
      "epoch:7 step:6609 [D loss: 0.630371, acc.: 64.06%] [G loss: 0.781593]\n",
      "epoch:7 step:6610 [D loss: 0.694214, acc.: 53.91%] [G loss: 0.840967]\n",
      "epoch:7 step:6611 [D loss: 0.704032, acc.: 53.12%] [G loss: 0.893587]\n",
      "epoch:7 step:6612 [D loss: 0.640029, acc.: 60.94%] [G loss: 0.850829]\n",
      "epoch:7 step:6613 [D loss: 0.676512, acc.: 59.38%] [G loss: 0.922630]\n",
      "epoch:7 step:6614 [D loss: 0.666386, acc.: 59.38%] [G loss: 0.819113]\n",
      "epoch:7 step:6615 [D loss: 0.668669, acc.: 61.72%] [G loss: 0.819908]\n",
      "epoch:7 step:6616 [D loss: 0.730465, acc.: 43.75%] [G loss: 0.744039]\n",
      "epoch:7 step:6617 [D loss: 0.708528, acc.: 53.91%] [G loss: 0.835135]\n",
      "epoch:7 step:6618 [D loss: 0.657923, acc.: 62.50%] [G loss: 0.860034]\n",
      "epoch:7 step:6619 [D loss: 0.658216, acc.: 52.34%] [G loss: 0.870569]\n",
      "epoch:7 step:6620 [D loss: 0.657879, acc.: 58.59%] [G loss: 0.893266]\n",
      "epoch:7 step:6621 [D loss: 0.656696, acc.: 61.72%] [G loss: 0.852946]\n",
      "epoch:7 step:6622 [D loss: 0.659193, acc.: 60.94%] [G loss: 1.024611]\n",
      "epoch:7 step:6623 [D loss: 0.709610, acc.: 52.34%] [G loss: 0.775476]\n",
      "epoch:7 step:6624 [D loss: 0.708158, acc.: 51.56%] [G loss: 0.817558]\n",
      "epoch:7 step:6625 [D loss: 0.694413, acc.: 50.78%] [G loss: 0.760561]\n",
      "epoch:7 step:6626 [D loss: 0.683894, acc.: 50.00%] [G loss: 0.840030]\n",
      "epoch:7 step:6627 [D loss: 0.671467, acc.: 61.72%] [G loss: 0.839356]\n",
      "epoch:7 step:6628 [D loss: 0.660090, acc.: 58.59%] [G loss: 0.881100]\n",
      "epoch:7 step:6629 [D loss: 0.659170, acc.: 63.28%] [G loss: 0.787005]\n",
      "epoch:7 step:6630 [D loss: 0.712619, acc.: 50.00%] [G loss: 0.785609]\n",
      "epoch:7 step:6631 [D loss: 0.658602, acc.: 58.59%] [G loss: 0.772410]\n",
      "epoch:7 step:6632 [D loss: 0.684409, acc.: 57.81%] [G loss: 0.784736]\n",
      "epoch:7 step:6633 [D loss: 0.659977, acc.: 57.81%] [G loss: 0.799071]\n",
      "epoch:7 step:6634 [D loss: 0.723166, acc.: 53.12%] [G loss: 0.751970]\n",
      "epoch:7 step:6635 [D loss: 0.666561, acc.: 57.81%] [G loss: 0.834736]\n",
      "epoch:7 step:6636 [D loss: 0.682685, acc.: 55.47%] [G loss: 0.731003]\n",
      "epoch:7 step:6637 [D loss: 0.703193, acc.: 49.22%] [G loss: 0.746999]\n",
      "epoch:7 step:6638 [D loss: 0.702262, acc.: 50.00%] [G loss: 0.738223]\n",
      "epoch:7 step:6639 [D loss: 0.672603, acc.: 55.47%] [G loss: 0.770183]\n",
      "epoch:7 step:6640 [D loss: 0.677507, acc.: 57.03%] [G loss: 0.821213]\n",
      "epoch:7 step:6641 [D loss: 0.688079, acc.: 54.69%] [G loss: 0.803740]\n",
      "epoch:7 step:6642 [D loss: 0.676129, acc.: 55.47%] [G loss: 0.812810]\n",
      "epoch:7 step:6643 [D loss: 0.690873, acc.: 56.25%] [G loss: 0.796169]\n",
      "epoch:7 step:6644 [D loss: 0.647530, acc.: 58.59%] [G loss: 0.874804]\n",
      "epoch:7 step:6645 [D loss: 0.691723, acc.: 60.94%] [G loss: 0.758201]\n",
      "epoch:7 step:6646 [D loss: 0.684877, acc.: 53.12%] [G loss: 0.612329]\n",
      "epoch:7 step:6647 [D loss: 0.707650, acc.: 54.69%] [G loss: 0.732235]\n",
      "epoch:7 step:6648 [D loss: 0.637690, acc.: 58.59%] [G loss: 0.769479]\n",
      "epoch:7 step:6649 [D loss: 0.682488, acc.: 58.59%] [G loss: 0.755665]\n",
      "epoch:7 step:6650 [D loss: 0.667931, acc.: 53.12%] [G loss: 0.860540]\n",
      "epoch:7 step:6651 [D loss: 0.656787, acc.: 60.16%] [G loss: 0.774794]\n",
      "epoch:7 step:6652 [D loss: 0.641357, acc.: 70.31%] [G loss: 0.852739]\n",
      "epoch:7 step:6653 [D loss: 0.671757, acc.: 57.03%] [G loss: 0.849696]\n",
      "epoch:7 step:6654 [D loss: 0.694637, acc.: 53.12%] [G loss: 0.789831]\n",
      "epoch:7 step:6655 [D loss: 0.677851, acc.: 57.81%] [G loss: 0.640071]\n",
      "epoch:7 step:6656 [D loss: 0.679804, acc.: 55.47%] [G loss: 0.866246]\n",
      "epoch:7 step:6657 [D loss: 0.671212, acc.: 54.69%] [G loss: 0.805034]\n",
      "epoch:7 step:6658 [D loss: 0.645485, acc.: 64.84%] [G loss: 0.824987]\n",
      "epoch:7 step:6659 [D loss: 0.669793, acc.: 59.38%] [G loss: 0.917969]\n",
      "epoch:7 step:6660 [D loss: 0.658396, acc.: 63.28%] [G loss: 0.909468]\n",
      "epoch:7 step:6661 [D loss: 0.658105, acc.: 58.59%] [G loss: 0.869649]\n",
      "epoch:7 step:6662 [D loss: 0.676605, acc.: 59.38%] [G loss: 0.903050]\n",
      "epoch:7 step:6663 [D loss: 0.660026, acc.: 57.81%] [G loss: 0.921781]\n",
      "epoch:7 step:6664 [D loss: 0.722862, acc.: 48.44%] [G loss: 0.896549]\n",
      "epoch:7 step:6665 [D loss: 0.719353, acc.: 50.00%] [G loss: 0.859166]\n",
      "epoch:7 step:6666 [D loss: 0.695887, acc.: 54.69%] [G loss: 0.837424]\n",
      "epoch:7 step:6667 [D loss: 0.689076, acc.: 53.12%] [G loss: 0.836202]\n",
      "epoch:7 step:6668 [D loss: 0.694363, acc.: 51.56%] [G loss: 0.759557]\n",
      "epoch:7 step:6669 [D loss: 0.696856, acc.: 54.69%] [G loss: 0.779812]\n",
      "epoch:7 step:6670 [D loss: 0.686444, acc.: 55.47%] [G loss: 0.851405]\n",
      "epoch:7 step:6671 [D loss: 0.630934, acc.: 65.62%] [G loss: 0.912759]\n",
      "epoch:7 step:6672 [D loss: 0.645542, acc.: 63.28%] [G loss: 0.882618]\n",
      "epoch:7 step:6673 [D loss: 0.682469, acc.: 53.91%] [G loss: 0.931798]\n",
      "epoch:7 step:6674 [D loss: 0.645948, acc.: 58.59%] [G loss: 0.892762]\n",
      "epoch:7 step:6675 [D loss: 0.708554, acc.: 50.00%] [G loss: 0.789500]\n",
      "epoch:7 step:6676 [D loss: 0.724645, acc.: 55.47%] [G loss: 0.763023]\n",
      "epoch:7 step:6677 [D loss: 0.731084, acc.: 46.88%] [G loss: 0.829371]\n",
      "epoch:7 step:6678 [D loss: 0.617251, acc.: 65.62%] [G loss: 0.979036]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6679 [D loss: 0.691213, acc.: 54.69%] [G loss: 1.092768]\n",
      "epoch:7 step:6680 [D loss: 0.714246, acc.: 44.53%] [G loss: 1.024409]\n",
      "epoch:7 step:6681 [D loss: 0.708090, acc.: 48.44%] [G loss: 0.930110]\n",
      "epoch:7 step:6682 [D loss: 0.656763, acc.: 54.69%] [G loss: 0.916245]\n",
      "epoch:7 step:6683 [D loss: 0.675208, acc.: 62.50%] [G loss: 0.921907]\n",
      "epoch:7 step:6684 [D loss: 0.642200, acc.: 61.72%] [G loss: 0.867186]\n",
      "epoch:7 step:6685 [D loss: 0.674271, acc.: 55.47%] [G loss: 0.882214]\n",
      "epoch:7 step:6686 [D loss: 0.681654, acc.: 58.59%] [G loss: 0.892766]\n",
      "epoch:7 step:6687 [D loss: 0.711044, acc.: 47.66%] [G loss: 0.964115]\n",
      "epoch:7 step:6688 [D loss: 0.717760, acc.: 49.22%] [G loss: 0.741413]\n",
      "epoch:7 step:6689 [D loss: 0.677824, acc.: 57.03%] [G loss: 0.790264]\n",
      "epoch:7 step:6690 [D loss: 0.694075, acc.: 49.22%] [G loss: 0.815082]\n",
      "epoch:7 step:6691 [D loss: 0.636394, acc.: 64.84%] [G loss: 0.863755]\n",
      "epoch:7 step:6692 [D loss: 0.724548, acc.: 49.22%] [G loss: 0.775264]\n",
      "epoch:7 step:6693 [D loss: 0.699203, acc.: 50.00%] [G loss: 0.791592]\n",
      "epoch:7 step:6694 [D loss: 0.645840, acc.: 62.50%] [G loss: 0.860267]\n",
      "epoch:7 step:6695 [D loss: 0.658983, acc.: 60.16%] [G loss: 0.832997]\n",
      "epoch:7 step:6696 [D loss: 0.658686, acc.: 69.53%] [G loss: 0.825277]\n",
      "epoch:7 step:6697 [D loss: 0.672313, acc.: 57.81%] [G loss: 0.861474]\n",
      "epoch:7 step:6698 [D loss: 0.602101, acc.: 82.81%] [G loss: 0.816207]\n",
      "epoch:7 step:6699 [D loss: 0.642490, acc.: 61.72%] [G loss: 0.841814]\n",
      "epoch:7 step:6700 [D loss: 0.680968, acc.: 57.03%] [G loss: 0.760327]\n",
      "epoch:7 step:6701 [D loss: 0.720732, acc.: 50.78%] [G loss: 0.710965]\n",
      "epoch:7 step:6702 [D loss: 0.667217, acc.: 55.47%] [G loss: 0.718589]\n",
      "epoch:7 step:6703 [D loss: 0.691467, acc.: 47.66%] [G loss: 0.775816]\n",
      "epoch:7 step:6704 [D loss: 0.664743, acc.: 53.12%] [G loss: 0.750234]\n",
      "epoch:7 step:6705 [D loss: 0.690950, acc.: 52.34%] [G loss: 0.758298]\n",
      "epoch:7 step:6706 [D loss: 0.699095, acc.: 50.00%] [G loss: 0.749325]\n",
      "epoch:7 step:6707 [D loss: 0.693355, acc.: 42.19%] [G loss: 0.816329]\n",
      "epoch:7 step:6708 [D loss: 0.678762, acc.: 53.91%] [G loss: 0.774539]\n",
      "epoch:7 step:6709 [D loss: 0.668692, acc.: 59.38%] [G loss: 0.832952]\n",
      "epoch:7 step:6710 [D loss: 0.602865, acc.: 77.34%] [G loss: 0.863791]\n",
      "epoch:7 step:6711 [D loss: 0.601749, acc.: 68.75%] [G loss: 0.837731]\n",
      "epoch:7 step:6712 [D loss: 0.701758, acc.: 50.78%] [G loss: 0.825447]\n",
      "epoch:7 step:6713 [D loss: 0.668232, acc.: 61.72%] [G loss: 0.903210]\n",
      "epoch:7 step:6714 [D loss: 0.645082, acc.: 62.50%] [G loss: 0.822013]\n",
      "epoch:7 step:6715 [D loss: 0.667110, acc.: 58.59%] [G loss: 0.809118]\n",
      "epoch:7 step:6716 [D loss: 0.734066, acc.: 57.81%] [G loss: 0.848775]\n",
      "epoch:7 step:6717 [D loss: 0.699252, acc.: 53.12%] [G loss: 0.857939]\n",
      "epoch:7 step:6718 [D loss: 0.670956, acc.: 57.81%] [G loss: 0.798684]\n",
      "epoch:7 step:6719 [D loss: 0.735301, acc.: 47.66%] [G loss: 0.754667]\n",
      "epoch:7 step:6720 [D loss: 0.663426, acc.: 67.19%] [G loss: 0.927212]\n",
      "epoch:7 step:6721 [D loss: 0.670754, acc.: 55.47%] [G loss: 0.801055]\n",
      "epoch:7 step:6722 [D loss: 0.691383, acc.: 50.78%] [G loss: 0.865160]\n",
      "epoch:7 step:6723 [D loss: 0.698727, acc.: 52.34%] [G loss: 0.798284]\n",
      "epoch:7 step:6724 [D loss: 0.667322, acc.: 62.50%] [G loss: 0.797517]\n",
      "epoch:7 step:6725 [D loss: 0.700766, acc.: 46.09%] [G loss: 0.815493]\n",
      "epoch:7 step:6726 [D loss: 0.662369, acc.: 52.34%] [G loss: 0.844604]\n",
      "epoch:7 step:6727 [D loss: 0.647170, acc.: 60.94%] [G loss: 0.852044]\n",
      "epoch:7 step:6728 [D loss: 0.682307, acc.: 54.69%] [G loss: 0.856865]\n",
      "epoch:7 step:6729 [D loss: 0.650997, acc.: 67.19%] [G loss: 0.798544]\n",
      "epoch:7 step:6730 [D loss: 0.649543, acc.: 55.47%] [G loss: 0.804590]\n",
      "epoch:7 step:6731 [D loss: 0.700676, acc.: 53.12%] [G loss: 0.854375]\n",
      "epoch:7 step:6732 [D loss: 0.671203, acc.: 58.59%] [G loss: 0.815267]\n",
      "epoch:7 step:6733 [D loss: 0.656688, acc.: 64.84%] [G loss: 0.814959]\n",
      "epoch:7 step:6734 [D loss: 0.689140, acc.: 57.81%] [G loss: 0.706014]\n",
      "epoch:7 step:6735 [D loss: 0.666580, acc.: 64.84%] [G loss: 0.785734]\n",
      "epoch:7 step:6736 [D loss: 0.724659, acc.: 46.09%] [G loss: 0.786457]\n",
      "epoch:7 step:6737 [D loss: 0.706249, acc.: 50.00%] [G loss: 0.732089]\n",
      "epoch:7 step:6738 [D loss: 0.707815, acc.: 53.12%] [G loss: 0.724388]\n",
      "epoch:7 step:6739 [D loss: 0.689626, acc.: 53.91%] [G loss: 0.733247]\n",
      "epoch:7 step:6740 [D loss: 0.665671, acc.: 57.81%] [G loss: 0.747958]\n",
      "epoch:7 step:6741 [D loss: 0.705984, acc.: 55.47%] [G loss: 0.767333]\n",
      "epoch:7 step:6742 [D loss: 0.661619, acc.: 64.84%] [G loss: 0.828782]\n",
      "epoch:7 step:6743 [D loss: 0.650886, acc.: 57.81%] [G loss: 0.809073]\n",
      "epoch:7 step:6744 [D loss: 0.633282, acc.: 65.62%] [G loss: 0.869551]\n",
      "epoch:7 step:6745 [D loss: 0.675428, acc.: 57.81%] [G loss: 0.895829]\n",
      "epoch:7 step:6746 [D loss: 0.631216, acc.: 64.84%] [G loss: 0.856433]\n",
      "epoch:7 step:6747 [D loss: 0.684538, acc.: 60.94%] [G loss: 0.830939]\n",
      "epoch:7 step:6748 [D loss: 0.676039, acc.: 53.12%] [G loss: 0.787282]\n",
      "epoch:7 step:6749 [D loss: 0.718675, acc.: 54.69%] [G loss: 0.736947]\n",
      "epoch:7 step:6750 [D loss: 0.668806, acc.: 55.47%] [G loss: 0.780562]\n",
      "epoch:7 step:6751 [D loss: 0.732132, acc.: 46.88%] [G loss: 0.835350]\n",
      "epoch:7 step:6752 [D loss: 0.708506, acc.: 50.00%] [G loss: 0.838640]\n",
      "epoch:7 step:6753 [D loss: 0.668267, acc.: 65.62%] [G loss: 0.779950]\n",
      "epoch:7 step:6754 [D loss: 0.667561, acc.: 57.03%] [G loss: 0.791172]\n",
      "epoch:7 step:6755 [D loss: 0.667905, acc.: 58.59%] [G loss: 0.857399]\n",
      "epoch:7 step:6756 [D loss: 0.666344, acc.: 59.38%] [G loss: 0.940679]\n",
      "epoch:7 step:6757 [D loss: 0.629421, acc.: 63.28%] [G loss: 0.945103]\n",
      "epoch:7 step:6758 [D loss: 0.676142, acc.: 53.91%] [G loss: 0.933705]\n",
      "epoch:7 step:6759 [D loss: 0.705015, acc.: 50.00%] [G loss: 0.860481]\n",
      "epoch:7 step:6760 [D loss: 0.693856, acc.: 53.91%] [G loss: 0.799967]\n",
      "epoch:7 step:6761 [D loss: 0.696760, acc.: 53.91%] [G loss: 0.771476]\n",
      "epoch:7 step:6762 [D loss: 0.721011, acc.: 48.44%] [G loss: 0.690948]\n",
      "epoch:7 step:6763 [D loss: 0.591774, acc.: 59.38%] [G loss: 0.748262]\n",
      "epoch:7 step:6764 [D loss: 0.707205, acc.: 48.44%] [G loss: 0.754590]\n",
      "epoch:7 step:6765 [D loss: 0.644718, acc.: 61.72%] [G loss: 0.715057]\n",
      "epoch:7 step:6766 [D loss: 0.446100, acc.: 69.53%] [G loss: 0.826621]\n",
      "epoch:7 step:6767 [D loss: 0.633472, acc.: 68.75%] [G loss: 0.846721]\n",
      "epoch:7 step:6768 [D loss: 0.619705, acc.: 64.84%] [G loss: 0.882015]\n",
      "epoch:7 step:6769 [D loss: 0.654113, acc.: 60.94%] [G loss: 0.873241]\n",
      "epoch:7 step:6770 [D loss: 0.636383, acc.: 64.06%] [G loss: 0.785637]\n",
      "epoch:7 step:6771 [D loss: 0.657283, acc.: 60.94%] [G loss: 0.825268]\n",
      "epoch:7 step:6772 [D loss: 0.693891, acc.: 57.81%] [G loss: 0.759066]\n",
      "epoch:7 step:6773 [D loss: 0.714817, acc.: 53.12%] [G loss: 0.763587]\n",
      "epoch:7 step:6774 [D loss: 0.752852, acc.: 43.75%] [G loss: 0.334582]\n",
      "epoch:7 step:6775 [D loss: 0.538236, acc.: 59.38%] [G loss: 0.723841]\n",
      "epoch:7 step:6776 [D loss: 0.793388, acc.: 34.38%] [G loss: 0.711904]\n",
      "epoch:7 step:6777 [D loss: 0.695000, acc.: 52.34%] [G loss: 0.244323]\n",
      "epoch:7 step:6778 [D loss: 0.689513, acc.: 50.00%] [G loss: 0.246726]\n",
      "epoch:7 step:6779 [D loss: 0.734408, acc.: 40.62%] [G loss: 0.798549]\n",
      "epoch:7 step:6780 [D loss: 0.660391, acc.: 62.50%] [G loss: 0.830926]\n",
      "epoch:7 step:6781 [D loss: 0.689369, acc.: 53.12%] [G loss: 0.846711]\n",
      "epoch:7 step:6782 [D loss: 0.638056, acc.: 69.53%] [G loss: 0.863166]\n",
      "epoch:7 step:6783 [D loss: 0.687832, acc.: 56.25%] [G loss: 0.869480]\n",
      "epoch:7 step:6784 [D loss: 0.641212, acc.: 72.66%] [G loss: 0.873098]\n",
      "epoch:7 step:6785 [D loss: 0.654416, acc.: 57.81%] [G loss: 0.856771]\n",
      "epoch:7 step:6786 [D loss: 0.669044, acc.: 55.47%] [G loss: 0.838930]\n",
      "epoch:7 step:6787 [D loss: 0.669473, acc.: 55.47%] [G loss: 0.868376]\n",
      "epoch:7 step:6788 [D loss: 0.639055, acc.: 67.19%] [G loss: 0.847069]\n",
      "epoch:7 step:6789 [D loss: 0.573807, acc.: 77.34%] [G loss: 0.837883]\n",
      "epoch:7 step:6790 [D loss: 0.550210, acc.: 72.66%] [G loss: 0.834671]\n",
      "epoch:7 step:6791 [D loss: 0.576115, acc.: 70.31%] [G loss: 0.860653]\n",
      "epoch:7 step:6792 [D loss: 0.670865, acc.: 63.28%] [G loss: 0.910452]\n",
      "epoch:7 step:6793 [D loss: 0.710386, acc.: 52.34%] [G loss: 0.843730]\n",
      "epoch:7 step:6794 [D loss: 0.658259, acc.: 57.81%] [G loss: 0.849511]\n",
      "epoch:7 step:6795 [D loss: 0.712360, acc.: 47.66%] [G loss: 0.971033]\n",
      "epoch:7 step:6796 [D loss: 0.653181, acc.: 60.94%] [G loss: 0.900347]\n",
      "epoch:7 step:6797 [D loss: 0.700514, acc.: 53.12%] [G loss: 0.968286]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6798 [D loss: 0.686668, acc.: 52.34%] [G loss: 1.001957]\n",
      "epoch:7 step:6799 [D loss: 0.668067, acc.: 55.47%] [G loss: 0.920809]\n",
      "epoch:7 step:6800 [D loss: 0.677833, acc.: 51.56%] [G loss: 0.952559]\n",
      "##############\n",
      "[4.3641708  2.10595923 5.79938593 4.99286573 4.31981887 6.14579581\n",
      " 5.28758945 5.68770969 5.53594616 4.70154464]\n",
      "##########\n",
      "epoch:7 step:6801 [D loss: 0.667490, acc.: 57.81%] [G loss: 0.935408]\n",
      "epoch:7 step:6802 [D loss: 0.728258, acc.: 50.00%] [G loss: 0.699619]\n",
      "epoch:7 step:6803 [D loss: 0.688836, acc.: 51.56%] [G loss: 0.756000]\n",
      "epoch:7 step:6804 [D loss: 0.734288, acc.: 46.09%] [G loss: 0.757094]\n",
      "epoch:7 step:6805 [D loss: 0.720015, acc.: 46.09%] [G loss: 0.746065]\n",
      "epoch:7 step:6806 [D loss: 0.726559, acc.: 47.66%] [G loss: 0.788518]\n",
      "epoch:7 step:6807 [D loss: 0.656952, acc.: 60.94%] [G loss: 0.835350]\n",
      "epoch:7 step:6808 [D loss: 0.705653, acc.: 53.91%] [G loss: 0.809495]\n",
      "epoch:7 step:6809 [D loss: 0.711141, acc.: 58.59%] [G loss: 0.837312]\n",
      "epoch:7 step:6810 [D loss: 0.653792, acc.: 66.41%] [G loss: 0.782355]\n",
      "epoch:7 step:6811 [D loss: 0.689874, acc.: 58.59%] [G loss: 0.760215]\n",
      "epoch:7 step:6812 [D loss: 0.710754, acc.: 50.00%] [G loss: 0.759314]\n",
      "epoch:7 step:6813 [D loss: 0.671098, acc.: 66.41%] [G loss: 0.750371]\n",
      "epoch:7 step:6814 [D loss: 0.687115, acc.: 50.78%] [G loss: 0.783017]\n",
      "epoch:7 step:6815 [D loss: 0.677356, acc.: 55.47%] [G loss: 0.782368]\n",
      "epoch:7 step:6816 [D loss: 0.673374, acc.: 60.94%] [G loss: 0.739308]\n",
      "epoch:7 step:6817 [D loss: 0.685149, acc.: 55.47%] [G loss: 0.741755]\n",
      "epoch:7 step:6818 [D loss: 0.647392, acc.: 61.72%] [G loss: 0.684372]\n",
      "epoch:7 step:6819 [D loss: 0.683563, acc.: 57.03%] [G loss: 0.750737]\n",
      "epoch:7 step:6820 [D loss: 0.657530, acc.: 57.81%] [G loss: 0.710410]\n",
      "epoch:7 step:6821 [D loss: 0.676787, acc.: 58.59%] [G loss: 0.728009]\n",
      "epoch:7 step:6822 [D loss: 0.521264, acc.: 64.84%] [G loss: 0.766758]\n",
      "epoch:7 step:6823 [D loss: 0.653821, acc.: 64.06%] [G loss: 0.759137]\n",
      "epoch:7 step:6824 [D loss: 0.685576, acc.: 57.81%] [G loss: 0.717351]\n",
      "epoch:7 step:6825 [D loss: 0.691295, acc.: 60.16%] [G loss: 0.778791]\n",
      "epoch:7 step:6826 [D loss: 0.680581, acc.: 53.91%] [G loss: 0.724909]\n",
      "epoch:7 step:6827 [D loss: 0.715294, acc.: 48.44%] [G loss: 0.712261]\n",
      "epoch:7 step:6828 [D loss: 0.694012, acc.: 53.91%] [G loss: 0.800412]\n",
      "epoch:7 step:6829 [D loss: 0.708171, acc.: 50.78%] [G loss: 0.812960]\n",
      "epoch:7 step:6830 [D loss: 0.643733, acc.: 67.97%] [G loss: 0.853214]\n",
      "epoch:7 step:6831 [D loss: 0.661480, acc.: 56.25%] [G loss: 0.885194]\n",
      "epoch:7 step:6832 [D loss: 0.649107, acc.: 60.94%] [G loss: 0.843784]\n",
      "epoch:7 step:6833 [D loss: 0.619843, acc.: 70.31%] [G loss: 0.879156]\n",
      "epoch:7 step:6834 [D loss: 0.635559, acc.: 62.50%] [G loss: 0.862022]\n",
      "epoch:7 step:6835 [D loss: 0.602569, acc.: 71.09%] [G loss: 0.864040]\n",
      "epoch:7 step:6836 [D loss: 0.703706, acc.: 52.34%] [G loss: 0.501455]\n",
      "epoch:7 step:6837 [D loss: 0.680611, acc.: 57.81%] [G loss: 0.797279]\n",
      "epoch:7 step:6838 [D loss: 0.728780, acc.: 46.09%] [G loss: 0.815812]\n",
      "epoch:7 step:6839 [D loss: 0.689202, acc.: 54.69%] [G loss: 0.737383]\n",
      "epoch:7 step:6840 [D loss: 0.711122, acc.: 48.44%] [G loss: 0.772929]\n",
      "epoch:7 step:6841 [D loss: 0.691799, acc.: 56.25%] [G loss: 0.715651]\n",
      "epoch:7 step:6842 [D loss: 0.676061, acc.: 54.69%] [G loss: 0.727713]\n",
      "epoch:7 step:6843 [D loss: 0.639528, acc.: 68.75%] [G loss: 0.795784]\n",
      "epoch:7 step:6844 [D loss: 0.691736, acc.: 55.47%] [G loss: 0.756870]\n",
      "epoch:7 step:6845 [D loss: 0.660547, acc.: 57.81%] [G loss: 0.790878]\n",
      "epoch:7 step:6846 [D loss: 0.668545, acc.: 58.59%] [G loss: 0.735529]\n",
      "epoch:7 step:6847 [D loss: 0.676821, acc.: 53.12%] [G loss: 0.751271]\n",
      "epoch:7 step:6848 [D loss: 0.617610, acc.: 64.84%] [G loss: 0.696072]\n",
      "epoch:7 step:6849 [D loss: 0.653355, acc.: 57.03%] [G loss: 0.747862]\n",
      "epoch:7 step:6850 [D loss: 0.733610, acc.: 46.09%] [G loss: 0.790129]\n",
      "epoch:7 step:6851 [D loss: 0.644459, acc.: 59.38%] [G loss: 0.761522]\n",
      "epoch:7 step:6852 [D loss: 0.676437, acc.: 59.38%] [G loss: 0.836036]\n",
      "epoch:7 step:6853 [D loss: 0.725642, acc.: 47.66%] [G loss: 0.741066]\n",
      "epoch:7 step:6854 [D loss: 0.696592, acc.: 53.12%] [G loss: 0.830663]\n",
      "epoch:7 step:6855 [D loss: 0.694904, acc.: 48.44%] [G loss: 0.869670]\n",
      "epoch:7 step:6856 [D loss: 0.699585, acc.: 50.78%] [G loss: 0.818497]\n",
      "epoch:7 step:6857 [D loss: 0.672235, acc.: 59.38%] [G loss: 0.850406]\n",
      "epoch:7 step:6858 [D loss: 0.696305, acc.: 49.22%] [G loss: 0.806352]\n",
      "epoch:7 step:6859 [D loss: 0.657276, acc.: 63.28%] [G loss: 0.808283]\n",
      "epoch:7 step:6860 [D loss: 0.703525, acc.: 50.00%] [G loss: 0.753761]\n",
      "epoch:7 step:6861 [D loss: 0.671058, acc.: 59.38%] [G loss: 0.803330]\n",
      "epoch:7 step:6862 [D loss: 0.739193, acc.: 45.31%] [G loss: 0.783120]\n",
      "epoch:7 step:6863 [D loss: 0.721735, acc.: 50.78%] [G loss: 0.706443]\n",
      "epoch:7 step:6864 [D loss: 0.679521, acc.: 56.25%] [G loss: 0.781306]\n",
      "epoch:7 step:6865 [D loss: 0.676406, acc.: 57.81%] [G loss: 0.759267]\n",
      "epoch:7 step:6866 [D loss: 0.682949, acc.: 60.94%] [G loss: 0.766749]\n",
      "epoch:7 step:6867 [D loss: 0.686219, acc.: 51.56%] [G loss: 0.760781]\n",
      "epoch:7 step:6868 [D loss: 0.626471, acc.: 71.09%] [G loss: 0.752648]\n",
      "epoch:7 step:6869 [D loss: 0.664287, acc.: 61.72%] [G loss: 0.836493]\n",
      "epoch:7 step:6870 [D loss: 0.657337, acc.: 60.94%] [G loss: 0.793795]\n",
      "epoch:7 step:6871 [D loss: 0.673411, acc.: 61.72%] [G loss: 0.841869]\n",
      "epoch:7 step:6872 [D loss: 0.652803, acc.: 65.62%] [G loss: 0.832645]\n",
      "epoch:7 step:6873 [D loss: 0.612475, acc.: 69.53%] [G loss: 0.801858]\n",
      "epoch:7 step:6874 [D loss: 0.663703, acc.: 59.38%] [G loss: 0.792039]\n",
      "epoch:7 step:6875 [D loss: 0.712534, acc.: 46.09%] [G loss: 0.806944]\n",
      "epoch:7 step:6876 [D loss: 0.700225, acc.: 48.44%] [G loss: 0.744600]\n",
      "epoch:7 step:6877 [D loss: 0.681602, acc.: 55.47%] [G loss: 0.764012]\n",
      "epoch:7 step:6878 [D loss: 0.690207, acc.: 53.12%] [G loss: 0.714639]\n",
      "epoch:7 step:6879 [D loss: 0.726656, acc.: 40.62%] [G loss: 0.763203]\n",
      "epoch:7 step:6880 [D loss: 0.711100, acc.: 52.34%] [G loss: 0.799853]\n",
      "epoch:7 step:6881 [D loss: 0.671388, acc.: 57.03%] [G loss: 0.820983]\n",
      "epoch:7 step:6882 [D loss: 0.665630, acc.: 60.94%] [G loss: 0.829134]\n",
      "epoch:7 step:6883 [D loss: 0.667407, acc.: 57.81%] [G loss: 0.801312]\n",
      "epoch:7 step:6884 [D loss: 0.662701, acc.: 60.94%] [G loss: 0.798042]\n",
      "epoch:7 step:6885 [D loss: 0.703897, acc.: 59.38%] [G loss: 0.798597]\n",
      "epoch:7 step:6886 [D loss: 0.666877, acc.: 57.03%] [G loss: 0.736767]\n",
      "epoch:7 step:6887 [D loss: 0.680140, acc.: 51.56%] [G loss: 0.842819]\n",
      "epoch:7 step:6888 [D loss: 0.705878, acc.: 52.34%] [G loss: 0.615586]\n",
      "epoch:7 step:6889 [D loss: 0.681498, acc.: 53.91%] [G loss: 0.744096]\n",
      "epoch:7 step:6890 [D loss: 0.705955, acc.: 52.34%] [G loss: 0.758640]\n",
      "epoch:7 step:6891 [D loss: 0.667342, acc.: 60.16%] [G loss: 0.726667]\n",
      "epoch:7 step:6892 [D loss: 0.687595, acc.: 52.34%] [G loss: 0.765701]\n",
      "epoch:7 step:6893 [D loss: 0.652211, acc.: 57.03%] [G loss: 0.742676]\n",
      "epoch:7 step:6894 [D loss: 0.666601, acc.: 59.38%] [G loss: 0.811047]\n",
      "epoch:7 step:6895 [D loss: 0.590215, acc.: 71.09%] [G loss: 0.830636]\n",
      "epoch:7 step:6896 [D loss: 0.674813, acc.: 60.94%] [G loss: 0.810269]\n",
      "epoch:7 step:6897 [D loss: 0.629215, acc.: 64.84%] [G loss: 0.787832]\n",
      "epoch:7 step:6898 [D loss: 0.674964, acc.: 59.38%] [G loss: 0.800481]\n",
      "epoch:7 step:6899 [D loss: 0.700664, acc.: 49.22%] [G loss: 0.759815]\n",
      "epoch:7 step:6900 [D loss: 0.693870, acc.: 50.00%] [G loss: 0.747679]\n",
      "epoch:7 step:6901 [D loss: 0.635699, acc.: 58.59%] [G loss: 0.831952]\n",
      "epoch:7 step:6902 [D loss: 0.631640, acc.: 56.25%] [G loss: 0.737326]\n",
      "epoch:7 step:6903 [D loss: 0.586228, acc.: 69.53%] [G loss: 0.842121]\n",
      "epoch:7 step:6904 [D loss: 0.713570, acc.: 50.78%] [G loss: 0.750251]\n",
      "epoch:7 step:6905 [D loss: 0.594810, acc.: 70.31%] [G loss: 0.799449]\n",
      "epoch:7 step:6906 [D loss: 0.556836, acc.: 73.44%] [G loss: 0.887884]\n",
      "epoch:7 step:6907 [D loss: 0.832301, acc.: 32.81%] [G loss: 0.894329]\n",
      "epoch:7 step:6908 [D loss: 0.729433, acc.: 42.97%] [G loss: 0.883859]\n",
      "epoch:7 step:6909 [D loss: 0.730361, acc.: 44.53%] [G loss: 0.882234]\n",
      "epoch:7 step:6910 [D loss: 0.712747, acc.: 43.75%] [G loss: 0.845064]\n",
      "epoch:7 step:6911 [D loss: 0.676129, acc.: 55.47%] [G loss: 0.882339]\n",
      "epoch:7 step:6912 [D loss: 0.687725, acc.: 52.34%] [G loss: 0.856460]\n",
      "epoch:7 step:6913 [D loss: 0.661720, acc.: 60.94%] [G loss: 0.921938]\n",
      "epoch:7 step:6914 [D loss: 0.681769, acc.: 60.94%] [G loss: 0.785325]\n",
      "epoch:7 step:6915 [D loss: 0.696512, acc.: 53.91%] [G loss: 0.845367]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6916 [D loss: 0.673438, acc.: 57.81%] [G loss: 0.821148]\n",
      "epoch:7 step:6917 [D loss: 0.683594, acc.: 53.91%] [G loss: 0.766056]\n",
      "epoch:7 step:6918 [D loss: 0.654044, acc.: 62.50%] [G loss: 0.849414]\n",
      "epoch:7 step:6919 [D loss: 0.689377, acc.: 54.69%] [G loss: 0.763421]\n",
      "epoch:7 step:6920 [D loss: 0.661860, acc.: 60.16%] [G loss: 0.804808]\n",
      "epoch:7 step:6921 [D loss: 0.736231, acc.: 42.19%] [G loss: 0.777792]\n",
      "epoch:7 step:6922 [D loss: 0.709496, acc.: 50.78%] [G loss: 0.745445]\n",
      "epoch:7 step:6923 [D loss: 0.685476, acc.: 56.25%] [G loss: 0.757776]\n",
      "epoch:7 step:6924 [D loss: 0.710111, acc.: 54.69%] [G loss: 0.781532]\n",
      "epoch:7 step:6925 [D loss: 0.696682, acc.: 55.47%] [G loss: 0.738482]\n",
      "epoch:7 step:6926 [D loss: 0.657512, acc.: 66.41%] [G loss: 0.766459]\n",
      "epoch:7 step:6927 [D loss: 0.659099, acc.: 61.72%] [G loss: 0.751897]\n",
      "epoch:7 step:6928 [D loss: 0.672686, acc.: 63.28%] [G loss: 0.758563]\n",
      "epoch:7 step:6929 [D loss: 0.694800, acc.: 50.00%] [G loss: 0.740554]\n",
      "epoch:7 step:6930 [D loss: 0.557635, acc.: 67.19%] [G loss: 0.725999]\n",
      "epoch:7 step:6931 [D loss: 0.667903, acc.: 68.75%] [G loss: 0.713635]\n",
      "epoch:7 step:6932 [D loss: 0.675325, acc.: 59.38%] [G loss: 0.388871]\n",
      "epoch:7 step:6933 [D loss: 0.689973, acc.: 58.59%] [G loss: 0.737466]\n",
      "epoch:7 step:6934 [D loss: 0.693566, acc.: 51.56%] [G loss: 0.739210]\n",
      "epoch:7 step:6935 [D loss: 0.686431, acc.: 57.81%] [G loss: 0.638352]\n",
      "epoch:7 step:6936 [D loss: 0.701790, acc.: 53.91%] [G loss: 0.724231]\n",
      "epoch:7 step:6937 [D loss: 0.652710, acc.: 61.72%] [G loss: 0.766102]\n",
      "epoch:7 step:6938 [D loss: 0.683326, acc.: 53.91%] [G loss: 0.744884]\n",
      "epoch:7 step:6939 [D loss: 0.705425, acc.: 54.69%] [G loss: 0.692930]\n",
      "epoch:7 step:6940 [D loss: 0.698494, acc.: 49.22%] [G loss: 0.754464]\n",
      "epoch:7 step:6941 [D loss: 0.761277, acc.: 49.22%] [G loss: 0.767282]\n",
      "epoch:7 step:6942 [D loss: 0.683735, acc.: 57.81%] [G loss: 0.791170]\n",
      "epoch:7 step:6943 [D loss: 0.667184, acc.: 60.16%] [G loss: 0.782263]\n",
      "epoch:7 step:6944 [D loss: 0.700618, acc.: 53.91%] [G loss: 0.810776]\n",
      "epoch:7 step:6945 [D loss: 0.726124, acc.: 46.09%] [G loss: 0.760678]\n",
      "epoch:7 step:6946 [D loss: 0.687987, acc.: 57.81%] [G loss: 0.721572]\n",
      "epoch:7 step:6947 [D loss: 0.760580, acc.: 41.41%] [G loss: 0.764340]\n",
      "epoch:7 step:6948 [D loss: 0.702214, acc.: 48.44%] [G loss: 0.759975]\n",
      "epoch:7 step:6949 [D loss: 0.689467, acc.: 56.25%] [G loss: 0.791578]\n",
      "epoch:7 step:6950 [D loss: 0.686310, acc.: 58.59%] [G loss: 0.806741]\n",
      "epoch:7 step:6951 [D loss: 0.688458, acc.: 52.34%] [G loss: 0.748041]\n",
      "epoch:7 step:6952 [D loss: 0.670256, acc.: 59.38%] [G loss: 0.773178]\n",
      "epoch:7 step:6953 [D loss: 0.677856, acc.: 55.47%] [G loss: 0.776226]\n",
      "epoch:7 step:6954 [D loss: 0.676125, acc.: 60.94%] [G loss: 0.815106]\n",
      "epoch:7 step:6955 [D loss: 0.713292, acc.: 52.34%] [G loss: 0.777316]\n",
      "epoch:7 step:6956 [D loss: 0.690311, acc.: 57.03%] [G loss: 0.716942]\n",
      "epoch:7 step:6957 [D loss: 0.661088, acc.: 60.16%] [G loss: 0.752902]\n",
      "epoch:7 step:6958 [D loss: 0.625012, acc.: 72.66%] [G loss: 0.762051]\n",
      "epoch:7 step:6959 [D loss: 0.640375, acc.: 61.72%] [G loss: 0.783063]\n",
      "epoch:7 step:6960 [D loss: 0.679229, acc.: 60.94%] [G loss: 0.799021]\n",
      "epoch:7 step:6961 [D loss: 0.684480, acc.: 57.81%] [G loss: 0.793268]\n",
      "epoch:7 step:6962 [D loss: 0.672594, acc.: 60.94%] [G loss: 0.818670]\n",
      "epoch:7 step:6963 [D loss: 0.591720, acc.: 67.19%] [G loss: 0.810016]\n",
      "epoch:7 step:6964 [D loss: 0.560736, acc.: 78.12%] [G loss: 0.714272]\n",
      "epoch:7 step:6965 [D loss: 0.512635, acc.: 82.03%] [G loss: 0.689473]\n",
      "epoch:7 step:6966 [D loss: 0.599233, acc.: 64.84%] [G loss: 0.687312]\n",
      "epoch:7 step:6967 [D loss: 0.653086, acc.: 57.03%] [G loss: 0.794763]\n",
      "epoch:7 step:6968 [D loss: 0.571025, acc.: 67.97%] [G loss: 0.574091]\n",
      "epoch:7 step:6969 [D loss: 0.813429, acc.: 41.41%] [G loss: 0.589307]\n",
      "epoch:7 step:6970 [D loss: 0.782849, acc.: 37.50%] [G loss: 0.907718]\n",
      "epoch:7 step:6971 [D loss: 0.729998, acc.: 43.75%] [G loss: 0.897705]\n",
      "epoch:7 step:6972 [D loss: 0.683185, acc.: 56.25%] [G loss: 0.833746]\n",
      "epoch:7 step:6973 [D loss: 0.749131, acc.: 46.09%] [G loss: 0.818783]\n",
      "epoch:7 step:6974 [D loss: 0.724677, acc.: 48.44%] [G loss: 0.880875]\n",
      "epoch:7 step:6975 [D loss: 0.694760, acc.: 53.12%] [G loss: 0.857779]\n",
      "epoch:7 step:6976 [D loss: 0.688424, acc.: 57.03%] [G loss: 0.853586]\n",
      "epoch:7 step:6977 [D loss: 0.711125, acc.: 52.34%] [G loss: 0.777517]\n",
      "epoch:7 step:6978 [D loss: 0.705944, acc.: 54.69%] [G loss: 0.778802]\n",
      "epoch:7 step:6979 [D loss: 0.677958, acc.: 60.16%] [G loss: 0.715499]\n",
      "epoch:7 step:6980 [D loss: 0.742757, acc.: 35.94%] [G loss: 0.725486]\n",
      "epoch:7 step:6981 [D loss: 0.713025, acc.: 40.62%] [G loss: 0.708982]\n",
      "epoch:7 step:6982 [D loss: 0.740705, acc.: 40.62%] [G loss: 0.731621]\n",
      "epoch:7 step:6983 [D loss: 0.681599, acc.: 59.38%] [G loss: 0.763921]\n",
      "epoch:7 step:6984 [D loss: 0.671959, acc.: 62.50%] [G loss: 0.712810]\n",
      "epoch:7 step:6985 [D loss: 0.720745, acc.: 40.62%] [G loss: 0.797461]\n",
      "epoch:7 step:6986 [D loss: 0.675571, acc.: 61.72%] [G loss: 0.754548]\n",
      "epoch:7 step:6987 [D loss: 0.616282, acc.: 69.53%] [G loss: 0.812162]\n",
      "epoch:7 step:6988 [D loss: 0.674908, acc.: 58.59%] [G loss: 0.780310]\n",
      "epoch:7 step:6989 [D loss: 0.653244, acc.: 60.16%] [G loss: 0.764626]\n",
      "epoch:7 step:6990 [D loss: 0.716858, acc.: 53.91%] [G loss: 0.861639]\n",
      "epoch:7 step:6991 [D loss: 0.728033, acc.: 45.31%] [G loss: 0.744801]\n",
      "epoch:7 step:6992 [D loss: 0.675468, acc.: 57.81%] [G loss: 0.787690]\n",
      "epoch:7 step:6993 [D loss: 0.683914, acc.: 54.69%] [G loss: 0.831120]\n",
      "epoch:7 step:6994 [D loss: 0.650489, acc.: 62.50%] [G loss: 0.832450]\n",
      "epoch:7 step:6995 [D loss: 0.664325, acc.: 60.16%] [G loss: 0.784643]\n",
      "epoch:7 step:6996 [D loss: 0.713633, acc.: 49.22%] [G loss: 0.751512]\n",
      "epoch:7 step:6997 [D loss: 0.707519, acc.: 47.66%] [G loss: 0.733809]\n",
      "epoch:7 step:6998 [D loss: 0.699499, acc.: 50.78%] [G loss: 0.784013]\n",
      "epoch:7 step:6999 [D loss: 0.681560, acc.: 53.12%] [G loss: 0.761427]\n",
      "epoch:7 step:7000 [D loss: 0.683218, acc.: 53.91%] [G loss: 0.775580]\n",
      "##############\n",
      "[4.14582631 2.67495062 6.67734879 5.66119789 4.70510965 6.18286832\n",
      " 5.27880557 5.50121193 5.77245501 5.02242467]\n",
      "##########\n",
      "epoch:7 step:7001 [D loss: 0.695762, acc.: 54.69%] [G loss: 0.770968]\n",
      "epoch:7 step:7002 [D loss: 0.660012, acc.: 61.72%] [G loss: 0.783195]\n",
      "epoch:7 step:7003 [D loss: 0.684940, acc.: 60.94%] [G loss: 0.747497]\n",
      "epoch:7 step:7004 [D loss: 0.649619, acc.: 62.50%] [G loss: 0.745198]\n",
      "epoch:7 step:7005 [D loss: 0.672805, acc.: 56.25%] [G loss: 0.807729]\n",
      "epoch:7 step:7006 [D loss: 0.686279, acc.: 55.47%] [G loss: 0.786575]\n",
      "epoch:7 step:7007 [D loss: 0.667335, acc.: 57.03%] [G loss: 0.826933]\n",
      "epoch:7 step:7008 [D loss: 0.657532, acc.: 64.06%] [G loss: 0.893121]\n",
      "epoch:7 step:7009 [D loss: 0.637467, acc.: 71.09%] [G loss: 0.831219]\n",
      "epoch:7 step:7010 [D loss: 0.573675, acc.: 82.03%] [G loss: 0.933619]\n",
      "epoch:7 step:7011 [D loss: 0.600040, acc.: 78.12%] [G loss: 0.922241]\n",
      "epoch:7 step:7012 [D loss: 0.626972, acc.: 71.09%] [G loss: 1.141705]\n",
      "epoch:7 step:7013 [D loss: 0.638025, acc.: 60.16%] [G loss: 1.082231]\n",
      "epoch:7 step:7014 [D loss: 0.558551, acc.: 67.97%] [G loss: 1.045727]\n",
      "epoch:7 step:7015 [D loss: 0.602807, acc.: 60.16%] [G loss: 1.138746]\n",
      "epoch:7 step:7016 [D loss: 0.527554, acc.: 75.00%] [G loss: 1.376999]\n",
      "epoch:7 step:7017 [D loss: 0.829766, acc.: 49.22%] [G loss: 0.617968]\n",
      "epoch:7 step:7018 [D loss: 0.787895, acc.: 43.75%] [G loss: 0.801010]\n",
      "epoch:7 step:7019 [D loss: 0.646602, acc.: 67.97%] [G loss: 0.814809]\n",
      "epoch:7 step:7020 [D loss: 0.870794, acc.: 23.44%] [G loss: 0.707538]\n",
      "epoch:7 step:7021 [D loss: 0.756967, acc.: 46.88%] [G loss: 0.849263]\n",
      "epoch:7 step:7022 [D loss: 0.655264, acc.: 63.28%] [G loss: 0.857092]\n",
      "epoch:7 step:7023 [D loss: 0.674061, acc.: 64.84%] [G loss: 0.901896]\n",
      "epoch:7 step:7024 [D loss: 0.672673, acc.: 59.38%] [G loss: 0.819112]\n",
      "epoch:7 step:7025 [D loss: 0.700317, acc.: 59.38%] [G loss: 0.829881]\n",
      "epoch:7 step:7026 [D loss: 0.675550, acc.: 59.38%] [G loss: 0.865382]\n",
      "epoch:7 step:7027 [D loss: 0.650770, acc.: 68.75%] [G loss: 0.851617]\n",
      "epoch:7 step:7028 [D loss: 0.670509, acc.: 57.03%] [G loss: 0.736395]\n",
      "epoch:7 step:7029 [D loss: 0.661618, acc.: 59.38%] [G loss: 0.767582]\n",
      "epoch:7 step:7030 [D loss: 0.668684, acc.: 58.59%] [G loss: 0.775919]\n",
      "epoch:7 step:7031 [D loss: 0.675971, acc.: 58.59%] [G loss: 0.745945]\n",
      "epoch:7 step:7032 [D loss: 0.726641, acc.: 47.66%] [G loss: 0.778682]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7033 [D loss: 0.690261, acc.: 50.00%] [G loss: 0.833578]\n",
      "epoch:7 step:7034 [D loss: 0.657425, acc.: 58.59%] [G loss: 0.845152]\n",
      "epoch:7 step:7035 [D loss: 0.698224, acc.: 50.00%] [G loss: 0.850691]\n",
      "epoch:7 step:7036 [D loss: 0.686165, acc.: 56.25%] [G loss: 0.759979]\n",
      "epoch:7 step:7037 [D loss: 0.704118, acc.: 43.75%] [G loss: 0.785125]\n",
      "epoch:7 step:7038 [D loss: 0.697473, acc.: 50.78%] [G loss: 0.780002]\n",
      "epoch:7 step:7039 [D loss: 0.696046, acc.: 50.78%] [G loss: 0.612401]\n",
      "epoch:7 step:7040 [D loss: 0.696250, acc.: 50.78%] [G loss: 0.838354]\n",
      "epoch:7 step:7041 [D loss: 0.675835, acc.: 58.59%] [G loss: 0.815768]\n",
      "epoch:7 step:7042 [D loss: 0.653815, acc.: 61.72%] [G loss: 0.801942]\n",
      "epoch:7 step:7043 [D loss: 0.623093, acc.: 65.62%] [G loss: 0.855047]\n",
      "epoch:7 step:7044 [D loss: 0.645175, acc.: 59.38%] [G loss: 0.910684]\n",
      "epoch:7 step:7045 [D loss: 0.626841, acc.: 65.62%] [G loss: 0.738689]\n",
      "epoch:7 step:7046 [D loss: 0.608440, acc.: 73.44%] [G loss: 0.842481]\n",
      "epoch:7 step:7047 [D loss: 0.616032, acc.: 69.53%] [G loss: 0.909563]\n",
      "epoch:7 step:7048 [D loss: 0.683085, acc.: 65.62%] [G loss: 0.785340]\n",
      "epoch:7 step:7049 [D loss: 0.713336, acc.: 50.00%] [G loss: 0.810505]\n",
      "epoch:7 step:7050 [D loss: 0.711608, acc.: 56.25%] [G loss: 0.784719]\n",
      "epoch:7 step:7051 [D loss: 0.751021, acc.: 39.84%] [G loss: 0.660663]\n",
      "epoch:7 step:7052 [D loss: 0.692597, acc.: 51.56%] [G loss: 0.735393]\n",
      "epoch:7 step:7053 [D loss: 0.758084, acc.: 40.62%] [G loss: 0.919891]\n",
      "epoch:7 step:7054 [D loss: 0.642944, acc.: 67.19%] [G loss: 0.849962]\n",
      "epoch:7 step:7055 [D loss: 0.682893, acc.: 56.25%] [G loss: 1.018022]\n",
      "epoch:7 step:7056 [D loss: 0.683284, acc.: 60.16%] [G loss: 0.827921]\n",
      "epoch:7 step:7057 [D loss: 0.573473, acc.: 67.97%] [G loss: 0.948829]\n",
      "epoch:7 step:7058 [D loss: 0.505136, acc.: 91.41%] [G loss: 0.800024]\n",
      "epoch:7 step:7059 [D loss: 0.850243, acc.: 32.03%] [G loss: 0.999239]\n",
      "epoch:7 step:7060 [D loss: 0.706190, acc.: 48.44%] [G loss: 0.806591]\n",
      "epoch:7 step:7061 [D loss: 0.722129, acc.: 50.00%] [G loss: 0.819766]\n",
      "epoch:7 step:7062 [D loss: 0.718243, acc.: 49.22%] [G loss: 0.888754]\n",
      "epoch:7 step:7063 [D loss: 0.657092, acc.: 64.84%] [G loss: 0.843870]\n",
      "epoch:7 step:7064 [D loss: 0.664646, acc.: 60.16%] [G loss: 0.834754]\n",
      "epoch:7 step:7065 [D loss: 0.689744, acc.: 52.34%] [G loss: 0.896882]\n",
      "epoch:7 step:7066 [D loss: 0.664802, acc.: 63.28%] [G loss: 0.913722]\n",
      "epoch:7 step:7067 [D loss: 0.615198, acc.: 65.62%] [G loss: 0.840425]\n",
      "epoch:7 step:7068 [D loss: 0.751276, acc.: 42.97%] [G loss: 0.806915]\n",
      "epoch:7 step:7069 [D loss: 0.711998, acc.: 53.12%] [G loss: 0.774090]\n",
      "epoch:7 step:7070 [D loss: 0.681512, acc.: 57.03%] [G loss: 0.825353]\n",
      "epoch:7 step:7071 [D loss: 0.653600, acc.: 63.28%] [G loss: 0.790904]\n",
      "epoch:7 step:7072 [D loss: 0.651270, acc.: 56.25%] [G loss: 0.759476]\n",
      "epoch:7 step:7073 [D loss: 0.681198, acc.: 61.72%] [G loss: 0.707675]\n",
      "epoch:7 step:7074 [D loss: 0.672333, acc.: 58.59%] [G loss: 0.757454]\n",
      "epoch:7 step:7075 [D loss: 0.671828, acc.: 60.94%] [G loss: 0.754704]\n",
      "epoch:7 step:7076 [D loss: 0.710008, acc.: 53.91%] [G loss: 0.750187]\n",
      "epoch:7 step:7077 [D loss: 0.687818, acc.: 50.78%] [G loss: 0.776297]\n",
      "epoch:7 step:7078 [D loss: 0.662242, acc.: 63.28%] [G loss: 0.763478]\n",
      "epoch:7 step:7079 [D loss: 0.678229, acc.: 57.03%] [G loss: 0.765909]\n",
      "epoch:7 step:7080 [D loss: 0.671959, acc.: 58.59%] [G loss: 0.763443]\n",
      "epoch:7 step:7081 [D loss: 0.680035, acc.: 60.16%] [G loss: 0.775255]\n",
      "epoch:7 step:7082 [D loss: 0.677326, acc.: 57.03%] [G loss: 0.720974]\n",
      "epoch:7 step:7083 [D loss: 0.633442, acc.: 68.75%] [G loss: 0.730341]\n",
      "epoch:7 step:7084 [D loss: 0.740354, acc.: 38.28%] [G loss: 0.787670]\n",
      "epoch:7 step:7085 [D loss: 0.692797, acc.: 53.91%] [G loss: 0.778008]\n",
      "epoch:7 step:7086 [D loss: 0.654254, acc.: 64.06%] [G loss: 0.844403]\n",
      "epoch:7 step:7087 [D loss: 0.727797, acc.: 45.31%] [G loss: 0.847615]\n",
      "epoch:7 step:7088 [D loss: 0.680485, acc.: 52.34%] [G loss: 0.802935]\n",
      "epoch:7 step:7089 [D loss: 0.643518, acc.: 62.50%] [G loss: 0.796872]\n",
      "epoch:7 step:7090 [D loss: 0.717983, acc.: 47.66%] [G loss: 0.818614]\n",
      "epoch:7 step:7091 [D loss: 0.687057, acc.: 55.47%] [G loss: 0.827442]\n",
      "epoch:7 step:7092 [D loss: 0.696239, acc.: 51.56%] [G loss: 0.797836]\n",
      "epoch:7 step:7093 [D loss: 0.677244, acc.: 56.25%] [G loss: 0.829604]\n",
      "epoch:7 step:7094 [D loss: 0.686254, acc.: 55.47%] [G loss: 0.808213]\n",
      "epoch:7 step:7095 [D loss: 0.669686, acc.: 60.16%] [G loss: 0.838230]\n",
      "epoch:7 step:7096 [D loss: 0.681219, acc.: 53.91%] [G loss: 0.807050]\n",
      "epoch:7 step:7097 [D loss: 0.684225, acc.: 57.03%] [G loss: 0.887431]\n",
      "epoch:7 step:7098 [D loss: 0.652854, acc.: 61.72%] [G loss: 0.835881]\n",
      "epoch:7 step:7099 [D loss: 0.683326, acc.: 58.59%] [G loss: 0.775058]\n",
      "epoch:7 step:7100 [D loss: 0.673789, acc.: 63.28%] [G loss: 0.785882]\n",
      "epoch:7 step:7101 [D loss: 0.696652, acc.: 47.66%] [G loss: 0.734235]\n",
      "epoch:7 step:7102 [D loss: 0.536175, acc.: 67.97%] [G loss: 0.835077]\n",
      "epoch:7 step:7103 [D loss: 0.663636, acc.: 60.94%] [G loss: 0.752185]\n",
      "epoch:7 step:7104 [D loss: 0.653662, acc.: 59.38%] [G loss: 0.830043]\n",
      "epoch:7 step:7105 [D loss: 0.665912, acc.: 67.97%] [G loss: 0.869133]\n",
      "epoch:7 step:7106 [D loss: 0.694923, acc.: 53.12%] [G loss: 0.861114]\n",
      "epoch:7 step:7107 [D loss: 0.672275, acc.: 60.16%] [G loss: 0.854022]\n",
      "epoch:7 step:7108 [D loss: 0.618239, acc.: 67.97%] [G loss: 0.843493]\n",
      "epoch:7 step:7109 [D loss: 0.449487, acc.: 71.88%] [G loss: 0.826878]\n",
      "epoch:7 step:7110 [D loss: 0.663129, acc.: 62.50%] [G loss: 0.815769]\n",
      "epoch:7 step:7111 [D loss: 0.644508, acc.: 64.06%] [G loss: 0.856303]\n",
      "epoch:7 step:7112 [D loss: 0.685473, acc.: 57.03%] [G loss: 0.791479]\n",
      "epoch:7 step:7113 [D loss: 0.605782, acc.: 73.44%] [G loss: 0.790992]\n",
      "epoch:7 step:7114 [D loss: 0.642274, acc.: 61.72%] [G loss: 0.867787]\n",
      "epoch:7 step:7115 [D loss: 0.690727, acc.: 55.47%] [G loss: 0.758816]\n",
      "epoch:7 step:7116 [D loss: 0.662353, acc.: 66.41%] [G loss: 0.762912]\n",
      "epoch:7 step:7117 [D loss: 0.657301, acc.: 60.16%] [G loss: 0.799798]\n",
      "epoch:7 step:7118 [D loss: 0.791151, acc.: 42.19%] [G loss: 0.733599]\n",
      "epoch:7 step:7119 [D loss: 0.731687, acc.: 47.66%] [G loss: 0.771686]\n",
      "epoch:7 step:7120 [D loss: 0.676970, acc.: 60.16%] [G loss: 0.832362]\n",
      "epoch:7 step:7121 [D loss: 0.711302, acc.: 48.44%] [G loss: 0.775278]\n",
      "epoch:7 step:7122 [D loss: 0.703557, acc.: 51.56%] [G loss: 0.786707]\n",
      "epoch:7 step:7123 [D loss: 0.685780, acc.: 50.00%] [G loss: 0.763628]\n",
      "epoch:7 step:7124 [D loss: 0.679302, acc.: 62.50%] [G loss: 0.786911]\n",
      "epoch:7 step:7125 [D loss: 0.640797, acc.: 59.38%] [G loss: 0.751564]\n",
      "epoch:7 step:7126 [D loss: 0.594772, acc.: 67.97%] [G loss: 0.749467]\n",
      "epoch:7 step:7127 [D loss: 0.632610, acc.: 64.84%] [G loss: 0.821851]\n",
      "epoch:7 step:7128 [D loss: 0.670071, acc.: 64.06%] [G loss: 0.811329]\n",
      "epoch:7 step:7129 [D loss: 0.674532, acc.: 55.47%] [G loss: 0.760647]\n",
      "epoch:7 step:7130 [D loss: 0.707009, acc.: 49.22%] [G loss: 0.758024]\n",
      "epoch:7 step:7131 [D loss: 0.649541, acc.: 64.06%] [G loss: 0.816738]\n",
      "epoch:7 step:7132 [D loss: 0.638993, acc.: 62.50%] [G loss: 0.746804]\n",
      "epoch:7 step:7133 [D loss: 0.663304, acc.: 57.81%] [G loss: 0.795969]\n",
      "epoch:7 step:7134 [D loss: 0.635517, acc.: 64.06%] [G loss: 0.855688]\n",
      "epoch:7 step:7135 [D loss: 0.643758, acc.: 66.41%] [G loss: 0.873163]\n",
      "epoch:7 step:7136 [D loss: 0.670659, acc.: 57.81%] [G loss: 0.862240]\n",
      "epoch:7 step:7137 [D loss: 0.630316, acc.: 67.19%] [G loss: 0.873240]\n",
      "epoch:7 step:7138 [D loss: 0.600981, acc.: 77.34%] [G loss: 0.874132]\n",
      "epoch:7 step:7139 [D loss: 0.795404, acc.: 39.06%] [G loss: 0.668287]\n",
      "epoch:7 step:7140 [D loss: 0.730685, acc.: 49.22%] [G loss: 0.846605]\n",
      "epoch:7 step:7141 [D loss: 0.674768, acc.: 56.25%] [G loss: 0.920321]\n",
      "epoch:7 step:7142 [D loss: 0.721800, acc.: 48.44%] [G loss: 0.810728]\n",
      "epoch:7 step:7143 [D loss: 0.740751, acc.: 38.28%] [G loss: 0.819805]\n",
      "epoch:7 step:7144 [D loss: 0.699274, acc.: 54.69%] [G loss: 0.843547]\n",
      "epoch:7 step:7145 [D loss: 0.691703, acc.: 48.44%] [G loss: 0.847772]\n",
      "epoch:7 step:7146 [D loss: 0.679467, acc.: 59.38%] [G loss: 0.775919]\n",
      "epoch:7 step:7147 [D loss: 0.634090, acc.: 70.31%] [G loss: 0.815377]\n",
      "epoch:7 step:7148 [D loss: 0.620509, acc.: 68.75%] [G loss: 0.883315]\n",
      "epoch:7 step:7149 [D loss: 0.713099, acc.: 57.03%] [G loss: 0.820193]\n",
      "epoch:7 step:7150 [D loss: 0.731468, acc.: 48.44%] [G loss: 0.864322]\n",
      "epoch:7 step:7151 [D loss: 0.656657, acc.: 64.84%] [G loss: 0.946051]\n",
      "epoch:7 step:7152 [D loss: 0.650960, acc.: 60.94%] [G loss: 0.862967]\n",
      "epoch:7 step:7153 [D loss: 0.690001, acc.: 51.56%] [G loss: 0.845401]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7154 [D loss: 0.648820, acc.: 67.19%] [G loss: 0.893177]\n",
      "epoch:7 step:7155 [D loss: 0.530894, acc.: 82.03%] [G loss: 0.866791]\n",
      "epoch:7 step:7156 [D loss: 0.777204, acc.: 37.50%] [G loss: 0.776405]\n",
      "epoch:7 step:7157 [D loss: 0.648175, acc.: 63.28%] [G loss: 0.799472]\n",
      "epoch:7 step:7158 [D loss: 0.679609, acc.: 53.12%] [G loss: 0.777876]\n",
      "epoch:7 step:7159 [D loss: 0.676098, acc.: 57.03%] [G loss: 0.750921]\n",
      "epoch:7 step:7160 [D loss: 0.707818, acc.: 50.78%] [G loss: 0.788096]\n",
      "epoch:7 step:7161 [D loss: 0.654679, acc.: 60.16%] [G loss: 0.722494]\n",
      "epoch:7 step:7162 [D loss: 0.682997, acc.: 47.66%] [G loss: 0.839799]\n",
      "epoch:7 step:7163 [D loss: 0.552254, acc.: 56.25%] [G loss: 0.806570]\n",
      "epoch:7 step:7164 [D loss: 0.702774, acc.: 46.88%] [G loss: 0.869747]\n",
      "epoch:7 step:7165 [D loss: 0.653939, acc.: 62.50%] [G loss: 0.828024]\n",
      "epoch:7 step:7166 [D loss: 0.681312, acc.: 59.38%] [G loss: 0.843452]\n",
      "epoch:7 step:7167 [D loss: 0.689345, acc.: 53.91%] [G loss: 0.832343]\n",
      "epoch:7 step:7168 [D loss: 0.650593, acc.: 62.50%] [G loss: 0.748883]\n",
      "epoch:7 step:7169 [D loss: 0.696266, acc.: 56.25%] [G loss: 0.750725]\n",
      "epoch:7 step:7170 [D loss: 0.668180, acc.: 60.94%] [G loss: 0.779134]\n",
      "epoch:7 step:7171 [D loss: 0.893466, acc.: 39.84%] [G loss: 0.798216]\n",
      "epoch:7 step:7172 [D loss: 0.669831, acc.: 61.72%] [G loss: 0.810809]\n",
      "epoch:7 step:7173 [D loss: 0.704294, acc.: 51.56%] [G loss: 0.795766]\n",
      "epoch:7 step:7174 [D loss: 0.692660, acc.: 50.78%] [G loss: 0.801533]\n",
      "epoch:7 step:7175 [D loss: 0.685419, acc.: 50.78%] [G loss: 0.711795]\n",
      "epoch:7 step:7176 [D loss: 0.692809, acc.: 57.03%] [G loss: 0.787526]\n",
      "epoch:7 step:7177 [D loss: 0.684408, acc.: 53.91%] [G loss: 0.761486]\n",
      "epoch:7 step:7178 [D loss: 0.654461, acc.: 62.50%] [G loss: 0.738815]\n",
      "epoch:7 step:7179 [D loss: 0.661708, acc.: 63.28%] [G loss: 0.759460]\n",
      "epoch:7 step:7180 [D loss: 0.679393, acc.: 60.16%] [G loss: 0.764899]\n",
      "epoch:7 step:7181 [D loss: 0.744709, acc.: 38.28%] [G loss: 0.789332]\n",
      "epoch:7 step:7182 [D loss: 0.763055, acc.: 26.56%] [G loss: 0.713284]\n",
      "epoch:7 step:7183 [D loss: 0.718826, acc.: 42.97%] [G loss: 0.763022]\n",
      "epoch:7 step:7184 [D loss: 0.679196, acc.: 58.59%] [G loss: 0.795045]\n",
      "epoch:7 step:7185 [D loss: 0.687697, acc.: 60.16%] [G loss: 0.734639]\n",
      "epoch:7 step:7186 [D loss: 0.654578, acc.: 64.06%] [G loss: 0.744965]\n",
      "epoch:7 step:7187 [D loss: 0.718038, acc.: 45.31%] [G loss: 0.742841]\n",
      "epoch:7 step:7188 [D loss: 0.675130, acc.: 62.50%] [G loss: 0.737746]\n",
      "epoch:7 step:7189 [D loss: 0.678484, acc.: 56.25%] [G loss: 0.768705]\n",
      "epoch:7 step:7190 [D loss: 0.695541, acc.: 53.12%] [G loss: 0.717109]\n",
      "epoch:7 step:7191 [D loss: 0.741114, acc.: 45.31%] [G loss: 0.743540]\n",
      "epoch:7 step:7192 [D loss: 0.711315, acc.: 46.88%] [G loss: 0.750506]\n",
      "epoch:7 step:7193 [D loss: 0.714322, acc.: 45.31%] [G loss: 0.720662]\n",
      "epoch:7 step:7194 [D loss: 0.684911, acc.: 51.56%] [G loss: 0.773019]\n",
      "epoch:7 step:7195 [D loss: 0.695160, acc.: 46.09%] [G loss: 0.749721]\n",
      "epoch:7 step:7196 [D loss: 0.697889, acc.: 51.56%] [G loss: 0.724162]\n",
      "epoch:7 step:7197 [D loss: 0.681339, acc.: 54.69%] [G loss: 0.751088]\n",
      "epoch:7 step:7198 [D loss: 0.672819, acc.: 65.62%] [G loss: 0.768784]\n",
      "epoch:7 step:7199 [D loss: 0.707834, acc.: 44.53%] [G loss: 0.783722]\n",
      "epoch:7 step:7200 [D loss: 0.627312, acc.: 73.44%] [G loss: 0.735058]\n",
      "##############\n",
      "[3.85978114 2.62831027 6.32018291 5.97281095 4.29612378 6.28948169\n",
      " 5.31772124 5.36261731 5.94724548 4.96716632]\n",
      "##########\n",
      "epoch:7 step:7201 [D loss: 0.695842, acc.: 51.56%] [G loss: 0.805869]\n",
      "epoch:7 step:7202 [D loss: 0.693269, acc.: 51.56%] [G loss: 0.803172]\n",
      "epoch:7 step:7203 [D loss: 0.656608, acc.: 64.06%] [G loss: 0.768438]\n",
      "epoch:7 step:7204 [D loss: 0.681621, acc.: 57.81%] [G loss: 0.809560]\n",
      "epoch:7 step:7205 [D loss: 0.690448, acc.: 51.56%] [G loss: 0.827462]\n",
      "epoch:7 step:7206 [D loss: 0.690200, acc.: 57.03%] [G loss: 0.802096]\n",
      "epoch:7 step:7207 [D loss: 0.655327, acc.: 60.94%] [G loss: 0.825221]\n",
      "epoch:7 step:7208 [D loss: 0.671992, acc.: 53.12%] [G loss: 0.803866]\n",
      "epoch:7 step:7209 [D loss: 0.652878, acc.: 67.19%] [G loss: 0.824581]\n",
      "epoch:7 step:7210 [D loss: 0.656271, acc.: 62.50%] [G loss: 0.877027]\n",
      "epoch:7 step:7211 [D loss: 0.685613, acc.: 55.47%] [G loss: 0.795306]\n",
      "epoch:7 step:7212 [D loss: 0.700901, acc.: 51.56%] [G loss: 0.737802]\n",
      "epoch:7 step:7213 [D loss: 0.694662, acc.: 53.91%] [G loss: 0.788492]\n",
      "epoch:7 step:7214 [D loss: 0.674850, acc.: 57.03%] [G loss: 0.774415]\n",
      "epoch:7 step:7215 [D loss: 0.689259, acc.: 54.69%] [G loss: 0.777671]\n",
      "epoch:7 step:7216 [D loss: 0.671213, acc.: 60.94%] [G loss: 0.778215]\n",
      "epoch:7 step:7217 [D loss: 0.695350, acc.: 50.00%] [G loss: 0.745750]\n",
      "epoch:7 step:7218 [D loss: 0.644143, acc.: 65.62%] [G loss: 0.803762]\n",
      "epoch:7 step:7219 [D loss: 0.687315, acc.: 58.59%] [G loss: 0.769825]\n",
      "epoch:7 step:7220 [D loss: 0.643509, acc.: 60.94%] [G loss: 0.751246]\n",
      "epoch:7 step:7221 [D loss: 0.661855, acc.: 59.38%] [G loss: 0.817895]\n",
      "epoch:7 step:7222 [D loss: 0.687559, acc.: 63.28%] [G loss: 0.771062]\n",
      "epoch:7 step:7223 [D loss: 0.642614, acc.: 68.75%] [G loss: 0.402260]\n",
      "epoch:7 step:7224 [D loss: 0.652787, acc.: 66.41%] [G loss: 0.800114]\n",
      "epoch:7 step:7225 [D loss: 0.653383, acc.: 57.03%] [G loss: 0.706634]\n",
      "epoch:7 step:7226 [D loss: 0.672679, acc.: 54.69%] [G loss: 0.771433]\n",
      "epoch:7 step:7227 [D loss: 0.721219, acc.: 53.12%] [G loss: 0.814668]\n",
      "epoch:7 step:7228 [D loss: 0.711502, acc.: 54.69%] [G loss: 0.817616]\n",
      "epoch:7 step:7229 [D loss: 0.708505, acc.: 50.78%] [G loss: 0.817448]\n",
      "epoch:7 step:7230 [D loss: 0.678799, acc.: 58.59%] [G loss: 0.808048]\n",
      "epoch:7 step:7231 [D loss: 0.670414, acc.: 60.94%] [G loss: 0.808267]\n",
      "epoch:7 step:7232 [D loss: 0.642472, acc.: 64.84%] [G loss: 0.799116]\n",
      "epoch:7 step:7233 [D loss: 0.608031, acc.: 64.84%] [G loss: 0.737994]\n",
      "epoch:7 step:7234 [D loss: 0.705441, acc.: 47.66%] [G loss: 0.785596]\n",
      "epoch:7 step:7235 [D loss: 0.695487, acc.: 54.69%] [G loss: 0.742211]\n",
      "epoch:7 step:7236 [D loss: 0.694294, acc.: 53.91%] [G loss: 0.767626]\n",
      "epoch:7 step:7237 [D loss: 0.728337, acc.: 47.66%] [G loss: 0.823693]\n",
      "epoch:7 step:7238 [D loss: 0.723351, acc.: 48.44%] [G loss: 0.760148]\n",
      "epoch:7 step:7239 [D loss: 0.705336, acc.: 50.00%] [G loss: 0.762357]\n",
      "epoch:7 step:7240 [D loss: 0.690908, acc.: 51.56%] [G loss: 0.752654]\n",
      "epoch:7 step:7241 [D loss: 0.692031, acc.: 54.69%] [G loss: 0.793671]\n",
      "epoch:7 step:7242 [D loss: 0.689820, acc.: 54.69%] [G loss: 0.743660]\n",
      "epoch:7 step:7243 [D loss: 0.707699, acc.: 50.00%] [G loss: 0.732510]\n",
      "epoch:7 step:7244 [D loss: 0.686664, acc.: 60.16%] [G loss: 0.746902]\n",
      "epoch:7 step:7245 [D loss: 0.706806, acc.: 50.00%] [G loss: 0.718931]\n",
      "epoch:7 step:7246 [D loss: 0.705659, acc.: 54.69%] [G loss: 0.740268]\n",
      "epoch:7 step:7247 [D loss: 0.687179, acc.: 60.94%] [G loss: 0.720610]\n",
      "epoch:7 step:7248 [D loss: 0.697071, acc.: 60.94%] [G loss: 0.740112]\n",
      "epoch:7 step:7249 [D loss: 0.677762, acc.: 57.03%] [G loss: 0.793646]\n",
      "epoch:7 step:7250 [D loss: 0.674293, acc.: 57.81%] [G loss: 0.750120]\n",
      "epoch:7 step:7251 [D loss: 0.662061, acc.: 56.25%] [G loss: 0.770313]\n",
      "epoch:7 step:7252 [D loss: 0.672774, acc.: 60.16%] [G loss: 0.796708]\n",
      "epoch:7 step:7253 [D loss: 0.652007, acc.: 60.94%] [G loss: 0.761691]\n",
      "epoch:7 step:7254 [D loss: 0.664076, acc.: 67.19%] [G loss: 0.820077]\n",
      "epoch:7 step:7255 [D loss: 0.687447, acc.: 47.66%] [G loss: 0.803022]\n",
      "epoch:7 step:7256 [D loss: 0.624427, acc.: 69.53%] [G loss: 0.756113]\n",
      "epoch:7 step:7257 [D loss: 0.639958, acc.: 67.97%] [G loss: 0.751373]\n",
      "epoch:7 step:7258 [D loss: 0.690410, acc.: 56.25%] [G loss: 0.782881]\n",
      "epoch:7 step:7259 [D loss: 0.629109, acc.: 65.62%] [G loss: 0.759547]\n",
      "epoch:7 step:7260 [D loss: 0.617014, acc.: 70.31%] [G loss: 0.849662]\n",
      "epoch:7 step:7261 [D loss: 0.605099, acc.: 69.53%] [G loss: 0.855277]\n",
      "epoch:7 step:7262 [D loss: 0.784474, acc.: 34.38%] [G loss: 0.742172]\n",
      "epoch:7 step:7263 [D loss: 0.627009, acc.: 67.97%] [G loss: 0.789543]\n",
      "epoch:7 step:7264 [D loss: 0.730067, acc.: 45.31%] [G loss: 0.766477]\n",
      "epoch:7 step:7265 [D loss: 0.580611, acc.: 78.91%] [G loss: 0.838999]\n",
      "epoch:7 step:7266 [D loss: 0.566655, acc.: 80.47%] [G loss: 0.662695]\n",
      "epoch:7 step:7267 [D loss: 0.527218, acc.: 84.38%] [G loss: 0.658052]\n",
      "epoch:7 step:7268 [D loss: 0.617086, acc.: 67.97%] [G loss: 0.679856]\n",
      "epoch:7 step:7269 [D loss: 0.787880, acc.: 39.06%] [G loss: 0.810778]\n",
      "epoch:7 step:7270 [D loss: 0.753449, acc.: 43.75%] [G loss: 0.701217]\n",
      "epoch:7 step:7271 [D loss: 0.820476, acc.: 39.06%] [G loss: 0.822597]\n",
      "epoch:7 step:7272 [D loss: 0.640205, acc.: 66.41%] [G loss: 0.841105]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7273 [D loss: 0.651562, acc.: 64.06%] [G loss: 0.785184]\n",
      "epoch:7 step:7274 [D loss: 0.713135, acc.: 46.88%] [G loss: 0.770714]\n",
      "epoch:7 step:7275 [D loss: 0.695987, acc.: 47.66%] [G loss: 0.934092]\n",
      "epoch:7 step:7276 [D loss: 0.676783, acc.: 64.06%] [G loss: 0.850826]\n",
      "epoch:7 step:7277 [D loss: 0.672056, acc.: 57.81%] [G loss: 0.923600]\n",
      "epoch:7 step:7278 [D loss: 0.625465, acc.: 69.53%] [G loss: 0.909315]\n",
      "epoch:7 step:7279 [D loss: 0.641781, acc.: 68.75%] [G loss: 0.863856]\n",
      "epoch:7 step:7280 [D loss: 0.592447, acc.: 71.88%] [G loss: 0.964976]\n",
      "epoch:7 step:7281 [D loss: 0.725905, acc.: 51.56%] [G loss: 0.926865]\n",
      "epoch:7 step:7282 [D loss: 0.654437, acc.: 57.81%] [G loss: 0.970369]\n",
      "epoch:7 step:7283 [D loss: 0.672767, acc.: 54.69%] [G loss: 0.820207]\n",
      "epoch:7 step:7284 [D loss: 0.618545, acc.: 69.53%] [G loss: 0.967585]\n",
      "epoch:7 step:7285 [D loss: 0.606925, acc.: 70.31%] [G loss: 1.001667]\n",
      "epoch:7 step:7286 [D loss: 0.819649, acc.: 43.75%] [G loss: 0.870343]\n",
      "epoch:7 step:7287 [D loss: 0.755674, acc.: 40.62%] [G loss: 0.882703]\n",
      "epoch:7 step:7288 [D loss: 0.658482, acc.: 54.69%] [G loss: 0.852794]\n",
      "epoch:7 step:7289 [D loss: 0.679484, acc.: 55.47%] [G loss: 0.813915]\n",
      "epoch:7 step:7290 [D loss: 0.670714, acc.: 57.81%] [G loss: 0.908709]\n",
      "epoch:7 step:7291 [D loss: 0.685897, acc.: 57.81%] [G loss: 0.800958]\n",
      "epoch:7 step:7292 [D loss: 0.682206, acc.: 53.91%] [G loss: 0.729683]\n",
      "epoch:7 step:7293 [D loss: 0.700557, acc.: 54.69%] [G loss: 0.792840]\n",
      "epoch:7 step:7294 [D loss: 0.734424, acc.: 38.28%] [G loss: 0.736980]\n",
      "epoch:7 step:7295 [D loss: 0.662246, acc.: 61.72%] [G loss: 0.666746]\n",
      "epoch:7 step:7296 [D loss: 0.685502, acc.: 53.12%] [G loss: 0.827950]\n",
      "epoch:7 step:7297 [D loss: 0.696728, acc.: 48.44%] [G loss: 0.718422]\n",
      "epoch:7 step:7298 [D loss: 0.680957, acc.: 57.81%] [G loss: 0.809083]\n",
      "epoch:7 step:7299 [D loss: 0.679540, acc.: 56.25%] [G loss: 0.751482]\n",
      "epoch:7 step:7300 [D loss: 0.666321, acc.: 61.72%] [G loss: 0.748368]\n",
      "epoch:7 step:7301 [D loss: 0.652615, acc.: 67.19%] [G loss: 0.752152]\n",
      "epoch:7 step:7302 [D loss: 0.662226, acc.: 62.50%] [G loss: 0.789899]\n",
      "epoch:7 step:7303 [D loss: 0.672745, acc.: 53.91%] [G loss: 0.738488]\n",
      "epoch:7 step:7304 [D loss: 0.706990, acc.: 51.56%] [G loss: 0.759523]\n",
      "epoch:7 step:7305 [D loss: 0.719208, acc.: 50.78%] [G loss: 0.692924]\n",
      "epoch:7 step:7306 [D loss: 0.660622, acc.: 60.94%] [G loss: 0.688693]\n",
      "epoch:7 step:7307 [D loss: 0.722149, acc.: 50.00%] [G loss: 0.708989]\n",
      "epoch:7 step:7308 [D loss: 0.666510, acc.: 55.47%] [G loss: 0.771774]\n",
      "epoch:7 step:7309 [D loss: 0.675358, acc.: 60.16%] [G loss: 0.763794]\n",
      "epoch:7 step:7310 [D loss: 0.670622, acc.: 59.38%] [G loss: 0.744694]\n",
      "epoch:7 step:7311 [D loss: 0.699685, acc.: 49.22%] [G loss: 0.735057]\n",
      "epoch:7 step:7312 [D loss: 0.666991, acc.: 59.38%] [G loss: 0.753885]\n",
      "epoch:7 step:7313 [D loss: 0.659600, acc.: 60.16%] [G loss: 0.746294]\n",
      "epoch:7 step:7314 [D loss: 0.665797, acc.: 59.38%] [G loss: 0.739386]\n",
      "epoch:7 step:7315 [D loss: 0.661764, acc.: 57.03%] [G loss: 0.768854]\n",
      "epoch:7 step:7316 [D loss: 0.642302, acc.: 60.94%] [G loss: 0.708054]\n",
      "epoch:7 step:7317 [D loss: 0.667452, acc.: 53.91%] [G loss: 0.700448]\n",
      "epoch:7 step:7318 [D loss: 0.711950, acc.: 48.44%] [G loss: 0.724377]\n",
      "epoch:7 step:7319 [D loss: 0.716166, acc.: 52.34%] [G loss: 0.745058]\n",
      "epoch:7 step:7320 [D loss: 0.699116, acc.: 48.44%] [G loss: 0.716731]\n",
      "epoch:7 step:7321 [D loss: 0.730014, acc.: 47.66%] [G loss: 0.724451]\n",
      "epoch:7 step:7322 [D loss: 0.668632, acc.: 60.94%] [G loss: 0.773250]\n",
      "epoch:7 step:7323 [D loss: 0.653683, acc.: 57.03%] [G loss: 0.740687]\n",
      "epoch:7 step:7324 [D loss: 0.726210, acc.: 44.53%] [G loss: 0.830701]\n",
      "epoch:7 step:7325 [D loss: 0.686044, acc.: 58.59%] [G loss: 0.794910]\n",
      "epoch:7 step:7326 [D loss: 0.683998, acc.: 57.81%] [G loss: 0.828655]\n",
      "epoch:7 step:7327 [D loss: 0.651288, acc.: 62.50%] [G loss: 0.813889]\n",
      "epoch:7 step:7328 [D loss: 0.698647, acc.: 53.91%] [G loss: 0.849563]\n",
      "epoch:7 step:7329 [D loss: 0.673023, acc.: 63.28%] [G loss: 0.837564]\n",
      "epoch:7 step:7330 [D loss: 0.664832, acc.: 60.94%] [G loss: 0.834850]\n",
      "epoch:7 step:7331 [D loss: 0.676458, acc.: 59.38%] [G loss: 0.842572]\n",
      "epoch:7 step:7332 [D loss: 0.689134, acc.: 56.25%] [G loss: 0.785649]\n",
      "epoch:7 step:7333 [D loss: 0.656677, acc.: 63.28%] [G loss: 0.794730]\n",
      "epoch:7 step:7334 [D loss: 0.629535, acc.: 63.28%] [G loss: 0.838154]\n",
      "epoch:7 step:7335 [D loss: 0.685221, acc.: 54.69%] [G loss: 0.777741]\n",
      "epoch:7 step:7336 [D loss: 0.674547, acc.: 57.03%] [G loss: 0.783217]\n",
      "epoch:7 step:7337 [D loss: 0.727545, acc.: 49.22%] [G loss: 0.747703]\n",
      "epoch:7 step:7338 [D loss: 0.687568, acc.: 53.91%] [G loss: 0.756407]\n",
      "epoch:7 step:7339 [D loss: 0.653237, acc.: 63.28%] [G loss: 0.743100]\n",
      "epoch:7 step:7340 [D loss: 0.672306, acc.: 59.38%] [G loss: 0.802692]\n",
      "epoch:7 step:7341 [D loss: 0.620928, acc.: 70.31%] [G loss: 0.869868]\n",
      "epoch:7 step:7342 [D loss: 0.661970, acc.: 60.94%] [G loss: 0.702929]\n",
      "epoch:7 step:7343 [D loss: 0.681155, acc.: 55.47%] [G loss: 0.844055]\n",
      "epoch:7 step:7344 [D loss: 0.674229, acc.: 62.50%] [G loss: 0.776991]\n",
      "epoch:7 step:7345 [D loss: 0.550678, acc.: 82.03%] [G loss: 0.813902]\n",
      "epoch:7 step:7346 [D loss: 0.723966, acc.: 50.78%] [G loss: 0.840489]\n",
      "epoch:7 step:7347 [D loss: 0.771517, acc.: 39.06%] [G loss: 0.797661]\n",
      "epoch:7 step:7348 [D loss: 0.712979, acc.: 44.53%] [G loss: 0.749678]\n",
      "epoch:7 step:7349 [D loss: 0.686624, acc.: 53.12%] [G loss: 0.831182]\n",
      "epoch:7 step:7350 [D loss: 0.571954, acc.: 77.34%] [G loss: 0.832686]\n",
      "epoch:7 step:7351 [D loss: 0.700682, acc.: 50.78%] [G loss: 0.754158]\n",
      "epoch:7 step:7352 [D loss: 0.819976, acc.: 53.91%] [G loss: 0.957038]\n",
      "epoch:7 step:7353 [D loss: 0.617069, acc.: 74.22%] [G loss: 0.970586]\n",
      "epoch:7 step:7354 [D loss: 0.661961, acc.: 63.28%] [G loss: 0.715200]\n",
      "epoch:7 step:7355 [D loss: 0.703409, acc.: 53.12%] [G loss: 1.007962]\n",
      "epoch:7 step:7356 [D loss: 0.906860, acc.: 25.78%] [G loss: 0.813571]\n",
      "epoch:7 step:7357 [D loss: 0.693649, acc.: 60.16%] [G loss: 0.770481]\n",
      "epoch:7 step:7358 [D loss: 0.723834, acc.: 51.56%] [G loss: 0.836840]\n",
      "epoch:7 step:7359 [D loss: 0.708293, acc.: 50.78%] [G loss: 0.886795]\n",
      "epoch:7 step:7360 [D loss: 0.685183, acc.: 57.81%] [G loss: 0.816470]\n",
      "epoch:7 step:7361 [D loss: 0.737893, acc.: 61.72%] [G loss: 0.862673]\n",
      "epoch:7 step:7362 [D loss: 0.749694, acc.: 48.44%] [G loss: 0.809573]\n",
      "epoch:7 step:7363 [D loss: 0.751667, acc.: 46.88%] [G loss: 0.674659]\n",
      "epoch:7 step:7364 [D loss: 0.672080, acc.: 64.06%] [G loss: 0.765561]\n",
      "epoch:7 step:7365 [D loss: 0.648580, acc.: 63.28%] [G loss: 0.726319]\n",
      "epoch:7 step:7366 [D loss: 0.705634, acc.: 46.09%] [G loss: 0.820311]\n",
      "epoch:7 step:7367 [D loss: 0.676197, acc.: 54.69%] [G loss: 0.826072]\n",
      "epoch:7 step:7368 [D loss: 0.654204, acc.: 60.94%] [G loss: 0.878674]\n",
      "epoch:7 step:7369 [D loss: 0.643010, acc.: 62.50%] [G loss: 0.858145]\n",
      "epoch:7 step:7370 [D loss: 0.727190, acc.: 44.53%] [G loss: 0.889499]\n",
      "epoch:7 step:7371 [D loss: 0.722201, acc.: 45.31%] [G loss: 0.783066]\n",
      "epoch:7 step:7372 [D loss: 0.675177, acc.: 58.59%] [G loss: 0.829858]\n",
      "epoch:7 step:7373 [D loss: 0.701308, acc.: 50.00%] [G loss: 0.773134]\n",
      "epoch:7 step:7374 [D loss: 0.614262, acc.: 74.22%] [G loss: 0.709316]\n",
      "epoch:7 step:7375 [D loss: 0.570182, acc.: 85.16%] [G loss: 0.802506]\n",
      "epoch:7 step:7376 [D loss: 0.710452, acc.: 54.69%] [G loss: 0.785224]\n",
      "epoch:7 step:7377 [D loss: 0.610119, acc.: 70.31%] [G loss: 0.724109]\n",
      "epoch:7 step:7378 [D loss: 0.609961, acc.: 70.31%] [G loss: 0.710896]\n",
      "epoch:7 step:7379 [D loss: 0.755623, acc.: 37.50%] [G loss: 0.549967]\n",
      "epoch:7 step:7380 [D loss: 0.848454, acc.: 16.41%] [G loss: 0.779358]\n",
      "epoch:7 step:7381 [D loss: 0.717495, acc.: 44.53%] [G loss: 0.809060]\n",
      "epoch:7 step:7382 [D loss: 0.656064, acc.: 61.72%] [G loss: 0.798582]\n",
      "epoch:7 step:7383 [D loss: 0.632013, acc.: 59.38%] [G loss: 0.818905]\n",
      "epoch:7 step:7384 [D loss: 0.605294, acc.: 74.22%] [G loss: 0.804993]\n",
      "epoch:7 step:7385 [D loss: 0.681600, acc.: 53.91%] [G loss: 0.852843]\n",
      "epoch:7 step:7386 [D loss: 0.729930, acc.: 46.09%] [G loss: 0.731120]\n",
      "epoch:7 step:7387 [D loss: 0.746553, acc.: 42.19%] [G loss: 0.679519]\n",
      "epoch:7 step:7388 [D loss: 0.691639, acc.: 51.56%] [G loss: 0.713963]\n",
      "epoch:7 step:7389 [D loss: 0.670110, acc.: 58.59%] [G loss: 0.701169]\n",
      "epoch:7 step:7390 [D loss: 0.690612, acc.: 57.81%] [G loss: 0.726865]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7391 [D loss: 0.681358, acc.: 57.81%] [G loss: 0.681851]\n",
      "epoch:7 step:7392 [D loss: 0.719256, acc.: 50.00%] [G loss: 0.655253]\n",
      "epoch:7 step:7393 [D loss: 0.708857, acc.: 52.34%] [G loss: 0.483819]\n",
      "epoch:7 step:7394 [D loss: 0.718061, acc.: 43.75%] [G loss: 0.732849]\n",
      "epoch:7 step:7395 [D loss: 0.738009, acc.: 37.50%] [G loss: 0.719610]\n",
      "epoch:7 step:7396 [D loss: 0.703313, acc.: 52.34%] [G loss: 0.724887]\n",
      "epoch:7 step:7397 [D loss: 0.653309, acc.: 65.62%] [G loss: 0.738400]\n",
      "epoch:7 step:7398 [D loss: 0.685366, acc.: 56.25%] [G loss: 0.586220]\n",
      "epoch:7 step:7399 [D loss: 0.694751, acc.: 53.12%] [G loss: 0.769947]\n",
      "epoch:7 step:7400 [D loss: 0.712022, acc.: 46.88%] [G loss: 0.801271]\n",
      "##############\n",
      "[4.58666667 1.6726248  6.31225852 5.65743226 3.26052719 6.13056794\n",
      " 5.48405548 4.77126172 5.98064533 4.21746185]\n",
      "##########\n",
      "epoch:7 step:7401 [D loss: 0.632541, acc.: 71.09%] [G loss: 0.775878]\n",
      "epoch:7 step:7402 [D loss: 0.715676, acc.: 50.78%] [G loss: 0.786365]\n",
      "epoch:7 step:7403 [D loss: 0.931025, acc.: 45.31%] [G loss: 0.902536]\n",
      "epoch:7 step:7404 [D loss: 0.738540, acc.: 58.59%] [G loss: 1.090114]\n",
      "epoch:7 step:7405 [D loss: 0.673325, acc.: 60.94%] [G loss: 0.840098]\n",
      "epoch:7 step:7406 [D loss: 0.668631, acc.: 57.03%] [G loss: 0.811451]\n",
      "epoch:7 step:7407 [D loss: 0.671235, acc.: 60.16%] [G loss: 0.790128]\n",
      "epoch:7 step:7408 [D loss: 0.716568, acc.: 43.75%] [G loss: 0.742771]\n",
      "epoch:7 step:7409 [D loss: 0.659761, acc.: 59.38%] [G loss: 0.790193]\n",
      "epoch:7 step:7410 [D loss: 0.632154, acc.: 64.06%] [G loss: 0.789835]\n",
      "epoch:7 step:7411 [D loss: 0.635060, acc.: 59.38%] [G loss: 0.760449]\n",
      "epoch:7 step:7412 [D loss: 0.655260, acc.: 65.62%] [G loss: 0.782679]\n",
      "epoch:7 step:7413 [D loss: 0.551663, acc.: 85.16%] [G loss: 0.833517]\n",
      "epoch:7 step:7414 [D loss: 0.661313, acc.: 58.59%] [G loss: 0.793254]\n",
      "epoch:7 step:7415 [D loss: 0.724103, acc.: 46.88%] [G loss: 0.968556]\n",
      "epoch:7 step:7416 [D loss: 0.595146, acc.: 78.12%] [G loss: 0.813791]\n",
      "epoch:7 step:7417 [D loss: 0.746911, acc.: 42.19%] [G loss: 0.833367]\n",
      "epoch:7 step:7418 [D loss: 0.705047, acc.: 52.34%] [G loss: 0.797787]\n",
      "epoch:7 step:7419 [D loss: 0.693866, acc.: 50.00%] [G loss: 0.764711]\n",
      "epoch:7 step:7420 [D loss: 0.683505, acc.: 60.94%] [G loss: 0.795542]\n",
      "epoch:7 step:7421 [D loss: 0.704896, acc.: 46.88%] [G loss: 0.799553]\n",
      "epoch:7 step:7422 [D loss: 0.677335, acc.: 57.03%] [G loss: 0.780065]\n",
      "epoch:7 step:7423 [D loss: 0.699390, acc.: 47.66%] [G loss: 0.738640]\n",
      "epoch:7 step:7424 [D loss: 0.679985, acc.: 57.81%] [G loss: 0.783262]\n",
      "epoch:7 step:7425 [D loss: 0.703485, acc.: 48.44%] [G loss: 0.726135]\n",
      "epoch:7 step:7426 [D loss: 0.705525, acc.: 53.91%] [G loss: 0.751268]\n",
      "epoch:7 step:7427 [D loss: 0.767422, acc.: 41.41%] [G loss: 0.692039]\n",
      "epoch:7 step:7428 [D loss: 0.694487, acc.: 50.78%] [G loss: 0.719541]\n",
      "epoch:7 step:7429 [D loss: 0.715925, acc.: 46.88%] [G loss: 0.765809]\n",
      "epoch:7 step:7430 [D loss: 0.664124, acc.: 60.16%] [G loss: 0.788838]\n",
      "epoch:7 step:7431 [D loss: 0.635699, acc.: 65.62%] [G loss: 0.750669]\n",
      "epoch:7 step:7432 [D loss: 0.705195, acc.: 46.09%] [G loss: 0.800363]\n",
      "epoch:7 step:7433 [D loss: 0.657077, acc.: 64.84%] [G loss: 0.834595]\n",
      "epoch:7 step:7434 [D loss: 0.675882, acc.: 55.47%] [G loss: 0.803219]\n",
      "epoch:7 step:7435 [D loss: 0.753740, acc.: 39.84%] [G loss: 0.784500]\n",
      "epoch:7 step:7436 [D loss: 0.690898, acc.: 56.25%] [G loss: 0.751320]\n",
      "epoch:7 step:7437 [D loss: 0.699704, acc.: 54.69%] [G loss: 0.866734]\n",
      "epoch:7 step:7438 [D loss: 0.702510, acc.: 54.69%] [G loss: 0.816772]\n",
      "epoch:7 step:7439 [D loss: 0.685351, acc.: 55.47%] [G loss: 0.837899]\n",
      "epoch:7 step:7440 [D loss: 0.688794, acc.: 53.91%] [G loss: 0.779088]\n",
      "epoch:7 step:7441 [D loss: 0.677246, acc.: 52.34%] [G loss: 0.778377]\n",
      "epoch:7 step:7442 [D loss: 0.665498, acc.: 60.16%] [G loss: 0.792087]\n",
      "epoch:7 step:7443 [D loss: 0.654646, acc.: 62.50%] [G loss: 0.753600]\n",
      "epoch:7 step:7444 [D loss: 0.633019, acc.: 67.97%] [G loss: 1.054985]\n",
      "epoch:7 step:7445 [D loss: 0.644999, acc.: 68.75%] [G loss: 0.715659]\n",
      "epoch:7 step:7446 [D loss: 0.736360, acc.: 44.53%] [G loss: 0.780137]\n",
      "epoch:7 step:7447 [D loss: 0.702049, acc.: 50.00%] [G loss: 0.748425]\n",
      "epoch:7 step:7448 [D loss: 0.676532, acc.: 54.69%] [G loss: 0.780061]\n",
      "epoch:7 step:7449 [D loss: 0.628841, acc.: 68.75%] [G loss: 0.799526]\n",
      "epoch:7 step:7450 [D loss: 0.714395, acc.: 46.09%] [G loss: 0.765616]\n",
      "epoch:7 step:7451 [D loss: 0.710744, acc.: 57.03%] [G loss: 0.805245]\n",
      "epoch:7 step:7452 [D loss: 0.720931, acc.: 50.78%] [G loss: 0.798959]\n",
      "epoch:7 step:7453 [D loss: 0.684958, acc.: 53.12%] [G loss: 0.722592]\n",
      "epoch:7 step:7454 [D loss: 0.686136, acc.: 56.25%] [G loss: 0.713341]\n",
      "epoch:7 step:7455 [D loss: 0.682954, acc.: 56.25%] [G loss: 0.757394]\n",
      "epoch:7 step:7456 [D loss: 0.690300, acc.: 56.25%] [G loss: 0.722981]\n",
      "epoch:7 step:7457 [D loss: 0.666588, acc.: 61.72%] [G loss: 0.806293]\n",
      "epoch:7 step:7458 [D loss: 0.591952, acc.: 67.19%] [G loss: 0.801025]\n",
      "epoch:7 step:7459 [D loss: 0.600830, acc.: 70.31%] [G loss: 0.857138]\n",
      "epoch:7 step:7460 [D loss: 0.649946, acc.: 66.41%] [G loss: 0.847413]\n",
      "epoch:7 step:7461 [D loss: 0.662541, acc.: 63.28%] [G loss: 0.834087]\n",
      "epoch:7 step:7462 [D loss: 0.683036, acc.: 55.47%] [G loss: 0.802807]\n",
      "epoch:7 step:7463 [D loss: 0.744051, acc.: 43.75%] [G loss: 0.797141]\n",
      "epoch:7 step:7464 [D loss: 0.753791, acc.: 42.19%] [G loss: 0.792290]\n",
      "epoch:7 step:7465 [D loss: 0.741574, acc.: 42.97%] [G loss: 0.729423]\n",
      "epoch:7 step:7466 [D loss: 0.694968, acc.: 52.34%] [G loss: 0.710421]\n",
      "epoch:7 step:7467 [D loss: 0.682571, acc.: 54.69%] [G loss: 0.746272]\n",
      "epoch:7 step:7468 [D loss: 0.656055, acc.: 65.62%] [G loss: 0.728477]\n",
      "epoch:7 step:7469 [D loss: 0.722822, acc.: 39.84%] [G loss: 0.670091]\n",
      "epoch:7 step:7470 [D loss: 0.661003, acc.: 63.28%] [G loss: 0.723898]\n",
      "epoch:7 step:7471 [D loss: 0.417310, acc.: 84.38%] [G loss: 0.761773]\n",
      "epoch:7 step:7472 [D loss: 0.686843, acc.: 52.34%] [G loss: 0.769379]\n",
      "epoch:7 step:7473 [D loss: 0.679577, acc.: 53.91%] [G loss: 0.757517]\n",
      "epoch:7 step:7474 [D loss: 0.716649, acc.: 46.88%] [G loss: 0.780502]\n",
      "epoch:7 step:7475 [D loss: 0.697508, acc.: 52.34%] [G loss: 0.792093]\n",
      "epoch:7 step:7476 [D loss: 0.688065, acc.: 60.16%] [G loss: 0.794872]\n",
      "epoch:7 step:7477 [D loss: 0.649757, acc.: 64.84%] [G loss: 0.752741]\n",
      "epoch:7 step:7478 [D loss: 0.625912, acc.: 67.97%] [G loss: 0.756152]\n",
      "epoch:7 step:7479 [D loss: 0.679326, acc.: 51.56%] [G loss: 0.734615]\n",
      "epoch:7 step:7480 [D loss: 0.657997, acc.: 64.06%] [G loss: 0.759129]\n",
      "epoch:7 step:7481 [D loss: 0.656357, acc.: 65.62%] [G loss: 0.774115]\n",
      "epoch:7 step:7482 [D loss: 0.649575, acc.: 64.06%] [G loss: 0.756490]\n",
      "epoch:7 step:7483 [D loss: 0.535841, acc.: 68.75%] [G loss: 0.491734]\n",
      "epoch:7 step:7484 [D loss: 0.480330, acc.: 82.03%] [G loss: 0.722443]\n",
      "epoch:7 step:7485 [D loss: 0.414328, acc.: 75.78%] [G loss: 0.867483]\n",
      "epoch:7 step:7486 [D loss: 0.349680, acc.: 82.81%] [G loss: 1.085063]\n",
      "epoch:7 step:7487 [D loss: 0.806137, acc.: 46.09%] [G loss: 1.005074]\n",
      "epoch:7 step:7488 [D loss: 0.685393, acc.: 53.91%] [G loss: 0.946362]\n",
      "epoch:7 step:7489 [D loss: 0.615905, acc.: 67.97%] [G loss: 0.865941]\n",
      "epoch:7 step:7490 [D loss: 0.620990, acc.: 68.75%] [G loss: 0.950191]\n",
      "epoch:7 step:7491 [D loss: 0.660109, acc.: 57.81%] [G loss: 0.750237]\n",
      "epoch:7 step:7492 [D loss: 0.414868, acc.: 75.00%] [G loss: 0.843557]\n",
      "epoch:7 step:7493 [D loss: 0.511840, acc.: 75.00%] [G loss: 0.763208]\n",
      "epoch:7 step:7494 [D loss: 0.570440, acc.: 78.12%] [G loss: 0.363169]\n",
      "epoch:7 step:7495 [D loss: 0.313769, acc.: 83.59%] [G loss: 0.947880]\n",
      "epoch:7 step:7496 [D loss: 0.265036, acc.: 92.97%] [G loss: 0.929747]\n",
      "epoch:8 step:7497 [D loss: 0.833691, acc.: 40.62%] [G loss: 0.939720]\n",
      "epoch:8 step:7498 [D loss: 0.832647, acc.: 41.41%] [G loss: 0.812238]\n",
      "epoch:8 step:7499 [D loss: 0.812078, acc.: 36.72%] [G loss: 0.340287]\n",
      "epoch:8 step:7500 [D loss: 0.767045, acc.: 36.72%] [G loss: 0.889302]\n",
      "epoch:8 step:7501 [D loss: 0.873917, acc.: 32.81%] [G loss: 0.933096]\n",
      "epoch:8 step:7502 [D loss: 0.843317, acc.: 26.56%] [G loss: 1.676634]\n",
      "epoch:8 step:7503 [D loss: 0.716538, acc.: 56.25%] [G loss: 1.383941]\n",
      "epoch:8 step:7504 [D loss: 0.724356, acc.: 53.91%] [G loss: 1.068398]\n",
      "epoch:8 step:7505 [D loss: 0.703044, acc.: 54.69%] [G loss: 0.939361]\n",
      "epoch:8 step:7506 [D loss: 0.734449, acc.: 50.00%] [G loss: 0.852330]\n",
      "epoch:8 step:7507 [D loss: 0.730083, acc.: 45.31%] [G loss: 0.809454]\n",
      "epoch:8 step:7508 [D loss: 0.722212, acc.: 48.44%] [G loss: 0.807652]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7509 [D loss: 0.694701, acc.: 55.47%] [G loss: 0.783703]\n",
      "epoch:8 step:7510 [D loss: 0.707466, acc.: 50.00%] [G loss: 0.804320]\n",
      "epoch:8 step:7511 [D loss: 0.663765, acc.: 59.38%] [G loss: 0.850289]\n",
      "epoch:8 step:7512 [D loss: 0.661402, acc.: 61.72%] [G loss: 0.767587]\n",
      "epoch:8 step:7513 [D loss: 0.683005, acc.: 57.03%] [G loss: 0.705113]\n",
      "epoch:8 step:7514 [D loss: 0.667115, acc.: 66.41%] [G loss: 0.807582]\n",
      "epoch:8 step:7515 [D loss: 0.748185, acc.: 32.81%] [G loss: 0.885011]\n",
      "epoch:8 step:7516 [D loss: 0.729209, acc.: 50.00%] [G loss: 0.868583]\n",
      "epoch:8 step:7517 [D loss: 0.688209, acc.: 53.12%] [G loss: 0.716085]\n",
      "epoch:8 step:7518 [D loss: 0.664324, acc.: 61.72%] [G loss: 0.792404]\n",
      "epoch:8 step:7519 [D loss: 0.674664, acc.: 56.25%] [G loss: 0.790066]\n",
      "epoch:8 step:7520 [D loss: 0.643569, acc.: 77.34%] [G loss: 0.766187]\n",
      "epoch:8 step:7521 [D loss: 0.667204, acc.: 62.50%] [G loss: 0.781218]\n",
      "epoch:8 step:7522 [D loss: 0.670400, acc.: 58.59%] [G loss: 0.739166]\n",
      "epoch:8 step:7523 [D loss: 0.768626, acc.: 35.16%] [G loss: 0.763075]\n",
      "epoch:8 step:7524 [D loss: 0.639822, acc.: 61.72%] [G loss: 0.743347]\n",
      "epoch:8 step:7525 [D loss: 0.658121, acc.: 64.84%] [G loss: 0.748947]\n",
      "epoch:8 step:7526 [D loss: 0.673635, acc.: 60.16%] [G loss: 0.810393]\n",
      "epoch:8 step:7527 [D loss: 0.646315, acc.: 64.06%] [G loss: 0.855182]\n",
      "epoch:8 step:7528 [D loss: 0.672309, acc.: 57.03%] [G loss: 0.817275]\n",
      "epoch:8 step:7529 [D loss: 0.688812, acc.: 57.03%] [G loss: 0.780471]\n",
      "epoch:8 step:7530 [D loss: 0.715184, acc.: 47.66%] [G loss: 0.760316]\n",
      "epoch:8 step:7531 [D loss: 0.659043, acc.: 59.38%] [G loss: 0.768338]\n",
      "epoch:8 step:7532 [D loss: 0.685959, acc.: 56.25%] [G loss: 0.801292]\n",
      "epoch:8 step:7533 [D loss: 0.696590, acc.: 53.91%] [G loss: 0.659488]\n",
      "epoch:8 step:7534 [D loss: 0.733989, acc.: 47.66%] [G loss: 0.732652]\n",
      "epoch:8 step:7535 [D loss: 0.710033, acc.: 42.97%] [G loss: 0.744322]\n",
      "epoch:8 step:7536 [D loss: 0.686104, acc.: 49.22%] [G loss: 0.702744]\n",
      "epoch:8 step:7537 [D loss: 0.693420, acc.: 49.22%] [G loss: 0.739295]\n",
      "epoch:8 step:7538 [D loss: 0.679367, acc.: 53.12%] [G loss: 0.720647]\n",
      "epoch:8 step:7539 [D loss: 0.650222, acc.: 67.19%] [G loss: 0.735999]\n",
      "epoch:8 step:7540 [D loss: 0.686770, acc.: 53.12%] [G loss: 0.707351]\n",
      "epoch:8 step:7541 [D loss: 0.698398, acc.: 50.00%] [G loss: 0.703520]\n",
      "epoch:8 step:7542 [D loss: 0.665118, acc.: 59.38%] [G loss: 0.620246]\n",
      "epoch:8 step:7543 [D loss: 0.671103, acc.: 57.81%] [G loss: 0.726709]\n",
      "epoch:8 step:7544 [D loss: 0.661265, acc.: 57.03%] [G loss: 0.666561]\n",
      "epoch:8 step:7545 [D loss: 0.678755, acc.: 60.16%] [G loss: 0.755256]\n",
      "epoch:8 step:7546 [D loss: 0.619641, acc.: 62.50%] [G loss: 0.756590]\n",
      "epoch:8 step:7547 [D loss: 0.654132, acc.: 60.16%] [G loss: 0.748824]\n",
      "epoch:8 step:7548 [D loss: 0.654005, acc.: 65.62%] [G loss: 0.789836]\n",
      "epoch:8 step:7549 [D loss: 0.655636, acc.: 67.19%] [G loss: 0.824422]\n",
      "epoch:8 step:7550 [D loss: 0.686250, acc.: 59.38%] [G loss: 0.754935]\n",
      "epoch:8 step:7551 [D loss: 0.703529, acc.: 47.66%] [G loss: 0.764928]\n",
      "epoch:8 step:7552 [D loss: 0.722550, acc.: 47.66%] [G loss: 0.752987]\n",
      "epoch:8 step:7553 [D loss: 0.693511, acc.: 53.91%] [G loss: 0.763957]\n",
      "epoch:8 step:7554 [D loss: 0.702313, acc.: 53.12%] [G loss: 0.781115]\n",
      "epoch:8 step:7555 [D loss: 0.703846, acc.: 49.22%] [G loss: 0.763157]\n",
      "epoch:8 step:7556 [D loss: 0.710795, acc.: 49.22%] [G loss: 0.776068]\n",
      "epoch:8 step:7557 [D loss: 0.689601, acc.: 50.78%] [G loss: 0.793345]\n",
      "epoch:8 step:7558 [D loss: 0.681926, acc.: 57.81%] [G loss: 0.804966]\n",
      "epoch:8 step:7559 [D loss: 0.674245, acc.: 55.47%] [G loss: 0.798768]\n",
      "epoch:8 step:7560 [D loss: 0.679194, acc.: 55.47%] [G loss: 0.817971]\n",
      "epoch:8 step:7561 [D loss: 0.691450, acc.: 53.91%] [G loss: 0.832955]\n",
      "epoch:8 step:7562 [D loss: 0.694672, acc.: 53.91%] [G loss: 0.811199]\n",
      "epoch:8 step:7563 [D loss: 0.654079, acc.: 64.84%] [G loss: 0.798835]\n",
      "epoch:8 step:7564 [D loss: 0.662577, acc.: 67.97%] [G loss: 0.771841]\n",
      "epoch:8 step:7565 [D loss: 0.630828, acc.: 71.09%] [G loss: 0.759091]\n",
      "epoch:8 step:7566 [D loss: 0.629101, acc.: 69.53%] [G loss: 0.802489]\n",
      "epoch:8 step:7567 [D loss: 0.793087, acc.: 31.25%] [G loss: 0.742807]\n",
      "epoch:8 step:7568 [D loss: 0.716253, acc.: 42.19%] [G loss: 0.721836]\n",
      "epoch:8 step:7569 [D loss: 0.681149, acc.: 53.91%] [G loss: 0.766720]\n",
      "epoch:8 step:7570 [D loss: 0.690178, acc.: 49.22%] [G loss: 0.757982]\n",
      "epoch:8 step:7571 [D loss: 0.625892, acc.: 64.06%] [G loss: 0.728543]\n",
      "epoch:8 step:7572 [D loss: 0.626218, acc.: 66.41%] [G loss: 0.737967]\n",
      "epoch:8 step:7573 [D loss: 0.561629, acc.: 75.78%] [G loss: 0.764798]\n",
      "epoch:8 step:7574 [D loss: 0.706198, acc.: 50.00%] [G loss: 0.755957]\n",
      "epoch:8 step:7575 [D loss: 0.669760, acc.: 62.50%] [G loss: 0.681188]\n",
      "epoch:8 step:7576 [D loss: 0.731079, acc.: 35.94%] [G loss: 0.777442]\n",
      "epoch:8 step:7577 [D loss: 0.722148, acc.: 42.19%] [G loss: 0.730765]\n",
      "epoch:8 step:7578 [D loss: 0.741014, acc.: 36.72%] [G loss: 0.745412]\n",
      "epoch:8 step:7579 [D loss: 0.669036, acc.: 63.28%] [G loss: 0.751843]\n",
      "epoch:8 step:7580 [D loss: 0.688752, acc.: 56.25%] [G loss: 0.616791]\n",
      "epoch:8 step:7581 [D loss: 0.716548, acc.: 43.75%] [G loss: 0.801982]\n",
      "epoch:8 step:7582 [D loss: 0.685104, acc.: 56.25%] [G loss: 0.799045]\n",
      "epoch:8 step:7583 [D loss: 0.771181, acc.: 32.03%] [G loss: 0.806668]\n",
      "epoch:8 step:7584 [D loss: 0.663760, acc.: 62.50%] [G loss: 0.798622]\n",
      "epoch:8 step:7585 [D loss: 0.653214, acc.: 66.41%] [G loss: 0.855705]\n",
      "epoch:8 step:7586 [D loss: 0.678062, acc.: 55.47%] [G loss: 0.828405]\n",
      "epoch:8 step:7587 [D loss: 0.689708, acc.: 55.47%] [G loss: 0.769110]\n",
      "epoch:8 step:7588 [D loss: 0.680994, acc.: 58.59%] [G loss: 0.842488]\n",
      "epoch:8 step:7589 [D loss: 0.695049, acc.: 57.81%] [G loss: 0.792733]\n",
      "epoch:8 step:7590 [D loss: 0.708101, acc.: 51.56%] [G loss: 0.750058]\n",
      "epoch:8 step:7591 [D loss: 0.707044, acc.: 52.34%] [G loss: 0.785619]\n",
      "epoch:8 step:7592 [D loss: 0.720340, acc.: 44.53%] [G loss: 0.727239]\n",
      "epoch:8 step:7593 [D loss: 0.676221, acc.: 55.47%] [G loss: 0.687430]\n",
      "epoch:8 step:7594 [D loss: 0.683473, acc.: 56.25%] [G loss: 0.653656]\n",
      "epoch:8 step:7595 [D loss: 0.689265, acc.: 51.56%] [G loss: 0.700235]\n",
      "epoch:8 step:7596 [D loss: 0.680324, acc.: 58.59%] [G loss: 0.688201]\n",
      "epoch:8 step:7597 [D loss: 0.673362, acc.: 60.94%] [G loss: 0.758220]\n",
      "epoch:8 step:7598 [D loss: 0.772450, acc.: 38.28%] [G loss: 0.811002]\n",
      "epoch:8 step:7599 [D loss: 0.680903, acc.: 53.12%] [G loss: 0.794123]\n",
      "epoch:8 step:7600 [D loss: 0.717322, acc.: 41.41%] [G loss: 0.750647]\n",
      "##############\n",
      "[3.77431469 2.3422724  6.5868619  5.51133012 4.36601688 6.0245482\n",
      " 5.03416883 6.03053134 5.64612448 5.09577139]\n",
      "##########\n",
      "epoch:8 step:7601 [D loss: 0.753639, acc.: 36.72%] [G loss: 0.751890]\n",
      "epoch:8 step:7602 [D loss: 0.697288, acc.: 53.91%] [G loss: 0.586895]\n",
      "epoch:8 step:7603 [D loss: 0.677485, acc.: 50.78%] [G loss: 0.743359]\n",
      "epoch:8 step:7604 [D loss: 0.705796, acc.: 47.66%] [G loss: 0.741342]\n",
      "epoch:8 step:7605 [D loss: 0.691650, acc.: 53.91%] [G loss: 0.773586]\n",
      "epoch:8 step:7606 [D loss: 0.676063, acc.: 62.50%] [G loss: 0.749451]\n",
      "epoch:8 step:7607 [D loss: 0.703268, acc.: 49.22%] [G loss: 0.618524]\n",
      "epoch:8 step:7608 [D loss: 0.673168, acc.: 53.91%] [G loss: 0.770126]\n",
      "epoch:8 step:7609 [D loss: 0.704934, acc.: 46.88%] [G loss: 0.745650]\n",
      "epoch:8 step:7610 [D loss: 0.697540, acc.: 53.12%] [G loss: 0.737911]\n",
      "epoch:8 step:7611 [D loss: 0.691617, acc.: 56.25%] [G loss: 0.759064]\n",
      "epoch:8 step:7612 [D loss: 0.687534, acc.: 55.47%] [G loss: 0.742006]\n",
      "epoch:8 step:7613 [D loss: 0.677636, acc.: 59.38%] [G loss: 0.749353]\n",
      "epoch:8 step:7614 [D loss: 0.650554, acc.: 68.75%] [G loss: 0.751726]\n",
      "epoch:8 step:7615 [D loss: 0.619356, acc.: 69.53%] [G loss: 0.579198]\n",
      "epoch:8 step:7616 [D loss: 0.710927, acc.: 52.34%] [G loss: 0.773910]\n",
      "epoch:8 step:7617 [D loss: 0.726168, acc.: 44.53%] [G loss: 0.766866]\n",
      "epoch:8 step:7618 [D loss: 0.690053, acc.: 50.78%] [G loss: 0.786063]\n",
      "epoch:8 step:7619 [D loss: 0.691694, acc.: 47.66%] [G loss: 0.795853]\n",
      "epoch:8 step:7620 [D loss: 0.671838, acc.: 60.94%] [G loss: 0.852082]\n",
      "epoch:8 step:7621 [D loss: 0.684409, acc.: 53.12%] [G loss: 0.842810]\n",
      "epoch:8 step:7622 [D loss: 0.656585, acc.: 71.88%] [G loss: 0.792584]\n",
      "epoch:8 step:7623 [D loss: 0.669311, acc.: 60.16%] [G loss: 0.818317]\n",
      "epoch:8 step:7624 [D loss: 0.685513, acc.: 53.91%] [G loss: 0.808608]\n",
      "epoch:8 step:7625 [D loss: 0.677369, acc.: 57.03%] [G loss: 0.783055]\n",
      "epoch:8 step:7626 [D loss: 0.656921, acc.: 64.06%] [G loss: 0.780146]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7627 [D loss: 0.674170, acc.: 55.47%] [G loss: 0.722889]\n",
      "epoch:8 step:7628 [D loss: 0.665119, acc.: 61.72%] [G loss: 0.790260]\n",
      "epoch:8 step:7629 [D loss: 0.659845, acc.: 64.06%] [G loss: 0.791274]\n",
      "epoch:8 step:7630 [D loss: 0.682597, acc.: 55.47%] [G loss: 0.797281]\n",
      "epoch:8 step:7631 [D loss: 0.663182, acc.: 62.50%] [G loss: 0.750740]\n",
      "epoch:8 step:7632 [D loss: 0.649567, acc.: 62.50%] [G loss: 0.734690]\n",
      "epoch:8 step:7633 [D loss: 0.726062, acc.: 46.88%] [G loss: 0.712831]\n",
      "epoch:8 step:7634 [D loss: 0.716025, acc.: 42.19%] [G loss: 0.716970]\n",
      "epoch:8 step:7635 [D loss: 0.740219, acc.: 42.19%] [G loss: 0.670392]\n",
      "epoch:8 step:7636 [D loss: 0.703995, acc.: 48.44%] [G loss: 0.757077]\n",
      "epoch:8 step:7637 [D loss: 0.713803, acc.: 48.44%] [G loss: 0.768696]\n",
      "epoch:8 step:7638 [D loss: 0.692278, acc.: 59.38%] [G loss: 0.776664]\n",
      "epoch:8 step:7639 [D loss: 0.680616, acc.: 57.81%] [G loss: 0.775207]\n",
      "epoch:8 step:7640 [D loss: 0.683471, acc.: 54.69%] [G loss: 0.774178]\n",
      "epoch:8 step:7641 [D loss: 0.626621, acc.: 67.97%] [G loss: 0.760823]\n",
      "epoch:8 step:7642 [D loss: 0.663401, acc.: 57.03%] [G loss: 0.800449]\n",
      "epoch:8 step:7643 [D loss: 0.683162, acc.: 53.12%] [G loss: 0.792276]\n",
      "epoch:8 step:7644 [D loss: 0.688039, acc.: 57.03%] [G loss: 0.786729]\n",
      "epoch:8 step:7645 [D loss: 0.646482, acc.: 61.72%] [G loss: 0.788454]\n",
      "epoch:8 step:7646 [D loss: 0.543210, acc.: 80.47%] [G loss: 0.798757]\n",
      "epoch:8 step:7647 [D loss: 0.585265, acc.: 76.56%] [G loss: 0.700691]\n",
      "epoch:8 step:7648 [D loss: 0.611648, acc.: 75.00%] [G loss: 0.733468]\n",
      "epoch:8 step:7649 [D loss: 0.747904, acc.: 45.31%] [G loss: 0.599176]\n",
      "epoch:8 step:7650 [D loss: 0.710247, acc.: 52.34%] [G loss: 0.680177]\n",
      "epoch:8 step:7651 [D loss: 0.703139, acc.: 53.91%] [G loss: 0.721260]\n",
      "epoch:8 step:7652 [D loss: 0.693491, acc.: 53.12%] [G loss: 0.748896]\n",
      "epoch:8 step:7653 [D loss: 0.712720, acc.: 46.88%] [G loss: 0.618195]\n",
      "epoch:8 step:7654 [D loss: 0.802990, acc.: 39.06%] [G loss: 0.665029]\n",
      "epoch:8 step:7655 [D loss: 0.732249, acc.: 40.62%] [G loss: 0.748784]\n",
      "epoch:8 step:7656 [D loss: 0.706089, acc.: 55.47%] [G loss: 0.822707]\n",
      "epoch:8 step:7657 [D loss: 0.703294, acc.: 45.31%] [G loss: 0.826865]\n",
      "epoch:8 step:7658 [D loss: 0.670688, acc.: 58.59%] [G loss: 0.726193]\n",
      "epoch:8 step:7659 [D loss: 0.647968, acc.: 67.97%] [G loss: 0.876706]\n",
      "epoch:8 step:7660 [D loss: 0.633356, acc.: 64.84%] [G loss: 0.709424]\n",
      "epoch:8 step:7661 [D loss: 0.662394, acc.: 62.50%] [G loss: 0.871122]\n",
      "epoch:8 step:7662 [D loss: 0.672966, acc.: 57.03%] [G loss: 0.778595]\n",
      "epoch:8 step:7663 [D loss: 0.698933, acc.: 53.91%] [G loss: 0.757298]\n",
      "epoch:8 step:7664 [D loss: 0.674524, acc.: 55.47%] [G loss: 0.777011]\n",
      "epoch:8 step:7665 [D loss: 0.724135, acc.: 46.09%] [G loss: 0.619180]\n",
      "epoch:8 step:7666 [D loss: 0.727985, acc.: 45.31%] [G loss: 0.612820]\n",
      "epoch:8 step:7667 [D loss: 0.673844, acc.: 58.59%] [G loss: 0.766936]\n",
      "epoch:8 step:7668 [D loss: 0.691525, acc.: 52.34%] [G loss: 0.773084]\n",
      "epoch:8 step:7669 [D loss: 0.664442, acc.: 60.94%] [G loss: 0.756853]\n",
      "epoch:8 step:7670 [D loss: 0.703440, acc.: 50.00%] [G loss: 0.794191]\n",
      "epoch:8 step:7671 [D loss: 0.699873, acc.: 51.56%] [G loss: 0.738140]\n",
      "epoch:8 step:7672 [D loss: 0.657650, acc.: 60.94%] [G loss: 0.743823]\n",
      "epoch:8 step:7673 [D loss: 0.710263, acc.: 47.66%] [G loss: 0.760123]\n",
      "epoch:8 step:7674 [D loss: 0.696702, acc.: 50.78%] [G loss: 0.771068]\n",
      "epoch:8 step:7675 [D loss: 0.708917, acc.: 52.34%] [G loss: 0.766629]\n",
      "epoch:8 step:7676 [D loss: 0.701024, acc.: 53.12%] [G loss: 0.788826]\n",
      "epoch:8 step:7677 [D loss: 0.650251, acc.: 62.50%] [G loss: 0.765520]\n",
      "epoch:8 step:7678 [D loss: 0.664986, acc.: 63.28%] [G loss: 0.809148]\n",
      "epoch:8 step:7679 [D loss: 0.667951, acc.: 55.47%] [G loss: 0.803568]\n",
      "epoch:8 step:7680 [D loss: 0.619034, acc.: 65.62%] [G loss: 0.759697]\n",
      "epoch:8 step:7681 [D loss: 0.673206, acc.: 53.12%] [G loss: 0.791326]\n",
      "epoch:8 step:7682 [D loss: 0.697129, acc.: 57.03%] [G loss: 0.819812]\n",
      "epoch:8 step:7683 [D loss: 0.643182, acc.: 63.28%] [G loss: 0.696913]\n",
      "epoch:8 step:7684 [D loss: 0.694528, acc.: 53.91%] [G loss: 0.786375]\n",
      "epoch:8 step:7685 [D loss: 0.678262, acc.: 62.50%] [G loss: 0.753786]\n",
      "epoch:8 step:7686 [D loss: 0.655320, acc.: 62.50%] [G loss: 0.792988]\n",
      "epoch:8 step:7687 [D loss: 0.686047, acc.: 54.69%] [G loss: 0.754810]\n",
      "epoch:8 step:7688 [D loss: 0.672248, acc.: 60.94%] [G loss: 0.688631]\n",
      "epoch:8 step:7689 [D loss: 0.678082, acc.: 58.59%] [G loss: 0.743980]\n",
      "epoch:8 step:7690 [D loss: 0.688350, acc.: 57.81%] [G loss: 0.745078]\n",
      "epoch:8 step:7691 [D loss: 0.675181, acc.: 62.50%] [G loss: 0.731430]\n",
      "epoch:8 step:7692 [D loss: 0.671910, acc.: 53.91%] [G loss: 0.777631]\n",
      "epoch:8 step:7693 [D loss: 0.721994, acc.: 51.56%] [G loss: 0.720196]\n",
      "epoch:8 step:7694 [D loss: 0.667838, acc.: 57.03%] [G loss: 0.859150]\n",
      "epoch:8 step:7695 [D loss: 0.662956, acc.: 56.25%] [G loss: 0.786059]\n",
      "epoch:8 step:7696 [D loss: 0.687698, acc.: 59.38%] [G loss: 0.892270]\n",
      "epoch:8 step:7697 [D loss: 0.643002, acc.: 63.28%] [G loss: 0.824630]\n",
      "epoch:8 step:7698 [D loss: 0.676006, acc.: 57.03%] [G loss: 0.806123]\n",
      "epoch:8 step:7699 [D loss: 0.653520, acc.: 57.03%] [G loss: 0.830013]\n",
      "epoch:8 step:7700 [D loss: 0.543703, acc.: 72.66%] [G loss: 0.901529]\n",
      "epoch:8 step:7701 [D loss: 0.675141, acc.: 61.72%] [G loss: 0.844990]\n",
      "epoch:8 step:7702 [D loss: 0.662131, acc.: 57.03%] [G loss: 0.810590]\n",
      "epoch:8 step:7703 [D loss: 0.505506, acc.: 71.88%] [G loss: 0.772998]\n",
      "epoch:8 step:7704 [D loss: 0.648277, acc.: 61.72%] [G loss: 0.774908]\n",
      "epoch:8 step:7705 [D loss: 0.638558, acc.: 62.50%] [G loss: 0.745777]\n",
      "epoch:8 step:7706 [D loss: 0.742758, acc.: 42.97%] [G loss: 0.763529]\n",
      "epoch:8 step:7707 [D loss: 0.709890, acc.: 49.22%] [G loss: 0.715750]\n",
      "epoch:8 step:7708 [D loss: 0.693499, acc.: 56.25%] [G loss: 0.740015]\n",
      "epoch:8 step:7709 [D loss: 0.700070, acc.: 53.91%] [G loss: 0.795554]\n",
      "epoch:8 step:7710 [D loss: 0.718358, acc.: 48.44%] [G loss: 0.757940]\n",
      "epoch:8 step:7711 [D loss: 0.719032, acc.: 44.53%] [G loss: 0.751995]\n",
      "epoch:8 step:7712 [D loss: 0.475762, acc.: 72.66%] [G loss: 0.808162]\n",
      "epoch:8 step:7713 [D loss: 0.655923, acc.: 60.94%] [G loss: 0.813678]\n",
      "epoch:8 step:7714 [D loss: 0.873902, acc.: 41.41%] [G loss: 0.875405]\n",
      "epoch:8 step:7715 [D loss: 0.592844, acc.: 73.44%] [G loss: 0.940227]\n",
      "epoch:8 step:7716 [D loss: 0.617490, acc.: 66.41%] [G loss: 0.913341]\n",
      "epoch:8 step:7717 [D loss: 0.562061, acc.: 78.91%] [G loss: 0.971237]\n",
      "epoch:8 step:7718 [D loss: 0.615264, acc.: 68.75%] [G loss: 0.877632]\n",
      "epoch:8 step:7719 [D loss: 0.593997, acc.: 75.00%] [G loss: 0.898113]\n",
      "epoch:8 step:7720 [D loss: 0.736493, acc.: 52.34%] [G loss: 0.689877]\n",
      "epoch:8 step:7721 [D loss: 0.728128, acc.: 47.66%] [G loss: 0.806310]\n",
      "epoch:8 step:7722 [D loss: 0.761621, acc.: 40.62%] [G loss: 0.761361]\n",
      "epoch:8 step:7723 [D loss: 0.710994, acc.: 53.12%] [G loss: 0.735660]\n",
      "epoch:8 step:7724 [D loss: 0.700626, acc.: 53.12%] [G loss: 0.790919]\n",
      "epoch:8 step:7725 [D loss: 0.682622, acc.: 51.56%] [G loss: 0.800094]\n",
      "epoch:8 step:7726 [D loss: 0.572095, acc.: 64.84%] [G loss: 0.742765]\n",
      "epoch:8 step:7727 [D loss: 0.536882, acc.: 67.97%] [G loss: 0.852914]\n",
      "epoch:8 step:7728 [D loss: 0.518869, acc.: 78.12%] [G loss: 0.819313]\n",
      "epoch:8 step:7729 [D loss: 0.701560, acc.: 52.34%] [G loss: 1.091265]\n",
      "epoch:8 step:7730 [D loss: 0.609777, acc.: 68.75%] [G loss: 0.900106]\n",
      "epoch:8 step:7731 [D loss: 0.493680, acc.: 79.69%] [G loss: 0.896507]\n",
      "epoch:8 step:7732 [D loss: 0.683722, acc.: 57.81%] [G loss: 0.899706]\n",
      "epoch:8 step:7733 [D loss: 0.616593, acc.: 67.19%] [G loss: 1.016179]\n",
      "epoch:8 step:7734 [D loss: 0.705688, acc.: 54.69%] [G loss: 0.936328]\n",
      "epoch:8 step:7735 [D loss: 0.716999, acc.: 49.22%] [G loss: 1.031173]\n",
      "epoch:8 step:7736 [D loss: 0.784272, acc.: 35.16%] [G loss: 0.933580]\n",
      "epoch:8 step:7737 [D loss: 0.745818, acc.: 32.03%] [G loss: 0.943048]\n",
      "epoch:8 step:7738 [D loss: 0.788928, acc.: 35.94%] [G loss: 0.904670]\n",
      "epoch:8 step:7739 [D loss: 0.713582, acc.: 50.78%] [G loss: 0.884049]\n",
      "epoch:8 step:7740 [D loss: 0.669558, acc.: 60.94%] [G loss: 0.911660]\n",
      "epoch:8 step:7741 [D loss: 0.652537, acc.: 64.06%] [G loss: 0.859898]\n",
      "epoch:8 step:7742 [D loss: 0.689320, acc.: 56.25%] [G loss: 0.900919]\n",
      "epoch:8 step:7743 [D loss: 0.664702, acc.: 60.16%] [G loss: 0.859452]\n",
      "epoch:8 step:7744 [D loss: 0.656577, acc.: 67.97%] [G loss: 0.811974]\n",
      "epoch:8 step:7745 [D loss: 0.738758, acc.: 45.31%] [G loss: 0.855549]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7746 [D loss: 0.695789, acc.: 51.56%] [G loss: 0.821840]\n",
      "epoch:8 step:7747 [D loss: 0.729915, acc.: 46.09%] [G loss: 0.727150]\n",
      "epoch:8 step:7748 [D loss: 0.689032, acc.: 47.66%] [G loss: 0.724780]\n",
      "epoch:8 step:7749 [D loss: 0.711757, acc.: 53.91%] [G loss: 0.715037]\n",
      "epoch:8 step:7750 [D loss: 0.709049, acc.: 45.31%] [G loss: 0.758538]\n",
      "epoch:8 step:7751 [D loss: 0.711597, acc.: 46.09%] [G loss: 0.675790]\n",
      "epoch:8 step:7752 [D loss: 0.698467, acc.: 51.56%] [G loss: 0.733413]\n",
      "epoch:8 step:7753 [D loss: 0.672660, acc.: 61.72%] [G loss: 0.723785]\n",
      "epoch:8 step:7754 [D loss: 0.693337, acc.: 57.03%] [G loss: 0.702607]\n",
      "epoch:8 step:7755 [D loss: 0.646010, acc.: 60.16%] [G loss: 0.680985]\n",
      "epoch:8 step:7756 [D loss: 0.656404, acc.: 60.94%] [G loss: 0.745547]\n",
      "epoch:8 step:7757 [D loss: 0.628238, acc.: 64.06%] [G loss: 0.754403]\n",
      "epoch:8 step:7758 [D loss: 0.688301, acc.: 57.03%] [G loss: 0.751101]\n",
      "epoch:8 step:7759 [D loss: 0.720071, acc.: 49.22%] [G loss: 0.804497]\n",
      "epoch:8 step:7760 [D loss: 0.679371, acc.: 52.34%] [G loss: 0.803164]\n",
      "epoch:8 step:7761 [D loss: 0.601449, acc.: 77.34%] [G loss: 0.810163]\n",
      "epoch:8 step:7762 [D loss: 0.741471, acc.: 33.59%] [G loss: 0.698455]\n",
      "epoch:8 step:7763 [D loss: 0.686935, acc.: 58.59%] [G loss: 0.706224]\n",
      "epoch:8 step:7764 [D loss: 0.694111, acc.: 50.00%] [G loss: 0.692874]\n",
      "epoch:8 step:7765 [D loss: 0.682920, acc.: 58.59%] [G loss: 0.809405]\n",
      "epoch:8 step:7766 [D loss: 0.684557, acc.: 50.78%] [G loss: 0.808377]\n",
      "epoch:8 step:7767 [D loss: 0.723628, acc.: 39.06%] [G loss: 0.782459]\n",
      "epoch:8 step:7768 [D loss: 0.737167, acc.: 33.59%] [G loss: 0.765079]\n",
      "epoch:8 step:7769 [D loss: 0.655976, acc.: 66.41%] [G loss: 0.808849]\n",
      "epoch:8 step:7770 [D loss: 0.627057, acc.: 76.56%] [G loss: 0.900193]\n",
      "epoch:8 step:7771 [D loss: 0.653853, acc.: 60.94%] [G loss: 0.784746]\n",
      "epoch:8 step:7772 [D loss: 0.652874, acc.: 62.50%] [G loss: 0.969468]\n",
      "epoch:8 step:7773 [D loss: 0.685614, acc.: 53.91%] [G loss: 0.705405]\n",
      "epoch:8 step:7774 [D loss: 0.688807, acc.: 54.69%] [G loss: 0.865803]\n",
      "epoch:8 step:7775 [D loss: 0.624427, acc.: 72.66%] [G loss: 0.728581]\n",
      "epoch:8 step:7776 [D loss: 0.730688, acc.: 45.31%] [G loss: 0.777994]\n",
      "epoch:8 step:7777 [D loss: 0.703094, acc.: 49.22%] [G loss: 0.793485]\n",
      "epoch:8 step:7778 [D loss: 0.684196, acc.: 50.78%] [G loss: 0.760666]\n",
      "epoch:8 step:7779 [D loss: 0.716709, acc.: 57.03%] [G loss: 0.607120]\n",
      "epoch:8 step:7780 [D loss: 0.683318, acc.: 54.69%] [G loss: 0.727759]\n",
      "epoch:8 step:7781 [D loss: 0.696770, acc.: 44.53%] [G loss: 0.718477]\n",
      "epoch:8 step:7782 [D loss: 0.688432, acc.: 54.69%] [G loss: 0.773465]\n",
      "epoch:8 step:7783 [D loss: 0.611337, acc.: 76.56%] [G loss: 0.791973]\n",
      "epoch:8 step:7784 [D loss: 0.564057, acc.: 78.12%] [G loss: 0.793583]\n",
      "epoch:8 step:7785 [D loss: 0.543114, acc.: 74.22%] [G loss: 0.821870]\n",
      "epoch:8 step:7786 [D loss: 0.535850, acc.: 77.34%] [G loss: 0.812476]\n",
      "epoch:8 step:7787 [D loss: 0.708834, acc.: 49.22%] [G loss: 0.726038]\n",
      "epoch:8 step:7788 [D loss: 0.566888, acc.: 59.38%] [G loss: 0.824123]\n",
      "epoch:8 step:7789 [D loss: 0.541670, acc.: 82.03%] [G loss: 0.868534]\n",
      "epoch:8 step:7790 [D loss: 0.593651, acc.: 75.00%] [G loss: 0.926601]\n",
      "epoch:8 step:7791 [D loss: 0.689298, acc.: 60.94%] [G loss: 0.795366]\n",
      "epoch:8 step:7792 [D loss: 0.686801, acc.: 53.12%] [G loss: 0.872253]\n",
      "epoch:8 step:7793 [D loss: 0.713877, acc.: 50.78%] [G loss: 0.793875]\n",
      "epoch:8 step:7794 [D loss: 0.728709, acc.: 39.06%] [G loss: 0.768710]\n",
      "epoch:8 step:7795 [D loss: 0.880735, acc.: 27.34%] [G loss: 0.549884]\n",
      "epoch:8 step:7796 [D loss: 0.681290, acc.: 53.12%] [G loss: 0.819672]\n",
      "epoch:8 step:7797 [D loss: 0.807407, acc.: 45.31%] [G loss: 0.801752]\n",
      "epoch:8 step:7798 [D loss: 0.675228, acc.: 62.50%] [G loss: 0.633032]\n",
      "epoch:8 step:7799 [D loss: 0.678842, acc.: 53.91%] [G loss: 0.781328]\n",
      "epoch:8 step:7800 [D loss: 0.753427, acc.: 40.62%] [G loss: 0.614224]\n",
      "##############\n",
      "[3.81069466 2.00742544 6.23245744 5.49010855 4.16470086 6.03614763\n",
      " 5.00843291 5.40754146 5.43920282 4.46322159]\n",
      "##########\n",
      "epoch:8 step:7801 [D loss: 0.631349, acc.: 77.34%] [G loss: 0.810338]\n",
      "epoch:8 step:7802 [D loss: 0.689290, acc.: 50.00%] [G loss: 0.594357]\n",
      "epoch:8 step:7803 [D loss: 0.674442, acc.: 57.81%] [G loss: 0.794649]\n",
      "epoch:8 step:7804 [D loss: 0.713409, acc.: 45.31%] [G loss: 0.614439]\n",
      "epoch:8 step:7805 [D loss: 0.512364, acc.: 84.38%] [G loss: 0.815040]\n",
      "epoch:8 step:7806 [D loss: 0.663934, acc.: 64.06%] [G loss: 0.826316]\n",
      "epoch:8 step:7807 [D loss: 0.639035, acc.: 73.44%] [G loss: 0.721536]\n",
      "epoch:8 step:7808 [D loss: 0.538901, acc.: 72.66%] [G loss: 0.467611]\n",
      "epoch:8 step:7809 [D loss: 0.516494, acc.: 71.09%] [G loss: 0.566182]\n",
      "epoch:8 step:7810 [D loss: 0.474887, acc.: 69.53%] [G loss: 0.904443]\n",
      "epoch:8 step:7811 [D loss: 0.760202, acc.: 49.22%] [G loss: 0.697754]\n",
      "epoch:8 step:7812 [D loss: 0.871246, acc.: 23.44%] [G loss: 0.952745]\n",
      "epoch:8 step:7813 [D loss: 0.803074, acc.: 27.34%] [G loss: 0.923859]\n",
      "epoch:8 step:7814 [D loss: 0.651626, acc.: 60.16%] [G loss: 0.995678]\n",
      "epoch:8 step:7815 [D loss: 0.641659, acc.: 55.47%] [G loss: 0.990572]\n",
      "epoch:8 step:7816 [D loss: 0.641931, acc.: 57.03%] [G loss: 0.987365]\n",
      "epoch:8 step:7817 [D loss: 0.657928, acc.: 59.38%] [G loss: 1.046010]\n",
      "epoch:8 step:7818 [D loss: 0.611380, acc.: 66.41%] [G loss: 1.175125]\n",
      "epoch:8 step:7819 [D loss: 0.662292, acc.: 57.81%] [G loss: 1.008878]\n",
      "epoch:8 step:7820 [D loss: 0.646606, acc.: 64.06%] [G loss: 0.952632]\n",
      "epoch:8 step:7821 [D loss: 0.582444, acc.: 72.66%] [G loss: 1.039999]\n",
      "epoch:8 step:7822 [D loss: 0.663110, acc.: 57.81%] [G loss: 0.879372]\n",
      "epoch:8 step:7823 [D loss: 0.491482, acc.: 90.62%] [G loss: 1.189592]\n",
      "epoch:8 step:7824 [D loss: 0.514653, acc.: 91.41%] [G loss: 1.327158]\n",
      "epoch:8 step:7825 [D loss: 0.712890, acc.: 53.12%] [G loss: 1.224860]\n",
      "epoch:8 step:7826 [D loss: 0.591450, acc.: 64.06%] [G loss: 1.275057]\n",
      "epoch:8 step:7827 [D loss: 0.638364, acc.: 57.81%] [G loss: 1.176767]\n",
      "epoch:8 step:7828 [D loss: 0.688912, acc.: 48.44%] [G loss: 1.094392]\n",
      "epoch:8 step:7829 [D loss: 0.966705, acc.: 17.97%] [G loss: 0.833362]\n",
      "epoch:8 step:7830 [D loss: 0.778260, acc.: 35.94%] [G loss: 0.692156]\n",
      "epoch:8 step:7831 [D loss: 0.760437, acc.: 35.94%] [G loss: 0.678985]\n",
      "epoch:8 step:7832 [D loss: 0.730731, acc.: 40.62%] [G loss: 0.757738]\n",
      "epoch:8 step:7833 [D loss: 0.667494, acc.: 53.91%] [G loss: 0.775901]\n",
      "epoch:8 step:7834 [D loss: 0.691325, acc.: 50.00%] [G loss: 0.707041]\n",
      "epoch:8 step:7835 [D loss: 0.719233, acc.: 55.47%] [G loss: 0.761897]\n",
      "epoch:8 step:7836 [D loss: 0.679991, acc.: 57.81%] [G loss: 0.738037]\n",
      "epoch:8 step:7837 [D loss: 0.680016, acc.: 54.69%] [G loss: 0.684192]\n",
      "epoch:8 step:7838 [D loss: 0.677392, acc.: 60.16%] [G loss: 0.746122]\n",
      "epoch:8 step:7839 [D loss: 0.681073, acc.: 51.56%] [G loss: 0.786632]\n",
      "epoch:8 step:7840 [D loss: 0.657937, acc.: 63.28%] [G loss: 0.772399]\n",
      "epoch:8 step:7841 [D loss: 0.682270, acc.: 51.56%] [G loss: 0.743007]\n",
      "epoch:8 step:7842 [D loss: 0.630767, acc.: 62.50%] [G loss: 0.767715]\n",
      "epoch:8 step:7843 [D loss: 0.629505, acc.: 66.41%] [G loss: 0.797922]\n",
      "epoch:8 step:7844 [D loss: 0.681536, acc.: 55.47%] [G loss: 0.804771]\n",
      "epoch:8 step:7845 [D loss: 0.688215, acc.: 56.25%] [G loss: 0.782953]\n",
      "epoch:8 step:7846 [D loss: 0.687244, acc.: 56.25%] [G loss: 0.757245]\n",
      "epoch:8 step:7847 [D loss: 0.679108, acc.: 57.03%] [G loss: 0.705962]\n",
      "epoch:8 step:7848 [D loss: 0.681380, acc.: 57.03%] [G loss: 0.807466]\n",
      "epoch:8 step:7849 [D loss: 0.681702, acc.: 55.47%] [G loss: 0.747684]\n",
      "epoch:8 step:7850 [D loss: 0.648212, acc.: 65.62%] [G loss: 0.876641]\n",
      "epoch:8 step:7851 [D loss: 0.675136, acc.: 63.28%] [G loss: 0.815325]\n",
      "epoch:8 step:7852 [D loss: 0.714015, acc.: 42.19%] [G loss: 0.747005]\n",
      "epoch:8 step:7853 [D loss: 0.678208, acc.: 60.16%] [G loss: 0.774086]\n",
      "epoch:8 step:7854 [D loss: 0.673548, acc.: 57.81%] [G loss: 0.837232]\n",
      "epoch:8 step:7855 [D loss: 0.647679, acc.: 60.16%] [G loss: 0.748676]\n",
      "epoch:8 step:7856 [D loss: 0.659959, acc.: 54.69%] [G loss: 0.870661]\n",
      "epoch:8 step:7857 [D loss: 0.678327, acc.: 58.59%] [G loss: 0.908496]\n",
      "epoch:8 step:7858 [D loss: 0.735866, acc.: 46.09%] [G loss: 0.814081]\n",
      "epoch:8 step:7859 [D loss: 0.716776, acc.: 48.44%] [G loss: 0.791563]\n",
      "epoch:8 step:7860 [D loss: 0.643241, acc.: 64.06%] [G loss: 0.779427]\n",
      "epoch:8 step:7861 [D loss: 0.678003, acc.: 49.22%] [G loss: 0.775286]\n",
      "epoch:8 step:7862 [D loss: 0.641684, acc.: 58.59%] [G loss: 0.836742]\n",
      "epoch:8 step:7863 [D loss: 0.686872, acc.: 53.91%] [G loss: 0.735049]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7864 [D loss: 0.690336, acc.: 53.12%] [G loss: 0.780156]\n",
      "epoch:8 step:7865 [D loss: 0.703266, acc.: 51.56%] [G loss: 0.765353]\n",
      "epoch:8 step:7866 [D loss: 0.714922, acc.: 48.44%] [G loss: 0.754480]\n",
      "epoch:8 step:7867 [D loss: 0.648119, acc.: 58.59%] [G loss: 0.776288]\n",
      "epoch:8 step:7868 [D loss: 0.649578, acc.: 61.72%] [G loss: 0.728043]\n",
      "epoch:8 step:7869 [D loss: 0.721884, acc.: 46.09%] [G loss: 0.757466]\n",
      "epoch:8 step:7870 [D loss: 0.666583, acc.: 57.81%] [G loss: 0.783494]\n",
      "epoch:8 step:7871 [D loss: 0.674377, acc.: 57.03%] [G loss: 0.730233]\n",
      "epoch:8 step:7872 [D loss: 0.673302, acc.: 57.03%] [G loss: 0.765260]\n",
      "epoch:8 step:7873 [D loss: 0.740293, acc.: 48.44%] [G loss: 0.787943]\n",
      "epoch:8 step:7874 [D loss: 0.690106, acc.: 60.16%] [G loss: 0.714239]\n",
      "epoch:8 step:7875 [D loss: 0.688167, acc.: 47.66%] [G loss: 0.715698]\n",
      "epoch:8 step:7876 [D loss: 0.680110, acc.: 55.47%] [G loss: 0.746057]\n",
      "epoch:8 step:7877 [D loss: 0.682487, acc.: 58.59%] [G loss: 0.717194]\n",
      "epoch:8 step:7878 [D loss: 0.687506, acc.: 53.12%] [G loss: 0.742700]\n",
      "epoch:8 step:7879 [D loss: 0.697660, acc.: 51.56%] [G loss: 0.739892]\n",
      "epoch:8 step:7880 [D loss: 0.668966, acc.: 55.47%] [G loss: 0.770528]\n",
      "epoch:8 step:7881 [D loss: 0.668023, acc.: 54.69%] [G loss: 0.750848]\n",
      "epoch:8 step:7882 [D loss: 0.673696, acc.: 57.03%] [G loss: 0.780348]\n",
      "epoch:8 step:7883 [D loss: 0.644846, acc.: 65.62%] [G loss: 0.806371]\n",
      "epoch:8 step:7884 [D loss: 0.657891, acc.: 60.16%] [G loss: 0.777277]\n",
      "epoch:8 step:7885 [D loss: 0.716073, acc.: 50.78%] [G loss: 0.762350]\n",
      "epoch:8 step:7886 [D loss: 0.694951, acc.: 46.88%] [G loss: 0.761274]\n",
      "epoch:8 step:7887 [D loss: 0.698603, acc.: 52.34%] [G loss: 0.803371]\n",
      "epoch:8 step:7888 [D loss: 0.700008, acc.: 54.69%] [G loss: 0.692503]\n",
      "epoch:8 step:7889 [D loss: 0.708967, acc.: 49.22%] [G loss: 0.740527]\n",
      "epoch:8 step:7890 [D loss: 0.729230, acc.: 46.88%] [G loss: 0.766565]\n",
      "epoch:8 step:7891 [D loss: 0.714517, acc.: 43.75%] [G loss: 0.721776]\n",
      "epoch:8 step:7892 [D loss: 0.710317, acc.: 51.56%] [G loss: 0.763130]\n",
      "epoch:8 step:7893 [D loss: 0.681661, acc.: 53.12%] [G loss: 0.767329]\n",
      "epoch:8 step:7894 [D loss: 0.584530, acc.: 71.88%] [G loss: 0.792141]\n",
      "epoch:8 step:7895 [D loss: 0.553001, acc.: 82.03%] [G loss: 0.819102]\n",
      "epoch:8 step:7896 [D loss: 0.541858, acc.: 78.12%] [G loss: 0.830977]\n",
      "epoch:8 step:7897 [D loss: 0.600180, acc.: 71.09%] [G loss: 0.801629]\n",
      "epoch:8 step:7898 [D loss: 0.473843, acc.: 76.56%] [G loss: 0.883088]\n",
      "epoch:8 step:7899 [D loss: 0.601965, acc.: 70.31%] [G loss: 0.880595]\n",
      "epoch:8 step:7900 [D loss: 0.460308, acc.: 79.69%] [G loss: 0.955375]\n",
      "epoch:8 step:7901 [D loss: 0.411025, acc.: 93.75%] [G loss: 0.795707]\n",
      "epoch:8 step:7902 [D loss: 0.405190, acc.: 85.94%] [G loss: 0.479355]\n",
      "epoch:8 step:7903 [D loss: 0.703773, acc.: 57.03%] [G loss: 0.774329]\n",
      "epoch:8 step:7904 [D loss: 0.517312, acc.: 77.34%] [G loss: 0.425851]\n",
      "epoch:8 step:7905 [D loss: 0.456269, acc.: 83.59%] [G loss: 1.140572]\n",
      "epoch:8 step:7906 [D loss: 0.685951, acc.: 60.16%] [G loss: 0.830784]\n",
      "epoch:8 step:7907 [D loss: 1.008997, acc.: 10.94%] [G loss: 0.866406]\n",
      "epoch:8 step:7908 [D loss: 0.761895, acc.: 46.88%] [G loss: 0.923625]\n",
      "epoch:8 step:7909 [D loss: 0.699900, acc.: 54.69%] [G loss: 0.729854]\n",
      "epoch:8 step:7910 [D loss: 0.829779, acc.: 35.94%] [G loss: 0.774037]\n",
      "epoch:8 step:7911 [D loss: 0.794278, acc.: 31.25%] [G loss: 0.886112]\n",
      "epoch:8 step:7912 [D loss: 0.738619, acc.: 38.28%] [G loss: 0.843420]\n",
      "epoch:8 step:7913 [D loss: 0.650005, acc.: 62.50%] [G loss: 0.855707]\n",
      "epoch:8 step:7914 [D loss: 0.684106, acc.: 53.12%] [G loss: 0.769183]\n",
      "epoch:8 step:7915 [D loss: 0.659797, acc.: 58.59%] [G loss: 0.866146]\n",
      "epoch:8 step:7916 [D loss: 0.701664, acc.: 50.78%] [G loss: 0.854852]\n",
      "epoch:8 step:7917 [D loss: 0.797174, acc.: 33.59%] [G loss: 0.859985]\n",
      "epoch:8 step:7918 [D loss: 0.730765, acc.: 42.97%] [G loss: 0.848139]\n",
      "epoch:8 step:7919 [D loss: 0.745386, acc.: 42.97%] [G loss: 0.916944]\n",
      "epoch:8 step:7920 [D loss: 0.657220, acc.: 60.16%] [G loss: 0.921611]\n",
      "epoch:8 step:7921 [D loss: 0.672148, acc.: 57.03%] [G loss: 0.838638]\n",
      "epoch:8 step:7922 [D loss: 0.724761, acc.: 42.19%] [G loss: 0.874105]\n",
      "epoch:8 step:7923 [D loss: 0.674645, acc.: 58.59%] [G loss: 0.852308]\n",
      "epoch:8 step:7924 [D loss: 0.644481, acc.: 64.06%] [G loss: 0.837638]\n",
      "epoch:8 step:7925 [D loss: 0.667738, acc.: 62.50%] [G loss: 0.758033]\n",
      "epoch:8 step:7926 [D loss: 0.723386, acc.: 49.22%] [G loss: 0.803740]\n",
      "epoch:8 step:7927 [D loss: 0.713820, acc.: 54.69%] [G loss: 0.808238]\n",
      "epoch:8 step:7928 [D loss: 0.732776, acc.: 38.28%] [G loss: 0.836949]\n",
      "epoch:8 step:7929 [D loss: 0.653106, acc.: 55.47%] [G loss: 0.907201]\n",
      "epoch:8 step:7930 [D loss: 0.663371, acc.: 58.59%] [G loss: 0.838653]\n",
      "epoch:8 step:7931 [D loss: 0.622528, acc.: 58.59%] [G loss: 0.825785]\n",
      "epoch:8 step:7932 [D loss: 0.679404, acc.: 54.69%] [G loss: 0.910999]\n",
      "epoch:8 step:7933 [D loss: 0.745233, acc.: 37.50%] [G loss: 0.796415]\n",
      "epoch:8 step:7934 [D loss: 0.724189, acc.: 46.09%] [G loss: 0.803615]\n",
      "epoch:8 step:7935 [D loss: 0.726554, acc.: 42.19%] [G loss: 0.863964]\n",
      "epoch:8 step:7936 [D loss: 0.706297, acc.: 48.44%] [G loss: 0.793681]\n",
      "epoch:8 step:7937 [D loss: 0.710722, acc.: 50.78%] [G loss: 0.774332]\n",
      "epoch:8 step:7938 [D loss: 0.686251, acc.: 56.25%] [G loss: 0.878135]\n",
      "epoch:8 step:7939 [D loss: 0.647613, acc.: 64.84%] [G loss: 0.798454]\n",
      "epoch:8 step:7940 [D loss: 0.657679, acc.: 57.03%] [G loss: 0.955350]\n",
      "epoch:8 step:7941 [D loss: 0.641633, acc.: 60.16%] [G loss: 0.880922]\n",
      "epoch:8 step:7942 [D loss: 0.646409, acc.: 56.25%] [G loss: 0.827851]\n",
      "epoch:8 step:7943 [D loss: 0.649618, acc.: 58.59%] [G loss: 0.856628]\n",
      "epoch:8 step:7944 [D loss: 0.647556, acc.: 63.28%] [G loss: 0.886168]\n",
      "epoch:8 step:7945 [D loss: 0.638329, acc.: 65.62%] [G loss: 0.900567]\n",
      "epoch:8 step:7946 [D loss: 0.625412, acc.: 69.53%] [G loss: 1.019524]\n",
      "epoch:8 step:7947 [D loss: 0.534334, acc.: 84.38%] [G loss: 0.848805]\n",
      "epoch:8 step:7948 [D loss: 0.530398, acc.: 82.03%] [G loss: 0.902490]\n",
      "epoch:8 step:7949 [D loss: 0.620667, acc.: 71.88%] [G loss: 1.194661]\n",
      "epoch:8 step:7950 [D loss: 0.626929, acc.: 67.19%] [G loss: 1.024395]\n",
      "epoch:8 step:7951 [D loss: 0.729862, acc.: 50.00%] [G loss: 0.803553]\n",
      "epoch:8 step:7952 [D loss: 0.479068, acc.: 84.38%] [G loss: 1.021672]\n",
      "epoch:8 step:7953 [D loss: 0.696633, acc.: 71.88%] [G loss: 1.260930]\n",
      "epoch:8 step:7954 [D loss: 0.715722, acc.: 51.56%] [G loss: 1.072402]\n",
      "epoch:8 step:7955 [D loss: 1.172729, acc.: 28.91%] [G loss: 1.343101]\n",
      "epoch:8 step:7956 [D loss: 0.696097, acc.: 59.38%] [G loss: 1.057673]\n",
      "epoch:8 step:7957 [D loss: 0.779389, acc.: 40.62%] [G loss: 0.880799]\n",
      "epoch:8 step:7958 [D loss: 0.795936, acc.: 39.84%] [G loss: 0.898025]\n",
      "epoch:8 step:7959 [D loss: 0.711617, acc.: 50.78%] [G loss: 0.844900]\n",
      "epoch:8 step:7960 [D loss: 0.702798, acc.: 49.22%] [G loss: 0.727982]\n",
      "epoch:8 step:7961 [D loss: 0.691473, acc.: 52.34%] [G loss: 0.804022]\n",
      "epoch:8 step:7962 [D loss: 0.679389, acc.: 56.25%] [G loss: 0.757613]\n",
      "epoch:8 step:7963 [D loss: 0.690634, acc.: 50.78%] [G loss: 0.713830]\n",
      "epoch:8 step:7964 [D loss: 0.625009, acc.: 71.09%] [G loss: 0.687238]\n",
      "epoch:8 step:7965 [D loss: 0.712788, acc.: 49.22%] [G loss: 0.722231]\n",
      "epoch:8 step:7966 [D loss: 0.628728, acc.: 67.97%] [G loss: 0.774641]\n",
      "epoch:8 step:7967 [D loss: 0.666404, acc.: 66.41%] [G loss: 0.780637]\n",
      "epoch:8 step:7968 [D loss: 0.686562, acc.: 49.22%] [G loss: 0.750949]\n",
      "epoch:8 step:7969 [D loss: 0.706829, acc.: 50.78%] [G loss: 0.809656]\n",
      "epoch:8 step:7970 [D loss: 0.677468, acc.: 52.34%] [G loss: 0.853433]\n",
      "epoch:8 step:7971 [D loss: 0.670053, acc.: 60.16%] [G loss: 0.848006]\n",
      "epoch:8 step:7972 [D loss: 0.697830, acc.: 57.03%] [G loss: 0.842325]\n",
      "epoch:8 step:7973 [D loss: 0.662559, acc.: 65.62%] [G loss: 0.741255]\n",
      "epoch:8 step:7974 [D loss: 0.678125, acc.: 57.03%] [G loss: 0.797148]\n",
      "epoch:8 step:7975 [D loss: 0.699156, acc.: 50.00%] [G loss: 0.821485]\n",
      "epoch:8 step:7976 [D loss: 0.674778, acc.: 56.25%] [G loss: 0.781094]\n",
      "epoch:8 step:7977 [D loss: 0.652684, acc.: 60.94%] [G loss: 0.772162]\n",
      "epoch:8 step:7978 [D loss: 0.687531, acc.: 54.69%] [G loss: 0.776502]\n",
      "epoch:8 step:7979 [D loss: 0.660706, acc.: 60.94%] [G loss: 0.793293]\n",
      "epoch:8 step:7980 [D loss: 0.682599, acc.: 51.56%] [G loss: 0.718010]\n",
      "epoch:8 step:7981 [D loss: 0.679591, acc.: 52.34%] [G loss: 0.737030]\n",
      "epoch:8 step:7982 [D loss: 0.674555, acc.: 58.59%] [G loss: 0.778467]\n",
      "epoch:8 step:7983 [D loss: 0.675878, acc.: 54.69%] [G loss: 0.746095]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7984 [D loss: 0.679693, acc.: 50.00%] [G loss: 0.751303]\n",
      "epoch:8 step:7985 [D loss: 0.689880, acc.: 57.81%] [G loss: 0.726072]\n",
      "epoch:8 step:7986 [D loss: 0.713447, acc.: 43.75%] [G loss: 0.762815]\n",
      "epoch:8 step:7987 [D loss: 0.659325, acc.: 56.25%] [G loss: 0.749225]\n",
      "epoch:8 step:7988 [D loss: 0.678923, acc.: 55.47%] [G loss: 0.743182]\n",
      "epoch:8 step:7989 [D loss: 0.697109, acc.: 58.59%] [G loss: 0.732384]\n",
      "epoch:8 step:7990 [D loss: 0.696108, acc.: 50.78%] [G loss: 0.723082]\n",
      "epoch:8 step:7991 [D loss: 0.656343, acc.: 63.28%] [G loss: 0.740637]\n",
      "epoch:8 step:7992 [D loss: 0.667097, acc.: 57.03%] [G loss: 0.732413]\n",
      "epoch:8 step:7993 [D loss: 0.588792, acc.: 72.66%] [G loss: 0.840592]\n",
      "epoch:8 step:7994 [D loss: 0.577569, acc.: 69.53%] [G loss: 0.882837]\n",
      "epoch:8 step:7995 [D loss: 0.566389, acc.: 73.44%] [G loss: 0.897174]\n",
      "epoch:8 step:7996 [D loss: 0.661641, acc.: 59.38%] [G loss: 0.822086]\n",
      "epoch:8 step:7997 [D loss: 0.725224, acc.: 44.53%] [G loss: 0.776795]\n",
      "epoch:8 step:7998 [D loss: 0.654261, acc.: 60.16%] [G loss: 0.736712]\n",
      "epoch:8 step:7999 [D loss: 0.750022, acc.: 41.41%] [G loss: 0.854376]\n",
      "epoch:8 step:8000 [D loss: 0.657641, acc.: 58.59%] [G loss: 0.828714]\n",
      "##############\n",
      "[4.31653002 2.74879708 6.09715832 5.79517772 4.02059888 6.13549069\n",
      " 5.13765863 5.0358437  5.4384698  4.81477867]\n",
      "##########\n",
      "epoch:8 step:8001 [D loss: 0.684965, acc.: 50.00%] [G loss: 0.878628]\n",
      "epoch:8 step:8002 [D loss: 0.682935, acc.: 56.25%] [G loss: 0.876771]\n",
      "epoch:8 step:8003 [D loss: 0.630430, acc.: 68.75%] [G loss: 0.832176]\n",
      "epoch:8 step:8004 [D loss: 0.676115, acc.: 64.06%] [G loss: 0.921589]\n",
      "epoch:8 step:8005 [D loss: 0.682130, acc.: 61.72%] [G loss: 0.894588]\n",
      "epoch:8 step:8006 [D loss: 0.667915, acc.: 61.72%] [G loss: 0.894434]\n",
      "epoch:8 step:8007 [D loss: 0.641873, acc.: 64.84%] [G loss: 0.899353]\n",
      "epoch:8 step:8008 [D loss: 0.651833, acc.: 70.31%] [G loss: 0.727634]\n",
      "epoch:8 step:8009 [D loss: 0.566074, acc.: 73.44%] [G loss: 0.855863]\n",
      "epoch:8 step:8010 [D loss: 0.559732, acc.: 71.88%] [G loss: 0.875199]\n",
      "epoch:8 step:8011 [D loss: 0.586272, acc.: 75.78%] [G loss: 0.770491]\n",
      "epoch:8 step:8012 [D loss: 0.649441, acc.: 64.84%] [G loss: 0.764992]\n",
      "epoch:8 step:8013 [D loss: 0.721469, acc.: 46.09%] [G loss: 0.741003]\n",
      "epoch:8 step:8014 [D loss: 0.740413, acc.: 44.53%] [G loss: 0.621465]\n",
      "epoch:8 step:8015 [D loss: 0.664062, acc.: 56.25%] [G loss: 0.796923]\n",
      "epoch:8 step:8016 [D loss: 0.712085, acc.: 48.44%] [G loss: 0.798105]\n",
      "epoch:8 step:8017 [D loss: 0.674066, acc.: 54.69%] [G loss: 0.880857]\n",
      "epoch:8 step:8018 [D loss: 0.617443, acc.: 67.97%] [G loss: 0.951331]\n",
      "epoch:8 step:8019 [D loss: 0.666816, acc.: 58.59%] [G loss: 1.024079]\n",
      "epoch:8 step:8020 [D loss: 0.599072, acc.: 73.44%] [G loss: 0.886779]\n",
      "epoch:8 step:8021 [D loss: 0.752148, acc.: 38.28%] [G loss: 0.762755]\n",
      "epoch:8 step:8022 [D loss: 0.776498, acc.: 39.06%] [G loss: 0.900638]\n",
      "epoch:8 step:8023 [D loss: 0.734950, acc.: 43.75%] [G loss: 0.846029]\n",
      "epoch:8 step:8024 [D loss: 0.724834, acc.: 41.41%] [G loss: 0.867458]\n",
      "epoch:8 step:8025 [D loss: 0.723161, acc.: 49.22%] [G loss: 0.898221]\n",
      "epoch:8 step:8026 [D loss: 0.715459, acc.: 45.31%] [G loss: 0.861831]\n",
      "epoch:8 step:8027 [D loss: 0.627877, acc.: 64.06%] [G loss: 0.854141]\n",
      "epoch:8 step:8028 [D loss: 0.606603, acc.: 69.53%] [G loss: 0.938854]\n",
      "epoch:8 step:8029 [D loss: 0.534395, acc.: 75.00%] [G loss: 1.106673]\n",
      "epoch:8 step:8030 [D loss: 0.550358, acc.: 75.00%] [G loss: 1.106225]\n",
      "epoch:8 step:8031 [D loss: 0.764031, acc.: 49.22%] [G loss: 1.031355]\n",
      "epoch:8 step:8032 [D loss: 0.782098, acc.: 41.41%] [G loss: 0.776019]\n",
      "epoch:8 step:8033 [D loss: 0.723606, acc.: 51.56%] [G loss: 0.755787]\n",
      "epoch:8 step:8034 [D loss: 0.697404, acc.: 53.12%] [G loss: 0.758121]\n",
      "epoch:8 step:8035 [D loss: 0.675316, acc.: 57.03%] [G loss: 0.739021]\n",
      "epoch:8 step:8036 [D loss: 0.693078, acc.: 52.34%] [G loss: 0.788949]\n",
      "epoch:8 step:8037 [D loss: 0.652342, acc.: 58.59%] [G loss: 0.767213]\n",
      "epoch:8 step:8038 [D loss: 0.592188, acc.: 74.22%] [G loss: 0.856125]\n",
      "epoch:8 step:8039 [D loss: 0.560708, acc.: 60.94%] [G loss: 0.862249]\n",
      "epoch:8 step:8040 [D loss: 0.635203, acc.: 65.62%] [G loss: 0.842301]\n",
      "epoch:8 step:8041 [D loss: 0.641895, acc.: 63.28%] [G loss: 0.788572]\n",
      "epoch:8 step:8042 [D loss: 0.680177, acc.: 60.16%] [G loss: 0.883096]\n",
      "epoch:8 step:8043 [D loss: 0.710517, acc.: 50.00%] [G loss: 0.821665]\n",
      "epoch:8 step:8044 [D loss: 0.656685, acc.: 64.06%] [G loss: 0.720113]\n",
      "epoch:8 step:8045 [D loss: 0.658624, acc.: 63.28%] [G loss: 0.856934]\n",
      "epoch:8 step:8046 [D loss: 0.409194, acc.: 82.03%] [G loss: 0.883583]\n",
      "epoch:8 step:8047 [D loss: 0.646814, acc.: 64.84%] [G loss: 0.853014]\n",
      "epoch:8 step:8048 [D loss: 0.587429, acc.: 74.22%] [G loss: 0.848794]\n",
      "epoch:8 step:8049 [D loss: 0.640682, acc.: 67.19%] [G loss: 0.894992]\n",
      "epoch:8 step:8050 [D loss: 0.525308, acc.: 86.72%] [G loss: 0.908047]\n",
      "epoch:8 step:8051 [D loss: 0.618823, acc.: 64.84%] [G loss: 0.907818]\n",
      "epoch:8 step:8052 [D loss: 0.571443, acc.: 82.03%] [G loss: 0.543402]\n",
      "epoch:8 step:8053 [D loss: 0.651978, acc.: 67.97%] [G loss: 0.692604]\n",
      "epoch:8 step:8054 [D loss: 0.866555, acc.: 42.97%] [G loss: 0.735686]\n",
      "epoch:8 step:8055 [D loss: 0.848249, acc.: 41.41%] [G loss: 0.873470]\n",
      "epoch:8 step:8056 [D loss: 0.866585, acc.: 24.22%] [G loss: 0.879796]\n",
      "epoch:8 step:8057 [D loss: 0.641354, acc.: 64.84%] [G loss: 0.965748]\n",
      "epoch:8 step:8058 [D loss: 0.661152, acc.: 56.25%] [G loss: 0.785394]\n",
      "epoch:8 step:8059 [D loss: 0.770130, acc.: 47.66%] [G loss: 0.720537]\n",
      "epoch:8 step:8060 [D loss: 0.629582, acc.: 60.16%] [G loss: 0.815474]\n",
      "epoch:8 step:8061 [D loss: 0.751295, acc.: 44.53%] [G loss: 0.760194]\n",
      "epoch:8 step:8062 [D loss: 0.670369, acc.: 57.03%] [G loss: 0.892636]\n",
      "epoch:8 step:8063 [D loss: 0.606886, acc.: 65.62%] [G loss: 0.845789]\n",
      "epoch:8 step:8064 [D loss: 0.658355, acc.: 61.72%] [G loss: 0.769340]\n",
      "epoch:8 step:8065 [D loss: 0.771618, acc.: 45.31%] [G loss: 0.926055]\n",
      "epoch:8 step:8066 [D loss: 0.667836, acc.: 57.81%] [G loss: 1.097314]\n",
      "epoch:8 step:8067 [D loss: 0.654486, acc.: 66.41%] [G loss: 1.046149]\n",
      "epoch:8 step:8068 [D loss: 0.608927, acc.: 71.09%] [G loss: 1.024049]\n",
      "epoch:8 step:8069 [D loss: 0.578042, acc.: 74.22%] [G loss: 1.685918]\n",
      "epoch:8 step:8070 [D loss: 0.517913, acc.: 79.69%] [G loss: 0.986739]\n",
      "epoch:8 step:8071 [D loss: 0.712234, acc.: 58.59%] [G loss: 0.946300]\n",
      "epoch:8 step:8072 [D loss: 0.661205, acc.: 58.59%] [G loss: 0.889755]\n",
      "epoch:8 step:8073 [D loss: 0.524999, acc.: 80.47%] [G loss: 0.879210]\n",
      "epoch:8 step:8074 [D loss: 0.675315, acc.: 52.34%] [G loss: 0.878771]\n",
      "epoch:8 step:8075 [D loss: 0.684569, acc.: 54.69%] [G loss: 0.773332]\n",
      "epoch:8 step:8076 [D loss: 0.704271, acc.: 51.56%] [G loss: 1.128840]\n",
      "epoch:8 step:8077 [D loss: 0.691577, acc.: 54.69%] [G loss: 0.816735]\n",
      "epoch:8 step:8078 [D loss: 0.703141, acc.: 51.56%] [G loss: 1.075583]\n",
      "epoch:8 step:8079 [D loss: 0.698491, acc.: 55.47%] [G loss: 0.691984]\n",
      "epoch:8 step:8080 [D loss: 0.746189, acc.: 34.38%] [G loss: 0.807066]\n",
      "epoch:8 step:8081 [D loss: 0.737122, acc.: 50.00%] [G loss: 0.635034]\n",
      "epoch:8 step:8082 [D loss: 0.701586, acc.: 44.53%] [G loss: 0.636045]\n",
      "epoch:8 step:8083 [D loss: 0.588996, acc.: 73.44%] [G loss: 0.866736]\n",
      "epoch:8 step:8084 [D loss: 0.579827, acc.: 70.31%] [G loss: 0.893621]\n",
      "epoch:8 step:8085 [D loss: 0.471104, acc.: 89.84%] [G loss: 0.947585]\n",
      "epoch:8 step:8086 [D loss: 0.672774, acc.: 57.81%] [G loss: 0.957511]\n",
      "epoch:8 step:8087 [D loss: 0.628694, acc.: 61.72%] [G loss: 0.845762]\n",
      "epoch:8 step:8088 [D loss: 0.683201, acc.: 46.88%] [G loss: 0.924576]\n",
      "epoch:8 step:8089 [D loss: 0.685988, acc.: 48.44%] [G loss: 0.937479]\n",
      "epoch:8 step:8090 [D loss: 0.685278, acc.: 54.69%] [G loss: 0.990279]\n",
      "epoch:8 step:8091 [D loss: 0.603284, acc.: 74.22%] [G loss: 0.897649]\n",
      "epoch:8 step:8092 [D loss: 0.616247, acc.: 68.75%] [G loss: 0.809487]\n",
      "epoch:8 step:8093 [D loss: 0.736962, acc.: 50.00%] [G loss: 0.777523]\n",
      "epoch:8 step:8094 [D loss: 0.661935, acc.: 60.94%] [G loss: 0.730311]\n",
      "epoch:8 step:8095 [D loss: 0.693538, acc.: 50.78%] [G loss: 0.798167]\n",
      "epoch:8 step:8096 [D loss: 0.569361, acc.: 72.66%] [G loss: 0.788953]\n",
      "epoch:8 step:8097 [D loss: 0.668276, acc.: 60.94%] [G loss: 0.811883]\n",
      "epoch:8 step:8098 [D loss: 0.593434, acc.: 67.97%] [G loss: 0.569527]\n",
      "epoch:8 step:8099 [D loss: 0.708347, acc.: 49.22%] [G loss: 0.768046]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8100 [D loss: 0.495628, acc.: 67.97%] [G loss: 0.891916]\n",
      "epoch:8 step:8101 [D loss: 0.694588, acc.: 49.22%] [G loss: 0.773068]\n",
      "epoch:8 step:8102 [D loss: 0.660687, acc.: 67.19%] [G loss: 0.902874]\n",
      "epoch:8 step:8103 [D loss: 0.679985, acc.: 52.34%] [G loss: 0.922197]\n",
      "epoch:8 step:8104 [D loss: 0.727742, acc.: 57.81%] [G loss: 0.763613]\n",
      "epoch:8 step:8105 [D loss: 0.583558, acc.: 67.97%] [G loss: 0.746433]\n",
      "epoch:8 step:8106 [D loss: 0.661912, acc.: 61.72%] [G loss: 0.887727]\n",
      "epoch:8 step:8107 [D loss: 0.723981, acc.: 54.69%] [G loss: 0.897496]\n",
      "epoch:8 step:8108 [D loss: 0.667750, acc.: 57.81%] [G loss: 0.698447]\n",
      "epoch:8 step:8109 [D loss: 0.698449, acc.: 54.69%] [G loss: 0.879295]\n",
      "epoch:8 step:8110 [D loss: 0.714660, acc.: 49.22%] [G loss: 0.870962]\n",
      "epoch:8 step:8111 [D loss: 0.680677, acc.: 57.03%] [G loss: 0.984438]\n",
      "epoch:8 step:8112 [D loss: 0.605442, acc.: 67.97%] [G loss: 1.098404]\n",
      "epoch:8 step:8113 [D loss: 0.570408, acc.: 72.66%] [G loss: 1.164353]\n",
      "epoch:8 step:8114 [D loss: 0.614483, acc.: 70.31%] [G loss: 1.017376]\n",
      "epoch:8 step:8115 [D loss: 0.687934, acc.: 59.38%] [G loss: 0.948428]\n",
      "epoch:8 step:8116 [D loss: 0.678981, acc.: 55.47%] [G loss: 0.806483]\n",
      "epoch:8 step:8117 [D loss: 0.667596, acc.: 59.38%] [G loss: 1.050586]\n",
      "epoch:8 step:8118 [D loss: 0.807172, acc.: 51.56%] [G loss: 0.841517]\n",
      "epoch:8 step:8119 [D loss: 0.652066, acc.: 64.06%] [G loss: 0.884929]\n",
      "epoch:8 step:8120 [D loss: 0.612841, acc.: 73.44%] [G loss: 1.142470]\n",
      "epoch:8 step:8121 [D loss: 0.783656, acc.: 43.75%] [G loss: 0.862274]\n",
      "epoch:8 step:8122 [D loss: 0.662975, acc.: 61.72%] [G loss: 0.778514]\n",
      "epoch:8 step:8123 [D loss: 0.688317, acc.: 54.69%] [G loss: 0.760432]\n",
      "epoch:8 step:8124 [D loss: 0.755704, acc.: 46.88%] [G loss: 0.713246]\n",
      "epoch:8 step:8125 [D loss: 0.652897, acc.: 60.16%] [G loss: 0.864908]\n",
      "epoch:8 step:8126 [D loss: 0.608318, acc.: 72.66%] [G loss: 0.776712]\n",
      "epoch:8 step:8127 [D loss: 0.669271, acc.: 58.59%] [G loss: 0.858829]\n",
      "epoch:8 step:8128 [D loss: 0.687177, acc.: 54.69%] [G loss: 1.010852]\n",
      "epoch:8 step:8129 [D loss: 0.662261, acc.: 57.81%] [G loss: 0.788690]\n",
      "epoch:8 step:8130 [D loss: 0.626190, acc.: 67.97%] [G loss: 0.928373]\n",
      "epoch:8 step:8131 [D loss: 0.687606, acc.: 53.91%] [G loss: 0.900996]\n",
      "epoch:8 step:8132 [D loss: 0.674795, acc.: 56.25%] [G loss: 0.901849]\n",
      "epoch:8 step:8133 [D loss: 0.699334, acc.: 44.53%] [G loss: 0.875289]\n",
      "epoch:8 step:8134 [D loss: 0.650163, acc.: 58.59%] [G loss: 0.798770]\n",
      "epoch:8 step:8135 [D loss: 1.250928, acc.: 32.81%] [G loss: 1.011872]\n",
      "epoch:8 step:8136 [D loss: 0.664713, acc.: 55.47%] [G loss: 1.038590]\n",
      "epoch:8 step:8137 [D loss: 0.660674, acc.: 63.28%] [G loss: 1.059252]\n",
      "epoch:8 step:8138 [D loss: 0.600093, acc.: 65.62%] [G loss: 1.037061]\n",
      "epoch:8 step:8139 [D loss: 0.690413, acc.: 57.03%] [G loss: 0.960938]\n",
      "epoch:8 step:8140 [D loss: 0.677303, acc.: 60.94%] [G loss: 0.938570]\n",
      "epoch:8 step:8141 [D loss: 0.665205, acc.: 57.03%] [G loss: 0.952659]\n",
      "epoch:8 step:8142 [D loss: 0.662907, acc.: 62.50%] [G loss: 0.801469]\n",
      "epoch:8 step:8143 [D loss: 0.673263, acc.: 58.59%] [G loss: 0.822469]\n",
      "epoch:8 step:8144 [D loss: 0.640671, acc.: 63.28%] [G loss: 0.858425]\n",
      "epoch:8 step:8145 [D loss: 0.648911, acc.: 59.38%] [G loss: 0.741742]\n",
      "epoch:8 step:8146 [D loss: 0.639695, acc.: 64.06%] [G loss: 0.877942]\n",
      "epoch:8 step:8147 [D loss: 0.629157, acc.: 59.38%] [G loss: 0.774065]\n",
      "epoch:8 step:8148 [D loss: 0.683073, acc.: 62.50%] [G loss: 0.778709]\n",
      "epoch:8 step:8149 [D loss: 0.677741, acc.: 63.28%] [G loss: 0.740301]\n",
      "epoch:8 step:8150 [D loss: 0.690618, acc.: 57.81%] [G loss: 0.771410]\n",
      "epoch:8 step:8151 [D loss: 0.692751, acc.: 55.47%] [G loss: 0.800009]\n",
      "epoch:8 step:8152 [D loss: 0.692560, acc.: 54.69%] [G loss: 0.742440]\n",
      "epoch:8 step:8153 [D loss: 0.725387, acc.: 43.75%] [G loss: 0.733084]\n",
      "epoch:8 step:8154 [D loss: 0.701478, acc.: 50.78%] [G loss: 0.766911]\n",
      "epoch:8 step:8155 [D loss: 0.683386, acc.: 54.69%] [G loss: 0.738507]\n",
      "epoch:8 step:8156 [D loss: 0.654851, acc.: 67.97%] [G loss: 0.710192]\n",
      "epoch:8 step:8157 [D loss: 0.651781, acc.: 61.72%] [G loss: 0.752227]\n",
      "epoch:8 step:8158 [D loss: 0.692126, acc.: 54.69%] [G loss: 0.774916]\n",
      "epoch:8 step:8159 [D loss: 0.706474, acc.: 50.78%] [G loss: 0.774400]\n",
      "epoch:8 step:8160 [D loss: 0.635360, acc.: 63.28%] [G loss: 0.766716]\n",
      "epoch:8 step:8161 [D loss: 0.608193, acc.: 71.09%] [G loss: 0.843474]\n",
      "epoch:8 step:8162 [D loss: 0.656482, acc.: 67.19%] [G loss: 0.807940]\n",
      "epoch:8 step:8163 [D loss: 0.659107, acc.: 68.75%] [G loss: 0.797948]\n",
      "epoch:8 step:8164 [D loss: 0.669786, acc.: 59.38%] [G loss: 0.774272]\n",
      "epoch:8 step:8165 [D loss: 0.677228, acc.: 56.25%] [G loss: 0.806496]\n",
      "epoch:8 step:8166 [D loss: 0.704380, acc.: 53.91%] [G loss: 0.822266]\n",
      "epoch:8 step:8167 [D loss: 0.701281, acc.: 50.78%] [G loss: 0.840056]\n",
      "epoch:8 step:8168 [D loss: 0.718382, acc.: 50.78%] [G loss: 0.661899]\n",
      "epoch:8 step:8169 [D loss: 0.677103, acc.: 60.94%] [G loss: 0.733011]\n",
      "epoch:8 step:8170 [D loss: 0.664206, acc.: 53.12%] [G loss: 0.740703]\n",
      "epoch:8 step:8171 [D loss: 0.671251, acc.: 60.16%] [G loss: 0.697605]\n",
      "epoch:8 step:8172 [D loss: 0.664904, acc.: 59.38%] [G loss: 0.692665]\n",
      "epoch:8 step:8173 [D loss: 0.664720, acc.: 59.38%] [G loss: 0.737718]\n",
      "epoch:8 step:8174 [D loss: 0.655957, acc.: 60.94%] [G loss: 0.746772]\n",
      "epoch:8 step:8175 [D loss: 0.701317, acc.: 53.91%] [G loss: 0.801832]\n",
      "epoch:8 step:8176 [D loss: 0.709538, acc.: 53.91%] [G loss: 0.769166]\n",
      "epoch:8 step:8177 [D loss: 0.689649, acc.: 59.38%] [G loss: 0.822988]\n",
      "epoch:8 step:8178 [D loss: 0.663677, acc.: 57.03%] [G loss: 0.797728]\n",
      "epoch:8 step:8179 [D loss: 0.662067, acc.: 58.59%] [G loss: 0.764289]\n",
      "epoch:8 step:8180 [D loss: 0.694027, acc.: 51.56%] [G loss: 0.837432]\n",
      "epoch:8 step:8181 [D loss: 0.660795, acc.: 64.84%] [G loss: 0.824509]\n",
      "epoch:8 step:8182 [D loss: 0.680009, acc.: 58.59%] [G loss: 0.823246]\n",
      "epoch:8 step:8183 [D loss: 0.661867, acc.: 57.03%] [G loss: 0.868326]\n",
      "epoch:8 step:8184 [D loss: 0.633792, acc.: 64.06%] [G loss: 0.848439]\n",
      "epoch:8 step:8185 [D loss: 0.630742, acc.: 69.53%] [G loss: 0.816231]\n",
      "epoch:8 step:8186 [D loss: 0.606195, acc.: 72.66%] [G loss: 0.832033]\n",
      "epoch:8 step:8187 [D loss: 0.675855, acc.: 57.03%] [G loss: 0.800182]\n",
      "epoch:8 step:8188 [D loss: 0.634474, acc.: 64.06%] [G loss: 0.765257]\n",
      "epoch:8 step:8189 [D loss: 0.623509, acc.: 65.62%] [G loss: 0.872388]\n",
      "epoch:8 step:8190 [D loss: 0.640004, acc.: 59.38%] [G loss: 0.820634]\n",
      "epoch:8 step:8191 [D loss: 0.704458, acc.: 52.34%] [G loss: 0.819079]\n",
      "epoch:8 step:8192 [D loss: 0.677050, acc.: 51.56%] [G loss: 0.732986]\n",
      "epoch:8 step:8193 [D loss: 0.649349, acc.: 57.81%] [G loss: 0.803348]\n",
      "epoch:8 step:8194 [D loss: 0.677500, acc.: 53.12%] [G loss: 0.852664]\n",
      "epoch:8 step:8195 [D loss: 0.698538, acc.: 49.22%] [G loss: 0.808348]\n",
      "epoch:8 step:8196 [D loss: 0.584201, acc.: 67.97%] [G loss: 0.754121]\n",
      "epoch:8 step:8197 [D loss: 0.558506, acc.: 74.22%] [G loss: 0.934239]\n",
      "epoch:8 step:8198 [D loss: 0.603357, acc.: 71.09%] [G loss: 0.957148]\n",
      "epoch:8 step:8199 [D loss: 0.627533, acc.: 61.72%] [G loss: 1.053101]\n",
      "epoch:8 step:8200 [D loss: 0.608464, acc.: 71.88%] [G loss: 0.973173]\n",
      "##############\n",
      "[4.66858729 2.58069936 6.71013234 5.13532307 3.8025464  6.04780433\n",
      " 5.61013948 5.5219212  5.38897568 4.84760117]\n",
      "##########\n",
      "epoch:8 step:8201 [D loss: 0.705678, acc.: 48.44%] [G loss: 0.883631]\n",
      "epoch:8 step:8202 [D loss: 0.500532, acc.: 77.34%] [G loss: 0.980451]\n",
      "epoch:8 step:8203 [D loss: 0.463441, acc.: 82.81%] [G loss: 0.891687]\n",
      "epoch:8 step:8204 [D loss: 0.450761, acc.: 84.38%] [G loss: 0.997017]\n",
      "epoch:8 step:8205 [D loss: 0.553253, acc.: 76.56%] [G loss: 0.922124]\n",
      "epoch:8 step:8206 [D loss: 0.824340, acc.: 44.53%] [G loss: 0.954642]\n",
      "epoch:8 step:8207 [D loss: 0.835284, acc.: 39.84%] [G loss: 0.786815]\n",
      "epoch:8 step:8208 [D loss: 0.640158, acc.: 71.09%] [G loss: 0.638456]\n",
      "epoch:8 step:8209 [D loss: 0.737085, acc.: 54.69%] [G loss: 0.915529]\n",
      "epoch:8 step:8210 [D loss: 0.490507, acc.: 70.31%] [G loss: 0.864664]\n",
      "epoch:8 step:8211 [D loss: 0.708981, acc.: 51.56%] [G loss: 0.809986]\n",
      "epoch:8 step:8212 [D loss: 0.748591, acc.: 41.41%] [G loss: 0.879012]\n",
      "epoch:8 step:8213 [D loss: 0.710712, acc.: 53.12%] [G loss: 0.851901]\n",
      "epoch:8 step:8214 [D loss: 0.692149, acc.: 51.56%] [G loss: 0.748553]\n",
      "epoch:8 step:8215 [D loss: 0.663655, acc.: 57.03%] [G loss: 0.740564]\n",
      "epoch:8 step:8216 [D loss: 0.653616, acc.: 62.50%] [G loss: 0.874398]\n",
      "epoch:8 step:8217 [D loss: 0.661048, acc.: 54.69%] [G loss: 0.650616]\n",
      "epoch:8 step:8218 [D loss: 0.706619, acc.: 50.78%] [G loss: 0.978520]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8219 [D loss: 0.701156, acc.: 50.00%] [G loss: 0.848211]\n",
      "epoch:8 step:8220 [D loss: 0.660143, acc.: 57.81%] [G loss: 0.881436]\n",
      "epoch:8 step:8221 [D loss: 0.662808, acc.: 56.25%] [G loss: 1.054931]\n",
      "epoch:8 step:8222 [D loss: 0.628996, acc.: 60.94%] [G loss: 1.117158]\n",
      "epoch:8 step:8223 [D loss: 0.717782, acc.: 53.91%] [G loss: 0.991985]\n",
      "epoch:8 step:8224 [D loss: 0.709685, acc.: 53.91%] [G loss: 0.825501]\n",
      "epoch:8 step:8225 [D loss: 0.713407, acc.: 50.78%] [G loss: 0.972086]\n",
      "epoch:8 step:8226 [D loss: 0.669473, acc.: 59.38%] [G loss: 0.789057]\n",
      "epoch:8 step:8227 [D loss: 0.685508, acc.: 54.69%] [G loss: 0.849703]\n",
      "epoch:8 step:8228 [D loss: 0.660383, acc.: 60.16%] [G loss: 0.744765]\n",
      "epoch:8 step:8229 [D loss: 0.747225, acc.: 43.75%] [G loss: 0.816553]\n",
      "epoch:8 step:8230 [D loss: 0.693247, acc.: 55.47%] [G loss: 0.799244]\n",
      "epoch:8 step:8231 [D loss: 0.725158, acc.: 40.62%] [G loss: 0.876653]\n",
      "epoch:8 step:8232 [D loss: 0.646198, acc.: 65.62%] [G loss: 0.880860]\n",
      "epoch:8 step:8233 [D loss: 0.681206, acc.: 49.22%] [G loss: 0.831221]\n",
      "epoch:8 step:8234 [D loss: 0.723217, acc.: 44.53%] [G loss: 0.769880]\n",
      "epoch:8 step:8235 [D loss: 0.707380, acc.: 49.22%] [G loss: 0.771866]\n",
      "epoch:8 step:8236 [D loss: 0.733745, acc.: 42.97%] [G loss: 0.742637]\n",
      "epoch:8 step:8237 [D loss: 0.621798, acc.: 72.66%] [G loss: 0.792074]\n",
      "epoch:8 step:8238 [D loss: 0.630234, acc.: 67.19%] [G loss: 0.857442]\n",
      "epoch:8 step:8239 [D loss: 0.577717, acc.: 76.56%] [G loss: 0.850304]\n",
      "epoch:8 step:8240 [D loss: 0.673081, acc.: 57.81%] [G loss: 0.865217]\n",
      "epoch:8 step:8241 [D loss: 0.747849, acc.: 48.44%] [G loss: 0.800309]\n",
      "epoch:8 step:8242 [D loss: 0.801106, acc.: 36.72%] [G loss: 0.753014]\n",
      "epoch:8 step:8243 [D loss: 0.685056, acc.: 57.03%] [G loss: 0.717344]\n",
      "epoch:8 step:8244 [D loss: 0.682229, acc.: 54.69%] [G loss: 0.727528]\n",
      "epoch:8 step:8245 [D loss: 0.627354, acc.: 71.09%] [G loss: 0.739056]\n",
      "epoch:8 step:8246 [D loss: 0.628383, acc.: 67.19%] [G loss: 0.707555]\n",
      "epoch:8 step:8247 [D loss: 0.721277, acc.: 56.25%] [G loss: 0.703439]\n",
      "epoch:8 step:8248 [D loss: 0.730105, acc.: 47.66%] [G loss: 0.677195]\n",
      "epoch:8 step:8249 [D loss: 0.673009, acc.: 55.47%] [G loss: 0.732923]\n",
      "epoch:8 step:8250 [D loss: 0.723552, acc.: 41.41%] [G loss: 0.805862]\n",
      "epoch:8 step:8251 [D loss: 0.682827, acc.: 54.69%] [G loss: 0.694671]\n",
      "epoch:8 step:8252 [D loss: 0.679038, acc.: 57.81%] [G loss: 0.778084]\n",
      "epoch:8 step:8253 [D loss: 0.661291, acc.: 65.62%] [G loss: 0.703353]\n",
      "epoch:8 step:8254 [D loss: 0.687885, acc.: 52.34%] [G loss: 0.738433]\n",
      "epoch:8 step:8255 [D loss: 0.681737, acc.: 55.47%] [G loss: 0.669546]\n",
      "epoch:8 step:8256 [D loss: 0.696157, acc.: 53.12%] [G loss: 0.729567]\n",
      "epoch:8 step:8257 [D loss: 0.694100, acc.: 55.47%] [G loss: 0.738477]\n",
      "epoch:8 step:8258 [D loss: 0.671563, acc.: 56.25%] [G loss: 0.779932]\n",
      "epoch:8 step:8259 [D loss: 0.690938, acc.: 54.69%] [G loss: 0.728370]\n",
      "epoch:8 step:8260 [D loss: 0.638655, acc.: 65.62%] [G loss: 0.743905]\n",
      "epoch:8 step:8261 [D loss: 0.680867, acc.: 55.47%] [G loss: 0.745594]\n",
      "epoch:8 step:8262 [D loss: 0.687707, acc.: 53.91%] [G loss: 0.760160]\n",
      "epoch:8 step:8263 [D loss: 0.685270, acc.: 56.25%] [G loss: 0.741505]\n",
      "epoch:8 step:8264 [D loss: 0.645086, acc.: 67.97%] [G loss: 0.778408]\n",
      "epoch:8 step:8265 [D loss: 0.647492, acc.: 60.16%] [G loss: 0.841683]\n",
      "epoch:8 step:8266 [D loss: 0.678432, acc.: 57.03%] [G loss: 0.848215]\n",
      "epoch:8 step:8267 [D loss: 0.680305, acc.: 54.69%] [G loss: 0.774169]\n",
      "epoch:8 step:8268 [D loss: 0.677864, acc.: 53.91%] [G loss: 0.781165]\n",
      "epoch:8 step:8269 [D loss: 0.664782, acc.: 53.12%] [G loss: 0.840454]\n",
      "epoch:8 step:8270 [D loss: 0.628435, acc.: 66.41%] [G loss: 0.854274]\n",
      "epoch:8 step:8271 [D loss: 0.631855, acc.: 64.06%] [G loss: 0.731346]\n",
      "epoch:8 step:8272 [D loss: 0.673880, acc.: 60.16%] [G loss: 0.843664]\n",
      "epoch:8 step:8273 [D loss: 0.694212, acc.: 54.69%] [G loss: 0.740888]\n",
      "epoch:8 step:8274 [D loss: 0.710441, acc.: 52.34%] [G loss: 0.772749]\n",
      "epoch:8 step:8275 [D loss: 0.686413, acc.: 61.72%] [G loss: 0.794261]\n",
      "epoch:8 step:8276 [D loss: 0.743548, acc.: 39.84%] [G loss: 0.707540]\n",
      "epoch:8 step:8277 [D loss: 0.716554, acc.: 45.31%] [G loss: 0.697863]\n",
      "epoch:8 step:8278 [D loss: 0.636745, acc.: 67.19%] [G loss: 0.765784]\n",
      "epoch:8 step:8279 [D loss: 0.695254, acc.: 61.72%] [G loss: 0.806737]\n",
      "epoch:8 step:8280 [D loss: 0.718402, acc.: 50.78%] [G loss: 0.691680]\n",
      "epoch:8 step:8281 [D loss: 0.698782, acc.: 53.12%] [G loss: 0.771130]\n",
      "epoch:8 step:8282 [D loss: 0.654407, acc.: 64.06%] [G loss: 0.759561]\n",
      "epoch:8 step:8283 [D loss: 0.718223, acc.: 43.75%] [G loss: 0.811596]\n",
      "epoch:8 step:8284 [D loss: 0.667431, acc.: 61.72%] [G loss: 0.805646]\n",
      "epoch:8 step:8285 [D loss: 0.675418, acc.: 60.16%] [G loss: 0.787651]\n",
      "epoch:8 step:8286 [D loss: 0.662117, acc.: 67.19%] [G loss: 0.790933]\n",
      "epoch:8 step:8287 [D loss: 0.614794, acc.: 74.22%] [G loss: 0.781761]\n",
      "epoch:8 step:8288 [D loss: 0.598674, acc.: 67.19%] [G loss: 0.791547]\n",
      "epoch:8 step:8289 [D loss: 0.609918, acc.: 71.88%] [G loss: 0.853648]\n",
      "epoch:8 step:8290 [D loss: 0.512504, acc.: 85.94%] [G loss: 0.934827]\n",
      "epoch:8 step:8291 [D loss: 0.643627, acc.: 69.53%] [G loss: 0.835917]\n",
      "epoch:8 step:8292 [D loss: 0.509520, acc.: 79.69%] [G loss: 0.878208]\n",
      "epoch:8 step:8293 [D loss: 0.704501, acc.: 48.44%] [G loss: 0.764601]\n",
      "epoch:8 step:8294 [D loss: 0.691573, acc.: 53.12%] [G loss: 0.700798]\n",
      "epoch:8 step:8295 [D loss: 0.669928, acc.: 57.81%] [G loss: 0.807180]\n",
      "epoch:8 step:8296 [D loss: 0.699561, acc.: 54.69%] [G loss: 0.840109]\n",
      "epoch:8 step:8297 [D loss: 0.708966, acc.: 51.56%] [G loss: 0.596964]\n",
      "epoch:8 step:8298 [D loss: 0.516068, acc.: 71.88%] [G loss: 0.586725]\n",
      "epoch:8 step:8299 [D loss: 0.724706, acc.: 52.34%] [G loss: 0.843246]\n",
      "epoch:8 step:8300 [D loss: 0.552313, acc.: 74.22%] [G loss: 0.827712]\n",
      "epoch:8 step:8301 [D loss: 0.547802, acc.: 78.12%] [G loss: 0.843543]\n",
      "epoch:8 step:8302 [D loss: 0.438755, acc.: 89.84%] [G loss: 0.961147]\n",
      "epoch:8 step:8303 [D loss: 0.727845, acc.: 49.22%] [G loss: 0.885173]\n",
      "epoch:8 step:8304 [D loss: 0.709199, acc.: 50.00%] [G loss: 0.649034]\n",
      "epoch:8 step:8305 [D loss: 0.683541, acc.: 46.09%] [G loss: 0.907988]\n",
      "epoch:8 step:8306 [D loss: 0.659605, acc.: 55.47%] [G loss: 0.749179]\n",
      "epoch:8 step:8307 [D loss: 0.667944, acc.: 59.38%] [G loss: 0.884906]\n",
      "epoch:8 step:8308 [D loss: 0.656199, acc.: 64.06%] [G loss: 0.908288]\n",
      "epoch:8 step:8309 [D loss: 0.887554, acc.: 41.41%] [G loss: 0.884063]\n",
      "epoch:8 step:8310 [D loss: 0.639195, acc.: 68.75%] [G loss: 0.623675]\n",
      "epoch:8 step:8311 [D loss: 0.795853, acc.: 41.41%] [G loss: 0.808187]\n",
      "epoch:8 step:8312 [D loss: 0.650024, acc.: 60.16%] [G loss: 0.774258]\n",
      "epoch:8 step:8313 [D loss: 0.584730, acc.: 71.88%] [G loss: 0.895203]\n",
      "epoch:8 step:8314 [D loss: 0.767355, acc.: 41.41%] [G loss: 0.903373]\n",
      "epoch:8 step:8315 [D loss: 0.715492, acc.: 51.56%] [G loss: 0.954929]\n",
      "epoch:8 step:8316 [D loss: 0.769565, acc.: 42.97%] [G loss: 0.882051]\n",
      "epoch:8 step:8317 [D loss: 0.764634, acc.: 43.75%] [G loss: 0.941790]\n",
      "epoch:8 step:8318 [D loss: 0.726409, acc.: 45.31%] [G loss: 0.785201]\n",
      "epoch:8 step:8319 [D loss: 0.673227, acc.: 56.25%] [G loss: 0.963955]\n",
      "epoch:8 step:8320 [D loss: 0.618659, acc.: 66.41%] [G loss: 0.930988]\n",
      "epoch:8 step:8321 [D loss: 0.613876, acc.: 69.53%] [G loss: 1.010580]\n",
      "epoch:8 step:8322 [D loss: 0.594146, acc.: 77.34%] [G loss: 0.837862]\n",
      "epoch:8 step:8323 [D loss: 0.675314, acc.: 48.44%] [G loss: 0.917116]\n",
      "epoch:8 step:8324 [D loss: 0.702015, acc.: 56.25%] [G loss: 0.940463]\n",
      "epoch:8 step:8325 [D loss: 0.631485, acc.: 65.62%] [G loss: 0.930818]\n",
      "epoch:8 step:8326 [D loss: 0.636044, acc.: 70.31%] [G loss: 0.732014]\n",
      "epoch:8 step:8327 [D loss: 0.540368, acc.: 76.56%] [G loss: 1.003858]\n",
      "epoch:8 step:8328 [D loss: 0.580422, acc.: 68.75%] [G loss: 0.953574]\n",
      "epoch:8 step:8329 [D loss: 0.628985, acc.: 64.06%] [G loss: 0.872980]\n",
      "epoch:8 step:8330 [D loss: 0.815203, acc.: 42.19%] [G loss: 0.853315]\n",
      "epoch:8 step:8331 [D loss: 0.670323, acc.: 53.12%] [G loss: 0.833559]\n",
      "epoch:8 step:8332 [D loss: 0.727948, acc.: 39.06%] [G loss: 0.731105]\n",
      "epoch:8 step:8333 [D loss: 0.582875, acc.: 75.78%] [G loss: 0.765416]\n",
      "epoch:8 step:8334 [D loss: 0.548175, acc.: 90.62%] [G loss: 0.978333]\n",
      "epoch:8 step:8335 [D loss: 0.816576, acc.: 30.47%] [G loss: 0.913771]\n",
      "epoch:8 step:8336 [D loss: 0.673807, acc.: 52.34%] [G loss: 0.763067]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8337 [D loss: 0.844025, acc.: 26.56%] [G loss: 0.681121]\n",
      "epoch:8 step:8338 [D loss: 0.529343, acc.: 89.84%] [G loss: 0.837595]\n",
      "epoch:8 step:8339 [D loss: 0.678728, acc.: 56.25%] [G loss: 0.933617]\n",
      "epoch:8 step:8340 [D loss: 0.685144, acc.: 56.25%] [G loss: 0.902661]\n",
      "epoch:8 step:8341 [D loss: 0.623803, acc.: 53.91%] [G loss: 0.746743]\n",
      "epoch:8 step:8342 [D loss: 0.723342, acc.: 51.56%] [G loss: 0.916561]\n",
      "epoch:8 step:8343 [D loss: 0.818250, acc.: 30.47%] [G loss: 0.770380]\n",
      "epoch:8 step:8344 [D loss: 0.828939, acc.: 26.56%] [G loss: 0.854123]\n",
      "epoch:8 step:8345 [D loss: 0.687069, acc.: 57.81%] [G loss: 0.755332]\n",
      "epoch:8 step:8346 [D loss: 0.780586, acc.: 35.16%] [G loss: 0.703904]\n",
      "epoch:8 step:8347 [D loss: 0.713080, acc.: 50.78%] [G loss: 0.781030]\n",
      "epoch:8 step:8348 [D loss: 0.735873, acc.: 40.62%] [G loss: 0.716238]\n",
      "epoch:8 step:8349 [D loss: 0.713342, acc.: 45.31%] [G loss: 0.715144]\n",
      "epoch:8 step:8350 [D loss: 0.682848, acc.: 54.69%] [G loss: 0.734236]\n",
      "epoch:8 step:8351 [D loss: 0.699980, acc.: 48.44%] [G loss: 0.758859]\n",
      "epoch:8 step:8352 [D loss: 0.686814, acc.: 57.03%] [G loss: 0.766198]\n",
      "epoch:8 step:8353 [D loss: 0.657919, acc.: 56.25%] [G loss: 0.800266]\n",
      "epoch:8 step:8354 [D loss: 0.718271, acc.: 51.56%] [G loss: 0.750160]\n",
      "epoch:8 step:8355 [D loss: 0.712609, acc.: 55.47%] [G loss: 0.755718]\n",
      "epoch:8 step:8356 [D loss: 0.666671, acc.: 68.75%] [G loss: 0.740107]\n",
      "epoch:8 step:8357 [D loss: 0.664849, acc.: 64.06%] [G loss: 0.790596]\n",
      "epoch:8 step:8358 [D loss: 0.663745, acc.: 60.94%] [G loss: 0.846883]\n",
      "epoch:8 step:8359 [D loss: 0.648914, acc.: 67.19%] [G loss: 0.837682]\n",
      "epoch:8 step:8360 [D loss: 0.666677, acc.: 62.50%] [G loss: 0.823711]\n",
      "epoch:8 step:8361 [D loss: 0.644871, acc.: 64.84%] [G loss: 0.805890]\n",
      "epoch:8 step:8362 [D loss: 0.654844, acc.: 67.19%] [G loss: 0.781346]\n",
      "epoch:8 step:8363 [D loss: 0.646493, acc.: 63.28%] [G loss: 0.802386]\n",
      "epoch:8 step:8364 [D loss: 0.665997, acc.: 61.72%] [G loss: 0.777541]\n",
      "epoch:8 step:8365 [D loss: 0.665170, acc.: 59.38%] [G loss: 0.798987]\n",
      "epoch:8 step:8366 [D loss: 0.670743, acc.: 57.03%] [G loss: 0.699420]\n",
      "epoch:8 step:8367 [D loss: 0.625944, acc.: 61.72%] [G loss: 0.793304]\n",
      "epoch:8 step:8368 [D loss: 0.616009, acc.: 67.97%] [G loss: 0.776662]\n",
      "epoch:8 step:8369 [D loss: 0.650812, acc.: 58.59%] [G loss: 0.841217]\n",
      "epoch:8 step:8370 [D loss: 0.688858, acc.: 53.12%] [G loss: 0.795882]\n",
      "epoch:8 step:8371 [D loss: 0.670757, acc.: 55.47%] [G loss: 0.816500]\n",
      "epoch:8 step:8372 [D loss: 0.736088, acc.: 49.22%] [G loss: 0.721767]\n",
      "epoch:8 step:8373 [D loss: 0.700499, acc.: 50.00%] [G loss: 0.797642]\n",
      "epoch:8 step:8374 [D loss: 0.698717, acc.: 50.00%] [G loss: 0.699038]\n",
      "epoch:8 step:8375 [D loss: 0.635884, acc.: 63.28%] [G loss: 0.709768]\n",
      "epoch:8 step:8376 [D loss: 0.703784, acc.: 46.09%] [G loss: 0.730204]\n",
      "epoch:8 step:8377 [D loss: 0.692298, acc.: 51.56%] [G loss: 0.767529]\n",
      "epoch:8 step:8378 [D loss: 0.593753, acc.: 78.12%] [G loss: 0.813440]\n",
      "epoch:8 step:8379 [D loss: 0.548600, acc.: 76.56%] [G loss: 0.829725]\n",
      "epoch:8 step:8380 [D loss: 0.560875, acc.: 79.69%] [G loss: 0.618586]\n",
      "epoch:8 step:8381 [D loss: 0.525934, acc.: 71.09%] [G loss: 0.871650]\n",
      "epoch:8 step:8382 [D loss: 0.497835, acc.: 75.78%] [G loss: 0.844055]\n",
      "epoch:8 step:8383 [D loss: 0.490312, acc.: 88.28%] [G loss: 0.795361]\n",
      "epoch:8 step:8384 [D loss: 0.845929, acc.: 33.59%] [G loss: 0.853855]\n",
      "epoch:8 step:8385 [D loss: 0.722902, acc.: 59.38%] [G loss: 0.659684]\n",
      "epoch:8 step:8386 [D loss: 0.510838, acc.: 80.47%] [G loss: 0.806871]\n",
      "epoch:8 step:8387 [D loss: 0.773174, acc.: 38.28%] [G loss: 0.707470]\n",
      "epoch:8 step:8388 [D loss: 0.760007, acc.: 44.53%] [G loss: 0.858311]\n",
      "epoch:8 step:8389 [D loss: 0.739180, acc.: 53.12%] [G loss: 0.776829]\n",
      "epoch:8 step:8390 [D loss: 0.693232, acc.: 52.34%] [G loss: 0.587095]\n",
      "epoch:8 step:8391 [D loss: 0.797563, acc.: 32.81%] [G loss: 0.830143]\n",
      "epoch:8 step:8392 [D loss: 0.807378, acc.: 36.72%] [G loss: 0.856122]\n",
      "epoch:8 step:8393 [D loss: 0.708452, acc.: 51.56%] [G loss: 0.823029]\n",
      "epoch:8 step:8394 [D loss: 0.657430, acc.: 61.72%] [G loss: 0.889743]\n",
      "epoch:8 step:8395 [D loss: 0.582730, acc.: 71.09%] [G loss: 0.912213]\n",
      "epoch:8 step:8396 [D loss: 0.575076, acc.: 67.97%] [G loss: 0.943890]\n",
      "epoch:8 step:8397 [D loss: 0.614941, acc.: 67.19%] [G loss: 1.016299]\n",
      "epoch:8 step:8398 [D loss: 0.625746, acc.: 61.72%] [G loss: 1.083297]\n",
      "epoch:8 step:8399 [D loss: 0.638512, acc.: 61.72%] [G loss: 0.532219]\n",
      "epoch:8 step:8400 [D loss: 0.836052, acc.: 39.06%] [G loss: 0.893586]\n",
      "##############\n",
      "[4.55050043 3.02857538 6.76421407 5.46035101 4.77575971 6.31781004\n",
      " 5.96614154 5.57436861 5.89654854 5.04509822]\n",
      "##########\n",
      "epoch:8 step:8401 [D loss: 0.717811, acc.: 49.22%] [G loss: 0.878598]\n",
      "epoch:8 step:8402 [D loss: 0.735390, acc.: 52.34%] [G loss: 0.864774]\n",
      "epoch:8 step:8403 [D loss: 0.672615, acc.: 50.78%] [G loss: 0.858552]\n",
      "epoch:8 step:8404 [D loss: 0.688534, acc.: 49.22%] [G loss: 0.773496]\n",
      "epoch:8 step:8405 [D loss: 0.611386, acc.: 73.44%] [G loss: 0.872935]\n",
      "epoch:8 step:8406 [D loss: 0.762550, acc.: 36.72%] [G loss: 0.936720]\n",
      "epoch:8 step:8407 [D loss: 0.660449, acc.: 67.97%] [G loss: 0.865672]\n",
      "epoch:8 step:8408 [D loss: 0.345269, acc.: 90.62%] [G loss: 0.906940]\n",
      "epoch:8 step:8409 [D loss: 0.679979, acc.: 50.78%] [G loss: 0.928410]\n",
      "epoch:8 step:8410 [D loss: 0.726706, acc.: 46.09%] [G loss: 0.792187]\n",
      "epoch:8 step:8411 [D loss: 0.724375, acc.: 49.22%] [G loss: 0.698860]\n",
      "epoch:8 step:8412 [D loss: 0.737895, acc.: 42.97%] [G loss: 0.849636]\n",
      "epoch:8 step:8413 [D loss: 0.745013, acc.: 47.66%] [G loss: 0.721656]\n",
      "epoch:8 step:8414 [D loss: 0.636676, acc.: 67.19%] [G loss: 0.810723]\n",
      "epoch:8 step:8415 [D loss: 0.606780, acc.: 68.75%] [G loss: 0.905898]\n",
      "epoch:8 step:8416 [D loss: 0.760819, acc.: 32.81%] [G loss: 0.736861]\n",
      "epoch:8 step:8417 [D loss: 0.669470, acc.: 54.69%] [G loss: 0.810190]\n",
      "epoch:8 step:8418 [D loss: 0.645197, acc.: 67.97%] [G loss: 0.708078]\n",
      "epoch:8 step:8419 [D loss: 0.620804, acc.: 67.19%] [G loss: 0.762687]\n",
      "epoch:8 step:8420 [D loss: 0.432046, acc.: 83.59%] [G loss: 0.827380]\n",
      "epoch:8 step:8421 [D loss: 0.433377, acc.: 83.59%] [G loss: 0.857157]\n",
      "epoch:8 step:8422 [D loss: 0.380180, acc.: 72.66%] [G loss: 0.851450]\n",
      "epoch:8 step:8423 [D loss: 0.338950, acc.: 82.03%] [G loss: 0.964659]\n",
      "epoch:8 step:8424 [D loss: 0.789124, acc.: 46.09%] [G loss: 0.926431]\n",
      "epoch:8 step:8425 [D loss: 0.630269, acc.: 65.62%] [G loss: 0.911294]\n",
      "epoch:8 step:8426 [D loss: 0.674221, acc.: 59.38%] [G loss: 0.879055]\n",
      "epoch:8 step:8427 [D loss: 0.589512, acc.: 72.66%] [G loss: 0.985635]\n",
      "epoch:8 step:8428 [D loss: 0.587616, acc.: 72.66%] [G loss: 1.014349]\n",
      "epoch:8 step:8429 [D loss: 0.381406, acc.: 82.03%] [G loss: 0.842014]\n",
      "epoch:8 step:8430 [D loss: 0.393187, acc.: 85.16%] [G loss: 0.863997]\n",
      "epoch:8 step:8431 [D loss: 0.471284, acc.: 85.16%] [G loss: 0.894739]\n",
      "epoch:8 step:8432 [D loss: 0.489098, acc.: 66.41%] [G loss: 0.946552]\n",
      "epoch:8 step:8433 [D loss: 0.281928, acc.: 87.50%] [G loss: 1.195991]\n",
      "epoch:9 step:8434 [D loss: 0.762253, acc.: 51.56%] [G loss: 1.042899]\n",
      "epoch:9 step:8435 [D loss: 0.795294, acc.: 44.53%] [G loss: 0.900137]\n",
      "epoch:9 step:8436 [D loss: 0.728750, acc.: 54.69%] [G loss: 0.934500]\n",
      "epoch:9 step:8437 [D loss: 0.745137, acc.: 45.31%] [G loss: 0.893556]\n",
      "epoch:9 step:8438 [D loss: 0.781492, acc.: 30.47%] [G loss: 0.835465]\n",
      "epoch:9 step:8439 [D loss: 0.678393, acc.: 58.59%] [G loss: 0.890299]\n",
      "epoch:9 step:8440 [D loss: 0.780334, acc.: 31.25%] [G loss: 0.729194]\n",
      "epoch:9 step:8441 [D loss: 0.701099, acc.: 48.44%] [G loss: 0.826161]\n",
      "epoch:9 step:8442 [D loss: 0.704243, acc.: 45.31%] [G loss: 0.700573]\n",
      "epoch:9 step:8443 [D loss: 0.709542, acc.: 50.00%] [G loss: 0.674532]\n",
      "epoch:9 step:8444 [D loss: 0.673874, acc.: 57.03%] [G loss: 0.742308]\n",
      "epoch:9 step:8445 [D loss: 0.795379, acc.: 32.03%] [G loss: 0.821538]\n",
      "epoch:9 step:8446 [D loss: 0.691796, acc.: 46.88%] [G loss: 0.883890]\n",
      "epoch:9 step:8447 [D loss: 0.688584, acc.: 50.00%] [G loss: 0.903600]\n",
      "epoch:9 step:8448 [D loss: 0.660489, acc.: 60.16%] [G loss: 0.814059]\n",
      "epoch:9 step:8449 [D loss: 0.672104, acc.: 50.78%] [G loss: 0.914357]\n",
      "epoch:9 step:8450 [D loss: 0.707323, acc.: 42.19%] [G loss: 0.770561]\n",
      "epoch:9 step:8451 [D loss: 0.699037, acc.: 44.53%] [G loss: 1.303038]\n",
      "epoch:9 step:8452 [D loss: 0.727371, acc.: 35.16%] [G loss: 0.861738]\n",
      "epoch:9 step:8453 [D loss: 0.730016, acc.: 41.41%] [G loss: 0.842387]\n",
      "epoch:9 step:8454 [D loss: 0.719104, acc.: 43.75%] [G loss: 0.895056]\n",
      "epoch:9 step:8455 [D loss: 0.690920, acc.: 54.69%] [G loss: 1.005372]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8456 [D loss: 0.681082, acc.: 51.56%] [G loss: 0.907990]\n",
      "epoch:9 step:8457 [D loss: 0.694255, acc.: 53.12%] [G loss: 0.926236]\n",
      "epoch:9 step:8458 [D loss: 0.668513, acc.: 58.59%] [G loss: 0.821073]\n",
      "epoch:9 step:8459 [D loss: 0.674434, acc.: 54.69%] [G loss: 0.801584]\n",
      "epoch:9 step:8460 [D loss: 0.711062, acc.: 48.44%] [G loss: 1.009442]\n",
      "epoch:9 step:8461 [D loss: 0.716531, acc.: 52.34%] [G loss: 0.802798]\n",
      "epoch:9 step:8462 [D loss: 0.625813, acc.: 75.78%] [G loss: 0.798342]\n",
      "epoch:9 step:8463 [D loss: 0.624214, acc.: 78.91%] [G loss: 0.785173]\n",
      "epoch:9 step:8464 [D loss: 0.603462, acc.: 71.09%] [G loss: 0.928932]\n",
      "epoch:9 step:8465 [D loss: 0.612391, acc.: 79.69%] [G loss: 0.943647]\n",
      "epoch:9 step:8466 [D loss: 0.637799, acc.: 68.75%] [G loss: 0.822767]\n",
      "epoch:9 step:8467 [D loss: 0.646156, acc.: 70.31%] [G loss: 0.877450]\n",
      "epoch:9 step:8468 [D loss: 0.572094, acc.: 78.12%] [G loss: 1.285156]\n",
      "epoch:9 step:8469 [D loss: 0.524631, acc.: 81.25%] [G loss: 0.850317]\n",
      "epoch:9 step:8470 [D loss: 0.772011, acc.: 34.38%] [G loss: 1.472395]\n",
      "epoch:9 step:8471 [D loss: 1.467071, acc.: 23.44%] [G loss: 0.686846]\n",
      "epoch:9 step:8472 [D loss: 0.750058, acc.: 32.81%] [G loss: 0.730735]\n",
      "epoch:9 step:8473 [D loss: 0.717746, acc.: 44.53%] [G loss: 0.746989]\n",
      "epoch:9 step:8474 [D loss: 0.692618, acc.: 50.00%] [G loss: 0.748330]\n",
      "epoch:9 step:8475 [D loss: 0.697182, acc.: 50.78%] [G loss: 0.698198]\n",
      "epoch:9 step:8476 [D loss: 0.672512, acc.: 65.62%] [G loss: 0.764319]\n",
      "epoch:9 step:8477 [D loss: 0.664215, acc.: 64.84%] [G loss: 0.787391]\n",
      "epoch:9 step:8478 [D loss: 0.670294, acc.: 64.84%] [G loss: 0.793089]\n",
      "epoch:9 step:8479 [D loss: 0.752868, acc.: 42.97%] [G loss: 0.784160]\n",
      "epoch:9 step:8480 [D loss: 0.662759, acc.: 60.16%] [G loss: 0.841857]\n",
      "epoch:9 step:8481 [D loss: 0.620531, acc.: 66.41%] [G loss: 0.802193]\n",
      "epoch:9 step:8482 [D loss: 0.644218, acc.: 78.12%] [G loss: 0.893990]\n",
      "epoch:9 step:8483 [D loss: 0.614469, acc.: 67.97%] [G loss: 0.925659]\n",
      "epoch:9 step:8484 [D loss: 0.693020, acc.: 56.25%] [G loss: 0.872685]\n",
      "epoch:9 step:8485 [D loss: 0.640227, acc.: 61.72%] [G loss: 0.905029]\n",
      "epoch:9 step:8486 [D loss: 0.647016, acc.: 60.94%] [G loss: 0.838190]\n",
      "epoch:9 step:8487 [D loss: 0.685644, acc.: 55.47%] [G loss: 0.864790]\n",
      "epoch:9 step:8488 [D loss: 0.631578, acc.: 67.97%] [G loss: 0.908420]\n",
      "epoch:9 step:8489 [D loss: 0.678004, acc.: 55.47%] [G loss: 0.843470]\n",
      "epoch:9 step:8490 [D loss: 0.726567, acc.: 49.22%] [G loss: 0.800053]\n",
      "epoch:9 step:8491 [D loss: 0.695650, acc.: 52.34%] [G loss: 0.751457]\n",
      "epoch:9 step:8492 [D loss: 0.675480, acc.: 56.25%] [G loss: 0.926733]\n",
      "epoch:9 step:8493 [D loss: 0.733213, acc.: 42.97%] [G loss: 0.792565]\n",
      "epoch:9 step:8494 [D loss: 0.695410, acc.: 53.12%] [G loss: 0.846233]\n",
      "epoch:9 step:8495 [D loss: 0.679317, acc.: 56.25%] [G loss: 0.801597]\n",
      "epoch:9 step:8496 [D loss: 0.689423, acc.: 52.34%] [G loss: 0.843015]\n",
      "epoch:9 step:8497 [D loss: 0.663414, acc.: 56.25%] [G loss: 0.787713]\n",
      "epoch:9 step:8498 [D loss: 0.690917, acc.: 60.16%] [G loss: 0.786862]\n",
      "epoch:9 step:8499 [D loss: 0.727087, acc.: 37.50%] [G loss: 0.746427]\n",
      "epoch:9 step:8500 [D loss: 0.630385, acc.: 74.22%] [G loss: 0.709010]\n",
      "epoch:9 step:8501 [D loss: 0.636261, acc.: 71.09%] [G loss: 0.819832]\n",
      "epoch:9 step:8502 [D loss: 0.589336, acc.: 76.56%] [G loss: 0.766067]\n",
      "epoch:9 step:8503 [D loss: 0.614454, acc.: 73.44%] [G loss: 0.819584]\n",
      "epoch:9 step:8504 [D loss: 0.839233, acc.: 23.44%] [G loss: 0.852109]\n",
      "epoch:9 step:8505 [D loss: 0.656006, acc.: 63.28%] [G loss: 0.782418]\n",
      "epoch:9 step:8506 [D loss: 0.695504, acc.: 53.91%] [G loss: 0.876541]\n",
      "epoch:9 step:8507 [D loss: 0.761647, acc.: 33.59%] [G loss: 0.776431]\n",
      "epoch:9 step:8508 [D loss: 0.679651, acc.: 54.69%] [G loss: 0.754061]\n",
      "epoch:9 step:8509 [D loss: 0.641460, acc.: 65.62%] [G loss: 0.801431]\n",
      "epoch:9 step:8510 [D loss: 0.615627, acc.: 66.41%] [G loss: 0.780941]\n",
      "epoch:9 step:8511 [D loss: 0.725950, acc.: 52.34%] [G loss: 0.781003]\n",
      "epoch:9 step:8512 [D loss: 0.695132, acc.: 49.22%] [G loss: 0.761590]\n",
      "epoch:9 step:8513 [D loss: 0.670700, acc.: 54.69%] [G loss: 0.740629]\n",
      "epoch:9 step:8514 [D loss: 0.658984, acc.: 63.28%] [G loss: 0.760153]\n",
      "epoch:9 step:8515 [D loss: 0.634349, acc.: 69.53%] [G loss: 0.631384]\n",
      "epoch:9 step:8516 [D loss: 0.634186, acc.: 71.88%] [G loss: 0.560343]\n",
      "epoch:9 step:8517 [D loss: 0.645702, acc.: 64.06%] [G loss: 0.779070]\n",
      "epoch:9 step:8518 [D loss: 0.433735, acc.: 78.91%] [G loss: 0.766863]\n",
      "epoch:9 step:8519 [D loss: 0.700094, acc.: 48.44%] [G loss: 0.737513]\n",
      "epoch:9 step:8520 [D loss: 0.681260, acc.: 56.25%] [G loss: 0.700212]\n",
      "epoch:9 step:8521 [D loss: 0.648758, acc.: 62.50%] [G loss: 0.840043]\n",
      "epoch:9 step:8522 [D loss: 0.624015, acc.: 69.53%] [G loss: 0.763448]\n",
      "epoch:9 step:8523 [D loss: 0.707324, acc.: 54.69%] [G loss: 0.103147]\n",
      "epoch:9 step:8524 [D loss: 0.682830, acc.: 56.25%] [G loss: 0.597872]\n",
      "epoch:9 step:8525 [D loss: 0.683626, acc.: 53.91%] [G loss: 0.247432]\n",
      "epoch:9 step:8526 [D loss: 0.725268, acc.: 50.78%] [G loss: 0.893418]\n",
      "epoch:9 step:8527 [D loss: 0.656635, acc.: 60.16%] [G loss: 0.757504]\n",
      "epoch:9 step:8528 [D loss: 0.706075, acc.: 48.44%] [G loss: 0.860949]\n",
      "epoch:9 step:8529 [D loss: 0.748277, acc.: 44.53%] [G loss: 0.892754]\n",
      "epoch:9 step:8530 [D loss: 0.640879, acc.: 61.72%] [G loss: 0.907379]\n",
      "epoch:9 step:8531 [D loss: 0.633639, acc.: 64.06%] [G loss: 0.829153]\n",
      "epoch:9 step:8532 [D loss: 0.632034, acc.: 66.41%] [G loss: 0.845362]\n",
      "epoch:9 step:8533 [D loss: 0.647417, acc.: 64.06%] [G loss: 0.925595]\n",
      "epoch:9 step:8534 [D loss: 0.695545, acc.: 57.03%] [G loss: 0.884029]\n",
      "epoch:9 step:8535 [D loss: 0.720618, acc.: 47.66%] [G loss: 0.811817]\n",
      "epoch:9 step:8536 [D loss: 0.662535, acc.: 59.38%] [G loss: 0.839195]\n",
      "epoch:9 step:8537 [D loss: 0.659346, acc.: 61.72%] [G loss: 0.831932]\n",
      "epoch:9 step:8538 [D loss: 0.491560, acc.: 88.28%] [G loss: 0.971497]\n",
      "epoch:9 step:8539 [D loss: 0.633527, acc.: 71.09%] [G loss: 1.083390]\n",
      "epoch:9 step:8540 [D loss: 0.544366, acc.: 83.59%] [G loss: 1.060359]\n",
      "epoch:9 step:8541 [D loss: 0.653017, acc.: 64.06%] [G loss: 0.988180]\n",
      "epoch:9 step:8542 [D loss: 0.665223, acc.: 64.06%] [G loss: 0.982478]\n",
      "epoch:9 step:8543 [D loss: 0.645246, acc.: 63.28%] [G loss: 0.902546]\n",
      "epoch:9 step:8544 [D loss: 0.684325, acc.: 53.12%] [G loss: 0.745657]\n",
      "epoch:9 step:8545 [D loss: 0.653481, acc.: 61.72%] [G loss: 0.822700]\n",
      "epoch:9 step:8546 [D loss: 0.782170, acc.: 43.75%] [G loss: 0.787222]\n",
      "epoch:9 step:8547 [D loss: 0.682321, acc.: 52.34%] [G loss: 0.658767]\n",
      "epoch:9 step:8548 [D loss: 0.678555, acc.: 52.34%] [G loss: 0.685525]\n",
      "epoch:9 step:8549 [D loss: 0.695889, acc.: 50.00%] [G loss: 0.642889]\n",
      "epoch:9 step:8550 [D loss: 0.750448, acc.: 42.97%] [G loss: 0.634397]\n",
      "epoch:9 step:8551 [D loss: 0.682711, acc.: 55.47%] [G loss: 0.740551]\n",
      "epoch:9 step:8552 [D loss: 0.547756, acc.: 69.53%] [G loss: 0.745139]\n",
      "epoch:9 step:8553 [D loss: 0.731726, acc.: 48.44%] [G loss: 0.829600]\n",
      "epoch:9 step:8554 [D loss: 0.735592, acc.: 40.62%] [G loss: 0.922167]\n",
      "epoch:9 step:8555 [D loss: 0.659388, acc.: 61.72%] [G loss: 0.929732]\n",
      "epoch:9 step:8556 [D loss: 0.648828, acc.: 60.94%] [G loss: 0.960715]\n",
      "epoch:9 step:8557 [D loss: 0.600308, acc.: 74.22%] [G loss: 1.001276]\n",
      "epoch:9 step:8558 [D loss: 0.640078, acc.: 71.09%] [G loss: 0.979886]\n",
      "epoch:9 step:8559 [D loss: 0.580764, acc.: 78.12%] [G loss: 1.058097]\n",
      "epoch:9 step:8560 [D loss: 0.662394, acc.: 59.38%] [G loss: 0.870737]\n",
      "epoch:9 step:8561 [D loss: 0.739567, acc.: 42.97%] [G loss: 0.830884]\n",
      "epoch:9 step:8562 [D loss: 0.708439, acc.: 54.69%] [G loss: 0.750420]\n",
      "epoch:9 step:8563 [D loss: 0.660558, acc.: 64.84%] [G loss: 0.812428]\n",
      "epoch:9 step:8564 [D loss: 0.675380, acc.: 57.81%] [G loss: 0.863020]\n",
      "epoch:9 step:8565 [D loss: 0.674549, acc.: 59.38%] [G loss: 0.817593]\n",
      "epoch:9 step:8566 [D loss: 0.640027, acc.: 60.16%] [G loss: 0.842052]\n",
      "epoch:9 step:8567 [D loss: 0.583246, acc.: 69.53%] [G loss: 0.821932]\n",
      "epoch:9 step:8568 [D loss: 0.697442, acc.: 53.12%] [G loss: 0.654650]\n",
      "epoch:9 step:8569 [D loss: 0.675553, acc.: 57.03%] [G loss: 0.773400]\n",
      "epoch:9 step:8570 [D loss: 0.727214, acc.: 50.78%] [G loss: 0.628524]\n",
      "epoch:9 step:8571 [D loss: 0.723402, acc.: 53.12%] [G loss: 0.721601]\n",
      "epoch:9 step:8572 [D loss: 0.629687, acc.: 65.62%] [G loss: 0.781190]\n",
      "epoch:9 step:8573 [D loss: 0.673848, acc.: 62.50%] [G loss: 0.857138]\n",
      "epoch:9 step:8574 [D loss: 0.703844, acc.: 45.31%] [G loss: 0.615675]\n",
      "epoch:9 step:8575 [D loss: 0.834715, acc.: 29.69%] [G loss: 0.910780]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8576 [D loss: 0.577478, acc.: 71.88%] [G loss: 0.708055]\n",
      "epoch:9 step:8577 [D loss: 0.566164, acc.: 76.56%] [G loss: 0.914598]\n",
      "epoch:9 step:8578 [D loss: 0.490783, acc.: 90.62%] [G loss: 0.900180]\n",
      "epoch:9 step:8579 [D loss: 0.715536, acc.: 51.56%] [G loss: 0.565681]\n",
      "epoch:9 step:8580 [D loss: 0.637564, acc.: 58.59%] [G loss: 0.849736]\n",
      "epoch:9 step:8581 [D loss: 0.683472, acc.: 60.16%] [G loss: 0.890330]\n",
      "epoch:9 step:8582 [D loss: 0.748227, acc.: 48.44%] [G loss: 0.662346]\n",
      "epoch:9 step:8583 [D loss: 0.573445, acc.: 77.34%] [G loss: 0.656036]\n",
      "epoch:9 step:8584 [D loss: 0.873822, acc.: 28.12%] [G loss: 0.656506]\n",
      "epoch:9 step:8585 [D loss: 0.820292, acc.: 42.97%] [G loss: 0.733019]\n",
      "epoch:9 step:8586 [D loss: 0.737165, acc.: 49.22%] [G loss: 0.832919]\n",
      "epoch:9 step:8587 [D loss: 0.670340, acc.: 57.03%] [G loss: 0.950865]\n",
      "epoch:9 step:8588 [D loss: 0.733329, acc.: 46.09%] [G loss: 0.926993]\n",
      "epoch:9 step:8589 [D loss: 0.607899, acc.: 67.97%] [G loss: 1.010440]\n",
      "epoch:9 step:8590 [D loss: 0.642842, acc.: 62.50%] [G loss: 0.997897]\n",
      "epoch:9 step:8591 [D loss: 0.662324, acc.: 59.38%] [G loss: 0.929082]\n",
      "epoch:9 step:8592 [D loss: 0.594186, acc.: 71.88%] [G loss: 1.080636]\n",
      "epoch:9 step:8593 [D loss: 0.730393, acc.: 54.69%] [G loss: 0.986128]\n",
      "epoch:9 step:8594 [D loss: 0.579368, acc.: 66.41%] [G loss: 1.089914]\n",
      "epoch:9 step:8595 [D loss: 0.745839, acc.: 46.09%] [G loss: 0.815107]\n",
      "epoch:9 step:8596 [D loss: 0.725132, acc.: 46.88%] [G loss: 0.894007]\n",
      "epoch:9 step:8597 [D loss: 0.590916, acc.: 71.09%] [G loss: 0.815074]\n",
      "epoch:9 step:8598 [D loss: 0.601580, acc.: 69.53%] [G loss: 1.100073]\n",
      "epoch:9 step:8599 [D loss: 0.511338, acc.: 83.59%] [G loss: 0.993572]\n",
      "epoch:9 step:8600 [D loss: 0.678165, acc.: 54.69%] [G loss: 0.699654]\n",
      "##############\n",
      "[3.8955978  2.21079002 6.51547317 5.87600277 3.80892453 6.22571494\n",
      " 5.37990328 5.07863731 5.69393465 5.21293336]\n",
      "##########\n",
      "epoch:9 step:8601 [D loss: 0.515793, acc.: 82.03%] [G loss: 0.666215]\n",
      "epoch:9 step:8602 [D loss: 0.651604, acc.: 57.81%] [G loss: 0.697293]\n",
      "epoch:9 step:8603 [D loss: 0.932530, acc.: 25.00%] [G loss: 0.864455]\n",
      "epoch:9 step:8604 [D loss: 0.728881, acc.: 46.88%] [G loss: 0.861217]\n",
      "epoch:9 step:8605 [D loss: 0.598764, acc.: 68.75%] [G loss: 0.733137]\n",
      "epoch:9 step:8606 [D loss: 0.617608, acc.: 68.75%] [G loss: 0.279921]\n",
      "epoch:9 step:8607 [D loss: 0.818256, acc.: 33.59%] [G loss: 0.636751]\n",
      "epoch:9 step:8608 [D loss: 1.127830, acc.: 31.25%] [G loss: 0.876999]\n",
      "epoch:9 step:8609 [D loss: 0.697944, acc.: 59.38%] [G loss: 0.866533]\n",
      "epoch:9 step:8610 [D loss: 0.723761, acc.: 55.47%] [G loss: 3.223767]\n",
      "epoch:9 step:8611 [D loss: 0.703102, acc.: 51.56%] [G loss: 1.161121]\n",
      "epoch:9 step:8612 [D loss: 0.751094, acc.: 43.75%] [G loss: 0.912509]\n",
      "epoch:9 step:8613 [D loss: 0.669281, acc.: 57.81%] [G loss: 0.827126]\n",
      "epoch:9 step:8614 [D loss: 0.668700, acc.: 64.06%] [G loss: 0.773950]\n",
      "epoch:9 step:8615 [D loss: 0.704552, acc.: 43.75%] [G loss: 0.982105]\n",
      "epoch:9 step:8616 [D loss: 0.705481, acc.: 42.19%] [G loss: 0.737729]\n",
      "epoch:9 step:8617 [D loss: 0.664511, acc.: 55.47%] [G loss: 0.681847]\n",
      "epoch:9 step:8618 [D loss: 0.774972, acc.: 40.62%] [G loss: 0.783988]\n",
      "epoch:9 step:8619 [D loss: 0.725047, acc.: 45.31%] [G loss: 0.775694]\n",
      "epoch:9 step:8620 [D loss: 0.630597, acc.: 71.88%] [G loss: 0.836277]\n",
      "epoch:9 step:8621 [D loss: 0.649552, acc.: 67.19%] [G loss: 0.707604]\n",
      "epoch:9 step:8622 [D loss: 0.698946, acc.: 49.22%] [G loss: 0.786118]\n",
      "epoch:9 step:8623 [D loss: 0.632963, acc.: 70.31%] [G loss: 0.817434]\n",
      "epoch:9 step:8624 [D loss: 0.664619, acc.: 63.28%] [G loss: 0.827440]\n",
      "epoch:9 step:8625 [D loss: 0.660306, acc.: 54.69%] [G loss: 0.783165]\n",
      "epoch:9 step:8626 [D loss: 0.704955, acc.: 51.56%] [G loss: 0.845865]\n",
      "epoch:9 step:8627 [D loss: 0.648636, acc.: 63.28%] [G loss: 0.689446]\n",
      "epoch:9 step:8628 [D loss: 0.623087, acc.: 73.44%] [G loss: 0.750789]\n",
      "epoch:9 step:8629 [D loss: 0.661521, acc.: 62.50%] [G loss: 0.799609]\n",
      "epoch:9 step:8630 [D loss: 0.620467, acc.: 67.19%] [G loss: 0.807886]\n",
      "epoch:9 step:8631 [D loss: 0.644057, acc.: 64.84%] [G loss: 0.898095]\n",
      "epoch:9 step:8632 [D loss: 0.681784, acc.: 53.91%] [G loss: 0.799742]\n",
      "epoch:9 step:8633 [D loss: 0.900715, acc.: 32.81%] [G loss: 0.764320]\n",
      "epoch:9 step:8634 [D loss: 0.829459, acc.: 37.50%] [G loss: 0.796057]\n",
      "epoch:9 step:8635 [D loss: 0.694543, acc.: 50.78%] [G loss: 0.854558]\n",
      "epoch:9 step:8636 [D loss: 0.633247, acc.: 69.53%] [G loss: 0.784341]\n",
      "epoch:9 step:8637 [D loss: 0.684640, acc.: 51.56%] [G loss: 0.746737]\n",
      "epoch:9 step:8638 [D loss: 0.674390, acc.: 61.72%] [G loss: 0.769743]\n",
      "epoch:9 step:8639 [D loss: 0.649690, acc.: 61.72%] [G loss: 0.759186]\n",
      "epoch:9 step:8640 [D loss: 0.788269, acc.: 64.84%] [G loss: 0.837496]\n",
      "epoch:9 step:8641 [D loss: 0.660822, acc.: 58.59%] [G loss: 0.959082]\n",
      "epoch:9 step:8642 [D loss: 0.661386, acc.: 62.50%] [G loss: 0.790059]\n",
      "epoch:9 step:8643 [D loss: 0.700280, acc.: 55.47%] [G loss: 0.784345]\n",
      "epoch:9 step:8644 [D loss: 0.686879, acc.: 53.12%] [G loss: 0.810856]\n",
      "epoch:9 step:8645 [D loss: 0.702865, acc.: 50.78%] [G loss: 0.986492]\n",
      "epoch:9 step:8646 [D loss: 0.693695, acc.: 50.78%] [G loss: 0.771434]\n",
      "epoch:9 step:8647 [D loss: 0.668254, acc.: 60.16%] [G loss: 0.751017]\n",
      "epoch:9 step:8648 [D loss: 0.656414, acc.: 69.53%] [G loss: 0.741565]\n",
      "epoch:9 step:8649 [D loss: 0.826332, acc.: 63.28%] [G loss: 0.699816]\n",
      "epoch:9 step:8650 [D loss: 0.683630, acc.: 56.25%] [G loss: 0.754707]\n",
      "epoch:9 step:8651 [D loss: 0.646474, acc.: 68.75%] [G loss: 0.794855]\n",
      "epoch:9 step:8652 [D loss: 0.635472, acc.: 66.41%] [G loss: 0.778577]\n",
      "epoch:9 step:8653 [D loss: 0.714797, acc.: 46.88%] [G loss: 0.768689]\n",
      "epoch:9 step:8654 [D loss: 0.620625, acc.: 69.53%] [G loss: 0.696714]\n",
      "epoch:9 step:8655 [D loss: 0.632340, acc.: 67.19%] [G loss: 0.727936]\n",
      "epoch:9 step:8656 [D loss: 0.663314, acc.: 62.50%] [G loss: 0.780087]\n",
      "epoch:9 step:8657 [D loss: 0.661017, acc.: 60.94%] [G loss: 0.769958]\n",
      "epoch:9 step:8658 [D loss: 0.671060, acc.: 52.34%] [G loss: 0.784371]\n",
      "epoch:9 step:8659 [D loss: 0.735856, acc.: 40.62%] [G loss: 0.767565]\n",
      "epoch:9 step:8660 [D loss: 0.702288, acc.: 48.44%] [G loss: 0.741619]\n",
      "epoch:9 step:8661 [D loss: 0.649364, acc.: 59.38%] [G loss: 0.697735]\n",
      "epoch:9 step:8662 [D loss: 0.688295, acc.: 57.81%] [G loss: 0.719983]\n",
      "epoch:9 step:8663 [D loss: 0.567952, acc.: 69.53%] [G loss: 0.841698]\n",
      "epoch:9 step:8664 [D loss: 0.596620, acc.: 64.84%] [G loss: 0.858006]\n",
      "epoch:9 step:8665 [D loss: 0.777343, acc.: 55.47%] [G loss: 0.980731]\n",
      "epoch:9 step:8666 [D loss: 0.669639, acc.: 63.28%] [G loss: 0.971259]\n",
      "epoch:9 step:8667 [D loss: 0.613484, acc.: 71.88%] [G loss: 1.376398]\n",
      "epoch:9 step:8668 [D loss: 0.572193, acc.: 71.09%] [G loss: 1.033210]\n",
      "epoch:9 step:8669 [D loss: 0.634205, acc.: 68.75%] [G loss: 1.067961]\n",
      "epoch:9 step:8670 [D loss: 0.625883, acc.: 64.06%] [G loss: 1.015011]\n",
      "epoch:9 step:8671 [D loss: 0.648068, acc.: 66.41%] [G loss: 0.977616]\n",
      "epoch:9 step:8672 [D loss: 0.643634, acc.: 61.72%] [G loss: 0.897375]\n",
      "epoch:9 step:8673 [D loss: 0.694511, acc.: 51.56%] [G loss: 0.831505]\n",
      "epoch:9 step:8674 [D loss: 0.787847, acc.: 38.28%] [G loss: 0.867869]\n",
      "epoch:9 step:8675 [D loss: 0.694604, acc.: 47.66%] [G loss: 0.858027]\n",
      "epoch:9 step:8676 [D loss: 0.695114, acc.: 51.56%] [G loss: 0.750102]\n",
      "epoch:9 step:8677 [D loss: 0.667866, acc.: 59.38%] [G loss: 0.732923]\n",
      "epoch:9 step:8678 [D loss: 0.749840, acc.: 44.53%] [G loss: 0.697351]\n",
      "epoch:9 step:8679 [D loss: 0.716894, acc.: 45.31%] [G loss: 0.747365]\n",
      "epoch:9 step:8680 [D loss: 0.681567, acc.: 54.69%] [G loss: 0.799274]\n",
      "epoch:9 step:8681 [D loss: 0.655908, acc.: 62.50%] [G loss: 0.812138]\n",
      "epoch:9 step:8682 [D loss: 0.667529, acc.: 62.50%] [G loss: 0.841818]\n",
      "epoch:9 step:8683 [D loss: 0.693083, acc.: 54.69%] [G loss: 0.792179]\n",
      "epoch:9 step:8684 [D loss: 0.700850, acc.: 53.12%] [G loss: 0.741772]\n",
      "epoch:9 step:8685 [D loss: 0.680538, acc.: 54.69%] [G loss: 0.733410]\n",
      "epoch:9 step:8686 [D loss: 0.670700, acc.: 56.25%] [G loss: 0.636547]\n",
      "epoch:9 step:8687 [D loss: 0.730931, acc.: 44.53%] [G loss: 0.747342]\n",
      "epoch:9 step:8688 [D loss: 0.648206, acc.: 63.28%] [G loss: 0.796637]\n",
      "epoch:9 step:8689 [D loss: 0.542762, acc.: 70.31%] [G loss: 0.793599]\n",
      "epoch:9 step:8690 [D loss: 0.647083, acc.: 67.19%] [G loss: 0.491820]\n",
      "epoch:9 step:8691 [D loss: 0.789092, acc.: 39.06%] [G loss: 0.769397]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8692 [D loss: 0.544177, acc.: 75.00%] [G loss: 0.790084]\n",
      "epoch:9 step:8693 [D loss: 0.568068, acc.: 74.22%] [G loss: 0.834125]\n",
      "epoch:9 step:8694 [D loss: 0.558649, acc.: 72.66%] [G loss: 0.864517]\n",
      "epoch:9 step:8695 [D loss: 0.698865, acc.: 53.12%] [G loss: 0.780437]\n",
      "epoch:9 step:8696 [D loss: 0.738629, acc.: 43.75%] [G loss: 0.882103]\n",
      "epoch:9 step:8697 [D loss: 0.666645, acc.: 60.94%] [G loss: 0.864440]\n",
      "epoch:9 step:8698 [D loss: 0.683568, acc.: 55.47%] [G loss: 0.607196]\n",
      "epoch:9 step:8699 [D loss: 0.706626, acc.: 50.78%] [G loss: 0.891291]\n",
      "epoch:9 step:8700 [D loss: 0.699895, acc.: 47.66%] [G loss: 0.822595]\n",
      "epoch:9 step:8701 [D loss: 0.756034, acc.: 35.16%] [G loss: 0.830041]\n",
      "epoch:9 step:8702 [D loss: 0.681826, acc.: 57.03%] [G loss: 0.856991]\n",
      "epoch:9 step:8703 [D loss: 0.715630, acc.: 49.22%] [G loss: 0.831655]\n",
      "epoch:9 step:8704 [D loss: 0.678837, acc.: 54.69%] [G loss: 0.838515]\n",
      "epoch:9 step:8705 [D loss: 0.677564, acc.: 55.47%] [G loss: 0.703045]\n",
      "epoch:9 step:8706 [D loss: 0.668811, acc.: 57.81%] [G loss: 0.838617]\n",
      "epoch:9 step:8707 [D loss: 0.721373, acc.: 48.44%] [G loss: 0.864879]\n",
      "epoch:9 step:8708 [D loss: 0.636732, acc.: 65.62%] [G loss: 0.882855]\n",
      "epoch:9 step:8709 [D loss: 0.655345, acc.: 64.84%] [G loss: 0.820773]\n",
      "epoch:9 step:8710 [D loss: 0.644655, acc.: 59.38%] [G loss: 0.870506]\n",
      "epoch:9 step:8711 [D loss: 0.651572, acc.: 63.28%] [G loss: 0.841835]\n",
      "epoch:9 step:8712 [D loss: 0.597562, acc.: 71.88%] [G loss: 0.839698]\n",
      "epoch:9 step:8713 [D loss: 0.700850, acc.: 55.47%] [G loss: 0.785731]\n",
      "epoch:9 step:8714 [D loss: 0.710806, acc.: 44.53%] [G loss: 0.821653]\n",
      "epoch:9 step:8715 [D loss: 0.662224, acc.: 61.72%] [G loss: 0.802806]\n",
      "epoch:9 step:8716 [D loss: 0.692020, acc.: 53.12%] [G loss: 0.769606]\n",
      "epoch:9 step:8717 [D loss: 0.708813, acc.: 46.88%] [G loss: 0.804574]\n",
      "epoch:9 step:8718 [D loss: 0.671106, acc.: 55.47%] [G loss: 0.797096]\n",
      "epoch:9 step:8719 [D loss: 0.708105, acc.: 46.09%] [G loss: 0.740760]\n",
      "epoch:9 step:8720 [D loss: 0.603293, acc.: 68.75%] [G loss: 0.824700]\n",
      "epoch:9 step:8721 [D loss: 0.581445, acc.: 73.44%] [G loss: 0.817667]\n",
      "epoch:9 step:8722 [D loss: 0.534541, acc.: 78.91%] [G loss: 0.875669]\n",
      "epoch:9 step:8723 [D loss: 0.554366, acc.: 73.44%] [G loss: 0.889858]\n",
      "epoch:9 step:8724 [D loss: 0.721622, acc.: 48.44%] [G loss: 0.839026]\n",
      "epoch:9 step:8725 [D loss: 0.485662, acc.: 82.81%] [G loss: 0.893948]\n",
      "epoch:9 step:8726 [D loss: 0.563213, acc.: 78.91%] [G loss: 0.626328]\n",
      "epoch:9 step:8727 [D loss: 0.689213, acc.: 48.44%] [G loss: 0.837409]\n",
      "epoch:9 step:8728 [D loss: 0.716779, acc.: 47.66%] [G loss: 0.798582]\n",
      "epoch:9 step:8729 [D loss: 0.694510, acc.: 57.81%] [G loss: 0.840527]\n",
      "epoch:9 step:8730 [D loss: 0.715616, acc.: 49.22%] [G loss: 0.439153]\n",
      "epoch:9 step:8731 [D loss: 0.732695, acc.: 38.28%] [G loss: 0.782855]\n",
      "epoch:9 step:8732 [D loss: 0.685785, acc.: 56.25%] [G loss: 0.828022]\n",
      "epoch:9 step:8733 [D loss: 0.712862, acc.: 53.12%] [G loss: 0.473711]\n",
      "epoch:9 step:8734 [D loss: 0.810041, acc.: 42.19%] [G loss: 0.830390]\n",
      "epoch:9 step:8735 [D loss: 0.658553, acc.: 63.28%] [G loss: 0.763310]\n",
      "epoch:9 step:8736 [D loss: 0.853654, acc.: 28.12%] [G loss: 0.713074]\n",
      "epoch:9 step:8737 [D loss: 0.698751, acc.: 51.56%] [G loss: 0.818107]\n",
      "epoch:9 step:8738 [D loss: 0.708027, acc.: 51.56%] [G loss: 0.844952]\n",
      "epoch:9 step:8739 [D loss: 0.671359, acc.: 63.28%] [G loss: 0.808597]\n",
      "epoch:9 step:8740 [D loss: 0.694684, acc.: 54.69%] [G loss: 0.827617]\n",
      "epoch:9 step:8741 [D loss: 0.724224, acc.: 45.31%] [G loss: 0.804857]\n",
      "epoch:9 step:8742 [D loss: 0.554429, acc.: 75.00%] [G loss: 0.708772]\n",
      "epoch:9 step:8743 [D loss: 0.693695, acc.: 51.56%] [G loss: 0.822066]\n",
      "epoch:9 step:8744 [D loss: 0.848392, acc.: 28.91%] [G loss: 0.846456]\n",
      "epoch:9 step:8745 [D loss: 0.594410, acc.: 69.53%] [G loss: 0.767608]\n",
      "epoch:9 step:8746 [D loss: 0.632202, acc.: 64.84%] [G loss: 0.888352]\n",
      "epoch:9 step:8747 [D loss: 0.534269, acc.: 84.38%] [G loss: 0.876003]\n",
      "epoch:9 step:8748 [D loss: 0.706925, acc.: 46.88%] [G loss: 0.915895]\n",
      "epoch:9 step:8749 [D loss: 0.666610, acc.: 56.25%] [G loss: 0.874010]\n",
      "epoch:9 step:8750 [D loss: 0.746127, acc.: 37.50%] [G loss: 0.884516]\n",
      "epoch:9 step:8751 [D loss: 0.646246, acc.: 60.94%] [G loss: 0.944152]\n",
      "epoch:9 step:8752 [D loss: 0.665173, acc.: 62.50%] [G loss: 0.859372]\n",
      "epoch:9 step:8753 [D loss: 0.680413, acc.: 55.47%] [G loss: 0.935759]\n",
      "epoch:9 step:8754 [D loss: 0.663075, acc.: 60.16%] [G loss: 0.880497]\n",
      "epoch:9 step:8755 [D loss: 0.658686, acc.: 57.03%] [G loss: 0.923009]\n",
      "epoch:9 step:8756 [D loss: 0.702273, acc.: 53.12%] [G loss: 0.879007]\n",
      "epoch:9 step:8757 [D loss: 0.674301, acc.: 55.47%] [G loss: 0.909742]\n",
      "epoch:9 step:8758 [D loss: 0.661928, acc.: 60.94%] [G loss: 0.852704]\n",
      "epoch:9 step:8759 [D loss: 0.708441, acc.: 50.78%] [G loss: 0.863117]\n",
      "epoch:9 step:8760 [D loss: 0.634192, acc.: 71.88%] [G loss: 0.816306]\n",
      "epoch:9 step:8761 [D loss: 0.640007, acc.: 64.84%] [G loss: 0.757634]\n",
      "epoch:9 step:8762 [D loss: 0.691817, acc.: 53.91%] [G loss: 0.850388]\n",
      "epoch:9 step:8763 [D loss: 0.652171, acc.: 61.72%] [G loss: 0.754846]\n",
      "epoch:9 step:8764 [D loss: 0.672143, acc.: 54.69%] [G loss: 0.727802]\n",
      "epoch:9 step:8765 [D loss: 0.728444, acc.: 50.00%] [G loss: 0.844106]\n",
      "epoch:9 step:8766 [D loss: 0.813250, acc.: 32.03%] [G loss: 0.815013]\n",
      "epoch:9 step:8767 [D loss: 0.758920, acc.: 33.59%] [G loss: 0.778620]\n",
      "epoch:9 step:8768 [D loss: 0.710250, acc.: 50.78%] [G loss: 0.757304]\n",
      "epoch:9 step:8769 [D loss: 0.660384, acc.: 64.06%] [G loss: 0.748712]\n",
      "epoch:9 step:8770 [D loss: 0.659663, acc.: 59.38%] [G loss: 0.775906]\n",
      "epoch:9 step:8771 [D loss: 0.698431, acc.: 50.78%] [G loss: 0.741323]\n",
      "epoch:9 step:8772 [D loss: 0.688168, acc.: 57.03%] [G loss: 0.688379]\n",
      "epoch:9 step:8773 [D loss: 0.686092, acc.: 50.78%] [G loss: 0.812846]\n",
      "epoch:9 step:8774 [D loss: 0.694778, acc.: 46.09%] [G loss: 0.708136]\n",
      "epoch:9 step:8775 [D loss: 0.644633, acc.: 64.06%] [G loss: 0.754441]\n",
      "epoch:9 step:8776 [D loss: 0.626073, acc.: 64.06%] [G loss: 0.840430]\n",
      "epoch:9 step:8777 [D loss: 0.632850, acc.: 62.50%] [G loss: 0.715011]\n",
      "epoch:9 step:8778 [D loss: 0.603942, acc.: 64.84%] [G loss: 0.751857]\n",
      "epoch:9 step:8779 [D loss: 0.587220, acc.: 67.97%] [G loss: 0.794180]\n",
      "epoch:9 step:8780 [D loss: 0.539601, acc.: 70.31%] [G loss: 0.720552]\n",
      "epoch:9 step:8781 [D loss: 0.691790, acc.: 57.03%] [G loss: 0.756153]\n",
      "epoch:9 step:8782 [D loss: 0.717821, acc.: 53.12%] [G loss: 0.779850]\n",
      "epoch:9 step:8783 [D loss: 0.677310, acc.: 58.59%] [G loss: 0.665441]\n",
      "epoch:9 step:8784 [D loss: 0.677466, acc.: 61.72%] [G loss: 0.714314]\n",
      "epoch:9 step:8785 [D loss: 0.712727, acc.: 44.53%] [G loss: 0.610643]\n",
      "epoch:9 step:8786 [D loss: 0.668663, acc.: 59.38%] [G loss: 0.767411]\n",
      "epoch:9 step:8787 [D loss: 0.674356, acc.: 52.34%] [G loss: 0.792363]\n",
      "epoch:9 step:8788 [D loss: 0.648756, acc.: 57.81%] [G loss: 0.811476]\n",
      "epoch:9 step:8789 [D loss: 0.659581, acc.: 59.38%] [G loss: 0.783654]\n",
      "epoch:9 step:8790 [D loss: 0.654902, acc.: 60.16%] [G loss: 0.791881]\n",
      "epoch:9 step:8791 [D loss: 0.671754, acc.: 64.06%] [G loss: 0.754130]\n",
      "epoch:9 step:8792 [D loss: 0.663553, acc.: 60.94%] [G loss: 0.852800]\n",
      "epoch:9 step:8793 [D loss: 0.681009, acc.: 54.69%] [G loss: 0.788538]\n",
      "epoch:9 step:8794 [D loss: 0.660990, acc.: 53.91%] [G loss: 0.800920]\n",
      "epoch:9 step:8795 [D loss: 0.684036, acc.: 54.69%] [G loss: 0.796244]\n",
      "epoch:9 step:8796 [D loss: 0.671114, acc.: 60.16%] [G loss: 0.813503]\n",
      "epoch:9 step:8797 [D loss: 0.631523, acc.: 69.53%] [G loss: 0.735795]\n",
      "epoch:9 step:8798 [D loss: 0.687365, acc.: 50.78%] [G loss: 0.742916]\n",
      "epoch:9 step:8799 [D loss: 0.540150, acc.: 75.78%] [G loss: 0.826361]\n",
      "epoch:9 step:8800 [D loss: 0.685518, acc.: 53.91%] [G loss: 0.794371]\n",
      "##############\n",
      "[4.41095118 2.23558916 6.34107176 5.79422889 3.63597483 6.12433954\n",
      " 5.04975624 4.98592059 5.47870704 4.83360876]\n",
      "##########\n",
      "epoch:9 step:8801 [D loss: 0.698398, acc.: 55.47%] [G loss: 0.765981]\n",
      "epoch:9 step:8802 [D loss: 0.728953, acc.: 44.53%] [G loss: 0.762204]\n",
      "epoch:9 step:8803 [D loss: 0.670528, acc.: 59.38%] [G loss: 0.721915]\n",
      "epoch:9 step:8804 [D loss: 0.585409, acc.: 64.84%] [G loss: 0.809683]\n",
      "epoch:9 step:8805 [D loss: 0.699480, acc.: 57.03%] [G loss: 0.666112]\n",
      "epoch:9 step:8806 [D loss: 0.726734, acc.: 46.88%] [G loss: 0.813008]\n",
      "epoch:9 step:8807 [D loss: 0.702590, acc.: 46.88%] [G loss: 0.770821]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8808 [D loss: 0.807904, acc.: 44.53%] [G loss: 0.785363]\n",
      "epoch:9 step:8809 [D loss: 0.671703, acc.: 64.06%] [G loss: 0.796630]\n",
      "epoch:9 step:8810 [D loss: 0.559542, acc.: 80.47%] [G loss: 0.782309]\n",
      "epoch:9 step:8811 [D loss: 0.555942, acc.: 82.03%] [G loss: 0.767182]\n",
      "epoch:9 step:8812 [D loss: 0.700616, acc.: 53.91%] [G loss: 0.803432]\n",
      "epoch:9 step:8813 [D loss: 0.661391, acc.: 56.25%] [G loss: 0.804472]\n",
      "epoch:9 step:8814 [D loss: 0.682141, acc.: 49.22%] [G loss: 0.803461]\n",
      "epoch:9 step:8815 [D loss: 0.687635, acc.: 57.03%] [G loss: 0.786901]\n",
      "epoch:9 step:8816 [D loss: 0.680103, acc.: 56.25%] [G loss: 0.786700]\n",
      "epoch:9 step:8817 [D loss: 0.680060, acc.: 60.94%] [G loss: 0.622936]\n",
      "epoch:9 step:8818 [D loss: 0.666425, acc.: 57.81%] [G loss: 0.752504]\n",
      "epoch:9 step:8819 [D loss: 0.657435, acc.: 58.59%] [G loss: 0.774380]\n",
      "epoch:9 step:8820 [D loss: 0.654327, acc.: 58.59%] [G loss: 0.808422]\n",
      "epoch:9 step:8821 [D loss: 0.711942, acc.: 49.22%] [G loss: 0.832718]\n",
      "epoch:9 step:8822 [D loss: 0.673073, acc.: 60.94%] [G loss: 0.733619]\n",
      "epoch:9 step:8823 [D loss: 0.677051, acc.: 60.94%] [G loss: 0.790189]\n",
      "epoch:9 step:8824 [D loss: 0.754114, acc.: 40.62%] [G loss: 0.837859]\n",
      "epoch:9 step:8825 [D loss: 0.682664, acc.: 50.78%] [G loss: 0.772783]\n",
      "epoch:9 step:8826 [D loss: 0.657073, acc.: 67.97%] [G loss: 0.789982]\n",
      "epoch:9 step:8827 [D loss: 0.757716, acc.: 39.84%] [G loss: 0.789818]\n",
      "epoch:9 step:8828 [D loss: 0.718541, acc.: 51.56%] [G loss: 0.655276]\n",
      "epoch:9 step:8829 [D loss: 0.539132, acc.: 79.69%] [G loss: 0.816474]\n",
      "epoch:9 step:8830 [D loss: 0.583729, acc.: 62.50%] [G loss: 0.824965]\n",
      "epoch:9 step:8831 [D loss: 0.436094, acc.: 92.19%] [G loss: 0.876490]\n",
      "epoch:9 step:8832 [D loss: 0.453569, acc.: 86.72%] [G loss: 0.853149]\n",
      "epoch:9 step:8833 [D loss: 0.504835, acc.: 82.81%] [G loss: 0.991180]\n",
      "epoch:9 step:8834 [D loss: 0.564407, acc.: 69.53%] [G loss: 0.860001]\n",
      "epoch:9 step:8835 [D loss: 0.410023, acc.: 86.72%] [G loss: 0.758316]\n",
      "epoch:9 step:8836 [D loss: 0.612030, acc.: 71.09%] [G loss: 0.983519]\n",
      "epoch:9 step:8837 [D loss: 0.364482, acc.: 91.41%] [G loss: 0.949361]\n",
      "epoch:9 step:8838 [D loss: 0.332787, acc.: 96.09%] [G loss: 0.859328]\n",
      "epoch:9 step:8839 [D loss: 0.400927, acc.: 79.69%] [G loss: 1.060019]\n",
      "epoch:9 step:8840 [D loss: 0.361444, acc.: 93.75%] [G loss: 1.133708]\n",
      "epoch:9 step:8841 [D loss: 0.905381, acc.: 52.34%] [G loss: 1.341548]\n",
      "epoch:9 step:8842 [D loss: 0.319442, acc.: 99.22%] [G loss: 1.360277]\n",
      "epoch:9 step:8843 [D loss: 0.711263, acc.: 57.03%] [G loss: 1.253856]\n",
      "epoch:9 step:8844 [D loss: 0.787308, acc.: 50.00%] [G loss: 1.060101]\n",
      "epoch:9 step:8845 [D loss: 0.703841, acc.: 51.56%] [G loss: 1.039657]\n",
      "epoch:9 step:8846 [D loss: 0.586673, acc.: 74.22%] [G loss: 1.070237]\n",
      "epoch:9 step:8847 [D loss: 0.343620, acc.: 96.88%] [G loss: 1.052156]\n",
      "epoch:9 step:8848 [D loss: 0.543935, acc.: 78.91%] [G loss: 0.873351]\n",
      "epoch:9 step:8849 [D loss: 0.459433, acc.: 88.28%] [G loss: 0.451174]\n",
      "epoch:9 step:8850 [D loss: 0.982284, acc.: 45.31%] [G loss: 0.747794]\n",
      "epoch:9 step:8851 [D loss: 0.689678, acc.: 58.59%] [G loss: 0.842746]\n",
      "epoch:9 step:8852 [D loss: 0.673493, acc.: 60.94%] [G loss: 0.507326]\n",
      "epoch:9 step:8853 [D loss: 0.814305, acc.: 31.25%] [G loss: 0.821664]\n",
      "epoch:9 step:8854 [D loss: 1.078511, acc.: 8.59%] [G loss: 0.718215]\n",
      "epoch:9 step:8855 [D loss: 0.892500, acc.: 28.91%] [G loss: 1.032007]\n",
      "epoch:9 step:8856 [D loss: 0.718856, acc.: 50.00%] [G loss: 1.048875]\n",
      "epoch:9 step:8857 [D loss: 0.715661, acc.: 47.66%] [G loss: 0.946084]\n",
      "epoch:9 step:8858 [D loss: 0.698824, acc.: 52.34%] [G loss: 0.905245]\n",
      "epoch:9 step:8859 [D loss: 0.707964, acc.: 50.78%] [G loss: 0.959288]\n",
      "epoch:9 step:8860 [D loss: 0.680809, acc.: 57.81%] [G loss: 0.921973]\n",
      "epoch:9 step:8861 [D loss: 0.681261, acc.: 53.12%] [G loss: 0.962373]\n",
      "epoch:9 step:8862 [D loss: 0.690957, acc.: 53.91%] [G loss: 0.845223]\n",
      "epoch:9 step:8863 [D loss: 0.686557, acc.: 57.81%] [G loss: 0.865307]\n",
      "epoch:9 step:8864 [D loss: 0.712512, acc.: 47.66%] [G loss: 0.808393]\n",
      "epoch:9 step:8865 [D loss: 0.717701, acc.: 46.09%] [G loss: 0.851715]\n",
      "epoch:9 step:8866 [D loss: 0.716112, acc.: 42.97%] [G loss: 0.902870]\n",
      "epoch:9 step:8867 [D loss: 0.676482, acc.: 53.12%] [G loss: 0.953418]\n",
      "epoch:9 step:8868 [D loss: 0.694892, acc.: 49.22%] [G loss: 0.928399]\n",
      "epoch:9 step:8869 [D loss: 0.673283, acc.: 54.69%] [G loss: 0.930828]\n",
      "epoch:9 step:8870 [D loss: 0.718361, acc.: 47.66%] [G loss: 0.906516]\n",
      "epoch:9 step:8871 [D loss: 0.720985, acc.: 52.34%] [G loss: 0.836948]\n",
      "epoch:9 step:8872 [D loss: 0.693568, acc.: 53.12%] [G loss: 0.789597]\n",
      "epoch:9 step:8873 [D loss: 0.693638, acc.: 53.91%] [G loss: 0.834229]\n",
      "epoch:9 step:8874 [D loss: 0.670058, acc.: 52.34%] [G loss: 0.898872]\n",
      "epoch:9 step:8875 [D loss: 0.689478, acc.: 57.03%] [G loss: 0.768354]\n",
      "epoch:9 step:8876 [D loss: 0.658135, acc.: 52.34%] [G loss: 0.862738]\n",
      "epoch:9 step:8877 [D loss: 0.682500, acc.: 50.78%] [G loss: 0.855513]\n",
      "epoch:9 step:8878 [D loss: 0.688157, acc.: 56.25%] [G loss: 0.873503]\n",
      "epoch:9 step:8879 [D loss: 0.695917, acc.: 51.56%] [G loss: 0.851609]\n",
      "epoch:9 step:8880 [D loss: 0.697785, acc.: 47.66%] [G loss: 0.814381]\n",
      "epoch:9 step:8881 [D loss: 0.671566, acc.: 62.50%] [G loss: 0.755449]\n",
      "epoch:9 step:8882 [D loss: 0.625992, acc.: 71.09%] [G loss: 0.818791]\n",
      "epoch:9 step:8883 [D loss: 0.614734, acc.: 71.09%] [G loss: 0.908212]\n",
      "epoch:9 step:8884 [D loss: 0.572738, acc.: 82.81%] [G loss: 0.752236]\n",
      "epoch:9 step:8885 [D loss: 0.540628, acc.: 86.72%] [G loss: 1.075232]\n",
      "epoch:9 step:8886 [D loss: 0.598974, acc.: 73.44%] [G loss: 1.161225]\n",
      "epoch:9 step:8887 [D loss: 0.600300, acc.: 70.31%] [G loss: 1.200456]\n",
      "epoch:9 step:8888 [D loss: 0.574643, acc.: 67.97%] [G loss: 0.976037]\n",
      "epoch:9 step:8889 [D loss: 0.401322, acc.: 85.16%] [G loss: 1.184207]\n",
      "epoch:9 step:8890 [D loss: 0.531538, acc.: 80.47%] [G loss: 0.850245]\n",
      "epoch:9 step:8891 [D loss: 0.705984, acc.: 57.81%] [G loss: 0.658346]\n",
      "epoch:9 step:8892 [D loss: 0.615412, acc.: 68.75%] [G loss: 1.125430]\n",
      "epoch:9 step:8893 [D loss: 0.649167, acc.: 62.50%] [G loss: 0.794145]\n",
      "epoch:9 step:8894 [D loss: 0.850229, acc.: 31.25%] [G loss: 0.690933]\n",
      "epoch:9 step:8895 [D loss: 0.979287, acc.: 15.62%] [G loss: 0.664538]\n",
      "epoch:9 step:8896 [D loss: 0.802993, acc.: 36.72%] [G loss: 0.721315]\n",
      "epoch:9 step:8897 [D loss: 0.661765, acc.: 63.28%] [G loss: 0.849962]\n",
      "epoch:9 step:8898 [D loss: 0.730724, acc.: 49.22%] [G loss: 0.617091]\n",
      "epoch:9 step:8899 [D loss: 0.672651, acc.: 54.69%] [G loss: 0.575154]\n",
      "epoch:9 step:8900 [D loss: 0.574679, acc.: 78.12%] [G loss: 0.810292]\n",
      "epoch:9 step:8901 [D loss: 0.576719, acc.: 78.12%] [G loss: 0.958857]\n",
      "epoch:9 step:8902 [D loss: 0.646551, acc.: 67.19%] [G loss: 0.819283]\n",
      "epoch:9 step:8903 [D loss: 0.557098, acc.: 77.34%] [G loss: 0.877220]\n",
      "epoch:9 step:8904 [D loss: 0.566801, acc.: 83.59%] [G loss: 0.693064]\n",
      "epoch:9 step:8905 [D loss: 0.633978, acc.: 64.06%] [G loss: 0.751971]\n",
      "epoch:9 step:8906 [D loss: 0.852549, acc.: 28.91%] [G loss: 0.672467]\n",
      "epoch:9 step:8907 [D loss: 0.811927, acc.: 27.34%] [G loss: 0.617540]\n",
      "epoch:9 step:8908 [D loss: 0.697855, acc.: 51.56%] [G loss: 0.798612]\n",
      "epoch:9 step:8909 [D loss: 0.755115, acc.: 42.19%] [G loss: 0.702131]\n",
      "epoch:9 step:8910 [D loss: 0.720134, acc.: 47.66%] [G loss: 0.743555]\n",
      "epoch:9 step:8911 [D loss: 0.761158, acc.: 46.09%] [G loss: 0.771604]\n",
      "epoch:9 step:8912 [D loss: 0.744386, acc.: 42.97%] [G loss: 0.854926]\n",
      "epoch:9 step:8913 [D loss: 0.646923, acc.: 59.38%] [G loss: 0.651273]\n",
      "epoch:9 step:8914 [D loss: 0.649616, acc.: 60.16%] [G loss: 0.765197]\n",
      "epoch:9 step:8915 [D loss: 0.736730, acc.: 40.62%] [G loss: 0.284352]\n",
      "epoch:9 step:8916 [D loss: 0.702471, acc.: 54.69%] [G loss: 0.798700]\n",
      "epoch:9 step:8917 [D loss: 0.678855, acc.: 53.91%] [G loss: 0.800185]\n",
      "epoch:9 step:8918 [D loss: 0.667859, acc.: 62.50%] [G loss: 0.766407]\n",
      "epoch:9 step:8919 [D loss: 0.710163, acc.: 46.09%] [G loss: 0.814858]\n",
      "epoch:9 step:8920 [D loss: 0.656370, acc.: 63.28%] [G loss: 0.799864]\n",
      "epoch:9 step:8921 [D loss: 0.677505, acc.: 56.25%] [G loss: 0.795390]\n",
      "epoch:9 step:8922 [D loss: 0.719045, acc.: 47.66%] [G loss: 0.778918]\n",
      "epoch:9 step:8923 [D loss: 0.696293, acc.: 52.34%] [G loss: 0.755402]\n",
      "epoch:9 step:8924 [D loss: 0.681456, acc.: 60.16%] [G loss: 0.747743]\n",
      "epoch:9 step:8925 [D loss: 0.706793, acc.: 45.31%] [G loss: 0.761796]\n",
      "epoch:9 step:8926 [D loss: 0.688616, acc.: 52.34%] [G loss: 0.759952]\n",
      "epoch:9 step:8927 [D loss: 0.688859, acc.: 57.03%] [G loss: 0.695279]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8928 [D loss: 0.701825, acc.: 51.56%] [G loss: 0.805177]\n",
      "epoch:9 step:8929 [D loss: 0.678381, acc.: 53.12%] [G loss: 0.794584]\n",
      "epoch:9 step:8930 [D loss: 0.616365, acc.: 71.88%] [G loss: 0.779040]\n",
      "epoch:9 step:8931 [D loss: 0.565934, acc.: 80.47%] [G loss: 0.752493]\n",
      "epoch:9 step:8932 [D loss: 0.546519, acc.: 81.25%] [G loss: 0.898292]\n",
      "epoch:9 step:8933 [D loss: 0.676283, acc.: 64.06%] [G loss: 0.946591]\n",
      "epoch:9 step:8934 [D loss: 0.796795, acc.: 40.62%] [G loss: 0.753379]\n",
      "epoch:9 step:8935 [D loss: 0.730496, acc.: 46.09%] [G loss: 0.841023]\n",
      "epoch:9 step:8936 [D loss: 0.730273, acc.: 56.25%] [G loss: 0.829955]\n",
      "epoch:9 step:8937 [D loss: 0.677766, acc.: 55.47%] [G loss: 0.814036]\n",
      "epoch:9 step:8938 [D loss: 0.658577, acc.: 57.03%] [G loss: 0.793961]\n",
      "epoch:9 step:8939 [D loss: 0.667798, acc.: 55.47%] [G loss: 0.831086]\n",
      "epoch:9 step:8940 [D loss: 0.643224, acc.: 62.50%] [G loss: 0.796422]\n",
      "epoch:9 step:8941 [D loss: 0.614287, acc.: 72.66%] [G loss: 0.806539]\n",
      "epoch:9 step:8942 [D loss: 0.712851, acc.: 60.94%] [G loss: 0.854719]\n",
      "epoch:9 step:8943 [D loss: 0.716426, acc.: 53.91%] [G loss: 0.793194]\n",
      "epoch:9 step:8944 [D loss: 0.680526, acc.: 63.28%] [G loss: 0.773649]\n",
      "epoch:9 step:8945 [D loss: 0.629201, acc.: 66.41%] [G loss: 0.832288]\n",
      "epoch:9 step:8946 [D loss: 0.577183, acc.: 75.78%] [G loss: 0.803019]\n",
      "epoch:9 step:8947 [D loss: 0.620718, acc.: 66.41%] [G loss: 0.747734]\n",
      "epoch:9 step:8948 [D loss: 0.593686, acc.: 78.12%] [G loss: 0.851537]\n",
      "epoch:9 step:8949 [D loss: 0.711094, acc.: 53.12%] [G loss: 1.045403]\n",
      "epoch:9 step:8950 [D loss: 0.722217, acc.: 45.31%] [G loss: 0.910324]\n",
      "epoch:9 step:8951 [D loss: 0.720251, acc.: 46.88%] [G loss: 0.818509]\n",
      "epoch:9 step:8952 [D loss: 0.677557, acc.: 60.16%] [G loss: 0.825379]\n",
      "epoch:9 step:8953 [D loss: 0.669124, acc.: 55.47%] [G loss: 0.863682]\n",
      "epoch:9 step:8954 [D loss: 0.663489, acc.: 59.38%] [G loss: 0.825713]\n",
      "epoch:9 step:8955 [D loss: 0.659492, acc.: 59.38%] [G loss: 0.830242]\n",
      "epoch:9 step:8956 [D loss: 0.722048, acc.: 46.09%] [G loss: 0.808115]\n",
      "epoch:9 step:8957 [D loss: 0.563333, acc.: 77.34%] [G loss: 0.843331]\n",
      "epoch:9 step:8958 [D loss: 0.685787, acc.: 51.56%] [G loss: 0.825869]\n",
      "epoch:9 step:8959 [D loss: 0.626823, acc.: 67.19%] [G loss: 0.882078]\n",
      "epoch:9 step:8960 [D loss: 0.632091, acc.: 60.16%] [G loss: 0.778429]\n",
      "epoch:9 step:8961 [D loss: 0.728662, acc.: 43.75%] [G loss: 0.965988]\n",
      "epoch:9 step:8962 [D loss: 0.726303, acc.: 47.66%] [G loss: 0.781107]\n",
      "epoch:9 step:8963 [D loss: 0.690223, acc.: 52.34%] [G loss: 0.791760]\n",
      "epoch:9 step:8964 [D loss: 0.743691, acc.: 36.72%] [G loss: 0.529285]\n",
      "epoch:9 step:8965 [D loss: 0.806670, acc.: 31.25%] [G loss: 0.780791]\n",
      "epoch:9 step:8966 [D loss: 0.741021, acc.: 35.16%] [G loss: 0.731090]\n",
      "epoch:9 step:8967 [D loss: 0.719548, acc.: 45.31%] [G loss: 0.775081]\n",
      "epoch:9 step:8968 [D loss: 0.678169, acc.: 53.91%] [G loss: 0.766787]\n",
      "epoch:9 step:8969 [D loss: 0.622522, acc.: 76.56%] [G loss: 0.771821]\n",
      "epoch:9 step:8970 [D loss: 0.655732, acc.: 67.97%] [G loss: 0.723002]\n",
      "epoch:9 step:8971 [D loss: 0.618813, acc.: 78.12%] [G loss: 0.781669]\n",
      "epoch:9 step:8972 [D loss: 0.718512, acc.: 50.00%] [G loss: 0.856060]\n",
      "epoch:9 step:8973 [D loss: 0.621183, acc.: 70.31%] [G loss: 0.876109]\n",
      "epoch:9 step:8974 [D loss: 0.648618, acc.: 63.28%] [G loss: 0.797905]\n",
      "epoch:9 step:8975 [D loss: 0.679965, acc.: 55.47%] [G loss: 0.844541]\n",
      "epoch:9 step:8976 [D loss: 0.574349, acc.: 66.41%] [G loss: 0.750479]\n",
      "epoch:9 step:8977 [D loss: 0.684657, acc.: 59.38%] [G loss: 0.827040]\n",
      "epoch:9 step:8978 [D loss: 0.730536, acc.: 41.41%] [G loss: 0.823332]\n",
      "epoch:9 step:8979 [D loss: 0.642850, acc.: 64.84%] [G loss: 0.847247]\n",
      "epoch:9 step:8980 [D loss: 0.664170, acc.: 60.16%] [G loss: 0.786795]\n",
      "epoch:9 step:8981 [D loss: 0.704744, acc.: 49.22%] [G loss: 0.751737]\n",
      "epoch:9 step:8982 [D loss: 0.616461, acc.: 65.62%] [G loss: 0.817725]\n",
      "epoch:9 step:8983 [D loss: 0.485381, acc.: 81.25%] [G loss: 0.840422]\n",
      "epoch:9 step:8984 [D loss: 0.664057, acc.: 56.25%] [G loss: 0.870950]\n",
      "epoch:9 step:8985 [D loss: 0.642579, acc.: 61.72%] [G loss: 0.791771]\n",
      "epoch:9 step:8986 [D loss: 0.702365, acc.: 53.12%] [G loss: 0.815592]\n",
      "epoch:9 step:8987 [D loss: 0.577738, acc.: 75.00%] [G loss: 0.883327]\n",
      "epoch:9 step:8988 [D loss: 0.622736, acc.: 66.41%] [G loss: 0.859303]\n",
      "epoch:9 step:8989 [D loss: 0.652959, acc.: 61.72%] [G loss: 0.873631]\n",
      "epoch:9 step:8990 [D loss: 0.639914, acc.: 59.38%] [G loss: 0.845369]\n",
      "epoch:9 step:8991 [D loss: 0.636694, acc.: 59.38%] [G loss: 0.793400]\n",
      "epoch:9 step:8992 [D loss: 0.742692, acc.: 46.88%] [G loss: 0.838253]\n",
      "epoch:9 step:8993 [D loss: 0.751871, acc.: 44.53%] [G loss: 0.816260]\n",
      "epoch:9 step:8994 [D loss: 0.673139, acc.: 60.94%] [G loss: 0.751037]\n",
      "epoch:9 step:8995 [D loss: 0.663941, acc.: 57.81%] [G loss: 0.811110]\n",
      "epoch:9 step:8996 [D loss: 0.670043, acc.: 53.91%] [G loss: 0.646543]\n",
      "epoch:9 step:8997 [D loss: 0.589844, acc.: 76.56%] [G loss: 0.852079]\n",
      "epoch:9 step:8998 [D loss: 0.697558, acc.: 56.25%] [G loss: 0.787927]\n",
      "epoch:9 step:8999 [D loss: 0.626007, acc.: 69.53%] [G loss: 0.836669]\n",
      "epoch:9 step:9000 [D loss: 0.568715, acc.: 75.00%] [G loss: 0.825302]\n",
      "##############\n",
      "[3.85527618 2.12865511 5.96445529 5.8325104  4.34815937 6.24009067\n",
      " 5.1271512  5.84687807 5.91817423 5.03499983]\n",
      "##########\n",
      "epoch:9 step:9001 [D loss: 0.640168, acc.: 64.84%] [G loss: 0.773034]\n",
      "epoch:9 step:9002 [D loss: 0.702686, acc.: 49.22%] [G loss: 0.850755]\n",
      "epoch:9 step:9003 [D loss: 0.626879, acc.: 64.84%] [G loss: 0.802837]\n",
      "epoch:9 step:9004 [D loss: 0.771797, acc.: 44.53%] [G loss: 0.832555]\n",
      "epoch:9 step:9005 [D loss: 0.727618, acc.: 48.44%] [G loss: 0.781040]\n",
      "epoch:9 step:9006 [D loss: 0.671453, acc.: 53.91%] [G loss: 0.946372]\n",
      "epoch:9 step:9007 [D loss: 0.665639, acc.: 60.94%] [G loss: 0.841666]\n",
      "epoch:9 step:9008 [D loss: 0.590355, acc.: 78.12%] [G loss: 0.897491]\n",
      "epoch:9 step:9009 [D loss: 0.641871, acc.: 59.38%] [G loss: 0.985175]\n",
      "epoch:9 step:9010 [D loss: 0.688415, acc.: 57.03%] [G loss: 0.893838]\n",
      "epoch:9 step:9011 [D loss: 0.614274, acc.: 67.97%] [G loss: 0.862405]\n",
      "epoch:9 step:9012 [D loss: 0.672279, acc.: 60.94%] [G loss: 0.786375]\n",
      "epoch:9 step:9013 [D loss: 0.690562, acc.: 54.69%] [G loss: 0.851365]\n",
      "epoch:9 step:9014 [D loss: 0.677554, acc.: 61.72%] [G loss: 0.791002]\n",
      "epoch:9 step:9015 [D loss: 0.673232, acc.: 50.78%] [G loss: 0.796267]\n",
      "epoch:9 step:9016 [D loss: 0.761146, acc.: 47.66%] [G loss: 0.832854]\n",
      "epoch:9 step:9017 [D loss: 0.755564, acc.: 39.84%] [G loss: 0.760067]\n",
      "epoch:9 step:9018 [D loss: 0.742222, acc.: 53.12%] [G loss: 0.784642]\n",
      "epoch:9 step:9019 [D loss: 0.698189, acc.: 50.00%] [G loss: 0.762823]\n",
      "epoch:9 step:9020 [D loss: 0.661675, acc.: 60.16%] [G loss: 0.804553]\n",
      "epoch:9 step:9021 [D loss: 0.604365, acc.: 72.66%] [G loss: 0.763985]\n",
      "epoch:9 step:9022 [D loss: 0.529718, acc.: 76.56%] [G loss: 0.860650]\n",
      "epoch:9 step:9023 [D loss: 0.710260, acc.: 49.22%] [G loss: 0.771724]\n",
      "epoch:9 step:9024 [D loss: 0.679892, acc.: 57.03%] [G loss: 0.849313]\n",
      "epoch:9 step:9025 [D loss: 0.664922, acc.: 57.03%] [G loss: 0.852845]\n",
      "epoch:9 step:9026 [D loss: 0.675828, acc.: 55.47%] [G loss: 0.873137]\n",
      "epoch:9 step:9027 [D loss: 0.725708, acc.: 42.97%] [G loss: 0.781205]\n",
      "epoch:9 step:9028 [D loss: 0.564821, acc.: 81.25%] [G loss: 0.887736]\n",
      "epoch:9 step:9029 [D loss: 0.559850, acc.: 72.66%] [G loss: 0.831495]\n",
      "epoch:9 step:9030 [D loss: 0.690107, acc.: 53.91%] [G loss: 0.868464]\n",
      "epoch:9 step:9031 [D loss: 0.633709, acc.: 65.62%] [G loss: 0.850574]\n",
      "epoch:9 step:9032 [D loss: 0.631801, acc.: 62.50%] [G loss: 0.848126]\n",
      "epoch:9 step:9033 [D loss: 0.571152, acc.: 65.62%] [G loss: 0.965546]\n",
      "epoch:9 step:9034 [D loss: 0.511529, acc.: 78.91%] [G loss: 0.900451]\n",
      "epoch:9 step:9035 [D loss: 0.554886, acc.: 75.00%] [G loss: 0.717164]\n",
      "epoch:9 step:9036 [D loss: 0.731665, acc.: 42.97%] [G loss: 0.815109]\n",
      "epoch:9 step:9037 [D loss: 0.646482, acc.: 53.91%] [G loss: 0.813740]\n",
      "epoch:9 step:9038 [D loss: 0.710223, acc.: 46.09%] [G loss: 0.825152]\n",
      "epoch:9 step:9039 [D loss: 0.868258, acc.: 25.00%] [G loss: 0.790121]\n",
      "epoch:9 step:9040 [D loss: 0.758317, acc.: 43.75%] [G loss: 0.763847]\n",
      "epoch:9 step:9041 [D loss: 0.677674, acc.: 59.38%] [G loss: 0.816733]\n",
      "epoch:9 step:9042 [D loss: 0.555765, acc.: 87.50%] [G loss: 0.774554]\n",
      "epoch:9 step:9043 [D loss: 0.682035, acc.: 59.38%] [G loss: 0.810499]\n",
      "epoch:9 step:9044 [D loss: 0.648590, acc.: 67.97%] [G loss: 0.845423]\n",
      "epoch:9 step:9045 [D loss: 0.707736, acc.: 59.38%] [G loss: 0.868928]\n",
      "epoch:9 step:9046 [D loss: 0.671615, acc.: 57.03%] [G loss: 0.899680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9047 [D loss: 0.708037, acc.: 52.34%] [G loss: 0.891419]\n",
      "epoch:9 step:9048 [D loss: 0.710615, acc.: 50.78%] [G loss: 0.801352]\n",
      "epoch:9 step:9049 [D loss: 0.787833, acc.: 32.81%] [G loss: 0.834773]\n",
      "epoch:9 step:9050 [D loss: 0.670605, acc.: 57.03%] [G loss: 0.938950]\n",
      "epoch:9 step:9051 [D loss: 0.637831, acc.: 65.62%] [G loss: 0.887685]\n",
      "epoch:9 step:9052 [D loss: 0.634271, acc.: 67.19%] [G loss: 0.886181]\n",
      "epoch:9 step:9053 [D loss: 0.698477, acc.: 52.34%] [G loss: 0.817082]\n",
      "epoch:9 step:9054 [D loss: 0.724454, acc.: 47.66%] [G loss: 0.770282]\n",
      "epoch:9 step:9055 [D loss: 0.730685, acc.: 55.47%] [G loss: 0.820568]\n",
      "epoch:9 step:9056 [D loss: 0.693648, acc.: 53.12%] [G loss: 0.863015]\n",
      "epoch:9 step:9057 [D loss: 0.701950, acc.: 53.91%] [G loss: 0.736976]\n",
      "epoch:9 step:9058 [D loss: 0.674956, acc.: 53.91%] [G loss: 0.803186]\n",
      "epoch:9 step:9059 [D loss: 0.761176, acc.: 42.97%] [G loss: 0.730577]\n",
      "epoch:9 step:9060 [D loss: 0.640744, acc.: 71.88%] [G loss: 0.803666]\n",
      "epoch:9 step:9061 [D loss: 0.694165, acc.: 51.56%] [G loss: 0.819642]\n",
      "epoch:9 step:9062 [D loss: 0.656311, acc.: 60.94%] [G loss: 0.788220]\n",
      "epoch:9 step:9063 [D loss: 0.752607, acc.: 35.94%] [G loss: 0.764647]\n",
      "epoch:9 step:9064 [D loss: 0.684703, acc.: 53.12%] [G loss: 0.741821]\n",
      "epoch:9 step:9065 [D loss: 0.652290, acc.: 54.69%] [G loss: 0.781483]\n",
      "epoch:9 step:9066 [D loss: 0.614424, acc.: 60.94%] [G loss: 0.839682]\n",
      "epoch:9 step:9067 [D loss: 0.601781, acc.: 71.88%] [G loss: 0.868113]\n",
      "epoch:9 step:9068 [D loss: 0.607265, acc.: 64.84%] [G loss: 0.780668]\n",
      "epoch:9 step:9069 [D loss: 0.675244, acc.: 57.03%] [G loss: 0.877989]\n",
      "epoch:9 step:9070 [D loss: 0.687418, acc.: 51.56%] [G loss: 0.744480]\n",
      "epoch:9 step:9071 [D loss: 0.679238, acc.: 59.38%] [G loss: 0.785621]\n",
      "epoch:9 step:9072 [D loss: 0.755004, acc.: 42.97%] [G loss: 0.769844]\n",
      "epoch:9 step:9073 [D loss: 0.740887, acc.: 35.94%] [G loss: 0.842793]\n",
      "epoch:9 step:9074 [D loss: 0.645594, acc.: 67.19%] [G loss: 0.801272]\n",
      "epoch:9 step:9075 [D loss: 0.710965, acc.: 43.75%] [G loss: 0.854207]\n",
      "epoch:9 step:9076 [D loss: 0.689587, acc.: 49.22%] [G loss: 0.866612]\n",
      "epoch:9 step:9077 [D loss: 0.558271, acc.: 78.91%] [G loss: 0.907546]\n",
      "epoch:9 step:9078 [D loss: 0.611264, acc.: 75.00%] [G loss: 0.726238]\n",
      "epoch:9 step:9079 [D loss: 0.604676, acc.: 68.75%] [G loss: 0.773557]\n",
      "epoch:9 step:9080 [D loss: 0.788406, acc.: 42.97%] [G loss: 0.795269]\n",
      "epoch:9 step:9081 [D loss: 0.592979, acc.: 73.44%] [G loss: 0.835442]\n",
      "epoch:9 step:9082 [D loss: 0.641420, acc.: 64.84%] [G loss: 0.816109]\n",
      "epoch:9 step:9083 [D loss: 0.616510, acc.: 73.44%] [G loss: 0.909314]\n",
      "epoch:9 step:9084 [D loss: 0.641304, acc.: 64.06%] [G loss: 0.986368]\n",
      "epoch:9 step:9085 [D loss: 0.670602, acc.: 60.94%] [G loss: 0.769946]\n",
      "epoch:9 step:9086 [D loss: 0.690150, acc.: 53.91%] [G loss: 0.782802]\n",
      "epoch:9 step:9087 [D loss: 0.765916, acc.: 39.84%] [G loss: 0.594568]\n",
      "epoch:9 step:9088 [D loss: 0.686418, acc.: 52.34%] [G loss: 0.781357]\n",
      "epoch:9 step:9089 [D loss: 0.671827, acc.: 59.38%] [G loss: 0.721158]\n",
      "epoch:9 step:9090 [D loss: 0.706683, acc.: 50.00%] [G loss: 0.777830]\n",
      "epoch:9 step:9091 [D loss: 0.635116, acc.: 64.06%] [G loss: 0.680412]\n",
      "epoch:9 step:9092 [D loss: 0.661083, acc.: 60.16%] [G loss: 0.846164]\n",
      "epoch:9 step:9093 [D loss: 0.602237, acc.: 67.19%] [G loss: 0.849920]\n",
      "epoch:9 step:9094 [D loss: 0.605407, acc.: 69.53%] [G loss: 0.942347]\n",
      "epoch:9 step:9095 [D loss: 0.727459, acc.: 46.09%] [G loss: 0.916916]\n",
      "epoch:9 step:9096 [D loss: 0.695646, acc.: 55.47%] [G loss: 0.887965]\n",
      "epoch:9 step:9097 [D loss: 0.567792, acc.: 69.53%] [G loss: 0.969284]\n",
      "epoch:9 step:9098 [D loss: 0.524353, acc.: 73.44%] [G loss: 0.903306]\n",
      "epoch:9 step:9099 [D loss: 0.634762, acc.: 67.19%] [G loss: 0.964078]\n",
      "epoch:9 step:9100 [D loss: 0.657254, acc.: 60.16%] [G loss: 1.123024]\n",
      "epoch:9 step:9101 [D loss: 0.678080, acc.: 57.81%] [G loss: 0.863277]\n",
      "epoch:9 step:9102 [D loss: 0.733056, acc.: 44.53%] [G loss: 0.937485]\n",
      "epoch:9 step:9103 [D loss: 0.776140, acc.: 40.62%] [G loss: 0.730962]\n",
      "epoch:9 step:9104 [D loss: 0.701377, acc.: 50.78%] [G loss: 0.760010]\n",
      "epoch:9 step:9105 [D loss: 0.708153, acc.: 55.47%] [G loss: 0.729124]\n",
      "epoch:9 step:9106 [D loss: 0.664957, acc.: 60.16%] [G loss: 0.785511]\n",
      "epoch:9 step:9107 [D loss: 0.805836, acc.: 52.34%] [G loss: 0.762603]\n",
      "epoch:9 step:9108 [D loss: 0.727841, acc.: 47.66%] [G loss: 0.952707]\n",
      "epoch:9 step:9109 [D loss: 0.673053, acc.: 59.38%] [G loss: 0.933510]\n",
      "epoch:9 step:9110 [D loss: 0.702058, acc.: 50.00%] [G loss: 0.826030]\n",
      "epoch:9 step:9111 [D loss: 0.708608, acc.: 48.44%] [G loss: 0.894153]\n",
      "epoch:9 step:9112 [D loss: 0.680217, acc.: 50.00%] [G loss: 0.874416]\n",
      "epoch:9 step:9113 [D loss: 0.699510, acc.: 52.34%] [G loss: 0.799814]\n",
      "epoch:9 step:9114 [D loss: 0.702058, acc.: 42.19%] [G loss: 0.848678]\n",
      "epoch:9 step:9115 [D loss: 0.762322, acc.: 45.31%] [G loss: 0.799214]\n",
      "epoch:9 step:9116 [D loss: 0.648107, acc.: 65.62%] [G loss: 0.701476]\n",
      "epoch:9 step:9117 [D loss: 0.604215, acc.: 79.69%] [G loss: 0.765139]\n",
      "epoch:9 step:9118 [D loss: 0.656884, acc.: 62.50%] [G loss: 0.643527]\n",
      "epoch:9 step:9119 [D loss: 0.599442, acc.: 65.62%] [G loss: 0.784960]\n",
      "epoch:9 step:9120 [D loss: 0.649113, acc.: 66.41%] [G loss: 0.760128]\n",
      "epoch:9 step:9121 [D loss: 0.660917, acc.: 64.06%] [G loss: 0.576756]\n",
      "epoch:9 step:9122 [D loss: 0.698143, acc.: 50.00%] [G loss: 0.557117]\n",
      "epoch:9 step:9123 [D loss: 0.690197, acc.: 53.12%] [G loss: 0.827501]\n",
      "epoch:9 step:9124 [D loss: 0.879245, acc.: 31.25%] [G loss: 0.591454]\n",
      "epoch:9 step:9125 [D loss: 0.742429, acc.: 46.88%] [G loss: 0.736145]\n",
      "epoch:9 step:9126 [D loss: 0.650089, acc.: 60.16%] [G loss: 0.794109]\n",
      "epoch:9 step:9127 [D loss: 0.622431, acc.: 67.19%] [G loss: 0.859599]\n",
      "epoch:9 step:9128 [D loss: 0.681537, acc.: 53.91%] [G loss: 1.001837]\n",
      "epoch:9 step:9129 [D loss: 0.672356, acc.: 60.94%] [G loss: 0.896012]\n",
      "epoch:9 step:9130 [D loss: 0.601351, acc.: 70.31%] [G loss: 0.919221]\n",
      "epoch:9 step:9131 [D loss: 0.560807, acc.: 74.22%] [G loss: 0.944174]\n",
      "epoch:9 step:9132 [D loss: 0.726590, acc.: 44.53%] [G loss: 0.887688]\n",
      "epoch:9 step:9133 [D loss: 0.574609, acc.: 76.56%] [G loss: 0.883627]\n",
      "epoch:9 step:9134 [D loss: 0.671851, acc.: 57.03%] [G loss: 0.775302]\n",
      "epoch:9 step:9135 [D loss: 0.673730, acc.: 60.16%] [G loss: 0.901606]\n",
      "epoch:9 step:9136 [D loss: 0.714750, acc.: 53.91%] [G loss: 0.854001]\n",
      "epoch:9 step:9137 [D loss: 0.702971, acc.: 48.44%] [G loss: 0.812215]\n",
      "epoch:9 step:9138 [D loss: 0.758564, acc.: 40.62%] [G loss: 0.777167]\n",
      "epoch:9 step:9139 [D loss: 0.699427, acc.: 54.69%] [G loss: 0.759860]\n",
      "epoch:9 step:9140 [D loss: 0.595406, acc.: 77.34%] [G loss: 0.857227]\n",
      "epoch:9 step:9141 [D loss: 0.607483, acc.: 62.50%] [G loss: 0.789676]\n",
      "epoch:9 step:9142 [D loss: 0.621063, acc.: 71.09%] [G loss: 0.816157]\n",
      "epoch:9 step:9143 [D loss: 0.771721, acc.: 40.62%] [G loss: 0.746057]\n",
      "epoch:9 step:9144 [D loss: 0.730034, acc.: 43.75%] [G loss: 0.944995]\n",
      "epoch:9 step:9145 [D loss: 0.686161, acc.: 57.81%] [G loss: 0.966521]\n",
      "epoch:9 step:9146 [D loss: 0.714644, acc.: 51.56%] [G loss: 0.884477]\n",
      "epoch:9 step:9147 [D loss: 0.612881, acc.: 69.53%] [G loss: 0.879446]\n",
      "epoch:9 step:9148 [D loss: 0.761110, acc.: 42.97%] [G loss: 0.837316]\n",
      "epoch:9 step:9149 [D loss: 0.648224, acc.: 64.06%] [G loss: 0.904806]\n",
      "epoch:9 step:9150 [D loss: 0.649007, acc.: 58.59%] [G loss: 0.790318]\n",
      "epoch:9 step:9151 [D loss: 0.625837, acc.: 63.28%] [G loss: 0.972480]\n",
      "epoch:9 step:9152 [D loss: 0.598686, acc.: 67.97%] [G loss: 0.924045]\n",
      "epoch:9 step:9153 [D loss: 0.573990, acc.: 69.53%] [G loss: 0.997200]\n",
      "epoch:9 step:9154 [D loss: 0.550388, acc.: 74.22%] [G loss: 1.068238]\n",
      "epoch:9 step:9155 [D loss: 0.781704, acc.: 46.88%] [G loss: 1.021701]\n",
      "epoch:9 step:9156 [D loss: 0.684686, acc.: 54.69%] [G loss: 1.027489]\n",
      "epoch:9 step:9157 [D loss: 0.517256, acc.: 84.38%] [G loss: 0.966092]\n",
      "epoch:9 step:9158 [D loss: 0.592795, acc.: 74.22%] [G loss: 0.990793]\n",
      "epoch:9 step:9159 [D loss: 0.562778, acc.: 73.44%] [G loss: 1.121824]\n",
      "epoch:9 step:9160 [D loss: 0.795174, acc.: 51.56%] [G loss: 0.850502]\n",
      "epoch:9 step:9161 [D loss: 0.883802, acc.: 33.59%] [G loss: 0.781124]\n",
      "epoch:9 step:9162 [D loss: 0.733480, acc.: 39.84%] [G loss: 0.801316]\n",
      "epoch:9 step:9163 [D loss: 0.695603, acc.: 50.00%] [G loss: 0.879846]\n",
      "epoch:9 step:9164 [D loss: 0.731158, acc.: 40.62%] [G loss: 0.903075]\n",
      "epoch:9 step:9165 [D loss: 0.689044, acc.: 56.25%] [G loss: 0.771846]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9166 [D loss: 0.684563, acc.: 55.47%] [G loss: 0.774995]\n",
      "epoch:9 step:9167 [D loss: 0.693795, acc.: 51.56%] [G loss: 0.825382]\n",
      "epoch:9 step:9168 [D loss: 0.655834, acc.: 59.38%] [G loss: 0.881318]\n",
      "epoch:9 step:9169 [D loss: 0.653165, acc.: 65.62%] [G loss: 0.880721]\n",
      "epoch:9 step:9170 [D loss: 0.642584, acc.: 66.41%] [G loss: 0.763147]\n",
      "epoch:9 step:9171 [D loss: 0.661712, acc.: 53.91%] [G loss: 0.934221]\n",
      "epoch:9 step:9172 [D loss: 0.718949, acc.: 50.78%] [G loss: 0.671565]\n",
      "epoch:9 step:9173 [D loss: 0.676305, acc.: 56.25%] [G loss: 0.696593]\n",
      "epoch:9 step:9174 [D loss: 0.596566, acc.: 73.44%] [G loss: 0.800322]\n",
      "epoch:9 step:9175 [D loss: 0.594370, acc.: 75.00%] [G loss: 0.834034]\n",
      "epoch:9 step:9176 [D loss: 0.567387, acc.: 76.56%] [G loss: 0.799341]\n",
      "epoch:9 step:9177 [D loss: 0.729412, acc.: 46.88%] [G loss: 0.807018]\n",
      "epoch:9 step:9178 [D loss: 0.733901, acc.: 46.09%] [G loss: 0.679006]\n",
      "epoch:9 step:9179 [D loss: 0.689522, acc.: 53.91%] [G loss: 0.860477]\n",
      "epoch:9 step:9180 [D loss: 0.739479, acc.: 44.53%] [G loss: 0.783738]\n",
      "epoch:9 step:9181 [D loss: 0.644757, acc.: 66.41%] [G loss: 0.778030]\n",
      "epoch:9 step:9182 [D loss: 0.643172, acc.: 67.19%] [G loss: 0.893183]\n",
      "epoch:9 step:9183 [D loss: 0.629252, acc.: 67.19%] [G loss: 0.745364]\n",
      "epoch:9 step:9184 [D loss: 0.695415, acc.: 54.69%] [G loss: 0.696207]\n",
      "epoch:9 step:9185 [D loss: 0.735201, acc.: 46.88%] [G loss: 0.685867]\n",
      "epoch:9 step:9186 [D loss: 0.675745, acc.: 55.47%] [G loss: 0.803814]\n",
      "epoch:9 step:9187 [D loss: 0.658217, acc.: 57.81%] [G loss: 0.764825]\n",
      "epoch:9 step:9188 [D loss: 0.689191, acc.: 53.91%] [G loss: 0.784879]\n",
      "epoch:9 step:9189 [D loss: 0.652254, acc.: 63.28%] [G loss: 0.815622]\n",
      "epoch:9 step:9190 [D loss: 0.681965, acc.: 56.25%] [G loss: 0.809769]\n",
      "epoch:9 step:9191 [D loss: 0.705228, acc.: 55.47%] [G loss: 0.784111]\n",
      "epoch:9 step:9192 [D loss: 0.692927, acc.: 50.78%] [G loss: 0.763829]\n",
      "epoch:9 step:9193 [D loss: 0.693981, acc.: 52.34%] [G loss: 0.775853]\n",
      "epoch:9 step:9194 [D loss: 0.659261, acc.: 55.47%] [G loss: 0.790340]\n",
      "epoch:9 step:9195 [D loss: 0.687711, acc.: 53.91%] [G loss: 0.756408]\n",
      "epoch:9 step:9196 [D loss: 0.687976, acc.: 57.81%] [G loss: 0.741661]\n",
      "epoch:9 step:9197 [D loss: 0.619370, acc.: 68.75%] [G loss: 0.778987]\n",
      "epoch:9 step:9198 [D loss: 0.714939, acc.: 46.88%] [G loss: 0.734832]\n",
      "epoch:9 step:9199 [D loss: 0.714708, acc.: 45.31%] [G loss: 0.877726]\n",
      "epoch:9 step:9200 [D loss: 0.672056, acc.: 53.91%] [G loss: 0.768811]\n",
      "##############\n",
      "[4.24931209 2.34419444 6.81546957 5.4100451  4.18786498 6.42308114\n",
      " 5.36233629 5.28258261 6.22318199 5.19760422]\n",
      "##########\n",
      "epoch:9 step:9201 [D loss: 0.653678, acc.: 61.72%] [G loss: 0.760836]\n",
      "epoch:9 step:9202 [D loss: 0.658108, acc.: 57.81%] [G loss: 0.773987]\n",
      "epoch:9 step:9203 [D loss: 0.641012, acc.: 63.28%] [G loss: 0.771287]\n",
      "epoch:9 step:9204 [D loss: 0.746368, acc.: 39.06%] [G loss: 0.772674]\n",
      "epoch:9 step:9205 [D loss: 0.669164, acc.: 57.81%] [G loss: 0.765395]\n",
      "epoch:9 step:9206 [D loss: 0.690438, acc.: 53.91%] [G loss: 0.776338]\n",
      "epoch:9 step:9207 [D loss: 0.599602, acc.: 70.31%] [G loss: 0.778790]\n",
      "epoch:9 step:9208 [D loss: 0.607922, acc.: 71.09%] [G loss: 0.763452]\n",
      "epoch:9 step:9209 [D loss: 0.698672, acc.: 56.25%] [G loss: 0.767886]\n",
      "epoch:9 step:9210 [D loss: 0.727484, acc.: 50.78%] [G loss: 0.747273]\n",
      "epoch:9 step:9211 [D loss: 0.729367, acc.: 43.75%] [G loss: 0.707888]\n",
      "epoch:9 step:9212 [D loss: 0.711726, acc.: 46.09%] [G loss: 0.713206]\n",
      "epoch:9 step:9213 [D loss: 0.654152, acc.: 61.72%] [G loss: 0.779927]\n",
      "epoch:9 step:9214 [D loss: 0.573504, acc.: 75.00%] [G loss: 0.777356]\n",
      "epoch:9 step:9215 [D loss: 0.570300, acc.: 75.00%] [G loss: 0.821877]\n",
      "epoch:9 step:9216 [D loss: 0.612475, acc.: 69.53%] [G loss: 0.820602]\n",
      "epoch:9 step:9217 [D loss: 0.666027, acc.: 53.91%] [G loss: 0.740493]\n",
      "epoch:9 step:9218 [D loss: 0.677729, acc.: 57.03%] [G loss: 0.790305]\n",
      "epoch:9 step:9219 [D loss: 0.508113, acc.: 78.12%] [G loss: 0.619485]\n",
      "epoch:9 step:9220 [D loss: 0.694892, acc.: 53.91%] [G loss: 0.842795]\n",
      "epoch:9 step:9221 [D loss: 0.574370, acc.: 76.56%] [G loss: 0.838981]\n",
      "epoch:9 step:9222 [D loss: 0.800209, acc.: 35.94%] [G loss: 0.782016]\n",
      "epoch:9 step:9223 [D loss: 0.724999, acc.: 44.53%] [G loss: 0.868145]\n",
      "epoch:9 step:9224 [D loss: 0.509634, acc.: 88.28%] [G loss: 0.868917]\n",
      "epoch:9 step:9225 [D loss: 0.465174, acc.: 85.94%] [G loss: 0.927237]\n",
      "epoch:9 step:9226 [D loss: 0.550308, acc.: 78.12%] [G loss: 0.751393]\n",
      "epoch:9 step:9227 [D loss: 0.652265, acc.: 59.38%] [G loss: 0.964097]\n",
      "epoch:9 step:9228 [D loss: 0.548176, acc.: 78.12%] [G loss: 1.059357]\n",
      "epoch:9 step:9229 [D loss: 0.500335, acc.: 84.38%] [G loss: 0.863867]\n",
      "epoch:9 step:9230 [D loss: 0.719630, acc.: 53.12%] [G loss: 0.809202]\n",
      "epoch:9 step:9231 [D loss: 0.858719, acc.: 28.91%] [G loss: 0.654601]\n",
      "epoch:9 step:9232 [D loss: 0.893422, acc.: 24.22%] [G loss: 0.754786]\n",
      "epoch:9 step:9233 [D loss: 0.650190, acc.: 67.19%] [G loss: 0.869527]\n",
      "epoch:9 step:9234 [D loss: 0.649051, acc.: 60.94%] [G loss: 0.856133]\n",
      "epoch:9 step:9235 [D loss: 0.447450, acc.: 79.69%] [G loss: 0.904325]\n",
      "epoch:9 step:9236 [D loss: 0.675261, acc.: 64.06%] [G loss: 0.924104]\n",
      "epoch:9 step:9237 [D loss: 0.657645, acc.: 60.94%] [G loss: 0.780565]\n",
      "epoch:9 step:9238 [D loss: 0.590360, acc.: 71.09%] [G loss: 0.834126]\n",
      "epoch:9 step:9239 [D loss: 0.558841, acc.: 76.56%] [G loss: 0.693908]\n",
      "epoch:9 step:9240 [D loss: 0.743547, acc.: 38.28%] [G loss: 0.666372]\n",
      "epoch:9 step:9241 [D loss: 0.691152, acc.: 48.44%] [G loss: 1.006617]\n",
      "epoch:9 step:9242 [D loss: 0.581946, acc.: 68.75%] [G loss: 1.115503]\n",
      "epoch:9 step:9243 [D loss: 0.536037, acc.: 74.22%] [G loss: 1.072919]\n",
      "epoch:9 step:9244 [D loss: 0.674802, acc.: 54.69%] [G loss: 1.035739]\n",
      "epoch:9 step:9245 [D loss: 0.700535, acc.: 56.25%] [G loss: 1.045894]\n",
      "epoch:9 step:9246 [D loss: 0.667563, acc.: 59.38%] [G loss: 1.096021]\n",
      "epoch:9 step:9247 [D loss: 0.630792, acc.: 57.03%] [G loss: 1.025925]\n",
      "epoch:9 step:9248 [D loss: 0.530964, acc.: 75.78%] [G loss: 0.981433]\n",
      "epoch:9 step:9249 [D loss: 0.489366, acc.: 82.03%] [G loss: 1.197066]\n",
      "epoch:9 step:9250 [D loss: 0.760483, acc.: 51.56%] [G loss: 0.967430]\n",
      "epoch:9 step:9251 [D loss: 0.630416, acc.: 67.97%] [G loss: 0.968176]\n",
      "epoch:9 step:9252 [D loss: 0.571110, acc.: 68.75%] [G loss: 1.326487]\n",
      "epoch:9 step:9253 [D loss: 0.721905, acc.: 44.53%] [G loss: 1.201013]\n",
      "epoch:9 step:9254 [D loss: 0.766248, acc.: 49.22%] [G loss: 0.882393]\n",
      "epoch:9 step:9255 [D loss: 0.740116, acc.: 42.19%] [G loss: 1.250661]\n",
      "epoch:9 step:9256 [D loss: 0.629240, acc.: 64.84%] [G loss: 1.062954]\n",
      "epoch:9 step:9257 [D loss: 0.560330, acc.: 78.91%] [G loss: 1.207474]\n",
      "epoch:9 step:9258 [D loss: 0.576449, acc.: 73.44%] [G loss: 1.034927]\n",
      "epoch:9 step:9259 [D loss: 0.644263, acc.: 56.25%] [G loss: 1.055050]\n",
      "epoch:9 step:9260 [D loss: 0.718725, acc.: 50.78%] [G loss: 1.067355]\n",
      "epoch:9 step:9261 [D loss: 0.726288, acc.: 50.00%] [G loss: 0.806294]\n",
      "epoch:9 step:9262 [D loss: 0.701319, acc.: 52.34%] [G loss: 0.710859]\n",
      "epoch:9 step:9263 [D loss: 0.602635, acc.: 75.00%] [G loss: 0.746615]\n",
      "epoch:9 step:9264 [D loss: 0.615429, acc.: 72.66%] [G loss: 0.715604]\n",
      "epoch:9 step:9265 [D loss: 0.586703, acc.: 76.56%] [G loss: 0.914666]\n",
      "epoch:9 step:9266 [D loss: 0.589626, acc.: 71.09%] [G loss: 0.795886]\n",
      "epoch:9 step:9267 [D loss: 0.735979, acc.: 48.44%] [G loss: 0.882096]\n",
      "epoch:9 step:9268 [D loss: 0.694459, acc.: 46.88%] [G loss: 0.962599]\n",
      "epoch:9 step:9269 [D loss: 0.641351, acc.: 67.19%] [G loss: 0.882569]\n",
      "epoch:9 step:9270 [D loss: 0.539154, acc.: 77.34%] [G loss: 1.055276]\n",
      "epoch:9 step:9271 [D loss: 0.503260, acc.: 85.94%] [G loss: 0.798666]\n",
      "epoch:9 step:9272 [D loss: 0.726893, acc.: 46.88%] [G loss: 0.828246]\n",
      "epoch:9 step:9273 [D loss: 0.725763, acc.: 49.22%] [G loss: 0.580475]\n",
      "epoch:9 step:9274 [D loss: 0.706868, acc.: 50.00%] [G loss: 0.732984]\n",
      "epoch:9 step:9275 [D loss: 0.701773, acc.: 53.12%] [G loss: 0.708313]\n",
      "epoch:9 step:9276 [D loss: 0.746104, acc.: 45.31%] [G loss: 0.899741]\n",
      "epoch:9 step:9277 [D loss: 0.734823, acc.: 49.22%] [G loss: 1.010147]\n",
      "epoch:9 step:9278 [D loss: 0.547793, acc.: 63.28%] [G loss: 0.662733]\n",
      "epoch:9 step:9279 [D loss: 0.702720, acc.: 48.44%] [G loss: 0.612306]\n",
      "epoch:9 step:9280 [D loss: 0.711378, acc.: 53.91%] [G loss: 0.895561]\n",
      "epoch:9 step:9281 [D loss: 0.768722, acc.: 47.66%] [G loss: 0.651219]\n",
      "epoch:9 step:9282 [D loss: 0.710968, acc.: 54.69%] [G loss: 0.953230]\n",
      "epoch:9 step:9283 [D loss: 0.721026, acc.: 41.41%] [G loss: 0.846552]\n",
      "epoch:9 step:9284 [D loss: 0.655672, acc.: 62.50%] [G loss: 0.848995]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9285 [D loss: 0.664255, acc.: 60.16%] [G loss: 1.032373]\n",
      "epoch:9 step:9286 [D loss: 0.647224, acc.: 62.50%] [G loss: 0.811861]\n",
      "epoch:9 step:9287 [D loss: 0.597824, acc.: 70.31%] [G loss: 1.083602]\n",
      "epoch:9 step:9288 [D loss: 0.687999, acc.: 58.59%] [G loss: 0.796483]\n",
      "epoch:9 step:9289 [D loss: 0.691312, acc.: 55.47%] [G loss: 0.785684]\n",
      "epoch:9 step:9290 [D loss: 0.640741, acc.: 60.94%] [G loss: 0.766603]\n",
      "epoch:9 step:9291 [D loss: 0.835414, acc.: 29.69%] [G loss: 0.701733]\n",
      "epoch:9 step:9292 [D loss: 0.749801, acc.: 42.19%] [G loss: 0.719034]\n",
      "epoch:9 step:9293 [D loss: 0.693766, acc.: 49.22%] [G loss: 0.786674]\n",
      "epoch:9 step:9294 [D loss: 0.670068, acc.: 55.47%] [G loss: 0.749077]\n",
      "epoch:9 step:9295 [D loss: 0.706434, acc.: 51.56%] [G loss: 0.718034]\n",
      "epoch:9 step:9296 [D loss: 0.685489, acc.: 50.78%] [G loss: 0.734109]\n",
      "epoch:9 step:9297 [D loss: 0.699989, acc.: 45.31%] [G loss: 0.747948]\n",
      "epoch:9 step:9298 [D loss: 0.684306, acc.: 53.91%] [G loss: 0.775978]\n",
      "epoch:9 step:9299 [D loss: 0.675922, acc.: 57.03%] [G loss: 0.757938]\n",
      "epoch:9 step:9300 [D loss: 0.645330, acc.: 59.38%] [G loss: 0.767266]\n",
      "epoch:9 step:9301 [D loss: 0.719634, acc.: 50.00%] [G loss: 0.746867]\n",
      "epoch:9 step:9302 [D loss: 0.682618, acc.: 56.25%] [G loss: 0.774743]\n",
      "epoch:9 step:9303 [D loss: 0.689443, acc.: 53.91%] [G loss: 0.807641]\n",
      "epoch:9 step:9304 [D loss: 0.679091, acc.: 56.25%] [G loss: 0.766908]\n",
      "epoch:9 step:9305 [D loss: 0.634469, acc.: 65.62%] [G loss: 0.789342]\n",
      "epoch:9 step:9306 [D loss: 0.651275, acc.: 63.28%] [G loss: 0.740533]\n",
      "epoch:9 step:9307 [D loss: 0.653777, acc.: 59.38%] [G loss: 0.774335]\n",
      "epoch:9 step:9308 [D loss: 0.658281, acc.: 58.59%] [G loss: 0.766961]\n",
      "epoch:9 step:9309 [D loss: 0.660562, acc.: 60.94%] [G loss: 0.782883]\n",
      "epoch:9 step:9310 [D loss: 0.680584, acc.: 53.91%] [G loss: 0.746312]\n",
      "epoch:9 step:9311 [D loss: 0.696114, acc.: 50.78%] [G loss: 0.830495]\n",
      "epoch:9 step:9312 [D loss: 0.694397, acc.: 51.56%] [G loss: 0.752078]\n",
      "epoch:9 step:9313 [D loss: 0.697090, acc.: 57.03%] [G loss: 0.747514]\n",
      "epoch:9 step:9314 [D loss: 0.709716, acc.: 53.12%] [G loss: 0.699732]\n",
      "epoch:9 step:9315 [D loss: 0.738628, acc.: 46.09%] [G loss: 0.719293]\n",
      "epoch:9 step:9316 [D loss: 0.672866, acc.: 55.47%] [G loss: 0.770900]\n",
      "epoch:9 step:9317 [D loss: 0.667061, acc.: 59.38%] [G loss: 0.744502]\n",
      "epoch:9 step:9318 [D loss: 0.560712, acc.: 76.56%] [G loss: 0.702892]\n",
      "epoch:9 step:9319 [D loss: 0.530309, acc.: 78.12%] [G loss: 0.802761]\n",
      "epoch:9 step:9320 [D loss: 0.520804, acc.: 78.91%] [G loss: 0.796259]\n",
      "epoch:9 step:9321 [D loss: 0.901858, acc.: 42.97%] [G loss: 0.680595]\n",
      "epoch:9 step:9322 [D loss: 0.476808, acc.: 87.50%] [G loss: 0.716995]\n",
      "epoch:9 step:9323 [D loss: 0.528564, acc.: 74.22%] [G loss: 0.880581]\n",
      "epoch:9 step:9324 [D loss: 0.727196, acc.: 44.53%] [G loss: 0.846627]\n",
      "epoch:9 step:9325 [D loss: 0.807778, acc.: 28.91%] [G loss: 0.814946]\n",
      "epoch:9 step:9326 [D loss: 0.753408, acc.: 40.62%] [G loss: 0.795100]\n",
      "epoch:9 step:9327 [D loss: 0.660838, acc.: 63.28%] [G loss: 0.879974]\n",
      "epoch:9 step:9328 [D loss: 0.736577, acc.: 43.75%] [G loss: 0.778811]\n",
      "epoch:9 step:9329 [D loss: 0.657781, acc.: 60.94%] [G loss: 0.835728]\n",
      "epoch:9 step:9330 [D loss: 0.660724, acc.: 60.94%] [G loss: 0.830486]\n",
      "epoch:9 step:9331 [D loss: 0.673164, acc.: 57.81%] [G loss: 0.828843]\n",
      "epoch:9 step:9332 [D loss: 0.508490, acc.: 79.69%] [G loss: 0.879105]\n",
      "epoch:9 step:9333 [D loss: 0.557604, acc.: 79.69%] [G loss: 0.872860]\n",
      "epoch:9 step:9334 [D loss: 0.653193, acc.: 60.94%] [G loss: 0.535136]\n",
      "epoch:9 step:9335 [D loss: 0.622430, acc.: 67.97%] [G loss: 0.797878]\n",
      "epoch:9 step:9336 [D loss: 0.659571, acc.: 60.16%] [G loss: 0.793008]\n",
      "epoch:9 step:9337 [D loss: 0.677126, acc.: 63.28%] [G loss: 0.829385]\n",
      "epoch:9 step:9338 [D loss: 0.667764, acc.: 57.81%] [G loss: 0.848537]\n",
      "epoch:9 step:9339 [D loss: 0.622696, acc.: 75.00%] [G loss: 0.812461]\n",
      "epoch:9 step:9340 [D loss: 0.697121, acc.: 61.72%] [G loss: 0.833491]\n",
      "epoch:9 step:9341 [D loss: 0.734558, acc.: 46.88%] [G loss: 0.821400]\n",
      "epoch:9 step:9342 [D loss: 0.656230, acc.: 63.28%] [G loss: 0.710111]\n",
      "epoch:9 step:9343 [D loss: 0.676127, acc.: 58.59%] [G loss: 0.687722]\n",
      "epoch:9 step:9344 [D loss: 0.671192, acc.: 59.38%] [G loss: 0.711707]\n",
      "epoch:9 step:9345 [D loss: 0.313840, acc.: 89.84%] [G loss: 0.914997]\n",
      "epoch:9 step:9346 [D loss: 0.699426, acc.: 51.56%] [G loss: 0.903247]\n",
      "epoch:9 step:9347 [D loss: 0.668598, acc.: 60.16%] [G loss: 0.886672]\n",
      "epoch:9 step:9348 [D loss: 0.713647, acc.: 51.56%] [G loss: 0.806446]\n",
      "epoch:9 step:9349 [D loss: 0.653260, acc.: 63.28%] [G loss: 0.862467]\n",
      "epoch:9 step:9350 [D loss: 0.750391, acc.: 46.09%] [G loss: 0.801280]\n",
      "epoch:9 step:9351 [D loss: 0.638522, acc.: 61.72%] [G loss: 0.877043]\n",
      "epoch:9 step:9352 [D loss: 0.557091, acc.: 75.78%] [G loss: 0.895380]\n",
      "epoch:9 step:9353 [D loss: 0.596572, acc.: 63.28%] [G loss: 0.931202]\n",
      "epoch:9 step:9354 [D loss: 0.511995, acc.: 83.59%] [G loss: 0.903353]\n",
      "epoch:9 step:9355 [D loss: 0.649245, acc.: 64.84%] [G loss: 0.877802]\n",
      "epoch:9 step:9356 [D loss: 0.605501, acc.: 72.66%] [G loss: 0.903778]\n",
      "epoch:9 step:9357 [D loss: 0.387391, acc.: 82.81%] [G loss: 0.816108]\n",
      "epoch:9 step:9358 [D loss: 0.415595, acc.: 85.16%] [G loss: 0.888934]\n",
      "epoch:9 step:9359 [D loss: 0.303336, acc.: 88.28%] [G loss: 0.879800]\n",
      "epoch:9 step:9360 [D loss: 0.280806, acc.: 92.97%] [G loss: 1.134573]\n",
      "epoch:9 step:9361 [D loss: 0.884884, acc.: 32.81%] [G loss: 0.987580]\n",
      "epoch:9 step:9362 [D loss: 0.550471, acc.: 77.34%] [G loss: 1.037682]\n",
      "epoch:9 step:9363 [D loss: 0.794811, acc.: 49.22%] [G loss: 1.120324]\n",
      "epoch:9 step:9364 [D loss: 0.619990, acc.: 68.75%] [G loss: 0.954701]\n",
      "epoch:9 step:9365 [D loss: 0.692119, acc.: 62.50%] [G loss: 0.927715]\n",
      "epoch:9 step:9366 [D loss: 0.518372, acc.: 74.22%] [G loss: 1.037324]\n",
      "epoch:9 step:9367 [D loss: 0.452025, acc.: 81.25%] [G loss: 0.853360]\n",
      "epoch:9 step:9368 [D loss: 0.554520, acc.: 79.69%] [G loss: 0.951660]\n",
      "epoch:9 step:9369 [D loss: 0.251119, acc.: 92.97%] [G loss: 0.727469]\n",
      "epoch:9 step:9370 [D loss: 0.269462, acc.: 87.50%] [G loss: 1.056146]\n",
      "epoch:10 step:9371 [D loss: 0.825241, acc.: 40.62%] [G loss: 0.896525]\n",
      "epoch:10 step:9372 [D loss: 0.805277, acc.: 45.31%] [G loss: 1.019127]\n",
      "epoch:10 step:9373 [D loss: 0.773243, acc.: 47.66%] [G loss: 1.043624]\n",
      "epoch:10 step:9374 [D loss: 0.733974, acc.: 48.44%] [G loss: 0.907151]\n",
      "epoch:10 step:9375 [D loss: 0.722642, acc.: 51.56%] [G loss: 0.916009]\n",
      "epoch:10 step:9376 [D loss: 0.737067, acc.: 44.53%] [G loss: 0.818652]\n",
      "epoch:10 step:9377 [D loss: 0.715831, acc.: 47.66%] [G loss: 0.897995]\n",
      "epoch:10 step:9378 [D loss: 0.687373, acc.: 56.25%] [G loss: 0.667642]\n",
      "epoch:10 step:9379 [D loss: 0.659887, acc.: 58.59%] [G loss: 0.772593]\n",
      "epoch:10 step:9380 [D loss: 0.846979, acc.: 40.62%] [G loss: 0.691321]\n",
      "epoch:10 step:9381 [D loss: 0.875982, acc.: 36.72%] [G loss: 0.812044]\n",
      "epoch:10 step:9382 [D loss: 1.253294, acc.: 24.22%] [G loss: 2.406823]\n",
      "epoch:10 step:9383 [D loss: 0.693381, acc.: 54.69%] [G loss: 0.993750]\n",
      "epoch:10 step:9384 [D loss: 0.732905, acc.: 56.25%] [G loss: 1.307518]\n",
      "epoch:10 step:9385 [D loss: 0.727226, acc.: 50.00%] [G loss: 1.078245]\n",
      "epoch:10 step:9386 [D loss: 0.760726, acc.: 43.75%] [G loss: 0.827342]\n",
      "epoch:10 step:9387 [D loss: 0.742550, acc.: 48.44%] [G loss: 0.843305]\n",
      "epoch:10 step:9388 [D loss: 0.739268, acc.: 37.50%] [G loss: 0.775301]\n",
      "epoch:10 step:9389 [D loss: 0.689342, acc.: 56.25%] [G loss: 0.802376]\n",
      "epoch:10 step:9390 [D loss: 0.704687, acc.: 50.00%] [G loss: 0.808328]\n",
      "epoch:10 step:9391 [D loss: 0.727218, acc.: 36.72%] [G loss: 0.718817]\n",
      "epoch:10 step:9392 [D loss: 0.666745, acc.: 60.16%] [G loss: 0.787269]\n",
      "epoch:10 step:9393 [D loss: 0.709795, acc.: 47.66%] [G loss: 0.777197]\n",
      "epoch:10 step:9394 [D loss: 0.700777, acc.: 53.12%] [G loss: 0.771281]\n",
      "epoch:10 step:9395 [D loss: 0.681614, acc.: 58.59%] [G loss: 0.800304]\n",
      "epoch:10 step:9396 [D loss: 0.698128, acc.: 55.47%] [G loss: 0.724162]\n",
      "epoch:10 step:9397 [D loss: 0.651065, acc.: 62.50%] [G loss: 0.802717]\n",
      "epoch:10 step:9398 [D loss: 0.655206, acc.: 60.94%] [G loss: 0.790541]\n",
      "epoch:10 step:9399 [D loss: 0.675953, acc.: 55.47%] [G loss: 0.753189]\n",
      "epoch:10 step:9400 [D loss: 0.749557, acc.: 42.97%] [G loss: 0.748944]\n",
      "##############\n",
      "[4.02304439 2.54429182 6.93597223 5.93152901 4.67828572 6.46431033\n",
      " 5.58007622 5.52653799 5.7818928  5.17154267]\n",
      "##########\n",
      "epoch:10 step:9401 [D loss: 0.648876, acc.: 59.38%] [G loss: 0.780599]\n",
      "epoch:10 step:9402 [D loss: 0.704862, acc.: 53.12%] [G loss: 0.783395]\n",
      "epoch:10 step:9403 [D loss: 0.653393, acc.: 63.28%] [G loss: 0.757779]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9404 [D loss: 0.662068, acc.: 55.47%] [G loss: 0.758184]\n",
      "epoch:10 step:9405 [D loss: 0.538897, acc.: 75.00%] [G loss: 0.773004]\n",
      "epoch:10 step:9406 [D loss: 0.526214, acc.: 81.25%] [G loss: 0.777043]\n",
      "epoch:10 step:9407 [D loss: 0.735858, acc.: 38.28%] [G loss: 0.519703]\n",
      "epoch:10 step:9408 [D loss: 0.785937, acc.: 39.06%] [G loss: 0.755170]\n",
      "epoch:10 step:9409 [D loss: 0.731573, acc.: 41.41%] [G loss: 0.811157]\n",
      "epoch:10 step:9410 [D loss: 0.679749, acc.: 55.47%] [G loss: 0.526671]\n",
      "epoch:10 step:9411 [D loss: 0.660220, acc.: 63.28%] [G loss: 0.853944]\n",
      "epoch:10 step:9412 [D loss: 0.713988, acc.: 48.44%] [G loss: 0.831638]\n",
      "epoch:10 step:9413 [D loss: 0.673828, acc.: 57.03%] [G loss: 0.710022]\n",
      "epoch:10 step:9414 [D loss: 0.696928, acc.: 52.34%] [G loss: 0.777519]\n",
      "epoch:10 step:9415 [D loss: 0.687436, acc.: 58.59%] [G loss: 0.749294]\n",
      "epoch:10 step:9416 [D loss: 0.687633, acc.: 53.91%] [G loss: 0.845534]\n",
      "epoch:10 step:9417 [D loss: 0.700067, acc.: 54.69%] [G loss: 0.783911]\n",
      "epoch:10 step:9418 [D loss: 0.659400, acc.: 60.94%] [G loss: 0.545101]\n",
      "epoch:10 step:9419 [D loss: 0.668917, acc.: 66.41%] [G loss: 0.812923]\n",
      "epoch:10 step:9420 [D loss: 0.647227, acc.: 56.25%] [G loss: 0.818590]\n",
      "epoch:10 step:9421 [D loss: 0.685987, acc.: 48.44%] [G loss: 0.749662]\n",
      "epoch:10 step:9422 [D loss: 0.651342, acc.: 64.06%] [G loss: 0.573024]\n",
      "epoch:10 step:9423 [D loss: 0.653169, acc.: 62.50%] [G loss: 0.559448]\n",
      "epoch:10 step:9424 [D loss: 0.688783, acc.: 55.47%] [G loss: 0.485097]\n",
      "epoch:10 step:9425 [D loss: 0.664515, acc.: 60.94%] [G loss: 0.819573]\n",
      "epoch:10 step:9426 [D loss: 0.671424, acc.: 58.59%] [G loss: 0.759335]\n",
      "epoch:10 step:9427 [D loss: 0.767060, acc.: 42.19%] [G loss: 0.811127]\n",
      "epoch:10 step:9428 [D loss: 0.730645, acc.: 50.78%] [G loss: 0.819170]\n",
      "epoch:10 step:9429 [D loss: 0.688024, acc.: 51.56%] [G loss: 0.836359]\n",
      "epoch:10 step:9430 [D loss: 0.718225, acc.: 50.00%] [G loss: 0.707808]\n",
      "epoch:10 step:9431 [D loss: 0.640142, acc.: 61.72%] [G loss: 0.889713]\n",
      "epoch:10 step:9432 [D loss: 0.664993, acc.: 60.94%] [G loss: 0.838673]\n",
      "epoch:10 step:9433 [D loss: 0.665753, acc.: 60.16%] [G loss: 0.899712]\n",
      "epoch:10 step:9434 [D loss: 0.631254, acc.: 69.53%] [G loss: 0.857981]\n",
      "epoch:10 step:9435 [D loss: 0.627382, acc.: 60.94%] [G loss: 0.856892]\n",
      "epoch:10 step:9436 [D loss: 0.770818, acc.: 45.31%] [G loss: 0.908267]\n",
      "epoch:10 step:9437 [D loss: 0.732894, acc.: 47.66%] [G loss: 0.892082]\n",
      "epoch:10 step:9438 [D loss: 0.621269, acc.: 64.06%] [G loss: 0.834974]\n",
      "epoch:10 step:9439 [D loss: 0.563972, acc.: 81.25%] [G loss: 0.934335]\n",
      "epoch:10 step:9440 [D loss: 0.583792, acc.: 73.44%] [G loss: 1.133916]\n",
      "epoch:10 step:9441 [D loss: 0.862225, acc.: 46.09%] [G loss: 0.851947]\n",
      "epoch:10 step:9442 [D loss: 0.623780, acc.: 65.62%] [G loss: 0.877230]\n",
      "epoch:10 step:9443 [D loss: 0.688102, acc.: 51.56%] [G loss: 0.874058]\n",
      "epoch:10 step:9444 [D loss: 0.675693, acc.: 53.91%] [G loss: 0.674154]\n",
      "epoch:10 step:9445 [D loss: 0.748449, acc.: 56.25%] [G loss: 0.936348]\n",
      "epoch:10 step:9446 [D loss: 0.748412, acc.: 46.09%] [G loss: 0.694982]\n",
      "epoch:10 step:9447 [D loss: 0.653343, acc.: 60.16%] [G loss: 0.693008]\n",
      "epoch:10 step:9448 [D loss: 0.699867, acc.: 51.56%] [G loss: 0.660828]\n",
      "epoch:10 step:9449 [D loss: 0.702637, acc.: 52.34%] [G loss: 0.728253]\n",
      "epoch:10 step:9450 [D loss: 0.681416, acc.: 57.81%] [G loss: 0.671499]\n",
      "epoch:10 step:9451 [D loss: 0.612366, acc.: 73.44%] [G loss: 0.728688]\n",
      "epoch:10 step:9452 [D loss: 0.574626, acc.: 80.47%] [G loss: 0.806919]\n",
      "epoch:10 step:9453 [D loss: 0.662534, acc.: 60.94%] [G loss: 0.785947]\n",
      "epoch:10 step:9454 [D loss: 0.639081, acc.: 61.72%] [G loss: 0.741978]\n",
      "epoch:10 step:9455 [D loss: 0.535793, acc.: 80.47%] [G loss: 0.783405]\n",
      "epoch:10 step:9456 [D loss: 0.633186, acc.: 72.66%] [G loss: 0.725777]\n",
      "epoch:10 step:9457 [D loss: 0.633590, acc.: 59.38%] [G loss: 0.840957]\n",
      "epoch:10 step:9458 [D loss: 0.691831, acc.: 62.50%] [G loss: 0.790901]\n",
      "epoch:10 step:9459 [D loss: 0.522579, acc.: 88.28%] [G loss: 0.925267]\n",
      "epoch:10 step:9460 [D loss: 0.609362, acc.: 70.31%] [G loss: 0.706123]\n",
      "epoch:10 step:9461 [D loss: 0.706544, acc.: 51.56%] [G loss: 0.754708]\n",
      "epoch:10 step:9462 [D loss: 0.767864, acc.: 43.75%] [G loss: 0.842496]\n",
      "epoch:10 step:9463 [D loss: 0.622951, acc.: 66.41%] [G loss: 0.956259]\n",
      "epoch:10 step:9464 [D loss: 0.637450, acc.: 67.19%] [G loss: 0.793696]\n",
      "epoch:10 step:9465 [D loss: 0.749514, acc.: 47.66%] [G loss: 0.661988]\n",
      "epoch:10 step:9466 [D loss: 0.669132, acc.: 52.34%] [G loss: 0.632893]\n",
      "epoch:10 step:9467 [D loss: 0.730597, acc.: 43.75%] [G loss: 0.722385]\n",
      "epoch:10 step:9468 [D loss: 0.702845, acc.: 50.78%] [G loss: 0.792547]\n",
      "epoch:10 step:9469 [D loss: 0.653023, acc.: 62.50%] [G loss: 0.764146]\n",
      "epoch:10 step:9470 [D loss: 0.623201, acc.: 66.41%] [G loss: 0.818022]\n",
      "epoch:10 step:9471 [D loss: 0.682567, acc.: 57.81%] [G loss: 0.911633]\n",
      "epoch:10 step:9472 [D loss: 0.687633, acc.: 53.12%] [G loss: 0.822045]\n",
      "epoch:10 step:9473 [D loss: 0.662891, acc.: 59.38%] [G loss: 0.487732]\n",
      "epoch:10 step:9474 [D loss: 0.932113, acc.: 32.81%] [G loss: 0.741709]\n",
      "epoch:10 step:9475 [D loss: 0.635329, acc.: 59.38%] [G loss: 0.831246]\n",
      "epoch:10 step:9476 [D loss: 0.719319, acc.: 48.44%] [G loss: 0.880050]\n",
      "epoch:10 step:9477 [D loss: 0.635368, acc.: 62.50%] [G loss: 0.848026]\n",
      "epoch:10 step:9478 [D loss: 0.655633, acc.: 63.28%] [G loss: 0.901266]\n",
      "epoch:10 step:9479 [D loss: 0.659145, acc.: 63.28%] [G loss: 0.883901]\n",
      "epoch:10 step:9480 [D loss: 0.646808, acc.: 64.06%] [G loss: 0.905874]\n",
      "epoch:10 step:9481 [D loss: 0.693988, acc.: 58.59%] [G loss: 0.828945]\n",
      "epoch:10 step:9482 [D loss: 0.643964, acc.: 64.84%] [G loss: 0.864060]\n",
      "epoch:10 step:9483 [D loss: 0.640765, acc.: 61.72%] [G loss: 0.920410]\n",
      "epoch:10 step:9484 [D loss: 0.667194, acc.: 59.38%] [G loss: 0.846566]\n",
      "epoch:10 step:9485 [D loss: 0.608474, acc.: 67.97%] [G loss: 0.844357]\n",
      "epoch:10 step:9486 [D loss: 0.637737, acc.: 60.16%] [G loss: 0.841845]\n",
      "epoch:10 step:9487 [D loss: 0.658710, acc.: 64.06%] [G loss: 0.782057]\n",
      "epoch:10 step:9488 [D loss: 0.601935, acc.: 66.41%] [G loss: 0.728939]\n",
      "epoch:10 step:9489 [D loss: 0.413841, acc.: 77.34%] [G loss: 0.700106]\n",
      "epoch:10 step:9490 [D loss: 0.767686, acc.: 50.00%] [G loss: 0.874319]\n",
      "epoch:10 step:9491 [D loss: 0.832801, acc.: 41.41%] [G loss: 0.806669]\n",
      "epoch:10 step:9492 [D loss: 0.719124, acc.: 44.53%] [G loss: 0.816264]\n",
      "epoch:10 step:9493 [D loss: 0.739711, acc.: 39.84%] [G loss: 0.833875]\n",
      "epoch:10 step:9494 [D loss: 0.695521, acc.: 54.69%] [G loss: 0.868267]\n",
      "epoch:10 step:9495 [D loss: 0.690259, acc.: 58.59%] [G loss: 0.978417]\n",
      "epoch:10 step:9496 [D loss: 0.628808, acc.: 66.41%] [G loss: 1.011507]\n",
      "epoch:10 step:9497 [D loss: 0.611260, acc.: 67.19%] [G loss: 1.086363]\n",
      "epoch:10 step:9498 [D loss: 0.663850, acc.: 60.16%] [G loss: 0.977377]\n",
      "epoch:10 step:9499 [D loss: 0.641781, acc.: 57.81%] [G loss: 0.956962]\n",
      "epoch:10 step:9500 [D loss: 0.640326, acc.: 60.94%] [G loss: 0.978044]\n",
      "epoch:10 step:9501 [D loss: 0.632811, acc.: 65.62%] [G loss: 0.910272]\n",
      "epoch:10 step:9502 [D loss: 0.661563, acc.: 61.72%] [G loss: 0.893583]\n",
      "epoch:10 step:9503 [D loss: 0.566708, acc.: 73.44%] [G loss: 0.924640]\n",
      "epoch:10 step:9504 [D loss: 0.560203, acc.: 73.44%] [G loss: 0.991146]\n",
      "epoch:10 step:9505 [D loss: 0.619526, acc.: 68.75%] [G loss: 0.825055]\n",
      "epoch:10 step:9506 [D loss: 0.694263, acc.: 53.91%] [G loss: 0.752039]\n",
      "epoch:10 step:9507 [D loss: 0.797425, acc.: 39.06%] [G loss: 0.794239]\n",
      "epoch:10 step:9508 [D loss: 0.717634, acc.: 48.44%] [G loss: 0.829588]\n",
      "epoch:10 step:9509 [D loss: 0.702738, acc.: 51.56%] [G loss: 0.791941]\n",
      "epoch:10 step:9510 [D loss: 0.676981, acc.: 57.03%] [G loss: 0.636843]\n",
      "epoch:10 step:9511 [D loss: 0.747989, acc.: 43.75%] [G loss: 0.794807]\n",
      "epoch:10 step:9512 [D loss: 0.752133, acc.: 37.50%] [G loss: 0.776630]\n",
      "epoch:10 step:9513 [D loss: 0.558968, acc.: 67.19%] [G loss: 0.880754]\n",
      "epoch:10 step:9514 [D loss: 0.738876, acc.: 55.47%] [G loss: 0.885613]\n",
      "epoch:10 step:9515 [D loss: 0.479875, acc.: 82.81%] [G loss: 1.025867]\n",
      "epoch:10 step:9516 [D loss: 0.672366, acc.: 60.16%] [G loss: 0.967677]\n",
      "epoch:10 step:9517 [D loss: 0.679951, acc.: 60.94%] [G loss: 0.934531]\n",
      "epoch:10 step:9518 [D loss: 0.660866, acc.: 57.03%] [G loss: 0.920605]\n",
      "epoch:10 step:9519 [D loss: 0.606595, acc.: 73.44%] [G loss: 0.735423]\n",
      "epoch:10 step:9520 [D loss: 0.399485, acc.: 92.19%] [G loss: 0.668293]\n",
      "epoch:10 step:9521 [D loss: 0.530344, acc.: 78.12%] [G loss: 0.935144]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9522 [D loss: 0.760679, acc.: 55.47%] [G loss: 0.718177]\n",
      "epoch:10 step:9523 [D loss: 0.825088, acc.: 28.91%] [G loss: 0.812857]\n",
      "epoch:10 step:9524 [D loss: 0.767284, acc.: 45.31%] [G loss: 0.921539]\n",
      "epoch:10 step:9525 [D loss: 0.677456, acc.: 57.81%] [G loss: 0.869268]\n",
      "epoch:10 step:9526 [D loss: 0.671454, acc.: 56.25%] [G loss: 0.876857]\n",
      "epoch:10 step:9527 [D loss: 0.804913, acc.: 36.72%] [G loss: 0.856959]\n",
      "epoch:10 step:9528 [D loss: 0.708213, acc.: 46.09%] [G loss: 0.936318]\n",
      "epoch:10 step:9529 [D loss: 0.691323, acc.: 48.44%] [G loss: 0.983468]\n",
      "epoch:10 step:9530 [D loss: 0.773926, acc.: 48.44%] [G loss: 0.928249]\n",
      "epoch:10 step:9531 [D loss: 0.725314, acc.: 52.34%] [G loss: 0.906483]\n",
      "epoch:10 step:9532 [D loss: 0.696716, acc.: 53.12%] [G loss: 0.840439]\n",
      "epoch:10 step:9533 [D loss: 0.707304, acc.: 49.22%] [G loss: 0.853302]\n",
      "epoch:10 step:9534 [D loss: 0.691580, acc.: 57.81%] [G loss: 0.855195]\n",
      "epoch:10 step:9535 [D loss: 0.672649, acc.: 65.62%] [G loss: 0.862910]\n",
      "epoch:10 step:9536 [D loss: 0.650597, acc.: 64.84%] [G loss: 0.848925]\n",
      "epoch:10 step:9537 [D loss: 0.679201, acc.: 59.38%] [G loss: 0.828048]\n",
      "epoch:10 step:9538 [D loss: 0.623513, acc.: 67.97%] [G loss: 0.739708]\n",
      "epoch:10 step:9539 [D loss: 0.706542, acc.: 58.59%] [G loss: 0.774461]\n",
      "epoch:10 step:9540 [D loss: 0.693858, acc.: 59.38%] [G loss: 0.825003]\n",
      "epoch:10 step:9541 [D loss: 0.673658, acc.: 56.25%] [G loss: 0.757193]\n",
      "epoch:10 step:9542 [D loss: 0.637386, acc.: 64.84%] [G loss: 0.734706]\n",
      "epoch:10 step:9543 [D loss: 0.679210, acc.: 56.25%] [G loss: 0.796239]\n",
      "epoch:10 step:9544 [D loss: 0.711878, acc.: 43.75%] [G loss: 0.779408]\n",
      "epoch:10 step:9545 [D loss: 0.706273, acc.: 47.66%] [G loss: 0.728682]\n",
      "epoch:10 step:9546 [D loss: 0.683870, acc.: 60.16%] [G loss: 0.750353]\n",
      "epoch:10 step:9547 [D loss: 0.744905, acc.: 40.62%] [G loss: 0.724348]\n",
      "epoch:10 step:9548 [D loss: 0.688911, acc.: 50.00%] [G loss: 0.781426]\n",
      "epoch:10 step:9549 [D loss: 0.714435, acc.: 46.09%] [G loss: 0.730452]\n",
      "epoch:10 step:9550 [D loss: 0.714088, acc.: 46.88%] [G loss: 0.751300]\n",
      "epoch:10 step:9551 [D loss: 0.687841, acc.: 59.38%] [G loss: 0.736221]\n",
      "epoch:10 step:9552 [D loss: 0.724135, acc.: 44.53%] [G loss: 0.722124]\n",
      "epoch:10 step:9553 [D loss: 0.702429, acc.: 51.56%] [G loss: 0.766195]\n",
      "epoch:10 step:9554 [D loss: 0.686912, acc.: 50.78%] [G loss: 0.759197]\n",
      "epoch:10 step:9555 [D loss: 0.669062, acc.: 59.38%] [G loss: 0.780889]\n",
      "epoch:10 step:9556 [D loss: 0.716448, acc.: 43.75%] [G loss: 0.768759]\n",
      "epoch:10 step:9557 [D loss: 0.684401, acc.: 52.34%] [G loss: 0.771455]\n",
      "epoch:10 step:9558 [D loss: 0.697243, acc.: 52.34%] [G loss: 0.771550]\n",
      "epoch:10 step:9559 [D loss: 0.685692, acc.: 53.91%] [G loss: 0.744234]\n",
      "epoch:10 step:9560 [D loss: 0.669957, acc.: 58.59%] [G loss: 0.748574]\n",
      "epoch:10 step:9561 [D loss: 0.675121, acc.: 51.56%] [G loss: 0.789963]\n",
      "epoch:10 step:9562 [D loss: 0.643872, acc.: 67.97%] [G loss: 0.772502]\n",
      "epoch:10 step:9563 [D loss: 0.689485, acc.: 50.00%] [G loss: 0.789171]\n",
      "epoch:10 step:9564 [D loss: 0.616356, acc.: 75.00%] [G loss: 0.801049]\n",
      "epoch:10 step:9565 [D loss: 0.685917, acc.: 55.47%] [G loss: 0.719374]\n",
      "epoch:10 step:9566 [D loss: 0.631841, acc.: 72.66%] [G loss: 0.736687]\n",
      "epoch:10 step:9567 [D loss: 0.694180, acc.: 55.47%] [G loss: 0.874900]\n",
      "epoch:10 step:9568 [D loss: 0.674755, acc.: 54.69%] [G loss: 0.759868]\n",
      "epoch:10 step:9569 [D loss: 0.708162, acc.: 50.00%] [G loss: 0.814711]\n",
      "epoch:10 step:9570 [D loss: 0.740250, acc.: 46.88%] [G loss: 0.774589]\n",
      "epoch:10 step:9571 [D loss: 0.669326, acc.: 59.38%] [G loss: 0.773778]\n",
      "epoch:10 step:9572 [D loss: 0.723329, acc.: 52.34%] [G loss: 0.750571]\n",
      "epoch:10 step:9573 [D loss: 0.675597, acc.: 64.06%] [G loss: 0.782626]\n",
      "epoch:10 step:9574 [D loss: 0.579559, acc.: 75.78%] [G loss: 0.827646]\n",
      "epoch:10 step:9575 [D loss: 0.716867, acc.: 46.88%] [G loss: 0.754451]\n",
      "epoch:10 step:9576 [D loss: 0.634851, acc.: 71.09%] [G loss: 0.732734]\n",
      "epoch:10 step:9577 [D loss: 0.663686, acc.: 59.38%] [G loss: 0.833583]\n",
      "epoch:10 step:9578 [D loss: 0.641699, acc.: 65.62%] [G loss: 0.964253]\n",
      "epoch:10 step:9579 [D loss: 0.651558, acc.: 67.19%] [G loss: 0.835883]\n",
      "epoch:10 step:9580 [D loss: 0.694390, acc.: 51.56%] [G loss: 0.910344]\n",
      "epoch:10 step:9581 [D loss: 0.724784, acc.: 46.09%] [G loss: 0.785719]\n",
      "epoch:10 step:9582 [D loss: 0.670492, acc.: 64.06%] [G loss: 0.797920]\n",
      "epoch:10 step:9583 [D loss: 0.681321, acc.: 57.81%] [G loss: 0.756871]\n",
      "epoch:10 step:9584 [D loss: 0.706182, acc.: 49.22%] [G loss: 0.850975]\n",
      "epoch:10 step:9585 [D loss: 0.728872, acc.: 48.44%] [G loss: 0.731934]\n",
      "epoch:10 step:9586 [D loss: 0.675455, acc.: 52.34%] [G loss: 0.827655]\n",
      "epoch:10 step:9587 [D loss: 0.713136, acc.: 50.00%] [G loss: 0.750693]\n",
      "epoch:10 step:9588 [D loss: 0.655921, acc.: 64.06%] [G loss: 0.764800]\n",
      "epoch:10 step:9589 [D loss: 0.634130, acc.: 72.66%] [G loss: 0.772560]\n",
      "epoch:10 step:9590 [D loss: 0.617326, acc.: 68.75%] [G loss: 0.733320]\n",
      "epoch:10 step:9591 [D loss: 0.610421, acc.: 73.44%] [G loss: 0.736189]\n",
      "epoch:10 step:9592 [D loss: 0.573960, acc.: 75.78%] [G loss: 0.802084]\n",
      "epoch:10 step:9593 [D loss: 0.694250, acc.: 59.38%] [G loss: 0.613253]\n",
      "epoch:10 step:9594 [D loss: 0.694206, acc.: 57.03%] [G loss: 0.804065]\n",
      "epoch:10 step:9595 [D loss: 0.641385, acc.: 64.84%] [G loss: 0.773524]\n",
      "epoch:10 step:9596 [D loss: 0.701868, acc.: 47.66%] [G loss: 0.792812]\n",
      "epoch:10 step:9597 [D loss: 0.691606, acc.: 53.91%] [G loss: 0.742348]\n",
      "epoch:10 step:9598 [D loss: 0.681370, acc.: 54.69%] [G loss: 0.804465]\n",
      "epoch:10 step:9599 [D loss: 0.656820, acc.: 61.72%] [G loss: 0.823774]\n",
      "epoch:10 step:9600 [D loss: 0.426276, acc.: 85.16%] [G loss: 0.843702]\n",
      "##############\n",
      "[4.13311105 2.39041594 6.71805445 5.17801958 4.49372776 6.21799277\n",
      " 5.4862665  5.36834565 5.71466706 5.07288035]\n",
      "##########\n",
      "epoch:10 step:9601 [D loss: 0.520990, acc.: 74.22%] [G loss: 0.877981]\n",
      "epoch:10 step:9602 [D loss: 0.469011, acc.: 81.25%] [G loss: 0.827097]\n",
      "epoch:10 step:9603 [D loss: 0.657826, acc.: 63.28%] [G loss: 0.834931]\n",
      "epoch:10 step:9604 [D loss: 0.580635, acc.: 75.00%] [G loss: 0.940355]\n",
      "epoch:10 step:9605 [D loss: 0.475028, acc.: 69.53%] [G loss: 0.969225]\n",
      "epoch:10 step:9606 [D loss: 0.630556, acc.: 67.19%] [G loss: 0.961779]\n",
      "epoch:10 step:9607 [D loss: 0.557575, acc.: 76.56%] [G loss: 0.731700]\n",
      "epoch:10 step:9608 [D loss: 0.506885, acc.: 84.38%] [G loss: 0.545787]\n",
      "epoch:10 step:9609 [D loss: 0.780117, acc.: 39.06%] [G loss: 0.967247]\n",
      "epoch:10 step:9610 [D loss: 0.759077, acc.: 38.28%] [G loss: 0.901394]\n",
      "epoch:10 step:9611 [D loss: 0.789266, acc.: 31.25%] [G loss: 0.812281]\n",
      "epoch:10 step:9612 [D loss: 1.027659, acc.: 20.31%] [G loss: 0.986623]\n",
      "epoch:10 step:9613 [D loss: 0.690730, acc.: 52.34%] [G loss: 0.921209]\n",
      "epoch:10 step:9614 [D loss: 0.699391, acc.: 52.34%] [G loss: 0.947748]\n",
      "epoch:10 step:9615 [D loss: 0.725901, acc.: 46.88%] [G loss: 0.754410]\n",
      "epoch:10 step:9616 [D loss: 0.739631, acc.: 41.41%] [G loss: 0.908820]\n",
      "epoch:10 step:9617 [D loss: 0.663599, acc.: 53.91%] [G loss: 0.775817]\n",
      "epoch:10 step:9618 [D loss: 0.671274, acc.: 60.16%] [G loss: 0.833525]\n",
      "epoch:10 step:9619 [D loss: 0.670462, acc.: 56.25%] [G loss: 0.699434]\n",
      "epoch:10 step:9620 [D loss: 0.798784, acc.: 25.00%] [G loss: 0.880229]\n",
      "epoch:10 step:9621 [D loss: 0.744969, acc.: 45.31%] [G loss: 0.894406]\n",
      "epoch:10 step:9622 [D loss: 0.687430, acc.: 55.47%] [G loss: 0.935083]\n",
      "epoch:10 step:9623 [D loss: 0.667916, acc.: 53.12%] [G loss: 0.846132]\n",
      "epoch:10 step:9624 [D loss: 0.695598, acc.: 53.12%] [G loss: 0.844340]\n",
      "epoch:10 step:9625 [D loss: 0.614964, acc.: 71.09%] [G loss: 0.771250]\n",
      "epoch:10 step:9626 [D loss: 0.467677, acc.: 87.50%] [G loss: 0.881780]\n",
      "epoch:10 step:9627 [D loss: 0.770383, acc.: 37.50%] [G loss: 0.794566]\n",
      "epoch:10 step:9628 [D loss: 0.714837, acc.: 44.53%] [G loss: 0.866941]\n",
      "epoch:10 step:9629 [D loss: 0.544863, acc.: 78.91%] [G loss: 0.831695]\n",
      "epoch:10 step:9630 [D loss: 0.601770, acc.: 78.91%] [G loss: 0.822359]\n",
      "epoch:10 step:9631 [D loss: 0.480230, acc.: 90.62%] [G loss: 0.848186]\n",
      "epoch:10 step:9632 [D loss: 0.704477, acc.: 53.12%] [G loss: 0.716176]\n",
      "epoch:10 step:9633 [D loss: 0.620221, acc.: 69.53%] [G loss: 0.825904]\n",
      "epoch:10 step:9634 [D loss: 0.697381, acc.: 51.56%] [G loss: 0.752720]\n",
      "epoch:10 step:9635 [D loss: 0.529656, acc.: 73.44%] [G loss: 0.883162]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9636 [D loss: 0.677232, acc.: 54.69%] [G loss: 0.879054]\n",
      "epoch:10 step:9637 [D loss: 0.715688, acc.: 46.88%] [G loss: 0.717457]\n",
      "epoch:10 step:9638 [D loss: 0.793564, acc.: 29.69%] [G loss: 0.814719]\n",
      "epoch:10 step:9639 [D loss: 0.638685, acc.: 60.94%] [G loss: 0.630707]\n",
      "epoch:10 step:9640 [D loss: 0.679547, acc.: 54.69%] [G loss: 0.874052]\n",
      "epoch:10 step:9641 [D loss: 0.742554, acc.: 36.72%] [G loss: 0.826998]\n",
      "epoch:10 step:9642 [D loss: 0.675532, acc.: 55.47%] [G loss: 0.929457]\n",
      "epoch:10 step:9643 [D loss: 0.611296, acc.: 68.75%] [G loss: 0.899221]\n",
      "epoch:10 step:9644 [D loss: 0.601190, acc.: 73.44%] [G loss: 0.990605]\n",
      "epoch:10 step:9645 [D loss: 0.664722, acc.: 60.16%] [G loss: 0.942458]\n",
      "epoch:10 step:9646 [D loss: 0.609316, acc.: 60.94%] [G loss: 1.007780]\n",
      "epoch:10 step:9647 [D loss: 0.641586, acc.: 59.38%] [G loss: 0.869008]\n",
      "epoch:10 step:9648 [D loss: 0.670530, acc.: 67.97%] [G loss: 0.885238]\n",
      "epoch:10 step:9649 [D loss: 0.472271, acc.: 88.28%] [G loss: 0.783996]\n",
      "epoch:10 step:9650 [D loss: 0.808894, acc.: 28.91%] [G loss: 0.712436]\n",
      "epoch:10 step:9651 [D loss: 0.712093, acc.: 46.09%] [G loss: 0.805912]\n",
      "epoch:10 step:9652 [D loss: 0.656922, acc.: 62.50%] [G loss: 0.799481]\n",
      "epoch:10 step:9653 [D loss: 0.789488, acc.: 34.38%] [G loss: 0.844456]\n",
      "epoch:10 step:9654 [D loss: 0.765712, acc.: 41.41%] [G loss: 0.779476]\n",
      "epoch:10 step:9655 [D loss: 0.736845, acc.: 37.50%] [G loss: 0.798298]\n",
      "epoch:10 step:9656 [D loss: 0.692357, acc.: 53.12%] [G loss: 0.467547]\n",
      "epoch:10 step:9657 [D loss: 0.587232, acc.: 70.31%] [G loss: 0.771363]\n",
      "epoch:10 step:9658 [D loss: 0.536763, acc.: 74.22%] [G loss: 0.751464]\n",
      "epoch:10 step:9659 [D loss: 0.450060, acc.: 75.78%] [G loss: 0.834210]\n",
      "epoch:10 step:9660 [D loss: 0.605513, acc.: 69.53%] [G loss: 0.820847]\n",
      "epoch:10 step:9661 [D loss: 0.678933, acc.: 60.16%] [G loss: 0.337837]\n",
      "epoch:10 step:9662 [D loss: 0.393197, acc.: 86.72%] [G loss: 0.887952]\n",
      "epoch:10 step:9663 [D loss: 0.555819, acc.: 80.47%] [G loss: 0.785911]\n",
      "epoch:10 step:9664 [D loss: 0.580059, acc.: 78.12%] [G loss: 0.854476]\n",
      "epoch:10 step:9665 [D loss: 0.709580, acc.: 45.31%] [G loss: 0.845042]\n",
      "epoch:10 step:9666 [D loss: 0.697613, acc.: 50.00%] [G loss: 0.905927]\n",
      "epoch:10 step:9667 [D loss: 0.652747, acc.: 60.16%] [G loss: 0.555616]\n",
      "epoch:10 step:9668 [D loss: 0.699104, acc.: 49.22%] [G loss: 0.890661]\n",
      "epoch:10 step:9669 [D loss: 0.770457, acc.: 40.62%] [G loss: 0.970502]\n",
      "epoch:10 step:9670 [D loss: 0.639711, acc.: 64.84%] [G loss: 0.966041]\n",
      "epoch:10 step:9671 [D loss: 0.725286, acc.: 47.66%] [G loss: 0.960267]\n",
      "epoch:10 step:9672 [D loss: 0.954375, acc.: 28.91%] [G loss: 1.068439]\n",
      "epoch:10 step:9673 [D loss: 0.662977, acc.: 57.81%] [G loss: 0.850935]\n",
      "epoch:10 step:9674 [D loss: 0.690353, acc.: 55.47%] [G loss: 0.919438]\n",
      "epoch:10 step:9675 [D loss: 0.710130, acc.: 53.12%] [G loss: 0.855665]\n",
      "epoch:10 step:9676 [D loss: 0.691770, acc.: 57.03%] [G loss: 0.837082]\n",
      "epoch:10 step:9677 [D loss: 0.682810, acc.: 50.78%] [G loss: 0.799040]\n",
      "epoch:10 step:9678 [D loss: 0.765412, acc.: 42.19%] [G loss: 0.665413]\n",
      "epoch:10 step:9679 [D loss: 0.616412, acc.: 65.62%] [G loss: 0.863584]\n",
      "epoch:10 step:9680 [D loss: 0.716820, acc.: 50.00%] [G loss: 0.747101]\n",
      "epoch:10 step:9681 [D loss: 0.730785, acc.: 44.53%] [G loss: 0.851802]\n",
      "epoch:10 step:9682 [D loss: 0.657734, acc.: 54.69%] [G loss: 0.807732]\n",
      "epoch:10 step:9683 [D loss: 0.505326, acc.: 75.00%] [G loss: 0.811945]\n",
      "epoch:10 step:9684 [D loss: 0.445437, acc.: 80.47%] [G loss: 0.856429]\n",
      "epoch:10 step:9685 [D loss: 0.644463, acc.: 71.88%] [G loss: 0.896195]\n",
      "epoch:10 step:9686 [D loss: 0.733152, acc.: 42.19%] [G loss: 0.803952]\n",
      "epoch:10 step:9687 [D loss: 0.738949, acc.: 37.50%] [G loss: 0.779083]\n",
      "epoch:10 step:9688 [D loss: 0.652252, acc.: 60.16%] [G loss: 0.859696]\n",
      "epoch:10 step:9689 [D loss: 0.654917, acc.: 53.91%] [G loss: 0.754951]\n",
      "epoch:10 step:9690 [D loss: 0.653660, acc.: 58.59%] [G loss: 0.866200]\n",
      "epoch:10 step:9691 [D loss: 0.753278, acc.: 47.66%] [G loss: 0.924374]\n",
      "epoch:10 step:9692 [D loss: 0.631381, acc.: 64.06%] [G loss: 0.914525]\n",
      "epoch:10 step:9693 [D loss: 0.725084, acc.: 44.53%] [G loss: 0.892718]\n",
      "epoch:10 step:9694 [D loss: 0.672472, acc.: 55.47%] [G loss: 0.916512]\n",
      "epoch:10 step:9695 [D loss: 0.608337, acc.: 73.44%] [G loss: 0.850291]\n",
      "epoch:10 step:9696 [D loss: 0.667455, acc.: 58.59%] [G loss: 0.889721]\n",
      "epoch:10 step:9697 [D loss: 0.523704, acc.: 85.16%] [G loss: 0.828356]\n",
      "epoch:10 step:9698 [D loss: 0.589936, acc.: 75.78%] [G loss: 0.738053]\n",
      "epoch:10 step:9699 [D loss: 0.696590, acc.: 52.34%] [G loss: 0.983020]\n",
      "epoch:10 step:9700 [D loss: 0.725535, acc.: 46.09%] [G loss: 0.993679]\n",
      "epoch:10 step:9701 [D loss: 0.764426, acc.: 36.72%] [G loss: 0.830523]\n",
      "epoch:10 step:9702 [D loss: 0.753298, acc.: 42.19%] [G loss: 0.705303]\n",
      "epoch:10 step:9703 [D loss: 0.697912, acc.: 55.47%] [G loss: 0.840852]\n",
      "epoch:10 step:9704 [D loss: 0.696421, acc.: 49.22%] [G loss: 0.701437]\n",
      "epoch:10 step:9705 [D loss: 0.719978, acc.: 50.78%] [G loss: 0.736921]\n",
      "epoch:10 step:9706 [D loss: 0.654253, acc.: 62.50%] [G loss: 0.694879]\n",
      "epoch:10 step:9707 [D loss: 0.697827, acc.: 55.47%] [G loss: 0.757553]\n",
      "epoch:10 step:9708 [D loss: 0.692538, acc.: 54.69%] [G loss: 0.744663]\n",
      "epoch:10 step:9709 [D loss: 0.657603, acc.: 62.50%] [G loss: 0.673259]\n",
      "epoch:10 step:9710 [D loss: 0.689946, acc.: 51.56%] [G loss: 0.733786]\n",
      "epoch:10 step:9711 [D loss: 0.743660, acc.: 39.84%] [G loss: 0.708183]\n",
      "epoch:10 step:9712 [D loss: 0.737350, acc.: 46.09%] [G loss: 0.708708]\n",
      "epoch:10 step:9713 [D loss: 0.458580, acc.: 78.12%] [G loss: 0.743116]\n",
      "epoch:10 step:9714 [D loss: 0.529969, acc.: 81.25%] [G loss: 0.760494]\n",
      "epoch:10 step:9715 [D loss: 0.482041, acc.: 75.78%] [G loss: 0.788309]\n",
      "epoch:10 step:9716 [D loss: 0.473524, acc.: 71.88%] [G loss: 0.894215]\n",
      "epoch:10 step:9717 [D loss: 0.552607, acc.: 59.38%] [G loss: 0.962084]\n",
      "epoch:10 step:9718 [D loss: 0.703526, acc.: 49.22%] [G loss: 0.977926]\n",
      "epoch:10 step:9719 [D loss: 0.707338, acc.: 57.81%] [G loss: 0.773494]\n",
      "epoch:10 step:9720 [D loss: 0.670690, acc.: 66.41%] [G loss: 0.842785]\n",
      "epoch:10 step:9721 [D loss: 0.699364, acc.: 49.22%] [G loss: 0.863073]\n",
      "epoch:10 step:9722 [D loss: 0.681102, acc.: 55.47%] [G loss: 0.756413]\n",
      "epoch:10 step:9723 [D loss: 0.669789, acc.: 57.03%] [G loss: 0.816899]\n",
      "epoch:10 step:9724 [D loss: 0.651888, acc.: 64.06%] [G loss: 0.810398]\n",
      "epoch:10 step:9725 [D loss: 0.698520, acc.: 53.91%] [G loss: 0.773557]\n",
      "epoch:10 step:9726 [D loss: 0.701243, acc.: 50.78%] [G loss: 0.591756]\n",
      "epoch:10 step:9727 [D loss: 0.665723, acc.: 60.16%] [G loss: 0.830022]\n",
      "epoch:10 step:9728 [D loss: 0.708222, acc.: 48.44%] [G loss: 0.852797]\n",
      "epoch:10 step:9729 [D loss: 0.659876, acc.: 62.50%] [G loss: 0.820275]\n",
      "epoch:10 step:9730 [D loss: 0.670438, acc.: 64.06%] [G loss: 0.854005]\n",
      "epoch:10 step:9731 [D loss: 0.675427, acc.: 56.25%] [G loss: 0.890492]\n",
      "epoch:10 step:9732 [D loss: 0.659857, acc.: 65.62%] [G loss: 0.774050]\n",
      "epoch:10 step:9733 [D loss: 0.565713, acc.: 81.25%] [G loss: 0.874541]\n",
      "epoch:10 step:9734 [D loss: 0.579522, acc.: 73.44%] [G loss: 0.950747]\n",
      "epoch:10 step:9735 [D loss: 0.616172, acc.: 65.62%] [G loss: 0.868132]\n",
      "epoch:10 step:9736 [D loss: 0.427814, acc.: 86.72%] [G loss: 0.831275]\n",
      "epoch:10 step:9737 [D loss: 0.680706, acc.: 53.91%] [G loss: 0.829877]\n",
      "epoch:10 step:9738 [D loss: 0.673713, acc.: 53.91%] [G loss: 0.712290]\n",
      "epoch:10 step:9739 [D loss: 0.690423, acc.: 59.38%] [G loss: 0.785726]\n",
      "epoch:10 step:9740 [D loss: 0.844270, acc.: 30.47%] [G loss: 0.870504]\n",
      "epoch:10 step:9741 [D loss: 0.664582, acc.: 61.72%] [G loss: 0.812794]\n",
      "epoch:10 step:9742 [D loss: 0.676522, acc.: 53.91%] [G loss: 0.680845]\n",
      "epoch:10 step:9743 [D loss: 0.740144, acc.: 42.19%] [G loss: 0.847857]\n",
      "epoch:10 step:9744 [D loss: 0.686635, acc.: 57.03%] [G loss: 0.762075]\n",
      "epoch:10 step:9745 [D loss: 0.700249, acc.: 50.00%] [G loss: 0.848365]\n",
      "epoch:10 step:9746 [D loss: 0.725302, acc.: 42.97%] [G loss: 0.794980]\n",
      "epoch:10 step:9747 [D loss: 0.476973, acc.: 93.75%] [G loss: 0.892782]\n",
      "epoch:10 step:9748 [D loss: 0.627707, acc.: 69.53%] [G loss: 0.766545]\n",
      "epoch:10 step:9749 [D loss: 0.700515, acc.: 48.44%] [G loss: 0.916743]\n",
      "epoch:10 step:9750 [D loss: 0.674924, acc.: 55.47%] [G loss: 0.883927]\n",
      "epoch:10 step:9751 [D loss: 0.594430, acc.: 67.19%] [G loss: 0.909762]\n",
      "epoch:10 step:9752 [D loss: 0.839866, acc.: 25.00%] [G loss: 0.893095]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9753 [D loss: 0.704529, acc.: 52.34%] [G loss: 0.951980]\n",
      "epoch:10 step:9754 [D loss: 0.683714, acc.: 59.38%] [G loss: 0.905506]\n",
      "epoch:10 step:9755 [D loss: 0.677553, acc.: 60.94%] [G loss: 0.777039]\n",
      "epoch:10 step:9756 [D loss: 0.672749, acc.: 60.94%] [G loss: 0.799126]\n",
      "epoch:10 step:9757 [D loss: 0.627600, acc.: 71.09%] [G loss: 0.761198]\n",
      "epoch:10 step:9758 [D loss: 0.635686, acc.: 59.38%] [G loss: 0.834555]\n",
      "epoch:10 step:9759 [D loss: 0.692583, acc.: 49.22%] [G loss: 0.834112]\n",
      "epoch:10 step:9760 [D loss: 0.724409, acc.: 52.34%] [G loss: 0.694309]\n",
      "epoch:10 step:9761 [D loss: 0.693610, acc.: 53.91%] [G loss: 0.828280]\n",
      "epoch:10 step:9762 [D loss: 0.699893, acc.: 51.56%] [G loss: 0.663224]\n",
      "epoch:10 step:9763 [D loss: 0.718572, acc.: 53.12%] [G loss: 0.650703]\n",
      "epoch:10 step:9764 [D loss: 0.745111, acc.: 38.28%] [G loss: 0.831093]\n",
      "epoch:10 step:9765 [D loss: 0.736585, acc.: 36.72%] [G loss: 0.668455]\n",
      "epoch:10 step:9766 [D loss: 0.572627, acc.: 72.66%] [G loss: 0.841603]\n",
      "epoch:10 step:9767 [D loss: 0.507741, acc.: 74.22%] [G loss: 0.830798]\n",
      "epoch:10 step:9768 [D loss: 0.379928, acc.: 93.75%] [G loss: 0.719688]\n",
      "epoch:10 step:9769 [D loss: 0.460313, acc.: 82.03%] [G loss: 0.802006]\n",
      "epoch:10 step:9770 [D loss: 0.444955, acc.: 82.81%] [G loss: 0.963841]\n",
      "epoch:10 step:9771 [D loss: 0.478514, acc.: 78.12%] [G loss: 0.850274]\n",
      "epoch:10 step:9772 [D loss: 0.349462, acc.: 86.72%] [G loss: 0.891932]\n",
      "epoch:10 step:9773 [D loss: 0.506038, acc.: 86.72%] [G loss: 0.952335]\n",
      "epoch:10 step:9774 [D loss: 0.295402, acc.: 96.09%] [G loss: 1.031667]\n",
      "epoch:10 step:9775 [D loss: 0.271360, acc.: 97.66%] [G loss: 1.041080]\n",
      "epoch:10 step:9776 [D loss: 0.257900, acc.: 98.44%] [G loss: 1.118234]\n",
      "epoch:10 step:9777 [D loss: 0.287333, acc.: 95.31%] [G loss: 1.144456]\n",
      "epoch:10 step:9778 [D loss: 0.429926, acc.: 93.75%] [G loss: 1.209077]\n",
      "epoch:10 step:9779 [D loss: 0.243358, acc.: 96.09%] [G loss: 1.317966]\n",
      "epoch:10 step:9780 [D loss: 0.340230, acc.: 91.41%] [G loss: 1.309568]\n",
      "epoch:10 step:9781 [D loss: 0.800913, acc.: 51.56%] [G loss: 1.052014]\n",
      "epoch:10 step:9782 [D loss: 0.321041, acc.: 92.19%] [G loss: 0.695106]\n",
      "epoch:10 step:9783 [D loss: 0.302691, acc.: 99.22%] [G loss: 0.940975]\n",
      "epoch:10 step:9784 [D loss: 0.250571, acc.: 96.88%] [G loss: 1.155737]\n",
      "epoch:10 step:9785 [D loss: 0.263468, acc.: 99.22%] [G loss: 1.211619]\n",
      "epoch:10 step:9786 [D loss: 0.373636, acc.: 81.25%] [G loss: 1.533436]\n",
      "epoch:10 step:9787 [D loss: 0.276980, acc.: 96.09%] [G loss: 1.226418]\n",
      "epoch:10 step:9788 [D loss: 1.223683, acc.: 52.34%] [G loss: 0.897038]\n",
      "epoch:10 step:9789 [D loss: 0.605737, acc.: 67.19%] [G loss: 1.636355]\n",
      "epoch:10 step:9790 [D loss: 0.835275, acc.: 50.78%] [G loss: 1.153378]\n",
      "epoch:10 step:9791 [D loss: 1.453854, acc.: 33.59%] [G loss: 0.860796]\n",
      "epoch:10 step:9792 [D loss: 1.219280, acc.: 20.31%] [G loss: 1.038771]\n",
      "epoch:10 step:9793 [D loss: 0.924492, acc.: 43.75%] [G loss: 1.053891]\n",
      "epoch:10 step:9794 [D loss: 0.726481, acc.: 50.78%] [G loss: 1.014012]\n",
      "epoch:10 step:9795 [D loss: 0.714068, acc.: 52.34%] [G loss: 0.911877]\n",
      "epoch:10 step:9796 [D loss: 0.835998, acc.: 42.19%] [G loss: 0.883482]\n",
      "epoch:10 step:9797 [D loss: 0.704176, acc.: 58.59%] [G loss: 0.884690]\n",
      "epoch:10 step:9798 [D loss: 0.624744, acc.: 69.53%] [G loss: 0.908848]\n",
      "epoch:10 step:9799 [D loss: 0.729771, acc.: 51.56%] [G loss: 0.949748]\n",
      "epoch:10 step:9800 [D loss: 0.674674, acc.: 60.94%] [G loss: 0.905501]\n",
      "##############\n",
      "[4.50445308 2.26540428 7.1737438  6.28346973 4.53464218 6.51017164\n",
      " 5.69938221 5.17270555 6.3141194  4.98686967]\n",
      "##########\n",
      "epoch:10 step:9801 [D loss: 0.732263, acc.: 50.00%] [G loss: 0.847096]\n",
      "epoch:10 step:9802 [D loss: 0.718145, acc.: 49.22%] [G loss: 0.891919]\n",
      "epoch:10 step:9803 [D loss: 0.686960, acc.: 53.12%] [G loss: 1.007682]\n",
      "epoch:10 step:9804 [D loss: 0.676903, acc.: 51.56%] [G loss: 1.005960]\n",
      "epoch:10 step:9805 [D loss: 0.679254, acc.: 50.00%] [G loss: 0.935923]\n",
      "epoch:10 step:9806 [D loss: 0.649367, acc.: 57.81%] [G loss: 0.912445]\n",
      "epoch:10 step:9807 [D loss: 0.734341, acc.: 41.41%] [G loss: 0.996053]\n",
      "epoch:10 step:9808 [D loss: 0.751399, acc.: 46.09%] [G loss: 0.929378]\n",
      "epoch:10 step:9809 [D loss: 0.707060, acc.: 50.78%] [G loss: 0.821028]\n",
      "epoch:10 step:9810 [D loss: 0.690969, acc.: 53.91%] [G loss: 0.922858]\n",
      "epoch:10 step:9811 [D loss: 0.677884, acc.: 53.91%] [G loss: 0.953848]\n",
      "epoch:10 step:9812 [D loss: 0.678122, acc.: 54.69%] [G loss: 0.877289]\n",
      "epoch:10 step:9813 [D loss: 0.614803, acc.: 64.84%] [G loss: 0.916127]\n",
      "epoch:10 step:9814 [D loss: 0.666233, acc.: 53.12%] [G loss: 0.922606]\n",
      "epoch:10 step:9815 [D loss: 0.677833, acc.: 65.62%] [G loss: 0.923281]\n",
      "epoch:10 step:9816 [D loss: 0.667201, acc.: 59.38%] [G loss: 0.915432]\n",
      "epoch:10 step:9817 [D loss: 0.675759, acc.: 59.38%] [G loss: 0.877857]\n",
      "epoch:10 step:9818 [D loss: 0.590858, acc.: 82.03%] [G loss: 0.860009]\n",
      "epoch:10 step:9819 [D loss: 0.562799, acc.: 83.59%] [G loss: 1.030415]\n",
      "epoch:10 step:9820 [D loss: 0.581316, acc.: 79.69%] [G loss: 0.910521]\n",
      "epoch:10 step:9821 [D loss: 0.443670, acc.: 95.31%] [G loss: 0.949244]\n",
      "epoch:10 step:9822 [D loss: 0.456733, acc.: 90.62%] [G loss: 1.109508]\n",
      "epoch:10 step:9823 [D loss: 0.492281, acc.: 88.28%] [G loss: 1.105437]\n",
      "epoch:10 step:9824 [D loss: 0.602526, acc.: 70.31%] [G loss: 1.394499]\n",
      "epoch:10 step:9825 [D loss: 0.674971, acc.: 58.59%] [G loss: 1.153194]\n",
      "epoch:10 step:9826 [D loss: 0.373716, acc.: 88.28%] [G loss: 1.255832]\n",
      "epoch:10 step:9827 [D loss: 0.439035, acc.: 89.84%] [G loss: 1.202084]\n",
      "epoch:10 step:9828 [D loss: 0.702067, acc.: 53.91%] [G loss: 1.298257]\n",
      "epoch:10 step:9829 [D loss: 0.627938, acc.: 63.28%] [G loss: 1.182148]\n",
      "epoch:10 step:9830 [D loss: 0.748445, acc.: 39.06%] [G loss: 0.748618]\n",
      "epoch:10 step:9831 [D loss: 1.041899, acc.: 13.28%] [G loss: 0.689966]\n",
      "epoch:10 step:9832 [D loss: 0.933594, acc.: 28.12%] [G loss: 0.588521]\n",
      "epoch:10 step:9833 [D loss: 0.891781, acc.: 22.66%] [G loss: 0.626554]\n",
      "epoch:10 step:9834 [D loss: 0.666702, acc.: 57.81%] [G loss: 0.680995]\n",
      "epoch:10 step:9835 [D loss: 0.599090, acc.: 69.53%] [G loss: 0.586741]\n",
      "epoch:10 step:9836 [D loss: 0.717821, acc.: 52.34%] [G loss: 0.681407]\n",
      "epoch:10 step:9837 [D loss: 0.637058, acc.: 60.94%] [G loss: 0.974564]\n",
      "epoch:10 step:9838 [D loss: 0.596690, acc.: 62.50%] [G loss: 0.612995]\n",
      "epoch:10 step:9839 [D loss: 0.621734, acc.: 68.75%] [G loss: 0.817159]\n",
      "epoch:10 step:9840 [D loss: 0.576732, acc.: 71.88%] [G loss: 0.820052]\n",
      "epoch:10 step:9841 [D loss: 0.580312, acc.: 77.34%] [G loss: 0.800582]\n",
      "epoch:10 step:9842 [D loss: 0.757679, acc.: 42.19%] [G loss: 0.899170]\n",
      "epoch:10 step:9843 [D loss: 0.938311, acc.: 14.84%] [G loss: 0.750521]\n",
      "epoch:10 step:9844 [D loss: 0.834900, acc.: 24.22%] [G loss: 0.759436]\n",
      "epoch:10 step:9845 [D loss: 0.735867, acc.: 48.44%] [G loss: 0.759980]\n",
      "epoch:10 step:9846 [D loss: 0.707365, acc.: 53.91%] [G loss: 0.869239]\n",
      "epoch:10 step:9847 [D loss: 0.714907, acc.: 46.88%] [G loss: 0.813939]\n",
      "epoch:10 step:9848 [D loss: 0.658528, acc.: 59.38%] [G loss: 0.866121]\n",
      "epoch:10 step:9849 [D loss: 0.713928, acc.: 46.88%] [G loss: 0.835361]\n",
      "epoch:10 step:9850 [D loss: 0.624933, acc.: 72.66%] [G loss: 0.878224]\n",
      "epoch:10 step:9851 [D loss: 0.656777, acc.: 59.38%] [G loss: 0.825000]\n",
      "epoch:10 step:9852 [D loss: 0.656246, acc.: 60.16%] [G loss: 0.853853]\n",
      "epoch:10 step:9853 [D loss: 0.674911, acc.: 54.69%] [G loss: 0.816636]\n",
      "epoch:10 step:9854 [D loss: 0.645795, acc.: 61.72%] [G loss: 0.891816]\n",
      "epoch:10 step:9855 [D loss: 0.659193, acc.: 59.38%] [G loss: 0.987150]\n",
      "epoch:10 step:9856 [D loss: 0.648396, acc.: 61.72%] [G loss: 0.890115]\n",
      "epoch:10 step:9857 [D loss: 0.666115, acc.: 61.72%] [G loss: 0.908529]\n",
      "epoch:10 step:9858 [D loss: 0.677212, acc.: 62.50%] [G loss: 0.856935]\n",
      "epoch:10 step:9859 [D loss: 0.738135, acc.: 41.41%] [G loss: 0.745020]\n",
      "epoch:10 step:9860 [D loss: 0.708050, acc.: 44.53%] [G loss: 0.779641]\n",
      "epoch:10 step:9861 [D loss: 0.697950, acc.: 53.12%] [G loss: 0.737345]\n",
      "epoch:10 step:9862 [D loss: 0.696003, acc.: 47.66%] [G loss: 0.812649]\n",
      "epoch:10 step:9863 [D loss: 0.750979, acc.: 39.84%] [G loss: 0.791061]\n",
      "epoch:10 step:9864 [D loss: 0.687724, acc.: 57.03%] [G loss: 0.744258]\n",
      "epoch:10 step:9865 [D loss: 0.655603, acc.: 63.28%] [G loss: 0.781293]\n",
      "epoch:10 step:9866 [D loss: 0.687716, acc.: 52.34%] [G loss: 0.746161]\n",
      "epoch:10 step:9867 [D loss: 0.565264, acc.: 80.47%] [G loss: 0.844610]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9868 [D loss: 0.548690, acc.: 74.22%] [G loss: 0.859943]\n",
      "epoch:10 step:9869 [D loss: 0.522468, acc.: 75.00%] [G loss: 0.839098]\n",
      "epoch:10 step:9870 [D loss: 0.634326, acc.: 61.72%] [G loss: 0.794809]\n",
      "epoch:10 step:9871 [D loss: 0.771145, acc.: 45.31%] [G loss: 0.801216]\n",
      "epoch:10 step:9872 [D loss: 0.690491, acc.: 49.22%] [G loss: 0.835212]\n",
      "epoch:10 step:9873 [D loss: 0.796815, acc.: 40.62%] [G loss: 0.844839]\n",
      "epoch:10 step:9874 [D loss: 0.662265, acc.: 61.72%] [G loss: 0.763384]\n",
      "epoch:10 step:9875 [D loss: 0.634502, acc.: 66.41%] [G loss: 0.832594]\n",
      "epoch:10 step:9876 [D loss: 0.801639, acc.: 35.94%] [G loss: 0.825867]\n",
      "epoch:10 step:9877 [D loss: 0.636194, acc.: 64.06%] [G loss: 0.815603]\n",
      "epoch:10 step:9878 [D loss: 0.671359, acc.: 54.69%] [G loss: 0.815022]\n",
      "epoch:10 step:9879 [D loss: 0.665034, acc.: 59.38%] [G loss: 0.807218]\n",
      "epoch:10 step:9880 [D loss: 0.617396, acc.: 77.34%] [G loss: 0.878101]\n",
      "epoch:10 step:9881 [D loss: 0.552259, acc.: 83.59%] [G loss: 0.780860]\n",
      "epoch:10 step:9882 [D loss: 0.504863, acc.: 86.72%] [G loss: 0.918050]\n",
      "epoch:10 step:9883 [D loss: 0.484424, acc.: 88.28%] [G loss: 1.050037]\n",
      "epoch:10 step:9884 [D loss: 0.476532, acc.: 85.16%] [G loss: 1.003661]\n",
      "epoch:10 step:9885 [D loss: 0.498870, acc.: 75.00%] [G loss: 0.970456]\n",
      "epoch:10 step:9886 [D loss: 0.672447, acc.: 61.72%] [G loss: 0.973023]\n",
      "epoch:10 step:9887 [D loss: 0.704894, acc.: 56.25%] [G loss: 0.928791]\n",
      "epoch:10 step:9888 [D loss: 0.721189, acc.: 53.91%] [G loss: 0.553387]\n",
      "epoch:10 step:9889 [D loss: 0.686069, acc.: 59.38%] [G loss: 0.908456]\n",
      "epoch:10 step:9890 [D loss: 0.674219, acc.: 57.03%] [G loss: 0.888901]\n",
      "epoch:10 step:9891 [D loss: 0.888363, acc.: 28.91%] [G loss: 0.591200]\n",
      "epoch:10 step:9892 [D loss: 0.636979, acc.: 65.62%] [G loss: 0.875667]\n",
      "epoch:10 step:9893 [D loss: 0.644978, acc.: 57.03%] [G loss: 0.960099]\n",
      "epoch:10 step:9894 [D loss: 0.500125, acc.: 87.50%] [G loss: 0.979296]\n",
      "epoch:10 step:9895 [D loss: 0.703058, acc.: 56.25%] [G loss: 0.911361]\n",
      "epoch:10 step:9896 [D loss: 0.684389, acc.: 55.47%] [G loss: 0.776524]\n",
      "epoch:10 step:9897 [D loss: 0.525134, acc.: 84.38%] [G loss: 0.880260]\n",
      "epoch:10 step:9898 [D loss: 0.718100, acc.: 53.91%] [G loss: 0.778808]\n",
      "epoch:10 step:9899 [D loss: 0.726471, acc.: 50.00%] [G loss: 0.804784]\n",
      "epoch:10 step:9900 [D loss: 0.710678, acc.: 56.25%] [G loss: 0.729829]\n",
      "epoch:10 step:9901 [D loss: 0.707296, acc.: 50.78%] [G loss: 0.568462]\n",
      "epoch:10 step:9902 [D loss: 0.735290, acc.: 39.06%] [G loss: 0.861542]\n",
      "epoch:10 step:9903 [D loss: 0.704036, acc.: 53.12%] [G loss: 0.911788]\n",
      "epoch:10 step:9904 [D loss: 0.630695, acc.: 61.72%] [G loss: 0.903435]\n",
      "epoch:10 step:9905 [D loss: 0.490367, acc.: 85.94%] [G loss: 0.940885]\n",
      "epoch:10 step:9906 [D loss: 0.520905, acc.: 78.12%] [G loss: 0.956497]\n",
      "epoch:10 step:9907 [D loss: 0.622183, acc.: 64.84%] [G loss: 0.666077]\n",
      "epoch:10 step:9908 [D loss: 0.820382, acc.: 47.66%] [G loss: 0.671741]\n",
      "epoch:10 step:9909 [D loss: 0.589873, acc.: 71.88%] [G loss: 0.824742]\n",
      "epoch:10 step:9910 [D loss: 0.719237, acc.: 55.47%] [G loss: 1.075696]\n",
      "epoch:10 step:9911 [D loss: 0.682861, acc.: 53.12%] [G loss: 0.981267]\n",
      "epoch:10 step:9912 [D loss: 0.628913, acc.: 64.06%] [G loss: 1.167583]\n",
      "epoch:10 step:9913 [D loss: 0.553195, acc.: 69.53%] [G loss: 1.196216]\n",
      "epoch:10 step:9914 [D loss: 0.639979, acc.: 60.94%] [G loss: 1.137704]\n",
      "epoch:10 step:9915 [D loss: 0.617595, acc.: 64.06%] [G loss: 1.076620]\n",
      "epoch:10 step:9916 [D loss: 0.575359, acc.: 66.41%] [G loss: 1.054430]\n",
      "epoch:10 step:9917 [D loss: 0.628323, acc.: 62.50%] [G loss: 0.992700]\n",
      "epoch:10 step:9918 [D loss: 0.548109, acc.: 75.00%] [G loss: 1.003182]\n",
      "epoch:10 step:9919 [D loss: 0.525643, acc.: 68.75%] [G loss: 1.107818]\n",
      "epoch:10 step:9920 [D loss: 0.327301, acc.: 93.75%] [G loss: 1.162266]\n",
      "epoch:10 step:9921 [D loss: 0.649582, acc.: 60.16%] [G loss: 1.213090]\n",
      "epoch:10 step:9922 [D loss: 0.525758, acc.: 78.12%] [G loss: 1.458513]\n",
      "epoch:10 step:9923 [D loss: 0.613340, acc.: 63.28%] [G loss: 1.206154]\n",
      "epoch:10 step:9924 [D loss: 0.439048, acc.: 88.28%] [G loss: 0.939818]\n",
      "epoch:10 step:9925 [D loss: 0.612836, acc.: 70.31%] [G loss: 1.286507]\n",
      "epoch:10 step:9926 [D loss: 0.732118, acc.: 56.25%] [G loss: 1.225569]\n",
      "epoch:10 step:9927 [D loss: 0.659820, acc.: 60.16%] [G loss: 1.318414]\n",
      "epoch:10 step:9928 [D loss: 0.616985, acc.: 64.06%] [G loss: 1.135468]\n",
      "epoch:10 step:9929 [D loss: 0.988854, acc.: 35.94%] [G loss: 1.097767]\n",
      "epoch:10 step:9930 [D loss: 0.864335, acc.: 37.50%] [G loss: 1.088538]\n",
      "epoch:10 step:9931 [D loss: 0.626821, acc.: 62.50%] [G loss: 1.170129]\n",
      "epoch:10 step:9932 [D loss: 0.648480, acc.: 64.84%] [G loss: 1.095859]\n",
      "epoch:10 step:9933 [D loss: 0.671877, acc.: 57.81%] [G loss: 0.913651]\n",
      "epoch:10 step:9934 [D loss: 0.624477, acc.: 62.50%] [G loss: 0.734697]\n",
      "epoch:10 step:9935 [D loss: 0.709313, acc.: 53.91%] [G loss: 0.728139]\n",
      "epoch:10 step:9936 [D loss: 0.704578, acc.: 57.03%] [G loss: 0.916799]\n",
      "epoch:10 step:9937 [D loss: 0.540978, acc.: 73.44%] [G loss: 0.981839]\n",
      "epoch:10 step:9938 [D loss: 0.629068, acc.: 71.09%] [G loss: 1.080875]\n",
      "epoch:10 step:9939 [D loss: 0.717858, acc.: 53.12%] [G loss: 0.987571]\n",
      "epoch:10 step:9940 [D loss: 0.643709, acc.: 67.19%] [G loss: 1.018067]\n",
      "epoch:10 step:9941 [D loss: 0.653755, acc.: 59.38%] [G loss: 0.981217]\n",
      "epoch:10 step:9942 [D loss: 0.678120, acc.: 57.03%] [G loss: 0.888371]\n",
      "epoch:10 step:9943 [D loss: 0.624835, acc.: 67.97%] [G loss: 0.890840]\n",
      "epoch:10 step:9944 [D loss: 0.615540, acc.: 65.62%] [G loss: 0.909400]\n",
      "epoch:10 step:9945 [D loss: 0.628621, acc.: 68.75%] [G loss: 0.905030]\n",
      "epoch:10 step:9946 [D loss: 0.635279, acc.: 63.28%] [G loss: 0.813669]\n",
      "epoch:10 step:9947 [D loss: 0.550748, acc.: 72.66%] [G loss: 0.967737]\n",
      "epoch:10 step:9948 [D loss: 0.470558, acc.: 78.12%] [G loss: 0.945761]\n",
      "epoch:10 step:9949 [D loss: 0.622389, acc.: 61.72%] [G loss: 0.919947]\n",
      "epoch:10 step:9950 [D loss: 0.713096, acc.: 52.34%] [G loss: 0.708995]\n",
      "epoch:10 step:9951 [D loss: 0.644819, acc.: 63.28%] [G loss: 0.826647]\n",
      "epoch:10 step:9952 [D loss: 0.674909, acc.: 56.25%] [G loss: 0.796874]\n",
      "epoch:10 step:9953 [D loss: 0.704810, acc.: 51.56%] [G loss: 0.690193]\n",
      "epoch:10 step:9954 [D loss: 0.727093, acc.: 46.88%] [G loss: 0.757933]\n",
      "epoch:10 step:9955 [D loss: 0.711461, acc.: 54.69%] [G loss: 0.699878]\n",
      "epoch:10 step:9956 [D loss: 0.704467, acc.: 51.56%] [G loss: 0.805275]\n",
      "epoch:10 step:9957 [D loss: 0.489687, acc.: 77.34%] [G loss: 0.770793]\n",
      "epoch:10 step:9958 [D loss: 0.408492, acc.: 89.84%] [G loss: 0.889972]\n",
      "epoch:10 step:9959 [D loss: 0.385108, acc.: 89.84%] [G loss: 0.917263]\n",
      "epoch:10 step:9960 [D loss: 0.778376, acc.: 39.84%] [G loss: 0.727193]\n",
      "epoch:10 step:9961 [D loss: 0.854554, acc.: 32.03%] [G loss: 0.847025]\n",
      "epoch:10 step:9962 [D loss: 0.664044, acc.: 57.81%] [G loss: 0.889048]\n",
      "epoch:10 step:9963 [D loss: 0.673751, acc.: 56.25%] [G loss: 0.955611]\n",
      "epoch:10 step:9964 [D loss: 0.719376, acc.: 42.19%] [G loss: 0.971835]\n",
      "epoch:10 step:9965 [D loss: 0.474253, acc.: 89.06%] [G loss: 0.749620]\n",
      "epoch:10 step:9966 [D loss: 0.678533, acc.: 57.03%] [G loss: 0.868001]\n",
      "epoch:10 step:9967 [D loss: 0.644745, acc.: 67.19%] [G loss: 0.961573]\n",
      "epoch:10 step:9968 [D loss: 0.600739, acc.: 70.31%] [G loss: 0.821807]\n",
      "epoch:10 step:9969 [D loss: 0.662374, acc.: 52.34%] [G loss: 0.865900]\n",
      "epoch:10 step:9970 [D loss: 0.462211, acc.: 85.16%] [G loss: 0.881076]\n",
      "epoch:10 step:9971 [D loss: 0.434907, acc.: 92.19%] [G loss: 0.949963]\n",
      "epoch:10 step:9972 [D loss: 0.468328, acc.: 89.06%] [G loss: 0.949651]\n",
      "epoch:10 step:9973 [D loss: 0.709964, acc.: 50.78%] [G loss: 0.913189]\n",
      "epoch:10 step:9974 [D loss: 0.571644, acc.: 57.81%] [G loss: 0.772828]\n",
      "epoch:10 step:9975 [D loss: 0.663442, acc.: 57.81%] [G loss: 1.002283]\n",
      "epoch:10 step:9976 [D loss: 0.740168, acc.: 49.22%] [G loss: 0.902243]\n",
      "epoch:10 step:9977 [D loss: 0.756215, acc.: 47.66%] [G loss: 0.819998]\n",
      "epoch:10 step:9978 [D loss: 0.641572, acc.: 66.41%] [G loss: 0.897922]\n",
      "epoch:10 step:9979 [D loss: 0.527240, acc.: 82.81%] [G loss: 0.745491]\n",
      "epoch:10 step:9980 [D loss: 0.644936, acc.: 58.59%] [G loss: 0.772157]\n",
      "epoch:10 step:9981 [D loss: 0.703645, acc.: 56.25%] [G loss: 0.908066]\n",
      "epoch:10 step:9982 [D loss: 0.780128, acc.: 42.19%] [G loss: 0.908974]\n",
      "epoch:10 step:9983 [D loss: 0.623207, acc.: 67.97%] [G loss: 0.906418]\n",
      "epoch:10 step:9984 [D loss: 0.664074, acc.: 58.59%] [G loss: 0.710618]\n",
      "epoch:10 step:9985 [D loss: 0.654936, acc.: 57.81%] [G loss: 0.951176]\n",
      "epoch:10 step:9986 [D loss: 0.620167, acc.: 70.31%] [G loss: 0.948583]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9987 [D loss: 0.611421, acc.: 67.19%] [G loss: 0.881772]\n",
      "epoch:10 step:9988 [D loss: 0.624426, acc.: 65.62%] [G loss: 0.870297]\n",
      "epoch:10 step:9989 [D loss: 0.659759, acc.: 58.59%] [G loss: 0.520467]\n",
      "epoch:10 step:9990 [D loss: 0.598132, acc.: 66.41%] [G loss: 0.391925]\n",
      "epoch:10 step:9991 [D loss: 0.677086, acc.: 58.59%] [G loss: 0.873303]\n",
      "epoch:10 step:9992 [D loss: 0.936016, acc.: 34.38%] [G loss: 0.769441]\n",
      "epoch:10 step:9993 [D loss: 0.624727, acc.: 64.06%] [G loss: 0.902430]\n",
      "epoch:10 step:9994 [D loss: 0.575781, acc.: 71.09%] [G loss: 0.955709]\n",
      "epoch:10 step:9995 [D loss: 0.611749, acc.: 69.53%] [G loss: 0.930845]\n",
      "epoch:10 step:9996 [D loss: 0.746783, acc.: 50.00%] [G loss: 0.947450]\n",
      "epoch:10 step:9997 [D loss: 0.634115, acc.: 64.06%] [G loss: 1.014032]\n",
      "epoch:10 step:9998 [D loss: 0.674800, acc.: 60.16%] [G loss: 0.957972]\n",
      "epoch:10 step:9999 [D loss: 0.553001, acc.: 74.22%] [G loss: 0.888011]\n",
      "epoch:10 step:10000 [D loss: 0.536987, acc.: 78.12%] [G loss: 0.961347]\n",
      "##############\n",
      "[3.75591892 2.3063522  6.31627343 5.57666521 4.17046122 6.2369247\n",
      " 5.04468876 5.16550231 5.95790126 5.04995692]\n",
      "##########\n",
      "epoch:10 step:10001 [D loss: 0.697574, acc.: 62.50%] [G loss: 0.886634]\n",
      "epoch:10 step:10002 [D loss: 0.464191, acc.: 85.16%] [G loss: 0.992189]\n",
      "epoch:10 step:10003 [D loss: 0.447662, acc.: 78.12%] [G loss: 0.881648]\n",
      "epoch:10 step:10004 [D loss: 0.552294, acc.: 71.09%] [G loss: 0.733173]\n",
      "epoch:10 step:10005 [D loss: 0.661930, acc.: 58.59%] [G loss: 0.600017]\n",
      "epoch:10 step:10006 [D loss: 0.669595, acc.: 54.69%] [G loss: 0.778437]\n",
      "epoch:10 step:10007 [D loss: 0.667217, acc.: 59.38%] [G loss: 0.835584]\n",
      "epoch:10 step:10008 [D loss: 0.715915, acc.: 53.12%] [G loss: 0.900242]\n",
      "epoch:10 step:10009 [D loss: 0.902940, acc.: 24.22%] [G loss: 0.637339]\n",
      "epoch:10 step:10010 [D loss: 0.910925, acc.: 29.69%] [G loss: 0.859512]\n",
      "epoch:10 step:10011 [D loss: 0.746098, acc.: 40.62%] [G loss: 0.751436]\n",
      "epoch:10 step:10012 [D loss: 0.793234, acc.: 41.41%] [G loss: 1.019940]\n",
      "epoch:10 step:10013 [D loss: 0.798338, acc.: 37.50%] [G loss: 0.823364]\n",
      "epoch:10 step:10014 [D loss: 0.577250, acc.: 71.09%] [G loss: 0.912241]\n",
      "epoch:10 step:10015 [D loss: 0.677633, acc.: 54.69%] [G loss: 0.938059]\n",
      "epoch:10 step:10016 [D loss: 0.672257, acc.: 57.03%] [G loss: 0.989582]\n",
      "epoch:10 step:10017 [D loss: 0.785132, acc.: 44.53%] [G loss: 0.886111]\n",
      "epoch:10 step:10018 [D loss: 0.643344, acc.: 69.53%] [G loss: 0.984004]\n",
      "epoch:10 step:10019 [D loss: 0.666848, acc.: 59.38%] [G loss: 1.014636]\n",
      "epoch:10 step:10020 [D loss: 0.616799, acc.: 69.53%] [G loss: 0.886540]\n",
      "epoch:10 step:10021 [D loss: 0.684457, acc.: 55.47%] [G loss: 0.931918]\n",
      "epoch:10 step:10022 [D loss: 0.731773, acc.: 53.91%] [G loss: 0.943967]\n",
      "epoch:10 step:10023 [D loss: 0.694243, acc.: 57.03%] [G loss: 0.987786]\n",
      "epoch:10 step:10024 [D loss: 0.709973, acc.: 57.03%] [G loss: 0.918742]\n",
      "epoch:10 step:10025 [D loss: 0.745541, acc.: 46.09%] [G loss: 0.853055]\n",
      "epoch:10 step:10026 [D loss: 0.726606, acc.: 44.53%] [G loss: 0.888034]\n",
      "epoch:10 step:10027 [D loss: 0.718819, acc.: 49.22%] [G loss: 0.831563]\n",
      "epoch:10 step:10028 [D loss: 0.679827, acc.: 57.81%] [G loss: 0.816815]\n",
      "epoch:10 step:10029 [D loss: 0.671825, acc.: 60.94%] [G loss: 0.809999]\n",
      "epoch:10 step:10030 [D loss: 0.640626, acc.: 65.62%] [G loss: 0.835905]\n",
      "epoch:10 step:10031 [D loss: 0.651307, acc.: 64.06%] [G loss: 0.869156]\n",
      "epoch:10 step:10032 [D loss: 0.655835, acc.: 59.38%] [G loss: 0.864853]\n",
      "epoch:10 step:10033 [D loss: 0.538733, acc.: 77.34%] [G loss: 0.907385]\n",
      "epoch:10 step:10034 [D loss: 0.454103, acc.: 82.03%] [G loss: 0.880144]\n",
      "epoch:10 step:10035 [D loss: 0.432178, acc.: 86.72%] [G loss: 0.927992]\n",
      "epoch:10 step:10036 [D loss: 0.595493, acc.: 74.22%] [G loss: 0.930602]\n",
      "epoch:10 step:10037 [D loss: 0.636840, acc.: 64.06%] [G loss: 0.952044]\n",
      "epoch:10 step:10038 [D loss: 0.664520, acc.: 59.38%] [G loss: 0.907896]\n",
      "epoch:10 step:10039 [D loss: 0.668322, acc.: 62.50%] [G loss: 0.841949]\n",
      "epoch:10 step:10040 [D loss: 0.691514, acc.: 56.25%] [G loss: 0.826801]\n",
      "epoch:10 step:10041 [D loss: 0.685221, acc.: 56.25%] [G loss: 0.848058]\n",
      "epoch:10 step:10042 [D loss: 0.727524, acc.: 50.78%] [G loss: 0.784031]\n",
      "epoch:10 step:10043 [D loss: 0.617751, acc.: 64.84%] [G loss: 0.838963]\n",
      "epoch:10 step:10044 [D loss: 0.647215, acc.: 63.28%] [G loss: 0.842713]\n",
      "epoch:10 step:10045 [D loss: 0.720254, acc.: 46.09%] [G loss: 0.805717]\n",
      "epoch:10 step:10046 [D loss: 0.669898, acc.: 59.38%] [G loss: 0.771081]\n",
      "epoch:10 step:10047 [D loss: 0.670515, acc.: 57.81%] [G loss: 0.797031]\n",
      "epoch:10 step:10048 [D loss: 0.692215, acc.: 53.91%] [G loss: 0.810460]\n",
      "epoch:10 step:10049 [D loss: 0.659425, acc.: 61.72%] [G loss: 0.806735]\n",
      "epoch:10 step:10050 [D loss: 0.680461, acc.: 55.47%] [G loss: 0.709227]\n",
      "epoch:10 step:10051 [D loss: 0.666006, acc.: 63.28%] [G loss: 0.817928]\n",
      "epoch:10 step:10052 [D loss: 0.643173, acc.: 64.06%] [G loss: 0.752545]\n",
      "epoch:10 step:10053 [D loss: 0.666615, acc.: 60.16%] [G loss: 0.842998]\n",
      "epoch:10 step:10054 [D loss: 0.577652, acc.: 75.78%] [G loss: 0.780318]\n",
      "epoch:10 step:10055 [D loss: 0.640795, acc.: 69.53%] [G loss: 0.775540]\n",
      "epoch:10 step:10056 [D loss: 0.528023, acc.: 76.56%] [G loss: 0.892231]\n",
      "epoch:10 step:10057 [D loss: 0.629168, acc.: 66.41%] [G loss: 0.806307]\n",
      "epoch:10 step:10058 [D loss: 0.648914, acc.: 61.72%] [G loss: 0.876970]\n",
      "epoch:10 step:10059 [D loss: 0.701874, acc.: 53.12%] [G loss: 0.431979]\n",
      "epoch:10 step:10060 [D loss: 0.668623, acc.: 61.72%] [G loss: 0.793933]\n",
      "epoch:10 step:10061 [D loss: 0.657552, acc.: 59.38%] [G loss: 0.804457]\n",
      "epoch:10 step:10062 [D loss: 0.667140, acc.: 61.72%] [G loss: 0.681822]\n",
      "epoch:10 step:10063 [D loss: 0.659328, acc.: 60.16%] [G loss: 0.841437]\n",
      "epoch:10 step:10064 [D loss: 0.729566, acc.: 44.53%] [G loss: 0.925238]\n",
      "epoch:10 step:10065 [D loss: 0.603851, acc.: 73.44%] [G loss: 0.832129]\n",
      "epoch:10 step:10066 [D loss: 0.524857, acc.: 70.31%] [G loss: 0.940872]\n",
      "epoch:10 step:10067 [D loss: 0.458093, acc.: 77.34%] [G loss: 0.908697]\n",
      "epoch:10 step:10068 [D loss: 0.486169, acc.: 88.28%] [G loss: 1.022393]\n",
      "epoch:10 step:10069 [D loss: 0.757073, acc.: 47.66%] [G loss: 0.874710]\n",
      "epoch:10 step:10070 [D loss: 0.380686, acc.: 92.19%] [G loss: 1.006012]\n",
      "epoch:10 step:10071 [D loss: 0.353792, acc.: 98.44%] [G loss: 0.760689]\n",
      "epoch:10 step:10072 [D loss: 0.639971, acc.: 60.16%] [G loss: 0.905801]\n",
      "epoch:10 step:10073 [D loss: 0.906367, acc.: 25.00%] [G loss: 1.105566]\n",
      "epoch:10 step:10074 [D loss: 0.686382, acc.: 60.94%] [G loss: 0.763894]\n",
      "epoch:10 step:10075 [D loss: 0.702073, acc.: 55.47%] [G loss: 1.185447]\n",
      "epoch:10 step:10076 [D loss: 0.415235, acc.: 89.84%] [G loss: 1.064903]\n",
      "epoch:10 step:10077 [D loss: 0.470106, acc.: 77.34%] [G loss: 1.105799]\n",
      "epoch:10 step:10078 [D loss: 0.534238, acc.: 70.31%] [G loss: 1.286549]\n",
      "epoch:10 step:10079 [D loss: 0.626026, acc.: 64.06%] [G loss: 1.170528]\n",
      "epoch:10 step:10080 [D loss: 0.855974, acc.: 38.28%] [G loss: 1.234547]\n",
      "epoch:10 step:10081 [D loss: 0.651515, acc.: 57.81%] [G loss: 1.193943]\n",
      "epoch:10 step:10082 [D loss: 0.757374, acc.: 45.31%] [G loss: 1.120371]\n",
      "epoch:10 step:10083 [D loss: 0.711155, acc.: 57.81%] [G loss: 0.905406]\n",
      "epoch:10 step:10084 [D loss: 0.544518, acc.: 68.75%] [G loss: 1.077236]\n",
      "epoch:10 step:10085 [D loss: 0.799377, acc.: 36.72%] [G loss: 1.033024]\n",
      "epoch:10 step:10086 [D loss: 0.703229, acc.: 56.25%] [G loss: 0.995045]\n",
      "epoch:10 step:10087 [D loss: 0.708741, acc.: 50.00%] [G loss: 1.050036]\n",
      "epoch:10 step:10088 [D loss: 0.601949, acc.: 66.41%] [G loss: 1.138448]\n",
      "epoch:10 step:10089 [D loss: 0.600226, acc.: 62.50%] [G loss: 1.087994]\n",
      "epoch:10 step:10090 [D loss: 0.566200, acc.: 71.88%] [G loss: 1.036577]\n",
      "epoch:10 step:10091 [D loss: 0.546231, acc.: 72.66%] [G loss: 1.160376]\n",
      "epoch:10 step:10092 [D loss: 0.767999, acc.: 50.00%] [G loss: 0.905898]\n",
      "epoch:10 step:10093 [D loss: 0.688292, acc.: 57.81%] [G loss: 0.952480]\n",
      "epoch:10 step:10094 [D loss: 0.487336, acc.: 87.50%] [G loss: 1.109879]\n",
      "epoch:10 step:10095 [D loss: 0.475235, acc.: 87.50%] [G loss: 1.282756]\n",
      "epoch:10 step:10096 [D loss: 0.590876, acc.: 67.97%] [G loss: 0.980137]\n",
      "epoch:10 step:10097 [D loss: 0.856617, acc.: 40.62%] [G loss: 0.971902]\n",
      "epoch:10 step:10098 [D loss: 0.736495, acc.: 46.09%] [G loss: 0.844905]\n",
      "epoch:10 step:10099 [D loss: 0.725223, acc.: 45.31%] [G loss: 0.791354]\n",
      "epoch:10 step:10100 [D loss: 0.646365, acc.: 62.50%] [G loss: 0.697653]\n",
      "epoch:10 step:10101 [D loss: 0.717697, acc.: 50.78%] [G loss: 0.849227]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:10102 [D loss: 0.591785, acc.: 65.62%] [G loss: 0.700035]\n",
      "epoch:10 step:10103 [D loss: 0.633315, acc.: 64.84%] [G loss: 0.825704]\n",
      "epoch:10 step:10104 [D loss: 0.747761, acc.: 46.88%] [G loss: 0.838522]\n",
      "epoch:10 step:10105 [D loss: 0.697026, acc.: 55.47%] [G loss: 0.815353]\n",
      "epoch:10 step:10106 [D loss: 0.620252, acc.: 70.31%] [G loss: 0.832537]\n",
      "epoch:10 step:10107 [D loss: 0.683088, acc.: 56.25%] [G loss: 0.809776]\n",
      "epoch:10 step:10108 [D loss: 0.719550, acc.: 50.78%] [G loss: 0.870650]\n",
      "epoch:10 step:10109 [D loss: 0.608945, acc.: 73.44%] [G loss: 0.836303]\n",
      "epoch:10 step:10110 [D loss: 0.719031, acc.: 48.44%] [G loss: 0.781338]\n",
      "epoch:10 step:10111 [D loss: 0.621042, acc.: 69.53%] [G loss: 0.783924]\n",
      "epoch:10 step:10112 [D loss: 0.637288, acc.: 62.50%] [G loss: 0.778363]\n",
      "epoch:10 step:10113 [D loss: 0.617787, acc.: 61.72%] [G loss: 0.812717]\n",
      "epoch:10 step:10114 [D loss: 0.692720, acc.: 50.00%] [G loss: 0.713631]\n",
      "epoch:10 step:10115 [D loss: 0.566336, acc.: 76.56%] [G loss: 0.765807]\n",
      "epoch:10 step:10116 [D loss: 0.469162, acc.: 89.06%] [G loss: 0.919501]\n",
      "epoch:10 step:10117 [D loss: 0.626002, acc.: 68.75%] [G loss: 0.862588]\n",
      "epoch:10 step:10118 [D loss: 0.654998, acc.: 64.06%] [G loss: 0.868015]\n",
      "epoch:10 step:10119 [D loss: 0.646804, acc.: 66.41%] [G loss: 0.741830]\n",
      "epoch:10 step:10120 [D loss: 0.620492, acc.: 64.06%] [G loss: 0.624503]\n",
      "epoch:10 step:10121 [D loss: 0.715979, acc.: 50.78%] [G loss: 0.790898]\n",
      "epoch:10 step:10122 [D loss: 0.774734, acc.: 42.19%] [G loss: 0.418489]\n",
      "epoch:10 step:10123 [D loss: 0.673558, acc.: 59.38%] [G loss: 0.769009]\n",
      "epoch:10 step:10124 [D loss: 0.423614, acc.: 83.59%] [G loss: 0.861257]\n",
      "epoch:10 step:10125 [D loss: 0.503821, acc.: 77.34%] [G loss: 0.886362]\n",
      "epoch:10 step:10126 [D loss: 0.509120, acc.: 68.75%] [G loss: 0.928460]\n",
      "epoch:10 step:10127 [D loss: 0.436919, acc.: 86.72%] [G loss: 1.014296]\n",
      "epoch:10 step:10128 [D loss: 0.479256, acc.: 89.84%] [G loss: 0.937077]\n",
      "epoch:10 step:10129 [D loss: 0.712180, acc.: 53.91%] [G loss: 0.966031]\n",
      "epoch:10 step:10130 [D loss: 0.770678, acc.: 36.72%] [G loss: 0.891725]\n",
      "epoch:10 step:10131 [D loss: 0.647230, acc.: 63.28%] [G loss: 1.087181]\n",
      "epoch:10 step:10132 [D loss: 0.551291, acc.: 78.91%] [G loss: 0.839786]\n",
      "epoch:10 step:10133 [D loss: 0.504563, acc.: 86.72%] [G loss: 0.635407]\n",
      "epoch:10 step:10134 [D loss: 0.337190, acc.: 85.16%] [G loss: 1.054131]\n",
      "epoch:10 step:10135 [D loss: 1.283898, acc.: 20.31%] [G loss: 0.907167]\n",
      "epoch:10 step:10136 [D loss: 0.596596, acc.: 69.53%] [G loss: 1.031673]\n",
      "epoch:10 step:10137 [D loss: 0.718036, acc.: 46.09%] [G loss: 1.086872]\n",
      "epoch:10 step:10138 [D loss: 0.614138, acc.: 68.75%] [G loss: 1.065714]\n",
      "epoch:10 step:10139 [D loss: 0.700453, acc.: 51.56%] [G loss: 0.977210]\n",
      "epoch:10 step:10140 [D loss: 0.748372, acc.: 39.06%] [G loss: 0.959761]\n",
      "epoch:10 step:10141 [D loss: 0.708255, acc.: 50.78%] [G loss: 0.889025]\n",
      "epoch:10 step:10142 [D loss: 0.746774, acc.: 48.44%] [G loss: 0.489782]\n",
      "epoch:10 step:10143 [D loss: 0.746126, acc.: 48.44%] [G loss: 0.875471]\n",
      "epoch:10 step:10144 [D loss: 0.674634, acc.: 56.25%] [G loss: 0.903280]\n",
      "epoch:10 step:10145 [D loss: 0.662798, acc.: 52.34%] [G loss: 0.668163]\n",
      "epoch:10 step:10146 [D loss: 0.739048, acc.: 47.66%] [G loss: 0.934234]\n",
      "epoch:10 step:10147 [D loss: 0.674935, acc.: 53.12%] [G loss: 0.904729]\n",
      "epoch:10 step:10148 [D loss: 0.715192, acc.: 48.44%] [G loss: 0.924705]\n",
      "epoch:10 step:10149 [D loss: 0.797573, acc.: 37.50%] [G loss: 0.992186]\n",
      "epoch:10 step:10150 [D loss: 0.480620, acc.: 86.72%] [G loss: 0.992239]\n",
      "epoch:10 step:10151 [D loss: 0.448732, acc.: 92.19%] [G loss: 0.953408]\n",
      "epoch:10 step:10152 [D loss: 0.595728, acc.: 70.31%] [G loss: 0.900333]\n",
      "epoch:10 step:10153 [D loss: 0.746296, acc.: 45.31%] [G loss: 1.036813]\n",
      "epoch:10 step:10154 [D loss: 0.659514, acc.: 59.38%] [G loss: 1.060439]\n",
      "epoch:10 step:10155 [D loss: 0.676502, acc.: 52.34%] [G loss: 1.009870]\n",
      "epoch:10 step:10156 [D loss: 0.572038, acc.: 74.22%] [G loss: 0.986271]\n",
      "epoch:10 step:10157 [D loss: 0.720094, acc.: 46.88%] [G loss: 1.035963]\n",
      "epoch:10 step:10158 [D loss: 0.760902, acc.: 42.97%] [G loss: 0.904455]\n",
      "epoch:10 step:10159 [D loss: 0.678107, acc.: 54.69%] [G loss: 1.030738]\n",
      "epoch:10 step:10160 [D loss: 0.694124, acc.: 53.91%] [G loss: 0.951063]\n",
      "epoch:10 step:10161 [D loss: 0.870123, acc.: 31.25%] [G loss: 0.900657]\n",
      "epoch:10 step:10162 [D loss: 0.564765, acc.: 74.22%] [G loss: 0.955261]\n",
      "epoch:10 step:10163 [D loss: 0.699602, acc.: 54.69%] [G loss: 0.941775]\n",
      "epoch:10 step:10164 [D loss: 0.523082, acc.: 86.72%] [G loss: 0.921741]\n",
      "epoch:10 step:10165 [D loss: 0.617135, acc.: 76.56%] [G loss: 0.884749]\n",
      "epoch:10 step:10166 [D loss: 0.918266, acc.: 50.78%] [G loss: 0.729561]\n",
      "epoch:10 step:10167 [D loss: 0.700501, acc.: 47.66%] [G loss: 0.911423]\n",
      "epoch:10 step:10168 [D loss: 0.795045, acc.: 24.22%] [G loss: 0.948102]\n",
      "epoch:10 step:10169 [D loss: 0.656605, acc.: 58.59%] [G loss: 0.837474]\n",
      "epoch:10 step:10170 [D loss: 0.555443, acc.: 73.44%] [G loss: 0.871867]\n",
      "epoch:10 step:10171 [D loss: 0.553814, acc.: 83.59%] [G loss: 0.991492]\n",
      "epoch:10 step:10172 [D loss: 0.321301, acc.: 91.41%] [G loss: 0.807917]\n",
      "epoch:10 step:10173 [D loss: 0.656750, acc.: 58.59%] [G loss: 0.888520]\n",
      "epoch:10 step:10174 [D loss: 0.666766, acc.: 62.50%] [G loss: 0.969127]\n",
      "epoch:10 step:10175 [D loss: 0.550282, acc.: 83.59%] [G loss: 0.949273]\n",
      "epoch:10 step:10176 [D loss: 0.620418, acc.: 72.66%] [G loss: 0.930472]\n",
      "epoch:10 step:10177 [D loss: 0.892343, acc.: 25.00%] [G loss: 0.887233]\n",
      "epoch:10 step:10178 [D loss: 0.575054, acc.: 73.44%] [G loss: 0.855410]\n",
      "epoch:10 step:10179 [D loss: 0.542997, acc.: 75.00%] [G loss: 0.934416]\n",
      "epoch:10 step:10180 [D loss: 0.539666, acc.: 73.44%] [G loss: 0.811295]\n",
      "epoch:10 step:10181 [D loss: 0.723061, acc.: 51.56%] [G loss: 1.122585]\n",
      "epoch:10 step:10182 [D loss: 0.872524, acc.: 31.25%] [G loss: 0.927764]\n",
      "epoch:10 step:10183 [D loss: 0.751352, acc.: 46.88%] [G loss: 0.969608]\n",
      "epoch:10 step:10184 [D loss: 0.668629, acc.: 59.38%] [G loss: 1.035513]\n",
      "epoch:10 step:10185 [D loss: 0.444377, acc.: 86.72%] [G loss: 1.095840]\n",
      "epoch:10 step:10186 [D loss: 0.401860, acc.: 93.75%] [G loss: 1.052043]\n",
      "epoch:10 step:10187 [D loss: 0.690367, acc.: 57.81%] [G loss: 1.059222]\n",
      "epoch:10 step:10188 [D loss: 0.527952, acc.: 82.03%] [G loss: 1.000261]\n",
      "epoch:10 step:10189 [D loss: 0.561868, acc.: 82.03%] [G loss: 0.859310]\n",
      "epoch:10 step:10190 [D loss: 0.805582, acc.: 32.81%] [G loss: 0.911464]\n",
      "epoch:10 step:10191 [D loss: 0.978466, acc.: 23.44%] [G loss: 0.475398]\n",
      "epoch:10 step:10192 [D loss: 0.771174, acc.: 36.72%] [G loss: 0.728693]\n",
      "epoch:10 step:10193 [D loss: 0.719670, acc.: 51.56%] [G loss: 0.833743]\n",
      "epoch:10 step:10194 [D loss: 0.557610, acc.: 74.22%] [G loss: 0.927337]\n",
      "epoch:10 step:10195 [D loss: 0.726125, acc.: 51.56%] [G loss: 0.949713]\n",
      "epoch:10 step:10196 [D loss: 0.642215, acc.: 64.84%] [G loss: 0.904293]\n",
      "epoch:10 step:10197 [D loss: 0.748197, acc.: 42.97%] [G loss: 0.938901]\n",
      "epoch:10 step:10198 [D loss: 0.706570, acc.: 46.09%] [G loss: 0.958913]\n",
      "epoch:10 step:10199 [D loss: 0.616259, acc.: 65.62%] [G loss: 0.993058]\n",
      "epoch:10 step:10200 [D loss: 0.641565, acc.: 62.50%] [G loss: 0.892385]\n",
      "##############\n",
      "[3.89090653 2.60499239 6.97570701 5.72567604 4.861291   6.14570469\n",
      " 5.25913183 5.40281954 5.72203273 4.96038057]\n",
      "##########\n",
      "epoch:10 step:10201 [D loss: 0.503628, acc.: 89.06%] [G loss: 0.884789]\n",
      "epoch:10 step:10202 [D loss: 0.517707, acc.: 81.25%] [G loss: 0.701558]\n",
      "epoch:10 step:10203 [D loss: 0.604964, acc.: 63.28%] [G loss: 0.713313]\n",
      "epoch:10 step:10204 [D loss: 0.924488, acc.: 16.41%] [G loss: 0.598466]\n",
      "epoch:10 step:10205 [D loss: 0.827818, acc.: 25.78%] [G loss: 0.857630]\n",
      "epoch:10 step:10206 [D loss: 0.744672, acc.: 42.19%] [G loss: 0.902221]\n",
      "epoch:10 step:10207 [D loss: 0.723108, acc.: 53.12%] [G loss: 0.760107]\n",
      "epoch:10 step:10208 [D loss: 0.659458, acc.: 59.38%] [G loss: 0.984443]\n",
      "epoch:10 step:10209 [D loss: 0.765311, acc.: 39.84%] [G loss: 0.776691]\n",
      "epoch:10 step:10210 [D loss: 0.794065, acc.: 32.81%] [G loss: 0.822699]\n",
      "epoch:10 step:10211 [D loss: 0.641110, acc.: 68.75%] [G loss: 0.922101]\n",
      "epoch:10 step:10212 [D loss: 0.665960, acc.: 57.03%] [G loss: 0.852207]\n",
      "epoch:10 step:10213 [D loss: 0.694134, acc.: 58.59%] [G loss: 0.839590]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:10214 [D loss: 1.129723, acc.: 50.78%] [G loss: 1.067434]\n",
      "epoch:10 step:10215 [D loss: 0.657990, acc.: 68.75%] [G loss: 0.952479]\n",
      "epoch:10 step:10216 [D loss: 0.677791, acc.: 56.25%] [G loss: 0.908318]\n",
      "epoch:10 step:10217 [D loss: 0.587108, acc.: 78.12%] [G loss: 0.962820]\n",
      "epoch:10 step:10218 [D loss: 0.577352, acc.: 72.66%] [G loss: 0.924175]\n",
      "epoch:10 step:10219 [D loss: 0.687573, acc.: 52.34%] [G loss: 0.848246]\n",
      "epoch:10 step:10220 [D loss: 0.593632, acc.: 74.22%] [G loss: 0.899987]\n",
      "epoch:10 step:10221 [D loss: 0.468790, acc.: 82.81%] [G loss: 2.487980]\n",
      "epoch:10 step:10222 [D loss: 0.438983, acc.: 85.16%] [G loss: 1.038720]\n",
      "epoch:10 step:10223 [D loss: 0.509822, acc.: 77.34%] [G loss: 0.882963]\n",
      "epoch:10 step:10224 [D loss: 0.437102, acc.: 82.81%] [G loss: 0.946713]\n",
      "epoch:10 step:10225 [D loss: 0.611562, acc.: 68.75%] [G loss: 0.947622]\n",
      "epoch:10 step:10226 [D loss: 0.663319, acc.: 60.16%] [G loss: 0.860579]\n",
      "epoch:10 step:10227 [D loss: 0.411217, acc.: 82.81%] [G loss: 0.855629]\n",
      "epoch:10 step:10228 [D loss: 0.783005, acc.: 43.75%] [G loss: 0.863221]\n",
      "epoch:10 step:10229 [D loss: 0.705847, acc.: 54.69%] [G loss: 0.906741]\n",
      "epoch:10 step:10230 [D loss: 0.654686, acc.: 59.38%] [G loss: 0.950457]\n",
      "epoch:10 step:10231 [D loss: 0.853312, acc.: 44.53%] [G loss: 0.894070]\n",
      "epoch:10 step:10232 [D loss: 0.709053, acc.: 52.34%] [G loss: 0.835859]\n",
      "epoch:10 step:10233 [D loss: 0.691895, acc.: 55.47%] [G loss: 0.867657]\n",
      "epoch:10 step:10234 [D loss: 0.694407, acc.: 48.44%] [G loss: 0.880896]\n",
      "epoch:10 step:10235 [D loss: 0.538820, acc.: 68.75%] [G loss: 0.895391]\n",
      "epoch:10 step:10236 [D loss: 0.570476, acc.: 75.78%] [G loss: 0.899453]\n",
      "epoch:10 step:10237 [D loss: 0.512713, acc.: 78.91%] [G loss: 0.918314]\n",
      "epoch:10 step:10238 [D loss: 0.658471, acc.: 59.38%] [G loss: 0.873045]\n",
      "epoch:10 step:10239 [D loss: 0.643902, acc.: 67.97%] [G loss: 0.897894]\n",
      "epoch:10 step:10240 [D loss: 0.650910, acc.: 58.59%] [G loss: 0.896092]\n",
      "epoch:10 step:10241 [D loss: 0.611897, acc.: 66.41%] [G loss: 0.697011]\n",
      "epoch:10 step:10242 [D loss: 0.469765, acc.: 70.31%] [G loss: 0.872337]\n",
      "epoch:10 step:10243 [D loss: 0.593503, acc.: 68.75%] [G loss: 0.936160]\n",
      "epoch:10 step:10244 [D loss: 0.819911, acc.: 50.00%] [G loss: 1.013304]\n",
      "epoch:10 step:10245 [D loss: 0.602167, acc.: 68.75%] [G loss: 0.965280]\n",
      "epoch:10 step:10246 [D loss: 0.693912, acc.: 53.91%] [G loss: 0.801370]\n",
      "epoch:10 step:10247 [D loss: 0.698471, acc.: 54.69%] [G loss: 0.595466]\n",
      "epoch:10 step:10248 [D loss: 0.774060, acc.: 42.19%] [G loss: 0.675824]\n",
      "epoch:10 step:10249 [D loss: 0.699439, acc.: 55.47%] [G loss: 0.784186]\n",
      "epoch:10 step:10250 [D loss: 0.707765, acc.: 48.44%] [G loss: 0.761014]\n",
      "epoch:10 step:10251 [D loss: 0.716783, acc.: 50.78%] [G loss: 0.869620]\n",
      "epoch:10 step:10252 [D loss: 0.606445, acc.: 64.84%] [G loss: 0.672099]\n",
      "epoch:10 step:10253 [D loss: 0.472573, acc.: 83.59%] [G loss: 0.901354]\n",
      "epoch:10 step:10254 [D loss: 0.461533, acc.: 85.94%] [G loss: 0.898287]\n",
      "epoch:10 step:10255 [D loss: 0.541256, acc.: 65.62%] [G loss: 0.524925]\n",
      "epoch:10 step:10256 [D loss: 0.361428, acc.: 92.19%] [G loss: 0.740301]\n",
      "epoch:10 step:10257 [D loss: 0.980207, acc.: 46.88%] [G loss: 0.703903]\n",
      "epoch:10 step:10258 [D loss: 0.821003, acc.: 42.97%] [G loss: 1.255197]\n",
      "epoch:10 step:10259 [D loss: 0.687875, acc.: 54.69%] [G loss: 0.909280]\n",
      "epoch:10 step:10260 [D loss: 0.638028, acc.: 68.75%] [G loss: 0.668285]\n",
      "epoch:10 step:10261 [D loss: 0.746554, acc.: 52.34%] [G loss: 1.068265]\n",
      "epoch:10 step:10262 [D loss: 0.822677, acc.: 39.06%] [G loss: 0.884572]\n",
      "epoch:10 step:10263 [D loss: 0.774021, acc.: 43.75%] [G loss: 1.013312]\n",
      "epoch:10 step:10264 [D loss: 0.695604, acc.: 53.91%] [G loss: 1.083583]\n",
      "epoch:10 step:10265 [D loss: 0.627675, acc.: 63.28%] [G loss: 1.114497]\n",
      "epoch:10 step:10266 [D loss: 0.598387, acc.: 64.06%] [G loss: 1.159161]\n",
      "epoch:10 step:10267 [D loss: 0.538609, acc.: 71.09%] [G loss: 1.220213]\n",
      "epoch:10 step:10268 [D loss: 0.521968, acc.: 73.44%] [G loss: 1.204348]\n",
      "epoch:10 step:10269 [D loss: 0.401442, acc.: 81.25%] [G loss: 1.108603]\n",
      "epoch:10 step:10270 [D loss: 0.435977, acc.: 86.72%] [G loss: 1.224613]\n",
      "epoch:10 step:10271 [D loss: 0.483197, acc.: 70.31%] [G loss: 1.433754]\n",
      "epoch:10 step:10272 [D loss: 0.534105, acc.: 71.88%] [G loss: 1.177103]\n",
      "epoch:10 step:10273 [D loss: 0.465786, acc.: 79.69%] [G loss: 1.523954]\n",
      "epoch:10 step:10274 [D loss: 1.201136, acc.: 35.94%] [G loss: 0.674562]\n",
      "epoch:10 step:10275 [D loss: 0.834531, acc.: 36.72%] [G loss: 0.642243]\n",
      "epoch:10 step:10276 [D loss: 0.881066, acc.: 28.91%] [G loss: 0.857743]\n",
      "epoch:10 step:10277 [D loss: 0.683859, acc.: 56.25%] [G loss: 0.937117]\n",
      "epoch:10 step:10278 [D loss: 0.658693, acc.: 60.94%] [G loss: 0.812886]\n",
      "epoch:10 step:10279 [D loss: 0.564865, acc.: 82.81%] [G loss: 0.934426]\n",
      "epoch:10 step:10280 [D loss: 0.737568, acc.: 42.19%] [G loss: 0.841676]\n",
      "epoch:10 step:10281 [D loss: 0.601480, acc.: 64.06%] [G loss: 0.915508]\n",
      "epoch:10 step:10282 [D loss: 0.283213, acc.: 96.09%] [G loss: 0.849921]\n",
      "epoch:10 step:10283 [D loss: 0.627713, acc.: 64.84%] [G loss: 0.938659]\n",
      "epoch:10 step:10284 [D loss: 0.648341, acc.: 63.28%] [G loss: 1.066683]\n",
      "epoch:10 step:10285 [D loss: 0.713975, acc.: 49.22%] [G loss: 0.780915]\n",
      "epoch:10 step:10286 [D loss: 0.785340, acc.: 45.31%] [G loss: 0.717173]\n",
      "epoch:10 step:10287 [D loss: 0.694733, acc.: 55.47%] [G loss: 0.760335]\n",
      "epoch:10 step:10288 [D loss: 0.598925, acc.: 75.78%] [G loss: 0.688255]\n",
      "epoch:10 step:10289 [D loss: 0.521704, acc.: 73.44%] [G loss: 0.777034]\n",
      "epoch:10 step:10290 [D loss: 0.791513, acc.: 34.38%] [G loss: 0.824500]\n",
      "epoch:10 step:10291 [D loss: 0.647157, acc.: 59.38%] [G loss: 0.699633]\n",
      "epoch:10 step:10292 [D loss: 0.621030, acc.: 63.28%] [G loss: 0.786602]\n",
      "epoch:10 step:10293 [D loss: 0.635002, acc.: 63.28%] [G loss: 0.722951]\n",
      "epoch:10 step:10294 [D loss: 0.525467, acc.: 61.72%] [G loss: 0.769401]\n",
      "epoch:10 step:10295 [D loss: 0.431253, acc.: 82.81%] [G loss: 0.743718]\n",
      "epoch:10 step:10296 [D loss: 0.330025, acc.: 89.06%] [G loss: 0.972015]\n",
      "epoch:10 step:10297 [D loss: 0.665346, acc.: 56.25%] [G loss: 0.951428]\n",
      "epoch:10 step:10298 [D loss: 0.800500, acc.: 46.09%] [G loss: 1.013730]\n",
      "epoch:10 step:10299 [D loss: 0.666247, acc.: 57.03%] [G loss: 0.960591]\n",
      "epoch:10 step:10300 [D loss: 0.647044, acc.: 71.09%] [G loss: 0.940084]\n",
      "epoch:10 step:10301 [D loss: 0.627077, acc.: 69.53%] [G loss: 0.950592]\n",
      "epoch:10 step:10302 [D loss: 0.657303, acc.: 60.16%] [G loss: 0.893922]\n",
      "epoch:10 step:10303 [D loss: 0.447892, acc.: 88.28%] [G loss: 0.832103]\n",
      "epoch:10 step:10304 [D loss: 0.502558, acc.: 78.12%] [G loss: 0.762917]\n",
      "epoch:10 step:10305 [D loss: 0.556665, acc.: 78.91%] [G loss: 0.859795]\n",
      "epoch:10 step:10306 [D loss: 0.423653, acc.: 67.97%] [G loss: 0.779337]\n",
      "epoch:10 step:10307 [D loss: 0.306095, acc.: 86.72%] [G loss: 1.180973]\n",
      "epoch:11 step:10308 [D loss: 0.747087, acc.: 51.56%] [G loss: 0.784311]\n",
      "epoch:11 step:10309 [D loss: 0.787115, acc.: 46.88%] [G loss: 0.981972]\n",
      "epoch:11 step:10310 [D loss: 0.895269, acc.: 25.78%] [G loss: 0.931396]\n",
      "epoch:11 step:10311 [D loss: 0.709036, acc.: 53.12%] [G loss: 1.095938]\n",
      "epoch:11 step:10312 [D loss: 0.712752, acc.: 46.88%] [G loss: 0.954294]\n",
      "epoch:11 step:10313 [D loss: 0.741273, acc.: 42.97%] [G loss: 0.912431]\n",
      "epoch:11 step:10314 [D loss: 0.690633, acc.: 53.91%] [G loss: 0.918307]\n",
      "epoch:11 step:10315 [D loss: 0.699445, acc.: 54.69%] [G loss: 0.902712]\n",
      "epoch:11 step:10316 [D loss: 0.697531, acc.: 54.69%] [G loss: 0.804883]\n",
      "epoch:11 step:10317 [D loss: 0.815682, acc.: 26.56%] [G loss: 0.782623]\n",
      "epoch:11 step:10318 [D loss: 0.716728, acc.: 48.44%] [G loss: 0.853648]\n",
      "epoch:11 step:10319 [D loss: 0.691092, acc.: 50.78%] [G loss: 0.878597]\n",
      "epoch:11 step:10320 [D loss: 0.717571, acc.: 48.44%] [G loss: 0.834898]\n",
      "epoch:11 step:10321 [D loss: 0.700048, acc.: 51.56%] [G loss: 0.844089]\n",
      "epoch:11 step:10322 [D loss: 0.660072, acc.: 64.84%] [G loss: 0.878828]\n",
      "epoch:11 step:10323 [D loss: 0.687316, acc.: 51.56%] [G loss: 0.842098]\n",
      "epoch:11 step:10324 [D loss: 0.722178, acc.: 47.66%] [G loss: 0.762610]\n",
      "epoch:11 step:10325 [D loss: 0.735522, acc.: 39.06%] [G loss: 0.803325]\n",
      "epoch:11 step:10326 [D loss: 0.723617, acc.: 45.31%] [G loss: 0.803191]\n",
      "epoch:11 step:10327 [D loss: 0.709218, acc.: 53.91%] [G loss: 0.864775]\n",
      "epoch:11 step:10328 [D loss: 0.796778, acc.: 51.56%] [G loss: 0.802058]\n",
      "epoch:11 step:10329 [D loss: 0.679170, acc.: 52.34%] [G loss: 0.874308]\n",
      "epoch:11 step:10330 [D loss: 0.669813, acc.: 56.25%] [G loss: 0.949953]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10331 [D loss: 0.717526, acc.: 53.12%] [G loss: 0.836274]\n",
      "epoch:11 step:10332 [D loss: 0.692365, acc.: 58.59%] [G loss: 0.801354]\n",
      "epoch:11 step:10333 [D loss: 0.689517, acc.: 52.34%] [G loss: 0.801169]\n",
      "epoch:11 step:10334 [D loss: 0.635374, acc.: 71.09%] [G loss: 0.838262]\n",
      "epoch:11 step:10335 [D loss: 0.664415, acc.: 64.06%] [G loss: 0.771712]\n",
      "epoch:11 step:10336 [D loss: 0.689254, acc.: 55.47%] [G loss: 0.795839]\n",
      "epoch:11 step:10337 [D loss: 0.683801, acc.: 54.69%] [G loss: 0.816640]\n",
      "epoch:11 step:10338 [D loss: 0.601929, acc.: 77.34%] [G loss: 1.092793]\n",
      "epoch:11 step:10339 [D loss: 0.638622, acc.: 65.62%] [G loss: 0.878987]\n",
      "epoch:11 step:10340 [D loss: 0.593713, acc.: 75.00%] [G loss: 1.103496]\n",
      "epoch:11 step:10341 [D loss: 0.563276, acc.: 81.25%] [G loss: 0.807624]\n",
      "epoch:11 step:10342 [D loss: 0.572153, acc.: 71.09%] [G loss: 1.226876]\n",
      "epoch:11 step:10343 [D loss: 0.472016, acc.: 82.03%] [G loss: 0.980433]\n",
      "epoch:11 step:10344 [D loss: 0.726747, acc.: 46.88%] [G loss: 0.786100]\n",
      "epoch:11 step:10345 [D loss: 0.923407, acc.: 32.03%] [G loss: 0.786168]\n",
      "epoch:11 step:10346 [D loss: 0.898337, acc.: 17.97%] [G loss: 0.754753]\n",
      "epoch:11 step:10347 [D loss: 0.802913, acc.: 39.84%] [G loss: 0.764461]\n",
      "epoch:11 step:10348 [D loss: 0.680581, acc.: 62.50%] [G loss: 0.754131]\n",
      "epoch:11 step:10349 [D loss: 0.665289, acc.: 60.94%] [G loss: 0.756876]\n",
      "epoch:11 step:10350 [D loss: 0.673068, acc.: 53.12%] [G loss: 0.726084]\n",
      "epoch:11 step:10351 [D loss: 0.674631, acc.: 57.03%] [G loss: 0.714745]\n",
      "epoch:11 step:10352 [D loss: 0.686849, acc.: 54.69%] [G loss: 0.651176]\n",
      "epoch:11 step:10353 [D loss: 0.644979, acc.: 66.41%] [G loss: 0.804798]\n",
      "epoch:11 step:10354 [D loss: 0.689909, acc.: 47.66%] [G loss: 0.794249]\n",
      "epoch:11 step:10355 [D loss: 0.686004, acc.: 51.56%] [G loss: 0.738815]\n",
      "epoch:11 step:10356 [D loss: 0.689035, acc.: 53.91%] [G loss: 0.751740]\n",
      "epoch:11 step:10357 [D loss: 0.638341, acc.: 62.50%] [G loss: 0.608723]\n",
      "epoch:11 step:10358 [D loss: 0.650858, acc.: 63.28%] [G loss: 0.647159]\n",
      "epoch:11 step:10359 [D loss: 0.675009, acc.: 53.91%] [G loss: 0.793222]\n",
      "epoch:11 step:10360 [D loss: 0.722764, acc.: 55.47%] [G loss: 0.798272]\n",
      "epoch:11 step:10361 [D loss: 0.687052, acc.: 57.03%] [G loss: 0.810327]\n",
      "epoch:11 step:10362 [D loss: 0.667230, acc.: 64.84%] [G loss: 0.751382]\n",
      "epoch:11 step:10363 [D loss: 0.673026, acc.: 57.81%] [G loss: 0.728723]\n",
      "epoch:11 step:10364 [D loss: 0.688696, acc.: 60.94%] [G loss: 0.794431]\n",
      "epoch:11 step:10365 [D loss: 0.645504, acc.: 67.19%] [G loss: 0.815889]\n",
      "epoch:11 step:10366 [D loss: 0.765771, acc.: 35.16%] [G loss: 0.834955]\n",
      "epoch:11 step:10367 [D loss: 0.673510, acc.: 54.69%] [G loss: 0.849241]\n",
      "epoch:11 step:10368 [D loss: 0.680023, acc.: 56.25%] [G loss: 0.803361]\n",
      "epoch:11 step:10369 [D loss: 0.670255, acc.: 57.03%] [G loss: 0.846848]\n",
      "epoch:11 step:10370 [D loss: 0.665554, acc.: 59.38%] [G loss: 0.811827]\n",
      "epoch:11 step:10371 [D loss: 0.666761, acc.: 62.50%] [G loss: 0.836253]\n",
      "epoch:11 step:10372 [D loss: 0.645905, acc.: 59.38%] [G loss: 0.838869]\n",
      "epoch:11 step:10373 [D loss: 0.679835, acc.: 54.69%] [G loss: 0.906312]\n",
      "epoch:11 step:10374 [D loss: 0.673321, acc.: 60.16%] [G loss: 0.834260]\n",
      "epoch:11 step:10375 [D loss: 0.629823, acc.: 60.94%] [G loss: 0.834848]\n",
      "epoch:11 step:10376 [D loss: 0.596380, acc.: 71.09%] [G loss: 0.871646]\n",
      "epoch:11 step:10377 [D loss: 0.709896, acc.: 51.56%] [G loss: 0.936121]\n",
      "epoch:11 step:10378 [D loss: 0.696363, acc.: 60.16%] [G loss: 0.788944]\n",
      "epoch:11 step:10379 [D loss: 0.684565, acc.: 57.03%] [G loss: 0.778551]\n",
      "epoch:11 step:10380 [D loss: 0.645663, acc.: 62.50%] [G loss: 0.825199]\n",
      "epoch:11 step:10381 [D loss: 0.678167, acc.: 60.16%] [G loss: 0.665448]\n",
      "epoch:11 step:10382 [D loss: 0.569775, acc.: 69.53%] [G loss: 0.840297]\n",
      "epoch:11 step:10383 [D loss: 0.621763, acc.: 70.31%] [G loss: 0.788396]\n",
      "epoch:11 step:10384 [D loss: 0.587177, acc.: 71.88%] [G loss: 0.812007]\n",
      "epoch:11 step:10385 [D loss: 0.722189, acc.: 51.56%] [G loss: 0.803607]\n",
      "epoch:11 step:10386 [D loss: 0.700716, acc.: 50.78%] [G loss: 0.822085]\n",
      "epoch:11 step:10387 [D loss: 0.687265, acc.: 57.03%] [G loss: 0.808830]\n",
      "epoch:11 step:10388 [D loss: 0.663441, acc.: 57.81%] [G loss: 0.829371]\n",
      "epoch:11 step:10389 [D loss: 0.650206, acc.: 60.94%] [G loss: 0.868941]\n",
      "epoch:11 step:10390 [D loss: 0.720873, acc.: 50.00%] [G loss: 0.873804]\n",
      "epoch:11 step:10391 [D loss: 0.633652, acc.: 62.50%] [G loss: 0.954415]\n",
      "epoch:11 step:10392 [D loss: 0.579259, acc.: 69.53%] [G loss: 0.838684]\n",
      "epoch:11 step:10393 [D loss: 0.624904, acc.: 69.53%] [G loss: 0.823285]\n",
      "epoch:11 step:10394 [D loss: 0.673867, acc.: 58.59%] [G loss: 0.803775]\n",
      "epoch:11 step:10395 [D loss: 0.643120, acc.: 62.50%] [G loss: 0.895169]\n",
      "epoch:11 step:10396 [D loss: 0.629749, acc.: 64.84%] [G loss: 0.873286]\n",
      "epoch:11 step:10397 [D loss: 0.634446, acc.: 64.06%] [G loss: 0.927597]\n",
      "epoch:11 step:10398 [D loss: 0.677742, acc.: 57.03%] [G loss: 0.790195]\n",
      "epoch:11 step:10399 [D loss: 0.623017, acc.: 66.41%] [G loss: 0.914159]\n",
      "epoch:11 step:10400 [D loss: 0.592668, acc.: 67.19%] [G loss: 0.710105]\n",
      "##############\n",
      "[3.98030638 2.32052829 6.73122044 5.58545439 4.32289679 5.8379076\n",
      " 5.41365275 4.98837442 5.86801261 5.05276801]\n",
      "##########\n",
      "epoch:11 step:10401 [D loss: 0.578682, acc.: 68.75%] [G loss: 0.907934]\n",
      "epoch:11 step:10402 [D loss: 0.755534, acc.: 45.31%] [G loss: 0.824366]\n",
      "epoch:11 step:10403 [D loss: 0.671066, acc.: 60.16%] [G loss: 0.880748]\n",
      "epoch:11 step:10404 [D loss: 0.704843, acc.: 51.56%] [G loss: 0.808250]\n",
      "epoch:11 step:10405 [D loss: 0.717398, acc.: 51.56%] [G loss: 0.805583]\n",
      "epoch:11 step:10406 [D loss: 0.764257, acc.: 46.09%] [G loss: 0.684914]\n",
      "epoch:11 step:10407 [D loss: 0.660214, acc.: 57.81%] [G loss: 0.719293]\n",
      "epoch:11 step:10408 [D loss: 0.687676, acc.: 51.56%] [G loss: 0.767051]\n",
      "epoch:11 step:10409 [D loss: 1.204633, acc.: 40.62%] [G loss: 0.839404]\n",
      "epoch:11 step:10410 [D loss: 0.694448, acc.: 50.00%] [G loss: 0.948465]\n",
      "epoch:11 step:10411 [D loss: 0.718897, acc.: 50.78%] [G loss: 0.928636]\n",
      "epoch:11 step:10412 [D loss: 0.592356, acc.: 73.44%] [G loss: 0.967052]\n",
      "epoch:11 step:10413 [D loss: 0.635613, acc.: 65.62%] [G loss: 1.011480]\n",
      "epoch:11 step:10414 [D loss: 0.528494, acc.: 82.03%] [G loss: 0.988041]\n",
      "epoch:11 step:10415 [D loss: 0.692925, acc.: 55.47%] [G loss: 0.883154]\n",
      "epoch:11 step:10416 [D loss: 0.672699, acc.: 62.50%] [G loss: 0.910432]\n",
      "epoch:11 step:10417 [D loss: 0.628334, acc.: 67.19%] [G loss: 0.828711]\n",
      "epoch:11 step:10418 [D loss: 0.650674, acc.: 64.06%] [G loss: 0.820622]\n",
      "epoch:11 step:10419 [D loss: 0.615180, acc.: 65.62%] [G loss: 0.866048]\n",
      "epoch:11 step:10420 [D loss: 0.604163, acc.: 68.75%] [G loss: 0.876853]\n",
      "epoch:11 step:10421 [D loss: 0.675349, acc.: 55.47%] [G loss: 0.861065]\n",
      "epoch:11 step:10422 [D loss: 0.623764, acc.: 60.16%] [G loss: 0.859218]\n",
      "epoch:11 step:10423 [D loss: 0.682714, acc.: 54.69%] [G loss: 1.392997]\n",
      "epoch:11 step:10424 [D loss: 0.748139, acc.: 47.66%] [G loss: 0.701660]\n",
      "epoch:11 step:10425 [D loss: 0.697168, acc.: 50.78%] [G loss: 0.684992]\n",
      "epoch:11 step:10426 [D loss: 0.727247, acc.: 57.03%] [G loss: 0.897518]\n",
      "epoch:11 step:10427 [D loss: 0.744951, acc.: 49.22%] [G loss: 0.847441]\n",
      "epoch:11 step:10428 [D loss: 0.670824, acc.: 59.38%] [G loss: 0.923815]\n",
      "epoch:11 step:10429 [D loss: 0.600959, acc.: 67.97%] [G loss: 1.032899]\n",
      "epoch:11 step:10430 [D loss: 0.618397, acc.: 63.28%] [G loss: 1.075779]\n",
      "epoch:11 step:10431 [D loss: 0.692622, acc.: 55.47%] [G loss: 1.066919]\n",
      "epoch:11 step:10432 [D loss: 0.601320, acc.: 68.75%] [G loss: 0.900621]\n",
      "epoch:11 step:10433 [D loss: 0.593420, acc.: 69.53%] [G loss: 0.909528]\n",
      "epoch:11 step:10434 [D loss: 0.658830, acc.: 67.19%] [G loss: 0.932029]\n",
      "epoch:11 step:10435 [D loss: 0.626151, acc.: 59.38%] [G loss: 0.908655]\n",
      "epoch:11 step:10436 [D loss: 0.662871, acc.: 61.72%] [G loss: 0.764225]\n",
      "epoch:11 step:10437 [D loss: 0.543953, acc.: 80.47%] [G loss: 0.788096]\n",
      "epoch:11 step:10438 [D loss: 0.686733, acc.: 54.69%] [G loss: 0.771356]\n",
      "epoch:11 step:10439 [D loss: 0.679319, acc.: 63.28%] [G loss: 1.041640]\n",
      "epoch:11 step:10440 [D loss: 0.720410, acc.: 53.12%] [G loss: 0.796259]\n",
      "epoch:11 step:10441 [D loss: 0.711259, acc.: 48.44%] [G loss: 0.799234]\n",
      "epoch:11 step:10442 [D loss: 0.706719, acc.: 51.56%] [G loss: 0.745186]\n",
      "epoch:11 step:10443 [D loss: 0.682236, acc.: 53.91%] [G loss: 0.748995]\n",
      "epoch:11 step:10444 [D loss: 0.666051, acc.: 57.81%] [G loss: 0.800121]\n",
      "epoch:11 step:10445 [D loss: 0.682358, acc.: 52.34%] [G loss: 0.797714]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10446 [D loss: 0.643755, acc.: 61.72%] [G loss: 0.843547]\n",
      "epoch:11 step:10447 [D loss: 0.672637, acc.: 58.59%] [G loss: 0.813737]\n",
      "epoch:11 step:10448 [D loss: 0.669941, acc.: 62.50%] [G loss: 0.840765]\n",
      "epoch:11 step:10449 [D loss: 0.741799, acc.: 41.41%] [G loss: 0.781727]\n",
      "epoch:11 step:10450 [D loss: 0.673894, acc.: 57.81%] [G loss: 0.797696]\n",
      "epoch:11 step:10451 [D loss: 0.668182, acc.: 58.59%] [G loss: 0.794655]\n",
      "epoch:11 step:10452 [D loss: 0.544803, acc.: 75.00%] [G loss: 0.726775]\n",
      "epoch:11 step:10453 [D loss: 0.647613, acc.: 67.97%] [G loss: 0.722631]\n",
      "epoch:11 step:10454 [D loss: 0.649953, acc.: 64.84%] [G loss: 0.795473]\n",
      "epoch:11 step:10455 [D loss: 0.673224, acc.: 53.91%] [G loss: 0.722014]\n",
      "epoch:11 step:10456 [D loss: 0.713252, acc.: 55.47%] [G loss: 0.738159]\n",
      "epoch:11 step:10457 [D loss: 0.495560, acc.: 83.59%] [G loss: 0.796970]\n",
      "epoch:11 step:10458 [D loss: 0.563737, acc.: 79.69%] [G loss: 0.670722]\n",
      "epoch:11 step:10459 [D loss: 0.660797, acc.: 58.59%] [G loss: 0.825555]\n",
      "epoch:11 step:10460 [D loss: 0.713285, acc.: 54.69%] [G loss: 0.793261]\n",
      "epoch:11 step:10461 [D loss: 0.681018, acc.: 51.56%] [G loss: 0.808033]\n",
      "epoch:11 step:10462 [D loss: 0.687421, acc.: 53.12%] [G loss: 0.754510]\n",
      "epoch:11 step:10463 [D loss: 0.685254, acc.: 56.25%] [G loss: 0.754841]\n",
      "epoch:11 step:10464 [D loss: 0.662058, acc.: 59.38%] [G loss: 0.784002]\n",
      "epoch:11 step:10465 [D loss: 0.721031, acc.: 48.44%] [G loss: 0.759805]\n",
      "epoch:11 step:10466 [D loss: 0.662477, acc.: 56.25%] [G loss: 0.808743]\n",
      "epoch:11 step:10467 [D loss: 0.628999, acc.: 64.84%] [G loss: 0.698045]\n",
      "epoch:11 step:10468 [D loss: 0.673184, acc.: 55.47%] [G loss: 0.778905]\n",
      "epoch:11 step:10469 [D loss: 0.660237, acc.: 62.50%] [G loss: 0.881673]\n",
      "epoch:11 step:10470 [D loss: 0.594390, acc.: 75.78%] [G loss: 0.710938]\n",
      "epoch:11 step:10471 [D loss: 0.559217, acc.: 81.25%] [G loss: 0.861040]\n",
      "epoch:11 step:10472 [D loss: 0.649542, acc.: 60.16%] [G loss: 0.815174]\n",
      "epoch:11 step:10473 [D loss: 0.696559, acc.: 50.78%] [G loss: 0.799394]\n",
      "epoch:11 step:10474 [D loss: 0.663433, acc.: 60.94%] [G loss: 0.893970]\n",
      "epoch:11 step:10475 [D loss: 0.686550, acc.: 57.03%] [G loss: 0.818091]\n",
      "epoch:11 step:10476 [D loss: 0.664549, acc.: 60.16%] [G loss: 0.994583]\n",
      "epoch:11 step:10477 [D loss: 0.588897, acc.: 73.44%] [G loss: 0.878724]\n",
      "epoch:11 step:10478 [D loss: 0.627846, acc.: 65.62%] [G loss: 0.829968]\n",
      "epoch:11 step:10479 [D loss: 0.631177, acc.: 66.41%] [G loss: 0.922024]\n",
      "epoch:11 step:10480 [D loss: 0.660426, acc.: 58.59%] [G loss: 0.864714]\n",
      "epoch:11 step:10481 [D loss: 0.646671, acc.: 63.28%] [G loss: 0.790482]\n",
      "epoch:11 step:10482 [D loss: 0.718199, acc.: 50.78%] [G loss: 0.752835]\n",
      "epoch:11 step:10483 [D loss: 0.664793, acc.: 57.81%] [G loss: 0.793363]\n",
      "epoch:11 step:10484 [D loss: 0.774108, acc.: 35.16%] [G loss: 0.842378]\n",
      "epoch:11 step:10485 [D loss: 0.678185, acc.: 58.59%] [G loss: 0.771572]\n",
      "epoch:11 step:10486 [D loss: 0.747016, acc.: 44.53%] [G loss: 0.757798]\n",
      "epoch:11 step:10487 [D loss: 0.770073, acc.: 39.06%] [G loss: 0.771152]\n",
      "epoch:11 step:10488 [D loss: 0.606244, acc.: 69.53%] [G loss: 0.839392]\n",
      "epoch:11 step:10489 [D loss: 0.750511, acc.: 39.84%] [G loss: 0.916694]\n",
      "epoch:11 step:10490 [D loss: 0.676179, acc.: 55.47%] [G loss: 0.880042]\n",
      "epoch:11 step:10491 [D loss: 0.676802, acc.: 54.69%] [G loss: 0.860335]\n",
      "epoch:11 step:10492 [D loss: 0.640931, acc.: 64.06%] [G loss: 0.868499]\n",
      "epoch:11 step:10493 [D loss: 0.717209, acc.: 46.88%] [G loss: 0.907204]\n",
      "epoch:11 step:10494 [D loss: 0.640579, acc.: 64.06%] [G loss: 0.952974]\n",
      "epoch:11 step:10495 [D loss: 0.644851, acc.: 62.50%] [G loss: 0.899220]\n",
      "epoch:11 step:10496 [D loss: 0.718865, acc.: 53.12%] [G loss: 0.948577]\n",
      "epoch:11 step:10497 [D loss: 0.619097, acc.: 66.41%] [G loss: 0.798392]\n",
      "epoch:11 step:10498 [D loss: 0.682014, acc.: 57.03%] [G loss: 0.859486]\n",
      "epoch:11 step:10499 [D loss: 0.587888, acc.: 65.62%] [G loss: 0.739711]\n",
      "epoch:11 step:10500 [D loss: 0.641039, acc.: 63.28%] [G loss: 0.822183]\n",
      "epoch:11 step:10501 [D loss: 0.514406, acc.: 83.59%] [G loss: 0.917297]\n",
      "epoch:11 step:10502 [D loss: 0.580318, acc.: 74.22%] [G loss: 0.950064]\n",
      "epoch:11 step:10503 [D loss: 0.608599, acc.: 67.19%] [G loss: 0.889388]\n",
      "epoch:11 step:10504 [D loss: 0.615344, acc.: 68.75%] [G loss: 0.733729]\n",
      "epoch:11 step:10505 [D loss: 0.650010, acc.: 64.84%] [G loss: 0.686368]\n",
      "epoch:11 step:10506 [D loss: 0.826059, acc.: 30.47%] [G loss: 0.933544]\n",
      "epoch:11 step:10507 [D loss: 0.870302, acc.: 35.16%] [G loss: 1.056350]\n",
      "epoch:11 step:10508 [D loss: 0.706288, acc.: 53.12%] [G loss: 0.979702]\n",
      "epoch:11 step:10509 [D loss: 0.708812, acc.: 48.44%] [G loss: 0.886332]\n",
      "epoch:11 step:10510 [D loss: 0.628853, acc.: 71.88%] [G loss: 0.972460]\n",
      "epoch:11 step:10511 [D loss: 0.487170, acc.: 84.38%] [G loss: 0.610283]\n",
      "epoch:11 step:10512 [D loss: 0.913180, acc.: 35.94%] [G loss: 0.938978]\n",
      "epoch:11 step:10513 [D loss: 0.597963, acc.: 75.00%] [G loss: 1.039199]\n",
      "epoch:11 step:10514 [D loss: 0.598577, acc.: 68.75%] [G loss: 0.793276]\n",
      "epoch:11 step:10515 [D loss: 0.575415, acc.: 74.22%] [G loss: 1.056700]\n",
      "epoch:11 step:10516 [D loss: 0.537946, acc.: 76.56%] [G loss: 1.005525]\n",
      "epoch:11 step:10517 [D loss: 0.852000, acc.: 40.62%] [G loss: 0.916654]\n",
      "epoch:11 step:10518 [D loss: 0.748839, acc.: 44.53%] [G loss: 0.892255]\n",
      "epoch:11 step:10519 [D loss: 0.716778, acc.: 48.44%] [G loss: 0.780410]\n",
      "epoch:11 step:10520 [D loss: 0.681910, acc.: 52.34%] [G loss: 0.919369]\n",
      "epoch:11 step:10521 [D loss: 0.773104, acc.: 37.50%] [G loss: 0.900161]\n",
      "epoch:11 step:10522 [D loss: 0.718030, acc.: 45.31%] [G loss: 0.944085]\n",
      "epoch:11 step:10523 [D loss: 0.690103, acc.: 60.16%] [G loss: 0.772764]\n",
      "epoch:11 step:10524 [D loss: 0.680349, acc.: 59.38%] [G loss: 0.861709]\n",
      "epoch:11 step:10525 [D loss: 0.741370, acc.: 51.56%] [G loss: 0.764738]\n",
      "epoch:11 step:10526 [D loss: 0.630565, acc.: 62.50%] [G loss: 0.798826]\n",
      "epoch:11 step:10527 [D loss: 0.488768, acc.: 78.12%] [G loss: 0.904838]\n",
      "epoch:11 step:10528 [D loss: 0.467104, acc.: 84.38%] [G loss: 0.904311]\n",
      "epoch:11 step:10529 [D loss: 0.503039, acc.: 76.56%] [G loss: 0.970449]\n",
      "epoch:11 step:10530 [D loss: 0.630863, acc.: 67.97%] [G loss: 1.026335]\n",
      "epoch:11 step:10531 [D loss: 0.687262, acc.: 52.34%] [G loss: 0.940161]\n",
      "epoch:11 step:10532 [D loss: 0.643104, acc.: 63.28%] [G loss: 0.889027]\n",
      "epoch:11 step:10533 [D loss: 0.659495, acc.: 60.16%] [G loss: 0.889558]\n",
      "epoch:11 step:10534 [D loss: 0.664403, acc.: 58.59%] [G loss: 0.865947]\n",
      "epoch:11 step:10535 [D loss: 0.673989, acc.: 60.94%] [G loss: 0.885690]\n",
      "epoch:11 step:10536 [D loss: 0.627281, acc.: 66.41%] [G loss: 0.864255]\n",
      "epoch:11 step:10537 [D loss: 0.395452, acc.: 82.81%] [G loss: 0.932828]\n",
      "epoch:11 step:10538 [D loss: 0.457781, acc.: 80.47%] [G loss: 0.946446]\n",
      "epoch:11 step:10539 [D loss: 0.433829, acc.: 82.03%] [G loss: 0.937893]\n",
      "epoch:11 step:10540 [D loss: 0.715757, acc.: 53.91%] [G loss: 1.107068]\n",
      "epoch:11 step:10541 [D loss: 0.737724, acc.: 50.00%] [G loss: 0.895221]\n",
      "epoch:11 step:10542 [D loss: 0.444036, acc.: 77.34%] [G loss: 0.905556]\n",
      "epoch:11 step:10543 [D loss: 0.711792, acc.: 45.31%] [G loss: 0.906735]\n",
      "epoch:11 step:10544 [D loss: 0.609968, acc.: 68.75%] [G loss: 0.683949]\n",
      "epoch:11 step:10545 [D loss: 0.508924, acc.: 78.12%] [G loss: 1.013541]\n",
      "epoch:11 step:10546 [D loss: 0.646863, acc.: 61.72%] [G loss: 1.118674]\n",
      "epoch:11 step:10547 [D loss: 0.659522, acc.: 61.72%] [G loss: 0.947659]\n",
      "epoch:11 step:10548 [D loss: 0.717173, acc.: 46.88%] [G loss: 0.927379]\n",
      "epoch:11 step:10549 [D loss: 0.629056, acc.: 65.62%] [G loss: 1.048342]\n",
      "epoch:11 step:10550 [D loss: 0.555029, acc.: 76.56%] [G loss: 1.024449]\n",
      "epoch:11 step:10551 [D loss: 0.631162, acc.: 66.41%] [G loss: 0.839003]\n",
      "epoch:11 step:10552 [D loss: 1.079830, acc.: 26.56%] [G loss: 1.008795]\n",
      "epoch:11 step:10553 [D loss: 0.751479, acc.: 45.31%] [G loss: 0.840108]\n",
      "epoch:11 step:10554 [D loss: 0.696838, acc.: 51.56%] [G loss: 0.861102]\n",
      "epoch:11 step:10555 [D loss: 0.677547, acc.: 57.03%] [G loss: 0.840364]\n",
      "epoch:11 step:10556 [D loss: 0.621456, acc.: 64.84%] [G loss: 0.792891]\n",
      "epoch:11 step:10557 [D loss: 0.677910, acc.: 54.69%] [G loss: 0.838797]\n",
      "epoch:11 step:10558 [D loss: 0.669500, acc.: 62.50%] [G loss: 0.881545]\n",
      "epoch:11 step:10559 [D loss: 0.701962, acc.: 53.91%] [G loss: 0.741075]\n",
      "epoch:11 step:10560 [D loss: 0.630069, acc.: 64.06%] [G loss: 0.826385]\n",
      "epoch:11 step:10561 [D loss: 0.681978, acc.: 55.47%] [G loss: 0.772275]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10562 [D loss: 0.402175, acc.: 82.81%] [G loss: 0.890076]\n",
      "epoch:11 step:10563 [D loss: 0.435336, acc.: 75.00%] [G loss: 0.671605]\n",
      "epoch:11 step:10564 [D loss: 0.490982, acc.: 83.59%] [G loss: 0.946984]\n",
      "epoch:11 step:10565 [D loss: 0.739040, acc.: 44.53%] [G loss: 0.839511]\n",
      "epoch:11 step:10566 [D loss: 0.405406, acc.: 83.59%] [G loss: 0.958618]\n",
      "epoch:11 step:10567 [D loss: 0.461983, acc.: 88.28%] [G loss: 0.871386]\n",
      "epoch:11 step:10568 [D loss: 0.348255, acc.: 91.41%] [G loss: 0.937824]\n",
      "epoch:11 step:10569 [D loss: 0.722644, acc.: 50.00%] [G loss: 0.976975]\n",
      "epoch:11 step:10570 [D loss: 0.742636, acc.: 57.81%] [G loss: 0.918765]\n",
      "epoch:11 step:10571 [D loss: 0.721130, acc.: 53.12%] [G loss: 0.696541]\n",
      "epoch:11 step:10572 [D loss: 0.568577, acc.: 66.41%] [G loss: 1.032640]\n",
      "epoch:11 step:10573 [D loss: 0.731825, acc.: 52.34%] [G loss: 0.992618]\n",
      "epoch:11 step:10574 [D loss: 0.740360, acc.: 46.09%] [G loss: 0.836453]\n",
      "epoch:11 step:10575 [D loss: 0.770748, acc.: 36.72%] [G loss: 0.960387]\n",
      "epoch:11 step:10576 [D loss: 0.707647, acc.: 43.75%] [G loss: 1.023841]\n",
      "epoch:11 step:10577 [D loss: 0.654681, acc.: 53.12%] [G loss: 0.939442]\n",
      "epoch:11 step:10578 [D loss: 0.677172, acc.: 53.12%] [G loss: 1.017503]\n",
      "epoch:11 step:10579 [D loss: 0.628797, acc.: 60.16%] [G loss: 1.017630]\n",
      "epoch:11 step:10580 [D loss: 0.587912, acc.: 64.06%] [G loss: 1.170998]\n",
      "epoch:11 step:10581 [D loss: 0.569464, acc.: 70.31%] [G loss: 1.116092]\n",
      "epoch:11 step:10582 [D loss: 0.587182, acc.: 68.75%] [G loss: 1.160043]\n",
      "epoch:11 step:10583 [D loss: 0.567307, acc.: 69.53%] [G loss: 1.010671]\n",
      "epoch:11 step:10584 [D loss: 0.662788, acc.: 58.59%] [G loss: 1.074419]\n",
      "epoch:11 step:10585 [D loss: 0.763423, acc.: 45.31%] [G loss: 0.909954]\n",
      "epoch:11 step:10586 [D loss: 0.800888, acc.: 42.97%] [G loss: 0.844246]\n",
      "epoch:11 step:10587 [D loss: 0.775153, acc.: 32.81%] [G loss: 0.804160]\n",
      "epoch:11 step:10588 [D loss: 0.771631, acc.: 32.81%] [G loss: 0.821718]\n",
      "epoch:11 step:10589 [D loss: 0.637825, acc.: 67.97%] [G loss: 0.887878]\n",
      "epoch:11 step:10590 [D loss: 0.668089, acc.: 54.69%] [G loss: 0.895104]\n",
      "epoch:11 step:10591 [D loss: 0.786453, acc.: 37.50%] [G loss: 0.777877]\n",
      "epoch:11 step:10592 [D loss: 0.705707, acc.: 50.78%] [G loss: 0.961454]\n",
      "epoch:11 step:10593 [D loss: 0.732580, acc.: 48.44%] [G loss: 0.751604]\n",
      "epoch:11 step:10594 [D loss: 0.763760, acc.: 52.34%] [G loss: 0.806415]\n",
      "epoch:11 step:10595 [D loss: 0.733273, acc.: 46.09%] [G loss: 0.908033]\n",
      "epoch:11 step:10596 [D loss: 0.649038, acc.: 62.50%] [G loss: 0.724985]\n",
      "epoch:11 step:10597 [D loss: 0.678861, acc.: 55.47%] [G loss: 0.784708]\n",
      "epoch:11 step:10598 [D loss: 0.736856, acc.: 42.97%] [G loss: 0.761928]\n",
      "epoch:11 step:10599 [D loss: 0.613209, acc.: 65.62%] [G loss: 0.803904]\n",
      "epoch:11 step:10600 [D loss: 0.688191, acc.: 54.69%] [G loss: 0.740449]\n",
      "##############\n",
      "[4.01156624 2.35474704 6.34045412 5.39674574 4.66566116 6.02317596\n",
      " 5.47884838 5.73060023 5.62101325 5.03784491]\n",
      "##########\n",
      "epoch:11 step:10601 [D loss: 0.681049, acc.: 61.72%] [G loss: 0.760223]\n",
      "epoch:11 step:10602 [D loss: 0.712538, acc.: 46.09%] [G loss: 0.763797]\n",
      "epoch:11 step:10603 [D loss: 0.695639, acc.: 53.12%] [G loss: 0.713749]\n",
      "epoch:11 step:10604 [D loss: 0.629647, acc.: 73.44%] [G loss: 0.805384]\n",
      "epoch:11 step:10605 [D loss: 0.633716, acc.: 73.44%] [G loss: 0.810881]\n",
      "epoch:11 step:10606 [D loss: 0.625789, acc.: 75.00%] [G loss: 0.754488]\n",
      "epoch:11 step:10607 [D loss: 0.638044, acc.: 64.84%] [G loss: 0.821383]\n",
      "epoch:11 step:10608 [D loss: 0.669534, acc.: 50.78%] [G loss: 0.819480]\n",
      "epoch:11 step:10609 [D loss: 0.720769, acc.: 45.31%] [G loss: 0.805609]\n",
      "epoch:11 step:10610 [D loss: 0.727276, acc.: 50.78%] [G loss: 0.745101]\n",
      "epoch:11 step:10611 [D loss: 0.707950, acc.: 49.22%] [G loss: 0.767517]\n",
      "epoch:11 step:10612 [D loss: 0.808258, acc.: 39.84%] [G loss: 0.686753]\n",
      "epoch:11 step:10613 [D loss: 0.729839, acc.: 42.97%] [G loss: 0.695388]\n",
      "epoch:11 step:10614 [D loss: 0.639874, acc.: 64.84%] [G loss: 0.890633]\n",
      "epoch:11 step:10615 [D loss: 0.698692, acc.: 50.00%] [G loss: 0.805203]\n",
      "epoch:11 step:10616 [D loss: 0.664263, acc.: 58.59%] [G loss: 0.799148]\n",
      "epoch:11 step:10617 [D loss: 0.717386, acc.: 45.31%] [G loss: 0.693470]\n",
      "epoch:11 step:10618 [D loss: 0.729249, acc.: 43.75%] [G loss: 0.799224]\n",
      "epoch:11 step:10619 [D loss: 0.622971, acc.: 62.50%] [G loss: 0.800254]\n",
      "epoch:11 step:10620 [D loss: 0.530177, acc.: 83.59%] [G loss: 0.647487]\n",
      "epoch:11 step:10621 [D loss: 0.428751, acc.: 85.16%] [G loss: 0.775714]\n",
      "epoch:11 step:10622 [D loss: 0.677816, acc.: 56.25%] [G loss: 0.831898]\n",
      "epoch:11 step:10623 [D loss: 0.688952, acc.: 53.12%] [G loss: 0.512040]\n",
      "epoch:11 step:10624 [D loss: 0.721089, acc.: 46.88%] [G loss: 0.762600]\n",
      "epoch:11 step:10625 [D loss: 0.692178, acc.: 57.81%] [G loss: 0.731098]\n",
      "epoch:11 step:10626 [D loss: 0.684793, acc.: 54.69%] [G loss: 0.762601]\n",
      "epoch:11 step:10627 [D loss: 0.685451, acc.: 53.91%] [G loss: 0.806540]\n",
      "epoch:11 step:10628 [D loss: 0.878681, acc.: 41.41%] [G loss: 0.786941]\n",
      "epoch:11 step:10629 [D loss: 0.680946, acc.: 60.16%] [G loss: 0.825701]\n",
      "epoch:11 step:10630 [D loss: 0.683331, acc.: 54.69%] [G loss: 0.742773]\n",
      "epoch:11 step:10631 [D loss: 0.668046, acc.: 58.59%] [G loss: 0.736285]\n",
      "epoch:11 step:10632 [D loss: 0.674475, acc.: 59.38%] [G loss: 0.799650]\n",
      "epoch:11 step:10633 [D loss: 0.675127, acc.: 60.94%] [G loss: 0.792232]\n",
      "epoch:11 step:10634 [D loss: 0.557569, acc.: 84.38%] [G loss: 0.811988]\n",
      "epoch:11 step:10635 [D loss: 0.564840, acc.: 80.47%] [G loss: 0.856187]\n",
      "epoch:11 step:10636 [D loss: 0.696706, acc.: 50.00%] [G loss: 0.857708]\n",
      "epoch:11 step:10637 [D loss: 0.711021, acc.: 50.00%] [G loss: 0.866246]\n",
      "epoch:11 step:10638 [D loss: 0.720542, acc.: 46.88%] [G loss: 0.816710]\n",
      "epoch:11 step:10639 [D loss: 0.691382, acc.: 48.44%] [G loss: 0.783895]\n",
      "epoch:11 step:10640 [D loss: 0.667141, acc.: 64.06%] [G loss: 0.812935]\n",
      "epoch:11 step:10641 [D loss: 0.711762, acc.: 47.66%] [G loss: 0.751664]\n",
      "epoch:11 step:10642 [D loss: 0.699627, acc.: 54.69%] [G loss: 0.725781]\n",
      "epoch:11 step:10643 [D loss: 0.675257, acc.: 57.81%] [G loss: 0.811564]\n",
      "epoch:11 step:10644 [D loss: 0.611108, acc.: 70.31%] [G loss: 0.758957]\n",
      "epoch:11 step:10645 [D loss: 0.655297, acc.: 62.50%] [G loss: 0.738821]\n",
      "epoch:11 step:10646 [D loss: 0.667714, acc.: 60.94%] [G loss: 0.808037]\n",
      "epoch:11 step:10647 [D loss: 0.701904, acc.: 51.56%] [G loss: 0.790336]\n",
      "epoch:11 step:10648 [D loss: 0.728702, acc.: 43.75%] [G loss: 0.741118]\n",
      "epoch:11 step:10649 [D loss: 0.603328, acc.: 67.19%] [G loss: 0.783694]\n",
      "epoch:11 step:10650 [D loss: 0.419037, acc.: 81.25%] [G loss: 0.699357]\n",
      "epoch:11 step:10651 [D loss: 0.504835, acc.: 72.66%] [G loss: 0.807439]\n",
      "epoch:11 step:10652 [D loss: 0.397115, acc.: 83.59%] [G loss: 0.889209]\n",
      "epoch:11 step:10653 [D loss: 0.405389, acc.: 81.25%] [G loss: 0.927293]\n",
      "epoch:11 step:10654 [D loss: 0.326956, acc.: 91.41%] [G loss: 0.996867]\n",
      "epoch:11 step:10655 [D loss: 0.835166, acc.: 32.03%] [G loss: 0.909024]\n",
      "epoch:11 step:10656 [D loss: 0.721366, acc.: 46.88%] [G loss: 0.794345]\n",
      "epoch:11 step:10657 [D loss: 0.595179, acc.: 78.91%] [G loss: 0.757215]\n",
      "epoch:11 step:10658 [D loss: 0.796738, acc.: 29.69%] [G loss: 0.891201]\n",
      "epoch:11 step:10659 [D loss: 0.654359, acc.: 57.81%] [G loss: 0.973576]\n",
      "epoch:11 step:10660 [D loss: 0.714625, acc.: 43.75%] [G loss: 0.920495]\n",
      "epoch:11 step:10661 [D loss: 0.767616, acc.: 36.72%] [G loss: 0.905222]\n",
      "epoch:11 step:10662 [D loss: 0.684385, acc.: 60.16%] [G loss: 0.965252]\n",
      "epoch:11 step:10663 [D loss: 0.749033, acc.: 40.62%] [G loss: 0.967732]\n",
      "epoch:11 step:10664 [D loss: 0.657166, acc.: 57.03%] [G loss: 0.877803]\n",
      "epoch:11 step:10665 [D loss: 0.651023, acc.: 57.81%] [G loss: 0.926745]\n",
      "epoch:11 step:10666 [D loss: 0.621370, acc.: 64.06%] [G loss: 0.935256]\n",
      "epoch:11 step:10667 [D loss: 0.686002, acc.: 54.69%] [G loss: 0.903350]\n",
      "epoch:11 step:10668 [D loss: 0.652505, acc.: 60.16%] [G loss: 0.909346]\n",
      "epoch:11 step:10669 [D loss: 0.654740, acc.: 67.19%] [G loss: 0.828858]\n",
      "epoch:11 step:10670 [D loss: 0.598237, acc.: 70.31%] [G loss: 0.854856]\n",
      "epoch:11 step:10671 [D loss: 0.735618, acc.: 45.31%] [G loss: 0.769937]\n",
      "epoch:11 step:10672 [D loss: 0.633655, acc.: 63.28%] [G loss: 0.861934]\n",
      "epoch:11 step:10673 [D loss: 0.653449, acc.: 59.38%] [G loss: 0.872481]\n",
      "epoch:11 step:10674 [D loss: 0.781333, acc.: 32.03%] [G loss: 0.918503]\n",
      "epoch:11 step:10675 [D loss: 0.692846, acc.: 51.56%] [G loss: 0.913192]\n",
      "epoch:11 step:10676 [D loss: 0.651815, acc.: 58.59%] [G loss: 0.932655]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10677 [D loss: 0.619675, acc.: 65.62%] [G loss: 0.868868]\n",
      "epoch:11 step:10678 [D loss: 0.509350, acc.: 83.59%] [G loss: 0.935056]\n",
      "epoch:11 step:10679 [D loss: 0.602000, acc.: 63.28%] [G loss: 0.966100]\n",
      "epoch:11 step:10680 [D loss: 0.722574, acc.: 53.91%] [G loss: 0.845165]\n",
      "epoch:11 step:10681 [D loss: 0.639638, acc.: 60.16%] [G loss: 0.895167]\n",
      "epoch:11 step:10682 [D loss: 0.692907, acc.: 57.81%] [G loss: 0.986201]\n",
      "epoch:11 step:10683 [D loss: 0.687410, acc.: 63.28%] [G loss: 0.889109]\n",
      "epoch:11 step:10684 [D loss: 0.552649, acc.: 78.91%] [G loss: 0.862243]\n",
      "epoch:11 step:10685 [D loss: 0.641037, acc.: 62.50%] [G loss: 0.820566]\n",
      "epoch:11 step:10686 [D loss: 0.658687, acc.: 60.94%] [G loss: 0.803985]\n",
      "epoch:11 step:10687 [D loss: 0.596641, acc.: 67.19%] [G loss: 0.930404]\n",
      "epoch:11 step:10688 [D loss: 0.546911, acc.: 74.22%] [G loss: 0.860468]\n",
      "epoch:11 step:10689 [D loss: 0.685388, acc.: 50.00%] [G loss: 0.916995]\n",
      "epoch:11 step:10690 [D loss: 0.732333, acc.: 49.22%] [G loss: 0.839386]\n",
      "epoch:11 step:10691 [D loss: 0.725902, acc.: 51.56%] [G loss: 0.796888]\n",
      "epoch:11 step:10692 [D loss: 0.642170, acc.: 58.59%] [G loss: 0.891429]\n",
      "epoch:11 step:10693 [D loss: 0.699207, acc.: 52.34%] [G loss: 0.811703]\n",
      "epoch:11 step:10694 [D loss: 0.618320, acc.: 67.97%] [G loss: 0.871406]\n",
      "epoch:11 step:10695 [D loss: 0.621652, acc.: 68.75%] [G loss: 0.842170]\n",
      "epoch:11 step:10696 [D loss: 0.671302, acc.: 58.59%] [G loss: 0.940361]\n",
      "epoch:11 step:10697 [D loss: 0.805661, acc.: 36.72%] [G loss: 0.655437]\n",
      "epoch:11 step:10698 [D loss: 0.767711, acc.: 35.94%] [G loss: 0.634372]\n",
      "epoch:11 step:10699 [D loss: 0.724830, acc.: 39.84%] [G loss: 0.706094]\n",
      "epoch:11 step:10700 [D loss: 0.722341, acc.: 52.34%] [G loss: 0.694046]\n",
      "epoch:11 step:10701 [D loss: 0.743603, acc.: 34.38%] [G loss: 0.777938]\n",
      "epoch:11 step:10702 [D loss: 0.734272, acc.: 40.62%] [G loss: 0.771062]\n",
      "epoch:11 step:10703 [D loss: 0.583848, acc.: 64.84%] [G loss: 0.753807]\n",
      "epoch:11 step:10704 [D loss: 0.426404, acc.: 86.72%] [G loss: 0.893062]\n",
      "epoch:11 step:10705 [D loss: 0.371172, acc.: 89.06%] [G loss: 0.822091]\n",
      "epoch:11 step:10706 [D loss: 0.435657, acc.: 85.94%] [G loss: 0.884475]\n",
      "epoch:11 step:10707 [D loss: 0.409347, acc.: 92.97%] [G loss: 0.915176]\n",
      "epoch:11 step:10708 [D loss: 0.539168, acc.: 68.75%] [G loss: 0.922581]\n",
      "epoch:11 step:10709 [D loss: 0.328932, acc.: 93.75%] [G loss: 0.991846]\n",
      "epoch:11 step:10710 [D loss: 0.569470, acc.: 78.91%] [G loss: 0.975964]\n",
      "epoch:11 step:10711 [D loss: 0.288089, acc.: 96.09%] [G loss: 0.980187]\n",
      "epoch:11 step:10712 [D loss: 0.275068, acc.: 100.00%] [G loss: 1.065640]\n",
      "epoch:11 step:10713 [D loss: 0.267016, acc.: 100.00%] [G loss: 0.888509]\n",
      "epoch:11 step:10714 [D loss: 0.461435, acc.: 67.19%] [G loss: 1.129684]\n",
      "epoch:11 step:10715 [D loss: 0.697421, acc.: 54.69%] [G loss: 1.298319]\n",
      "epoch:11 step:10716 [D loss: 0.396661, acc.: 75.78%] [G loss: 1.185038]\n",
      "epoch:11 step:10717 [D loss: 0.609163, acc.: 71.88%] [G loss: 1.242186]\n",
      "epoch:11 step:10718 [D loss: 0.802894, acc.: 50.78%] [G loss: 1.183953]\n",
      "epoch:11 step:10719 [D loss: 0.657106, acc.: 68.75%] [G loss: 0.909461]\n",
      "epoch:11 step:10720 [D loss: 0.509424, acc.: 89.06%] [G loss: 0.564588]\n",
      "epoch:11 step:10721 [D loss: 0.288218, acc.: 99.22%] [G loss: 1.072620]\n",
      "epoch:11 step:10722 [D loss: 0.847848, acc.: 53.91%] [G loss: 1.108762]\n",
      "epoch:11 step:10723 [D loss: 0.698744, acc.: 55.47%] [G loss: 0.990611]\n",
      "epoch:11 step:10724 [D loss: 0.405167, acc.: 93.75%] [G loss: 0.586715]\n",
      "epoch:11 step:10725 [D loss: 0.306912, acc.: 93.75%] [G loss: 1.137862]\n",
      "epoch:11 step:10726 [D loss: 1.020950, acc.: 53.91%] [G loss: 0.592784]\n",
      "epoch:11 step:10727 [D loss: 0.637826, acc.: 66.41%] [G loss: 1.343008]\n",
      "epoch:11 step:10728 [D loss: 1.152085, acc.: 16.41%] [G loss: 1.212802]\n",
      "epoch:11 step:10729 [D loss: 0.881746, acc.: 43.75%] [G loss: 1.067847]\n",
      "epoch:11 step:10730 [D loss: 0.931824, acc.: 38.28%] [G loss: 1.034591]\n",
      "epoch:11 step:10731 [D loss: 0.672783, acc.: 58.59%] [G loss: 1.025999]\n",
      "epoch:11 step:10732 [D loss: 0.649498, acc.: 60.94%] [G loss: 0.919762]\n",
      "epoch:11 step:10733 [D loss: 0.754748, acc.: 46.88%] [G loss: 1.006965]\n",
      "epoch:11 step:10734 [D loss: 0.678446, acc.: 52.34%] [G loss: 0.818240]\n",
      "epoch:11 step:10735 [D loss: 0.696550, acc.: 53.91%] [G loss: 0.972687]\n",
      "epoch:11 step:10736 [D loss: 0.732699, acc.: 44.53%] [G loss: 0.906134]\n",
      "epoch:11 step:10737 [D loss: 0.747672, acc.: 42.97%] [G loss: 0.978423]\n",
      "epoch:11 step:10738 [D loss: 0.739590, acc.: 46.88%] [G loss: 1.107795]\n",
      "epoch:11 step:10739 [D loss: 0.665379, acc.: 55.47%] [G loss: 1.124956]\n",
      "epoch:11 step:10740 [D loss: 0.599075, acc.: 60.94%] [G loss: 1.186126]\n",
      "epoch:11 step:10741 [D loss: 0.607610, acc.: 64.06%] [G loss: 1.177123]\n",
      "epoch:11 step:10742 [D loss: 0.592493, acc.: 70.31%] [G loss: 1.155447]\n",
      "epoch:11 step:10743 [D loss: 0.614385, acc.: 64.84%] [G loss: 1.104937]\n",
      "epoch:11 step:10744 [D loss: 0.673457, acc.: 55.47%] [G loss: 1.098195]\n",
      "epoch:11 step:10745 [D loss: 0.775052, acc.: 50.00%] [G loss: 1.076347]\n",
      "epoch:11 step:10746 [D loss: 0.697428, acc.: 47.66%] [G loss: 0.905553]\n",
      "epoch:11 step:10747 [D loss: 0.672588, acc.: 57.81%] [G loss: 0.992617]\n",
      "epoch:11 step:10748 [D loss: 0.697433, acc.: 56.25%] [G loss: 0.834400]\n",
      "epoch:11 step:10749 [D loss: 0.682454, acc.: 51.56%] [G loss: 0.970255]\n",
      "epoch:11 step:10750 [D loss: 0.526225, acc.: 80.47%] [G loss: 1.118219]\n",
      "epoch:11 step:10751 [D loss: 0.639928, acc.: 59.38%] [G loss: 1.012091]\n",
      "epoch:11 step:10752 [D loss: 0.610765, acc.: 66.41%] [G loss: 1.056555]\n",
      "epoch:11 step:10753 [D loss: 0.632642, acc.: 63.28%] [G loss: 0.926014]\n",
      "epoch:11 step:10754 [D loss: 0.654398, acc.: 62.50%] [G loss: 0.899919]\n",
      "epoch:11 step:10755 [D loss: 0.535332, acc.: 75.78%] [G loss: 1.133291]\n",
      "epoch:11 step:10756 [D loss: 0.520244, acc.: 84.38%] [G loss: 0.970920]\n",
      "epoch:11 step:10757 [D loss: 0.540068, acc.: 75.00%] [G loss: 0.933663]\n",
      "epoch:11 step:10758 [D loss: 0.401937, acc.: 94.53%] [G loss: 0.979250]\n",
      "epoch:11 step:10759 [D loss: 0.419172, acc.: 95.31%] [G loss: 1.219052]\n",
      "epoch:11 step:10760 [D loss: 0.465196, acc.: 85.16%] [G loss: 1.778095]\n",
      "epoch:11 step:10761 [D loss: 0.505132, acc.: 81.25%] [G loss: 1.387774]\n",
      "epoch:11 step:10762 [D loss: 0.523036, acc.: 71.09%] [G loss: 1.416569]\n",
      "epoch:11 step:10763 [D loss: 0.421259, acc.: 72.66%] [G loss: 1.721465]\n",
      "epoch:11 step:10764 [D loss: 0.448352, acc.: 91.41%] [G loss: 1.822778]\n",
      "epoch:11 step:10765 [D loss: 0.845015, acc.: 41.41%] [G loss: 1.336368]\n",
      "epoch:11 step:10766 [D loss: 0.761262, acc.: 46.09%] [G loss: 1.339552]\n",
      "epoch:11 step:10767 [D loss: 0.702738, acc.: 50.78%] [G loss: 1.268310]\n",
      "epoch:11 step:10768 [D loss: 1.255168, acc.: 14.84%] [G loss: 1.123760]\n",
      "epoch:11 step:10769 [D loss: 0.952205, acc.: 33.59%] [G loss: 1.297117]\n",
      "epoch:11 step:10770 [D loss: 0.755403, acc.: 46.09%] [G loss: 1.308987]\n",
      "epoch:11 step:10771 [D loss: 0.651716, acc.: 69.53%] [G loss: 1.092562]\n",
      "epoch:11 step:10772 [D loss: 0.670236, acc.: 60.94%] [G loss: 0.911285]\n",
      "epoch:11 step:10773 [D loss: 0.667533, acc.: 59.38%] [G loss: 0.815916]\n",
      "epoch:11 step:10774 [D loss: 0.670591, acc.: 56.25%] [G loss: 0.723757]\n",
      "epoch:11 step:10775 [D loss: 0.680256, acc.: 56.25%] [G loss: 0.741338]\n",
      "epoch:11 step:10776 [D loss: 0.652541, acc.: 59.38%] [G loss: 0.874305]\n",
      "epoch:11 step:10777 [D loss: 0.648027, acc.: 64.84%] [G loss: 0.829465]\n",
      "epoch:11 step:10778 [D loss: 0.674688, acc.: 53.12%] [G loss: 0.821269]\n",
      "epoch:11 step:10779 [D loss: 0.669910, acc.: 53.12%] [G loss: 0.942061]\n",
      "epoch:11 step:10780 [D loss: 0.680462, acc.: 52.34%] [G loss: 1.237587]\n",
      "epoch:11 step:10781 [D loss: 0.591095, acc.: 74.22%] [G loss: 0.973387]\n",
      "epoch:11 step:10782 [D loss: 0.603138, acc.: 64.06%] [G loss: 0.987729]\n",
      "epoch:11 step:10783 [D loss: 0.626421, acc.: 72.66%] [G loss: 1.364875]\n",
      "epoch:11 step:10784 [D loss: 0.777454, acc.: 44.53%] [G loss: 0.979013]\n",
      "epoch:11 step:10785 [D loss: 0.695396, acc.: 52.34%] [G loss: 0.881506]\n",
      "epoch:11 step:10786 [D loss: 0.718116, acc.: 50.00%] [G loss: 0.821239]\n",
      "epoch:11 step:10787 [D loss: 0.729214, acc.: 50.78%] [G loss: 0.795891]\n",
      "epoch:11 step:10788 [D loss: 0.650980, acc.: 57.81%] [G loss: 0.926762]\n",
      "epoch:11 step:10789 [D loss: 0.661273, acc.: 60.16%] [G loss: 0.732885]\n",
      "epoch:11 step:10790 [D loss: 0.611677, acc.: 67.97%] [G loss: 0.842089]\n",
      "epoch:11 step:10791 [D loss: 0.636528, acc.: 58.59%] [G loss: 0.773751]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10792 [D loss: 0.658011, acc.: 56.25%] [G loss: 0.827570]\n",
      "epoch:11 step:10793 [D loss: 0.643108, acc.: 57.81%] [G loss: 0.829830]\n",
      "epoch:11 step:10794 [D loss: 0.663189, acc.: 57.81%] [G loss: 0.854981]\n",
      "epoch:11 step:10795 [D loss: 0.656008, acc.: 57.81%] [G loss: 0.867841]\n",
      "epoch:11 step:10796 [D loss: 0.622025, acc.: 69.53%] [G loss: 0.808057]\n",
      "epoch:11 step:10797 [D loss: 0.656807, acc.: 57.03%] [G loss: 0.836503]\n",
      "epoch:11 step:10798 [D loss: 0.657564, acc.: 58.59%] [G loss: 0.833823]\n",
      "epoch:11 step:10799 [D loss: 0.658834, acc.: 58.59%] [G loss: 0.788563]\n",
      "epoch:11 step:10800 [D loss: 0.630610, acc.: 62.50%] [G loss: 0.808269]\n",
      "##############\n",
      "[4.07835562 2.56263617 7.12807509 5.91225566 4.24314376 5.86675405\n",
      " 5.51165634 5.8229637  5.26599953 5.17121959]\n",
      "##########\n",
      "epoch:11 step:10801 [D loss: 0.611396, acc.: 65.62%] [G loss: 0.821756]\n",
      "epoch:11 step:10802 [D loss: 0.631039, acc.: 58.59%] [G loss: 0.913793]\n",
      "epoch:11 step:10803 [D loss: 0.636691, acc.: 62.50%] [G loss: 0.842294]\n",
      "epoch:11 step:10804 [D loss: 0.586655, acc.: 71.09%] [G loss: 0.846520]\n",
      "epoch:11 step:10805 [D loss: 0.601915, acc.: 73.44%] [G loss: 0.785692]\n",
      "epoch:11 step:10806 [D loss: 0.563074, acc.: 72.66%] [G loss: 0.852713]\n",
      "epoch:11 step:10807 [D loss: 0.694178, acc.: 62.50%] [G loss: 0.833091]\n",
      "epoch:11 step:10808 [D loss: 0.706914, acc.: 52.34%] [G loss: 0.891390]\n",
      "epoch:11 step:10809 [D loss: 0.672888, acc.: 57.81%] [G loss: 0.901172]\n",
      "epoch:11 step:10810 [D loss: 0.650767, acc.: 59.38%] [G loss: 0.816091]\n",
      "epoch:11 step:10811 [D loss: 0.574409, acc.: 71.88%] [G loss: 0.826166]\n",
      "epoch:11 step:10812 [D loss: 0.625118, acc.: 65.62%] [G loss: 0.834942]\n",
      "epoch:11 step:10813 [D loss: 0.676816, acc.: 59.38%] [G loss: 0.889753]\n",
      "epoch:11 step:10814 [D loss: 0.589252, acc.: 70.31%] [G loss: 0.907570]\n",
      "epoch:11 step:10815 [D loss: 0.546112, acc.: 77.34%] [G loss: 0.899068]\n",
      "epoch:11 step:10816 [D loss: 0.666325, acc.: 56.25%] [G loss: 0.852065]\n",
      "epoch:11 step:10817 [D loss: 0.731004, acc.: 57.81%] [G loss: 0.917657]\n",
      "epoch:11 step:10818 [D loss: 0.846386, acc.: 52.34%] [G loss: 0.989766]\n",
      "epoch:11 step:10819 [D loss: 0.603201, acc.: 68.75%] [G loss: 1.061159]\n",
      "epoch:11 step:10820 [D loss: 0.485987, acc.: 85.16%] [G loss: 0.991978]\n",
      "epoch:11 step:10821 [D loss: 0.454156, acc.: 84.38%] [G loss: 1.410190]\n",
      "epoch:11 step:10822 [D loss: 0.501785, acc.: 78.91%] [G loss: 0.785536]\n",
      "epoch:11 step:10823 [D loss: 0.764128, acc.: 45.31%] [G loss: 0.851421]\n",
      "epoch:11 step:10824 [D loss: 0.677129, acc.: 57.81%] [G loss: 1.001262]\n",
      "epoch:11 step:10825 [D loss: 0.729843, acc.: 51.56%] [G loss: 0.989569]\n",
      "epoch:11 step:10826 [D loss: 0.750804, acc.: 45.31%] [G loss: 1.007360]\n",
      "epoch:11 step:10827 [D loss: 0.554674, acc.: 75.00%] [G loss: 1.200612]\n",
      "epoch:11 step:10828 [D loss: 0.622863, acc.: 64.06%] [G loss: 1.185233]\n",
      "epoch:11 step:10829 [D loss: 0.588023, acc.: 68.75%] [G loss: 1.208446]\n",
      "epoch:11 step:10830 [D loss: 0.564414, acc.: 66.41%] [G loss: 1.176716]\n",
      "epoch:11 step:10831 [D loss: 0.780368, acc.: 55.47%] [G loss: 0.985150]\n",
      "epoch:11 step:10832 [D loss: 0.693993, acc.: 57.81%] [G loss: 0.987963]\n",
      "epoch:11 step:10833 [D loss: 0.694485, acc.: 51.56%] [G loss: 1.014940]\n",
      "epoch:11 step:10834 [D loss: 0.692486, acc.: 56.25%] [G loss: 1.036455]\n",
      "epoch:11 step:10835 [D loss: 0.663352, acc.: 55.47%] [G loss: 0.852353]\n",
      "epoch:11 step:10836 [D loss: 0.714913, acc.: 45.31%] [G loss: 0.968052]\n",
      "epoch:11 step:10837 [D loss: 0.654372, acc.: 63.28%] [G loss: 0.955970]\n",
      "epoch:11 step:10838 [D loss: 0.605434, acc.: 64.06%] [G loss: 0.956337]\n",
      "epoch:11 step:10839 [D loss: 0.506395, acc.: 82.81%] [G loss: 1.034232]\n",
      "epoch:11 step:10840 [D loss: 0.481239, acc.: 75.78%] [G loss: 1.009391]\n",
      "epoch:11 step:10841 [D loss: 0.442704, acc.: 87.50%] [G loss: 1.094091]\n",
      "epoch:11 step:10842 [D loss: 0.765985, acc.: 57.81%] [G loss: 1.088148]\n",
      "epoch:11 step:10843 [D loss: 0.698487, acc.: 53.91%] [G loss: 0.819391]\n",
      "epoch:11 step:10844 [D loss: 0.779748, acc.: 38.28%] [G loss: 0.858162]\n",
      "epoch:11 step:10845 [D loss: 0.696576, acc.: 55.47%] [G loss: 0.826380]\n",
      "epoch:11 step:10846 [D loss: 0.687798, acc.: 55.47%] [G loss: 0.870978]\n",
      "epoch:11 step:10847 [D loss: 0.657055, acc.: 57.03%] [G loss: 0.830704]\n",
      "epoch:11 step:10848 [D loss: 0.645020, acc.: 65.62%] [G loss: 0.793397]\n",
      "epoch:11 step:10849 [D loss: 0.502312, acc.: 80.47%] [G loss: 0.948216]\n",
      "epoch:11 step:10850 [D loss: 0.383349, acc.: 80.47%] [G loss: 1.022215]\n",
      "epoch:11 step:10851 [D loss: 0.500201, acc.: 84.38%] [G loss: 1.053011]\n",
      "epoch:11 step:10852 [D loss: 0.475888, acc.: 88.28%] [G loss: 0.883496]\n",
      "epoch:11 step:10853 [D loss: 0.458768, acc.: 89.06%] [G loss: 1.409088]\n",
      "epoch:11 step:10854 [D loss: 0.544255, acc.: 75.00%] [G loss: 0.853287]\n",
      "epoch:11 step:10855 [D loss: 0.431739, acc.: 87.50%] [G loss: 1.170915]\n",
      "epoch:11 step:10856 [D loss: 0.446216, acc.: 83.59%] [G loss: 0.808393]\n",
      "epoch:11 step:10857 [D loss: 0.415369, acc.: 69.53%] [G loss: 1.186773]\n",
      "epoch:11 step:10858 [D loss: 0.548254, acc.: 77.34%] [G loss: 0.902730]\n",
      "epoch:11 step:10859 [D loss: 0.421972, acc.: 88.28%] [G loss: 0.764463]\n",
      "epoch:11 step:10860 [D loss: 0.678499, acc.: 59.38%] [G loss: 0.678766]\n",
      "epoch:11 step:10861 [D loss: 0.440823, acc.: 68.75%] [G loss: 0.960757]\n",
      "epoch:11 step:10862 [D loss: 0.703326, acc.: 57.03%] [G loss: 1.082523]\n",
      "epoch:11 step:10863 [D loss: 0.611337, acc.: 64.06%] [G loss: 0.998778]\n",
      "epoch:11 step:10864 [D loss: 0.797253, acc.: 50.00%] [G loss: 0.748105]\n",
      "epoch:11 step:10865 [D loss: 0.822639, acc.: 40.62%] [G loss: 1.039453]\n",
      "epoch:11 step:10866 [D loss: 1.055629, acc.: 40.62%] [G loss: 1.263795]\n",
      "epoch:11 step:10867 [D loss: 0.969677, acc.: 32.03%] [G loss: 1.665883]\n",
      "epoch:11 step:10868 [D loss: 0.642592, acc.: 59.38%] [G loss: 1.149985]\n",
      "epoch:11 step:10869 [D loss: 0.713042, acc.: 60.16%] [G loss: 1.650731]\n",
      "epoch:11 step:10870 [D loss: 0.708501, acc.: 53.91%] [G loss: 1.113664]\n",
      "epoch:11 step:10871 [D loss: 0.602161, acc.: 69.53%] [G loss: 1.082455]\n",
      "epoch:11 step:10872 [D loss: 0.668980, acc.: 59.38%] [G loss: 1.281992]\n",
      "epoch:11 step:10873 [D loss: 0.513434, acc.: 75.00%] [G loss: 1.371858]\n",
      "epoch:11 step:10874 [D loss: 0.472271, acc.: 82.03%] [G loss: 1.401809]\n",
      "epoch:11 step:10875 [D loss: 0.585513, acc.: 69.53%] [G loss: 1.300766]\n",
      "epoch:11 step:10876 [D loss: 0.688349, acc.: 61.72%] [G loss: 1.052118]\n",
      "epoch:11 step:10877 [D loss: 0.600427, acc.: 70.31%] [G loss: 1.127432]\n",
      "epoch:11 step:10878 [D loss: 0.672341, acc.: 57.03%] [G loss: 1.003771]\n",
      "epoch:11 step:10879 [D loss: 0.613124, acc.: 63.28%] [G loss: 1.005002]\n",
      "epoch:11 step:10880 [D loss: 0.535390, acc.: 77.34%] [G loss: 1.039628]\n",
      "epoch:11 step:10881 [D loss: 0.542318, acc.: 74.22%] [G loss: 1.127752]\n",
      "epoch:11 step:10882 [D loss: 0.527544, acc.: 74.22%] [G loss: 1.057682]\n",
      "epoch:11 step:10883 [D loss: 0.556444, acc.: 69.53%] [G loss: 1.235270]\n",
      "epoch:11 step:10884 [D loss: 0.545206, acc.: 71.09%] [G loss: 0.915911]\n",
      "epoch:11 step:10885 [D loss: 0.479846, acc.: 76.56%] [G loss: 1.149191]\n",
      "epoch:11 step:10886 [D loss: 0.627200, acc.: 60.94%] [G loss: 0.680169]\n",
      "epoch:11 step:10887 [D loss: 0.755079, acc.: 46.88%] [G loss: 0.905061]\n",
      "epoch:11 step:10888 [D loss: 0.736543, acc.: 43.75%] [G loss: 0.789285]\n",
      "epoch:11 step:10889 [D loss: 0.777273, acc.: 40.62%] [G loss: 0.774266]\n",
      "epoch:11 step:10890 [D loss: 0.759359, acc.: 50.78%] [G loss: 0.805608]\n",
      "epoch:11 step:10891 [D loss: 0.757796, acc.: 44.53%] [G loss: 0.820970]\n",
      "epoch:11 step:10892 [D loss: 0.717187, acc.: 50.78%] [G loss: 0.811439]\n",
      "epoch:11 step:10893 [D loss: 0.664345, acc.: 57.03%] [G loss: 0.855121]\n",
      "epoch:11 step:10894 [D loss: 0.536593, acc.: 74.22%] [G loss: 0.877490]\n",
      "epoch:11 step:10895 [D loss: 0.467008, acc.: 88.28%] [G loss: 0.922836]\n",
      "epoch:11 step:10896 [D loss: 0.385326, acc.: 89.06%] [G loss: 1.060004]\n",
      "epoch:11 step:10897 [D loss: 0.683027, acc.: 55.47%] [G loss: 1.066150]\n",
      "epoch:11 step:10898 [D loss: 0.586654, acc.: 71.09%] [G loss: 1.018490]\n",
      "epoch:11 step:10899 [D loss: 0.552795, acc.: 77.34%] [G loss: 1.024134]\n",
      "epoch:11 step:10900 [D loss: 0.606850, acc.: 68.75%] [G loss: 1.096622]\n",
      "epoch:11 step:10901 [D loss: 0.687283, acc.: 51.56%] [G loss: 0.894056]\n",
      "epoch:11 step:10902 [D loss: 0.468841, acc.: 81.25%] [G loss: 0.973044]\n",
      "epoch:11 step:10903 [D loss: 0.492341, acc.: 78.91%] [G loss: 0.839095]\n",
      "epoch:11 step:10904 [D loss: 0.706375, acc.: 56.25%] [G loss: 0.953496]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10905 [D loss: 0.598348, acc.: 67.97%] [G loss: 0.924930]\n",
      "epoch:11 step:10906 [D loss: 0.637282, acc.: 64.84%] [G loss: 0.870427]\n",
      "epoch:11 step:10907 [D loss: 0.535398, acc.: 71.09%] [G loss: 0.979587]\n",
      "epoch:11 step:10908 [D loss: 0.487592, acc.: 76.56%] [G loss: 0.800517]\n",
      "epoch:11 step:10909 [D loss: 0.449400, acc.: 81.25%] [G loss: 0.804607]\n",
      "epoch:11 step:10910 [D loss: 0.738320, acc.: 48.44%] [G loss: 0.748476]\n",
      "epoch:11 step:10911 [D loss: 0.664153, acc.: 57.03%] [G loss: 0.958615]\n",
      "epoch:11 step:10912 [D loss: 0.635119, acc.: 60.16%] [G loss: 1.040454]\n",
      "epoch:11 step:10913 [D loss: 0.862311, acc.: 35.94%] [G loss: 0.659050]\n",
      "epoch:11 step:10914 [D loss: 0.749231, acc.: 54.69%] [G loss: 0.828760]\n",
      "epoch:11 step:10915 [D loss: 0.714220, acc.: 55.47%] [G loss: 0.952766]\n",
      "epoch:11 step:10916 [D loss: 0.591987, acc.: 75.78%] [G loss: 0.938111]\n",
      "epoch:11 step:10917 [D loss: 0.724536, acc.: 50.00%] [G loss: 0.901476]\n",
      "epoch:11 step:10918 [D loss: 0.671511, acc.: 56.25%] [G loss: 0.943936]\n",
      "epoch:11 step:10919 [D loss: 0.712228, acc.: 54.69%] [G loss: 0.853391]\n",
      "epoch:11 step:10920 [D loss: 0.643539, acc.: 61.72%] [G loss: 0.972428]\n",
      "epoch:11 step:10921 [D loss: 0.700788, acc.: 54.69%] [G loss: 0.900586]\n",
      "epoch:11 step:10922 [D loss: 0.724152, acc.: 47.66%] [G loss: 0.937632]\n",
      "epoch:11 step:10923 [D loss: 0.655317, acc.: 60.94%] [G loss: 0.948873]\n",
      "epoch:11 step:10924 [D loss: 0.600938, acc.: 67.97%] [G loss: 0.911789]\n",
      "epoch:11 step:10925 [D loss: 0.581569, acc.: 74.22%] [G loss: 0.913558]\n",
      "epoch:11 step:10926 [D loss: 0.668236, acc.: 62.50%] [G loss: 0.888483]\n",
      "epoch:11 step:10927 [D loss: 0.556909, acc.: 76.56%] [G loss: 0.893114]\n",
      "epoch:11 step:10928 [D loss: 0.745363, acc.: 42.97%] [G loss: 0.876783]\n",
      "epoch:11 step:10929 [D loss: 0.747961, acc.: 42.97%] [G loss: 0.850048]\n",
      "epoch:11 step:10930 [D loss: 0.670811, acc.: 54.69%] [G loss: 0.927771]\n",
      "epoch:11 step:10931 [D loss: 0.673354, acc.: 60.16%] [G loss: 0.750498]\n",
      "epoch:11 step:10932 [D loss: 0.625067, acc.: 69.53%] [G loss: 0.816928]\n",
      "epoch:11 step:10933 [D loss: 0.641466, acc.: 67.97%] [G loss: 0.867827]\n",
      "epoch:11 step:10934 [D loss: 0.566511, acc.: 78.91%] [G loss: 0.680202]\n",
      "epoch:11 step:10935 [D loss: 0.692436, acc.: 57.81%] [G loss: 0.823194]\n",
      "epoch:11 step:10936 [D loss: 0.785963, acc.: 38.28%] [G loss: 0.870021]\n",
      "epoch:11 step:10937 [D loss: 0.617542, acc.: 67.97%] [G loss: 0.886544]\n",
      "epoch:11 step:10938 [D loss: 0.651084, acc.: 63.28%] [G loss: 0.799862]\n",
      "epoch:11 step:10939 [D loss: 0.681636, acc.: 55.47%] [G loss: 0.771067]\n",
      "epoch:11 step:10940 [D loss: 0.559119, acc.: 69.53%] [G loss: 0.857931]\n",
      "epoch:11 step:10941 [D loss: 0.540742, acc.: 81.25%] [G loss: 0.914989]\n",
      "epoch:11 step:10942 [D loss: 0.502234, acc.: 82.81%] [G loss: 0.678651]\n",
      "epoch:11 step:10943 [D loss: 0.606452, acc.: 66.41%] [G loss: 1.068984]\n",
      "epoch:11 step:10944 [D loss: 0.653746, acc.: 66.41%] [G loss: 1.027882]\n",
      "epoch:11 step:10945 [D loss: 0.606401, acc.: 68.75%] [G loss: 0.852736]\n",
      "epoch:11 step:10946 [D loss: 0.709419, acc.: 50.00%] [G loss: 0.875900]\n",
      "epoch:11 step:10947 [D loss: 0.832925, acc.: 32.81%] [G loss: 0.934290]\n",
      "epoch:11 step:10948 [D loss: 0.529716, acc.: 75.00%] [G loss: 1.001475]\n",
      "epoch:11 step:10949 [D loss: 0.754689, acc.: 46.88%] [G loss: 0.973814]\n",
      "epoch:11 step:10950 [D loss: 0.696986, acc.: 50.78%] [G loss: 0.878864]\n",
      "epoch:11 step:10951 [D loss: 0.442288, acc.: 82.81%] [G loss: 0.923886]\n",
      "epoch:11 step:10952 [D loss: 0.528055, acc.: 78.91%] [G loss: 1.112588]\n",
      "epoch:11 step:10953 [D loss: 0.458854, acc.: 87.50%] [G loss: 0.723367]\n",
      "epoch:11 step:10954 [D loss: 0.533154, acc.: 77.34%] [G loss: 0.727960]\n",
      "epoch:11 step:10955 [D loss: 0.527174, acc.: 71.09%] [G loss: 0.917000]\n",
      "epoch:11 step:10956 [D loss: 0.731720, acc.: 51.56%] [G loss: 0.774385]\n",
      "epoch:11 step:10957 [D loss: 0.432160, acc.: 85.94%] [G loss: 0.980219]\n",
      "epoch:11 step:10958 [D loss: 0.824234, acc.: 41.41%] [G loss: 1.063232]\n",
      "epoch:11 step:10959 [D loss: 0.683436, acc.: 58.59%] [G loss: 0.971136]\n",
      "epoch:11 step:10960 [D loss: 0.826711, acc.: 42.19%] [G loss: 1.055883]\n",
      "epoch:11 step:10961 [D loss: 0.829645, acc.: 42.19%] [G loss: 1.123547]\n",
      "epoch:11 step:10962 [D loss: 0.786887, acc.: 38.28%] [G loss: 0.981977]\n",
      "epoch:11 step:10963 [D loss: 0.822677, acc.: 36.72%] [G loss: 1.112817]\n",
      "epoch:11 step:10964 [D loss: 0.738646, acc.: 44.53%] [G loss: 1.151162]\n",
      "epoch:11 step:10965 [D loss: 0.693722, acc.: 59.38%] [G loss: 1.066499]\n",
      "epoch:11 step:10966 [D loss: 0.648517, acc.: 61.72%] [G loss: 0.843598]\n",
      "epoch:11 step:10967 [D loss: 0.579813, acc.: 74.22%] [G loss: 0.841479]\n",
      "epoch:11 step:10968 [D loss: 0.659035, acc.: 59.38%] [G loss: 1.011935]\n",
      "epoch:11 step:10969 [D loss: 0.733871, acc.: 48.44%] [G loss: 1.038745]\n",
      "epoch:11 step:10970 [D loss: 0.439886, acc.: 92.19%] [G loss: 1.029956]\n",
      "epoch:11 step:10971 [D loss: 0.415655, acc.: 87.50%] [G loss: 1.162495]\n",
      "epoch:11 step:10972 [D loss: 0.399826, acc.: 84.38%] [G loss: 1.184960]\n",
      "epoch:11 step:10973 [D loss: 0.595376, acc.: 67.19%] [G loss: 1.197358]\n",
      "epoch:11 step:10974 [D loss: 0.611606, acc.: 63.28%] [G loss: 0.967874]\n",
      "epoch:11 step:10975 [D loss: 0.676920, acc.: 58.59%] [G loss: 0.958273]\n",
      "epoch:11 step:10976 [D loss: 0.630506, acc.: 71.88%] [G loss: 1.108315]\n",
      "epoch:11 step:10977 [D loss: 0.668160, acc.: 61.72%] [G loss: 0.934389]\n",
      "epoch:11 step:10978 [D loss: 0.666260, acc.: 57.81%] [G loss: 0.937692]\n",
      "epoch:11 step:10979 [D loss: 0.772164, acc.: 45.31%] [G loss: 0.858772]\n",
      "epoch:11 step:10980 [D loss: 0.670132, acc.: 58.59%] [G loss: 0.894656]\n",
      "epoch:11 step:10981 [D loss: 0.550328, acc.: 68.75%] [G loss: 0.917225]\n",
      "epoch:11 step:10982 [D loss: 0.808293, acc.: 42.97%] [G loss: 0.840712]\n",
      "epoch:11 step:10983 [D loss: 0.700558, acc.: 48.44%] [G loss: 0.756372]\n",
      "epoch:11 step:10984 [D loss: 0.695688, acc.: 52.34%] [G loss: 0.800815]\n",
      "epoch:11 step:10985 [D loss: 0.747677, acc.: 54.69%] [G loss: 0.749381]\n",
      "epoch:11 step:10986 [D loss: 0.694898, acc.: 54.69%] [G loss: 0.810196]\n",
      "epoch:11 step:10987 [D loss: 0.686677, acc.: 57.81%] [G loss: 0.764916]\n",
      "epoch:11 step:10988 [D loss: 0.659394, acc.: 62.50%] [G loss: 0.846386]\n",
      "epoch:11 step:10989 [D loss: 0.587740, acc.: 68.75%] [G loss: 0.803820]\n",
      "epoch:11 step:10990 [D loss: 0.626773, acc.: 64.84%] [G loss: 0.815699]\n",
      "epoch:11 step:10991 [D loss: 0.568430, acc.: 77.34%] [G loss: 0.792715]\n",
      "epoch:11 step:10992 [D loss: 0.624065, acc.: 71.88%] [G loss: 0.611463]\n",
      "epoch:11 step:10993 [D loss: 0.499861, acc.: 76.56%] [G loss: 0.358693]\n",
      "epoch:11 step:10994 [D loss: 0.786914, acc.: 50.78%] [G loss: 0.828532]\n",
      "epoch:11 step:10995 [D loss: 0.662579, acc.: 62.50%] [G loss: 0.909680]\n",
      "epoch:11 step:10996 [D loss: 0.903227, acc.: 35.16%] [G loss: 0.934416]\n",
      "epoch:11 step:10997 [D loss: 0.635251, acc.: 66.41%] [G loss: 0.928209]\n",
      "epoch:11 step:10998 [D loss: 0.671026, acc.: 62.50%] [G loss: 0.706031]\n",
      "epoch:11 step:10999 [D loss: 0.602099, acc.: 66.41%] [G loss: 0.809286]\n",
      "epoch:11 step:11000 [D loss: 0.691181, acc.: 54.69%] [G loss: 0.926591]\n",
      "##############\n",
      "[3.65809554 2.75169594 6.69170481 5.7728766  4.62446444 6.38555399\n",
      " 5.53878214 5.57962717 5.94895301 5.24326701]\n",
      "##########\n",
      "epoch:11 step:11001 [D loss: 0.710583, acc.: 52.34%] [G loss: 1.013640]\n",
      "epoch:11 step:11002 [D loss: 0.710878, acc.: 57.81%] [G loss: 0.855744]\n",
      "epoch:11 step:11003 [D loss: 0.582177, acc.: 73.44%] [G loss: 0.946879]\n",
      "epoch:11 step:11004 [D loss: 0.453901, acc.: 85.94%] [G loss: 0.987736]\n",
      "epoch:11 step:11005 [D loss: 0.526592, acc.: 82.03%] [G loss: 0.933092]\n",
      "epoch:11 step:11006 [D loss: 0.716242, acc.: 53.12%] [G loss: 0.788862]\n",
      "epoch:11 step:11007 [D loss: 0.659024, acc.: 53.91%] [G loss: 1.018297]\n",
      "epoch:11 step:11008 [D loss: 0.445202, acc.: 89.06%] [G loss: 1.073065]\n",
      "epoch:11 step:11009 [D loss: 0.483977, acc.: 88.28%] [G loss: 1.003987]\n",
      "epoch:11 step:11010 [D loss: 0.710903, acc.: 53.91%] [G loss: 1.047202]\n",
      "epoch:11 step:11011 [D loss: 0.690690, acc.: 54.69%] [G loss: 0.718752]\n",
      "epoch:11 step:11012 [D loss: 0.675115, acc.: 60.94%] [G loss: 0.917600]\n",
      "epoch:11 step:11013 [D loss: 0.432986, acc.: 92.97%] [G loss: 0.956812]\n",
      "epoch:11 step:11014 [D loss: 0.320621, acc.: 94.53%] [G loss: 0.780355]\n",
      "epoch:11 step:11015 [D loss: 0.322242, acc.: 94.53%] [G loss: 0.884952]\n",
      "epoch:11 step:11016 [D loss: 0.559481, acc.: 79.69%] [G loss: 1.046948]\n",
      "epoch:11 step:11017 [D loss: 0.738634, acc.: 57.03%] [G loss: 0.865767]\n",
      "epoch:11 step:11018 [D loss: 1.208036, acc.: 22.66%] [G loss: 1.003173]\n",
      "epoch:11 step:11019 [D loss: 0.635107, acc.: 60.94%] [G loss: 1.025941]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:11020 [D loss: 0.372847, acc.: 90.62%] [G loss: 1.034583]\n",
      "epoch:11 step:11021 [D loss: 0.362353, acc.: 90.62%] [G loss: 1.082668]\n",
      "epoch:11 step:11022 [D loss: 0.883536, acc.: 30.47%] [G loss: 0.622065]\n",
      "epoch:11 step:11023 [D loss: 0.882834, acc.: 29.69%] [G loss: 1.060060]\n",
      "epoch:11 step:11024 [D loss: 0.676417, acc.: 60.16%] [G loss: 0.871263]\n",
      "epoch:11 step:11025 [D loss: 0.696371, acc.: 51.56%] [G loss: 1.050563]\n",
      "epoch:11 step:11026 [D loss: 0.663871, acc.: 59.38%] [G loss: 1.085532]\n",
      "epoch:11 step:11027 [D loss: 0.635636, acc.: 67.19%] [G loss: 1.104377]\n",
      "epoch:11 step:11028 [D loss: 0.542403, acc.: 73.44%] [G loss: 1.183604]\n",
      "epoch:11 step:11029 [D loss: 0.722902, acc.: 52.34%] [G loss: 1.048460]\n",
      "epoch:11 step:11030 [D loss: 0.669275, acc.: 57.03%] [G loss: 0.926270]\n",
      "epoch:11 step:11031 [D loss: 0.469431, acc.: 86.72%] [G loss: 0.985932]\n",
      "epoch:11 step:11032 [D loss: 0.472574, acc.: 84.38%] [G loss: 1.221639]\n",
      "epoch:11 step:11033 [D loss: 0.499268, acc.: 87.50%] [G loss: 1.233586]\n",
      "epoch:11 step:11034 [D loss: 0.806418, acc.: 53.12%] [G loss: 0.982808]\n",
      "epoch:11 step:11035 [D loss: 0.760941, acc.: 50.00%] [G loss: 0.846273]\n",
      "epoch:11 step:11036 [D loss: 0.714063, acc.: 50.00%] [G loss: 0.989619]\n",
      "epoch:11 step:11037 [D loss: 0.677227, acc.: 54.69%] [G loss: 0.895037]\n",
      "epoch:11 step:11038 [D loss: 0.659038, acc.: 62.50%] [G loss: 0.795246]\n",
      "epoch:11 step:11039 [D loss: 0.633776, acc.: 64.84%] [G loss: 0.895782]\n",
      "epoch:11 step:11040 [D loss: 0.581892, acc.: 68.75%] [G loss: 0.903733]\n",
      "epoch:11 step:11041 [D loss: 0.706322, acc.: 55.47%] [G loss: 0.676444]\n",
      "epoch:11 step:11042 [D loss: 0.604912, acc.: 68.75%] [G loss: 0.874798]\n",
      "epoch:11 step:11043 [D loss: 0.636359, acc.: 58.59%] [G loss: 1.028588]\n",
      "epoch:11 step:11044 [D loss: 0.661900, acc.: 57.81%] [G loss: 0.655270]\n",
      "epoch:11 step:11045 [D loss: 0.687052, acc.: 53.91%] [G loss: 0.806057]\n",
      "epoch:11 step:11046 [D loss: 0.832336, acc.: 40.62%] [G loss: 0.780835]\n",
      "epoch:11 step:11047 [D loss: 0.668765, acc.: 57.81%] [G loss: 0.936984]\n",
      "epoch:11 step:11048 [D loss: 0.621101, acc.: 64.06%] [G loss: 0.993021]\n",
      "epoch:11 step:11049 [D loss: 0.584543, acc.: 67.97%] [G loss: 0.921154]\n",
      "epoch:11 step:11050 [D loss: 0.445736, acc.: 92.19%] [G loss: 1.075829]\n",
      "epoch:11 step:11051 [D loss: 0.646480, acc.: 57.81%] [G loss: 1.065284]\n",
      "epoch:11 step:11052 [D loss: 0.754314, acc.: 53.91%] [G loss: 0.999036]\n",
      "epoch:11 step:11053 [D loss: 0.765015, acc.: 46.88%] [G loss: 0.946273]\n",
      "epoch:11 step:11054 [D loss: 0.678774, acc.: 64.06%] [G loss: 0.907412]\n",
      "epoch:11 step:11055 [D loss: 0.597368, acc.: 69.53%] [G loss: 0.802062]\n",
      "epoch:11 step:11056 [D loss: 0.552487, acc.: 75.00%] [G loss: 0.763979]\n",
      "epoch:11 step:11057 [D loss: 0.458583, acc.: 87.50%] [G loss: 0.893376]\n",
      "epoch:11 step:11058 [D loss: 0.669664, acc.: 63.28%] [G loss: 0.746706]\n",
      "epoch:11 step:11059 [D loss: 0.761819, acc.: 42.97%] [G loss: 1.050072]\n",
      "epoch:11 step:11060 [D loss: 0.722386, acc.: 50.00%] [G loss: 0.774768]\n",
      "epoch:11 step:11061 [D loss: 0.710029, acc.: 50.78%] [G loss: 0.930019]\n",
      "epoch:11 step:11062 [D loss: 0.638662, acc.: 61.72%] [G loss: 0.807106]\n",
      "epoch:11 step:11063 [D loss: 0.591822, acc.: 73.44%] [G loss: 0.743707]\n",
      "epoch:11 step:11064 [D loss: 0.662456, acc.: 55.47%] [G loss: 0.894214]\n",
      "epoch:11 step:11065 [D loss: 0.720993, acc.: 46.09%] [G loss: 0.796371]\n",
      "epoch:11 step:11066 [D loss: 0.620425, acc.: 64.06%] [G loss: 0.783236]\n",
      "epoch:11 step:11067 [D loss: 0.595041, acc.: 71.88%] [G loss: 0.690211]\n",
      "epoch:11 step:11068 [D loss: 0.788509, acc.: 39.06%] [G loss: 0.756047]\n",
      "epoch:11 step:11069 [D loss: 0.678939, acc.: 59.38%] [G loss: 0.876808]\n",
      "epoch:11 step:11070 [D loss: 0.644796, acc.: 63.28%] [G loss: 0.779725]\n",
      "epoch:11 step:11071 [D loss: 0.569808, acc.: 73.44%] [G loss: 0.765266]\n",
      "epoch:11 step:11072 [D loss: 0.642306, acc.: 60.16%] [G loss: 0.887930]\n",
      "epoch:11 step:11073 [D loss: 0.607086, acc.: 69.53%] [G loss: 0.855770]\n",
      "epoch:11 step:11074 [D loss: 0.596751, acc.: 71.88%] [G loss: 0.735045]\n",
      "epoch:11 step:11075 [D loss: 0.503807, acc.: 80.47%] [G loss: 0.905787]\n",
      "epoch:11 step:11076 [D loss: 0.600109, acc.: 67.97%] [G loss: 0.773005]\n",
      "epoch:11 step:11077 [D loss: 0.681012, acc.: 60.94%] [G loss: 0.901182]\n",
      "epoch:11 step:11078 [D loss: 0.726539, acc.: 53.12%] [G loss: 0.883698]\n",
      "epoch:11 step:11079 [D loss: 0.699791, acc.: 54.69%] [G loss: 0.874227]\n",
      "epoch:11 step:11080 [D loss: 0.723048, acc.: 57.81%] [G loss: 0.784965]\n",
      "epoch:11 step:11081 [D loss: 0.593999, acc.: 69.53%] [G loss: 0.866946]\n",
      "epoch:11 step:11082 [D loss: 0.659542, acc.: 57.03%] [G loss: 0.798743]\n",
      "epoch:11 step:11083 [D loss: 0.716455, acc.: 52.34%] [G loss: 0.716981]\n",
      "epoch:11 step:11084 [D loss: 0.676831, acc.: 58.59%] [G loss: 0.806630]\n",
      "epoch:11 step:11085 [D loss: 0.773599, acc.: 49.22%] [G loss: 0.935555]\n",
      "epoch:11 step:11086 [D loss: 0.732975, acc.: 52.34%] [G loss: 0.861396]\n",
      "epoch:11 step:11087 [D loss: 0.470727, acc.: 81.25%] [G loss: 0.991984]\n",
      "epoch:11 step:11088 [D loss: 0.394228, acc.: 85.16%] [G loss: 1.042521]\n",
      "epoch:11 step:11089 [D loss: 0.442662, acc.: 80.47%] [G loss: 1.098359]\n",
      "epoch:11 step:11090 [D loss: 0.483664, acc.: 81.25%] [G loss: 1.146496]\n",
      "epoch:11 step:11091 [D loss: 0.496301, acc.: 81.25%] [G loss: 1.183109]\n",
      "epoch:11 step:11092 [D loss: 0.615141, acc.: 67.97%] [G loss: 1.130243]\n",
      "epoch:11 step:11093 [D loss: 0.389053, acc.: 80.47%] [G loss: 1.161870]\n",
      "epoch:11 step:11094 [D loss: 0.743511, acc.: 51.56%] [G loss: 1.180198]\n",
      "epoch:11 step:11095 [D loss: 0.463125, acc.: 82.03%] [G loss: 1.127244]\n",
      "epoch:11 step:11096 [D loss: 0.784386, acc.: 46.88%] [G loss: 0.973469]\n",
      "epoch:11 step:11097 [D loss: 0.652460, acc.: 60.94%] [G loss: 0.834701]\n",
      "epoch:11 step:11098 [D loss: 0.367392, acc.: 90.62%] [G loss: 1.049543]\n",
      "epoch:11 step:11099 [D loss: 0.349613, acc.: 81.25%] [G loss: 1.077153]\n",
      "epoch:11 step:11100 [D loss: 0.376767, acc.: 85.94%] [G loss: 1.160456]\n",
      "epoch:11 step:11101 [D loss: 0.245314, acc.: 98.44%] [G loss: 1.203357]\n",
      "epoch:11 step:11102 [D loss: 0.363964, acc.: 91.41%] [G loss: 1.130644]\n",
      "epoch:11 step:11103 [D loss: 0.247755, acc.: 96.88%] [G loss: 0.858055]\n",
      "epoch:11 step:11104 [D loss: 0.774418, acc.: 53.12%] [G loss: 1.072121]\n",
      "epoch:11 step:11105 [D loss: 0.670593, acc.: 52.34%] [G loss: 1.178668]\n",
      "epoch:11 step:11106 [D loss: 0.749185, acc.: 56.25%] [G loss: 0.202098]\n",
      "epoch:11 step:11107 [D loss: 0.731860, acc.: 50.00%] [G loss: 0.611242]\n",
      "epoch:11 step:11108 [D loss: 0.987151, acc.: 25.78%] [G loss: 0.830370]\n",
      "epoch:11 step:11109 [D loss: 0.774341, acc.: 59.38%] [G loss: 0.983345]\n",
      "epoch:11 step:11110 [D loss: 0.719580, acc.: 48.44%] [G loss: 0.838492]\n",
      "epoch:11 step:11111 [D loss: 0.367551, acc.: 83.59%] [G loss: 1.124973]\n",
      "epoch:11 step:11112 [D loss: 0.796386, acc.: 53.91%] [G loss: 1.230959]\n",
      "epoch:11 step:11113 [D loss: 0.396154, acc.: 83.59%] [G loss: 1.502826]\n",
      "epoch:11 step:11114 [D loss: 0.686070, acc.: 55.47%] [G loss: 1.303260]\n",
      "epoch:11 step:11115 [D loss: 0.683722, acc.: 57.03%] [G loss: 1.343965]\n",
      "epoch:11 step:11116 [D loss: 0.622054, acc.: 59.38%] [G loss: 1.244322]\n",
      "epoch:11 step:11117 [D loss: 0.668377, acc.: 53.12%] [G loss: 1.289301]\n",
      "epoch:11 step:11118 [D loss: 0.877006, acc.: 39.06%] [G loss: 1.207302]\n",
      "epoch:11 step:11119 [D loss: 0.760002, acc.: 51.56%] [G loss: 1.057740]\n",
      "epoch:11 step:11120 [D loss: 0.756097, acc.: 51.56%] [G loss: 1.068168]\n",
      "epoch:11 step:11121 [D loss: 0.728689, acc.: 48.44%] [G loss: 1.033793]\n",
      "epoch:11 step:11122 [D loss: 0.533224, acc.: 77.34%] [G loss: 0.976542]\n",
      "epoch:11 step:11123 [D loss: 0.565998, acc.: 75.78%] [G loss: 1.065153]\n",
      "epoch:11 step:11124 [D loss: 0.757724, acc.: 52.34%] [G loss: 1.072944]\n",
      "epoch:11 step:11125 [D loss: 0.624134, acc.: 60.16%] [G loss: 0.975376]\n",
      "epoch:11 step:11126 [D loss: 0.585178, acc.: 67.97%] [G loss: 0.990461]\n",
      "epoch:11 step:11127 [D loss: 0.692918, acc.: 47.66%] [G loss: 1.047953]\n",
      "epoch:11 step:11128 [D loss: 0.839149, acc.: 38.28%] [G loss: 0.907727]\n",
      "epoch:11 step:11129 [D loss: 0.736697, acc.: 43.75%] [G loss: 0.808475]\n",
      "epoch:11 step:11130 [D loss: 0.645267, acc.: 60.94%] [G loss: 0.793613]\n",
      "epoch:11 step:11131 [D loss: 0.550823, acc.: 80.47%] [G loss: 0.876381]\n",
      "epoch:11 step:11132 [D loss: 0.606647, acc.: 67.97%] [G loss: 1.081119]\n",
      "epoch:11 step:11133 [D loss: 0.568622, acc.: 79.69%] [G loss: 1.087153]\n",
      "epoch:11 step:11134 [D loss: 0.707356, acc.: 54.69%] [G loss: 0.805951]\n",
      "epoch:11 step:11135 [D loss: 0.665077, acc.: 57.81%] [G loss: 0.779655]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:11136 [D loss: 0.706318, acc.: 53.12%] [G loss: 0.748470]\n",
      "epoch:11 step:11137 [D loss: 0.626483, acc.: 68.75%] [G loss: 0.940270]\n",
      "epoch:11 step:11138 [D loss: 0.540537, acc.: 80.47%] [G loss: 0.923507]\n",
      "epoch:11 step:11139 [D loss: 0.511309, acc.: 82.81%] [G loss: 1.028609]\n",
      "epoch:11 step:11140 [D loss: 0.524792, acc.: 80.47%] [G loss: 0.783499]\n",
      "epoch:11 step:11141 [D loss: 0.807475, acc.: 40.62%] [G loss: 1.159161]\n",
      "epoch:11 step:11142 [D loss: 0.600217, acc.: 69.53%] [G loss: 1.072495]\n",
      "epoch:11 step:11143 [D loss: 0.725495, acc.: 42.97%] [G loss: 0.879589]\n",
      "epoch:11 step:11144 [D loss: 0.772449, acc.: 47.66%] [G loss: 0.754111]\n",
      "epoch:11 step:11145 [D loss: 0.588939, acc.: 71.09%] [G loss: 0.837679]\n",
      "epoch:11 step:11146 [D loss: 0.712054, acc.: 47.66%] [G loss: 0.545432]\n",
      "epoch:11 step:11147 [D loss: 0.737238, acc.: 48.44%] [G loss: 0.827028]\n",
      "epoch:11 step:11148 [D loss: 0.759009, acc.: 49.22%] [G loss: 0.799248]\n",
      "epoch:11 step:11149 [D loss: 0.660835, acc.: 60.16%] [G loss: 0.834363]\n",
      "epoch:11 step:11150 [D loss: 0.638499, acc.: 63.28%] [G loss: 0.826480]\n",
      "epoch:11 step:11151 [D loss: 0.714215, acc.: 47.66%] [G loss: 0.976925]\n",
      "epoch:11 step:11152 [D loss: 0.471951, acc.: 68.75%] [G loss: 0.801037]\n",
      "epoch:11 step:11153 [D loss: 0.690566, acc.: 53.91%] [G loss: 0.793598]\n",
      "epoch:11 step:11154 [D loss: 0.758594, acc.: 46.88%] [G loss: 0.825570]\n",
      "epoch:11 step:11155 [D loss: 0.774079, acc.: 40.62%] [G loss: 0.758640]\n",
      "epoch:11 step:11156 [D loss: 0.655749, acc.: 60.94%] [G loss: 0.816377]\n",
      "epoch:11 step:11157 [D loss: 0.700012, acc.: 57.81%] [G loss: 0.717587]\n",
      "epoch:11 step:11158 [D loss: 0.653129, acc.: 52.34%] [G loss: 0.810510]\n",
      "epoch:11 step:11159 [D loss: 0.562904, acc.: 72.66%] [G loss: 0.791840]\n",
      "epoch:11 step:11160 [D loss: 0.566678, acc.: 75.78%] [G loss: 0.738364]\n",
      "epoch:11 step:11161 [D loss: 0.445598, acc.: 85.16%] [G loss: 0.828217]\n",
      "epoch:11 step:11162 [D loss: 0.696631, acc.: 57.03%] [G loss: 0.837731]\n",
      "epoch:11 step:11163 [D loss: 0.703001, acc.: 57.03%] [G loss: 0.778683]\n",
      "epoch:11 step:11164 [D loss: 0.533901, acc.: 77.34%] [G loss: 0.903198]\n",
      "epoch:11 step:11165 [D loss: 0.714555, acc.: 46.88%] [G loss: 0.828594]\n",
      "epoch:11 step:11166 [D loss: 0.614874, acc.: 64.84%] [G loss: 0.773026]\n",
      "epoch:11 step:11167 [D loss: 0.716487, acc.: 51.56%] [G loss: 0.911606]\n",
      "epoch:11 step:11168 [D loss: 0.625443, acc.: 71.88%] [G loss: 0.831873]\n",
      "epoch:11 step:11169 [D loss: 0.699166, acc.: 55.47%] [G loss: 0.817430]\n",
      "epoch:11 step:11170 [D loss: 0.661302, acc.: 63.28%] [G loss: 0.842854]\n",
      "epoch:11 step:11171 [D loss: 0.722293, acc.: 44.53%] [G loss: 0.822808]\n",
      "epoch:11 step:11172 [D loss: 0.583649, acc.: 66.41%] [G loss: 0.830538]\n",
      "epoch:11 step:11173 [D loss: 0.609531, acc.: 67.19%] [G loss: 0.850851]\n",
      "epoch:11 step:11174 [D loss: 0.491132, acc.: 71.09%] [G loss: 0.861510]\n",
      "epoch:11 step:11175 [D loss: 0.672307, acc.: 60.94%] [G loss: 0.782013]\n",
      "epoch:11 step:11176 [D loss: 0.650773, acc.: 61.72%] [G loss: 0.811067]\n",
      "epoch:11 step:11177 [D loss: 0.648421, acc.: 67.97%] [G loss: 0.856717]\n",
      "epoch:11 step:11178 [D loss: 0.601801, acc.: 72.66%] [G loss: 0.814495]\n",
      "epoch:11 step:11179 [D loss: 0.472493, acc.: 76.56%] [G loss: 0.438000]\n",
      "epoch:11 step:11180 [D loss: 0.582841, acc.: 73.44%] [G loss: 0.882607]\n",
      "epoch:11 step:11181 [D loss: 0.481483, acc.: 78.12%] [G loss: 0.926629]\n",
      "epoch:11 step:11182 [D loss: 0.592444, acc.: 74.22%] [G loss: 0.872450]\n",
      "epoch:11 step:11183 [D loss: 0.596794, acc.: 70.31%] [G loss: 0.910279]\n",
      "epoch:11 step:11184 [D loss: 0.651905, acc.: 61.72%] [G loss: 0.835770]\n",
      "epoch:11 step:11185 [D loss: 0.721964, acc.: 50.78%] [G loss: 0.795593]\n",
      "epoch:11 step:11186 [D loss: 0.595107, acc.: 75.78%] [G loss: 0.829490]\n",
      "epoch:11 step:11187 [D loss: 0.671481, acc.: 60.16%] [G loss: 0.502408]\n",
      "epoch:11 step:11188 [D loss: 0.587245, acc.: 70.31%] [G loss: 0.707300]\n",
      "epoch:11 step:11189 [D loss: 0.391340, acc.: 78.91%] [G loss: 0.850764]\n",
      "epoch:11 step:11190 [D loss: 0.431281, acc.: 72.66%] [G loss: 1.053168]\n",
      "epoch:11 step:11191 [D loss: 0.269331, acc.: 94.53%] [G loss: 1.169164]\n",
      "epoch:11 step:11192 [D loss: 0.254227, acc.: 97.66%] [G loss: 1.192927]\n",
      "epoch:11 step:11193 [D loss: 0.246164, acc.: 96.09%] [G loss: 1.078681]\n",
      "epoch:11 step:11194 [D loss: 0.183475, acc.: 99.22%] [G loss: 1.219876]\n",
      "epoch:11 step:11195 [D loss: 0.820009, acc.: 45.31%] [G loss: 0.666304]\n",
      "epoch:11 step:11196 [D loss: 0.762217, acc.: 53.12%] [G loss: 1.349830]\n",
      "epoch:11 step:11197 [D loss: 0.273698, acc.: 99.22%] [G loss: 0.537777]\n",
      "epoch:11 step:11198 [D loss: 1.453359, acc.: 7.81%] [G loss: 1.231310]\n",
      "epoch:11 step:11199 [D loss: 0.874291, acc.: 50.00%] [G loss: 1.252927]\n",
      "epoch:11 step:11200 [D loss: 0.827579, acc.: 50.78%] [G loss: 1.191041]\n",
      "##############\n",
      "[4.30730225 2.94377876 6.60557016 6.17687716 4.56202557 6.21855019\n",
      " 5.65746013 6.08030498 6.1525054  5.04126453]\n",
      "##########\n",
      "epoch:11 step:11201 [D loss: 0.716880, acc.: 55.47%] [G loss: 1.124018]\n",
      "epoch:11 step:11202 [D loss: 0.698519, acc.: 53.12%] [G loss: 1.145072]\n",
      "epoch:11 step:11203 [D loss: 0.690184, acc.: 52.34%] [G loss: 1.096135]\n",
      "epoch:11 step:11204 [D loss: 0.674240, acc.: 60.94%] [G loss: 1.085222]\n",
      "epoch:11 step:11205 [D loss: 0.625232, acc.: 64.84%] [G loss: 1.066020]\n",
      "epoch:11 step:11206 [D loss: 0.513214, acc.: 80.47%] [G loss: 1.025692]\n",
      "epoch:11 step:11207 [D loss: 0.555900, acc.: 75.78%] [G loss: 1.201755]\n",
      "epoch:11 step:11208 [D loss: 0.590231, acc.: 65.62%] [G loss: 1.026756]\n",
      "epoch:11 step:11209 [D loss: 0.614672, acc.: 57.81%] [G loss: 1.049514]\n",
      "epoch:11 step:11210 [D loss: 0.638402, acc.: 64.06%] [G loss: 1.091498]\n",
      "epoch:11 step:11211 [D loss: 0.821257, acc.: 45.31%] [G loss: 0.896221]\n",
      "epoch:11 step:11212 [D loss: 0.729668, acc.: 50.78%] [G loss: 0.921315]\n",
      "epoch:11 step:11213 [D loss: 0.786269, acc.: 42.19%] [G loss: 0.831889]\n",
      "epoch:11 step:11214 [D loss: 0.693156, acc.: 59.38%] [G loss: 0.758874]\n",
      "epoch:11 step:11215 [D loss: 0.692651, acc.: 53.12%] [G loss: 0.785589]\n",
      "epoch:11 step:11216 [D loss: 0.584947, acc.: 78.12%] [G loss: 0.833241]\n",
      "epoch:11 step:11217 [D loss: 0.691713, acc.: 50.00%] [G loss: 0.787553]\n",
      "epoch:11 step:11218 [D loss: 0.579486, acc.: 73.44%] [G loss: 0.903673]\n",
      "epoch:11 step:11219 [D loss: 0.302301, acc.: 95.31%] [G loss: 0.807874]\n",
      "epoch:11 step:11220 [D loss: 0.611909, acc.: 63.28%] [G loss: 0.905514]\n",
      "epoch:11 step:11221 [D loss: 0.722763, acc.: 50.78%] [G loss: 0.804258]\n",
      "epoch:11 step:11222 [D loss: 0.705371, acc.: 51.56%] [G loss: 0.923971]\n",
      "epoch:11 step:11223 [D loss: 0.780946, acc.: 41.41%] [G loss: 0.810955]\n",
      "epoch:11 step:11224 [D loss: 0.716735, acc.: 52.34%] [G loss: 0.867371]\n",
      "epoch:11 step:11225 [D loss: 0.621044, acc.: 68.75%] [G loss: 0.762486]\n",
      "epoch:11 step:11226 [D loss: 0.572148, acc.: 69.53%] [G loss: 0.853363]\n",
      "epoch:11 step:11227 [D loss: 0.727186, acc.: 56.25%] [G loss: 0.839011]\n",
      "epoch:11 step:11228 [D loss: 0.643984, acc.: 66.41%] [G loss: 0.861447]\n",
      "epoch:11 step:11229 [D loss: 0.642016, acc.: 64.84%] [G loss: 0.819008]\n",
      "epoch:11 step:11230 [D loss: 0.633178, acc.: 61.72%] [G loss: 0.804137]\n",
      "epoch:11 step:11231 [D loss: 0.452554, acc.: 87.50%] [G loss: 0.799189]\n",
      "epoch:11 step:11232 [D loss: 0.473512, acc.: 83.59%] [G loss: 0.863458]\n",
      "epoch:11 step:11233 [D loss: 0.413005, acc.: 79.69%] [G loss: 1.005290]\n",
      "epoch:11 step:11234 [D loss: 0.314900, acc.: 90.62%] [G loss: 1.002249]\n",
      "epoch:11 step:11235 [D loss: 0.733965, acc.: 60.94%] [G loss: 0.980825]\n",
      "epoch:11 step:11236 [D loss: 0.659085, acc.: 60.16%] [G loss: 0.921499]\n",
      "epoch:11 step:11237 [D loss: 0.611529, acc.: 73.44%] [G loss: 0.900515]\n",
      "epoch:11 step:11238 [D loss: 0.628677, acc.: 64.06%] [G loss: 0.854071]\n",
      "epoch:11 step:11239 [D loss: 0.605220, acc.: 75.00%] [G loss: 0.908413]\n",
      "epoch:11 step:11240 [D loss: 0.387708, acc.: 92.97%] [G loss: 0.875043]\n",
      "epoch:11 step:11241 [D loss: 0.348066, acc.: 89.84%] [G loss: 1.000315]\n",
      "epoch:11 step:11242 [D loss: 0.519705, acc.: 78.91%] [G loss: 0.971148]\n",
      "epoch:11 step:11243 [D loss: 0.277384, acc.: 92.97%] [G loss: 1.056904]\n",
      "epoch:11 step:11244 [D loss: 0.211593, acc.: 98.44%] [G loss: 1.037996]\n",
      "epoch:12 step:11245 [D loss: 0.600019, acc.: 67.19%] [G loss: 0.949107]\n",
      "epoch:12 step:11246 [D loss: 0.767531, acc.: 46.88%] [G loss: 1.054022]\n",
      "epoch:12 step:11247 [D loss: 0.698655, acc.: 50.78%] [G loss: 0.875833]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11248 [D loss: 0.791392, acc.: 42.19%] [G loss: 0.959423]\n",
      "epoch:12 step:11249 [D loss: 0.718158, acc.: 48.44%] [G loss: 0.710933]\n",
      "epoch:12 step:11250 [D loss: 0.654792, acc.: 60.16%] [G loss: 0.616482]\n",
      "epoch:12 step:11251 [D loss: 0.617706, acc.: 65.62%] [G loss: 0.707091]\n",
      "epoch:12 step:11252 [D loss: 0.590195, acc.: 66.41%] [G loss: 0.488397]\n",
      "epoch:12 step:11253 [D loss: 0.588494, acc.: 71.88%] [G loss: 0.544074]\n",
      "epoch:12 step:11254 [D loss: 0.629430, acc.: 63.28%] [G loss: 0.650666]\n",
      "epoch:12 step:11255 [D loss: 0.644659, acc.: 63.28%] [G loss: 0.827073]\n",
      "epoch:12 step:11256 [D loss: 1.219486, acc.: 40.62%] [G loss: 1.013192]\n",
      "epoch:12 step:11257 [D loss: 0.616136, acc.: 67.19%] [G loss: 0.857725]\n",
      "epoch:12 step:11258 [D loss: 0.655254, acc.: 61.72%] [G loss: 0.782195]\n",
      "epoch:12 step:11259 [D loss: 0.608891, acc.: 69.53%] [G loss: 1.038693]\n",
      "epoch:12 step:11260 [D loss: 0.896171, acc.: 27.34%] [G loss: 0.848772]\n",
      "epoch:12 step:11261 [D loss: 0.732569, acc.: 51.56%] [G loss: 0.969091]\n",
      "epoch:12 step:11262 [D loss: 0.816137, acc.: 36.72%] [G loss: 1.005282]\n",
      "epoch:12 step:11263 [D loss: 0.759508, acc.: 46.09%] [G loss: 1.041234]\n",
      "epoch:12 step:11264 [D loss: 0.766482, acc.: 49.22%] [G loss: 0.818952]\n",
      "epoch:12 step:11265 [D loss: 0.733838, acc.: 49.22%] [G loss: 1.188145]\n",
      "epoch:12 step:11266 [D loss: 0.739784, acc.: 43.75%] [G loss: 0.944856]\n",
      "epoch:12 step:11267 [D loss: 0.709327, acc.: 49.22%] [G loss: 0.915441]\n",
      "epoch:12 step:11268 [D loss: 0.688143, acc.: 57.81%] [G loss: 0.975011]\n",
      "epoch:12 step:11269 [D loss: 0.645977, acc.: 64.06%] [G loss: 0.885677]\n",
      "epoch:12 step:11270 [D loss: 0.736616, acc.: 43.75%] [G loss: 0.946453]\n",
      "epoch:12 step:11271 [D loss: 0.701525, acc.: 56.25%] [G loss: 0.859542]\n",
      "epoch:12 step:11272 [D loss: 0.717111, acc.: 54.69%] [G loss: 0.862019]\n",
      "epoch:12 step:11273 [D loss: 0.710576, acc.: 53.12%] [G loss: 1.153558]\n",
      "epoch:12 step:11274 [D loss: 0.672483, acc.: 50.78%] [G loss: 0.867027]\n",
      "epoch:12 step:11275 [D loss: 0.577245, acc.: 75.78%] [G loss: 0.983140]\n",
      "epoch:12 step:11276 [D loss: 0.640634, acc.: 60.94%] [G loss: 0.855889]\n",
      "epoch:12 step:11277 [D loss: 0.602195, acc.: 71.88%] [G loss: 0.986596]\n",
      "epoch:12 step:11278 [D loss: 0.635572, acc.: 67.97%] [G loss: 0.938661]\n",
      "epoch:12 step:11279 [D loss: 0.534476, acc.: 78.91%] [G loss: 1.169849]\n",
      "epoch:12 step:11280 [D loss: 0.502056, acc.: 78.91%] [G loss: 1.076612]\n",
      "epoch:12 step:11281 [D loss: 0.689332, acc.: 56.25%] [G loss: 1.026492]\n",
      "epoch:12 step:11282 [D loss: 0.895471, acc.: 35.94%] [G loss: 0.840052]\n",
      "epoch:12 step:11283 [D loss: 0.741074, acc.: 49.22%] [G loss: 0.787438]\n",
      "epoch:12 step:11284 [D loss: 0.794104, acc.: 40.62%] [G loss: 0.750473]\n",
      "epoch:12 step:11285 [D loss: 0.692529, acc.: 53.91%] [G loss: 0.776326]\n",
      "epoch:12 step:11286 [D loss: 0.661501, acc.: 61.72%] [G loss: 0.763206]\n",
      "epoch:12 step:11287 [D loss: 0.661756, acc.: 60.16%] [G loss: 0.763456]\n",
      "epoch:12 step:11288 [D loss: 0.682100, acc.: 59.38%] [G loss: 0.709453]\n",
      "epoch:12 step:11289 [D loss: 0.681279, acc.: 55.47%] [G loss: 0.820155]\n",
      "epoch:12 step:11290 [D loss: 0.635309, acc.: 71.88%] [G loss: 0.853544]\n",
      "epoch:12 step:11291 [D loss: 0.654914, acc.: 64.84%] [G loss: 0.834493]\n",
      "epoch:12 step:11292 [D loss: 0.682126, acc.: 53.12%] [G loss: 0.797974]\n",
      "epoch:12 step:11293 [D loss: 0.659778, acc.: 55.47%] [G loss: 0.812200]\n",
      "epoch:12 step:11294 [D loss: 0.662320, acc.: 60.16%] [G loss: 0.856630]\n",
      "epoch:12 step:11295 [D loss: 0.601923, acc.: 69.53%] [G loss: 0.844235]\n",
      "epoch:12 step:11296 [D loss: 0.658089, acc.: 59.38%] [G loss: 0.886619]\n",
      "epoch:12 step:11297 [D loss: 0.663234, acc.: 64.06%] [G loss: 0.785008]\n",
      "epoch:12 step:11298 [D loss: 0.654393, acc.: 64.06%] [G loss: 0.758348]\n",
      "epoch:12 step:11299 [D loss: 0.675871, acc.: 57.81%] [G loss: 0.689844]\n",
      "epoch:12 step:11300 [D loss: 0.641252, acc.: 64.84%] [G loss: 0.786590]\n",
      "epoch:12 step:11301 [D loss: 0.589059, acc.: 69.53%] [G loss: 0.810286]\n",
      "epoch:12 step:11302 [D loss: 0.681658, acc.: 70.31%] [G loss: 0.841552]\n",
      "epoch:12 step:11303 [D loss: 0.680131, acc.: 57.81%] [G loss: 0.864782]\n",
      "epoch:12 step:11304 [D loss: 0.611597, acc.: 65.62%] [G loss: 1.068518]\n",
      "epoch:12 step:11305 [D loss: 0.712034, acc.: 54.69%] [G loss: 0.870228]\n",
      "epoch:12 step:11306 [D loss: 0.740732, acc.: 42.97%] [G loss: 0.841025]\n",
      "epoch:12 step:11307 [D loss: 0.649570, acc.: 62.50%] [G loss: 0.788975]\n",
      "epoch:12 step:11308 [D loss: 0.729188, acc.: 51.56%] [G loss: 1.070262]\n",
      "epoch:12 step:11309 [D loss: 0.698261, acc.: 57.03%] [G loss: 0.683661]\n",
      "epoch:12 step:11310 [D loss: 0.659983, acc.: 67.19%] [G loss: 0.678009]\n",
      "epoch:12 step:11311 [D loss: 0.679686, acc.: 53.91%] [G loss: 0.983032]\n",
      "epoch:12 step:11312 [D loss: 0.714766, acc.: 49.22%] [G loss: 0.757160]\n",
      "epoch:12 step:11313 [D loss: 0.837513, acc.: 27.34%] [G loss: 0.686926]\n",
      "epoch:12 step:11314 [D loss: 0.785694, acc.: 38.28%] [G loss: 0.802868]\n",
      "epoch:12 step:11315 [D loss: 0.473715, acc.: 76.56%] [G loss: 0.810891]\n",
      "epoch:12 step:11316 [D loss: 0.635915, acc.: 66.41%] [G loss: 0.824242]\n",
      "epoch:12 step:11317 [D loss: 0.696890, acc.: 53.91%] [G loss: 0.753227]\n",
      "epoch:12 step:11318 [D loss: 0.693810, acc.: 50.78%] [G loss: 0.919280]\n",
      "epoch:12 step:11319 [D loss: 0.386692, acc.: 92.97%] [G loss: 0.927344]\n",
      "epoch:12 step:11320 [D loss: 0.528646, acc.: 82.81%] [G loss: 0.866600]\n",
      "epoch:12 step:11321 [D loss: 0.386077, acc.: 95.31%] [G loss: 1.140599]\n",
      "epoch:12 step:11322 [D loss: 0.761093, acc.: 40.62%] [G loss: 0.912905]\n",
      "epoch:12 step:11323 [D loss: 0.661024, acc.: 62.50%] [G loss: 0.821941]\n",
      "epoch:12 step:11324 [D loss: 0.729562, acc.: 52.34%] [G loss: 0.869413]\n",
      "epoch:12 step:11325 [D loss: 0.774342, acc.: 38.28%] [G loss: 0.910281]\n",
      "epoch:12 step:11326 [D loss: 0.721060, acc.: 50.00%] [G loss: 0.796174]\n",
      "epoch:12 step:11327 [D loss: 0.709859, acc.: 53.91%] [G loss: 0.876840]\n",
      "epoch:12 step:11328 [D loss: 0.663179, acc.: 59.38%] [G loss: 0.561164]\n",
      "epoch:12 step:11329 [D loss: 0.754030, acc.: 49.22%] [G loss: 0.577366]\n",
      "epoch:12 step:11330 [D loss: 0.889592, acc.: 33.59%] [G loss: 0.810646]\n",
      "epoch:12 step:11331 [D loss: 0.658658, acc.: 58.59%] [G loss: 0.837789]\n",
      "epoch:12 step:11332 [D loss: 0.645899, acc.: 64.84%] [G loss: 0.702539]\n",
      "epoch:12 step:11333 [D loss: 0.643705, acc.: 64.06%] [G loss: 0.918104]\n",
      "epoch:12 step:11334 [D loss: 0.766841, acc.: 42.97%] [G loss: 0.727169]\n",
      "epoch:12 step:11335 [D loss: 0.666368, acc.: 57.81%] [G loss: 0.777240]\n",
      "epoch:12 step:11336 [D loss: 0.654207, acc.: 59.38%] [G loss: 0.903703]\n",
      "epoch:12 step:11337 [D loss: 0.656240, acc.: 69.53%] [G loss: 0.875196]\n",
      "epoch:12 step:11338 [D loss: 0.675259, acc.: 57.03%] [G loss: 0.774675]\n",
      "epoch:12 step:11339 [D loss: 0.650097, acc.: 63.28%] [G loss: 0.958726]\n",
      "epoch:12 step:11340 [D loss: 0.664366, acc.: 57.03%] [G loss: 0.792475]\n",
      "epoch:12 step:11341 [D loss: 0.633037, acc.: 67.19%] [G loss: 0.818413]\n",
      "epoch:12 step:11342 [D loss: 0.679557, acc.: 60.16%] [G loss: 0.836854]\n",
      "epoch:12 step:11343 [D loss: 0.676810, acc.: 53.91%] [G loss: 0.799326]\n",
      "epoch:12 step:11344 [D loss: 0.641827, acc.: 61.72%] [G loss: 0.698979]\n",
      "epoch:12 step:11345 [D loss: 0.627639, acc.: 65.62%] [G loss: 0.729197]\n",
      "epoch:12 step:11346 [D loss: 0.654039, acc.: 57.81%] [G loss: 0.868884]\n",
      "epoch:12 step:11347 [D loss: 0.730587, acc.: 50.78%] [G loss: 0.773769]\n",
      "epoch:12 step:11348 [D loss: 0.802404, acc.: 39.84%] [G loss: 0.859827]\n",
      "epoch:12 step:11349 [D loss: 0.582075, acc.: 74.22%] [G loss: 0.721379]\n",
      "epoch:12 step:11350 [D loss: 0.626305, acc.: 64.06%] [G loss: 0.735975]\n",
      "epoch:12 step:11351 [D loss: 0.610376, acc.: 71.88%] [G loss: 0.943925]\n",
      "epoch:12 step:11352 [D loss: 0.702120, acc.: 50.78%] [G loss: 0.996095]\n",
      "epoch:12 step:11353 [D loss: 0.701639, acc.: 50.78%] [G loss: 0.791076]\n",
      "epoch:12 step:11354 [D loss: 0.695287, acc.: 52.34%] [G loss: 0.785795]\n",
      "epoch:12 step:11355 [D loss: 0.602013, acc.: 70.31%] [G loss: 0.920884]\n",
      "epoch:12 step:11356 [D loss: 0.597070, acc.: 70.31%] [G loss: 0.890568]\n",
      "epoch:12 step:11357 [D loss: 0.508311, acc.: 84.38%] [G loss: 1.029813]\n",
      "epoch:12 step:11358 [D loss: 0.502632, acc.: 76.56%] [G loss: 1.106613]\n",
      "epoch:12 step:11359 [D loss: 0.507514, acc.: 77.34%] [G loss: 1.079195]\n",
      "epoch:12 step:11360 [D loss: 0.643296, acc.: 63.28%] [G loss: 1.042798]\n",
      "epoch:12 step:11361 [D loss: 0.690902, acc.: 50.78%] [G loss: 0.861935]\n",
      "epoch:12 step:11362 [D loss: 0.745581, acc.: 54.69%] [G loss: 0.904213]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11363 [D loss: 0.751867, acc.: 53.12%] [G loss: 0.889743]\n",
      "epoch:12 step:11364 [D loss: 0.602377, acc.: 71.09%] [G loss: 0.892369]\n",
      "epoch:12 step:11365 [D loss: 0.529553, acc.: 75.00%] [G loss: 0.981665]\n",
      "epoch:12 step:11366 [D loss: 0.429638, acc.: 90.62%] [G loss: 0.349110]\n",
      "epoch:12 step:11367 [D loss: 0.603518, acc.: 72.66%] [G loss: 1.055515]\n",
      "epoch:12 step:11368 [D loss: 0.772777, acc.: 49.22%] [G loss: 0.968902]\n",
      "epoch:12 step:11369 [D loss: 0.595222, acc.: 65.62%] [G loss: 1.228976]\n",
      "epoch:12 step:11370 [D loss: 0.594078, acc.: 69.53%] [G loss: 0.808094]\n",
      "epoch:12 step:11371 [D loss: 0.655409, acc.: 60.16%] [G loss: 1.043990]\n",
      "epoch:12 step:11372 [D loss: 0.515086, acc.: 83.59%] [G loss: 1.203589]\n",
      "epoch:12 step:11373 [D loss: 0.414455, acc.: 93.75%] [G loss: 0.960215]\n",
      "epoch:12 step:11374 [D loss: 0.382472, acc.: 88.28%] [G loss: 1.417303]\n",
      "epoch:12 step:11375 [D loss: 0.588319, acc.: 67.19%] [G loss: 0.741574]\n",
      "epoch:12 step:11376 [D loss: 0.500095, acc.: 81.25%] [G loss: 1.030072]\n",
      "epoch:12 step:11377 [D loss: 0.819332, acc.: 50.00%] [G loss: 0.868924]\n",
      "epoch:12 step:11378 [D loss: 0.742467, acc.: 53.12%] [G loss: 0.778720]\n",
      "epoch:12 step:11379 [D loss: 0.811404, acc.: 39.84%] [G loss: 0.956687]\n",
      "epoch:12 step:11380 [D loss: 0.862651, acc.: 44.53%] [G loss: 0.842895]\n",
      "epoch:12 step:11381 [D loss: 0.694731, acc.: 55.47%] [G loss: 0.918165]\n",
      "epoch:12 step:11382 [D loss: 0.654565, acc.: 62.50%] [G loss: 0.774703]\n",
      "epoch:12 step:11383 [D loss: 0.557033, acc.: 73.44%] [G loss: 0.993914]\n",
      "epoch:12 step:11384 [D loss: 0.718949, acc.: 55.47%] [G loss: 0.722102]\n",
      "epoch:12 step:11385 [D loss: 0.891570, acc.: 31.25%] [G loss: 0.766094]\n",
      "epoch:12 step:11386 [D loss: 0.967300, acc.: 20.31%] [G loss: 0.818474]\n",
      "epoch:12 step:11387 [D loss: 0.729386, acc.: 46.88%] [G loss: 1.004168]\n",
      "epoch:12 step:11388 [D loss: 0.691011, acc.: 57.03%] [G loss: 0.921738]\n",
      "epoch:12 step:11389 [D loss: 0.596739, acc.: 66.41%] [G loss: 1.000917]\n",
      "epoch:12 step:11390 [D loss: 0.686039, acc.: 55.47%] [G loss: 0.913328]\n",
      "epoch:12 step:11391 [D loss: 0.669067, acc.: 58.59%] [G loss: 0.878137]\n",
      "epoch:12 step:11392 [D loss: 0.683321, acc.: 58.59%] [G loss: 0.907480]\n",
      "epoch:12 step:11393 [D loss: 0.662984, acc.: 54.69%] [G loss: 0.850627]\n",
      "epoch:12 step:11394 [D loss: 0.511516, acc.: 80.47%] [G loss: 0.863699]\n",
      "epoch:12 step:11395 [D loss: 0.610104, acc.: 70.31%] [G loss: 0.830183]\n",
      "epoch:12 step:11396 [D loss: 0.587970, acc.: 72.66%] [G loss: 0.870850]\n",
      "epoch:12 step:11397 [D loss: 0.717778, acc.: 56.25%] [G loss: 0.883745]\n",
      "epoch:12 step:11398 [D loss: 0.685194, acc.: 57.03%] [G loss: 0.922972]\n",
      "epoch:12 step:11399 [D loss: 0.680015, acc.: 54.69%] [G loss: 0.843618]\n",
      "epoch:12 step:11400 [D loss: 0.707945, acc.: 48.44%] [G loss: 0.665988]\n",
      "##############\n",
      "[3.8680124  2.5448997  6.22795157 5.41565079 4.1124345  6.13286407\n",
      " 4.96585831 5.44143237 5.76709998 5.15737038]\n",
      "##########\n",
      "epoch:12 step:11401 [D loss: 0.757023, acc.: 48.44%] [G loss: 0.736024]\n",
      "epoch:12 step:11402 [D loss: 0.751231, acc.: 47.66%] [G loss: 0.794181]\n",
      "epoch:12 step:11403 [D loss: 0.717766, acc.: 50.78%] [G loss: 0.765365]\n",
      "epoch:12 step:11404 [D loss: 0.694424, acc.: 59.38%] [G loss: 0.812832]\n",
      "epoch:12 step:11405 [D loss: 0.706824, acc.: 50.78%] [G loss: 0.817466]\n",
      "epoch:12 step:11406 [D loss: 0.667379, acc.: 57.03%] [G loss: 0.828139]\n",
      "epoch:12 step:11407 [D loss: 0.675844, acc.: 54.69%] [G loss: 0.773746]\n",
      "epoch:12 step:11408 [D loss: 0.669645, acc.: 53.91%] [G loss: 0.784204]\n",
      "epoch:12 step:11409 [D loss: 0.677827, acc.: 61.72%] [G loss: 0.827157]\n",
      "epoch:12 step:11410 [D loss: 0.696957, acc.: 55.47%] [G loss: 0.849435]\n",
      "epoch:12 step:11411 [D loss: 0.691233, acc.: 54.69%] [G loss: 0.779865]\n",
      "epoch:12 step:11412 [D loss: 0.643223, acc.: 65.62%] [G loss: 0.892465]\n",
      "epoch:12 step:11413 [D loss: 0.679493, acc.: 57.81%] [G loss: 0.821483]\n",
      "epoch:12 step:11414 [D loss: 0.557427, acc.: 78.12%] [G loss: 0.891406]\n",
      "epoch:12 step:11415 [D loss: 0.640732, acc.: 64.84%] [G loss: 0.831160]\n",
      "epoch:12 step:11416 [D loss: 0.625911, acc.: 69.53%] [G loss: 0.943410]\n",
      "epoch:12 step:11417 [D loss: 0.644896, acc.: 63.28%] [G loss: 0.879675]\n",
      "epoch:12 step:11418 [D loss: 0.660814, acc.: 63.28%] [G loss: 0.842537]\n",
      "epoch:12 step:11419 [D loss: 0.638333, acc.: 66.41%] [G loss: 0.848086]\n",
      "epoch:12 step:11420 [D loss: 0.625057, acc.: 63.28%] [G loss: 0.819088]\n",
      "epoch:12 step:11421 [D loss: 0.700495, acc.: 52.34%] [G loss: 0.822405]\n",
      "epoch:12 step:11422 [D loss: 0.692895, acc.: 53.91%] [G loss: 0.826199]\n",
      "epoch:12 step:11423 [D loss: 0.667163, acc.: 62.50%] [G loss: 0.787108]\n",
      "epoch:12 step:11424 [D loss: 0.692658, acc.: 57.03%] [G loss: 0.874454]\n",
      "epoch:12 step:11425 [D loss: 0.714684, acc.: 49.22%] [G loss: 0.748991]\n",
      "epoch:12 step:11426 [D loss: 0.715146, acc.: 51.56%] [G loss: 0.796037]\n",
      "epoch:12 step:11427 [D loss: 0.768592, acc.: 43.75%] [G loss: 0.758010]\n",
      "epoch:12 step:11428 [D loss: 0.679284, acc.: 53.12%] [G loss: 0.831674]\n",
      "epoch:12 step:11429 [D loss: 0.702715, acc.: 57.81%] [G loss: 0.804466]\n",
      "epoch:12 step:11430 [D loss: 0.719713, acc.: 48.44%] [G loss: 0.832457]\n",
      "epoch:12 step:11431 [D loss: 0.703839, acc.: 49.22%] [G loss: 0.841665]\n",
      "epoch:12 step:11432 [D loss: 0.712584, acc.: 46.09%] [G loss: 0.848787]\n",
      "epoch:12 step:11433 [D loss: 0.662516, acc.: 60.16%] [G loss: 0.830436]\n",
      "epoch:12 step:11434 [D loss: 0.668527, acc.: 57.81%] [G loss: 0.830066]\n",
      "epoch:12 step:11435 [D loss: 0.657954, acc.: 60.94%] [G loss: 0.809415]\n",
      "epoch:12 step:11436 [D loss: 0.645529, acc.: 61.72%] [G loss: 0.873722]\n",
      "epoch:12 step:11437 [D loss: 0.680541, acc.: 59.38%] [G loss: 0.830256]\n",
      "epoch:12 step:11438 [D loss: 0.634562, acc.: 64.06%] [G loss: 0.816470]\n",
      "epoch:12 step:11439 [D loss: 0.603233, acc.: 72.66%] [G loss: 0.841078]\n",
      "epoch:12 step:11440 [D loss: 0.642438, acc.: 62.50%] [G loss: 0.812942]\n",
      "epoch:12 step:11441 [D loss: 0.679919, acc.: 54.69%] [G loss: 0.885069]\n",
      "epoch:12 step:11442 [D loss: 0.612263, acc.: 68.75%] [G loss: 0.870338]\n",
      "epoch:12 step:11443 [D loss: 0.695028, acc.: 53.91%] [G loss: 0.928699]\n",
      "epoch:12 step:11444 [D loss: 0.602214, acc.: 66.41%] [G loss: 0.858484]\n",
      "epoch:12 step:11445 [D loss: 0.550666, acc.: 73.44%] [G loss: 0.962052]\n",
      "epoch:12 step:11446 [D loss: 0.697716, acc.: 59.38%] [G loss: 0.885949]\n",
      "epoch:12 step:11447 [D loss: 0.718551, acc.: 58.59%] [G loss: 0.859721]\n",
      "epoch:12 step:11448 [D loss: 0.667515, acc.: 67.97%] [G loss: 0.881130]\n",
      "epoch:12 step:11449 [D loss: 0.663395, acc.: 62.50%] [G loss: 0.766079]\n",
      "epoch:12 step:11450 [D loss: 0.742181, acc.: 50.78%] [G loss: 0.812211]\n",
      "epoch:12 step:11451 [D loss: 0.503831, acc.: 73.44%] [G loss: 0.840766]\n",
      "epoch:12 step:11452 [D loss: 0.615436, acc.: 66.41%] [G loss: 0.841416]\n",
      "epoch:12 step:11453 [D loss: 0.585620, acc.: 71.88%] [G loss: 0.757658]\n",
      "epoch:12 step:11454 [D loss: 0.702983, acc.: 57.03%] [G loss: 0.830997]\n",
      "epoch:12 step:11455 [D loss: 0.816817, acc.: 35.16%] [G loss: 0.846060]\n",
      "epoch:12 step:11456 [D loss: 0.685901, acc.: 56.25%] [G loss: 0.802803]\n",
      "epoch:12 step:11457 [D loss: 0.685826, acc.: 57.03%] [G loss: 0.817703]\n",
      "epoch:12 step:11458 [D loss: 0.645797, acc.: 64.06%] [G loss: 0.823737]\n",
      "epoch:12 step:11459 [D loss: 0.740337, acc.: 43.75%] [G loss: 0.811702]\n",
      "epoch:12 step:11460 [D loss: 0.598745, acc.: 67.97%] [G loss: 0.824004]\n",
      "epoch:12 step:11461 [D loss: 0.696008, acc.: 52.34%] [G loss: 0.782661]\n",
      "epoch:12 step:11462 [D loss: 0.600705, acc.: 67.19%] [G loss: 0.777547]\n",
      "epoch:12 step:11463 [D loss: 0.550527, acc.: 75.78%] [G loss: 0.813634]\n",
      "epoch:12 step:11464 [D loss: 0.493521, acc.: 80.47%] [G loss: 0.817768]\n",
      "epoch:12 step:11465 [D loss: 0.460521, acc.: 78.12%] [G loss: 0.844221]\n",
      "epoch:12 step:11466 [D loss: 0.466636, acc.: 79.69%] [G loss: 1.034505]\n",
      "epoch:12 step:11467 [D loss: 0.638397, acc.: 59.38%] [G loss: 0.870925]\n",
      "epoch:12 step:11468 [D loss: 0.700431, acc.: 52.34%] [G loss: 0.987443]\n",
      "epoch:12 step:11469 [D loss: 0.669092, acc.: 58.59%] [G loss: 0.963754]\n",
      "epoch:12 step:11470 [D loss: 0.743683, acc.: 47.66%] [G loss: 0.866459]\n",
      "epoch:12 step:11471 [D loss: 0.761097, acc.: 43.75%] [G loss: 0.887312]\n",
      "epoch:12 step:11472 [D loss: 0.705436, acc.: 53.91%] [G loss: 0.933704]\n",
      "epoch:12 step:11473 [D loss: 0.676140, acc.: 55.47%] [G loss: 0.869732]\n",
      "epoch:12 step:11474 [D loss: 0.374841, acc.: 80.47%] [G loss: 0.917209]\n",
      "epoch:12 step:11475 [D loss: 0.466340, acc.: 82.03%] [G loss: 0.941539]\n",
      "epoch:12 step:11476 [D loss: 0.377728, acc.: 85.94%] [G loss: 0.991086]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11477 [D loss: 0.712944, acc.: 55.47%] [G loss: 0.988703]\n",
      "epoch:12 step:11478 [D loss: 0.543497, acc.: 82.81%] [G loss: 0.926920]\n",
      "epoch:12 step:11479 [D loss: 0.348379, acc.: 92.97%] [G loss: 0.917182]\n",
      "epoch:12 step:11480 [D loss: 0.668763, acc.: 62.50%] [G loss: 0.972795]\n",
      "epoch:12 step:11481 [D loss: 0.524854, acc.: 81.25%] [G loss: 0.971094]\n",
      "epoch:12 step:11482 [D loss: 0.437066, acc.: 81.25%] [G loss: 1.008720]\n",
      "epoch:12 step:11483 [D loss: 0.740750, acc.: 39.84%] [G loss: 0.998150]\n",
      "epoch:12 step:11484 [D loss: 0.702358, acc.: 53.12%] [G loss: 0.882892]\n",
      "epoch:12 step:11485 [D loss: 0.764577, acc.: 42.97%] [G loss: 0.928216]\n",
      "epoch:12 step:11486 [D loss: 0.730091, acc.: 43.75%] [G loss: 0.861901]\n",
      "epoch:12 step:11487 [D loss: 0.665968, acc.: 56.25%] [G loss: 0.911537]\n",
      "epoch:12 step:11488 [D loss: 0.700139, acc.: 52.34%] [G loss: 0.867904]\n",
      "epoch:12 step:11489 [D loss: 0.728058, acc.: 48.44%] [G loss: 0.832980]\n",
      "epoch:12 step:11490 [D loss: 0.701412, acc.: 44.53%] [G loss: 0.826067]\n",
      "epoch:12 step:11491 [D loss: 0.747833, acc.: 40.62%] [G loss: 0.810875]\n",
      "epoch:12 step:11492 [D loss: 0.725333, acc.: 46.88%] [G loss: 0.838409]\n",
      "epoch:12 step:11493 [D loss: 0.636596, acc.: 66.41%] [G loss: 0.677590]\n",
      "epoch:12 step:11494 [D loss: 1.036211, acc.: 21.09%] [G loss: 0.837849]\n",
      "epoch:12 step:11495 [D loss: 0.607421, acc.: 65.62%] [G loss: 0.896879]\n",
      "epoch:12 step:11496 [D loss: 0.653143, acc.: 60.16%] [G loss: 0.874954]\n",
      "epoch:12 step:11497 [D loss: 0.661822, acc.: 65.62%] [G loss: 0.862193]\n",
      "epoch:12 step:11498 [D loss: 0.614453, acc.: 73.44%] [G loss: 0.861259]\n",
      "epoch:12 step:11499 [D loss: 0.380375, acc.: 85.16%] [G loss: 0.893872]\n",
      "epoch:12 step:11500 [D loss: 0.315541, acc.: 92.19%] [G loss: 0.944482]\n",
      "epoch:12 step:11501 [D loss: 0.459767, acc.: 88.28%] [G loss: 0.979514]\n",
      "epoch:12 step:11502 [D loss: 0.686854, acc.: 52.34%] [G loss: 0.800649]\n",
      "epoch:12 step:11503 [D loss: 0.578596, acc.: 60.16%] [G loss: 0.935559]\n",
      "epoch:12 step:11504 [D loss: 0.478538, acc.: 73.44%] [G loss: 0.787477]\n",
      "epoch:12 step:11505 [D loss: 0.299488, acc.: 96.88%] [G loss: 0.645102]\n",
      "epoch:12 step:11506 [D loss: 0.716753, acc.: 48.44%] [G loss: 0.924443]\n",
      "epoch:12 step:11507 [D loss: 0.489398, acc.: 82.81%] [G loss: 0.973478]\n",
      "epoch:12 step:11508 [D loss: 0.742911, acc.: 53.12%] [G loss: 0.819610]\n",
      "epoch:12 step:11509 [D loss: 0.465435, acc.: 85.16%] [G loss: 0.856001]\n",
      "epoch:12 step:11510 [D loss: 0.743510, acc.: 50.00%] [G loss: 0.386899]\n",
      "epoch:12 step:11511 [D loss: 0.921495, acc.: 21.09%] [G loss: 0.894736]\n",
      "epoch:12 step:11512 [D loss: 1.069072, acc.: 10.16%] [G loss: 1.032261]\n",
      "epoch:12 step:11513 [D loss: 0.690153, acc.: 49.22%] [G loss: 0.494717]\n",
      "epoch:12 step:11514 [D loss: 0.823821, acc.: 32.03%] [G loss: 1.037494]\n",
      "epoch:12 step:11515 [D loss: 0.766310, acc.: 34.38%] [G loss: 1.073092]\n",
      "epoch:12 step:11516 [D loss: 0.623513, acc.: 59.38%] [G loss: 1.094596]\n",
      "epoch:12 step:11517 [D loss: 0.574227, acc.: 64.06%] [G loss: 1.117903]\n",
      "epoch:12 step:11518 [D loss: 0.607424, acc.: 64.06%] [G loss: 1.057159]\n",
      "epoch:12 step:11519 [D loss: 0.624164, acc.: 59.38%] [G loss: 1.062664]\n",
      "epoch:12 step:11520 [D loss: 0.600255, acc.: 64.84%] [G loss: 1.064320]\n",
      "epoch:12 step:11521 [D loss: 0.605254, acc.: 62.50%] [G loss: 1.197987]\n",
      "epoch:12 step:11522 [D loss: 0.743580, acc.: 52.34%] [G loss: 1.041390]\n",
      "epoch:12 step:11523 [D loss: 0.806065, acc.: 50.00%] [G loss: 0.918875]\n",
      "epoch:12 step:11524 [D loss: 0.726960, acc.: 45.31%] [G loss: 0.854069]\n",
      "epoch:12 step:11525 [D loss: 0.631365, acc.: 65.62%] [G loss: 0.853111]\n",
      "epoch:12 step:11526 [D loss: 0.554631, acc.: 79.69%] [G loss: 0.884982]\n",
      "epoch:12 step:11527 [D loss: 0.733499, acc.: 43.75%] [G loss: 0.748298]\n",
      "epoch:12 step:11528 [D loss: 0.697632, acc.: 47.66%] [G loss: 0.895786]\n",
      "epoch:12 step:11529 [D loss: 0.710959, acc.: 46.88%] [G loss: 0.945762]\n",
      "epoch:12 step:11530 [D loss: 0.706034, acc.: 53.12%] [G loss: 0.916943]\n",
      "epoch:12 step:11531 [D loss: 0.712883, acc.: 56.25%] [G loss: 0.874677]\n",
      "epoch:12 step:11532 [D loss: 0.670977, acc.: 62.50%] [G loss: 0.844998]\n",
      "epoch:12 step:11533 [D loss: 0.669919, acc.: 62.50%] [G loss: 0.883300]\n",
      "epoch:12 step:11534 [D loss: 0.759304, acc.: 37.50%] [G loss: 0.704966]\n",
      "epoch:12 step:11535 [D loss: 0.717301, acc.: 46.09%] [G loss: 0.841998]\n",
      "epoch:12 step:11536 [D loss: 0.625758, acc.: 72.66%] [G loss: 0.834191]\n",
      "epoch:12 step:11537 [D loss: 0.658013, acc.: 57.03%] [G loss: 0.819255]\n",
      "epoch:12 step:11538 [D loss: 0.692538, acc.: 51.56%] [G loss: 0.715758]\n",
      "epoch:12 step:11539 [D loss: 0.634764, acc.: 69.53%] [G loss: 0.756105]\n",
      "epoch:12 step:11540 [D loss: 0.654521, acc.: 61.72%] [G loss: 0.775976]\n",
      "epoch:12 step:11541 [D loss: 0.563965, acc.: 78.91%] [G loss: 0.765546]\n",
      "epoch:12 step:11542 [D loss: 0.590795, acc.: 71.88%] [G loss: 0.713856]\n",
      "epoch:12 step:11543 [D loss: 0.599550, acc.: 70.31%] [G loss: 0.839633]\n",
      "epoch:12 step:11544 [D loss: 0.563057, acc.: 82.03%] [G loss: 0.791410]\n",
      "epoch:12 step:11545 [D loss: 0.687612, acc.: 54.69%] [G loss: 0.870372]\n",
      "epoch:12 step:11546 [D loss: 0.654646, acc.: 63.28%] [G loss: 0.867676]\n",
      "epoch:12 step:11547 [D loss: 0.600070, acc.: 71.09%] [G loss: 0.894431]\n",
      "epoch:12 step:11548 [D loss: 0.693907, acc.: 56.25%] [G loss: 0.916549]\n",
      "epoch:12 step:11549 [D loss: 0.759753, acc.: 46.09%] [G loss: 0.873081]\n",
      "epoch:12 step:11550 [D loss: 0.685618, acc.: 54.69%] [G loss: 0.924019]\n",
      "epoch:12 step:11551 [D loss: 0.647343, acc.: 61.72%] [G loss: 0.806628]\n",
      "epoch:12 step:11552 [D loss: 0.736857, acc.: 44.53%] [G loss: 0.875662]\n",
      "epoch:12 step:11553 [D loss: 0.733992, acc.: 50.00%] [G loss: 0.810382]\n",
      "epoch:12 step:11554 [D loss: 0.674021, acc.: 60.16%] [G loss: 0.777199]\n",
      "epoch:12 step:11555 [D loss: 0.720769, acc.: 43.75%] [G loss: 0.705048]\n",
      "epoch:12 step:11556 [D loss: 0.626516, acc.: 63.28%] [G loss: 0.820871]\n",
      "epoch:12 step:11557 [D loss: 0.640767, acc.: 62.50%] [G loss: 0.766949]\n",
      "epoch:12 step:11558 [D loss: 0.515382, acc.: 79.69%] [G loss: 0.838241]\n",
      "epoch:12 step:11559 [D loss: 0.841591, acc.: 50.78%] [G loss: 0.716045]\n",
      "epoch:12 step:11560 [D loss: 0.617258, acc.: 73.44%] [G loss: 0.871752]\n",
      "epoch:12 step:11561 [D loss: 0.633947, acc.: 66.41%] [G loss: 0.835858]\n",
      "epoch:12 step:11562 [D loss: 0.583827, acc.: 74.22%] [G loss: 0.864226]\n",
      "epoch:12 step:11563 [D loss: 0.644997, acc.: 64.84%] [G loss: 0.770337]\n",
      "epoch:12 step:11564 [D loss: 0.622971, acc.: 69.53%] [G loss: 0.852149]\n",
      "epoch:12 step:11565 [D loss: 0.712029, acc.: 52.34%] [G loss: 0.897244]\n",
      "epoch:12 step:11566 [D loss: 0.623931, acc.: 66.41%] [G loss: 0.636642]\n",
      "epoch:12 step:11567 [D loss: 0.713902, acc.: 51.56%] [G loss: 0.711611]\n",
      "epoch:12 step:11568 [D loss: 0.716341, acc.: 48.44%] [G loss: 0.543142]\n",
      "epoch:12 step:11569 [D loss: 0.628004, acc.: 67.19%] [G loss: 1.007251]\n",
      "epoch:12 step:11570 [D loss: 0.660676, acc.: 64.84%] [G loss: 0.777412]\n",
      "epoch:12 step:11571 [D loss: 0.465986, acc.: 89.84%] [G loss: 0.534967]\n",
      "epoch:12 step:11572 [D loss: 0.523659, acc.: 82.81%] [G loss: 0.854367]\n",
      "epoch:12 step:11573 [D loss: 0.715618, acc.: 48.44%] [G loss: 0.713322]\n",
      "epoch:12 step:11574 [D loss: 0.762506, acc.: 35.94%] [G loss: 0.911581]\n",
      "epoch:12 step:11575 [D loss: 0.716821, acc.: 50.00%] [G loss: 0.763912]\n",
      "epoch:12 step:11576 [D loss: 0.730833, acc.: 50.78%] [G loss: 0.341158]\n",
      "epoch:12 step:11577 [D loss: 0.788874, acc.: 32.81%] [G loss: 0.787688]\n",
      "epoch:12 step:11578 [D loss: 0.690719, acc.: 53.12%] [G loss: 0.734612]\n",
      "epoch:12 step:11579 [D loss: 0.786572, acc.: 34.38%] [G loss: 0.738690]\n",
      "epoch:12 step:11580 [D loss: 0.717183, acc.: 48.44%] [G loss: 0.771982]\n",
      "epoch:12 step:11581 [D loss: 0.733350, acc.: 43.75%] [G loss: 0.816143]\n",
      "epoch:12 step:11582 [D loss: 0.701987, acc.: 52.34%] [G loss: 0.760304]\n",
      "epoch:12 step:11583 [D loss: 0.692585, acc.: 52.34%] [G loss: 0.772122]\n",
      "epoch:12 step:11584 [D loss: 0.735242, acc.: 42.19%] [G loss: 0.837187]\n",
      "epoch:12 step:11585 [D loss: 0.715533, acc.: 36.72%] [G loss: 0.743055]\n",
      "epoch:12 step:11586 [D loss: 0.664030, acc.: 64.06%] [G loss: 0.823124]\n",
      "epoch:12 step:11587 [D loss: 0.479113, acc.: 85.94%] [G loss: 0.871852]\n",
      "epoch:12 step:11588 [D loss: 0.498062, acc.: 83.59%] [G loss: 0.858086]\n",
      "epoch:12 step:11589 [D loss: 0.411967, acc.: 82.81%] [G loss: 0.914017]\n",
      "epoch:12 step:11590 [D loss: 0.424239, acc.: 84.38%] [G loss: 0.868807]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11591 [D loss: 0.313894, acc.: 96.09%] [G loss: 1.010335]\n",
      "epoch:12 step:11592 [D loss: 0.711431, acc.: 54.69%] [G loss: 1.003613]\n",
      "epoch:12 step:11593 [D loss: 0.709726, acc.: 51.56%] [G loss: 0.994613]\n",
      "epoch:12 step:11594 [D loss: 0.606835, acc.: 66.41%] [G loss: 0.832720]\n",
      "epoch:12 step:11595 [D loss: 0.676935, acc.: 53.12%] [G loss: 0.849665]\n",
      "epoch:12 step:11596 [D loss: 0.670874, acc.: 56.25%] [G loss: 0.886066]\n",
      "epoch:12 step:11597 [D loss: 0.750557, acc.: 37.50%] [G loss: 0.768566]\n",
      "epoch:12 step:11598 [D loss: 0.686552, acc.: 51.56%] [G loss: 0.874257]\n",
      "epoch:12 step:11599 [D loss: 0.699153, acc.: 49.22%] [G loss: 0.860853]\n",
      "epoch:12 step:11600 [D loss: 0.683107, acc.: 57.81%] [G loss: 0.851515]\n",
      "##############\n",
      "[4.10583454 2.14946592 6.76399801 5.5388774  4.42485236 6.13998209\n",
      " 5.22701533 5.97340558 6.00840603 4.61910646]\n",
      "##########\n",
      "epoch:12 step:11601 [D loss: 0.706928, acc.: 44.53%] [G loss: 0.866217]\n",
      "epoch:12 step:11602 [D loss: 0.708182, acc.: 51.56%] [G loss: 0.824610]\n",
      "epoch:12 step:11603 [D loss: 0.822184, acc.: 33.59%] [G loss: 0.745637]\n",
      "epoch:12 step:11604 [D loss: 0.649702, acc.: 66.41%] [G loss: 0.878144]\n",
      "epoch:12 step:11605 [D loss: 0.661369, acc.: 63.28%] [G loss: 0.812138]\n",
      "epoch:12 step:11606 [D loss: 0.531576, acc.: 77.34%] [G loss: 0.885424]\n",
      "epoch:12 step:11607 [D loss: 0.457095, acc.: 86.72%] [G loss: 0.939044]\n",
      "epoch:12 step:11608 [D loss: 0.565342, acc.: 75.00%] [G loss: 0.779083]\n",
      "epoch:12 step:11609 [D loss: 0.637976, acc.: 63.28%] [G loss: 0.949993]\n",
      "epoch:12 step:11610 [D loss: 0.338551, acc.: 85.94%] [G loss: 0.925693]\n",
      "epoch:12 step:11611 [D loss: 0.594227, acc.: 67.19%] [G loss: 0.911858]\n",
      "epoch:12 step:11612 [D loss: 0.638257, acc.: 64.84%] [G loss: 0.814230]\n",
      "epoch:12 step:11613 [D loss: 0.719402, acc.: 50.00%] [G loss: 0.924371]\n",
      "epoch:12 step:11614 [D loss: 0.690903, acc.: 53.12%] [G loss: 0.683169]\n",
      "epoch:12 step:11615 [D loss: 0.623493, acc.: 67.19%] [G loss: 0.833594]\n",
      "epoch:12 step:11616 [D loss: 0.748273, acc.: 43.75%] [G loss: 0.701261]\n",
      "epoch:12 step:11617 [D loss: 0.701947, acc.: 53.91%] [G loss: 0.850229]\n",
      "epoch:12 step:11618 [D loss: 0.714309, acc.: 47.66%] [G loss: 0.807106]\n",
      "epoch:12 step:11619 [D loss: 0.641153, acc.: 59.38%] [G loss: 0.915254]\n",
      "epoch:12 step:11620 [D loss: 0.707919, acc.: 55.47%] [G loss: 0.855126]\n",
      "epoch:12 step:11621 [D loss: 0.395955, acc.: 84.38%] [G loss: 0.911188]\n",
      "epoch:12 step:11622 [D loss: 0.446022, acc.: 89.84%] [G loss: 0.946331]\n",
      "epoch:12 step:11623 [D loss: 0.727908, acc.: 40.62%] [G loss: 0.882355]\n",
      "epoch:12 step:11624 [D loss: 0.644965, acc.: 64.84%] [G loss: 0.738549]\n",
      "epoch:12 step:11625 [D loss: 0.583159, acc.: 66.41%] [G loss: 0.946217]\n",
      "epoch:12 step:11626 [D loss: 0.743103, acc.: 46.88%] [G loss: 0.854971]\n",
      "epoch:12 step:11627 [D loss: 0.688695, acc.: 48.44%] [G loss: 0.722744]\n",
      "epoch:12 step:11628 [D loss: 0.766256, acc.: 35.94%] [G loss: 0.989043]\n",
      "epoch:12 step:11629 [D loss: 0.626472, acc.: 64.84%] [G loss: 0.866926]\n",
      "epoch:12 step:11630 [D loss: 0.789857, acc.: 39.06%] [G loss: 0.953620]\n",
      "epoch:12 step:11631 [D loss: 0.665566, acc.: 53.12%] [G loss: 0.882797]\n",
      "epoch:12 step:11632 [D loss: 0.686032, acc.: 53.91%] [G loss: 0.876438]\n",
      "epoch:12 step:11633 [D loss: 0.692963, acc.: 55.47%] [G loss: 0.810586]\n",
      "epoch:12 step:11634 [D loss: 0.732135, acc.: 47.66%] [G loss: 0.846493]\n",
      "epoch:12 step:11635 [D loss: 0.727211, acc.: 42.19%] [G loss: 0.806186]\n",
      "epoch:12 step:11636 [D loss: 0.713027, acc.: 44.53%] [G loss: 0.802364]\n",
      "epoch:12 step:11637 [D loss: 0.687909, acc.: 60.94%] [G loss: 0.836939]\n",
      "epoch:12 step:11638 [D loss: 0.702698, acc.: 48.44%] [G loss: 0.745328]\n",
      "epoch:12 step:11639 [D loss: 0.742369, acc.: 42.97%] [G loss: 0.745874]\n",
      "epoch:12 step:11640 [D loss: 0.457310, acc.: 76.56%] [G loss: 0.778147]\n",
      "epoch:12 step:11641 [D loss: 0.361320, acc.: 87.50%] [G loss: 0.854620]\n",
      "epoch:12 step:11642 [D loss: 0.314365, acc.: 92.97%] [G loss: 0.990307]\n",
      "epoch:12 step:11643 [D loss: 0.319655, acc.: 96.09%] [G loss: 0.964270]\n",
      "epoch:12 step:11644 [D loss: 0.331963, acc.: 93.75%] [G loss: 0.893662]\n",
      "epoch:12 step:11645 [D loss: 0.455383, acc.: 83.59%] [G loss: 0.999900]\n",
      "epoch:12 step:11646 [D loss: 0.278872, acc.: 96.88%] [G loss: 1.095052]\n",
      "epoch:12 step:11647 [D loss: 0.654859, acc.: 60.94%] [G loss: 1.042954]\n",
      "epoch:12 step:11648 [D loss: 0.289693, acc.: 95.31%] [G loss: 1.024788]\n",
      "epoch:12 step:11649 [D loss: 0.253832, acc.: 97.66%] [G loss: 1.132071]\n",
      "epoch:12 step:11650 [D loss: 0.229045, acc.: 99.22%] [G loss: 1.158771]\n",
      "epoch:12 step:11651 [D loss: 0.252623, acc.: 97.66%] [G loss: 1.253582]\n",
      "epoch:12 step:11652 [D loss: 0.567649, acc.: 71.88%] [G loss: 1.220058]\n",
      "epoch:12 step:11653 [D loss: 0.220811, acc.: 98.44%] [G loss: 1.276000]\n",
      "epoch:12 step:11654 [D loss: 0.404463, acc.: 90.62%] [G loss: 0.948294]\n",
      "epoch:12 step:11655 [D loss: 0.828426, acc.: 50.00%] [G loss: 0.983566]\n",
      "epoch:12 step:11656 [D loss: 0.389116, acc.: 97.66%] [G loss: 0.989787]\n",
      "epoch:12 step:11657 [D loss: 0.276621, acc.: 100.00%] [G loss: 0.844872]\n",
      "epoch:12 step:11658 [D loss: 0.507751, acc.: 62.50%] [G loss: 1.362613]\n",
      "epoch:12 step:11659 [D loss: 1.010951, acc.: 50.78%] [G loss: 1.278201]\n",
      "epoch:12 step:11660 [D loss: 0.946749, acc.: 32.81%] [G loss: 1.715489]\n",
      "epoch:12 step:11661 [D loss: 0.440971, acc.: 85.16%] [G loss: 1.659291]\n",
      "epoch:12 step:11662 [D loss: 0.396652, acc.: 89.84%] [G loss: 1.591259]\n",
      "epoch:12 step:11663 [D loss: 0.406283, acc.: 85.16%] [G loss: 0.869683]\n",
      "epoch:12 step:11664 [D loss: 0.889002, acc.: 45.31%] [G loss: 1.477851]\n",
      "epoch:12 step:11665 [D loss: 0.867861, acc.: 50.00%] [G loss: 0.967512]\n",
      "epoch:12 step:11666 [D loss: 1.032828, acc.: 22.66%] [G loss: 1.001797]\n",
      "epoch:12 step:11667 [D loss: 0.861108, acc.: 35.16%] [G loss: 1.063744]\n",
      "epoch:12 step:11668 [D loss: 0.855796, acc.: 51.56%] [G loss: 0.744742]\n",
      "epoch:12 step:11669 [D loss: 0.776368, acc.: 47.66%] [G loss: 1.115726]\n",
      "epoch:12 step:11670 [D loss: 0.754701, acc.: 52.34%] [G loss: 0.967668]\n",
      "epoch:12 step:11671 [D loss: 0.688852, acc.: 60.16%] [G loss: 0.746463]\n",
      "epoch:12 step:11672 [D loss: 0.609500, acc.: 65.62%] [G loss: 1.053592]\n",
      "epoch:12 step:11673 [D loss: 0.734917, acc.: 52.34%] [G loss: 0.789258]\n",
      "epoch:12 step:11674 [D loss: 0.582701, acc.: 72.66%] [G loss: 0.449556]\n",
      "epoch:12 step:11675 [D loss: 1.128496, acc.: 17.19%] [G loss: 0.783300]\n",
      "epoch:12 step:11676 [D loss: 0.690437, acc.: 53.12%] [G loss: 0.998161]\n",
      "epoch:12 step:11677 [D loss: 0.837094, acc.: 32.03%] [G loss: 1.103536]\n",
      "epoch:12 step:11678 [D loss: 0.755394, acc.: 43.75%] [G loss: 1.093969]\n",
      "epoch:12 step:11679 [D loss: 0.663074, acc.: 54.69%] [G loss: 1.125391]\n",
      "epoch:12 step:11680 [D loss: 0.690814, acc.: 53.12%] [G loss: 1.056458]\n",
      "epoch:12 step:11681 [D loss: 0.719879, acc.: 50.00%] [G loss: 1.124802]\n",
      "epoch:12 step:11682 [D loss: 0.778010, acc.: 50.00%] [G loss: 0.985538]\n",
      "epoch:12 step:11683 [D loss: 0.686572, acc.: 53.91%] [G loss: 1.026616]\n",
      "epoch:12 step:11684 [D loss: 0.682665, acc.: 53.91%] [G loss: 0.975972]\n",
      "epoch:12 step:11685 [D loss: 0.664841, acc.: 61.72%] [G loss: 1.013939]\n",
      "epoch:12 step:11686 [D loss: 0.683731, acc.: 56.25%] [G loss: 1.097170]\n",
      "epoch:12 step:11687 [D loss: 0.609699, acc.: 60.94%] [G loss: 0.995775]\n",
      "epoch:12 step:11688 [D loss: 0.651021, acc.: 60.16%] [G loss: 0.948954]\n",
      "epoch:12 step:11689 [D loss: 0.655470, acc.: 64.84%] [G loss: 0.993039]\n",
      "epoch:12 step:11690 [D loss: 0.679755, acc.: 53.12%] [G loss: 1.060929]\n",
      "epoch:12 step:11691 [D loss: 0.652907, acc.: 60.16%] [G loss: 0.869845]\n",
      "epoch:12 step:11692 [D loss: 0.559542, acc.: 79.69%] [G loss: 0.990450]\n",
      "epoch:12 step:11693 [D loss: 0.530687, acc.: 82.81%] [G loss: 0.857131]\n",
      "epoch:12 step:11694 [D loss: 0.532149, acc.: 82.03%] [G loss: 1.105942]\n",
      "epoch:12 step:11695 [D loss: 0.431546, acc.: 96.09%] [G loss: 1.077949]\n",
      "epoch:12 step:11696 [D loss: 0.403427, acc.: 93.75%] [G loss: 1.427899]\n",
      "epoch:12 step:11697 [D loss: 0.476459, acc.: 86.72%] [G loss: 1.032420]\n",
      "epoch:12 step:11698 [D loss: 0.487174, acc.: 81.25%] [G loss: 1.373020]\n",
      "epoch:12 step:11699 [D loss: 0.466497, acc.: 84.38%] [G loss: 1.501281]\n",
      "epoch:12 step:11700 [D loss: 0.261787, acc.: 93.75%] [G loss: 1.034807]\n",
      "epoch:12 step:11701 [D loss: 0.416547, acc.: 89.84%] [G loss: 1.491788]\n",
      "epoch:12 step:11702 [D loss: 0.648455, acc.: 60.16%] [G loss: 0.985827]\n",
      "epoch:12 step:11703 [D loss: 0.637748, acc.: 59.38%] [G loss: 1.559989]\n",
      "epoch:12 step:11704 [D loss: 0.735409, acc.: 50.78%] [G loss: 1.267263]\n",
      "epoch:12 step:11705 [D loss: 0.966221, acc.: 46.88%] [G loss: 0.938115]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11706 [D loss: 1.143401, acc.: 21.88%] [G loss: 0.888985]\n",
      "epoch:12 step:11707 [D loss: 0.704006, acc.: 52.34%] [G loss: 0.552519]\n",
      "epoch:12 step:11708 [D loss: 0.682370, acc.: 59.38%] [G loss: 0.769045]\n",
      "epoch:12 step:11709 [D loss: 0.634788, acc.: 58.59%] [G loss: 0.643286]\n",
      "epoch:12 step:11710 [D loss: 0.675876, acc.: 52.34%] [G loss: 0.641830]\n",
      "epoch:12 step:11711 [D loss: 0.551060, acc.: 70.31%] [G loss: 0.750304]\n",
      "epoch:12 step:11712 [D loss: 0.406678, acc.: 87.50%] [G loss: 0.868985]\n",
      "epoch:12 step:11713 [D loss: 0.517078, acc.: 79.69%] [G loss: 0.829090]\n",
      "epoch:12 step:11714 [D loss: 0.370082, acc.: 91.41%] [G loss: 0.942261]\n",
      "epoch:12 step:11715 [D loss: 0.413298, acc.: 87.50%] [G loss: 0.380573]\n",
      "epoch:12 step:11716 [D loss: 0.494984, acc.: 80.47%] [G loss: 0.927830]\n",
      "epoch:12 step:11717 [D loss: 1.062840, acc.: 33.59%] [G loss: 0.747291]\n",
      "epoch:12 step:11718 [D loss: 0.901139, acc.: 29.69%] [G loss: 0.856647]\n",
      "epoch:12 step:11719 [D loss: 0.827941, acc.: 35.94%] [G loss: 0.765600]\n",
      "epoch:12 step:11720 [D loss: 0.802174, acc.: 48.44%] [G loss: 0.945219]\n",
      "epoch:12 step:11721 [D loss: 0.748598, acc.: 58.59%] [G loss: 0.761576]\n",
      "epoch:12 step:11722 [D loss: 0.782874, acc.: 38.28%] [G loss: 0.725749]\n",
      "epoch:12 step:11723 [D loss: 0.744746, acc.: 46.09%] [G loss: 0.807915]\n",
      "epoch:12 step:11724 [D loss: 0.643768, acc.: 62.50%] [G loss: 0.848697]\n",
      "epoch:12 step:11725 [D loss: 0.658701, acc.: 57.81%] [G loss: 0.881113]\n",
      "epoch:12 step:11726 [D loss: 0.773063, acc.: 49.22%] [G loss: 0.933707]\n",
      "epoch:12 step:11727 [D loss: 0.673199, acc.: 55.47%] [G loss: 0.984403]\n",
      "epoch:12 step:11728 [D loss: 0.662257, acc.: 51.56%] [G loss: 0.817025]\n",
      "epoch:12 step:11729 [D loss: 0.685342, acc.: 58.59%] [G loss: 1.001079]\n",
      "epoch:12 step:11730 [D loss: 0.685236, acc.: 53.12%] [G loss: 0.970165]\n",
      "epoch:12 step:11731 [D loss: 0.690684, acc.: 53.91%] [G loss: 1.043787]\n",
      "epoch:12 step:11732 [D loss: 0.708898, acc.: 52.34%] [G loss: 0.857478]\n",
      "epoch:12 step:11733 [D loss: 0.690128, acc.: 53.91%] [G loss: 0.916708]\n",
      "epoch:12 step:11734 [D loss: 0.720022, acc.: 49.22%] [G loss: 0.852748]\n",
      "epoch:12 step:11735 [D loss: 0.700933, acc.: 54.69%] [G loss: 0.833878]\n",
      "epoch:12 step:11736 [D loss: 0.677244, acc.: 62.50%] [G loss: 0.841570]\n",
      "epoch:12 step:11737 [D loss: 0.665648, acc.: 59.38%] [G loss: 0.728155]\n",
      "epoch:12 step:11738 [D loss: 0.673258, acc.: 55.47%] [G loss: 0.774175]\n",
      "epoch:12 step:11739 [D loss: 0.654438, acc.: 63.28%] [G loss: 0.802922]\n",
      "epoch:12 step:11740 [D loss: 0.679669, acc.: 53.12%] [G loss: 0.835444]\n",
      "epoch:12 step:11741 [D loss: 0.589261, acc.: 67.97%] [G loss: 0.804791]\n",
      "epoch:12 step:11742 [D loss: 0.619758, acc.: 66.41%] [G loss: 0.835001]\n",
      "epoch:12 step:11743 [D loss: 0.574577, acc.: 73.44%] [G loss: 0.856846]\n",
      "epoch:12 step:11744 [D loss: 0.694484, acc.: 50.00%] [G loss: 0.924707]\n",
      "epoch:12 step:11745 [D loss: 0.712777, acc.: 53.91%] [G loss: 0.809000]\n",
      "epoch:12 step:11746 [D loss: 0.670473, acc.: 58.59%] [G loss: 0.855889]\n",
      "epoch:12 step:11747 [D loss: 0.785150, acc.: 50.78%] [G loss: 0.751882]\n",
      "epoch:12 step:11748 [D loss: 0.630123, acc.: 64.84%] [G loss: 0.706626]\n",
      "epoch:12 step:11749 [D loss: 0.629688, acc.: 63.28%] [G loss: 0.762569]\n",
      "epoch:12 step:11750 [D loss: 0.697523, acc.: 53.91%] [G loss: 0.795684]\n",
      "epoch:12 step:11751 [D loss: 0.662880, acc.: 60.16%] [G loss: 0.755652]\n",
      "epoch:12 step:11752 [D loss: 0.645574, acc.: 56.25%] [G loss: 0.825157]\n",
      "epoch:12 step:11753 [D loss: 0.690570, acc.: 63.28%] [G loss: 0.757586]\n",
      "epoch:12 step:11754 [D loss: 0.685257, acc.: 54.69%] [G loss: 0.811459]\n",
      "epoch:12 step:11755 [D loss: 0.633496, acc.: 60.94%] [G loss: 0.815543]\n",
      "epoch:12 step:11756 [D loss: 0.588351, acc.: 75.00%] [G loss: 0.886298]\n",
      "epoch:12 step:11757 [D loss: 0.678704, acc.: 54.69%] [G loss: 0.840577]\n",
      "epoch:12 step:11758 [D loss: 0.571117, acc.: 72.66%] [G loss: 0.958362]\n",
      "epoch:12 step:11759 [D loss: 0.581138, acc.: 71.09%] [G loss: 0.911487]\n",
      "epoch:12 step:11760 [D loss: 0.632702, acc.: 67.19%] [G loss: 0.828855]\n",
      "epoch:12 step:11761 [D loss: 0.633404, acc.: 66.41%] [G loss: 1.154872]\n",
      "epoch:12 step:11762 [D loss: 0.683264, acc.: 55.47%] [G loss: 0.744132]\n",
      "epoch:12 step:11763 [D loss: 0.622385, acc.: 59.38%] [G loss: 0.815290]\n",
      "epoch:12 step:11764 [D loss: 0.666915, acc.: 56.25%] [G loss: 0.826844]\n",
      "epoch:12 step:11765 [D loss: 0.713788, acc.: 49.22%] [G loss: 0.736124]\n",
      "epoch:12 step:11766 [D loss: 0.658232, acc.: 57.81%] [G loss: 0.831590]\n",
      "epoch:12 step:11767 [D loss: 0.643080, acc.: 64.06%] [G loss: 0.837645]\n",
      "epoch:12 step:11768 [D loss: 0.629730, acc.: 71.88%] [G loss: 0.942353]\n",
      "epoch:12 step:11769 [D loss: 0.688704, acc.: 53.91%] [G loss: 0.848023]\n",
      "epoch:12 step:11770 [D loss: 0.647203, acc.: 63.28%] [G loss: 0.850435]\n",
      "epoch:12 step:11771 [D loss: 0.587562, acc.: 73.44%] [G loss: 0.793434]\n",
      "epoch:12 step:11772 [D loss: 0.738892, acc.: 47.66%] [G loss: 0.847686]\n",
      "epoch:12 step:11773 [D loss: 0.662297, acc.: 62.50%] [G loss: 0.923146]\n",
      "epoch:12 step:11774 [D loss: 0.564322, acc.: 75.78%] [G loss: 0.870053]\n",
      "epoch:12 step:11775 [D loss: 0.701053, acc.: 54.69%] [G loss: 0.936509]\n",
      "epoch:12 step:11776 [D loss: 0.814968, acc.: 38.28%] [G loss: 0.859844]\n",
      "epoch:12 step:11777 [D loss: 0.666852, acc.: 57.81%] [G loss: 0.849509]\n",
      "epoch:12 step:11778 [D loss: 0.705079, acc.: 48.44%] [G loss: 0.799861]\n",
      "epoch:12 step:11779 [D loss: 0.618476, acc.: 65.62%] [G loss: 0.844655]\n",
      "epoch:12 step:11780 [D loss: 0.598591, acc.: 76.56%] [G loss: 0.829782]\n",
      "epoch:12 step:11781 [D loss: 0.691123, acc.: 50.78%] [G loss: 0.801952]\n",
      "epoch:12 step:11782 [D loss: 0.663754, acc.: 60.94%] [G loss: 0.805553]\n",
      "epoch:12 step:11783 [D loss: 0.680309, acc.: 57.03%] [G loss: 0.887248]\n",
      "epoch:12 step:11784 [D loss: 0.619942, acc.: 69.53%] [G loss: 0.849726]\n",
      "epoch:12 step:11785 [D loss: 0.603323, acc.: 74.22%] [G loss: 0.856108]\n",
      "epoch:12 step:11786 [D loss: 0.665183, acc.: 62.50%] [G loss: 0.816373]\n",
      "epoch:12 step:11787 [D loss: 0.432936, acc.: 79.69%] [G loss: 0.822121]\n",
      "epoch:12 step:11788 [D loss: 0.674085, acc.: 53.91%] [G loss: 0.771867]\n",
      "epoch:12 step:11789 [D loss: 0.615787, acc.: 64.06%] [G loss: 0.791752]\n",
      "epoch:12 step:11790 [D loss: 0.715642, acc.: 50.78%] [G loss: 0.844280]\n",
      "epoch:12 step:11791 [D loss: 0.658463, acc.: 59.38%] [G loss: 0.824190]\n",
      "epoch:12 step:11792 [D loss: 0.606030, acc.: 64.84%] [G loss: 0.841649]\n",
      "epoch:12 step:11793 [D loss: 0.558899, acc.: 73.44%] [G loss: 0.858097]\n",
      "epoch:12 step:11794 [D loss: 0.436053, acc.: 82.03%] [G loss: 0.949304]\n",
      "epoch:12 step:11795 [D loss: 0.664477, acc.: 57.81%] [G loss: 0.918120]\n",
      "epoch:12 step:11796 [D loss: 0.539885, acc.: 75.78%] [G loss: 0.909860]\n",
      "epoch:12 step:11797 [D loss: 0.613720, acc.: 64.84%] [G loss: 0.911054]\n",
      "epoch:12 step:11798 [D loss: 0.445353, acc.: 83.59%] [G loss: 0.835262]\n",
      "epoch:12 step:11799 [D loss: 0.505893, acc.: 82.03%] [G loss: 0.821128]\n",
      "epoch:12 step:11800 [D loss: 0.745039, acc.: 56.25%] [G loss: 0.767379]\n",
      "##############\n",
      "[4.28078546 2.34208699 6.41113214 5.29906093 4.45323363 5.89740422\n",
      " 5.45963472 5.51248618 5.81601659 4.85746068]\n",
      "##########\n",
      "epoch:12 step:11801 [D loss: 0.458312, acc.: 89.84%] [G loss: 1.090746]\n",
      "epoch:12 step:11802 [D loss: 0.616552, acc.: 69.53%] [G loss: 1.116691]\n",
      "epoch:12 step:11803 [D loss: 0.729161, acc.: 52.34%] [G loss: 1.072330]\n",
      "epoch:12 step:11804 [D loss: 0.776911, acc.: 47.66%] [G loss: 0.959521]\n",
      "epoch:12 step:11805 [D loss: 0.676815, acc.: 57.81%] [G loss: 0.740505]\n",
      "epoch:12 step:11806 [D loss: 0.738806, acc.: 55.47%] [G loss: 0.962051]\n",
      "epoch:12 step:11807 [D loss: 0.781398, acc.: 42.97%] [G loss: 0.607095]\n",
      "epoch:12 step:11808 [D loss: 0.661259, acc.: 60.94%] [G loss: 0.798683]\n",
      "epoch:12 step:11809 [D loss: 0.704267, acc.: 51.56%] [G loss: 0.808574]\n",
      "epoch:12 step:11810 [D loss: 0.678822, acc.: 57.81%] [G loss: 0.978231]\n",
      "epoch:12 step:11811 [D loss: 0.513969, acc.: 77.34%] [G loss: 0.977296]\n",
      "epoch:12 step:11812 [D loss: 0.662557, acc.: 60.16%] [G loss: 1.010597]\n",
      "epoch:12 step:11813 [D loss: 0.681466, acc.: 57.03%] [G loss: 1.073641]\n",
      "epoch:12 step:11814 [D loss: 0.654448, acc.: 58.59%] [G loss: 1.014305]\n",
      "epoch:12 step:11815 [D loss: 0.684507, acc.: 53.91%] [G loss: 0.920878]\n",
      "epoch:12 step:11816 [D loss: 0.652541, acc.: 61.72%] [G loss: 0.975603]\n",
      "epoch:12 step:11817 [D loss: 0.569426, acc.: 76.56%] [G loss: 0.954862]\n",
      "epoch:12 step:11818 [D loss: 0.638147, acc.: 63.28%] [G loss: 1.018741]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11819 [D loss: 0.553628, acc.: 67.97%] [G loss: 1.253592]\n",
      "epoch:12 step:11820 [D loss: 0.599771, acc.: 65.62%] [G loss: 1.252936]\n",
      "epoch:12 step:11821 [D loss: 0.541656, acc.: 74.22%] [G loss: 1.045752]\n",
      "epoch:12 step:11822 [D loss: 0.606100, acc.: 67.97%] [G loss: 0.986848]\n",
      "epoch:12 step:11823 [D loss: 0.512536, acc.: 77.34%] [G loss: 0.956537]\n",
      "epoch:12 step:11824 [D loss: 0.694509, acc.: 57.03%] [G loss: 0.964189]\n",
      "epoch:12 step:11825 [D loss: 0.735653, acc.: 52.34%] [G loss: 0.617927]\n",
      "epoch:12 step:11826 [D loss: 0.717975, acc.: 51.56%] [G loss: 0.766619]\n",
      "epoch:12 step:11827 [D loss: 0.778502, acc.: 43.75%] [G loss: 0.802800]\n",
      "epoch:12 step:11828 [D loss: 0.784353, acc.: 43.75%] [G loss: 0.811475]\n",
      "epoch:12 step:11829 [D loss: 0.777710, acc.: 43.75%] [G loss: 0.808954]\n",
      "epoch:12 step:11830 [D loss: 0.709568, acc.: 53.91%] [G loss: 0.813954]\n",
      "epoch:12 step:11831 [D loss: 0.458377, acc.: 83.59%] [G loss: 0.912760]\n",
      "epoch:12 step:11832 [D loss: 0.503972, acc.: 78.12%] [G loss: 0.877678]\n",
      "epoch:12 step:11833 [D loss: 0.360628, acc.: 89.84%] [G loss: 0.945995]\n",
      "epoch:12 step:11834 [D loss: 0.755539, acc.: 44.53%] [G loss: 0.910722]\n",
      "epoch:12 step:11835 [D loss: 0.705388, acc.: 58.59%] [G loss: 0.884771]\n",
      "epoch:12 step:11836 [D loss: 0.646190, acc.: 64.84%] [G loss: 0.975250]\n",
      "epoch:12 step:11837 [D loss: 0.693875, acc.: 50.78%] [G loss: 0.981153]\n",
      "epoch:12 step:11838 [D loss: 0.625326, acc.: 59.38%] [G loss: 1.039730]\n",
      "epoch:12 step:11839 [D loss: 0.453659, acc.: 85.94%] [G loss: 1.039131]\n",
      "epoch:12 step:11840 [D loss: 0.665406, acc.: 58.59%] [G loss: 0.951510]\n",
      "epoch:12 step:11841 [D loss: 0.706955, acc.: 55.47%] [G loss: 0.742310]\n",
      "epoch:12 step:11842 [D loss: 0.692766, acc.: 56.25%] [G loss: 0.639754]\n",
      "epoch:12 step:11843 [D loss: 0.745422, acc.: 46.88%] [G loss: 0.802848]\n",
      "epoch:12 step:11844 [D loss: 0.429932, acc.: 79.69%] [G loss: 0.749436]\n",
      "epoch:12 step:11845 [D loss: 0.413229, acc.: 79.69%] [G loss: 0.894016]\n",
      "epoch:12 step:11846 [D loss: 0.459549, acc.: 86.72%] [G loss: 0.907475]\n",
      "epoch:12 step:11847 [D loss: 1.040029, acc.: 9.38%] [G loss: 0.943869]\n",
      "epoch:12 step:11848 [D loss: 0.454852, acc.: 82.03%] [G loss: 1.019027]\n",
      "epoch:12 step:11849 [D loss: 0.727771, acc.: 50.00%] [G loss: 0.743216]\n",
      "epoch:12 step:11850 [D loss: 0.703863, acc.: 54.69%] [G loss: 0.981895]\n",
      "epoch:12 step:11851 [D loss: 0.830039, acc.: 32.81%] [G loss: 0.928464]\n",
      "epoch:12 step:11852 [D loss: 0.590180, acc.: 81.25%] [G loss: 0.915368]\n",
      "epoch:12 step:11853 [D loss: 0.602571, acc.: 72.66%] [G loss: 0.807873]\n",
      "epoch:12 step:11854 [D loss: 0.680392, acc.: 57.03%] [G loss: 0.955354]\n",
      "epoch:12 step:11855 [D loss: 0.683476, acc.: 53.91%] [G loss: 0.772271]\n",
      "epoch:12 step:11856 [D loss: 0.529707, acc.: 82.03%] [G loss: 1.013499]\n",
      "epoch:12 step:11857 [D loss: 0.635747, acc.: 66.41%] [G loss: 0.967218]\n",
      "epoch:12 step:11858 [D loss: 0.848742, acc.: 24.22%] [G loss: 0.791405]\n",
      "epoch:12 step:11859 [D loss: 0.827299, acc.: 33.59%] [G loss: 0.940989]\n",
      "epoch:12 step:11860 [D loss: 0.694085, acc.: 48.44%] [G loss: 0.988538]\n",
      "epoch:12 step:11861 [D loss: 0.648745, acc.: 60.16%] [G loss: 1.003157]\n",
      "epoch:12 step:11862 [D loss: 0.656953, acc.: 61.72%] [G loss: 0.901330]\n",
      "epoch:12 step:11863 [D loss: 0.627820, acc.: 64.84%] [G loss: 0.929828]\n",
      "epoch:12 step:11864 [D loss: 0.620923, acc.: 64.84%] [G loss: 0.834278]\n",
      "epoch:12 step:11865 [D loss: 0.704334, acc.: 55.47%] [G loss: 0.802324]\n",
      "epoch:12 step:11866 [D loss: 0.742334, acc.: 46.88%] [G loss: 0.583960]\n",
      "epoch:12 step:11867 [D loss: 0.657041, acc.: 67.19%] [G loss: 0.798440]\n",
      "epoch:12 step:11868 [D loss: 0.630648, acc.: 67.97%] [G loss: 0.761156]\n",
      "epoch:12 step:11869 [D loss: 0.652478, acc.: 65.62%] [G loss: 0.743514]\n",
      "epoch:12 step:11870 [D loss: 0.716045, acc.: 48.44%] [G loss: 0.603910]\n",
      "epoch:12 step:11871 [D loss: 0.655350, acc.: 66.41%] [G loss: 0.713704]\n",
      "epoch:12 step:11872 [D loss: 0.682978, acc.: 55.47%] [G loss: 0.888956]\n",
      "epoch:12 step:11873 [D loss: 0.702265, acc.: 53.12%] [G loss: 0.866753]\n",
      "epoch:12 step:11874 [D loss: 0.619454, acc.: 72.66%] [G loss: 0.836939]\n",
      "epoch:12 step:11875 [D loss: 0.637384, acc.: 63.28%] [G loss: 0.917727]\n",
      "epoch:12 step:11876 [D loss: 0.565923, acc.: 74.22%] [G loss: 0.630224]\n",
      "epoch:12 step:11877 [D loss: 0.500637, acc.: 82.81%] [G loss: 0.975114]\n",
      "epoch:12 step:11878 [D loss: 0.448842, acc.: 92.19%] [G loss: 1.076305]\n",
      "epoch:12 step:11879 [D loss: 0.493669, acc.: 82.03%] [G loss: 1.033437]\n",
      "epoch:12 step:11880 [D loss: 0.560129, acc.: 72.66%] [G loss: 0.976294]\n",
      "epoch:12 step:11881 [D loss: 0.566217, acc.: 71.88%] [G loss: 0.857412]\n",
      "epoch:12 step:11882 [D loss: 0.559925, acc.: 71.09%] [G loss: 0.964006]\n",
      "epoch:12 step:11883 [D loss: 0.743765, acc.: 42.97%] [G loss: 1.024646]\n",
      "epoch:12 step:11884 [D loss: 0.753452, acc.: 46.88%] [G loss: 0.823940]\n",
      "epoch:12 step:11885 [D loss: 0.693057, acc.: 54.69%] [G loss: 0.805244]\n",
      "epoch:12 step:11886 [D loss: 0.742266, acc.: 42.19%] [G loss: 0.878202]\n",
      "epoch:12 step:11887 [D loss: 0.588661, acc.: 71.88%] [G loss: 0.913050]\n",
      "epoch:12 step:11888 [D loss: 0.378357, acc.: 83.59%] [G loss: 0.907516]\n",
      "epoch:12 step:11889 [D loss: 0.424609, acc.: 92.19%] [G loss: 1.027679]\n",
      "epoch:12 step:11890 [D loss: 0.385320, acc.: 84.38%] [G loss: 1.312373]\n",
      "epoch:12 step:11891 [D loss: 0.474117, acc.: 79.69%] [G loss: 0.966780]\n",
      "epoch:12 step:11892 [D loss: 0.321322, acc.: 97.66%] [G loss: 1.064470]\n",
      "epoch:12 step:11893 [D loss: 0.363798, acc.: 96.88%] [G loss: 1.237533]\n",
      "epoch:12 step:11894 [D loss: 0.349312, acc.: 85.94%] [G loss: 1.000581]\n",
      "epoch:12 step:11895 [D loss: 0.399765, acc.: 90.62%] [G loss: 1.038608]\n",
      "epoch:12 step:11896 [D loss: 0.771341, acc.: 64.06%] [G loss: 1.145527]\n",
      "epoch:12 step:11897 [D loss: 0.798439, acc.: 45.31%] [G loss: 0.889137]\n",
      "epoch:12 step:11898 [D loss: 0.954238, acc.: 32.81%] [G loss: 0.916388]\n",
      "epoch:12 step:11899 [D loss: 0.587133, acc.: 71.09%] [G loss: 1.082750]\n",
      "epoch:12 step:11900 [D loss: 0.627659, acc.: 67.97%] [G loss: 1.115151]\n",
      "epoch:12 step:11901 [D loss: 0.853194, acc.: 38.28%] [G loss: 0.654546]\n",
      "epoch:12 step:11902 [D loss: 1.129531, acc.: 33.59%] [G loss: 0.986323]\n",
      "epoch:12 step:11903 [D loss: 0.499228, acc.: 85.16%] [G loss: 1.079848]\n",
      "epoch:12 step:11904 [D loss: 0.712743, acc.: 48.44%] [G loss: 1.223310]\n",
      "epoch:12 step:11905 [D loss: 0.684040, acc.: 53.91%] [G loss: 1.154757]\n",
      "epoch:12 step:11906 [D loss: 0.737694, acc.: 52.34%] [G loss: 0.992156]\n",
      "epoch:12 step:11907 [D loss: 0.753383, acc.: 42.19%] [G loss: 0.998519]\n",
      "epoch:12 step:11908 [D loss: 0.512520, acc.: 78.91%] [G loss: 1.199486]\n",
      "epoch:12 step:11909 [D loss: 0.571764, acc.: 71.09%] [G loss: 1.172080]\n",
      "epoch:12 step:11910 [D loss: 0.648885, acc.: 53.12%] [G loss: 1.308173]\n",
      "epoch:12 step:11911 [D loss: 0.714428, acc.: 56.25%] [G loss: 1.145535]\n",
      "epoch:12 step:11912 [D loss: 0.709628, acc.: 61.72%] [G loss: 1.145838]\n",
      "epoch:12 step:11913 [D loss: 0.687990, acc.: 57.81%] [G loss: 1.022108]\n",
      "epoch:12 step:11914 [D loss: 0.700431, acc.: 53.12%] [G loss: 1.018592]\n",
      "epoch:12 step:11915 [D loss: 0.691509, acc.: 57.03%] [G loss: 0.866627]\n",
      "epoch:12 step:11916 [D loss: 0.719042, acc.: 53.91%] [G loss: 0.902072]\n",
      "epoch:12 step:11917 [D loss: 0.641983, acc.: 65.62%] [G loss: 0.789317]\n",
      "epoch:12 step:11918 [D loss: 0.606740, acc.: 71.88%] [G loss: 0.951658]\n",
      "epoch:12 step:11919 [D loss: 0.792579, acc.: 45.31%] [G loss: 0.815749]\n",
      "epoch:12 step:11920 [D loss: 0.659849, acc.: 59.38%] [G loss: 0.862547]\n",
      "epoch:12 step:11921 [D loss: 0.644860, acc.: 63.28%] [G loss: 0.868978]\n",
      "epoch:12 step:11922 [D loss: 0.677359, acc.: 62.50%] [G loss: 0.870444]\n",
      "epoch:12 step:11923 [D loss: 0.612036, acc.: 68.75%] [G loss: 0.919589]\n",
      "epoch:12 step:11924 [D loss: 0.680489, acc.: 56.25%] [G loss: 0.812384]\n",
      "epoch:12 step:11925 [D loss: 0.624311, acc.: 66.41%] [G loss: 0.884109]\n",
      "epoch:12 step:11926 [D loss: 0.659765, acc.: 58.59%] [G loss: 0.773971]\n",
      "epoch:12 step:11927 [D loss: 0.655608, acc.: 57.03%] [G loss: 0.816848]\n",
      "epoch:12 step:11928 [D loss: 0.683674, acc.: 54.69%] [G loss: 0.824285]\n",
      "epoch:12 step:11929 [D loss: 0.648981, acc.: 64.84%] [G loss: 0.847557]\n",
      "epoch:12 step:11930 [D loss: 0.593175, acc.: 71.09%] [G loss: 0.885231]\n",
      "epoch:12 step:11931 [D loss: 0.634316, acc.: 63.28%] [G loss: 0.944967]\n",
      "epoch:12 step:11932 [D loss: 0.665887, acc.: 64.06%] [G loss: 0.879614]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11933 [D loss: 0.641353, acc.: 65.62%] [G loss: 0.847524]\n",
      "epoch:12 step:11934 [D loss: 0.642407, acc.: 57.03%] [G loss: 0.833550]\n",
      "epoch:12 step:11935 [D loss: 0.666439, acc.: 55.47%] [G loss: 0.636756]\n",
      "epoch:12 step:11936 [D loss: 0.685840, acc.: 53.12%] [G loss: 0.876489]\n",
      "epoch:12 step:11937 [D loss: 0.625563, acc.: 67.97%] [G loss: 0.857991]\n",
      "epoch:12 step:11938 [D loss: 0.628672, acc.: 65.62%] [G loss: 0.852271]\n",
      "epoch:12 step:11939 [D loss: 0.768717, acc.: 47.66%] [G loss: 0.792333]\n",
      "epoch:12 step:11940 [D loss: 0.453185, acc.: 83.59%] [G loss: 0.858647]\n",
      "epoch:12 step:11941 [D loss: 0.413804, acc.: 74.22%] [G loss: 0.742779]\n",
      "epoch:12 step:11942 [D loss: 0.432760, acc.: 87.50%] [G loss: 0.994592]\n",
      "epoch:12 step:11943 [D loss: 0.720327, acc.: 52.34%] [G loss: 0.954684]\n",
      "epoch:12 step:11944 [D loss: 0.370347, acc.: 89.06%] [G loss: 0.919023]\n",
      "epoch:12 step:11945 [D loss: 0.382361, acc.: 90.62%] [G loss: 1.207064]\n",
      "epoch:12 step:11946 [D loss: 0.392247, acc.: 92.19%] [G loss: 1.165058]\n",
      "epoch:12 step:11947 [D loss: 0.749417, acc.: 47.66%] [G loss: 1.081499]\n",
      "epoch:12 step:11948 [D loss: 0.607385, acc.: 72.66%] [G loss: 1.092952]\n",
      "epoch:12 step:11949 [D loss: 0.698178, acc.: 55.47%] [G loss: 1.017353]\n",
      "epoch:12 step:11950 [D loss: 0.382770, acc.: 84.38%] [G loss: 0.981799]\n",
      "epoch:12 step:11951 [D loss: 0.415798, acc.: 69.53%] [G loss: 1.104581]\n",
      "epoch:12 step:11952 [D loss: 0.238691, acc.: 98.44%] [G loss: 1.233233]\n",
      "epoch:12 step:11953 [D loss: 0.471371, acc.: 89.06%] [G loss: 1.303535]\n",
      "epoch:12 step:11954 [D loss: 0.808808, acc.: 52.34%] [G loss: 1.128096]\n",
      "epoch:12 step:11955 [D loss: 0.678380, acc.: 60.94%] [G loss: 0.879282]\n",
      "epoch:12 step:11956 [D loss: 0.711980, acc.: 50.00%] [G loss: 0.742365]\n",
      "epoch:12 step:11957 [D loss: 0.277717, acc.: 94.53%] [G loss: 1.063725]\n",
      "epoch:12 step:11958 [D loss: 0.248709, acc.: 96.09%] [G loss: 0.653201]\n",
      "epoch:12 step:11959 [D loss: 0.867522, acc.: 32.81%] [G loss: 1.052633]\n",
      "epoch:12 step:11960 [D loss: 0.839026, acc.: 34.38%] [G loss: 0.999860]\n",
      "epoch:12 step:11961 [D loss: 0.822682, acc.: 35.16%] [G loss: 1.111785]\n",
      "epoch:12 step:11962 [D loss: 0.650639, acc.: 61.72%] [G loss: 1.030220]\n",
      "epoch:12 step:11963 [D loss: 0.631448, acc.: 62.50%] [G loss: 1.046885]\n",
      "epoch:12 step:11964 [D loss: 0.649704, acc.: 62.50%] [G loss: 0.982696]\n",
      "epoch:12 step:11965 [D loss: 0.649602, acc.: 64.84%] [G loss: 0.870325]\n",
      "epoch:12 step:11966 [D loss: 0.688160, acc.: 57.81%] [G loss: 0.833865]\n",
      "epoch:12 step:11967 [D loss: 0.619882, acc.: 64.06%] [G loss: 0.825135]\n",
      "epoch:12 step:11968 [D loss: 0.809302, acc.: 39.84%] [G loss: 0.975622]\n",
      "epoch:12 step:11969 [D loss: 0.810378, acc.: 39.06%] [G loss: 0.916299]\n",
      "epoch:12 step:11970 [D loss: 0.600167, acc.: 70.31%] [G loss: 0.982571]\n",
      "epoch:12 step:11971 [D loss: 0.419268, acc.: 94.53%] [G loss: 0.920576]\n",
      "epoch:12 step:11972 [D loss: 0.330662, acc.: 93.75%] [G loss: 1.013789]\n",
      "epoch:12 step:11973 [D loss: 0.459111, acc.: 88.28%] [G loss: 1.084802]\n",
      "epoch:12 step:11974 [D loss: 0.381476, acc.: 91.41%] [G loss: 1.076557]\n",
      "epoch:12 step:11975 [D loss: 0.449939, acc.: 87.50%] [G loss: 1.099485]\n",
      "epoch:12 step:11976 [D loss: 0.323722, acc.: 94.53%] [G loss: 1.191533]\n",
      "epoch:12 step:11977 [D loss: 0.531284, acc.: 83.59%] [G loss: 1.108722]\n",
      "epoch:12 step:11978 [D loss: 0.724128, acc.: 56.25%] [G loss: 0.561943]\n",
      "epoch:12 step:11979 [D loss: 0.794132, acc.: 43.75%] [G loss: 0.274148]\n",
      "epoch:12 step:11980 [D loss: 0.703578, acc.: 60.94%] [G loss: 1.039488]\n",
      "epoch:12 step:11981 [D loss: 0.839955, acc.: 31.25%] [G loss: 0.845811]\n",
      "epoch:12 step:11982 [D loss: 0.701088, acc.: 50.00%] [G loss: 0.871701]\n",
      "epoch:12 step:11983 [D loss: 0.357164, acc.: 94.53%] [G loss: 0.931903]\n",
      "epoch:12 step:11984 [D loss: 0.685709, acc.: 53.91%] [G loss: 0.923272]\n",
      "epoch:12 step:11985 [D loss: 0.682108, acc.: 57.03%] [G loss: 0.912769]\n",
      "epoch:12 step:11986 [D loss: 1.194628, acc.: 21.09%] [G loss: 1.070990]\n",
      "epoch:12 step:11987 [D loss: 0.581937, acc.: 66.41%] [G loss: 0.986370]\n",
      "epoch:12 step:11988 [D loss: 0.695109, acc.: 57.03%] [G loss: 1.098043]\n",
      "epoch:12 step:11989 [D loss: 0.584616, acc.: 76.56%] [G loss: 0.938872]\n",
      "epoch:12 step:11990 [D loss: 0.385917, acc.: 94.53%] [G loss: 0.912053]\n",
      "epoch:12 step:11991 [D loss: 0.718115, acc.: 50.00%] [G loss: 0.990394]\n",
      "epoch:12 step:11992 [D loss: 0.699782, acc.: 56.25%] [G loss: 0.920702]\n",
      "epoch:12 step:11993 [D loss: 0.707132, acc.: 49.22%] [G loss: 0.937777]\n",
      "epoch:12 step:11994 [D loss: 0.598557, acc.: 67.19%] [G loss: 0.918297]\n",
      "epoch:12 step:11995 [D loss: 0.885772, acc.: 22.66%] [G loss: 0.562353]\n",
      "epoch:12 step:11996 [D loss: 0.755724, acc.: 45.31%] [G loss: 0.866118]\n",
      "epoch:12 step:11997 [D loss: 0.902084, acc.: 22.66%] [G loss: 0.941388]\n",
      "epoch:12 step:11998 [D loss: 0.666167, acc.: 60.16%] [G loss: 0.958493]\n",
      "epoch:12 step:11999 [D loss: 0.616993, acc.: 70.31%] [G loss: 0.859833]\n",
      "epoch:12 step:12000 [D loss: 0.463727, acc.: 92.97%] [G loss: 0.859668]\n",
      "##############\n",
      "[3.90608795 2.42369195 6.57754749 5.22073412 4.3933259  5.8642843\n",
      " 5.08653836 4.86035631 5.64493415 4.93535174]\n",
      "##########\n",
      "epoch:12 step:12001 [D loss: 0.714717, acc.: 48.44%] [G loss: 0.880515]\n",
      "epoch:12 step:12002 [D loss: 0.677201, acc.: 64.06%] [G loss: 0.896848]\n",
      "epoch:12 step:12003 [D loss: 0.642217, acc.: 62.50%] [G loss: 0.848311]\n",
      "epoch:12 step:12004 [D loss: 0.637373, acc.: 64.06%] [G loss: 0.846743]\n",
      "epoch:12 step:12005 [D loss: 0.690030, acc.: 47.66%] [G loss: 0.812766]\n",
      "epoch:12 step:12006 [D loss: 0.712502, acc.: 52.34%] [G loss: 0.834807]\n",
      "epoch:12 step:12007 [D loss: 0.681550, acc.: 54.69%] [G loss: 0.878233]\n",
      "epoch:12 step:12008 [D loss: 0.587775, acc.: 68.75%] [G loss: 0.804023]\n",
      "epoch:12 step:12009 [D loss: 0.704115, acc.: 48.44%] [G loss: 0.747539]\n",
      "epoch:12 step:12010 [D loss: 0.715300, acc.: 49.22%] [G loss: 0.927117]\n",
      "epoch:12 step:12011 [D loss: 0.659750, acc.: 60.16%] [G loss: 0.779571]\n",
      "epoch:12 step:12012 [D loss: 0.539855, acc.: 83.59%] [G loss: 0.878047]\n",
      "epoch:12 step:12013 [D loss: 0.572316, acc.: 68.75%] [G loss: 0.890101]\n",
      "epoch:12 step:12014 [D loss: 0.696225, acc.: 60.94%] [G loss: 0.853630]\n",
      "epoch:12 step:12015 [D loss: 0.599207, acc.: 69.53%] [G loss: 0.837015]\n",
      "epoch:12 step:12016 [D loss: 0.712350, acc.: 48.44%] [G loss: 0.821621]\n",
      "epoch:12 step:12017 [D loss: 0.655328, acc.: 57.03%] [G loss: 0.792512]\n",
      "epoch:12 step:12018 [D loss: 0.538171, acc.: 75.00%] [G loss: 0.923826]\n",
      "epoch:12 step:12019 [D loss: 0.604747, acc.: 65.62%] [G loss: 0.814032]\n",
      "epoch:12 step:12020 [D loss: 0.696280, acc.: 53.91%] [G loss: 0.884282]\n",
      "epoch:12 step:12021 [D loss: 0.650346, acc.: 68.75%] [G loss: 0.828084]\n",
      "epoch:12 step:12022 [D loss: 0.929255, acc.: 28.12%] [G loss: 0.706402]\n",
      "epoch:12 step:12023 [D loss: 0.716008, acc.: 50.78%] [G loss: 0.933739]\n",
      "epoch:12 step:12024 [D loss: 0.532397, acc.: 74.22%] [G loss: 0.941581]\n",
      "epoch:12 step:12025 [D loss: 0.331377, acc.: 90.62%] [G loss: 0.907570]\n",
      "epoch:12 step:12026 [D loss: 0.440725, acc.: 79.69%] [G loss: 0.960412]\n",
      "epoch:12 step:12027 [D loss: 0.511164, acc.: 79.69%] [G loss: 0.960530]\n",
      "epoch:12 step:12028 [D loss: 0.590578, acc.: 75.00%] [G loss: 0.885951]\n",
      "epoch:12 step:12029 [D loss: 0.695228, acc.: 54.69%] [G loss: 1.032501]\n",
      "epoch:12 step:12030 [D loss: 0.262441, acc.: 96.09%] [G loss: 1.086421]\n",
      "epoch:12 step:12031 [D loss: 0.829313, acc.: 32.03%] [G loss: 1.012678]\n",
      "epoch:12 step:12032 [D loss: 0.402403, acc.: 93.75%] [G loss: 0.946624]\n",
      "epoch:12 step:12033 [D loss: 0.772166, acc.: 43.75%] [G loss: 0.947721]\n",
      "epoch:12 step:12034 [D loss: 0.651344, acc.: 57.81%] [G loss: 0.930992]\n",
      "epoch:12 step:12035 [D loss: 0.377776, acc.: 92.97%] [G loss: 0.948724]\n",
      "epoch:12 step:12036 [D loss: 0.245813, acc.: 93.75%] [G loss: 1.054732]\n",
      "epoch:12 step:12037 [D loss: 0.530862, acc.: 74.22%] [G loss: 1.089333]\n",
      "epoch:12 step:12038 [D loss: 0.448822, acc.: 70.31%] [G loss: 0.547003]\n",
      "epoch:12 step:12039 [D loss: 0.274570, acc.: 97.66%] [G loss: 1.352329]\n",
      "epoch:12 step:12040 [D loss: 0.379102, acc.: 79.69%] [G loss: 1.435258]\n",
      "epoch:12 step:12041 [D loss: 0.811708, acc.: 49.22%] [G loss: 1.202635]\n",
      "epoch:12 step:12042 [D loss: 0.720006, acc.: 51.56%] [G loss: 1.202010]\n",
      "epoch:12 step:12043 [D loss: 0.817270, acc.: 40.62%] [G loss: 0.958860]\n",
      "epoch:12 step:12044 [D loss: 0.812294, acc.: 38.28%] [G loss: 1.145324]\n",
      "epoch:12 step:12045 [D loss: 0.635174, acc.: 60.94%] [G loss: 1.143151]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:12046 [D loss: 0.466538, acc.: 79.69%] [G loss: 1.055260]\n",
      "epoch:12 step:12047 [D loss: 0.757942, acc.: 49.22%] [G loss: 1.008851]\n",
      "epoch:12 step:12048 [D loss: 0.354458, acc.: 97.66%] [G loss: 1.099249]\n",
      "epoch:12 step:12049 [D loss: 0.278690, acc.: 98.44%] [G loss: 1.097541]\n",
      "epoch:12 step:12050 [D loss: 0.410285, acc.: 93.75%] [G loss: 0.540706]\n",
      "epoch:12 step:12051 [D loss: 0.715992, acc.: 54.69%] [G loss: 0.764061]\n",
      "epoch:12 step:12052 [D loss: 0.718704, acc.: 52.34%] [G loss: 1.097892]\n",
      "epoch:12 step:12053 [D loss: 0.660931, acc.: 60.16%] [G loss: 1.044621]\n",
      "epoch:12 step:12054 [D loss: 0.647157, acc.: 63.28%] [G loss: 1.042155]\n",
      "epoch:12 step:12055 [D loss: 0.698175, acc.: 55.47%] [G loss: 0.913059]\n",
      "epoch:12 step:12056 [D loss: 0.469544, acc.: 95.31%] [G loss: 0.990170]\n",
      "epoch:12 step:12057 [D loss: 0.702418, acc.: 53.12%] [G loss: 0.175073]\n",
      "epoch:12 step:12058 [D loss: 0.713316, acc.: 53.12%] [G loss: 0.925426]\n",
      "epoch:12 step:12059 [D loss: 1.065084, acc.: 36.72%] [G loss: 0.980641]\n",
      "epoch:12 step:12060 [D loss: 0.597169, acc.: 71.09%] [G loss: 1.020159]\n",
      "epoch:12 step:12061 [D loss: 0.608862, acc.: 66.41%] [G loss: 1.043895]\n",
      "epoch:12 step:12062 [D loss: 1.018119, acc.: 19.53%] [G loss: 1.037433]\n",
      "epoch:12 step:12063 [D loss: 0.652912, acc.: 58.59%] [G loss: 0.997401]\n",
      "epoch:12 step:12064 [D loss: 0.751695, acc.: 49.22%] [G loss: 0.800323]\n",
      "epoch:12 step:12065 [D loss: 0.599059, acc.: 72.66%] [G loss: 0.537592]\n",
      "epoch:12 step:12066 [D loss: 0.529090, acc.: 84.38%] [G loss: 0.984987]\n",
      "epoch:12 step:12067 [D loss: 0.670898, acc.: 57.03%] [G loss: 0.988589]\n",
      "epoch:12 step:12068 [D loss: 0.571971, acc.: 78.12%] [G loss: 0.924253]\n",
      "epoch:12 step:12069 [D loss: 0.553060, acc.: 83.59%] [G loss: 0.860240]\n",
      "epoch:12 step:12070 [D loss: 0.606703, acc.: 74.22%] [G loss: 0.886154]\n",
      "epoch:12 step:12071 [D loss: 0.651674, acc.: 62.50%] [G loss: 0.256538]\n",
      "epoch:12 step:12072 [D loss: 0.729356, acc.: 52.34%] [G loss: 0.891385]\n",
      "epoch:12 step:12073 [D loss: 0.634246, acc.: 64.84%] [G loss: 0.835667]\n",
      "epoch:12 step:12074 [D loss: 0.540363, acc.: 78.91%] [G loss: 0.411212]\n",
      "epoch:12 step:12075 [D loss: 0.510272, acc.: 77.34%] [G loss: 0.857342]\n",
      "epoch:12 step:12076 [D loss: 0.430059, acc.: 89.84%] [G loss: 0.923898]\n",
      "epoch:12 step:12077 [D loss: 0.499632, acc.: 85.16%] [G loss: 0.744174]\n",
      "epoch:12 step:12078 [D loss: 0.694456, acc.: 54.69%] [G loss: 1.044676]\n",
      "epoch:12 step:12079 [D loss: 0.712973, acc.: 50.78%] [G loss: 0.587073]\n",
      "epoch:12 step:12080 [D loss: 0.657283, acc.: 63.28%] [G loss: 0.983563]\n",
      "epoch:12 step:12081 [D loss: 0.682128, acc.: 61.72%] [G loss: 0.920556]\n",
      "epoch:12 step:12082 [D loss: 0.463378, acc.: 90.62%] [G loss: 0.909393]\n",
      "epoch:12 step:12083 [D loss: 0.635995, acc.: 65.62%] [G loss: 0.822445]\n",
      "epoch:12 step:12084 [D loss: 0.770210, acc.: 39.06%] [G loss: 0.892786]\n",
      "epoch:12 step:12085 [D loss: 0.663238, acc.: 63.28%] [G loss: 0.765823]\n",
      "epoch:12 step:12086 [D loss: 0.596552, acc.: 67.97%] [G loss: 0.813616]\n",
      "epoch:12 step:12087 [D loss: 0.515064, acc.: 77.34%] [G loss: 0.457371]\n",
      "epoch:12 step:12088 [D loss: 0.509904, acc.: 77.34%] [G loss: 1.043082]\n",
      "epoch:12 step:12089 [D loss: 0.410534, acc.: 72.66%] [G loss: 0.936184]\n",
      "epoch:12 step:12090 [D loss: 0.736082, acc.: 43.75%] [G loss: 0.928536]\n",
      "epoch:12 step:12091 [D loss: 1.078172, acc.: 25.00%] [G loss: 1.092918]\n",
      "epoch:12 step:12092 [D loss: 0.673894, acc.: 64.06%] [G loss: 1.113224]\n",
      "epoch:12 step:12093 [D loss: 0.784165, acc.: 40.62%] [G loss: 0.916021]\n",
      "epoch:12 step:12094 [D loss: 0.720287, acc.: 55.47%] [G loss: 0.934984]\n",
      "epoch:12 step:12095 [D loss: 0.532783, acc.: 73.44%] [G loss: 0.837570]\n",
      "epoch:12 step:12096 [D loss: 0.480487, acc.: 85.94%] [G loss: 0.988677]\n",
      "epoch:12 step:12097 [D loss: 0.550703, acc.: 82.81%] [G loss: 0.812706]\n",
      "epoch:12 step:12098 [D loss: 0.442690, acc.: 74.22%] [G loss: 1.006325]\n",
      "epoch:12 step:12099 [D loss: 0.702125, acc.: 54.69%] [G loss: 0.823574]\n",
      "epoch:12 step:12100 [D loss: 0.698227, acc.: 57.03%] [G loss: 1.021649]\n",
      "epoch:12 step:12101 [D loss: 0.556712, acc.: 79.69%] [G loss: 0.976234]\n",
      "epoch:12 step:12102 [D loss: 0.601111, acc.: 75.00%] [G loss: 0.939478]\n",
      "epoch:12 step:12103 [D loss: 0.618382, acc.: 64.06%] [G loss: 0.906692]\n",
      "epoch:12 step:12104 [D loss: 0.485842, acc.: 84.38%] [G loss: 0.946311]\n",
      "epoch:12 step:12105 [D loss: 0.806322, acc.: 28.12%] [G loss: 1.009289]\n",
      "epoch:12 step:12106 [D loss: 0.661479, acc.: 51.56%] [G loss: 0.969153]\n",
      "epoch:12 step:12107 [D loss: 0.592966, acc.: 73.44%] [G loss: 1.063596]\n",
      "epoch:12 step:12108 [D loss: 0.758632, acc.: 36.72%] [G loss: 0.742058]\n",
      "epoch:12 step:12109 [D loss: 1.055588, acc.: 49.22%] [G loss: 1.000422]\n",
      "epoch:12 step:12110 [D loss: 0.623199, acc.: 67.19%] [G loss: 0.794238]\n",
      "epoch:12 step:12111 [D loss: 0.740403, acc.: 50.78%] [G loss: 0.748038]\n",
      "epoch:12 step:12112 [D loss: 0.682509, acc.: 57.81%] [G loss: 0.641047]\n",
      "epoch:12 step:12113 [D loss: 0.823793, acc.: 28.91%] [G loss: 0.856748]\n",
      "epoch:12 step:12114 [D loss: 0.687896, acc.: 53.12%] [G loss: 1.064935]\n",
      "epoch:12 step:12115 [D loss: 0.713006, acc.: 51.56%] [G loss: 0.887378]\n",
      "epoch:12 step:12116 [D loss: 0.501139, acc.: 79.69%] [G loss: 0.896020]\n",
      "epoch:12 step:12117 [D loss: 0.682536, acc.: 60.94%] [G loss: 0.948676]\n",
      "epoch:12 step:12118 [D loss: 0.611058, acc.: 69.53%] [G loss: 0.807800]\n",
      "epoch:12 step:12119 [D loss: 0.822011, acc.: 42.97%] [G loss: 0.892385]\n",
      "epoch:12 step:12120 [D loss: 0.647140, acc.: 65.62%] [G loss: 0.784747]\n",
      "epoch:12 step:12121 [D loss: 0.580463, acc.: 74.22%] [G loss: 0.768013]\n",
      "epoch:12 step:12122 [D loss: 0.476131, acc.: 84.38%] [G loss: 0.817548]\n",
      "epoch:12 step:12123 [D loss: 0.718143, acc.: 50.00%] [G loss: 0.916235]\n",
      "epoch:12 step:12124 [D loss: 0.739558, acc.: 44.53%] [G loss: 0.926042]\n",
      "epoch:12 step:12125 [D loss: 0.724484, acc.: 49.22%] [G loss: 0.908554]\n",
      "epoch:12 step:12126 [D loss: 0.489738, acc.: 75.00%] [G loss: 0.901209]\n",
      "epoch:12 step:12127 [D loss: 0.461848, acc.: 91.41%] [G loss: 0.740370]\n",
      "epoch:12 step:12128 [D loss: 0.523855, acc.: 71.09%] [G loss: 0.963363]\n",
      "epoch:12 step:12129 [D loss: 0.428825, acc.: 70.31%] [G loss: 0.722595]\n",
      "epoch:12 step:12130 [D loss: 0.366461, acc.: 91.41%] [G loss: 0.845454]\n",
      "epoch:12 step:12131 [D loss: 0.312256, acc.: 93.75%] [G loss: 1.164324]\n",
      "epoch:12 step:12132 [D loss: 0.786266, acc.: 49.22%] [G loss: 1.094479]\n",
      "epoch:12 step:12133 [D loss: 0.287387, acc.: 96.09%] [G loss: 1.022460]\n",
      "epoch:12 step:12134 [D loss: 0.258829, acc.: 99.22%] [G loss: 1.256036]\n",
      "epoch:12 step:12135 [D loss: 0.745687, acc.: 50.78%] [G loss: 1.096998]\n",
      "epoch:12 step:12136 [D loss: 0.756435, acc.: 54.69%] [G loss: 1.117882]\n",
      "epoch:12 step:12137 [D loss: 0.749403, acc.: 53.12%] [G loss: 0.977900]\n",
      "epoch:12 step:12138 [D loss: 0.715452, acc.: 50.78%] [G loss: 0.918165]\n",
      "epoch:12 step:12139 [D loss: 0.693039, acc.: 60.16%] [G loss: 0.864029]\n",
      "epoch:12 step:12140 [D loss: 0.633900, acc.: 63.28%] [G loss: 1.046403]\n",
      "epoch:12 step:12141 [D loss: 0.677739, acc.: 56.25%] [G loss: 0.758179]\n",
      "epoch:12 step:12142 [D loss: 0.585070, acc.: 68.75%] [G loss: 0.867764]\n",
      "epoch:12 step:12143 [D loss: 0.409396, acc.: 77.34%] [G loss: 0.974249]\n",
      "epoch:12 step:12144 [D loss: 0.355170, acc.: 94.53%] [G loss: 1.068832]\n",
      "epoch:12 step:12145 [D loss: 0.499942, acc.: 82.03%] [G loss: 1.013661]\n",
      "epoch:12 step:12146 [D loss: 0.684374, acc.: 55.47%] [G loss: 0.806638]\n",
      "epoch:12 step:12147 [D loss: 0.586340, acc.: 69.53%] [G loss: 1.018372]\n",
      "epoch:12 step:12148 [D loss: 0.464811, acc.: 91.41%] [G loss: 0.753119]\n",
      "epoch:12 step:12149 [D loss: 0.382576, acc.: 89.06%] [G loss: 0.867775]\n",
      "epoch:12 step:12150 [D loss: 0.504606, acc.: 82.81%] [G loss: 0.735292]\n",
      "epoch:12 step:12151 [D loss: 0.763628, acc.: 46.88%] [G loss: 0.940453]\n",
      "epoch:12 step:12152 [D loss: 1.096262, acc.: 17.97%] [G loss: 0.963480]\n",
      "epoch:12 step:12153 [D loss: 0.436225, acc.: 92.19%] [G loss: 1.056114]\n",
      "epoch:12 step:12154 [D loss: 0.778140, acc.: 43.75%] [G loss: 0.933961]\n",
      "epoch:12 step:12155 [D loss: 0.437134, acc.: 88.28%] [G loss: 0.711868]\n",
      "epoch:12 step:12156 [D loss: 0.216306, acc.: 96.09%] [G loss: 1.015726]\n",
      "epoch:12 step:12157 [D loss: 0.639021, acc.: 62.50%] [G loss: 0.701999]\n",
      "epoch:12 step:12158 [D loss: 0.692860, acc.: 54.69%] [G loss: 1.030042]\n",
      "epoch:12 step:12159 [D loss: 0.801980, acc.: 39.06%] [G loss: 0.946576]\n",
      "epoch:12 step:12160 [D loss: 0.791516, acc.: 43.75%] [G loss: 0.915227]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:12161 [D loss: 0.552799, acc.: 70.31%] [G loss: 0.618250]\n",
      "epoch:12 step:12162 [D loss: 0.715534, acc.: 47.66%] [G loss: 1.120910]\n",
      "epoch:12 step:12163 [D loss: 0.361002, acc.: 96.09%] [G loss: 0.587110]\n",
      "epoch:12 step:12164 [D loss: 0.426128, acc.: 71.88%] [G loss: 0.708686]\n",
      "epoch:12 step:12165 [D loss: 0.298914, acc.: 94.53%] [G loss: 0.880134]\n",
      "epoch:12 step:12166 [D loss: 0.710272, acc.: 60.94%] [G loss: 1.190258]\n",
      "epoch:12 step:12167 [D loss: 0.720153, acc.: 50.78%] [G loss: 1.015836]\n",
      "epoch:12 step:12168 [D loss: 0.411565, acc.: 88.28%] [G loss: 0.921580]\n",
      "epoch:12 step:12169 [D loss: 0.455415, acc.: 82.03%] [G loss: 0.939845]\n",
      "epoch:12 step:12170 [D loss: 0.267338, acc.: 96.09%] [G loss: 0.818861]\n",
      "epoch:12 step:12171 [D loss: 0.352961, acc.: 81.25%] [G loss: 1.117286]\n",
      "epoch:12 step:12172 [D loss: 0.940512, acc.: 37.50%] [G loss: 1.174629]\n",
      "epoch:12 step:12173 [D loss: 0.223776, acc.: 96.88%] [G loss: 1.240575]\n",
      "epoch:12 step:12174 [D loss: 0.240848, acc.: 100.00%] [G loss: 1.424539]\n",
      "epoch:12 step:12175 [D loss: 0.626998, acc.: 60.94%] [G loss: 1.351419]\n",
      "epoch:12 step:12176 [D loss: 0.669434, acc.: 54.69%] [G loss: 1.007575]\n",
      "epoch:12 step:12177 [D loss: 0.604291, acc.: 66.41%] [G loss: 1.083165]\n",
      "epoch:12 step:12178 [D loss: 0.440713, acc.: 83.59%] [G loss: 1.075581]\n",
      "epoch:12 step:12179 [D loss: 0.901567, acc.: 37.50%] [G loss: 0.491812]\n",
      "epoch:12 step:12180 [D loss: 0.513627, acc.: 63.28%] [G loss: 1.187726]\n",
      "epoch:12 step:12181 [D loss: 0.231648, acc.: 94.53%] [G loss: 1.446597]\n",
      "epoch:13 step:12182 [D loss: 0.884791, acc.: 44.53%] [G loss: 1.245221]\n",
      "epoch:13 step:12183 [D loss: 0.796424, acc.: 49.22%] [G loss: 1.230994]\n",
      "epoch:13 step:12184 [D loss: 0.663965, acc.: 60.16%] [G loss: 1.262125]\n",
      "epoch:13 step:12185 [D loss: 0.719527, acc.: 48.44%] [G loss: 1.028195]\n",
      "epoch:13 step:12186 [D loss: 0.575765, acc.: 71.09%] [G loss: 1.284192]\n",
      "epoch:13 step:12187 [D loss: 0.628807, acc.: 59.38%] [G loss: 1.103721]\n",
      "epoch:13 step:12188 [D loss: 0.688027, acc.: 55.47%] [G loss: 1.102348]\n",
      "epoch:13 step:12189 [D loss: 0.777177, acc.: 43.75%] [G loss: 0.952464]\n",
      "epoch:13 step:12190 [D loss: 0.751216, acc.: 43.75%] [G loss: 0.959009]\n",
      "epoch:13 step:12191 [D loss: 0.768755, acc.: 44.53%] [G loss: 0.934379]\n",
      "epoch:13 step:12192 [D loss: 0.714667, acc.: 52.34%] [G loss: 0.890940]\n",
      "epoch:13 step:12193 [D loss: 0.720093, acc.: 51.56%] [G loss: 0.939914]\n",
      "epoch:13 step:12194 [D loss: 1.340765, acc.: 34.38%] [G loss: 0.908692]\n",
      "epoch:13 step:12195 [D loss: 0.698172, acc.: 58.59%] [G loss: 1.002102]\n",
      "epoch:13 step:12196 [D loss: 0.736210, acc.: 53.91%] [G loss: 1.090181]\n",
      "epoch:13 step:12197 [D loss: 0.937462, acc.: 17.97%] [G loss: 0.998681]\n",
      "epoch:13 step:12198 [D loss: 0.719890, acc.: 50.78%] [G loss: 0.876160]\n",
      "epoch:13 step:12199 [D loss: 0.699790, acc.: 52.34%] [G loss: 0.995129]\n",
      "epoch:13 step:12200 [D loss: 0.689913, acc.: 51.56%] [G loss: 0.798349]\n",
      "##############\n",
      "[4.41007639 2.78799135 6.46642984 5.58750649 4.80740931 6.15891642\n",
      " 5.61304182 5.69974607 5.95142288 4.96461679]\n",
      "##########\n",
      "epoch:13 step:12201 [D loss: 0.578022, acc.: 85.16%] [G loss: 0.857870]\n",
      "epoch:13 step:12202 [D loss: 0.681698, acc.: 52.34%] [G loss: 0.841517]\n",
      "epoch:13 step:12203 [D loss: 0.609010, acc.: 80.47%] [G loss: 0.793499]\n",
      "epoch:13 step:12204 [D loss: 0.741243, acc.: 42.19%] [G loss: 0.882594]\n",
      "epoch:13 step:12205 [D loss: 0.690268, acc.: 53.91%] [G loss: 0.846854]\n",
      "epoch:13 step:12206 [D loss: 0.784164, acc.: 35.94%] [G loss: 0.795655]\n",
      "epoch:13 step:12207 [D loss: 0.670017, acc.: 54.69%] [G loss: 0.789549]\n",
      "epoch:13 step:12208 [D loss: 0.316450, acc.: 95.31%] [G loss: 0.618626]\n",
      "epoch:13 step:12209 [D loss: 0.661108, acc.: 60.16%] [G loss: 1.006559]\n",
      "epoch:13 step:12210 [D loss: 0.632369, acc.: 64.84%] [G loss: 0.887061]\n",
      "epoch:13 step:12211 [D loss: 0.672148, acc.: 50.00%] [G loss: 0.579552]\n",
      "epoch:13 step:12212 [D loss: 0.496626, acc.: 85.94%] [G loss: 0.899394]\n",
      "epoch:13 step:12213 [D loss: 0.512940, acc.: 85.16%] [G loss: 1.051458]\n",
      "epoch:13 step:12214 [D loss: 0.730934, acc.: 49.22%] [G loss: 1.081717]\n",
      "epoch:13 step:12215 [D loss: 1.064953, acc.: 47.66%] [G loss: 1.081275]\n",
      "epoch:13 step:12216 [D loss: 0.770592, acc.: 47.66%] [G loss: 1.127818]\n",
      "epoch:13 step:12217 [D loss: 0.476386, acc.: 83.59%] [G loss: 1.199057]\n",
      "epoch:13 step:12218 [D loss: 0.755924, acc.: 49.22%] [G loss: 0.835630]\n",
      "epoch:13 step:12219 [D loss: 0.831286, acc.: 39.06%] [G loss: 0.562988]\n",
      "epoch:13 step:12220 [D loss: 0.896319, acc.: 23.44%] [G loss: 1.849560]\n",
      "epoch:13 step:12221 [D loss: 0.670388, acc.: 58.59%] [G loss: 1.077661]\n",
      "epoch:13 step:12222 [D loss: 0.698671, acc.: 49.22%] [G loss: 0.935475]\n",
      "epoch:13 step:12223 [D loss: 0.735265, acc.: 45.31%] [G loss: 1.030495]\n",
      "epoch:13 step:12224 [D loss: 0.714980, acc.: 53.12%] [G loss: 0.884190]\n",
      "epoch:13 step:12225 [D loss: 0.700330, acc.: 55.47%] [G loss: 0.936903]\n",
      "epoch:13 step:12226 [D loss: 0.652867, acc.: 55.47%] [G loss: 0.891993]\n",
      "epoch:13 step:12227 [D loss: 0.702296, acc.: 49.22%] [G loss: 0.737755]\n",
      "epoch:13 step:12228 [D loss: 0.594586, acc.: 59.38%] [G loss: 1.034459]\n",
      "epoch:13 step:12229 [D loss: 0.528984, acc.: 81.25%] [G loss: 0.817264]\n",
      "epoch:13 step:12230 [D loss: 0.503202, acc.: 88.28%] [G loss: 0.963486]\n",
      "epoch:13 step:12231 [D loss: 0.516308, acc.: 75.00%] [G loss: 1.202540]\n",
      "epoch:13 step:12232 [D loss: 0.624443, acc.: 60.16%] [G loss: 1.344757]\n",
      "epoch:13 step:12233 [D loss: 0.610947, acc.: 60.94%] [G loss: 1.608406]\n",
      "epoch:13 step:12234 [D loss: 0.434875, acc.: 93.75%] [G loss: 1.403984]\n",
      "epoch:13 step:12235 [D loss: 0.421916, acc.: 91.41%] [G loss: 0.965531]\n",
      "epoch:13 step:12236 [D loss: 0.427814, acc.: 94.53%] [G loss: 1.319627]\n",
      "epoch:13 step:12237 [D loss: 0.481210, acc.: 87.50%] [G loss: 1.586479]\n",
      "epoch:13 step:12238 [D loss: 0.667310, acc.: 54.69%] [G loss: 0.978189]\n",
      "epoch:13 step:12239 [D loss: 1.059863, acc.: 17.19%] [G loss: 0.739863]\n",
      "epoch:13 step:12240 [D loss: 0.710416, acc.: 47.66%] [G loss: 1.248022]\n",
      "epoch:13 step:12241 [D loss: 0.683459, acc.: 56.25%] [G loss: 0.532770]\n",
      "epoch:13 step:12242 [D loss: 0.597970, acc.: 76.56%] [G loss: 1.195129]\n",
      "epoch:13 step:12243 [D loss: 0.637631, acc.: 61.72%] [G loss: 0.686008]\n",
      "epoch:13 step:12244 [D loss: 0.594653, acc.: 72.66%] [G loss: 0.761118]\n",
      "epoch:13 step:12245 [D loss: 0.574494, acc.: 73.44%] [G loss: 1.379519]\n",
      "epoch:13 step:12246 [D loss: 0.571055, acc.: 77.34%] [G loss: 0.914164]\n",
      "epoch:13 step:12247 [D loss: 0.737849, acc.: 48.44%] [G loss: 1.426473]\n",
      "epoch:13 step:12248 [D loss: 0.451936, acc.: 91.41%] [G loss: 0.786726]\n",
      "epoch:13 step:12249 [D loss: 0.436965, acc.: 90.62%] [G loss: 1.062556]\n",
      "epoch:13 step:12250 [D loss: 0.449697, acc.: 82.81%] [G loss: 0.987673]\n",
      "epoch:13 step:12251 [D loss: 0.443327, acc.: 88.28%] [G loss: 0.991428]\n",
      "epoch:13 step:12252 [D loss: 1.507538, acc.: 45.31%] [G loss: 0.925352]\n",
      "epoch:13 step:12253 [D loss: 0.965079, acc.: 17.19%] [G loss: 0.606571]\n",
      "epoch:13 step:12254 [D loss: 0.787521, acc.: 33.59%] [G loss: 0.679454]\n",
      "epoch:13 step:12255 [D loss: 0.746325, acc.: 41.41%] [G loss: 0.793990]\n",
      "epoch:13 step:12256 [D loss: 0.870536, acc.: 24.22%] [G loss: 0.695553]\n",
      "epoch:13 step:12257 [D loss: 0.731826, acc.: 43.75%] [G loss: 0.725406]\n",
      "epoch:13 step:12258 [D loss: 0.726946, acc.: 45.31%] [G loss: 0.763543]\n",
      "epoch:13 step:12259 [D loss: 0.792399, acc.: 35.16%] [G loss: 0.763886]\n",
      "epoch:13 step:12260 [D loss: 0.745230, acc.: 42.19%] [G loss: 0.641981]\n",
      "epoch:13 step:12261 [D loss: 0.653444, acc.: 58.59%] [G loss: 0.687075]\n",
      "epoch:13 step:12262 [D loss: 0.675302, acc.: 57.81%] [G loss: 0.621282]\n",
      "epoch:13 step:12263 [D loss: 0.611754, acc.: 60.16%] [G loss: 0.711943]\n",
      "epoch:13 step:12264 [D loss: 0.618864, acc.: 62.50%] [G loss: 0.743328]\n",
      "epoch:13 step:12265 [D loss: 0.673103, acc.: 60.94%] [G loss: 0.752410]\n",
      "epoch:13 step:12266 [D loss: 0.566063, acc.: 72.66%] [G loss: 0.793783]\n",
      "epoch:13 step:12267 [D loss: 0.602557, acc.: 75.00%] [G loss: 0.789415]\n",
      "epoch:13 step:12268 [D loss: 0.663921, acc.: 56.25%] [G loss: 0.760196]\n",
      "epoch:13 step:12269 [D loss: 0.694852, acc.: 53.12%] [G loss: 0.752440]\n",
      "epoch:13 step:12270 [D loss: 0.546634, acc.: 85.16%] [G loss: 0.697726]\n",
      "epoch:13 step:12271 [D loss: 0.692494, acc.: 53.91%] [G loss: 0.652946]\n",
      "epoch:13 step:12272 [D loss: 0.698542, acc.: 55.47%] [G loss: 0.739667]\n",
      "epoch:13 step:12273 [D loss: 0.729208, acc.: 46.09%] [G loss: 0.692673]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12274 [D loss: 0.724955, acc.: 53.12%] [G loss: 0.777097]\n",
      "epoch:13 step:12275 [D loss: 0.718276, acc.: 55.47%] [G loss: 0.824591]\n",
      "epoch:13 step:12276 [D loss: 0.662997, acc.: 62.50%] [G loss: 0.815636]\n",
      "epoch:13 step:12277 [D loss: 0.646883, acc.: 56.25%] [G loss: 0.818848]\n",
      "epoch:13 step:12278 [D loss: 0.628953, acc.: 64.84%] [G loss: 0.885535]\n",
      "epoch:13 step:12279 [D loss: 0.654806, acc.: 64.06%] [G loss: 0.876782]\n",
      "epoch:13 step:12280 [D loss: 0.657240, acc.: 60.94%] [G loss: 0.935007]\n",
      "epoch:13 step:12281 [D loss: 0.562117, acc.: 73.44%] [G loss: 0.889851]\n",
      "epoch:13 step:12282 [D loss: 0.740313, acc.: 41.41%] [G loss: 0.953727]\n",
      "epoch:13 step:12283 [D loss: 0.584116, acc.: 67.19%] [G loss: 0.984386]\n",
      "epoch:13 step:12284 [D loss: 0.643062, acc.: 57.03%] [G loss: 0.922416]\n",
      "epoch:13 step:12285 [D loss: 0.747462, acc.: 46.88%] [G loss: 1.019539]\n",
      "epoch:13 step:12286 [D loss: 0.568614, acc.: 76.56%] [G loss: 0.921990]\n",
      "epoch:13 step:12287 [D loss: 0.729704, acc.: 53.12%] [G loss: 1.061352]\n",
      "epoch:13 step:12288 [D loss: 0.555378, acc.: 75.78%] [G loss: 0.885619]\n",
      "epoch:13 step:12289 [D loss: 0.623102, acc.: 64.84%] [G loss: 1.016215]\n",
      "epoch:13 step:12290 [D loss: 0.624578, acc.: 65.62%] [G loss: 1.048760]\n",
      "epoch:13 step:12291 [D loss: 0.648368, acc.: 57.81%] [G loss: 0.753600]\n",
      "epoch:13 step:12292 [D loss: 0.684287, acc.: 59.38%] [G loss: 1.043640]\n",
      "epoch:13 step:12293 [D loss: 0.734279, acc.: 50.78%] [G loss: 0.862253]\n",
      "epoch:13 step:12294 [D loss: 0.842654, acc.: 35.94%] [G loss: 0.897836]\n",
      "epoch:13 step:12295 [D loss: 0.669293, acc.: 62.50%] [G loss: 0.879918]\n",
      "epoch:13 step:12296 [D loss: 0.643683, acc.: 65.62%] [G loss: 0.855695]\n",
      "epoch:13 step:12297 [D loss: 0.709300, acc.: 47.66%] [G loss: 0.853933]\n",
      "epoch:13 step:12298 [D loss: 0.554857, acc.: 82.81%] [G loss: 0.706092]\n",
      "epoch:13 step:12299 [D loss: 0.574771, acc.: 70.31%] [G loss: 0.943960]\n",
      "epoch:13 step:12300 [D loss: 0.343336, acc.: 86.72%] [G loss: 1.080240]\n",
      "epoch:13 step:12301 [D loss: 0.755134, acc.: 47.66%] [G loss: 0.932256]\n",
      "epoch:13 step:12302 [D loss: 0.710715, acc.: 55.47%] [G loss: 0.828923]\n",
      "epoch:13 step:12303 [D loss: 0.635611, acc.: 65.62%] [G loss: 0.903884]\n",
      "epoch:13 step:12304 [D loss: 0.715393, acc.: 50.00%] [G loss: 0.773780]\n",
      "epoch:13 step:12305 [D loss: 0.598028, acc.: 68.75%] [G loss: 0.911644]\n",
      "epoch:13 step:12306 [D loss: 0.698173, acc.: 53.91%] [G loss: 0.828746]\n",
      "epoch:13 step:12307 [D loss: 0.668419, acc.: 57.81%] [G loss: 0.824700]\n",
      "epoch:13 step:12308 [D loss: 0.661879, acc.: 66.41%] [G loss: 0.996392]\n",
      "epoch:13 step:12309 [D loss: 0.723496, acc.: 46.88%] [G loss: 0.911643]\n",
      "epoch:13 step:12310 [D loss: 0.648181, acc.: 58.59%] [G loss: 0.893570]\n",
      "epoch:13 step:12311 [D loss: 0.644202, acc.: 61.72%] [G loss: 0.964436]\n",
      "epoch:13 step:12312 [D loss: 0.624194, acc.: 63.28%] [G loss: 0.927169]\n",
      "epoch:13 step:12313 [D loss: 0.649658, acc.: 61.72%] [G loss: 0.927556]\n",
      "epoch:13 step:12314 [D loss: 0.469611, acc.: 86.72%] [G loss: 0.819497]\n",
      "epoch:13 step:12315 [D loss: 0.583202, acc.: 71.88%] [G loss: 0.925221]\n",
      "epoch:13 step:12316 [D loss: 0.563245, acc.: 78.12%] [G loss: 0.871374]\n",
      "epoch:13 step:12317 [D loss: 0.647154, acc.: 62.50%] [G loss: 0.867655]\n",
      "epoch:13 step:12318 [D loss: 0.819329, acc.: 37.50%] [G loss: 0.897440]\n",
      "epoch:13 step:12319 [D loss: 0.676480, acc.: 50.78%] [G loss: 0.824073]\n",
      "epoch:13 step:12320 [D loss: 0.641001, acc.: 58.59%] [G loss: 0.815427]\n",
      "epoch:13 step:12321 [D loss: 0.796622, acc.: 42.19%] [G loss: 0.820901]\n",
      "epoch:13 step:12322 [D loss: 0.672816, acc.: 64.84%] [G loss: 0.691047]\n",
      "epoch:13 step:12323 [D loss: 0.739124, acc.: 50.78%] [G loss: 0.811580]\n",
      "epoch:13 step:12324 [D loss: 0.534946, acc.: 75.78%] [G loss: 0.820540]\n",
      "epoch:13 step:12325 [D loss: 0.616004, acc.: 74.22%] [G loss: 0.881011]\n",
      "epoch:13 step:12326 [D loss: 0.459076, acc.: 85.94%] [G loss: 0.945925]\n",
      "epoch:13 step:12327 [D loss: 0.648221, acc.: 63.28%] [G loss: 0.860181]\n",
      "epoch:13 step:12328 [D loss: 0.705478, acc.: 53.91%] [G loss: 0.916409]\n",
      "epoch:13 step:12329 [D loss: 0.694804, acc.: 52.34%] [G loss: 0.786859]\n",
      "epoch:13 step:12330 [D loss: 0.683919, acc.: 61.72%] [G loss: 0.897178]\n",
      "epoch:13 step:12331 [D loss: 0.376977, acc.: 90.62%] [G loss: 0.902292]\n",
      "epoch:13 step:12332 [D loss: 0.476392, acc.: 84.38%] [G loss: 0.873817]\n",
      "epoch:13 step:12333 [D loss: 0.695957, acc.: 55.47%] [G loss: 0.993579]\n",
      "epoch:13 step:12334 [D loss: 0.708432, acc.: 62.50%] [G loss: 0.904508]\n",
      "epoch:13 step:12335 [D loss: 0.816383, acc.: 33.59%] [G loss: 0.927961]\n",
      "epoch:13 step:12336 [D loss: 0.648950, acc.: 64.06%] [G loss: 0.764507]\n",
      "epoch:13 step:12337 [D loss: 0.770824, acc.: 39.06%] [G loss: 0.999494]\n",
      "epoch:13 step:12338 [D loss: 0.677302, acc.: 57.81%] [G loss: 1.031048]\n",
      "epoch:13 step:12339 [D loss: 0.819892, acc.: 37.50%] [G loss: 0.996813]\n",
      "epoch:13 step:12340 [D loss: 0.611524, acc.: 70.31%] [G loss: 1.053252]\n",
      "epoch:13 step:12341 [D loss: 0.739498, acc.: 53.91%] [G loss: 0.964422]\n",
      "epoch:13 step:12342 [D loss: 0.729989, acc.: 51.56%] [G loss: 0.734631]\n",
      "epoch:13 step:12343 [D loss: 0.601929, acc.: 67.19%] [G loss: 0.946004]\n",
      "epoch:13 step:12344 [D loss: 0.645584, acc.: 64.06%] [G loss: 0.923623]\n",
      "epoch:13 step:12345 [D loss: 0.908714, acc.: 39.84%] [G loss: 0.814056]\n",
      "epoch:13 step:12346 [D loss: 0.684731, acc.: 58.59%] [G loss: 0.729105]\n",
      "epoch:13 step:12347 [D loss: 0.834193, acc.: 31.25%] [G loss: 0.867721]\n",
      "epoch:13 step:12348 [D loss: 0.622356, acc.: 68.75%] [G loss: 0.896791]\n",
      "epoch:13 step:12349 [D loss: 0.578436, acc.: 74.22%] [G loss: 0.842063]\n",
      "epoch:13 step:12350 [D loss: 0.695986, acc.: 57.03%] [G loss: 0.864440]\n",
      "epoch:13 step:12351 [D loss: 0.687864, acc.: 60.16%] [G loss: 0.888775]\n",
      "epoch:13 step:12352 [D loss: 0.706480, acc.: 50.00%] [G loss: 0.831592]\n",
      "epoch:13 step:12353 [D loss: 0.630730, acc.: 64.06%] [G loss: 0.772696]\n",
      "epoch:13 step:12354 [D loss: 0.787344, acc.: 39.84%] [G loss: 0.865159]\n",
      "epoch:13 step:12355 [D loss: 0.644457, acc.: 61.72%] [G loss: 0.870422]\n",
      "epoch:13 step:12356 [D loss: 0.704045, acc.: 49.22%] [G loss: 0.885588]\n",
      "epoch:13 step:12357 [D loss: 0.631543, acc.: 65.62%] [G loss: 0.885172]\n",
      "epoch:13 step:12358 [D loss: 0.683259, acc.: 53.12%] [G loss: 0.920722]\n",
      "epoch:13 step:12359 [D loss: 0.686423, acc.: 53.91%] [G loss: 0.866584]\n",
      "epoch:13 step:12360 [D loss: 0.699514, acc.: 55.47%] [G loss: 0.906777]\n",
      "epoch:13 step:12361 [D loss: 0.681783, acc.: 56.25%] [G loss: 0.805377]\n",
      "epoch:13 step:12362 [D loss: 0.560067, acc.: 75.00%] [G loss: 0.968107]\n",
      "epoch:13 step:12363 [D loss: 0.625879, acc.: 64.06%] [G loss: 0.896556]\n",
      "epoch:13 step:12364 [D loss: 0.631060, acc.: 62.50%] [G loss: 0.906671]\n",
      "epoch:13 step:12365 [D loss: 0.491025, acc.: 89.06%] [G loss: 0.766934]\n",
      "epoch:13 step:12366 [D loss: 0.676960, acc.: 56.25%] [G loss: 0.798515]\n",
      "epoch:13 step:12367 [D loss: 0.711249, acc.: 50.00%] [G loss: 0.863744]\n",
      "epoch:13 step:12368 [D loss: 0.664490, acc.: 59.38%] [G loss: 0.797258]\n",
      "epoch:13 step:12369 [D loss: 0.645116, acc.: 64.06%] [G loss: 0.858547]\n",
      "epoch:13 step:12370 [D loss: 0.631541, acc.: 67.97%] [G loss: 0.867229]\n",
      "epoch:13 step:12371 [D loss: 0.635370, acc.: 60.16%] [G loss: 0.830585]\n",
      "epoch:13 step:12372 [D loss: 0.641606, acc.: 60.94%] [G loss: 0.850554]\n",
      "epoch:13 step:12373 [D loss: 0.454089, acc.: 78.91%] [G loss: 0.929587]\n",
      "epoch:13 step:12374 [D loss: 0.573656, acc.: 67.97%] [G loss: 0.956977]\n",
      "epoch:13 step:12375 [D loss: 0.473490, acc.: 84.38%] [G loss: 1.053321]\n",
      "epoch:13 step:12376 [D loss: 0.533200, acc.: 75.78%] [G loss: 0.828000]\n",
      "epoch:13 step:12377 [D loss: 0.550054, acc.: 79.69%] [G loss: 1.071044]\n",
      "epoch:13 step:12378 [D loss: 0.636346, acc.: 64.06%] [G loss: 0.946999]\n",
      "epoch:13 step:12379 [D loss: 0.626651, acc.: 66.41%] [G loss: 1.100801]\n",
      "epoch:13 step:12380 [D loss: 0.744320, acc.: 47.66%] [G loss: 1.009128]\n",
      "epoch:13 step:12381 [D loss: 0.823793, acc.: 45.31%] [G loss: 0.888281]\n",
      "epoch:13 step:12382 [D loss: 0.618291, acc.: 64.84%] [G loss: 1.026731]\n",
      "epoch:13 step:12383 [D loss: 0.838564, acc.: 35.94%] [G loss: 1.047778]\n",
      "epoch:13 step:12384 [D loss: 0.569026, acc.: 71.09%] [G loss: 0.839766]\n",
      "epoch:13 step:12385 [D loss: 0.463787, acc.: 82.03%] [G loss: 0.800839]\n",
      "epoch:13 step:12386 [D loss: 0.560037, acc.: 74.22%] [G loss: 0.843071]\n",
      "epoch:13 step:12387 [D loss: 0.503022, acc.: 81.25%] [G loss: 1.036154]\n",
      "epoch:13 step:12388 [D loss: 0.480787, acc.: 60.94%] [G loss: 1.005434]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12389 [D loss: 0.469219, acc.: 91.41%] [G loss: 1.230172]\n",
      "epoch:13 step:12390 [D loss: 0.555025, acc.: 75.78%] [G loss: 0.791240]\n",
      "epoch:13 step:12391 [D loss: 0.838687, acc.: 36.72%] [G loss: 1.100291]\n",
      "epoch:13 step:12392 [D loss: 0.771416, acc.: 46.09%] [G loss: 1.039061]\n",
      "epoch:13 step:12393 [D loss: 0.675385, acc.: 53.91%] [G loss: 0.975291]\n",
      "epoch:13 step:12394 [D loss: 0.647752, acc.: 59.38%] [G loss: 0.634063]\n",
      "epoch:13 step:12395 [D loss: 0.808343, acc.: 42.19%] [G loss: 0.841755]\n",
      "epoch:13 step:12396 [D loss: 0.828544, acc.: 34.38%] [G loss: 0.804849]\n",
      "epoch:13 step:12397 [D loss: 0.777763, acc.: 42.97%] [G loss: 0.898738]\n",
      "epoch:13 step:12398 [D loss: 0.662903, acc.: 56.25%] [G loss: 0.792520]\n",
      "epoch:13 step:12399 [D loss: 0.562166, acc.: 73.44%] [G loss: 0.941786]\n",
      "epoch:13 step:12400 [D loss: 0.534427, acc.: 82.03%] [G loss: 0.926917]\n",
      "##############\n",
      "[4.31908739 2.397898   6.66828352 5.14776476 3.9292208  6.22747937\n",
      " 5.52687964 5.59943964 5.53508275 4.81920427]\n",
      "##########\n",
      "epoch:13 step:12401 [D loss: 0.511103, acc.: 64.06%] [G loss: 0.886651]\n",
      "epoch:13 step:12402 [D loss: 0.530965, acc.: 75.78%] [G loss: 1.110870]\n",
      "epoch:13 step:12403 [D loss: 0.449667, acc.: 78.91%] [G loss: 1.057007]\n",
      "epoch:13 step:12404 [D loss: 0.629630, acc.: 64.84%] [G loss: 1.216912]\n",
      "epoch:13 step:12405 [D loss: 0.766589, acc.: 53.91%] [G loss: 1.086661]\n",
      "epoch:13 step:12406 [D loss: 0.683944, acc.: 61.72%] [G loss: 1.136171]\n",
      "epoch:13 step:12407 [D loss: 0.709017, acc.: 52.34%] [G loss: 0.909554]\n",
      "epoch:13 step:12408 [D loss: 0.699957, acc.: 54.69%] [G loss: 0.980566]\n",
      "epoch:13 step:12409 [D loss: 0.711069, acc.: 55.47%] [G loss: 1.002532]\n",
      "epoch:13 step:12410 [D loss: 0.687173, acc.: 57.03%] [G loss: 0.979932]\n",
      "epoch:13 step:12411 [D loss: 0.329277, acc.: 83.59%] [G loss: 1.114365]\n",
      "epoch:13 step:12412 [D loss: 0.426317, acc.: 85.94%] [G loss: 1.048311]\n",
      "epoch:13 step:12413 [D loss: 0.352671, acc.: 91.41%] [G loss: 1.067313]\n",
      "epoch:13 step:12414 [D loss: 0.732266, acc.: 53.12%] [G loss: 1.063657]\n",
      "epoch:13 step:12415 [D loss: 0.530431, acc.: 78.12%] [G loss: 0.952514]\n",
      "epoch:13 step:12416 [D loss: 0.273147, acc.: 94.53%] [G loss: 1.129892]\n",
      "epoch:13 step:12417 [D loss: 0.647507, acc.: 64.84%] [G loss: 1.423344]\n",
      "epoch:13 step:12418 [D loss: 0.491090, acc.: 84.38%] [G loss: 1.058673]\n",
      "epoch:13 step:12419 [D loss: 0.356794, acc.: 81.25%] [G loss: 0.984628]\n",
      "epoch:13 step:12420 [D loss: 0.746445, acc.: 46.09%] [G loss: 0.960145]\n",
      "epoch:13 step:12421 [D loss: 0.741469, acc.: 47.66%] [G loss: 1.312613]\n",
      "epoch:13 step:12422 [D loss: 0.883855, acc.: 21.09%] [G loss: 0.938530]\n",
      "epoch:13 step:12423 [D loss: 0.660649, acc.: 60.16%] [G loss: 1.016393]\n",
      "epoch:13 step:12424 [D loss: 0.612196, acc.: 71.88%] [G loss: 0.880011]\n",
      "epoch:13 step:12425 [D loss: 0.688467, acc.: 53.12%] [G loss: 0.824122]\n",
      "epoch:13 step:12426 [D loss: 0.770703, acc.: 46.09%] [G loss: 0.828547]\n",
      "epoch:13 step:12427 [D loss: 0.759027, acc.: 42.97%] [G loss: 0.887410]\n",
      "epoch:13 step:12428 [D loss: 0.686706, acc.: 49.22%] [G loss: 0.804221]\n",
      "epoch:13 step:12429 [D loss: 0.682689, acc.: 53.12%] [G loss: 0.874218]\n",
      "epoch:13 step:12430 [D loss: 0.625904, acc.: 69.53%] [G loss: 0.469316]\n",
      "epoch:13 step:12431 [D loss: 0.944232, acc.: 29.69%] [G loss: 0.894479]\n",
      "epoch:13 step:12432 [D loss: 0.824625, acc.: 39.84%] [G loss: 0.780768]\n",
      "epoch:13 step:12433 [D loss: 0.692613, acc.: 55.47%] [G loss: 0.882620]\n",
      "epoch:13 step:12434 [D loss: 0.699221, acc.: 50.00%] [G loss: 0.905762]\n",
      "epoch:13 step:12435 [D loss: 0.655561, acc.: 60.94%] [G loss: 0.582584]\n",
      "epoch:13 step:12436 [D loss: 0.473297, acc.: 75.00%] [G loss: 0.941926]\n",
      "epoch:13 step:12437 [D loss: 0.309292, acc.: 95.31%] [G loss: 0.715953]\n",
      "epoch:13 step:12438 [D loss: 1.276901, acc.: 31.25%] [G loss: 0.948288]\n",
      "epoch:13 step:12439 [D loss: 0.728928, acc.: 47.66%] [G loss: 0.741440]\n",
      "epoch:13 step:12440 [D loss: 0.754256, acc.: 54.69%] [G loss: 0.760246]\n",
      "epoch:13 step:12441 [D loss: 0.786406, acc.: 39.06%] [G loss: 0.901941]\n",
      "epoch:13 step:12442 [D loss: 0.686994, acc.: 60.16%] [G loss: 1.021031]\n",
      "epoch:13 step:12443 [D loss: 0.823886, acc.: 35.94%] [G loss: 1.057071]\n",
      "epoch:13 step:12444 [D loss: 0.477646, acc.: 80.47%] [G loss: 1.057178]\n",
      "epoch:13 step:12445 [D loss: 0.503976, acc.: 80.47%] [G loss: 1.113994]\n",
      "epoch:13 step:12446 [D loss: 0.856745, acc.: 40.62%] [G loss: 1.091682]\n",
      "epoch:13 step:12447 [D loss: 0.626413, acc.: 61.72%] [G loss: 1.040422]\n",
      "epoch:13 step:12448 [D loss: 0.626289, acc.: 57.03%] [G loss: 1.203455]\n",
      "epoch:13 step:12449 [D loss: 0.638087, acc.: 57.81%] [G loss: 1.227297]\n",
      "epoch:13 step:12450 [D loss: 0.454060, acc.: 88.28%] [G loss: 1.329379]\n",
      "epoch:13 step:12451 [D loss: 0.505861, acc.: 77.34%] [G loss: 1.222425]\n",
      "epoch:13 step:12452 [D loss: 0.400404, acc.: 92.97%] [G loss: 1.483949]\n",
      "epoch:13 step:12453 [D loss: 0.433736, acc.: 88.28%] [G loss: 1.544057]\n",
      "epoch:13 step:12454 [D loss: 0.377774, acc.: 89.06%] [G loss: 1.640537]\n",
      "epoch:13 step:12455 [D loss: 0.391958, acc.: 92.97%] [G loss: 2.047958]\n",
      "epoch:13 step:12456 [D loss: 0.410382, acc.: 82.81%] [G loss: 1.494159]\n",
      "epoch:13 step:12457 [D loss: 0.346350, acc.: 92.19%] [G loss: 1.253894]\n",
      "epoch:13 step:12458 [D loss: 0.584484, acc.: 70.31%] [G loss: 1.161075]\n",
      "epoch:13 step:12459 [D loss: 1.039235, acc.: 33.59%] [G loss: 0.779303]\n",
      "epoch:13 step:12460 [D loss: 1.118650, acc.: 36.72%] [G loss: 0.881876]\n",
      "epoch:13 step:12461 [D loss: 0.794376, acc.: 42.97%] [G loss: 0.729122]\n",
      "epoch:13 step:12462 [D loss: 0.589839, acc.: 71.09%] [G loss: 0.709975]\n",
      "epoch:13 step:12463 [D loss: 0.466649, acc.: 83.59%] [G loss: 0.848938]\n",
      "epoch:13 step:12464 [D loss: 0.663049, acc.: 66.41%] [G loss: 1.099160]\n",
      "epoch:13 step:12465 [D loss: 0.776402, acc.: 40.62%] [G loss: 0.831159]\n",
      "epoch:13 step:12466 [D loss: 0.750468, acc.: 39.84%] [G loss: 0.648266]\n",
      "epoch:13 step:12467 [D loss: 0.637260, acc.: 67.97%] [G loss: 0.836156]\n",
      "epoch:13 step:12468 [D loss: 0.762885, acc.: 50.00%] [G loss: 0.808392]\n",
      "epoch:13 step:12469 [D loss: 0.729134, acc.: 57.03%] [G loss: 0.966445]\n",
      "epoch:13 step:12470 [D loss: 0.668712, acc.: 57.03%] [G loss: 0.897246]\n",
      "epoch:13 step:12471 [D loss: 0.768025, acc.: 46.88%] [G loss: 0.841852]\n",
      "epoch:13 step:12472 [D loss: 0.683898, acc.: 56.25%] [G loss: 0.865653]\n",
      "epoch:13 step:12473 [D loss: 0.738713, acc.: 47.66%] [G loss: 0.834000]\n",
      "epoch:13 step:12474 [D loss: 0.721089, acc.: 53.12%] [G loss: 0.778381]\n",
      "epoch:13 step:12475 [D loss: 0.732356, acc.: 45.31%] [G loss: 0.772631]\n",
      "epoch:13 step:12476 [D loss: 0.735191, acc.: 56.25%] [G loss: 0.787085]\n",
      "epoch:13 step:12477 [D loss: 0.653701, acc.: 64.06%] [G loss: 0.810526]\n",
      "epoch:13 step:12478 [D loss: 0.621779, acc.: 69.53%] [G loss: 0.833236]\n",
      "epoch:13 step:12479 [D loss: 0.623229, acc.: 66.41%] [G loss: 0.863271]\n",
      "epoch:13 step:12480 [D loss: 0.614989, acc.: 71.88%] [G loss: 0.888422]\n",
      "epoch:13 step:12481 [D loss: 0.602583, acc.: 71.09%] [G loss: 0.815581]\n",
      "epoch:13 step:12482 [D loss: 0.688231, acc.: 55.47%] [G loss: 0.772256]\n",
      "epoch:13 step:12483 [D loss: 0.638772, acc.: 71.88%] [G loss: 0.948716]\n",
      "epoch:13 step:12484 [D loss: 0.675471, acc.: 58.59%] [G loss: 0.821199]\n",
      "epoch:13 step:12485 [D loss: 0.734686, acc.: 42.19%] [G loss: 0.919233]\n",
      "epoch:13 step:12486 [D loss: 0.756469, acc.: 46.09%] [G loss: 0.917617]\n",
      "epoch:13 step:12487 [D loss: 0.675477, acc.: 59.38%] [G loss: 0.853388]\n",
      "epoch:13 step:12488 [D loss: 0.676704, acc.: 56.25%] [G loss: 0.850654]\n",
      "epoch:13 step:12489 [D loss: 0.655855, acc.: 57.03%] [G loss: 0.859711]\n",
      "epoch:13 step:12490 [D loss: 0.627407, acc.: 60.94%] [G loss: 0.847260]\n",
      "epoch:13 step:12491 [D loss: 0.681178, acc.: 54.69%] [G loss: 0.780792]\n",
      "epoch:13 step:12492 [D loss: 0.679856, acc.: 60.16%] [G loss: 0.808127]\n",
      "epoch:13 step:12493 [D loss: 0.588268, acc.: 67.19%] [G loss: 0.773089]\n",
      "epoch:13 step:12494 [D loss: 0.577264, acc.: 65.62%] [G loss: 0.882427]\n",
      "epoch:13 step:12495 [D loss: 0.503684, acc.: 73.44%] [G loss: 0.987347]\n",
      "epoch:13 step:12496 [D loss: 0.653515, acc.: 62.50%] [G loss: 0.810100]\n",
      "epoch:13 step:12497 [D loss: 0.687538, acc.: 57.03%] [G loss: 0.837326]\n",
      "epoch:13 step:12498 [D loss: 0.719758, acc.: 48.44%] [G loss: 0.813068]\n",
      "epoch:13 step:12499 [D loss: 0.676561, acc.: 54.69%] [G loss: 0.963713]\n",
      "epoch:13 step:12500 [D loss: 0.676713, acc.: 57.03%] [G loss: 0.916003]\n",
      "epoch:13 step:12501 [D loss: 0.717878, acc.: 48.44%] [G loss: 0.794218]\n",
      "epoch:13 step:12502 [D loss: 0.642609, acc.: 58.59%] [G loss: 0.895995]\n",
      "epoch:13 step:12503 [D loss: 0.649565, acc.: 64.06%] [G loss: 0.935228]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12504 [D loss: 0.694981, acc.: 56.25%] [G loss: 0.865359]\n",
      "epoch:13 step:12505 [D loss: 0.718598, acc.: 49.22%] [G loss: 0.790643]\n",
      "epoch:13 step:12506 [D loss: 0.655549, acc.: 62.50%] [G loss: 0.898146]\n",
      "epoch:13 step:12507 [D loss: 0.686367, acc.: 53.91%] [G loss: 0.757347]\n",
      "epoch:13 step:12508 [D loss: 0.643543, acc.: 68.75%] [G loss: 0.874989]\n",
      "epoch:13 step:12509 [D loss: 0.649953, acc.: 60.94%] [G loss: 0.846276]\n",
      "epoch:13 step:12510 [D loss: 0.711148, acc.: 52.34%] [G loss: 0.796612]\n",
      "epoch:13 step:12511 [D loss: 0.711517, acc.: 52.34%] [G loss: 0.822752]\n",
      "epoch:13 step:12512 [D loss: 0.649109, acc.: 61.72%] [G loss: 0.808808]\n",
      "epoch:13 step:12513 [D loss: 0.665920, acc.: 59.38%] [G loss: 0.770075]\n",
      "epoch:13 step:12514 [D loss: 0.599231, acc.: 65.62%] [G loss: 0.828776]\n",
      "epoch:13 step:12515 [D loss: 0.630111, acc.: 64.84%] [G loss: 0.728648]\n",
      "epoch:13 step:12516 [D loss: 0.637279, acc.: 67.19%] [G loss: 0.839215]\n",
      "epoch:13 step:12517 [D loss: 0.539352, acc.: 74.22%] [G loss: 0.728415]\n",
      "epoch:13 step:12518 [D loss: 0.629092, acc.: 64.06%] [G loss: 0.836708]\n",
      "epoch:13 step:12519 [D loss: 0.748876, acc.: 48.44%] [G loss: 0.697184]\n",
      "epoch:13 step:12520 [D loss: 0.710122, acc.: 48.44%] [G loss: 0.824405]\n",
      "epoch:13 step:12521 [D loss: 0.681896, acc.: 53.91%] [G loss: 0.700120]\n",
      "epoch:13 step:12522 [D loss: 0.691904, acc.: 50.00%] [G loss: 0.869927]\n",
      "epoch:13 step:12523 [D loss: 0.491226, acc.: 85.94%] [G loss: 0.827945]\n",
      "epoch:13 step:12524 [D loss: 0.374826, acc.: 89.06%] [G loss: 0.941671]\n",
      "epoch:13 step:12525 [D loss: 0.471125, acc.: 79.69%] [G loss: 1.059213]\n",
      "epoch:13 step:12526 [D loss: 0.331918, acc.: 91.41%] [G loss: 1.085763]\n",
      "epoch:13 step:12527 [D loss: 0.444209, acc.: 71.88%] [G loss: 0.549681]\n",
      "epoch:13 step:12528 [D loss: 0.509630, acc.: 66.41%] [G loss: 1.148650]\n",
      "epoch:13 step:12529 [D loss: 1.001925, acc.: 20.31%] [G loss: 1.221376]\n",
      "epoch:13 step:12530 [D loss: 0.745772, acc.: 49.22%] [G loss: 1.184251]\n",
      "epoch:13 step:12531 [D loss: 0.758267, acc.: 46.09%] [G loss: 1.005179]\n",
      "epoch:13 step:12532 [D loss: 0.716838, acc.: 49.22%] [G loss: 1.010561]\n",
      "epoch:13 step:12533 [D loss: 0.691975, acc.: 55.47%] [G loss: 1.000790]\n",
      "epoch:13 step:12534 [D loss: 0.669476, acc.: 54.69%] [G loss: 1.010398]\n",
      "epoch:13 step:12535 [D loss: 0.751857, acc.: 44.53%] [G loss: 0.962875]\n",
      "epoch:13 step:12536 [D loss: 0.710876, acc.: 53.91%] [G loss: 1.000987]\n",
      "epoch:13 step:12537 [D loss: 0.695656, acc.: 55.47%] [G loss: 0.935346]\n",
      "epoch:13 step:12538 [D loss: 0.642824, acc.: 68.75%] [G loss: 0.931931]\n",
      "epoch:13 step:12539 [D loss: 0.644581, acc.: 59.38%] [G loss: 1.002115]\n",
      "epoch:13 step:12540 [D loss: 0.632158, acc.: 60.16%] [G loss: 0.963883]\n",
      "epoch:13 step:12541 [D loss: 0.668812, acc.: 54.69%] [G loss: 0.912694]\n",
      "epoch:13 step:12542 [D loss: 0.661219, acc.: 54.69%] [G loss: 0.869146]\n",
      "epoch:13 step:12543 [D loss: 0.723598, acc.: 51.56%] [G loss: 0.849434]\n",
      "epoch:13 step:12544 [D loss: 0.701573, acc.: 55.47%] [G loss: 0.874144]\n",
      "epoch:13 step:12545 [D loss: 0.683371, acc.: 56.25%] [G loss: 0.821015]\n",
      "epoch:13 step:12546 [D loss: 0.714823, acc.: 48.44%] [G loss: 0.858322]\n",
      "epoch:13 step:12547 [D loss: 0.649820, acc.: 62.50%] [G loss: 0.786849]\n",
      "epoch:13 step:12548 [D loss: 0.677667, acc.: 58.59%] [G loss: 0.832381]\n",
      "epoch:13 step:12549 [D loss: 0.680075, acc.: 53.91%] [G loss: 0.757932]\n",
      "epoch:13 step:12550 [D loss: 0.614929, acc.: 63.28%] [G loss: 0.834894]\n",
      "epoch:13 step:12551 [D loss: 0.578026, acc.: 68.75%] [G loss: 0.841519]\n",
      "epoch:13 step:12552 [D loss: 0.483022, acc.: 78.12%] [G loss: 0.952648]\n",
      "epoch:13 step:12553 [D loss: 0.563124, acc.: 78.91%] [G loss: 0.828329]\n",
      "epoch:13 step:12554 [D loss: 0.729840, acc.: 46.09%] [G loss: 0.881516]\n",
      "epoch:13 step:12555 [D loss: 0.625568, acc.: 67.19%] [G loss: 0.868398]\n",
      "epoch:13 step:12556 [D loss: 0.694812, acc.: 55.47%] [G loss: 0.808570]\n",
      "epoch:13 step:12557 [D loss: 0.702227, acc.: 50.78%] [G loss: 0.833973]\n",
      "epoch:13 step:12558 [D loss: 0.629574, acc.: 71.88%] [G loss: 0.841446]\n",
      "epoch:13 step:12559 [D loss: 0.652162, acc.: 60.16%] [G loss: 0.868162]\n",
      "epoch:13 step:12560 [D loss: 0.584138, acc.: 79.69%] [G loss: 0.815121]\n",
      "epoch:13 step:12561 [D loss: 0.538383, acc.: 74.22%] [G loss: 0.816783]\n",
      "epoch:13 step:12562 [D loss: 0.599344, acc.: 71.88%] [G loss: 0.722445]\n",
      "epoch:13 step:12563 [D loss: 0.666234, acc.: 54.69%] [G loss: 0.846409]\n",
      "epoch:13 step:12564 [D loss: 0.703259, acc.: 47.66%] [G loss: 0.849056]\n",
      "epoch:13 step:12565 [D loss: 0.729751, acc.: 47.66%] [G loss: 0.897342]\n",
      "epoch:13 step:12566 [D loss: 0.627224, acc.: 70.31%] [G loss: 0.659906]\n",
      "epoch:13 step:12567 [D loss: 0.649786, acc.: 66.41%] [G loss: 0.789813]\n",
      "epoch:13 step:12568 [D loss: 0.650141, acc.: 75.00%] [G loss: 0.830104]\n",
      "epoch:13 step:12569 [D loss: 0.689193, acc.: 54.69%] [G loss: 0.808623]\n",
      "epoch:13 step:12570 [D loss: 0.694238, acc.: 50.78%] [G loss: 0.966384]\n",
      "epoch:13 step:12571 [D loss: 0.706425, acc.: 53.91%] [G loss: 0.790282]\n",
      "epoch:13 step:12572 [D loss: 0.768687, acc.: 38.28%] [G loss: 0.563138]\n",
      "epoch:13 step:12573 [D loss: 0.684056, acc.: 54.69%] [G loss: 0.558931]\n",
      "epoch:13 step:12574 [D loss: 0.692526, acc.: 56.25%] [G loss: 0.701058]\n",
      "epoch:13 step:12575 [D loss: 0.710710, acc.: 45.31%] [G loss: 0.875610]\n",
      "epoch:13 step:12576 [D loss: 0.702457, acc.: 51.56%] [G loss: 0.799177]\n",
      "epoch:13 step:12577 [D loss: 0.524404, acc.: 74.22%] [G loss: 0.825877]\n",
      "epoch:13 step:12578 [D loss: 0.447508, acc.: 79.69%] [G loss: 0.643607]\n",
      "epoch:13 step:12579 [D loss: 0.361103, acc.: 92.97%] [G loss: 0.841234]\n",
      "epoch:13 step:12580 [D loss: 0.415582, acc.: 85.94%] [G loss: 0.996441]\n",
      "epoch:13 step:12581 [D loss: 0.413417, acc.: 88.28%] [G loss: 0.981458]\n",
      "epoch:13 step:12582 [D loss: 0.501037, acc.: 79.69%] [G loss: 0.971289]\n",
      "epoch:13 step:12583 [D loss: 0.309964, acc.: 92.97%] [G loss: 0.979335]\n",
      "epoch:13 step:12584 [D loss: 0.572204, acc.: 78.91%] [G loss: 0.945011]\n",
      "epoch:13 step:12585 [D loss: 0.291680, acc.: 97.66%] [G loss: 1.005885]\n",
      "epoch:13 step:12586 [D loss: 0.277249, acc.: 96.88%] [G loss: 0.991954]\n",
      "epoch:13 step:12587 [D loss: 0.348811, acc.: 82.81%] [G loss: 1.072007]\n",
      "epoch:13 step:12588 [D loss: 0.251521, acc.: 99.22%] [G loss: 1.143365]\n",
      "epoch:13 step:12589 [D loss: 0.473343, acc.: 88.28%] [G loss: 1.096745]\n",
      "epoch:13 step:12590 [D loss: 0.233303, acc.: 98.44%] [G loss: 1.061491]\n",
      "epoch:13 step:12591 [D loss: 0.464501, acc.: 90.62%] [G loss: 1.155371]\n",
      "epoch:13 step:12592 [D loss: 0.831536, acc.: 50.00%] [G loss: 1.032005]\n",
      "epoch:13 step:12593 [D loss: 0.412124, acc.: 90.62%] [G loss: 1.098374]\n",
      "epoch:13 step:12594 [D loss: 0.320835, acc.: 94.53%] [G loss: 1.018308]\n",
      "epoch:13 step:12595 [D loss: 0.213116, acc.: 99.22%] [G loss: 1.193657]\n",
      "epoch:13 step:12596 [D loss: 0.255524, acc.: 99.22%] [G loss: 1.238146]\n",
      "epoch:13 step:12597 [D loss: 0.327119, acc.: 95.31%] [G loss: 1.307434]\n",
      "epoch:13 step:12598 [D loss: 0.218479, acc.: 97.66%] [G loss: 1.313402]\n",
      "epoch:13 step:12599 [D loss: 0.195758, acc.: 100.00%] [G loss: 1.259711]\n",
      "epoch:13 step:12600 [D loss: 0.152621, acc.: 100.00%] [G loss: 1.436890]\n",
      "##############\n",
      "[3.61587107 2.443219   6.66822886 5.76437321 4.17201124 6.21327712\n",
      " 5.54042905 5.36389553 5.52920287 4.73202824]\n",
      "##########\n",
      "epoch:13 step:12601 [D loss: 0.271124, acc.: 94.53%] [G loss: 1.622639]\n",
      "epoch:13 step:12602 [D loss: 0.639694, acc.: 57.81%] [G loss: 0.745482]\n",
      "epoch:13 step:12603 [D loss: 0.806787, acc.: 48.44%] [G loss: 1.047188]\n",
      "epoch:13 step:12604 [D loss: 0.454422, acc.: 75.00%] [G loss: 1.380862]\n",
      "epoch:13 step:12605 [D loss: 1.423231, acc.: 50.00%] [G loss: 1.321618]\n",
      "epoch:13 step:12606 [D loss: 0.328040, acc.: 87.50%] [G loss: 1.538109]\n",
      "epoch:13 step:12607 [D loss: 1.154131, acc.: 42.19%] [G loss: 1.748445]\n",
      "epoch:13 step:12608 [D loss: 0.559491, acc.: 69.53%] [G loss: 1.621037]\n",
      "epoch:13 step:12609 [D loss: 0.280245, acc.: 97.66%] [G loss: 0.970824]\n",
      "epoch:13 step:12610 [D loss: 0.632874, acc.: 63.28%] [G loss: 0.914956]\n",
      "epoch:13 step:12611 [D loss: 0.277139, acc.: 96.88%] [G loss: 0.274723]\n",
      "epoch:13 step:12612 [D loss: 0.654537, acc.: 66.41%] [G loss: 0.153431]\n",
      "epoch:13 step:12613 [D loss: 1.906532, acc.: 1.56%] [G loss: 0.667616]\n",
      "epoch:13 step:12614 [D loss: 0.853504, acc.: 50.78%] [G loss: 1.290479]\n",
      "epoch:13 step:12615 [D loss: 0.750330, acc.: 51.56%] [G loss: 0.772874]\n",
      "epoch:13 step:12616 [D loss: 1.094407, acc.: 17.19%] [G loss: 0.956956]\n",
      "epoch:13 step:12617 [D loss: 0.701920, acc.: 48.44%] [G loss: 0.912998]\n",
      "epoch:13 step:12618 [D loss: 0.874928, acc.: 32.81%] [G loss: 1.123419]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12619 [D loss: 0.834203, acc.: 37.50%] [G loss: 0.984741]\n",
      "epoch:13 step:12620 [D loss: 0.854225, acc.: 36.72%] [G loss: 1.003288]\n",
      "epoch:13 step:12621 [D loss: 0.779389, acc.: 39.06%] [G loss: 0.943232]\n",
      "epoch:13 step:12622 [D loss: 0.793486, acc.: 43.75%] [G loss: 0.965926]\n",
      "epoch:13 step:12623 [D loss: 0.746122, acc.: 50.78%] [G loss: 0.981672]\n",
      "epoch:13 step:12624 [D loss: 0.745211, acc.: 43.75%] [G loss: 1.002594]\n",
      "epoch:13 step:12625 [D loss: 0.696563, acc.: 50.00%] [G loss: 1.049339]\n",
      "epoch:13 step:12626 [D loss: 0.699975, acc.: 50.00%] [G loss: 1.040695]\n",
      "epoch:13 step:12627 [D loss: 0.710751, acc.: 50.78%] [G loss: 0.989428]\n",
      "epoch:13 step:12628 [D loss: 0.697377, acc.: 54.69%] [G loss: 1.023966]\n",
      "epoch:13 step:12629 [D loss: 0.625816, acc.: 58.59%] [G loss: 0.975522]\n",
      "epoch:13 step:12630 [D loss: 0.586928, acc.: 68.75%] [G loss: 1.009611]\n",
      "epoch:13 step:12631 [D loss: 0.604850, acc.: 63.28%] [G loss: 1.078996]\n",
      "epoch:13 step:12632 [D loss: 0.498221, acc.: 85.16%] [G loss: 1.202947]\n",
      "epoch:13 step:12633 [D loss: 0.504317, acc.: 85.16%] [G loss: 1.267975]\n",
      "epoch:13 step:12634 [D loss: 0.486025, acc.: 85.94%] [G loss: 1.197797]\n",
      "epoch:13 step:12635 [D loss: 0.542313, acc.: 76.56%] [G loss: 1.224823]\n",
      "epoch:13 step:12636 [D loss: 0.512924, acc.: 74.22%] [G loss: 1.161796]\n",
      "epoch:13 step:12637 [D loss: 0.275256, acc.: 95.31%] [G loss: 1.473566]\n",
      "epoch:13 step:12638 [D loss: 0.432018, acc.: 90.62%] [G loss: 1.335254]\n",
      "epoch:13 step:12639 [D loss: 0.608902, acc.: 59.38%] [G loss: 1.346943]\n",
      "epoch:13 step:12640 [D loss: 0.592218, acc.: 68.75%] [G loss: 1.419301]\n",
      "epoch:13 step:12641 [D loss: 0.522928, acc.: 69.53%] [G loss: 1.291684]\n",
      "epoch:13 step:12642 [D loss: 0.771927, acc.: 50.00%] [G loss: 1.263009]\n",
      "epoch:13 step:12643 [D loss: 0.853244, acc.: 50.78%] [G loss: 1.123246]\n",
      "epoch:13 step:12644 [D loss: 0.723842, acc.: 51.56%] [G loss: 0.965278]\n",
      "epoch:13 step:12645 [D loss: 0.552064, acc.: 76.56%] [G loss: 0.892114]\n",
      "epoch:13 step:12646 [D loss: 0.576659, acc.: 72.66%] [G loss: 1.267852]\n",
      "epoch:13 step:12647 [D loss: 0.542079, acc.: 76.56%] [G loss: 1.154075]\n",
      "epoch:13 step:12648 [D loss: 0.493040, acc.: 80.47%] [G loss: 1.123782]\n",
      "epoch:13 step:12649 [D loss: 0.377579, acc.: 91.41%] [G loss: 1.345788]\n",
      "epoch:13 step:12650 [D loss: 0.397972, acc.: 90.62%] [G loss: 1.415988]\n",
      "epoch:13 step:12651 [D loss: 0.298134, acc.: 94.53%] [G loss: 1.702499]\n",
      "epoch:13 step:12652 [D loss: 0.306346, acc.: 96.88%] [G loss: 1.207894]\n",
      "epoch:13 step:12653 [D loss: 0.489889, acc.: 75.78%] [G loss: 1.412821]\n",
      "epoch:13 step:12654 [D loss: 1.255619, acc.: 30.47%] [G loss: 0.679833]\n",
      "epoch:13 step:12655 [D loss: 0.909302, acc.: 40.62%] [G loss: 0.891838]\n",
      "epoch:13 step:12656 [D loss: 0.824752, acc.: 35.94%] [G loss: 0.581814]\n",
      "epoch:13 step:12657 [D loss: 0.604556, acc.: 68.75%] [G loss: 0.932366]\n",
      "epoch:13 step:12658 [D loss: 0.604499, acc.: 67.19%] [G loss: 0.783661]\n",
      "epoch:13 step:12659 [D loss: 0.675464, acc.: 55.47%] [G loss: 0.712788]\n",
      "epoch:13 step:12660 [D loss: 0.556853, acc.: 70.31%] [G loss: 0.644981]\n",
      "epoch:13 step:12661 [D loss: 0.417448, acc.: 80.47%] [G loss: 0.887856]\n",
      "epoch:13 step:12662 [D loss: 0.347766, acc.: 86.72%] [G loss: 0.985105]\n",
      "epoch:13 step:12663 [D loss: 1.176333, acc.: 24.22%] [G loss: 0.994368]\n",
      "epoch:13 step:12664 [D loss: 0.873115, acc.: 47.66%] [G loss: 1.064862]\n",
      "epoch:13 step:12665 [D loss: 0.850008, acc.: 29.69%] [G loss: 0.993867]\n",
      "epoch:13 step:12666 [D loss: 0.689582, acc.: 54.69%] [G loss: 0.941654]\n",
      "epoch:13 step:12667 [D loss: 0.708078, acc.: 49.22%] [G loss: 0.945521]\n",
      "epoch:13 step:12668 [D loss: 0.676528, acc.: 53.91%] [G loss: 0.886490]\n",
      "epoch:13 step:12669 [D loss: 0.660698, acc.: 57.03%] [G loss: 0.812764]\n",
      "epoch:13 step:12670 [D loss: 0.663516, acc.: 58.59%] [G loss: 0.857749]\n",
      "epoch:13 step:12671 [D loss: 0.604936, acc.: 68.75%] [G loss: 0.823370]\n",
      "epoch:13 step:12672 [D loss: 0.652327, acc.: 60.16%] [G loss: 0.830167]\n",
      "epoch:13 step:12673 [D loss: 0.645804, acc.: 60.94%] [G loss: 0.811494]\n",
      "epoch:13 step:12674 [D loss: 0.671055, acc.: 58.59%] [G loss: 0.858601]\n",
      "epoch:13 step:12675 [D loss: 0.640831, acc.: 61.72%] [G loss: 0.867669]\n",
      "epoch:13 step:12676 [D loss: 0.648719, acc.: 58.59%] [G loss: 0.944773]\n",
      "epoch:13 step:12677 [D loss: 0.675430, acc.: 55.47%] [G loss: 0.826344]\n",
      "epoch:13 step:12678 [D loss: 0.637508, acc.: 66.41%] [G loss: 0.909305]\n",
      "epoch:13 step:12679 [D loss: 0.598184, acc.: 70.31%] [G loss: 0.868151]\n",
      "epoch:13 step:12680 [D loss: 0.580244, acc.: 70.31%] [G loss: 1.004328]\n",
      "epoch:13 step:12681 [D loss: 0.673218, acc.: 60.16%] [G loss: 0.818187]\n",
      "epoch:13 step:12682 [D loss: 0.667956, acc.: 55.47%] [G loss: 0.939215]\n",
      "epoch:13 step:12683 [D loss: 0.644685, acc.: 56.25%] [G loss: 0.782855]\n",
      "epoch:13 step:12684 [D loss: 0.680912, acc.: 55.47%] [G loss: 0.757671]\n",
      "epoch:13 step:12685 [D loss: 0.507001, acc.: 79.69%] [G loss: 0.907998]\n",
      "epoch:13 step:12686 [D loss: 0.589801, acc.: 65.62%] [G loss: 0.896544]\n",
      "epoch:13 step:12687 [D loss: 0.667573, acc.: 60.94%] [G loss: 0.824170]\n",
      "epoch:13 step:12688 [D loss: 0.557920, acc.: 76.56%] [G loss: 0.960592]\n",
      "epoch:13 step:12689 [D loss: 0.544719, acc.: 75.00%] [G loss: 0.849161]\n",
      "epoch:13 step:12690 [D loss: 0.703830, acc.: 45.31%] [G loss: 0.877459]\n",
      "epoch:13 step:12691 [D loss: 0.748510, acc.: 48.44%] [G loss: 0.828779]\n",
      "epoch:13 step:12692 [D loss: 0.716980, acc.: 49.22%] [G loss: 0.872740]\n",
      "epoch:13 step:12693 [D loss: 0.596007, acc.: 72.66%] [G loss: 0.957701]\n",
      "epoch:13 step:12694 [D loss: 0.554469, acc.: 75.78%] [G loss: 0.838570]\n",
      "epoch:13 step:12695 [D loss: 0.455368, acc.: 90.62%] [G loss: 0.982731]\n",
      "epoch:13 step:12696 [D loss: 0.508563, acc.: 78.91%] [G loss: 0.975418]\n",
      "epoch:13 step:12697 [D loss: 0.658176, acc.: 61.72%] [G loss: 1.033870]\n",
      "epoch:13 step:12698 [D loss: 0.679987, acc.: 55.47%] [G loss: 0.971539]\n",
      "epoch:13 step:12699 [D loss: 0.609042, acc.: 67.19%] [G loss: 0.968739]\n",
      "epoch:13 step:12700 [D loss: 0.572223, acc.: 71.09%] [G loss: 0.962631]\n",
      "epoch:13 step:12701 [D loss: 0.577053, acc.: 72.66%] [G loss: 0.992585]\n",
      "epoch:13 step:12702 [D loss: 0.617010, acc.: 62.50%] [G loss: 0.885694]\n",
      "epoch:13 step:12703 [D loss: 0.595433, acc.: 73.44%] [G loss: 0.817801]\n",
      "epoch:13 step:12704 [D loss: 0.582327, acc.: 77.34%] [G loss: 0.794823]\n",
      "epoch:13 step:12705 [D loss: 0.602066, acc.: 66.41%] [G loss: 0.848683]\n",
      "epoch:13 step:12706 [D loss: 0.741485, acc.: 46.88%] [G loss: 0.860873]\n",
      "epoch:13 step:12707 [D loss: 0.684382, acc.: 58.59%] [G loss: 0.981855]\n",
      "epoch:13 step:12708 [D loss: 0.586425, acc.: 68.75%] [G loss: 0.939093]\n",
      "epoch:13 step:12709 [D loss: 0.719276, acc.: 50.78%] [G loss: 0.953766]\n",
      "epoch:13 step:12710 [D loss: 0.660418, acc.: 59.38%] [G loss: 0.877571]\n",
      "epoch:13 step:12711 [D loss: 0.483120, acc.: 76.56%] [G loss: 0.920094]\n",
      "epoch:13 step:12712 [D loss: 0.710641, acc.: 53.91%] [G loss: 0.840743]\n",
      "epoch:13 step:12713 [D loss: 0.669483, acc.: 62.50%] [G loss: 0.878093]\n",
      "epoch:13 step:12714 [D loss: 0.611614, acc.: 63.28%] [G loss: 0.942808]\n",
      "epoch:13 step:12715 [D loss: 0.679703, acc.: 53.91%] [G loss: 0.972309]\n",
      "epoch:13 step:12716 [D loss: 0.541378, acc.: 75.00%] [G loss: 1.047387]\n",
      "epoch:13 step:12717 [D loss: 0.411285, acc.: 86.72%] [G loss: 1.189923]\n",
      "epoch:13 step:12718 [D loss: 0.515551, acc.: 78.12%] [G loss: 1.005371]\n",
      "epoch:13 step:12719 [D loss: 0.440849, acc.: 82.81%] [G loss: 1.156012]\n",
      "epoch:13 step:12720 [D loss: 0.565031, acc.: 71.09%] [G loss: 0.906107]\n",
      "epoch:13 step:12721 [D loss: 0.451713, acc.: 87.50%] [G loss: 1.094601]\n",
      "epoch:13 step:12722 [D loss: 0.523826, acc.: 82.81%] [G loss: 0.946683]\n",
      "epoch:13 step:12723 [D loss: 0.689090, acc.: 55.47%] [G loss: 0.603849]\n",
      "epoch:13 step:12724 [D loss: 0.445034, acc.: 82.03%] [G loss: 1.116244]\n",
      "epoch:13 step:12725 [D loss: 0.770814, acc.: 46.09%] [G loss: 0.838618]\n",
      "epoch:13 step:12726 [D loss: 0.621872, acc.: 67.97%] [G loss: 0.848749]\n",
      "epoch:13 step:12727 [D loss: 0.817383, acc.: 45.31%] [G loss: 0.850897]\n",
      "epoch:13 step:12728 [D loss: 0.597751, acc.: 70.31%] [G loss: 0.651659]\n",
      "epoch:13 step:12729 [D loss: 0.898038, acc.: 33.59%] [G loss: 0.980424]\n",
      "epoch:13 step:12730 [D loss: 0.611786, acc.: 67.97%] [G loss: 1.033480]\n",
      "epoch:13 step:12731 [D loss: 0.368312, acc.: 88.28%] [G loss: 1.037816]\n",
      "epoch:13 step:12732 [D loss: 0.625164, acc.: 69.53%] [G loss: 1.001369]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12733 [D loss: 0.505472, acc.: 74.22%] [G loss: 1.057223]\n",
      "epoch:13 step:12734 [D loss: 0.600152, acc.: 69.53%] [G loss: 0.911639]\n",
      "epoch:13 step:12735 [D loss: 0.381533, acc.: 92.19%] [G loss: 0.991472]\n",
      "epoch:13 step:12736 [D loss: 0.500857, acc.: 83.59%] [G loss: 0.982067]\n",
      "epoch:13 step:12737 [D loss: 0.503774, acc.: 75.00%] [G loss: 1.206222]\n",
      "epoch:13 step:12738 [D loss: 0.358770, acc.: 96.09%] [G loss: 0.812406]\n",
      "epoch:13 step:12739 [D loss: 0.478529, acc.: 82.03%] [G loss: 1.274817]\n",
      "epoch:13 step:12740 [D loss: 0.579932, acc.: 75.00%] [G loss: 1.324672]\n",
      "epoch:13 step:12741 [D loss: 0.863601, acc.: 46.09%] [G loss: 1.263608]\n",
      "epoch:13 step:12742 [D loss: 0.496102, acc.: 80.47%] [G loss: 0.531776]\n",
      "epoch:13 step:12743 [D loss: 0.705561, acc.: 59.38%] [G loss: 0.986265]\n",
      "epoch:13 step:12744 [D loss: 0.693859, acc.: 54.69%] [G loss: 0.078776]\n",
      "epoch:13 step:12745 [D loss: 0.564375, acc.: 73.44%] [G loss: 0.958628]\n",
      "epoch:13 step:12746 [D loss: 0.664746, acc.: 54.69%] [G loss: 1.154099]\n",
      "epoch:13 step:12747 [D loss: 0.477449, acc.: 78.12%] [G loss: 1.118590]\n",
      "epoch:13 step:12748 [D loss: 0.358089, acc.: 88.28%] [G loss: 1.262307]\n",
      "epoch:13 step:12749 [D loss: 0.684219, acc.: 57.81%] [G loss: 1.177920]\n",
      "epoch:13 step:12750 [D loss: 0.645128, acc.: 69.53%] [G loss: 0.881894]\n",
      "epoch:13 step:12751 [D loss: 0.729138, acc.: 53.91%] [G loss: 1.069725]\n",
      "epoch:13 step:12752 [D loss: 0.583356, acc.: 71.88%] [G loss: 0.781968]\n",
      "epoch:13 step:12753 [D loss: 0.714935, acc.: 53.91%] [G loss: 1.132369]\n",
      "epoch:13 step:12754 [D loss: 0.617861, acc.: 65.62%] [G loss: 1.152945]\n",
      "epoch:13 step:12755 [D loss: 0.532140, acc.: 75.00%] [G loss: 1.124644]\n",
      "epoch:13 step:12756 [D loss: 0.518849, acc.: 70.31%] [G loss: 1.108203]\n",
      "epoch:13 step:12757 [D loss: 0.475844, acc.: 79.69%] [G loss: 1.041946]\n",
      "epoch:13 step:12758 [D loss: 0.465516, acc.: 78.91%] [G loss: 1.093194]\n",
      "epoch:13 step:12759 [D loss: 0.331372, acc.: 91.41%] [G loss: 1.175434]\n",
      "epoch:13 step:12760 [D loss: 0.414662, acc.: 87.50%] [G loss: 1.026559]\n",
      "epoch:13 step:12761 [D loss: 0.784662, acc.: 46.09%] [G loss: 0.913546]\n",
      "epoch:13 step:12762 [D loss: 0.681111, acc.: 60.16%] [G loss: 1.239064]\n",
      "epoch:13 step:12763 [D loss: 0.768359, acc.: 46.09%] [G loss: 0.867153]\n",
      "epoch:13 step:12764 [D loss: 0.900188, acc.: 36.72%] [G loss: 0.998118]\n",
      "epoch:13 step:12765 [D loss: 0.781341, acc.: 44.53%] [G loss: 1.002395]\n",
      "epoch:13 step:12766 [D loss: 0.735472, acc.: 44.53%] [G loss: 1.001318]\n",
      "epoch:13 step:12767 [D loss: 0.673068, acc.: 64.84%] [G loss: 1.009959]\n",
      "epoch:13 step:12768 [D loss: 0.375159, acc.: 88.28%] [G loss: 0.996578]\n",
      "epoch:13 step:12769 [D loss: 0.368979, acc.: 87.50%] [G loss: 1.101861]\n",
      "epoch:13 step:12770 [D loss: 0.320584, acc.: 90.62%] [G loss: 1.271124]\n",
      "epoch:13 step:12771 [D loss: 0.806583, acc.: 56.25%] [G loss: 1.105451]\n",
      "epoch:13 step:12772 [D loss: 0.587873, acc.: 70.31%] [G loss: 1.155222]\n",
      "epoch:13 step:12773 [D loss: 0.452528, acc.: 85.94%] [G loss: 1.278923]\n",
      "epoch:13 step:12774 [D loss: 0.727654, acc.: 46.09%] [G loss: 1.251984]\n",
      "epoch:13 step:12775 [D loss: 0.755238, acc.: 48.44%] [G loss: 1.130131]\n",
      "epoch:13 step:12776 [D loss: 0.509230, acc.: 76.56%] [G loss: 1.014983]\n",
      "epoch:13 step:12777 [D loss: 0.493108, acc.: 79.69%] [G loss: 1.107249]\n",
      "epoch:13 step:12778 [D loss: 0.694214, acc.: 56.25%] [G loss: 0.948242]\n",
      "epoch:13 step:12779 [D loss: 0.559864, acc.: 75.78%] [G loss: 0.925792]\n",
      "epoch:13 step:12780 [D loss: 0.696473, acc.: 57.03%] [G loss: 0.918155]\n",
      "epoch:13 step:12781 [D loss: 0.390724, acc.: 78.91%] [G loss: 1.064457]\n",
      "epoch:13 step:12782 [D loss: 0.356254, acc.: 85.94%] [G loss: 1.079149]\n",
      "epoch:13 step:12783 [D loss: 0.390018, acc.: 92.97%] [G loss: 1.144319]\n",
      "epoch:13 step:12784 [D loss: 0.786775, acc.: 50.00%] [G loss: 1.013420]\n",
      "epoch:13 step:12785 [D loss: 0.312998, acc.: 85.94%] [G loss: 0.887348]\n",
      "epoch:13 step:12786 [D loss: 0.718170, acc.: 54.69%] [G loss: 1.037687]\n",
      "epoch:13 step:12787 [D loss: 0.746858, acc.: 50.78%] [G loss: 0.956937]\n",
      "epoch:13 step:12788 [D loss: 0.716772, acc.: 50.78%] [G loss: 0.996348]\n",
      "epoch:13 step:12789 [D loss: 0.463654, acc.: 82.81%] [G loss: 1.135851]\n",
      "epoch:13 step:12790 [D loss: 0.341226, acc.: 96.09%] [G loss: 1.101303]\n",
      "epoch:13 step:12791 [D loss: 0.772521, acc.: 50.00%] [G loss: 0.741587]\n",
      "epoch:13 step:12792 [D loss: 0.352302, acc.: 95.31%] [G loss: 0.683819]\n",
      "epoch:13 step:12793 [D loss: 0.330015, acc.: 93.75%] [G loss: 1.115757]\n",
      "epoch:13 step:12794 [D loss: 0.694141, acc.: 54.69%] [G loss: 1.154012]\n",
      "epoch:13 step:12795 [D loss: 0.697690, acc.: 55.47%] [G loss: 1.171267]\n",
      "epoch:13 step:12796 [D loss: 0.901035, acc.: 33.59%] [G loss: 1.148059]\n",
      "epoch:13 step:12797 [D loss: 0.707525, acc.: 50.78%] [G loss: 1.033500]\n",
      "epoch:13 step:12798 [D loss: 0.737591, acc.: 49.22%] [G loss: 0.823859]\n",
      "epoch:13 step:12799 [D loss: 0.835220, acc.: 56.25%] [G loss: 1.168968]\n",
      "epoch:13 step:12800 [D loss: 0.483587, acc.: 82.81%] [G loss: 1.100045]\n",
      "##############\n",
      "[4.46986268 2.0697918  6.83936423 5.39216848 4.90909509 6.27271864\n",
      " 5.23261615 5.59081373 5.45579587 4.80882339]\n",
      "##########\n",
      "epoch:13 step:12801 [D loss: 0.446462, acc.: 90.62%] [G loss: 0.814344]\n",
      "epoch:13 step:12802 [D loss: 0.744640, acc.: 54.69%] [G loss: 1.053355]\n",
      "epoch:13 step:12803 [D loss: 0.760989, acc.: 46.09%] [G loss: 0.936639]\n",
      "epoch:13 step:12804 [D loss: 0.721201, acc.: 48.44%] [G loss: 0.724446]\n",
      "epoch:13 step:12805 [D loss: 0.681654, acc.: 54.69%] [G loss: 0.876402]\n",
      "epoch:13 step:12806 [D loss: 0.424895, acc.: 88.28%] [G loss: 0.886130]\n",
      "epoch:13 step:12807 [D loss: 0.709501, acc.: 57.81%] [G loss: 0.893030]\n",
      "epoch:13 step:12808 [D loss: 0.436827, acc.: 84.38%] [G loss: 0.723035]\n",
      "epoch:13 step:12809 [D loss: 0.460824, acc.: 89.06%] [G loss: 0.826433]\n",
      "epoch:13 step:12810 [D loss: 0.899125, acc.: 27.34%] [G loss: 0.235083]\n",
      "epoch:13 step:12811 [D loss: 1.046942, acc.: 27.34%] [G loss: 0.325190]\n",
      "epoch:13 step:12812 [D loss: 0.537360, acc.: 73.44%] [G loss: 1.003536]\n",
      "epoch:13 step:12813 [D loss: 0.659643, acc.: 59.38%] [G loss: 0.904816]\n",
      "epoch:13 step:12814 [D loss: 0.571124, acc.: 71.88%] [G loss: 1.130723]\n",
      "epoch:13 step:12815 [D loss: 0.521598, acc.: 75.00%] [G loss: 0.962034]\n",
      "epoch:13 step:12816 [D loss: 0.525116, acc.: 75.00%] [G loss: 1.179714]\n",
      "epoch:13 step:12817 [D loss: 0.712566, acc.: 50.78%] [G loss: 1.015938]\n",
      "epoch:13 step:12818 [D loss: 0.602591, acc.: 64.06%] [G loss: 1.172257]\n",
      "epoch:13 step:12819 [D loss: 0.690277, acc.: 58.59%] [G loss: 0.795360]\n",
      "epoch:13 step:12820 [D loss: 1.048444, acc.: 17.97%] [G loss: 1.057272]\n",
      "epoch:13 step:12821 [D loss: 0.814360, acc.: 38.28%] [G loss: 0.950724]\n",
      "epoch:13 step:12822 [D loss: 0.457887, acc.: 83.59%] [G loss: 0.779746]\n",
      "epoch:13 step:12823 [D loss: 0.748885, acc.: 47.66%] [G loss: 1.184940]\n",
      "epoch:13 step:12824 [D loss: 0.610931, acc.: 61.72%] [G loss: 0.899213]\n",
      "epoch:13 step:12825 [D loss: 0.336323, acc.: 85.94%] [G loss: 1.178935]\n",
      "epoch:13 step:12826 [D loss: 0.503075, acc.: 78.91%] [G loss: 1.612693]\n",
      "epoch:13 step:12827 [D loss: 0.282955, acc.: 93.75%] [G loss: 1.485495]\n",
      "epoch:13 step:12828 [D loss: 0.295541, acc.: 92.97%] [G loss: 1.565341]\n",
      "epoch:13 step:12829 [D loss: 0.187183, acc.: 97.66%] [G loss: 1.827896]\n",
      "epoch:13 step:12830 [D loss: 0.202798, acc.: 99.22%] [G loss: 1.724849]\n",
      "epoch:13 step:12831 [D loss: 0.115943, acc.: 99.22%] [G loss: 1.928821]\n",
      "epoch:13 step:12832 [D loss: 0.190105, acc.: 97.66%] [G loss: 2.248454]\n",
      "epoch:13 step:12833 [D loss: 0.230770, acc.: 98.44%] [G loss: 2.092411]\n",
      "epoch:13 step:12834 [D loss: 0.508534, acc.: 70.31%] [G loss: 1.833164]\n",
      "epoch:13 step:12835 [D loss: 0.275242, acc.: 96.88%] [G loss: 2.119689]\n",
      "epoch:13 step:12836 [D loss: 0.105121, acc.: 99.22%] [G loss: 1.675977]\n",
      "epoch:13 step:12837 [D loss: 0.247806, acc.: 92.97%] [G loss: 1.463467]\n",
      "epoch:13 step:12838 [D loss: 0.248394, acc.: 94.53%] [G loss: 1.056488]\n",
      "epoch:13 step:12839 [D loss: 0.689347, acc.: 61.72%] [G loss: 1.185694]\n",
      "epoch:13 step:12840 [D loss: 0.902485, acc.: 53.91%] [G loss: 3.253457]\n",
      "epoch:13 step:12841 [D loss: 0.291855, acc.: 92.97%] [G loss: 2.103889]\n",
      "epoch:13 step:12842 [D loss: 0.343467, acc.: 90.62%] [G loss: 2.191837]\n",
      "epoch:13 step:12843 [D loss: 1.224928, acc.: 17.19%] [G loss: 0.825388]\n",
      "epoch:13 step:12844 [D loss: 1.886968, acc.: 20.31%] [G loss: 1.605682]\n",
      "epoch:13 step:12845 [D loss: 0.946249, acc.: 48.44%] [G loss: 1.521552]\n",
      "epoch:13 step:12846 [D loss: 0.550130, acc.: 68.75%] [G loss: 1.441927]\n",
      "epoch:13 step:12847 [D loss: 0.702157, acc.: 50.00%] [G loss: 1.756191]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12848 [D loss: 0.694434, acc.: 54.69%] [G loss: 0.992941]\n",
      "epoch:13 step:12849 [D loss: 0.550535, acc.: 73.44%] [G loss: 1.523719]\n",
      "epoch:13 step:12850 [D loss: 0.661622, acc.: 56.25%] [G loss: 1.137876]\n",
      "epoch:13 step:12851 [D loss: 0.681890, acc.: 56.25%] [G loss: 0.946595]\n",
      "epoch:13 step:12852 [D loss: 0.699767, acc.: 56.25%] [G loss: 1.099690]\n",
      "epoch:13 step:12853 [D loss: 0.730551, acc.: 51.56%] [G loss: 1.195192]\n",
      "epoch:13 step:12854 [D loss: 0.717823, acc.: 57.81%] [G loss: 1.005225]\n",
      "epoch:13 step:12855 [D loss: 0.618721, acc.: 64.84%] [G loss: 1.086642]\n",
      "epoch:13 step:12856 [D loss: 0.590147, acc.: 73.44%] [G loss: 0.985561]\n",
      "epoch:13 step:12857 [D loss: 0.579739, acc.: 69.53%] [G loss: 0.937513]\n",
      "epoch:13 step:12858 [D loss: 0.546869, acc.: 76.56%] [G loss: 0.947717]\n",
      "epoch:13 step:12859 [D loss: 0.620261, acc.: 59.38%] [G loss: 0.929049]\n",
      "epoch:13 step:12860 [D loss: 0.621946, acc.: 60.94%] [G loss: 0.920002]\n",
      "epoch:13 step:12861 [D loss: 0.674132, acc.: 57.81%] [G loss: 0.879921]\n",
      "epoch:13 step:12862 [D loss: 0.543339, acc.: 67.97%] [G loss: 0.903615]\n",
      "epoch:13 step:12863 [D loss: 0.538465, acc.: 73.44%] [G loss: 0.899727]\n",
      "epoch:13 step:12864 [D loss: 0.627996, acc.: 61.72%] [G loss: 1.119682]\n",
      "epoch:13 step:12865 [D loss: 0.559413, acc.: 73.44%] [G loss: 0.947564]\n",
      "epoch:13 step:12866 [D loss: 0.685469, acc.: 57.81%] [G loss: 0.844919]\n",
      "epoch:13 step:12867 [D loss: 0.590997, acc.: 67.97%] [G loss: 1.047015]\n",
      "epoch:13 step:12868 [D loss: 0.555832, acc.: 74.22%] [G loss: 1.132638]\n",
      "epoch:13 step:12869 [D loss: 0.719437, acc.: 49.22%] [G loss: 1.020351]\n",
      "epoch:13 step:12870 [D loss: 0.689416, acc.: 57.03%] [G loss: 0.911147]\n",
      "epoch:13 step:12871 [D loss: 0.656951, acc.: 58.59%] [G loss: 0.845881]\n",
      "epoch:13 step:12872 [D loss: 0.598989, acc.: 67.97%] [G loss: 1.097196]\n",
      "epoch:13 step:12873 [D loss: 0.430591, acc.: 80.47%] [G loss: 0.829804]\n",
      "epoch:13 step:12874 [D loss: 0.514555, acc.: 81.25%] [G loss: 0.317273]\n",
      "epoch:13 step:12875 [D loss: 0.527477, acc.: 71.88%] [G loss: 0.909849]\n",
      "epoch:13 step:12876 [D loss: 0.958730, acc.: 28.91%] [G loss: 0.795884]\n",
      "epoch:13 step:12877 [D loss: 0.465346, acc.: 80.47%] [G loss: 0.853755]\n",
      "epoch:13 step:12878 [D loss: 0.384382, acc.: 85.16%] [G loss: 1.155555]\n",
      "epoch:13 step:12879 [D loss: 0.362716, acc.: 87.50%] [G loss: 1.108440]\n",
      "epoch:13 step:12880 [D loss: 0.726771, acc.: 50.00%] [G loss: 1.067617]\n",
      "epoch:13 step:12881 [D loss: 0.432295, acc.: 82.81%] [G loss: 0.966791]\n",
      "epoch:13 step:12882 [D loss: 0.325488, acc.: 93.75%] [G loss: 1.195714]\n",
      "epoch:13 step:12883 [D loss: 0.280814, acc.: 96.88%] [G loss: 1.204983]\n",
      "epoch:13 step:12884 [D loss: 0.725732, acc.: 50.78%] [G loss: 1.638155]\n",
      "epoch:13 step:12885 [D loss: 0.614047, acc.: 68.75%] [G loss: 1.077779]\n",
      "epoch:13 step:12886 [D loss: 0.678605, acc.: 60.94%] [G loss: 1.021927]\n",
      "epoch:13 step:12887 [D loss: 0.350231, acc.: 87.50%] [G loss: 1.102182]\n",
      "epoch:13 step:12888 [D loss: 0.254050, acc.: 93.75%] [G loss: 1.255390]\n",
      "epoch:13 step:12889 [D loss: 0.211524, acc.: 98.44%] [G loss: 1.098632]\n",
      "epoch:13 step:12890 [D loss: 0.290550, acc.: 97.66%] [G loss: 1.503230]\n",
      "epoch:13 step:12891 [D loss: 0.830728, acc.: 52.34%] [G loss: 1.322993]\n",
      "epoch:13 step:12892 [D loss: 0.664409, acc.: 64.06%] [G loss: 1.047354]\n",
      "epoch:13 step:12893 [D loss: 0.989115, acc.: 35.16%] [G loss: 1.001777]\n",
      "epoch:13 step:12894 [D loss: 0.344279, acc.: 80.47%] [G loss: 1.209701]\n",
      "epoch:13 step:12895 [D loss: 0.190579, acc.: 98.44%] [G loss: 1.347501]\n",
      "epoch:13 step:12896 [D loss: 0.663334, acc.: 58.59%] [G loss: 1.385807]\n",
      "epoch:13 step:12897 [D loss: 0.782328, acc.: 51.56%] [G loss: 1.136407]\n",
      "epoch:13 step:12898 [D loss: 0.731859, acc.: 52.34%] [G loss: 1.025113]\n",
      "epoch:13 step:12899 [D loss: 0.841778, acc.: 38.28%] [G loss: 1.081940]\n",
      "epoch:13 step:12900 [D loss: 0.747176, acc.: 52.34%] [G loss: 0.423573]\n",
      "epoch:13 step:12901 [D loss: 0.749747, acc.: 51.56%] [G loss: 0.774531]\n",
      "epoch:13 step:12902 [D loss: 0.700400, acc.: 53.91%] [G loss: 0.939325]\n",
      "epoch:13 step:12903 [D loss: 0.515241, acc.: 82.03%] [G loss: 0.902499]\n",
      "epoch:13 step:12904 [D loss: 0.488690, acc.: 84.38%] [G loss: 0.913598]\n",
      "epoch:13 step:12905 [D loss: 0.712336, acc.: 53.91%] [G loss: 0.956886]\n",
      "epoch:13 step:12906 [D loss: 0.731270, acc.: 49.22%] [G loss: 0.978129]\n",
      "epoch:13 step:12907 [D loss: 0.665071, acc.: 60.16%] [G loss: 0.912950]\n",
      "epoch:13 step:12908 [D loss: 0.283082, acc.: 95.31%] [G loss: 0.966811]\n",
      "epoch:13 step:12909 [D loss: 0.533329, acc.: 65.62%] [G loss: 1.247435]\n",
      "epoch:13 step:12910 [D loss: 0.450301, acc.: 71.88%] [G loss: 1.356741]\n",
      "epoch:13 step:12911 [D loss: 0.261626, acc.: 97.66%] [G loss: 1.545230]\n",
      "epoch:13 step:12912 [D loss: 0.287792, acc.: 97.66%] [G loss: 1.348360]\n",
      "epoch:13 step:12913 [D loss: 0.228098, acc.: 98.44%] [G loss: 1.030309]\n",
      "epoch:13 step:12914 [D loss: 0.326888, acc.: 92.97%] [G loss: 1.384117]\n",
      "epoch:13 step:12915 [D loss: 0.895648, acc.: 39.06%] [G loss: 0.641677]\n",
      "epoch:13 step:12916 [D loss: 1.955491, acc.: 3.91%] [G loss: 0.940218]\n",
      "epoch:13 step:12917 [D loss: 0.851400, acc.: 42.19%] [G loss: 1.222013]\n",
      "epoch:13 step:12918 [D loss: 1.085842, acc.: 19.53%] [G loss: 1.396146]\n",
      "epoch:13 step:12919 [D loss: 0.818473, acc.: 50.78%] [G loss: 1.101778]\n",
      "epoch:13 step:12920 [D loss: 0.649063, acc.: 60.16%] [G loss: 1.142000]\n",
      "epoch:13 step:12921 [D loss: 0.964964, acc.: 18.75%] [G loss: 1.097857]\n",
      "epoch:13 step:12922 [D loss: 0.621159, acc.: 61.72%] [G loss: 1.053000]\n",
      "epoch:13 step:12923 [D loss: 0.568271, acc.: 69.53%] [G loss: 1.107155]\n",
      "epoch:13 step:12924 [D loss: 0.539123, acc.: 75.78%] [G loss: 0.842342]\n",
      "epoch:13 step:12925 [D loss: 0.659035, acc.: 58.59%] [G loss: 0.977833]\n",
      "epoch:13 step:12926 [D loss: 0.700661, acc.: 56.25%] [G loss: 0.942452]\n",
      "epoch:13 step:12927 [D loss: 0.591895, acc.: 73.44%] [G loss: 0.999191]\n",
      "epoch:13 step:12928 [D loss: 0.761067, acc.: 45.31%] [G loss: 1.049304]\n",
      "epoch:13 step:12929 [D loss: 0.706776, acc.: 47.66%] [G loss: 1.040982]\n",
      "epoch:13 step:12930 [D loss: 0.553259, acc.: 76.56%] [G loss: 1.051589]\n",
      "epoch:13 step:12931 [D loss: 0.481075, acc.: 82.81%] [G loss: 1.154704]\n",
      "epoch:13 step:12932 [D loss: 0.740133, acc.: 46.09%] [G loss: 1.052093]\n",
      "epoch:13 step:12933 [D loss: 0.804822, acc.: 39.84%] [G loss: 0.958901]\n",
      "epoch:13 step:12934 [D loss: 0.713200, acc.: 50.78%] [G loss: 1.061949]\n",
      "epoch:13 step:12935 [D loss: 0.592549, acc.: 75.00%] [G loss: 0.971691]\n",
      "epoch:13 step:12936 [D loss: 0.672306, acc.: 57.81%] [G loss: 1.083339]\n",
      "epoch:13 step:12937 [D loss: 0.620257, acc.: 70.31%] [G loss: 0.996622]\n",
      "epoch:13 step:12938 [D loss: 0.673531, acc.: 58.59%] [G loss: 0.786617]\n",
      "epoch:13 step:12939 [D loss: 0.743103, acc.: 48.44%] [G loss: 0.857479]\n",
      "epoch:13 step:12940 [D loss: 0.518928, acc.: 75.00%] [G loss: 0.925585]\n",
      "epoch:13 step:12941 [D loss: 0.487761, acc.: 83.59%] [G loss: 1.103119]\n",
      "epoch:13 step:12942 [D loss: 0.606870, acc.: 65.62%] [G loss: 1.196088]\n",
      "epoch:13 step:12943 [D loss: 0.649929, acc.: 58.59%] [G loss: 1.105331]\n",
      "epoch:13 step:12944 [D loss: 0.678907, acc.: 55.47%] [G loss: 1.000228]\n",
      "epoch:13 step:12945 [D loss: 0.732099, acc.: 53.12%] [G loss: 0.955606]\n",
      "epoch:13 step:12946 [D loss: 0.515131, acc.: 79.69%] [G loss: 1.076172]\n",
      "epoch:13 step:12947 [D loss: 0.570468, acc.: 74.22%] [G loss: 1.016189]\n",
      "epoch:13 step:12948 [D loss: 0.452003, acc.: 87.50%] [G loss: 1.189762]\n",
      "epoch:13 step:12949 [D loss: 0.288944, acc.: 92.97%] [G loss: 0.986570]\n",
      "epoch:13 step:12950 [D loss: 0.281754, acc.: 97.66%] [G loss: 0.987071]\n",
      "epoch:13 step:12951 [D loss: 0.532978, acc.: 80.47%] [G loss: 1.578293]\n",
      "epoch:13 step:12952 [D loss: 0.496418, acc.: 82.81%] [G loss: 1.201142]\n",
      "epoch:13 step:12953 [D loss: 0.636683, acc.: 68.75%] [G loss: 1.026429]\n",
      "epoch:13 step:12954 [D loss: 0.461210, acc.: 81.25%] [G loss: 0.753794]\n",
      "epoch:13 step:12955 [D loss: 0.305159, acc.: 89.84%] [G loss: 0.578135]\n",
      "epoch:13 step:12956 [D loss: 0.574658, acc.: 58.59%] [G loss: 1.125282]\n",
      "epoch:13 step:12957 [D loss: 0.464752, acc.: 84.38%] [G loss: 1.114809]\n",
      "epoch:13 step:12958 [D loss: 0.455912, acc.: 84.38%] [G loss: 1.667821]\n",
      "epoch:13 step:12959 [D loss: 0.588526, acc.: 67.97%] [G loss: 1.550925]\n",
      "epoch:13 step:12960 [D loss: 1.248500, acc.: 8.59%] [G loss: 1.187946]\n",
      "epoch:13 step:12961 [D loss: 1.134717, acc.: 35.16%] [G loss: 0.470600]\n",
      "epoch:13 step:12962 [D loss: 0.731442, acc.: 61.72%] [G loss: 0.869454]\n",
      "epoch:13 step:12963 [D loss: 1.367876, acc.: 25.00%] [G loss: 0.950156]\n",
      "epoch:13 step:12964 [D loss: 0.787292, acc.: 52.34%] [G loss: 1.109054]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12965 [D loss: 0.797878, acc.: 49.22%] [G loss: 0.857314]\n",
      "epoch:13 step:12966 [D loss: 0.736909, acc.: 45.31%] [G loss: 0.932822]\n",
      "epoch:13 step:12967 [D loss: 0.589753, acc.: 75.00%] [G loss: 0.956888]\n",
      "epoch:13 step:12968 [D loss: 0.717845, acc.: 52.34%] [G loss: 0.976176]\n",
      "epoch:13 step:12969 [D loss: 0.674987, acc.: 58.59%] [G loss: 0.951385]\n",
      "epoch:13 step:12970 [D loss: 0.677852, acc.: 58.59%] [G loss: 0.920055]\n",
      "epoch:13 step:12971 [D loss: 0.680961, acc.: 52.34%] [G loss: 0.926598]\n",
      "epoch:13 step:12972 [D loss: 0.520709, acc.: 84.38%] [G loss: 0.879400]\n",
      "epoch:13 step:12973 [D loss: 0.388351, acc.: 94.53%] [G loss: 0.991895]\n",
      "epoch:13 step:12974 [D loss: 0.506710, acc.: 76.56%] [G loss: 1.209797]\n",
      "epoch:13 step:12975 [D loss: 0.435706, acc.: 84.38%] [G loss: 1.041611]\n",
      "epoch:13 step:12976 [D loss: 0.475411, acc.: 85.94%] [G loss: 0.942335]\n",
      "epoch:13 step:12977 [D loss: 0.405017, acc.: 86.72%] [G loss: 1.032883]\n",
      "epoch:13 step:12978 [D loss: 0.677078, acc.: 57.03%] [G loss: 1.014264]\n",
      "epoch:13 step:12979 [D loss: 0.670287, acc.: 60.16%] [G loss: 0.856711]\n",
      "epoch:13 step:12980 [D loss: 0.655354, acc.: 64.06%] [G loss: 0.977246]\n",
      "epoch:13 step:12981 [D loss: 0.589083, acc.: 69.53%] [G loss: 0.915444]\n",
      "epoch:13 step:12982 [D loss: 0.581964, acc.: 72.66%] [G loss: 0.937632]\n",
      "epoch:13 step:12983 [D loss: 0.471232, acc.: 71.88%] [G loss: 0.875647]\n",
      "epoch:13 step:12984 [D loss: 0.683451, acc.: 58.59%] [G loss: 0.890660]\n",
      "epoch:13 step:12985 [D loss: 0.360055, acc.: 87.50%] [G loss: 1.020251]\n",
      "epoch:13 step:12986 [D loss: 0.371439, acc.: 88.28%] [G loss: 1.065764]\n",
      "epoch:13 step:12987 [D loss: 0.291003, acc.: 93.75%] [G loss: 1.118900]\n",
      "epoch:13 step:12988 [D loss: 0.833211, acc.: 37.50%] [G loss: 1.033146]\n",
      "epoch:13 step:12989 [D loss: 0.767389, acc.: 47.66%] [G loss: 0.946154]\n",
      "epoch:13 step:12990 [D loss: 0.658397, acc.: 66.41%] [G loss: 0.821602]\n",
      "epoch:13 step:12991 [D loss: 0.670610, acc.: 60.16%] [G loss: 0.881575]\n",
      "epoch:13 step:12992 [D loss: 0.637249, acc.: 67.19%] [G loss: 0.754933]\n",
      "epoch:13 step:12993 [D loss: 0.510637, acc.: 77.34%] [G loss: 0.647857]\n",
      "epoch:13 step:12994 [D loss: 0.655304, acc.: 65.62%] [G loss: 0.430343]\n",
      "epoch:13 step:12995 [D loss: 0.667544, acc.: 62.50%] [G loss: 0.901286]\n",
      "epoch:13 step:12996 [D loss: 0.597059, acc.: 71.88%] [G loss: 0.828584]\n",
      "epoch:13 step:12997 [D loss: 0.622963, acc.: 66.41%] [G loss: 0.889208]\n",
      "epoch:13 step:12998 [D loss: 0.424578, acc.: 88.28%] [G loss: 0.957166]\n",
      "epoch:13 step:12999 [D loss: 0.689973, acc.: 51.56%] [G loss: 0.839368]\n",
      "epoch:13 step:13000 [D loss: 0.612619, acc.: 72.66%] [G loss: 0.933726]\n",
      "##############\n",
      "[3.95492084 2.43441493 7.0707224  5.62536513 4.29689135 5.73897869\n",
      " 5.35521166 5.40236503 5.60310415 4.97929348]\n",
      "##########\n",
      "epoch:13 step:13001 [D loss: 0.735105, acc.: 42.97%] [G loss: 0.919500]\n",
      "epoch:13 step:13002 [D loss: 0.362936, acc.: 81.25%] [G loss: 0.881342]\n",
      "epoch:13 step:13003 [D loss: 0.410777, acc.: 74.22%] [G loss: 0.663364]\n",
      "epoch:13 step:13004 [D loss: 0.603740, acc.: 72.66%] [G loss: 0.959216]\n",
      "epoch:13 step:13005 [D loss: 0.714984, acc.: 51.56%] [G loss: 0.977556]\n",
      "epoch:13 step:13006 [D loss: 0.636608, acc.: 58.59%] [G loss: 0.720785]\n",
      "epoch:13 step:13007 [D loss: 0.977282, acc.: 41.41%] [G loss: 0.499445]\n",
      "epoch:13 step:13008 [D loss: 0.614672, acc.: 67.97%] [G loss: 0.850528]\n",
      "epoch:13 step:13009 [D loss: 0.567765, acc.: 76.56%] [G loss: 0.612369]\n",
      "epoch:13 step:13010 [D loss: 0.593963, acc.: 71.88%] [G loss: 0.414653]\n",
      "epoch:13 step:13011 [D loss: 0.732684, acc.: 46.09%] [G loss: 0.399818]\n",
      "epoch:13 step:13012 [D loss: 0.682493, acc.: 54.69%] [G loss: 0.672580]\n",
      "epoch:13 step:13013 [D loss: 1.020027, acc.: 27.34%] [G loss: 0.979951]\n",
      "epoch:13 step:13014 [D loss: 0.579955, acc.: 72.66%] [G loss: 0.726730]\n",
      "epoch:13 step:13015 [D loss: 0.452608, acc.: 77.34%] [G loss: 1.191761]\n",
      "epoch:13 step:13016 [D loss: 0.912958, acc.: 25.00%] [G loss: 1.253810]\n",
      "epoch:13 step:13017 [D loss: 0.780019, acc.: 42.19%] [G loss: 1.375221]\n",
      "epoch:13 step:13018 [D loss: 0.691449, acc.: 53.12%] [G loss: 1.085011]\n",
      "epoch:13 step:13019 [D loss: 0.686813, acc.: 53.12%] [G loss: 1.139919]\n",
      "epoch:13 step:13020 [D loss: 0.680688, acc.: 59.38%] [G loss: 0.914455]\n",
      "epoch:13 step:13021 [D loss: 0.735978, acc.: 45.31%] [G loss: 0.727332]\n",
      "epoch:13 step:13022 [D loss: 0.477272, acc.: 86.72%] [G loss: 0.762283]\n",
      "epoch:13 step:13023 [D loss: 0.868454, acc.: 34.38%] [G loss: 1.022436]\n",
      "epoch:13 step:13024 [D loss: 0.619827, acc.: 67.97%] [G loss: 1.076321]\n",
      "epoch:13 step:13025 [D loss: 0.624118, acc.: 64.06%] [G loss: 0.994302]\n",
      "epoch:13 step:13026 [D loss: 0.353725, acc.: 92.97%] [G loss: 1.129794]\n",
      "epoch:13 step:13027 [D loss: 0.643528, acc.: 55.47%] [G loss: 1.003733]\n",
      "epoch:13 step:13028 [D loss: 0.597009, acc.: 67.97%] [G loss: 0.972258]\n",
      "epoch:13 step:13029 [D loss: 0.575693, acc.: 75.00%] [G loss: 0.811275]\n",
      "epoch:13 step:13030 [D loss: 0.811099, acc.: 42.19%] [G loss: 0.911648]\n",
      "epoch:13 step:13031 [D loss: 0.701995, acc.: 59.38%] [G loss: 0.854360]\n",
      "epoch:13 step:13032 [D loss: 0.433816, acc.: 87.50%] [G loss: 0.988408]\n",
      "epoch:13 step:13033 [D loss: 0.462789, acc.: 89.84%] [G loss: 0.698905]\n",
      "epoch:13 step:13034 [D loss: 0.447895, acc.: 89.84%] [G loss: 0.951637]\n",
      "epoch:13 step:13035 [D loss: 0.559409, acc.: 66.41%] [G loss: 1.085249]\n",
      "epoch:13 step:13036 [D loss: 0.730849, acc.: 53.91%] [G loss: 1.081753]\n",
      "epoch:13 step:13037 [D loss: 0.699050, acc.: 55.47%] [G loss: 0.915894]\n",
      "epoch:13 step:13038 [D loss: 0.560475, acc.: 76.56%] [G loss: 0.605417]\n",
      "epoch:13 step:13039 [D loss: 1.050725, acc.: 37.50%] [G loss: 1.027332]\n",
      "epoch:13 step:13040 [D loss: 0.628004, acc.: 64.84%] [G loss: 0.984169]\n",
      "epoch:13 step:13041 [D loss: 0.434789, acc.: 91.41%] [G loss: 1.192838]\n",
      "epoch:13 step:13042 [D loss: 0.751319, acc.: 51.56%] [G loss: 1.126434]\n",
      "epoch:13 step:13043 [D loss: 0.682023, acc.: 50.78%] [G loss: 1.092654]\n",
      "epoch:13 step:13044 [D loss: 0.537850, acc.: 81.25%] [G loss: 1.108862]\n",
      "epoch:13 step:13045 [D loss: 0.661501, acc.: 51.56%] [G loss: 1.001965]\n",
      "epoch:13 step:13046 [D loss: 0.747896, acc.: 58.59%] [G loss: 0.970782]\n",
      "epoch:13 step:13047 [D loss: 0.640043, acc.: 58.59%] [G loss: 0.833946]\n",
      "epoch:13 step:13048 [D loss: 0.683898, acc.: 57.03%] [G loss: 0.809725]\n",
      "epoch:13 step:13049 [D loss: 0.639549, acc.: 64.84%] [G loss: 0.888365]\n",
      "epoch:13 step:13050 [D loss: 0.636564, acc.: 57.03%] [G loss: 0.901975]\n",
      "epoch:13 step:13051 [D loss: 0.631131, acc.: 60.94%] [G loss: 1.213400]\n",
      "epoch:13 step:13052 [D loss: 0.598637, acc.: 57.81%] [G loss: 1.209817]\n",
      "epoch:13 step:13053 [D loss: 0.718654, acc.: 52.34%] [G loss: 0.916685]\n",
      "epoch:13 step:13054 [D loss: 0.596330, acc.: 66.41%] [G loss: 1.004852]\n",
      "epoch:13 step:13055 [D loss: 0.586801, acc.: 68.75%] [G loss: 1.084442]\n",
      "epoch:13 step:13056 [D loss: 0.574919, acc.: 74.22%] [G loss: 1.063154]\n",
      "epoch:13 step:13057 [D loss: 0.446476, acc.: 85.94%] [G loss: 1.077192]\n",
      "epoch:13 step:13058 [D loss: 0.414930, acc.: 96.09%] [G loss: 1.136592]\n",
      "epoch:13 step:13059 [D loss: 0.319462, acc.: 86.72%] [G loss: 1.162810]\n",
      "epoch:13 step:13060 [D loss: 0.665668, acc.: 54.69%] [G loss: 1.058818]\n",
      "epoch:13 step:13061 [D loss: 0.788607, acc.: 46.88%] [G loss: 1.087525]\n",
      "epoch:13 step:13062 [D loss: 0.718633, acc.: 53.91%] [G loss: 1.263057]\n",
      "epoch:13 step:13063 [D loss: 0.764112, acc.: 43.75%] [G loss: 0.996598]\n",
      "epoch:13 step:13064 [D loss: 0.673266, acc.: 56.25%] [G loss: 0.911660]\n",
      "epoch:13 step:13065 [D loss: 0.711172, acc.: 52.34%] [G loss: 0.826096]\n",
      "epoch:13 step:13066 [D loss: 0.634438, acc.: 58.59%] [G loss: 0.807574]\n",
      "epoch:13 step:13067 [D loss: 0.628013, acc.: 69.53%] [G loss: 0.645651]\n",
      "epoch:13 step:13068 [D loss: 0.586514, acc.: 71.88%] [G loss: 0.824948]\n",
      "epoch:13 step:13069 [D loss: 0.804743, acc.: 35.16%] [G loss: 0.779106]\n",
      "epoch:13 step:13070 [D loss: 0.695675, acc.: 52.34%] [G loss: 0.910919]\n",
      "epoch:13 step:13071 [D loss: 0.601783, acc.: 67.97%] [G loss: 0.884479]\n",
      "epoch:13 step:13072 [D loss: 0.722198, acc.: 50.00%] [G loss: 0.991232]\n",
      "epoch:13 step:13073 [D loss: 0.507552, acc.: 82.03%] [G loss: 0.934590]\n",
      "epoch:13 step:13074 [D loss: 0.493682, acc.: 75.00%] [G loss: 1.025480]\n",
      "epoch:13 step:13075 [D loss: 0.511370, acc.: 86.72%] [G loss: 0.920382]\n",
      "epoch:13 step:13076 [D loss: 0.568896, acc.: 71.88%] [G loss: 0.876111]\n",
      "epoch:13 step:13077 [D loss: 0.636398, acc.: 63.28%] [G loss: 1.031655]\n",
      "epoch:13 step:13078 [D loss: 0.563048, acc.: 70.31%] [G loss: 1.251531]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:13079 [D loss: 0.438732, acc.: 86.72%] [G loss: 0.682622]\n",
      "epoch:13 step:13080 [D loss: 0.249861, acc.: 92.97%] [G loss: 1.239139]\n",
      "epoch:13 step:13081 [D loss: 0.222428, acc.: 96.09%] [G loss: 1.283524]\n",
      "epoch:13 step:13082 [D loss: 0.413340, acc.: 86.72%] [G loss: 1.405927]\n",
      "epoch:13 step:13083 [D loss: 0.686561, acc.: 56.25%] [G loss: 0.854171]\n",
      "epoch:13 step:13084 [D loss: 0.456966, acc.: 80.47%] [G loss: 0.910344]\n",
      "epoch:13 step:13085 [D loss: 1.052798, acc.: 22.66%] [G loss: 1.098594]\n",
      "epoch:13 step:13086 [D loss: 0.624123, acc.: 64.06%] [G loss: 0.095733]\n",
      "epoch:13 step:13087 [D loss: 0.694278, acc.: 53.12%] [G loss: 0.933147]\n",
      "epoch:13 step:13088 [D loss: 0.722642, acc.: 53.91%] [G loss: 0.616273]\n",
      "epoch:13 step:13089 [D loss: 0.962076, acc.: 25.00%] [G loss: 0.835004]\n",
      "epoch:13 step:13090 [D loss: 0.475984, acc.: 91.41%] [G loss: 1.025505]\n",
      "epoch:13 step:13091 [D loss: 0.743519, acc.: 49.22%] [G loss: 1.086234]\n",
      "epoch:13 step:13092 [D loss: 0.607418, acc.: 73.44%] [G loss: 0.529351]\n",
      "epoch:13 step:13093 [D loss: 0.242853, acc.: 94.53%] [G loss: 0.867169]\n",
      "epoch:13 step:13094 [D loss: 0.610657, acc.: 62.50%] [G loss: 1.169791]\n",
      "epoch:13 step:13095 [D loss: 0.681886, acc.: 51.56%] [G loss: 0.868749]\n",
      "epoch:13 step:13096 [D loss: 0.822024, acc.: 34.38%] [G loss: 0.972078]\n",
      "epoch:13 step:13097 [D loss: 0.546576, acc.: 77.34%] [G loss: 0.939437]\n",
      "epoch:13 step:13098 [D loss: 0.419187, acc.: 94.53%] [G loss: 0.915884]\n",
      "epoch:13 step:13099 [D loss: 0.679095, acc.: 54.69%] [G loss: 0.941142]\n",
      "epoch:13 step:13100 [D loss: 0.409230, acc.: 88.28%] [G loss: 1.002130]\n",
      "epoch:13 step:13101 [D loss: 0.421300, acc.: 80.47%] [G loss: 0.770314]\n",
      "epoch:13 step:13102 [D loss: 0.401486, acc.: 81.25%] [G loss: 0.940050]\n",
      "epoch:13 step:13103 [D loss: 0.667760, acc.: 63.28%] [G loss: 0.869368]\n",
      "epoch:13 step:13104 [D loss: 0.753096, acc.: 40.62%] [G loss: 0.849169]\n",
      "epoch:13 step:13105 [D loss: 0.420395, acc.: 90.62%] [G loss: 0.918168]\n",
      "epoch:13 step:13106 [D loss: 0.580328, acc.: 67.97%] [G loss: 1.218284]\n",
      "epoch:13 step:13107 [D loss: 0.455111, acc.: 67.19%] [G loss: 1.227592]\n",
      "epoch:13 step:13108 [D loss: 0.345988, acc.: 81.25%] [G loss: 0.726672]\n",
      "epoch:13 step:13109 [D loss: 0.762347, acc.: 55.47%] [G loss: 1.088193]\n",
      "epoch:13 step:13110 [D loss: 0.701243, acc.: 57.03%] [G loss: 1.223893]\n",
      "epoch:13 step:13111 [D loss: 0.359212, acc.: 91.41%] [G loss: 1.253915]\n",
      "epoch:13 step:13112 [D loss: 0.539913, acc.: 75.78%] [G loss: 1.252910]\n",
      "epoch:13 step:13113 [D loss: 0.802580, acc.: 47.66%] [G loss: 1.112019]\n",
      "epoch:13 step:13114 [D loss: 0.660135, acc.: 67.97%] [G loss: 1.055852]\n",
      "epoch:13 step:13115 [D loss: 0.483794, acc.: 85.16%] [G loss: 1.035983]\n",
      "epoch:13 step:13116 [D loss: 0.674174, acc.: 64.06%] [G loss: 0.824146]\n",
      "epoch:13 step:13117 [D loss: 0.360994, acc.: 88.28%] [G loss: 1.028849]\n",
      "epoch:13 step:13118 [D loss: 0.216434, acc.: 96.09%] [G loss: 1.237532]\n",
      "epoch:14 step:13119 [D loss: 0.836882, acc.: 44.53%] [G loss: 0.956262]\n",
      "epoch:14 step:13120 [D loss: 0.771405, acc.: 46.88%] [G loss: 1.132175]\n",
      "epoch:14 step:13121 [D loss: 0.698811, acc.: 53.12%] [G loss: 0.909758]\n",
      "epoch:14 step:13122 [D loss: 0.660438, acc.: 57.03%] [G loss: 0.808773]\n",
      "epoch:14 step:13123 [D loss: 0.572961, acc.: 76.56%] [G loss: 0.885652]\n",
      "epoch:14 step:13124 [D loss: 0.666751, acc.: 64.06%] [G loss: 0.899089]\n",
      "epoch:14 step:13125 [D loss: 0.727748, acc.: 49.22%] [G loss: 0.995825]\n",
      "epoch:14 step:13126 [D loss: 0.703803, acc.: 50.78%] [G loss: 0.724992]\n",
      "epoch:14 step:13127 [D loss: 0.657702, acc.: 60.94%] [G loss: 0.884615]\n",
      "epoch:14 step:13128 [D loss: 0.675757, acc.: 57.03%] [G loss: 0.791642]\n",
      "epoch:14 step:13129 [D loss: 0.691034, acc.: 52.34%] [G loss: 0.892113]\n",
      "epoch:14 step:13130 [D loss: 0.780401, acc.: 44.53%] [G loss: 0.923775]\n",
      "epoch:14 step:13131 [D loss: 0.557176, acc.: 81.25%] [G loss: 0.817503]\n",
      "epoch:14 step:13132 [D loss: 0.622849, acc.: 66.41%] [G loss: 0.869989]\n",
      "epoch:14 step:13133 [D loss: 0.536702, acc.: 78.91%] [G loss: 0.912151]\n",
      "epoch:14 step:13134 [D loss: 0.810461, acc.: 39.06%] [G loss: 0.153319]\n",
      "epoch:14 step:13135 [D loss: 0.684965, acc.: 56.25%] [G loss: 0.918273]\n",
      "epoch:14 step:13136 [D loss: 0.667455, acc.: 58.59%] [G loss: 0.957897]\n",
      "epoch:14 step:13137 [D loss: 0.744280, acc.: 50.78%] [G loss: 0.835014]\n",
      "epoch:14 step:13138 [D loss: 0.835913, acc.: 39.06%] [G loss: 0.589285]\n",
      "epoch:14 step:13139 [D loss: 0.655485, acc.: 60.94%] [G loss: 0.947284]\n",
      "epoch:14 step:13140 [D loss: 0.990574, acc.: 17.19%] [G loss: 0.389950]\n",
      "epoch:14 step:13141 [D loss: 0.700541, acc.: 57.81%] [G loss: 0.949739]\n",
      "epoch:14 step:13142 [D loss: 0.601680, acc.: 72.66%] [G loss: 0.795905]\n",
      "epoch:14 step:13143 [D loss: 0.794917, acc.: 46.88%] [G loss: 1.064414]\n",
      "epoch:14 step:13144 [D loss: 0.678421, acc.: 51.56%] [G loss: 1.035250]\n",
      "epoch:14 step:13145 [D loss: 0.339907, acc.: 96.88%] [G loss: 0.951875]\n",
      "epoch:14 step:13146 [D loss: 0.535726, acc.: 78.12%] [G loss: 1.082197]\n",
      "epoch:14 step:13147 [D loss: 0.657283, acc.: 59.38%] [G loss: 1.076985]\n",
      "epoch:14 step:13148 [D loss: 0.653447, acc.: 57.81%] [G loss: 1.089097]\n",
      "epoch:14 step:13149 [D loss: 0.429115, acc.: 92.19%] [G loss: 1.056647]\n",
      "epoch:14 step:13150 [D loss: 0.405533, acc.: 96.88%] [G loss: 1.019004]\n",
      "epoch:14 step:13151 [D loss: 0.417557, acc.: 92.97%] [G loss: 1.047224]\n",
      "epoch:14 step:13152 [D loss: 0.388964, acc.: 85.94%] [G loss: 1.130884]\n",
      "epoch:14 step:13153 [D loss: 0.299629, acc.: 87.50%] [G loss: 1.181464]\n",
      "epoch:14 step:13154 [D loss: 0.308623, acc.: 85.94%] [G loss: 1.301111]\n",
      "epoch:14 step:13155 [D loss: 0.743297, acc.: 48.44%] [G loss: 1.035900]\n",
      "epoch:14 step:13156 [D loss: 0.682196, acc.: 60.94%] [G loss: 1.110546]\n",
      "epoch:14 step:13157 [D loss: 0.731852, acc.: 53.91%] [G loss: 0.992565]\n",
      "epoch:14 step:13158 [D loss: 0.557138, acc.: 74.22%] [G loss: 0.922081]\n",
      "epoch:14 step:13159 [D loss: 0.687138, acc.: 53.91%] [G loss: 0.908434]\n",
      "epoch:14 step:13160 [D loss: 0.624828, acc.: 67.97%] [G loss: 0.846037]\n",
      "epoch:14 step:13161 [D loss: 0.598207, acc.: 71.88%] [G loss: 0.811174]\n",
      "epoch:14 step:13162 [D loss: 0.720643, acc.: 52.34%] [G loss: 0.760526]\n",
      "epoch:14 step:13163 [D loss: 0.764214, acc.: 41.41%] [G loss: 0.924224]\n",
      "epoch:14 step:13164 [D loss: 0.514732, acc.: 85.16%] [G loss: 0.958067]\n",
      "epoch:14 step:13165 [D loss: 0.796275, acc.: 35.94%] [G loss: 0.724120]\n",
      "epoch:14 step:13166 [D loss: 1.076412, acc.: 25.00%] [G loss: 1.009763]\n",
      "epoch:14 step:13167 [D loss: 0.682181, acc.: 61.72%] [G loss: 0.928202]\n",
      "epoch:14 step:13168 [D loss: 0.608771, acc.: 64.84%] [G loss: 0.937016]\n",
      "epoch:14 step:13169 [D loss: 0.668869, acc.: 60.16%] [G loss: 1.072297]\n",
      "epoch:14 step:13170 [D loss: 0.708775, acc.: 51.56%] [G loss: 0.496585]\n",
      "epoch:14 step:13171 [D loss: 0.608368, acc.: 67.19%] [G loss: 1.032896]\n",
      "epoch:14 step:13172 [D loss: 0.734559, acc.: 48.44%] [G loss: 0.894835]\n",
      "epoch:14 step:13173 [D loss: 0.578652, acc.: 68.75%] [G loss: 1.034600]\n",
      "epoch:14 step:13174 [D loss: 0.803127, acc.: 42.97%] [G loss: 0.948981]\n",
      "epoch:14 step:13175 [D loss: 0.736322, acc.: 54.69%] [G loss: 0.748076]\n",
      "epoch:14 step:13176 [D loss: 0.588396, acc.: 67.97%] [G loss: 1.005555]\n",
      "epoch:14 step:13177 [D loss: 0.727999, acc.: 50.78%] [G loss: 0.822066]\n",
      "epoch:14 step:13178 [D loss: 0.700205, acc.: 57.03%] [G loss: 1.070383]\n",
      "epoch:14 step:13179 [D loss: 1.229240, acc.: 21.09%] [G loss: 1.055489]\n",
      "epoch:14 step:13180 [D loss: 0.797530, acc.: 35.16%] [G loss: 1.081012]\n",
      "epoch:14 step:13181 [D loss: 0.636499, acc.: 60.16%] [G loss: 1.032024]\n",
      "epoch:14 step:13182 [D loss: 0.651791, acc.: 58.59%] [G loss: 1.209112]\n",
      "epoch:14 step:13183 [D loss: 0.600222, acc.: 63.28%] [G loss: 1.277396]\n",
      "epoch:14 step:13184 [D loss: 0.651989, acc.: 54.69%] [G loss: 1.184682]\n",
      "epoch:14 step:13185 [D loss: 0.577465, acc.: 65.62%] [G loss: 1.331648]\n",
      "epoch:14 step:13186 [D loss: 0.440225, acc.: 92.19%] [G loss: 1.217312]\n",
      "epoch:14 step:13187 [D loss: 0.343636, acc.: 94.53%] [G loss: 1.363174]\n",
      "epoch:14 step:13188 [D loss: 0.427117, acc.: 90.62%] [G loss: 1.041391]\n",
      "epoch:14 step:13189 [D loss: 0.900322, acc.: 47.66%] [G loss: 0.985041]\n",
      "epoch:14 step:13190 [D loss: 0.797178, acc.: 48.44%] [G loss: 0.795528]\n",
      "epoch:14 step:13191 [D loss: 0.715622, acc.: 48.44%] [G loss: 0.642346]\n",
      "epoch:14 step:13192 [D loss: 0.677311, acc.: 54.69%] [G loss: 0.590745]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13193 [D loss: 0.690634, acc.: 54.69%] [G loss: 0.929146]\n",
      "epoch:14 step:13194 [D loss: 0.750552, acc.: 45.31%] [G loss: 0.773401]\n",
      "epoch:14 step:13195 [D loss: 0.633298, acc.: 69.53%] [G loss: 0.847589]\n",
      "epoch:14 step:13196 [D loss: 0.763377, acc.: 47.66%] [G loss: 0.919187]\n",
      "epoch:14 step:13197 [D loss: 0.740539, acc.: 46.88%] [G loss: 0.920628]\n",
      "epoch:14 step:13198 [D loss: 0.564425, acc.: 78.91%] [G loss: 1.013706]\n",
      "epoch:14 step:13199 [D loss: 0.544059, acc.: 78.12%] [G loss: 0.873964]\n",
      "epoch:14 step:13200 [D loss: 0.372575, acc.: 87.50%] [G loss: 0.889332]\n",
      "##############\n",
      "[3.98393404 2.21233075 7.00293902 5.78388405 4.74135387 6.17787947\n",
      " 5.62273081 5.55992561 5.87828337 5.04706297]\n",
      "##########\n",
      "epoch:14 step:13201 [D loss: 0.403366, acc.: 92.19%] [G loss: 0.855927]\n",
      "epoch:14 step:13202 [D loss: 0.463217, acc.: 89.84%] [G loss: 1.064682]\n",
      "epoch:14 step:13203 [D loss: 0.322143, acc.: 90.62%] [G loss: 1.229213]\n",
      "epoch:14 step:13204 [D loss: 0.522617, acc.: 83.59%] [G loss: 1.034419]\n",
      "epoch:14 step:13205 [D loss: 0.503939, acc.: 82.81%] [G loss: 0.917003]\n",
      "epoch:14 step:13206 [D loss: 0.470400, acc.: 85.16%] [G loss: 0.643951]\n",
      "epoch:14 step:13207 [D loss: 0.518373, acc.: 69.53%] [G loss: 0.811315]\n",
      "epoch:14 step:13208 [D loss: 0.509171, acc.: 78.91%] [G loss: 0.631576]\n",
      "epoch:14 step:13209 [D loss: 0.802859, acc.: 43.75%] [G loss: 0.752132]\n",
      "epoch:14 step:13210 [D loss: 0.685427, acc.: 61.72%] [G loss: 0.423466]\n",
      "epoch:14 step:13211 [D loss: 0.630660, acc.: 59.38%] [G loss: 0.673736]\n",
      "epoch:14 step:13212 [D loss: 0.703596, acc.: 54.69%] [G loss: 0.919364]\n",
      "epoch:14 step:13213 [D loss: 1.075313, acc.: 16.41%] [G loss: 0.824915]\n",
      "epoch:14 step:13214 [D loss: 0.684874, acc.: 58.59%] [G loss: 0.980699]\n",
      "epoch:14 step:13215 [D loss: 0.834956, acc.: 29.69%] [G loss: 0.695829]\n",
      "epoch:14 step:13216 [D loss: 0.684111, acc.: 53.91%] [G loss: 1.009284]\n",
      "epoch:14 step:13217 [D loss: 0.759048, acc.: 42.97%] [G loss: 0.963393]\n",
      "epoch:14 step:13218 [D loss: 0.659829, acc.: 60.94%] [G loss: 1.160375]\n",
      "epoch:14 step:13219 [D loss: 0.824361, acc.: 41.41%] [G loss: 0.976806]\n",
      "epoch:14 step:13220 [D loss: 1.347388, acc.: 32.81%] [G loss: 1.449601]\n",
      "epoch:14 step:13221 [D loss: 0.655251, acc.: 58.59%] [G loss: 1.300067]\n",
      "epoch:14 step:13222 [D loss: 0.560324, acc.: 62.50%] [G loss: 2.359873]\n",
      "epoch:14 step:13223 [D loss: 0.430758, acc.: 86.72%] [G loss: 2.329080]\n",
      "epoch:14 step:13224 [D loss: 0.682200, acc.: 64.06%] [G loss: 1.120082]\n",
      "epoch:14 step:13225 [D loss: 0.456706, acc.: 79.69%] [G loss: 1.256509]\n",
      "epoch:14 step:13226 [D loss: 0.620292, acc.: 61.72%] [G loss: 1.237228]\n",
      "epoch:14 step:13227 [D loss: 0.695353, acc.: 53.91%] [G loss: 1.032877]\n",
      "epoch:14 step:13228 [D loss: 0.588715, acc.: 67.97%] [G loss: 0.975724]\n",
      "epoch:14 step:13229 [D loss: 0.765999, acc.: 42.19%] [G loss: 0.903388]\n",
      "epoch:14 step:13230 [D loss: 0.716330, acc.: 59.38%] [G loss: 0.977219]\n",
      "epoch:14 step:13231 [D loss: 0.803811, acc.: 43.75%] [G loss: 0.889293]\n",
      "epoch:14 step:13232 [D loss: 0.719513, acc.: 55.47%] [G loss: 0.815482]\n",
      "epoch:14 step:13233 [D loss: 0.725403, acc.: 50.00%] [G loss: 0.835986]\n",
      "epoch:14 step:13234 [D loss: 0.663923, acc.: 54.69%] [G loss: 0.800447]\n",
      "epoch:14 step:13235 [D loss: 0.549475, acc.: 75.78%] [G loss: 0.839980]\n",
      "epoch:14 step:13236 [D loss: 0.514066, acc.: 74.22%] [G loss: 0.984372]\n",
      "epoch:14 step:13237 [D loss: 0.330149, acc.: 87.50%] [G loss: 1.018345]\n",
      "epoch:14 step:13238 [D loss: 0.787391, acc.: 42.19%] [G loss: 1.047530]\n",
      "epoch:14 step:13239 [D loss: 0.748977, acc.: 59.38%] [G loss: 1.420654]\n",
      "epoch:14 step:13240 [D loss: 0.661831, acc.: 62.50%] [G loss: 0.891851]\n",
      "epoch:14 step:13241 [D loss: 0.680807, acc.: 53.12%] [G loss: 0.917154]\n",
      "epoch:14 step:13242 [D loss: 0.617664, acc.: 67.19%] [G loss: 0.826128]\n",
      "epoch:14 step:13243 [D loss: 0.637662, acc.: 66.41%] [G loss: 0.930072]\n",
      "epoch:14 step:13244 [D loss: 0.599077, acc.: 69.53%] [G loss: 0.950141]\n",
      "epoch:14 step:13245 [D loss: 0.768729, acc.: 39.06%] [G loss: 0.940224]\n",
      "epoch:14 step:13246 [D loss: 0.791944, acc.: 30.47%] [G loss: 0.908317]\n",
      "epoch:14 step:13247 [D loss: 0.685260, acc.: 57.03%] [G loss: 0.903281]\n",
      "epoch:14 step:13248 [D loss: 0.648635, acc.: 57.81%] [G loss: 1.032080]\n",
      "epoch:14 step:13249 [D loss: 0.631233, acc.: 62.50%] [G loss: 0.848257]\n",
      "epoch:14 step:13250 [D loss: 0.663029, acc.: 54.69%] [G loss: 0.890248]\n",
      "epoch:14 step:13251 [D loss: 0.520037, acc.: 82.03%] [G loss: 0.880364]\n",
      "epoch:14 step:13252 [D loss: 0.614125, acc.: 66.41%] [G loss: 0.868713]\n",
      "epoch:14 step:13253 [D loss: 0.603785, acc.: 71.88%] [G loss: 0.719104]\n",
      "epoch:14 step:13254 [D loss: 0.674784, acc.: 57.03%] [G loss: 0.830764]\n",
      "epoch:14 step:13255 [D loss: 0.715470, acc.: 47.66%] [G loss: 0.776353]\n",
      "epoch:14 step:13256 [D loss: 0.657191, acc.: 64.06%] [G loss: 0.767039]\n",
      "epoch:14 step:13257 [D loss: 0.586856, acc.: 67.97%] [G loss: 0.892946]\n",
      "epoch:14 step:13258 [D loss: 0.669663, acc.: 57.03%] [G loss: 0.948130]\n",
      "epoch:14 step:13259 [D loss: 0.659451, acc.: 64.06%] [G loss: 0.777205]\n",
      "epoch:14 step:13260 [D loss: 0.741205, acc.: 40.62%] [G loss: 0.816422]\n",
      "epoch:14 step:13261 [D loss: 0.554051, acc.: 68.75%] [G loss: 0.845717]\n",
      "epoch:14 step:13262 [D loss: 0.620605, acc.: 67.19%] [G loss: 0.627434]\n",
      "epoch:14 step:13263 [D loss: 0.598013, acc.: 62.50%] [G loss: 0.888712]\n",
      "epoch:14 step:13264 [D loss: 0.681496, acc.: 60.16%] [G loss: 0.960678]\n",
      "epoch:14 step:13265 [D loss: 0.697896, acc.: 55.47%] [G loss: 0.913158]\n",
      "epoch:14 step:13266 [D loss: 0.702351, acc.: 56.25%] [G loss: 0.858681]\n",
      "epoch:14 step:13267 [D loss: 0.721950, acc.: 49.22%] [G loss: 0.818871]\n",
      "epoch:14 step:13268 [D loss: 0.422557, acc.: 92.19%] [G loss: 0.844725]\n",
      "epoch:14 step:13269 [D loss: 0.645540, acc.: 64.84%] [G loss: 0.955458]\n",
      "epoch:14 step:13270 [D loss: 0.775494, acc.: 42.97%] [G loss: 0.954182]\n",
      "epoch:14 step:13271 [D loss: 0.732469, acc.: 48.44%] [G loss: 1.039124]\n",
      "epoch:14 step:13272 [D loss: 0.741552, acc.: 54.69%] [G loss: 1.023747]\n",
      "epoch:14 step:13273 [D loss: 0.714542, acc.: 58.59%] [G loss: 0.907904]\n",
      "epoch:14 step:13274 [D loss: 0.591763, acc.: 73.44%] [G loss: 0.977526]\n",
      "epoch:14 step:13275 [D loss: 0.746341, acc.: 46.09%] [G loss: 0.923854]\n",
      "epoch:14 step:13276 [D loss: 0.701833, acc.: 49.22%] [G loss: 0.944730]\n",
      "epoch:14 step:13277 [D loss: 0.656046, acc.: 66.41%] [G loss: 0.992440]\n",
      "epoch:14 step:13278 [D loss: 0.693436, acc.: 62.50%] [G loss: 0.925383]\n",
      "epoch:14 step:13279 [D loss: 0.680328, acc.: 60.94%] [G loss: 0.796507]\n",
      "epoch:14 step:13280 [D loss: 0.724285, acc.: 50.00%] [G loss: 0.876828]\n",
      "epoch:14 step:13281 [D loss: 0.715589, acc.: 49.22%] [G loss: 0.753469]\n",
      "epoch:14 step:13282 [D loss: 0.676777, acc.: 61.72%] [G loss: 0.925923]\n",
      "epoch:14 step:13283 [D loss: 0.669131, acc.: 60.94%] [G loss: 0.814171]\n",
      "epoch:14 step:13284 [D loss: 0.651353, acc.: 60.16%] [G loss: 0.841202]\n",
      "epoch:14 step:13285 [D loss: 0.610352, acc.: 63.28%] [G loss: 0.935094]\n",
      "epoch:14 step:13286 [D loss: 0.599946, acc.: 69.53%] [G loss: 0.864624]\n",
      "epoch:14 step:13287 [D loss: 0.601077, acc.: 61.72%] [G loss: 0.806254]\n",
      "epoch:14 step:13288 [D loss: 0.707984, acc.: 53.91%] [G loss: 0.935876]\n",
      "epoch:14 step:13289 [D loss: 0.686406, acc.: 55.47%] [G loss: 0.906566]\n",
      "epoch:14 step:13290 [D loss: 0.656241, acc.: 64.84%] [G loss: 0.872904]\n",
      "epoch:14 step:13291 [D loss: 0.673389, acc.: 59.38%] [G loss: 0.868469]\n",
      "epoch:14 step:13292 [D loss: 0.666495, acc.: 63.28%] [G loss: 0.838968]\n",
      "epoch:14 step:13293 [D loss: 0.637920, acc.: 65.62%] [G loss: 0.830760]\n",
      "epoch:14 step:13294 [D loss: 0.604445, acc.: 74.22%] [G loss: 0.803299]\n",
      "epoch:14 step:13295 [D loss: 0.690082, acc.: 54.69%] [G loss: 0.904071]\n",
      "epoch:14 step:13296 [D loss: 0.719258, acc.: 48.44%] [G loss: 0.832694]\n",
      "epoch:14 step:13297 [D loss: 0.707003, acc.: 55.47%] [G loss: 0.810011]\n",
      "epoch:14 step:13298 [D loss: 0.648806, acc.: 65.62%] [G loss: 0.815949]\n",
      "epoch:14 step:13299 [D loss: 0.603110, acc.: 71.09%] [G loss: 0.797816]\n",
      "epoch:14 step:13300 [D loss: 0.623613, acc.: 68.75%] [G loss: 0.920707]\n",
      "epoch:14 step:13301 [D loss: 0.628161, acc.: 65.62%] [G loss: 0.827196]\n",
      "epoch:14 step:13302 [D loss: 0.601745, acc.: 67.19%] [G loss: 0.859986]\n",
      "epoch:14 step:13303 [D loss: 0.647840, acc.: 61.72%] [G loss: 0.845856]\n",
      "epoch:14 step:13304 [D loss: 0.699032, acc.: 55.47%] [G loss: 0.821370]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13305 [D loss: 0.769836, acc.: 42.19%] [G loss: 0.842994]\n",
      "epoch:14 step:13306 [D loss: 0.604732, acc.: 70.31%] [G loss: 0.892661]\n",
      "epoch:14 step:13307 [D loss: 0.627682, acc.: 67.19%] [G loss: 0.912879]\n",
      "epoch:14 step:13308 [D loss: 0.647663, acc.: 64.06%] [G loss: 0.769042]\n",
      "epoch:14 step:13309 [D loss: 0.584250, acc.: 72.66%] [G loss: 0.824991]\n",
      "epoch:14 step:13310 [D loss: 0.453594, acc.: 91.41%] [G loss: 0.864656]\n",
      "epoch:14 step:13311 [D loss: 0.622210, acc.: 67.19%] [G loss: 0.795179]\n",
      "epoch:14 step:13312 [D loss: 0.492873, acc.: 83.59%] [G loss: 1.011787]\n",
      "epoch:14 step:13313 [D loss: 0.505670, acc.: 84.38%] [G loss: 0.832010]\n",
      "epoch:14 step:13314 [D loss: 0.565041, acc.: 76.56%] [G loss: 0.709313]\n",
      "epoch:14 step:13315 [D loss: 0.527260, acc.: 77.34%] [G loss: 1.002758]\n",
      "epoch:14 step:13316 [D loss: 0.553285, acc.: 80.47%] [G loss: 0.700948]\n",
      "epoch:14 step:13317 [D loss: 0.712345, acc.: 52.34%] [G loss: 1.279388]\n",
      "epoch:14 step:13318 [D loss: 0.823933, acc.: 45.31%] [G loss: 1.008862]\n",
      "epoch:14 step:13319 [D loss: 0.430141, acc.: 90.62%] [G loss: 0.814540]\n",
      "epoch:14 step:13320 [D loss: 0.751566, acc.: 42.97%] [G loss: 0.864595]\n",
      "epoch:14 step:13321 [D loss: 0.418246, acc.: 93.75%] [G loss: 0.845771]\n",
      "epoch:14 step:13322 [D loss: 0.429463, acc.: 83.59%] [G loss: 1.209029]\n",
      "epoch:14 step:13323 [D loss: 0.528380, acc.: 76.56%] [G loss: 0.894906]\n",
      "epoch:14 step:13324 [D loss: 0.424450, acc.: 89.84%] [G loss: 1.013412]\n",
      "epoch:14 step:13325 [D loss: 0.340982, acc.: 82.81%] [G loss: 1.114713]\n",
      "epoch:14 step:13326 [D loss: 0.409124, acc.: 90.62%] [G loss: 1.404699]\n",
      "epoch:14 step:13327 [D loss: 0.427281, acc.: 84.38%] [G loss: 1.213778]\n",
      "epoch:14 step:13328 [D loss: 0.862533, acc.: 43.75%] [G loss: 0.704733]\n",
      "epoch:14 step:13329 [D loss: 1.089268, acc.: 17.19%] [G loss: 1.129079]\n",
      "epoch:14 step:13330 [D loss: 0.792091, acc.: 47.66%] [G loss: 1.276775]\n",
      "epoch:14 step:13331 [D loss: 0.820748, acc.: 34.38%] [G loss: 0.814879]\n",
      "epoch:14 step:13332 [D loss: 0.865217, acc.: 39.84%] [G loss: 0.735397]\n",
      "epoch:14 step:13333 [D loss: 0.773202, acc.: 39.84%] [G loss: 0.808117]\n",
      "epoch:14 step:13334 [D loss: 0.711582, acc.: 58.59%] [G loss: 0.819632]\n",
      "epoch:14 step:13335 [D loss: 0.666815, acc.: 60.94%] [G loss: 0.716072]\n",
      "epoch:14 step:13336 [D loss: 0.519216, acc.: 76.56%] [G loss: 0.823081]\n",
      "epoch:14 step:13337 [D loss: 0.495595, acc.: 83.59%] [G loss: 0.694239]\n",
      "epoch:14 step:13338 [D loss: 0.449677, acc.: 76.56%] [G loss: 0.772900]\n",
      "epoch:14 step:13339 [D loss: 0.384169, acc.: 89.06%] [G loss: 1.032916]\n",
      "epoch:14 step:13340 [D loss: 0.449075, acc.: 77.34%] [G loss: 0.788759]\n",
      "epoch:14 step:13341 [D loss: 0.671166, acc.: 58.59%] [G loss: 1.042922]\n",
      "epoch:14 step:13342 [D loss: 0.777196, acc.: 42.19%] [G loss: 1.029487]\n",
      "epoch:14 step:13343 [D loss: 0.632331, acc.: 64.06%] [G loss: 0.877264]\n",
      "epoch:14 step:13344 [D loss: 0.749469, acc.: 48.44%] [G loss: 0.992869]\n",
      "epoch:14 step:13345 [D loss: 0.699646, acc.: 51.56%] [G loss: 0.826195]\n",
      "epoch:14 step:13346 [D loss: 0.687497, acc.: 49.22%] [G loss: 0.765829]\n",
      "epoch:14 step:13347 [D loss: 0.666712, acc.: 57.03%] [G loss: 1.000151]\n",
      "epoch:14 step:13348 [D loss: 0.463410, acc.: 71.88%] [G loss: 1.168334]\n",
      "epoch:14 step:13349 [D loss: 0.416170, acc.: 85.16%] [G loss: 0.962857]\n",
      "epoch:14 step:13350 [D loss: 0.381891, acc.: 82.03%] [G loss: 1.165653]\n",
      "epoch:14 step:13351 [D loss: 0.709499, acc.: 55.47%] [G loss: 1.180398]\n",
      "epoch:14 step:13352 [D loss: 0.472757, acc.: 80.47%] [G loss: 1.154868]\n",
      "epoch:14 step:13353 [D loss: 0.242452, acc.: 94.53%] [G loss: 1.326466]\n",
      "epoch:14 step:13354 [D loss: 0.591461, acc.: 69.53%] [G loss: 1.538150]\n",
      "epoch:14 step:13355 [D loss: 0.407004, acc.: 92.97%] [G loss: 1.124327]\n",
      "epoch:14 step:13356 [D loss: 0.282061, acc.: 86.72%] [G loss: 1.559881]\n",
      "epoch:14 step:13357 [D loss: 0.614189, acc.: 65.62%] [G loss: 1.414071]\n",
      "epoch:14 step:13358 [D loss: 0.538998, acc.: 72.66%] [G loss: 1.560867]\n",
      "epoch:14 step:13359 [D loss: 0.783470, acc.: 42.97%] [G loss: 1.178460]\n",
      "epoch:14 step:13360 [D loss: 0.555292, acc.: 73.44%] [G loss: 0.947284]\n",
      "epoch:14 step:13361 [D loss: 0.418884, acc.: 87.50%] [G loss: 0.782857]\n",
      "epoch:14 step:13362 [D loss: 0.574576, acc.: 68.75%] [G loss: 1.539448]\n",
      "epoch:14 step:13363 [D loss: 0.788690, acc.: 42.19%] [G loss: 0.957036]\n",
      "epoch:14 step:13364 [D loss: 0.615311, acc.: 67.19%] [G loss: 1.360306]\n",
      "epoch:14 step:13365 [D loss: 0.973592, acc.: 29.69%] [G loss: 0.683931]\n",
      "epoch:14 step:13366 [D loss: 0.778826, acc.: 42.19%] [G loss: 1.129256]\n",
      "epoch:14 step:13367 [D loss: 0.571411, acc.: 67.97%] [G loss: 0.758240]\n",
      "epoch:14 step:13368 [D loss: 0.780780, acc.: 39.06%] [G loss: 0.791417]\n",
      "epoch:14 step:13369 [D loss: 0.702746, acc.: 57.03%] [G loss: 0.271437]\n",
      "epoch:14 step:13370 [D loss: 0.697186, acc.: 54.69%] [G loss: 0.892597]\n",
      "epoch:14 step:13371 [D loss: 0.544037, acc.: 75.78%] [G loss: 0.857016]\n",
      "epoch:14 step:13372 [D loss: 0.459395, acc.: 81.25%] [G loss: 0.868276]\n",
      "epoch:14 step:13373 [D loss: 0.762621, acc.: 53.12%] [G loss: 1.079267]\n",
      "epoch:14 step:13374 [D loss: 0.244477, acc.: 94.53%] [G loss: 1.015744]\n",
      "epoch:14 step:13375 [D loss: 0.407068, acc.: 92.19%] [G loss: 1.112060]\n",
      "epoch:14 step:13376 [D loss: 0.781664, acc.: 46.09%] [G loss: 0.854642]\n",
      "epoch:14 step:13377 [D loss: 0.334384, acc.: 84.38%] [G loss: 1.041907]\n",
      "epoch:14 step:13378 [D loss: 0.409894, acc.: 93.75%] [G loss: 1.126482]\n",
      "epoch:14 step:13379 [D loss: 0.274038, acc.: 92.19%] [G loss: 1.096018]\n",
      "epoch:14 step:13380 [D loss: 0.764544, acc.: 44.53%] [G loss: 1.144568]\n",
      "epoch:14 step:13381 [D loss: 1.182662, acc.: 35.94%] [G loss: 1.024111]\n",
      "epoch:14 step:13382 [D loss: 0.868423, acc.: 29.69%] [G loss: 0.258413]\n",
      "epoch:14 step:13383 [D loss: 0.550841, acc.: 76.56%] [G loss: 1.255276]\n",
      "epoch:14 step:13384 [D loss: 0.748670, acc.: 47.66%] [G loss: 1.167319]\n",
      "epoch:14 step:13385 [D loss: 0.688758, acc.: 53.12%] [G loss: 1.092011]\n",
      "epoch:14 step:13386 [D loss: 0.702102, acc.: 49.22%] [G loss: 1.059798]\n",
      "epoch:14 step:13387 [D loss: 0.609559, acc.: 60.94%] [G loss: 0.559966]\n",
      "epoch:14 step:13388 [D loss: 0.998585, acc.: 21.09%] [G loss: 1.064440]\n",
      "epoch:14 step:13389 [D loss: 0.535607, acc.: 66.41%] [G loss: 1.344336]\n",
      "epoch:14 step:13390 [D loss: 0.540042, acc.: 73.44%] [G loss: 1.203239]\n",
      "epoch:14 step:13391 [D loss: 0.491207, acc.: 75.78%] [G loss: 1.269771]\n",
      "epoch:14 step:13392 [D loss: 0.500385, acc.: 77.34%] [G loss: 1.421384]\n",
      "epoch:14 step:13393 [D loss: 0.515592, acc.: 70.31%] [G loss: 1.360752]\n",
      "epoch:14 step:13394 [D loss: 0.467297, acc.: 76.56%] [G loss: 1.333093]\n",
      "epoch:14 step:13395 [D loss: 0.509839, acc.: 69.53%] [G loss: 1.767468]\n",
      "epoch:14 step:13396 [D loss: 0.903331, acc.: 42.19%] [G loss: 0.996953]\n",
      "epoch:14 step:13397 [D loss: 0.867135, acc.: 46.88%] [G loss: 1.004148]\n",
      "epoch:14 step:13398 [D loss: 0.587154, acc.: 65.62%] [G loss: 0.938653]\n",
      "epoch:14 step:13399 [D loss: 0.466843, acc.: 87.50%] [G loss: 1.067431]\n",
      "epoch:14 step:13400 [D loss: 0.617221, acc.: 64.84%] [G loss: 1.296030]\n",
      "##############\n",
      "[4.13265669 3.18345775 6.912225   6.26385587 5.00002072 6.18676812\n",
      " 5.14266696 5.89504631 5.84658745 4.97183286]\n",
      "##########\n",
      "epoch:14 step:13401 [D loss: 0.637329, acc.: 64.06%] [G loss: 1.089855]\n",
      "epoch:14 step:13402 [D loss: 0.700032, acc.: 59.38%] [G loss: 1.347183]\n",
      "epoch:14 step:13403 [D loss: 0.616470, acc.: 60.16%] [G loss: 0.841769]\n",
      "epoch:14 step:13404 [D loss: 0.746225, acc.: 50.78%] [G loss: 0.753936]\n",
      "epoch:14 step:13405 [D loss: 0.800551, acc.: 37.50%] [G loss: 0.724941]\n",
      "epoch:14 step:13406 [D loss: 0.772262, acc.: 40.62%] [G loss: 0.798310]\n",
      "epoch:14 step:13407 [D loss: 0.760288, acc.: 43.75%] [G loss: 0.846195]\n",
      "epoch:14 step:13408 [D loss: 0.777088, acc.: 32.81%] [G loss: 0.774239]\n",
      "epoch:14 step:13409 [D loss: 0.757392, acc.: 36.72%] [G loss: 0.718003]\n",
      "epoch:14 step:13410 [D loss: 0.651238, acc.: 60.94%] [G loss: 0.772407]\n",
      "epoch:14 step:13411 [D loss: 0.716087, acc.: 50.78%] [G loss: 0.772567]\n",
      "epoch:14 step:13412 [D loss: 0.706090, acc.: 47.66%] [G loss: 0.743333]\n",
      "epoch:14 step:13413 [D loss: 0.644478, acc.: 60.16%] [G loss: 0.674915]\n",
      "epoch:14 step:13414 [D loss: 0.656718, acc.: 57.81%] [G loss: 0.792049]\n",
      "epoch:14 step:13415 [D loss: 0.537048, acc.: 82.81%] [G loss: 0.794059]\n",
      "epoch:14 step:13416 [D loss: 0.598262, acc.: 67.97%] [G loss: 0.785538]\n",
      "epoch:14 step:13417 [D loss: 0.534662, acc.: 87.50%] [G loss: 0.825555]\n",
      "epoch:14 step:13418 [D loss: 0.559454, acc.: 82.81%] [G loss: 0.959149]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13419 [D loss: 0.643018, acc.: 62.50%] [G loss: 0.922844]\n",
      "epoch:14 step:13420 [D loss: 0.708185, acc.: 47.66%] [G loss: 0.655870]\n",
      "epoch:14 step:13421 [D loss: 0.599154, acc.: 74.22%] [G loss: 0.724400]\n",
      "epoch:14 step:13422 [D loss: 0.679706, acc.: 58.59%] [G loss: 0.819073]\n",
      "epoch:14 step:13423 [D loss: 0.742267, acc.: 43.75%] [G loss: 0.724397]\n",
      "epoch:14 step:13424 [D loss: 0.677258, acc.: 57.81%] [G loss: 0.865305]\n",
      "epoch:14 step:13425 [D loss: 0.712313, acc.: 45.31%] [G loss: 0.760566]\n",
      "epoch:14 step:13426 [D loss: 0.688081, acc.: 57.03%] [G loss: 0.748065]\n",
      "epoch:14 step:13427 [D loss: 0.695162, acc.: 53.91%] [G loss: 0.857169]\n",
      "epoch:14 step:13428 [D loss: 0.697665, acc.: 46.88%] [G loss: 0.825631]\n",
      "epoch:14 step:13429 [D loss: 0.727216, acc.: 49.22%] [G loss: 0.783177]\n",
      "epoch:14 step:13430 [D loss: 0.647406, acc.: 60.94%] [G loss: 0.682082]\n",
      "epoch:14 step:13431 [D loss: 0.562179, acc.: 68.75%] [G loss: 0.922994]\n",
      "epoch:14 step:13432 [D loss: 0.531298, acc.: 71.88%] [G loss: 0.789422]\n",
      "epoch:14 step:13433 [D loss: 0.648059, acc.: 66.41%] [G loss: 0.852301]\n",
      "epoch:14 step:13434 [D loss: 0.719526, acc.: 50.00%] [G loss: 0.691461]\n",
      "epoch:14 step:13435 [D loss: 0.698211, acc.: 53.12%] [G loss: 0.820532]\n",
      "epoch:14 step:13436 [D loss: 0.623571, acc.: 72.66%] [G loss: 0.847512]\n",
      "epoch:14 step:13437 [D loss: 0.639446, acc.: 67.97%] [G loss: 0.872844]\n",
      "epoch:14 step:13438 [D loss: 0.650189, acc.: 64.84%] [G loss: 0.639332]\n",
      "epoch:14 step:13439 [D loss: 0.832169, acc.: 38.28%] [G loss: 0.665777]\n",
      "epoch:14 step:13440 [D loss: 0.669443, acc.: 56.25%] [G loss: 0.740096]\n",
      "epoch:14 step:13441 [D loss: 0.682654, acc.: 46.88%] [G loss: 0.796899]\n",
      "epoch:14 step:13442 [D loss: 0.678916, acc.: 61.72%] [G loss: 0.781187]\n",
      "epoch:14 step:13443 [D loss: 0.620131, acc.: 71.88%] [G loss: 0.736990]\n",
      "epoch:14 step:13444 [D loss: 0.694736, acc.: 52.34%] [G loss: 0.744453]\n",
      "epoch:14 step:13445 [D loss: 0.557438, acc.: 77.34%] [G loss: 0.721664]\n",
      "epoch:14 step:13446 [D loss: 0.626605, acc.: 67.19%] [G loss: 0.801184]\n",
      "epoch:14 step:13447 [D loss: 0.693417, acc.: 51.56%] [G loss: 0.874302]\n",
      "epoch:14 step:13448 [D loss: 0.737238, acc.: 38.28%] [G loss: 0.759949]\n",
      "epoch:14 step:13449 [D loss: 0.674757, acc.: 60.94%] [G loss: 0.828668]\n",
      "epoch:14 step:13450 [D loss: 0.694651, acc.: 53.12%] [G loss: 0.834520]\n",
      "epoch:14 step:13451 [D loss: 0.491829, acc.: 81.25%] [G loss: 0.838772]\n",
      "epoch:14 step:13452 [D loss: 0.566280, acc.: 70.31%] [G loss: 0.850800]\n",
      "epoch:14 step:13453 [D loss: 0.607147, acc.: 70.31%] [G loss: 0.700894]\n",
      "epoch:14 step:13454 [D loss: 0.449841, acc.: 78.91%] [G loss: 0.815012]\n",
      "epoch:14 step:13455 [D loss: 0.583902, acc.: 67.97%] [G loss: 0.817731]\n",
      "epoch:14 step:13456 [D loss: 0.638712, acc.: 62.50%] [G loss: 0.870678]\n",
      "epoch:14 step:13457 [D loss: 0.695775, acc.: 55.47%] [G loss: 0.888120]\n",
      "epoch:14 step:13458 [D loss: 0.727125, acc.: 48.44%] [G loss: 0.806979]\n",
      "epoch:14 step:13459 [D loss: 0.702262, acc.: 56.25%] [G loss: 0.843970]\n",
      "epoch:14 step:13460 [D loss: 0.518425, acc.: 73.44%] [G loss: 0.876831]\n",
      "epoch:14 step:13461 [D loss: 0.339460, acc.: 89.84%] [G loss: 0.995485]\n",
      "epoch:14 step:13462 [D loss: 0.380648, acc.: 92.19%] [G loss: 0.961004]\n",
      "epoch:14 step:13463 [D loss: 0.283054, acc.: 92.19%] [G loss: 1.064958]\n",
      "epoch:14 step:13464 [D loss: 0.255870, acc.: 97.66%] [G loss: 1.135135]\n",
      "epoch:14 step:13465 [D loss: 0.209772, acc.: 99.22%] [G loss: 1.166719]\n",
      "epoch:14 step:13466 [D loss: 0.765852, acc.: 45.31%] [G loss: 0.993253]\n",
      "epoch:14 step:13467 [D loss: 0.831245, acc.: 39.06%] [G loss: 1.112832]\n",
      "epoch:14 step:13468 [D loss: 0.555802, acc.: 74.22%] [G loss: 1.068752]\n",
      "epoch:14 step:13469 [D loss: 0.743873, acc.: 46.09%] [G loss: 1.098370]\n",
      "epoch:14 step:13470 [D loss: 0.723053, acc.: 48.44%] [G loss: 1.005395]\n",
      "epoch:14 step:13471 [D loss: 0.835635, acc.: 33.59%] [G loss: 1.071703]\n",
      "epoch:14 step:13472 [D loss: 0.682567, acc.: 55.47%] [G loss: 1.072402]\n",
      "epoch:14 step:13473 [D loss: 0.644810, acc.: 55.47%] [G loss: 1.066095]\n",
      "epoch:14 step:13474 [D loss: 0.718786, acc.: 54.69%] [G loss: 0.978734]\n",
      "epoch:14 step:13475 [D loss: 0.681418, acc.: 57.03%] [G loss: 0.984751]\n",
      "epoch:14 step:13476 [D loss: 0.665365, acc.: 55.47%] [G loss: 1.044243]\n",
      "epoch:14 step:13477 [D loss: 0.693069, acc.: 54.69%] [G loss: 0.949428]\n",
      "epoch:14 step:13478 [D loss: 0.831615, acc.: 30.47%] [G loss: 0.906986]\n",
      "epoch:14 step:13479 [D loss: 0.686275, acc.: 59.38%] [G loss: 0.927845]\n",
      "epoch:14 step:13480 [D loss: 0.615227, acc.: 71.88%] [G loss: 0.938854]\n",
      "epoch:14 step:13481 [D loss: 0.542340, acc.: 76.56%] [G loss: 0.860529]\n",
      "epoch:14 step:13482 [D loss: 0.586414, acc.: 70.31%] [G loss: 0.876703]\n",
      "epoch:14 step:13483 [D loss: 0.521908, acc.: 83.59%] [G loss: 0.767130]\n",
      "epoch:14 step:13484 [D loss: 0.317859, acc.: 92.97%] [G loss: 0.821349]\n",
      "epoch:14 step:13485 [D loss: 0.624390, acc.: 61.72%] [G loss: 0.927493]\n",
      "epoch:14 step:13486 [D loss: 0.667897, acc.: 66.41%] [G loss: 0.860543]\n",
      "epoch:14 step:13487 [D loss: 0.715350, acc.: 53.12%] [G loss: 0.889509]\n",
      "epoch:14 step:13488 [D loss: 0.821544, acc.: 29.69%] [G loss: 0.923520]\n",
      "epoch:14 step:13489 [D loss: 0.591763, acc.: 74.22%] [G loss: 0.941490]\n",
      "epoch:14 step:13490 [D loss: 0.638654, acc.: 62.50%] [G loss: 0.942113]\n",
      "epoch:14 step:13491 [D loss: 0.756481, acc.: 40.62%] [G loss: 0.899978]\n",
      "epoch:14 step:13492 [D loss: 0.699581, acc.: 50.78%] [G loss: 0.890094]\n",
      "epoch:14 step:13493 [D loss: 0.667451, acc.: 66.41%] [G loss: 0.893920]\n",
      "epoch:14 step:13494 [D loss: 0.694263, acc.: 54.69%] [G loss: 0.880389]\n",
      "epoch:14 step:13495 [D loss: 0.324002, acc.: 92.97%] [G loss: 0.947711]\n",
      "epoch:14 step:13496 [D loss: 0.366232, acc.: 95.31%] [G loss: 0.825994]\n",
      "epoch:14 step:13497 [D loss: 0.653497, acc.: 59.38%] [G loss: 0.888318]\n",
      "epoch:14 step:13498 [D loss: 0.635121, acc.: 62.50%] [G loss: 0.894286]\n",
      "epoch:14 step:13499 [D loss: 0.600839, acc.: 70.31%] [G loss: 0.927868]\n",
      "epoch:14 step:13500 [D loss: 0.758061, acc.: 41.41%] [G loss: 0.925223]\n",
      "epoch:14 step:13501 [D loss: 0.685660, acc.: 58.59%] [G loss: 0.707306]\n",
      "epoch:14 step:13502 [D loss: 0.591953, acc.: 76.56%] [G loss: 0.800289]\n",
      "epoch:14 step:13503 [D loss: 0.655890, acc.: 57.03%] [G loss: 0.930117]\n",
      "epoch:14 step:13504 [D loss: 0.739688, acc.: 52.34%] [G loss: 0.658258]\n",
      "epoch:14 step:13505 [D loss: 1.194643, acc.: 25.78%] [G loss: 0.804482]\n",
      "epoch:14 step:13506 [D loss: 0.731847, acc.: 46.09%] [G loss: 0.888653]\n",
      "epoch:14 step:13507 [D loss: 0.592816, acc.: 74.22%] [G loss: 0.484713]\n",
      "epoch:14 step:13508 [D loss: 0.661764, acc.: 64.06%] [G loss: 0.702328]\n",
      "epoch:14 step:13509 [D loss: 0.738384, acc.: 42.19%] [G loss: 0.928133]\n",
      "epoch:14 step:13510 [D loss: 0.701194, acc.: 53.91%] [G loss: 0.898247]\n",
      "epoch:14 step:13511 [D loss: 0.648256, acc.: 64.06%] [G loss: 0.829092]\n",
      "epoch:14 step:13512 [D loss: 0.709173, acc.: 48.44%] [G loss: 0.625735]\n",
      "epoch:14 step:13513 [D loss: 0.721927, acc.: 49.22%] [G loss: 0.967631]\n",
      "epoch:14 step:13514 [D loss: 0.588266, acc.: 59.38%] [G loss: 0.777875]\n",
      "epoch:14 step:13515 [D loss: 0.355836, acc.: 90.62%] [G loss: 1.035429]\n",
      "epoch:14 step:13516 [D loss: 0.275302, acc.: 96.88%] [G loss: 1.046483]\n",
      "epoch:14 step:13517 [D loss: 0.377995, acc.: 96.88%] [G loss: 1.191279]\n",
      "epoch:14 step:13518 [D loss: 0.334490, acc.: 95.31%] [G loss: 0.756242]\n",
      "epoch:14 step:13519 [D loss: 0.526265, acc.: 79.69%] [G loss: 0.764344]\n",
      "epoch:14 step:13520 [D loss: 0.241764, acc.: 98.44%] [G loss: 0.860597]\n",
      "epoch:14 step:13521 [D loss: 0.546990, acc.: 73.44%] [G loss: 0.923325]\n",
      "epoch:14 step:13522 [D loss: 1.114641, acc.: 53.12%] [G loss: 1.304657]\n",
      "epoch:14 step:13523 [D loss: 0.674223, acc.: 57.81%] [G loss: 1.507112]\n",
      "epoch:14 step:13524 [D loss: 0.720009, acc.: 52.34%] [G loss: 1.304164]\n",
      "epoch:14 step:13525 [D loss: 0.512873, acc.: 82.03%] [G loss: 1.058795]\n",
      "epoch:14 step:13526 [D loss: 0.742843, acc.: 52.34%] [G loss: 1.195530]\n",
      "epoch:14 step:13527 [D loss: 0.507859, acc.: 81.25%] [G loss: 1.036185]\n",
      "epoch:14 step:13528 [D loss: 0.639949, acc.: 58.59%] [G loss: 1.039024]\n",
      "epoch:14 step:13529 [D loss: 1.301156, acc.: 7.03%] [G loss: 0.599891]\n",
      "epoch:14 step:13530 [D loss: 0.807875, acc.: 41.41%] [G loss: 1.008200]\n",
      "epoch:14 step:13531 [D loss: 0.664201, acc.: 57.03%] [G loss: 0.703610]\n",
      "epoch:14 step:13532 [D loss: 0.773493, acc.: 42.97%] [G loss: 0.916160]\n",
      "epoch:14 step:13533 [D loss: 0.785546, acc.: 37.50%] [G loss: 0.795575]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13534 [D loss: 0.803523, acc.: 36.72%] [G loss: 0.925979]\n",
      "epoch:14 step:13535 [D loss: 0.698580, acc.: 55.47%] [G loss: 0.874578]\n",
      "epoch:14 step:13536 [D loss: 0.690091, acc.: 55.47%] [G loss: 0.703843]\n",
      "epoch:14 step:13537 [D loss: 0.786628, acc.: 50.00%] [G loss: 0.838043]\n",
      "epoch:14 step:13538 [D loss: 0.802245, acc.: 34.38%] [G loss: 0.909267]\n",
      "epoch:14 step:13539 [D loss: 0.792415, acc.: 37.50%] [G loss: 0.909125]\n",
      "epoch:14 step:13540 [D loss: 0.724116, acc.: 46.09%] [G loss: 0.949061]\n",
      "epoch:14 step:13541 [D loss: 0.750809, acc.: 44.53%] [G loss: 0.943701]\n",
      "epoch:14 step:13542 [D loss: 0.689724, acc.: 53.91%] [G loss: 0.958161]\n",
      "epoch:14 step:13543 [D loss: 0.685501, acc.: 60.16%] [G loss: 0.907874]\n",
      "epoch:14 step:13544 [D loss: 0.703400, acc.: 42.97%] [G loss: 0.914726]\n",
      "epoch:14 step:13545 [D loss: 0.701786, acc.: 53.12%] [G loss: 0.772198]\n",
      "epoch:14 step:13546 [D loss: 0.628586, acc.: 64.06%] [G loss: 0.879050]\n",
      "epoch:14 step:13547 [D loss: 0.722723, acc.: 46.88%] [G loss: 0.933852]\n",
      "epoch:14 step:13548 [D loss: 0.660230, acc.: 57.81%] [G loss: 0.918141]\n",
      "epoch:14 step:13549 [D loss: 0.708881, acc.: 51.56%] [G loss: 0.911558]\n",
      "epoch:14 step:13550 [D loss: 0.617746, acc.: 69.53%] [G loss: 1.038580]\n",
      "epoch:14 step:13551 [D loss: 0.571435, acc.: 76.56%] [G loss: 0.983788]\n",
      "epoch:14 step:13552 [D loss: 0.605166, acc.: 69.53%] [G loss: 1.054149]\n",
      "epoch:14 step:13553 [D loss: 0.583244, acc.: 62.50%] [G loss: 0.956318]\n",
      "epoch:14 step:13554 [D loss: 0.588810, acc.: 70.31%] [G loss: 0.931363]\n",
      "epoch:14 step:13555 [D loss: 0.657836, acc.: 52.34%] [G loss: 0.902857]\n",
      "epoch:14 step:13556 [D loss: 0.727955, acc.: 48.44%] [G loss: 0.914500]\n",
      "epoch:14 step:13557 [D loss: 0.687843, acc.: 51.56%] [G loss: 0.938557]\n",
      "epoch:14 step:13558 [D loss: 0.723131, acc.: 50.00%] [G loss: 0.968662]\n",
      "epoch:14 step:13559 [D loss: 0.616340, acc.: 71.09%] [G loss: 0.805313]\n",
      "epoch:14 step:13560 [D loss: 0.679797, acc.: 55.47%] [G loss: 0.982784]\n",
      "epoch:14 step:13561 [D loss: 0.576375, acc.: 82.03%] [G loss: 1.550632]\n",
      "epoch:14 step:13562 [D loss: 0.606651, acc.: 65.62%] [G loss: 0.896876]\n",
      "epoch:14 step:13563 [D loss: 0.641889, acc.: 57.81%] [G loss: 0.950047]\n",
      "epoch:14 step:13564 [D loss: 0.642773, acc.: 60.16%] [G loss: 0.944045]\n",
      "epoch:14 step:13565 [D loss: 0.656147, acc.: 61.72%] [G loss: 0.933136]\n",
      "epoch:14 step:13566 [D loss: 0.516101, acc.: 88.28%] [G loss: 1.048548]\n",
      "epoch:14 step:13567 [D loss: 0.431751, acc.: 95.31%] [G loss: 1.083968]\n",
      "epoch:14 step:13568 [D loss: 0.514304, acc.: 88.28%] [G loss: 0.878521]\n",
      "epoch:14 step:13569 [D loss: 0.381487, acc.: 94.53%] [G loss: 0.994768]\n",
      "epoch:14 step:13570 [D loss: 0.419696, acc.: 89.06%] [G loss: 1.380194]\n",
      "epoch:14 step:13571 [D loss: 0.336247, acc.: 98.44%] [G loss: 1.429391]\n",
      "epoch:14 step:13572 [D loss: 0.439891, acc.: 86.72%] [G loss: 1.393735]\n",
      "epoch:14 step:13573 [D loss: 0.426420, acc.: 87.50%] [G loss: 1.203450]\n",
      "epoch:14 step:13574 [D loss: 0.169768, acc.: 99.22%] [G loss: 1.495170]\n",
      "epoch:14 step:13575 [D loss: 0.304450, acc.: 97.66%] [G loss: 1.108295]\n",
      "epoch:14 step:13576 [D loss: 0.896194, acc.: 28.12%] [G loss: 1.024344]\n",
      "epoch:14 step:13577 [D loss: 0.660657, acc.: 57.81%] [G loss: 1.115771]\n",
      "epoch:14 step:13578 [D loss: 0.665113, acc.: 61.72%] [G loss: 1.153917]\n",
      "epoch:14 step:13579 [D loss: 0.955711, acc.: 31.25%] [G loss: 0.798021]\n",
      "epoch:14 step:13580 [D loss: 1.182634, acc.: 16.41%] [G loss: 0.966729]\n",
      "epoch:14 step:13581 [D loss: 0.916462, acc.: 23.44%] [G loss: 0.656459]\n",
      "epoch:14 step:13582 [D loss: 0.628492, acc.: 64.84%] [G loss: 0.788217]\n",
      "epoch:14 step:13583 [D loss: 0.583230, acc.: 67.19%] [G loss: 0.831448]\n",
      "epoch:14 step:13584 [D loss: 0.688994, acc.: 54.69%] [G loss: 0.608843]\n",
      "epoch:14 step:13585 [D loss: 0.521075, acc.: 70.31%] [G loss: 0.853871]\n",
      "epoch:14 step:13586 [D loss: 0.384644, acc.: 81.25%] [G loss: 0.715030]\n",
      "epoch:14 step:13587 [D loss: 0.577879, acc.: 63.28%] [G loss: 1.124028]\n",
      "epoch:14 step:13588 [D loss: 0.361525, acc.: 88.28%] [G loss: 1.076767]\n",
      "epoch:14 step:13589 [D loss: 0.392878, acc.: 89.06%] [G loss: 0.930837]\n",
      "epoch:14 step:13590 [D loss: 0.485148, acc.: 81.25%] [G loss: 1.106388]\n",
      "epoch:14 step:13591 [D loss: 0.978213, acc.: 37.50%] [G loss: 0.902705]\n",
      "epoch:14 step:13592 [D loss: 0.861106, acc.: 37.50%] [G loss: 0.850767]\n",
      "epoch:14 step:13593 [D loss: 0.781816, acc.: 39.06%] [G loss: 0.926835]\n",
      "epoch:14 step:13594 [D loss: 0.675392, acc.: 56.25%] [G loss: 0.605512]\n",
      "epoch:14 step:13595 [D loss: 0.713335, acc.: 55.47%] [G loss: 0.838127]\n",
      "epoch:14 step:13596 [D loss: 0.867839, acc.: 31.25%] [G loss: 0.585421]\n",
      "epoch:14 step:13597 [D loss: 0.687246, acc.: 57.03%] [G loss: 0.547141]\n",
      "epoch:14 step:13598 [D loss: 0.885947, acc.: 52.34%] [G loss: 0.810278]\n",
      "epoch:14 step:13599 [D loss: 0.527020, acc.: 75.00%] [G loss: 1.004812]\n",
      "epoch:14 step:13600 [D loss: 0.796643, acc.: 45.31%] [G loss: 0.924334]\n",
      "##############\n",
      "[4.01771129 2.44420461 6.73204508 5.69328548 4.39828947 6.13764656\n",
      " 5.23739834 5.56421814 5.58878524 4.90106246]\n",
      "##########\n",
      "epoch:14 step:13601 [D loss: 0.712847, acc.: 50.00%] [G loss: 0.833689]\n",
      "epoch:14 step:13602 [D loss: 0.722914, acc.: 46.88%] [G loss: 0.817140]\n",
      "epoch:14 step:13603 [D loss: 0.735073, acc.: 45.31%] [G loss: 0.975248]\n",
      "epoch:14 step:13604 [D loss: 0.711351, acc.: 46.88%] [G loss: 0.914300]\n",
      "epoch:14 step:13605 [D loss: 0.728261, acc.: 49.22%] [G loss: 0.871642]\n",
      "epoch:14 step:13606 [D loss: 0.724598, acc.: 47.66%] [G loss: 0.938215]\n",
      "epoch:14 step:13607 [D loss: 0.714452, acc.: 53.12%] [G loss: 0.943005]\n",
      "epoch:14 step:13608 [D loss: 0.664275, acc.: 64.84%] [G loss: 0.870279]\n",
      "epoch:14 step:13609 [D loss: 0.660811, acc.: 64.84%] [G loss: 0.861281]\n",
      "epoch:14 step:13610 [D loss: 0.645875, acc.: 59.38%] [G loss: 0.777486]\n",
      "epoch:14 step:13611 [D loss: 0.690308, acc.: 51.56%] [G loss: 0.841792]\n",
      "epoch:14 step:13612 [D loss: 0.742618, acc.: 42.97%] [G loss: 0.843421]\n",
      "epoch:14 step:13613 [D loss: 0.652306, acc.: 64.84%] [G loss: 0.867529]\n",
      "epoch:14 step:13614 [D loss: 0.667831, acc.: 57.03%] [G loss: 0.851878]\n",
      "epoch:14 step:13615 [D loss: 0.541884, acc.: 85.94%] [G loss: 0.893999]\n",
      "epoch:14 step:13616 [D loss: 0.496040, acc.: 82.03%] [G loss: 1.261979]\n",
      "epoch:14 step:13617 [D loss: 0.428569, acc.: 86.72%] [G loss: 1.008157]\n",
      "epoch:14 step:13618 [D loss: 0.634717, acc.: 64.84%] [G loss: 1.044988]\n",
      "epoch:14 step:13619 [D loss: 0.641770, acc.: 69.53%] [G loss: 1.007177]\n",
      "epoch:14 step:13620 [D loss: 0.649669, acc.: 61.72%] [G loss: 0.964581]\n",
      "epoch:14 step:13621 [D loss: 0.677593, acc.: 62.50%] [G loss: 0.953293]\n",
      "epoch:14 step:13622 [D loss: 0.573788, acc.: 78.12%] [G loss: 0.885536]\n",
      "epoch:14 step:13623 [D loss: 0.545332, acc.: 69.53%] [G loss: 0.856334]\n",
      "epoch:14 step:13624 [D loss: 0.664695, acc.: 60.16%] [G loss: 0.922621]\n",
      "epoch:14 step:13625 [D loss: 0.656627, acc.: 53.91%] [G loss: 0.848390]\n",
      "epoch:14 step:13626 [D loss: 0.608547, acc.: 69.53%] [G loss: 0.886121]\n",
      "epoch:14 step:13627 [D loss: 0.648314, acc.: 61.72%] [G loss: 0.842099]\n",
      "epoch:14 step:13628 [D loss: 0.506012, acc.: 77.34%] [G loss: 0.929749]\n",
      "epoch:14 step:13629 [D loss: 0.440746, acc.: 84.38%] [G loss: 0.924967]\n",
      "epoch:14 step:13630 [D loss: 0.477638, acc.: 80.47%] [G loss: 0.833688]\n",
      "epoch:14 step:13631 [D loss: 0.528820, acc.: 78.12%] [G loss: 0.844046]\n",
      "epoch:14 step:13632 [D loss: 0.411178, acc.: 82.03%] [G loss: 0.864068]\n",
      "epoch:14 step:13633 [D loss: 0.314316, acc.: 90.62%] [G loss: 1.066779]\n",
      "epoch:14 step:13634 [D loss: 0.659761, acc.: 59.38%] [G loss: 1.108416]\n",
      "epoch:14 step:13635 [D loss: 0.653857, acc.: 59.38%] [G loss: 0.920053]\n",
      "epoch:14 step:13636 [D loss: 0.707342, acc.: 57.03%] [G loss: 0.966035]\n",
      "epoch:14 step:13637 [D loss: 0.720670, acc.: 56.25%] [G loss: 0.820187]\n",
      "epoch:14 step:13638 [D loss: 0.671553, acc.: 56.25%] [G loss: 0.921554]\n",
      "epoch:14 step:13639 [D loss: 0.766797, acc.: 42.19%] [G loss: 0.780598]\n",
      "epoch:14 step:13640 [D loss: 0.677067, acc.: 57.81%] [G loss: 0.844627]\n",
      "epoch:14 step:13641 [D loss: 0.636759, acc.: 66.41%] [G loss: 0.918086]\n",
      "epoch:14 step:13642 [D loss: 0.354397, acc.: 84.38%] [G loss: 0.906628]\n",
      "epoch:14 step:13643 [D loss: 0.634849, acc.: 65.62%] [G loss: 0.893628]\n",
      "epoch:14 step:13644 [D loss: 0.546408, acc.: 80.47%] [G loss: 1.044954]\n",
      "epoch:14 step:13645 [D loss: 0.424336, acc.: 85.94%] [G loss: 0.872797]\n",
      "epoch:14 step:13646 [D loss: 0.638401, acc.: 66.41%] [G loss: 1.110756]\n",
      "epoch:14 step:13647 [D loss: 0.544789, acc.: 82.81%] [G loss: 1.250307]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13648 [D loss: 0.397387, acc.: 75.00%] [G loss: 0.364686]\n",
      "epoch:14 step:13649 [D loss: 0.681118, acc.: 53.91%] [G loss: 0.839143]\n",
      "epoch:14 step:13650 [D loss: 0.603384, acc.: 64.84%] [G loss: 1.013964]\n",
      "epoch:14 step:13651 [D loss: 0.942619, acc.: 21.88%] [G loss: 0.844619]\n",
      "epoch:14 step:13652 [D loss: 0.817702, acc.: 32.03%] [G loss: 1.072326]\n",
      "epoch:14 step:13653 [D loss: 0.343157, acc.: 87.50%] [G loss: 1.000705]\n",
      "epoch:14 step:13654 [D loss: 0.286427, acc.: 92.19%] [G loss: 1.119086]\n",
      "epoch:14 step:13655 [D loss: 0.412731, acc.: 83.59%] [G loss: 1.020412]\n",
      "epoch:14 step:13656 [D loss: 0.395684, acc.: 95.31%] [G loss: 1.250208]\n",
      "epoch:14 step:13657 [D loss: 0.397802, acc.: 87.50%] [G loss: 1.292675]\n",
      "epoch:14 step:13658 [D loss: 0.498314, acc.: 74.22%] [G loss: 1.310323]\n",
      "epoch:14 step:13659 [D loss: 0.438466, acc.: 89.06%] [G loss: 1.520345]\n",
      "epoch:14 step:13660 [D loss: 0.749900, acc.: 53.91%] [G loss: 1.210749]\n",
      "epoch:14 step:13661 [D loss: 0.505991, acc.: 83.59%] [G loss: 0.991011]\n",
      "epoch:14 step:13662 [D loss: 0.772574, acc.: 49.22%] [G loss: 1.068175]\n",
      "epoch:14 step:13663 [D loss: 0.855671, acc.: 39.06%] [G loss: 0.950365]\n",
      "epoch:14 step:13664 [D loss: 0.730321, acc.: 53.91%] [G loss: 0.994390]\n",
      "epoch:14 step:13665 [D loss: 0.666087, acc.: 57.03%] [G loss: 0.744310]\n",
      "epoch:14 step:13666 [D loss: 0.656662, acc.: 58.59%] [G loss: 0.811241]\n",
      "epoch:14 step:13667 [D loss: 0.600528, acc.: 67.97%] [G loss: 0.966156]\n",
      "epoch:14 step:13668 [D loss: 0.441194, acc.: 88.28%] [G loss: 0.826456]\n",
      "epoch:14 step:13669 [D loss: 0.707927, acc.: 53.91%] [G loss: 0.944961]\n",
      "epoch:14 step:13670 [D loss: 0.627658, acc.: 65.62%] [G loss: 0.919510]\n",
      "epoch:14 step:13671 [D loss: 0.648276, acc.: 55.47%] [G loss: 0.985671]\n",
      "epoch:14 step:13672 [D loss: 0.455338, acc.: 87.50%] [G loss: 0.992904]\n",
      "epoch:14 step:13673 [D loss: 0.575075, acc.: 67.19%] [G loss: 0.965703]\n",
      "epoch:14 step:13674 [D loss: 0.758057, acc.: 60.16%] [G loss: 0.978132]\n",
      "epoch:14 step:13675 [D loss: 0.494341, acc.: 81.25%] [G loss: 1.169813]\n",
      "epoch:14 step:13676 [D loss: 0.593084, acc.: 66.41%] [G loss: 1.200742]\n",
      "epoch:14 step:13677 [D loss: 0.372740, acc.: 93.75%] [G loss: 1.125137]\n",
      "epoch:14 step:13678 [D loss: 0.621739, acc.: 69.53%] [G loss: 1.039208]\n",
      "epoch:14 step:13679 [D loss: 0.312072, acc.: 97.66%] [G loss: 1.107279]\n",
      "epoch:14 step:13680 [D loss: 0.894867, acc.: 37.50%] [G loss: 1.005372]\n",
      "epoch:14 step:13681 [D loss: 0.673249, acc.: 58.59%] [G loss: 0.985202]\n",
      "epoch:14 step:13682 [D loss: 0.708948, acc.: 58.59%] [G loss: 0.945089]\n",
      "epoch:14 step:13683 [D loss: 0.589409, acc.: 71.09%] [G loss: 0.835587]\n",
      "epoch:14 step:13684 [D loss: 0.366798, acc.: 85.16%] [G loss: 0.931576]\n",
      "epoch:14 step:13685 [D loss: 0.308102, acc.: 91.41%] [G loss: 0.423613]\n",
      "epoch:14 step:13686 [D loss: 0.605012, acc.: 70.31%] [G loss: 1.047689]\n",
      "epoch:14 step:13687 [D loss: 0.790806, acc.: 40.62%] [G loss: 1.089061]\n",
      "epoch:14 step:13688 [D loss: 0.629255, acc.: 64.84%] [G loss: 0.904969]\n",
      "epoch:14 step:13689 [D loss: 0.635935, acc.: 67.97%] [G loss: 1.021744]\n",
      "epoch:14 step:13690 [D loss: 0.733714, acc.: 53.12%] [G loss: 1.029275]\n",
      "epoch:14 step:13691 [D loss: 0.555645, acc.: 78.12%] [G loss: 0.914658]\n",
      "epoch:14 step:13692 [D loss: 0.541240, acc.: 76.56%] [G loss: 0.962254]\n",
      "epoch:14 step:13693 [D loss: 0.596541, acc.: 68.75%] [G loss: 0.792197]\n",
      "epoch:14 step:13694 [D loss: 0.512294, acc.: 70.31%] [G loss: 0.895289]\n",
      "epoch:14 step:13695 [D loss: 0.514727, acc.: 67.19%] [G loss: 1.139581]\n",
      "epoch:14 step:13696 [D loss: 0.365850, acc.: 85.94%] [G loss: 1.254429]\n",
      "epoch:14 step:13697 [D loss: 0.441874, acc.: 90.62%] [G loss: 1.227531]\n",
      "epoch:14 step:13698 [D loss: 0.734786, acc.: 53.91%] [G loss: 1.205970]\n",
      "epoch:14 step:13699 [D loss: 0.796656, acc.: 39.06%] [G loss: 1.149463]\n",
      "epoch:14 step:13700 [D loss: 0.689170, acc.: 57.03%] [G loss: 0.975921]\n",
      "epoch:14 step:13701 [D loss: 0.674914, acc.: 57.03%] [G loss: 1.039484]\n",
      "epoch:14 step:13702 [D loss: 0.772864, acc.: 47.66%] [G loss: 1.028605]\n",
      "epoch:14 step:13703 [D loss: 0.617220, acc.: 67.19%] [G loss: 1.090104]\n",
      "epoch:14 step:13704 [D loss: 0.640618, acc.: 59.38%] [G loss: 1.033499]\n",
      "epoch:14 step:13705 [D loss: 0.289857, acc.: 89.06%] [G loss: 0.777468]\n",
      "epoch:14 step:13706 [D loss: 0.274825, acc.: 94.53%] [G loss: 1.094411]\n",
      "epoch:14 step:13707 [D loss: 0.235107, acc.: 95.31%] [G loss: 0.976157]\n",
      "epoch:14 step:13708 [D loss: 0.876580, acc.: 40.62%] [G loss: 1.176884]\n",
      "epoch:14 step:13709 [D loss: 0.567843, acc.: 71.88%] [G loss: 1.123830]\n",
      "epoch:14 step:13710 [D loss: 0.489193, acc.: 82.81%] [G loss: 1.110186]\n",
      "epoch:14 step:13711 [D loss: 0.667227, acc.: 53.12%] [G loss: 0.986552]\n",
      "epoch:14 step:13712 [D loss: 0.725644, acc.: 51.56%] [G loss: 1.037767]\n",
      "epoch:14 step:13713 [D loss: 0.377003, acc.: 87.50%] [G loss: 1.053425]\n",
      "epoch:14 step:13714 [D loss: 0.590701, acc.: 70.31%] [G loss: 0.997832]\n",
      "epoch:14 step:13715 [D loss: 0.824392, acc.: 44.53%] [G loss: 0.988211]\n",
      "epoch:14 step:13716 [D loss: 0.766407, acc.: 46.88%] [G loss: 1.055242]\n",
      "epoch:14 step:13717 [D loss: 0.806319, acc.: 35.94%] [G loss: 0.974979]\n",
      "epoch:14 step:13718 [D loss: 0.272521, acc.: 92.19%] [G loss: 1.142276]\n",
      "epoch:14 step:13719 [D loss: 0.248972, acc.: 97.66%] [G loss: 1.098563]\n",
      "epoch:14 step:13720 [D loss: 0.236609, acc.: 100.00%] [G loss: 1.158950]\n",
      "epoch:14 step:13721 [D loss: 0.737836, acc.: 53.91%] [G loss: 0.747301]\n",
      "epoch:14 step:13722 [D loss: 0.473704, acc.: 77.34%] [G loss: 1.147732]\n",
      "epoch:14 step:13723 [D loss: 0.748100, acc.: 45.31%] [G loss: 1.165330]\n",
      "epoch:14 step:13724 [D loss: 0.597669, acc.: 67.19%] [G loss: 1.021924]\n",
      "epoch:14 step:13725 [D loss: 0.572140, acc.: 79.69%] [G loss: 0.926443]\n",
      "epoch:14 step:13726 [D loss: 0.347101, acc.: 85.94%] [G loss: 0.623649]\n",
      "epoch:14 step:13727 [D loss: 0.271998, acc.: 96.09%] [G loss: 0.446717]\n",
      "epoch:14 step:13728 [D loss: 0.703856, acc.: 54.69%] [G loss: 1.057314]\n",
      "epoch:14 step:13729 [D loss: 0.241317, acc.: 100.00%] [G loss: 1.122024]\n",
      "epoch:14 step:13730 [D loss: 0.235896, acc.: 95.31%] [G loss: 1.231069]\n",
      "epoch:14 step:13731 [D loss: 0.586222, acc.: 70.31%] [G loss: 1.166965]\n",
      "epoch:14 step:13732 [D loss: 0.800636, acc.: 36.72%] [G loss: 1.185230]\n",
      "epoch:14 step:13733 [D loss: 0.694549, acc.: 59.38%] [G loss: 1.126382]\n",
      "epoch:14 step:13734 [D loss: 0.780938, acc.: 46.88%] [G loss: 1.018328]\n",
      "epoch:14 step:13735 [D loss: 0.773474, acc.: 42.19%] [G loss: 0.973488]\n",
      "epoch:14 step:13736 [D loss: 0.318686, acc.: 95.31%] [G loss: 1.085692]\n",
      "epoch:14 step:13737 [D loss: 0.409442, acc.: 76.56%] [G loss: 1.155772]\n",
      "epoch:14 step:13738 [D loss: 0.272282, acc.: 93.75%] [G loss: 1.288149]\n",
      "epoch:14 step:13739 [D loss: 0.702478, acc.: 57.03%] [G loss: 0.522178]\n",
      "epoch:14 step:13740 [D loss: 0.858683, acc.: 43.75%] [G loss: 1.136089]\n",
      "epoch:14 step:13741 [D loss: 0.763550, acc.: 47.66%] [G loss: 0.988369]\n",
      "epoch:14 step:13742 [D loss: 0.784074, acc.: 46.09%] [G loss: 0.862644]\n",
      "epoch:14 step:13743 [D loss: 0.272040, acc.: 97.66%] [G loss: 0.626102]\n",
      "epoch:14 step:13744 [D loss: 0.903104, acc.: 31.25%] [G loss: 1.024865]\n",
      "epoch:14 step:13745 [D loss: 0.537299, acc.: 62.50%] [G loss: 0.912993]\n",
      "epoch:14 step:13746 [D loss: 1.653795, acc.: 27.34%] [G loss: 1.064485]\n",
      "epoch:14 step:13747 [D loss: 1.132698, acc.: 13.28%] [G loss: 1.550849]\n",
      "epoch:14 step:13748 [D loss: 0.822854, acc.: 46.88%] [G loss: 1.552723]\n",
      "epoch:14 step:13749 [D loss: 0.740428, acc.: 54.69%] [G loss: 1.352785]\n",
      "epoch:14 step:13750 [D loss: 0.619316, acc.: 62.50%] [G loss: 1.455982]\n",
      "epoch:14 step:13751 [D loss: 0.529595, acc.: 70.31%] [G loss: 1.204477]\n",
      "epoch:14 step:13752 [D loss: 0.560166, acc.: 68.75%] [G loss: 1.050672]\n",
      "epoch:14 step:13753 [D loss: 0.582639, acc.: 64.84%] [G loss: 0.943354]\n",
      "epoch:14 step:13754 [D loss: 0.718495, acc.: 51.56%] [G loss: 1.334647]\n",
      "epoch:14 step:13755 [D loss: 0.585480, acc.: 62.50%] [G loss: 1.371256]\n",
      "epoch:14 step:13756 [D loss: 0.619428, acc.: 58.59%] [G loss: 1.426424]\n",
      "epoch:14 step:13757 [D loss: 0.796870, acc.: 42.19%] [G loss: 1.343791]\n",
      "epoch:14 step:13758 [D loss: 0.772811, acc.: 45.31%] [G loss: 1.309469]\n",
      "epoch:14 step:13759 [D loss: 0.687493, acc.: 54.69%] [G loss: 1.293084]\n",
      "epoch:14 step:13760 [D loss: 0.649191, acc.: 55.47%] [G loss: 1.367836]\n",
      "epoch:14 step:13761 [D loss: 0.477108, acc.: 86.72%] [G loss: 1.315129]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13762 [D loss: 0.322029, acc.: 92.97%] [G loss: 1.372887]\n",
      "epoch:14 step:13763 [D loss: 0.332913, acc.: 95.31%] [G loss: 1.461764]\n",
      "epoch:14 step:13764 [D loss: 0.293773, acc.: 92.19%] [G loss: 1.705955]\n",
      "epoch:14 step:13765 [D loss: 0.383590, acc.: 93.75%] [G loss: 1.453220]\n",
      "epoch:14 step:13766 [D loss: 0.233053, acc.: 97.66%] [G loss: 1.674299]\n",
      "epoch:14 step:13767 [D loss: 0.298030, acc.: 95.31%] [G loss: 1.241390]\n",
      "epoch:14 step:13768 [D loss: 0.199677, acc.: 97.66%] [G loss: 1.207935]\n",
      "epoch:14 step:13769 [D loss: 0.354361, acc.: 95.31%] [G loss: 1.924806]\n",
      "epoch:14 step:13770 [D loss: 0.405543, acc.: 89.06%] [G loss: 1.485276]\n",
      "epoch:14 step:13771 [D loss: 0.882162, acc.: 30.47%] [G loss: 0.848526]\n",
      "epoch:14 step:13772 [D loss: 0.817264, acc.: 46.88%] [G loss: 0.734818]\n",
      "epoch:14 step:13773 [D loss: 0.803550, acc.: 47.66%] [G loss: 1.782917]\n",
      "epoch:14 step:13774 [D loss: 0.578453, acc.: 76.56%] [G loss: 1.691915]\n",
      "epoch:14 step:13775 [D loss: 0.806164, acc.: 39.06%] [G loss: 0.664130]\n",
      "epoch:14 step:13776 [D loss: 0.874827, acc.: 33.59%] [G loss: 1.619888]\n",
      "epoch:14 step:13777 [D loss: 0.353888, acc.: 89.84%] [G loss: 1.010724]\n",
      "epoch:14 step:13778 [D loss: 0.621905, acc.: 61.72%] [G loss: 0.877346]\n",
      "epoch:14 step:13779 [D loss: 0.542368, acc.: 75.78%] [G loss: 1.185027]\n",
      "epoch:14 step:13780 [D loss: 0.828488, acc.: 48.44%] [G loss: 1.675350]\n",
      "epoch:14 step:13781 [D loss: 1.309784, acc.: 21.88%] [G loss: 1.220097]\n",
      "epoch:14 step:13782 [D loss: 0.739985, acc.: 64.06%] [G loss: 0.919182]\n",
      "epoch:14 step:13783 [D loss: 0.667635, acc.: 58.59%] [G loss: 1.019073]\n",
      "epoch:14 step:13784 [D loss: 0.829046, acc.: 37.50%] [G loss: 1.075877]\n",
      "epoch:14 step:13785 [D loss: 0.699999, acc.: 57.81%] [G loss: 1.002570]\n",
      "epoch:14 step:13786 [D loss: 0.690513, acc.: 59.38%] [G loss: 1.070652]\n",
      "epoch:14 step:13787 [D loss: 0.740419, acc.: 46.09%] [G loss: 1.134674]\n",
      "epoch:14 step:13788 [D loss: 0.718570, acc.: 56.25%] [G loss: 1.004419]\n",
      "epoch:14 step:13789 [D loss: 0.776115, acc.: 38.28%] [G loss: 0.919439]\n",
      "epoch:14 step:13790 [D loss: 0.775072, acc.: 41.41%] [G loss: 0.880772]\n",
      "epoch:14 step:13791 [D loss: 0.724872, acc.: 49.22%] [G loss: 0.895023]\n",
      "epoch:14 step:13792 [D loss: 0.655947, acc.: 61.72%] [G loss: 1.029721]\n",
      "epoch:14 step:13793 [D loss: 0.752598, acc.: 49.22%] [G loss: 0.843918]\n",
      "epoch:14 step:13794 [D loss: 0.681172, acc.: 53.12%] [G loss: 0.907903]\n",
      "epoch:14 step:13795 [D loss: 0.666881, acc.: 60.94%] [G loss: 0.908798]\n",
      "epoch:14 step:13796 [D loss: 0.669692, acc.: 59.38%] [G loss: 0.877245]\n",
      "epoch:14 step:13797 [D loss: 0.698495, acc.: 56.25%] [G loss: 0.838067]\n",
      "epoch:14 step:13798 [D loss: 0.684669, acc.: 50.78%] [G loss: 0.898629]\n",
      "epoch:14 step:13799 [D loss: 0.679465, acc.: 53.12%] [G loss: 0.895545]\n",
      "epoch:14 step:13800 [D loss: 0.636022, acc.: 67.19%] [G loss: 0.935259]\n",
      "##############\n",
      "[4.02307917 2.20252715 6.89759199 4.90813043 4.42617622 6.0244797\n",
      " 5.63528818 4.8642942  5.43631632 5.21652492]\n",
      "##########\n",
      "epoch:14 step:13801 [D loss: 0.990890, acc.: 42.19%] [G loss: 1.015736]\n",
      "epoch:14 step:13802 [D loss: 0.562093, acc.: 78.12%] [G loss: 1.065993]\n",
      "epoch:14 step:13803 [D loss: 0.589145, acc.: 69.53%] [G loss: 1.351556]\n",
      "epoch:14 step:13804 [D loss: 0.521170, acc.: 76.56%] [G loss: 1.566290]\n",
      "epoch:14 step:13805 [D loss: 0.592017, acc.: 75.00%] [G loss: 1.341287]\n",
      "epoch:14 step:13806 [D loss: 0.619368, acc.: 69.53%] [G loss: 0.917542]\n",
      "epoch:14 step:13807 [D loss: 0.842522, acc.: 47.66%] [G loss: 0.878757]\n",
      "epoch:14 step:13808 [D loss: 0.774741, acc.: 40.62%] [G loss: 0.882711]\n",
      "epoch:14 step:13809 [D loss: 0.673609, acc.: 57.81%] [G loss: 0.787617]\n",
      "epoch:14 step:13810 [D loss: 0.792051, acc.: 42.19%] [G loss: 0.718276]\n",
      "epoch:14 step:13811 [D loss: 0.673449, acc.: 60.16%] [G loss: 0.727583]\n",
      "epoch:14 step:13812 [D loss: 0.662066, acc.: 56.25%] [G loss: 0.727856]\n",
      "epoch:14 step:13813 [D loss: 0.688178, acc.: 51.56%] [G loss: 0.782976]\n",
      "epoch:14 step:13814 [D loss: 0.467595, acc.: 79.69%] [G loss: 0.841326]\n",
      "epoch:14 step:13815 [D loss: 0.431428, acc.: 76.56%] [G loss: 0.863192]\n",
      "epoch:14 step:13816 [D loss: 0.445296, acc.: 82.81%] [G loss: 0.892635]\n",
      "epoch:14 step:13817 [D loss: 0.645706, acc.: 69.53%] [G loss: 0.942343]\n",
      "epoch:14 step:13818 [D loss: 0.386469, acc.: 88.28%] [G loss: 0.992630]\n",
      "epoch:14 step:13819 [D loss: 0.338996, acc.: 92.19%] [G loss: 0.988835]\n",
      "epoch:14 step:13820 [D loss: 0.333797, acc.: 95.31%] [G loss: 1.057262]\n",
      "epoch:14 step:13821 [D loss: 0.662282, acc.: 59.38%] [G loss: 0.957165]\n",
      "epoch:14 step:13822 [D loss: 0.509870, acc.: 83.59%] [G loss: 1.187023]\n",
      "epoch:14 step:13823 [D loss: 0.719941, acc.: 50.00%] [G loss: 0.908771]\n",
      "epoch:14 step:13824 [D loss: 0.403854, acc.: 85.16%] [G loss: 1.020873]\n",
      "epoch:14 step:13825 [D loss: 0.276112, acc.: 93.75%] [G loss: 0.979071]\n",
      "epoch:14 step:13826 [D loss: 0.307785, acc.: 92.19%] [G loss: 1.241026]\n",
      "epoch:14 step:13827 [D loss: 0.429465, acc.: 90.62%] [G loss: 1.340384]\n",
      "epoch:14 step:13828 [D loss: 0.925355, acc.: 42.19%] [G loss: 0.992491]\n",
      "epoch:14 step:13829 [D loss: 0.703524, acc.: 53.91%] [G loss: 1.059376]\n",
      "epoch:14 step:13830 [D loss: 0.689998, acc.: 62.50%] [G loss: 0.814852]\n",
      "epoch:14 step:13831 [D loss: 0.348714, acc.: 82.03%] [G loss: 1.016880]\n",
      "epoch:14 step:13832 [D loss: 0.282608, acc.: 90.62%] [G loss: 0.880478]\n",
      "epoch:14 step:13833 [D loss: 0.839090, acc.: 35.94%] [G loss: 1.176618]\n",
      "epoch:14 step:13834 [D loss: 0.746644, acc.: 53.91%] [G loss: 1.084976]\n",
      "epoch:14 step:13835 [D loss: 1.011197, acc.: 25.78%] [G loss: 1.068642]\n",
      "epoch:14 step:13836 [D loss: 0.748401, acc.: 51.56%] [G loss: 0.991369]\n",
      "epoch:14 step:13837 [D loss: 0.727477, acc.: 48.44%] [G loss: 0.963190]\n",
      "epoch:14 step:13838 [D loss: 0.702698, acc.: 54.69%] [G loss: 0.969999]\n",
      "epoch:14 step:13839 [D loss: 0.656422, acc.: 53.91%] [G loss: 0.973581]\n",
      "epoch:14 step:13840 [D loss: 0.754068, acc.: 45.31%] [G loss: 1.025057]\n",
      "epoch:14 step:13841 [D loss: 0.704686, acc.: 55.47%] [G loss: 0.960856]\n",
      "epoch:14 step:13842 [D loss: 0.652939, acc.: 61.72%] [G loss: 0.851776]\n",
      "epoch:14 step:13843 [D loss: 0.649375, acc.: 59.38%] [G loss: 0.845589]\n",
      "epoch:14 step:13844 [D loss: 0.682637, acc.: 52.34%] [G loss: 0.875536]\n",
      "epoch:14 step:13845 [D loss: 0.494403, acc.: 87.50%] [G loss: 0.905012]\n",
      "epoch:14 step:13846 [D loss: 0.391397, acc.: 90.62%] [G loss: 0.936630]\n",
      "epoch:14 step:13847 [D loss: 0.496352, acc.: 85.94%] [G loss: 1.113006]\n",
      "epoch:14 step:13848 [D loss: 0.349785, acc.: 90.62%] [G loss: 1.019421]\n",
      "epoch:14 step:13849 [D loss: 0.343776, acc.: 95.31%] [G loss: 1.010821]\n",
      "epoch:14 step:13850 [D loss: 0.318396, acc.: 92.97%] [G loss: 0.878688]\n",
      "epoch:14 step:13851 [D loss: 0.418982, acc.: 93.75%] [G loss: 1.060248]\n",
      "epoch:14 step:13852 [D loss: 0.690655, acc.: 58.59%] [G loss: 1.054162]\n",
      "epoch:14 step:13853 [D loss: 0.718710, acc.: 54.69%] [G loss: 0.996806]\n",
      "epoch:14 step:13854 [D loss: 0.700912, acc.: 51.56%] [G loss: 0.929199]\n",
      "epoch:14 step:13855 [D loss: 0.778376, acc.: 42.19%] [G loss: 0.919723]\n",
      "epoch:14 step:13856 [D loss: 0.704736, acc.: 49.22%] [G loss: 1.011457]\n",
      "epoch:14 step:13857 [D loss: 0.449277, acc.: 74.22%] [G loss: 1.059713]\n",
      "epoch:14 step:13858 [D loss: 0.548722, acc.: 76.56%] [G loss: 1.067271]\n",
      "epoch:14 step:13859 [D loss: 0.647712, acc.: 62.50%] [G loss: 0.994957]\n",
      "epoch:14 step:13860 [D loss: 0.821923, acc.: 34.38%] [G loss: 1.012252]\n",
      "epoch:14 step:13861 [D loss: 0.614232, acc.: 64.06%] [G loss: 1.098061]\n",
      "epoch:14 step:13862 [D loss: 0.662966, acc.: 60.16%] [G loss: 1.078198]\n",
      "epoch:14 step:13863 [D loss: 0.418054, acc.: 93.75%] [G loss: 1.033235]\n",
      "epoch:14 step:13864 [D loss: 0.338613, acc.: 97.66%] [G loss: 1.058662]\n",
      "epoch:14 step:13865 [D loss: 0.565991, acc.: 80.47%] [G loss: 1.015026]\n",
      "epoch:14 step:13866 [D loss: 0.773036, acc.: 41.41%] [G loss: 0.953329]\n",
      "epoch:14 step:13867 [D loss: 0.632972, acc.: 66.41%] [G loss: 0.990184]\n",
      "epoch:14 step:13868 [D loss: 0.600346, acc.: 67.19%] [G loss: 1.003338]\n",
      "epoch:14 step:13869 [D loss: 0.686289, acc.: 58.59%] [G loss: 0.661482]\n",
      "epoch:14 step:13870 [D loss: 0.668332, acc.: 62.50%] [G loss: 0.912099]\n",
      "epoch:14 step:13871 [D loss: 0.617725, acc.: 62.50%] [G loss: 0.921384]\n",
      "epoch:14 step:13872 [D loss: 0.321132, acc.: 91.41%] [G loss: 0.961263]\n",
      "epoch:14 step:13873 [D loss: 0.836961, acc.: 53.91%] [G loss: 1.052135]\n",
      "epoch:14 step:13874 [D loss: 0.343426, acc.: 92.97%] [G loss: 1.008958]\n",
      "epoch:14 step:13875 [D loss: 0.537354, acc.: 79.69%] [G loss: 1.172095]\n",
      "epoch:14 step:13876 [D loss: 0.593037, acc.: 67.97%] [G loss: 1.115951]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13877 [D loss: 0.752571, acc.: 46.09%] [G loss: 0.646592]\n",
      "epoch:14 step:13878 [D loss: 0.821123, acc.: 35.94%] [G loss: 0.901256]\n",
      "epoch:14 step:13879 [D loss: 0.738773, acc.: 56.25%] [G loss: 0.477745]\n",
      "epoch:14 step:13880 [D loss: 0.608088, acc.: 67.97%] [G loss: 1.009805]\n",
      "epoch:14 step:13881 [D loss: 0.583191, acc.: 69.53%] [G loss: 1.029325]\n",
      "epoch:14 step:13882 [D loss: 0.292378, acc.: 97.66%] [G loss: 0.906865]\n",
      "epoch:14 step:13883 [D loss: 0.852106, acc.: 33.59%] [G loss: 1.000462]\n",
      "epoch:14 step:13884 [D loss: 0.715177, acc.: 50.78%] [G loss: 0.778767]\n",
      "epoch:14 step:13885 [D loss: 0.890882, acc.: 23.44%] [G loss: 0.899544]\n",
      "epoch:14 step:13886 [D loss: 0.885587, acc.: 39.84%] [G loss: 1.031002]\n",
      "epoch:14 step:13887 [D loss: 0.500454, acc.: 77.34%] [G loss: 0.944620]\n",
      "epoch:14 step:13888 [D loss: 0.677868, acc.: 57.03%] [G loss: 1.120997]\n",
      "epoch:14 step:13889 [D loss: 0.695619, acc.: 53.12%] [G loss: 0.948909]\n",
      "epoch:14 step:13890 [D loss: 0.996744, acc.: 17.19%] [G loss: 1.107234]\n",
      "epoch:14 step:13891 [D loss: 0.615109, acc.: 65.62%] [G loss: 1.057550]\n",
      "epoch:14 step:13892 [D loss: 0.375582, acc.: 95.31%] [G loss: 1.181263]\n",
      "epoch:14 step:13893 [D loss: 0.389723, acc.: 92.97%] [G loss: 1.167041]\n",
      "epoch:14 step:13894 [D loss: 0.570416, acc.: 74.22%] [G loss: 1.191340]\n",
      "epoch:14 step:13895 [D loss: 0.464132, acc.: 89.84%] [G loss: 1.211882]\n",
      "epoch:14 step:13896 [D loss: 0.614612, acc.: 61.72%] [G loss: 1.215205]\n",
      "epoch:14 step:13897 [D loss: 0.675341, acc.: 57.03%] [G loss: 1.284545]\n",
      "epoch:14 step:13898 [D loss: 0.692174, acc.: 59.38%] [G loss: 1.016960]\n",
      "epoch:14 step:13899 [D loss: 0.688934, acc.: 60.94%] [G loss: 0.873257]\n",
      "epoch:14 step:13900 [D loss: 0.707607, acc.: 50.78%] [G loss: 1.084195]\n",
      "epoch:14 step:13901 [D loss: 0.718501, acc.: 54.69%] [G loss: 0.931259]\n",
      "epoch:14 step:13902 [D loss: 0.781300, acc.: 43.75%] [G loss: 0.765709]\n",
      "epoch:14 step:13903 [D loss: 0.698148, acc.: 53.91%] [G loss: 1.038467]\n",
      "epoch:14 step:13904 [D loss: 0.670014, acc.: 60.16%] [G loss: 1.023346]\n",
      "epoch:14 step:13905 [D loss: 0.724321, acc.: 43.75%] [G loss: 0.855143]\n",
      "epoch:14 step:13906 [D loss: 0.707266, acc.: 53.12%] [G loss: 1.018940]\n",
      "epoch:14 step:13907 [D loss: 0.575436, acc.: 75.00%] [G loss: 0.922745]\n",
      "epoch:14 step:13908 [D loss: 0.639548, acc.: 61.72%] [G loss: 0.877880]\n",
      "epoch:14 step:13909 [D loss: 0.716524, acc.: 56.25%] [G loss: 0.947812]\n",
      "epoch:14 step:13910 [D loss: 0.659049, acc.: 64.84%] [G loss: 0.585191]\n",
      "epoch:14 step:13911 [D loss: 0.691765, acc.: 53.91%] [G loss: 0.970758]\n",
      "epoch:14 step:13912 [D loss: 0.568086, acc.: 64.84%] [G loss: 1.000100]\n",
      "epoch:14 step:13913 [D loss: 0.778012, acc.: 38.28%] [G loss: 0.879821]\n",
      "epoch:14 step:13914 [D loss: 0.522492, acc.: 75.00%] [G loss: 0.893350]\n",
      "epoch:14 step:13915 [D loss: 0.667826, acc.: 55.47%] [G loss: 0.998925]\n",
      "epoch:14 step:13916 [D loss: 0.709109, acc.: 52.34%] [G loss: 0.877412]\n",
      "epoch:14 step:13917 [D loss: 0.684278, acc.: 57.03%] [G loss: 0.762151]\n",
      "epoch:14 step:13918 [D loss: 0.411593, acc.: 86.72%] [G loss: 1.005822]\n",
      "epoch:14 step:13919 [D loss: 0.416246, acc.: 86.72%] [G loss: 0.967693]\n",
      "epoch:14 step:13920 [D loss: 0.288992, acc.: 93.75%] [G loss: 0.706833]\n",
      "epoch:14 step:13921 [D loss: 0.741990, acc.: 56.25%] [G loss: 0.995243]\n",
      "epoch:14 step:13922 [D loss: 0.531222, acc.: 78.91%] [G loss: 1.109458]\n",
      "epoch:14 step:13923 [D loss: 0.495730, acc.: 82.81%] [G loss: 0.853006]\n",
      "epoch:14 step:13924 [D loss: 0.345359, acc.: 95.31%] [G loss: 1.041242]\n",
      "epoch:14 step:13925 [D loss: 0.734574, acc.: 46.09%] [G loss: 1.059579]\n",
      "epoch:14 step:13926 [D loss: 0.512212, acc.: 83.59%] [G loss: 1.070226]\n",
      "epoch:14 step:13927 [D loss: 0.495178, acc.: 88.28%] [G loss: 0.932690]\n",
      "epoch:14 step:13928 [D loss: 0.533469, acc.: 75.00%] [G loss: 0.932495]\n",
      "epoch:14 step:13929 [D loss: 0.763969, acc.: 52.34%] [G loss: 0.947485]\n",
      "epoch:14 step:13930 [D loss: 0.688819, acc.: 61.72%] [G loss: 0.817571]\n",
      "epoch:14 step:13931 [D loss: 0.842847, acc.: 37.50%] [G loss: 0.967530]\n",
      "epoch:14 step:13932 [D loss: 0.689750, acc.: 53.91%] [G loss: 0.897381]\n",
      "epoch:14 step:13933 [D loss: 0.393100, acc.: 82.81%] [G loss: 0.898616]\n",
      "epoch:14 step:13934 [D loss: 0.512296, acc.: 81.25%] [G loss: 1.017029]\n",
      "epoch:14 step:13935 [D loss: 0.576495, acc.: 73.44%] [G loss: 1.059257]\n",
      "epoch:14 step:13936 [D loss: 0.817695, acc.: 39.06%] [G loss: 0.807924]\n",
      "epoch:14 step:13937 [D loss: 0.655074, acc.: 60.94%] [G loss: 0.825222]\n",
      "epoch:14 step:13938 [D loss: 0.821096, acc.: 35.94%] [G loss: 0.781446]\n",
      "epoch:14 step:13939 [D loss: 0.521781, acc.: 72.66%] [G loss: 0.650763]\n",
      "epoch:14 step:13940 [D loss: 0.496328, acc.: 80.47%] [G loss: 0.760976]\n",
      "epoch:14 step:13941 [D loss: 0.714484, acc.: 44.53%] [G loss: 0.637807]\n",
      "epoch:14 step:13942 [D loss: 0.699942, acc.: 51.56%] [G loss: 0.756300]\n",
      "epoch:14 step:13943 [D loss: 0.614377, acc.: 70.31%] [G loss: 0.863396]\n",
      "epoch:14 step:13944 [D loss: 0.729520, acc.: 46.09%] [G loss: 0.854885]\n",
      "epoch:14 step:13945 [D loss: 0.811971, acc.: 33.59%] [G loss: 0.774996]\n",
      "epoch:14 step:13946 [D loss: 0.652373, acc.: 56.25%] [G loss: 0.854232]\n",
      "epoch:14 step:13947 [D loss: 0.713432, acc.: 50.78%] [G loss: 0.832357]\n",
      "epoch:14 step:13948 [D loss: 0.810258, acc.: 37.50%] [G loss: 0.775845]\n",
      "epoch:14 step:13949 [D loss: 0.576755, acc.: 82.03%] [G loss: 0.883076]\n",
      "epoch:14 step:13950 [D loss: 0.632095, acc.: 70.31%] [G loss: 0.833178]\n",
      "epoch:14 step:13951 [D loss: 0.654392, acc.: 61.72%] [G loss: 0.777760]\n",
      "epoch:14 step:13952 [D loss: 0.509439, acc.: 83.59%] [G loss: 0.816240]\n",
      "epoch:14 step:13953 [D loss: 0.722363, acc.: 50.78%] [G loss: 0.966252]\n",
      "epoch:14 step:13954 [D loss: 0.750661, acc.: 43.75%] [G loss: 0.914239]\n",
      "epoch:14 step:13955 [D loss: 0.665324, acc.: 54.69%] [G loss: 0.818977]\n",
      "epoch:14 step:13956 [D loss: 0.698559, acc.: 49.22%] [G loss: 0.839679]\n",
      "epoch:14 step:13957 [D loss: 0.630804, acc.: 63.28%] [G loss: 0.870067]\n",
      "epoch:14 step:13958 [D loss: 0.646995, acc.: 56.25%] [G loss: 0.851866]\n",
      "epoch:14 step:13959 [D loss: 0.373306, acc.: 87.50%] [G loss: 0.915343]\n",
      "epoch:14 step:13960 [D loss: 0.601624, acc.: 72.66%] [G loss: 0.928213]\n",
      "epoch:14 step:13961 [D loss: 0.718106, acc.: 51.56%] [G loss: 0.770040]\n",
      "epoch:14 step:13962 [D loss: 0.622917, acc.: 67.19%] [G loss: 0.772419]\n",
      "epoch:14 step:13963 [D loss: 0.459244, acc.: 75.00%] [G loss: 0.920164]\n",
      "epoch:14 step:13964 [D loss: 0.912910, acc.: 25.00%] [G loss: 0.868052]\n",
      "epoch:14 step:13965 [D loss: 0.308907, acc.: 89.84%] [G loss: 1.015232]\n",
      "epoch:14 step:13966 [D loss: 0.362327, acc.: 89.84%] [G loss: 1.040322]\n",
      "epoch:14 step:13967 [D loss: 0.702615, acc.: 56.25%] [G loss: 1.049052]\n",
      "epoch:14 step:13968 [D loss: 0.342389, acc.: 92.19%] [G loss: 1.049418]\n",
      "epoch:14 step:13969 [D loss: 0.256952, acc.: 97.66%] [G loss: 1.041165]\n",
      "epoch:14 step:13970 [D loss: 0.241799, acc.: 96.09%] [G loss: 1.140824]\n",
      "epoch:14 step:13971 [D loss: 0.214694, acc.: 99.22%] [G loss: 1.192520]\n",
      "epoch:14 step:13972 [D loss: 0.217732, acc.: 99.22%] [G loss: 1.206535]\n",
      "epoch:14 step:13973 [D loss: 0.540122, acc.: 78.12%] [G loss: 1.237157]\n",
      "epoch:14 step:13974 [D loss: 0.655528, acc.: 64.06%] [G loss: 1.011474]\n",
      "epoch:14 step:13975 [D loss: 0.223931, acc.: 98.44%] [G loss: 1.141623]\n",
      "epoch:14 step:13976 [D loss: 0.814555, acc.: 50.78%] [G loss: 1.127982]\n",
      "epoch:14 step:13977 [D loss: 0.769478, acc.: 50.00%] [G loss: 1.106243]\n",
      "epoch:14 step:13978 [D loss: 0.723486, acc.: 47.66%] [G loss: 0.984366]\n",
      "epoch:14 step:13979 [D loss: 0.432612, acc.: 92.19%] [G loss: 1.032618]\n",
      "epoch:14 step:13980 [D loss: 0.706542, acc.: 50.78%] [G loss: 1.008868]\n",
      "epoch:14 step:13981 [D loss: 0.683582, acc.: 57.03%] [G loss: 0.889121]\n",
      "epoch:14 step:13982 [D loss: 0.788003, acc.: 35.16%] [G loss: 0.462864]\n",
      "epoch:14 step:13983 [D loss: 0.439273, acc.: 67.19%] [G loss: 1.015090]\n",
      "epoch:14 step:13984 [D loss: 0.385309, acc.: 97.66%] [G loss: 1.072239]\n",
      "epoch:14 step:13985 [D loss: 0.486405, acc.: 67.19%] [G loss: 0.707695]\n",
      "epoch:14 step:13986 [D loss: 1.454081, acc.: 12.50%] [G loss: 1.021973]\n",
      "epoch:14 step:13987 [D loss: 0.717294, acc.: 53.12%] [G loss: 1.110803]\n",
      "epoch:14 step:13988 [D loss: 0.749669, acc.: 53.91%] [G loss: 0.993460]\n",
      "epoch:14 step:13989 [D loss: 0.669002, acc.: 56.25%] [G loss: 0.336658]\n",
      "epoch:14 step:13990 [D loss: 0.416243, acc.: 88.28%] [G loss: 1.113672]\n",
      "epoch:14 step:13991 [D loss: 0.682630, acc.: 63.28%] [G loss: 0.965005]\n",
      "epoch:14 step:13992 [D loss: 0.619428, acc.: 64.84%] [G loss: 0.956756]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13993 [D loss: 0.577855, acc.: 75.78%] [G loss: 0.986810]\n",
      "epoch:14 step:13994 [D loss: 0.629498, acc.: 67.19%] [G loss: 0.798862]\n",
      "epoch:14 step:13995 [D loss: 0.757176, acc.: 40.62%] [G loss: 0.874029]\n",
      "epoch:14 step:13996 [D loss: 0.812518, acc.: 40.62%] [G loss: 1.077808]\n",
      "epoch:14 step:13997 [D loss: 0.847478, acc.: 29.69%] [G loss: 1.011723]\n",
      "epoch:14 step:13998 [D loss: 0.729266, acc.: 42.19%] [G loss: 0.980075]\n",
      "epoch:14 step:13999 [D loss: 0.821156, acc.: 31.25%] [G loss: 0.865257]\n",
      "epoch:14 step:14000 [D loss: 0.448502, acc.: 85.16%] [G loss: 1.003154]\n",
      "##############\n",
      "[4.06796928 2.62882389 6.50751488 5.72043354 4.6710773  6.09245513\n",
      " 5.88447057 5.76152039 6.06685379 5.23138766]\n",
      "##########\n",
      "epoch:14 step:14001 [D loss: 0.535564, acc.: 73.44%] [G loss: 0.939882]\n",
      "epoch:14 step:14002 [D loss: 0.402947, acc.: 83.59%] [G loss: 0.549113]\n",
      "epoch:14 step:14003 [D loss: 0.226460, acc.: 100.00%] [G loss: 0.476027]\n",
      "epoch:14 step:14004 [D loss: 0.260553, acc.: 97.66%] [G loss: 0.624131]\n",
      "epoch:14 step:14005 [D loss: 0.435938, acc.: 72.66%] [G loss: 0.294063]\n",
      "epoch:14 step:14006 [D loss: 0.980523, acc.: 24.22%] [G loss: 0.720087]\n",
      "epoch:14 step:14007 [D loss: 0.779151, acc.: 57.81%] [G loss: 0.746298]\n",
      "epoch:14 step:14008 [D loss: 0.817870, acc.: 48.44%] [G loss: 0.993424]\n",
      "epoch:14 step:14009 [D loss: 0.956589, acc.: 30.47%] [G loss: 1.330453]\n",
      "epoch:14 step:14010 [D loss: 0.776880, acc.: 49.22%] [G loss: 1.402861]\n",
      "epoch:14 step:14011 [D loss: 0.624130, acc.: 62.50%] [G loss: 1.254801]\n",
      "epoch:14 step:14012 [D loss: 0.615969, acc.: 61.72%] [G loss: 1.482014]\n",
      "epoch:14 step:14013 [D loss: 0.584898, acc.: 64.06%] [G loss: 1.434763]\n",
      "epoch:14 step:14014 [D loss: 0.536652, acc.: 70.31%] [G loss: 1.486593]\n",
      "epoch:14 step:14015 [D loss: 0.453711, acc.: 79.69%] [G loss: 1.500438]\n",
      "epoch:14 step:14016 [D loss: 0.366912, acc.: 87.50%] [G loss: 1.656276]\n",
      "epoch:14 step:14017 [D loss: 0.207728, acc.: 95.31%] [G loss: 1.634017]\n",
      "epoch:14 step:14018 [D loss: 0.203356, acc.: 96.09%] [G loss: 1.583666]\n",
      "epoch:14 step:14019 [D loss: 0.379111, acc.: 90.62%] [G loss: 1.629220]\n",
      "epoch:14 step:14020 [D loss: 0.349411, acc.: 91.41%] [G loss: 1.723851]\n",
      "epoch:14 step:14021 [D loss: 0.374967, acc.: 92.97%] [G loss: 1.780391]\n",
      "epoch:14 step:14022 [D loss: 1.051455, acc.: 44.53%] [G loss: 0.987291]\n",
      "epoch:14 step:14023 [D loss: 0.851077, acc.: 40.62%] [G loss: 1.121324]\n",
      "epoch:14 step:14024 [D loss: 0.820362, acc.: 44.53%] [G loss: 1.135556]\n",
      "epoch:14 step:14025 [D loss: 0.702654, acc.: 56.25%] [G loss: 1.320933]\n",
      "epoch:14 step:14026 [D loss: 0.442975, acc.: 92.19%] [G loss: 1.418393]\n",
      "epoch:14 step:14027 [D loss: 0.252568, acc.: 94.53%] [G loss: 1.091163]\n",
      "epoch:14 step:14028 [D loss: 1.107621, acc.: 12.50%] [G loss: 1.171281]\n",
      "epoch:14 step:14029 [D loss: 0.241609, acc.: 98.44%] [G loss: 0.921279]\n",
      "epoch:14 step:14030 [D loss: 0.219826, acc.: 97.66%] [G loss: 1.083230]\n",
      "epoch:14 step:14031 [D loss: 0.617508, acc.: 63.28%] [G loss: 1.784749]\n",
      "epoch:14 step:14032 [D loss: 0.660877, acc.: 54.69%] [G loss: 1.462202]\n",
      "epoch:14 step:14033 [D loss: 1.166786, acc.: 9.38%] [G loss: 0.826891]\n",
      "epoch:14 step:14034 [D loss: 0.942278, acc.: 38.28%] [G loss: 1.030484]\n",
      "epoch:14 step:14035 [D loss: 0.838367, acc.: 50.78%] [G loss: 1.092026]\n",
      "epoch:14 step:14036 [D loss: 0.557393, acc.: 78.91%] [G loss: 0.984362]\n",
      "epoch:14 step:14037 [D loss: 0.391958, acc.: 89.06%] [G loss: 0.791326]\n",
      "epoch:14 step:14038 [D loss: 1.170444, acc.: 10.94%] [G loss: 0.843133]\n",
      "epoch:14 step:14039 [D loss: 0.711148, acc.: 57.81%] [G loss: 0.874688]\n",
      "epoch:14 step:14040 [D loss: 0.556170, acc.: 78.91%] [G loss: 0.883942]\n",
      "epoch:14 step:14041 [D loss: 0.554833, acc.: 78.12%] [G loss: 1.055096]\n",
      "epoch:14 step:14042 [D loss: 0.497704, acc.: 72.66%] [G loss: 1.156183]\n",
      "epoch:14 step:14043 [D loss: 0.413099, acc.: 82.03%] [G loss: 0.970143]\n",
      "epoch:14 step:14044 [D loss: 0.390589, acc.: 75.78%] [G loss: 1.065524]\n",
      "epoch:14 step:14045 [D loss: 0.323180, acc.: 82.03%] [G loss: 0.998848]\n",
      "epoch:14 step:14046 [D loss: 0.786499, acc.: 49.22%] [G loss: 0.859939]\n",
      "epoch:14 step:14047 [D loss: 0.770194, acc.: 52.34%] [G loss: 1.166686]\n",
      "epoch:14 step:14048 [D loss: 0.605063, acc.: 73.44%] [G loss: 1.049468]\n",
      "epoch:14 step:14049 [D loss: 0.613253, acc.: 67.19%] [G loss: 0.915806]\n",
      "epoch:14 step:14050 [D loss: 0.551437, acc.: 71.09%] [G loss: 0.947516]\n",
      "epoch:14 step:14051 [D loss: 0.384776, acc.: 91.41%] [G loss: 0.546858]\n",
      "epoch:14 step:14052 [D loss: 0.314192, acc.: 82.03%] [G loss: 0.903013]\n",
      "epoch:14 step:14053 [D loss: 0.546197, acc.: 67.97%] [G loss: 0.966589]\n",
      "epoch:14 step:14054 [D loss: 0.280890, acc.: 92.19%] [G loss: 1.125858]\n",
      "epoch:14 step:14055 [D loss: 0.194901, acc.: 98.44%] [G loss: 1.300722]\n",
      "epoch:15 step:14056 [D loss: 0.743579, acc.: 51.56%] [G loss: 0.987854]\n",
      "epoch:15 step:14057 [D loss: 0.815157, acc.: 36.72%] [G loss: 0.897382]\n",
      "epoch:15 step:14058 [D loss: 1.135933, acc.: 19.53%] [G loss: 0.925548]\n",
      "epoch:15 step:14059 [D loss: 0.855981, acc.: 32.03%] [G loss: 1.159524]\n",
      "epoch:15 step:14060 [D loss: 0.698880, acc.: 59.38%] [G loss: 1.250469]\n",
      "epoch:15 step:14061 [D loss: 0.734174, acc.: 46.09%] [G loss: 1.096667]\n",
      "epoch:15 step:14062 [D loss: 0.666089, acc.: 57.03%] [G loss: 1.105986]\n",
      "epoch:15 step:14063 [D loss: 0.671608, acc.: 59.38%] [G loss: 1.080943]\n",
      "epoch:15 step:14064 [D loss: 0.606017, acc.: 72.66%] [G loss: 0.946958]\n",
      "epoch:15 step:14065 [D loss: 0.600943, acc.: 64.84%] [G loss: 0.798679]\n",
      "epoch:15 step:14066 [D loss: 0.590724, acc.: 73.44%] [G loss: 0.915369]\n",
      "epoch:15 step:14067 [D loss: 0.671358, acc.: 60.94%] [G loss: 0.906243]\n",
      "epoch:15 step:14068 [D loss: 0.571442, acc.: 70.31%] [G loss: 0.663230]\n",
      "epoch:15 step:14069 [D loss: 0.589928, acc.: 71.88%] [G loss: 0.737117]\n",
      "epoch:15 step:14070 [D loss: 0.525045, acc.: 75.78%] [G loss: 0.842955]\n",
      "epoch:15 step:14071 [D loss: 0.595441, acc.: 71.09%] [G loss: 0.779523]\n",
      "epoch:15 step:14072 [D loss: 0.665542, acc.: 60.16%] [G loss: 0.716542]\n",
      "epoch:15 step:14073 [D loss: 0.936391, acc.: 45.31%] [G loss: 0.898434]\n",
      "epoch:15 step:14074 [D loss: 0.717686, acc.: 46.09%] [G loss: 0.739217]\n",
      "epoch:15 step:14075 [D loss: 1.018338, acc.: 15.62%] [G loss: 0.954753]\n",
      "epoch:15 step:14076 [D loss: 0.790079, acc.: 39.06%] [G loss: 0.976874]\n",
      "epoch:15 step:14077 [D loss: 0.676308, acc.: 55.47%] [G loss: 1.085246]\n",
      "epoch:15 step:14078 [D loss: 0.729553, acc.: 43.75%] [G loss: 1.144581]\n",
      "epoch:15 step:14079 [D loss: 0.685403, acc.: 60.94%] [G loss: 1.046767]\n",
      "epoch:15 step:14080 [D loss: 0.699695, acc.: 53.12%] [G loss: 0.920584]\n",
      "epoch:15 step:14081 [D loss: 0.728914, acc.: 42.19%] [G loss: 1.082228]\n",
      "epoch:15 step:14082 [D loss: 0.598752, acc.: 78.91%] [G loss: 0.788355]\n",
      "epoch:15 step:14083 [D loss: 0.640917, acc.: 60.94%] [G loss: 0.976831]\n",
      "epoch:15 step:14084 [D loss: 0.657735, acc.: 58.59%] [G loss: 1.110292]\n",
      "epoch:15 step:14085 [D loss: 0.677527, acc.: 52.34%] [G loss: 1.040097]\n",
      "epoch:15 step:14086 [D loss: 0.576396, acc.: 75.00%] [G loss: 1.011117]\n",
      "epoch:15 step:14087 [D loss: 0.593870, acc.: 69.53%] [G loss: 1.167339]\n",
      "epoch:15 step:14088 [D loss: 0.542562, acc.: 78.12%] [G loss: 1.051146]\n",
      "epoch:15 step:14089 [D loss: 0.518286, acc.: 80.47%] [G loss: 1.069874]\n",
      "epoch:15 step:14090 [D loss: 0.425329, acc.: 93.75%] [G loss: 1.256744]\n",
      "epoch:15 step:14091 [D loss: 0.446664, acc.: 88.28%] [G loss: 1.204446]\n",
      "epoch:15 step:14092 [D loss: 0.706368, acc.: 56.25%] [G loss: 1.001759]\n",
      "epoch:15 step:14093 [D loss: 1.009926, acc.: 34.38%] [G loss: 0.928630]\n",
      "epoch:15 step:14094 [D loss: 0.853112, acc.: 33.59%] [G loss: 0.754456]\n",
      "epoch:15 step:14095 [D loss: 0.749606, acc.: 49.22%] [G loss: 0.884065]\n",
      "epoch:15 step:14096 [D loss: 0.703227, acc.: 53.12%] [G loss: 0.787234]\n",
      "epoch:15 step:14097 [D loss: 0.634710, acc.: 67.19%] [G loss: 0.802851]\n",
      "epoch:15 step:14098 [D loss: 0.656091, acc.: 62.50%] [G loss: 0.719944]\n",
      "epoch:15 step:14099 [D loss: 0.676672, acc.: 60.16%] [G loss: 0.755860]\n",
      "epoch:15 step:14100 [D loss: 0.650333, acc.: 65.62%] [G loss: 0.793408]\n",
      "epoch:15 step:14101 [D loss: 0.640990, acc.: 64.06%] [G loss: 0.791430]\n",
      "epoch:15 step:14102 [D loss: 0.669407, acc.: 61.72%] [G loss: 0.761707]\n",
      "epoch:15 step:14103 [D loss: 0.719865, acc.: 47.66%] [G loss: 0.809605]\n",
      "epoch:15 step:14104 [D loss: 0.791242, acc.: 39.06%] [G loss: 0.709911]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14105 [D loss: 0.639466, acc.: 61.72%] [G loss: 0.763650]\n",
      "epoch:15 step:14106 [D loss: 0.624864, acc.: 62.50%] [G loss: 0.887556]\n",
      "epoch:15 step:14107 [D loss: 0.649891, acc.: 64.84%] [G loss: 0.776210]\n",
      "epoch:15 step:14108 [D loss: 0.653057, acc.: 61.72%] [G loss: 0.741788]\n",
      "epoch:15 step:14109 [D loss: 0.696511, acc.: 49.22%] [G loss: 0.803304]\n",
      "epoch:15 step:14110 [D loss: 0.747171, acc.: 38.28%] [G loss: 0.750496]\n",
      "epoch:15 step:14111 [D loss: 0.686794, acc.: 53.12%] [G loss: 0.867652]\n",
      "epoch:15 step:14112 [D loss: 0.586107, acc.: 79.69%] [G loss: 0.866715]\n",
      "epoch:15 step:14113 [D loss: 0.529864, acc.: 74.22%] [G loss: 0.843633]\n",
      "epoch:15 step:14114 [D loss: 0.622783, acc.: 71.88%] [G loss: 0.744204]\n",
      "epoch:15 step:14115 [D loss: 0.635804, acc.: 61.72%] [G loss: 0.853553]\n",
      "epoch:15 step:14116 [D loss: 0.735450, acc.: 43.75%] [G loss: 0.797177]\n",
      "epoch:15 step:14117 [D loss: 0.658445, acc.: 60.94%] [G loss: 0.797985]\n",
      "epoch:15 step:14118 [D loss: 0.633860, acc.: 67.19%] [G loss: 0.851951]\n",
      "epoch:15 step:14119 [D loss: 0.780300, acc.: 37.50%] [G loss: 0.872016]\n",
      "epoch:15 step:14120 [D loss: 0.694470, acc.: 55.47%] [G loss: 0.816777]\n",
      "epoch:15 step:14121 [D loss: 0.667437, acc.: 62.50%] [G loss: 0.790176]\n",
      "epoch:15 step:14122 [D loss: 0.709898, acc.: 49.22%] [G loss: 0.827521]\n",
      "epoch:15 step:14123 [D loss: 0.693987, acc.: 53.91%] [G loss: 0.827834]\n",
      "epoch:15 step:14124 [D loss: 0.659847, acc.: 54.69%] [G loss: 0.799171]\n",
      "epoch:15 step:14125 [D loss: 0.650283, acc.: 64.84%] [G loss: 0.816243]\n",
      "epoch:15 step:14126 [D loss: 0.495073, acc.: 83.59%] [G loss: 0.836924]\n",
      "epoch:15 step:14127 [D loss: 0.594018, acc.: 74.22%] [G loss: 0.866627]\n",
      "epoch:15 step:14128 [D loss: 0.550512, acc.: 75.00%] [G loss: 0.855285]\n",
      "epoch:15 step:14129 [D loss: 0.680437, acc.: 55.47%] [G loss: 0.840414]\n",
      "epoch:15 step:14130 [D loss: 0.398144, acc.: 82.81%] [G loss: 0.631619]\n",
      "epoch:15 step:14131 [D loss: 0.514266, acc.: 76.56%] [G loss: 0.875591]\n",
      "epoch:15 step:14132 [D loss: 0.411131, acc.: 91.41%] [G loss: 0.911457]\n",
      "epoch:15 step:14133 [D loss: 0.763250, acc.: 50.00%] [G loss: 0.808694]\n",
      "epoch:15 step:14134 [D loss: 0.717123, acc.: 47.66%] [G loss: 0.605806]\n",
      "epoch:15 step:14135 [D loss: 0.690283, acc.: 53.91%] [G loss: 0.883393]\n",
      "epoch:15 step:14136 [D loss: 0.788625, acc.: 36.72%] [G loss: 0.918532]\n",
      "epoch:15 step:14137 [D loss: 0.712735, acc.: 46.88%] [G loss: 0.886939]\n",
      "epoch:15 step:14138 [D loss: 0.645098, acc.: 60.94%] [G loss: 0.871994]\n",
      "epoch:15 step:14139 [D loss: 0.675654, acc.: 58.59%] [G loss: 0.947764]\n",
      "epoch:15 step:14140 [D loss: 0.632097, acc.: 65.62%] [G loss: 0.719717]\n",
      "epoch:15 step:14141 [D loss: 0.696461, acc.: 53.12%] [G loss: 0.902134]\n",
      "epoch:15 step:14142 [D loss: 0.643431, acc.: 64.84%] [G loss: 0.891192]\n",
      "epoch:15 step:14143 [D loss: 0.729893, acc.: 51.56%] [G loss: 0.869639]\n",
      "epoch:15 step:14144 [D loss: 0.544351, acc.: 77.34%] [G loss: 0.955164]\n",
      "epoch:15 step:14145 [D loss: 0.631676, acc.: 64.84%] [G loss: 0.875363]\n",
      "epoch:15 step:14146 [D loss: 0.755630, acc.: 40.62%] [G loss: 0.879363]\n",
      "epoch:15 step:14147 [D loss: 0.624493, acc.: 69.53%] [G loss: 0.897682]\n",
      "epoch:15 step:14148 [D loss: 0.592825, acc.: 70.31%] [G loss: 0.897666]\n",
      "epoch:15 step:14149 [D loss: 0.575532, acc.: 72.66%] [G loss: 0.889811]\n",
      "epoch:15 step:14150 [D loss: 0.649711, acc.: 61.72%] [G loss: 0.818420]\n",
      "epoch:15 step:14151 [D loss: 0.610317, acc.: 69.53%] [G loss: 0.988739]\n",
      "epoch:15 step:14152 [D loss: 0.678107, acc.: 59.38%] [G loss: 0.762331]\n",
      "epoch:15 step:14153 [D loss: 0.645289, acc.: 63.28%] [G loss: 0.840705]\n",
      "epoch:15 step:14154 [D loss: 0.678224, acc.: 51.56%] [G loss: 0.806792]\n",
      "epoch:15 step:14155 [D loss: 0.611779, acc.: 68.75%] [G loss: 0.818734]\n",
      "epoch:15 step:14156 [D loss: 0.643531, acc.: 67.97%] [G loss: 0.595050]\n",
      "epoch:15 step:14157 [D loss: 0.721296, acc.: 44.53%] [G loss: 0.808286]\n",
      "epoch:15 step:14158 [D loss: 0.716784, acc.: 46.88%] [G loss: 0.841877]\n",
      "epoch:15 step:14159 [D loss: 0.777351, acc.: 39.06%] [G loss: 0.755275]\n",
      "epoch:15 step:14160 [D loss: 0.664957, acc.: 60.94%] [G loss: 0.739573]\n",
      "epoch:15 step:14161 [D loss: 0.674906, acc.: 58.59%] [G loss: 0.396582]\n",
      "epoch:15 step:14162 [D loss: 0.603877, acc.: 67.19%] [G loss: 0.897505]\n",
      "epoch:15 step:14163 [D loss: 0.690506, acc.: 55.47%] [G loss: 0.858853]\n",
      "epoch:15 step:14164 [D loss: 0.729851, acc.: 46.09%] [G loss: 0.900314]\n",
      "epoch:15 step:14165 [D loss: 0.676016, acc.: 56.25%] [G loss: 0.917489]\n",
      "epoch:15 step:14166 [D loss: 0.648322, acc.: 64.84%] [G loss: 0.890428]\n",
      "epoch:15 step:14167 [D loss: 0.710419, acc.: 52.34%] [G loss: 0.802533]\n",
      "epoch:15 step:14168 [D loss: 0.525700, acc.: 78.91%] [G loss: 1.023343]\n",
      "epoch:15 step:14169 [D loss: 0.537164, acc.: 77.34%] [G loss: 0.933734]\n",
      "epoch:15 step:14170 [D loss: 0.506706, acc.: 78.91%] [G loss: 1.054747]\n",
      "epoch:15 step:14171 [D loss: 0.727127, acc.: 49.22%] [G loss: 0.925139]\n",
      "epoch:15 step:14172 [D loss: 0.743900, acc.: 49.22%] [G loss: 0.944120]\n",
      "epoch:15 step:14173 [D loss: 0.574348, acc.: 74.22%] [G loss: 0.944027]\n",
      "epoch:15 step:14174 [D loss: 0.421890, acc.: 84.38%] [G loss: 0.976570]\n",
      "epoch:15 step:14175 [D loss: 0.626394, acc.: 67.97%] [G loss: 0.837509]\n",
      "epoch:15 step:14176 [D loss: 0.499578, acc.: 75.78%] [G loss: 0.853681]\n",
      "epoch:15 step:14177 [D loss: 0.545572, acc.: 75.00%] [G loss: 0.939290]\n",
      "epoch:15 step:14178 [D loss: 0.750893, acc.: 46.09%] [G loss: 0.961159]\n",
      "epoch:15 step:14179 [D loss: 0.815260, acc.: 46.88%] [G loss: 0.826904]\n",
      "epoch:15 step:14180 [D loss: 0.963267, acc.: 21.88%] [G loss: 0.893211]\n",
      "epoch:15 step:14181 [D loss: 0.658107, acc.: 66.41%] [G loss: 0.919967]\n",
      "epoch:15 step:14182 [D loss: 0.689465, acc.: 50.78%] [G loss: 0.915768]\n",
      "epoch:15 step:14183 [D loss: 0.700250, acc.: 52.34%] [G loss: 0.896647]\n",
      "epoch:15 step:14184 [D loss: 0.621151, acc.: 75.00%] [G loss: 0.975197]\n",
      "epoch:15 step:14185 [D loss: 0.536170, acc.: 81.25%] [G loss: 0.833680]\n",
      "epoch:15 step:14186 [D loss: 0.571174, acc.: 78.12%] [G loss: 0.824117]\n",
      "epoch:15 step:14187 [D loss: 0.575894, acc.: 76.56%] [G loss: 0.974532]\n",
      "epoch:15 step:14188 [D loss: 0.590594, acc.: 71.88%] [G loss: 0.947646]\n",
      "epoch:15 step:14189 [D loss: 0.620426, acc.: 70.31%] [G loss: 0.950565]\n",
      "epoch:15 step:14190 [D loss: 0.632416, acc.: 67.19%] [G loss: 0.930540]\n",
      "epoch:15 step:14191 [D loss: 0.684855, acc.: 57.81%] [G loss: 0.950670]\n",
      "epoch:15 step:14192 [D loss: 0.607939, acc.: 69.53%] [G loss: 0.923377]\n",
      "epoch:15 step:14193 [D loss: 0.589104, acc.: 67.19%] [G loss: 0.777437]\n",
      "epoch:15 step:14194 [D loss: 0.495480, acc.: 77.34%] [G loss: 0.784944]\n",
      "epoch:15 step:14195 [D loss: 0.641174, acc.: 65.62%] [G loss: 0.912974]\n",
      "epoch:15 step:14196 [D loss: 0.661133, acc.: 60.16%] [G loss: 0.898043]\n",
      "epoch:15 step:14197 [D loss: 0.751038, acc.: 46.88%] [G loss: 0.956359]\n",
      "epoch:15 step:14198 [D loss: 0.453999, acc.: 81.25%] [G loss: 0.932443]\n",
      "epoch:15 step:14199 [D loss: 0.581951, acc.: 64.84%] [G loss: 0.935961]\n",
      "epoch:15 step:14200 [D loss: 0.367777, acc.: 84.38%] [G loss: 0.937423]\n",
      "##############\n",
      "[4.11119979 2.1662094  6.60093177 5.36623881 4.26725211 6.24654462\n",
      " 5.40149129 5.71869469 6.12878593 5.24835429]\n",
      "##########\n",
      "epoch:15 step:14201 [D loss: 0.616416, acc.: 69.53%] [G loss: 0.975627]\n",
      "epoch:15 step:14202 [D loss: 0.688248, acc.: 49.22%] [G loss: 0.852622]\n",
      "epoch:15 step:14203 [D loss: 0.720017, acc.: 48.44%] [G loss: 0.929611]\n",
      "epoch:15 step:14204 [D loss: 0.652728, acc.: 64.06%] [G loss: 0.881341]\n",
      "epoch:15 step:14205 [D loss: 0.361253, acc.: 85.94%] [G loss: 0.858109]\n",
      "epoch:15 step:14206 [D loss: 0.406972, acc.: 89.84%] [G loss: 0.980428]\n",
      "epoch:15 step:14207 [D loss: 0.580598, acc.: 73.44%] [G loss: 0.581149]\n",
      "epoch:15 step:14208 [D loss: 0.782423, acc.: 45.31%] [G loss: 0.978108]\n",
      "epoch:15 step:14209 [D loss: 0.631182, acc.: 67.97%] [G loss: 0.844782]\n",
      "epoch:15 step:14210 [D loss: 0.615602, acc.: 67.19%] [G loss: 0.486355]\n",
      "epoch:15 step:14211 [D loss: 0.658277, acc.: 61.72%] [G loss: 0.921632]\n",
      "epoch:15 step:14212 [D loss: 0.730177, acc.: 46.88%] [G loss: 0.629599]\n",
      "epoch:15 step:14213 [D loss: 0.861283, acc.: 28.12%] [G loss: 0.850017]\n",
      "epoch:15 step:14214 [D loss: 0.675377, acc.: 59.38%] [G loss: 0.679294]\n",
      "epoch:15 step:14215 [D loss: 0.731780, acc.: 46.88%] [G loss: 0.979271]\n",
      "epoch:15 step:14216 [D loss: 0.691785, acc.: 60.16%] [G loss: 0.815838]\n",
      "epoch:15 step:14217 [D loss: 0.601055, acc.: 73.44%] [G loss: 0.682385]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14218 [D loss: 0.711529, acc.: 51.56%] [G loss: 0.990632]\n",
      "epoch:15 step:14219 [D loss: 0.553093, acc.: 77.34%] [G loss: 0.799952]\n",
      "epoch:15 step:14220 [D loss: 0.859129, acc.: 27.34%] [G loss: 0.965456]\n",
      "epoch:15 step:14221 [D loss: 0.687185, acc.: 54.69%] [G loss: 0.737889]\n",
      "epoch:15 step:14222 [D loss: 0.680667, acc.: 55.47%] [G loss: 0.964882]\n",
      "epoch:15 step:14223 [D loss: 0.627441, acc.: 67.19%] [G loss: 0.734635]\n",
      "epoch:15 step:14224 [D loss: 0.764480, acc.: 46.09%] [G loss: 0.990294]\n",
      "epoch:15 step:14225 [D loss: 0.827086, acc.: 39.06%] [G loss: 0.887123]\n",
      "epoch:15 step:14226 [D loss: 0.749734, acc.: 45.31%] [G loss: 0.947004]\n",
      "epoch:15 step:14227 [D loss: 0.697702, acc.: 57.03%] [G loss: 1.020577]\n",
      "epoch:15 step:14228 [D loss: 0.707352, acc.: 54.69%] [G loss: 0.864780]\n",
      "epoch:15 step:14229 [D loss: 0.703232, acc.: 57.81%] [G loss: 0.650296]\n",
      "epoch:15 step:14230 [D loss: 0.698583, acc.: 53.91%] [G loss: 0.841200]\n",
      "epoch:15 step:14231 [D loss: 0.709567, acc.: 46.88%] [G loss: 0.963319]\n",
      "epoch:15 step:14232 [D loss: 0.660372, acc.: 57.81%] [G loss: 0.818183]\n",
      "epoch:15 step:14233 [D loss: 0.642408, acc.: 66.41%] [G loss: 0.964450]\n",
      "epoch:15 step:14234 [D loss: 0.854286, acc.: 32.03%] [G loss: 0.700610]\n",
      "epoch:15 step:14235 [D loss: 0.698309, acc.: 57.03%] [G loss: 0.804173]\n",
      "epoch:15 step:14236 [D loss: 0.539512, acc.: 77.34%] [G loss: 0.961926]\n",
      "epoch:15 step:14237 [D loss: 0.602040, acc.: 71.09%] [G loss: 1.054293]\n",
      "epoch:15 step:14238 [D loss: 0.626844, acc.: 59.38%] [G loss: 1.094152]\n",
      "epoch:15 step:14239 [D loss: 0.475938, acc.: 81.25%] [G loss: 1.196123]\n",
      "epoch:15 step:14240 [D loss: 0.705316, acc.: 52.34%] [G loss: 1.191149]\n",
      "epoch:15 step:14241 [D loss: 0.664031, acc.: 57.81%] [G loss: 1.111344]\n",
      "epoch:15 step:14242 [D loss: 0.546799, acc.: 78.91%] [G loss: 1.030796]\n",
      "epoch:15 step:14243 [D loss: 0.496682, acc.: 88.28%] [G loss: 1.158423]\n",
      "epoch:15 step:14244 [D loss: 0.542257, acc.: 78.12%] [G loss: 1.219363]\n",
      "epoch:15 step:14245 [D loss: 0.526447, acc.: 78.12%] [G loss: 1.268545]\n",
      "epoch:15 step:14246 [D loss: 0.485177, acc.: 82.81%] [G loss: 1.217198]\n",
      "epoch:15 step:14247 [D loss: 0.341321, acc.: 90.62%] [G loss: 1.045192]\n",
      "epoch:15 step:14248 [D loss: 0.481597, acc.: 82.81%] [G loss: 1.080969]\n",
      "epoch:15 step:14249 [D loss: 0.274426, acc.: 96.88%] [G loss: 1.373839]\n",
      "epoch:15 step:14250 [D loss: 0.394574, acc.: 86.72%] [G loss: 1.487422]\n",
      "epoch:15 step:14251 [D loss: 0.431058, acc.: 94.53%] [G loss: 1.831640]\n",
      "epoch:15 step:14252 [D loss: 0.491194, acc.: 75.00%] [G loss: 1.040401]\n",
      "epoch:15 step:14253 [D loss: 0.333905, acc.: 92.97%] [G loss: 1.009819]\n",
      "epoch:15 step:14254 [D loss: 0.678873, acc.: 54.69%] [G loss: 0.951998]\n",
      "epoch:15 step:14255 [D loss: 1.046880, acc.: 41.41%] [G loss: 1.218078]\n",
      "epoch:15 step:14256 [D loss: 0.998548, acc.: 39.06%] [G loss: 0.808641]\n",
      "epoch:15 step:14257 [D loss: 0.684729, acc.: 57.03%] [G loss: 1.119732]\n",
      "epoch:15 step:14258 [D loss: 0.702694, acc.: 53.12%] [G loss: 0.550181]\n",
      "epoch:15 step:14259 [D loss: 0.323922, acc.: 84.38%] [G loss: 0.860705]\n",
      "epoch:15 step:14260 [D loss: 0.549697, acc.: 75.78%] [G loss: 0.890888]\n",
      "epoch:15 step:14261 [D loss: 0.383945, acc.: 93.75%] [G loss: 0.745249]\n",
      "epoch:15 step:14262 [D loss: 0.321030, acc.: 82.81%] [G loss: 1.053729]\n",
      "epoch:15 step:14263 [D loss: 0.373716, acc.: 96.09%] [G loss: 1.052484]\n",
      "epoch:15 step:14264 [D loss: 0.462223, acc.: 76.56%] [G loss: 0.775963]\n",
      "epoch:15 step:14265 [D loss: 1.021228, acc.: 15.62%] [G loss: 1.516799]\n",
      "epoch:15 step:14266 [D loss: 0.941688, acc.: 33.59%] [G loss: 0.845666]\n",
      "epoch:15 step:14267 [D loss: 0.851399, acc.: 40.62%] [G loss: 1.119379]\n",
      "epoch:15 step:14268 [D loss: 0.787121, acc.: 44.53%] [G loss: 0.860844]\n",
      "epoch:15 step:14269 [D loss: 0.809780, acc.: 46.09%] [G loss: 1.083170]\n",
      "epoch:15 step:14270 [D loss: 0.849199, acc.: 33.59%] [G loss: 0.796076]\n",
      "epoch:15 step:14271 [D loss: 0.714836, acc.: 55.47%] [G loss: 1.006042]\n",
      "epoch:15 step:14272 [D loss: 0.635976, acc.: 69.53%] [G loss: 0.746072]\n",
      "epoch:15 step:14273 [D loss: 0.543452, acc.: 75.78%] [G loss: 1.145158]\n",
      "epoch:15 step:14274 [D loss: 0.548034, acc.: 80.47%] [G loss: 0.883001]\n",
      "epoch:15 step:14275 [D loss: 0.608564, acc.: 69.53%] [G loss: 0.851959]\n",
      "epoch:15 step:14276 [D loss: 0.630714, acc.: 62.50%] [G loss: 0.938672]\n",
      "epoch:15 step:14277 [D loss: 0.538047, acc.: 74.22%] [G loss: 1.111786]\n",
      "epoch:15 step:14278 [D loss: 0.666332, acc.: 58.59%] [G loss: 1.227584]\n",
      "epoch:15 step:14279 [D loss: 0.708457, acc.: 53.91%] [G loss: 0.960401]\n",
      "epoch:15 step:14280 [D loss: 0.667877, acc.: 63.28%] [G loss: 0.951938]\n",
      "epoch:15 step:14281 [D loss: 0.681308, acc.: 59.38%] [G loss: 0.984676]\n",
      "epoch:15 step:14282 [D loss: 0.685622, acc.: 57.03%] [G loss: 0.917102]\n",
      "epoch:15 step:14283 [D loss: 0.700588, acc.: 57.03%] [G loss: 1.002585]\n",
      "epoch:15 step:14284 [D loss: 0.668967, acc.: 62.50%] [G loss: 0.996696]\n",
      "epoch:15 step:14285 [D loss: 0.333025, acc.: 82.81%] [G loss: 0.958169]\n",
      "epoch:15 step:14286 [D loss: 0.465642, acc.: 75.78%] [G loss: 1.129191]\n",
      "epoch:15 step:14287 [D loss: 0.326291, acc.: 89.84%] [G loss: 1.040666]\n",
      "epoch:15 step:14288 [D loss: 0.717448, acc.: 55.47%] [G loss: 0.983118]\n",
      "epoch:15 step:14289 [D loss: 0.565444, acc.: 74.22%] [G loss: 0.993085]\n",
      "epoch:15 step:14290 [D loss: 0.356052, acc.: 87.50%] [G loss: 1.054915]\n",
      "epoch:15 step:14291 [D loss: 0.678001, acc.: 62.50%] [G loss: 1.058700]\n",
      "epoch:15 step:14292 [D loss: 0.506717, acc.: 81.25%] [G loss: 1.090815]\n",
      "epoch:15 step:14293 [D loss: 0.376617, acc.: 86.72%] [G loss: 0.977685]\n",
      "epoch:15 step:14294 [D loss: 0.659030, acc.: 60.94%] [G loss: 1.028510]\n",
      "epoch:15 step:14295 [D loss: 0.702908, acc.: 49.22%] [G loss: 1.097412]\n",
      "epoch:15 step:14296 [D loss: 0.922081, acc.: 21.09%] [G loss: 0.954239]\n",
      "epoch:15 step:14297 [D loss: 0.679456, acc.: 54.69%] [G loss: 1.065790]\n",
      "epoch:15 step:14298 [D loss: 0.591356, acc.: 68.75%] [G loss: 1.018459]\n",
      "epoch:15 step:14299 [D loss: 0.621162, acc.: 67.97%] [G loss: 0.943934]\n",
      "epoch:15 step:14300 [D loss: 0.779387, acc.: 46.88%] [G loss: 0.813018]\n",
      "epoch:15 step:14301 [D loss: 0.761392, acc.: 45.31%] [G loss: 0.867898]\n",
      "epoch:15 step:14302 [D loss: 0.649890, acc.: 64.06%] [G loss: 1.027477]\n",
      "epoch:15 step:14303 [D loss: 0.619899, acc.: 70.31%] [G loss: 1.010456]\n",
      "epoch:15 step:14304 [D loss: 0.612743, acc.: 70.31%] [G loss: 0.972699]\n",
      "epoch:15 step:14305 [D loss: 0.645247, acc.: 66.41%] [G loss: 1.000665]\n",
      "epoch:15 step:14306 [D loss: 0.649816, acc.: 64.84%] [G loss: 0.895087]\n",
      "epoch:15 step:14307 [D loss: 0.662234, acc.: 59.38%] [G loss: 0.990960]\n",
      "epoch:15 step:14308 [D loss: 0.643555, acc.: 62.50%] [G loss: 0.899805]\n",
      "epoch:15 step:14309 [D loss: 0.620571, acc.: 64.84%] [G loss: 0.766847]\n",
      "epoch:15 step:14310 [D loss: 0.332236, acc.: 92.19%] [G loss: 0.926530]\n",
      "epoch:15 step:14311 [D loss: 0.309650, acc.: 90.62%] [G loss: 0.979429]\n",
      "epoch:15 step:14312 [D loss: 0.445311, acc.: 84.38%] [G loss: 1.125652]\n",
      "epoch:15 step:14313 [D loss: 0.840062, acc.: 32.03%] [G loss: 0.940680]\n",
      "epoch:15 step:14314 [D loss: 0.324455, acc.: 86.72%] [G loss: 1.014294]\n",
      "epoch:15 step:14315 [D loss: 0.351334, acc.: 90.62%] [G loss: 1.130199]\n",
      "epoch:15 step:14316 [D loss: 0.239210, acc.: 97.66%] [G loss: 1.284989]\n",
      "epoch:15 step:14317 [D loss: 0.663617, acc.: 62.50%] [G loss: 1.207713]\n",
      "epoch:15 step:14318 [D loss: 0.571772, acc.: 73.44%] [G loss: 1.134990]\n",
      "epoch:15 step:14319 [D loss: 0.752659, acc.: 52.34%] [G loss: 1.081870]\n",
      "epoch:15 step:14320 [D loss: 0.492336, acc.: 77.34%] [G loss: 1.040792]\n",
      "epoch:15 step:14321 [D loss: 0.774553, acc.: 48.44%] [G loss: 0.959613]\n",
      "epoch:15 step:14322 [D loss: 0.677741, acc.: 57.81%] [G loss: 0.927762]\n",
      "epoch:15 step:14323 [D loss: 0.740677, acc.: 52.34%] [G loss: 0.921444]\n",
      "epoch:15 step:14324 [D loss: 0.662552, acc.: 64.06%] [G loss: 0.925407]\n",
      "epoch:15 step:14325 [D loss: 0.727937, acc.: 47.66%] [G loss: 0.862352]\n",
      "epoch:15 step:14326 [D loss: 0.601615, acc.: 65.62%] [G loss: 0.848070]\n",
      "epoch:15 step:14327 [D loss: 0.711825, acc.: 53.12%] [G loss: 0.882338]\n",
      "epoch:15 step:14328 [D loss: 0.655410, acc.: 57.81%] [G loss: 0.760917]\n",
      "epoch:15 step:14329 [D loss: 0.711146, acc.: 50.78%] [G loss: 0.918152]\n",
      "epoch:15 step:14330 [D loss: 0.675256, acc.: 54.69%] [G loss: 1.035072]\n",
      "epoch:15 step:14331 [D loss: 0.584731, acc.: 68.75%] [G loss: 0.807869]\n",
      "epoch:15 step:14332 [D loss: 0.645494, acc.: 56.25%] [G loss: 0.751579]\n",
      "epoch:15 step:14333 [D loss: 0.477104, acc.: 74.22%] [G loss: 1.074399]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14334 [D loss: 0.291492, acc.: 88.28%] [G loss: 1.113477]\n",
      "epoch:15 step:14335 [D loss: 0.717779, acc.: 53.12%] [G loss: 1.107735]\n",
      "epoch:15 step:14336 [D loss: 0.730312, acc.: 52.34%] [G loss: 1.086399]\n",
      "epoch:15 step:14337 [D loss: 0.740932, acc.: 44.53%] [G loss: 0.717038]\n",
      "epoch:15 step:14338 [D loss: 0.796510, acc.: 43.75%] [G loss: 0.912547]\n",
      "epoch:15 step:14339 [D loss: 0.555611, acc.: 78.91%] [G loss: 0.939108]\n",
      "epoch:15 step:14340 [D loss: 0.869676, acc.: 41.41%] [G loss: 1.032362]\n",
      "epoch:15 step:14341 [D loss: 0.537042, acc.: 81.25%] [G loss: 0.946103]\n",
      "epoch:15 step:14342 [D loss: 0.390243, acc.: 89.84%] [G loss: 1.188233]\n",
      "epoch:15 step:14343 [D loss: 0.288085, acc.: 93.75%] [G loss: 1.025264]\n",
      "epoch:15 step:14344 [D loss: 0.264783, acc.: 96.88%] [G loss: 1.121095]\n",
      "epoch:15 step:14345 [D loss: 0.533353, acc.: 80.47%] [G loss: 0.780751]\n",
      "epoch:15 step:14346 [D loss: 0.675674, acc.: 60.16%] [G loss: 1.151239]\n",
      "epoch:15 step:14347 [D loss: 0.303193, acc.: 93.75%] [G loss: 1.233086]\n",
      "epoch:15 step:14348 [D loss: 0.475082, acc.: 85.16%] [G loss: 1.130520]\n",
      "epoch:15 step:14349 [D loss: 0.767860, acc.: 50.78%] [G loss: 1.177129]\n",
      "epoch:15 step:14350 [D loss: 0.837150, acc.: 46.09%] [G loss: 1.157612]\n",
      "epoch:15 step:14351 [D loss: 0.748569, acc.: 51.56%] [G loss: 1.071644]\n",
      "epoch:15 step:14352 [D loss: 0.830488, acc.: 30.47%] [G loss: 1.050436]\n",
      "epoch:15 step:14353 [D loss: 0.686845, acc.: 53.91%] [G loss: 0.995740]\n",
      "epoch:15 step:14354 [D loss: 0.677680, acc.: 60.94%] [G loss: 1.012198]\n",
      "epoch:15 step:14355 [D loss: 0.732842, acc.: 53.12%] [G loss: 0.957956]\n",
      "epoch:15 step:14356 [D loss: 0.733691, acc.: 53.12%] [G loss: 1.006519]\n",
      "epoch:15 step:14357 [D loss: 0.673287, acc.: 59.38%] [G loss: 0.940442]\n",
      "epoch:15 step:14358 [D loss: 0.664253, acc.: 59.38%] [G loss: 0.920337]\n",
      "epoch:15 step:14359 [D loss: 0.681685, acc.: 60.16%] [G loss: 0.933557]\n",
      "epoch:15 step:14360 [D loss: 0.498493, acc.: 82.81%] [G loss: 0.891264]\n",
      "epoch:15 step:14361 [D loss: 0.566073, acc.: 76.56%] [G loss: 0.869977]\n",
      "epoch:15 step:14362 [D loss: 0.620209, acc.: 67.19%] [G loss: 0.715669]\n",
      "epoch:15 step:14363 [D loss: 0.518476, acc.: 82.03%] [G loss: 0.952620]\n",
      "epoch:15 step:14364 [D loss: 0.313776, acc.: 82.81%] [G loss: 0.903624]\n",
      "epoch:15 step:14365 [D loss: 0.605605, acc.: 67.19%] [G loss: 0.892881]\n",
      "epoch:15 step:14366 [D loss: 0.531752, acc.: 78.91%] [G loss: 0.429945]\n",
      "epoch:15 step:14367 [D loss: 0.272222, acc.: 96.09%] [G loss: 0.916782]\n",
      "epoch:15 step:14368 [D loss: 0.432381, acc.: 68.75%] [G loss: 1.029353]\n",
      "epoch:15 step:14369 [D loss: 0.203768, acc.: 98.44%] [G loss: 1.062460]\n",
      "epoch:15 step:14370 [D loss: 0.678486, acc.: 60.16%] [G loss: 1.095086]\n",
      "epoch:15 step:14371 [D loss: 0.736957, acc.: 55.47%] [G loss: 1.011880]\n",
      "epoch:15 step:14372 [D loss: 0.899575, acc.: 27.34%] [G loss: 0.466520]\n",
      "epoch:15 step:14373 [D loss: 0.751593, acc.: 49.22%] [G loss: 1.061705]\n",
      "epoch:15 step:14374 [D loss: 0.691600, acc.: 52.34%] [G loss: 0.809075]\n",
      "epoch:15 step:14375 [D loss: 0.982636, acc.: 16.41%] [G loss: 0.932242]\n",
      "epoch:15 step:14376 [D loss: 0.822162, acc.: 39.84%] [G loss: 1.090110]\n",
      "epoch:15 step:14377 [D loss: 0.609880, acc.: 63.28%] [G loss: 1.183787]\n",
      "epoch:15 step:14378 [D loss: 0.725206, acc.: 51.56%] [G loss: 0.878869]\n",
      "epoch:15 step:14379 [D loss: 0.773835, acc.: 44.53%] [G loss: 1.164850]\n",
      "epoch:15 step:14380 [D loss: 0.686025, acc.: 53.12%] [G loss: 1.141977]\n",
      "epoch:15 step:14381 [D loss: 0.586321, acc.: 62.50%] [G loss: 1.162819]\n",
      "epoch:15 step:14382 [D loss: 0.391704, acc.: 92.97%] [G loss: 1.164208]\n",
      "epoch:15 step:14383 [D loss: 0.415437, acc.: 93.75%] [G loss: 1.236241]\n",
      "epoch:15 step:14384 [D loss: 0.593257, acc.: 60.16%] [G loss: 1.305459]\n",
      "epoch:15 step:14385 [D loss: 0.631528, acc.: 57.03%] [G loss: 1.369010]\n",
      "epoch:15 step:14386 [D loss: 0.625907, acc.: 60.16%] [G loss: 1.181529]\n",
      "epoch:15 step:14387 [D loss: 0.612059, acc.: 61.72%] [G loss: 1.054104]\n",
      "epoch:15 step:14388 [D loss: 0.740732, acc.: 51.56%] [G loss: 1.024099]\n",
      "epoch:15 step:14389 [D loss: 0.699408, acc.: 57.81%] [G loss: 0.904613]\n",
      "epoch:15 step:14390 [D loss: 0.671226, acc.: 54.69%] [G loss: 0.855940]\n",
      "epoch:15 step:14391 [D loss: 0.709393, acc.: 55.47%] [G loss: 0.811543]\n",
      "epoch:15 step:14392 [D loss: 0.735518, acc.: 43.75%] [G loss: 0.797998]\n",
      "epoch:15 step:14393 [D loss: 0.578796, acc.: 81.25%] [G loss: 0.766143]\n",
      "epoch:15 step:14394 [D loss: 0.586092, acc.: 69.53%] [G loss: 0.759550]\n",
      "epoch:15 step:14395 [D loss: 0.590028, acc.: 72.66%] [G loss: 1.193267]\n",
      "epoch:15 step:14396 [D loss: 0.691433, acc.: 53.12%] [G loss: 0.858134]\n",
      "epoch:15 step:14397 [D loss: 0.844583, acc.: 39.06%] [G loss: 0.807949]\n",
      "epoch:15 step:14398 [D loss: 0.781460, acc.: 46.09%] [G loss: 0.834017]\n",
      "epoch:15 step:14399 [D loss: 0.751021, acc.: 41.41%] [G loss: 0.696846]\n",
      "epoch:15 step:14400 [D loss: 0.706903, acc.: 48.44%] [G loss: 0.779351]\n",
      "##############\n",
      "[4.61073648 2.64593476 6.65997724 5.83252331 4.31986698 6.02561515\n",
      " 5.34818636 5.403275   5.90280933 5.04275924]\n",
      "##########\n",
      "epoch:15 step:14401 [D loss: 0.590126, acc.: 62.50%] [G loss: 0.871520]\n",
      "epoch:15 step:14402 [D loss: 0.524577, acc.: 78.91%] [G loss: 0.837776]\n",
      "epoch:15 step:14403 [D loss: 0.702553, acc.: 52.34%] [G loss: 0.885181]\n",
      "epoch:15 step:14404 [D loss: 0.591892, acc.: 75.00%] [G loss: 0.916892]\n",
      "epoch:15 step:14405 [D loss: 0.741979, acc.: 44.53%] [G loss: 0.856831]\n",
      "epoch:15 step:14406 [D loss: 0.541860, acc.: 80.47%] [G loss: 0.725194]\n",
      "epoch:15 step:14407 [D loss: 0.601996, acc.: 63.28%] [G loss: 0.772863]\n",
      "epoch:15 step:14408 [D loss: 0.524166, acc.: 84.38%] [G loss: 0.860849]\n",
      "epoch:15 step:14409 [D loss: 0.584808, acc.: 72.66%] [G loss: 0.875307]\n",
      "epoch:15 step:14410 [D loss: 0.645855, acc.: 65.62%] [G loss: 0.887549]\n",
      "epoch:15 step:14411 [D loss: 0.699902, acc.: 52.34%] [G loss: 0.866494]\n",
      "epoch:15 step:14412 [D loss: 0.505783, acc.: 86.72%] [G loss: 0.798263]\n",
      "epoch:15 step:14413 [D loss: 0.530577, acc.: 82.81%] [G loss: 0.993748]\n",
      "epoch:15 step:14414 [D loss: 0.489212, acc.: 85.16%] [G loss: 0.892773]\n",
      "epoch:15 step:14415 [D loss: 0.693503, acc.: 54.69%] [G loss: 0.890811]\n",
      "epoch:15 step:14416 [D loss: 0.693816, acc.: 57.03%] [G loss: 0.936548]\n",
      "epoch:15 step:14417 [D loss: 0.845873, acc.: 32.81%] [G loss: 0.935124]\n",
      "epoch:15 step:14418 [D loss: 0.747647, acc.: 47.66%] [G loss: 0.760771]\n",
      "epoch:15 step:14419 [D loss: 0.716738, acc.: 49.22%] [G loss: 0.678393]\n",
      "epoch:15 step:14420 [D loss: 0.636552, acc.: 67.97%] [G loss: 0.858330]\n",
      "epoch:15 step:14421 [D loss: 0.374378, acc.: 82.81%] [G loss: 0.871117]\n",
      "epoch:15 step:14422 [D loss: 0.758176, acc.: 40.62%] [G loss: 0.774504]\n",
      "epoch:15 step:14423 [D loss: 0.763165, acc.: 39.06%] [G loss: 0.845898]\n",
      "epoch:15 step:14424 [D loss: 0.569122, acc.: 75.78%] [G loss: 0.922495]\n",
      "epoch:15 step:14425 [D loss: 0.534512, acc.: 81.25%] [G loss: 0.897327]\n",
      "epoch:15 step:14426 [D loss: 0.447220, acc.: 78.12%] [G loss: 0.841075]\n",
      "epoch:15 step:14427 [D loss: 0.578407, acc.: 72.66%] [G loss: 0.846207]\n",
      "epoch:15 step:14428 [D loss: 0.748917, acc.: 44.53%] [G loss: 0.789963]\n",
      "epoch:15 step:14429 [D loss: 0.678059, acc.: 61.72%] [G loss: 0.864876]\n",
      "epoch:15 step:14430 [D loss: 0.712544, acc.: 51.56%] [G loss: 0.852264]\n",
      "epoch:15 step:14431 [D loss: 0.778356, acc.: 38.28%] [G loss: 0.697029]\n",
      "epoch:15 step:14432 [D loss: 0.527523, acc.: 70.31%] [G loss: 0.776830]\n",
      "epoch:15 step:14433 [D loss: 0.529399, acc.: 83.59%] [G loss: 0.839926]\n",
      "epoch:15 step:14434 [D loss: 0.708344, acc.: 52.34%] [G loss: 0.885850]\n",
      "epoch:15 step:14435 [D loss: 0.538929, acc.: 70.31%] [G loss: 0.657923]\n",
      "epoch:15 step:14436 [D loss: 0.569993, acc.: 75.78%] [G loss: 0.849901]\n",
      "epoch:15 step:14437 [D loss: 0.683760, acc.: 51.56%] [G loss: 0.654488]\n",
      "epoch:15 step:14438 [D loss: 0.748066, acc.: 42.19%] [G loss: 0.610177]\n",
      "epoch:15 step:14439 [D loss: 0.680654, acc.: 53.91%] [G loss: 0.780308]\n",
      "epoch:15 step:14440 [D loss: 0.712234, acc.: 47.66%] [G loss: 0.660707]\n",
      "epoch:15 step:14441 [D loss: 0.735121, acc.: 48.44%] [G loss: 0.635822]\n",
      "epoch:15 step:14442 [D loss: 0.876383, acc.: 35.94%] [G loss: 1.017058]\n",
      "epoch:15 step:14443 [D loss: 0.718803, acc.: 52.34%] [G loss: 0.942345]\n",
      "epoch:15 step:14444 [D loss: 0.602446, acc.: 69.53%] [G loss: 0.945951]\n",
      "epoch:15 step:14445 [D loss: 0.565640, acc.: 72.66%] [G loss: 1.029942]\n",
      "epoch:15 step:14446 [D loss: 0.631491, acc.: 64.84%] [G loss: 0.736359]\n",
      "epoch:15 step:14447 [D loss: 0.703069, acc.: 53.91%] [G loss: 0.945890]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14448 [D loss: 0.466717, acc.: 73.44%] [G loss: 1.009958]\n",
      "epoch:15 step:14449 [D loss: 0.687025, acc.: 53.12%] [G loss: 0.960402]\n",
      "epoch:15 step:14450 [D loss: 0.676664, acc.: 56.25%] [G loss: 0.938632]\n",
      "epoch:15 step:14451 [D loss: 0.303638, acc.: 86.72%] [G loss: 1.019709]\n",
      "epoch:15 step:14452 [D loss: 0.250882, acc.: 92.97%] [G loss: 0.983982]\n",
      "epoch:15 step:14453 [D loss: 0.221608, acc.: 97.66%] [G loss: 1.082214]\n",
      "epoch:15 step:14454 [D loss: 0.219431, acc.: 93.75%] [G loss: 1.340838]\n",
      "epoch:15 step:14455 [D loss: 0.259390, acc.: 90.62%] [G loss: 1.376900]\n",
      "epoch:15 step:14456 [D loss: 0.248819, acc.: 95.31%] [G loss: 1.481720]\n",
      "epoch:15 step:14457 [D loss: 0.164948, acc.: 98.44%] [G loss: 1.508441]\n",
      "epoch:15 step:14458 [D loss: 0.299202, acc.: 98.44%] [G loss: 0.730621]\n",
      "epoch:15 step:14459 [D loss: 0.193617, acc.: 99.22%] [G loss: 2.124402]\n",
      "epoch:15 step:14460 [D loss: 0.149542, acc.: 100.00%] [G loss: 1.641216]\n",
      "epoch:15 step:14461 [D loss: 0.562658, acc.: 64.84%] [G loss: 1.664090]\n",
      "epoch:15 step:14462 [D loss: 0.138863, acc.: 100.00%] [G loss: 2.047131]\n",
      "epoch:15 step:14463 [D loss: 0.500148, acc.: 79.69%] [G loss: 1.799365]\n",
      "epoch:15 step:14464 [D loss: 0.149959, acc.: 98.44%] [G loss: 1.853838]\n",
      "epoch:15 step:14465 [D loss: 0.262448, acc.: 95.31%] [G loss: 1.762401]\n",
      "epoch:15 step:14466 [D loss: 1.079894, acc.: 46.09%] [G loss: 1.139440]\n",
      "epoch:15 step:14467 [D loss: 0.334733, acc.: 96.09%] [G loss: 0.093816]\n",
      "epoch:15 step:14468 [D loss: 0.351231, acc.: 83.59%] [G loss: 1.499073]\n",
      "epoch:15 step:14469 [D loss: 1.634030, acc.: 50.00%] [G loss: 1.717552]\n",
      "epoch:15 step:14470 [D loss: 0.353681, acc.: 90.62%] [G loss: 1.562742]\n",
      "epoch:15 step:14471 [D loss: 0.822042, acc.: 42.97%] [G loss: 1.596763]\n",
      "epoch:15 step:14472 [D loss: 0.339900, acc.: 92.19%] [G loss: 1.505821]\n",
      "epoch:15 step:14473 [D loss: 0.243590, acc.: 98.44%] [G loss: 0.749624]\n",
      "epoch:15 step:14474 [D loss: 0.201242, acc.: 100.00%] [G loss: 0.965312]\n",
      "epoch:15 step:14475 [D loss: 0.642957, acc.: 60.16%] [G loss: 0.410512]\n",
      "epoch:15 step:14476 [D loss: 1.694234, acc.: 3.91%] [G loss: 0.582868]\n",
      "epoch:15 step:14477 [D loss: 0.960201, acc.: 38.28%] [G loss: 1.533427]\n",
      "epoch:15 step:14478 [D loss: 0.916498, acc.: 32.03%] [G loss: 1.304468]\n",
      "epoch:15 step:14479 [D loss: 0.462247, acc.: 83.59%] [G loss: 0.898894]\n",
      "epoch:15 step:14480 [D loss: 0.623625, acc.: 66.41%] [G loss: 0.970262]\n",
      "epoch:15 step:14481 [D loss: 1.042292, acc.: 17.19%] [G loss: 0.829779]\n",
      "epoch:15 step:14482 [D loss: 0.880024, acc.: 33.59%] [G loss: 1.187304]\n",
      "epoch:15 step:14483 [D loss: 0.591260, acc.: 73.44%] [G loss: 1.045074]\n",
      "epoch:15 step:14484 [D loss: 0.840257, acc.: 39.06%] [G loss: 1.106677]\n",
      "epoch:15 step:14485 [D loss: 0.627304, acc.: 67.19%] [G loss: 0.993694]\n",
      "epoch:15 step:14486 [D loss: 0.950374, acc.: 28.91%] [G loss: 1.049470]\n",
      "epoch:15 step:14487 [D loss: 0.764248, acc.: 51.56%] [G loss: 1.254936]\n",
      "epoch:15 step:14488 [D loss: 0.726675, acc.: 53.91%] [G loss: 1.158494]\n",
      "epoch:15 step:14489 [D loss: 0.738794, acc.: 50.00%] [G loss: 1.110190]\n",
      "epoch:15 step:14490 [D loss: 0.665516, acc.: 56.25%] [G loss: 0.947087]\n",
      "epoch:15 step:14491 [D loss: 0.742351, acc.: 55.47%] [G loss: 1.169982]\n",
      "epoch:15 step:14492 [D loss: 0.752886, acc.: 44.53%] [G loss: 1.036481]\n",
      "epoch:15 step:14493 [D loss: 0.825683, acc.: 42.97%] [G loss: 0.987079]\n",
      "epoch:15 step:14494 [D loss: 0.693081, acc.: 54.69%] [G loss: 1.069991]\n",
      "epoch:15 step:14495 [D loss: 0.699427, acc.: 56.25%] [G loss: 1.170227]\n",
      "epoch:15 step:14496 [D loss: 0.629019, acc.: 58.59%] [G loss: 1.207864]\n",
      "epoch:15 step:14497 [D loss: 0.632314, acc.: 63.28%] [G loss: 1.161091]\n",
      "epoch:15 step:14498 [D loss: 0.585539, acc.: 64.84%] [G loss: 1.000357]\n",
      "epoch:15 step:14499 [D loss: 0.616179, acc.: 60.94%] [G loss: 1.067062]\n",
      "epoch:15 step:14500 [D loss: 0.660156, acc.: 58.59%] [G loss: 1.061227]\n",
      "epoch:15 step:14501 [D loss: 0.673111, acc.: 59.38%] [G loss: 1.029468]\n",
      "epoch:15 step:14502 [D loss: 0.657584, acc.: 66.41%] [G loss: 0.910821]\n",
      "epoch:15 step:14503 [D loss: 0.646456, acc.: 60.94%] [G loss: 0.918057]\n",
      "epoch:15 step:14504 [D loss: 0.586971, acc.: 74.22%] [G loss: 0.954521]\n",
      "epoch:15 step:14505 [D loss: 0.560964, acc.: 78.91%] [G loss: 0.977874]\n",
      "epoch:15 step:14506 [D loss: 0.490654, acc.: 85.94%] [G loss: 1.166000]\n",
      "epoch:15 step:14507 [D loss: 0.462384, acc.: 88.28%] [G loss: 1.128548]\n",
      "epoch:15 step:14508 [D loss: 0.485963, acc.: 82.81%] [G loss: 1.219716]\n",
      "epoch:15 step:14509 [D loss: 0.489964, acc.: 83.59%] [G loss: 1.273709]\n",
      "epoch:15 step:14510 [D loss: 0.487715, acc.: 78.12%] [G loss: 1.191286]\n",
      "epoch:15 step:14511 [D loss: 0.339418, acc.: 91.41%] [G loss: 1.364220]\n",
      "epoch:15 step:14512 [D loss: 0.431032, acc.: 82.03%] [G loss: 1.556039]\n",
      "epoch:15 step:14513 [D loss: 0.601691, acc.: 64.84%] [G loss: 1.415065]\n",
      "epoch:15 step:14514 [D loss: 0.567856, acc.: 67.97%] [G loss: 0.872464]\n",
      "epoch:15 step:14515 [D loss: 0.572565, acc.: 67.97%] [G loss: 1.096558]\n",
      "epoch:15 step:14516 [D loss: 0.922870, acc.: 49.22%] [G loss: 0.803748]\n",
      "epoch:15 step:14517 [D loss: 0.876923, acc.: 46.88%] [G loss: 0.682846]\n",
      "epoch:15 step:14518 [D loss: 0.781833, acc.: 49.22%] [G loss: 0.829068]\n",
      "epoch:15 step:14519 [D loss: 0.503062, acc.: 76.56%] [G loss: 0.764752]\n",
      "epoch:15 step:14520 [D loss: 0.542340, acc.: 77.34%] [G loss: 0.991582]\n",
      "epoch:15 step:14521 [D loss: 0.610398, acc.: 68.75%] [G loss: 0.964410]\n",
      "epoch:15 step:14522 [D loss: 0.513390, acc.: 78.91%] [G loss: 1.204734]\n",
      "epoch:15 step:14523 [D loss: 0.464827, acc.: 79.69%] [G loss: 1.349742]\n",
      "epoch:15 step:14524 [D loss: 0.391468, acc.: 92.97%] [G loss: 1.218309]\n",
      "epoch:15 step:14525 [D loss: 0.347300, acc.: 90.62%] [G loss: 1.132869]\n",
      "epoch:15 step:14526 [D loss: 0.365003, acc.: 92.97%] [G loss: 1.804220]\n",
      "epoch:15 step:14527 [D loss: 0.611451, acc.: 63.28%] [G loss: 1.131998]\n",
      "epoch:15 step:14528 [D loss: 1.346887, acc.: 28.91%] [G loss: 0.949489]\n",
      "epoch:15 step:14529 [D loss: 0.960192, acc.: 28.91%] [G loss: 0.823040]\n",
      "epoch:15 step:14530 [D loss: 0.756172, acc.: 49.22%] [G loss: 0.736743]\n",
      "epoch:15 step:14531 [D loss: 0.749209, acc.: 46.88%] [G loss: 0.617687]\n",
      "epoch:15 step:14532 [D loss: 0.772294, acc.: 47.66%] [G loss: 0.665377]\n",
      "epoch:15 step:14533 [D loss: 0.722452, acc.: 49.22%] [G loss: 0.357685]\n",
      "epoch:15 step:14534 [D loss: 0.597196, acc.: 65.62%] [G loss: 0.736915]\n",
      "epoch:15 step:14535 [D loss: 0.520993, acc.: 73.44%] [G loss: 0.732479]\n",
      "epoch:15 step:14536 [D loss: 0.589800, acc.: 62.50%] [G loss: 0.738787]\n",
      "epoch:15 step:14537 [D loss: 0.911412, acc.: 32.81%] [G loss: 0.716945]\n",
      "epoch:15 step:14538 [D loss: 0.793831, acc.: 39.84%] [G loss: 0.901107]\n",
      "epoch:15 step:14539 [D loss: 0.770485, acc.: 39.06%] [G loss: 0.971834]\n",
      "epoch:15 step:14540 [D loss: 0.701667, acc.: 45.31%] [G loss: 1.054607]\n",
      "epoch:15 step:14541 [D loss: 0.667435, acc.: 53.91%] [G loss: 0.947572]\n",
      "epoch:15 step:14542 [D loss: 0.703052, acc.: 47.66%] [G loss: 1.007931]\n",
      "epoch:15 step:14543 [D loss: 0.675707, acc.: 59.38%] [G loss: 0.972924]\n",
      "epoch:15 step:14544 [D loss: 0.714339, acc.: 56.25%] [G loss: 1.032784]\n",
      "epoch:15 step:14545 [D loss: 0.688906, acc.: 54.69%] [G loss: 1.019863]\n",
      "epoch:15 step:14546 [D loss: 0.694679, acc.: 51.56%] [G loss: 0.787769]\n",
      "epoch:15 step:14547 [D loss: 0.707749, acc.: 46.88%] [G loss: 0.854720]\n",
      "epoch:15 step:14548 [D loss: 0.680071, acc.: 53.91%] [G loss: 0.843254]\n",
      "epoch:15 step:14549 [D loss: 0.651582, acc.: 64.06%] [G loss: 0.890518]\n",
      "epoch:15 step:14550 [D loss: 0.672500, acc.: 58.59%] [G loss: 0.861588]\n",
      "epoch:15 step:14551 [D loss: 0.678308, acc.: 53.91%] [G loss: 0.928836]\n",
      "epoch:15 step:14552 [D loss: 0.590117, acc.: 71.09%] [G loss: 1.018644]\n",
      "epoch:15 step:14553 [D loss: 0.548554, acc.: 74.22%] [G loss: 1.142858]\n",
      "epoch:15 step:14554 [D loss: 0.531016, acc.: 79.69%] [G loss: 1.117387]\n",
      "epoch:15 step:14555 [D loss: 0.585970, acc.: 67.19%] [G loss: 1.201294]\n",
      "epoch:15 step:14556 [D loss: 0.652080, acc.: 57.81%] [G loss: 1.086641]\n",
      "epoch:15 step:14557 [D loss: 0.640955, acc.: 59.38%] [G loss: 0.917847]\n",
      "epoch:15 step:14558 [D loss: 0.747747, acc.: 60.16%] [G loss: 0.913601]\n",
      "epoch:15 step:14559 [D loss: 0.622512, acc.: 70.31%] [G loss: 0.813815]\n",
      "epoch:15 step:14560 [D loss: 0.592389, acc.: 70.31%] [G loss: 0.869992]\n",
      "epoch:15 step:14561 [D loss: 0.649782, acc.: 64.06%] [G loss: 0.657655]\n",
      "epoch:15 step:14562 [D loss: 0.657346, acc.: 60.16%] [G loss: 0.794793]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14563 [D loss: 0.748379, acc.: 56.25%] [G loss: 0.837377]\n",
      "epoch:15 step:14564 [D loss: 0.678529, acc.: 56.25%] [G loss: 0.838742]\n",
      "epoch:15 step:14565 [D loss: 0.685470, acc.: 53.91%] [G loss: 0.824107]\n",
      "epoch:15 step:14566 [D loss: 0.710801, acc.: 53.91%] [G loss: 0.871702]\n",
      "epoch:15 step:14567 [D loss: 0.569849, acc.: 78.91%] [G loss: 0.868915]\n",
      "epoch:15 step:14568 [D loss: 0.579375, acc.: 72.66%] [G loss: 0.902287]\n",
      "epoch:15 step:14569 [D loss: 0.575143, acc.: 70.31%] [G loss: 1.020940]\n",
      "epoch:15 step:14570 [D loss: 0.595319, acc.: 64.84%] [G loss: 0.995080]\n",
      "epoch:15 step:14571 [D loss: 0.633977, acc.: 71.09%] [G loss: 0.978295]\n",
      "epoch:15 step:14572 [D loss: 0.649797, acc.: 63.28%] [G loss: 0.914479]\n",
      "epoch:15 step:14573 [D loss: 0.623708, acc.: 60.94%] [G loss: 0.973465]\n",
      "epoch:15 step:14574 [D loss: 0.669667, acc.: 60.16%] [G loss: 0.921171]\n",
      "epoch:15 step:14575 [D loss: 0.625032, acc.: 60.94%] [G loss: 1.080934]\n",
      "epoch:15 step:14576 [D loss: 0.664380, acc.: 60.16%] [G loss: 0.926339]\n",
      "epoch:15 step:14577 [D loss: 0.623302, acc.: 65.62%] [G loss: 1.012019]\n",
      "epoch:15 step:14578 [D loss: 0.642245, acc.: 67.19%] [G loss: 0.977338]\n",
      "epoch:15 step:14579 [D loss: 0.566738, acc.: 77.34%] [G loss: 0.992922]\n",
      "epoch:15 step:14580 [D loss: 0.678092, acc.: 56.25%] [G loss: 1.011012]\n",
      "epoch:15 step:14581 [D loss: 0.633686, acc.: 62.50%] [G loss: 0.927225]\n",
      "epoch:15 step:14582 [D loss: 0.591848, acc.: 75.00%] [G loss: 0.886876]\n",
      "epoch:15 step:14583 [D loss: 0.734079, acc.: 54.69%] [G loss: 0.950803]\n",
      "epoch:15 step:14584 [D loss: 0.696982, acc.: 57.03%] [G loss: 0.903752]\n",
      "epoch:15 step:14585 [D loss: 0.544424, acc.: 78.12%] [G loss: 0.922325]\n",
      "epoch:15 step:14586 [D loss: 0.700980, acc.: 52.34%] [G loss: 0.880077]\n",
      "epoch:15 step:14587 [D loss: 0.675398, acc.: 60.16%] [G loss: 0.855149]\n",
      "epoch:15 step:14588 [D loss: 0.628301, acc.: 60.94%] [G loss: 0.854424]\n",
      "epoch:15 step:14589 [D loss: 0.658844, acc.: 60.94%] [G loss: 0.888802]\n",
      "epoch:15 step:14590 [D loss: 0.585998, acc.: 66.41%] [G loss: 0.776035]\n",
      "epoch:15 step:14591 [D loss: 0.443529, acc.: 86.72%] [G loss: 0.819074]\n",
      "epoch:15 step:14592 [D loss: 0.552626, acc.: 72.66%] [G loss: 0.909833]\n",
      "epoch:15 step:14593 [D loss: 0.511130, acc.: 82.03%] [G loss: 0.945543]\n",
      "epoch:15 step:14594 [D loss: 0.427927, acc.: 85.94%] [G loss: 1.048037]\n",
      "epoch:15 step:14595 [D loss: 0.468549, acc.: 82.03%] [G loss: 1.219927]\n",
      "epoch:15 step:14596 [D loss: 0.540589, acc.: 71.88%] [G loss: 0.824275]\n",
      "epoch:15 step:14597 [D loss: 0.785946, acc.: 53.12%] [G loss: 1.044599]\n",
      "epoch:15 step:14598 [D loss: 0.664568, acc.: 60.16%] [G loss: 1.048653]\n",
      "epoch:15 step:14599 [D loss: 0.974803, acc.: 26.56%] [G loss: 0.912805]\n",
      "epoch:15 step:14600 [D loss: 0.626738, acc.: 64.84%] [G loss: 0.927958]\n",
      "##############\n",
      "[4.28809193 2.69104537 6.53902425 5.6676811  4.93733393 6.22968608\n",
      " 5.5639954  5.6592751  5.72560444 4.96416365]\n",
      "##########\n",
      "epoch:15 step:14601 [D loss: 0.649885, acc.: 65.62%] [G loss: 0.992525]\n",
      "epoch:15 step:14602 [D loss: 0.633869, acc.: 64.06%] [G loss: 0.904308]\n",
      "epoch:15 step:14603 [D loss: 0.601629, acc.: 67.97%] [G loss: 1.015268]\n",
      "epoch:15 step:14604 [D loss: 0.607531, acc.: 68.75%] [G loss: 0.988924]\n",
      "epoch:15 step:14605 [D loss: 0.413791, acc.: 87.50%] [G loss: 0.960113]\n",
      "epoch:15 step:14606 [D loss: 0.616621, acc.: 64.06%] [G loss: 0.975413]\n",
      "epoch:15 step:14607 [D loss: 0.558096, acc.: 75.78%] [G loss: 0.919626]\n",
      "epoch:15 step:14608 [D loss: 0.601392, acc.: 72.66%] [G loss: 0.970240]\n",
      "epoch:15 step:14609 [D loss: 0.460749, acc.: 82.81%] [G loss: 0.947498]\n",
      "epoch:15 step:14610 [D loss: 0.542876, acc.: 74.22%] [G loss: 0.741011]\n",
      "epoch:15 step:14611 [D loss: 0.567568, acc.: 67.97%] [G loss: 0.980040]\n",
      "epoch:15 step:14612 [D loss: 0.403048, acc.: 96.09%] [G loss: 0.888827]\n",
      "epoch:15 step:14613 [D loss: 0.529392, acc.: 77.34%] [G loss: 0.956703]\n",
      "epoch:15 step:14614 [D loss: 0.665128, acc.: 57.03%] [G loss: 0.387078]\n",
      "epoch:15 step:14615 [D loss: 0.591540, acc.: 75.00%] [G loss: 0.997921]\n",
      "epoch:15 step:14616 [D loss: 0.511809, acc.: 83.59%] [G loss: 0.971939]\n",
      "epoch:15 step:14617 [D loss: 0.716638, acc.: 62.50%] [G loss: 0.863336]\n",
      "epoch:15 step:14618 [D loss: 0.723634, acc.: 54.69%] [G loss: 0.694744]\n",
      "epoch:15 step:14619 [D loss: 0.703167, acc.: 54.69%] [G loss: 0.896338]\n",
      "epoch:15 step:14620 [D loss: 0.569261, acc.: 75.00%] [G loss: 0.903731]\n",
      "epoch:15 step:14621 [D loss: 0.527951, acc.: 67.97%] [G loss: 1.033169]\n",
      "epoch:15 step:14622 [D loss: 0.354075, acc.: 88.28%] [G loss: 1.078838]\n",
      "epoch:15 step:14623 [D loss: 0.755031, acc.: 51.56%] [G loss: 1.096612]\n",
      "epoch:15 step:14624 [D loss: 0.708712, acc.: 54.69%] [G loss: 0.317041]\n",
      "epoch:15 step:14625 [D loss: 0.597389, acc.: 69.53%] [G loss: 1.003319]\n",
      "epoch:15 step:14626 [D loss: 0.676497, acc.: 56.25%] [G loss: 0.934402]\n",
      "epoch:15 step:14627 [D loss: 0.614179, acc.: 65.62%] [G loss: 0.932225]\n",
      "epoch:15 step:14628 [D loss: 0.429308, acc.: 87.50%] [G loss: 1.186662]\n",
      "epoch:15 step:14629 [D loss: 0.535953, acc.: 73.44%] [G loss: 1.020285]\n",
      "epoch:15 step:14630 [D loss: 0.626034, acc.: 64.84%] [G loss: 1.037788]\n",
      "epoch:15 step:14631 [D loss: 0.347844, acc.: 89.84%] [G loss: 1.219898]\n",
      "epoch:15 step:14632 [D loss: 0.278033, acc.: 96.88%] [G loss: 1.327742]\n",
      "epoch:15 step:14633 [D loss: 0.312924, acc.: 92.19%] [G loss: 1.535842]\n",
      "epoch:15 step:14634 [D loss: 0.290484, acc.: 92.97%] [G loss: 1.413608]\n",
      "epoch:15 step:14635 [D loss: 0.738383, acc.: 53.12%] [G loss: 1.146273]\n",
      "epoch:15 step:14636 [D loss: 0.698730, acc.: 54.69%] [G loss: 1.034188]\n",
      "epoch:15 step:14637 [D loss: 0.714896, acc.: 50.78%] [G loss: 1.003866]\n",
      "epoch:15 step:14638 [D loss: 0.862254, acc.: 37.50%] [G loss: 0.906654]\n",
      "epoch:15 step:14639 [D loss: 0.857804, acc.: 39.06%] [G loss: 0.932279]\n",
      "epoch:15 step:14640 [D loss: 0.794102, acc.: 45.31%] [G loss: 1.049364]\n",
      "epoch:15 step:14641 [D loss: 0.698799, acc.: 53.12%] [G loss: 0.744986]\n",
      "epoch:15 step:14642 [D loss: 0.425187, acc.: 75.78%] [G loss: 1.075269]\n",
      "epoch:15 step:14643 [D loss: 0.316299, acc.: 88.28%] [G loss: 1.529382]\n",
      "epoch:15 step:14644 [D loss: 0.283654, acc.: 90.62%] [G loss: 1.199580]\n",
      "epoch:15 step:14645 [D loss: 0.778960, acc.: 53.12%] [G loss: 1.275298]\n",
      "epoch:15 step:14646 [D loss: 0.763601, acc.: 49.22%] [G loss: 0.952440]\n",
      "epoch:15 step:14647 [D loss: 0.670867, acc.: 57.03%] [G loss: 1.022551]\n",
      "epoch:15 step:14648 [D loss: 0.731839, acc.: 42.97%] [G loss: 1.095267]\n",
      "epoch:15 step:14649 [D loss: 0.731283, acc.: 50.00%] [G loss: 1.081868]\n",
      "epoch:15 step:14650 [D loss: 0.447680, acc.: 87.50%] [G loss: 0.986937]\n",
      "epoch:15 step:14651 [D loss: 0.816955, acc.: 44.53%] [G loss: 1.083509]\n",
      "epoch:15 step:14652 [D loss: 0.948442, acc.: 24.22%] [G loss: 1.007280]\n",
      "epoch:15 step:14653 [D loss: 0.639561, acc.: 64.06%] [G loss: 1.108647]\n",
      "epoch:15 step:14654 [D loss: 0.675265, acc.: 55.47%] [G loss: 0.846449]\n",
      "epoch:15 step:14655 [D loss: 0.427759, acc.: 86.72%] [G loss: 0.993634]\n",
      "epoch:15 step:14656 [D loss: 0.417062, acc.: 87.50%] [G loss: 1.038430]\n",
      "epoch:15 step:14657 [D loss: 0.622624, acc.: 63.28%] [G loss: 1.040715]\n",
      "epoch:15 step:14658 [D loss: 0.742461, acc.: 50.00%] [G loss: 1.065698]\n",
      "epoch:15 step:14659 [D loss: 0.462997, acc.: 66.41%] [G loss: 1.017237]\n",
      "epoch:15 step:14660 [D loss: 0.667717, acc.: 58.59%] [G loss: 1.149716]\n",
      "epoch:15 step:14661 [D loss: 0.740840, acc.: 49.22%] [G loss: 1.008296]\n",
      "epoch:15 step:14662 [D loss: 0.659625, acc.: 59.38%] [G loss: 0.979623]\n",
      "epoch:15 step:14663 [D loss: 0.680879, acc.: 61.72%] [G loss: 0.945536]\n",
      "epoch:15 step:14664 [D loss: 0.528371, acc.: 82.81%] [G loss: 0.927810]\n",
      "epoch:15 step:14665 [D loss: 0.772578, acc.: 38.28%] [G loss: 0.924123]\n",
      "epoch:15 step:14666 [D loss: 0.494067, acc.: 85.94%] [G loss: 0.795740]\n",
      "epoch:15 step:14667 [D loss: 0.480242, acc.: 85.94%] [G loss: 0.933943]\n",
      "epoch:15 step:14668 [D loss: 0.668030, acc.: 62.50%] [G loss: 0.898005]\n",
      "epoch:15 step:14669 [D loss: 0.700157, acc.: 52.34%] [G loss: 0.863471]\n",
      "epoch:15 step:14670 [D loss: 0.834914, acc.: 43.75%] [G loss: 0.969849]\n",
      "epoch:15 step:14671 [D loss: 0.748785, acc.: 44.53%] [G loss: 0.963010]\n",
      "epoch:15 step:14672 [D loss: 0.630042, acc.: 62.50%] [G loss: 0.937835]\n",
      "epoch:15 step:14673 [D loss: 0.671077, acc.: 59.38%] [G loss: 0.793868]\n",
      "epoch:15 step:14674 [D loss: 0.663602, acc.: 61.72%] [G loss: 0.827293]\n",
      "epoch:15 step:14675 [D loss: 0.622433, acc.: 71.88%] [G loss: 0.717675]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14676 [D loss: 0.685190, acc.: 57.03%] [G loss: 0.899195]\n",
      "epoch:15 step:14677 [D loss: 0.648312, acc.: 59.38%] [G loss: 0.861636]\n",
      "epoch:15 step:14678 [D loss: 0.640911, acc.: 65.62%] [G loss: 0.917649]\n",
      "epoch:15 step:14679 [D loss: 0.579061, acc.: 78.12%] [G loss: 0.876108]\n",
      "epoch:15 step:14680 [D loss: 0.647018, acc.: 64.06%] [G loss: 0.852535]\n",
      "epoch:15 step:14681 [D loss: 0.674361, acc.: 56.25%] [G loss: 0.823330]\n",
      "epoch:15 step:14682 [D loss: 0.647134, acc.: 60.94%] [G loss: 0.627625]\n",
      "epoch:15 step:14683 [D loss: 0.702478, acc.: 50.78%] [G loss: 0.818473]\n",
      "epoch:15 step:14684 [D loss: 0.786287, acc.: 43.75%] [G loss: 0.732555]\n",
      "epoch:15 step:14685 [D loss: 0.701219, acc.: 52.34%] [G loss: 0.894504]\n",
      "epoch:15 step:14686 [D loss: 0.659396, acc.: 66.41%] [G loss: 0.881863]\n",
      "epoch:15 step:14687 [D loss: 0.557496, acc.: 71.88%] [G loss: 0.896126]\n",
      "epoch:15 step:14688 [D loss: 0.388579, acc.: 92.97%] [G loss: 0.703131]\n",
      "epoch:15 step:14689 [D loss: 0.495298, acc.: 85.94%] [G loss: 0.937693]\n",
      "epoch:15 step:14690 [D loss: 0.556217, acc.: 71.09%] [G loss: 0.919869]\n",
      "epoch:15 step:14691 [D loss: 0.550926, acc.: 68.75%] [G loss: 1.181995]\n",
      "epoch:15 step:14692 [D loss: 0.619694, acc.: 59.38%] [G loss: 0.751292]\n",
      "epoch:15 step:14693 [D loss: 0.761389, acc.: 45.31%] [G loss: 0.895911]\n",
      "epoch:15 step:14694 [D loss: 0.677535, acc.: 57.03%] [G loss: 1.123770]\n",
      "epoch:15 step:14695 [D loss: 0.818991, acc.: 44.53%] [G loss: 1.046392]\n",
      "epoch:15 step:14696 [D loss: 0.595034, acc.: 64.84%] [G loss: 1.009030]\n",
      "epoch:15 step:14697 [D loss: 0.892619, acc.: 28.91%] [G loss: 1.000791]\n",
      "epoch:15 step:14698 [D loss: 0.639013, acc.: 56.25%] [G loss: 1.089967]\n",
      "epoch:15 step:14699 [D loss: 0.319313, acc.: 94.53%] [G loss: 1.233054]\n",
      "epoch:15 step:14700 [D loss: 0.362292, acc.: 96.09%] [G loss: 1.199488]\n",
      "epoch:15 step:14701 [D loss: 0.272263, acc.: 97.66%] [G loss: 1.246499]\n",
      "epoch:15 step:14702 [D loss: 0.298964, acc.: 96.09%] [G loss: 1.118027]\n",
      "epoch:15 step:14703 [D loss: 0.332086, acc.: 91.41%] [G loss: 1.433876]\n",
      "epoch:15 step:14704 [D loss: 0.326467, acc.: 97.66%] [G loss: 0.966129]\n",
      "epoch:15 step:14705 [D loss: 0.154355, acc.: 100.00%] [G loss: 1.387107]\n",
      "epoch:15 step:14706 [D loss: 0.312925, acc.: 97.66%] [G loss: 1.683206]\n",
      "epoch:15 step:14707 [D loss: 0.452844, acc.: 85.94%] [G loss: 1.510914]\n",
      "epoch:15 step:14708 [D loss: 0.804414, acc.: 46.09%] [G loss: 0.640876]\n",
      "epoch:15 step:14709 [D loss: 0.685218, acc.: 51.56%] [G loss: 1.270939]\n",
      "epoch:15 step:14710 [D loss: 0.963149, acc.: 46.09%] [G loss: 0.754387]\n",
      "epoch:15 step:14711 [D loss: 0.666350, acc.: 60.94%] [G loss: 1.312856]\n",
      "epoch:15 step:14712 [D loss: 0.845392, acc.: 26.56%] [G loss: 0.379317]\n",
      "epoch:15 step:14713 [D loss: 0.813924, acc.: 47.66%] [G loss: 0.784324]\n",
      "epoch:15 step:14714 [D loss: 0.459267, acc.: 75.78%] [G loss: 1.004998]\n",
      "epoch:15 step:14715 [D loss: 0.476084, acc.: 81.25%] [G loss: 0.849758]\n",
      "epoch:15 step:14716 [D loss: 0.962752, acc.: 46.88%] [G loss: 0.908875]\n",
      "epoch:15 step:14717 [D loss: 0.891175, acc.: 39.84%] [G loss: 1.043588]\n",
      "epoch:15 step:14718 [D loss: 0.803846, acc.: 51.56%] [G loss: 1.092570]\n",
      "epoch:15 step:14719 [D loss: 0.627859, acc.: 67.97%] [G loss: 1.074053]\n",
      "epoch:15 step:14720 [D loss: 0.392178, acc.: 96.88%] [G loss: 1.102168]\n",
      "epoch:15 step:14721 [D loss: 0.803393, acc.: 41.41%] [G loss: 1.324595]\n",
      "epoch:15 step:14722 [D loss: 0.774340, acc.: 40.62%] [G loss: 1.264119]\n",
      "epoch:15 step:14723 [D loss: 0.753059, acc.: 47.66%] [G loss: 0.989604]\n",
      "epoch:15 step:14724 [D loss: 0.732715, acc.: 47.66%] [G loss: 0.968837]\n",
      "epoch:15 step:14725 [D loss: 0.756499, acc.: 47.66%] [G loss: 1.054975]\n",
      "epoch:15 step:14726 [D loss: 0.697555, acc.: 60.16%] [G loss: 1.067025]\n",
      "epoch:15 step:14727 [D loss: 0.719108, acc.: 55.47%] [G loss: 1.047092]\n",
      "epoch:15 step:14728 [D loss: 0.674265, acc.: 60.16%] [G loss: 0.950603]\n",
      "epoch:15 step:14729 [D loss: 0.686079, acc.: 54.69%] [G loss: 0.988001]\n",
      "epoch:15 step:14730 [D loss: 0.860398, acc.: 38.28%] [G loss: 1.048903]\n",
      "epoch:15 step:14731 [D loss: 0.643573, acc.: 64.84%] [G loss: 0.976495]\n",
      "epoch:15 step:14732 [D loss: 0.664382, acc.: 59.38%] [G loss: 0.939880]\n",
      "epoch:15 step:14733 [D loss: 0.700722, acc.: 53.91%] [G loss: 0.969368]\n",
      "epoch:15 step:14734 [D loss: 0.636643, acc.: 60.94%] [G loss: 0.858959]\n",
      "epoch:15 step:14735 [D loss: 0.645560, acc.: 62.50%] [G loss: 0.935002]\n",
      "epoch:15 step:14736 [D loss: 0.645105, acc.: 63.28%] [G loss: 0.795127]\n",
      "epoch:15 step:14737 [D loss: 0.554110, acc.: 82.03%] [G loss: 0.825925]\n",
      "epoch:15 step:14738 [D loss: 0.596142, acc.: 65.62%] [G loss: 0.916773]\n",
      "epoch:15 step:14739 [D loss: 0.480503, acc.: 85.94%] [G loss: 1.187920]\n",
      "epoch:15 step:14740 [D loss: 0.551598, acc.: 76.56%] [G loss: 1.238669]\n",
      "epoch:15 step:14741 [D loss: 0.435840, acc.: 82.81%] [G loss: 1.199282]\n",
      "epoch:15 step:14742 [D loss: 0.541490, acc.: 79.69%] [G loss: 1.162676]\n",
      "epoch:15 step:14743 [D loss: 0.640786, acc.: 64.06%] [G loss: 1.164949]\n",
      "epoch:15 step:14744 [D loss: 0.789282, acc.: 42.97%] [G loss: 0.977158]\n",
      "epoch:15 step:14745 [D loss: 0.722038, acc.: 54.69%] [G loss: 0.815697]\n",
      "epoch:15 step:14746 [D loss: 0.688088, acc.: 53.12%] [G loss: 0.841250]\n",
      "epoch:15 step:14747 [D loss: 0.722086, acc.: 50.78%] [G loss: 0.718481]\n",
      "epoch:15 step:14748 [D loss: 0.930640, acc.: 39.06%] [G loss: 0.760988]\n",
      "epoch:15 step:14749 [D loss: 0.635185, acc.: 60.94%] [G loss: 0.784930]\n",
      "epoch:15 step:14750 [D loss: 0.651350, acc.: 67.19%] [G loss: 0.815224]\n",
      "epoch:15 step:14751 [D loss: 0.381319, acc.: 78.12%] [G loss: 0.854541]\n",
      "epoch:15 step:14752 [D loss: 0.329369, acc.: 86.72%] [G loss: 0.595493]\n",
      "epoch:15 step:14753 [D loss: 0.339137, acc.: 89.06%] [G loss: 1.183299]\n",
      "epoch:15 step:14754 [D loss: 0.534346, acc.: 80.47%] [G loss: 1.102011]\n",
      "epoch:15 step:14755 [D loss: 0.336653, acc.: 85.94%] [G loss: 1.180840]\n",
      "epoch:15 step:14756 [D loss: 0.322173, acc.: 92.19%] [G loss: 1.299301]\n",
      "epoch:15 step:14757 [D loss: 0.269417, acc.: 97.66%] [G loss: 1.330439]\n",
      "epoch:15 step:14758 [D loss: 0.755983, acc.: 46.09%] [G loss: 1.268740]\n",
      "epoch:15 step:14759 [D loss: 0.428239, acc.: 89.84%] [G loss: 1.054996]\n",
      "epoch:15 step:14760 [D loss: 0.661511, acc.: 60.16%] [G loss: 1.216540]\n",
      "epoch:15 step:14761 [D loss: 0.388913, acc.: 85.94%] [G loss: 1.089423]\n",
      "epoch:15 step:14762 [D loss: 0.291769, acc.: 84.38%] [G loss: 1.222864]\n",
      "epoch:15 step:14763 [D loss: 0.200361, acc.: 100.00%] [G loss: 1.408116]\n",
      "epoch:15 step:14764 [D loss: 0.274108, acc.: 100.00%] [G loss: 1.449285]\n",
      "epoch:15 step:14765 [D loss: 1.152008, acc.: 14.84%] [G loss: 1.346654]\n",
      "epoch:15 step:14766 [D loss: 0.704879, acc.: 61.72%] [G loss: 0.559561]\n",
      "epoch:15 step:14767 [D loss: 0.663993, acc.: 58.59%] [G loss: 1.080123]\n",
      "epoch:15 step:14768 [D loss: 0.235440, acc.: 97.66%] [G loss: 1.138607]\n",
      "epoch:15 step:14769 [D loss: 0.223607, acc.: 98.44%] [G loss: 1.174065]\n",
      "epoch:15 step:14770 [D loss: 0.760701, acc.: 51.56%] [G loss: 1.130051]\n",
      "epoch:15 step:14771 [D loss: 0.792602, acc.: 50.78%] [G loss: 1.071051]\n",
      "epoch:15 step:14772 [D loss: 0.707192, acc.: 58.59%] [G loss: 1.027040]\n",
      "epoch:15 step:14773 [D loss: 0.678215, acc.: 56.25%] [G loss: 1.023414]\n",
      "epoch:15 step:14774 [D loss: 0.700484, acc.: 47.66%] [G loss: 0.989357]\n",
      "epoch:15 step:14775 [D loss: 0.653940, acc.: 60.16%] [G loss: 0.886544]\n",
      "epoch:15 step:14776 [D loss: 0.666083, acc.: 59.38%] [G loss: 0.621133]\n",
      "epoch:15 step:14777 [D loss: 0.480421, acc.: 85.94%] [G loss: 0.960187]\n",
      "epoch:15 step:14778 [D loss: 0.477945, acc.: 84.38%] [G loss: 0.958647]\n",
      "epoch:15 step:14779 [D loss: 0.711846, acc.: 58.59%] [G loss: 0.744581]\n",
      "epoch:15 step:14780 [D loss: 0.743738, acc.: 47.66%] [G loss: 0.873868]\n",
      "epoch:15 step:14781 [D loss: 0.683517, acc.: 55.47%] [G loss: 0.398225]\n",
      "epoch:15 step:14782 [D loss: 0.386515, acc.: 79.69%] [G loss: 0.988760]\n",
      "epoch:15 step:14783 [D loss: 0.663263, acc.: 56.25%] [G loss: 1.111920]\n",
      "epoch:15 step:14784 [D loss: 0.319488, acc.: 96.88%] [G loss: 1.326369]\n",
      "epoch:15 step:14785 [D loss: 0.254550, acc.: 96.88%] [G loss: 1.255531]\n",
      "epoch:15 step:14786 [D loss: 0.400345, acc.: 92.97%] [G loss: 0.968362]\n",
      "epoch:15 step:14787 [D loss: 0.242109, acc.: 97.66%] [G loss: 0.838485]\n",
      "epoch:15 step:14788 [D loss: 0.857079, acc.: 54.69%] [G loss: 1.147267]\n",
      "epoch:15 step:14789 [D loss: 0.856499, acc.: 50.00%] [G loss: 0.642693]\n",
      "epoch:15 step:14790 [D loss: 1.024400, acc.: 25.78%] [G loss: 1.266274]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14791 [D loss: 0.900192, acc.: 38.28%] [G loss: 1.196023]\n",
      "epoch:15 step:14792 [D loss: 0.849844, acc.: 47.66%] [G loss: 1.361533]\n",
      "epoch:15 step:14793 [D loss: 0.854104, acc.: 46.09%] [G loss: 1.378777]\n",
      "epoch:15 step:14794 [D loss: 0.723067, acc.: 53.91%] [G loss: 1.404353]\n",
      "epoch:15 step:14795 [D loss: 0.825126, acc.: 42.19%] [G loss: 1.219833]\n",
      "epoch:15 step:14796 [D loss: 0.561636, acc.: 71.88%] [G loss: 1.287899]\n",
      "epoch:15 step:14797 [D loss: 0.505266, acc.: 72.66%] [G loss: 1.277835]\n",
      "epoch:15 step:14798 [D loss: 0.467686, acc.: 81.25%] [G loss: 1.453048]\n",
      "epoch:15 step:14799 [D loss: 0.594686, acc.: 67.19%] [G loss: 1.496409]\n",
      "epoch:15 step:14800 [D loss: 0.830072, acc.: 51.56%] [G loss: 1.274307]\n",
      "##############\n",
      "[4.21311674 3.23286496 6.80285194 6.7290651  4.87296308 6.57696359\n",
      " 5.93149328 5.50331185 5.84282059 5.03105776]\n",
      "##########\n",
      "epoch:15 step:14801 [D loss: 0.821472, acc.: 48.44%] [G loss: 1.038968]\n",
      "epoch:15 step:14802 [D loss: 0.711243, acc.: 53.91%] [G loss: 1.083178]\n",
      "epoch:15 step:14803 [D loss: 0.558246, acc.: 71.88%] [G loss: 1.061603]\n",
      "epoch:15 step:14804 [D loss: 0.462736, acc.: 90.62%] [G loss: 1.222270]\n",
      "epoch:15 step:14805 [D loss: 0.379468, acc.: 92.97%] [G loss: 1.172549]\n",
      "epoch:15 step:14806 [D loss: 0.625710, acc.: 57.03%] [G loss: 1.237818]\n",
      "epoch:15 step:14807 [D loss: 0.756376, acc.: 50.00%] [G loss: 1.178449]\n",
      "epoch:15 step:14808 [D loss: 0.684361, acc.: 57.03%] [G loss: 1.039378]\n",
      "epoch:15 step:14809 [D loss: 0.710562, acc.: 56.25%] [G loss: 0.926670]\n",
      "epoch:15 step:14810 [D loss: 0.730297, acc.: 51.56%] [G loss: 0.848858]\n",
      "epoch:15 step:14811 [D loss: 0.725064, acc.: 43.75%] [G loss: 0.833325]\n",
      "epoch:15 step:14812 [D loss: 0.660885, acc.: 62.50%] [G loss: 0.858859]\n",
      "epoch:15 step:14813 [D loss: 0.660625, acc.: 64.06%] [G loss: 0.767195]\n",
      "epoch:15 step:14814 [D loss: 0.465338, acc.: 87.50%] [G loss: 0.934906]\n",
      "epoch:15 step:14815 [D loss: 0.465522, acc.: 87.50%] [G loss: 1.003947]\n",
      "epoch:15 step:14816 [D loss: 0.570637, acc.: 71.88%] [G loss: 0.972025]\n",
      "epoch:15 step:14817 [D loss: 0.676022, acc.: 61.72%] [G loss: 1.016881]\n",
      "epoch:15 step:14818 [D loss: 0.651505, acc.: 62.50%] [G loss: 0.839502]\n",
      "epoch:15 step:14819 [D loss: 0.743515, acc.: 47.66%] [G loss: 0.797072]\n",
      "epoch:15 step:14820 [D loss: 0.557134, acc.: 83.59%] [G loss: 0.726394]\n",
      "epoch:15 step:14821 [D loss: 0.561736, acc.: 71.88%] [G loss: 0.724178]\n",
      "epoch:15 step:14822 [D loss: 0.547346, acc.: 74.22%] [G loss: 0.933241]\n",
      "epoch:15 step:14823 [D loss: 0.415112, acc.: 86.72%] [G loss: 0.831869]\n",
      "epoch:15 step:14824 [D loss: 0.358050, acc.: 92.19%] [G loss: 0.769963]\n",
      "epoch:15 step:14825 [D loss: 0.596201, acc.: 69.53%] [G loss: 1.218449]\n",
      "epoch:15 step:14826 [D loss: 0.656875, acc.: 60.94%] [G loss: 0.993773]\n",
      "epoch:15 step:14827 [D loss: 0.763408, acc.: 44.53%] [G loss: 0.792244]\n",
      "epoch:15 step:14828 [D loss: 0.716030, acc.: 57.81%] [G loss: 0.997482]\n",
      "epoch:15 step:14829 [D loss: 0.401152, acc.: 85.16%] [G loss: 0.962502]\n",
      "epoch:15 step:14830 [D loss: 0.328110, acc.: 97.66%] [G loss: 0.819450]\n",
      "epoch:15 step:14831 [D loss: 0.646969, acc.: 63.28%] [G loss: 0.928025]\n",
      "epoch:15 step:14832 [D loss: 0.612469, acc.: 64.06%] [G loss: 0.853265]\n",
      "epoch:15 step:14833 [D loss: 0.771995, acc.: 46.09%] [G loss: 0.883297]\n",
      "epoch:15 step:14834 [D loss: 0.875494, acc.: 32.03%] [G loss: 0.939995]\n",
      "epoch:15 step:14835 [D loss: 0.921737, acc.: 26.56%] [G loss: 0.619419]\n",
      "epoch:15 step:14836 [D loss: 0.826722, acc.: 33.59%] [G loss: 0.745115]\n",
      "epoch:15 step:14837 [D loss: 0.795920, acc.: 47.66%] [G loss: 0.947821]\n",
      "epoch:15 step:14838 [D loss: 0.674119, acc.: 64.84%] [G loss: 1.064286]\n",
      "epoch:15 step:14839 [D loss: 0.733900, acc.: 46.88%] [G loss: 0.964865]\n",
      "epoch:15 step:14840 [D loss: 0.690199, acc.: 57.03%] [G loss: 0.911976]\n",
      "epoch:15 step:14841 [D loss: 0.711939, acc.: 53.91%] [G loss: 0.694078]\n",
      "epoch:15 step:14842 [D loss: 0.680082, acc.: 54.69%] [G loss: 0.897000]\n",
      "epoch:15 step:14843 [D loss: 0.663150, acc.: 58.59%] [G loss: 0.987556]\n",
      "epoch:15 step:14844 [D loss: 0.765017, acc.: 40.62%] [G loss: 0.906285]\n",
      "epoch:15 step:14845 [D loss: 0.747866, acc.: 45.31%] [G loss: 0.928167]\n",
      "epoch:15 step:14846 [D loss: 0.493043, acc.: 85.16%] [G loss: 1.016398]\n",
      "epoch:15 step:14847 [D loss: 0.455720, acc.: 85.94%] [G loss: 1.129990]\n",
      "epoch:15 step:14848 [D loss: 0.520427, acc.: 75.78%] [G loss: 1.225451]\n",
      "epoch:15 step:14849 [D loss: 0.399183, acc.: 87.50%] [G loss: 1.326884]\n",
      "epoch:15 step:14850 [D loss: 0.447773, acc.: 79.69%] [G loss: 1.081072]\n",
      "epoch:15 step:14851 [D loss: 0.404106, acc.: 83.59%] [G loss: 1.291587]\n",
      "epoch:15 step:14852 [D loss: 0.727976, acc.: 55.47%] [G loss: 1.159640]\n",
      "epoch:15 step:14853 [D loss: 0.616822, acc.: 66.41%] [G loss: 1.136399]\n",
      "epoch:15 step:14854 [D loss: 0.721119, acc.: 54.69%] [G loss: 0.999203]\n",
      "epoch:15 step:14855 [D loss: 0.975552, acc.: 33.59%] [G loss: 0.875800]\n",
      "epoch:15 step:14856 [D loss: 0.761755, acc.: 50.78%] [G loss: 0.970783]\n",
      "epoch:15 step:14857 [D loss: 0.516779, acc.: 73.44%] [G loss: 0.858877]\n",
      "epoch:15 step:14858 [D loss: 0.691769, acc.: 57.03%] [G loss: 0.818139]\n",
      "epoch:15 step:14859 [D loss: 0.444791, acc.: 81.25%] [G loss: 0.994955]\n",
      "epoch:15 step:14860 [D loss: 0.467946, acc.: 84.38%] [G loss: 0.960324]\n",
      "epoch:15 step:14861 [D loss: 0.367784, acc.: 86.72%] [G loss: 0.967101]\n",
      "epoch:15 step:14862 [D loss: 0.714606, acc.: 47.66%] [G loss: 0.849764]\n",
      "epoch:15 step:14863 [D loss: 0.689160, acc.: 52.34%] [G loss: 0.959974]\n",
      "epoch:15 step:14864 [D loss: 0.666083, acc.: 57.03%] [G loss: 1.002368]\n",
      "epoch:15 step:14865 [D loss: 0.702316, acc.: 51.56%] [G loss: 1.039374]\n",
      "epoch:15 step:14866 [D loss: 0.782208, acc.: 48.44%] [G loss: 0.864058]\n",
      "epoch:15 step:14867 [D loss: 0.629246, acc.: 67.19%] [G loss: 0.849832]\n",
      "epoch:15 step:14868 [D loss: 0.783965, acc.: 46.09%] [G loss: 0.935770]\n",
      "epoch:15 step:14869 [D loss: 0.719407, acc.: 50.78%] [G loss: 0.925362]\n",
      "epoch:15 step:14870 [D loss: 0.506113, acc.: 82.81%] [G loss: 0.970455]\n",
      "epoch:15 step:14871 [D loss: 0.612398, acc.: 64.84%] [G loss: 0.829183]\n",
      "epoch:15 step:14872 [D loss: 0.572025, acc.: 77.34%] [G loss: 0.892822]\n",
      "epoch:15 step:14873 [D loss: 0.725767, acc.: 46.88%] [G loss: 0.956130]\n",
      "epoch:15 step:14874 [D loss: 0.645935, acc.: 61.72%] [G loss: 1.030567]\n",
      "epoch:15 step:14875 [D loss: 0.742238, acc.: 43.75%] [G loss: 0.877972]\n",
      "epoch:15 step:14876 [D loss: 0.483300, acc.: 82.03%] [G loss: 0.852028]\n",
      "epoch:15 step:14877 [D loss: 0.530516, acc.: 72.66%] [G loss: 1.001758]\n",
      "epoch:15 step:14878 [D loss: 0.633635, acc.: 64.06%] [G loss: 1.018269]\n",
      "epoch:15 step:14879 [D loss: 0.737430, acc.: 49.22%] [G loss: 0.900035]\n",
      "epoch:15 step:14880 [D loss: 0.650431, acc.: 62.50%] [G loss: 0.857487]\n",
      "epoch:15 step:14881 [D loss: 0.660481, acc.: 60.16%] [G loss: 0.867474]\n",
      "epoch:15 step:14882 [D loss: 0.663016, acc.: 65.62%] [G loss: 0.778739]\n",
      "epoch:15 step:14883 [D loss: 0.625405, acc.: 65.62%] [G loss: 0.780625]\n",
      "epoch:15 step:14884 [D loss: 0.677278, acc.: 57.03%] [G loss: 0.835431]\n",
      "epoch:15 step:14885 [D loss: 0.683957, acc.: 55.47%] [G loss: 0.828024]\n",
      "epoch:15 step:14886 [D loss: 0.705826, acc.: 52.34%] [G loss: 0.818284]\n",
      "epoch:15 step:14887 [D loss: 0.695220, acc.: 57.03%] [G loss: 0.750228]\n",
      "epoch:15 step:14888 [D loss: 0.738239, acc.: 45.31%] [G loss: 0.715906]\n",
      "epoch:15 step:14889 [D loss: 0.509207, acc.: 75.00%] [G loss: 0.809675]\n",
      "epoch:15 step:14890 [D loss: 0.723407, acc.: 47.66%] [G loss: 0.926428]\n",
      "epoch:15 step:14891 [D loss: 0.685863, acc.: 53.91%] [G loss: 0.837868]\n",
      "epoch:15 step:14892 [D loss: 0.716123, acc.: 43.75%] [G loss: 0.891634]\n",
      "epoch:15 step:14893 [D loss: 0.667193, acc.: 53.91%] [G loss: 0.852779]\n",
      "epoch:15 step:14894 [D loss: 0.584577, acc.: 69.53%] [G loss: 0.844841]\n",
      "epoch:15 step:14895 [D loss: 0.605373, acc.: 68.75%] [G loss: 0.923596]\n",
      "epoch:15 step:14896 [D loss: 0.380254, acc.: 85.94%] [G loss: 0.867103]\n",
      "epoch:15 step:14897 [D loss: 0.431502, acc.: 94.53%] [G loss: 0.954565]\n",
      "epoch:15 step:14898 [D loss: 0.758655, acc.: 48.44%] [G loss: 0.919605]\n",
      "epoch:15 step:14899 [D loss: 0.747281, acc.: 46.09%] [G loss: 0.855428]\n",
      "epoch:15 step:14900 [D loss: 0.511502, acc.: 85.16%] [G loss: 0.644651]\n",
      "epoch:15 step:14901 [D loss: 0.719364, acc.: 42.97%] [G loss: 0.905998]\n",
      "epoch:15 step:14902 [D loss: 0.559890, acc.: 60.16%] [G loss: 0.888458]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14903 [D loss: 0.366187, acc.: 92.19%] [G loss: 1.040994]\n",
      "epoch:15 step:14904 [D loss: 0.618197, acc.: 67.97%] [G loss: 1.119669]\n",
      "epoch:15 step:14905 [D loss: 0.454851, acc.: 82.81%] [G loss: 0.862526]\n",
      "epoch:15 step:14906 [D loss: 0.321239, acc.: 89.06%] [G loss: 1.101181]\n",
      "epoch:15 step:14907 [D loss: 0.279658, acc.: 96.09%] [G loss: 1.238542]\n",
      "epoch:15 step:14908 [D loss: 0.224328, acc.: 100.00%] [G loss: 1.330450]\n",
      "epoch:15 step:14909 [D loss: 0.233187, acc.: 99.22%] [G loss: 1.254865]\n",
      "epoch:15 step:14910 [D loss: 0.482534, acc.: 85.94%] [G loss: 1.272698]\n",
      "epoch:15 step:14911 [D loss: 0.622129, acc.: 67.97%] [G loss: 1.053399]\n",
      "epoch:15 step:14912 [D loss: 0.408333, acc.: 81.25%] [G loss: 0.957041]\n",
      "epoch:15 step:14913 [D loss: 1.294644, acc.: 8.59%] [G loss: 1.147180]\n",
      "epoch:15 step:14914 [D loss: 0.716419, acc.: 57.81%] [G loss: 1.058287]\n",
      "epoch:15 step:14915 [D loss: 0.614690, acc.: 62.50%] [G loss: 1.187346]\n",
      "epoch:15 step:14916 [D loss: 0.565246, acc.: 78.91%] [G loss: 1.120838]\n",
      "epoch:15 step:14917 [D loss: 0.756179, acc.: 48.44%] [G loss: 1.042554]\n",
      "epoch:15 step:14918 [D loss: 0.707304, acc.: 53.12%] [G loss: 0.978684]\n",
      "epoch:15 step:14919 [D loss: 0.803861, acc.: 35.16%] [G loss: 1.001634]\n",
      "epoch:15 step:14920 [D loss: 0.618413, acc.: 60.16%] [G loss: 1.004503]\n",
      "epoch:15 step:14921 [D loss: 0.538253, acc.: 80.47%] [G loss: 1.042554]\n",
      "epoch:15 step:14922 [D loss: 0.461877, acc.: 85.94%] [G loss: 1.045804]\n",
      "epoch:15 step:14923 [D loss: 0.680852, acc.: 62.50%] [G loss: 0.802947]\n",
      "epoch:15 step:14924 [D loss: 0.666893, acc.: 59.38%] [G loss: 0.944815]\n",
      "epoch:15 step:14925 [D loss: 0.675898, acc.: 59.38%] [G loss: 0.910065]\n",
      "epoch:15 step:14926 [D loss: 0.751660, acc.: 48.44%] [G loss: 0.907119]\n",
      "epoch:15 step:14927 [D loss: 0.375116, acc.: 94.53%] [G loss: 0.553406]\n",
      "epoch:15 step:14928 [D loss: 0.634983, acc.: 67.97%] [G loss: 1.027451]\n",
      "epoch:15 step:14929 [D loss: 1.172957, acc.: 45.31%] [G loss: 0.953666]\n",
      "epoch:15 step:14930 [D loss: 0.580798, acc.: 75.78%] [G loss: 0.975467]\n",
      "epoch:15 step:14931 [D loss: 0.702332, acc.: 53.12%] [G loss: 1.009596]\n",
      "epoch:15 step:14932 [D loss: 0.646012, acc.: 63.28%] [G loss: 0.709498]\n",
      "epoch:15 step:14933 [D loss: 0.601370, acc.: 61.72%] [G loss: 0.515064]\n",
      "epoch:15 step:14934 [D loss: 1.028207, acc.: 18.75%] [G loss: 1.000134]\n",
      "epoch:15 step:14935 [D loss: 0.715027, acc.: 47.66%] [G loss: 1.128375]\n",
      "epoch:15 step:14936 [D loss: 0.764584, acc.: 41.41%] [G loss: 1.208539]\n",
      "epoch:15 step:14937 [D loss: 0.619876, acc.: 66.41%] [G loss: 0.894578]\n",
      "epoch:15 step:14938 [D loss: 0.649716, acc.: 58.59%] [G loss: 0.876301]\n",
      "epoch:15 step:14939 [D loss: 0.525734, acc.: 79.69%] [G loss: 0.568419]\n",
      "epoch:15 step:14940 [D loss: 0.816830, acc.: 52.34%] [G loss: 0.892146]\n",
      "epoch:15 step:14941 [D loss: 0.484149, acc.: 77.34%] [G loss: 0.740131]\n",
      "epoch:15 step:14942 [D loss: 0.734261, acc.: 53.12%] [G loss: 0.866835]\n",
      "epoch:15 step:14943 [D loss: 0.840670, acc.: 35.16%] [G loss: 1.152917]\n",
      "epoch:15 step:14944 [D loss: 0.541510, acc.: 75.78%] [G loss: 0.873031]\n",
      "epoch:15 step:14945 [D loss: 0.671650, acc.: 55.47%] [G loss: 0.934305]\n",
      "epoch:15 step:14946 [D loss: 0.758448, acc.: 44.53%] [G loss: 0.822163]\n",
      "epoch:15 step:14947 [D loss: 0.726522, acc.: 48.44%] [G loss: 0.881471]\n",
      "epoch:15 step:14948 [D loss: 0.645911, acc.: 59.38%] [G loss: 1.144452]\n",
      "epoch:15 step:14949 [D loss: 0.558165, acc.: 73.44%] [G loss: 1.158674]\n",
      "epoch:15 step:14950 [D loss: 0.656029, acc.: 59.38%] [G loss: 1.146395]\n",
      "epoch:15 step:14951 [D loss: 0.565914, acc.: 67.19%] [G loss: 1.160324]\n",
      "epoch:15 step:14952 [D loss: 0.505574, acc.: 77.34%] [G loss: 1.216596]\n",
      "epoch:15 step:14953 [D loss: 0.361159, acc.: 91.41%] [G loss: 1.542960]\n",
      "epoch:15 step:14954 [D loss: 0.227982, acc.: 99.22%] [G loss: 1.573864]\n",
      "epoch:15 step:14955 [D loss: 0.208199, acc.: 98.44%] [G loss: 1.260313]\n",
      "epoch:15 step:14956 [D loss: 0.428703, acc.: 82.81%] [G loss: 1.687127]\n",
      "epoch:15 step:14957 [D loss: 0.544375, acc.: 69.53%] [G loss: 1.742062]\n",
      "epoch:15 step:14958 [D loss: 0.473223, acc.: 85.16%] [G loss: 1.379284]\n",
      "epoch:15 step:14959 [D loss: 1.093921, acc.: 42.19%] [G loss: 0.991619]\n",
      "epoch:15 step:14960 [D loss: 0.721467, acc.: 50.00%] [G loss: 1.049331]\n",
      "epoch:15 step:14961 [D loss: 0.815557, acc.: 41.41%] [G loss: 0.744586]\n",
      "epoch:15 step:14962 [D loss: 0.618549, acc.: 62.50%] [G loss: 0.771892]\n",
      "epoch:15 step:14963 [D loss: 0.590300, acc.: 70.31%] [G loss: 0.906470]\n",
      "epoch:15 step:14964 [D loss: 0.386732, acc.: 85.94%] [G loss: 0.577122]\n",
      "epoch:15 step:14965 [D loss: 0.781576, acc.: 46.09%] [G loss: 1.018175]\n",
      "epoch:15 step:14966 [D loss: 0.362596, acc.: 87.50%] [G loss: 0.938572]\n",
      "epoch:15 step:14967 [D loss: 0.222811, acc.: 96.09%] [G loss: 1.097868]\n",
      "epoch:15 step:14968 [D loss: 0.538383, acc.: 81.25%] [G loss: 0.931586]\n",
      "epoch:15 step:14969 [D loss: 0.855136, acc.: 28.91%] [G loss: 0.770330]\n",
      "epoch:15 step:14970 [D loss: 0.705837, acc.: 61.72%] [G loss: 0.940451]\n",
      "epoch:15 step:14971 [D loss: 0.841401, acc.: 44.53%] [G loss: 0.962840]\n",
      "epoch:15 step:14972 [D loss: 0.796777, acc.: 40.62%] [G loss: 0.944281]\n",
      "epoch:15 step:14973 [D loss: 0.684524, acc.: 54.69%] [G loss: 0.875360]\n",
      "epoch:15 step:14974 [D loss: 0.576493, acc.: 57.81%] [G loss: 0.977248]\n",
      "epoch:15 step:14975 [D loss: 0.745451, acc.: 48.44%] [G loss: 0.832173]\n",
      "epoch:15 step:14976 [D loss: 0.619119, acc.: 67.19%] [G loss: 0.941199]\n",
      "epoch:15 step:14977 [D loss: 0.670311, acc.: 61.72%] [G loss: 0.929853]\n",
      "epoch:15 step:14978 [D loss: 0.630202, acc.: 67.97%] [G loss: 0.844965]\n",
      "epoch:15 step:14979 [D loss: 0.383519, acc.: 90.62%] [G loss: 0.946388]\n",
      "epoch:15 step:14980 [D loss: 0.434958, acc.: 85.94%] [G loss: 1.013474]\n",
      "epoch:15 step:14981 [D loss: 0.471415, acc.: 66.41%] [G loss: 1.052211]\n",
      "epoch:15 step:14982 [D loss: 0.269494, acc.: 90.62%] [G loss: 1.129802]\n",
      "epoch:15 step:14983 [D loss: 0.777158, acc.: 46.09%] [G loss: 0.997537]\n",
      "epoch:15 step:14984 [D loss: 0.610471, acc.: 69.53%] [G loss: 0.856731]\n",
      "epoch:15 step:14985 [D loss: 0.491445, acc.: 86.72%] [G loss: 0.913388]\n",
      "epoch:15 step:14986 [D loss: 0.608373, acc.: 69.53%] [G loss: 0.960215]\n",
      "epoch:15 step:14987 [D loss: 0.695263, acc.: 55.47%] [G loss: 0.716687]\n",
      "epoch:15 step:14988 [D loss: 0.623186, acc.: 63.28%] [G loss: 0.733519]\n",
      "epoch:15 step:14989 [D loss: 0.402446, acc.: 82.81%] [G loss: 1.086434]\n",
      "epoch:15 step:14990 [D loss: 0.540584, acc.: 80.47%] [G loss: 0.854930]\n",
      "epoch:15 step:14991 [D loss: 0.319473, acc.: 88.28%] [G loss: 0.893806]\n",
      "epoch:15 step:14992 [D loss: 0.286298, acc.: 85.16%] [G loss: 1.126964]\n",
      "epoch:16 step:14993 [D loss: 0.796455, acc.: 45.31%] [G loss: 1.073298]\n",
      "epoch:16 step:14994 [D loss: 0.809191, acc.: 42.19%] [G loss: 0.983303]\n",
      "epoch:16 step:14995 [D loss: 0.827888, acc.: 39.06%] [G loss: 1.073641]\n",
      "epoch:16 step:14996 [D loss: 0.760211, acc.: 42.19%] [G loss: 1.191689]\n",
      "epoch:16 step:14997 [D loss: 0.726302, acc.: 47.66%] [G loss: 1.062257]\n",
      "epoch:16 step:14998 [D loss: 0.751432, acc.: 45.31%] [G loss: 1.184898]\n",
      "epoch:16 step:14999 [D loss: 0.754640, acc.: 46.09%] [G loss: 0.875968]\n",
      "epoch:16 step:15000 [D loss: 0.829561, acc.: 37.50%] [G loss: 1.058279]\n",
      "##############\n",
      "[3.75770493 2.33363633 6.59366089 5.3058855  4.30267189 6.28215076\n",
      " 5.53451031 5.55920229 5.65832307 5.25812582]\n",
      "##########\n",
      "epoch:16 step:15001 [D loss: 0.696149, acc.: 54.69%] [G loss: 1.074842]\n",
      "epoch:16 step:15002 [D loss: 0.702150, acc.: 53.12%] [G loss: 0.950745]\n",
      "epoch:16 step:15003 [D loss: 0.658905, acc.: 61.72%] [G loss: 0.972975]\n",
      "epoch:16 step:15004 [D loss: 0.772085, acc.: 48.44%] [G loss: 0.868324]\n",
      "epoch:16 step:15005 [D loss: 0.706357, acc.: 53.12%] [G loss: 0.899560]\n",
      "epoch:16 step:15006 [D loss: 0.657377, acc.: 59.38%] [G loss: 0.783603]\n",
      "epoch:16 step:15007 [D loss: 0.665614, acc.: 58.59%] [G loss: 0.924831]\n",
      "epoch:16 step:15008 [D loss: 0.683148, acc.: 57.81%] [G loss: 0.993101]\n",
      "epoch:16 step:15009 [D loss: 0.761212, acc.: 39.06%] [G loss: 0.971250]\n",
      "epoch:16 step:15010 [D loss: 0.685910, acc.: 57.81%] [G loss: 0.927262]\n",
      "epoch:16 step:15011 [D loss: 0.693867, acc.: 51.56%] [G loss: 1.059187]\n",
      "epoch:16 step:15012 [D loss: 0.608512, acc.: 73.44%] [G loss: 0.956437]\n",
      "epoch:16 step:15013 [D loss: 1.176838, acc.: 42.19%] [G loss: 1.114167]\n",
      "epoch:16 step:15014 [D loss: 0.603885, acc.: 71.09%] [G loss: 1.297010]\n",
      "epoch:16 step:15015 [D loss: 0.761092, acc.: 51.56%] [G loss: 1.510397]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15016 [D loss: 0.799833, acc.: 48.44%] [G loss: 0.896750]\n",
      "epoch:16 step:15017 [D loss: 0.622572, acc.: 57.03%] [G loss: 0.898906]\n",
      "epoch:16 step:15018 [D loss: 0.565047, acc.: 82.81%] [G loss: 0.768947]\n",
      "epoch:16 step:15019 [D loss: 0.434666, acc.: 89.84%] [G loss: 0.851522]\n",
      "epoch:16 step:15020 [D loss: 0.532331, acc.: 78.12%] [G loss: 0.819124]\n",
      "epoch:16 step:15021 [D loss: 0.596146, acc.: 72.66%] [G loss: 1.267130]\n",
      "epoch:16 step:15022 [D loss: 0.603847, acc.: 69.53%] [G loss: 1.030247]\n",
      "epoch:16 step:15023 [D loss: 0.401438, acc.: 91.41%] [G loss: 1.156009]\n",
      "epoch:16 step:15024 [D loss: 0.515304, acc.: 75.78%] [G loss: 0.901104]\n",
      "epoch:16 step:15025 [D loss: 0.447317, acc.: 89.06%] [G loss: 1.796999]\n",
      "epoch:16 step:15026 [D loss: 0.426719, acc.: 84.38%] [G loss: 1.162348]\n",
      "epoch:16 step:15027 [D loss: 0.498477, acc.: 70.31%] [G loss: 0.987793]\n",
      "epoch:16 step:15028 [D loss: 0.265088, acc.: 96.09%] [G loss: 1.155607]\n",
      "epoch:16 step:15029 [D loss: 0.906265, acc.: 28.12%] [G loss: 0.688772]\n",
      "epoch:16 step:15030 [D loss: 1.621458, acc.: 7.81%] [G loss: 0.906500]\n",
      "epoch:16 step:15031 [D loss: 0.822928, acc.: 37.50%] [G loss: 0.741416]\n",
      "epoch:16 step:15032 [D loss: 0.795196, acc.: 48.44%] [G loss: 0.795877]\n",
      "epoch:16 step:15033 [D loss: 0.678443, acc.: 56.25%] [G loss: 0.852180]\n",
      "epoch:16 step:15034 [D loss: 0.709384, acc.: 49.22%] [G loss: 0.800408]\n",
      "epoch:16 step:15035 [D loss: 0.629574, acc.: 65.62%] [G loss: 0.897728]\n",
      "epoch:16 step:15036 [D loss: 0.628213, acc.: 61.72%] [G loss: 0.747950]\n",
      "epoch:16 step:15037 [D loss: 0.652310, acc.: 59.38%] [G loss: 0.610614]\n",
      "epoch:16 step:15038 [D loss: 0.685655, acc.: 56.25%] [G loss: 0.795944]\n",
      "epoch:16 step:15039 [D loss: 0.701422, acc.: 47.66%] [G loss: 0.808845]\n",
      "epoch:16 step:15040 [D loss: 0.682240, acc.: 52.34%] [G loss: 0.832503]\n",
      "epoch:16 step:15041 [D loss: 0.674367, acc.: 57.81%] [G loss: 0.823504]\n",
      "epoch:16 step:15042 [D loss: 0.696459, acc.: 51.56%] [G loss: 0.851263]\n",
      "epoch:16 step:15043 [D loss: 0.695009, acc.: 57.03%] [G loss: 0.660501]\n",
      "epoch:16 step:15044 [D loss: 0.704564, acc.: 50.00%] [G loss: 0.811289]\n",
      "epoch:16 step:15045 [D loss: 0.643617, acc.: 62.50%] [G loss: 1.038463]\n",
      "epoch:16 step:15046 [D loss: 0.665215, acc.: 56.25%] [G loss: 0.750238]\n",
      "epoch:16 step:15047 [D loss: 0.656572, acc.: 64.06%] [G loss: 0.792791]\n",
      "epoch:16 step:15048 [D loss: 0.624108, acc.: 73.44%] [G loss: 0.835720]\n",
      "epoch:16 step:15049 [D loss: 0.646858, acc.: 64.06%] [G loss: 0.709998]\n",
      "epoch:16 step:15050 [D loss: 0.644781, acc.: 58.59%] [G loss: 0.812418]\n",
      "epoch:16 step:15051 [D loss: 0.596163, acc.: 73.44%] [G loss: 0.820324]\n",
      "epoch:16 step:15052 [D loss: 0.580216, acc.: 75.00%] [G loss: 0.856197]\n",
      "epoch:16 step:15053 [D loss: 0.660813, acc.: 57.03%] [G loss: 0.764120]\n",
      "epoch:16 step:15054 [D loss: 0.696956, acc.: 57.03%] [G loss: 0.780818]\n",
      "epoch:16 step:15055 [D loss: 0.689795, acc.: 53.91%] [G loss: 0.819960]\n",
      "epoch:16 step:15056 [D loss: 0.678787, acc.: 56.25%] [G loss: 0.692912]\n",
      "epoch:16 step:15057 [D loss: 0.681090, acc.: 48.44%] [G loss: 0.782569]\n",
      "epoch:16 step:15058 [D loss: 0.699213, acc.: 53.91%] [G loss: 0.580129]\n",
      "epoch:16 step:15059 [D loss: 0.746586, acc.: 50.78%] [G loss: 0.741088]\n",
      "epoch:16 step:15060 [D loss: 0.617273, acc.: 68.75%] [G loss: 0.850280]\n",
      "epoch:16 step:15061 [D loss: 0.600074, acc.: 67.97%] [G loss: 0.880867]\n",
      "epoch:16 step:15062 [D loss: 0.616388, acc.: 67.19%] [G loss: 0.906892]\n",
      "epoch:16 step:15063 [D loss: 0.646341, acc.: 68.75%] [G loss: 0.895201]\n",
      "epoch:16 step:15064 [D loss: 0.738902, acc.: 57.03%] [G loss: 0.931080]\n",
      "epoch:16 step:15065 [D loss: 0.752733, acc.: 53.12%] [G loss: 0.796331]\n",
      "epoch:16 step:15066 [D loss: 0.695423, acc.: 53.12%] [G loss: 0.804551]\n",
      "epoch:16 step:15067 [D loss: 0.445360, acc.: 90.62%] [G loss: 0.845662]\n",
      "epoch:16 step:15068 [D loss: 0.561690, acc.: 76.56%] [G loss: 0.845821]\n",
      "epoch:16 step:15069 [D loss: 0.506812, acc.: 84.38%] [G loss: 0.886013]\n",
      "epoch:16 step:15070 [D loss: 0.740364, acc.: 47.66%] [G loss: 0.900254]\n",
      "epoch:16 step:15071 [D loss: 0.663502, acc.: 57.03%] [G loss: 0.953157]\n",
      "epoch:16 step:15072 [D loss: 0.896408, acc.: 33.59%] [G loss: 0.925952]\n",
      "epoch:16 step:15073 [D loss: 0.622232, acc.: 63.28%] [G loss: 0.914060]\n",
      "epoch:16 step:15074 [D loss: 0.567677, acc.: 74.22%] [G loss: 0.891228]\n",
      "epoch:16 step:15075 [D loss: 0.617257, acc.: 62.50%] [G loss: 0.870660]\n",
      "epoch:16 step:15076 [D loss: 0.605943, acc.: 71.09%] [G loss: 0.927996]\n",
      "epoch:16 step:15077 [D loss: 0.634492, acc.: 64.84%] [G loss: 0.882355]\n",
      "epoch:16 step:15078 [D loss: 0.680332, acc.: 60.16%] [G loss: 0.975480]\n",
      "epoch:16 step:15079 [D loss: 0.614062, acc.: 64.06%] [G loss: 0.895062]\n",
      "epoch:16 step:15080 [D loss: 0.588846, acc.: 66.41%] [G loss: 0.922769]\n",
      "epoch:16 step:15081 [D loss: 0.596348, acc.: 74.22%] [G loss: 0.959900]\n",
      "epoch:16 step:15082 [D loss: 0.610038, acc.: 66.41%] [G loss: 0.913133]\n",
      "epoch:16 step:15083 [D loss: 0.798127, acc.: 42.97%] [G loss: 0.863435]\n",
      "epoch:16 step:15084 [D loss: 0.619018, acc.: 67.19%] [G loss: 0.793193]\n",
      "epoch:16 step:15085 [D loss: 0.598269, acc.: 67.19%] [G loss: 0.897800]\n",
      "epoch:16 step:15086 [D loss: 0.655287, acc.: 64.06%] [G loss: 0.900499]\n",
      "epoch:16 step:15087 [D loss: 0.691922, acc.: 55.47%] [G loss: 0.969636]\n",
      "epoch:16 step:15088 [D loss: 0.639657, acc.: 59.38%] [G loss: 0.883955]\n",
      "epoch:16 step:15089 [D loss: 0.611391, acc.: 71.09%] [G loss: 0.833539]\n",
      "epoch:16 step:15090 [D loss: 0.582388, acc.: 70.31%] [G loss: 0.833525]\n",
      "epoch:16 step:15091 [D loss: 0.557836, acc.: 68.75%] [G loss: 0.997148]\n",
      "epoch:16 step:15092 [D loss: 0.447274, acc.: 88.28%] [G loss: 0.978198]\n",
      "epoch:16 step:15093 [D loss: 0.703770, acc.: 53.91%] [G loss: 0.910471]\n",
      "epoch:16 step:15094 [D loss: 0.605886, acc.: 67.97%] [G loss: 0.884908]\n",
      "epoch:16 step:15095 [D loss: 0.627987, acc.: 61.72%] [G loss: 0.799373]\n",
      "epoch:16 step:15096 [D loss: 0.748343, acc.: 46.09%] [G loss: 0.853601]\n",
      "epoch:16 step:15097 [D loss: 0.480614, acc.: 82.03%] [G loss: 0.906784]\n",
      "epoch:16 step:15098 [D loss: 0.672315, acc.: 59.38%] [G loss: 0.717254]\n",
      "epoch:16 step:15099 [D loss: 0.676552, acc.: 62.50%] [G loss: 0.848642]\n",
      "epoch:16 step:15100 [D loss: 0.746271, acc.: 42.19%] [G loss: 0.856855]\n",
      "epoch:16 step:15101 [D loss: 0.838385, acc.: 35.94%] [G loss: 0.941408]\n",
      "epoch:16 step:15102 [D loss: 0.691692, acc.: 53.12%] [G loss: 0.980543]\n",
      "epoch:16 step:15103 [D loss: 0.656177, acc.: 62.50%] [G loss: 0.849140]\n",
      "epoch:16 step:15104 [D loss: 0.743499, acc.: 48.44%] [G loss: 0.965139]\n",
      "epoch:16 step:15105 [D loss: 0.688150, acc.: 60.16%] [G loss: 0.926595]\n",
      "epoch:16 step:15106 [D loss: 0.562487, acc.: 75.00%] [G loss: 0.955066]\n",
      "epoch:16 step:15107 [D loss: 0.628467, acc.: 67.97%] [G loss: 0.907893]\n",
      "epoch:16 step:15108 [D loss: 0.673651, acc.: 58.59%] [G loss: 0.950905]\n",
      "epoch:16 step:15109 [D loss: 0.682268, acc.: 57.81%] [G loss: 0.949290]\n",
      "epoch:16 step:15110 [D loss: 0.592199, acc.: 71.09%] [G loss: 0.936241]\n",
      "epoch:16 step:15111 [D loss: 0.389475, acc.: 84.38%] [G loss: 0.969556]\n",
      "epoch:16 step:15112 [D loss: 0.653857, acc.: 67.97%] [G loss: 0.958503]\n",
      "epoch:16 step:15113 [D loss: 0.533504, acc.: 79.69%] [G loss: 0.975905]\n",
      "epoch:16 step:15114 [D loss: 0.526403, acc.: 85.94%] [G loss: 0.996556]\n",
      "epoch:16 step:15115 [D loss: 0.639591, acc.: 60.94%] [G loss: 0.994824]\n",
      "epoch:16 step:15116 [D loss: 0.727338, acc.: 51.56%] [G loss: 0.905794]\n",
      "epoch:16 step:15117 [D loss: 0.810521, acc.: 41.41%] [G loss: 0.943830]\n",
      "epoch:16 step:15118 [D loss: 0.641824, acc.: 64.06%] [G loss: 0.935141]\n",
      "epoch:16 step:15119 [D loss: 0.704680, acc.: 53.12%] [G loss: 1.051672]\n",
      "epoch:16 step:15120 [D loss: 0.696816, acc.: 56.25%] [G loss: 0.879513]\n",
      "epoch:16 step:15121 [D loss: 0.598635, acc.: 68.75%] [G loss: 1.029348]\n",
      "epoch:16 step:15122 [D loss: 0.542407, acc.: 72.66%] [G loss: 0.969266]\n",
      "epoch:16 step:15123 [D loss: 0.509053, acc.: 89.84%] [G loss: 0.970436]\n",
      "epoch:16 step:15124 [D loss: 0.690762, acc.: 56.25%] [G loss: 0.845375]\n",
      "epoch:16 step:15125 [D loss: 0.602137, acc.: 69.53%] [G loss: 0.902629]\n",
      "epoch:16 step:15126 [D loss: 0.589206, acc.: 79.69%] [G loss: 0.904653]\n",
      "epoch:16 step:15127 [D loss: 0.585932, acc.: 72.66%] [G loss: 0.943006]\n",
      "epoch:16 step:15128 [D loss: 0.652926, acc.: 60.16%] [G loss: 0.867939]\n",
      "epoch:16 step:15129 [D loss: 0.711973, acc.: 55.47%] [G loss: 0.842140]\n",
      "epoch:16 step:15130 [D loss: 0.583242, acc.: 73.44%] [G loss: 0.846085]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15131 [D loss: 0.630589, acc.: 62.50%] [G loss: 0.894034]\n",
      "epoch:16 step:15132 [D loss: 0.673899, acc.: 57.81%] [G loss: 0.854838]\n",
      "epoch:16 step:15133 [D loss: 0.606672, acc.: 73.44%] [G loss: 0.872716]\n",
      "epoch:16 step:15134 [D loss: 0.765767, acc.: 42.97%] [G loss: 0.826450]\n",
      "epoch:16 step:15135 [D loss: 0.454111, acc.: 81.25%] [G loss: 0.894917]\n",
      "epoch:16 step:15136 [D loss: 0.437302, acc.: 87.50%] [G loss: 0.986027]\n",
      "epoch:16 step:15137 [D loss: 0.346285, acc.: 85.16%] [G loss: 0.865502]\n",
      "epoch:16 step:15138 [D loss: 0.559346, acc.: 75.00%] [G loss: 0.971429]\n",
      "epoch:16 step:15139 [D loss: 0.690981, acc.: 60.16%] [G loss: 0.917984]\n",
      "epoch:16 step:15140 [D loss: 0.668473, acc.: 58.59%] [G loss: 0.906914]\n",
      "epoch:16 step:15141 [D loss: 0.698088, acc.: 56.25%] [G loss: 0.878639]\n",
      "epoch:16 step:15142 [D loss: 0.492232, acc.: 64.06%] [G loss: 1.040106]\n",
      "epoch:16 step:15143 [D loss: 0.383138, acc.: 87.50%] [G loss: 1.093203]\n",
      "epoch:16 step:15144 [D loss: 0.637691, acc.: 60.94%] [G loss: 1.015572]\n",
      "epoch:16 step:15145 [D loss: 0.839395, acc.: 41.41%] [G loss: 0.911059]\n",
      "epoch:16 step:15146 [D loss: 0.880653, acc.: 33.59%] [G loss: 1.076329]\n",
      "epoch:16 step:15147 [D loss: 0.658286, acc.: 60.94%] [G loss: 1.027282]\n",
      "epoch:16 step:15148 [D loss: 0.699310, acc.: 53.12%] [G loss: 0.920766]\n",
      "epoch:16 step:15149 [D loss: 0.705772, acc.: 54.69%] [G loss: 0.786012]\n",
      "epoch:16 step:15150 [D loss: 0.748818, acc.: 43.75%] [G loss: 0.973310]\n",
      "epoch:16 step:15151 [D loss: 0.661634, acc.: 58.59%] [G loss: 0.905863]\n",
      "epoch:16 step:15152 [D loss: 0.666104, acc.: 63.28%] [G loss: 0.930008]\n",
      "epoch:16 step:15153 [D loss: 0.662446, acc.: 62.50%] [G loss: 0.849147]\n",
      "epoch:16 step:15154 [D loss: 0.607999, acc.: 69.53%] [G loss: 0.874685]\n",
      "epoch:16 step:15155 [D loss: 0.655394, acc.: 60.16%] [G loss: 0.826240]\n",
      "epoch:16 step:15156 [D loss: 0.617477, acc.: 62.50%] [G loss: 0.922404]\n",
      "epoch:16 step:15157 [D loss: 0.606055, acc.: 71.88%] [G loss: 0.885863]\n",
      "epoch:16 step:15158 [D loss: 0.666856, acc.: 63.28%] [G loss: 0.768798]\n",
      "epoch:16 step:15159 [D loss: 0.759497, acc.: 43.75%] [G loss: 0.700375]\n",
      "epoch:16 step:15160 [D loss: 0.599086, acc.: 73.44%] [G loss: 0.653999]\n",
      "epoch:16 step:15161 [D loss: 0.753662, acc.: 53.12%] [G loss: 0.917427]\n",
      "epoch:16 step:15162 [D loss: 0.585118, acc.: 72.66%] [G loss: 0.757816]\n",
      "epoch:16 step:15163 [D loss: 0.705382, acc.: 53.12%] [G loss: 0.870396]\n",
      "epoch:16 step:15164 [D loss: 0.626090, acc.: 66.41%] [G loss: 0.992819]\n",
      "epoch:16 step:15165 [D loss: 0.750266, acc.: 46.88%] [G loss: 0.912321]\n",
      "epoch:16 step:15166 [D loss: 0.710199, acc.: 51.56%] [G loss: 0.489416]\n",
      "epoch:16 step:15167 [D loss: 0.772878, acc.: 40.62%] [G loss: 0.758337]\n",
      "epoch:16 step:15168 [D loss: 0.651170, acc.: 60.16%] [G loss: 0.761376]\n",
      "epoch:16 step:15169 [D loss: 0.757982, acc.: 39.06%] [G loss: 0.845359]\n",
      "epoch:16 step:15170 [D loss: 0.692799, acc.: 54.69%] [G loss: 0.817433]\n",
      "epoch:16 step:15171 [D loss: 0.730176, acc.: 48.44%] [G loss: 0.733115]\n",
      "epoch:16 step:15172 [D loss: 0.640069, acc.: 66.41%] [G loss: 0.994782]\n",
      "epoch:16 step:15173 [D loss: 0.704631, acc.: 53.12%] [G loss: 0.997692]\n",
      "epoch:16 step:15174 [D loss: 0.651438, acc.: 60.16%] [G loss: 0.786734]\n",
      "epoch:16 step:15175 [D loss: 0.697164, acc.: 55.47%] [G loss: 0.915390]\n",
      "epoch:16 step:15176 [D loss: 0.589843, acc.: 67.19%] [G loss: 0.722924]\n",
      "epoch:16 step:15177 [D loss: 0.678478, acc.: 57.81%] [G loss: 0.861038]\n",
      "epoch:16 step:15178 [D loss: 0.826970, acc.: 33.59%] [G loss: 0.875511]\n",
      "epoch:16 step:15179 [D loss: 0.713295, acc.: 49.22%] [G loss: 1.102100]\n",
      "epoch:16 step:15180 [D loss: 0.637817, acc.: 60.94%] [G loss: 0.987568]\n",
      "epoch:16 step:15181 [D loss: 0.623083, acc.: 64.06%] [G loss: 1.007925]\n",
      "epoch:16 step:15182 [D loss: 0.634429, acc.: 59.38%] [G loss: 1.006319]\n",
      "epoch:16 step:15183 [D loss: 0.580646, acc.: 65.62%] [G loss: 1.033173]\n",
      "epoch:16 step:15184 [D loss: 0.376204, acc.: 95.31%] [G loss: 1.046588]\n",
      "epoch:16 step:15185 [D loss: 0.563937, acc.: 68.75%] [G loss: 1.178510]\n",
      "epoch:16 step:15186 [D loss: 0.417616, acc.: 86.72%] [G loss: 1.368875]\n",
      "epoch:16 step:15187 [D loss: 0.446379, acc.: 86.72%] [G loss: 1.189780]\n",
      "epoch:16 step:15188 [D loss: 0.495279, acc.: 82.81%] [G loss: 1.359641]\n",
      "epoch:16 step:15189 [D loss: 0.381045, acc.: 95.31%] [G loss: 0.975269]\n",
      "epoch:16 step:15190 [D loss: 0.528143, acc.: 80.47%] [G loss: 1.098406]\n",
      "epoch:16 step:15191 [D loss: 0.592010, acc.: 60.16%] [G loss: 0.905342]\n",
      "epoch:16 step:15192 [D loss: 0.867744, acc.: 40.62%] [G loss: 1.510285]\n",
      "epoch:16 step:15193 [D loss: 0.663975, acc.: 62.50%] [G loss: 1.005233]\n",
      "epoch:16 step:15194 [D loss: 0.805909, acc.: 42.19%] [G loss: 0.940737]\n",
      "epoch:16 step:15195 [D loss: 0.668257, acc.: 59.38%] [G loss: 0.861476]\n",
      "epoch:16 step:15196 [D loss: 0.334393, acc.: 92.97%] [G loss: 0.921212]\n",
      "epoch:16 step:15197 [D loss: 0.472100, acc.: 90.62%] [G loss: 1.248347]\n",
      "epoch:16 step:15198 [D loss: 0.454226, acc.: 91.41%] [G loss: 0.881194]\n",
      "epoch:16 step:15199 [D loss: 0.315651, acc.: 89.84%] [G loss: 1.011762]\n",
      "epoch:16 step:15200 [D loss: 0.334533, acc.: 96.88%] [G loss: 1.692284]\n",
      "##############\n",
      "[4.15096613 2.48304062 6.31359189 5.65798227 4.54735339 6.26160128\n",
      " 5.23707857 5.29099417 5.54317025 5.08843141]\n",
      "##########\n",
      "epoch:16 step:15201 [D loss: 0.301578, acc.: 97.66%] [G loss: 1.086565]\n",
      "epoch:16 step:15202 [D loss: 0.838940, acc.: 36.72%] [G loss: 1.036195]\n",
      "epoch:16 step:15203 [D loss: 1.050749, acc.: 17.97%] [G loss: 0.906649]\n",
      "epoch:16 step:15204 [D loss: 0.712720, acc.: 50.00%] [G loss: 1.095887]\n",
      "epoch:16 step:15205 [D loss: 0.735055, acc.: 53.12%] [G loss: 0.806379]\n",
      "epoch:16 step:15206 [D loss: 0.648344, acc.: 60.94%] [G loss: 0.678677]\n",
      "epoch:16 step:15207 [D loss: 0.821198, acc.: 29.69%] [G loss: 0.936019]\n",
      "epoch:16 step:15208 [D loss: 0.858389, acc.: 43.75%] [G loss: 0.809776]\n",
      "epoch:16 step:15209 [D loss: 0.466054, acc.: 86.72%] [G loss: 1.075062]\n",
      "epoch:16 step:15210 [D loss: 0.369647, acc.: 88.28%] [G loss: 0.650264]\n",
      "epoch:16 step:15211 [D loss: 0.485778, acc.: 76.56%] [G loss: 0.894851]\n",
      "epoch:16 step:15212 [D loss: 0.680437, acc.: 58.59%] [G loss: 0.496541]\n",
      "epoch:16 step:15213 [D loss: 0.484458, acc.: 79.69%] [G loss: 0.691230]\n",
      "epoch:16 step:15214 [D loss: 0.588725, acc.: 67.19%] [G loss: 0.841955]\n",
      "epoch:16 step:15215 [D loss: 0.829249, acc.: 32.81%] [G loss: 1.063316]\n",
      "epoch:16 step:15216 [D loss: 0.743869, acc.: 48.44%] [G loss: 1.003481]\n",
      "epoch:16 step:15217 [D loss: 0.563607, acc.: 74.22%] [G loss: 1.009127]\n",
      "epoch:16 step:15218 [D loss: 0.814278, acc.: 33.59%] [G loss: 0.844467]\n",
      "epoch:16 step:15219 [D loss: 0.697548, acc.: 54.69%] [G loss: 1.105106]\n",
      "epoch:16 step:15220 [D loss: 0.710636, acc.: 55.47%] [G loss: 1.050409]\n",
      "epoch:16 step:15221 [D loss: 0.709876, acc.: 54.69%] [G loss: 0.904129]\n",
      "epoch:16 step:15222 [D loss: 0.328380, acc.: 86.72%] [G loss: 0.987065]\n",
      "epoch:16 step:15223 [D loss: 0.426583, acc.: 89.06%] [G loss: 1.094220]\n",
      "epoch:16 step:15224 [D loss: 0.331375, acc.: 92.19%] [G loss: 1.080407]\n",
      "epoch:16 step:15225 [D loss: 0.720910, acc.: 56.25%] [G loss: 1.097529]\n",
      "epoch:16 step:15226 [D loss: 0.528391, acc.: 78.91%] [G loss: 1.129187]\n",
      "epoch:16 step:15227 [D loss: 0.334878, acc.: 92.19%] [G loss: 1.396108]\n",
      "epoch:16 step:15228 [D loss: 0.632028, acc.: 68.75%] [G loss: 1.096365]\n",
      "epoch:16 step:15229 [D loss: 0.501173, acc.: 81.25%] [G loss: 1.130604]\n",
      "epoch:16 step:15230 [D loss: 0.419480, acc.: 79.69%] [G loss: 1.112905]\n",
      "epoch:16 step:15231 [D loss: 0.603389, acc.: 67.97%] [G loss: 1.131350]\n",
      "epoch:16 step:15232 [D loss: 0.616841, acc.: 68.75%] [G loss: 0.954824]\n",
      "epoch:16 step:15233 [D loss: 0.802265, acc.: 42.19%] [G loss: 1.031507]\n",
      "epoch:16 step:15234 [D loss: 0.686775, acc.: 57.03%] [G loss: 1.106072]\n",
      "epoch:16 step:15235 [D loss: 0.572227, acc.: 71.88%] [G loss: 0.934580]\n",
      "epoch:16 step:15236 [D loss: 0.662988, acc.: 65.62%] [G loss: 0.875941]\n",
      "epoch:16 step:15237 [D loss: 0.812413, acc.: 39.06%] [G loss: 0.891132]\n",
      "epoch:16 step:15238 [D loss: 0.715981, acc.: 56.25%] [G loss: 0.954973]\n",
      "epoch:16 step:15239 [D loss: 0.677630, acc.: 57.81%] [G loss: 1.018865]\n",
      "epoch:16 step:15240 [D loss: 0.692669, acc.: 53.12%] [G loss: 0.897967]\n",
      "epoch:16 step:15241 [D loss: 0.631253, acc.: 67.19%] [G loss: 1.038382]\n",
      "epoch:16 step:15242 [D loss: 0.673634, acc.: 58.59%] [G loss: 1.092676]\n",
      "epoch:16 step:15243 [D loss: 0.633779, acc.: 60.94%] [G loss: 0.934797]\n",
      "epoch:16 step:15244 [D loss: 0.668898, acc.: 59.38%] [G loss: 0.927504]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15245 [D loss: 0.546533, acc.: 80.47%] [G loss: 0.934056]\n",
      "epoch:16 step:15246 [D loss: 0.601485, acc.: 63.28%] [G loss: 1.073999]\n",
      "epoch:16 step:15247 [D loss: 0.274326, acc.: 89.84%] [G loss: 1.154480]\n",
      "epoch:16 step:15248 [D loss: 0.233984, acc.: 98.44%] [G loss: 1.104338]\n",
      "epoch:16 step:15249 [D loss: 0.328338, acc.: 93.75%] [G loss: 1.264438]\n",
      "epoch:16 step:15250 [D loss: 0.694430, acc.: 57.03%] [G loss: 1.073832]\n",
      "epoch:16 step:15251 [D loss: 0.260923, acc.: 92.19%] [G loss: 1.120852]\n",
      "epoch:16 step:15252 [D loss: 0.453793, acc.: 87.50%] [G loss: 1.199934]\n",
      "epoch:16 step:15253 [D loss: 0.207841, acc.: 99.22%] [G loss: 1.211699]\n",
      "epoch:16 step:15254 [D loss: 0.668944, acc.: 62.50%] [G loss: 1.103784]\n",
      "epoch:16 step:15255 [D loss: 0.526821, acc.: 62.50%] [G loss: 1.075154]\n",
      "epoch:16 step:15256 [D loss: 0.732063, acc.: 55.47%] [G loss: 1.243598]\n",
      "epoch:16 step:15257 [D loss: 0.434508, acc.: 85.16%] [G loss: 1.153181]\n",
      "epoch:16 step:15258 [D loss: 0.816793, acc.: 46.88%] [G loss: 1.041440]\n",
      "epoch:16 step:15259 [D loss: 0.677697, acc.: 53.91%] [G loss: 0.936681]\n",
      "epoch:16 step:15260 [D loss: 0.721962, acc.: 50.78%] [G loss: 1.055588]\n",
      "epoch:16 step:15261 [D loss: 0.712330, acc.: 53.12%] [G loss: 1.138583]\n",
      "epoch:16 step:15262 [D loss: 0.697511, acc.: 55.47%] [G loss: 1.032545]\n",
      "epoch:16 step:15263 [D loss: 0.568267, acc.: 67.97%] [G loss: 0.917926]\n",
      "epoch:16 step:15264 [D loss: 0.696510, acc.: 56.25%] [G loss: 1.023403]\n",
      "epoch:16 step:15265 [D loss: 0.644279, acc.: 57.03%] [G loss: 0.956065]\n",
      "epoch:16 step:15266 [D loss: 0.595630, acc.: 64.84%] [G loss: 0.920127]\n",
      "epoch:16 step:15267 [D loss: 0.673657, acc.: 59.38%] [G loss: 0.904447]\n",
      "epoch:16 step:15268 [D loss: 0.648652, acc.: 55.47%] [G loss: 0.734215]\n",
      "epoch:16 step:15269 [D loss: 0.730556, acc.: 41.41%] [G loss: 0.775996]\n",
      "epoch:16 step:15270 [D loss: 0.349429, acc.: 92.97%] [G loss: 0.877460]\n",
      "epoch:16 step:15271 [D loss: 0.297445, acc.: 90.62%] [G loss: 1.043937]\n",
      "epoch:16 step:15272 [D loss: 0.679176, acc.: 60.94%] [G loss: 0.870066]\n",
      "epoch:16 step:15273 [D loss: 0.770216, acc.: 44.53%] [G loss: 0.956433]\n",
      "epoch:16 step:15274 [D loss: 0.641243, acc.: 61.72%] [G loss: 0.811201]\n",
      "epoch:16 step:15275 [D loss: 0.793576, acc.: 46.88%] [G loss: 0.855800]\n",
      "epoch:16 step:15276 [D loss: 0.532735, acc.: 77.34%] [G loss: 0.937757]\n",
      "epoch:16 step:15277 [D loss: 0.552516, acc.: 78.91%] [G loss: 0.948221]\n",
      "epoch:16 step:15278 [D loss: 0.426676, acc.: 83.59%] [G loss: 0.983211]\n",
      "epoch:16 step:15279 [D loss: 0.370332, acc.: 89.84%] [G loss: 1.052215]\n",
      "epoch:16 step:15280 [D loss: 0.252256, acc.: 95.31%] [G loss: 0.600421]\n",
      "epoch:16 step:15281 [D loss: 0.230368, acc.: 96.88%] [G loss: 1.188671]\n",
      "epoch:16 step:15282 [D loss: 0.551284, acc.: 75.78%] [G loss: 1.159587]\n",
      "epoch:16 step:15283 [D loss: 0.351655, acc.: 91.41%] [G loss: 1.037213]\n",
      "epoch:16 step:15284 [D loss: 1.637919, acc.: 50.00%] [G loss: 1.400566]\n",
      "epoch:16 step:15285 [D loss: 0.541734, acc.: 71.88%] [G loss: 1.455017]\n",
      "epoch:16 step:15286 [D loss: 0.677290, acc.: 66.41%] [G loss: 1.196381]\n",
      "epoch:16 step:15287 [D loss: 0.783416, acc.: 49.22%] [G loss: 1.246960]\n",
      "epoch:16 step:15288 [D loss: 0.775717, acc.: 50.00%] [G loss: 1.141470]\n",
      "epoch:16 step:15289 [D loss: 0.726933, acc.: 52.34%] [G loss: 1.157674]\n",
      "epoch:16 step:15290 [D loss: 0.720211, acc.: 53.12%] [G loss: 0.668813]\n",
      "epoch:16 step:15291 [D loss: 0.671193, acc.: 60.16%] [G loss: 0.994798]\n",
      "epoch:16 step:15292 [D loss: 0.635379, acc.: 60.16%] [G loss: 0.987896]\n",
      "epoch:16 step:15293 [D loss: 0.928135, acc.: 35.16%] [G loss: 0.972706]\n",
      "epoch:16 step:15294 [D loss: 0.658194, acc.: 63.28%] [G loss: 0.834689]\n",
      "epoch:16 step:15295 [D loss: 0.704751, acc.: 49.22%] [G loss: 0.963667]\n",
      "epoch:16 step:15296 [D loss: 0.654692, acc.: 60.94%] [G loss: 0.961382]\n",
      "epoch:16 step:15297 [D loss: 0.459295, acc.: 87.50%] [G loss: 0.965590]\n",
      "epoch:16 step:15298 [D loss: 0.594134, acc.: 65.62%] [G loss: 0.984026]\n",
      "epoch:16 step:15299 [D loss: 0.621113, acc.: 67.19%] [G loss: 0.561738]\n",
      "epoch:16 step:15300 [D loss: 0.442926, acc.: 87.50%] [G loss: 0.766987]\n",
      "epoch:16 step:15301 [D loss: 0.298840, acc.: 88.28%] [G loss: 1.086615]\n",
      "epoch:16 step:15302 [D loss: 0.637234, acc.: 64.84%] [G loss: 1.021327]\n",
      "epoch:16 step:15303 [D loss: 0.418547, acc.: 89.84%] [G loss: 0.964942]\n",
      "epoch:16 step:15304 [D loss: 0.252611, acc.: 94.53%] [G loss: 1.106655]\n",
      "epoch:16 step:15305 [D loss: 0.345652, acc.: 85.16%] [G loss: 1.045596]\n",
      "epoch:16 step:15306 [D loss: 0.223183, acc.: 97.66%] [G loss: 1.148655]\n",
      "epoch:16 step:15307 [D loss: 1.159174, acc.: 50.00%] [G loss: 1.149609]\n",
      "epoch:16 step:15308 [D loss: 0.755785, acc.: 51.56%] [G loss: 1.345834]\n",
      "epoch:16 step:15309 [D loss: 0.767940, acc.: 53.91%] [G loss: 1.144513]\n",
      "epoch:16 step:15310 [D loss: 0.675744, acc.: 59.38%] [G loss: 1.100892]\n",
      "epoch:16 step:15311 [D loss: 0.744011, acc.: 51.56%] [G loss: 0.787874]\n",
      "epoch:16 step:15312 [D loss: 0.692281, acc.: 53.12%] [G loss: 1.052888]\n",
      "epoch:16 step:15313 [D loss: 1.165770, acc.: 27.34%] [G loss: 0.983085]\n",
      "epoch:16 step:15314 [D loss: 0.777106, acc.: 42.97%] [G loss: 0.959503]\n",
      "epoch:16 step:15315 [D loss: 0.801769, acc.: 43.75%] [G loss: 1.033656]\n",
      "epoch:16 step:15316 [D loss: 0.712268, acc.: 51.56%] [G loss: 0.987113]\n",
      "epoch:16 step:15317 [D loss: 0.787211, acc.: 39.84%] [G loss: 0.966961]\n",
      "epoch:16 step:15318 [D loss: 0.717386, acc.: 43.75%] [G loss: 0.906605]\n",
      "epoch:16 step:15319 [D loss: 0.655859, acc.: 60.94%] [G loss: 0.875163]\n",
      "epoch:16 step:15320 [D loss: 0.621347, acc.: 68.75%] [G loss: 1.128970]\n",
      "epoch:16 step:15321 [D loss: 0.726214, acc.: 45.31%] [G loss: 0.899999]\n",
      "epoch:16 step:15322 [D loss: 0.696027, acc.: 53.12%] [G loss: 1.031056]\n",
      "epoch:16 step:15323 [D loss: 0.657681, acc.: 58.59%] [G loss: 1.040602]\n",
      "epoch:16 step:15324 [D loss: 0.706313, acc.: 49.22%] [G loss: 1.002655]\n",
      "epoch:16 step:15325 [D loss: 0.594718, acc.: 65.62%] [G loss: 0.695365]\n",
      "epoch:16 step:15326 [D loss: 0.745379, acc.: 47.66%] [G loss: 0.978413]\n",
      "epoch:16 step:15327 [D loss: 0.671824, acc.: 60.16%] [G loss: 1.037187]\n",
      "epoch:16 step:15328 [D loss: 0.585701, acc.: 69.53%] [G loss: 0.889835]\n",
      "epoch:16 step:15329 [D loss: 0.664948, acc.: 58.59%] [G loss: 0.947168]\n",
      "epoch:16 step:15330 [D loss: 0.696332, acc.: 47.66%] [G loss: 0.829277]\n",
      "epoch:16 step:15331 [D loss: 0.634812, acc.: 63.28%] [G loss: 0.938403]\n",
      "epoch:16 step:15332 [D loss: 0.690668, acc.: 46.88%] [G loss: 1.013987]\n",
      "epoch:16 step:15333 [D loss: 0.677363, acc.: 51.56%] [G loss: 1.024683]\n",
      "epoch:16 step:15334 [D loss: 0.672122, acc.: 53.12%] [G loss: 0.939767]\n",
      "epoch:16 step:15335 [D loss: 0.583181, acc.: 67.19%] [G loss: 0.943929]\n",
      "epoch:16 step:15336 [D loss: 0.568212, acc.: 75.78%] [G loss: 0.998026]\n",
      "epoch:16 step:15337 [D loss: 0.774382, acc.: 53.12%] [G loss: 0.789114]\n",
      "epoch:16 step:15338 [D loss: 0.655086, acc.: 64.84%] [G loss: 0.956418]\n",
      "epoch:16 step:15339 [D loss: 0.524307, acc.: 72.66%] [G loss: 0.770042]\n",
      "epoch:16 step:15340 [D loss: 0.654403, acc.: 57.03%] [G loss: 0.978083]\n",
      "epoch:16 step:15341 [D loss: 0.769459, acc.: 41.41%] [G loss: 1.095111]\n",
      "epoch:16 step:15342 [D loss: 0.634334, acc.: 58.59%] [G loss: 1.124783]\n",
      "epoch:16 step:15343 [D loss: 0.462317, acc.: 91.41%] [G loss: 0.967416]\n",
      "epoch:16 step:15344 [D loss: 0.384355, acc.: 96.88%] [G loss: 1.383527]\n",
      "epoch:16 step:15345 [D loss: 0.400707, acc.: 97.66%] [G loss: 1.302376]\n",
      "epoch:16 step:15346 [D loss: 0.509472, acc.: 85.94%] [G loss: 1.429030]\n",
      "epoch:16 step:15347 [D loss: 0.425914, acc.: 92.97%] [G loss: 0.847473]\n",
      "epoch:16 step:15348 [D loss: 0.661096, acc.: 59.38%] [G loss: 0.720529]\n",
      "epoch:16 step:15349 [D loss: 0.485511, acc.: 91.41%] [G loss: 0.857872]\n",
      "epoch:16 step:15350 [D loss: 0.414805, acc.: 92.97%] [G loss: 0.792117]\n",
      "epoch:16 step:15351 [D loss: 0.483297, acc.: 85.16%] [G loss: 1.658983]\n",
      "epoch:16 step:15352 [D loss: 0.595328, acc.: 68.75%] [G loss: 0.701989]\n",
      "epoch:16 step:15353 [D loss: 0.602635, acc.: 65.62%] [G loss: 0.981210]\n",
      "epoch:16 step:15354 [D loss: 1.331991, acc.: 16.41%] [G loss: 0.746999]\n",
      "epoch:16 step:15355 [D loss: 0.837465, acc.: 54.69%] [G loss: 0.797595]\n",
      "epoch:16 step:15356 [D loss: 0.734639, acc.: 52.34%] [G loss: 0.724167]\n",
      "epoch:16 step:15357 [D loss: 0.908900, acc.: 30.47%] [G loss: 0.803491]\n",
      "epoch:16 step:15358 [D loss: 0.815526, acc.: 38.28%] [G loss: 0.865680]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15359 [D loss: 0.830380, acc.: 30.47%] [G loss: 0.975552]\n",
      "epoch:16 step:15360 [D loss: 0.692828, acc.: 48.44%] [G loss: 0.828086]\n",
      "epoch:16 step:15361 [D loss: 0.607143, acc.: 67.97%] [G loss: 0.854275]\n",
      "epoch:16 step:15362 [D loss: 0.455671, acc.: 85.94%] [G loss: 0.945604]\n",
      "epoch:16 step:15363 [D loss: 0.405693, acc.: 86.72%] [G loss: 0.987563]\n",
      "epoch:16 step:15364 [D loss: 0.649814, acc.: 55.47%] [G loss: 0.804398]\n",
      "epoch:16 step:15365 [D loss: 0.864196, acc.: 28.91%] [G loss: 0.897177]\n",
      "epoch:16 step:15366 [D loss: 0.687979, acc.: 53.91%] [G loss: 0.814293]\n",
      "epoch:16 step:15367 [D loss: 0.774107, acc.: 42.19%] [G loss: 0.977719]\n",
      "epoch:16 step:15368 [D loss: 0.755434, acc.: 50.00%] [G loss: 0.830510]\n",
      "epoch:16 step:15369 [D loss: 0.630207, acc.: 63.28%] [G loss: 0.887442]\n",
      "epoch:16 step:15370 [D loss: 0.551658, acc.: 77.34%] [G loss: 0.881137]\n",
      "epoch:16 step:15371 [D loss: 0.713732, acc.: 55.47%] [G loss: 0.992847]\n",
      "epoch:16 step:15372 [D loss: 0.538514, acc.: 78.91%] [G loss: 0.891309]\n",
      "epoch:16 step:15373 [D loss: 0.573285, acc.: 71.09%] [G loss: 0.713806]\n",
      "epoch:16 step:15374 [D loss: 0.671422, acc.: 57.81%] [G loss: 0.832473]\n",
      "epoch:16 step:15375 [D loss: 0.742054, acc.: 45.31%] [G loss: 0.931625]\n",
      "epoch:16 step:15376 [D loss: 0.650715, acc.: 55.47%] [G loss: 1.081807]\n",
      "epoch:16 step:15377 [D loss: 0.734251, acc.: 44.53%] [G loss: 0.870002]\n",
      "epoch:16 step:15378 [D loss: 0.679603, acc.: 52.34%] [G loss: 0.869017]\n",
      "epoch:16 step:15379 [D loss: 0.756570, acc.: 43.75%] [G loss: 0.785128]\n",
      "epoch:16 step:15380 [D loss: 0.663098, acc.: 60.94%] [G loss: 0.921821]\n",
      "epoch:16 step:15381 [D loss: 0.654764, acc.: 63.28%] [G loss: 0.986341]\n",
      "epoch:16 step:15382 [D loss: 0.575705, acc.: 71.09%] [G loss: 0.898177]\n",
      "epoch:16 step:15383 [D loss: 0.662101, acc.: 57.81%] [G loss: 0.920957]\n",
      "epoch:16 step:15384 [D loss: 0.764341, acc.: 42.97%] [G loss: 0.831672]\n",
      "epoch:16 step:15385 [D loss: 0.600771, acc.: 64.06%] [G loss: 0.905364]\n",
      "epoch:16 step:15386 [D loss: 0.726930, acc.: 46.09%] [G loss: 0.959398]\n",
      "epoch:16 step:15387 [D loss: 0.667014, acc.: 59.38%] [G loss: 0.937743]\n",
      "epoch:16 step:15388 [D loss: 0.394677, acc.: 79.69%] [G loss: 1.052335]\n",
      "epoch:16 step:15389 [D loss: 0.309060, acc.: 88.28%] [G loss: 1.095602]\n",
      "epoch:16 step:15390 [D loss: 0.276835, acc.: 91.41%] [G loss: 1.114279]\n",
      "epoch:16 step:15391 [D loss: 0.298917, acc.: 94.53%] [G loss: 1.123975]\n",
      "epoch:16 step:15392 [D loss: 0.327981, acc.: 96.88%] [G loss: 1.137485]\n",
      "epoch:16 step:15393 [D loss: 0.485446, acc.: 78.12%] [G loss: 1.179560]\n",
      "epoch:16 step:15394 [D loss: 0.270590, acc.: 96.88%] [G loss: 1.222803]\n",
      "epoch:16 step:15395 [D loss: 0.361688, acc.: 95.31%] [G loss: 1.311949]\n",
      "epoch:16 step:15396 [D loss: 0.274388, acc.: 96.09%] [G loss: 1.197188]\n",
      "epoch:16 step:15397 [D loss: 0.233368, acc.: 97.66%] [G loss: 1.177675]\n",
      "epoch:16 step:15398 [D loss: 0.194598, acc.: 99.22%] [G loss: 1.422571]\n",
      "epoch:16 step:15399 [D loss: 0.195598, acc.: 100.00%] [G loss: 1.055628]\n",
      "epoch:16 step:15400 [D loss: 0.311190, acc.: 96.88%] [G loss: 1.303228]\n",
      "##############\n",
      "[4.1262417  2.38291899 6.90204718 5.5311517  4.62865035 6.24873143\n",
      " 5.33740242 5.49402976 5.88965833 4.87876853]\n",
      "##########\n",
      "epoch:16 step:15401 [D loss: 0.307240, acc.: 87.50%] [G loss: 1.504264]\n",
      "epoch:16 step:15402 [D loss: 0.363432, acc.: 89.06%] [G loss: 1.420570]\n",
      "epoch:16 step:15403 [D loss: 0.944880, acc.: 49.22%] [G loss: 1.216532]\n",
      "epoch:16 step:15404 [D loss: 0.411377, acc.: 93.75%] [G loss: 0.983549]\n",
      "epoch:16 step:15405 [D loss: 0.467955, acc.: 66.41%] [G loss: 0.743203]\n",
      "epoch:16 step:15406 [D loss: 0.271095, acc.: 95.31%] [G loss: 1.340562]\n",
      "epoch:16 step:15407 [D loss: 0.503029, acc.: 74.22%] [G loss: 1.045334]\n",
      "epoch:16 step:15408 [D loss: 0.815809, acc.: 55.47%] [G loss: 0.630885]\n",
      "epoch:16 step:15409 [D loss: 0.432437, acc.: 84.38%] [G loss: 1.477026]\n",
      "epoch:16 step:15410 [D loss: 0.184071, acc.: 100.00%] [G loss: 1.164347]\n",
      "epoch:16 step:15411 [D loss: 0.478035, acc.: 76.56%] [G loss: 1.875250]\n",
      "epoch:16 step:15412 [D loss: 0.490920, acc.: 79.69%] [G loss: 1.142911]\n",
      "epoch:16 step:15413 [D loss: 1.107350, acc.: 31.25%] [G loss: 0.395518]\n",
      "epoch:16 step:15414 [D loss: 1.304982, acc.: 11.72%] [G loss: 0.908110]\n",
      "epoch:16 step:15415 [D loss: 0.966352, acc.: 29.69%] [G loss: 0.609461]\n",
      "epoch:16 step:15416 [D loss: 0.452209, acc.: 85.94%] [G loss: 1.393681]\n",
      "epoch:16 step:15417 [D loss: 0.556742, acc.: 70.31%] [G loss: 1.062966]\n",
      "epoch:16 step:15418 [D loss: 0.964230, acc.: 37.50%] [G loss: 1.220240]\n",
      "epoch:16 step:15419 [D loss: 0.737500, acc.: 48.44%] [G loss: 0.992625]\n",
      "epoch:16 step:15420 [D loss: 0.619100, acc.: 64.84%] [G loss: 1.029669]\n",
      "epoch:16 step:15421 [D loss: 0.842839, acc.: 43.75%] [G loss: 1.211041]\n",
      "epoch:16 step:15422 [D loss: 0.678088, acc.: 59.38%] [G loss: 1.151067]\n",
      "epoch:16 step:15423 [D loss: 0.819021, acc.: 45.31%] [G loss: 1.144402]\n",
      "epoch:16 step:15424 [D loss: 0.743178, acc.: 51.56%] [G loss: 1.109457]\n",
      "epoch:16 step:15425 [D loss: 0.761517, acc.: 50.00%] [G loss: 1.145370]\n",
      "epoch:16 step:15426 [D loss: 0.728763, acc.: 51.56%] [G loss: 1.192943]\n",
      "epoch:16 step:15427 [D loss: 0.689106, acc.: 54.69%] [G loss: 1.021859]\n",
      "epoch:16 step:15428 [D loss: 0.662751, acc.: 57.03%] [G loss: 1.059803]\n",
      "epoch:16 step:15429 [D loss: 0.736647, acc.: 49.22%] [G loss: 1.159691]\n",
      "epoch:16 step:15430 [D loss: 0.755713, acc.: 49.22%] [G loss: 1.076210]\n",
      "epoch:16 step:15431 [D loss: 0.679056, acc.: 53.12%] [G loss: 1.077121]\n",
      "epoch:16 step:15432 [D loss: 0.710715, acc.: 52.34%] [G loss: 1.054572]\n",
      "epoch:16 step:15433 [D loss: 0.632943, acc.: 60.16%] [G loss: 1.073345]\n",
      "epoch:16 step:15434 [D loss: 0.661273, acc.: 60.16%] [G loss: 1.058023]\n",
      "epoch:16 step:15435 [D loss: 0.576513, acc.: 71.09%] [G loss: 1.089278]\n",
      "epoch:16 step:15436 [D loss: 0.624181, acc.: 58.59%] [G loss: 1.115707]\n",
      "epoch:16 step:15437 [D loss: 0.651513, acc.: 60.94%] [G loss: 1.128662]\n",
      "epoch:16 step:15438 [D loss: 0.633143, acc.: 56.25%] [G loss: 1.062279]\n",
      "epoch:16 step:15439 [D loss: 0.638289, acc.: 60.16%] [G loss: 0.989057]\n",
      "epoch:16 step:15440 [D loss: 0.540068, acc.: 83.59%] [G loss: 1.119540]\n",
      "epoch:16 step:15441 [D loss: 0.498014, acc.: 89.84%] [G loss: 1.277485]\n",
      "epoch:16 step:15442 [D loss: 0.494895, acc.: 88.28%] [G loss: 1.169351]\n",
      "epoch:16 step:15443 [D loss: 0.399204, acc.: 98.44%] [G loss: 1.287850]\n",
      "epoch:16 step:15444 [D loss: 0.409224, acc.: 97.66%] [G loss: 1.502424]\n",
      "epoch:16 step:15445 [D loss: 0.415134, acc.: 92.19%] [G loss: 1.381950]\n",
      "epoch:16 step:15446 [D loss: 0.451144, acc.: 89.06%] [G loss: 1.522861]\n",
      "epoch:16 step:15447 [D loss: 0.409278, acc.: 85.94%] [G loss: 1.608759]\n",
      "epoch:16 step:15448 [D loss: 0.361690, acc.: 90.62%] [G loss: 1.275351]\n",
      "epoch:16 step:15449 [D loss: 0.392410, acc.: 92.97%] [G loss: 1.376342]\n",
      "epoch:16 step:15450 [D loss: 0.595114, acc.: 66.41%] [G loss: 1.112102]\n",
      "epoch:16 step:15451 [D loss: 0.533375, acc.: 79.69%] [G loss: 1.411814]\n",
      "epoch:16 step:15452 [D loss: 0.550878, acc.: 73.44%] [G loss: 0.729030]\n",
      "epoch:16 step:15453 [D loss: 0.986769, acc.: 34.38%] [G loss: 1.049995]\n",
      "epoch:16 step:15454 [D loss: 1.269799, acc.: 10.16%] [G loss: 0.421147]\n",
      "epoch:16 step:15455 [D loss: 0.789282, acc.: 33.59%] [G loss: 0.537895]\n",
      "epoch:16 step:15456 [D loss: 0.771532, acc.: 49.22%] [G loss: 0.517734]\n",
      "epoch:16 step:15457 [D loss: 0.510986, acc.: 80.47%] [G loss: 0.978947]\n",
      "epoch:16 step:15458 [D loss: 0.618105, acc.: 62.50%] [G loss: 0.614729]\n",
      "epoch:16 step:15459 [D loss: 0.555478, acc.: 64.84%] [G loss: 0.775850]\n",
      "epoch:16 step:15460 [D loss: 0.487276, acc.: 71.09%] [G loss: 1.335313]\n",
      "epoch:16 step:15461 [D loss: 0.520101, acc.: 74.22%] [G loss: 1.068763]\n",
      "epoch:16 step:15462 [D loss: 0.503987, acc.: 58.59%] [G loss: 0.954251]\n",
      "epoch:16 step:15463 [D loss: 0.335697, acc.: 93.75%] [G loss: 1.244085]\n",
      "epoch:16 step:15464 [D loss: 0.457084, acc.: 89.06%] [G loss: 1.675530]\n",
      "epoch:16 step:15465 [D loss: 1.024922, acc.: 37.50%] [G loss: 0.847086]\n",
      "epoch:16 step:15466 [D loss: 1.039746, acc.: 11.72%] [G loss: 0.679107]\n",
      "epoch:16 step:15467 [D loss: 0.787802, acc.: 35.16%] [G loss: 0.630532]\n",
      "epoch:16 step:15468 [D loss: 0.665188, acc.: 61.72%] [G loss: 0.846703]\n",
      "epoch:16 step:15469 [D loss: 0.667367, acc.: 62.50%] [G loss: 0.684638]\n",
      "epoch:16 step:15470 [D loss: 0.627569, acc.: 63.28%] [G loss: 1.032121]\n",
      "epoch:16 step:15471 [D loss: 0.575446, acc.: 75.00%] [G loss: 0.820451]\n",
      "epoch:16 step:15472 [D loss: 0.554853, acc.: 75.78%] [G loss: 0.789044]\n",
      "epoch:16 step:15473 [D loss: 0.553791, acc.: 70.31%] [G loss: 1.117434]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15474 [D loss: 0.911471, acc.: 32.03%] [G loss: 0.754872]\n",
      "epoch:16 step:15475 [D loss: 0.744410, acc.: 46.09%] [G loss: 0.839311]\n",
      "epoch:16 step:15476 [D loss: 0.796293, acc.: 37.50%] [G loss: 0.841896]\n",
      "epoch:16 step:15477 [D loss: 0.732704, acc.: 45.31%] [G loss: 0.697647]\n",
      "epoch:16 step:15478 [D loss: 0.720826, acc.: 50.00%] [G loss: 0.839030]\n",
      "epoch:16 step:15479 [D loss: 0.748192, acc.: 44.53%] [G loss: 0.879428]\n",
      "epoch:16 step:15480 [D loss: 0.690724, acc.: 53.91%] [G loss: 1.159757]\n",
      "epoch:16 step:15481 [D loss: 0.733272, acc.: 48.44%] [G loss: 0.812109]\n",
      "epoch:16 step:15482 [D loss: 0.650554, acc.: 58.59%] [G loss: 1.114114]\n",
      "epoch:16 step:15483 [D loss: 0.671175, acc.: 57.03%] [G loss: 0.775513]\n",
      "epoch:16 step:15484 [D loss: 0.731800, acc.: 46.09%] [G loss: 0.693740]\n",
      "epoch:16 step:15485 [D loss: 0.683310, acc.: 54.69%] [G loss: 0.814901]\n",
      "epoch:16 step:15486 [D loss: 0.664986, acc.: 62.50%] [G loss: 0.857980]\n",
      "epoch:16 step:15487 [D loss: 0.738083, acc.: 43.75%] [G loss: 0.778830]\n",
      "epoch:16 step:15488 [D loss: 0.653658, acc.: 60.16%] [G loss: 0.870832]\n",
      "epoch:16 step:15489 [D loss: 0.603972, acc.: 65.62%] [G loss: 0.915845]\n",
      "epoch:16 step:15490 [D loss: 0.590801, acc.: 68.75%] [G loss: 0.954829]\n",
      "epoch:16 step:15491 [D loss: 0.579177, acc.: 73.44%] [G loss: 0.994586]\n",
      "epoch:16 step:15492 [D loss: 0.679235, acc.: 61.72%] [G loss: 0.984359]\n",
      "epoch:16 step:15493 [D loss: 0.640990, acc.: 61.72%] [G loss: 0.913559]\n",
      "epoch:16 step:15494 [D loss: 0.655293, acc.: 61.72%] [G loss: 0.962569]\n",
      "epoch:16 step:15495 [D loss: 0.684166, acc.: 60.16%] [G loss: 0.887927]\n",
      "epoch:16 step:15496 [D loss: 0.642558, acc.: 66.41%] [G loss: 0.816966]\n",
      "epoch:16 step:15497 [D loss: 0.694231, acc.: 53.91%] [G loss: 0.858504]\n",
      "epoch:16 step:15498 [D loss: 0.731005, acc.: 39.84%] [G loss: 0.835660]\n",
      "epoch:16 step:15499 [D loss: 0.686052, acc.: 59.38%] [G loss: 0.889916]\n",
      "epoch:16 step:15500 [D loss: 0.666008, acc.: 55.47%] [G loss: 0.816005]\n",
      "epoch:16 step:15501 [D loss: 0.661467, acc.: 62.50%] [G loss: 0.928316]\n",
      "epoch:16 step:15502 [D loss: 0.613785, acc.: 67.19%] [G loss: 0.908250]\n",
      "epoch:16 step:15503 [D loss: 0.504339, acc.: 81.25%] [G loss: 0.914421]\n",
      "epoch:16 step:15504 [D loss: 0.494704, acc.: 87.50%] [G loss: 0.940917]\n",
      "epoch:16 step:15505 [D loss: 0.481757, acc.: 79.69%] [G loss: 0.984377]\n",
      "epoch:16 step:15506 [D loss: 0.453067, acc.: 85.16%] [G loss: 1.085570]\n",
      "epoch:16 step:15507 [D loss: 0.417092, acc.: 82.81%] [G loss: 1.115844]\n",
      "epoch:16 step:15508 [D loss: 0.626935, acc.: 65.62%] [G loss: 0.931626]\n",
      "epoch:16 step:15509 [D loss: 0.649570, acc.: 68.75%] [G loss: 0.982957]\n",
      "epoch:16 step:15510 [D loss: 0.683572, acc.: 60.16%] [G loss: 0.848895]\n",
      "epoch:16 step:15511 [D loss: 0.638752, acc.: 63.28%] [G loss: 0.780054]\n",
      "epoch:16 step:15512 [D loss: 0.618601, acc.: 64.06%] [G loss: 0.888969]\n",
      "epoch:16 step:15513 [D loss: 0.813338, acc.: 36.72%] [G loss: 1.005333]\n",
      "epoch:16 step:15514 [D loss: 0.645685, acc.: 61.72%] [G loss: 0.871508]\n",
      "epoch:16 step:15515 [D loss: 0.618263, acc.: 64.84%] [G loss: 0.991537]\n",
      "epoch:16 step:15516 [D loss: 0.396443, acc.: 89.84%] [G loss: 1.047666]\n",
      "epoch:16 step:15517 [D loss: 0.696041, acc.: 53.12%] [G loss: 0.964923]\n",
      "epoch:16 step:15518 [D loss: 0.564602, acc.: 75.00%] [G loss: 1.080321]\n",
      "epoch:16 step:15519 [D loss: 0.483202, acc.: 75.00%] [G loss: 0.971665]\n",
      "epoch:16 step:15520 [D loss: 0.617437, acc.: 70.31%] [G loss: 1.145092]\n",
      "epoch:16 step:15521 [D loss: 0.679620, acc.: 59.38%] [G loss: 1.094673]\n",
      "epoch:16 step:15522 [D loss: 0.414393, acc.: 82.03%] [G loss: 1.232929]\n",
      "epoch:16 step:15523 [D loss: 0.811230, acc.: 40.62%] [G loss: 0.801026]\n",
      "epoch:16 step:15524 [D loss: 0.671173, acc.: 58.59%] [G loss: 1.015404]\n",
      "epoch:16 step:15525 [D loss: 0.691587, acc.: 58.59%] [G loss: 0.942029]\n",
      "epoch:16 step:15526 [D loss: 0.663052, acc.: 55.47%] [G loss: 0.993264]\n",
      "epoch:16 step:15527 [D loss: 0.484305, acc.: 75.00%] [G loss: 0.978391]\n",
      "epoch:16 step:15528 [D loss: 0.364771, acc.: 88.28%] [G loss: 1.009765]\n",
      "epoch:16 step:15529 [D loss: 0.391168, acc.: 91.41%] [G loss: 1.036567]\n",
      "epoch:16 step:15530 [D loss: 0.494272, acc.: 83.59%] [G loss: 0.954193]\n",
      "epoch:16 step:15531 [D loss: 0.436864, acc.: 85.94%] [G loss: 1.200719]\n",
      "epoch:16 step:15532 [D loss: 0.404580, acc.: 87.50%] [G loss: 1.130080]\n",
      "epoch:16 step:15533 [D loss: 0.418374, acc.: 92.97%] [G loss: 1.172786]\n",
      "epoch:16 step:15534 [D loss: 0.743135, acc.: 58.59%] [G loss: 0.895010]\n",
      "epoch:16 step:15535 [D loss: 0.608882, acc.: 64.84%] [G loss: 1.132016]\n",
      "epoch:16 step:15536 [D loss: 1.203583, acc.: 12.50%] [G loss: 0.817007]\n",
      "epoch:16 step:15537 [D loss: 0.769289, acc.: 46.88%] [G loss: 0.806412]\n",
      "epoch:16 step:15538 [D loss: 0.667792, acc.: 60.16%] [G loss: 1.104300]\n",
      "epoch:16 step:15539 [D loss: 0.787321, acc.: 42.19%] [G loss: 0.798717]\n",
      "epoch:16 step:15540 [D loss: 0.648153, acc.: 61.72%] [G loss: 1.044154]\n",
      "epoch:16 step:15541 [D loss: 0.614631, acc.: 66.41%] [G loss: 1.053977]\n",
      "epoch:16 step:15542 [D loss: 0.540090, acc.: 76.56%] [G loss: 0.988928]\n",
      "epoch:16 step:15543 [D loss: 0.584049, acc.: 70.31%] [G loss: 1.021158]\n",
      "epoch:16 step:15544 [D loss: 0.565708, acc.: 75.00%] [G loss: 0.864581]\n",
      "epoch:16 step:15545 [D loss: 0.632403, acc.: 62.50%] [G loss: 1.030580]\n",
      "epoch:16 step:15546 [D loss: 0.460957, acc.: 85.16%] [G loss: 0.925600]\n",
      "epoch:16 step:15547 [D loss: 0.513493, acc.: 78.12%] [G loss: 1.033316]\n",
      "epoch:16 step:15548 [D loss: 0.470406, acc.: 83.59%] [G loss: 1.090032]\n",
      "epoch:16 step:15549 [D loss: 0.448923, acc.: 88.28%] [G loss: 1.029182]\n",
      "epoch:16 step:15550 [D loss: 0.516222, acc.: 77.34%] [G loss: 1.038318]\n",
      "epoch:16 step:15551 [D loss: 0.482739, acc.: 78.91%] [G loss: 1.036997]\n",
      "epoch:16 step:15552 [D loss: 0.593423, acc.: 69.53%] [G loss: 1.124402]\n",
      "epoch:16 step:15553 [D loss: 0.360796, acc.: 92.97%] [G loss: 0.753314]\n",
      "epoch:16 step:15554 [D loss: 0.578586, acc.: 71.09%] [G loss: 0.943874]\n",
      "epoch:16 step:15555 [D loss: 0.591159, acc.: 68.75%] [G loss: 1.014825]\n",
      "epoch:16 step:15556 [D loss: 0.607686, acc.: 70.31%] [G loss: 0.862448]\n",
      "epoch:16 step:15557 [D loss: 0.569593, acc.: 75.00%] [G loss: 0.694640]\n",
      "epoch:16 step:15558 [D loss: 0.537501, acc.: 66.41%] [G loss: 0.791542]\n",
      "epoch:16 step:15559 [D loss: 0.317479, acc.: 92.19%] [G loss: 1.100957]\n",
      "epoch:16 step:15560 [D loss: 0.791297, acc.: 42.97%] [G loss: 1.213726]\n",
      "epoch:16 step:15561 [D loss: 0.631595, acc.: 62.50%] [G loss: 1.056558]\n",
      "epoch:16 step:15562 [D loss: 0.876303, acc.: 39.06%] [G loss: 0.975783]\n",
      "epoch:16 step:15563 [D loss: 0.680871, acc.: 57.03%] [G loss: 1.201552]\n",
      "epoch:16 step:15564 [D loss: 0.735947, acc.: 46.88%] [G loss: 1.167550]\n",
      "epoch:16 step:15565 [D loss: 0.698500, acc.: 56.25%] [G loss: 1.061520]\n",
      "epoch:16 step:15566 [D loss: 0.606635, acc.: 69.53%] [G loss: 1.185249]\n",
      "epoch:16 step:15567 [D loss: 0.555469, acc.: 70.31%] [G loss: 1.177005]\n",
      "epoch:16 step:15568 [D loss: 0.634392, acc.: 65.62%] [G loss: 1.068249]\n",
      "epoch:16 step:15569 [D loss: 0.640929, acc.: 67.97%] [G loss: 0.690674]\n",
      "epoch:16 step:15570 [D loss: 0.719896, acc.: 55.47%] [G loss: 1.025995]\n",
      "epoch:16 step:15571 [D loss: 0.605515, acc.: 69.53%] [G loss: 0.837357]\n",
      "epoch:16 step:15572 [D loss: 0.552508, acc.: 77.34%] [G loss: 0.774344]\n",
      "epoch:16 step:15573 [D loss: 0.665734, acc.: 64.06%] [G loss: 0.880390]\n",
      "epoch:16 step:15574 [D loss: 0.478997, acc.: 85.94%] [G loss: 0.995117]\n",
      "epoch:16 step:15575 [D loss: 0.439757, acc.: 86.72%] [G loss: 0.977945]\n",
      "epoch:16 step:15576 [D loss: 0.520281, acc.: 73.44%] [G loss: 1.073517]\n",
      "epoch:16 step:15577 [D loss: 0.362246, acc.: 85.94%] [G loss: 1.019958]\n",
      "epoch:16 step:15578 [D loss: 0.477357, acc.: 76.56%] [G loss: 1.243535]\n",
      "epoch:16 step:15579 [D loss: 0.788776, acc.: 50.78%] [G loss: 0.900334]\n",
      "epoch:16 step:15580 [D loss: 0.685690, acc.: 56.25%] [G loss: 1.027340]\n",
      "epoch:16 step:15581 [D loss: 0.388086, acc.: 90.62%] [G loss: 0.878010]\n",
      "epoch:16 step:15582 [D loss: 0.687935, acc.: 57.81%] [G loss: 1.165755]\n",
      "epoch:16 step:15583 [D loss: 0.336615, acc.: 88.28%] [G loss: 1.200598]\n",
      "epoch:16 step:15584 [D loss: 0.357003, acc.: 85.94%] [G loss: 1.165268]\n",
      "epoch:16 step:15585 [D loss: 0.525699, acc.: 75.00%] [G loss: 1.201934]\n",
      "epoch:16 step:15586 [D loss: 0.843592, acc.: 44.53%] [G loss: 0.676559]\n",
      "epoch:16 step:15587 [D loss: 0.967916, acc.: 29.69%] [G loss: 0.991529]\n",
      "epoch:16 step:15588 [D loss: 0.460463, acc.: 81.25%] [G loss: 1.071637]\n",
      "epoch:16 step:15589 [D loss: 0.752365, acc.: 52.34%] [G loss: 0.825612]\n",
      "epoch:16 step:15590 [D loss: 0.493728, acc.: 82.81%] [G loss: 1.115466]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15591 [D loss: 1.139017, acc.: 34.38%] [G loss: 0.748636]\n",
      "epoch:16 step:15592 [D loss: 0.589754, acc.: 70.31%] [G loss: 1.183073]\n",
      "epoch:16 step:15593 [D loss: 0.496831, acc.: 82.03%] [G loss: 1.160507]\n",
      "epoch:16 step:15594 [D loss: 0.545670, acc.: 75.78%] [G loss: 1.154311]\n",
      "epoch:16 step:15595 [D loss: 0.778369, acc.: 42.97%] [G loss: 1.113144]\n",
      "epoch:16 step:15596 [D loss: 0.441841, acc.: 75.00%] [G loss: 0.868610]\n",
      "epoch:16 step:15597 [D loss: 0.701920, acc.: 54.69%] [G loss: 0.999882]\n",
      "epoch:16 step:15598 [D loss: 0.752043, acc.: 50.78%] [G loss: 1.072332]\n",
      "epoch:16 step:15599 [D loss: 0.702097, acc.: 53.91%] [G loss: 1.001712]\n",
      "epoch:16 step:15600 [D loss: 0.561771, acc.: 73.44%] [G loss: 1.042768]\n",
      "##############\n",
      "[3.27844968 2.27689446 6.77510523 5.45518497 4.6619853  6.2849792\n",
      " 5.27393646 5.69612281 5.07071205 4.67135768]\n",
      "##########\n",
      "epoch:16 step:15601 [D loss: 0.357767, acc.: 90.62%] [G loss: 1.130406]\n",
      "epoch:16 step:15602 [D loss: 0.726259, acc.: 51.56%] [G loss: 1.012292]\n",
      "epoch:16 step:15603 [D loss: 0.362258, acc.: 93.75%] [G loss: 1.131642]\n",
      "epoch:16 step:15604 [D loss: 0.358210, acc.: 92.97%] [G loss: 1.065082]\n",
      "epoch:16 step:15605 [D loss: 0.733880, acc.: 46.88%] [G loss: 1.231890]\n",
      "epoch:16 step:15606 [D loss: 0.722278, acc.: 53.12%] [G loss: 1.002986]\n",
      "epoch:16 step:15607 [D loss: 0.678648, acc.: 63.28%] [G loss: 1.092306]\n",
      "epoch:16 step:15608 [D loss: 0.751768, acc.: 41.41%] [G loss: 1.004452]\n",
      "epoch:16 step:15609 [D loss: 0.875997, acc.: 26.56%] [G loss: 0.951385]\n",
      "epoch:16 step:15610 [D loss: 0.355467, acc.: 92.19%] [G loss: 0.962088]\n",
      "epoch:16 step:15611 [D loss: 0.396756, acc.: 94.53%] [G loss: 0.865789]\n",
      "epoch:16 step:15612 [D loss: 0.345975, acc.: 93.75%] [G loss: 0.931908]\n",
      "epoch:16 step:15613 [D loss: 0.647420, acc.: 62.50%] [G loss: 1.038021]\n",
      "epoch:16 step:15614 [D loss: 0.924293, acc.: 25.78%] [G loss: 1.030298]\n",
      "epoch:16 step:15615 [D loss: 0.743315, acc.: 45.31%] [G loss: 0.954346]\n",
      "epoch:16 step:15616 [D loss: 0.751771, acc.: 42.19%] [G loss: 0.970331]\n",
      "epoch:16 step:15617 [D loss: 0.375340, acc.: 91.41%] [G loss: 1.092912]\n",
      "epoch:16 step:15618 [D loss: 0.679679, acc.: 59.38%] [G loss: 1.031469]\n",
      "epoch:16 step:15619 [D loss: 0.425893, acc.: 82.03%] [G loss: 0.765229]\n",
      "epoch:16 step:15620 [D loss: 0.507463, acc.: 82.81%] [G loss: 1.112825]\n",
      "epoch:16 step:15621 [D loss: 0.986417, acc.: 21.09%] [G loss: 0.657012]\n",
      "epoch:16 step:15622 [D loss: 0.694203, acc.: 57.03%] [G loss: 0.801579]\n",
      "epoch:16 step:15623 [D loss: 0.414175, acc.: 82.81%] [G loss: 0.757506]\n",
      "epoch:16 step:15624 [D loss: 0.737882, acc.: 51.56%] [G loss: 0.902026]\n",
      "epoch:16 step:15625 [D loss: 0.642152, acc.: 60.16%] [G loss: 0.919170]\n",
      "epoch:16 step:15626 [D loss: 0.638811, acc.: 59.38%] [G loss: 0.176919]\n",
      "epoch:16 step:15627 [D loss: 0.773574, acc.: 39.84%] [G loss: 0.887145]\n",
      "epoch:16 step:15628 [D loss: 0.715219, acc.: 51.56%] [G loss: 1.100350]\n",
      "epoch:16 step:15629 [D loss: 1.060938, acc.: 16.41%] [G loss: 1.073821]\n",
      "epoch:16 step:15630 [D loss: 0.721373, acc.: 53.12%] [G loss: 1.052121]\n",
      "epoch:16 step:15631 [D loss: 0.873805, acc.: 27.34%] [G loss: 1.169163]\n",
      "epoch:16 step:15632 [D loss: 0.764465, acc.: 40.62%] [G loss: 0.957669]\n",
      "epoch:16 step:15633 [D loss: 0.489062, acc.: 81.25%] [G loss: 0.982847]\n",
      "epoch:16 step:15634 [D loss: 0.761335, acc.: 46.09%] [G loss: 0.999684]\n",
      "epoch:16 step:15635 [D loss: 0.644581, acc.: 53.12%] [G loss: 0.943447]\n",
      "epoch:16 step:15636 [D loss: 0.431219, acc.: 88.28%] [G loss: 1.045289]\n",
      "epoch:16 step:15637 [D loss: 0.458555, acc.: 85.94%] [G loss: 1.303220]\n",
      "epoch:16 step:15638 [D loss: 0.387909, acc.: 90.62%] [G loss: 1.294364]\n",
      "epoch:16 step:15639 [D loss: 0.406216, acc.: 88.28%] [G loss: 1.465311]\n",
      "epoch:16 step:15640 [D loss: 0.335117, acc.: 93.75%] [G loss: 1.403512]\n",
      "epoch:16 step:15641 [D loss: 0.341726, acc.: 96.09%] [G loss: 1.568911]\n",
      "epoch:16 step:15642 [D loss: 0.277389, acc.: 92.97%] [G loss: 1.725773]\n",
      "epoch:16 step:15643 [D loss: 0.326688, acc.: 96.88%] [G loss: 2.003089]\n",
      "epoch:16 step:15644 [D loss: 0.322146, acc.: 94.53%] [G loss: 2.052588]\n",
      "epoch:16 step:15645 [D loss: 0.542963, acc.: 64.06%] [G loss: 1.599572]\n",
      "epoch:16 step:15646 [D loss: 0.486807, acc.: 78.12%] [G loss: 1.674175]\n",
      "epoch:16 step:15647 [D loss: 0.340043, acc.: 96.09%] [G loss: 1.961568]\n",
      "epoch:16 step:15648 [D loss: 0.293086, acc.: 96.09%] [G loss: 1.605693]\n",
      "epoch:16 step:15649 [D loss: 0.277610, acc.: 96.88%] [G loss: 0.944188]\n",
      "epoch:16 step:15650 [D loss: 0.327696, acc.: 90.62%] [G loss: 1.072947]\n",
      "epoch:16 step:15651 [D loss: 0.228036, acc.: 92.97%] [G loss: 2.007332]\n",
      "epoch:16 step:15652 [D loss: 0.492427, acc.: 67.97%] [G loss: 1.246568]\n",
      "epoch:16 step:15653 [D loss: 0.119099, acc.: 100.00%] [G loss: 1.499482]\n",
      "epoch:16 step:15654 [D loss: 0.924267, acc.: 39.06%] [G loss: 1.345236]\n",
      "epoch:16 step:15655 [D loss: 1.570153, acc.: 42.97%] [G loss: 0.559642]\n",
      "epoch:16 step:15656 [D loss: 1.141689, acc.: 17.19%] [G loss: 1.377578]\n",
      "epoch:16 step:15657 [D loss: 0.647876, acc.: 50.78%] [G loss: 0.958249]\n",
      "epoch:16 step:15658 [D loss: 1.085938, acc.: 21.09%] [G loss: 1.300200]\n",
      "epoch:16 step:15659 [D loss: 0.801561, acc.: 45.31%] [G loss: 1.021926]\n",
      "epoch:16 step:15660 [D loss: 0.597993, acc.: 62.50%] [G loss: 0.894640]\n",
      "epoch:16 step:15661 [D loss: 0.555743, acc.: 67.19%] [G loss: 1.094056]\n",
      "epoch:16 step:15662 [D loss: 0.774860, acc.: 39.84%] [G loss: 1.047543]\n",
      "epoch:16 step:15663 [D loss: 0.754992, acc.: 48.44%] [G loss: 1.135134]\n",
      "epoch:16 step:15664 [D loss: 0.769069, acc.: 42.97%] [G loss: 0.968200]\n",
      "epoch:16 step:15665 [D loss: 0.744879, acc.: 51.56%] [G loss: 1.208939]\n",
      "epoch:16 step:15666 [D loss: 0.774063, acc.: 42.19%] [G loss: 1.132396]\n",
      "epoch:16 step:15667 [D loss: 0.661098, acc.: 59.38%] [G loss: 0.968807]\n",
      "epoch:16 step:15668 [D loss: 0.711678, acc.: 52.34%] [G loss: 0.932574]\n",
      "epoch:16 step:15669 [D loss: 0.570340, acc.: 72.66%] [G loss: 0.989756]\n",
      "epoch:16 step:15670 [D loss: 0.654369, acc.: 64.84%] [G loss: 1.024147]\n",
      "epoch:16 step:15671 [D loss: 0.628180, acc.: 65.62%] [G loss: 0.875266]\n",
      "epoch:16 step:15672 [D loss: 0.693055, acc.: 54.69%] [G loss: 0.843412]\n",
      "epoch:16 step:15673 [D loss: 0.632040, acc.: 67.19%] [G loss: 0.927934]\n",
      "epoch:16 step:15674 [D loss: 0.766494, acc.: 51.56%] [G loss: 0.921500]\n",
      "epoch:16 step:15675 [D loss: 0.640358, acc.: 62.50%] [G loss: 0.896764]\n",
      "epoch:16 step:15676 [D loss: 0.568483, acc.: 73.44%] [G loss: 0.941946]\n",
      "epoch:16 step:15677 [D loss: 0.575520, acc.: 71.88%] [G loss: 1.304779]\n",
      "epoch:16 step:15678 [D loss: 0.574102, acc.: 69.53%] [G loss: 0.999921]\n",
      "epoch:16 step:15679 [D loss: 0.594121, acc.: 66.41%] [G loss: 0.951168]\n",
      "epoch:16 step:15680 [D loss: 0.675655, acc.: 58.59%] [G loss: 0.955987]\n",
      "epoch:16 step:15681 [D loss: 0.730271, acc.: 57.81%] [G loss: 0.868900]\n",
      "epoch:16 step:15682 [D loss: 0.710560, acc.: 53.91%] [G loss: 0.836693]\n",
      "epoch:16 step:15683 [D loss: 0.687801, acc.: 50.78%] [G loss: 0.755893]\n",
      "epoch:16 step:15684 [D loss: 0.741509, acc.: 49.22%] [G loss: 0.869326]\n",
      "epoch:16 step:15685 [D loss: 0.648038, acc.: 64.06%] [G loss: 0.715104]\n",
      "epoch:16 step:15686 [D loss: 0.610312, acc.: 64.84%] [G loss: 0.779034]\n",
      "epoch:16 step:15687 [D loss: 0.677274, acc.: 58.59%] [G loss: 0.776317]\n",
      "epoch:16 step:15688 [D loss: 0.422011, acc.: 80.47%] [G loss: 0.849839]\n",
      "epoch:16 step:15689 [D loss: 0.343034, acc.: 82.81%] [G loss: 1.036224]\n",
      "epoch:16 step:15690 [D loss: 0.392527, acc.: 85.94%] [G loss: 0.966435]\n",
      "epoch:16 step:15691 [D loss: 0.569829, acc.: 70.31%] [G loss: 1.079310]\n",
      "epoch:16 step:15692 [D loss: 0.379259, acc.: 80.47%] [G loss: 1.034424]\n",
      "epoch:16 step:15693 [D loss: 0.243356, acc.: 96.09%] [G loss: 1.499266]\n",
      "epoch:16 step:15694 [D loss: 0.338646, acc.: 88.28%] [G loss: 1.309657]\n",
      "epoch:16 step:15695 [D loss: 0.773397, acc.: 54.69%] [G loss: 1.029883]\n",
      "epoch:16 step:15696 [D loss: 0.485114, acc.: 89.06%] [G loss: 1.174329]\n",
      "epoch:16 step:15697 [D loss: 0.769315, acc.: 46.88%] [G loss: 1.055806]\n",
      "epoch:16 step:15698 [D loss: 0.323863, acc.: 91.41%] [G loss: 1.094122]\n",
      "epoch:16 step:15699 [D loss: 0.291541, acc.: 92.97%] [G loss: 1.269328]\n",
      "epoch:16 step:15700 [D loss: 0.210212, acc.: 99.22%] [G loss: 0.878381]\n",
      "epoch:16 step:15701 [D loss: 0.288942, acc.: 96.09%] [G loss: 1.534014]\n",
      "epoch:16 step:15702 [D loss: 0.911810, acc.: 50.78%] [G loss: 1.190277]\n",
      "epoch:16 step:15703 [D loss: 0.702214, acc.: 57.81%] [G loss: 1.100684]\n",
      "epoch:16 step:15704 [D loss: 0.890095, acc.: 30.47%] [G loss: 1.178840]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15705 [D loss: 0.237036, acc.: 96.88%] [G loss: 1.175674]\n",
      "epoch:16 step:15706 [D loss: 0.229683, acc.: 97.66%] [G loss: 1.103641]\n",
      "epoch:16 step:15707 [D loss: 0.875049, acc.: 39.06%] [G loss: 1.080754]\n",
      "epoch:16 step:15708 [D loss: 0.784433, acc.: 50.78%] [G loss: 1.155755]\n",
      "epoch:16 step:15709 [D loss: 0.684285, acc.: 60.94%] [G loss: 1.052136]\n",
      "epoch:16 step:15710 [D loss: 0.696335, acc.: 56.25%] [G loss: 1.088189]\n",
      "epoch:16 step:15711 [D loss: 0.638413, acc.: 57.03%] [G loss: 1.166044]\n",
      "epoch:16 step:15712 [D loss: 0.643064, acc.: 61.72%] [G loss: 0.980526]\n",
      "epoch:16 step:15713 [D loss: 0.664549, acc.: 60.94%] [G loss: 0.963014]\n",
      "epoch:16 step:15714 [D loss: 0.718716, acc.: 47.66%] [G loss: 1.052039]\n",
      "epoch:16 step:15715 [D loss: 0.623054, acc.: 62.50%] [G loss: 0.928990]\n",
      "epoch:16 step:15716 [D loss: 0.690867, acc.: 52.34%] [G loss: 0.859440]\n",
      "epoch:16 step:15717 [D loss: 0.638889, acc.: 67.19%] [G loss: 1.071072]\n",
      "epoch:16 step:15718 [D loss: 0.614842, acc.: 64.84%] [G loss: 1.049535]\n",
      "epoch:16 step:15719 [D loss: 0.427419, acc.: 85.94%] [G loss: 0.850015]\n",
      "epoch:16 step:15720 [D loss: 0.312064, acc.: 95.31%] [G loss: 1.043742]\n",
      "epoch:16 step:15721 [D loss: 0.353340, acc.: 94.53%] [G loss: 1.049992]\n",
      "epoch:16 step:15722 [D loss: 0.280132, acc.: 92.19%] [G loss: 1.076434]\n",
      "epoch:16 step:15723 [D loss: 0.296279, acc.: 98.44%] [G loss: 1.160611]\n",
      "epoch:16 step:15724 [D loss: 0.252313, acc.: 97.66%] [G loss: 1.358133]\n",
      "epoch:16 step:15725 [D loss: 0.309536, acc.: 95.31%] [G loss: 1.286185]\n",
      "epoch:16 step:15726 [D loss: 0.739925, acc.: 50.78%] [G loss: 1.272928]\n",
      "epoch:16 step:15727 [D loss: 0.729852, acc.: 53.91%] [G loss: 0.957762]\n",
      "epoch:16 step:15728 [D loss: 1.214971, acc.: 17.19%] [G loss: 1.094623]\n",
      "epoch:16 step:15729 [D loss: 0.697156, acc.: 59.38%] [G loss: 1.111457]\n",
      "epoch:16 step:15730 [D loss: 0.771987, acc.: 43.75%] [G loss: 0.884004]\n",
      "epoch:16 step:15731 [D loss: 0.491627, acc.: 81.25%] [G loss: 1.082763]\n",
      "epoch:16 step:15732 [D loss: 0.770354, acc.: 47.66%] [G loss: 1.020751]\n",
      "epoch:16 step:15733 [D loss: 0.597814, acc.: 67.97%] [G loss: 0.840296]\n",
      "epoch:16 step:15734 [D loss: 0.531406, acc.: 78.91%] [G loss: 0.922924]\n",
      "epoch:16 step:15735 [D loss: 0.513976, acc.: 77.34%] [G loss: 1.092436]\n",
      "epoch:16 step:15736 [D loss: 0.692732, acc.: 57.03%] [G loss: 0.452702]\n",
      "epoch:16 step:15737 [D loss: 0.494017, acc.: 82.81%] [G loss: 0.770880]\n",
      "epoch:16 step:15738 [D loss: 0.481755, acc.: 75.78%] [G loss: 0.711723]\n",
      "epoch:16 step:15739 [D loss: 0.749986, acc.: 50.78%] [G loss: 0.734792]\n",
      "epoch:16 step:15740 [D loss: 0.647674, acc.: 58.59%] [G loss: 0.846450]\n",
      "epoch:16 step:15741 [D loss: 0.569577, acc.: 67.97%] [G loss: 1.124905]\n",
      "epoch:16 step:15742 [D loss: 0.469270, acc.: 83.59%] [G loss: 1.026624]\n",
      "epoch:16 step:15743 [D loss: 0.945780, acc.: 23.44%] [G loss: 1.027789]\n",
      "epoch:16 step:15744 [D loss: 1.003403, acc.: 22.66%] [G loss: 1.123590]\n",
      "epoch:16 step:15745 [D loss: 0.668305, acc.: 60.94%] [G loss: 1.260836]\n",
      "epoch:16 step:15746 [D loss: 0.780113, acc.: 48.44%] [G loss: 0.971720]\n",
      "epoch:16 step:15747 [D loss: 0.713320, acc.: 55.47%] [G loss: 1.031322]\n",
      "epoch:16 step:15748 [D loss: 0.696858, acc.: 50.78%] [G loss: 0.996114]\n",
      "epoch:16 step:15749 [D loss: 0.681928, acc.: 52.34%] [G loss: 0.910937]\n",
      "epoch:16 step:15750 [D loss: 0.638173, acc.: 64.06%] [G loss: 0.980863]\n",
      "epoch:16 step:15751 [D loss: 0.468111, acc.: 91.41%] [G loss: 1.022375]\n",
      "epoch:16 step:15752 [D loss: 0.426824, acc.: 89.84%] [G loss: 1.092411]\n",
      "epoch:16 step:15753 [D loss: 0.552339, acc.: 71.09%] [G loss: 1.083673]\n",
      "epoch:16 step:15754 [D loss: 0.698541, acc.: 56.25%] [G loss: 0.962341]\n",
      "epoch:16 step:15755 [D loss: 0.648994, acc.: 58.59%] [G loss: 1.009504]\n",
      "epoch:16 step:15756 [D loss: 0.719920, acc.: 53.91%] [G loss: 0.965877]\n",
      "epoch:16 step:15757 [D loss: 0.591927, acc.: 75.00%] [G loss: 0.952002]\n",
      "epoch:16 step:15758 [D loss: 0.488561, acc.: 79.69%] [G loss: 0.930071]\n",
      "epoch:16 step:15759 [D loss: 0.481921, acc.: 88.28%] [G loss: 1.091080]\n",
      "epoch:16 step:15760 [D loss: 0.329607, acc.: 87.50%] [G loss: 0.929965]\n",
      "epoch:16 step:15761 [D loss: 0.315210, acc.: 85.94%] [G loss: 1.148082]\n",
      "epoch:16 step:15762 [D loss: 0.475292, acc.: 83.59%] [G loss: 1.059803]\n",
      "epoch:16 step:15763 [D loss: 0.607659, acc.: 67.97%] [G loss: 1.116398]\n",
      "epoch:16 step:15764 [D loss: 0.725196, acc.: 54.69%] [G loss: 1.284078]\n",
      "epoch:16 step:15765 [D loss: 0.512202, acc.: 78.12%] [G loss: 1.143985]\n",
      "epoch:16 step:15766 [D loss: 0.241406, acc.: 96.09%] [G loss: 1.234908]\n",
      "epoch:16 step:15767 [D loss: 0.393271, acc.: 77.34%] [G loss: 0.922140]\n",
      "epoch:16 step:15768 [D loss: 0.560678, acc.: 73.44%] [G loss: 1.114582]\n",
      "epoch:16 step:15769 [D loss: 0.487294, acc.: 78.91%] [G loss: 1.391231]\n",
      "epoch:16 step:15770 [D loss: 0.956208, acc.: 41.41%] [G loss: 1.450239]\n",
      "epoch:16 step:15771 [D loss: 0.648766, acc.: 55.47%] [G loss: 1.306499]\n",
      "epoch:16 step:15772 [D loss: 0.999067, acc.: 41.41%] [G loss: 1.208934]\n",
      "epoch:16 step:15773 [D loss: 0.815443, acc.: 46.88%] [G loss: 1.317901]\n",
      "epoch:16 step:15774 [D loss: 0.705975, acc.: 49.22%] [G loss: 1.040303]\n",
      "epoch:16 step:15775 [D loss: 0.832188, acc.: 35.16%] [G loss: 1.265965]\n",
      "epoch:16 step:15776 [D loss: 0.777495, acc.: 42.19%] [G loss: 1.237963]\n",
      "epoch:16 step:15777 [D loss: 0.787596, acc.: 36.72%] [G loss: 0.946136]\n",
      "epoch:16 step:15778 [D loss: 0.668200, acc.: 55.47%] [G loss: 0.974002]\n",
      "epoch:16 step:15779 [D loss: 0.725199, acc.: 45.31%] [G loss: 0.915326]\n",
      "epoch:16 step:15780 [D loss: 0.672559, acc.: 62.50%] [G loss: 0.953476]\n",
      "epoch:16 step:15781 [D loss: 0.667154, acc.: 60.94%] [G loss: 1.087573]\n",
      "epoch:16 step:15782 [D loss: 0.658190, acc.: 56.25%] [G loss: 0.886846]\n",
      "epoch:16 step:15783 [D loss: 0.607352, acc.: 69.53%] [G loss: 1.109756]\n",
      "epoch:16 step:15784 [D loss: 0.472399, acc.: 82.03%] [G loss: 1.085384]\n",
      "epoch:16 step:15785 [D loss: 0.574295, acc.: 70.31%] [G loss: 1.112879]\n",
      "epoch:16 step:15786 [D loss: 0.426616, acc.: 88.28%] [G loss: 1.146206]\n",
      "epoch:16 step:15787 [D loss: 0.550776, acc.: 78.12%] [G loss: 1.080625]\n",
      "epoch:16 step:15788 [D loss: 0.451944, acc.: 81.25%] [G loss: 1.149901]\n",
      "epoch:16 step:15789 [D loss: 0.695219, acc.: 58.59%] [G loss: 1.186371]\n",
      "epoch:16 step:15790 [D loss: 0.620299, acc.: 63.28%] [G loss: 1.168381]\n",
      "epoch:16 step:15791 [D loss: 0.696617, acc.: 56.25%] [G loss: 0.919184]\n",
      "epoch:16 step:15792 [D loss: 0.464015, acc.: 82.81%] [G loss: 0.796685]\n",
      "epoch:16 step:15793 [D loss: 0.456516, acc.: 79.69%] [G loss: 1.138929]\n",
      "epoch:16 step:15794 [D loss: 0.426959, acc.: 75.00%] [G loss: 0.870724]\n",
      "epoch:16 step:15795 [D loss: 0.574068, acc.: 71.88%] [G loss: 0.895105]\n",
      "epoch:16 step:15796 [D loss: 0.485257, acc.: 74.22%] [G loss: 1.051865]\n",
      "epoch:16 step:15797 [D loss: 0.392605, acc.: 80.47%] [G loss: 1.070681]\n",
      "epoch:16 step:15798 [D loss: 0.304824, acc.: 83.59%] [G loss: 1.094066]\n",
      "epoch:16 step:15799 [D loss: 0.714132, acc.: 53.12%] [G loss: 1.032387]\n",
      "epoch:16 step:15800 [D loss: 0.609826, acc.: 74.22%] [G loss: 0.916586]\n",
      "##############\n",
      "[3.50038682 2.49066385 6.80328263 5.65447975 4.38619364 5.9363832\n",
      " 5.29064555 5.48771234 5.76542639 4.77534581]\n",
      "##########\n",
      "epoch:16 step:15801 [D loss: 0.522866, acc.: 77.34%] [G loss: 0.993791]\n",
      "epoch:16 step:15802 [D loss: 0.612339, acc.: 71.09%] [G loss: 0.834271]\n",
      "epoch:16 step:15803 [D loss: 0.752955, acc.: 55.47%] [G loss: 0.968067]\n",
      "epoch:16 step:15804 [D loss: 0.615330, acc.: 65.62%] [G loss: 0.882715]\n",
      "epoch:16 step:15805 [D loss: 0.730346, acc.: 53.12%] [G loss: 0.941210]\n",
      "epoch:16 step:15806 [D loss: 0.769908, acc.: 42.97%] [G loss: 0.940312]\n",
      "epoch:16 step:15807 [D loss: 0.516986, acc.: 70.31%] [G loss: 1.052443]\n",
      "epoch:16 step:15808 [D loss: 0.628735, acc.: 63.28%] [G loss: 0.991747]\n",
      "epoch:16 step:15809 [D loss: 0.531387, acc.: 75.78%] [G loss: 0.976078]\n",
      "epoch:16 step:15810 [D loss: 0.738051, acc.: 48.44%] [G loss: 1.064760]\n",
      "epoch:16 step:15811 [D loss: 0.649202, acc.: 60.16%] [G loss: 0.897842]\n",
      "epoch:16 step:15812 [D loss: 0.849921, acc.: 35.94%] [G loss: 0.887246]\n",
      "epoch:16 step:15813 [D loss: 0.374021, acc.: 83.59%] [G loss: 0.951429]\n",
      "epoch:16 step:15814 [D loss: 0.417210, acc.: 82.03%] [G loss: 0.948817]\n",
      "epoch:16 step:15815 [D loss: 0.691224, acc.: 59.38%] [G loss: 0.959281]\n",
      "epoch:16 step:15816 [D loss: 0.725535, acc.: 50.78%] [G loss: 0.954705]\n",
      "epoch:16 step:15817 [D loss: 0.600408, acc.: 67.19%] [G loss: 0.796795]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15818 [D loss: 0.642644, acc.: 61.72%] [G loss: 0.906254]\n",
      "epoch:16 step:15819 [D loss: 0.659665, acc.: 63.28%] [G loss: 0.962945]\n",
      "epoch:16 step:15820 [D loss: 0.647905, acc.: 60.16%] [G loss: 0.820985]\n",
      "epoch:16 step:15821 [D loss: 0.632506, acc.: 65.62%] [G loss: 0.646495]\n",
      "epoch:16 step:15822 [D loss: 0.659959, acc.: 61.72%] [G loss: 0.965773]\n",
      "epoch:16 step:15823 [D loss: 0.680249, acc.: 59.38%] [G loss: 0.910344]\n",
      "epoch:16 step:15824 [D loss: 0.706543, acc.: 61.72%] [G loss: 0.808621]\n",
      "epoch:16 step:15825 [D loss: 0.669487, acc.: 59.38%] [G loss: 0.965941]\n",
      "epoch:16 step:15826 [D loss: 0.378884, acc.: 87.50%] [G loss: 1.111477]\n",
      "epoch:16 step:15827 [D loss: 0.633527, acc.: 58.59%] [G loss: 1.001488]\n",
      "epoch:16 step:15828 [D loss: 0.761463, acc.: 46.09%] [G loss: 0.931704]\n",
      "epoch:16 step:15829 [D loss: 0.772940, acc.: 43.75%] [G loss: 1.057176]\n",
      "epoch:16 step:15830 [D loss: 0.713185, acc.: 49.22%] [G loss: 0.942069]\n",
      "epoch:16 step:15831 [D loss: 0.541600, acc.: 75.00%] [G loss: 0.951357]\n",
      "epoch:16 step:15832 [D loss: 0.479324, acc.: 78.91%] [G loss: 1.098608]\n",
      "epoch:16 step:15833 [D loss: 0.263936, acc.: 91.41%] [G loss: 1.168288]\n",
      "epoch:16 step:15834 [D loss: 0.394148, acc.: 89.84%] [G loss: 1.208070]\n",
      "epoch:16 step:15835 [D loss: 0.768580, acc.: 53.12%] [G loss: 0.785791]\n",
      "epoch:16 step:15836 [D loss: 0.806958, acc.: 52.34%] [G loss: 0.765294]\n",
      "epoch:16 step:15837 [D loss: 0.827288, acc.: 48.44%] [G loss: 0.979401]\n",
      "epoch:16 step:15838 [D loss: 0.703448, acc.: 55.47%] [G loss: 0.882124]\n",
      "epoch:16 step:15839 [D loss: 0.314685, acc.: 89.06%] [G loss: 1.001135]\n",
      "epoch:16 step:15840 [D loss: 0.298562, acc.: 91.41%] [G loss: 1.116506]\n",
      "epoch:16 step:15841 [D loss: 0.589514, acc.: 66.41%] [G loss: 1.125454]\n",
      "epoch:16 step:15842 [D loss: 0.263842, acc.: 97.66%] [G loss: 1.227166]\n",
      "epoch:16 step:15843 [D loss: 0.214575, acc.: 98.44%] [G loss: 1.238266]\n",
      "epoch:16 step:15844 [D loss: 0.199705, acc.: 99.22%] [G loss: 0.667084]\n",
      "epoch:16 step:15845 [D loss: 0.342406, acc.: 76.56%] [G loss: 1.400888]\n",
      "epoch:16 step:15846 [D loss: 0.298359, acc.: 85.94%] [G loss: 1.445676]\n",
      "epoch:16 step:15847 [D loss: 0.497844, acc.: 75.78%] [G loss: 1.494528]\n",
      "epoch:16 step:15848 [D loss: 0.681586, acc.: 57.81%] [G loss: 1.430390]\n",
      "epoch:16 step:15849 [D loss: 0.223887, acc.: 98.44%] [G loss: 1.223912]\n",
      "epoch:16 step:15850 [D loss: 0.865411, acc.: 50.78%] [G loss: 1.198759]\n",
      "epoch:16 step:15851 [D loss: 0.980026, acc.: 21.88%] [G loss: 1.204173]\n",
      "epoch:16 step:15852 [D loss: 0.701374, acc.: 53.91%] [G loss: 1.199752]\n",
      "epoch:16 step:15853 [D loss: 0.681723, acc.: 58.59%] [G loss: 1.247260]\n",
      "epoch:16 step:15854 [D loss: 0.790089, acc.: 50.00%] [G loss: 1.154013]\n",
      "epoch:16 step:15855 [D loss: 0.715798, acc.: 57.81%] [G loss: 1.110243]\n",
      "epoch:16 step:15856 [D loss: 0.760914, acc.: 49.22%] [G loss: 1.028506]\n",
      "epoch:16 step:15857 [D loss: 0.402415, acc.: 92.19%] [G loss: 1.076561]\n",
      "epoch:16 step:15858 [D loss: 0.584228, acc.: 75.78%] [G loss: 0.702382]\n",
      "epoch:16 step:15859 [D loss: 0.429725, acc.: 85.16%] [G loss: 0.948847]\n",
      "epoch:16 step:15860 [D loss: 0.792322, acc.: 44.53%] [G loss: 0.994599]\n",
      "epoch:16 step:15861 [D loss: 0.711477, acc.: 50.00%] [G loss: 0.742859]\n",
      "epoch:16 step:15862 [D loss: 0.737360, acc.: 41.41%] [G loss: 0.989539]\n",
      "epoch:16 step:15863 [D loss: 0.809352, acc.: 35.16%] [G loss: 1.000445]\n",
      "epoch:16 step:15864 [D loss: 0.459764, acc.: 91.41%] [G loss: 1.005488]\n",
      "epoch:16 step:15865 [D loss: 0.678944, acc.: 60.94%] [G loss: 0.890983]\n",
      "epoch:16 step:15866 [D loss: 0.630774, acc.: 67.97%] [G loss: 0.935782]\n",
      "epoch:16 step:15867 [D loss: 0.641193, acc.: 63.28%] [G loss: 1.028067]\n",
      "epoch:16 step:15868 [D loss: 0.758992, acc.: 48.44%] [G loss: 0.349179]\n",
      "epoch:16 step:15869 [D loss: 0.756203, acc.: 46.88%] [G loss: 0.980540]\n",
      "epoch:16 step:15870 [D loss: 1.130951, acc.: 46.88%] [G loss: 1.106406]\n",
      "epoch:16 step:15871 [D loss: 0.665016, acc.: 57.03%] [G loss: 0.876951]\n",
      "epoch:16 step:15872 [D loss: 0.726098, acc.: 50.00%] [G loss: 1.034462]\n",
      "epoch:16 step:15873 [D loss: 0.726090, acc.: 50.78%] [G loss: 1.009790]\n",
      "epoch:16 step:15874 [D loss: 0.398082, acc.: 91.41%] [G loss: 1.084462]\n",
      "epoch:16 step:15875 [D loss: 0.491980, acc.: 80.47%] [G loss: 0.707631]\n",
      "epoch:16 step:15876 [D loss: 0.374913, acc.: 97.66%] [G loss: 1.075876]\n",
      "epoch:16 step:15877 [D loss: 0.297726, acc.: 97.66%] [G loss: 0.496551]\n",
      "epoch:16 step:15878 [D loss: 0.303404, acc.: 96.09%] [G loss: 1.009167]\n",
      "epoch:16 step:15879 [D loss: 0.313931, acc.: 88.28%] [G loss: 0.419735]\n",
      "epoch:16 step:15880 [D loss: 1.088332, acc.: 10.16%] [G loss: 1.197011]\n",
      "epoch:16 step:15881 [D loss: 0.283196, acc.: 99.22%] [G loss: 1.075136]\n",
      "epoch:16 step:15882 [D loss: 0.519810, acc.: 81.25%] [G loss: 1.182742]\n",
      "epoch:16 step:15883 [D loss: 0.787927, acc.: 50.78%] [G loss: 0.915426]\n",
      "epoch:16 step:15884 [D loss: 0.746468, acc.: 48.44%] [G loss: 0.907917]\n",
      "epoch:16 step:15885 [D loss: 0.640286, acc.: 60.16%] [G loss: 0.714396]\n",
      "epoch:16 step:15886 [D loss: 0.619685, acc.: 61.72%] [G loss: 0.659947]\n",
      "epoch:16 step:15887 [D loss: 0.573326, acc.: 68.75%] [G loss: 1.358061]\n",
      "epoch:16 step:15888 [D loss: 0.824556, acc.: 45.31%] [G loss: 1.123421]\n",
      "epoch:16 step:15889 [D loss: 0.616629, acc.: 62.50%] [G loss: 1.617872]\n",
      "epoch:16 step:15890 [D loss: 0.335855, acc.: 91.41%] [G loss: 1.547710]\n",
      "epoch:16 step:15891 [D loss: 0.190884, acc.: 98.44%] [G loss: 1.927500]\n",
      "epoch:16 step:15892 [D loss: 0.144117, acc.: 99.22%] [G loss: 1.936575]\n",
      "epoch:16 step:15893 [D loss: 0.313761, acc.: 90.62%] [G loss: 2.131554]\n",
      "epoch:16 step:15894 [D loss: 0.377849, acc.: 83.59%] [G loss: 1.678324]\n",
      "epoch:16 step:15895 [D loss: 0.268493, acc.: 98.44%] [G loss: 1.896405]\n",
      "epoch:16 step:15896 [D loss: 1.200532, acc.: 47.66%] [G loss: 1.373689]\n",
      "epoch:16 step:15897 [D loss: 0.802870, acc.: 42.97%] [G loss: 1.308925]\n",
      "epoch:16 step:15898 [D loss: 0.780868, acc.: 47.66%] [G loss: 1.095093]\n",
      "epoch:16 step:15899 [D loss: 0.523292, acc.: 75.78%] [G loss: 1.072302]\n",
      "epoch:16 step:15900 [D loss: 0.315085, acc.: 96.09%] [G loss: 1.392134]\n",
      "epoch:16 step:15901 [D loss: 0.193852, acc.: 98.44%] [G loss: 1.078625]\n",
      "epoch:16 step:15902 [D loss: 0.720917, acc.: 52.34%] [G loss: 1.532050]\n",
      "epoch:16 step:15903 [D loss: 0.225307, acc.: 93.75%] [G loss: 1.416594]\n",
      "epoch:16 step:15904 [D loss: 0.155854, acc.: 98.44%] [G loss: 1.684376]\n",
      "epoch:16 step:15905 [D loss: 0.295451, acc.: 96.09%] [G loss: 1.984572]\n",
      "epoch:16 step:15906 [D loss: 0.407090, acc.: 85.16%] [G loss: 1.717066]\n",
      "epoch:16 step:15907 [D loss: 0.582791, acc.: 66.41%] [G loss: 0.747370]\n",
      "epoch:16 step:15908 [D loss: 0.885876, acc.: 49.22%] [G loss: 0.761184]\n",
      "epoch:16 step:15909 [D loss: 0.847584, acc.: 40.62%] [G loss: 0.780484]\n",
      "epoch:16 step:15910 [D loss: 0.407299, acc.: 80.47%] [G loss: 1.266653]\n",
      "epoch:16 step:15911 [D loss: 0.376155, acc.: 74.22%] [G loss: 1.351773]\n",
      "epoch:16 step:15912 [D loss: 1.289963, acc.: 20.31%] [G loss: 1.208485]\n",
      "epoch:16 step:15913 [D loss: 0.795837, acc.: 53.91%] [G loss: 0.983538]\n",
      "epoch:16 step:15914 [D loss: 0.846884, acc.: 49.22%] [G loss: 1.066332]\n",
      "epoch:16 step:15915 [D loss: 0.561714, acc.: 69.53%] [G loss: 1.345976]\n",
      "epoch:16 step:15916 [D loss: 0.352204, acc.: 88.28%] [G loss: 0.922154]\n",
      "epoch:16 step:15917 [D loss: 0.479006, acc.: 75.00%] [G loss: 1.472380]\n",
      "epoch:16 step:15918 [D loss: 0.462724, acc.: 71.88%] [G loss: 1.589288]\n",
      "epoch:16 step:15919 [D loss: 0.290409, acc.: 89.06%] [G loss: 1.223635]\n",
      "epoch:16 step:15920 [D loss: 0.910860, acc.: 35.94%] [G loss: 1.473002]\n",
      "epoch:16 step:15921 [D loss: 0.598411, acc.: 63.28%] [G loss: 1.881988]\n",
      "epoch:16 step:15922 [D loss: 0.576337, acc.: 66.41%] [G loss: 1.790530]\n",
      "epoch:16 step:15923 [D loss: 0.585058, acc.: 69.53%] [G loss: 1.458525]\n",
      "epoch:16 step:15924 [D loss: 0.558831, acc.: 68.75%] [G loss: 1.410418]\n",
      "epoch:16 step:15925 [D loss: 0.452114, acc.: 82.81%] [G loss: 1.228189]\n",
      "epoch:16 step:15926 [D loss: 0.366180, acc.: 85.16%] [G loss: 1.009501]\n",
      "epoch:16 step:15927 [D loss: 0.499168, acc.: 77.34%] [G loss: 1.350997]\n",
      "epoch:16 step:15928 [D loss: 0.308462, acc.: 84.38%] [G loss: 1.192322]\n",
      "epoch:16 step:15929 [D loss: 0.224508, acc.: 89.06%] [G loss: 1.765932]\n",
      "epoch:17 step:15930 [D loss: 0.533992, acc.: 73.44%] [G loss: 1.530533]\n",
      "epoch:17 step:15931 [D loss: 0.779517, acc.: 50.78%] [G loss: 1.472613]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:15932 [D loss: 0.824387, acc.: 50.78%] [G loss: 1.444028]\n",
      "epoch:17 step:15933 [D loss: 0.625100, acc.: 61.72%] [G loss: 1.672711]\n",
      "epoch:17 step:15934 [D loss: 0.558136, acc.: 71.88%] [G loss: 1.891554]\n",
      "epoch:17 step:15935 [D loss: 0.568346, acc.: 67.97%] [G loss: 1.174603]\n",
      "epoch:17 step:15936 [D loss: 0.528014, acc.: 78.12%] [G loss: 1.281683]\n",
      "epoch:17 step:15937 [D loss: 0.591964, acc.: 72.66%] [G loss: 1.040040]\n",
      "epoch:17 step:15938 [D loss: 0.603619, acc.: 67.19%] [G loss: 0.974900]\n",
      "epoch:17 step:15939 [D loss: 0.672838, acc.: 59.38%] [G loss: 0.682862]\n",
      "epoch:17 step:15940 [D loss: 0.691023, acc.: 60.16%] [G loss: 1.112091]\n",
      "epoch:17 step:15941 [D loss: 0.538589, acc.: 77.34%] [G loss: 1.051281]\n",
      "epoch:17 step:15942 [D loss: 0.502709, acc.: 73.44%] [G loss: 0.933804]\n",
      "epoch:17 step:15943 [D loss: 0.576014, acc.: 73.44%] [G loss: 0.940032]\n",
      "epoch:17 step:15944 [D loss: 0.488952, acc.: 82.81%] [G loss: 1.075237]\n",
      "epoch:17 step:15945 [D loss: 0.479500, acc.: 81.25%] [G loss: 1.278509]\n",
      "epoch:17 step:15946 [D loss: 0.645813, acc.: 60.16%] [G loss: 1.004827]\n",
      "epoch:17 step:15947 [D loss: 0.660447, acc.: 57.03%] [G loss: 1.066222]\n",
      "epoch:17 step:15948 [D loss: 0.614269, acc.: 66.41%] [G loss: 0.921028]\n",
      "epoch:17 step:15949 [D loss: 0.927520, acc.: 28.12%] [G loss: 0.960889]\n",
      "epoch:17 step:15950 [D loss: 0.688517, acc.: 60.16%] [G loss: 1.052247]\n",
      "epoch:17 step:15951 [D loss: 0.728462, acc.: 61.72%] [G loss: 1.079722]\n",
      "epoch:17 step:15952 [D loss: 0.690592, acc.: 58.59%] [G loss: 0.867597]\n",
      "epoch:17 step:15953 [D loss: 0.587575, acc.: 72.66%] [G loss: 1.042912]\n",
      "epoch:17 step:15954 [D loss: 0.605804, acc.: 64.06%] [G loss: 1.043243]\n",
      "epoch:17 step:15955 [D loss: 0.692221, acc.: 52.34%] [G loss: 0.964109]\n",
      "epoch:17 step:15956 [D loss: 0.697910, acc.: 56.25%] [G loss: 1.206074]\n",
      "epoch:17 step:15957 [D loss: 0.736997, acc.: 53.91%] [G loss: 1.057291]\n",
      "epoch:17 step:15958 [D loss: 0.610753, acc.: 60.16%] [G loss: 1.154928]\n",
      "epoch:17 step:15959 [D loss: 0.686156, acc.: 59.38%] [G loss: 1.315428]\n",
      "epoch:17 step:15960 [D loss: 0.552044, acc.: 81.25%] [G loss: 1.159991]\n",
      "epoch:17 step:15961 [D loss: 0.536646, acc.: 82.81%] [G loss: 2.201692]\n",
      "epoch:17 step:15962 [D loss: 0.458410, acc.: 85.16%] [G loss: 1.265831]\n",
      "epoch:17 step:15963 [D loss: 0.592667, acc.: 71.09%] [G loss: 0.654309]\n",
      "epoch:17 step:15964 [D loss: 0.508424, acc.: 80.47%] [G loss: 1.155560]\n",
      "epoch:17 step:15965 [D loss: 0.452634, acc.: 80.47%] [G loss: 1.344766]\n",
      "epoch:17 step:15966 [D loss: 0.821987, acc.: 47.66%] [G loss: 1.487142]\n",
      "epoch:17 step:15967 [D loss: 1.067738, acc.: 33.59%] [G loss: 0.885982]\n",
      "epoch:17 step:15968 [D loss: 0.686954, acc.: 58.59%] [G loss: 0.882816]\n",
      "epoch:17 step:15969 [D loss: 0.579033, acc.: 68.75%] [G loss: 0.946506]\n",
      "epoch:17 step:15970 [D loss: 0.628152, acc.: 64.84%] [G loss: 0.917951]\n",
      "epoch:17 step:15971 [D loss: 0.639209, acc.: 65.62%] [G loss: 1.063174]\n",
      "epoch:17 step:15972 [D loss: 0.616148, acc.: 70.31%] [G loss: 0.893934]\n",
      "epoch:17 step:15973 [D loss: 0.649969, acc.: 63.28%] [G loss: 0.888681]\n",
      "epoch:17 step:15974 [D loss: 0.646626, acc.: 65.62%] [G loss: 0.888178]\n",
      "epoch:17 step:15975 [D loss: 0.657106, acc.: 55.47%] [G loss: 0.878101]\n",
      "epoch:17 step:15976 [D loss: 0.545468, acc.: 79.69%] [G loss: 0.930304]\n",
      "epoch:17 step:15977 [D loss: 0.549366, acc.: 74.22%] [G loss: 0.972579]\n",
      "epoch:17 step:15978 [D loss: 0.533114, acc.: 74.22%] [G loss: 0.880526]\n",
      "epoch:17 step:15979 [D loss: 0.571401, acc.: 67.97%] [G loss: 0.990507]\n",
      "epoch:17 step:15980 [D loss: 0.690097, acc.: 54.69%] [G loss: 0.998358]\n",
      "epoch:17 step:15981 [D loss: 0.630478, acc.: 67.97%] [G loss: 0.862661]\n",
      "epoch:17 step:15982 [D loss: 0.570857, acc.: 74.22%] [G loss: 0.915266]\n",
      "epoch:17 step:15983 [D loss: 0.546879, acc.: 77.34%] [G loss: 1.111123]\n",
      "epoch:17 step:15984 [D loss: 0.507831, acc.: 78.91%] [G loss: 1.085978]\n",
      "epoch:17 step:15985 [D loss: 0.611087, acc.: 71.09%] [G loss: 1.102190]\n",
      "epoch:17 step:15986 [D loss: 0.644903, acc.: 62.50%] [G loss: 1.018939]\n",
      "epoch:17 step:15987 [D loss: 0.697585, acc.: 62.50%] [G loss: 0.942213]\n",
      "epoch:17 step:15988 [D loss: 0.679648, acc.: 59.38%] [G loss: 0.940270]\n",
      "epoch:17 step:15989 [D loss: 0.617167, acc.: 64.84%] [G loss: 0.902562]\n",
      "epoch:17 step:15990 [D loss: 0.613661, acc.: 63.28%] [G loss: 0.922521]\n",
      "epoch:17 step:15991 [D loss: 0.707610, acc.: 55.47%] [G loss: 0.847120]\n",
      "epoch:17 step:15992 [D loss: 0.664016, acc.: 62.50%] [G loss: 0.915151]\n",
      "epoch:17 step:15993 [D loss: 0.621629, acc.: 59.38%] [G loss: 1.068365]\n",
      "epoch:17 step:15994 [D loss: 0.552672, acc.: 75.78%] [G loss: 1.023227]\n",
      "epoch:17 step:15995 [D loss: 0.696915, acc.: 57.03%] [G loss: 1.042245]\n",
      "epoch:17 step:15996 [D loss: 0.585530, acc.: 70.31%] [G loss: 0.910039]\n",
      "epoch:17 step:15997 [D loss: 0.526869, acc.: 75.00%] [G loss: 0.932294]\n",
      "epoch:17 step:15998 [D loss: 0.470925, acc.: 77.34%] [G loss: 0.921957]\n",
      "epoch:17 step:15999 [D loss: 0.504251, acc.: 79.69%] [G loss: 1.066516]\n",
      "epoch:17 step:16000 [D loss: 0.688067, acc.: 63.28%] [G loss: 0.955403]\n",
      "##############\n",
      "[4.58320801 2.85754737 6.96458378 5.79975865 4.59720428 6.3907889\n",
      " 5.58377407 5.40995952 5.87311503 4.86674147]\n",
      "##########\n",
      "epoch:17 step:16001 [D loss: 0.801738, acc.: 50.00%] [G loss: 0.912659]\n",
      "epoch:17 step:16002 [D loss: 0.635020, acc.: 60.16%] [G loss: 1.029364]\n",
      "epoch:17 step:16003 [D loss: 0.683981, acc.: 57.03%] [G loss: 0.731834]\n",
      "epoch:17 step:16004 [D loss: 0.363605, acc.: 86.72%] [G loss: 0.809555]\n",
      "epoch:17 step:16005 [D loss: 0.604333, acc.: 64.06%] [G loss: 1.079742]\n",
      "epoch:17 step:16006 [D loss: 0.509604, acc.: 75.00%] [G loss: 1.038020]\n",
      "epoch:17 step:16007 [D loss: 0.806615, acc.: 37.50%] [G loss: 0.937080]\n",
      "epoch:17 step:16008 [D loss: 0.722633, acc.: 51.56%] [G loss: 0.927675]\n",
      "epoch:17 step:16009 [D loss: 0.590155, acc.: 67.19%] [G loss: 0.920059]\n",
      "epoch:17 step:16010 [D loss: 0.649423, acc.: 60.94%] [G loss: 0.999991]\n",
      "epoch:17 step:16011 [D loss: 0.479911, acc.: 79.69%] [G loss: 0.662690]\n",
      "epoch:17 step:16012 [D loss: 0.611416, acc.: 64.06%] [G loss: 0.888302]\n",
      "epoch:17 step:16013 [D loss: 0.761082, acc.: 53.91%] [G loss: 1.041696]\n",
      "epoch:17 step:16014 [D loss: 0.673654, acc.: 67.19%] [G loss: 0.957504]\n",
      "epoch:17 step:16015 [D loss: 0.775258, acc.: 46.09%] [G loss: 0.902085]\n",
      "epoch:17 step:16016 [D loss: 0.646001, acc.: 64.06%] [G loss: 0.903923]\n",
      "epoch:17 step:16017 [D loss: 0.626129, acc.: 67.19%] [G loss: 0.971512]\n",
      "epoch:17 step:16018 [D loss: 0.644782, acc.: 56.25%] [G loss: 0.802466]\n",
      "epoch:17 step:16019 [D loss: 0.689058, acc.: 57.03%] [G loss: 1.009995]\n",
      "epoch:17 step:16020 [D loss: 0.736615, acc.: 47.66%] [G loss: 0.984846]\n",
      "epoch:17 step:16021 [D loss: 0.737084, acc.: 46.09%] [G loss: 0.705082]\n",
      "epoch:17 step:16022 [D loss: 0.575671, acc.: 72.66%] [G loss: 0.941121]\n",
      "epoch:17 step:16023 [D loss: 0.690871, acc.: 56.25%] [G loss: 0.777889]\n",
      "epoch:17 step:16024 [D loss: 0.869480, acc.: 40.62%] [G loss: 1.091696]\n",
      "epoch:17 step:16025 [D loss: 0.682759, acc.: 59.38%] [G loss: 1.012392]\n",
      "epoch:17 step:16026 [D loss: 0.674429, acc.: 57.03%] [G loss: 0.674222]\n",
      "epoch:17 step:16027 [D loss: 0.536236, acc.: 74.22%] [G loss: 0.998382]\n",
      "epoch:17 step:16028 [D loss: 0.517892, acc.: 75.00%] [G loss: 1.085888]\n",
      "epoch:17 step:16029 [D loss: 0.585668, acc.: 66.41%] [G loss: 1.013664]\n",
      "epoch:17 step:16030 [D loss: 0.686388, acc.: 56.25%] [G loss: 1.103594]\n",
      "epoch:17 step:16031 [D loss: 0.520321, acc.: 77.34%] [G loss: 1.016244]\n",
      "epoch:17 step:16032 [D loss: 0.651138, acc.: 60.16%] [G loss: 0.910824]\n",
      "epoch:17 step:16033 [D loss: 0.643410, acc.: 60.16%] [G loss: 1.022243]\n",
      "epoch:17 step:16034 [D loss: 0.357269, acc.: 84.38%] [G loss: 1.009383]\n",
      "epoch:17 step:16035 [D loss: 0.644220, acc.: 62.50%] [G loss: 0.739818]\n",
      "epoch:17 step:16036 [D loss: 0.377529, acc.: 83.59%] [G loss: 1.157653]\n",
      "epoch:17 step:16037 [D loss: 0.570551, acc.: 67.97%] [G loss: 1.307261]\n",
      "epoch:17 step:16038 [D loss: 0.609359, acc.: 73.44%] [G loss: 1.351769]\n",
      "epoch:17 step:16039 [D loss: 0.556410, acc.: 75.78%] [G loss: 1.237927]\n",
      "epoch:17 step:16040 [D loss: 0.744946, acc.: 50.78%] [G loss: 1.052745]\n",
      "epoch:17 step:16041 [D loss: 0.652018, acc.: 66.41%] [G loss: 1.008397]\n",
      "epoch:17 step:16042 [D loss: 0.701205, acc.: 54.69%] [G loss: 0.800206]\n",
      "epoch:17 step:16043 [D loss: 0.748382, acc.: 49.22%] [G loss: 0.837279]\n",
      "epoch:17 step:16044 [D loss: 0.653558, acc.: 55.47%] [G loss: 0.719624]\n",
      "epoch:17 step:16045 [D loss: 0.722241, acc.: 48.44%] [G loss: 0.746217]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16046 [D loss: 0.525900, acc.: 74.22%] [G loss: 0.986464]\n",
      "epoch:17 step:16047 [D loss: 0.377099, acc.: 86.72%] [G loss: 0.984129]\n",
      "epoch:17 step:16048 [D loss: 0.667036, acc.: 58.59%] [G loss: 1.157741]\n",
      "epoch:17 step:16049 [D loss: 0.682188, acc.: 61.72%] [G loss: 0.921715]\n",
      "epoch:17 step:16050 [D loss: 0.609402, acc.: 69.53%] [G loss: 1.196687]\n",
      "epoch:17 step:16051 [D loss: 0.565320, acc.: 67.97%] [G loss: 1.107745]\n",
      "epoch:17 step:16052 [D loss: 0.662259, acc.: 56.25%] [G loss: 1.207165]\n",
      "epoch:17 step:16053 [D loss: 0.563916, acc.: 74.22%] [G loss: 1.220229]\n",
      "epoch:17 step:16054 [D loss: 0.619959, acc.: 66.41%] [G loss: 1.122266]\n",
      "epoch:17 step:16055 [D loss: 0.557338, acc.: 77.34%] [G loss: 0.625856]\n",
      "epoch:17 step:16056 [D loss: 0.668605, acc.: 60.16%] [G loss: 0.994377]\n",
      "epoch:17 step:16057 [D loss: 0.699483, acc.: 48.44%] [G loss: 0.841329]\n",
      "epoch:17 step:16058 [D loss: 0.647940, acc.: 64.06%] [G loss: 0.922063]\n",
      "epoch:17 step:16059 [D loss: 0.549556, acc.: 71.88%] [G loss: 1.033453]\n",
      "epoch:17 step:16060 [D loss: 0.573227, acc.: 70.31%] [G loss: 1.026883]\n",
      "epoch:17 step:16061 [D loss: 0.659140, acc.: 60.16%] [G loss: 1.092843]\n",
      "epoch:17 step:16062 [D loss: 0.524182, acc.: 74.22%] [G loss: 1.039452]\n",
      "epoch:17 step:16063 [D loss: 0.490013, acc.: 84.38%] [G loss: 1.003031]\n",
      "epoch:17 step:16064 [D loss: 0.571568, acc.: 67.97%] [G loss: 1.084338]\n",
      "epoch:17 step:16065 [D loss: 0.635944, acc.: 62.50%] [G loss: 0.985201]\n",
      "epoch:17 step:16066 [D loss: 0.735811, acc.: 49.22%] [G loss: 1.080323]\n",
      "epoch:17 step:16067 [D loss: 0.759654, acc.: 46.09%] [G loss: 0.999162]\n",
      "epoch:17 step:16068 [D loss: 0.470369, acc.: 82.81%] [G loss: 1.013093]\n",
      "epoch:17 step:16069 [D loss: 0.759431, acc.: 49.22%] [G loss: 1.041406]\n",
      "epoch:17 step:16070 [D loss: 0.664915, acc.: 60.94%] [G loss: 0.985664]\n",
      "epoch:17 step:16071 [D loss: 0.737210, acc.: 53.12%] [G loss: 1.087178]\n",
      "epoch:17 step:16072 [D loss: 0.430831, acc.: 89.06%] [G loss: 0.960378]\n",
      "epoch:17 step:16073 [D loss: 0.453268, acc.: 82.03%] [G loss: 1.093169]\n",
      "epoch:17 step:16074 [D loss: 0.326650, acc.: 86.72%] [G loss: 1.263620]\n",
      "epoch:17 step:16075 [D loss: 0.685757, acc.: 59.38%] [G loss: 0.995402]\n",
      "epoch:17 step:16076 [D loss: 0.782626, acc.: 43.75%] [G loss: 1.076590]\n",
      "epoch:17 step:16077 [D loss: 0.748519, acc.: 48.44%] [G loss: 1.198182]\n",
      "epoch:17 step:16078 [D loss: 0.650968, acc.: 60.94%] [G loss: 1.130189]\n",
      "epoch:17 step:16079 [D loss: 0.470725, acc.: 74.22%] [G loss: 1.066679]\n",
      "epoch:17 step:16080 [D loss: 0.549406, acc.: 77.34%] [G loss: 1.259159]\n",
      "epoch:17 step:16081 [D loss: 0.668543, acc.: 57.03%] [G loss: 1.086535]\n",
      "epoch:17 step:16082 [D loss: 0.658701, acc.: 58.59%] [G loss: 0.982143]\n",
      "epoch:17 step:16083 [D loss: 0.717317, acc.: 53.91%] [G loss: 0.987108]\n",
      "epoch:17 step:16084 [D loss: 0.792426, acc.: 39.84%] [G loss: 0.743383]\n",
      "epoch:17 step:16085 [D loss: 0.582740, acc.: 67.97%] [G loss: 0.597181]\n",
      "epoch:17 step:16086 [D loss: 0.672511, acc.: 59.38%] [G loss: 0.841839]\n",
      "epoch:17 step:16087 [D loss: 0.821644, acc.: 38.28%] [G loss: 1.159138]\n",
      "epoch:17 step:16088 [D loss: 0.457643, acc.: 86.72%] [G loss: 1.049957]\n",
      "epoch:17 step:16089 [D loss: 0.808230, acc.: 51.56%] [G loss: 1.058077]\n",
      "epoch:17 step:16090 [D loss: 0.692611, acc.: 55.47%] [G loss: 1.021171]\n",
      "epoch:17 step:16091 [D loss: 0.706115, acc.: 53.12%] [G loss: 1.043254]\n",
      "epoch:17 step:16092 [D loss: 0.701169, acc.: 57.81%] [G loss: 0.870331]\n",
      "epoch:17 step:16093 [D loss: 0.678970, acc.: 61.72%] [G loss: 0.971960]\n",
      "epoch:17 step:16094 [D loss: 0.625925, acc.: 61.72%] [G loss: 1.033150]\n",
      "epoch:17 step:16095 [D loss: 0.491975, acc.: 82.03%] [G loss: 0.951317]\n",
      "epoch:17 step:16096 [D loss: 0.479057, acc.: 86.72%] [G loss: 1.031437]\n",
      "epoch:17 step:16097 [D loss: 0.433105, acc.: 83.59%] [G loss: 0.942173]\n",
      "epoch:17 step:16098 [D loss: 0.544620, acc.: 74.22%] [G loss: 0.973821]\n",
      "epoch:17 step:16099 [D loss: 0.672868, acc.: 61.72%] [G loss: 0.822319]\n",
      "epoch:17 step:16100 [D loss: 0.538097, acc.: 72.66%] [G loss: 1.017109]\n",
      "epoch:17 step:16101 [D loss: 0.474458, acc.: 81.25%] [G loss: 1.093189]\n",
      "epoch:17 step:16102 [D loss: 0.523116, acc.: 80.47%] [G loss: 1.098469]\n",
      "epoch:17 step:16103 [D loss: 0.551951, acc.: 76.56%] [G loss: 0.772426]\n",
      "epoch:17 step:16104 [D loss: 0.616189, acc.: 64.06%] [G loss: 0.655731]\n",
      "epoch:17 step:16105 [D loss: 0.420341, acc.: 89.84%] [G loss: 1.304593]\n",
      "epoch:17 step:16106 [D loss: 0.658625, acc.: 58.59%] [G loss: 0.979739]\n",
      "epoch:17 step:16107 [D loss: 0.739225, acc.: 50.78%] [G loss: 0.945528]\n",
      "epoch:17 step:16108 [D loss: 0.854728, acc.: 30.47%] [G loss: 0.783033]\n",
      "epoch:17 step:16109 [D loss: 0.762164, acc.: 50.78%] [G loss: 0.938886]\n",
      "epoch:17 step:16110 [D loss: 0.481622, acc.: 80.47%] [G loss: 1.134774]\n",
      "epoch:17 step:16111 [D loss: 0.512756, acc.: 78.91%] [G loss: 1.057348]\n",
      "epoch:17 step:16112 [D loss: 0.674227, acc.: 56.25%] [G loss: 0.686338]\n",
      "epoch:17 step:16113 [D loss: 0.631393, acc.: 64.84%] [G loss: 0.781496]\n",
      "epoch:17 step:16114 [D loss: 0.819705, acc.: 41.41%] [G loss: 1.429467]\n",
      "epoch:17 step:16115 [D loss: 0.847691, acc.: 39.84%] [G loss: 0.929741]\n",
      "epoch:17 step:16116 [D loss: 0.860895, acc.: 46.09%] [G loss: 0.991085]\n",
      "epoch:17 step:16117 [D loss: 0.574709, acc.: 74.22%] [G loss: 0.833025]\n",
      "epoch:17 step:16118 [D loss: 0.651278, acc.: 69.53%] [G loss: 0.776047]\n",
      "epoch:17 step:16119 [D loss: 0.890063, acc.: 38.28%] [G loss: 1.108064]\n",
      "epoch:17 step:16120 [D loss: 0.657105, acc.: 55.47%] [G loss: 1.032540]\n",
      "epoch:17 step:16121 [D loss: 0.538317, acc.: 70.31%] [G loss: 0.963338]\n",
      "epoch:17 step:16122 [D loss: 0.787945, acc.: 36.72%] [G loss: 1.013287]\n",
      "epoch:17 step:16123 [D loss: 0.523061, acc.: 84.38%] [G loss: 0.916325]\n",
      "epoch:17 step:16124 [D loss: 0.505501, acc.: 81.25%] [G loss: 0.635788]\n",
      "epoch:17 step:16125 [D loss: 0.622399, acc.: 63.28%] [G loss: 0.769306]\n",
      "epoch:17 step:16126 [D loss: 0.602706, acc.: 67.19%] [G loss: 1.218929]\n",
      "epoch:17 step:16127 [D loss: 0.638589, acc.: 63.28%] [G loss: 0.763977]\n",
      "epoch:17 step:16128 [D loss: 0.767030, acc.: 42.97%] [G loss: 1.172409]\n",
      "epoch:17 step:16129 [D loss: 0.933367, acc.: 26.56%] [G loss: 0.720573]\n",
      "epoch:17 step:16130 [D loss: 0.610965, acc.: 66.41%] [G loss: 0.834851]\n",
      "epoch:17 step:16131 [D loss: 0.785422, acc.: 42.97%] [G loss: 1.145516]\n",
      "epoch:17 step:16132 [D loss: 0.699883, acc.: 60.16%] [G loss: 1.204245]\n",
      "epoch:17 step:16133 [D loss: 0.473071, acc.: 82.81%] [G loss: 0.726912]\n",
      "epoch:17 step:16134 [D loss: 0.660288, acc.: 64.84%] [G loss: 0.859044]\n",
      "epoch:17 step:16135 [D loss: 0.600101, acc.: 69.53%] [G loss: 1.008017]\n",
      "epoch:17 step:16136 [D loss: 0.363105, acc.: 79.69%] [G loss: 1.065311]\n",
      "epoch:17 step:16137 [D loss: 0.557982, acc.: 76.56%] [G loss: 0.916363]\n",
      "epoch:17 step:16138 [D loss: 0.579763, acc.: 68.75%] [G loss: 1.051080]\n",
      "epoch:17 step:16139 [D loss: 0.863131, acc.: 35.16%] [G loss: 0.773293]\n",
      "epoch:17 step:16140 [D loss: 0.887864, acc.: 32.81%] [G loss: 0.789307]\n",
      "epoch:17 step:16141 [D loss: 0.773727, acc.: 45.31%] [G loss: 0.868839]\n",
      "epoch:17 step:16142 [D loss: 0.781513, acc.: 38.28%] [G loss: 1.153272]\n",
      "epoch:17 step:16143 [D loss: 0.709365, acc.: 52.34%] [G loss: 1.245363]\n",
      "epoch:17 step:16144 [D loss: 0.719732, acc.: 53.91%] [G loss: 1.094667]\n",
      "epoch:17 step:16145 [D loss: 0.642702, acc.: 60.94%] [G loss: 1.135509]\n",
      "epoch:17 step:16146 [D loss: 0.739277, acc.: 55.47%] [G loss: 0.870199]\n",
      "epoch:17 step:16147 [D loss: 0.678083, acc.: 59.38%] [G loss: 0.875070]\n",
      "epoch:17 step:16148 [D loss: 0.635461, acc.: 63.28%] [G loss: 0.877518]\n",
      "epoch:17 step:16149 [D loss: 0.365811, acc.: 82.81%] [G loss: 0.952887]\n",
      "epoch:17 step:16150 [D loss: 0.384746, acc.: 84.38%] [G loss: 0.977064]\n",
      "epoch:17 step:16151 [D loss: 0.391412, acc.: 85.16%] [G loss: 1.215927]\n",
      "epoch:17 step:16152 [D loss: 0.524549, acc.: 78.91%] [G loss: 1.316373]\n",
      "epoch:17 step:16153 [D loss: 0.772831, acc.: 46.09%] [G loss: 1.273214]\n",
      "epoch:17 step:16154 [D loss: 0.821190, acc.: 44.53%] [G loss: 1.101391]\n",
      "epoch:17 step:16155 [D loss: 0.587258, acc.: 75.78%] [G loss: 1.106500]\n",
      "epoch:17 step:16156 [D loss: 0.557382, acc.: 79.69%] [G loss: 1.111335]\n",
      "epoch:17 step:16157 [D loss: 0.602311, acc.: 65.62%] [G loss: 1.138202]\n",
      "epoch:17 step:16158 [D loss: 0.628626, acc.: 66.41%] [G loss: 1.022828]\n",
      "epoch:17 step:16159 [D loss: 0.239122, acc.: 95.31%] [G loss: 1.205111]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16160 [D loss: 0.330024, acc.: 91.41%] [G loss: 1.725968]\n",
      "epoch:17 step:16161 [D loss: 0.224555, acc.: 94.53%] [G loss: 1.269938]\n",
      "epoch:17 step:16162 [D loss: 0.621726, acc.: 70.31%] [G loss: 1.551407]\n",
      "epoch:17 step:16163 [D loss: 0.483673, acc.: 78.91%] [G loss: 1.776551]\n",
      "epoch:17 step:16164 [D loss: 0.251374, acc.: 97.66%] [G loss: 1.708282]\n",
      "epoch:17 step:16165 [D loss: 0.600493, acc.: 71.09%] [G loss: 1.244951]\n",
      "epoch:17 step:16166 [D loss: 0.438418, acc.: 83.59%] [G loss: 0.966530]\n",
      "epoch:17 step:16167 [D loss: 0.236105, acc.: 96.88%] [G loss: 1.940797]\n",
      "epoch:17 step:16168 [D loss: 0.663200, acc.: 64.84%] [G loss: 0.922434]\n",
      "epoch:17 step:16169 [D loss: 0.650665, acc.: 67.19%] [G loss: 0.907053]\n",
      "epoch:17 step:16170 [D loss: 0.983465, acc.: 28.12%] [G loss: 0.243332]\n",
      "epoch:17 step:16171 [D loss: 0.587020, acc.: 69.53%] [G loss: 0.364772]\n",
      "epoch:17 step:16172 [D loss: 0.565185, acc.: 64.84%] [G loss: 0.880889]\n",
      "epoch:17 step:16173 [D loss: 0.725238, acc.: 52.34%] [G loss: 0.901892]\n",
      "epoch:17 step:16174 [D loss: 0.953924, acc.: 32.03%] [G loss: 0.700623]\n",
      "epoch:17 step:16175 [D loss: 0.775202, acc.: 39.06%] [G loss: 0.445879]\n",
      "epoch:17 step:16176 [D loss: 0.773972, acc.: 39.06%] [G loss: 0.665945]\n",
      "epoch:17 step:16177 [D loss: 0.730706, acc.: 47.66%] [G loss: 0.923422]\n",
      "epoch:17 step:16178 [D loss: 0.634361, acc.: 64.84%] [G loss: 0.769812]\n",
      "epoch:17 step:16179 [D loss: 0.962300, acc.: 27.34%] [G loss: 0.880571]\n",
      "epoch:17 step:16180 [D loss: 0.635058, acc.: 70.31%] [G loss: 1.034399]\n",
      "epoch:17 step:16181 [D loss: 0.644217, acc.: 61.72%] [G loss: 0.861099]\n",
      "epoch:17 step:16182 [D loss: 0.757291, acc.: 46.88%] [G loss: 1.067286]\n",
      "epoch:17 step:16183 [D loss: 0.617110, acc.: 67.19%] [G loss: 0.960468]\n",
      "epoch:17 step:16184 [D loss: 0.396757, acc.: 93.75%] [G loss: 0.999456]\n",
      "epoch:17 step:16185 [D loss: 0.314243, acc.: 92.19%] [G loss: 0.995913]\n",
      "epoch:17 step:16186 [D loss: 0.566925, acc.: 72.66%] [G loss: 1.011326]\n",
      "epoch:17 step:16187 [D loss: 0.678854, acc.: 55.47%] [G loss: 0.981701]\n",
      "epoch:17 step:16188 [D loss: 0.358900, acc.: 85.94%] [G loss: 1.108631]\n",
      "epoch:17 step:16189 [D loss: 0.617728, acc.: 63.28%] [G loss: 1.102430]\n",
      "epoch:17 step:16190 [D loss: 0.295166, acc.: 97.66%] [G loss: 1.178770]\n",
      "epoch:17 step:16191 [D loss: 0.771970, acc.: 43.75%] [G loss: 1.200312]\n",
      "epoch:17 step:16192 [D loss: 0.318938, acc.: 94.53%] [G loss: 1.222782]\n",
      "epoch:17 step:16193 [D loss: 0.593194, acc.: 74.22%] [G loss: 1.112209]\n",
      "epoch:17 step:16194 [D loss: 0.570514, acc.: 77.34%] [G loss: 1.238856]\n",
      "epoch:17 step:16195 [D loss: 0.730356, acc.: 53.91%] [G loss: 0.995174]\n",
      "epoch:17 step:16196 [D loss: 0.720666, acc.: 51.56%] [G loss: 0.618596]\n",
      "epoch:17 step:16197 [D loss: 0.651196, acc.: 57.81%] [G loss: 0.620896]\n",
      "epoch:17 step:16198 [D loss: 0.536639, acc.: 85.16%] [G loss: 1.121505]\n",
      "epoch:17 step:16199 [D loss: 0.642436, acc.: 66.41%] [G loss: 1.079319]\n",
      "epoch:17 step:16200 [D loss: 0.481567, acc.: 78.12%] [G loss: 1.050502]\n",
      "##############\n",
      "[4.3666536  2.54928142 6.62352472 5.699748   5.02960618 6.09283879\n",
      " 5.31423613 5.69088403 5.93069619 5.30638424]\n",
      "##########\n",
      "epoch:17 step:16201 [D loss: 0.592052, acc.: 71.88%] [G loss: 0.624473]\n",
      "epoch:17 step:16202 [D loss: 0.595835, acc.: 73.44%] [G loss: 0.715626]\n",
      "epoch:17 step:16203 [D loss: 0.494399, acc.: 84.38%] [G loss: 0.846703]\n",
      "epoch:17 step:16204 [D loss: 1.050339, acc.: 34.38%] [G loss: 1.057064]\n",
      "epoch:17 step:16205 [D loss: 0.442324, acc.: 88.28%] [G loss: 1.083781]\n",
      "epoch:17 step:16206 [D loss: 0.560945, acc.: 73.44%] [G loss: 0.837192]\n",
      "epoch:17 step:16207 [D loss: 0.581997, acc.: 71.09%] [G loss: 0.550052]\n",
      "epoch:17 step:16208 [D loss: 0.403208, acc.: 82.03%] [G loss: 1.125449]\n",
      "epoch:17 step:16209 [D loss: 0.776864, acc.: 41.41%] [G loss: 1.038800]\n",
      "epoch:17 step:16210 [D loss: 0.581947, acc.: 70.31%] [G loss: 0.835250]\n",
      "epoch:17 step:16211 [D loss: 0.702034, acc.: 60.16%] [G loss: 1.210514]\n",
      "epoch:17 step:16212 [D loss: 0.651010, acc.: 60.16%] [G loss: 1.293496]\n",
      "epoch:17 step:16213 [D loss: 0.798481, acc.: 45.31%] [G loss: 1.178534]\n",
      "epoch:17 step:16214 [D loss: 0.754461, acc.: 49.22%] [G loss: 1.120959]\n",
      "epoch:17 step:16215 [D loss: 0.791277, acc.: 46.09%] [G loss: 1.078090]\n",
      "epoch:17 step:16216 [D loss: 0.771430, acc.: 48.44%] [G loss: 0.953232]\n",
      "epoch:17 step:16217 [D loss: 0.662969, acc.: 60.16%] [G loss: 0.899397]\n",
      "epoch:17 step:16218 [D loss: 0.603029, acc.: 64.84%] [G loss: 0.865662]\n",
      "epoch:17 step:16219 [D loss: 0.810230, acc.: 37.50%] [G loss: 0.946242]\n",
      "epoch:17 step:16220 [D loss: 0.712233, acc.: 49.22%] [G loss: 0.952832]\n",
      "epoch:17 step:16221 [D loss: 0.535605, acc.: 76.56%] [G loss: 1.005386]\n",
      "epoch:17 step:16222 [D loss: 0.852400, acc.: 42.19%] [G loss: 0.973656]\n",
      "epoch:17 step:16223 [D loss: 0.686928, acc.: 57.81%] [G loss: 0.802360]\n",
      "epoch:17 step:16224 [D loss: 0.542534, acc.: 83.59%] [G loss: 0.851622]\n",
      "epoch:17 step:16225 [D loss: 0.644944, acc.: 67.19%] [G loss: 0.954216]\n",
      "epoch:17 step:16226 [D loss: 0.520362, acc.: 76.56%] [G loss: 1.092408]\n",
      "epoch:17 step:16227 [D loss: 0.409971, acc.: 93.75%] [G loss: 1.053710]\n",
      "epoch:17 step:16228 [D loss: 0.365003, acc.: 94.53%] [G loss: 1.100406]\n",
      "epoch:17 step:16229 [D loss: 0.468307, acc.: 87.50%] [G loss: 1.293167]\n",
      "epoch:17 step:16230 [D loss: 0.511005, acc.: 76.56%] [G loss: 1.166841]\n",
      "epoch:17 step:16231 [D loss: 0.646616, acc.: 64.06%] [G loss: 1.274610]\n",
      "epoch:17 step:16232 [D loss: 0.534428, acc.: 72.66%] [G loss: 0.890072]\n",
      "epoch:17 step:16233 [D loss: 0.674206, acc.: 56.25%] [G loss: 1.066326]\n",
      "epoch:17 step:16234 [D loss: 0.751133, acc.: 51.56%] [G loss: 0.749875]\n",
      "epoch:17 step:16235 [D loss: 0.729240, acc.: 53.91%] [G loss: 0.341919]\n",
      "epoch:17 step:16236 [D loss: 0.503646, acc.: 78.12%] [G loss: 0.688155]\n",
      "epoch:17 step:16237 [D loss: 0.848182, acc.: 40.62%] [G loss: 0.759434]\n",
      "epoch:17 step:16238 [D loss: 0.705740, acc.: 54.69%] [G loss: 0.913893]\n",
      "epoch:17 step:16239 [D loss: 0.841876, acc.: 32.03%] [G loss: 0.511145]\n",
      "epoch:17 step:16240 [D loss: 0.812948, acc.: 43.75%] [G loss: 0.812188]\n",
      "epoch:17 step:16241 [D loss: 0.682631, acc.: 67.19%] [G loss: 0.915096]\n",
      "epoch:17 step:16242 [D loss: 0.567950, acc.: 71.88%] [G loss: 0.940444]\n",
      "epoch:17 step:16243 [D loss: 0.458063, acc.: 75.00%] [G loss: 0.882919]\n",
      "epoch:17 step:16244 [D loss: 0.660228, acc.: 61.72%] [G loss: 0.783080]\n",
      "epoch:17 step:16245 [D loss: 0.579991, acc.: 72.66%] [G loss: 0.869909]\n",
      "epoch:17 step:16246 [D loss: 0.683308, acc.: 57.81%] [G loss: 0.892520]\n",
      "epoch:17 step:16247 [D loss: 1.032902, acc.: 37.50%] [G loss: 1.048900]\n",
      "epoch:17 step:16248 [D loss: 0.588206, acc.: 71.09%] [G loss: 1.100644]\n",
      "epoch:17 step:16249 [D loss: 0.618990, acc.: 64.06%] [G loss: 0.982495]\n",
      "epoch:17 step:16250 [D loss: 0.762114, acc.: 47.66%] [G loss: 0.941288]\n",
      "epoch:17 step:16251 [D loss: 0.650257, acc.: 65.62%] [G loss: 0.757438]\n",
      "epoch:17 step:16252 [D loss: 0.750124, acc.: 54.69%] [G loss: 0.946885]\n",
      "epoch:17 step:16253 [D loss: 0.680679, acc.: 57.03%] [G loss: 0.970289]\n",
      "epoch:17 step:16254 [D loss: 0.680925, acc.: 47.66%] [G loss: 0.905435]\n",
      "epoch:17 step:16255 [D loss: 0.645012, acc.: 65.62%] [G loss: 0.834891]\n",
      "epoch:17 step:16256 [D loss: 0.553955, acc.: 70.31%] [G loss: 0.760813]\n",
      "epoch:17 step:16257 [D loss: 0.547982, acc.: 75.78%] [G loss: 0.817534]\n",
      "epoch:17 step:16258 [D loss: 0.687086, acc.: 50.00%] [G loss: 0.983645]\n",
      "epoch:17 step:16259 [D loss: 0.717132, acc.: 53.91%] [G loss: 0.873843]\n",
      "epoch:17 step:16260 [D loss: 0.733722, acc.: 48.44%] [G loss: 0.978884]\n",
      "epoch:17 step:16261 [D loss: 0.685820, acc.: 54.69%] [G loss: 0.759641]\n",
      "epoch:17 step:16262 [D loss: 0.513088, acc.: 70.31%] [G loss: 0.961880]\n",
      "epoch:17 step:16263 [D loss: 0.616123, acc.: 67.19%] [G loss: 1.039217]\n",
      "epoch:17 step:16264 [D loss: 0.610742, acc.: 67.97%] [G loss: 0.990819]\n",
      "epoch:17 step:16265 [D loss: 0.399534, acc.: 83.59%] [G loss: 1.011647]\n",
      "epoch:17 step:16266 [D loss: 0.557274, acc.: 73.44%] [G loss: 0.913005]\n",
      "epoch:17 step:16267 [D loss: 0.669072, acc.: 60.16%] [G loss: 0.760439]\n",
      "epoch:17 step:16268 [D loss: 0.635433, acc.: 61.72%] [G loss: 0.982458]\n",
      "epoch:17 step:16269 [D loss: 0.619800, acc.: 64.06%] [G loss: 0.955011]\n",
      "epoch:17 step:16270 [D loss: 0.765182, acc.: 46.88%] [G loss: 0.787155]\n",
      "epoch:17 step:16271 [D loss: 0.397413, acc.: 90.62%] [G loss: 1.198253]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16272 [D loss: 0.291057, acc.: 92.97%] [G loss: 1.057375]\n",
      "epoch:17 step:16273 [D loss: 0.344087, acc.: 91.41%] [G loss: 1.199152]\n",
      "epoch:17 step:16274 [D loss: 0.304193, acc.: 88.28%] [G loss: 1.695723]\n",
      "epoch:17 step:16275 [D loss: 0.257019, acc.: 96.09%] [G loss: 1.567950]\n",
      "epoch:17 step:16276 [D loss: 0.198047, acc.: 96.88%] [G loss: 1.351941]\n",
      "epoch:17 step:16277 [D loss: 0.815535, acc.: 44.53%] [G loss: 1.493122]\n",
      "epoch:17 step:16278 [D loss: 0.924772, acc.: 42.19%] [G loss: 1.111682]\n",
      "epoch:17 step:16279 [D loss: 0.570291, acc.: 71.88%] [G loss: 1.155703]\n",
      "epoch:17 step:16280 [D loss: 0.742866, acc.: 50.00%] [G loss: 1.186865]\n",
      "epoch:17 step:16281 [D loss: 0.744173, acc.: 48.44%] [G loss: 1.031557]\n",
      "epoch:17 step:16282 [D loss: 0.722241, acc.: 53.91%] [G loss: 0.983884]\n",
      "epoch:17 step:16283 [D loss: 0.608679, acc.: 67.19%] [G loss: 0.900486]\n",
      "epoch:17 step:16284 [D loss: 0.705038, acc.: 57.81%] [G loss: 0.972937]\n",
      "epoch:17 step:16285 [D loss: 0.688348, acc.: 57.03%] [G loss: 0.864865]\n",
      "epoch:17 step:16286 [D loss: 0.608977, acc.: 67.97%] [G loss: 1.478128]\n",
      "epoch:17 step:16287 [D loss: 0.605600, acc.: 67.97%] [G loss: 0.924221]\n",
      "epoch:17 step:16288 [D loss: 0.655656, acc.: 60.94%] [G loss: 0.836187]\n",
      "epoch:17 step:16289 [D loss: 0.684487, acc.: 53.12%] [G loss: 0.826468]\n",
      "epoch:17 step:16290 [D loss: 0.679866, acc.: 58.59%] [G loss: 0.732999]\n",
      "epoch:17 step:16291 [D loss: 0.517466, acc.: 75.00%] [G loss: 0.842084]\n",
      "epoch:17 step:16292 [D loss: 0.711362, acc.: 56.25%] [G loss: 0.844608]\n",
      "epoch:17 step:16293 [D loss: 0.580606, acc.: 67.97%] [G loss: 0.988802]\n",
      "epoch:17 step:16294 [D loss: 0.476001, acc.: 81.25%] [G loss: 0.844039]\n",
      "epoch:17 step:16295 [D loss: 0.323321, acc.: 86.72%] [G loss: 0.756769]\n",
      "epoch:17 step:16296 [D loss: 0.594872, acc.: 70.31%] [G loss: 0.990378]\n",
      "epoch:17 step:16297 [D loss: 0.683935, acc.: 56.25%] [G loss: 0.915587]\n",
      "epoch:17 step:16298 [D loss: 0.718653, acc.: 56.25%] [G loss: 0.810026]\n",
      "epoch:17 step:16299 [D loss: 0.646046, acc.: 65.62%] [G loss: 0.609181]\n",
      "epoch:17 step:16300 [D loss: 0.481177, acc.: 84.38%] [G loss: 0.929370]\n",
      "epoch:17 step:16301 [D loss: 0.633514, acc.: 66.41%] [G loss: 0.816683]\n",
      "epoch:17 step:16302 [D loss: 0.711575, acc.: 54.69%] [G loss: 1.015080]\n",
      "epoch:17 step:16303 [D loss: 0.734698, acc.: 47.66%] [G loss: 1.034818]\n",
      "epoch:17 step:16304 [D loss: 0.594638, acc.: 73.44%] [G loss: 0.882906]\n",
      "epoch:17 step:16305 [D loss: 0.770050, acc.: 48.44%] [G loss: 0.923506]\n",
      "epoch:17 step:16306 [D loss: 0.306391, acc.: 96.09%] [G loss: 0.903801]\n",
      "epoch:17 step:16307 [D loss: 0.314605, acc.: 91.41%] [G loss: 1.094623]\n",
      "epoch:17 step:16308 [D loss: 0.762591, acc.: 40.62%] [G loss: 0.784773]\n",
      "epoch:17 step:16309 [D loss: 0.454128, acc.: 87.50%] [G loss: 1.057811]\n",
      "epoch:17 step:16310 [D loss: 0.473818, acc.: 86.72%] [G loss: 1.036586]\n",
      "epoch:17 step:16311 [D loss: 0.787921, acc.: 42.19%] [G loss: 1.017691]\n",
      "epoch:17 step:16312 [D loss: 0.715176, acc.: 50.78%] [G loss: 0.815752]\n",
      "epoch:17 step:16313 [D loss: 0.688920, acc.: 54.69%] [G loss: 0.955800]\n",
      "epoch:17 step:16314 [D loss: 0.568889, acc.: 69.53%] [G loss: 0.842325]\n",
      "epoch:17 step:16315 [D loss: 0.683186, acc.: 53.12%] [G loss: 0.912130]\n",
      "epoch:17 step:16316 [D loss: 0.637239, acc.: 65.62%] [G loss: 0.939085]\n",
      "epoch:17 step:16317 [D loss: 0.692250, acc.: 52.34%] [G loss: 0.913099]\n",
      "epoch:17 step:16318 [D loss: 0.693450, acc.: 59.38%] [G loss: 0.687648]\n",
      "epoch:17 step:16319 [D loss: 0.692683, acc.: 57.81%] [G loss: 0.955521]\n",
      "epoch:17 step:16320 [D loss: 0.733576, acc.: 42.97%] [G loss: 0.870526]\n",
      "epoch:17 step:16321 [D loss: 0.742315, acc.: 42.97%] [G loss: 0.873324]\n",
      "epoch:17 step:16322 [D loss: 0.922124, acc.: 41.41%] [G loss: 0.892812]\n",
      "epoch:17 step:16323 [D loss: 0.728895, acc.: 45.31%] [G loss: 0.880162]\n",
      "epoch:17 step:16324 [D loss: 0.702959, acc.: 52.34%] [G loss: 0.981257]\n",
      "epoch:17 step:16325 [D loss: 0.446025, acc.: 82.03%] [G loss: 0.855271]\n",
      "epoch:17 step:16326 [D loss: 0.320790, acc.: 87.50%] [G loss: 0.919608]\n",
      "epoch:17 step:16327 [D loss: 0.264349, acc.: 97.66%] [G loss: 0.877577]\n",
      "epoch:17 step:16328 [D loss: 0.385653, acc.: 92.97%] [G loss: 1.036791]\n",
      "epoch:17 step:16329 [D loss: 0.364501, acc.: 88.28%] [G loss: 1.104483]\n",
      "epoch:17 step:16330 [D loss: 0.499656, acc.: 82.81%] [G loss: 1.171900]\n",
      "epoch:17 step:16331 [D loss: 0.258861, acc.: 96.88%] [G loss: 1.160700]\n",
      "epoch:17 step:16332 [D loss: 0.444705, acc.: 92.97%] [G loss: 0.955123]\n",
      "epoch:17 step:16333 [D loss: 0.244060, acc.: 99.22%] [G loss: 1.139019]\n",
      "epoch:17 step:16334 [D loss: 0.219499, acc.: 98.44%] [G loss: 1.112516]\n",
      "epoch:17 step:16335 [D loss: 0.216068, acc.: 100.00%] [G loss: 1.216192]\n",
      "epoch:17 step:16336 [D loss: 0.238185, acc.: 89.06%] [G loss: 1.329768]\n",
      "epoch:17 step:16337 [D loss: 0.299009, acc.: 98.44%] [G loss: 1.191761]\n",
      "epoch:17 step:16338 [D loss: 0.191841, acc.: 95.31%] [G loss: 1.400168]\n",
      "epoch:17 step:16339 [D loss: 0.316465, acc.: 97.66%] [G loss: 1.453138]\n",
      "epoch:17 step:16340 [D loss: 0.807361, acc.: 50.78%] [G loss: 1.261412]\n",
      "epoch:17 step:16341 [D loss: 0.571294, acc.: 64.06%] [G loss: 1.277628]\n",
      "epoch:17 step:16342 [D loss: 0.170786, acc.: 100.00%] [G loss: 1.480068]\n",
      "epoch:17 step:16343 [D loss: 0.183969, acc.: 99.22%] [G loss: 1.587632]\n",
      "epoch:17 step:16344 [D loss: 0.182408, acc.: 99.22%] [G loss: 1.629226]\n",
      "epoch:17 step:16345 [D loss: 0.281161, acc.: 96.09%] [G loss: 1.488591]\n",
      "epoch:17 step:16346 [D loss: 0.151211, acc.: 100.00%] [G loss: 1.218268]\n",
      "epoch:17 step:16347 [D loss: 0.133818, acc.: 100.00%] [G loss: 1.298578]\n",
      "epoch:17 step:16348 [D loss: 0.141329, acc.: 100.00%] [G loss: 1.681637]\n",
      "epoch:17 step:16349 [D loss: 0.159440, acc.: 100.00%] [G loss: 1.955048]\n",
      "epoch:17 step:16350 [D loss: 0.914641, acc.: 44.53%] [G loss: 1.693995]\n",
      "epoch:17 step:16351 [D loss: 0.928575, acc.: 40.62%] [G loss: 1.401629]\n",
      "epoch:17 step:16352 [D loss: 0.485916, acc.: 78.91%] [G loss: 1.466300]\n",
      "epoch:17 step:16353 [D loss: 0.427323, acc.: 68.75%] [G loss: 1.775080]\n",
      "epoch:17 step:16354 [D loss: 0.241269, acc.: 90.62%] [G loss: 1.004162]\n",
      "epoch:17 step:16355 [D loss: 1.227522, acc.: 29.69%] [G loss: 1.743667]\n",
      "epoch:17 step:16356 [D loss: 0.195909, acc.: 100.00%] [G loss: 1.548981]\n",
      "epoch:17 step:16357 [D loss: 0.365702, acc.: 79.69%] [G loss: 1.804220]\n",
      "epoch:17 step:16358 [D loss: 0.722246, acc.: 60.16%] [G loss: 1.359896]\n",
      "epoch:17 step:16359 [D loss: 0.669338, acc.: 55.47%] [G loss: 1.887192]\n",
      "epoch:17 step:16360 [D loss: 0.794378, acc.: 51.56%] [G loss: 1.744587]\n",
      "epoch:17 step:16361 [D loss: 1.020472, acc.: 43.75%] [G loss: 1.544129]\n",
      "epoch:17 step:16362 [D loss: 0.876117, acc.: 48.44%] [G loss: 1.449137]\n",
      "epoch:17 step:16363 [D loss: 0.953976, acc.: 42.19%] [G loss: 1.333504]\n",
      "epoch:17 step:16364 [D loss: 1.257277, acc.: 4.69%] [G loss: 0.902127]\n",
      "epoch:17 step:16365 [D loss: 0.747754, acc.: 55.47%] [G loss: 1.029923]\n",
      "epoch:17 step:16366 [D loss: 0.802287, acc.: 47.66%] [G loss: 1.219849]\n",
      "epoch:17 step:16367 [D loss: 0.618367, acc.: 67.97%] [G loss: 0.997488]\n",
      "epoch:17 step:16368 [D loss: 0.796071, acc.: 49.22%] [G loss: 0.519175]\n",
      "epoch:17 step:16369 [D loss: 0.650010, acc.: 62.50%] [G loss: 0.901119]\n",
      "epoch:17 step:16370 [D loss: 0.858111, acc.: 32.81%] [G loss: 0.398090]\n",
      "epoch:17 step:16371 [D loss: 0.635109, acc.: 68.75%] [G loss: 0.620904]\n",
      "epoch:17 step:16372 [D loss: 0.825603, acc.: 35.16%] [G loss: 0.560076]\n",
      "epoch:17 step:16373 [D loss: 0.791242, acc.: 43.75%] [G loss: 0.501048]\n",
      "epoch:17 step:16374 [D loss: 0.944718, acc.: 36.72%] [G loss: 0.574762]\n",
      "epoch:17 step:16375 [D loss: 1.118955, acc.: 8.59%] [G loss: 0.885351]\n",
      "epoch:17 step:16376 [D loss: 0.747902, acc.: 42.97%] [G loss: 1.173033]\n",
      "epoch:17 step:16377 [D loss: 0.604987, acc.: 60.16%] [G loss: 1.185701]\n",
      "epoch:17 step:16378 [D loss: 0.554021, acc.: 70.31%] [G loss: 1.185437]\n",
      "epoch:17 step:16379 [D loss: 0.587481, acc.: 60.94%] [G loss: 1.278574]\n",
      "epoch:17 step:16380 [D loss: 0.442332, acc.: 90.62%] [G loss: 1.379224]\n",
      "epoch:17 step:16381 [D loss: 0.412332, acc.: 93.75%] [G loss: 1.405182]\n",
      "epoch:17 step:16382 [D loss: 0.396204, acc.: 90.62%] [G loss: 1.409728]\n",
      "epoch:17 step:16383 [D loss: 0.430496, acc.: 89.84%] [G loss: 1.603642]\n",
      "epoch:17 step:16384 [D loss: 0.443409, acc.: 86.72%] [G loss: 1.624457]\n",
      "epoch:17 step:16385 [D loss: 0.187759, acc.: 98.44%] [G loss: 1.564562]\n",
      "epoch:17 step:16386 [D loss: 0.335217, acc.: 95.31%] [G loss: 1.504301]\n",
      "epoch:17 step:16387 [D loss: 0.612234, acc.: 54.69%] [G loss: 1.724464]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16388 [D loss: 0.491661, acc.: 75.00%] [G loss: 1.616141]\n",
      "epoch:17 step:16389 [D loss: 0.597336, acc.: 71.09%] [G loss: 1.368670]\n",
      "epoch:17 step:16390 [D loss: 0.746063, acc.: 53.12%] [G loss: 1.216383]\n",
      "epoch:17 step:16391 [D loss: 0.980102, acc.: 40.62%] [G loss: 1.015642]\n",
      "epoch:17 step:16392 [D loss: 0.718597, acc.: 53.91%] [G loss: 0.804417]\n",
      "epoch:17 step:16393 [D loss: 0.498443, acc.: 85.94%] [G loss: 0.938147]\n",
      "epoch:17 step:16394 [D loss: 0.414890, acc.: 83.59%] [G loss: 0.880235]\n",
      "epoch:17 step:16395 [D loss: 0.386726, acc.: 90.62%] [G loss: 1.119502]\n",
      "epoch:17 step:16396 [D loss: 0.371754, acc.: 86.72%] [G loss: 0.706117]\n",
      "epoch:17 step:16397 [D loss: 0.311145, acc.: 88.28%] [G loss: 1.091732]\n",
      "epoch:17 step:16398 [D loss: 0.222431, acc.: 96.88%] [G loss: 1.269133]\n",
      "epoch:17 step:16399 [D loss: 0.217131, acc.: 98.44%] [G loss: 1.170501]\n",
      "epoch:17 step:16400 [D loss: 0.233256, acc.: 96.09%] [G loss: 1.226830]\n",
      "##############\n",
      "[4.37486297 2.33918233 6.17559834 5.66045094 4.48588126 6.02788119\n",
      " 4.85141766 5.71687415 5.50336498 4.70402203]\n",
      "##########\n",
      "epoch:17 step:16401 [D loss: 0.321607, acc.: 97.66%] [G loss: 1.618984]\n",
      "epoch:17 step:16402 [D loss: 1.083533, acc.: 46.88%] [G loss: 1.319384]\n",
      "epoch:17 step:16403 [D loss: 1.021151, acc.: 45.31%] [G loss: 0.827466]\n",
      "epoch:17 step:16404 [D loss: 0.865527, acc.: 30.47%] [G loss: 0.922391]\n",
      "epoch:17 step:16405 [D loss: 0.604388, acc.: 65.62%] [G loss: 0.689640]\n",
      "epoch:17 step:16406 [D loss: 0.845934, acc.: 40.62%] [G loss: 0.247950]\n",
      "epoch:17 step:16407 [D loss: 0.690869, acc.: 53.12%] [G loss: 1.186719]\n",
      "epoch:17 step:16408 [D loss: 0.440241, acc.: 82.03%] [G loss: 0.958048]\n",
      "epoch:17 step:16409 [D loss: 0.660397, acc.: 56.25%] [G loss: 0.783135]\n",
      "epoch:17 step:16410 [D loss: 0.401767, acc.: 86.72%] [G loss: 0.875881]\n",
      "epoch:17 step:16411 [D loss: 0.928650, acc.: 50.78%] [G loss: 0.831887]\n",
      "epoch:17 step:16412 [D loss: 0.889927, acc.: 46.09%] [G loss: 1.162975]\n",
      "epoch:17 step:16413 [D loss: 0.843822, acc.: 45.31%] [G loss: 0.695045]\n",
      "epoch:17 step:16414 [D loss: 0.758213, acc.: 42.97%] [G loss: 0.975016]\n",
      "epoch:17 step:16415 [D loss: 0.764996, acc.: 44.53%] [G loss: 0.867257]\n",
      "epoch:17 step:16416 [D loss: 0.748564, acc.: 43.75%] [G loss: 0.933289]\n",
      "epoch:17 step:16417 [D loss: 0.738548, acc.: 38.28%] [G loss: 0.825815]\n",
      "epoch:17 step:16418 [D loss: 0.651926, acc.: 62.50%] [G loss: 0.786388]\n",
      "epoch:17 step:16419 [D loss: 0.492667, acc.: 87.50%] [G loss: 0.652473]\n",
      "epoch:17 step:16420 [D loss: 0.595557, acc.: 70.31%] [G loss: 0.794687]\n",
      "epoch:17 step:16421 [D loss: 0.707557, acc.: 49.22%] [G loss: 0.895565]\n",
      "epoch:17 step:16422 [D loss: 0.677825, acc.: 58.59%] [G loss: 0.669653]\n",
      "epoch:17 step:16423 [D loss: 0.756603, acc.: 41.41%] [G loss: 0.678825]\n",
      "epoch:17 step:16424 [D loss: 0.694362, acc.: 53.91%] [G loss: 0.967709]\n",
      "epoch:17 step:16425 [D loss: 0.759826, acc.: 42.19%] [G loss: 0.588939]\n",
      "epoch:17 step:16426 [D loss: 0.708352, acc.: 50.78%] [G loss: 0.771105]\n",
      "epoch:17 step:16427 [D loss: 0.644618, acc.: 60.94%] [G loss: 0.712931]\n",
      "epoch:17 step:16428 [D loss: 0.582287, acc.: 73.44%] [G loss: 0.903123]\n",
      "epoch:17 step:16429 [D loss: 0.647014, acc.: 63.28%] [G loss: 0.808100]\n",
      "epoch:17 step:16430 [D loss: 0.752061, acc.: 46.88%] [G loss: 0.944734]\n",
      "epoch:17 step:16431 [D loss: 0.669813, acc.: 55.47%] [G loss: 0.980454]\n",
      "epoch:17 step:16432 [D loss: 0.495878, acc.: 75.78%] [G loss: 1.010314]\n",
      "epoch:17 step:16433 [D loss: 0.463922, acc.: 87.50%] [G loss: 0.994786]\n",
      "epoch:17 step:16434 [D loss: 0.576217, acc.: 72.66%] [G loss: 0.999428]\n",
      "epoch:17 step:16435 [D loss: 0.660127, acc.: 60.16%] [G loss: 0.646140]\n",
      "epoch:17 step:16436 [D loss: 0.583076, acc.: 69.53%] [G loss: 0.558846]\n",
      "epoch:17 step:16437 [D loss: 0.748322, acc.: 48.44%] [G loss: 1.100213]\n",
      "epoch:17 step:16438 [D loss: 0.668472, acc.: 56.25%] [G loss: 0.907879]\n",
      "epoch:17 step:16439 [D loss: 0.586775, acc.: 66.41%] [G loss: 1.008441]\n",
      "epoch:17 step:16440 [D loss: 0.490836, acc.: 80.47%] [G loss: 1.243407]\n",
      "epoch:17 step:16441 [D loss: 0.495020, acc.: 85.16%] [G loss: 1.212587]\n",
      "epoch:17 step:16442 [D loss: 0.454899, acc.: 85.16%] [G loss: 1.248910]\n",
      "epoch:17 step:16443 [D loss: 0.379470, acc.: 87.50%] [G loss: 1.310933]\n",
      "epoch:17 step:16444 [D loss: 0.263336, acc.: 94.53%] [G loss: 1.361969]\n",
      "epoch:17 step:16445 [D loss: 0.701771, acc.: 58.59%] [G loss: 1.302958]\n",
      "epoch:17 step:16446 [D loss: 0.664850, acc.: 61.72%] [G loss: 1.176444]\n",
      "epoch:17 step:16447 [D loss: 0.641970, acc.: 62.50%] [G loss: 1.221476]\n",
      "epoch:17 step:16448 [D loss: 0.639969, acc.: 66.41%] [G loss: 1.112635]\n",
      "epoch:17 step:16449 [D loss: 0.584732, acc.: 67.19%] [G loss: 0.865820]\n",
      "epoch:17 step:16450 [D loss: 0.895045, acc.: 35.94%] [G loss: 1.041092]\n",
      "epoch:17 step:16451 [D loss: 0.629921, acc.: 61.72%] [G loss: 0.904866]\n",
      "epoch:17 step:16452 [D loss: 0.648945, acc.: 56.25%] [G loss: 0.842538]\n",
      "epoch:17 step:16453 [D loss: 0.411643, acc.: 82.81%] [G loss: 0.992889]\n",
      "epoch:17 step:16454 [D loss: 0.637557, acc.: 60.16%] [G loss: 1.080993]\n",
      "epoch:17 step:16455 [D loss: 0.623870, acc.: 64.84%] [G loss: 1.018126]\n",
      "epoch:17 step:16456 [D loss: 0.388486, acc.: 89.06%] [G loss: 1.182062]\n",
      "epoch:17 step:16457 [D loss: 0.669697, acc.: 62.50%] [G loss: 1.098847]\n",
      "epoch:17 step:16458 [D loss: 0.610315, acc.: 71.88%] [G loss: 1.151258]\n",
      "epoch:17 step:16459 [D loss: 0.396089, acc.: 85.16%] [G loss: 1.115471]\n",
      "epoch:17 step:16460 [D loss: 0.702342, acc.: 55.47%] [G loss: 1.164755]\n",
      "epoch:17 step:16461 [D loss: 0.733366, acc.: 54.69%] [G loss: 1.033461]\n",
      "epoch:17 step:16462 [D loss: 0.793058, acc.: 42.19%] [G loss: 0.773920]\n",
      "epoch:17 step:16463 [D loss: 0.708512, acc.: 51.56%] [G loss: 1.084694]\n",
      "epoch:17 step:16464 [D loss: 0.359260, acc.: 85.94%] [G loss: 0.976807]\n",
      "epoch:17 step:16465 [D loss: 0.296878, acc.: 87.50%] [G loss: 1.068789]\n",
      "epoch:17 step:16466 [D loss: 0.291839, acc.: 92.19%] [G loss: 1.040084]\n",
      "epoch:17 step:16467 [D loss: 0.471154, acc.: 88.28%] [G loss: 1.184524]\n",
      "epoch:17 step:16468 [D loss: 0.290955, acc.: 93.75%] [G loss: 1.159193]\n",
      "epoch:17 step:16469 [D loss: 0.331117, acc.: 92.97%] [G loss: 1.331004]\n",
      "epoch:17 step:16470 [D loss: 0.560078, acc.: 71.09%] [G loss: 1.047826]\n",
      "epoch:17 step:16471 [D loss: 0.925674, acc.: 51.56%] [G loss: 1.240685]\n",
      "epoch:17 step:16472 [D loss: 0.545626, acc.: 79.69%] [G loss: 1.043766]\n",
      "epoch:17 step:16473 [D loss: 1.069969, acc.: 26.56%] [G loss: 0.844040]\n",
      "epoch:17 step:16474 [D loss: 0.635304, acc.: 69.53%] [G loss: 0.995314]\n",
      "epoch:17 step:16475 [D loss: 0.608794, acc.: 72.66%] [G loss: 1.011060]\n",
      "epoch:17 step:16476 [D loss: 0.632788, acc.: 63.28%] [G loss: 0.984297]\n",
      "epoch:17 step:16477 [D loss: 0.525704, acc.: 75.78%] [G loss: 0.943885]\n",
      "epoch:17 step:16478 [D loss: 0.536165, acc.: 78.12%] [G loss: 0.816822]\n",
      "epoch:17 step:16479 [D loss: 0.316110, acc.: 89.84%] [G loss: 1.150920]\n",
      "epoch:17 step:16480 [D loss: 0.557540, acc.: 76.56%] [G loss: 0.921692]\n",
      "epoch:17 step:16481 [D loss: 0.511181, acc.: 78.91%] [G loss: 1.104850]\n",
      "epoch:17 step:16482 [D loss: 0.647164, acc.: 57.81%] [G loss: 1.022488]\n",
      "epoch:17 step:16483 [D loss: 0.563808, acc.: 66.41%] [G loss: 1.171613]\n",
      "epoch:17 step:16484 [D loss: 0.395628, acc.: 89.06%] [G loss: 1.380165]\n",
      "epoch:17 step:16485 [D loss: 0.326025, acc.: 89.84%] [G loss: 1.477659]\n",
      "epoch:17 step:16486 [D loss: 0.256980, acc.: 95.31%] [G loss: 1.406998]\n",
      "epoch:17 step:16487 [D loss: 0.312699, acc.: 97.66%] [G loss: 1.351613]\n",
      "epoch:17 step:16488 [D loss: 0.393165, acc.: 88.28%] [G loss: 1.007134]\n",
      "epoch:17 step:16489 [D loss: 0.794772, acc.: 52.34%] [G loss: 0.931298]\n",
      "epoch:17 step:16490 [D loss: 0.376435, acc.: 89.84%] [G loss: 0.998257]\n",
      "epoch:17 step:16491 [D loss: 0.849604, acc.: 42.97%] [G loss: 0.926446]\n",
      "epoch:17 step:16492 [D loss: 0.722437, acc.: 51.56%] [G loss: 0.916491]\n",
      "epoch:17 step:16493 [D loss: 0.760482, acc.: 46.09%] [G loss: 1.138459]\n",
      "epoch:17 step:16494 [D loss: 1.098612, acc.: 30.47%] [G loss: 0.754680]\n",
      "epoch:17 step:16495 [D loss: 0.448962, acc.: 82.81%] [G loss: 1.031550]\n",
      "epoch:17 step:16496 [D loss: 0.337957, acc.: 88.28%] [G loss: 1.304532]\n",
      "epoch:17 step:16497 [D loss: 0.681388, acc.: 50.00%] [G loss: 1.124895]\n",
      "epoch:17 step:16498 [D loss: 0.778442, acc.: 42.19%] [G loss: 0.996752]\n",
      "epoch:17 step:16499 [D loss: 0.803182, acc.: 41.41%] [G loss: 1.110179]\n",
      "epoch:17 step:16500 [D loss: 0.648001, acc.: 62.50%] [G loss: 1.105339]\n",
      "epoch:17 step:16501 [D loss: 0.771770, acc.: 53.12%] [G loss: 0.913785]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16502 [D loss: 0.639993, acc.: 63.28%] [G loss: 1.042131]\n",
      "epoch:17 step:16503 [D loss: 0.707666, acc.: 52.34%] [G loss: 0.934627]\n",
      "epoch:17 step:16504 [D loss: 0.608934, acc.: 70.31%] [G loss: 0.738755]\n",
      "epoch:17 step:16505 [D loss: 0.487245, acc.: 80.47%] [G loss: 0.724688]\n",
      "epoch:17 step:16506 [D loss: 0.375095, acc.: 87.50%] [G loss: 0.500156]\n",
      "epoch:17 step:16507 [D loss: 0.337879, acc.: 91.41%] [G loss: 1.106910]\n",
      "epoch:17 step:16508 [D loss: 0.448201, acc.: 82.81%] [G loss: 1.255448]\n",
      "epoch:17 step:16509 [D loss: 0.709603, acc.: 50.78%] [G loss: 1.093271]\n",
      "epoch:17 step:16510 [D loss: 0.764833, acc.: 38.28%] [G loss: 1.024965]\n",
      "epoch:17 step:16511 [D loss: 0.671427, acc.: 59.38%] [G loss: 1.005268]\n",
      "epoch:17 step:16512 [D loss: 0.733066, acc.: 49.22%] [G loss: 0.976508]\n",
      "epoch:17 step:16513 [D loss: 0.747065, acc.: 51.56%] [G loss: 1.092062]\n",
      "epoch:17 step:16514 [D loss: 0.598062, acc.: 69.53%] [G loss: 0.941773]\n",
      "epoch:17 step:16515 [D loss: 0.652367, acc.: 62.50%] [G loss: 1.015891]\n",
      "epoch:17 step:16516 [D loss: 0.270750, acc.: 91.41%] [G loss: 1.103467]\n",
      "epoch:17 step:16517 [D loss: 0.234970, acc.: 95.31%] [G loss: 1.188633]\n",
      "epoch:17 step:16518 [D loss: 0.207740, acc.: 97.66%] [G loss: 1.243346]\n",
      "epoch:17 step:16519 [D loss: 0.744161, acc.: 51.56%] [G loss: 1.134107]\n",
      "epoch:17 step:16520 [D loss: 0.535758, acc.: 78.91%] [G loss: 0.973227]\n",
      "epoch:17 step:16521 [D loss: 0.495241, acc.: 84.38%] [G loss: 1.039923]\n",
      "epoch:17 step:16522 [D loss: 0.685189, acc.: 57.03%] [G loss: 0.970627]\n",
      "epoch:17 step:16523 [D loss: 0.800762, acc.: 36.72%] [G loss: 0.868857]\n",
      "epoch:17 step:16524 [D loss: 0.408961, acc.: 80.47%] [G loss: 1.218085]\n",
      "epoch:17 step:16525 [D loss: 0.604839, acc.: 70.31%] [G loss: 1.053304]\n",
      "epoch:17 step:16526 [D loss: 0.776673, acc.: 49.22%] [G loss: 0.631387]\n",
      "epoch:17 step:16527 [D loss: 0.664435, acc.: 61.72%] [G loss: 0.780887]\n",
      "epoch:17 step:16528 [D loss: 0.732415, acc.: 50.78%] [G loss: 1.085751]\n",
      "epoch:17 step:16529 [D loss: 0.381160, acc.: 85.16%] [G loss: 1.094180]\n",
      "epoch:17 step:16530 [D loss: 0.213417, acc.: 98.44%] [G loss: 1.223158]\n",
      "epoch:17 step:16531 [D loss: 0.362416, acc.: 95.31%] [G loss: 1.288289]\n",
      "epoch:17 step:16532 [D loss: 0.738081, acc.: 51.56%] [G loss: 0.991727]\n",
      "epoch:17 step:16533 [D loss: 0.386079, acc.: 79.69%] [G loss: 1.123495]\n",
      "epoch:17 step:16534 [D loss: 0.675063, acc.: 55.47%] [G loss: 1.172227]\n",
      "epoch:17 step:16535 [D loss: 0.720823, acc.: 54.69%] [G loss: 1.061141]\n",
      "epoch:17 step:16536 [D loss: 0.632931, acc.: 67.19%] [G loss: 1.094955]\n",
      "epoch:17 step:16537 [D loss: 0.486881, acc.: 79.69%] [G loss: 0.999928]\n",
      "epoch:17 step:16538 [D loss: 0.293152, acc.: 96.88%] [G loss: 0.612044]\n",
      "epoch:17 step:16539 [D loss: 0.737013, acc.: 53.12%] [G loss: 1.063155]\n",
      "epoch:17 step:16540 [D loss: 0.430572, acc.: 90.62%] [G loss: 1.159421]\n",
      "epoch:17 step:16541 [D loss: 0.359696, acc.: 87.50%] [G loss: 1.191601]\n",
      "epoch:17 step:16542 [D loss: 0.671484, acc.: 63.28%] [G loss: 0.349899]\n",
      "epoch:17 step:16543 [D loss: 0.771172, acc.: 46.88%] [G loss: 1.045838]\n",
      "epoch:17 step:16544 [D loss: 0.679719, acc.: 62.50%] [G loss: 0.955747]\n",
      "epoch:17 step:16545 [D loss: 0.651207, acc.: 58.59%] [G loss: 1.009156]\n",
      "epoch:17 step:16546 [D loss: 0.856449, acc.: 35.94%] [G loss: 0.865205]\n",
      "epoch:17 step:16547 [D loss: 0.416565, acc.: 86.72%] [G loss: 0.898468]\n",
      "epoch:17 step:16548 [D loss: 0.538568, acc.: 75.78%] [G loss: 1.103808]\n",
      "epoch:17 step:16549 [D loss: 0.357260, acc.: 92.19%] [G loss: 1.152446]\n",
      "epoch:17 step:16550 [D loss: 0.685113, acc.: 58.59%] [G loss: 0.935619]\n",
      "epoch:17 step:16551 [D loss: 1.314784, acc.: 10.94%] [G loss: 1.125033]\n",
      "epoch:17 step:16552 [D loss: 0.679833, acc.: 55.47%] [G loss: 1.173873]\n",
      "epoch:17 step:16553 [D loss: 0.699337, acc.: 50.78%] [G loss: 1.112952]\n",
      "epoch:17 step:16554 [D loss: 0.484410, acc.: 82.03%] [G loss: 0.786636]\n",
      "epoch:17 step:16555 [D loss: 0.770879, acc.: 51.56%] [G loss: 0.884505]\n",
      "epoch:17 step:16556 [D loss: 0.490027, acc.: 83.59%] [G loss: 0.797486]\n",
      "epoch:17 step:16557 [D loss: 0.743802, acc.: 49.22%] [G loss: 0.874048]\n",
      "epoch:17 step:16558 [D loss: 0.680700, acc.: 58.59%] [G loss: 1.013056]\n",
      "epoch:17 step:16559 [D loss: 0.781939, acc.: 42.19%] [G loss: 1.042955]\n",
      "epoch:17 step:16560 [D loss: 0.635460, acc.: 67.97%] [G loss: 0.870326]\n",
      "epoch:17 step:16561 [D loss: 0.555718, acc.: 73.44%] [G loss: 0.817770]\n",
      "epoch:17 step:16562 [D loss: 0.470626, acc.: 80.47%] [G loss: 1.080025]\n",
      "epoch:17 step:16563 [D loss: 0.757569, acc.: 54.69%] [G loss: 1.119230]\n",
      "epoch:17 step:16564 [D loss: 0.384916, acc.: 95.31%] [G loss: 1.296933]\n",
      "epoch:17 step:16565 [D loss: 0.560179, acc.: 69.53%] [G loss: 1.187760]\n",
      "epoch:17 step:16566 [D loss: 0.591913, acc.: 73.44%] [G loss: 1.201282]\n",
      "epoch:17 step:16567 [D loss: 0.762655, acc.: 42.19%] [G loss: 1.305980]\n",
      "epoch:17 step:16568 [D loss: 0.731885, acc.: 52.34%] [G loss: 1.156453]\n",
      "epoch:17 step:16569 [D loss: 0.925063, acc.: 29.69%] [G loss: 1.031435]\n",
      "epoch:17 step:16570 [D loss: 0.453695, acc.: 86.72%] [G loss: 1.077714]\n",
      "epoch:17 step:16571 [D loss: 0.780140, acc.: 45.31%] [G loss: 0.829848]\n",
      "epoch:17 step:16572 [D loss: 0.516899, acc.: 77.34%] [G loss: 0.975330]\n",
      "epoch:17 step:16573 [D loss: 0.280469, acc.: 92.97%] [G loss: 0.873991]\n",
      "epoch:17 step:16574 [D loss: 0.309906, acc.: 96.09%] [G loss: 1.224232]\n",
      "epoch:17 step:16575 [D loss: 0.312310, acc.: 88.28%] [G loss: 1.374695]\n",
      "epoch:17 step:16576 [D loss: 0.311931, acc.: 93.75%] [G loss: 1.281350]\n",
      "epoch:17 step:16577 [D loss: 0.302657, acc.: 93.75%] [G loss: 1.502255]\n",
      "epoch:17 step:16578 [D loss: 0.326326, acc.: 94.53%] [G loss: 0.904987]\n",
      "epoch:17 step:16579 [D loss: 0.194533, acc.: 99.22%] [G loss: 1.596183]\n",
      "epoch:17 step:16580 [D loss: 0.532444, acc.: 72.66%] [G loss: 0.701985]\n",
      "epoch:17 step:16581 [D loss: 0.491037, acc.: 79.69%] [G loss: 0.432798]\n",
      "epoch:17 step:16582 [D loss: 0.773259, acc.: 47.66%] [G loss: 1.353473]\n",
      "epoch:17 step:16583 [D loss: 0.750332, acc.: 49.22%] [G loss: 0.922822]\n",
      "epoch:17 step:16584 [D loss: 1.056931, acc.: 42.19%] [G loss: 1.357208]\n",
      "epoch:17 step:16585 [D loss: 0.735948, acc.: 50.78%] [G loss: 1.012170]\n",
      "epoch:17 step:16586 [D loss: 0.815102, acc.: 40.62%] [G loss: 0.649693]\n",
      "epoch:17 step:16587 [D loss: 0.871688, acc.: 43.75%] [G loss: 1.071401]\n",
      "epoch:17 step:16588 [D loss: 0.581554, acc.: 66.41%] [G loss: 1.336409]\n",
      "epoch:17 step:16589 [D loss: 0.527990, acc.: 75.78%] [G loss: 0.322085]\n",
      "epoch:17 step:16590 [D loss: 0.550967, acc.: 78.91%] [G loss: 0.379792]\n",
      "epoch:17 step:16591 [D loss: 1.190459, acc.: 8.59%] [G loss: 0.861410]\n",
      "epoch:17 step:16592 [D loss: 0.323798, acc.: 92.97%] [G loss: 1.345152]\n",
      "epoch:17 step:16593 [D loss: 0.419062, acc.: 76.56%] [G loss: 1.027111]\n",
      "epoch:17 step:16594 [D loss: 0.251517, acc.: 99.22%] [G loss: 1.337498]\n",
      "epoch:17 step:16595 [D loss: 0.875775, acc.: 50.00%] [G loss: 1.089253]\n",
      "epoch:17 step:16596 [D loss: 0.826809, acc.: 50.00%] [G loss: 1.105846]\n",
      "epoch:17 step:16597 [D loss: 0.706916, acc.: 53.91%] [G loss: 1.490685]\n",
      "epoch:17 step:16598 [D loss: 0.718381, acc.: 50.78%] [G loss: 1.091425]\n",
      "epoch:17 step:16599 [D loss: 0.727921, acc.: 52.34%] [G loss: 1.113679]\n",
      "epoch:17 step:16600 [D loss: 0.797384, acc.: 41.41%] [G loss: 1.552817]\n",
      "##############\n",
      "[3.4393952  1.77648852 6.50386905 5.4163032  4.05129405 5.89013853\n",
      " 5.10862029 5.23857557 5.52535786 4.73937884]\n",
      "##########\n",
      "epoch:17 step:16601 [D loss: 0.722359, acc.: 49.22%] [G loss: 1.031344]\n",
      "epoch:17 step:16602 [D loss: 0.738132, acc.: 49.22%] [G loss: 1.147710]\n",
      "epoch:17 step:16603 [D loss: 0.683891, acc.: 52.34%] [G loss: 1.399421]\n",
      "epoch:17 step:16604 [D loss: 0.701536, acc.: 50.78%] [G loss: 1.118719]\n",
      "epoch:17 step:16605 [D loss: 0.646707, acc.: 53.91%] [G loss: 0.945103]\n",
      "epoch:17 step:16606 [D loss: 0.659176, acc.: 65.62%] [G loss: 1.046463]\n",
      "epoch:17 step:16607 [D loss: 0.758107, acc.: 37.50%] [G loss: 0.815237]\n",
      "epoch:17 step:16608 [D loss: 0.691351, acc.: 57.81%] [G loss: 1.411563]\n",
      "epoch:17 step:16609 [D loss: 0.695604, acc.: 51.56%] [G loss: 0.862557]\n",
      "epoch:17 step:16610 [D loss: 0.689011, acc.: 54.69%] [G loss: 0.879299]\n",
      "epoch:17 step:16611 [D loss: 0.562328, acc.: 75.78%] [G loss: 1.027199]\n",
      "epoch:17 step:16612 [D loss: 0.654734, acc.: 63.28%] [G loss: 1.228230]\n",
      "epoch:17 step:16613 [D loss: 0.543635, acc.: 78.91%] [G loss: 0.997006]\n",
      "epoch:17 step:16614 [D loss: 0.604269, acc.: 73.44%] [G loss: 1.035431]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16615 [D loss: 0.493416, acc.: 85.94%] [G loss: 1.053068]\n",
      "epoch:17 step:16616 [D loss: 0.598031, acc.: 69.53%] [G loss: 0.780956]\n",
      "epoch:17 step:16617 [D loss: 0.682664, acc.: 53.12%] [G loss: 0.762896]\n",
      "epoch:17 step:16618 [D loss: 0.763987, acc.: 50.00%] [G loss: 1.085742]\n",
      "epoch:17 step:16619 [D loss: 0.751736, acc.: 52.34%] [G loss: 0.770619]\n",
      "epoch:17 step:16620 [D loss: 0.726139, acc.: 46.09%] [G loss: 0.808875]\n",
      "epoch:17 step:16621 [D loss: 0.680141, acc.: 53.91%] [G loss: 0.758178]\n",
      "epoch:17 step:16622 [D loss: 0.738367, acc.: 46.88%] [G loss: 0.763623]\n",
      "epoch:17 step:16623 [D loss: 0.635480, acc.: 64.06%] [G loss: 0.911917]\n",
      "epoch:17 step:16624 [D loss: 0.674521, acc.: 55.47%] [G loss: 0.822191]\n",
      "epoch:17 step:16625 [D loss: 0.327801, acc.: 83.59%] [G loss: 0.859871]\n",
      "epoch:17 step:16626 [D loss: 0.290571, acc.: 88.28%] [G loss: 1.015646]\n",
      "epoch:17 step:16627 [D loss: 0.315020, acc.: 85.94%] [G loss: 1.074541]\n",
      "epoch:17 step:16628 [D loss: 0.543477, acc.: 78.91%] [G loss: 1.141413]\n",
      "epoch:17 step:16629 [D loss: 0.239923, acc.: 97.66%] [G loss: 1.174232]\n",
      "epoch:17 step:16630 [D loss: 0.231601, acc.: 97.66%] [G loss: 1.160675]\n",
      "epoch:17 step:16631 [D loss: 0.230422, acc.: 100.00%] [G loss: 1.493752]\n",
      "epoch:17 step:16632 [D loss: 0.634840, acc.: 60.16%] [G loss: 1.346009]\n",
      "epoch:17 step:16633 [D loss: 0.444889, acc.: 86.72%] [G loss: 1.498518]\n",
      "epoch:17 step:16634 [D loss: 0.671571, acc.: 57.81%] [G loss: 1.102006]\n",
      "epoch:17 step:16635 [D loss: 0.204204, acc.: 99.22%] [G loss: 1.262265]\n",
      "epoch:17 step:16636 [D loss: 0.215615, acc.: 99.22%] [G loss: 1.364353]\n",
      "epoch:17 step:16637 [D loss: 0.182628, acc.: 99.22%] [G loss: 0.946137]\n",
      "epoch:17 step:16638 [D loss: 0.248719, acc.: 99.22%] [G loss: 1.196070]\n",
      "epoch:17 step:16639 [D loss: 1.002972, acc.: 51.56%] [G loss: 0.930302]\n",
      "epoch:17 step:16640 [D loss: 0.768588, acc.: 58.59%] [G loss: 0.886820]\n",
      "epoch:17 step:16641 [D loss: 0.601078, acc.: 77.34%] [G loss: 0.925486]\n",
      "epoch:17 step:16642 [D loss: 0.247440, acc.: 95.31%] [G loss: 0.878565]\n",
      "epoch:17 step:16643 [D loss: 0.834985, acc.: 50.78%] [G loss: 0.466098]\n",
      "epoch:17 step:16644 [D loss: 0.726094, acc.: 57.03%] [G loss: 1.295650]\n",
      "epoch:17 step:16645 [D loss: 0.756058, acc.: 51.56%] [G loss: 0.240448]\n",
      "epoch:17 step:16646 [D loss: 1.251078, acc.: 11.72%] [G loss: 1.014407]\n",
      "epoch:17 step:16647 [D loss: 0.696269, acc.: 57.81%] [G loss: 1.099805]\n",
      "epoch:17 step:16648 [D loss: 0.654900, acc.: 60.94%] [G loss: 1.160075]\n",
      "epoch:17 step:16649 [D loss: 0.676400, acc.: 58.59%] [G loss: 1.125552]\n",
      "epoch:17 step:16650 [D loss: 0.636872, acc.: 60.94%] [G loss: 1.103043]\n",
      "epoch:17 step:16651 [D loss: 0.569946, acc.: 75.78%] [G loss: 1.197152]\n",
      "epoch:17 step:16652 [D loss: 0.587866, acc.: 72.66%] [G loss: 0.935112]\n",
      "epoch:17 step:16653 [D loss: 0.780799, acc.: 41.41%] [G loss: 1.102549]\n",
      "epoch:17 step:16654 [D loss: 0.587806, acc.: 74.22%] [G loss: 1.151130]\n",
      "epoch:17 step:16655 [D loss: 0.573921, acc.: 72.66%] [G loss: 1.072583]\n",
      "epoch:17 step:16656 [D loss: 0.297798, acc.: 96.88%] [G loss: 1.136678]\n",
      "epoch:17 step:16657 [D loss: 0.252187, acc.: 98.44%] [G loss: 1.103629]\n",
      "epoch:17 step:16658 [D loss: 0.511340, acc.: 80.47%] [G loss: 1.152010]\n",
      "epoch:17 step:16659 [D loss: 0.293235, acc.: 92.97%] [G loss: 0.902895]\n",
      "epoch:17 step:16660 [D loss: 0.321174, acc.: 98.44%] [G loss: 1.256954]\n",
      "epoch:17 step:16661 [D loss: 0.213373, acc.: 98.44%] [G loss: 1.217342]\n",
      "epoch:17 step:16662 [D loss: 0.299352, acc.: 95.31%] [G loss: 1.237080]\n",
      "epoch:17 step:16663 [D loss: 0.783546, acc.: 47.66%] [G loss: 1.329032]\n",
      "epoch:17 step:16664 [D loss: 0.720533, acc.: 58.59%] [G loss: 1.263982]\n",
      "epoch:17 step:16665 [D loss: 0.713666, acc.: 56.25%] [G loss: 1.031502]\n",
      "epoch:17 step:16666 [D loss: 0.675098, acc.: 63.28%] [G loss: 1.067330]\n",
      "epoch:17 step:16667 [D loss: 0.704650, acc.: 51.56%] [G loss: 1.082891]\n",
      "epoch:17 step:16668 [D loss: 0.313758, acc.: 94.53%] [G loss: 1.057717]\n",
      "epoch:17 step:16669 [D loss: 0.564578, acc.: 77.34%] [G loss: 1.068787]\n",
      "epoch:17 step:16670 [D loss: 0.632162, acc.: 64.06%] [G loss: 1.040793]\n",
      "epoch:17 step:16671 [D loss: 0.553435, acc.: 76.56%] [G loss: 0.882645]\n",
      "epoch:17 step:16672 [D loss: 0.603123, acc.: 67.97%] [G loss: 0.996142]\n",
      "epoch:17 step:16673 [D loss: 0.646807, acc.: 61.72%] [G loss: 0.948911]\n",
      "epoch:17 step:16674 [D loss: 0.307482, acc.: 92.97%] [G loss: 0.995474]\n",
      "epoch:17 step:16675 [D loss: 0.265910, acc.: 95.31%] [G loss: 1.153891]\n",
      "epoch:17 step:16676 [D loss: 0.383405, acc.: 92.97%] [G loss: 1.029899]\n",
      "epoch:17 step:16677 [D loss: 0.703065, acc.: 54.69%] [G loss: 0.899392]\n",
      "epoch:17 step:16678 [D loss: 0.706638, acc.: 58.59%] [G loss: 1.005910]\n",
      "epoch:17 step:16679 [D loss: 0.643886, acc.: 58.59%] [G loss: 1.089102]\n",
      "epoch:17 step:16680 [D loss: 0.684627, acc.: 57.03%] [G loss: 0.920750]\n",
      "epoch:17 step:16681 [D loss: 0.541805, acc.: 75.00%] [G loss: 0.626670]\n",
      "epoch:17 step:16682 [D loss: 0.417761, acc.: 89.06%] [G loss: 1.095645]\n",
      "epoch:17 step:16683 [D loss: 0.253499, acc.: 90.62%] [G loss: 0.923179]\n",
      "epoch:17 step:16684 [D loss: 0.250455, acc.: 93.75%] [G loss: 1.110155]\n",
      "epoch:17 step:16685 [D loss: 0.192120, acc.: 99.22%] [G loss: 1.343197]\n",
      "epoch:17 step:16686 [D loss: 0.218171, acc.: 99.22%] [G loss: 1.466135]\n",
      "epoch:17 step:16687 [D loss: 0.454093, acc.: 80.47%] [G loss: 1.313134]\n",
      "epoch:17 step:16688 [D loss: 0.769157, acc.: 51.56%] [G loss: 1.156956]\n",
      "epoch:17 step:16689 [D loss: 0.758627, acc.: 46.88%] [G loss: 1.117553]\n",
      "epoch:17 step:16690 [D loss: 0.688639, acc.: 60.16%] [G loss: 1.077641]\n",
      "epoch:17 step:16691 [D loss: 0.483153, acc.: 73.44%] [G loss: 1.069646]\n",
      "epoch:17 step:16692 [D loss: 0.335029, acc.: 96.09%] [G loss: 1.110943]\n",
      "epoch:17 step:16693 [D loss: 0.176762, acc.: 98.44%] [G loss: 1.295421]\n",
      "epoch:17 step:16694 [D loss: 0.795963, acc.: 50.00%] [G loss: 1.196842]\n",
      "epoch:17 step:16695 [D loss: 0.717493, acc.: 59.38%] [G loss: 1.006436]\n",
      "epoch:17 step:16696 [D loss: 0.740364, acc.: 51.56%] [G loss: 1.356450]\n",
      "epoch:17 step:16697 [D loss: 0.589633, acc.: 75.00%] [G loss: 0.996454]\n",
      "epoch:17 step:16698 [D loss: 0.534456, acc.: 80.47%] [G loss: 1.189499]\n",
      "epoch:17 step:16699 [D loss: 0.799737, acc.: 50.00%] [G loss: 1.038998]\n",
      "epoch:17 step:16700 [D loss: 0.642841, acc.: 63.28%] [G loss: 0.874940]\n",
      "epoch:17 step:16701 [D loss: 0.754577, acc.: 52.34%] [G loss: 1.026162]\n",
      "epoch:17 step:16702 [D loss: 0.604846, acc.: 65.62%] [G loss: 0.814189]\n",
      "epoch:17 step:16703 [D loss: 1.292327, acc.: 42.97%] [G loss: 1.101156]\n",
      "epoch:17 step:16704 [D loss: 0.490573, acc.: 81.25%] [G loss: 1.004803]\n",
      "epoch:17 step:16705 [D loss: 0.734322, acc.: 54.69%] [G loss: 1.128852]\n",
      "epoch:17 step:16706 [D loss: 0.678638, acc.: 57.81%] [G loss: 0.815804]\n",
      "epoch:17 step:16707 [D loss: 0.823582, acc.: 40.62%] [G loss: 0.883772]\n",
      "epoch:17 step:16708 [D loss: 0.699462, acc.: 55.47%] [G loss: 1.054515]\n",
      "epoch:17 step:16709 [D loss: 0.274048, acc.: 95.31%] [G loss: 1.094862]\n",
      "epoch:17 step:16710 [D loss: 0.346936, acc.: 78.91%] [G loss: 0.985589]\n",
      "epoch:17 step:16711 [D loss: 0.256690, acc.: 95.31%] [G loss: 0.692758]\n",
      "epoch:17 step:16712 [D loss: 0.321206, acc.: 97.66%] [G loss: 0.995378]\n",
      "epoch:17 step:16713 [D loss: 0.448176, acc.: 88.28%] [G loss: 1.242823]\n",
      "epoch:17 step:16714 [D loss: 0.623958, acc.: 64.84%] [G loss: 0.994046]\n",
      "epoch:17 step:16715 [D loss: 0.427417, acc.: 72.66%] [G loss: 1.033829]\n",
      "epoch:17 step:16716 [D loss: 0.796347, acc.: 50.78%] [G loss: 1.055794]\n",
      "epoch:17 step:16717 [D loss: 0.485912, acc.: 80.47%] [G loss: 1.208489]\n",
      "epoch:17 step:16718 [D loss: 0.788703, acc.: 52.34%] [G loss: 1.072583]\n",
      "epoch:17 step:16719 [D loss: 0.672803, acc.: 55.47%] [G loss: 1.171152]\n",
      "epoch:17 step:16720 [D loss: 0.252196, acc.: 96.09%] [G loss: 1.173722]\n",
      "epoch:17 step:16721 [D loss: 0.188463, acc.: 100.00%] [G loss: 1.233096]\n",
      "epoch:17 step:16722 [D loss: 0.245780, acc.: 95.31%] [G loss: 1.290980]\n",
      "epoch:17 step:16723 [D loss: 0.180500, acc.: 98.44%] [G loss: 1.472313]\n",
      "epoch:17 step:16724 [D loss: 0.217396, acc.: 99.22%] [G loss: 1.384522]\n",
      "epoch:17 step:16725 [D loss: 0.174991, acc.: 100.00%] [G loss: 1.284635]\n",
      "epoch:17 step:16726 [D loss: 0.683368, acc.: 55.47%] [G loss: 1.218460]\n",
      "epoch:17 step:16727 [D loss: 0.646296, acc.: 60.94%] [G loss: 0.779366]\n",
      "epoch:17 step:16728 [D loss: 0.647787, acc.: 61.72%] [G loss: 1.056057]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16729 [D loss: 0.616876, acc.: 67.19%] [G loss: 1.316904]\n",
      "epoch:17 step:16730 [D loss: 0.659890, acc.: 60.94%] [G loss: 0.407527]\n",
      "epoch:17 step:16731 [D loss: 0.375403, acc.: 88.28%] [G loss: 1.200835]\n",
      "epoch:17 step:16732 [D loss: 0.775946, acc.: 45.31%] [G loss: 1.073842]\n",
      "epoch:17 step:16733 [D loss: 0.248729, acc.: 95.31%] [G loss: 1.150119]\n",
      "epoch:17 step:16734 [D loss: 0.207784, acc.: 96.88%] [G loss: 1.287660]\n",
      "epoch:17 step:16735 [D loss: 0.223955, acc.: 95.31%] [G loss: 1.293407]\n",
      "epoch:17 step:16736 [D loss: 1.096687, acc.: 23.44%] [G loss: 0.677611]\n",
      "epoch:17 step:16737 [D loss: 0.848588, acc.: 41.41%] [G loss: 1.108677]\n",
      "epoch:17 step:16738 [D loss: 0.718353, acc.: 57.81%] [G loss: 1.565966]\n",
      "epoch:17 step:16739 [D loss: 0.718575, acc.: 53.12%] [G loss: 1.154350]\n",
      "epoch:17 step:16740 [D loss: 0.771186, acc.: 41.41%] [G loss: 1.149088]\n",
      "epoch:17 step:16741 [D loss: 0.292015, acc.: 95.31%] [G loss: 1.196500]\n",
      "epoch:17 step:16742 [D loss: 0.650764, acc.: 60.16%] [G loss: 1.118037]\n",
      "epoch:17 step:16743 [D loss: 0.759381, acc.: 48.44%] [G loss: 1.041434]\n",
      "epoch:17 step:16744 [D loss: 0.662321, acc.: 54.69%] [G loss: 1.170208]\n",
      "epoch:17 step:16745 [D loss: 0.902694, acc.: 24.22%] [G loss: 1.157834]\n",
      "epoch:17 step:16746 [D loss: 0.452476, acc.: 85.94%] [G loss: 1.190028]\n",
      "epoch:17 step:16747 [D loss: 0.710031, acc.: 52.34%] [G loss: 1.136041]\n",
      "epoch:17 step:16748 [D loss: 0.632283, acc.: 64.06%] [G loss: 1.014301]\n",
      "epoch:17 step:16749 [D loss: 0.717285, acc.: 47.66%] [G loss: 1.014826]\n",
      "epoch:17 step:16750 [D loss: 0.504634, acc.: 57.81%] [G loss: 1.155927]\n",
      "epoch:17 step:16751 [D loss: 0.257992, acc.: 97.66%] [G loss: 1.166464]\n",
      "epoch:17 step:16752 [D loss: 0.630700, acc.: 59.38%] [G loss: 1.187422]\n",
      "epoch:17 step:16753 [D loss: 0.737747, acc.: 47.66%] [G loss: 1.159068]\n",
      "epoch:17 step:16754 [D loss: 0.655677, acc.: 56.25%] [G loss: 1.089704]\n",
      "epoch:17 step:16755 [D loss: 1.341436, acc.: 19.53%] [G loss: 1.072174]\n",
      "epoch:17 step:16756 [D loss: 0.614101, acc.: 67.19%] [G loss: 1.095786]\n",
      "epoch:17 step:16757 [D loss: 0.664262, acc.: 57.81%] [G loss: 1.060886]\n",
      "epoch:17 step:16758 [D loss: 0.720137, acc.: 54.69%] [G loss: 1.009132]\n",
      "epoch:17 step:16759 [D loss: 0.632367, acc.: 61.72%] [G loss: 0.985275]\n",
      "epoch:17 step:16760 [D loss: 0.614170, acc.: 67.97%] [G loss: 0.994949]\n",
      "epoch:17 step:16761 [D loss: 0.531787, acc.: 81.25%] [G loss: 0.655475]\n",
      "epoch:17 step:16762 [D loss: 0.571010, acc.: 71.88%] [G loss: 1.081534]\n",
      "epoch:17 step:16763 [D loss: 0.347573, acc.: 88.28%] [G loss: 1.019467]\n",
      "epoch:17 step:16764 [D loss: 0.636689, acc.: 63.28%] [G loss: 1.051050]\n",
      "epoch:17 step:16765 [D loss: 0.745743, acc.: 47.66%] [G loss: 0.871640]\n",
      "epoch:17 step:16766 [D loss: 0.868675, acc.: 32.03%] [G loss: 0.908047]\n",
      "epoch:17 step:16767 [D loss: 0.659044, acc.: 57.03%] [G loss: 0.809082]\n",
      "epoch:17 step:16768 [D loss: 0.649372, acc.: 61.72%] [G loss: 0.762463]\n",
      "epoch:17 step:16769 [D loss: 0.580258, acc.: 73.44%] [G loss: 0.958319]\n",
      "epoch:17 step:16770 [D loss: 0.294838, acc.: 96.88%] [G loss: 0.949918]\n",
      "epoch:17 step:16771 [D loss: 0.449710, acc.: 92.97%] [G loss: 1.011729]\n",
      "epoch:17 step:16772 [D loss: 0.598682, acc.: 66.41%] [G loss: 1.013741]\n",
      "epoch:17 step:16773 [D loss: 0.743105, acc.: 50.78%] [G loss: 0.980939]\n",
      "epoch:17 step:16774 [D loss: 0.267119, acc.: 97.66%] [G loss: 1.180897]\n",
      "epoch:17 step:16775 [D loss: 0.777620, acc.: 41.41%] [G loss: 1.090829]\n",
      "epoch:17 step:16776 [D loss: 0.569035, acc.: 72.66%] [G loss: 1.067068]\n",
      "epoch:17 step:16777 [D loss: 0.424123, acc.: 95.31%] [G loss: 0.707940]\n",
      "epoch:17 step:16778 [D loss: 0.992202, acc.: 31.25%] [G loss: 1.156704]\n",
      "epoch:17 step:16779 [D loss: 0.486020, acc.: 83.59%] [G loss: 1.105296]\n",
      "epoch:17 step:16780 [D loss: 0.211025, acc.: 100.00%] [G loss: 1.285399]\n",
      "epoch:17 step:16781 [D loss: 0.255899, acc.: 97.66%] [G loss: 1.165395]\n",
      "epoch:17 step:16782 [D loss: 0.205450, acc.: 99.22%] [G loss: 0.286963]\n",
      "epoch:17 step:16783 [D loss: 0.239072, acc.: 96.09%] [G loss: 1.232520]\n",
      "epoch:17 step:16784 [D loss: 0.534644, acc.: 81.25%] [G loss: 1.204545]\n",
      "epoch:17 step:16785 [D loss: 0.807539, acc.: 46.88%] [G loss: 0.639343]\n",
      "epoch:17 step:16786 [D loss: 0.401659, acc.: 82.81%] [G loss: 1.097109]\n",
      "epoch:17 step:16787 [D loss: 1.315241, acc.: 37.50%] [G loss: 1.184517]\n",
      "epoch:17 step:16788 [D loss: 0.325521, acc.: 94.53%] [G loss: 1.564874]\n",
      "epoch:17 step:16789 [D loss: 0.391430, acc.: 85.94%] [G loss: 1.185541]\n",
      "epoch:17 step:16790 [D loss: 0.871303, acc.: 53.91%] [G loss: 1.687782]\n",
      "epoch:17 step:16791 [D loss: 0.800180, acc.: 49.22%] [G loss: 1.482242]\n",
      "epoch:17 step:16792 [D loss: 0.824781, acc.: 50.78%] [G loss: 1.560610]\n",
      "epoch:17 step:16793 [D loss: 0.693656, acc.: 55.47%] [G loss: 1.440778]\n",
      "epoch:17 step:16794 [D loss: 0.823493, acc.: 56.25%] [G loss: 1.311887]\n",
      "epoch:17 step:16795 [D loss: 0.710342, acc.: 53.91%] [G loss: 1.163865]\n",
      "epoch:17 step:16796 [D loss: 0.705183, acc.: 56.25%] [G loss: 1.004056]\n",
      "epoch:17 step:16797 [D loss: 0.399515, acc.: 87.50%] [G loss: 0.970986]\n",
      "epoch:17 step:16798 [D loss: 0.640392, acc.: 62.50%] [G loss: 0.663430]\n",
      "epoch:17 step:16799 [D loss: 0.347730, acc.: 89.84%] [G loss: 0.970868]\n",
      "epoch:17 step:16800 [D loss: 0.529167, acc.: 80.47%] [G loss: 0.953445]\n",
      "##############\n",
      "[3.83684575 2.45285866 6.43918299 5.93741233 4.34079815 6.30802338\n",
      " 5.57723378 5.17625426 5.59812618 4.77829943]\n",
      "##########\n",
      "epoch:17 step:16801 [D loss: 0.911810, acc.: 25.78%] [G loss: 0.557696]\n",
      "epoch:17 step:16802 [D loss: 0.704010, acc.: 54.69%] [G loss: 1.082871]\n",
      "epoch:17 step:16803 [D loss: 0.783844, acc.: 51.56%] [G loss: 1.082141]\n",
      "epoch:17 step:16804 [D loss: 0.700930, acc.: 45.31%] [G loss: 1.085587]\n",
      "epoch:17 step:16805 [D loss: 0.472474, acc.: 82.03%] [G loss: 0.909450]\n",
      "epoch:17 step:16806 [D loss: 0.377448, acc.: 80.47%] [G loss: 1.009548]\n",
      "epoch:17 step:16807 [D loss: 0.354092, acc.: 78.91%] [G loss: 1.392342]\n",
      "epoch:17 step:16808 [D loss: 0.733275, acc.: 50.78%] [G loss: 1.331701]\n",
      "epoch:17 step:16809 [D loss: 1.095477, acc.: 23.44%] [G loss: 0.929231]\n",
      "epoch:17 step:16810 [D loss: 0.922715, acc.: 39.84%] [G loss: 1.066692]\n",
      "epoch:17 step:16811 [D loss: 1.114669, acc.: 17.97%] [G loss: 0.993840]\n",
      "epoch:17 step:16812 [D loss: 0.818829, acc.: 49.22%] [G loss: 0.997245]\n",
      "epoch:17 step:16813 [D loss: 0.760266, acc.: 48.44%] [G loss: 0.927648]\n",
      "epoch:17 step:16814 [D loss: 0.611896, acc.: 63.28%] [G loss: 0.882236]\n",
      "epoch:17 step:16815 [D loss: 0.539524, acc.: 74.22%] [G loss: 1.022625]\n",
      "epoch:17 step:16816 [D loss: 0.329968, acc.: 94.53%] [G loss: 1.157654]\n",
      "epoch:17 step:16817 [D loss: 0.765445, acc.: 43.75%] [G loss: 1.133622]\n",
      "epoch:17 step:16818 [D loss: 0.325243, acc.: 91.41%] [G loss: 1.254616]\n",
      "epoch:17 step:16819 [D loss: 0.459524, acc.: 84.38%] [G loss: 1.179999]\n",
      "epoch:17 step:16820 [D loss: 0.693178, acc.: 52.34%] [G loss: 1.132473]\n",
      "epoch:17 step:16821 [D loss: 0.725468, acc.: 55.47%] [G loss: 1.120223]\n",
      "epoch:17 step:16822 [D loss: 0.720038, acc.: 49.22%] [G loss: 1.020285]\n",
      "epoch:17 step:16823 [D loss: 0.700515, acc.: 51.56%] [G loss: 0.997734]\n",
      "epoch:17 step:16824 [D loss: 0.671031, acc.: 59.38%] [G loss: 1.174794]\n",
      "epoch:17 step:16825 [D loss: 0.674085, acc.: 64.06%] [G loss: 0.829697]\n",
      "epoch:17 step:16826 [D loss: 0.686532, acc.: 58.59%] [G loss: 0.814082]\n",
      "epoch:17 step:16827 [D loss: 0.580423, acc.: 75.78%] [G loss: 0.841065]\n",
      "epoch:17 step:16828 [D loss: 0.462184, acc.: 82.81%] [G loss: 0.859705]\n",
      "epoch:17 step:16829 [D loss: 0.528781, acc.: 66.41%] [G loss: 1.011225]\n",
      "epoch:17 step:16830 [D loss: 0.661884, acc.: 57.81%] [G loss: 0.913837]\n",
      "epoch:17 step:16831 [D loss: 0.677217, acc.: 57.81%] [G loss: 0.896122]\n",
      "epoch:17 step:16832 [D loss: 0.691564, acc.: 53.12%] [G loss: 0.920005]\n",
      "epoch:17 step:16833 [D loss: 0.518049, acc.: 69.53%] [G loss: 0.880457]\n",
      "epoch:17 step:16834 [D loss: 0.432141, acc.: 74.22%] [G loss: 0.931221]\n",
      "epoch:17 step:16835 [D loss: 0.310932, acc.: 92.97%] [G loss: 1.007601]\n",
      "epoch:17 step:16836 [D loss: 0.580086, acc.: 75.78%] [G loss: 1.035827]\n",
      "epoch:17 step:16837 [D loss: 0.659162, acc.: 60.16%] [G loss: 1.021546]\n",
      "epoch:17 step:16838 [D loss: 0.713289, acc.: 52.34%] [G loss: 0.945553]\n",
      "epoch:17 step:16839 [D loss: 0.366269, acc.: 90.62%] [G loss: 1.210445]\n",
      "epoch:17 step:16840 [D loss: 0.676169, acc.: 67.19%] [G loss: 0.958584]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16841 [D loss: 0.269882, acc.: 91.41%] [G loss: 0.977793]\n",
      "epoch:17 step:16842 [D loss: 0.821846, acc.: 34.38%] [G loss: 1.016264]\n",
      "epoch:17 step:16843 [D loss: 0.586092, acc.: 72.66%] [G loss: 1.050996]\n",
      "epoch:17 step:16844 [D loss: 0.625037, acc.: 63.28%] [G loss: 0.978745]\n",
      "epoch:17 step:16845 [D loss: 0.362601, acc.: 93.75%] [G loss: 1.116855]\n",
      "epoch:17 step:16846 [D loss: 0.342144, acc.: 81.25%] [G loss: 1.056804]\n",
      "epoch:17 step:16847 [D loss: 0.584062, acc.: 72.66%] [G loss: 1.278871]\n",
      "epoch:17 step:16848 [D loss: 0.693453, acc.: 58.59%] [G loss: 1.075180]\n",
      "epoch:17 step:16849 [D loss: 0.214707, acc.: 95.31%] [G loss: 1.174829]\n",
      "epoch:17 step:16850 [D loss: 0.225338, acc.: 98.44%] [G loss: 0.736149]\n",
      "epoch:17 step:16851 [D loss: 0.514915, acc.: 85.16%] [G loss: 1.150982]\n",
      "epoch:17 step:16852 [D loss: 0.651692, acc.: 61.72%] [G loss: 0.946276]\n",
      "epoch:17 step:16853 [D loss: 0.622737, acc.: 60.94%] [G loss: 1.005470]\n",
      "epoch:17 step:16854 [D loss: 0.649307, acc.: 67.97%] [G loss: 0.872659]\n",
      "epoch:17 step:16855 [D loss: 0.518213, acc.: 81.25%] [G loss: 0.977616]\n",
      "epoch:17 step:16856 [D loss: 0.515277, acc.: 69.53%] [G loss: 0.877063]\n",
      "epoch:17 step:16857 [D loss: 0.614184, acc.: 64.06%] [G loss: 1.061496]\n",
      "epoch:17 step:16858 [D loss: 0.235490, acc.: 94.53%] [G loss: 1.065960]\n",
      "epoch:17 step:16859 [D loss: 0.288352, acc.: 95.31%] [G loss: 1.108813]\n",
      "epoch:17 step:16860 [D loss: 0.423890, acc.: 89.84%] [G loss: 1.087331]\n",
      "epoch:17 step:16861 [D loss: 0.721369, acc.: 56.25%] [G loss: 1.021580]\n",
      "epoch:17 step:16862 [D loss: 0.645350, acc.: 60.94%] [G loss: 0.848367]\n",
      "epoch:17 step:16863 [D loss: 0.652747, acc.: 64.06%] [G loss: 1.265410]\n",
      "epoch:17 step:16864 [D loss: 0.556726, acc.: 76.56%] [G loss: 1.174490]\n",
      "epoch:17 step:16865 [D loss: 0.335157, acc.: 91.41%] [G loss: 1.239220]\n",
      "epoch:17 step:16866 [D loss: 0.243391, acc.: 89.84%] [G loss: 1.300391]\n",
      "epoch:18 step:16867 [D loss: 0.601445, acc.: 71.09%] [G loss: 1.334342]\n",
      "epoch:18 step:16868 [D loss: 0.658767, acc.: 60.94%] [G loss: 1.080912]\n",
      "epoch:18 step:16869 [D loss: 0.741577, acc.: 57.81%] [G loss: 1.297105]\n",
      "epoch:18 step:16870 [D loss: 0.711527, acc.: 53.91%] [G loss: 0.894798]\n",
      "epoch:18 step:16871 [D loss: 0.700596, acc.: 57.03%] [G loss: 0.996544]\n",
      "epoch:18 step:16872 [D loss: 0.947577, acc.: 33.59%] [G loss: 1.131118]\n",
      "epoch:18 step:16873 [D loss: 0.683845, acc.: 53.91%] [G loss: 0.923190]\n",
      "epoch:18 step:16874 [D loss: 0.624424, acc.: 68.75%] [G loss: 1.150170]\n",
      "epoch:18 step:16875 [D loss: 0.496228, acc.: 81.25%] [G loss: 0.874228]\n",
      "epoch:18 step:16876 [D loss: 0.439306, acc.: 79.69%] [G loss: 1.034129]\n",
      "epoch:18 step:16877 [D loss: 0.490560, acc.: 85.16%] [G loss: 1.186304]\n",
      "epoch:18 step:16878 [D loss: 0.328483, acc.: 94.53%] [G loss: 1.080101]\n",
      "epoch:18 step:16879 [D loss: 0.650154, acc.: 57.03%] [G loss: 0.791085]\n",
      "epoch:18 step:16880 [D loss: 0.688512, acc.: 57.81%] [G loss: 0.544353]\n",
      "epoch:18 step:16881 [D loss: 0.412983, acc.: 82.03%] [G loss: 1.053105]\n",
      "epoch:18 step:16882 [D loss: 0.813878, acc.: 47.66%] [G loss: 1.079820]\n",
      "epoch:18 step:16883 [D loss: 0.845748, acc.: 25.78%] [G loss: 1.236586]\n",
      "epoch:18 step:16884 [D loss: 0.720869, acc.: 53.91%] [G loss: 1.387660]\n",
      "epoch:18 step:16885 [D loss: 1.729861, acc.: 1.56%] [G loss: 1.199758]\n",
      "epoch:18 step:16886 [D loss: 0.773684, acc.: 52.34%] [G loss: 1.056459]\n",
      "epoch:18 step:16887 [D loss: 0.792254, acc.: 45.31%] [G loss: 1.249009]\n",
      "epoch:18 step:16888 [D loss: 0.711738, acc.: 55.47%] [G loss: 1.247993]\n",
      "epoch:18 step:16889 [D loss: 0.772662, acc.: 46.09%] [G loss: 1.198827]\n",
      "epoch:18 step:16890 [D loss: 0.737788, acc.: 48.44%] [G loss: 1.064970]\n",
      "epoch:18 step:16891 [D loss: 0.725578, acc.: 53.91%] [G loss: 0.960471]\n",
      "epoch:18 step:16892 [D loss: 0.714426, acc.: 47.66%] [G loss: 1.089949]\n",
      "epoch:18 step:16893 [D loss: 0.291712, acc.: 94.53%] [G loss: 1.099651]\n",
      "epoch:18 step:16894 [D loss: 0.535023, acc.: 72.66%] [G loss: 1.061022]\n",
      "epoch:18 step:16895 [D loss: 0.625283, acc.: 64.06%] [G loss: 1.656284]\n",
      "epoch:18 step:16896 [D loss: 0.623848, acc.: 56.25%] [G loss: 1.032776]\n",
      "epoch:18 step:16897 [D loss: 0.333941, acc.: 98.44%] [G loss: 1.218711]\n",
      "epoch:18 step:16898 [D loss: 0.318557, acc.: 96.88%] [G loss: 1.183249]\n",
      "epoch:18 step:16899 [D loss: 0.323141, acc.: 98.44%] [G loss: 1.233190]\n",
      "epoch:18 step:16900 [D loss: 0.288491, acc.: 97.66%] [G loss: 1.321790]\n",
      "epoch:18 step:16901 [D loss: 0.237092, acc.: 100.00%] [G loss: 1.387836]\n",
      "epoch:18 step:16902 [D loss: 0.174930, acc.: 99.22%] [G loss: 1.789460]\n",
      "epoch:18 step:16903 [D loss: 0.843937, acc.: 46.09%] [G loss: 1.126965]\n",
      "epoch:18 step:16904 [D loss: 0.877370, acc.: 47.66%] [G loss: 1.302426]\n",
      "epoch:18 step:16905 [D loss: 0.928132, acc.: 45.31%] [G loss: 0.951422]\n",
      "epoch:18 step:16906 [D loss: 0.704790, acc.: 58.59%] [G loss: 0.911812]\n",
      "epoch:18 step:16907 [D loss: 0.636769, acc.: 67.97%] [G loss: 0.874869]\n",
      "epoch:18 step:16908 [D loss: 0.586620, acc.: 74.22%] [G loss: 0.929849]\n",
      "epoch:18 step:16909 [D loss: 0.504611, acc.: 83.59%] [G loss: 1.041902]\n",
      "epoch:18 step:16910 [D loss: 0.610902, acc.: 71.88%] [G loss: 0.834099]\n",
      "epoch:18 step:16911 [D loss: 0.663192, acc.: 60.16%] [G loss: 0.821909]\n",
      "epoch:18 step:16912 [D loss: 0.556666, acc.: 73.44%] [G loss: 0.922638]\n",
      "epoch:18 step:16913 [D loss: 0.754031, acc.: 44.53%] [G loss: 0.852791]\n",
      "epoch:18 step:16914 [D loss: 0.913013, acc.: 25.78%] [G loss: 0.859322]\n",
      "epoch:18 step:16915 [D loss: 0.733650, acc.: 43.75%] [G loss: 0.918546]\n",
      "epoch:18 step:16916 [D loss: 0.638349, acc.: 64.06%] [G loss: 0.613133]\n",
      "epoch:18 step:16917 [D loss: 0.631517, acc.: 60.94%] [G loss: 0.376910]\n",
      "epoch:18 step:16918 [D loss: 0.569888, acc.: 75.78%] [G loss: 0.486704]\n",
      "epoch:18 step:16919 [D loss: 1.087647, acc.: 28.12%] [G loss: 0.694610]\n",
      "epoch:18 step:16920 [D loss: 0.706529, acc.: 50.78%] [G loss: 0.947493]\n",
      "epoch:18 step:16921 [D loss: 0.786190, acc.: 35.94%] [G loss: 0.988548]\n",
      "epoch:18 step:16922 [D loss: 0.654549, acc.: 60.94%] [G loss: 0.824647]\n",
      "epoch:18 step:16923 [D loss: 0.501840, acc.: 81.25%] [G loss: 1.114277]\n",
      "epoch:18 step:16924 [D loss: 0.673609, acc.: 60.94%] [G loss: 0.921105]\n",
      "epoch:18 step:16925 [D loss: 0.681646, acc.: 51.56%] [G loss: 0.915265]\n",
      "epoch:18 step:16926 [D loss: 0.553589, acc.: 78.12%] [G loss: 1.042647]\n",
      "epoch:18 step:16927 [D loss: 1.433586, acc.: 12.50%] [G loss: 0.670917]\n",
      "epoch:18 step:16928 [D loss: 0.723010, acc.: 46.09%] [G loss: 0.813971]\n",
      "epoch:18 step:16929 [D loss: 1.020817, acc.: 20.31%] [G loss: 1.182426]\n",
      "epoch:18 step:16930 [D loss: 0.665972, acc.: 58.59%] [G loss: 1.275088]\n",
      "epoch:18 step:16931 [D loss: 0.678973, acc.: 50.00%] [G loss: 1.309222]\n",
      "epoch:18 step:16932 [D loss: 0.675058, acc.: 51.56%] [G loss: 1.097399]\n",
      "epoch:18 step:16933 [D loss: 0.625377, acc.: 55.47%] [G loss: 1.097172]\n",
      "epoch:18 step:16934 [D loss: 0.571634, acc.: 77.34%] [G loss: 1.141582]\n",
      "epoch:18 step:16935 [D loss: 0.567572, acc.: 68.75%] [G loss: 1.214003]\n",
      "epoch:18 step:16936 [D loss: 0.614508, acc.: 64.06%] [G loss: 1.084803]\n",
      "epoch:18 step:16937 [D loss: 0.708549, acc.: 64.84%] [G loss: 1.137674]\n",
      "epoch:18 step:16938 [D loss: 0.726436, acc.: 52.34%] [G loss: 1.024671]\n",
      "epoch:18 step:16939 [D loss: 0.643295, acc.: 57.03%] [G loss: 1.021379]\n",
      "epoch:18 step:16940 [D loss: 0.731711, acc.: 45.31%] [G loss: 1.077865]\n",
      "epoch:18 step:16941 [D loss: 0.564765, acc.: 72.66%] [G loss: 0.880059]\n",
      "epoch:18 step:16942 [D loss: 0.684105, acc.: 62.50%] [G loss: 0.830836]\n",
      "epoch:18 step:16943 [D loss: 0.623810, acc.: 69.53%] [G loss: 0.892403]\n",
      "epoch:18 step:16944 [D loss: 0.753845, acc.: 50.00%] [G loss: 0.888889]\n",
      "epoch:18 step:16945 [D loss: 0.824744, acc.: 37.50%] [G loss: 0.793687]\n",
      "epoch:18 step:16946 [D loss: 0.621849, acc.: 67.19%] [G loss: 0.947803]\n",
      "epoch:18 step:16947 [D loss: 0.582786, acc.: 80.47%] [G loss: 0.884301]\n",
      "epoch:18 step:16948 [D loss: 0.462523, acc.: 89.06%] [G loss: 1.128778]\n",
      "epoch:18 step:16949 [D loss: 0.499640, acc.: 86.72%] [G loss: 0.995266]\n",
      "epoch:18 step:16950 [D loss: 0.567199, acc.: 75.00%] [G loss: 1.011423]\n",
      "epoch:18 step:16951 [D loss: 0.527355, acc.: 82.03%] [G loss: 0.973393]\n",
      "epoch:18 step:16952 [D loss: 0.583013, acc.: 76.56%] [G loss: 1.109197]\n",
      "epoch:18 step:16953 [D loss: 0.552967, acc.: 77.34%] [G loss: 1.265439]\n",
      "epoch:18 step:16954 [D loss: 0.463630, acc.: 92.19%] [G loss: 1.117621]\n",
      "epoch:18 step:16955 [D loss: 0.466565, acc.: 89.06%] [G loss: 1.208262]\n",
      "epoch:18 step:16956 [D loss: 0.485872, acc.: 78.12%] [G loss: 1.312334]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:16957 [D loss: 0.548527, acc.: 77.34%] [G loss: 1.191920]\n",
      "epoch:18 step:16958 [D loss: 0.475968, acc.: 84.38%] [G loss: 1.237691]\n",
      "epoch:18 step:16959 [D loss: 0.393900, acc.: 89.84%] [G loss: 1.156697]\n",
      "epoch:18 step:16960 [D loss: 0.427718, acc.: 87.50%] [G loss: 1.113714]\n",
      "epoch:18 step:16961 [D loss: 0.578377, acc.: 71.09%] [G loss: 1.109429]\n",
      "epoch:18 step:16962 [D loss: 0.467698, acc.: 83.59%] [G loss: 1.092446]\n",
      "epoch:18 step:16963 [D loss: 0.665677, acc.: 64.06%] [G loss: 1.114114]\n",
      "epoch:18 step:16964 [D loss: 0.829037, acc.: 54.69%] [G loss: 1.229966]\n",
      "epoch:18 step:16965 [D loss: 0.713587, acc.: 57.03%] [G loss: 0.804476]\n",
      "epoch:18 step:16966 [D loss: 0.732329, acc.: 51.56%] [G loss: 0.834275]\n",
      "epoch:18 step:16967 [D loss: 0.737402, acc.: 50.00%] [G loss: 0.918096]\n",
      "epoch:18 step:16968 [D loss: 0.653831, acc.: 60.94%] [G loss: 0.854025]\n",
      "epoch:18 step:16969 [D loss: 0.601190, acc.: 71.09%] [G loss: 0.775209]\n",
      "epoch:18 step:16970 [D loss: 0.689402, acc.: 50.78%] [G loss: 0.817671]\n",
      "epoch:18 step:16971 [D loss: 0.873860, acc.: 33.59%] [G loss: 0.785924]\n",
      "epoch:18 step:16972 [D loss: 0.695877, acc.: 55.47%] [G loss: 0.851652]\n",
      "epoch:18 step:16973 [D loss: 0.647024, acc.: 60.16%] [G loss: 0.923059]\n",
      "epoch:18 step:16974 [D loss: 0.816078, acc.: 44.53%] [G loss: 0.921296]\n",
      "epoch:18 step:16975 [D loss: 0.661716, acc.: 60.16%] [G loss: 0.975385]\n",
      "epoch:18 step:16976 [D loss: 0.724444, acc.: 47.66%] [G loss: 0.656094]\n",
      "epoch:18 step:16977 [D loss: 0.579012, acc.: 69.53%] [G loss: 0.897160]\n",
      "epoch:18 step:16978 [D loss: 0.631153, acc.: 64.84%] [G loss: 0.573669]\n",
      "epoch:18 step:16979 [D loss: 0.453015, acc.: 85.94%] [G loss: 0.907659]\n",
      "epoch:18 step:16980 [D loss: 0.484194, acc.: 77.34%] [G loss: 0.932026]\n",
      "epoch:18 step:16981 [D loss: 0.434661, acc.: 85.94%] [G loss: 0.920861]\n",
      "epoch:18 step:16982 [D loss: 0.680609, acc.: 53.12%] [G loss: 0.761367]\n",
      "epoch:18 step:16983 [D loss: 0.825542, acc.: 42.19%] [G loss: 0.888063]\n",
      "epoch:18 step:16984 [D loss: 0.956172, acc.: 29.69%] [G loss: 0.929838]\n",
      "epoch:18 step:16985 [D loss: 0.564727, acc.: 70.31%] [G loss: 1.084649]\n",
      "epoch:18 step:16986 [D loss: 0.706964, acc.: 62.50%] [G loss: 0.913677]\n",
      "epoch:18 step:16987 [D loss: 0.428822, acc.: 84.38%] [G loss: 0.989227]\n",
      "epoch:18 step:16988 [D loss: 0.501974, acc.: 78.12%] [G loss: 1.218431]\n",
      "epoch:18 step:16989 [D loss: 0.797960, acc.: 42.19%] [G loss: 0.514209]\n",
      "epoch:18 step:16990 [D loss: 0.760143, acc.: 44.53%] [G loss: 1.001686]\n",
      "epoch:18 step:16991 [D loss: 0.777563, acc.: 46.09%] [G loss: 0.881068]\n",
      "epoch:18 step:16992 [D loss: 0.717737, acc.: 54.69%] [G loss: 1.049834]\n",
      "epoch:18 step:16993 [D loss: 0.712116, acc.: 52.34%] [G loss: 1.049278]\n",
      "epoch:18 step:16994 [D loss: 0.761517, acc.: 53.91%] [G loss: 0.982147]\n",
      "epoch:18 step:16995 [D loss: 0.655061, acc.: 65.62%] [G loss: 0.659877]\n",
      "epoch:18 step:16996 [D loss: 0.631706, acc.: 64.06%] [G loss: 0.981733]\n",
      "epoch:18 step:16997 [D loss: 0.528447, acc.: 82.03%] [G loss: 0.746433]\n",
      "epoch:18 step:16998 [D loss: 0.909172, acc.: 34.38%] [G loss: 0.927046]\n",
      "epoch:18 step:16999 [D loss: 0.581923, acc.: 75.78%] [G loss: 1.051657]\n",
      "epoch:18 step:17000 [D loss: 0.563830, acc.: 67.19%] [G loss: 0.951684]\n",
      "##############\n",
      "[3.24354842 2.4478494  6.61807939 5.22764527 4.5902029  5.89799591\n",
      " 5.33500351 5.70932996 5.49292034 4.67939722]\n",
      "##########\n",
      "epoch:18 step:17001 [D loss: 0.534085, acc.: 76.56%] [G loss: 1.191911]\n",
      "epoch:18 step:17002 [D loss: 0.666448, acc.: 61.72%] [G loss: 1.080765]\n",
      "epoch:18 step:17003 [D loss: 0.872400, acc.: 46.09%] [G loss: 1.055147]\n",
      "epoch:18 step:17004 [D loss: 0.660748, acc.: 63.28%] [G loss: 1.156145]\n",
      "epoch:18 step:17005 [D loss: 0.778034, acc.: 49.22%] [G loss: 0.982122]\n",
      "epoch:18 step:17006 [D loss: 0.540135, acc.: 78.91%] [G loss: 0.757956]\n",
      "epoch:18 step:17007 [D loss: 0.467836, acc.: 85.94%] [G loss: 0.996864]\n",
      "epoch:18 step:17008 [D loss: 0.546125, acc.: 75.78%] [G loss: 1.047329]\n",
      "epoch:18 step:17009 [D loss: 0.454675, acc.: 80.47%] [G loss: 1.190321]\n",
      "epoch:18 step:17010 [D loss: 0.470492, acc.: 75.00%] [G loss: 1.403610]\n",
      "epoch:18 step:17011 [D loss: 0.268583, acc.: 93.75%] [G loss: 1.092176]\n",
      "epoch:18 step:17012 [D loss: 0.447001, acc.: 82.03%] [G loss: 1.276098]\n",
      "epoch:18 step:17013 [D loss: 0.661266, acc.: 62.50%] [G loss: 1.213550]\n",
      "epoch:18 step:17014 [D loss: 0.735766, acc.: 60.16%] [G loss: 1.218926]\n",
      "epoch:18 step:17015 [D loss: 0.432902, acc.: 86.72%] [G loss: 1.212505]\n",
      "epoch:18 step:17016 [D loss: 0.314667, acc.: 85.94%] [G loss: 0.923022]\n",
      "epoch:18 step:17017 [D loss: 0.292906, acc.: 89.06%] [G loss: 1.237554]\n",
      "epoch:18 step:17018 [D loss: 0.433430, acc.: 86.72%] [G loss: 1.468948]\n",
      "epoch:18 step:17019 [D loss: 0.740149, acc.: 55.47%] [G loss: 1.064494]\n",
      "epoch:18 step:17020 [D loss: 0.910157, acc.: 46.09%] [G loss: 1.468271]\n",
      "epoch:18 step:17021 [D loss: 0.501996, acc.: 79.69%] [G loss: 0.885955]\n",
      "epoch:18 step:17022 [D loss: 0.787981, acc.: 50.00%] [G loss: 1.179617]\n",
      "epoch:18 step:17023 [D loss: 0.654941, acc.: 63.28%] [G loss: 0.975120]\n",
      "epoch:18 step:17024 [D loss: 0.788401, acc.: 42.19%] [G loss: 0.971167]\n",
      "epoch:18 step:17025 [D loss: 0.778290, acc.: 42.19%] [G loss: 1.006109]\n",
      "epoch:18 step:17026 [D loss: 0.635333, acc.: 60.94%] [G loss: 0.582844]\n",
      "epoch:18 step:17027 [D loss: 0.702821, acc.: 53.91%] [G loss: 1.099690]\n",
      "epoch:18 step:17028 [D loss: 0.582927, acc.: 64.06%] [G loss: 0.901083]\n",
      "epoch:18 step:17029 [D loss: 0.594501, acc.: 67.19%] [G loss: 1.051738]\n",
      "epoch:18 step:17030 [D loss: 0.524114, acc.: 78.91%] [G loss: 0.917679]\n",
      "epoch:18 step:17031 [D loss: 0.567667, acc.: 70.31%] [G loss: 1.214782]\n",
      "epoch:18 step:17032 [D loss: 1.063174, acc.: 21.09%] [G loss: 0.987447]\n",
      "epoch:18 step:17033 [D loss: 0.749486, acc.: 48.44%] [G loss: 1.062286]\n",
      "epoch:18 step:17034 [D loss: 0.692626, acc.: 58.59%] [G loss: 1.068558]\n",
      "epoch:18 step:17035 [D loss: 0.661071, acc.: 57.81%] [G loss: 0.818890]\n",
      "epoch:18 step:17036 [D loss: 0.525898, acc.: 85.94%] [G loss: 0.629840]\n",
      "epoch:18 step:17037 [D loss: 0.687573, acc.: 49.22%] [G loss: 0.936661]\n",
      "epoch:18 step:17038 [D loss: 0.715235, acc.: 54.69%] [G loss: 0.694277]\n",
      "epoch:18 step:17039 [D loss: 0.778065, acc.: 39.06%] [G loss: 0.798334]\n",
      "epoch:18 step:17040 [D loss: 0.725936, acc.: 41.41%] [G loss: 0.577297]\n",
      "epoch:18 step:17041 [D loss: 0.638292, acc.: 68.75%] [G loss: 0.737390]\n",
      "epoch:18 step:17042 [D loss: 0.716527, acc.: 51.56%] [G loss: 0.891835]\n",
      "epoch:18 step:17043 [D loss: 0.935624, acc.: 32.03%] [G loss: 0.742705]\n",
      "epoch:18 step:17044 [D loss: 0.508359, acc.: 86.72%] [G loss: 0.785808]\n",
      "epoch:18 step:17045 [D loss: 0.609084, acc.: 74.22%] [G loss: 0.622196]\n",
      "epoch:18 step:17046 [D loss: 0.813341, acc.: 47.66%] [G loss: 0.917241]\n",
      "epoch:18 step:17047 [D loss: 0.852772, acc.: 34.38%] [G loss: 0.892944]\n",
      "epoch:18 step:17048 [D loss: 0.915219, acc.: 24.22%] [G loss: 0.934776]\n",
      "epoch:18 step:17049 [D loss: 0.694099, acc.: 49.22%] [G loss: 0.964332]\n",
      "epoch:18 step:17050 [D loss: 0.647881, acc.: 61.72%] [G loss: 1.023192]\n",
      "epoch:18 step:17051 [D loss: 0.571116, acc.: 68.75%] [G loss: 0.839183]\n",
      "epoch:18 step:17052 [D loss: 0.703693, acc.: 50.00%] [G loss: 0.826774]\n",
      "epoch:18 step:17053 [D loss: 0.714852, acc.: 50.78%] [G loss: 0.971878]\n",
      "epoch:18 step:17054 [D loss: 0.647588, acc.: 54.69%] [G loss: 0.974523]\n",
      "epoch:18 step:17055 [D loss: 0.664347, acc.: 55.47%] [G loss: 0.954094]\n",
      "epoch:18 step:17056 [D loss: 0.669553, acc.: 57.03%] [G loss: 0.968076]\n",
      "epoch:18 step:17057 [D loss: 0.624493, acc.: 58.59%] [G loss: 1.102744]\n",
      "epoch:18 step:17058 [D loss: 0.576953, acc.: 73.44%] [G loss: 0.952536]\n",
      "epoch:18 step:17059 [D loss: 0.584798, acc.: 70.31%] [G loss: 0.986203]\n",
      "epoch:18 step:17060 [D loss: 0.546496, acc.: 77.34%] [G loss: 0.936578]\n",
      "epoch:18 step:17061 [D loss: 0.551452, acc.: 74.22%] [G loss: 1.084378]\n",
      "epoch:18 step:17062 [D loss: 0.613274, acc.: 65.62%] [G loss: 0.857021]\n",
      "epoch:18 step:17063 [D loss: 0.581144, acc.: 72.66%] [G loss: 1.222094]\n",
      "epoch:18 step:17064 [D loss: 0.545290, acc.: 77.34%] [G loss: 0.931915]\n",
      "epoch:18 step:17065 [D loss: 0.667738, acc.: 56.25%] [G loss: 1.159850]\n",
      "epoch:18 step:17066 [D loss: 0.699551, acc.: 58.59%] [G loss: 1.075584]\n",
      "epoch:18 step:17067 [D loss: 0.496937, acc.: 85.16%] [G loss: 0.972467]\n",
      "epoch:18 step:17068 [D loss: 0.664020, acc.: 62.50%] [G loss: 1.037563]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17069 [D loss: 0.587881, acc.: 75.00%] [G loss: 0.979431]\n",
      "epoch:18 step:17070 [D loss: 0.505303, acc.: 83.59%] [G loss: 1.011893]\n",
      "epoch:18 step:17071 [D loss: 0.551051, acc.: 79.69%] [G loss: 1.059477]\n",
      "epoch:18 step:17072 [D loss: 0.460416, acc.: 84.38%] [G loss: 0.807446]\n",
      "epoch:18 step:17073 [D loss: 0.449671, acc.: 78.91%] [G loss: 1.272949]\n",
      "epoch:18 step:17074 [D loss: 0.427363, acc.: 89.06%] [G loss: 0.992398]\n",
      "epoch:18 step:17075 [D loss: 0.440349, acc.: 89.84%] [G loss: 1.166631]\n",
      "epoch:18 step:17076 [D loss: 0.834116, acc.: 50.00%] [G loss: 1.106044]\n",
      "epoch:18 step:17077 [D loss: 0.884032, acc.: 37.50%] [G loss: 1.009746]\n",
      "epoch:18 step:17078 [D loss: 0.732915, acc.: 42.97%] [G loss: 0.937973]\n",
      "epoch:18 step:17079 [D loss: 0.779986, acc.: 53.91%] [G loss: 0.821986]\n",
      "epoch:18 step:17080 [D loss: 0.613075, acc.: 70.31%] [G loss: 0.784839]\n",
      "epoch:18 step:17081 [D loss: 0.760402, acc.: 37.50%] [G loss: 0.896912]\n",
      "epoch:18 step:17082 [D loss: 0.604690, acc.: 64.84%] [G loss: 0.727171]\n",
      "epoch:18 step:17083 [D loss: 0.524880, acc.: 84.38%] [G loss: 0.867782]\n",
      "epoch:18 step:17084 [D loss: 0.494244, acc.: 71.88%] [G loss: 0.777360]\n",
      "epoch:18 step:17085 [D loss: 0.460227, acc.: 85.16%] [G loss: 0.892164]\n",
      "epoch:18 step:17086 [D loss: 0.426393, acc.: 84.38%] [G loss: 0.981691]\n",
      "epoch:18 step:17087 [D loss: 0.423388, acc.: 83.59%] [G loss: 1.004995]\n",
      "epoch:18 step:17088 [D loss: 0.445157, acc.: 82.81%] [G loss: 1.111128]\n",
      "epoch:18 step:17089 [D loss: 0.605133, acc.: 64.06%] [G loss: 1.070108]\n",
      "epoch:18 step:17090 [D loss: 0.653928, acc.: 61.72%] [G loss: 0.996377]\n",
      "epoch:18 step:17091 [D loss: 0.532511, acc.: 82.81%] [G loss: 0.971468]\n",
      "epoch:18 step:17092 [D loss: 0.668494, acc.: 57.03%] [G loss: 1.024600]\n",
      "epoch:18 step:17093 [D loss: 0.622932, acc.: 65.62%] [G loss: 0.986328]\n",
      "epoch:18 step:17094 [D loss: 0.681866, acc.: 61.72%] [G loss: 1.010895]\n",
      "epoch:18 step:17095 [D loss: 0.745731, acc.: 49.22%] [G loss: 0.927219]\n",
      "epoch:18 step:17096 [D loss: 0.309701, acc.: 85.94%] [G loss: 1.066202]\n",
      "epoch:18 step:17097 [D loss: 0.375772, acc.: 84.38%] [G loss: 1.078736]\n",
      "epoch:18 step:17098 [D loss: 0.283578, acc.: 90.62%] [G loss: 1.198037]\n",
      "epoch:18 step:17099 [D loss: 0.780554, acc.: 53.91%] [G loss: 1.138256]\n",
      "epoch:18 step:17100 [D loss: 0.493658, acc.: 83.59%] [G loss: 1.096601]\n",
      "epoch:18 step:17101 [D loss: 0.284919, acc.: 96.09%] [G loss: 1.173526]\n",
      "epoch:18 step:17102 [D loss: 0.641780, acc.: 61.72%] [G loss: 1.159051]\n",
      "epoch:18 step:17103 [D loss: 0.537127, acc.: 76.56%] [G loss: 1.182517]\n",
      "epoch:18 step:17104 [D loss: 0.384879, acc.: 83.59%] [G loss: 1.179161]\n",
      "epoch:18 step:17105 [D loss: 0.693470, acc.: 57.81%] [G loss: 1.039458]\n",
      "epoch:18 step:17106 [D loss: 0.711179, acc.: 56.25%] [G loss: 0.992612]\n",
      "epoch:18 step:17107 [D loss: 0.730276, acc.: 52.34%] [G loss: 0.855327]\n",
      "epoch:18 step:17108 [D loss: 0.756610, acc.: 48.44%] [G loss: 0.756995]\n",
      "epoch:18 step:17109 [D loss: 0.633109, acc.: 66.41%] [G loss: 0.859044]\n",
      "epoch:18 step:17110 [D loss: 0.730379, acc.: 53.91%] [G loss: 0.969246]\n",
      "epoch:18 step:17111 [D loss: 0.769212, acc.: 40.62%] [G loss: 0.882102]\n",
      "epoch:18 step:17112 [D loss: 0.673321, acc.: 53.91%] [G loss: 0.999276]\n",
      "epoch:18 step:17113 [D loss: 0.696034, acc.: 57.03%] [G loss: 0.832853]\n",
      "epoch:18 step:17114 [D loss: 0.713432, acc.: 46.88%] [G loss: 0.947844]\n",
      "epoch:18 step:17115 [D loss: 0.575656, acc.: 73.44%] [G loss: 0.874438]\n",
      "epoch:18 step:17116 [D loss: 0.795291, acc.: 48.44%] [G loss: 0.502756]\n",
      "epoch:18 step:17117 [D loss: 0.569644, acc.: 73.44%] [G loss: 0.946621]\n",
      "epoch:18 step:17118 [D loss: 0.668728, acc.: 57.03%] [G loss: 0.462069]\n",
      "epoch:18 step:17119 [D loss: 0.656129, acc.: 63.28%] [G loss: 0.655133]\n",
      "epoch:18 step:17120 [D loss: 0.598770, acc.: 64.84%] [G loss: 1.104532]\n",
      "epoch:18 step:17121 [D loss: 0.270809, acc.: 93.75%] [G loss: 1.152786]\n",
      "epoch:18 step:17122 [D loss: 0.288649, acc.: 87.50%] [G loss: 1.260845]\n",
      "epoch:18 step:17123 [D loss: 0.585611, acc.: 67.19%] [G loss: 1.153626]\n",
      "epoch:18 step:17124 [D loss: 0.766164, acc.: 49.22%] [G loss: 0.507135]\n",
      "epoch:18 step:17125 [D loss: 0.239247, acc.: 99.22%] [G loss: 1.245050]\n",
      "epoch:18 step:17126 [D loss: 0.419052, acc.: 82.81%] [G loss: 1.322525]\n",
      "epoch:18 step:17127 [D loss: 0.237900, acc.: 94.53%] [G loss: 1.248041]\n",
      "epoch:18 step:17128 [D loss: 0.769761, acc.: 53.12%] [G loss: 1.170888]\n",
      "epoch:18 step:17129 [D loss: 0.338352, acc.: 89.84%] [G loss: 1.296160]\n",
      "epoch:18 step:17130 [D loss: 0.785007, acc.: 42.97%] [G loss: 1.293650]\n",
      "epoch:18 step:17131 [D loss: 0.625881, acc.: 64.84%] [G loss: 1.263762]\n",
      "epoch:18 step:17132 [D loss: 0.802086, acc.: 44.53%] [G loss: 1.071067]\n",
      "epoch:18 step:17133 [D loss: 1.181739, acc.: 14.84%] [G loss: 0.833642]\n",
      "epoch:18 step:17134 [D loss: 0.667059, acc.: 56.25%] [G loss: 1.226048]\n",
      "epoch:18 step:17135 [D loss: 0.446133, acc.: 87.50%] [G loss: 1.216417]\n",
      "epoch:18 step:17136 [D loss: 0.558048, acc.: 70.31%] [G loss: 1.211827]\n",
      "epoch:18 step:17137 [D loss: 0.450717, acc.: 87.50%] [G loss: 1.141876]\n",
      "epoch:18 step:17138 [D loss: 0.515081, acc.: 82.03%] [G loss: 1.204044]\n",
      "epoch:18 step:17139 [D loss: 0.556498, acc.: 72.66%] [G loss: 1.188159]\n",
      "epoch:18 step:17140 [D loss: 0.480421, acc.: 85.16%] [G loss: 1.013706]\n",
      "epoch:18 step:17141 [D loss: 0.662818, acc.: 58.59%] [G loss: 1.283007]\n",
      "epoch:18 step:17142 [D loss: 0.453773, acc.: 85.94%] [G loss: 1.135614]\n",
      "epoch:18 step:17143 [D loss: 0.620552, acc.: 64.06%] [G loss: 0.963000]\n",
      "epoch:18 step:17144 [D loss: 0.496414, acc.: 81.25%] [G loss: 1.221652]\n",
      "epoch:18 step:17145 [D loss: 0.269599, acc.: 96.88%] [G loss: 1.169393]\n",
      "epoch:18 step:17146 [D loss: 0.702216, acc.: 54.69%] [G loss: 0.921579]\n",
      "epoch:18 step:17147 [D loss: 0.650755, acc.: 61.72%] [G loss: 0.950859]\n",
      "epoch:18 step:17148 [D loss: 0.463797, acc.: 84.38%] [G loss: 0.848571]\n",
      "epoch:18 step:17149 [D loss: 0.852696, acc.: 35.16%] [G loss: 0.804043]\n",
      "epoch:18 step:17150 [D loss: 0.897825, acc.: 31.25%] [G loss: 0.884990]\n",
      "epoch:18 step:17151 [D loss: 0.758582, acc.: 50.00%] [G loss: 0.776577]\n",
      "epoch:18 step:17152 [D loss: 0.725693, acc.: 50.00%] [G loss: 0.867074]\n",
      "epoch:18 step:17153 [D loss: 0.683255, acc.: 62.50%] [G loss: 0.770580]\n",
      "epoch:18 step:17154 [D loss: 0.462885, acc.: 79.69%] [G loss: 0.889252]\n",
      "epoch:18 step:17155 [D loss: 0.373384, acc.: 88.28%] [G loss: 0.978614]\n",
      "epoch:18 step:17156 [D loss: 0.666785, acc.: 57.03%] [G loss: 0.950436]\n",
      "epoch:18 step:17157 [D loss: 0.650954, acc.: 58.59%] [G loss: 0.739908]\n",
      "epoch:18 step:17158 [D loss: 0.346820, acc.: 94.53%] [G loss: 0.851891]\n",
      "epoch:18 step:17159 [D loss: 0.516814, acc.: 80.47%] [G loss: 1.028178]\n",
      "epoch:18 step:17160 [D loss: 0.606971, acc.: 71.09%] [G loss: 0.990020]\n",
      "epoch:18 step:17161 [D loss: 0.684570, acc.: 55.47%] [G loss: 0.915689]\n",
      "epoch:18 step:17162 [D loss: 0.736270, acc.: 52.34%] [G loss: 0.924502]\n",
      "epoch:18 step:17163 [D loss: 0.564874, acc.: 74.22%] [G loss: 0.984285]\n",
      "epoch:18 step:17164 [D loss: 0.569204, acc.: 69.53%] [G loss: 0.568548]\n",
      "epoch:18 step:17165 [D loss: 0.530086, acc.: 82.03%] [G loss: 0.846364]\n",
      "epoch:18 step:17166 [D loss: 0.610951, acc.: 71.09%] [G loss: 0.950340]\n",
      "epoch:18 step:17167 [D loss: 0.744368, acc.: 53.91%] [G loss: 0.971523]\n",
      "epoch:18 step:17168 [D loss: 0.596319, acc.: 69.53%] [G loss: 0.989613]\n",
      "epoch:18 step:17169 [D loss: 0.849173, acc.: 39.84%] [G loss: 1.054579]\n",
      "epoch:18 step:17170 [D loss: 0.668499, acc.: 64.06%] [G loss: 0.923460]\n",
      "epoch:18 step:17171 [D loss: 0.332288, acc.: 96.88%] [G loss: 1.024253]\n",
      "epoch:18 step:17172 [D loss: 0.485318, acc.: 78.91%] [G loss: 0.839509]\n",
      "epoch:18 step:17173 [D loss: 0.594732, acc.: 72.66%] [G loss: 1.080558]\n",
      "epoch:18 step:17174 [D loss: 0.367245, acc.: 90.62%] [G loss: 0.943108]\n",
      "epoch:18 step:17175 [D loss: 0.246799, acc.: 91.41%] [G loss: 1.086225]\n",
      "epoch:18 step:17176 [D loss: 0.587876, acc.: 74.22%] [G loss: 1.118545]\n",
      "epoch:18 step:17177 [D loss: 0.445227, acc.: 84.38%] [G loss: 0.563577]\n",
      "epoch:18 step:17178 [D loss: 0.209340, acc.: 97.66%] [G loss: 1.194677]\n",
      "epoch:18 step:17179 [D loss: 0.206168, acc.: 95.31%] [G loss: 1.209783]\n",
      "epoch:18 step:17180 [D loss: 0.194611, acc.: 95.31%] [G loss: 0.861578]\n",
      "epoch:18 step:17181 [D loss: 0.353785, acc.: 93.75%] [G loss: 1.499342]\n",
      "epoch:18 step:17182 [D loss: 0.733069, acc.: 56.25%] [G loss: 1.414138]\n",
      "epoch:18 step:17183 [D loss: 1.287194, acc.: 3.91%] [G loss: 0.937482]\n",
      "epoch:18 step:17184 [D loss: 0.680276, acc.: 60.16%] [G loss: 1.102129]\n",
      "epoch:18 step:17185 [D loss: 0.758498, acc.: 49.22%] [G loss: 0.815154]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17186 [D loss: 0.721246, acc.: 49.22%] [G loss: 1.222047]\n",
      "epoch:18 step:17187 [D loss: 0.910075, acc.: 37.50%] [G loss: 1.199604]\n",
      "epoch:18 step:17188 [D loss: 0.722743, acc.: 52.34%] [G loss: 0.598360]\n",
      "epoch:18 step:17189 [D loss: 0.612396, acc.: 70.31%] [G loss: 1.112029]\n",
      "epoch:18 step:17190 [D loss: 0.611104, acc.: 66.41%] [G loss: 1.223418]\n",
      "epoch:18 step:17191 [D loss: 0.695582, acc.: 54.69%] [G loss: 0.815205]\n",
      "epoch:18 step:17192 [D loss: 0.620442, acc.: 66.41%] [G loss: 1.064866]\n",
      "epoch:18 step:17193 [D loss: 0.500383, acc.: 83.59%] [G loss: 0.883778]\n",
      "epoch:18 step:17194 [D loss: 0.587767, acc.: 69.53%] [G loss: 1.057852]\n",
      "epoch:18 step:17195 [D loss: 0.673885, acc.: 57.03%] [G loss: 1.093090]\n",
      "epoch:18 step:17196 [D loss: 0.824809, acc.: 42.97%] [G loss: 1.017370]\n",
      "epoch:18 step:17197 [D loss: 0.760217, acc.: 47.66%] [G loss: 1.092644]\n",
      "epoch:18 step:17198 [D loss: 0.969232, acc.: 37.50%] [G loss: 1.045739]\n",
      "epoch:18 step:17199 [D loss: 0.363035, acc.: 90.62%] [G loss: 1.134153]\n",
      "epoch:18 step:17200 [D loss: 0.616992, acc.: 67.19%] [G loss: 0.997627]\n",
      "##############\n",
      "[4.02824663 2.67395865 6.40307035 6.17932767 4.52118736 6.58480728\n",
      " 5.49596557 5.75279696 6.16858689 4.99727562]\n",
      "##########\n",
      "epoch:18 step:17201 [D loss: 0.551543, acc.: 78.12%] [G loss: 1.077374]\n",
      "epoch:18 step:17202 [D loss: 0.414873, acc.: 82.81%] [G loss: 1.130818]\n",
      "epoch:18 step:17203 [D loss: 0.576476, acc.: 71.88%] [G loss: 0.997854]\n",
      "epoch:18 step:17204 [D loss: 0.721849, acc.: 46.88%] [G loss: 0.987681]\n",
      "epoch:18 step:17205 [D loss: 0.754918, acc.: 50.00%] [G loss: 0.896412]\n",
      "epoch:18 step:17206 [D loss: 0.798762, acc.: 41.41%] [G loss: 0.676100]\n",
      "epoch:18 step:17207 [D loss: 0.898724, acc.: 27.34%] [G loss: 0.824690]\n",
      "epoch:18 step:17208 [D loss: 0.285424, acc.: 95.31%] [G loss: 1.120242]\n",
      "epoch:18 step:17209 [D loss: 0.229359, acc.: 97.66%] [G loss: 1.201770]\n",
      "epoch:18 step:17210 [D loss: 0.503576, acc.: 71.88%] [G loss: 1.202913]\n",
      "epoch:18 step:17211 [D loss: 0.304234, acc.: 92.97%] [G loss: 0.937893]\n",
      "epoch:18 step:17212 [D loss: 0.289661, acc.: 92.97%] [G loss: 1.122699]\n",
      "epoch:18 step:17213 [D loss: 0.283612, acc.: 96.09%] [G loss: 1.031888]\n",
      "epoch:18 step:17214 [D loss: 0.895553, acc.: 39.06%] [G loss: 1.352840]\n",
      "epoch:18 step:17215 [D loss: 0.774244, acc.: 50.78%] [G loss: 1.208874]\n",
      "epoch:18 step:17216 [D loss: 0.735500, acc.: 53.12%] [G loss: 1.308182]\n",
      "epoch:18 step:17217 [D loss: 0.512630, acc.: 84.38%] [G loss: 1.049206]\n",
      "epoch:18 step:17218 [D loss: 0.539336, acc.: 78.12%] [G loss: 1.315954]\n",
      "epoch:18 step:17219 [D loss: 0.355575, acc.: 94.53%] [G loss: 1.483199]\n",
      "epoch:18 step:17220 [D loss: 0.382909, acc.: 94.53%] [G loss: 1.641461]\n",
      "epoch:18 step:17221 [D loss: 0.461844, acc.: 81.25%] [G loss: 1.413509]\n",
      "epoch:18 step:17222 [D loss: 0.506287, acc.: 78.12%] [G loss: 1.780886]\n",
      "epoch:18 step:17223 [D loss: 0.332434, acc.: 93.75%] [G loss: 1.826071]\n",
      "epoch:18 step:17224 [D loss: 0.185837, acc.: 98.44%] [G loss: 1.575109]\n",
      "epoch:18 step:17225 [D loss: 0.163168, acc.: 100.00%] [G loss: 2.162738]\n",
      "epoch:18 step:17226 [D loss: 0.274989, acc.: 97.66%] [G loss: 2.041801]\n",
      "epoch:18 step:17227 [D loss: 0.237472, acc.: 99.22%] [G loss: 1.947517]\n",
      "epoch:18 step:17228 [D loss: 0.673264, acc.: 63.28%] [G loss: 1.587216]\n",
      "epoch:18 step:17229 [D loss: 0.972432, acc.: 37.50%] [G loss: 1.245939]\n",
      "epoch:18 step:17230 [D loss: 0.541486, acc.: 68.75%] [G loss: 1.357693]\n",
      "epoch:18 step:17231 [D loss: 0.653965, acc.: 67.97%] [G loss: 1.091687]\n",
      "epoch:18 step:17232 [D loss: 0.820762, acc.: 50.00%] [G loss: 0.833550]\n",
      "epoch:18 step:17233 [D loss: 1.340784, acc.: 29.69%] [G loss: 1.132598]\n",
      "epoch:18 step:17234 [D loss: 0.459057, acc.: 85.16%] [G loss: 1.205503]\n",
      "epoch:18 step:17235 [D loss: 0.395966, acc.: 74.22%] [G loss: 0.977267]\n",
      "epoch:18 step:17236 [D loss: 0.336714, acc.: 81.25%] [G loss: 1.051074]\n",
      "epoch:18 step:17237 [D loss: 0.167300, acc.: 97.66%] [G loss: 1.329245]\n",
      "epoch:18 step:17238 [D loss: 0.276469, acc.: 98.44%] [G loss: 1.312243]\n",
      "epoch:18 step:17239 [D loss: 1.019989, acc.: 24.22%] [G loss: 0.913893]\n",
      "epoch:18 step:17240 [D loss: 0.492926, acc.: 81.25%] [G loss: 1.409578]\n",
      "epoch:18 step:17241 [D loss: 0.873758, acc.: 37.50%] [G loss: 1.046881]\n",
      "epoch:18 step:17242 [D loss: 1.231825, acc.: 27.34%] [G loss: 1.058753]\n",
      "epoch:18 step:17243 [D loss: 1.203892, acc.: 20.31%] [G loss: 0.914217]\n",
      "epoch:18 step:17244 [D loss: 1.168134, acc.: 19.53%] [G loss: 0.929819]\n",
      "epoch:18 step:17245 [D loss: 0.620958, acc.: 67.97%] [G loss: 0.817620]\n",
      "epoch:18 step:17246 [D loss: 0.450608, acc.: 85.16%] [G loss: 1.016377]\n",
      "epoch:18 step:17247 [D loss: 0.492672, acc.: 77.34%] [G loss: 0.896620]\n",
      "epoch:18 step:17248 [D loss: 0.742386, acc.: 47.66%] [G loss: 1.080846]\n",
      "epoch:18 step:17249 [D loss: 0.676455, acc.: 58.59%] [G loss: 1.073497]\n",
      "epoch:18 step:17250 [D loss: 0.805800, acc.: 43.75%] [G loss: 0.852674]\n",
      "epoch:18 step:17251 [D loss: 0.673943, acc.: 58.59%] [G loss: 0.596366]\n",
      "epoch:18 step:17252 [D loss: 0.842113, acc.: 33.59%] [G loss: 0.841619]\n",
      "epoch:18 step:17253 [D loss: 0.810854, acc.: 38.28%] [G loss: 0.996401]\n",
      "epoch:18 step:17254 [D loss: 0.747975, acc.: 39.06%] [G loss: 1.056715]\n",
      "epoch:18 step:17255 [D loss: 0.746486, acc.: 50.00%] [G loss: 0.778097]\n",
      "epoch:18 step:17256 [D loss: 0.741534, acc.: 41.41%] [G loss: 1.052527]\n",
      "epoch:18 step:17257 [D loss: 0.741858, acc.: 39.84%] [G loss: 0.947162]\n",
      "epoch:18 step:17258 [D loss: 0.724064, acc.: 38.28%] [G loss: 1.119002]\n",
      "epoch:18 step:17259 [D loss: 0.679218, acc.: 50.78%] [G loss: 1.185797]\n",
      "epoch:18 step:17260 [D loss: 0.658086, acc.: 53.91%] [G loss: 0.947396]\n",
      "epoch:18 step:17261 [D loss: 0.700505, acc.: 50.78%] [G loss: 1.010063]\n",
      "epoch:18 step:17262 [D loss: 0.557232, acc.: 75.00%] [G loss: 1.193570]\n",
      "epoch:18 step:17263 [D loss: 0.460248, acc.: 81.25%] [G loss: 1.253863]\n",
      "epoch:18 step:17264 [D loss: 0.437715, acc.: 87.50%] [G loss: 1.240552]\n",
      "epoch:18 step:17265 [D loss: 0.418110, acc.: 90.62%] [G loss: 1.426885]\n",
      "epoch:18 step:17266 [D loss: 0.483197, acc.: 82.03%] [G loss: 1.248168]\n",
      "epoch:18 step:17267 [D loss: 0.490695, acc.: 79.69%] [G loss: 1.467618]\n",
      "epoch:18 step:17268 [D loss: 0.403850, acc.: 82.81%] [G loss: 1.647403]\n",
      "epoch:18 step:17269 [D loss: 0.477742, acc.: 82.81%] [G loss: 1.520402]\n",
      "epoch:18 step:17270 [D loss: 0.325946, acc.: 92.97%] [G loss: 1.357551]\n",
      "epoch:18 step:17271 [D loss: 0.310164, acc.: 92.19%] [G loss: 1.158508]\n",
      "epoch:18 step:17272 [D loss: 0.302990, acc.: 92.19%] [G loss: 1.309470]\n",
      "epoch:18 step:17273 [D loss: 0.249472, acc.: 94.53%] [G loss: 1.538953]\n",
      "epoch:18 step:17274 [D loss: 0.425598, acc.: 82.03%] [G loss: 1.682191]\n",
      "epoch:18 step:17275 [D loss: 0.203614, acc.: 99.22%] [G loss: 1.415645]\n",
      "epoch:18 step:17276 [D loss: 0.446452, acc.: 87.50%] [G loss: 1.264665]\n",
      "epoch:18 step:17277 [D loss: 1.084381, acc.: 32.03%] [G loss: 0.795067]\n",
      "epoch:18 step:17278 [D loss: 0.447710, acc.: 88.28%] [G loss: 1.104383]\n",
      "epoch:18 step:17279 [D loss: 0.334547, acc.: 83.59%] [G loss: 1.112750]\n",
      "epoch:18 step:17280 [D loss: 0.487034, acc.: 70.31%] [G loss: 0.642418]\n",
      "epoch:18 step:17281 [D loss: 0.338898, acc.: 89.06%] [G loss: 1.131465]\n",
      "epoch:18 step:17282 [D loss: 0.578006, acc.: 67.19%] [G loss: 0.427162]\n",
      "epoch:18 step:17283 [D loss: 0.510892, acc.: 72.66%] [G loss: 1.739674]\n",
      "epoch:18 step:17284 [D loss: 0.422707, acc.: 75.78%] [G loss: 1.354237]\n",
      "epoch:18 step:17285 [D loss: 0.314873, acc.: 92.97%] [G loss: 1.139237]\n",
      "epoch:18 step:17286 [D loss: 0.842323, acc.: 47.66%] [G loss: 0.989270]\n",
      "epoch:18 step:17287 [D loss: 0.910120, acc.: 47.66%] [G loss: 0.746912]\n",
      "epoch:18 step:17288 [D loss: 1.511507, acc.: 16.41%] [G loss: 0.996378]\n",
      "epoch:18 step:17289 [D loss: 0.756625, acc.: 54.69%] [G loss: 1.451698]\n",
      "epoch:18 step:17290 [D loss: 0.681467, acc.: 59.38%] [G loss: 1.106830]\n",
      "epoch:18 step:17291 [D loss: 0.647480, acc.: 60.94%] [G loss: 0.866908]\n",
      "epoch:18 step:17292 [D loss: 0.787556, acc.: 47.66%] [G loss: 1.143444]\n",
      "epoch:18 step:17293 [D loss: 0.599687, acc.: 67.97%] [G loss: 1.007376]\n",
      "epoch:18 step:17294 [D loss: 0.374658, acc.: 88.28%] [G loss: 1.010110]\n",
      "epoch:18 step:17295 [D loss: 1.130223, acc.: 34.38%] [G loss: 1.274967]\n",
      "epoch:18 step:17296 [D loss: 0.559140, acc.: 75.78%] [G loss: 1.037396]\n",
      "epoch:18 step:17297 [D loss: 0.804891, acc.: 51.56%] [G loss: 1.151611]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17298 [D loss: 0.842158, acc.: 45.31%] [G loss: 0.976209]\n",
      "epoch:18 step:17299 [D loss: 0.755723, acc.: 46.88%] [G loss: 0.890955]\n",
      "epoch:18 step:17300 [D loss: 0.715117, acc.: 45.31%] [G loss: 1.030879]\n",
      "epoch:18 step:17301 [D loss: 0.747910, acc.: 43.75%] [G loss: 0.932983]\n",
      "epoch:18 step:17302 [D loss: 0.708882, acc.: 54.69%] [G loss: 1.073395]\n",
      "epoch:18 step:17303 [D loss: 0.741313, acc.: 44.53%] [G loss: 1.026587]\n",
      "epoch:18 step:17304 [D loss: 0.687779, acc.: 57.81%] [G loss: 1.049481]\n",
      "epoch:18 step:17305 [D loss: 0.704955, acc.: 53.91%] [G loss: 1.024861]\n",
      "epoch:18 step:17306 [D loss: 0.682241, acc.: 53.91%] [G loss: 1.061807]\n",
      "epoch:18 step:17307 [D loss: 0.700508, acc.: 57.81%] [G loss: 0.913131]\n",
      "epoch:18 step:17308 [D loss: 0.675122, acc.: 56.25%] [G loss: 0.872213]\n",
      "epoch:18 step:17309 [D loss: 0.654012, acc.: 57.03%] [G loss: 0.918421]\n",
      "epoch:18 step:17310 [D loss: 0.651817, acc.: 60.16%] [G loss: 0.992279]\n",
      "epoch:18 step:17311 [D loss: 0.622809, acc.: 60.16%] [G loss: 0.921472]\n",
      "epoch:18 step:17312 [D loss: 0.670565, acc.: 54.69%] [G loss: 0.989234]\n",
      "epoch:18 step:17313 [D loss: 0.710875, acc.: 54.69%] [G loss: 0.967941]\n",
      "epoch:18 step:17314 [D loss: 0.633642, acc.: 64.84%] [G loss: 1.006770]\n",
      "epoch:18 step:17315 [D loss: 0.567940, acc.: 78.91%] [G loss: 1.061114]\n",
      "epoch:18 step:17316 [D loss: 0.602190, acc.: 68.75%] [G loss: 0.990099]\n",
      "epoch:18 step:17317 [D loss: 0.472097, acc.: 90.62%] [G loss: 1.108960]\n",
      "epoch:18 step:17318 [D loss: 0.476720, acc.: 90.62%] [G loss: 1.091913]\n",
      "epoch:18 step:17319 [D loss: 0.465623, acc.: 90.62%] [G loss: 1.172337]\n",
      "epoch:18 step:17320 [D loss: 0.496868, acc.: 82.03%] [G loss: 1.149356]\n",
      "epoch:18 step:17321 [D loss: 0.501054, acc.: 79.69%] [G loss: 1.175257]\n",
      "epoch:18 step:17322 [D loss: 0.332392, acc.: 96.09%] [G loss: 1.329411]\n",
      "epoch:18 step:17323 [D loss: 0.416552, acc.: 90.62%] [G loss: 1.337162]\n",
      "epoch:18 step:17324 [D loss: 0.670585, acc.: 57.03%] [G loss: 1.049243]\n",
      "epoch:18 step:17325 [D loss: 0.594498, acc.: 68.75%] [G loss: 1.068070]\n",
      "epoch:18 step:17326 [D loss: 0.566119, acc.: 66.41%] [G loss: 0.944500]\n",
      "epoch:18 step:17327 [D loss: 0.845976, acc.: 50.78%] [G loss: 1.143839]\n",
      "epoch:18 step:17328 [D loss: 1.067152, acc.: 39.06%] [G loss: 0.729345]\n",
      "epoch:18 step:17329 [D loss: 0.706051, acc.: 56.25%] [G loss: 0.832738]\n",
      "epoch:18 step:17330 [D loss: 0.574804, acc.: 81.25%] [G loss: 0.787930]\n",
      "epoch:18 step:17331 [D loss: 0.495602, acc.: 87.50%] [G loss: 0.581530]\n",
      "epoch:18 step:17332 [D loss: 0.514304, acc.: 85.16%] [G loss: 0.666198]\n",
      "epoch:18 step:17333 [D loss: 0.546043, acc.: 71.09%] [G loss: 1.031925]\n",
      "epoch:18 step:17334 [D loss: 0.471659, acc.: 67.97%] [G loss: 0.879802]\n",
      "epoch:18 step:17335 [D loss: 0.397491, acc.: 88.28%] [G loss: 0.986765]\n",
      "epoch:18 step:17336 [D loss: 0.281668, acc.: 95.31%] [G loss: 0.961752]\n",
      "epoch:18 step:17337 [D loss: 0.267800, acc.: 98.44%] [G loss: 1.190544]\n",
      "epoch:18 step:17338 [D loss: 0.439722, acc.: 87.50%] [G loss: 1.479886]\n",
      "epoch:18 step:17339 [D loss: 1.010574, acc.: 37.50%] [G loss: 0.627362]\n",
      "epoch:18 step:17340 [D loss: 0.933316, acc.: 28.12%] [G loss: 0.805004]\n",
      "epoch:18 step:17341 [D loss: 0.664042, acc.: 53.91%] [G loss: 1.163797]\n",
      "epoch:18 step:17342 [D loss: 0.547269, acc.: 78.12%] [G loss: 0.756600]\n",
      "epoch:18 step:17343 [D loss: 0.769454, acc.: 46.09%] [G loss: 0.805286]\n",
      "epoch:18 step:17344 [D loss: 0.733266, acc.: 53.12%] [G loss: 0.792386]\n",
      "epoch:18 step:17345 [D loss: 0.479325, acc.: 82.03%] [G loss: 0.889659]\n",
      "epoch:18 step:17346 [D loss: 0.632732, acc.: 60.16%] [G loss: 0.757433]\n",
      "epoch:18 step:17347 [D loss: 0.457287, acc.: 78.91%] [G loss: 0.862391]\n",
      "epoch:18 step:17348 [D loss: 0.959761, acc.: 29.69%] [G loss: 1.059613]\n",
      "epoch:18 step:17349 [D loss: 0.738371, acc.: 48.44%] [G loss: 0.892777]\n",
      "epoch:18 step:17350 [D loss: 0.740566, acc.: 46.88%] [G loss: 0.945149]\n",
      "epoch:18 step:17351 [D loss: 0.718696, acc.: 50.78%] [G loss: 0.992355]\n",
      "epoch:18 step:17352 [D loss: 0.695920, acc.: 53.12%] [G loss: 0.784498]\n",
      "epoch:18 step:17353 [D loss: 0.736261, acc.: 39.06%] [G loss: 1.089042]\n",
      "epoch:18 step:17354 [D loss: 0.678031, acc.: 52.34%] [G loss: 0.876021]\n",
      "epoch:18 step:17355 [D loss: 0.598350, acc.: 71.88%] [G loss: 0.805263]\n",
      "epoch:18 step:17356 [D loss: 0.519331, acc.: 75.00%] [G loss: 0.865523]\n",
      "epoch:18 step:17357 [D loss: 0.588258, acc.: 66.41%] [G loss: 0.879532]\n",
      "epoch:18 step:17358 [D loss: 0.636773, acc.: 62.50%] [G loss: 0.869075]\n",
      "epoch:18 step:17359 [D loss: 0.717285, acc.: 50.00%] [G loss: 0.833656]\n",
      "epoch:18 step:17360 [D loss: 0.545927, acc.: 78.91%] [G loss: 0.879512]\n",
      "epoch:18 step:17361 [D loss: 0.602260, acc.: 67.19%] [G loss: 0.898474]\n",
      "epoch:18 step:17362 [D loss: 0.800960, acc.: 41.41%] [G loss: 0.800813]\n",
      "epoch:18 step:17363 [D loss: 0.608372, acc.: 70.31%] [G loss: 0.943674]\n",
      "epoch:18 step:17364 [D loss: 0.562740, acc.: 66.41%] [G loss: 1.085906]\n",
      "epoch:18 step:17365 [D loss: 0.555452, acc.: 73.44%] [G loss: 0.994009]\n",
      "epoch:18 step:17366 [D loss: 0.695343, acc.: 63.28%] [G loss: 0.884733]\n",
      "epoch:18 step:17367 [D loss: 0.694721, acc.: 57.03%] [G loss: 1.140122]\n",
      "epoch:18 step:17368 [D loss: 0.716479, acc.: 51.56%] [G loss: 0.927568]\n",
      "epoch:18 step:17369 [D loss: 0.426715, acc.: 89.06%] [G loss: 0.956674]\n",
      "epoch:18 step:17370 [D loss: 0.413130, acc.: 86.72%] [G loss: 1.015067]\n",
      "epoch:18 step:17371 [D loss: 0.504114, acc.: 80.47%] [G loss: 0.988103]\n",
      "epoch:18 step:17372 [D loss: 0.653264, acc.: 61.72%] [G loss: 0.965174]\n",
      "epoch:18 step:17373 [D loss: 0.496718, acc.: 76.56%] [G loss: 0.990375]\n",
      "epoch:18 step:17374 [D loss: 0.477898, acc.: 84.38%] [G loss: 1.070906]\n",
      "epoch:18 step:17375 [D loss: 0.708835, acc.: 57.03%] [G loss: 0.837560]\n",
      "epoch:18 step:17376 [D loss: 0.707774, acc.: 57.81%] [G loss: 0.968571]\n",
      "epoch:18 step:17377 [D loss: 0.568512, acc.: 72.66%] [G loss: 1.076791]\n",
      "epoch:18 step:17378 [D loss: 0.517554, acc.: 80.47%] [G loss: 1.008497]\n",
      "epoch:18 step:17379 [D loss: 0.460161, acc.: 82.03%] [G loss: 1.336069]\n",
      "epoch:18 step:17380 [D loss: 0.429986, acc.: 86.72%] [G loss: 1.199358]\n",
      "epoch:18 step:17381 [D loss: 0.358648, acc.: 89.06%] [G loss: 1.230488]\n",
      "epoch:18 step:17382 [D loss: 0.654929, acc.: 66.41%] [G loss: 0.992449]\n",
      "epoch:18 step:17383 [D loss: 0.450744, acc.: 87.50%] [G loss: 1.120500]\n",
      "epoch:18 step:17384 [D loss: 0.601876, acc.: 69.53%] [G loss: 0.945772]\n",
      "epoch:18 step:17385 [D loss: 0.585006, acc.: 70.31%] [G loss: 1.067773]\n",
      "epoch:18 step:17386 [D loss: 0.509012, acc.: 77.34%] [G loss: 0.738512]\n",
      "epoch:18 step:17387 [D loss: 0.615367, acc.: 67.97%] [G loss: 0.816930]\n",
      "epoch:18 step:17388 [D loss: 0.692482, acc.: 60.16%] [G loss: 0.987277]\n",
      "epoch:18 step:17389 [D loss: 0.576471, acc.: 72.66%] [G loss: 1.007798]\n",
      "epoch:18 step:17390 [D loss: 0.334692, acc.: 92.97%] [G loss: 0.926534]\n",
      "epoch:18 step:17391 [D loss: 0.782354, acc.: 46.09%] [G loss: 1.064202]\n",
      "epoch:18 step:17392 [D loss: 0.618560, acc.: 71.88%] [G loss: 1.008041]\n",
      "epoch:18 step:17393 [D loss: 0.489282, acc.: 80.47%] [G loss: 1.017822]\n",
      "epoch:18 step:17394 [D loss: 0.687958, acc.: 64.06%] [G loss: 1.227961]\n",
      "epoch:18 step:17395 [D loss: 0.693833, acc.: 60.16%] [G loss: 0.925447]\n",
      "epoch:18 step:17396 [D loss: 0.377200, acc.: 83.59%] [G loss: 0.992827]\n",
      "epoch:18 step:17397 [D loss: 0.793875, acc.: 42.97%] [G loss: 1.021781]\n",
      "epoch:18 step:17398 [D loss: 0.680043, acc.: 60.16%] [G loss: 1.000473]\n",
      "epoch:18 step:17399 [D loss: 0.510190, acc.: 84.38%] [G loss: 0.875001]\n",
      "epoch:18 step:17400 [D loss: 0.600169, acc.: 70.31%] [G loss: 0.905463]\n",
      "##############\n",
      "[4.15487481 2.5857887  6.18539341 5.46791738 4.73107056 6.13585939\n",
      " 5.74467638 5.56100185 5.90180428 4.9704998 ]\n",
      "##########\n",
      "epoch:18 step:17401 [D loss: 0.391852, acc.: 80.47%] [G loss: 1.094953]\n",
      "epoch:18 step:17402 [D loss: 0.294524, acc.: 90.62%] [G loss: 1.061510]\n",
      "epoch:18 step:17403 [D loss: 0.315687, acc.: 92.97%] [G loss: 1.120009]\n",
      "epoch:18 step:17404 [D loss: 0.448018, acc.: 84.38%] [G loss: 1.308581]\n",
      "epoch:18 step:17405 [D loss: 0.371046, acc.: 90.62%] [G loss: 1.179961]\n",
      "epoch:18 step:17406 [D loss: 0.326437, acc.: 96.09%] [G loss: 1.402163]\n",
      "epoch:18 step:17407 [D loss: 0.355145, acc.: 93.75%] [G loss: 1.289843]\n",
      "epoch:18 step:17408 [D loss: 0.739512, acc.: 52.34%] [G loss: 1.238897]\n",
      "epoch:18 step:17409 [D loss: 0.223044, acc.: 96.09%] [G loss: 0.973435]\n",
      "epoch:18 step:17410 [D loss: 0.704229, acc.: 53.12%] [G loss: 1.093132]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17411 [D loss: 0.771260, acc.: 52.34%] [G loss: 0.930628]\n",
      "epoch:18 step:17412 [D loss: 0.746077, acc.: 43.75%] [G loss: 1.026327]\n",
      "epoch:18 step:17413 [D loss: 0.576319, acc.: 67.97%] [G loss: 1.017089]\n",
      "epoch:18 step:17414 [D loss: 0.695215, acc.: 57.81%] [G loss: 1.181643]\n",
      "epoch:18 step:17415 [D loss: 0.752504, acc.: 53.12%] [G loss: 1.208097]\n",
      "epoch:18 step:17416 [D loss: 0.443116, acc.: 83.59%] [G loss: 1.055006]\n",
      "epoch:18 step:17417 [D loss: 0.731252, acc.: 54.69%] [G loss: 0.848550]\n",
      "epoch:18 step:17418 [D loss: 0.554484, acc.: 72.66%] [G loss: 0.882910]\n",
      "epoch:18 step:17419 [D loss: 0.705959, acc.: 60.94%] [G loss: 0.984411]\n",
      "epoch:18 step:17420 [D loss: 0.439744, acc.: 82.81%] [G loss: 0.541907]\n",
      "epoch:18 step:17421 [D loss: 1.058321, acc.: 38.28%] [G loss: 1.234890]\n",
      "epoch:18 step:17422 [D loss: 0.617691, acc.: 65.62%] [G loss: 0.960894]\n",
      "epoch:18 step:17423 [D loss: 0.514300, acc.: 82.03%] [G loss: 1.130708]\n",
      "epoch:18 step:17424 [D loss: 0.625139, acc.: 63.28%] [G loss: 1.094631]\n",
      "epoch:18 step:17425 [D loss: 0.287422, acc.: 87.50%] [G loss: 1.383811]\n",
      "epoch:18 step:17426 [D loss: 0.396557, acc.: 85.16%] [G loss: 1.146335]\n",
      "epoch:18 step:17427 [D loss: 0.230560, acc.: 95.31%] [G loss: 1.373080]\n",
      "epoch:18 step:17428 [D loss: 0.695590, acc.: 62.50%] [G loss: 1.508813]\n",
      "epoch:18 step:17429 [D loss: 0.723076, acc.: 53.91%] [G loss: 1.126746]\n",
      "epoch:18 step:17430 [D loss: 0.711146, acc.: 57.81%] [G loss: 1.139690]\n",
      "epoch:18 step:17431 [D loss: 0.539140, acc.: 71.09%] [G loss: 1.232681]\n",
      "epoch:18 step:17432 [D loss: 0.220225, acc.: 94.53%] [G loss: 0.844214]\n",
      "epoch:18 step:17433 [D loss: 0.215203, acc.: 95.31%] [G loss: 1.334069]\n",
      "epoch:18 step:17434 [D loss: 0.422544, acc.: 90.62%] [G loss: 1.378268]\n",
      "epoch:18 step:17435 [D loss: 0.766030, acc.: 46.88%] [G loss: 0.961073]\n",
      "epoch:18 step:17436 [D loss: 0.569402, acc.: 72.66%] [G loss: 1.211457]\n",
      "epoch:18 step:17437 [D loss: 0.639559, acc.: 62.50%] [G loss: 1.166126]\n",
      "epoch:18 step:17438 [D loss: 0.604669, acc.: 65.62%] [G loss: 1.224651]\n",
      "epoch:18 step:17439 [D loss: 0.330265, acc.: 89.84%] [G loss: 1.297803]\n",
      "epoch:18 step:17440 [D loss: 0.342101, acc.: 92.97%] [G loss: 1.498896]\n",
      "epoch:18 step:17441 [D loss: 0.376299, acc.: 91.41%] [G loss: 1.546367]\n",
      "epoch:18 step:17442 [D loss: 0.206975, acc.: 94.53%] [G loss: 1.619313]\n",
      "epoch:18 step:17443 [D loss: 0.175115, acc.: 95.31%] [G loss: 1.546772]\n",
      "epoch:18 step:17444 [D loss: 0.157233, acc.: 97.66%] [G loss: 1.611601]\n",
      "epoch:18 step:17445 [D loss: 0.191542, acc.: 96.88%] [G loss: 2.050776]\n",
      "epoch:18 step:17446 [D loss: 0.758978, acc.: 53.91%] [G loss: 1.385890]\n",
      "epoch:18 step:17447 [D loss: 0.691182, acc.: 59.38%] [G loss: 1.325005]\n",
      "epoch:18 step:17448 [D loss: 0.630588, acc.: 60.94%] [G loss: 1.145765]\n",
      "epoch:18 step:17449 [D loss: 0.941609, acc.: 34.38%] [G loss: 1.384492]\n",
      "epoch:18 step:17450 [D loss: 0.911276, acc.: 39.84%] [G loss: 0.601632]\n",
      "epoch:18 step:17451 [D loss: 0.746985, acc.: 48.44%] [G loss: 0.950856]\n",
      "epoch:18 step:17452 [D loss: 0.612987, acc.: 69.53%] [G loss: 0.522752]\n",
      "epoch:18 step:17453 [D loss: 0.832316, acc.: 53.91%] [G loss: 1.165136]\n",
      "epoch:18 step:17454 [D loss: 0.224246, acc.: 95.31%] [G loss: 1.159328]\n",
      "epoch:18 step:17455 [D loss: 0.228973, acc.: 92.19%] [G loss: 1.516985]\n",
      "epoch:18 step:17456 [D loss: 0.594897, acc.: 69.53%] [G loss: 1.087395]\n",
      "epoch:18 step:17457 [D loss: 0.834569, acc.: 57.81%] [G loss: 1.208905]\n",
      "epoch:18 step:17458 [D loss: 0.712021, acc.: 53.91%] [G loss: 1.237969]\n",
      "epoch:18 step:17459 [D loss: 0.744974, acc.: 53.91%] [G loss: 0.931348]\n",
      "epoch:18 step:17460 [D loss: 0.516412, acc.: 78.91%] [G loss: 0.988351]\n",
      "epoch:18 step:17461 [D loss: 0.295220, acc.: 91.41%] [G loss: 0.637037]\n",
      "epoch:18 step:17462 [D loss: 0.905446, acc.: 30.47%] [G loss: 1.129322]\n",
      "epoch:18 step:17463 [D loss: 0.656709, acc.: 60.16%] [G loss: 1.162662]\n",
      "epoch:18 step:17464 [D loss: 0.663902, acc.: 63.28%] [G loss: 1.206661]\n",
      "epoch:18 step:17465 [D loss: 1.306288, acc.: 23.44%] [G loss: 0.913368]\n",
      "epoch:18 step:17466 [D loss: 0.255498, acc.: 92.97%] [G loss: 1.170403]\n",
      "epoch:18 step:17467 [D loss: 0.367981, acc.: 81.25%] [G loss: 1.357207]\n",
      "epoch:18 step:17468 [D loss: 0.330398, acc.: 95.31%] [G loss: 1.377556]\n",
      "epoch:18 step:17469 [D loss: 0.865334, acc.: 42.97%] [G loss: 1.234078]\n",
      "epoch:18 step:17470 [D loss: 0.483866, acc.: 78.91%] [G loss: 0.984695]\n",
      "epoch:18 step:17471 [D loss: 0.714078, acc.: 53.12%] [G loss: 1.174934]\n",
      "epoch:18 step:17472 [D loss: 0.623123, acc.: 67.19%] [G loss: 0.935932]\n",
      "epoch:18 step:17473 [D loss: 0.536684, acc.: 74.22%] [G loss: 0.957893]\n",
      "epoch:18 step:17474 [D loss: 0.443245, acc.: 82.03%] [G loss: 0.930497]\n",
      "epoch:18 step:17475 [D loss: 0.419637, acc.: 74.22%] [G loss: 0.461322]\n",
      "epoch:18 step:17476 [D loss: 0.772491, acc.: 47.66%] [G loss: 0.977850]\n",
      "epoch:18 step:17477 [D loss: 0.484269, acc.: 72.66%] [G loss: 1.069136]\n",
      "epoch:18 step:17478 [D loss: 0.335767, acc.: 95.31%] [G loss: 1.068674]\n",
      "epoch:18 step:17479 [D loss: 1.142079, acc.: 12.50%] [G loss: 1.103155]\n",
      "epoch:18 step:17480 [D loss: 0.847183, acc.: 42.97%] [G loss: 0.427585]\n",
      "epoch:18 step:17481 [D loss: 0.738954, acc.: 49.22%] [G loss: 1.048052]\n",
      "epoch:18 step:17482 [D loss: 0.822124, acc.: 39.06%] [G loss: 0.916990]\n",
      "epoch:18 step:17483 [D loss: 0.635407, acc.: 60.16%] [G loss: 1.027036]\n",
      "epoch:18 step:17484 [D loss: 0.728539, acc.: 50.78%] [G loss: 0.809493]\n",
      "epoch:18 step:17485 [D loss: 0.666904, acc.: 53.91%] [G loss: 0.757620]\n",
      "epoch:18 step:17486 [D loss: 0.628529, acc.: 66.41%] [G loss: 0.702813]\n",
      "epoch:18 step:17487 [D loss: 0.752205, acc.: 48.44%] [G loss: 0.728060]\n",
      "epoch:18 step:17488 [D loss: 0.636707, acc.: 61.72%] [G loss: 1.274455]\n",
      "epoch:18 step:17489 [D loss: 0.574924, acc.: 69.53%] [G loss: 0.995224]\n",
      "epoch:18 step:17490 [D loss: 0.648272, acc.: 58.59%] [G loss: 1.220897]\n",
      "epoch:18 step:17491 [D loss: 0.709310, acc.: 58.59%] [G loss: 1.280870]\n",
      "epoch:18 step:17492 [D loss: 0.706054, acc.: 50.00%] [G loss: 0.804249]\n",
      "epoch:18 step:17493 [D loss: 0.655419, acc.: 58.59%] [G loss: 1.222886]\n",
      "epoch:18 step:17494 [D loss: 0.845449, acc.: 43.75%] [G loss: 0.918003]\n",
      "epoch:18 step:17495 [D loss: 0.472405, acc.: 81.25%] [G loss: 1.098046]\n",
      "epoch:18 step:17496 [D loss: 0.466813, acc.: 83.59%] [G loss: 1.305227]\n",
      "epoch:18 step:17497 [D loss: 0.685351, acc.: 61.72%] [G loss: 1.098669]\n",
      "epoch:18 step:17498 [D loss: 0.366697, acc.: 90.62%] [G loss: 0.860970]\n",
      "epoch:18 step:17499 [D loss: 0.317273, acc.: 92.97%] [G loss: 1.180704]\n",
      "epoch:18 step:17500 [D loss: 0.421719, acc.: 85.16%] [G loss: 1.105796]\n",
      "epoch:18 step:17501 [D loss: 0.329447, acc.: 96.09%] [G loss: 1.437881]\n",
      "epoch:18 step:17502 [D loss: 0.417673, acc.: 79.69%] [G loss: 1.303300]\n",
      "epoch:18 step:17503 [D loss: 0.366150, acc.: 94.53%] [G loss: 1.638002]\n",
      "epoch:18 step:17504 [D loss: 0.521210, acc.: 77.34%] [G loss: 1.089627]\n",
      "epoch:18 step:17505 [D loss: 0.701860, acc.: 57.03%] [G loss: 1.023321]\n",
      "epoch:18 step:17506 [D loss: 0.900138, acc.: 42.19%] [G loss: 1.036200]\n",
      "epoch:18 step:17507 [D loss: 0.970500, acc.: 33.59%] [G loss: 1.025579]\n",
      "epoch:18 step:17508 [D loss: 0.861912, acc.: 40.62%] [G loss: 0.923759]\n",
      "epoch:18 step:17509 [D loss: 0.440468, acc.: 85.16%] [G loss: 1.221025]\n",
      "epoch:18 step:17510 [D loss: 0.260895, acc.: 91.41%] [G loss: 1.379318]\n",
      "epoch:18 step:17511 [D loss: 0.374749, acc.: 82.03%] [G loss: 0.915963]\n",
      "epoch:18 step:17512 [D loss: 0.374739, acc.: 76.56%] [G loss: 1.192740]\n",
      "epoch:18 step:17513 [D loss: 0.381728, acc.: 84.38%] [G loss: 1.064543]\n",
      "epoch:18 step:17514 [D loss: 0.290487, acc.: 96.09%] [G loss: 1.160457]\n",
      "epoch:18 step:17515 [D loss: 0.308789, acc.: 96.09%] [G loss: 1.403685]\n",
      "epoch:18 step:17516 [D loss: 0.204844, acc.: 99.22%] [G loss: 1.663468]\n",
      "epoch:18 step:17517 [D loss: 0.426916, acc.: 86.72%] [G loss: 1.499353]\n",
      "epoch:18 step:17518 [D loss: 0.433972, acc.: 85.16%] [G loss: 1.084710]\n",
      "epoch:18 step:17519 [D loss: 0.644537, acc.: 59.38%] [G loss: 1.410810]\n",
      "epoch:18 step:17520 [D loss: 0.733787, acc.: 55.47%] [G loss: 0.885025]\n",
      "epoch:18 step:17521 [D loss: 0.523956, acc.: 76.56%] [G loss: 1.153019]\n",
      "epoch:18 step:17522 [D loss: 0.734985, acc.: 49.22%] [G loss: 0.958191]\n",
      "epoch:18 step:17523 [D loss: 0.759629, acc.: 54.69%] [G loss: 1.157804]\n",
      "epoch:18 step:17524 [D loss: 0.708753, acc.: 57.81%] [G loss: 0.794330]\n",
      "epoch:18 step:17525 [D loss: 0.291544, acc.: 92.19%] [G loss: 1.107708]\n",
      "epoch:18 step:17526 [D loss: 0.317523, acc.: 90.62%] [G loss: 0.898976]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17527 [D loss: 0.330437, acc.: 92.97%] [G loss: 0.778623]\n",
      "epoch:18 step:17528 [D loss: 0.855958, acc.: 39.06%] [G loss: 0.859507]\n",
      "epoch:18 step:17529 [D loss: 1.261533, acc.: 17.19%] [G loss: 1.123776]\n",
      "epoch:18 step:17530 [D loss: 0.830559, acc.: 50.00%] [G loss: 0.936881]\n",
      "epoch:18 step:17531 [D loss: 0.412720, acc.: 83.59%] [G loss: 1.248172]\n",
      "epoch:18 step:17532 [D loss: 0.806901, acc.: 47.66%] [G loss: 1.056457]\n",
      "epoch:18 step:17533 [D loss: 0.780007, acc.: 50.78%] [G loss: 1.150539]\n",
      "epoch:18 step:17534 [D loss: 0.804196, acc.: 42.97%] [G loss: 1.125394]\n",
      "epoch:18 step:17535 [D loss: 0.695738, acc.: 48.44%] [G loss: 0.937269]\n",
      "epoch:18 step:17536 [D loss: 0.761146, acc.: 47.66%] [G loss: 1.083666]\n",
      "epoch:18 step:17537 [D loss: 0.709246, acc.: 57.03%] [G loss: 1.132647]\n",
      "epoch:18 step:17538 [D loss: 1.160960, acc.: 17.19%] [G loss: 1.144782]\n",
      "epoch:18 step:17539 [D loss: 0.771072, acc.: 48.44%] [G loss: 1.434113]\n",
      "epoch:18 step:17540 [D loss: 0.596036, acc.: 61.72%] [G loss: 1.401139]\n",
      "epoch:18 step:17541 [D loss: 0.749374, acc.: 54.69%] [G loss: 1.288303]\n",
      "epoch:18 step:17542 [D loss: 0.566807, acc.: 72.66%] [G loss: 1.363241]\n",
      "epoch:18 step:17543 [D loss: 0.640726, acc.: 56.25%] [G loss: 1.367047]\n",
      "epoch:18 step:17544 [D loss: 0.703473, acc.: 55.47%] [G loss: 1.123088]\n",
      "epoch:18 step:17545 [D loss: 0.597652, acc.: 67.97%] [G loss: 0.969129]\n",
      "epoch:18 step:17546 [D loss: 0.616341, acc.: 64.84%] [G loss: 0.886582]\n",
      "epoch:18 step:17547 [D loss: 0.705201, acc.: 54.69%] [G loss: 0.876350]\n",
      "epoch:18 step:17548 [D loss: 0.515854, acc.: 78.91%] [G loss: 1.088657]\n",
      "epoch:18 step:17549 [D loss: 0.600150, acc.: 65.62%] [G loss: 0.852658]\n",
      "epoch:18 step:17550 [D loss: 0.483110, acc.: 85.94%] [G loss: 1.099690]\n",
      "epoch:18 step:17551 [D loss: 0.505830, acc.: 82.81%] [G loss: 1.262487]\n",
      "epoch:18 step:17552 [D loss: 0.452407, acc.: 79.69%] [G loss: 1.333147]\n",
      "epoch:18 step:17553 [D loss: 0.486729, acc.: 83.59%] [G loss: 1.180554]\n",
      "epoch:18 step:17554 [D loss: 0.543840, acc.: 78.91%] [G loss: 0.830838]\n",
      "epoch:18 step:17555 [D loss: 0.869997, acc.: 39.06%] [G loss: 1.179154]\n",
      "epoch:18 step:17556 [D loss: 0.828702, acc.: 35.16%] [G loss: 1.064670]\n",
      "epoch:18 step:17557 [D loss: 0.726147, acc.: 50.78%] [G loss: 0.852052]\n",
      "epoch:18 step:17558 [D loss: 0.697454, acc.: 55.47%] [G loss: 0.722864]\n",
      "epoch:18 step:17559 [D loss: 0.709487, acc.: 54.69%] [G loss: 0.783168]\n",
      "epoch:18 step:17560 [D loss: 0.616286, acc.: 66.41%] [G loss: 0.752423]\n",
      "epoch:18 step:17561 [D loss: 0.661614, acc.: 54.69%] [G loss: 0.700291]\n",
      "epoch:18 step:17562 [D loss: 0.383856, acc.: 73.44%] [G loss: 0.765031]\n",
      "epoch:18 step:17563 [D loss: 0.324930, acc.: 85.16%] [G loss: 0.968025]\n",
      "epoch:18 step:17564 [D loss: 0.335267, acc.: 88.28%] [G loss: 0.956715]\n",
      "epoch:18 step:17565 [D loss: 0.471612, acc.: 89.06%] [G loss: 1.071838]\n",
      "epoch:18 step:17566 [D loss: 0.283032, acc.: 90.62%] [G loss: 1.087877]\n",
      "epoch:18 step:17567 [D loss: 0.243936, acc.: 98.44%] [G loss: 1.319154]\n",
      "epoch:18 step:17568 [D loss: 0.264208, acc.: 94.53%] [G loss: 1.375890]\n",
      "epoch:18 step:17569 [D loss: 0.648928, acc.: 58.59%] [G loss: 1.283393]\n",
      "epoch:18 step:17570 [D loss: 0.443842, acc.: 88.28%] [G loss: 1.068097]\n",
      "epoch:18 step:17571 [D loss: 0.714070, acc.: 53.91%] [G loss: 1.165365]\n",
      "epoch:18 step:17572 [D loss: 0.443298, acc.: 67.97%] [G loss: 1.490939]\n",
      "epoch:18 step:17573 [D loss: 0.267529, acc.: 93.75%] [G loss: 0.764593]\n",
      "epoch:18 step:17574 [D loss: 0.194826, acc.: 99.22%] [G loss: 1.359537]\n",
      "epoch:18 step:17575 [D loss: 0.192036, acc.: 99.22%] [G loss: 1.331545]\n",
      "epoch:18 step:17576 [D loss: 0.976111, acc.: 54.69%] [G loss: 1.271373]\n",
      "epoch:18 step:17577 [D loss: 0.761086, acc.: 54.69%] [G loss: 1.168517]\n",
      "epoch:18 step:17578 [D loss: 0.665490, acc.: 57.81%] [G loss: 1.073524]\n",
      "epoch:18 step:17579 [D loss: 0.380708, acc.: 72.66%] [G loss: 1.074566]\n",
      "epoch:18 step:17580 [D loss: 0.197231, acc.: 98.44%] [G loss: 1.273751]\n",
      "epoch:18 step:17581 [D loss: 0.865241, acc.: 42.19%] [G loss: 1.230015]\n",
      "epoch:18 step:17582 [D loss: 0.798387, acc.: 50.00%] [G loss: 1.181719]\n",
      "epoch:18 step:17583 [D loss: 0.808941, acc.: 36.72%] [G loss: 0.721555]\n",
      "epoch:18 step:17584 [D loss: 0.745908, acc.: 49.22%] [G loss: 1.031772]\n",
      "epoch:18 step:17585 [D loss: 0.668381, acc.: 59.38%] [G loss: 1.106018]\n",
      "epoch:18 step:17586 [D loss: 0.613401, acc.: 65.62%] [G loss: 0.999573]\n",
      "epoch:18 step:17587 [D loss: 0.662350, acc.: 59.38%] [G loss: 0.951458]\n",
      "epoch:18 step:17588 [D loss: 0.620548, acc.: 64.06%] [G loss: 1.040464]\n",
      "epoch:18 step:17589 [D loss: 0.711620, acc.: 50.78%] [G loss: 0.736962]\n",
      "epoch:18 step:17590 [D loss: 0.659438, acc.: 64.84%] [G loss: 1.130090]\n",
      "epoch:18 step:17591 [D loss: 0.698050, acc.: 54.69%] [G loss: 0.757773]\n",
      "epoch:18 step:17592 [D loss: 0.650833, acc.: 54.69%] [G loss: 1.102430]\n",
      "epoch:18 step:17593 [D loss: 0.362835, acc.: 92.97%] [G loss: 1.315480]\n",
      "epoch:18 step:17594 [D loss: 0.258909, acc.: 94.53%] [G loss: 1.460684]\n",
      "epoch:18 step:17595 [D loss: 0.380104, acc.: 92.19%] [G loss: 1.060743]\n",
      "epoch:18 step:17596 [D loss: 0.218599, acc.: 98.44%] [G loss: 1.278872]\n",
      "epoch:18 step:17597 [D loss: 0.700340, acc.: 57.81%] [G loss: 1.333207]\n",
      "epoch:18 step:17598 [D loss: 0.253560, acc.: 96.88%] [G loss: 1.576558]\n",
      "epoch:18 step:17599 [D loss: 0.532006, acc.: 76.56%] [G loss: 1.343978]\n",
      "epoch:18 step:17600 [D loss: 0.998484, acc.: 26.56%] [G loss: 1.370485]\n",
      "##############\n",
      "[4.40394505 2.39666712 6.64610308 5.90609788 5.09911976 5.84762131\n",
      " 5.21048399 5.38101031 5.70973855 5.06999375]\n",
      "##########\n",
      "epoch:18 step:17601 [D loss: 0.818777, acc.: 40.62%] [G loss: 1.147802]\n",
      "epoch:18 step:17602 [D loss: 0.678754, acc.: 58.59%] [G loss: 1.314871]\n",
      "epoch:18 step:17603 [D loss: 0.716902, acc.: 54.69%] [G loss: 1.307738]\n",
      "epoch:18 step:17604 [D loss: 0.738674, acc.: 56.25%] [G loss: 1.175209]\n",
      "epoch:18 step:17605 [D loss: 0.530794, acc.: 76.56%] [G loss: 1.159016]\n",
      "epoch:18 step:17606 [D loss: 0.737432, acc.: 55.47%] [G loss: 1.156994]\n",
      "epoch:18 step:17607 [D loss: 0.571416, acc.: 66.41%] [G loss: 1.058125]\n",
      "epoch:18 step:17608 [D loss: 0.495748, acc.: 82.03%] [G loss: 1.143202]\n",
      "epoch:18 step:17609 [D loss: 0.458413, acc.: 87.50%] [G loss: 1.007782]\n",
      "epoch:18 step:17610 [D loss: 0.593774, acc.: 69.53%] [G loss: 1.155304]\n",
      "epoch:18 step:17611 [D loss: 0.463377, acc.: 88.28%] [G loss: 1.033730]\n",
      "epoch:18 step:17612 [D loss: 0.613156, acc.: 58.59%] [G loss: 0.859565]\n",
      "epoch:18 step:17613 [D loss: 0.830098, acc.: 37.50%] [G loss: 1.191458]\n",
      "epoch:18 step:17614 [D loss: 0.581825, acc.: 66.41%] [G loss: 1.230938]\n",
      "epoch:18 step:17615 [D loss: 0.497960, acc.: 78.91%] [G loss: 1.173847]\n",
      "epoch:18 step:17616 [D loss: 0.497030, acc.: 82.81%] [G loss: 1.175012]\n",
      "epoch:18 step:17617 [D loss: 0.698672, acc.: 57.03%] [G loss: 1.126536]\n",
      "epoch:18 step:17618 [D loss: 0.740376, acc.: 53.91%] [G loss: 1.187716]\n",
      "epoch:18 step:17619 [D loss: 0.765052, acc.: 57.81%] [G loss: 1.001139]\n",
      "epoch:18 step:17620 [D loss: 0.550303, acc.: 76.56%] [G loss: 0.856568]\n",
      "epoch:18 step:17621 [D loss: 0.522892, acc.: 78.12%] [G loss: 1.052193]\n",
      "epoch:18 step:17622 [D loss: 0.417851, acc.: 89.06%] [G loss: 1.070604]\n",
      "epoch:18 step:17623 [D loss: 0.590936, acc.: 74.22%] [G loss: 0.528437]\n",
      "epoch:18 step:17624 [D loss: 0.612825, acc.: 70.31%] [G loss: 0.567014]\n",
      "epoch:18 step:17625 [D loss: 0.553246, acc.: 76.56%] [G loss: 0.723788]\n",
      "epoch:18 step:17626 [D loss: 0.459875, acc.: 87.50%] [G loss: 0.387379]\n",
      "epoch:18 step:17627 [D loss: 1.219586, acc.: 29.69%] [G loss: 1.059818]\n",
      "epoch:18 step:17628 [D loss: 0.748458, acc.: 53.91%] [G loss: 0.913268]\n",
      "epoch:18 step:17629 [D loss: 0.804261, acc.: 40.62%] [G loss: 1.001237]\n",
      "epoch:18 step:17630 [D loss: 0.622142, acc.: 67.19%] [G loss: 0.938352]\n",
      "epoch:18 step:17631 [D loss: 0.514099, acc.: 78.12%] [G loss: 1.136577]\n",
      "epoch:18 step:17632 [D loss: 0.523290, acc.: 81.25%] [G loss: 0.897998]\n",
      "epoch:18 step:17633 [D loss: 0.633162, acc.: 65.62%] [G loss: 1.014874]\n",
      "epoch:18 step:17634 [D loss: 0.336349, acc.: 92.19%] [G loss: 0.934831]\n",
      "epoch:18 step:17635 [D loss: 0.313470, acc.: 94.53%] [G loss: 0.757286]\n",
      "epoch:18 step:17636 [D loss: 0.545205, acc.: 81.25%] [G loss: 1.045084]\n",
      "epoch:18 step:17637 [D loss: 0.631507, acc.: 66.41%] [G loss: 1.091487]\n",
      "epoch:18 step:17638 [D loss: 0.700410, acc.: 56.25%] [G loss: 0.321998]\n",
      "epoch:18 step:17639 [D loss: 0.658542, acc.: 58.59%] [G loss: 0.886928]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17640 [D loss: 0.438113, acc.: 71.09%] [G loss: 0.927457]\n",
      "epoch:18 step:17641 [D loss: 0.385728, acc.: 85.94%] [G loss: 1.206990]\n",
      "epoch:18 step:17642 [D loss: 0.691937, acc.: 60.94%] [G loss: 1.291989]\n",
      "epoch:18 step:17643 [D loss: 0.550451, acc.: 78.91%] [G loss: 1.172968]\n",
      "epoch:18 step:17644 [D loss: 0.718905, acc.: 59.38%] [G loss: 1.216476]\n",
      "epoch:18 step:17645 [D loss: 0.812877, acc.: 42.97%] [G loss: 1.093377]\n",
      "epoch:18 step:17646 [D loss: 0.790249, acc.: 50.00%] [G loss: 1.242027]\n",
      "epoch:18 step:17647 [D loss: 0.368051, acc.: 90.62%] [G loss: 1.275594]\n",
      "epoch:18 step:17648 [D loss: 0.447983, acc.: 84.38%] [G loss: 1.279834]\n",
      "epoch:18 step:17649 [D loss: 0.552662, acc.: 74.22%] [G loss: 1.444394]\n",
      "epoch:18 step:17650 [D loss: 0.674827, acc.: 67.19%] [G loss: 1.011943]\n",
      "epoch:18 step:17651 [D loss: 0.689706, acc.: 53.12%] [G loss: 1.045379]\n",
      "epoch:18 step:17652 [D loss: 0.311511, acc.: 96.09%] [G loss: 1.304457]\n",
      "epoch:18 step:17653 [D loss: 0.784792, acc.: 48.44%] [G loss: 1.081385]\n",
      "epoch:18 step:17654 [D loss: 0.657716, acc.: 61.72%] [G loss: 1.093028]\n",
      "epoch:18 step:17655 [D loss: 0.793258, acc.: 46.09%] [G loss: 0.875847]\n",
      "epoch:18 step:17656 [D loss: 0.685405, acc.: 56.25%] [G loss: 1.030312]\n",
      "epoch:18 step:17657 [D loss: 0.336872, acc.: 91.41%] [G loss: 0.913815]\n",
      "epoch:18 step:17658 [D loss: 0.250995, acc.: 95.31%] [G loss: 1.160697]\n",
      "epoch:18 step:17659 [D loss: 0.717442, acc.: 60.16%] [G loss: 1.203256]\n",
      "epoch:18 step:17660 [D loss: 0.234964, acc.: 97.66%] [G loss: 1.120733]\n",
      "epoch:18 step:17661 [D loss: 0.352208, acc.: 94.53%] [G loss: 0.966579]\n",
      "epoch:18 step:17662 [D loss: 0.251464, acc.: 96.09%] [G loss: 1.350937]\n",
      "epoch:18 step:17663 [D loss: 0.675815, acc.: 56.25%] [G loss: 1.338147]\n",
      "epoch:18 step:17664 [D loss: 0.661215, acc.: 58.59%] [G loss: 0.604930]\n",
      "epoch:18 step:17665 [D loss: 1.130637, acc.: 23.44%] [G loss: 0.985223]\n",
      "epoch:18 step:17666 [D loss: 0.575386, acc.: 72.66%] [G loss: 0.946138]\n",
      "epoch:18 step:17667 [D loss: 0.575451, acc.: 74.22%] [G loss: 0.892118]\n",
      "epoch:18 step:17668 [D loss: 0.295490, acc.: 91.41%] [G loss: 1.151965]\n",
      "epoch:18 step:17669 [D loss: 0.699272, acc.: 57.03%] [G loss: 0.918922]\n",
      "epoch:18 step:17670 [D loss: 0.288006, acc.: 90.62%] [G loss: 1.113045]\n",
      "epoch:18 step:17671 [D loss: 0.296436, acc.: 93.75%] [G loss: 1.188076]\n",
      "epoch:18 step:17672 [D loss: 0.240996, acc.: 95.31%] [G loss: 1.353126]\n",
      "epoch:18 step:17673 [D loss: 0.813425, acc.: 43.75%] [G loss: 1.100053]\n",
      "epoch:18 step:17674 [D loss: 0.544861, acc.: 82.03%] [G loss: 1.262026]\n",
      "epoch:18 step:17675 [D loss: 0.538725, acc.: 78.91%] [G loss: 1.148415]\n",
      "epoch:18 step:17676 [D loss: 0.590568, acc.: 69.53%] [G loss: 1.083013]\n",
      "epoch:18 step:17677 [D loss: 0.675977, acc.: 57.81%] [G loss: 1.015383]\n",
      "epoch:18 step:17678 [D loss: 0.594158, acc.: 65.62%] [G loss: 1.107715]\n",
      "epoch:18 step:17679 [D loss: 0.715561, acc.: 52.34%] [G loss: 0.984894]\n",
      "epoch:18 step:17680 [D loss: 0.718624, acc.: 53.91%] [G loss: 0.998309]\n",
      "epoch:18 step:17681 [D loss: 0.430632, acc.: 79.69%] [G loss: 0.912432]\n",
      "epoch:18 step:17682 [D loss: 0.577293, acc.: 68.75%] [G loss: 1.133287]\n",
      "epoch:18 step:17683 [D loss: 0.509663, acc.: 77.34%] [G loss: 0.972039]\n",
      "epoch:18 step:17684 [D loss: 0.737823, acc.: 52.34%] [G loss: 0.902146]\n",
      "epoch:18 step:17685 [D loss: 0.620891, acc.: 66.41%] [G loss: 1.048944]\n",
      "epoch:18 step:17686 [D loss: 0.834601, acc.: 39.06%] [G loss: 0.887111]\n",
      "epoch:18 step:17687 [D loss: 0.303733, acc.: 94.53%] [G loss: 0.926937]\n",
      "epoch:18 step:17688 [D loss: 0.345199, acc.: 82.81%] [G loss: 0.804319]\n",
      "epoch:18 step:17689 [D loss: 0.635391, acc.: 61.72%] [G loss: 1.013937]\n",
      "epoch:18 step:17690 [D loss: 0.672921, acc.: 57.03%] [G loss: 0.820747]\n",
      "epoch:18 step:17691 [D loss: 0.599507, acc.: 65.62%] [G loss: 1.044178]\n",
      "epoch:18 step:17692 [D loss: 0.665145, acc.: 62.50%] [G loss: 1.039858]\n",
      "epoch:18 step:17693 [D loss: 0.508087, acc.: 82.81%] [G loss: 0.989891]\n",
      "epoch:18 step:17694 [D loss: 0.535544, acc.: 77.34%] [G loss: 0.738515]\n",
      "epoch:18 step:17695 [D loss: 0.741859, acc.: 47.66%] [G loss: 0.956889]\n",
      "epoch:18 step:17696 [D loss: 0.585291, acc.: 71.88%] [G loss: 0.942178]\n",
      "epoch:18 step:17697 [D loss: 0.561742, acc.: 75.00%] [G loss: 0.940518]\n",
      "epoch:18 step:17698 [D loss: 0.617363, acc.: 65.62%] [G loss: 0.789078]\n",
      "epoch:18 step:17699 [D loss: 0.624703, acc.: 69.53%] [G loss: 1.006408]\n",
      "epoch:18 step:17700 [D loss: 0.276449, acc.: 96.09%] [G loss: 1.229806]\n",
      "epoch:18 step:17701 [D loss: 0.647095, acc.: 57.81%] [G loss: 1.088019]\n",
      "epoch:18 step:17702 [D loss: 0.774803, acc.: 46.09%] [G loss: 0.743692]\n",
      "epoch:18 step:17703 [D loss: 0.693509, acc.: 57.03%] [G loss: 1.011243]\n",
      "epoch:18 step:17704 [D loss: 0.723825, acc.: 53.91%] [G loss: 0.983161]\n",
      "epoch:18 step:17705 [D loss: 0.558014, acc.: 71.09%] [G loss: 0.857923]\n",
      "epoch:18 step:17706 [D loss: 0.478919, acc.: 82.03%] [G loss: 0.974343]\n",
      "epoch:18 step:17707 [D loss: 0.311015, acc.: 85.16%] [G loss: 1.024240]\n",
      "epoch:18 step:17708 [D loss: 0.414958, acc.: 86.72%] [G loss: 1.042369]\n",
      "epoch:18 step:17709 [D loss: 0.696937, acc.: 60.94%] [G loss: 1.061950]\n",
      "epoch:18 step:17710 [D loss: 0.649678, acc.: 64.84%] [G loss: 0.943663]\n",
      "epoch:18 step:17711 [D loss: 0.333312, acc.: 86.72%] [G loss: 1.079099]\n",
      "epoch:18 step:17712 [D loss: 0.755814, acc.: 44.53%] [G loss: 0.955700]\n",
      "epoch:18 step:17713 [D loss: 0.261712, acc.: 96.88%] [G loss: 0.811360]\n",
      "epoch:18 step:17714 [D loss: 0.290667, acc.: 88.28%] [G loss: 1.082725]\n",
      "epoch:18 step:17715 [D loss: 0.667609, acc.: 53.12%] [G loss: 1.237931]\n",
      "epoch:18 step:17716 [D loss: 0.291126, acc.: 97.66%] [G loss: 1.191554]\n",
      "epoch:18 step:17717 [D loss: 0.214901, acc.: 95.31%] [G loss: 1.393482]\n",
      "epoch:18 step:17718 [D loss: 0.174184, acc.: 98.44%] [G loss: 1.446829]\n",
      "epoch:18 step:17719 [D loss: 0.152193, acc.: 100.00%] [G loss: 1.481299]\n",
      "epoch:18 step:17720 [D loss: 0.227731, acc.: 91.41%] [G loss: 1.549551]\n",
      "epoch:18 step:17721 [D loss: 0.437005, acc.: 84.38%] [G loss: 1.517183]\n",
      "epoch:18 step:17722 [D loss: 0.615373, acc.: 69.53%] [G loss: 1.162029]\n",
      "epoch:18 step:17723 [D loss: 0.182417, acc.: 97.66%] [G loss: 1.541133]\n",
      "epoch:18 step:17724 [D loss: 0.700302, acc.: 59.38%] [G loss: 1.102044]\n",
      "epoch:18 step:17725 [D loss: 0.713273, acc.: 52.34%] [G loss: 1.187309]\n",
      "epoch:18 step:17726 [D loss: 0.490155, acc.: 82.03%] [G loss: 1.216444]\n",
      "epoch:18 step:17727 [D loss: 0.313411, acc.: 93.75%] [G loss: 1.331572]\n",
      "epoch:18 step:17728 [D loss: 0.815810, acc.: 46.88%] [G loss: 1.196539]\n",
      "epoch:18 step:17729 [D loss: 0.741676, acc.: 42.97%] [G loss: 0.751988]\n",
      "epoch:18 step:17730 [D loss: 0.890966, acc.: 36.72%] [G loss: 1.269806]\n",
      "epoch:18 step:17731 [D loss: 0.330794, acc.: 91.41%] [G loss: 1.059033]\n",
      "epoch:18 step:17732 [D loss: 0.414130, acc.: 89.06%] [G loss: 1.143337]\n",
      "epoch:18 step:17733 [D loss: 0.297567, acc.: 93.75%] [G loss: 1.222496]\n",
      "epoch:18 step:17734 [D loss: 0.564261, acc.: 74.22%] [G loss: 1.205957]\n",
      "epoch:18 step:17735 [D loss: 0.517193, acc.: 77.34%] [G loss: 0.886057]\n",
      "epoch:18 step:17736 [D loss: 0.657509, acc.: 60.16%] [G loss: 0.774426]\n",
      "epoch:18 step:17737 [D loss: 0.375394, acc.: 89.06%] [G loss: 1.114843]\n",
      "epoch:18 step:17738 [D loss: 0.284742, acc.: 87.50%] [G loss: 0.927671]\n",
      "epoch:18 step:17739 [D loss: 0.282912, acc.: 97.66%] [G loss: 1.116589]\n",
      "epoch:18 step:17740 [D loss: 0.282148, acc.: 87.50%] [G loss: 1.746083]\n",
      "epoch:18 step:17741 [D loss: 0.234080, acc.: 100.00%] [G loss: 1.648978]\n",
      "epoch:18 step:17742 [D loss: 0.907237, acc.: 32.81%] [G loss: 0.964454]\n",
      "epoch:18 step:17743 [D loss: 1.247640, acc.: 16.41%] [G loss: 0.818309]\n",
      "epoch:18 step:17744 [D loss: 0.695809, acc.: 55.47%] [G loss: 1.524978]\n",
      "epoch:18 step:17745 [D loss: 0.857334, acc.: 50.78%] [G loss: 1.742726]\n",
      "epoch:18 step:17746 [D loss: 0.686274, acc.: 52.34%] [G loss: 1.516691]\n",
      "epoch:18 step:17747 [D loss: 0.693972, acc.: 52.34%] [G loss: 0.536889]\n",
      "epoch:18 step:17748 [D loss: 1.361341, acc.: 53.12%] [G loss: 1.658677]\n",
      "epoch:18 step:17749 [D loss: 0.329068, acc.: 89.06%] [G loss: 1.844398]\n",
      "epoch:18 step:17750 [D loss: 0.189718, acc.: 99.22%] [G loss: 1.883168]\n",
      "epoch:18 step:17751 [D loss: 0.192882, acc.: 97.66%] [G loss: 1.824930]\n",
      "epoch:18 step:17752 [D loss: 0.225018, acc.: 96.88%] [G loss: 1.836005]\n",
      "epoch:18 step:17753 [D loss: 0.185424, acc.: 98.44%] [G loss: 1.728486]\n",
      "epoch:18 step:17754 [D loss: 0.832306, acc.: 50.00%] [G loss: 0.814552]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17755 [D loss: 0.135584, acc.: 99.22%] [G loss: 2.051157]\n",
      "epoch:18 step:17756 [D loss: 0.181581, acc.: 98.44%] [G loss: 0.582449]\n",
      "epoch:18 step:17757 [D loss: 0.871357, acc.: 50.78%] [G loss: 0.742711]\n",
      "epoch:18 step:17758 [D loss: 0.897882, acc.: 52.34%] [G loss: 0.433767]\n",
      "epoch:18 step:17759 [D loss: 1.254100, acc.: 14.06%] [G loss: 0.200044]\n",
      "epoch:18 step:17760 [D loss: 0.686070, acc.: 55.47%] [G loss: 0.813848]\n",
      "epoch:18 step:17761 [D loss: 0.887204, acc.: 32.03%] [G loss: 1.128953]\n",
      "epoch:18 step:17762 [D loss: 0.655283, acc.: 58.59%] [G loss: 0.629271]\n",
      "epoch:18 step:17763 [D loss: 0.583805, acc.: 69.53%] [G loss: 0.751535]\n",
      "epoch:18 step:17764 [D loss: 0.414747, acc.: 86.72%] [G loss: 1.668787]\n",
      "epoch:18 step:17765 [D loss: 0.544404, acc.: 66.41%] [G loss: 0.761070]\n",
      "epoch:18 step:17766 [D loss: 0.381553, acc.: 78.91%] [G loss: 1.191036]\n",
      "epoch:18 step:17767 [D loss: 0.499798, acc.: 75.78%] [G loss: 1.675044]\n",
      "epoch:18 step:17768 [D loss: 0.524201, acc.: 75.00%] [G loss: 1.596800]\n",
      "epoch:18 step:17769 [D loss: 0.441209, acc.: 83.59%] [G loss: 1.515253]\n",
      "epoch:18 step:17770 [D loss: 0.839794, acc.: 50.78%] [G loss: 1.016961]\n",
      "epoch:18 step:17771 [D loss: 0.686401, acc.: 60.16%] [G loss: 1.024034]\n",
      "epoch:18 step:17772 [D loss: 0.508456, acc.: 75.00%] [G loss: 1.026359]\n",
      "epoch:18 step:17773 [D loss: 0.623089, acc.: 69.53%] [G loss: 0.936763]\n",
      "epoch:18 step:17774 [D loss: 0.517546, acc.: 79.69%] [G loss: 1.115698]\n",
      "epoch:18 step:17775 [D loss: 0.384675, acc.: 85.16%] [G loss: 0.989754]\n",
      "epoch:18 step:17776 [D loss: 0.626703, acc.: 67.19%] [G loss: 1.129590]\n",
      "epoch:18 step:17777 [D loss: 0.314472, acc.: 89.84%] [G loss: 0.995810]\n",
      "epoch:18 step:17778 [D loss: 0.179628, acc.: 99.22%] [G loss: 1.425019]\n",
      "epoch:18 step:17779 [D loss: 0.463443, acc.: 81.25%] [G loss: 1.401155]\n",
      "epoch:18 step:17780 [D loss: 0.651042, acc.: 60.16%] [G loss: 1.011791]\n",
      "epoch:18 step:17781 [D loss: 0.647415, acc.: 60.94%] [G loss: 1.436560]\n",
      "epoch:18 step:17782 [D loss: 0.610100, acc.: 71.09%] [G loss: 1.358840]\n",
      "epoch:18 step:17783 [D loss: 0.576340, acc.: 67.19%] [G loss: 0.858504]\n",
      "epoch:18 step:17784 [D loss: 0.466665, acc.: 86.72%] [G loss: 0.746366]\n",
      "epoch:18 step:17785 [D loss: 0.203655, acc.: 96.88%] [G loss: 0.825797]\n",
      "epoch:18 step:17786 [D loss: 0.832573, acc.: 46.88%] [G loss: 1.519340]\n",
      "epoch:18 step:17787 [D loss: 0.290739, acc.: 95.31%] [G loss: 1.583135]\n",
      "epoch:18 step:17788 [D loss: 0.507050, acc.: 78.12%] [G loss: 1.327491]\n",
      "epoch:18 step:17789 [D loss: 0.618803, acc.: 67.19%] [G loss: 1.436050]\n",
      "epoch:18 step:17790 [D loss: 0.148716, acc.: 99.22%] [G loss: 1.199856]\n",
      "epoch:18 step:17791 [D loss: 0.321218, acc.: 87.50%] [G loss: 1.336871]\n",
      "epoch:18 step:17792 [D loss: 0.241527, acc.: 90.62%] [G loss: 1.693580]\n",
      "epoch:18 step:17793 [D loss: 0.108449, acc.: 99.22%] [G loss: 1.880022]\n",
      "epoch:18 step:17794 [D loss: 0.682631, acc.: 57.81%] [G loss: 1.641324]\n",
      "epoch:18 step:17795 [D loss: 0.458540, acc.: 80.47%] [G loss: 1.505849]\n",
      "epoch:18 step:17796 [D loss: 0.792224, acc.: 54.69%] [G loss: 1.217370]\n",
      "epoch:18 step:17797 [D loss: 0.671219, acc.: 53.91%] [G loss: 1.412860]\n",
      "epoch:18 step:17798 [D loss: 0.308196, acc.: 89.84%] [G loss: 1.045873]\n",
      "epoch:18 step:17799 [D loss: 0.374476, acc.: 78.91%] [G loss: 1.192767]\n",
      "epoch:18 step:17800 [D loss: 0.395601, acc.: 71.88%] [G loss: 1.548568]\n",
      "##############\n",
      "[4.03419939 2.79359277 6.42421397 5.76007008 4.80551242 5.78546452\n",
      " 5.01702594 5.15078878 5.51839087 4.81935121]\n",
      "##########\n",
      "epoch:18 step:17801 [D loss: 0.302401, acc.: 92.97%] [G loss: 1.135033]\n",
      "epoch:18 step:17802 [D loss: 0.204805, acc.: 96.88%] [G loss: 1.578242]\n",
      "epoch:18 step:17803 [D loss: 0.105547, acc.: 100.00%] [G loss: 1.595462]\n",
      "epoch:19 step:17804 [D loss: 0.557179, acc.: 72.66%] [G loss: 1.487808]\n",
      "epoch:19 step:17805 [D loss: 0.718520, acc.: 58.59%] [G loss: 1.252651]\n",
      "epoch:19 step:17806 [D loss: 0.733566, acc.: 52.34%] [G loss: 0.862035]\n",
      "epoch:19 step:17807 [D loss: 0.839522, acc.: 49.22%] [G loss: 1.260008]\n",
      "epoch:19 step:17808 [D loss: 1.087968, acc.: 21.09%] [G loss: 0.916273]\n",
      "epoch:19 step:17809 [D loss: 0.724410, acc.: 53.91%] [G loss: 1.028684]\n",
      "epoch:19 step:17810 [D loss: 0.593908, acc.: 67.97%] [G loss: 1.315201]\n",
      "epoch:19 step:17811 [D loss: 0.611845, acc.: 69.53%] [G loss: 0.540764]\n",
      "epoch:19 step:17812 [D loss: 0.381374, acc.: 89.06%] [G loss: 1.283084]\n",
      "epoch:19 step:17813 [D loss: 0.660262, acc.: 58.59%] [G loss: 1.121127]\n",
      "epoch:19 step:17814 [D loss: 0.653256, acc.: 65.62%] [G loss: 0.870511]\n",
      "epoch:19 step:17815 [D loss: 1.756397, acc.: 42.19%] [G loss: 1.448456]\n",
      "epoch:19 step:17816 [D loss: 0.769278, acc.: 57.81%] [G loss: 1.754187]\n",
      "epoch:19 step:17817 [D loss: 0.922421, acc.: 41.41%] [G loss: 1.783410]\n",
      "epoch:19 step:17818 [D loss: 0.720546, acc.: 56.25%] [G loss: 2.160300]\n",
      "epoch:19 step:17819 [D loss: 0.729025, acc.: 51.56%] [G loss: 1.519741]\n",
      "epoch:19 step:17820 [D loss: 0.758170, acc.: 50.78%] [G loss: 1.640150]\n",
      "epoch:19 step:17821 [D loss: 0.683435, acc.: 59.38%] [G loss: 1.493747]\n",
      "epoch:19 step:17822 [D loss: 0.776436, acc.: 40.62%] [G loss: 1.193366]\n",
      "epoch:19 step:17823 [D loss: 0.792227, acc.: 39.84%] [G loss: 1.113697]\n",
      "epoch:19 step:17824 [D loss: 0.681458, acc.: 56.25%] [G loss: 1.147553]\n",
      "epoch:19 step:17825 [D loss: 0.751229, acc.: 51.56%] [G loss: 1.309584]\n",
      "epoch:19 step:17826 [D loss: 0.719507, acc.: 56.25%] [G loss: 1.239674]\n",
      "epoch:19 step:17827 [D loss: 0.751768, acc.: 53.12%] [G loss: 0.946915]\n",
      "epoch:19 step:17828 [D loss: 0.622157, acc.: 64.06%] [G loss: 0.956455]\n",
      "epoch:19 step:17829 [D loss: 0.657028, acc.: 54.69%] [G loss: 1.224681]\n",
      "epoch:19 step:17830 [D loss: 0.529008, acc.: 75.00%] [G loss: 1.098615]\n",
      "epoch:19 step:17831 [D loss: 0.648895, acc.: 53.91%] [G loss: 1.199389]\n",
      "epoch:19 step:17832 [D loss: 0.597205, acc.: 60.16%] [G loss: 1.309380]\n",
      "epoch:19 step:17833 [D loss: 0.567272, acc.: 70.31%] [G loss: 1.181363]\n",
      "epoch:19 step:17834 [D loss: 0.479037, acc.: 78.12%] [G loss: 1.563630]\n",
      "epoch:19 step:17835 [D loss: 0.422197, acc.: 87.50%] [G loss: 1.278174]\n",
      "epoch:19 step:17836 [D loss: 0.376241, acc.: 93.75%] [G loss: 1.373002]\n",
      "epoch:19 step:17837 [D loss: 0.434963, acc.: 89.84%] [G loss: 2.379077]\n",
      "epoch:19 step:17838 [D loss: 0.309446, acc.: 94.53%] [G loss: 1.422016]\n",
      "epoch:19 step:17839 [D loss: 0.254544, acc.: 96.09%] [G loss: 1.566671]\n",
      "epoch:19 step:17840 [D loss: 0.849866, acc.: 54.69%] [G loss: 1.329817]\n",
      "epoch:19 step:17841 [D loss: 1.133031, acc.: 33.59%] [G loss: 0.980457]\n",
      "epoch:19 step:17842 [D loss: 0.916914, acc.: 39.06%] [G loss: 0.835434]\n",
      "epoch:19 step:17843 [D loss: 0.632170, acc.: 62.50%] [G loss: 0.871966]\n",
      "epoch:19 step:17844 [D loss: 0.589224, acc.: 67.19%] [G loss: 0.757172]\n",
      "epoch:19 step:17845 [D loss: 0.566200, acc.: 72.66%] [G loss: 0.958877]\n",
      "epoch:19 step:17846 [D loss: 0.475655, acc.: 79.69%] [G loss: 0.914209]\n",
      "epoch:19 step:17847 [D loss: 0.578118, acc.: 67.19%] [G loss: 0.764637]\n",
      "epoch:19 step:17848 [D loss: 0.725307, acc.: 58.59%] [G loss: 0.752115]\n",
      "epoch:19 step:17849 [D loss: 0.554577, acc.: 73.44%] [G loss: 0.891053]\n",
      "epoch:19 step:17850 [D loss: 0.655537, acc.: 58.59%] [G loss: 0.805773]\n",
      "epoch:19 step:17851 [D loss: 0.704071, acc.: 52.34%] [G loss: 0.879902]\n",
      "epoch:19 step:17852 [D loss: 0.680578, acc.: 56.25%] [G loss: 0.836041]\n",
      "epoch:19 step:17853 [D loss: 0.623031, acc.: 62.50%] [G loss: 0.880467]\n",
      "epoch:19 step:17854 [D loss: 0.601342, acc.: 71.88%] [G loss: 0.730908]\n",
      "epoch:19 step:17855 [D loss: 0.688743, acc.: 58.59%] [G loss: 0.819061]\n",
      "epoch:19 step:17856 [D loss: 0.637576, acc.: 62.50%] [G loss: 0.908858]\n",
      "epoch:19 step:17857 [D loss: 1.010692, acc.: 34.38%] [G loss: 0.949852]\n",
      "epoch:19 step:17858 [D loss: 0.662165, acc.: 59.38%] [G loss: 0.978044]\n",
      "epoch:19 step:17859 [D loss: 0.604220, acc.: 68.75%] [G loss: 0.958196]\n",
      "epoch:19 step:17860 [D loss: 0.528894, acc.: 78.12%] [G loss: 1.023022]\n",
      "epoch:19 step:17861 [D loss: 0.530120, acc.: 74.22%] [G loss: 1.045246]\n",
      "epoch:19 step:17862 [D loss: 0.570700, acc.: 77.34%] [G loss: 1.033538]\n",
      "epoch:19 step:17863 [D loss: 0.614421, acc.: 63.28%] [G loss: 1.067840]\n",
      "epoch:19 step:17864 [D loss: 0.658608, acc.: 60.16%] [G loss: 0.985080]\n",
      "epoch:19 step:17865 [D loss: 0.862843, acc.: 38.28%] [G loss: 0.858310]\n",
      "epoch:19 step:17866 [D loss: 0.653533, acc.: 64.84%] [G loss: 0.999292]\n",
      "epoch:19 step:17867 [D loss: 0.721269, acc.: 53.12%] [G loss: 0.947242]\n",
      "epoch:19 step:17868 [D loss: 0.665928, acc.: 60.94%] [G loss: 0.842952]\n",
      "epoch:19 step:17869 [D loss: 0.696998, acc.: 60.16%] [G loss: 0.757099]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:17870 [D loss: 0.684433, acc.: 57.03%] [G loss: 0.854421]\n",
      "epoch:19 step:17871 [D loss: 0.660274, acc.: 59.38%] [G loss: 0.821618]\n",
      "epoch:19 step:17872 [D loss: 0.539800, acc.: 78.12%] [G loss: 0.899161]\n",
      "epoch:19 step:17873 [D loss: 0.640326, acc.: 64.84%] [G loss: 0.904451]\n",
      "epoch:19 step:17874 [D loss: 0.409619, acc.: 81.25%] [G loss: 1.038817]\n",
      "epoch:19 step:17875 [D loss: 0.450284, acc.: 85.94%] [G loss: 1.021344]\n",
      "epoch:19 step:17876 [D loss: 0.508743, acc.: 78.12%] [G loss: 0.922728]\n",
      "epoch:19 step:17877 [D loss: 0.586658, acc.: 66.41%] [G loss: 1.034073]\n",
      "epoch:19 step:17878 [D loss: 0.345742, acc.: 83.59%] [G loss: 0.957713]\n",
      "epoch:19 step:17879 [D loss: 0.404816, acc.: 92.97%] [G loss: 1.135581]\n",
      "epoch:19 step:17880 [D loss: 0.336786, acc.: 94.53%] [G loss: 1.097638]\n",
      "epoch:19 step:17881 [D loss: 0.730918, acc.: 55.47%] [G loss: 0.964584]\n",
      "epoch:19 step:17882 [D loss: 0.717580, acc.: 53.12%] [G loss: 1.137993]\n",
      "epoch:19 step:17883 [D loss: 0.736779, acc.: 56.25%] [G loss: 1.027996]\n",
      "epoch:19 step:17884 [D loss: 0.729971, acc.: 51.56%] [G loss: 0.859435]\n",
      "epoch:19 step:17885 [D loss: 0.586854, acc.: 78.12%] [G loss: 1.139069]\n",
      "epoch:19 step:17886 [D loss: 0.582177, acc.: 70.31%] [G loss: 0.840151]\n",
      "epoch:19 step:17887 [D loss: 0.664698, acc.: 59.38%] [G loss: 1.014310]\n",
      "epoch:19 step:17888 [D loss: 0.523246, acc.: 81.25%] [G loss: 1.139341]\n",
      "epoch:19 step:17889 [D loss: 0.648790, acc.: 65.62%] [G loss: 0.841487]\n",
      "epoch:19 step:17890 [D loss: 0.656546, acc.: 59.38%] [G loss: 1.016305]\n",
      "epoch:19 step:17891 [D loss: 0.633429, acc.: 64.84%] [G loss: 0.890655]\n",
      "epoch:19 step:17892 [D loss: 0.580474, acc.: 75.78%] [G loss: 1.076000]\n",
      "epoch:19 step:17893 [D loss: 0.652705, acc.: 60.16%] [G loss: 1.021872]\n",
      "epoch:19 step:17894 [D loss: 0.780694, acc.: 44.53%] [G loss: 0.854986]\n",
      "epoch:19 step:17895 [D loss: 0.554233, acc.: 76.56%] [G loss: 1.133559]\n",
      "epoch:19 step:17896 [D loss: 0.471496, acc.: 85.16%] [G loss: 0.953468]\n",
      "epoch:19 step:17897 [D loss: 0.588021, acc.: 71.09%] [G loss: 0.834550]\n",
      "epoch:19 step:17898 [D loss: 0.677173, acc.: 59.38%] [G loss: 0.881875]\n",
      "epoch:19 step:17899 [D loss: 0.638347, acc.: 63.28%] [G loss: 0.886385]\n",
      "epoch:19 step:17900 [D loss: 0.620559, acc.: 63.28%] [G loss: 0.734683]\n",
      "epoch:19 step:17901 [D loss: 0.534051, acc.: 76.56%] [G loss: 0.816191]\n",
      "epoch:19 step:17902 [D loss: 0.652683, acc.: 60.94%] [G loss: 0.861026]\n",
      "epoch:19 step:17903 [D loss: 0.432469, acc.: 81.25%] [G loss: 1.131822]\n",
      "epoch:19 step:17904 [D loss: 0.645741, acc.: 57.81%] [G loss: 1.047763]\n",
      "epoch:19 step:17905 [D loss: 0.819822, acc.: 42.97%] [G loss: 0.957982]\n",
      "epoch:19 step:17906 [D loss: 0.746252, acc.: 42.97%] [G loss: 0.986499]\n",
      "epoch:19 step:17907 [D loss: 0.800405, acc.: 47.66%] [G loss: 0.921800]\n",
      "epoch:19 step:17908 [D loss: 0.522449, acc.: 82.81%] [G loss: 1.056499]\n",
      "epoch:19 step:17909 [D loss: 0.689817, acc.: 53.12%] [G loss: 0.893077]\n",
      "epoch:19 step:17910 [D loss: 0.413977, acc.: 86.72%] [G loss: 0.756191]\n",
      "epoch:19 step:17911 [D loss: 0.641169, acc.: 58.59%] [G loss: 0.839648]\n",
      "epoch:19 step:17912 [D loss: 0.707281, acc.: 51.56%] [G loss: 1.267342]\n",
      "epoch:19 step:17913 [D loss: 0.818067, acc.: 39.06%] [G loss: 1.089858]\n",
      "epoch:19 step:17914 [D loss: 0.524978, acc.: 76.56%] [G loss: 1.186111]\n",
      "epoch:19 step:17915 [D loss: 0.586665, acc.: 64.06%] [G loss: 1.019333]\n",
      "epoch:19 step:17916 [D loss: 0.431881, acc.: 89.84%] [G loss: 1.135445]\n",
      "epoch:19 step:17917 [D loss: 0.429695, acc.: 81.25%] [G loss: 1.048068]\n",
      "epoch:19 step:17918 [D loss: 0.498847, acc.: 76.56%] [G loss: 1.021161]\n",
      "epoch:19 step:17919 [D loss: 0.622147, acc.: 66.41%] [G loss: 1.044282]\n",
      "epoch:19 step:17920 [D loss: 0.590754, acc.: 67.97%] [G loss: 0.952427]\n",
      "epoch:19 step:17921 [D loss: 0.458364, acc.: 83.59%] [G loss: 0.917509]\n",
      "epoch:19 step:17922 [D loss: 0.314450, acc.: 85.94%] [G loss: 1.030560]\n",
      "epoch:19 step:17923 [D loss: 0.528069, acc.: 74.22%] [G loss: 1.088177]\n",
      "epoch:19 step:17924 [D loss: 0.464154, acc.: 75.78%] [G loss: 1.162093]\n",
      "epoch:19 step:17925 [D loss: 0.406262, acc.: 88.28%] [G loss: 1.204536]\n",
      "epoch:19 step:17926 [D loss: 0.655082, acc.: 61.72%] [G loss: 1.024177]\n",
      "epoch:19 step:17927 [D loss: 0.766571, acc.: 48.44%] [G loss: 1.217183]\n",
      "epoch:19 step:17928 [D loss: 0.787760, acc.: 47.66%] [G loss: 0.745276]\n",
      "epoch:19 step:17929 [D loss: 0.715641, acc.: 56.25%] [G loss: 1.132598]\n",
      "epoch:19 step:17930 [D loss: 0.670221, acc.: 59.38%] [G loss: 1.317274]\n",
      "epoch:19 step:17931 [D loss: 0.634398, acc.: 67.19%] [G loss: 1.082406]\n",
      "epoch:19 step:17932 [D loss: 0.424501, acc.: 89.06%] [G loss: 0.953483]\n",
      "epoch:19 step:17933 [D loss: 0.322209, acc.: 88.28%] [G loss: 0.904526]\n",
      "epoch:19 step:17934 [D loss: 0.356305, acc.: 90.62%] [G loss: 1.360421]\n",
      "epoch:19 step:17935 [D loss: 0.528804, acc.: 77.34%] [G loss: 1.467800]\n",
      "epoch:19 step:17936 [D loss: 0.519016, acc.: 75.78%] [G loss: 0.950847]\n",
      "epoch:19 step:17937 [D loss: 0.521127, acc.: 75.78%] [G loss: 1.222981]\n",
      "epoch:19 step:17938 [D loss: 0.508505, acc.: 77.34%] [G loss: 1.137048]\n",
      "epoch:19 step:17939 [D loss: 0.576901, acc.: 71.09%] [G loss: 1.178954]\n",
      "epoch:19 step:17940 [D loss: 0.664683, acc.: 60.16%] [G loss: 1.018911]\n",
      "epoch:19 step:17941 [D loss: 0.507176, acc.: 78.91%] [G loss: 0.999620]\n",
      "epoch:19 step:17942 [D loss: 0.311222, acc.: 91.41%] [G loss: 1.147300]\n",
      "epoch:19 step:17943 [D loss: 0.603095, acc.: 69.53%] [G loss: 0.727987]\n",
      "epoch:19 step:17944 [D loss: 0.617716, acc.: 61.72%] [G loss: 1.014394]\n",
      "epoch:19 step:17945 [D loss: 0.744976, acc.: 54.69%] [G loss: 1.108281]\n",
      "epoch:19 step:17946 [D loss: 0.380941, acc.: 78.12%] [G loss: 0.928083]\n",
      "epoch:19 step:17947 [D loss: 0.511467, acc.: 75.00%] [G loss: 1.074147]\n",
      "epoch:19 step:17948 [D loss: 0.282972, acc.: 86.72%] [G loss: 1.192434]\n",
      "epoch:19 step:17949 [D loss: 0.362413, acc.: 91.41%] [G loss: 1.367681]\n",
      "epoch:19 step:17950 [D loss: 0.756683, acc.: 53.91%] [G loss: 1.249282]\n",
      "epoch:19 step:17951 [D loss: 0.839060, acc.: 40.62%] [G loss: 1.075217]\n",
      "epoch:19 step:17952 [D loss: 0.700975, acc.: 62.50%] [G loss: 1.025251]\n",
      "epoch:19 step:17953 [D loss: 0.468746, acc.: 71.09%] [G loss: 1.246589]\n",
      "epoch:19 step:17954 [D loss: 0.276252, acc.: 92.19%] [G loss: 1.417235]\n",
      "epoch:19 step:17955 [D loss: 0.483029, acc.: 78.91%] [G loss: 1.387703]\n",
      "epoch:19 step:17956 [D loss: 0.943970, acc.: 30.47%] [G loss: 1.394063]\n",
      "epoch:19 step:17957 [D loss: 0.742631, acc.: 57.81%] [G loss: 1.205060]\n",
      "epoch:19 step:17958 [D loss: 0.664095, acc.: 59.38%] [G loss: 1.154221]\n",
      "epoch:19 step:17959 [D loss: 0.720430, acc.: 51.56%] [G loss: 1.071865]\n",
      "epoch:19 step:17960 [D loss: 0.753973, acc.: 50.00%] [G loss: 0.785993]\n",
      "epoch:19 step:17961 [D loss: 0.786033, acc.: 44.53%] [G loss: 1.152836]\n",
      "epoch:19 step:17962 [D loss: 0.621700, acc.: 67.97%] [G loss: 1.016097]\n",
      "epoch:19 step:17963 [D loss: 0.679419, acc.: 65.62%] [G loss: 0.901976]\n",
      "epoch:19 step:17964 [D loss: 0.701744, acc.: 53.91%] [G loss: 1.097325]\n",
      "epoch:19 step:17965 [D loss: 0.415152, acc.: 78.91%] [G loss: 0.952510]\n",
      "epoch:19 step:17966 [D loss: 0.574518, acc.: 71.88%] [G loss: 0.681754]\n",
      "epoch:19 step:17967 [D loss: 0.632291, acc.: 65.62%] [G loss: 0.895763]\n",
      "epoch:19 step:17968 [D loss: 0.474012, acc.: 85.16%] [G loss: 1.003976]\n",
      "epoch:19 step:17969 [D loss: 0.735057, acc.: 49.22%] [G loss: 1.079116]\n",
      "epoch:19 step:17970 [D loss: 0.747770, acc.: 47.66%] [G loss: 0.836271]\n",
      "epoch:19 step:17971 [D loss: 0.759697, acc.: 51.56%] [G loss: 1.102749]\n",
      "epoch:19 step:17972 [D loss: 0.695732, acc.: 53.91%] [G loss: 1.007638]\n",
      "epoch:19 step:17973 [D loss: 0.581024, acc.: 72.66%] [G loss: 1.032193]\n",
      "epoch:19 step:17974 [D loss: 0.732943, acc.: 51.56%] [G loss: 1.042056]\n",
      "epoch:19 step:17975 [D loss: 0.637729, acc.: 62.50%] [G loss: 0.935033]\n",
      "epoch:19 step:17976 [D loss: 0.788438, acc.: 41.41%] [G loss: 1.165386]\n",
      "epoch:19 step:17977 [D loss: 0.669560, acc.: 58.59%] [G loss: 0.954877]\n",
      "epoch:19 step:17978 [D loss: 0.678519, acc.: 60.16%] [G loss: 0.960173]\n",
      "epoch:19 step:17979 [D loss: 0.662998, acc.: 61.72%] [G loss: 0.940605]\n",
      "epoch:19 step:17980 [D loss: 0.720140, acc.: 50.00%] [G loss: 0.900839]\n",
      "epoch:19 step:17981 [D loss: 0.503289, acc.: 78.91%] [G loss: 0.950581]\n",
      "epoch:19 step:17982 [D loss: 0.496981, acc.: 83.59%] [G loss: 0.971465]\n",
      "epoch:19 step:17983 [D loss: 0.708256, acc.: 53.91%] [G loss: 1.086332]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:17984 [D loss: 0.657758, acc.: 58.59%] [G loss: 1.090562]\n",
      "epoch:19 step:17985 [D loss: 0.722862, acc.: 51.56%] [G loss: 0.980470]\n",
      "epoch:19 step:17986 [D loss: 0.672306, acc.: 57.81%] [G loss: 1.037631]\n",
      "epoch:19 step:17987 [D loss: 0.583304, acc.: 72.66%] [G loss: 1.084888]\n",
      "epoch:19 step:17988 [D loss: 0.561384, acc.: 68.75%] [G loss: 1.040987]\n",
      "epoch:19 step:17989 [D loss: 0.625501, acc.: 63.28%] [G loss: 1.160703]\n",
      "epoch:19 step:17990 [D loss: 0.691066, acc.: 53.12%] [G loss: 0.688943]\n",
      "epoch:19 step:17991 [D loss: 0.866445, acc.: 36.72%] [G loss: 0.992134]\n",
      "epoch:19 step:17992 [D loss: 0.716768, acc.: 50.00%] [G loss: 1.110346]\n",
      "epoch:19 step:17993 [D loss: 0.655998, acc.: 60.16%] [G loss: 1.068856]\n",
      "epoch:19 step:17994 [D loss: 0.774513, acc.: 42.19%] [G loss: 1.006742]\n",
      "epoch:19 step:17995 [D loss: 0.490432, acc.: 80.47%] [G loss: 1.112452]\n",
      "epoch:19 step:17996 [D loss: 0.600870, acc.: 65.62%] [G loss: 1.197929]\n",
      "epoch:19 step:17997 [D loss: 0.428231, acc.: 86.72%] [G loss: 1.155208]\n",
      "epoch:19 step:17998 [D loss: 0.538756, acc.: 77.34%] [G loss: 1.128174]\n",
      "epoch:19 step:17999 [D loss: 0.457247, acc.: 80.47%] [G loss: 1.187247]\n",
      "epoch:19 step:18000 [D loss: 0.511120, acc.: 80.47%] [G loss: 1.155707]\n",
      "##############\n",
      "[4.05865807 2.66341005 6.61531825 5.92193658 4.77321802 6.14404876\n",
      " 5.53513241 5.73651305 5.97981671 5.11561128]\n",
      "##########\n",
      "epoch:19 step:18001 [D loss: 0.460818, acc.: 82.03%] [G loss: 1.301734]\n",
      "epoch:19 step:18002 [D loss: 0.871907, acc.: 42.19%] [G loss: 1.265721]\n",
      "epoch:19 step:18003 [D loss: 0.486020, acc.: 84.38%] [G loss: 1.015950]\n",
      "epoch:19 step:18004 [D loss: 0.247560, acc.: 96.09%] [G loss: 1.066725]\n",
      "epoch:19 step:18005 [D loss: 0.666967, acc.: 60.16%] [G loss: 1.168031]\n",
      "epoch:19 step:18006 [D loss: 0.458429, acc.: 87.50%] [G loss: 1.124362]\n",
      "epoch:19 step:18007 [D loss: 0.280955, acc.: 97.66%] [G loss: 0.907655]\n",
      "epoch:19 step:18008 [D loss: 0.603957, acc.: 71.88%] [G loss: 0.891388]\n",
      "epoch:19 step:18009 [D loss: 0.483918, acc.: 73.44%] [G loss: 1.178398]\n",
      "epoch:19 step:18010 [D loss: 0.262369, acc.: 86.72%] [G loss: 1.343414]\n",
      "epoch:19 step:18011 [D loss: 0.306965, acc.: 96.09%] [G loss: 1.217184]\n",
      "epoch:19 step:18012 [D loss: 0.265690, acc.: 97.66%] [G loss: 1.095194]\n",
      "epoch:19 step:18013 [D loss: 0.827924, acc.: 53.91%] [G loss: 1.227894]\n",
      "epoch:19 step:18014 [D loss: 1.048121, acc.: 33.59%] [G loss: 0.906506]\n",
      "epoch:19 step:18015 [D loss: 0.913190, acc.: 28.12%] [G loss: 0.366541]\n",
      "epoch:19 step:18016 [D loss: 0.831603, acc.: 44.53%] [G loss: 1.033125]\n",
      "epoch:19 step:18017 [D loss: 0.700377, acc.: 57.81%] [G loss: 0.902390]\n",
      "epoch:19 step:18018 [D loss: 0.877328, acc.: 28.91%] [G loss: 0.933863]\n",
      "epoch:19 step:18019 [D loss: 0.647349, acc.: 62.50%] [G loss: 0.568019]\n",
      "epoch:19 step:18020 [D loss: 0.444155, acc.: 82.81%] [G loss: 0.945990]\n",
      "epoch:19 step:18021 [D loss: 1.142473, acc.: 50.78%] [G loss: 0.502313]\n",
      "epoch:19 step:18022 [D loss: 0.388643, acc.: 94.53%] [G loss: 0.971771]\n",
      "epoch:19 step:18023 [D loss: 0.271521, acc.: 89.84%] [G loss: 0.912465]\n",
      "epoch:19 step:18024 [D loss: 0.272971, acc.: 94.53%] [G loss: 1.197673]\n",
      "epoch:19 step:18025 [D loss: 0.281744, acc.: 96.88%] [G loss: 1.424552]\n",
      "epoch:19 step:18026 [D loss: 0.599015, acc.: 64.84%] [G loss: 1.577168]\n",
      "epoch:19 step:18027 [D loss: 0.907421, acc.: 32.81%] [G loss: 1.009300]\n",
      "epoch:19 step:18028 [D loss: 0.606653, acc.: 66.41%] [G loss: 1.368442]\n",
      "epoch:19 step:18029 [D loss: 0.743228, acc.: 49.22%] [G loss: 1.130117]\n",
      "epoch:19 step:18030 [D loss: 0.700248, acc.: 58.59%] [G loss: 1.289591]\n",
      "epoch:19 step:18031 [D loss: 0.687297, acc.: 58.59%] [G loss: 1.131277]\n",
      "epoch:19 step:18032 [D loss: 0.680989, acc.: 53.91%] [G loss: 1.234688]\n",
      "epoch:19 step:18033 [D loss: 0.314064, acc.: 82.03%] [G loss: 1.075682]\n",
      "epoch:19 step:18034 [D loss: 0.262309, acc.: 93.75%] [G loss: 1.276053]\n",
      "epoch:19 step:18035 [D loss: 0.186005, acc.: 100.00%] [G loss: 1.315824]\n",
      "epoch:19 step:18036 [D loss: 0.621524, acc.: 67.97%] [G loss: 1.375374]\n",
      "epoch:19 step:18037 [D loss: 0.321480, acc.: 90.62%] [G loss: 1.191541]\n",
      "epoch:19 step:18038 [D loss: 0.214077, acc.: 94.53%] [G loss: 1.208940]\n",
      "epoch:19 step:18039 [D loss: 0.569006, acc.: 76.56%] [G loss: 1.277254]\n",
      "epoch:19 step:18040 [D loss: 0.350977, acc.: 91.41%] [G loss: 1.407442]\n",
      "epoch:19 step:18041 [D loss: 0.194821, acc.: 96.88%] [G loss: 1.020338]\n",
      "epoch:19 step:18042 [D loss: 0.478957, acc.: 82.81%] [G loss: 0.917727]\n",
      "epoch:19 step:18043 [D loss: 0.553002, acc.: 71.88%] [G loss: 1.355875]\n",
      "epoch:19 step:18044 [D loss: 0.821304, acc.: 42.97%] [G loss: 1.045014]\n",
      "epoch:19 step:18045 [D loss: 0.628969, acc.: 68.75%] [G loss: 1.084863]\n",
      "epoch:19 step:18046 [D loss: 0.410334, acc.: 82.03%] [G loss: 0.715979]\n",
      "epoch:19 step:18047 [D loss: 0.729563, acc.: 51.56%] [G loss: 1.148718]\n",
      "epoch:19 step:18048 [D loss: 0.812850, acc.: 47.66%] [G loss: 1.143437]\n",
      "epoch:19 step:18049 [D loss: 0.689027, acc.: 51.56%] [G loss: 0.769011]\n",
      "epoch:19 step:18050 [D loss: 1.127955, acc.: 17.97%] [G loss: 0.925730]\n",
      "epoch:19 step:18051 [D loss: 0.692778, acc.: 57.03%] [G loss: 0.981108]\n",
      "epoch:19 step:18052 [D loss: 0.565799, acc.: 71.88%] [G loss: 0.744611]\n",
      "epoch:19 step:18053 [D loss: 1.144899, acc.: 16.41%] [G loss: 1.150841]\n",
      "epoch:19 step:18054 [D loss: 0.606724, acc.: 65.62%] [G loss: 1.116074]\n",
      "epoch:19 step:18055 [D loss: 0.621268, acc.: 66.41%] [G loss: 1.213683]\n",
      "epoch:19 step:18056 [D loss: 0.579156, acc.: 71.09%] [G loss: 1.093551]\n",
      "epoch:19 step:18057 [D loss: 0.652384, acc.: 57.03%] [G loss: 1.174675]\n",
      "epoch:19 step:18058 [D loss: 0.193988, acc.: 99.22%] [G loss: 1.346564]\n",
      "epoch:19 step:18059 [D loss: 0.190268, acc.: 97.66%] [G loss: 1.341486]\n",
      "epoch:19 step:18060 [D loss: 0.365427, acc.: 88.28%] [G loss: 1.435797]\n",
      "epoch:19 step:18061 [D loss: 0.698358, acc.: 57.03%] [G loss: 1.149507]\n",
      "epoch:19 step:18062 [D loss: 0.215780, acc.: 98.44%] [G loss: 1.351031]\n",
      "epoch:19 step:18063 [D loss: 0.399967, acc.: 91.41%] [G loss: 1.352672]\n",
      "epoch:19 step:18064 [D loss: 0.190323, acc.: 99.22%] [G loss: 1.263907]\n",
      "epoch:19 step:18065 [D loss: 0.769019, acc.: 48.44%] [G loss: 1.323014]\n",
      "epoch:19 step:18066 [D loss: 0.433801, acc.: 77.34%] [G loss: 1.098648]\n",
      "epoch:19 step:18067 [D loss: 0.639065, acc.: 63.28%] [G loss: 0.967342]\n",
      "epoch:19 step:18068 [D loss: 0.704630, acc.: 61.72%] [G loss: 0.141722]\n",
      "epoch:19 step:18069 [D loss: 0.913761, acc.: 25.78%] [G loss: 1.173122]\n",
      "epoch:19 step:18070 [D loss: 0.890822, acc.: 25.00%] [G loss: 1.265531]\n",
      "epoch:19 step:18071 [D loss: 0.854088, acc.: 38.28%] [G loss: 1.174090]\n",
      "epoch:19 step:18072 [D loss: 0.465989, acc.: 79.69%] [G loss: 0.940829]\n",
      "epoch:19 step:18073 [D loss: 0.620728, acc.: 60.16%] [G loss: 1.215737]\n",
      "epoch:19 step:18074 [D loss: 0.381499, acc.: 92.19%] [G loss: 0.292697]\n",
      "epoch:19 step:18075 [D loss: 0.555920, acc.: 74.22%] [G loss: 1.203411]\n",
      "epoch:19 step:18076 [D loss: 0.621381, acc.: 63.28%] [G loss: 0.357808]\n",
      "epoch:19 step:18077 [D loss: 0.485663, acc.: 85.94%] [G loss: 0.454870]\n",
      "epoch:19 step:18078 [D loss: 0.775597, acc.: 41.41%] [G loss: 0.920845]\n",
      "epoch:19 step:18079 [D loss: 0.696190, acc.: 59.38%] [G loss: 1.559687]\n",
      "epoch:19 step:18080 [D loss: 0.501242, acc.: 69.53%] [G loss: 1.681237]\n",
      "epoch:19 step:18081 [D loss: 0.780033, acc.: 55.47%] [G loss: 1.201669]\n",
      "epoch:19 step:18082 [D loss: 0.548944, acc.: 71.88%] [G loss: 1.281665]\n",
      "epoch:19 step:18083 [D loss: 0.680893, acc.: 57.03%] [G loss: 1.012132]\n",
      "epoch:19 step:18084 [D loss: 0.588727, acc.: 71.09%] [G loss: 1.124338]\n",
      "epoch:19 step:18085 [D loss: 0.383714, acc.: 90.62%] [G loss: 1.413410]\n",
      "epoch:19 step:18086 [D loss: 0.624490, acc.: 59.38%] [G loss: 1.249796]\n",
      "epoch:19 step:18087 [D loss: 0.711059, acc.: 51.56%] [G loss: 1.382487]\n",
      "epoch:19 step:18088 [D loss: 0.680079, acc.: 52.34%] [G loss: 1.135039]\n",
      "epoch:19 step:18089 [D loss: 0.714855, acc.: 51.56%] [G loss: 1.147027]\n",
      "epoch:19 step:18090 [D loss: 0.669240, acc.: 66.41%] [G loss: 1.211688]\n",
      "epoch:19 step:18091 [D loss: 0.734095, acc.: 52.34%] [G loss: 0.811387]\n",
      "epoch:19 step:18092 [D loss: 0.651088, acc.: 60.94%] [G loss: 1.033403]\n",
      "epoch:19 step:18093 [D loss: 0.566218, acc.: 74.22%] [G loss: 1.095098]\n",
      "epoch:19 step:18094 [D loss: 0.689951, acc.: 59.38%] [G loss: 0.908934]\n",
      "epoch:19 step:18095 [D loss: 0.716148, acc.: 56.25%] [G loss: 0.942443]\n",
      "epoch:19 step:18096 [D loss: 0.667296, acc.: 56.25%] [G loss: 0.651289]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18097 [D loss: 0.623292, acc.: 64.84%] [G loss: 1.069759]\n",
      "epoch:19 step:18098 [D loss: 0.391589, acc.: 81.25%] [G loss: 0.880441]\n",
      "epoch:19 step:18099 [D loss: 0.378955, acc.: 96.09%] [G loss: 1.510377]\n",
      "epoch:19 step:18100 [D loss: 0.403734, acc.: 75.00%] [G loss: 1.484358]\n",
      "epoch:19 step:18101 [D loss: 0.194978, acc.: 99.22%] [G loss: 1.848798]\n",
      "epoch:19 step:18102 [D loss: 0.454637, acc.: 70.31%] [G loss: 1.557137]\n",
      "epoch:19 step:18103 [D loss: 0.306316, acc.: 93.75%] [G loss: 1.530816]\n",
      "epoch:19 step:18104 [D loss: 0.749016, acc.: 47.66%] [G loss: 1.050828]\n",
      "epoch:19 step:18105 [D loss: 0.619697, acc.: 66.41%] [G loss: 1.297018]\n",
      "epoch:19 step:18106 [D loss: 0.440919, acc.: 88.28%] [G loss: 1.427598]\n",
      "epoch:19 step:18107 [D loss: 0.700167, acc.: 57.81%] [G loss: 1.258836]\n",
      "epoch:19 step:18108 [D loss: 0.823406, acc.: 53.91%] [G loss: 0.805604]\n",
      "epoch:19 step:18109 [D loss: 0.690682, acc.: 55.47%] [G loss: 1.165849]\n",
      "epoch:19 step:18110 [D loss: 0.464307, acc.: 87.50%] [G loss: 0.542005]\n",
      "epoch:19 step:18111 [D loss: 0.962563, acc.: 24.22%] [G loss: 0.940217]\n",
      "epoch:19 step:18112 [D loss: 1.029710, acc.: 17.97%] [G loss: 0.912369]\n",
      "epoch:19 step:18113 [D loss: 0.655728, acc.: 60.16%] [G loss: 0.712904]\n",
      "epoch:19 step:18114 [D loss: 0.925914, acc.: 23.44%] [G loss: 0.549817]\n",
      "epoch:19 step:18115 [D loss: 0.731627, acc.: 50.78%] [G loss: 0.779876]\n",
      "epoch:19 step:18116 [D loss: 0.717023, acc.: 51.56%] [G loss: 0.629397]\n",
      "epoch:19 step:18117 [D loss: 0.540318, acc.: 69.53%] [G loss: 0.883667]\n",
      "epoch:19 step:18118 [D loss: 0.676805, acc.: 57.81%] [G loss: 0.907687]\n",
      "epoch:19 step:18119 [D loss: 0.564104, acc.: 75.00%] [G loss: 0.900858]\n",
      "epoch:19 step:18120 [D loss: 0.655857, acc.: 60.16%] [G loss: 0.945610]\n",
      "epoch:19 step:18121 [D loss: 0.771309, acc.: 50.78%] [G loss: 0.897487]\n",
      "epoch:19 step:18122 [D loss: 0.609513, acc.: 67.97%] [G loss: 0.887343]\n",
      "epoch:19 step:18123 [D loss: 0.550732, acc.: 79.69%] [G loss: 0.992853]\n",
      "epoch:19 step:18124 [D loss: 0.734431, acc.: 55.47%] [G loss: 0.963896]\n",
      "epoch:19 step:18125 [D loss: 0.710506, acc.: 52.34%] [G loss: 0.957244]\n",
      "epoch:19 step:18126 [D loss: 0.684329, acc.: 60.16%] [G loss: 1.100254]\n",
      "epoch:19 step:18127 [D loss: 0.678135, acc.: 57.03%] [G loss: 1.017387]\n",
      "epoch:19 step:18128 [D loss: 0.629247, acc.: 64.84%] [G loss: 1.003115]\n",
      "epoch:19 step:18129 [D loss: 0.666420, acc.: 61.72%] [G loss: 0.875514]\n",
      "epoch:19 step:18130 [D loss: 0.450507, acc.: 82.81%] [G loss: 1.136693]\n",
      "epoch:19 step:18131 [D loss: 0.496574, acc.: 86.72%] [G loss: 0.975043]\n",
      "epoch:19 step:18132 [D loss: 0.695513, acc.: 53.12%] [G loss: 0.898894]\n",
      "epoch:19 step:18133 [D loss: 0.823206, acc.: 37.50%] [G loss: 0.847033]\n",
      "epoch:19 step:18134 [D loss: 0.733634, acc.: 53.91%] [G loss: 0.999944]\n",
      "epoch:19 step:18135 [D loss: 0.726135, acc.: 53.91%] [G loss: 0.739491]\n",
      "epoch:19 step:18136 [D loss: 0.722336, acc.: 53.91%] [G loss: 0.958186]\n",
      "epoch:19 step:18137 [D loss: 0.607376, acc.: 67.97%] [G loss: 0.844388]\n",
      "epoch:19 step:18138 [D loss: 0.674693, acc.: 53.91%] [G loss: 0.896352]\n",
      "epoch:19 step:18139 [D loss: 0.573109, acc.: 68.75%] [G loss: 1.033172]\n",
      "epoch:19 step:18140 [D loss: 0.710905, acc.: 53.12%] [G loss: 0.991056]\n",
      "epoch:19 step:18141 [D loss: 0.612708, acc.: 69.53%] [G loss: 0.981028]\n",
      "epoch:19 step:18142 [D loss: 0.739229, acc.: 50.00%] [G loss: 0.895037]\n",
      "epoch:19 step:18143 [D loss: 0.692772, acc.: 53.91%] [G loss: 1.008977]\n",
      "epoch:19 step:18144 [D loss: 0.684068, acc.: 53.12%] [G loss: 0.834906]\n",
      "epoch:19 step:18145 [D loss: 0.415674, acc.: 81.25%] [G loss: 0.974308]\n",
      "epoch:19 step:18146 [D loss: 0.300544, acc.: 89.84%] [G loss: 1.023985]\n",
      "epoch:19 step:18147 [D loss: 0.319799, acc.: 90.62%] [G loss: 0.761099]\n",
      "epoch:19 step:18148 [D loss: 0.272476, acc.: 90.62%] [G loss: 1.154186]\n",
      "epoch:19 step:18149 [D loss: 0.240070, acc.: 98.44%] [G loss: 1.351568]\n",
      "epoch:19 step:18150 [D loss: 0.246933, acc.: 92.97%] [G loss: 1.378453]\n",
      "epoch:19 step:18151 [D loss: 0.724405, acc.: 53.91%] [G loss: 1.388140]\n",
      "epoch:19 step:18152 [D loss: 0.720069, acc.: 57.03%] [G loss: 1.110252]\n",
      "epoch:19 step:18153 [D loss: 0.532172, acc.: 75.00%] [G loss: 1.119341]\n",
      "epoch:19 step:18154 [D loss: 0.719965, acc.: 59.38%] [G loss: 1.076038]\n",
      "epoch:19 step:18155 [D loss: 0.720761, acc.: 57.03%] [G loss: 0.897242]\n",
      "epoch:19 step:18156 [D loss: 0.791190, acc.: 46.88%] [G loss: 0.905345]\n",
      "epoch:19 step:18157 [D loss: 0.719607, acc.: 53.12%] [G loss: 0.982275]\n",
      "epoch:19 step:18158 [D loss: 0.726206, acc.: 50.78%] [G loss: 0.850210]\n",
      "epoch:19 step:18159 [D loss: 0.671596, acc.: 59.38%] [G loss: 0.918473]\n",
      "epoch:19 step:18160 [D loss: 0.663582, acc.: 59.38%] [G loss: 0.952959]\n",
      "epoch:19 step:18161 [D loss: 0.682860, acc.: 51.56%] [G loss: 0.863089]\n",
      "epoch:19 step:18162 [D loss: 0.598782, acc.: 69.53%] [G loss: 0.883059]\n",
      "epoch:19 step:18163 [D loss: 0.745176, acc.: 50.00%] [G loss: 0.882793]\n",
      "epoch:19 step:18164 [D loss: 0.741091, acc.: 49.22%] [G loss: 0.916372]\n",
      "epoch:19 step:18165 [D loss: 0.532064, acc.: 79.69%] [G loss: 0.975575]\n",
      "epoch:19 step:18166 [D loss: 0.441239, acc.: 83.59%] [G loss: 0.823582]\n",
      "epoch:19 step:18167 [D loss: 0.515689, acc.: 82.81%] [G loss: 0.823860]\n",
      "epoch:19 step:18168 [D loss: 0.349334, acc.: 92.97%] [G loss: 1.035441]\n",
      "epoch:19 step:18169 [D loss: 0.281430, acc.: 88.28%] [G loss: 1.033237]\n",
      "epoch:19 step:18170 [D loss: 0.510007, acc.: 82.03%] [G loss: 1.083391]\n",
      "epoch:19 step:18171 [D loss: 0.588804, acc.: 72.66%] [G loss: 0.837896]\n",
      "epoch:19 step:18172 [D loss: 0.637513, acc.: 63.28%] [G loss: 1.005041]\n",
      "epoch:19 step:18173 [D loss: 0.638377, acc.: 63.28%] [G loss: 0.876159]\n",
      "epoch:19 step:18174 [D loss: 0.521599, acc.: 75.78%] [G loss: 0.897921]\n",
      "epoch:19 step:18175 [D loss: 0.651970, acc.: 57.03%] [G loss: 0.925658]\n",
      "epoch:19 step:18176 [D loss: 0.649064, acc.: 64.84%] [G loss: 0.884540]\n",
      "epoch:19 step:18177 [D loss: 0.746703, acc.: 39.06%] [G loss: 1.053327]\n",
      "epoch:19 step:18178 [D loss: 0.534538, acc.: 79.69%] [G loss: 1.009053]\n",
      "epoch:19 step:18179 [D loss: 0.694133, acc.: 54.69%] [G loss: 1.015573]\n",
      "epoch:19 step:18180 [D loss: 0.265692, acc.: 93.75%] [G loss: 0.844451]\n",
      "epoch:19 step:18181 [D loss: 0.315092, acc.: 84.38%] [G loss: 1.067359]\n",
      "epoch:19 step:18182 [D loss: 0.673573, acc.: 60.16%] [G loss: 1.131988]\n",
      "epoch:19 step:18183 [D loss: 0.590416, acc.: 70.31%] [G loss: 0.844851]\n",
      "epoch:19 step:18184 [D loss: 0.627399, acc.: 63.28%] [G loss: 1.140725]\n",
      "epoch:19 step:18185 [D loss: 0.670011, acc.: 57.03%] [G loss: 0.903230]\n",
      "epoch:19 step:18186 [D loss: 0.600773, acc.: 67.97%] [G loss: 1.046828]\n",
      "epoch:19 step:18187 [D loss: 0.486916, acc.: 81.25%] [G loss: 0.972609]\n",
      "epoch:19 step:18188 [D loss: 0.723030, acc.: 50.78%] [G loss: 0.845485]\n",
      "epoch:19 step:18189 [D loss: 0.720201, acc.: 57.81%] [G loss: 1.052453]\n",
      "epoch:19 step:18190 [D loss: 0.641460, acc.: 60.94%] [G loss: 0.894322]\n",
      "epoch:19 step:18191 [D loss: 0.714096, acc.: 51.56%] [G loss: 0.854317]\n",
      "epoch:19 step:18192 [D loss: 0.433600, acc.: 89.06%] [G loss: 0.861679]\n",
      "epoch:19 step:18193 [D loss: 0.504332, acc.: 76.56%] [G loss: 1.017456]\n",
      "epoch:19 step:18194 [D loss: 0.710006, acc.: 53.91%] [G loss: 1.148866]\n",
      "epoch:19 step:18195 [D loss: 0.696036, acc.: 53.12%] [G loss: 0.844784]\n",
      "epoch:19 step:18196 [D loss: 0.408766, acc.: 77.34%] [G loss: 1.041237]\n",
      "epoch:19 step:18197 [D loss: 0.752532, acc.: 45.31%] [G loss: 1.101776]\n",
      "epoch:19 step:18198 [D loss: 0.715977, acc.: 50.00%] [G loss: 0.855381]\n",
      "epoch:19 step:18199 [D loss: 0.295773, acc.: 84.38%] [G loss: 1.052515]\n",
      "epoch:19 step:18200 [D loss: 0.237815, acc.: 92.97%] [G loss: 1.314454]\n",
      "##############\n",
      "[4.2895615  2.72050759 6.7150374  5.76847143 4.58118192 6.01668006\n",
      " 5.54111952 5.94098362 5.8864064  5.16261115]\n",
      "##########\n",
      "epoch:19 step:18201 [D loss: 0.434358, acc.: 66.41%] [G loss: 1.270993]\n",
      "epoch:19 step:18202 [D loss: 0.178147, acc.: 97.66%] [G loss: 1.252082]\n",
      "epoch:19 step:18203 [D loss: 0.181850, acc.: 97.66%] [G loss: 1.076939]\n",
      "epoch:19 step:18204 [D loss: 0.246995, acc.: 96.09%] [G loss: 1.661115]\n",
      "epoch:19 step:18205 [D loss: 0.153311, acc.: 98.44%] [G loss: 1.552303]\n",
      "epoch:19 step:18206 [D loss: 0.438363, acc.: 88.28%] [G loss: 0.756567]\n",
      "epoch:19 step:18207 [D loss: 0.139464, acc.: 99.22%] [G loss: 1.616024]\n",
      "epoch:19 step:18208 [D loss: 0.129654, acc.: 100.00%] [G loss: 1.758316]\n",
      "epoch:19 step:18209 [D loss: 0.146678, acc.: 99.22%] [G loss: 1.640107]\n",
      "epoch:19 step:18210 [D loss: 0.262994, acc.: 90.62%] [G loss: 1.750665]\n",
      "epoch:19 step:18211 [D loss: 0.311373, acc.: 93.75%] [G loss: 1.462524]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18212 [D loss: 0.170184, acc.: 98.44%] [G loss: 1.740457]\n",
      "epoch:19 step:18213 [D loss: 0.315256, acc.: 91.41%] [G loss: 2.039844]\n",
      "epoch:19 step:18214 [D loss: 1.055540, acc.: 49.22%] [G loss: 0.586981]\n",
      "epoch:19 step:18215 [D loss: 0.864290, acc.: 50.00%] [G loss: 1.563724]\n",
      "epoch:19 step:18216 [D loss: 0.919017, acc.: 50.78%] [G loss: 2.006362]\n",
      "epoch:19 step:18217 [D loss: 0.487324, acc.: 77.34%] [G loss: 1.769621]\n",
      "epoch:19 step:18218 [D loss: 0.740945, acc.: 58.59%] [G loss: 0.548377]\n",
      "epoch:19 step:18219 [D loss: 0.842842, acc.: 40.62%] [G loss: 1.234045]\n",
      "epoch:19 step:18220 [D loss: 0.449553, acc.: 78.91%] [G loss: 1.521633]\n",
      "epoch:19 step:18221 [D loss: 0.862207, acc.: 55.47%] [G loss: 1.833795]\n",
      "epoch:19 step:18222 [D loss: 0.584202, acc.: 67.19%] [G loss: 1.348390]\n",
      "epoch:19 step:18223 [D loss: 0.971822, acc.: 39.06%] [G loss: 1.678478]\n",
      "epoch:19 step:18224 [D loss: 1.065428, acc.: 42.19%] [G loss: 1.094256]\n",
      "epoch:19 step:18225 [D loss: 0.940798, acc.: 46.88%] [G loss: 1.236277]\n",
      "epoch:19 step:18226 [D loss: 0.859568, acc.: 42.19%] [G loss: 1.101650]\n",
      "epoch:19 step:18227 [D loss: 0.704408, acc.: 55.47%] [G loss: 0.887382]\n",
      "epoch:19 step:18228 [D loss: 0.631737, acc.: 64.84%] [G loss: 1.236467]\n",
      "epoch:19 step:18229 [D loss: 0.793196, acc.: 46.88%] [G loss: 1.235867]\n",
      "epoch:19 step:18230 [D loss: 0.685513, acc.: 57.03%] [G loss: 1.177488]\n",
      "epoch:19 step:18231 [D loss: 0.448924, acc.: 83.59%] [G loss: 1.245293]\n",
      "epoch:19 step:18232 [D loss: 0.692946, acc.: 57.03%] [G loss: 1.370569]\n",
      "epoch:19 step:18233 [D loss: 0.557610, acc.: 71.88%] [G loss: 1.133779]\n",
      "epoch:19 step:18234 [D loss: 0.743527, acc.: 51.56%] [G loss: 1.213683]\n",
      "epoch:19 step:18235 [D loss: 0.776436, acc.: 42.97%] [G loss: 0.969162]\n",
      "epoch:19 step:18236 [D loss: 0.718172, acc.: 48.44%] [G loss: 1.124885]\n",
      "epoch:19 step:18237 [D loss: 0.701189, acc.: 53.12%] [G loss: 0.888155]\n",
      "epoch:19 step:18238 [D loss: 0.709422, acc.: 51.56%] [G loss: 1.124412]\n",
      "epoch:19 step:18239 [D loss: 0.683603, acc.: 52.34%] [G loss: 1.040777]\n",
      "epoch:19 step:18240 [D loss: 0.753186, acc.: 47.66%] [G loss: 1.072131]\n",
      "epoch:19 step:18241 [D loss: 0.768501, acc.: 41.41%] [G loss: 0.954898]\n",
      "epoch:19 step:18242 [D loss: 0.717272, acc.: 50.78%] [G loss: 1.024240]\n",
      "epoch:19 step:18243 [D loss: 0.708247, acc.: 51.56%] [G loss: 0.992911]\n",
      "epoch:19 step:18244 [D loss: 0.657145, acc.: 60.16%] [G loss: 0.887234]\n",
      "epoch:19 step:18245 [D loss: 0.675581, acc.: 60.16%] [G loss: 0.931412]\n",
      "epoch:19 step:18246 [D loss: 0.617212, acc.: 74.22%] [G loss: 1.069911]\n",
      "epoch:19 step:18247 [D loss: 0.654522, acc.: 57.03%] [G loss: 1.097816]\n",
      "epoch:19 step:18248 [D loss: 0.637373, acc.: 60.16%] [G loss: 0.963964]\n",
      "epoch:19 step:18249 [D loss: 0.679719, acc.: 55.47%] [G loss: 0.853264]\n",
      "epoch:19 step:18250 [D loss: 0.699927, acc.: 58.59%] [G loss: 0.943687]\n",
      "epoch:19 step:18251 [D loss: 0.570554, acc.: 75.00%] [G loss: 0.976831]\n",
      "epoch:19 step:18252 [D loss: 0.506067, acc.: 93.75%] [G loss: 1.029206]\n",
      "epoch:19 step:18253 [D loss: 0.557736, acc.: 81.25%] [G loss: 0.970462]\n",
      "epoch:19 step:18254 [D loss: 0.399213, acc.: 97.66%] [G loss: 0.956120]\n",
      "epoch:19 step:18255 [D loss: 0.395425, acc.: 96.09%] [G loss: 1.134263]\n",
      "epoch:19 step:18256 [D loss: 0.375616, acc.: 92.19%] [G loss: 1.398550]\n",
      "epoch:19 step:18257 [D loss: 0.463893, acc.: 84.38%] [G loss: 1.302340]\n",
      "epoch:19 step:18258 [D loss: 0.508540, acc.: 85.16%] [G loss: 1.317947]\n",
      "epoch:19 step:18259 [D loss: 0.248364, acc.: 94.53%] [G loss: 1.439660]\n",
      "epoch:19 step:18260 [D loss: 0.427343, acc.: 92.19%] [G loss: 1.416635]\n",
      "epoch:19 step:18261 [D loss: 0.674564, acc.: 52.34%] [G loss: 1.408949]\n",
      "epoch:19 step:18262 [D loss: 0.595167, acc.: 65.62%] [G loss: 1.308223]\n",
      "epoch:19 step:18263 [D loss: 0.604812, acc.: 64.06%] [G loss: 1.203413]\n",
      "epoch:19 step:18264 [D loss: 0.930763, acc.: 42.19%] [G loss: 0.956223]\n",
      "epoch:19 step:18265 [D loss: 1.106652, acc.: 26.56%] [G loss: 0.746108]\n",
      "epoch:19 step:18266 [D loss: 0.759637, acc.: 49.22%] [G loss: 0.766605]\n",
      "epoch:19 step:18267 [D loss: 0.575670, acc.: 75.78%] [G loss: 0.841679]\n",
      "epoch:19 step:18268 [D loss: 0.542422, acc.: 78.91%] [G loss: 0.922089]\n",
      "epoch:19 step:18269 [D loss: 0.488934, acc.: 88.28%] [G loss: 0.935012]\n",
      "epoch:19 step:18270 [D loss: 0.513780, acc.: 76.56%] [G loss: 0.851306]\n",
      "epoch:19 step:18271 [D loss: 0.419654, acc.: 79.69%] [G loss: 1.178746]\n",
      "epoch:19 step:18272 [D loss: 0.353255, acc.: 92.19%] [G loss: 0.959887]\n",
      "epoch:19 step:18273 [D loss: 0.259385, acc.: 94.53%] [G loss: 1.489112]\n",
      "epoch:19 step:18274 [D loss: 0.266476, acc.: 92.97%] [G loss: 1.213656]\n",
      "epoch:19 step:18275 [D loss: 0.390032, acc.: 92.97%] [G loss: 0.940473]\n",
      "epoch:19 step:18276 [D loss: 1.061911, acc.: 47.66%] [G loss: 0.733856]\n",
      "epoch:19 step:18277 [D loss: 0.955327, acc.: 31.25%] [G loss: 0.948607]\n",
      "epoch:19 step:18278 [D loss: 0.718096, acc.: 48.44%] [G loss: 0.884069]\n",
      "epoch:19 step:18279 [D loss: 0.581835, acc.: 69.53%] [G loss: 0.886442]\n",
      "epoch:19 step:18280 [D loss: 0.613425, acc.: 66.41%] [G loss: 0.798518]\n",
      "epoch:19 step:18281 [D loss: 0.655362, acc.: 57.03%] [G loss: 1.054450]\n",
      "epoch:19 step:18282 [D loss: 0.490702, acc.: 71.88%] [G loss: 0.666781]\n",
      "epoch:19 step:18283 [D loss: 0.442528, acc.: 78.91%] [G loss: 1.096659]\n",
      "epoch:19 step:18284 [D loss: 0.274677, acc.: 96.09%] [G loss: 0.950789]\n",
      "epoch:19 step:18285 [D loss: 0.934899, acc.: 46.88%] [G loss: 0.996407]\n",
      "epoch:19 step:18286 [D loss: 0.812047, acc.: 42.97%] [G loss: 0.896571]\n",
      "epoch:19 step:18287 [D loss: 0.930849, acc.: 28.12%] [G loss: 0.903604]\n",
      "epoch:19 step:18288 [D loss: 0.857462, acc.: 32.81%] [G loss: 0.868508]\n",
      "epoch:19 step:18289 [D loss: 0.798980, acc.: 33.59%] [G loss: 0.898599]\n",
      "epoch:19 step:18290 [D loss: 0.753584, acc.: 44.53%] [G loss: 0.930149]\n",
      "epoch:19 step:18291 [D loss: 0.764929, acc.: 39.84%] [G loss: 0.826594]\n",
      "epoch:19 step:18292 [D loss: 0.560354, acc.: 78.91%] [G loss: 0.811597]\n",
      "epoch:19 step:18293 [D loss: 0.585642, acc.: 71.09%] [G loss: 0.839719]\n",
      "epoch:19 step:18294 [D loss: 0.575180, acc.: 68.75%] [G loss: 1.024968]\n",
      "epoch:19 step:18295 [D loss: 0.746917, acc.: 47.66%] [G loss: 0.830103]\n",
      "epoch:19 step:18296 [D loss: 0.713806, acc.: 48.44%] [G loss: 0.834767]\n",
      "epoch:19 step:18297 [D loss: 0.664285, acc.: 61.72%] [G loss: 0.846275]\n",
      "epoch:19 step:18298 [D loss: 0.635625, acc.: 64.06%] [G loss: 0.934543]\n",
      "epoch:19 step:18299 [D loss: 0.731771, acc.: 47.66%] [G loss: 0.817154]\n",
      "epoch:19 step:18300 [D loss: 0.874532, acc.: 30.47%] [G loss: 0.785172]\n",
      "epoch:19 step:18301 [D loss: 0.661375, acc.: 63.28%] [G loss: 0.839439]\n",
      "epoch:19 step:18302 [D loss: 0.651500, acc.: 57.81%] [G loss: 1.002088]\n",
      "epoch:19 step:18303 [D loss: 0.662551, acc.: 58.59%] [G loss: 1.058121]\n",
      "epoch:19 step:18304 [D loss: 0.702272, acc.: 57.03%] [G loss: 1.007917]\n",
      "epoch:19 step:18305 [D loss: 0.625149, acc.: 64.84%] [G loss: 1.012292]\n",
      "epoch:19 step:18306 [D loss: 0.441900, acc.: 82.03%] [G loss: 0.988794]\n",
      "epoch:19 step:18307 [D loss: 0.477328, acc.: 75.78%] [G loss: 1.149160]\n",
      "epoch:19 step:18308 [D loss: 0.449951, acc.: 85.94%] [G loss: 1.095817]\n",
      "epoch:19 step:18309 [D loss: 0.603675, acc.: 68.75%] [G loss: 1.067565]\n",
      "epoch:19 step:18310 [D loss: 0.516406, acc.: 71.88%] [G loss: 0.952864]\n",
      "epoch:19 step:18311 [D loss: 0.512752, acc.: 80.47%] [G loss: 0.960611]\n",
      "epoch:19 step:18312 [D loss: 0.892583, acc.: 22.66%] [G loss: 0.956378]\n",
      "epoch:19 step:18313 [D loss: 0.730152, acc.: 49.22%] [G loss: 1.248505]\n",
      "epoch:19 step:18314 [D loss: 0.485720, acc.: 80.47%] [G loss: 1.154618]\n",
      "epoch:19 step:18315 [D loss: 0.612257, acc.: 64.06%] [G loss: 1.146598]\n",
      "epoch:19 step:18316 [D loss: 0.496466, acc.: 80.47%] [G loss: 1.161385]\n",
      "epoch:19 step:18317 [D loss: 0.487409, acc.: 78.12%] [G loss: 1.250374]\n",
      "epoch:19 step:18318 [D loss: 0.388958, acc.: 89.84%] [G loss: 1.175820]\n",
      "epoch:19 step:18319 [D loss: 0.708407, acc.: 58.59%] [G loss: 1.092321]\n",
      "epoch:19 step:18320 [D loss: 0.551098, acc.: 73.44%] [G loss: 1.012828]\n",
      "epoch:19 step:18321 [D loss: 0.686196, acc.: 53.12%] [G loss: 0.837878]\n",
      "epoch:19 step:18322 [D loss: 0.644726, acc.: 61.72%] [G loss: 0.952263]\n",
      "epoch:19 step:18323 [D loss: 0.561242, acc.: 73.44%] [G loss: 0.894188]\n",
      "epoch:19 step:18324 [D loss: 0.652750, acc.: 65.62%] [G loss: 0.940682]\n",
      "epoch:19 step:18325 [D loss: 0.596192, acc.: 67.19%] [G loss: 0.936425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18326 [D loss: 0.623039, acc.: 64.84%] [G loss: 0.962285]\n",
      "epoch:19 step:18327 [D loss: 0.354245, acc.: 86.72%] [G loss: 1.046783]\n",
      "epoch:19 step:18328 [D loss: 0.705424, acc.: 53.91%] [G loss: 0.926545]\n",
      "epoch:19 step:18329 [D loss: 0.583659, acc.: 68.75%] [G loss: 1.075311]\n",
      "epoch:19 step:18330 [D loss: 0.537829, acc.: 75.78%] [G loss: 1.174593]\n",
      "epoch:19 step:18331 [D loss: 0.669027, acc.: 60.94%] [G loss: 0.996999]\n",
      "epoch:19 step:18332 [D loss: 0.755451, acc.: 52.34%] [G loss: 1.018222]\n",
      "epoch:19 step:18333 [D loss: 0.609636, acc.: 66.41%] [G loss: 1.108256]\n",
      "epoch:19 step:18334 [D loss: 0.709368, acc.: 53.91%] [G loss: 1.053677]\n",
      "epoch:19 step:18335 [D loss: 0.617691, acc.: 65.62%] [G loss: 1.067255]\n",
      "epoch:19 step:18336 [D loss: 0.504726, acc.: 79.69%] [G loss: 1.079430]\n",
      "epoch:19 step:18337 [D loss: 0.597991, acc.: 63.28%] [G loss: 0.847880]\n",
      "epoch:19 step:18338 [D loss: 0.421087, acc.: 86.72%] [G loss: 1.095205]\n",
      "epoch:19 step:18339 [D loss: 0.319832, acc.: 87.50%] [G loss: 1.126840]\n",
      "epoch:19 step:18340 [D loss: 0.401153, acc.: 89.06%] [G loss: 1.260960]\n",
      "epoch:19 step:18341 [D loss: 0.500889, acc.: 84.38%] [G loss: 1.334379]\n",
      "epoch:19 step:18342 [D loss: 0.351544, acc.: 94.53%] [G loss: 1.199750]\n",
      "epoch:19 step:18343 [D loss: 0.437159, acc.: 85.94%] [G loss: 1.389693]\n",
      "epoch:19 step:18344 [D loss: 0.402535, acc.: 89.84%] [G loss: 1.151928]\n",
      "epoch:19 step:18345 [D loss: 0.744863, acc.: 45.31%] [G loss: 1.132736]\n",
      "epoch:19 step:18346 [D loss: 0.212685, acc.: 97.66%] [G loss: 1.353166]\n",
      "epoch:19 step:18347 [D loss: 0.670445, acc.: 60.94%] [G loss: 1.409336]\n",
      "epoch:19 step:18348 [D loss: 1.061686, acc.: 45.31%] [G loss: 1.486068]\n",
      "epoch:19 step:18349 [D loss: 0.738533, acc.: 53.91%] [G loss: 1.600221]\n",
      "epoch:19 step:18350 [D loss: 0.693390, acc.: 54.69%] [G loss: 1.245000]\n",
      "epoch:19 step:18351 [D loss: 0.634579, acc.: 64.06%] [G loss: 1.038244]\n",
      "epoch:19 step:18352 [D loss: 0.634656, acc.: 67.19%] [G loss: 1.204197]\n",
      "epoch:19 step:18353 [D loss: 0.608704, acc.: 75.00%] [G loss: 0.891830]\n",
      "epoch:19 step:18354 [D loss: 0.667214, acc.: 59.38%] [G loss: 0.993295]\n",
      "epoch:19 step:18355 [D loss: 0.674149, acc.: 59.38%] [G loss: 1.031623]\n",
      "epoch:19 step:18356 [D loss: 0.660525, acc.: 62.50%] [G loss: 0.892408]\n",
      "epoch:19 step:18357 [D loss: 0.441664, acc.: 86.72%] [G loss: 1.031641]\n",
      "epoch:19 step:18358 [D loss: 0.607358, acc.: 70.31%] [G loss: 0.935351]\n",
      "epoch:19 step:18359 [D loss: 0.484800, acc.: 79.69%] [G loss: 0.906122]\n",
      "epoch:19 step:18360 [D loss: 0.539982, acc.: 78.12%] [G loss: 1.160749]\n",
      "epoch:19 step:18361 [D loss: 0.718625, acc.: 53.12%] [G loss: 1.083540]\n",
      "epoch:19 step:18362 [D loss: 0.254291, acc.: 96.88%] [G loss: 0.942694]\n",
      "epoch:19 step:18363 [D loss: 0.433750, acc.: 85.16%] [G loss: 1.151005]\n",
      "epoch:19 step:18364 [D loss: 0.241000, acc.: 99.22%] [G loss: 1.156766]\n",
      "epoch:19 step:18365 [D loss: 0.665546, acc.: 63.28%] [G loss: 0.836298]\n",
      "epoch:19 step:18366 [D loss: 0.662083, acc.: 65.62%] [G loss: 0.902341]\n",
      "epoch:19 step:18367 [D loss: 0.742530, acc.: 53.12%] [G loss: 0.817859]\n",
      "epoch:19 step:18368 [D loss: 0.374618, acc.: 96.09%] [G loss: 1.249907]\n",
      "epoch:19 step:18369 [D loss: 0.278567, acc.: 87.50%] [G loss: 1.219893]\n",
      "epoch:19 step:18370 [D loss: 0.257838, acc.: 90.62%] [G loss: 1.360406]\n",
      "epoch:19 step:18371 [D loss: 0.524522, acc.: 80.47%] [G loss: 1.071597]\n",
      "epoch:19 step:18372 [D loss: 0.750135, acc.: 53.91%] [G loss: 1.344028]\n",
      "epoch:19 step:18373 [D loss: 0.552075, acc.: 80.47%] [G loss: 1.205392]\n",
      "epoch:19 step:18374 [D loss: 0.698330, acc.: 55.47%] [G loss: 1.073805]\n",
      "epoch:19 step:18375 [D loss: 0.679170, acc.: 57.81%] [G loss: 0.795603]\n",
      "epoch:19 step:18376 [D loss: 0.510374, acc.: 75.78%] [G loss: 0.921372]\n",
      "epoch:19 step:18377 [D loss: 0.441399, acc.: 85.94%] [G loss: 1.100454]\n",
      "epoch:19 step:18378 [D loss: 0.490843, acc.: 84.38%] [G loss: 1.079101]\n",
      "epoch:19 step:18379 [D loss: 0.249286, acc.: 96.09%] [G loss: 1.119176]\n",
      "epoch:19 step:18380 [D loss: 0.253307, acc.: 92.97%] [G loss: 1.427187]\n",
      "epoch:19 step:18381 [D loss: 0.208393, acc.: 93.75%] [G loss: 1.273132]\n",
      "epoch:19 step:18382 [D loss: 0.239683, acc.: 92.19%] [G loss: 0.781981]\n",
      "epoch:19 step:18383 [D loss: 0.788239, acc.: 52.34%] [G loss: 1.190723]\n",
      "epoch:19 step:18384 [D loss: 0.777310, acc.: 48.44%] [G loss: 1.398398]\n",
      "epoch:19 step:18385 [D loss: 0.737644, acc.: 51.56%] [G loss: 0.899875]\n",
      "epoch:19 step:18386 [D loss: 0.715544, acc.: 54.69%] [G loss: 1.151147]\n",
      "epoch:19 step:18387 [D loss: 0.797065, acc.: 44.53%] [G loss: 1.137163]\n",
      "epoch:19 step:18388 [D loss: 0.674919, acc.: 61.72%] [G loss: 1.049478]\n",
      "epoch:19 step:18389 [D loss: 0.923130, acc.: 35.16%] [G loss: 0.528023]\n",
      "epoch:19 step:18390 [D loss: 0.303878, acc.: 84.38%] [G loss: 1.117400]\n",
      "epoch:19 step:18391 [D loss: 0.175975, acc.: 98.44%] [G loss: 1.119775]\n",
      "epoch:19 step:18392 [D loss: 0.280685, acc.: 86.72%] [G loss: 0.909071]\n",
      "epoch:19 step:18393 [D loss: 0.755431, acc.: 52.34%] [G loss: 1.143487]\n",
      "epoch:19 step:18394 [D loss: 0.766869, acc.: 48.44%] [G loss: 1.059167]\n",
      "epoch:19 step:18395 [D loss: 1.014055, acc.: 37.50%] [G loss: 1.273551]\n",
      "epoch:19 step:18396 [D loss: 0.824630, acc.: 43.75%] [G loss: 1.901643]\n",
      "epoch:19 step:18397 [D loss: 0.788064, acc.: 50.00%] [G loss: 1.617624]\n",
      "epoch:19 step:18398 [D loss: 0.816387, acc.: 47.66%] [G loss: 1.128754]\n",
      "epoch:19 step:18399 [D loss: 0.657471, acc.: 57.81%] [G loss: 0.881941]\n",
      "epoch:19 step:18400 [D loss: 0.734308, acc.: 46.88%] [G loss: 1.372467]\n",
      "##############\n",
      "[4.06489165 2.52330713 6.74544586 6.12932225 4.6091861  6.00916744\n",
      " 5.35522716 5.03003333 5.62828762 5.01825728]\n",
      "##########\n",
      "epoch:19 step:18401 [D loss: 0.493486, acc.: 80.47%] [G loss: 1.251378]\n",
      "epoch:19 step:18402 [D loss: 0.622344, acc.: 66.41%] [G loss: 1.138117]\n",
      "epoch:19 step:18403 [D loss: 0.621886, acc.: 68.75%] [G loss: 1.188477]\n",
      "epoch:19 step:18404 [D loss: 0.692147, acc.: 60.94%] [G loss: 1.092639]\n",
      "epoch:19 step:18405 [D loss: 0.835973, acc.: 42.19%] [G loss: 1.152489]\n",
      "epoch:19 step:18406 [D loss: 0.569706, acc.: 67.19%] [G loss: 1.013055]\n",
      "epoch:19 step:18407 [D loss: 0.228658, acc.: 94.53%] [G loss: 1.297965]\n",
      "epoch:19 step:18408 [D loss: 0.490640, acc.: 81.25%] [G loss: 1.527283]\n",
      "epoch:19 step:18409 [D loss: 0.666556, acc.: 59.38%] [G loss: 1.251157]\n",
      "epoch:19 step:18410 [D loss: 0.711387, acc.: 57.03%] [G loss: 1.447267]\n",
      "epoch:19 step:18411 [D loss: 0.668013, acc.: 58.59%] [G loss: 1.298129]\n",
      "epoch:19 step:18412 [D loss: 0.718524, acc.: 51.56%] [G loss: 1.019782]\n",
      "epoch:19 step:18413 [D loss: 0.519240, acc.: 80.47%] [G loss: 1.108784]\n",
      "epoch:19 step:18414 [D loss: 0.748535, acc.: 48.44%] [G loss: 1.074799]\n",
      "epoch:19 step:18415 [D loss: 0.662089, acc.: 62.50%] [G loss: 0.983247]\n",
      "epoch:19 step:18416 [D loss: 0.424310, acc.: 85.94%] [G loss: 1.101459]\n",
      "epoch:19 step:18417 [D loss: 0.528310, acc.: 74.22%] [G loss: 0.937638]\n",
      "epoch:19 step:18418 [D loss: 0.473346, acc.: 83.59%] [G loss: 1.194196]\n",
      "epoch:19 step:18419 [D loss: 0.309177, acc.: 92.97%] [G loss: 1.226589]\n",
      "epoch:19 step:18420 [D loss: 0.337588, acc.: 89.06%] [G loss: 1.304361]\n",
      "epoch:19 step:18421 [D loss: 0.701818, acc.: 57.81%] [G loss: 1.313927]\n",
      "epoch:19 step:18422 [D loss: 0.632992, acc.: 62.50%] [G loss: 1.032441]\n",
      "epoch:19 step:18423 [D loss: 0.710098, acc.: 53.12%] [G loss: 1.117108]\n",
      "epoch:19 step:18424 [D loss: 0.638496, acc.: 64.06%] [G loss: 0.764978]\n",
      "epoch:19 step:18425 [D loss: 0.413173, acc.: 85.16%] [G loss: 1.191148]\n",
      "epoch:19 step:18426 [D loss: 0.405585, acc.: 87.50%] [G loss: 0.910406]\n",
      "epoch:19 step:18427 [D loss: 0.397824, acc.: 82.03%] [G loss: 1.264994]\n",
      "epoch:19 step:18428 [D loss: 0.870702, acc.: 39.06%] [G loss: 0.705080]\n",
      "epoch:19 step:18429 [D loss: 0.648082, acc.: 63.28%] [G loss: 0.687553]\n",
      "epoch:19 step:18430 [D loss: 0.708897, acc.: 51.56%] [G loss: 0.934251]\n",
      "epoch:19 step:18431 [D loss: 0.698779, acc.: 50.78%] [G loss: 0.803064]\n",
      "epoch:19 step:18432 [D loss: 0.606913, acc.: 67.19%] [G loss: 0.714176]\n",
      "epoch:19 step:18433 [D loss: 0.553637, acc.: 76.56%] [G loss: 0.805040]\n",
      "epoch:19 step:18434 [D loss: 0.711566, acc.: 61.72%] [G loss: 0.938006]\n",
      "epoch:19 step:18435 [D loss: 0.366400, acc.: 85.16%] [G loss: 0.412120]\n",
      "epoch:19 step:18436 [D loss: 0.403105, acc.: 76.56%] [G loss: 1.129548]\n",
      "epoch:19 step:18437 [D loss: 0.479509, acc.: 72.66%] [G loss: 1.203462]\n",
      "epoch:19 step:18438 [D loss: 0.417027, acc.: 87.50%] [G loss: 1.492113]\n",
      "epoch:19 step:18439 [D loss: 0.637493, acc.: 64.84%] [G loss: 1.199881]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18440 [D loss: 0.671017, acc.: 63.28%] [G loss: 1.071583]\n",
      "epoch:19 step:18441 [D loss: 0.834005, acc.: 37.50%] [G loss: 0.722199]\n",
      "epoch:19 step:18442 [D loss: 0.853138, acc.: 44.53%] [G loss: 0.527227]\n",
      "epoch:19 step:18443 [D loss: 0.956600, acc.: 30.47%] [G loss: 0.833566]\n",
      "epoch:19 step:18444 [D loss: 0.847481, acc.: 43.75%] [G loss: 0.785183]\n",
      "epoch:19 step:18445 [D loss: 1.111778, acc.: 19.53%] [G loss: 0.780855]\n",
      "epoch:19 step:18446 [D loss: 0.741101, acc.: 49.22%] [G loss: 0.949001]\n",
      "epoch:19 step:18447 [D loss: 0.480290, acc.: 71.09%] [G loss: 1.041450]\n",
      "epoch:19 step:18448 [D loss: 0.505832, acc.: 81.25%] [G loss: 0.756090]\n",
      "epoch:19 step:18449 [D loss: 0.527587, acc.: 79.69%] [G loss: 0.876509]\n",
      "epoch:19 step:18450 [D loss: 0.638112, acc.: 64.06%] [G loss: 1.063186]\n",
      "epoch:19 step:18451 [D loss: 0.447714, acc.: 84.38%] [G loss: 1.058463]\n",
      "epoch:19 step:18452 [D loss: 0.573478, acc.: 73.44%] [G loss: 0.913095]\n",
      "epoch:19 step:18453 [D loss: 0.492249, acc.: 75.78%] [G loss: 0.929519]\n",
      "epoch:19 step:18454 [D loss: 0.794157, acc.: 47.66%] [G loss: 0.692927]\n",
      "epoch:19 step:18455 [D loss: 0.771122, acc.: 50.78%] [G loss: 0.711777]\n",
      "epoch:19 step:18456 [D loss: 0.699383, acc.: 51.56%] [G loss: 1.014238]\n",
      "epoch:19 step:18457 [D loss: 0.805214, acc.: 38.28%] [G loss: 1.200444]\n",
      "epoch:19 step:18458 [D loss: 0.731436, acc.: 51.56%] [G loss: 0.969474]\n",
      "epoch:19 step:18459 [D loss: 0.822000, acc.: 43.75%] [G loss: 1.186030]\n",
      "epoch:19 step:18460 [D loss: 0.796695, acc.: 44.53%] [G loss: 0.945128]\n",
      "epoch:19 step:18461 [D loss: 0.804279, acc.: 41.41%] [G loss: 0.907937]\n",
      "epoch:19 step:18462 [D loss: 0.583988, acc.: 75.00%] [G loss: 1.109657]\n",
      "epoch:19 step:18463 [D loss: 0.694200, acc.: 57.03%] [G loss: 1.096101]\n",
      "epoch:19 step:18464 [D loss: 0.736971, acc.: 47.66%] [G loss: 0.976596]\n",
      "epoch:19 step:18465 [D loss: 0.705045, acc.: 51.56%] [G loss: 1.325504]\n",
      "epoch:19 step:18466 [D loss: 0.485690, acc.: 77.34%] [G loss: 1.425213]\n",
      "epoch:19 step:18467 [D loss: 0.410560, acc.: 91.41%] [G loss: 1.476736]\n",
      "epoch:19 step:18468 [D loss: 0.313919, acc.: 94.53%] [G loss: 1.528723]\n",
      "epoch:19 step:18469 [D loss: 0.517097, acc.: 71.09%] [G loss: 1.526015]\n",
      "epoch:19 step:18470 [D loss: 0.497013, acc.: 79.69%] [G loss: 1.547523]\n",
      "epoch:19 step:18471 [D loss: 0.724592, acc.: 54.69%] [G loss: 1.500304]\n",
      "epoch:19 step:18472 [D loss: 0.527264, acc.: 69.53%] [G loss: 1.767748]\n",
      "epoch:19 step:18473 [D loss: 0.591669, acc.: 67.19%] [G loss: 1.189341]\n",
      "epoch:19 step:18474 [D loss: 0.523187, acc.: 75.78%] [G loss: 1.036230]\n",
      "epoch:19 step:18475 [D loss: 0.601233, acc.: 69.53%] [G loss: 1.194014]\n",
      "epoch:19 step:18476 [D loss: 0.652720, acc.: 58.59%] [G loss: 1.521399]\n",
      "epoch:19 step:18477 [D loss: 0.524142, acc.: 80.47%] [G loss: 1.526506]\n",
      "epoch:19 step:18478 [D loss: 0.768613, acc.: 53.91%] [G loss: 0.591472]\n",
      "epoch:19 step:18479 [D loss: 0.617349, acc.: 67.97%] [G loss: 1.053892]\n",
      "epoch:19 step:18480 [D loss: 0.686500, acc.: 58.59%] [G loss: 0.806145]\n",
      "epoch:19 step:18481 [D loss: 0.866865, acc.: 32.81%] [G loss: 0.961485]\n",
      "epoch:19 step:18482 [D loss: 0.689219, acc.: 54.69%] [G loss: 1.011847]\n",
      "epoch:19 step:18483 [D loss: 0.635159, acc.: 62.50%] [G loss: 0.664438]\n",
      "epoch:19 step:18484 [D loss: 0.961314, acc.: 27.34%] [G loss: 0.621259]\n",
      "epoch:19 step:18485 [D loss: 0.607076, acc.: 62.50%] [G loss: 0.796923]\n",
      "epoch:19 step:18486 [D loss: 0.587012, acc.: 70.31%] [G loss: 0.796553]\n",
      "epoch:19 step:18487 [D loss: 0.560470, acc.: 70.31%] [G loss: 0.659393]\n",
      "epoch:19 step:18488 [D loss: 0.608510, acc.: 63.28%] [G loss: 0.857623]\n",
      "epoch:19 step:18489 [D loss: 0.538434, acc.: 74.22%] [G loss: 1.143042]\n",
      "epoch:19 step:18490 [D loss: 0.469116, acc.: 83.59%] [G loss: 0.730884]\n",
      "epoch:19 step:18491 [D loss: 0.666226, acc.: 63.28%] [G loss: 0.880928]\n",
      "epoch:19 step:18492 [D loss: 0.785309, acc.: 47.66%] [G loss: 0.838404]\n",
      "epoch:19 step:18493 [D loss: 0.775180, acc.: 42.19%] [G loss: 0.781540]\n",
      "epoch:19 step:18494 [D loss: 0.643375, acc.: 67.19%] [G loss: 0.796224]\n",
      "epoch:19 step:18495 [D loss: 0.741461, acc.: 43.75%] [G loss: 0.833828]\n",
      "epoch:19 step:18496 [D loss: 0.696042, acc.: 50.78%] [G loss: 0.988199]\n",
      "epoch:19 step:18497 [D loss: 0.578498, acc.: 74.22%] [G loss: 0.901636]\n",
      "epoch:19 step:18498 [D loss: 0.642074, acc.: 66.41%] [G loss: 0.979470]\n",
      "epoch:19 step:18499 [D loss: 0.432687, acc.: 75.00%] [G loss: 0.851428]\n",
      "epoch:19 step:18500 [D loss: 0.290939, acc.: 92.97%] [G loss: 0.909918]\n",
      "epoch:19 step:18501 [D loss: 0.458046, acc.: 75.78%] [G loss: 1.087908]\n",
      "epoch:19 step:18502 [D loss: 0.458526, acc.: 86.72%] [G loss: 0.894735]\n",
      "epoch:19 step:18503 [D loss: 0.341888, acc.: 84.38%] [G loss: 1.026719]\n",
      "epoch:19 step:18504 [D loss: 0.318328, acc.: 90.62%] [G loss: 1.198980]\n",
      "epoch:19 step:18505 [D loss: 0.513069, acc.: 69.53%] [G loss: 1.071957]\n",
      "epoch:19 step:18506 [D loss: 0.826521, acc.: 42.19%] [G loss: 1.248139]\n",
      "epoch:19 step:18507 [D loss: 0.660059, acc.: 64.06%] [G loss: 0.974434]\n",
      "epoch:19 step:18508 [D loss: 0.708912, acc.: 54.69%] [G loss: 0.916659]\n",
      "epoch:19 step:18509 [D loss: 0.447286, acc.: 85.94%] [G loss: 0.452115]\n",
      "epoch:19 step:18510 [D loss: 0.369510, acc.: 79.69%] [G loss: 0.945799]\n",
      "epoch:19 step:18511 [D loss: 0.364707, acc.: 84.38%] [G loss: 1.202747]\n",
      "epoch:19 step:18512 [D loss: 0.469015, acc.: 73.44%] [G loss: 0.800049]\n",
      "epoch:19 step:18513 [D loss: 0.870041, acc.: 43.75%] [G loss: 1.323066]\n",
      "epoch:19 step:18514 [D loss: 0.698656, acc.: 57.03%] [G loss: 1.260435]\n",
      "epoch:19 step:18515 [D loss: 0.722515, acc.: 50.78%] [G loss: 1.311180]\n",
      "epoch:19 step:18516 [D loss: 0.639040, acc.: 67.19%] [G loss: 0.929683]\n",
      "epoch:19 step:18517 [D loss: 0.545293, acc.: 78.91%] [G loss: 1.031397]\n",
      "epoch:19 step:18518 [D loss: 0.877924, acc.: 46.09%] [G loss: 0.927204]\n",
      "epoch:19 step:18519 [D loss: 0.846247, acc.: 35.16%] [G loss: 0.963239]\n",
      "epoch:19 step:18520 [D loss: 0.716960, acc.: 52.34%] [G loss: 0.830592]\n",
      "epoch:19 step:18521 [D loss: 0.521631, acc.: 76.56%] [G loss: 1.247833]\n",
      "epoch:19 step:18522 [D loss: 0.531952, acc.: 65.62%] [G loss: 1.218614]\n",
      "epoch:19 step:18523 [D loss: 0.496046, acc.: 78.12%] [G loss: 1.402140]\n",
      "epoch:19 step:18524 [D loss: 0.490593, acc.: 77.34%] [G loss: 1.465477]\n",
      "epoch:19 step:18525 [D loss: 0.769514, acc.: 50.78%] [G loss: 1.228689]\n",
      "epoch:19 step:18526 [D loss: 0.644761, acc.: 61.72%] [G loss: 1.451348]\n",
      "epoch:19 step:18527 [D loss: 0.420439, acc.: 89.84%] [G loss: 1.170954]\n",
      "epoch:19 step:18528 [D loss: 0.394521, acc.: 90.62%] [G loss: 1.441929]\n",
      "epoch:19 step:18529 [D loss: 0.306989, acc.: 96.88%] [G loss: 1.648725]\n",
      "epoch:19 step:18530 [D loss: 1.082875, acc.: 42.19%] [G loss: 1.124312]\n",
      "epoch:19 step:18531 [D loss: 0.960547, acc.: 42.19%] [G loss: 0.976171]\n",
      "epoch:19 step:18532 [D loss: 0.752428, acc.: 38.28%] [G loss: 0.941946]\n",
      "epoch:19 step:18533 [D loss: 0.748715, acc.: 50.78%] [G loss: 0.837344]\n",
      "epoch:19 step:18534 [D loss: 0.674688, acc.: 58.59%] [G loss: 0.937435]\n",
      "epoch:19 step:18535 [D loss: 0.691961, acc.: 56.25%] [G loss: 0.959342]\n",
      "epoch:19 step:18536 [D loss: 0.667272, acc.: 58.59%] [G loss: 0.962742]\n",
      "epoch:19 step:18537 [D loss: 0.666383, acc.: 61.72%] [G loss: 0.877270]\n",
      "epoch:19 step:18538 [D loss: 0.436171, acc.: 92.19%] [G loss: 0.964548]\n",
      "epoch:19 step:18539 [D loss: 0.524532, acc.: 87.50%] [G loss: 0.893339]\n",
      "epoch:19 step:18540 [D loss: 0.560136, acc.: 75.00%] [G loss: 0.994330]\n",
      "epoch:19 step:18541 [D loss: 0.603942, acc.: 70.31%] [G loss: 1.016872]\n",
      "epoch:19 step:18542 [D loss: 0.763064, acc.: 48.44%] [G loss: 1.000000]\n",
      "epoch:19 step:18543 [D loss: 0.591237, acc.: 75.00%] [G loss: 0.882194]\n",
      "epoch:19 step:18544 [D loss: 0.473530, acc.: 75.78%] [G loss: 1.037356]\n",
      "epoch:19 step:18545 [D loss: 0.372024, acc.: 89.84%] [G loss: 1.009241]\n",
      "epoch:19 step:18546 [D loss: 0.358545, acc.: 94.53%] [G loss: 1.017035]\n",
      "epoch:19 step:18547 [D loss: 0.531202, acc.: 82.81%] [G loss: 1.082002]\n",
      "epoch:19 step:18548 [D loss: 0.863768, acc.: 46.88%] [G loss: 1.065192]\n",
      "epoch:19 step:18549 [D loss: 0.817994, acc.: 32.03%] [G loss: 0.906810]\n",
      "epoch:19 step:18550 [D loss: 0.650491, acc.: 64.84%] [G loss: 0.811250]\n",
      "epoch:19 step:18551 [D loss: 0.578941, acc.: 70.31%] [G loss: 0.946220]\n",
      "epoch:19 step:18552 [D loss: 0.475271, acc.: 76.56%] [G loss: 0.942728]\n",
      "epoch:19 step:18553 [D loss: 0.436631, acc.: 85.16%] [G loss: 1.139581]\n",
      "epoch:19 step:18554 [D loss: 0.637112, acc.: 62.50%] [G loss: 1.251133]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18555 [D loss: 0.703912, acc.: 57.03%] [G loss: 0.977644]\n",
      "epoch:19 step:18556 [D loss: 0.718759, acc.: 60.16%] [G loss: 0.932717]\n",
      "epoch:19 step:18557 [D loss: 0.697249, acc.: 57.81%] [G loss: 1.048050]\n",
      "epoch:19 step:18558 [D loss: 0.716607, acc.: 51.56%] [G loss: 0.951351]\n",
      "epoch:19 step:18559 [D loss: 0.638516, acc.: 62.50%] [G loss: 1.051226]\n",
      "epoch:19 step:18560 [D loss: 0.651029, acc.: 60.16%] [G loss: 0.965453]\n",
      "epoch:19 step:18561 [D loss: 0.630791, acc.: 69.53%] [G loss: 1.149110]\n",
      "epoch:19 step:18562 [D loss: 0.613285, acc.: 62.50%] [G loss: 1.090436]\n",
      "epoch:19 step:18563 [D loss: 0.519109, acc.: 76.56%] [G loss: 0.911093]\n",
      "epoch:19 step:18564 [D loss: 0.681757, acc.: 55.47%] [G loss: 1.018753]\n",
      "epoch:19 step:18565 [D loss: 0.668907, acc.: 55.47%] [G loss: 0.932241]\n",
      "epoch:19 step:18566 [D loss: 0.717611, acc.: 51.56%] [G loss: 1.008340]\n",
      "epoch:19 step:18567 [D loss: 0.629962, acc.: 60.16%] [G loss: 0.933108]\n",
      "epoch:19 step:18568 [D loss: 0.648678, acc.: 64.06%] [G loss: 0.789605]\n",
      "epoch:19 step:18569 [D loss: 0.670881, acc.: 62.50%] [G loss: 0.772301]\n",
      "epoch:19 step:18570 [D loss: 0.686068, acc.: 58.59%] [G loss: 0.750648]\n",
      "epoch:19 step:18571 [D loss: 0.453243, acc.: 76.56%] [G loss: 0.774197]\n",
      "epoch:19 step:18572 [D loss: 0.463502, acc.: 75.78%] [G loss: 0.888473]\n",
      "epoch:19 step:18573 [D loss: 0.731939, acc.: 50.00%] [G loss: 1.084447]\n",
      "epoch:19 step:18574 [D loss: 0.658677, acc.: 64.06%] [G loss: 1.037249]\n",
      "epoch:19 step:18575 [D loss: 0.773391, acc.: 41.41%] [G loss: 0.936381]\n",
      "epoch:19 step:18576 [D loss: 0.667545, acc.: 57.03%] [G loss: 1.097563]\n",
      "epoch:19 step:18577 [D loss: 0.373464, acc.: 82.81%] [G loss: 1.153171]\n",
      "epoch:19 step:18578 [D loss: 0.385208, acc.: 89.84%] [G loss: 1.251384]\n",
      "epoch:19 step:18579 [D loss: 0.632453, acc.: 66.41%] [G loss: 1.057265]\n",
      "epoch:19 step:18580 [D loss: 0.602691, acc.: 68.75%] [G loss: 1.078347]\n",
      "epoch:19 step:18581 [D loss: 0.890066, acc.: 34.38%] [G loss: 1.135526]\n",
      "epoch:19 step:18582 [D loss: 0.714314, acc.: 55.47%] [G loss: 0.876024]\n",
      "epoch:19 step:18583 [D loss: 0.613881, acc.: 69.53%] [G loss: 0.857320]\n",
      "epoch:19 step:18584 [D loss: 0.598999, acc.: 66.41%] [G loss: 0.872776]\n",
      "epoch:19 step:18585 [D loss: 0.707619, acc.: 57.81%] [G loss: 1.055734]\n",
      "epoch:19 step:18586 [D loss: 0.632782, acc.: 64.06%] [G loss: 0.996188]\n",
      "epoch:19 step:18587 [D loss: 0.686207, acc.: 54.69%] [G loss: 1.032072]\n",
      "epoch:19 step:18588 [D loss: 0.614782, acc.: 67.19%] [G loss: 1.091892]\n",
      "epoch:19 step:18589 [D loss: 0.544445, acc.: 73.44%] [G loss: 0.798496]\n",
      "epoch:19 step:18590 [D loss: 0.792248, acc.: 46.09%] [G loss: 0.948267]\n",
      "epoch:19 step:18591 [D loss: 0.692726, acc.: 57.03%] [G loss: 0.826131]\n",
      "epoch:19 step:18592 [D loss: 0.751604, acc.: 52.34%] [G loss: 0.925982]\n",
      "epoch:19 step:18593 [D loss: 0.661111, acc.: 56.25%] [G loss: 1.029176]\n",
      "epoch:19 step:18594 [D loss: 0.409288, acc.: 85.16%] [G loss: 1.004377]\n",
      "epoch:19 step:18595 [D loss: 0.358507, acc.: 88.28%] [G loss: 1.022228]\n",
      "epoch:19 step:18596 [D loss: 0.473196, acc.: 83.59%] [G loss: 1.251051]\n",
      "epoch:19 step:18597 [D loss: 0.347154, acc.: 89.84%] [G loss: 1.259015]\n",
      "epoch:19 step:18598 [D loss: 0.499454, acc.: 78.91%] [G loss: 1.255211]\n",
      "epoch:19 step:18599 [D loss: 0.431705, acc.: 84.38%] [G loss: 1.339164]\n",
      "epoch:19 step:18600 [D loss: 0.631446, acc.: 61.72%] [G loss: 1.968487]\n",
      "##############\n",
      "[4.1144326  3.21319511 6.57901609 5.97594578 4.80676196 6.48545038\n",
      " 5.87153832 5.84345997 6.04232606 5.27038616]\n",
      "##########\n",
      "epoch:19 step:18601 [D loss: 0.502837, acc.: 79.69%] [G loss: 2.052705]\n",
      "epoch:19 step:18602 [D loss: 0.621697, acc.: 69.53%] [G loss: 1.458848]\n",
      "epoch:19 step:18603 [D loss: 0.761738, acc.: 55.47%] [G loss: 1.114684]\n",
      "epoch:19 step:18604 [D loss: 0.653107, acc.: 64.06%] [G loss: 1.043695]\n",
      "epoch:19 step:18605 [D loss: 0.540184, acc.: 70.31%] [G loss: 1.202212]\n",
      "epoch:19 step:18606 [D loss: 0.628753, acc.: 67.97%] [G loss: 1.000237]\n",
      "epoch:19 step:18607 [D loss: 0.320245, acc.: 85.94%] [G loss: 1.051402]\n",
      "epoch:19 step:18608 [D loss: 0.329584, acc.: 82.81%] [G loss: 1.108786]\n",
      "epoch:19 step:18609 [D loss: 0.300789, acc.: 89.06%] [G loss: 1.131838]\n",
      "epoch:19 step:18610 [D loss: 0.778429, acc.: 50.00%] [G loss: 1.099206]\n",
      "epoch:19 step:18611 [D loss: 0.635534, acc.: 67.97%] [G loss: 1.003105]\n",
      "epoch:19 step:18612 [D loss: 0.585878, acc.: 69.53%] [G loss: 0.954383]\n",
      "epoch:19 step:18613 [D loss: 0.701676, acc.: 51.56%] [G loss: 1.052070]\n",
      "epoch:19 step:18614 [D loss: 0.767334, acc.: 46.09%] [G loss: 1.035273]\n",
      "epoch:19 step:18615 [D loss: 0.546930, acc.: 71.88%] [G loss: 1.065838]\n",
      "epoch:19 step:18616 [D loss: 0.715065, acc.: 55.47%] [G loss: 0.884399]\n",
      "epoch:19 step:18617 [D loss: 0.751738, acc.: 46.88%] [G loss: 0.926019]\n",
      "epoch:19 step:18618 [D loss: 0.543890, acc.: 62.50%] [G loss: 0.990025]\n",
      "epoch:19 step:18619 [D loss: 0.618877, acc.: 71.09%] [G loss: 0.922074]\n",
      "epoch:19 step:18620 [D loss: 0.607221, acc.: 64.06%] [G loss: 0.994796]\n",
      "epoch:19 step:18621 [D loss: 0.704422, acc.: 50.78%] [G loss: 1.023805]\n",
      "epoch:19 step:18622 [D loss: 0.686776, acc.: 57.03%] [G loss: 1.007046]\n",
      "epoch:19 step:18623 [D loss: 0.755667, acc.: 39.06%] [G loss: 0.925135]\n",
      "epoch:19 step:18624 [D loss: 0.389842, acc.: 83.59%] [G loss: 0.985265]\n",
      "epoch:19 step:18625 [D loss: 0.487353, acc.: 78.91%] [G loss: 1.197881]\n",
      "epoch:19 step:18626 [D loss: 0.591666, acc.: 69.53%] [G loss: 0.960912]\n",
      "epoch:19 step:18627 [D loss: 0.734975, acc.: 49.22%] [G loss: 0.943871]\n",
      "epoch:19 step:18628 [D loss: 0.656932, acc.: 54.69%] [G loss: 0.909418]\n",
      "epoch:19 step:18629 [D loss: 0.680105, acc.: 60.16%] [G loss: 1.050009]\n",
      "epoch:19 step:18630 [D loss: 0.589916, acc.: 66.41%] [G loss: 0.909987]\n",
      "epoch:19 step:18631 [D loss: 0.635521, acc.: 60.94%] [G loss: 0.969153]\n",
      "epoch:19 step:18632 [D loss: 0.626612, acc.: 68.75%] [G loss: 0.890415]\n",
      "epoch:19 step:18633 [D loss: 0.699266, acc.: 56.25%] [G loss: 0.897750]\n",
      "epoch:19 step:18634 [D loss: 0.698932, acc.: 61.72%] [G loss: 0.850317]\n",
      "epoch:19 step:18635 [D loss: 0.613815, acc.: 64.84%] [G loss: 0.819799]\n",
      "epoch:19 step:18636 [D loss: 0.700992, acc.: 55.47%] [G loss: 0.646755]\n",
      "epoch:19 step:18637 [D loss: 0.511901, acc.: 64.06%] [G loss: 0.732882]\n",
      "epoch:19 step:18638 [D loss: 0.536629, acc.: 78.91%] [G loss: 0.994786]\n",
      "epoch:19 step:18639 [D loss: 0.680909, acc.: 55.47%] [G loss: 0.764595]\n",
      "epoch:19 step:18640 [D loss: 0.725298, acc.: 51.56%] [G loss: 0.929079]\n",
      "epoch:19 step:18641 [D loss: 0.735684, acc.: 46.09%] [G loss: 1.025218]\n",
      "epoch:19 step:18642 [D loss: 0.486445, acc.: 71.09%] [G loss: 0.916154]\n",
      "epoch:19 step:18643 [D loss: 0.424702, acc.: 87.50%] [G loss: 0.892723]\n",
      "epoch:19 step:18644 [D loss: 0.296861, acc.: 87.50%] [G loss: 1.052717]\n",
      "epoch:19 step:18645 [D loss: 0.283085, acc.: 94.53%] [G loss: 1.048656]\n",
      "epoch:19 step:18646 [D loss: 0.770702, acc.: 48.44%] [G loss: 1.269857]\n",
      "epoch:19 step:18647 [D loss: 0.768129, acc.: 50.00%] [G loss: 0.973915]\n",
      "epoch:19 step:18648 [D loss: 0.535071, acc.: 72.66%] [G loss: 1.045531]\n",
      "epoch:19 step:18649 [D loss: 0.707732, acc.: 53.12%] [G loss: 0.974874]\n",
      "epoch:19 step:18650 [D loss: 0.317937, acc.: 89.84%] [G loss: 0.655500]\n",
      "epoch:19 step:18651 [D loss: 0.308507, acc.: 90.62%] [G loss: 1.175496]\n",
      "epoch:19 step:18652 [D loss: 0.447739, acc.: 89.84%] [G loss: 1.232378]\n",
      "epoch:19 step:18653 [D loss: 0.489103, acc.: 64.84%] [G loss: 1.268798]\n",
      "epoch:19 step:18654 [D loss: 0.199874, acc.: 100.00%] [G loss: 1.431712]\n",
      "epoch:19 step:18655 [D loss: 0.188664, acc.: 99.22%] [G loss: 1.426805]\n",
      "epoch:19 step:18656 [D loss: 0.159571, acc.: 100.00%] [G loss: 1.493107]\n",
      "epoch:19 step:18657 [D loss: 0.156071, acc.: 100.00%] [G loss: 1.583228]\n",
      "epoch:19 step:18658 [D loss: 0.302295, acc.: 96.09%] [G loss: 1.552617]\n",
      "epoch:19 step:18659 [D loss: 0.566166, acc.: 67.19%] [G loss: 1.166367]\n",
      "epoch:19 step:18660 [D loss: 0.197912, acc.: 99.22%] [G loss: 0.965471]\n",
      "epoch:19 step:18661 [D loss: 1.083865, acc.: 19.53%] [G loss: 1.267283]\n",
      "epoch:19 step:18662 [D loss: 0.770065, acc.: 48.44%] [G loss: 0.960563]\n",
      "epoch:19 step:18663 [D loss: 0.561766, acc.: 66.41%] [G loss: 1.349637]\n",
      "epoch:19 step:18664 [D loss: 0.552058, acc.: 67.19%] [G loss: 1.330020]\n",
      "epoch:19 step:18665 [D loss: 0.815941, acc.: 49.22%] [G loss: 1.221906]\n",
      "epoch:19 step:18666 [D loss: 0.744710, acc.: 50.00%] [G loss: 1.202898]\n",
      "epoch:19 step:18667 [D loss: 0.813371, acc.: 46.88%] [G loss: 1.144034]\n",
      "epoch:19 step:18668 [D loss: 0.332495, acc.: 98.44%] [G loss: 1.045463]\n",
      "epoch:19 step:18669 [D loss: 0.660805, acc.: 60.94%] [G loss: 0.553607]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18670 [D loss: 0.635033, acc.: 71.88%] [G loss: 0.223296]\n",
      "epoch:19 step:18671 [D loss: 1.063537, acc.: 17.97%] [G loss: 0.688404]\n",
      "epoch:19 step:18672 [D loss: 0.864238, acc.: 34.38%] [G loss: 1.278665]\n",
      "epoch:19 step:18673 [D loss: 1.091115, acc.: 15.62%] [G loss: 1.087230]\n",
      "epoch:19 step:18674 [D loss: 0.965243, acc.: 25.78%] [G loss: 1.083164]\n",
      "epoch:19 step:18675 [D loss: 0.723623, acc.: 47.66%] [G loss: 1.186336]\n",
      "epoch:19 step:18676 [D loss: 0.914399, acc.: 36.72%] [G loss: 0.885077]\n",
      "epoch:19 step:18677 [D loss: 0.913846, acc.: 34.38%] [G loss: 1.040439]\n",
      "epoch:19 step:18678 [D loss: 0.703544, acc.: 54.69%] [G loss: 1.067602]\n",
      "epoch:19 step:18679 [D loss: 0.769976, acc.: 51.56%] [G loss: 1.116385]\n",
      "epoch:19 step:18680 [D loss: 0.677242, acc.: 53.12%] [G loss: 1.193903]\n",
      "epoch:19 step:18681 [D loss: 0.343827, acc.: 93.75%] [G loss: 1.334633]\n",
      "epoch:19 step:18682 [D loss: 0.703780, acc.: 53.91%] [G loss: 1.334604]\n",
      "epoch:19 step:18683 [D loss: 0.701344, acc.: 52.34%] [G loss: 1.259230]\n",
      "epoch:19 step:18684 [D loss: 0.678236, acc.: 55.47%] [G loss: 1.318012]\n",
      "epoch:19 step:18685 [D loss: 0.805620, acc.: 53.12%] [G loss: 1.145721]\n",
      "epoch:19 step:18686 [D loss: 0.729239, acc.: 53.91%] [G loss: 1.008886]\n",
      "epoch:19 step:18687 [D loss: 0.676082, acc.: 60.94%] [G loss: 1.064478]\n",
      "epoch:19 step:18688 [D loss: 0.581548, acc.: 70.31%] [G loss: 1.050019]\n",
      "epoch:19 step:18689 [D loss: 0.656281, acc.: 67.97%] [G loss: 0.937425]\n",
      "epoch:19 step:18690 [D loss: 0.645266, acc.: 63.28%] [G loss: 0.831837]\n",
      "epoch:19 step:18691 [D loss: 0.683610, acc.: 50.78%] [G loss: 0.964077]\n",
      "epoch:19 step:18692 [D loss: 0.696483, acc.: 60.94%] [G loss: 0.829418]\n",
      "epoch:19 step:18693 [D loss: 0.648979, acc.: 60.94%] [G loss: 0.865682]\n",
      "epoch:19 step:18694 [D loss: 0.602990, acc.: 65.62%] [G loss: 0.905789]\n",
      "epoch:19 step:18695 [D loss: 0.649369, acc.: 67.19%] [G loss: 1.056934]\n",
      "epoch:19 step:18696 [D loss: 0.509863, acc.: 83.59%] [G loss: 1.091343]\n",
      "epoch:19 step:18697 [D loss: 0.419727, acc.: 92.19%] [G loss: 1.111711]\n",
      "epoch:19 step:18698 [D loss: 0.463659, acc.: 89.06%] [G loss: 1.386583]\n",
      "epoch:19 step:18699 [D loss: 0.430008, acc.: 87.50%] [G loss: 1.301463]\n",
      "epoch:19 step:18700 [D loss: 0.448933, acc.: 88.28%] [G loss: 1.594040]\n",
      "epoch:19 step:18701 [D loss: 0.284827, acc.: 96.88%] [G loss: 1.106544]\n",
      "epoch:19 step:18702 [D loss: 0.251288, acc.: 92.19%] [G loss: 1.456072]\n",
      "epoch:19 step:18703 [D loss: 0.238164, acc.: 95.31%] [G loss: 1.138272]\n",
      "epoch:19 step:18704 [D loss: 0.419077, acc.: 91.41%] [G loss: 1.194708]\n",
      "epoch:19 step:18705 [D loss: 0.502665, acc.: 78.12%] [G loss: 1.223572]\n",
      "epoch:19 step:18706 [D loss: 0.365749, acc.: 90.62%] [G loss: 1.010934]\n",
      "epoch:19 step:18707 [D loss: 1.025711, acc.: 44.53%] [G loss: 1.196361]\n",
      "epoch:19 step:18708 [D loss: 0.786367, acc.: 45.31%] [G loss: 0.758428]\n",
      "epoch:19 step:18709 [D loss: 0.792660, acc.: 50.78%] [G loss: 0.585068]\n",
      "epoch:19 step:18710 [D loss: 0.840597, acc.: 36.72%] [G loss: 0.810838]\n",
      "epoch:19 step:18711 [D loss: 0.569004, acc.: 74.22%] [G loss: 1.070268]\n",
      "epoch:19 step:18712 [D loss: 0.431855, acc.: 77.34%] [G loss: 1.079039]\n",
      "epoch:19 step:18713 [D loss: 0.827059, acc.: 48.44%] [G loss: 1.056131]\n",
      "epoch:19 step:18714 [D loss: 0.437057, acc.: 75.78%] [G loss: 0.785591]\n",
      "epoch:19 step:18715 [D loss: 0.256521, acc.: 93.75%] [G loss: 1.052373]\n",
      "epoch:19 step:18716 [D loss: 0.731673, acc.: 52.34%] [G loss: 0.976651]\n",
      "epoch:19 step:18717 [D loss: 0.825138, acc.: 41.41%] [G loss: 0.908457]\n",
      "epoch:19 step:18718 [D loss: 0.689741, acc.: 51.56%] [G loss: 1.021124]\n",
      "epoch:19 step:18719 [D loss: 0.908559, acc.: 38.28%] [G loss: 1.000357]\n",
      "epoch:19 step:18720 [D loss: 0.708851, acc.: 53.91%] [G loss: 1.030839]\n",
      "epoch:19 step:18721 [D loss: 0.771161, acc.: 38.28%] [G loss: 0.918741]\n",
      "epoch:19 step:18722 [D loss: 0.380741, acc.: 91.41%] [G loss: 0.986537]\n",
      "epoch:19 step:18723 [D loss: 0.642962, acc.: 64.06%] [G loss: 0.886844]\n",
      "epoch:19 step:18724 [D loss: 0.464281, acc.: 85.94%] [G loss: 1.240893]\n",
      "epoch:19 step:18725 [D loss: 0.656593, acc.: 56.25%] [G loss: 1.176947]\n",
      "epoch:19 step:18726 [D loss: 0.632513, acc.: 63.28%] [G loss: 0.923041]\n",
      "epoch:19 step:18727 [D loss: 0.480006, acc.: 82.03%] [G loss: 1.098201]\n",
      "epoch:19 step:18728 [D loss: 0.473841, acc.: 82.81%] [G loss: 1.027612]\n",
      "epoch:19 step:18729 [D loss: 0.410011, acc.: 84.38%] [G loss: 1.073600]\n",
      "epoch:19 step:18730 [D loss: 0.283370, acc.: 89.06%] [G loss: 1.031916]\n",
      "epoch:19 step:18731 [D loss: 0.829267, acc.: 43.75%] [G loss: 0.825913]\n",
      "epoch:19 step:18732 [D loss: 0.292357, acc.: 91.41%] [G loss: 0.981368]\n",
      "epoch:19 step:18733 [D loss: 0.526502, acc.: 72.66%] [G loss: 1.047064]\n",
      "epoch:19 step:18734 [D loss: 0.542265, acc.: 71.88%] [G loss: 1.083318]\n",
      "epoch:19 step:18735 [D loss: 0.590215, acc.: 73.44%] [G loss: 1.087714]\n",
      "epoch:19 step:18736 [D loss: 0.510757, acc.: 76.56%] [G loss: 1.150727]\n",
      "epoch:19 step:18737 [D loss: 0.276483, acc.: 88.28%] [G loss: 0.884949]\n",
      "epoch:19 step:18738 [D loss: 0.562648, acc.: 76.56%] [G loss: 1.133173]\n",
      "epoch:19 step:18739 [D loss: 0.414484, acc.: 80.47%] [G loss: 0.922540]\n",
      "epoch:19 step:18740 [D loss: 0.162818, acc.: 100.00%] [G loss: 1.207534]\n",
      "epoch:20 step:18741 [D loss: 0.649165, acc.: 65.62%] [G loss: 1.307968]\n",
      "epoch:20 step:18742 [D loss: 0.643042, acc.: 61.72%] [G loss: 0.811220]\n",
      "epoch:20 step:18743 [D loss: 0.865614, acc.: 38.28%] [G loss: 1.025585]\n",
      "epoch:20 step:18744 [D loss: 0.774611, acc.: 40.62%] [G loss: 1.252493]\n",
      "epoch:20 step:18745 [D loss: 0.711992, acc.: 53.91%] [G loss: 1.212687]\n",
      "epoch:20 step:18746 [D loss: 0.689035, acc.: 60.16%] [G loss: 1.054998]\n",
      "epoch:20 step:18747 [D loss: 0.632281, acc.: 63.28%] [G loss: 1.039428]\n",
      "epoch:20 step:18748 [D loss: 0.516400, acc.: 81.25%] [G loss: 0.841500]\n",
      "epoch:20 step:18749 [D loss: 0.652245, acc.: 65.62%] [G loss: 0.900602]\n",
      "epoch:20 step:18750 [D loss: 0.389794, acc.: 92.97%] [G loss: 0.938860]\n",
      "epoch:20 step:18751 [D loss: 0.505962, acc.: 82.03%] [G loss: 0.864038]\n",
      "epoch:20 step:18752 [D loss: 0.586653, acc.: 65.62%] [G loss: 0.733399]\n",
      "epoch:20 step:18753 [D loss: 0.523017, acc.: 66.41%] [G loss: 0.709804]\n",
      "epoch:20 step:18754 [D loss: 0.601193, acc.: 62.50%] [G loss: 1.114351]\n",
      "epoch:20 step:18755 [D loss: 0.439488, acc.: 83.59%] [G loss: 0.958448]\n",
      "epoch:20 step:18756 [D loss: 0.668490, acc.: 58.59%] [G loss: 0.976086]\n",
      "epoch:20 step:18757 [D loss: 0.721112, acc.: 50.00%] [G loss: 1.122768]\n",
      "epoch:20 step:18758 [D loss: 1.111972, acc.: 34.38%] [G loss: 0.249529]\n",
      "epoch:20 step:18759 [D loss: 0.876637, acc.: 36.72%] [G loss: 1.083444]\n",
      "epoch:20 step:18760 [D loss: 0.948418, acc.: 28.12%] [G loss: 1.004701]\n",
      "epoch:20 step:18761 [D loss: 0.779526, acc.: 45.31%] [G loss: 1.078690]\n",
      "epoch:20 step:18762 [D loss: 0.870549, acc.: 39.06%] [G loss: 1.193405]\n",
      "epoch:20 step:18763 [D loss: 0.888469, acc.: 32.81%] [G loss: 1.123469]\n",
      "epoch:20 step:18764 [D loss: 0.724131, acc.: 53.91%] [G loss: 1.244104]\n",
      "epoch:20 step:18765 [D loss: 0.676580, acc.: 61.72%] [G loss: 0.928037]\n",
      "epoch:20 step:18766 [D loss: 0.681572, acc.: 49.22%] [G loss: 0.907819]\n",
      "epoch:20 step:18767 [D loss: 0.451902, acc.: 85.94%] [G loss: 1.163249]\n",
      "epoch:20 step:18768 [D loss: 0.623825, acc.: 64.06%] [G loss: 1.057597]\n",
      "epoch:20 step:18769 [D loss: 0.624939, acc.: 62.50%] [G loss: 1.071947]\n",
      "epoch:20 step:18770 [D loss: 0.653466, acc.: 50.00%] [G loss: 1.098271]\n",
      "epoch:20 step:18771 [D loss: 0.480443, acc.: 82.03%] [G loss: 1.019073]\n",
      "epoch:20 step:18772 [D loss: 0.452763, acc.: 85.94%] [G loss: 1.100290]\n",
      "epoch:20 step:18773 [D loss: 0.392738, acc.: 89.06%] [G loss: 1.185949]\n",
      "epoch:20 step:18774 [D loss: 0.375089, acc.: 89.84%] [G loss: 1.236562]\n",
      "epoch:20 step:18775 [D loss: 0.334306, acc.: 92.19%] [G loss: 1.466150]\n",
      "epoch:20 step:18776 [D loss: 0.226071, acc.: 99.22%] [G loss: 1.655028]\n",
      "epoch:20 step:18777 [D loss: 0.719875, acc.: 56.25%] [G loss: 1.356775]\n",
      "epoch:20 step:18778 [D loss: 0.795911, acc.: 42.97%] [G loss: 1.201549]\n",
      "epoch:20 step:18779 [D loss: 0.762148, acc.: 53.91%] [G loss: 0.983036]\n",
      "epoch:20 step:18780 [D loss: 0.740685, acc.: 50.00%] [G loss: 0.989217]\n",
      "epoch:20 step:18781 [D loss: 0.568437, acc.: 78.12%] [G loss: 0.987982]\n",
      "epoch:20 step:18782 [D loss: 0.497769, acc.: 80.47%] [G loss: 0.906170]\n",
      "epoch:20 step:18783 [D loss: 0.443803, acc.: 87.50%] [G loss: 1.001443]\n",
      "epoch:20 step:18784 [D loss: 0.558008, acc.: 78.91%] [G loss: 1.054889]\n",
      "epoch:20 step:18785 [D loss: 0.629516, acc.: 69.53%] [G loss: 0.997021]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:18786 [D loss: 0.481475, acc.: 81.25%] [G loss: 1.064508]\n",
      "epoch:20 step:18787 [D loss: 0.606838, acc.: 70.31%] [G loss: 1.325833]\n",
      "epoch:20 step:18788 [D loss: 0.775991, acc.: 45.31%] [G loss: 1.146150]\n",
      "epoch:20 step:18789 [D loss: 0.887079, acc.: 31.25%] [G loss: 0.700045]\n",
      "epoch:20 step:18790 [D loss: 0.595745, acc.: 67.19%] [G loss: 1.117563]\n",
      "epoch:20 step:18791 [D loss: 0.586936, acc.: 72.66%] [G loss: 0.942913]\n",
      "epoch:20 step:18792 [D loss: 0.564046, acc.: 75.78%] [G loss: 1.035677]\n",
      "epoch:20 step:18793 [D loss: 0.574336, acc.: 73.44%] [G loss: 1.023382]\n",
      "epoch:20 step:18794 [D loss: 0.695733, acc.: 52.34%] [G loss: 0.683460]\n",
      "epoch:20 step:18795 [D loss: 0.719659, acc.: 44.53%] [G loss: 0.822014]\n",
      "epoch:20 step:18796 [D loss: 0.682128, acc.: 57.81%] [G loss: 1.031845]\n",
      "epoch:20 step:18797 [D loss: 0.332900, acc.: 88.28%] [G loss: 1.067034]\n",
      "epoch:20 step:18798 [D loss: 0.347937, acc.: 83.59%] [G loss: 0.883804]\n",
      "epoch:20 step:18799 [D loss: 0.563704, acc.: 69.53%] [G loss: 0.951420]\n",
      "epoch:20 step:18800 [D loss: 0.381768, acc.: 89.06%] [G loss: 1.048115]\n",
      "##############\n",
      "[3.89445134 2.38573519 6.28936364 6.13221055 4.44278771 6.15072621\n",
      " 5.40568489 5.50021283 6.35312917 5.10323191]\n",
      "##########\n",
      "epoch:20 step:18801 [D loss: 0.648352, acc.: 60.94%] [G loss: 1.344186]\n",
      "epoch:20 step:18802 [D loss: 0.668420, acc.: 60.94%] [G loss: 1.035529]\n",
      "epoch:20 step:18803 [D loss: 0.616061, acc.: 68.75%] [G loss: 1.045570]\n",
      "epoch:20 step:18804 [D loss: 0.795699, acc.: 41.41%] [G loss: 0.954811]\n",
      "epoch:20 step:18805 [D loss: 0.810737, acc.: 34.38%] [G loss: 0.817687]\n",
      "epoch:20 step:18806 [D loss: 0.752636, acc.: 50.78%] [G loss: 0.924955]\n",
      "epoch:20 step:18807 [D loss: 0.734596, acc.: 48.44%] [G loss: 1.000624]\n",
      "epoch:20 step:18808 [D loss: 0.808031, acc.: 46.09%] [G loss: 0.998901]\n",
      "epoch:20 step:18809 [D loss: 1.073697, acc.: 19.53%] [G loss: 0.778262]\n",
      "epoch:20 step:18810 [D loss: 0.675830, acc.: 52.34%] [G loss: 1.278321]\n",
      "epoch:20 step:18811 [D loss: 0.363536, acc.: 91.41%] [G loss: 1.105523]\n",
      "epoch:20 step:18812 [D loss: 0.500605, acc.: 77.34%] [G loss: 1.104482]\n",
      "epoch:20 step:18813 [D loss: 0.513983, acc.: 79.69%] [G loss: 1.459775]\n",
      "epoch:20 step:18814 [D loss: 0.713230, acc.: 52.34%] [G loss: 0.981096]\n",
      "epoch:20 step:18815 [D loss: 0.418110, acc.: 71.88%] [G loss: 1.136445]\n",
      "epoch:20 step:18816 [D loss: 0.367243, acc.: 91.41%] [G loss: 0.870572]\n",
      "epoch:20 step:18817 [D loss: 0.440544, acc.: 83.59%] [G loss: 1.313012]\n",
      "epoch:20 step:18818 [D loss: 0.966724, acc.: 34.38%] [G loss: 1.105437]\n",
      "epoch:20 step:18819 [D loss: 0.830308, acc.: 45.31%] [G loss: 1.105613]\n",
      "epoch:20 step:18820 [D loss: 0.758740, acc.: 44.53%] [G loss: 1.056743]\n",
      "epoch:20 step:18821 [D loss: 0.681616, acc.: 57.81%] [G loss: 1.061963]\n",
      "epoch:20 step:18822 [D loss: 0.618233, acc.: 62.50%] [G loss: 1.001093]\n",
      "epoch:20 step:18823 [D loss: 0.627401, acc.: 65.62%] [G loss: 1.191112]\n",
      "epoch:20 step:18824 [D loss: 0.632599, acc.: 60.94%] [G loss: 1.145823]\n",
      "epoch:20 step:18825 [D loss: 0.598500, acc.: 66.41%] [G loss: 1.396468]\n",
      "epoch:20 step:18826 [D loss: 0.715369, acc.: 52.34%] [G loss: 1.081909]\n",
      "epoch:20 step:18827 [D loss: 0.610258, acc.: 67.19%] [G loss: 1.282485]\n",
      "epoch:20 step:18828 [D loss: 0.659356, acc.: 64.06%] [G loss: 0.990890]\n",
      "epoch:20 step:18829 [D loss: 0.549089, acc.: 71.09%] [G loss: 0.943761]\n",
      "epoch:20 step:18830 [D loss: 0.547436, acc.: 69.53%] [G loss: 1.246912]\n",
      "epoch:20 step:18831 [D loss: 0.657723, acc.: 61.72%] [G loss: 1.125631]\n",
      "epoch:20 step:18832 [D loss: 0.511421, acc.: 78.91%] [G loss: 1.142269]\n",
      "epoch:20 step:18833 [D loss: 0.546136, acc.: 74.22%] [G loss: 1.035071]\n",
      "epoch:20 step:18834 [D loss: 0.686134, acc.: 55.47%] [G loss: 0.889729]\n",
      "epoch:20 step:18835 [D loss: 0.670579, acc.: 56.25%] [G loss: 0.652580]\n",
      "epoch:20 step:18836 [D loss: 0.807516, acc.: 31.25%] [G loss: 0.665753]\n",
      "epoch:20 step:18837 [D loss: 0.659043, acc.: 60.16%] [G loss: 0.657940]\n",
      "epoch:20 step:18838 [D loss: 0.995667, acc.: 27.34%] [G loss: 0.764544]\n",
      "epoch:20 step:18839 [D loss: 0.687598, acc.: 57.81%] [G loss: 0.710617]\n",
      "epoch:20 step:18840 [D loss: 0.699164, acc.: 43.75%] [G loss: 0.837816]\n",
      "epoch:20 step:18841 [D loss: 0.637370, acc.: 66.41%] [G loss: 0.764284]\n",
      "epoch:20 step:18842 [D loss: 0.620184, acc.: 57.81%] [G loss: 0.755676]\n",
      "epoch:20 step:18843 [D loss: 0.733445, acc.: 47.66%] [G loss: 0.837359]\n",
      "epoch:20 step:18844 [D loss: 0.700054, acc.: 53.12%] [G loss: 0.871106]\n",
      "epoch:20 step:18845 [D loss: 0.676540, acc.: 59.38%] [G loss: 0.817747]\n",
      "epoch:20 step:18846 [D loss: 0.698629, acc.: 52.34%] [G loss: 0.891899]\n",
      "epoch:20 step:18847 [D loss: 0.699658, acc.: 54.69%] [G loss: 0.909301]\n",
      "epoch:20 step:18848 [D loss: 0.620604, acc.: 67.19%] [G loss: 0.868221]\n",
      "epoch:20 step:18849 [D loss: 0.662778, acc.: 59.38%] [G loss: 0.909713]\n",
      "epoch:20 step:18850 [D loss: 0.619134, acc.: 64.06%] [G loss: 0.896239]\n",
      "epoch:20 step:18851 [D loss: 0.595273, acc.: 66.41%] [G loss: 0.982261]\n",
      "epoch:20 step:18852 [D loss: 0.566852, acc.: 74.22%] [G loss: 0.976511]\n",
      "epoch:20 step:18853 [D loss: 0.549415, acc.: 77.34%] [G loss: 0.958859]\n",
      "epoch:20 step:18854 [D loss: 0.462130, acc.: 82.81%] [G loss: 0.892533]\n",
      "epoch:20 step:18855 [D loss: 0.533745, acc.: 77.34%] [G loss: 0.910531]\n",
      "epoch:20 step:18856 [D loss: 0.641253, acc.: 60.16%] [G loss: 0.804620]\n",
      "epoch:20 step:18857 [D loss: 0.634229, acc.: 63.28%] [G loss: 0.748939]\n",
      "epoch:20 step:18858 [D loss: 0.537045, acc.: 75.00%] [G loss: 1.064728]\n",
      "epoch:20 step:18859 [D loss: 0.343287, acc.: 83.59%] [G loss: 0.987625]\n",
      "epoch:20 step:18860 [D loss: 0.611959, acc.: 67.97%] [G loss: 0.987654]\n",
      "epoch:20 step:18861 [D loss: 0.496781, acc.: 75.78%] [G loss: 0.938132]\n",
      "epoch:20 step:18862 [D loss: 0.559771, acc.: 61.72%] [G loss: 1.018549]\n",
      "epoch:20 step:18863 [D loss: 0.697706, acc.: 61.72%] [G loss: 0.978766]\n",
      "epoch:20 step:18864 [D loss: 0.817197, acc.: 43.75%] [G loss: 0.865403]\n",
      "epoch:20 step:18865 [D loss: 0.734213, acc.: 50.78%] [G loss: 0.916169]\n",
      "epoch:20 step:18866 [D loss: 0.719409, acc.: 53.91%] [G loss: 0.832145]\n",
      "epoch:20 step:18867 [D loss: 0.690887, acc.: 55.47%] [G loss: 0.912420]\n",
      "epoch:20 step:18868 [D loss: 0.634028, acc.: 67.19%] [G loss: 0.956920]\n",
      "epoch:20 step:18869 [D loss: 0.563566, acc.: 73.44%] [G loss: 1.042692]\n",
      "epoch:20 step:18870 [D loss: 0.413437, acc.: 82.81%] [G loss: 0.993890]\n",
      "epoch:20 step:18871 [D loss: 0.441895, acc.: 88.28%] [G loss: 1.129879]\n",
      "epoch:20 step:18872 [D loss: 0.494787, acc.: 84.38%] [G loss: 1.023005]\n",
      "epoch:20 step:18873 [D loss: 0.567009, acc.: 76.56%] [G loss: 1.099103]\n",
      "epoch:20 step:18874 [D loss: 0.581620, acc.: 78.12%] [G loss: 1.197958]\n",
      "epoch:20 step:18875 [D loss: 0.527371, acc.: 78.91%] [G loss: 1.040989]\n",
      "epoch:20 step:18876 [D loss: 0.632464, acc.: 60.94%] [G loss: 1.038361]\n",
      "epoch:20 step:18877 [D loss: 0.605325, acc.: 65.62%] [G loss: 1.044967]\n",
      "epoch:20 step:18878 [D loss: 0.535455, acc.: 76.56%] [G loss: 0.995415]\n",
      "epoch:20 step:18879 [D loss: 0.404024, acc.: 86.72%] [G loss: 0.997766]\n",
      "epoch:20 step:18880 [D loss: 0.618497, acc.: 65.62%] [G loss: 1.051398]\n",
      "epoch:20 step:18881 [D loss: 0.538918, acc.: 74.22%] [G loss: 0.867527]\n",
      "epoch:20 step:18882 [D loss: 0.708453, acc.: 54.69%] [G loss: 1.016223]\n",
      "epoch:20 step:18883 [D loss: 0.406139, acc.: 78.12%] [G loss: 1.038221]\n",
      "epoch:20 step:18884 [D loss: 0.500923, acc.: 78.12%] [G loss: 1.062796]\n",
      "epoch:20 step:18885 [D loss: 0.316022, acc.: 88.28%] [G loss: 1.167181]\n",
      "epoch:20 step:18886 [D loss: 0.468190, acc.: 85.16%] [G loss: 1.188880]\n",
      "epoch:20 step:18887 [D loss: 0.700870, acc.: 58.59%] [G loss: 1.033502]\n",
      "epoch:20 step:18888 [D loss: 0.725954, acc.: 51.56%] [G loss: 1.027254]\n",
      "epoch:20 step:18889 [D loss: 0.575004, acc.: 71.88%] [G loss: 0.945132]\n",
      "epoch:20 step:18890 [D loss: 0.276995, acc.: 85.94%] [G loss: 1.137655]\n",
      "epoch:20 step:18891 [D loss: 0.330807, acc.: 86.72%] [G loss: 1.244749]\n",
      "epoch:20 step:18892 [D loss: 0.506190, acc.: 74.22%] [G loss: 1.190953]\n",
      "epoch:20 step:18893 [D loss: 0.773403, acc.: 53.12%] [G loss: 1.091199]\n",
      "epoch:20 step:18894 [D loss: 0.793743, acc.: 46.09%] [G loss: 0.955859]\n",
      "epoch:20 step:18895 [D loss: 0.657397, acc.: 59.38%] [G loss: 0.776262]\n",
      "epoch:20 step:18896 [D loss: 0.725722, acc.: 60.16%] [G loss: 0.923281]\n",
      "epoch:20 step:18897 [D loss: 0.756263, acc.: 50.00%] [G loss: 0.881177]\n",
      "epoch:20 step:18898 [D loss: 0.756371, acc.: 42.97%] [G loss: 1.002296]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:18899 [D loss: 0.579843, acc.: 73.44%] [G loss: 1.004607]\n",
      "epoch:20 step:18900 [D loss: 0.645746, acc.: 61.72%] [G loss: 0.803028]\n",
      "epoch:20 step:18901 [D loss: 1.094259, acc.: 23.44%] [G loss: 1.017955]\n",
      "epoch:20 step:18902 [D loss: 0.551851, acc.: 72.66%] [G loss: 1.093910]\n",
      "epoch:20 step:18903 [D loss: 0.605013, acc.: 71.88%] [G loss: 1.112774]\n",
      "epoch:20 step:18904 [D loss: 0.629952, acc.: 60.16%] [G loss: 0.905281]\n",
      "epoch:20 step:18905 [D loss: 0.673054, acc.: 57.81%] [G loss: 0.633734]\n",
      "epoch:20 step:18906 [D loss: 0.699553, acc.: 58.59%] [G loss: 1.019820]\n",
      "epoch:20 step:18907 [D loss: 0.677977, acc.: 54.69%] [G loss: 0.633607]\n",
      "epoch:20 step:18908 [D loss: 0.484849, acc.: 82.03%] [G loss: 1.031095]\n",
      "epoch:20 step:18909 [D loss: 0.799867, acc.: 46.88%] [G loss: 1.075400]\n",
      "epoch:20 step:18910 [D loss: 0.875837, acc.: 32.03%] [G loss: 1.023933]\n",
      "epoch:20 step:18911 [D loss: 0.625713, acc.: 63.28%] [G loss: 1.041191]\n",
      "epoch:20 step:18912 [D loss: 0.670815, acc.: 61.72%] [G loss: 0.861926]\n",
      "epoch:20 step:18913 [D loss: 0.609010, acc.: 64.84%] [G loss: 0.929479]\n",
      "epoch:20 step:18914 [D loss: 0.605771, acc.: 64.06%] [G loss: 1.205510]\n",
      "epoch:20 step:18915 [D loss: 0.594853, acc.: 67.97%] [G loss: 0.912113]\n",
      "epoch:20 step:18916 [D loss: 0.437978, acc.: 87.50%] [G loss: 1.149878]\n",
      "epoch:20 step:18917 [D loss: 0.611704, acc.: 60.94%] [G loss: 0.860367]\n",
      "epoch:20 step:18918 [D loss: 0.802061, acc.: 39.06%] [G loss: 0.737972]\n",
      "epoch:20 step:18919 [D loss: 0.757016, acc.: 50.00%] [G loss: 0.871797]\n",
      "epoch:20 step:18920 [D loss: 0.624089, acc.: 64.84%] [G loss: 0.665845]\n",
      "epoch:20 step:18921 [D loss: 0.492569, acc.: 76.56%] [G loss: 0.929366]\n",
      "epoch:20 step:18922 [D loss: 0.607290, acc.: 64.84%] [G loss: 0.958963]\n",
      "epoch:20 step:18923 [D loss: 0.722156, acc.: 44.53%] [G loss: 1.067871]\n",
      "epoch:20 step:18924 [D loss: 0.379476, acc.: 92.19%] [G loss: 0.872122]\n",
      "epoch:20 step:18925 [D loss: 0.973100, acc.: 29.69%] [G loss: 0.900213]\n",
      "epoch:20 step:18926 [D loss: 0.813791, acc.: 33.59%] [G loss: 0.931271]\n",
      "epoch:20 step:18927 [D loss: 0.652668, acc.: 67.19%] [G loss: 0.880733]\n",
      "epoch:20 step:18928 [D loss: 0.505928, acc.: 82.03%] [G loss: 1.047786]\n",
      "epoch:20 step:18929 [D loss: 0.672388, acc.: 57.03%] [G loss: 0.734291]\n",
      "epoch:20 step:18930 [D loss: 0.686565, acc.: 53.91%] [G loss: 0.821206]\n",
      "epoch:20 step:18931 [D loss: 0.856262, acc.: 41.41%] [G loss: 0.971985]\n",
      "epoch:20 step:18932 [D loss: 0.365520, acc.: 86.72%] [G loss: 0.853202]\n",
      "epoch:20 step:18933 [D loss: 0.523061, acc.: 77.34%] [G loss: 0.976787]\n",
      "epoch:20 step:18934 [D loss: 0.452300, acc.: 87.50%] [G loss: 1.039369]\n",
      "epoch:20 step:18935 [D loss: 0.463726, acc.: 89.06%] [G loss: 1.016961]\n",
      "epoch:20 step:18936 [D loss: 0.574055, acc.: 72.66%] [G loss: 0.908628]\n",
      "epoch:20 step:18937 [D loss: 0.512649, acc.: 77.34%] [G loss: 0.954675]\n",
      "epoch:20 step:18938 [D loss: 0.558999, acc.: 70.31%] [G loss: 1.300067]\n",
      "epoch:20 step:18939 [D loss: 0.784759, acc.: 44.53%] [G loss: 1.138633]\n",
      "epoch:20 step:18940 [D loss: 0.755450, acc.: 50.00%] [G loss: 0.826240]\n",
      "epoch:20 step:18941 [D loss: 0.360061, acc.: 86.72%] [G loss: 0.594183]\n",
      "epoch:20 step:18942 [D loss: 0.842622, acc.: 39.84%] [G loss: 1.087040]\n",
      "epoch:20 step:18943 [D loss: 0.577853, acc.: 67.19%] [G loss: 0.920097]\n",
      "epoch:20 step:18944 [D loss: 0.456508, acc.: 81.25%] [G loss: 0.666516]\n",
      "epoch:20 step:18945 [D loss: 0.576207, acc.: 69.53%] [G loss: 1.159693]\n",
      "epoch:20 step:18946 [D loss: 0.460800, acc.: 81.25%] [G loss: 0.958408]\n",
      "epoch:20 step:18947 [D loss: 0.443616, acc.: 70.31%] [G loss: 1.216672]\n",
      "epoch:20 step:18948 [D loss: 0.738306, acc.: 57.03%] [G loss: 0.944957]\n",
      "epoch:20 step:18949 [D loss: 0.482563, acc.: 78.12%] [G loss: 0.997545]\n",
      "epoch:20 step:18950 [D loss: 0.883947, acc.: 49.22%] [G loss: 1.215132]\n",
      "epoch:20 step:18951 [D loss: 0.844913, acc.: 40.62%] [G loss: 1.145392]\n",
      "epoch:20 step:18952 [D loss: 0.826716, acc.: 39.84%] [G loss: 1.177179]\n",
      "epoch:20 step:18953 [D loss: 0.753362, acc.: 42.19%] [G loss: 1.095551]\n",
      "epoch:20 step:18954 [D loss: 0.778589, acc.: 53.12%] [G loss: 1.061745]\n",
      "epoch:20 step:18955 [D loss: 0.766640, acc.: 44.53%] [G loss: 1.017623]\n",
      "epoch:20 step:18956 [D loss: 0.754539, acc.: 54.69%] [G loss: 1.076205]\n",
      "epoch:20 step:18957 [D loss: 0.702511, acc.: 57.03%] [G loss: 1.009450]\n",
      "epoch:20 step:18958 [D loss: 0.678037, acc.: 63.28%] [G loss: 1.010375]\n",
      "epoch:20 step:18959 [D loss: 0.616531, acc.: 64.06%] [G loss: 0.959105]\n",
      "epoch:20 step:18960 [D loss: 0.347831, acc.: 80.47%] [G loss: 1.069803]\n",
      "epoch:20 step:18961 [D loss: 0.331270, acc.: 89.06%] [G loss: 1.049163]\n",
      "epoch:20 step:18962 [D loss: 0.261499, acc.: 92.19%] [G loss: 1.218867]\n",
      "epoch:20 step:18963 [D loss: 0.558838, acc.: 75.78%] [G loss: 1.440047]\n",
      "epoch:20 step:18964 [D loss: 0.783226, acc.: 44.53%] [G loss: 1.083648]\n",
      "epoch:20 step:18965 [D loss: 0.704942, acc.: 60.16%] [G loss: 1.017799]\n",
      "epoch:20 step:18966 [D loss: 0.668268, acc.: 53.91%] [G loss: 1.077928]\n",
      "epoch:20 step:18967 [D loss: 0.634744, acc.: 66.41%] [G loss: 1.187483]\n",
      "epoch:20 step:18968 [D loss: 0.672438, acc.: 57.81%] [G loss: 0.978110]\n",
      "epoch:20 step:18969 [D loss: 0.763701, acc.: 51.56%] [G loss: 1.026900]\n",
      "epoch:20 step:18970 [D loss: 0.262823, acc.: 86.72%] [G loss: 1.070915]\n",
      "epoch:20 step:18971 [D loss: 0.284641, acc.: 86.72%] [G loss: 1.137129]\n",
      "epoch:20 step:18972 [D loss: 0.266657, acc.: 89.06%] [G loss: 1.279419]\n",
      "epoch:20 step:18973 [D loss: 0.639577, acc.: 64.84%] [G loss: 1.170650]\n",
      "epoch:20 step:18974 [D loss: 0.428652, acc.: 85.94%] [G loss: 1.400021]\n",
      "epoch:20 step:18975 [D loss: 0.279235, acc.: 92.19%] [G loss: 1.286201]\n",
      "epoch:20 step:18976 [D loss: 0.606920, acc.: 68.75%] [G loss: 1.190506]\n",
      "epoch:20 step:18977 [D loss: 0.456299, acc.: 88.28%] [G loss: 1.370884]\n",
      "epoch:20 step:18978 [D loss: 0.253387, acc.: 96.88%] [G loss: 1.285946]\n",
      "epoch:20 step:18979 [D loss: 0.552369, acc.: 77.34%] [G loss: 1.135755]\n",
      "epoch:20 step:18980 [D loss: 0.643049, acc.: 65.62%] [G loss: 0.823408]\n",
      "epoch:20 step:18981 [D loss: 0.818831, acc.: 46.88%] [G loss: 1.063597]\n",
      "epoch:20 step:18982 [D loss: 0.645193, acc.: 60.16%] [G loss: 1.184058]\n",
      "epoch:20 step:18983 [D loss: 0.402433, acc.: 88.28%] [G loss: 1.197747]\n",
      "epoch:20 step:18984 [D loss: 0.572278, acc.: 67.19%] [G loss: 0.791984]\n",
      "epoch:20 step:18985 [D loss: 1.061757, acc.: 17.19%] [G loss: 0.905701]\n",
      "epoch:20 step:18986 [D loss: 0.731859, acc.: 43.75%] [G loss: 0.841865]\n",
      "epoch:20 step:18987 [D loss: 0.792799, acc.: 36.72%] [G loss: 1.028922]\n",
      "epoch:20 step:18988 [D loss: 0.690617, acc.: 58.59%] [G loss: 1.145850]\n",
      "epoch:20 step:18989 [D loss: 0.522602, acc.: 79.69%] [G loss: 1.119354]\n",
      "epoch:20 step:18990 [D loss: 0.640308, acc.: 63.28%] [G loss: 1.042228]\n",
      "epoch:20 step:18991 [D loss: 0.559111, acc.: 75.00%] [G loss: 0.880686]\n",
      "epoch:20 step:18992 [D loss: 0.530338, acc.: 73.44%] [G loss: 1.085918]\n",
      "epoch:20 step:18993 [D loss: 0.517632, acc.: 81.25%] [G loss: 0.453959]\n",
      "epoch:20 step:18994 [D loss: 0.445792, acc.: 77.34%] [G loss: 0.693598]\n",
      "epoch:20 step:18995 [D loss: 0.290716, acc.: 88.28%] [G loss: 1.254401]\n",
      "epoch:20 step:18996 [D loss: 0.370302, acc.: 75.78%] [G loss: 1.197579]\n",
      "epoch:20 step:18997 [D loss: 0.244870, acc.: 98.44%] [G loss: 1.280878]\n",
      "epoch:20 step:18998 [D loss: 0.697188, acc.: 54.69%] [G loss: 1.296345]\n",
      "epoch:20 step:18999 [D loss: 0.194962, acc.: 98.44%] [G loss: 1.349941]\n",
      "epoch:20 step:19000 [D loss: 0.269322, acc.: 97.66%] [G loss: 1.378305]\n",
      "##############\n",
      "[4.18459905 2.63085506 6.8375829  6.13502953 4.66266583 5.88341687\n",
      " 5.61514213 5.31499672 6.2152638  5.07539625]\n",
      "##########\n",
      "epoch:20 step:19001 [D loss: 0.256703, acc.: 91.41%] [G loss: 1.335833]\n",
      "epoch:20 step:19002 [D loss: 0.687231, acc.: 55.47%] [G loss: 1.183151]\n",
      "epoch:20 step:19003 [D loss: 0.419495, acc.: 75.00%] [G loss: 1.368797]\n",
      "epoch:20 step:19004 [D loss: 0.746809, acc.: 53.12%] [G loss: 1.188529]\n",
      "epoch:20 step:19005 [D loss: 0.547289, acc.: 79.69%] [G loss: 1.331218]\n",
      "epoch:20 step:19006 [D loss: 0.823872, acc.: 46.88%] [G loss: 1.407273]\n",
      "epoch:20 step:19007 [D loss: 0.676033, acc.: 50.78%] [G loss: 1.315084]\n",
      "epoch:20 step:19008 [D loss: 0.831745, acc.: 38.28%] [G loss: 1.274155]\n",
      "epoch:20 step:19009 [D loss: 0.597024, acc.: 67.97%] [G loss: 1.286556]\n",
      "epoch:20 step:19010 [D loss: 0.686857, acc.: 55.47%] [G loss: 1.153868]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19011 [D loss: 0.509396, acc.: 74.22%] [G loss: 0.801646]\n",
      "epoch:20 step:19012 [D loss: 0.623245, acc.: 65.62%] [G loss: 1.317554]\n",
      "epoch:20 step:19013 [D loss: 0.608567, acc.: 62.50%] [G loss: 1.016166]\n",
      "epoch:20 step:19014 [D loss: 0.570897, acc.: 69.53%] [G loss: 1.287526]\n",
      "epoch:20 step:19015 [D loss: 0.650130, acc.: 53.91%] [G loss: 1.204825]\n",
      "epoch:20 step:19016 [D loss: 0.499984, acc.: 78.12%] [G loss: 1.083650]\n",
      "epoch:20 step:19017 [D loss: 0.573477, acc.: 68.75%] [G loss: 1.071188]\n",
      "epoch:20 step:19018 [D loss: 0.409558, acc.: 86.72%] [G loss: 0.799318]\n",
      "epoch:20 step:19019 [D loss: 0.211429, acc.: 96.88%] [G loss: 1.229259]\n",
      "epoch:20 step:19020 [D loss: 0.715573, acc.: 50.00%] [G loss: 1.240804]\n",
      "epoch:20 step:19021 [D loss: 0.704084, acc.: 54.69%] [G loss: 1.202202]\n",
      "epoch:20 step:19022 [D loss: 0.614783, acc.: 66.41%] [G loss: 0.842274]\n",
      "epoch:20 step:19023 [D loss: 0.781708, acc.: 46.88%] [G loss: 1.012151]\n",
      "epoch:20 step:19024 [D loss: 0.636119, acc.: 64.06%] [G loss: 0.882466]\n",
      "epoch:20 step:19025 [D loss: 0.618452, acc.: 70.31%] [G loss: 0.852828]\n",
      "epoch:20 step:19026 [D loss: 0.515705, acc.: 78.12%] [G loss: 1.035323]\n",
      "epoch:20 step:19027 [D loss: 0.429263, acc.: 86.72%] [G loss: 0.565728]\n",
      "epoch:20 step:19028 [D loss: 0.405469, acc.: 76.56%] [G loss: 1.142448]\n",
      "epoch:20 step:19029 [D loss: 0.232282, acc.: 97.66%] [G loss: 0.947746]\n",
      "epoch:20 step:19030 [D loss: 0.872425, acc.: 42.19%] [G loss: 1.295462]\n",
      "epoch:20 step:19031 [D loss: 0.660636, acc.: 61.72%] [G loss: 1.302545]\n",
      "epoch:20 step:19032 [D loss: 0.242586, acc.: 97.66%] [G loss: 1.469914]\n",
      "epoch:20 step:19033 [D loss: 0.500185, acc.: 83.59%] [G loss: 1.195668]\n",
      "epoch:20 step:19034 [D loss: 0.672948, acc.: 61.72%] [G loss: 1.220858]\n",
      "epoch:20 step:19035 [D loss: 0.835193, acc.: 40.62%] [G loss: 1.263401]\n",
      "epoch:20 step:19036 [D loss: 0.715149, acc.: 52.34%] [G loss: 1.232549]\n",
      "epoch:20 step:19037 [D loss: 0.562669, acc.: 72.66%] [G loss: 0.917359]\n",
      "epoch:20 step:19038 [D loss: 0.547423, acc.: 76.56%] [G loss: 1.108215]\n",
      "epoch:20 step:19039 [D loss: 0.493496, acc.: 77.34%] [G loss: 1.241912]\n",
      "epoch:20 step:19040 [D loss: 0.546433, acc.: 75.00%] [G loss: 0.716322]\n",
      "epoch:20 step:19041 [D loss: 0.706626, acc.: 53.12%] [G loss: 1.117861]\n",
      "epoch:20 step:19042 [D loss: 0.689448, acc.: 55.47%] [G loss: 1.181939]\n",
      "epoch:20 step:19043 [D loss: 0.614035, acc.: 65.62%] [G loss: 1.259880]\n",
      "epoch:20 step:19044 [D loss: 0.682465, acc.: 60.94%] [G loss: 0.976964]\n",
      "epoch:20 step:19045 [D loss: 0.883071, acc.: 38.28%] [G loss: 1.088300]\n",
      "epoch:20 step:19046 [D loss: 0.660142, acc.: 60.94%] [G loss: 1.072442]\n",
      "epoch:20 step:19047 [D loss: 0.871940, acc.: 46.09%] [G loss: 1.167412]\n",
      "epoch:20 step:19048 [D loss: 0.771852, acc.: 49.22%] [G loss: 1.164531]\n",
      "epoch:20 step:19049 [D loss: 0.609416, acc.: 66.41%] [G loss: 1.065450]\n",
      "epoch:20 step:19050 [D loss: 0.679409, acc.: 57.81%] [G loss: 0.958879]\n",
      "epoch:20 step:19051 [D loss: 0.779714, acc.: 44.53%] [G loss: 1.014803]\n",
      "epoch:20 step:19052 [D loss: 0.405564, acc.: 91.41%] [G loss: 1.080596]\n",
      "epoch:20 step:19053 [D loss: 1.017127, acc.: 50.00%] [G loss: 1.140495]\n",
      "epoch:20 step:19054 [D loss: 0.421852, acc.: 89.06%] [G loss: 1.062164]\n",
      "epoch:20 step:19055 [D loss: 0.671289, acc.: 65.62%] [G loss: 1.058050]\n",
      "epoch:20 step:19056 [D loss: 0.443069, acc.: 87.50%] [G loss: 1.038483]\n",
      "epoch:20 step:19057 [D loss: 0.475428, acc.: 83.59%] [G loss: 0.782710]\n",
      "epoch:20 step:19058 [D loss: 0.488617, acc.: 80.47%] [G loss: 1.098721]\n",
      "epoch:20 step:19059 [D loss: 0.522794, acc.: 83.59%] [G loss: 1.089257]\n",
      "epoch:20 step:19060 [D loss: 0.509199, acc.: 85.94%] [G loss: 1.033998]\n",
      "epoch:20 step:19061 [D loss: 0.618305, acc.: 62.50%] [G loss: 0.884179]\n",
      "epoch:20 step:19062 [D loss: 0.642990, acc.: 62.50%] [G loss: 1.039799]\n",
      "epoch:20 step:19063 [D loss: 0.807057, acc.: 44.53%] [G loss: 1.253778]\n",
      "epoch:20 step:19064 [D loss: 0.685293, acc.: 57.03%] [G loss: 1.026566]\n",
      "epoch:20 step:19065 [D loss: 0.548927, acc.: 78.91%] [G loss: 1.041792]\n",
      "epoch:20 step:19066 [D loss: 0.590180, acc.: 72.66%] [G loss: 0.866661]\n",
      "epoch:20 step:19067 [D loss: 0.471420, acc.: 70.31%] [G loss: 1.015660]\n",
      "epoch:20 step:19068 [D loss: 0.442904, acc.: 77.34%] [G loss: 1.248539]\n",
      "epoch:20 step:19069 [D loss: 0.675505, acc.: 52.34%] [G loss: 1.208402]\n",
      "epoch:20 step:19070 [D loss: 0.779499, acc.: 44.53%] [G loss: 1.471903]\n",
      "epoch:20 step:19071 [D loss: 0.773351, acc.: 50.00%] [G loss: 1.085734]\n",
      "epoch:20 step:19072 [D loss: 0.910995, acc.: 24.22%] [G loss: 0.976443]\n",
      "epoch:20 step:19073 [D loss: 0.685149, acc.: 51.56%] [G loss: 1.020959]\n",
      "epoch:20 step:19074 [D loss: 0.640513, acc.: 60.94%] [G loss: 1.008161]\n",
      "epoch:20 step:19075 [D loss: 0.662635, acc.: 53.91%] [G loss: 1.121574]\n",
      "epoch:20 step:19076 [D loss: 0.462949, acc.: 85.16%] [G loss: 0.856283]\n",
      "epoch:20 step:19077 [D loss: 0.776046, acc.: 39.06%] [G loss: 0.998527]\n",
      "epoch:20 step:19078 [D loss: 0.653971, acc.: 61.72%] [G loss: 0.991698]\n",
      "epoch:20 step:19079 [D loss: 0.716385, acc.: 53.12%] [G loss: 0.979562]\n",
      "epoch:20 step:19080 [D loss: 0.678980, acc.: 61.72%] [G loss: 0.907626]\n",
      "epoch:20 step:19081 [D loss: 0.728304, acc.: 44.53%] [G loss: 0.959685]\n",
      "epoch:20 step:19082 [D loss: 0.457587, acc.: 78.12%] [G loss: 1.076123]\n",
      "epoch:20 step:19083 [D loss: 0.295911, acc.: 85.94%] [G loss: 1.106266]\n",
      "epoch:20 step:19084 [D loss: 0.343907, acc.: 89.06%] [G loss: 1.093884]\n",
      "epoch:20 step:19085 [D loss: 0.263986, acc.: 90.62%] [G loss: 1.284230]\n",
      "epoch:20 step:19086 [D loss: 0.312653, acc.: 89.06%] [G loss: 1.142582]\n",
      "epoch:20 step:19087 [D loss: 0.195276, acc.: 99.22%] [G loss: 1.447167]\n",
      "epoch:20 step:19088 [D loss: 0.788346, acc.: 50.00%] [G loss: 1.101882]\n",
      "epoch:20 step:19089 [D loss: 0.768204, acc.: 46.88%] [G loss: 1.235746]\n",
      "epoch:20 step:19090 [D loss: 0.582415, acc.: 72.66%] [G loss: 1.161745]\n",
      "epoch:20 step:19091 [D loss: 0.700077, acc.: 60.16%] [G loss: 0.979195]\n",
      "epoch:20 step:19092 [D loss: 0.612497, acc.: 72.66%] [G loss: 1.006399]\n",
      "epoch:20 step:19093 [D loss: 0.630920, acc.: 64.84%] [G loss: 0.900160]\n",
      "epoch:20 step:19094 [D loss: 0.576574, acc.: 72.66%] [G loss: 1.056629]\n",
      "epoch:20 step:19095 [D loss: 0.708267, acc.: 57.03%] [G loss: 0.967372]\n",
      "epoch:20 step:19096 [D loss: 0.732824, acc.: 46.09%] [G loss: 1.008525]\n",
      "epoch:20 step:19097 [D loss: 0.568020, acc.: 78.12%] [G loss: 0.999138]\n",
      "epoch:20 step:19098 [D loss: 0.553591, acc.: 76.56%] [G loss: 1.028106]\n",
      "epoch:20 step:19099 [D loss: 0.639254, acc.: 64.84%] [G loss: 0.995097]\n",
      "epoch:20 step:19100 [D loss: 0.653449, acc.: 61.72%] [G loss: 0.939872]\n",
      "epoch:20 step:19101 [D loss: 0.660211, acc.: 60.94%] [G loss: 0.828588]\n",
      "epoch:20 step:19102 [D loss: 0.564960, acc.: 71.88%] [G loss: 0.983002]\n",
      "epoch:20 step:19103 [D loss: 0.487747, acc.: 82.81%] [G loss: 0.867454]\n",
      "epoch:20 step:19104 [D loss: 0.570867, acc.: 71.88%] [G loss: 0.783306]\n",
      "epoch:20 step:19105 [D loss: 0.378996, acc.: 82.81%] [G loss: 0.960352]\n",
      "epoch:20 step:19106 [D loss: 0.310300, acc.: 85.94%] [G loss: 0.978161]\n",
      "epoch:20 step:19107 [D loss: 0.501069, acc.: 74.22%] [G loss: 1.081924]\n",
      "epoch:20 step:19108 [D loss: 0.638068, acc.: 65.62%] [G loss: 0.970420]\n",
      "epoch:20 step:19109 [D loss: 0.698566, acc.: 57.81%] [G loss: 0.882910]\n",
      "epoch:20 step:19110 [D loss: 0.570792, acc.: 67.97%] [G loss: 0.975624]\n",
      "epoch:20 step:19111 [D loss: 0.596594, acc.: 67.19%] [G loss: 1.097968]\n",
      "epoch:20 step:19112 [D loss: 0.858897, acc.: 35.94%] [G loss: 1.100228]\n",
      "epoch:20 step:19113 [D loss: 0.753900, acc.: 46.88%] [G loss: 0.947368]\n",
      "epoch:20 step:19114 [D loss: 0.741181, acc.: 48.44%] [G loss: 1.065706]\n",
      "epoch:20 step:19115 [D loss: 0.570210, acc.: 76.56%] [G loss: 1.071901]\n",
      "epoch:20 step:19116 [D loss: 1.137252, acc.: 43.75%] [G loss: 1.148935]\n",
      "epoch:20 step:19117 [D loss: 0.244545, acc.: 93.75%] [G loss: 1.113848]\n",
      "epoch:20 step:19118 [D loss: 0.199956, acc.: 100.00%] [G loss: 1.347152]\n",
      "epoch:20 step:19119 [D loss: 0.742336, acc.: 51.56%] [G loss: 1.194987]\n",
      "epoch:20 step:19120 [D loss: 0.637336, acc.: 64.06%] [G loss: 1.266107]\n",
      "epoch:20 step:19121 [D loss: 0.598735, acc.: 60.94%] [G loss: 1.070581]\n",
      "epoch:20 step:19122 [D loss: 0.705749, acc.: 53.12%] [G loss: 1.039007]\n",
      "epoch:20 step:19123 [D loss: 0.646870, acc.: 61.72%] [G loss: 1.020223]\n",
      "epoch:20 step:19124 [D loss: 0.893502, acc.: 53.12%] [G loss: 1.076192]\n",
      "epoch:20 step:19125 [D loss: 0.696451, acc.: 54.69%] [G loss: 0.988836]\n",
      "epoch:20 step:19126 [D loss: 0.730901, acc.: 47.66%] [G loss: 1.034734]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19127 [D loss: 0.705861, acc.: 49.22%] [G loss: 0.942668]\n",
      "epoch:20 step:19128 [D loss: 0.668017, acc.: 56.25%] [G loss: 0.919923]\n",
      "epoch:20 step:19129 [D loss: 0.590191, acc.: 68.75%] [G loss: 0.912591]\n",
      "epoch:20 step:19130 [D loss: 0.512000, acc.: 81.25%] [G loss: 0.936914]\n",
      "epoch:20 step:19131 [D loss: 0.647346, acc.: 59.38%] [G loss: 0.979560]\n",
      "epoch:20 step:19132 [D loss: 0.711958, acc.: 46.09%] [G loss: 1.002097]\n",
      "epoch:20 step:19133 [D loss: 0.388396, acc.: 88.28%] [G loss: 1.090630]\n",
      "epoch:20 step:19134 [D loss: 0.701781, acc.: 53.91%] [G loss: 0.955734]\n",
      "epoch:20 step:19135 [D loss: 0.711917, acc.: 48.44%] [G loss: 0.977971]\n",
      "epoch:20 step:19136 [D loss: 0.323478, acc.: 81.25%] [G loss: 1.031335]\n",
      "epoch:20 step:19137 [D loss: 0.218443, acc.: 95.31%] [G loss: 1.077750]\n",
      "epoch:20 step:19138 [D loss: 0.275515, acc.: 88.28%] [G loss: 1.045419]\n",
      "epoch:20 step:19139 [D loss: 0.185103, acc.: 96.09%] [G loss: 1.378534]\n",
      "epoch:20 step:19140 [D loss: 0.189180, acc.: 97.66%] [G loss: 1.447935]\n",
      "epoch:20 step:19141 [D loss: 0.201076, acc.: 95.31%] [G loss: 1.441783]\n",
      "epoch:20 step:19142 [D loss: 0.165240, acc.: 98.44%] [G loss: 1.415252]\n",
      "epoch:20 step:19143 [D loss: 0.286183, acc.: 96.09%] [G loss: 1.173939]\n",
      "epoch:20 step:19144 [D loss: 0.216131, acc.: 96.88%] [G loss: 1.523419]\n",
      "epoch:20 step:19145 [D loss: 0.143154, acc.: 98.44%] [G loss: 1.149450]\n",
      "epoch:20 step:19146 [D loss: 0.157746, acc.: 98.44%] [G loss: 1.452263]\n",
      "epoch:20 step:19147 [D loss: 0.199755, acc.: 94.53%] [G loss: 2.048748]\n",
      "epoch:20 step:19148 [D loss: 0.284425, acc.: 90.62%] [G loss: 1.992394]\n",
      "epoch:20 step:19149 [D loss: 0.436197, acc.: 73.44%] [G loss: 1.242962]\n",
      "epoch:20 step:19150 [D loss: 0.957945, acc.: 54.69%] [G loss: 1.640960]\n",
      "epoch:20 step:19151 [D loss: 1.048518, acc.: 50.00%] [G loss: 1.416714]\n",
      "epoch:20 step:19152 [D loss: 0.844500, acc.: 42.19%] [G loss: 0.519142]\n",
      "epoch:20 step:19153 [D loss: 0.342801, acc.: 92.97%] [G loss: 1.452462]\n",
      "epoch:20 step:19154 [D loss: 0.734686, acc.: 53.12%] [G loss: 1.684477]\n",
      "epoch:20 step:19155 [D loss: 0.875311, acc.: 35.94%] [G loss: 1.427773]\n",
      "epoch:20 step:19156 [D loss: 0.728701, acc.: 50.00%] [G loss: 1.653652]\n",
      "epoch:20 step:19157 [D loss: 0.377781, acc.: 86.72%] [G loss: 0.989873]\n",
      "epoch:20 step:19158 [D loss: 0.722705, acc.: 60.94%] [G loss: 1.601071]\n",
      "epoch:20 step:19159 [D loss: 0.407477, acc.: 84.38%] [G loss: 1.293401]\n",
      "epoch:20 step:19160 [D loss: 0.821974, acc.: 46.09%] [G loss: 1.021243]\n",
      "epoch:20 step:19161 [D loss: 0.912035, acc.: 51.56%] [G loss: 0.906355]\n",
      "epoch:20 step:19162 [D loss: 1.248291, acc.: 22.66%] [G loss: 1.519327]\n",
      "epoch:20 step:19163 [D loss: 0.830174, acc.: 49.22%] [G loss: 1.533157]\n",
      "epoch:20 step:19164 [D loss: 0.694067, acc.: 60.16%] [G loss: 1.397132]\n",
      "epoch:20 step:19165 [D loss: 0.614875, acc.: 60.94%] [G loss: 1.148434]\n",
      "epoch:20 step:19166 [D loss: 0.864587, acc.: 35.94%] [G loss: 1.219650]\n",
      "epoch:20 step:19167 [D loss: 0.744910, acc.: 53.91%] [G loss: 1.194042]\n",
      "epoch:20 step:19168 [D loss: 0.675187, acc.: 54.69%] [G loss: 1.057975]\n",
      "epoch:20 step:19169 [D loss: 0.770237, acc.: 47.66%] [G loss: 1.229541]\n",
      "epoch:20 step:19170 [D loss: 0.588196, acc.: 64.84%] [G loss: 1.018079]\n",
      "epoch:20 step:19171 [D loss: 0.695901, acc.: 50.00%] [G loss: 1.051527]\n",
      "epoch:20 step:19172 [D loss: 0.622953, acc.: 57.81%] [G loss: 1.227790]\n",
      "epoch:20 step:19173 [D loss: 0.629080, acc.: 55.47%] [G loss: 1.232655]\n",
      "epoch:20 step:19174 [D loss: 0.625154, acc.: 58.59%] [G loss: 1.307950]\n",
      "epoch:20 step:19175 [D loss: 0.539410, acc.: 67.19%] [G loss: 1.219946]\n",
      "epoch:20 step:19176 [D loss: 0.557402, acc.: 67.19%] [G loss: 1.437359]\n",
      "epoch:20 step:19177 [D loss: 0.665685, acc.: 48.44%] [G loss: 1.182953]\n",
      "epoch:20 step:19178 [D loss: 0.780476, acc.: 49.22%] [G loss: 1.077004]\n",
      "epoch:20 step:19179 [D loss: 0.613852, acc.: 62.50%] [G loss: 1.186498]\n",
      "epoch:20 step:19180 [D loss: 0.663226, acc.: 60.94%] [G loss: 1.033762]\n",
      "epoch:20 step:19181 [D loss: 0.615068, acc.: 67.19%] [G loss: 1.200002]\n",
      "epoch:20 step:19182 [D loss: 0.655404, acc.: 64.06%] [G loss: 1.032621]\n",
      "epoch:20 step:19183 [D loss: 0.514640, acc.: 83.59%] [G loss: 1.231308]\n",
      "epoch:20 step:19184 [D loss: 0.579598, acc.: 69.53%] [G loss: 1.246394]\n",
      "epoch:20 step:19185 [D loss: 0.592031, acc.: 67.97%] [G loss: 1.258048]\n",
      "epoch:20 step:19186 [D loss: 0.553047, acc.: 71.88%] [G loss: 1.236920]\n",
      "epoch:20 step:19187 [D loss: 0.573530, acc.: 72.66%] [G loss: 1.130122]\n",
      "epoch:20 step:19188 [D loss: 0.501440, acc.: 88.28%] [G loss: 1.197353]\n",
      "epoch:20 step:19189 [D loss: 0.444296, acc.: 90.62%] [G loss: 1.254780]\n",
      "epoch:20 step:19190 [D loss: 0.451831, acc.: 92.19%] [G loss: 1.057996]\n",
      "epoch:20 step:19191 [D loss: 0.404731, acc.: 90.62%] [G loss: 1.185672]\n",
      "epoch:20 step:19192 [D loss: 0.323275, acc.: 99.22%] [G loss: 1.330480]\n",
      "epoch:20 step:19193 [D loss: 0.338442, acc.: 96.88%] [G loss: 1.536072]\n",
      "epoch:20 step:19194 [D loss: 0.408405, acc.: 91.41%] [G loss: 1.412588]\n",
      "epoch:20 step:19195 [D loss: 0.390846, acc.: 92.97%] [G loss: 1.413457]\n",
      "epoch:20 step:19196 [D loss: 0.355015, acc.: 90.62%] [G loss: 1.475121]\n",
      "epoch:20 step:19197 [D loss: 0.404194, acc.: 91.41%] [G loss: 1.270179]\n",
      "epoch:20 step:19198 [D loss: 0.673554, acc.: 61.72%] [G loss: 0.837396]\n",
      "epoch:20 step:19199 [D loss: 0.696120, acc.: 56.25%] [G loss: 0.649531]\n",
      "epoch:20 step:19200 [D loss: 0.671374, acc.: 52.34%] [G loss: 1.535058]\n",
      "##############\n",
      "[3.90031448 2.61474353 6.39853814 5.70889242 4.61587748 6.28103144\n",
      " 4.93322739 5.16224884 5.73401333 4.85060158]\n",
      "##########\n",
      "epoch:20 step:19201 [D loss: 1.347665, acc.: 5.47%] [G loss: 0.566814]\n",
      "epoch:20 step:19202 [D loss: 1.120764, acc.: 28.91%] [G loss: 0.713975]\n",
      "epoch:20 step:19203 [D loss: 0.754433, acc.: 47.66%] [G loss: 0.580851]\n",
      "epoch:20 step:19204 [D loss: 0.757455, acc.: 51.56%] [G loss: 0.706558]\n",
      "epoch:20 step:19205 [D loss: 0.571078, acc.: 71.09%] [G loss: 0.640354]\n",
      "epoch:20 step:19206 [D loss: 0.623104, acc.: 64.84%] [G loss: 1.059803]\n",
      "epoch:20 step:19207 [D loss: 0.549578, acc.: 75.00%] [G loss: 0.841902]\n",
      "epoch:20 step:19208 [D loss: 0.453219, acc.: 78.12%] [G loss: 0.848920]\n",
      "epoch:20 step:19209 [D loss: 0.438780, acc.: 86.72%] [G loss: 0.869427]\n",
      "epoch:20 step:19210 [D loss: 0.339436, acc.: 92.97%] [G loss: 1.206387]\n",
      "epoch:20 step:19211 [D loss: 0.369006, acc.: 85.16%] [G loss: 1.516733]\n",
      "epoch:20 step:19212 [D loss: 0.499232, acc.: 84.38%] [G loss: 1.036363]\n",
      "epoch:20 step:19213 [D loss: 1.093482, acc.: 19.53%] [G loss: 1.084570]\n",
      "epoch:20 step:19214 [D loss: 0.928239, acc.: 29.69%] [G loss: 1.157214]\n",
      "epoch:20 step:19215 [D loss: 0.768698, acc.: 46.09%] [G loss: 0.920777]\n",
      "epoch:20 step:19216 [D loss: 0.699612, acc.: 56.25%] [G loss: 0.941925]\n",
      "epoch:20 step:19217 [D loss: 0.733406, acc.: 50.00%] [G loss: 0.880752]\n",
      "epoch:20 step:19218 [D loss: 0.664780, acc.: 57.81%] [G loss: 0.831588]\n",
      "epoch:20 step:19219 [D loss: 0.540741, acc.: 74.22%] [G loss: 0.884041]\n",
      "epoch:20 step:19220 [D loss: 0.554628, acc.: 70.31%] [G loss: 0.794201]\n",
      "epoch:20 step:19221 [D loss: 0.468472, acc.: 79.69%] [G loss: 0.735684]\n",
      "epoch:20 step:19222 [D loss: 0.891767, acc.: 29.69%] [G loss: 0.816443]\n",
      "epoch:20 step:19223 [D loss: 0.733372, acc.: 47.66%] [G loss: 0.708042]\n",
      "epoch:20 step:19224 [D loss: 0.629484, acc.: 66.41%] [G loss: 0.896374]\n",
      "epoch:20 step:19225 [D loss: 0.730152, acc.: 48.44%] [G loss: 1.126449]\n",
      "epoch:20 step:19226 [D loss: 0.700890, acc.: 46.09%] [G loss: 0.860294]\n",
      "epoch:20 step:19227 [D loss: 0.691927, acc.: 46.88%] [G loss: 1.150644]\n",
      "epoch:20 step:19228 [D loss: 0.662905, acc.: 56.25%] [G loss: 1.165413]\n",
      "epoch:20 step:19229 [D loss: 0.727137, acc.: 58.59%] [G loss: 1.186185]\n",
      "epoch:20 step:19230 [D loss: 0.661277, acc.: 65.62%] [G loss: 1.008074]\n",
      "epoch:20 step:19231 [D loss: 0.660265, acc.: 58.59%] [G loss: 0.822083]\n",
      "epoch:20 step:19232 [D loss: 0.666659, acc.: 57.81%] [G loss: 0.776597]\n",
      "epoch:20 step:19233 [D loss: 0.729593, acc.: 50.78%] [G loss: 0.927565]\n",
      "epoch:20 step:19234 [D loss: 0.693556, acc.: 53.91%] [G loss: 0.897132]\n",
      "epoch:20 step:19235 [D loss: 0.709771, acc.: 52.34%] [G loss: 0.967777]\n",
      "epoch:20 step:19236 [D loss: 0.664680, acc.: 56.25%] [G loss: 0.888841]\n",
      "epoch:20 step:19237 [D loss: 0.490497, acc.: 78.12%] [G loss: 1.003190]\n",
      "epoch:20 step:19238 [D loss: 0.454204, acc.: 81.25%] [G loss: 0.986513]\n",
      "epoch:20 step:19239 [D loss: 0.381406, acc.: 91.41%] [G loss: 1.185725]\n",
      "epoch:20 step:19240 [D loss: 0.615911, acc.: 64.06%] [G loss: 1.062081]\n",
      "epoch:20 step:19241 [D loss: 0.639635, acc.: 64.84%] [G loss: 1.074203]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19242 [D loss: 0.577213, acc.: 69.53%] [G loss: 0.943139]\n",
      "epoch:20 step:19243 [D loss: 0.669465, acc.: 57.03%] [G loss: 0.903530]\n",
      "epoch:20 step:19244 [D loss: 0.591026, acc.: 64.84%] [G loss: 0.838688]\n",
      "epoch:20 step:19245 [D loss: 0.594348, acc.: 69.53%] [G loss: 0.865189]\n",
      "epoch:20 step:19246 [D loss: 0.679031, acc.: 60.94%] [G loss: 0.796831]\n",
      "epoch:20 step:19247 [D loss: 0.687028, acc.: 56.25%] [G loss: 0.843361]\n",
      "epoch:20 step:19248 [D loss: 0.658660, acc.: 57.81%] [G loss: 0.975536]\n",
      "epoch:20 step:19249 [D loss: 0.712953, acc.: 49.22%] [G loss: 0.875104]\n",
      "epoch:20 step:19250 [D loss: 0.472725, acc.: 76.56%] [G loss: 0.999642]\n",
      "epoch:20 step:19251 [D loss: 0.387482, acc.: 82.81%] [G loss: 1.070262]\n",
      "epoch:20 step:19252 [D loss: 0.492333, acc.: 82.03%] [G loss: 1.284667]\n",
      "epoch:20 step:19253 [D loss: 0.356686, acc.: 85.94%] [G loss: 1.369482]\n",
      "epoch:20 step:19254 [D loss: 0.353309, acc.: 89.06%] [G loss: 1.292130]\n",
      "epoch:20 step:19255 [D loss: 0.280141, acc.: 97.66%] [G loss: 1.506619]\n",
      "epoch:20 step:19256 [D loss: 0.710878, acc.: 63.28%] [G loss: 1.142709]\n",
      "epoch:20 step:19257 [D loss: 0.552293, acc.: 71.09%] [G loss: 1.089604]\n",
      "epoch:20 step:19258 [D loss: 0.714164, acc.: 53.91%] [G loss: 1.035283]\n",
      "epoch:20 step:19259 [D loss: 0.621441, acc.: 64.06%] [G loss: 0.991153]\n",
      "epoch:20 step:19260 [D loss: 0.627792, acc.: 66.41%] [G loss: 0.852834]\n",
      "epoch:20 step:19261 [D loss: 0.653238, acc.: 60.94%] [G loss: 0.937496]\n",
      "epoch:20 step:19262 [D loss: 0.660563, acc.: 56.25%] [G loss: 0.981113]\n",
      "epoch:20 step:19263 [D loss: 0.672927, acc.: 59.38%] [G loss: 0.871159]\n",
      "epoch:20 step:19264 [D loss: 0.398544, acc.: 78.91%] [G loss: 0.995566]\n",
      "epoch:20 step:19265 [D loss: 0.592701, acc.: 67.19%] [G loss: 0.773153]\n",
      "epoch:20 step:19266 [D loss: 0.499353, acc.: 81.25%] [G loss: 1.081289]\n",
      "epoch:20 step:19267 [D loss: 0.387039, acc.: 87.50%] [G loss: 1.137126]\n",
      "epoch:20 step:19268 [D loss: 0.679569, acc.: 63.28%] [G loss: 1.125820]\n",
      "epoch:20 step:19269 [D loss: 0.511339, acc.: 81.25%] [G loss: 1.154271]\n",
      "epoch:20 step:19270 [D loss: 0.335424, acc.: 85.94%] [G loss: 1.146925]\n",
      "epoch:20 step:19271 [D loss: 0.675846, acc.: 62.50%] [G loss: 1.065168]\n",
      "epoch:20 step:19272 [D loss: 0.723251, acc.: 57.81%] [G loss: 1.086282]\n",
      "epoch:20 step:19273 [D loss: 0.651028, acc.: 59.38%] [G loss: 0.905565]\n",
      "epoch:20 step:19274 [D loss: 0.727899, acc.: 52.34%] [G loss: 0.906496]\n",
      "epoch:20 step:19275 [D loss: 0.335506, acc.: 89.06%] [G loss: 1.013875]\n",
      "epoch:20 step:19276 [D loss: 0.242279, acc.: 96.09%] [G loss: 1.124867]\n",
      "epoch:20 step:19277 [D loss: 0.326630, acc.: 91.41%] [G loss: 1.158897]\n",
      "epoch:20 step:19278 [D loss: 0.405225, acc.: 94.53%] [G loss: 1.193184]\n",
      "epoch:20 step:19279 [D loss: 0.262691, acc.: 97.66%] [G loss: 1.347155]\n",
      "epoch:20 step:19280 [D loss: 0.496862, acc.: 79.69%] [G loss: 1.386171]\n",
      "epoch:20 step:19281 [D loss: 0.387372, acc.: 92.19%] [G loss: 1.336802]\n",
      "epoch:20 step:19282 [D loss: 0.706941, acc.: 59.38%] [G loss: 1.287974]\n",
      "epoch:20 step:19283 [D loss: 0.306492, acc.: 88.28%] [G loss: 1.430048]\n",
      "epoch:20 step:19284 [D loss: 0.770151, acc.: 50.00%] [G loss: 1.008292]\n",
      "epoch:20 step:19285 [D loss: 0.658991, acc.: 52.34%] [G loss: 1.339260]\n",
      "epoch:20 step:19286 [D loss: 0.723033, acc.: 57.81%] [G loss: 0.953559]\n",
      "epoch:20 step:19287 [D loss: 0.609543, acc.: 69.53%] [G loss: 0.872310]\n",
      "epoch:20 step:19288 [D loss: 0.584656, acc.: 69.53%] [G loss: 0.949304]\n",
      "epoch:20 step:19289 [D loss: 0.612832, acc.: 65.62%] [G loss: 1.220297]\n",
      "epoch:20 step:19290 [D loss: 0.425751, acc.: 84.38%] [G loss: 1.078766]\n",
      "epoch:20 step:19291 [D loss: 0.747905, acc.: 52.34%] [G loss: 0.990539]\n",
      "epoch:20 step:19292 [D loss: 0.579244, acc.: 68.75%] [G loss: 0.960262]\n",
      "epoch:20 step:19293 [D loss: 0.695745, acc.: 57.03%] [G loss: 0.738870]\n",
      "epoch:20 step:19294 [D loss: 0.391154, acc.: 91.41%] [G loss: 1.153694]\n",
      "epoch:20 step:19295 [D loss: 0.668586, acc.: 64.06%] [G loss: 1.156445]\n",
      "epoch:20 step:19296 [D loss: 0.475420, acc.: 77.34%] [G loss: 0.785937]\n",
      "epoch:20 step:19297 [D loss: 0.461058, acc.: 87.50%] [G loss: 1.030172]\n",
      "epoch:20 step:19298 [D loss: 0.585459, acc.: 67.97%] [G loss: 0.819615]\n",
      "epoch:20 step:19299 [D loss: 0.428272, acc.: 67.97%] [G loss: 1.039904]\n",
      "epoch:20 step:19300 [D loss: 0.441564, acc.: 82.03%] [G loss: 1.243637]\n",
      "epoch:20 step:19301 [D loss: 0.439854, acc.: 68.75%] [G loss: 1.565271]\n",
      "epoch:20 step:19302 [D loss: 0.742370, acc.: 61.72%] [G loss: 1.436561]\n",
      "epoch:20 step:19303 [D loss: 0.662239, acc.: 62.50%] [G loss: 1.382497]\n",
      "epoch:20 step:19304 [D loss: 0.650346, acc.: 59.38%] [G loss: 1.244312]\n",
      "epoch:20 step:19305 [D loss: 0.335650, acc.: 92.19%] [G loss: 1.176793]\n",
      "epoch:20 step:19306 [D loss: 0.242594, acc.: 90.62%] [G loss: 1.395722]\n",
      "epoch:20 step:19307 [D loss: 0.176572, acc.: 97.66%] [G loss: 1.216122]\n",
      "epoch:20 step:19308 [D loss: 0.445017, acc.: 82.03%] [G loss: 1.331222]\n",
      "epoch:20 step:19309 [D loss: 0.714404, acc.: 56.25%] [G loss: 1.442675]\n",
      "epoch:20 step:19310 [D loss: 0.462643, acc.: 85.16%] [G loss: 1.315487]\n",
      "epoch:20 step:19311 [D loss: 0.649914, acc.: 55.47%] [G loss: 1.090007]\n",
      "epoch:20 step:19312 [D loss: 0.632510, acc.: 61.72%] [G loss: 1.236624]\n",
      "epoch:20 step:19313 [D loss: 0.348531, acc.: 92.19%] [G loss: 1.252487]\n",
      "epoch:20 step:19314 [D loss: 0.511762, acc.: 75.78%] [G loss: 0.844470]\n",
      "epoch:20 step:19315 [D loss: 0.491279, acc.: 79.69%] [G loss: 0.531786]\n",
      "epoch:20 step:19316 [D loss: 0.210656, acc.: 97.66%] [G loss: 1.495726]\n",
      "epoch:20 step:19317 [D loss: 0.131372, acc.: 99.22%] [G loss: 1.483793]\n",
      "epoch:20 step:19318 [D loss: 0.284722, acc.: 85.16%] [G loss: 1.269711]\n",
      "epoch:20 step:19319 [D loss: 0.195919, acc.: 96.09%] [G loss: 1.583508]\n",
      "epoch:20 step:19320 [D loss: 0.865344, acc.: 47.66%] [G loss: 2.940341]\n",
      "epoch:20 step:19321 [D loss: 0.842719, acc.: 49.22%] [G loss: 1.472665]\n",
      "epoch:20 step:19322 [D loss: 1.191955, acc.: 25.78%] [G loss: 1.494418]\n",
      "epoch:20 step:19323 [D loss: 0.915253, acc.: 45.31%] [G loss: 1.853632]\n",
      "epoch:20 step:19324 [D loss: 0.872237, acc.: 49.22%] [G loss: 1.463935]\n",
      "epoch:20 step:19325 [D loss: 0.712118, acc.: 55.47%] [G loss: 1.695816]\n",
      "epoch:20 step:19326 [D loss: 0.780061, acc.: 53.12%] [G loss: 1.407389]\n",
      "epoch:20 step:19327 [D loss: 0.551915, acc.: 72.66%] [G loss: 0.921661]\n",
      "epoch:20 step:19328 [D loss: 0.755472, acc.: 60.16%] [G loss: 1.449716]\n",
      "epoch:20 step:19329 [D loss: 0.500104, acc.: 78.12%] [G loss: 1.195415]\n",
      "epoch:20 step:19330 [D loss: 0.899676, acc.: 35.16%] [G loss: 1.213928]\n",
      "epoch:20 step:19331 [D loss: 0.649390, acc.: 64.84%] [G loss: 1.165405]\n",
      "epoch:20 step:19332 [D loss: 0.499657, acc.: 75.78%] [G loss: 1.292448]\n",
      "epoch:20 step:19333 [D loss: 0.668527, acc.: 54.69%] [G loss: 1.387329]\n",
      "epoch:20 step:19334 [D loss: 0.784488, acc.: 45.31%] [G loss: 1.438043]\n",
      "epoch:20 step:19335 [D loss: 0.738526, acc.: 53.91%] [G loss: 1.249526]\n",
      "epoch:20 step:19336 [D loss: 0.529657, acc.: 75.78%] [G loss: 1.232014]\n",
      "epoch:20 step:19337 [D loss: 0.715114, acc.: 50.78%] [G loss: 1.621004]\n",
      "epoch:20 step:19338 [D loss: 0.453172, acc.: 84.38%] [G loss: 1.550627]\n",
      "epoch:20 step:19339 [D loss: 0.466877, acc.: 78.12%] [G loss: 1.525613]\n",
      "epoch:20 step:19340 [D loss: 0.600034, acc.: 67.97%] [G loss: 1.249482]\n",
      "epoch:20 step:19341 [D loss: 0.636199, acc.: 63.28%] [G loss: 1.050128]\n",
      "epoch:20 step:19342 [D loss: 0.662346, acc.: 59.38%] [G loss: 1.138789]\n",
      "epoch:20 step:19343 [D loss: 0.494254, acc.: 82.81%] [G loss: 1.227056]\n",
      "epoch:20 step:19344 [D loss: 0.327537, acc.: 85.16%] [G loss: 1.090331]\n",
      "epoch:20 step:19345 [D loss: 0.506837, acc.: 78.12%] [G loss: 1.191000]\n",
      "epoch:20 step:19346 [D loss: 0.664789, acc.: 59.38%] [G loss: 1.097037]\n",
      "epoch:20 step:19347 [D loss: 0.666307, acc.: 60.94%] [G loss: 0.935140]\n",
      "epoch:20 step:19348 [D loss: 0.732495, acc.: 52.34%] [G loss: 0.990496]\n",
      "epoch:20 step:19349 [D loss: 0.683366, acc.: 54.69%] [G loss: 1.038198]\n",
      "epoch:20 step:19350 [D loss: 0.582473, acc.: 72.66%] [G loss: 1.005953]\n",
      "epoch:20 step:19351 [D loss: 0.862969, acc.: 40.62%] [G loss: 0.819101]\n",
      "epoch:20 step:19352 [D loss: 0.783560, acc.: 43.75%] [G loss: 0.798543]\n",
      "epoch:20 step:19353 [D loss: 0.605771, acc.: 67.97%] [G loss: 0.822330]\n",
      "epoch:20 step:19354 [D loss: 0.719861, acc.: 55.47%] [G loss: 0.986292]\n",
      "epoch:20 step:19355 [D loss: 0.543667, acc.: 75.78%] [G loss: 0.924507]\n",
      "epoch:20 step:19356 [D loss: 0.408266, acc.: 89.06%] [G loss: 1.104911]\n",
      "epoch:20 step:19357 [D loss: 0.431106, acc.: 86.72%] [G loss: 0.916625]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19358 [D loss: 0.832573, acc.: 46.88%] [G loss: 0.961300]\n",
      "epoch:20 step:19359 [D loss: 0.727358, acc.: 56.25%] [G loss: 0.973174]\n",
      "epoch:20 step:19360 [D loss: 0.673904, acc.: 57.81%] [G loss: 1.006785]\n",
      "epoch:20 step:19361 [D loss: 0.581998, acc.: 67.97%] [G loss: 0.812785]\n",
      "epoch:20 step:19362 [D loss: 0.571805, acc.: 65.62%] [G loss: 1.122672]\n",
      "epoch:20 step:19363 [D loss: 0.461492, acc.: 88.28%] [G loss: 1.131133]\n",
      "epoch:20 step:19364 [D loss: 0.429110, acc.: 86.72%] [G loss: 0.852050]\n",
      "epoch:20 step:19365 [D loss: 0.875071, acc.: 48.44%] [G loss: 0.982846]\n",
      "epoch:20 step:19366 [D loss: 0.540249, acc.: 78.91%] [G loss: 0.859980]\n",
      "epoch:20 step:19367 [D loss: 0.694390, acc.: 45.31%] [G loss: 0.752567]\n",
      "epoch:20 step:19368 [D loss: 0.698617, acc.: 52.34%] [G loss: 0.671392]\n",
      "epoch:20 step:19369 [D loss: 0.556553, acc.: 68.75%] [G loss: 1.145389]\n",
      "epoch:20 step:19370 [D loss: 0.525695, acc.: 77.34%] [G loss: 1.027658]\n",
      "epoch:20 step:19371 [D loss: 0.682335, acc.: 63.28%] [G loss: 0.994247]\n",
      "epoch:20 step:19372 [D loss: 0.364836, acc.: 89.06%] [G loss: 0.562964]\n",
      "epoch:20 step:19373 [D loss: 0.353743, acc.: 83.59%] [G loss: 0.698841]\n",
      "epoch:20 step:19374 [D loss: 0.459386, acc.: 77.34%] [G loss: 0.961711]\n",
      "epoch:20 step:19375 [D loss: 0.337932, acc.: 93.75%] [G loss: 1.039489]\n",
      "epoch:20 step:19376 [D loss: 0.897576, acc.: 41.41%] [G loss: 1.119010]\n",
      "epoch:20 step:19377 [D loss: 0.568612, acc.: 76.56%] [G loss: 1.314371]\n",
      "epoch:20 step:19378 [D loss: 0.657913, acc.: 60.94%] [G loss: 1.406121]\n",
      "epoch:20 step:19379 [D loss: 0.891761, acc.: 46.09%] [G loss: 1.213195]\n",
      "epoch:20 step:19380 [D loss: 0.948722, acc.: 22.66%] [G loss: 0.915947]\n",
      "epoch:20 step:19381 [D loss: 0.621574, acc.: 61.72%] [G loss: 0.557948]\n",
      "epoch:20 step:19382 [D loss: 0.940478, acc.: 28.12%] [G loss: 1.041188]\n",
      "epoch:20 step:19383 [D loss: 0.642534, acc.: 62.50%] [G loss: 0.984518]\n",
      "epoch:20 step:19384 [D loss: 0.368813, acc.: 88.28%] [G loss: 0.841121]\n",
      "epoch:20 step:19385 [D loss: 0.515837, acc.: 73.44%] [G loss: 0.841169]\n",
      "epoch:20 step:19386 [D loss: 0.402265, acc.: 84.38%] [G loss: 1.166121]\n",
      "epoch:20 step:19387 [D loss: 0.476265, acc.: 86.72%] [G loss: 0.828794]\n",
      "epoch:20 step:19388 [D loss: 0.381732, acc.: 92.19%] [G loss: 1.181910]\n",
      "epoch:20 step:19389 [D loss: 0.508815, acc.: 78.12%] [G loss: 0.589664]\n",
      "epoch:20 step:19390 [D loss: 0.541610, acc.: 71.09%] [G loss: 0.926289]\n",
      "epoch:20 step:19391 [D loss: 0.690318, acc.: 54.69%] [G loss: 1.066297]\n",
      "epoch:20 step:19392 [D loss: 0.761971, acc.: 54.69%] [G loss: 0.682621]\n",
      "epoch:20 step:19393 [D loss: 0.866139, acc.: 28.12%] [G loss: 1.250845]\n",
      "epoch:20 step:19394 [D loss: 0.690556, acc.: 57.81%] [G loss: 0.590163]\n",
      "epoch:20 step:19395 [D loss: 0.807352, acc.: 42.19%] [G loss: 0.841380]\n",
      "epoch:20 step:19396 [D loss: 0.881719, acc.: 35.16%] [G loss: 0.994126]\n",
      "epoch:20 step:19397 [D loss: 0.717525, acc.: 56.25%] [G loss: 0.726468]\n",
      "epoch:20 step:19398 [D loss: 0.778058, acc.: 40.62%] [G loss: 0.954721]\n",
      "epoch:20 step:19399 [D loss: 0.530785, acc.: 78.91%] [G loss: 0.992480]\n",
      "epoch:20 step:19400 [D loss: 0.574228, acc.: 71.09%] [G loss: 0.842353]\n",
      "##############\n",
      "[3.55558544 1.95379288 6.28511031 5.51130097 4.32954783 5.94565223\n",
      " 5.31023066 5.20951824 5.84144784 4.87329531]\n",
      "##########\n",
      "epoch:20 step:19401 [D loss: 0.636980, acc.: 59.38%] [G loss: 0.789289]\n",
      "epoch:20 step:19402 [D loss: 0.779405, acc.: 39.84%] [G loss: 1.074370]\n",
      "epoch:20 step:19403 [D loss: 0.305253, acc.: 95.31%] [G loss: 1.004516]\n",
      "epoch:20 step:19404 [D loss: 0.374970, acc.: 85.94%] [G loss: 1.305450]\n",
      "epoch:20 step:19405 [D loss: 0.303053, acc.: 89.06%] [G loss: 1.362171]\n",
      "epoch:20 step:19406 [D loss: 0.652992, acc.: 56.25%] [G loss: 1.357714]\n",
      "epoch:20 step:19407 [D loss: 0.620128, acc.: 65.62%] [G loss: 1.529324]\n",
      "epoch:20 step:19408 [D loss: 0.697954, acc.: 60.94%] [G loss: 1.476305]\n",
      "epoch:20 step:19409 [D loss: 0.636175, acc.: 62.50%] [G loss: 1.150547]\n",
      "epoch:20 step:19410 [D loss: 0.709889, acc.: 53.12%] [G loss: 1.154059]\n",
      "epoch:20 step:19411 [D loss: 0.617887, acc.: 65.62%] [G loss: 1.239200]\n",
      "epoch:20 step:19412 [D loss: 0.686411, acc.: 55.47%] [G loss: 1.204899]\n",
      "epoch:20 step:19413 [D loss: 0.611164, acc.: 70.31%] [G loss: 1.090518]\n",
      "epoch:20 step:19414 [D loss: 0.624227, acc.: 62.50%] [G loss: 1.223272]\n",
      "epoch:20 step:19415 [D loss: 0.695633, acc.: 59.38%] [G loss: 1.179787]\n",
      "epoch:20 step:19416 [D loss: 0.646408, acc.: 63.28%] [G loss: 1.216709]\n",
      "epoch:20 step:19417 [D loss: 0.647798, acc.: 60.94%] [G loss: 1.062909]\n",
      "epoch:20 step:19418 [D loss: 0.696691, acc.: 54.69%] [G loss: 0.920192]\n",
      "epoch:20 step:19419 [D loss: 0.735024, acc.: 46.88%] [G loss: 0.858679]\n",
      "epoch:20 step:19420 [D loss: 0.659971, acc.: 57.81%] [G loss: 0.941797]\n",
      "epoch:20 step:19421 [D loss: 0.737801, acc.: 52.34%] [G loss: 0.837418]\n",
      "epoch:20 step:19422 [D loss: 0.539154, acc.: 75.78%] [G loss: 1.009446]\n",
      "epoch:20 step:19423 [D loss: 0.640507, acc.: 57.03%] [G loss: 0.740700]\n",
      "epoch:20 step:19424 [D loss: 0.533923, acc.: 79.69%] [G loss: 0.898627]\n",
      "epoch:20 step:19425 [D loss: 0.523212, acc.: 79.69%] [G loss: 0.917158]\n",
      "epoch:20 step:19426 [D loss: 0.511455, acc.: 74.22%] [G loss: 0.972717]\n",
      "epoch:20 step:19427 [D loss: 0.557346, acc.: 73.44%] [G loss: 0.923794]\n",
      "epoch:20 step:19428 [D loss: 0.596846, acc.: 63.28%] [G loss: 1.037324]\n",
      "epoch:20 step:19429 [D loss: 0.791310, acc.: 52.34%] [G loss: 0.906852]\n",
      "epoch:20 step:19430 [D loss: 0.751570, acc.: 53.91%] [G loss: 0.958417]\n",
      "epoch:20 step:19431 [D loss: 0.711860, acc.: 54.69%] [G loss: 0.869520]\n",
      "epoch:20 step:19432 [D loss: 0.693183, acc.: 54.69%] [G loss: 0.844748]\n",
      "epoch:20 step:19433 [D loss: 0.700742, acc.: 52.34%] [G loss: 0.792333]\n",
      "epoch:20 step:19434 [D loss: 0.666996, acc.: 59.38%] [G loss: 0.801609]\n",
      "epoch:20 step:19435 [D loss: 0.671738, acc.: 60.16%] [G loss: 0.739824]\n",
      "epoch:20 step:19436 [D loss: 0.330202, acc.: 89.84%] [G loss: 0.858140]\n",
      "epoch:20 step:19437 [D loss: 0.277807, acc.: 90.62%] [G loss: 1.022718]\n",
      "epoch:20 step:19438 [D loss: 0.316948, acc.: 92.19%] [G loss: 1.054540]\n",
      "epoch:20 step:19439 [D loss: 0.507996, acc.: 82.03%] [G loss: 1.011383]\n",
      "epoch:20 step:19440 [D loss: 0.231314, acc.: 95.31%] [G loss: 0.962333]\n",
      "epoch:20 step:19441 [D loss: 0.220996, acc.: 98.44%] [G loss: 1.112378]\n",
      "epoch:20 step:19442 [D loss: 0.260082, acc.: 96.09%] [G loss: 1.336708]\n",
      "epoch:20 step:19443 [D loss: 0.648230, acc.: 61.72%] [G loss: 1.349809]\n",
      "epoch:20 step:19444 [D loss: 0.344361, acc.: 93.75%] [G loss: 1.116739]\n",
      "epoch:20 step:19445 [D loss: 0.691198, acc.: 55.47%] [G loss: 1.338538]\n",
      "epoch:20 step:19446 [D loss: 0.224434, acc.: 96.09%] [G loss: 0.821844]\n",
      "epoch:20 step:19447 [D loss: 0.328053, acc.: 80.47%] [G loss: 1.344455]\n",
      "epoch:20 step:19448 [D loss: 0.206477, acc.: 95.31%] [G loss: 1.436338]\n",
      "epoch:20 step:19449 [D loss: 0.187865, acc.: 99.22%] [G loss: 1.966132]\n",
      "epoch:20 step:19450 [D loss: 0.859833, acc.: 54.69%] [G loss: 0.945210]\n",
      "epoch:20 step:19451 [D loss: 0.761109, acc.: 61.72%] [G loss: 1.234769]\n",
      "epoch:20 step:19452 [D loss: 0.734786, acc.: 51.56%] [G loss: 0.955300]\n",
      "epoch:20 step:19453 [D loss: 0.198254, acc.: 96.88%] [G loss: 1.154578]\n",
      "epoch:20 step:19454 [D loss: 0.322641, acc.: 83.59%] [G loss: 0.867317]\n",
      "epoch:20 step:19455 [D loss: 0.803466, acc.: 47.66%] [G loss: 1.308993]\n",
      "epoch:20 step:19456 [D loss: 1.202749, acc.: 14.06%] [G loss: 1.012772]\n",
      "epoch:20 step:19457 [D loss: 0.791055, acc.: 48.44%] [G loss: 1.392592]\n",
      "epoch:20 step:19458 [D loss: 0.782984, acc.: 44.53%] [G loss: 1.293013]\n",
      "epoch:20 step:19459 [D loss: 0.703985, acc.: 50.00%] [G loss: 1.453806]\n",
      "epoch:20 step:19460 [D loss: 0.590508, acc.: 67.19%] [G loss: 1.483672]\n",
      "epoch:20 step:19461 [D loss: 0.563174, acc.: 64.84%] [G loss: 1.456970]\n",
      "epoch:20 step:19462 [D loss: 0.773371, acc.: 50.00%] [G loss: 1.403490]\n",
      "epoch:20 step:19463 [D loss: 0.649310, acc.: 61.72%] [G loss: 1.182957]\n",
      "epoch:20 step:19464 [D loss: 0.518591, acc.: 77.34%] [G loss: 1.428281]\n",
      "epoch:20 step:19465 [D loss: 0.522183, acc.: 75.00%] [G loss: 1.453255]\n",
      "epoch:20 step:19466 [D loss: 0.479357, acc.: 80.47%] [G loss: 1.367922]\n",
      "epoch:20 step:19467 [D loss: 0.734347, acc.: 66.41%] [G loss: 1.217157]\n",
      "epoch:20 step:19468 [D loss: 0.419914, acc.: 87.50%] [G loss: 1.094285]\n",
      "epoch:20 step:19469 [D loss: 0.782176, acc.: 52.34%] [G loss: 0.946421]\n",
      "epoch:20 step:19470 [D loss: 0.390783, acc.: 89.06%] [G loss: 1.277030]\n",
      "epoch:20 step:19471 [D loss: 0.445815, acc.: 89.06%] [G loss: 1.181961]\n",
      "epoch:20 step:19472 [D loss: 0.426598, acc.: 89.06%] [G loss: 0.992549]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19473 [D loss: 0.467076, acc.: 82.81%] [G loss: 1.236959]\n",
      "epoch:20 step:19474 [D loss: 0.681309, acc.: 53.91%] [G loss: 0.934916]\n",
      "epoch:20 step:19475 [D loss: 0.704330, acc.: 53.91%] [G loss: 1.124594]\n",
      "epoch:20 step:19476 [D loss: 0.759018, acc.: 48.44%] [G loss: 1.124262]\n",
      "epoch:20 step:19477 [D loss: 0.707254, acc.: 54.69%] [G loss: 1.164462]\n",
      "epoch:20 step:19478 [D loss: 0.767046, acc.: 45.31%] [G loss: 1.110256]\n",
      "epoch:20 step:19479 [D loss: 0.789824, acc.: 54.69%] [G loss: 0.914865]\n",
      "epoch:20 step:19480 [D loss: 1.021239, acc.: 18.75%] [G loss: 1.090301]\n",
      "epoch:20 step:19481 [D loss: 0.443163, acc.: 89.06%] [G loss: 1.131774]\n",
      "epoch:20 step:19482 [D loss: 0.402275, acc.: 89.84%] [G loss: 1.313110]\n",
      "epoch:20 step:19483 [D loss: 0.342600, acc.: 94.53%] [G loss: 1.217307]\n",
      "epoch:20 step:19484 [D loss: 0.469081, acc.: 78.12%] [G loss: 1.032589]\n",
      "epoch:20 step:19485 [D loss: 0.646204, acc.: 60.16%] [G loss: 1.385099]\n",
      "epoch:20 step:19486 [D loss: 0.661914, acc.: 59.38%] [G loss: 1.085801]\n",
      "epoch:20 step:19487 [D loss: 0.705822, acc.: 57.81%] [G loss: 0.924149]\n",
      "epoch:20 step:19488 [D loss: 0.660165, acc.: 61.72%] [G loss: 1.061180]\n",
      "epoch:20 step:19489 [D loss: 0.371024, acc.: 92.97%] [G loss: 1.495504]\n",
      "epoch:20 step:19490 [D loss: 0.329850, acc.: 95.31%] [G loss: 1.721194]\n",
      "epoch:20 step:19491 [D loss: 0.570653, acc.: 64.84%] [G loss: 1.295145]\n",
      "epoch:20 step:19492 [D loss: 0.717079, acc.: 56.25%] [G loss: 1.318703]\n",
      "epoch:20 step:19493 [D loss: 0.623521, acc.: 65.62%] [G loss: 1.088822]\n",
      "epoch:20 step:19494 [D loss: 0.784848, acc.: 51.56%] [G loss: 1.073246]\n",
      "epoch:20 step:19495 [D loss: 0.781786, acc.: 56.25%] [G loss: 0.751069]\n",
      "epoch:20 step:19496 [D loss: 0.829540, acc.: 39.06%] [G loss: 0.894328]\n",
      "epoch:20 step:19497 [D loss: 0.703554, acc.: 53.91%] [G loss: 0.728952]\n",
      "epoch:20 step:19498 [D loss: 0.802112, acc.: 46.88%] [G loss: 0.940363]\n",
      "epoch:20 step:19499 [D loss: 0.443421, acc.: 86.72%] [G loss: 0.832030]\n",
      "epoch:20 step:19500 [D loss: 0.468287, acc.: 82.81%] [G loss: 0.932425]\n",
      "epoch:20 step:19501 [D loss: 0.619480, acc.: 69.53%] [G loss: 1.079757]\n",
      "epoch:20 step:19502 [D loss: 0.814229, acc.: 45.31%] [G loss: 0.957844]\n",
      "epoch:20 step:19503 [D loss: 0.688112, acc.: 54.69%] [G loss: 0.950690]\n",
      "epoch:20 step:19504 [D loss: 0.685223, acc.: 60.16%] [G loss: 0.918385]\n",
      "epoch:20 step:19505 [D loss: 0.547206, acc.: 76.56%] [G loss: 0.845901]\n",
      "epoch:20 step:19506 [D loss: 0.582736, acc.: 72.66%] [G loss: 0.943200]\n",
      "epoch:20 step:19507 [D loss: 0.535733, acc.: 72.66%] [G loss: 0.717696]\n",
      "epoch:20 step:19508 [D loss: 0.331336, acc.: 88.28%] [G loss: 0.911800]\n",
      "epoch:20 step:19509 [D loss: 0.320663, acc.: 92.19%] [G loss: 0.880477]\n",
      "epoch:20 step:19510 [D loss: 0.629479, acc.: 64.84%] [G loss: 0.918847]\n",
      "epoch:20 step:19511 [D loss: 0.653913, acc.: 60.16%] [G loss: 0.993454]\n",
      "epoch:20 step:19512 [D loss: 0.604150, acc.: 64.06%] [G loss: 0.847433]\n",
      "epoch:20 step:19513 [D loss: 0.640794, acc.: 63.28%] [G loss: 0.598116]\n",
      "epoch:20 step:19514 [D loss: 0.347907, acc.: 83.59%] [G loss: 1.016628]\n",
      "epoch:20 step:19515 [D loss: 0.302441, acc.: 97.66%] [G loss: 1.223925]\n",
      "epoch:20 step:19516 [D loss: 0.762733, acc.: 45.31%] [G loss: 0.808393]\n",
      "epoch:20 step:19517 [D loss: 0.411509, acc.: 89.84%] [G loss: 0.912739]\n",
      "epoch:20 step:19518 [D loss: 0.658107, acc.: 58.59%] [G loss: 1.146883]\n",
      "epoch:20 step:19519 [D loss: 0.860744, acc.: 38.28%] [G loss: 1.048951]\n",
      "epoch:20 step:19520 [D loss: 0.706188, acc.: 57.81%] [G loss: 0.857456]\n",
      "epoch:20 step:19521 [D loss: 0.689128, acc.: 53.91%] [G loss: 0.940839]\n",
      "epoch:20 step:19522 [D loss: 0.572235, acc.: 67.97%] [G loss: 0.979108]\n",
      "epoch:20 step:19523 [D loss: 0.770650, acc.: 50.78%] [G loss: 0.885845]\n",
      "epoch:20 step:19524 [D loss: 0.649658, acc.: 59.38%] [G loss: 1.048924]\n",
      "epoch:20 step:19525 [D loss: 0.749071, acc.: 46.09%] [G loss: 1.128360]\n",
      "epoch:20 step:19526 [D loss: 0.371074, acc.: 87.50%] [G loss: 1.154596]\n",
      "epoch:20 step:19527 [D loss: 0.720363, acc.: 48.44%] [G loss: 0.962836]\n",
      "epoch:20 step:19528 [D loss: 0.648955, acc.: 57.03%] [G loss: 0.936537]\n",
      "epoch:20 step:19529 [D loss: 0.813279, acc.: 38.28%] [G loss: 1.011100]\n",
      "epoch:20 step:19530 [D loss: 0.737469, acc.: 51.56%] [G loss: 1.167827]\n",
      "epoch:20 step:19531 [D loss: 0.350316, acc.: 87.50%] [G loss: 1.099083]\n",
      "epoch:20 step:19532 [D loss: 0.313278, acc.: 87.50%] [G loss: 1.039978]\n",
      "epoch:20 step:19533 [D loss: 0.505493, acc.: 77.34%] [G loss: 1.265042]\n",
      "epoch:20 step:19534 [D loss: 0.269070, acc.: 92.19%] [G loss: 1.181212]\n",
      "epoch:20 step:19535 [D loss: 0.453331, acc.: 84.38%] [G loss: 1.640170]\n",
      "epoch:20 step:19536 [D loss: 0.264827, acc.: 96.09%] [G loss: 1.295160]\n",
      "epoch:20 step:19537 [D loss: 0.654796, acc.: 60.16%] [G loss: 1.302047]\n",
      "epoch:20 step:19538 [D loss: 0.567294, acc.: 70.31%] [G loss: 1.407860]\n",
      "epoch:20 step:19539 [D loss: 0.767101, acc.: 52.34%] [G loss: 1.137293]\n",
      "epoch:20 step:19540 [D loss: 0.666174, acc.: 64.84%] [G loss: 1.104691]\n",
      "epoch:20 step:19541 [D loss: 0.602070, acc.: 72.66%] [G loss: 0.994721]\n",
      "epoch:20 step:19542 [D loss: 0.395040, acc.: 81.25%] [G loss: 1.121848]\n",
      "epoch:20 step:19543 [D loss: 0.701247, acc.: 53.91%] [G loss: 0.933991]\n",
      "epoch:20 step:19544 [D loss: 0.308821, acc.: 85.94%] [G loss: 0.992169]\n",
      "epoch:20 step:19545 [D loss: 0.287186, acc.: 85.94%] [G loss: 1.012986]\n",
      "epoch:20 step:19546 [D loss: 0.239807, acc.: 92.97%] [G loss: 1.215325]\n",
      "epoch:20 step:19547 [D loss: 0.843125, acc.: 42.97%] [G loss: 1.238756]\n",
      "epoch:20 step:19548 [D loss: 0.682017, acc.: 60.16%] [G loss: 1.050730]\n",
      "epoch:20 step:19549 [D loss: 0.643303, acc.: 67.97%] [G loss: 0.976149]\n",
      "epoch:20 step:19550 [D loss: 0.727092, acc.: 49.22%] [G loss: 1.002209]\n",
      "epoch:20 step:19551 [D loss: 0.660546, acc.: 59.38%] [G loss: 0.971733]\n",
      "epoch:20 step:19552 [D loss: 0.432080, acc.: 84.38%] [G loss: 0.935577]\n",
      "epoch:20 step:19553 [D loss: 0.642128, acc.: 65.62%] [G loss: 1.059275]\n",
      "epoch:20 step:19554 [D loss: 0.724989, acc.: 50.78%] [G loss: 1.008474]\n",
      "epoch:20 step:19555 [D loss: 0.445796, acc.: 85.16%] [G loss: 1.055809]\n",
      "epoch:20 step:19556 [D loss: 0.650594, acc.: 60.94%] [G loss: 0.833716]\n",
      "epoch:20 step:19557 [D loss: 0.434777, acc.: 85.94%] [G loss: 0.977504]\n",
      "epoch:20 step:19558 [D loss: 0.758093, acc.: 40.62%] [G loss: 0.974063]\n",
      "epoch:20 step:19559 [D loss: 0.651957, acc.: 59.38%] [G loss: 1.123989]\n",
      "epoch:20 step:19560 [D loss: 0.639944, acc.: 65.62%] [G loss: 0.993487]\n",
      "epoch:20 step:19561 [D loss: 0.311995, acc.: 85.16%] [G loss: 1.081473]\n",
      "epoch:20 step:19562 [D loss: 0.428495, acc.: 69.53%] [G loss: 1.071007]\n",
      "epoch:20 step:19563 [D loss: 0.538908, acc.: 81.25%] [G loss: 1.116586]\n",
      "epoch:20 step:19564 [D loss: 0.707163, acc.: 57.81%] [G loss: 1.095360]\n",
      "epoch:20 step:19565 [D loss: 0.627554, acc.: 63.28%] [G loss: 0.931969]\n",
      "epoch:20 step:19566 [D loss: 0.604737, acc.: 71.88%] [G loss: 0.985533]\n",
      "epoch:20 step:19567 [D loss: 0.520725, acc.: 76.56%] [G loss: 1.017762]\n",
      "epoch:20 step:19568 [D loss: 0.584540, acc.: 72.66%] [G loss: 1.089160]\n",
      "epoch:20 step:19569 [D loss: 0.547677, acc.: 80.47%] [G loss: 0.913760]\n",
      "epoch:20 step:19570 [D loss: 0.779990, acc.: 51.56%] [G loss: 0.861967]\n",
      "epoch:20 step:19571 [D loss: 0.705389, acc.: 53.12%] [G loss: 0.732183]\n",
      "epoch:20 step:19572 [D loss: 0.840043, acc.: 42.97%] [G loss: 0.994136]\n",
      "epoch:20 step:19573 [D loss: 0.643940, acc.: 60.94%] [G loss: 0.811692]\n",
      "epoch:20 step:19574 [D loss: 0.283854, acc.: 90.62%] [G loss: 1.049992]\n",
      "epoch:20 step:19575 [D loss: 0.592054, acc.: 75.00%] [G loss: 0.920208]\n",
      "epoch:20 step:19576 [D loss: 0.747846, acc.: 44.53%] [G loss: 1.018409]\n",
      "epoch:20 step:19577 [D loss: 0.727786, acc.: 50.00%] [G loss: 1.127343]\n",
      "epoch:20 step:19578 [D loss: 0.741340, acc.: 46.88%] [G loss: 0.962341]\n",
      "epoch:20 step:19579 [D loss: 0.511655, acc.: 80.47%] [G loss: 1.101881]\n",
      "epoch:20 step:19580 [D loss: 0.429725, acc.: 88.28%] [G loss: 0.771548]\n",
      "epoch:20 step:19581 [D loss: 0.295063, acc.: 88.28%] [G loss: 1.064501]\n",
      "epoch:20 step:19582 [D loss: 0.536952, acc.: 71.88%] [G loss: 0.695720]\n",
      "epoch:20 step:19583 [D loss: 0.698390, acc.: 53.12%] [G loss: 1.247014]\n",
      "epoch:20 step:19584 [D loss: 0.798191, acc.: 48.44%] [G loss: 0.432720]\n",
      "epoch:20 step:19585 [D loss: 0.501205, acc.: 72.66%] [G loss: 0.701857]\n",
      "epoch:20 step:19586 [D loss: 0.715665, acc.: 54.69%] [G loss: 1.228425]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19587 [D loss: 0.291499, acc.: 95.31%] [G loss: 1.106883]\n",
      "epoch:20 step:19588 [D loss: 0.320763, acc.: 95.31%] [G loss: 1.115782]\n",
      "epoch:20 step:19589 [D loss: 0.709080, acc.: 54.69%] [G loss: 1.091242]\n",
      "epoch:20 step:19590 [D loss: 0.500981, acc.: 78.12%] [G loss: 1.269263]\n",
      "epoch:20 step:19591 [D loss: 0.550181, acc.: 60.94%] [G loss: 1.378811]\n",
      "epoch:20 step:19592 [D loss: 0.262197, acc.: 97.66%] [G loss: 1.455098]\n",
      "epoch:20 step:19593 [D loss: 0.911798, acc.: 52.34%] [G loss: 1.055344]\n",
      "epoch:20 step:19594 [D loss: 0.478513, acc.: 82.03%] [G loss: 1.615653]\n",
      "epoch:20 step:19595 [D loss: 0.949728, acc.: 41.41%] [G loss: 1.527360]\n",
      "epoch:20 step:19596 [D loss: 0.862059, acc.: 44.53%] [G loss: 0.920161]\n",
      "epoch:20 step:19597 [D loss: 1.050661, acc.: 24.22%] [G loss: 0.962873]\n",
      "epoch:20 step:19598 [D loss: 0.456522, acc.: 81.25%] [G loss: 1.517411]\n",
      "epoch:20 step:19599 [D loss: 0.373042, acc.: 90.62%] [G loss: 1.515030]\n",
      "epoch:20 step:19600 [D loss: 0.308688, acc.: 96.88%] [G loss: 1.754534]\n",
      "##############\n",
      "[4.19797944 2.94688858 6.55910099 6.17046287 5.02623205 6.02596289\n",
      " 5.45015356 5.84691252 5.79749046 5.06259102]\n",
      "##########\n",
      "epoch:20 step:19601 [D loss: 0.872980, acc.: 47.66%] [G loss: 1.116318]\n",
      "epoch:20 step:19602 [D loss: 0.696099, acc.: 51.56%] [G loss: 1.392373]\n",
      "epoch:20 step:19603 [D loss: 0.478700, acc.: 78.12%] [G loss: 1.434832]\n",
      "epoch:20 step:19604 [D loss: 0.569875, acc.: 64.84%] [G loss: 1.684408]\n",
      "epoch:20 step:19605 [D loss: 0.689929, acc.: 62.50%] [G loss: 1.371611]\n",
      "epoch:20 step:19606 [D loss: 0.586945, acc.: 64.84%] [G loss: 1.367546]\n",
      "epoch:20 step:19607 [D loss: 0.719247, acc.: 55.47%] [G loss: 1.432997]\n",
      "epoch:20 step:19608 [D loss: 0.432415, acc.: 83.59%] [G loss: 1.509113]\n",
      "epoch:20 step:19609 [D loss: 0.605043, acc.: 64.06%] [G loss: 1.333768]\n",
      "epoch:20 step:19610 [D loss: 0.319104, acc.: 92.97%] [G loss: 1.415694]\n",
      "epoch:20 step:19611 [D loss: 0.382732, acc.: 92.19%] [G loss: 1.638179]\n",
      "epoch:20 step:19612 [D loss: 0.685508, acc.: 54.69%] [G loss: 1.201027]\n",
      "epoch:20 step:19613 [D loss: 0.376042, acc.: 93.75%] [G loss: 1.228009]\n",
      "epoch:20 step:19614 [D loss: 0.401377, acc.: 91.41%] [G loss: 1.188142]\n",
      "epoch:20 step:19615 [D loss: 0.380437, acc.: 90.62%] [G loss: 1.499965]\n",
      "epoch:20 step:19616 [D loss: 0.283456, acc.: 95.31%] [G loss: 1.462353]\n",
      "epoch:20 step:19617 [D loss: 0.184633, acc.: 96.88%] [G loss: 1.433550]\n",
      "epoch:20 step:19618 [D loss: 0.479574, acc.: 68.75%] [G loss: 1.622962]\n",
      "epoch:20 step:19619 [D loss: 0.582923, acc.: 64.06%] [G loss: 1.858998]\n",
      "epoch:20 step:19620 [D loss: 0.758846, acc.: 49.22%] [G loss: 1.729537]\n",
      "epoch:20 step:19621 [D loss: 0.857340, acc.: 35.16%] [G loss: 0.809366]\n",
      "epoch:20 step:19622 [D loss: 1.264652, acc.: 27.34%] [G loss: 1.053268]\n",
      "epoch:20 step:19623 [D loss: 1.029707, acc.: 38.28%] [G loss: 1.196428]\n",
      "epoch:20 step:19624 [D loss: 0.998264, acc.: 25.00%] [G loss: 0.922490]\n",
      "epoch:20 step:19625 [D loss: 0.893237, acc.: 38.28%] [G loss: 0.816800]\n",
      "epoch:20 step:19626 [D loss: 0.759286, acc.: 50.78%] [G loss: 0.696532]\n",
      "epoch:20 step:19627 [D loss: 0.695241, acc.: 52.34%] [G loss: 0.802506]\n",
      "epoch:20 step:19628 [D loss: 0.743078, acc.: 42.19%] [G loss: 0.823328]\n",
      "epoch:20 step:19629 [D loss: 0.705170, acc.: 55.47%] [G loss: 0.986468]\n",
      "epoch:20 step:19630 [D loss: 0.630961, acc.: 63.28%] [G loss: 0.977661]\n",
      "epoch:20 step:19631 [D loss: 0.617896, acc.: 64.06%] [G loss: 0.998952]\n",
      "epoch:20 step:19632 [D loss: 0.608078, acc.: 70.31%] [G loss: 0.966490]\n",
      "epoch:20 step:19633 [D loss: 0.672681, acc.: 58.59%] [G loss: 0.979702]\n",
      "epoch:20 step:19634 [D loss: 0.547178, acc.: 78.12%] [G loss: 0.951934]\n",
      "epoch:20 step:19635 [D loss: 0.587277, acc.: 70.31%] [G loss: 1.012345]\n",
      "epoch:20 step:19636 [D loss: 0.526534, acc.: 79.69%] [G loss: 0.967030]\n",
      "epoch:20 step:19637 [D loss: 0.607270, acc.: 67.19%] [G loss: 0.769312]\n",
      "epoch:20 step:19638 [D loss: 0.454862, acc.: 81.25%] [G loss: 0.979164]\n",
      "epoch:20 step:19639 [D loss: 0.334269, acc.: 79.69%] [G loss: 1.026079]\n",
      "epoch:20 step:19640 [D loss: 0.327095, acc.: 87.50%] [G loss: 1.056909]\n",
      "epoch:20 step:19641 [D loss: 0.548407, acc.: 76.56%] [G loss: 1.012555]\n",
      "epoch:20 step:19642 [D loss: 0.662444, acc.: 63.28%] [G loss: 0.935006]\n",
      "epoch:20 step:19643 [D loss: 0.635771, acc.: 64.06%] [G loss: 0.797100]\n",
      "epoch:20 step:19644 [D loss: 0.757933, acc.: 45.31%] [G loss: 1.024026]\n",
      "epoch:20 step:19645 [D loss: 0.576280, acc.: 68.75%] [G loss: 1.355666]\n",
      "epoch:20 step:19646 [D loss: 0.416240, acc.: 86.72%] [G loss: 1.357907]\n",
      "epoch:20 step:19647 [D loss: 0.654728, acc.: 59.38%] [G loss: 1.222887]\n",
      "epoch:20 step:19648 [D loss: 0.710656, acc.: 52.34%] [G loss: 0.957872]\n",
      "epoch:20 step:19649 [D loss: 0.647885, acc.: 60.94%] [G loss: 1.123436]\n",
      "epoch:20 step:19650 [D loss: 0.504585, acc.: 80.47%] [G loss: 1.223628]\n",
      "epoch:20 step:19651 [D loss: 0.642619, acc.: 64.84%] [G loss: 1.144771]\n",
      "epoch:20 step:19652 [D loss: 0.281269, acc.: 87.50%] [G loss: 1.281855]\n",
      "epoch:20 step:19653 [D loss: 0.735714, acc.: 50.00%] [G loss: 1.048507]\n",
      "epoch:20 step:19654 [D loss: 0.676515, acc.: 56.25%] [G loss: 1.111274]\n",
      "epoch:20 step:19655 [D loss: 0.646313, acc.: 56.25%] [G loss: 1.166965]\n",
      "epoch:20 step:19656 [D loss: 0.496706, acc.: 82.03%] [G loss: 1.128793]\n",
      "epoch:20 step:19657 [D loss: 0.321131, acc.: 95.31%] [G loss: 1.271906]\n",
      "epoch:20 step:19658 [D loss: 0.585497, acc.: 67.19%] [G loss: 1.487868]\n",
      "epoch:20 step:19659 [D loss: 0.668491, acc.: 69.53%] [G loss: 1.098169]\n",
      "epoch:20 step:19660 [D loss: 0.266926, acc.: 89.84%] [G loss: 1.148975]\n",
      "epoch:20 step:19661 [D loss: 0.231605, acc.: 93.75%] [G loss: 1.450589]\n",
      "epoch:20 step:19662 [D loss: 0.508937, acc.: 75.78%] [G loss: 1.315053]\n",
      "epoch:20 step:19663 [D loss: 0.635814, acc.: 58.59%] [G loss: 1.378210]\n",
      "epoch:20 step:19664 [D loss: 0.620628, acc.: 67.19%] [G loss: 1.049649]\n",
      "epoch:20 step:19665 [D loss: 0.633607, acc.: 64.84%] [G loss: 1.059624]\n",
      "epoch:20 step:19666 [D loss: 0.550056, acc.: 67.97%] [G loss: 1.023468]\n",
      "epoch:20 step:19667 [D loss: 0.488588, acc.: 74.22%] [G loss: 0.988504]\n",
      "epoch:20 step:19668 [D loss: 0.664292, acc.: 62.50%] [G loss: 1.089425]\n",
      "epoch:20 step:19669 [D loss: 0.258983, acc.: 89.06%] [G loss: 1.104897]\n",
      "epoch:20 step:19670 [D loss: 0.308040, acc.: 92.97%] [G loss: 1.421412]\n",
      "epoch:20 step:19671 [D loss: 0.428890, acc.: 83.59%] [G loss: 1.246183]\n",
      "epoch:20 step:19672 [D loss: 0.742511, acc.: 53.91%] [G loss: 1.250615]\n",
      "epoch:20 step:19673 [D loss: 0.616891, acc.: 66.41%] [G loss: 1.326755]\n",
      "epoch:20 step:19674 [D loss: 0.486869, acc.: 73.44%] [G loss: 1.119196]\n",
      "epoch:20 step:19675 [D loss: 0.616623, acc.: 64.06%] [G loss: 1.228701]\n",
      "epoch:20 step:19676 [D loss: 0.338011, acc.: 89.06%] [G loss: 0.996128]\n",
      "epoch:20 step:19677 [D loss: 0.223739, acc.: 91.41%] [G loss: 1.197161]\n",
      "epoch:21 step:19678 [D loss: 0.730885, acc.: 57.81%] [G loss: 1.085575]\n",
      "epoch:21 step:19679 [D loss: 0.785096, acc.: 47.66%] [G loss: 1.072091]\n",
      "epoch:21 step:19680 [D loss: 0.768537, acc.: 53.91%] [G loss: 0.949911]\n",
      "epoch:21 step:19681 [D loss: 0.701455, acc.: 56.25%] [G loss: 1.044803]\n",
      "epoch:21 step:19682 [D loss: 0.637184, acc.: 61.72%] [G loss: 0.809017]\n",
      "epoch:21 step:19683 [D loss: 0.621075, acc.: 64.84%] [G loss: 1.000879]\n",
      "epoch:21 step:19684 [D loss: 0.782589, acc.: 53.12%] [G loss: 1.032999]\n",
      "epoch:21 step:19685 [D loss: 0.614455, acc.: 65.62%] [G loss: 0.657591]\n",
      "epoch:21 step:19686 [D loss: 0.560789, acc.: 75.00%] [G loss: 0.835053]\n",
      "epoch:21 step:19687 [D loss: 0.466213, acc.: 82.03%] [G loss: 1.110945]\n",
      "epoch:21 step:19688 [D loss: 0.682613, acc.: 60.94%] [G loss: 0.786972]\n",
      "epoch:21 step:19689 [D loss: 1.136466, acc.: 44.53%] [G loss: 1.176529]\n",
      "epoch:21 step:19690 [D loss: 0.578137, acc.: 68.75%] [G loss: 1.195632]\n",
      "epoch:21 step:19691 [D loss: 0.550147, acc.: 72.66%] [G loss: 1.340033]\n",
      "epoch:21 step:19692 [D loss: 0.531313, acc.: 75.78%] [G loss: 1.221462]\n",
      "epoch:21 step:19693 [D loss: 0.546081, acc.: 78.91%] [G loss: 1.113814]\n",
      "epoch:21 step:19694 [D loss: 0.739658, acc.: 45.31%] [G loss: 0.765105]\n",
      "epoch:21 step:19695 [D loss: 0.564664, acc.: 73.44%] [G loss: 1.276117]\n",
      "epoch:21 step:19696 [D loss: 0.998035, acc.: 25.78%] [G loss: 0.945805]\n",
      "epoch:21 step:19697 [D loss: 0.687802, acc.: 52.34%] [G loss: 0.919952]\n",
      "epoch:21 step:19698 [D loss: 0.808361, acc.: 45.31%] [G loss: 1.064360]\n",
      "epoch:21 step:19699 [D loss: 0.759443, acc.: 43.75%] [G loss: 0.941371]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:19700 [D loss: 0.757080, acc.: 48.44%] [G loss: 0.892242]\n",
      "epoch:21 step:19701 [D loss: 0.652709, acc.: 63.28%] [G loss: 1.070458]\n",
      "epoch:21 step:19702 [D loss: 0.549552, acc.: 72.66%] [G loss: 1.154248]\n",
      "epoch:21 step:19703 [D loss: 0.684892, acc.: 50.78%] [G loss: 1.035779]\n",
      "epoch:21 step:19704 [D loss: 0.511092, acc.: 67.19%] [G loss: 1.119032]\n",
      "epoch:21 step:19705 [D loss: 0.597425, acc.: 67.19%] [G loss: 1.184340]\n",
      "epoch:21 step:19706 [D loss: 0.597897, acc.: 61.72%] [G loss: 1.293888]\n",
      "epoch:21 step:19707 [D loss: 0.676690, acc.: 55.47%] [G loss: 1.133965]\n",
      "epoch:21 step:19708 [D loss: 0.405772, acc.: 85.94%] [G loss: 1.237226]\n",
      "epoch:21 step:19709 [D loss: 0.321273, acc.: 96.09%] [G loss: 1.145878]\n",
      "epoch:21 step:19710 [D loss: 0.341709, acc.: 92.19%] [G loss: 1.251440]\n",
      "epoch:21 step:19711 [D loss: 0.276912, acc.: 92.97%] [G loss: 1.623701]\n",
      "epoch:21 step:19712 [D loss: 0.240034, acc.: 97.66%] [G loss: 1.474867]\n",
      "epoch:21 step:19713 [D loss: 0.154050, acc.: 98.44%] [G loss: 2.512959]\n",
      "epoch:21 step:19714 [D loss: 0.792676, acc.: 51.56%] [G loss: 1.141966]\n",
      "epoch:21 step:19715 [D loss: 0.895682, acc.: 47.66%] [G loss: 1.034715]\n",
      "epoch:21 step:19716 [D loss: 0.847755, acc.: 51.56%] [G loss: 1.193366]\n",
      "epoch:21 step:19717 [D loss: 0.715772, acc.: 53.12%] [G loss: 1.089635]\n",
      "epoch:21 step:19718 [D loss: 0.586784, acc.: 71.09%] [G loss: 0.942420]\n",
      "epoch:21 step:19719 [D loss: 0.553987, acc.: 78.12%] [G loss: 0.957564]\n",
      "epoch:21 step:19720 [D loss: 0.488960, acc.: 83.59%] [G loss: 0.790896]\n",
      "epoch:21 step:19721 [D loss: 0.544239, acc.: 80.47%] [G loss: 0.866556]\n",
      "epoch:21 step:19722 [D loss: 0.779456, acc.: 48.44%] [G loss: 0.607800]\n",
      "epoch:21 step:19723 [D loss: 0.502492, acc.: 75.00%] [G loss: 1.030964]\n",
      "epoch:21 step:19724 [D loss: 0.667233, acc.: 61.72%] [G loss: 1.006857]\n",
      "epoch:21 step:19725 [D loss: 0.716636, acc.: 53.12%] [G loss: 1.139704]\n",
      "epoch:21 step:19726 [D loss: 0.815058, acc.: 39.06%] [G loss: 0.918136]\n",
      "epoch:21 step:19727 [D loss: 0.632185, acc.: 60.16%] [G loss: 0.858866]\n",
      "epoch:21 step:19728 [D loss: 0.546492, acc.: 78.91%] [G loss: 0.635160]\n",
      "epoch:21 step:19729 [D loss: 0.571320, acc.: 73.44%] [G loss: 0.719542]\n",
      "epoch:21 step:19730 [D loss: 0.635763, acc.: 63.28%] [G loss: 0.948747]\n",
      "epoch:21 step:19731 [D loss: 0.711463, acc.: 51.56%] [G loss: 0.788499]\n",
      "epoch:21 step:19732 [D loss: 0.653900, acc.: 64.84%] [G loss: 0.816441]\n",
      "epoch:21 step:19733 [D loss: 0.664376, acc.: 54.69%] [G loss: 0.666127]\n",
      "epoch:21 step:19734 [D loss: 0.378755, acc.: 83.59%] [G loss: 0.908595]\n",
      "epoch:21 step:19735 [D loss: 0.392071, acc.: 78.12%] [G loss: 0.880874]\n",
      "epoch:21 step:19736 [D loss: 0.563472, acc.: 77.34%] [G loss: 0.960010]\n",
      "epoch:21 step:19737 [D loss: 0.649491, acc.: 60.16%] [G loss: 1.159735]\n",
      "epoch:21 step:19738 [D loss: 0.680356, acc.: 60.94%] [G loss: 1.108196]\n",
      "epoch:21 step:19739 [D loss: 0.693385, acc.: 53.91%] [G loss: 0.497920]\n",
      "epoch:21 step:19740 [D loss: 0.739913, acc.: 52.34%] [G loss: 0.745011]\n",
      "epoch:21 step:19741 [D loss: 0.781168, acc.: 46.09%] [G loss: 0.700100]\n",
      "epoch:21 step:19742 [D loss: 0.734895, acc.: 51.56%] [G loss: 0.842237]\n",
      "epoch:21 step:19743 [D loss: 0.867770, acc.: 33.59%] [G loss: 0.758516]\n",
      "epoch:21 step:19744 [D loss: 1.155166, acc.: 18.75%] [G loss: 0.989395]\n",
      "epoch:21 step:19745 [D loss: 0.838528, acc.: 34.38%] [G loss: 1.193640]\n",
      "epoch:21 step:19746 [D loss: 0.562424, acc.: 64.84%] [G loss: 1.353056]\n",
      "epoch:21 step:19747 [D loss: 0.594852, acc.: 60.94%] [G loss: 1.521491]\n",
      "epoch:21 step:19748 [D loss: 0.527101, acc.: 72.66%] [G loss: 1.469968]\n",
      "epoch:21 step:19749 [D loss: 0.629983, acc.: 63.28%] [G loss: 1.272212]\n",
      "epoch:21 step:19750 [D loss: 0.595320, acc.: 66.41%] [G loss: 1.083416]\n",
      "epoch:21 step:19751 [D loss: 0.731478, acc.: 48.44%] [G loss: 1.135646]\n",
      "epoch:21 step:19752 [D loss: 0.393562, acc.: 86.72%] [G loss: 1.074584]\n",
      "epoch:21 step:19753 [D loss: 0.664899, acc.: 63.28%] [G loss: 1.305463]\n",
      "epoch:21 step:19754 [D loss: 0.530984, acc.: 75.78%] [G loss: 1.101898]\n",
      "epoch:21 step:19755 [D loss: 0.868784, acc.: 38.28%] [G loss: 1.202579]\n",
      "epoch:21 step:19756 [D loss: 0.845454, acc.: 44.53%] [G loss: 1.027043]\n",
      "epoch:21 step:19757 [D loss: 0.634610, acc.: 67.19%] [G loss: 1.117443]\n",
      "epoch:21 step:19758 [D loss: 0.542214, acc.: 76.56%] [G loss: 1.227565]\n",
      "epoch:21 step:19759 [D loss: 0.430905, acc.: 87.50%] [G loss: 1.251085]\n",
      "epoch:21 step:19760 [D loss: 0.463411, acc.: 86.72%] [G loss: 1.228503]\n",
      "epoch:21 step:19761 [D loss: 0.793973, acc.: 48.44%] [G loss: 1.249955]\n",
      "epoch:21 step:19762 [D loss: 0.477409, acc.: 78.12%] [G loss: 1.374339]\n",
      "epoch:21 step:19763 [D loss: 0.644986, acc.: 59.38%] [G loss: 1.203367]\n",
      "epoch:21 step:19764 [D loss: 0.507646, acc.: 75.78%] [G loss: 0.961346]\n",
      "epoch:21 step:19765 [D loss: 0.540345, acc.: 78.12%] [G loss: 1.328237]\n",
      "epoch:21 step:19766 [D loss: 0.452898, acc.: 94.53%] [G loss: 1.088795]\n",
      "epoch:21 step:19767 [D loss: 0.481442, acc.: 89.06%] [G loss: 1.262568]\n",
      "epoch:21 step:19768 [D loss: 0.539113, acc.: 75.00%] [G loss: 0.975929]\n",
      "epoch:21 step:19769 [D loss: 0.504606, acc.: 78.12%] [G loss: 1.097007]\n",
      "epoch:21 step:19770 [D loss: 0.310096, acc.: 91.41%] [G loss: 1.097486]\n",
      "epoch:21 step:19771 [D loss: 0.501806, acc.: 80.47%] [G loss: 0.728332]\n",
      "epoch:21 step:19772 [D loss: 0.751886, acc.: 55.47%] [G loss: 1.156058]\n",
      "epoch:21 step:19773 [D loss: 0.554576, acc.: 72.66%] [G loss: 1.048179]\n",
      "epoch:21 step:19774 [D loss: 0.647219, acc.: 61.72%] [G loss: 0.523236]\n",
      "epoch:21 step:19775 [D loss: 1.020847, acc.: 20.31%] [G loss: 1.271297]\n",
      "epoch:21 step:19776 [D loss: 0.692301, acc.: 56.25%] [G loss: 0.624977]\n",
      "epoch:21 step:19777 [D loss: 0.715605, acc.: 50.00%] [G loss: 0.463155]\n",
      "epoch:21 step:19778 [D loss: 0.586343, acc.: 71.88%] [G loss: 0.845889]\n",
      "epoch:21 step:19779 [D loss: 0.978682, acc.: 39.06%] [G loss: 0.990380]\n",
      "epoch:21 step:19780 [D loss: 0.585944, acc.: 68.75%] [G loss: 1.023097]\n",
      "epoch:21 step:19781 [D loss: 0.770371, acc.: 46.88%] [G loss: 0.943817]\n",
      "epoch:21 step:19782 [D loss: 0.819439, acc.: 45.31%] [G loss: 0.910113]\n",
      "epoch:21 step:19783 [D loss: 0.681359, acc.: 58.59%] [G loss: 0.758836]\n",
      "epoch:21 step:19784 [D loss: 0.696571, acc.: 49.22%] [G loss: 0.856205]\n",
      "epoch:21 step:19785 [D loss: 0.613334, acc.: 60.16%] [G loss: 0.986071]\n",
      "epoch:21 step:19786 [D loss: 0.672247, acc.: 62.50%] [G loss: 0.936223]\n",
      "epoch:21 step:19787 [D loss: 0.667156, acc.: 57.81%] [G loss: 0.866915]\n",
      "epoch:21 step:19788 [D loss: 0.631094, acc.: 68.75%] [G loss: 0.810710]\n",
      "epoch:21 step:19789 [D loss: 0.632376, acc.: 64.06%] [G loss: 0.712545]\n",
      "epoch:21 step:19790 [D loss: 0.603649, acc.: 69.53%] [G loss: 0.747992]\n",
      "epoch:21 step:19791 [D loss: 1.179201, acc.: 52.34%] [G loss: 1.001629]\n",
      "epoch:21 step:19792 [D loss: 0.573197, acc.: 71.09%] [G loss: 1.097384]\n",
      "epoch:21 step:19793 [D loss: 0.701083, acc.: 56.25%] [G loss: 1.133391]\n",
      "epoch:21 step:19794 [D loss: 0.684987, acc.: 51.56%] [G loss: 1.079736]\n",
      "epoch:21 step:19795 [D loss: 0.569749, acc.: 66.41%] [G loss: 1.185281]\n",
      "epoch:21 step:19796 [D loss: 0.421333, acc.: 83.59%] [G loss: 1.295151]\n",
      "epoch:21 step:19797 [D loss: 0.671842, acc.: 64.06%] [G loss: 1.127094]\n",
      "epoch:21 step:19798 [D loss: 0.581051, acc.: 72.66%] [G loss: 1.079066]\n",
      "epoch:21 step:19799 [D loss: 0.530366, acc.: 75.78%] [G loss: 1.047215]\n",
      "epoch:21 step:19800 [D loss: 0.733342, acc.: 53.91%] [G loss: 1.069591]\n",
      "##############\n",
      "[3.92658919 2.78244661 6.41397464 5.68534061 4.53984765 6.13712388\n",
      " 5.56903123 5.83574337 5.78367891 4.82424603]\n",
      "##########\n",
      "epoch:21 step:19801 [D loss: 0.694102, acc.: 53.12%] [G loss: 1.000989]\n",
      "epoch:21 step:19802 [D loss: 0.687947, acc.: 56.25%] [G loss: 0.980407]\n",
      "epoch:21 step:19803 [D loss: 0.670717, acc.: 62.50%] [G loss: 0.983531]\n",
      "epoch:21 step:19804 [D loss: 0.640409, acc.: 64.06%] [G loss: 1.036795]\n",
      "epoch:21 step:19805 [D loss: 0.674449, acc.: 58.59%] [G loss: 1.001586]\n",
      "epoch:21 step:19806 [D loss: 0.631896, acc.: 63.28%] [G loss: 0.846277]\n",
      "epoch:21 step:19807 [D loss: 0.516816, acc.: 75.78%] [G loss: 0.764051]\n",
      "epoch:21 step:19808 [D loss: 0.561052, acc.: 70.31%] [G loss: 0.804264]\n",
      "epoch:21 step:19809 [D loss: 0.752896, acc.: 54.69%] [G loss: 0.867337]\n",
      "epoch:21 step:19810 [D loss: 0.557935, acc.: 71.88%] [G loss: 1.019509]\n",
      "epoch:21 step:19811 [D loss: 0.638692, acc.: 62.50%] [G loss: 1.120738]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:19812 [D loss: 0.550757, acc.: 69.53%] [G loss: 1.014552]\n",
      "epoch:21 step:19813 [D loss: 0.643152, acc.: 66.41%] [G loss: 1.139790]\n",
      "epoch:21 step:19814 [D loss: 0.726632, acc.: 54.69%] [G loss: 1.008262]\n",
      "epoch:21 step:19815 [D loss: 0.680140, acc.: 56.25%] [G loss: 1.089252]\n",
      "epoch:21 step:19816 [D loss: 0.620572, acc.: 72.66%] [G loss: 0.994131]\n",
      "epoch:21 step:19817 [D loss: 0.578639, acc.: 68.75%] [G loss: 0.943803]\n",
      "epoch:21 step:19818 [D loss: 0.484336, acc.: 81.25%] [G loss: 0.804605]\n",
      "epoch:21 step:19819 [D loss: 0.543486, acc.: 73.44%] [G loss: 1.169213]\n",
      "epoch:21 step:19820 [D loss: 0.360689, acc.: 92.19%] [G loss: 1.121673]\n",
      "epoch:21 step:19821 [D loss: 0.407931, acc.: 84.38%] [G loss: 1.193578]\n",
      "epoch:21 step:19822 [D loss: 0.272464, acc.: 92.97%] [G loss: 1.306411]\n",
      "epoch:21 step:19823 [D loss: 0.534193, acc.: 70.31%] [G loss: 1.303928]\n",
      "epoch:21 step:19824 [D loss: 0.668946, acc.: 62.50%] [G loss: 1.422039]\n",
      "epoch:21 step:19825 [D loss: 0.689978, acc.: 53.91%] [G loss: 1.078047]\n",
      "epoch:21 step:19826 [D loss: 0.462327, acc.: 80.47%] [G loss: 1.095893]\n",
      "epoch:21 step:19827 [D loss: 0.244782, acc.: 93.75%] [G loss: 1.291002]\n",
      "epoch:21 step:19828 [D loss: 0.274999, acc.: 92.97%] [G loss: 1.277091]\n",
      "epoch:21 step:19829 [D loss: 0.425042, acc.: 85.16%] [G loss: 1.418333]\n",
      "epoch:21 step:19830 [D loss: 0.819996, acc.: 50.00%] [G loss: 1.244257]\n",
      "epoch:21 step:19831 [D loss: 0.586283, acc.: 71.09%] [G loss: 1.239360]\n",
      "epoch:21 step:19832 [D loss: 0.538549, acc.: 75.00%] [G loss: 1.348379]\n",
      "epoch:21 step:19833 [D loss: 0.744574, acc.: 49.22%] [G loss: 1.028794]\n",
      "epoch:21 step:19834 [D loss: 0.739427, acc.: 51.56%] [G loss: 0.841956]\n",
      "epoch:21 step:19835 [D loss: 0.718225, acc.: 53.12%] [G loss: 1.270312]\n",
      "epoch:21 step:19836 [D loss: 0.730529, acc.: 53.12%] [G loss: 1.162922]\n",
      "epoch:21 step:19837 [D loss: 0.591455, acc.: 67.19%] [G loss: 0.962454]\n",
      "epoch:21 step:19838 [D loss: 0.555163, acc.: 75.00%] [G loss: 0.938164]\n",
      "epoch:21 step:19839 [D loss: 0.520654, acc.: 69.53%] [G loss: 0.936121]\n",
      "epoch:21 step:19840 [D loss: 0.679295, acc.: 57.81%] [G loss: 0.623333]\n",
      "epoch:21 step:19841 [D loss: 0.482074, acc.: 78.12%] [G loss: 1.024187]\n",
      "epoch:21 step:19842 [D loss: 0.583769, acc.: 68.75%] [G loss: 0.830696]\n",
      "epoch:21 step:19843 [D loss: 0.852234, acc.: 53.91%] [G loss: 0.967031]\n",
      "epoch:21 step:19844 [D loss: 1.175506, acc.: 15.62%] [G loss: 0.601364]\n",
      "epoch:21 step:19845 [D loss: 0.839880, acc.: 42.97%] [G loss: 0.913643]\n",
      "epoch:21 step:19846 [D loss: 0.706656, acc.: 50.78%] [G loss: 1.032654]\n",
      "epoch:21 step:19847 [D loss: 0.702812, acc.: 55.47%] [G loss: 0.968639]\n",
      "epoch:21 step:19848 [D loss: 0.686806, acc.: 53.12%] [G loss: 0.806677]\n",
      "epoch:21 step:19849 [D loss: 0.719193, acc.: 57.03%] [G loss: 0.907287]\n",
      "epoch:21 step:19850 [D loss: 0.655668, acc.: 58.59%] [G loss: 0.907821]\n",
      "epoch:21 step:19851 [D loss: 0.759723, acc.: 49.22%] [G loss: 1.028489]\n",
      "epoch:21 step:19852 [D loss: 0.665960, acc.: 57.03%] [G loss: 0.974832]\n",
      "epoch:21 step:19853 [D loss: 0.604705, acc.: 63.28%] [G loss: 0.926527]\n",
      "epoch:21 step:19854 [D loss: 0.702408, acc.: 50.00%] [G loss: 0.893830]\n",
      "epoch:21 step:19855 [D loss: 0.660884, acc.: 61.72%] [G loss: 0.980413]\n",
      "epoch:21 step:19856 [D loss: 0.759098, acc.: 45.31%] [G loss: 0.922669]\n",
      "epoch:21 step:19857 [D loss: 0.701698, acc.: 61.72%] [G loss: 0.805043]\n",
      "epoch:21 step:19858 [D loss: 0.677850, acc.: 54.69%] [G loss: 0.872990]\n",
      "epoch:21 step:19859 [D loss: 0.700806, acc.: 55.47%] [G loss: 0.857404]\n",
      "epoch:21 step:19860 [D loss: 0.614918, acc.: 66.41%] [G loss: 0.853345]\n",
      "epoch:21 step:19861 [D loss: 0.625531, acc.: 60.16%] [G loss: 0.865230]\n",
      "epoch:21 step:19862 [D loss: 0.607248, acc.: 67.97%] [G loss: 0.854521]\n",
      "epoch:21 step:19863 [D loss: 0.706091, acc.: 57.03%] [G loss: 0.923654]\n",
      "epoch:21 step:19864 [D loss: 0.704008, acc.: 50.78%] [G loss: 0.818093]\n",
      "epoch:21 step:19865 [D loss: 0.703190, acc.: 51.56%] [G loss: 0.865684]\n",
      "epoch:21 step:19866 [D loss: 0.667590, acc.: 61.72%] [G loss: 0.841484]\n",
      "epoch:21 step:19867 [D loss: 0.639205, acc.: 50.78%] [G loss: 0.828263]\n",
      "epoch:21 step:19868 [D loss: 0.636868, acc.: 62.50%] [G loss: 0.808051]\n",
      "epoch:21 step:19869 [D loss: 0.549551, acc.: 70.31%] [G loss: 0.945213]\n",
      "epoch:21 step:19870 [D loss: 0.577961, acc.: 71.09%] [G loss: 1.016983]\n",
      "epoch:21 step:19871 [D loss: 0.534992, acc.: 79.69%] [G loss: 0.855324]\n",
      "epoch:21 step:19872 [D loss: 0.541678, acc.: 78.91%] [G loss: 1.058762]\n",
      "epoch:21 step:19873 [D loss: 0.626880, acc.: 65.62%] [G loss: 0.960802]\n",
      "epoch:21 step:19874 [D loss: 0.541303, acc.: 77.34%] [G loss: 1.250751]\n",
      "epoch:21 step:19875 [D loss: 0.569664, acc.: 74.22%] [G loss: 1.073602]\n",
      "epoch:21 step:19876 [D loss: 0.785904, acc.: 49.22%] [G loss: 0.962684]\n",
      "epoch:21 step:19877 [D loss: 0.570566, acc.: 69.53%] [G loss: 0.895691]\n",
      "epoch:21 step:19878 [D loss: 0.316584, acc.: 92.97%] [G loss: 1.067065]\n",
      "epoch:21 step:19879 [D loss: 0.671082, acc.: 58.59%] [G loss: 0.892292]\n",
      "epoch:21 step:19880 [D loss: 0.530845, acc.: 78.91%] [G loss: 0.922235]\n",
      "epoch:21 step:19881 [D loss: 0.412119, acc.: 86.72%] [G loss: 0.993738]\n",
      "epoch:21 step:19882 [D loss: 0.627775, acc.: 62.50%] [G loss: 1.003700]\n",
      "epoch:21 step:19883 [D loss: 0.525780, acc.: 74.22%] [G loss: 0.893032]\n",
      "epoch:21 step:19884 [D loss: 0.348936, acc.: 81.25%] [G loss: 1.157106]\n",
      "epoch:21 step:19885 [D loss: 0.459376, acc.: 86.72%] [G loss: 1.199909]\n",
      "epoch:21 step:19886 [D loss: 0.504720, acc.: 76.56%] [G loss: 1.417086]\n",
      "epoch:21 step:19887 [D loss: 0.811064, acc.: 49.22%] [G loss: 1.011106]\n",
      "epoch:21 step:19888 [D loss: 0.822482, acc.: 42.19%] [G loss: 1.048533]\n",
      "epoch:21 step:19889 [D loss: 0.657957, acc.: 52.34%] [G loss: 0.974142]\n",
      "epoch:21 step:19890 [D loss: 0.691987, acc.: 55.47%] [G loss: 0.704745]\n",
      "epoch:21 step:19891 [D loss: 0.672822, acc.: 61.72%] [G loss: 0.976030]\n",
      "epoch:21 step:19892 [D loss: 0.725199, acc.: 50.78%] [G loss: 0.892052]\n",
      "epoch:21 step:19893 [D loss: 0.620480, acc.: 62.50%] [G loss: 0.830677]\n",
      "epoch:21 step:19894 [D loss: 0.489908, acc.: 85.16%] [G loss: 0.894341]\n",
      "epoch:21 step:19895 [D loss: 0.441880, acc.: 82.03%] [G loss: 1.021242]\n",
      "epoch:21 step:19896 [D loss: 0.364713, acc.: 89.84%] [G loss: 0.774629]\n",
      "epoch:21 step:19897 [D loss: 0.315455, acc.: 89.06%] [G loss: 1.092096]\n",
      "epoch:21 step:19898 [D loss: 0.355985, acc.: 87.50%] [G loss: 1.049764]\n",
      "epoch:21 step:19899 [D loss: 0.360259, acc.: 82.81%] [G loss: 0.549784]\n",
      "epoch:21 step:19900 [D loss: 0.552523, acc.: 76.56%] [G loss: 1.189787]\n",
      "epoch:21 step:19901 [D loss: 0.649573, acc.: 60.94%] [G loss: 1.066126]\n",
      "epoch:21 step:19902 [D loss: 0.593038, acc.: 65.62%] [G loss: 1.059962]\n",
      "epoch:21 step:19903 [D loss: 0.772173, acc.: 49.22%] [G loss: 1.085653]\n",
      "epoch:21 step:19904 [D loss: 0.697001, acc.: 61.72%] [G loss: 1.112942]\n",
      "epoch:21 step:19905 [D loss: 0.742834, acc.: 46.09%] [G loss: 1.123301]\n",
      "epoch:21 step:19906 [D loss: 0.701460, acc.: 52.34%] [G loss: 1.157238]\n",
      "epoch:21 step:19907 [D loss: 0.241409, acc.: 94.53%] [G loss: 1.326001]\n",
      "epoch:21 step:19908 [D loss: 0.262946, acc.: 92.19%] [G loss: 1.242122]\n",
      "epoch:21 step:19909 [D loss: 0.273722, acc.: 89.06%] [G loss: 1.257360]\n",
      "epoch:21 step:19910 [D loss: 0.675008, acc.: 67.97%] [G loss: 1.403086]\n",
      "epoch:21 step:19911 [D loss: 0.427608, acc.: 85.16%] [G loss: 1.028245]\n",
      "epoch:21 step:19912 [D loss: 0.343484, acc.: 86.72%] [G loss: 1.437776]\n",
      "epoch:21 step:19913 [D loss: 0.563641, acc.: 73.44%] [G loss: 1.129853]\n",
      "epoch:21 step:19914 [D loss: 0.405358, acc.: 89.06%] [G loss: 1.242338]\n",
      "epoch:21 step:19915 [D loss: 0.275286, acc.: 96.88%] [G loss: 1.144204]\n",
      "epoch:21 step:19916 [D loss: 0.558074, acc.: 75.78%] [G loss: 1.189128]\n",
      "epoch:21 step:19917 [D loss: 0.840580, acc.: 42.97%] [G loss: 0.961128]\n",
      "epoch:21 step:19918 [D loss: 1.109352, acc.: 26.56%] [G loss: 1.197937]\n",
      "epoch:21 step:19919 [D loss: 0.788256, acc.: 46.88%] [G loss: 1.117553]\n",
      "epoch:21 step:19920 [D loss: 0.573215, acc.: 75.78%] [G loss: 0.931639]\n",
      "epoch:21 step:19921 [D loss: 0.737628, acc.: 50.00%] [G loss: 1.054469]\n",
      "epoch:21 step:19922 [D loss: 0.780434, acc.: 50.00%] [G loss: 1.130808]\n",
      "epoch:21 step:19923 [D loss: 0.854595, acc.: 38.28%] [G loss: 0.471860]\n",
      "epoch:21 step:19924 [D loss: 0.675436, acc.: 56.25%] [G loss: 1.018279]\n",
      "epoch:21 step:19925 [D loss: 0.594679, acc.: 71.09%] [G loss: 1.087606]\n",
      "epoch:21 step:19926 [D loss: 0.670944, acc.: 60.94%] [G loss: 0.889486]\n",
      "epoch:21 step:19927 [D loss: 0.748825, acc.: 50.78%] [G loss: 0.990514]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:19928 [D loss: 0.626041, acc.: 65.62%] [G loss: 0.989462]\n",
      "epoch:21 step:19929 [D loss: 0.637386, acc.: 60.16%] [G loss: 0.991998]\n",
      "epoch:21 step:19930 [D loss: 0.649001, acc.: 64.84%] [G loss: 0.907218]\n",
      "epoch:21 step:19931 [D loss: 0.559932, acc.: 67.19%] [G loss: 0.873933]\n",
      "epoch:21 step:19932 [D loss: 0.345096, acc.: 82.81%] [G loss: 0.725406]\n",
      "epoch:21 step:19933 [D loss: 0.333530, acc.: 85.16%] [G loss: 1.123650]\n",
      "epoch:21 step:19934 [D loss: 0.315410, acc.: 98.44%] [G loss: 1.059130]\n",
      "epoch:21 step:19935 [D loss: 0.661769, acc.: 58.59%] [G loss: 1.094432]\n",
      "epoch:21 step:19936 [D loss: 0.621666, acc.: 57.81%] [G loss: 1.218848]\n",
      "epoch:21 step:19937 [D loss: 0.322713, acc.: 96.88%] [G loss: 1.244098]\n",
      "epoch:21 step:19938 [D loss: 0.259278, acc.: 95.31%] [G loss: 1.326152]\n",
      "epoch:21 step:19939 [D loss: 0.804722, acc.: 46.09%] [G loss: 1.371979]\n",
      "epoch:21 step:19940 [D loss: 0.244341, acc.: 96.88%] [G loss: 1.108327]\n",
      "epoch:21 step:19941 [D loss: 0.541893, acc.: 72.66%] [G loss: 0.948983]\n",
      "epoch:21 step:19942 [D loss: 0.659127, acc.: 67.97%] [G loss: 1.118031]\n",
      "epoch:21 step:19943 [D loss: 0.754834, acc.: 46.09%] [G loss: 1.083115]\n",
      "epoch:21 step:19944 [D loss: 0.653961, acc.: 57.03%] [G loss: 1.199971]\n",
      "epoch:21 step:19945 [D loss: 0.769831, acc.: 42.19%] [G loss: 1.043509]\n",
      "epoch:21 step:19946 [D loss: 0.541999, acc.: 73.44%] [G loss: 1.132297]\n",
      "epoch:21 step:19947 [D loss: 0.664765, acc.: 60.94%] [G loss: 0.961695]\n",
      "epoch:21 step:19948 [D loss: 0.452063, acc.: 82.81%] [G loss: 1.146188]\n",
      "epoch:21 step:19949 [D loss: 0.606725, acc.: 67.97%] [G loss: 1.015145]\n",
      "epoch:21 step:19950 [D loss: 0.686498, acc.: 53.12%] [G loss: 0.463939]\n",
      "epoch:21 step:19951 [D loss: 0.526565, acc.: 80.47%] [G loss: 1.034734]\n",
      "epoch:21 step:19952 [D loss: 0.569374, acc.: 71.88%] [G loss: 1.044588]\n",
      "epoch:21 step:19953 [D loss: 0.510834, acc.: 82.81%] [G loss: 0.993510]\n",
      "epoch:21 step:19954 [D loss: 0.718158, acc.: 47.66%] [G loss: 1.111153]\n",
      "epoch:21 step:19955 [D loss: 0.385612, acc.: 82.03%] [G loss: 0.978341]\n",
      "epoch:21 step:19956 [D loss: 0.270706, acc.: 94.53%] [G loss: 1.215126]\n",
      "epoch:21 step:19957 [D loss: 0.685419, acc.: 56.25%] [G loss: 1.098652]\n",
      "epoch:21 step:19958 [D loss: 0.837702, acc.: 33.59%] [G loss: 1.220224]\n",
      "epoch:21 step:19959 [D loss: 0.638312, acc.: 62.50%] [G loss: 1.070417]\n",
      "epoch:21 step:19960 [D loss: 0.782435, acc.: 48.44%] [G loss: 0.681906]\n",
      "epoch:21 step:19961 [D loss: 0.413395, acc.: 92.19%] [G loss: 0.457071]\n",
      "epoch:21 step:19962 [D loss: 0.518420, acc.: 79.69%] [G loss: 0.906993]\n",
      "epoch:21 step:19963 [D loss: 0.477267, acc.: 75.78%] [G loss: 0.973411]\n",
      "epoch:21 step:19964 [D loss: 0.349541, acc.: 92.19%] [G loss: 0.987580]\n",
      "epoch:21 step:19965 [D loss: 0.323908, acc.: 89.84%] [G loss: 1.194780]\n",
      "epoch:21 step:19966 [D loss: 0.232027, acc.: 95.31%] [G loss: 1.329438]\n",
      "epoch:21 step:19967 [D loss: 0.463690, acc.: 82.81%] [G loss: 1.194502]\n",
      "epoch:21 step:19968 [D loss: 0.366696, acc.: 88.28%] [G loss: 1.217672]\n",
      "epoch:21 step:19969 [D loss: 0.219693, acc.: 98.44%] [G loss: 1.231602]\n",
      "epoch:21 step:19970 [D loss: 0.320670, acc.: 92.97%] [G loss: 1.443528]\n",
      "epoch:21 step:19971 [D loss: 0.357180, acc.: 94.53%] [G loss: 1.314076]\n",
      "epoch:21 step:19972 [D loss: 0.923684, acc.: 42.19%] [G loss: 1.249995]\n",
      "epoch:21 step:19973 [D loss: 0.791902, acc.: 50.78%] [G loss: 1.159915]\n",
      "epoch:21 step:19974 [D loss: 0.676084, acc.: 60.94%] [G loss: 1.068021]\n",
      "epoch:21 step:19975 [D loss: 0.692322, acc.: 52.34%] [G loss: 0.944680]\n",
      "epoch:21 step:19976 [D loss: 0.570124, acc.: 73.44%] [G loss: 1.113001]\n",
      "epoch:21 step:19977 [D loss: 0.749958, acc.: 46.88%] [G loss: 0.949418]\n",
      "epoch:21 step:19978 [D loss: 0.731535, acc.: 51.56%] [G loss: 0.949943]\n",
      "epoch:21 step:19979 [D loss: 0.694183, acc.: 53.12%] [G loss: 0.909217]\n",
      "epoch:21 step:19980 [D loss: 0.718704, acc.: 48.44%] [G loss: 0.921065]\n",
      "epoch:21 step:19981 [D loss: 0.665833, acc.: 60.16%] [G loss: 1.092753]\n",
      "epoch:21 step:19982 [D loss: 0.358844, acc.: 78.12%] [G loss: 1.154152]\n",
      "epoch:21 step:19983 [D loss: 0.455457, acc.: 78.91%] [G loss: 1.177769]\n",
      "epoch:21 step:19984 [D loss: 0.607160, acc.: 64.06%] [G loss: 1.112009]\n",
      "epoch:21 step:19985 [D loss: 0.294831, acc.: 94.53%] [G loss: 0.955646]\n",
      "epoch:21 step:19986 [D loss: 0.210681, acc.: 97.66%] [G loss: 1.318829]\n",
      "epoch:21 step:19987 [D loss: 0.587158, acc.: 67.19%] [G loss: 1.166203]\n",
      "epoch:21 step:19988 [D loss: 0.300839, acc.: 95.31%] [G loss: 1.348551]\n",
      "epoch:21 step:19989 [D loss: 0.660113, acc.: 57.81%] [G loss: 1.424275]\n",
      "epoch:21 step:19990 [D loss: 0.187103, acc.: 98.44%] [G loss: 1.498137]\n",
      "epoch:21 step:19991 [D loss: 0.142466, acc.: 100.00%] [G loss: 1.634468]\n",
      "epoch:21 step:19992 [D loss: 0.345434, acc.: 93.75%] [G loss: 1.525729]\n",
      "epoch:21 step:19993 [D loss: 0.800929, acc.: 53.91%] [G loss: 1.517461]\n",
      "epoch:21 step:19994 [D loss: 0.860245, acc.: 47.66%] [G loss: 1.250140]\n",
      "epoch:21 step:19995 [D loss: 0.746761, acc.: 52.34%] [G loss: 1.133425]\n",
      "epoch:21 step:19996 [D loss: 0.832524, acc.: 42.19%] [G loss: 1.025504]\n",
      "epoch:21 step:19997 [D loss: 0.762852, acc.: 43.75%] [G loss: 1.130299]\n",
      "epoch:21 step:19998 [D loss: 0.975636, acc.: 35.94%] [G loss: 1.095983]\n",
      "epoch:21 step:19999 [D loss: 0.740257, acc.: 51.56%] [G loss: 1.094675]\n",
      "epoch:21 step:20000 [D loss: 0.373340, acc.: 93.75%] [G loss: 1.201838]\n",
      "##############\n",
      "[3.77434408 2.51930613 6.49615921 5.52188286 4.27667036 5.71960478\n",
      " 5.28258299 5.38091053 5.90916323 4.8773859 ]\n",
      "##########\n",
      "epoch:21 step:20001 [D loss: 0.566861, acc.: 70.31%] [G loss: 1.195800]\n",
      "epoch:21 step:20002 [D loss: 0.613427, acc.: 64.84%] [G loss: 1.203544]\n",
      "epoch:21 step:20003 [D loss: 0.706635, acc.: 51.56%] [G loss: 1.063947]\n",
      "epoch:21 step:20004 [D loss: 0.660899, acc.: 60.16%] [G loss: 1.019186]\n",
      "epoch:21 step:20005 [D loss: 0.612095, acc.: 66.41%] [G loss: 1.160303]\n",
      "epoch:21 step:20006 [D loss: 0.705023, acc.: 53.12%] [G loss: 1.092362]\n",
      "epoch:21 step:20007 [D loss: 0.742804, acc.: 42.97%] [G loss: 0.727842]\n",
      "epoch:21 step:20008 [D loss: 0.427785, acc.: 85.16%] [G loss: 0.762667]\n",
      "epoch:21 step:20009 [D loss: 0.308221, acc.: 91.41%] [G loss: 0.788701]\n",
      "epoch:21 step:20010 [D loss: 0.252276, acc.: 95.31%] [G loss: 0.543521]\n",
      "epoch:21 step:20011 [D loss: 0.248895, acc.: 94.53%] [G loss: 1.571003]\n",
      "epoch:21 step:20012 [D loss: 0.291086, acc.: 97.66%] [G loss: 0.506923]\n",
      "epoch:21 step:20013 [D loss: 0.237480, acc.: 94.53%] [G loss: 1.539648]\n",
      "epoch:21 step:20014 [D loss: 1.177329, acc.: 35.16%] [G loss: 1.413253]\n",
      "epoch:21 step:20015 [D loss: 0.654801, acc.: 56.25%] [G loss: 1.567115]\n",
      "epoch:21 step:20016 [D loss: 0.888099, acc.: 33.59%] [G loss: 1.418092]\n",
      "epoch:21 step:20017 [D loss: 0.724227, acc.: 54.69%] [G loss: 1.128903]\n",
      "epoch:21 step:20018 [D loss: 0.747267, acc.: 51.56%] [G loss: 1.198327]\n",
      "epoch:21 step:20019 [D loss: 0.191693, acc.: 100.00%] [G loss: 1.268449]\n",
      "epoch:21 step:20020 [D loss: 0.179040, acc.: 100.00%] [G loss: 1.455009]\n",
      "epoch:21 step:20021 [D loss: 0.203393, acc.: 97.66%] [G loss: 1.269108]\n",
      "epoch:21 step:20022 [D loss: 0.389795, acc.: 78.12%] [G loss: 1.398793]\n",
      "epoch:21 step:20023 [D loss: 0.358462, acc.: 89.84%] [G loss: 0.918655]\n",
      "epoch:21 step:20024 [D loss: 0.421993, acc.: 72.66%] [G loss: 1.227358]\n",
      "epoch:21 step:20025 [D loss: 0.850756, acc.: 50.78%] [G loss: 1.206118]\n",
      "epoch:21 step:20026 [D loss: 1.011511, acc.: 35.94%] [G loss: 0.997243]\n",
      "epoch:21 step:20027 [D loss: 0.781569, acc.: 50.78%] [G loss: 0.832945]\n",
      "epoch:21 step:20028 [D loss: 0.673358, acc.: 57.81%] [G loss: 0.784424]\n",
      "epoch:21 step:20029 [D loss: 0.736396, acc.: 49.22%] [G loss: 1.190890]\n",
      "epoch:21 step:20030 [D loss: 0.558574, acc.: 72.66%] [G loss: 1.021325]\n",
      "epoch:21 step:20031 [D loss: 0.764816, acc.: 48.44%] [G loss: 0.914052]\n",
      "epoch:21 step:20032 [D loss: 0.650012, acc.: 55.47%] [G loss: 1.367401]\n",
      "epoch:21 step:20033 [D loss: 0.701289, acc.: 50.00%] [G loss: 1.446392]\n",
      "epoch:21 step:20034 [D loss: 0.651309, acc.: 57.81%] [G loss: 1.399015]\n",
      "epoch:21 step:20035 [D loss: 0.362081, acc.: 92.19%] [G loss: 1.892225]\n",
      "epoch:21 step:20036 [D loss: 0.336824, acc.: 89.06%] [G loss: 2.029275]\n",
      "epoch:21 step:20037 [D loss: 0.321669, acc.: 93.75%] [G loss: 1.948530]\n",
      "epoch:21 step:20038 [D loss: 0.329208, acc.: 92.19%] [G loss: 2.063934]\n",
      "epoch:21 step:20039 [D loss: 0.810272, acc.: 53.91%] [G loss: 1.563354]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20040 [D loss: 0.724074, acc.: 55.47%] [G loss: 1.098722]\n",
      "epoch:21 step:20041 [D loss: 0.495262, acc.: 78.91%] [G loss: 0.881421]\n",
      "epoch:21 step:20042 [D loss: 0.589568, acc.: 73.44%] [G loss: 0.846766]\n",
      "epoch:21 step:20043 [D loss: 0.836124, acc.: 46.88%] [G loss: 0.830277]\n",
      "epoch:21 step:20044 [D loss: 0.843640, acc.: 41.41%] [G loss: 0.975894]\n",
      "epoch:21 step:20045 [D loss: 0.615414, acc.: 66.41%] [G loss: 0.576944]\n",
      "epoch:21 step:20046 [D loss: 0.380945, acc.: 77.34%] [G loss: 0.954396]\n",
      "epoch:21 step:20047 [D loss: 0.272880, acc.: 89.84%] [G loss: 1.187572]\n",
      "epoch:21 step:20048 [D loss: 0.244661, acc.: 91.41%] [G loss: 1.113762]\n",
      "epoch:21 step:20049 [D loss: 0.293068, acc.: 96.88%] [G loss: 1.373190]\n",
      "epoch:21 step:20050 [D loss: 0.712565, acc.: 54.69%] [G loss: 1.024028]\n",
      "epoch:21 step:20051 [D loss: 0.405180, acc.: 89.84%] [G loss: 1.255093]\n",
      "epoch:21 step:20052 [D loss: 0.766153, acc.: 43.75%] [G loss: 0.981380]\n",
      "epoch:21 step:20053 [D loss: 0.751862, acc.: 46.88%] [G loss: 0.696734]\n",
      "epoch:21 step:20054 [D loss: 1.408855, acc.: 10.94%] [G loss: 0.573419]\n",
      "epoch:21 step:20055 [D loss: 1.016149, acc.: 28.12%] [G loss: 0.853857]\n",
      "epoch:21 step:20056 [D loss: 0.500443, acc.: 79.69%] [G loss: 0.928374]\n",
      "epoch:21 step:20057 [D loss: 0.391623, acc.: 78.91%] [G loss: 0.946397]\n",
      "epoch:21 step:20058 [D loss: 0.429864, acc.: 80.47%] [G loss: 0.972577]\n",
      "epoch:21 step:20059 [D loss: 0.858699, acc.: 35.16%] [G loss: 1.117231]\n",
      "epoch:21 step:20060 [D loss: 0.789825, acc.: 42.97%] [G loss: 1.033087]\n",
      "epoch:21 step:20061 [D loss: 0.730067, acc.: 44.53%] [G loss: 1.038100]\n",
      "epoch:21 step:20062 [D loss: 0.733116, acc.: 52.34%] [G loss: 1.001470]\n",
      "epoch:21 step:20063 [D loss: 0.743144, acc.: 42.19%] [G loss: 0.937762]\n",
      "epoch:21 step:20064 [D loss: 0.794942, acc.: 40.62%] [G loss: 1.064560]\n",
      "epoch:21 step:20065 [D loss: 0.612268, acc.: 65.62%] [G loss: 1.070522]\n",
      "epoch:21 step:20066 [D loss: 0.687654, acc.: 53.12%] [G loss: 1.135934]\n",
      "epoch:21 step:20067 [D loss: 0.792926, acc.: 39.06%] [G loss: 0.968353]\n",
      "epoch:21 step:20068 [D loss: 0.746083, acc.: 42.19%] [G loss: 0.909517]\n",
      "epoch:21 step:20069 [D loss: 0.703776, acc.: 54.69%] [G loss: 1.018069]\n",
      "epoch:21 step:20070 [D loss: 0.724033, acc.: 42.97%] [G loss: 1.028248]\n",
      "epoch:21 step:20071 [D loss: 0.731315, acc.: 42.97%] [G loss: 1.052169]\n",
      "epoch:21 step:20072 [D loss: 0.646013, acc.: 59.38%] [G loss: 1.058950]\n",
      "epoch:21 step:20073 [D loss: 0.580789, acc.: 75.00%] [G loss: 0.959285]\n",
      "epoch:21 step:20074 [D loss: 0.421815, acc.: 85.16%] [G loss: 1.143809]\n",
      "epoch:21 step:20075 [D loss: 0.384584, acc.: 94.53%] [G loss: 1.190006]\n",
      "epoch:21 step:20076 [D loss: 0.389872, acc.: 86.72%] [G loss: 1.438159]\n",
      "epoch:21 step:20077 [D loss: 0.441635, acc.: 82.81%] [G loss: 1.219623]\n",
      "epoch:21 step:20078 [D loss: 0.510817, acc.: 83.59%] [G loss: 1.143220]\n",
      "epoch:21 step:20079 [D loss: 0.351745, acc.: 92.19%] [G loss: 1.343577]\n",
      "epoch:21 step:20080 [D loss: 0.425805, acc.: 87.50%] [G loss: 1.143820]\n",
      "epoch:21 step:20081 [D loss: 0.356414, acc.: 96.09%] [G loss: 1.409893]\n",
      "epoch:21 step:20082 [D loss: 0.342097, acc.: 88.28%] [G loss: 1.457658]\n",
      "epoch:21 step:20083 [D loss: 0.243387, acc.: 96.88%] [G loss: 1.323820]\n",
      "epoch:21 step:20084 [D loss: 0.303032, acc.: 86.72%] [G loss: 1.380173]\n",
      "epoch:21 step:20085 [D loss: 0.336529, acc.: 93.75%] [G loss: 1.438079]\n",
      "epoch:21 step:20086 [D loss: 0.275633, acc.: 92.19%] [G loss: 0.990791]\n",
      "epoch:21 step:20087 [D loss: 0.591952, acc.: 71.88%] [G loss: 1.058956]\n",
      "epoch:21 step:20088 [D loss: 1.011249, acc.: 30.47%] [G loss: 1.252892]\n",
      "epoch:21 step:20089 [D loss: 0.360053, acc.: 95.31%] [G loss: 1.316898]\n",
      "epoch:21 step:20090 [D loss: 0.361913, acc.: 82.81%] [G loss: 0.496555]\n",
      "epoch:21 step:20091 [D loss: 0.314035, acc.: 95.31%] [G loss: 1.314079]\n",
      "epoch:21 step:20092 [D loss: 0.359205, acc.: 94.53%] [G loss: 0.528347]\n",
      "epoch:21 step:20093 [D loss: 0.711309, acc.: 60.16%] [G loss: 0.457018]\n",
      "epoch:21 step:20094 [D loss: 0.510866, acc.: 70.31%] [G loss: 1.284551]\n",
      "epoch:21 step:20095 [D loss: 0.166257, acc.: 99.22%] [G loss: 1.339214]\n",
      "epoch:21 step:20096 [D loss: 0.203588, acc.: 98.44%] [G loss: 1.728878]\n",
      "epoch:21 step:20097 [D loss: 0.859462, acc.: 57.03%] [G loss: 1.115276]\n",
      "epoch:21 step:20098 [D loss: 1.384866, acc.: 12.50%] [G loss: 1.274587]\n",
      "epoch:21 step:20099 [D loss: 1.010649, acc.: 39.84%] [G loss: 1.342592]\n",
      "epoch:21 step:20100 [D loss: 0.717151, acc.: 55.47%] [G loss: 1.086871]\n",
      "epoch:21 step:20101 [D loss: 0.550270, acc.: 73.44%] [G loss: 1.393537]\n",
      "epoch:21 step:20102 [D loss: 0.520135, acc.: 72.66%] [G loss: 0.942935]\n",
      "epoch:21 step:20103 [D loss: 0.929287, acc.: 34.38%] [G loss: 1.171834]\n",
      "epoch:21 step:20104 [D loss: 0.501189, acc.: 78.12%] [G loss: 1.247630]\n",
      "epoch:21 step:20105 [D loss: 0.291635, acc.: 96.88%] [G loss: 1.095112]\n",
      "epoch:21 step:20106 [D loss: 0.619088, acc.: 69.53%] [G loss: 0.975589]\n",
      "epoch:21 step:20107 [D loss: 0.419801, acc.: 77.34%] [G loss: 1.240416]\n",
      "epoch:21 step:20108 [D loss: 0.820197, acc.: 43.75%] [G loss: 1.221656]\n",
      "epoch:21 step:20109 [D loss: 0.750141, acc.: 52.34%] [G loss: 1.269723]\n",
      "epoch:21 step:20110 [D loss: 0.743219, acc.: 53.12%] [G loss: 1.288808]\n",
      "epoch:21 step:20111 [D loss: 0.661423, acc.: 58.59%] [G loss: 0.900519]\n",
      "epoch:21 step:20112 [D loss: 0.717605, acc.: 56.25%] [G loss: 0.934447]\n",
      "epoch:21 step:20113 [D loss: 0.690776, acc.: 55.47%] [G loss: 1.094180]\n",
      "epoch:21 step:20114 [D loss: 0.699675, acc.: 53.12%] [G loss: 1.084642]\n",
      "epoch:21 step:20115 [D loss: 0.746359, acc.: 54.69%] [G loss: 1.191870]\n",
      "epoch:21 step:20116 [D loss: 0.793847, acc.: 36.72%] [G loss: 1.156697]\n",
      "epoch:21 step:20117 [D loss: 0.691603, acc.: 54.69%] [G loss: 1.038591]\n",
      "epoch:21 step:20118 [D loss: 0.661358, acc.: 59.38%] [G loss: 1.048643]\n",
      "epoch:21 step:20119 [D loss: 0.656072, acc.: 58.59%] [G loss: 1.051891]\n",
      "epoch:21 step:20120 [D loss: 0.650682, acc.: 61.72%] [G loss: 1.080670]\n",
      "epoch:21 step:20121 [D loss: 0.670742, acc.: 57.03%] [G loss: 1.081769]\n",
      "epoch:21 step:20122 [D loss: 0.667403, acc.: 60.94%] [G loss: 1.129319]\n",
      "epoch:21 step:20123 [D loss: 0.679091, acc.: 58.59%] [G loss: 0.984674]\n",
      "epoch:21 step:20124 [D loss: 0.705315, acc.: 57.03%] [G loss: 0.993206]\n",
      "epoch:21 step:20125 [D loss: 0.573355, acc.: 74.22%] [G loss: 1.130069]\n",
      "epoch:21 step:20126 [D loss: 0.518122, acc.: 85.94%] [G loss: 1.120965]\n",
      "epoch:21 step:20127 [D loss: 0.503901, acc.: 78.91%] [G loss: 1.046630]\n",
      "epoch:21 step:20128 [D loss: 0.431748, acc.: 92.97%] [G loss: 1.353993]\n",
      "epoch:21 step:20129 [D loss: 0.436132, acc.: 92.97%] [G loss: 1.351222]\n",
      "epoch:21 step:20130 [D loss: 0.428913, acc.: 85.94%] [G loss: 1.521107]\n",
      "epoch:21 step:20131 [D loss: 0.451231, acc.: 84.38%] [G loss: 1.413936]\n",
      "epoch:21 step:20132 [D loss: 0.426090, acc.: 84.38%] [G loss: 1.283502]\n",
      "epoch:21 step:20133 [D loss: 0.364579, acc.: 92.97%] [G loss: 1.441885]\n",
      "epoch:21 step:20134 [D loss: 0.399785, acc.: 90.62%] [G loss: 1.368405]\n",
      "epoch:21 step:20135 [D loss: 0.618340, acc.: 59.38%] [G loss: 1.274882]\n",
      "epoch:21 step:20136 [D loss: 0.499721, acc.: 72.66%] [G loss: 1.301944]\n",
      "epoch:21 step:20137 [D loss: 0.612499, acc.: 65.62%] [G loss: 1.228851]\n",
      "epoch:21 step:20138 [D loss: 0.910458, acc.: 39.06%] [G loss: 0.753942]\n",
      "epoch:21 step:20139 [D loss: 0.965275, acc.: 39.06%] [G loss: 0.901212]\n",
      "epoch:21 step:20140 [D loss: 0.739993, acc.: 42.19%] [G loss: 0.714991]\n",
      "epoch:21 step:20141 [D loss: 0.624518, acc.: 64.06%] [G loss: 0.803851]\n",
      "epoch:21 step:20142 [D loss: 0.650711, acc.: 62.50%] [G loss: 0.848531]\n",
      "epoch:21 step:20143 [D loss: 0.573599, acc.: 72.66%] [G loss: 1.127121]\n",
      "epoch:21 step:20144 [D loss: 0.511109, acc.: 85.16%] [G loss: 0.861003]\n",
      "epoch:21 step:20145 [D loss: 0.398730, acc.: 89.84%] [G loss: 0.908434]\n",
      "epoch:21 step:20146 [D loss: 0.474237, acc.: 74.22%] [G loss: 1.040455]\n",
      "epoch:21 step:20147 [D loss: 0.302004, acc.: 96.09%] [G loss: 1.499553]\n",
      "epoch:21 step:20148 [D loss: 0.292854, acc.: 94.53%] [G loss: 1.318972]\n",
      "epoch:21 step:20149 [D loss: 0.469715, acc.: 85.16%] [G loss: 1.104945]\n",
      "epoch:21 step:20150 [D loss: 1.050040, acc.: 47.66%] [G loss: 1.039025]\n",
      "epoch:21 step:20151 [D loss: 1.001054, acc.: 29.69%] [G loss: 1.012589]\n",
      "epoch:21 step:20152 [D loss: 0.832051, acc.: 35.16%] [G loss: 0.870397]\n",
      "epoch:21 step:20153 [D loss: 0.629539, acc.: 70.31%] [G loss: 0.740579]\n",
      "epoch:21 step:20154 [D loss: 0.626344, acc.: 67.19%] [G loss: 0.787807]\n",
      "epoch:21 step:20155 [D loss: 0.636388, acc.: 64.06%] [G loss: 0.919167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20156 [D loss: 0.430377, acc.: 86.72%] [G loss: 1.047930]\n",
      "epoch:21 step:20157 [D loss: 0.486506, acc.: 75.00%] [G loss: 0.939286]\n",
      "epoch:21 step:20158 [D loss: 0.477419, acc.: 71.88%] [G loss: 0.911161]\n",
      "epoch:21 step:20159 [D loss: 0.872440, acc.: 39.84%] [G loss: 0.913877]\n",
      "epoch:21 step:20160 [D loss: 0.740909, acc.: 53.91%] [G loss: 0.886881]\n",
      "epoch:21 step:20161 [D loss: 0.710930, acc.: 44.53%] [G loss: 1.006695]\n",
      "epoch:21 step:20162 [D loss: 0.743265, acc.: 43.75%] [G loss: 0.914465]\n",
      "epoch:21 step:20163 [D loss: 0.702984, acc.: 47.66%] [G loss: 0.952363]\n",
      "epoch:21 step:20164 [D loss: 0.703321, acc.: 46.88%] [G loss: 0.782601]\n",
      "epoch:21 step:20165 [D loss: 0.633763, acc.: 67.97%] [G loss: 0.871959]\n",
      "epoch:21 step:20166 [D loss: 0.633358, acc.: 65.62%] [G loss: 0.788993]\n",
      "epoch:21 step:20167 [D loss: 0.464525, acc.: 85.94%] [G loss: 1.011660]\n",
      "epoch:21 step:20168 [D loss: 0.582305, acc.: 64.84%] [G loss: 0.811466]\n",
      "epoch:21 step:20169 [D loss: 0.651408, acc.: 60.16%] [G loss: 0.995297]\n",
      "epoch:21 step:20170 [D loss: 0.799510, acc.: 44.53%] [G loss: 0.875423]\n",
      "epoch:21 step:20171 [D loss: 0.605711, acc.: 74.22%] [G loss: 0.916528]\n",
      "epoch:21 step:20172 [D loss: 0.625414, acc.: 63.28%] [G loss: 0.766224]\n",
      "epoch:21 step:20173 [D loss: 0.790243, acc.: 49.22%] [G loss: 1.064440]\n",
      "epoch:21 step:20174 [D loss: 0.602282, acc.: 67.19%] [G loss: 0.963611]\n",
      "epoch:21 step:20175 [D loss: 0.475894, acc.: 85.16%] [G loss: 1.153774]\n",
      "epoch:21 step:20176 [D loss: 0.439062, acc.: 83.59%] [G loss: 1.122519]\n",
      "epoch:21 step:20177 [D loss: 0.667972, acc.: 63.28%] [G loss: 0.963949]\n",
      "epoch:21 step:20178 [D loss: 0.666776, acc.: 63.28%] [G loss: 1.029018]\n",
      "epoch:21 step:20179 [D loss: 0.639696, acc.: 62.50%] [G loss: 1.099175]\n",
      "epoch:21 step:20180 [D loss: 0.363901, acc.: 88.28%] [G loss: 1.152274]\n",
      "epoch:21 step:20181 [D loss: 0.369422, acc.: 86.72%] [G loss: 1.157883]\n",
      "epoch:21 step:20182 [D loss: 0.413558, acc.: 84.38%] [G loss: 1.198749]\n",
      "epoch:21 step:20183 [D loss: 0.574311, acc.: 68.75%] [G loss: 1.040400]\n",
      "epoch:21 step:20184 [D loss: 0.400761, acc.: 87.50%] [G loss: 1.067440]\n",
      "epoch:21 step:20185 [D loss: 0.510799, acc.: 79.69%] [G loss: 1.009584]\n",
      "epoch:21 step:20186 [D loss: 0.737122, acc.: 51.56%] [G loss: 1.050453]\n",
      "epoch:21 step:20187 [D loss: 0.607881, acc.: 65.62%] [G loss: 1.334718]\n",
      "epoch:21 step:20188 [D loss: 0.373069, acc.: 80.47%] [G loss: 1.385663]\n",
      "epoch:21 step:20189 [D loss: 0.509304, acc.: 75.00%] [G loss: 1.299561]\n",
      "epoch:21 step:20190 [D loss: 0.330744, acc.: 90.62%] [G loss: 1.437065]\n",
      "epoch:21 step:20191 [D loss: 0.317152, acc.: 90.62%] [G loss: 1.168612]\n",
      "epoch:21 step:20192 [D loss: 0.297521, acc.: 85.94%] [G loss: 1.652727]\n",
      "epoch:21 step:20193 [D loss: 0.746630, acc.: 64.06%] [G loss: 1.204452]\n",
      "epoch:21 step:20194 [D loss: 0.515839, acc.: 74.22%] [G loss: 1.089130]\n",
      "epoch:21 step:20195 [D loss: 0.765472, acc.: 51.56%] [G loss: 1.269060]\n",
      "epoch:21 step:20196 [D loss: 0.666822, acc.: 64.84%] [G loss: 1.126586]\n",
      "epoch:21 step:20197 [D loss: 0.628720, acc.: 60.94%] [G loss: 1.075423]\n",
      "epoch:21 step:20198 [D loss: 0.693598, acc.: 57.81%] [G loss: 1.001034]\n",
      "epoch:21 step:20199 [D loss: 0.667915, acc.: 57.03%] [G loss: 0.936239]\n",
      "epoch:21 step:20200 [D loss: 0.643094, acc.: 64.06%] [G loss: 1.112410]\n",
      "##############\n",
      "[4.00988424 2.47704637 6.7586989  5.27207518 4.26399656 5.57292513\n",
      " 5.25104962 5.67161829 5.84729776 4.76901859]\n",
      "##########\n",
      "epoch:21 step:20201 [D loss: 0.299279, acc.: 85.94%] [G loss: 1.154863]\n",
      "epoch:21 step:20202 [D loss: 0.602323, acc.: 73.44%] [G loss: 1.190804]\n",
      "epoch:21 step:20203 [D loss: 0.521386, acc.: 76.56%] [G loss: 1.124481]\n",
      "epoch:21 step:20204 [D loss: 0.279166, acc.: 93.75%] [G loss: 1.159604]\n",
      "epoch:21 step:20205 [D loss: 0.510938, acc.: 80.47%] [G loss: 0.769399]\n",
      "epoch:21 step:20206 [D loss: 0.682158, acc.: 56.25%] [G loss: 1.178888]\n",
      "epoch:21 step:20207 [D loss: 0.291846, acc.: 89.06%] [G loss: 1.394544]\n",
      "epoch:21 step:20208 [D loss: 0.713929, acc.: 53.91%] [G loss: 0.881235]\n",
      "epoch:21 step:20209 [D loss: 0.709004, acc.: 55.47%] [G loss: 0.973589]\n",
      "epoch:21 step:20210 [D loss: 0.510736, acc.: 80.47%] [G loss: 1.029769]\n",
      "epoch:21 step:20211 [D loss: 0.535295, acc.: 74.22%] [G loss: 1.080490]\n",
      "epoch:21 step:20212 [D loss: 0.279160, acc.: 89.06%] [G loss: 0.937201]\n",
      "epoch:21 step:20213 [D loss: 0.205631, acc.: 96.88%] [G loss: 1.184092]\n",
      "epoch:21 step:20214 [D loss: 0.308922, acc.: 87.50%] [G loss: 1.484026]\n",
      "epoch:21 step:20215 [D loss: 0.435882, acc.: 86.72%] [G loss: 1.304780]\n",
      "epoch:21 step:20216 [D loss: 0.294436, acc.: 93.75%] [G loss: 1.006898]\n",
      "epoch:21 step:20217 [D loss: 0.393223, acc.: 89.84%] [G loss: 1.358764]\n",
      "epoch:21 step:20218 [D loss: 0.456872, acc.: 73.44%] [G loss: 1.374484]\n",
      "epoch:21 step:20219 [D loss: 0.641109, acc.: 67.19%] [G loss: 1.361473]\n",
      "epoch:21 step:20220 [D loss: 0.237668, acc.: 93.75%] [G loss: 1.160466]\n",
      "epoch:21 step:20221 [D loss: 0.754535, acc.: 53.91%] [G loss: 1.183580]\n",
      "epoch:21 step:20222 [D loss: 0.509346, acc.: 77.34%] [G loss: 1.471651]\n",
      "epoch:21 step:20223 [D loss: 0.682856, acc.: 60.94%] [G loss: 1.267419]\n",
      "epoch:21 step:20224 [D loss: 0.657173, acc.: 60.94%] [G loss: 1.116392]\n",
      "epoch:21 step:20225 [D loss: 0.438542, acc.: 81.25%] [G loss: 1.229509]\n",
      "epoch:21 step:20226 [D loss: 0.330290, acc.: 93.75%] [G loss: 1.234042]\n",
      "epoch:21 step:20227 [D loss: 0.230103, acc.: 96.09%] [G loss: 1.248089]\n",
      "epoch:21 step:20228 [D loss: 0.473416, acc.: 82.81%] [G loss: 1.185957]\n",
      "epoch:21 step:20229 [D loss: 0.590882, acc.: 67.97%] [G loss: 1.472470]\n",
      "epoch:21 step:20230 [D loss: 0.692275, acc.: 60.16%] [G loss: 1.244399]\n",
      "epoch:21 step:20231 [D loss: 0.341443, acc.: 87.50%] [G loss: 1.070030]\n",
      "epoch:21 step:20232 [D loss: 0.594921, acc.: 74.22%] [G loss: 1.266219]\n",
      "epoch:21 step:20233 [D loss: 0.528770, acc.: 64.84%] [G loss: 1.723561]\n",
      "epoch:21 step:20234 [D loss: 0.583060, acc.: 64.84%] [G loss: 0.242159]\n",
      "epoch:21 step:20235 [D loss: 0.626755, acc.: 64.84%] [G loss: 1.747016]\n",
      "epoch:21 step:20236 [D loss: 0.286346, acc.: 91.41%] [G loss: 1.618232]\n",
      "epoch:21 step:20237 [D loss: 0.353804, acc.: 92.19%] [G loss: 1.267355]\n",
      "epoch:21 step:20238 [D loss: 0.147996, acc.: 100.00%] [G loss: 1.381321]\n",
      "epoch:21 step:20239 [D loss: 0.784971, acc.: 59.38%] [G loss: 1.752999]\n",
      "epoch:21 step:20240 [D loss: 1.137422, acc.: 32.03%] [G loss: 1.605686]\n",
      "epoch:21 step:20241 [D loss: 0.630560, acc.: 64.06%] [G loss: 1.462114]\n",
      "epoch:21 step:20242 [D loss: 0.333459, acc.: 92.97%] [G loss: 1.480814]\n",
      "epoch:21 step:20243 [D loss: 0.275537, acc.: 85.94%] [G loss: 1.625588]\n",
      "epoch:21 step:20244 [D loss: 0.153538, acc.: 99.22%] [G loss: 1.663150]\n",
      "epoch:21 step:20245 [D loss: 0.508807, acc.: 71.88%] [G loss: 1.525603]\n",
      "epoch:21 step:20246 [D loss: 0.794847, acc.: 47.66%] [G loss: 1.586204]\n",
      "epoch:21 step:20247 [D loss: 0.502343, acc.: 78.91%] [G loss: 1.499021]\n",
      "epoch:21 step:20248 [D loss: 0.583835, acc.: 64.06%] [G loss: 1.306448]\n",
      "epoch:21 step:20249 [D loss: 0.492524, acc.: 80.47%] [G loss: 1.244920]\n",
      "epoch:21 step:20250 [D loss: 0.247241, acc.: 96.09%] [G loss: 1.125815]\n",
      "epoch:21 step:20251 [D loss: 0.386204, acc.: 82.81%] [G loss: 1.326386]\n",
      "epoch:21 step:20252 [D loss: 0.390428, acc.: 85.16%] [G loss: 1.244898]\n",
      "epoch:21 step:20253 [D loss: 0.151538, acc.: 99.22%] [G loss: 1.774871]\n",
      "epoch:21 step:20254 [D loss: 0.125120, acc.: 99.22%] [G loss: 2.094526]\n",
      "epoch:21 step:20255 [D loss: 0.124525, acc.: 99.22%] [G loss: 1.956396]\n",
      "epoch:21 step:20256 [D loss: 0.102820, acc.: 99.22%] [G loss: 1.976122]\n",
      "epoch:21 step:20257 [D loss: 0.831071, acc.: 54.69%] [G loss: 1.038834]\n",
      "epoch:21 step:20258 [D loss: 0.874025, acc.: 41.41%] [G loss: 0.815710]\n",
      "epoch:21 step:20259 [D loss: 0.783480, acc.: 50.00%] [G loss: 0.750194]\n",
      "epoch:21 step:20260 [D loss: 0.891251, acc.: 47.66%] [G loss: 1.384177]\n",
      "epoch:21 step:20261 [D loss: 1.098686, acc.: 35.94%] [G loss: 1.074430]\n",
      "epoch:21 step:20262 [D loss: 0.762626, acc.: 49.22%] [G loss: 1.358815]\n",
      "epoch:21 step:20263 [D loss: 0.753422, acc.: 53.12%] [G loss: 0.683590]\n",
      "epoch:21 step:20264 [D loss: 0.837947, acc.: 59.38%] [G loss: 1.126896]\n",
      "epoch:21 step:20265 [D loss: 0.201861, acc.: 96.88%] [G loss: 1.197738]\n",
      "epoch:21 step:20266 [D loss: 0.171572, acc.: 99.22%] [G loss: 1.246130]\n",
      "epoch:21 step:20267 [D loss: 1.223805, acc.: 21.88%] [G loss: 1.759091]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20268 [D loss: 0.561893, acc.: 67.97%] [G loss: 1.740705]\n",
      "epoch:21 step:20269 [D loss: 0.530218, acc.: 66.41%] [G loss: 1.544481]\n",
      "epoch:21 step:20270 [D loss: 0.706586, acc.: 54.69%] [G loss: 1.465061]\n",
      "epoch:21 step:20271 [D loss: 0.845444, acc.: 54.69%] [G loss: 1.332976]\n",
      "epoch:21 step:20272 [D loss: 0.692676, acc.: 58.59%] [G loss: 1.281318]\n",
      "epoch:21 step:20273 [D loss: 0.603066, acc.: 69.53%] [G loss: 1.102709]\n",
      "epoch:21 step:20274 [D loss: 0.677502, acc.: 57.03%] [G loss: 1.145791]\n",
      "epoch:21 step:20275 [D loss: 0.649527, acc.: 69.53%] [G loss: 1.325282]\n",
      "epoch:21 step:20276 [D loss: 0.685348, acc.: 55.47%] [G loss: 1.452363]\n",
      "epoch:21 step:20277 [D loss: 0.452093, acc.: 84.38%] [G loss: 1.354279]\n",
      "epoch:21 step:20278 [D loss: 0.564035, acc.: 70.31%] [G loss: 1.206850]\n",
      "epoch:21 step:20279 [D loss: 0.585653, acc.: 72.66%] [G loss: 1.370215]\n",
      "epoch:21 step:20280 [D loss: 0.665957, acc.: 59.38%] [G loss: 1.206220]\n",
      "epoch:21 step:20281 [D loss: 0.385686, acc.: 78.91%] [G loss: 1.267363]\n",
      "epoch:21 step:20282 [D loss: 0.564880, acc.: 70.31%] [G loss: 1.279268]\n",
      "epoch:21 step:20283 [D loss: 0.609478, acc.: 68.75%] [G loss: 1.353199]\n",
      "epoch:21 step:20284 [D loss: 0.609544, acc.: 67.19%] [G loss: 1.026003]\n",
      "epoch:21 step:20285 [D loss: 0.561418, acc.: 71.09%] [G loss: 0.985702]\n",
      "epoch:21 step:20286 [D loss: 0.407840, acc.: 89.06%] [G loss: 1.076504]\n",
      "epoch:21 step:20287 [D loss: 0.638381, acc.: 60.16%] [G loss: 1.081181]\n",
      "epoch:21 step:20288 [D loss: 0.402945, acc.: 86.72%] [G loss: 0.883829]\n",
      "epoch:21 step:20289 [D loss: 0.605455, acc.: 58.59%] [G loss: 1.120023]\n",
      "epoch:21 step:20290 [D loss: 1.161701, acc.: 25.00%] [G loss: 1.178514]\n",
      "epoch:21 step:20291 [D loss: 0.769594, acc.: 46.09%] [G loss: 1.067438]\n",
      "epoch:21 step:20292 [D loss: 0.629277, acc.: 66.41%] [G loss: 1.088362]\n",
      "epoch:21 step:20293 [D loss: 0.534943, acc.: 78.12%] [G loss: 0.886797]\n",
      "epoch:21 step:20294 [D loss: 0.546723, acc.: 74.22%] [G loss: 1.102091]\n",
      "epoch:21 step:20295 [D loss: 0.650356, acc.: 61.72%] [G loss: 0.999821]\n",
      "epoch:21 step:20296 [D loss: 0.878734, acc.: 46.09%] [G loss: 0.987442]\n",
      "epoch:21 step:20297 [D loss: 0.590936, acc.: 69.53%] [G loss: 0.963940]\n",
      "epoch:21 step:20298 [D loss: 0.663871, acc.: 59.38%] [G loss: 1.071916]\n",
      "epoch:21 step:20299 [D loss: 0.606648, acc.: 72.66%] [G loss: 1.072418]\n",
      "epoch:21 step:20300 [D loss: 0.533363, acc.: 78.91%] [G loss: 1.083570]\n",
      "epoch:21 step:20301 [D loss: 0.503379, acc.: 78.12%] [G loss: 1.102951]\n",
      "epoch:21 step:20302 [D loss: 0.727856, acc.: 53.91%] [G loss: 1.114933]\n",
      "epoch:21 step:20303 [D loss: 0.563815, acc.: 73.44%] [G loss: 0.901532]\n",
      "epoch:21 step:20304 [D loss: 0.641809, acc.: 61.72%] [G loss: 1.083387]\n",
      "epoch:21 step:20305 [D loss: 0.728999, acc.: 53.12%] [G loss: 1.041629]\n",
      "epoch:21 step:20306 [D loss: 0.539991, acc.: 70.31%] [G loss: 0.909781]\n",
      "epoch:21 step:20307 [D loss: 0.421908, acc.: 86.72%] [G loss: 0.967142]\n",
      "epoch:21 step:20308 [D loss: 0.787943, acc.: 45.31%] [G loss: 0.829409]\n",
      "epoch:21 step:20309 [D loss: 0.410541, acc.: 82.03%] [G loss: 0.989459]\n",
      "epoch:21 step:20310 [D loss: 0.290407, acc.: 93.75%] [G loss: 0.907758]\n",
      "epoch:21 step:20311 [D loss: 0.339553, acc.: 90.62%] [G loss: 1.008864]\n",
      "epoch:21 step:20312 [D loss: 0.396140, acc.: 85.16%] [G loss: 1.234470]\n",
      "epoch:21 step:20313 [D loss: 0.547891, acc.: 72.66%] [G loss: 1.141137]\n",
      "epoch:21 step:20314 [D loss: 0.685800, acc.: 60.16%] [G loss: 1.446103]\n",
      "epoch:21 step:20315 [D loss: 0.783850, acc.: 46.88%] [G loss: 0.947332]\n",
      "epoch:21 step:20316 [D loss: 0.991503, acc.: 20.31%] [G loss: 0.929500]\n",
      "epoch:21 step:20317 [D loss: 0.836631, acc.: 49.22%] [G loss: 0.986116]\n",
      "epoch:21 step:20318 [D loss: 0.466932, acc.: 76.56%] [G loss: 0.976036]\n",
      "epoch:21 step:20319 [D loss: 0.991438, acc.: 21.09%] [G loss: 0.990540]\n",
      "epoch:21 step:20320 [D loss: 0.682898, acc.: 57.03%] [G loss: 1.162130]\n",
      "epoch:21 step:20321 [D loss: 0.357179, acc.: 91.41%] [G loss: 0.932277]\n",
      "epoch:21 step:20322 [D loss: 0.402934, acc.: 90.62%] [G loss: 1.067485]\n",
      "epoch:21 step:20323 [D loss: 0.506120, acc.: 69.53%] [G loss: 0.903927]\n",
      "epoch:21 step:20324 [D loss: 0.455293, acc.: 80.47%] [G loss: 0.950178]\n",
      "epoch:21 step:20325 [D loss: 0.356923, acc.: 94.53%] [G loss: 1.326164]\n",
      "epoch:21 step:20326 [D loss: 0.468391, acc.: 86.72%] [G loss: 1.324054]\n",
      "epoch:21 step:20327 [D loss: 0.397371, acc.: 82.81%] [G loss: 1.396119]\n",
      "epoch:21 step:20328 [D loss: 0.566973, acc.: 65.62%] [G loss: 1.273484]\n",
      "epoch:21 step:20329 [D loss: 0.772639, acc.: 46.09%] [G loss: 1.126146]\n",
      "epoch:21 step:20330 [D loss: 0.825322, acc.: 43.75%] [G loss: 1.093506]\n",
      "epoch:21 step:20331 [D loss: 0.860170, acc.: 28.91%] [G loss: 1.229371]\n",
      "epoch:21 step:20332 [D loss: 0.644067, acc.: 61.72%] [G loss: 1.004480]\n",
      "epoch:21 step:20333 [D loss: 0.714078, acc.: 60.94%] [G loss: 1.057432]\n",
      "epoch:21 step:20334 [D loss: 0.814206, acc.: 36.72%] [G loss: 0.909405]\n",
      "epoch:21 step:20335 [D loss: 0.808693, acc.: 42.19%] [G loss: 0.972654]\n",
      "epoch:21 step:20336 [D loss: 0.523761, acc.: 74.22%] [G loss: 0.822240]\n",
      "epoch:21 step:20337 [D loss: 0.569851, acc.: 74.22%] [G loss: 1.277357]\n",
      "epoch:21 step:20338 [D loss: 0.632914, acc.: 63.28%] [G loss: 1.255619]\n",
      "epoch:21 step:20339 [D loss: 0.804478, acc.: 39.06%] [G loss: 0.836453]\n",
      "epoch:21 step:20340 [D loss: 0.497239, acc.: 69.53%] [G loss: 1.206774]\n",
      "epoch:21 step:20341 [D loss: 0.420195, acc.: 79.69%] [G loss: 1.514308]\n",
      "epoch:21 step:20342 [D loss: 0.182002, acc.: 100.00%] [G loss: 1.487498]\n",
      "epoch:21 step:20343 [D loss: 0.724845, acc.: 50.78%] [G loss: 1.509635]\n",
      "epoch:21 step:20344 [D loss: 0.672449, acc.: 57.03%] [G loss: 1.354866]\n",
      "epoch:21 step:20345 [D loss: 0.734879, acc.: 55.47%] [G loss: 1.174234]\n",
      "epoch:21 step:20346 [D loss: 0.666350, acc.: 51.56%] [G loss: 1.188263]\n",
      "epoch:21 step:20347 [D loss: 0.718454, acc.: 47.66%] [G loss: 1.347654]\n",
      "epoch:21 step:20348 [D loss: 0.595901, acc.: 68.75%] [G loss: 1.305546]\n",
      "epoch:21 step:20349 [D loss: 0.663071, acc.: 58.59%] [G loss: 1.115555]\n",
      "epoch:21 step:20350 [D loss: 0.602027, acc.: 68.75%] [G loss: 1.174164]\n",
      "epoch:21 step:20351 [D loss: 0.552791, acc.: 70.31%] [G loss: 1.111898]\n",
      "epoch:21 step:20352 [D loss: 0.738522, acc.: 58.59%] [G loss: 1.172698]\n",
      "epoch:21 step:20353 [D loss: 0.921758, acc.: 49.22%] [G loss: 1.355604]\n",
      "epoch:21 step:20354 [D loss: 0.717861, acc.: 54.69%] [G loss: 1.237158]\n",
      "epoch:21 step:20355 [D loss: 0.748333, acc.: 53.91%] [G loss: 0.777231]\n",
      "epoch:21 step:20356 [D loss: 0.675136, acc.: 56.25%] [G loss: 0.917381]\n",
      "epoch:21 step:20357 [D loss: 0.601086, acc.: 65.62%] [G loss: 0.741891]\n",
      "epoch:21 step:20358 [D loss: 0.788414, acc.: 51.56%] [G loss: 0.979530]\n",
      "epoch:21 step:20359 [D loss: 0.495066, acc.: 79.69%] [G loss: 0.783008]\n",
      "epoch:21 step:20360 [D loss: 0.556745, acc.: 71.09%] [G loss: 1.092074]\n",
      "epoch:21 step:20361 [D loss: 0.521930, acc.: 68.75%] [G loss: 0.769001]\n",
      "epoch:21 step:20362 [D loss: 0.466110, acc.: 85.16%] [G loss: 0.755061]\n",
      "epoch:21 step:20363 [D loss: 0.636048, acc.: 57.81%] [G loss: 1.016191]\n",
      "epoch:21 step:20364 [D loss: 0.474409, acc.: 82.81%] [G loss: 0.694607]\n",
      "epoch:21 step:20365 [D loss: 0.661965, acc.: 57.03%] [G loss: 1.142236]\n",
      "epoch:21 step:20366 [D loss: 0.913435, acc.: 37.50%] [G loss: 0.832146]\n",
      "epoch:21 step:20367 [D loss: 0.910158, acc.: 28.12%] [G loss: 0.897362]\n",
      "epoch:21 step:20368 [D loss: 0.742158, acc.: 52.34%] [G loss: 0.911639]\n",
      "epoch:21 step:20369 [D loss: 0.691149, acc.: 58.59%] [G loss: 0.897179]\n",
      "epoch:21 step:20370 [D loss: 0.893263, acc.: 30.47%] [G loss: 0.825886]\n",
      "epoch:21 step:20371 [D loss: 0.621385, acc.: 65.62%] [G loss: 0.960003]\n",
      "epoch:21 step:20372 [D loss: 0.725850, acc.: 50.78%] [G loss: 0.892114]\n",
      "epoch:21 step:20373 [D loss: 0.362871, acc.: 78.91%] [G loss: 0.863177]\n",
      "epoch:21 step:20374 [D loss: 0.286916, acc.: 94.53%] [G loss: 0.937158]\n",
      "epoch:21 step:20375 [D loss: 0.335020, acc.: 92.19%] [G loss: 0.999684]\n",
      "epoch:21 step:20376 [D loss: 0.427754, acc.: 94.53%] [G loss: 0.916654]\n",
      "epoch:21 step:20377 [D loss: 0.268000, acc.: 92.97%] [G loss: 1.137521]\n",
      "epoch:21 step:20378 [D loss: 0.281765, acc.: 93.75%] [G loss: 1.217844]\n",
      "epoch:21 step:20379 [D loss: 0.236242, acc.: 99.22%] [G loss: 1.444458]\n",
      "epoch:21 step:20380 [D loss: 0.610310, acc.: 60.94%] [G loss: 1.367306]\n",
      "epoch:21 step:20381 [D loss: 0.382274, acc.: 89.84%] [G loss: 1.147129]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20382 [D loss: 0.635740, acc.: 64.84%] [G loss: 1.099437]\n",
      "epoch:21 step:20383 [D loss: 0.254011, acc.: 96.88%] [G loss: 1.315636]\n",
      "epoch:21 step:20384 [D loss: 0.280101, acc.: 89.06%] [G loss: 1.246662]\n",
      "epoch:21 step:20385 [D loss: 0.303887, acc.: 83.59%] [G loss: 1.404588]\n",
      "epoch:21 step:20386 [D loss: 0.159992, acc.: 99.22%] [G loss: 1.460502]\n",
      "epoch:21 step:20387 [D loss: 0.778076, acc.: 52.34%] [G loss: 1.381820]\n",
      "epoch:21 step:20388 [D loss: 0.666745, acc.: 60.16%] [G loss: 1.347959]\n",
      "epoch:21 step:20389 [D loss: 0.715917, acc.: 50.00%] [G loss: 0.991540]\n",
      "epoch:21 step:20390 [D loss: 0.185936, acc.: 99.22%] [G loss: 1.403628]\n",
      "epoch:21 step:20391 [D loss: 0.251587, acc.: 95.31%] [G loss: 1.265628]\n",
      "epoch:21 step:20392 [D loss: 0.801349, acc.: 51.56%] [G loss: 1.340219]\n",
      "epoch:21 step:20393 [D loss: 0.804997, acc.: 51.56%] [G loss: 1.149709]\n",
      "epoch:21 step:20394 [D loss: 0.661740, acc.: 57.81%] [G loss: 1.184767]\n",
      "epoch:21 step:20395 [D loss: 0.763395, acc.: 42.97%] [G loss: 1.002993]\n",
      "epoch:21 step:20396 [D loss: 0.685088, acc.: 57.03%] [G loss: 1.207850]\n",
      "epoch:21 step:20397 [D loss: 0.629014, acc.: 63.28%] [G loss: 0.976952]\n",
      "epoch:21 step:20398 [D loss: 0.672285, acc.: 57.03%] [G loss: 0.978905]\n",
      "epoch:21 step:20399 [D loss: 0.467693, acc.: 85.94%] [G loss: 1.068889]\n",
      "epoch:21 step:20400 [D loss: 0.425225, acc.: 82.81%] [G loss: 1.038365]\n",
      "##############\n",
      "[3.78324424 2.22496221 6.47490949 6.24921928 4.59920205 5.76612501\n",
      " 5.38560699 5.56750655 5.92368882 4.91370492]\n",
      "##########\n",
      "epoch:21 step:20401 [D loss: 0.714620, acc.: 48.44%] [G loss: 0.983986]\n",
      "epoch:21 step:20402 [D loss: 0.676888, acc.: 55.47%] [G loss: 0.970290]\n",
      "epoch:21 step:20403 [D loss: 0.675011, acc.: 56.25%] [G loss: 0.857606]\n",
      "epoch:21 step:20404 [D loss: 0.280462, acc.: 92.97%] [G loss: 0.976905]\n",
      "epoch:21 step:20405 [D loss: 0.213504, acc.: 97.66%] [G loss: 1.271335]\n",
      "epoch:21 step:20406 [D loss: 0.198971, acc.: 98.44%] [G loss: 1.244440]\n",
      "epoch:21 step:20407 [D loss: 0.188889, acc.: 98.44%] [G loss: 1.348295]\n",
      "epoch:21 step:20408 [D loss: 0.184240, acc.: 99.22%] [G loss: 1.350694]\n",
      "epoch:21 step:20409 [D loss: 0.151497, acc.: 100.00%] [G loss: 1.458262]\n",
      "epoch:21 step:20410 [D loss: 0.178404, acc.: 95.31%] [G loss: 1.460755]\n",
      "epoch:21 step:20411 [D loss: 0.752491, acc.: 59.38%] [G loss: 1.271549]\n",
      "epoch:21 step:20412 [D loss: 0.793136, acc.: 50.00%] [G loss: 1.402677]\n",
      "epoch:21 step:20413 [D loss: 0.798905, acc.: 50.78%] [G loss: 1.271259]\n",
      "epoch:21 step:20414 [D loss: 0.736229, acc.: 55.47%] [G loss: 1.163374]\n",
      "epoch:21 step:20415 [D loss: 0.641232, acc.: 62.50%] [G loss: 1.077411]\n",
      "epoch:21 step:20416 [D loss: 0.236873, acc.: 95.31%] [G loss: 0.778548]\n",
      "epoch:21 step:20417 [D loss: 0.486729, acc.: 82.81%] [G loss: 1.179937]\n",
      "epoch:21 step:20418 [D loss: 0.690632, acc.: 59.38%] [G loss: 1.083232]\n",
      "epoch:21 step:20419 [D loss: 0.703063, acc.: 55.47%] [G loss: 0.774521]\n",
      "epoch:21 step:20420 [D loss: 0.718843, acc.: 47.66%] [G loss: 1.072044]\n",
      "epoch:21 step:20421 [D loss: 0.673068, acc.: 60.94%] [G loss: 1.063497]\n",
      "epoch:21 step:20422 [D loss: 0.274385, acc.: 95.31%] [G loss: 0.827392]\n",
      "epoch:21 step:20423 [D loss: 0.294171, acc.: 91.41%] [G loss: 1.257818]\n",
      "epoch:21 step:20424 [D loss: 0.381614, acc.: 90.62%] [G loss: 1.056138]\n",
      "epoch:21 step:20425 [D loss: 0.725614, acc.: 56.25%] [G loss: 1.223314]\n",
      "epoch:21 step:20426 [D loss: 0.936266, acc.: 25.00%] [G loss: 1.181278]\n",
      "epoch:21 step:20427 [D loss: 0.873853, acc.: 31.25%] [G loss: 0.711869]\n",
      "epoch:21 step:20428 [D loss: 0.610214, acc.: 69.53%] [G loss: 1.230338]\n",
      "epoch:21 step:20429 [D loss: 0.564243, acc.: 76.56%] [G loss: 0.376006]\n",
      "epoch:21 step:20430 [D loss: 0.281830, acc.: 93.75%] [G loss: 0.960143]\n",
      "epoch:21 step:20431 [D loss: 0.277279, acc.: 91.41%] [G loss: 1.079413]\n",
      "epoch:21 step:20432 [D loss: 0.340591, acc.: 82.03%] [G loss: 1.151798]\n",
      "epoch:21 step:20433 [D loss: 0.210178, acc.: 96.88%] [G loss: 1.549997]\n",
      "epoch:21 step:20434 [D loss: 0.505671, acc.: 71.88%] [G loss: 1.095423]\n",
      "epoch:21 step:20435 [D loss: 1.029923, acc.: 35.16%] [G loss: 1.308120]\n",
      "epoch:21 step:20436 [D loss: 0.837969, acc.: 50.78%] [G loss: 1.402331]\n",
      "epoch:21 step:20437 [D loss: 0.746841, acc.: 53.91%] [G loss: 0.755855]\n",
      "epoch:21 step:20438 [D loss: 0.804431, acc.: 49.22%] [G loss: 1.357339]\n",
      "epoch:21 step:20439 [D loss: 0.645750, acc.: 62.50%] [G loss: 0.886069]\n",
      "epoch:21 step:20440 [D loss: 0.994485, acc.: 23.44%] [G loss: 1.237620]\n",
      "epoch:21 step:20441 [D loss: 0.286926, acc.: 96.09%] [G loss: 1.237067]\n",
      "epoch:21 step:20442 [D loss: 1.314838, acc.: 7.81%] [G loss: 1.303540]\n",
      "epoch:21 step:20443 [D loss: 0.823991, acc.: 44.53%] [G loss: 1.092863]\n",
      "epoch:21 step:20444 [D loss: 0.649495, acc.: 53.91%] [G loss: 1.455382]\n",
      "epoch:21 step:20445 [D loss: 0.433664, acc.: 85.94%] [G loss: 1.353557]\n",
      "epoch:21 step:20446 [D loss: 0.489860, acc.: 82.81%] [G loss: 1.325470]\n",
      "epoch:21 step:20447 [D loss: 0.610367, acc.: 60.16%] [G loss: 1.502435]\n",
      "epoch:21 step:20448 [D loss: 0.754163, acc.: 50.00%] [G loss: 1.120700]\n",
      "epoch:21 step:20449 [D loss: 0.705454, acc.: 54.69%] [G loss: 1.237549]\n",
      "epoch:21 step:20450 [D loss: 0.667926, acc.: 58.59%] [G loss: 1.320541]\n",
      "epoch:21 step:20451 [D loss: 0.317458, acc.: 99.22%] [G loss: 1.271371]\n",
      "epoch:21 step:20452 [D loss: 0.339483, acc.: 97.66%] [G loss: 1.193382]\n",
      "epoch:21 step:20453 [D loss: 0.683023, acc.: 54.69%] [G loss: 1.056987]\n",
      "epoch:21 step:20454 [D loss: 0.474454, acc.: 91.41%] [G loss: 0.999451]\n",
      "epoch:21 step:20455 [D loss: 0.602138, acc.: 65.62%] [G loss: 1.270001]\n",
      "epoch:21 step:20456 [D loss: 0.730566, acc.: 50.78%] [G loss: 0.956926]\n",
      "epoch:21 step:20457 [D loss: 0.837489, acc.: 42.19%] [G loss: 1.019170]\n",
      "epoch:21 step:20458 [D loss: 0.581373, acc.: 74.22%] [G loss: 0.880492]\n",
      "epoch:21 step:20459 [D loss: 0.537726, acc.: 78.91%] [G loss: 1.016270]\n",
      "epoch:21 step:20460 [D loss: 0.615180, acc.: 75.78%] [G loss: 0.922214]\n",
      "epoch:21 step:20461 [D loss: 0.669233, acc.: 63.28%] [G loss: 0.840750]\n",
      "epoch:21 step:20462 [D loss: 0.732973, acc.: 45.31%] [G loss: 0.849151]\n",
      "epoch:21 step:20463 [D loss: 0.509184, acc.: 75.00%] [G loss: 0.502388]\n",
      "epoch:21 step:20464 [D loss: 0.694983, acc.: 51.56%] [G loss: 0.934408]\n",
      "epoch:21 step:20465 [D loss: 0.737624, acc.: 51.56%] [G loss: 0.936586]\n",
      "epoch:21 step:20466 [D loss: 0.720917, acc.: 47.66%] [G loss: 0.886544]\n",
      "epoch:21 step:20467 [D loss: 0.684626, acc.: 57.81%] [G loss: 0.983185]\n",
      "epoch:21 step:20468 [D loss: 0.511696, acc.: 77.34%] [G loss: 0.899828]\n",
      "epoch:21 step:20469 [D loss: 0.417481, acc.: 92.19%] [G loss: 0.854344]\n",
      "epoch:21 step:20470 [D loss: 0.567897, acc.: 71.88%] [G loss: 0.903330]\n",
      "epoch:21 step:20471 [D loss: 0.505302, acc.: 82.81%] [G loss: 1.007884]\n",
      "epoch:21 step:20472 [D loss: 0.657407, acc.: 66.41%] [G loss: 0.970623]\n",
      "epoch:21 step:20473 [D loss: 0.485511, acc.: 87.50%] [G loss: 0.689156]\n",
      "epoch:21 step:20474 [D loss: 0.642705, acc.: 63.28%] [G loss: 1.140625]\n",
      "epoch:21 step:20475 [D loss: 0.676230, acc.: 60.94%] [G loss: 0.965908]\n",
      "epoch:21 step:20476 [D loss: 0.677553, acc.: 59.38%] [G loss: 0.838782]\n",
      "epoch:21 step:20477 [D loss: 0.500394, acc.: 74.22%] [G loss: 0.916484]\n",
      "epoch:21 step:20478 [D loss: 0.710133, acc.: 59.38%] [G loss: 1.055650]\n",
      "epoch:21 step:20479 [D loss: 0.330476, acc.: 91.41%] [G loss: 1.107481]\n",
      "epoch:21 step:20480 [D loss: 0.530605, acc.: 78.12%] [G loss: 1.106750]\n",
      "epoch:21 step:20481 [D loss: 0.340517, acc.: 94.53%] [G loss: 0.543096]\n",
      "epoch:21 step:20482 [D loss: 0.322381, acc.: 89.84%] [G loss: 1.104932]\n",
      "epoch:21 step:20483 [D loss: 0.640180, acc.: 59.38%] [G loss: 1.469086]\n",
      "epoch:21 step:20484 [D loss: 0.705474, acc.: 50.78%] [G loss: 1.340902]\n",
      "epoch:21 step:20485 [D loss: 0.392783, acc.: 91.41%] [G loss: 1.295156]\n",
      "epoch:21 step:20486 [D loss: 0.347198, acc.: 96.88%] [G loss: 1.415503]\n",
      "epoch:21 step:20487 [D loss: 0.493011, acc.: 84.38%] [G loss: 1.426205]\n",
      "epoch:21 step:20488 [D loss: 0.800505, acc.: 49.22%] [G loss: 1.086844]\n",
      "epoch:21 step:20489 [D loss: 0.764006, acc.: 57.81%] [G loss: 1.164655]\n",
      "epoch:21 step:20490 [D loss: 0.761479, acc.: 50.78%] [G loss: 0.981210]\n",
      "epoch:21 step:20491 [D loss: 0.716716, acc.: 50.00%] [G loss: 0.879634]\n",
      "epoch:21 step:20492 [D loss: 0.353348, acc.: 79.69%] [G loss: 0.939678]\n",
      "epoch:21 step:20493 [D loss: 0.416695, acc.: 92.97%] [G loss: 1.168833]\n",
      "epoch:21 step:20494 [D loss: 0.742325, acc.: 50.00%] [G loss: 0.931113]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20495 [D loss: 0.751560, acc.: 46.09%] [G loss: 1.064952]\n",
      "epoch:21 step:20496 [D loss: 0.574967, acc.: 71.88%] [G loss: 1.038743]\n",
      "epoch:21 step:20497 [D loss: 0.780463, acc.: 44.53%] [G loss: 1.018718]\n",
      "epoch:21 step:20498 [D loss: 0.629416, acc.: 67.97%] [G loss: 1.024782]\n",
      "epoch:21 step:20499 [D loss: 0.623648, acc.: 62.50%] [G loss: 0.719975]\n",
      "epoch:21 step:20500 [D loss: 0.651028, acc.: 62.50%] [G loss: 0.898826]\n",
      "epoch:21 step:20501 [D loss: 0.529878, acc.: 80.47%] [G loss: 0.931787]\n",
      "epoch:21 step:20502 [D loss: 0.462644, acc.: 85.16%] [G loss: 0.753819]\n",
      "epoch:21 step:20503 [D loss: 0.674643, acc.: 60.94%] [G loss: 0.993320]\n",
      "epoch:21 step:20504 [D loss: 0.696811, acc.: 54.69%] [G loss: 0.878157]\n",
      "epoch:21 step:20505 [D loss: 0.679073, acc.: 58.59%] [G loss: 0.880657]\n",
      "epoch:21 step:20506 [D loss: 0.719417, acc.: 50.78%] [G loss: 0.935400]\n",
      "epoch:21 step:20507 [D loss: 0.465477, acc.: 78.91%] [G loss: 0.884539]\n",
      "epoch:21 step:20508 [D loss: 0.421995, acc.: 79.69%] [G loss: 0.867711]\n",
      "epoch:21 step:20509 [D loss: 0.348068, acc.: 86.72%] [G loss: 1.173164]\n",
      "epoch:21 step:20510 [D loss: 0.499083, acc.: 78.12%] [G loss: 1.041823]\n",
      "epoch:21 step:20511 [D loss: 0.728385, acc.: 49.22%] [G loss: 1.085994]\n",
      "epoch:21 step:20512 [D loss: 0.856505, acc.: 39.06%] [G loss: 0.779637]\n",
      "epoch:21 step:20513 [D loss: 0.938362, acc.: 19.53%] [G loss: 0.861179]\n",
      "epoch:21 step:20514 [D loss: 0.776643, acc.: 40.62%] [G loss: 1.072111]\n",
      "epoch:21 step:20515 [D loss: 0.608175, acc.: 65.62%] [G loss: 1.022256]\n",
      "epoch:21 step:20516 [D loss: 0.667158, acc.: 53.91%] [G loss: 0.822629]\n",
      "epoch:21 step:20517 [D loss: 0.702122, acc.: 50.78%] [G loss: 1.082111]\n",
      "epoch:21 step:20518 [D loss: 0.463564, acc.: 84.38%] [G loss: 0.845996]\n",
      "epoch:21 step:20519 [D loss: 0.502417, acc.: 82.03%] [G loss: 0.846689]\n",
      "epoch:21 step:20520 [D loss: 0.551256, acc.: 79.69%] [G loss: 0.876355]\n",
      "epoch:21 step:20521 [D loss: 0.487136, acc.: 82.81%] [G loss: 0.832896]\n",
      "epoch:21 step:20522 [D loss: 0.360645, acc.: 89.84%] [G loss: 1.000555]\n",
      "epoch:21 step:20523 [D loss: 0.788423, acc.: 48.44%] [G loss: 0.995088]\n",
      "epoch:21 step:20524 [D loss: 0.447020, acc.: 74.22%] [G loss: 1.082890]\n",
      "epoch:21 step:20525 [D loss: 0.378373, acc.: 88.28%] [G loss: 1.173874]\n",
      "epoch:21 step:20526 [D loss: 0.586999, acc.: 65.62%] [G loss: 1.349064]\n",
      "epoch:21 step:20527 [D loss: 0.432048, acc.: 89.84%] [G loss: 0.748188]\n",
      "epoch:21 step:20528 [D loss: 0.270014, acc.: 85.16%] [G loss: 1.131786]\n",
      "epoch:21 step:20529 [D loss: 0.256966, acc.: 94.53%] [G loss: 1.147135]\n",
      "epoch:21 step:20530 [D loss: 0.180879, acc.: 100.00%] [G loss: 1.317962]\n",
      "epoch:21 step:20531 [D loss: 0.213281, acc.: 97.66%] [G loss: 1.498517]\n",
      "epoch:21 step:20532 [D loss: 0.396732, acc.: 92.19%] [G loss: 1.349641]\n",
      "epoch:21 step:20533 [D loss: 0.635234, acc.: 58.59%] [G loss: 1.321983]\n",
      "epoch:21 step:20534 [D loss: 0.246596, acc.: 96.88%] [G loss: 1.333637]\n",
      "epoch:21 step:20535 [D loss: 0.578360, acc.: 70.31%] [G loss: 1.321661]\n",
      "epoch:21 step:20536 [D loss: 0.503387, acc.: 77.34%] [G loss: 1.274729]\n",
      "epoch:21 step:20537 [D loss: 0.516335, acc.: 78.12%] [G loss: 1.099276]\n",
      "epoch:21 step:20538 [D loss: 0.420917, acc.: 89.84%] [G loss: 1.001798]\n",
      "epoch:21 step:20539 [D loss: 0.803779, acc.: 39.06%] [G loss: 1.238690]\n",
      "epoch:21 step:20540 [D loss: 0.641814, acc.: 60.16%] [G loss: 1.178790]\n",
      "epoch:21 step:20541 [D loss: 0.770312, acc.: 51.56%] [G loss: 1.148918]\n",
      "epoch:21 step:20542 [D loss: 0.291039, acc.: 89.84%] [G loss: 1.102213]\n",
      "epoch:21 step:20543 [D loss: 0.382057, acc.: 81.25%] [G loss: 1.222780]\n",
      "epoch:21 step:20544 [D loss: 0.477570, acc.: 69.53%] [G loss: 1.477346]\n",
      "epoch:21 step:20545 [D loss: 0.607890, acc.: 68.75%] [G loss: 1.537624]\n",
      "epoch:21 step:20546 [D loss: 0.583694, acc.: 63.28%] [G loss: 1.365478]\n",
      "epoch:21 step:20547 [D loss: 0.723169, acc.: 53.91%] [G loss: 1.179274]\n",
      "epoch:21 step:20548 [D loss: 0.587641, acc.: 64.84%] [G loss: 1.309714]\n",
      "epoch:21 step:20549 [D loss: 0.298550, acc.: 91.41%] [G loss: 1.314802]\n",
      "epoch:21 step:20550 [D loss: 0.404952, acc.: 91.41%] [G loss: 1.524336]\n",
      "epoch:21 step:20551 [D loss: 0.254079, acc.: 96.88%] [G loss: 1.102173]\n",
      "epoch:21 step:20552 [D loss: 0.346592, acc.: 86.72%] [G loss: 1.754376]\n",
      "epoch:21 step:20553 [D loss: 0.617210, acc.: 64.84%] [G loss: 1.347029]\n",
      "epoch:21 step:20554 [D loss: 0.739479, acc.: 52.34%] [G loss: 0.925963]\n",
      "epoch:21 step:20555 [D loss: 0.908630, acc.: 46.09%] [G loss: 1.184728]\n",
      "epoch:21 step:20556 [D loss: 0.584132, acc.: 74.22%] [G loss: 0.430331]\n",
      "epoch:21 step:20557 [D loss: 0.436142, acc.: 86.72%] [G loss: 0.614409]\n",
      "epoch:21 step:20558 [D loss: 0.543604, acc.: 75.78%] [G loss: 0.593176]\n",
      "epoch:21 step:20559 [D loss: 0.982022, acc.: 50.78%] [G loss: 0.945697]\n",
      "epoch:21 step:20560 [D loss: 0.531468, acc.: 64.84%] [G loss: 1.637424]\n",
      "epoch:21 step:20561 [D loss: 0.324575, acc.: 85.94%] [G loss: 1.942690]\n",
      "epoch:21 step:20562 [D loss: 0.123183, acc.: 99.22%] [G loss: 1.779540]\n",
      "epoch:21 step:20563 [D loss: 0.123354, acc.: 99.22%] [G loss: 2.251302]\n",
      "epoch:21 step:20564 [D loss: 0.136733, acc.: 100.00%] [G loss: 1.738309]\n",
      "epoch:21 step:20565 [D loss: 1.014317, acc.: 50.00%] [G loss: 0.489764]\n",
      "epoch:21 step:20566 [D loss: 0.318884, acc.: 83.59%] [G loss: 2.039940]\n",
      "epoch:21 step:20567 [D loss: 0.453147, acc.: 85.94%] [G loss: 1.427736]\n",
      "epoch:21 step:20568 [D loss: 1.081190, acc.: 47.66%] [G loss: 1.539887]\n",
      "epoch:21 step:20569 [D loss: 1.060736, acc.: 44.53%] [G loss: 1.357327]\n",
      "epoch:21 step:20570 [D loss: 1.150036, acc.: 29.69%] [G loss: 1.444043]\n",
      "epoch:21 step:20571 [D loss: 0.958698, acc.: 24.22%] [G loss: 1.454667]\n",
      "epoch:21 step:20572 [D loss: 0.835931, acc.: 40.62%] [G loss: 1.436958]\n",
      "epoch:21 step:20573 [D loss: 0.737063, acc.: 53.91%] [G loss: 1.285106]\n",
      "epoch:21 step:20574 [D loss: 0.635030, acc.: 59.38%] [G loss: 1.486081]\n",
      "epoch:21 step:20575 [D loss: 0.433121, acc.: 85.16%] [G loss: 1.280515]\n",
      "epoch:21 step:20576 [D loss: 0.218720, acc.: 96.88%] [G loss: 1.498562]\n",
      "epoch:21 step:20577 [D loss: 0.242643, acc.: 99.22%] [G loss: 1.478981]\n",
      "epoch:21 step:20578 [D loss: 0.505244, acc.: 68.75%] [G loss: 1.662578]\n",
      "epoch:21 step:20579 [D loss: 0.595740, acc.: 61.72%] [G loss: 1.502930]\n",
      "epoch:21 step:20580 [D loss: 0.523559, acc.: 70.31%] [G loss: 1.550296]\n",
      "epoch:21 step:20581 [D loss: 0.899211, acc.: 46.09%] [G loss: 1.229099]\n",
      "epoch:21 step:20582 [D loss: 0.800889, acc.: 43.75%] [G loss: 0.922680]\n",
      "epoch:21 step:20583 [D loss: 0.655657, acc.: 65.62%] [G loss: 0.925229]\n",
      "epoch:21 step:20584 [D loss: 0.709176, acc.: 54.69%] [G loss: 1.081578]\n",
      "epoch:21 step:20585 [D loss: 0.575047, acc.: 68.75%] [G loss: 0.835149]\n",
      "epoch:21 step:20586 [D loss: 0.398512, acc.: 95.31%] [G loss: 1.207318]\n",
      "epoch:21 step:20587 [D loss: 0.733324, acc.: 56.25%] [G loss: 0.994232]\n",
      "epoch:21 step:20588 [D loss: 0.313263, acc.: 95.31%] [G loss: 1.069137]\n",
      "epoch:21 step:20589 [D loss: 0.204135, acc.: 98.44%] [G loss: 1.158488]\n",
      "epoch:21 step:20590 [D loss: 0.505031, acc.: 82.03%] [G loss: 1.133341]\n",
      "epoch:21 step:20591 [D loss: 0.692857, acc.: 44.53%] [G loss: 1.033551]\n",
      "epoch:21 step:20592 [D loss: 0.665896, acc.: 58.59%] [G loss: 1.177474]\n",
      "epoch:21 step:20593 [D loss: 0.893756, acc.: 42.19%] [G loss: 0.781294]\n",
      "epoch:21 step:20594 [D loss: 0.752052, acc.: 46.09%] [G loss: 1.043121]\n",
      "epoch:21 step:20595 [D loss: 0.566780, acc.: 72.66%] [G loss: 1.009159]\n",
      "epoch:21 step:20596 [D loss: 0.332942, acc.: 86.72%] [G loss: 0.964013]\n",
      "epoch:21 step:20597 [D loss: 0.589046, acc.: 71.88%] [G loss: 1.021505]\n",
      "epoch:21 step:20598 [D loss: 0.463809, acc.: 84.38%] [G loss: 1.009240]\n",
      "epoch:21 step:20599 [D loss: 0.629218, acc.: 61.72%] [G loss: 0.969376]\n",
      "epoch:21 step:20600 [D loss: 0.484611, acc.: 88.28%] [G loss: 1.063690]\n",
      "##############\n",
      "[3.93254726 2.89286884 6.64558935 6.18327916 4.64808532 6.05846402\n",
      " 5.54149383 5.70598361 5.85032694 4.95765027]\n",
      "##########\n",
      "epoch:21 step:20601 [D loss: 0.349782, acc.: 90.62%] [G loss: 1.152238]\n",
      "epoch:21 step:20602 [D loss: 0.317601, acc.: 96.09%] [G loss: 1.194851]\n",
      "epoch:21 step:20603 [D loss: 0.215721, acc.: 97.66%] [G loss: 1.181883]\n",
      "epoch:21 step:20604 [D loss: 0.200260, acc.: 97.66%] [G loss: 1.103858]\n",
      "epoch:21 step:20605 [D loss: 0.716449, acc.: 57.03%] [G loss: 1.364784]\n",
      "epoch:21 step:20606 [D loss: 0.291273, acc.: 96.88%] [G loss: 1.308147]\n",
      "epoch:21 step:20607 [D loss: 0.604780, acc.: 65.62%] [G loss: 1.061568]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20608 [D loss: 0.600047, acc.: 68.75%] [G loss: 1.035756]\n",
      "epoch:21 step:20609 [D loss: 0.416118, acc.: 83.59%] [G loss: 0.882557]\n",
      "epoch:21 step:20610 [D loss: 0.328060, acc.: 95.31%] [G loss: 1.049663]\n",
      "epoch:21 step:20611 [D loss: 0.216938, acc.: 96.09%] [G loss: 1.305480]\n",
      "epoch:21 step:20612 [D loss: 0.312903, acc.: 97.66%] [G loss: 1.345689]\n",
      "epoch:21 step:20613 [D loss: 0.250203, acc.: 93.75%] [G loss: 1.229894]\n",
      "epoch:21 step:20614 [D loss: 0.193185, acc.: 98.44%] [G loss: 1.252596]\n",
      "epoch:22 step:20615 [D loss: 0.401220, acc.: 89.06%] [G loss: 1.549029]\n",
      "epoch:22 step:20616 [D loss: 0.725511, acc.: 54.69%] [G loss: 1.552049]\n",
      "epoch:22 step:20617 [D loss: 0.535225, acc.: 71.88%] [G loss: 1.154596]\n",
      "epoch:22 step:20618 [D loss: 0.720101, acc.: 53.91%] [G loss: 1.108592]\n",
      "epoch:22 step:20619 [D loss: 0.769527, acc.: 48.44%] [G loss: 1.042548]\n",
      "epoch:22 step:20620 [D loss: 0.530335, acc.: 73.44%] [G loss: 1.066490]\n",
      "epoch:22 step:20621 [D loss: 0.452034, acc.: 79.69%] [G loss: 0.890948]\n",
      "epoch:22 step:20622 [D loss: 0.351786, acc.: 96.88%] [G loss: 0.752366]\n",
      "epoch:22 step:20623 [D loss: 0.418198, acc.: 75.78%] [G loss: 1.271919]\n",
      "epoch:22 step:20624 [D loss: 0.290365, acc.: 87.50%] [G loss: 0.971065]\n",
      "epoch:22 step:20625 [D loss: 0.341394, acc.: 96.09%] [G loss: 0.223528]\n",
      "epoch:22 step:20626 [D loss: 0.310839, acc.: 91.41%] [G loss: 1.140712]\n",
      "epoch:22 step:20627 [D loss: 0.318481, acc.: 89.84%] [G loss: 0.125312]\n",
      "epoch:22 step:20628 [D loss: 0.347014, acc.: 90.62%] [G loss: 0.425261]\n",
      "epoch:22 step:20629 [D loss: 0.459115, acc.: 76.56%] [G loss: 0.982463]\n",
      "epoch:22 step:20630 [D loss: 0.479849, acc.: 85.16%] [G loss: 1.762246]\n",
      "epoch:22 step:20631 [D loss: 0.722498, acc.: 50.00%] [G loss: 1.054586]\n",
      "epoch:22 step:20632 [D loss: 0.660781, acc.: 62.50%] [G loss: 0.905201]\n",
      "epoch:22 step:20633 [D loss: 1.726220, acc.: 6.25%] [G loss: 1.131582]\n",
      "epoch:22 step:20634 [D loss: 1.448701, acc.: 17.97%] [G loss: 2.166014]\n",
      "epoch:22 step:20635 [D loss: 1.082252, acc.: 39.84%] [G loss: 1.790276]\n",
      "epoch:22 step:20636 [D loss: 1.033698, acc.: 42.19%] [G loss: 1.252830]\n",
      "epoch:22 step:20637 [D loss: 0.906714, acc.: 46.88%] [G loss: 1.555877]\n",
      "epoch:22 step:20638 [D loss: 0.722646, acc.: 56.25%] [G loss: 1.010278]\n",
      "epoch:22 step:20639 [D loss: 0.743055, acc.: 50.78%] [G loss: 1.303652]\n",
      "epoch:22 step:20640 [D loss: 1.220143, acc.: 5.47%] [G loss: 1.819554]\n",
      "epoch:22 step:20641 [D loss: 0.348617, acc.: 89.06%] [G loss: 1.754700]\n",
      "epoch:22 step:20642 [D loss: 0.679357, acc.: 53.91%] [G loss: 1.586909]\n",
      "epoch:22 step:20643 [D loss: 0.648375, acc.: 55.47%] [G loss: 1.914994]\n",
      "epoch:22 step:20644 [D loss: 0.659121, acc.: 50.00%] [G loss: 1.483256]\n",
      "epoch:22 step:20645 [D loss: 0.383901, acc.: 90.62%] [G loss: 1.271946]\n",
      "epoch:22 step:20646 [D loss: 0.280864, acc.: 96.88%] [G loss: 1.800594]\n",
      "epoch:22 step:20647 [D loss: 0.271844, acc.: 98.44%] [G loss: 1.812911]\n",
      "epoch:22 step:20648 [D loss: 0.325757, acc.: 95.31%] [G loss: 1.555365]\n",
      "epoch:22 step:20649 [D loss: 0.235684, acc.: 97.66%] [G loss: 2.305126]\n",
      "epoch:22 step:20650 [D loss: 0.164446, acc.: 99.22%] [G loss: 1.662174]\n",
      "epoch:22 step:20651 [D loss: 0.789573, acc.: 54.69%] [G loss: 1.383935]\n",
      "epoch:22 step:20652 [D loss: 0.891774, acc.: 50.00%] [G loss: 1.228771]\n",
      "epoch:22 step:20653 [D loss: 0.865536, acc.: 50.78%] [G loss: 1.067129]\n",
      "epoch:22 step:20654 [D loss: 0.689881, acc.: 59.38%] [G loss: 0.976770]\n",
      "epoch:22 step:20655 [D loss: 0.545613, acc.: 75.78%] [G loss: 0.900141]\n",
      "epoch:22 step:20656 [D loss: 0.475910, acc.: 85.16%] [G loss: 1.011610]\n",
      "epoch:22 step:20657 [D loss: 0.452586, acc.: 89.06%] [G loss: 1.148909]\n",
      "epoch:22 step:20658 [D loss: 0.478677, acc.: 82.03%] [G loss: 1.035414]\n",
      "epoch:22 step:20659 [D loss: 0.555751, acc.: 78.12%] [G loss: 1.008287]\n",
      "epoch:22 step:20660 [D loss: 0.446173, acc.: 82.03%] [G loss: 1.065416]\n",
      "epoch:22 step:20661 [D loss: 0.695193, acc.: 56.25%] [G loss: 1.104067]\n",
      "epoch:22 step:20662 [D loss: 0.647339, acc.: 64.06%] [G loss: 1.068762]\n",
      "epoch:22 step:20663 [D loss: 0.662888, acc.: 62.50%] [G loss: 1.029495]\n",
      "epoch:22 step:20664 [D loss: 0.501061, acc.: 82.81%] [G loss: 0.884808]\n",
      "epoch:22 step:20665 [D loss: 0.399923, acc.: 89.06%] [G loss: 0.897682]\n",
      "epoch:22 step:20666 [D loss: 0.467922, acc.: 82.81%] [G loss: 0.875064]\n",
      "epoch:22 step:20667 [D loss: 0.517413, acc.: 79.69%] [G loss: 0.861781]\n",
      "epoch:22 step:20668 [D loss: 1.487292, acc.: 35.16%] [G loss: 0.965421]\n",
      "epoch:22 step:20669 [D loss: 0.665796, acc.: 60.16%] [G loss: 1.211479]\n",
      "epoch:22 step:20670 [D loss: 0.768003, acc.: 46.09%] [G loss: 1.064811]\n",
      "epoch:22 step:20671 [D loss: 0.351356, acc.: 93.75%] [G loss: 1.209271]\n",
      "epoch:22 step:20672 [D loss: 0.347143, acc.: 91.41%] [G loss: 1.196185]\n",
      "epoch:22 step:20673 [D loss: 0.431312, acc.: 88.28%] [G loss: 1.304203]\n",
      "epoch:22 step:20674 [D loss: 0.373793, acc.: 92.19%] [G loss: 1.147921]\n",
      "epoch:22 step:20675 [D loss: 0.626881, acc.: 63.28%] [G loss: 0.739846]\n",
      "epoch:22 step:20676 [D loss: 0.579371, acc.: 73.44%] [G loss: 1.026808]\n",
      "epoch:22 step:20677 [D loss: 0.481387, acc.: 85.16%] [G loss: 1.278513]\n",
      "epoch:22 step:20678 [D loss: 0.754209, acc.: 55.47%] [G loss: 1.021980]\n",
      "epoch:22 step:20679 [D loss: 0.763907, acc.: 43.75%] [G loss: 0.825352]\n",
      "epoch:22 step:20680 [D loss: 0.861449, acc.: 44.53%] [G loss: 0.831930]\n",
      "epoch:22 step:20681 [D loss: 0.667418, acc.: 59.38%] [G loss: 0.701339]\n",
      "epoch:22 step:20682 [D loss: 0.764160, acc.: 51.56%] [G loss: 0.967301]\n",
      "epoch:22 step:20683 [D loss: 0.728507, acc.: 54.69%] [G loss: 0.443913]\n",
      "epoch:22 step:20684 [D loss: 0.804561, acc.: 43.75%] [G loss: 0.836663]\n",
      "epoch:22 step:20685 [D loss: 0.462501, acc.: 66.41%] [G loss: 0.728488]\n",
      "epoch:22 step:20686 [D loss: 0.412847, acc.: 82.81%] [G loss: 1.257219]\n",
      "epoch:22 step:20687 [D loss: 0.421825, acc.: 78.12%] [G loss: 1.355354]\n",
      "epoch:22 step:20688 [D loss: 0.805263, acc.: 41.41%] [G loss: 1.365875]\n",
      "epoch:22 step:20689 [D loss: 0.298232, acc.: 85.16%] [G loss: 1.212013]\n",
      "epoch:22 step:20690 [D loss: 0.547289, acc.: 73.44%] [G loss: 1.492130]\n",
      "epoch:22 step:20691 [D loss: 0.293618, acc.: 98.44%] [G loss: 1.453357]\n",
      "epoch:22 step:20692 [D loss: 0.921859, acc.: 50.00%] [G loss: 1.540385]\n",
      "epoch:22 step:20693 [D loss: 0.829585, acc.: 51.56%] [G loss: 1.331680]\n",
      "epoch:22 step:20694 [D loss: 0.856254, acc.: 44.53%] [G loss: 1.332766]\n",
      "epoch:22 step:20695 [D loss: 0.714985, acc.: 51.56%] [G loss: 1.222725]\n",
      "epoch:22 step:20696 [D loss: 0.670006, acc.: 62.50%] [G loss: 1.337211]\n",
      "epoch:22 step:20697 [D loss: 0.606006, acc.: 64.84%] [G loss: 1.124698]\n",
      "epoch:22 step:20698 [D loss: 0.662650, acc.: 60.16%] [G loss: 1.139356]\n",
      "epoch:22 step:20699 [D loss: 0.616286, acc.: 70.31%] [G loss: 1.045999]\n",
      "epoch:22 step:20700 [D loss: 0.689520, acc.: 60.94%] [G loss: 0.997661]\n",
      "epoch:22 step:20701 [D loss: 0.689260, acc.: 57.81%] [G loss: 1.106074]\n",
      "epoch:22 step:20702 [D loss: 0.678450, acc.: 59.38%] [G loss: 1.014234]\n",
      "epoch:22 step:20703 [D loss: 0.623120, acc.: 64.06%] [G loss: 0.952730]\n",
      "epoch:22 step:20704 [D loss: 0.616154, acc.: 59.38%] [G loss: 1.134520]\n",
      "epoch:22 step:20705 [D loss: 0.662299, acc.: 60.16%] [G loss: 1.054288]\n",
      "epoch:22 step:20706 [D loss: 0.597870, acc.: 67.19%] [G loss: 1.117227]\n",
      "epoch:22 step:20707 [D loss: 0.493453, acc.: 84.38%] [G loss: 0.873128]\n",
      "epoch:22 step:20708 [D loss: 0.573607, acc.: 70.31%] [G loss: 0.787163]\n",
      "epoch:22 step:20709 [D loss: 0.624235, acc.: 61.72%] [G loss: 1.078087]\n",
      "epoch:22 step:20710 [D loss: 0.618161, acc.: 65.62%] [G loss: 0.898619]\n",
      "epoch:22 step:20711 [D loss: 0.648115, acc.: 63.28%] [G loss: 1.115199]\n",
      "epoch:22 step:20712 [D loss: 0.729153, acc.: 58.59%] [G loss: 0.756363]\n",
      "epoch:22 step:20713 [D loss: 0.698056, acc.: 52.34%] [G loss: 0.846711]\n",
      "epoch:22 step:20714 [D loss: 0.661426, acc.: 56.25%] [G loss: 0.777655]\n",
      "epoch:22 step:20715 [D loss: 0.623091, acc.: 72.66%] [G loss: 0.841365]\n",
      "epoch:22 step:20716 [D loss: 0.691765, acc.: 50.00%] [G loss: 0.826717]\n",
      "epoch:22 step:20717 [D loss: 0.681029, acc.: 56.25%] [G loss: 0.883926]\n",
      "epoch:22 step:20718 [D loss: 0.787714, acc.: 45.31%] [G loss: 0.870698]\n",
      "epoch:22 step:20719 [D loss: 0.689089, acc.: 65.62%] [G loss: 0.870765]\n",
      "epoch:22 step:20720 [D loss: 0.730958, acc.: 45.31%] [G loss: 0.948910]\n",
      "epoch:22 step:20721 [D loss: 0.601829, acc.: 64.06%] [G loss: 0.797569]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20722 [D loss: 0.679778, acc.: 56.25%] [G loss: 0.907393]\n",
      "epoch:22 step:20723 [D loss: 0.651597, acc.: 62.50%] [G loss: 0.878764]\n",
      "epoch:22 step:20724 [D loss: 0.672127, acc.: 59.38%] [G loss: 0.754542]\n",
      "epoch:22 step:20725 [D loss: 0.616881, acc.: 72.66%] [G loss: 0.944330]\n",
      "epoch:22 step:20726 [D loss: 0.589095, acc.: 71.09%] [G loss: 0.839500]\n",
      "epoch:22 step:20727 [D loss: 0.484003, acc.: 79.69%] [G loss: 0.859482]\n",
      "epoch:22 step:20728 [D loss: 0.439312, acc.: 87.50%] [G loss: 0.802355]\n",
      "epoch:22 step:20729 [D loss: 0.564944, acc.: 69.53%] [G loss: 1.064464]\n",
      "epoch:22 step:20730 [D loss: 0.667343, acc.: 60.94%] [G loss: 0.873598]\n",
      "epoch:22 step:20731 [D loss: 0.649140, acc.: 64.06%] [G loss: 0.951665]\n",
      "epoch:22 step:20732 [D loss: 0.655946, acc.: 64.06%] [G loss: 0.932802]\n",
      "epoch:22 step:20733 [D loss: 0.397785, acc.: 79.69%] [G loss: 0.942458]\n",
      "epoch:22 step:20734 [D loss: 0.507656, acc.: 75.78%] [G loss: 1.140970]\n",
      "epoch:22 step:20735 [D loss: 0.364329, acc.: 86.72%] [G loss: 0.894054]\n",
      "epoch:22 step:20736 [D loss: 0.365023, acc.: 90.62%] [G loss: 1.169386]\n",
      "epoch:22 step:20737 [D loss: 0.628172, acc.: 66.41%] [G loss: 1.226447]\n",
      "epoch:22 step:20738 [D loss: 0.721210, acc.: 51.56%] [G loss: 1.080988]\n",
      "epoch:22 step:20739 [D loss: 0.803933, acc.: 39.84%] [G loss: 0.857729]\n",
      "epoch:22 step:20740 [D loss: 0.664551, acc.: 57.03%] [G loss: 0.937262]\n",
      "epoch:22 step:20741 [D loss: 0.700069, acc.: 52.34%] [G loss: 0.968544]\n",
      "epoch:22 step:20742 [D loss: 0.565768, acc.: 73.44%] [G loss: 0.901381]\n",
      "epoch:22 step:20743 [D loss: 0.460775, acc.: 79.69%] [G loss: 0.706635]\n",
      "epoch:22 step:20744 [D loss: 0.429547, acc.: 73.44%] [G loss: 1.154300]\n",
      "epoch:22 step:20745 [D loss: 0.460150, acc.: 80.47%] [G loss: 1.346077]\n",
      "epoch:22 step:20746 [D loss: 0.564381, acc.: 71.09%] [G loss: 1.067318]\n",
      "epoch:22 step:20747 [D loss: 0.774042, acc.: 50.78%] [G loss: 1.038232]\n",
      "epoch:22 step:20748 [D loss: 0.734147, acc.: 53.91%] [G loss: 1.002699]\n",
      "epoch:22 step:20749 [D loss: 0.587616, acc.: 75.00%] [G loss: 1.010308]\n",
      "epoch:22 step:20750 [D loss: 0.674059, acc.: 55.47%] [G loss: 0.998572]\n",
      "epoch:22 step:20751 [D loss: 0.596274, acc.: 69.53%] [G loss: 1.090074]\n",
      "epoch:22 step:20752 [D loss: 0.551931, acc.: 73.44%] [G loss: 1.049939]\n",
      "epoch:22 step:20753 [D loss: 0.433209, acc.: 81.25%] [G loss: 1.192083]\n",
      "epoch:22 step:20754 [D loss: 0.699007, acc.: 55.47%] [G loss: 0.933841]\n",
      "epoch:22 step:20755 [D loss: 0.511459, acc.: 81.25%] [G loss: 1.109765]\n",
      "epoch:22 step:20756 [D loss: 0.623762, acc.: 64.84%] [G loss: 1.070955]\n",
      "epoch:22 step:20757 [D loss: 0.316692, acc.: 87.50%] [G loss: 1.079330]\n",
      "epoch:22 step:20758 [D loss: 0.365249, acc.: 86.72%] [G loss: 1.107568]\n",
      "epoch:22 step:20759 [D loss: 0.261654, acc.: 91.41%] [G loss: 1.102900]\n",
      "epoch:22 step:20760 [D loss: 0.469954, acc.: 81.25%] [G loss: 1.278224]\n",
      "epoch:22 step:20761 [D loss: 0.697976, acc.: 56.25%] [G loss: 0.962185]\n",
      "epoch:22 step:20762 [D loss: 0.662916, acc.: 65.62%] [G loss: 1.112424]\n",
      "epoch:22 step:20763 [D loss: 0.603733, acc.: 67.19%] [G loss: 0.944122]\n",
      "epoch:22 step:20764 [D loss: 0.239953, acc.: 93.75%] [G loss: 1.151418]\n",
      "epoch:22 step:20765 [D loss: 0.306901, acc.: 93.75%] [G loss: 1.112642]\n",
      "epoch:22 step:20766 [D loss: 0.388894, acc.: 89.06%] [G loss: 1.241803]\n",
      "epoch:22 step:20767 [D loss: 0.828467, acc.: 51.56%] [G loss: 1.014410]\n",
      "epoch:22 step:20768 [D loss: 0.774964, acc.: 50.00%] [G loss: 0.990346]\n",
      "epoch:22 step:20769 [D loss: 0.620596, acc.: 69.53%] [G loss: 1.221391]\n",
      "epoch:22 step:20770 [D loss: 0.619360, acc.: 64.06%] [G loss: 1.081683]\n",
      "epoch:22 step:20771 [D loss: 0.748822, acc.: 50.00%] [G loss: 1.030045]\n",
      "epoch:22 step:20772 [D loss: 0.753126, acc.: 46.88%] [G loss: 0.720260]\n",
      "epoch:22 step:20773 [D loss: 0.890063, acc.: 41.41%] [G loss: 0.891395]\n",
      "epoch:22 step:20774 [D loss: 0.650347, acc.: 58.59%] [G loss: 1.045967]\n",
      "epoch:22 step:20775 [D loss: 0.633663, acc.: 63.28%] [G loss: 1.111670]\n",
      "epoch:22 step:20776 [D loss: 0.424988, acc.: 89.06%] [G loss: 1.135854]\n",
      "epoch:22 step:20777 [D loss: 0.566025, acc.: 74.22%] [G loss: 0.878528]\n",
      "epoch:22 step:20778 [D loss: 0.408814, acc.: 86.72%] [G loss: 1.109580]\n",
      "epoch:22 step:20779 [D loss: 0.465814, acc.: 85.16%] [G loss: 1.090819]\n",
      "epoch:22 step:20780 [D loss: 0.778471, acc.: 51.56%] [G loss: 0.958298]\n",
      "epoch:22 step:20781 [D loss: 0.730253, acc.: 51.56%] [G loss: 0.909762]\n",
      "epoch:22 step:20782 [D loss: 0.558695, acc.: 74.22%] [G loss: 0.746439]\n",
      "epoch:22 step:20783 [D loss: 0.779657, acc.: 39.84%] [G loss: 1.164734]\n",
      "epoch:22 step:20784 [D loss: 0.709660, acc.: 55.47%] [G loss: 0.606933]\n",
      "epoch:22 step:20785 [D loss: 0.715093, acc.: 54.69%] [G loss: 0.964229]\n",
      "epoch:22 step:20786 [D loss: 0.673490, acc.: 60.94%] [G loss: 1.101985]\n",
      "epoch:22 step:20787 [D loss: 1.018766, acc.: 25.00%] [G loss: 1.127858]\n",
      "epoch:22 step:20788 [D loss: 0.759801, acc.: 46.88%] [G loss: 1.105787]\n",
      "epoch:22 step:20789 [D loss: 0.686287, acc.: 55.47%] [G loss: 1.088630]\n",
      "epoch:22 step:20790 [D loss: 0.616340, acc.: 64.06%] [G loss: 0.888688]\n",
      "epoch:22 step:20791 [D loss: 0.722724, acc.: 47.66%] [G loss: 0.888341]\n",
      "epoch:22 step:20792 [D loss: 0.604075, acc.: 67.19%] [G loss: 1.024008]\n",
      "epoch:22 step:20793 [D loss: 0.540772, acc.: 75.78%] [G loss: 1.099825]\n",
      "epoch:22 step:20794 [D loss: 0.639256, acc.: 64.06%] [G loss: 1.047166]\n",
      "epoch:22 step:20795 [D loss: 0.645533, acc.: 60.16%] [G loss: 1.155235]\n",
      "epoch:22 step:20796 [D loss: 0.694248, acc.: 53.12%] [G loss: 1.007843]\n",
      "epoch:22 step:20797 [D loss: 0.624742, acc.: 58.59%] [G loss: 1.081885]\n",
      "epoch:22 step:20798 [D loss: 0.550609, acc.: 75.00%] [G loss: 1.079506]\n",
      "epoch:22 step:20799 [D loss: 0.476968, acc.: 80.47%] [G loss: 0.980484]\n",
      "epoch:22 step:20800 [D loss: 0.641881, acc.: 61.72%] [G loss: 0.950867]\n",
      "##############\n",
      "[3.76190814 2.7544375  7.01992803 5.9018345  4.4934678  6.1675303\n",
      " 5.48970228 5.62632797 6.02208027 4.76660142]\n",
      "##########\n",
      "epoch:22 step:20801 [D loss: 0.725981, acc.: 51.56%] [G loss: 1.061884]\n",
      "epoch:22 step:20802 [D loss: 0.696674, acc.: 53.91%] [G loss: 0.854433]\n",
      "epoch:22 step:20803 [D loss: 0.665720, acc.: 66.41%] [G loss: 0.771538]\n",
      "epoch:22 step:20804 [D loss: 0.603062, acc.: 66.41%] [G loss: 1.023438]\n",
      "epoch:22 step:20805 [D loss: 0.609197, acc.: 67.97%] [G loss: 0.872820]\n",
      "epoch:22 step:20806 [D loss: 0.445466, acc.: 85.16%] [G loss: 1.002795]\n",
      "epoch:22 step:20807 [D loss: 0.653573, acc.: 66.41%] [G loss: 1.058427]\n",
      "epoch:22 step:20808 [D loss: 0.483135, acc.: 84.38%] [G loss: 1.008468]\n",
      "epoch:22 step:20809 [D loss: 0.504668, acc.: 78.91%] [G loss: 1.097549]\n",
      "epoch:22 step:20810 [D loss: 0.485372, acc.: 78.12%] [G loss: 0.876918]\n",
      "epoch:22 step:20811 [D loss: 0.563879, acc.: 76.56%] [G loss: 1.272954]\n",
      "epoch:22 step:20812 [D loss: 0.451735, acc.: 85.16%] [G loss: 1.021625]\n",
      "epoch:22 step:20813 [D loss: 0.793966, acc.: 49.22%] [G loss: 0.997654]\n",
      "epoch:22 step:20814 [D loss: 0.453860, acc.: 80.47%] [G loss: 0.926101]\n",
      "epoch:22 step:20815 [D loss: 0.218685, acc.: 98.44%] [G loss: 1.232833]\n",
      "epoch:22 step:20816 [D loss: 0.761228, acc.: 43.75%] [G loss: 1.257610]\n",
      "epoch:22 step:20817 [D loss: 0.449526, acc.: 86.72%] [G loss: 1.104560]\n",
      "epoch:22 step:20818 [D loss: 0.353949, acc.: 88.28%] [G loss: 1.363820]\n",
      "epoch:22 step:20819 [D loss: 0.519240, acc.: 76.56%] [G loss: 0.931603]\n",
      "epoch:22 step:20820 [D loss: 0.311556, acc.: 92.97%] [G loss: 0.836145]\n",
      "epoch:22 step:20821 [D loss: 0.302126, acc.: 83.59%] [G loss: 1.465957]\n",
      "epoch:22 step:20822 [D loss: 0.273746, acc.: 98.44%] [G loss: 0.855343]\n",
      "epoch:22 step:20823 [D loss: 0.374919, acc.: 85.94%] [G loss: 1.218599]\n",
      "epoch:22 step:20824 [D loss: 0.984683, acc.: 35.16%] [G loss: 1.418451]\n",
      "epoch:22 step:20825 [D loss: 0.981819, acc.: 32.03%] [G loss: 0.813556]\n",
      "epoch:22 step:20826 [D loss: 0.739535, acc.: 51.56%] [G loss: 1.061372]\n",
      "epoch:22 step:20827 [D loss: 0.764430, acc.: 53.91%] [G loss: 0.864607]\n",
      "epoch:22 step:20828 [D loss: 0.950281, acc.: 38.28%] [G loss: 1.064930]\n",
      "epoch:22 step:20829 [D loss: 0.790948, acc.: 50.00%] [G loss: 0.873845]\n",
      "epoch:22 step:20830 [D loss: 0.644087, acc.: 60.94%] [G loss: 0.880602]\n",
      "epoch:22 step:20831 [D loss: 0.618293, acc.: 67.19%] [G loss: 1.000785]\n",
      "epoch:22 step:20832 [D loss: 0.501617, acc.: 68.75%] [G loss: 0.897957]\n",
      "epoch:22 step:20833 [D loss: 0.427600, acc.: 85.16%] [G loss: 1.236376]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20834 [D loss: 0.267487, acc.: 90.62%] [G loss: 1.159397]\n",
      "epoch:22 step:20835 [D loss: 0.285545, acc.: 92.19%] [G loss: 1.223152]\n",
      "epoch:22 step:20836 [D loss: 0.238422, acc.: 96.09%] [G loss: 1.437156]\n",
      "epoch:22 step:20837 [D loss: 0.449962, acc.: 85.16%] [G loss: 1.222144]\n",
      "epoch:22 step:20838 [D loss: 0.740904, acc.: 54.69%] [G loss: 1.367612]\n",
      "epoch:22 step:20839 [D loss: 0.572964, acc.: 71.09%] [G loss: 1.220024]\n",
      "epoch:22 step:20840 [D loss: 0.669712, acc.: 57.03%] [G loss: 0.908719]\n",
      "epoch:22 step:20841 [D loss: 0.582196, acc.: 71.09%] [G loss: 1.116491]\n",
      "epoch:22 step:20842 [D loss: 0.663107, acc.: 60.16%] [G loss: 1.027025]\n",
      "epoch:22 step:20843 [D loss: 0.658842, acc.: 60.94%] [G loss: 0.987341]\n",
      "epoch:22 step:20844 [D loss: 0.297083, acc.: 82.03%] [G loss: 1.026460]\n",
      "epoch:22 step:20845 [D loss: 0.220344, acc.: 95.31%] [G loss: 1.180814]\n",
      "epoch:22 step:20846 [D loss: 0.199186, acc.: 96.88%] [G loss: 1.534267]\n",
      "epoch:22 step:20847 [D loss: 0.535522, acc.: 78.12%] [G loss: 1.379231]\n",
      "epoch:22 step:20848 [D loss: 0.326422, acc.: 90.62%] [G loss: 1.363066]\n",
      "epoch:22 step:20849 [D loss: 0.229381, acc.: 94.53%] [G loss: 1.380854]\n",
      "epoch:22 step:20850 [D loss: 0.528057, acc.: 77.34%] [G loss: 1.371429]\n",
      "epoch:22 step:20851 [D loss: 0.310352, acc.: 95.31%] [G loss: 1.505782]\n",
      "epoch:22 step:20852 [D loss: 0.185148, acc.: 96.88%] [G loss: 1.137498]\n",
      "epoch:22 step:20853 [D loss: 0.467007, acc.: 83.59%] [G loss: 1.301127]\n",
      "epoch:22 step:20854 [D loss: 0.513590, acc.: 77.34%] [G loss: 1.349146]\n",
      "epoch:22 step:20855 [D loss: 0.826883, acc.: 46.88%] [G loss: 1.101198]\n",
      "epoch:22 step:20856 [D loss: 0.571496, acc.: 68.75%] [G loss: 1.122227]\n",
      "epoch:22 step:20857 [D loss: 0.300030, acc.: 90.62%] [G loss: 1.176269]\n",
      "epoch:22 step:20858 [D loss: 0.549123, acc.: 73.44%] [G loss: 0.731413]\n",
      "epoch:22 step:20859 [D loss: 0.866720, acc.: 41.41%] [G loss: 1.005869]\n",
      "epoch:22 step:20860 [D loss: 0.750017, acc.: 53.12%] [G loss: 1.003192]\n",
      "epoch:22 step:20861 [D loss: 0.811969, acc.: 43.75%] [G loss: 1.024423]\n",
      "epoch:22 step:20862 [D loss: 0.754613, acc.: 45.31%] [G loss: 1.052533]\n",
      "epoch:22 step:20863 [D loss: 0.401202, acc.: 85.94%] [G loss: 0.998174]\n",
      "epoch:22 step:20864 [D loss: 0.667329, acc.: 61.72%] [G loss: 0.956281]\n",
      "epoch:22 step:20865 [D loss: 0.591485, acc.: 70.31%] [G loss: 1.134966]\n",
      "epoch:22 step:20866 [D loss: 0.478581, acc.: 77.34%] [G loss: 1.305864]\n",
      "epoch:22 step:20867 [D loss: 0.448968, acc.: 80.47%] [G loss: 1.205524]\n",
      "epoch:22 step:20868 [D loss: 0.336977, acc.: 81.25%] [G loss: 1.569057]\n",
      "epoch:22 step:20869 [D loss: 0.343689, acc.: 78.12%] [G loss: 1.623527]\n",
      "epoch:22 step:20870 [D loss: 0.181914, acc.: 97.66%] [G loss: 2.023210]\n",
      "epoch:22 step:20871 [D loss: 0.238514, acc.: 93.75%] [G loss: 1.804868]\n",
      "epoch:22 step:20872 [D loss: 0.802329, acc.: 50.78%] [G loss: 1.112274]\n",
      "epoch:22 step:20873 [D loss: 0.155329, acc.: 99.22%] [G loss: 1.027503]\n",
      "epoch:22 step:20874 [D loss: 0.795614, acc.: 56.25%] [G loss: 1.919584]\n",
      "epoch:22 step:20875 [D loss: 0.331408, acc.: 83.59%] [G loss: 1.852456]\n",
      "epoch:22 step:20876 [D loss: 1.140506, acc.: 43.75%] [G loss: 1.780374]\n",
      "epoch:22 step:20877 [D loss: 0.342976, acc.: 87.50%] [G loss: 2.006358]\n",
      "epoch:22 step:20878 [D loss: 0.578403, acc.: 66.41%] [G loss: 1.336673]\n",
      "epoch:22 step:20879 [D loss: 0.904607, acc.: 49.22%] [G loss: 1.817763]\n",
      "epoch:22 step:20880 [D loss: 0.781963, acc.: 49.22%] [G loss: 1.474993]\n",
      "epoch:22 step:20881 [D loss: 0.860874, acc.: 40.62%] [G loss: 1.608812]\n",
      "epoch:22 step:20882 [D loss: 0.715582, acc.: 57.03%] [G loss: 1.697659]\n",
      "epoch:22 step:20883 [D loss: 0.320304, acc.: 92.97%] [G loss: 1.457501]\n",
      "epoch:22 step:20884 [D loss: 0.529410, acc.: 67.97%] [G loss: 1.721742]\n",
      "epoch:22 step:20885 [D loss: 0.288124, acc.: 97.66%] [G loss: 1.422691]\n",
      "epoch:22 step:20886 [D loss: 0.390273, acc.: 86.72%] [G loss: 1.701100]\n",
      "epoch:22 step:20887 [D loss: 0.444470, acc.: 81.25%] [G loss: 1.741283]\n",
      "epoch:22 step:20888 [D loss: 0.289965, acc.: 96.88%] [G loss: 1.676939]\n",
      "epoch:22 step:20889 [D loss: 0.313830, acc.: 92.97%] [G loss: 1.640490]\n",
      "epoch:22 step:20890 [D loss: 0.250290, acc.: 98.44%] [G loss: 1.381035]\n",
      "epoch:22 step:20891 [D loss: 0.355126, acc.: 89.84%] [G loss: 1.299382]\n",
      "epoch:22 step:20892 [D loss: 0.900067, acc.: 46.88%] [G loss: 1.632129]\n",
      "epoch:22 step:20893 [D loss: 0.832473, acc.: 52.34%] [G loss: 1.124954]\n",
      "epoch:22 step:20894 [D loss: 0.760066, acc.: 52.34%] [G loss: 0.788300]\n",
      "epoch:22 step:20895 [D loss: 0.746166, acc.: 52.34%] [G loss: 1.290839]\n",
      "epoch:22 step:20896 [D loss: 0.410187, acc.: 88.28%] [G loss: 1.055688]\n",
      "epoch:22 step:20897 [D loss: 0.641132, acc.: 63.28%] [G loss: 0.629818]\n",
      "epoch:22 step:20898 [D loss: 0.774719, acc.: 43.75%] [G loss: 1.021921]\n",
      "epoch:22 step:20899 [D loss: 0.659263, acc.: 64.84%] [G loss: 1.246827]\n",
      "epoch:22 step:20900 [D loss: 0.593931, acc.: 71.09%] [G loss: 1.101501]\n",
      "epoch:22 step:20901 [D loss: 0.652058, acc.: 65.62%] [G loss: 1.002900]\n",
      "epoch:22 step:20902 [D loss: 0.465659, acc.: 82.03%] [G loss: 1.073548]\n",
      "epoch:22 step:20903 [D loss: 0.399308, acc.: 83.59%] [G loss: 0.838892]\n",
      "epoch:22 step:20904 [D loss: 0.738255, acc.: 49.22%] [G loss: 1.051297]\n",
      "epoch:22 step:20905 [D loss: 0.590089, acc.: 69.53%] [G loss: 1.170490]\n",
      "epoch:22 step:20906 [D loss: 0.283995, acc.: 93.75%] [G loss: 1.331879]\n",
      "epoch:22 step:20907 [D loss: 0.435969, acc.: 88.28%] [G loss: 1.175523]\n",
      "epoch:22 step:20908 [D loss: 0.567004, acc.: 75.00%] [G loss: 1.228070]\n",
      "epoch:22 step:20909 [D loss: 0.624664, acc.: 62.50%] [G loss: 1.150985]\n",
      "epoch:22 step:20910 [D loss: 0.710048, acc.: 49.22%] [G loss: 0.423459]\n",
      "epoch:22 step:20911 [D loss: 0.500490, acc.: 80.47%] [G loss: 0.950351]\n",
      "epoch:22 step:20912 [D loss: 0.459321, acc.: 87.50%] [G loss: 1.044903]\n",
      "epoch:22 step:20913 [D loss: 0.375317, acc.: 96.09%] [G loss: 1.220301]\n",
      "epoch:22 step:20914 [D loss: 0.656561, acc.: 66.41%] [G loss: 1.064173]\n",
      "epoch:22 step:20915 [D loss: 0.704546, acc.: 57.81%] [G loss: 0.974348]\n",
      "epoch:22 step:20916 [D loss: 0.639308, acc.: 64.84%] [G loss: 0.818284]\n",
      "epoch:22 step:20917 [D loss: 0.565436, acc.: 72.66%] [G loss: 0.556385]\n",
      "epoch:22 step:20918 [D loss: 0.721025, acc.: 54.69%] [G loss: 0.766653]\n",
      "epoch:22 step:20919 [D loss: 0.484404, acc.: 69.53%] [G loss: 1.168631]\n",
      "epoch:22 step:20920 [D loss: 0.567699, acc.: 70.31%] [G loss: 0.566036]\n",
      "epoch:22 step:20921 [D loss: 0.612090, acc.: 65.62%] [G loss: 1.306554]\n",
      "epoch:22 step:20922 [D loss: 0.379333, acc.: 86.72%] [G loss: 1.227381]\n",
      "epoch:22 step:20923 [D loss: 0.364085, acc.: 75.78%] [G loss: 1.343962]\n",
      "epoch:22 step:20924 [D loss: 0.653338, acc.: 62.50%] [G loss: 1.299630]\n",
      "epoch:22 step:20925 [D loss: 0.477068, acc.: 81.25%] [G loss: 1.260812]\n",
      "epoch:22 step:20926 [D loss: 0.279565, acc.: 84.38%] [G loss: 1.005644]\n",
      "epoch:22 step:20927 [D loss: 0.512305, acc.: 66.41%] [G loss: 1.417598]\n",
      "epoch:22 step:20928 [D loss: 0.200868, acc.: 94.53%] [G loss: 1.786852]\n",
      "epoch:22 step:20929 [D loss: 0.708556, acc.: 58.59%] [G loss: 1.120707]\n",
      "epoch:22 step:20930 [D loss: 0.629148, acc.: 60.94%] [G loss: 1.420061]\n",
      "epoch:22 step:20931 [D loss: 0.721478, acc.: 54.69%] [G loss: 0.986563]\n",
      "epoch:22 step:20932 [D loss: 0.567402, acc.: 69.53%] [G loss: 1.180356]\n",
      "epoch:22 step:20933 [D loss: 0.636195, acc.: 65.62%] [G loss: 1.067712]\n",
      "epoch:22 step:20934 [D loss: 0.564133, acc.: 77.34%] [G loss: 1.191362]\n",
      "epoch:22 step:20935 [D loss: 0.631279, acc.: 57.03%] [G loss: 1.063782]\n",
      "epoch:22 step:20936 [D loss: 0.589434, acc.: 67.19%] [G loss: 1.212918]\n",
      "epoch:22 step:20937 [D loss: 0.760908, acc.: 50.78%] [G loss: 1.140314]\n",
      "epoch:22 step:20938 [D loss: 0.710662, acc.: 54.69%] [G loss: 1.060269]\n",
      "epoch:22 step:20939 [D loss: 0.740680, acc.: 55.47%] [G loss: 1.303258]\n",
      "epoch:22 step:20940 [D loss: 0.569508, acc.: 75.00%] [G loss: 0.961425]\n",
      "epoch:22 step:20941 [D loss: 0.356920, acc.: 85.94%] [G loss: 1.182165]\n",
      "epoch:22 step:20942 [D loss: 0.334216, acc.: 86.72%] [G loss: 1.010204]\n",
      "epoch:22 step:20943 [D loss: 0.614553, acc.: 64.84%] [G loss: 1.030399]\n",
      "epoch:22 step:20944 [D loss: 0.797699, acc.: 47.66%] [G loss: 1.175610]\n",
      "epoch:22 step:20945 [D loss: 0.847605, acc.: 40.62%] [G loss: 0.898885]\n",
      "epoch:22 step:20946 [D loss: 0.540341, acc.: 76.56%] [G loss: 1.045260]\n",
      "epoch:22 step:20947 [D loss: 0.333551, acc.: 93.75%] [G loss: 0.984435]\n",
      "epoch:22 step:20948 [D loss: 0.522800, acc.: 73.44%] [G loss: 0.892608]\n",
      "epoch:22 step:20949 [D loss: 0.456308, acc.: 82.81%] [G loss: 1.121757]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20950 [D loss: 0.310258, acc.: 87.50%] [G loss: 1.319384]\n",
      "epoch:22 step:20951 [D loss: 0.577188, acc.: 72.66%] [G loss: 1.078658]\n",
      "epoch:22 step:20952 [D loss: 1.187160, acc.: 27.34%] [G loss: 1.281408]\n",
      "epoch:22 step:20953 [D loss: 0.667175, acc.: 57.81%] [G loss: 1.130875]\n",
      "epoch:22 step:20954 [D loss: 0.711167, acc.: 54.69%] [G loss: 1.079655]\n",
      "epoch:22 step:20955 [D loss: 0.744039, acc.: 49.22%] [G loss: 1.243480]\n",
      "epoch:22 step:20956 [D loss: 0.242476, acc.: 96.09%] [G loss: 1.049929]\n",
      "epoch:22 step:20957 [D loss: 0.223761, acc.: 97.66%] [G loss: 1.310583]\n",
      "epoch:22 step:20958 [D loss: 0.292205, acc.: 87.50%] [G loss: 1.408664]\n",
      "epoch:22 step:20959 [D loss: 0.177173, acc.: 96.88%] [G loss: 1.374658]\n",
      "epoch:22 step:20960 [D loss: 0.159610, acc.: 99.22%] [G loss: 1.476479]\n",
      "epoch:22 step:20961 [D loss: 0.145622, acc.: 100.00%] [G loss: 1.215684]\n",
      "epoch:22 step:20962 [D loss: 1.125270, acc.: 18.75%] [G loss: 1.610608]\n",
      "epoch:22 step:20963 [D loss: 0.735314, acc.: 56.25%] [G loss: 1.579539]\n",
      "epoch:22 step:20964 [D loss: 0.772567, acc.: 53.91%] [G loss: 1.315132]\n",
      "epoch:22 step:20965 [D loss: 0.540210, acc.: 75.00%] [G loss: 1.355087]\n",
      "epoch:22 step:20966 [D loss: 0.459343, acc.: 85.94%] [G loss: 0.695553]\n",
      "epoch:22 step:20967 [D loss: 0.345723, acc.: 94.53%] [G loss: 1.326863]\n",
      "epoch:22 step:20968 [D loss: 0.390509, acc.: 89.84%] [G loss: 1.142019]\n",
      "epoch:22 step:20969 [D loss: 0.629121, acc.: 64.06%] [G loss: 1.525129]\n",
      "epoch:22 step:20970 [D loss: 0.728789, acc.: 50.78%] [G loss: 0.789197]\n",
      "epoch:22 step:20971 [D loss: 0.504901, acc.: 80.47%] [G loss: 0.615719]\n",
      "epoch:22 step:20972 [D loss: 0.337787, acc.: 96.09%] [G loss: 0.537716]\n",
      "epoch:22 step:20973 [D loss: 0.340879, acc.: 97.66%] [G loss: 0.745599]\n",
      "epoch:22 step:20974 [D loss: 0.627753, acc.: 62.50%] [G loss: 0.744011]\n",
      "epoch:22 step:20975 [D loss: 0.720481, acc.: 57.03%] [G loss: 1.488701]\n",
      "epoch:22 step:20976 [D loss: 0.821325, acc.: 47.66%] [G loss: 1.299790]\n",
      "epoch:22 step:20977 [D loss: 0.381152, acc.: 90.62%] [G loss: 0.846113]\n",
      "epoch:22 step:20978 [D loss: 0.894621, acc.: 29.69%] [G loss: 1.216655]\n",
      "epoch:22 step:20979 [D loss: 0.363840, acc.: 91.41%] [G loss: 0.900216]\n",
      "epoch:22 step:20980 [D loss: 0.169259, acc.: 99.22%] [G loss: 0.994053]\n",
      "epoch:22 step:20981 [D loss: 0.359953, acc.: 82.81%] [G loss: 1.441472]\n",
      "epoch:22 step:20982 [D loss: 0.655093, acc.: 64.06%] [G loss: 1.300525]\n",
      "epoch:22 step:20983 [D loss: 0.692484, acc.: 60.16%] [G loss: 1.186830]\n",
      "epoch:22 step:20984 [D loss: 0.421419, acc.: 84.38%] [G loss: 1.177518]\n",
      "epoch:22 step:20985 [D loss: 0.371834, acc.: 90.62%] [G loss: 1.262243]\n",
      "epoch:22 step:20986 [D loss: 0.682274, acc.: 57.03%] [G loss: 1.201606]\n",
      "epoch:22 step:20987 [D loss: 0.702251, acc.: 54.69%] [G loss: 0.941895]\n",
      "epoch:22 step:20988 [D loss: 0.683275, acc.: 58.59%] [G loss: 0.759531]\n",
      "epoch:22 step:20989 [D loss: 0.697605, acc.: 57.03%] [G loss: 1.086577]\n",
      "epoch:22 step:20990 [D loss: 0.563719, acc.: 73.44%] [G loss: 1.095215]\n",
      "epoch:22 step:20991 [D loss: 0.189552, acc.: 97.66%] [G loss: 1.035452]\n",
      "epoch:22 step:20992 [D loss: 0.203378, acc.: 94.53%] [G loss: 1.475611]\n",
      "epoch:22 step:20993 [D loss: 0.789918, acc.: 47.66%] [G loss: 1.305468]\n",
      "epoch:22 step:20994 [D loss: 0.740385, acc.: 50.00%] [G loss: 1.405848]\n",
      "epoch:22 step:20995 [D loss: 0.595119, acc.: 69.53%] [G loss: 0.994216]\n",
      "epoch:22 step:20996 [D loss: 0.701200, acc.: 55.47%] [G loss: 0.912188]\n",
      "epoch:22 step:20997 [D loss: 0.465146, acc.: 79.69%] [G loss: 1.259322]\n",
      "epoch:22 step:20998 [D loss: 0.264280, acc.: 92.97%] [G loss: 1.270264]\n",
      "epoch:22 step:20999 [D loss: 0.596551, acc.: 71.09%] [G loss: 1.267866]\n",
      "epoch:22 step:21000 [D loss: 0.588411, acc.: 69.53%] [G loss: 1.203932]\n",
      "##############\n",
      "[4.21521382 2.06893459 6.63202796 5.49123657 4.01184403 5.95155251\n",
      " 5.41680252 5.47760567 5.66464662 4.68001337]\n",
      "##########\n",
      "epoch:22 step:21001 [D loss: 0.507459, acc.: 77.34%] [G loss: 1.137354]\n",
      "epoch:22 step:21002 [D loss: 0.422001, acc.: 85.16%] [G loss: 1.024808]\n",
      "epoch:22 step:21003 [D loss: 0.244602, acc.: 92.19%] [G loss: 1.330663]\n",
      "epoch:22 step:21004 [D loss: 0.238640, acc.: 92.97%] [G loss: 1.652562]\n",
      "epoch:22 step:21005 [D loss: 0.490172, acc.: 77.34%] [G loss: 1.495493]\n",
      "epoch:22 step:21006 [D loss: 0.239601, acc.: 97.66%] [G loss: 1.544283]\n",
      "epoch:22 step:21007 [D loss: 0.135664, acc.: 99.22%] [G loss: 1.583173]\n",
      "epoch:22 step:21008 [D loss: 0.433883, acc.: 84.38%] [G loss: 1.675557]\n",
      "epoch:22 step:21009 [D loss: 0.562894, acc.: 75.00%] [G loss: 1.773527]\n",
      "epoch:22 step:21010 [D loss: 0.176344, acc.: 93.75%] [G loss: 1.571297]\n",
      "epoch:22 step:21011 [D loss: 0.166204, acc.: 97.66%] [G loss: 1.798822]\n",
      "epoch:22 step:21012 [D loss: 0.119865, acc.: 100.00%] [G loss: 1.722714]\n",
      "epoch:22 step:21013 [D loss: 0.247735, acc.: 90.62%] [G loss: 1.954534]\n",
      "epoch:22 step:21014 [D loss: 0.065892, acc.: 100.00%] [G loss: 2.131330]\n",
      "epoch:22 step:21015 [D loss: 0.085763, acc.: 99.22%] [G loss: 2.292032]\n",
      "epoch:22 step:21016 [D loss: 0.108155, acc.: 100.00%] [G loss: 1.910274]\n",
      "epoch:22 step:21017 [D loss: 0.087630, acc.: 100.00%] [G loss: 2.521695]\n",
      "epoch:22 step:21018 [D loss: 0.077988, acc.: 100.00%] [G loss: 2.114590]\n",
      "epoch:22 step:21019 [D loss: 0.109932, acc.: 100.00%] [G loss: 2.661547]\n",
      "epoch:22 step:21020 [D loss: 0.050450, acc.: 100.00%] [G loss: 2.430393]\n",
      "epoch:22 step:21021 [D loss: 0.069899, acc.: 100.00%] [G loss: 3.038315]\n",
      "epoch:22 step:21022 [D loss: 0.080489, acc.: 99.22%] [G loss: 2.643718]\n",
      "epoch:22 step:21023 [D loss: 0.054163, acc.: 100.00%] [G loss: 3.511496]\n",
      "epoch:22 step:21024 [D loss: 0.066037, acc.: 100.00%] [G loss: 2.143592]\n",
      "epoch:22 step:21025 [D loss: 0.929299, acc.: 52.34%] [G loss: 1.380892]\n",
      "epoch:22 step:21026 [D loss: 2.073779, acc.: 50.00%] [G loss: 0.589756]\n",
      "epoch:22 step:21027 [D loss: 0.816382, acc.: 57.81%] [G loss: 3.004105]\n",
      "epoch:22 step:21028 [D loss: 0.360231, acc.: 85.94%] [G loss: 2.755937]\n",
      "epoch:22 step:21029 [D loss: 0.276187, acc.: 89.84%] [G loss: 3.097423]\n",
      "epoch:22 step:21030 [D loss: 0.890449, acc.: 42.19%] [G loss: 1.322747]\n",
      "epoch:22 step:21031 [D loss: 0.695627, acc.: 64.84%] [G loss: 0.956774]\n",
      "epoch:22 step:21032 [D loss: 0.800406, acc.: 60.16%] [G loss: 2.123596]\n",
      "epoch:22 step:21033 [D loss: 0.453343, acc.: 75.78%] [G loss: 2.188013]\n",
      "epoch:22 step:21034 [D loss: 1.232870, acc.: 51.56%] [G loss: 1.029851]\n",
      "epoch:22 step:21035 [D loss: 1.784688, acc.: 9.38%] [G loss: 1.586083]\n",
      "epoch:22 step:21036 [D loss: 1.163373, acc.: 35.16%] [G loss: 1.867093]\n",
      "epoch:22 step:21037 [D loss: 0.906984, acc.: 50.00%] [G loss: 1.319741]\n",
      "epoch:22 step:21038 [D loss: 0.632227, acc.: 61.72%] [G loss: 1.205779]\n",
      "epoch:22 step:21039 [D loss: 0.657089, acc.: 58.59%] [G loss: 0.836207]\n",
      "epoch:22 step:21040 [D loss: 0.822668, acc.: 42.19%] [G loss: 1.228259]\n",
      "epoch:22 step:21041 [D loss: 0.612037, acc.: 62.50%] [G loss: 0.989607]\n",
      "epoch:22 step:21042 [D loss: 0.444664, acc.: 81.25%] [G loss: 1.377278]\n",
      "epoch:22 step:21043 [D loss: 0.653802, acc.: 51.56%] [G loss: 1.417326]\n",
      "epoch:22 step:21044 [D loss: 0.540084, acc.: 74.22%] [G loss: 1.420726]\n",
      "epoch:22 step:21045 [D loss: 0.930571, acc.: 39.06%] [G loss: 1.170189]\n",
      "epoch:22 step:21046 [D loss: 0.712456, acc.: 53.12%] [G loss: 1.418821]\n",
      "epoch:22 step:21047 [D loss: 0.726090, acc.: 53.12%] [G loss: 1.229414]\n",
      "epoch:22 step:21048 [D loss: 0.604217, acc.: 64.84%] [G loss: 1.261345]\n",
      "epoch:22 step:21049 [D loss: 0.699260, acc.: 44.53%] [G loss: 1.403718]\n",
      "epoch:22 step:21050 [D loss: 0.646364, acc.: 59.38%] [G loss: 1.154775]\n",
      "epoch:22 step:21051 [D loss: 0.724558, acc.: 53.12%] [G loss: 1.164905]\n",
      "epoch:22 step:21052 [D loss: 0.715460, acc.: 54.69%] [G loss: 1.245688]\n",
      "epoch:22 step:21053 [D loss: 0.639179, acc.: 59.38%] [G loss: 1.008991]\n",
      "epoch:22 step:21054 [D loss: 0.587316, acc.: 64.06%] [G loss: 1.089692]\n",
      "epoch:22 step:21055 [D loss: 0.691457, acc.: 50.78%] [G loss: 1.197636]\n",
      "epoch:22 step:21056 [D loss: 0.634822, acc.: 59.38%] [G loss: 1.017260]\n",
      "epoch:22 step:21057 [D loss: 0.585309, acc.: 75.00%] [G loss: 1.065805]\n",
      "epoch:22 step:21058 [D loss: 0.621765, acc.: 60.16%] [G loss: 1.163012]\n",
      "epoch:22 step:21059 [D loss: 0.596412, acc.: 67.19%] [G loss: 1.141625]\n",
      "epoch:22 step:21060 [D loss: 0.686772, acc.: 57.03%] [G loss: 0.992826]\n",
      "epoch:22 step:21061 [D loss: 0.613270, acc.: 65.62%] [G loss: 1.107130]\n",
      "epoch:22 step:21062 [D loss: 0.501428, acc.: 83.59%] [G loss: 1.039283]\n",
      "epoch:22 step:21063 [D loss: 0.485227, acc.: 82.81%] [G loss: 1.162745]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21064 [D loss: 0.442252, acc.: 88.28%] [G loss: 1.209736]\n",
      "epoch:22 step:21065 [D loss: 0.411655, acc.: 89.06%] [G loss: 1.313306]\n",
      "epoch:22 step:21066 [D loss: 0.298950, acc.: 99.22%] [G loss: 1.298472]\n",
      "epoch:22 step:21067 [D loss: 0.415923, acc.: 90.62%] [G loss: 1.288432]\n",
      "epoch:22 step:21068 [D loss: 0.405002, acc.: 89.06%] [G loss: 1.675115]\n",
      "epoch:22 step:21069 [D loss: 0.492934, acc.: 85.94%] [G loss: 1.205555]\n",
      "epoch:22 step:21070 [D loss: 0.368009, acc.: 86.72%] [G loss: 1.456979]\n",
      "epoch:22 step:21071 [D loss: 0.419701, acc.: 89.84%] [G loss: 2.324593]\n",
      "epoch:22 step:21072 [D loss: 0.763630, acc.: 50.00%] [G loss: 1.334903]\n",
      "epoch:22 step:21073 [D loss: 0.721265, acc.: 52.34%] [G loss: 1.158615]\n",
      "epoch:22 step:21074 [D loss: 0.836215, acc.: 35.94%] [G loss: 1.168264]\n",
      "epoch:22 step:21075 [D loss: 0.931900, acc.: 32.81%] [G loss: 0.740146]\n",
      "epoch:22 step:21076 [D loss: 1.095329, acc.: 19.53%] [G loss: 0.796659]\n",
      "epoch:22 step:21077 [D loss: 0.831667, acc.: 35.16%] [G loss: 0.666463]\n",
      "epoch:22 step:21078 [D loss: 0.642664, acc.: 61.72%] [G loss: 0.796258]\n",
      "epoch:22 step:21079 [D loss: 0.647610, acc.: 60.16%] [G loss: 0.865890]\n",
      "epoch:22 step:21080 [D loss: 0.624817, acc.: 61.72%] [G loss: 1.040977]\n",
      "epoch:22 step:21081 [D loss: 0.599921, acc.: 66.41%] [G loss: 0.982719]\n",
      "epoch:22 step:21082 [D loss: 0.378566, acc.: 92.19%] [G loss: 1.041262]\n",
      "epoch:22 step:21083 [D loss: 0.469481, acc.: 81.25%] [G loss: 0.891286]\n",
      "epoch:22 step:21084 [D loss: 0.411062, acc.: 80.47%] [G loss: 1.011465]\n",
      "epoch:22 step:21085 [D loss: 0.256064, acc.: 96.88%] [G loss: 1.283909]\n",
      "epoch:22 step:21086 [D loss: 0.495049, acc.: 77.34%] [G loss: 1.215675]\n",
      "epoch:22 step:21087 [D loss: 0.964985, acc.: 42.19%] [G loss: 0.916647]\n",
      "epoch:22 step:21088 [D loss: 0.755849, acc.: 50.78%] [G loss: 1.073179]\n",
      "epoch:22 step:21089 [D loss: 0.823192, acc.: 41.41%] [G loss: 1.099050]\n",
      "epoch:22 step:21090 [D loss: 0.813359, acc.: 44.53%] [G loss: 0.958583]\n",
      "epoch:22 step:21091 [D loss: 0.748949, acc.: 46.09%] [G loss: 0.948147]\n",
      "epoch:22 step:21092 [D loss: 0.654721, acc.: 60.94%] [G loss: 0.990637]\n",
      "epoch:22 step:21093 [D loss: 0.560086, acc.: 72.66%] [G loss: 0.851634]\n",
      "epoch:22 step:21094 [D loss: 0.566528, acc.: 71.09%] [G loss: 0.845647]\n",
      "epoch:22 step:21095 [D loss: 0.601335, acc.: 69.53%] [G loss: 1.054730]\n",
      "epoch:22 step:21096 [D loss: 0.796150, acc.: 42.97%] [G loss: 0.989540]\n",
      "epoch:22 step:21097 [D loss: 0.693504, acc.: 49.22%] [G loss: 0.895857]\n",
      "epoch:22 step:21098 [D loss: 0.630224, acc.: 61.72%] [G loss: 1.070897]\n",
      "epoch:22 step:21099 [D loss: 0.732798, acc.: 44.53%] [G loss: 1.290291]\n",
      "epoch:22 step:21100 [D loss: 0.613097, acc.: 65.62%] [G loss: 1.230830]\n",
      "epoch:22 step:21101 [D loss: 0.623592, acc.: 60.16%] [G loss: 1.073015]\n",
      "epoch:22 step:21102 [D loss: 0.601973, acc.: 66.41%] [G loss: 1.008241]\n",
      "epoch:22 step:21103 [D loss: 0.688397, acc.: 64.84%] [G loss: 1.099503]\n",
      "epoch:22 step:21104 [D loss: 0.598471, acc.: 73.44%] [G loss: 0.969413]\n",
      "epoch:22 step:21105 [D loss: 0.666024, acc.: 57.81%] [G loss: 1.013820]\n",
      "epoch:22 step:21106 [D loss: 0.674776, acc.: 58.59%] [G loss: 1.038070]\n",
      "epoch:22 step:21107 [D loss: 0.766894, acc.: 50.00%] [G loss: 0.813131]\n",
      "epoch:22 step:21108 [D loss: 0.661170, acc.: 62.50%] [G loss: 0.867087]\n",
      "epoch:22 step:21109 [D loss: 0.591605, acc.: 68.75%] [G loss: 0.885950]\n",
      "epoch:22 step:21110 [D loss: 0.690904, acc.: 54.69%] [G loss: 0.858607]\n",
      "epoch:22 step:21111 [D loss: 0.503253, acc.: 77.34%] [G loss: 1.118513]\n",
      "epoch:22 step:21112 [D loss: 0.441006, acc.: 83.59%] [G loss: 1.118189]\n",
      "epoch:22 step:21113 [D loss: 0.399196, acc.: 87.50%] [G loss: 1.232121]\n",
      "epoch:22 step:21114 [D loss: 0.728835, acc.: 50.00%] [G loss: 1.148257]\n",
      "epoch:22 step:21115 [D loss: 0.710055, acc.: 60.16%] [G loss: 0.994456]\n",
      "epoch:22 step:21116 [D loss: 0.704700, acc.: 54.69%] [G loss: 0.983869]\n",
      "epoch:22 step:21117 [D loss: 0.561942, acc.: 67.19%] [G loss: 0.918630]\n",
      "epoch:22 step:21118 [D loss: 0.491462, acc.: 82.03%] [G loss: 0.968417]\n",
      "epoch:22 step:21119 [D loss: 0.554485, acc.: 72.66%] [G loss: 1.016980]\n",
      "epoch:22 step:21120 [D loss: 0.773544, acc.: 44.53%] [G loss: 0.975091]\n",
      "epoch:22 step:21121 [D loss: 0.574133, acc.: 76.56%] [G loss: 1.108450]\n",
      "epoch:22 step:21122 [D loss: 0.577132, acc.: 67.97%] [G loss: 0.980743]\n",
      "epoch:22 step:21123 [D loss: 0.679034, acc.: 48.44%] [G loss: 0.970209]\n",
      "epoch:22 step:21124 [D loss: 0.564280, acc.: 73.44%] [G loss: 1.170432]\n",
      "epoch:22 step:21125 [D loss: 0.387410, acc.: 87.50%] [G loss: 1.200701]\n",
      "epoch:22 step:21126 [D loss: 0.485876, acc.: 83.59%] [G loss: 0.860388]\n",
      "epoch:22 step:21127 [D loss: 0.407548, acc.: 89.06%] [G loss: 1.477473]\n",
      "epoch:22 step:21128 [D loss: 0.350295, acc.: 92.97%] [G loss: 1.365428]\n",
      "epoch:22 step:21129 [D loss: 0.335968, acc.: 91.41%] [G loss: 1.490336]\n",
      "epoch:22 step:21130 [D loss: 0.722897, acc.: 57.81%] [G loss: 1.463639]\n",
      "epoch:22 step:21131 [D loss: 0.562486, acc.: 73.44%] [G loss: 0.969952]\n",
      "epoch:22 step:21132 [D loss: 0.640150, acc.: 60.94%] [G loss: 0.916098]\n",
      "epoch:22 step:21133 [D loss: 0.634875, acc.: 64.06%] [G loss: 0.963288]\n",
      "epoch:22 step:21134 [D loss: 0.597820, acc.: 62.50%] [G loss: 1.042831]\n",
      "epoch:22 step:21135 [D loss: 0.751141, acc.: 50.78%] [G loss: 1.101309]\n",
      "epoch:22 step:21136 [D loss: 0.690370, acc.: 54.69%] [G loss: 1.064778]\n",
      "epoch:22 step:21137 [D loss: 0.592147, acc.: 67.19%] [G loss: 1.105700]\n",
      "epoch:22 step:21138 [D loss: 0.382247, acc.: 90.62%] [G loss: 1.077365]\n",
      "epoch:22 step:21139 [D loss: 0.596904, acc.: 67.97%] [G loss: 1.209576]\n",
      "epoch:22 step:21140 [D loss: 0.480470, acc.: 80.47%] [G loss: 1.318696]\n",
      "epoch:22 step:21141 [D loss: 0.440217, acc.: 81.25%] [G loss: 1.116262]\n",
      "epoch:22 step:21142 [D loss: 0.525540, acc.: 78.12%] [G loss: 1.114942]\n",
      "epoch:22 step:21143 [D loss: 0.500483, acc.: 80.47%] [G loss: 1.234081]\n",
      "epoch:22 step:21144 [D loss: 0.378606, acc.: 83.59%] [G loss: 1.414477]\n",
      "epoch:22 step:21145 [D loss: 0.670521, acc.: 59.38%] [G loss: 1.227425]\n",
      "epoch:22 step:21146 [D loss: 0.736772, acc.: 58.59%] [G loss: 1.084785]\n",
      "epoch:22 step:21147 [D loss: 0.638497, acc.: 62.50%] [G loss: 0.957066]\n",
      "epoch:22 step:21148 [D loss: 0.673027, acc.: 57.03%] [G loss: 1.137980]\n",
      "epoch:22 step:21149 [D loss: 0.338123, acc.: 91.41%] [G loss: 1.037539]\n",
      "epoch:22 step:21150 [D loss: 0.257185, acc.: 92.19%] [G loss: 1.229584]\n",
      "epoch:22 step:21151 [D loss: 0.238161, acc.: 97.66%] [G loss: 1.445335]\n",
      "epoch:22 step:21152 [D loss: 0.349471, acc.: 95.31%] [G loss: 1.254472]\n",
      "epoch:22 step:21153 [D loss: 0.253840, acc.: 96.09%] [G loss: 1.200518]\n",
      "epoch:22 step:21154 [D loss: 0.359923, acc.: 89.84%] [G loss: 1.538416]\n",
      "epoch:22 step:21155 [D loss: 0.283959, acc.: 95.31%] [G loss: 1.431774]\n",
      "epoch:22 step:21156 [D loss: 0.688061, acc.: 60.94%] [G loss: 1.297333]\n",
      "epoch:22 step:21157 [D loss: 0.261704, acc.: 91.41%] [G loss: 1.388727]\n",
      "epoch:22 step:21158 [D loss: 0.773591, acc.: 50.00%] [G loss: 1.165312]\n",
      "epoch:22 step:21159 [D loss: 0.672963, acc.: 56.25%] [G loss: 1.139534]\n",
      "epoch:22 step:21160 [D loss: 1.017049, acc.: 25.78%] [G loss: 1.421776]\n",
      "epoch:22 step:21161 [D loss: 0.621768, acc.: 58.59%] [G loss: 1.291211]\n",
      "epoch:22 step:21162 [D loss: 0.539285, acc.: 70.31%] [G loss: 1.369417]\n",
      "epoch:22 step:21163 [D loss: 0.432233, acc.: 83.59%] [G loss: 1.304123]\n",
      "epoch:22 step:21164 [D loss: 0.359194, acc.: 85.94%] [G loss: 1.598298]\n",
      "epoch:22 step:21165 [D loss: 0.450766, acc.: 85.94%] [G loss: 1.263149]\n",
      "epoch:22 step:21166 [D loss: 0.430188, acc.: 84.38%] [G loss: 1.428088]\n",
      "epoch:22 step:21167 [D loss: 0.539937, acc.: 71.88%] [G loss: 1.324562]\n",
      "epoch:22 step:21168 [D loss: 0.246440, acc.: 92.97%] [G loss: 1.270936]\n",
      "epoch:22 step:21169 [D loss: 0.434047, acc.: 82.81%] [G loss: 1.482644]\n",
      "epoch:22 step:21170 [D loss: 0.243270, acc.: 93.75%] [G loss: 1.752727]\n",
      "epoch:22 step:21171 [D loss: 0.228452, acc.: 96.88%] [G loss: 1.922615]\n",
      "epoch:22 step:21172 [D loss: 0.282577, acc.: 95.31%] [G loss: 1.818297]\n",
      "epoch:22 step:21173 [D loss: 0.240291, acc.: 97.66%] [G loss: 1.763059]\n",
      "epoch:22 step:21174 [D loss: 0.473961, acc.: 78.91%] [G loss: 1.268199]\n",
      "epoch:22 step:21175 [D loss: 0.327689, acc.: 90.62%] [G loss: 1.651389]\n",
      "epoch:22 step:21176 [D loss: 0.623470, acc.: 64.84%] [G loss: 1.091102]\n",
      "epoch:22 step:21177 [D loss: 0.692099, acc.: 58.59%] [G loss: 1.027650]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21178 [D loss: 0.556769, acc.: 70.31%] [G loss: 0.982334]\n",
      "epoch:22 step:21179 [D loss: 0.646152, acc.: 60.94%] [G loss: 0.799205]\n",
      "epoch:22 step:21180 [D loss: 0.665525, acc.: 64.84%] [G loss: 0.998562]\n",
      "epoch:22 step:21181 [D loss: 0.171904, acc.: 97.66%] [G loss: 1.418522]\n",
      "epoch:22 step:21182 [D loss: 0.679368, acc.: 62.50%] [G loss: 1.496627]\n",
      "epoch:22 step:21183 [D loss: 0.809686, acc.: 50.00%] [G loss: 1.447839]\n",
      "epoch:22 step:21184 [D loss: 0.636297, acc.: 61.72%] [G loss: 0.938908]\n",
      "epoch:22 step:21185 [D loss: 0.713371, acc.: 53.91%] [G loss: 1.113625]\n",
      "epoch:22 step:21186 [D loss: 0.546037, acc.: 73.44%] [G loss: 1.380417]\n",
      "epoch:22 step:21187 [D loss: 0.389170, acc.: 87.50%] [G loss: 1.168112]\n",
      "epoch:22 step:21188 [D loss: 0.779007, acc.: 60.16%] [G loss: 1.541658]\n",
      "epoch:22 step:21189 [D loss: 0.428633, acc.: 82.81%] [G loss: 1.553139]\n",
      "epoch:22 step:21190 [D loss: 0.180940, acc.: 98.44%] [G loss: 1.588443]\n",
      "epoch:22 step:21191 [D loss: 0.248278, acc.: 92.97%] [G loss: 1.810457]\n",
      "epoch:22 step:21192 [D loss: 0.169293, acc.: 98.44%] [G loss: 1.762460]\n",
      "epoch:22 step:21193 [D loss: 0.215525, acc.: 97.66%] [G loss: 1.984518]\n",
      "epoch:22 step:21194 [D loss: 0.677580, acc.: 59.38%] [G loss: 1.650806]\n",
      "epoch:22 step:21195 [D loss: 0.734939, acc.: 54.69%] [G loss: 1.307775]\n",
      "epoch:22 step:21196 [D loss: 0.587765, acc.: 67.97%] [G loss: 1.229236]\n",
      "epoch:22 step:21197 [D loss: 0.767307, acc.: 46.09%] [G loss: 1.130626]\n",
      "epoch:22 step:21198 [D loss: 0.843412, acc.: 42.97%] [G loss: 1.012456]\n",
      "epoch:22 step:21199 [D loss: 0.692789, acc.: 57.81%] [G loss: 1.093764]\n",
      "epoch:22 step:21200 [D loss: 0.515223, acc.: 78.91%] [G loss: 1.303079]\n",
      "##############\n",
      "[3.63797104 2.11387632 6.67128409 5.92378124 4.32391501 6.09698265\n",
      " 5.4574047  4.73691275 5.95934165 5.03470412]\n",
      "##########\n",
      "epoch:22 step:21201 [D loss: 0.251703, acc.: 90.62%] [G loss: 1.514922]\n",
      "epoch:22 step:21202 [D loss: 0.181588, acc.: 97.66%] [G loss: 1.157941]\n",
      "epoch:22 step:21203 [D loss: 0.167139, acc.: 93.75%] [G loss: 1.535150]\n",
      "epoch:22 step:21204 [D loss: 0.373331, acc.: 87.50%] [G loss: 1.655361]\n",
      "epoch:22 step:21205 [D loss: 0.778442, acc.: 58.59%] [G loss: 1.333552]\n",
      "epoch:22 step:21206 [D loss: 0.745690, acc.: 46.09%] [G loss: 1.080854]\n",
      "epoch:22 step:21207 [D loss: 0.622865, acc.: 67.19%] [G loss: 1.366469]\n",
      "epoch:22 step:21208 [D loss: 0.411033, acc.: 77.34%] [G loss: 0.735887]\n",
      "epoch:22 step:21209 [D loss: 0.309252, acc.: 85.94%] [G loss: 1.263023]\n",
      "epoch:22 step:21210 [D loss: 0.823163, acc.: 55.47%] [G loss: 1.368068]\n",
      "epoch:22 step:21211 [D loss: 0.724020, acc.: 53.91%] [G loss: 1.194448]\n",
      "epoch:22 step:21212 [D loss: 0.916842, acc.: 46.09%] [G loss: 0.747203]\n",
      "epoch:22 step:21213 [D loss: 0.758243, acc.: 50.00%] [G loss: 1.223461]\n",
      "epoch:22 step:21214 [D loss: 0.238870, acc.: 91.41%] [G loss: 1.168110]\n",
      "epoch:22 step:21215 [D loss: 0.296053, acc.: 86.72%] [G loss: 2.357826]\n",
      "epoch:22 step:21216 [D loss: 0.547768, acc.: 65.62%] [G loss: 1.971072]\n",
      "epoch:22 step:21217 [D loss: 0.834047, acc.: 52.34%] [G loss: 1.371151]\n",
      "epoch:22 step:21218 [D loss: 0.472829, acc.: 78.12%] [G loss: 1.341996]\n",
      "epoch:22 step:21219 [D loss: 0.734627, acc.: 51.56%] [G loss: 1.277268]\n",
      "epoch:22 step:21220 [D loss: 0.790912, acc.: 53.91%] [G loss: 0.660711]\n",
      "epoch:22 step:21221 [D loss: 0.800104, acc.: 49.22%] [G loss: 1.221927]\n",
      "epoch:22 step:21222 [D loss: 0.641678, acc.: 59.38%] [G loss: 1.153565]\n",
      "epoch:22 step:21223 [D loss: 0.856305, acc.: 51.56%] [G loss: 0.746593]\n",
      "epoch:22 step:21224 [D loss: 0.788674, acc.: 54.69%] [G loss: 1.964300]\n",
      "epoch:22 step:21225 [D loss: 0.655821, acc.: 64.06%] [G loss: 1.587856]\n",
      "epoch:22 step:21226 [D loss: 0.685575, acc.: 60.16%] [G loss: 1.540395]\n",
      "epoch:22 step:21227 [D loss: 0.818473, acc.: 44.53%] [G loss: 1.757332]\n",
      "epoch:22 step:21228 [D loss: 0.700557, acc.: 54.69%] [G loss: 1.351575]\n",
      "epoch:22 step:21229 [D loss: 0.607261, acc.: 64.06%] [G loss: 1.612054]\n",
      "epoch:22 step:21230 [D loss: 0.545066, acc.: 71.09%] [G loss: 1.490076]\n",
      "epoch:22 step:21231 [D loss: 0.391982, acc.: 85.16%] [G loss: 1.811904]\n",
      "epoch:22 step:21232 [D loss: 0.733629, acc.: 56.25%] [G loss: 1.532366]\n",
      "epoch:22 step:21233 [D loss: 0.600870, acc.: 60.94%] [G loss: 1.383469]\n",
      "epoch:22 step:21234 [D loss: 0.633593, acc.: 61.72%] [G loss: 1.432707]\n",
      "epoch:22 step:21235 [D loss: 0.650149, acc.: 59.38%] [G loss: 1.288906]\n",
      "epoch:22 step:21236 [D loss: 0.354303, acc.: 89.84%] [G loss: 1.598300]\n",
      "epoch:22 step:21237 [D loss: 0.370157, acc.: 90.62%] [G loss: 1.310933]\n",
      "epoch:22 step:21238 [D loss: 0.301942, acc.: 95.31%] [G loss: 1.520477]\n",
      "epoch:22 step:21239 [D loss: 0.656624, acc.: 65.62%] [G loss: 1.510247]\n",
      "epoch:22 step:21240 [D loss: 0.480070, acc.: 79.69%] [G loss: 1.447761]\n",
      "epoch:22 step:21241 [D loss: 0.605171, acc.: 67.19%] [G loss: 1.433975]\n",
      "epoch:22 step:21242 [D loss: 0.639942, acc.: 69.53%] [G loss: 1.333256]\n",
      "epoch:22 step:21243 [D loss: 0.316032, acc.: 92.19%] [G loss: 1.564356]\n",
      "epoch:22 step:21244 [D loss: 0.351980, acc.: 89.84%] [G loss: 1.572926]\n",
      "epoch:22 step:21245 [D loss: 0.764797, acc.: 54.69%] [G loss: 0.943454]\n",
      "epoch:22 step:21246 [D loss: 0.288841, acc.: 92.97%] [G loss: 1.091295]\n",
      "epoch:22 step:21247 [D loss: 0.329216, acc.: 80.47%] [G loss: 1.467923]\n",
      "epoch:22 step:21248 [D loss: 0.242438, acc.: 92.97%] [G loss: 0.860910]\n",
      "epoch:22 step:21249 [D loss: 0.229694, acc.: 96.09%] [G loss: 1.233765]\n",
      "epoch:22 step:21250 [D loss: 0.769227, acc.: 51.56%] [G loss: 1.321569]\n",
      "epoch:22 step:21251 [D loss: 0.611463, acc.: 61.72%] [G loss: 1.026395]\n",
      "epoch:22 step:21252 [D loss: 0.690458, acc.: 60.94%] [G loss: 1.227841]\n",
      "epoch:22 step:21253 [D loss: 0.936587, acc.: 43.75%] [G loss: 0.850966]\n",
      "epoch:22 step:21254 [D loss: 1.173190, acc.: 25.78%] [G loss: 0.547743]\n",
      "epoch:22 step:21255 [D loss: 1.029071, acc.: 24.22%] [G loss: 0.717989]\n",
      "epoch:22 step:21256 [D loss: 0.901390, acc.: 27.34%] [G loss: 1.090227]\n",
      "epoch:22 step:21257 [D loss: 0.666972, acc.: 57.81%] [G loss: 0.844209]\n",
      "epoch:22 step:21258 [D loss: 0.356381, acc.: 85.16%] [G loss: 1.295426]\n",
      "epoch:22 step:21259 [D loss: 0.530031, acc.: 66.41%] [G loss: 0.753283]\n",
      "epoch:22 step:21260 [D loss: 0.384168, acc.: 81.25%] [G loss: 1.029541]\n",
      "epoch:22 step:21261 [D loss: 0.345356, acc.: 92.97%] [G loss: 0.857026]\n",
      "epoch:22 step:21262 [D loss: 0.333135, acc.: 95.31%] [G loss: 1.215853]\n",
      "epoch:22 step:21263 [D loss: 0.531458, acc.: 74.22%] [G loss: 1.375952]\n",
      "epoch:22 step:21264 [D loss: 0.401346, acc.: 75.78%] [G loss: 0.925216]\n",
      "epoch:22 step:21265 [D loss: 0.514697, acc.: 78.91%] [G loss: 1.125081]\n",
      "epoch:22 step:21266 [D loss: 1.002889, acc.: 28.12%] [G loss: 0.977625]\n",
      "epoch:22 step:21267 [D loss: 0.755189, acc.: 54.69%] [G loss: 0.858555]\n",
      "epoch:22 step:21268 [D loss: 0.881182, acc.: 29.69%] [G loss: 1.266347]\n",
      "epoch:22 step:21269 [D loss: 0.638600, acc.: 63.28%] [G loss: 1.168897]\n",
      "epoch:22 step:21270 [D loss: 0.750646, acc.: 52.34%] [G loss: 0.848992]\n",
      "epoch:22 step:21271 [D loss: 0.714534, acc.: 44.53%] [G loss: 1.223827]\n",
      "epoch:22 step:21272 [D loss: 0.799671, acc.: 42.97%] [G loss: 0.850449]\n",
      "epoch:22 step:21273 [D loss: 0.482549, acc.: 82.03%] [G loss: 1.161466]\n",
      "epoch:22 step:21274 [D loss: 0.576309, acc.: 72.66%] [G loss: 1.246758]\n",
      "epoch:22 step:21275 [D loss: 0.671060, acc.: 60.94%] [G loss: 1.326149]\n",
      "epoch:22 step:21276 [D loss: 0.693379, acc.: 53.12%] [G loss: 0.908588]\n",
      "epoch:22 step:21277 [D loss: 0.538320, acc.: 75.00%] [G loss: 1.212070]\n",
      "epoch:22 step:21278 [D loss: 0.604117, acc.: 63.28%] [G loss: 1.604807]\n",
      "epoch:22 step:21279 [D loss: 0.391360, acc.: 85.94%] [G loss: 1.414438]\n",
      "epoch:22 step:21280 [D loss: 0.703799, acc.: 54.69%] [G loss: 1.451184]\n",
      "epoch:22 step:21281 [D loss: 0.524629, acc.: 73.44%] [G loss: 1.600662]\n",
      "epoch:22 step:21282 [D loss: 0.681937, acc.: 57.03%] [G loss: 1.367907]\n",
      "epoch:22 step:21283 [D loss: 0.591350, acc.: 65.62%] [G loss: 1.223647]\n",
      "epoch:22 step:21284 [D loss: 0.575935, acc.: 69.53%] [G loss: 1.173871]\n",
      "epoch:22 step:21285 [D loss: 0.485161, acc.: 80.47%] [G loss: 1.528118]\n",
      "epoch:22 step:21286 [D loss: 0.625992, acc.: 62.50%] [G loss: 1.257262]\n",
      "epoch:22 step:21287 [D loss: 0.510841, acc.: 75.78%] [G loss: 1.432294]\n",
      "epoch:22 step:21288 [D loss: 0.481538, acc.: 77.34%] [G loss: 1.236964]\n",
      "epoch:22 step:21289 [D loss: 0.710060, acc.: 60.16%] [G loss: 1.137053]\n",
      "epoch:22 step:21290 [D loss: 0.521636, acc.: 77.34%] [G loss: 1.093617]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21291 [D loss: 0.695935, acc.: 57.03%] [G loss: 1.207912]\n",
      "epoch:22 step:21292 [D loss: 0.701686, acc.: 57.03%] [G loss: 1.053243]\n",
      "epoch:22 step:21293 [D loss: 0.650208, acc.: 59.38%] [G loss: 1.463196]\n",
      "epoch:22 step:21294 [D loss: 0.696848, acc.: 61.72%] [G loss: 0.899585]\n",
      "epoch:22 step:21295 [D loss: 0.774635, acc.: 46.09%] [G loss: 0.717685]\n",
      "epoch:22 step:21296 [D loss: 0.472632, acc.: 85.16%] [G loss: 0.960989]\n",
      "epoch:22 step:21297 [D loss: 0.575922, acc.: 69.53%] [G loss: 0.944539]\n",
      "epoch:22 step:21298 [D loss: 0.498202, acc.: 80.47%] [G loss: 0.869494]\n",
      "epoch:22 step:21299 [D loss: 0.508025, acc.: 75.00%] [G loss: 1.145066]\n",
      "epoch:22 step:21300 [D loss: 0.437596, acc.: 80.47%] [G loss: 1.109335]\n",
      "epoch:22 step:21301 [D loss: 0.405621, acc.: 83.59%] [G loss: 1.126522]\n",
      "epoch:22 step:21302 [D loss: 0.625499, acc.: 60.94%] [G loss: 1.057754]\n",
      "epoch:22 step:21303 [D loss: 0.746807, acc.: 55.47%] [G loss: 1.101540]\n",
      "epoch:22 step:21304 [D loss: 0.776278, acc.: 47.66%] [G loss: 1.042669]\n",
      "epoch:22 step:21305 [D loss: 0.812621, acc.: 46.88%] [G loss: 0.846671]\n",
      "epoch:22 step:21306 [D loss: 0.668418, acc.: 64.06%] [G loss: 1.014641]\n",
      "epoch:22 step:21307 [D loss: 0.710843, acc.: 50.78%] [G loss: 0.974611]\n",
      "epoch:22 step:21308 [D loss: 0.530213, acc.: 75.78%] [G loss: 0.961447]\n",
      "epoch:22 step:21309 [D loss: 0.753634, acc.: 48.44%] [G loss: 0.927715]\n",
      "epoch:22 step:21310 [D loss: 0.427960, acc.: 78.91%] [G loss: 1.004527]\n",
      "epoch:22 step:21311 [D loss: 0.265074, acc.: 91.41%] [G loss: 1.092964]\n",
      "epoch:22 step:21312 [D loss: 0.330586, acc.: 92.97%] [G loss: 1.208472]\n",
      "epoch:22 step:21313 [D loss: 0.360913, acc.: 86.72%] [G loss: 0.877403]\n",
      "epoch:22 step:21314 [D loss: 0.228332, acc.: 96.09%] [G loss: 1.052217]\n",
      "epoch:22 step:21315 [D loss: 0.263628, acc.: 94.53%] [G loss: 1.435787]\n",
      "epoch:22 step:21316 [D loss: 0.278070, acc.: 96.09%] [G loss: 1.444440]\n",
      "epoch:22 step:21317 [D loss: 0.632897, acc.: 64.06%] [G loss: 1.396629]\n",
      "epoch:22 step:21318 [D loss: 0.444412, acc.: 85.94%] [G loss: 1.351972]\n",
      "epoch:22 step:21319 [D loss: 0.596850, acc.: 65.62%] [G loss: 1.197775]\n",
      "epoch:22 step:21320 [D loss: 0.271704, acc.: 93.75%] [G loss: 1.205070]\n",
      "epoch:22 step:21321 [D loss: 0.282045, acc.: 88.28%] [G loss: 1.348779]\n",
      "epoch:22 step:21322 [D loss: 0.157797, acc.: 100.00%] [G loss: 1.549642]\n",
      "epoch:22 step:21323 [D loss: 0.153194, acc.: 100.00%] [G loss: 1.413901]\n",
      "epoch:22 step:21324 [D loss: 0.788439, acc.: 57.81%] [G loss: 0.986286]\n",
      "epoch:22 step:21325 [D loss: 0.590132, acc.: 74.22%] [G loss: 1.359672]\n",
      "epoch:22 step:21326 [D loss: 0.551962, acc.: 68.75%] [G loss: 0.952803]\n",
      "epoch:22 step:21327 [D loss: 0.304138, acc.: 84.38%] [G loss: 1.259961]\n",
      "epoch:22 step:21328 [D loss: 0.192083, acc.: 95.31%] [G loss: 1.518915]\n",
      "epoch:22 step:21329 [D loss: 0.788524, acc.: 55.47%] [G loss: 1.052724]\n",
      "epoch:22 step:21330 [D loss: 0.839845, acc.: 43.75%] [G loss: 1.378562]\n",
      "epoch:22 step:21331 [D loss: 1.028749, acc.: 32.03%] [G loss: 1.217239]\n",
      "epoch:22 step:21332 [D loss: 0.669220, acc.: 53.91%] [G loss: 1.355173]\n",
      "epoch:22 step:21333 [D loss: 0.704587, acc.: 51.56%] [G loss: 1.155120]\n",
      "epoch:22 step:21334 [D loss: 0.645584, acc.: 61.72%] [G loss: 1.292055]\n",
      "epoch:22 step:21335 [D loss: 0.644941, acc.: 61.72%] [G loss: 1.192554]\n",
      "epoch:22 step:21336 [D loss: 0.518732, acc.: 81.25%] [G loss: 1.002246]\n",
      "epoch:22 step:21337 [D loss: 0.602770, acc.: 66.41%] [G loss: 0.643727]\n",
      "epoch:22 step:21338 [D loss: 0.633689, acc.: 61.72%] [G loss: 1.298419]\n",
      "epoch:22 step:21339 [D loss: 0.861075, acc.: 43.75%] [G loss: 1.152605]\n",
      "epoch:22 step:21340 [D loss: 0.572703, acc.: 71.88%] [G loss: 1.381495]\n",
      "epoch:22 step:21341 [D loss: 0.542743, acc.: 72.66%] [G loss: 1.223485]\n",
      "epoch:22 step:21342 [D loss: 0.282162, acc.: 89.84%] [G loss: 1.502074]\n",
      "epoch:22 step:21343 [D loss: 0.509708, acc.: 77.34%] [G loss: 1.306368]\n",
      "epoch:22 step:21344 [D loss: 0.370915, acc.: 83.59%] [G loss: 1.537479]\n",
      "epoch:22 step:21345 [D loss: 0.554831, acc.: 75.00%] [G loss: 0.978782]\n",
      "epoch:22 step:21346 [D loss: 0.454382, acc.: 77.34%] [G loss: 1.066016]\n",
      "epoch:22 step:21347 [D loss: 0.640816, acc.: 62.50%] [G loss: 1.285209]\n",
      "epoch:22 step:21348 [D loss: 0.902496, acc.: 37.50%] [G loss: 0.948632]\n",
      "epoch:22 step:21349 [D loss: 0.877035, acc.: 36.72%] [G loss: 1.202738]\n",
      "epoch:22 step:21350 [D loss: 0.775831, acc.: 51.56%] [G loss: 1.711212]\n",
      "epoch:22 step:21351 [D loss: 0.737202, acc.: 56.25%] [G loss: 1.478530]\n",
      "epoch:22 step:21352 [D loss: 0.797058, acc.: 53.12%] [G loss: 1.481405]\n",
      "epoch:22 step:21353 [D loss: 1.041679, acc.: 37.50%] [G loss: 1.295269]\n",
      "epoch:22 step:21354 [D loss: 0.686811, acc.: 61.72%] [G loss: 1.168553]\n",
      "epoch:22 step:21355 [D loss: 0.361081, acc.: 94.53%] [G loss: 1.305964]\n",
      "epoch:22 step:21356 [D loss: 0.333218, acc.: 93.75%] [G loss: 1.427188]\n",
      "epoch:22 step:21357 [D loss: 0.354108, acc.: 93.75%] [G loss: 1.658926]\n",
      "epoch:22 step:21358 [D loss: 0.444735, acc.: 85.16%] [G loss: 1.536211]\n",
      "epoch:22 step:21359 [D loss: 0.687689, acc.: 55.47%] [G loss: 1.269564]\n",
      "epoch:22 step:21360 [D loss: 0.667130, acc.: 63.28%] [G loss: 1.186926]\n",
      "epoch:22 step:21361 [D loss: 0.599371, acc.: 67.97%] [G loss: 1.129504]\n",
      "epoch:22 step:21362 [D loss: 0.420908, acc.: 86.72%] [G loss: 1.148539]\n",
      "epoch:22 step:21363 [D loss: 0.303083, acc.: 95.31%] [G loss: 1.245112]\n",
      "epoch:22 step:21364 [D loss: 0.238976, acc.: 99.22%] [G loss: 1.287412]\n",
      "epoch:22 step:21365 [D loss: 0.654913, acc.: 60.16%] [G loss: 1.053263]\n",
      "epoch:22 step:21366 [D loss: 0.821348, acc.: 45.31%] [G loss: 0.982051]\n",
      "epoch:22 step:21367 [D loss: 0.838708, acc.: 42.19%] [G loss: 0.892456]\n",
      "epoch:22 step:21368 [D loss: 0.815111, acc.: 40.62%] [G loss: 0.978923]\n",
      "epoch:22 step:21369 [D loss: 0.738631, acc.: 55.47%] [G loss: 0.851479]\n",
      "epoch:22 step:21370 [D loss: 0.625225, acc.: 63.28%] [G loss: 1.062042]\n",
      "epoch:22 step:21371 [D loss: 0.597134, acc.: 65.62%] [G loss: 0.927132]\n",
      "epoch:22 step:21372 [D loss: 0.597346, acc.: 71.09%] [G loss: 1.063988]\n",
      "epoch:22 step:21373 [D loss: 0.488430, acc.: 80.47%] [G loss: 0.906812]\n",
      "epoch:22 step:21374 [D loss: 0.473711, acc.: 75.78%] [G loss: 1.052972]\n",
      "epoch:22 step:21375 [D loss: 0.618987, acc.: 70.31%] [G loss: 1.084665]\n",
      "epoch:22 step:21376 [D loss: 0.777258, acc.: 46.88%] [G loss: 1.075746]\n",
      "epoch:22 step:21377 [D loss: 0.688192, acc.: 58.59%] [G loss: 1.246005]\n",
      "epoch:22 step:21378 [D loss: 0.596632, acc.: 66.41%] [G loss: 0.974367]\n",
      "epoch:22 step:21379 [D loss: 0.648905, acc.: 58.59%] [G loss: 1.068438]\n",
      "epoch:22 step:21380 [D loss: 0.522814, acc.: 76.56%] [G loss: 0.981151]\n",
      "epoch:22 step:21381 [D loss: 0.538643, acc.: 74.22%] [G loss: 1.134646]\n",
      "epoch:22 step:21382 [D loss: 0.312063, acc.: 89.84%] [G loss: 1.247909]\n",
      "epoch:22 step:21383 [D loss: 0.270587, acc.: 95.31%] [G loss: 1.154673]\n",
      "epoch:22 step:21384 [D loss: 0.500801, acc.: 82.81%] [G loss: 1.236944]\n",
      "epoch:22 step:21385 [D loss: 0.724404, acc.: 55.47%] [G loss: 0.954771]\n",
      "epoch:22 step:21386 [D loss: 0.678261, acc.: 55.47%] [G loss: 0.840301]\n",
      "epoch:22 step:21387 [D loss: 1.007088, acc.: 36.72%] [G loss: 1.321716]\n",
      "epoch:22 step:21388 [D loss: 0.223961, acc.: 93.75%] [G loss: 1.270558]\n",
      "epoch:22 step:21389 [D loss: 0.272507, acc.: 96.09%] [G loss: 1.368929]\n",
      "epoch:22 step:21390 [D loss: 0.692246, acc.: 58.59%] [G loss: 1.389595]\n",
      "epoch:22 step:21391 [D loss: 0.467400, acc.: 89.06%] [G loss: 1.097438]\n",
      "epoch:22 step:21392 [D loss: 0.676589, acc.: 56.25%] [G loss: 1.248471]\n",
      "epoch:22 step:21393 [D loss: 0.786658, acc.: 42.19%] [G loss: 0.903400]\n",
      "epoch:22 step:21394 [D loss: 0.563584, acc.: 75.00%] [G loss: 0.929579]\n",
      "epoch:22 step:21395 [D loss: 0.559577, acc.: 70.31%] [G loss: 0.966320]\n",
      "epoch:22 step:21396 [D loss: 0.605211, acc.: 64.84%] [G loss: 0.846788]\n",
      "epoch:22 step:21397 [D loss: 0.567125, acc.: 69.53%] [G loss: 1.251675]\n",
      "epoch:22 step:21398 [D loss: 0.590206, acc.: 71.09%] [G loss: 0.976462]\n",
      "epoch:22 step:21399 [D loss: 0.662307, acc.: 64.06%] [G loss: 1.264158]\n",
      "epoch:22 step:21400 [D loss: 0.324704, acc.: 88.28%] [G loss: 1.227672]\n",
      "##############\n",
      "[3.74353025 2.41566226 6.61002126 5.51788574 4.21257751 6.30805721\n",
      " 5.41975281 5.29339202 6.03617704 4.73665094]\n",
      "##########\n",
      "epoch:22 step:21401 [D loss: 0.675756, acc.: 55.47%] [G loss: 1.182375]\n",
      "epoch:22 step:21402 [D loss: 0.756321, acc.: 53.91%] [G loss: 1.051584]\n",
      "epoch:22 step:21403 [D loss: 0.772398, acc.: 49.22%] [G loss: 0.996377]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21404 [D loss: 0.739595, acc.: 54.69%] [G loss: 1.207545]\n",
      "epoch:22 step:21405 [D loss: 0.407226, acc.: 76.56%] [G loss: 1.209781]\n",
      "epoch:22 step:21406 [D loss: 0.266795, acc.: 93.75%] [G loss: 1.282627]\n",
      "epoch:22 step:21407 [D loss: 0.408679, acc.: 88.28%] [G loss: 1.326043]\n",
      "epoch:22 step:21408 [D loss: 0.351338, acc.: 84.38%] [G loss: 1.469470]\n",
      "epoch:22 step:21409 [D loss: 0.465128, acc.: 82.81%] [G loss: 1.377289]\n",
      "epoch:22 step:21410 [D loss: 0.399935, acc.: 86.72%] [G loss: 1.342566]\n",
      "epoch:22 step:21411 [D loss: 0.695928, acc.: 55.47%] [G loss: 1.558985]\n",
      "epoch:22 step:21412 [D loss: 0.495030, acc.: 77.34%] [G loss: 1.374643]\n",
      "epoch:22 step:21413 [D loss: 0.769517, acc.: 49.22%] [G loss: 1.345243]\n",
      "epoch:22 step:21414 [D loss: 0.608914, acc.: 70.31%] [G loss: 1.168555]\n",
      "epoch:22 step:21415 [D loss: 0.489589, acc.: 76.56%] [G loss: 1.182918]\n",
      "epoch:22 step:21416 [D loss: 0.477862, acc.: 71.88%] [G loss: 1.369723]\n",
      "epoch:22 step:21417 [D loss: 0.659772, acc.: 64.84%] [G loss: 1.228916]\n",
      "epoch:22 step:21418 [D loss: 0.207671, acc.: 95.31%] [G loss: 1.352987]\n",
      "epoch:22 step:21419 [D loss: 0.300882, acc.: 87.50%] [G loss: 1.500575]\n",
      "epoch:22 step:21420 [D loss: 0.203870, acc.: 96.09%] [G loss: 1.525706]\n",
      "epoch:22 step:21421 [D loss: 0.857307, acc.: 46.88%] [G loss: 1.594055]\n",
      "epoch:22 step:21422 [D loss: 0.609301, acc.: 72.66%] [G loss: 1.252552]\n",
      "epoch:22 step:21423 [D loss: 0.650772, acc.: 61.72%] [G loss: 1.055413]\n",
      "epoch:22 step:21424 [D loss: 0.663423, acc.: 58.59%] [G loss: 1.236254]\n",
      "epoch:22 step:21425 [D loss: 0.706584, acc.: 54.69%] [G loss: 1.360073]\n",
      "epoch:22 step:21426 [D loss: 0.409315, acc.: 85.94%] [G loss: 1.041555]\n",
      "epoch:22 step:21427 [D loss: 0.714389, acc.: 60.16%] [G loss: 0.975331]\n",
      "epoch:22 step:21428 [D loss: 0.670942, acc.: 60.94%] [G loss: 1.276655]\n",
      "epoch:22 step:21429 [D loss: 0.331638, acc.: 92.19%] [G loss: 0.938052]\n",
      "epoch:22 step:21430 [D loss: 0.548695, acc.: 78.12%] [G loss: 1.103252]\n",
      "epoch:22 step:21431 [D loss: 0.527594, acc.: 75.00%] [G loss: 1.196007]\n",
      "epoch:22 step:21432 [D loss: 0.657982, acc.: 56.25%] [G loss: 0.844486]\n",
      "epoch:22 step:21433 [D loss: 0.682834, acc.: 55.47%] [G loss: 0.946931]\n",
      "epoch:22 step:21434 [D loss: 0.625297, acc.: 65.62%] [G loss: 0.915887]\n",
      "epoch:22 step:21435 [D loss: 0.351086, acc.: 81.25%] [G loss: 0.912441]\n",
      "epoch:22 step:21436 [D loss: 0.374173, acc.: 83.59%] [G loss: 1.009518]\n",
      "epoch:22 step:21437 [D loss: 0.507565, acc.: 75.78%] [G loss: 1.285602]\n",
      "epoch:22 step:21438 [D loss: 0.688279, acc.: 57.03%] [G loss: 1.143957]\n",
      "epoch:22 step:21439 [D loss: 0.619473, acc.: 62.50%] [G loss: 1.071673]\n",
      "epoch:22 step:21440 [D loss: 0.538492, acc.: 78.91%] [G loss: 1.084588]\n",
      "epoch:22 step:21441 [D loss: 0.562836, acc.: 72.66%] [G loss: 0.999911]\n",
      "epoch:22 step:21442 [D loss: 0.667390, acc.: 62.50%] [G loss: 1.132677]\n",
      "epoch:22 step:21443 [D loss: 0.610691, acc.: 67.97%] [G loss: 1.013060]\n",
      "epoch:22 step:21444 [D loss: 0.630747, acc.: 64.06%] [G loss: 0.984286]\n",
      "epoch:22 step:21445 [D loss: 0.644434, acc.: 61.72%] [G loss: 0.589117]\n",
      "epoch:22 step:21446 [D loss: 0.565346, acc.: 73.44%] [G loss: 1.029041]\n",
      "epoch:22 step:21447 [D loss: 0.632670, acc.: 63.28%] [G loss: 1.032615]\n",
      "epoch:22 step:21448 [D loss: 0.338666, acc.: 81.25%] [G loss: 0.945622]\n",
      "epoch:22 step:21449 [D loss: 0.472009, acc.: 81.25%] [G loss: 0.959196]\n",
      "epoch:22 step:21450 [D loss: 0.674325, acc.: 57.81%] [G loss: 1.029149]\n",
      "epoch:22 step:21451 [D loss: 0.804926, acc.: 42.19%] [G loss: 1.123668]\n",
      "epoch:22 step:21452 [D loss: 0.643497, acc.: 62.50%] [G loss: 1.195772]\n",
      "epoch:22 step:21453 [D loss: 0.448376, acc.: 85.16%] [G loss: 0.869473]\n",
      "epoch:22 step:21454 [D loss: 0.434072, acc.: 79.69%] [G loss: 0.974857]\n",
      "epoch:22 step:21455 [D loss: 0.218850, acc.: 96.88%] [G loss: 1.331263]\n",
      "epoch:22 step:21456 [D loss: 0.358511, acc.: 82.81%] [G loss: 1.412791]\n",
      "epoch:22 step:21457 [D loss: 0.827365, acc.: 49.22%] [G loss: 1.195911]\n",
      "epoch:22 step:21458 [D loss: 0.712468, acc.: 61.72%] [G loss: 1.240614]\n",
      "epoch:22 step:21459 [D loss: 0.281389, acc.: 95.31%] [G loss: 1.120281]\n",
      "epoch:22 step:21460 [D loss: 0.774546, acc.: 50.78%] [G loss: 1.234623]\n",
      "epoch:22 step:21461 [D loss: 0.223394, acc.: 96.09%] [G loss: 1.219535]\n",
      "epoch:22 step:21462 [D loss: 0.222654, acc.: 96.88%] [G loss: 1.195140]\n",
      "epoch:22 step:21463 [D loss: 0.324492, acc.: 94.53%] [G loss: 1.220757]\n",
      "epoch:22 step:21464 [D loss: 0.347734, acc.: 92.97%] [G loss: 1.576469]\n",
      "epoch:22 step:21465 [D loss: 0.183157, acc.: 98.44%] [G loss: 1.525708]\n",
      "epoch:22 step:21466 [D loss: 0.265236, acc.: 88.28%] [G loss: 1.574964]\n",
      "epoch:22 step:21467 [D loss: 0.272967, acc.: 89.06%] [G loss: 1.704464]\n",
      "epoch:22 step:21468 [D loss: 0.141589, acc.: 99.22%] [G loss: 2.040825]\n",
      "epoch:22 step:21469 [D loss: 0.512640, acc.: 75.78%] [G loss: 1.551960]\n",
      "epoch:22 step:21470 [D loss: 1.186960, acc.: 20.31%] [G loss: 1.523389]\n",
      "epoch:22 step:21471 [D loss: 0.414756, acc.: 86.72%] [G loss: 0.374044]\n",
      "epoch:22 step:21472 [D loss: 0.557325, acc.: 67.97%] [G loss: 1.629014]\n",
      "epoch:22 step:21473 [D loss: 0.399795, acc.: 85.16%] [G loss: 1.717928]\n",
      "epoch:22 step:21474 [D loss: 0.654926, acc.: 67.19%] [G loss: 1.175732]\n",
      "epoch:22 step:21475 [D loss: 0.926264, acc.: 45.31%] [G loss: 1.830201]\n",
      "epoch:22 step:21476 [D loss: 1.167026, acc.: 25.78%] [G loss: 0.978960]\n",
      "epoch:22 step:21477 [D loss: 0.620349, acc.: 66.41%] [G loss: 1.390199]\n",
      "epoch:22 step:21478 [D loss: 0.649484, acc.: 61.72%] [G loss: 1.279274]\n",
      "epoch:22 step:21479 [D loss: 0.957956, acc.: 34.38%] [G loss: 1.100972]\n",
      "epoch:22 step:21480 [D loss: 0.825062, acc.: 45.31%] [G loss: 1.193844]\n",
      "epoch:22 step:21481 [D loss: 0.667006, acc.: 64.06%] [G loss: 1.144475]\n",
      "epoch:22 step:21482 [D loss: 0.549971, acc.: 72.66%] [G loss: 1.240557]\n",
      "epoch:22 step:21483 [D loss: 0.680458, acc.: 55.47%] [G loss: 1.148344]\n",
      "epoch:22 step:21484 [D loss: 0.366348, acc.: 86.72%] [G loss: 1.303025]\n",
      "epoch:22 step:21485 [D loss: 0.498321, acc.: 79.69%] [G loss: 1.571978]\n",
      "epoch:22 step:21486 [D loss: 0.724038, acc.: 53.12%] [G loss: 1.309050]\n",
      "epoch:22 step:21487 [D loss: 0.423268, acc.: 85.94%] [G loss: 1.416678]\n",
      "epoch:22 step:21488 [D loss: 0.355742, acc.: 89.06%] [G loss: 1.421385]\n",
      "epoch:22 step:21489 [D loss: 0.503333, acc.: 82.81%] [G loss: 1.431239]\n",
      "epoch:22 step:21490 [D loss: 0.241023, acc.: 94.53%] [G loss: 1.578835]\n",
      "epoch:22 step:21491 [D loss: 0.178775, acc.: 98.44%] [G loss: 1.189658]\n",
      "epoch:22 step:21492 [D loss: 0.218103, acc.: 92.19%] [G loss: 1.437147]\n",
      "epoch:22 step:21493 [D loss: 0.569561, acc.: 71.88%] [G loss: 0.813184]\n",
      "epoch:22 step:21494 [D loss: 0.740362, acc.: 50.78%] [G loss: 1.233970]\n",
      "epoch:22 step:21495 [D loss: 0.805562, acc.: 43.75%] [G loss: 0.560269]\n",
      "epoch:22 step:21496 [D loss: 1.232563, acc.: 23.44%] [G loss: 1.205806]\n",
      "epoch:22 step:21497 [D loss: 0.977332, acc.: 38.28%] [G loss: 0.865858]\n",
      "epoch:22 step:21498 [D loss: 0.899038, acc.: 37.50%] [G loss: 0.773803]\n",
      "epoch:22 step:21499 [D loss: 0.773933, acc.: 46.88%] [G loss: 1.008604]\n",
      "epoch:22 step:21500 [D loss: 0.751080, acc.: 50.78%] [G loss: 0.952417]\n",
      "epoch:22 step:21501 [D loss: 0.588120, acc.: 71.09%] [G loss: 1.088252]\n",
      "epoch:22 step:21502 [D loss: 0.783325, acc.: 37.50%] [G loss: 1.363564]\n",
      "epoch:22 step:21503 [D loss: 0.420356, acc.: 87.50%] [G loss: 1.089933]\n",
      "epoch:22 step:21504 [D loss: 0.446883, acc.: 83.59%] [G loss: 1.210484]\n",
      "epoch:22 step:21505 [D loss: 0.586781, acc.: 72.66%] [G loss: 1.146149]\n",
      "epoch:22 step:21506 [D loss: 0.586621, acc.: 73.44%] [G loss: 1.101104]\n",
      "epoch:22 step:21507 [D loss: 0.605232, acc.: 70.31%] [G loss: 0.994909]\n",
      "epoch:22 step:21508 [D loss: 0.515459, acc.: 76.56%] [G loss: 1.036606]\n",
      "epoch:22 step:21509 [D loss: 0.538980, acc.: 79.69%] [G loss: 0.819523]\n",
      "epoch:22 step:21510 [D loss: 0.590486, acc.: 64.84%] [G loss: 0.673840]\n",
      "epoch:22 step:21511 [D loss: 0.723033, acc.: 60.94%] [G loss: 0.769854]\n",
      "epoch:22 step:21512 [D loss: 0.314129, acc.: 90.62%] [G loss: 1.090522]\n",
      "epoch:22 step:21513 [D loss: 0.417621, acc.: 67.97%] [G loss: 0.976840]\n",
      "epoch:22 step:21514 [D loss: 0.245758, acc.: 92.97%] [G loss: 0.969798]\n",
      "epoch:22 step:21515 [D loss: 0.713275, acc.: 48.44%] [G loss: 1.105863]\n",
      "epoch:22 step:21516 [D loss: 0.765597, acc.: 51.56%] [G loss: 0.658921]\n",
      "epoch:22 step:21517 [D loss: 0.758538, acc.: 46.09%] [G loss: 0.830368]\n",
      "epoch:22 step:21518 [D loss: 0.721684, acc.: 55.47%] [G loss: 0.891815]\n",
      "epoch:22 step:21519 [D loss: 0.325031, acc.: 89.84%] [G loss: 1.363260]\n",
      "epoch:22 step:21520 [D loss: 0.303838, acc.: 88.28%] [G loss: 1.107607]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21521 [D loss: 0.587774, acc.: 70.31%] [G loss: 0.954184]\n",
      "epoch:22 step:21522 [D loss: 0.700819, acc.: 54.69%] [G loss: 1.225597]\n",
      "epoch:22 step:21523 [D loss: 0.595706, acc.: 67.19%] [G loss: 1.215184]\n",
      "epoch:22 step:21524 [D loss: 0.370626, acc.: 86.72%] [G loss: 0.621302]\n",
      "epoch:22 step:21525 [D loss: 0.720646, acc.: 56.25%] [G loss: 1.204766]\n",
      "epoch:22 step:21526 [D loss: 0.191936, acc.: 96.09%] [G loss: 1.291668]\n",
      "epoch:22 step:21527 [D loss: 0.715342, acc.: 53.91%] [G loss: 1.145435]\n",
      "epoch:22 step:21528 [D loss: 0.734693, acc.: 50.00%] [G loss: 1.039753]\n",
      "epoch:22 step:21529 [D loss: 0.685930, acc.: 57.81%] [G loss: 1.220849]\n",
      "epoch:22 step:21530 [D loss: 0.370277, acc.: 93.75%] [G loss: 1.095925]\n",
      "epoch:22 step:21531 [D loss: 0.280484, acc.: 90.62%] [G loss: 0.715617]\n",
      "epoch:22 step:21532 [D loss: 0.629555, acc.: 59.38%] [G loss: 1.233773]\n",
      "epoch:22 step:21533 [D loss: 0.610080, acc.: 67.19%] [G loss: 0.981252]\n",
      "epoch:22 step:21534 [D loss: 0.220271, acc.: 92.97%] [G loss: 0.887844]\n",
      "epoch:22 step:21535 [D loss: 0.274260, acc.: 88.28%] [G loss: 1.232290]\n",
      "epoch:22 step:21536 [D loss: 0.483028, acc.: 82.81%] [G loss: 1.643440]\n",
      "epoch:22 step:21537 [D loss: 0.578466, acc.: 67.97%] [G loss: 1.339384]\n",
      "epoch:22 step:21538 [D loss: 0.536801, acc.: 75.78%] [G loss: 1.271188]\n",
      "epoch:22 step:21539 [D loss: 0.521731, acc.: 75.78%] [G loss: 1.150086]\n",
      "epoch:22 step:21540 [D loss: 0.554175, acc.: 73.44%] [G loss: 1.029616]\n",
      "epoch:22 step:21541 [D loss: 0.427948, acc.: 80.47%] [G loss: 1.097419]\n",
      "epoch:22 step:21542 [D loss: 0.479174, acc.: 78.12%] [G loss: 1.277090]\n",
      "epoch:22 step:21543 [D loss: 0.423822, acc.: 70.31%] [G loss: 1.343759]\n",
      "epoch:22 step:21544 [D loss: 0.183080, acc.: 96.09%] [G loss: 1.687616]\n",
      "epoch:22 step:21545 [D loss: 0.332489, acc.: 90.62%] [G loss: 1.554852]\n",
      "epoch:22 step:21546 [D loss: 0.705100, acc.: 59.38%] [G loss: 1.087899]\n",
      "epoch:22 step:21547 [D loss: 0.635879, acc.: 63.28%] [G loss: 1.187468]\n",
      "epoch:22 step:21548 [D loss: 0.480695, acc.: 79.69%] [G loss: 1.208787]\n",
      "epoch:22 step:21549 [D loss: 0.634524, acc.: 64.06%] [G loss: 1.170329]\n",
      "epoch:22 step:21550 [D loss: 0.414041, acc.: 82.03%] [G loss: 1.476675]\n",
      "epoch:22 step:21551 [D loss: 0.319141, acc.: 82.03%] [G loss: 1.337527]\n",
      "epoch:23 step:21552 [D loss: 0.738567, acc.: 61.72%] [G loss: 0.950161]\n",
      "epoch:23 step:21553 [D loss: 0.701668, acc.: 54.69%] [G loss: 1.077805]\n",
      "epoch:23 step:21554 [D loss: 0.687674, acc.: 61.72%] [G loss: 1.034493]\n",
      "epoch:23 step:21555 [D loss: 0.585179, acc.: 71.88%] [G loss: 1.081737]\n",
      "epoch:23 step:21556 [D loss: 0.491838, acc.: 79.69%] [G loss: 1.274434]\n",
      "epoch:23 step:21557 [D loss: 0.552100, acc.: 71.09%] [G loss: 1.196948]\n",
      "epoch:23 step:21558 [D loss: 0.868074, acc.: 42.19%] [G loss: 1.065387]\n",
      "epoch:23 step:21559 [D loss: 0.754696, acc.: 50.78%] [G loss: 1.166706]\n",
      "epoch:23 step:21560 [D loss: 0.705859, acc.: 55.47%] [G loss: 0.967870]\n",
      "epoch:23 step:21561 [D loss: 0.735999, acc.: 56.25%] [G loss: 0.864958]\n",
      "epoch:23 step:21562 [D loss: 0.784862, acc.: 46.88%] [G loss: 1.049136]\n",
      "epoch:23 step:21563 [D loss: 0.681619, acc.: 60.94%] [G loss: 0.725021]\n",
      "epoch:23 step:21564 [D loss: 0.552776, acc.: 78.12%] [G loss: 0.926304]\n",
      "epoch:23 step:21565 [D loss: 0.780966, acc.: 47.66%] [G loss: 0.856154]\n",
      "epoch:23 step:21566 [D loss: 0.802930, acc.: 51.56%] [G loss: 1.144328]\n",
      "epoch:23 step:21567 [D loss: 0.697989, acc.: 59.38%] [G loss: 1.102183]\n",
      "epoch:23 step:21568 [D loss: 0.675801, acc.: 53.91%] [G loss: 1.164518]\n",
      "epoch:23 step:21569 [D loss: 0.556460, acc.: 74.22%] [G loss: 1.058256]\n",
      "epoch:23 step:21570 [D loss: 0.771976, acc.: 45.31%] [G loss: 1.074883]\n",
      "epoch:23 step:21571 [D loss: 0.684697, acc.: 62.50%] [G loss: 0.996645]\n",
      "epoch:23 step:21572 [D loss: 0.675394, acc.: 61.72%] [G loss: 0.418404]\n",
      "epoch:23 step:21573 [D loss: 0.665695, acc.: 63.28%] [G loss: 0.946946]\n",
      "epoch:23 step:21574 [D loss: 0.699074, acc.: 57.81%] [G loss: 1.017246]\n",
      "epoch:23 step:21575 [D loss: 0.667237, acc.: 60.94%] [G loss: 1.006821]\n",
      "epoch:23 step:21576 [D loss: 0.544133, acc.: 71.88%] [G loss: 0.894963]\n",
      "epoch:23 step:21577 [D loss: 0.666361, acc.: 59.38%] [G loss: 1.156242]\n",
      "epoch:23 step:21578 [D loss: 0.268112, acc.: 92.97%] [G loss: 1.242945]\n",
      "epoch:23 step:21579 [D loss: 0.480079, acc.: 80.47%] [G loss: 1.304263]\n",
      "epoch:23 step:21580 [D loss: 0.572006, acc.: 70.31%] [G loss: 1.133536]\n",
      "epoch:23 step:21581 [D loss: 0.722215, acc.: 53.12%] [G loss: 0.991996]\n",
      "epoch:23 step:21582 [D loss: 0.395874, acc.: 88.28%] [G loss: 1.109020]\n",
      "epoch:23 step:21583 [D loss: 0.265880, acc.: 95.31%] [G loss: 1.078964]\n",
      "epoch:23 step:21584 [D loss: 0.275983, acc.: 93.75%] [G loss: 1.269709]\n",
      "epoch:23 step:21585 [D loss: 0.315500, acc.: 90.62%] [G loss: 1.229010]\n",
      "epoch:23 step:21586 [D loss: 0.225674, acc.: 98.44%] [G loss: 1.187921]\n",
      "epoch:23 step:21587 [D loss: 0.241098, acc.: 92.97%] [G loss: 1.434216]\n",
      "epoch:23 step:21588 [D loss: 0.839668, acc.: 50.78%] [G loss: 1.458208]\n",
      "epoch:23 step:21589 [D loss: 0.609163, acc.: 62.50%] [G loss: 1.196682]\n",
      "epoch:23 step:21590 [D loss: 0.701899, acc.: 57.03%] [G loss: 1.054241]\n",
      "epoch:23 step:21591 [D loss: 0.552988, acc.: 68.75%] [G loss: 1.057668]\n",
      "epoch:23 step:21592 [D loss: 0.663973, acc.: 61.72%] [G loss: 1.036980]\n",
      "epoch:23 step:21593 [D loss: 0.550566, acc.: 72.66%] [G loss: 1.028521]\n",
      "epoch:23 step:21594 [D loss: 0.671348, acc.: 57.03%] [G loss: 0.768888]\n",
      "epoch:23 step:21595 [D loss: 0.582232, acc.: 69.53%] [G loss: 1.036548]\n",
      "epoch:23 step:21596 [D loss: 0.675181, acc.: 61.72%] [G loss: 1.032066]\n",
      "epoch:23 step:21597 [D loss: 0.563507, acc.: 68.75%] [G loss: 1.115768]\n",
      "epoch:23 step:21598 [D loss: 0.680864, acc.: 57.81%] [G loss: 1.070152]\n",
      "epoch:23 step:21599 [D loss: 0.760857, acc.: 49.22%] [G loss: 0.992602]\n",
      "epoch:23 step:21600 [D loss: 0.656465, acc.: 58.59%] [G loss: 0.948096]\n",
      "##############\n",
      "[3.84117046 2.74306534 6.79195913 6.11492439 4.87399376 5.93589368\n",
      " 5.49156677 5.80350311 5.93550688 5.05615228]\n",
      "##########\n",
      "epoch:23 step:21601 [D loss: 0.642926, acc.: 59.38%] [G loss: 0.869749]\n",
      "epoch:23 step:21602 [D loss: 0.674221, acc.: 60.16%] [G loss: 0.845332]\n",
      "epoch:23 step:21603 [D loss: 0.568632, acc.: 75.00%] [G loss: 0.901603]\n",
      "epoch:23 step:21604 [D loss: 0.619933, acc.: 65.62%] [G loss: 1.022371]\n",
      "epoch:23 step:21605 [D loss: 0.851175, acc.: 39.06%] [G loss: 1.056292]\n",
      "epoch:23 step:21606 [D loss: 0.670928, acc.: 58.59%] [G loss: 1.277035]\n",
      "epoch:23 step:21607 [D loss: 0.631035, acc.: 62.50%] [G loss: 0.867114]\n",
      "epoch:23 step:21608 [D loss: 0.349072, acc.: 85.16%] [G loss: 0.909828]\n",
      "epoch:23 step:21609 [D loss: 0.427684, acc.: 82.03%] [G loss: 1.011637]\n",
      "epoch:23 step:21610 [D loss: 0.505435, acc.: 78.12%] [G loss: 1.007256]\n",
      "epoch:23 step:21611 [D loss: 0.848418, acc.: 50.00%] [G loss: 0.710491]\n",
      "epoch:23 step:21612 [D loss: 0.834043, acc.: 42.19%] [G loss: 0.914021]\n",
      "epoch:23 step:21613 [D loss: 0.713944, acc.: 55.47%] [G loss: 1.343418]\n",
      "epoch:23 step:21614 [D loss: 0.665667, acc.: 61.72%] [G loss: 0.977358]\n",
      "epoch:23 step:21615 [D loss: 0.756274, acc.: 54.69%] [G loss: 0.923807]\n",
      "epoch:23 step:21616 [D loss: 0.768100, acc.: 44.53%] [G loss: 0.938704]\n",
      "epoch:23 step:21617 [D loss: 0.921505, acc.: 28.12%] [G loss: 0.792300]\n",
      "epoch:23 step:21618 [D loss: 0.775083, acc.: 43.75%] [G loss: 0.612480]\n",
      "epoch:23 step:21619 [D loss: 0.652463, acc.: 62.50%] [G loss: 0.827164]\n",
      "epoch:23 step:21620 [D loss: 0.765086, acc.: 49.22%] [G loss: 1.032051]\n",
      "epoch:23 step:21621 [D loss: 0.512274, acc.: 71.88%] [G loss: 1.353035]\n",
      "epoch:23 step:21622 [D loss: 0.397651, acc.: 83.59%] [G loss: 0.899034]\n",
      "epoch:23 step:21623 [D loss: 0.804158, acc.: 46.88%] [G loss: 1.155583]\n",
      "epoch:23 step:21624 [D loss: 0.649733, acc.: 62.50%] [G loss: 1.297106]\n",
      "epoch:23 step:21625 [D loss: 0.790059, acc.: 39.06%] [G loss: 1.458978]\n",
      "epoch:23 step:21626 [D loss: 0.423744, acc.: 84.38%] [G loss: 1.161745]\n",
      "epoch:23 step:21627 [D loss: 0.656066, acc.: 67.19%] [G loss: 1.391360]\n",
      "epoch:23 step:21628 [D loss: 0.551415, acc.: 73.44%] [G loss: 1.418726]\n",
      "epoch:23 step:21629 [D loss: 0.782665, acc.: 45.31%] [G loss: 1.286245]\n",
      "epoch:23 step:21630 [D loss: 0.758317, acc.: 51.56%] [G loss: 1.581452]\n",
      "epoch:23 step:21631 [D loss: 0.489815, acc.: 77.34%] [G loss: 1.886672]\n",
      "epoch:23 step:21632 [D loss: 0.400384, acc.: 89.06%] [G loss: 1.615451]\n",
      "epoch:23 step:21633 [D loss: 0.246333, acc.: 96.09%] [G loss: 1.921856]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21634 [D loss: 0.220517, acc.: 98.44%] [G loss: 1.314992]\n",
      "epoch:23 step:21635 [D loss: 0.405467, acc.: 83.59%] [G loss: 2.149495]\n",
      "epoch:23 step:21636 [D loss: 0.332577, acc.: 92.97%] [G loss: 2.049435]\n",
      "epoch:23 step:21637 [D loss: 0.420253, acc.: 88.28%] [G loss: 1.770103]\n",
      "epoch:23 step:21638 [D loss: 0.259699, acc.: 97.66%] [G loss: 1.785298]\n",
      "epoch:23 step:21639 [D loss: 0.277977, acc.: 97.66%] [G loss: 1.343817]\n",
      "epoch:23 step:21640 [D loss: 0.271835, acc.: 96.88%] [G loss: 1.667810]\n",
      "epoch:23 step:21641 [D loss: 0.334795, acc.: 97.66%] [G loss: 1.440977]\n",
      "epoch:23 step:21642 [D loss: 1.161645, acc.: 42.97%] [G loss: 2.156474]\n",
      "epoch:23 step:21643 [D loss: 0.313819, acc.: 94.53%] [G loss: 0.852645]\n",
      "epoch:23 step:21644 [D loss: 0.300928, acc.: 92.19%] [G loss: 1.375759]\n",
      "epoch:23 step:21645 [D loss: 0.520417, acc.: 74.22%] [G loss: 1.707605]\n",
      "epoch:23 step:21646 [D loss: 0.959827, acc.: 35.94%] [G loss: 1.209719]\n",
      "epoch:23 step:21647 [D loss: 0.625035, acc.: 64.84%] [G loss: 0.759774]\n",
      "epoch:23 step:21648 [D loss: 0.832256, acc.: 47.66%] [G loss: 0.944255]\n",
      "epoch:23 step:21649 [D loss: 1.164540, acc.: 48.44%] [G loss: 1.245192]\n",
      "epoch:23 step:21650 [D loss: 0.996905, acc.: 32.81%] [G loss: 0.500549]\n",
      "epoch:23 step:21651 [D loss: 0.719295, acc.: 51.56%] [G loss: 0.973063]\n",
      "epoch:23 step:21652 [D loss: 0.557674, acc.: 68.75%] [G loss: 0.716535]\n",
      "epoch:23 step:21653 [D loss: 0.683924, acc.: 56.25%] [G loss: 0.776612]\n",
      "epoch:23 step:21654 [D loss: 0.741893, acc.: 50.00%] [G loss: 0.983562]\n",
      "epoch:23 step:21655 [D loss: 0.669060, acc.: 50.78%] [G loss: 0.889893]\n",
      "epoch:23 step:21656 [D loss: 0.922964, acc.: 44.53%] [G loss: 1.230400]\n",
      "epoch:23 step:21657 [D loss: 0.700546, acc.: 51.56%] [G loss: 1.087546]\n",
      "epoch:23 step:21658 [D loss: 0.907251, acc.: 42.19%] [G loss: 1.060297]\n",
      "epoch:23 step:21659 [D loss: 0.731066, acc.: 48.44%] [G loss: 1.091620]\n",
      "epoch:23 step:21660 [D loss: 0.674733, acc.: 57.03%] [G loss: 1.259429]\n",
      "epoch:23 step:21661 [D loss: 0.635266, acc.: 56.25%] [G loss: 1.213343]\n",
      "epoch:23 step:21662 [D loss: 0.581915, acc.: 74.22%] [G loss: 1.025700]\n",
      "epoch:23 step:21663 [D loss: 0.618273, acc.: 66.41%] [G loss: 0.907868]\n",
      "epoch:23 step:21664 [D loss: 0.649595, acc.: 63.28%] [G loss: 0.963209]\n",
      "epoch:23 step:21665 [D loss: 0.552599, acc.: 73.44%] [G loss: 1.120491]\n",
      "epoch:23 step:21666 [D loss: 0.532207, acc.: 76.56%] [G loss: 1.070221]\n",
      "epoch:23 step:21667 [D loss: 0.676753, acc.: 63.28%] [G loss: 0.955844]\n",
      "epoch:23 step:21668 [D loss: 0.619743, acc.: 58.59%] [G loss: 1.332861]\n",
      "epoch:23 step:21669 [D loss: 0.601375, acc.: 67.97%] [G loss: 2.061233]\n",
      "epoch:23 step:21670 [D loss: 0.433231, acc.: 82.81%] [G loss: 1.307999]\n",
      "epoch:23 step:21671 [D loss: 0.634537, acc.: 66.41%] [G loss: 1.160800]\n",
      "epoch:23 step:21672 [D loss: 0.451264, acc.: 79.69%] [G loss: 1.211316]\n",
      "epoch:23 step:21673 [D loss: 0.525003, acc.: 76.56%] [G loss: 1.028973]\n",
      "epoch:23 step:21674 [D loss: 0.637393, acc.: 62.50%] [G loss: 1.106759]\n",
      "epoch:23 step:21675 [D loss: 0.710996, acc.: 59.38%] [G loss: 1.284202]\n",
      "epoch:23 step:21676 [D loss: 0.631232, acc.: 66.41%] [G loss: 1.275006]\n",
      "epoch:23 step:21677 [D loss: 0.626676, acc.: 63.28%] [G loss: 1.311681]\n",
      "epoch:23 step:21678 [D loss: 0.552970, acc.: 71.09%] [G loss: 1.239350]\n",
      "epoch:23 step:21679 [D loss: 0.627766, acc.: 66.41%] [G loss: 1.047491]\n",
      "epoch:23 step:21680 [D loss: 0.673770, acc.: 64.84%] [G loss: 1.174124]\n",
      "epoch:23 step:21681 [D loss: 0.514851, acc.: 75.00%] [G loss: 1.183901]\n",
      "epoch:23 step:21682 [D loss: 0.524620, acc.: 72.66%] [G loss: 0.918258]\n",
      "epoch:23 step:21683 [D loss: 0.618480, acc.: 64.84%] [G loss: 0.883572]\n",
      "epoch:23 step:21684 [D loss: 0.505745, acc.: 76.56%] [G loss: 1.262796]\n",
      "epoch:23 step:21685 [D loss: 0.511510, acc.: 76.56%] [G loss: 1.183466]\n",
      "epoch:23 step:21686 [D loss: 0.527680, acc.: 76.56%] [G loss: 1.221148]\n",
      "epoch:23 step:21687 [D loss: 0.613258, acc.: 69.53%] [G loss: 1.129651]\n",
      "epoch:23 step:21688 [D loss: 0.633654, acc.: 63.28%] [G loss: 1.076751]\n",
      "epoch:23 step:21689 [D loss: 0.641881, acc.: 62.50%] [G loss: 1.048944]\n",
      "epoch:23 step:21690 [D loss: 0.561268, acc.: 71.09%] [G loss: 1.039246]\n",
      "epoch:23 step:21691 [D loss: 0.552555, acc.: 71.09%] [G loss: 1.132680]\n",
      "epoch:23 step:21692 [D loss: 0.524998, acc.: 76.56%] [G loss: 0.980780]\n",
      "epoch:23 step:21693 [D loss: 0.590245, acc.: 68.75%] [G loss: 1.035764]\n",
      "epoch:23 step:21694 [D loss: 0.410726, acc.: 82.81%] [G loss: 1.291545]\n",
      "epoch:23 step:21695 [D loss: 0.357743, acc.: 86.72%] [G loss: 1.379258]\n",
      "epoch:23 step:21696 [D loss: 0.284289, acc.: 86.72%] [G loss: 1.572837]\n",
      "epoch:23 step:21697 [D loss: 0.379901, acc.: 91.41%] [G loss: 1.937645]\n",
      "epoch:23 step:21698 [D loss: 0.701480, acc.: 60.16%] [G loss: 1.716336]\n",
      "epoch:23 step:21699 [D loss: 0.794608, acc.: 48.44%] [G loss: 1.224950]\n",
      "epoch:23 step:21700 [D loss: 0.489064, acc.: 77.34%] [G loss: 1.330140]\n",
      "epoch:23 step:21701 [D loss: 0.289771, acc.: 89.84%] [G loss: 1.056766]\n",
      "epoch:23 step:21702 [D loss: 0.414246, acc.: 78.91%] [G loss: 1.583783]\n",
      "epoch:23 step:21703 [D loss: 0.418505, acc.: 81.25%] [G loss: 1.180541]\n",
      "epoch:23 step:21704 [D loss: 0.861658, acc.: 50.78%] [G loss: 1.444776]\n",
      "epoch:23 step:21705 [D loss: 0.673822, acc.: 61.72%] [G loss: 1.108479]\n",
      "epoch:23 step:21706 [D loss: 0.721413, acc.: 56.25%] [G loss: 0.972703]\n",
      "epoch:23 step:21707 [D loss: 0.880203, acc.: 41.41%] [G loss: 0.987154]\n",
      "epoch:23 step:21708 [D loss: 0.777572, acc.: 45.31%] [G loss: 0.998384]\n",
      "epoch:23 step:21709 [D loss: 0.745394, acc.: 47.66%] [G loss: 1.065034]\n",
      "epoch:23 step:21710 [D loss: 0.653323, acc.: 61.72%] [G loss: 0.976810]\n",
      "epoch:23 step:21711 [D loss: 0.697186, acc.: 57.03%] [G loss: 0.843735]\n",
      "epoch:23 step:21712 [D loss: 0.613066, acc.: 68.75%] [G loss: 0.893386]\n",
      "epoch:23 step:21713 [D loss: 0.511996, acc.: 76.56%] [G loss: 0.971891]\n",
      "epoch:23 step:21714 [D loss: 0.599255, acc.: 64.84%] [G loss: 1.054126]\n",
      "epoch:23 step:21715 [D loss: 0.546661, acc.: 71.88%] [G loss: 0.979734]\n",
      "epoch:23 step:21716 [D loss: 0.553385, acc.: 73.44%] [G loss: 1.050588]\n",
      "epoch:23 step:21717 [D loss: 0.731606, acc.: 55.47%] [G loss: 1.079719]\n",
      "epoch:23 step:21718 [D loss: 0.696180, acc.: 53.12%] [G loss: 0.942086]\n",
      "epoch:23 step:21719 [D loss: 0.664178, acc.: 64.06%] [G loss: 0.914378]\n",
      "epoch:23 step:21720 [D loss: 0.610578, acc.: 64.84%] [G loss: 0.989126]\n",
      "epoch:23 step:21721 [D loss: 0.689219, acc.: 55.47%] [G loss: 0.876658]\n",
      "epoch:23 step:21722 [D loss: 0.635519, acc.: 60.94%] [G loss: 0.999329]\n",
      "epoch:23 step:21723 [D loss: 0.688166, acc.: 57.81%] [G loss: 0.919759]\n",
      "epoch:23 step:21724 [D loss: 0.647697, acc.: 60.16%] [G loss: 0.857080]\n",
      "epoch:23 step:21725 [D loss: 0.683720, acc.: 56.25%] [G loss: 0.949335]\n",
      "epoch:23 step:21726 [D loss: 0.681801, acc.: 59.38%] [G loss: 0.899151]\n",
      "epoch:23 step:21727 [D loss: 0.636418, acc.: 60.16%] [G loss: 0.934418]\n",
      "epoch:23 step:21728 [D loss: 0.684214, acc.: 54.69%] [G loss: 0.847622]\n",
      "epoch:23 step:21729 [D loss: 0.635290, acc.: 58.59%] [G loss: 0.886944]\n",
      "epoch:23 step:21730 [D loss: 0.646210, acc.: 65.62%] [G loss: 1.007694]\n",
      "epoch:23 step:21731 [D loss: 0.622270, acc.: 68.75%] [G loss: 1.039866]\n",
      "epoch:23 step:21732 [D loss: 0.642946, acc.: 60.16%] [G loss: 0.958207]\n",
      "epoch:23 step:21733 [D loss: 0.712032, acc.: 53.12%] [G loss: 0.949837]\n",
      "epoch:23 step:21734 [D loss: 0.681747, acc.: 57.03%] [G loss: 0.913390]\n",
      "epoch:23 step:21735 [D loss: 0.562548, acc.: 69.53%] [G loss: 0.973988]\n",
      "epoch:23 step:21736 [D loss: 0.521953, acc.: 81.25%] [G loss: 0.882432]\n",
      "epoch:23 step:21737 [D loss: 0.695810, acc.: 59.38%] [G loss: 0.829294]\n",
      "epoch:23 step:21738 [D loss: 0.673561, acc.: 61.72%] [G loss: 1.039403]\n",
      "epoch:23 step:21739 [D loss: 0.626885, acc.: 67.97%] [G loss: 1.022300]\n",
      "epoch:23 step:21740 [D loss: 0.609496, acc.: 70.31%] [G loss: 0.899883]\n",
      "epoch:23 step:21741 [D loss: 0.646148, acc.: 60.16%] [G loss: 0.765999]\n",
      "epoch:23 step:21742 [D loss: 0.600484, acc.: 70.31%] [G loss: 0.979563]\n",
      "epoch:23 step:21743 [D loss: 0.425973, acc.: 82.03%] [G loss: 1.383427]\n",
      "epoch:23 step:21744 [D loss: 0.558016, acc.: 74.22%] [G loss: 1.047279]\n",
      "epoch:23 step:21745 [D loss: 0.371862, acc.: 88.28%] [G loss: 0.926626]\n",
      "epoch:23 step:21746 [D loss: 0.535045, acc.: 75.00%] [G loss: 1.045611]\n",
      "epoch:23 step:21747 [D loss: 0.530064, acc.: 73.44%] [G loss: 1.091568]\n",
      "epoch:23 step:21748 [D loss: 0.539059, acc.: 74.22%] [G loss: 1.268787]\n",
      "epoch:23 step:21749 [D loss: 0.497442, acc.: 78.12%] [G loss: 1.240700]\n",
      "epoch:23 step:21750 [D loss: 0.665394, acc.: 57.81%] [G loss: 1.096117]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21751 [D loss: 0.743269, acc.: 62.50%] [G loss: 0.986424]\n",
      "epoch:23 step:21752 [D loss: 0.356524, acc.: 86.72%] [G loss: 1.083821]\n",
      "epoch:23 step:21753 [D loss: 0.704283, acc.: 57.81%] [G loss: 1.013528]\n",
      "epoch:23 step:21754 [D loss: 0.408545, acc.: 86.72%] [G loss: 0.962924]\n",
      "epoch:23 step:21755 [D loss: 0.338337, acc.: 83.59%] [G loss: 1.209364]\n",
      "epoch:23 step:21756 [D loss: 0.461798, acc.: 85.16%] [G loss: 1.317900]\n",
      "epoch:23 step:21757 [D loss: 0.283401, acc.: 96.88%] [G loss: 1.345300]\n",
      "epoch:23 step:21758 [D loss: 0.164810, acc.: 98.44%] [G loss: 1.314367]\n",
      "epoch:23 step:21759 [D loss: 0.336797, acc.: 90.62%] [G loss: 1.222269]\n",
      "epoch:23 step:21760 [D loss: 0.221906, acc.: 99.22%] [G loss: 1.598024]\n",
      "epoch:23 step:21761 [D loss: 0.760345, acc.: 60.16%] [G loss: 1.425217]\n",
      "epoch:23 step:21762 [D loss: 0.875571, acc.: 43.75%] [G loss: 0.774168]\n",
      "epoch:23 step:21763 [D loss: 0.760126, acc.: 56.25%] [G loss: 1.275599]\n",
      "epoch:23 step:21764 [D loss: 0.860949, acc.: 42.19%] [G loss: 1.027816]\n",
      "epoch:23 step:21765 [D loss: 0.985923, acc.: 24.22%] [G loss: 1.142078]\n",
      "epoch:23 step:21766 [D loss: 0.829772, acc.: 43.75%] [G loss: 1.073732]\n",
      "epoch:23 step:21767 [D loss: 0.704110, acc.: 53.12%] [G loss: 1.242200]\n",
      "epoch:23 step:21768 [D loss: 0.548453, acc.: 72.66%] [G loss: 1.021439]\n",
      "epoch:23 step:21769 [D loss: 0.343021, acc.: 91.41%] [G loss: 0.986999]\n",
      "epoch:23 step:21770 [D loss: 0.300117, acc.: 94.53%] [G loss: 1.330136]\n",
      "epoch:23 step:21771 [D loss: 0.310062, acc.: 85.94%] [G loss: 1.237161]\n",
      "epoch:23 step:21772 [D loss: 0.324350, acc.: 86.72%] [G loss: 1.244951]\n",
      "epoch:23 step:21773 [D loss: 0.357627, acc.: 86.72%] [G loss: 1.454438]\n",
      "epoch:23 step:21774 [D loss: 0.366491, acc.: 96.88%] [G loss: 1.395241]\n",
      "epoch:23 step:21775 [D loss: 0.696615, acc.: 54.69%] [G loss: 1.337531]\n",
      "epoch:23 step:21776 [D loss: 0.422294, acc.: 90.62%] [G loss: 1.314229]\n",
      "epoch:23 step:21777 [D loss: 0.718881, acc.: 58.59%] [G loss: 1.182818]\n",
      "epoch:23 step:21778 [D loss: 0.663659, acc.: 58.59%] [G loss: 1.300801]\n",
      "epoch:23 step:21779 [D loss: 0.682647, acc.: 58.59%] [G loss: 1.174588]\n",
      "epoch:23 step:21780 [D loss: 0.729277, acc.: 57.03%] [G loss: 0.897049]\n",
      "epoch:23 step:21781 [D loss: 0.263032, acc.: 89.84%] [G loss: 1.285698]\n",
      "epoch:23 step:21782 [D loss: 0.291448, acc.: 89.06%] [G loss: 1.309716]\n",
      "epoch:23 step:21783 [D loss: 0.290271, acc.: 88.28%] [G loss: 1.332799]\n",
      "epoch:23 step:21784 [D loss: 0.678507, acc.: 62.50%] [G loss: 1.345535]\n",
      "epoch:23 step:21785 [D loss: 0.431126, acc.: 85.16%] [G loss: 1.251867]\n",
      "epoch:23 step:21786 [D loss: 0.307618, acc.: 87.50%] [G loss: 1.303359]\n",
      "epoch:23 step:21787 [D loss: 0.574633, acc.: 64.84%] [G loss: 1.276106]\n",
      "epoch:23 step:21788 [D loss: 0.478330, acc.: 82.03%] [G loss: 1.287442]\n",
      "epoch:23 step:21789 [D loss: 0.523149, acc.: 73.44%] [G loss: 1.398559]\n",
      "epoch:23 step:21790 [D loss: 0.521219, acc.: 78.12%] [G loss: 1.434667]\n",
      "epoch:23 step:21791 [D loss: 0.603254, acc.: 70.31%] [G loss: 1.643219]\n",
      "epoch:23 step:21792 [D loss: 0.838661, acc.: 52.34%] [G loss: 1.240115]\n",
      "epoch:23 step:21793 [D loss: 0.545697, acc.: 76.56%] [G loss: 0.700563]\n",
      "epoch:23 step:21794 [D loss: 0.338998, acc.: 83.59%] [G loss: 1.689940]\n",
      "epoch:23 step:21795 [D loss: 0.609719, acc.: 70.31%] [G loss: 0.966824]\n",
      "epoch:23 step:21796 [D loss: 0.893829, acc.: 35.16%] [G loss: 0.669701]\n",
      "epoch:23 step:21797 [D loss: 0.763128, acc.: 42.97%] [G loss: 0.880400]\n",
      "epoch:23 step:21798 [D loss: 0.735494, acc.: 52.34%] [G loss: 1.134150]\n",
      "epoch:23 step:21799 [D loss: 0.760540, acc.: 46.09%] [G loss: 0.893561]\n",
      "epoch:23 step:21800 [D loss: 0.562085, acc.: 68.75%] [G loss: 0.842920]\n",
      "##############\n",
      "[4.11964339 2.66526068 6.92012303 5.97713145 4.8437928  6.32840612\n",
      " 5.42414639 5.42786457 6.00792649 4.935885  ]\n",
      "##########\n",
      "epoch:23 step:21801 [D loss: 0.825245, acc.: 41.41%] [G loss: 0.935737]\n",
      "epoch:23 step:21802 [D loss: 0.558556, acc.: 75.00%] [G loss: 1.126478]\n",
      "epoch:23 step:21803 [D loss: 0.487733, acc.: 77.34%] [G loss: 1.139184]\n",
      "epoch:23 step:21804 [D loss: 0.543596, acc.: 72.66%] [G loss: 0.745749]\n",
      "epoch:23 step:21805 [D loss: 0.529203, acc.: 68.75%] [G loss: 0.908492]\n",
      "epoch:23 step:21806 [D loss: 0.400438, acc.: 75.00%] [G loss: 1.252769]\n",
      "epoch:23 step:21807 [D loss: 0.181478, acc.: 95.31%] [G loss: 1.328402]\n",
      "epoch:23 step:21808 [D loss: 0.279576, acc.: 96.88%] [G loss: 1.438482]\n",
      "epoch:23 step:21809 [D loss: 0.587564, acc.: 65.62%] [G loss: 1.098597]\n",
      "epoch:23 step:21810 [D loss: 0.184866, acc.: 96.09%] [G loss: 1.287315]\n",
      "epoch:23 step:21811 [D loss: 0.636106, acc.: 63.28%] [G loss: 1.149271]\n",
      "epoch:23 step:21812 [D loss: 0.171363, acc.: 97.66%] [G loss: 1.850366]\n",
      "epoch:23 step:21813 [D loss: 0.900503, acc.: 41.41%] [G loss: 1.133972]\n",
      "epoch:23 step:21814 [D loss: 0.301539, acc.: 87.50%] [G loss: 1.275273]\n",
      "epoch:23 step:21815 [D loss: 0.597037, acc.: 68.75%] [G loss: 1.340721]\n",
      "epoch:23 step:21816 [D loss: 0.704343, acc.: 57.81%] [G loss: 0.851429]\n",
      "epoch:23 step:21817 [D loss: 1.290349, acc.: 12.50%] [G loss: 1.256747]\n",
      "epoch:23 step:21818 [D loss: 0.768542, acc.: 45.31%] [G loss: 1.451955]\n",
      "epoch:23 step:21819 [D loss: 0.712136, acc.: 51.56%] [G loss: 1.077504]\n",
      "epoch:23 step:21820 [D loss: 0.505500, acc.: 74.22%] [G loss: 1.074766]\n",
      "epoch:23 step:21821 [D loss: 0.617576, acc.: 58.59%] [G loss: 1.504568]\n",
      "epoch:23 step:21822 [D loss: 0.470513, acc.: 82.03%] [G loss: 1.390532]\n",
      "epoch:23 step:21823 [D loss: 0.519397, acc.: 68.75%] [G loss: 1.584187]\n",
      "epoch:23 step:21824 [D loss: 0.514426, acc.: 74.22%] [G loss: 1.630282]\n",
      "epoch:23 step:21825 [D loss: 0.411197, acc.: 83.59%] [G loss: 1.913252]\n",
      "epoch:23 step:21826 [D loss: 0.442119, acc.: 86.72%] [G loss: 1.875207]\n",
      "epoch:23 step:21827 [D loss: 0.289741, acc.: 96.88%] [G loss: 1.569905]\n",
      "epoch:23 step:21828 [D loss: 0.412325, acc.: 79.69%] [G loss: 1.693334]\n",
      "epoch:23 step:21829 [D loss: 0.790332, acc.: 55.47%] [G loss: 1.424000]\n",
      "epoch:23 step:21830 [D loss: 0.557256, acc.: 72.66%] [G loss: 1.155086]\n",
      "epoch:23 step:21831 [D loss: 0.705788, acc.: 55.47%] [G loss: 0.902659]\n",
      "epoch:23 step:21832 [D loss: 0.557320, acc.: 71.09%] [G loss: 0.916212]\n",
      "epoch:23 step:21833 [D loss: 0.405660, acc.: 92.19%] [G loss: 1.309149]\n",
      "epoch:23 step:21834 [D loss: 0.596253, acc.: 71.88%] [G loss: 1.229770]\n",
      "epoch:23 step:21835 [D loss: 0.664582, acc.: 60.94%] [G loss: 1.079714]\n",
      "epoch:23 step:21836 [D loss: 0.658301, acc.: 62.50%] [G loss: 0.821954]\n",
      "epoch:23 step:21837 [D loss: 0.708731, acc.: 57.81%] [G loss: 0.829344]\n",
      "epoch:23 step:21838 [D loss: 0.644520, acc.: 62.50%] [G loss: 0.890868]\n",
      "epoch:23 step:21839 [D loss: 0.658635, acc.: 67.97%] [G loss: 0.924458]\n",
      "epoch:23 step:21840 [D loss: 0.430070, acc.: 81.25%] [G loss: 1.065853]\n",
      "epoch:23 step:21841 [D loss: 0.558754, acc.: 68.75%] [G loss: 1.173606]\n",
      "epoch:23 step:21842 [D loss: 0.742459, acc.: 53.91%] [G loss: 0.967540]\n",
      "epoch:23 step:21843 [D loss: 0.442849, acc.: 83.59%] [G loss: 1.190266]\n",
      "epoch:23 step:21844 [D loss: 0.989675, acc.: 38.28%] [G loss: 1.041539]\n",
      "epoch:23 step:21845 [D loss: 0.804594, acc.: 40.62%] [G loss: 0.800130]\n",
      "epoch:23 step:21846 [D loss: 0.508834, acc.: 74.22%] [G loss: 1.269742]\n",
      "epoch:23 step:21847 [D loss: 0.506626, acc.: 78.12%] [G loss: 1.446827]\n",
      "epoch:23 step:21848 [D loss: 0.279466, acc.: 98.44%] [G loss: 1.169771]\n",
      "epoch:23 step:21849 [D loss: 0.287795, acc.: 92.19%] [G loss: 1.432312]\n",
      "epoch:23 step:21850 [D loss: 0.245238, acc.: 91.41%] [G loss: 1.454145]\n",
      "epoch:23 step:21851 [D loss: 0.346254, acc.: 93.75%] [G loss: 1.583422]\n",
      "epoch:23 step:21852 [D loss: 0.522009, acc.: 76.56%] [G loss: 1.391768]\n",
      "epoch:23 step:21853 [D loss: 0.686507, acc.: 53.91%] [G loss: 1.326612]\n",
      "epoch:23 step:21854 [D loss: 0.391837, acc.: 87.50%] [G loss: 1.194376]\n",
      "epoch:23 step:21855 [D loss: 0.650395, acc.: 60.16%] [G loss: 1.385502]\n",
      "epoch:23 step:21856 [D loss: 0.741919, acc.: 52.34%] [G loss: 0.878114]\n",
      "epoch:23 step:21857 [D loss: 0.659639, acc.: 58.59%] [G loss: 1.229239]\n",
      "epoch:23 step:21858 [D loss: 0.625838, acc.: 62.50%] [G loss: 0.996749]\n",
      "epoch:23 step:21859 [D loss: 0.831037, acc.: 47.66%] [G loss: 0.759144]\n",
      "epoch:23 step:21860 [D loss: 0.806213, acc.: 48.44%] [G loss: 1.012006]\n",
      "epoch:23 step:21861 [D loss: 0.698780, acc.: 52.34%] [G loss: 1.056668]\n",
      "epoch:23 step:21862 [D loss: 0.870586, acc.: 38.28%] [G loss: 0.977875]\n",
      "epoch:23 step:21863 [D loss: 0.526878, acc.: 72.66%] [G loss: 1.088786]\n",
      "epoch:23 step:21864 [D loss: 0.548875, acc.: 71.09%] [G loss: 0.930536]\n",
      "epoch:23 step:21865 [D loss: 0.419194, acc.: 82.03%] [G loss: 1.012528]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21866 [D loss: 0.710906, acc.: 55.47%] [G loss: 1.082581]\n",
      "epoch:23 step:21867 [D loss: 0.446096, acc.: 77.34%] [G loss: 1.094004]\n",
      "epoch:23 step:21868 [D loss: 0.570822, acc.: 71.09%] [G loss: 1.129941]\n",
      "epoch:23 step:21869 [D loss: 0.421817, acc.: 89.06%] [G loss: 1.051091]\n",
      "epoch:23 step:21870 [D loss: 0.471679, acc.: 82.81%] [G loss: 1.052515]\n",
      "epoch:23 step:21871 [D loss: 0.450372, acc.: 82.03%] [G loss: 1.062941]\n",
      "epoch:23 step:21872 [D loss: 0.455222, acc.: 78.91%] [G loss: 0.532214]\n",
      "epoch:23 step:21873 [D loss: 0.425075, acc.: 83.59%] [G loss: 0.688956]\n",
      "epoch:23 step:21874 [D loss: 0.877621, acc.: 40.62%] [G loss: 1.046461]\n",
      "epoch:23 step:21875 [D loss: 0.857214, acc.: 39.06%] [G loss: 0.721362]\n",
      "epoch:23 step:21876 [D loss: 0.586110, acc.: 68.75%] [G loss: 1.193531]\n",
      "epoch:23 step:21877 [D loss: 0.651831, acc.: 57.03%] [G loss: 0.784425]\n",
      "epoch:23 step:21878 [D loss: 0.470357, acc.: 68.75%] [G loss: 0.973727]\n",
      "epoch:23 step:21879 [D loss: 0.430106, acc.: 75.00%] [G loss: 1.438144]\n",
      "epoch:23 step:21880 [D loss: 0.813216, acc.: 39.06%] [G loss: 1.485628]\n",
      "epoch:23 step:21881 [D loss: 0.857808, acc.: 48.44%] [G loss: 1.321046]\n",
      "epoch:23 step:21882 [D loss: 0.749191, acc.: 53.91%] [G loss: 0.942448]\n",
      "epoch:23 step:21883 [D loss: 0.700554, acc.: 56.25%] [G loss: 1.110548]\n",
      "epoch:23 step:21884 [D loss: 0.513081, acc.: 76.56%] [G loss: 1.103879]\n",
      "epoch:23 step:21885 [D loss: 0.530603, acc.: 72.66%] [G loss: 1.159943]\n",
      "epoch:23 step:21886 [D loss: 0.616208, acc.: 67.97%] [G loss: 0.905865]\n",
      "epoch:23 step:21887 [D loss: 0.387629, acc.: 83.59%] [G loss: 1.272818]\n",
      "epoch:23 step:21888 [D loss: 0.722641, acc.: 53.91%] [G loss: 1.250521]\n",
      "epoch:23 step:21889 [D loss: 0.614384, acc.: 67.19%] [G loss: 1.101173]\n",
      "epoch:23 step:21890 [D loss: 0.658173, acc.: 61.72%] [G loss: 1.166420]\n",
      "epoch:23 step:21891 [D loss: 0.642450, acc.: 60.94%] [G loss: 1.026341]\n",
      "epoch:23 step:21892 [D loss: 0.711753, acc.: 56.25%] [G loss: 1.171148]\n",
      "epoch:23 step:21893 [D loss: 0.302420, acc.: 91.41%] [G loss: 1.156233]\n",
      "epoch:23 step:21894 [D loss: 0.370565, acc.: 78.91%] [G loss: 1.265700]\n",
      "epoch:23 step:21895 [D loss: 0.258715, acc.: 96.09%] [G loss: 1.192365]\n",
      "epoch:23 step:21896 [D loss: 0.181198, acc.: 97.66%] [G loss: 1.521744]\n",
      "epoch:23 step:21897 [D loss: 0.218133, acc.: 93.75%] [G loss: 1.482589]\n",
      "epoch:23 step:21898 [D loss: 0.167835, acc.: 99.22%] [G loss: 1.399271]\n",
      "epoch:23 step:21899 [D loss: 0.674704, acc.: 60.16%] [G loss: 1.565416]\n",
      "epoch:23 step:21900 [D loss: 0.780114, acc.: 56.25%] [G loss: 1.462978]\n",
      "epoch:23 step:21901 [D loss: 0.536719, acc.: 73.44%] [G loss: 1.191614]\n",
      "epoch:23 step:21902 [D loss: 0.716315, acc.: 55.47%] [G loss: 0.984197]\n",
      "epoch:23 step:21903 [D loss: 0.824392, acc.: 41.41%] [G loss: 1.414448]\n",
      "epoch:23 step:21904 [D loss: 0.577270, acc.: 72.66%] [G loss: 1.102885]\n",
      "epoch:23 step:21905 [D loss: 0.627898, acc.: 64.84%] [G loss: 0.896786]\n",
      "epoch:23 step:21906 [D loss: 0.671133, acc.: 60.94%] [G loss: 1.148233]\n",
      "epoch:23 step:21907 [D loss: 0.655178, acc.: 62.50%] [G loss: 1.038185]\n",
      "epoch:23 step:21908 [D loss: 0.628477, acc.: 64.06%] [G loss: 0.832727]\n",
      "epoch:23 step:21909 [D loss: 0.626987, acc.: 65.62%] [G loss: 0.977298]\n",
      "epoch:23 step:21910 [D loss: 0.680400, acc.: 59.38%] [G loss: 0.921271]\n",
      "epoch:23 step:21911 [D loss: 0.636444, acc.: 62.50%] [G loss: 0.966426]\n",
      "epoch:23 step:21912 [D loss: 0.699657, acc.: 63.28%] [G loss: 0.987098]\n",
      "epoch:23 step:21913 [D loss: 0.479725, acc.: 78.12%] [G loss: 0.941681]\n",
      "epoch:23 step:21914 [D loss: 0.389707, acc.: 87.50%] [G loss: 0.968623]\n",
      "epoch:23 step:21915 [D loss: 0.551899, acc.: 78.12%] [G loss: 0.903792]\n",
      "epoch:23 step:21916 [D loss: 0.382028, acc.: 83.59%] [G loss: 0.958073]\n",
      "epoch:23 step:21917 [D loss: 0.248013, acc.: 94.53%] [G loss: 1.211565]\n",
      "epoch:23 step:21918 [D loss: 0.292591, acc.: 96.88%] [G loss: 1.017643]\n",
      "epoch:23 step:21919 [D loss: 0.594398, acc.: 68.75%] [G loss: 1.236893]\n",
      "epoch:23 step:21920 [D loss: 0.641340, acc.: 65.62%] [G loss: 1.115916]\n",
      "epoch:23 step:21921 [D loss: 0.516077, acc.: 74.22%] [G loss: 1.038723]\n",
      "epoch:23 step:21922 [D loss: 0.373867, acc.: 89.06%] [G loss: 1.120344]\n",
      "epoch:23 step:21923 [D loss: 0.616480, acc.: 66.41%] [G loss: 1.110427]\n",
      "epoch:23 step:21924 [D loss: 0.721546, acc.: 52.34%] [G loss: 0.944999]\n",
      "epoch:23 step:21925 [D loss: 0.685072, acc.: 57.81%] [G loss: 0.957574]\n",
      "epoch:23 step:21926 [D loss: 0.621619, acc.: 67.97%] [G loss: 1.080886]\n",
      "epoch:23 step:21927 [D loss: 0.831111, acc.: 51.56%] [G loss: 0.632597]\n",
      "epoch:23 step:21928 [D loss: 0.332174, acc.: 82.81%] [G loss: 1.095045]\n",
      "epoch:23 step:21929 [D loss: 0.242684, acc.: 93.75%] [G loss: 1.281418]\n",
      "epoch:23 step:21930 [D loss: 0.719642, acc.: 53.12%] [G loss: 1.135420]\n",
      "epoch:23 step:21931 [D loss: 0.625591, acc.: 64.84%] [G loss: 1.101639]\n",
      "epoch:23 step:21932 [D loss: 0.565944, acc.: 73.44%] [G loss: 0.927445]\n",
      "epoch:23 step:21933 [D loss: 0.632864, acc.: 58.59%] [G loss: 0.806312]\n",
      "epoch:23 step:21934 [D loss: 0.617250, acc.: 68.75%] [G loss: 0.959805]\n",
      "epoch:23 step:21935 [D loss: 0.441828, acc.: 82.81%] [G loss: 1.114282]\n",
      "epoch:23 step:21936 [D loss: 0.630239, acc.: 61.72%] [G loss: 1.150506]\n",
      "epoch:23 step:21937 [D loss: 0.659212, acc.: 64.84%] [G loss: 1.040820]\n",
      "epoch:23 step:21938 [D loss: 0.639303, acc.: 60.94%] [G loss: 1.182139]\n",
      "epoch:23 step:21939 [D loss: 0.633117, acc.: 60.94%] [G loss: 0.883243]\n",
      "epoch:23 step:21940 [D loss: 0.413420, acc.: 81.25%] [G loss: 1.062600]\n",
      "epoch:23 step:21941 [D loss: 0.412197, acc.: 85.94%] [G loss: 1.009524]\n",
      "epoch:23 step:21942 [D loss: 0.582400, acc.: 77.34%] [G loss: 1.202376]\n",
      "epoch:23 step:21943 [D loss: 0.457447, acc.: 82.03%] [G loss: 1.093357]\n",
      "epoch:23 step:21944 [D loss: 0.238793, acc.: 92.97%] [G loss: 1.195150]\n",
      "epoch:23 step:21945 [D loss: 0.591769, acc.: 72.66%] [G loss: 1.035078]\n",
      "epoch:23 step:21946 [D loss: 0.628321, acc.: 64.06%] [G loss: 1.172155]\n",
      "epoch:23 step:21947 [D loss: 0.249419, acc.: 90.62%] [G loss: 1.070004]\n",
      "epoch:23 step:21948 [D loss: 0.173648, acc.: 96.09%] [G loss: 1.219567]\n",
      "epoch:23 step:21949 [D loss: 0.167636, acc.: 97.66%] [G loss: 1.463815]\n",
      "epoch:23 step:21950 [D loss: 0.209151, acc.: 95.31%] [G loss: 1.373543]\n",
      "epoch:23 step:21951 [D loss: 0.119532, acc.: 98.44%] [G loss: 1.735801]\n",
      "epoch:23 step:21952 [D loss: 0.154635, acc.: 97.66%] [G loss: 1.741018]\n",
      "epoch:23 step:21953 [D loss: 0.137705, acc.: 100.00%] [G loss: 1.959629]\n",
      "epoch:23 step:21954 [D loss: 0.246270, acc.: 92.19%] [G loss: 2.120378]\n",
      "epoch:23 step:21955 [D loss: 0.147650, acc.: 99.22%] [G loss: 1.915161]\n",
      "epoch:23 step:21956 [D loss: 0.301470, acc.: 83.59%] [G loss: 2.208233]\n",
      "epoch:23 step:21957 [D loss: 0.087638, acc.: 100.00%] [G loss: 2.038010]\n",
      "epoch:23 step:21958 [D loss: 0.066628, acc.: 100.00%] [G loss: 2.834876]\n",
      "epoch:23 step:21959 [D loss: 0.209845, acc.: 95.31%] [G loss: 2.332461]\n",
      "epoch:23 step:21960 [D loss: 0.145421, acc.: 96.09%] [G loss: 1.811918]\n",
      "epoch:23 step:21961 [D loss: 0.376585, acc.: 89.06%] [G loss: 1.648774]\n",
      "epoch:23 step:21962 [D loss: 1.496489, acc.: 11.72%] [G loss: 2.243756]\n",
      "epoch:23 step:21963 [D loss: 0.257091, acc.: 92.97%] [G loss: 1.324358]\n",
      "epoch:23 step:21964 [D loss: 0.348787, acc.: 85.16%] [G loss: 0.458831]\n",
      "epoch:23 step:21965 [D loss: 0.851186, acc.: 53.91%] [G loss: 2.479290]\n",
      "epoch:23 step:21966 [D loss: 0.566046, acc.: 67.19%] [G loss: 1.003813]\n",
      "epoch:23 step:21967 [D loss: 0.965786, acc.: 42.97%] [G loss: 1.148790]\n",
      "epoch:23 step:21968 [D loss: 0.352823, acc.: 88.28%] [G loss: 1.600241]\n",
      "epoch:23 step:21969 [D loss: 0.187915, acc.: 96.88%] [G loss: 1.893985]\n",
      "epoch:23 step:21970 [D loss: 0.388935, acc.: 79.69%] [G loss: 1.981921]\n",
      "epoch:23 step:21971 [D loss: 1.189258, acc.: 30.47%] [G loss: 1.428728]\n",
      "epoch:23 step:21972 [D loss: 1.750521, acc.: 17.19%] [G loss: 1.532268]\n",
      "epoch:23 step:21973 [D loss: 1.209186, acc.: 40.62%] [G loss: 1.622447]\n",
      "epoch:23 step:21974 [D loss: 0.959411, acc.: 47.66%] [G loss: 1.099189]\n",
      "epoch:23 step:21975 [D loss: 0.809768, acc.: 45.31%] [G loss: 1.415700]\n",
      "epoch:23 step:21976 [D loss: 0.648551, acc.: 60.16%] [G loss: 1.308957]\n",
      "epoch:23 step:21977 [D loss: 0.907521, acc.: 44.53%] [G loss: 1.431957]\n",
      "epoch:23 step:21978 [D loss: 0.552097, acc.: 74.22%] [G loss: 1.023769]\n",
      "epoch:23 step:21979 [D loss: 0.378491, acc.: 88.28%] [G loss: 1.062071]\n",
      "epoch:23 step:21980 [D loss: 0.811818, acc.: 50.00%] [G loss: 0.947351]\n",
      "epoch:23 step:21981 [D loss: 0.568594, acc.: 67.97%] [G loss: 0.562437]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21982 [D loss: 0.993513, acc.: 32.03%] [G loss: 1.002342]\n",
      "epoch:23 step:21983 [D loss: 0.708760, acc.: 53.12%] [G loss: 1.454628]\n",
      "epoch:23 step:21984 [D loss: 0.750651, acc.: 49.22%] [G loss: 1.342871]\n",
      "epoch:23 step:21985 [D loss: 0.696854, acc.: 57.81%] [G loss: 1.424363]\n",
      "epoch:23 step:21986 [D loss: 0.657960, acc.: 57.03%] [G loss: 1.106780]\n",
      "epoch:23 step:21987 [D loss: 0.618255, acc.: 56.25%] [G loss: 1.552358]\n",
      "epoch:23 step:21988 [D loss: 0.704006, acc.: 53.91%] [G loss: 1.445635]\n",
      "epoch:23 step:21989 [D loss: 0.794678, acc.: 51.56%] [G loss: 1.297281]\n",
      "epoch:23 step:21990 [D loss: 0.644055, acc.: 57.81%] [G loss: 1.293706]\n",
      "epoch:23 step:21991 [D loss: 0.626823, acc.: 63.28%] [G loss: 1.036670]\n",
      "epoch:23 step:21992 [D loss: 0.603687, acc.: 63.28%] [G loss: 1.110608]\n",
      "epoch:23 step:21993 [D loss: 0.633034, acc.: 60.94%] [G loss: 1.101994]\n",
      "epoch:23 step:21994 [D loss: 0.558195, acc.: 69.53%] [G loss: 1.188331]\n",
      "epoch:23 step:21995 [D loss: 0.606696, acc.: 67.19%] [G loss: 1.052842]\n",
      "epoch:23 step:21996 [D loss: 0.604049, acc.: 66.41%] [G loss: 1.014562]\n",
      "epoch:23 step:21997 [D loss: 0.635700, acc.: 65.62%] [G loss: 1.102652]\n",
      "epoch:23 step:21998 [D loss: 0.617695, acc.: 67.19%] [G loss: 0.963574]\n",
      "epoch:23 step:21999 [D loss: 0.485075, acc.: 90.62%] [G loss: 1.207367]\n",
      "epoch:23 step:22000 [D loss: 0.417263, acc.: 96.09%] [G loss: 1.293081]\n",
      "##############\n",
      "[4.70560033 3.05776091 7.14865185 6.39472903 5.00954579 6.40361235\n",
      " 5.71985502 5.68087159 5.64143558 5.24507725]\n",
      "##########\n",
      "epoch:23 step:22001 [D loss: 0.428981, acc.: 90.62%] [G loss: 1.242310]\n",
      "epoch:23 step:22002 [D loss: 0.351635, acc.: 96.88%] [G loss: 1.436973]\n",
      "epoch:23 step:22003 [D loss: 0.299954, acc.: 98.44%] [G loss: 1.375566]\n",
      "epoch:23 step:22004 [D loss: 0.293707, acc.: 96.88%] [G loss: 1.787793]\n",
      "epoch:23 step:22005 [D loss: 0.353340, acc.: 93.75%] [G loss: 1.535741]\n",
      "epoch:23 step:22006 [D loss: 0.368538, acc.: 92.97%] [G loss: 1.678135]\n",
      "epoch:23 step:22007 [D loss: 0.225343, acc.: 97.66%] [G loss: 1.750730]\n",
      "epoch:23 step:22008 [D loss: 0.317652, acc.: 92.19%] [G loss: 2.381356]\n",
      "epoch:23 step:22009 [D loss: 0.553781, acc.: 71.09%] [G loss: 1.351375]\n",
      "epoch:23 step:22010 [D loss: 0.462814, acc.: 83.59%] [G loss: 1.918007]\n",
      "epoch:23 step:22011 [D loss: 0.528332, acc.: 78.91%] [G loss: 1.263757]\n",
      "epoch:23 step:22012 [D loss: 0.984563, acc.: 42.97%] [G loss: 0.830944]\n",
      "epoch:23 step:22013 [D loss: 1.103632, acc.: 35.94%] [G loss: 0.988847]\n",
      "epoch:23 step:22014 [D loss: 0.647021, acc.: 61.72%] [G loss: 0.917395]\n",
      "epoch:23 step:22015 [D loss: 0.502110, acc.: 72.66%] [G loss: 0.892918]\n",
      "epoch:23 step:22016 [D loss: 0.476160, acc.: 75.00%] [G loss: 1.167311]\n",
      "epoch:23 step:22017 [D loss: 0.419992, acc.: 89.84%] [G loss: 1.350219]\n",
      "epoch:23 step:22018 [D loss: 0.422015, acc.: 87.50%] [G loss: 1.318469]\n",
      "epoch:23 step:22019 [D loss: 0.275002, acc.: 92.97%] [G loss: 1.405255]\n",
      "epoch:23 step:22020 [D loss: 0.215610, acc.: 99.22%] [G loss: 1.733167]\n",
      "epoch:23 step:22021 [D loss: 0.166625, acc.: 98.44%] [G loss: 1.863469]\n",
      "epoch:23 step:22022 [D loss: 0.186341, acc.: 96.88%] [G loss: 1.925789]\n",
      "epoch:23 step:22023 [D loss: 0.297707, acc.: 97.66%] [G loss: 1.238729]\n",
      "epoch:23 step:22024 [D loss: 1.368535, acc.: 41.41%] [G loss: 1.406750]\n",
      "epoch:23 step:22025 [D loss: 0.951211, acc.: 36.72%] [G loss: 0.955993]\n",
      "epoch:23 step:22026 [D loss: 0.674644, acc.: 60.16%] [G loss: 1.234147]\n",
      "epoch:23 step:22027 [D loss: 0.550948, acc.: 67.19%] [G loss: 0.837699]\n",
      "epoch:23 step:22028 [D loss: 0.537761, acc.: 75.78%] [G loss: 0.912775]\n",
      "epoch:23 step:22029 [D loss: 0.562130, acc.: 75.00%] [G loss: 1.045740]\n",
      "epoch:23 step:22030 [D loss: 0.376225, acc.: 82.81%] [G loss: 0.833173]\n",
      "epoch:23 step:22031 [D loss: 0.589845, acc.: 66.41%] [G loss: 1.652061]\n",
      "epoch:23 step:22032 [D loss: 0.315893, acc.: 85.94%] [G loss: 1.452218]\n",
      "epoch:23 step:22033 [D loss: 1.154961, acc.: 39.06%] [G loss: 0.965049]\n",
      "epoch:23 step:22034 [D loss: 0.775731, acc.: 48.44%] [G loss: 0.857221]\n",
      "epoch:23 step:22035 [D loss: 0.714601, acc.: 55.47%] [G loss: 0.916445]\n",
      "epoch:23 step:22036 [D loss: 0.748943, acc.: 50.00%] [G loss: 1.033123]\n",
      "epoch:23 step:22037 [D loss: 0.783758, acc.: 45.31%] [G loss: 0.828281]\n",
      "epoch:23 step:22038 [D loss: 0.764763, acc.: 44.53%] [G loss: 0.885091]\n",
      "epoch:23 step:22039 [D loss: 0.658934, acc.: 57.81%] [G loss: 1.167086]\n",
      "epoch:23 step:22040 [D loss: 0.588045, acc.: 72.66%] [G loss: 1.009652]\n",
      "epoch:23 step:22041 [D loss: 0.605179, acc.: 65.62%] [G loss: 1.071231]\n",
      "epoch:23 step:22042 [D loss: 0.628630, acc.: 61.72%] [G loss: 1.259994]\n",
      "epoch:23 step:22043 [D loss: 0.749071, acc.: 47.66%] [G loss: 1.171103]\n",
      "epoch:23 step:22044 [D loss: 0.752772, acc.: 45.31%] [G loss: 1.131326]\n",
      "epoch:23 step:22045 [D loss: 0.596886, acc.: 66.41%] [G loss: 1.110882]\n",
      "epoch:23 step:22046 [D loss: 0.610340, acc.: 63.28%] [G loss: 0.948856]\n",
      "epoch:23 step:22047 [D loss: 0.700102, acc.: 50.78%] [G loss: 1.037362]\n",
      "epoch:23 step:22048 [D loss: 0.526533, acc.: 76.56%] [G loss: 1.229202]\n",
      "epoch:23 step:22049 [D loss: 0.466030, acc.: 82.81%] [G loss: 1.509871]\n",
      "epoch:23 step:22050 [D loss: 0.398590, acc.: 91.41%] [G loss: 1.662707]\n",
      "epoch:23 step:22051 [D loss: 0.791467, acc.: 44.53%] [G loss: 1.302243]\n",
      "epoch:23 step:22052 [D loss: 0.643208, acc.: 60.16%] [G loss: 1.247019]\n",
      "epoch:23 step:22053 [D loss: 0.671547, acc.: 55.47%] [G loss: 1.286473]\n",
      "epoch:23 step:22054 [D loss: 0.505659, acc.: 77.34%] [G loss: 1.247318]\n",
      "epoch:23 step:22055 [D loss: 0.418995, acc.: 86.72%] [G loss: 1.017328]\n",
      "epoch:23 step:22056 [D loss: 0.492332, acc.: 75.78%] [G loss: 1.051855]\n",
      "epoch:23 step:22057 [D loss: 0.687029, acc.: 56.25%] [G loss: 0.966376]\n",
      "epoch:23 step:22058 [D loss: 0.509585, acc.: 77.34%] [G loss: 0.964713]\n",
      "epoch:23 step:22059 [D loss: 0.501254, acc.: 75.78%] [G loss: 0.934435]\n",
      "epoch:23 step:22060 [D loss: 0.753653, acc.: 54.69%] [G loss: 0.971710]\n",
      "epoch:23 step:22061 [D loss: 0.492830, acc.: 82.81%] [G loss: 1.094975]\n",
      "epoch:23 step:22062 [D loss: 0.389623, acc.: 85.16%] [G loss: 1.085174]\n",
      "epoch:23 step:22063 [D loss: 0.529085, acc.: 76.56%] [G loss: 1.011534]\n",
      "epoch:23 step:22064 [D loss: 0.413785, acc.: 93.75%] [G loss: 1.237056]\n",
      "epoch:23 step:22065 [D loss: 0.369232, acc.: 95.31%] [G loss: 1.407487]\n",
      "epoch:23 step:22066 [D loss: 0.312141, acc.: 92.19%] [G loss: 1.506576]\n",
      "epoch:23 step:22067 [D loss: 0.699547, acc.: 61.72%] [G loss: 1.341743]\n",
      "epoch:23 step:22068 [D loss: 0.455122, acc.: 78.91%] [G loss: 1.290837]\n",
      "epoch:23 step:22069 [D loss: 0.669266, acc.: 62.50%] [G loss: 1.375756]\n",
      "epoch:23 step:22070 [D loss: 0.681116, acc.: 60.94%] [G loss: 1.109029]\n",
      "epoch:23 step:22071 [D loss: 0.622825, acc.: 66.41%] [G loss: 1.104406]\n",
      "epoch:23 step:22072 [D loss: 0.648834, acc.: 61.72%] [G loss: 1.158940]\n",
      "epoch:23 step:22073 [D loss: 0.601025, acc.: 64.06%] [G loss: 1.172758]\n",
      "epoch:23 step:22074 [D loss: 0.611214, acc.: 62.50%] [G loss: 0.945266]\n",
      "epoch:23 step:22075 [D loss: 0.341871, acc.: 89.06%] [G loss: 1.191672]\n",
      "epoch:23 step:22076 [D loss: 0.596306, acc.: 64.06%] [G loss: 1.553907]\n",
      "epoch:23 step:22077 [D loss: 0.409520, acc.: 87.50%] [G loss: 1.405031]\n",
      "epoch:23 step:22078 [D loss: 0.313506, acc.: 92.19%] [G loss: 1.471258]\n",
      "epoch:23 step:22079 [D loss: 0.491849, acc.: 79.69%] [G loss: 1.043611]\n",
      "epoch:23 step:22080 [D loss: 0.427545, acc.: 85.94%] [G loss: 1.418138]\n",
      "epoch:23 step:22081 [D loss: 0.303000, acc.: 89.06%] [G loss: 1.414198]\n",
      "epoch:23 step:22082 [D loss: 0.757601, acc.: 61.72%] [G loss: 0.880929]\n",
      "epoch:23 step:22083 [D loss: 0.716731, acc.: 57.81%] [G loss: 0.900183]\n",
      "epoch:23 step:22084 [D loss: 0.751998, acc.: 53.12%] [G loss: 0.948930]\n",
      "epoch:23 step:22085 [D loss: 0.648801, acc.: 57.03%] [G loss: 0.933878]\n",
      "epoch:23 step:22086 [D loss: 0.390063, acc.: 80.47%] [G loss: 1.209083]\n",
      "epoch:23 step:22087 [D loss: 0.374288, acc.: 78.91%] [G loss: 1.421098]\n",
      "epoch:23 step:22088 [D loss: 0.286121, acc.: 92.19%] [G loss: 1.912643]\n",
      "epoch:23 step:22089 [D loss: 0.434660, acc.: 78.12%] [G loss: 1.389193]\n",
      "epoch:23 step:22090 [D loss: 0.470360, acc.: 78.12%] [G loss: 1.375127]\n",
      "epoch:23 step:22091 [D loss: 0.489470, acc.: 72.66%] [G loss: 1.959241]\n",
      "epoch:23 step:22092 [D loss: 0.402605, acc.: 87.50%] [G loss: 1.278382]\n",
      "epoch:23 step:22093 [D loss: 0.814189, acc.: 49.22%] [G loss: 1.227906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22094 [D loss: 0.206523, acc.: 92.19%] [G loss: 1.587410]\n",
      "epoch:23 step:22095 [D loss: 0.595639, acc.: 68.75%] [G loss: 1.812964]\n",
      "epoch:23 step:22096 [D loss: 0.458387, acc.: 78.12%] [G loss: 1.042268]\n",
      "epoch:23 step:22097 [D loss: 0.629741, acc.: 60.16%] [G loss: 1.499814]\n",
      "epoch:23 step:22098 [D loss: 0.406439, acc.: 83.59%] [G loss: 1.450749]\n",
      "epoch:23 step:22099 [D loss: 0.368143, acc.: 87.50%] [G loss: 1.565065]\n",
      "epoch:23 step:22100 [D loss: 0.268664, acc.: 92.97%] [G loss: 1.450290]\n",
      "epoch:23 step:22101 [D loss: 0.182588, acc.: 96.09%] [G loss: 1.543632]\n",
      "epoch:23 step:22102 [D loss: 0.326357, acc.: 90.62%] [G loss: 1.705536]\n",
      "epoch:23 step:22103 [D loss: 0.331888, acc.: 90.62%] [G loss: 1.694367]\n",
      "epoch:23 step:22104 [D loss: 0.390597, acc.: 85.94%] [G loss: 1.720729]\n",
      "epoch:23 step:22105 [D loss: 0.130695, acc.: 97.66%] [G loss: 1.739148]\n",
      "epoch:23 step:22106 [D loss: 0.205662, acc.: 96.09%] [G loss: 1.599690]\n",
      "epoch:23 step:22107 [D loss: 0.186521, acc.: 96.88%] [G loss: 1.677997]\n",
      "epoch:23 step:22108 [D loss: 0.139747, acc.: 99.22%] [G loss: 2.084843]\n",
      "epoch:23 step:22109 [D loss: 0.201987, acc.: 95.31%] [G loss: 2.390918]\n",
      "epoch:23 step:22110 [D loss: 0.549387, acc.: 70.31%] [G loss: 1.773083]\n",
      "epoch:23 step:22111 [D loss: 0.743530, acc.: 59.38%] [G loss: 1.721826]\n",
      "epoch:23 step:22112 [D loss: 0.278365, acc.: 92.97%] [G loss: 1.672123]\n",
      "epoch:23 step:22113 [D loss: 0.647394, acc.: 65.62%] [G loss: 1.440480]\n",
      "epoch:23 step:22114 [D loss: 0.357649, acc.: 87.50%] [G loss: 1.428476]\n",
      "epoch:23 step:22115 [D loss: 0.351033, acc.: 84.38%] [G loss: 1.882793]\n",
      "epoch:23 step:22116 [D loss: 0.643058, acc.: 69.53%] [G loss: 1.077367]\n",
      "epoch:23 step:22117 [D loss: 0.750003, acc.: 61.72%] [G loss: 1.675532]\n",
      "epoch:23 step:22118 [D loss: 0.214943, acc.: 96.09%] [G loss: 1.538966]\n",
      "epoch:23 step:22119 [D loss: 0.654309, acc.: 64.84%] [G loss: 1.352902]\n",
      "epoch:23 step:22120 [D loss: 0.792616, acc.: 46.88%] [G loss: 1.235525]\n",
      "epoch:23 step:22121 [D loss: 0.650848, acc.: 64.06%] [G loss: 1.212587]\n",
      "epoch:23 step:22122 [D loss: 0.542300, acc.: 71.09%] [G loss: 1.170721]\n",
      "epoch:23 step:22123 [D loss: 1.048499, acc.: 37.50%] [G loss: 1.246665]\n",
      "epoch:23 step:22124 [D loss: 0.708653, acc.: 54.69%] [G loss: 1.275502]\n",
      "epoch:23 step:22125 [D loss: 0.715651, acc.: 54.69%] [G loss: 1.415250]\n",
      "epoch:23 step:22126 [D loss: 0.611781, acc.: 63.28%] [G loss: 1.206377]\n",
      "epoch:23 step:22127 [D loss: 0.476290, acc.: 78.91%] [G loss: 1.587791]\n",
      "epoch:23 step:22128 [D loss: 0.473251, acc.: 77.34%] [G loss: 1.497279]\n",
      "epoch:23 step:22129 [D loss: 0.514946, acc.: 68.75%] [G loss: 1.604608]\n",
      "epoch:23 step:22130 [D loss: 0.483877, acc.: 80.47%] [G loss: 1.357567]\n",
      "epoch:23 step:22131 [D loss: 0.675560, acc.: 62.50%] [G loss: 1.501499]\n",
      "epoch:23 step:22132 [D loss: 0.592734, acc.: 65.62%] [G loss: 1.185734]\n",
      "epoch:23 step:22133 [D loss: 0.640231, acc.: 65.62%] [G loss: 1.371903]\n",
      "epoch:23 step:22134 [D loss: 0.345314, acc.: 90.62%] [G loss: 1.606051]\n",
      "epoch:23 step:22135 [D loss: 0.430695, acc.: 82.03%] [G loss: 1.503841]\n",
      "epoch:23 step:22136 [D loss: 0.389163, acc.: 84.38%] [G loss: 1.320856]\n",
      "epoch:23 step:22137 [D loss: 0.408548, acc.: 85.16%] [G loss: 1.361423]\n",
      "epoch:23 step:22138 [D loss: 0.445307, acc.: 83.59%] [G loss: 1.325754]\n",
      "epoch:23 step:22139 [D loss: 0.417835, acc.: 81.25%] [G loss: 1.125040]\n",
      "epoch:23 step:22140 [D loss: 0.314605, acc.: 84.38%] [G loss: 1.682208]\n",
      "epoch:23 step:22141 [D loss: 1.182751, acc.: 25.78%] [G loss: 1.317508]\n",
      "epoch:23 step:22142 [D loss: 0.221707, acc.: 92.97%] [G loss: 2.030998]\n",
      "epoch:23 step:22143 [D loss: 0.110973, acc.: 99.22%] [G loss: 2.017463]\n",
      "epoch:23 step:22144 [D loss: 0.475855, acc.: 76.56%] [G loss: 1.299769]\n",
      "epoch:23 step:22145 [D loss: 0.939960, acc.: 53.12%] [G loss: 1.691599]\n",
      "epoch:23 step:22146 [D loss: 0.827788, acc.: 53.12%] [G loss: 1.527386]\n",
      "epoch:23 step:22147 [D loss: 0.288372, acc.: 91.41%] [G loss: 1.509656]\n",
      "epoch:23 step:22148 [D loss: 0.419822, acc.: 83.59%] [G loss: 1.683151]\n",
      "epoch:23 step:22149 [D loss: 0.160342, acc.: 96.88%] [G loss: 1.902090]\n",
      "epoch:23 step:22150 [D loss: 0.286320, acc.: 95.31%] [G loss: 1.588685]\n",
      "epoch:23 step:22151 [D loss: 0.771748, acc.: 54.69%] [G loss: 1.556975]\n",
      "epoch:23 step:22152 [D loss: 0.811232, acc.: 53.91%] [G loss: 1.266390]\n",
      "epoch:23 step:22153 [D loss: 0.663909, acc.: 61.72%] [G loss: 1.143244]\n",
      "epoch:23 step:22154 [D loss: 0.274856, acc.: 92.97%] [G loss: 1.269106]\n",
      "epoch:23 step:22155 [D loss: 0.240191, acc.: 89.06%] [G loss: 1.524830]\n",
      "epoch:23 step:22156 [D loss: 0.226586, acc.: 96.09%] [G loss: 1.407481]\n",
      "epoch:23 step:22157 [D loss: 0.649454, acc.: 65.62%] [G loss: 1.358675]\n",
      "epoch:23 step:22158 [D loss: 0.870327, acc.: 48.44%] [G loss: 1.189112]\n",
      "epoch:23 step:22159 [D loss: 0.917615, acc.: 40.62%] [G loss: 0.989556]\n",
      "epoch:23 step:22160 [D loss: 0.706669, acc.: 55.47%] [G loss: 1.086976]\n",
      "epoch:23 step:22161 [D loss: 0.439405, acc.: 79.69%] [G loss: 1.214004]\n",
      "epoch:23 step:22162 [D loss: 0.793038, acc.: 50.00%] [G loss: 1.379934]\n",
      "epoch:23 step:22163 [D loss: 0.943313, acc.: 31.25%] [G loss: 1.353343]\n",
      "epoch:23 step:22164 [D loss: 0.350693, acc.: 86.72%] [G loss: 1.263276]\n",
      "epoch:23 step:22165 [D loss: 0.409603, acc.: 85.94%] [G loss: 1.484867]\n",
      "epoch:23 step:22166 [D loss: 0.364074, acc.: 85.16%] [G loss: 1.560251]\n",
      "epoch:23 step:22167 [D loss: 0.167383, acc.: 96.88%] [G loss: 1.530453]\n",
      "epoch:23 step:22168 [D loss: 0.165126, acc.: 97.66%] [G loss: 1.701025]\n",
      "epoch:23 step:22169 [D loss: 0.818183, acc.: 54.69%] [G loss: 1.885854]\n",
      "epoch:23 step:22170 [D loss: 0.622913, acc.: 65.62%] [G loss: 1.161950]\n",
      "epoch:23 step:22171 [D loss: 0.826083, acc.: 46.09%] [G loss: 0.764508]\n",
      "epoch:23 step:22172 [D loss: 0.526398, acc.: 69.53%] [G loss: 0.784042]\n",
      "epoch:23 step:22173 [D loss: 0.391813, acc.: 78.12%] [G loss: 0.635573]\n",
      "epoch:23 step:22174 [D loss: 1.028061, acc.: 53.12%] [G loss: 2.026292]\n",
      "epoch:23 step:22175 [D loss: 0.312685, acc.: 89.06%] [G loss: 1.607815]\n",
      "epoch:23 step:22176 [D loss: 0.902080, acc.: 55.47%] [G loss: 1.324934]\n",
      "epoch:23 step:22177 [D loss: 0.555085, acc.: 65.62%] [G loss: 1.248618]\n",
      "epoch:23 step:22178 [D loss: 0.708251, acc.: 64.84%] [G loss: 1.260929]\n",
      "epoch:23 step:22179 [D loss: 0.888860, acc.: 39.06%] [G loss: 1.002230]\n",
      "epoch:23 step:22180 [D loss: 0.752610, acc.: 58.59%] [G loss: 0.907022]\n",
      "epoch:23 step:22181 [D loss: 0.679163, acc.: 64.84%] [G loss: 0.474501]\n",
      "epoch:23 step:22182 [D loss: 0.791796, acc.: 50.00%] [G loss: 1.359782]\n",
      "epoch:23 step:22183 [D loss: 0.534849, acc.: 69.53%] [G loss: 1.096579]\n",
      "epoch:23 step:22184 [D loss: 0.370100, acc.: 85.16%] [G loss: 0.802883]\n",
      "epoch:23 step:22185 [D loss: 0.638350, acc.: 67.19%] [G loss: 1.672849]\n",
      "epoch:23 step:22186 [D loss: 0.501108, acc.: 78.91%] [G loss: 1.487376]\n",
      "epoch:23 step:22187 [D loss: 0.726917, acc.: 52.34%] [G loss: 1.598425]\n",
      "epoch:23 step:22188 [D loss: 0.799412, acc.: 47.66%] [G loss: 0.872997]\n",
      "epoch:23 step:22189 [D loss: 0.728523, acc.: 54.69%] [G loss: 1.009435]\n",
      "epoch:23 step:22190 [D loss: 0.785775, acc.: 46.88%] [G loss: 1.177392]\n",
      "epoch:23 step:22191 [D loss: 0.861116, acc.: 35.16%] [G loss: 1.068422]\n",
      "epoch:23 step:22192 [D loss: 0.432499, acc.: 82.03%] [G loss: 1.285891]\n",
      "epoch:23 step:22193 [D loss: 0.840272, acc.: 45.31%] [G loss: 1.164796]\n",
      "epoch:23 step:22194 [D loss: 0.845885, acc.: 44.53%] [G loss: 1.196490]\n",
      "epoch:23 step:22195 [D loss: 0.644887, acc.: 60.16%] [G loss: 1.046197]\n",
      "epoch:23 step:22196 [D loss: 0.516452, acc.: 78.91%] [G loss: 0.913972]\n",
      "epoch:23 step:22197 [D loss: 0.491297, acc.: 82.03%] [G loss: 0.976098]\n",
      "epoch:23 step:22198 [D loss: 0.632218, acc.: 60.94%] [G loss: 0.846577]\n",
      "epoch:23 step:22199 [D loss: 0.606558, acc.: 67.97%] [G loss: 1.182583]\n",
      "epoch:23 step:22200 [D loss: 0.584661, acc.: 71.88%] [G loss: 1.129079]\n",
      "##############\n",
      "[4.28569398 2.24362891 7.04294387 5.94588691 4.50351125 6.5945465\n",
      " 5.39877667 5.4817133  5.92262202 5.01474107]\n",
      "##########\n",
      "epoch:23 step:22201 [D loss: 0.540300, acc.: 67.19%] [G loss: 0.878934]\n",
      "epoch:23 step:22202 [D loss: 0.552421, acc.: 73.44%] [G loss: 1.355086]\n",
      "epoch:23 step:22203 [D loss: 0.717235, acc.: 59.38%] [G loss: 1.051837]\n",
      "epoch:23 step:22204 [D loss: 0.722835, acc.: 47.66%] [G loss: 0.960255]\n",
      "epoch:23 step:22205 [D loss: 0.690457, acc.: 50.78%] [G loss: 0.830637]\n",
      "epoch:23 step:22206 [D loss: 0.726664, acc.: 47.66%] [G loss: 1.165836]\n",
      "epoch:23 step:22207 [D loss: 0.719826, acc.: 59.38%] [G loss: 1.318270]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22208 [D loss: 0.695137, acc.: 48.44%] [G loss: 1.353046]\n",
      "epoch:23 step:22209 [D loss: 0.530231, acc.: 75.00%] [G loss: 1.378287]\n",
      "epoch:23 step:22210 [D loss: 0.617361, acc.: 70.31%] [G loss: 1.455564]\n",
      "epoch:23 step:22211 [D loss: 0.676121, acc.: 55.47%] [G loss: 1.591148]\n",
      "epoch:23 step:22212 [D loss: 0.537728, acc.: 74.22%] [G loss: 1.400648]\n",
      "epoch:23 step:22213 [D loss: 0.649843, acc.: 53.12%] [G loss: 1.409256]\n",
      "epoch:23 step:22214 [D loss: 0.244799, acc.: 92.97%] [G loss: 1.398550]\n",
      "epoch:23 step:22215 [D loss: 0.269250, acc.: 94.53%] [G loss: 1.482315]\n",
      "epoch:23 step:22216 [D loss: 0.203311, acc.: 96.88%] [G loss: 1.471075]\n",
      "epoch:23 step:22217 [D loss: 0.462405, acc.: 78.91%] [G loss: 2.507993]\n",
      "epoch:23 step:22218 [D loss: 0.431574, acc.: 82.03%] [G loss: 2.023969]\n",
      "epoch:23 step:22219 [D loss: 0.658594, acc.: 64.84%] [G loss: 1.220536]\n",
      "epoch:23 step:22220 [D loss: 0.524286, acc.: 78.12%] [G loss: 1.665612]\n",
      "epoch:23 step:22221 [D loss: 0.531716, acc.: 80.47%] [G loss: 1.571199]\n",
      "epoch:23 step:22222 [D loss: 0.456074, acc.: 82.81%] [G loss: 1.278139]\n",
      "epoch:23 step:22223 [D loss: 0.703876, acc.: 60.94%] [G loss: 1.350814]\n",
      "epoch:23 step:22224 [D loss: 0.569639, acc.: 71.09%] [G loss: 1.087204]\n",
      "epoch:23 step:22225 [D loss: 0.521523, acc.: 75.00%] [G loss: 1.124624]\n",
      "epoch:23 step:22226 [D loss: 0.788650, acc.: 58.59%] [G loss: 1.159891]\n",
      "epoch:23 step:22227 [D loss: 0.573747, acc.: 71.88%] [G loss: 0.913178]\n",
      "epoch:23 step:22228 [D loss: 0.610318, acc.: 60.94%] [G loss: 1.061775]\n",
      "epoch:23 step:22229 [D loss: 0.704163, acc.: 53.91%] [G loss: 0.959872]\n",
      "epoch:23 step:22230 [D loss: 0.670752, acc.: 53.91%] [G loss: 0.985521]\n",
      "epoch:23 step:22231 [D loss: 0.591490, acc.: 64.06%] [G loss: 0.872964]\n",
      "epoch:23 step:22232 [D loss: 0.697963, acc.: 59.38%] [G loss: 0.898200]\n",
      "epoch:23 step:22233 [D loss: 0.489066, acc.: 82.03%] [G loss: 0.953601]\n",
      "epoch:23 step:22234 [D loss: 0.507788, acc.: 78.12%] [G loss: 1.262419]\n",
      "epoch:23 step:22235 [D loss: 0.436277, acc.: 85.16%] [G loss: 0.814073]\n",
      "epoch:23 step:22236 [D loss: 0.496499, acc.: 75.00%] [G loss: 1.130228]\n",
      "epoch:23 step:22237 [D loss: 0.487395, acc.: 73.44%] [G loss: 1.184974]\n",
      "epoch:23 step:22238 [D loss: 0.502224, acc.: 71.09%] [G loss: 1.743491]\n",
      "epoch:23 step:22239 [D loss: 0.537654, acc.: 76.56%] [G loss: 0.977661]\n",
      "epoch:23 step:22240 [D loss: 0.781899, acc.: 50.00%] [G loss: 0.829806]\n",
      "epoch:23 step:22241 [D loss: 0.693204, acc.: 53.91%] [G loss: 1.194506]\n",
      "epoch:23 step:22242 [D loss: 0.826388, acc.: 46.88%] [G loss: 0.958956]\n",
      "epoch:23 step:22243 [D loss: 0.674029, acc.: 63.28%] [G loss: 0.877613]\n",
      "epoch:23 step:22244 [D loss: 0.609685, acc.: 67.19%] [G loss: 1.187772]\n",
      "epoch:23 step:22245 [D loss: 0.585264, acc.: 69.53%] [G loss: 0.686763]\n",
      "epoch:23 step:22246 [D loss: 0.762111, acc.: 50.00%] [G loss: 0.855534]\n",
      "epoch:23 step:22247 [D loss: 0.402917, acc.: 71.88%] [G loss: 1.149376]\n",
      "epoch:23 step:22248 [D loss: 0.244471, acc.: 96.09%] [G loss: 1.056777]\n",
      "epoch:23 step:22249 [D loss: 0.314405, acc.: 92.19%] [G loss: 1.397008]\n",
      "epoch:23 step:22250 [D loss: 0.445864, acc.: 88.28%] [G loss: 1.179469]\n",
      "epoch:23 step:22251 [D loss: 0.361389, acc.: 80.47%] [G loss: 1.197666]\n",
      "epoch:23 step:22252 [D loss: 0.245738, acc.: 96.09%] [G loss: 1.137923]\n",
      "epoch:23 step:22253 [D loss: 0.392289, acc.: 92.19%] [G loss: 1.488560]\n",
      "epoch:23 step:22254 [D loss: 0.773660, acc.: 50.78%] [G loss: 1.212520]\n",
      "epoch:23 step:22255 [D loss: 0.399765, acc.: 93.75%] [G loss: 1.469689]\n",
      "epoch:23 step:22256 [D loss: 0.678366, acc.: 60.94%] [G loss: 1.056622]\n",
      "epoch:23 step:22257 [D loss: 0.285735, acc.: 95.31%] [G loss: 1.542526]\n",
      "epoch:23 step:22258 [D loss: 0.553177, acc.: 60.16%] [G loss: 1.582151]\n",
      "epoch:23 step:22259 [D loss: 0.165475, acc.: 96.88%] [G loss: 1.498189]\n",
      "epoch:23 step:22260 [D loss: 0.200286, acc.: 97.66%] [G loss: 1.547916]\n",
      "epoch:23 step:22261 [D loss: 0.692265, acc.: 62.50%] [G loss: 1.677910]\n",
      "epoch:23 step:22262 [D loss: 0.572836, acc.: 64.06%] [G loss: 1.268864]\n",
      "epoch:23 step:22263 [D loss: 0.685805, acc.: 56.25%] [G loss: 1.185505]\n",
      "epoch:23 step:22264 [D loss: 0.188004, acc.: 99.22%] [G loss: 1.375378]\n",
      "epoch:23 step:22265 [D loss: 0.261054, acc.: 92.19%] [G loss: 1.337808]\n",
      "epoch:23 step:22266 [D loss: 0.856927, acc.: 49.22%] [G loss: 1.329156]\n",
      "epoch:23 step:22267 [D loss: 0.814727, acc.: 39.06%] [G loss: 1.195342]\n",
      "epoch:23 step:22268 [D loss: 0.769700, acc.: 53.12%] [G loss: 1.013763]\n",
      "epoch:23 step:22269 [D loss: 0.630500, acc.: 60.16%] [G loss: 1.308988]\n",
      "epoch:23 step:22270 [D loss: 0.558844, acc.: 70.31%] [G loss: 1.363314]\n",
      "epoch:23 step:22271 [D loss: 0.508169, acc.: 74.22%] [G loss: 1.353174]\n",
      "epoch:23 step:22272 [D loss: 0.548932, acc.: 73.44%] [G loss: 1.272517]\n",
      "epoch:23 step:22273 [D loss: 0.572006, acc.: 69.53%] [G loss: 1.235268]\n",
      "epoch:23 step:22274 [D loss: 0.614899, acc.: 66.41%] [G loss: 0.975872]\n",
      "epoch:23 step:22275 [D loss: 0.796077, acc.: 57.03%] [G loss: 1.250769]\n",
      "epoch:23 step:22276 [D loss: 0.370044, acc.: 87.50%] [G loss: 1.772730]\n",
      "epoch:23 step:22277 [D loss: 0.412717, acc.: 85.94%] [G loss: 1.508677]\n",
      "epoch:23 step:22278 [D loss: 0.491415, acc.: 81.25%] [G loss: 1.000368]\n",
      "epoch:23 step:22279 [D loss: 0.349146, acc.: 82.81%] [G loss: 1.587646]\n",
      "epoch:23 step:22280 [D loss: 0.524397, acc.: 74.22%] [G loss: 1.613276]\n",
      "epoch:23 step:22281 [D loss: 0.298218, acc.: 93.75%] [G loss: 1.590662]\n",
      "epoch:23 step:22282 [D loss: 0.333803, acc.: 91.41%] [G loss: 1.508350]\n",
      "epoch:23 step:22283 [D loss: 0.708150, acc.: 62.50%] [G loss: 0.895104]\n",
      "epoch:23 step:22284 [D loss: 0.647784, acc.: 64.06%] [G loss: 1.258665]\n",
      "epoch:23 step:22285 [D loss: 1.042398, acc.: 34.38%] [G loss: 1.458046]\n",
      "epoch:23 step:22286 [D loss: 0.507681, acc.: 73.44%] [G loss: 1.694434]\n",
      "epoch:23 step:22287 [D loss: 0.674870, acc.: 59.38%] [G loss: 1.324022]\n",
      "epoch:23 step:22288 [D loss: 0.773494, acc.: 50.78%] [G loss: 1.439273]\n",
      "epoch:23 step:22289 [D loss: 0.740503, acc.: 53.12%] [G loss: 1.006147]\n",
      "epoch:23 step:22290 [D loss: 0.874101, acc.: 48.44%] [G loss: 1.283620]\n",
      "epoch:23 step:22291 [D loss: 0.742304, acc.: 52.34%] [G loss: 1.286267]\n",
      "epoch:23 step:22292 [D loss: 0.323388, acc.: 91.41%] [G loss: 1.505874]\n",
      "epoch:23 step:22293 [D loss: 0.220832, acc.: 96.88%] [G loss: 1.386913]\n",
      "epoch:23 step:22294 [D loss: 0.210317, acc.: 96.09%] [G loss: 1.501347]\n",
      "epoch:23 step:22295 [D loss: 0.434265, acc.: 84.38%] [G loss: 1.693892]\n",
      "epoch:23 step:22296 [D loss: 0.794692, acc.: 53.91%] [G loss: 1.309052]\n",
      "epoch:23 step:22297 [D loss: 0.778466, acc.: 50.00%] [G loss: 1.241566]\n",
      "epoch:23 step:22298 [D loss: 0.601413, acc.: 69.53%] [G loss: 1.166012]\n",
      "epoch:23 step:22299 [D loss: 0.278768, acc.: 93.75%] [G loss: 1.560981]\n",
      "epoch:23 step:22300 [D loss: 0.206532, acc.: 96.88%] [G loss: 1.787088]\n",
      "epoch:23 step:22301 [D loss: 0.227787, acc.: 92.97%] [G loss: 1.670909]\n",
      "epoch:23 step:22302 [D loss: 0.528999, acc.: 69.53%] [G loss: 1.677653]\n",
      "epoch:23 step:22303 [D loss: 0.676922, acc.: 57.03%] [G loss: 1.406184]\n",
      "epoch:23 step:22304 [D loss: 0.666595, acc.: 64.84%] [G loss: 1.348114]\n",
      "epoch:23 step:22305 [D loss: 0.783699, acc.: 50.00%] [G loss: 1.318321]\n",
      "epoch:23 step:22306 [D loss: 0.792415, acc.: 46.88%] [G loss: 1.137464]\n",
      "epoch:23 step:22307 [D loss: 0.711525, acc.: 50.78%] [G loss: 1.039127]\n",
      "epoch:23 step:22308 [D loss: 0.571095, acc.: 69.53%] [G loss: 1.164544]\n",
      "epoch:23 step:22309 [D loss: 0.510116, acc.: 80.47%] [G loss: 1.108294]\n",
      "epoch:23 step:22310 [D loss: 0.313375, acc.: 85.16%] [G loss: 1.429235]\n",
      "epoch:23 step:22311 [D loss: 0.217929, acc.: 95.31%] [G loss: 1.212943]\n",
      "epoch:23 step:22312 [D loss: 0.395017, acc.: 90.62%] [G loss: 1.181394]\n",
      "epoch:23 step:22313 [D loss: 0.762261, acc.: 55.47%] [G loss: 1.060655]\n",
      "epoch:23 step:22314 [D loss: 0.727940, acc.: 53.12%] [G loss: 1.175949]\n",
      "epoch:23 step:22315 [D loss: 1.017726, acc.: 30.47%] [G loss: 1.121838]\n",
      "epoch:23 step:22316 [D loss: 0.253969, acc.: 94.53%] [G loss: 0.915967]\n",
      "epoch:23 step:22317 [D loss: 0.314580, acc.: 90.62%] [G loss: 1.348686]\n",
      "epoch:23 step:22318 [D loss: 0.363749, acc.: 87.50%] [G loss: 1.516079]\n",
      "epoch:23 step:22319 [D loss: 0.185048, acc.: 96.09%] [G loss: 1.443097]\n",
      "epoch:23 step:22320 [D loss: 0.217820, acc.: 96.09%] [G loss: 1.452519]\n",
      "epoch:23 step:22321 [D loss: 0.287080, acc.: 96.09%] [G loss: 1.924299]\n",
      "epoch:23 step:22322 [D loss: 0.514939, acc.: 74.22%] [G loss: 1.611400]\n",
      "epoch:23 step:22323 [D loss: 0.596473, acc.: 67.97%] [G loss: 1.142859]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22324 [D loss: 0.732700, acc.: 60.94%] [G loss: 1.591652]\n",
      "epoch:23 step:22325 [D loss: 0.403254, acc.: 73.44%] [G loss: 1.786726]\n",
      "epoch:23 step:22326 [D loss: 0.264161, acc.: 88.28%] [G loss: 1.225302]\n",
      "epoch:23 step:22327 [D loss: 0.868942, acc.: 50.00%] [G loss: 1.257470]\n",
      "epoch:23 step:22328 [D loss: 0.580667, acc.: 68.75%] [G loss: 1.276504]\n",
      "epoch:23 step:22329 [D loss: 0.660796, acc.: 62.50%] [G loss: 1.280287]\n",
      "epoch:23 step:22330 [D loss: 1.132804, acc.: 33.59%] [G loss: 1.236185]\n",
      "epoch:23 step:22331 [D loss: 0.941714, acc.: 45.31%] [G loss: 1.198083]\n",
      "epoch:23 step:22332 [D loss: 0.933193, acc.: 39.06%] [G loss: 1.358059]\n",
      "epoch:23 step:22333 [D loss: 0.767277, acc.: 56.25%] [G loss: 1.098891]\n",
      "epoch:23 step:22334 [D loss: 0.779949, acc.: 56.25%] [G loss: 1.139055]\n",
      "epoch:23 step:22335 [D loss: 0.670943, acc.: 61.72%] [G loss: 1.292367]\n",
      "epoch:23 step:22336 [D loss: 0.746977, acc.: 53.12%] [G loss: 1.353649]\n",
      "epoch:23 step:22337 [D loss: 0.395135, acc.: 88.28%] [G loss: 1.414424]\n",
      "epoch:23 step:22338 [D loss: 0.772028, acc.: 46.88%] [G loss: 1.319930]\n",
      "epoch:23 step:22339 [D loss: 0.624922, acc.: 58.59%] [G loss: 1.104153]\n",
      "epoch:23 step:22340 [D loss: 0.669722, acc.: 59.38%] [G loss: 1.339095]\n",
      "epoch:23 step:22341 [D loss: 0.585578, acc.: 67.19%] [G loss: 1.179875]\n",
      "epoch:23 step:22342 [D loss: 0.308334, acc.: 89.06%] [G loss: 1.006721]\n",
      "epoch:23 step:22343 [D loss: 0.260138, acc.: 95.31%] [G loss: 1.657509]\n",
      "epoch:23 step:22344 [D loss: 0.461527, acc.: 80.47%] [G loss: 1.155833]\n",
      "epoch:23 step:22345 [D loss: 0.229322, acc.: 99.22%] [G loss: 1.791265]\n",
      "epoch:23 step:22346 [D loss: 0.430188, acc.: 85.94%] [G loss: 1.412690]\n",
      "epoch:23 step:22347 [D loss: 0.302301, acc.: 92.19%] [G loss: 2.000869]\n",
      "epoch:23 step:22348 [D loss: 0.581402, acc.: 64.84%] [G loss: 1.635702]\n",
      "epoch:23 step:22349 [D loss: 0.446038, acc.: 86.72%] [G loss: 1.633533]\n",
      "epoch:23 step:22350 [D loss: 0.652163, acc.: 59.38%] [G loss: 1.393057]\n",
      "epoch:23 step:22351 [D loss: 1.092580, acc.: 37.50%] [G loss: 1.186471]\n",
      "epoch:23 step:22352 [D loss: 0.825385, acc.: 49.22%] [G loss: 1.099901]\n",
      "epoch:23 step:22353 [D loss: 0.506478, acc.: 70.31%] [G loss: 1.160494]\n",
      "epoch:23 step:22354 [D loss: 0.693886, acc.: 64.06%] [G loss: 1.089973]\n",
      "epoch:23 step:22355 [D loss: 0.335535, acc.: 85.94%] [G loss: 1.114287]\n",
      "epoch:23 step:22356 [D loss: 0.325733, acc.: 90.62%] [G loss: 1.091749]\n",
      "epoch:23 step:22357 [D loss: 0.290840, acc.: 87.50%] [G loss: 1.130116]\n",
      "epoch:23 step:22358 [D loss: 0.778053, acc.: 51.56%] [G loss: 1.149939]\n",
      "epoch:23 step:22359 [D loss: 0.511614, acc.: 77.34%] [G loss: 1.033510]\n",
      "epoch:23 step:22360 [D loss: 0.461822, acc.: 86.72%] [G loss: 1.137098]\n",
      "epoch:23 step:22361 [D loss: 0.558406, acc.: 74.22%] [G loss: 0.952363]\n",
      "epoch:23 step:22362 [D loss: 0.750420, acc.: 53.91%] [G loss: 0.863510]\n",
      "epoch:23 step:22363 [D loss: 0.609070, acc.: 64.06%] [G loss: 0.907500]\n",
      "epoch:23 step:22364 [D loss: 0.765898, acc.: 50.00%] [G loss: 0.982431]\n",
      "epoch:23 step:22365 [D loss: 0.780225, acc.: 48.44%] [G loss: 0.924216]\n",
      "epoch:23 step:22366 [D loss: 0.379094, acc.: 80.47%] [G loss: 1.021310]\n",
      "epoch:23 step:22367 [D loss: 0.578413, acc.: 78.91%] [G loss: 1.052212]\n",
      "epoch:23 step:22368 [D loss: 0.688959, acc.: 64.84%] [G loss: 1.215744]\n",
      "epoch:23 step:22369 [D loss: 0.687513, acc.: 53.12%] [G loss: 1.126408]\n",
      "epoch:23 step:22370 [D loss: 0.696660, acc.: 59.38%] [G loss: 0.985686]\n",
      "epoch:23 step:22371 [D loss: 0.667773, acc.: 60.94%] [G loss: 1.070758]\n",
      "epoch:23 step:22372 [D loss: 0.337613, acc.: 89.84%] [G loss: 1.228929]\n",
      "epoch:23 step:22373 [D loss: 0.397981, acc.: 88.28%] [G loss: 1.164751]\n",
      "epoch:23 step:22374 [D loss: 0.515243, acc.: 77.34%] [G loss: 1.162385]\n",
      "epoch:23 step:22375 [D loss: 0.587882, acc.: 67.19%] [G loss: 1.199065]\n",
      "epoch:23 step:22376 [D loss: 0.534149, acc.: 71.09%] [G loss: 1.096957]\n",
      "epoch:23 step:22377 [D loss: 0.548280, acc.: 77.34%] [G loss: 0.795111]\n",
      "epoch:23 step:22378 [D loss: 0.559720, acc.: 68.75%] [G loss: 0.907757]\n",
      "epoch:23 step:22379 [D loss: 0.625312, acc.: 59.38%] [G loss: 1.097646]\n",
      "epoch:23 step:22380 [D loss: 0.518736, acc.: 76.56%] [G loss: 0.833367]\n",
      "epoch:23 step:22381 [D loss: 0.596068, acc.: 67.19%] [G loss: 1.078465]\n",
      "epoch:23 step:22382 [D loss: 0.602970, acc.: 67.97%] [G loss: 0.773675]\n",
      "epoch:23 step:22383 [D loss: 0.582600, acc.: 71.09%] [G loss: 0.957645]\n",
      "epoch:23 step:22384 [D loss: 0.656271, acc.: 60.16%] [G loss: 1.082498]\n",
      "epoch:23 step:22385 [D loss: 0.362205, acc.: 80.47%] [G loss: 0.982244]\n",
      "epoch:23 step:22386 [D loss: 0.478446, acc.: 82.81%] [G loss: 0.901958]\n",
      "epoch:23 step:22387 [D loss: 0.676473, acc.: 55.47%] [G loss: 1.072004]\n",
      "epoch:23 step:22388 [D loss: 0.711477, acc.: 50.78%] [G loss: 1.012918]\n",
      "epoch:23 step:22389 [D loss: 0.937484, acc.: 32.03%] [G loss: 1.128707]\n",
      "epoch:23 step:22390 [D loss: 0.405608, acc.: 85.94%] [G loss: 1.311269]\n",
      "epoch:23 step:22391 [D loss: 0.571085, acc.: 71.09%] [G loss: 1.046912]\n",
      "epoch:23 step:22392 [D loss: 0.339066, acc.: 85.16%] [G loss: 1.004285]\n",
      "epoch:23 step:22393 [D loss: 0.339550, acc.: 90.62%] [G loss: 1.262858]\n",
      "epoch:23 step:22394 [D loss: 0.627478, acc.: 65.62%] [G loss: 1.257178]\n",
      "epoch:23 step:22395 [D loss: 0.748412, acc.: 58.59%] [G loss: 1.128442]\n",
      "epoch:23 step:22396 [D loss: 0.261195, acc.: 92.97%] [G loss: 1.192629]\n",
      "epoch:23 step:22397 [D loss: 0.692862, acc.: 56.25%] [G loss: 1.198015]\n",
      "epoch:23 step:22398 [D loss: 0.302004, acc.: 90.62%] [G loss: 0.860043]\n",
      "epoch:23 step:22399 [D loss: 0.237466, acc.: 96.09%] [G loss: 1.258758]\n",
      "epoch:23 step:22400 [D loss: 0.427483, acc.: 83.59%] [G loss: 1.392880]\n",
      "##############\n",
      "[3.87131345 2.66303252 6.66776483 5.6087125  4.75923218 6.24829874\n",
      " 5.43150852 5.53828765 6.237365   5.30132109]\n",
      "##########\n",
      "epoch:23 step:22401 [D loss: 0.308265, acc.: 95.31%] [G loss: 0.978552]\n",
      "epoch:23 step:22402 [D loss: 0.277997, acc.: 85.94%] [G loss: 1.459426]\n",
      "epoch:23 step:22403 [D loss: 0.169980, acc.: 99.22%] [G loss: 1.646766]\n",
      "epoch:23 step:22404 [D loss: 0.150576, acc.: 99.22%] [G loss: 1.648699]\n",
      "epoch:23 step:22405 [D loss: 0.136400, acc.: 98.44%] [G loss: 1.609536]\n",
      "epoch:23 step:22406 [D loss: 0.323949, acc.: 93.75%] [G loss: 1.682945]\n",
      "epoch:23 step:22407 [D loss: 0.707020, acc.: 60.16%] [G loss: 1.703744]\n",
      "epoch:23 step:22408 [D loss: 0.194205, acc.: 98.44%] [G loss: 1.529645]\n",
      "epoch:23 step:22409 [D loss: 0.928275, acc.: 53.12%] [G loss: 1.370313]\n",
      "epoch:23 step:22410 [D loss: 0.615243, acc.: 64.06%] [G loss: 1.544009]\n",
      "epoch:23 step:22411 [D loss: 0.457357, acc.: 80.47%] [G loss: 1.658550]\n",
      "epoch:23 step:22412 [D loss: 0.585162, acc.: 71.88%] [G loss: 1.670749]\n",
      "epoch:23 step:22413 [D loss: 0.780607, acc.: 54.69%] [G loss: 1.601169]\n",
      "epoch:23 step:22414 [D loss: 0.781978, acc.: 54.69%] [G loss: 0.942634]\n",
      "epoch:23 step:22415 [D loss: 0.834287, acc.: 42.97%] [G loss: 1.425354]\n",
      "epoch:23 step:22416 [D loss: 0.561607, acc.: 71.09%] [G loss: 0.996362]\n",
      "epoch:23 step:22417 [D loss: 0.610498, acc.: 64.06%] [G loss: 1.128907]\n",
      "epoch:23 step:22418 [D loss: 0.593439, acc.: 63.28%] [G loss: 0.990263]\n",
      "epoch:23 step:22419 [D loss: 0.705630, acc.: 54.69%] [G loss: 1.183018]\n",
      "epoch:23 step:22420 [D loss: 0.763410, acc.: 45.31%] [G loss: 0.938143]\n",
      "epoch:23 step:22421 [D loss: 0.737351, acc.: 50.00%] [G loss: 0.832916]\n",
      "epoch:23 step:22422 [D loss: 0.675885, acc.: 62.50%] [G loss: 1.222242]\n",
      "epoch:23 step:22423 [D loss: 0.748103, acc.: 50.00%] [G loss: 1.098636]\n",
      "epoch:23 step:22424 [D loss: 0.835312, acc.: 41.41%] [G loss: 1.321017]\n",
      "epoch:23 step:22425 [D loss: 0.850540, acc.: 41.41%] [G loss: 1.120501]\n",
      "epoch:23 step:22426 [D loss: 0.758331, acc.: 50.00%] [G loss: 1.422250]\n",
      "epoch:23 step:22427 [D loss: 0.563728, acc.: 74.22%] [G loss: 1.177009]\n",
      "epoch:23 step:22428 [D loss: 0.287344, acc.: 95.31%] [G loss: 1.642672]\n",
      "epoch:23 step:22429 [D loss: 0.176149, acc.: 93.75%] [G loss: 1.748097]\n",
      "epoch:23 step:22430 [D loss: 0.523478, acc.: 71.88%] [G loss: 1.716989]\n",
      "epoch:23 step:22431 [D loss: 0.592010, acc.: 60.94%] [G loss: 1.545138]\n",
      "epoch:23 step:22432 [D loss: 0.578519, acc.: 61.72%] [G loss: 1.619107]\n",
      "epoch:23 step:22433 [D loss: 0.800904, acc.: 51.56%] [G loss: 1.438644]\n",
      "epoch:23 step:22434 [D loss: 0.703407, acc.: 55.47%] [G loss: 1.303171]\n",
      "epoch:23 step:22435 [D loss: 0.687563, acc.: 56.25%] [G loss: 1.118014]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22436 [D loss: 0.587476, acc.: 69.53%] [G loss: 1.397942]\n",
      "epoch:23 step:22437 [D loss: 0.598850, acc.: 66.41%] [G loss: 1.231227]\n",
      "epoch:23 step:22438 [D loss: 0.701079, acc.: 62.50%] [G loss: 1.206555]\n",
      "epoch:23 step:22439 [D loss: 0.657486, acc.: 59.38%] [G loss: 1.073054]\n",
      "epoch:23 step:22440 [D loss: 0.675819, acc.: 56.25%] [G loss: 1.159522]\n",
      "epoch:23 step:22441 [D loss: 0.685613, acc.: 61.72%] [G loss: 1.012461]\n",
      "epoch:23 step:22442 [D loss: 0.355059, acc.: 85.16%] [G loss: 1.152631]\n",
      "epoch:23 step:22443 [D loss: 0.313072, acc.: 88.28%] [G loss: 1.704599]\n",
      "epoch:23 step:22444 [D loss: 0.249313, acc.: 92.19%] [G loss: 1.537673]\n",
      "epoch:23 step:22445 [D loss: 0.253995, acc.: 96.09%] [G loss: 1.578151]\n",
      "epoch:23 step:22446 [D loss: 0.280009, acc.: 95.31%] [G loss: 1.662329]\n",
      "epoch:23 step:22447 [D loss: 0.162253, acc.: 100.00%] [G loss: 1.479803]\n",
      "epoch:23 step:22448 [D loss: 0.215488, acc.: 98.44%] [G loss: 1.506833]\n",
      "epoch:23 step:22449 [D loss: 0.102616, acc.: 97.66%] [G loss: 1.962363]\n",
      "epoch:23 step:22450 [D loss: 0.429303, acc.: 71.09%] [G loss: 1.735780]\n",
      "epoch:23 step:22451 [D loss: 0.079139, acc.: 100.00%] [G loss: 1.686249]\n",
      "epoch:23 step:22452 [D loss: 0.200579, acc.: 99.22%] [G loss: 2.128505]\n",
      "epoch:23 step:22453 [D loss: 0.580819, acc.: 68.75%] [G loss: 1.335328]\n",
      "epoch:23 step:22454 [D loss: 0.454618, acc.: 83.59%] [G loss: 1.965066]\n",
      "epoch:23 step:22455 [D loss: 1.144588, acc.: 45.31%] [G loss: 1.057148]\n",
      "epoch:23 step:22456 [D loss: 0.834159, acc.: 53.91%] [G loss: 0.601286]\n",
      "epoch:23 step:22457 [D loss: 0.465687, acc.: 83.59%] [G loss: 0.665201]\n",
      "epoch:23 step:22458 [D loss: 0.778641, acc.: 51.56%] [G loss: 0.833455]\n",
      "epoch:23 step:22459 [D loss: 0.662174, acc.: 66.41%] [G loss: 0.915464]\n",
      "epoch:23 step:22460 [D loss: 0.509684, acc.: 63.28%] [G loss: 1.179933]\n",
      "epoch:23 step:22461 [D loss: 0.691060, acc.: 60.94%] [G loss: 1.290681]\n",
      "epoch:23 step:22462 [D loss: 0.269497, acc.: 91.41%] [G loss: 1.346811]\n",
      "epoch:23 step:22463 [D loss: 0.483834, acc.: 70.31%] [G loss: 1.016824]\n",
      "epoch:23 step:22464 [D loss: 0.569442, acc.: 70.31%] [G loss: 1.452008]\n",
      "epoch:23 step:22465 [D loss: 0.745638, acc.: 53.91%] [G loss: 1.363649]\n",
      "epoch:23 step:22466 [D loss: 0.807923, acc.: 50.78%] [G loss: 1.221962]\n",
      "epoch:23 step:22467 [D loss: 0.977089, acc.: 32.81%] [G loss: 1.012558]\n",
      "epoch:23 step:22468 [D loss: 0.876977, acc.: 38.28%] [G loss: 0.813830]\n",
      "epoch:23 step:22469 [D loss: 0.638319, acc.: 57.81%] [G loss: 0.949170]\n",
      "epoch:23 step:22470 [D loss: 0.344186, acc.: 90.62%] [G loss: 1.288935]\n",
      "epoch:23 step:22471 [D loss: 0.397520, acc.: 81.25%] [G loss: 1.345962]\n",
      "epoch:23 step:22472 [D loss: 0.288476, acc.: 92.19%] [G loss: 1.422891]\n",
      "epoch:23 step:22473 [D loss: 0.602153, acc.: 65.62%] [G loss: 1.448629]\n",
      "epoch:23 step:22474 [D loss: 0.629389, acc.: 58.59%] [G loss: 1.458514]\n",
      "epoch:23 step:22475 [D loss: 0.396850, acc.: 88.28%] [G loss: 1.333064]\n",
      "epoch:23 step:22476 [D loss: 0.404836, acc.: 88.28%] [G loss: 1.187387]\n",
      "epoch:23 step:22477 [D loss: 0.225719, acc.: 93.75%] [G loss: 1.041876]\n",
      "epoch:23 step:22478 [D loss: 0.280084, acc.: 87.50%] [G loss: 1.310875]\n",
      "epoch:23 step:22479 [D loss: 0.686154, acc.: 52.34%] [G loss: 1.378955]\n",
      "epoch:23 step:22480 [D loss: 0.176848, acc.: 96.09%] [G loss: 1.459448]\n",
      "epoch:23 step:22481 [D loss: 0.389086, acc.: 87.50%] [G loss: 1.404248]\n",
      "epoch:23 step:22482 [D loss: 0.414287, acc.: 89.06%] [G loss: 1.424801]\n",
      "epoch:23 step:22483 [D loss: 0.672136, acc.: 67.97%] [G loss: 1.234378]\n",
      "epoch:23 step:22484 [D loss: 0.456745, acc.: 84.38%] [G loss: 0.952121]\n",
      "epoch:23 step:22485 [D loss: 0.280885, acc.: 88.28%] [G loss: 1.270573]\n",
      "epoch:23 step:22486 [D loss: 0.483669, acc.: 79.69%] [G loss: 0.981056]\n",
      "epoch:23 step:22487 [D loss: 0.304731, acc.: 88.28%] [G loss: 1.411425]\n",
      "epoch:23 step:22488 [D loss: 0.205675, acc.: 92.19%] [G loss: 1.957875]\n",
      "epoch:24 step:22489 [D loss: 0.920746, acc.: 39.06%] [G loss: 1.601950]\n",
      "epoch:24 step:22490 [D loss: 0.708156, acc.: 57.03%] [G loss: 1.091168]\n",
      "epoch:24 step:22491 [D loss: 0.842468, acc.: 42.97%] [G loss: 0.887587]\n",
      "epoch:24 step:22492 [D loss: 0.668405, acc.: 59.38%] [G loss: 1.192504]\n",
      "epoch:24 step:22493 [D loss: 0.626018, acc.: 60.16%] [G loss: 0.994082]\n",
      "epoch:24 step:22494 [D loss: 0.637654, acc.: 61.72%] [G loss: 1.246680]\n",
      "epoch:24 step:22495 [D loss: 0.653188, acc.: 62.50%] [G loss: 1.226084]\n",
      "epoch:24 step:22496 [D loss: 0.807139, acc.: 42.19%] [G loss: 0.890628]\n",
      "epoch:24 step:22497 [D loss: 0.646772, acc.: 61.72%] [G loss: 1.278905]\n",
      "epoch:24 step:22498 [D loss: 0.545628, acc.: 72.66%] [G loss: 1.110404]\n",
      "epoch:24 step:22499 [D loss: 0.594476, acc.: 67.97%] [G loss: 1.214017]\n",
      "epoch:24 step:22500 [D loss: 0.735722, acc.: 51.56%] [G loss: 1.144335]\n",
      "epoch:24 step:22501 [D loss: 0.494776, acc.: 80.47%] [G loss: 0.958154]\n",
      "epoch:24 step:22502 [D loss: 0.627333, acc.: 64.06%] [G loss: 0.648393]\n",
      "epoch:24 step:22503 [D loss: 0.620140, acc.: 63.28%] [G loss: 0.949174]\n",
      "epoch:24 step:22504 [D loss: 0.771875, acc.: 42.97%] [G loss: 1.165701]\n",
      "epoch:24 step:22505 [D loss: 0.659118, acc.: 55.47%] [G loss: 0.935099]\n",
      "epoch:24 step:22506 [D loss: 0.686262, acc.: 59.38%] [G loss: 0.692582]\n",
      "epoch:24 step:22507 [D loss: 0.654375, acc.: 60.94%] [G loss: 0.962128]\n",
      "epoch:24 step:22508 [D loss: 0.644600, acc.: 60.94%] [G loss: 0.923194]\n",
      "epoch:24 step:22509 [D loss: 0.777998, acc.: 52.34%] [G loss: 1.151511]\n",
      "epoch:24 step:22510 [D loss: 0.620865, acc.: 60.94%] [G loss: 1.393943]\n",
      "epoch:24 step:22511 [D loss: 0.757961, acc.: 46.88%] [G loss: 1.254673]\n",
      "epoch:24 step:22512 [D loss: 0.717645, acc.: 61.72%] [G loss: 0.874637]\n",
      "epoch:24 step:22513 [D loss: 0.572012, acc.: 64.84%] [G loss: 1.000890]\n",
      "epoch:24 step:22514 [D loss: 0.640899, acc.: 57.81%] [G loss: 1.097673]\n",
      "epoch:24 step:22515 [D loss: 0.289302, acc.: 89.06%] [G loss: 1.293729]\n",
      "epoch:24 step:22516 [D loss: 0.430363, acc.: 81.25%] [G loss: 1.356214]\n",
      "epoch:24 step:22517 [D loss: 0.523162, acc.: 73.44%] [G loss: 1.425630]\n",
      "epoch:24 step:22518 [D loss: 0.620201, acc.: 60.16%] [G loss: 0.920230]\n",
      "epoch:24 step:22519 [D loss: 0.320603, acc.: 90.62%] [G loss: 1.020088]\n",
      "epoch:24 step:22520 [D loss: 0.218155, acc.: 94.53%] [G loss: 1.186563]\n",
      "epoch:24 step:22521 [D loss: 0.233324, acc.: 98.44%] [G loss: 1.625777]\n",
      "epoch:24 step:22522 [D loss: 0.249590, acc.: 95.31%] [G loss: 1.803971]\n",
      "epoch:24 step:22523 [D loss: 0.221615, acc.: 96.09%] [G loss: 1.578529]\n",
      "epoch:24 step:22524 [D loss: 0.187866, acc.: 98.44%] [G loss: 1.864773]\n",
      "epoch:24 step:22525 [D loss: 0.793515, acc.: 54.69%] [G loss: 1.342404]\n",
      "epoch:24 step:22526 [D loss: 1.006646, acc.: 42.19%] [G loss: 1.314112]\n",
      "epoch:24 step:22527 [D loss: 0.799775, acc.: 64.84%] [G loss: 1.197789]\n",
      "epoch:24 step:22528 [D loss: 0.609012, acc.: 64.06%] [G loss: 1.249545]\n",
      "epoch:24 step:22529 [D loss: 0.796572, acc.: 39.06%] [G loss: 1.039095]\n",
      "epoch:24 step:22530 [D loss: 0.545887, acc.: 75.00%] [G loss: 1.155563]\n",
      "epoch:24 step:22531 [D loss: 0.477302, acc.: 80.47%] [G loss: 1.037135]\n",
      "epoch:24 step:22532 [D loss: 0.633140, acc.: 64.84%] [G loss: 0.992952]\n",
      "epoch:24 step:22533 [D loss: 0.619433, acc.: 66.41%] [G loss: 0.778763]\n",
      "epoch:24 step:22534 [D loss: 0.553243, acc.: 70.31%] [G loss: 0.647923]\n",
      "epoch:24 step:22535 [D loss: 0.752597, acc.: 53.12%] [G loss: 1.233689]\n",
      "epoch:24 step:22536 [D loss: 0.798831, acc.: 46.09%] [G loss: 1.287675]\n",
      "epoch:24 step:22537 [D loss: 0.828884, acc.: 38.28%] [G loss: 1.105878]\n",
      "epoch:24 step:22538 [D loss: 0.654078, acc.: 56.25%] [G loss: 1.206623]\n",
      "epoch:24 step:22539 [D loss: 0.626376, acc.: 63.28%] [G loss: 0.815152]\n",
      "epoch:24 step:22540 [D loss: 0.592814, acc.: 71.09%] [G loss: 1.167444]\n",
      "epoch:24 step:22541 [D loss: 0.642794, acc.: 64.84%] [G loss: 0.705382]\n",
      "epoch:24 step:22542 [D loss: 0.878266, acc.: 34.38%] [G loss: 1.025650]\n",
      "epoch:24 step:22543 [D loss: 0.578208, acc.: 67.19%] [G loss: 1.066415]\n",
      "epoch:24 step:22544 [D loss: 0.701014, acc.: 60.94%] [G loss: 1.024965]\n",
      "epoch:24 step:22545 [D loss: 0.431503, acc.: 86.72%] [G loss: 1.152451]\n",
      "epoch:24 step:22546 [D loss: 0.416979, acc.: 82.81%] [G loss: 1.247824]\n",
      "epoch:24 step:22547 [D loss: 0.585888, acc.: 66.41%] [G loss: 1.085885]\n",
      "epoch:24 step:22548 [D loss: 0.428570, acc.: 86.72%] [G loss: 1.204431]\n",
      "epoch:24 step:22549 [D loss: 0.698161, acc.: 54.69%] [G loss: 0.789555]\n",
      "epoch:24 step:22550 [D loss: 0.664310, acc.: 57.81%] [G loss: 0.977661]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22551 [D loss: 0.583521, acc.: 69.53%] [G loss: 0.856245]\n",
      "epoch:24 step:22552 [D loss: 0.797452, acc.: 41.41%] [G loss: 1.049411]\n",
      "epoch:24 step:22553 [D loss: 0.645870, acc.: 66.41%] [G loss: 0.949694]\n",
      "epoch:24 step:22554 [D loss: 0.674069, acc.: 53.91%] [G loss: 0.929384]\n",
      "epoch:24 step:22555 [D loss: 0.593121, acc.: 71.88%] [G loss: 0.863349]\n",
      "epoch:24 step:22556 [D loss: 0.610929, acc.: 70.31%] [G loss: 1.201981]\n",
      "epoch:24 step:22557 [D loss: 0.487888, acc.: 81.25%] [G loss: 1.092534]\n",
      "epoch:24 step:22558 [D loss: 0.546277, acc.: 71.09%] [G loss: 1.242424]\n",
      "epoch:24 step:22559 [D loss: 0.306948, acc.: 88.28%] [G loss: 1.186135]\n",
      "epoch:24 step:22560 [D loss: 0.545481, acc.: 78.12%] [G loss: 1.066249]\n",
      "epoch:24 step:22561 [D loss: 0.422656, acc.: 84.38%] [G loss: 1.161739]\n",
      "epoch:24 step:22562 [D loss: 0.602033, acc.: 68.75%] [G loss: 1.116548]\n",
      "epoch:24 step:22563 [D loss: 0.241269, acc.: 92.97%] [G loss: 1.145867]\n",
      "epoch:24 step:22564 [D loss: 0.211576, acc.: 97.66%] [G loss: 1.304748]\n",
      "epoch:24 step:22565 [D loss: 0.250106, acc.: 95.31%] [G loss: 1.243889]\n",
      "epoch:24 step:22566 [D loss: 0.933371, acc.: 45.31%] [G loss: 1.142060]\n",
      "epoch:24 step:22567 [D loss: 0.742548, acc.: 55.47%] [G loss: 1.019103]\n",
      "epoch:24 step:22568 [D loss: 0.749105, acc.: 53.12%] [G loss: 1.122227]\n",
      "epoch:24 step:22569 [D loss: 0.735369, acc.: 57.81%] [G loss: 1.170571]\n",
      "epoch:24 step:22570 [D loss: 0.677747, acc.: 59.38%] [G loss: 1.147161]\n",
      "epoch:24 step:22571 [D loss: 0.564202, acc.: 68.75%] [G loss: 1.267613]\n",
      "epoch:24 step:22572 [D loss: 0.622039, acc.: 68.75%] [G loss: 0.946660]\n",
      "epoch:24 step:22573 [D loss: 0.479274, acc.: 80.47%] [G loss: 1.416023]\n",
      "epoch:24 step:22574 [D loss: 0.735305, acc.: 53.12%] [G loss: 1.125489]\n",
      "epoch:24 step:22575 [D loss: 0.697038, acc.: 53.12%] [G loss: 0.909907]\n",
      "epoch:24 step:22576 [D loss: 0.662790, acc.: 60.94%] [G loss: 1.008343]\n",
      "epoch:24 step:22577 [D loss: 0.667657, acc.: 63.28%] [G loss: 1.285732]\n",
      "epoch:24 step:22578 [D loss: 0.608708, acc.: 63.28%] [G loss: 1.046362]\n",
      "epoch:24 step:22579 [D loss: 0.699166, acc.: 57.81%] [G loss: 0.929590]\n",
      "epoch:24 step:22580 [D loss: 0.589998, acc.: 65.62%] [G loss: 1.075999]\n",
      "epoch:24 step:22581 [D loss: 0.422209, acc.: 89.06%] [G loss: 1.040658]\n",
      "epoch:24 step:22582 [D loss: 0.564263, acc.: 75.78%] [G loss: 1.052213]\n",
      "epoch:24 step:22583 [D loss: 0.667070, acc.: 57.81%] [G loss: 0.774587]\n",
      "epoch:24 step:22584 [D loss: 0.612395, acc.: 67.19%] [G loss: 1.047653]\n",
      "epoch:24 step:22585 [D loss: 0.757027, acc.: 42.97%] [G loss: 0.964490]\n",
      "epoch:24 step:22586 [D loss: 0.493640, acc.: 72.66%] [G loss: 0.961702]\n",
      "epoch:24 step:22587 [D loss: 0.554519, acc.: 68.75%] [G loss: 1.128721]\n",
      "epoch:24 step:22588 [D loss: 0.415564, acc.: 82.03%] [G loss: 1.074109]\n",
      "epoch:24 step:22589 [D loss: 0.714094, acc.: 53.91%] [G loss: 1.046044]\n",
      "epoch:24 step:22590 [D loss: 0.685665, acc.: 53.91%] [G loss: 1.174247]\n",
      "epoch:24 step:22591 [D loss: 0.742295, acc.: 51.56%] [G loss: 0.941503]\n",
      "epoch:24 step:22592 [D loss: 0.734567, acc.: 51.56%] [G loss: 0.931032]\n",
      "epoch:24 step:22593 [D loss: 0.356748, acc.: 85.16%] [G loss: 1.165167]\n",
      "epoch:24 step:22594 [D loss: 0.677531, acc.: 59.38%] [G loss: 0.971557]\n",
      "epoch:24 step:22595 [D loss: 0.428520, acc.: 84.38%] [G loss: 1.288268]\n",
      "epoch:24 step:22596 [D loss: 0.554938, acc.: 76.56%] [G loss: 1.130346]\n",
      "epoch:24 step:22597 [D loss: 0.648376, acc.: 61.72%] [G loss: 0.960214]\n",
      "epoch:24 step:22598 [D loss: 0.747175, acc.: 50.00%] [G loss: 1.181069]\n",
      "epoch:24 step:22599 [D loss: 0.629756, acc.: 61.72%] [G loss: 0.994438]\n",
      "epoch:24 step:22600 [D loss: 0.651955, acc.: 63.28%] [G loss: 0.933486]\n",
      "##############\n",
      "[4.12601611 2.65278987 6.76498345 5.6871054  4.8910316  6.25676474\n",
      " 5.58821999 5.34010866 6.01368049 5.26588467]\n",
      "##########\n",
      "epoch:24 step:22601 [D loss: 0.684732, acc.: 61.72%] [G loss: 1.163582]\n",
      "epoch:24 step:22602 [D loss: 0.442033, acc.: 79.69%] [G loss: 1.079697]\n",
      "epoch:24 step:22603 [D loss: 0.488819, acc.: 80.47%] [G loss: 0.968036]\n",
      "epoch:24 step:22604 [D loss: 0.642661, acc.: 57.03%] [G loss: 0.964810]\n",
      "epoch:24 step:22605 [D loss: 0.470414, acc.: 72.66%] [G loss: 0.956107]\n",
      "epoch:24 step:22606 [D loss: 0.272481, acc.: 92.19%] [G loss: 0.995429]\n",
      "epoch:24 step:22607 [D loss: 0.229982, acc.: 93.75%] [G loss: 1.169887]\n",
      "epoch:24 step:22608 [D loss: 0.528289, acc.: 77.34%] [G loss: 1.287422]\n",
      "epoch:24 step:22609 [D loss: 0.368057, acc.: 80.47%] [G loss: 1.362489]\n",
      "epoch:24 step:22610 [D loss: 0.265353, acc.: 95.31%] [G loss: 1.362466]\n",
      "epoch:24 step:22611 [D loss: 0.855727, acc.: 46.09%] [G loss: 1.272814]\n",
      "epoch:24 step:22612 [D loss: 0.832428, acc.: 51.56%] [G loss: 1.271613]\n",
      "epoch:24 step:22613 [D loss: 0.753950, acc.: 49.22%] [G loss: 1.060510]\n",
      "epoch:24 step:22614 [D loss: 0.790622, acc.: 50.00%] [G loss: 1.114246]\n",
      "epoch:24 step:22615 [D loss: 0.691262, acc.: 54.69%] [G loss: 1.043451]\n",
      "epoch:24 step:22616 [D loss: 0.709383, acc.: 50.78%] [G loss: 0.940278]\n",
      "epoch:24 step:22617 [D loss: 0.414217, acc.: 83.59%] [G loss: 0.921485]\n",
      "epoch:24 step:22618 [D loss: 0.311746, acc.: 89.06%] [G loss: 1.169021]\n",
      "epoch:24 step:22619 [D loss: 0.325040, acc.: 94.53%] [G loss: 1.020522]\n",
      "epoch:24 step:22620 [D loss: 0.448819, acc.: 85.16%] [G loss: 1.288528]\n",
      "epoch:24 step:22621 [D loss: 0.668944, acc.: 60.94%] [G loss: 1.035621]\n",
      "epoch:24 step:22622 [D loss: 0.426828, acc.: 87.50%] [G loss: 1.372044]\n",
      "epoch:24 step:22623 [D loss: 0.456582, acc.: 85.94%] [G loss: 1.066880]\n",
      "epoch:24 step:22624 [D loss: 0.772799, acc.: 50.00%] [G loss: 0.965127]\n",
      "epoch:24 step:22625 [D loss: 0.671961, acc.: 61.72%] [G loss: 1.057088]\n",
      "epoch:24 step:22626 [D loss: 0.697608, acc.: 57.81%] [G loss: 0.553526]\n",
      "epoch:24 step:22627 [D loss: 0.432952, acc.: 82.03%] [G loss: 1.152607]\n",
      "epoch:24 step:22628 [D loss: 0.438282, acc.: 87.50%] [G loss: 1.319689]\n",
      "epoch:24 step:22629 [D loss: 0.333296, acc.: 89.06%] [G loss: 1.285756]\n",
      "epoch:24 step:22630 [D loss: 0.523253, acc.: 70.31%] [G loss: 1.348347]\n",
      "epoch:24 step:22631 [D loss: 0.205522, acc.: 97.66%] [G loss: 1.301661]\n",
      "epoch:24 step:22632 [D loss: 0.201936, acc.: 96.88%] [G loss: 1.622158]\n",
      "epoch:24 step:22633 [D loss: 0.179040, acc.: 95.31%] [G loss: 1.511043]\n",
      "epoch:24 step:22634 [D loss: 0.325785, acc.: 89.84%] [G loss: 1.583313]\n",
      "epoch:24 step:22635 [D loss: 0.814300, acc.: 47.66%] [G loss: 1.403844]\n",
      "epoch:24 step:22636 [D loss: 0.725848, acc.: 51.56%] [G loss: 1.443543]\n",
      "epoch:24 step:22637 [D loss: 0.450760, acc.: 80.47%] [G loss: 1.345093]\n",
      "epoch:24 step:22638 [D loss: 0.170300, acc.: 97.66%] [G loss: 1.378492]\n",
      "epoch:24 step:22639 [D loss: 0.174741, acc.: 96.88%] [G loss: 1.704025]\n",
      "epoch:24 step:22640 [D loss: 0.242361, acc.: 94.53%] [G loss: 1.612021]\n",
      "epoch:24 step:22641 [D loss: 0.831228, acc.: 50.00%] [G loss: 1.451219]\n",
      "epoch:24 step:22642 [D loss: 0.620468, acc.: 65.62%] [G loss: 1.462459]\n",
      "epoch:24 step:22643 [D loss: 0.570463, acc.: 72.66%] [G loss: 1.243196]\n",
      "epoch:24 step:22644 [D loss: 0.741350, acc.: 56.25%] [G loss: 1.246270]\n",
      "epoch:24 step:22645 [D loss: 0.595661, acc.: 69.53%] [G loss: 0.968685]\n",
      "epoch:24 step:22646 [D loss: 0.758490, acc.: 48.44%] [G loss: 0.887758]\n",
      "epoch:24 step:22647 [D loss: 0.768101, acc.: 48.44%] [G loss: 0.868370]\n",
      "epoch:24 step:22648 [D loss: 0.327311, acc.: 91.41%] [G loss: 1.199428]\n",
      "epoch:24 step:22649 [D loss: 0.705197, acc.: 56.25%] [G loss: 0.960656]\n",
      "epoch:24 step:22650 [D loss: 0.243137, acc.: 95.31%] [G loss: 1.134164]\n",
      "epoch:24 step:22651 [D loss: 0.423630, acc.: 83.59%] [G loss: 1.378136]\n",
      "epoch:24 step:22652 [D loss: 0.419942, acc.: 82.03%] [G loss: 1.112514]\n",
      "epoch:24 step:22653 [D loss: 0.404023, acc.: 88.28%] [G loss: 0.972316]\n",
      "epoch:24 step:22654 [D loss: 1.366174, acc.: 16.41%] [G loss: 1.066275]\n",
      "epoch:24 step:22655 [D loss: 0.922377, acc.: 34.38%] [G loss: 1.004628]\n",
      "epoch:24 step:22656 [D loss: 0.784420, acc.: 52.34%] [G loss: 1.421541]\n",
      "epoch:24 step:22657 [D loss: 0.703792, acc.: 61.72%] [G loss: 1.188428]\n",
      "epoch:24 step:22658 [D loss: 0.778894, acc.: 45.31%] [G loss: 0.849100]\n",
      "epoch:24 step:22659 [D loss: 1.018037, acc.: 22.66%] [G loss: 0.873606]\n",
      "epoch:24 step:22660 [D loss: 0.672570, acc.: 62.50%] [G loss: 1.359083]\n",
      "epoch:24 step:22661 [D loss: 0.683561, acc.: 54.69%] [G loss: 1.080059]\n",
      "epoch:24 step:22662 [D loss: 0.776335, acc.: 43.75%] [G loss: 1.373206]\n",
      "epoch:24 step:22663 [D loss: 0.740417, acc.: 47.66%] [G loss: 0.919942]\n",
      "epoch:24 step:22664 [D loss: 0.671262, acc.: 56.25%] [G loss: 1.361212]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22665 [D loss: 0.742838, acc.: 41.41%] [G loss: 0.911251]\n",
      "epoch:24 step:22666 [D loss: 0.748266, acc.: 49.22%] [G loss: 1.265548]\n",
      "epoch:24 step:22667 [D loss: 0.780048, acc.: 49.22%] [G loss: 1.052779]\n",
      "epoch:24 step:22668 [D loss: 0.776630, acc.: 46.09%] [G loss: 1.147212]\n",
      "epoch:24 step:22669 [D loss: 0.521492, acc.: 69.53%] [G loss: 1.213908]\n",
      "epoch:24 step:22670 [D loss: 0.606914, acc.: 60.16%] [G loss: 1.223024]\n",
      "epoch:24 step:22671 [D loss: 0.643354, acc.: 58.59%] [G loss: 1.690339]\n",
      "epoch:24 step:22672 [D loss: 0.386788, acc.: 87.50%] [G loss: 1.584908]\n",
      "epoch:24 step:22673 [D loss: 0.688508, acc.: 63.28%] [G loss: 1.460005]\n",
      "epoch:24 step:22674 [D loss: 0.643891, acc.: 60.16%] [G loss: 1.358923]\n",
      "epoch:24 step:22675 [D loss: 0.525826, acc.: 77.34%] [G loss: 1.305541]\n",
      "epoch:24 step:22676 [D loss: 0.412834, acc.: 92.19%] [G loss: 1.367202]\n",
      "epoch:24 step:22677 [D loss: 0.572783, acc.: 69.53%] [G loss: 1.245240]\n",
      "epoch:24 step:22678 [D loss: 0.484921, acc.: 78.91%] [G loss: 1.226799]\n",
      "epoch:24 step:22679 [D loss: 0.568117, acc.: 74.22%] [G loss: 1.144982]\n",
      "epoch:24 step:22680 [D loss: 0.228752, acc.: 93.75%] [G loss: 0.486941]\n",
      "epoch:24 step:22681 [D loss: 0.382832, acc.: 87.50%] [G loss: 1.459380]\n",
      "epoch:24 step:22682 [D loss: 0.253758, acc.: 95.31%] [G loss: 1.210087]\n",
      "epoch:24 step:22683 [D loss: 0.388028, acc.: 86.72%] [G loss: 0.861567]\n",
      "epoch:24 step:22684 [D loss: 0.403378, acc.: 90.62%] [G loss: 1.288160]\n",
      "epoch:24 step:22685 [D loss: 0.292172, acc.: 97.66%] [G loss: 1.403965]\n",
      "epoch:24 step:22686 [D loss: 0.243816, acc.: 97.66%] [G loss: 1.215150]\n",
      "epoch:24 step:22687 [D loss: 0.775421, acc.: 45.31%] [G loss: 1.238478]\n",
      "epoch:24 step:22688 [D loss: 1.034046, acc.: 44.53%] [G loss: 0.822251]\n",
      "epoch:24 step:22689 [D loss: 0.643966, acc.: 66.41%] [G loss: 1.556710]\n",
      "epoch:24 step:22690 [D loss: 0.671174, acc.: 60.16%] [G loss: 0.864924]\n",
      "epoch:24 step:22691 [D loss: 0.333084, acc.: 88.28%] [G loss: 1.048236]\n",
      "epoch:24 step:22692 [D loss: 0.439526, acc.: 69.53%] [G loss: 0.817985]\n",
      "epoch:24 step:22693 [D loss: 0.455747, acc.: 83.59%] [G loss: 0.938636]\n",
      "epoch:24 step:22694 [D loss: 0.221996, acc.: 96.09%] [G loss: 1.513063]\n",
      "epoch:24 step:22695 [D loss: 0.306709, acc.: 82.03%] [G loss: 0.821332]\n",
      "epoch:24 step:22696 [D loss: 0.318021, acc.: 89.84%] [G loss: 1.321974]\n",
      "epoch:24 step:22697 [D loss: 0.160214, acc.: 100.00%] [G loss: 1.283508]\n",
      "epoch:24 step:22698 [D loss: 1.093478, acc.: 31.25%] [G loss: 1.110131]\n",
      "epoch:24 step:22699 [D loss: 1.235851, acc.: 17.19%] [G loss: 1.470325]\n",
      "epoch:24 step:22700 [D loss: 0.817957, acc.: 48.44%] [G loss: 1.277194]\n",
      "epoch:24 step:22701 [D loss: 0.815011, acc.: 52.34%] [G loss: 1.341380]\n",
      "epoch:24 step:22702 [D loss: 0.675726, acc.: 53.91%] [G loss: 1.046307]\n",
      "epoch:24 step:22703 [D loss: 0.726282, acc.: 52.34%] [G loss: 1.261585]\n",
      "epoch:24 step:22704 [D loss: 0.645236, acc.: 57.03%] [G loss: 1.123289]\n",
      "epoch:24 step:22705 [D loss: 0.533835, acc.: 71.09%] [G loss: 1.081534]\n",
      "epoch:24 step:22706 [D loss: 0.366562, acc.: 86.72%] [G loss: 1.242471]\n",
      "epoch:24 step:22707 [D loss: 0.337983, acc.: 89.06%] [G loss: 1.265435]\n",
      "epoch:24 step:22708 [D loss: 0.324138, acc.: 92.97%] [G loss: 1.306428]\n",
      "epoch:24 step:22709 [D loss: 0.459730, acc.: 78.91%] [G loss: 1.256612]\n",
      "epoch:24 step:22710 [D loss: 0.298576, acc.: 95.31%] [G loss: 1.425619]\n",
      "epoch:24 step:22711 [D loss: 0.510851, acc.: 75.78%] [G loss: 1.504465]\n",
      "epoch:24 step:22712 [D loss: 0.719423, acc.: 60.16%] [G loss: 1.406445]\n",
      "epoch:24 step:22713 [D loss: 0.435048, acc.: 87.50%] [G loss: 1.173653]\n",
      "epoch:24 step:22714 [D loss: 0.719725, acc.: 52.34%] [G loss: 1.326145]\n",
      "epoch:24 step:22715 [D loss: 0.674129, acc.: 57.81%] [G loss: 1.088606]\n",
      "epoch:24 step:22716 [D loss: 0.718911, acc.: 50.00%] [G loss: 1.328550]\n",
      "epoch:24 step:22717 [D loss: 0.672200, acc.: 60.16%] [G loss: 1.123208]\n",
      "epoch:24 step:22718 [D loss: 0.221517, acc.: 99.22%] [G loss: 1.220289]\n",
      "epoch:24 step:22719 [D loss: 0.228596, acc.: 96.88%] [G loss: 1.282212]\n",
      "epoch:24 step:22720 [D loss: 0.241648, acc.: 94.53%] [G loss: 1.304319]\n",
      "epoch:24 step:22721 [D loss: 0.648423, acc.: 67.97%] [G loss: 1.599503]\n",
      "epoch:24 step:22722 [D loss: 0.466578, acc.: 82.81%] [G loss: 1.309186]\n",
      "epoch:24 step:22723 [D loss: 0.390962, acc.: 87.50%] [G loss: 1.380922]\n",
      "epoch:24 step:22724 [D loss: 0.639856, acc.: 67.19%] [G loss: 1.207890]\n",
      "epoch:24 step:22725 [D loss: 0.445512, acc.: 85.16%] [G loss: 1.401127]\n",
      "epoch:24 step:22726 [D loss: 0.254115, acc.: 95.31%] [G loss: 1.523059]\n",
      "epoch:24 step:22727 [D loss: 0.513664, acc.: 75.00%] [G loss: 1.263170]\n",
      "epoch:24 step:22728 [D loss: 0.494440, acc.: 76.56%] [G loss: 1.369172]\n",
      "epoch:24 step:22729 [D loss: 0.727228, acc.: 53.91%] [G loss: 1.073918]\n",
      "epoch:24 step:22730 [D loss: 0.695504, acc.: 50.78%] [G loss: 1.210367]\n",
      "epoch:24 step:22731 [D loss: 0.371212, acc.: 85.16%] [G loss: 1.125028]\n",
      "epoch:24 step:22732 [D loss: 0.676047, acc.: 56.25%] [G loss: 1.029543]\n",
      "epoch:24 step:22733 [D loss: 0.818269, acc.: 39.84%] [G loss: 0.997675]\n",
      "epoch:24 step:22734 [D loss: 0.727565, acc.: 56.25%] [G loss: 0.936761]\n",
      "epoch:24 step:22735 [D loss: 0.705536, acc.: 60.16%] [G loss: 0.912011]\n",
      "epoch:24 step:22736 [D loss: 0.629124, acc.: 66.41%] [G loss: 1.017513]\n",
      "epoch:24 step:22737 [D loss: 0.631349, acc.: 64.84%] [G loss: 1.035340]\n",
      "epoch:24 step:22738 [D loss: 0.740540, acc.: 47.66%] [G loss: 0.989322]\n",
      "epoch:24 step:22739 [D loss: 0.561219, acc.: 75.78%] [G loss: 1.050072]\n",
      "epoch:24 step:22740 [D loss: 0.586270, acc.: 66.41%] [G loss: 1.084210]\n",
      "epoch:24 step:22741 [D loss: 0.462259, acc.: 83.59%] [G loss: 0.855634]\n",
      "epoch:24 step:22742 [D loss: 0.384276, acc.: 82.81%] [G loss: 0.877557]\n",
      "epoch:24 step:22743 [D loss: 0.280327, acc.: 86.72%] [G loss: 1.286683]\n",
      "epoch:24 step:22744 [D loss: 0.291390, acc.: 85.94%] [G loss: 1.541610]\n",
      "epoch:24 step:22745 [D loss: 0.236161, acc.: 95.31%] [G loss: 1.506194]\n",
      "epoch:24 step:22746 [D loss: 0.583617, acc.: 68.75%] [G loss: 1.529373]\n",
      "epoch:24 step:22747 [D loss: 0.193260, acc.: 94.53%] [G loss: 1.491020]\n",
      "epoch:24 step:22748 [D loss: 0.214268, acc.: 96.88%] [G loss: 1.384388]\n",
      "epoch:24 step:22749 [D loss: 0.189341, acc.: 96.88%] [G loss: 0.897574]\n",
      "epoch:24 step:22750 [D loss: 0.734139, acc.: 52.34%] [G loss: 1.381800]\n",
      "epoch:24 step:22751 [D loss: 0.132200, acc.: 99.22%] [G loss: 0.937369]\n",
      "epoch:24 step:22752 [D loss: 0.718303, acc.: 54.69%] [G loss: 1.245147]\n",
      "epoch:24 step:22753 [D loss: 0.500718, acc.: 83.59%] [G loss: 1.282146]\n",
      "epoch:24 step:22754 [D loss: 0.732909, acc.: 58.59%] [G loss: 1.157172]\n",
      "epoch:24 step:22755 [D loss: 0.656088, acc.: 58.59%] [G loss: 0.368422]\n",
      "epoch:24 step:22756 [D loss: 1.233782, acc.: 17.97%] [G loss: 1.275911]\n",
      "epoch:24 step:22757 [D loss: 0.526339, acc.: 73.44%] [G loss: 1.151092]\n",
      "epoch:24 step:22758 [D loss: 0.656794, acc.: 64.06%] [G loss: 1.173463]\n",
      "epoch:24 step:22759 [D loss: 0.413114, acc.: 85.94%] [G loss: 1.413748]\n",
      "epoch:24 step:22760 [D loss: 0.539394, acc.: 78.12%] [G loss: 1.214712]\n",
      "epoch:24 step:22761 [D loss: 0.666916, acc.: 66.41%] [G loss: 1.309776]\n",
      "epoch:24 step:22762 [D loss: 0.424982, acc.: 83.59%] [G loss: 0.941628]\n",
      "epoch:24 step:22763 [D loss: 0.417182, acc.: 86.72%] [G loss: 1.176068]\n",
      "epoch:24 step:22764 [D loss: 0.318216, acc.: 96.88%] [G loss: 1.242104]\n",
      "epoch:24 step:22765 [D loss: 0.654233, acc.: 60.94%] [G loss: 1.465205]\n",
      "epoch:24 step:22766 [D loss: 0.350802, acc.: 89.06%] [G loss: 1.522105]\n",
      "epoch:24 step:22767 [D loss: 0.137521, acc.: 99.22%] [G loss: 1.616323]\n",
      "epoch:24 step:22768 [D loss: 0.702250, acc.: 60.16%] [G loss: 0.888425]\n",
      "epoch:24 step:22769 [D loss: 0.658869, acc.: 57.03%] [G loss: 1.077150]\n",
      "epoch:24 step:22770 [D loss: 0.539054, acc.: 68.75%] [G loss: 1.014101]\n",
      "epoch:24 step:22771 [D loss: 0.735209, acc.: 52.34%] [G loss: 0.781288]\n",
      "epoch:24 step:22772 [D loss: 0.723553, acc.: 53.91%] [G loss: 1.085567]\n",
      "epoch:24 step:22773 [D loss: 0.524485, acc.: 77.34%] [G loss: 1.136491]\n",
      "epoch:24 step:22774 [D loss: 0.505177, acc.: 71.88%] [G loss: 0.887305]\n",
      "epoch:24 step:22775 [D loss: 0.406603, acc.: 84.38%] [G loss: 1.330584]\n",
      "epoch:24 step:22776 [D loss: 0.335788, acc.: 85.16%] [G loss: 1.284266]\n",
      "epoch:24 step:22777 [D loss: 0.187754, acc.: 99.22%] [G loss: 1.259734]\n",
      "epoch:24 step:22778 [D loss: 0.555704, acc.: 73.44%] [G loss: 1.238377]\n",
      "epoch:24 step:22779 [D loss: 0.532981, acc.: 68.75%] [G loss: 1.284201]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22780 [D loss: 0.261825, acc.: 87.50%] [G loss: 1.557807]\n",
      "epoch:24 step:22781 [D loss: 0.290686, acc.: 96.09%] [G loss: 1.600081]\n",
      "epoch:24 step:22782 [D loss: 0.563686, acc.: 73.44%] [G loss: 1.276651]\n",
      "epoch:24 step:22783 [D loss: 0.972710, acc.: 40.62%] [G loss: 1.067137]\n",
      "epoch:24 step:22784 [D loss: 0.891052, acc.: 43.75%] [G loss: 0.595184]\n",
      "epoch:24 step:22785 [D loss: 0.766811, acc.: 51.56%] [G loss: 1.157894]\n",
      "epoch:24 step:22786 [D loss: 0.516309, acc.: 77.34%] [G loss: 0.792305]\n",
      "epoch:24 step:22787 [D loss: 0.388509, acc.: 90.62%] [G loss: 1.210575]\n",
      "epoch:24 step:22788 [D loss: 0.611979, acc.: 61.72%] [G loss: 1.211059]\n",
      "epoch:24 step:22789 [D loss: 0.911773, acc.: 41.41%] [G loss: 1.224420]\n",
      "epoch:24 step:22790 [D loss: 0.733915, acc.: 54.69%] [G loss: 1.307447]\n",
      "epoch:24 step:22791 [D loss: 0.786680, acc.: 43.75%] [G loss: 1.244686]\n",
      "epoch:24 step:22792 [D loss: 0.676569, acc.: 64.06%] [G loss: 1.009083]\n",
      "epoch:24 step:22793 [D loss: 0.308395, acc.: 96.88%] [G loss: 1.245748]\n",
      "epoch:24 step:22794 [D loss: 0.486538, acc.: 79.69%] [G loss: 1.158415]\n",
      "epoch:24 step:22795 [D loss: 0.615339, acc.: 65.62%] [G loss: 1.123416]\n",
      "epoch:24 step:22796 [D loss: 0.306488, acc.: 90.62%] [G loss: 1.128670]\n",
      "epoch:24 step:22797 [D loss: 0.227551, acc.: 92.97%] [G loss: 1.125554]\n",
      "epoch:24 step:22798 [D loss: 0.551500, acc.: 74.22%] [G loss: 1.188754]\n",
      "epoch:24 step:22799 [D loss: 0.594877, acc.: 67.97%] [G loss: 0.786085]\n",
      "epoch:24 step:22800 [D loss: 0.262162, acc.: 86.72%] [G loss: 1.700221]\n",
      "##############\n",
      "[3.80345911 2.67046092 6.22790046 5.68753572 4.42893905 6.25198915\n",
      " 5.40672713 5.79621928 5.78959418 4.88211492]\n",
      "##########\n",
      "epoch:24 step:22801 [D loss: 0.185559, acc.: 96.88%] [G loss: 1.568300]\n",
      "epoch:24 step:22802 [D loss: 0.135313, acc.: 99.22%] [G loss: 1.602437]\n",
      "epoch:24 step:22803 [D loss: 0.652926, acc.: 60.16%] [G loss: 1.558034]\n",
      "epoch:24 step:22804 [D loss: 0.680006, acc.: 59.38%] [G loss: 1.518679]\n",
      "epoch:24 step:22805 [D loss: 0.752944, acc.: 55.47%] [G loss: 1.325849]\n",
      "epoch:24 step:22806 [D loss: 0.534477, acc.: 71.88%] [G loss: 1.209570]\n",
      "epoch:24 step:22807 [D loss: 0.582666, acc.: 68.75%] [G loss: 1.349436]\n",
      "epoch:24 step:22808 [D loss: 0.457128, acc.: 89.84%] [G loss: 1.279199]\n",
      "epoch:24 step:22809 [D loss: 0.518360, acc.: 75.78%] [G loss: 1.105025]\n",
      "epoch:24 step:22810 [D loss: 0.453848, acc.: 83.59%] [G loss: 1.261995]\n",
      "epoch:24 step:22811 [D loss: 0.674058, acc.: 59.38%] [G loss: 0.927923]\n",
      "epoch:24 step:22812 [D loss: 0.659302, acc.: 61.72%] [G loss: 0.818234]\n",
      "epoch:24 step:22813 [D loss: 0.595471, acc.: 66.41%] [G loss: 1.016636]\n",
      "epoch:24 step:22814 [D loss: 0.423660, acc.: 82.81%] [G loss: 1.200738]\n",
      "epoch:24 step:22815 [D loss: 0.308769, acc.: 87.50%] [G loss: 0.964782]\n",
      "epoch:24 step:22816 [D loss: 0.188450, acc.: 96.88%] [G loss: 1.609258]\n",
      "epoch:24 step:22817 [D loss: 0.572441, acc.: 69.53%] [G loss: 1.141513]\n",
      "epoch:24 step:22818 [D loss: 0.802508, acc.: 46.09%] [G loss: 1.055954]\n",
      "epoch:24 step:22819 [D loss: 0.798910, acc.: 42.97%] [G loss: 1.207869]\n",
      "epoch:24 step:22820 [D loss: 0.625072, acc.: 68.75%] [G loss: 1.157308]\n",
      "epoch:24 step:22821 [D loss: 0.666791, acc.: 64.06%] [G loss: 0.702066]\n",
      "epoch:24 step:22822 [D loss: 0.508879, acc.: 75.78%] [G loss: 1.310399]\n",
      "epoch:24 step:22823 [D loss: 0.573383, acc.: 73.44%] [G loss: 1.497276]\n",
      "epoch:24 step:22824 [D loss: 0.232882, acc.: 92.19%] [G loss: 1.328321]\n",
      "epoch:24 step:22825 [D loss: 0.675459, acc.: 60.16%] [G loss: 1.304446]\n",
      "epoch:24 step:22826 [D loss: 0.689634, acc.: 60.16%] [G loss: 1.269951]\n",
      "epoch:24 step:22827 [D loss: 0.720661, acc.: 49.22%] [G loss: 0.930403]\n",
      "epoch:24 step:22828 [D loss: 0.814280, acc.: 44.53%] [G loss: 1.132190]\n",
      "epoch:24 step:22829 [D loss: 0.719474, acc.: 52.34%] [G loss: 1.135797]\n",
      "epoch:24 step:22830 [D loss: 0.287338, acc.: 89.84%] [G loss: 1.231405]\n",
      "epoch:24 step:22831 [D loss: 0.237955, acc.: 92.19%] [G loss: 1.245194]\n",
      "epoch:24 step:22832 [D loss: 0.212843, acc.: 94.53%] [G loss: 1.341341]\n",
      "epoch:24 step:22833 [D loss: 0.191847, acc.: 94.53%] [G loss: 1.410703]\n",
      "epoch:24 step:22834 [D loss: 0.159820, acc.: 96.88%] [G loss: 1.525039]\n",
      "epoch:24 step:22835 [D loss: 0.126866, acc.: 99.22%] [G loss: 1.664607]\n",
      "epoch:24 step:22836 [D loss: 0.793541, acc.: 56.25%] [G loss: 1.293581]\n",
      "epoch:24 step:22837 [D loss: 0.811568, acc.: 46.88%] [G loss: 1.361591]\n",
      "epoch:24 step:22838 [D loss: 0.711124, acc.: 53.91%] [G loss: 1.393790]\n",
      "epoch:24 step:22839 [D loss: 0.500053, acc.: 79.69%] [G loss: 0.879681]\n",
      "epoch:24 step:22840 [D loss: 0.489985, acc.: 82.03%] [G loss: 1.112039]\n",
      "epoch:24 step:22841 [D loss: 0.393868, acc.: 85.16%] [G loss: 1.251329]\n",
      "epoch:24 step:22842 [D loss: 0.383258, acc.: 92.97%] [G loss: 1.088423]\n",
      "epoch:24 step:22843 [D loss: 0.802781, acc.: 46.88%] [G loss: 1.230398]\n",
      "epoch:24 step:22844 [D loss: 0.694599, acc.: 53.91%] [G loss: 1.292925]\n",
      "epoch:24 step:22845 [D loss: 0.543810, acc.: 74.22%] [G loss: 1.251723]\n",
      "epoch:24 step:22846 [D loss: 0.381995, acc.: 86.72%] [G loss: 1.196764]\n",
      "epoch:24 step:22847 [D loss: 0.617430, acc.: 67.19%] [G loss: 0.779455]\n",
      "epoch:24 step:22848 [D loss: 0.868773, acc.: 47.66%] [G loss: 0.801430]\n",
      "epoch:24 step:22849 [D loss: 0.571440, acc.: 72.66%] [G loss: 1.237184]\n",
      "epoch:24 step:22850 [D loss: 0.591136, acc.: 70.31%] [G loss: 1.407832]\n",
      "epoch:24 step:22851 [D loss: 0.240296, acc.: 95.31%] [G loss: 1.489264]\n",
      "epoch:24 step:22852 [D loss: 0.615489, acc.: 63.28%] [G loss: 1.312214]\n",
      "epoch:24 step:22853 [D loss: 0.278159, acc.: 88.28%] [G loss: 1.236955]\n",
      "epoch:24 step:22854 [D loss: 0.326589, acc.: 80.47%] [G loss: 1.433114]\n",
      "epoch:24 step:22855 [D loss: 0.259324, acc.: 92.97%] [G loss: 1.576370]\n",
      "epoch:24 step:22856 [D loss: 0.597028, acc.: 70.31%] [G loss: 1.039185]\n",
      "epoch:24 step:22857 [D loss: 0.543391, acc.: 76.56%] [G loss: 1.305706]\n",
      "epoch:24 step:22858 [D loss: 0.615716, acc.: 71.88%] [G loss: 1.417569]\n",
      "epoch:24 step:22859 [D loss: 0.268285, acc.: 95.31%] [G loss: 1.680705]\n",
      "epoch:24 step:22860 [D loss: 0.676971, acc.: 64.06%] [G loss: 1.501596]\n",
      "epoch:24 step:22861 [D loss: 0.690551, acc.: 52.34%] [G loss: 1.223295]\n",
      "epoch:24 step:22862 [D loss: 0.766727, acc.: 52.34%] [G loss: 1.191503]\n",
      "epoch:24 step:22863 [D loss: 0.483206, acc.: 78.91%] [G loss: 1.306399]\n",
      "epoch:24 step:22864 [D loss: 0.606787, acc.: 71.09%] [G loss: 0.892175]\n",
      "epoch:24 step:22865 [D loss: 0.205615, acc.: 93.75%] [G loss: 1.172548]\n",
      "epoch:24 step:22866 [D loss: 0.271817, acc.: 86.72%] [G loss: 1.525644]\n",
      "epoch:24 step:22867 [D loss: 0.768990, acc.: 50.78%] [G loss: 1.496046]\n",
      "epoch:24 step:22868 [D loss: 0.496326, acc.: 76.56%] [G loss: 0.955773]\n",
      "epoch:24 step:22869 [D loss: 0.550935, acc.: 71.09%] [G loss: 1.422924]\n",
      "epoch:24 step:22870 [D loss: 0.667642, acc.: 62.50%] [G loss: 1.312538]\n",
      "epoch:24 step:22871 [D loss: 0.568211, acc.: 73.44%] [G loss: 1.102558]\n",
      "epoch:24 step:22872 [D loss: 0.345419, acc.: 90.62%] [G loss: 1.485111]\n",
      "epoch:24 step:22873 [D loss: 0.809480, acc.: 49.22%] [G loss: 1.052958]\n",
      "epoch:24 step:22874 [D loss: 0.828550, acc.: 50.00%] [G loss: 1.298761]\n",
      "epoch:24 step:22875 [D loss: 0.441493, acc.: 92.19%] [G loss: 1.092999]\n",
      "epoch:24 step:22876 [D loss: 0.541416, acc.: 72.66%] [G loss: 1.105544]\n",
      "epoch:24 step:22877 [D loss: 0.279027, acc.: 89.06%] [G loss: 1.565278]\n",
      "epoch:24 step:22878 [D loss: 0.248368, acc.: 97.66%] [G loss: 1.561413]\n",
      "epoch:24 step:22879 [D loss: 0.539006, acc.: 69.53%] [G loss: 1.413564]\n",
      "epoch:24 step:22880 [D loss: 1.203106, acc.: 53.91%] [G loss: 1.575453]\n",
      "epoch:24 step:22881 [D loss: 0.131421, acc.: 100.00%] [G loss: 1.760224]\n",
      "epoch:24 step:22882 [D loss: 0.747615, acc.: 53.12%] [G loss: 1.450227]\n",
      "epoch:24 step:22883 [D loss: 0.817134, acc.: 47.66%] [G loss: 1.199489]\n",
      "epoch:24 step:22884 [D loss: 0.186558, acc.: 96.09%] [G loss: 1.453383]\n",
      "epoch:24 step:22885 [D loss: 0.251543, acc.: 89.06%] [G loss: 1.050202]\n",
      "epoch:24 step:22886 [D loss: 0.188612, acc.: 98.44%] [G loss: 0.854089]\n",
      "epoch:24 step:22887 [D loss: 0.557863, acc.: 64.06%] [G loss: 1.455629]\n",
      "epoch:24 step:22888 [D loss: 0.143477, acc.: 98.44%] [G loss: 1.485176]\n",
      "epoch:24 step:22889 [D loss: 0.257835, acc.: 94.53%] [G loss: 2.077131]\n",
      "epoch:24 step:22890 [D loss: 0.145911, acc.: 100.00%] [G loss: 1.760326]\n",
      "epoch:24 step:22891 [D loss: 0.675034, acc.: 58.59%] [G loss: 1.234480]\n",
      "epoch:24 step:22892 [D loss: 0.188514, acc.: 98.44%] [G loss: 0.197472]\n",
      "epoch:24 step:22893 [D loss: 1.650769, acc.: 50.00%] [G loss: 0.768761]\n",
      "epoch:24 step:22894 [D loss: 0.405232, acc.: 83.59%] [G loss: 2.357114]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22895 [D loss: 0.429218, acc.: 78.91%] [G loss: 2.017619]\n",
      "epoch:24 step:22896 [D loss: 1.352104, acc.: 14.84%] [G loss: 1.688536]\n",
      "epoch:24 step:22897 [D loss: 0.639392, acc.: 67.19%] [G loss: 1.435779]\n",
      "epoch:24 step:22898 [D loss: 1.082526, acc.: 32.81%] [G loss: 1.553591]\n",
      "epoch:24 step:22899 [D loss: 1.218773, acc.: 36.72%] [G loss: 1.450150]\n",
      "epoch:24 step:22900 [D loss: 1.078392, acc.: 36.72%] [G loss: 1.205670]\n",
      "epoch:24 step:22901 [D loss: 1.110715, acc.: 26.56%] [G loss: 0.963516]\n",
      "epoch:24 step:22902 [D loss: 0.833050, acc.: 50.78%] [G loss: 0.773769]\n",
      "epoch:24 step:22903 [D loss: 0.770537, acc.: 54.69%] [G loss: 1.037166]\n",
      "epoch:24 step:22904 [D loss: 0.846033, acc.: 41.41%] [G loss: 1.516147]\n",
      "epoch:24 step:22905 [D loss: 0.674595, acc.: 60.94%] [G loss: 1.163938]\n",
      "epoch:24 step:22906 [D loss: 0.848365, acc.: 38.28%] [G loss: 1.042308]\n",
      "epoch:24 step:22907 [D loss: 0.658432, acc.: 64.06%] [G loss: 1.265177]\n",
      "epoch:24 step:22908 [D loss: 0.720718, acc.: 48.44%] [G loss: 1.088637]\n",
      "epoch:24 step:22909 [D loss: 0.734444, acc.: 48.44%] [G loss: 1.096136]\n",
      "epoch:24 step:22910 [D loss: 0.739773, acc.: 50.78%] [G loss: 1.234219]\n",
      "epoch:24 step:22911 [D loss: 0.681204, acc.: 53.12%] [G loss: 1.140870]\n",
      "epoch:24 step:22912 [D loss: 0.572950, acc.: 69.53%] [G loss: 1.132184]\n",
      "epoch:24 step:22913 [D loss: 0.603906, acc.: 70.31%] [G loss: 1.049184]\n",
      "epoch:24 step:22914 [D loss: 0.645055, acc.: 59.38%] [G loss: 1.432852]\n",
      "epoch:24 step:22915 [D loss: 0.586797, acc.: 68.75%] [G loss: 0.897035]\n",
      "epoch:24 step:22916 [D loss: 0.563097, acc.: 74.22%] [G loss: 1.136656]\n",
      "epoch:24 step:22917 [D loss: 0.671417, acc.: 60.16%] [G loss: 1.374638]\n",
      "epoch:24 step:22918 [D loss: 0.477229, acc.: 83.59%] [G loss: 0.986381]\n",
      "epoch:24 step:22919 [D loss: 0.663874, acc.: 59.38%] [G loss: 1.078156]\n",
      "epoch:24 step:22920 [D loss: 0.572510, acc.: 67.19%] [G loss: 0.782793]\n",
      "epoch:24 step:22921 [D loss: 0.578173, acc.: 61.72%] [G loss: 1.319435]\n",
      "epoch:24 step:22922 [D loss: 0.570932, acc.: 67.97%] [G loss: 1.397965]\n",
      "epoch:24 step:22923 [D loss: 0.551586, acc.: 71.09%] [G loss: 1.339681]\n",
      "epoch:24 step:22924 [D loss: 0.564804, acc.: 67.97%] [G loss: 1.346974]\n",
      "epoch:24 step:22925 [D loss: 0.637378, acc.: 57.03%] [G loss: 1.280183]\n",
      "epoch:24 step:22926 [D loss: 0.782210, acc.: 51.56%] [G loss: 1.059528]\n",
      "epoch:24 step:22927 [D loss: 0.628627, acc.: 63.28%] [G loss: 1.236220]\n",
      "epoch:24 step:22928 [D loss: 0.563834, acc.: 68.75%] [G loss: 1.287285]\n",
      "epoch:24 step:22929 [D loss: 0.544772, acc.: 73.44%] [G loss: 1.043570]\n",
      "epoch:24 step:22930 [D loss: 0.649124, acc.: 64.06%] [G loss: 0.950271]\n",
      "epoch:24 step:22931 [D loss: 0.465419, acc.: 90.62%] [G loss: 0.948117]\n",
      "epoch:24 step:22932 [D loss: 0.586741, acc.: 69.53%] [G loss: 1.485444]\n",
      "epoch:24 step:22933 [D loss: 0.540618, acc.: 71.88%] [G loss: 1.238906]\n",
      "epoch:24 step:22934 [D loss: 0.579302, acc.: 65.62%] [G loss: 1.062333]\n",
      "epoch:24 step:22935 [D loss: 0.548574, acc.: 71.88%] [G loss: 1.266479]\n",
      "epoch:24 step:22936 [D loss: 0.378717, acc.: 90.62%] [G loss: 1.246752]\n",
      "epoch:24 step:22937 [D loss: 0.355183, acc.: 89.06%] [G loss: 1.314324]\n",
      "epoch:24 step:22938 [D loss: 0.374026, acc.: 93.75%] [G loss: 1.472041]\n",
      "epoch:24 step:22939 [D loss: 0.270796, acc.: 99.22%] [G loss: 1.391989]\n",
      "epoch:24 step:22940 [D loss: 0.257455, acc.: 96.09%] [G loss: 1.624638]\n",
      "epoch:24 step:22941 [D loss: 0.289168, acc.: 94.53%] [G loss: 1.787987]\n",
      "epoch:24 step:22942 [D loss: 0.330467, acc.: 92.19%] [G loss: 1.465573]\n",
      "epoch:24 step:22943 [D loss: 0.385063, acc.: 88.28%] [G loss: 1.830150]\n",
      "epoch:24 step:22944 [D loss: 0.197667, acc.: 93.75%] [G loss: 1.697996]\n",
      "epoch:24 step:22945 [D loss: 0.286373, acc.: 96.88%] [G loss: 1.369780]\n",
      "epoch:24 step:22946 [D loss: 0.582705, acc.: 68.75%] [G loss: 1.231925]\n",
      "epoch:24 step:22947 [D loss: 0.626505, acc.: 62.50%] [G loss: 1.349454]\n",
      "epoch:24 step:22948 [D loss: 0.744507, acc.: 46.09%] [G loss: 1.462564]\n",
      "epoch:24 step:22949 [D loss: 1.050685, acc.: 37.50%] [G loss: 0.924569]\n",
      "epoch:24 step:22950 [D loss: 1.368215, acc.: 19.53%] [G loss: 0.877896]\n",
      "epoch:24 step:22951 [D loss: 0.892458, acc.: 39.06%] [G loss: 0.720701]\n",
      "epoch:24 step:22952 [D loss: 0.614000, acc.: 65.62%] [G loss: 0.942331]\n",
      "epoch:24 step:22953 [D loss: 0.490952, acc.: 76.56%] [G loss: 0.896836]\n",
      "epoch:24 step:22954 [D loss: 0.601368, acc.: 63.28%] [G loss: 0.794704]\n",
      "epoch:24 step:22955 [D loss: 0.438073, acc.: 80.47%] [G loss: 1.216336]\n",
      "epoch:24 step:22956 [D loss: 0.281232, acc.: 90.62%] [G loss: 1.047776]\n",
      "epoch:24 step:22957 [D loss: 0.337934, acc.: 87.50%] [G loss: 1.280283]\n",
      "epoch:24 step:22958 [D loss: 0.234393, acc.: 93.75%] [G loss: 1.597546]\n",
      "epoch:24 step:22959 [D loss: 0.171001, acc.: 98.44%] [G loss: 1.650037]\n",
      "epoch:24 step:22960 [D loss: 0.365755, acc.: 94.53%] [G loss: 1.668666]\n",
      "epoch:24 step:22961 [D loss: 1.111216, acc.: 48.44%] [G loss: 1.424201]\n",
      "epoch:24 step:22962 [D loss: 0.957882, acc.: 43.75%] [G loss: 1.131727]\n",
      "epoch:24 step:22963 [D loss: 0.759035, acc.: 53.91%] [G loss: 1.043851]\n",
      "epoch:24 step:22964 [D loss: 0.631192, acc.: 68.75%] [G loss: 1.105744]\n",
      "epoch:24 step:22965 [D loss: 0.642965, acc.: 60.16%] [G loss: 0.917807]\n",
      "epoch:24 step:22966 [D loss: 0.573430, acc.: 74.22%] [G loss: 1.087344]\n",
      "epoch:24 step:22967 [D loss: 0.441421, acc.: 76.56%] [G loss: 1.289186]\n",
      "epoch:24 step:22968 [D loss: 0.473257, acc.: 75.78%] [G loss: 0.774898]\n",
      "epoch:24 step:22969 [D loss: 0.332018, acc.: 90.62%] [G loss: 1.206918]\n",
      "epoch:24 step:22970 [D loss: 1.086045, acc.: 32.03%] [G loss: 1.565550]\n",
      "epoch:24 step:22971 [D loss: 0.861962, acc.: 43.75%] [G loss: 0.968181]\n",
      "epoch:24 step:22972 [D loss: 0.837747, acc.: 39.84%] [G loss: 1.187072]\n",
      "epoch:24 step:22973 [D loss: 0.670945, acc.: 57.81%] [G loss: 1.107113]\n",
      "epoch:24 step:22974 [D loss: 0.741866, acc.: 49.22%] [G loss: 1.045889]\n",
      "epoch:24 step:22975 [D loss: 0.744544, acc.: 48.44%] [G loss: 1.128932]\n",
      "epoch:24 step:22976 [D loss: 0.699509, acc.: 46.88%] [G loss: 1.080557]\n",
      "epoch:24 step:22977 [D loss: 0.600491, acc.: 67.97%] [G loss: 1.020683]\n",
      "epoch:24 step:22978 [D loss: 0.514584, acc.: 79.69%] [G loss: 0.975818]\n",
      "epoch:24 step:22979 [D loss: 0.590911, acc.: 71.09%] [G loss: 1.192774]\n",
      "epoch:24 step:22980 [D loss: 0.659520, acc.: 57.81%] [G loss: 0.970972]\n",
      "epoch:24 step:22981 [D loss: 0.712642, acc.: 50.78%] [G loss: 0.841048]\n",
      "epoch:24 step:22982 [D loss: 0.640658, acc.: 62.50%] [G loss: 0.976323]\n",
      "epoch:24 step:22983 [D loss: 0.652963, acc.: 59.38%] [G loss: 1.028944]\n",
      "epoch:24 step:22984 [D loss: 0.681539, acc.: 57.81%] [G loss: 0.992849]\n",
      "epoch:24 step:22985 [D loss: 0.591703, acc.: 68.75%] [G loss: 1.115829]\n",
      "epoch:24 step:22986 [D loss: 0.595329, acc.: 68.75%] [G loss: 1.415966]\n",
      "epoch:24 step:22987 [D loss: 0.481452, acc.: 83.59%] [G loss: 1.220627]\n",
      "epoch:24 step:22988 [D loss: 0.721926, acc.: 53.91%] [G loss: 1.191735]\n",
      "epoch:24 step:22989 [D loss: 0.633118, acc.: 60.94%] [G loss: 1.047452]\n",
      "epoch:24 step:22990 [D loss: 0.800524, acc.: 47.66%] [G loss: 0.941704]\n",
      "epoch:24 step:22991 [D loss: 0.413759, acc.: 82.03%] [G loss: 1.184203]\n",
      "epoch:24 step:22992 [D loss: 0.376641, acc.: 86.72%] [G loss: 1.344137]\n",
      "epoch:24 step:22993 [D loss: 0.541130, acc.: 75.78%] [G loss: 1.333298]\n",
      "epoch:24 step:22994 [D loss: 0.648678, acc.: 61.72%] [G loss: 1.253152]\n",
      "epoch:24 step:22995 [D loss: 0.574951, acc.: 68.75%] [G loss: 1.171830]\n",
      "epoch:24 step:22996 [D loss: 0.551668, acc.: 71.09%] [G loss: 1.021765]\n",
      "epoch:24 step:22997 [D loss: 0.742218, acc.: 48.44%] [G loss: 1.089338]\n",
      "epoch:24 step:22998 [D loss: 0.537591, acc.: 77.34%] [G loss: 0.984223]\n",
      "epoch:24 step:22999 [D loss: 0.472964, acc.: 79.69%] [G loss: 1.148917]\n",
      "epoch:24 step:23000 [D loss: 0.474528, acc.: 84.38%] [G loss: 1.368318]\n",
      "##############\n",
      "[3.97433313 2.6615429  6.47845236 5.59965483 4.6416021  5.8274376\n",
      " 5.28585996 5.30770159 6.06771792 5.24494798]\n",
      "##########\n",
      "epoch:24 step:23001 [D loss: 0.453367, acc.: 82.81%] [G loss: 1.178277]\n",
      "epoch:24 step:23002 [D loss: 0.455651, acc.: 86.72%] [G loss: 1.222956]\n",
      "epoch:24 step:23003 [D loss: 0.368215, acc.: 88.28%] [G loss: 1.779912]\n",
      "epoch:24 step:23004 [D loss: 0.757077, acc.: 57.81%] [G loss: 1.184011]\n",
      "epoch:24 step:23005 [D loss: 0.446404, acc.: 85.94%] [G loss: 1.100853]\n",
      "epoch:24 step:23006 [D loss: 0.644770, acc.: 66.41%] [G loss: 0.853564]\n",
      "epoch:24 step:23007 [D loss: 0.703840, acc.: 56.25%] [G loss: 1.004603]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:23008 [D loss: 0.567694, acc.: 71.09%] [G loss: 1.456164]\n",
      "epoch:24 step:23009 [D loss: 0.599836, acc.: 66.41%] [G loss: 1.035454]\n",
      "epoch:24 step:23010 [D loss: 0.664558, acc.: 60.94%] [G loss: 0.720665]\n",
      "epoch:24 step:23011 [D loss: 0.598248, acc.: 69.53%] [G loss: 1.049766]\n",
      "epoch:24 step:23012 [D loss: 0.458949, acc.: 81.25%] [G loss: 1.084668]\n",
      "epoch:24 step:23013 [D loss: 0.614713, acc.: 64.06%] [G loss: 1.169106]\n",
      "epoch:24 step:23014 [D loss: 0.609367, acc.: 65.62%] [G loss: 1.033096]\n",
      "epoch:24 step:23015 [D loss: 0.425455, acc.: 83.59%] [G loss: 1.296046]\n",
      "epoch:24 step:23016 [D loss: 0.509005, acc.: 77.34%] [G loss: 1.620499]\n",
      "epoch:24 step:23017 [D loss: 0.584083, acc.: 70.31%] [G loss: 1.240701]\n",
      "epoch:24 step:23018 [D loss: 0.396318, acc.: 87.50%] [G loss: 1.290835]\n",
      "epoch:24 step:23019 [D loss: 0.786839, acc.: 44.53%] [G loss: 0.954343]\n",
      "epoch:24 step:23020 [D loss: 0.646424, acc.: 61.72%] [G loss: 0.898964]\n",
      "epoch:24 step:23021 [D loss: 0.508591, acc.: 74.22%] [G loss: 1.081692]\n",
      "epoch:24 step:23022 [D loss: 0.581603, acc.: 64.06%] [G loss: 0.898622]\n",
      "epoch:24 step:23023 [D loss: 0.422456, acc.: 80.47%] [G loss: 1.163586]\n",
      "epoch:24 step:23024 [D loss: 0.317325, acc.: 92.19%] [G loss: 1.105043]\n",
      "epoch:24 step:23025 [D loss: 0.308489, acc.: 94.53%] [G loss: 1.496230]\n",
      "epoch:24 step:23026 [D loss: 0.480804, acc.: 82.81%] [G loss: 1.420091]\n",
      "epoch:24 step:23027 [D loss: 0.357851, acc.: 91.41%] [G loss: 1.462458]\n",
      "epoch:24 step:23028 [D loss: 0.533081, acc.: 76.56%] [G loss: 1.102295]\n",
      "epoch:24 step:23029 [D loss: 0.474992, acc.: 83.59%] [G loss: 1.879774]\n",
      "epoch:24 step:23030 [D loss: 0.677248, acc.: 55.47%] [G loss: 1.379574]\n",
      "epoch:24 step:23031 [D loss: 0.190933, acc.: 93.75%] [G loss: 1.089760]\n",
      "epoch:24 step:23032 [D loss: 0.670914, acc.: 61.72%] [G loss: 1.170864]\n",
      "epoch:24 step:23033 [D loss: 0.327258, acc.: 89.84%] [G loss: 1.576741]\n",
      "epoch:24 step:23034 [D loss: 0.443243, acc.: 82.81%] [G loss: 1.321100]\n",
      "epoch:24 step:23035 [D loss: 0.375406, acc.: 91.41%] [G loss: 1.346390]\n",
      "epoch:24 step:23036 [D loss: 0.292420, acc.: 91.41%] [G loss: 1.209022]\n",
      "epoch:24 step:23037 [D loss: 0.183017, acc.: 97.66%] [G loss: 1.659386]\n",
      "epoch:24 step:23038 [D loss: 0.126413, acc.: 99.22%] [G loss: 1.571193]\n",
      "epoch:24 step:23039 [D loss: 0.319035, acc.: 89.84%] [G loss: 1.686732]\n",
      "epoch:24 step:23040 [D loss: 0.307079, acc.: 93.75%] [G loss: 1.646870]\n",
      "epoch:24 step:23041 [D loss: 0.290701, acc.: 95.31%] [G loss: 1.674823]\n",
      "epoch:24 step:23042 [D loss: 0.115528, acc.: 98.44%] [G loss: 1.939221]\n",
      "epoch:24 step:23043 [D loss: 0.343024, acc.: 85.94%] [G loss: 2.081892]\n",
      "epoch:24 step:23044 [D loss: 0.094374, acc.: 99.22%] [G loss: 2.374162]\n",
      "epoch:24 step:23045 [D loss: 0.074759, acc.: 100.00%] [G loss: 2.248210]\n",
      "epoch:24 step:23046 [D loss: 0.199220, acc.: 97.66%] [G loss: 1.802919]\n",
      "epoch:24 step:23047 [D loss: 0.642011, acc.: 68.75%] [G loss: 1.613567]\n",
      "epoch:24 step:23048 [D loss: 0.710281, acc.: 60.94%] [G loss: 1.511500]\n",
      "epoch:24 step:23049 [D loss: 0.298451, acc.: 94.53%] [G loss: 1.289739]\n",
      "epoch:24 step:23050 [D loss: 0.796594, acc.: 50.00%] [G loss: 1.257728]\n",
      "epoch:24 step:23051 [D loss: 0.937526, acc.: 52.34%] [G loss: 1.278616]\n",
      "epoch:24 step:23052 [D loss: 0.627142, acc.: 64.06%] [G loss: 1.514053]\n",
      "epoch:24 step:23053 [D loss: 0.566954, acc.: 71.88%] [G loss: 1.669295]\n",
      "epoch:24 step:23054 [D loss: 0.299807, acc.: 89.84%] [G loss: 1.365351]\n",
      "epoch:24 step:23055 [D loss: 0.223689, acc.: 94.53%] [G loss: 1.500828]\n",
      "epoch:24 step:23056 [D loss: 0.594158, acc.: 66.41%] [G loss: 1.605474]\n",
      "epoch:24 step:23057 [D loss: 0.822765, acc.: 49.22%] [G loss: 1.168708]\n",
      "epoch:24 step:23058 [D loss: 0.672652, acc.: 60.16%] [G loss: 0.568942]\n",
      "epoch:24 step:23059 [D loss: 0.603245, acc.: 61.72%] [G loss: 1.162927]\n",
      "epoch:24 step:23060 [D loss: 0.846789, acc.: 50.00%] [G loss: 0.986107]\n",
      "epoch:24 step:23061 [D loss: 0.640620, acc.: 62.50%] [G loss: 1.352616]\n",
      "epoch:24 step:23062 [D loss: 0.662744, acc.: 64.84%] [G loss: 1.105432]\n",
      "epoch:24 step:23063 [D loss: 0.571588, acc.: 71.88%] [G loss: 1.045998]\n",
      "epoch:24 step:23064 [D loss: 0.460527, acc.: 82.03%] [G loss: 1.372434]\n",
      "epoch:24 step:23065 [D loss: 0.414733, acc.: 83.59%] [G loss: 1.178532]\n",
      "epoch:24 step:23066 [D loss: 0.282908, acc.: 92.97%] [G loss: 1.306998]\n",
      "epoch:24 step:23067 [D loss: 0.419878, acc.: 84.38%] [G loss: 1.623008]\n",
      "epoch:24 step:23068 [D loss: 0.828442, acc.: 43.75%] [G loss: 1.467990]\n",
      "epoch:24 step:23069 [D loss: 0.553400, acc.: 71.88%] [G loss: 1.230879]\n",
      "epoch:24 step:23070 [D loss: 0.518099, acc.: 73.44%] [G loss: 1.339109]\n",
      "epoch:24 step:23071 [D loss: 0.582957, acc.: 65.62%] [G loss: 1.251706]\n",
      "epoch:24 step:23072 [D loss: 0.626920, acc.: 64.84%] [G loss: 1.236124]\n",
      "epoch:24 step:23073 [D loss: 0.701178, acc.: 67.19%] [G loss: 1.343177]\n",
      "epoch:24 step:23074 [D loss: 0.634226, acc.: 63.28%] [G loss: 1.121676]\n",
      "epoch:24 step:23075 [D loss: 0.179058, acc.: 97.66%] [G loss: 1.409695]\n",
      "epoch:24 step:23076 [D loss: 0.165276, acc.: 97.66%] [G loss: 1.607371]\n",
      "epoch:24 step:23077 [D loss: 0.475352, acc.: 69.53%] [G loss: 2.094150]\n",
      "epoch:24 step:23078 [D loss: 0.753085, acc.: 59.38%] [G loss: 1.683720]\n",
      "epoch:24 step:23079 [D loss: 0.452883, acc.: 79.69%] [G loss: 1.788214]\n",
      "epoch:24 step:23080 [D loss: 0.219159, acc.: 95.31%] [G loss: 1.422180]\n",
      "epoch:24 step:23081 [D loss: 0.689144, acc.: 54.69%] [G loss: 1.439098]\n",
      "epoch:24 step:23082 [D loss: 0.554082, acc.: 67.97%] [G loss: 1.432216]\n",
      "epoch:24 step:23083 [D loss: 0.448382, acc.: 78.12%] [G loss: 1.524955]\n",
      "epoch:24 step:23084 [D loss: 0.646977, acc.: 64.84%] [G loss: 0.483934]\n",
      "epoch:24 step:23085 [D loss: 0.809858, acc.: 54.69%] [G loss: 1.445433]\n",
      "epoch:24 step:23086 [D loss: 0.581719, acc.: 66.41%] [G loss: 0.652822]\n",
      "epoch:24 step:23087 [D loss: 0.978121, acc.: 35.16%] [G loss: 1.136928]\n",
      "epoch:24 step:23088 [D loss: 0.348231, acc.: 77.34%] [G loss: 1.217820]\n",
      "epoch:24 step:23089 [D loss: 0.162512, acc.: 98.44%] [G loss: 1.477211]\n",
      "epoch:24 step:23090 [D loss: 0.184923, acc.: 99.22%] [G loss: 1.811986]\n",
      "epoch:24 step:23091 [D loss: 0.976328, acc.: 42.19%] [G loss: 1.497699]\n",
      "epoch:24 step:23092 [D loss: 0.514921, acc.: 75.78%] [G loss: 1.334068]\n",
      "epoch:24 step:23093 [D loss: 0.773915, acc.: 48.44%] [G loss: 1.359062]\n",
      "epoch:24 step:23094 [D loss: 0.403320, acc.: 85.94%] [G loss: 1.230810]\n",
      "epoch:24 step:23095 [D loss: 0.293096, acc.: 92.19%] [G loss: 1.153772]\n",
      "epoch:24 step:23096 [D loss: 0.173713, acc.: 96.88%] [G loss: 1.613791]\n",
      "epoch:24 step:23097 [D loss: 0.120535, acc.: 100.00%] [G loss: 1.730990]\n",
      "epoch:24 step:23098 [D loss: 0.548487, acc.: 73.44%] [G loss: 1.528361]\n",
      "epoch:24 step:23099 [D loss: 0.160852, acc.: 97.66%] [G loss: 1.273603]\n",
      "epoch:24 step:23100 [D loss: 0.170571, acc.: 96.88%] [G loss: 1.719656]\n",
      "epoch:24 step:23101 [D loss: 0.585340, acc.: 68.75%] [G loss: 1.235693]\n",
      "epoch:24 step:23102 [D loss: 0.515059, acc.: 71.88%] [G loss: 1.176870]\n",
      "epoch:24 step:23103 [D loss: 0.716355, acc.: 59.38%] [G loss: 1.386609]\n",
      "epoch:24 step:23104 [D loss: 0.865464, acc.: 42.19%] [G loss: 1.230775]\n",
      "epoch:24 step:23105 [D loss: 0.995363, acc.: 25.78%] [G loss: 1.127579]\n",
      "epoch:24 step:23106 [D loss: 0.301930, acc.: 85.94%] [G loss: 1.265144]\n",
      "epoch:24 step:23107 [D loss: 0.451659, acc.: 72.66%] [G loss: 1.581325]\n",
      "epoch:24 step:23108 [D loss: 0.199966, acc.: 96.88%] [G loss: 1.557518]\n",
      "epoch:24 step:23109 [D loss: 0.373548, acc.: 88.28%] [G loss: 1.540376]\n",
      "epoch:24 step:23110 [D loss: 0.956226, acc.: 44.53%] [G loss: 1.184320]\n",
      "epoch:24 step:23111 [D loss: 0.748047, acc.: 53.12%] [G loss: 0.504937]\n",
      "epoch:24 step:23112 [D loss: 0.753294, acc.: 51.56%] [G loss: 0.934521]\n",
      "epoch:24 step:23113 [D loss: 0.265556, acc.: 92.97%] [G loss: 0.990065]\n",
      "epoch:24 step:23114 [D loss: 0.959972, acc.: 32.81%] [G loss: 1.204422]\n",
      "epoch:24 step:23115 [D loss: 0.513378, acc.: 69.53%] [G loss: 1.442736]\n",
      "epoch:24 step:23116 [D loss: 0.576271, acc.: 74.22%] [G loss: 0.472141]\n",
      "epoch:24 step:23117 [D loss: 0.987189, acc.: 34.38%] [G loss: 1.185657]\n",
      "epoch:24 step:23118 [D loss: 0.824027, acc.: 48.44%] [G loss: 1.172478]\n",
      "epoch:24 step:23119 [D loss: 0.667169, acc.: 64.06%] [G loss: 1.246136]\n",
      "epoch:24 step:23120 [D loss: 0.831260, acc.: 46.09%] [G loss: 1.111727]\n",
      "epoch:24 step:23121 [D loss: 0.559333, acc.: 70.31%] [G loss: 1.260393]\n",
      "epoch:24 step:23122 [D loss: 0.593396, acc.: 70.31%] [G loss: 1.334832]\n",
      "epoch:24 step:23123 [D loss: 0.517046, acc.: 73.44%] [G loss: 1.182350]\n",
      "epoch:24 step:23124 [D loss: 0.755466, acc.: 46.88%] [G loss: 0.975588]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:23125 [D loss: 0.647633, acc.: 59.38%] [G loss: 1.370818]\n",
      "epoch:24 step:23126 [D loss: 0.814491, acc.: 46.09%] [G loss: 1.129225]\n",
      "epoch:24 step:23127 [D loss: 0.682982, acc.: 54.69%] [G loss: 1.108282]\n",
      "epoch:24 step:23128 [D loss: 0.623626, acc.: 70.31%] [G loss: 1.526593]\n",
      "epoch:24 step:23129 [D loss: 0.309429, acc.: 89.06%] [G loss: 1.412338]\n",
      "epoch:24 step:23130 [D loss: 0.708694, acc.: 52.34%] [G loss: 1.337364]\n",
      "epoch:24 step:23131 [D loss: 0.717066, acc.: 55.47%] [G loss: 1.115915]\n",
      "epoch:24 step:23132 [D loss: 0.272715, acc.: 92.19%] [G loss: 1.352977]\n",
      "epoch:24 step:23133 [D loss: 0.252235, acc.: 97.66%] [G loss: 1.482775]\n",
      "epoch:24 step:23134 [D loss: 0.176486, acc.: 95.31%] [G loss: 1.866750]\n",
      "epoch:24 step:23135 [D loss: 0.242552, acc.: 95.31%] [G loss: 1.629067]\n",
      "epoch:24 step:23136 [D loss: 0.173199, acc.: 97.66%] [G loss: 1.866962]\n",
      "epoch:24 step:23137 [D loss: 0.239221, acc.: 97.66%] [G loss: 1.758486]\n",
      "epoch:24 step:23138 [D loss: 0.147940, acc.: 96.88%] [G loss: 1.684412]\n",
      "epoch:24 step:23139 [D loss: 0.251264, acc.: 96.09%] [G loss: 1.886050]\n",
      "epoch:24 step:23140 [D loss: 0.325290, acc.: 92.19%] [G loss: 1.593826]\n",
      "epoch:24 step:23141 [D loss: 0.602365, acc.: 64.06%] [G loss: 1.661649]\n",
      "epoch:24 step:23142 [D loss: 0.516917, acc.: 70.31%] [G loss: 1.215322]\n",
      "epoch:24 step:23143 [D loss: 0.364609, acc.: 86.72%] [G loss: 0.936144]\n",
      "epoch:24 step:23144 [D loss: 0.361179, acc.: 87.50%] [G loss: 0.853863]\n",
      "epoch:24 step:23145 [D loss: 0.405321, acc.: 89.84%] [G loss: 1.324992]\n",
      "epoch:24 step:23146 [D loss: 0.851785, acc.: 43.75%] [G loss: 1.021809]\n",
      "epoch:24 step:23147 [D loss: 1.493274, acc.: 50.00%] [G loss: 0.932167]\n",
      "epoch:24 step:23148 [D loss: 0.247632, acc.: 94.53%] [G loss: 1.104909]\n",
      "epoch:24 step:23149 [D loss: 0.460123, acc.: 85.16%] [G loss: 0.647272]\n",
      "epoch:24 step:23150 [D loss: 0.686519, acc.: 60.94%] [G loss: 1.375784]\n",
      "epoch:24 step:23151 [D loss: 0.475420, acc.: 85.94%] [G loss: 0.877579]\n",
      "epoch:24 step:23152 [D loss: 0.439746, acc.: 84.38%] [G loss: 1.348492]\n",
      "epoch:24 step:23153 [D loss: 1.074567, acc.: 48.44%] [G loss: 1.730480]\n",
      "epoch:24 step:23154 [D loss: 0.982693, acc.: 45.31%] [G loss: 1.934279]\n",
      "epoch:24 step:23155 [D loss: 0.914143, acc.: 48.44%] [G loss: 1.294720]\n",
      "epoch:24 step:23156 [D loss: 0.730320, acc.: 53.91%] [G loss: 1.274954]\n",
      "epoch:24 step:23157 [D loss: 0.733458, acc.: 50.00%] [G loss: 1.237610]\n",
      "epoch:24 step:23158 [D loss: 0.855777, acc.: 39.84%] [G loss: 0.953563]\n",
      "epoch:24 step:23159 [D loss: 0.665412, acc.: 59.38%] [G loss: 1.130761]\n",
      "epoch:24 step:23160 [D loss: 0.714583, acc.: 50.00%] [G loss: 1.288207]\n",
      "epoch:24 step:23161 [D loss: 0.819752, acc.: 55.47%] [G loss: 1.241917]\n",
      "epoch:24 step:23162 [D loss: 0.735161, acc.: 52.34%] [G loss: 1.239185]\n",
      "epoch:24 step:23163 [D loss: 0.723312, acc.: 52.34%] [G loss: 1.054251]\n",
      "epoch:24 step:23164 [D loss: 0.664491, acc.: 60.16%] [G loss: 0.913100]\n",
      "epoch:24 step:23165 [D loss: 0.668269, acc.: 57.03%] [G loss: 0.965101]\n",
      "epoch:24 step:23166 [D loss: 0.582124, acc.: 64.06%] [G loss: 0.882824]\n",
      "epoch:24 step:23167 [D loss: 0.655842, acc.: 56.25%] [G loss: 1.051555]\n",
      "epoch:24 step:23168 [D loss: 0.605288, acc.: 68.75%] [G loss: 0.987184]\n",
      "epoch:24 step:23169 [D loss: 0.590371, acc.: 64.84%] [G loss: 1.030562]\n",
      "epoch:24 step:23170 [D loss: 0.612393, acc.: 64.84%] [G loss: 0.993686]\n",
      "epoch:24 step:23171 [D loss: 0.687544, acc.: 57.03%] [G loss: 1.088472]\n",
      "epoch:24 step:23172 [D loss: 0.652710, acc.: 56.25%] [G loss: 0.989970]\n",
      "epoch:24 step:23173 [D loss: 0.612427, acc.: 68.75%] [G loss: 0.892601]\n",
      "epoch:24 step:23174 [D loss: 0.614681, acc.: 67.19%] [G loss: 0.797288]\n",
      "epoch:24 step:23175 [D loss: 0.539339, acc.: 73.44%] [G loss: 0.939563]\n",
      "epoch:24 step:23176 [D loss: 0.641450, acc.: 59.38%] [G loss: 1.016535]\n",
      "epoch:24 step:23177 [D loss: 0.545370, acc.: 75.78%] [G loss: 0.931319]\n",
      "epoch:24 step:23178 [D loss: 0.507660, acc.: 78.91%] [G loss: 0.921075]\n",
      "epoch:24 step:23179 [D loss: 0.527243, acc.: 85.16%] [G loss: 1.055970]\n",
      "epoch:24 step:23180 [D loss: 0.405525, acc.: 87.50%] [G loss: 1.031968]\n",
      "epoch:24 step:23181 [D loss: 0.519944, acc.: 78.91%] [G loss: 1.217674]\n",
      "epoch:24 step:23182 [D loss: 0.391480, acc.: 85.16%] [G loss: 1.300126]\n",
      "epoch:24 step:23183 [D loss: 1.154364, acc.: 20.31%] [G loss: 0.988315]\n",
      "epoch:24 step:23184 [D loss: 0.274999, acc.: 92.97%] [G loss: 1.258273]\n",
      "epoch:24 step:23185 [D loss: 0.194855, acc.: 96.88%] [G loss: 1.200160]\n",
      "epoch:24 step:23186 [D loss: 0.270894, acc.: 96.09%] [G loss: 1.314575]\n",
      "epoch:24 step:23187 [D loss: 0.452796, acc.: 80.47%] [G loss: 1.282747]\n",
      "epoch:24 step:23188 [D loss: 0.129868, acc.: 100.00%] [G loss: 1.728100]\n",
      "epoch:24 step:23189 [D loss: 0.181043, acc.: 98.44%] [G loss: 1.836287]\n",
      "epoch:24 step:23190 [D loss: 0.223968, acc.: 97.66%] [G loss: 1.573200]\n",
      "epoch:24 step:23191 [D loss: 0.579524, acc.: 62.50%] [G loss: 1.103579]\n",
      "epoch:24 step:23192 [D loss: 0.270390, acc.: 97.66%] [G loss: 1.729666]\n",
      "epoch:24 step:23193 [D loss: 0.802142, acc.: 40.62%] [G loss: 1.265204]\n",
      "epoch:24 step:23194 [D loss: 0.273871, acc.: 88.28%] [G loss: 1.724883]\n",
      "epoch:24 step:23195 [D loss: 0.153682, acc.: 98.44%] [G loss: 1.517024]\n",
      "epoch:24 step:23196 [D loss: 0.136732, acc.: 100.00%] [G loss: 1.004655]\n",
      "epoch:24 step:23197 [D loss: 0.133312, acc.: 100.00%] [G loss: 1.779276]\n",
      "epoch:24 step:23198 [D loss: 0.856166, acc.: 63.28%] [G loss: 1.635764]\n",
      "epoch:24 step:23199 [D loss: 0.574017, acc.: 73.44%] [G loss: 1.321255]\n",
      "epoch:24 step:23200 [D loss: 0.785504, acc.: 44.53%] [G loss: 1.435909]\n",
      "##############\n",
      "[3.80044443 2.82953484 6.48713385 5.85783794 4.55650078 5.99666798\n",
      " 5.47458585 5.60097415 5.93342329 5.10446495]\n",
      "##########\n",
      "epoch:24 step:23201 [D loss: 0.185278, acc.: 97.66%] [G loss: 1.204521]\n",
      "epoch:24 step:23202 [D loss: 0.236099, acc.: 93.75%] [G loss: 1.633322]\n",
      "epoch:24 step:23203 [D loss: 0.684034, acc.: 56.25%] [G loss: 1.239642]\n",
      "epoch:24 step:23204 [D loss: 0.796132, acc.: 51.56%] [G loss: 1.284648]\n",
      "epoch:24 step:23205 [D loss: 0.713148, acc.: 58.59%] [G loss: 1.090134]\n",
      "epoch:24 step:23206 [D loss: 0.671287, acc.: 59.38%] [G loss: 0.917772]\n",
      "epoch:24 step:23207 [D loss: 0.674060, acc.: 56.25%] [G loss: 0.540742]\n",
      "epoch:24 step:23208 [D loss: 0.660904, acc.: 57.81%] [G loss: 0.986866]\n",
      "epoch:24 step:23209 [D loss: 0.648031, acc.: 60.94%] [G loss: 1.032492]\n",
      "epoch:24 step:23210 [D loss: 0.349503, acc.: 89.84%] [G loss: 1.049169]\n",
      "epoch:24 step:23211 [D loss: 0.328209, acc.: 96.88%] [G loss: 0.897104]\n",
      "epoch:24 step:23212 [D loss: 0.559265, acc.: 73.44%] [G loss: 0.262282]\n",
      "epoch:24 step:23213 [D loss: 0.636811, acc.: 58.59%] [G loss: 1.057719]\n",
      "epoch:24 step:23214 [D loss: 0.542476, acc.: 79.69%] [G loss: 1.040728]\n",
      "epoch:24 step:23215 [D loss: 0.198240, acc.: 99.22%] [G loss: 1.305950]\n",
      "epoch:24 step:23216 [D loss: 0.211685, acc.: 95.31%] [G loss: 1.215952]\n",
      "epoch:24 step:23217 [D loss: 0.291293, acc.: 85.94%] [G loss: 1.427495]\n",
      "epoch:24 step:23218 [D loss: 0.173475, acc.: 96.09%] [G loss: 1.743249]\n",
      "epoch:24 step:23219 [D loss: 0.161324, acc.: 98.44%] [G loss: 1.717676]\n",
      "epoch:24 step:23220 [D loss: 0.140809, acc.: 99.22%] [G loss: 1.912374]\n",
      "epoch:24 step:23221 [D loss: 0.166607, acc.: 99.22%] [G loss: 2.024195]\n",
      "epoch:24 step:23222 [D loss: 0.647792, acc.: 60.94%] [G loss: 1.684553]\n",
      "epoch:24 step:23223 [D loss: 0.738303, acc.: 51.56%] [G loss: 1.381304]\n",
      "epoch:24 step:23224 [D loss: 0.771256, acc.: 54.69%] [G loss: 1.484746]\n",
      "epoch:24 step:23225 [D loss: 0.730781, acc.: 57.03%] [G loss: 1.080791]\n",
      "epoch:24 step:23226 [D loss: 0.623165, acc.: 64.06%] [G loss: 1.181937]\n",
      "epoch:24 step:23227 [D loss: 0.255959, acc.: 95.31%] [G loss: 1.221756]\n",
      "epoch:24 step:23228 [D loss: 0.442075, acc.: 84.38%] [G loss: 1.140601]\n",
      "epoch:24 step:23229 [D loss: 0.663521, acc.: 63.28%] [G loss: 0.865251]\n",
      "epoch:24 step:23230 [D loss: 0.573825, acc.: 68.75%] [G loss: 1.235882]\n",
      "epoch:24 step:23231 [D loss: 0.462901, acc.: 89.84%] [G loss: 1.551443]\n",
      "epoch:24 step:23232 [D loss: 0.606960, acc.: 67.19%] [G loss: 1.221743]\n",
      "epoch:24 step:23233 [D loss: 0.208469, acc.: 96.09%] [G loss: 1.340347]\n",
      "epoch:24 step:23234 [D loss: 0.238702, acc.: 95.31%] [G loss: 1.431142]\n",
      "epoch:24 step:23235 [D loss: 0.368321, acc.: 90.62%] [G loss: 1.287981]\n",
      "epoch:24 step:23236 [D loss: 0.701068, acc.: 60.16%] [G loss: 1.262148]\n",
      "epoch:24 step:23237 [D loss: 0.606851, acc.: 66.41%] [G loss: 1.185069]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:23238 [D loss: 0.540719, acc.: 74.22%] [G loss: 0.941623]\n",
      "epoch:24 step:23239 [D loss: 0.588471, acc.: 66.41%] [G loss: 1.232888]\n",
      "epoch:24 step:23240 [D loss: 0.521722, acc.: 78.91%] [G loss: 1.094490]\n",
      "epoch:24 step:23241 [D loss: 0.380187, acc.: 82.03%] [G loss: 1.184209]\n",
      "epoch:24 step:23242 [D loss: 0.169135, acc.: 98.44%] [G loss: 1.275977]\n",
      "epoch:24 step:23243 [D loss: 0.169369, acc.: 94.53%] [G loss: 1.567933]\n",
      "epoch:24 step:23244 [D loss: 0.197601, acc.: 92.97%] [G loss: 1.690805]\n",
      "epoch:24 step:23245 [D loss: 0.161764, acc.: 99.22%] [G loss: 1.745094]\n",
      "epoch:24 step:23246 [D loss: 0.568102, acc.: 71.88%] [G loss: 1.555230]\n",
      "epoch:24 step:23247 [D loss: 0.872295, acc.: 50.78%] [G loss: 1.418518]\n",
      "epoch:24 step:23248 [D loss: 0.997809, acc.: 34.38%] [G loss: 1.438941]\n",
      "epoch:24 step:23249 [D loss: 0.745396, acc.: 52.34%] [G loss: 1.180760]\n",
      "epoch:24 step:23250 [D loss: 0.267867, acc.: 91.41%] [G loss: 0.911287]\n",
      "epoch:24 step:23251 [D loss: 0.326026, acc.: 93.75%] [G loss: 1.484401]\n",
      "epoch:24 step:23252 [D loss: 0.154947, acc.: 97.66%] [G loss: 1.581521]\n",
      "epoch:24 step:23253 [D loss: 0.812314, acc.: 50.00%] [G loss: 0.842191]\n",
      "epoch:24 step:23254 [D loss: 0.836396, acc.: 42.19%] [G loss: 1.239030]\n",
      "epoch:24 step:23255 [D loss: 0.757632, acc.: 53.12%] [G loss: 0.776155]\n",
      "epoch:24 step:23256 [D loss: 0.409419, acc.: 84.38%] [G loss: 0.674793]\n",
      "epoch:24 step:23257 [D loss: 0.376482, acc.: 92.97%] [G loss: 1.194403]\n",
      "epoch:24 step:23258 [D loss: 0.764846, acc.: 45.31%] [G loss: 1.001236]\n",
      "epoch:24 step:23259 [D loss: 0.711736, acc.: 53.91%] [G loss: 1.261612]\n",
      "epoch:24 step:23260 [D loss: 0.741354, acc.: 55.47%] [G loss: 1.316610]\n",
      "epoch:24 step:23261 [D loss: 0.733975, acc.: 55.47%] [G loss: 0.942317]\n",
      "epoch:24 step:23262 [D loss: 0.331148, acc.: 80.47%] [G loss: 1.092620]\n",
      "epoch:24 step:23263 [D loss: 0.262471, acc.: 94.53%] [G loss: 1.344640]\n",
      "epoch:24 step:23264 [D loss: 0.692044, acc.: 62.50%] [G loss: 1.219870]\n",
      "epoch:24 step:23265 [D loss: 0.499568, acc.: 84.38%] [G loss: 1.171424]\n",
      "epoch:24 step:23266 [D loss: 0.752179, acc.: 54.69%] [G loss: 1.232887]\n",
      "epoch:24 step:23267 [D loss: 0.701023, acc.: 55.47%] [G loss: 0.940246]\n",
      "epoch:24 step:23268 [D loss: 0.458833, acc.: 68.75%] [G loss: 1.118797]\n",
      "epoch:24 step:23269 [D loss: 0.181194, acc.: 97.66%] [G loss: 1.136659]\n",
      "epoch:24 step:23270 [D loss: 0.163546, acc.: 99.22%] [G loss: 1.460492]\n",
      "epoch:24 step:23271 [D loss: 0.481555, acc.: 77.34%] [G loss: 1.457613]\n",
      "epoch:24 step:23272 [D loss: 0.411230, acc.: 88.28%] [G loss: 1.485588]\n",
      "epoch:24 step:23273 [D loss: 0.632774, acc.: 64.06%] [G loss: 0.928390]\n",
      "epoch:24 step:23274 [D loss: 0.289874, acc.: 92.19%] [G loss: 1.287470]\n",
      "epoch:24 step:23275 [D loss: 0.915623, acc.: 37.50%] [G loss: 1.459962]\n",
      "epoch:24 step:23276 [D loss: 0.496391, acc.: 75.78%] [G loss: 1.431870]\n",
      "epoch:24 step:23277 [D loss: 0.975947, acc.: 34.38%] [G loss: 0.840570]\n",
      "epoch:24 step:23278 [D loss: 0.852509, acc.: 39.84%] [G loss: 1.154728]\n",
      "epoch:24 step:23279 [D loss: 0.235908, acc.: 94.53%] [G loss: 0.715840]\n",
      "epoch:24 step:23280 [D loss: 0.387207, acc.: 75.78%] [G loss: 1.266762]\n",
      "epoch:24 step:23281 [D loss: 0.698862, acc.: 59.38%] [G loss: 1.519704]\n",
      "epoch:24 step:23282 [D loss: 0.283067, acc.: 93.75%] [G loss: 1.725476]\n",
      "epoch:24 step:23283 [D loss: 0.584592, acc.: 73.44%] [G loss: 1.623548]\n",
      "epoch:24 step:23284 [D loss: 0.533043, acc.: 78.12%] [G loss: 1.567625]\n",
      "epoch:24 step:23285 [D loss: 1.023141, acc.: 32.03%] [G loss: 1.132754]\n",
      "epoch:24 step:23286 [D loss: 0.990779, acc.: 27.34%] [G loss: 0.843163]\n",
      "epoch:24 step:23287 [D loss: 0.816119, acc.: 46.09%] [G loss: 1.724776]\n",
      "epoch:24 step:23288 [D loss: 0.305065, acc.: 82.81%] [G loss: 1.716189]\n",
      "epoch:24 step:23289 [D loss: 0.178515, acc.: 96.88%] [G loss: 2.057874]\n",
      "epoch:24 step:23290 [D loss: 0.140109, acc.: 99.22%] [G loss: 1.622122]\n",
      "epoch:24 step:23291 [D loss: 0.643624, acc.: 61.72%] [G loss: 1.771212]\n",
      "epoch:24 step:23292 [D loss: 0.732267, acc.: 52.34%] [G loss: 1.652064]\n",
      "epoch:24 step:23293 [D loss: 0.715112, acc.: 60.16%] [G loss: 1.122125]\n",
      "epoch:24 step:23294 [D loss: 0.202549, acc.: 98.44%] [G loss: 1.513782]\n",
      "epoch:24 step:23295 [D loss: 0.562032, acc.: 70.31%] [G loss: 0.708754]\n",
      "epoch:24 step:23296 [D loss: 0.177101, acc.: 97.66%] [G loss: 2.160119]\n",
      "epoch:24 step:23297 [D loss: 0.139556, acc.: 99.22%] [G loss: 1.509256]\n",
      "epoch:24 step:23298 [D loss: 0.362736, acc.: 89.84%] [G loss: 1.706855]\n",
      "epoch:24 step:23299 [D loss: 0.845079, acc.: 50.00%] [G loss: 2.117340]\n",
      "epoch:24 step:23300 [D loss: 0.803703, acc.: 53.91%] [G loss: 1.749871]\n",
      "epoch:24 step:23301 [D loss: 0.310251, acc.: 92.19%] [G loss: 1.616013]\n",
      "epoch:24 step:23302 [D loss: 0.449022, acc.: 84.38%] [G loss: 1.480759]\n",
      "epoch:24 step:23303 [D loss: 0.152501, acc.: 96.09%] [G loss: 1.834895]\n",
      "epoch:24 step:23304 [D loss: 0.110591, acc.: 99.22%] [G loss: 1.962714]\n",
      "epoch:24 step:23305 [D loss: 0.395539, acc.: 83.59%] [G loss: 1.837208]\n",
      "epoch:24 step:23306 [D loss: 0.178534, acc.: 98.44%] [G loss: 2.027841]\n",
      "epoch:24 step:23307 [D loss: 0.225169, acc.: 94.53%] [G loss: 2.015745]\n",
      "epoch:24 step:23308 [D loss: 0.565498, acc.: 70.31%] [G loss: 2.073441]\n",
      "epoch:24 step:23309 [D loss: 1.056651, acc.: 46.88%] [G loss: 0.950928]\n",
      "epoch:24 step:23310 [D loss: 0.513687, acc.: 82.03%] [G loss: 1.208801]\n",
      "epoch:24 step:23311 [D loss: 0.279437, acc.: 95.31%] [G loss: 1.119339]\n",
      "epoch:24 step:23312 [D loss: 0.274186, acc.: 89.84%] [G loss: 1.197048]\n",
      "epoch:24 step:23313 [D loss: 0.162008, acc.: 98.44%] [G loss: 1.397131]\n",
      "epoch:24 step:23314 [D loss: 0.315394, acc.: 92.97%] [G loss: 1.283324]\n",
      "epoch:24 step:23315 [D loss: 0.463604, acc.: 79.69%] [G loss: 1.250689]\n",
      "epoch:24 step:23316 [D loss: 0.742573, acc.: 51.56%] [G loss: 1.537691]\n",
      "epoch:24 step:23317 [D loss: 0.556112, acc.: 67.97%] [G loss: 2.099594]\n",
      "epoch:24 step:23318 [D loss: 0.117516, acc.: 97.66%] [G loss: 1.952674]\n",
      "epoch:24 step:23319 [D loss: 0.214984, acc.: 92.19%] [G loss: 1.716392]\n",
      "epoch:24 step:23320 [D loss: 0.981045, acc.: 52.34%] [G loss: 0.288765]\n",
      "epoch:24 step:23321 [D loss: 0.703706, acc.: 65.62%] [G loss: 0.752192]\n",
      "epoch:24 step:23322 [D loss: 2.031296, acc.: 22.66%] [G loss: 4.668650]\n",
      "epoch:24 step:23323 [D loss: 1.020639, acc.: 39.06%] [G loss: 2.409169]\n",
      "epoch:24 step:23324 [D loss: 0.730517, acc.: 49.22%] [G loss: 2.348506]\n",
      "epoch:24 step:23325 [D loss: 0.845628, acc.: 40.62%] [G loss: 5.038723]\n",
      "epoch:24 step:23326 [D loss: 0.533010, acc.: 60.94%] [G loss: 4.003047]\n",
      "epoch:24 step:23327 [D loss: 0.592232, acc.: 59.38%] [G loss: 3.725212]\n",
      "epoch:24 step:23328 [D loss: 0.561700, acc.: 63.28%] [G loss: 4.896017]\n",
      "epoch:24 step:23329 [D loss: 0.367771, acc.: 93.75%] [G loss: 1.574912]\n",
      "epoch:24 step:23330 [D loss: 0.310672, acc.: 97.66%] [G loss: 2.237244]\n",
      "epoch:24 step:23331 [D loss: 0.639180, acc.: 64.06%] [G loss: 1.363380]\n",
      "epoch:24 step:23332 [D loss: 0.776615, acc.: 57.81%] [G loss: 0.986026]\n",
      "epoch:24 step:23333 [D loss: 0.680792, acc.: 61.72%] [G loss: 1.151575]\n",
      "epoch:24 step:23334 [D loss: 0.425809, acc.: 92.97%] [G loss: 1.020081]\n",
      "epoch:24 step:23335 [D loss: 0.424219, acc.: 87.50%] [G loss: 1.401512]\n",
      "epoch:24 step:23336 [D loss: 0.568132, acc.: 70.31%] [G loss: 1.190081]\n",
      "epoch:24 step:23337 [D loss: 0.376102, acc.: 85.94%] [G loss: 1.366948]\n",
      "epoch:24 step:23338 [D loss: 0.376975, acc.: 90.62%] [G loss: 1.308655]\n",
      "epoch:24 step:23339 [D loss: 0.304039, acc.: 91.41%] [G loss: 1.809383]\n",
      "epoch:24 step:23340 [D loss: 0.386482, acc.: 86.72%] [G loss: 1.339604]\n",
      "epoch:24 step:23341 [D loss: 0.383334, acc.: 89.06%] [G loss: 1.858899]\n",
      "epoch:24 step:23342 [D loss: 0.226296, acc.: 96.88%] [G loss: 2.793988]\n",
      "epoch:24 step:23343 [D loss: 0.401857, acc.: 82.03%] [G loss: 1.365281]\n",
      "epoch:24 step:23344 [D loss: 0.476961, acc.: 79.69%] [G loss: 0.989221]\n",
      "epoch:24 step:23345 [D loss: 0.678176, acc.: 59.38%] [G loss: 1.481298]\n",
      "epoch:24 step:23346 [D loss: 1.133222, acc.: 39.84%] [G loss: 1.293045]\n",
      "epoch:24 step:23347 [D loss: 0.808612, acc.: 54.69%] [G loss: 1.450686]\n",
      "epoch:24 step:23348 [D loss: 0.631018, acc.: 64.84%] [G loss: 0.921512]\n",
      "epoch:24 step:23349 [D loss: 0.537164, acc.: 78.12%] [G loss: 1.151382]\n",
      "epoch:24 step:23350 [D loss: 0.622168, acc.: 68.75%] [G loss: 0.976566]\n",
      "epoch:24 step:23351 [D loss: 0.558415, acc.: 73.44%] [G loss: 1.372685]\n",
      "epoch:24 step:23352 [D loss: 0.565506, acc.: 73.44%] [G loss: 0.921751]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:23353 [D loss: 0.765214, acc.: 52.34%] [G loss: 0.941887]\n",
      "epoch:24 step:23354 [D loss: 0.638160, acc.: 63.28%] [G loss: 1.107525]\n",
      "epoch:24 step:23355 [D loss: 0.537679, acc.: 71.88%] [G loss: 1.077467]\n",
      "epoch:24 step:23356 [D loss: 0.696950, acc.: 53.91%] [G loss: 0.960487]\n",
      "epoch:24 step:23357 [D loss: 0.648052, acc.: 66.41%] [G loss: 0.951204]\n",
      "epoch:24 step:23358 [D loss: 0.631207, acc.: 63.28%] [G loss: 0.826022]\n",
      "epoch:24 step:23359 [D loss: 0.693286, acc.: 50.00%] [G loss: 0.976918]\n",
      "epoch:24 step:23360 [D loss: 0.761685, acc.: 46.09%] [G loss: 0.970051]\n",
      "epoch:24 step:23361 [D loss: 0.766948, acc.: 46.88%] [G loss: 0.781008]\n",
      "epoch:24 step:23362 [D loss: 0.802387, acc.: 42.97%] [G loss: 1.122043]\n",
      "epoch:24 step:23363 [D loss: 0.597785, acc.: 65.62%] [G loss: 0.881005]\n",
      "epoch:24 step:23364 [D loss: 0.662971, acc.: 63.28%] [G loss: 1.106666]\n",
      "epoch:24 step:23365 [D loss: 0.573117, acc.: 66.41%] [G loss: 0.839853]\n",
      "epoch:24 step:23366 [D loss: 0.357339, acc.: 84.38%] [G loss: 1.556437]\n",
      "epoch:24 step:23367 [D loss: 0.822879, acc.: 45.31%] [G loss: 0.902897]\n",
      "epoch:24 step:23368 [D loss: 0.697178, acc.: 57.03%] [G loss: 1.135263]\n",
      "epoch:24 step:23369 [D loss: 0.584067, acc.: 70.31%] [G loss: 1.089201]\n",
      "epoch:24 step:23370 [D loss: 0.591865, acc.: 70.31%] [G loss: 0.870899]\n",
      "epoch:24 step:23371 [D loss: 0.782412, acc.: 52.34%] [G loss: 0.837046]\n",
      "epoch:24 step:23372 [D loss: 0.653452, acc.: 60.94%] [G loss: 0.881824]\n",
      "epoch:24 step:23373 [D loss: 0.505380, acc.: 69.53%] [G loss: 0.923618]\n",
      "epoch:24 step:23374 [D loss: 0.668382, acc.: 60.94%] [G loss: 1.000136]\n",
      "epoch:24 step:23375 [D loss: 0.497595, acc.: 74.22%] [G loss: 1.099306]\n",
      "epoch:24 step:23376 [D loss: 0.648993, acc.: 64.06%] [G loss: 0.914175]\n",
      "epoch:24 step:23377 [D loss: 0.515728, acc.: 82.81%] [G loss: 1.225911]\n",
      "epoch:24 step:23378 [D loss: 0.463939, acc.: 78.12%] [G loss: 1.011958]\n",
      "epoch:24 step:23379 [D loss: 0.790067, acc.: 39.06%] [G loss: 1.061056]\n",
      "epoch:24 step:23380 [D loss: 0.700206, acc.: 57.03%] [G loss: 1.146240]\n",
      "epoch:24 step:23381 [D loss: 0.686330, acc.: 52.34%] [G loss: 1.065212]\n",
      "epoch:24 step:23382 [D loss: 0.563097, acc.: 77.34%] [G loss: 1.011895]\n",
      "epoch:24 step:23383 [D loss: 0.609153, acc.: 67.97%] [G loss: 1.142793]\n",
      "epoch:24 step:23384 [D loss: 0.557237, acc.: 75.78%] [G loss: 1.007629]\n",
      "epoch:24 step:23385 [D loss: 0.522891, acc.: 81.25%] [G loss: 1.006216]\n",
      "epoch:24 step:23386 [D loss: 0.302814, acc.: 96.09%] [G loss: 1.103870]\n",
      "epoch:24 step:23387 [D loss: 0.242572, acc.: 96.09%] [G loss: 1.353688]\n",
      "epoch:24 step:23388 [D loss: 0.228684, acc.: 98.44%] [G loss: 1.321701]\n",
      "epoch:24 step:23389 [D loss: 0.392203, acc.: 91.41%] [G loss: 1.410041]\n",
      "epoch:24 step:23390 [D loss: 0.619476, acc.: 60.94%] [G loss: 1.397552]\n",
      "epoch:24 step:23391 [D loss: 0.490919, acc.: 82.81%] [G loss: 1.295162]\n",
      "epoch:24 step:23392 [D loss: 0.602260, acc.: 72.66%] [G loss: 1.206626]\n",
      "epoch:24 step:23393 [D loss: 0.896118, acc.: 37.50%] [G loss: 1.084642]\n",
      "epoch:24 step:23394 [D loss: 0.595077, acc.: 71.09%] [G loss: 1.073439]\n",
      "epoch:24 step:23395 [D loss: 0.669581, acc.: 59.38%] [G loss: 0.894260]\n",
      "epoch:24 step:23396 [D loss: 0.666912, acc.: 60.16%] [G loss: 0.886334]\n",
      "epoch:24 step:23397 [D loss: 0.335692, acc.: 92.19%] [G loss: 0.954534]\n",
      "epoch:24 step:23398 [D loss: 0.833755, acc.: 35.94%] [G loss: 1.050838]\n",
      "epoch:24 step:23399 [D loss: 0.262135, acc.: 95.31%] [G loss: 1.224380]\n",
      "epoch:24 step:23400 [D loss: 0.209845, acc.: 97.66%] [G loss: 1.135228]\n",
      "##############\n",
      "[4.38133396 2.41599518 6.48783894 6.01118238 4.97293051 6.18300098\n",
      " 5.75485661 5.92365535 6.00062421 5.10334229]\n",
      "##########\n",
      "epoch:24 step:23401 [D loss: 0.533592, acc.: 74.22%] [G loss: 1.224424]\n",
      "epoch:24 step:23402 [D loss: 0.881708, acc.: 46.88%] [G loss: 1.285404]\n",
      "epoch:24 step:23403 [D loss: 0.813270, acc.: 41.41%] [G loss: 1.064996]\n",
      "epoch:24 step:23404 [D loss: 0.851863, acc.: 33.59%] [G loss: 1.001586]\n",
      "epoch:24 step:23405 [D loss: 0.648160, acc.: 65.62%] [G loss: 1.062565]\n",
      "epoch:24 step:23406 [D loss: 0.615454, acc.: 64.84%] [G loss: 1.168067]\n",
      "epoch:24 step:23407 [D loss: 0.285472, acc.: 94.53%] [G loss: 1.179712]\n",
      "epoch:24 step:23408 [D loss: 0.291510, acc.: 94.53%] [G loss: 1.423206]\n",
      "epoch:24 step:23409 [D loss: 0.437393, acc.: 88.28%] [G loss: 1.168405]\n",
      "epoch:24 step:23410 [D loss: 0.589741, acc.: 68.75%] [G loss: 1.335203]\n",
      "epoch:24 step:23411 [D loss: 0.499347, acc.: 82.81%] [G loss: 1.133313]\n",
      "epoch:24 step:23412 [D loss: 0.441088, acc.: 75.78%] [G loss: 1.287459]\n",
      "epoch:24 step:23413 [D loss: 0.309386, acc.: 95.31%] [G loss: 1.370241]\n",
      "epoch:24 step:23414 [D loss: 0.181896, acc.: 96.88%] [G loss: 1.490230]\n",
      "epoch:24 step:23415 [D loss: 0.135613, acc.: 99.22%] [G loss: 1.846128]\n",
      "epoch:24 step:23416 [D loss: 0.887277, acc.: 54.69%] [G loss: 1.373537]\n",
      "epoch:24 step:23417 [D loss: 0.195872, acc.: 96.88%] [G loss: 1.540095]\n",
      "epoch:24 step:23418 [D loss: 0.512289, acc.: 71.88%] [G loss: 1.639189]\n",
      "epoch:24 step:23419 [D loss: 0.491442, acc.: 78.91%] [G loss: 1.251827]\n",
      "epoch:24 step:23420 [D loss: 0.282842, acc.: 94.53%] [G loss: 1.402712]\n",
      "epoch:24 step:23421 [D loss: 0.271936, acc.: 94.53%] [G loss: 1.340201]\n",
      "epoch:24 step:23422 [D loss: 0.182705, acc.: 98.44%] [G loss: 1.550640]\n",
      "epoch:24 step:23423 [D loss: 0.157979, acc.: 100.00%] [G loss: 1.308668]\n",
      "epoch:24 step:23424 [D loss: 0.297574, acc.: 84.38%] [G loss: 1.864772]\n",
      "epoch:24 step:23425 [D loss: 0.156486, acc.: 96.88%] [G loss: 1.561214]\n",
      "epoch:25 step:23426 [D loss: 0.335666, acc.: 94.53%] [G loss: 1.136447]\n",
      "epoch:25 step:23427 [D loss: 0.606161, acc.: 67.19%] [G loss: 2.054707]\n",
      "epoch:25 step:23428 [D loss: 0.420534, acc.: 80.47%] [G loss: 1.404875]\n",
      "epoch:25 step:23429 [D loss: 0.596163, acc.: 67.97%] [G loss: 0.792372]\n",
      "epoch:25 step:23430 [D loss: 0.918552, acc.: 33.59%] [G loss: 0.793144]\n",
      "epoch:25 step:23431 [D loss: 0.453415, acc.: 79.69%] [G loss: 1.261143]\n",
      "epoch:25 step:23432 [D loss: 0.861077, acc.: 55.47%] [G loss: 1.359651]\n",
      "epoch:25 step:23433 [D loss: 0.259353, acc.: 96.09%] [G loss: 1.353161]\n",
      "epoch:25 step:23434 [D loss: 0.491673, acc.: 65.62%] [G loss: 1.721915]\n",
      "epoch:25 step:23435 [D loss: 0.149872, acc.: 99.22%] [G loss: 1.222467]\n",
      "epoch:25 step:23436 [D loss: 0.319531, acc.: 91.41%] [G loss: 1.224186]\n",
      "epoch:25 step:23437 [D loss: 1.527227, acc.: 48.44%] [G loss: 2.327956]\n",
      "epoch:25 step:23438 [D loss: 0.735745, acc.: 60.94%] [G loss: 1.861391]\n",
      "epoch:25 step:23439 [D loss: 0.740421, acc.: 62.50%] [G loss: 1.151106]\n",
      "epoch:25 step:23440 [D loss: 0.408718, acc.: 82.81%] [G loss: 1.503960]\n",
      "epoch:25 step:23441 [D loss: 0.409348, acc.: 83.59%] [G loss: 0.795740]\n",
      "epoch:25 step:23442 [D loss: 1.373749, acc.: 20.31%] [G loss: 2.096762]\n",
      "epoch:25 step:23443 [D loss: 0.527412, acc.: 74.22%] [G loss: 1.579607]\n",
      "epoch:25 step:23444 [D loss: 0.979933, acc.: 34.38%] [G loss: 0.509218]\n",
      "epoch:25 step:23445 [D loss: 1.280558, acc.: 22.66%] [G loss: 1.093790]\n",
      "epoch:25 step:23446 [D loss: 0.782782, acc.: 52.34%] [G loss: 1.465693]\n",
      "epoch:25 step:23447 [D loss: 0.791822, acc.: 51.56%] [G loss: 1.217032]\n",
      "epoch:25 step:23448 [D loss: 0.678194, acc.: 61.72%] [G loss: 0.376448]\n",
      "epoch:25 step:23449 [D loss: 0.845719, acc.: 47.66%] [G loss: 0.838890]\n",
      "epoch:25 step:23450 [D loss: 0.548672, acc.: 71.88%] [G loss: 0.524136]\n",
      "epoch:25 step:23451 [D loss: 0.942695, acc.: 34.38%] [G loss: 1.317058]\n",
      "epoch:25 step:23452 [D loss: 0.391287, acc.: 88.28%] [G loss: 1.505333]\n",
      "epoch:25 step:23453 [D loss: 0.634165, acc.: 65.62%] [G loss: 1.522895]\n",
      "epoch:25 step:23454 [D loss: 0.558426, acc.: 68.75%] [G loss: 1.676100]\n",
      "epoch:25 step:23455 [D loss: 0.730286, acc.: 47.66%] [G loss: 1.607767]\n",
      "epoch:25 step:23456 [D loss: 0.240177, acc.: 92.97%] [G loss: 1.702734]\n",
      "epoch:25 step:23457 [D loss: 0.270765, acc.: 96.09%] [G loss: 1.828976]\n",
      "epoch:25 step:23458 [D loss: 0.208631, acc.: 94.53%] [G loss: 1.898107]\n",
      "epoch:25 step:23459 [D loss: 0.213057, acc.: 99.22%] [G loss: 2.233536]\n",
      "epoch:25 step:23460 [D loss: 0.112455, acc.: 98.44%] [G loss: 1.968028]\n",
      "epoch:25 step:23461 [D loss: 0.103805, acc.: 100.00%] [G loss: 1.942257]\n",
      "epoch:25 step:23462 [D loss: 0.653448, acc.: 61.72%] [G loss: 1.697908]\n",
      "epoch:25 step:23463 [D loss: 0.840201, acc.: 52.34%] [G loss: 1.407270]\n",
      "epoch:25 step:23464 [D loss: 0.796942, acc.: 56.25%] [G loss: 1.185096]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23465 [D loss: 0.676071, acc.: 64.84%] [G loss: 1.030246]\n",
      "epoch:25 step:23466 [D loss: 0.500356, acc.: 79.69%] [G loss: 1.174530]\n",
      "epoch:25 step:23467 [D loss: 0.372532, acc.: 90.62%] [G loss: 1.218995]\n",
      "epoch:25 step:23468 [D loss: 0.363482, acc.: 89.06%] [G loss: 1.267147]\n",
      "epoch:25 step:23469 [D loss: 0.385622, acc.: 89.84%] [G loss: 1.399117]\n",
      "epoch:25 step:23470 [D loss: 0.449299, acc.: 87.50%] [G loss: 1.603334]\n",
      "epoch:25 step:23471 [D loss: 0.347230, acc.: 90.62%] [G loss: 1.058447]\n",
      "epoch:25 step:23472 [D loss: 0.473235, acc.: 81.25%] [G loss: 1.322671]\n",
      "epoch:25 step:23473 [D loss: 0.725238, acc.: 54.69%] [G loss: 1.236726]\n",
      "epoch:25 step:23474 [D loss: 0.789443, acc.: 49.22%] [G loss: 1.246061]\n",
      "epoch:25 step:23475 [D loss: 0.437680, acc.: 86.72%] [G loss: 1.063772]\n",
      "epoch:25 step:23476 [D loss: 0.342673, acc.: 90.62%] [G loss: 1.195650]\n",
      "epoch:25 step:23477 [D loss: 0.338081, acc.: 87.50%] [G loss: 1.517228]\n",
      "epoch:25 step:23478 [D loss: 0.517214, acc.: 74.22%] [G loss: 0.959810]\n",
      "epoch:25 step:23479 [D loss: 0.744997, acc.: 48.44%] [G loss: 0.612774]\n",
      "epoch:25 step:23480 [D loss: 0.708335, acc.: 50.00%] [G loss: 0.904928]\n",
      "epoch:25 step:23481 [D loss: 0.576654, acc.: 75.00%] [G loss: 1.069109]\n",
      "epoch:25 step:23482 [D loss: 0.296590, acc.: 84.38%] [G loss: 1.873045]\n",
      "epoch:25 step:23483 [D loss: 0.482333, acc.: 69.53%] [G loss: 1.639043]\n",
      "epoch:25 step:23484 [D loss: 0.225734, acc.: 99.22%] [G loss: 1.591061]\n",
      "epoch:25 step:23485 [D loss: 0.229223, acc.: 96.09%] [G loss: 1.787215]\n",
      "epoch:25 step:23486 [D loss: 0.720569, acc.: 58.59%] [G loss: 0.966425]\n",
      "epoch:25 step:23487 [D loss: 0.465599, acc.: 75.78%] [G loss: 1.395154]\n",
      "epoch:25 step:23488 [D loss: 0.422094, acc.: 86.72%] [G loss: 1.126563]\n",
      "epoch:25 step:23489 [D loss: 0.819750, acc.: 49.22%] [G loss: 0.385085]\n",
      "epoch:25 step:23490 [D loss: 1.181228, acc.: 23.44%] [G loss: 0.995206]\n",
      "epoch:25 step:23491 [D loss: 0.508595, acc.: 76.56%] [G loss: 1.374048]\n",
      "epoch:25 step:23492 [D loss: 0.689351, acc.: 64.06%] [G loss: 0.286857]\n",
      "epoch:25 step:23493 [D loss: 1.252170, acc.: 12.50%] [G loss: 0.674577]\n",
      "epoch:25 step:23494 [D loss: 1.097885, acc.: 26.56%] [G loss: 1.476520]\n",
      "epoch:25 step:23495 [D loss: 0.851198, acc.: 49.22%] [G loss: 1.156572]\n",
      "epoch:25 step:23496 [D loss: 0.213915, acc.: 96.88%] [G loss: 1.138283]\n",
      "epoch:25 step:23497 [D loss: 0.677062, acc.: 60.94%] [G loss: 1.387719]\n",
      "epoch:25 step:23498 [D loss: 0.329290, acc.: 91.41%] [G loss: 1.543312]\n",
      "epoch:25 step:23499 [D loss: 0.613303, acc.: 67.97%] [G loss: 1.685577]\n",
      "epoch:25 step:23500 [D loss: 0.122718, acc.: 99.22%] [G loss: 1.022477]\n",
      "epoch:25 step:23501 [D loss: 0.205672, acc.: 95.31%] [G loss: 1.366810]\n",
      "epoch:25 step:23502 [D loss: 0.273453, acc.: 90.62%] [G loss: 1.464455]\n",
      "epoch:25 step:23503 [D loss: 1.017933, acc.: 40.62%] [G loss: 1.499198]\n",
      "epoch:25 step:23504 [D loss: 0.770628, acc.: 56.25%] [G loss: 1.382940]\n",
      "epoch:25 step:23505 [D loss: 0.855126, acc.: 50.00%] [G loss: 1.118660]\n",
      "epoch:25 step:23506 [D loss: 0.885686, acc.: 35.16%] [G loss: 1.206485]\n",
      "epoch:25 step:23507 [D loss: 0.688581, acc.: 57.81%] [G loss: 1.518474]\n",
      "epoch:25 step:23508 [D loss: 0.623699, acc.: 64.06%] [G loss: 1.219758]\n",
      "epoch:25 step:23509 [D loss: 0.686577, acc.: 61.72%] [G loss: 1.287255]\n",
      "epoch:25 step:23510 [D loss: 0.651811, acc.: 67.19%] [G loss: 1.200839]\n",
      "epoch:25 step:23511 [D loss: 0.688902, acc.: 60.16%] [G loss: 1.186679]\n",
      "epoch:25 step:23512 [D loss: 0.686898, acc.: 54.69%] [G loss: 1.161293]\n",
      "epoch:25 step:23513 [D loss: 0.601898, acc.: 64.84%] [G loss: 1.089298]\n",
      "epoch:25 step:23514 [D loss: 0.530293, acc.: 71.88%] [G loss: 1.139247]\n",
      "epoch:25 step:23515 [D loss: 0.596841, acc.: 65.62%] [G loss: 0.992220]\n",
      "epoch:25 step:23516 [D loss: 0.635313, acc.: 64.84%] [G loss: 1.021135]\n",
      "epoch:25 step:23517 [D loss: 0.533429, acc.: 76.56%] [G loss: 0.992968]\n",
      "epoch:25 step:23518 [D loss: 0.432018, acc.: 86.72%] [G loss: 0.973899]\n",
      "epoch:25 step:23519 [D loss: 0.449607, acc.: 80.47%] [G loss: 1.254731]\n",
      "epoch:25 step:23520 [D loss: 0.639978, acc.: 63.28%] [G loss: 1.151842]\n",
      "epoch:25 step:23521 [D loss: 0.607156, acc.: 71.09%] [G loss: 1.066245]\n",
      "epoch:25 step:23522 [D loss: 0.604480, acc.: 70.31%] [G loss: 0.916417]\n",
      "epoch:25 step:23523 [D loss: 0.612551, acc.: 67.19%] [G loss: 1.149033]\n",
      "epoch:25 step:23524 [D loss: 0.683432, acc.: 52.34%] [G loss: 0.919632]\n",
      "epoch:25 step:23525 [D loss: 0.679372, acc.: 60.94%] [G loss: 0.915137]\n",
      "epoch:25 step:23526 [D loss: 0.631588, acc.: 66.41%] [G loss: 0.962716]\n",
      "epoch:25 step:23527 [D loss: 0.672765, acc.: 62.50%] [G loss: 0.922415]\n",
      "epoch:25 step:23528 [D loss: 0.749547, acc.: 48.44%] [G loss: 1.029759]\n",
      "epoch:25 step:23529 [D loss: 0.666765, acc.: 59.38%] [G loss: 0.917174]\n",
      "epoch:25 step:23530 [D loss: 0.766501, acc.: 46.88%] [G loss: 0.628358]\n",
      "epoch:25 step:23531 [D loss: 0.734962, acc.: 46.09%] [G loss: 0.850134]\n",
      "epoch:25 step:23532 [D loss: 0.666733, acc.: 58.59%] [G loss: 1.023074]\n",
      "epoch:25 step:23533 [D loss: 0.643964, acc.: 58.59%] [G loss: 0.998760]\n",
      "epoch:25 step:23534 [D loss: 0.649243, acc.: 61.72%] [G loss: 0.934852]\n",
      "epoch:25 step:23535 [D loss: 0.633646, acc.: 62.50%] [G loss: 0.871851]\n",
      "epoch:25 step:23536 [D loss: 0.531152, acc.: 76.56%] [G loss: 1.032889]\n",
      "epoch:25 step:23537 [D loss: 0.506173, acc.: 81.25%] [G loss: 0.945908]\n",
      "epoch:25 step:23538 [D loss: 0.451805, acc.: 82.03%] [G loss: 0.995277]\n",
      "epoch:25 step:23539 [D loss: 0.371777, acc.: 90.62%] [G loss: 1.190766]\n",
      "epoch:25 step:23540 [D loss: 0.457131, acc.: 83.59%] [G loss: 1.249764]\n",
      "epoch:25 step:23541 [D loss: 0.620336, acc.: 62.50%] [G loss: 1.160900]\n",
      "epoch:25 step:23542 [D loss: 0.757731, acc.: 49.22%] [G loss: 1.372656]\n",
      "epoch:25 step:23543 [D loss: 0.674486, acc.: 56.25%] [G loss: 0.904906]\n",
      "epoch:25 step:23544 [D loss: 0.276064, acc.: 95.31%] [G loss: 0.997039]\n",
      "epoch:25 step:23545 [D loss: 0.384489, acc.: 89.06%] [G loss: 1.049361]\n",
      "epoch:25 step:23546 [D loss: 0.293475, acc.: 91.41%] [G loss: 1.125684]\n",
      "epoch:25 step:23547 [D loss: 0.304586, acc.: 92.97%] [G loss: 1.308572]\n",
      "epoch:25 step:23548 [D loss: 0.543715, acc.: 73.44%] [G loss: 1.111617]\n",
      "epoch:25 step:23549 [D loss: 0.719467, acc.: 52.34%] [G loss: 1.172429]\n",
      "epoch:25 step:23550 [D loss: 0.738426, acc.: 51.56%] [G loss: 0.967764]\n",
      "epoch:25 step:23551 [D loss: 0.718299, acc.: 59.38%] [G loss: 0.979105]\n",
      "epoch:25 step:23552 [D loss: 0.669464, acc.: 60.94%] [G loss: 1.032549]\n",
      "epoch:25 step:23553 [D loss: 0.585191, acc.: 65.62%] [G loss: 1.100726]\n",
      "epoch:25 step:23554 [D loss: 0.347234, acc.: 93.75%] [G loss: 1.066750]\n",
      "epoch:25 step:23555 [D loss: 0.296239, acc.: 89.84%] [G loss: 0.935787]\n",
      "epoch:25 step:23556 [D loss: 0.377247, acc.: 85.16%] [G loss: 0.725392]\n",
      "epoch:25 step:23557 [D loss: 0.480251, acc.: 74.22%] [G loss: 1.107404]\n",
      "epoch:25 step:23558 [D loss: 0.681011, acc.: 64.84%] [G loss: 1.092487]\n",
      "epoch:25 step:23559 [D loss: 0.766401, acc.: 50.00%] [G loss: 1.257696]\n",
      "epoch:25 step:23560 [D loss: 0.615253, acc.: 68.75%] [G loss: 1.310120]\n",
      "epoch:25 step:23561 [D loss: 0.638864, acc.: 67.97%] [G loss: 1.259487]\n",
      "epoch:25 step:23562 [D loss: 0.509958, acc.: 78.91%] [G loss: 1.092238]\n",
      "epoch:25 step:23563 [D loss: 0.421817, acc.: 86.72%] [G loss: 0.702175]\n",
      "epoch:25 step:23564 [D loss: 0.337760, acc.: 91.41%] [G loss: 1.119064]\n",
      "epoch:25 step:23565 [D loss: 0.503839, acc.: 79.69%] [G loss: 0.925526]\n",
      "epoch:25 step:23566 [D loss: 0.538465, acc.: 78.12%] [G loss: 1.023268]\n",
      "epoch:25 step:23567 [D loss: 0.649149, acc.: 63.28%] [G loss: 1.008801]\n",
      "epoch:25 step:23568 [D loss: 0.326776, acc.: 84.38%] [G loss: 1.133551]\n",
      "epoch:25 step:23569 [D loss: 0.387097, acc.: 79.69%] [G loss: 1.322719]\n",
      "epoch:25 step:23570 [D loss: 0.251478, acc.: 90.62%] [G loss: 1.282196]\n",
      "epoch:25 step:23571 [D loss: 0.401873, acc.: 87.50%] [G loss: 1.322974]\n",
      "epoch:25 step:23572 [D loss: 0.688545, acc.: 59.38%] [G loss: 1.361224]\n",
      "epoch:25 step:23573 [D loss: 0.621885, acc.: 65.62%] [G loss: 1.239415]\n",
      "epoch:25 step:23574 [D loss: 0.581375, acc.: 70.31%] [G loss: 1.213598]\n",
      "epoch:25 step:23575 [D loss: 0.226076, acc.: 94.53%] [G loss: 1.371824]\n",
      "epoch:25 step:23576 [D loss: 0.281485, acc.: 89.84%] [G loss: 1.344434]\n",
      "epoch:25 step:23577 [D loss: 0.373363, acc.: 89.06%] [G loss: 1.512184]\n",
      "epoch:25 step:23578 [D loss: 0.747601, acc.: 50.78%] [G loss: 0.751175]\n",
      "epoch:25 step:23579 [D loss: 0.650776, acc.: 66.41%] [G loss: 1.155470]\n",
      "epoch:25 step:23580 [D loss: 0.587629, acc.: 68.75%] [G loss: 1.259870]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23581 [D loss: 0.611714, acc.: 69.53%] [G loss: 0.770947]\n",
      "epoch:25 step:23582 [D loss: 0.616671, acc.: 68.75%] [G loss: 1.103053]\n",
      "epoch:25 step:23583 [D loss: 0.711936, acc.: 55.47%] [G loss: 0.827521]\n",
      "epoch:25 step:23584 [D loss: 0.661581, acc.: 58.59%] [G loss: 0.730935]\n",
      "epoch:25 step:23585 [D loss: 0.565618, acc.: 61.72%] [G loss: 0.927009]\n",
      "epoch:25 step:23586 [D loss: 1.142533, acc.: 40.62%] [G loss: 1.446340]\n",
      "epoch:25 step:23587 [D loss: 0.423628, acc.: 82.81%] [G loss: 1.368924]\n",
      "epoch:25 step:23588 [D loss: 0.507221, acc.: 78.91%] [G loss: 1.297982]\n",
      "epoch:25 step:23589 [D loss: 0.474497, acc.: 78.91%] [G loss: 1.510333]\n",
      "epoch:25 step:23590 [D loss: 0.600419, acc.: 67.19%] [G loss: 1.361760]\n",
      "epoch:25 step:23591 [D loss: 0.681117, acc.: 64.06%] [G loss: 1.092972]\n",
      "epoch:25 step:23592 [D loss: 0.652540, acc.: 60.94%] [G loss: 0.892214]\n",
      "epoch:25 step:23593 [D loss: 0.565611, acc.: 66.41%] [G loss: 1.062561]\n",
      "epoch:25 step:23594 [D loss: 0.713366, acc.: 56.25%] [G loss: 1.275453]\n",
      "epoch:25 step:23595 [D loss: 0.599545, acc.: 66.41%] [G loss: 1.454432]\n",
      "epoch:25 step:23596 [D loss: 0.784795, acc.: 45.31%] [G loss: 1.412795]\n",
      "epoch:25 step:23597 [D loss: 0.657541, acc.: 64.06%] [G loss: 1.113061]\n",
      "epoch:25 step:23598 [D loss: 0.707508, acc.: 52.34%] [G loss: 1.008073]\n",
      "epoch:25 step:23599 [D loss: 0.734025, acc.: 50.78%] [G loss: 0.983394]\n",
      "epoch:25 step:23600 [D loss: 0.687344, acc.: 56.25%] [G loss: 0.996733]\n",
      "##############\n",
      "[4.25687832 2.77626296 6.5901125  5.93316925 4.39928088 5.80365335\n",
      " 5.0013324  5.4990999  5.91509747 4.76541164]\n",
      "##########\n",
      "epoch:25 step:23601 [D loss: 0.608359, acc.: 66.41%] [G loss: 0.997134]\n",
      "epoch:25 step:23602 [D loss: 0.760053, acc.: 48.44%] [G loss: 0.392061]\n",
      "epoch:25 step:23603 [D loss: 0.784199, acc.: 54.69%] [G loss: 1.140864]\n",
      "epoch:25 step:23604 [D loss: 0.497604, acc.: 81.25%] [G loss: 1.057382]\n",
      "epoch:25 step:23605 [D loss: 0.685337, acc.: 60.94%] [G loss: 1.189155]\n",
      "epoch:25 step:23606 [D loss: 0.684354, acc.: 53.91%] [G loss: 1.242392]\n",
      "epoch:25 step:23607 [D loss: 0.668135, acc.: 55.47%] [G loss: 1.015107]\n",
      "epoch:25 step:23608 [D loss: 0.703003, acc.: 50.78%] [G loss: 0.915405]\n",
      "epoch:25 step:23609 [D loss: 0.543424, acc.: 75.00%] [G loss: 0.975955]\n",
      "epoch:25 step:23610 [D loss: 0.492706, acc.: 73.44%] [G loss: 1.108931]\n",
      "epoch:25 step:23611 [D loss: 0.579762, acc.: 74.22%] [G loss: 0.976112]\n",
      "epoch:25 step:23612 [D loss: 0.774079, acc.: 51.56%] [G loss: 0.793573]\n",
      "epoch:25 step:23613 [D loss: 0.650863, acc.: 61.72%] [G loss: 0.807600]\n",
      "epoch:25 step:23614 [D loss: 0.725784, acc.: 51.56%] [G loss: 0.888869]\n",
      "epoch:25 step:23615 [D loss: 0.644635, acc.: 64.84%] [G loss: 0.981451]\n",
      "epoch:25 step:23616 [D loss: 0.606772, acc.: 64.84%] [G loss: 0.979737]\n",
      "epoch:25 step:23617 [D loss: 0.344457, acc.: 85.16%] [G loss: 1.162566]\n",
      "epoch:25 step:23618 [D loss: 0.463594, acc.: 87.50%] [G loss: 1.245247]\n",
      "epoch:25 step:23619 [D loss: 0.305228, acc.: 91.41%] [G loss: 1.295349]\n",
      "epoch:25 step:23620 [D loss: 0.391291, acc.: 89.06%] [G loss: 1.370167]\n",
      "epoch:25 step:23621 [D loss: 0.398667, acc.: 86.72%] [G loss: 1.317361]\n",
      "epoch:25 step:23622 [D loss: 0.415420, acc.: 88.28%] [G loss: 1.333562]\n",
      "epoch:25 step:23623 [D loss: 0.368077, acc.: 91.41%] [G loss: 1.112743]\n",
      "epoch:25 step:23624 [D loss: 0.698679, acc.: 59.38%] [G loss: 0.972721]\n",
      "epoch:25 step:23625 [D loss: 0.376067, acc.: 85.16%] [G loss: 1.149058]\n",
      "epoch:25 step:23626 [D loss: 0.226229, acc.: 95.31%] [G loss: 1.461440]\n",
      "epoch:25 step:23627 [D loss: 0.698081, acc.: 54.69%] [G loss: 1.311743]\n",
      "epoch:25 step:23628 [D loss: 0.261062, acc.: 95.31%] [G loss: 1.203808]\n",
      "epoch:25 step:23629 [D loss: 0.183010, acc.: 97.66%] [G loss: 1.287355]\n",
      "epoch:25 step:23630 [D loss: 0.343499, acc.: 92.97%] [G loss: 1.240170]\n",
      "epoch:25 step:23631 [D loss: 0.183821, acc.: 96.88%] [G loss: 1.218339]\n",
      "epoch:25 step:23632 [D loss: 0.335296, acc.: 82.03%] [G loss: 1.061112]\n",
      "epoch:25 step:23633 [D loss: 0.141744, acc.: 99.22%] [G loss: 1.508986]\n",
      "epoch:25 step:23634 [D loss: 0.216761, acc.: 98.44%] [G loss: 1.655714]\n",
      "epoch:25 step:23635 [D loss: 1.006877, acc.: 47.66%] [G loss: 1.544906]\n",
      "epoch:25 step:23636 [D loss: 1.029352, acc.: 46.09%] [G loss: 0.869249]\n",
      "epoch:25 step:23637 [D loss: 0.650457, acc.: 55.47%] [G loss: 1.104732]\n",
      "epoch:25 step:23638 [D loss: 1.045922, acc.: 23.44%] [G loss: 1.291486]\n",
      "epoch:25 step:23639 [D loss: 0.980392, acc.: 32.03%] [G loss: 1.595989]\n",
      "epoch:25 step:23640 [D loss: 0.836422, acc.: 39.06%] [G loss: 1.079784]\n",
      "epoch:25 step:23641 [D loss: 0.805236, acc.: 45.31%] [G loss: 1.321908]\n",
      "epoch:25 step:23642 [D loss: 0.338674, acc.: 92.19%] [G loss: 0.879116]\n",
      "epoch:25 step:23643 [D loss: 0.315503, acc.: 87.50%] [G loss: 0.959068]\n",
      "epoch:25 step:23644 [D loss: 0.300235, acc.: 92.19%] [G loss: 1.129157]\n",
      "epoch:25 step:23645 [D loss: 0.248142, acc.: 94.53%] [G loss: 0.787138]\n",
      "epoch:25 step:23646 [D loss: 0.448250, acc.: 67.97%] [G loss: 1.085967]\n",
      "epoch:25 step:23647 [D loss: 0.177935, acc.: 98.44%] [G loss: 1.510078]\n",
      "epoch:25 step:23648 [D loss: 0.388637, acc.: 86.72%] [G loss: 1.533563]\n",
      "epoch:25 step:23649 [D loss: 0.664051, acc.: 57.81%] [G loss: 1.338286]\n",
      "epoch:25 step:23650 [D loss: 0.426844, acc.: 85.16%] [G loss: 0.308784]\n",
      "epoch:25 step:23651 [D loss: 0.876169, acc.: 44.53%] [G loss: 1.204851]\n",
      "epoch:25 step:23652 [D loss: 0.680209, acc.: 59.38%] [G loss: 1.409916]\n",
      "epoch:25 step:23653 [D loss: 0.791332, acc.: 42.97%] [G loss: 1.104353]\n",
      "epoch:25 step:23654 [D loss: 0.644839, acc.: 64.06%] [G loss: 0.979977]\n",
      "epoch:25 step:23655 [D loss: 0.279456, acc.: 87.50%] [G loss: 1.338799]\n",
      "epoch:25 step:23656 [D loss: 0.179945, acc.: 97.66%] [G loss: 1.241512]\n",
      "epoch:25 step:23657 [D loss: 0.180822, acc.: 98.44%] [G loss: 1.598514]\n",
      "epoch:25 step:23658 [D loss: 0.641609, acc.: 64.84%] [G loss: 1.404601]\n",
      "epoch:25 step:23659 [D loss: 0.458829, acc.: 78.12%] [G loss: 1.472044]\n",
      "epoch:25 step:23660 [D loss: 0.260159, acc.: 94.53%] [G loss: 1.830186]\n",
      "epoch:25 step:23661 [D loss: 0.514089, acc.: 78.91%] [G loss: 1.411642]\n",
      "epoch:25 step:23662 [D loss: 0.273232, acc.: 94.53%] [G loss: 1.371465]\n",
      "epoch:25 step:23663 [D loss: 0.202254, acc.: 97.66%] [G loss: 1.069508]\n",
      "epoch:25 step:23664 [D loss: 0.368320, acc.: 94.53%] [G loss: 1.909767]\n",
      "epoch:25 step:23665 [D loss: 0.516340, acc.: 75.78%] [G loss: 1.473464]\n",
      "epoch:25 step:23666 [D loss: 0.840064, acc.: 53.12%] [G loss: 1.060308]\n",
      "epoch:25 step:23667 [D loss: 0.842314, acc.: 53.12%] [G loss: 1.493157]\n",
      "epoch:25 step:23668 [D loss: 0.205476, acc.: 99.22%] [G loss: 1.372360]\n",
      "epoch:25 step:23669 [D loss: 0.582131, acc.: 70.31%] [G loss: 1.592330]\n",
      "epoch:25 step:23670 [D loss: 0.830647, acc.: 46.88%] [G loss: 1.049990]\n",
      "epoch:25 step:23671 [D loss: 0.748828, acc.: 53.12%] [G loss: 1.208889]\n",
      "epoch:25 step:23672 [D loss: 0.704293, acc.: 55.47%] [G loss: 0.326464]\n",
      "epoch:25 step:23673 [D loss: 0.843795, acc.: 42.97%] [G loss: 1.004482]\n",
      "epoch:25 step:23674 [D loss: 0.532630, acc.: 74.22%] [G loss: 1.098093]\n",
      "epoch:25 step:23675 [D loss: 0.741372, acc.: 48.44%] [G loss: 1.235945]\n",
      "epoch:25 step:23676 [D loss: 0.508416, acc.: 78.12%] [G loss: 0.815506]\n",
      "epoch:25 step:23677 [D loss: 0.498539, acc.: 82.03%] [G loss: 1.421632]\n",
      "epoch:25 step:23678 [D loss: 0.490667, acc.: 79.69%] [G loss: 0.902249]\n",
      "epoch:25 step:23679 [D loss: 0.395134, acc.: 78.12%] [G loss: 1.694914]\n",
      "epoch:25 step:23680 [D loss: 0.166508, acc.: 97.66%] [G loss: 1.489735]\n",
      "epoch:25 step:23681 [D loss: 0.183696, acc.: 97.66%] [G loss: 1.581544]\n",
      "epoch:25 step:23682 [D loss: 0.223621, acc.: 96.88%] [G loss: 1.127010]\n",
      "epoch:25 step:23683 [D loss: 0.594041, acc.: 67.19%] [G loss: 1.719951]\n",
      "epoch:25 step:23684 [D loss: 0.334331, acc.: 82.03%] [G loss: 1.551432]\n",
      "epoch:25 step:23685 [D loss: 0.257586, acc.: 90.62%] [G loss: 1.401250]\n",
      "epoch:25 step:23686 [D loss: 0.103856, acc.: 100.00%] [G loss: 1.830375]\n",
      "epoch:25 step:23687 [D loss: 0.781793, acc.: 56.25%] [G loss: 1.102165]\n",
      "epoch:25 step:23688 [D loss: 0.391158, acc.: 84.38%] [G loss: 1.369639]\n",
      "epoch:25 step:23689 [D loss: 0.783457, acc.: 46.88%] [G loss: 1.556796]\n",
      "epoch:25 step:23690 [D loss: 0.670535, acc.: 60.94%] [G loss: 1.256721]\n",
      "epoch:25 step:23691 [D loss: 2.324223, acc.: 9.38%] [G loss: 1.854246]\n",
      "epoch:25 step:23692 [D loss: 0.724910, acc.: 53.91%] [G loss: 1.647469]\n",
      "epoch:25 step:23693 [D loss: 0.740804, acc.: 59.38%] [G loss: 1.424878]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23694 [D loss: 0.291436, acc.: 95.31%] [G loss: 1.717973]\n",
      "epoch:25 step:23695 [D loss: 0.561543, acc.: 67.19%] [G loss: 1.511325]\n",
      "epoch:25 step:23696 [D loss: 0.250862, acc.: 96.88%] [G loss: 1.532568]\n",
      "epoch:25 step:23697 [D loss: 0.402185, acc.: 84.38%] [G loss: 1.517517]\n",
      "epoch:25 step:23698 [D loss: 0.542082, acc.: 69.53%] [G loss: 1.317021]\n",
      "epoch:25 step:23699 [D loss: 0.317023, acc.: 92.97%] [G loss: 1.525765]\n",
      "epoch:25 step:23700 [D loss: 0.414832, acc.: 86.72%] [G loss: 1.467810]\n",
      "epoch:25 step:23701 [D loss: 0.295079, acc.: 94.53%] [G loss: 1.699517]\n",
      "epoch:25 step:23702 [D loss: 0.508774, acc.: 75.78%] [G loss: 1.184639]\n",
      "epoch:25 step:23703 [D loss: 0.587276, acc.: 70.31%] [G loss: 1.338258]\n",
      "epoch:25 step:23704 [D loss: 0.235467, acc.: 97.66%] [G loss: 1.161103]\n",
      "epoch:25 step:23705 [D loss: 0.740202, acc.: 54.69%] [G loss: 1.190496]\n",
      "epoch:25 step:23706 [D loss: 0.651460, acc.: 64.84%] [G loss: 0.804785]\n",
      "epoch:25 step:23707 [D loss: 0.329757, acc.: 94.53%] [G loss: 1.004681]\n",
      "epoch:25 step:23708 [D loss: 0.729558, acc.: 49.22%] [G loss: 0.803763]\n",
      "epoch:25 step:23709 [D loss: 0.635076, acc.: 65.62%] [G loss: 1.241939]\n",
      "epoch:25 step:23710 [D loss: 0.528843, acc.: 77.34%] [G loss: 1.232074]\n",
      "epoch:25 step:23711 [D loss: 0.480072, acc.: 82.81%] [G loss: 1.118300]\n",
      "epoch:25 step:23712 [D loss: 0.683930, acc.: 54.69%] [G loss: 1.004457]\n",
      "epoch:25 step:23713 [D loss: 0.392071, acc.: 89.84%] [G loss: 1.207475]\n",
      "epoch:25 step:23714 [D loss: 0.276010, acc.: 94.53%] [G loss: 1.205565]\n",
      "epoch:25 step:23715 [D loss: 0.623540, acc.: 65.62%] [G loss: 1.323162]\n",
      "epoch:25 step:23716 [D loss: 0.815939, acc.: 47.66%] [G loss: 1.372990]\n",
      "epoch:25 step:23717 [D loss: 0.300718, acc.: 93.75%] [G loss: 1.397210]\n",
      "epoch:25 step:23718 [D loss: 0.556521, acc.: 71.09%] [G loss: 1.363315]\n",
      "epoch:25 step:23719 [D loss: 0.632288, acc.: 64.84%] [G loss: 0.814914]\n",
      "epoch:25 step:23720 [D loss: 0.569798, acc.: 70.31%] [G loss: 1.074141]\n",
      "epoch:25 step:23721 [D loss: 0.686855, acc.: 53.91%] [G loss: 0.565583]\n",
      "epoch:25 step:23722 [D loss: 0.319742, acc.: 94.53%] [G loss: 1.351445]\n",
      "epoch:25 step:23723 [D loss: 0.272110, acc.: 93.75%] [G loss: 1.055634]\n",
      "epoch:25 step:23724 [D loss: 0.223658, acc.: 98.44%] [G loss: 1.580395]\n",
      "epoch:25 step:23725 [D loss: 0.366393, acc.: 93.75%] [G loss: 1.424887]\n",
      "epoch:25 step:23726 [D loss: 0.674061, acc.: 57.81%] [G loss: 1.405601]\n",
      "epoch:25 step:23727 [D loss: 0.655844, acc.: 59.38%] [G loss: 1.283743]\n",
      "epoch:25 step:23728 [D loss: 0.376951, acc.: 92.97%] [G loss: 1.066287]\n",
      "epoch:25 step:23729 [D loss: 0.782961, acc.: 46.88%] [G loss: 1.087685]\n",
      "epoch:25 step:23730 [D loss: 0.516715, acc.: 82.81%] [G loss: 1.158758]\n",
      "epoch:25 step:23731 [D loss: 0.606967, acc.: 63.28%] [G loss: 1.304713]\n",
      "epoch:25 step:23732 [D loss: 0.475500, acc.: 84.38%] [G loss: 0.955435]\n",
      "epoch:25 step:23733 [D loss: 0.548924, acc.: 78.91%] [G loss: 0.846488]\n",
      "epoch:25 step:23734 [D loss: 0.355726, acc.: 80.47%] [G loss: 1.027480]\n",
      "epoch:25 step:23735 [D loss: 0.608345, acc.: 67.97%] [G loss: 1.570510]\n",
      "epoch:25 step:23736 [D loss: 0.514289, acc.: 77.34%] [G loss: 1.108602]\n",
      "epoch:25 step:23737 [D loss: 0.231392, acc.: 93.75%] [G loss: 0.234200]\n",
      "epoch:25 step:23738 [D loss: 0.192708, acc.: 97.66%] [G loss: 1.530135]\n",
      "epoch:25 step:23739 [D loss: 0.191072, acc.: 99.22%] [G loss: 1.219484]\n",
      "epoch:25 step:23740 [D loss: 0.430098, acc.: 84.38%] [G loss: 1.536881]\n",
      "epoch:25 step:23741 [D loss: 0.451026, acc.: 81.25%] [G loss: 1.637534]\n",
      "epoch:25 step:23742 [D loss: 0.731147, acc.: 52.34%] [G loss: 1.431742]\n",
      "epoch:25 step:23743 [D loss: 0.394537, acc.: 90.62%] [G loss: 1.469602]\n",
      "epoch:25 step:23744 [D loss: 0.632035, acc.: 65.62%] [G loss: 1.262953]\n",
      "epoch:25 step:23745 [D loss: 0.555089, acc.: 72.66%] [G loss: 1.455006]\n",
      "epoch:25 step:23746 [D loss: 0.548710, acc.: 71.88%] [G loss: 1.296779]\n",
      "epoch:25 step:23747 [D loss: 0.485354, acc.: 79.69%] [G loss: 1.600169]\n",
      "epoch:25 step:23748 [D loss: 0.817016, acc.: 47.66%] [G loss: 1.246156]\n",
      "epoch:25 step:23749 [D loss: 0.610496, acc.: 64.84%] [G loss: 1.179151]\n",
      "epoch:25 step:23750 [D loss: 0.568493, acc.: 67.97%] [G loss: 1.198792]\n",
      "epoch:25 step:23751 [D loss: 0.522620, acc.: 77.34%] [G loss: 1.435569]\n",
      "epoch:25 step:23752 [D loss: 0.305427, acc.: 86.72%] [G loss: 1.540746]\n",
      "epoch:25 step:23753 [D loss: 0.264208, acc.: 92.97%] [G loss: 1.049608]\n",
      "epoch:25 step:23754 [D loss: 0.535965, acc.: 74.22%] [G loss: 1.006868]\n",
      "epoch:25 step:23755 [D loss: 0.870173, acc.: 47.66%] [G loss: 0.789257]\n",
      "epoch:25 step:23756 [D loss: 0.647361, acc.: 65.62%] [G loss: 0.976882]\n",
      "epoch:25 step:23757 [D loss: 0.491036, acc.: 75.78%] [G loss: 1.208193]\n",
      "epoch:25 step:23758 [D loss: 0.277614, acc.: 92.97%] [G loss: 0.999709]\n",
      "epoch:25 step:23759 [D loss: 0.626380, acc.: 61.72%] [G loss: 1.587522]\n",
      "epoch:25 step:23760 [D loss: 0.395192, acc.: 90.62%] [G loss: 1.443286]\n",
      "epoch:25 step:23761 [D loss: 0.209291, acc.: 93.75%] [G loss: 1.836842]\n",
      "epoch:25 step:23762 [D loss: 0.508605, acc.: 78.12%] [G loss: 1.678746]\n",
      "epoch:25 step:23763 [D loss: 0.512850, acc.: 75.78%] [G loss: 1.633708]\n",
      "epoch:25 step:23764 [D loss: 0.568309, acc.: 67.19%] [G loss: 1.386996]\n",
      "epoch:25 step:23765 [D loss: 0.435050, acc.: 81.25%] [G loss: 1.386368]\n",
      "epoch:25 step:23766 [D loss: 0.549917, acc.: 75.00%] [G loss: 1.123942]\n",
      "epoch:25 step:23767 [D loss: 0.165210, acc.: 95.31%] [G loss: 1.627105]\n",
      "epoch:25 step:23768 [D loss: 0.268702, acc.: 85.94%] [G loss: 1.506767]\n",
      "epoch:25 step:23769 [D loss: 0.179701, acc.: 95.31%] [G loss: 1.915539]\n",
      "epoch:25 step:23770 [D loss: 0.094558, acc.: 100.00%] [G loss: 2.001312]\n",
      "epoch:25 step:23771 [D loss: 0.127721, acc.: 98.44%] [G loss: 2.250679]\n",
      "epoch:25 step:23772 [D loss: 0.139467, acc.: 96.88%] [G loss: 1.956490]\n",
      "epoch:25 step:23773 [D loss: 0.609032, acc.: 64.06%] [G loss: 1.927481]\n",
      "epoch:25 step:23774 [D loss: 0.981375, acc.: 50.00%] [G loss: 1.837409]\n",
      "epoch:25 step:23775 [D loss: 0.423067, acc.: 85.94%] [G loss: 1.674513]\n",
      "epoch:25 step:23776 [D loss: 0.775236, acc.: 49.22%] [G loss: 0.935867]\n",
      "epoch:25 step:23777 [D loss: 0.652671, acc.: 60.94%] [G loss: 1.167325]\n",
      "epoch:25 step:23778 [D loss: 0.611876, acc.: 67.19%] [G loss: 1.202254]\n",
      "epoch:25 step:23779 [D loss: 1.037143, acc.: 29.69%] [G loss: 1.368852]\n",
      "epoch:25 step:23780 [D loss: 0.783140, acc.: 54.69%] [G loss: 1.145600]\n",
      "epoch:25 step:23781 [D loss: 0.736002, acc.: 53.91%] [G loss: 1.464141]\n",
      "epoch:25 step:23782 [D loss: 0.772796, acc.: 43.75%] [G loss: 1.354046]\n",
      "epoch:25 step:23783 [D loss: 0.609259, acc.: 69.53%] [G loss: 1.334047]\n",
      "epoch:25 step:23784 [D loss: 0.577288, acc.: 68.75%] [G loss: 1.323208]\n",
      "epoch:25 step:23785 [D loss: 0.688004, acc.: 56.25%] [G loss: 1.223695]\n",
      "epoch:25 step:23786 [D loss: 0.653299, acc.: 60.16%] [G loss: 1.067697]\n",
      "epoch:25 step:23787 [D loss: 0.390014, acc.: 79.69%] [G loss: 1.268427]\n",
      "epoch:25 step:23788 [D loss: 0.273196, acc.: 89.84%] [G loss: 1.453178]\n",
      "epoch:25 step:23789 [D loss: 0.426909, acc.: 82.81%] [G loss: 1.517176]\n",
      "epoch:25 step:23790 [D loss: 0.378747, acc.: 78.91%] [G loss: 1.327423]\n",
      "epoch:25 step:23791 [D loss: 0.185113, acc.: 96.88%] [G loss: 1.680964]\n",
      "epoch:25 step:23792 [D loss: 0.159542, acc.: 99.22%] [G loss: 1.548156]\n",
      "epoch:25 step:23793 [D loss: 0.591011, acc.: 69.53%] [G loss: 1.543406]\n",
      "epoch:25 step:23794 [D loss: 0.444246, acc.: 87.50%] [G loss: 1.299638]\n",
      "epoch:25 step:23795 [D loss: 0.464461, acc.: 82.03%] [G loss: 1.308290]\n",
      "epoch:25 step:23796 [D loss: 0.376462, acc.: 85.94%] [G loss: 1.349476]\n",
      "epoch:25 step:23797 [D loss: 0.673586, acc.: 62.50%] [G loss: 1.195515]\n",
      "epoch:25 step:23798 [D loss: 0.687793, acc.: 59.38%] [G loss: 1.480273]\n",
      "epoch:25 step:23799 [D loss: 0.758874, acc.: 52.34%] [G loss: 1.010464]\n",
      "epoch:25 step:23800 [D loss: 0.417782, acc.: 83.59%] [G loss: 1.303558]\n",
      "##############\n",
      "[4.00038996 2.54734489 6.39338726 5.65620552 4.75471903 5.98495041\n",
      " 5.35530655 4.89909843 6.0486937  4.78237166]\n",
      "##########\n",
      "epoch:25 step:23801 [D loss: 0.554296, acc.: 71.09%] [G loss: 1.076087]\n",
      "epoch:25 step:23802 [D loss: 1.112513, acc.: 50.78%] [G loss: 1.538674]\n",
      "epoch:25 step:23803 [D loss: 0.154221, acc.: 99.22%] [G loss: 1.674630]\n",
      "epoch:25 step:23804 [D loss: 0.567221, acc.: 64.84%] [G loss: 1.514853]\n",
      "epoch:25 step:23805 [D loss: 0.301750, acc.: 94.53%] [G loss: 1.445717]\n",
      "epoch:25 step:23806 [D loss: 0.281912, acc.: 96.09%] [G loss: 1.311624]\n",
      "epoch:25 step:23807 [D loss: 0.820242, acc.: 54.69%] [G loss: 1.409107]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23808 [D loss: 0.818299, acc.: 42.19%] [G loss: 1.250082]\n",
      "epoch:25 step:23809 [D loss: 0.496267, acc.: 81.25%] [G loss: 1.127319]\n",
      "epoch:25 step:23810 [D loss: 0.711953, acc.: 59.38%] [G loss: 1.239948]\n",
      "epoch:25 step:23811 [D loss: 0.728006, acc.: 56.25%] [G loss: 0.984572]\n",
      "epoch:25 step:23812 [D loss: 0.650751, acc.: 60.16%] [G loss: 0.199193]\n",
      "epoch:25 step:23813 [D loss: 0.705650, acc.: 56.25%] [G loss: 0.978517]\n",
      "epoch:25 step:23814 [D loss: 0.683007, acc.: 58.59%] [G loss: 1.009001]\n",
      "epoch:25 step:23815 [D loss: 0.649156, acc.: 60.94%] [G loss: 1.157451]\n",
      "epoch:25 step:23816 [D loss: 0.678385, acc.: 59.38%] [G loss: 1.089973]\n",
      "epoch:25 step:23817 [D loss: 0.531095, acc.: 78.12%] [G loss: 1.206717]\n",
      "epoch:25 step:23818 [D loss: 0.281685, acc.: 88.28%] [G loss: 1.014993]\n",
      "epoch:25 step:23819 [D loss: 0.653770, acc.: 57.81%] [G loss: 1.141746]\n",
      "epoch:25 step:23820 [D loss: 0.706058, acc.: 56.25%] [G loss: 1.033007]\n",
      "epoch:25 step:23821 [D loss: 0.344237, acc.: 78.91%] [G loss: 0.988280]\n",
      "epoch:25 step:23822 [D loss: 0.213960, acc.: 92.97%] [G loss: 1.212994]\n",
      "epoch:25 step:23823 [D loss: 0.221940, acc.: 95.31%] [G loss: 1.351207]\n",
      "epoch:25 step:23824 [D loss: 0.176151, acc.: 96.88%] [G loss: 1.441267]\n",
      "epoch:25 step:23825 [D loss: 0.126920, acc.: 100.00%] [G loss: 1.640934]\n",
      "epoch:25 step:23826 [D loss: 0.208435, acc.: 91.41%] [G loss: 1.627174]\n",
      "epoch:25 step:23827 [D loss: 0.131774, acc.: 97.66%] [G loss: 1.759696]\n",
      "epoch:25 step:23828 [D loss: 0.146726, acc.: 98.44%] [G loss: 1.669989]\n",
      "epoch:25 step:23829 [D loss: 0.102054, acc.: 100.00%] [G loss: 1.909199]\n",
      "epoch:25 step:23830 [D loss: 0.133388, acc.: 98.44%] [G loss: 1.982852]\n",
      "epoch:25 step:23831 [D loss: 0.083177, acc.: 100.00%] [G loss: 2.006277]\n",
      "epoch:25 step:23832 [D loss: 0.083059, acc.: 100.00%] [G loss: 2.029815]\n",
      "epoch:25 step:23833 [D loss: 0.098462, acc.: 99.22%] [G loss: 2.234051]\n",
      "epoch:25 step:23834 [D loss: 0.174843, acc.: 97.66%] [G loss: 2.070003]\n",
      "epoch:25 step:23835 [D loss: 0.125604, acc.: 99.22%] [G loss: 2.385476]\n",
      "epoch:25 step:23836 [D loss: 0.855485, acc.: 50.78%] [G loss: 1.998848]\n",
      "epoch:25 step:23837 [D loss: 0.151455, acc.: 96.09%] [G loss: 0.401221]\n",
      "epoch:25 step:23838 [D loss: 0.103812, acc.: 100.00%] [G loss: 0.049378]\n",
      "epoch:25 step:23839 [D loss: 0.089382, acc.: 100.00%] [G loss: 2.176828]\n",
      "epoch:25 step:23840 [D loss: 0.425748, acc.: 70.31%] [G loss: 2.386488]\n",
      "epoch:25 step:23841 [D loss: 0.099039, acc.: 100.00%] [G loss: 2.463858]\n",
      "epoch:25 step:23842 [D loss: 0.063423, acc.: 100.00%] [G loss: 1.894991]\n",
      "epoch:25 step:23843 [D loss: 0.065088, acc.: 100.00%] [G loss: 2.369642]\n",
      "epoch:25 step:23844 [D loss: 0.067792, acc.: 100.00%] [G loss: 2.330050]\n",
      "epoch:25 step:23845 [D loss: 0.271852, acc.: 87.50%] [G loss: 2.603507]\n",
      "epoch:25 step:23846 [D loss: 0.641275, acc.: 57.81%] [G loss: 2.548268]\n",
      "epoch:25 step:23847 [D loss: 0.718433, acc.: 58.59%] [G loss: 2.291929]\n",
      "epoch:25 step:23848 [D loss: 0.330770, acc.: 89.06%] [G loss: 1.285970]\n",
      "epoch:25 step:23849 [D loss: 0.087557, acc.: 98.44%] [G loss: 0.257507]\n",
      "epoch:25 step:23850 [D loss: 0.210826, acc.: 94.53%] [G loss: 1.892222]\n",
      "epoch:25 step:23851 [D loss: 3.051591, acc.: 18.75%] [G loss: 2.236471]\n",
      "epoch:25 step:23852 [D loss: 0.071429, acc.: 100.00%] [G loss: 2.392428]\n",
      "epoch:25 step:23853 [D loss: 0.075451, acc.: 100.00%] [G loss: 2.497732]\n",
      "epoch:25 step:23854 [D loss: 0.296217, acc.: 92.19%] [G loss: 2.100817]\n",
      "epoch:25 step:23855 [D loss: 0.088051, acc.: 100.00%] [G loss: 1.387899]\n",
      "epoch:25 step:23856 [D loss: 0.753163, acc.: 50.78%] [G loss: 2.258545]\n",
      "epoch:25 step:23857 [D loss: 1.370702, acc.: 25.78%] [G loss: 1.527549]\n",
      "epoch:25 step:23858 [D loss: 0.677957, acc.: 57.03%] [G loss: 1.167330]\n",
      "epoch:25 step:23859 [D loss: 0.686293, acc.: 57.81%] [G loss: 0.791653]\n",
      "epoch:25 step:23860 [D loss: 1.443828, acc.: 25.00%] [G loss: 0.947716]\n",
      "epoch:25 step:23861 [D loss: 0.507020, acc.: 71.88%] [G loss: 0.897835]\n",
      "epoch:25 step:23862 [D loss: 0.962157, acc.: 25.78%] [G loss: 1.166984]\n",
      "epoch:25 step:23863 [D loss: 0.162578, acc.: 100.00%] [G loss: 1.745087]\n",
      "epoch:25 step:23864 [D loss: 0.885124, acc.: 39.06%] [G loss: 1.084423]\n",
      "epoch:25 step:23865 [D loss: 0.897919, acc.: 44.53%] [G loss: 1.334346]\n",
      "epoch:25 step:23866 [D loss: 1.233220, acc.: 15.62%] [G loss: 0.703687]\n",
      "epoch:25 step:23867 [D loss: 0.794351, acc.: 47.66%] [G loss: 1.549630]\n",
      "epoch:25 step:23868 [D loss: 1.006371, acc.: 46.88%] [G loss: 1.264604]\n",
      "epoch:25 step:23869 [D loss: 1.200573, acc.: 22.66%] [G loss: 1.588618]\n",
      "epoch:25 step:23870 [D loss: 0.859601, acc.: 43.75%] [G loss: 1.092698]\n",
      "epoch:25 step:23871 [D loss: 0.778364, acc.: 47.66%] [G loss: 1.234555]\n",
      "epoch:25 step:23872 [D loss: 0.702866, acc.: 57.03%] [G loss: 1.175101]\n",
      "epoch:25 step:23873 [D loss: 0.946197, acc.: 32.81%] [G loss: 1.697752]\n",
      "epoch:25 step:23874 [D loss: 0.578146, acc.: 64.84%] [G loss: 1.592157]\n",
      "epoch:25 step:23875 [D loss: 0.753257, acc.: 52.34%] [G loss: 1.492335]\n",
      "epoch:25 step:23876 [D loss: 0.424916, acc.: 88.28%] [G loss: 1.688140]\n",
      "epoch:25 step:23877 [D loss: 0.313045, acc.: 94.53%] [G loss: 1.672552]\n",
      "epoch:25 step:23878 [D loss: 0.319850, acc.: 92.19%] [G loss: 1.608478]\n",
      "epoch:25 step:23879 [D loss: 0.329040, acc.: 93.75%] [G loss: 1.836892]\n",
      "epoch:25 step:23880 [D loss: 0.472919, acc.: 72.66%] [G loss: 1.903642]\n",
      "epoch:25 step:23881 [D loss: 0.126133, acc.: 99.22%] [G loss: 2.475694]\n",
      "epoch:25 step:23882 [D loss: 0.249173, acc.: 99.22%] [G loss: 1.946581]\n",
      "epoch:25 step:23883 [D loss: 0.603893, acc.: 66.41%] [G loss: 1.731586]\n",
      "epoch:25 step:23884 [D loss: 0.529636, acc.: 70.31%] [G loss: 1.280545]\n",
      "epoch:25 step:23885 [D loss: 0.577857, acc.: 63.28%] [G loss: 1.629102]\n",
      "epoch:25 step:23886 [D loss: 0.720115, acc.: 55.47%] [G loss: 1.400155]\n",
      "epoch:25 step:23887 [D loss: 0.839688, acc.: 36.72%] [G loss: 0.929891]\n",
      "epoch:25 step:23888 [D loss: 0.638164, acc.: 63.28%] [G loss: 1.142300]\n",
      "epoch:25 step:23889 [D loss: 0.382482, acc.: 88.28%] [G loss: 1.025842]\n",
      "epoch:25 step:23890 [D loss: 0.341399, acc.: 85.16%] [G loss: 1.304784]\n",
      "epoch:25 step:23891 [D loss: 0.296429, acc.: 92.19%] [G loss: 1.334186]\n",
      "epoch:25 step:23892 [D loss: 0.270696, acc.: 93.75%] [G loss: 1.439071]\n",
      "epoch:25 step:23893 [D loss: 0.241900, acc.: 92.19%] [G loss: 1.571597]\n",
      "epoch:25 step:23894 [D loss: 0.182241, acc.: 95.31%] [G loss: 1.371399]\n",
      "epoch:25 step:23895 [D loss: 0.108708, acc.: 98.44%] [G loss: 2.313552]\n",
      "epoch:25 step:23896 [D loss: 0.154510, acc.: 97.66%] [G loss: 2.284515]\n",
      "epoch:25 step:23897 [D loss: 0.154642, acc.: 100.00%] [G loss: 1.215325]\n",
      "epoch:25 step:23898 [D loss: 1.161439, acc.: 41.41%] [G loss: 1.562411]\n",
      "epoch:25 step:23899 [D loss: 0.938469, acc.: 46.09%] [G loss: 1.208579]\n",
      "epoch:25 step:23900 [D loss: 0.800639, acc.: 50.78%] [G loss: 1.242617]\n",
      "epoch:25 step:23901 [D loss: 0.607312, acc.: 64.84%] [G loss: 0.910976]\n",
      "epoch:25 step:23902 [D loss: 0.479482, acc.: 85.94%] [G loss: 0.949355]\n",
      "epoch:25 step:23903 [D loss: 0.764378, acc.: 50.00%] [G loss: 1.084618]\n",
      "epoch:25 step:23904 [D loss: 0.163221, acc.: 100.00%] [G loss: 1.289666]\n",
      "epoch:25 step:23905 [D loss: 0.330417, acc.: 93.75%] [G loss: 1.691914]\n",
      "epoch:25 step:23906 [D loss: 0.213185, acc.: 96.09%] [G loss: 1.329507]\n",
      "epoch:25 step:23907 [D loss: 1.042539, acc.: 53.12%] [G loss: 1.127178]\n",
      "epoch:25 step:23908 [D loss: 0.829624, acc.: 48.44%] [G loss: 0.982168]\n",
      "epoch:25 step:23909 [D loss: 0.825387, acc.: 39.84%] [G loss: 0.993213]\n",
      "epoch:25 step:23910 [D loss: 0.778993, acc.: 46.09%] [G loss: 0.930157]\n",
      "epoch:25 step:23911 [D loss: 0.754458, acc.: 50.00%] [G loss: 0.803224]\n",
      "epoch:25 step:23912 [D loss: 0.790633, acc.: 39.84%] [G loss: 0.722142]\n",
      "epoch:25 step:23913 [D loss: 0.878248, acc.: 33.59%] [G loss: 0.936249]\n",
      "epoch:25 step:23914 [D loss: 0.395538, acc.: 92.19%] [G loss: 1.183082]\n",
      "epoch:25 step:23915 [D loss: 0.302322, acc.: 96.88%] [G loss: 1.087458]\n",
      "epoch:25 step:23916 [D loss: 0.432726, acc.: 86.72%] [G loss: 1.103837]\n",
      "epoch:25 step:23917 [D loss: 0.684232, acc.: 57.81%] [G loss: 1.069319]\n",
      "epoch:25 step:23918 [D loss: 0.725993, acc.: 53.12%] [G loss: 1.035211]\n",
      "epoch:25 step:23919 [D loss: 0.943151, acc.: 46.88%] [G loss: 1.322838]\n",
      "epoch:25 step:23920 [D loss: 0.593861, acc.: 61.72%] [G loss: 1.185360]\n",
      "epoch:25 step:23921 [D loss: 0.755332, acc.: 50.00%] [G loss: 0.853081]\n",
      "epoch:25 step:23922 [D loss: 0.662190, acc.: 55.47%] [G loss: 1.092063]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23923 [D loss: 0.469934, acc.: 80.47%] [G loss: 0.946118]\n",
      "epoch:25 step:23924 [D loss: 0.304619, acc.: 96.09%] [G loss: 1.214105]\n",
      "epoch:25 step:23925 [D loss: 0.659272, acc.: 61.72%] [G loss: 1.298272]\n",
      "epoch:25 step:23926 [D loss: 0.766461, acc.: 41.41%] [G loss: 1.150509]\n",
      "epoch:25 step:23927 [D loss: 0.645178, acc.: 59.38%] [G loss: 1.169383]\n",
      "epoch:25 step:23928 [D loss: 0.297917, acc.: 86.72%] [G loss: 0.966298]\n",
      "epoch:25 step:23929 [D loss: 0.303078, acc.: 87.50%] [G loss: 1.288935]\n",
      "epoch:25 step:23930 [D loss: 0.334750, acc.: 91.41%] [G loss: 1.305344]\n",
      "epoch:25 step:23931 [D loss: 0.654203, acc.: 64.84%] [G loss: 1.040139]\n",
      "epoch:25 step:23932 [D loss: 0.458874, acc.: 78.91%] [G loss: 0.894567]\n",
      "epoch:25 step:23933 [D loss: 0.438368, acc.: 85.94%] [G loss: 1.279294]\n",
      "epoch:25 step:23934 [D loss: 0.660275, acc.: 58.59%] [G loss: 0.574931]\n",
      "epoch:25 step:23935 [D loss: 0.510369, acc.: 75.00%] [G loss: 1.395355]\n",
      "epoch:25 step:23936 [D loss: 0.516913, acc.: 72.66%] [G loss: 1.201229]\n",
      "epoch:25 step:23937 [D loss: 0.355469, acc.: 93.75%] [G loss: 1.491201]\n",
      "epoch:25 step:23938 [D loss: 0.341824, acc.: 92.97%] [G loss: 1.391372]\n",
      "epoch:25 step:23939 [D loss: 0.265157, acc.: 94.53%] [G loss: 1.712718]\n",
      "epoch:25 step:23940 [D loss: 0.198764, acc.: 97.66%] [G loss: 1.855865]\n",
      "epoch:25 step:23941 [D loss: 0.637910, acc.: 60.94%] [G loss: 1.526749]\n",
      "epoch:25 step:23942 [D loss: 0.340935, acc.: 89.06%] [G loss: 1.228843]\n",
      "epoch:25 step:23943 [D loss: 0.636993, acc.: 58.59%] [G loss: 1.464374]\n",
      "epoch:25 step:23944 [D loss: 0.591005, acc.: 66.41%] [G loss: 1.043023]\n",
      "epoch:25 step:23945 [D loss: 0.589938, acc.: 71.88%] [G loss: 1.263676]\n",
      "epoch:25 step:23946 [D loss: 0.822683, acc.: 46.88%] [G loss: 0.750247]\n",
      "epoch:25 step:23947 [D loss: 0.532030, acc.: 77.34%] [G loss: 1.320627]\n",
      "epoch:25 step:23948 [D loss: 0.617737, acc.: 67.19%] [G loss: 1.250818]\n",
      "epoch:25 step:23949 [D loss: 0.288457, acc.: 90.62%] [G loss: 1.216552]\n",
      "epoch:25 step:23950 [D loss: 0.522493, acc.: 77.34%] [G loss: 1.522012]\n",
      "epoch:25 step:23951 [D loss: 0.394555, acc.: 89.06%] [G loss: 1.316169]\n",
      "epoch:25 step:23952 [D loss: 0.333110, acc.: 92.97%] [G loss: 1.609085]\n",
      "epoch:25 step:23953 [D loss: 0.465064, acc.: 78.91%] [G loss: 1.647625]\n",
      "epoch:25 step:23954 [D loss: 0.374837, acc.: 89.84%] [G loss: 1.263740]\n",
      "epoch:25 step:23955 [D loss: 0.217213, acc.: 96.09%] [G loss: 1.482163]\n",
      "epoch:25 step:23956 [D loss: 0.626226, acc.: 65.62%] [G loss: 1.397865]\n",
      "epoch:25 step:23957 [D loss: 0.673890, acc.: 60.16%] [G loss: 1.234136]\n",
      "epoch:25 step:23958 [D loss: 0.656588, acc.: 64.06%] [G loss: 1.239165]\n",
      "epoch:25 step:23959 [D loss: 0.591070, acc.: 65.62%] [G loss: 1.293550]\n",
      "epoch:25 step:23960 [D loss: 0.358953, acc.: 85.94%] [G loss: 1.424505]\n",
      "epoch:25 step:23961 [D loss: 0.223615, acc.: 95.31%] [G loss: 1.470099]\n",
      "epoch:25 step:23962 [D loss: 0.193487, acc.: 97.66%] [G loss: 1.330001]\n",
      "epoch:25 step:23963 [D loss: 0.322122, acc.: 94.53%] [G loss: 1.305006]\n",
      "epoch:25 step:23964 [D loss: 0.160181, acc.: 99.22%] [G loss: 1.735361]\n",
      "epoch:25 step:23965 [D loss: 0.286106, acc.: 96.09%] [G loss: 1.565817]\n",
      "epoch:25 step:23966 [D loss: 0.270359, acc.: 96.88%] [G loss: 1.483022]\n",
      "epoch:25 step:23967 [D loss: 0.601144, acc.: 68.75%] [G loss: 1.672589]\n",
      "epoch:25 step:23968 [D loss: 0.248182, acc.: 88.28%] [G loss: 1.662581]\n",
      "epoch:25 step:23969 [D loss: 0.760346, acc.: 53.91%] [G loss: 1.377628]\n",
      "epoch:25 step:23970 [D loss: 0.478804, acc.: 78.91%] [G loss: 1.441707]\n",
      "epoch:25 step:23971 [D loss: 0.622948, acc.: 63.28%] [G loss: 1.251974]\n",
      "epoch:25 step:23972 [D loss: 0.548385, acc.: 73.44%] [G loss: 1.186288]\n",
      "epoch:25 step:23973 [D loss: 0.464968, acc.: 77.34%] [G loss: 1.494853]\n",
      "epoch:25 step:23974 [D loss: 0.414056, acc.: 87.50%] [G loss: 1.287016]\n",
      "epoch:25 step:23975 [D loss: 0.291202, acc.: 89.06%] [G loss: 1.390786]\n",
      "epoch:25 step:23976 [D loss: 0.788607, acc.: 53.12%] [G loss: 1.217693]\n",
      "epoch:25 step:23977 [D loss: 0.722923, acc.: 52.34%] [G loss: 1.395231]\n",
      "epoch:25 step:23978 [D loss: 0.720031, acc.: 54.69%] [G loss: 1.349747]\n",
      "epoch:25 step:23979 [D loss: 0.283946, acc.: 89.06%] [G loss: 0.515050]\n",
      "epoch:25 step:23980 [D loss: 0.493962, acc.: 75.78%] [G loss: 0.814616]\n",
      "epoch:25 step:23981 [D loss: 0.600729, acc.: 64.84%] [G loss: 1.958616]\n",
      "epoch:25 step:23982 [D loss: 0.423934, acc.: 82.81%] [G loss: 1.573283]\n",
      "epoch:25 step:23983 [D loss: 0.580246, acc.: 67.97%] [G loss: 1.195706]\n",
      "epoch:25 step:23984 [D loss: 0.159838, acc.: 95.31%] [G loss: 1.410743]\n",
      "epoch:25 step:23985 [D loss: 0.331477, acc.: 85.94%] [G loss: 1.386282]\n",
      "epoch:25 step:23986 [D loss: 0.394150, acc.: 75.00%] [G loss: 1.560749]\n",
      "epoch:25 step:23987 [D loss: 0.788810, acc.: 50.00%] [G loss: 1.573292]\n",
      "epoch:25 step:23988 [D loss: 0.824217, acc.: 47.66%] [G loss: 1.970964]\n",
      "epoch:25 step:23989 [D loss: 0.453707, acc.: 78.12%] [G loss: 2.112204]\n",
      "epoch:25 step:23990 [D loss: 0.282185, acc.: 90.62%] [G loss: 1.879913]\n",
      "epoch:25 step:23991 [D loss: 0.077197, acc.: 100.00%] [G loss: 2.172105]\n",
      "epoch:25 step:23992 [D loss: 0.091695, acc.: 100.00%] [G loss: 1.729143]\n",
      "epoch:25 step:23993 [D loss: 0.239885, acc.: 91.41%] [G loss: 2.528364]\n",
      "epoch:25 step:23994 [D loss: 0.719337, acc.: 59.38%] [G loss: 1.868527]\n",
      "epoch:25 step:23995 [D loss: 0.530114, acc.: 75.78%] [G loss: 1.478428]\n",
      "epoch:25 step:23996 [D loss: 0.569681, acc.: 67.19%] [G loss: 1.455106]\n",
      "epoch:25 step:23997 [D loss: 0.334512, acc.: 89.06%] [G loss: 1.423893]\n",
      "epoch:25 step:23998 [D loss: 0.217303, acc.: 96.09%] [G loss: 0.739841]\n",
      "epoch:25 step:23999 [D loss: 0.353110, acc.: 85.94%] [G loss: 2.278251]\n",
      "epoch:25 step:24000 [D loss: 0.206346, acc.: 98.44%] [G loss: 1.156822]\n",
      "##############\n",
      "[4.04805569 2.9402943  7.23021392 6.07183116 5.19053119 6.58405035\n",
      " 5.71761937 5.87167055 6.2424784  5.1198855 ]\n",
      "##########\n",
      "epoch:25 step:24001 [D loss: 0.275460, acc.: 88.28%] [G loss: 1.326496]\n",
      "epoch:25 step:24002 [D loss: 0.293880, acc.: 83.59%] [G loss: 2.286559]\n",
      "epoch:25 step:24003 [D loss: 0.083453, acc.: 99.22%] [G loss: 3.566436]\n",
      "epoch:25 step:24004 [D loss: 0.143931, acc.: 97.66%] [G loss: 1.818998]\n",
      "epoch:25 step:24005 [D loss: 0.866545, acc.: 57.81%] [G loss: 1.493731]\n",
      "epoch:25 step:24006 [D loss: 0.728232, acc.: 54.69%] [G loss: 0.911895]\n",
      "epoch:25 step:24007 [D loss: 1.347478, acc.: 28.91%] [G loss: 1.707496]\n",
      "epoch:25 step:24008 [D loss: 1.024101, acc.: 34.38%] [G loss: 1.978163]\n",
      "epoch:25 step:24009 [D loss: 0.855236, acc.: 51.56%] [G loss: 1.132646]\n",
      "epoch:25 step:24010 [D loss: 1.137718, acc.: 26.56%] [G loss: 1.283099]\n",
      "epoch:25 step:24011 [D loss: 0.576946, acc.: 67.19%] [G loss: 1.264771]\n",
      "epoch:25 step:24012 [D loss: 0.236547, acc.: 92.19%] [G loss: 0.902555]\n",
      "epoch:25 step:24013 [D loss: 0.263448, acc.: 91.41%] [G loss: 0.960408]\n",
      "epoch:25 step:24014 [D loss: 0.179340, acc.: 94.53%] [G loss: 1.484073]\n",
      "epoch:25 step:24015 [D loss: 0.569317, acc.: 71.88%] [G loss: 1.026904]\n",
      "epoch:25 step:24016 [D loss: 0.731354, acc.: 57.03%] [G loss: 1.251407]\n",
      "epoch:25 step:24017 [D loss: 1.263356, acc.: 40.62%] [G loss: 1.594738]\n",
      "epoch:25 step:24018 [D loss: 0.783770, acc.: 55.47%] [G loss: 1.672726]\n",
      "epoch:25 step:24019 [D loss: 0.786605, acc.: 50.00%] [G loss: 1.334795]\n",
      "epoch:25 step:24020 [D loss: 0.815796, acc.: 49.22%] [G loss: 1.287991]\n",
      "epoch:25 step:24021 [D loss: 0.758941, acc.: 48.44%] [G loss: 1.268558]\n",
      "epoch:25 step:24022 [D loss: 0.766427, acc.: 53.91%] [G loss: 1.206316]\n",
      "epoch:25 step:24023 [D loss: 0.573238, acc.: 70.31%] [G loss: 1.075933]\n",
      "epoch:25 step:24024 [D loss: 0.612177, acc.: 64.84%] [G loss: 1.501837]\n",
      "epoch:25 step:24025 [D loss: 0.455250, acc.: 75.00%] [G loss: 1.307123]\n",
      "epoch:25 step:24026 [D loss: 0.499595, acc.: 82.81%] [G loss: 1.085585]\n",
      "epoch:25 step:24027 [D loss: 0.478513, acc.: 78.91%] [G loss: 1.365813]\n",
      "epoch:25 step:24028 [D loss: 0.657125, acc.: 60.94%] [G loss: 1.192560]\n",
      "epoch:25 step:24029 [D loss: 0.199848, acc.: 93.75%] [G loss: 1.483828]\n",
      "epoch:25 step:24030 [D loss: 0.599397, acc.: 59.38%] [G loss: 1.368209]\n",
      "epoch:25 step:24031 [D loss: 0.600506, acc.: 67.19%] [G loss: 1.418797]\n",
      "epoch:25 step:24032 [D loss: 0.616787, acc.: 59.38%] [G loss: 1.271075]\n",
      "epoch:25 step:24033 [D loss: 0.528454, acc.: 67.97%] [G loss: 1.256268]\n",
      "epoch:25 step:24034 [D loss: 0.453935, acc.: 76.56%] [G loss: 1.342401]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:24035 [D loss: 0.699916, acc.: 52.34%] [G loss: 1.386344]\n",
      "epoch:25 step:24036 [D loss: 0.688571, acc.: 60.16%] [G loss: 1.389529]\n",
      "epoch:25 step:24037 [D loss: 0.677148, acc.: 55.47%] [G loss: 1.127260]\n",
      "epoch:25 step:24038 [D loss: 0.572572, acc.: 67.19%] [G loss: 1.101442]\n",
      "epoch:25 step:24039 [D loss: 0.790933, acc.: 42.97%] [G loss: 1.090462]\n",
      "epoch:25 step:24040 [D loss: 0.605679, acc.: 63.28%] [G loss: 0.959620]\n",
      "epoch:25 step:24041 [D loss: 0.641681, acc.: 66.41%] [G loss: 1.242611]\n",
      "epoch:25 step:24042 [D loss: 0.400376, acc.: 89.84%] [G loss: 1.346285]\n",
      "epoch:25 step:24043 [D loss: 0.751144, acc.: 51.56%] [G loss: 1.392426]\n",
      "epoch:25 step:24044 [D loss: 0.714052, acc.: 58.59%] [G loss: 1.011047]\n",
      "epoch:25 step:24045 [D loss: 0.603202, acc.: 63.28%] [G loss: 1.027909]\n",
      "epoch:25 step:24046 [D loss: 0.758372, acc.: 51.56%] [G loss: 1.165774]\n",
      "epoch:25 step:24047 [D loss: 0.390672, acc.: 86.72%] [G loss: 1.351501]\n",
      "epoch:25 step:24048 [D loss: 0.362929, acc.: 91.41%] [G loss: 1.172531]\n",
      "epoch:25 step:24049 [D loss: 0.283273, acc.: 95.31%] [G loss: 1.714626]\n",
      "epoch:25 step:24050 [D loss: 0.784492, acc.: 53.91%] [G loss: 1.064024]\n",
      "epoch:25 step:24051 [D loss: 0.441060, acc.: 87.50%] [G loss: 1.160148]\n",
      "epoch:25 step:24052 [D loss: 0.604340, acc.: 68.75%] [G loss: 1.088442]\n",
      "epoch:25 step:24053 [D loss: 0.590301, acc.: 64.06%] [G loss: 1.122029]\n",
      "epoch:25 step:24054 [D loss: 0.388963, acc.: 89.06%] [G loss: 1.006351]\n",
      "epoch:25 step:24055 [D loss: 0.306520, acc.: 93.75%] [G loss: 1.325245]\n",
      "epoch:25 step:24056 [D loss: 0.597863, acc.: 65.62%] [G loss: 1.179541]\n",
      "epoch:25 step:24057 [D loss: 0.298630, acc.: 85.16%] [G loss: 1.153337]\n",
      "epoch:25 step:24058 [D loss: 0.195445, acc.: 94.53%] [G loss: 1.558579]\n",
      "epoch:25 step:24059 [D loss: 0.176091, acc.: 96.88%] [G loss: 1.376422]\n",
      "epoch:25 step:24060 [D loss: 0.146753, acc.: 98.44%] [G loss: 1.954426]\n",
      "epoch:25 step:24061 [D loss: 0.339142, acc.: 92.19%] [G loss: 1.959437]\n",
      "epoch:25 step:24062 [D loss: 0.443239, acc.: 79.69%] [G loss: 1.449333]\n",
      "epoch:25 step:24063 [D loss: 0.471580, acc.: 78.12%] [G loss: 1.367110]\n",
      "epoch:25 step:24064 [D loss: 0.666089, acc.: 55.47%] [G loss: 1.145209]\n",
      "epoch:25 step:24065 [D loss: 0.998997, acc.: 37.50%] [G loss: 1.014756]\n",
      "epoch:25 step:24066 [D loss: 0.600333, acc.: 62.50%] [G loss: 0.999632]\n",
      "epoch:25 step:24067 [D loss: 0.839296, acc.: 42.97%] [G loss: 0.917153]\n",
      "epoch:25 step:24068 [D loss: 0.450150, acc.: 76.56%] [G loss: 1.043699]\n",
      "epoch:25 step:24069 [D loss: 0.202809, acc.: 95.31%] [G loss: 1.217976]\n",
      "epoch:25 step:24070 [D loss: 0.196199, acc.: 95.31%] [G loss: 1.345117]\n",
      "epoch:25 step:24071 [D loss: 0.192672, acc.: 92.97%] [G loss: 1.252580]\n",
      "epoch:25 step:24072 [D loss: 0.171339, acc.: 94.53%] [G loss: 1.152300]\n",
      "epoch:25 step:24073 [D loss: 0.141680, acc.: 100.00%] [G loss: 1.615397]\n",
      "epoch:25 step:24074 [D loss: 0.171614, acc.: 98.44%] [G loss: 1.495795]\n",
      "epoch:25 step:24075 [D loss: 0.320593, acc.: 81.25%] [G loss: 1.934740]\n",
      "epoch:25 step:24076 [D loss: 0.401379, acc.: 89.84%] [G loss: 1.836258]\n",
      "epoch:25 step:24077 [D loss: 0.689642, acc.: 63.28%] [G loss: 1.025183]\n",
      "epoch:25 step:24078 [D loss: 0.907993, acc.: 43.75%] [G loss: 0.380540]\n",
      "epoch:25 step:24079 [D loss: 0.745906, acc.: 46.88%] [G loss: 1.194271]\n",
      "epoch:25 step:24080 [D loss: 0.497546, acc.: 78.12%] [G loss: 0.865162]\n",
      "epoch:25 step:24081 [D loss: 0.643907, acc.: 63.28%] [G loss: 1.261207]\n",
      "epoch:25 step:24082 [D loss: 1.045460, acc.: 34.38%] [G loss: 0.794062]\n",
      "epoch:25 step:24083 [D loss: 0.691244, acc.: 53.12%] [G loss: 0.426012]\n",
      "epoch:25 step:24084 [D loss: 0.265864, acc.: 90.62%] [G loss: 0.730085]\n",
      "epoch:25 step:24085 [D loss: 0.200284, acc.: 99.22%] [G loss: 1.433736]\n",
      "epoch:25 step:24086 [D loss: 0.972399, acc.: 55.47%] [G loss: 1.344485]\n",
      "epoch:25 step:24087 [D loss: 0.782918, acc.: 52.34%] [G loss: 1.377718]\n",
      "epoch:25 step:24088 [D loss: 0.575505, acc.: 67.97%] [G loss: 0.943099]\n",
      "epoch:25 step:24089 [D loss: 0.521206, acc.: 75.00%] [G loss: 1.955935]\n",
      "epoch:25 step:24090 [D loss: 0.682378, acc.: 60.16%] [G loss: 1.913819]\n",
      "epoch:25 step:24091 [D loss: 0.906943, acc.: 47.66%] [G loss: 1.315497]\n",
      "epoch:25 step:24092 [D loss: 0.759264, acc.: 52.34%] [G loss: 1.631124]\n",
      "epoch:25 step:24093 [D loss: 0.826468, acc.: 47.66%] [G loss: 1.478723]\n",
      "epoch:25 step:24094 [D loss: 0.727528, acc.: 55.47%] [G loss: 1.499834]\n",
      "epoch:25 step:24095 [D loss: 0.703360, acc.: 57.81%] [G loss: 1.342482]\n",
      "epoch:25 step:24096 [D loss: 0.594304, acc.: 68.75%] [G loss: 1.552421]\n",
      "epoch:25 step:24097 [D loss: 0.658962, acc.: 62.50%] [G loss: 1.187895]\n",
      "epoch:25 step:24098 [D loss: 0.552001, acc.: 74.22%] [G loss: 1.245311]\n",
      "epoch:25 step:24099 [D loss: 0.552970, acc.: 66.41%] [G loss: 1.235494]\n",
      "epoch:25 step:24100 [D loss: 0.786659, acc.: 49.22%] [G loss: 1.206171]\n",
      "epoch:25 step:24101 [D loss: 0.626547, acc.: 64.06%] [G loss: 1.189265]\n",
      "epoch:25 step:24102 [D loss: 0.644964, acc.: 60.94%] [G loss: 1.126333]\n",
      "epoch:25 step:24103 [D loss: 0.808001, acc.: 44.53%] [G loss: 1.087345]\n",
      "epoch:25 step:24104 [D loss: 0.652939, acc.: 54.69%] [G loss: 1.045665]\n",
      "epoch:25 step:24105 [D loss: 0.709453, acc.: 56.25%] [G loss: 1.158496]\n",
      "epoch:25 step:24106 [D loss: 0.654215, acc.: 60.16%] [G loss: 1.191590]\n",
      "epoch:25 step:24107 [D loss: 0.417513, acc.: 88.28%] [G loss: 0.956247]\n",
      "epoch:25 step:24108 [D loss: 0.492653, acc.: 85.94%] [G loss: 1.287907]\n",
      "epoch:25 step:24109 [D loss: 0.413351, acc.: 85.16%] [G loss: 1.071607]\n",
      "epoch:25 step:24110 [D loss: 0.623935, acc.: 60.94%] [G loss: 0.878363]\n",
      "epoch:25 step:24111 [D loss: 0.332308, acc.: 94.53%] [G loss: 1.751049]\n",
      "epoch:25 step:24112 [D loss: 0.392823, acc.: 93.75%] [G loss: 3.092880]\n",
      "epoch:25 step:24113 [D loss: 0.614489, acc.: 64.84%] [G loss: 1.248682]\n",
      "epoch:25 step:24114 [D loss: 0.893461, acc.: 49.22%] [G loss: 0.939475]\n",
      "epoch:25 step:24115 [D loss: 0.834107, acc.: 35.94%] [G loss: 0.658038]\n",
      "epoch:25 step:24116 [D loss: 0.751451, acc.: 47.66%] [G loss: 1.114295]\n",
      "epoch:25 step:24117 [D loss: 0.623979, acc.: 62.50%] [G loss: 1.265807]\n",
      "epoch:25 step:24118 [D loss: 0.648847, acc.: 60.94%] [G loss: 1.035911]\n",
      "epoch:25 step:24119 [D loss: 0.533824, acc.: 78.91%] [G loss: 1.020733]\n",
      "epoch:25 step:24120 [D loss: 0.619995, acc.: 70.31%] [G loss: 1.019965]\n",
      "epoch:25 step:24121 [D loss: 0.308579, acc.: 89.84%] [G loss: 0.903533]\n",
      "epoch:25 step:24122 [D loss: 0.286887, acc.: 87.50%] [G loss: 1.270255]\n",
      "epoch:25 step:24123 [D loss: 0.315836, acc.: 90.62%] [G loss: 1.105902]\n",
      "epoch:25 step:24124 [D loss: 0.376585, acc.: 96.88%] [G loss: 1.346390]\n",
      "epoch:25 step:24125 [D loss: 0.192091, acc.: 96.09%] [G loss: 1.377477]\n",
      "epoch:25 step:24126 [D loss: 0.267723, acc.: 93.75%] [G loss: 1.332106]\n",
      "epoch:25 step:24127 [D loss: 0.301212, acc.: 98.44%] [G loss: 1.400018]\n",
      "epoch:25 step:24128 [D loss: 0.669071, acc.: 58.59%] [G loss: 1.454056]\n",
      "epoch:25 step:24129 [D loss: 0.356552, acc.: 97.66%] [G loss: 1.475521]\n",
      "epoch:25 step:24130 [D loss: 0.752884, acc.: 53.12%] [G loss: 1.473478]\n",
      "epoch:25 step:24131 [D loss: 0.291231, acc.: 89.06%] [G loss: 1.396083]\n",
      "epoch:25 step:24132 [D loss: 0.324593, acc.: 81.25%] [G loss: 1.435696]\n",
      "epoch:25 step:24133 [D loss: 0.145656, acc.: 97.66%] [G loss: 1.633217]\n",
      "epoch:25 step:24134 [D loss: 0.171308, acc.: 97.66%] [G loss: 1.532474]\n",
      "epoch:25 step:24135 [D loss: 0.682866, acc.: 65.62%] [G loss: 1.339269]\n",
      "epoch:25 step:24136 [D loss: 0.525139, acc.: 75.00%] [G loss: 1.246477]\n",
      "epoch:25 step:24137 [D loss: 0.671050, acc.: 58.59%] [G loss: 1.334569]\n",
      "epoch:25 step:24138 [D loss: 0.183245, acc.: 96.09%] [G loss: 1.060923]\n",
      "epoch:25 step:24139 [D loss: 0.258852, acc.: 89.84%] [G loss: 0.979398]\n",
      "epoch:25 step:24140 [D loss: 0.798519, acc.: 45.31%] [G loss: 1.370754]\n",
      "epoch:25 step:24141 [D loss: 0.926866, acc.: 41.41%] [G loss: 1.443650]\n",
      "epoch:25 step:24142 [D loss: 0.702098, acc.: 56.25%] [G loss: 0.788860]\n",
      "epoch:25 step:24143 [D loss: 0.624111, acc.: 62.50%] [G loss: 1.151837]\n",
      "epoch:25 step:24144 [D loss: 0.584721, acc.: 66.41%] [G loss: 1.328823]\n",
      "epoch:25 step:24145 [D loss: 0.571506, acc.: 72.66%] [G loss: 1.328224]\n",
      "epoch:25 step:24146 [D loss: 0.613876, acc.: 71.88%] [G loss: 1.143957]\n",
      "epoch:25 step:24147 [D loss: 0.500650, acc.: 83.59%] [G loss: 1.100394]\n",
      "epoch:25 step:24148 [D loss: 0.492395, acc.: 80.47%] [G loss: 0.780338]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:24149 [D loss: 0.458183, acc.: 85.94%] [G loss: 1.221788]\n",
      "epoch:25 step:24150 [D loss: 0.443192, acc.: 85.94%] [G loss: 1.117495]\n",
      "epoch:25 step:24151 [D loss: 0.466338, acc.: 81.25%] [G loss: 1.274793]\n",
      "epoch:25 step:24152 [D loss: 0.201747, acc.: 96.88%] [G loss: 1.188422]\n",
      "epoch:25 step:24153 [D loss: 0.193816, acc.: 96.09%] [G loss: 1.483195]\n",
      "epoch:25 step:24154 [D loss: 0.331818, acc.: 92.97%] [G loss: 1.507810]\n",
      "epoch:25 step:24155 [D loss: 0.147922, acc.: 98.44%] [G loss: 1.617244]\n",
      "epoch:25 step:24156 [D loss: 0.229571, acc.: 96.88%] [G loss: 1.770126]\n",
      "epoch:25 step:24157 [D loss: 0.220575, acc.: 99.22%] [G loss: 1.643671]\n",
      "epoch:25 step:24158 [D loss: 0.255214, acc.: 96.09%] [G loss: 1.641076]\n",
      "epoch:25 step:24159 [D loss: 0.764559, acc.: 54.69%] [G loss: 1.522845]\n",
      "epoch:25 step:24160 [D loss: 0.562596, acc.: 72.66%] [G loss: 1.517593]\n",
      "epoch:25 step:24161 [D loss: 0.644923, acc.: 63.28%] [G loss: 1.186486]\n",
      "epoch:25 step:24162 [D loss: 0.739610, acc.: 57.03%] [G loss: 1.293301]\n",
      "epoch:25 step:24163 [D loss: 0.728552, acc.: 55.47%] [G loss: 0.951909]\n",
      "epoch:25 step:24164 [D loss: 0.390321, acc.: 80.47%] [G loss: 1.191142]\n",
      "epoch:25 step:24165 [D loss: 0.540844, acc.: 75.00%] [G loss: 1.232773]\n",
      "epoch:25 step:24166 [D loss: 0.545276, acc.: 77.34%] [G loss: 1.267756]\n",
      "epoch:25 step:24167 [D loss: 0.360518, acc.: 90.62%] [G loss: 1.358392]\n",
      "epoch:25 step:24168 [D loss: 0.350319, acc.: 92.19%] [G loss: 1.245984]\n",
      "epoch:25 step:24169 [D loss: 0.612885, acc.: 67.19%] [G loss: 1.270877]\n",
      "epoch:25 step:24170 [D loss: 0.308741, acc.: 93.75%] [G loss: 0.583926]\n",
      "epoch:25 step:24171 [D loss: 0.236783, acc.: 96.09%] [G loss: 1.386504]\n",
      "epoch:25 step:24172 [D loss: 0.573284, acc.: 67.97%] [G loss: 1.401609]\n",
      "epoch:25 step:24173 [D loss: 0.725800, acc.: 50.78%] [G loss: 1.550784]\n",
      "epoch:25 step:24174 [D loss: 0.439158, acc.: 85.16%] [G loss: 1.313143]\n",
      "epoch:25 step:24175 [D loss: 0.317217, acc.: 94.53%] [G loss: 1.214098]\n",
      "epoch:25 step:24176 [D loss: 0.775206, acc.: 50.78%] [G loss: 0.933353]\n",
      "epoch:25 step:24177 [D loss: 0.810176, acc.: 48.44%] [G loss: 1.143274]\n",
      "epoch:25 step:24178 [D loss: 0.488983, acc.: 75.78%] [G loss: 1.278166]\n",
      "epoch:25 step:24179 [D loss: 0.254942, acc.: 91.41%] [G loss: 0.773772]\n",
      "epoch:25 step:24180 [D loss: 0.200985, acc.: 92.19%] [G loss: 1.362122]\n",
      "epoch:25 step:24181 [D loss: 0.147914, acc.: 99.22%] [G loss: 1.396024]\n",
      "epoch:25 step:24182 [D loss: 0.436457, acc.: 85.16%] [G loss: 1.699323]\n",
      "epoch:25 step:24183 [D loss: 0.552825, acc.: 66.41%] [G loss: 1.416466]\n",
      "epoch:25 step:24184 [D loss: 0.768539, acc.: 57.03%] [G loss: 0.907177]\n",
      "epoch:25 step:24185 [D loss: 1.271236, acc.: 25.00%] [G loss: 1.111834]\n",
      "epoch:25 step:24186 [D loss: 0.743216, acc.: 56.25%] [G loss: 1.226860]\n",
      "epoch:25 step:24187 [D loss: 0.405114, acc.: 82.03%] [G loss: 1.550700]\n",
      "epoch:25 step:24188 [D loss: 0.603011, acc.: 64.84%] [G loss: 1.422970]\n",
      "epoch:25 step:24189 [D loss: 0.172594, acc.: 97.66%] [G loss: 1.174860]\n",
      "epoch:25 step:24190 [D loss: 0.758703, acc.: 58.59%] [G loss: 1.407803]\n",
      "epoch:25 step:24191 [D loss: 0.666660, acc.: 62.50%] [G loss: 1.165894]\n",
      "epoch:25 step:24192 [D loss: 0.666042, acc.: 58.59%] [G loss: 0.880613]\n",
      "epoch:25 step:24193 [D loss: 0.506619, acc.: 64.06%] [G loss: 0.886650]\n",
      "epoch:25 step:24194 [D loss: 0.500739, acc.: 64.84%] [G loss: 1.283167]\n",
      "epoch:25 step:24195 [D loss: 0.644042, acc.: 64.84%] [G loss: 1.326979]\n",
      "epoch:25 step:24196 [D loss: 0.787162, acc.: 51.56%] [G loss: 1.234666]\n",
      "epoch:25 step:24197 [D loss: 0.788192, acc.: 49.22%] [G loss: 1.226550]\n",
      "epoch:25 step:24198 [D loss: 0.693902, acc.: 57.03%] [G loss: 1.250826]\n",
      "epoch:25 step:24199 [D loss: 0.243045, acc.: 93.75%] [G loss: 1.425324]\n",
      "epoch:25 step:24200 [D loss: 0.254596, acc.: 93.75%] [G loss: 1.096485]\n",
      "##############\n",
      "[3.76395411 2.69658141 6.4171254  5.57541133 4.28296464 6.20299567\n",
      " 5.37343735 5.49329624 5.72954864 5.20622646]\n",
      "##########\n",
      "epoch:25 step:24201 [D loss: 0.688321, acc.: 59.38%] [G loss: 1.234472]\n",
      "epoch:25 step:24202 [D loss: 0.560555, acc.: 73.44%] [G loss: 1.029727]\n",
      "epoch:25 step:24203 [D loss: 0.778368, acc.: 52.34%] [G loss: 1.218586]\n",
      "epoch:25 step:24204 [D loss: 0.654823, acc.: 57.81%] [G loss: 1.038559]\n",
      "epoch:25 step:24205 [D loss: 0.306969, acc.: 86.72%] [G loss: 1.276010]\n",
      "epoch:25 step:24206 [D loss: 0.201421, acc.: 94.53%] [G loss: 0.847922]\n",
      "epoch:25 step:24207 [D loss: 0.296566, acc.: 82.81%] [G loss: 0.836378]\n",
      "epoch:25 step:24208 [D loss: 0.247317, acc.: 96.09%] [G loss: 1.382535]\n",
      "epoch:25 step:24209 [D loss: 0.355681, acc.: 90.62%] [G loss: 1.197560]\n",
      "epoch:25 step:24210 [D loss: 0.455553, acc.: 82.81%] [G loss: 1.369353]\n",
      "epoch:25 step:24211 [D loss: 0.161198, acc.: 99.22%] [G loss: 1.462631]\n",
      "epoch:25 step:24212 [D loss: 0.752017, acc.: 55.47%] [G loss: 1.815235]\n",
      "epoch:25 step:24213 [D loss: 0.413647, acc.: 81.25%] [G loss: 1.171503]\n",
      "epoch:25 step:24214 [D loss: 0.853607, acc.: 42.97%] [G loss: 1.283651]\n",
      "epoch:25 step:24215 [D loss: 0.487026, acc.: 79.69%] [G loss: 1.337161]\n",
      "epoch:25 step:24216 [D loss: 0.182177, acc.: 95.31%] [G loss: 1.305888]\n",
      "epoch:25 step:24217 [D loss: 0.158333, acc.: 97.66%] [G loss: 1.543504]\n",
      "epoch:25 step:24218 [D loss: 0.203888, acc.: 96.88%] [G loss: 1.352114]\n",
      "epoch:25 step:24219 [D loss: 0.138768, acc.: 100.00%] [G loss: 1.667582]\n",
      "epoch:25 step:24220 [D loss: 0.171505, acc.: 99.22%] [G loss: 2.215241]\n",
      "epoch:25 step:24221 [D loss: 0.131915, acc.: 100.00%] [G loss: 1.730029]\n",
      "epoch:25 step:24222 [D loss: 0.540998, acc.: 69.53%] [G loss: 1.878306]\n",
      "epoch:25 step:24223 [D loss: 0.253826, acc.: 96.88%] [G loss: 1.749168]\n",
      "epoch:25 step:24224 [D loss: 0.604618, acc.: 67.19%] [G loss: 1.642751]\n",
      "epoch:25 step:24225 [D loss: 0.499233, acc.: 75.78%] [G loss: 1.607890]\n",
      "epoch:25 step:24226 [D loss: 0.523497, acc.: 75.00%] [G loss: 1.352297]\n",
      "epoch:25 step:24227 [D loss: 0.324367, acc.: 89.06%] [G loss: 1.354894]\n",
      "epoch:25 step:24228 [D loss: 0.701024, acc.: 60.16%] [G loss: 1.375118]\n",
      "epoch:25 step:24229 [D loss: 0.214299, acc.: 92.97%] [G loss: 1.023246]\n",
      "epoch:25 step:24230 [D loss: 0.160662, acc.: 98.44%] [G loss: 1.656881]\n",
      "epoch:25 step:24231 [D loss: 0.147846, acc.: 97.66%] [G loss: 1.485509]\n",
      "epoch:25 step:24232 [D loss: 0.854169, acc.: 51.56%] [G loss: 1.235484]\n",
      "epoch:25 step:24233 [D loss: 0.562725, acc.: 74.22%] [G loss: 1.356323]\n",
      "epoch:25 step:24234 [D loss: 0.505110, acc.: 79.69%] [G loss: 1.288573]\n",
      "epoch:25 step:24235 [D loss: 0.740657, acc.: 51.56%] [G loss: 1.156066]\n",
      "epoch:25 step:24236 [D loss: 0.578524, acc.: 74.22%] [G loss: 1.113949]\n",
      "epoch:25 step:24237 [D loss: 0.298077, acc.: 89.06%] [G loss: 1.255429]\n",
      "epoch:25 step:24238 [D loss: 0.547625, acc.: 74.22%] [G loss: 1.243270]\n",
      "epoch:25 step:24239 [D loss: 0.795044, acc.: 48.44%] [G loss: 1.311601]\n",
      "epoch:25 step:24240 [D loss: 0.216054, acc.: 95.31%] [G loss: 1.079806]\n",
      "epoch:25 step:24241 [D loss: 0.642998, acc.: 57.81%] [G loss: 1.241494]\n",
      "epoch:25 step:24242 [D loss: 0.350819, acc.: 94.53%] [G loss: 1.257402]\n",
      "epoch:25 step:24243 [D loss: 0.710249, acc.: 51.56%] [G loss: 0.828633]\n",
      "epoch:25 step:24244 [D loss: 0.488292, acc.: 88.28%] [G loss: 1.099002]\n",
      "epoch:25 step:24245 [D loss: 0.482042, acc.: 82.81%] [G loss: 1.097624]\n",
      "epoch:25 step:24246 [D loss: 0.251367, acc.: 90.62%] [G loss: 0.397431]\n",
      "epoch:25 step:24247 [D loss: 0.177223, acc.: 96.09%] [G loss: 0.569748]\n",
      "epoch:25 step:24248 [D loss: 0.706119, acc.: 54.69%] [G loss: 0.785174]\n",
      "epoch:25 step:24249 [D loss: 0.669430, acc.: 60.94%] [G loss: 0.542099]\n",
      "epoch:25 step:24250 [D loss: 0.880199, acc.: 39.84%] [G loss: 0.960755]\n",
      "epoch:25 step:24251 [D loss: 0.906942, acc.: 47.66%] [G loss: 0.796344]\n",
      "epoch:25 step:24252 [D loss: 0.544324, acc.: 73.44%] [G loss: 1.294086]\n",
      "epoch:25 step:24253 [D loss: 1.482309, acc.: 24.22%] [G loss: 1.320549]\n",
      "epoch:25 step:24254 [D loss: 0.693788, acc.: 59.38%] [G loss: 1.313580]\n",
      "epoch:25 step:24255 [D loss: 0.906197, acc.: 43.75%] [G loss: 1.239419]\n",
      "epoch:25 step:24256 [D loss: 0.465754, acc.: 82.03%] [G loss: 0.970120]\n",
      "epoch:25 step:24257 [D loss: 0.381216, acc.: 84.38%] [G loss: 1.809977]\n",
      "epoch:25 step:24258 [D loss: 0.481440, acc.: 78.12%] [G loss: 1.129779]\n",
      "epoch:25 step:24259 [D loss: 0.557863, acc.: 72.66%] [G loss: 1.949096]\n",
      "epoch:25 step:24260 [D loss: 0.760436, acc.: 53.91%] [G loss: 1.144961]\n",
      "epoch:25 step:24261 [D loss: 1.041871, acc.: 28.91%] [G loss: 1.298782]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:24262 [D loss: 0.904407, acc.: 37.50%] [G loss: 1.636412]\n",
      "epoch:25 step:24263 [D loss: 0.538634, acc.: 75.00%] [G loss: 1.932983]\n",
      "epoch:25 step:24264 [D loss: 0.781860, acc.: 54.69%] [G loss: 1.830949]\n",
      "epoch:25 step:24265 [D loss: 0.854083, acc.: 49.22%] [G loss: 1.667114]\n",
      "epoch:25 step:24266 [D loss: 0.685773, acc.: 57.03%] [G loss: 1.225368]\n",
      "epoch:25 step:24267 [D loss: 0.567963, acc.: 67.19%] [G loss: 1.148184]\n",
      "epoch:25 step:24268 [D loss: 0.253533, acc.: 91.41%] [G loss: 1.502945]\n",
      "epoch:25 step:24269 [D loss: 0.204543, acc.: 93.75%] [G loss: 1.271130]\n",
      "epoch:25 step:24270 [D loss: 0.171689, acc.: 93.75%] [G loss: 1.803181]\n",
      "epoch:25 step:24271 [D loss: 0.523184, acc.: 75.00%] [G loss: 1.539860]\n",
      "epoch:25 step:24272 [D loss: 0.928724, acc.: 47.66%] [G loss: 1.270513]\n",
      "epoch:25 step:24273 [D loss: 1.022872, acc.: 38.28%] [G loss: 1.179533]\n",
      "epoch:25 step:24274 [D loss: 0.656093, acc.: 61.72%] [G loss: 1.197997]\n",
      "epoch:25 step:24275 [D loss: 0.822122, acc.: 46.88%] [G loss: 0.825409]\n",
      "epoch:25 step:24276 [D loss: 0.736402, acc.: 59.38%] [G loss: 0.967170]\n",
      "epoch:25 step:24277 [D loss: 0.787435, acc.: 50.00%] [G loss: 0.873310]\n",
      "epoch:25 step:24278 [D loss: 0.623288, acc.: 63.28%] [G loss: 0.970418]\n",
      "epoch:25 step:24279 [D loss: 0.649562, acc.: 58.59%] [G loss: 1.095442]\n",
      "epoch:25 step:24280 [D loss: 0.634787, acc.: 64.84%] [G loss: 1.097111]\n",
      "epoch:25 step:24281 [D loss: 0.628536, acc.: 64.84%] [G loss: 0.834424]\n",
      "epoch:25 step:24282 [D loss: 0.804837, acc.: 46.88%] [G loss: 0.940929]\n",
      "epoch:25 step:24283 [D loss: 0.227393, acc.: 93.75%] [G loss: 1.043272]\n",
      "epoch:25 step:24284 [D loss: 0.259297, acc.: 88.28%] [G loss: 1.249295]\n",
      "epoch:25 step:24285 [D loss: 0.201760, acc.: 97.66%] [G loss: 1.526836]\n",
      "epoch:25 step:24286 [D loss: 0.787578, acc.: 48.44%] [G loss: 1.202082]\n",
      "epoch:25 step:24287 [D loss: 0.634585, acc.: 58.59%] [G loss: 1.297229]\n",
      "epoch:25 step:24288 [D loss: 0.291160, acc.: 94.53%] [G loss: 1.206367]\n",
      "epoch:25 step:24289 [D loss: 0.379792, acc.: 91.41%] [G loss: 1.400117]\n",
      "epoch:25 step:24290 [D loss: 0.728452, acc.: 57.03%] [G loss: 1.105664]\n",
      "epoch:25 step:24291 [D loss: 0.608563, acc.: 64.06%] [G loss: 1.077375]\n",
      "epoch:25 step:24292 [D loss: 0.652113, acc.: 68.75%] [G loss: 1.158733]\n",
      "epoch:25 step:24293 [D loss: 0.443577, acc.: 82.03%] [G loss: 1.136789]\n",
      "epoch:25 step:24294 [D loss: 0.553798, acc.: 74.22%] [G loss: 1.127819]\n",
      "epoch:25 step:24295 [D loss: 0.343663, acc.: 85.94%] [G loss: 1.046938]\n",
      "epoch:25 step:24296 [D loss: 0.539216, acc.: 79.69%] [G loss: 1.166983]\n",
      "epoch:25 step:24297 [D loss: 1.149136, acc.: 17.97%] [G loss: 0.919711]\n",
      "epoch:25 step:24298 [D loss: 0.640221, acc.: 59.38%] [G loss: 1.182765]\n",
      "epoch:25 step:24299 [D loss: 0.514431, acc.: 82.03%] [G loss: 0.902466]\n",
      "epoch:25 step:24300 [D loss: 0.884614, acc.: 31.25%] [G loss: 1.213527]\n",
      "epoch:25 step:24301 [D loss: 0.285022, acc.: 94.53%] [G loss: 0.997970]\n",
      "epoch:25 step:24302 [D loss: 0.234474, acc.: 92.19%] [G loss: 0.740702]\n",
      "epoch:25 step:24303 [D loss: 0.362169, acc.: 75.00%] [G loss: 1.667190]\n",
      "epoch:25 step:24304 [D loss: 0.643622, acc.: 60.16%] [G loss: 1.820414]\n",
      "epoch:25 step:24305 [D loss: 0.894943, acc.: 41.41%] [G loss: 1.284326]\n",
      "epoch:25 step:24306 [D loss: 0.708139, acc.: 53.12%] [G loss: 1.200067]\n",
      "epoch:25 step:24307 [D loss: 0.897570, acc.: 50.00%] [G loss: 0.948721]\n",
      "epoch:25 step:24308 [D loss: 0.801134, acc.: 54.69%] [G loss: 0.817435]\n",
      "epoch:25 step:24309 [D loss: 0.714773, acc.: 50.00%] [G loss: 1.139994]\n",
      "epoch:25 step:24310 [D loss: 0.713688, acc.: 51.56%] [G loss: 0.942159]\n",
      "epoch:25 step:24311 [D loss: 0.421117, acc.: 88.28%] [G loss: 1.537808]\n",
      "epoch:25 step:24312 [D loss: 0.268894, acc.: 99.22%] [G loss: 1.179068]\n",
      "epoch:25 step:24313 [D loss: 0.748267, acc.: 52.34%] [G loss: 0.978859]\n",
      "epoch:25 step:24314 [D loss: 0.471149, acc.: 68.75%] [G loss: 1.230185]\n",
      "epoch:25 step:24315 [D loss: 0.593812, acc.: 67.97%] [G loss: 1.455519]\n",
      "epoch:25 step:24316 [D loss: 0.702067, acc.: 54.69%] [G loss: 1.345672]\n",
      "epoch:25 step:24317 [D loss: 0.761155, acc.: 51.56%] [G loss: 1.195788]\n",
      "epoch:25 step:24318 [D loss: 0.656320, acc.: 64.06%] [G loss: 1.159520]\n",
      "epoch:25 step:24319 [D loss: 0.571340, acc.: 71.09%] [G loss: 1.112598]\n",
      "epoch:25 step:24320 [D loss: 0.601236, acc.: 72.66%] [G loss: 1.049624]\n",
      "epoch:25 step:24321 [D loss: 0.545244, acc.: 72.66%] [G loss: 0.711362]\n",
      "epoch:25 step:24322 [D loss: 0.613060, acc.: 71.09%] [G loss: 0.980314]\n",
      "epoch:25 step:24323 [D loss: 0.340077, acc.: 85.94%] [G loss: 0.925993]\n",
      "epoch:25 step:24324 [D loss: 0.279626, acc.: 86.72%] [G loss: 1.070790]\n",
      "epoch:25 step:24325 [D loss: 0.224542, acc.: 92.19%] [G loss: 1.166497]\n",
      "epoch:25 step:24326 [D loss: 0.537528, acc.: 74.22%] [G loss: 1.456085]\n",
      "epoch:25 step:24327 [D loss: 0.841932, acc.: 41.41%] [G loss: 0.955965]\n",
      "epoch:25 step:24328 [D loss: 0.650365, acc.: 64.06%] [G loss: 1.164922]\n",
      "epoch:25 step:24329 [D loss: 0.408535, acc.: 89.84%] [G loss: 1.215022]\n",
      "epoch:25 step:24330 [D loss: 0.347698, acc.: 87.50%] [G loss: 1.500528]\n",
      "epoch:25 step:24331 [D loss: 0.274867, acc.: 95.31%] [G loss: 1.355864]\n",
      "epoch:25 step:24332 [D loss: 0.647667, acc.: 62.50%] [G loss: 0.957351]\n",
      "epoch:25 step:24333 [D loss: 0.767482, acc.: 52.34%] [G loss: 1.359155]\n",
      "epoch:25 step:24334 [D loss: 0.462124, acc.: 85.94%] [G loss: 0.812766]\n",
      "epoch:25 step:24335 [D loss: 0.326010, acc.: 96.09%] [G loss: 1.233653]\n",
      "epoch:25 step:24336 [D loss: 0.376846, acc.: 92.19%] [G loss: 1.030903]\n",
      "epoch:25 step:24337 [D loss: 0.203453, acc.: 96.09%] [G loss: 1.145370]\n",
      "epoch:25 step:24338 [D loss: 1.135457, acc.: 13.28%] [G loss: 1.062562]\n",
      "epoch:25 step:24339 [D loss: 0.658304, acc.: 58.59%] [G loss: 1.287592]\n",
      "epoch:25 step:24340 [D loss: 2.632919, acc.: 10.16%] [G loss: 1.622016]\n",
      "epoch:25 step:24341 [D loss: 0.248138, acc.: 92.19%] [G loss: 6.004571]\n",
      "epoch:25 step:24342 [D loss: 0.109114, acc.: 99.22%] [G loss: 2.355536]\n",
      "epoch:25 step:24343 [D loss: 0.511888, acc.: 73.44%] [G loss: 3.156411]\n",
      "epoch:25 step:24344 [D loss: 1.081920, acc.: 46.09%] [G loss: 1.193514]\n",
      "epoch:25 step:24345 [D loss: 0.131505, acc.: 94.53%] [G loss: 2.121493]\n",
      "epoch:25 step:24346 [D loss: 0.277611, acc.: 87.50%] [G loss: 2.663794]\n",
      "epoch:25 step:24347 [D loss: 0.396649, acc.: 88.28%] [G loss: 1.631787]\n",
      "epoch:25 step:24348 [D loss: 0.536982, acc.: 70.31%] [G loss: 1.486892]\n",
      "epoch:25 step:24349 [D loss: 0.584707, acc.: 71.88%] [G loss: 1.259047]\n",
      "epoch:25 step:24350 [D loss: 0.666468, acc.: 58.59%] [G loss: 0.951940]\n",
      "epoch:25 step:24351 [D loss: 0.933400, acc.: 45.31%] [G loss: 1.222669]\n",
      "epoch:25 step:24352 [D loss: 1.197927, acc.: 35.94%] [G loss: 0.583905]\n",
      "epoch:25 step:24353 [D loss: 0.437121, acc.: 76.56%] [G loss: 0.874525]\n",
      "epoch:25 step:24354 [D loss: 0.261791, acc.: 89.06%] [G loss: 0.910638]\n",
      "epoch:25 step:24355 [D loss: 0.287871, acc.: 88.28%] [G loss: 0.861101]\n",
      "epoch:25 step:24356 [D loss: 0.308453, acc.: 90.62%] [G loss: 1.218239]\n",
      "epoch:25 step:24357 [D loss: 0.739230, acc.: 57.03%] [G loss: 1.052024]\n",
      "epoch:25 step:24358 [D loss: 0.690302, acc.: 56.25%] [G loss: 0.974481]\n",
      "epoch:25 step:24359 [D loss: 0.600594, acc.: 67.97%] [G loss: 1.140581]\n",
      "epoch:25 step:24360 [D loss: 0.787199, acc.: 46.09%] [G loss: 0.951464]\n",
      "epoch:25 step:24361 [D loss: 0.567467, acc.: 71.09%] [G loss: 1.067488]\n",
      "epoch:25 step:24362 [D loss: 0.276915, acc.: 89.84%] [G loss: 1.457441]\n",
      "epoch:26 step:24363 [D loss: 0.787185, acc.: 46.88%] [G loss: 1.071735]\n",
      "epoch:26 step:24364 [D loss: 0.839672, acc.: 40.62%] [G loss: 0.912786]\n",
      "epoch:26 step:24365 [D loss: 0.837184, acc.: 42.97%] [G loss: 0.806893]\n",
      "epoch:26 step:24366 [D loss: 0.732564, acc.: 50.00%] [G loss: 0.868499]\n",
      "epoch:26 step:24367 [D loss: 0.695937, acc.: 57.81%] [G loss: 1.024644]\n",
      "epoch:26 step:24368 [D loss: 0.678633, acc.: 60.16%] [G loss: 0.974808]\n",
      "epoch:26 step:24369 [D loss: 0.718233, acc.: 57.81%] [G loss: 0.939108]\n",
      "epoch:26 step:24370 [D loss: 0.623606, acc.: 68.75%] [G loss: 1.068710]\n",
      "epoch:26 step:24371 [D loss: 0.483591, acc.: 84.38%] [G loss: 1.061263]\n",
      "epoch:26 step:24372 [D loss: 0.463252, acc.: 82.03%] [G loss: 0.935492]\n",
      "epoch:26 step:24373 [D loss: 0.513904, acc.: 78.91%] [G loss: 1.117887]\n",
      "epoch:26 step:24374 [D loss: 0.420970, acc.: 84.38%] [G loss: 1.079365]\n",
      "epoch:26 step:24375 [D loss: 0.418007, acc.: 83.59%] [G loss: 1.209554]\n",
      "epoch:26 step:24376 [D loss: 0.375584, acc.: 90.62%] [G loss: 1.250042]\n",
      "epoch:26 step:24377 [D loss: 0.252058, acc.: 95.31%] [G loss: 1.174579]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24378 [D loss: 0.265354, acc.: 97.66%] [G loss: 1.374054]\n",
      "epoch:26 step:24379 [D loss: 0.406898, acc.: 93.75%] [G loss: 1.361050]\n",
      "epoch:26 step:24380 [D loss: 0.321215, acc.: 92.97%] [G loss: 1.442172]\n",
      "epoch:26 step:24381 [D loss: 0.503965, acc.: 82.81%] [G loss: 1.357977]\n",
      "epoch:26 step:24382 [D loss: 0.801751, acc.: 46.09%] [G loss: 1.371515]\n",
      "epoch:26 step:24383 [D loss: 0.609497, acc.: 64.84%] [G loss: 0.751645]\n",
      "epoch:26 step:24384 [D loss: 0.678972, acc.: 63.28%] [G loss: 1.258386]\n",
      "epoch:26 step:24385 [D loss: 0.290224, acc.: 96.09%] [G loss: 0.740618]\n",
      "epoch:26 step:24386 [D loss: 0.272709, acc.: 95.31%] [G loss: 1.049460]\n",
      "epoch:26 step:24387 [D loss: 0.282363, acc.: 89.06%] [G loss: 1.268024]\n",
      "epoch:26 step:24388 [D loss: 0.985943, acc.: 28.91%] [G loss: 1.207289]\n",
      "epoch:26 step:24389 [D loss: 0.338014, acc.: 92.97%] [G loss: 1.611522]\n",
      "epoch:26 step:24390 [D loss: 0.743216, acc.: 57.03%] [G loss: 1.442506]\n",
      "epoch:26 step:24391 [D loss: 0.769307, acc.: 52.34%] [G loss: 1.186178]\n",
      "epoch:26 step:24392 [D loss: 0.796242, acc.: 44.53%] [G loss: 0.952744]\n",
      "epoch:26 step:24393 [D loss: 0.508423, acc.: 77.34%] [G loss: 0.795796]\n",
      "epoch:26 step:24394 [D loss: 0.334904, acc.: 92.97%] [G loss: 1.064256]\n",
      "epoch:26 step:24395 [D loss: 0.378611, acc.: 90.62%] [G loss: 1.098710]\n",
      "epoch:26 step:24396 [D loss: 0.356059, acc.: 92.97%] [G loss: 1.236670]\n",
      "epoch:26 step:24397 [D loss: 0.318912, acc.: 97.66%] [G loss: 1.181859]\n",
      "epoch:26 step:24398 [D loss: 0.299989, acc.: 88.28%] [G loss: 1.139929]\n",
      "epoch:26 step:24399 [D loss: 0.668330, acc.: 65.62%] [G loss: 1.207923]\n",
      "epoch:26 step:24400 [D loss: 0.274086, acc.: 97.66%] [G loss: 1.381875]\n",
      "##############\n",
      "[3.80688125 2.63120955 6.69668055 5.9974436  4.36332994 6.21485397\n",
      " 5.56624984 5.57451491 6.29589549 5.22642936]\n",
      "##########\n",
      "epoch:26 step:24401 [D loss: 0.389964, acc.: 85.16%] [G loss: 1.193917]\n",
      "epoch:26 step:24402 [D loss: 0.225338, acc.: 97.66%] [G loss: 1.191704]\n",
      "epoch:26 step:24403 [D loss: 1.027412, acc.: 28.91%] [G loss: 0.822236]\n",
      "epoch:26 step:24404 [D loss: 0.639367, acc.: 64.84%] [G loss: 1.301629]\n",
      "epoch:26 step:24405 [D loss: 0.614982, acc.: 67.19%] [G loss: 1.082383]\n",
      "epoch:26 step:24406 [D loss: 0.680770, acc.: 59.38%] [G loss: 0.803528]\n",
      "epoch:26 step:24407 [D loss: 0.715270, acc.: 53.91%] [G loss: 1.099456]\n",
      "epoch:26 step:24408 [D loss: 0.638208, acc.: 67.19%] [G loss: 1.064688]\n",
      "epoch:26 step:24409 [D loss: 0.740513, acc.: 53.91%] [G loss: 0.571429]\n",
      "epoch:26 step:24410 [D loss: 0.780212, acc.: 47.66%] [G loss: 1.136334]\n",
      "epoch:26 step:24411 [D loss: 0.713011, acc.: 54.69%] [G loss: 1.137938]\n",
      "epoch:26 step:24412 [D loss: 0.590475, acc.: 71.09%] [G loss: 1.173006]\n",
      "epoch:26 step:24413 [D loss: 0.348484, acc.: 92.19%] [G loss: 1.088252]\n",
      "epoch:26 step:24414 [D loss: 0.540447, acc.: 75.78%] [G loss: 1.128248]\n",
      "epoch:26 step:24415 [D loss: 0.531352, acc.: 76.56%] [G loss: 1.275473]\n",
      "epoch:26 step:24416 [D loss: 0.749942, acc.: 42.19%] [G loss: 1.099569]\n",
      "epoch:26 step:24417 [D loss: 0.704740, acc.: 53.91%] [G loss: 0.872953]\n",
      "epoch:26 step:24418 [D loss: 0.704376, acc.: 53.91%] [G loss: 0.793558]\n",
      "epoch:26 step:24419 [D loss: 0.248332, acc.: 92.97%] [G loss: 1.435584]\n",
      "epoch:26 step:24420 [D loss: 0.213674, acc.: 98.44%] [G loss: 1.364862]\n",
      "epoch:26 step:24421 [D loss: 0.275784, acc.: 94.53%] [G loss: 1.360558]\n",
      "epoch:26 step:24422 [D loss: 0.309316, acc.: 94.53%] [G loss: 1.216443]\n",
      "epoch:26 step:24423 [D loss: 0.925632, acc.: 26.56%] [G loss: 1.349562]\n",
      "epoch:26 step:24424 [D loss: 1.130370, acc.: 30.47%] [G loss: 1.222707]\n",
      "epoch:26 step:24425 [D loss: 0.507642, acc.: 81.25%] [G loss: 1.147745]\n",
      "epoch:26 step:24426 [D loss: 0.975592, acc.: 32.81%] [G loss: 1.530348]\n",
      "epoch:26 step:24427 [D loss: 1.851168, acc.: 10.94%] [G loss: 1.111268]\n",
      "epoch:26 step:24428 [D loss: 0.675672, acc.: 64.06%] [G loss: 1.484351]\n",
      "epoch:26 step:24429 [D loss: 0.727251, acc.: 56.25%] [G loss: 1.162869]\n",
      "epoch:26 step:24430 [D loss: 0.703893, acc.: 50.00%] [G loss: 1.091858]\n",
      "epoch:26 step:24431 [D loss: 0.559189, acc.: 74.22%] [G loss: 1.123873]\n",
      "epoch:26 step:24432 [D loss: 0.707370, acc.: 57.81%] [G loss: 1.073004]\n",
      "epoch:26 step:24433 [D loss: 0.245602, acc.: 97.66%] [G loss: 1.115794]\n",
      "epoch:26 step:24434 [D loss: 0.322332, acc.: 96.09%] [G loss: 1.131336]\n",
      "epoch:26 step:24435 [D loss: 0.306939, acc.: 92.97%] [G loss: 1.233277]\n",
      "epoch:26 step:24436 [D loss: 0.651762, acc.: 60.16%] [G loss: 1.117087]\n",
      "epoch:26 step:24437 [D loss: 0.442855, acc.: 72.66%] [G loss: 0.983121]\n",
      "epoch:26 step:24438 [D loss: 0.253042, acc.: 96.09%] [G loss: 1.389133]\n",
      "epoch:26 step:24439 [D loss: 0.352890, acc.: 89.84%] [G loss: 1.360269]\n",
      "epoch:26 step:24440 [D loss: 0.890008, acc.: 40.62%] [G loss: 1.405112]\n",
      "epoch:26 step:24441 [D loss: 0.750297, acc.: 57.03%] [G loss: 1.239676]\n",
      "epoch:26 step:24442 [D loss: 0.653800, acc.: 60.94%] [G loss: 1.201591]\n",
      "epoch:26 step:24443 [D loss: 0.489743, acc.: 78.91%] [G loss: 1.116214]\n",
      "epoch:26 step:24444 [D loss: 0.441238, acc.: 85.16%] [G loss: 1.341320]\n",
      "epoch:26 step:24445 [D loss: 0.324740, acc.: 90.62%] [G loss: 1.247118]\n",
      "epoch:26 step:24446 [D loss: 0.620766, acc.: 60.16%] [G loss: 1.457604]\n",
      "epoch:26 step:24447 [D loss: 0.815258, acc.: 43.75%] [G loss: 1.453017]\n",
      "epoch:26 step:24448 [D loss: 0.691251, acc.: 63.28%] [G loss: 1.591354]\n",
      "epoch:26 step:24449 [D loss: 0.311327, acc.: 96.88%] [G loss: 1.599918]\n",
      "epoch:26 step:24450 [D loss: 0.410169, acc.: 89.84%] [G loss: 1.532455]\n",
      "epoch:26 step:24451 [D loss: 0.333424, acc.: 93.75%] [G loss: 1.016212]\n",
      "epoch:26 step:24452 [D loss: 0.338118, acc.: 97.66%] [G loss: 1.649844]\n",
      "epoch:26 step:24453 [D loss: 0.539770, acc.: 76.56%] [G loss: 1.319292]\n",
      "epoch:26 step:24454 [D loss: 0.164509, acc.: 99.22%] [G loss: 1.756138]\n",
      "epoch:26 step:24455 [D loss: 0.241706, acc.: 96.88%] [G loss: 1.795199]\n",
      "epoch:26 step:24456 [D loss: 0.277804, acc.: 94.53%] [G loss: 1.202588]\n",
      "epoch:26 step:24457 [D loss: 0.654275, acc.: 61.72%] [G loss: 1.505465]\n",
      "epoch:26 step:24458 [D loss: 0.352535, acc.: 91.41%] [G loss: 0.852745]\n",
      "epoch:26 step:24459 [D loss: 0.472855, acc.: 80.47%] [G loss: 0.980184]\n",
      "epoch:26 step:24460 [D loss: 0.911594, acc.: 45.31%] [G loss: 1.013067]\n",
      "epoch:26 step:24461 [D loss: 0.806208, acc.: 44.53%] [G loss: 0.825112]\n",
      "epoch:26 step:24462 [D loss: 0.882897, acc.: 34.38%] [G loss: 1.243593]\n",
      "epoch:26 step:24463 [D loss: 0.393914, acc.: 85.16%] [G loss: 1.254488]\n",
      "epoch:26 step:24464 [D loss: 0.664381, acc.: 60.94%] [G loss: 1.022916]\n",
      "epoch:26 step:24465 [D loss: 0.981321, acc.: 21.09%] [G loss: 1.072515]\n",
      "epoch:26 step:24466 [D loss: 0.644856, acc.: 62.50%] [G loss: 0.937955]\n",
      "epoch:26 step:24467 [D loss: 0.822508, acc.: 46.09%] [G loss: 0.959049]\n",
      "epoch:26 step:24468 [D loss: 1.011492, acc.: 30.47%] [G loss: 1.186939]\n",
      "epoch:26 step:24469 [D loss: 1.155548, acc.: 27.34%] [G loss: 0.958399]\n",
      "epoch:26 step:24470 [D loss: 0.938406, acc.: 29.69%] [G loss: 1.021782]\n",
      "epoch:26 step:24471 [D loss: 0.712412, acc.: 53.12%] [G loss: 0.823839]\n",
      "epoch:26 step:24472 [D loss: 0.785988, acc.: 41.41%] [G loss: 0.946742]\n",
      "epoch:26 step:24473 [D loss: 0.469260, acc.: 80.47%] [G loss: 1.156516]\n",
      "epoch:26 step:24474 [D loss: 0.531237, acc.: 79.69%] [G loss: 1.108400]\n",
      "epoch:26 step:24475 [D loss: 0.454098, acc.: 85.16%] [G loss: 1.184929]\n",
      "epoch:26 step:24476 [D loss: 0.487178, acc.: 69.53%] [G loss: 0.995814]\n",
      "epoch:26 step:24477 [D loss: 0.390190, acc.: 93.75%] [G loss: 0.507536]\n",
      "epoch:26 step:24478 [D loss: 0.705253, acc.: 56.25%] [G loss: 1.134951]\n",
      "epoch:26 step:24479 [D loss: 0.682089, acc.: 52.34%] [G loss: 1.075809]\n",
      "epoch:26 step:24480 [D loss: 0.514223, acc.: 75.78%] [G loss: 1.191288]\n",
      "epoch:26 step:24481 [D loss: 0.233744, acc.: 97.66%] [G loss: 1.286169]\n",
      "epoch:26 step:24482 [D loss: 0.324630, acc.: 96.09%] [G loss: 1.007451]\n",
      "epoch:26 step:24483 [D loss: 0.291230, acc.: 90.62%] [G loss: 0.942702]\n",
      "epoch:26 step:24484 [D loss: 0.253968, acc.: 90.62%] [G loss: 1.174318]\n",
      "epoch:26 step:24485 [D loss: 0.631392, acc.: 64.84%] [G loss: 1.180427]\n",
      "epoch:26 step:24486 [D loss: 1.042006, acc.: 21.09%] [G loss: 0.936908]\n",
      "epoch:26 step:24487 [D loss: 0.730764, acc.: 52.34%] [G loss: 0.905854]\n",
      "epoch:26 step:24488 [D loss: 0.773598, acc.: 51.56%] [G loss: 1.164240]\n",
      "epoch:26 step:24489 [D loss: 0.823764, acc.: 43.75%] [G loss: 1.164263]\n",
      "epoch:26 step:24490 [D loss: 0.705331, acc.: 53.91%] [G loss: 1.073113]\n",
      "epoch:26 step:24491 [D loss: 0.594332, acc.: 65.62%] [G loss: 1.191003]\n",
      "epoch:26 step:24492 [D loss: 0.419817, acc.: 83.59%] [G loss: 1.169092]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24493 [D loss: 0.588639, acc.: 67.19%] [G loss: 0.278710]\n",
      "epoch:26 step:24494 [D loss: 0.527272, acc.: 75.78%] [G loss: 1.415691]\n",
      "epoch:26 step:24495 [D loss: 0.539974, acc.: 70.31%] [G loss: 0.598274]\n",
      "epoch:26 step:24496 [D loss: 0.459395, acc.: 78.12%] [G loss: 1.175096]\n",
      "epoch:26 step:24497 [D loss: 0.274233, acc.: 93.75%] [G loss: 1.684688]\n",
      "epoch:26 step:24498 [D loss: 0.515042, acc.: 74.22%] [G loss: 1.508832]\n",
      "epoch:26 step:24499 [D loss: 0.620479, acc.: 66.41%] [G loss: 1.229389]\n",
      "epoch:26 step:24500 [D loss: 0.657620, acc.: 60.94%] [G loss: 1.132804]\n",
      "epoch:26 step:24501 [D loss: 0.614201, acc.: 67.19%] [G loss: 1.073228]\n",
      "epoch:26 step:24502 [D loss: 0.301172, acc.: 89.06%] [G loss: 1.091754]\n",
      "epoch:26 step:24503 [D loss: 0.249533, acc.: 92.97%] [G loss: 1.268966]\n",
      "epoch:26 step:24504 [D loss: 0.374227, acc.: 84.38%] [G loss: 1.159445]\n",
      "epoch:26 step:24505 [D loss: 0.202947, acc.: 95.31%] [G loss: 1.400630]\n",
      "epoch:26 step:24506 [D loss: 0.180366, acc.: 96.09%] [G loss: 1.384004]\n",
      "epoch:26 step:24507 [D loss: 0.157306, acc.: 98.44%] [G loss: 1.645355]\n",
      "epoch:26 step:24508 [D loss: 0.203764, acc.: 97.66%] [G loss: 1.579194]\n",
      "epoch:26 step:24509 [D loss: 0.538822, acc.: 74.22%] [G loss: 1.661181]\n",
      "epoch:26 step:24510 [D loss: 0.526878, acc.: 74.22%] [G loss: 1.531202]\n",
      "epoch:26 step:24511 [D loss: 0.203299, acc.: 98.44%] [G loss: 1.761182]\n",
      "epoch:26 step:24512 [D loss: 0.156440, acc.: 97.66%] [G loss: 1.430170]\n",
      "epoch:26 step:24513 [D loss: 0.140877, acc.: 96.88%] [G loss: 2.035910]\n",
      "epoch:26 step:24514 [D loss: 0.153665, acc.: 97.66%] [G loss: 1.863298]\n",
      "epoch:26 step:24515 [D loss: 0.578915, acc.: 68.75%] [G loss: 1.786289]\n",
      "epoch:26 step:24516 [D loss: 0.464121, acc.: 82.03%] [G loss: 1.736702]\n",
      "epoch:26 step:24517 [D loss: 0.470899, acc.: 81.25%] [G loss: 1.509868]\n",
      "epoch:26 step:24518 [D loss: 0.959932, acc.: 34.38%] [G loss: 1.190324]\n",
      "epoch:26 step:24519 [D loss: 0.402622, acc.: 87.50%] [G loss: 1.581798]\n",
      "epoch:26 step:24520 [D loss: 0.519559, acc.: 71.88%] [G loss: 1.370489]\n",
      "epoch:26 step:24521 [D loss: 0.754030, acc.: 49.22%] [G loss: 1.272944]\n",
      "epoch:26 step:24522 [D loss: 0.256576, acc.: 93.75%] [G loss: 1.220880]\n",
      "epoch:26 step:24523 [D loss: 0.379409, acc.: 77.34%] [G loss: 1.135044]\n",
      "epoch:26 step:24524 [D loss: 0.192379, acc.: 94.53%] [G loss: 1.473356]\n",
      "epoch:26 step:24525 [D loss: 0.199146, acc.: 96.88%] [G loss: 1.543916]\n",
      "epoch:26 step:24526 [D loss: 0.201224, acc.: 96.88%] [G loss: 1.753059]\n",
      "epoch:26 step:24527 [D loss: 0.214955, acc.: 95.31%] [G loss: 1.754935]\n",
      "epoch:26 step:24528 [D loss: 0.926245, acc.: 46.09%] [G loss: 0.645420]\n",
      "epoch:26 step:24529 [D loss: 1.189290, acc.: 21.88%] [G loss: 0.498994]\n",
      "epoch:26 step:24530 [D loss: 1.069647, acc.: 25.00%] [G loss: 1.047813]\n",
      "epoch:26 step:24531 [D loss: 0.697700, acc.: 57.03%] [G loss: 0.950475]\n",
      "epoch:26 step:24532 [D loss: 0.744620, acc.: 50.78%] [G loss: 1.190948]\n",
      "epoch:26 step:24533 [D loss: 0.658183, acc.: 60.94%] [G loss: 0.812874]\n",
      "epoch:26 step:24534 [D loss: 1.169268, acc.: 32.81%] [G loss: 1.359988]\n",
      "epoch:26 step:24535 [D loss: 0.828622, acc.: 49.22%] [G loss: 0.866538]\n",
      "epoch:26 step:24536 [D loss: 0.659890, acc.: 59.38%] [G loss: 1.003212]\n",
      "epoch:26 step:24537 [D loss: 0.627495, acc.: 67.19%] [G loss: 1.208822]\n",
      "epoch:26 step:24538 [D loss: 1.062378, acc.: 28.91%] [G loss: 0.594140]\n",
      "epoch:26 step:24539 [D loss: 0.726373, acc.: 53.91%] [G loss: 1.329384]\n",
      "epoch:26 step:24540 [D loss: 0.740209, acc.: 56.25%] [G loss: 1.390076]\n",
      "epoch:26 step:24541 [D loss: 0.605442, acc.: 67.19%] [G loss: 1.222909]\n",
      "epoch:26 step:24542 [D loss: 0.980968, acc.: 34.38%] [G loss: 1.043035]\n",
      "epoch:26 step:24543 [D loss: 0.702375, acc.: 56.25%] [G loss: 1.472292]\n",
      "epoch:26 step:24544 [D loss: 0.887461, acc.: 38.28%] [G loss: 1.187140]\n",
      "epoch:26 step:24545 [D loss: 0.829267, acc.: 47.66%] [G loss: 1.209394]\n",
      "epoch:26 step:24546 [D loss: 0.674799, acc.: 60.94%] [G loss: 1.207011]\n",
      "epoch:26 step:24547 [D loss: 0.508531, acc.: 78.12%] [G loss: 1.395396]\n",
      "epoch:26 step:24548 [D loss: 0.850168, acc.: 36.72%] [G loss: 0.978451]\n",
      "epoch:26 step:24549 [D loss: 1.144236, acc.: 21.88%] [G loss: 0.853985]\n",
      "epoch:26 step:24550 [D loss: 0.694294, acc.: 53.91%] [G loss: 1.223533]\n",
      "epoch:26 step:24551 [D loss: 0.736637, acc.: 53.91%] [G loss: 1.470220]\n",
      "epoch:26 step:24552 [D loss: 0.655547, acc.: 58.59%] [G loss: 1.191899]\n",
      "epoch:26 step:24553 [D loss: 0.579720, acc.: 67.19%] [G loss: 1.198251]\n",
      "epoch:26 step:24554 [D loss: 0.395111, acc.: 89.84%] [G loss: 1.244784]\n",
      "epoch:26 step:24555 [D loss: 0.531173, acc.: 74.22%] [G loss: 1.332587]\n",
      "epoch:26 step:24556 [D loss: 0.399887, acc.: 92.19%] [G loss: 1.434524]\n",
      "epoch:26 step:24557 [D loss: 0.477312, acc.: 78.91%] [G loss: 1.390597]\n",
      "epoch:26 step:24558 [D loss: 0.495668, acc.: 77.34%] [G loss: 1.077985]\n",
      "epoch:26 step:24559 [D loss: 0.525194, acc.: 80.47%] [G loss: 1.207794]\n",
      "epoch:26 step:24560 [D loss: 0.531601, acc.: 82.03%] [G loss: 1.384680]\n",
      "epoch:26 step:24561 [D loss: 0.716955, acc.: 50.78%] [G loss: 1.042675]\n",
      "epoch:26 step:24562 [D loss: 0.628136, acc.: 71.88%] [G loss: 1.158253]\n",
      "epoch:26 step:24563 [D loss: 0.371449, acc.: 92.19%] [G loss: 1.135156]\n",
      "epoch:26 step:24564 [D loss: 0.659883, acc.: 57.81%] [G loss: 1.269374]\n",
      "epoch:26 step:24565 [D loss: 0.366686, acc.: 93.75%] [G loss: 1.049354]\n",
      "epoch:26 step:24566 [D loss: 0.302632, acc.: 94.53%] [G loss: 1.038102]\n",
      "epoch:26 step:24567 [D loss: 0.458938, acc.: 85.94%] [G loss: 1.197315]\n",
      "epoch:26 step:24568 [D loss: 0.281896, acc.: 96.09%] [G loss: 1.204073]\n",
      "epoch:26 step:24569 [D loss: 0.251289, acc.: 91.41%] [G loss: 1.412285]\n",
      "epoch:26 step:24570 [D loss: 0.244113, acc.: 98.44%] [G loss: 1.689601]\n",
      "epoch:26 step:24571 [D loss: 0.215397, acc.: 97.66%] [G loss: 1.615321]\n",
      "epoch:26 step:24572 [D loss: 0.669949, acc.: 62.50%] [G loss: 1.413531]\n",
      "epoch:26 step:24573 [D loss: 0.892265, acc.: 46.88%] [G loss: 1.207791]\n",
      "epoch:26 step:24574 [D loss: 0.526223, acc.: 78.12%] [G loss: 1.210682]\n",
      "epoch:26 step:24575 [D loss: 0.723757, acc.: 53.91%] [G loss: 0.971215]\n",
      "epoch:26 step:24576 [D loss: 0.533470, acc.: 77.34%] [G loss: 1.066545]\n",
      "epoch:26 step:24577 [D loss: 0.705976, acc.: 52.34%] [G loss: 1.059012]\n",
      "epoch:26 step:24578 [D loss: 0.562458, acc.: 71.88%] [G loss: 1.002755]\n",
      "epoch:26 step:24579 [D loss: 0.360892, acc.: 82.81%] [G loss: 1.125062]\n",
      "epoch:26 step:24580 [D loss: 0.306107, acc.: 85.94%] [G loss: 1.167285]\n",
      "epoch:26 step:24581 [D loss: 0.262629, acc.: 95.31%] [G loss: 1.379271]\n",
      "epoch:26 step:24582 [D loss: 0.368510, acc.: 91.41%] [G loss: 1.107745]\n",
      "epoch:26 step:24583 [D loss: 0.352182, acc.: 90.62%] [G loss: 1.354890]\n",
      "epoch:26 step:24584 [D loss: 0.351552, acc.: 93.75%] [G loss: 1.339818]\n",
      "epoch:26 step:24585 [D loss: 0.535432, acc.: 72.66%] [G loss: 1.377156]\n",
      "epoch:26 step:24586 [D loss: 0.479517, acc.: 77.34%] [G loss: 1.226430]\n",
      "epoch:26 step:24587 [D loss: 0.271084, acc.: 95.31%] [G loss: 1.047490]\n",
      "epoch:26 step:24588 [D loss: 0.718906, acc.: 56.25%] [G loss: 1.375156]\n",
      "epoch:26 step:24589 [D loss: 0.793258, acc.: 46.88%] [G loss: 1.278787]\n",
      "epoch:26 step:24590 [D loss: 0.716072, acc.: 54.69%] [G loss: 1.248725]\n",
      "epoch:26 step:24591 [D loss: 0.721967, acc.: 51.56%] [G loss: 1.109787]\n",
      "epoch:26 step:24592 [D loss: 0.251864, acc.: 90.62%] [G loss: 1.234419]\n",
      "epoch:26 step:24593 [D loss: 0.347661, acc.: 80.47%] [G loss: 1.288568]\n",
      "epoch:26 step:24594 [D loss: 0.286360, acc.: 94.53%] [G loss: 1.514029]\n",
      "epoch:26 step:24595 [D loss: 0.633627, acc.: 67.19%] [G loss: 1.308354]\n",
      "epoch:26 step:24596 [D loss: 0.604621, acc.: 66.41%] [G loss: 1.177666]\n",
      "epoch:26 step:24597 [D loss: 0.445265, acc.: 85.94%] [G loss: 1.630541]\n",
      "epoch:26 step:24598 [D loss: 0.541746, acc.: 71.09%] [G loss: 1.168347]\n",
      "epoch:26 step:24599 [D loss: 0.481540, acc.: 82.81%] [G loss: 1.165634]\n",
      "epoch:26 step:24600 [D loss: 0.540295, acc.: 74.22%] [G loss: 0.869405]\n",
      "##############\n",
      "[3.90315121 2.78248084 6.56888737 5.9249668  4.73362368 6.29788384\n",
      " 5.46864262 5.97593797 6.30413941 4.90384522]\n",
      "##########\n",
      "epoch:26 step:24601 [D loss: 0.667949, acc.: 61.72%] [G loss: 1.205407]\n",
      "epoch:26 step:24602 [D loss: 0.698640, acc.: 51.56%] [G loss: 1.060002]\n",
      "epoch:26 step:24603 [D loss: 0.529216, acc.: 79.69%] [G loss: 1.105923]\n",
      "epoch:26 step:24604 [D loss: 0.892755, acc.: 35.16%] [G loss: 0.804942]\n",
      "epoch:26 step:24605 [D loss: 0.598960, acc.: 69.53%] [G loss: 1.177602]\n",
      "epoch:26 step:24606 [D loss: 1.043300, acc.: 29.69%] [G loss: 1.113481]\n",
      "epoch:26 step:24607 [D loss: 0.677565, acc.: 58.59%] [G loss: 1.068856]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24608 [D loss: 0.391604, acc.: 89.84%] [G loss: 1.146240]\n",
      "epoch:26 step:24609 [D loss: 0.419005, acc.: 88.28%] [G loss: 1.184755]\n",
      "epoch:26 step:24610 [D loss: 0.349131, acc.: 91.41%] [G loss: 1.261891]\n",
      "epoch:26 step:24611 [D loss: 0.750992, acc.: 54.69%] [G loss: 1.286041]\n",
      "epoch:26 step:24612 [D loss: 0.621237, acc.: 65.62%] [G loss: 1.064480]\n",
      "epoch:26 step:24613 [D loss: 0.653318, acc.: 59.38%] [G loss: 1.189138]\n",
      "epoch:26 step:24614 [D loss: 0.737910, acc.: 59.38%] [G loss: 1.128543]\n",
      "epoch:26 step:24615 [D loss: 0.815966, acc.: 48.44%] [G loss: 0.731709]\n",
      "epoch:26 step:24616 [D loss: 0.642184, acc.: 60.16%] [G loss: 0.966043]\n",
      "epoch:26 step:24617 [D loss: 0.630004, acc.: 69.53%] [G loss: 1.034928]\n",
      "epoch:26 step:24618 [D loss: 0.340864, acc.: 85.16%] [G loss: 0.960464]\n",
      "epoch:26 step:24619 [D loss: 0.551004, acc.: 74.22%] [G loss: 1.125127]\n",
      "epoch:26 step:24620 [D loss: 0.734441, acc.: 50.00%] [G loss: 1.093556]\n",
      "epoch:26 step:24621 [D loss: 0.280947, acc.: 95.31%] [G loss: 1.228075]\n",
      "epoch:26 step:24622 [D loss: 0.425852, acc.: 82.03%] [G loss: 1.216182]\n",
      "epoch:26 step:24623 [D loss: 0.261011, acc.: 94.53%] [G loss: 1.258031]\n",
      "epoch:26 step:24624 [D loss: 0.724737, acc.: 51.56%] [G loss: 1.282728]\n",
      "epoch:26 step:24625 [D loss: 0.252304, acc.: 92.97%] [G loss: 1.185619]\n",
      "epoch:26 step:24626 [D loss: 0.226330, acc.: 96.88%] [G loss: 1.179976]\n",
      "epoch:26 step:24627 [D loss: 0.579974, acc.: 70.31%] [G loss: 1.419926]\n",
      "epoch:26 step:24628 [D loss: 0.612718, acc.: 63.28%] [G loss: 1.296531]\n",
      "epoch:26 step:24629 [D loss: 0.690520, acc.: 53.12%] [G loss: 1.164912]\n",
      "epoch:26 step:24630 [D loss: 0.675845, acc.: 58.59%] [G loss: 0.962602]\n",
      "epoch:26 step:24631 [D loss: 0.289124, acc.: 93.75%] [G loss: 1.132364]\n",
      "epoch:26 step:24632 [D loss: 0.464632, acc.: 83.59%] [G loss: 1.225062]\n",
      "epoch:26 step:24633 [D loss: 0.340849, acc.: 91.41%] [G loss: 1.321653]\n",
      "epoch:26 step:24634 [D loss: 0.295294, acc.: 92.97%] [G loss: 1.160683]\n",
      "epoch:26 step:24635 [D loss: 0.494013, acc.: 80.47%] [G loss: 1.225877]\n",
      "epoch:26 step:24636 [D loss: 0.449962, acc.: 75.78%] [G loss: 1.477868]\n",
      "epoch:26 step:24637 [D loss: 0.476660, acc.: 81.25%] [G loss: 1.392932]\n",
      "epoch:26 step:24638 [D loss: 0.301181, acc.: 96.88%] [G loss: 1.540394]\n",
      "epoch:26 step:24639 [D loss: 0.650166, acc.: 57.03%] [G loss: 1.546819]\n",
      "epoch:26 step:24640 [D loss: 0.271609, acc.: 95.31%] [G loss: 1.215724]\n",
      "epoch:26 step:24641 [D loss: 0.187969, acc.: 99.22%] [G loss: 1.507899]\n",
      "epoch:26 step:24642 [D loss: 0.652211, acc.: 63.28%] [G loss: 1.253397]\n",
      "epoch:26 step:24643 [D loss: 0.790570, acc.: 49.22%] [G loss: 1.219581]\n",
      "epoch:26 step:24644 [D loss: 0.507329, acc.: 79.69%] [G loss: 1.358962]\n",
      "epoch:26 step:24645 [D loss: 0.806137, acc.: 42.19%] [G loss: 0.553201]\n",
      "epoch:26 step:24646 [D loss: 0.353314, acc.: 89.06%] [G loss: 0.821184]\n",
      "epoch:26 step:24647 [D loss: 0.421194, acc.: 85.94%] [G loss: 1.354030]\n",
      "epoch:26 step:24648 [D loss: 0.436870, acc.: 80.47%] [G loss: 1.399113]\n",
      "epoch:26 step:24649 [D loss: 0.396497, acc.: 88.28%] [G loss: 0.992410]\n",
      "epoch:26 step:24650 [D loss: 0.267902, acc.: 96.09%] [G loss: 1.517087]\n",
      "epoch:26 step:24651 [D loss: 0.179503, acc.: 98.44%] [G loss: 1.722250]\n",
      "epoch:26 step:24652 [D loss: 0.422206, acc.: 85.16%] [G loss: 1.358199]\n",
      "epoch:26 step:24653 [D loss: 0.306487, acc.: 90.62%] [G loss: 1.649133]\n",
      "epoch:26 step:24654 [D loss: 0.164433, acc.: 98.44%] [G loss: 1.435425]\n",
      "epoch:26 step:24655 [D loss: 0.171784, acc.: 99.22%] [G loss: 1.609533]\n",
      "epoch:26 step:24656 [D loss: 0.377399, acc.: 89.84%] [G loss: 1.610080]\n",
      "epoch:26 step:24657 [D loss: 0.861735, acc.: 54.69%] [G loss: 1.448876]\n",
      "epoch:26 step:24658 [D loss: 0.862467, acc.: 46.09%] [G loss: 1.154166]\n",
      "epoch:26 step:24659 [D loss: 0.515714, acc.: 73.44%] [G loss: 0.831016]\n",
      "epoch:26 step:24660 [D loss: 0.513800, acc.: 75.00%] [G loss: 0.959684]\n",
      "epoch:26 step:24661 [D loss: 0.361407, acc.: 91.41%] [G loss: 0.852872]\n",
      "epoch:26 step:24662 [D loss: 0.814410, acc.: 40.62%] [G loss: 0.818980]\n",
      "epoch:26 step:24663 [D loss: 1.071075, acc.: 18.75%] [G loss: 1.300002]\n",
      "epoch:26 step:24664 [D loss: 0.660520, acc.: 60.94%] [G loss: 1.189711]\n",
      "epoch:26 step:24665 [D loss: 0.689828, acc.: 54.69%] [G loss: 0.689527]\n",
      "epoch:26 step:24666 [D loss: 0.399907, acc.: 88.28%] [G loss: 1.028576]\n",
      "epoch:26 step:24667 [D loss: 0.223178, acc.: 93.75%] [G loss: 1.385219]\n",
      "epoch:26 step:24668 [D loss: 0.289212, acc.: 92.97%] [G loss: 1.354973]\n",
      "epoch:26 step:24669 [D loss: 0.549883, acc.: 74.22%] [G loss: 1.003022]\n",
      "epoch:26 step:24670 [D loss: 0.295988, acc.: 82.81%] [G loss: 1.217846]\n",
      "epoch:26 step:24671 [D loss: 0.170168, acc.: 98.44%] [G loss: 1.740023]\n",
      "epoch:26 step:24672 [D loss: 0.276392, acc.: 96.09%] [G loss: 1.617668]\n",
      "epoch:26 step:24673 [D loss: 0.272530, acc.: 92.19%] [G loss: 1.516483]\n",
      "epoch:26 step:24674 [D loss: 0.238442, acc.: 90.62%] [G loss: 2.030324]\n",
      "epoch:26 step:24675 [D loss: 0.168369, acc.: 97.66%] [G loss: 2.181640]\n",
      "epoch:26 step:24676 [D loss: 0.081277, acc.: 99.22%] [G loss: 2.100211]\n",
      "epoch:26 step:24677 [D loss: 0.118243, acc.: 100.00%] [G loss: 2.525331]\n",
      "epoch:26 step:24678 [D loss: 1.171108, acc.: 50.00%] [G loss: 1.814111]\n",
      "epoch:26 step:24679 [D loss: 0.933404, acc.: 47.66%] [G loss: 1.359125]\n",
      "epoch:26 step:24680 [D loss: 0.879041, acc.: 50.00%] [G loss: 1.460100]\n",
      "epoch:26 step:24681 [D loss: 0.767173, acc.: 50.78%] [G loss: 1.197254]\n",
      "epoch:26 step:24682 [D loss: 0.795667, acc.: 47.66%] [G loss: 1.111976]\n",
      "epoch:26 step:24683 [D loss: 0.717169, acc.: 59.38%] [G loss: 1.107217]\n",
      "epoch:26 step:24684 [D loss: 0.722106, acc.: 50.00%] [G loss: 0.832197]\n",
      "epoch:26 step:24685 [D loss: 0.583714, acc.: 59.38%] [G loss: 1.349130]\n",
      "epoch:26 step:24686 [D loss: 0.519647, acc.: 78.12%] [G loss: 1.402954]\n",
      "epoch:26 step:24687 [D loss: 0.462889, acc.: 82.81%] [G loss: 1.357728]\n",
      "epoch:26 step:24688 [D loss: 0.734838, acc.: 52.34%] [G loss: 1.379501]\n",
      "epoch:26 step:24689 [D loss: 0.510193, acc.: 75.00%] [G loss: 1.277883]\n",
      "epoch:26 step:24690 [D loss: 0.481320, acc.: 81.25%] [G loss: 0.996566]\n",
      "epoch:26 step:24691 [D loss: 0.723701, acc.: 57.03%] [G loss: 1.495483]\n",
      "epoch:26 step:24692 [D loss: 0.580801, acc.: 69.53%] [G loss: 0.966400]\n",
      "epoch:26 step:24693 [D loss: 0.436445, acc.: 79.69%] [G loss: 1.220325]\n",
      "epoch:26 step:24694 [D loss: 0.177670, acc.: 96.88%] [G loss: 1.372878]\n",
      "epoch:26 step:24695 [D loss: 0.205889, acc.: 96.09%] [G loss: 1.202685]\n",
      "epoch:26 step:24696 [D loss: 0.143452, acc.: 100.00%] [G loss: 1.506008]\n",
      "epoch:26 step:24697 [D loss: 0.222195, acc.: 98.44%] [G loss: 1.769065]\n",
      "epoch:26 step:24698 [D loss: 0.216725, acc.: 94.53%] [G loss: 1.057671]\n",
      "epoch:26 step:24699 [D loss: 0.380439, acc.: 90.62%] [G loss: 1.497888]\n",
      "epoch:26 step:24700 [D loss: 0.503674, acc.: 78.91%] [G loss: 2.021568]\n",
      "epoch:26 step:24701 [D loss: 0.532127, acc.: 71.88%] [G loss: 1.342991]\n",
      "epoch:26 step:24702 [D loss: 0.566839, acc.: 74.22%] [G loss: 1.429347]\n",
      "epoch:26 step:24703 [D loss: 0.419640, acc.: 91.41%] [G loss: 0.507973]\n",
      "epoch:26 step:24704 [D loss: 0.709925, acc.: 59.38%] [G loss: 1.459558]\n",
      "epoch:26 step:24705 [D loss: 0.147107, acc.: 100.00%] [G loss: 1.891507]\n",
      "epoch:26 step:24706 [D loss: 0.121741, acc.: 99.22%] [G loss: 0.301883]\n",
      "epoch:26 step:24707 [D loss: 0.124811, acc.: 99.22%] [G loss: 2.149432]\n",
      "epoch:26 step:24708 [D loss: 0.095652, acc.: 98.44%] [G loss: 1.791706]\n",
      "epoch:26 step:24709 [D loss: 0.394616, acc.: 71.88%] [G loss: 2.457106]\n",
      "epoch:26 step:24710 [D loss: 0.664263, acc.: 57.03%] [G loss: 1.533130]\n",
      "epoch:26 step:24711 [D loss: 1.052084, acc.: 50.78%] [G loss: 1.686265]\n",
      "epoch:26 step:24712 [D loss: 0.621034, acc.: 58.59%] [G loss: 0.954333]\n",
      "epoch:26 step:24713 [D loss: 0.719460, acc.: 55.47%] [G loss: 0.871445]\n",
      "epoch:26 step:24714 [D loss: 0.512164, acc.: 72.66%] [G loss: 1.597438]\n",
      "epoch:26 step:24715 [D loss: 0.439933, acc.: 82.81%] [G loss: 1.452527]\n",
      "epoch:26 step:24716 [D loss: 0.940243, acc.: 48.44%] [G loss: 1.595790]\n",
      "epoch:26 step:24717 [D loss: 0.791233, acc.: 52.34%] [G loss: 1.484819]\n",
      "epoch:26 step:24718 [D loss: 0.680037, acc.: 61.72%] [G loss: 1.156899]\n",
      "epoch:26 step:24719 [D loss: 0.458099, acc.: 78.12%] [G loss: 1.195718]\n",
      "epoch:26 step:24720 [D loss: 0.459934, acc.: 78.91%] [G loss: 1.777237]\n",
      "epoch:26 step:24721 [D loss: 0.310655, acc.: 92.19%] [G loss: 1.632677]\n",
      "epoch:26 step:24722 [D loss: 0.310231, acc.: 92.97%] [G loss: 1.431803]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24723 [D loss: 0.363434, acc.: 88.28%] [G loss: 2.093157]\n",
      "epoch:26 step:24724 [D loss: 0.744658, acc.: 60.16%] [G loss: 1.294863]\n",
      "epoch:26 step:24725 [D loss: 0.647858, acc.: 66.41%] [G loss: 1.622710]\n",
      "epoch:26 step:24726 [D loss: 0.594749, acc.: 65.62%] [G loss: 1.008457]\n",
      "epoch:26 step:24727 [D loss: 0.577704, acc.: 63.28%] [G loss: 1.632894]\n",
      "epoch:26 step:24728 [D loss: 0.262339, acc.: 95.31%] [G loss: 1.347995]\n",
      "epoch:26 step:24729 [D loss: 0.719578, acc.: 54.69%] [G loss: 1.464191]\n",
      "epoch:26 step:24730 [D loss: 0.920800, acc.: 37.50%] [G loss: 0.734437]\n",
      "epoch:26 step:24731 [D loss: 0.257517, acc.: 87.50%] [G loss: 1.526406]\n",
      "epoch:26 step:24732 [D loss: 0.283342, acc.: 84.38%] [G loss: 1.843610]\n",
      "epoch:26 step:24733 [D loss: 0.148572, acc.: 98.44%] [G loss: 1.818813]\n",
      "epoch:26 step:24734 [D loss: 0.128755, acc.: 98.44%] [G loss: 1.950403]\n",
      "epoch:26 step:24735 [D loss: 0.826249, acc.: 53.91%] [G loss: 1.440463]\n",
      "epoch:26 step:24736 [D loss: 0.486347, acc.: 81.25%] [G loss: 1.341964]\n",
      "epoch:26 step:24737 [D loss: 0.726674, acc.: 54.69%] [G loss: 1.160219]\n",
      "epoch:26 step:24738 [D loss: 0.705285, acc.: 57.81%] [G loss: 0.735065]\n",
      "epoch:26 step:24739 [D loss: 1.060558, acc.: 28.91%] [G loss: 0.941789]\n",
      "epoch:26 step:24740 [D loss: 1.209144, acc.: 24.22%] [G loss: 1.001540]\n",
      "epoch:26 step:24741 [D loss: 0.317542, acc.: 85.16%] [G loss: 0.808374]\n",
      "epoch:26 step:24742 [D loss: 0.270693, acc.: 89.84%] [G loss: 1.370579]\n",
      "epoch:26 step:24743 [D loss: 0.139541, acc.: 98.44%] [G loss: 1.580214]\n",
      "epoch:26 step:24744 [D loss: 0.684593, acc.: 58.59%] [G loss: 1.205683]\n",
      "epoch:26 step:24745 [D loss: 0.722579, acc.: 51.56%] [G loss: 1.086262]\n",
      "epoch:26 step:24746 [D loss: 0.822346, acc.: 40.62%] [G loss: 1.309160]\n",
      "epoch:26 step:24747 [D loss: 0.514517, acc.: 75.00%] [G loss: 1.373664]\n",
      "epoch:26 step:24748 [D loss: 1.050946, acc.: 34.38%] [G loss: 1.075490]\n",
      "epoch:26 step:24749 [D loss: 0.735815, acc.: 50.00%] [G loss: 1.492892]\n",
      "epoch:26 step:24750 [D loss: 0.736466, acc.: 49.22%] [G loss: 1.194373]\n",
      "epoch:26 step:24751 [D loss: 0.731641, acc.: 52.34%] [G loss: 1.100596]\n",
      "epoch:26 step:24752 [D loss: 0.774646, acc.: 44.53%] [G loss: 1.075088]\n",
      "epoch:26 step:24753 [D loss: 0.744541, acc.: 43.75%] [G loss: 0.807943]\n",
      "epoch:26 step:24754 [D loss: 0.851128, acc.: 32.81%] [G loss: 0.718843]\n",
      "epoch:26 step:24755 [D loss: 0.690036, acc.: 56.25%] [G loss: 0.957477]\n",
      "epoch:26 step:24756 [D loss: 0.757950, acc.: 44.53%] [G loss: 1.140180]\n",
      "epoch:26 step:24757 [D loss: 0.722688, acc.: 46.09%] [G loss: 1.100707]\n",
      "epoch:26 step:24758 [D loss: 0.586801, acc.: 59.38%] [G loss: 0.986007]\n",
      "epoch:26 step:24759 [D loss: 0.355367, acc.: 78.12%] [G loss: 1.321521]\n",
      "epoch:26 step:24760 [D loss: 0.200956, acc.: 98.44%] [G loss: 1.313507]\n",
      "epoch:26 step:24761 [D loss: 0.191344, acc.: 100.00%] [G loss: 0.897064]\n",
      "epoch:26 step:24762 [D loss: 0.231340, acc.: 96.88%] [G loss: 1.286849]\n",
      "epoch:26 step:24763 [D loss: 0.221886, acc.: 97.66%] [G loss: 1.394125]\n",
      "epoch:26 step:24764 [D loss: 0.190168, acc.: 99.22%] [G loss: 1.441620]\n",
      "epoch:26 step:24765 [D loss: 0.265799, acc.: 98.44%] [G loss: 1.463003]\n",
      "epoch:26 step:24766 [D loss: 0.196595, acc.: 97.66%] [G loss: 1.539982]\n",
      "epoch:26 step:24767 [D loss: 0.149460, acc.: 99.22%] [G loss: 1.534050]\n",
      "epoch:26 step:24768 [D loss: 0.190946, acc.: 96.88%] [G loss: 1.623208]\n",
      "epoch:26 step:24769 [D loss: 0.114525, acc.: 100.00%] [G loss: 1.454518]\n",
      "epoch:26 step:24770 [D loss: 0.131407, acc.: 100.00%] [G loss: 1.794140]\n",
      "epoch:26 step:24771 [D loss: 0.124063, acc.: 100.00%] [G loss: 1.984155]\n",
      "epoch:26 step:24772 [D loss: 0.222833, acc.: 99.22%] [G loss: 1.760275]\n",
      "epoch:26 step:24773 [D loss: 0.643738, acc.: 59.38%] [G loss: 1.687938]\n",
      "epoch:26 step:24774 [D loss: 0.139421, acc.: 100.00%] [G loss: 1.407874]\n",
      "epoch:26 step:24775 [D loss: 0.121182, acc.: 99.22%] [G loss: 1.319485]\n",
      "epoch:26 step:24776 [D loss: 0.171526, acc.: 100.00%] [G loss: 1.568460]\n",
      "epoch:26 step:24777 [D loss: 0.135311, acc.: 100.00%] [G loss: 1.550602]\n",
      "epoch:26 step:24778 [D loss: 0.142566, acc.: 100.00%] [G loss: 2.009603]\n",
      "epoch:26 step:24779 [D loss: 0.117909, acc.: 100.00%] [G loss: 1.945907]\n",
      "epoch:26 step:24780 [D loss: 0.111246, acc.: 99.22%] [G loss: 1.953925]\n",
      "epoch:26 step:24781 [D loss: 0.111511, acc.: 100.00%] [G loss: 1.987154]\n",
      "epoch:26 step:24782 [D loss: 0.101073, acc.: 99.22%] [G loss: 2.005633]\n",
      "epoch:26 step:24783 [D loss: 0.237630, acc.: 98.44%] [G loss: 1.871126]\n",
      "epoch:26 step:24784 [D loss: 0.452459, acc.: 81.25%] [G loss: 1.901686]\n",
      "epoch:26 step:24785 [D loss: 0.152974, acc.: 100.00%] [G loss: 1.671616]\n",
      "epoch:26 step:24786 [D loss: 0.249708, acc.: 91.41%] [G loss: 1.920383]\n",
      "epoch:26 step:24787 [D loss: 0.119618, acc.: 100.00%] [G loss: 2.178304]\n",
      "epoch:26 step:24788 [D loss: 0.343147, acc.: 87.50%] [G loss: 2.142671]\n",
      "epoch:26 step:24789 [D loss: 0.107001, acc.: 100.00%] [G loss: 2.017879]\n",
      "epoch:26 step:24790 [D loss: 0.157297, acc.: 97.66%] [G loss: 2.261404]\n",
      "epoch:26 step:24791 [D loss: 0.080619, acc.: 100.00%] [G loss: 2.163976]\n",
      "epoch:26 step:24792 [D loss: 0.083311, acc.: 100.00%] [G loss: 2.315752]\n",
      "epoch:26 step:24793 [D loss: 0.101553, acc.: 100.00%] [G loss: 2.318576]\n",
      "epoch:26 step:24794 [D loss: 0.678316, acc.: 59.38%] [G loss: 1.584366]\n",
      "epoch:26 step:24795 [D loss: 0.150085, acc.: 100.00%] [G loss: 1.898323]\n",
      "epoch:26 step:24796 [D loss: 0.133333, acc.: 100.00%] [G loss: 2.136629]\n",
      "epoch:26 step:24797 [D loss: 0.187787, acc.: 98.44%] [G loss: 1.621954]\n",
      "epoch:26 step:24798 [D loss: 0.533511, acc.: 62.50%] [G loss: 1.369686]\n",
      "epoch:26 step:24799 [D loss: 0.106109, acc.: 100.00%] [G loss: 1.546648]\n",
      "epoch:26 step:24800 [D loss: 0.102445, acc.: 99.22%] [G loss: 1.825256]\n",
      "##############\n",
      "[3.55226908 2.47659728 6.55688185 5.65733228 4.47734238 6.1221963\n",
      " 5.07011847 5.56125657 5.74484087 5.02685435]\n",
      "##########\n",
      "epoch:26 step:24801 [D loss: 0.190024, acc.: 98.44%] [G loss: 1.720297]\n",
      "epoch:26 step:24802 [D loss: 0.429769, acc.: 69.53%] [G loss: 1.946260]\n",
      "epoch:26 step:24803 [D loss: 0.182916, acc.: 98.44%] [G loss: 2.355126]\n",
      "epoch:26 step:24804 [D loss: 0.102739, acc.: 100.00%] [G loss: 2.243335]\n",
      "epoch:26 step:24805 [D loss: 1.106981, acc.: 48.44%] [G loss: 1.146958]\n",
      "epoch:26 step:24806 [D loss: 0.860011, acc.: 54.69%] [G loss: 1.135445]\n",
      "epoch:26 step:24807 [D loss: 0.149393, acc.: 97.66%] [G loss: 1.374820]\n",
      "epoch:26 step:24808 [D loss: 0.853295, acc.: 56.25%] [G loss: 2.481444]\n",
      "epoch:26 step:24809 [D loss: 1.110034, acc.: 47.66%] [G loss: 2.329073]\n",
      "epoch:26 step:24810 [D loss: 1.441076, acc.: 49.22%] [G loss: 3.163396]\n",
      "epoch:26 step:24811 [D loss: 1.062217, acc.: 51.56%] [G loss: 2.768357]\n",
      "epoch:26 step:24812 [D loss: 1.154645, acc.: 45.31%] [G loss: 2.468019]\n",
      "epoch:26 step:24813 [D loss: 0.546152, acc.: 64.06%] [G loss: 2.323036]\n",
      "epoch:26 step:24814 [D loss: 0.421964, acc.: 77.34%] [G loss: 2.292018]\n",
      "epoch:26 step:24815 [D loss: 0.438846, acc.: 73.44%] [G loss: 1.582391]\n",
      "epoch:26 step:24816 [D loss: 0.420556, acc.: 80.47%] [G loss: 2.190587]\n",
      "epoch:26 step:24817 [D loss: 0.441242, acc.: 75.00%] [G loss: 1.958606]\n",
      "epoch:26 step:24818 [D loss: 0.143225, acc.: 98.44%] [G loss: 1.949739]\n",
      "epoch:26 step:24819 [D loss: 0.226597, acc.: 98.44%] [G loss: 2.228314]\n",
      "epoch:26 step:24820 [D loss: 0.657811, acc.: 57.03%] [G loss: 1.998305]\n",
      "epoch:26 step:24821 [D loss: 0.630644, acc.: 57.81%] [G loss: 1.716260]\n",
      "epoch:26 step:24822 [D loss: 0.603183, acc.: 60.16%] [G loss: 1.552403]\n",
      "epoch:26 step:24823 [D loss: 0.649737, acc.: 54.69%] [G loss: 1.318105]\n",
      "epoch:26 step:24824 [D loss: 0.773585, acc.: 43.75%] [G loss: 0.900392]\n",
      "epoch:26 step:24825 [D loss: 0.532594, acc.: 74.22%] [G loss: 0.997185]\n",
      "epoch:26 step:24826 [D loss: 0.397038, acc.: 86.72%] [G loss: 1.321699]\n",
      "epoch:26 step:24827 [D loss: 0.218477, acc.: 94.53%] [G loss: 1.416243]\n",
      "epoch:26 step:24828 [D loss: 0.414446, acc.: 76.56%] [G loss: 1.248456]\n",
      "epoch:26 step:24829 [D loss: 0.366135, acc.: 86.72%] [G loss: 1.160027]\n",
      "epoch:26 step:24830 [D loss: 0.182681, acc.: 96.88%] [G loss: 1.433129]\n",
      "epoch:26 step:24831 [D loss: 0.133953, acc.: 100.00%] [G loss: 1.239111]\n",
      "epoch:26 step:24832 [D loss: 0.113949, acc.: 98.44%] [G loss: 1.741536]\n",
      "epoch:26 step:24833 [D loss: 0.143001, acc.: 99.22%] [G loss: 2.128808]\n",
      "epoch:26 step:24834 [D loss: 0.155595, acc.: 98.44%] [G loss: 1.658827]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24835 [D loss: 1.482962, acc.: 33.59%] [G loss: 1.883687]\n",
      "epoch:26 step:24836 [D loss: 1.077045, acc.: 37.50%] [G loss: 0.408479]\n",
      "epoch:26 step:24837 [D loss: 0.933648, acc.: 42.97%] [G loss: 1.711139]\n",
      "epoch:26 step:24838 [D loss: 0.576062, acc.: 71.09%] [G loss: 1.237917]\n",
      "epoch:26 step:24839 [D loss: 0.722481, acc.: 57.81%] [G loss: 1.451193]\n",
      "epoch:26 step:24840 [D loss: 0.733481, acc.: 52.34%] [G loss: 1.071364]\n",
      "epoch:26 step:24841 [D loss: 0.264082, acc.: 98.44%] [G loss: 1.281338]\n",
      "epoch:26 step:24842 [D loss: 0.432625, acc.: 83.59%] [G loss: 1.057413]\n",
      "epoch:26 step:24843 [D loss: 0.338477, acc.: 89.06%] [G loss: 1.295938]\n",
      "epoch:26 step:24844 [D loss: 0.928976, acc.: 32.81%] [G loss: 0.897848]\n",
      "epoch:26 step:24845 [D loss: 0.574714, acc.: 65.62%] [G loss: 1.294975]\n",
      "epoch:26 step:24846 [D loss: 0.613412, acc.: 64.84%] [G loss: 1.216157]\n",
      "epoch:26 step:24847 [D loss: 0.710238, acc.: 53.12%] [G loss: 1.866302]\n",
      "epoch:26 step:24848 [D loss: 0.528039, acc.: 68.75%] [G loss: 1.805136]\n",
      "epoch:26 step:24849 [D loss: 0.582867, acc.: 72.66%] [G loss: 1.368369]\n",
      "epoch:26 step:24850 [D loss: 0.606346, acc.: 64.84%] [G loss: 1.259393]\n",
      "epoch:26 step:24851 [D loss: 0.583984, acc.: 71.09%] [G loss: 1.226065]\n",
      "epoch:26 step:24852 [D loss: 0.520558, acc.: 71.88%] [G loss: 0.963064]\n",
      "epoch:26 step:24853 [D loss: 0.553852, acc.: 73.44%] [G loss: 1.205447]\n",
      "epoch:26 step:24854 [D loss: 0.663871, acc.: 60.16%] [G loss: 1.083262]\n",
      "epoch:26 step:24855 [D loss: 0.554684, acc.: 69.53%] [G loss: 1.372728]\n",
      "epoch:26 step:24856 [D loss: 0.509053, acc.: 76.56%] [G loss: 1.249852]\n",
      "epoch:26 step:24857 [D loss: 0.503073, acc.: 77.34%] [G loss: 1.642378]\n",
      "epoch:26 step:24858 [D loss: 0.512702, acc.: 73.44%] [G loss: 1.304759]\n",
      "epoch:26 step:24859 [D loss: 0.279721, acc.: 87.50%] [G loss: 1.417802]\n",
      "epoch:26 step:24860 [D loss: 0.258638, acc.: 86.72%] [G loss: 2.141426]\n",
      "epoch:26 step:24861 [D loss: 0.142496, acc.: 98.44%] [G loss: 2.021660]\n",
      "epoch:26 step:24862 [D loss: 0.691389, acc.: 63.28%] [G loss: 1.519961]\n",
      "epoch:26 step:24863 [D loss: 0.544074, acc.: 75.00%] [G loss: 1.380599]\n",
      "epoch:26 step:24864 [D loss: 0.552994, acc.: 71.88%] [G loss: 1.366875]\n",
      "epoch:26 step:24865 [D loss: 0.266390, acc.: 95.31%] [G loss: 1.185191]\n",
      "epoch:26 step:24866 [D loss: 0.275197, acc.: 90.62%] [G loss: 1.293126]\n",
      "epoch:26 step:24867 [D loss: 0.496553, acc.: 75.00%] [G loss: 0.959461]\n",
      "epoch:26 step:24868 [D loss: 0.801844, acc.: 43.75%] [G loss: 1.205857]\n",
      "epoch:26 step:24869 [D loss: 0.532020, acc.: 73.44%] [G loss: 1.024094]\n",
      "epoch:26 step:24870 [D loss: 0.524982, acc.: 74.22%] [G loss: 1.049349]\n",
      "epoch:26 step:24871 [D loss: 0.637692, acc.: 60.16%] [G loss: 1.148116]\n",
      "epoch:26 step:24872 [D loss: 0.222438, acc.: 95.31%] [G loss: 1.115763]\n",
      "epoch:26 step:24873 [D loss: 0.270304, acc.: 88.28%] [G loss: 1.280461]\n",
      "epoch:26 step:24874 [D loss: 0.299976, acc.: 97.66%] [G loss: 1.758948]\n",
      "epoch:26 step:24875 [D loss: 0.195477, acc.: 97.66%] [G loss: 1.693591]\n",
      "epoch:26 step:24876 [D loss: 0.174205, acc.: 98.44%] [G loss: 2.123320]\n",
      "epoch:26 step:24877 [D loss: 0.128147, acc.: 98.44%] [G loss: 1.771978]\n",
      "epoch:26 step:24878 [D loss: 0.823942, acc.: 50.00%] [G loss: 1.581792]\n",
      "epoch:26 step:24879 [D loss: 0.368291, acc.: 92.97%] [G loss: 1.411031]\n",
      "epoch:26 step:24880 [D loss: 0.651608, acc.: 63.28%] [G loss: 1.144717]\n",
      "epoch:26 step:24881 [D loss: 0.551493, acc.: 71.88%] [G loss: 0.899431]\n",
      "epoch:26 step:24882 [D loss: 0.561343, acc.: 70.31%] [G loss: 1.034188]\n",
      "epoch:26 step:24883 [D loss: 0.528026, acc.: 76.56%] [G loss: 1.133198]\n",
      "epoch:26 step:24884 [D loss: 0.619623, acc.: 63.28%] [G loss: 0.859421]\n",
      "epoch:26 step:24885 [D loss: 0.550787, acc.: 75.78%] [G loss: 1.049093]\n",
      "epoch:26 step:24886 [D loss: 0.282491, acc.: 89.84%] [G loss: 1.004932]\n",
      "epoch:26 step:24887 [D loss: 0.690900, acc.: 57.03%] [G loss: 1.044224]\n",
      "epoch:26 step:24888 [D loss: 0.457050, acc.: 83.59%] [G loss: 1.376423]\n",
      "epoch:26 step:24889 [D loss: 0.228497, acc.: 96.88%] [G loss: 1.864903]\n",
      "epoch:26 step:24890 [D loss: 0.472131, acc.: 82.81%] [G loss: 1.238835]\n",
      "epoch:26 step:24891 [D loss: 0.329770, acc.: 94.53%] [G loss: 1.434154]\n",
      "epoch:26 step:24892 [D loss: 0.205703, acc.: 94.53%] [G loss: 1.264489]\n",
      "epoch:26 step:24893 [D loss: 0.722946, acc.: 55.47%] [G loss: 1.606371]\n",
      "epoch:26 step:24894 [D loss: 0.713220, acc.: 57.81%] [G loss: 1.205079]\n",
      "epoch:26 step:24895 [D loss: 0.377596, acc.: 89.06%] [G loss: 0.873133]\n",
      "epoch:26 step:24896 [D loss: 0.377903, acc.: 94.53%] [G loss: 1.339880]\n",
      "epoch:26 step:24897 [D loss: 0.368684, acc.: 78.12%] [G loss: 1.033790]\n",
      "epoch:26 step:24898 [D loss: 0.128926, acc.: 99.22%] [G loss: 1.659224]\n",
      "epoch:26 step:24899 [D loss: 0.187520, acc.: 94.53%] [G loss: 1.957472]\n",
      "epoch:26 step:24900 [D loss: 0.183550, acc.: 99.22%] [G loss: 2.012467]\n",
      "epoch:26 step:24901 [D loss: 0.115946, acc.: 99.22%] [G loss: 1.997341]\n",
      "epoch:26 step:24902 [D loss: 0.232922, acc.: 96.09%] [G loss: 2.058142]\n",
      "epoch:26 step:24903 [D loss: 0.209626, acc.: 98.44%] [G loss: 1.980691]\n",
      "epoch:26 step:24904 [D loss: 0.798949, acc.: 58.59%] [G loss: 1.478667]\n",
      "epoch:26 step:24905 [D loss: 0.478453, acc.: 74.22%] [G loss: 1.347300]\n",
      "epoch:26 step:24906 [D loss: 1.045132, acc.: 32.81%] [G loss: 1.743881]\n",
      "epoch:26 step:24907 [D loss: 0.575097, acc.: 66.41%] [G loss: 1.519233]\n",
      "epoch:26 step:24908 [D loss: 0.796453, acc.: 52.34%] [G loss: 1.441428]\n",
      "epoch:26 step:24909 [D loss: 0.539213, acc.: 76.56%] [G loss: 1.148447]\n",
      "epoch:26 step:24910 [D loss: 0.602322, acc.: 68.75%] [G loss: 1.001538]\n",
      "epoch:26 step:24911 [D loss: 0.538403, acc.: 77.34%] [G loss: 0.570377]\n",
      "epoch:26 step:24912 [D loss: 0.477669, acc.: 75.78%] [G loss: 1.195849]\n",
      "epoch:26 step:24913 [D loss: 0.898561, acc.: 42.19%] [G loss: 0.822471]\n",
      "epoch:26 step:24914 [D loss: 0.699636, acc.: 57.03%] [G loss: 0.865698]\n",
      "epoch:26 step:24915 [D loss: 0.931877, acc.: 34.38%] [G loss: 0.866269]\n",
      "epoch:26 step:24916 [D loss: 0.430197, acc.: 80.47%] [G loss: 1.035648]\n",
      "epoch:26 step:24917 [D loss: 0.915685, acc.: 39.06%] [G loss: 1.483721]\n",
      "epoch:26 step:24918 [D loss: 0.516389, acc.: 78.91%] [G loss: 0.973802]\n",
      "epoch:26 step:24919 [D loss: 0.538254, acc.: 72.66%] [G loss: 1.219543]\n",
      "epoch:26 step:24920 [D loss: 0.650406, acc.: 60.16%] [G loss: 0.220252]\n",
      "epoch:26 step:24921 [D loss: 0.220582, acc.: 90.62%] [G loss: 0.527355]\n",
      "epoch:26 step:24922 [D loss: 0.254668, acc.: 89.06%] [G loss: 0.046891]\n",
      "epoch:26 step:24923 [D loss: 0.251642, acc.: 89.06%] [G loss: 1.003771]\n",
      "epoch:26 step:24924 [D loss: 0.446667, acc.: 78.12%] [G loss: 1.856172]\n",
      "epoch:26 step:24925 [D loss: 0.837621, acc.: 60.16%] [G loss: 2.747386]\n",
      "epoch:26 step:24926 [D loss: 0.230572, acc.: 92.97%] [G loss: 3.368489]\n",
      "epoch:26 step:24927 [D loss: 0.059737, acc.: 100.00%] [G loss: 3.212429]\n",
      "epoch:26 step:24928 [D loss: 0.042296, acc.: 100.00%] [G loss: 2.872600]\n",
      "epoch:26 step:24929 [D loss: 0.064679, acc.: 100.00%] [G loss: 2.481608]\n",
      "epoch:26 step:24930 [D loss: 0.064306, acc.: 100.00%] [G loss: 2.780511]\n",
      "epoch:26 step:24931 [D loss: 0.507901, acc.: 71.09%] [G loss: 2.463000]\n",
      "epoch:26 step:24932 [D loss: 0.281007, acc.: 92.19%] [G loss: 2.811883]\n",
      "epoch:26 step:24933 [D loss: 0.309635, acc.: 92.97%] [G loss: 2.058690]\n",
      "epoch:26 step:24934 [D loss: 0.190555, acc.: 96.88%] [G loss: 1.690968]\n",
      "epoch:26 step:24935 [D loss: 0.136238, acc.: 100.00%] [G loss: 1.603421]\n",
      "epoch:26 step:24936 [D loss: 0.441586, acc.: 75.78%] [G loss: 2.930553]\n",
      "epoch:26 step:24937 [D loss: 0.306843, acc.: 89.84%] [G loss: 3.161933]\n",
      "epoch:26 step:24938 [D loss: 0.056749, acc.: 100.00%] [G loss: 2.279421]\n",
      "epoch:26 step:24939 [D loss: 0.106262, acc.: 99.22%] [G loss: 2.437567]\n",
      "epoch:26 step:24940 [D loss: 0.046223, acc.: 100.00%] [G loss: 3.388103]\n",
      "epoch:26 step:24941 [D loss: 0.329444, acc.: 86.72%] [G loss: 2.013830]\n",
      "epoch:26 step:24942 [D loss: 1.048544, acc.: 57.03%] [G loss: 0.388689]\n",
      "epoch:26 step:24943 [D loss: 0.836577, acc.: 51.56%] [G loss: 1.870343]\n",
      "epoch:26 step:24944 [D loss: 0.765785, acc.: 54.69%] [G loss: 1.092102]\n",
      "epoch:26 step:24945 [D loss: 1.368279, acc.: 30.47%] [G loss: 0.632131]\n",
      "epoch:26 step:24946 [D loss: 1.864477, acc.: 14.06%] [G loss: 1.870450]\n",
      "epoch:26 step:24947 [D loss: 0.913300, acc.: 60.16%] [G loss: 2.230756]\n",
      "epoch:26 step:24948 [D loss: 0.774421, acc.: 54.69%] [G loss: 1.511305]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24949 [D loss: 0.417738, acc.: 77.34%] [G loss: 1.335297]\n",
      "epoch:26 step:24950 [D loss: 0.673343, acc.: 63.28%] [G loss: 1.651620]\n",
      "epoch:26 step:24951 [D loss: 0.220515, acc.: 94.53%] [G loss: 0.983640]\n",
      "epoch:26 step:24952 [D loss: 0.992423, acc.: 42.19%] [G loss: 1.283643]\n",
      "epoch:26 step:24953 [D loss: 0.866921, acc.: 49.22%] [G loss: 1.198806]\n",
      "epoch:26 step:24954 [D loss: 0.730336, acc.: 60.16%] [G loss: 1.932210]\n",
      "epoch:26 step:24955 [D loss: 0.841242, acc.: 48.44%] [G loss: 1.396352]\n",
      "epoch:26 step:24956 [D loss: 0.908797, acc.: 36.72%] [G loss: 1.271697]\n",
      "epoch:26 step:24957 [D loss: 0.484410, acc.: 79.69%] [G loss: 1.612592]\n",
      "epoch:26 step:24958 [D loss: 0.788003, acc.: 46.09%] [G loss: 1.614650]\n",
      "epoch:26 step:24959 [D loss: 0.801220, acc.: 50.78%] [G loss: 1.780889]\n",
      "epoch:26 step:24960 [D loss: 0.587024, acc.: 63.28%] [G loss: 1.698125]\n",
      "epoch:26 step:24961 [D loss: 0.597224, acc.: 65.62%] [G loss: 1.631042]\n",
      "epoch:26 step:24962 [D loss: 0.493385, acc.: 77.34%] [G loss: 1.761226]\n",
      "epoch:26 step:24963 [D loss: 0.577207, acc.: 73.44%] [G loss: 1.296738]\n",
      "epoch:26 step:24964 [D loss: 0.488894, acc.: 80.47%] [G loss: 1.150995]\n",
      "epoch:26 step:24965 [D loss: 0.547799, acc.: 67.19%] [G loss: 1.020897]\n",
      "epoch:26 step:24966 [D loss: 0.559730, acc.: 75.00%] [G loss: 1.283578]\n",
      "epoch:26 step:24967 [D loss: 0.548245, acc.: 71.09%] [G loss: 1.357243]\n",
      "epoch:26 step:24968 [D loss: 0.609334, acc.: 67.97%] [G loss: 1.106037]\n",
      "epoch:26 step:24969 [D loss: 0.695593, acc.: 54.69%] [G loss: 0.975233]\n",
      "epoch:26 step:24970 [D loss: 0.447039, acc.: 79.69%] [G loss: 1.107339]\n",
      "epoch:26 step:24971 [D loss: 0.345599, acc.: 89.84%] [G loss: 1.044882]\n",
      "epoch:26 step:24972 [D loss: 0.654804, acc.: 60.16%] [G loss: 1.103169]\n",
      "epoch:26 step:24973 [D loss: 0.691207, acc.: 62.50%] [G loss: 1.064825]\n",
      "epoch:26 step:24974 [D loss: 0.697305, acc.: 58.59%] [G loss: 1.062750]\n",
      "epoch:26 step:24975 [D loss: 0.638360, acc.: 63.28%] [G loss: 1.169817]\n",
      "epoch:26 step:24976 [D loss: 0.613120, acc.: 64.06%] [G loss: 1.136674]\n",
      "epoch:26 step:24977 [D loss: 0.737425, acc.: 47.66%] [G loss: 0.819454]\n",
      "epoch:26 step:24978 [D loss: 0.517955, acc.: 75.78%] [G loss: 1.135191]\n",
      "epoch:26 step:24979 [D loss: 0.523564, acc.: 75.78%] [G loss: 0.990510]\n",
      "epoch:26 step:24980 [D loss: 0.653522, acc.: 61.72%] [G loss: 1.106858]\n",
      "epoch:26 step:24981 [D loss: 0.630863, acc.: 69.53%] [G loss: 0.415881]\n",
      "epoch:26 step:24982 [D loss: 0.795837, acc.: 50.78%] [G loss: 1.028585]\n",
      "epoch:26 step:24983 [D loss: 0.572521, acc.: 75.00%] [G loss: 1.192112]\n",
      "epoch:26 step:24984 [D loss: 0.436992, acc.: 82.81%] [G loss: 1.126066]\n",
      "epoch:26 step:24985 [D loss: 0.530027, acc.: 77.34%] [G loss: 0.738940]\n",
      "epoch:26 step:24986 [D loss: 0.451268, acc.: 85.16%] [G loss: 1.123244]\n",
      "epoch:26 step:24987 [D loss: 0.669631, acc.: 59.38%] [G loss: 1.116238]\n",
      "epoch:26 step:24988 [D loss: 0.504661, acc.: 81.25%] [G loss: 0.933627]\n",
      "epoch:26 step:24989 [D loss: 0.650417, acc.: 61.72%] [G loss: 1.185741]\n",
      "epoch:26 step:24990 [D loss: 0.593148, acc.: 66.41%] [G loss: 1.130384]\n",
      "epoch:26 step:24991 [D loss: 0.547654, acc.: 70.31%] [G loss: 1.146648]\n",
      "epoch:26 step:24992 [D loss: 0.405438, acc.: 89.84%] [G loss: 1.170382]\n",
      "epoch:26 step:24993 [D loss: 0.558379, acc.: 77.34%] [G loss: 1.178526]\n",
      "epoch:26 step:24994 [D loss: 0.297099, acc.: 89.06%] [G loss: 1.161773]\n",
      "epoch:26 step:24995 [D loss: 0.298732, acc.: 88.28%] [G loss: 1.383702]\n",
      "epoch:26 step:24996 [D loss: 0.248331, acc.: 95.31%] [G loss: 1.732694]\n",
      "epoch:26 step:24997 [D loss: 0.230156, acc.: 96.88%] [G loss: 1.866414]\n",
      "epoch:26 step:24998 [D loss: 0.514999, acc.: 73.44%] [G loss: 1.536514]\n",
      "epoch:26 step:24999 [D loss: 0.469149, acc.: 80.47%] [G loss: 1.566770]\n",
      "epoch:26 step:25000 [D loss: 0.580884, acc.: 67.19%] [G loss: 1.542449]\n",
      "##############\n",
      "[4.50699944 2.79347374 6.91314785 6.16086987 4.68760376 6.09914193\n",
      " 5.19459643 5.94374375 5.89342363 5.33663672]\n",
      "##########\n",
      "epoch:26 step:25001 [D loss: 0.796496, acc.: 43.75%] [G loss: 1.548992]\n",
      "epoch:26 step:25002 [D loss: 0.921059, acc.: 37.50%] [G loss: 1.300370]\n",
      "epoch:26 step:25003 [D loss: 0.576275, acc.: 67.97%] [G loss: 0.989428]\n",
      "epoch:26 step:25004 [D loss: 0.721486, acc.: 53.12%] [G loss: 0.994828]\n",
      "epoch:26 step:25005 [D loss: 0.432920, acc.: 84.38%] [G loss: 1.103138]\n",
      "epoch:26 step:25006 [D loss: 0.268024, acc.: 91.41%] [G loss: 1.246255]\n",
      "epoch:26 step:25007 [D loss: 0.241177, acc.: 93.75%] [G loss: 1.117888]\n",
      "epoch:26 step:25008 [D loss: 0.218037, acc.: 93.75%] [G loss: 1.351104]\n",
      "epoch:26 step:25009 [D loss: 0.275521, acc.: 85.16%] [G loss: 1.299796]\n",
      "epoch:26 step:25010 [D loss: 0.189107, acc.: 96.88%] [G loss: 1.750264]\n",
      "epoch:26 step:25011 [D loss: 0.188945, acc.: 99.22%] [G loss: 1.795784]\n",
      "epoch:26 step:25012 [D loss: 0.144363, acc.: 98.44%] [G loss: 1.904601]\n",
      "epoch:26 step:25013 [D loss: 0.309166, acc.: 92.19%] [G loss: 1.524355]\n",
      "epoch:26 step:25014 [D loss: 0.570500, acc.: 72.66%] [G loss: 1.216420]\n",
      "epoch:26 step:25015 [D loss: 0.656279, acc.: 59.38%] [G loss: 1.031828]\n",
      "epoch:26 step:25016 [D loss: 0.591068, acc.: 75.00%] [G loss: 0.450659]\n",
      "epoch:26 step:25017 [D loss: 0.354701, acc.: 89.84%] [G loss: 0.716406]\n",
      "epoch:26 step:25018 [D loss: 0.444744, acc.: 82.03%] [G loss: 0.837958]\n",
      "epoch:26 step:25019 [D loss: 0.571118, acc.: 73.44%] [G loss: 1.490498]\n",
      "epoch:26 step:25020 [D loss: 0.637105, acc.: 60.94%] [G loss: 0.735904]\n",
      "epoch:26 step:25021 [D loss: 0.212254, acc.: 96.88%] [G loss: 1.358900]\n",
      "epoch:26 step:25022 [D loss: 0.284157, acc.: 88.28%] [G loss: 1.386369]\n",
      "epoch:26 step:25023 [D loss: 0.404905, acc.: 80.47%] [G loss: 0.299527]\n",
      "epoch:26 step:25024 [D loss: 0.590125, acc.: 68.75%] [G loss: 2.269810]\n",
      "epoch:26 step:25025 [D loss: 0.792988, acc.: 50.78%] [G loss: 1.188708]\n",
      "epoch:26 step:25026 [D loss: 0.518618, acc.: 71.09%] [G loss: 2.005120]\n",
      "epoch:26 step:25027 [D loss: 0.249549, acc.: 94.53%] [G loss: 1.794073]\n",
      "epoch:26 step:25028 [D loss: 0.978492, acc.: 42.97%] [G loss: 1.459744]\n",
      "epoch:26 step:25029 [D loss: 0.922054, acc.: 44.53%] [G loss: 1.148694]\n",
      "epoch:26 step:25030 [D loss: 0.611775, acc.: 60.94%] [G loss: 1.686860]\n",
      "epoch:26 step:25031 [D loss: 0.705879, acc.: 54.69%] [G loss: 0.657632]\n",
      "epoch:26 step:25032 [D loss: 0.816641, acc.: 46.09%] [G loss: 0.711662]\n",
      "epoch:26 step:25033 [D loss: 0.883179, acc.: 37.50%] [G loss: 1.040584]\n",
      "epoch:26 step:25034 [D loss: 0.841682, acc.: 43.75%] [G loss: 0.795646]\n",
      "epoch:26 step:25035 [D loss: 0.857110, acc.: 51.56%] [G loss: 1.201801]\n",
      "epoch:26 step:25036 [D loss: 0.553345, acc.: 71.09%] [G loss: 1.478531]\n",
      "epoch:26 step:25037 [D loss: 0.965252, acc.: 35.94%] [G loss: 1.151072]\n",
      "epoch:26 step:25038 [D loss: 0.567907, acc.: 69.53%] [G loss: 1.154565]\n",
      "epoch:26 step:25039 [D loss: 0.629229, acc.: 61.72%] [G loss: 1.259790]\n",
      "epoch:26 step:25040 [D loss: 0.627150, acc.: 64.84%] [G loss: 1.122593]\n",
      "epoch:26 step:25041 [D loss: 0.674888, acc.: 53.91%] [G loss: 1.152512]\n",
      "epoch:26 step:25042 [D loss: 0.625012, acc.: 64.84%] [G loss: 1.213432]\n",
      "epoch:26 step:25043 [D loss: 0.582540, acc.: 69.53%] [G loss: 1.100503]\n",
      "epoch:26 step:25044 [D loss: 0.634142, acc.: 60.94%] [G loss: 0.947607]\n",
      "epoch:26 step:25045 [D loss: 0.506606, acc.: 78.12%] [G loss: 1.110736]\n",
      "epoch:26 step:25046 [D loss: 0.450623, acc.: 80.47%] [G loss: 0.937884]\n",
      "epoch:26 step:25047 [D loss: 0.564930, acc.: 74.22%] [G loss: 1.026520]\n",
      "epoch:26 step:25048 [D loss: 0.413301, acc.: 82.81%] [G loss: 1.271952]\n",
      "epoch:26 step:25049 [D loss: 0.450943, acc.: 82.03%] [G loss: 1.462381]\n",
      "epoch:26 step:25050 [D loss: 0.583222, acc.: 70.31%] [G loss: 1.295923]\n",
      "epoch:26 step:25051 [D loss: 0.667836, acc.: 66.41%] [G loss: 1.054985]\n",
      "epoch:26 step:25052 [D loss: 0.523438, acc.: 71.88%] [G loss: 1.111587]\n",
      "epoch:26 step:25053 [D loss: 0.726295, acc.: 46.88%] [G loss: 1.176719]\n",
      "epoch:26 step:25054 [D loss: 0.604774, acc.: 70.31%] [G loss: 1.126924]\n",
      "epoch:26 step:25055 [D loss: 0.612041, acc.: 62.50%] [G loss: 0.922533]\n",
      "epoch:26 step:25056 [D loss: 0.533826, acc.: 71.88%] [G loss: 1.107389]\n",
      "epoch:26 step:25057 [D loss: 0.694436, acc.: 54.69%] [G loss: 0.952261]\n",
      "epoch:26 step:25058 [D loss: 0.270472, acc.: 92.97%] [G loss: 1.157012]\n",
      "epoch:26 step:25059 [D loss: 0.217362, acc.: 94.53%] [G loss: 1.333130]\n",
      "epoch:26 step:25060 [D loss: 0.290085, acc.: 91.41%] [G loss: 1.207194]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:25061 [D loss: 0.388646, acc.: 93.75%] [G loss: 1.302821]\n",
      "epoch:26 step:25062 [D loss: 0.177458, acc.: 97.66%] [G loss: 1.578124]\n",
      "epoch:26 step:25063 [D loss: 0.207160, acc.: 100.00%] [G loss: 1.839394]\n",
      "epoch:26 step:25064 [D loss: 0.286806, acc.: 96.09%] [G loss: 1.800519]\n",
      "epoch:26 step:25065 [D loss: 0.591680, acc.: 70.31%] [G loss: 1.576389]\n",
      "epoch:26 step:25066 [D loss: 0.294166, acc.: 93.75%] [G loss: 1.542065]\n",
      "epoch:26 step:25067 [D loss: 0.647846, acc.: 64.84%] [G loss: 1.484775]\n",
      "epoch:26 step:25068 [D loss: 0.435302, acc.: 71.88%] [G loss: 1.427253]\n",
      "epoch:26 step:25069 [D loss: 0.224087, acc.: 92.19%] [G loss: 1.594092]\n",
      "epoch:26 step:25070 [D loss: 0.131519, acc.: 100.00%] [G loss: 1.953421]\n",
      "epoch:26 step:25071 [D loss: 0.138795, acc.: 100.00%] [G loss: 2.016270]\n",
      "epoch:26 step:25072 [D loss: 0.745066, acc.: 62.50%] [G loss: 1.580231]\n",
      "epoch:26 step:25073 [D loss: 0.547038, acc.: 71.88%] [G loss: 1.921062]\n",
      "epoch:26 step:25074 [D loss: 0.764329, acc.: 53.91%] [G loss: 0.822354]\n",
      "epoch:26 step:25075 [D loss: 0.282592, acc.: 85.94%] [G loss: 1.583921]\n",
      "epoch:26 step:25076 [D loss: 0.183736, acc.: 96.88%] [G loss: 1.549845]\n",
      "epoch:26 step:25077 [D loss: 0.773310, acc.: 53.91%] [G loss: 1.466480]\n",
      "epoch:26 step:25078 [D loss: 0.833669, acc.: 50.00%] [G loss: 1.452810]\n",
      "epoch:26 step:25079 [D loss: 0.600341, acc.: 67.97%] [G loss: 1.150413]\n",
      "epoch:26 step:25080 [D loss: 0.604235, acc.: 68.75%] [G loss: 1.221517]\n",
      "epoch:26 step:25081 [D loss: 0.573062, acc.: 69.53%] [G loss: 1.189684]\n",
      "epoch:26 step:25082 [D loss: 0.562137, acc.: 66.41%] [G loss: 0.793815]\n",
      "epoch:26 step:25083 [D loss: 0.626638, acc.: 64.06%] [G loss: 1.071740]\n",
      "epoch:26 step:25084 [D loss: 0.393420, acc.: 84.38%] [G loss: 0.931657]\n",
      "epoch:26 step:25085 [D loss: 0.347947, acc.: 92.97%] [G loss: 0.491526]\n",
      "epoch:26 step:25086 [D loss: 0.768362, acc.: 46.88%] [G loss: 1.213233]\n",
      "epoch:26 step:25087 [D loss: 0.636372, acc.: 63.28%] [G loss: 1.434388]\n",
      "epoch:26 step:25088 [D loss: 0.594222, acc.: 67.19%] [G loss: 1.317937]\n",
      "epoch:26 step:25089 [D loss: 0.243589, acc.: 93.75%] [G loss: 1.432363]\n",
      "epoch:26 step:25090 [D loss: 0.206395, acc.: 94.53%] [G loss: 1.646296]\n",
      "epoch:26 step:25091 [D loss: 0.208356, acc.: 95.31%] [G loss: 1.513086]\n",
      "epoch:26 step:25092 [D loss: 0.109092, acc.: 99.22%] [G loss: 1.841450]\n",
      "epoch:26 step:25093 [D loss: 0.145069, acc.: 99.22%] [G loss: 1.847899]\n",
      "epoch:26 step:25094 [D loss: 0.147420, acc.: 98.44%] [G loss: 1.926048]\n",
      "epoch:26 step:25095 [D loss: 0.133419, acc.: 100.00%] [G loss: 1.732681]\n",
      "epoch:26 step:25096 [D loss: 0.764888, acc.: 55.47%] [G loss: 1.843714]\n",
      "epoch:26 step:25097 [D loss: 0.710784, acc.: 60.16%] [G loss: 1.589202]\n",
      "epoch:26 step:25098 [D loss: 0.706925, acc.: 58.59%] [G loss: 1.493475]\n",
      "epoch:26 step:25099 [D loss: 0.845232, acc.: 46.09%] [G loss: 1.199942]\n",
      "epoch:26 step:25100 [D loss: 0.656128, acc.: 57.03%] [G loss: 1.330961]\n",
      "epoch:26 step:25101 [D loss: 0.483210, acc.: 67.97%] [G loss: 1.369039]\n",
      "epoch:26 step:25102 [D loss: 0.490393, acc.: 79.69%] [G loss: 1.047008]\n",
      "epoch:26 step:25103 [D loss: 0.503302, acc.: 75.00%] [G loss: 1.421132]\n",
      "epoch:26 step:25104 [D loss: 0.330578, acc.: 92.19%] [G loss: 1.401086]\n",
      "epoch:26 step:25105 [D loss: 0.284912, acc.: 96.09%] [G loss: 1.717176]\n",
      "epoch:26 step:25106 [D loss: 0.473104, acc.: 78.12%] [G loss: 1.703712]\n",
      "epoch:26 step:25107 [D loss: 0.313898, acc.: 96.09%] [G loss: 1.386034]\n",
      "epoch:26 step:25108 [D loss: 0.274617, acc.: 96.88%] [G loss: 1.677282]\n",
      "epoch:26 step:25109 [D loss: 0.464236, acc.: 86.72%] [G loss: 1.348991]\n",
      "epoch:26 step:25110 [D loss: 0.619661, acc.: 60.94%] [G loss: 0.722643]\n",
      "epoch:26 step:25111 [D loss: 0.439144, acc.: 86.72%] [G loss: 1.368067]\n",
      "epoch:26 step:25112 [D loss: 0.327783, acc.: 93.75%] [G loss: 1.393479]\n",
      "epoch:26 step:25113 [D loss: 0.665061, acc.: 58.59%] [G loss: 1.284081]\n",
      "epoch:26 step:25114 [D loss: 0.521717, acc.: 73.44%] [G loss: 1.000345]\n",
      "epoch:26 step:25115 [D loss: 0.352736, acc.: 92.19%] [G loss: 1.367094]\n",
      "epoch:26 step:25116 [D loss: 0.363073, acc.: 75.00%] [G loss: 1.515922]\n",
      "epoch:26 step:25117 [D loss: 0.156631, acc.: 97.66%] [G loss: 1.095157]\n",
      "epoch:26 step:25118 [D loss: 0.222649, acc.: 91.41%] [G loss: 1.892869]\n",
      "epoch:26 step:25119 [D loss: 0.341645, acc.: 89.84%] [G loss: 1.866781]\n",
      "epoch:26 step:25120 [D loss: 0.567742, acc.: 68.75%] [G loss: 1.449739]\n",
      "epoch:26 step:25121 [D loss: 0.774748, acc.: 51.56%] [G loss: 1.710191]\n",
      "epoch:26 step:25122 [D loss: 0.614248, acc.: 66.41%] [G loss: 1.122750]\n",
      "epoch:26 step:25123 [D loss: 0.897479, acc.: 43.75%] [G loss: 1.473813]\n",
      "epoch:26 step:25124 [D loss: 0.489048, acc.: 76.56%] [G loss: 1.514560]\n",
      "epoch:26 step:25125 [D loss: 0.411555, acc.: 85.16%] [G loss: 1.491447]\n",
      "epoch:26 step:25126 [D loss: 0.228451, acc.: 91.41%] [G loss: 1.729874]\n",
      "epoch:26 step:25127 [D loss: 0.754297, acc.: 53.91%] [G loss: 1.254018]\n",
      "epoch:26 step:25128 [D loss: 0.747403, acc.: 57.03%] [G loss: 1.612499]\n",
      "epoch:26 step:25129 [D loss: 0.719403, acc.: 56.25%] [G loss: 1.092993]\n",
      "epoch:26 step:25130 [D loss: 0.358406, acc.: 78.91%] [G loss: 1.395190]\n",
      "epoch:26 step:25131 [D loss: 0.295875, acc.: 83.59%] [G loss: 1.719198]\n",
      "epoch:26 step:25132 [D loss: 0.579595, acc.: 68.75%] [G loss: 1.660715]\n",
      "epoch:26 step:25133 [D loss: 0.831060, acc.: 51.56%] [G loss: 1.542630]\n",
      "epoch:26 step:25134 [D loss: 0.912612, acc.: 38.28%] [G loss: 1.287717]\n",
      "epoch:26 step:25135 [D loss: 0.709484, acc.: 55.47%] [G loss: 0.782321]\n",
      "epoch:26 step:25136 [D loss: 0.203547, acc.: 94.53%] [G loss: 1.616257]\n",
      "epoch:26 step:25137 [D loss: 0.220842, acc.: 96.09%] [G loss: 1.306680]\n",
      "epoch:26 step:25138 [D loss: 0.747685, acc.: 57.03%] [G loss: 0.750148]\n",
      "epoch:26 step:25139 [D loss: 0.410931, acc.: 87.50%] [G loss: 1.077027]\n",
      "epoch:26 step:25140 [D loss: 0.768667, acc.: 46.09%] [G loss: 1.107202]\n",
      "epoch:26 step:25141 [D loss: 0.941316, acc.: 38.28%] [G loss: 1.032821]\n",
      "epoch:26 step:25142 [D loss: 0.197267, acc.: 99.22%] [G loss: 1.035071]\n",
      "epoch:26 step:25143 [D loss: 0.569547, acc.: 58.59%] [G loss: 1.549613]\n",
      "epoch:26 step:25144 [D loss: 0.262199, acc.: 88.28%] [G loss: 1.436973]\n",
      "epoch:26 step:25145 [D loss: 0.286823, acc.: 94.53%] [G loss: 1.134541]\n",
      "epoch:26 step:25146 [D loss: 0.279633, acc.: 96.09%] [G loss: 1.330758]\n",
      "epoch:26 step:25147 [D loss: 0.555322, acc.: 69.53%] [G loss: 1.791586]\n",
      "epoch:26 step:25148 [D loss: 0.139906, acc.: 99.22%] [G loss: 1.953632]\n",
      "epoch:26 step:25149 [D loss: 0.810246, acc.: 47.66%] [G loss: 1.738964]\n",
      "epoch:26 step:25150 [D loss: 0.395214, acc.: 88.28%] [G loss: 1.731130]\n",
      "epoch:26 step:25151 [D loss: 0.634651, acc.: 67.19%] [G loss: 1.462674]\n",
      "epoch:26 step:25152 [D loss: 0.403467, acc.: 85.94%] [G loss: 1.478485]\n",
      "epoch:26 step:25153 [D loss: 0.141488, acc.: 99.22%] [G loss: 1.448314]\n",
      "epoch:26 step:25154 [D loss: 0.141004, acc.: 100.00%] [G loss: 1.562050]\n",
      "epoch:26 step:25155 [D loss: 0.149260, acc.: 96.88%] [G loss: 2.106266]\n",
      "epoch:26 step:25156 [D loss: 0.097034, acc.: 100.00%] [G loss: 1.787507]\n",
      "epoch:26 step:25157 [D loss: 0.148195, acc.: 100.00%] [G loss: 1.773172]\n",
      "epoch:26 step:25158 [D loss: 0.091177, acc.: 100.00%] [G loss: 1.893278]\n",
      "epoch:26 step:25159 [D loss: 1.026353, acc.: 41.41%] [G loss: 1.910368]\n",
      "epoch:26 step:25160 [D loss: 0.212688, acc.: 97.66%] [G loss: 2.057653]\n",
      "epoch:26 step:25161 [D loss: 0.549984, acc.: 69.53%] [G loss: 1.590017]\n",
      "epoch:26 step:25162 [D loss: 0.902116, acc.: 56.25%] [G loss: 1.948328]\n",
      "epoch:26 step:25163 [D loss: 0.662498, acc.: 62.50%] [G loss: 1.494712]\n",
      "epoch:26 step:25164 [D loss: 0.507754, acc.: 75.78%] [G loss: 1.145677]\n",
      "epoch:26 step:25165 [D loss: 0.836489, acc.: 45.31%] [G loss: 1.316055]\n",
      "epoch:26 step:25166 [D loss: 0.166561, acc.: 97.66%] [G loss: 1.537500]\n",
      "epoch:26 step:25167 [D loss: 0.230603, acc.: 92.97%] [G loss: 1.868334]\n",
      "epoch:26 step:25168 [D loss: 0.134811, acc.: 98.44%] [G loss: 1.526350]\n",
      "epoch:26 step:25169 [D loss: 0.881363, acc.: 51.56%] [G loss: 1.529297]\n",
      "epoch:26 step:25170 [D loss: 0.676549, acc.: 60.94%] [G loss: 1.509957]\n",
      "epoch:26 step:25171 [D loss: 0.596182, acc.: 72.66%] [G loss: 1.434916]\n",
      "epoch:26 step:25172 [D loss: 0.686522, acc.: 57.03%] [G loss: 1.371474]\n",
      "epoch:26 step:25173 [D loss: 0.668461, acc.: 57.03%] [G loss: 1.235539]\n",
      "epoch:26 step:25174 [D loss: 0.262461, acc.: 95.31%] [G loss: 0.836222]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:25175 [D loss: 0.829317, acc.: 46.88%] [G loss: 1.341827]\n",
      "epoch:26 step:25176 [D loss: 0.756805, acc.: 52.34%] [G loss: 1.253977]\n",
      "epoch:26 step:25177 [D loss: 0.226596, acc.: 95.31%] [G loss: 1.336533]\n",
      "epoch:26 step:25178 [D loss: 1.029950, acc.: 24.22%] [G loss: 1.414441]\n",
      "epoch:26 step:25179 [D loss: 0.473155, acc.: 78.12%] [G loss: 1.406366]\n",
      "epoch:26 step:25180 [D loss: 0.811443, acc.: 49.22%] [G loss: 1.149541]\n",
      "epoch:26 step:25181 [D loss: 0.610118, acc.: 64.84%] [G loss: 1.164850]\n",
      "epoch:26 step:25182 [D loss: 0.795152, acc.: 43.75%] [G loss: 1.192322]\n",
      "epoch:26 step:25183 [D loss: 0.211170, acc.: 96.09%] [G loss: 0.965971]\n",
      "epoch:26 step:25184 [D loss: 0.221276, acc.: 97.66%] [G loss: 1.180958]\n",
      "epoch:26 step:25185 [D loss: 0.434184, acc.: 83.59%] [G loss: 1.236391]\n",
      "epoch:26 step:25186 [D loss: 0.655268, acc.: 58.59%] [G loss: 0.945853]\n",
      "epoch:26 step:25187 [D loss: 0.647354, acc.: 61.72%] [G loss: 1.177003]\n",
      "epoch:26 step:25188 [D loss: 0.552602, acc.: 70.31%] [G loss: 1.019588]\n",
      "epoch:26 step:25189 [D loss: 1.502974, acc.: 42.19%] [G loss: 1.142666]\n",
      "epoch:26 step:25190 [D loss: 0.529435, acc.: 70.31%] [G loss: 1.068814]\n",
      "epoch:26 step:25191 [D loss: 0.647114, acc.: 60.94%] [G loss: 1.357396]\n",
      "epoch:26 step:25192 [D loss: 1.063657, acc.: 29.69%] [G loss: 1.307676]\n",
      "epoch:26 step:25193 [D loss: 0.463193, acc.: 81.25%] [G loss: 1.102247]\n",
      "epoch:26 step:25194 [D loss: 0.427467, acc.: 84.38%] [G loss: 1.329702]\n",
      "epoch:26 step:25195 [D loss: 0.408299, acc.: 85.16%] [G loss: 1.359479]\n",
      "epoch:26 step:25196 [D loss: 0.278138, acc.: 96.88%] [G loss: 1.456948]\n",
      "epoch:26 step:25197 [D loss: 0.582210, acc.: 68.75%] [G loss: 1.316144]\n",
      "epoch:26 step:25198 [D loss: 0.710459, acc.: 57.03%] [G loss: 1.225533]\n",
      "epoch:26 step:25199 [D loss: 0.741758, acc.: 54.69%] [G loss: 1.153732]\n",
      "epoch:26 step:25200 [D loss: 0.656955, acc.: 59.38%] [G loss: 1.214086]\n",
      "##############\n",
      "[3.85436879 2.55611879 6.51961958 5.64640932 4.4738635  5.8619207\n",
      " 5.379944   6.00420726 5.66752283 5.04764147]\n",
      "##########\n",
      "epoch:26 step:25201 [D loss: 0.563961, acc.: 71.09%] [G loss: 0.878070]\n",
      "epoch:26 step:25202 [D loss: 0.538515, acc.: 70.31%] [G loss: 1.014574]\n",
      "epoch:26 step:25203 [D loss: 0.260535, acc.: 96.09%] [G loss: 1.103717]\n",
      "epoch:26 step:25204 [D loss: 0.326848, acc.: 94.53%] [G loss: 0.817726]\n",
      "epoch:26 step:25205 [D loss: 0.633759, acc.: 65.62%] [G loss: 1.148301]\n",
      "epoch:26 step:25206 [D loss: 1.039631, acc.: 51.56%] [G loss: 1.571912]\n",
      "epoch:26 step:25207 [D loss: 0.147467, acc.: 99.22%] [G loss: 1.488363]\n",
      "epoch:26 step:25208 [D loss: 0.795191, acc.: 55.47%] [G loss: 1.558957]\n",
      "epoch:26 step:25209 [D loss: 0.526458, acc.: 73.44%] [G loss: 1.508624]\n",
      "epoch:26 step:25210 [D loss: 0.556810, acc.: 75.78%] [G loss: 1.104020]\n",
      "epoch:26 step:25211 [D loss: 0.711694, acc.: 52.34%] [G loss: 1.360668]\n",
      "epoch:26 step:25212 [D loss: 0.505538, acc.: 79.69%] [G loss: 0.783772]\n",
      "epoch:26 step:25213 [D loss: 0.195786, acc.: 95.31%] [G loss: 1.210255]\n",
      "epoch:26 step:25214 [D loss: 0.228448, acc.: 96.88%] [G loss: 0.913886]\n",
      "epoch:26 step:25215 [D loss: 0.317898, acc.: 83.59%] [G loss: 1.536309]\n",
      "epoch:26 step:25216 [D loss: 0.300135, acc.: 87.50%] [G loss: 1.707960]\n",
      "epoch:26 step:25217 [D loss: 0.825424, acc.: 42.19%] [G loss: 1.807207]\n",
      "epoch:26 step:25218 [D loss: 0.842396, acc.: 54.69%] [G loss: 1.184491]\n",
      "epoch:26 step:25219 [D loss: 0.448244, acc.: 82.03%] [G loss: 1.238271]\n",
      "epoch:26 step:25220 [D loss: 0.447594, acc.: 70.31%] [G loss: 0.675276]\n",
      "epoch:26 step:25221 [D loss: 0.519859, acc.: 68.75%] [G loss: 1.064349]\n",
      "epoch:26 step:25222 [D loss: 0.117087, acc.: 99.22%] [G loss: 1.955683]\n",
      "epoch:26 step:25223 [D loss: 1.095190, acc.: 49.22%] [G loss: 1.196456]\n",
      "epoch:26 step:25224 [D loss: 0.979087, acc.: 43.75%] [G loss: 1.809448]\n",
      "epoch:26 step:25225 [D loss: 0.646379, acc.: 59.38%] [G loss: 1.715466]\n",
      "epoch:26 step:25226 [D loss: 0.452581, acc.: 75.78%] [G loss: 1.393601]\n",
      "epoch:26 step:25227 [D loss: 0.761755, acc.: 52.34%] [G loss: 1.552111]\n",
      "epoch:26 step:25228 [D loss: 0.600198, acc.: 64.84%] [G loss: 1.356306]\n",
      "epoch:26 step:25229 [D loss: 0.730661, acc.: 54.69%] [G loss: 1.304781]\n",
      "epoch:26 step:25230 [D loss: 0.385654, acc.: 88.28%] [G loss: 1.409563]\n",
      "epoch:26 step:25231 [D loss: 0.528394, acc.: 80.47%] [G loss: 1.449455]\n",
      "epoch:26 step:25232 [D loss: 0.211360, acc.: 95.31%] [G loss: 1.425139]\n",
      "epoch:26 step:25233 [D loss: 0.382053, acc.: 89.06%] [G loss: 1.506170]\n",
      "epoch:26 step:25234 [D loss: 0.718909, acc.: 57.81%] [G loss: 1.358662]\n",
      "epoch:26 step:25235 [D loss: 0.429897, acc.: 82.03%] [G loss: 1.242085]\n",
      "epoch:26 step:25236 [D loss: 0.254435, acc.: 93.75%] [G loss: 1.644824]\n",
      "epoch:26 step:25237 [D loss: 0.373608, acc.: 89.06%] [G loss: 1.316776]\n",
      "epoch:26 step:25238 [D loss: 0.169961, acc.: 97.66%] [G loss: 1.353111]\n",
      "epoch:26 step:25239 [D loss: 0.119874, acc.: 100.00%] [G loss: 1.534192]\n",
      "epoch:26 step:25240 [D loss: 0.413918, acc.: 74.22%] [G loss: 1.544047]\n",
      "epoch:26 step:25241 [D loss: 0.370615, acc.: 86.72%] [G loss: 2.277700]\n",
      "epoch:26 step:25242 [D loss: 0.900260, acc.: 35.94%] [G loss: 1.416426]\n",
      "epoch:26 step:25243 [D loss: 0.548153, acc.: 73.44%] [G loss: 1.719815]\n",
      "epoch:26 step:25244 [D loss: 1.216226, acc.: 25.78%] [G loss: 0.830280]\n",
      "epoch:26 step:25245 [D loss: 1.109280, acc.: 33.59%] [G loss: 1.417824]\n",
      "epoch:26 step:25246 [D loss: 1.398089, acc.: 10.16%] [G loss: 1.320391]\n",
      "epoch:26 step:25247 [D loss: 0.803227, acc.: 47.66%] [G loss: 1.453485]\n",
      "epoch:26 step:25248 [D loss: 0.596314, acc.: 71.09%] [G loss: 1.189133]\n",
      "epoch:26 step:25249 [D loss: 0.483319, acc.: 78.12%] [G loss: 1.349067]\n",
      "epoch:26 step:25250 [D loss: 0.795536, acc.: 46.09%] [G loss: 1.317792]\n",
      "epoch:26 step:25251 [D loss: 0.428223, acc.: 82.81%] [G loss: 1.101784]\n",
      "epoch:26 step:25252 [D loss: 0.422141, acc.: 90.62%] [G loss: 1.459074]\n",
      "epoch:26 step:25253 [D loss: 0.574891, acc.: 70.31%] [G loss: 1.226927]\n",
      "epoch:26 step:25254 [D loss: 0.442917, acc.: 85.94%] [G loss: 1.150349]\n",
      "epoch:26 step:25255 [D loss: 0.377542, acc.: 91.41%] [G loss: 1.242693]\n",
      "epoch:26 step:25256 [D loss: 0.358957, acc.: 90.62%] [G loss: 1.127535]\n",
      "epoch:26 step:25257 [D loss: 0.373635, acc.: 94.53%] [G loss: 1.179789]\n",
      "epoch:26 step:25258 [D loss: 0.347879, acc.: 96.88%] [G loss: 1.441857]\n",
      "epoch:26 step:25259 [D loss: 0.808067, acc.: 50.78%] [G loss: 1.181873]\n",
      "epoch:26 step:25260 [D loss: 0.161976, acc.: 99.22%] [G loss: 1.342078]\n",
      "epoch:26 step:25261 [D loss: 0.445877, acc.: 71.09%] [G loss: 1.508493]\n",
      "epoch:26 step:25262 [D loss: 0.110490, acc.: 100.00%] [G loss: 1.660229]\n",
      "epoch:26 step:25263 [D loss: 0.390542, acc.: 88.28%] [G loss: 1.835452]\n",
      "epoch:26 step:25264 [D loss: 0.712488, acc.: 55.47%] [G loss: 1.063278]\n",
      "epoch:26 step:25265 [D loss: 0.569499, acc.: 69.53%] [G loss: 1.493405]\n",
      "epoch:26 step:25266 [D loss: 0.588647, acc.: 71.09%] [G loss: 1.175078]\n",
      "epoch:26 step:25267 [D loss: 0.447600, acc.: 82.81%] [G loss: 0.047497]\n",
      "epoch:26 step:25268 [D loss: 0.272113, acc.: 94.53%] [G loss: 1.841725]\n",
      "epoch:26 step:25269 [D loss: 0.687826, acc.: 56.25%] [G loss: 1.179620]\n",
      "epoch:26 step:25270 [D loss: 0.667868, acc.: 57.81%] [G loss: 1.752715]\n",
      "epoch:26 step:25271 [D loss: 0.565098, acc.: 66.41%] [G loss: 1.264749]\n",
      "epoch:26 step:25272 [D loss: 0.373676, acc.: 89.06%] [G loss: 1.174983]\n",
      "epoch:26 step:25273 [D loss: 0.434492, acc.: 79.69%] [G loss: 1.312295]\n",
      "epoch:26 step:25274 [D loss: 0.271535, acc.: 89.06%] [G loss: 1.383803]\n",
      "epoch:26 step:25275 [D loss: 0.671710, acc.: 51.56%] [G loss: 1.331517]\n",
      "epoch:26 step:25276 [D loss: 0.858956, acc.: 39.84%] [G loss: 1.757939]\n",
      "epoch:26 step:25277 [D loss: 0.743117, acc.: 53.91%] [G loss: 1.104726]\n",
      "epoch:26 step:25278 [D loss: 0.361578, acc.: 89.06%] [G loss: 1.757426]\n",
      "epoch:26 step:25279 [D loss: 0.348720, acc.: 76.56%] [G loss: 1.880641]\n",
      "epoch:26 step:25280 [D loss: 0.697492, acc.: 57.81%] [G loss: 1.390141]\n",
      "epoch:26 step:25281 [D loss: 0.439082, acc.: 79.69%] [G loss: 1.621845]\n",
      "epoch:26 step:25282 [D loss: 0.201333, acc.: 92.19%] [G loss: 1.727844]\n",
      "epoch:26 step:25283 [D loss: 0.145108, acc.: 97.66%] [G loss: 1.920997]\n",
      "epoch:26 step:25284 [D loss: 0.587558, acc.: 67.97%] [G loss: 1.794913]\n",
      "epoch:26 step:25285 [D loss: 0.678890, acc.: 57.03%] [G loss: 1.644421]\n",
      "epoch:26 step:25286 [D loss: 0.513550, acc.: 72.66%] [G loss: 1.150052]\n",
      "epoch:26 step:25287 [D loss: 0.558027, acc.: 71.88%] [G loss: 1.258407]\n",
      "epoch:26 step:25288 [D loss: 0.476997, acc.: 77.34%] [G loss: 1.225577]\n",
      "epoch:26 step:25289 [D loss: 0.360714, acc.: 89.06%] [G loss: 1.387906]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:25290 [D loss: 0.521887, acc.: 76.56%] [G loss: 1.424254]\n",
      "epoch:26 step:25291 [D loss: 0.225523, acc.: 91.41%] [G loss: 1.507930]\n",
      "epoch:26 step:25292 [D loss: 0.199586, acc.: 92.19%] [G loss: 0.987158]\n",
      "epoch:26 step:25293 [D loss: 0.270176, acc.: 89.84%] [G loss: 1.717139]\n",
      "epoch:26 step:25294 [D loss: 0.673819, acc.: 61.72%] [G loss: 1.257875]\n",
      "epoch:26 step:25295 [D loss: 0.637626, acc.: 60.94%] [G loss: 1.726206]\n",
      "epoch:26 step:25296 [D loss: 0.440637, acc.: 86.72%] [G loss: 1.137294]\n",
      "epoch:26 step:25297 [D loss: 0.829471, acc.: 47.66%] [G loss: 1.413322]\n",
      "epoch:26 step:25298 [D loss: 0.349295, acc.: 92.97%] [G loss: 1.269432]\n",
      "epoch:26 step:25299 [D loss: 0.221341, acc.: 91.41%] [G loss: 1.172001]\n",
      "epoch:27 step:25300 [D loss: 0.754360, acc.: 51.56%] [G loss: 1.389522]\n",
      "epoch:27 step:25301 [D loss: 0.763481, acc.: 49.22%] [G loss: 1.111442]\n",
      "epoch:27 step:25302 [D loss: 0.729252, acc.: 57.03%] [G loss: 0.991710]\n",
      "epoch:27 step:25303 [D loss: 0.574209, acc.: 71.88%] [G loss: 1.133668]\n",
      "epoch:27 step:25304 [D loss: 0.463976, acc.: 77.34%] [G loss: 0.989586]\n",
      "epoch:27 step:25305 [D loss: 0.666639, acc.: 60.16%] [G loss: 1.072817]\n",
      "epoch:27 step:25306 [D loss: 0.660083, acc.: 63.28%] [G loss: 1.199468]\n",
      "epoch:27 step:25307 [D loss: 0.728525, acc.: 52.34%] [G loss: 0.934888]\n",
      "epoch:27 step:25308 [D loss: 0.578002, acc.: 71.09%] [G loss: 1.015628]\n",
      "epoch:27 step:25309 [D loss: 0.455561, acc.: 81.25%] [G loss: 1.145467]\n",
      "epoch:27 step:25310 [D loss: 0.635293, acc.: 66.41%] [G loss: 0.905954]\n",
      "epoch:27 step:25311 [D loss: 0.547823, acc.: 70.31%] [G loss: 1.115258]\n",
      "epoch:27 step:25312 [D loss: 0.478584, acc.: 81.25%] [G loss: 0.909167]\n",
      "epoch:27 step:25313 [D loss: 0.546902, acc.: 73.44%] [G loss: 1.060224]\n",
      "epoch:27 step:25314 [D loss: 0.393854, acc.: 78.12%] [G loss: 1.375102]\n",
      "epoch:27 step:25315 [D loss: 0.344980, acc.: 94.53%] [G loss: 1.065940]\n",
      "epoch:27 step:25316 [D loss: 0.508614, acc.: 82.03%] [G loss: 0.672588]\n",
      "epoch:27 step:25317 [D loss: 0.437465, acc.: 85.94%] [G loss: 1.027495]\n",
      "epoch:27 step:25318 [D loss: 0.624846, acc.: 60.16%] [G loss: 0.604989]\n",
      "epoch:27 step:25319 [D loss: 0.409588, acc.: 87.50%] [G loss: 1.059099]\n",
      "epoch:27 step:25320 [D loss: 0.715655, acc.: 57.03%] [G loss: 1.274352]\n",
      "epoch:27 step:25321 [D loss: 0.573320, acc.: 68.75%] [G loss: 0.841921]\n",
      "epoch:27 step:25322 [D loss: 1.609055, acc.: 45.31%] [G loss: 1.182814]\n",
      "epoch:27 step:25323 [D loss: 0.495590, acc.: 73.44%] [G loss: 1.573105]\n",
      "epoch:27 step:25324 [D loss: 0.375208, acc.: 85.94%] [G loss: 1.481458]\n",
      "epoch:27 step:25325 [D loss: 0.687331, acc.: 59.38%] [G loss: 1.255456]\n",
      "epoch:27 step:25326 [D loss: 0.245194, acc.: 92.19%] [G loss: 0.918430]\n",
      "epoch:27 step:25327 [D loss: 0.417057, acc.: 83.59%] [G loss: 1.282733]\n",
      "epoch:27 step:25328 [D loss: 0.474845, acc.: 81.25%] [G loss: 1.445765]\n",
      "epoch:27 step:25329 [D loss: 0.580875, acc.: 68.75%] [G loss: 1.534861]\n",
      "epoch:27 step:25330 [D loss: 0.272891, acc.: 85.94%] [G loss: 1.922731]\n",
      "epoch:27 step:25331 [D loss: 0.254686, acc.: 85.94%] [G loss: 1.842527]\n",
      "epoch:27 step:25332 [D loss: 0.096432, acc.: 100.00%] [G loss: 2.296202]\n",
      "epoch:27 step:25333 [D loss: 0.089592, acc.: 100.00%] [G loss: 2.104493]\n",
      "epoch:27 step:25334 [D loss: 0.069765, acc.: 100.00%] [G loss: 2.197661]\n",
      "epoch:27 step:25335 [D loss: 0.133463, acc.: 97.66%] [G loss: 2.534942]\n",
      "epoch:27 step:25336 [D loss: 1.066798, acc.: 49.22%] [G loss: 1.595957]\n",
      "epoch:27 step:25337 [D loss: 0.873511, acc.: 57.03%] [G loss: 1.407274]\n",
      "epoch:27 step:25338 [D loss: 0.853081, acc.: 46.09%] [G loss: 1.267181]\n",
      "epoch:27 step:25339 [D loss: 0.628748, acc.: 61.72%] [G loss: 0.930107]\n",
      "epoch:27 step:25340 [D loss: 0.623380, acc.: 66.41%] [G loss: 1.245762]\n",
      "epoch:27 step:25341 [D loss: 0.290907, acc.: 94.53%] [G loss: 1.106857]\n",
      "epoch:27 step:25342 [D loss: 0.273814, acc.: 92.97%] [G loss: 1.516467]\n",
      "epoch:27 step:25343 [D loss: 0.312034, acc.: 95.31%] [G loss: 0.579505]\n",
      "epoch:27 step:25344 [D loss: 0.517528, acc.: 68.75%] [G loss: 0.922582]\n",
      "epoch:27 step:25345 [D loss: 0.374253, acc.: 89.06%] [G loss: 1.222426]\n",
      "epoch:27 step:25346 [D loss: 0.571847, acc.: 67.97%] [G loss: 1.127422]\n",
      "epoch:27 step:25347 [D loss: 0.741970, acc.: 54.69%] [G loss: 1.186270]\n",
      "epoch:27 step:25348 [D loss: 0.657376, acc.: 57.03%] [G loss: 1.098747]\n",
      "epoch:27 step:25349 [D loss: 0.647062, acc.: 65.62%] [G loss: 0.817483]\n",
      "epoch:27 step:25350 [D loss: 0.326975, acc.: 80.47%] [G loss: 1.257016]\n",
      "epoch:27 step:25351 [D loss: 0.253023, acc.: 95.31%] [G loss: 0.801463]\n",
      "epoch:27 step:25352 [D loss: 0.588741, acc.: 66.41%] [G loss: 1.512728]\n",
      "epoch:27 step:25353 [D loss: 0.777636, acc.: 45.31%] [G loss: 1.386586]\n",
      "epoch:27 step:25354 [D loss: 0.787812, acc.: 49.22%] [G loss: 1.162748]\n",
      "epoch:27 step:25355 [D loss: 0.559202, acc.: 67.97%] [G loss: 0.988044]\n",
      "epoch:27 step:25356 [D loss: 0.623842, acc.: 59.38%] [G loss: 1.231641]\n",
      "epoch:27 step:25357 [D loss: 0.162359, acc.: 97.66%] [G loss: 1.507593]\n",
      "epoch:27 step:25358 [D loss: 0.224799, acc.: 96.88%] [G loss: 1.294655]\n",
      "epoch:27 step:25359 [D loss: 0.232145, acc.: 98.44%] [G loss: 1.879229]\n",
      "epoch:27 step:25360 [D loss: 0.613487, acc.: 64.84%] [G loss: 1.102788]\n",
      "epoch:27 step:25361 [D loss: 0.698799, acc.: 62.50%] [G loss: 1.108094]\n",
      "epoch:27 step:25362 [D loss: 0.437348, acc.: 86.72%] [G loss: 0.943179]\n",
      "epoch:27 step:25363 [D loss: 0.891381, acc.: 41.41%] [G loss: 0.815012]\n",
      "epoch:27 step:25364 [D loss: 1.062418, acc.: 20.31%] [G loss: 0.922045]\n",
      "epoch:27 step:25365 [D loss: 1.776190, acc.: 40.62%] [G loss: 0.704317]\n",
      "epoch:27 step:25366 [D loss: 0.752802, acc.: 54.69%] [G loss: 1.149749]\n",
      "epoch:27 step:25367 [D loss: 0.891166, acc.: 50.00%] [G loss: 1.388524]\n",
      "epoch:27 step:25368 [D loss: 0.979122, acc.: 39.06%] [G loss: 0.936799]\n",
      "epoch:27 step:25369 [D loss: 0.816182, acc.: 51.56%] [G loss: 1.028357]\n",
      "epoch:27 step:25370 [D loss: 0.285202, acc.: 88.28%] [G loss: 0.863671]\n",
      "epoch:27 step:25371 [D loss: 0.492649, acc.: 82.03%] [G loss: 0.700074]\n",
      "epoch:27 step:25372 [D loss: 0.321566, acc.: 95.31%] [G loss: 1.280788]\n",
      "epoch:27 step:25373 [D loss: 0.847348, acc.: 40.62%] [G loss: 0.961125]\n",
      "epoch:27 step:25374 [D loss: 0.131407, acc.: 98.44%] [G loss: 1.177656]\n",
      "epoch:27 step:25375 [D loss: 0.989540, acc.: 51.56%] [G loss: 1.459044]\n",
      "epoch:27 step:25376 [D loss: 0.593020, acc.: 67.97%] [G loss: 2.007349]\n",
      "epoch:27 step:25377 [D loss: 1.039507, acc.: 49.22%] [G loss: 1.248390]\n",
      "epoch:27 step:25378 [D loss: 0.941367, acc.: 51.56%] [G loss: 1.452720]\n",
      "epoch:27 step:25379 [D loss: 0.763382, acc.: 54.69%] [G loss: 1.746869]\n",
      "epoch:27 step:25380 [D loss: 0.569484, acc.: 69.53%] [G loss: 1.620485]\n",
      "epoch:27 step:25381 [D loss: 0.479234, acc.: 77.34%] [G loss: 1.638846]\n",
      "epoch:27 step:25382 [D loss: 0.320391, acc.: 93.75%] [G loss: 1.596125]\n",
      "epoch:27 step:25383 [D loss: 0.613772, acc.: 65.62%] [G loss: 1.420477]\n",
      "epoch:27 step:25384 [D loss: 0.615251, acc.: 66.41%] [G loss: 1.455743]\n",
      "epoch:27 step:25385 [D loss: 0.633661, acc.: 59.38%] [G loss: 1.590950]\n",
      "epoch:27 step:25386 [D loss: 0.465785, acc.: 79.69%] [G loss: 1.471219]\n",
      "epoch:27 step:25387 [D loss: 0.405828, acc.: 91.41%] [G loss: 1.492762]\n",
      "epoch:27 step:25388 [D loss: 0.433448, acc.: 93.75%] [G loss: 1.327579]\n",
      "epoch:27 step:25389 [D loss: 0.376117, acc.: 91.41%] [G loss: 1.360730]\n",
      "epoch:27 step:25390 [D loss: 0.431522, acc.: 80.47%] [G loss: 1.358365]\n",
      "epoch:27 step:25391 [D loss: 0.259300, acc.: 98.44%] [G loss: 1.589189]\n",
      "epoch:27 step:25392 [D loss: 0.209285, acc.: 96.88%] [G loss: 1.718687]\n",
      "epoch:27 step:25393 [D loss: 0.262408, acc.: 98.44%] [G loss: 1.946394]\n",
      "epoch:27 step:25394 [D loss: 0.607653, acc.: 64.06%] [G loss: 1.489879]\n",
      "epoch:27 step:25395 [D loss: 0.360838, acc.: 92.19%] [G loss: 1.236919]\n",
      "epoch:27 step:25396 [D loss: 0.441689, acc.: 88.28%] [G loss: 1.471458]\n",
      "epoch:27 step:25397 [D loss: 0.770220, acc.: 51.56%] [G loss: 1.039693]\n",
      "epoch:27 step:25398 [D loss: 0.558307, acc.: 74.22%] [G loss: 1.106403]\n",
      "epoch:27 step:25399 [D loss: 0.611650, acc.: 61.72%] [G loss: 0.876395]\n",
      "epoch:27 step:25400 [D loss: 0.332501, acc.: 87.50%] [G loss: 0.894747]\n",
      "##############\n",
      "[4.29241056 2.46024864 6.99258911 5.33791373 4.92774668 5.74215502\n",
      " 5.2948075  5.45902386 5.75120873 5.15359415]\n",
      "##########\n",
      "epoch:27 step:25401 [D loss: 0.607331, acc.: 69.53%] [G loss: 1.399802]\n",
      "epoch:27 step:25402 [D loss: 0.544893, acc.: 75.78%] [G loss: 1.327860]\n",
      "epoch:27 step:25403 [D loss: 0.526033, acc.: 77.34%] [G loss: 1.181253]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25404 [D loss: 0.934615, acc.: 42.19%] [G loss: 0.877219]\n",
      "epoch:27 step:25405 [D loss: 0.672435, acc.: 63.28%] [G loss: 0.591447]\n",
      "epoch:27 step:25406 [D loss: 0.707266, acc.: 52.34%] [G loss: 0.875259]\n",
      "epoch:27 step:25407 [D loss: 0.798474, acc.: 48.44%] [G loss: 1.054962]\n",
      "epoch:27 step:25408 [D loss: 0.687607, acc.: 59.38%] [G loss: 0.795050]\n",
      "epoch:27 step:25409 [D loss: 0.667299, acc.: 57.81%] [G loss: 1.061665]\n",
      "epoch:27 step:25410 [D loss: 0.295110, acc.: 89.84%] [G loss: 0.944908]\n",
      "epoch:27 step:25411 [D loss: 0.329009, acc.: 89.06%] [G loss: 0.805333]\n",
      "epoch:27 step:25412 [D loss: 0.428095, acc.: 74.22%] [G loss: 1.172994]\n",
      "epoch:27 step:25413 [D loss: 0.478088, acc.: 67.97%] [G loss: 1.210433]\n",
      "epoch:27 step:25414 [D loss: 0.221053, acc.: 97.66%] [G loss: 1.683564]\n",
      "epoch:27 step:25415 [D loss: 0.673623, acc.: 57.81%] [G loss: 1.480236]\n",
      "epoch:27 step:25416 [D loss: 0.906441, acc.: 49.22%] [G loss: 1.779264]\n",
      "epoch:27 step:25417 [D loss: 1.060352, acc.: 32.81%] [G loss: 1.435658]\n",
      "epoch:27 step:25418 [D loss: 0.606035, acc.: 68.75%] [G loss: 1.291561]\n",
      "epoch:27 step:25419 [D loss: 0.319267, acc.: 88.28%] [G loss: 0.768328]\n",
      "epoch:27 step:25420 [D loss: 0.268229, acc.: 89.84%] [G loss: 1.187474]\n",
      "epoch:27 step:25421 [D loss: 0.213086, acc.: 96.88%] [G loss: 0.812328]\n",
      "epoch:27 step:25422 [D loss: 0.552345, acc.: 68.75%] [G loss: 1.132687]\n",
      "epoch:27 step:25423 [D loss: 0.913084, acc.: 39.06%] [G loss: 1.012110]\n",
      "epoch:27 step:25424 [D loss: 0.912755, acc.: 39.06%] [G loss: 0.717632]\n",
      "epoch:27 step:25425 [D loss: 0.889027, acc.: 34.38%] [G loss: 1.115794]\n",
      "epoch:27 step:25426 [D loss: 0.900198, acc.: 38.28%] [G loss: 1.450723]\n",
      "epoch:27 step:25427 [D loss: 0.665058, acc.: 58.59%] [G loss: 1.332430]\n",
      "epoch:27 step:25428 [D loss: 0.544908, acc.: 74.22%] [G loss: 1.309793]\n",
      "epoch:27 step:25429 [D loss: 0.306239, acc.: 95.31%] [G loss: 0.930535]\n",
      "epoch:27 step:25430 [D loss: 0.337669, acc.: 92.19%] [G loss: 1.275063]\n",
      "epoch:27 step:25431 [D loss: 0.451201, acc.: 78.12%] [G loss: 1.016657]\n",
      "epoch:27 step:25432 [D loss: 0.629993, acc.: 67.19%] [G loss: 0.970902]\n",
      "epoch:27 step:25433 [D loss: 0.645930, acc.: 55.47%] [G loss: 1.063332]\n",
      "epoch:27 step:25434 [D loss: 0.497015, acc.: 75.78%] [G loss: 1.205223]\n",
      "epoch:27 step:25435 [D loss: 0.873519, acc.: 40.62%] [G loss: 1.678526]\n",
      "epoch:27 step:25436 [D loss: 0.785246, acc.: 45.31%] [G loss: 1.757722]\n",
      "epoch:27 step:25437 [D loss: 0.628982, acc.: 65.62%] [G loss: 1.243501]\n",
      "epoch:27 step:25438 [D loss: 0.443127, acc.: 83.59%] [G loss: 1.411347]\n",
      "epoch:27 step:25439 [D loss: 1.008492, acc.: 54.69%] [G loss: 1.413956]\n",
      "epoch:27 step:25440 [D loss: 0.367729, acc.: 90.62%] [G loss: 1.688959]\n",
      "epoch:27 step:25441 [D loss: 0.356622, acc.: 92.97%] [G loss: 1.794118]\n",
      "epoch:27 step:25442 [D loss: 0.183338, acc.: 98.44%] [G loss: 2.326528]\n",
      "epoch:27 step:25443 [D loss: 0.229032, acc.: 95.31%] [G loss: 2.209612]\n",
      "epoch:27 step:25444 [D loss: 0.172990, acc.: 96.88%] [G loss: 1.866101]\n",
      "epoch:27 step:25445 [D loss: 0.313132, acc.: 90.62%] [G loss: 1.924936]\n",
      "epoch:27 step:25446 [D loss: 0.472638, acc.: 78.12%] [G loss: 1.528347]\n",
      "epoch:27 step:25447 [D loss: 0.552189, acc.: 74.22%] [G loss: 2.088911]\n",
      "epoch:27 step:25448 [D loss: 0.232788, acc.: 95.31%] [G loss: 1.294772]\n",
      "epoch:27 step:25449 [D loss: 0.144815, acc.: 98.44%] [G loss: 1.475707]\n",
      "epoch:27 step:25450 [D loss: 0.185793, acc.: 94.53%] [G loss: 1.654467]\n",
      "epoch:27 step:25451 [D loss: 0.165844, acc.: 97.66%] [G loss: 1.595395]\n",
      "epoch:27 step:25452 [D loss: 0.652709, acc.: 61.72%] [G loss: 1.223181]\n",
      "epoch:27 step:25453 [D loss: 0.525862, acc.: 75.78%] [G loss: 1.392278]\n",
      "epoch:27 step:25454 [D loss: 0.643595, acc.: 64.84%] [G loss: 1.539998]\n",
      "epoch:27 step:25455 [D loss: 0.891080, acc.: 42.97%] [G loss: 1.345766]\n",
      "epoch:27 step:25456 [D loss: 0.569236, acc.: 71.09%] [G loss: 0.887274]\n",
      "epoch:27 step:25457 [D loss: 1.101830, acc.: 34.38%] [G loss: 1.183255]\n",
      "epoch:27 step:25458 [D loss: 0.819532, acc.: 48.44%] [G loss: 1.469850]\n",
      "epoch:27 step:25459 [D loss: 0.566918, acc.: 69.53%] [G loss: 1.049215]\n",
      "epoch:27 step:25460 [D loss: 0.538125, acc.: 73.44%] [G loss: 1.188166]\n",
      "epoch:27 step:25461 [D loss: 0.469769, acc.: 76.56%] [G loss: 1.052992]\n",
      "epoch:27 step:25462 [D loss: 0.356641, acc.: 93.75%] [G loss: 0.915664]\n",
      "epoch:27 step:25463 [D loss: 0.388332, acc.: 89.06%] [G loss: 1.451881]\n",
      "epoch:27 step:25464 [D loss: 0.452349, acc.: 84.38%] [G loss: 0.983108]\n",
      "epoch:27 step:25465 [D loss: 0.900566, acc.: 43.75%] [G loss: 0.953117]\n",
      "epoch:27 step:25466 [D loss: 0.872323, acc.: 32.03%] [G loss: 0.944514]\n",
      "epoch:27 step:25467 [D loss: 0.832832, acc.: 46.88%] [G loss: 1.011850]\n",
      "epoch:27 step:25468 [D loss: 0.737971, acc.: 56.25%] [G loss: 1.077445]\n",
      "epoch:27 step:25469 [D loss: 0.462849, acc.: 82.03%] [G loss: 0.968263]\n",
      "epoch:27 step:25470 [D loss: 0.751108, acc.: 49.22%] [G loss: 0.813760]\n",
      "epoch:27 step:25471 [D loss: 0.790175, acc.: 43.75%] [G loss: 1.201921]\n",
      "epoch:27 step:25472 [D loss: 0.665496, acc.: 64.06%] [G loss: 0.715217]\n",
      "epoch:27 step:25473 [D loss: 0.695987, acc.: 52.34%] [G loss: 0.980741]\n",
      "epoch:27 step:25474 [D loss: 0.661226, acc.: 59.38%] [G loss: 1.009381]\n",
      "epoch:27 step:25475 [D loss: 0.804772, acc.: 46.09%] [G loss: 0.959940]\n",
      "epoch:27 step:25476 [D loss: 0.836659, acc.: 37.50%] [G loss: 0.644994]\n",
      "epoch:27 step:25477 [D loss: 0.423378, acc.: 89.06%] [G loss: 0.799357]\n",
      "epoch:27 step:25478 [D loss: 0.517365, acc.: 75.00%] [G loss: 1.021448]\n",
      "epoch:27 step:25479 [D loss: 0.669562, acc.: 58.59%] [G loss: 1.195930]\n",
      "epoch:27 step:25480 [D loss: 1.348165, acc.: 19.53%] [G loss: 0.385089]\n",
      "epoch:27 step:25481 [D loss: 0.763765, acc.: 51.56%] [G loss: 1.096324]\n",
      "epoch:27 step:25482 [D loss: 0.734410, acc.: 58.59%] [G loss: 1.462652]\n",
      "epoch:27 step:25483 [D loss: 0.667619, acc.: 60.94%] [G loss: 1.106847]\n",
      "epoch:27 step:25484 [D loss: 0.577062, acc.: 70.31%] [G loss: 1.049265]\n",
      "epoch:27 step:25485 [D loss: 0.601680, acc.: 67.97%] [G loss: 1.177190]\n",
      "epoch:27 step:25486 [D loss: 0.658551, acc.: 60.16%] [G loss: 1.191290]\n",
      "epoch:27 step:25487 [D loss: 0.663782, acc.: 57.03%] [G loss: 0.860560]\n",
      "epoch:27 step:25488 [D loss: 0.666809, acc.: 60.16%] [G loss: 1.086069]\n",
      "epoch:27 step:25489 [D loss: 0.705300, acc.: 50.78%] [G loss: 0.892684]\n",
      "epoch:27 step:25490 [D loss: 0.706595, acc.: 51.56%] [G loss: 0.982027]\n",
      "epoch:27 step:25491 [D loss: 0.574302, acc.: 70.31%] [G loss: 0.862415]\n",
      "epoch:27 step:25492 [D loss: 0.621176, acc.: 62.50%] [G loss: 1.143045]\n",
      "epoch:27 step:25493 [D loss: 0.438835, acc.: 87.50%] [G loss: 1.116659]\n",
      "epoch:27 step:25494 [D loss: 0.559918, acc.: 69.53%] [G loss: 1.202428]\n",
      "epoch:27 step:25495 [D loss: 0.566468, acc.: 65.62%] [G loss: 1.281499]\n",
      "epoch:27 step:25496 [D loss: 0.525697, acc.: 73.44%] [G loss: 1.324032]\n",
      "epoch:27 step:25497 [D loss: 0.478278, acc.: 80.47%] [G loss: 1.195660]\n",
      "epoch:27 step:25498 [D loss: 0.783617, acc.: 50.78%] [G loss: 1.313369]\n",
      "epoch:27 step:25499 [D loss: 0.417611, acc.: 83.59%] [G loss: 1.079997]\n",
      "epoch:27 step:25500 [D loss: 0.321247, acc.: 95.31%] [G loss: 1.228815]\n",
      "epoch:27 step:25501 [D loss: 0.582219, acc.: 64.84%] [G loss: 1.242085]\n",
      "epoch:27 step:25502 [D loss: 0.424114, acc.: 87.50%] [G loss: 1.089716]\n",
      "epoch:27 step:25503 [D loss: 0.306680, acc.: 92.97%] [G loss: 1.205000]\n",
      "epoch:27 step:25504 [D loss: 0.388496, acc.: 87.50%] [G loss: 1.274269]\n",
      "epoch:27 step:25505 [D loss: 0.318614, acc.: 91.41%] [G loss: 1.412091]\n",
      "epoch:27 step:25506 [D loss: 0.236815, acc.: 93.75%] [G loss: 1.656201]\n",
      "epoch:27 step:25507 [D loss: 0.177768, acc.: 100.00%] [G loss: 1.625434]\n",
      "epoch:27 step:25508 [D loss: 0.179756, acc.: 98.44%] [G loss: 1.817093]\n",
      "epoch:27 step:25509 [D loss: 0.656176, acc.: 59.38%] [G loss: 1.657173]\n",
      "epoch:27 step:25510 [D loss: 0.878230, acc.: 50.00%] [G loss: 0.958927]\n",
      "epoch:27 step:25511 [D loss: 0.614041, acc.: 67.19%] [G loss: 1.299897]\n",
      "epoch:27 step:25512 [D loss: 0.720622, acc.: 56.25%] [G loss: 1.121350]\n",
      "epoch:27 step:25513 [D loss: 0.683825, acc.: 55.47%] [G loss: 0.947803]\n",
      "epoch:27 step:25514 [D loss: 0.614605, acc.: 64.06%] [G loss: 0.819255]\n",
      "epoch:27 step:25515 [D loss: 0.609645, acc.: 70.31%] [G loss: 1.116999]\n",
      "epoch:27 step:25516 [D loss: 0.276597, acc.: 96.09%] [G loss: 0.699327]\n",
      "epoch:27 step:25517 [D loss: 0.315659, acc.: 84.38%] [G loss: 1.245931]\n",
      "epoch:27 step:25518 [D loss: 0.292035, acc.: 87.50%] [G loss: 0.882095]\n",
      "epoch:27 step:25519 [D loss: 0.398225, acc.: 87.50%] [G loss: 1.392390]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25520 [D loss: 0.392283, acc.: 85.16%] [G loss: 1.296038]\n",
      "epoch:27 step:25521 [D loss: 0.453136, acc.: 89.84%] [G loss: 1.260025]\n",
      "epoch:27 step:25522 [D loss: 0.469597, acc.: 82.03%] [G loss: 1.331821]\n",
      "epoch:27 step:25523 [D loss: 0.521337, acc.: 81.25%] [G loss: 1.285496]\n",
      "epoch:27 step:25524 [D loss: 0.303348, acc.: 95.31%] [G loss: 1.329800]\n",
      "epoch:27 step:25525 [D loss: 0.747290, acc.: 50.78%] [G loss: 1.335846]\n",
      "epoch:27 step:25526 [D loss: 0.736253, acc.: 55.47%] [G loss: 1.041252]\n",
      "epoch:27 step:25527 [D loss: 0.768813, acc.: 42.19%] [G loss: 1.217038]\n",
      "epoch:27 step:25528 [D loss: 0.721981, acc.: 54.69%] [G loss: 1.080609]\n",
      "epoch:27 step:25529 [D loss: 0.234897, acc.: 92.97%] [G loss: 1.055634]\n",
      "epoch:27 step:25530 [D loss: 0.257185, acc.: 92.97%] [G loss: 1.373134]\n",
      "epoch:27 step:25531 [D loss: 0.305476, acc.: 91.41%] [G loss: 1.351775]\n",
      "epoch:27 step:25532 [D loss: 0.736015, acc.: 57.03%] [G loss: 1.189427]\n",
      "epoch:27 step:25533 [D loss: 0.653636, acc.: 64.06%] [G loss: 1.175343]\n",
      "epoch:27 step:25534 [D loss: 0.538707, acc.: 78.12%] [G loss: 1.050346]\n",
      "epoch:27 step:25535 [D loss: 0.608051, acc.: 67.19%] [G loss: 0.989630]\n",
      "epoch:27 step:25536 [D loss: 0.625447, acc.: 63.28%] [G loss: 0.876731]\n",
      "epoch:27 step:25537 [D loss: 0.454764, acc.: 79.69%] [G loss: 1.148418]\n",
      "epoch:27 step:25538 [D loss: 0.741928, acc.: 47.66%] [G loss: 1.075278]\n",
      "epoch:27 step:25539 [D loss: 0.729304, acc.: 53.12%] [G loss: 1.232236]\n",
      "epoch:27 step:25540 [D loss: 0.436889, acc.: 89.06%] [G loss: 0.648554]\n",
      "epoch:27 step:25541 [D loss: 0.694914, acc.: 59.38%] [G loss: 1.087299]\n",
      "epoch:27 step:25542 [D loss: 0.542878, acc.: 71.88%] [G loss: 0.774460]\n",
      "epoch:27 step:25543 [D loss: 0.682957, acc.: 53.91%] [G loss: 1.098620]\n",
      "epoch:27 step:25544 [D loss: 0.495762, acc.: 78.12%] [G loss: 0.973758]\n",
      "epoch:27 step:25545 [D loss: 0.376424, acc.: 88.28%] [G loss: 1.122707]\n",
      "epoch:27 step:25546 [D loss: 0.310881, acc.: 95.31%] [G loss: 1.067363]\n",
      "epoch:27 step:25547 [D loss: 0.285285, acc.: 91.41%] [G loss: 1.121585]\n",
      "epoch:27 step:25548 [D loss: 0.708445, acc.: 58.59%] [G loss: 1.214854]\n",
      "epoch:27 step:25549 [D loss: 0.638593, acc.: 58.59%] [G loss: 1.034210]\n",
      "epoch:27 step:25550 [D loss: 0.626748, acc.: 60.94%] [G loss: 1.092376]\n",
      "epoch:27 step:25551 [D loss: 0.694302, acc.: 63.28%] [G loss: 1.049408]\n",
      "epoch:27 step:25552 [D loss: 0.739825, acc.: 50.78%] [G loss: 0.951643]\n",
      "epoch:27 step:25553 [D loss: 0.515033, acc.: 78.12%] [G loss: 1.053714]\n",
      "epoch:27 step:25554 [D loss: 0.517442, acc.: 66.41%] [G loss: 1.189487]\n",
      "epoch:27 step:25555 [D loss: 0.235581, acc.: 93.75%] [G loss: 0.824915]\n",
      "epoch:27 step:25556 [D loss: 0.376399, acc.: 85.94%] [G loss: 1.006337]\n",
      "epoch:27 step:25557 [D loss: 0.775015, acc.: 51.56%] [G loss: 1.286971]\n",
      "epoch:27 step:25558 [D loss: 0.376442, acc.: 74.22%] [G loss: 1.359234]\n",
      "epoch:27 step:25559 [D loss: 0.296619, acc.: 94.53%] [G loss: 1.350104]\n",
      "epoch:27 step:25560 [D loss: 0.228960, acc.: 94.53%] [G loss: 1.273919]\n",
      "epoch:27 step:25561 [D loss: 0.684706, acc.: 60.16%] [G loss: 1.413881]\n",
      "epoch:27 step:25562 [D loss: 0.212561, acc.: 92.97%] [G loss: 1.267235]\n",
      "epoch:27 step:25563 [D loss: 0.210775, acc.: 99.22%] [G loss: 1.454000]\n",
      "epoch:27 step:25564 [D loss: 0.796656, acc.: 49.22%] [G loss: 1.485058]\n",
      "epoch:27 step:25565 [D loss: 0.520329, acc.: 72.66%] [G loss: 1.045512]\n",
      "epoch:27 step:25566 [D loss: 0.824356, acc.: 40.62%] [G loss: 1.335941]\n",
      "epoch:27 step:25567 [D loss: 0.665040, acc.: 60.94%] [G loss: 1.266914]\n",
      "epoch:27 step:25568 [D loss: 0.331732, acc.: 82.03%] [G loss: 1.512165]\n",
      "epoch:27 step:25569 [D loss: 0.371582, acc.: 91.41%] [G loss: 1.506551]\n",
      "epoch:27 step:25570 [D loss: 0.256072, acc.: 95.31%] [G loss: 1.436176]\n",
      "epoch:27 step:25571 [D loss: 0.240920, acc.: 94.53%] [G loss: 1.314732]\n",
      "epoch:27 step:25572 [D loss: 0.403415, acc.: 82.81%] [G loss: 1.554925]\n",
      "epoch:27 step:25573 [D loss: 0.207424, acc.: 97.66%] [G loss: 1.669631]\n",
      "epoch:27 step:25574 [D loss: 0.326166, acc.: 91.41%] [G loss: 1.761655]\n",
      "epoch:27 step:25575 [D loss: 0.168542, acc.: 97.66%] [G loss: 1.764219]\n",
      "epoch:27 step:25576 [D loss: 0.400586, acc.: 82.03%] [G loss: 1.481768]\n",
      "epoch:27 step:25577 [D loss: 0.617476, acc.: 69.53%] [G loss: 1.275056]\n",
      "epoch:27 step:25578 [D loss: 0.198786, acc.: 95.31%] [G loss: 1.744444]\n",
      "epoch:27 step:25579 [D loss: 0.773698, acc.: 52.34%] [G loss: 1.648628]\n",
      "epoch:27 step:25580 [D loss: 0.623599, acc.: 71.09%] [G loss: 1.188619]\n",
      "epoch:27 step:25581 [D loss: 0.218912, acc.: 97.66%] [G loss: 1.605823]\n",
      "epoch:27 step:25582 [D loss: 0.564207, acc.: 71.09%] [G loss: 1.465594]\n",
      "epoch:27 step:25583 [D loss: 0.727586, acc.: 58.59%] [G loss: 1.342117]\n",
      "epoch:27 step:25584 [D loss: 0.716157, acc.: 57.03%] [G loss: 1.011823]\n",
      "epoch:27 step:25585 [D loss: 0.624353, acc.: 64.06%] [G loss: 1.264390]\n",
      "epoch:27 step:25586 [D loss: 0.761544, acc.: 52.34%] [G loss: 0.713287]\n",
      "epoch:27 step:25587 [D loss: 0.609645, acc.: 63.28%] [G loss: 0.665327]\n",
      "epoch:27 step:25588 [D loss: 0.437063, acc.: 78.91%] [G loss: 1.443043]\n",
      "epoch:27 step:25589 [D loss: 0.598950, acc.: 63.28%] [G loss: 1.419997]\n",
      "epoch:27 step:25590 [D loss: 0.623538, acc.: 64.84%] [G loss: 1.019257]\n",
      "epoch:27 step:25591 [D loss: 0.444620, acc.: 79.69%] [G loss: 1.234679]\n",
      "epoch:27 step:25592 [D loss: 0.555236, acc.: 75.78%] [G loss: 1.235533]\n",
      "epoch:27 step:25593 [D loss: 0.849352, acc.: 44.53%] [G loss: 1.187118]\n",
      "epoch:27 step:25594 [D loss: 0.344734, acc.: 90.62%] [G loss: 1.426342]\n",
      "epoch:27 step:25595 [D loss: 0.698458, acc.: 62.50%] [G loss: 1.351468]\n",
      "epoch:27 step:25596 [D loss: 0.326759, acc.: 87.50%] [G loss: 1.771319]\n",
      "epoch:27 step:25597 [D loss: 0.126084, acc.: 97.66%] [G loss: 1.704311]\n",
      "epoch:27 step:25598 [D loss: 0.097170, acc.: 99.22%] [G loss: 1.816469]\n",
      "epoch:27 step:25599 [D loss: 0.166092, acc.: 99.22%] [G loss: 1.548569]\n",
      "epoch:27 step:25600 [D loss: 0.476976, acc.: 78.91%] [G loss: 1.685406]\n",
      "##############\n",
      "[3.55704841 2.36148922 6.43349475 5.78963474 4.80355079 5.93211013\n",
      " 5.08837185 5.67954968 5.96787208 4.79907357]\n",
      "##########\n",
      "epoch:27 step:25601 [D loss: 0.550371, acc.: 64.06%] [G loss: 0.276322]\n",
      "epoch:27 step:25602 [D loss: 0.682374, acc.: 62.50%] [G loss: 1.096734]\n",
      "epoch:27 step:25603 [D loss: 0.706286, acc.: 57.81%] [G loss: 0.912074]\n",
      "epoch:27 step:25604 [D loss: 1.102347, acc.: 29.69%] [G loss: 1.238618]\n",
      "epoch:27 step:25605 [D loss: 0.793056, acc.: 50.00%] [G loss: 0.752390]\n",
      "epoch:27 step:25606 [D loss: 0.535029, acc.: 75.78%] [G loss: 0.722872]\n",
      "epoch:27 step:25607 [D loss: 0.938292, acc.: 37.50%] [G loss: 1.009465]\n",
      "epoch:27 step:25608 [D loss: 0.826691, acc.: 41.41%] [G loss: 1.368184]\n",
      "epoch:27 step:25609 [D loss: 0.835030, acc.: 41.41%] [G loss: 0.535961]\n",
      "epoch:27 step:25610 [D loss: 0.805156, acc.: 50.00%] [G loss: 1.095665]\n",
      "epoch:27 step:25611 [D loss: 0.320069, acc.: 94.53%] [G loss: 1.073406]\n",
      "epoch:27 step:25612 [D loss: 0.347010, acc.: 85.94%] [G loss: 1.362093]\n",
      "epoch:27 step:25613 [D loss: 0.331444, acc.: 83.59%] [G loss: 1.406263]\n",
      "epoch:27 step:25614 [D loss: 0.550549, acc.: 74.22%] [G loss: 1.075765]\n",
      "epoch:27 step:25615 [D loss: 0.505531, acc.: 78.91%] [G loss: 0.810321]\n",
      "epoch:27 step:25616 [D loss: 0.545722, acc.: 73.44%] [G loss: 1.315659]\n",
      "epoch:27 step:25617 [D loss: 0.479566, acc.: 83.59%] [G loss: 1.355764]\n",
      "epoch:27 step:25618 [D loss: 0.623029, acc.: 64.06%] [G loss: 0.330984]\n",
      "epoch:27 step:25619 [D loss: 1.021913, acc.: 51.56%] [G loss: 0.883632]\n",
      "epoch:27 step:25620 [D loss: 0.581254, acc.: 71.09%] [G loss: 1.159217]\n",
      "epoch:27 step:25621 [D loss: 0.568329, acc.: 67.97%] [G loss: 1.064185]\n",
      "epoch:27 step:25622 [D loss: 0.758225, acc.: 56.25%] [G loss: 1.333525]\n",
      "epoch:27 step:25623 [D loss: 0.668513, acc.: 54.69%] [G loss: 1.291092]\n",
      "epoch:27 step:25624 [D loss: 0.717217, acc.: 53.91%] [G loss: 1.184097]\n",
      "epoch:27 step:25625 [D loss: 0.517490, acc.: 76.56%] [G loss: 0.899325]\n",
      "epoch:27 step:25626 [D loss: 0.276725, acc.: 96.09%] [G loss: 1.094308]\n",
      "epoch:27 step:25627 [D loss: 0.317766, acc.: 92.19%] [G loss: 1.338066]\n",
      "epoch:27 step:25628 [D loss: 0.555198, acc.: 69.53%] [G loss: 0.992121]\n",
      "epoch:27 step:25629 [D loss: 0.838391, acc.: 48.44%] [G loss: 1.337299]\n",
      "epoch:27 step:25630 [D loss: 0.783549, acc.: 44.53%] [G loss: 0.989652]\n",
      "epoch:27 step:25631 [D loss: 0.576145, acc.: 71.09%] [G loss: 0.924624]\n",
      "epoch:27 step:25632 [D loss: 0.334583, acc.: 91.41%] [G loss: 1.108803]\n",
      "epoch:27 step:25633 [D loss: 0.421618, acc.: 85.16%] [G loss: 0.852327]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25634 [D loss: 0.514360, acc.: 77.34%] [G loss: 1.440805]\n",
      "epoch:27 step:25635 [D loss: 0.293889, acc.: 83.59%] [G loss: 1.568781]\n",
      "epoch:27 step:25636 [D loss: 0.535458, acc.: 71.88%] [G loss: 1.420993]\n",
      "epoch:27 step:25637 [D loss: 0.649944, acc.: 64.06%] [G loss: 0.992489]\n",
      "epoch:27 step:25638 [D loss: 0.683672, acc.: 58.59%] [G loss: 1.375059]\n",
      "epoch:27 step:25639 [D loss: 0.471630, acc.: 77.34%] [G loss: 1.292013]\n",
      "epoch:27 step:25640 [D loss: 0.360620, acc.: 92.19%] [G loss: 1.193546]\n",
      "epoch:27 step:25641 [D loss: 0.206508, acc.: 91.41%] [G loss: 1.576362]\n",
      "epoch:27 step:25642 [D loss: 0.186770, acc.: 96.09%] [G loss: 1.943576]\n",
      "epoch:27 step:25643 [D loss: 0.169397, acc.: 97.66%] [G loss: 1.609425]\n",
      "epoch:27 step:25644 [D loss: 0.117523, acc.: 98.44%] [G loss: 1.738154]\n",
      "epoch:27 step:25645 [D loss: 0.150228, acc.: 97.66%] [G loss: 2.018244]\n",
      "epoch:27 step:25646 [D loss: 0.132851, acc.: 100.00%] [G loss: 2.009238]\n",
      "epoch:27 step:25647 [D loss: 0.427390, acc.: 83.59%] [G loss: 2.034239]\n",
      "epoch:27 step:25648 [D loss: 0.806849, acc.: 53.91%] [G loss: 1.513915]\n",
      "epoch:27 step:25649 [D loss: 0.349454, acc.: 90.62%] [G loss: 1.691258]\n",
      "epoch:27 step:25650 [D loss: 0.735620, acc.: 57.03%] [G loss: 1.320385]\n",
      "epoch:27 step:25651 [D loss: 0.761552, acc.: 51.56%] [G loss: 1.333305]\n",
      "epoch:27 step:25652 [D loss: 0.606098, acc.: 72.66%] [G loss: 1.376675]\n",
      "epoch:27 step:25653 [D loss: 0.703750, acc.: 64.06%] [G loss: 1.217712]\n",
      "epoch:27 step:25654 [D loss: 0.709825, acc.: 55.47%] [G loss: 1.337498]\n",
      "epoch:27 step:25655 [D loss: 0.612074, acc.: 66.41%] [G loss: 0.912774]\n",
      "epoch:27 step:25656 [D loss: 0.720725, acc.: 50.78%] [G loss: 1.128192]\n",
      "epoch:27 step:25657 [D loss: 0.583383, acc.: 65.62%] [G loss: 1.063622]\n",
      "epoch:27 step:25658 [D loss: 0.686131, acc.: 59.38%] [G loss: 1.012726]\n",
      "epoch:27 step:25659 [D loss: 0.767103, acc.: 46.09%] [G loss: 1.094118]\n",
      "epoch:27 step:25660 [D loss: 0.585538, acc.: 64.84%] [G loss: 1.094449]\n",
      "epoch:27 step:25661 [D loss: 0.284420, acc.: 90.62%] [G loss: 1.476389]\n",
      "epoch:27 step:25662 [D loss: 0.206897, acc.: 94.53%] [G loss: 1.126924]\n",
      "epoch:27 step:25663 [D loss: 0.358302, acc.: 90.62%] [G loss: 1.292367]\n",
      "epoch:27 step:25664 [D loss: 0.212907, acc.: 96.09%] [G loss: 1.471560]\n",
      "epoch:27 step:25665 [D loss: 0.177780, acc.: 97.66%] [G loss: 1.241167]\n",
      "epoch:27 step:25666 [D loss: 0.143629, acc.: 98.44%] [G loss: 1.437273]\n",
      "epoch:27 step:25667 [D loss: 0.424975, acc.: 85.94%] [G loss: 1.573409]\n",
      "epoch:27 step:25668 [D loss: 0.637315, acc.: 63.28%] [G loss: 1.312452]\n",
      "epoch:27 step:25669 [D loss: 0.601866, acc.: 68.75%] [G loss: 1.161445]\n",
      "epoch:27 step:25670 [D loss: 0.439453, acc.: 85.16%] [G loss: 1.202460]\n",
      "epoch:27 step:25671 [D loss: 0.710320, acc.: 53.12%] [G loss: 1.147261]\n",
      "epoch:27 step:25672 [D loss: 0.511637, acc.: 80.47%] [G loss: 0.284375]\n",
      "epoch:27 step:25673 [D loss: 0.519672, acc.: 77.34%] [G loss: 1.137741]\n",
      "epoch:27 step:25674 [D loss: 0.344225, acc.: 88.28%] [G loss: 1.055385]\n",
      "epoch:27 step:25675 [D loss: 0.391768, acc.: 82.81%] [G loss: 1.231593]\n",
      "epoch:27 step:25676 [D loss: 0.173128, acc.: 99.22%] [G loss: 1.456686]\n",
      "epoch:27 step:25677 [D loss: 0.160486, acc.: 99.22%] [G loss: 1.607100]\n",
      "epoch:27 step:25678 [D loss: 0.845935, acc.: 45.31%] [G loss: 1.443370]\n",
      "epoch:27 step:25679 [D loss: 0.676628, acc.: 61.72%] [G loss: 1.441671]\n",
      "epoch:27 step:25680 [D loss: 0.553838, acc.: 75.00%] [G loss: 1.211791]\n",
      "epoch:27 step:25681 [D loss: 0.623094, acc.: 60.94%] [G loss: 1.089035]\n",
      "epoch:27 step:25682 [D loss: 0.514062, acc.: 74.22%] [G loss: 1.322093]\n",
      "epoch:27 step:25683 [D loss: 0.241822, acc.: 94.53%] [G loss: 1.174884]\n",
      "epoch:27 step:25684 [D loss: 0.538696, acc.: 75.00%] [G loss: 1.052308]\n",
      "epoch:27 step:25685 [D loss: 0.569457, acc.: 70.31%] [G loss: 1.162960]\n",
      "epoch:27 step:25686 [D loss: 0.640167, acc.: 64.06%] [G loss: 0.129916]\n",
      "epoch:27 step:25687 [D loss: 0.484131, acc.: 81.25%] [G loss: 0.823401]\n",
      "epoch:27 step:25688 [D loss: 0.271894, acc.: 92.97%] [G loss: 0.561228]\n",
      "epoch:27 step:25689 [D loss: 0.265859, acc.: 90.62%] [G loss: 1.331421]\n",
      "epoch:27 step:25690 [D loss: 0.476959, acc.: 80.47%] [G loss: 1.807781]\n",
      "epoch:27 step:25691 [D loss: 0.251762, acc.: 97.66%] [G loss: 1.020532]\n",
      "epoch:27 step:25692 [D loss: 0.304026, acc.: 81.25%] [G loss: 0.118411]\n",
      "epoch:27 step:25693 [D loss: 0.426118, acc.: 82.81%] [G loss: 0.900608]\n",
      "epoch:27 step:25694 [D loss: 0.971580, acc.: 23.44%] [G loss: 1.524920]\n",
      "epoch:27 step:25695 [D loss: 0.203890, acc.: 94.53%] [G loss: 0.646457]\n",
      "epoch:27 step:25696 [D loss: 0.123096, acc.: 100.00%] [G loss: 1.326805]\n",
      "epoch:27 step:25697 [D loss: 0.210453, acc.: 95.31%] [G loss: 2.315226]\n",
      "epoch:27 step:25698 [D loss: 0.129370, acc.: 99.22%] [G loss: 2.822130]\n",
      "epoch:27 step:25699 [D loss: 0.158119, acc.: 98.44%] [G loss: 1.898144]\n",
      "epoch:27 step:25700 [D loss: 0.165970, acc.: 96.09%] [G loss: 2.453115]\n",
      "epoch:27 step:25701 [D loss: 0.067126, acc.: 100.00%] [G loss: 2.130626]\n",
      "epoch:27 step:25702 [D loss: 0.305620, acc.: 96.09%] [G loss: 1.728215]\n",
      "epoch:27 step:25703 [D loss: 0.444528, acc.: 68.75%] [G loss: 1.146444]\n",
      "epoch:27 step:25704 [D loss: 0.129668, acc.: 98.44%] [G loss: 2.277820]\n",
      "epoch:27 step:25705 [D loss: 0.339580, acc.: 82.03%] [G loss: 3.192045]\n",
      "epoch:27 step:25706 [D loss: 0.063281, acc.: 98.44%] [G loss: 2.685905]\n",
      "epoch:27 step:25707 [D loss: 0.457727, acc.: 79.69%] [G loss: 1.367853]\n",
      "epoch:27 step:25708 [D loss: 0.209169, acc.: 94.53%] [G loss: 2.937084]\n",
      "epoch:27 step:25709 [D loss: 1.012461, acc.: 34.38%] [G loss: 1.345880]\n",
      "epoch:27 step:25710 [D loss: 1.563651, acc.: 35.16%] [G loss: 1.739149]\n",
      "epoch:27 step:25711 [D loss: 0.734819, acc.: 54.69%] [G loss: 1.829772]\n",
      "epoch:27 step:25712 [D loss: 0.840050, acc.: 55.47%] [G loss: 0.401924]\n",
      "epoch:27 step:25713 [D loss: 1.705878, acc.: 17.97%] [G loss: 2.232882]\n",
      "epoch:27 step:25714 [D loss: 0.838501, acc.: 57.03%] [G loss: 1.973750]\n",
      "epoch:27 step:25715 [D loss: 0.909066, acc.: 43.75%] [G loss: 1.657557]\n",
      "epoch:27 step:25716 [D loss: 0.793893, acc.: 50.00%] [G loss: 1.441967]\n",
      "epoch:27 step:25717 [D loss: 0.695850, acc.: 57.03%] [G loss: 1.366735]\n",
      "epoch:27 step:25718 [D loss: 0.780772, acc.: 57.03%] [G loss: 1.311764]\n",
      "epoch:27 step:25719 [D loss: 0.741830, acc.: 57.03%] [G loss: 2.232007]\n",
      "epoch:27 step:25720 [D loss: 1.038848, acc.: 50.78%] [G loss: 0.932504]\n",
      "epoch:27 step:25721 [D loss: 0.966779, acc.: 45.31%] [G loss: 1.471732]\n",
      "epoch:27 step:25722 [D loss: 1.006164, acc.: 38.28%] [G loss: 1.155751]\n",
      "epoch:27 step:25723 [D loss: 0.463482, acc.: 82.03%] [G loss: 0.863886]\n",
      "epoch:27 step:25724 [D loss: 0.599019, acc.: 65.62%] [G loss: 1.236798]\n",
      "epoch:27 step:25725 [D loss: 0.763108, acc.: 51.56%] [G loss: 1.213421]\n",
      "epoch:27 step:25726 [D loss: 0.471091, acc.: 80.47%] [G loss: 1.183748]\n",
      "epoch:27 step:25727 [D loss: 0.351219, acc.: 87.50%] [G loss: 1.372801]\n",
      "epoch:27 step:25728 [D loss: 0.873092, acc.: 38.28%] [G loss: 1.200297]\n",
      "epoch:27 step:25729 [D loss: 0.434041, acc.: 85.94%] [G loss: 1.561956]\n",
      "epoch:27 step:25730 [D loss: 0.832869, acc.: 47.66%] [G loss: 1.665366]\n",
      "epoch:27 step:25731 [D loss: 0.630297, acc.: 60.94%] [G loss: 1.641822]\n",
      "epoch:27 step:25732 [D loss: 0.624610, acc.: 59.38%] [G loss: 1.283957]\n",
      "epoch:27 step:25733 [D loss: 0.764871, acc.: 48.44%] [G loss: 1.724508]\n",
      "epoch:27 step:25734 [D loss: 0.531253, acc.: 68.75%] [G loss: 1.442831]\n",
      "epoch:27 step:25735 [D loss: 0.569506, acc.: 62.50%] [G loss: 1.418293]\n",
      "epoch:27 step:25736 [D loss: 0.696406, acc.: 57.03%] [G loss: 1.393877]\n",
      "epoch:27 step:25737 [D loss: 0.725356, acc.: 54.69%] [G loss: 1.187522]\n",
      "epoch:27 step:25738 [D loss: 0.654340, acc.: 57.81%] [G loss: 1.068537]\n",
      "epoch:27 step:25739 [D loss: 0.683369, acc.: 56.25%] [G loss: 1.342455]\n",
      "epoch:27 step:25740 [D loss: 0.578495, acc.: 71.88%] [G loss: 1.082751]\n",
      "epoch:27 step:25741 [D loss: 0.614868, acc.: 63.28%] [G loss: 0.978208]\n",
      "epoch:27 step:25742 [D loss: 0.539369, acc.: 81.25%] [G loss: 0.969944]\n",
      "epoch:27 step:25743 [D loss: 0.592596, acc.: 64.06%] [G loss: 1.034462]\n",
      "epoch:27 step:25744 [D loss: 0.613117, acc.: 60.94%] [G loss: 1.206017]\n",
      "epoch:27 step:25745 [D loss: 0.600434, acc.: 63.28%] [G loss: 1.089658]\n",
      "epoch:27 step:25746 [D loss: 0.632522, acc.: 64.84%] [G loss: 0.986059]\n",
      "epoch:27 step:25747 [D loss: 0.439642, acc.: 86.72%] [G loss: 1.407584]\n",
      "epoch:27 step:25748 [D loss: 0.287604, acc.: 93.75%] [G loss: 1.539569]\n",
      "epoch:27 step:25749 [D loss: 0.339412, acc.: 96.09%] [G loss: 1.796190]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25750 [D loss: 0.205149, acc.: 99.22%] [G loss: 1.353478]\n",
      "epoch:27 step:25751 [D loss: 0.202671, acc.: 100.00%] [G loss: 2.053768]\n",
      "epoch:27 step:25752 [D loss: 0.184348, acc.: 99.22%] [G loss: 2.017524]\n",
      "epoch:27 step:25753 [D loss: 0.255435, acc.: 97.66%] [G loss: 2.419527]\n",
      "epoch:27 step:25754 [D loss: 0.314659, acc.: 93.75%] [G loss: 2.023840]\n",
      "epoch:27 step:25755 [D loss: 0.156054, acc.: 99.22%] [G loss: 2.019361]\n",
      "epoch:27 step:25756 [D loss: 0.145789, acc.: 100.00%] [G loss: 2.017153]\n",
      "epoch:27 step:25757 [D loss: 0.516733, acc.: 72.66%] [G loss: 1.463740]\n",
      "epoch:27 step:25758 [D loss: 0.445070, acc.: 83.59%] [G loss: 1.338414]\n",
      "epoch:27 step:25759 [D loss: 0.388556, acc.: 87.50%] [G loss: 1.641411]\n",
      "epoch:27 step:25760 [D loss: 0.871199, acc.: 49.22%] [G loss: 1.307925]\n",
      "epoch:27 step:25761 [D loss: 1.069622, acc.: 37.50%] [G loss: 0.843021]\n",
      "epoch:27 step:25762 [D loss: 0.675409, acc.: 59.38%] [G loss: 0.761519]\n",
      "epoch:27 step:25763 [D loss: 0.435808, acc.: 77.34%] [G loss: 1.562571]\n",
      "epoch:27 step:25764 [D loss: 0.327646, acc.: 92.19%] [G loss: 1.427376]\n",
      "epoch:27 step:25765 [D loss: 0.353951, acc.: 96.88%] [G loss: 1.427529]\n",
      "epoch:27 step:25766 [D loss: 0.406166, acc.: 89.06%] [G loss: 1.180030]\n",
      "epoch:27 step:25767 [D loss: 0.271523, acc.: 92.19%] [G loss: 1.091456]\n",
      "epoch:27 step:25768 [D loss: 0.259715, acc.: 93.75%] [G loss: 1.441887]\n",
      "epoch:27 step:25769 [D loss: 0.083356, acc.: 100.00%] [G loss: 1.679806]\n",
      "epoch:27 step:25770 [D loss: 0.163497, acc.: 96.09%] [G loss: 2.378502]\n",
      "epoch:27 step:25771 [D loss: 0.203692, acc.: 96.09%] [G loss: 2.455348]\n",
      "epoch:27 step:25772 [D loss: 1.575407, acc.: 39.84%] [G loss: 1.066771]\n",
      "epoch:27 step:25773 [D loss: 1.566121, acc.: 13.28%] [G loss: 1.064599]\n",
      "epoch:27 step:25774 [D loss: 0.782116, acc.: 42.97%] [G loss: 1.469181]\n",
      "epoch:27 step:25775 [D loss: 0.562059, acc.: 67.97%] [G loss: 1.017052]\n",
      "epoch:27 step:25776 [D loss: 0.623032, acc.: 63.28%] [G loss: 0.887637]\n",
      "epoch:27 step:25777 [D loss: 0.615094, acc.: 66.41%] [G loss: 1.193980]\n",
      "epoch:27 step:25778 [D loss: 0.367858, acc.: 82.03%] [G loss: 1.128559]\n",
      "epoch:27 step:25779 [D loss: 0.477359, acc.: 77.34%] [G loss: 0.679920]\n",
      "epoch:27 step:25780 [D loss: 0.393711, acc.: 81.25%] [G loss: 1.040685]\n",
      "epoch:27 step:25781 [D loss: 1.021561, acc.: 32.03%] [G loss: 1.147538]\n",
      "epoch:27 step:25782 [D loss: 0.843754, acc.: 39.84%] [G loss: 0.920537]\n",
      "epoch:27 step:25783 [D loss: 0.795162, acc.: 47.66%] [G loss: 1.202527]\n",
      "epoch:27 step:25784 [D loss: 0.666738, acc.: 54.69%] [G loss: 0.991106]\n",
      "epoch:27 step:25785 [D loss: 0.695892, acc.: 58.59%] [G loss: 1.164607]\n",
      "epoch:27 step:25786 [D loss: 0.877409, acc.: 39.06%] [G loss: 1.136122]\n",
      "epoch:27 step:25787 [D loss: 0.693579, acc.: 53.12%] [G loss: 1.113749]\n",
      "epoch:27 step:25788 [D loss: 0.436470, acc.: 82.81%] [G loss: 1.238911]\n",
      "epoch:27 step:25789 [D loss: 0.442077, acc.: 85.94%] [G loss: 1.163363]\n",
      "epoch:27 step:25790 [D loss: 0.526812, acc.: 72.66%] [G loss: 1.008017]\n",
      "epoch:27 step:25791 [D loss: 0.633401, acc.: 68.75%] [G loss: 0.964001]\n",
      "epoch:27 step:25792 [D loss: 0.800610, acc.: 50.78%] [G loss: 1.048925]\n",
      "epoch:27 step:25793 [D loss: 0.563531, acc.: 74.22%] [G loss: 1.180037]\n",
      "epoch:27 step:25794 [D loss: 0.604253, acc.: 67.19%] [G loss: 1.189558]\n",
      "epoch:27 step:25795 [D loss: 0.718409, acc.: 53.12%] [G loss: 1.176281]\n",
      "epoch:27 step:25796 [D loss: 0.541980, acc.: 71.88%] [G loss: 1.351840]\n",
      "epoch:27 step:25797 [D loss: 0.460557, acc.: 77.34%] [G loss: 1.382227]\n",
      "epoch:27 step:25798 [D loss: 0.459002, acc.: 81.25%] [G loss: 1.347682]\n",
      "epoch:27 step:25799 [D loss: 0.721874, acc.: 59.38%] [G loss: 1.224211]\n",
      "epoch:27 step:25800 [D loss: 0.664344, acc.: 61.72%] [G loss: 1.239662]\n",
      "##############\n",
      "[3.97846199 2.37667313 6.4882081  5.961112   4.70024887 6.38499527\n",
      " 4.94262368 5.46914327 5.71907626 4.7270294 ]\n",
      "##########\n",
      "epoch:27 step:25801 [D loss: 0.605104, acc.: 65.62%] [G loss: 1.113394]\n",
      "epoch:27 step:25802 [D loss: 0.324025, acc.: 90.62%] [G loss: 1.190737]\n",
      "epoch:27 step:25803 [D loss: 0.226453, acc.: 94.53%] [G loss: 1.937033]\n",
      "epoch:27 step:25804 [D loss: 0.427787, acc.: 82.03%] [G loss: 1.473780]\n",
      "epoch:27 step:25805 [D loss: 0.694638, acc.: 48.44%] [G loss: 1.684241]\n",
      "epoch:27 step:25806 [D loss: 0.494414, acc.: 78.91%] [G loss: 1.615858]\n",
      "epoch:27 step:25807 [D loss: 0.520448, acc.: 78.12%] [G loss: 1.745325]\n",
      "epoch:27 step:25808 [D loss: 0.661750, acc.: 57.03%] [G loss: 1.085919]\n",
      "epoch:27 step:25809 [D loss: 0.577389, acc.: 67.19%] [G loss: 1.170087]\n",
      "epoch:27 step:25810 [D loss: 0.371868, acc.: 83.59%] [G loss: 1.101674]\n",
      "epoch:27 step:25811 [D loss: 0.519285, acc.: 75.78%] [G loss: 2.350855]\n",
      "epoch:27 step:25812 [D loss: 0.424439, acc.: 84.38%] [G loss: 1.332114]\n",
      "epoch:27 step:25813 [D loss: 0.473374, acc.: 81.25%] [G loss: 1.641829]\n",
      "epoch:27 step:25814 [D loss: 0.323515, acc.: 90.62%] [G loss: 1.408974]\n",
      "epoch:27 step:25815 [D loss: 0.836319, acc.: 41.41%] [G loss: 1.360564]\n",
      "epoch:27 step:25816 [D loss: 0.415801, acc.: 86.72%] [G loss: 1.134515]\n",
      "epoch:27 step:25817 [D loss: 0.725123, acc.: 52.34%] [G loss: 1.144349]\n",
      "epoch:27 step:25818 [D loss: 0.553624, acc.: 71.88%] [G loss: 1.383484]\n",
      "epoch:27 step:25819 [D loss: 0.555651, acc.: 75.78%] [G loss: 1.120575]\n",
      "epoch:27 step:25820 [D loss: 0.644123, acc.: 63.28%] [G loss: 0.969510]\n",
      "epoch:27 step:25821 [D loss: 0.478675, acc.: 80.47%] [G loss: 1.181937]\n",
      "epoch:27 step:25822 [D loss: 0.638214, acc.: 64.06%] [G loss: 1.018195]\n",
      "epoch:27 step:25823 [D loss: 0.417341, acc.: 85.16%] [G loss: 1.163156]\n",
      "epoch:27 step:25824 [D loss: 0.628550, acc.: 64.84%] [G loss: 1.347114]\n",
      "epoch:27 step:25825 [D loss: 0.499059, acc.: 75.00%] [G loss: 1.045131]\n",
      "epoch:27 step:25826 [D loss: 0.388415, acc.: 86.72%] [G loss: 1.427006]\n",
      "epoch:27 step:25827 [D loss: 0.567360, acc.: 75.00%] [G loss: 1.278712]\n",
      "epoch:27 step:25828 [D loss: 0.567594, acc.: 75.78%] [G loss: 1.267905]\n",
      "epoch:27 step:25829 [D loss: 0.319012, acc.: 89.84%] [G loss: 1.394674]\n",
      "epoch:27 step:25830 [D loss: 0.645909, acc.: 60.94%] [G loss: 1.364232]\n",
      "epoch:27 step:25831 [D loss: 0.656621, acc.: 63.28%] [G loss: 1.274937]\n",
      "epoch:27 step:25832 [D loss: 0.469407, acc.: 81.25%] [G loss: 1.026935]\n",
      "epoch:27 step:25833 [D loss: 0.639518, acc.: 60.16%] [G loss: 1.271978]\n",
      "epoch:27 step:25834 [D loss: 0.318396, acc.: 87.50%] [G loss: 1.262102]\n",
      "epoch:27 step:25835 [D loss: 0.164733, acc.: 99.22%] [G loss: 1.536514]\n",
      "epoch:27 step:25836 [D loss: 0.193446, acc.: 98.44%] [G loss: 1.531324]\n",
      "epoch:27 step:25837 [D loss: 0.367214, acc.: 88.28%] [G loss: 1.973247]\n",
      "epoch:27 step:25838 [D loss: 0.238564, acc.: 96.88%] [G loss: 1.613722]\n",
      "epoch:27 step:25839 [D loss: 0.359265, acc.: 89.06%] [G loss: 1.534701]\n",
      "epoch:27 step:25840 [D loss: 0.419622, acc.: 88.28%] [G loss: 1.549197]\n",
      "epoch:27 step:25841 [D loss: 0.694190, acc.: 62.50%] [G loss: 1.488518]\n",
      "epoch:27 step:25842 [D loss: 0.313466, acc.: 84.38%] [G loss: 1.423725]\n",
      "epoch:27 step:25843 [D loss: 0.614853, acc.: 69.53%] [G loss: 1.352695]\n",
      "epoch:27 step:25844 [D loss: 0.427663, acc.: 83.59%] [G loss: 1.471785]\n",
      "epoch:27 step:25845 [D loss: 0.647252, acc.: 64.06%] [G loss: 1.122914]\n",
      "epoch:27 step:25846 [D loss: 0.468852, acc.: 78.12%] [G loss: 1.292300]\n",
      "epoch:27 step:25847 [D loss: 0.733505, acc.: 59.38%] [G loss: 1.040126]\n",
      "epoch:27 step:25848 [D loss: 0.512897, acc.: 75.78%] [G loss: 1.549022]\n",
      "epoch:27 step:25849 [D loss: 0.350204, acc.: 90.62%] [G loss: 1.601666]\n",
      "epoch:27 step:25850 [D loss: 0.562337, acc.: 72.66%] [G loss: 1.460618]\n",
      "epoch:27 step:25851 [D loss: 0.522353, acc.: 74.22%] [G loss: 1.212266]\n",
      "epoch:27 step:25852 [D loss: 0.733916, acc.: 59.38%] [G loss: 0.762295]\n",
      "epoch:27 step:25853 [D loss: 0.273902, acc.: 86.72%] [G loss: 0.950964]\n",
      "epoch:27 step:25854 [D loss: 0.522430, acc.: 71.88%] [G loss: 0.872169]\n",
      "epoch:27 step:25855 [D loss: 1.007018, acc.: 51.56%] [G loss: 1.162781]\n",
      "epoch:27 step:25856 [D loss: 0.547719, acc.: 71.09%] [G loss: 1.993002]\n",
      "epoch:27 step:25857 [D loss: 0.983011, acc.: 37.50%] [G loss: 0.928681]\n",
      "epoch:27 step:25858 [D loss: 0.368364, acc.: 79.69%] [G loss: 1.401100]\n",
      "epoch:27 step:25859 [D loss: 0.307556, acc.: 90.62%] [G loss: 1.120004]\n",
      "epoch:27 step:25860 [D loss: 0.236578, acc.: 85.94%] [G loss: 2.288597]\n",
      "epoch:27 step:25861 [D loss: 0.619820, acc.: 63.28%] [G loss: 2.221871]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25862 [D loss: 0.684039, acc.: 60.94%] [G loss: 2.860774]\n",
      "epoch:27 step:25863 [D loss: 0.316462, acc.: 86.72%] [G loss: 2.229012]\n",
      "epoch:27 step:25864 [D loss: 0.251828, acc.: 94.53%] [G loss: 2.506059]\n",
      "epoch:27 step:25865 [D loss: 0.047532, acc.: 100.00%] [G loss: 2.237420]\n",
      "epoch:27 step:25866 [D loss: 0.091896, acc.: 99.22%] [G loss: 2.852819]\n",
      "epoch:27 step:25867 [D loss: 0.224982, acc.: 94.53%] [G loss: 3.276679]\n",
      "epoch:27 step:25868 [D loss: 0.512710, acc.: 75.78%] [G loss: 2.356643]\n",
      "epoch:27 step:25869 [D loss: 0.351662, acc.: 87.50%] [G loss: 2.225981]\n",
      "epoch:27 step:25870 [D loss: 0.371449, acc.: 88.28%] [G loss: 2.392989]\n",
      "epoch:27 step:25871 [D loss: 0.237533, acc.: 95.31%] [G loss: 1.725868]\n",
      "epoch:27 step:25872 [D loss: 0.181355, acc.: 99.22%] [G loss: 2.049088]\n",
      "epoch:27 step:25873 [D loss: 0.227068, acc.: 95.31%] [G loss: 2.802421]\n",
      "epoch:27 step:25874 [D loss: 0.311187, acc.: 91.41%] [G loss: 2.366620]\n",
      "epoch:27 step:25875 [D loss: 0.185349, acc.: 95.31%] [G loss: 2.666643]\n",
      "epoch:27 step:25876 [D loss: 0.059584, acc.: 100.00%] [G loss: 2.567781]\n",
      "epoch:27 step:25877 [D loss: 0.133823, acc.: 98.44%] [G loss: 2.875763]\n",
      "epoch:27 step:25878 [D loss: 0.646514, acc.: 64.06%] [G loss: 2.202810]\n",
      "epoch:27 step:25879 [D loss: 1.011831, acc.: 56.25%] [G loss: 2.014971]\n",
      "epoch:27 step:25880 [D loss: 0.900961, acc.: 38.28%] [G loss: 1.486620]\n",
      "epoch:27 step:25881 [D loss: 0.781143, acc.: 49.22%] [G loss: 0.320633]\n",
      "epoch:27 step:25882 [D loss: 0.920411, acc.: 52.34%] [G loss: 0.672404]\n",
      "epoch:27 step:25883 [D loss: 1.217040, acc.: 30.47%] [G loss: 0.764649]\n",
      "epoch:27 step:25884 [D loss: 0.859932, acc.: 42.19%] [G loss: 0.737934]\n",
      "epoch:27 step:25885 [D loss: 0.658583, acc.: 66.41%] [G loss: 1.099363]\n",
      "epoch:27 step:25886 [D loss: 0.188049, acc.: 95.31%] [G loss: 1.517069]\n",
      "epoch:27 step:25887 [D loss: 0.267935, acc.: 90.62%] [G loss: 1.551004]\n",
      "epoch:27 step:25888 [D loss: 0.318487, acc.: 82.03%] [G loss: 1.242625]\n",
      "epoch:27 step:25889 [D loss: 0.606538, acc.: 64.84%] [G loss: 0.972684]\n",
      "epoch:27 step:25890 [D loss: 0.941002, acc.: 53.91%] [G loss: 1.722300]\n",
      "epoch:27 step:25891 [D loss: 0.785253, acc.: 57.03%] [G loss: 1.121641]\n",
      "epoch:27 step:25892 [D loss: 0.957803, acc.: 34.38%] [G loss: 1.045889]\n",
      "epoch:27 step:25893 [D loss: 0.626080, acc.: 67.97%] [G loss: 0.540365]\n",
      "epoch:27 step:25894 [D loss: 0.406761, acc.: 89.06%] [G loss: 1.304963]\n",
      "epoch:27 step:25895 [D loss: 0.732090, acc.: 58.59%] [G loss: 1.331349]\n",
      "epoch:27 step:25896 [D loss: 0.858882, acc.: 48.44%] [G loss: 0.888259]\n",
      "epoch:27 step:25897 [D loss: 0.751465, acc.: 55.47%] [G loss: 1.241066]\n",
      "epoch:27 step:25898 [D loss: 0.671192, acc.: 54.69%] [G loss: 1.271334]\n",
      "epoch:27 step:25899 [D loss: 0.369114, acc.: 84.38%] [G loss: 1.058744]\n",
      "epoch:27 step:25900 [D loss: 0.375614, acc.: 88.28%] [G loss: 1.020171]\n",
      "epoch:27 step:25901 [D loss: 0.453657, acc.: 82.03%] [G loss: 1.090900]\n",
      "epoch:27 step:25902 [D loss: 0.730446, acc.: 51.56%] [G loss: 1.476110]\n",
      "epoch:27 step:25903 [D loss: 0.646157, acc.: 60.94%] [G loss: 1.453873]\n",
      "epoch:27 step:25904 [D loss: 0.633862, acc.: 62.50%] [G loss: 1.383672]\n",
      "epoch:27 step:25905 [D loss: 0.718294, acc.: 59.38%] [G loss: 1.353894]\n",
      "epoch:27 step:25906 [D loss: 0.639526, acc.: 66.41%] [G loss: 1.120948]\n",
      "epoch:27 step:25907 [D loss: 0.466031, acc.: 78.91%] [G loss: 1.202892]\n",
      "epoch:27 step:25908 [D loss: 0.463009, acc.: 78.12%] [G loss: 1.113374]\n",
      "epoch:27 step:25909 [D loss: 0.643462, acc.: 57.03%] [G loss: 1.058911]\n",
      "epoch:27 step:25910 [D loss: 0.637906, acc.: 62.50%] [G loss: 1.134838]\n",
      "epoch:27 step:25911 [D loss: 0.667817, acc.: 61.72%] [G loss: 1.054516]\n",
      "epoch:27 step:25912 [D loss: 0.674936, acc.: 60.94%] [G loss: 0.903916]\n",
      "epoch:27 step:25913 [D loss: 0.671948, acc.: 57.81%] [G loss: 1.006227]\n",
      "epoch:27 step:25914 [D loss: 0.687615, acc.: 56.25%] [G loss: 0.923846]\n",
      "epoch:27 step:25915 [D loss: 0.537987, acc.: 71.88%] [G loss: 1.130476]\n",
      "epoch:27 step:25916 [D loss: 0.511596, acc.: 74.22%] [G loss: 1.084298]\n",
      "epoch:27 step:25917 [D loss: 0.706873, acc.: 60.94%] [G loss: 1.170264]\n",
      "epoch:27 step:25918 [D loss: 0.693278, acc.: 53.91%] [G loss: 1.030173]\n",
      "epoch:27 step:25919 [D loss: 0.562556, acc.: 69.53%] [G loss: 0.982547]\n",
      "epoch:27 step:25920 [D loss: 0.648264, acc.: 59.38%] [G loss: 1.043848]\n",
      "epoch:27 step:25921 [D loss: 0.460269, acc.: 84.38%] [G loss: 1.014682]\n",
      "epoch:27 step:25922 [D loss: 0.668190, acc.: 60.94%] [G loss: 1.313859]\n",
      "epoch:27 step:25923 [D loss: 0.453961, acc.: 81.25%] [G loss: 1.424611]\n",
      "epoch:27 step:25924 [D loss: 0.732087, acc.: 60.16%] [G loss: 1.328247]\n",
      "epoch:27 step:25925 [D loss: 0.552085, acc.: 72.66%] [G loss: 1.389880]\n",
      "epoch:27 step:25926 [D loss: 0.613476, acc.: 63.28%] [G loss: 1.328614]\n",
      "epoch:27 step:25927 [D loss: 0.601879, acc.: 63.28%] [G loss: 1.165036]\n",
      "epoch:27 step:25928 [D loss: 0.500642, acc.: 76.56%] [G loss: 1.605692]\n",
      "epoch:27 step:25929 [D loss: 0.395209, acc.: 87.50%] [G loss: 1.595683]\n",
      "epoch:27 step:25930 [D loss: 0.601843, acc.: 71.09%] [G loss: 1.650632]\n",
      "epoch:27 step:25931 [D loss: 0.314151, acc.: 87.50%] [G loss: 1.456300]\n",
      "epoch:27 step:25932 [D loss: 0.209834, acc.: 98.44%] [G loss: 2.196631]\n",
      "epoch:27 step:25933 [D loss: 0.236770, acc.: 93.75%] [G loss: 1.713872]\n",
      "epoch:27 step:25934 [D loss: 0.298301, acc.: 93.75%] [G loss: 2.043128]\n",
      "epoch:27 step:25935 [D loss: 0.385174, acc.: 82.03%] [G loss: 1.765409]\n",
      "epoch:27 step:25936 [D loss: 0.383446, acc.: 85.16%] [G loss: 1.453403]\n",
      "epoch:27 step:25937 [D loss: 0.356542, acc.: 82.81%] [G loss: 1.708571]\n",
      "epoch:27 step:25938 [D loss: 0.634262, acc.: 59.38%] [G loss: 1.361515]\n",
      "epoch:27 step:25939 [D loss: 1.084999, acc.: 28.12%] [G loss: 0.989078]\n",
      "epoch:27 step:25940 [D loss: 0.917428, acc.: 35.16%] [G loss: 0.988001]\n",
      "epoch:27 step:25941 [D loss: 0.653200, acc.: 60.94%] [G loss: 0.848064]\n",
      "epoch:27 step:25942 [D loss: 0.503893, acc.: 70.31%] [G loss: 0.666227]\n",
      "epoch:27 step:25943 [D loss: 0.295462, acc.: 85.16%] [G loss: 1.370509]\n",
      "epoch:27 step:25944 [D loss: 0.219100, acc.: 94.53%] [G loss: 1.724695]\n",
      "epoch:27 step:25945 [D loss: 0.288939, acc.: 86.72%] [G loss: 1.452508]\n",
      "epoch:27 step:25946 [D loss: 0.187746, acc.: 96.88%] [G loss: 1.427987]\n",
      "epoch:27 step:25947 [D loss: 0.224486, acc.: 94.53%] [G loss: 1.807840]\n",
      "epoch:27 step:25948 [D loss: 0.253402, acc.: 95.31%] [G loss: 1.895732]\n",
      "epoch:27 step:25949 [D loss: 0.164722, acc.: 98.44%] [G loss: 2.012403]\n",
      "epoch:27 step:25950 [D loss: 0.279758, acc.: 96.09%] [G loss: 2.383061]\n",
      "epoch:27 step:25951 [D loss: 0.517395, acc.: 75.00%] [G loss: 1.605396]\n",
      "epoch:27 step:25952 [D loss: 0.682800, acc.: 60.94%] [G loss: 1.384233]\n",
      "epoch:27 step:25953 [D loss: 0.557541, acc.: 68.75%] [G loss: 1.536006]\n",
      "epoch:27 step:25954 [D loss: 0.484234, acc.: 78.12%] [G loss: 0.809432]\n",
      "epoch:27 step:25955 [D loss: 0.499292, acc.: 68.75%] [G loss: 1.383960]\n",
      "epoch:27 step:25956 [D loss: 0.365456, acc.: 91.41%] [G loss: 0.619599]\n",
      "epoch:27 step:25957 [D loss: 0.652505, acc.: 63.28%] [G loss: 0.851635]\n",
      "epoch:27 step:25958 [D loss: 0.388284, acc.: 73.44%] [G loss: 1.278028]\n",
      "epoch:27 step:25959 [D loss: 0.267061, acc.: 92.97%] [G loss: 2.189115]\n",
      "epoch:27 step:25960 [D loss: 0.256799, acc.: 94.53%] [G loss: 1.942147]\n",
      "epoch:27 step:25961 [D loss: 0.453831, acc.: 76.56%] [G loss: 2.052309]\n",
      "epoch:27 step:25962 [D loss: 1.039999, acc.: 34.38%] [G loss: 1.113169]\n",
      "epoch:27 step:25963 [D loss: 0.562264, acc.: 69.53%] [G loss: 0.936145]\n",
      "epoch:27 step:25964 [D loss: 0.557052, acc.: 71.09%] [G loss: 1.578733]\n",
      "epoch:27 step:25965 [D loss: 0.780777, acc.: 53.91%] [G loss: 1.239375]\n",
      "epoch:27 step:25966 [D loss: 0.787079, acc.: 56.25%] [G loss: 1.076054]\n",
      "epoch:27 step:25967 [D loss: 0.559999, acc.: 70.31%] [G loss: 0.803385]\n",
      "epoch:27 step:25968 [D loss: 0.672317, acc.: 66.41%] [G loss: 0.753535]\n",
      "epoch:27 step:25969 [D loss: 0.906371, acc.: 36.72%] [G loss: 0.617179]\n",
      "epoch:27 step:25970 [D loss: 1.209326, acc.: 24.22%] [G loss: 1.252445]\n",
      "epoch:27 step:25971 [D loss: 0.723017, acc.: 54.69%] [G loss: 1.134603]\n",
      "epoch:27 step:25972 [D loss: 0.710997, acc.: 53.91%] [G loss: 1.069280]\n",
      "epoch:27 step:25973 [D loss: 0.671286, acc.: 56.25%] [G loss: 1.459150]\n",
      "epoch:27 step:25974 [D loss: 0.708918, acc.: 54.69%] [G loss: 1.065607]\n",
      "epoch:27 step:25975 [D loss: 0.724180, acc.: 60.94%] [G loss: 1.134477]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25976 [D loss: 0.538951, acc.: 74.22%] [G loss: 1.217347]\n",
      "epoch:27 step:25977 [D loss: 0.661800, acc.: 57.03%] [G loss: 0.881518]\n",
      "epoch:27 step:25978 [D loss: 0.607219, acc.: 62.50%] [G loss: 1.048716]\n",
      "epoch:27 step:25979 [D loss: 0.627624, acc.: 61.72%] [G loss: 1.154112]\n",
      "epoch:27 step:25980 [D loss: 0.576753, acc.: 71.88%] [G loss: 1.031724]\n",
      "epoch:27 step:25981 [D loss: 0.595643, acc.: 70.31%] [G loss: 0.960570]\n",
      "epoch:27 step:25982 [D loss: 0.538812, acc.: 74.22%] [G loss: 0.994519]\n",
      "epoch:27 step:25983 [D loss: 0.507328, acc.: 74.22%] [G loss: 1.156128]\n",
      "epoch:27 step:25984 [D loss: 0.527763, acc.: 75.00%] [G loss: 1.168521]\n",
      "epoch:27 step:25985 [D loss: 0.465359, acc.: 82.03%] [G loss: 1.253222]\n",
      "epoch:27 step:25986 [D loss: 0.454458, acc.: 82.81%] [G loss: 1.459172]\n",
      "epoch:27 step:25987 [D loss: 0.624066, acc.: 64.84%] [G loss: 1.209837]\n",
      "epoch:27 step:25988 [D loss: 0.590020, acc.: 68.75%] [G loss: 1.260990]\n",
      "epoch:27 step:25989 [D loss: 0.521101, acc.: 78.12%] [G loss: 1.256816]\n",
      "epoch:27 step:25990 [D loss: 0.632072, acc.: 67.19%] [G loss: 1.062774]\n",
      "epoch:27 step:25991 [D loss: 0.525629, acc.: 71.88%] [G loss: 1.107127]\n",
      "epoch:27 step:25992 [D loss: 0.527702, acc.: 78.12%] [G loss: 1.030368]\n",
      "epoch:27 step:25993 [D loss: 0.473625, acc.: 78.12%] [G loss: 0.947330]\n",
      "epoch:27 step:25994 [D loss: 0.595482, acc.: 67.97%] [G loss: 1.023929]\n",
      "epoch:27 step:25995 [D loss: 0.321784, acc.: 85.16%] [G loss: 1.238951]\n",
      "epoch:27 step:25996 [D loss: 0.238191, acc.: 92.19%] [G loss: 1.264010]\n",
      "epoch:27 step:25997 [D loss: 0.272657, acc.: 94.53%] [G loss: 1.252570]\n",
      "epoch:27 step:25998 [D loss: 0.457305, acc.: 83.59%] [G loss: 1.624949]\n",
      "epoch:27 step:25999 [D loss: 0.216936, acc.: 90.62%] [G loss: 1.850184]\n",
      "epoch:27 step:26000 [D loss: 0.187948, acc.: 97.66%] [G loss: 1.714683]\n",
      "##############\n",
      "[4.09197764 2.61011229 6.81839559 5.9084467  4.81322359 6.29070727\n",
      " 5.56458089 5.70335424 5.8693377  5.28390066]\n",
      "##########\n",
      "epoch:27 step:26001 [D loss: 0.254234, acc.: 96.09%] [G loss: 2.084348]\n",
      "epoch:27 step:26002 [D loss: 0.510979, acc.: 77.34%] [G loss: 1.673623]\n",
      "epoch:27 step:26003 [D loss: 0.268293, acc.: 96.09%] [G loss: 1.472849]\n",
      "epoch:27 step:26004 [D loss: 0.524485, acc.: 74.22%] [G loss: 1.511305]\n",
      "epoch:27 step:26005 [D loss: 0.184216, acc.: 96.88%] [G loss: 1.913919]\n",
      "epoch:27 step:26006 [D loss: 0.161671, acc.: 97.66%] [G loss: 1.618446]\n",
      "epoch:27 step:26007 [D loss: 0.181948, acc.: 96.88%] [G loss: 1.927855]\n",
      "epoch:27 step:26008 [D loss: 0.150030, acc.: 100.00%] [G loss: 1.800909]\n",
      "epoch:27 step:26009 [D loss: 1.065238, acc.: 52.34%] [G loss: 1.423092]\n",
      "epoch:27 step:26010 [D loss: 0.601236, acc.: 67.97%] [G loss: 1.416344]\n",
      "epoch:27 step:26011 [D loss: 0.675679, acc.: 59.38%] [G loss: 1.082837]\n",
      "epoch:27 step:26012 [D loss: 0.219546, acc.: 91.41%] [G loss: 1.374297]\n",
      "epoch:27 step:26013 [D loss: 0.144362, acc.: 100.00%] [G loss: 1.505511]\n",
      "epoch:27 step:26014 [D loss: 0.750906, acc.: 53.12%] [G loss: 1.264296]\n",
      "epoch:27 step:26015 [D loss: 0.788190, acc.: 53.12%] [G loss: 1.240565]\n",
      "epoch:27 step:26016 [D loss: 0.701616, acc.: 60.16%] [G loss: 1.088747]\n",
      "epoch:27 step:26017 [D loss: 0.776659, acc.: 50.78%] [G loss: 1.144677]\n",
      "epoch:27 step:26018 [D loss: 0.680220, acc.: 60.94%] [G loss: 1.462856]\n",
      "epoch:27 step:26019 [D loss: 0.551772, acc.: 72.66%] [G loss: 1.192486]\n",
      "epoch:27 step:26020 [D loss: 0.687880, acc.: 60.16%] [G loss: 0.817748]\n",
      "epoch:27 step:26021 [D loss: 0.409177, acc.: 84.38%] [G loss: 1.063504]\n",
      "epoch:27 step:26022 [D loss: 0.400524, acc.: 82.81%] [G loss: 1.304711]\n",
      "epoch:27 step:26023 [D loss: 0.683697, acc.: 54.69%] [G loss: 1.158400]\n",
      "epoch:27 step:26024 [D loss: 0.595394, acc.: 71.88%] [G loss: 1.127791]\n",
      "epoch:27 step:26025 [D loss: 0.538290, acc.: 71.88%] [G loss: 1.095353]\n",
      "epoch:27 step:26026 [D loss: 0.264297, acc.: 87.50%] [G loss: 1.205467]\n",
      "epoch:27 step:26027 [D loss: 0.190719, acc.: 98.44%] [G loss: 1.425981]\n",
      "epoch:27 step:26028 [D loss: 0.267875, acc.: 90.62%] [G loss: 1.624664]\n",
      "epoch:27 step:26029 [D loss: 0.134715, acc.: 100.00%] [G loss: 1.314620]\n",
      "epoch:27 step:26030 [D loss: 0.178304, acc.: 96.88%] [G loss: 1.858475]\n",
      "epoch:27 step:26031 [D loss: 0.123191, acc.: 100.00%] [G loss: 1.833733]\n",
      "epoch:27 step:26032 [D loss: 0.145986, acc.: 99.22%] [G loss: 2.008351]\n",
      "epoch:27 step:26033 [D loss: 0.660313, acc.: 60.16%] [G loss: 1.497711]\n",
      "epoch:27 step:26034 [D loss: 0.785901, acc.: 55.47%] [G loss: 1.574371]\n",
      "epoch:27 step:26035 [D loss: 0.884604, acc.: 42.19%] [G loss: 1.174958]\n",
      "epoch:27 step:26036 [D loss: 0.675663, acc.: 57.03%] [G loss: 1.153920]\n",
      "epoch:27 step:26037 [D loss: 0.606073, acc.: 67.19%] [G loss: 1.003316]\n",
      "epoch:27 step:26038 [D loss: 0.305843, acc.: 88.28%] [G loss: 1.112702]\n",
      "epoch:27 step:26039 [D loss: 0.281938, acc.: 97.66%] [G loss: 1.302975]\n",
      "epoch:27 step:26040 [D loss: 0.642644, acc.: 59.38%] [G loss: 1.092125]\n",
      "epoch:27 step:26041 [D loss: 0.453349, acc.: 78.91%] [G loss: 0.946643]\n",
      "epoch:27 step:26042 [D loss: 0.740048, acc.: 56.25%] [G loss: 1.385094]\n",
      "epoch:27 step:26043 [D loss: 0.602702, acc.: 65.62%] [G loss: 1.460879]\n",
      "epoch:27 step:26044 [D loss: 0.237795, acc.: 96.88%] [G loss: 1.530126]\n",
      "epoch:27 step:26045 [D loss: 0.291687, acc.: 92.19%] [G loss: 1.374041]\n",
      "epoch:27 step:26046 [D loss: 0.554700, acc.: 75.78%] [G loss: 1.163591]\n",
      "epoch:27 step:26047 [D loss: 0.729722, acc.: 53.12%] [G loss: 1.238334]\n",
      "epoch:27 step:26048 [D loss: 0.731234, acc.: 53.12%] [G loss: 1.296422]\n",
      "epoch:27 step:26049 [D loss: 0.428927, acc.: 82.81%] [G loss: 1.154621]\n",
      "epoch:27 step:26050 [D loss: 0.666170, acc.: 57.81%] [G loss: 1.367054]\n",
      "epoch:27 step:26051 [D loss: 0.546243, acc.: 71.88%] [G loss: 0.832693]\n",
      "epoch:27 step:26052 [D loss: 0.525274, acc.: 74.22%] [G loss: 1.057317]\n",
      "epoch:27 step:26053 [D loss: 0.764148, acc.: 60.94%] [G loss: 1.519021]\n",
      "epoch:27 step:26054 [D loss: 0.252535, acc.: 89.06%] [G loss: 1.219351]\n",
      "epoch:27 step:26055 [D loss: 0.341361, acc.: 89.06%] [G loss: 1.770131]\n",
      "epoch:27 step:26056 [D loss: 0.441921, acc.: 80.47%] [G loss: 1.536198]\n",
      "epoch:27 step:26057 [D loss: 0.653810, acc.: 60.94%] [G loss: 1.401734]\n",
      "epoch:27 step:26058 [D loss: 0.530069, acc.: 74.22%] [G loss: 1.410734]\n",
      "epoch:27 step:26059 [D loss: 0.521401, acc.: 74.22%] [G loss: 1.249380]\n",
      "epoch:27 step:26060 [D loss: 1.287876, acc.: 20.31%] [G loss: 1.427095]\n",
      "epoch:27 step:26061 [D loss: 0.515891, acc.: 71.09%] [G loss: 1.055863]\n",
      "epoch:27 step:26062 [D loss: 0.645529, acc.: 61.72%] [G loss: 1.095073]\n",
      "epoch:27 step:26063 [D loss: 0.258838, acc.: 96.88%] [G loss: 1.036879]\n",
      "epoch:27 step:26064 [D loss: 0.507659, acc.: 75.00%] [G loss: 1.519434]\n",
      "epoch:27 step:26065 [D loss: 0.572870, acc.: 72.66%] [G loss: 0.830746]\n",
      "epoch:27 step:26066 [D loss: 0.467450, acc.: 83.59%] [G loss: 1.530858]\n",
      "epoch:27 step:26067 [D loss: 0.242179, acc.: 92.97%] [G loss: 1.657297]\n",
      "epoch:27 step:26068 [D loss: 0.142851, acc.: 96.88%] [G loss: 1.868729]\n",
      "epoch:27 step:26069 [D loss: 0.353178, acc.: 93.75%] [G loss: 1.515477]\n",
      "epoch:27 step:26070 [D loss: 0.828506, acc.: 49.22%] [G loss: 1.681432]\n",
      "epoch:27 step:26071 [D loss: 0.890305, acc.: 39.84%] [G loss: 1.416492]\n",
      "epoch:27 step:26072 [D loss: 0.628582, acc.: 66.41%] [G loss: 1.131860]\n",
      "epoch:27 step:26073 [D loss: 0.262157, acc.: 85.16%] [G loss: 1.470108]\n",
      "epoch:27 step:26074 [D loss: 0.186461, acc.: 93.75%] [G loss: 1.204077]\n",
      "epoch:27 step:26075 [D loss: 0.455452, acc.: 80.47%] [G loss: 1.345613]\n",
      "epoch:27 step:26076 [D loss: 0.233604, acc.: 94.53%] [G loss: 1.546496]\n",
      "epoch:27 step:26077 [D loss: 0.436391, acc.: 85.94%] [G loss: 1.362274]\n",
      "epoch:27 step:26078 [D loss: 1.258056, acc.: 21.09%] [G loss: 1.355088]\n",
      "epoch:27 step:26079 [D loss: 0.335618, acc.: 89.84%] [G loss: 1.719218]\n",
      "epoch:27 step:26080 [D loss: 0.224965, acc.: 98.44%] [G loss: 1.573220]\n",
      "epoch:27 step:26081 [D loss: 0.503992, acc.: 76.56%] [G loss: 1.678740]\n",
      "epoch:27 step:26082 [D loss: 0.654408, acc.: 67.19%] [G loss: 1.212459]\n",
      "epoch:27 step:26083 [D loss: 0.727161, acc.: 57.81%] [G loss: 1.501774]\n",
      "epoch:27 step:26084 [D loss: 0.746798, acc.: 51.56%] [G loss: 1.328277]\n",
      "epoch:27 step:26085 [D loss: 0.277454, acc.: 86.72%] [G loss: 1.476845]\n",
      "epoch:27 step:26086 [D loss: 0.773354, acc.: 51.56%] [G loss: 1.410784]\n",
      "epoch:27 step:26087 [D loss: 0.717966, acc.: 59.38%] [G loss: 1.363387]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:26088 [D loss: 0.858934, acc.: 41.41%] [G loss: 1.243609]\n",
      "epoch:27 step:26089 [D loss: 0.623038, acc.: 66.41%] [G loss: 1.152983]\n",
      "epoch:27 step:26090 [D loss: 0.224685, acc.: 92.19%] [G loss: 1.140619]\n",
      "epoch:27 step:26091 [D loss: 0.293644, acc.: 85.94%] [G loss: 1.324141]\n",
      "epoch:27 step:26092 [D loss: 0.247012, acc.: 92.97%] [G loss: 1.506070]\n",
      "epoch:27 step:26093 [D loss: 0.251839, acc.: 91.41%] [G loss: 1.544208]\n",
      "epoch:27 step:26094 [D loss: 0.513640, acc.: 80.47%] [G loss: 1.574288]\n",
      "epoch:27 step:26095 [D loss: 0.200828, acc.: 100.00%] [G loss: 1.595623]\n",
      "epoch:27 step:26096 [D loss: 0.623576, acc.: 60.94%] [G loss: 1.680642]\n",
      "epoch:27 step:26097 [D loss: 0.445680, acc.: 85.16%] [G loss: 1.382853]\n",
      "epoch:27 step:26098 [D loss: 0.590775, acc.: 72.66%] [G loss: 1.445873]\n",
      "epoch:27 step:26099 [D loss: 0.473799, acc.: 75.78%] [G loss: 1.430295]\n",
      "epoch:27 step:26100 [D loss: 0.374738, acc.: 85.94%] [G loss: 1.424403]\n",
      "epoch:27 step:26101 [D loss: 0.267405, acc.: 94.53%] [G loss: 1.241681]\n",
      "epoch:27 step:26102 [D loss: 0.716643, acc.: 54.69%] [G loss: 1.313083]\n",
      "epoch:27 step:26103 [D loss: 0.219346, acc.: 94.53%] [G loss: 1.522515]\n",
      "epoch:27 step:26104 [D loss: 0.339914, acc.: 78.12%] [G loss: 1.420351]\n",
      "epoch:27 step:26105 [D loss: 0.136636, acc.: 98.44%] [G loss: 1.836080]\n",
      "epoch:27 step:26106 [D loss: 0.913552, acc.: 46.88%] [G loss: 1.359457]\n",
      "epoch:27 step:26107 [D loss: 0.383960, acc.: 85.16%] [G loss: 1.552545]\n",
      "epoch:27 step:26108 [D loss: 0.265625, acc.: 94.53%] [G loss: 1.517018]\n",
      "epoch:27 step:26109 [D loss: 0.491185, acc.: 75.00%] [G loss: 1.542752]\n",
      "epoch:27 step:26110 [D loss: 0.798623, acc.: 53.12%] [G loss: 1.473135]\n",
      "epoch:27 step:26111 [D loss: 0.630585, acc.: 61.72%] [G loss: 1.484243]\n",
      "epoch:27 step:26112 [D loss: 0.872626, acc.: 45.31%] [G loss: 1.138066]\n",
      "epoch:27 step:26113 [D loss: 0.719265, acc.: 56.25%] [G loss: 1.063789]\n",
      "epoch:27 step:26114 [D loss: 0.323201, acc.: 79.69%] [G loss: 1.376716]\n",
      "epoch:27 step:26115 [D loss: 0.365218, acc.: 89.84%] [G loss: 1.338415]\n",
      "epoch:27 step:26116 [D loss: 0.590683, acc.: 67.19%] [G loss: 1.225075]\n",
      "epoch:27 step:26117 [D loss: 0.737589, acc.: 52.34%] [G loss: 1.128016]\n",
      "epoch:27 step:26118 [D loss: 0.779823, acc.: 43.75%] [G loss: 0.857605]\n",
      "epoch:27 step:26119 [D loss: 0.751541, acc.: 50.00%] [G loss: 1.028758]\n",
      "epoch:27 step:26120 [D loss: 0.371570, acc.: 79.69%] [G loss: 1.246996]\n",
      "epoch:27 step:26121 [D loss: 0.405929, acc.: 84.38%] [G loss: 1.227916]\n",
      "epoch:27 step:26122 [D loss: 0.627896, acc.: 67.19%] [G loss: 1.168369]\n",
      "epoch:27 step:26123 [D loss: 0.552825, acc.: 72.66%] [G loss: 0.968365]\n",
      "epoch:27 step:26124 [D loss: 0.543032, acc.: 75.00%] [G loss: 1.189858]\n",
      "epoch:27 step:26125 [D loss: 0.848083, acc.: 46.88%] [G loss: 1.240424]\n",
      "epoch:27 step:26126 [D loss: 0.736793, acc.: 51.56%] [G loss: 1.201423]\n",
      "epoch:27 step:26127 [D loss: 0.629528, acc.: 64.06%] [G loss: 1.148453]\n",
      "epoch:27 step:26128 [D loss: 0.629439, acc.: 65.62%] [G loss: 0.885571]\n",
      "epoch:27 step:26129 [D loss: 0.442204, acc.: 85.16%] [G loss: 1.150712]\n",
      "epoch:27 step:26130 [D loss: 0.265460, acc.: 96.09%] [G loss: 1.177628]\n",
      "epoch:27 step:26131 [D loss: 0.337600, acc.: 82.81%] [G loss: 1.385337]\n",
      "epoch:27 step:26132 [D loss: 0.217927, acc.: 97.66%] [G loss: 1.193858]\n",
      "epoch:27 step:26133 [D loss: 0.435096, acc.: 85.16%] [G loss: 1.398612]\n",
      "epoch:27 step:26134 [D loss: 0.570866, acc.: 67.97%] [G loss: 1.277051]\n",
      "epoch:27 step:26135 [D loss: 0.705011, acc.: 56.25%] [G loss: 0.784968]\n",
      "epoch:27 step:26136 [D loss: 0.678053, acc.: 59.38%] [G loss: 0.992422]\n",
      "epoch:27 step:26137 [D loss: 0.504050, acc.: 78.12%] [G loss: 1.155251]\n",
      "epoch:27 step:26138 [D loss: 0.697252, acc.: 53.91%] [G loss: 1.061273]\n",
      "epoch:27 step:26139 [D loss: 0.627520, acc.: 60.94%] [G loss: 1.109772]\n",
      "epoch:27 step:26140 [D loss: 0.305662, acc.: 93.75%] [G loss: 1.260114]\n",
      "epoch:27 step:26141 [D loss: 0.367420, acc.: 89.84%] [G loss: 1.368418]\n",
      "epoch:27 step:26142 [D loss: 0.276823, acc.: 96.88%] [G loss: 1.303568]\n",
      "epoch:27 step:26143 [D loss: 0.325945, acc.: 89.06%] [G loss: 0.894208]\n",
      "epoch:27 step:26144 [D loss: 0.219667, acc.: 94.53%] [G loss: 1.191265]\n",
      "epoch:27 step:26145 [D loss: 0.854276, acc.: 42.19%] [G loss: 0.808553]\n",
      "epoch:27 step:26146 [D loss: 0.231896, acc.: 94.53%] [G loss: 1.630945]\n",
      "epoch:27 step:26147 [D loss: 0.302824, acc.: 93.75%] [G loss: 0.841657]\n",
      "epoch:27 step:26148 [D loss: 0.661902, acc.: 63.28%] [G loss: 0.435276]\n",
      "epoch:27 step:26149 [D loss: 1.174859, acc.: 52.34%] [G loss: 0.934214]\n",
      "epoch:27 step:26150 [D loss: 0.179182, acc.: 96.88%] [G loss: 1.293545]\n",
      "epoch:27 step:26151 [D loss: 0.284916, acc.: 93.75%] [G loss: 1.815541]\n",
      "epoch:27 step:26152 [D loss: 0.290026, acc.: 95.31%] [G loss: 1.763704]\n",
      "epoch:27 step:26153 [D loss: 0.540410, acc.: 65.62%] [G loss: 0.365421]\n",
      "epoch:27 step:26154 [D loss: 0.653314, acc.: 59.38%] [G loss: 0.899614]\n",
      "epoch:27 step:26155 [D loss: 0.884980, acc.: 51.56%] [G loss: 1.029934]\n",
      "epoch:27 step:26156 [D loss: 1.162074, acc.: 42.19%] [G loss: 0.814923]\n",
      "epoch:27 step:26157 [D loss: 0.243593, acc.: 92.97%] [G loss: 0.991882]\n",
      "epoch:27 step:26158 [D loss: 0.227699, acc.: 90.62%] [G loss: 1.246998]\n",
      "epoch:27 step:26159 [D loss: 0.204604, acc.: 93.75%] [G loss: 1.549712]\n",
      "epoch:27 step:26160 [D loss: 1.178069, acc.: 40.62%] [G loss: 1.109978]\n",
      "epoch:27 step:26161 [D loss: 1.095667, acc.: 36.72%] [G loss: 1.178725]\n",
      "epoch:27 step:26162 [D loss: 0.455803, acc.: 75.00%] [G loss: 1.746594]\n",
      "epoch:27 step:26163 [D loss: 0.496065, acc.: 74.22%] [G loss: 1.830197]\n",
      "epoch:27 step:26164 [D loss: 0.794920, acc.: 56.25%] [G loss: 1.859689]\n",
      "epoch:27 step:26165 [D loss: 0.619103, acc.: 65.62%] [G loss: 1.244656]\n",
      "epoch:27 step:26166 [D loss: 0.690326, acc.: 61.72%] [G loss: 1.406557]\n",
      "epoch:27 step:26167 [D loss: 0.424370, acc.: 82.03%] [G loss: 1.466828]\n",
      "epoch:27 step:26168 [D loss: 0.510454, acc.: 77.34%] [G loss: 1.311344]\n",
      "epoch:27 step:26169 [D loss: 0.236408, acc.: 92.97%] [G loss: 1.820154]\n",
      "epoch:27 step:26170 [D loss: 0.297469, acc.: 91.41%] [G loss: 1.698824]\n",
      "epoch:27 step:26171 [D loss: 0.670362, acc.: 59.38%] [G loss: 1.663630]\n",
      "epoch:27 step:26172 [D loss: 0.219337, acc.: 98.44%] [G loss: 1.786107]\n",
      "epoch:27 step:26173 [D loss: 0.215641, acc.: 95.31%] [G loss: 1.331241]\n",
      "epoch:27 step:26174 [D loss: 0.234848, acc.: 96.09%] [G loss: 2.085375]\n",
      "epoch:27 step:26175 [D loss: 0.142550, acc.: 97.66%] [G loss: 1.897479]\n",
      "epoch:27 step:26176 [D loss: 0.114991, acc.: 99.22%] [G loss: 1.880423]\n",
      "epoch:27 step:26177 [D loss: 0.171551, acc.: 96.09%] [G loss: 2.148998]\n",
      "epoch:27 step:26178 [D loss: 0.245111, acc.: 94.53%] [G loss: 1.431068]\n",
      "epoch:27 step:26179 [D loss: 0.496594, acc.: 69.53%] [G loss: 1.945640]\n",
      "epoch:27 step:26180 [D loss: 0.432086, acc.: 84.38%] [G loss: 0.819581]\n",
      "epoch:27 step:26181 [D loss: 1.184309, acc.: 28.12%] [G loss: 1.192602]\n",
      "epoch:27 step:26182 [D loss: 1.057826, acc.: 30.47%] [G loss: 0.485762]\n",
      "epoch:27 step:26183 [D loss: 1.001044, acc.: 46.09%] [G loss: 0.411108]\n",
      "epoch:27 step:26184 [D loss: 0.792070, acc.: 57.03%] [G loss: 0.875233]\n",
      "epoch:27 step:26185 [D loss: 0.868060, acc.: 39.84%] [G loss: 1.334299]\n",
      "epoch:27 step:26186 [D loss: 0.931485, acc.: 43.75%] [G loss: 0.783384]\n",
      "epoch:27 step:26187 [D loss: 0.784020, acc.: 47.66%] [G loss: 1.299888]\n",
      "epoch:27 step:26188 [D loss: 0.636196, acc.: 60.16%] [G loss: 1.176161]\n",
      "epoch:27 step:26189 [D loss: 0.659760, acc.: 61.72%] [G loss: 0.830818]\n",
      "epoch:27 step:26190 [D loss: 0.445096, acc.: 71.88%] [G loss: 0.852377]\n",
      "epoch:27 step:26191 [D loss: 0.235666, acc.: 96.09%] [G loss: 1.542607]\n",
      "epoch:27 step:26192 [D loss: 0.188173, acc.: 96.09%] [G loss: 1.520756]\n",
      "epoch:27 step:26193 [D loss: 0.483470, acc.: 70.31%] [G loss: 0.620709]\n",
      "epoch:27 step:26194 [D loss: 0.441225, acc.: 80.47%] [G loss: 0.952985]\n",
      "epoch:27 step:26195 [D loss: 0.226801, acc.: 98.44%] [G loss: 1.967231]\n",
      "epoch:27 step:26196 [D loss: 0.587526, acc.: 67.97%] [G loss: 1.125800]\n",
      "epoch:27 step:26197 [D loss: 0.181761, acc.: 98.44%] [G loss: 1.338456]\n",
      "epoch:27 step:26198 [D loss: 0.388044, acc.: 79.69%] [G loss: 2.317275]\n",
      "epoch:27 step:26199 [D loss: 0.249178, acc.: 89.06%] [G loss: 2.944507]\n",
      "epoch:27 step:26200 [D loss: 0.455205, acc.: 82.03%] [G loss: 1.511716]\n",
      "##############\n",
      "[3.92637323 2.24730788 6.57203243 5.51703614 4.48307575 6.17739516\n",
      " 5.28057726 5.57833981 5.95999555 5.03558889]\n",
      "##########\n",
      "epoch:27 step:26201 [D loss: 0.926890, acc.: 50.78%] [G loss: 1.015679]\n",
      "epoch:27 step:26202 [D loss: 0.543981, acc.: 63.28%] [G loss: 0.671665]\n",
      "epoch:27 step:26203 [D loss: 1.129880, acc.: 21.88%] [G loss: 1.054463]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:26204 [D loss: 0.986652, acc.: 39.06%] [G loss: 1.907868]\n",
      "epoch:27 step:26205 [D loss: 0.457933, acc.: 83.59%] [G loss: 1.776851]\n",
      "epoch:27 step:26206 [D loss: 0.724772, acc.: 54.69%] [G loss: 1.523707]\n",
      "epoch:27 step:26207 [D loss: 1.084913, acc.: 25.78%] [G loss: 1.785130]\n",
      "epoch:27 step:26208 [D loss: 0.585892, acc.: 71.88%] [G loss: 1.043629]\n",
      "epoch:27 step:26209 [D loss: 0.548061, acc.: 68.75%] [G loss: 1.632422]\n",
      "epoch:27 step:26210 [D loss: 0.567888, acc.: 72.66%] [G loss: 1.347805]\n",
      "epoch:27 step:26211 [D loss: 0.265200, acc.: 90.62%] [G loss: 1.820504]\n",
      "epoch:27 step:26212 [D loss: 0.690024, acc.: 53.91%] [G loss: 1.624204]\n",
      "epoch:27 step:26213 [D loss: 0.750292, acc.: 49.22%] [G loss: 1.294185]\n",
      "epoch:27 step:26214 [D loss: 0.782791, acc.: 50.78%] [G loss: 1.829035]\n",
      "epoch:27 step:26215 [D loss: 0.446978, acc.: 80.47%] [G loss: 1.368459]\n",
      "epoch:27 step:26216 [D loss: 0.299366, acc.: 96.88%] [G loss: 1.520858]\n",
      "epoch:27 step:26217 [D loss: 0.578236, acc.: 64.84%] [G loss: 1.503367]\n",
      "epoch:27 step:26218 [D loss: 0.547677, acc.: 71.09%] [G loss: 1.230728]\n",
      "epoch:27 step:26219 [D loss: 0.224873, acc.: 93.75%] [G loss: 1.520333]\n",
      "epoch:27 step:26220 [D loss: 0.200483, acc.: 96.09%] [G loss: 1.300969]\n",
      "epoch:27 step:26221 [D loss: 0.555735, acc.: 75.00%] [G loss: 1.519275]\n",
      "epoch:27 step:26222 [D loss: 0.586482, acc.: 67.19%] [G loss: 1.722272]\n",
      "epoch:27 step:26223 [D loss: 0.418073, acc.: 84.38%] [G loss: 1.449867]\n",
      "epoch:27 step:26224 [D loss: 0.446043, acc.: 84.38%] [G loss: 1.141525]\n",
      "epoch:27 step:26225 [D loss: 0.513111, acc.: 75.78%] [G loss: 1.027775]\n",
      "epoch:27 step:26226 [D loss: 0.374892, acc.: 82.81%] [G loss: 1.275279]\n",
      "epoch:27 step:26227 [D loss: 0.474647, acc.: 77.34%] [G loss: 1.082834]\n",
      "epoch:27 step:26228 [D loss: 0.220723, acc.: 93.75%] [G loss: 1.268251]\n",
      "epoch:27 step:26229 [D loss: 0.242546, acc.: 92.97%] [G loss: 1.620081]\n",
      "epoch:27 step:26230 [D loss: 0.240224, acc.: 96.88%] [G loss: 1.306080]\n",
      "epoch:27 step:26231 [D loss: 0.676904, acc.: 62.50%] [G loss: 1.482096]\n",
      "epoch:27 step:26232 [D loss: 0.463580, acc.: 85.94%] [G loss: 1.337133]\n",
      "epoch:27 step:26233 [D loss: 0.652079, acc.: 63.28%] [G loss: 1.334152]\n",
      "epoch:27 step:26234 [D loss: 0.707987, acc.: 59.38%] [G loss: 1.177605]\n",
      "epoch:27 step:26235 [D loss: 0.467630, acc.: 78.12%] [G loss: 1.321575]\n",
      "epoch:27 step:26236 [D loss: 0.376902, acc.: 82.81%] [G loss: 1.646770]\n",
      "epoch:28 step:26237 [D loss: 0.727474, acc.: 52.34%] [G loss: 1.297445]\n",
      "epoch:28 step:26238 [D loss: 0.692170, acc.: 53.12%] [G loss: 1.269651]\n",
      "epoch:28 step:26239 [D loss: 0.771994, acc.: 51.56%] [G loss: 1.390396]\n",
      "epoch:28 step:26240 [D loss: 0.581838, acc.: 69.53%] [G loss: 0.986015]\n",
      "epoch:28 step:26241 [D loss: 0.557215, acc.: 76.56%] [G loss: 1.327404]\n",
      "epoch:28 step:26242 [D loss: 0.569540, acc.: 72.66%] [G loss: 1.273590]\n",
      "epoch:28 step:26243 [D loss: 0.890196, acc.: 36.72%] [G loss: 1.282282]\n",
      "epoch:28 step:26244 [D loss: 0.773686, acc.: 41.41%] [G loss: 1.143259]\n",
      "epoch:28 step:26245 [D loss: 0.558356, acc.: 70.31%] [G loss: 1.233928]\n",
      "epoch:28 step:26246 [D loss: 0.436475, acc.: 87.50%] [G loss: 1.056962]\n",
      "epoch:28 step:26247 [D loss: 0.623010, acc.: 67.97%] [G loss: 0.858535]\n",
      "epoch:28 step:26248 [D loss: 0.467741, acc.: 80.47%] [G loss: 1.077357]\n",
      "epoch:28 step:26249 [D loss: 0.568090, acc.: 71.88%] [G loss: 1.083150]\n",
      "epoch:28 step:26250 [D loss: 0.586271, acc.: 69.53%] [G loss: 0.906949]\n",
      "epoch:28 step:26251 [D loss: 0.327652, acc.: 88.28%] [G loss: 1.189422]\n",
      "epoch:28 step:26252 [D loss: 0.395690, acc.: 85.16%] [G loss: 1.000503]\n",
      "epoch:28 step:26253 [D loss: 0.545284, acc.: 74.22%] [G loss: 1.595977]\n",
      "epoch:28 step:26254 [D loss: 0.491778, acc.: 79.69%] [G loss: 1.310664]\n",
      "epoch:28 step:26255 [D loss: 1.189382, acc.: 31.25%] [G loss: 1.394105]\n",
      "epoch:28 step:26256 [D loss: 0.607574, acc.: 63.28%] [G loss: 1.390117]\n",
      "epoch:28 step:26257 [D loss: 0.706180, acc.: 60.94%] [G loss: 1.427105]\n",
      "epoch:28 step:26258 [D loss: 0.649906, acc.: 64.84%] [G loss: 1.146487]\n",
      "epoch:28 step:26259 [D loss: 0.527248, acc.: 72.66%] [G loss: 1.112837]\n",
      "epoch:28 step:26260 [D loss: 0.640125, acc.: 59.38%] [G loss: 1.013371]\n",
      "epoch:28 step:26261 [D loss: 0.352196, acc.: 87.50%] [G loss: 1.420967]\n",
      "epoch:28 step:26262 [D loss: 0.731010, acc.: 51.56%] [G loss: 1.202334]\n",
      "epoch:28 step:26263 [D loss: 0.286913, acc.: 97.66%] [G loss: 1.044599]\n",
      "epoch:28 step:26264 [D loss: 0.678485, acc.: 58.59%] [G loss: 1.048395]\n",
      "epoch:28 step:26265 [D loss: 0.562724, acc.: 72.66%] [G loss: 1.246287]\n",
      "epoch:28 step:26266 [D loss: 0.609584, acc.: 65.62%] [G loss: 1.262265]\n",
      "epoch:28 step:26267 [D loss: 0.357637, acc.: 85.16%] [G loss: 1.320898]\n",
      "epoch:28 step:26268 [D loss: 0.267376, acc.: 95.31%] [G loss: 1.302865]\n",
      "epoch:28 step:26269 [D loss: 0.316572, acc.: 89.84%] [G loss: 1.308751]\n",
      "epoch:28 step:26270 [D loss: 0.268154, acc.: 95.31%] [G loss: 1.452326]\n",
      "epoch:28 step:26271 [D loss: 0.190999, acc.: 97.66%] [G loss: 1.720848]\n",
      "epoch:28 step:26272 [D loss: 0.156959, acc.: 96.09%] [G loss: 0.724601]\n",
      "epoch:28 step:26273 [D loss: 0.832108, acc.: 54.69%] [G loss: 1.386601]\n",
      "epoch:28 step:26274 [D loss: 0.535187, acc.: 75.78%] [G loss: 1.332300]\n",
      "epoch:28 step:26275 [D loss: 0.815361, acc.: 41.41%] [G loss: 1.356176]\n",
      "epoch:28 step:26276 [D loss: 0.386062, acc.: 91.41%] [G loss: 1.223443]\n",
      "epoch:28 step:26277 [D loss: 0.765483, acc.: 50.00%] [G loss: 1.143609]\n",
      "epoch:28 step:26278 [D loss: 0.562569, acc.: 71.88%] [G loss: 1.081415]\n",
      "epoch:28 step:26279 [D loss: 0.511762, acc.: 82.81%] [G loss: 1.136690]\n",
      "epoch:28 step:26280 [D loss: 0.578178, acc.: 71.88%] [G loss: 1.384927]\n",
      "epoch:28 step:26281 [D loss: 0.545370, acc.: 78.91%] [G loss: 0.581242]\n",
      "epoch:28 step:26282 [D loss: 0.499703, acc.: 83.59%] [G loss: 1.215664]\n",
      "epoch:28 step:26283 [D loss: 0.776958, acc.: 44.53%] [G loss: 1.008375]\n",
      "epoch:28 step:26284 [D loss: 0.660874, acc.: 57.03%] [G loss: 1.103823]\n",
      "epoch:28 step:26285 [D loss: 0.726203, acc.: 54.69%] [G loss: 1.087538]\n",
      "epoch:28 step:26286 [D loss: 0.517423, acc.: 73.44%] [G loss: 0.634013]\n",
      "epoch:28 step:26287 [D loss: 0.484685, acc.: 78.91%] [G loss: 0.869225]\n",
      "epoch:28 step:26288 [D loss: 0.659559, acc.: 58.59%] [G loss: 0.713389]\n",
      "epoch:28 step:26289 [D loss: 0.983644, acc.: 39.06%] [G loss: 1.208758]\n",
      "epoch:28 step:26290 [D loss: 0.719230, acc.: 54.69%] [G loss: 1.057597]\n",
      "epoch:28 step:26291 [D loss: 0.630428, acc.: 67.97%] [G loss: 0.805028]\n",
      "epoch:28 step:26292 [D loss: 0.749258, acc.: 49.22%] [G loss: 0.844774]\n",
      "epoch:28 step:26293 [D loss: 0.653821, acc.: 62.50%] [G loss: 1.397531]\n",
      "epoch:28 step:26294 [D loss: 0.459185, acc.: 85.94%] [G loss: 1.470841]\n",
      "epoch:28 step:26295 [D loss: 0.512071, acc.: 78.91%] [G loss: 1.194487]\n",
      "epoch:28 step:26296 [D loss: 0.613346, acc.: 68.75%] [G loss: 1.115443]\n",
      "epoch:28 step:26297 [D loss: 0.708850, acc.: 54.69%] [G loss: 1.095208]\n",
      "epoch:28 step:26298 [D loss: 0.802863, acc.: 42.19%] [G loss: 0.933318]\n",
      "epoch:28 step:26299 [D loss: 0.669660, acc.: 64.84%] [G loss: 0.621455]\n",
      "epoch:28 step:26300 [D loss: 0.669625, acc.: 59.38%] [G loss: 1.137872]\n",
      "epoch:28 step:26301 [D loss: 0.925762, acc.: 32.81%] [G loss: 1.091012]\n",
      "epoch:28 step:26302 [D loss: 0.681254, acc.: 57.03%] [G loss: 0.997176]\n",
      "epoch:28 step:26303 [D loss: 0.852667, acc.: 39.84%] [G loss: 1.025597]\n",
      "epoch:28 step:26304 [D loss: 0.534641, acc.: 75.78%] [G loss: 0.794049]\n",
      "epoch:28 step:26305 [D loss: 0.281704, acc.: 94.53%] [G loss: 1.290953]\n",
      "epoch:28 step:26306 [D loss: 0.459020, acc.: 80.47%] [G loss: 1.484459]\n",
      "epoch:28 step:26307 [D loss: 0.341090, acc.: 89.84%] [G loss: 1.382291]\n",
      "epoch:28 step:26308 [D loss: 0.558687, acc.: 75.78%] [G loss: 1.147621]\n",
      "epoch:28 step:26309 [D loss: 0.723558, acc.: 53.91%] [G loss: 1.314900]\n",
      "epoch:28 step:26310 [D loss: 0.739670, acc.: 50.78%] [G loss: 1.476649]\n",
      "epoch:28 step:26311 [D loss: 0.341114, acc.: 85.94%] [G loss: 1.460100]\n",
      "epoch:28 step:26312 [D loss: 0.348062, acc.: 88.28%] [G loss: 1.519405]\n",
      "epoch:28 step:26313 [D loss: 0.483915, acc.: 76.56%] [G loss: 1.545880]\n",
      "epoch:28 step:26314 [D loss: 0.794069, acc.: 50.78%] [G loss: 0.670933]\n",
      "epoch:28 step:26315 [D loss: 0.801247, acc.: 53.12%] [G loss: 1.533480]\n",
      "epoch:28 step:26316 [D loss: 0.503868, acc.: 77.34%] [G loss: 1.335984]\n",
      "epoch:28 step:26317 [D loss: 0.296359, acc.: 96.09%] [G loss: 1.227586]\n",
      "epoch:28 step:26318 [D loss: 0.223370, acc.: 95.31%] [G loss: 1.422568]\n",
      "epoch:28 step:26319 [D loss: 0.265326, acc.: 86.72%] [G loss: 1.876775]\n",
      "epoch:28 step:26320 [D loss: 0.435184, acc.: 79.69%] [G loss: 1.594318]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26321 [D loss: 0.420205, acc.: 86.72%] [G loss: 1.702344]\n",
      "epoch:28 step:26322 [D loss: 0.533530, acc.: 67.19%] [G loss: 1.326020]\n",
      "epoch:28 step:26323 [D loss: 0.224206, acc.: 94.53%] [G loss: 1.540627]\n",
      "epoch:28 step:26324 [D loss: 0.324497, acc.: 92.97%] [G loss: 1.197461]\n",
      "epoch:28 step:26325 [D loss: 0.219933, acc.: 100.00%] [G loss: 1.674570]\n",
      "epoch:28 step:26326 [D loss: 0.206751, acc.: 98.44%] [G loss: 1.876996]\n",
      "epoch:28 step:26327 [D loss: 0.348978, acc.: 92.19%] [G loss: 1.199278]\n",
      "epoch:28 step:26328 [D loss: 0.190306, acc.: 96.88%] [G loss: 1.311040]\n",
      "epoch:28 step:26329 [D loss: 0.622241, acc.: 59.38%] [G loss: 1.748021]\n",
      "epoch:28 step:26330 [D loss: 0.426154, acc.: 82.03%] [G loss: 1.721507]\n",
      "epoch:28 step:26331 [D loss: 0.739565, acc.: 60.94%] [G loss: 1.634568]\n",
      "epoch:28 step:26332 [D loss: 0.490835, acc.: 77.34%] [G loss: 0.641022]\n",
      "epoch:28 step:26333 [D loss: 0.500556, acc.: 73.44%] [G loss: 0.888310]\n",
      "epoch:28 step:26334 [D loss: 0.856254, acc.: 46.09%] [G loss: 0.563166]\n",
      "epoch:28 step:26335 [D loss: 1.521528, acc.: 21.88%] [G loss: 1.207237]\n",
      "epoch:28 step:26336 [D loss: 0.916211, acc.: 37.50%] [G loss: 1.499902]\n",
      "epoch:28 step:26337 [D loss: 0.501432, acc.: 82.03%] [G loss: 1.615114]\n",
      "epoch:28 step:26338 [D loss: 0.921295, acc.: 38.28%] [G loss: 0.900972]\n",
      "epoch:28 step:26339 [D loss: 0.882143, acc.: 39.84%] [G loss: 0.751165]\n",
      "epoch:28 step:26340 [D loss: 0.789011, acc.: 50.78%] [G loss: 0.833303]\n",
      "epoch:28 step:26341 [D loss: 0.653212, acc.: 63.28%] [G loss: 0.919477]\n",
      "epoch:28 step:26342 [D loss: 0.699619, acc.: 57.03%] [G loss: 1.212700]\n",
      "epoch:28 step:26343 [D loss: 0.832524, acc.: 46.88%] [G loss: 0.867366]\n",
      "epoch:28 step:26344 [D loss: 0.710616, acc.: 52.34%] [G loss: 1.035305]\n",
      "epoch:28 step:26345 [D loss: 0.698720, acc.: 54.69%] [G loss: 1.021084]\n",
      "epoch:28 step:26346 [D loss: 0.669356, acc.: 60.16%] [G loss: 1.109663]\n",
      "epoch:28 step:26347 [D loss: 0.459282, acc.: 84.38%] [G loss: 1.115859]\n",
      "epoch:28 step:26348 [D loss: 0.603514, acc.: 64.84%] [G loss: 1.009214]\n",
      "epoch:28 step:26349 [D loss: 0.440175, acc.: 85.16%] [G loss: 0.933692]\n",
      "epoch:28 step:26350 [D loss: 0.486797, acc.: 76.56%] [G loss: 1.239182]\n",
      "epoch:28 step:26351 [D loss: 0.390216, acc.: 82.81%] [G loss: 1.172964]\n",
      "epoch:28 step:26352 [D loss: 0.619744, acc.: 70.31%] [G loss: 1.239038]\n",
      "epoch:28 step:26353 [D loss: 0.691169, acc.: 60.94%] [G loss: 1.321408]\n",
      "epoch:28 step:26354 [D loss: 0.416165, acc.: 85.16%] [G loss: 1.514004]\n",
      "epoch:28 step:26355 [D loss: 0.321661, acc.: 85.16%] [G loss: 1.753910]\n",
      "epoch:28 step:26356 [D loss: 0.443606, acc.: 78.12%] [G loss: 1.483620]\n",
      "epoch:28 step:26357 [D loss: 0.265121, acc.: 94.53%] [G loss: 1.332549]\n",
      "epoch:28 step:26358 [D loss: 0.232685, acc.: 97.66%] [G loss: 1.402513]\n",
      "epoch:28 step:26359 [D loss: 0.717573, acc.: 57.03%] [G loss: 1.493831]\n",
      "epoch:28 step:26360 [D loss: 0.630158, acc.: 65.62%] [G loss: 1.255624]\n",
      "epoch:28 step:26361 [D loss: 0.610019, acc.: 62.50%] [G loss: 1.422049]\n",
      "epoch:28 step:26362 [D loss: 0.937605, acc.: 42.97%] [G loss: 1.530892]\n",
      "epoch:28 step:26363 [D loss: 0.625453, acc.: 69.53%] [G loss: 1.465836]\n",
      "epoch:28 step:26364 [D loss: 0.750866, acc.: 50.78%] [G loss: 1.271414]\n",
      "epoch:28 step:26365 [D loss: 0.596873, acc.: 67.19%] [G loss: 1.257442]\n",
      "epoch:28 step:26366 [D loss: 0.488164, acc.: 77.34%] [G loss: 1.215652]\n",
      "epoch:28 step:26367 [D loss: 0.444457, acc.: 85.94%] [G loss: 1.370504]\n",
      "epoch:28 step:26368 [D loss: 0.556629, acc.: 73.44%] [G loss: 0.727622]\n",
      "epoch:28 step:26369 [D loss: 0.553308, acc.: 67.97%] [G loss: 1.178406]\n",
      "epoch:28 step:26370 [D loss: 0.344016, acc.: 85.94%] [G loss: 0.608348]\n",
      "epoch:28 step:26371 [D loss: 0.312973, acc.: 91.41%] [G loss: 1.509541]\n",
      "epoch:28 step:26372 [D loss: 0.661506, acc.: 59.38%] [G loss: 1.389532]\n",
      "epoch:28 step:26373 [D loss: 0.687532, acc.: 54.69%] [G loss: 1.458704]\n",
      "epoch:28 step:26374 [D loss: 0.701667, acc.: 57.81%] [G loss: 1.591787]\n",
      "epoch:28 step:26375 [D loss: 0.678640, acc.: 60.94%] [G loss: 1.667401]\n",
      "epoch:28 step:26376 [D loss: 0.317088, acc.: 86.72%] [G loss: 1.364820]\n",
      "epoch:28 step:26377 [D loss: 0.233707, acc.: 92.97%] [G loss: 1.510501]\n",
      "epoch:28 step:26378 [D loss: 0.293884, acc.: 91.41%] [G loss: 1.658216]\n",
      "epoch:28 step:26379 [D loss: 0.217119, acc.: 94.53%] [G loss: 1.836432]\n",
      "epoch:28 step:26380 [D loss: 0.172008, acc.: 95.31%] [G loss: 1.836600]\n",
      "epoch:28 step:26381 [D loss: 0.168379, acc.: 98.44%] [G loss: 2.102267]\n",
      "epoch:28 step:26382 [D loss: 0.224766, acc.: 97.66%] [G loss: 2.046890]\n",
      "epoch:28 step:26383 [D loss: 0.473897, acc.: 75.78%] [G loss: 1.816105]\n",
      "epoch:28 step:26384 [D loss: 0.529012, acc.: 73.44%] [G loss: 1.511136]\n",
      "epoch:28 step:26385 [D loss: 0.278233, acc.: 93.75%] [G loss: 1.760207]\n",
      "epoch:28 step:26386 [D loss: 0.148788, acc.: 97.66%] [G loss: 1.797198]\n",
      "epoch:28 step:26387 [D loss: 0.120773, acc.: 100.00%] [G loss: 1.819118]\n",
      "epoch:28 step:26388 [D loss: 0.217291, acc.: 96.88%] [G loss: 1.512994]\n",
      "epoch:28 step:26389 [D loss: 0.563741, acc.: 75.00%] [G loss: 1.464586]\n",
      "epoch:28 step:26390 [D loss: 0.404899, acc.: 82.03%] [G loss: 2.004736]\n",
      "epoch:28 step:26391 [D loss: 0.533651, acc.: 75.78%] [G loss: 1.128162]\n",
      "epoch:28 step:26392 [D loss: 0.788104, acc.: 59.38%] [G loss: 1.519883]\n",
      "epoch:28 step:26393 [D loss: 0.579021, acc.: 74.22%] [G loss: 0.686080]\n",
      "epoch:28 step:26394 [D loss: 0.583005, acc.: 73.44%] [G loss: 0.837493]\n",
      "epoch:28 step:26395 [D loss: 1.159711, acc.: 25.78%] [G loss: 0.888826]\n",
      "epoch:28 step:26396 [D loss: 0.481489, acc.: 78.91%] [G loss: 1.298460]\n",
      "epoch:28 step:26397 [D loss: 0.442567, acc.: 78.91%] [G loss: 0.904332]\n",
      "epoch:28 step:26398 [D loss: 0.212905, acc.: 96.88%] [G loss: 1.565293]\n",
      "epoch:28 step:26399 [D loss: 0.405142, acc.: 83.59%] [G loss: 1.903698]\n",
      "epoch:28 step:26400 [D loss: 0.558366, acc.: 71.88%] [G loss: 1.467063]\n",
      "##############\n",
      "[4.08588825 2.96244183 6.80927774 5.59621215 4.78325646 6.03106634\n",
      " 5.44560058 5.40775848 6.2108484  5.12842013]\n",
      "##########\n",
      "epoch:28 step:26401 [D loss: 0.329361, acc.: 91.41%] [G loss: 1.053346]\n",
      "epoch:28 step:26402 [D loss: 0.894845, acc.: 45.31%] [G loss: 0.808020]\n",
      "epoch:28 step:26403 [D loss: 0.993112, acc.: 34.38%] [G loss: 0.887712]\n",
      "epoch:28 step:26404 [D loss: 0.921624, acc.: 44.53%] [G loss: 1.051152]\n",
      "epoch:28 step:26405 [D loss: 0.880474, acc.: 46.09%] [G loss: 0.839919]\n",
      "epoch:28 step:26406 [D loss: 0.564901, acc.: 67.19%] [G loss: 0.829650]\n",
      "epoch:28 step:26407 [D loss: 0.698627, acc.: 53.12%] [G loss: 0.370350]\n",
      "epoch:28 step:26408 [D loss: 1.222167, acc.: 33.59%] [G loss: 1.014772]\n",
      "epoch:28 step:26409 [D loss: 0.751227, acc.: 52.34%] [G loss: 0.645332]\n",
      "epoch:28 step:26410 [D loss: 0.704707, acc.: 60.16%] [G loss: 1.134181]\n",
      "epoch:28 step:26411 [D loss: 0.789786, acc.: 37.50%] [G loss: 1.027147]\n",
      "epoch:28 step:26412 [D loss: 0.749163, acc.: 44.53%] [G loss: 1.154273]\n",
      "epoch:28 step:26413 [D loss: 0.672400, acc.: 51.56%] [G loss: 0.853555]\n",
      "epoch:28 step:26414 [D loss: 0.512017, acc.: 75.78%] [G loss: 1.230920]\n",
      "epoch:28 step:26415 [D loss: 0.467072, acc.: 78.12%] [G loss: 0.866459]\n",
      "epoch:28 step:26416 [D loss: 0.731067, acc.: 54.69%] [G loss: 0.825167]\n",
      "epoch:28 step:26417 [D loss: 0.902691, acc.: 33.59%] [G loss: 1.045605]\n",
      "epoch:28 step:26418 [D loss: 0.975079, acc.: 28.12%] [G loss: 0.672928]\n",
      "epoch:28 step:26419 [D loss: 0.754949, acc.: 50.78%] [G loss: 0.863942]\n",
      "epoch:28 step:26420 [D loss: 0.682095, acc.: 60.94%] [G loss: 0.881796]\n",
      "epoch:28 step:26421 [D loss: 0.534415, acc.: 71.88%] [G loss: 0.955564]\n",
      "epoch:28 step:26422 [D loss: 0.668308, acc.: 61.72%] [G loss: 1.251114]\n",
      "epoch:28 step:26423 [D loss: 0.714636, acc.: 57.81%] [G loss: 1.099495]\n",
      "epoch:28 step:26424 [D loss: 0.725847, acc.: 57.81%] [G loss: 0.932198]\n",
      "epoch:28 step:26425 [D loss: 0.720817, acc.: 50.78%] [G loss: 0.981855]\n",
      "epoch:28 step:26426 [D loss: 0.817443, acc.: 39.84%] [G loss: 1.202348]\n",
      "epoch:28 step:26427 [D loss: 0.611431, acc.: 63.28%] [G loss: 0.780051]\n",
      "epoch:28 step:26428 [D loss: 0.837044, acc.: 49.22%] [G loss: 1.215139]\n",
      "epoch:28 step:26429 [D loss: 0.550505, acc.: 70.31%] [G loss: 1.381417]\n",
      "epoch:28 step:26430 [D loss: 0.510409, acc.: 78.12%] [G loss: 1.276205]\n",
      "epoch:28 step:26431 [D loss: 0.482065, acc.: 80.47%] [G loss: 1.339536]\n",
      "epoch:28 step:26432 [D loss: 0.544039, acc.: 71.09%] [G loss: 1.603006]\n",
      "epoch:28 step:26433 [D loss: 0.432901, acc.: 81.25%] [G loss: 1.668687]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26434 [D loss: 0.406172, acc.: 82.81%] [G loss: 1.530282]\n",
      "epoch:28 step:26435 [D loss: 0.655072, acc.: 57.81%] [G loss: 1.270952]\n",
      "epoch:28 step:26436 [D loss: 0.564900, acc.: 73.44%] [G loss: 1.388162]\n",
      "epoch:28 step:26437 [D loss: 0.422813, acc.: 90.62%] [G loss: 1.234454]\n",
      "epoch:28 step:26438 [D loss: 0.812375, acc.: 45.31%] [G loss: 1.329018]\n",
      "epoch:28 step:26439 [D loss: 0.278887, acc.: 94.53%] [G loss: 1.444309]\n",
      "epoch:28 step:26440 [D loss: 0.217258, acc.: 92.97%] [G loss: 1.500490]\n",
      "epoch:28 step:26441 [D loss: 0.262635, acc.: 96.88%] [G loss: 1.837012]\n",
      "epoch:28 step:26442 [D loss: 0.162685, acc.: 100.00%] [G loss: 1.608387]\n",
      "epoch:28 step:26443 [D loss: 0.152301, acc.: 96.88%] [G loss: 1.783886]\n",
      "epoch:28 step:26444 [D loss: 0.124053, acc.: 99.22%] [G loss: 2.152996]\n",
      "epoch:28 step:26445 [D loss: 0.108006, acc.: 100.00%] [G loss: 1.697832]\n",
      "epoch:28 step:26446 [D loss: 0.664658, acc.: 60.94%] [G loss: 1.985097]\n",
      "epoch:28 step:26447 [D loss: 0.789402, acc.: 53.12%] [G loss: 1.593816]\n",
      "epoch:28 step:26448 [D loss: 0.576109, acc.: 72.66%] [G loss: 1.338059]\n",
      "epoch:28 step:26449 [D loss: 0.666567, acc.: 59.38%] [G loss: 1.460123]\n",
      "epoch:28 step:26450 [D loss: 0.488760, acc.: 77.34%] [G loss: 1.271562]\n",
      "epoch:28 step:26451 [D loss: 0.742254, acc.: 44.53%] [G loss: 0.885474]\n",
      "epoch:28 step:26452 [D loss: 0.468637, acc.: 82.81%] [G loss: 1.199135]\n",
      "epoch:28 step:26453 [D loss: 0.395176, acc.: 78.91%] [G loss: 1.284700]\n",
      "epoch:28 step:26454 [D loss: 0.229947, acc.: 89.84%] [G loss: 1.386344]\n",
      "epoch:28 step:26455 [D loss: 0.152018, acc.: 99.22%] [G loss: 1.419071]\n",
      "epoch:28 step:26456 [D loss: 0.485866, acc.: 78.12%] [G loss: 1.347475]\n",
      "epoch:28 step:26457 [D loss: 0.457548, acc.: 81.25%] [G loss: 1.564056]\n",
      "epoch:28 step:26458 [D loss: 0.561917, acc.: 79.69%] [G loss: 1.132150]\n",
      "epoch:28 step:26459 [D loss: 0.492105, acc.: 80.47%] [G loss: 0.962163]\n",
      "epoch:28 step:26460 [D loss: 0.403200, acc.: 90.62%] [G loss: 1.313752]\n",
      "epoch:28 step:26461 [D loss: 0.227390, acc.: 97.66%] [G loss: 1.008315]\n",
      "epoch:28 step:26462 [D loss: 0.761501, acc.: 52.34%] [G loss: 1.459028]\n",
      "epoch:28 step:26463 [D loss: 0.756018, acc.: 54.69%] [G loss: 1.049768]\n",
      "epoch:28 step:26464 [D loss: 0.677161, acc.: 57.81%] [G loss: 1.149699]\n",
      "epoch:28 step:26465 [D loss: 0.561832, acc.: 71.09%] [G loss: 1.027487]\n",
      "epoch:28 step:26466 [D loss: 0.287196, acc.: 89.06%] [G loss: 0.839931]\n",
      "epoch:28 step:26467 [D loss: 0.300259, acc.: 88.28%] [G loss: 1.167228]\n",
      "epoch:28 step:26468 [D loss: 0.345271, acc.: 89.84%] [G loss: 1.370219]\n",
      "epoch:28 step:26469 [D loss: 0.720302, acc.: 56.25%] [G loss: 1.146523]\n",
      "epoch:28 step:26470 [D loss: 0.822904, acc.: 48.44%] [G loss: 1.216409]\n",
      "epoch:28 step:26471 [D loss: 0.691432, acc.: 64.84%] [G loss: 1.154617]\n",
      "epoch:28 step:26472 [D loss: 0.708183, acc.: 50.00%] [G loss: 1.155558]\n",
      "epoch:28 step:26473 [D loss: 0.599473, acc.: 69.53%] [G loss: 1.174420]\n",
      "epoch:28 step:26474 [D loss: 0.620042, acc.: 65.62%] [G loss: 1.018092]\n",
      "epoch:28 step:26475 [D loss: 0.580735, acc.: 73.44%] [G loss: 0.729782]\n",
      "epoch:28 step:26476 [D loss: 0.518725, acc.: 76.56%] [G loss: 0.801753]\n",
      "epoch:28 step:26477 [D loss: 0.361725, acc.: 82.03%] [G loss: 1.051115]\n",
      "epoch:28 step:26478 [D loss: 0.624225, acc.: 66.41%] [G loss: 0.935554]\n",
      "epoch:28 step:26479 [D loss: 0.682661, acc.: 60.16%] [G loss: 0.992442]\n",
      "epoch:28 step:26480 [D loss: 0.697718, acc.: 53.12%] [G loss: 0.920740]\n",
      "epoch:28 step:26481 [D loss: 0.397622, acc.: 89.84%] [G loss: 1.217603]\n",
      "epoch:28 step:26482 [D loss: 0.278937, acc.: 89.06%] [G loss: 1.243979]\n",
      "epoch:28 step:26483 [D loss: 0.226361, acc.: 96.88%] [G loss: 1.364626]\n",
      "epoch:28 step:26484 [D loss: 0.205769, acc.: 96.88%] [G loss: 1.364202]\n",
      "epoch:28 step:26485 [D loss: 0.753505, acc.: 56.25%] [G loss: 1.203463]\n",
      "epoch:28 step:26486 [D loss: 0.510910, acc.: 75.00%] [G loss: 1.350716]\n",
      "epoch:28 step:26487 [D loss: 0.736163, acc.: 59.38%] [G loss: 1.244764]\n",
      "epoch:28 step:26488 [D loss: 0.774835, acc.: 50.00%] [G loss: 1.071997]\n",
      "epoch:28 step:26489 [D loss: 1.051507, acc.: 27.34%] [G loss: 1.128049]\n",
      "epoch:28 step:26490 [D loss: 0.743518, acc.: 56.25%] [G loss: 1.286545]\n",
      "epoch:28 step:26491 [D loss: 0.607597, acc.: 67.97%] [G loss: 1.004890]\n",
      "epoch:28 step:26492 [D loss: 0.368180, acc.: 84.38%] [G loss: 1.101136]\n",
      "epoch:28 step:26493 [D loss: 0.953876, acc.: 43.75%] [G loss: 1.420319]\n",
      "epoch:28 step:26494 [D loss: 0.685282, acc.: 57.81%] [G loss: 1.708626]\n",
      "epoch:28 step:26495 [D loss: 0.303070, acc.: 93.75%] [G loss: 1.208185]\n",
      "epoch:28 step:26496 [D loss: 0.298115, acc.: 92.97%] [G loss: 1.251426]\n",
      "epoch:28 step:26497 [D loss: 0.226285, acc.: 96.09%] [G loss: 1.632420]\n",
      "epoch:28 step:26498 [D loss: 0.746347, acc.: 52.34%] [G loss: 1.383980]\n",
      "epoch:28 step:26499 [D loss: 0.185638, acc.: 96.88%] [G loss: 1.684342]\n",
      "epoch:28 step:26500 [D loss: 0.287020, acc.: 94.53%] [G loss: 1.136562]\n",
      "epoch:28 step:26501 [D loss: 0.567987, acc.: 71.88%] [G loss: 1.440617]\n",
      "epoch:28 step:26502 [D loss: 0.628202, acc.: 64.84%] [G loss: 1.300182]\n",
      "epoch:28 step:26503 [D loss: 0.832301, acc.: 36.72%] [G loss: 1.347239]\n",
      "epoch:28 step:26504 [D loss: 0.773666, acc.: 50.00%] [G loss: 1.274661]\n",
      "epoch:28 step:26505 [D loss: 0.345551, acc.: 89.84%] [G loss: 1.289300]\n",
      "epoch:28 step:26506 [D loss: 0.553188, acc.: 71.09%] [G loss: 1.373236]\n",
      "epoch:28 step:26507 [D loss: 0.335486, acc.: 92.19%] [G loss: 1.295937]\n",
      "epoch:28 step:26508 [D loss: 0.366741, acc.: 89.84%] [G loss: 1.241256]\n",
      "epoch:28 step:26509 [D loss: 0.560157, acc.: 76.56%] [G loss: 1.303677]\n",
      "epoch:28 step:26510 [D loss: 0.278901, acc.: 93.75%] [G loss: 1.386696]\n",
      "epoch:28 step:26511 [D loss: 0.440164, acc.: 85.94%] [G loss: 1.252187]\n",
      "epoch:28 step:26512 [D loss: 0.387348, acc.: 90.62%] [G loss: 1.508404]\n",
      "epoch:28 step:26513 [D loss: 0.668359, acc.: 58.59%] [G loss: 1.229329]\n",
      "epoch:28 step:26514 [D loss: 0.300181, acc.: 91.41%] [G loss: 1.427627]\n",
      "epoch:28 step:26515 [D loss: 0.170281, acc.: 97.66%] [G loss: 1.219397]\n",
      "epoch:28 step:26516 [D loss: 0.782697, acc.: 47.66%] [G loss: 1.043630]\n",
      "epoch:28 step:26517 [D loss: 0.773000, acc.: 47.66%] [G loss: 0.890125]\n",
      "epoch:28 step:26518 [D loss: 0.469367, acc.: 83.59%] [G loss: 1.517949]\n",
      "epoch:28 step:26519 [D loss: 0.994614, acc.: 24.22%] [G loss: 1.021779]\n",
      "epoch:28 step:26520 [D loss: 0.378945, acc.: 89.84%] [G loss: 1.487396]\n",
      "epoch:28 step:26521 [D loss: 0.465485, acc.: 82.81%] [G loss: 1.286282]\n",
      "epoch:28 step:26522 [D loss: 0.454794, acc.: 77.34%] [G loss: 1.232358]\n",
      "epoch:28 step:26523 [D loss: 0.337919, acc.: 90.62%] [G loss: 1.618984]\n",
      "epoch:28 step:26524 [D loss: 0.268858, acc.: 91.41%] [G loss: 1.475312]\n",
      "epoch:28 step:26525 [D loss: 0.144763, acc.: 99.22%] [G loss: 1.391624]\n",
      "epoch:28 step:26526 [D loss: 0.446379, acc.: 78.91%] [G loss: 1.498244]\n",
      "epoch:28 step:26527 [D loss: 0.259054, acc.: 93.75%] [G loss: 1.552959]\n",
      "epoch:28 step:26528 [D loss: 0.231162, acc.: 92.97%] [G loss: 1.694041]\n",
      "epoch:28 step:26529 [D loss: 0.174798, acc.: 98.44%] [G loss: 1.435389]\n",
      "epoch:28 step:26530 [D loss: 0.392467, acc.: 89.06%] [G loss: 1.954469]\n",
      "epoch:28 step:26531 [D loss: 0.936010, acc.: 39.06%] [G loss: 1.500090]\n",
      "epoch:28 step:26532 [D loss: 0.765124, acc.: 51.56%] [G loss: 1.457759]\n",
      "epoch:28 step:26533 [D loss: 0.640595, acc.: 64.84%] [G loss: 1.195992]\n",
      "epoch:28 step:26534 [D loss: 0.551314, acc.: 74.22%] [G loss: 1.219474]\n",
      "epoch:28 step:26535 [D loss: 0.379971, acc.: 89.06%] [G loss: 1.372601]\n",
      "epoch:28 step:26536 [D loss: 0.736691, acc.: 49.22%] [G loss: 1.594282]\n",
      "epoch:28 step:26537 [D loss: 0.805315, acc.: 54.69%] [G loss: 1.219605]\n",
      "epoch:28 step:26538 [D loss: 0.719491, acc.: 55.47%] [G loss: 0.910188]\n",
      "epoch:28 step:26539 [D loss: 0.773013, acc.: 51.56%] [G loss: 0.881227]\n",
      "epoch:28 step:26540 [D loss: 0.477637, acc.: 76.56%] [G loss: 1.010241]\n",
      "epoch:28 step:26541 [D loss: 0.316108, acc.: 82.03%] [G loss: 1.392318]\n",
      "epoch:28 step:26542 [D loss: 0.410021, acc.: 85.94%] [G loss: 1.406430]\n",
      "epoch:28 step:26543 [D loss: 0.583431, acc.: 70.31%] [G loss: 1.038949]\n",
      "epoch:28 step:26544 [D loss: 0.239730, acc.: 89.84%] [G loss: 1.044170]\n",
      "epoch:28 step:26545 [D loss: 0.197109, acc.: 98.44%] [G loss: 1.283727]\n",
      "epoch:28 step:26546 [D loss: 0.372479, acc.: 87.50%] [G loss: 1.409432]\n",
      "epoch:28 step:26547 [D loss: 0.182634, acc.: 99.22%] [G loss: 1.170270]\n",
      "epoch:28 step:26548 [D loss: 0.408224, acc.: 75.00%] [G loss: 1.783058]\n",
      "epoch:28 step:26549 [D loss: 0.095215, acc.: 99.22%] [G loss: 1.993737]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26550 [D loss: 0.172711, acc.: 96.09%] [G loss: 1.953852]\n",
      "epoch:28 step:26551 [D loss: 0.202843, acc.: 96.88%] [G loss: 1.993562]\n",
      "epoch:28 step:26552 [D loss: 0.950802, acc.: 47.66%] [G loss: 1.777153]\n",
      "epoch:28 step:26553 [D loss: 0.920938, acc.: 48.44%] [G loss: 1.805275]\n",
      "epoch:28 step:26554 [D loss: 0.828488, acc.: 54.69%] [G loss: 1.214669]\n",
      "epoch:28 step:26555 [D loss: 0.752716, acc.: 50.00%] [G loss: 1.438778]\n",
      "epoch:28 step:26556 [D loss: 0.716165, acc.: 54.69%] [G loss: 1.427612]\n",
      "epoch:28 step:26557 [D loss: 0.806834, acc.: 48.44%] [G loss: 1.077657]\n",
      "epoch:28 step:26558 [D loss: 0.649285, acc.: 56.25%] [G loss: 1.272908]\n",
      "epoch:28 step:26559 [D loss: 0.453699, acc.: 79.69%] [G loss: 1.258832]\n",
      "epoch:28 step:26560 [D loss: 0.670664, acc.: 58.59%] [G loss: 1.296270]\n",
      "epoch:28 step:26561 [D loss: 0.514436, acc.: 77.34%] [G loss: 1.125215]\n",
      "epoch:28 step:26562 [D loss: 0.633051, acc.: 65.62%] [G loss: 1.305549]\n",
      "epoch:28 step:26563 [D loss: 0.344562, acc.: 93.75%] [G loss: 1.098513]\n",
      "epoch:28 step:26564 [D loss: 0.336680, acc.: 91.41%] [G loss: 1.310278]\n",
      "epoch:28 step:26565 [D loss: 0.692049, acc.: 60.16%] [G loss: 1.283381]\n",
      "epoch:28 step:26566 [D loss: 0.760563, acc.: 44.53%] [G loss: 1.085170]\n",
      "epoch:28 step:26567 [D loss: 0.488722, acc.: 79.69%] [G loss: 1.118925]\n",
      "epoch:28 step:26568 [D loss: 0.275202, acc.: 92.19%] [G loss: 1.132595]\n",
      "epoch:28 step:26569 [D loss: 0.271266, acc.: 98.44%] [G loss: 1.049848]\n",
      "epoch:28 step:26570 [D loss: 0.350404, acc.: 88.28%] [G loss: 1.246733]\n",
      "epoch:28 step:26571 [D loss: 0.416800, acc.: 86.72%] [G loss: 1.167367]\n",
      "epoch:28 step:26572 [D loss: 0.501662, acc.: 64.06%] [G loss: 1.212949]\n",
      "epoch:28 step:26573 [D loss: 0.540498, acc.: 72.66%] [G loss: 1.311101]\n",
      "epoch:28 step:26574 [D loss: 0.576630, acc.: 67.97%] [G loss: 1.071968]\n",
      "epoch:28 step:26575 [D loss: 0.601067, acc.: 64.06%] [G loss: 1.177471]\n",
      "epoch:28 step:26576 [D loss: 0.503440, acc.: 75.78%] [G loss: 1.166524]\n",
      "epoch:28 step:26577 [D loss: 0.414010, acc.: 84.38%] [G loss: 0.740093]\n",
      "epoch:28 step:26578 [D loss: 0.442800, acc.: 75.00%] [G loss: 1.625742]\n",
      "epoch:28 step:26579 [D loss: 0.193595, acc.: 94.53%] [G loss: 1.619262]\n",
      "epoch:28 step:26580 [D loss: 0.188376, acc.: 95.31%] [G loss: 1.639975]\n",
      "epoch:28 step:26581 [D loss: 0.110319, acc.: 98.44%] [G loss: 1.644513]\n",
      "epoch:28 step:26582 [D loss: 0.094463, acc.: 99.22%] [G loss: 2.052960]\n",
      "epoch:28 step:26583 [D loss: 0.088822, acc.: 100.00%] [G loss: 2.152716]\n",
      "epoch:28 step:26584 [D loss: 0.652569, acc.: 61.72%] [G loss: 1.632352]\n",
      "epoch:28 step:26585 [D loss: 0.785872, acc.: 54.69%] [G loss: 1.628014]\n",
      "epoch:28 step:26586 [D loss: 0.457325, acc.: 80.47%] [G loss: 1.196711]\n",
      "epoch:28 step:26587 [D loss: 0.634717, acc.: 60.16%] [G loss: 0.360134]\n",
      "epoch:28 step:26588 [D loss: 0.530027, acc.: 75.78%] [G loss: 0.301304]\n",
      "epoch:28 step:26589 [D loss: 0.333925, acc.: 91.41%] [G loss: 0.779493]\n",
      "epoch:28 step:26590 [D loss: 0.368955, acc.: 88.28%] [G loss: 1.467925]\n",
      "epoch:28 step:26591 [D loss: 0.712781, acc.: 60.94%] [G loss: 0.922763]\n",
      "epoch:28 step:26592 [D loss: 0.740360, acc.: 55.47%] [G loss: 1.032318]\n",
      "epoch:28 step:26593 [D loss: 0.679760, acc.: 60.16%] [G loss: 1.243910]\n",
      "epoch:28 step:26594 [D loss: 0.296483, acc.: 98.44%] [G loss: 1.319233]\n",
      "epoch:28 step:26595 [D loss: 0.695680, acc.: 67.19%] [G loss: 1.437424]\n",
      "epoch:28 step:26596 [D loss: 0.425253, acc.: 87.50%] [G loss: 1.460703]\n",
      "epoch:28 step:26597 [D loss: 0.556736, acc.: 67.19%] [G loss: 1.625670]\n",
      "epoch:28 step:26598 [D loss: 0.353616, acc.: 89.84%] [G loss: 1.549419]\n",
      "epoch:28 step:26599 [D loss: 0.477777, acc.: 77.34%] [G loss: 1.726086]\n",
      "epoch:28 step:26600 [D loss: 0.791139, acc.: 47.66%] [G loss: 1.480454]\n",
      "##############\n",
      "[3.98922346 2.87200931 6.44777486 5.5318784  4.4976763  6.09605614\n",
      " 5.25554157 5.5702018  5.81197621 4.69188105]\n",
      "##########\n",
      "epoch:28 step:26601 [D loss: 0.307403, acc.: 92.97%] [G loss: 1.308867]\n",
      "epoch:28 step:26602 [D loss: 0.190996, acc.: 96.09%] [G loss: 1.630970]\n",
      "epoch:28 step:26603 [D loss: 0.352503, acc.: 89.84%] [G loss: 1.676040]\n",
      "epoch:28 step:26604 [D loss: 0.906095, acc.: 50.00%] [G loss: 1.158452]\n",
      "epoch:28 step:26605 [D loss: 0.166276, acc.: 99.22%] [G loss: 1.558347]\n",
      "epoch:28 step:26606 [D loss: 1.022956, acc.: 53.12%] [G loss: 1.690157]\n",
      "epoch:28 step:26607 [D loss: 0.102744, acc.: 98.44%] [G loss: 2.223124]\n",
      "epoch:28 step:26608 [D loss: 0.224374, acc.: 95.31%] [G loss: 2.007025]\n",
      "epoch:28 step:26609 [D loss: 0.903308, acc.: 53.12%] [G loss: 1.705048]\n",
      "epoch:28 step:26610 [D loss: 0.665193, acc.: 60.94%] [G loss: 1.323767]\n",
      "epoch:28 step:26611 [D loss: 0.748446, acc.: 59.38%] [G loss: 1.113302]\n",
      "epoch:28 step:26612 [D loss: 0.763381, acc.: 55.47%] [G loss: 1.103323]\n",
      "epoch:28 step:26613 [D loss: 0.504479, acc.: 75.00%] [G loss: 0.882574]\n",
      "epoch:28 step:26614 [D loss: 0.486487, acc.: 78.12%] [G loss: 1.164959]\n",
      "epoch:28 step:26615 [D loss: 0.410331, acc.: 75.00%] [G loss: 1.466290]\n",
      "epoch:28 step:26616 [D loss: 0.176049, acc.: 96.88%] [G loss: 1.657491]\n",
      "epoch:28 step:26617 [D loss: 0.157720, acc.: 97.66%] [G loss: 1.584004]\n",
      "epoch:28 step:26618 [D loss: 0.507045, acc.: 78.12%] [G loss: 1.281477]\n",
      "epoch:28 step:26619 [D loss: 0.579214, acc.: 69.53%] [G loss: 1.283348]\n",
      "epoch:28 step:26620 [D loss: 0.708351, acc.: 58.59%] [G loss: 1.170836]\n",
      "epoch:28 step:26621 [D loss: 0.357602, acc.: 88.28%] [G loss: 1.328856]\n",
      "epoch:28 step:26622 [D loss: 0.401116, acc.: 81.25%] [G loss: 1.316764]\n",
      "epoch:28 step:26623 [D loss: 0.243341, acc.: 98.44%] [G loss: 0.986507]\n",
      "epoch:28 step:26624 [D loss: 0.405052, acc.: 86.72%] [G loss: 1.610862]\n",
      "epoch:28 step:26625 [D loss: 0.753874, acc.: 51.56%] [G loss: 0.945760]\n",
      "epoch:28 step:26626 [D loss: 1.316655, acc.: 11.72%] [G loss: 1.422234]\n",
      "epoch:28 step:26627 [D loss: 0.756876, acc.: 46.09%] [G loss: 1.147224]\n",
      "epoch:28 step:26628 [D loss: 1.065268, acc.: 20.31%] [G loss: 1.053976]\n",
      "epoch:28 step:26629 [D loss: 1.257836, acc.: 16.41%] [G loss: 0.870287]\n",
      "epoch:28 step:26630 [D loss: 0.942390, acc.: 32.81%] [G loss: 1.274009]\n",
      "epoch:28 step:26631 [D loss: 0.466850, acc.: 81.25%] [G loss: 0.667859]\n",
      "epoch:28 step:26632 [D loss: 0.837763, acc.: 42.97%] [G loss: 0.508367]\n",
      "epoch:28 step:26633 [D loss: 0.233705, acc.: 95.31%] [G loss: 1.468236]\n",
      "epoch:28 step:26634 [D loss: 0.163168, acc.: 100.00%] [G loss: 1.440068]\n",
      "epoch:28 step:26635 [D loss: 0.930188, acc.: 46.88%] [G loss: 1.679704]\n",
      "epoch:28 step:26636 [D loss: 0.412162, acc.: 87.50%] [G loss: 1.796679]\n",
      "epoch:28 step:26637 [D loss: 0.330056, acc.: 90.62%] [G loss: 1.964196]\n",
      "epoch:28 step:26638 [D loss: 0.247145, acc.: 98.44%] [G loss: 1.000925]\n",
      "epoch:28 step:26639 [D loss: 0.465257, acc.: 83.59%] [G loss: 1.583551]\n",
      "epoch:28 step:26640 [D loss: 0.201818, acc.: 98.44%] [G loss: 1.472212]\n",
      "epoch:28 step:26641 [D loss: 0.263259, acc.: 89.06%] [G loss: 1.854311]\n",
      "epoch:28 step:26642 [D loss: 0.116900, acc.: 100.00%] [G loss: 1.881066]\n",
      "epoch:28 step:26643 [D loss: 0.121521, acc.: 100.00%] [G loss: 1.998527]\n",
      "epoch:28 step:26644 [D loss: 0.150937, acc.: 100.00%] [G loss: 1.894760]\n",
      "epoch:28 step:26645 [D loss: 0.128337, acc.: 100.00%] [G loss: 1.622853]\n",
      "epoch:28 step:26646 [D loss: 0.392657, acc.: 92.19%] [G loss: 1.770074]\n",
      "epoch:28 step:26647 [D loss: 0.673211, acc.: 56.25%] [G loss: 1.777624]\n",
      "epoch:28 step:26648 [D loss: 0.149711, acc.: 98.44%] [G loss: 1.596854]\n",
      "epoch:28 step:26649 [D loss: 0.156450, acc.: 100.00%] [G loss: 1.732909]\n",
      "epoch:28 step:26650 [D loss: 0.117020, acc.: 99.22%] [G loss: 1.856127]\n",
      "epoch:28 step:26651 [D loss: 0.284398, acc.: 88.28%] [G loss: 1.720955]\n",
      "epoch:28 step:26652 [D loss: 0.112685, acc.: 100.00%] [G loss: 2.410578]\n",
      "epoch:28 step:26653 [D loss: 0.095699, acc.: 100.00%] [G loss: 1.993786]\n",
      "epoch:28 step:26654 [D loss: 0.087003, acc.: 100.00%] [G loss: 2.038749]\n",
      "epoch:28 step:26655 [D loss: 0.072274, acc.: 100.00%] [G loss: 2.212381]\n",
      "epoch:28 step:26656 [D loss: 0.106181, acc.: 100.00%] [G loss: 1.936069]\n",
      "epoch:28 step:26657 [D loss: 0.427890, acc.: 79.69%] [G loss: 1.874452]\n",
      "epoch:28 step:26658 [D loss: 0.431879, acc.: 78.91%] [G loss: 1.976422]\n",
      "epoch:28 step:26659 [D loss: 0.489116, acc.: 69.53%] [G loss: 1.650135]\n",
      "epoch:28 step:26660 [D loss: 0.145961, acc.: 99.22%] [G loss: 2.107991]\n",
      "epoch:28 step:26661 [D loss: 0.085363, acc.: 100.00%] [G loss: 1.203182]\n",
      "epoch:28 step:26662 [D loss: 0.415065, acc.: 78.91%] [G loss: 1.676548]\n",
      "epoch:28 step:26663 [D loss: 0.084092, acc.: 100.00%] [G loss: 1.345314]\n",
      "epoch:28 step:26664 [D loss: 0.716744, acc.: 57.81%] [G loss: 1.955925]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26665 [D loss: 0.055782, acc.: 100.00%] [G loss: 2.569301]\n",
      "epoch:28 step:26666 [D loss: 0.067910, acc.: 100.00%] [G loss: 2.840380]\n",
      "epoch:28 step:26667 [D loss: 0.403879, acc.: 81.25%] [G loss: 2.572094]\n",
      "epoch:28 step:26668 [D loss: 1.070864, acc.: 50.78%] [G loss: 1.312841]\n",
      "epoch:28 step:26669 [D loss: 0.460433, acc.: 81.25%] [G loss: 1.801605]\n",
      "epoch:28 step:26670 [D loss: 0.433343, acc.: 79.69%] [G loss: 0.052715]\n",
      "epoch:28 step:26671 [D loss: 0.557563, acc.: 71.09%] [G loss: 1.272698]\n",
      "epoch:28 step:26672 [D loss: 1.638111, acc.: 51.56%] [G loss: 1.227227]\n",
      "epoch:28 step:26673 [D loss: 0.469264, acc.: 77.34%] [G loss: 1.752892]\n",
      "epoch:28 step:26674 [D loss: 0.196700, acc.: 94.53%] [G loss: 1.986490]\n",
      "epoch:28 step:26675 [D loss: 0.856770, acc.: 49.22%] [G loss: 1.221982]\n",
      "epoch:28 step:26676 [D loss: 0.589154, acc.: 60.94%] [G loss: 0.585364]\n",
      "epoch:28 step:26677 [D loss: 1.546300, acc.: 10.94%] [G loss: 1.747494]\n",
      "epoch:28 step:26678 [D loss: 0.661243, acc.: 53.91%] [G loss: 2.271228]\n",
      "epoch:28 step:26679 [D loss: 1.343476, acc.: 30.47%] [G loss: 1.801006]\n",
      "epoch:28 step:26680 [D loss: 1.157136, acc.: 27.34%] [G loss: 1.107678]\n",
      "epoch:28 step:26681 [D loss: 0.570808, acc.: 74.22%] [G loss: 1.439403]\n",
      "epoch:28 step:26682 [D loss: 1.022608, acc.: 42.19%] [G loss: 1.794944]\n",
      "epoch:28 step:26683 [D loss: 0.846499, acc.: 39.84%] [G loss: 0.165194]\n",
      "epoch:28 step:26684 [D loss: 0.979270, acc.: 52.34%] [G loss: 2.016692]\n",
      "epoch:28 step:26685 [D loss: 0.757001, acc.: 53.91%] [G loss: 1.121642]\n",
      "epoch:28 step:26686 [D loss: 0.842803, acc.: 54.69%] [G loss: 1.702110]\n",
      "epoch:28 step:26687 [D loss: 0.373503, acc.: 91.41%] [G loss: 1.627550]\n",
      "epoch:28 step:26688 [D loss: 0.688256, acc.: 63.28%] [G loss: 1.874769]\n",
      "epoch:28 step:26689 [D loss: 0.287785, acc.: 92.19%] [G loss: 2.162129]\n",
      "epoch:28 step:26690 [D loss: 0.334350, acc.: 89.06%] [G loss: 2.571043]\n",
      "epoch:28 step:26691 [D loss: 0.447026, acc.: 75.00%] [G loss: 2.057319]\n",
      "epoch:28 step:26692 [D loss: 0.115679, acc.: 98.44%] [G loss: 2.452438]\n",
      "epoch:28 step:26693 [D loss: 0.165301, acc.: 99.22%] [G loss: 2.361548]\n",
      "epoch:28 step:26694 [D loss: 0.637307, acc.: 57.81%] [G loss: 2.124730]\n",
      "epoch:28 step:26695 [D loss: 0.643097, acc.: 61.72%] [G loss: 2.058935]\n",
      "epoch:28 step:26696 [D loss: 0.639027, acc.: 56.25%] [G loss: 1.772443]\n",
      "epoch:28 step:26697 [D loss: 0.717933, acc.: 55.47%] [G loss: 1.593776]\n",
      "epoch:28 step:26698 [D loss: 0.747986, acc.: 50.78%] [G loss: 1.351883]\n",
      "epoch:28 step:26699 [D loss: 0.614721, acc.: 66.41%] [G loss: 1.303336]\n",
      "epoch:28 step:26700 [D loss: 0.437436, acc.: 76.56%] [G loss: 1.327045]\n",
      "epoch:28 step:26701 [D loss: 0.224424, acc.: 92.19%] [G loss: 1.595418]\n",
      "epoch:28 step:26702 [D loss: 0.153915, acc.: 97.66%] [G loss: 1.958971]\n",
      "epoch:28 step:26703 [D loss: 0.168142, acc.: 97.66%] [G loss: 1.916224]\n",
      "epoch:28 step:26704 [D loss: 0.104295, acc.: 100.00%] [G loss: 2.106574]\n",
      "epoch:28 step:26705 [D loss: 0.075387, acc.: 100.00%] [G loss: 2.440261]\n",
      "epoch:28 step:26706 [D loss: 0.107005, acc.: 98.44%] [G loss: 1.939141]\n",
      "epoch:28 step:26707 [D loss: 0.079005, acc.: 100.00%] [G loss: 2.821898]\n",
      "epoch:28 step:26708 [D loss: 0.069723, acc.: 100.00%] [G loss: 2.385736]\n",
      "epoch:28 step:26709 [D loss: 1.012198, acc.: 54.69%] [G loss: 1.770839]\n",
      "epoch:28 step:26710 [D loss: 0.943555, acc.: 45.31%] [G loss: 1.416398]\n",
      "epoch:28 step:26711 [D loss: 0.724670, acc.: 53.12%] [G loss: 1.144737]\n",
      "epoch:28 step:26712 [D loss: 0.364958, acc.: 84.38%] [G loss: 1.183184]\n",
      "epoch:28 step:26713 [D loss: 0.284979, acc.: 95.31%] [G loss: 1.410307]\n",
      "epoch:28 step:26714 [D loss: 0.259815, acc.: 99.22%] [G loss: 1.588429]\n",
      "epoch:28 step:26715 [D loss: 0.199415, acc.: 96.09%] [G loss: 1.581278]\n",
      "epoch:28 step:26716 [D loss: 0.127094, acc.: 99.22%] [G loss: 1.937861]\n",
      "epoch:28 step:26717 [D loss: 0.162135, acc.: 99.22%] [G loss: 1.660064]\n",
      "epoch:28 step:26718 [D loss: 1.165307, acc.: 50.00%] [G loss: 1.771250]\n",
      "epoch:28 step:26719 [D loss: 1.054183, acc.: 36.72%] [G loss: 1.786252]\n",
      "epoch:28 step:26720 [D loss: 1.050091, acc.: 28.91%] [G loss: 0.708373]\n",
      "epoch:28 step:26721 [D loss: 0.821766, acc.: 46.09%] [G loss: 0.589531]\n",
      "epoch:28 step:26722 [D loss: 0.837497, acc.: 36.72%] [G loss: 0.777447]\n",
      "epoch:28 step:26723 [D loss: 0.738065, acc.: 51.56%] [G loss: 0.649834]\n",
      "epoch:28 step:26724 [D loss: 0.848965, acc.: 34.38%] [G loss: 0.547731]\n",
      "epoch:28 step:26725 [D loss: 0.301392, acc.: 87.50%] [G loss: 1.089647]\n",
      "epoch:28 step:26726 [D loss: 0.239775, acc.: 92.19%] [G loss: 1.237920]\n",
      "epoch:28 step:26727 [D loss: 0.253513, acc.: 95.31%] [G loss: 0.901810]\n",
      "epoch:28 step:26728 [D loss: 0.533429, acc.: 77.34%] [G loss: 1.732395]\n",
      "epoch:28 step:26729 [D loss: 0.800950, acc.: 46.88%] [G loss: 0.467233]\n",
      "epoch:28 step:26730 [D loss: 0.306651, acc.: 95.31%] [G loss: 0.169321]\n",
      "epoch:28 step:26731 [D loss: 0.750733, acc.: 54.69%] [G loss: 0.943569]\n",
      "epoch:28 step:26732 [D loss: 0.902142, acc.: 28.91%] [G loss: 1.333158]\n",
      "epoch:28 step:26733 [D loss: 0.862221, acc.: 43.75%] [G loss: 1.503623]\n",
      "epoch:28 step:26734 [D loss: 0.640428, acc.: 62.50%] [G loss: 1.280020]\n",
      "epoch:28 step:26735 [D loss: 0.455442, acc.: 88.28%] [G loss: 1.211213]\n",
      "epoch:28 step:26736 [D loss: 0.722734, acc.: 57.81%] [G loss: 1.242070]\n",
      "epoch:28 step:26737 [D loss: 0.672312, acc.: 61.72%] [G loss: 1.153821]\n",
      "epoch:28 step:26738 [D loss: 0.539898, acc.: 73.44%] [G loss: 0.973620]\n",
      "epoch:28 step:26739 [D loss: 0.189461, acc.: 97.66%] [G loss: 0.916292]\n",
      "epoch:28 step:26740 [D loss: 0.454470, acc.: 69.53%] [G loss: 1.264594]\n",
      "epoch:28 step:26741 [D loss: 0.195441, acc.: 95.31%] [G loss: 1.397856]\n",
      "epoch:28 step:26742 [D loss: 0.693111, acc.: 60.16%] [G loss: 1.323658]\n",
      "epoch:28 step:26743 [D loss: 0.257754, acc.: 96.88%] [G loss: 1.542785]\n",
      "epoch:28 step:26744 [D loss: 0.242144, acc.: 98.44%] [G loss: 1.495399]\n",
      "epoch:28 step:26745 [D loss: 0.753720, acc.: 56.25%] [G loss: 1.091046]\n",
      "epoch:28 step:26746 [D loss: 0.756033, acc.: 57.81%] [G loss: 1.162659]\n",
      "epoch:28 step:26747 [D loss: 0.494119, acc.: 78.91%] [G loss: 1.152481]\n",
      "epoch:28 step:26748 [D loss: 0.598858, acc.: 62.50%] [G loss: 1.299366]\n",
      "epoch:28 step:26749 [D loss: 0.389376, acc.: 88.28%] [G loss: 1.314968]\n",
      "epoch:28 step:26750 [D loss: 0.380461, acc.: 89.06%] [G loss: 1.299420]\n",
      "epoch:28 step:26751 [D loss: 0.298734, acc.: 96.09%] [G loss: 1.294285]\n",
      "epoch:28 step:26752 [D loss: 0.748458, acc.: 53.91%] [G loss: 1.337856]\n",
      "epoch:28 step:26753 [D loss: 0.172398, acc.: 100.00%] [G loss: 1.298811]\n",
      "epoch:28 step:26754 [D loss: 0.493183, acc.: 83.59%] [G loss: 1.266458]\n",
      "epoch:28 step:26755 [D loss: 0.402875, acc.: 91.41%] [G loss: 1.318581]\n",
      "epoch:28 step:26756 [D loss: 0.470324, acc.: 83.59%] [G loss: 0.867348]\n",
      "epoch:28 step:26757 [D loss: 0.418036, acc.: 87.50%] [G loss: 1.210554]\n",
      "epoch:28 step:26758 [D loss: 0.438090, acc.: 83.59%] [G loss: 1.069840]\n",
      "epoch:28 step:26759 [D loss: 0.542891, acc.: 71.88%] [G loss: 1.181642]\n",
      "epoch:28 step:26760 [D loss: 0.286106, acc.: 95.31%] [G loss: 1.197943]\n",
      "epoch:28 step:26761 [D loss: 0.849705, acc.: 38.28%] [G loss: 0.861216]\n",
      "epoch:28 step:26762 [D loss: 0.788040, acc.: 49.22%] [G loss: 1.182626]\n",
      "epoch:28 step:26763 [D loss: 0.477277, acc.: 77.34%] [G loss: 1.608226]\n",
      "epoch:28 step:26764 [D loss: 0.678188, acc.: 57.81%] [G loss: 0.981344]\n",
      "epoch:28 step:26765 [D loss: 0.535826, acc.: 75.78%] [G loss: 0.935912]\n",
      "epoch:28 step:26766 [D loss: 0.390273, acc.: 85.94%] [G loss: 1.314615]\n",
      "epoch:28 step:26767 [D loss: 0.696079, acc.: 52.34%] [G loss: 1.199437]\n",
      "epoch:28 step:26768 [D loss: 0.546820, acc.: 73.44%] [G loss: 1.090279]\n",
      "epoch:28 step:26769 [D loss: 0.323155, acc.: 89.84%] [G loss: 1.363137]\n",
      "epoch:28 step:26770 [D loss: 0.339924, acc.: 92.97%] [G loss: 1.267210]\n",
      "epoch:28 step:26771 [D loss: 0.311532, acc.: 92.97%] [G loss: 1.484699]\n",
      "epoch:28 step:26772 [D loss: 0.190073, acc.: 96.88%] [G loss: 1.496033]\n",
      "epoch:28 step:26773 [D loss: 0.236340, acc.: 96.09%] [G loss: 1.569597]\n",
      "epoch:28 step:26774 [D loss: 0.488985, acc.: 78.91%] [G loss: 1.567218]\n",
      "epoch:28 step:26775 [D loss: 0.251302, acc.: 96.88%] [G loss: 1.726445]\n",
      "epoch:28 step:26776 [D loss: 0.389629, acc.: 85.16%] [G loss: 2.076101]\n",
      "epoch:28 step:26777 [D loss: 0.442985, acc.: 85.16%] [G loss: 1.151403]\n",
      "epoch:28 step:26778 [D loss: 0.602916, acc.: 67.97%] [G loss: 1.411810]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26779 [D loss: 0.210109, acc.: 92.97%] [G loss: 1.262739]\n",
      "epoch:28 step:26780 [D loss: 0.554092, acc.: 69.53%] [G loss: 1.243337]\n",
      "epoch:28 step:26781 [D loss: 0.404198, acc.: 82.81%] [G loss: 1.199032]\n",
      "epoch:28 step:26782 [D loss: 0.829844, acc.: 40.62%] [G loss: 0.896671]\n",
      "epoch:28 step:26783 [D loss: 0.374870, acc.: 91.41%] [G loss: 1.468749]\n",
      "epoch:28 step:26784 [D loss: 0.346079, acc.: 88.28%] [G loss: 1.498056]\n",
      "epoch:28 step:26785 [D loss: 0.302447, acc.: 87.50%] [G loss: 1.298421]\n",
      "epoch:28 step:26786 [D loss: 0.283772, acc.: 89.06%] [G loss: 1.485928]\n",
      "epoch:28 step:26787 [D loss: 0.495962, acc.: 73.44%] [G loss: 1.275128]\n",
      "epoch:28 step:26788 [D loss: 0.447102, acc.: 82.81%] [G loss: 1.365645]\n",
      "epoch:28 step:26789 [D loss: 0.539515, acc.: 72.66%] [G loss: 1.084076]\n",
      "epoch:28 step:26790 [D loss: 0.272519, acc.: 85.94%] [G loss: 1.310083]\n",
      "epoch:28 step:26791 [D loss: 0.788584, acc.: 59.38%] [G loss: 1.914021]\n",
      "epoch:28 step:26792 [D loss: 0.392629, acc.: 76.56%] [G loss: 2.128855]\n",
      "epoch:28 step:26793 [D loss: 0.347137, acc.: 91.41%] [G loss: 1.254010]\n",
      "epoch:28 step:26794 [D loss: 1.145495, acc.: 37.50%] [G loss: 1.785057]\n",
      "epoch:28 step:26795 [D loss: 0.217809, acc.: 88.28%] [G loss: 2.540946]\n",
      "epoch:28 step:26796 [D loss: 0.242515, acc.: 94.53%] [G loss: 2.645366]\n",
      "epoch:28 step:26797 [D loss: 0.060916, acc.: 100.00%] [G loss: 2.041420]\n",
      "epoch:28 step:26798 [D loss: 0.796918, acc.: 56.25%] [G loss: 1.984611]\n",
      "epoch:28 step:26799 [D loss: 0.915310, acc.: 51.56%] [G loss: 1.898912]\n",
      "epoch:28 step:26800 [D loss: 0.550884, acc.: 68.75%] [G loss: 1.558550]\n",
      "##############\n",
      "[3.77403153 2.77539429 7.14443268 5.62458882 4.70980097 6.28761575\n",
      " 5.76386054 5.65563947 6.00666007 5.33974658]\n",
      "##########\n",
      "epoch:28 step:26801 [D loss: 0.205545, acc.: 96.09%] [G loss: 1.633111]\n",
      "epoch:28 step:26802 [D loss: 0.095770, acc.: 99.22%] [G loss: 1.752491]\n",
      "epoch:28 step:26803 [D loss: 0.084969, acc.: 99.22%] [G loss: 2.052775]\n",
      "epoch:28 step:26804 [D loss: 0.289018, acc.: 89.06%] [G loss: 1.900485]\n",
      "epoch:28 step:26805 [D loss: 0.590001, acc.: 61.72%] [G loss: 1.951065]\n",
      "epoch:28 step:26806 [D loss: 0.427190, acc.: 86.72%] [G loss: 1.632734]\n",
      "epoch:28 step:26807 [D loss: 0.474069, acc.: 78.91%] [G loss: 1.962387]\n",
      "epoch:28 step:26808 [D loss: 0.330106, acc.: 90.62%] [G loss: 1.966075]\n",
      "epoch:28 step:26809 [D loss: 0.171518, acc.: 97.66%] [G loss: 1.986553]\n",
      "epoch:28 step:26810 [D loss: 0.263696, acc.: 93.75%] [G loss: 1.763570]\n",
      "epoch:28 step:26811 [D loss: 0.291102, acc.: 92.97%] [G loss: 2.745466]\n",
      "epoch:28 step:26812 [D loss: 0.143504, acc.: 98.44%] [G loss: 2.031199]\n",
      "epoch:28 step:26813 [D loss: 0.125843, acc.: 97.66%] [G loss: 2.015551]\n",
      "epoch:28 step:26814 [D loss: 0.032802, acc.: 100.00%] [G loss: 2.631687]\n",
      "epoch:28 step:26815 [D loss: 0.120672, acc.: 99.22%] [G loss: 2.261184]\n",
      "epoch:28 step:26816 [D loss: 0.736957, acc.: 58.59%] [G loss: 1.416600]\n",
      "epoch:28 step:26817 [D loss: 0.583056, acc.: 71.09%] [G loss: 0.832474]\n",
      "epoch:28 step:26818 [D loss: 0.953065, acc.: 47.66%] [G loss: 0.718520]\n",
      "epoch:28 step:26819 [D loss: 1.098224, acc.: 48.44%] [G loss: 0.224351]\n",
      "epoch:28 step:26820 [D loss: 1.041357, acc.: 37.50%] [G loss: 1.906264]\n",
      "epoch:28 step:26821 [D loss: 0.610731, acc.: 70.31%] [G loss: 1.517097]\n",
      "epoch:28 step:26822 [D loss: 0.677550, acc.: 60.16%] [G loss: 1.334453]\n",
      "epoch:28 step:26823 [D loss: 0.280899, acc.: 84.38%] [G loss: 1.106474]\n",
      "epoch:28 step:26824 [D loss: 0.214715, acc.: 90.62%] [G loss: 1.769268]\n",
      "epoch:28 step:26825 [D loss: 0.088111, acc.: 98.44%] [G loss: 2.408291]\n",
      "epoch:28 step:26826 [D loss: 0.666386, acc.: 63.28%] [G loss: 1.938507]\n",
      "epoch:28 step:26827 [D loss: 1.063751, acc.: 47.66%] [G loss: 1.277525]\n",
      "epoch:28 step:26828 [D loss: 0.825837, acc.: 57.81%] [G loss: 1.312708]\n",
      "epoch:28 step:26829 [D loss: 0.762460, acc.: 47.66%] [G loss: 0.998130]\n",
      "epoch:28 step:26830 [D loss: 0.452901, acc.: 84.38%] [G loss: 1.044680]\n",
      "epoch:28 step:26831 [D loss: 0.651875, acc.: 63.28%] [G loss: 1.164154]\n",
      "epoch:28 step:26832 [D loss: 0.715279, acc.: 57.81%] [G loss: 1.679256]\n",
      "epoch:28 step:26833 [D loss: 1.044427, acc.: 28.91%] [G loss: 1.360994]\n",
      "epoch:28 step:26834 [D loss: 0.735638, acc.: 55.47%] [G loss: 1.300261]\n",
      "epoch:28 step:26835 [D loss: 0.851547, acc.: 37.50%] [G loss: 1.187854]\n",
      "epoch:28 step:26836 [D loss: 0.212373, acc.: 95.31%] [G loss: 1.034471]\n",
      "epoch:28 step:26837 [D loss: 0.234186, acc.: 98.44%] [G loss: 1.233307]\n",
      "epoch:28 step:26838 [D loss: 0.430866, acc.: 80.47%] [G loss: 1.321340]\n",
      "epoch:28 step:26839 [D loss: 0.794583, acc.: 50.78%] [G loss: 1.334323]\n",
      "epoch:28 step:26840 [D loss: 0.401707, acc.: 81.25%] [G loss: 1.669900]\n",
      "epoch:28 step:26841 [D loss: 0.719191, acc.: 53.12%] [G loss: 1.675599]\n",
      "epoch:28 step:26842 [D loss: 0.640487, acc.: 66.41%] [G loss: 1.389673]\n",
      "epoch:28 step:26843 [D loss: 0.564432, acc.: 70.31%] [G loss: 1.333058]\n",
      "epoch:28 step:26844 [D loss: 0.327013, acc.: 92.19%] [G loss: 1.398804]\n",
      "epoch:28 step:26845 [D loss: 0.185387, acc.: 100.00%] [G loss: 1.529495]\n",
      "epoch:28 step:26846 [D loss: 0.606097, acc.: 65.62%] [G loss: 1.402685]\n",
      "epoch:28 step:26847 [D loss: 0.335187, acc.: 92.19%] [G loss: 1.064069]\n",
      "epoch:28 step:26848 [D loss: 0.420159, acc.: 85.16%] [G loss: 1.623215]\n",
      "epoch:28 step:26849 [D loss: 0.720909, acc.: 53.91%] [G loss: 1.067102]\n",
      "epoch:28 step:26850 [D loss: 0.664162, acc.: 55.47%] [G loss: 1.122508]\n",
      "epoch:28 step:26851 [D loss: 0.701360, acc.: 64.84%] [G loss: 0.786315]\n",
      "epoch:28 step:26852 [D loss: 0.602922, acc.: 65.62%] [G loss: 1.209215]\n",
      "epoch:28 step:26853 [D loss: 0.582077, acc.: 71.88%] [G loss: 1.096821]\n",
      "epoch:28 step:26854 [D loss: 0.549580, acc.: 72.66%] [G loss: 0.954010]\n",
      "epoch:28 step:26855 [D loss: 0.607202, acc.: 66.41%] [G loss: 0.664701]\n",
      "epoch:28 step:26856 [D loss: 0.548402, acc.: 70.31%] [G loss: 0.983938]\n",
      "epoch:28 step:26857 [D loss: 0.559527, acc.: 66.41%] [G loss: 1.253057]\n",
      "epoch:28 step:26858 [D loss: 0.501617, acc.: 76.56%] [G loss: 0.413182]\n",
      "epoch:28 step:26859 [D loss: 0.577836, acc.: 64.06%] [G loss: 0.939303]\n",
      "epoch:28 step:26860 [D loss: 0.542358, acc.: 71.09%] [G loss: 0.612009]\n",
      "epoch:28 step:26861 [D loss: 0.583372, acc.: 68.75%] [G loss: 1.236549]\n",
      "epoch:28 step:26862 [D loss: 0.837656, acc.: 43.75%] [G loss: 1.248638]\n",
      "epoch:28 step:26863 [D loss: 0.562348, acc.: 71.88%] [G loss: 0.839440]\n",
      "epoch:28 step:26864 [D loss: 1.011740, acc.: 35.16%] [G loss: 0.777869]\n",
      "epoch:28 step:26865 [D loss: 0.576384, acc.: 68.75%] [G loss: 1.710203]\n",
      "epoch:28 step:26866 [D loss: 0.384515, acc.: 87.50%] [G loss: 1.660343]\n",
      "epoch:28 step:26867 [D loss: 0.689152, acc.: 62.50%] [G loss: 1.619136]\n",
      "epoch:28 step:26868 [D loss: 0.287009, acc.: 89.06%] [G loss: 1.378566]\n",
      "epoch:28 step:26869 [D loss: 0.388174, acc.: 77.34%] [G loss: 1.896364]\n",
      "epoch:28 step:26870 [D loss: 0.171050, acc.: 98.44%] [G loss: 1.793604]\n",
      "epoch:28 step:26871 [D loss: 0.169921, acc.: 98.44%] [G loss: 2.364879]\n",
      "epoch:28 step:26872 [D loss: 0.385704, acc.: 81.25%] [G loss: 2.095855]\n",
      "epoch:28 step:26873 [D loss: 0.468952, acc.: 75.00%] [G loss: 1.824857]\n",
      "epoch:28 step:26874 [D loss: 0.506742, acc.: 70.31%] [G loss: 2.194584]\n",
      "epoch:28 step:26875 [D loss: 0.739751, acc.: 53.12%] [G loss: 1.788910]\n",
      "epoch:28 step:26876 [D loss: 0.947554, acc.: 52.34%] [G loss: 1.380591]\n",
      "epoch:28 step:26877 [D loss: 0.579071, acc.: 71.09%] [G loss: 1.053558]\n",
      "epoch:28 step:26878 [D loss: 0.786433, acc.: 53.12%] [G loss: 1.196231]\n",
      "epoch:28 step:26879 [D loss: 0.334121, acc.: 84.38%] [G loss: 1.619619]\n",
      "epoch:28 step:26880 [D loss: 0.228157, acc.: 90.62%] [G loss: 1.322720]\n",
      "epoch:28 step:26881 [D loss: 0.113068, acc.: 99.22%] [G loss: 1.672862]\n",
      "epoch:28 step:26882 [D loss: 0.120348, acc.: 98.44%] [G loss: 1.382275]\n",
      "epoch:28 step:26883 [D loss: 0.090711, acc.: 97.66%] [G loss: 1.749082]\n",
      "epoch:28 step:26884 [D loss: 0.108936, acc.: 99.22%] [G loss: 1.741455]\n",
      "epoch:28 step:26885 [D loss: 0.146232, acc.: 98.44%] [G loss: 2.220510]\n",
      "epoch:28 step:26886 [D loss: 0.065743, acc.: 100.00%] [G loss: 2.080289]\n",
      "epoch:28 step:26887 [D loss: 0.176429, acc.: 98.44%] [G loss: 2.143363]\n",
      "epoch:28 step:26888 [D loss: 0.444057, acc.: 82.81%] [G loss: 2.013594]\n",
      "epoch:28 step:26889 [D loss: 0.605378, acc.: 62.50%] [G loss: 1.569984]\n",
      "epoch:28 step:26890 [D loss: 0.662578, acc.: 59.38%] [G loss: 1.090147]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26891 [D loss: 0.272879, acc.: 93.75%] [G loss: 0.575636]\n",
      "epoch:28 step:26892 [D loss: 0.277678, acc.: 94.53%] [G loss: 1.234546]\n",
      "epoch:28 step:26893 [D loss: 0.519975, acc.: 72.66%] [G loss: 1.373324]\n",
      "epoch:28 step:26894 [D loss: 1.174301, acc.: 39.84%] [G loss: 1.223491]\n",
      "epoch:28 step:26895 [D loss: 0.269518, acc.: 89.84%] [G loss: 1.424000]\n",
      "epoch:28 step:26896 [D loss: 0.211788, acc.: 96.88%] [G loss: 1.955867]\n",
      "epoch:28 step:26897 [D loss: 0.267746, acc.: 95.31%] [G loss: 0.899679]\n",
      "epoch:28 step:26898 [D loss: 0.664023, acc.: 57.81%] [G loss: 2.209774]\n",
      "epoch:28 step:26899 [D loss: 0.414116, acc.: 84.38%] [G loss: 1.699102]\n",
      "epoch:28 step:26900 [D loss: 0.412032, acc.: 85.16%] [G loss: 0.847335]\n",
      "epoch:28 step:26901 [D loss: 0.368359, acc.: 84.38%] [G loss: 1.512094]\n",
      "epoch:28 step:26902 [D loss: 1.090562, acc.: 35.16%] [G loss: 1.685586]\n",
      "epoch:28 step:26903 [D loss: 0.920257, acc.: 49.22%] [G loss: 1.651327]\n",
      "epoch:28 step:26904 [D loss: 0.756045, acc.: 54.69%] [G loss: 1.341611]\n",
      "epoch:28 step:26905 [D loss: 0.732188, acc.: 51.56%] [G loss: 0.695226]\n",
      "epoch:28 step:26906 [D loss: 0.907051, acc.: 42.19%] [G loss: 0.898766]\n",
      "epoch:28 step:26907 [D loss: 0.910731, acc.: 41.41%] [G loss: 1.314378]\n",
      "epoch:28 step:26908 [D loss: 0.785800, acc.: 45.31%] [G loss: 1.122364]\n",
      "epoch:28 step:26909 [D loss: 0.746119, acc.: 58.59%] [G loss: 0.928906]\n",
      "epoch:28 step:26910 [D loss: 0.630492, acc.: 59.38%] [G loss: 1.321110]\n",
      "epoch:28 step:26911 [D loss: 2.039348, acc.: 19.53%] [G loss: 1.661442]\n",
      "epoch:28 step:26912 [D loss: 0.699487, acc.: 57.03%] [G loss: 1.607579]\n",
      "epoch:28 step:26913 [D loss: 0.733021, acc.: 60.16%] [G loss: 1.453853]\n",
      "epoch:28 step:26914 [D loss: 0.663389, acc.: 60.94%] [G loss: 1.193180]\n",
      "epoch:28 step:26915 [D loss: 0.601082, acc.: 74.22%] [G loss: 1.247936]\n",
      "epoch:28 step:26916 [D loss: 0.605827, acc.: 59.38%] [G loss: 1.172130]\n",
      "epoch:28 step:26917 [D loss: 0.689011, acc.: 58.59%] [G loss: 0.979478]\n",
      "epoch:28 step:26918 [D loss: 0.616151, acc.: 63.28%] [G loss: 1.097078]\n",
      "epoch:28 step:26919 [D loss: 0.568913, acc.: 68.75%] [G loss: 1.011440]\n",
      "epoch:28 step:26920 [D loss: 0.534542, acc.: 76.56%] [G loss: 1.168057]\n",
      "epoch:28 step:26921 [D loss: 0.629880, acc.: 59.38%] [G loss: 1.302274]\n",
      "epoch:28 step:26922 [D loss: 0.522136, acc.: 73.44%] [G loss: 1.040059]\n",
      "epoch:28 step:26923 [D loss: 0.494382, acc.: 78.12%] [G loss: 1.098656]\n",
      "epoch:28 step:26924 [D loss: 0.707463, acc.: 51.56%] [G loss: 0.950835]\n",
      "epoch:28 step:26925 [D loss: 0.721820, acc.: 59.38%] [G loss: 1.050457]\n",
      "epoch:28 step:26926 [D loss: 0.494901, acc.: 78.12%] [G loss: 1.025291]\n",
      "epoch:28 step:26927 [D loss: 0.695491, acc.: 54.69%] [G loss: 1.124782]\n",
      "epoch:28 step:26928 [D loss: 0.466022, acc.: 78.12%] [G loss: 1.030480]\n",
      "epoch:28 step:26929 [D loss: 0.571212, acc.: 70.31%] [G loss: 1.360941]\n",
      "epoch:28 step:26930 [D loss: 0.445135, acc.: 78.91%] [G loss: 1.134390]\n",
      "epoch:28 step:26931 [D loss: 0.717586, acc.: 60.94%] [G loss: 1.071635]\n",
      "epoch:28 step:26932 [D loss: 0.310950, acc.: 90.62%] [G loss: 1.150472]\n",
      "epoch:28 step:26933 [D loss: 0.265847, acc.: 93.75%] [G loss: 1.041793]\n",
      "epoch:28 step:26934 [D loss: 0.371853, acc.: 88.28%] [G loss: 1.397765]\n",
      "epoch:28 step:26935 [D loss: 0.460157, acc.: 89.06%] [G loss: 1.222200]\n",
      "epoch:28 step:26936 [D loss: 0.211026, acc.: 96.09%] [G loss: 1.178367]\n",
      "epoch:28 step:26937 [D loss: 0.311396, acc.: 90.62%] [G loss: 1.344962]\n",
      "epoch:28 step:26938 [D loss: 0.367041, acc.: 92.19%] [G loss: 1.422223]\n",
      "epoch:28 step:26939 [D loss: 0.710164, acc.: 54.69%] [G loss: 1.336669]\n",
      "epoch:28 step:26940 [D loss: 0.504509, acc.: 78.12%] [G loss: 1.510411]\n",
      "epoch:28 step:26941 [D loss: 0.681812, acc.: 61.72%] [G loss: 1.270411]\n",
      "epoch:28 step:26942 [D loss: 0.179622, acc.: 100.00%] [G loss: 1.101203]\n",
      "epoch:28 step:26943 [D loss: 0.205100, acc.: 95.31%] [G loss: 1.199831]\n",
      "epoch:28 step:26944 [D loss: 0.169320, acc.: 100.00%] [G loss: 2.078893]\n",
      "epoch:28 step:26945 [D loss: 0.166825, acc.: 97.66%] [G loss: 1.629115]\n",
      "epoch:28 step:26946 [D loss: 0.664789, acc.: 60.94%] [G loss: 1.745818]\n",
      "epoch:28 step:26947 [D loss: 0.468279, acc.: 84.38%] [G loss: 1.426808]\n",
      "epoch:28 step:26948 [D loss: 0.568750, acc.: 77.34%] [G loss: 1.434295]\n",
      "epoch:28 step:26949 [D loss: 0.210198, acc.: 95.31%] [G loss: 1.314342]\n",
      "epoch:28 step:26950 [D loss: 0.187196, acc.: 97.66%] [G loss: 1.387556]\n",
      "epoch:28 step:26951 [D loss: 0.733478, acc.: 54.69%] [G loss: 1.346974]\n",
      "epoch:28 step:26952 [D loss: 0.759916, acc.: 50.78%] [G loss: 1.123659]\n",
      "epoch:28 step:26953 [D loss: 0.626059, acc.: 62.50%] [G loss: 0.574143]\n",
      "epoch:28 step:26954 [D loss: 0.625262, acc.: 64.84%] [G loss: 1.066352]\n",
      "epoch:28 step:26955 [D loss: 0.854949, acc.: 39.06%] [G loss: 0.514858]\n",
      "epoch:28 step:26956 [D loss: 0.640872, acc.: 62.50%] [G loss: 0.776558]\n",
      "epoch:28 step:26957 [D loss: 0.715340, acc.: 53.91%] [G loss: 1.089904]\n",
      "epoch:28 step:26958 [D loss: 0.372511, acc.: 85.94%] [G loss: 1.263774]\n",
      "epoch:28 step:26959 [D loss: 0.396826, acc.: 85.16%] [G loss: 1.167834]\n",
      "epoch:28 step:26960 [D loss: 0.631348, acc.: 67.19%] [G loss: 1.053279]\n",
      "epoch:28 step:26961 [D loss: 0.603165, acc.: 70.31%] [G loss: 1.023246]\n",
      "epoch:28 step:26962 [D loss: 0.545820, acc.: 73.44%] [G loss: 1.018519]\n",
      "epoch:28 step:26963 [D loss: 0.248598, acc.: 92.97%] [G loss: 0.918317]\n",
      "epoch:28 step:26964 [D loss: 0.156870, acc.: 99.22%] [G loss: 1.591833]\n",
      "epoch:28 step:26965 [D loss: 0.196098, acc.: 95.31%] [G loss: 1.424334]\n",
      "epoch:28 step:26966 [D loss: 0.155257, acc.: 97.66%] [G loss: 1.757038]\n",
      "epoch:28 step:26967 [D loss: 0.184160, acc.: 94.53%] [G loss: 1.732119]\n",
      "epoch:28 step:26968 [D loss: 0.126669, acc.: 100.00%] [G loss: 1.780779]\n",
      "epoch:28 step:26969 [D loss: 0.267338, acc.: 92.97%] [G loss: 1.950329]\n",
      "epoch:28 step:26970 [D loss: 0.693076, acc.: 60.16%] [G loss: 1.910929]\n",
      "epoch:28 step:26971 [D loss: 0.842511, acc.: 53.12%] [G loss: 1.788974]\n",
      "epoch:28 step:26972 [D loss: 0.897370, acc.: 37.50%] [G loss: 1.495126]\n",
      "epoch:28 step:26973 [D loss: 0.701912, acc.: 55.47%] [G loss: 1.310406]\n",
      "epoch:28 step:26974 [D loss: 0.571288, acc.: 71.09%] [G loss: 1.380782]\n",
      "epoch:28 step:26975 [D loss: 0.185059, acc.: 98.44%] [G loss: 1.590291]\n",
      "epoch:28 step:26976 [D loss: 0.265004, acc.: 96.88%] [G loss: 1.404190]\n",
      "epoch:28 step:26977 [D loss: 0.761235, acc.: 53.12%] [G loss: 1.372314]\n",
      "epoch:28 step:26978 [D loss: 0.562083, acc.: 71.88%] [G loss: 1.135462]\n",
      "epoch:28 step:26979 [D loss: 0.598982, acc.: 67.19%] [G loss: 1.395622]\n",
      "epoch:28 step:26980 [D loss: 0.719443, acc.: 56.25%] [G loss: 1.139375]\n",
      "epoch:28 step:26981 [D loss: 0.226948, acc.: 94.53%] [G loss: 1.329720]\n",
      "epoch:28 step:26982 [D loss: 0.268190, acc.: 91.41%] [G loss: 1.524897]\n",
      "epoch:28 step:26983 [D loss: 0.331753, acc.: 92.19%] [G loss: 1.500809]\n",
      "epoch:28 step:26984 [D loss: 0.723647, acc.: 57.03%] [G loss: 1.360646]\n",
      "epoch:28 step:26985 [D loss: 0.704930, acc.: 60.94%] [G loss: 1.338444]\n",
      "epoch:28 step:26986 [D loss: 0.649072, acc.: 59.38%] [G loss: 1.206871]\n",
      "epoch:28 step:26987 [D loss: 0.498816, acc.: 80.47%] [G loss: 1.035047]\n",
      "epoch:28 step:26988 [D loss: 0.391391, acc.: 88.28%] [G loss: 1.202450]\n",
      "epoch:28 step:26989 [D loss: 0.250849, acc.: 94.53%] [G loss: 1.429980]\n",
      "epoch:28 step:26990 [D loss: 0.168884, acc.: 96.88%] [G loss: 0.872720]\n",
      "epoch:28 step:26991 [D loss: 0.182390, acc.: 97.66%] [G loss: 1.432319]\n",
      "epoch:28 step:26992 [D loss: 0.189316, acc.: 96.09%] [G loss: 1.396292]\n",
      "epoch:28 step:26993 [D loss: 0.155024, acc.: 97.66%] [G loss: 1.710682]\n",
      "epoch:28 step:26994 [D loss: 0.322706, acc.: 91.41%] [G loss: 1.564430]\n",
      "epoch:28 step:26995 [D loss: 0.933784, acc.: 47.66%] [G loss: 1.348570]\n",
      "epoch:28 step:26996 [D loss: 0.798704, acc.: 54.69%] [G loss: 1.367938]\n",
      "epoch:28 step:26997 [D loss: 0.904735, acc.: 34.38%] [G loss: 1.377009]\n",
      "epoch:28 step:26998 [D loss: 0.238995, acc.: 92.97%] [G loss: 1.189757]\n",
      "epoch:28 step:26999 [D loss: 0.585472, acc.: 67.19%] [G loss: 1.493280]\n",
      "epoch:28 step:27000 [D loss: 0.147675, acc.: 97.66%] [G loss: 1.237536]\n",
      "##############\n",
      "[4.0537629  2.55152908 6.55051721 5.34537894 4.61054418 5.96665188\n",
      " 5.20477513 5.3929499  5.79203697 5.15351213]\n",
      "##########\n",
      "epoch:28 step:27001 [D loss: 0.958573, acc.: 48.44%] [G loss: 1.542889]\n",
      "epoch:28 step:27002 [D loss: 0.710479, acc.: 60.94%] [G loss: 1.558751]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:27003 [D loss: 0.775807, acc.: 53.91%] [G loss: 1.204603]\n",
      "epoch:28 step:27004 [D loss: 0.460322, acc.: 86.72%] [G loss: 1.286387]\n",
      "epoch:28 step:27005 [D loss: 0.333294, acc.: 92.19%] [G loss: 1.283420]\n",
      "epoch:28 step:27006 [D loss: 0.712684, acc.: 56.25%] [G loss: 1.470982]\n",
      "epoch:28 step:27007 [D loss: 0.520846, acc.: 77.34%] [G loss: 1.221137]\n",
      "epoch:28 step:27008 [D loss: 0.674361, acc.: 59.38%] [G loss: 1.243574]\n",
      "epoch:28 step:27009 [D loss: 0.635132, acc.: 63.28%] [G loss: 0.825516]\n",
      "epoch:28 step:27010 [D loss: 0.263496, acc.: 92.97%] [G loss: 0.677667]\n",
      "epoch:28 step:27011 [D loss: 0.264346, acc.: 92.19%] [G loss: 1.345898]\n",
      "epoch:28 step:27012 [D loss: 0.540984, acc.: 73.44%] [G loss: 1.117259]\n",
      "epoch:28 step:27013 [D loss: 0.571650, acc.: 72.66%] [G loss: 1.273376]\n",
      "epoch:28 step:27014 [D loss: 0.800447, acc.: 46.09%] [G loss: 0.986692]\n",
      "epoch:28 step:27015 [D loss: 0.546721, acc.: 71.09%] [G loss: 1.021592]\n",
      "epoch:28 step:27016 [D loss: 0.247488, acc.: 89.84%] [G loss: 1.186926]\n",
      "epoch:28 step:27017 [D loss: 0.177799, acc.: 97.66%] [G loss: 1.187287]\n",
      "epoch:28 step:27018 [D loss: 0.201247, acc.: 93.75%] [G loss: 1.348450]\n",
      "epoch:28 step:27019 [D loss: 0.220107, acc.: 96.88%] [G loss: 1.529389]\n",
      "epoch:28 step:27020 [D loss: 0.259673, acc.: 95.31%] [G loss: 1.355083]\n",
      "epoch:28 step:27021 [D loss: 0.358990, acc.: 94.53%] [G loss: 1.972622]\n",
      "epoch:28 step:27022 [D loss: 0.148253, acc.: 100.00%] [G loss: 1.152097]\n",
      "epoch:28 step:27023 [D loss: 0.683552, acc.: 61.72%] [G loss: 1.493865]\n",
      "epoch:28 step:27024 [D loss: 0.331060, acc.: 90.62%] [G loss: 1.483366]\n",
      "epoch:28 step:27025 [D loss: 0.529607, acc.: 74.22%] [G loss: 1.370196]\n",
      "epoch:28 step:27026 [D loss: 0.516514, acc.: 74.22%] [G loss: 0.966092]\n",
      "epoch:28 step:27027 [D loss: 0.164199, acc.: 98.44%] [G loss: 0.580476]\n",
      "epoch:28 step:27028 [D loss: 0.440686, acc.: 70.31%] [G loss: 1.771295]\n",
      "epoch:28 step:27029 [D loss: 0.129883, acc.: 100.00%] [G loss: 1.840662]\n",
      "epoch:28 step:27030 [D loss: 0.139243, acc.: 98.44%] [G loss: 1.796664]\n",
      "epoch:28 step:27031 [D loss: 0.204101, acc.: 98.44%] [G loss: 2.350333]\n",
      "epoch:28 step:27032 [D loss: 0.156670, acc.: 97.66%] [G loss: 1.401116]\n",
      "epoch:28 step:27033 [D loss: 0.555913, acc.: 67.19%] [G loss: 1.049010]\n",
      "epoch:28 step:27034 [D loss: 0.280126, acc.: 96.88%] [G loss: 2.091381]\n",
      "epoch:28 step:27035 [D loss: 0.611866, acc.: 64.84%] [G loss: 1.414077]\n",
      "epoch:28 step:27036 [D loss: 0.619026, acc.: 64.06%] [G loss: 0.237588]\n",
      "epoch:28 step:27037 [D loss: 0.554325, acc.: 71.88%] [G loss: 1.289857]\n",
      "epoch:28 step:27038 [D loss: 0.273762, acc.: 92.97%] [G loss: 1.314878]\n",
      "epoch:28 step:27039 [D loss: 0.685299, acc.: 64.84%] [G loss: 1.137398]\n",
      "epoch:28 step:27040 [D loss: 0.208008, acc.: 93.75%] [G loss: 0.662324]\n",
      "epoch:28 step:27041 [D loss: 0.356619, acc.: 80.47%] [G loss: 1.885531]\n",
      "epoch:28 step:27042 [D loss: 1.557415, acc.: 50.78%] [G loss: 1.171845]\n",
      "epoch:28 step:27043 [D loss: 0.992127, acc.: 53.12%] [G loss: 2.072659]\n",
      "epoch:28 step:27044 [D loss: 0.136586, acc.: 98.44%] [G loss: 2.550498]\n",
      "epoch:28 step:27045 [D loss: 0.146570, acc.: 97.66%] [G loss: 2.448561]\n",
      "epoch:28 step:27046 [D loss: 0.433329, acc.: 78.91%] [G loss: 1.957623]\n",
      "epoch:28 step:27047 [D loss: 0.947053, acc.: 50.00%] [G loss: 1.903974]\n",
      "epoch:28 step:27048 [D loss: 0.689411, acc.: 57.81%] [G loss: 1.575921]\n",
      "epoch:28 step:27049 [D loss: 0.723230, acc.: 54.69%] [G loss: 1.366934]\n",
      "epoch:28 step:27050 [D loss: 0.769690, acc.: 50.78%] [G loss: 1.080969]\n",
      "epoch:28 step:27051 [D loss: 0.188630, acc.: 96.09%] [G loss: 1.175995]\n",
      "epoch:28 step:27052 [D loss: 0.219382, acc.: 97.66%] [G loss: 0.954694]\n",
      "epoch:28 step:27053 [D loss: 0.783458, acc.: 56.25%] [G loss: 1.102714]\n",
      "epoch:28 step:27054 [D loss: 0.547764, acc.: 71.88%] [G loss: 1.085977]\n",
      "epoch:28 step:27055 [D loss: 0.641064, acc.: 63.28%] [G loss: 0.932629]\n",
      "epoch:28 step:27056 [D loss: 0.719064, acc.: 57.81%] [G loss: 0.930620]\n",
      "epoch:28 step:27057 [D loss: 0.520245, acc.: 79.69%] [G loss: 0.986373]\n",
      "epoch:28 step:27058 [D loss: 0.784180, acc.: 52.34%] [G loss: 1.244269]\n",
      "epoch:28 step:27059 [D loss: 0.689267, acc.: 53.91%] [G loss: 1.248998]\n",
      "epoch:28 step:27060 [D loss: 0.368274, acc.: 83.59%] [G loss: 0.903794]\n",
      "epoch:28 step:27061 [D loss: 0.269107, acc.: 89.06%] [G loss: 1.489719]\n",
      "epoch:28 step:27062 [D loss: 0.607038, acc.: 61.72%] [G loss: 1.417530]\n",
      "epoch:28 step:27063 [D loss: 0.793362, acc.: 49.22%] [G loss: 1.070751]\n",
      "epoch:28 step:27064 [D loss: 0.541204, acc.: 74.22%] [G loss: 1.011739]\n",
      "epoch:28 step:27065 [D loss: 0.305552, acc.: 94.53%] [G loss: 0.534681]\n",
      "epoch:28 step:27066 [D loss: 0.225761, acc.: 92.97%] [G loss: 1.546618]\n",
      "epoch:28 step:27067 [D loss: 0.536805, acc.: 66.41%] [G loss: 1.921795]\n",
      "epoch:28 step:27068 [D loss: 0.095859, acc.: 99.22%] [G loss: 2.038764]\n",
      "epoch:28 step:27069 [D loss: 0.181351, acc.: 97.66%] [G loss: 2.079049]\n",
      "epoch:28 step:27070 [D loss: 1.038346, acc.: 50.00%] [G loss: 1.804816]\n",
      "epoch:28 step:27071 [D loss: 0.977483, acc.: 44.53%] [G loss: 1.514215]\n",
      "epoch:28 step:27072 [D loss: 0.864551, acc.: 45.31%] [G loss: 1.372466]\n",
      "epoch:28 step:27073 [D loss: 0.791482, acc.: 42.19%] [G loss: 1.507498]\n",
      "epoch:28 step:27074 [D loss: 0.612640, acc.: 67.19%] [G loss: 1.214542]\n",
      "epoch:28 step:27075 [D loss: 0.779688, acc.: 48.44%] [G loss: 1.097686]\n",
      "epoch:28 step:27076 [D loss: 0.793960, acc.: 46.09%] [G loss: 0.909168]\n",
      "epoch:28 step:27077 [D loss: 0.609506, acc.: 64.84%] [G loss: 1.193350]\n",
      "epoch:28 step:27078 [D loss: 0.554328, acc.: 71.88%] [G loss: 1.086465]\n",
      "epoch:28 step:27079 [D loss: 0.256991, acc.: 90.62%] [G loss: 1.340459]\n",
      "epoch:28 step:27080 [D loss: 0.550847, acc.: 67.19%] [G loss: 1.463541]\n",
      "epoch:28 step:27081 [D loss: 0.142791, acc.: 100.00%] [G loss: 1.867963]\n",
      "epoch:28 step:27082 [D loss: 0.703588, acc.: 52.34%] [G loss: 1.732857]\n",
      "epoch:28 step:27083 [D loss: 0.484985, acc.: 81.25%] [G loss: 1.542188]\n",
      "epoch:28 step:27084 [D loss: 0.515060, acc.: 78.91%] [G loss: 1.661079]\n",
      "epoch:28 step:27085 [D loss: 0.545419, acc.: 73.44%] [G loss: 1.463529]\n",
      "epoch:28 step:27086 [D loss: 0.352260, acc.: 87.50%] [G loss: 1.734067]\n",
      "epoch:28 step:27087 [D loss: 0.134439, acc.: 99.22%] [G loss: 1.168625]\n",
      "epoch:28 step:27088 [D loss: 0.195487, acc.: 97.66%] [G loss: 1.918092]\n",
      "epoch:28 step:27089 [D loss: 0.189658, acc.: 99.22%] [G loss: 1.628295]\n",
      "epoch:28 step:27090 [D loss: 0.148015, acc.: 99.22%] [G loss: 1.796323]\n",
      "epoch:28 step:27091 [D loss: 0.224663, acc.: 100.00%] [G loss: 1.414953]\n",
      "epoch:28 step:27092 [D loss: 0.698983, acc.: 54.69%] [G loss: 1.612744]\n",
      "epoch:28 step:27093 [D loss: 0.177970, acc.: 98.44%] [G loss: 1.616628]\n",
      "epoch:28 step:27094 [D loss: 0.206538, acc.: 96.88%] [G loss: 1.631767]\n",
      "epoch:28 step:27095 [D loss: 0.229745, acc.: 93.75%] [G loss: 1.557994]\n",
      "epoch:28 step:27096 [D loss: 0.158359, acc.: 98.44%] [G loss: 1.728466]\n",
      "epoch:28 step:27097 [D loss: 0.531607, acc.: 73.44%] [G loss: 1.581336]\n",
      "epoch:28 step:27098 [D loss: 0.790753, acc.: 50.78%] [G loss: 1.454660]\n",
      "epoch:28 step:27099 [D loss: 0.717030, acc.: 60.16%] [G loss: 1.373057]\n",
      "epoch:28 step:27100 [D loss: 0.806690, acc.: 48.44%] [G loss: 1.190845]\n",
      "epoch:28 step:27101 [D loss: 0.396733, acc.: 85.94%] [G loss: 0.911285]\n",
      "epoch:28 step:27102 [D loss: 0.610798, acc.: 63.28%] [G loss: 1.179802]\n",
      "epoch:28 step:27103 [D loss: 0.415389, acc.: 78.12%] [G loss: 1.227575]\n",
      "epoch:28 step:27104 [D loss: 0.811960, acc.: 51.56%] [G loss: 0.848413]\n",
      "epoch:28 step:27105 [D loss: 0.622871, acc.: 66.41%] [G loss: 1.134831]\n",
      "epoch:28 step:27106 [D loss: 0.716012, acc.: 56.25%] [G loss: 1.280014]\n",
      "epoch:28 step:27107 [D loss: 0.535630, acc.: 72.66%] [G loss: 1.288359]\n",
      "epoch:28 step:27108 [D loss: 1.005244, acc.: 48.44%] [G loss: 0.431028]\n",
      "epoch:28 step:27109 [D loss: 1.660413, acc.: 22.66%] [G loss: 1.379125]\n",
      "epoch:28 step:27110 [D loss: 0.861130, acc.: 49.22%] [G loss: 1.369934]\n",
      "epoch:28 step:27111 [D loss: 0.706304, acc.: 53.91%] [G loss: 1.714693]\n",
      "epoch:28 step:27112 [D loss: 0.853175, acc.: 43.75%] [G loss: 1.218525]\n",
      "epoch:28 step:27113 [D loss: 0.531843, acc.: 74.22%] [G loss: 0.987061]\n",
      "epoch:28 step:27114 [D loss: 0.151519, acc.: 97.66%] [G loss: 1.949505]\n",
      "epoch:28 step:27115 [D loss: 0.700851, acc.: 59.38%] [G loss: 1.403562]\n",
      "epoch:28 step:27116 [D loss: 0.791315, acc.: 49.22%] [G loss: 1.447412]\n",
      "epoch:28 step:27117 [D loss: 0.750350, acc.: 49.22%] [G loss: 0.974528]\n",
      "epoch:28 step:27118 [D loss: 0.395911, acc.: 85.94%] [G loss: 1.461611]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:27119 [D loss: 0.438406, acc.: 86.72%] [G loss: 1.353116]\n",
      "epoch:28 step:27120 [D loss: 0.301624, acc.: 96.88%] [G loss: 0.994904]\n",
      "epoch:28 step:27121 [D loss: 0.246916, acc.: 89.84%] [G loss: 0.797750]\n",
      "epoch:28 step:27122 [D loss: 0.221459, acc.: 98.44%] [G loss: 1.450895]\n",
      "epoch:28 step:27123 [D loss: 0.178189, acc.: 99.22%] [G loss: 1.472958]\n",
      "epoch:28 step:27124 [D loss: 0.864749, acc.: 46.88%] [G loss: 0.795512]\n",
      "epoch:28 step:27125 [D loss: 0.271159, acc.: 89.84%] [G loss: 0.964216]\n",
      "epoch:28 step:27126 [D loss: 0.255291, acc.: 96.88%] [G loss: 1.480511]\n",
      "epoch:28 step:27127 [D loss: 0.594208, acc.: 63.28%] [G loss: 1.251342]\n",
      "epoch:28 step:27128 [D loss: 0.518728, acc.: 75.78%] [G loss: 1.297889]\n",
      "epoch:28 step:27129 [D loss: 0.459467, acc.: 83.59%] [G loss: 0.949563]\n",
      "epoch:28 step:27130 [D loss: 0.624537, acc.: 60.94%] [G loss: 1.304321]\n",
      "epoch:28 step:27131 [D loss: 0.376475, acc.: 82.81%] [G loss: 1.289183]\n",
      "epoch:28 step:27132 [D loss: 0.226310, acc.: 99.22%] [G loss: 1.426199]\n",
      "epoch:28 step:27133 [D loss: 0.331087, acc.: 86.72%] [G loss: 1.459584]\n",
      "epoch:28 step:27134 [D loss: 0.163408, acc.: 98.44%] [G loss: 1.752125]\n",
      "epoch:28 step:27135 [D loss: 0.111707, acc.: 98.44%] [G loss: 1.694996]\n",
      "epoch:28 step:27136 [D loss: 0.119502, acc.: 97.66%] [G loss: 2.076857]\n",
      "epoch:28 step:27137 [D loss: 0.109882, acc.: 100.00%] [G loss: 1.419952]\n",
      "epoch:28 step:27138 [D loss: 0.409079, acc.: 79.69%] [G loss: 1.785993]\n",
      "epoch:28 step:27139 [D loss: 0.259742, acc.: 95.31%] [G loss: 1.850215]\n",
      "epoch:28 step:27140 [D loss: 0.840485, acc.: 51.56%] [G loss: 1.212801]\n",
      "epoch:28 step:27141 [D loss: 0.774884, acc.: 56.25%] [G loss: 1.518123]\n",
      "epoch:28 step:27142 [D loss: 0.844174, acc.: 47.66%] [G loss: 1.218709]\n",
      "epoch:28 step:27143 [D loss: 0.885582, acc.: 45.31%] [G loss: 1.112262]\n",
      "epoch:28 step:27144 [D loss: 0.500092, acc.: 77.34%] [G loss: 1.356428]\n",
      "epoch:28 step:27145 [D loss: 0.218945, acc.: 96.88%] [G loss: 1.215066]\n",
      "epoch:28 step:27146 [D loss: 0.703150, acc.: 59.38%] [G loss: 1.306066]\n",
      "epoch:28 step:27147 [D loss: 0.193238, acc.: 96.09%] [G loss: 1.488617]\n",
      "epoch:28 step:27148 [D loss: 0.234797, acc.: 92.97%] [G loss: 1.489339]\n",
      "epoch:28 step:27149 [D loss: 0.420437, acc.: 82.03%] [G loss: 1.517791]\n",
      "epoch:28 step:27150 [D loss: 0.836677, acc.: 47.66%] [G loss: 1.484908]\n",
      "epoch:28 step:27151 [D loss: 0.673444, acc.: 59.38%] [G loss: 1.164689]\n",
      "epoch:28 step:27152 [D loss: 0.582005, acc.: 68.75%] [G loss: 0.886996]\n",
      "epoch:28 step:27153 [D loss: 0.348054, acc.: 91.41%] [G loss: 1.359798]\n",
      "epoch:28 step:27154 [D loss: 0.651399, acc.: 57.81%] [G loss: 1.261475]\n",
      "epoch:28 step:27155 [D loss: 0.212650, acc.: 93.75%] [G loss: 1.232736]\n",
      "epoch:28 step:27156 [D loss: 0.308709, acc.: 89.06%] [G loss: 1.108765]\n",
      "epoch:28 step:27157 [D loss: 0.221943, acc.: 96.09%] [G loss: 1.588058]\n",
      "epoch:28 step:27158 [D loss: 0.589630, acc.: 60.94%] [G loss: 1.285210]\n",
      "epoch:28 step:27159 [D loss: 0.430994, acc.: 86.72%] [G loss: 1.517372]\n",
      "epoch:28 step:27160 [D loss: 0.189204, acc.: 96.09%] [G loss: 1.312690]\n",
      "epoch:28 step:27161 [D loss: 0.517395, acc.: 67.97%] [G loss: 0.939354]\n",
      "epoch:28 step:27162 [D loss: 0.130097, acc.: 99.22%] [G loss: 1.868293]\n",
      "epoch:28 step:27163 [D loss: 0.118813, acc.: 97.66%] [G loss: 1.744495]\n",
      "epoch:28 step:27164 [D loss: 0.596307, acc.: 66.41%] [G loss: 1.683082]\n",
      "epoch:28 step:27165 [D loss: 0.244282, acc.: 93.75%] [G loss: 1.667771]\n",
      "epoch:28 step:27166 [D loss: 0.662691, acc.: 60.94%] [G loss: 1.224753]\n",
      "epoch:28 step:27167 [D loss: 0.469551, acc.: 86.72%] [G loss: 1.333713]\n",
      "epoch:28 step:27168 [D loss: 0.248748, acc.: 91.41%] [G loss: 1.571887]\n",
      "epoch:28 step:27169 [D loss: 0.254224, acc.: 89.06%] [G loss: 1.387284]\n",
      "epoch:28 step:27170 [D loss: 0.128067, acc.: 98.44%] [G loss: 1.787703]\n",
      "epoch:28 step:27171 [D loss: 0.142470, acc.: 95.31%] [G loss: 1.817702]\n",
      "epoch:28 step:27172 [D loss: 0.114557, acc.: 97.66%] [G loss: 1.582682]\n",
      "epoch:28 step:27173 [D loss: 0.082266, acc.: 100.00%] [G loss: 1.932247]\n",
      "epoch:29 step:27174 [D loss: 0.239704, acc.: 92.97%] [G loss: 1.301783]\n",
      "epoch:29 step:27175 [D loss: 0.128597, acc.: 100.00%] [G loss: 2.020903]\n",
      "epoch:29 step:27176 [D loss: 0.265386, acc.: 88.28%] [G loss: 1.464144]\n",
      "epoch:29 step:27177 [D loss: 0.595879, acc.: 68.75%] [G loss: 1.833522]\n",
      "epoch:29 step:27178 [D loss: 0.543582, acc.: 70.31%] [G loss: 1.613149]\n",
      "epoch:29 step:27179 [D loss: 0.514796, acc.: 70.31%] [G loss: 1.715300]\n",
      "epoch:29 step:27180 [D loss: 0.112985, acc.: 99.22%] [G loss: 0.956660]\n",
      "epoch:29 step:27181 [D loss: 0.156128, acc.: 98.44%] [G loss: 0.954176]\n",
      "epoch:29 step:27182 [D loss: 0.122624, acc.: 98.44%] [G loss: 1.095648]\n",
      "epoch:29 step:27183 [D loss: 0.148924, acc.: 96.88%] [G loss: 1.327764]\n",
      "epoch:29 step:27184 [D loss: 0.135030, acc.: 99.22%] [G loss: 1.629191]\n",
      "epoch:29 step:27185 [D loss: 0.905535, acc.: 52.34%] [G loss: 1.330953]\n",
      "epoch:29 step:27186 [D loss: 0.703421, acc.: 64.84%] [G loss: 2.677780]\n",
      "epoch:29 step:27187 [D loss: 0.729062, acc.: 58.59%] [G loss: 1.517262]\n",
      "epoch:29 step:27188 [D loss: 0.209828, acc.: 96.88%] [G loss: 1.709667]\n",
      "epoch:29 step:27189 [D loss: 0.248987, acc.: 93.75%] [G loss: 1.428261]\n",
      "epoch:29 step:27190 [D loss: 0.677324, acc.: 56.25%] [G loss: 2.313331]\n",
      "epoch:29 step:27191 [D loss: 2.173704, acc.: 41.41%] [G loss: 2.251411]\n",
      "epoch:29 step:27192 [D loss: 1.295600, acc.: 44.53%] [G loss: 2.141067]\n",
      "epoch:29 step:27193 [D loss: 1.271104, acc.: 46.88%] [G loss: 1.100980]\n",
      "epoch:29 step:27194 [D loss: 1.484398, acc.: 25.78%] [G loss: 1.816247]\n",
      "epoch:29 step:27195 [D loss: 1.117728, acc.: 44.53%] [G loss: 1.903700]\n",
      "epoch:29 step:27196 [D loss: 0.879153, acc.: 45.31%] [G loss: 1.807324]\n",
      "epoch:29 step:27197 [D loss: 0.701508, acc.: 50.78%] [G loss: 1.573138]\n",
      "epoch:29 step:27198 [D loss: 0.632152, acc.: 61.72%] [G loss: 0.974145]\n",
      "epoch:29 step:27199 [D loss: 0.992997, acc.: 19.53%] [G loss: 1.460095]\n",
      "epoch:29 step:27200 [D loss: 0.367230, acc.: 92.97%] [G loss: 1.682733]\n",
      "##############\n",
      "[3.8404468  2.69524316 7.28599348 6.10398954 4.65267681 6.85804259\n",
      " 5.37529928 6.28871334 6.01742792 5.24557851]\n",
      "##########\n",
      "epoch:29 step:27201 [D loss: 0.548049, acc.: 67.19%] [G loss: 1.847916]\n",
      "epoch:29 step:27202 [D loss: 0.492172, acc.: 71.09%] [G loss: 1.747972]\n",
      "epoch:29 step:27203 [D loss: 0.497008, acc.: 75.00%] [G loss: 1.707693]\n",
      "epoch:29 step:27204 [D loss: 0.205673, acc.: 95.31%] [G loss: 1.997908]\n",
      "epoch:29 step:27205 [D loss: 0.245360, acc.: 98.44%] [G loss: 1.408711]\n",
      "epoch:29 step:27206 [D loss: 0.210930, acc.: 100.00%] [G loss: 2.355057]\n",
      "epoch:29 step:27207 [D loss: 0.248035, acc.: 99.22%] [G loss: 2.440061]\n",
      "epoch:29 step:27208 [D loss: 0.137626, acc.: 100.00%] [G loss: 1.981777]\n",
      "epoch:29 step:27209 [D loss: 0.102285, acc.: 100.00%] [G loss: 1.770402]\n",
      "epoch:29 step:27210 [D loss: 0.883555, acc.: 50.78%] [G loss: 1.255314]\n",
      "epoch:29 step:27211 [D loss: 0.981997, acc.: 39.06%] [G loss: 1.031730]\n",
      "epoch:29 step:27212 [D loss: 0.881241, acc.: 46.09%] [G loss: 1.031724]\n",
      "epoch:29 step:27213 [D loss: 0.525027, acc.: 78.91%] [G loss: 0.888879]\n",
      "epoch:29 step:27214 [D loss: 0.507978, acc.: 83.59%] [G loss: 1.008691]\n",
      "epoch:29 step:27215 [D loss: 0.375890, acc.: 96.88%] [G loss: 0.829741]\n",
      "epoch:29 step:27216 [D loss: 0.431718, acc.: 92.19%] [G loss: 1.176146]\n",
      "epoch:29 step:27217 [D loss: 0.469051, acc.: 89.84%] [G loss: 0.904190]\n",
      "epoch:29 step:27218 [D loss: 0.477012, acc.: 81.25%] [G loss: 1.111682]\n",
      "epoch:29 step:27219 [D loss: 0.422502, acc.: 89.84%] [G loss: 1.273390]\n",
      "epoch:29 step:27220 [D loss: 0.617047, acc.: 72.66%] [G loss: 1.085841]\n",
      "epoch:29 step:27221 [D loss: 0.646410, acc.: 70.31%] [G loss: 0.711234]\n",
      "epoch:29 step:27222 [D loss: 0.597411, acc.: 67.19%] [G loss: 1.085353]\n",
      "epoch:29 step:27223 [D loss: 0.570489, acc.: 74.22%] [G loss: 1.054178]\n",
      "epoch:29 step:27224 [D loss: 0.343275, acc.: 94.53%] [G loss: 1.186683]\n",
      "epoch:29 step:27225 [D loss: 0.619754, acc.: 71.88%] [G loss: 1.014700]\n",
      "epoch:29 step:27226 [D loss: 0.527569, acc.: 77.34%] [G loss: 1.162697]\n",
      "epoch:29 step:27227 [D loss: 0.681685, acc.: 61.72%] [G loss: 0.750616]\n",
      "epoch:29 step:27228 [D loss: 0.797408, acc.: 42.19%] [G loss: 0.924525]\n",
      "epoch:29 step:27229 [D loss: 0.602244, acc.: 68.75%] [G loss: 1.382398]\n",
      "epoch:29 step:27230 [D loss: 0.294427, acc.: 90.62%] [G loss: 0.977016]\n",
      "epoch:29 step:27231 [D loss: 0.241849, acc.: 96.09%] [G loss: 1.092490]\n",
      "epoch:29 step:27232 [D loss: 0.351502, acc.: 92.19%] [G loss: 1.093584]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27233 [D loss: 0.314803, acc.: 94.53%] [G loss: 1.254049]\n",
      "epoch:29 step:27234 [D loss: 0.541700, acc.: 70.31%] [G loss: 1.479147]\n",
      "epoch:29 step:27235 [D loss: 0.941507, acc.: 37.50%] [G loss: 0.800507]\n",
      "epoch:29 step:27236 [D loss: 0.375449, acc.: 92.97%] [G loss: 1.574599]\n",
      "epoch:29 step:27237 [D loss: 0.863812, acc.: 45.31%] [G loss: 0.997183]\n",
      "epoch:29 step:27238 [D loss: 0.830421, acc.: 41.41%] [G loss: 1.038044]\n",
      "epoch:29 step:27239 [D loss: 0.651633, acc.: 63.28%] [G loss: 1.137855]\n",
      "epoch:29 step:27240 [D loss: 0.686365, acc.: 61.72%] [G loss: 0.881727]\n",
      "epoch:29 step:27241 [D loss: 0.973103, acc.: 32.03%] [G loss: 0.838606]\n",
      "epoch:29 step:27242 [D loss: 0.698505, acc.: 63.28%] [G loss: 0.800291]\n",
      "epoch:29 step:27243 [D loss: 0.660364, acc.: 60.94%] [G loss: 0.851759]\n",
      "epoch:29 step:27244 [D loss: 0.357374, acc.: 76.56%] [G loss: 1.191006]\n",
      "epoch:29 step:27245 [D loss: 0.381755, acc.: 84.38%] [G loss: 1.401612]\n",
      "epoch:29 step:27246 [D loss: 0.273548, acc.: 98.44%] [G loss: 1.366026]\n",
      "epoch:29 step:27247 [D loss: 0.599257, acc.: 68.75%] [G loss: 1.062326]\n",
      "epoch:29 step:27248 [D loss: 0.244270, acc.: 86.72%] [G loss: 1.311772]\n",
      "epoch:29 step:27249 [D loss: 0.268971, acc.: 89.84%] [G loss: 1.274845]\n",
      "epoch:29 step:27250 [D loss: 0.191113, acc.: 97.66%] [G loss: 1.460795]\n",
      "epoch:29 step:27251 [D loss: 0.901931, acc.: 52.34%] [G loss: 1.553583]\n",
      "epoch:29 step:27252 [D loss: 0.759508, acc.: 57.81%] [G loss: 0.808136]\n",
      "epoch:29 step:27253 [D loss: 0.974703, acc.: 35.16%] [G loss: 1.245367]\n",
      "epoch:29 step:27254 [D loss: 0.610493, acc.: 67.19%] [G loss: 0.742154]\n",
      "epoch:29 step:27255 [D loss: 0.619636, acc.: 67.97%] [G loss: 0.821856]\n",
      "epoch:29 step:27256 [D loss: 0.424031, acc.: 88.28%] [G loss: 1.219240]\n",
      "epoch:29 step:27257 [D loss: 0.976401, acc.: 32.81%] [G loss: 1.296067]\n",
      "epoch:29 step:27258 [D loss: 0.605625, acc.: 67.97%] [G loss: 1.270819]\n",
      "epoch:29 step:27259 [D loss: 0.743582, acc.: 52.34%] [G loss: 1.014179]\n",
      "epoch:29 step:27260 [D loss: 0.598349, acc.: 72.66%] [G loss: 0.936051]\n",
      "epoch:29 step:27261 [D loss: 0.623045, acc.: 70.31%] [G loss: 1.244186]\n",
      "epoch:29 step:27262 [D loss: 0.476930, acc.: 86.72%] [G loss: 1.107903]\n",
      "epoch:29 step:27263 [D loss: 0.569358, acc.: 70.31%] [G loss: 1.074537]\n",
      "epoch:29 step:27264 [D loss: 0.639260, acc.: 65.62%] [G loss: 1.445631]\n",
      "epoch:29 step:27265 [D loss: 0.600681, acc.: 60.16%] [G loss: 1.137932]\n",
      "epoch:29 step:27266 [D loss: 0.318418, acc.: 92.97%] [G loss: 1.307414]\n",
      "epoch:29 step:27267 [D loss: 0.607698, acc.: 68.75%] [G loss: 1.140769]\n",
      "epoch:29 step:27268 [D loss: 0.842850, acc.: 46.88%] [G loss: 1.201533]\n",
      "epoch:29 step:27269 [D loss: 0.647141, acc.: 65.62%] [G loss: 1.117804]\n",
      "epoch:29 step:27270 [D loss: 0.660531, acc.: 56.25%] [G loss: 1.278434]\n",
      "epoch:29 step:27271 [D loss: 0.478254, acc.: 85.16%] [G loss: 1.269151]\n",
      "epoch:29 step:27272 [D loss: 0.693598, acc.: 61.72%] [G loss: 0.937225]\n",
      "epoch:29 step:27273 [D loss: 0.560280, acc.: 74.22%] [G loss: 1.103256]\n",
      "epoch:29 step:27274 [D loss: 0.635242, acc.: 67.19%] [G loss: 1.200016]\n",
      "epoch:29 step:27275 [D loss: 0.769609, acc.: 47.66%] [G loss: 1.008947]\n",
      "epoch:29 step:27276 [D loss: 0.658833, acc.: 60.16%] [G loss: 0.991241]\n",
      "epoch:29 step:27277 [D loss: 0.846347, acc.: 40.62%] [G loss: 0.912079]\n",
      "epoch:29 step:27278 [D loss: 0.460906, acc.: 82.03%] [G loss: 0.932709]\n",
      "epoch:29 step:27279 [D loss: 0.722300, acc.: 53.12%] [G loss: 0.955066]\n",
      "epoch:29 step:27280 [D loss: 0.544062, acc.: 73.44%] [G loss: 0.988568]\n",
      "epoch:29 step:27281 [D loss: 0.624171, acc.: 67.19%] [G loss: 0.939656]\n",
      "epoch:29 step:27282 [D loss: 0.667987, acc.: 60.16%] [G loss: 1.149030]\n",
      "epoch:29 step:27283 [D loss: 0.628893, acc.: 64.84%] [G loss: 0.969481]\n",
      "epoch:29 step:27284 [D loss: 0.450880, acc.: 78.91%] [G loss: 0.992274]\n",
      "epoch:29 step:27285 [D loss: 0.493162, acc.: 78.91%] [G loss: 0.785212]\n",
      "epoch:29 step:27286 [D loss: 0.578833, acc.: 71.09%] [G loss: 1.163080]\n",
      "epoch:29 step:27287 [D loss: 0.279177, acc.: 95.31%] [G loss: 1.200722]\n",
      "epoch:29 step:27288 [D loss: 0.323022, acc.: 89.84%] [G loss: 1.035878]\n",
      "epoch:29 step:27289 [D loss: 0.660118, acc.: 59.38%] [G loss: 1.266405]\n",
      "epoch:29 step:27290 [D loss: 0.529792, acc.: 74.22%] [G loss: 1.012564]\n",
      "epoch:29 step:27291 [D loss: 0.503052, acc.: 75.00%] [G loss: 1.147331]\n",
      "epoch:29 step:27292 [D loss: 0.199990, acc.: 97.66%] [G loss: 1.105399]\n",
      "epoch:29 step:27293 [D loss: 0.303717, acc.: 92.97%] [G loss: 1.129938]\n",
      "epoch:29 step:27294 [D loss: 0.319395, acc.: 85.94%] [G loss: 1.325681]\n",
      "epoch:29 step:27295 [D loss: 0.255262, acc.: 92.19%] [G loss: 1.677632]\n",
      "epoch:29 step:27296 [D loss: 0.623325, acc.: 62.50%] [G loss: 1.541112]\n",
      "epoch:29 step:27297 [D loss: 0.750842, acc.: 57.81%] [G loss: 1.556182]\n",
      "epoch:29 step:27298 [D loss: 0.723205, acc.: 57.03%] [G loss: 1.283868]\n",
      "epoch:29 step:27299 [D loss: 0.679919, acc.: 60.16%] [G loss: 1.204172]\n",
      "epoch:29 step:27300 [D loss: 0.685708, acc.: 53.91%] [G loss: 1.062243]\n",
      "epoch:29 step:27301 [D loss: 0.551765, acc.: 75.78%] [G loss: 0.707644]\n",
      "epoch:29 step:27302 [D loss: 0.370092, acc.: 78.91%] [G loss: 1.052334]\n",
      "epoch:29 step:27303 [D loss: 0.430184, acc.: 75.00%] [G loss: 0.968505]\n",
      "epoch:29 step:27304 [D loss: 0.318771, acc.: 97.66%] [G loss: 1.432064]\n",
      "epoch:29 step:27305 [D loss: 0.523022, acc.: 71.88%] [G loss: 1.288812]\n",
      "epoch:29 step:27306 [D loss: 0.666267, acc.: 63.28%] [G loss: 1.413277]\n",
      "epoch:29 step:27307 [D loss: 0.332336, acc.: 91.41%] [G loss: 1.554697]\n",
      "epoch:29 step:27308 [D loss: 0.369342, acc.: 89.06%] [G loss: 1.298140]\n",
      "epoch:29 step:27309 [D loss: 0.458351, acc.: 82.81%] [G loss: 1.484753]\n",
      "epoch:29 step:27310 [D loss: 0.792089, acc.: 52.34%] [G loss: 1.310280]\n",
      "epoch:29 step:27311 [D loss: 0.572715, acc.: 71.88%] [G loss: 1.322652]\n",
      "epoch:29 step:27312 [D loss: 0.423337, acc.: 81.25%] [G loss: 1.302476]\n",
      "epoch:29 step:27313 [D loss: 0.321686, acc.: 89.84%] [G loss: 1.551959]\n",
      "epoch:29 step:27314 [D loss: 0.264141, acc.: 94.53%] [G loss: 1.644886]\n",
      "epoch:29 step:27315 [D loss: 0.542236, acc.: 74.22%] [G loss: 1.305984]\n",
      "epoch:29 step:27316 [D loss: 0.173910, acc.: 93.75%] [G loss: 1.648770]\n",
      "epoch:29 step:27317 [D loss: 0.150704, acc.: 99.22%] [G loss: 1.734154]\n",
      "epoch:29 step:27318 [D loss: 0.124529, acc.: 99.22%] [G loss: 1.760857]\n",
      "epoch:29 step:27319 [D loss: 0.203186, acc.: 98.44%] [G loss: 1.948285]\n",
      "epoch:29 step:27320 [D loss: 0.647028, acc.: 67.19%] [G loss: 1.818041]\n",
      "epoch:29 step:27321 [D loss: 0.773795, acc.: 50.00%] [G loss: 1.111940]\n",
      "epoch:29 step:27322 [D loss: 0.360780, acc.: 89.06%] [G loss: 1.439129]\n",
      "epoch:29 step:27323 [D loss: 0.163418, acc.: 97.66%] [G loss: 1.248863]\n",
      "epoch:29 step:27324 [D loss: 0.142609, acc.: 99.22%] [G loss: 2.025945]\n",
      "epoch:29 step:27325 [D loss: 0.183812, acc.: 96.88%] [G loss: 1.454293]\n",
      "epoch:29 step:27326 [D loss: 0.702628, acc.: 60.94%] [G loss: 1.606463]\n",
      "epoch:29 step:27327 [D loss: 0.697692, acc.: 54.69%] [G loss: 1.250129]\n",
      "epoch:29 step:27328 [D loss: 0.582893, acc.: 66.41%] [G loss: 1.588784]\n",
      "epoch:29 step:27329 [D loss: 0.802787, acc.: 51.56%] [G loss: 1.445408]\n",
      "epoch:29 step:27330 [D loss: 0.560358, acc.: 71.09%] [G loss: 1.273595]\n",
      "epoch:29 step:27331 [D loss: 0.859246, acc.: 40.62%] [G loss: 1.322268]\n",
      "epoch:29 step:27332 [D loss: 1.082041, acc.: 24.22%] [G loss: 0.912105]\n",
      "epoch:29 step:27333 [D loss: 0.324926, acc.: 91.41%] [G loss: 1.500712]\n",
      "epoch:29 step:27334 [D loss: 0.392475, acc.: 90.62%] [G loss: 0.968788]\n",
      "epoch:29 step:27335 [D loss: 0.197811, acc.: 97.66%] [G loss: 1.626548]\n",
      "epoch:29 step:27336 [D loss: 0.354138, acc.: 89.06%] [G loss: 1.919645]\n",
      "epoch:29 step:27337 [D loss: 0.228899, acc.: 96.09%] [G loss: 1.368264]\n",
      "epoch:29 step:27338 [D loss: 0.352951, acc.: 91.41%] [G loss: 1.247889]\n",
      "epoch:29 step:27339 [D loss: 0.924979, acc.: 44.53%] [G loss: 1.704083]\n",
      "epoch:29 step:27340 [D loss: 0.941986, acc.: 39.06%] [G loss: 1.575202]\n",
      "epoch:29 step:27341 [D loss: 1.013894, acc.: 32.81%] [G loss: 1.688423]\n",
      "epoch:29 step:27342 [D loss: 0.720209, acc.: 60.94%] [G loss: 1.289410]\n",
      "epoch:29 step:27343 [D loss: 0.501720, acc.: 76.56%] [G loss: 1.044168]\n",
      "epoch:29 step:27344 [D loss: 0.911959, acc.: 32.81%] [G loss: 1.428821]\n",
      "epoch:29 step:27345 [D loss: 1.457245, acc.: 28.91%] [G loss: 1.412642]\n",
      "epoch:29 step:27346 [D loss: 0.737823, acc.: 50.78%] [G loss: 1.389353]\n",
      "epoch:29 step:27347 [D loss: 0.669173, acc.: 64.84%] [G loss: 1.470830]\n",
      "epoch:29 step:27348 [D loss: 1.202379, acc.: 21.09%] [G loss: 1.664522]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27349 [D loss: 0.640628, acc.: 60.16%] [G loss: 1.492916]\n",
      "epoch:29 step:27350 [D loss: 0.729697, acc.: 51.56%] [G loss: 1.464015]\n",
      "epoch:29 step:27351 [D loss: 0.538555, acc.: 75.78%] [G loss: 1.038249]\n",
      "epoch:29 step:27352 [D loss: 0.420026, acc.: 82.81%] [G loss: 1.200584]\n",
      "epoch:29 step:27353 [D loss: 0.632912, acc.: 68.75%] [G loss: 1.211479]\n",
      "epoch:29 step:27354 [D loss: 0.722902, acc.: 55.47%] [G loss: 1.059208]\n",
      "epoch:29 step:27355 [D loss: 0.828931, acc.: 41.41%] [G loss: 1.084448]\n",
      "epoch:29 step:27356 [D loss: 0.684430, acc.: 61.72%] [G loss: 0.905244]\n",
      "epoch:29 step:27357 [D loss: 0.762009, acc.: 48.44%] [G loss: 1.168134]\n",
      "epoch:29 step:27358 [D loss: 0.496769, acc.: 72.66%] [G loss: 0.966166]\n",
      "epoch:29 step:27359 [D loss: 0.538569, acc.: 77.34%] [G loss: 1.017460]\n",
      "epoch:29 step:27360 [D loss: 0.612853, acc.: 65.62%] [G loss: 1.179822]\n",
      "epoch:29 step:27361 [D loss: 0.682914, acc.: 57.03%] [G loss: 1.092193]\n",
      "epoch:29 step:27362 [D loss: 0.729773, acc.: 50.00%] [G loss: 0.760767]\n",
      "epoch:29 step:27363 [D loss: 0.833798, acc.: 40.62%] [G loss: 0.929710]\n",
      "epoch:29 step:27364 [D loss: 0.634588, acc.: 62.50%] [G loss: 1.271042]\n",
      "epoch:29 step:27365 [D loss: 0.311330, acc.: 92.19%] [G loss: 1.061428]\n",
      "epoch:29 step:27366 [D loss: 0.483884, acc.: 78.12%] [G loss: 1.216959]\n",
      "epoch:29 step:27367 [D loss: 0.297907, acc.: 92.97%] [G loss: 1.388774]\n",
      "epoch:29 step:27368 [D loss: 0.390109, acc.: 88.28%] [G loss: 1.351125]\n",
      "epoch:29 step:27369 [D loss: 0.435010, acc.: 79.69%] [G loss: 1.415343]\n",
      "epoch:29 step:27370 [D loss: 0.414067, acc.: 85.94%] [G loss: 1.369590]\n",
      "epoch:29 step:27371 [D loss: 0.379341, acc.: 89.84%] [G loss: 1.377796]\n",
      "epoch:29 step:27372 [D loss: 0.758128, acc.: 50.78%] [G loss: 1.257732]\n",
      "epoch:29 step:27373 [D loss: 0.414102, acc.: 85.16%] [G loss: 1.536056]\n",
      "epoch:29 step:27374 [D loss: 0.238663, acc.: 96.09%] [G loss: 1.439100]\n",
      "epoch:29 step:27375 [D loss: 0.670753, acc.: 57.03%] [G loss: 1.534318]\n",
      "epoch:29 step:27376 [D loss: 0.204006, acc.: 100.00%] [G loss: 1.350228]\n",
      "epoch:29 step:27377 [D loss: 0.215613, acc.: 97.66%] [G loss: 1.546550]\n",
      "epoch:29 step:27378 [D loss: 0.328089, acc.: 91.41%] [G loss: 1.884486]\n",
      "epoch:29 step:27379 [D loss: 0.125070, acc.: 99.22%] [G loss: 1.651967]\n",
      "epoch:29 step:27380 [D loss: 0.126550, acc.: 98.44%] [G loss: 1.509061]\n",
      "epoch:29 step:27381 [D loss: 0.109889, acc.: 99.22%] [G loss: 1.864356]\n",
      "epoch:29 step:27382 [D loss: 0.166936, acc.: 96.09%] [G loss: 1.890414]\n",
      "epoch:29 step:27383 [D loss: 0.696958, acc.: 60.16%] [G loss: 1.380755]\n",
      "epoch:29 step:27384 [D loss: 0.941553, acc.: 49.22%] [G loss: 1.106919]\n",
      "epoch:29 step:27385 [D loss: 0.608319, acc.: 67.97%] [G loss: 0.898090]\n",
      "epoch:29 step:27386 [D loss: 0.769618, acc.: 54.69%] [G loss: 0.812314]\n",
      "epoch:29 step:27387 [D loss: 0.631606, acc.: 67.97%] [G loss: 0.836006]\n",
      "epoch:29 step:27388 [D loss: 0.799099, acc.: 45.31%] [G loss: 0.746689]\n",
      "epoch:29 step:27389 [D loss: 0.633730, acc.: 64.06%] [G loss: 1.362409]\n",
      "epoch:29 step:27390 [D loss: 0.252382, acc.: 91.41%] [G loss: 1.630908]\n",
      "epoch:29 step:27391 [D loss: 0.384549, acc.: 78.12%] [G loss: 1.615490]\n",
      "epoch:29 step:27392 [D loss: 0.267466, acc.: 87.50%] [G loss: 1.612775]\n",
      "epoch:29 step:27393 [D loss: 0.144697, acc.: 100.00%] [G loss: 1.348064]\n",
      "epoch:29 step:27394 [D loss: 0.375308, acc.: 89.06%] [G loss: 1.625364]\n",
      "epoch:29 step:27395 [D loss: 0.414760, acc.: 80.47%] [G loss: 1.524239]\n",
      "epoch:29 step:27396 [D loss: 0.376947, acc.: 85.94%] [G loss: 1.774839]\n",
      "epoch:29 step:27397 [D loss: 0.475092, acc.: 82.03%] [G loss: 1.655641]\n",
      "epoch:29 step:27398 [D loss: 0.347626, acc.: 89.84%] [G loss: 1.702497]\n",
      "epoch:29 step:27399 [D loss: 0.912696, acc.: 46.88%] [G loss: 1.562395]\n",
      "epoch:29 step:27400 [D loss: 0.886387, acc.: 46.09%] [G loss: 1.313411]\n",
      "##############\n",
      "[3.83572041 2.2738236  6.50187105 5.5166983  4.61400101 6.25411621\n",
      " 5.65928643 5.82519315 5.9734401  4.94928398]\n",
      "##########\n",
      "epoch:29 step:27401 [D loss: 0.761192, acc.: 50.78%] [G loss: 1.172952]\n",
      "epoch:29 step:27402 [D loss: 0.672399, acc.: 57.03%] [G loss: 1.154597]\n",
      "epoch:29 step:27403 [D loss: 0.164112, acc.: 98.44%] [G loss: 1.289160]\n",
      "epoch:29 step:27404 [D loss: 0.231196, acc.: 96.09%] [G loss: 1.307193]\n",
      "epoch:29 step:27405 [D loss: 0.222760, acc.: 93.75%] [G loss: 1.500399]\n",
      "epoch:29 step:27406 [D loss: 0.804705, acc.: 50.00%] [G loss: 1.386961]\n",
      "epoch:29 step:27407 [D loss: 0.486416, acc.: 78.91%] [G loss: 1.367389]\n",
      "epoch:29 step:27408 [D loss: 0.480166, acc.: 78.91%] [G loss: 1.178980]\n",
      "epoch:29 step:27409 [D loss: 0.667151, acc.: 55.47%] [G loss: 1.238733]\n",
      "epoch:29 step:27410 [D loss: 0.470870, acc.: 83.59%] [G loss: 1.006251]\n",
      "epoch:29 step:27411 [D loss: 0.389384, acc.: 86.72%] [G loss: 1.652813]\n",
      "epoch:29 step:27412 [D loss: 0.550292, acc.: 75.78%] [G loss: 1.148267]\n",
      "epoch:29 step:27413 [D loss: 0.685428, acc.: 58.59%] [G loss: 1.093936]\n",
      "epoch:29 step:27414 [D loss: 0.635513, acc.: 61.72%] [G loss: 1.263645]\n",
      "epoch:29 step:27415 [D loss: 0.664628, acc.: 61.72%] [G loss: 1.027568]\n",
      "epoch:29 step:27416 [D loss: 0.604590, acc.: 64.06%] [G loss: 1.305705]\n",
      "epoch:29 step:27417 [D loss: 0.627435, acc.: 65.62%] [G loss: 1.356336]\n",
      "epoch:29 step:27418 [D loss: 0.787986, acc.: 51.56%] [G loss: 1.368505]\n",
      "epoch:29 step:27419 [D loss: 0.671673, acc.: 56.25%] [G loss: 1.006763]\n",
      "epoch:29 step:27420 [D loss: 0.619525, acc.: 64.06%] [G loss: 1.251819]\n",
      "epoch:29 step:27421 [D loss: 0.603296, acc.: 67.19%] [G loss: 1.072489]\n",
      "epoch:29 step:27422 [D loss: 0.580657, acc.: 71.88%] [G loss: 0.991146]\n",
      "epoch:29 step:27423 [D loss: 0.724162, acc.: 50.78%] [G loss: 1.054101]\n",
      "epoch:29 step:27424 [D loss: 0.571938, acc.: 69.53%] [G loss: 1.152384]\n",
      "epoch:29 step:27425 [D loss: 0.532515, acc.: 75.00%] [G loss: 1.128091]\n",
      "epoch:29 step:27426 [D loss: 0.576949, acc.: 72.66%] [G loss: 0.943708]\n",
      "epoch:29 step:27427 [D loss: 0.326437, acc.: 85.16%] [G loss: 1.502308]\n",
      "epoch:29 step:27428 [D loss: 0.204567, acc.: 95.31%] [G loss: 1.709293]\n",
      "epoch:29 step:27429 [D loss: 0.136185, acc.: 98.44%] [G loss: 1.427330]\n",
      "epoch:29 step:27430 [D loss: 0.175020, acc.: 98.44%] [G loss: 1.552999]\n",
      "epoch:29 step:27431 [D loss: 0.544844, acc.: 69.53%] [G loss: 1.523641]\n",
      "epoch:29 step:27432 [D loss: 0.150542, acc.: 98.44%] [G loss: 1.685439]\n",
      "epoch:29 step:27433 [D loss: 0.196285, acc.: 96.88%] [G loss: 1.968510]\n",
      "epoch:29 step:27434 [D loss: 0.128585, acc.: 99.22%] [G loss: 1.498293]\n",
      "epoch:29 step:27435 [D loss: 0.668939, acc.: 58.59%] [G loss: 1.748971]\n",
      "epoch:29 step:27436 [D loss: 0.543813, acc.: 80.47%] [G loss: 1.416852]\n",
      "epoch:29 step:27437 [D loss: 0.462892, acc.: 78.12%] [G loss: 1.219503]\n",
      "epoch:29 step:27438 [D loss: 0.479906, acc.: 82.81%] [G loss: 1.536278]\n",
      "epoch:29 step:27439 [D loss: 0.786825, acc.: 52.34%] [G loss: 1.071622]\n",
      "epoch:29 step:27440 [D loss: 0.637804, acc.: 63.28%] [G loss: 1.411443]\n",
      "epoch:29 step:27441 [D loss: 0.819101, acc.: 50.78%] [G loss: 1.290103]\n",
      "epoch:29 step:27442 [D loss: 0.314175, acc.: 94.53%] [G loss: 1.043293]\n",
      "epoch:29 step:27443 [D loss: 0.616394, acc.: 67.19%] [G loss: 1.272271]\n",
      "epoch:29 step:27444 [D loss: 0.348233, acc.: 88.28%] [G loss: 1.380778]\n",
      "epoch:29 step:27445 [D loss: 0.332211, acc.: 92.19%] [G loss: 1.411066]\n",
      "epoch:29 step:27446 [D loss: 0.672121, acc.: 60.16%] [G loss: 1.303543]\n",
      "epoch:29 step:27447 [D loss: 0.295549, acc.: 92.19%] [G loss: 0.909589]\n",
      "epoch:29 step:27448 [D loss: 0.324184, acc.: 94.53%] [G loss: 1.617369]\n",
      "epoch:29 step:27449 [D loss: 0.297640, acc.: 96.09%] [G loss: 0.761521]\n",
      "epoch:29 step:27450 [D loss: 0.505341, acc.: 73.44%] [G loss: 1.462053]\n",
      "epoch:29 step:27451 [D loss: 0.170438, acc.: 98.44%] [G loss: 1.373388]\n",
      "epoch:29 step:27452 [D loss: 0.133635, acc.: 100.00%] [G loss: 1.612423]\n",
      "epoch:29 step:27453 [D loss: 0.481076, acc.: 78.91%] [G loss: 1.089697]\n",
      "epoch:29 step:27454 [D loss: 0.705921, acc.: 53.91%] [G loss: 1.206393]\n",
      "epoch:29 step:27455 [D loss: 0.342490, acc.: 90.62%] [G loss: 0.970449]\n",
      "epoch:29 step:27456 [D loss: 0.645685, acc.: 63.28%] [G loss: 1.198175]\n",
      "epoch:29 step:27457 [D loss: 0.267051, acc.: 93.75%] [G loss: 1.342973]\n",
      "epoch:29 step:27458 [D loss: 0.319158, acc.: 92.19%] [G loss: 1.582306]\n",
      "epoch:29 step:27459 [D loss: 0.350339, acc.: 82.81%] [G loss: 1.688516]\n",
      "epoch:29 step:27460 [D loss: 0.299662, acc.: 93.75%] [G loss: 0.999228]\n",
      "epoch:29 step:27461 [D loss: 0.227089, acc.: 97.66%] [G loss: 1.667238]\n",
      "epoch:29 step:27462 [D loss: 0.138916, acc.: 99.22%] [G loss: 1.365915]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27463 [D loss: 0.595117, acc.: 65.62%] [G loss: 1.609711]\n",
      "epoch:29 step:27464 [D loss: 0.321186, acc.: 88.28%] [G loss: 1.232653]\n",
      "epoch:29 step:27465 [D loss: 0.197980, acc.: 96.09%] [G loss: 1.364670]\n",
      "epoch:29 step:27466 [D loss: 0.202380, acc.: 96.88%] [G loss: 1.788306]\n",
      "epoch:29 step:27467 [D loss: 0.419632, acc.: 82.81%] [G loss: 1.472408]\n",
      "epoch:29 step:27468 [D loss: 0.851170, acc.: 52.34%] [G loss: 1.509681]\n",
      "epoch:29 step:27469 [D loss: 0.833984, acc.: 50.00%] [G loss: 1.229671]\n",
      "epoch:29 step:27470 [D loss: 0.341399, acc.: 92.19%] [G loss: 1.189115]\n",
      "epoch:29 step:27471 [D loss: 0.289692, acc.: 93.75%] [G loss: 0.998015]\n",
      "epoch:29 step:27472 [D loss: 0.304937, acc.: 89.06%] [G loss: 1.436603]\n",
      "epoch:29 step:27473 [D loss: 0.704400, acc.: 55.47%] [G loss: 1.368524]\n",
      "epoch:29 step:27474 [D loss: 0.889949, acc.: 42.19%] [G loss: 1.382645]\n",
      "epoch:29 step:27475 [D loss: 0.810794, acc.: 47.66%] [G loss: 1.306531]\n",
      "epoch:29 step:27476 [D loss: 0.728444, acc.: 56.25%] [G loss: 0.939902]\n",
      "epoch:29 step:27477 [D loss: 0.474051, acc.: 82.81%] [G loss: 0.814362]\n",
      "epoch:29 step:27478 [D loss: 0.281115, acc.: 86.72%] [G loss: 0.945963]\n",
      "epoch:29 step:27479 [D loss: 0.388742, acc.: 84.38%] [G loss: 1.555385]\n",
      "epoch:29 step:27480 [D loss: 0.550593, acc.: 73.44%] [G loss: 1.435705]\n",
      "epoch:29 step:27481 [D loss: 0.339887, acc.: 81.25%] [G loss: 0.880771]\n",
      "epoch:29 step:27482 [D loss: 0.120060, acc.: 99.22%] [G loss: 1.842809]\n",
      "epoch:29 step:27483 [D loss: 0.311658, acc.: 91.41%] [G loss: 0.624198]\n",
      "epoch:29 step:27484 [D loss: 0.369469, acc.: 78.12%] [G loss: 1.876787]\n",
      "epoch:29 step:27485 [D loss: 0.126491, acc.: 96.88%] [G loss: 2.050684]\n",
      "epoch:29 step:27486 [D loss: 0.110489, acc.: 99.22%] [G loss: 2.168066]\n",
      "epoch:29 step:27487 [D loss: 0.149327, acc.: 97.66%] [G loss: 2.206810]\n",
      "epoch:29 step:27488 [D loss: 0.108926, acc.: 100.00%] [G loss: 2.251532]\n",
      "epoch:29 step:27489 [D loss: 1.224074, acc.: 48.44%] [G loss: 2.018883]\n",
      "epoch:29 step:27490 [D loss: 0.906341, acc.: 50.78%] [G loss: 1.591954]\n",
      "epoch:29 step:27491 [D loss: 0.888110, acc.: 50.78%] [G loss: 1.130428]\n",
      "epoch:29 step:27492 [D loss: 0.761718, acc.: 51.56%] [G loss: 1.292508]\n",
      "epoch:29 step:27493 [D loss: 0.982430, acc.: 33.59%] [G loss: 1.351162]\n",
      "epoch:29 step:27494 [D loss: 0.831770, acc.: 52.34%] [G loss: 1.298259]\n",
      "epoch:29 step:27495 [D loss: 0.656805, acc.: 57.81%] [G loss: 1.243712]\n",
      "epoch:29 step:27496 [D loss: 0.421280, acc.: 71.88%] [G loss: 1.334709]\n",
      "epoch:29 step:27497 [D loss: 0.356727, acc.: 92.19%] [G loss: 1.695973]\n",
      "epoch:29 step:27498 [D loss: 0.409505, acc.: 84.38%] [G loss: 1.424931]\n",
      "epoch:29 step:27499 [D loss: 0.752619, acc.: 53.12%] [G loss: 1.029857]\n",
      "epoch:29 step:27500 [D loss: 0.626080, acc.: 62.50%] [G loss: 1.293347]\n",
      "epoch:29 step:27501 [D loss: 0.615899, acc.: 71.09%] [G loss: 1.430639]\n",
      "epoch:29 step:27502 [D loss: 0.723324, acc.: 50.78%] [G loss: 0.679579]\n",
      "epoch:29 step:27503 [D loss: 0.376006, acc.: 90.62%] [G loss: 1.372155]\n",
      "epoch:29 step:27504 [D loss: 0.265071, acc.: 92.19%] [G loss: 1.279597]\n",
      "epoch:29 step:27505 [D loss: 0.347548, acc.: 77.34%] [G loss: 1.689644]\n",
      "epoch:29 step:27506 [D loss: 0.158198, acc.: 98.44%] [G loss: 1.988800]\n",
      "epoch:29 step:27507 [D loss: 0.163298, acc.: 96.88%] [G loss: 1.779845]\n",
      "epoch:29 step:27508 [D loss: 0.172690, acc.: 98.44%] [G loss: 1.883680]\n",
      "epoch:29 step:27509 [D loss: 0.121058, acc.: 100.00%] [G loss: 1.884086]\n",
      "epoch:29 step:27510 [D loss: 0.345169, acc.: 89.06%] [G loss: 1.898552]\n",
      "epoch:29 step:27511 [D loss: 0.694043, acc.: 59.38%] [G loss: 1.224406]\n",
      "epoch:29 step:27512 [D loss: 0.673343, acc.: 59.38%] [G loss: 1.620414]\n",
      "epoch:29 step:27513 [D loss: 0.436575, acc.: 83.59%] [G loss: 1.211441]\n",
      "epoch:29 step:27514 [D loss: 0.250034, acc.: 98.44%] [G loss: 1.499349]\n",
      "epoch:29 step:27515 [D loss: 0.294885, acc.: 82.03%] [G loss: 1.550318]\n",
      "epoch:29 step:27516 [D loss: 0.875254, acc.: 53.91%] [G loss: 2.053222]\n",
      "epoch:29 step:27517 [D loss: 0.068590, acc.: 100.00%] [G loss: 2.138438]\n",
      "epoch:29 step:27518 [D loss: 0.123286, acc.: 97.66%] [G loss: 2.673795]\n",
      "epoch:29 step:27519 [D loss: 0.063660, acc.: 100.00%] [G loss: 2.330046]\n",
      "epoch:29 step:27520 [D loss: 0.069565, acc.: 100.00%] [G loss: 2.433348]\n",
      "epoch:29 step:27521 [D loss: 0.615827, acc.: 62.50%] [G loss: 2.111665]\n",
      "epoch:29 step:27522 [D loss: 1.050217, acc.: 48.44%] [G loss: 1.946410]\n",
      "epoch:29 step:27523 [D loss: 0.473407, acc.: 79.69%] [G loss: 1.766392]\n",
      "epoch:29 step:27524 [D loss: 0.798174, acc.: 52.34%] [G loss: 1.457693]\n",
      "epoch:29 step:27525 [D loss: 0.702370, acc.: 57.81%] [G loss: 1.330483]\n",
      "epoch:29 step:27526 [D loss: 0.542038, acc.: 68.75%] [G loss: 1.778012]\n",
      "epoch:29 step:27527 [D loss: 0.471970, acc.: 79.69%] [G loss: 0.881656]\n",
      "epoch:29 step:27528 [D loss: 0.796928, acc.: 54.69%] [G loss: 1.329720]\n",
      "epoch:29 step:27529 [D loss: 0.588238, acc.: 62.50%] [G loss: 1.169817]\n",
      "epoch:29 step:27530 [D loss: 0.904009, acc.: 35.94%] [G loss: 1.141674]\n",
      "epoch:29 step:27531 [D loss: 0.596527, acc.: 67.97%] [G loss: 1.139925]\n",
      "epoch:29 step:27532 [D loss: 0.490593, acc.: 82.03%] [G loss: 1.257189]\n",
      "epoch:29 step:27533 [D loss: 0.854421, acc.: 46.88%] [G loss: 1.244111]\n",
      "epoch:29 step:27534 [D loss: 0.706973, acc.: 55.47%] [G loss: 0.803198]\n",
      "epoch:29 step:27535 [D loss: 0.551115, acc.: 64.06%] [G loss: 1.356241]\n",
      "epoch:29 step:27536 [D loss: 0.217554, acc.: 91.41%] [G loss: 1.636236]\n",
      "epoch:29 step:27537 [D loss: 0.378570, acc.: 89.84%] [G loss: 1.601782]\n",
      "epoch:29 step:27538 [D loss: 0.166596, acc.: 99.22%] [G loss: 1.534461]\n",
      "epoch:29 step:27539 [D loss: 0.144772, acc.: 97.66%] [G loss: 1.745414]\n",
      "epoch:29 step:27540 [D loss: 0.153050, acc.: 97.66%] [G loss: 1.805173]\n",
      "epoch:29 step:27541 [D loss: 0.463957, acc.: 78.12%] [G loss: 1.580961]\n",
      "epoch:29 step:27542 [D loss: 0.312915, acc.: 94.53%] [G loss: 1.800210]\n",
      "epoch:29 step:27543 [D loss: 0.291845, acc.: 96.09%] [G loss: 1.317901]\n",
      "epoch:29 step:27544 [D loss: 0.251115, acc.: 96.88%] [G loss: 1.512493]\n",
      "epoch:29 step:27545 [D loss: 0.755131, acc.: 56.25%] [G loss: 1.526988]\n",
      "epoch:29 step:27546 [D loss: 0.470203, acc.: 75.00%] [G loss: 1.218328]\n",
      "epoch:29 step:27547 [D loss: 0.730897, acc.: 53.12%] [G loss: 1.328703]\n",
      "epoch:29 step:27548 [D loss: 0.237849, acc.: 98.44%] [G loss: 0.956922]\n",
      "epoch:29 step:27549 [D loss: 0.429054, acc.: 85.16%] [G loss: 1.279064]\n",
      "epoch:29 step:27550 [D loss: 0.206826, acc.: 94.53%] [G loss: 1.348229]\n",
      "epoch:29 step:27551 [D loss: 0.168380, acc.: 98.44%] [G loss: 1.328800]\n",
      "epoch:29 step:27552 [D loss: 0.660032, acc.: 58.59%] [G loss: 1.400378]\n",
      "epoch:29 step:27553 [D loss: 0.707660, acc.: 60.16%] [G loss: 1.176743]\n",
      "epoch:29 step:27554 [D loss: 0.429639, acc.: 86.72%] [G loss: 1.042205]\n",
      "epoch:29 step:27555 [D loss: 0.672615, acc.: 60.16%] [G loss: 1.382036]\n",
      "epoch:29 step:27556 [D loss: 0.497902, acc.: 82.03%] [G loss: 1.108808]\n",
      "epoch:29 step:27557 [D loss: 0.241445, acc.: 94.53%] [G loss: 0.774719]\n",
      "epoch:29 step:27558 [D loss: 0.457768, acc.: 89.06%] [G loss: 0.770212]\n",
      "epoch:29 step:27559 [D loss: 0.535953, acc.: 72.66%] [G loss: 1.087785]\n",
      "epoch:29 step:27560 [D loss: 0.409404, acc.: 85.94%] [G loss: 0.985453]\n",
      "epoch:29 step:27561 [D loss: 0.386870, acc.: 92.97%] [G loss: 1.509740]\n",
      "epoch:29 step:27562 [D loss: 0.278825, acc.: 89.06%] [G loss: 0.730556]\n",
      "epoch:29 step:27563 [D loss: 0.343181, acc.: 79.69%] [G loss: 1.525425]\n",
      "epoch:29 step:27564 [D loss: 0.402304, acc.: 92.19%] [G loss: 1.827170]\n",
      "epoch:29 step:27565 [D loss: 0.154889, acc.: 99.22%] [G loss: 1.385941]\n",
      "epoch:29 step:27566 [D loss: 0.285201, acc.: 83.59%] [G loss: 1.861038]\n",
      "epoch:29 step:27567 [D loss: 0.292927, acc.: 93.75%] [G loss: 1.387718]\n",
      "epoch:29 step:27568 [D loss: 0.839122, acc.: 39.84%] [G loss: 1.571200]\n",
      "epoch:29 step:27569 [D loss: 0.164664, acc.: 97.66%] [G loss: 0.023842]\n",
      "epoch:29 step:27570 [D loss: 0.172496, acc.: 98.44%] [G loss: 1.677775]\n",
      "epoch:29 step:27571 [D loss: 0.093954, acc.: 100.00%] [G loss: 0.765954]\n",
      "epoch:29 step:27572 [D loss: 0.069981, acc.: 100.00%] [G loss: 2.105470]\n",
      "epoch:29 step:27573 [D loss: 0.060440, acc.: 100.00%] [G loss: 2.302851]\n",
      "epoch:29 step:27574 [D loss: 0.137911, acc.: 98.44%] [G loss: 2.235872]\n",
      "epoch:29 step:27575 [D loss: 0.066927, acc.: 100.00%] [G loss: 0.864846]\n",
      "epoch:29 step:27576 [D loss: 0.140812, acc.: 99.22%] [G loss: 2.300585]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27577 [D loss: 0.226259, acc.: 92.19%] [G loss: 2.701303]\n",
      "epoch:29 step:27578 [D loss: 0.039498, acc.: 100.00%] [G loss: 1.354953]\n",
      "epoch:29 step:27579 [D loss: 0.797829, acc.: 55.47%] [G loss: 3.099097]\n",
      "epoch:29 step:27580 [D loss: 0.210367, acc.: 91.41%] [G loss: 3.176332]\n",
      "epoch:29 step:27581 [D loss: 0.106726, acc.: 99.22%] [G loss: 3.158405]\n",
      "epoch:29 step:27582 [D loss: 0.034484, acc.: 100.00%] [G loss: 3.686164]\n",
      "epoch:29 step:27583 [D loss: 0.396419, acc.: 78.91%] [G loss: 3.383944]\n",
      "epoch:29 step:27584 [D loss: 1.072544, acc.: 51.56%] [G loss: 1.837684]\n",
      "epoch:29 step:27585 [D loss: 0.163402, acc.: 96.88%] [G loss: 1.022491]\n",
      "epoch:29 step:27586 [D loss: 0.291812, acc.: 84.38%] [G loss: 2.705895]\n",
      "epoch:29 step:27587 [D loss: 0.054435, acc.: 100.00%] [G loss: 2.895245]\n",
      "epoch:29 step:27588 [D loss: 0.116972, acc.: 100.00%] [G loss: 1.523711]\n",
      "epoch:29 step:27589 [D loss: 0.161605, acc.: 98.44%] [G loss: 2.296528]\n",
      "epoch:29 step:27590 [D loss: 0.071706, acc.: 99.22%] [G loss: 2.773578]\n",
      "epoch:29 step:27591 [D loss: 0.348484, acc.: 78.12%] [G loss: 2.085595]\n",
      "epoch:29 step:27592 [D loss: 0.183858, acc.: 96.09%] [G loss: 3.049107]\n",
      "epoch:29 step:27593 [D loss: 0.077881, acc.: 100.00%] [G loss: 1.018513]\n",
      "epoch:29 step:27594 [D loss: 1.012225, acc.: 46.09%] [G loss: 1.940471]\n",
      "epoch:29 step:27595 [D loss: 1.778544, acc.: 7.03%] [G loss: 1.216897]\n",
      "epoch:29 step:27596 [D loss: 0.963756, acc.: 34.38%] [G loss: 1.671842]\n",
      "epoch:29 step:27597 [D loss: 0.315895, acc.: 83.59%] [G loss: 1.896500]\n",
      "epoch:29 step:27598 [D loss: 1.277697, acc.: 50.78%] [G loss: 1.648119]\n",
      "epoch:29 step:27599 [D loss: 1.390470, acc.: 45.31%] [G loss: 2.758141]\n",
      "epoch:29 step:27600 [D loss: 0.748002, acc.: 57.03%] [G loss: 2.123213]\n",
      "##############\n",
      "[4.27390476 3.0628336  7.07453255 5.92562821 5.18566258 6.62072377\n",
      " 5.85390721 6.14253621 6.15871247 5.30647876]\n",
      "##########\n",
      "epoch:29 step:27601 [D loss: 0.630454, acc.: 67.97%] [G loss: 1.987693]\n",
      "epoch:29 step:27602 [D loss: 0.635549, acc.: 61.72%] [G loss: 2.315455]\n",
      "epoch:29 step:27603 [D loss: 0.310853, acc.: 89.84%] [G loss: 1.327789]\n",
      "epoch:29 step:27604 [D loss: 1.297727, acc.: 31.25%] [G loss: 1.599140]\n",
      "epoch:29 step:27605 [D loss: 1.230101, acc.: 41.41%] [G loss: 1.491059]\n",
      "epoch:29 step:27606 [D loss: 1.247027, acc.: 33.59%] [G loss: 1.746192]\n",
      "epoch:29 step:27607 [D loss: 0.965092, acc.: 51.56%] [G loss: 1.667755]\n",
      "epoch:29 step:27608 [D loss: 0.890262, acc.: 52.34%] [G loss: 1.717052]\n",
      "epoch:29 step:27609 [D loss: 0.787230, acc.: 56.25%] [G loss: 1.151883]\n",
      "epoch:29 step:27610 [D loss: 0.996080, acc.: 36.72%] [G loss: 1.223584]\n",
      "epoch:29 step:27611 [D loss: 0.774390, acc.: 53.12%] [G loss: 1.448124]\n",
      "epoch:29 step:27612 [D loss: 0.838468, acc.: 41.41%] [G loss: 1.297562]\n",
      "epoch:29 step:27613 [D loss: 0.666482, acc.: 55.47%] [G loss: 1.071011]\n",
      "epoch:29 step:27614 [D loss: 0.797772, acc.: 40.62%] [G loss: 1.080619]\n",
      "epoch:29 step:27615 [D loss: 0.713906, acc.: 50.78%] [G loss: 1.286449]\n",
      "epoch:29 step:27616 [D loss: 0.623869, acc.: 57.03%] [G loss: 1.319650]\n",
      "epoch:29 step:27617 [D loss: 0.647703, acc.: 55.47%] [G loss: 1.134557]\n",
      "epoch:29 step:27618 [D loss: 0.672008, acc.: 60.94%] [G loss: 1.141294]\n",
      "epoch:29 step:27619 [D loss: 0.640373, acc.: 57.81%] [G loss: 1.107260]\n",
      "epoch:29 step:27620 [D loss: 0.639067, acc.: 63.28%] [G loss: 1.018191]\n",
      "epoch:29 step:27621 [D loss: 0.451745, acc.: 90.62%] [G loss: 1.228145]\n",
      "epoch:29 step:27622 [D loss: 0.373511, acc.: 96.09%] [G loss: 1.284089]\n",
      "epoch:29 step:27623 [D loss: 0.458112, acc.: 83.59%] [G loss: 1.332460]\n",
      "epoch:29 step:27624 [D loss: 0.230148, acc.: 98.44%] [G loss: 1.444215]\n",
      "epoch:29 step:27625 [D loss: 0.250576, acc.: 95.31%] [G loss: 1.768517]\n",
      "epoch:29 step:27626 [D loss: 0.221259, acc.: 98.44%] [G loss: 1.694507]\n",
      "epoch:29 step:27627 [D loss: 0.252114, acc.: 100.00%] [G loss: 1.761941]\n",
      "epoch:29 step:27628 [D loss: 0.351512, acc.: 95.31%] [G loss: 1.890478]\n",
      "epoch:29 step:27629 [D loss: 0.130713, acc.: 99.22%] [G loss: 1.928924]\n",
      "epoch:29 step:27630 [D loss: 0.195509, acc.: 100.00%] [G loss: 2.097612]\n",
      "epoch:29 step:27631 [D loss: 0.431581, acc.: 79.69%] [G loss: 2.029430]\n",
      "epoch:29 step:27632 [D loss: 0.475238, acc.: 77.34%] [G loss: 1.613580]\n",
      "epoch:29 step:27633 [D loss: 0.598067, acc.: 64.84%] [G loss: 1.477995]\n",
      "epoch:29 step:27634 [D loss: 0.643132, acc.: 70.31%] [G loss: 1.102946]\n",
      "epoch:29 step:27635 [D loss: 0.733502, acc.: 57.81%] [G loss: 1.263601]\n",
      "epoch:29 step:27636 [D loss: 0.563300, acc.: 72.66%] [G loss: 1.184210]\n",
      "epoch:29 step:27637 [D loss: 0.319364, acc.: 93.75%] [G loss: 1.067227]\n",
      "epoch:29 step:27638 [D loss: 0.322580, acc.: 92.97%] [G loss: 1.399072]\n",
      "epoch:29 step:27639 [D loss: 0.275769, acc.: 95.31%] [G loss: 1.823594]\n",
      "epoch:29 step:27640 [D loss: 0.271470, acc.: 96.09%] [G loss: 1.870712]\n",
      "epoch:29 step:27641 [D loss: 0.176295, acc.: 98.44%] [G loss: 1.925352]\n",
      "epoch:29 step:27642 [D loss: 0.120727, acc.: 98.44%] [G loss: 2.094428]\n",
      "epoch:29 step:27643 [D loss: 0.145659, acc.: 96.09%] [G loss: 1.892846]\n",
      "epoch:29 step:27644 [D loss: 0.109416, acc.: 99.22%] [G loss: 1.843165]\n",
      "epoch:29 step:27645 [D loss: 0.138223, acc.: 98.44%] [G loss: 2.017207]\n",
      "epoch:29 step:27646 [D loss: 1.371720, acc.: 45.31%] [G loss: 1.008205]\n",
      "epoch:29 step:27647 [D loss: 1.031070, acc.: 37.50%] [G loss: 1.005677]\n",
      "epoch:29 step:27648 [D loss: 0.733097, acc.: 49.22%] [G loss: 1.090603]\n",
      "epoch:29 step:27649 [D loss: 0.638024, acc.: 62.50%] [G loss: 1.150621]\n",
      "epoch:29 step:27650 [D loss: 0.331799, acc.: 89.06%] [G loss: 1.414064]\n",
      "epoch:29 step:27651 [D loss: 0.442092, acc.: 84.38%] [G loss: 0.833917]\n",
      "epoch:29 step:27652 [D loss: 0.267553, acc.: 88.28%] [G loss: 1.393461]\n",
      "epoch:29 step:27653 [D loss: 0.334560, acc.: 85.94%] [G loss: 1.338145]\n",
      "epoch:29 step:27654 [D loss: 0.156846, acc.: 98.44%] [G loss: 1.854989]\n",
      "epoch:29 step:27655 [D loss: 1.090442, acc.: 50.78%] [G loss: 0.996378]\n",
      "epoch:29 step:27656 [D loss: 0.873361, acc.: 45.31%] [G loss: 1.431663]\n",
      "epoch:29 step:27657 [D loss: 0.829343, acc.: 50.00%] [G loss: 1.095239]\n",
      "epoch:29 step:27658 [D loss: 0.697679, acc.: 56.25%] [G loss: 0.593409]\n",
      "epoch:29 step:27659 [D loss: 0.782620, acc.: 46.88%] [G loss: 0.995216]\n",
      "epoch:29 step:27660 [D loss: 0.719551, acc.: 48.44%] [G loss: 1.060103]\n",
      "epoch:29 step:27661 [D loss: 0.837572, acc.: 46.09%] [G loss: 1.064430]\n",
      "epoch:29 step:27662 [D loss: 0.267408, acc.: 93.75%] [G loss: 1.155506]\n",
      "epoch:29 step:27663 [D loss: 0.229077, acc.: 96.88%] [G loss: 1.331039]\n",
      "epoch:29 step:27664 [D loss: 0.282345, acc.: 94.53%] [G loss: 1.061405]\n",
      "epoch:29 step:27665 [D loss: 0.658009, acc.: 64.84%] [G loss: 1.148035]\n",
      "epoch:29 step:27666 [D loss: 0.673950, acc.: 58.59%] [G loss: 0.979848]\n",
      "epoch:29 step:27667 [D loss: 0.451297, acc.: 85.16%] [G loss: 0.861680]\n",
      "epoch:29 step:27668 [D loss: 0.398761, acc.: 96.09%] [G loss: 1.196818]\n",
      "epoch:29 step:27669 [D loss: 0.866242, acc.: 39.06%] [G loss: 0.745434]\n",
      "epoch:29 step:27670 [D loss: 0.621125, acc.: 62.50%] [G loss: 0.979008]\n",
      "epoch:29 step:27671 [D loss: 0.566905, acc.: 71.88%] [G loss: 1.049042]\n",
      "epoch:29 step:27672 [D loss: 0.405832, acc.: 85.94%] [G loss: 1.420354]\n",
      "epoch:29 step:27673 [D loss: 0.713731, acc.: 55.47%] [G loss: 0.962736]\n",
      "epoch:29 step:27674 [D loss: 0.634794, acc.: 63.28%] [G loss: 1.234478]\n",
      "epoch:29 step:27675 [D loss: 0.564837, acc.: 71.88%] [G loss: 1.428068]\n",
      "epoch:29 step:27676 [D loss: 0.234947, acc.: 92.97%] [G loss: 1.239177]\n",
      "epoch:29 step:27677 [D loss: 0.184127, acc.: 96.88%] [G loss: 1.329938]\n",
      "epoch:29 step:27678 [D loss: 0.259682, acc.: 89.06%] [G loss: 1.539228]\n",
      "epoch:29 step:27679 [D loss: 0.734592, acc.: 58.59%] [G loss: 1.033848]\n",
      "epoch:29 step:27680 [D loss: 0.282094, acc.: 96.09%] [G loss: 1.466926]\n",
      "epoch:29 step:27681 [D loss: 0.400261, acc.: 82.81%] [G loss: 1.723717]\n",
      "epoch:29 step:27682 [D loss: 0.587688, acc.: 68.75%] [G loss: 1.709932]\n",
      "epoch:29 step:27683 [D loss: 0.882938, acc.: 43.75%] [G loss: 1.217955]\n",
      "epoch:29 step:27684 [D loss: 0.330656, acc.: 89.06%] [G loss: 1.717477]\n",
      "epoch:29 step:27685 [D loss: 0.502751, acc.: 72.66%] [G loss: 1.499334]\n",
      "epoch:29 step:27686 [D loss: 0.349711, acc.: 92.19%] [G loss: 1.827758]\n",
      "epoch:29 step:27687 [D loss: 0.360094, acc.: 88.28%] [G loss: 1.439587]\n",
      "epoch:29 step:27688 [D loss: 0.219793, acc.: 98.44%] [G loss: 2.008771]\n",
      "epoch:29 step:27689 [D loss: 0.669276, acc.: 57.03%] [G loss: 1.527926]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27690 [D loss: 0.381427, acc.: 82.81%] [G loss: 1.216360]\n",
      "epoch:29 step:27691 [D loss: 0.555718, acc.: 72.66%] [G loss: 1.550380]\n",
      "epoch:29 step:27692 [D loss: 0.611526, acc.: 68.75%] [G loss: 1.485785]\n",
      "epoch:29 step:27693 [D loss: 0.444327, acc.: 85.16%] [G loss: 1.393849]\n",
      "epoch:29 step:27694 [D loss: 0.597832, acc.: 66.41%] [G loss: 0.984916]\n",
      "epoch:29 step:27695 [D loss: 0.583227, acc.: 71.88%] [G loss: 1.148434]\n",
      "epoch:29 step:27696 [D loss: 0.581541, acc.: 69.53%] [G loss: 1.209403]\n",
      "epoch:29 step:27697 [D loss: 0.273022, acc.: 93.75%] [G loss: 1.195002]\n",
      "epoch:29 step:27698 [D loss: 0.676652, acc.: 60.16%] [G loss: 1.480438]\n",
      "epoch:29 step:27699 [D loss: 0.445345, acc.: 87.50%] [G loss: 1.525149]\n",
      "epoch:29 step:27700 [D loss: 0.390325, acc.: 87.50%] [G loss: 1.571841]\n",
      "epoch:29 step:27701 [D loss: 0.501242, acc.: 80.47%] [G loss: 1.232576]\n",
      "epoch:29 step:27702 [D loss: 0.434090, acc.: 84.38%] [G loss: 1.468566]\n",
      "epoch:29 step:27703 [D loss: 0.399190, acc.: 80.47%] [G loss: 1.521553]\n",
      "epoch:29 step:27704 [D loss: 0.656393, acc.: 58.59%] [G loss: 1.354211]\n",
      "epoch:29 step:27705 [D loss: 0.665248, acc.: 60.94%] [G loss: 1.375178]\n",
      "epoch:29 step:27706 [D loss: 0.368722, acc.: 83.59%] [G loss: 1.492113]\n",
      "epoch:29 step:27707 [D loss: 0.420370, acc.: 86.72%] [G loss: 1.627585]\n",
      "epoch:29 step:27708 [D loss: 0.284166, acc.: 92.19%] [G loss: 1.591637]\n",
      "epoch:29 step:27709 [D loss: 0.177652, acc.: 98.44%] [G loss: 1.663446]\n",
      "epoch:29 step:27710 [D loss: 0.231378, acc.: 98.44%] [G loss: 1.413934]\n",
      "epoch:29 step:27711 [D loss: 0.476754, acc.: 81.25%] [G loss: 2.131526]\n",
      "epoch:29 step:27712 [D loss: 0.193598, acc.: 96.88%] [G loss: 1.894984]\n",
      "epoch:29 step:27713 [D loss: 0.401393, acc.: 85.94%] [G loss: 1.493835]\n",
      "epoch:29 step:27714 [D loss: 0.424427, acc.: 89.84%] [G loss: 1.400968]\n",
      "epoch:29 step:27715 [D loss: 0.436093, acc.: 84.38%] [G loss: 1.517516]\n",
      "epoch:29 step:27716 [D loss: 0.143996, acc.: 97.66%] [G loss: 1.426105]\n",
      "epoch:29 step:27717 [D loss: 0.548478, acc.: 71.88%] [G loss: 1.639714]\n",
      "epoch:29 step:27718 [D loss: 0.448109, acc.: 76.56%] [G loss: 0.928749]\n",
      "epoch:29 step:27719 [D loss: 0.542052, acc.: 71.09%] [G loss: 1.745444]\n",
      "epoch:29 step:27720 [D loss: 0.284557, acc.: 92.97%] [G loss: 1.696035]\n",
      "epoch:29 step:27721 [D loss: 0.276034, acc.: 91.41%] [G loss: 1.814375]\n",
      "epoch:29 step:27722 [D loss: 0.125041, acc.: 98.44%] [G loss: 1.785274]\n",
      "epoch:29 step:27723 [D loss: 0.128018, acc.: 97.66%] [G loss: 2.122644]\n",
      "epoch:29 step:27724 [D loss: 0.205116, acc.: 96.88%] [G loss: 1.881310]\n",
      "epoch:29 step:27725 [D loss: 0.194528, acc.: 98.44%] [G loss: 2.626108]\n",
      "epoch:29 step:27726 [D loss: 0.389002, acc.: 84.38%] [G loss: 2.286808]\n",
      "epoch:29 step:27727 [D loss: 0.115809, acc.: 99.22%] [G loss: 1.763603]\n",
      "epoch:29 step:27728 [D loss: 0.152811, acc.: 98.44%] [G loss: 2.213466]\n",
      "epoch:29 step:27729 [D loss: 0.083119, acc.: 99.22%] [G loss: 2.366149]\n",
      "epoch:29 step:27730 [D loss: 0.104263, acc.: 99.22%] [G loss: 2.297542]\n",
      "epoch:29 step:27731 [D loss: 0.133023, acc.: 99.22%] [G loss: 2.382131]\n",
      "epoch:29 step:27732 [D loss: 0.167081, acc.: 97.66%] [G loss: 2.147787]\n",
      "epoch:29 step:27733 [D loss: 0.531457, acc.: 73.44%] [G loss: 1.702593]\n",
      "epoch:29 step:27734 [D loss: 0.153856, acc.: 96.88%] [G loss: 1.941804]\n",
      "epoch:29 step:27735 [D loss: 0.845060, acc.: 53.91%] [G loss: 1.666806]\n",
      "epoch:29 step:27736 [D loss: 0.508508, acc.: 75.00%] [G loss: 1.794400]\n",
      "epoch:29 step:27737 [D loss: 0.714206, acc.: 60.16%] [G loss: 0.864744]\n",
      "epoch:29 step:27738 [D loss: 0.646494, acc.: 59.38%] [G loss: 0.895992]\n",
      "epoch:29 step:27739 [D loss: 0.208552, acc.: 94.53%] [G loss: 1.040836]\n",
      "epoch:29 step:27740 [D loss: 0.245077, acc.: 89.06%] [G loss: 0.853610]\n",
      "epoch:29 step:27741 [D loss: 0.705560, acc.: 57.81%] [G loss: 1.507497]\n",
      "epoch:29 step:27742 [D loss: 0.834240, acc.: 52.34%] [G loss: 1.130658]\n",
      "epoch:29 step:27743 [D loss: 0.778317, acc.: 46.88%] [G loss: 1.421036]\n",
      "epoch:29 step:27744 [D loss: 0.638982, acc.: 62.50%] [G loss: 1.079709]\n",
      "epoch:29 step:27745 [D loss: 0.628688, acc.: 64.84%] [G loss: 1.338349]\n",
      "epoch:29 step:27746 [D loss: 0.606099, acc.: 69.53%] [G loss: 1.396551]\n",
      "epoch:29 step:27747 [D loss: 0.617787, acc.: 71.88%] [G loss: 1.630857]\n",
      "epoch:29 step:27748 [D loss: 0.685450, acc.: 60.16%] [G loss: 1.629807]\n",
      "epoch:29 step:27749 [D loss: 0.364616, acc.: 81.25%] [G loss: 1.463310]\n",
      "epoch:29 step:27750 [D loss: 0.293923, acc.: 89.84%] [G loss: 1.911353]\n",
      "epoch:29 step:27751 [D loss: 0.255723, acc.: 89.84%] [G loss: 1.738835]\n",
      "epoch:29 step:27752 [D loss: 0.253667, acc.: 96.09%] [G loss: 1.779821]\n",
      "epoch:29 step:27753 [D loss: 0.786390, acc.: 53.91%] [G loss: 1.589335]\n",
      "epoch:29 step:27754 [D loss: 0.686109, acc.: 57.03%] [G loss: 1.512956]\n",
      "epoch:29 step:27755 [D loss: 0.642382, acc.: 64.84%] [G loss: 0.797800]\n",
      "epoch:29 step:27756 [D loss: 0.501919, acc.: 77.34%] [G loss: 1.150210]\n",
      "epoch:29 step:27757 [D loss: 0.634496, acc.: 63.28%] [G loss: 1.033258]\n",
      "epoch:29 step:27758 [D loss: 0.480013, acc.: 78.12%] [G loss: 1.071762]\n",
      "epoch:29 step:27759 [D loss: 0.580043, acc.: 70.31%] [G loss: 1.124949]\n",
      "epoch:29 step:27760 [D loss: 0.365292, acc.: 81.25%] [G loss: 1.349607]\n",
      "epoch:29 step:27761 [D loss: 0.185017, acc.: 96.09%] [G loss: 1.688140]\n",
      "epoch:29 step:27762 [D loss: 0.204760, acc.: 94.53%] [G loss: 1.709932]\n",
      "epoch:29 step:27763 [D loss: 0.537856, acc.: 75.78%] [G loss: 1.137986]\n",
      "epoch:29 step:27764 [D loss: 0.455203, acc.: 84.38%] [G loss: 1.718064]\n",
      "epoch:29 step:27765 [D loss: 0.224889, acc.: 95.31%] [G loss: 1.843933]\n",
      "epoch:29 step:27766 [D loss: 0.903963, acc.: 46.09%] [G loss: 1.732469]\n",
      "epoch:29 step:27767 [D loss: 0.400117, acc.: 87.50%] [G loss: 1.619782]\n",
      "epoch:29 step:27768 [D loss: 0.168130, acc.: 97.66%] [G loss: 1.746008]\n",
      "epoch:29 step:27769 [D loss: 0.625436, acc.: 67.97%] [G loss: 0.832802]\n",
      "epoch:29 step:27770 [D loss: 0.821859, acc.: 49.22%] [G loss: 0.670435]\n",
      "epoch:29 step:27771 [D loss: 0.377982, acc.: 87.50%] [G loss: 1.391856]\n",
      "epoch:29 step:27772 [D loss: 0.487903, acc.: 72.66%] [G loss: 1.491757]\n",
      "epoch:29 step:27773 [D loss: 0.276751, acc.: 87.50%] [G loss: 1.482957]\n",
      "epoch:29 step:27774 [D loss: 0.190705, acc.: 93.75%] [G loss: 1.253444]\n",
      "epoch:29 step:27775 [D loss: 0.156748, acc.: 99.22%] [G loss: 1.663222]\n",
      "epoch:29 step:27776 [D loss: 0.462215, acc.: 78.91%] [G loss: 1.490028]\n",
      "epoch:29 step:27777 [D loss: 0.179437, acc.: 93.75%] [G loss: 1.079740]\n",
      "epoch:29 step:27778 [D loss: 0.564905, acc.: 67.19%] [G loss: 2.117189]\n",
      "epoch:29 step:27779 [D loss: 0.550890, acc.: 73.44%] [G loss: 1.563165]\n",
      "epoch:29 step:27780 [D loss: 0.375943, acc.: 86.72%] [G loss: 1.386229]\n",
      "epoch:29 step:27781 [D loss: 0.338482, acc.: 84.38%] [G loss: 1.652273]\n",
      "epoch:29 step:27782 [D loss: 0.126055, acc.: 99.22%] [G loss: 1.037774]\n",
      "epoch:29 step:27783 [D loss: 1.142141, acc.: 28.12%] [G loss: 1.916776]\n",
      "epoch:29 step:27784 [D loss: 0.322622, acc.: 89.84%] [G loss: 1.878557]\n",
      "epoch:29 step:27785 [D loss: 0.421446, acc.: 81.25%] [G loss: 0.895960]\n",
      "epoch:29 step:27786 [D loss: 0.544854, acc.: 67.97%] [G loss: 1.114872]\n",
      "epoch:29 step:27787 [D loss: 0.778935, acc.: 54.69%] [G loss: 1.574149]\n",
      "epoch:29 step:27788 [D loss: 0.649004, acc.: 64.84%] [G loss: 1.430748]\n",
      "epoch:29 step:27789 [D loss: 0.320555, acc.: 90.62%] [G loss: 1.195005]\n",
      "epoch:29 step:27790 [D loss: 0.231106, acc.: 94.53%] [G loss: 1.447803]\n",
      "epoch:29 step:27791 [D loss: 0.390479, acc.: 83.59%] [G loss: 1.712267]\n",
      "epoch:29 step:27792 [D loss: 0.358177, acc.: 88.28%] [G loss: 1.810949]\n",
      "epoch:29 step:27793 [D loss: 0.375399, acc.: 89.06%] [G loss: 1.695169]\n",
      "epoch:29 step:27794 [D loss: 0.605391, acc.: 65.62%] [G loss: 1.501085]\n",
      "epoch:29 step:27795 [D loss: 0.324715, acc.: 91.41%] [G loss: 0.811625]\n",
      "epoch:29 step:27796 [D loss: 0.636323, acc.: 63.28%] [G loss: 1.533848]\n",
      "epoch:29 step:27797 [D loss: 0.217536, acc.: 95.31%] [G loss: 1.890288]\n",
      "epoch:29 step:27798 [D loss: 0.423007, acc.: 79.69%] [G loss: 1.708109]\n",
      "epoch:29 step:27799 [D loss: 0.707515, acc.: 62.50%] [G loss: 1.621235]\n",
      "epoch:29 step:27800 [D loss: 0.425835, acc.: 82.03%] [G loss: 1.693335]\n",
      "##############\n",
      "[4.101822   2.12148084 6.82606756 5.75297234 4.59876468 5.93138345\n",
      " 5.31091847 5.20618815 5.79086842 4.93691448]\n",
      "##########\n",
      "epoch:29 step:27801 [D loss: 0.624826, acc.: 63.28%] [G loss: 1.355290]\n",
      "epoch:29 step:27802 [D loss: 0.459423, acc.: 82.81%] [G loss: 0.835840]\n",
      "epoch:29 step:27803 [D loss: 0.516354, acc.: 77.34%] [G loss: 1.175978]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27804 [D loss: 0.606045, acc.: 65.62%] [G loss: 0.934630]\n",
      "epoch:29 step:27805 [D loss: 0.400810, acc.: 78.91%] [G loss: 1.209384]\n",
      "epoch:29 step:27806 [D loss: 0.189932, acc.: 95.31%] [G loss: 1.689720]\n",
      "epoch:29 step:27807 [D loss: 0.273032, acc.: 93.75%] [G loss: 1.616303]\n",
      "epoch:29 step:27808 [D loss: 0.159380, acc.: 99.22%] [G loss: 2.388522]\n",
      "epoch:29 step:27809 [D loss: 0.791008, acc.: 53.12%] [G loss: 1.562628]\n",
      "epoch:29 step:27810 [D loss: 0.609621, acc.: 63.28%] [G loss: 1.791037]\n",
      "epoch:29 step:27811 [D loss: 0.771598, acc.: 49.22%] [G loss: 1.634838]\n",
      "epoch:29 step:27812 [D loss: 0.792376, acc.: 55.47%] [G loss: 0.462559]\n",
      "epoch:29 step:27813 [D loss: 0.736904, acc.: 54.69%] [G loss: 1.478487]\n",
      "epoch:29 step:27814 [D loss: 0.314106, acc.: 82.03%] [G loss: 2.144861]\n",
      "epoch:29 step:27815 [D loss: 1.047469, acc.: 39.84%] [G loss: 0.945944]\n",
      "epoch:29 step:27816 [D loss: 0.398343, acc.: 89.84%] [G loss: 1.387189]\n",
      "epoch:29 step:27817 [D loss: 0.144595, acc.: 96.88%] [G loss: 1.736725]\n",
      "epoch:29 step:27818 [D loss: 0.160432, acc.: 96.88%] [G loss: 1.370328]\n",
      "epoch:29 step:27819 [D loss: 0.203121, acc.: 92.97%] [G loss: 1.726686]\n",
      "epoch:29 step:27820 [D loss: 0.214809, acc.: 92.97%] [G loss: 1.768464]\n",
      "epoch:29 step:27821 [D loss: 0.103993, acc.: 100.00%] [G loss: 1.721484]\n",
      "epoch:29 step:27822 [D loss: 0.309464, acc.: 85.94%] [G loss: 1.794233]\n",
      "epoch:29 step:27823 [D loss: 0.065690, acc.: 100.00%] [G loss: 2.758108]\n",
      "epoch:29 step:27824 [D loss: 0.314182, acc.: 90.62%] [G loss: 2.505072]\n",
      "epoch:29 step:27825 [D loss: 0.713314, acc.: 64.84%] [G loss: 2.128235]\n",
      "epoch:29 step:27826 [D loss: 0.804786, acc.: 50.78%] [G loss: 1.505097]\n",
      "epoch:29 step:27827 [D loss: 0.772557, acc.: 56.25%] [G loss: 0.805613]\n",
      "epoch:29 step:27828 [D loss: 0.733978, acc.: 59.38%] [G loss: 1.653855]\n",
      "epoch:29 step:27829 [D loss: 0.672763, acc.: 64.06%] [G loss: 1.668151]\n",
      "epoch:29 step:27830 [D loss: 0.725624, acc.: 56.25%] [G loss: 1.514017]\n",
      "epoch:29 step:27831 [D loss: 0.750308, acc.: 53.91%] [G loss: 0.828547]\n",
      "epoch:29 step:27832 [D loss: 0.312566, acc.: 85.16%] [G loss: 1.142662]\n",
      "epoch:29 step:27833 [D loss: 0.176941, acc.: 96.09%] [G loss: 1.744470]\n",
      "epoch:29 step:27834 [D loss: 0.392031, acc.: 81.25%] [G loss: 0.769349]\n",
      "epoch:29 step:27835 [D loss: 0.606600, acc.: 64.06%] [G loss: 2.100871]\n",
      "epoch:29 step:27836 [D loss: 0.671438, acc.: 58.59%] [G loss: 2.310990]\n",
      "epoch:29 step:27837 [D loss: 0.084401, acc.: 100.00%] [G loss: 2.462924]\n",
      "epoch:29 step:27838 [D loss: 0.078521, acc.: 100.00%] [G loss: 1.983564]\n",
      "epoch:29 step:27839 [D loss: 0.848179, acc.: 55.47%] [G loss: 1.516979]\n",
      "epoch:29 step:27840 [D loss: 0.540424, acc.: 69.53%] [G loss: 1.794987]\n",
      "epoch:29 step:27841 [D loss: 0.792060, acc.: 56.25%] [G loss: 1.769231]\n",
      "epoch:29 step:27842 [D loss: 0.668487, acc.: 60.94%] [G loss: 1.303273]\n",
      "epoch:29 step:27843 [D loss: 0.855406, acc.: 42.19%] [G loss: 1.681769]\n",
      "epoch:29 step:27844 [D loss: 0.300556, acc.: 96.88%] [G loss: 1.295979]\n",
      "epoch:29 step:27845 [D loss: 0.559118, acc.: 74.22%] [G loss: 1.426746]\n",
      "epoch:29 step:27846 [D loss: 0.428322, acc.: 82.81%] [G loss: 1.512533]\n",
      "epoch:29 step:27847 [D loss: 0.276409, acc.: 96.88%] [G loss: 0.948127]\n",
      "epoch:29 step:27848 [D loss: 0.793793, acc.: 46.09%] [G loss: 1.105525]\n",
      "epoch:29 step:27849 [D loss: 0.536768, acc.: 77.34%] [G loss: 1.292620]\n",
      "epoch:29 step:27850 [D loss: 0.673147, acc.: 55.47%] [G loss: 1.143859]\n",
      "epoch:29 step:27851 [D loss: 0.777523, acc.: 50.78%] [G loss: 0.720286]\n",
      "epoch:29 step:27852 [D loss: 0.640569, acc.: 60.94%] [G loss: 1.150096]\n",
      "epoch:29 step:27853 [D loss: 0.619534, acc.: 64.84%] [G loss: 0.951342]\n",
      "epoch:29 step:27854 [D loss: 0.515232, acc.: 76.56%] [G loss: 1.032772]\n",
      "epoch:29 step:27855 [D loss: 0.431050, acc.: 83.59%] [G loss: 1.072925]\n",
      "epoch:29 step:27856 [D loss: 0.542473, acc.: 75.00%] [G loss: 1.039410]\n",
      "epoch:29 step:27857 [D loss: 0.442521, acc.: 79.69%] [G loss: 1.124794]\n",
      "epoch:29 step:27858 [D loss: 0.474442, acc.: 81.25%] [G loss: 1.319418]\n",
      "epoch:29 step:27859 [D loss: 0.240626, acc.: 97.66%] [G loss: 1.677231]\n",
      "epoch:29 step:27860 [D loss: 0.222624, acc.: 94.53%] [G loss: 1.633356]\n",
      "epoch:29 step:27861 [D loss: 0.550125, acc.: 75.00%] [G loss: 1.697884]\n",
      "epoch:29 step:27862 [D loss: 0.609988, acc.: 70.31%] [G loss: 1.664031]\n",
      "epoch:29 step:27863 [D loss: 0.366083, acc.: 89.06%] [G loss: 1.266085]\n",
      "epoch:29 step:27864 [D loss: 0.411330, acc.: 87.50%] [G loss: 1.963614]\n",
      "epoch:29 step:27865 [D loss: 0.344384, acc.: 88.28%] [G loss: 1.068718]\n",
      "epoch:29 step:27866 [D loss: 0.455316, acc.: 82.03%] [G loss: 1.467797]\n",
      "epoch:29 step:27867 [D loss: 0.180551, acc.: 98.44%] [G loss: 1.854927]\n",
      "epoch:29 step:27868 [D loss: 0.838603, acc.: 49.22%] [G loss: 1.649485]\n",
      "epoch:29 step:27869 [D loss: 0.167791, acc.: 98.44%] [G loss: 1.558899]\n",
      "epoch:29 step:27870 [D loss: 0.212125, acc.: 92.97%] [G loss: 1.615590]\n",
      "epoch:29 step:27871 [D loss: 0.151126, acc.: 98.44%] [G loss: 1.163755]\n",
      "epoch:29 step:27872 [D loss: 0.188242, acc.: 98.44%] [G loss: 1.476626]\n",
      "epoch:29 step:27873 [D loss: 0.114552, acc.: 99.22%] [G loss: 1.815088]\n",
      "epoch:29 step:27874 [D loss: 0.092189, acc.: 100.00%] [G loss: 1.848266]\n",
      "epoch:29 step:27875 [D loss: 0.121013, acc.: 100.00%] [G loss: 2.272486]\n",
      "epoch:29 step:27876 [D loss: 0.525032, acc.: 74.22%] [G loss: 0.766226]\n",
      "epoch:29 step:27877 [D loss: 0.186967, acc.: 99.22%] [G loss: 1.279370]\n",
      "epoch:29 step:27878 [D loss: 0.979405, acc.: 32.81%] [G loss: 1.781189]\n",
      "epoch:29 step:27879 [D loss: 0.169744, acc.: 98.44%] [G loss: 1.529485]\n",
      "epoch:29 step:27880 [D loss: 0.121927, acc.: 100.00%] [G loss: 2.073602]\n",
      "epoch:29 step:27881 [D loss: 0.180781, acc.: 97.66%] [G loss: 1.620930]\n",
      "epoch:29 step:27882 [D loss: 0.116777, acc.: 96.88%] [G loss: 1.940279]\n",
      "epoch:29 step:27883 [D loss: 0.218167, acc.: 96.88%] [G loss: 1.627107]\n",
      "epoch:29 step:27884 [D loss: 0.343175, acc.: 85.16%] [G loss: 1.316409]\n",
      "epoch:29 step:27885 [D loss: 1.621701, acc.: 7.03%] [G loss: 1.145734]\n",
      "epoch:29 step:27886 [D loss: 0.124146, acc.: 97.66%] [G loss: 1.604682]\n",
      "epoch:29 step:27887 [D loss: 0.414408, acc.: 75.00%] [G loss: 2.095880]\n",
      "epoch:29 step:27888 [D loss: 1.366685, acc.: 39.84%] [G loss: 1.244929]\n",
      "epoch:29 step:27889 [D loss: 1.128838, acc.: 42.19%] [G loss: 2.200405]\n",
      "epoch:29 step:27890 [D loss: 0.503373, acc.: 76.56%] [G loss: 2.014721]\n",
      "epoch:29 step:27891 [D loss: 0.523413, acc.: 76.56%] [G loss: 2.293777]\n",
      "epoch:29 step:27892 [D loss: 0.165353, acc.: 96.09%] [G loss: 2.630753]\n",
      "epoch:29 step:27893 [D loss: 0.107323, acc.: 98.44%] [G loss: 2.733186]\n",
      "epoch:29 step:27894 [D loss: 0.224527, acc.: 92.19%] [G loss: 2.080510]\n",
      "epoch:29 step:27895 [D loss: 1.166615, acc.: 47.66%] [G loss: 1.904943]\n",
      "epoch:29 step:27896 [D loss: 0.714965, acc.: 57.81%] [G loss: 1.707041]\n",
      "epoch:29 step:27897 [D loss: 0.123766, acc.: 97.66%] [G loss: 1.853802]\n",
      "epoch:29 step:27898 [D loss: 0.112394, acc.: 97.66%] [G loss: 1.793846]\n",
      "epoch:29 step:27899 [D loss: 0.131788, acc.: 96.88%] [G loss: 2.285080]\n",
      "epoch:29 step:27900 [D loss: 0.891363, acc.: 53.12%] [G loss: 1.320450]\n",
      "epoch:29 step:27901 [D loss: 0.505362, acc.: 75.00%] [G loss: 1.291446]\n",
      "epoch:29 step:27902 [D loss: 0.751463, acc.: 60.16%] [G loss: 1.246991]\n",
      "epoch:29 step:27903 [D loss: 0.424638, acc.: 82.03%] [G loss: 1.390439]\n",
      "epoch:29 step:27904 [D loss: 0.556549, acc.: 73.44%] [G loss: 0.809116]\n",
      "epoch:29 step:27905 [D loss: 0.682626, acc.: 56.25%] [G loss: 1.037278]\n",
      "epoch:29 step:27906 [D loss: 0.722238, acc.: 57.81%] [G loss: 0.955624]\n",
      "epoch:29 step:27907 [D loss: 0.907488, acc.: 34.38%] [G loss: 1.027978]\n",
      "epoch:29 step:27908 [D loss: 0.206096, acc.: 93.75%] [G loss: 1.928795]\n",
      "epoch:29 step:27909 [D loss: 0.136169, acc.: 98.44%] [G loss: 1.739151]\n",
      "epoch:29 step:27910 [D loss: 0.314899, acc.: 92.19%] [G loss: 2.148362]\n",
      "epoch:29 step:27911 [D loss: 0.712163, acc.: 60.16%] [G loss: 1.983090]\n",
      "epoch:29 step:27912 [D loss: 0.691725, acc.: 58.59%] [G loss: 1.688601]\n",
      "epoch:29 step:27913 [D loss: 0.484389, acc.: 82.03%] [G loss: 1.307295]\n",
      "epoch:29 step:27914 [D loss: 0.133349, acc.: 98.44%] [G loss: 1.955060]\n",
      "epoch:29 step:27915 [D loss: 0.121126, acc.: 99.22%] [G loss: 1.935905]\n",
      "epoch:29 step:27916 [D loss: 0.100959, acc.: 99.22%] [G loss: 2.113207]\n",
      "epoch:29 step:27917 [D loss: 0.100721, acc.: 99.22%] [G loss: 2.404722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27918 [D loss: 0.850279, acc.: 57.03%] [G loss: 2.028532]\n",
      "epoch:29 step:27919 [D loss: 0.657866, acc.: 60.16%] [G loss: 1.606085]\n",
      "epoch:29 step:27920 [D loss: 0.398292, acc.: 84.38%] [G loss: 1.736953]\n",
      "epoch:29 step:27921 [D loss: 0.173118, acc.: 99.22%] [G loss: 1.571135]\n",
      "epoch:29 step:27922 [D loss: 0.104684, acc.: 100.00%] [G loss: 2.105829]\n",
      "epoch:29 step:27923 [D loss: 0.157068, acc.: 96.88%] [G loss: 2.205333]\n",
      "epoch:29 step:27924 [D loss: 0.510658, acc.: 73.44%] [G loss: 2.255005]\n",
      "epoch:29 step:27925 [D loss: 0.672283, acc.: 58.59%] [G loss: 1.710766]\n",
      "epoch:29 step:27926 [D loss: 0.693092, acc.: 60.94%] [G loss: 1.752663]\n",
      "epoch:29 step:27927 [D loss: 0.896947, acc.: 45.31%] [G loss: 1.748425]\n",
      "epoch:29 step:27928 [D loss: 0.777373, acc.: 56.25%] [G loss: 1.637267]\n",
      "epoch:29 step:27929 [D loss: 0.677192, acc.: 61.72%] [G loss: 1.686040]\n",
      "epoch:29 step:27930 [D loss: 0.653899, acc.: 61.72%] [G loss: 1.434088]\n",
      "epoch:29 step:27931 [D loss: 0.327205, acc.: 90.62%] [G loss: 1.291191]\n",
      "epoch:29 step:27932 [D loss: 0.290845, acc.: 84.38%] [G loss: 1.654263]\n",
      "epoch:29 step:27933 [D loss: 0.145493, acc.: 98.44%] [G loss: 1.960492]\n",
      "epoch:29 step:27934 [D loss: 0.231036, acc.: 96.09%] [G loss: 2.049513]\n",
      "epoch:29 step:27935 [D loss: 1.050048, acc.: 49.22%] [G loss: 1.796803]\n",
      "epoch:29 step:27936 [D loss: 0.705661, acc.: 55.47%] [G loss: 1.289307]\n",
      "epoch:29 step:27937 [D loss: 0.849205, acc.: 46.88%] [G loss: 1.125555]\n",
      "epoch:29 step:27938 [D loss: 0.276191, acc.: 95.31%] [G loss: 1.715217]\n",
      "epoch:29 step:27939 [D loss: 0.344165, acc.: 90.62%] [G loss: 1.629277]\n",
      "epoch:29 step:27940 [D loss: 0.581052, acc.: 64.06%] [G loss: 1.529709]\n",
      "epoch:29 step:27941 [D loss: 0.162165, acc.: 96.88%] [G loss: 1.371800]\n",
      "epoch:29 step:27942 [D loss: 0.158180, acc.: 96.88%] [G loss: 1.773210]\n",
      "epoch:29 step:27943 [D loss: 0.200480, acc.: 97.66%] [G loss: 0.752194]\n",
      "epoch:29 step:27944 [D loss: 0.776149, acc.: 60.16%] [G loss: 1.228829]\n",
      "epoch:29 step:27945 [D loss: 0.806978, acc.: 48.44%] [G loss: 1.432821]\n",
      "epoch:29 step:27946 [D loss: 0.522056, acc.: 74.22%] [G loss: 0.743148]\n",
      "epoch:29 step:27947 [D loss: 0.624963, acc.: 58.59%] [G loss: 0.682621]\n",
      "epoch:29 step:27948 [D loss: 0.235930, acc.: 89.84%] [G loss: 1.042073]\n",
      "epoch:29 step:27949 [D loss: 0.339137, acc.: 86.72%] [G loss: 1.426327]\n",
      "epoch:29 step:27950 [D loss: 0.199409, acc.: 97.66%] [G loss: 0.517819]\n",
      "epoch:29 step:27951 [D loss: 1.136016, acc.: 44.53%] [G loss: 0.695527]\n",
      "epoch:29 step:27952 [D loss: 1.097160, acc.: 39.84%] [G loss: 0.592268]\n",
      "epoch:29 step:27953 [D loss: 0.495285, acc.: 72.66%] [G loss: 1.721263]\n",
      "epoch:29 step:27954 [D loss: 0.449878, acc.: 81.25%] [G loss: 0.962576]\n",
      "epoch:29 step:27955 [D loss: 0.434912, acc.: 74.22%] [G loss: 2.009827]\n",
      "epoch:29 step:27956 [D loss: 0.640534, acc.: 65.62%] [G loss: 2.098456]\n",
      "epoch:29 step:27957 [D loss: 0.664238, acc.: 62.50%] [G loss: 1.908363]\n",
      "epoch:29 step:27958 [D loss: 0.731998, acc.: 53.12%] [G loss: 1.972806]\n",
      "epoch:29 step:27959 [D loss: 0.154594, acc.: 95.31%] [G loss: 1.770248]\n",
      "epoch:29 step:27960 [D loss: 0.633849, acc.: 62.50%] [G loss: 1.746417]\n",
      "epoch:29 step:27961 [D loss: 0.362304, acc.: 88.28%] [G loss: 1.800769]\n",
      "epoch:29 step:27962 [D loss: 0.436577, acc.: 85.16%] [G loss: 1.416201]\n",
      "epoch:29 step:27963 [D loss: 0.341303, acc.: 90.62%] [G loss: 1.455006]\n",
      "epoch:29 step:27964 [D loss: 0.169759, acc.: 98.44%] [G loss: 1.863464]\n",
      "epoch:29 step:27965 [D loss: 0.135783, acc.: 98.44%] [G loss: 1.454070]\n",
      "epoch:29 step:27966 [D loss: 0.185301, acc.: 95.31%] [G loss: 1.872453]\n",
      "epoch:29 step:27967 [D loss: 0.107474, acc.: 100.00%] [G loss: 1.589357]\n",
      "epoch:29 step:27968 [D loss: 0.175745, acc.: 97.66%] [G loss: 1.937834]\n",
      "epoch:29 step:27969 [D loss: 0.177563, acc.: 97.66%] [G loss: 2.502518]\n",
      "epoch:29 step:27970 [D loss: 0.388370, acc.: 81.25%] [G loss: 1.794753]\n",
      "epoch:29 step:27971 [D loss: 0.157036, acc.: 98.44%] [G loss: 1.241781]\n",
      "epoch:29 step:27972 [D loss: 0.393828, acc.: 84.38%] [G loss: 2.073742]\n",
      "epoch:29 step:27973 [D loss: 0.719450, acc.: 62.50%] [G loss: 1.517550]\n",
      "epoch:29 step:27974 [D loss: 0.484483, acc.: 77.34%] [G loss: 1.840183]\n",
      "epoch:29 step:27975 [D loss: 0.312440, acc.: 90.62%] [G loss: 1.466714]\n",
      "epoch:29 step:27976 [D loss: 0.627014, acc.: 64.84%] [G loss: 1.629275]\n",
      "epoch:29 step:27977 [D loss: 0.149398, acc.: 97.66%] [G loss: 1.475480]\n",
      "epoch:29 step:27978 [D loss: 0.230636, acc.: 91.41%] [G loss: 1.591403]\n",
      "epoch:29 step:27979 [D loss: 0.109289, acc.: 99.22%] [G loss: 1.549111]\n",
      "epoch:29 step:27980 [D loss: 0.775870, acc.: 54.69%] [G loss: 1.962554]\n",
      "epoch:29 step:27981 [D loss: 0.201456, acc.: 96.88%] [G loss: 1.967626]\n",
      "epoch:29 step:27982 [D loss: 0.150572, acc.: 98.44%] [G loss: 1.896640]\n",
      "epoch:29 step:27983 [D loss: 0.561315, acc.: 65.62%] [G loss: 1.519386]\n",
      "epoch:29 step:27984 [D loss: 0.994993, acc.: 32.03%] [G loss: 1.555234]\n",
      "epoch:29 step:27985 [D loss: 0.338442, acc.: 93.75%] [G loss: 1.382722]\n",
      "epoch:29 step:27986 [D loss: 0.932072, acc.: 46.88%] [G loss: 1.499237]\n",
      "epoch:29 step:27987 [D loss: 0.897389, acc.: 42.19%] [G loss: 1.179123]\n",
      "epoch:29 step:27988 [D loss: 0.333663, acc.: 85.94%] [G loss: 1.415670]\n",
      "epoch:29 step:27989 [D loss: 0.267995, acc.: 93.75%] [G loss: 1.544570]\n",
      "epoch:29 step:27990 [D loss: 0.771365, acc.: 50.00%] [G loss: 1.548941]\n",
      "epoch:29 step:27991 [D loss: 0.688307, acc.: 56.25%] [G loss: 1.255173]\n",
      "epoch:29 step:27992 [D loss: 0.640875, acc.: 60.16%] [G loss: 0.961966]\n",
      "epoch:29 step:27993 [D loss: 0.698424, acc.: 61.72%] [G loss: 0.936079]\n",
      "epoch:29 step:27994 [D loss: 0.323891, acc.: 85.16%] [G loss: 1.345718]\n",
      "epoch:29 step:27995 [D loss: 0.386916, acc.: 87.50%] [G loss: 1.182309]\n",
      "epoch:29 step:27996 [D loss: 0.515578, acc.: 75.78%] [G loss: 0.982872]\n",
      "epoch:29 step:27997 [D loss: 0.668225, acc.: 62.50%] [G loss: 1.281580]\n",
      "epoch:29 step:27998 [D loss: 0.312528, acc.: 95.31%] [G loss: 1.385712]\n",
      "epoch:29 step:27999 [D loss: 0.550553, acc.: 73.44%] [G loss: 1.239869]\n",
      "epoch:29 step:28000 [D loss: 0.694798, acc.: 59.38%] [G loss: 1.218180]\n",
      "##############\n",
      "[3.90472894 2.49210446 6.36122564 5.78437765 4.84125433 6.16591502\n",
      " 5.40042445 5.74301574 5.98231423 5.1036605 ]\n",
      "##########\n",
      "epoch:29 step:28001 [D loss: 0.788872, acc.: 47.66%] [G loss: 1.048186]\n",
      "epoch:29 step:28002 [D loss: 0.649926, acc.: 61.72%] [G loss: 1.074836]\n",
      "epoch:29 step:28003 [D loss: 0.351593, acc.: 88.28%] [G loss: 1.154599]\n",
      "epoch:29 step:28004 [D loss: 0.257277, acc.: 91.41%] [G loss: 1.274894]\n",
      "epoch:29 step:28005 [D loss: 0.266994, acc.: 86.72%] [G loss: 1.465374]\n",
      "epoch:29 step:28006 [D loss: 0.197903, acc.: 97.66%] [G loss: 1.609442]\n",
      "epoch:29 step:28007 [D loss: 0.185104, acc.: 97.66%] [G loss: 1.960715]\n",
      "epoch:29 step:28008 [D loss: 0.301817, acc.: 96.09%] [G loss: 1.704933]\n",
      "epoch:29 step:28009 [D loss: 0.683562, acc.: 60.94%] [G loss: 1.620194]\n",
      "epoch:29 step:28010 [D loss: 0.774634, acc.: 45.31%] [G loss: 1.539594]\n",
      "epoch:29 step:28011 [D loss: 0.678950, acc.: 55.47%] [G loss: 1.278509]\n",
      "epoch:29 step:28012 [D loss: 0.531677, acc.: 74.22%] [G loss: 1.131060]\n",
      "epoch:29 step:28013 [D loss: 0.509574, acc.: 78.12%] [G loss: 0.879991]\n",
      "epoch:29 step:28014 [D loss: 0.238765, acc.: 94.53%] [G loss: 1.381743]\n",
      "epoch:29 step:28015 [D loss: 0.962212, acc.: 55.47%] [G loss: 1.165265]\n",
      "epoch:29 step:28016 [D loss: 0.250910, acc.: 92.97%] [G loss: 2.033633]\n",
      "epoch:29 step:28017 [D loss: 0.133304, acc.: 99.22%] [G loss: 2.175587]\n",
      "epoch:29 step:28018 [D loss: 0.100407, acc.: 98.44%] [G loss: 2.188649]\n",
      "epoch:29 step:28019 [D loss: 0.849759, acc.: 51.56%] [G loss: 2.043375]\n",
      "epoch:29 step:28020 [D loss: 0.475006, acc.: 75.00%] [G loss: 1.217321]\n",
      "epoch:29 step:28021 [D loss: 0.564905, acc.: 71.88%] [G loss: 1.764689]\n",
      "epoch:29 step:28022 [D loss: 0.500840, acc.: 79.69%] [G loss: 1.449335]\n",
      "epoch:29 step:28023 [D loss: 0.257390, acc.: 94.53%] [G loss: 1.147883]\n",
      "epoch:29 step:28024 [D loss: 0.155031, acc.: 99.22%] [G loss: 0.793824]\n",
      "epoch:29 step:28025 [D loss: 0.156046, acc.: 98.44%] [G loss: 1.816762]\n",
      "epoch:29 step:28026 [D loss: 0.446598, acc.: 70.31%] [G loss: 1.966356]\n",
      "epoch:29 step:28027 [D loss: 0.351635, acc.: 81.25%] [G loss: 2.216366]\n",
      "epoch:29 step:28028 [D loss: 0.599500, acc.: 67.19%] [G loss: 1.649930]\n",
      "epoch:29 step:28029 [D loss: 0.994111, acc.: 49.22%] [G loss: 2.129047]\n",
      "epoch:29 step:28030 [D loss: 0.258825, acc.: 96.88%] [G loss: 1.555735]\n",
      "epoch:29 step:28031 [D loss: 0.299478, acc.: 82.03%] [G loss: 1.607798]\n",
      "epoch:29 step:28032 [D loss: 0.166315, acc.: 97.66%] [G loss: 1.807145]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:28033 [D loss: 0.313826, acc.: 82.03%] [G loss: 1.862371]\n",
      "epoch:29 step:28034 [D loss: 1.128102, acc.: 45.31%] [G loss: 1.667502]\n",
      "epoch:29 step:28035 [D loss: 1.159333, acc.: 31.25%] [G loss: 1.423984]\n",
      "epoch:29 step:28036 [D loss: 0.301397, acc.: 94.53%] [G loss: 1.545533]\n",
      "epoch:29 step:28037 [D loss: 0.373043, acc.: 88.28%] [G loss: 1.436424]\n",
      "epoch:29 step:28038 [D loss: 0.903927, acc.: 50.00%] [G loss: 0.970527]\n",
      "epoch:29 step:28039 [D loss: 0.619667, acc.: 67.97%] [G loss: 1.753277]\n",
      "epoch:29 step:28040 [D loss: 0.522087, acc.: 76.56%] [G loss: 1.630170]\n",
      "epoch:29 step:28041 [D loss: 0.259302, acc.: 90.62%] [G loss: 1.732653]\n",
      "epoch:29 step:28042 [D loss: 0.525931, acc.: 71.88%] [G loss: 1.625619]\n",
      "epoch:29 step:28043 [D loss: 0.150655, acc.: 96.09%] [G loss: 1.893654]\n",
      "epoch:29 step:28044 [D loss: 0.193965, acc.: 97.66%] [G loss: 2.036582]\n",
      "epoch:29 step:28045 [D loss: 0.652695, acc.: 60.94%] [G loss: 1.372816]\n",
      "epoch:29 step:28046 [D loss: 0.231975, acc.: 91.41%] [G loss: 1.412172]\n",
      "epoch:29 step:28047 [D loss: 0.250990, acc.: 89.84%] [G loss: 1.415272]\n",
      "epoch:29 step:28048 [D loss: 0.409404, acc.: 86.72%] [G loss: 1.914935]\n",
      "epoch:29 step:28049 [D loss: 0.143069, acc.: 96.88%] [G loss: 1.902353]\n",
      "epoch:29 step:28050 [D loss: 0.054841, acc.: 99.22%] [G loss: 1.444697]\n",
      "epoch:29 step:28051 [D loss: 0.211309, acc.: 89.84%] [G loss: 2.406477]\n",
      "epoch:29 step:28052 [D loss: 0.218947, acc.: 97.66%] [G loss: 1.066398]\n",
      "epoch:29 step:28053 [D loss: 1.124948, acc.: 41.41%] [G loss: 0.471678]\n",
      "epoch:29 step:28054 [D loss: 0.809699, acc.: 49.22%] [G loss: 1.152874]\n",
      "epoch:29 step:28055 [D loss: 1.702810, acc.: 17.97%] [G loss: 1.317304]\n",
      "epoch:29 step:28056 [D loss: 1.093033, acc.: 52.34%] [G loss: 1.256774]\n",
      "epoch:29 step:28057 [D loss: 0.890300, acc.: 50.78%] [G loss: 0.230971]\n",
      "epoch:29 step:28058 [D loss: 0.323293, acc.: 89.84%] [G loss: 2.065962]\n",
      "epoch:29 step:28059 [D loss: 0.318700, acc.: 89.84%] [G loss: 2.576578]\n",
      "epoch:29 step:28060 [D loss: 0.215747, acc.: 96.09%] [G loss: 2.014244]\n",
      "epoch:29 step:28061 [D loss: 0.662332, acc.: 55.47%] [G loss: 2.225559]\n",
      "epoch:29 step:28062 [D loss: 0.121501, acc.: 96.88%] [G loss: 2.749463]\n",
      "epoch:29 step:28063 [D loss: 0.299289, acc.: 88.28%] [G loss: 2.514141]\n",
      "epoch:29 step:28064 [D loss: 0.620518, acc.: 62.50%] [G loss: 2.184543]\n",
      "epoch:29 step:28065 [D loss: 0.541697, acc.: 71.88%] [G loss: 1.231096]\n",
      "epoch:29 step:28066 [D loss: 1.657206, acc.: 50.00%] [G loss: 2.197189]\n",
      "epoch:29 step:28067 [D loss: 0.418848, acc.: 78.91%] [G loss: 3.710379]\n",
      "epoch:29 step:28068 [D loss: 0.721829, acc.: 60.16%] [G loss: 2.516182]\n",
      "epoch:29 step:28069 [D loss: 0.562725, acc.: 68.75%] [G loss: 2.417939]\n",
      "epoch:29 step:28070 [D loss: 0.621277, acc.: 64.06%] [G loss: 1.995768]\n",
      "epoch:29 step:28071 [D loss: 0.301943, acc.: 89.84%] [G loss: 1.973619]\n",
      "epoch:29 step:28072 [D loss: 0.297998, acc.: 87.50%] [G loss: 1.630094]\n",
      "epoch:29 step:28073 [D loss: 0.153334, acc.: 97.66%] [G loss: 1.020072]\n",
      "epoch:29 step:28074 [D loss: 0.375342, acc.: 85.94%] [G loss: 2.012615]\n",
      "epoch:29 step:28075 [D loss: 0.548232, acc.: 68.75%] [G loss: 1.542306]\n",
      "epoch:29 step:28076 [D loss: 0.587513, acc.: 69.53%] [G loss: 1.250207]\n",
      "epoch:29 step:28077 [D loss: 0.420765, acc.: 78.12%] [G loss: 1.140404]\n",
      "epoch:29 step:28078 [D loss: 0.231058, acc.: 90.62%] [G loss: 1.991889]\n",
      "epoch:29 step:28079 [D loss: 0.154375, acc.: 97.66%] [G loss: 1.698736]\n",
      "epoch:29 step:28080 [D loss: 0.494581, acc.: 75.00%] [G loss: 1.550885]\n",
      "epoch:29 step:28081 [D loss: 0.583975, acc.: 64.06%] [G loss: 1.206069]\n",
      "epoch:29 step:28082 [D loss: 0.311649, acc.: 91.41%] [G loss: 2.170964]\n",
      "epoch:29 step:28083 [D loss: 0.276872, acc.: 92.97%] [G loss: 1.302894]\n",
      "epoch:29 step:28084 [D loss: 0.335012, acc.: 89.06%] [G loss: 1.685049]\n",
      "epoch:29 step:28085 [D loss: 0.210921, acc.: 96.09%] [G loss: 1.217789]\n",
      "epoch:29 step:28086 [D loss: 0.615254, acc.: 64.06%] [G loss: 1.855490]\n",
      "epoch:29 step:28087 [D loss: 0.570553, acc.: 70.31%] [G loss: 1.606020]\n",
      "epoch:29 step:28088 [D loss: 0.682269, acc.: 58.59%] [G loss: 1.357318]\n",
      "epoch:29 step:28089 [D loss: 0.480803, acc.: 73.44%] [G loss: 1.460703]\n",
      "epoch:29 step:28090 [D loss: 0.257126, acc.: 89.84%] [G loss: 1.412763]\n",
      "epoch:29 step:28091 [D loss: 0.595767, acc.: 66.41%] [G loss: 1.462048]\n",
      "epoch:29 step:28092 [D loss: 0.323368, acc.: 87.50%] [G loss: 1.347394]\n",
      "epoch:29 step:28093 [D loss: 0.150512, acc.: 94.53%] [G loss: 1.964445]\n",
      "epoch:29 step:28094 [D loss: 0.199243, acc.: 93.75%] [G loss: 0.672990]\n",
      "epoch:29 step:28095 [D loss: 0.688334, acc.: 64.84%] [G loss: 1.467162]\n",
      "epoch:29 step:28096 [D loss: 0.744242, acc.: 53.12%] [G loss: 1.263096]\n",
      "epoch:29 step:28097 [D loss: 0.428541, acc.: 81.25%] [G loss: 1.631445]\n",
      "epoch:29 step:28098 [D loss: 0.505866, acc.: 75.78%] [G loss: 1.499423]\n",
      "epoch:29 step:28099 [D loss: 0.311688, acc.: 89.84%] [G loss: 1.700846]\n",
      "epoch:29 step:28100 [D loss: 0.420664, acc.: 81.25%] [G loss: 1.438644]\n",
      "epoch:29 step:28101 [D loss: 0.843973, acc.: 59.38%] [G loss: 1.636809]\n",
      "epoch:29 step:28102 [D loss: 0.145805, acc.: 98.44%] [G loss: 1.530757]\n",
      "epoch:29 step:28103 [D loss: 0.248134, acc.: 93.75%] [G loss: 1.800419]\n",
      "epoch:29 step:28104 [D loss: 0.462454, acc.: 80.47%] [G loss: 1.571957]\n",
      "epoch:29 step:28105 [D loss: 0.589282, acc.: 74.22%] [G loss: 1.400308]\n",
      "epoch:29 step:28106 [D loss: 0.413796, acc.: 86.72%] [G loss: 1.253153]\n",
      "epoch:29 step:28107 [D loss: 0.303414, acc.: 88.28%] [G loss: 1.165042]\n",
      "epoch:29 step:28108 [D loss: 0.403622, acc.: 88.28%] [G loss: 1.356545]\n",
      "epoch:29 step:28109 [D loss: 0.237513, acc.: 93.75%] [G loss: 1.687938]\n",
      "epoch:29 step:28110 [D loss: 0.146220, acc.: 96.88%] [G loss: 1.638577]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if not os.path.isdir('saved_models_{}'.format('cgan')):\n",
    "    os.mkdir('saved_models_{}'.format('cgan'))\n",
    "f = open('saved_models_{}/log_collapse1.txt'.format('cgan'), mode='w')\n",
    "\n",
    "\n",
    "from keras.datasets import fashion_mnist,mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, multiply\n",
    "from keras.layers import BatchNormalization, Activation, Embedding, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "class CGAN():\n",
    "    def __init__(self):\n",
    "        # Input shape\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        self.num_classes = 10\n",
    "        self.latent_dim = 100\n",
    "        self.x = []\n",
    "        self.y = np.zeros((31, 1), dtype=np.int)\n",
    "        self.y = list(self.y)\n",
    "        for i in range(31):\n",
    "            self.y[i] = []\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss=['binary_crossentropy'],\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise and the target label as input\n",
    "        # and generates the corresponding digit of that label\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        label = Input(shape=(1,))\n",
    "        img = self.generator([noise, label])\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated image as input and determines validity\n",
    "        # and the label of that image\n",
    "        valid = self.discriminator([img, label])\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains generator to fool discriminator\n",
    "        self.combined = Model([noise, label], valid)\n",
    "        self.combined.compile(loss=['binary_crossentropy'],\n",
    "            optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(512 * 7 * 7, input_dim=self.latent_dim))\n",
    "        model.add(Reshape((7,7, 512)))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(256, kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(128, kernel_size=3,strides=1,padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(UpSampling2D())\n",
    "        model.add(Conv2D(64, kernel_size=3,strides=1, padding=\"same\"))\n",
    "        model.add(Activation(\"relu\"))\n",
    "\n",
    "        model.add(Conv2D(self.channels, strides=2,kernel_size=3, padding=\"same\"))\n",
    "        model.add(Activation(\"tanh\"))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        label = Input(shape=(1,), dtype='int32')\n",
    "        label_embedding = Flatten()(Embedding(self.num_classes, self.latent_dim)(label))\n",
    "\n",
    "        model_input = multiply([noise, label_embedding])\n",
    "        img = model(model_input)\n",
    "\n",
    "        return Model([noise, label], img)\n",
    "    def build_discriminator(self):\n",
    "        model = Sequential()\n",
    "        model.add(Dense(self.img_rows*self.img_cols*self.channels, input_dim=np.prod(self.img_shape)))\n",
    "        model.add(Reshape((self.img_rows,self.img_cols,self.channels)))\n",
    "\n",
    "        model.add(Conv2D(64, kernel_size=3, strides=2,padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(128, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(256, kernel_size=3, strides=2, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Conv2D(512, kernel_size=3, strides=1, padding=\"same\"))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        model.summary()\n",
    "        img = Input(shape=self.img_shape)\n",
    "        label = Input(shape=(1,), dtype='int32')\n",
    "\n",
    "        label_embedding = Flatten()(Embedding(self.num_classes, np.prod(self.img_shape))(label))\n",
    "        flat_img = Flatten()(img)\n",
    "\n",
    "        model_input = multiply([flat_img, label_embedding])\n",
    "\n",
    "        validity = model(model_input)\n",
    "\n",
    "        return Model([img, label], validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "        # Configure input\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "        X_test = (X_test.astype(np.float32) - 127.5) / 127.5\n",
    "        # X_test = X_test / 127.5 - 1.\n",
    "        X_test = np.expand_dims(X_test, axis=3)\n",
    "\n",
    "        y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        nb_batches = int(X_train.shape[0] / batch_size)\n",
    "        global_step = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            for index in range(nb_batches):\n",
    "                global_step += 1\n",
    "                imgs = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "                labels = y_train[index * batch_size:(index + 1) * batch_size]\n",
    "\n",
    "                # Sample noise as generator input\n",
    "                noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "\n",
    "                # Generate a half batch of new images\n",
    "                gen_imgs = self.generator.predict([noise, labels])\n",
    "\n",
    "                # Train the discriminator\n",
    "                d_loss_real = self.discriminator.train_on_batch([imgs, labels], valid)\n",
    "                d_loss_fake = self.discriminator.train_on_batch([gen_imgs, labels], fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Generator\n",
    "                # ---------------------\n",
    "\n",
    "                # Condition on labels\n",
    "                sampled_labels = np.random.randint(0, 10, batch_size).reshape(-1, 1)\n",
    "\n",
    "                # Train the generator\n",
    "                g_loss = self.combined.train_on_batch([noise, sampled_labels], valid)\n",
    "\n",
    "                # Plot the progress\n",
    "                print(\"epoch:%d step:%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch,global_step, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "\n",
    "                sampleSize = 5000\n",
    "                # If at save interval => save generated image samples\n",
    "                if global_step % sample_interval == 0:\n",
    "                    s = self.sample_images(global_step, X_test,y_test, sampleSize)\n",
    "    def sample_images(self, epoch,x_test,y_test,sample_num):\n",
    "        r, c = sample_num//10, 10\n",
    "        noise = np.random.normal(0, 1, (r * c, 100))\n",
    "        sampled_labels = np.array([num for _ in range(r) for num in range(c)])\n",
    "        gen_imgs = self.generator.predict([noise,sampled_labels])\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        labels = np.squeeze(y_test[:sample_num])\n",
    "        labels = np.squeeze(labels)\n",
    "        dis_real = cal_distance_image_real(x_test[:sample_num], labels)\n",
    "        dis_fake = cal_distance_image_fake(gen_imgs)\n",
    "        dis_cha = dis_real - dis_fake\n",
    "        print('##############')\n",
    "        # print(dis_real)\n",
    "        # print(dis_fake)\n",
    "        print(dis_cha)\n",
    "        print('##########')\n",
    "        f.writelines('\\n')\n",
    "        f.writelines('epoch:' + str(epoch))\n",
    "        f.writelines('\\n')\n",
    "        f.writelines('紧度')\n",
    "        f.writelines('\\n')\n",
    "        f.writelines(' %.8f ' % (i) for i in dis_cha)\n",
    "        f.writelines('\\n')\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    cgan = CGAN()\n",
    "    cgan.train(epochs=30, batch_size=64, sample_interval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pppppppp [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
