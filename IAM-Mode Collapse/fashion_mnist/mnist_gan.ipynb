{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-*-coding:utf-8-*-\n",
    "import util\n",
    "import tensorflow as tf\n",
    "MNIST_CLASSIFIER_FROZEN_GRAPH = './classify_mnist_graph_def.pb'\n",
    "INPUT_TENSOR = 'inputs:0'\n",
    "OUTPUT_TENSOR = 'logits:0'\n",
    "def EuclideanDistances(A, B):\n",
    "\n",
    "    BT = B.transpose()\n",
    "    # vecProd = A * BT\n",
    "    vecProd = np.dot(A, BT)\n",
    "    # print(vecProd)\n",
    "    SqA = A ** 2\n",
    "    # print(SqA)\n",
    "    sumSqA = np.matrix(np.sum(SqA, axis=1))\n",
    "    sumSqAEx = np.tile(sumSqA.transpose(), (1, vecProd.shape[1]))\n",
    "    # print(sumSqAEx)\n",
    "\n",
    "    SqB = B ** 2\n",
    "    sumSqB = np.sum(SqB, axis=1)\n",
    "    sumSqBEx = np.tile(sumSqB, (vecProd.shape[0], 1))\n",
    "    SqED = sumSqBEx + sumSqAEx - 2 * vecProd\n",
    "    SqED[SqED < 0] = 0.0\n",
    "    ED = np.sqrt(SqED)\n",
    "    return np.divide(ED.sum(),ED.shape[0]*ED.shape[1])\n",
    "def cal_distance_image_real(images,labels):\n",
    "    eval_images=tf.convert_to_tensor(images)\n",
    "    y_logits=util.mnist_logits(eval_images, MNIST_CLASSIFIER_FROZEN_GRAPH, INPUT_TENSOR, OUTPUT_TENSOR)\n",
    "    y_logits=tf.Session().run(y_logits)\n",
    "    dict={}\n",
    "    all_dis=[]\n",
    "    for i in range(10):\n",
    "        dict[i]=[]\n",
    "    for i in range(len(labels)):\n",
    "        dict[labels[i]].append(y_logits[i])\n",
    "    for i in range(10):\n",
    "        dict[i]=np.array(dict[i])\n",
    "        if len(dict[i]):\n",
    "            dis = EuclideanDistances(dict[i], dict[i])  # 生成图片的紧度\n",
    "        else:\n",
    "            dis = -1\n",
    "        all_dis.append(dis)\n",
    "    return np.array(all_dis)\n",
    "def cal_distance_image_fake(images):\n",
    "    eval_images=tf.convert_to_tensor(images)\n",
    "    y_logits=util.mnist_logits(eval_images, MNIST_CLASSIFIER_FROZEN_GRAPH, INPUT_TENSOR, OUTPUT_TENSOR)\n",
    "    y_logits=tf.Session().run(y_logits)\n",
    "    labels = tf.Session().run(tf.argmax(y_logits, 1))\n",
    "    dict={}\n",
    "    all_dis=[]\n",
    "    for i in range(10):\n",
    "        dict[i]=[]\n",
    "    for i in range(len(labels)):\n",
    "        dict[labels[i]].append(y_logits[i])\n",
    "    for i in range(10):\n",
    "        dict[i]=np.array(dict[i])\n",
    "        if len(dict[i]):\n",
    "            dis = EuclideanDistances(dict[i], dict[i])  # 生成图片的紧度\n",
    "        else:\n",
    "            dis = -1\n",
    "        all_dis.append(dis)\n",
    "    return np.array(all_dis)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 533,505\n",
      "Trainable params: 533,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 784)               803600    \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 28, 28, 1)         0         \n",
      "=================================================================\n",
      "Total params: 1,493,520\n",
      "Trainable params: 1,489,936\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n",
      "epoch:0 step:1 [D loss: 0.925844, acc.: 16.41%] [G loss: 0.952955]\n",
      "epoch:0 step:2 [D loss: 0.456300, acc.: 79.69%] [G loss: 0.924327]\n",
      "epoch:0 step:3 [D loss: 0.337499, acc.: 88.28%] [G loss: 1.066450]\n",
      "epoch:0 step:4 [D loss: 0.301071, acc.: 92.19%] [G loss: 1.117667]\n",
      "epoch:0 step:5 [D loss: 0.280847, acc.: 92.19%] [G loss: 1.214205]\n",
      "epoch:0 step:6 [D loss: 0.210837, acc.: 97.66%] [G loss: 1.449755]\n",
      "epoch:0 step:7 [D loss: 0.179408, acc.: 100.00%] [G loss: 1.433241]\n",
      "epoch:0 step:8 [D loss: 0.163486, acc.: 99.22%] [G loss: 1.537285]\n",
      "epoch:0 step:9 [D loss: 0.159536, acc.: 100.00%] [G loss: 1.651492]\n",
      "epoch:0 step:10 [D loss: 0.170209, acc.: 98.44%] [G loss: 1.679177]\n",
      "epoch:0 step:11 [D loss: 0.143820, acc.: 100.00%] [G loss: 1.787165]\n",
      "epoch:0 step:12 [D loss: 0.117061, acc.: 100.00%] [G loss: 1.862157]\n",
      "epoch:0 step:13 [D loss: 0.106808, acc.: 99.22%] [G loss: 1.937993]\n",
      "epoch:0 step:14 [D loss: 0.112822, acc.: 100.00%] [G loss: 1.968877]\n",
      "epoch:0 step:15 [D loss: 0.093430, acc.: 100.00%] [G loss: 2.009159]\n",
      "epoch:0 step:16 [D loss: 0.097758, acc.: 100.00%] [G loss: 2.182791]\n",
      "epoch:0 step:17 [D loss: 0.092574, acc.: 100.00%] [G loss: 2.261405]\n",
      "epoch:0 step:18 [D loss: 0.088345, acc.: 99.22%] [G loss: 2.224704]\n",
      "epoch:0 step:19 [D loss: 0.097867, acc.: 99.22%] [G loss: 2.211967]\n",
      "epoch:0 step:20 [D loss: 0.084814, acc.: 100.00%] [G loss: 2.400079]\n",
      "epoch:0 step:21 [D loss: 0.065583, acc.: 100.00%] [G loss: 2.396650]\n",
      "epoch:0 step:22 [D loss: 0.079016, acc.: 100.00%] [G loss: 2.525002]\n",
      "epoch:0 step:23 [D loss: 0.056575, acc.: 100.00%] [G loss: 2.573752]\n",
      "epoch:0 step:24 [D loss: 0.054177, acc.: 100.00%] [G loss: 2.623604]\n",
      "epoch:0 step:25 [D loss: 0.051198, acc.: 100.00%] [G loss: 2.600944]\n",
      "epoch:0 step:26 [D loss: 0.050972, acc.: 100.00%] [G loss: 2.679266]\n",
      "epoch:0 step:27 [D loss: 0.055704, acc.: 100.00%] [G loss: 2.740371]\n",
      "epoch:0 step:28 [D loss: 0.056095, acc.: 100.00%] [G loss: 2.846713]\n",
      "epoch:0 step:29 [D loss: 0.051137, acc.: 100.00%] [G loss: 2.876832]\n",
      "epoch:0 step:30 [D loss: 0.096286, acc.: 97.66%] [G loss: 2.909585]\n",
      "epoch:0 step:31 [D loss: 0.050233, acc.: 100.00%] [G loss: 2.991718]\n",
      "epoch:0 step:32 [D loss: 0.040241, acc.: 100.00%] [G loss: 2.999955]\n",
      "epoch:0 step:33 [D loss: 0.047118, acc.: 100.00%] [G loss: 3.111100]\n",
      "epoch:0 step:34 [D loss: 0.038178, acc.: 100.00%] [G loss: 3.076198]\n",
      "epoch:0 step:35 [D loss: 0.047249, acc.: 100.00%] [G loss: 3.151007]\n",
      "epoch:0 step:36 [D loss: 0.035122, acc.: 100.00%] [G loss: 3.159276]\n",
      "epoch:0 step:37 [D loss: 0.037232, acc.: 100.00%] [G loss: 3.174971]\n",
      "epoch:0 step:38 [D loss: 0.053421, acc.: 99.22%] [G loss: 3.240135]\n",
      "epoch:0 step:39 [D loss: 0.032930, acc.: 100.00%] [G loss: 3.342671]\n",
      "epoch:0 step:40 [D loss: 0.037350, acc.: 100.00%] [G loss: 3.333105]\n",
      "epoch:0 step:41 [D loss: 0.034770, acc.: 100.00%] [G loss: 3.292854]\n",
      "epoch:0 step:42 [D loss: 0.037936, acc.: 99.22%] [G loss: 3.351306]\n",
      "epoch:0 step:43 [D loss: 0.032642, acc.: 100.00%] [G loss: 3.305353]\n",
      "epoch:0 step:44 [D loss: 0.041175, acc.: 100.00%] [G loss: 3.398005]\n",
      "epoch:0 step:45 [D loss: 0.026701, acc.: 100.00%] [G loss: 3.500628]\n",
      "epoch:0 step:46 [D loss: 0.030726, acc.: 100.00%] [G loss: 3.470816]\n",
      "epoch:0 step:47 [D loss: 0.035475, acc.: 100.00%] [G loss: 3.517201]\n",
      "epoch:0 step:48 [D loss: 0.028765, acc.: 100.00%] [G loss: 3.620029]\n",
      "epoch:0 step:49 [D loss: 0.027811, acc.: 100.00%] [G loss: 3.557809]\n",
      "epoch:0 step:50 [D loss: 0.027462, acc.: 100.00%] [G loss: 3.584795]\n",
      "epoch:0 step:51 [D loss: 0.031474, acc.: 100.00%] [G loss: 3.606752]\n",
      "epoch:0 step:52 [D loss: 0.041804, acc.: 100.00%] [G loss: 3.609370]\n",
      "epoch:0 step:53 [D loss: 0.033096, acc.: 100.00%] [G loss: 3.670696]\n",
      "epoch:0 step:54 [D loss: 0.028169, acc.: 100.00%] [G loss: 3.753528]\n",
      "epoch:0 step:55 [D loss: 0.030897, acc.: 100.00%] [G loss: 3.768252]\n",
      "epoch:0 step:56 [D loss: 0.042533, acc.: 99.22%] [G loss: 3.664568]\n",
      "epoch:0 step:57 [D loss: 0.033388, acc.: 100.00%] [G loss: 3.817331]\n",
      "epoch:0 step:58 [D loss: 0.028801, acc.: 100.00%] [G loss: 3.810244]\n",
      "epoch:0 step:59 [D loss: 0.031183, acc.: 100.00%] [G loss: 3.859474]\n",
      "epoch:0 step:60 [D loss: 0.031449, acc.: 100.00%] [G loss: 3.766553]\n",
      "epoch:0 step:61 [D loss: 0.030512, acc.: 100.00%] [G loss: 3.867187]\n",
      "epoch:0 step:62 [D loss: 0.031424, acc.: 100.00%] [G loss: 3.862752]\n",
      "epoch:0 step:63 [D loss: 0.031164, acc.: 100.00%] [G loss: 3.676640]\n",
      "epoch:0 step:64 [D loss: 0.029105, acc.: 100.00%] [G loss: 3.856131]\n",
      "epoch:0 step:65 [D loss: 0.029177, acc.: 100.00%] [G loss: 3.935413]\n",
      "epoch:0 step:66 [D loss: 0.042469, acc.: 99.22%] [G loss: 3.858285]\n",
      "epoch:0 step:67 [D loss: 0.031731, acc.: 100.00%] [G loss: 3.821811]\n",
      "epoch:0 step:68 [D loss: 0.031222, acc.: 100.00%] [G loss: 3.861895]\n",
      "epoch:0 step:69 [D loss: 0.041316, acc.: 99.22%] [G loss: 3.945571]\n",
      "epoch:0 step:70 [D loss: 0.032776, acc.: 100.00%] [G loss: 3.808316]\n",
      "epoch:0 step:71 [D loss: 0.049195, acc.: 99.22%] [G loss: 4.030234]\n",
      "epoch:0 step:72 [D loss: 0.028988, acc.: 100.00%] [G loss: 3.893896]\n",
      "epoch:0 step:73 [D loss: 0.038773, acc.: 100.00%] [G loss: 3.899888]\n",
      "epoch:0 step:74 [D loss: 0.039028, acc.: 100.00%] [G loss: 3.994137]\n",
      "epoch:0 step:75 [D loss: 0.029412, acc.: 100.00%] [G loss: 4.132748]\n",
      "epoch:0 step:76 [D loss: 0.043811, acc.: 100.00%] [G loss: 4.133413]\n",
      "epoch:0 step:77 [D loss: 0.034705, acc.: 99.22%] [G loss: 3.999170]\n",
      "epoch:0 step:78 [D loss: 0.037526, acc.: 100.00%] [G loss: 4.191136]\n",
      "epoch:0 step:79 [D loss: 0.040513, acc.: 100.00%] [G loss: 3.967088]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:80 [D loss: 0.043489, acc.: 99.22%] [G loss: 3.985941]\n",
      "epoch:0 step:81 [D loss: 0.053799, acc.: 100.00%] [G loss: 4.132371]\n",
      "epoch:0 step:82 [D loss: 0.037805, acc.: 100.00%] [G loss: 4.003183]\n",
      "epoch:0 step:83 [D loss: 0.036968, acc.: 100.00%] [G loss: 3.879628]\n",
      "epoch:0 step:84 [D loss: 0.044919, acc.: 100.00%] [G loss: 3.923260]\n",
      "epoch:0 step:85 [D loss: 0.061386, acc.: 100.00%] [G loss: 4.237591]\n",
      "epoch:0 step:86 [D loss: 0.073392, acc.: 99.22%] [G loss: 4.005834]\n",
      "epoch:0 step:87 [D loss: 0.075656, acc.: 98.44%] [G loss: 4.308805]\n",
      "epoch:0 step:88 [D loss: 0.077506, acc.: 98.44%] [G loss: 3.787255]\n",
      "epoch:0 step:89 [D loss: 0.070413, acc.: 97.66%] [G loss: 4.239999]\n",
      "epoch:0 step:90 [D loss: 0.045084, acc.: 100.00%] [G loss: 4.442176]\n",
      "epoch:0 step:91 [D loss: 0.060369, acc.: 100.00%] [G loss: 4.199509]\n",
      "epoch:0 step:92 [D loss: 0.053730, acc.: 100.00%] [G loss: 4.260989]\n",
      "epoch:0 step:93 [D loss: 0.081690, acc.: 98.44%] [G loss: 4.227237]\n",
      "epoch:0 step:94 [D loss: 0.099869, acc.: 97.66%] [G loss: 3.954895]\n",
      "epoch:0 step:95 [D loss: 0.106537, acc.: 95.31%] [G loss: 4.275301]\n",
      "epoch:0 step:96 [D loss: 0.084026, acc.: 98.44%] [G loss: 4.125525]\n",
      "epoch:0 step:97 [D loss: 0.073315, acc.: 98.44%] [G loss: 4.322546]\n",
      "epoch:0 step:98 [D loss: 0.071946, acc.: 98.44%] [G loss: 3.915920]\n",
      "epoch:0 step:99 [D loss: 0.127600, acc.: 96.88%] [G loss: 4.275203]\n",
      "epoch:0 step:100 [D loss: 0.206202, acc.: 91.41%] [G loss: 3.756787]\n",
      "epoch:0 step:101 [D loss: 0.093794, acc.: 96.09%] [G loss: 4.398201]\n",
      "epoch:0 step:102 [D loss: 0.243598, acc.: 89.06%] [G loss: 3.383343]\n",
      "epoch:0 step:103 [D loss: 0.176443, acc.: 92.97%] [G loss: 3.864906]\n",
      "epoch:0 step:104 [D loss: 0.059977, acc.: 99.22%] [G loss: 3.922631]\n",
      "epoch:0 step:105 [D loss: 0.161589, acc.: 95.31%] [G loss: 3.643793]\n",
      "epoch:0 step:106 [D loss: 0.095438, acc.: 95.31%] [G loss: 4.172141]\n",
      "epoch:0 step:107 [D loss: 0.177403, acc.: 93.75%] [G loss: 3.827534]\n",
      "epoch:0 step:108 [D loss: 0.146636, acc.: 95.31%] [G loss: 4.060247]\n",
      "epoch:0 step:109 [D loss: 0.256229, acc.: 89.84%] [G loss: 3.774817]\n",
      "epoch:0 step:110 [D loss: 0.094086, acc.: 97.66%] [G loss: 4.006791]\n",
      "epoch:0 step:111 [D loss: 0.366191, acc.: 85.94%] [G loss: 3.697815]\n",
      "epoch:0 step:112 [D loss: 0.127800, acc.: 95.31%] [G loss: 4.028784]\n",
      "epoch:0 step:113 [D loss: 0.476014, acc.: 78.12%] [G loss: 2.829102]\n",
      "epoch:0 step:114 [D loss: 0.139237, acc.: 95.31%] [G loss: 3.605258]\n",
      "epoch:0 step:115 [D loss: 0.126033, acc.: 96.88%] [G loss: 3.608033]\n",
      "epoch:0 step:116 [D loss: 0.182880, acc.: 93.75%] [G loss: 3.474867]\n",
      "epoch:0 step:117 [D loss: 0.302735, acc.: 86.72%] [G loss: 3.353127]\n",
      "epoch:0 step:118 [D loss: 0.201269, acc.: 91.41%] [G loss: 3.532169]\n",
      "epoch:0 step:119 [D loss: 0.129160, acc.: 96.88%] [G loss: 3.728200]\n",
      "epoch:0 step:120 [D loss: 0.365284, acc.: 83.59%] [G loss: 2.812241]\n",
      "epoch:0 step:121 [D loss: 0.139868, acc.: 96.88%] [G loss: 3.516705]\n",
      "epoch:0 step:122 [D loss: 0.191990, acc.: 96.88%] [G loss: 3.288799]\n",
      "epoch:0 step:123 [D loss: 0.143713, acc.: 95.31%] [G loss: 3.440919]\n",
      "epoch:0 step:124 [D loss: 0.191707, acc.: 92.97%] [G loss: 3.293040]\n",
      "epoch:0 step:125 [D loss: 0.289288, acc.: 87.50%] [G loss: 3.428491]\n",
      "epoch:0 step:126 [D loss: 0.154284, acc.: 96.09%] [G loss: 3.261027]\n",
      "epoch:0 step:127 [D loss: 0.218595, acc.: 90.62%] [G loss: 3.141764]\n",
      "epoch:0 step:128 [D loss: 0.196886, acc.: 92.19%] [G loss: 3.066985]\n",
      "epoch:0 step:129 [D loss: 0.267507, acc.: 89.84%] [G loss: 3.299863]\n",
      "epoch:0 step:130 [D loss: 0.188039, acc.: 93.75%] [G loss: 3.103414]\n",
      "epoch:0 step:131 [D loss: 0.146132, acc.: 95.31%] [G loss: 3.537723]\n",
      "epoch:0 step:132 [D loss: 0.327590, acc.: 84.38%] [G loss: 2.772690]\n",
      "epoch:0 step:133 [D loss: 0.165356, acc.: 92.97%] [G loss: 3.581402]\n",
      "epoch:0 step:134 [D loss: 0.332820, acc.: 82.03%] [G loss: 3.057219]\n",
      "epoch:0 step:135 [D loss: 0.376994, acc.: 82.03%] [G loss: 3.572669]\n",
      "epoch:0 step:136 [D loss: 0.104369, acc.: 96.88%] [G loss: 3.863290]\n",
      "epoch:0 step:137 [D loss: 0.228123, acc.: 92.97%] [G loss: 3.171988]\n",
      "epoch:0 step:138 [D loss: 0.143506, acc.: 96.09%] [G loss: 3.252233]\n",
      "epoch:0 step:139 [D loss: 0.169110, acc.: 96.09%] [G loss: 3.300745]\n",
      "epoch:0 step:140 [D loss: 0.326238, acc.: 88.28%] [G loss: 3.009602]\n",
      "epoch:0 step:141 [D loss: 0.155682, acc.: 94.53%] [G loss: 3.465203]\n",
      "epoch:0 step:142 [D loss: 0.355995, acc.: 83.59%] [G loss: 3.475436]\n",
      "epoch:0 step:143 [D loss: 0.314336, acc.: 89.06%] [G loss: 3.124290]\n",
      "epoch:0 step:144 [D loss: 0.257026, acc.: 90.62%] [G loss: 3.322198]\n",
      "epoch:0 step:145 [D loss: 0.276991, acc.: 85.16%] [G loss: 3.478234]\n",
      "epoch:0 step:146 [D loss: 0.483185, acc.: 82.03%] [G loss: 2.453612]\n",
      "epoch:0 step:147 [D loss: 0.219343, acc.: 92.97%] [G loss: 3.505030]\n",
      "epoch:0 step:148 [D loss: 0.195779, acc.: 93.75%] [G loss: 3.592268]\n",
      "epoch:0 step:149 [D loss: 0.278642, acc.: 87.50%] [G loss: 3.090802]\n",
      "epoch:0 step:150 [D loss: 0.286399, acc.: 86.72%] [G loss: 3.400039]\n",
      "epoch:0 step:151 [D loss: 0.443016, acc.: 78.91%] [G loss: 2.858656]\n",
      "epoch:0 step:152 [D loss: 0.275830, acc.: 89.84%] [G loss: 3.121343]\n",
      "epoch:0 step:153 [D loss: 0.364306, acc.: 83.59%] [G loss: 2.847488]\n",
      "epoch:0 step:154 [D loss: 0.212034, acc.: 91.41%] [G loss: 3.651937]\n",
      "epoch:0 step:155 [D loss: 0.653825, acc.: 71.88%] [G loss: 2.423166]\n",
      "epoch:0 step:156 [D loss: 0.254407, acc.: 89.06%] [G loss: 3.095738]\n",
      "epoch:0 step:157 [D loss: 0.160372, acc.: 94.53%] [G loss: 3.396799]\n",
      "epoch:0 step:158 [D loss: 0.252988, acc.: 88.28%] [G loss: 2.930682]\n",
      "epoch:0 step:159 [D loss: 0.427345, acc.: 81.25%] [G loss: 2.889191]\n",
      "epoch:0 step:160 [D loss: 0.423923, acc.: 80.47%] [G loss: 2.811655]\n",
      "epoch:0 step:161 [D loss: 0.658987, acc.: 70.31%] [G loss: 2.752562]\n",
      "epoch:0 step:162 [D loss: 0.236719, acc.: 93.75%] [G loss: 2.783160]\n",
      "epoch:0 step:163 [D loss: 0.295046, acc.: 90.62%] [G loss: 2.551449]\n",
      "epoch:0 step:164 [D loss: 0.385713, acc.: 79.69%] [G loss: 3.024775]\n",
      "epoch:0 step:165 [D loss: 0.404713, acc.: 82.81%] [G loss: 2.603223]\n",
      "epoch:0 step:166 [D loss: 0.349506, acc.: 84.38%] [G loss: 3.063862]\n",
      "epoch:0 step:167 [D loss: 0.621382, acc.: 71.88%] [G loss: 2.667139]\n",
      "epoch:0 step:168 [D loss: 0.352090, acc.: 85.16%] [G loss: 2.965585]\n",
      "epoch:0 step:169 [D loss: 0.316774, acc.: 85.94%] [G loss: 2.845084]\n",
      "epoch:0 step:170 [D loss: 0.469574, acc.: 83.59%] [G loss: 2.888202]\n",
      "epoch:0 step:171 [D loss: 0.440735, acc.: 83.59%] [G loss: 2.816520]\n",
      "epoch:0 step:172 [D loss: 0.432817, acc.: 75.78%] [G loss: 2.502327]\n",
      "epoch:0 step:173 [D loss: 0.433656, acc.: 82.03%] [G loss: 2.706693]\n",
      "epoch:0 step:174 [D loss: 0.461237, acc.: 82.03%] [G loss: 2.745712]\n",
      "epoch:0 step:175 [D loss: 0.430813, acc.: 77.34%] [G loss: 3.030750]\n",
      "epoch:0 step:176 [D loss: 0.502526, acc.: 77.34%] [G loss: 2.980560]\n",
      "epoch:0 step:177 [D loss: 0.523513, acc.: 71.88%] [G loss: 2.355470]\n",
      "epoch:0 step:178 [D loss: 0.326209, acc.: 85.94%] [G loss: 2.684744]\n",
      "epoch:0 step:179 [D loss: 0.397127, acc.: 83.59%] [G loss: 2.371083]\n",
      "epoch:0 step:180 [D loss: 0.249571, acc.: 92.97%] [G loss: 2.658030]\n",
      "epoch:0 step:181 [D loss: 0.459905, acc.: 82.03%] [G loss: 2.441360]\n",
      "epoch:0 step:182 [D loss: 0.449500, acc.: 81.25%] [G loss: 2.689772]\n",
      "epoch:0 step:183 [D loss: 0.748006, acc.: 59.38%] [G loss: 2.049290]\n",
      "epoch:0 step:184 [D loss: 0.355336, acc.: 85.16%] [G loss: 2.614690]\n",
      "epoch:0 step:185 [D loss: 0.434981, acc.: 78.91%] [G loss: 2.266655]\n",
      "epoch:0 step:186 [D loss: 0.358428, acc.: 80.47%] [G loss: 2.962993]\n",
      "epoch:0 step:187 [D loss: 0.455170, acc.: 81.25%] [G loss: 2.194924]\n",
      "epoch:0 step:188 [D loss: 0.453960, acc.: 80.47%] [G loss: 2.425321]\n",
      "epoch:0 step:189 [D loss: 0.475871, acc.: 82.03%] [G loss: 2.146558]\n",
      "epoch:0 step:190 [D loss: 0.402561, acc.: 83.59%] [G loss: 2.359142]\n",
      "epoch:0 step:191 [D loss: 0.833269, acc.: 50.00%] [G loss: 2.345616]\n",
      "epoch:0 step:192 [D loss: 0.582761, acc.: 65.62%] [G loss: 2.178520]\n",
      "epoch:0 step:193 [D loss: 0.503218, acc.: 78.91%] [G loss: 2.442928]\n",
      "epoch:0 step:194 [D loss: 0.632064, acc.: 67.97%] [G loss: 2.114770]\n",
      "epoch:0 step:195 [D loss: 0.428064, acc.: 80.47%] [G loss: 2.520469]\n",
      "epoch:0 step:196 [D loss: 0.560727, acc.: 76.56%] [G loss: 2.347838]\n",
      "epoch:0 step:197 [D loss: 0.693428, acc.: 71.88%] [G loss: 1.895977]\n",
      "epoch:0 step:198 [D loss: 0.700097, acc.: 66.41%] [G loss: 2.114727]\n",
      "epoch:0 step:199 [D loss: 0.577260, acc.: 69.53%] [G loss: 1.967939]\n",
      "epoch:0 step:200 [D loss: 0.373283, acc.: 88.28%] [G loss: 2.313669]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/imi432_006/anaconda3/envs/tf/lib/python3.5/site-packages/tensorflow/contrib/gan/python/eval/python/classifier_metrics_impl.py:185: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.gfile.GFile.\n",
      "##############\n",
      "[ 4.35050724  6.87274919  4.48101285  7.2320855   3.37031399 10.27426719\n",
      "  6.31613501  7.504254    4.84565664  8.14868929]\n",
      "##########\n",
      "epoch:0 step:201 [D loss: 0.478117, acc.: 78.91%] [G loss: 1.955027]\n",
      "epoch:0 step:202 [D loss: 0.533448, acc.: 74.22%] [G loss: 2.155856]\n",
      "epoch:0 step:203 [D loss: 0.583235, acc.: 74.22%] [G loss: 2.167778]\n",
      "epoch:0 step:204 [D loss: 0.788427, acc.: 60.16%] [G loss: 1.944820]\n",
      "epoch:0 step:205 [D loss: 0.542409, acc.: 74.22%] [G loss: 2.066016]\n",
      "epoch:0 step:206 [D loss: 0.516660, acc.: 78.12%] [G loss: 1.934346]\n",
      "epoch:0 step:207 [D loss: 0.472558, acc.: 77.34%] [G loss: 2.116593]\n",
      "epoch:0 step:208 [D loss: 0.601694, acc.: 69.53%] [G loss: 1.872287]\n",
      "epoch:0 step:209 [D loss: 0.489880, acc.: 79.69%] [G loss: 1.946437]\n",
      "epoch:0 step:210 [D loss: 0.590220, acc.: 74.22%] [G loss: 2.025565]\n",
      "epoch:0 step:211 [D loss: 0.790653, acc.: 50.78%] [G loss: 1.813059]\n",
      "epoch:0 step:212 [D loss: 0.636002, acc.: 65.62%] [G loss: 1.789356]\n",
      "epoch:0 step:213 [D loss: 0.880465, acc.: 46.09%] [G loss: 1.606448]\n",
      "epoch:0 step:214 [D loss: 0.638289, acc.: 66.41%] [G loss: 1.642948]\n",
      "epoch:0 step:215 [D loss: 0.727094, acc.: 64.06%] [G loss: 1.592293]\n",
      "epoch:0 step:216 [D loss: 0.610089, acc.: 66.41%] [G loss: 1.782818]\n",
      "epoch:0 step:217 [D loss: 0.684150, acc.: 59.38%] [G loss: 1.608520]\n",
      "epoch:0 step:218 [D loss: 0.822850, acc.: 50.00%] [G loss: 1.409375]\n",
      "epoch:0 step:219 [D loss: 0.524717, acc.: 75.78%] [G loss: 1.691630]\n",
      "epoch:0 step:220 [D loss: 0.828478, acc.: 51.56%] [G loss: 1.431164]\n",
      "epoch:0 step:221 [D loss: 0.680458, acc.: 66.41%] [G loss: 1.537338]\n",
      "epoch:0 step:222 [D loss: 0.649958, acc.: 66.41%] [G loss: 1.579801]\n",
      "epoch:0 step:223 [D loss: 0.861389, acc.: 42.97%] [G loss: 1.279405]\n",
      "epoch:0 step:224 [D loss: 0.615976, acc.: 67.97%] [G loss: 1.470681]\n",
      "epoch:0 step:225 [D loss: 0.697655, acc.: 57.81%] [G loss: 1.305761]\n",
      "epoch:0 step:226 [D loss: 0.652144, acc.: 69.53%] [G loss: 1.408159]\n",
      "epoch:0 step:227 [D loss: 0.730371, acc.: 57.03%] [G loss: 1.327903]\n",
      "epoch:0 step:228 [D loss: 0.799417, acc.: 53.12%] [G loss: 1.190425]\n",
      "epoch:0 step:229 [D loss: 0.589531, acc.: 67.97%] [G loss: 1.433985]\n",
      "epoch:0 step:230 [D loss: 0.615357, acc.: 69.53%] [G loss: 1.473347]\n",
      "epoch:0 step:231 [D loss: 0.813141, acc.: 63.28%] [G loss: 1.300040]\n",
      "epoch:0 step:232 [D loss: 0.923295, acc.: 40.62%] [G loss: 1.095930]\n",
      "epoch:0 step:233 [D loss: 0.780347, acc.: 48.44%] [G loss: 1.010695]\n",
      "epoch:0 step:234 [D loss: 0.695751, acc.: 61.72%] [G loss: 1.249366]\n",
      "epoch:0 step:235 [D loss: 0.742922, acc.: 60.16%] [G loss: 1.147487]\n",
      "epoch:0 step:236 [D loss: 0.659359, acc.: 64.06%] [G loss: 1.249640]\n",
      "epoch:0 step:237 [D loss: 0.662998, acc.: 65.62%] [G loss: 1.286545]\n",
      "epoch:0 step:238 [D loss: 0.584097, acc.: 71.09%] [G loss: 1.306077]\n",
      "epoch:0 step:239 [D loss: 0.642544, acc.: 68.75%] [G loss: 1.359924]\n",
      "epoch:0 step:240 [D loss: 0.797969, acc.: 53.91%] [G loss: 1.110431]\n",
      "epoch:0 step:241 [D loss: 0.737684, acc.: 56.25%] [G loss: 1.194468]\n",
      "epoch:0 step:242 [D loss: 0.663430, acc.: 63.28%] [G loss: 1.162773]\n",
      "epoch:0 step:243 [D loss: 0.709563, acc.: 53.91%] [G loss: 1.116374]\n",
      "epoch:0 step:244 [D loss: 0.628457, acc.: 63.28%] [G loss: 1.294431]\n",
      "epoch:0 step:245 [D loss: 0.740304, acc.: 59.38%] [G loss: 1.077070]\n",
      "epoch:0 step:246 [D loss: 0.673778, acc.: 67.97%] [G loss: 1.161419]\n",
      "epoch:0 step:247 [D loss: 0.721057, acc.: 57.03%] [G loss: 1.105815]\n",
      "epoch:0 step:248 [D loss: 0.737789, acc.: 48.44%] [G loss: 0.989635]\n",
      "epoch:0 step:249 [D loss: 0.655153, acc.: 62.50%] [G loss: 1.117827]\n",
      "epoch:0 step:250 [D loss: 0.677623, acc.: 67.19%] [G loss: 1.091669]\n",
      "epoch:0 step:251 [D loss: 0.657866, acc.: 60.16%] [G loss: 1.120686]\n",
      "epoch:0 step:252 [D loss: 0.622687, acc.: 70.31%] [G loss: 1.120921]\n",
      "epoch:0 step:253 [D loss: 0.773232, acc.: 53.12%] [G loss: 1.067020]\n",
      "epoch:0 step:254 [D loss: 0.690633, acc.: 58.59%] [G loss: 1.019437]\n",
      "epoch:0 step:255 [D loss: 0.659811, acc.: 60.16%] [G loss: 1.119817]\n",
      "epoch:0 step:256 [D loss: 0.701678, acc.: 62.50%] [G loss: 1.078389]\n",
      "epoch:0 step:257 [D loss: 0.605453, acc.: 67.19%] [G loss: 1.159488]\n",
      "epoch:0 step:258 [D loss: 0.735798, acc.: 59.38%] [G loss: 1.064684]\n",
      "epoch:0 step:259 [D loss: 0.691226, acc.: 58.59%] [G loss: 1.065858]\n",
      "epoch:0 step:260 [D loss: 0.647520, acc.: 67.97%] [G loss: 1.079000]\n",
      "epoch:0 step:261 [D loss: 0.776504, acc.: 48.44%] [G loss: 1.011026]\n",
      "epoch:0 step:262 [D loss: 0.767942, acc.: 43.75%] [G loss: 0.892987]\n",
      "epoch:0 step:263 [D loss: 0.707704, acc.: 45.31%] [G loss: 0.962483]\n",
      "epoch:0 step:264 [D loss: 0.760354, acc.: 43.75%] [G loss: 0.924892]\n",
      "epoch:0 step:265 [D loss: 0.714654, acc.: 54.69%] [G loss: 0.928646]\n",
      "epoch:0 step:266 [D loss: 0.768613, acc.: 50.78%] [G loss: 0.928235]\n",
      "epoch:0 step:267 [D loss: 0.643572, acc.: 67.97%] [G loss: 0.944256]\n",
      "epoch:0 step:268 [D loss: 0.633901, acc.: 65.62%] [G loss: 1.038743]\n",
      "epoch:0 step:269 [D loss: 0.647609, acc.: 64.06%] [G loss: 1.052158]\n",
      "epoch:0 step:270 [D loss: 0.635346, acc.: 70.31%] [G loss: 1.059745]\n",
      "epoch:0 step:271 [D loss: 0.734008, acc.: 52.34%] [G loss: 0.912755]\n",
      "epoch:0 step:272 [D loss: 0.663966, acc.: 57.81%] [G loss: 0.935038]\n",
      "epoch:0 step:273 [D loss: 0.760811, acc.: 50.78%] [G loss: 0.904652]\n",
      "epoch:0 step:274 [D loss: 0.613570, acc.: 65.62%] [G loss: 0.933494]\n",
      "epoch:0 step:275 [D loss: 0.707682, acc.: 53.12%] [G loss: 0.894653]\n",
      "epoch:0 step:276 [D loss: 0.732517, acc.: 50.00%] [G loss: 0.868600]\n",
      "epoch:0 step:277 [D loss: 0.712085, acc.: 48.44%] [G loss: 0.851315]\n",
      "epoch:0 step:278 [D loss: 0.644478, acc.: 59.38%] [G loss: 0.888509]\n",
      "epoch:0 step:279 [D loss: 0.698127, acc.: 57.81%] [G loss: 0.900781]\n",
      "epoch:0 step:280 [D loss: 0.626955, acc.: 65.62%] [G loss: 0.907230]\n",
      "epoch:0 step:281 [D loss: 0.675018, acc.: 63.28%] [G loss: 0.944835]\n",
      "epoch:0 step:282 [D loss: 0.666705, acc.: 64.06%] [G loss: 0.905003]\n",
      "epoch:0 step:283 [D loss: 0.656007, acc.: 60.94%] [G loss: 0.903614]\n",
      "epoch:0 step:284 [D loss: 0.574664, acc.: 70.31%] [G loss: 0.959538]\n",
      "epoch:0 step:285 [D loss: 0.720010, acc.: 58.59%] [G loss: 0.881255]\n",
      "epoch:0 step:286 [D loss: 0.629532, acc.: 63.28%] [G loss: 0.919369]\n",
      "epoch:0 step:287 [D loss: 0.663893, acc.: 61.72%] [G loss: 0.893952]\n",
      "epoch:0 step:288 [D loss: 0.641756, acc.: 64.06%] [G loss: 0.894587]\n",
      "epoch:0 step:289 [D loss: 0.619583, acc.: 63.28%] [G loss: 0.920615]\n",
      "epoch:0 step:290 [D loss: 0.652552, acc.: 67.19%] [G loss: 0.921835]\n",
      "epoch:0 step:291 [D loss: 0.657057, acc.: 59.38%] [G loss: 0.905453]\n",
      "epoch:0 step:292 [D loss: 0.584700, acc.: 70.31%] [G loss: 0.946904]\n",
      "epoch:0 step:293 [D loss: 0.671939, acc.: 57.81%] [G loss: 0.941400]\n",
      "epoch:0 step:294 [D loss: 0.626563, acc.: 63.28%] [G loss: 0.925726]\n",
      "epoch:0 step:295 [D loss: 0.634060, acc.: 70.31%] [G loss: 0.879588]\n",
      "epoch:0 step:296 [D loss: 0.674981, acc.: 57.81%] [G loss: 0.907227]\n",
      "epoch:0 step:297 [D loss: 0.668626, acc.: 56.25%] [G loss: 0.924129]\n",
      "epoch:0 step:298 [D loss: 0.691788, acc.: 58.59%] [G loss: 0.887460]\n",
      "epoch:0 step:299 [D loss: 0.625965, acc.: 66.41%] [G loss: 0.883210]\n",
      "epoch:0 step:300 [D loss: 0.710472, acc.: 57.03%] [G loss: 0.907677]\n",
      "epoch:0 step:301 [D loss: 0.628549, acc.: 67.97%] [G loss: 0.985014]\n",
      "epoch:0 step:302 [D loss: 0.685131, acc.: 54.69%] [G loss: 0.928744]\n",
      "epoch:0 step:303 [D loss: 0.635832, acc.: 60.16%] [G loss: 0.909890]\n",
      "epoch:0 step:304 [D loss: 0.639800, acc.: 62.50%] [G loss: 0.940393]\n",
      "epoch:0 step:305 [D loss: 0.678740, acc.: 60.94%] [G loss: 0.911844]\n",
      "epoch:0 step:306 [D loss: 0.671446, acc.: 60.16%] [G loss: 0.903754]\n",
      "epoch:0 step:307 [D loss: 0.657905, acc.: 58.59%] [G loss: 0.876778]\n",
      "epoch:0 step:308 [D loss: 0.652589, acc.: 64.06%] [G loss: 0.864353]\n",
      "epoch:0 step:309 [D loss: 0.614970, acc.: 64.06%] [G loss: 0.962781]\n",
      "epoch:0 step:310 [D loss: 0.704622, acc.: 57.03%] [G loss: 0.964668]\n",
      "epoch:0 step:311 [D loss: 0.671286, acc.: 60.16%] [G loss: 0.962053]\n",
      "epoch:0 step:312 [D loss: 0.673721, acc.: 60.94%] [G loss: 0.913117]\n",
      "epoch:0 step:313 [D loss: 0.659572, acc.: 60.94%] [G loss: 0.877896]\n",
      "epoch:0 step:314 [D loss: 0.647696, acc.: 58.59%] [G loss: 0.871608]\n",
      "epoch:0 step:315 [D loss: 0.577780, acc.: 67.97%] [G loss: 0.901606]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:316 [D loss: 0.577951, acc.: 73.44%] [G loss: 1.020572]\n",
      "epoch:0 step:317 [D loss: 0.686783, acc.: 57.03%] [G loss: 0.984415]\n",
      "epoch:0 step:318 [D loss: 0.669792, acc.: 59.38%] [G loss: 0.985197]\n",
      "epoch:0 step:319 [D loss: 0.651394, acc.: 64.84%] [G loss: 0.946735]\n",
      "epoch:0 step:320 [D loss: 0.658933, acc.: 56.25%] [G loss: 0.901718]\n",
      "epoch:0 step:321 [D loss: 0.647998, acc.: 61.72%] [G loss: 0.930086]\n",
      "epoch:0 step:322 [D loss: 0.622871, acc.: 64.84%] [G loss: 0.920117]\n",
      "epoch:0 step:323 [D loss: 0.674205, acc.: 54.69%] [G loss: 0.882902]\n",
      "epoch:0 step:324 [D loss: 0.659460, acc.: 61.72%] [G loss: 0.877337]\n",
      "epoch:0 step:325 [D loss: 0.584786, acc.: 65.62%] [G loss: 0.904281]\n",
      "epoch:0 step:326 [D loss: 0.671191, acc.: 56.25%] [G loss: 0.946370]\n",
      "epoch:0 step:327 [D loss: 0.609741, acc.: 71.09%] [G loss: 0.915879]\n",
      "epoch:0 step:328 [D loss: 0.654802, acc.: 60.16%] [G loss: 0.920569]\n",
      "epoch:0 step:329 [D loss: 0.644707, acc.: 58.59%] [G loss: 0.909157]\n",
      "epoch:0 step:330 [D loss: 0.642364, acc.: 62.50%] [G loss: 0.909978]\n",
      "epoch:0 step:331 [D loss: 0.632609, acc.: 62.50%] [G loss: 0.900443]\n",
      "epoch:0 step:332 [D loss: 0.620907, acc.: 63.28%] [G loss: 0.889151]\n",
      "epoch:0 step:333 [D loss: 0.677555, acc.: 60.94%] [G loss: 0.939630]\n",
      "epoch:0 step:334 [D loss: 0.677104, acc.: 53.91%] [G loss: 0.928031]\n",
      "epoch:0 step:335 [D loss: 0.651321, acc.: 60.16%] [G loss: 0.874754]\n",
      "epoch:0 step:336 [D loss: 0.708290, acc.: 56.25%] [G loss: 0.856546]\n",
      "epoch:0 step:337 [D loss: 0.678311, acc.: 54.69%] [G loss: 0.861518]\n",
      "epoch:0 step:338 [D loss: 0.651537, acc.: 57.81%] [G loss: 0.867340]\n",
      "epoch:0 step:339 [D loss: 0.648617, acc.: 64.06%] [G loss: 0.815468]\n",
      "epoch:0 step:340 [D loss: 0.668272, acc.: 53.12%] [G loss: 0.822918]\n",
      "epoch:0 step:341 [D loss: 0.635552, acc.: 64.84%] [G loss: 0.819278]\n",
      "epoch:0 step:342 [D loss: 0.659650, acc.: 53.12%] [G loss: 0.839682]\n",
      "epoch:0 step:343 [D loss: 0.645317, acc.: 61.72%] [G loss: 0.850696]\n",
      "epoch:0 step:344 [D loss: 0.592029, acc.: 66.41%] [G loss: 0.907670]\n",
      "epoch:0 step:345 [D loss: 0.685533, acc.: 51.56%] [G loss: 0.890465]\n",
      "epoch:0 step:346 [D loss: 0.625643, acc.: 56.25%] [G loss: 0.905931]\n",
      "epoch:0 step:347 [D loss: 0.638635, acc.: 66.41%] [G loss: 0.875922]\n",
      "epoch:0 step:348 [D loss: 0.680907, acc.: 56.25%] [G loss: 0.851287]\n",
      "epoch:0 step:349 [D loss: 0.652123, acc.: 53.12%] [G loss: 0.937117]\n",
      "epoch:0 step:350 [D loss: 0.703057, acc.: 51.56%] [G loss: 0.855994]\n",
      "epoch:0 step:351 [D loss: 0.645972, acc.: 58.59%] [G loss: 0.882391]\n",
      "epoch:0 step:352 [D loss: 0.570566, acc.: 73.44%] [G loss: 0.920520]\n",
      "epoch:0 step:353 [D loss: 0.679507, acc.: 56.25%] [G loss: 0.899160]\n",
      "epoch:0 step:354 [D loss: 0.646572, acc.: 63.28%] [G loss: 0.909586]\n",
      "epoch:0 step:355 [D loss: 0.682900, acc.: 56.25%] [G loss: 0.877511]\n",
      "epoch:0 step:356 [D loss: 0.642539, acc.: 62.50%] [G loss: 0.897794]\n",
      "epoch:0 step:357 [D loss: 0.656554, acc.: 57.81%] [G loss: 0.864690]\n",
      "epoch:0 step:358 [D loss: 0.631951, acc.: 62.50%] [G loss: 0.891864]\n",
      "epoch:0 step:359 [D loss: 0.652188, acc.: 60.16%] [G loss: 0.863335]\n",
      "epoch:0 step:360 [D loss: 0.699648, acc.: 50.78%] [G loss: 0.900710]\n",
      "epoch:0 step:361 [D loss: 0.683090, acc.: 53.91%] [G loss: 0.845015]\n",
      "epoch:0 step:362 [D loss: 0.619084, acc.: 60.94%] [G loss: 0.851269]\n",
      "epoch:0 step:363 [D loss: 0.581801, acc.: 70.31%] [G loss: 0.910726]\n",
      "epoch:0 step:364 [D loss: 0.595902, acc.: 68.75%] [G loss: 0.905992]\n",
      "epoch:0 step:365 [D loss: 0.724923, acc.: 54.69%] [G loss: 0.886636]\n",
      "epoch:0 step:366 [D loss: 0.644931, acc.: 60.16%] [G loss: 0.873312]\n",
      "epoch:0 step:367 [D loss: 0.627608, acc.: 64.84%] [G loss: 0.862782]\n",
      "epoch:0 step:368 [D loss: 0.626602, acc.: 67.97%] [G loss: 0.841054]\n",
      "epoch:0 step:369 [D loss: 0.689942, acc.: 57.81%] [G loss: 0.823811]\n",
      "epoch:0 step:370 [D loss: 0.618858, acc.: 64.84%] [G loss: 0.828862]\n",
      "epoch:0 step:371 [D loss: 0.638235, acc.: 64.84%] [G loss: 0.907139]\n",
      "epoch:0 step:372 [D loss: 0.637269, acc.: 61.72%] [G loss: 0.891845]\n",
      "epoch:0 step:373 [D loss: 0.654955, acc.: 57.81%] [G loss: 0.875958]\n",
      "epoch:0 step:374 [D loss: 0.633993, acc.: 60.94%] [G loss: 0.890381]\n",
      "epoch:0 step:375 [D loss: 0.635222, acc.: 64.06%] [G loss: 0.816283]\n",
      "epoch:0 step:376 [D loss: 0.638676, acc.: 63.28%] [G loss: 0.837941]\n",
      "epoch:0 step:377 [D loss: 0.661050, acc.: 55.47%] [G loss: 0.803001]\n",
      "epoch:0 step:378 [D loss: 0.637509, acc.: 64.84%] [G loss: 0.813769]\n",
      "epoch:0 step:379 [D loss: 0.635267, acc.: 64.84%] [G loss: 0.809141]\n",
      "epoch:0 step:380 [D loss: 0.635015, acc.: 64.84%] [G loss: 0.856784]\n",
      "epoch:0 step:381 [D loss: 0.619991, acc.: 62.50%] [G loss: 0.899075]\n",
      "epoch:0 step:382 [D loss: 0.679635, acc.: 53.91%] [G loss: 0.844128]\n",
      "epoch:0 step:383 [D loss: 0.619070, acc.: 60.94%] [G loss: 0.825784]\n",
      "epoch:0 step:384 [D loss: 0.727165, acc.: 53.91%] [G loss: 0.823576]\n",
      "epoch:0 step:385 [D loss: 0.662948, acc.: 59.38%] [G loss: 0.822834]\n",
      "epoch:0 step:386 [D loss: 0.711004, acc.: 50.00%] [G loss: 0.803010]\n",
      "epoch:0 step:387 [D loss: 0.669937, acc.: 50.00%] [G loss: 0.798134]\n",
      "epoch:0 step:388 [D loss: 0.676733, acc.: 57.03%] [G loss: 0.815233]\n",
      "epoch:0 step:389 [D loss: 0.667032, acc.: 60.16%] [G loss: 0.850284]\n",
      "epoch:0 step:390 [D loss: 0.631803, acc.: 60.16%] [G loss: 0.886168]\n",
      "epoch:0 step:391 [D loss: 0.668501, acc.: 60.94%] [G loss: 0.818325]\n",
      "epoch:0 step:392 [D loss: 0.629908, acc.: 58.59%] [G loss: 0.848148]\n",
      "epoch:0 step:393 [D loss: 0.617226, acc.: 64.84%] [G loss: 0.807952]\n",
      "epoch:0 step:394 [D loss: 0.729518, acc.: 52.34%] [G loss: 0.786186]\n",
      "epoch:0 step:395 [D loss: 0.636635, acc.: 57.81%] [G loss: 0.788167]\n",
      "epoch:0 step:396 [D loss: 0.638870, acc.: 56.25%] [G loss: 0.826649]\n",
      "epoch:0 step:397 [D loss: 0.650658, acc.: 64.06%] [G loss: 0.855138]\n",
      "epoch:0 step:398 [D loss: 0.643242, acc.: 59.38%] [G loss: 0.863934]\n",
      "epoch:0 step:399 [D loss: 0.670426, acc.: 59.38%] [G loss: 0.824412]\n",
      "epoch:0 step:400 [D loss: 0.661769, acc.: 61.72%] [G loss: 0.823865]\n",
      "##############\n",
      "[ 3.53957756  5.06092425  5.31421055  5.82541768  2.93287492 10.27426719\n",
      "  4.00170219  5.85896765  4.73233192  8.14868929]\n",
      "##########\n",
      "epoch:0 step:401 [D loss: 0.641588, acc.: 64.06%] [G loss: 0.846119]\n",
      "epoch:0 step:402 [D loss: 0.638401, acc.: 62.50%] [G loss: 0.837902]\n",
      "epoch:0 step:403 [D loss: 0.663399, acc.: 60.16%] [G loss: 0.804114]\n",
      "epoch:0 step:404 [D loss: 0.644347, acc.: 59.38%] [G loss: 0.830806]\n",
      "epoch:0 step:405 [D loss: 0.611622, acc.: 69.53%] [G loss: 0.841361]\n",
      "epoch:0 step:406 [D loss: 0.684220, acc.: 60.16%] [G loss: 0.863661]\n",
      "epoch:0 step:407 [D loss: 0.668632, acc.: 57.03%] [G loss: 0.836735]\n",
      "epoch:0 step:408 [D loss: 0.641311, acc.: 57.81%] [G loss: 0.838752]\n",
      "epoch:0 step:409 [D loss: 0.641471, acc.: 67.19%] [G loss: 0.826373]\n",
      "epoch:0 step:410 [D loss: 0.656442, acc.: 58.59%] [G loss: 0.842853]\n",
      "epoch:0 step:411 [D loss: 0.658333, acc.: 64.84%] [G loss: 0.822173]\n",
      "epoch:0 step:412 [D loss: 0.654428, acc.: 66.41%] [G loss: 0.850160]\n",
      "epoch:0 step:413 [D loss: 0.615540, acc.: 68.75%] [G loss: 0.821103]\n",
      "epoch:0 step:414 [D loss: 0.621378, acc.: 66.41%] [G loss: 0.814444]\n",
      "epoch:0 step:415 [D loss: 0.654608, acc.: 64.84%] [G loss: 0.852479]\n",
      "epoch:0 step:416 [D loss: 0.638320, acc.: 61.72%] [G loss: 0.848969]\n",
      "epoch:0 step:417 [D loss: 0.681267, acc.: 53.91%] [G loss: 0.887215]\n",
      "epoch:0 step:418 [D loss: 0.654776, acc.: 60.94%] [G loss: 0.846927]\n",
      "epoch:0 step:419 [D loss: 0.632070, acc.: 61.72%] [G loss: 0.847202]\n",
      "epoch:0 step:420 [D loss: 0.685094, acc.: 50.78%] [G loss: 0.869971]\n",
      "epoch:0 step:421 [D loss: 0.654797, acc.: 59.38%] [G loss: 0.836305]\n",
      "epoch:0 step:422 [D loss: 0.630157, acc.: 66.41%] [G loss: 0.856775]\n",
      "epoch:0 step:423 [D loss: 0.639685, acc.: 62.50%] [G loss: 0.811608]\n",
      "epoch:0 step:424 [D loss: 0.659971, acc.: 63.28%] [G loss: 0.819177]\n",
      "epoch:0 step:425 [D loss: 0.649792, acc.: 59.38%] [G loss: 0.825982]\n",
      "epoch:0 step:426 [D loss: 0.654800, acc.: 56.25%] [G loss: 0.864436]\n",
      "epoch:0 step:427 [D loss: 0.666189, acc.: 58.59%] [G loss: 0.864222]\n",
      "epoch:0 step:428 [D loss: 0.638294, acc.: 67.19%] [G loss: 0.851513]\n",
      "epoch:0 step:429 [D loss: 0.667487, acc.: 58.59%] [G loss: 0.833372]\n",
      "epoch:0 step:430 [D loss: 0.646511, acc.: 63.28%] [G loss: 0.827282]\n",
      "epoch:0 step:431 [D loss: 0.611230, acc.: 66.41%] [G loss: 0.858443]\n",
      "epoch:0 step:432 [D loss: 0.632916, acc.: 60.94%] [G loss: 0.830817]\n",
      "epoch:0 step:433 [D loss: 0.640905, acc.: 63.28%] [G loss: 0.840477]\n",
      "epoch:0 step:434 [D loss: 0.660884, acc.: 57.03%] [G loss: 0.849388]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:435 [D loss: 0.589563, acc.: 69.53%] [G loss: 0.878412]\n",
      "epoch:0 step:436 [D loss: 0.622669, acc.: 70.31%] [G loss: 0.874695]\n",
      "epoch:0 step:437 [D loss: 0.587486, acc.: 71.09%] [G loss: 0.906179]\n",
      "epoch:0 step:438 [D loss: 0.585871, acc.: 67.97%] [G loss: 0.921165]\n",
      "epoch:0 step:439 [D loss: 0.650897, acc.: 63.28%] [G loss: 0.908506]\n",
      "epoch:0 step:440 [D loss: 0.690593, acc.: 57.03%] [G loss: 0.856414]\n",
      "epoch:0 step:441 [D loss: 0.643830, acc.: 60.16%] [G loss: 0.917351]\n",
      "epoch:0 step:442 [D loss: 0.643601, acc.: 66.41%] [G loss: 0.863472]\n",
      "epoch:0 step:443 [D loss: 0.650120, acc.: 62.50%] [G loss: 0.862136]\n",
      "epoch:0 step:444 [D loss: 0.653897, acc.: 54.69%] [G loss: 0.854973]\n",
      "epoch:0 step:445 [D loss: 0.606373, acc.: 68.75%] [G loss: 0.900758]\n",
      "epoch:0 step:446 [D loss: 0.685892, acc.: 57.03%] [G loss: 0.879098]\n",
      "epoch:0 step:447 [D loss: 0.656681, acc.: 60.16%] [G loss: 0.869827]\n",
      "epoch:0 step:448 [D loss: 0.636683, acc.: 64.06%] [G loss: 0.821655]\n",
      "epoch:0 step:449 [D loss: 0.661101, acc.: 59.38%] [G loss: 0.846055]\n",
      "epoch:0 step:450 [D loss: 0.627730, acc.: 62.50%] [G loss: 0.870107]\n",
      "epoch:0 step:451 [D loss: 0.688086, acc.: 56.25%] [G loss: 0.846601]\n",
      "epoch:0 step:452 [D loss: 0.650978, acc.: 59.38%] [G loss: 0.827859]\n",
      "epoch:0 step:453 [D loss: 0.617481, acc.: 71.88%] [G loss: 0.826815]\n",
      "epoch:0 step:454 [D loss: 0.672614, acc.: 60.94%] [G loss: 0.812671]\n",
      "epoch:0 step:455 [D loss: 0.598343, acc.: 69.53%] [G loss: 0.807895]\n",
      "epoch:0 step:456 [D loss: 0.675235, acc.: 57.81%] [G loss: 0.877673]\n",
      "epoch:0 step:457 [D loss: 0.623584, acc.: 67.19%] [G loss: 0.869702]\n",
      "epoch:0 step:458 [D loss: 0.631074, acc.: 65.62%] [G loss: 0.877227]\n",
      "epoch:0 step:459 [D loss: 0.637027, acc.: 66.41%] [G loss: 0.877809]\n",
      "epoch:0 step:460 [D loss: 0.645013, acc.: 61.72%] [G loss: 0.856798]\n",
      "epoch:0 step:461 [D loss: 0.650382, acc.: 67.19%] [G loss: 0.821641]\n",
      "epoch:0 step:462 [D loss: 0.643181, acc.: 67.97%] [G loss: 0.867618]\n",
      "epoch:0 step:463 [D loss: 0.619391, acc.: 67.19%] [G loss: 0.917959]\n",
      "epoch:0 step:464 [D loss: 0.611886, acc.: 66.41%] [G loss: 0.914284]\n",
      "epoch:0 step:465 [D loss: 0.618293, acc.: 64.06%] [G loss: 0.919181]\n",
      "epoch:0 step:466 [D loss: 0.591456, acc.: 70.31%] [G loss: 0.876086]\n",
      "epoch:0 step:467 [D loss: 0.649288, acc.: 66.41%] [G loss: 0.892329]\n",
      "epoch:0 step:468 [D loss: 0.643659, acc.: 67.19%] [G loss: 0.843879]\n",
      "epoch:0 step:469 [D loss: 0.635332, acc.: 65.62%] [G loss: 0.839337]\n",
      "epoch:0 step:470 [D loss: 0.616733, acc.: 64.84%] [G loss: 0.870806]\n",
      "epoch:0 step:471 [D loss: 0.633956, acc.: 63.28%] [G loss: 0.842778]\n",
      "epoch:0 step:472 [D loss: 0.616230, acc.: 62.50%] [G loss: 0.852795]\n",
      "epoch:0 step:473 [D loss: 0.661512, acc.: 64.84%] [G loss: 0.866696]\n",
      "epoch:0 step:474 [D loss: 0.661108, acc.: 58.59%] [G loss: 0.870016]\n",
      "epoch:0 step:475 [D loss: 0.631548, acc.: 67.19%] [G loss: 0.873168]\n",
      "epoch:0 step:476 [D loss: 0.673923, acc.: 53.91%] [G loss: 0.831707]\n",
      "epoch:0 step:477 [D loss: 0.636155, acc.: 58.59%] [G loss: 0.854480]\n",
      "epoch:0 step:478 [D loss: 0.621125, acc.: 64.06%] [G loss: 0.894315]\n",
      "epoch:0 step:479 [D loss: 0.628558, acc.: 62.50%] [G loss: 0.860067]\n",
      "epoch:0 step:480 [D loss: 0.684299, acc.: 60.16%] [G loss: 0.860619]\n",
      "epoch:0 step:481 [D loss: 0.594563, acc.: 71.88%] [G loss: 0.905639]\n",
      "epoch:0 step:482 [D loss: 0.629280, acc.: 61.72%] [G loss: 0.876567]\n",
      "epoch:0 step:483 [D loss: 0.639271, acc.: 64.06%] [G loss: 0.870718]\n",
      "epoch:0 step:484 [D loss: 0.604099, acc.: 65.62%] [G loss: 0.853559]\n",
      "epoch:0 step:485 [D loss: 0.659662, acc.: 57.03%] [G loss: 0.855289]\n",
      "epoch:0 step:486 [D loss: 0.625418, acc.: 64.84%] [G loss: 0.835936]\n",
      "epoch:0 step:487 [D loss: 0.640427, acc.: 60.16%] [G loss: 0.830962]\n",
      "epoch:0 step:488 [D loss: 0.619663, acc.: 64.84%] [G loss: 0.859782]\n",
      "epoch:0 step:489 [D loss: 0.673533, acc.: 59.38%] [G loss: 0.813939]\n",
      "epoch:0 step:490 [D loss: 0.625285, acc.: 63.28%] [G loss: 0.849096]\n",
      "epoch:0 step:491 [D loss: 0.680444, acc.: 51.56%] [G loss: 0.845023]\n",
      "epoch:0 step:492 [D loss: 0.650343, acc.: 57.03%] [G loss: 0.845849]\n",
      "epoch:0 step:493 [D loss: 0.615744, acc.: 66.41%] [G loss: 0.848773]\n",
      "epoch:0 step:494 [D loss: 0.640332, acc.: 66.41%] [G loss: 0.846331]\n",
      "epoch:0 step:495 [D loss: 0.667189, acc.: 53.91%] [G loss: 0.887881]\n",
      "epoch:0 step:496 [D loss: 0.613467, acc.: 66.41%] [G loss: 0.849689]\n",
      "epoch:0 step:497 [D loss: 0.626852, acc.: 63.28%] [G loss: 0.874248]\n",
      "epoch:0 step:498 [D loss: 0.718581, acc.: 56.25%] [G loss: 0.861642]\n",
      "epoch:0 step:499 [D loss: 0.684231, acc.: 52.34%] [G loss: 0.810036]\n",
      "epoch:0 step:500 [D loss: 0.658286, acc.: 58.59%] [G loss: 0.842931]\n",
      "epoch:0 step:501 [D loss: 0.672278, acc.: 56.25%] [G loss: 0.858621]\n",
      "epoch:0 step:502 [D loss: 0.691289, acc.: 52.34%] [G loss: 0.820152]\n",
      "epoch:0 step:503 [D loss: 0.674602, acc.: 54.69%] [G loss: 0.814608]\n",
      "epoch:0 step:504 [D loss: 0.701109, acc.: 50.00%] [G loss: 0.821783]\n",
      "epoch:0 step:505 [D loss: 0.660965, acc.: 59.38%] [G loss: 0.850858]\n",
      "epoch:0 step:506 [D loss: 0.675609, acc.: 56.25%] [G loss: 0.815755]\n",
      "epoch:0 step:507 [D loss: 0.680775, acc.: 53.91%] [G loss: 0.842570]\n",
      "epoch:0 step:508 [D loss: 0.670302, acc.: 54.69%] [G loss: 0.816615]\n",
      "epoch:0 step:509 [D loss: 0.683212, acc.: 52.34%] [G loss: 0.810138]\n",
      "epoch:0 step:510 [D loss: 0.728866, acc.: 53.12%] [G loss: 0.850675]\n",
      "epoch:0 step:511 [D loss: 0.688001, acc.: 52.34%] [G loss: 0.862261]\n",
      "epoch:0 step:512 [D loss: 0.652614, acc.: 61.72%] [G loss: 0.792455]\n",
      "epoch:0 step:513 [D loss: 0.702227, acc.: 55.47%] [G loss: 0.753878]\n",
      "epoch:0 step:514 [D loss: 0.692469, acc.: 51.56%] [G loss: 0.786387]\n",
      "epoch:0 step:515 [D loss: 0.691548, acc.: 56.25%] [G loss: 0.822000]\n",
      "epoch:0 step:516 [D loss: 0.686926, acc.: 52.34%] [G loss: 0.814985]\n",
      "epoch:0 step:517 [D loss: 0.654121, acc.: 52.34%] [G loss: 0.769716]\n",
      "epoch:0 step:518 [D loss: 0.683838, acc.: 47.66%] [G loss: 0.792639]\n",
      "epoch:0 step:519 [D loss: 0.693224, acc.: 57.03%] [G loss: 0.821951]\n",
      "epoch:0 step:520 [D loss: 0.651309, acc.: 58.59%] [G loss: 0.841534]\n",
      "epoch:0 step:521 [D loss: 0.656752, acc.: 64.84%] [G loss: 0.832625]\n",
      "epoch:0 step:522 [D loss: 0.629139, acc.: 60.94%] [G loss: 0.836519]\n",
      "epoch:0 step:523 [D loss: 0.701425, acc.: 58.59%] [G loss: 0.810723]\n",
      "epoch:0 step:524 [D loss: 0.674576, acc.: 57.03%] [G loss: 0.769417]\n",
      "epoch:0 step:525 [D loss: 0.647908, acc.: 65.62%] [G loss: 0.807684]\n",
      "epoch:0 step:526 [D loss: 0.645268, acc.: 64.06%] [G loss: 0.838573]\n",
      "epoch:0 step:527 [D loss: 0.639709, acc.: 57.03%] [G loss: 0.841817]\n",
      "epoch:0 step:528 [D loss: 0.684944, acc.: 54.69%] [G loss: 0.813113]\n",
      "epoch:0 step:529 [D loss: 0.608610, acc.: 68.75%] [G loss: 0.805567]\n",
      "epoch:0 step:530 [D loss: 0.624417, acc.: 60.94%] [G loss: 0.860946]\n",
      "epoch:0 step:531 [D loss: 0.652445, acc.: 58.59%] [G loss: 0.821497]\n",
      "epoch:0 step:532 [D loss: 0.648911, acc.: 62.50%] [G loss: 0.850388]\n",
      "epoch:0 step:533 [D loss: 0.703511, acc.: 45.31%] [G loss: 0.828819]\n",
      "epoch:0 step:534 [D loss: 0.647730, acc.: 61.72%] [G loss: 0.808897]\n",
      "epoch:0 step:535 [D loss: 0.674039, acc.: 60.16%] [G loss: 0.819631]\n",
      "epoch:0 step:536 [D loss: 0.623302, acc.: 63.28%] [G loss: 0.810629]\n",
      "epoch:0 step:537 [D loss: 0.606066, acc.: 66.41%] [G loss: 0.806847]\n",
      "epoch:0 step:538 [D loss: 0.650565, acc.: 61.72%] [G loss: 0.832786]\n",
      "epoch:0 step:539 [D loss: 0.634893, acc.: 61.72%] [G loss: 0.838430]\n",
      "epoch:0 step:540 [D loss: 0.620602, acc.: 69.53%] [G loss: 0.817890]\n",
      "epoch:0 step:541 [D loss: 0.652924, acc.: 59.38%] [G loss: 0.821307]\n",
      "epoch:0 step:542 [D loss: 0.622845, acc.: 64.06%] [G loss: 0.861791]\n",
      "epoch:0 step:543 [D loss: 0.642675, acc.: 63.28%] [G loss: 0.832141]\n",
      "epoch:0 step:544 [D loss: 0.613114, acc.: 66.41%] [G loss: 0.783374]\n",
      "epoch:0 step:545 [D loss: 0.644940, acc.: 64.06%] [G loss: 0.804578]\n",
      "epoch:0 step:546 [D loss: 0.647297, acc.: 62.50%] [G loss: 0.823026]\n",
      "epoch:0 step:547 [D loss: 0.648562, acc.: 67.97%] [G loss: 0.781874]\n",
      "epoch:0 step:548 [D loss: 0.624803, acc.: 64.06%] [G loss: 0.840091]\n",
      "epoch:0 step:549 [D loss: 0.648554, acc.: 65.62%] [G loss: 0.815771]\n",
      "epoch:0 step:550 [D loss: 0.631080, acc.: 68.75%] [G loss: 0.873323]\n",
      "epoch:0 step:551 [D loss: 0.641908, acc.: 63.28%] [G loss: 0.809720]\n",
      "epoch:0 step:552 [D loss: 0.644746, acc.: 64.84%] [G loss: 0.813897]\n",
      "epoch:0 step:553 [D loss: 0.666656, acc.: 61.72%] [G loss: 0.796598]\n",
      "epoch:0 step:554 [D loss: 0.598929, acc.: 71.09%] [G loss: 0.818002]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:555 [D loss: 0.615752, acc.: 68.75%] [G loss: 0.815398]\n",
      "epoch:0 step:556 [D loss: 0.679181, acc.: 60.94%] [G loss: 0.801733]\n",
      "epoch:0 step:557 [D loss: 0.607738, acc.: 65.62%] [G loss: 0.805555]\n",
      "epoch:0 step:558 [D loss: 0.657547, acc.: 60.94%] [G loss: 0.767754]\n",
      "epoch:0 step:559 [D loss: 0.623652, acc.: 64.84%] [G loss: 0.769578]\n",
      "epoch:0 step:560 [D loss: 0.648844, acc.: 65.62%] [G loss: 0.790892]\n",
      "epoch:0 step:561 [D loss: 0.652588, acc.: 60.94%] [G loss: 0.855223]\n",
      "epoch:0 step:562 [D loss: 0.634660, acc.: 60.16%] [G loss: 0.837658]\n",
      "epoch:0 step:563 [D loss: 0.600538, acc.: 67.19%] [G loss: 0.795045]\n",
      "epoch:0 step:564 [D loss: 0.604817, acc.: 66.41%] [G loss: 0.841152]\n",
      "epoch:0 step:565 [D loss: 0.618594, acc.: 64.06%] [G loss: 0.822790]\n",
      "epoch:0 step:566 [D loss: 0.639920, acc.: 67.19%] [G loss: 0.869177]\n",
      "epoch:0 step:567 [D loss: 0.641059, acc.: 64.06%] [G loss: 0.850609]\n",
      "epoch:0 step:568 [D loss: 0.658128, acc.: 57.03%] [G loss: 0.792265]\n",
      "epoch:0 step:569 [D loss: 0.623265, acc.: 61.72%] [G loss: 0.841947]\n",
      "epoch:0 step:570 [D loss: 0.663703, acc.: 60.94%] [G loss: 0.856722]\n",
      "epoch:0 step:571 [D loss: 0.642586, acc.: 68.75%] [G loss: 0.814663]\n",
      "epoch:0 step:572 [D loss: 0.633460, acc.: 69.53%] [G loss: 0.811968]\n",
      "epoch:0 step:573 [D loss: 0.659085, acc.: 57.81%] [G loss: 0.829284]\n",
      "epoch:0 step:574 [D loss: 0.625692, acc.: 64.84%] [G loss: 0.849910]\n",
      "epoch:0 step:575 [D loss: 0.621490, acc.: 60.16%] [G loss: 0.821923]\n",
      "epoch:0 step:576 [D loss: 0.661920, acc.: 54.69%] [G loss: 0.815363]\n",
      "epoch:0 step:577 [D loss: 0.651974, acc.: 57.81%] [G loss: 0.862382]\n",
      "epoch:0 step:578 [D loss: 0.634597, acc.: 65.62%] [G loss: 0.856873]\n",
      "epoch:0 step:579 [D loss: 0.671634, acc.: 52.34%] [G loss: 0.826347]\n",
      "epoch:0 step:580 [D loss: 0.695536, acc.: 53.12%] [G loss: 0.825462]\n",
      "epoch:0 step:581 [D loss: 0.686809, acc.: 54.69%] [G loss: 0.783917]\n",
      "epoch:0 step:582 [D loss: 0.637258, acc.: 62.50%] [G loss: 0.827911]\n",
      "epoch:0 step:583 [D loss: 0.670942, acc.: 55.47%] [G loss: 0.816429]\n",
      "epoch:0 step:584 [D loss: 0.647249, acc.: 60.94%] [G loss: 0.835291]\n",
      "epoch:0 step:585 [D loss: 0.635137, acc.: 63.28%] [G loss: 0.822418]\n",
      "epoch:0 step:586 [D loss: 0.669505, acc.: 60.94%] [G loss: 0.843912]\n",
      "epoch:0 step:587 [D loss: 0.643267, acc.: 60.94%] [G loss: 0.820112]\n",
      "epoch:0 step:588 [D loss: 0.606273, acc.: 66.41%] [G loss: 0.848355]\n",
      "epoch:0 step:589 [D loss: 0.618681, acc.: 62.50%] [G loss: 0.842344]\n",
      "epoch:0 step:590 [D loss: 0.681903, acc.: 53.91%] [G loss: 0.810325]\n",
      "epoch:0 step:591 [D loss: 0.655269, acc.: 57.03%] [G loss: 0.856103]\n",
      "epoch:0 step:592 [D loss: 0.655739, acc.: 58.59%] [G loss: 0.844295]\n",
      "epoch:0 step:593 [D loss: 0.670653, acc.: 60.94%] [G loss: 0.890988]\n",
      "epoch:0 step:594 [D loss: 0.664523, acc.: 60.16%] [G loss: 0.837599]\n",
      "epoch:0 step:595 [D loss: 0.644055, acc.: 67.97%] [G loss: 0.787838]\n",
      "epoch:0 step:596 [D loss: 0.653645, acc.: 64.06%] [G loss: 0.780264]\n",
      "epoch:0 step:597 [D loss: 0.641944, acc.: 64.84%] [G loss: 0.839344]\n",
      "epoch:0 step:598 [D loss: 0.653051, acc.: 68.75%] [G loss: 0.872548]\n",
      "epoch:0 step:599 [D loss: 0.633012, acc.: 60.94%] [G loss: 0.906332]\n",
      "epoch:0 step:600 [D loss: 0.707454, acc.: 53.12%] [G loss: 0.851955]\n",
      "##############\n",
      "[ 3.3900452   4.67776243  3.59962596  5.43988939  3.06038999 10.27426719\n",
      "  6.31613501  6.504254    4.8149344   8.14868929]\n",
      "##########\n",
      "epoch:0 step:601 [D loss: 0.640793, acc.: 60.16%] [G loss: 0.835834]\n",
      "epoch:0 step:602 [D loss: 0.641603, acc.: 61.72%] [G loss: 0.839485]\n",
      "epoch:0 step:603 [D loss: 0.633211, acc.: 66.41%] [G loss: 0.814314]\n",
      "epoch:0 step:604 [D loss: 0.637974, acc.: 57.81%] [G loss: 0.812504]\n",
      "epoch:0 step:605 [D loss: 0.659591, acc.: 64.06%] [G loss: 0.838386]\n",
      "epoch:0 step:606 [D loss: 0.632503, acc.: 64.84%] [G loss: 0.835034]\n",
      "epoch:0 step:607 [D loss: 0.623628, acc.: 60.16%] [G loss: 0.843336]\n",
      "epoch:0 step:608 [D loss: 0.630359, acc.: 63.28%] [G loss: 0.802991]\n",
      "epoch:0 step:609 [D loss: 0.637129, acc.: 64.84%] [G loss: 0.823688]\n",
      "epoch:0 step:610 [D loss: 0.679440, acc.: 61.72%] [G loss: 0.824082]\n",
      "epoch:0 step:611 [D loss: 0.645993, acc.: 64.06%] [G loss: 0.823673]\n",
      "epoch:0 step:612 [D loss: 0.607934, acc.: 71.88%] [G loss: 0.812631]\n",
      "epoch:0 step:613 [D loss: 0.646171, acc.: 62.50%] [G loss: 0.805452]\n",
      "epoch:0 step:614 [D loss: 0.632879, acc.: 64.84%] [G loss: 0.809489]\n",
      "epoch:0 step:615 [D loss: 0.629207, acc.: 65.62%] [G loss: 0.819111]\n",
      "epoch:0 step:616 [D loss: 0.623078, acc.: 64.06%] [G loss: 0.799022]\n",
      "epoch:0 step:617 [D loss: 0.647131, acc.: 64.06%] [G loss: 0.794521]\n",
      "epoch:0 step:618 [D loss: 0.628354, acc.: 63.28%] [G loss: 0.772033]\n",
      "epoch:0 step:619 [D loss: 0.622026, acc.: 60.16%] [G loss: 0.807631]\n",
      "epoch:0 step:620 [D loss: 0.632829, acc.: 60.94%] [G loss: 0.798665]\n",
      "epoch:0 step:621 [D loss: 0.637256, acc.: 67.97%] [G loss: 0.821060]\n",
      "epoch:0 step:622 [D loss: 0.611819, acc.: 72.66%] [G loss: 0.814642]\n",
      "epoch:0 step:623 [D loss: 0.656877, acc.: 64.06%] [G loss: 0.807603]\n",
      "epoch:0 step:624 [D loss: 0.643339, acc.: 56.25%] [G loss: 0.849406]\n",
      "epoch:0 step:625 [D loss: 0.628750, acc.: 71.09%] [G loss: 0.841763]\n",
      "epoch:0 step:626 [D loss: 0.653016, acc.: 60.16%] [G loss: 0.826268]\n",
      "epoch:0 step:627 [D loss: 0.615537, acc.: 61.72%] [G loss: 0.883817]\n",
      "epoch:0 step:628 [D loss: 0.700697, acc.: 53.12%] [G loss: 0.802877]\n",
      "epoch:0 step:629 [D loss: 0.633311, acc.: 64.06%] [G loss: 0.778280]\n",
      "epoch:0 step:630 [D loss: 0.649391, acc.: 65.62%] [G loss: 0.771842]\n",
      "epoch:0 step:631 [D loss: 0.609560, acc.: 64.06%] [G loss: 0.803921]\n",
      "epoch:0 step:632 [D loss: 0.689018, acc.: 60.16%] [G loss: 0.790244]\n",
      "epoch:0 step:633 [D loss: 0.629873, acc.: 64.06%] [G loss: 0.866914]\n",
      "epoch:0 step:634 [D loss: 0.634258, acc.: 67.19%] [G loss: 0.854724]\n",
      "epoch:0 step:635 [D loss: 0.632460, acc.: 64.84%] [G loss: 0.833177]\n",
      "epoch:0 step:636 [D loss: 0.662597, acc.: 61.72%] [G loss: 0.840932]\n",
      "epoch:0 step:637 [D loss: 0.621265, acc.: 65.62%] [G loss: 0.827982]\n",
      "epoch:0 step:638 [D loss: 0.666657, acc.: 58.59%] [G loss: 0.793951]\n",
      "epoch:0 step:639 [D loss: 0.690631, acc.: 57.03%] [G loss: 0.773088]\n",
      "epoch:0 step:640 [D loss: 0.650068, acc.: 60.94%] [G loss: 0.804655]\n",
      "epoch:0 step:641 [D loss: 0.674557, acc.: 63.28%] [G loss: 0.808845]\n",
      "epoch:0 step:642 [D loss: 0.673889, acc.: 55.47%] [G loss: 0.814614]\n",
      "epoch:0 step:643 [D loss: 0.575770, acc.: 74.22%] [G loss: 0.881556]\n",
      "epoch:0 step:644 [D loss: 0.661965, acc.: 60.94%] [G loss: 0.879527]\n",
      "epoch:0 step:645 [D loss: 0.675439, acc.: 55.47%] [G loss: 0.876115]\n",
      "epoch:0 step:646 [D loss: 0.642964, acc.: 64.06%] [G loss: 0.808528]\n",
      "epoch:0 step:647 [D loss: 0.653488, acc.: 60.94%] [G loss: 0.835041]\n",
      "epoch:0 step:648 [D loss: 0.643841, acc.: 59.38%] [G loss: 0.817539]\n",
      "epoch:0 step:649 [D loss: 0.633007, acc.: 65.62%] [G loss: 0.815915]\n",
      "epoch:0 step:650 [D loss: 0.648279, acc.: 59.38%] [G loss: 0.795589]\n",
      "epoch:0 step:651 [D loss: 0.675716, acc.: 60.94%] [G loss: 0.791359]\n",
      "epoch:0 step:652 [D loss: 0.609265, acc.: 67.97%] [G loss: 0.841407]\n",
      "epoch:0 step:653 [D loss: 0.624349, acc.: 68.75%] [G loss: 0.824980]\n",
      "epoch:0 step:654 [D loss: 0.625141, acc.: 68.75%] [G loss: 0.801183]\n",
      "epoch:0 step:655 [D loss: 0.645092, acc.: 68.75%] [G loss: 0.802066]\n",
      "epoch:0 step:656 [D loss: 0.640007, acc.: 66.41%] [G loss: 0.815711]\n",
      "epoch:0 step:657 [D loss: 0.634775, acc.: 65.62%] [G loss: 0.801599]\n",
      "epoch:0 step:658 [D loss: 0.630521, acc.: 63.28%] [G loss: 0.827420]\n",
      "epoch:0 step:659 [D loss: 0.598540, acc.: 71.88%] [G loss: 0.838640]\n",
      "epoch:0 step:660 [D loss: 0.628582, acc.: 69.53%] [G loss: 0.842841]\n",
      "epoch:0 step:661 [D loss: 0.643568, acc.: 65.62%] [G loss: 0.810832]\n",
      "epoch:0 step:662 [D loss: 0.616169, acc.: 74.22%] [G loss: 0.833098]\n",
      "epoch:0 step:663 [D loss: 0.655476, acc.: 66.41%] [G loss: 0.884103]\n",
      "epoch:0 step:664 [D loss: 0.630313, acc.: 66.41%] [G loss: 0.914779]\n",
      "epoch:0 step:665 [D loss: 0.689806, acc.: 57.03%] [G loss: 0.859896]\n",
      "epoch:0 step:666 [D loss: 0.637031, acc.: 70.31%] [G loss: 0.853879]\n",
      "epoch:0 step:667 [D loss: 0.630372, acc.: 65.62%] [G loss: 0.806357]\n",
      "epoch:0 step:668 [D loss: 0.641148, acc.: 64.06%] [G loss: 0.809698]\n",
      "epoch:0 step:669 [D loss: 0.611288, acc.: 64.84%] [G loss: 0.803766]\n",
      "epoch:0 step:670 [D loss: 0.689679, acc.: 58.59%] [G loss: 0.768081]\n",
      "epoch:0 step:671 [D loss: 0.646695, acc.: 62.50%] [G loss: 0.810812]\n",
      "epoch:0 step:672 [D loss: 0.621512, acc.: 64.84%] [G loss: 0.815778]\n",
      "epoch:0 step:673 [D loss: 0.633811, acc.: 64.06%] [G loss: 0.805998]\n",
      "epoch:0 step:674 [D loss: 0.658642, acc.: 67.97%] [G loss: 0.837790]\n",
      "epoch:0 step:675 [D loss: 0.692128, acc.: 57.03%] [G loss: 0.834021]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:676 [D loss: 0.619233, acc.: 71.88%] [G loss: 0.821668]\n",
      "epoch:0 step:677 [D loss: 0.661239, acc.: 54.69%] [G loss: 0.785918]\n",
      "epoch:0 step:678 [D loss: 0.645179, acc.: 64.06%] [G loss: 0.844190]\n",
      "epoch:0 step:679 [D loss: 0.609523, acc.: 64.06%] [G loss: 0.843786]\n",
      "epoch:0 step:680 [D loss: 0.657784, acc.: 55.47%] [G loss: 0.832568]\n",
      "epoch:0 step:681 [D loss: 0.644213, acc.: 60.16%] [G loss: 0.834971]\n",
      "epoch:0 step:682 [D loss: 0.638375, acc.: 59.38%] [G loss: 0.799500]\n",
      "epoch:0 step:683 [D loss: 0.617710, acc.: 64.06%] [G loss: 0.812148]\n",
      "epoch:0 step:684 [D loss: 0.633198, acc.: 60.16%] [G loss: 0.866440]\n",
      "epoch:0 step:685 [D loss: 0.638460, acc.: 65.62%] [G loss: 0.860610]\n",
      "epoch:0 step:686 [D loss: 0.689270, acc.: 57.03%] [G loss: 0.822902]\n",
      "epoch:0 step:687 [D loss: 0.629675, acc.: 68.75%] [G loss: 0.840198]\n",
      "epoch:0 step:688 [D loss: 0.653273, acc.: 56.25%] [G loss: 0.857396]\n",
      "epoch:0 step:689 [D loss: 0.616236, acc.: 67.19%] [G loss: 0.832632]\n",
      "epoch:0 step:690 [D loss: 0.623157, acc.: 65.62%] [G loss: 0.802659]\n",
      "epoch:0 step:691 [D loss: 0.647372, acc.: 60.16%] [G loss: 0.777103]\n",
      "epoch:0 step:692 [D loss: 0.644109, acc.: 61.72%] [G loss: 0.777786]\n",
      "epoch:0 step:693 [D loss: 0.623132, acc.: 64.84%] [G loss: 0.840093]\n",
      "epoch:0 step:694 [D loss: 0.642946, acc.: 62.50%] [G loss: 0.841787]\n",
      "epoch:0 step:695 [D loss: 0.626400, acc.: 60.16%] [G loss: 0.851705]\n",
      "epoch:0 step:696 [D loss: 0.649406, acc.: 64.84%] [G loss: 0.839210]\n",
      "epoch:0 step:697 [D loss: 0.657343, acc.: 59.38%] [G loss: 0.827658]\n",
      "epoch:0 step:698 [D loss: 0.616003, acc.: 67.19%] [G loss: 0.824076]\n",
      "epoch:0 step:699 [D loss: 0.620294, acc.: 67.97%] [G loss: 0.863294]\n",
      "epoch:0 step:700 [D loss: 0.620027, acc.: 64.84%] [G loss: 0.818084]\n",
      "epoch:0 step:701 [D loss: 0.633356, acc.: 58.59%] [G loss: 0.799667]\n",
      "epoch:0 step:702 [D loss: 0.634267, acc.: 61.72%] [G loss: 0.838774]\n",
      "epoch:0 step:703 [D loss: 0.652030, acc.: 57.81%] [G loss: 0.835366]\n",
      "epoch:0 step:704 [D loss: 0.626192, acc.: 63.28%] [G loss: 0.872407]\n",
      "epoch:0 step:705 [D loss: 0.643937, acc.: 61.72%] [G loss: 0.788186]\n",
      "epoch:0 step:706 [D loss: 0.649972, acc.: 67.19%] [G loss: 0.771334]\n",
      "epoch:0 step:707 [D loss: 0.663232, acc.: 55.47%] [G loss: 0.758067]\n",
      "epoch:0 step:708 [D loss: 0.649591, acc.: 62.50%] [G loss: 0.817915]\n",
      "epoch:0 step:709 [D loss: 0.683295, acc.: 50.78%] [G loss: 0.873725]\n",
      "epoch:0 step:710 [D loss: 0.623548, acc.: 62.50%] [G loss: 0.848974]\n",
      "epoch:0 step:711 [D loss: 0.642649, acc.: 60.94%] [G loss: 0.853592]\n",
      "epoch:0 step:712 [D loss: 0.609965, acc.: 65.62%] [G loss: 0.800670]\n",
      "epoch:0 step:713 [D loss: 0.606094, acc.: 72.66%] [G loss: 0.822221]\n",
      "epoch:0 step:714 [D loss: 0.647643, acc.: 64.84%] [G loss: 0.810283]\n",
      "epoch:0 step:715 [D loss: 0.629515, acc.: 65.62%] [G loss: 0.819489]\n",
      "epoch:0 step:716 [D loss: 0.619056, acc.: 67.97%] [G loss: 0.809658]\n",
      "epoch:0 step:717 [D loss: 0.629828, acc.: 65.62%] [G loss: 0.795848]\n",
      "epoch:0 step:718 [D loss: 0.627648, acc.: 63.28%] [G loss: 0.829025]\n",
      "epoch:0 step:719 [D loss: 0.610951, acc.: 70.31%] [G loss: 0.825361]\n",
      "epoch:0 step:720 [D loss: 0.632564, acc.: 68.75%] [G loss: 0.824762]\n",
      "epoch:0 step:721 [D loss: 0.628723, acc.: 60.94%] [G loss: 0.850524]\n",
      "epoch:0 step:722 [D loss: 0.635443, acc.: 64.06%] [G loss: 0.826534]\n",
      "epoch:0 step:723 [D loss: 0.657285, acc.: 54.69%] [G loss: 0.876266]\n",
      "epoch:0 step:724 [D loss: 0.629342, acc.: 67.19%] [G loss: 0.777458]\n",
      "epoch:0 step:725 [D loss: 0.620908, acc.: 67.97%] [G loss: 0.859866]\n",
      "epoch:0 step:726 [D loss: 0.599103, acc.: 68.75%] [G loss: 0.883788]\n",
      "epoch:0 step:727 [D loss: 0.647981, acc.: 60.16%] [G loss: 0.910072]\n",
      "epoch:0 step:728 [D loss: 0.611058, acc.: 64.84%] [G loss: 0.865976]\n",
      "epoch:0 step:729 [D loss: 0.615745, acc.: 68.75%] [G loss: 0.824418]\n",
      "epoch:0 step:730 [D loss: 0.597878, acc.: 64.84%] [G loss: 0.797781]\n",
      "epoch:0 step:731 [D loss: 0.671854, acc.: 57.03%] [G loss: 0.879694]\n",
      "epoch:0 step:732 [D loss: 0.623223, acc.: 60.94%] [G loss: 0.900045]\n",
      "epoch:0 step:733 [D loss: 0.640653, acc.: 61.72%] [G loss: 0.888913]\n",
      "epoch:0 step:734 [D loss: 0.591788, acc.: 67.97%] [G loss: 0.861016]\n",
      "epoch:0 step:735 [D loss: 0.599838, acc.: 67.97%] [G loss: 0.860667]\n",
      "epoch:0 step:736 [D loss: 0.648551, acc.: 55.47%] [G loss: 0.853743]\n",
      "epoch:0 step:737 [D loss: 0.634152, acc.: 64.06%] [G loss: 0.843056]\n",
      "epoch:0 step:738 [D loss: 0.628565, acc.: 64.06%] [G loss: 0.858610]\n",
      "epoch:0 step:739 [D loss: 0.628799, acc.: 64.06%] [G loss: 0.843514]\n",
      "epoch:0 step:740 [D loss: 0.659054, acc.: 59.38%] [G loss: 0.865333]\n",
      "epoch:0 step:741 [D loss: 0.618500, acc.: 69.53%] [G loss: 0.838027]\n",
      "epoch:0 step:742 [D loss: 0.646030, acc.: 59.38%] [G loss: 0.841524]\n",
      "epoch:0 step:743 [D loss: 0.611011, acc.: 70.31%] [G loss: 0.832265]\n",
      "epoch:0 step:744 [D loss: 0.622066, acc.: 70.31%] [G loss: 0.840909]\n",
      "epoch:0 step:745 [D loss: 0.667258, acc.: 57.03%] [G loss: 0.885082]\n",
      "epoch:0 step:746 [D loss: 0.654755, acc.: 56.25%] [G loss: 0.843418]\n",
      "epoch:0 step:747 [D loss: 0.613707, acc.: 67.97%] [G loss: 0.873860]\n",
      "epoch:0 step:748 [D loss: 0.631264, acc.: 62.50%] [G loss: 0.818716]\n",
      "epoch:0 step:749 [D loss: 0.644674, acc.: 62.50%] [G loss: 0.799613]\n",
      "epoch:0 step:750 [D loss: 0.635628, acc.: 58.59%] [G loss: 0.819672]\n",
      "epoch:0 step:751 [D loss: 0.628364, acc.: 67.19%] [G loss: 0.852580]\n",
      "epoch:0 step:752 [D loss: 0.611830, acc.: 64.06%] [G loss: 0.839009]\n",
      "epoch:0 step:753 [D loss: 0.622340, acc.: 62.50%] [G loss: 0.841760]\n",
      "epoch:0 step:754 [D loss: 0.610425, acc.: 64.06%] [G loss: 0.845727]\n",
      "epoch:0 step:755 [D loss: 0.666507, acc.: 60.16%] [G loss: 0.850959]\n",
      "epoch:0 step:756 [D loss: 0.641895, acc.: 60.94%] [G loss: 0.872533]\n",
      "epoch:0 step:757 [D loss: 0.670559, acc.: 52.34%] [G loss: 0.816155]\n",
      "epoch:0 step:758 [D loss: 0.643446, acc.: 60.94%] [G loss: 0.849242]\n",
      "epoch:0 step:759 [D loss: 0.629914, acc.: 61.72%] [G loss: 0.828925]\n",
      "epoch:0 step:760 [D loss: 0.657629, acc.: 62.50%] [G loss: 0.825038]\n",
      "epoch:0 step:761 [D loss: 0.657776, acc.: 60.94%] [G loss: 0.800008]\n",
      "epoch:0 step:762 [D loss: 0.671155, acc.: 57.81%] [G loss: 0.798067]\n",
      "epoch:0 step:763 [D loss: 0.638315, acc.: 62.50%] [G loss: 0.783701]\n",
      "epoch:0 step:764 [D loss: 0.652312, acc.: 62.50%] [G loss: 0.831671]\n",
      "epoch:0 step:765 [D loss: 0.647379, acc.: 60.94%] [G loss: 0.883505]\n",
      "epoch:0 step:766 [D loss: 0.666886, acc.: 54.69%] [G loss: 0.838934]\n",
      "epoch:0 step:767 [D loss: 0.650125, acc.: 61.72%] [G loss: 0.845544]\n",
      "epoch:0 step:768 [D loss: 0.654040, acc.: 62.50%] [G loss: 0.839284]\n",
      "epoch:0 step:769 [D loss: 0.654908, acc.: 63.28%] [G loss: 0.854807]\n",
      "epoch:0 step:770 [D loss: 0.650862, acc.: 60.94%] [G loss: 0.834458]\n",
      "epoch:0 step:771 [D loss: 0.631233, acc.: 66.41%] [G loss: 0.848941]\n",
      "epoch:0 step:772 [D loss: 0.648170, acc.: 60.94%] [G loss: 0.816514]\n",
      "epoch:0 step:773 [D loss: 0.641689, acc.: 64.06%] [G loss: 0.819671]\n",
      "epoch:0 step:774 [D loss: 0.654296, acc.: 67.19%] [G loss: 0.845764]\n",
      "epoch:0 step:775 [D loss: 0.637942, acc.: 64.06%] [G loss: 0.830749]\n",
      "epoch:0 step:776 [D loss: 0.665917, acc.: 57.81%] [G loss: 0.820734]\n",
      "epoch:0 step:777 [D loss: 0.624507, acc.: 64.84%] [G loss: 0.819796]\n",
      "epoch:0 step:778 [D loss: 0.618681, acc.: 65.62%] [G loss: 0.859334]\n",
      "epoch:0 step:779 [D loss: 0.641765, acc.: 58.59%] [G loss: 0.834423]\n",
      "epoch:0 step:780 [D loss: 0.652930, acc.: 64.06%] [G loss: 0.832988]\n",
      "epoch:0 step:781 [D loss: 0.673990, acc.: 55.47%] [G loss: 0.804359]\n",
      "epoch:0 step:782 [D loss: 0.641017, acc.: 57.81%] [G loss: 0.821581]\n",
      "epoch:0 step:783 [D loss: 0.635245, acc.: 59.38%] [G loss: 0.795454]\n",
      "epoch:0 step:784 [D loss: 0.638645, acc.: 55.47%] [G loss: 0.815859]\n",
      "epoch:0 step:785 [D loss: 0.683454, acc.: 49.22%] [G loss: 0.832271]\n",
      "epoch:0 step:786 [D loss: 0.620450, acc.: 71.09%] [G loss: 0.842575]\n",
      "epoch:0 step:787 [D loss: 0.658125, acc.: 60.94%] [G loss: 0.802146]\n",
      "epoch:0 step:788 [D loss: 0.610396, acc.: 67.19%] [G loss: 0.795313]\n",
      "epoch:0 step:789 [D loss: 0.645975, acc.: 58.59%] [G loss: 0.788405]\n",
      "epoch:0 step:790 [D loss: 0.633213, acc.: 67.97%] [G loss: 0.819748]\n",
      "epoch:0 step:791 [D loss: 0.672639, acc.: 55.47%] [G loss: 0.821493]\n",
      "epoch:0 step:792 [D loss: 0.630770, acc.: 66.41%] [G loss: 0.844156]\n",
      "epoch:0 step:793 [D loss: 0.647682, acc.: 60.16%] [G loss: 0.824181]\n",
      "epoch:0 step:794 [D loss: 0.659630, acc.: 60.94%] [G loss: 0.811614]\n",
      "epoch:0 step:795 [D loss: 0.644628, acc.: 63.28%] [G loss: 0.833752]\n",
      "epoch:0 step:796 [D loss: 0.615262, acc.: 63.28%] [G loss: 0.836468]\n",
      "epoch:0 step:797 [D loss: 0.679258, acc.: 56.25%] [G loss: 0.785983]\n",
      "epoch:0 step:798 [D loss: 0.597551, acc.: 71.09%] [G loss: 0.785193]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:799 [D loss: 0.625986, acc.: 65.62%] [G loss: 0.770214]\n",
      "epoch:0 step:800 [D loss: 0.652628, acc.: 64.84%] [G loss: 0.761989]\n",
      "##############\n",
      "[ 3.47571899  4.65767558  3.73890694  4.93435777  3.08365415 10.27426719\n",
      "  4.64120131  6.15124862  4.81324489  8.14868929]\n",
      "##########\n",
      "epoch:0 step:801 [D loss: 0.651909, acc.: 61.72%] [G loss: 0.813924]\n",
      "epoch:0 step:802 [D loss: 0.644621, acc.: 60.94%] [G loss: 0.826006]\n",
      "epoch:0 step:803 [D loss: 0.659046, acc.: 55.47%] [G loss: 0.781834]\n",
      "epoch:0 step:804 [D loss: 0.640208, acc.: 66.41%] [G loss: 0.860828]\n",
      "epoch:0 step:805 [D loss: 0.636661, acc.: 64.84%] [G loss: 0.793928]\n",
      "epoch:0 step:806 [D loss: 0.650815, acc.: 60.94%] [G loss: 0.796374]\n",
      "epoch:0 step:807 [D loss: 0.616702, acc.: 69.53%] [G loss: 0.817377]\n",
      "epoch:0 step:808 [D loss: 0.635750, acc.: 67.19%] [G loss: 0.833994]\n",
      "epoch:0 step:809 [D loss: 0.628693, acc.: 60.94%] [G loss: 0.852268]\n",
      "epoch:0 step:810 [D loss: 0.615200, acc.: 64.06%] [G loss: 0.879328]\n",
      "epoch:0 step:811 [D loss: 0.619132, acc.: 65.62%] [G loss: 0.865702]\n",
      "epoch:0 step:812 [D loss: 0.676934, acc.: 56.25%] [G loss: 0.900078]\n",
      "epoch:0 step:813 [D loss: 0.621067, acc.: 67.19%] [G loss: 0.870222]\n",
      "epoch:0 step:814 [D loss: 0.607402, acc.: 67.97%] [G loss: 0.878254]\n",
      "epoch:0 step:815 [D loss: 0.630759, acc.: 67.19%] [G loss: 0.851626]\n",
      "epoch:0 step:816 [D loss: 0.591412, acc.: 67.97%] [G loss: 0.840761]\n",
      "epoch:0 step:817 [D loss: 0.655245, acc.: 64.06%] [G loss: 0.874012]\n",
      "epoch:0 step:818 [D loss: 0.651842, acc.: 57.03%] [G loss: 0.840584]\n",
      "epoch:0 step:819 [D loss: 0.633943, acc.: 64.06%] [G loss: 0.806631]\n",
      "epoch:0 step:820 [D loss: 0.611712, acc.: 71.88%] [G loss: 0.795257]\n",
      "epoch:0 step:821 [D loss: 0.672257, acc.: 53.12%] [G loss: 0.806586]\n",
      "epoch:0 step:822 [D loss: 0.622449, acc.: 67.97%] [G loss: 0.843318]\n",
      "epoch:0 step:823 [D loss: 0.631241, acc.: 67.19%] [G loss: 0.782702]\n",
      "epoch:0 step:824 [D loss: 0.651273, acc.: 60.94%] [G loss: 0.841807]\n",
      "epoch:0 step:825 [D loss: 0.651093, acc.: 63.28%] [G loss: 0.879964]\n",
      "epoch:0 step:826 [D loss: 0.615009, acc.: 64.06%] [G loss: 0.874663]\n",
      "epoch:0 step:827 [D loss: 0.611286, acc.: 70.31%] [G loss: 0.864661]\n",
      "epoch:0 step:828 [D loss: 0.659072, acc.: 64.06%] [G loss: 0.833532]\n",
      "epoch:0 step:829 [D loss: 0.646837, acc.: 64.06%] [G loss: 0.837570]\n",
      "epoch:0 step:830 [D loss: 0.634085, acc.: 63.28%] [G loss: 0.852685]\n",
      "epoch:0 step:831 [D loss: 0.602304, acc.: 74.22%] [G loss: 0.857405]\n",
      "epoch:0 step:832 [D loss: 0.628759, acc.: 62.50%] [G loss: 0.840587]\n",
      "epoch:0 step:833 [D loss: 0.684487, acc.: 55.47%] [G loss: 0.833913]\n",
      "epoch:0 step:834 [D loss: 0.619470, acc.: 68.75%] [G loss: 0.795372]\n",
      "epoch:0 step:835 [D loss: 0.641512, acc.: 61.72%] [G loss: 0.864590]\n",
      "epoch:0 step:836 [D loss: 0.605049, acc.: 61.72%] [G loss: 0.877348]\n",
      "epoch:0 step:837 [D loss: 0.612917, acc.: 65.62%] [G loss: 0.841375]\n",
      "epoch:0 step:838 [D loss: 0.668733, acc.: 56.25%] [G loss: 0.827408]\n",
      "epoch:0 step:839 [D loss: 0.642179, acc.: 57.81%] [G loss: 0.868514]\n",
      "epoch:0 step:840 [D loss: 0.630871, acc.: 64.84%] [G loss: 0.886102]\n",
      "epoch:0 step:841 [D loss: 0.627298, acc.: 63.28%] [G loss: 0.850858]\n",
      "epoch:0 step:842 [D loss: 0.658954, acc.: 62.50%] [G loss: 0.848595]\n",
      "epoch:0 step:843 [D loss: 0.651149, acc.: 64.84%] [G loss: 0.858609]\n",
      "epoch:0 step:844 [D loss: 0.625804, acc.: 63.28%] [G loss: 0.836903]\n",
      "epoch:0 step:845 [D loss: 0.640577, acc.: 60.94%] [G loss: 0.805620]\n",
      "epoch:0 step:846 [D loss: 0.654441, acc.: 60.94%] [G loss: 0.836038]\n",
      "epoch:0 step:847 [D loss: 0.640063, acc.: 60.16%] [G loss: 0.816202]\n",
      "epoch:0 step:848 [D loss: 0.645988, acc.: 60.94%] [G loss: 0.848229]\n",
      "epoch:0 step:849 [D loss: 0.626783, acc.: 66.41%] [G loss: 0.825662]\n",
      "epoch:0 step:850 [D loss: 0.627622, acc.: 61.72%] [G loss: 0.800928]\n",
      "epoch:0 step:851 [D loss: 0.645798, acc.: 56.25%] [G loss: 0.844962]\n",
      "epoch:0 step:852 [D loss: 0.626390, acc.: 64.84%] [G loss: 0.887735]\n",
      "epoch:0 step:853 [D loss: 0.614009, acc.: 67.19%] [G loss: 0.876094]\n",
      "epoch:0 step:854 [D loss: 0.643009, acc.: 66.41%] [G loss: 0.820628]\n",
      "epoch:0 step:855 [D loss: 0.632940, acc.: 64.06%] [G loss: 0.837705]\n",
      "epoch:0 step:856 [D loss: 0.634348, acc.: 61.72%] [G loss: 0.831527]\n",
      "epoch:0 step:857 [D loss: 0.628831, acc.: 64.84%] [G loss: 0.829453]\n",
      "epoch:0 step:858 [D loss: 0.609354, acc.: 67.19%] [G loss: 0.852435]\n",
      "epoch:0 step:859 [D loss: 0.601069, acc.: 70.31%] [G loss: 0.908205]\n",
      "epoch:0 step:860 [D loss: 0.641050, acc.: 65.62%] [G loss: 0.905167]\n",
      "epoch:0 step:861 [D loss: 0.614713, acc.: 59.38%] [G loss: 0.852268]\n",
      "epoch:0 step:862 [D loss: 0.627882, acc.: 57.03%] [G loss: 0.836195]\n",
      "epoch:0 step:863 [D loss: 0.613640, acc.: 67.19%] [G loss: 0.854782]\n",
      "epoch:0 step:864 [D loss: 0.652161, acc.: 61.72%] [G loss: 0.857887]\n",
      "epoch:0 step:865 [D loss: 0.641218, acc.: 56.25%] [G loss: 0.851887]\n",
      "epoch:0 step:866 [D loss: 0.641987, acc.: 60.94%] [G loss: 0.820601]\n",
      "epoch:0 step:867 [D loss: 0.606593, acc.: 65.62%] [G loss: 0.857333]\n",
      "epoch:0 step:868 [D loss: 0.593205, acc.: 70.31%] [G loss: 0.832711]\n",
      "epoch:0 step:869 [D loss: 0.590941, acc.: 65.62%] [G loss: 0.875763]\n",
      "epoch:0 step:870 [D loss: 0.601505, acc.: 65.62%] [G loss: 0.882077]\n",
      "epoch:0 step:871 [D loss: 0.641373, acc.: 59.38%] [G loss: 0.819638]\n",
      "epoch:0 step:872 [D loss: 0.641083, acc.: 60.94%] [G loss: 0.833191]\n",
      "epoch:0 step:873 [D loss: 0.619291, acc.: 63.28%] [G loss: 0.813994]\n",
      "epoch:0 step:874 [D loss: 0.655342, acc.: 58.59%] [G loss: 0.842548]\n",
      "epoch:0 step:875 [D loss: 0.618558, acc.: 66.41%] [G loss: 0.833520]\n",
      "epoch:0 step:876 [D loss: 0.650270, acc.: 60.16%] [G loss: 0.830812]\n",
      "epoch:0 step:877 [D loss: 0.605284, acc.: 63.28%] [G loss: 0.863608]\n",
      "epoch:0 step:878 [D loss: 0.631226, acc.: 61.72%] [G loss: 0.844911]\n",
      "epoch:0 step:879 [D loss: 0.608534, acc.: 67.19%] [G loss: 0.802096]\n",
      "epoch:0 step:880 [D loss: 0.603126, acc.: 64.06%] [G loss: 0.861442]\n",
      "epoch:0 step:881 [D loss: 0.620855, acc.: 66.41%] [G loss: 0.829080]\n",
      "epoch:0 step:882 [D loss: 0.603279, acc.: 61.72%] [G loss: 0.887999]\n",
      "epoch:0 step:883 [D loss: 0.605421, acc.: 63.28%] [G loss: 0.866497]\n",
      "epoch:0 step:884 [D loss: 0.663545, acc.: 59.38%] [G loss: 0.874813]\n",
      "epoch:0 step:885 [D loss: 0.618236, acc.: 64.06%] [G loss: 0.867347]\n",
      "epoch:0 step:886 [D loss: 0.612905, acc.: 66.41%] [G loss: 0.891141]\n",
      "epoch:0 step:887 [D loss: 0.616685, acc.: 65.62%] [G loss: 0.832469]\n",
      "epoch:0 step:888 [D loss: 0.601697, acc.: 64.84%] [G loss: 0.855297]\n",
      "epoch:0 step:889 [D loss: 0.610455, acc.: 66.41%] [G loss: 0.853031]\n",
      "epoch:0 step:890 [D loss: 0.607268, acc.: 70.31%] [G loss: 0.865826]\n",
      "epoch:0 step:891 [D loss: 0.657632, acc.: 58.59%] [G loss: 0.916124]\n",
      "epoch:0 step:892 [D loss: 0.619077, acc.: 57.81%] [G loss: 0.903814]\n",
      "epoch:0 step:893 [D loss: 0.609712, acc.: 65.62%] [G loss: 0.894938]\n",
      "epoch:0 step:894 [D loss: 0.664862, acc.: 55.47%] [G loss: 0.814538]\n",
      "epoch:0 step:895 [D loss: 0.608568, acc.: 63.28%] [G loss: 0.844995]\n",
      "epoch:0 step:896 [D loss: 0.646745, acc.: 67.97%] [G loss: 0.960081]\n",
      "epoch:0 step:897 [D loss: 0.637420, acc.: 64.06%] [G loss: 0.941193]\n",
      "epoch:0 step:898 [D loss: 0.591343, acc.: 68.75%] [G loss: 0.943287]\n",
      "epoch:0 step:899 [D loss: 0.654492, acc.: 58.59%] [G loss: 0.915658]\n",
      "epoch:0 step:900 [D loss: 0.624092, acc.: 64.06%] [G loss: 0.886984]\n",
      "epoch:0 step:901 [D loss: 0.601161, acc.: 70.31%] [G loss: 0.910822]\n",
      "epoch:0 step:902 [D loss: 0.601962, acc.: 67.19%] [G loss: 0.900785]\n",
      "epoch:0 step:903 [D loss: 0.586180, acc.: 78.12%] [G loss: 0.884767]\n",
      "epoch:0 step:904 [D loss: 0.583991, acc.: 71.09%] [G loss: 0.917587]\n",
      "epoch:0 step:905 [D loss: 0.599121, acc.: 71.09%] [G loss: 0.917816]\n",
      "epoch:0 step:906 [D loss: 0.578577, acc.: 77.34%] [G loss: 0.897771]\n",
      "epoch:0 step:907 [D loss: 0.648157, acc.: 60.94%] [G loss: 0.831173]\n",
      "epoch:0 step:908 [D loss: 0.657115, acc.: 56.25%] [G loss: 0.902397]\n",
      "epoch:0 step:909 [D loss: 0.648748, acc.: 58.59%] [G loss: 0.868887]\n",
      "epoch:0 step:910 [D loss: 0.620153, acc.: 71.88%] [G loss: 0.880161]\n",
      "epoch:0 step:911 [D loss: 0.661148, acc.: 61.72%] [G loss: 0.853552]\n",
      "epoch:0 step:912 [D loss: 0.639371, acc.: 66.41%] [G loss: 0.875992]\n",
      "epoch:0 step:913 [D loss: 0.643603, acc.: 64.84%] [G loss: 0.847357]\n",
      "epoch:0 step:914 [D loss: 0.644675, acc.: 60.16%] [G loss: 0.877558]\n",
      "epoch:0 step:915 [D loss: 0.593605, acc.: 67.19%] [G loss: 0.792089]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:0 step:916 [D loss: 0.609615, acc.: 63.28%] [G loss: 0.874112]\n",
      "epoch:0 step:917 [D loss: 0.668601, acc.: 64.84%] [G loss: 0.810807]\n",
      "epoch:0 step:918 [D loss: 0.664041, acc.: 60.16%] [G loss: 0.818791]\n",
      "epoch:0 step:919 [D loss: 0.602464, acc.: 68.75%] [G loss: 0.846308]\n",
      "epoch:0 step:920 [D loss: 0.632740, acc.: 61.72%] [G loss: 0.813640]\n",
      "epoch:0 step:921 [D loss: 0.666133, acc.: 63.28%] [G loss: 0.821329]\n",
      "epoch:0 step:922 [D loss: 0.657166, acc.: 56.25%] [G loss: 0.834905]\n",
      "epoch:0 step:923 [D loss: 0.628073, acc.: 64.06%] [G loss: 0.856633]\n",
      "epoch:0 step:924 [D loss: 0.639539, acc.: 65.62%] [G loss: 0.869519]\n",
      "epoch:0 step:925 [D loss: 0.642709, acc.: 62.50%] [G loss: 0.812503]\n",
      "epoch:0 step:926 [D loss: 0.598832, acc.: 66.41%] [G loss: 0.877479]\n",
      "epoch:0 step:927 [D loss: 0.656644, acc.: 62.50%] [G loss: 0.849757]\n",
      "epoch:0 step:928 [D loss: 0.653548, acc.: 57.03%] [G loss: 0.891178]\n",
      "epoch:0 step:929 [D loss: 0.636956, acc.: 64.84%] [G loss: 0.872535]\n",
      "epoch:0 step:930 [D loss: 0.619982, acc.: 65.62%] [G loss: 0.901536]\n",
      "epoch:0 step:931 [D loss: 0.614279, acc.: 64.84%] [G loss: 0.815373]\n",
      "epoch:0 step:932 [D loss: 0.618402, acc.: 66.41%] [G loss: 0.844397]\n",
      "epoch:0 step:933 [D loss: 0.621245, acc.: 61.72%] [G loss: 0.819809]\n",
      "epoch:0 step:934 [D loss: 0.641780, acc.: 62.50%] [G loss: 0.879898]\n",
      "epoch:0 step:935 [D loss: 0.613331, acc.: 66.41%] [G loss: 0.893613]\n",
      "epoch:0 step:936 [D loss: 0.645033, acc.: 58.59%] [G loss: 0.838108]\n",
      "epoch:0 step:937 [D loss: 0.593239, acc.: 68.75%] [G loss: 0.901541]\n",
      "epoch:1 step:938 [D loss: 0.628305, acc.: 60.94%] [G loss: 0.794865]\n",
      "epoch:1 step:939 [D loss: 0.662855, acc.: 59.38%] [G loss: 0.828738]\n",
      "epoch:1 step:940 [D loss: 0.607825, acc.: 65.62%] [G loss: 0.909591]\n",
      "epoch:1 step:941 [D loss: 0.623191, acc.: 64.06%] [G loss: 0.867373]\n",
      "epoch:1 step:942 [D loss: 0.633062, acc.: 60.16%] [G loss: 0.866950]\n",
      "epoch:1 step:943 [D loss: 0.666483, acc.: 57.03%] [G loss: 0.804207]\n",
      "epoch:1 step:944 [D loss: 0.611207, acc.: 66.41%] [G loss: 0.838827]\n",
      "epoch:1 step:945 [D loss: 0.642441, acc.: 59.38%] [G loss: 0.837837]\n",
      "epoch:1 step:946 [D loss: 0.590963, acc.: 69.53%] [G loss: 0.860479]\n",
      "epoch:1 step:947 [D loss: 0.592518, acc.: 71.88%] [G loss: 0.881295]\n",
      "epoch:1 step:948 [D loss: 0.605947, acc.: 65.62%] [G loss: 0.878260]\n",
      "epoch:1 step:949 [D loss: 0.578542, acc.: 70.31%] [G loss: 0.896807]\n",
      "epoch:1 step:950 [D loss: 0.588358, acc.: 67.19%] [G loss: 0.928775]\n",
      "epoch:1 step:951 [D loss: 0.638035, acc.: 61.72%] [G loss: 0.906092]\n",
      "epoch:1 step:952 [D loss: 0.619745, acc.: 66.41%] [G loss: 0.836455]\n",
      "epoch:1 step:953 [D loss: 0.615837, acc.: 64.06%] [G loss: 0.844438]\n",
      "epoch:1 step:954 [D loss: 0.591545, acc.: 69.53%] [G loss: 0.800669]\n",
      "epoch:1 step:955 [D loss: 0.658550, acc.: 57.81%] [G loss: 0.847270]\n",
      "epoch:1 step:956 [D loss: 0.626136, acc.: 63.28%] [G loss: 0.889815]\n",
      "epoch:1 step:957 [D loss: 0.667657, acc.: 56.25%] [G loss: 0.833271]\n",
      "epoch:1 step:958 [D loss: 0.590897, acc.: 71.88%] [G loss: 0.858891]\n",
      "epoch:1 step:959 [D loss: 0.629147, acc.: 66.41%] [G loss: 0.828508]\n",
      "epoch:1 step:960 [D loss: 0.654012, acc.: 63.28%] [G loss: 0.835011]\n",
      "epoch:1 step:961 [D loss: 0.625498, acc.: 57.81%] [G loss: 0.872492]\n",
      "epoch:1 step:962 [D loss: 0.611614, acc.: 66.41%] [G loss: 0.856371]\n",
      "epoch:1 step:963 [D loss: 0.612897, acc.: 66.41%] [G loss: 0.845785]\n",
      "epoch:1 step:964 [D loss: 0.624220, acc.: 62.50%] [G loss: 0.840756]\n",
      "epoch:1 step:965 [D loss: 0.627039, acc.: 61.72%] [G loss: 0.880986]\n",
      "epoch:1 step:966 [D loss: 0.647233, acc.: 57.03%] [G loss: 0.826827]\n",
      "epoch:1 step:967 [D loss: 0.628394, acc.: 64.84%] [G loss: 0.828728]\n",
      "epoch:1 step:968 [D loss: 0.661639, acc.: 54.69%] [G loss: 0.888523]\n",
      "epoch:1 step:969 [D loss: 0.621748, acc.: 57.81%] [G loss: 0.882643]\n",
      "epoch:1 step:970 [D loss: 0.674114, acc.: 53.91%] [G loss: 0.902509]\n",
      "epoch:1 step:971 [D loss: 0.683013, acc.: 53.12%] [G loss: 0.947069]\n",
      "epoch:1 step:972 [D loss: 0.629555, acc.: 65.62%] [G loss: 0.899530]\n",
      "epoch:1 step:973 [D loss: 0.618541, acc.: 64.06%] [G loss: 0.894272]\n",
      "epoch:1 step:974 [D loss: 0.610294, acc.: 65.62%] [G loss: 0.877369]\n",
      "epoch:1 step:975 [D loss: 0.643997, acc.: 63.28%] [G loss: 0.885259]\n",
      "epoch:1 step:976 [D loss: 0.622882, acc.: 66.41%] [G loss: 0.861344]\n",
      "epoch:1 step:977 [D loss: 0.648322, acc.: 60.94%] [G loss: 0.886678]\n",
      "epoch:1 step:978 [D loss: 0.646344, acc.: 58.59%] [G loss: 0.875767]\n",
      "epoch:1 step:979 [D loss: 0.635608, acc.: 60.16%] [G loss: 0.900057]\n",
      "epoch:1 step:980 [D loss: 0.612414, acc.: 63.28%] [G loss: 0.892750]\n",
      "epoch:1 step:981 [D loss: 0.632783, acc.: 66.41%] [G loss: 0.819580]\n",
      "epoch:1 step:982 [D loss: 0.677766, acc.: 57.81%] [G loss: 0.814809]\n",
      "epoch:1 step:983 [D loss: 0.640482, acc.: 60.16%] [G loss: 0.858572]\n",
      "epoch:1 step:984 [D loss: 0.649961, acc.: 60.94%] [G loss: 0.841794]\n",
      "epoch:1 step:985 [D loss: 0.630712, acc.: 63.28%] [G loss: 0.819324]\n",
      "epoch:1 step:986 [D loss: 0.645689, acc.: 60.16%] [G loss: 0.857805]\n",
      "epoch:1 step:987 [D loss: 0.633116, acc.: 62.50%] [G loss: 0.870477]\n",
      "epoch:1 step:988 [D loss: 0.615863, acc.: 66.41%] [G loss: 0.876902]\n",
      "epoch:1 step:989 [D loss: 0.624704, acc.: 64.84%] [G loss: 0.876311]\n",
      "epoch:1 step:990 [D loss: 0.662259, acc.: 49.22%] [G loss: 0.868420]\n",
      "epoch:1 step:991 [D loss: 0.602483, acc.: 65.62%] [G loss: 0.875348]\n",
      "epoch:1 step:992 [D loss: 0.646333, acc.: 57.03%] [G loss: 0.877265]\n",
      "epoch:1 step:993 [D loss: 0.613696, acc.: 63.28%] [G loss: 0.892776]\n",
      "epoch:1 step:994 [D loss: 0.624987, acc.: 63.28%] [G loss: 0.894732]\n",
      "epoch:1 step:995 [D loss: 0.636566, acc.: 66.41%] [G loss: 0.835617]\n",
      "epoch:1 step:996 [D loss: 0.629938, acc.: 64.06%] [G loss: 0.862707]\n",
      "epoch:1 step:997 [D loss: 0.644225, acc.: 60.16%] [G loss: 0.867634]\n",
      "epoch:1 step:998 [D loss: 0.653476, acc.: 55.47%] [G loss: 0.874153]\n",
      "epoch:1 step:999 [D loss: 0.668118, acc.: 51.56%] [G loss: 0.856010]\n",
      "epoch:1 step:1000 [D loss: 0.626530, acc.: 60.94%] [G loss: 0.881044]\n",
      "##############\n",
      "[ 3.43114351  3.61322877  3.49561731  4.9215486   2.64212374 10.27426719\n",
      "  3.76700801  6.18692641  4.56309631  8.14868929]\n",
      "##########\n",
      "epoch:1 step:1001 [D loss: 0.601638, acc.: 67.19%] [G loss: 0.834316]\n",
      "epoch:1 step:1002 [D loss: 0.637639, acc.: 54.69%] [G loss: 0.857858]\n",
      "epoch:1 step:1003 [D loss: 0.644773, acc.: 61.72%] [G loss: 0.860648]\n",
      "epoch:1 step:1004 [D loss: 0.666160, acc.: 54.69%] [G loss: 0.839112]\n",
      "epoch:1 step:1005 [D loss: 0.669100, acc.: 60.94%] [G loss: 0.906330]\n",
      "epoch:1 step:1006 [D loss: 0.628790, acc.: 62.50%] [G loss: 0.848629]\n",
      "epoch:1 step:1007 [D loss: 0.641589, acc.: 67.19%] [G loss: 0.883643]\n",
      "epoch:1 step:1008 [D loss: 0.680585, acc.: 56.25%] [G loss: 0.862010]\n",
      "epoch:1 step:1009 [D loss: 0.622512, acc.: 65.62%] [G loss: 0.873780]\n",
      "epoch:1 step:1010 [D loss: 0.614687, acc.: 67.19%] [G loss: 0.820757]\n",
      "epoch:1 step:1011 [D loss: 0.649616, acc.: 60.16%] [G loss: 0.872807]\n",
      "epoch:1 step:1012 [D loss: 0.687614, acc.: 53.91%] [G loss: 0.898929]\n",
      "epoch:1 step:1013 [D loss: 0.592886, acc.: 73.44%] [G loss: 0.849046]\n",
      "epoch:1 step:1014 [D loss: 0.650575, acc.: 64.06%] [G loss: 0.856614]\n",
      "epoch:1 step:1015 [D loss: 0.652997, acc.: 60.94%] [G loss: 0.847114]\n",
      "epoch:1 step:1016 [D loss: 0.673911, acc.: 60.16%] [G loss: 0.836777]\n",
      "epoch:1 step:1017 [D loss: 0.619921, acc.: 63.28%] [G loss: 0.872667]\n",
      "epoch:1 step:1018 [D loss: 0.621693, acc.: 64.06%] [G loss: 0.787337]\n",
      "epoch:1 step:1019 [D loss: 0.657353, acc.: 58.59%] [G loss: 0.770662]\n",
      "epoch:1 step:1020 [D loss: 0.646319, acc.: 61.72%] [G loss: 0.825899]\n",
      "epoch:1 step:1021 [D loss: 0.652433, acc.: 60.16%] [G loss: 0.838654]\n",
      "epoch:1 step:1022 [D loss: 0.618199, acc.: 64.84%] [G loss: 0.872290]\n",
      "epoch:1 step:1023 [D loss: 0.635875, acc.: 64.06%] [G loss: 0.834135]\n",
      "epoch:1 step:1024 [D loss: 0.622063, acc.: 64.84%] [G loss: 0.826716]\n",
      "epoch:1 step:1025 [D loss: 0.636152, acc.: 64.06%] [G loss: 0.852895]\n",
      "epoch:1 step:1026 [D loss: 0.628411, acc.: 62.50%] [G loss: 0.876149]\n",
      "epoch:1 step:1027 [D loss: 0.616449, acc.: 66.41%] [G loss: 0.882791]\n",
      "epoch:1 step:1028 [D loss: 0.674964, acc.: 60.94%] [G loss: 0.840271]\n",
      "epoch:1 step:1029 [D loss: 0.634016, acc.: 62.50%] [G loss: 0.800620]\n",
      "epoch:1 step:1030 [D loss: 0.669036, acc.: 59.38%] [G loss: 0.797777]\n",
      "epoch:1 step:1031 [D loss: 0.653587, acc.: 64.84%] [G loss: 0.830617]\n",
      "epoch:1 step:1032 [D loss: 0.593623, acc.: 68.75%] [G loss: 0.856924]\n",
      "epoch:1 step:1033 [D loss: 0.603771, acc.: 68.75%] [G loss: 0.841050]\n",
      "epoch:1 step:1034 [D loss: 0.602489, acc.: 64.84%] [G loss: 0.888644]\n",
      "epoch:1 step:1035 [D loss: 0.603849, acc.: 67.97%] [G loss: 0.885175]\n",
      "epoch:1 step:1036 [D loss: 0.606800, acc.: 61.72%] [G loss: 0.925795]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1037 [D loss: 0.636622, acc.: 65.62%] [G loss: 0.887676]\n",
      "epoch:1 step:1038 [D loss: 0.625596, acc.: 65.62%] [G loss: 0.872573]\n",
      "epoch:1 step:1039 [D loss: 0.657969, acc.: 60.94%] [G loss: 0.862633]\n",
      "epoch:1 step:1040 [D loss: 0.639039, acc.: 64.84%] [G loss: 0.816117]\n",
      "epoch:1 step:1041 [D loss: 0.609242, acc.: 68.75%] [G loss: 0.856699]\n",
      "epoch:1 step:1042 [D loss: 0.625312, acc.: 64.84%] [G loss: 0.904146]\n",
      "epoch:1 step:1043 [D loss: 0.624060, acc.: 64.84%] [G loss: 0.806034]\n",
      "epoch:1 step:1044 [D loss: 0.620242, acc.: 64.84%] [G loss: 0.857798]\n",
      "epoch:1 step:1045 [D loss: 0.649685, acc.: 60.16%] [G loss: 0.897132]\n",
      "epoch:1 step:1046 [D loss: 0.610971, acc.: 64.84%] [G loss: 0.878403]\n",
      "epoch:1 step:1047 [D loss: 0.652685, acc.: 64.84%] [G loss: 0.922630]\n",
      "epoch:1 step:1048 [D loss: 0.631150, acc.: 66.41%] [G loss: 0.886915]\n",
      "epoch:1 step:1049 [D loss: 0.636187, acc.: 59.38%] [G loss: 0.859831]\n",
      "epoch:1 step:1050 [D loss: 0.617723, acc.: 71.09%] [G loss: 0.873942]\n",
      "epoch:1 step:1051 [D loss: 0.634169, acc.: 63.28%] [G loss: 0.869197]\n",
      "epoch:1 step:1052 [D loss: 0.653301, acc.: 64.06%] [G loss: 0.836701]\n",
      "epoch:1 step:1053 [D loss: 0.673202, acc.: 56.25%] [G loss: 0.815285]\n",
      "epoch:1 step:1054 [D loss: 0.680122, acc.: 60.94%] [G loss: 0.836351]\n",
      "epoch:1 step:1055 [D loss: 0.627745, acc.: 67.19%] [G loss: 0.847439]\n",
      "epoch:1 step:1056 [D loss: 0.654442, acc.: 64.84%] [G loss: 0.803891]\n",
      "epoch:1 step:1057 [D loss: 0.650527, acc.: 65.62%] [G loss: 0.836936]\n",
      "epoch:1 step:1058 [D loss: 0.651664, acc.: 63.28%] [G loss: 0.865044]\n",
      "epoch:1 step:1059 [D loss: 0.616141, acc.: 60.94%] [G loss: 0.805018]\n",
      "epoch:1 step:1060 [D loss: 0.612769, acc.: 69.53%] [G loss: 0.831257]\n",
      "epoch:1 step:1061 [D loss: 0.665477, acc.: 60.16%] [G loss: 0.792081]\n",
      "epoch:1 step:1062 [D loss: 0.635804, acc.: 62.50%] [G loss: 0.863533]\n",
      "epoch:1 step:1063 [D loss: 0.637399, acc.: 63.28%] [G loss: 0.870563]\n",
      "epoch:1 step:1064 [D loss: 0.667013, acc.: 53.91%] [G loss: 0.869292]\n",
      "epoch:1 step:1065 [D loss: 0.643818, acc.: 64.84%] [G loss: 0.868759]\n",
      "epoch:1 step:1066 [D loss: 0.628382, acc.: 66.41%] [G loss: 0.861947]\n",
      "epoch:1 step:1067 [D loss: 0.610236, acc.: 67.19%] [G loss: 0.823636]\n",
      "epoch:1 step:1068 [D loss: 0.604097, acc.: 71.88%] [G loss: 0.789401]\n",
      "epoch:1 step:1069 [D loss: 0.642110, acc.: 63.28%] [G loss: 0.798396]\n",
      "epoch:1 step:1070 [D loss: 0.643397, acc.: 67.19%] [G loss: 0.883715]\n",
      "epoch:1 step:1071 [D loss: 0.637844, acc.: 60.94%] [G loss: 0.811921]\n",
      "epoch:1 step:1072 [D loss: 0.632759, acc.: 64.06%] [G loss: 0.894547]\n",
      "epoch:1 step:1073 [D loss: 0.668774, acc.: 57.81%] [G loss: 0.851248]\n",
      "epoch:1 step:1074 [D loss: 0.609494, acc.: 67.19%] [G loss: 0.825696]\n",
      "epoch:1 step:1075 [D loss: 0.622817, acc.: 66.41%] [G loss: 0.868195]\n",
      "epoch:1 step:1076 [D loss: 0.629450, acc.: 62.50%] [G loss: 0.833424]\n",
      "epoch:1 step:1077 [D loss: 0.642036, acc.: 64.06%] [G loss: 0.825672]\n",
      "epoch:1 step:1078 [D loss: 0.596416, acc.: 71.09%] [G loss: 0.816077]\n",
      "epoch:1 step:1079 [D loss: 0.620125, acc.: 60.16%] [G loss: 0.836401]\n",
      "epoch:1 step:1080 [D loss: 0.649447, acc.: 59.38%] [G loss: 0.807960]\n",
      "epoch:1 step:1081 [D loss: 0.627666, acc.: 64.06%] [G loss: 0.879090]\n",
      "epoch:1 step:1082 [D loss: 0.621093, acc.: 60.16%] [G loss: 0.819000]\n",
      "epoch:1 step:1083 [D loss: 0.635061, acc.: 66.41%] [G loss: 0.862416]\n",
      "epoch:1 step:1084 [D loss: 0.650477, acc.: 58.59%] [G loss: 0.946602]\n",
      "epoch:1 step:1085 [D loss: 0.638170, acc.: 63.28%] [G loss: 0.932097]\n",
      "epoch:1 step:1086 [D loss: 0.657878, acc.: 63.28%] [G loss: 0.836665]\n",
      "epoch:1 step:1087 [D loss: 0.660380, acc.: 57.81%] [G loss: 0.811204]\n",
      "epoch:1 step:1088 [D loss: 0.664517, acc.: 57.81%] [G loss: 0.853144]\n",
      "epoch:1 step:1089 [D loss: 0.607769, acc.: 67.97%] [G loss: 0.852777]\n",
      "epoch:1 step:1090 [D loss: 0.625208, acc.: 67.97%] [G loss: 0.837265]\n",
      "epoch:1 step:1091 [D loss: 0.652191, acc.: 57.81%] [G loss: 0.845714]\n",
      "epoch:1 step:1092 [D loss: 0.648204, acc.: 63.28%] [G loss: 0.853481]\n",
      "epoch:1 step:1093 [D loss: 0.637747, acc.: 64.84%] [G loss: 0.867885]\n",
      "epoch:1 step:1094 [D loss: 0.674932, acc.: 57.81%] [G loss: 0.807079]\n",
      "epoch:1 step:1095 [D loss: 0.642445, acc.: 62.50%] [G loss: 0.864028]\n",
      "epoch:1 step:1096 [D loss: 0.647714, acc.: 59.38%] [G loss: 0.834743]\n",
      "epoch:1 step:1097 [D loss: 0.620544, acc.: 64.84%] [G loss: 0.805717]\n",
      "epoch:1 step:1098 [D loss: 0.676706, acc.: 53.91%] [G loss: 0.818220]\n",
      "epoch:1 step:1099 [D loss: 0.623564, acc.: 64.84%] [G loss: 0.831693]\n",
      "epoch:1 step:1100 [D loss: 0.648188, acc.: 63.28%] [G loss: 0.849992]\n",
      "epoch:1 step:1101 [D loss: 0.634736, acc.: 64.84%] [G loss: 0.814569]\n",
      "epoch:1 step:1102 [D loss: 0.637141, acc.: 64.84%] [G loss: 0.887896]\n",
      "epoch:1 step:1103 [D loss: 0.634455, acc.: 64.06%] [G loss: 0.859168]\n",
      "epoch:1 step:1104 [D loss: 0.668524, acc.: 58.59%] [G loss: 0.810556]\n",
      "epoch:1 step:1105 [D loss: 0.666967, acc.: 56.25%] [G loss: 0.865800]\n",
      "epoch:1 step:1106 [D loss: 0.699672, acc.: 57.03%] [G loss: 0.864268]\n",
      "epoch:1 step:1107 [D loss: 0.655899, acc.: 64.06%] [G loss: 0.880423]\n",
      "epoch:1 step:1108 [D loss: 0.637444, acc.: 66.41%] [G loss: 0.859330]\n",
      "epoch:1 step:1109 [D loss: 0.642261, acc.: 60.94%] [G loss: 0.850324]\n",
      "epoch:1 step:1110 [D loss: 0.601542, acc.: 67.97%] [G loss: 0.849258]\n",
      "epoch:1 step:1111 [D loss: 0.620595, acc.: 65.62%] [G loss: 0.866365]\n",
      "epoch:1 step:1112 [D loss: 0.597047, acc.: 67.19%] [G loss: 0.827055]\n",
      "epoch:1 step:1113 [D loss: 0.592252, acc.: 72.66%] [G loss: 0.913365]\n",
      "epoch:1 step:1114 [D loss: 0.625677, acc.: 62.50%] [G loss: 0.854533]\n",
      "epoch:1 step:1115 [D loss: 0.618430, acc.: 64.06%] [G loss: 0.872519]\n",
      "epoch:1 step:1116 [D loss: 0.671042, acc.: 63.28%] [G loss: 0.876871]\n",
      "epoch:1 step:1117 [D loss: 0.609311, acc.: 63.28%] [G loss: 0.882757]\n",
      "epoch:1 step:1118 [D loss: 0.610288, acc.: 69.53%] [G loss: 0.896918]\n",
      "epoch:1 step:1119 [D loss: 0.616479, acc.: 67.97%] [G loss: 0.860707]\n",
      "epoch:1 step:1120 [D loss: 0.629012, acc.: 70.31%] [G loss: 0.870639]\n",
      "epoch:1 step:1121 [D loss: 0.585728, acc.: 75.00%] [G loss: 0.882804]\n",
      "epoch:1 step:1122 [D loss: 0.631689, acc.: 63.28%] [G loss: 0.898740]\n",
      "epoch:1 step:1123 [D loss: 0.622828, acc.: 67.97%] [G loss: 0.864007]\n",
      "epoch:1 step:1124 [D loss: 0.638983, acc.: 64.06%] [G loss: 0.831181]\n",
      "epoch:1 step:1125 [D loss: 0.633123, acc.: 61.72%] [G loss: 0.820513]\n",
      "epoch:1 step:1126 [D loss: 0.657402, acc.: 62.50%] [G loss: 0.839806]\n",
      "epoch:1 step:1127 [D loss: 0.636640, acc.: 67.19%] [G loss: 0.819326]\n",
      "epoch:1 step:1128 [D loss: 0.621662, acc.: 64.84%] [G loss: 0.767328]\n",
      "epoch:1 step:1129 [D loss: 0.619569, acc.: 69.53%] [G loss: 0.843242]\n",
      "epoch:1 step:1130 [D loss: 0.630340, acc.: 61.72%] [G loss: 0.840205]\n",
      "epoch:1 step:1131 [D loss: 0.683737, acc.: 53.12%] [G loss: 0.805943]\n",
      "epoch:1 step:1132 [D loss: 0.607201, acc.: 68.75%] [G loss: 0.833535]\n",
      "epoch:1 step:1133 [D loss: 0.594703, acc.: 69.53%] [G loss: 0.866629]\n",
      "epoch:1 step:1134 [D loss: 0.607236, acc.: 69.53%] [G loss: 0.856643]\n",
      "epoch:1 step:1135 [D loss: 0.565671, acc.: 71.88%] [G loss: 0.913896]\n",
      "epoch:1 step:1136 [D loss: 0.645004, acc.: 62.50%] [G loss: 0.885838]\n",
      "epoch:1 step:1137 [D loss: 0.626789, acc.: 63.28%] [G loss: 0.797794]\n",
      "epoch:1 step:1138 [D loss: 0.643332, acc.: 66.41%] [G loss: 0.901944]\n",
      "epoch:1 step:1139 [D loss: 0.612245, acc.: 65.62%] [G loss: 0.842397]\n",
      "epoch:1 step:1140 [D loss: 0.621061, acc.: 65.62%] [G loss: 0.874949]\n",
      "epoch:1 step:1141 [D loss: 0.667288, acc.: 50.00%] [G loss: 0.884736]\n",
      "epoch:1 step:1142 [D loss: 0.634462, acc.: 60.16%] [G loss: 0.906772]\n",
      "epoch:1 step:1143 [D loss: 0.638693, acc.: 60.16%] [G loss: 0.887385]\n",
      "epoch:1 step:1144 [D loss: 0.628666, acc.: 66.41%] [G loss: 0.892147]\n",
      "epoch:1 step:1145 [D loss: 0.609573, acc.: 65.62%] [G loss: 0.865664]\n",
      "epoch:1 step:1146 [D loss: 0.645980, acc.: 60.94%] [G loss: 0.852748]\n",
      "epoch:1 step:1147 [D loss: 0.643833, acc.: 60.16%] [G loss: 0.929779]\n",
      "epoch:1 step:1148 [D loss: 0.657816, acc.: 56.25%] [G loss: 0.909118]\n",
      "epoch:1 step:1149 [D loss: 0.602839, acc.: 67.97%] [G loss: 0.869933]\n",
      "epoch:1 step:1150 [D loss: 0.669748, acc.: 53.91%] [G loss: 0.867746]\n",
      "epoch:1 step:1151 [D loss: 0.657562, acc.: 61.72%] [G loss: 0.812726]\n",
      "epoch:1 step:1152 [D loss: 0.639626, acc.: 68.75%] [G loss: 0.824398]\n",
      "epoch:1 step:1153 [D loss: 0.609340, acc.: 67.19%] [G loss: 0.865189]\n",
      "epoch:1 step:1154 [D loss: 0.623031, acc.: 74.22%] [G loss: 0.872364]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1155 [D loss: 0.643400, acc.: 64.06%] [G loss: 0.842589]\n",
      "epoch:1 step:1156 [D loss: 0.654123, acc.: 63.28%] [G loss: 0.864244]\n",
      "epoch:1 step:1157 [D loss: 0.660330, acc.: 60.16%] [G loss: 0.894025]\n",
      "epoch:1 step:1158 [D loss: 0.614269, acc.: 57.81%] [G loss: 0.864176]\n",
      "epoch:1 step:1159 [D loss: 0.641363, acc.: 58.59%] [G loss: 0.908156]\n",
      "epoch:1 step:1160 [D loss: 0.641821, acc.: 60.16%] [G loss: 0.865977]\n",
      "epoch:1 step:1161 [D loss: 0.633048, acc.: 64.06%] [G loss: 0.897400]\n",
      "epoch:1 step:1162 [D loss: 0.631469, acc.: 64.06%] [G loss: 0.879942]\n",
      "epoch:1 step:1163 [D loss: 0.620132, acc.: 66.41%] [G loss: 0.850274]\n",
      "epoch:1 step:1164 [D loss: 0.610126, acc.: 67.97%] [G loss: 0.869563]\n",
      "epoch:1 step:1165 [D loss: 0.667421, acc.: 53.91%] [G loss: 0.899616]\n",
      "epoch:1 step:1166 [D loss: 0.599059, acc.: 71.88%] [G loss: 0.920290]\n",
      "epoch:1 step:1167 [D loss: 0.630080, acc.: 60.94%] [G loss: 0.908165]\n",
      "epoch:1 step:1168 [D loss: 0.625465, acc.: 68.75%] [G loss: 0.907509]\n",
      "epoch:1 step:1169 [D loss: 0.639481, acc.: 63.28%] [G loss: 0.893611]\n",
      "epoch:1 step:1170 [D loss: 0.616071, acc.: 70.31%] [G loss: 0.946689]\n",
      "epoch:1 step:1171 [D loss: 0.645151, acc.: 64.06%] [G loss: 0.918424]\n",
      "epoch:1 step:1172 [D loss: 0.646661, acc.: 58.59%] [G loss: 0.931036]\n",
      "epoch:1 step:1173 [D loss: 0.638499, acc.: 64.06%] [G loss: 0.928815]\n",
      "epoch:1 step:1174 [D loss: 0.665958, acc.: 57.81%] [G loss: 0.898810]\n",
      "epoch:1 step:1175 [D loss: 0.613883, acc.: 66.41%] [G loss: 0.944218]\n",
      "epoch:1 step:1176 [D loss: 0.641076, acc.: 62.50%] [G loss: 0.842586]\n",
      "epoch:1 step:1177 [D loss: 0.633263, acc.: 67.97%] [G loss: 0.888464]\n",
      "epoch:1 step:1178 [D loss: 0.620076, acc.: 66.41%] [G loss: 0.863306]\n",
      "epoch:1 step:1179 [D loss: 0.640824, acc.: 62.50%] [G loss: 0.819957]\n",
      "epoch:1 step:1180 [D loss: 0.643564, acc.: 63.28%] [G loss: 0.856925]\n",
      "epoch:1 step:1181 [D loss: 0.642576, acc.: 60.94%] [G loss: 0.814572]\n",
      "epoch:1 step:1182 [D loss: 0.632121, acc.: 65.62%] [G loss: 0.905877]\n",
      "epoch:1 step:1183 [D loss: 0.670655, acc.: 59.38%] [G loss: 0.876891]\n",
      "epoch:1 step:1184 [D loss: 0.626438, acc.: 63.28%] [G loss: 0.823602]\n",
      "epoch:1 step:1185 [D loss: 0.581179, acc.: 74.22%] [G loss: 0.816882]\n",
      "epoch:1 step:1186 [D loss: 0.615964, acc.: 65.62%] [G loss: 0.829236]\n",
      "epoch:1 step:1187 [D loss: 0.625191, acc.: 66.41%] [G loss: 0.880723]\n",
      "epoch:1 step:1188 [D loss: 0.623960, acc.: 70.31%] [G loss: 0.857596]\n",
      "epoch:1 step:1189 [D loss: 0.611956, acc.: 71.88%] [G loss: 0.898907]\n",
      "epoch:1 step:1190 [D loss: 0.614254, acc.: 65.62%] [G loss: 0.848990]\n",
      "epoch:1 step:1191 [D loss: 0.645289, acc.: 63.28%] [G loss: 0.859327]\n",
      "epoch:1 step:1192 [D loss: 0.604306, acc.: 71.88%] [G loss: 0.920474]\n",
      "epoch:1 step:1193 [D loss: 0.603914, acc.: 71.09%] [G loss: 0.898273]\n",
      "epoch:1 step:1194 [D loss: 0.611234, acc.: 67.19%] [G loss: 0.892218]\n",
      "epoch:1 step:1195 [D loss: 0.608843, acc.: 69.53%] [G loss: 0.923116]\n",
      "epoch:1 step:1196 [D loss: 0.613991, acc.: 62.50%] [G loss: 0.897159]\n",
      "epoch:1 step:1197 [D loss: 0.605462, acc.: 70.31%] [G loss: 0.951771]\n",
      "epoch:1 step:1198 [D loss: 0.633074, acc.: 61.72%] [G loss: 0.963724]\n",
      "epoch:1 step:1199 [D loss: 0.628478, acc.: 65.62%] [G loss: 0.872783]\n",
      "epoch:1 step:1200 [D loss: 0.607374, acc.: 68.75%] [G loss: 0.952163]\n",
      "##############\n",
      "[ 3.21709149  4.42024142  5.31421055  7.2320855   2.63587536 10.27426719\n",
      "  3.96583009  7.504254    4.72872791  8.14868929]\n",
      "##########\n",
      "epoch:1 step:1201 [D loss: 0.621094, acc.: 67.19%] [G loss: 0.910543]\n",
      "epoch:1 step:1202 [D loss: 0.640772, acc.: 60.94%] [G loss: 0.893539]\n",
      "epoch:1 step:1203 [D loss: 0.658797, acc.: 60.94%] [G loss: 0.931174]\n",
      "epoch:1 step:1204 [D loss: 0.625488, acc.: 66.41%] [G loss: 0.895540]\n",
      "epoch:1 step:1205 [D loss: 0.600009, acc.: 69.53%] [G loss: 0.894661]\n",
      "epoch:1 step:1206 [D loss: 0.620371, acc.: 60.16%] [G loss: 0.868528]\n",
      "epoch:1 step:1207 [D loss: 0.621973, acc.: 64.06%] [G loss: 0.877276]\n",
      "epoch:1 step:1208 [D loss: 0.605994, acc.: 66.41%] [G loss: 0.869076]\n",
      "epoch:1 step:1209 [D loss: 0.660709, acc.: 56.25%] [G loss: 0.899591]\n",
      "epoch:1 step:1210 [D loss: 0.639015, acc.: 64.06%] [G loss: 0.894470]\n",
      "epoch:1 step:1211 [D loss: 0.612899, acc.: 65.62%] [G loss: 0.885741]\n",
      "epoch:1 step:1212 [D loss: 0.688130, acc.: 55.47%] [G loss: 0.802324]\n",
      "epoch:1 step:1213 [D loss: 0.652408, acc.: 60.94%] [G loss: 0.835257]\n",
      "epoch:1 step:1214 [D loss: 0.635061, acc.: 64.06%] [G loss: 0.878348]\n",
      "epoch:1 step:1215 [D loss: 0.619119, acc.: 70.31%] [G loss: 0.832340]\n",
      "epoch:1 step:1216 [D loss: 0.639385, acc.: 60.94%] [G loss: 0.891303]\n",
      "epoch:1 step:1217 [D loss: 0.622650, acc.: 64.84%] [G loss: 0.888518]\n",
      "epoch:1 step:1218 [D loss: 0.625947, acc.: 65.62%] [G loss: 0.870527]\n",
      "epoch:1 step:1219 [D loss: 0.631333, acc.: 67.19%] [G loss: 0.879076]\n",
      "epoch:1 step:1220 [D loss: 0.635982, acc.: 66.41%] [G loss: 0.894467]\n",
      "epoch:1 step:1221 [D loss: 0.590354, acc.: 72.66%] [G loss: 0.870237]\n",
      "epoch:1 step:1222 [D loss: 0.665219, acc.: 52.34%] [G loss: 0.860851]\n",
      "epoch:1 step:1223 [D loss: 0.602983, acc.: 69.53%] [G loss: 0.860586]\n",
      "epoch:1 step:1224 [D loss: 0.630092, acc.: 65.62%] [G loss: 0.900102]\n",
      "epoch:1 step:1225 [D loss: 0.614462, acc.: 71.09%] [G loss: 0.911152]\n",
      "epoch:1 step:1226 [D loss: 0.639290, acc.: 60.94%] [G loss: 0.915726]\n",
      "epoch:1 step:1227 [D loss: 0.621059, acc.: 65.62%] [G loss: 0.864943]\n",
      "epoch:1 step:1228 [D loss: 0.639292, acc.: 62.50%] [G loss: 0.893771]\n",
      "epoch:1 step:1229 [D loss: 0.599778, acc.: 65.62%] [G loss: 0.951768]\n",
      "epoch:1 step:1230 [D loss: 0.630720, acc.: 65.62%] [G loss: 0.892181]\n",
      "epoch:1 step:1231 [D loss: 0.581141, acc.: 71.88%] [G loss: 0.946836]\n",
      "epoch:1 step:1232 [D loss: 0.633070, acc.: 65.62%] [G loss: 0.872555]\n",
      "epoch:1 step:1233 [D loss: 0.646308, acc.: 64.06%] [G loss: 1.000065]\n",
      "epoch:1 step:1234 [D loss: 0.628578, acc.: 64.06%] [G loss: 0.897935]\n",
      "epoch:1 step:1235 [D loss: 0.629446, acc.: 57.81%] [G loss: 0.871536]\n",
      "epoch:1 step:1236 [D loss: 0.639195, acc.: 63.28%] [G loss: 0.853542]\n",
      "epoch:1 step:1237 [D loss: 0.646947, acc.: 65.62%] [G loss: 0.925274]\n",
      "epoch:1 step:1238 [D loss: 0.643182, acc.: 63.28%] [G loss: 0.914783]\n",
      "epoch:1 step:1239 [D loss: 0.617317, acc.: 64.84%] [G loss: 0.886215]\n",
      "epoch:1 step:1240 [D loss: 0.626017, acc.: 66.41%] [G loss: 0.964295]\n",
      "epoch:1 step:1241 [D loss: 0.597247, acc.: 69.53%] [G loss: 0.940561]\n",
      "epoch:1 step:1242 [D loss: 0.648748, acc.: 64.06%] [G loss: 0.927532]\n",
      "epoch:1 step:1243 [D loss: 0.603536, acc.: 63.28%] [G loss: 0.908312]\n",
      "epoch:1 step:1244 [D loss: 0.596828, acc.: 72.66%] [G loss: 0.897072]\n",
      "epoch:1 step:1245 [D loss: 0.601161, acc.: 64.06%] [G loss: 0.912444]\n",
      "epoch:1 step:1246 [D loss: 0.643496, acc.: 61.72%] [G loss: 0.884375]\n",
      "epoch:1 step:1247 [D loss: 0.639803, acc.: 64.84%] [G loss: 0.925641]\n",
      "epoch:1 step:1248 [D loss: 0.607275, acc.: 62.50%] [G loss: 0.925126]\n",
      "epoch:1 step:1249 [D loss: 0.663847, acc.: 64.06%] [G loss: 0.886133]\n",
      "epoch:1 step:1250 [D loss: 0.669949, acc.: 57.03%] [G loss: 0.834665]\n",
      "epoch:1 step:1251 [D loss: 0.625966, acc.: 65.62%] [G loss: 0.927676]\n",
      "epoch:1 step:1252 [D loss: 0.610961, acc.: 69.53%] [G loss: 0.817683]\n",
      "epoch:1 step:1253 [D loss: 0.631201, acc.: 65.62%] [G loss: 0.836634]\n",
      "epoch:1 step:1254 [D loss: 0.640432, acc.: 63.28%] [G loss: 0.896286]\n",
      "epoch:1 step:1255 [D loss: 0.632113, acc.: 57.03%] [G loss: 0.853130]\n",
      "epoch:1 step:1256 [D loss: 0.632935, acc.: 69.53%] [G loss: 0.891455]\n",
      "epoch:1 step:1257 [D loss: 0.611058, acc.: 57.81%] [G loss: 0.927113]\n",
      "epoch:1 step:1258 [D loss: 0.622519, acc.: 64.06%] [G loss: 0.939173]\n",
      "epoch:1 step:1259 [D loss: 0.621524, acc.: 64.06%] [G loss: 0.931737]\n",
      "epoch:1 step:1260 [D loss: 0.677545, acc.: 60.94%] [G loss: 0.871567]\n",
      "epoch:1 step:1261 [D loss: 0.600482, acc.: 65.62%] [G loss: 0.899558]\n",
      "epoch:1 step:1262 [D loss: 0.627208, acc.: 57.03%] [G loss: 0.872532]\n",
      "epoch:1 step:1263 [D loss: 0.642142, acc.: 59.38%] [G loss: 0.912383]\n",
      "epoch:1 step:1264 [D loss: 0.593182, acc.: 70.31%] [G loss: 0.907294]\n",
      "epoch:1 step:1265 [D loss: 0.583977, acc.: 74.22%] [G loss: 0.897502]\n",
      "epoch:1 step:1266 [D loss: 0.612749, acc.: 70.31%] [G loss: 0.868807]\n",
      "epoch:1 step:1267 [D loss: 0.607047, acc.: 64.06%] [G loss: 0.908502]\n",
      "epoch:1 step:1268 [D loss: 0.600926, acc.: 65.62%] [G loss: 0.941089]\n",
      "epoch:1 step:1269 [D loss: 0.574408, acc.: 68.75%] [G loss: 0.938013]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1270 [D loss: 0.620584, acc.: 63.28%] [G loss: 0.982707]\n",
      "epoch:1 step:1271 [D loss: 0.647409, acc.: 62.50%] [G loss: 0.914683]\n",
      "epoch:1 step:1272 [D loss: 0.632328, acc.: 66.41%] [G loss: 0.925139]\n",
      "epoch:1 step:1273 [D loss: 0.593581, acc.: 74.22%] [G loss: 0.962189]\n",
      "epoch:1 step:1274 [D loss: 0.643892, acc.: 60.94%] [G loss: 0.916782]\n",
      "epoch:1 step:1275 [D loss: 0.572107, acc.: 75.00%] [G loss: 0.959788]\n",
      "epoch:1 step:1276 [D loss: 0.618053, acc.: 67.97%] [G loss: 0.939622]\n",
      "epoch:1 step:1277 [D loss: 0.581427, acc.: 72.66%] [G loss: 0.899284]\n",
      "epoch:1 step:1278 [D loss: 0.609748, acc.: 69.53%] [G loss: 0.914156]\n",
      "epoch:1 step:1279 [D loss: 0.618458, acc.: 64.06%] [G loss: 0.899245]\n",
      "epoch:1 step:1280 [D loss: 0.628656, acc.: 61.72%] [G loss: 0.906499]\n",
      "epoch:1 step:1281 [D loss: 0.632671, acc.: 62.50%] [G loss: 0.892691]\n",
      "epoch:1 step:1282 [D loss: 0.621942, acc.: 67.19%] [G loss: 0.981034]\n",
      "epoch:1 step:1283 [D loss: 0.654430, acc.: 60.16%] [G loss: 0.925570]\n",
      "epoch:1 step:1284 [D loss: 0.591329, acc.: 75.00%] [G loss: 0.907304]\n",
      "epoch:1 step:1285 [D loss: 0.619312, acc.: 68.75%] [G loss: 0.820576]\n",
      "epoch:1 step:1286 [D loss: 0.610049, acc.: 70.31%] [G loss: 0.850237]\n",
      "epoch:1 step:1287 [D loss: 0.635829, acc.: 64.06%] [G loss: 0.915400]\n",
      "epoch:1 step:1288 [D loss: 0.582011, acc.: 69.53%] [G loss: 0.911769]\n",
      "epoch:1 step:1289 [D loss: 0.572057, acc.: 78.91%] [G loss: 0.902459]\n",
      "epoch:1 step:1290 [D loss: 0.619840, acc.: 70.31%] [G loss: 0.910421]\n",
      "epoch:1 step:1291 [D loss: 0.618266, acc.: 64.84%] [G loss: 0.882800]\n",
      "epoch:1 step:1292 [D loss: 0.573696, acc.: 64.06%] [G loss: 0.940308]\n",
      "epoch:1 step:1293 [D loss: 0.595918, acc.: 67.19%] [G loss: 0.899266]\n",
      "epoch:1 step:1294 [D loss: 0.624390, acc.: 64.84%] [G loss: 0.924644]\n",
      "epoch:1 step:1295 [D loss: 0.583388, acc.: 73.44%] [G loss: 0.892408]\n",
      "epoch:1 step:1296 [D loss: 0.654888, acc.: 54.69%] [G loss: 0.860554]\n",
      "epoch:1 step:1297 [D loss: 0.564208, acc.: 76.56%] [G loss: 0.886651]\n",
      "epoch:1 step:1298 [D loss: 0.603788, acc.: 67.97%] [G loss: 0.876799]\n",
      "epoch:1 step:1299 [D loss: 0.582094, acc.: 74.22%] [G loss: 0.931048]\n",
      "epoch:1 step:1300 [D loss: 0.625214, acc.: 67.97%] [G loss: 0.918423]\n",
      "epoch:1 step:1301 [D loss: 0.616662, acc.: 67.19%] [G loss: 0.918978]\n",
      "epoch:1 step:1302 [D loss: 0.621816, acc.: 71.09%] [G loss: 0.967698]\n",
      "epoch:1 step:1303 [D loss: 0.604606, acc.: 69.53%] [G loss: 0.939796]\n",
      "epoch:1 step:1304 [D loss: 0.601448, acc.: 74.22%] [G loss: 0.945215]\n",
      "epoch:1 step:1305 [D loss: 0.605729, acc.: 70.31%] [G loss: 0.897925]\n",
      "epoch:1 step:1306 [D loss: 0.591343, acc.: 67.19%] [G loss: 0.838926]\n",
      "epoch:1 step:1307 [D loss: 0.626253, acc.: 63.28%] [G loss: 0.882931]\n",
      "epoch:1 step:1308 [D loss: 0.628461, acc.: 65.62%] [G loss: 0.868466]\n",
      "epoch:1 step:1309 [D loss: 0.625995, acc.: 66.41%] [G loss: 0.889769]\n",
      "epoch:1 step:1310 [D loss: 0.595340, acc.: 69.53%] [G loss: 0.922305]\n",
      "epoch:1 step:1311 [D loss: 0.587826, acc.: 70.31%] [G loss: 0.942617]\n",
      "epoch:1 step:1312 [D loss: 0.621871, acc.: 64.84%] [G loss: 0.950203]\n",
      "epoch:1 step:1313 [D loss: 0.626226, acc.: 71.09%] [G loss: 0.943315]\n",
      "epoch:1 step:1314 [D loss: 0.666781, acc.: 57.81%] [G loss: 0.901420]\n",
      "epoch:1 step:1315 [D loss: 0.615827, acc.: 71.88%] [G loss: 0.928231]\n",
      "epoch:1 step:1316 [D loss: 0.630422, acc.: 67.19%] [G loss: 0.891771]\n",
      "epoch:1 step:1317 [D loss: 0.608769, acc.: 66.41%] [G loss: 0.952251]\n",
      "epoch:1 step:1318 [D loss: 0.620697, acc.: 61.72%] [G loss: 0.925324]\n",
      "epoch:1 step:1319 [D loss: 0.567285, acc.: 75.78%] [G loss: 0.899800]\n",
      "epoch:1 step:1320 [D loss: 0.586307, acc.: 69.53%] [G loss: 0.875149]\n",
      "epoch:1 step:1321 [D loss: 0.628145, acc.: 63.28%] [G loss: 0.946311]\n",
      "epoch:1 step:1322 [D loss: 0.587376, acc.: 72.66%] [G loss: 0.965855]\n",
      "epoch:1 step:1323 [D loss: 0.612268, acc.: 67.97%] [G loss: 0.914568]\n",
      "epoch:1 step:1324 [D loss: 0.595982, acc.: 74.22%] [G loss: 0.948952]\n",
      "epoch:1 step:1325 [D loss: 0.626631, acc.: 62.50%] [G loss: 0.875856]\n",
      "epoch:1 step:1326 [D loss: 0.621381, acc.: 60.94%] [G loss: 0.962843]\n",
      "epoch:1 step:1327 [D loss: 0.595481, acc.: 71.88%] [G loss: 0.929956]\n",
      "epoch:1 step:1328 [D loss: 0.624826, acc.: 67.19%] [G loss: 0.943577]\n",
      "epoch:1 step:1329 [D loss: 0.634360, acc.: 67.97%] [G loss: 0.927438]\n",
      "epoch:1 step:1330 [D loss: 0.644159, acc.: 57.81%] [G loss: 0.876706]\n",
      "epoch:1 step:1331 [D loss: 0.635962, acc.: 62.50%] [G loss: 0.915515]\n",
      "epoch:1 step:1332 [D loss: 0.604855, acc.: 64.06%] [G loss: 0.913271]\n",
      "epoch:1 step:1333 [D loss: 0.609877, acc.: 66.41%] [G loss: 0.920339]\n",
      "epoch:1 step:1334 [D loss: 0.640008, acc.: 60.16%] [G loss: 0.847693]\n",
      "epoch:1 step:1335 [D loss: 0.622021, acc.: 65.62%] [G loss: 0.822127]\n",
      "epoch:1 step:1336 [D loss: 0.584997, acc.: 67.19%] [G loss: 0.891352]\n",
      "epoch:1 step:1337 [D loss: 0.654875, acc.: 64.84%] [G loss: 0.894573]\n",
      "epoch:1 step:1338 [D loss: 0.627432, acc.: 61.72%] [G loss: 0.900473]\n",
      "epoch:1 step:1339 [D loss: 0.627816, acc.: 64.84%] [G loss: 0.915832]\n",
      "epoch:1 step:1340 [D loss: 0.615725, acc.: 69.53%] [G loss: 0.944101]\n",
      "epoch:1 step:1341 [D loss: 0.645223, acc.: 58.59%] [G loss: 0.941315]\n",
      "epoch:1 step:1342 [D loss: 0.627018, acc.: 63.28%] [G loss: 0.947032]\n",
      "epoch:1 step:1343 [D loss: 0.647188, acc.: 59.38%] [G loss: 0.921871]\n",
      "epoch:1 step:1344 [D loss: 0.626559, acc.: 64.84%] [G loss: 0.960170]\n",
      "epoch:1 step:1345 [D loss: 0.602849, acc.: 64.84%] [G loss: 0.974514]\n",
      "epoch:1 step:1346 [D loss: 0.634466, acc.: 67.19%] [G loss: 0.967375]\n",
      "epoch:1 step:1347 [D loss: 0.687775, acc.: 51.56%] [G loss: 0.913424]\n",
      "epoch:1 step:1348 [D loss: 0.627280, acc.: 65.62%] [G loss: 0.988347]\n",
      "epoch:1 step:1349 [D loss: 0.578158, acc.: 75.78%] [G loss: 0.979254]\n",
      "epoch:1 step:1350 [D loss: 0.640694, acc.: 60.94%] [G loss: 0.895799]\n",
      "epoch:1 step:1351 [D loss: 0.667876, acc.: 57.03%] [G loss: 0.950136]\n",
      "epoch:1 step:1352 [D loss: 0.591753, acc.: 71.88%] [G loss: 0.951007]\n",
      "epoch:1 step:1353 [D loss: 0.597957, acc.: 69.53%] [G loss: 0.912563]\n",
      "epoch:1 step:1354 [D loss: 0.649598, acc.: 64.06%] [G loss: 1.003984]\n",
      "epoch:1 step:1355 [D loss: 0.611856, acc.: 66.41%] [G loss: 0.961987]\n",
      "epoch:1 step:1356 [D loss: 0.617244, acc.: 62.50%] [G loss: 0.925543]\n",
      "epoch:1 step:1357 [D loss: 0.579461, acc.: 71.09%] [G loss: 0.936073]\n",
      "epoch:1 step:1358 [D loss: 0.627187, acc.: 64.06%] [G loss: 0.946389]\n",
      "epoch:1 step:1359 [D loss: 0.628603, acc.: 64.84%] [G loss: 0.919094]\n",
      "epoch:1 step:1360 [D loss: 0.584553, acc.: 69.53%] [G loss: 0.989463]\n",
      "epoch:1 step:1361 [D loss: 0.653097, acc.: 60.16%] [G loss: 0.914828]\n",
      "epoch:1 step:1362 [D loss: 0.562305, acc.: 75.00%] [G loss: 0.950438]\n",
      "epoch:1 step:1363 [D loss: 0.638506, acc.: 66.41%] [G loss: 0.954377]\n",
      "epoch:1 step:1364 [D loss: 0.582640, acc.: 78.91%] [G loss: 0.938620]\n",
      "epoch:1 step:1365 [D loss: 0.642548, acc.: 63.28%] [G loss: 0.964149]\n",
      "epoch:1 step:1366 [D loss: 0.627529, acc.: 66.41%] [G loss: 0.910075]\n",
      "epoch:1 step:1367 [D loss: 0.639483, acc.: 60.94%] [G loss: 0.844341]\n",
      "epoch:1 step:1368 [D loss: 0.637689, acc.: 62.50%] [G loss: 0.898776]\n",
      "epoch:1 step:1369 [D loss: 0.626409, acc.: 69.53%] [G loss: 0.906330]\n",
      "epoch:1 step:1370 [D loss: 0.620169, acc.: 64.84%] [G loss: 0.880038]\n",
      "epoch:1 step:1371 [D loss: 0.645859, acc.: 60.94%] [G loss: 0.900890]\n",
      "epoch:1 step:1372 [D loss: 0.592961, acc.: 75.78%] [G loss: 0.873100]\n",
      "epoch:1 step:1373 [D loss: 0.624516, acc.: 67.19%] [G loss: 0.915779]\n",
      "epoch:1 step:1374 [D loss: 0.627607, acc.: 65.62%] [G loss: 0.931387]\n",
      "epoch:1 step:1375 [D loss: 0.618659, acc.: 64.84%] [G loss: 0.934101]\n",
      "epoch:1 step:1376 [D loss: 0.652101, acc.: 60.16%] [G loss: 0.946312]\n",
      "epoch:1 step:1377 [D loss: 0.622658, acc.: 67.19%] [G loss: 0.948426]\n",
      "epoch:1 step:1378 [D loss: 0.600903, acc.: 67.97%] [G loss: 0.878277]\n",
      "epoch:1 step:1379 [D loss: 0.595273, acc.: 69.53%] [G loss: 0.933931]\n",
      "epoch:1 step:1380 [D loss: 0.598196, acc.: 72.66%] [G loss: 0.949825]\n",
      "epoch:1 step:1381 [D loss: 0.591797, acc.: 71.09%] [G loss: 0.932860]\n",
      "epoch:1 step:1382 [D loss: 0.582930, acc.: 67.19%] [G loss: 0.929209]\n",
      "epoch:1 step:1383 [D loss: 0.615681, acc.: 68.75%] [G loss: 0.929256]\n",
      "epoch:1 step:1384 [D loss: 0.553828, acc.: 71.88%] [G loss: 0.957828]\n",
      "epoch:1 step:1385 [D loss: 0.663120, acc.: 56.25%] [G loss: 0.932626]\n",
      "epoch:1 step:1386 [D loss: 0.611284, acc.: 70.31%] [G loss: 0.885067]\n",
      "epoch:1 step:1387 [D loss: 0.583498, acc.: 69.53%] [G loss: 0.881866]\n",
      "epoch:1 step:1388 [D loss: 0.625419, acc.: 65.62%] [G loss: 0.928039]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1389 [D loss: 0.613208, acc.: 64.06%] [G loss: 0.907408]\n",
      "epoch:1 step:1390 [D loss: 0.561065, acc.: 71.88%] [G loss: 0.918671]\n",
      "epoch:1 step:1391 [D loss: 0.675623, acc.: 53.91%] [G loss: 0.884190]\n",
      "epoch:1 step:1392 [D loss: 0.612493, acc.: 60.16%] [G loss: 0.921777]\n",
      "epoch:1 step:1393 [D loss: 0.590101, acc.: 66.41%] [G loss: 0.955681]\n",
      "epoch:1 step:1394 [D loss: 0.612978, acc.: 69.53%] [G loss: 0.960073]\n",
      "epoch:1 step:1395 [D loss: 0.590719, acc.: 73.44%] [G loss: 1.000470]\n",
      "epoch:1 step:1396 [D loss: 0.571090, acc.: 71.88%] [G loss: 0.945348]\n",
      "epoch:1 step:1397 [D loss: 0.611013, acc.: 60.94%] [G loss: 0.937983]\n",
      "epoch:1 step:1398 [D loss: 0.640937, acc.: 64.06%] [G loss: 0.927271]\n",
      "epoch:1 step:1399 [D loss: 0.606602, acc.: 68.75%] [G loss: 0.912177]\n",
      "epoch:1 step:1400 [D loss: 0.662514, acc.: 58.59%] [G loss: 0.999956]\n",
      "##############\n",
      "[ 3.47152207  4.12447741  3.72398873  5.06992249  2.64737585 10.27426719\n",
      "  6.31613501  5.50269912  4.88513039  8.14868929]\n",
      "##########\n",
      "epoch:1 step:1401 [D loss: 0.582818, acc.: 71.88%] [G loss: 0.905147]\n",
      "epoch:1 step:1402 [D loss: 0.627390, acc.: 61.72%] [G loss: 0.955111]\n",
      "epoch:1 step:1403 [D loss: 0.635275, acc.: 64.06%] [G loss: 0.928597]\n",
      "epoch:1 step:1404 [D loss: 0.626619, acc.: 63.28%] [G loss: 0.900721]\n",
      "epoch:1 step:1405 [D loss: 0.612753, acc.: 63.28%] [G loss: 0.922472]\n",
      "epoch:1 step:1406 [D loss: 0.606281, acc.: 62.50%] [G loss: 0.946737]\n",
      "epoch:1 step:1407 [D loss: 0.652056, acc.: 60.94%] [G loss: 0.859495]\n",
      "epoch:1 step:1408 [D loss: 0.612067, acc.: 63.28%] [G loss: 0.987637]\n",
      "epoch:1 step:1409 [D loss: 0.561848, acc.: 72.66%] [G loss: 0.916853]\n",
      "epoch:1 step:1410 [D loss: 0.634615, acc.: 66.41%] [G loss: 0.906220]\n",
      "epoch:1 step:1411 [D loss: 0.623838, acc.: 59.38%] [G loss: 0.953130]\n",
      "epoch:1 step:1412 [D loss: 0.585735, acc.: 71.88%] [G loss: 0.999755]\n",
      "epoch:1 step:1413 [D loss: 0.631466, acc.: 61.72%] [G loss: 0.898001]\n",
      "epoch:1 step:1414 [D loss: 0.614178, acc.: 63.28%] [G loss: 0.924663]\n",
      "epoch:1 step:1415 [D loss: 0.613759, acc.: 64.84%] [G loss: 0.910311]\n",
      "epoch:1 step:1416 [D loss: 0.615905, acc.: 64.84%] [G loss: 0.956746]\n",
      "epoch:1 step:1417 [D loss: 0.639079, acc.: 60.16%] [G loss: 0.918900]\n",
      "epoch:1 step:1418 [D loss: 0.598658, acc.: 67.19%] [G loss: 0.951930]\n",
      "epoch:1 step:1419 [D loss: 0.589854, acc.: 68.75%] [G loss: 0.956361]\n",
      "epoch:1 step:1420 [D loss: 0.643887, acc.: 61.72%] [G loss: 0.898573]\n",
      "epoch:1 step:1421 [D loss: 0.582052, acc.: 74.22%] [G loss: 0.931844]\n",
      "epoch:1 step:1422 [D loss: 0.591926, acc.: 67.97%] [G loss: 0.921820]\n",
      "epoch:1 step:1423 [D loss: 0.617078, acc.: 72.66%] [G loss: 0.911719]\n",
      "epoch:1 step:1424 [D loss: 0.654492, acc.: 57.03%] [G loss: 0.888746]\n",
      "epoch:1 step:1425 [D loss: 0.596080, acc.: 65.62%] [G loss: 0.901163]\n",
      "epoch:1 step:1426 [D loss: 0.632446, acc.: 63.28%] [G loss: 0.902043]\n",
      "epoch:1 step:1427 [D loss: 0.607520, acc.: 67.19%] [G loss: 0.894977]\n",
      "epoch:1 step:1428 [D loss: 0.592374, acc.: 67.97%] [G loss: 0.912539]\n",
      "epoch:1 step:1429 [D loss: 0.592089, acc.: 67.97%] [G loss: 0.898527]\n",
      "epoch:1 step:1430 [D loss: 0.591995, acc.: 64.84%] [G loss: 0.965750]\n",
      "epoch:1 step:1431 [D loss: 0.582720, acc.: 71.09%] [G loss: 0.994890]\n",
      "epoch:1 step:1432 [D loss: 0.652594, acc.: 61.72%] [G loss: 0.895619]\n",
      "epoch:1 step:1433 [D loss: 0.578522, acc.: 69.53%] [G loss: 0.940765]\n",
      "epoch:1 step:1434 [D loss: 0.571302, acc.: 70.31%] [G loss: 0.921452]\n",
      "epoch:1 step:1435 [D loss: 0.662627, acc.: 60.94%] [G loss: 0.964957]\n",
      "epoch:1 step:1436 [D loss: 0.629095, acc.: 64.06%] [G loss: 0.886533]\n",
      "epoch:1 step:1437 [D loss: 0.618869, acc.: 64.84%] [G loss: 0.924157]\n",
      "epoch:1 step:1438 [D loss: 0.594867, acc.: 65.62%] [G loss: 0.865734]\n",
      "epoch:1 step:1439 [D loss: 0.607894, acc.: 65.62%] [G loss: 0.916955]\n",
      "epoch:1 step:1440 [D loss: 0.558772, acc.: 69.53%] [G loss: 0.922853]\n",
      "epoch:1 step:1441 [D loss: 0.612389, acc.: 70.31%] [G loss: 0.882440]\n",
      "epoch:1 step:1442 [D loss: 0.607488, acc.: 63.28%] [G loss: 0.935202]\n",
      "epoch:1 step:1443 [D loss: 0.589462, acc.: 67.97%] [G loss: 0.976901]\n",
      "epoch:1 step:1444 [D loss: 0.592338, acc.: 67.19%] [G loss: 0.980269]\n",
      "epoch:1 step:1445 [D loss: 0.608476, acc.: 66.41%] [G loss: 0.949137]\n",
      "epoch:1 step:1446 [D loss: 0.627789, acc.: 58.59%] [G loss: 0.963857]\n",
      "epoch:1 step:1447 [D loss: 0.623623, acc.: 68.75%] [G loss: 1.004537]\n",
      "epoch:1 step:1448 [D loss: 0.652135, acc.: 60.94%] [G loss: 0.884905]\n",
      "epoch:1 step:1449 [D loss: 0.619740, acc.: 61.72%] [G loss: 0.897094]\n",
      "epoch:1 step:1450 [D loss: 0.619238, acc.: 65.62%] [G loss: 0.831547]\n",
      "epoch:1 step:1451 [D loss: 0.619809, acc.: 67.97%] [G loss: 0.878298]\n",
      "epoch:1 step:1452 [D loss: 0.586210, acc.: 67.97%] [G loss: 0.911686]\n",
      "epoch:1 step:1453 [D loss: 0.652724, acc.: 64.06%] [G loss: 0.906116]\n",
      "epoch:1 step:1454 [D loss: 0.617229, acc.: 67.19%] [G loss: 0.968400]\n",
      "epoch:1 step:1455 [D loss: 0.651303, acc.: 61.72%] [G loss: 0.922713]\n",
      "epoch:1 step:1456 [D loss: 0.597940, acc.: 69.53%] [G loss: 0.964748]\n",
      "epoch:1 step:1457 [D loss: 0.644827, acc.: 60.94%] [G loss: 0.916961]\n",
      "epoch:1 step:1458 [D loss: 0.616202, acc.: 65.62%] [G loss: 0.912515]\n",
      "epoch:1 step:1459 [D loss: 0.619378, acc.: 66.41%] [G loss: 0.939569]\n",
      "epoch:1 step:1460 [D loss: 0.637929, acc.: 61.72%] [G loss: 0.988763]\n",
      "epoch:1 step:1461 [D loss: 0.636021, acc.: 65.62%] [G loss: 0.977215]\n",
      "epoch:1 step:1462 [D loss: 0.649086, acc.: 61.72%] [G loss: 1.013561]\n",
      "epoch:1 step:1463 [D loss: 0.642830, acc.: 62.50%] [G loss: 0.892760]\n",
      "epoch:1 step:1464 [D loss: 0.653946, acc.: 63.28%] [G loss: 0.959670]\n",
      "epoch:1 step:1465 [D loss: 0.618239, acc.: 67.97%] [G loss: 0.942751]\n",
      "epoch:1 step:1466 [D loss: 0.624445, acc.: 64.06%] [G loss: 0.977421]\n",
      "epoch:1 step:1467 [D loss: 0.640586, acc.: 65.62%] [G loss: 0.942238]\n",
      "epoch:1 step:1468 [D loss: 0.595529, acc.: 66.41%] [G loss: 1.002366]\n",
      "epoch:1 step:1469 [D loss: 0.637740, acc.: 68.75%] [G loss: 1.012613]\n",
      "epoch:1 step:1470 [D loss: 0.629840, acc.: 68.75%] [G loss: 0.992367]\n",
      "epoch:1 step:1471 [D loss: 0.629964, acc.: 66.41%] [G loss: 1.019558]\n",
      "epoch:1 step:1472 [D loss: 0.643686, acc.: 65.62%] [G loss: 0.967368]\n",
      "epoch:1 step:1473 [D loss: 0.617335, acc.: 63.28%] [G loss: 0.900125]\n",
      "epoch:1 step:1474 [D loss: 0.630938, acc.: 60.16%] [G loss: 0.930928]\n",
      "epoch:1 step:1475 [D loss: 0.650761, acc.: 58.59%] [G loss: 0.927057]\n",
      "epoch:1 step:1476 [D loss: 0.585988, acc.: 70.31%] [G loss: 0.909334]\n",
      "epoch:1 step:1477 [D loss: 0.593093, acc.: 73.44%] [G loss: 0.912482]\n",
      "epoch:1 step:1478 [D loss: 0.606366, acc.: 65.62%] [G loss: 0.932170]\n",
      "epoch:1 step:1479 [D loss: 0.597573, acc.: 68.75%] [G loss: 0.891202]\n",
      "epoch:1 step:1480 [D loss: 0.636104, acc.: 71.09%] [G loss: 1.000432]\n",
      "epoch:1 step:1481 [D loss: 0.618273, acc.: 67.19%] [G loss: 0.911268]\n",
      "epoch:1 step:1482 [D loss: 0.597846, acc.: 64.06%] [G loss: 0.927816]\n",
      "epoch:1 step:1483 [D loss: 0.590758, acc.: 68.75%] [G loss: 0.928548]\n",
      "epoch:1 step:1484 [D loss: 0.620324, acc.: 66.41%] [G loss: 0.869440]\n",
      "epoch:1 step:1485 [D loss: 0.579248, acc.: 76.56%] [G loss: 0.923692]\n",
      "epoch:1 step:1486 [D loss: 0.595149, acc.: 71.88%] [G loss: 0.908089]\n",
      "epoch:1 step:1487 [D loss: 0.591217, acc.: 71.09%] [G loss: 0.919061]\n",
      "epoch:1 step:1488 [D loss: 0.626073, acc.: 67.19%] [G loss: 0.897648]\n",
      "epoch:1 step:1489 [D loss: 0.611131, acc.: 63.28%] [G loss: 0.878096]\n",
      "epoch:1 step:1490 [D loss: 0.659452, acc.: 59.38%] [G loss: 0.873535]\n",
      "epoch:1 step:1491 [D loss: 0.600602, acc.: 67.97%] [G loss: 0.866010]\n",
      "epoch:1 step:1492 [D loss: 0.620500, acc.: 65.62%] [G loss: 0.841572]\n",
      "epoch:1 step:1493 [D loss: 0.649818, acc.: 64.84%] [G loss: 0.890889]\n",
      "epoch:1 step:1494 [D loss: 0.583451, acc.: 75.00%] [G loss: 0.924823]\n",
      "epoch:1 step:1495 [D loss: 0.620654, acc.: 63.28%] [G loss: 0.984873]\n",
      "epoch:1 step:1496 [D loss: 0.637433, acc.: 60.16%] [G loss: 0.975769]\n",
      "epoch:1 step:1497 [D loss: 0.628992, acc.: 60.16%] [G loss: 0.907462]\n",
      "epoch:1 step:1498 [D loss: 0.621510, acc.: 61.72%] [G loss: 0.876463]\n",
      "epoch:1 step:1499 [D loss: 0.647193, acc.: 59.38%] [G loss: 0.941593]\n",
      "epoch:1 step:1500 [D loss: 0.553545, acc.: 72.66%] [G loss: 0.967673]\n",
      "epoch:1 step:1501 [D loss: 0.538466, acc.: 76.56%] [G loss: 0.980785]\n",
      "epoch:1 step:1502 [D loss: 0.590027, acc.: 68.75%] [G loss: 0.936991]\n",
      "epoch:1 step:1503 [D loss: 0.617936, acc.: 67.97%] [G loss: 0.997873]\n",
      "epoch:1 step:1504 [D loss: 0.640486, acc.: 62.50%] [G loss: 0.912551]\n",
      "epoch:1 step:1505 [D loss: 0.662335, acc.: 58.59%] [G loss: 0.983463]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1506 [D loss: 0.593989, acc.: 66.41%] [G loss: 0.907096]\n",
      "epoch:1 step:1507 [D loss: 0.622733, acc.: 64.84%] [G loss: 0.913239]\n",
      "epoch:1 step:1508 [D loss: 0.606153, acc.: 71.09%] [G loss: 0.894845]\n",
      "epoch:1 step:1509 [D loss: 0.576165, acc.: 75.78%] [G loss: 0.943410]\n",
      "epoch:1 step:1510 [D loss: 0.640489, acc.: 60.94%] [G loss: 0.919188]\n",
      "epoch:1 step:1511 [D loss: 0.618725, acc.: 60.94%] [G loss: 0.911659]\n",
      "epoch:1 step:1512 [D loss: 0.640136, acc.: 59.38%] [G loss: 0.923857]\n",
      "epoch:1 step:1513 [D loss: 0.634871, acc.: 67.19%] [G loss: 0.922387]\n",
      "epoch:1 step:1514 [D loss: 0.586736, acc.: 74.22%] [G loss: 0.997693]\n",
      "epoch:1 step:1515 [D loss: 0.599893, acc.: 70.31%] [G loss: 0.930142]\n",
      "epoch:1 step:1516 [D loss: 0.616519, acc.: 63.28%] [G loss: 0.978428]\n",
      "epoch:1 step:1517 [D loss: 0.620604, acc.: 65.62%] [G loss: 0.952168]\n",
      "epoch:1 step:1518 [D loss: 0.605509, acc.: 66.41%] [G loss: 0.918985]\n",
      "epoch:1 step:1519 [D loss: 0.572294, acc.: 67.19%] [G loss: 0.963009]\n",
      "epoch:1 step:1520 [D loss: 0.603476, acc.: 67.97%] [G loss: 0.969258]\n",
      "epoch:1 step:1521 [D loss: 0.577636, acc.: 71.09%] [G loss: 1.000951]\n",
      "epoch:1 step:1522 [D loss: 0.619163, acc.: 64.06%] [G loss: 0.944264]\n",
      "epoch:1 step:1523 [D loss: 0.671169, acc.: 64.06%] [G loss: 0.963588]\n",
      "epoch:1 step:1524 [D loss: 0.602058, acc.: 66.41%] [G loss: 0.953112]\n",
      "epoch:1 step:1525 [D loss: 0.611148, acc.: 71.09%] [G loss: 0.916755]\n",
      "epoch:1 step:1526 [D loss: 0.601331, acc.: 66.41%] [G loss: 0.957180]\n",
      "epoch:1 step:1527 [D loss: 0.587806, acc.: 69.53%] [G loss: 0.942328]\n",
      "epoch:1 step:1528 [D loss: 0.619559, acc.: 64.84%] [G loss: 0.931167]\n",
      "epoch:1 step:1529 [D loss: 0.614783, acc.: 67.97%] [G loss: 0.951292]\n",
      "epoch:1 step:1530 [D loss: 0.628204, acc.: 67.97%] [G loss: 0.867698]\n",
      "epoch:1 step:1531 [D loss: 0.586817, acc.: 67.19%] [G loss: 0.961162]\n",
      "epoch:1 step:1532 [D loss: 0.612622, acc.: 67.97%] [G loss: 0.891250]\n",
      "epoch:1 step:1533 [D loss: 0.591859, acc.: 71.09%] [G loss: 0.971225]\n",
      "epoch:1 step:1534 [D loss: 0.602589, acc.: 66.41%] [G loss: 0.905117]\n",
      "epoch:1 step:1535 [D loss: 0.607227, acc.: 68.75%] [G loss: 0.904909]\n",
      "epoch:1 step:1536 [D loss: 0.598738, acc.: 64.84%] [G loss: 0.908475]\n",
      "epoch:1 step:1537 [D loss: 0.668134, acc.: 57.03%] [G loss: 0.888973]\n",
      "epoch:1 step:1538 [D loss: 0.645893, acc.: 62.50%] [G loss: 0.877136]\n",
      "epoch:1 step:1539 [D loss: 0.615998, acc.: 66.41%] [G loss: 0.892903]\n",
      "epoch:1 step:1540 [D loss: 0.627035, acc.: 64.84%] [G loss: 1.014072]\n",
      "epoch:1 step:1541 [D loss: 0.622027, acc.: 63.28%] [G loss: 1.020089]\n",
      "epoch:1 step:1542 [D loss: 0.587056, acc.: 74.22%] [G loss: 0.944165]\n",
      "epoch:1 step:1543 [D loss: 0.622536, acc.: 71.88%] [G loss: 0.917234]\n",
      "epoch:1 step:1544 [D loss: 0.610886, acc.: 66.41%] [G loss: 0.922789]\n",
      "epoch:1 step:1545 [D loss: 0.604805, acc.: 62.50%] [G loss: 0.928638]\n",
      "epoch:1 step:1546 [D loss: 0.573724, acc.: 71.88%] [G loss: 0.953611]\n",
      "epoch:1 step:1547 [D loss: 0.605241, acc.: 65.62%] [G loss: 0.922739]\n",
      "epoch:1 step:1548 [D loss: 0.606606, acc.: 66.41%] [G loss: 0.936694]\n",
      "epoch:1 step:1549 [D loss: 0.591316, acc.: 68.75%] [G loss: 0.984134]\n",
      "epoch:1 step:1550 [D loss: 0.623151, acc.: 59.38%] [G loss: 0.973984]\n",
      "epoch:1 step:1551 [D loss: 0.640197, acc.: 57.81%] [G loss: 0.960008]\n",
      "epoch:1 step:1552 [D loss: 0.630272, acc.: 59.38%] [G loss: 0.976236]\n",
      "epoch:1 step:1553 [D loss: 0.548477, acc.: 77.34%] [G loss: 0.864963]\n",
      "epoch:1 step:1554 [D loss: 0.607493, acc.: 68.75%] [G loss: 0.929514]\n",
      "epoch:1 step:1555 [D loss: 0.617315, acc.: 66.41%] [G loss: 0.972583]\n",
      "epoch:1 step:1556 [D loss: 0.611687, acc.: 65.62%] [G loss: 0.975564]\n",
      "epoch:1 step:1557 [D loss: 0.605539, acc.: 67.19%] [G loss: 0.981318]\n",
      "epoch:1 step:1558 [D loss: 0.634710, acc.: 64.06%] [G loss: 0.905026]\n",
      "epoch:1 step:1559 [D loss: 0.592824, acc.: 72.66%] [G loss: 0.984681]\n",
      "epoch:1 step:1560 [D loss: 0.616181, acc.: 68.75%] [G loss: 0.937840]\n",
      "epoch:1 step:1561 [D loss: 0.612516, acc.: 67.19%] [G loss: 0.945231]\n",
      "epoch:1 step:1562 [D loss: 0.632406, acc.: 64.06%] [G loss: 0.969310]\n",
      "epoch:1 step:1563 [D loss: 0.604665, acc.: 66.41%] [G loss: 0.967232]\n",
      "epoch:1 step:1564 [D loss: 0.558278, acc.: 75.00%] [G loss: 0.989540]\n",
      "epoch:1 step:1565 [D loss: 0.633116, acc.: 65.62%] [G loss: 0.934258]\n",
      "epoch:1 step:1566 [D loss: 0.613030, acc.: 71.88%] [G loss: 0.896813]\n",
      "epoch:1 step:1567 [D loss: 0.659750, acc.: 55.47%] [G loss: 0.907646]\n",
      "epoch:1 step:1568 [D loss: 0.586253, acc.: 68.75%] [G loss: 0.970199]\n",
      "epoch:1 step:1569 [D loss: 0.584512, acc.: 71.88%] [G loss: 0.908383]\n",
      "epoch:1 step:1570 [D loss: 0.611039, acc.: 67.97%] [G loss: 0.929239]\n",
      "epoch:1 step:1571 [D loss: 0.591761, acc.: 70.31%] [G loss: 0.981495]\n",
      "epoch:1 step:1572 [D loss: 0.639100, acc.: 61.72%] [G loss: 0.931853]\n",
      "epoch:1 step:1573 [D loss: 0.607657, acc.: 64.84%] [G loss: 0.905267]\n",
      "epoch:1 step:1574 [D loss: 0.617549, acc.: 62.50%] [G loss: 0.980096]\n",
      "epoch:1 step:1575 [D loss: 0.579872, acc.: 71.09%] [G loss: 0.922814]\n",
      "epoch:1 step:1576 [D loss: 0.638720, acc.: 63.28%] [G loss: 0.992008]\n",
      "epoch:1 step:1577 [D loss: 0.628985, acc.: 63.28%] [G loss: 0.883879]\n",
      "epoch:1 step:1578 [D loss: 0.677031, acc.: 61.72%] [G loss: 0.867873]\n",
      "epoch:1 step:1579 [D loss: 0.627008, acc.: 65.62%] [G loss: 0.932047]\n",
      "epoch:1 step:1580 [D loss: 0.618329, acc.: 66.41%] [G loss: 0.922066]\n",
      "epoch:1 step:1581 [D loss: 0.616840, acc.: 71.88%] [G loss: 0.891553]\n",
      "epoch:1 step:1582 [D loss: 0.636905, acc.: 57.03%] [G loss: 0.898459]\n",
      "epoch:1 step:1583 [D loss: 0.646442, acc.: 57.81%] [G loss: 0.906239]\n",
      "epoch:1 step:1584 [D loss: 0.635447, acc.: 67.19%] [G loss: 0.936053]\n",
      "epoch:1 step:1585 [D loss: 0.626471, acc.: 62.50%] [G loss: 0.967660]\n",
      "epoch:1 step:1586 [D loss: 0.647677, acc.: 56.25%] [G loss: 0.958656]\n",
      "epoch:1 step:1587 [D loss: 0.631736, acc.: 64.06%] [G loss: 0.927500]\n",
      "epoch:1 step:1588 [D loss: 0.645393, acc.: 64.06%] [G loss: 0.924355]\n",
      "epoch:1 step:1589 [D loss: 0.654976, acc.: 62.50%] [G loss: 0.908878]\n",
      "epoch:1 step:1590 [D loss: 0.614230, acc.: 64.84%] [G loss: 0.923003]\n",
      "epoch:1 step:1591 [D loss: 0.617175, acc.: 64.84%] [G loss: 0.922596]\n",
      "epoch:1 step:1592 [D loss: 0.625601, acc.: 64.84%] [G loss: 0.916669]\n",
      "epoch:1 step:1593 [D loss: 0.664098, acc.: 61.72%] [G loss: 0.943480]\n",
      "epoch:1 step:1594 [D loss: 0.654896, acc.: 62.50%] [G loss: 0.917053]\n",
      "epoch:1 step:1595 [D loss: 0.644942, acc.: 61.72%] [G loss: 0.886878]\n",
      "epoch:1 step:1596 [D loss: 0.630987, acc.: 67.19%] [G loss: 0.888168]\n",
      "epoch:1 step:1597 [D loss: 0.658113, acc.: 60.16%] [G loss: 0.895953]\n",
      "epoch:1 step:1598 [D loss: 0.639114, acc.: 55.47%] [G loss: 0.925554]\n",
      "epoch:1 step:1599 [D loss: 0.590736, acc.: 67.19%] [G loss: 0.899099]\n",
      "epoch:1 step:1600 [D loss: 0.598059, acc.: 65.62%] [G loss: 0.953965]\n",
      "##############\n",
      "[ 3.16793388  4.23064264  3.21630989  5.18071977  2.52763916 10.27426719\n",
      "  6.31613501  5.33175022  4.75633108  8.14868929]\n",
      "##########\n",
      "epoch:1 step:1601 [D loss: 0.631995, acc.: 61.72%] [G loss: 0.902740]\n",
      "epoch:1 step:1602 [D loss: 0.658104, acc.: 61.72%] [G loss: 0.907622]\n",
      "epoch:1 step:1603 [D loss: 0.587981, acc.: 69.53%] [G loss: 0.946271]\n",
      "epoch:1 step:1604 [D loss: 0.619660, acc.: 71.09%] [G loss: 0.966415]\n",
      "epoch:1 step:1605 [D loss: 0.630802, acc.: 61.72%] [G loss: 0.912206]\n",
      "epoch:1 step:1606 [D loss: 0.644449, acc.: 57.81%] [G loss: 0.874291]\n",
      "epoch:1 step:1607 [D loss: 0.656193, acc.: 61.72%] [G loss: 0.966807]\n",
      "epoch:1 step:1608 [D loss: 0.639767, acc.: 60.16%] [G loss: 0.974363]\n",
      "epoch:1 step:1609 [D loss: 0.635800, acc.: 61.72%] [G loss: 0.978643]\n",
      "epoch:1 step:1610 [D loss: 0.643275, acc.: 62.50%] [G loss: 0.953651]\n",
      "epoch:1 step:1611 [D loss: 0.633038, acc.: 64.84%] [G loss: 0.964992]\n",
      "epoch:1 step:1612 [D loss: 0.614887, acc.: 67.19%] [G loss: 0.889478]\n",
      "epoch:1 step:1613 [D loss: 0.669309, acc.: 59.38%] [G loss: 0.874892]\n",
      "epoch:1 step:1614 [D loss: 0.617748, acc.: 64.06%] [G loss: 0.892667]\n",
      "epoch:1 step:1615 [D loss: 0.609876, acc.: 64.84%] [G loss: 0.900483]\n",
      "epoch:1 step:1616 [D loss: 0.661317, acc.: 54.69%] [G loss: 0.912012]\n",
      "epoch:1 step:1617 [D loss: 0.628725, acc.: 60.16%] [G loss: 0.960567]\n",
      "epoch:1 step:1618 [D loss: 0.598653, acc.: 70.31%] [G loss: 0.939884]\n",
      "epoch:1 step:1619 [D loss: 0.618024, acc.: 62.50%] [G loss: 0.887042]\n",
      "epoch:1 step:1620 [D loss: 0.582068, acc.: 72.66%] [G loss: 0.940271]\n",
      "epoch:1 step:1621 [D loss: 0.581981, acc.: 68.75%] [G loss: 0.939292]\n",
      "epoch:1 step:1622 [D loss: 0.623402, acc.: 61.72%] [G loss: 0.928247]\n",
      "epoch:1 step:1623 [D loss: 0.631850, acc.: 60.16%] [G loss: 0.905066]\n",
      "epoch:1 step:1624 [D loss: 0.603749, acc.: 69.53%] [G loss: 0.904580]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1625 [D loss: 0.590820, acc.: 71.09%] [G loss: 0.898467]\n",
      "epoch:1 step:1626 [D loss: 0.596218, acc.: 67.97%] [G loss: 0.917147]\n",
      "epoch:1 step:1627 [D loss: 0.638663, acc.: 64.84%] [G loss: 0.926128]\n",
      "epoch:1 step:1628 [D loss: 0.591553, acc.: 66.41%] [G loss: 0.892484]\n",
      "epoch:1 step:1629 [D loss: 0.619363, acc.: 63.28%] [G loss: 0.880655]\n",
      "epoch:1 step:1630 [D loss: 0.609599, acc.: 65.62%] [G loss: 0.872982]\n",
      "epoch:1 step:1631 [D loss: 0.643203, acc.: 61.72%] [G loss: 0.861200]\n",
      "epoch:1 step:1632 [D loss: 0.606901, acc.: 66.41%] [G loss: 0.890288]\n",
      "epoch:1 step:1633 [D loss: 0.621129, acc.: 63.28%] [G loss: 0.906522]\n",
      "epoch:1 step:1634 [D loss: 0.612195, acc.: 65.62%] [G loss: 0.969702]\n",
      "epoch:1 step:1635 [D loss: 0.578757, acc.: 70.31%] [G loss: 0.885290]\n",
      "epoch:1 step:1636 [D loss: 0.654159, acc.: 62.50%] [G loss: 0.923270]\n",
      "epoch:1 step:1637 [D loss: 0.581085, acc.: 71.09%] [G loss: 0.810194]\n",
      "epoch:1 step:1638 [D loss: 0.627523, acc.: 61.72%] [G loss: 0.888973]\n",
      "epoch:1 step:1639 [D loss: 0.591802, acc.: 64.06%] [G loss: 0.918645]\n",
      "epoch:1 step:1640 [D loss: 0.623190, acc.: 64.84%] [G loss: 0.876428]\n",
      "epoch:1 step:1641 [D loss: 0.637499, acc.: 67.19%] [G loss: 0.951830]\n",
      "epoch:1 step:1642 [D loss: 0.614972, acc.: 60.16%] [G loss: 0.886682]\n",
      "epoch:1 step:1643 [D loss: 0.666828, acc.: 61.72%] [G loss: 0.954540]\n",
      "epoch:1 step:1644 [D loss: 0.644398, acc.: 63.28%] [G loss: 0.959247]\n",
      "epoch:1 step:1645 [D loss: 0.565995, acc.: 75.78%] [G loss: 0.944495]\n",
      "epoch:1 step:1646 [D loss: 0.667480, acc.: 57.03%] [G loss: 0.928722]\n",
      "epoch:1 step:1647 [D loss: 0.619658, acc.: 63.28%] [G loss: 0.844307]\n",
      "epoch:1 step:1648 [D loss: 0.573780, acc.: 75.00%] [G loss: 0.898952]\n",
      "epoch:1 step:1649 [D loss: 0.619798, acc.: 60.94%] [G loss: 0.907881]\n",
      "epoch:1 step:1650 [D loss: 0.636336, acc.: 66.41%] [G loss: 0.913876]\n",
      "epoch:1 step:1651 [D loss: 0.635395, acc.: 65.62%] [G loss: 0.914261]\n",
      "epoch:1 step:1652 [D loss: 0.631859, acc.: 68.75%] [G loss: 0.931460]\n",
      "epoch:1 step:1653 [D loss: 0.651379, acc.: 55.47%] [G loss: 0.967206]\n",
      "epoch:1 step:1654 [D loss: 0.627501, acc.: 67.97%] [G loss: 0.907121]\n",
      "epoch:1 step:1655 [D loss: 0.604894, acc.: 64.06%] [G loss: 0.886024]\n",
      "epoch:1 step:1656 [D loss: 0.616088, acc.: 64.84%] [G loss: 0.884001]\n",
      "epoch:1 step:1657 [D loss: 0.607680, acc.: 64.06%] [G loss: 0.847651]\n",
      "epoch:1 step:1658 [D loss: 0.594788, acc.: 63.28%] [G loss: 0.870156]\n",
      "epoch:1 step:1659 [D loss: 0.634578, acc.: 60.94%] [G loss: 0.917725]\n",
      "epoch:1 step:1660 [D loss: 0.628038, acc.: 65.62%] [G loss: 0.891255]\n",
      "epoch:1 step:1661 [D loss: 0.620607, acc.: 67.97%] [G loss: 0.867171]\n",
      "epoch:1 step:1662 [D loss: 0.599326, acc.: 66.41%] [G loss: 0.904953]\n",
      "epoch:1 step:1663 [D loss: 0.613664, acc.: 67.97%] [G loss: 0.941803]\n",
      "epoch:1 step:1664 [D loss: 0.577232, acc.: 74.22%] [G loss: 0.924261]\n",
      "epoch:1 step:1665 [D loss: 0.638475, acc.: 63.28%] [G loss: 0.904027]\n",
      "epoch:1 step:1666 [D loss: 0.585704, acc.: 69.53%] [G loss: 0.925579]\n",
      "epoch:1 step:1667 [D loss: 0.638124, acc.: 63.28%] [G loss: 0.866225]\n",
      "epoch:1 step:1668 [D loss: 0.679552, acc.: 57.81%] [G loss: 0.916740]\n",
      "epoch:1 step:1669 [D loss: 0.631106, acc.: 60.16%] [G loss: 0.893625]\n",
      "epoch:1 step:1670 [D loss: 0.638365, acc.: 61.72%] [G loss: 0.880552]\n",
      "epoch:1 step:1671 [D loss: 0.588174, acc.: 67.97%] [G loss: 0.924820]\n",
      "epoch:1 step:1672 [D loss: 0.623564, acc.: 67.97%] [G loss: 0.974066]\n",
      "epoch:1 step:1673 [D loss: 0.647171, acc.: 57.03%] [G loss: 0.936637]\n",
      "epoch:1 step:1674 [D loss: 0.615048, acc.: 67.97%] [G loss: 0.904377]\n",
      "epoch:1 step:1675 [D loss: 0.653764, acc.: 60.16%] [G loss: 0.904439]\n",
      "epoch:1 step:1676 [D loss: 0.639016, acc.: 60.94%] [G loss: 0.915640]\n",
      "epoch:1 step:1677 [D loss: 0.652164, acc.: 60.94%] [G loss: 0.891754]\n",
      "epoch:1 step:1678 [D loss: 0.640980, acc.: 62.50%] [G loss: 0.927354]\n",
      "epoch:1 step:1679 [D loss: 0.616907, acc.: 67.97%] [G loss: 0.915485]\n",
      "epoch:1 step:1680 [D loss: 0.660541, acc.: 57.81%] [G loss: 0.893537]\n",
      "epoch:1 step:1681 [D loss: 0.618904, acc.: 67.97%] [G loss: 0.959246]\n",
      "epoch:1 step:1682 [D loss: 0.611414, acc.: 67.19%] [G loss: 0.878486]\n",
      "epoch:1 step:1683 [D loss: 0.566379, acc.: 70.31%] [G loss: 0.974917]\n",
      "epoch:1 step:1684 [D loss: 0.617881, acc.: 65.62%] [G loss: 0.951943]\n",
      "epoch:1 step:1685 [D loss: 0.567502, acc.: 70.31%] [G loss: 1.002995]\n",
      "epoch:1 step:1686 [D loss: 0.673710, acc.: 61.72%] [G loss: 0.985717]\n",
      "epoch:1 step:1687 [D loss: 0.630844, acc.: 62.50%] [G loss: 0.910802]\n",
      "epoch:1 step:1688 [D loss: 0.619634, acc.: 62.50%] [G loss: 0.946349]\n",
      "epoch:1 step:1689 [D loss: 0.591595, acc.: 72.66%] [G loss: 0.941814]\n",
      "epoch:1 step:1690 [D loss: 0.606120, acc.: 67.19%] [G loss: 0.921116]\n",
      "epoch:1 step:1691 [D loss: 0.622793, acc.: 63.28%] [G loss: 0.887433]\n",
      "epoch:1 step:1692 [D loss: 0.608910, acc.: 68.75%] [G loss: 0.925913]\n",
      "epoch:1 step:1693 [D loss: 0.634586, acc.: 64.84%] [G loss: 0.891780]\n",
      "epoch:1 step:1694 [D loss: 0.648168, acc.: 60.16%] [G loss: 0.932848]\n",
      "epoch:1 step:1695 [D loss: 0.613154, acc.: 62.50%] [G loss: 1.027960]\n",
      "epoch:1 step:1696 [D loss: 0.598097, acc.: 64.84%] [G loss: 0.950215]\n",
      "epoch:1 step:1697 [D loss: 0.650782, acc.: 66.41%] [G loss: 0.978609]\n",
      "epoch:1 step:1698 [D loss: 0.640159, acc.: 57.81%] [G loss: 0.930629]\n",
      "epoch:1 step:1699 [D loss: 0.618257, acc.: 68.75%] [G loss: 0.927162]\n",
      "epoch:1 step:1700 [D loss: 0.575157, acc.: 69.53%] [G loss: 0.956958]\n",
      "epoch:1 step:1701 [D loss: 0.585674, acc.: 71.09%] [G loss: 0.927849]\n",
      "epoch:1 step:1702 [D loss: 0.622458, acc.: 68.75%] [G loss: 0.927051]\n",
      "epoch:1 step:1703 [D loss: 0.629435, acc.: 60.16%] [G loss: 0.948697]\n",
      "epoch:1 step:1704 [D loss: 0.633533, acc.: 60.94%] [G loss: 0.863658]\n",
      "epoch:1 step:1705 [D loss: 0.571246, acc.: 71.09%] [G loss: 0.955477]\n",
      "epoch:1 step:1706 [D loss: 0.639712, acc.: 64.84%] [G loss: 0.858831]\n",
      "epoch:1 step:1707 [D loss: 0.665978, acc.: 57.03%] [G loss: 0.904174]\n",
      "epoch:1 step:1708 [D loss: 0.584405, acc.: 74.22%] [G loss: 0.954145]\n",
      "epoch:1 step:1709 [D loss: 0.566603, acc.: 73.44%] [G loss: 0.895096]\n",
      "epoch:1 step:1710 [D loss: 0.610497, acc.: 66.41%] [G loss: 0.937755]\n",
      "epoch:1 step:1711 [D loss: 0.625379, acc.: 64.06%] [G loss: 0.980722]\n",
      "epoch:1 step:1712 [D loss: 0.628020, acc.: 64.84%] [G loss: 0.973999]\n",
      "epoch:1 step:1713 [D loss: 0.611229, acc.: 65.62%] [G loss: 0.930548]\n",
      "epoch:1 step:1714 [D loss: 0.597028, acc.: 70.31%] [G loss: 0.885696]\n",
      "epoch:1 step:1715 [D loss: 0.649891, acc.: 58.59%] [G loss: 0.943662]\n",
      "epoch:1 step:1716 [D loss: 0.581876, acc.: 71.88%] [G loss: 0.964652]\n",
      "epoch:1 step:1717 [D loss: 0.664490, acc.: 57.81%] [G loss: 0.907816]\n",
      "epoch:1 step:1718 [D loss: 0.637430, acc.: 60.94%] [G loss: 0.939762]\n",
      "epoch:1 step:1719 [D loss: 0.611699, acc.: 70.31%] [G loss: 0.911062]\n",
      "epoch:1 step:1720 [D loss: 0.663478, acc.: 61.72%] [G loss: 0.860734]\n",
      "epoch:1 step:1721 [D loss: 0.664506, acc.: 57.81%] [G loss: 0.915651]\n",
      "epoch:1 step:1722 [D loss: 0.633045, acc.: 64.84%] [G loss: 0.942327]\n",
      "epoch:1 step:1723 [D loss: 0.627438, acc.: 64.84%] [G loss: 0.905000]\n",
      "epoch:1 step:1724 [D loss: 0.647397, acc.: 57.81%] [G loss: 0.871137]\n",
      "epoch:1 step:1725 [D loss: 0.630764, acc.: 62.50%] [G loss: 0.841119]\n",
      "epoch:1 step:1726 [D loss: 0.608715, acc.: 65.62%] [G loss: 0.863624]\n",
      "epoch:1 step:1727 [D loss: 0.653072, acc.: 60.16%] [G loss: 0.859715]\n",
      "epoch:1 step:1728 [D loss: 0.620986, acc.: 59.38%] [G loss: 0.897953]\n",
      "epoch:1 step:1729 [D loss: 0.680000, acc.: 57.81%] [G loss: 0.911407]\n",
      "epoch:1 step:1730 [D loss: 0.632077, acc.: 64.06%] [G loss: 0.917341]\n",
      "epoch:1 step:1731 [D loss: 0.636220, acc.: 64.06%] [G loss: 0.953285]\n",
      "epoch:1 step:1732 [D loss: 0.643694, acc.: 59.38%] [G loss: 0.986599]\n",
      "epoch:1 step:1733 [D loss: 0.598229, acc.: 69.53%] [G loss: 0.949922]\n",
      "epoch:1 step:1734 [D loss: 0.652434, acc.: 58.59%] [G loss: 0.905272]\n",
      "epoch:1 step:1735 [D loss: 0.608178, acc.: 71.09%] [G loss: 0.886209]\n",
      "epoch:1 step:1736 [D loss: 0.595465, acc.: 68.75%] [G loss: 0.886895]\n",
      "epoch:1 step:1737 [D loss: 0.680487, acc.: 51.56%] [G loss: 0.900791]\n",
      "epoch:1 step:1738 [D loss: 0.627893, acc.: 67.97%] [G loss: 0.889596]\n",
      "epoch:1 step:1739 [D loss: 0.612689, acc.: 66.41%] [G loss: 0.904326]\n",
      "epoch:1 step:1740 [D loss: 0.679413, acc.: 55.47%] [G loss: 0.896469]\n",
      "epoch:1 step:1741 [D loss: 0.635568, acc.: 63.28%] [G loss: 0.883135]\n",
      "epoch:1 step:1742 [D loss: 0.613972, acc.: 61.72%] [G loss: 0.899737]\n",
      "epoch:1 step:1743 [D loss: 0.642222, acc.: 61.72%] [G loss: 0.843272]\n",
      "epoch:1 step:1744 [D loss: 0.626284, acc.: 60.94%] [G loss: 0.951047]\n",
      "epoch:1 step:1745 [D loss: 0.637990, acc.: 64.84%] [G loss: 0.890065]\n",
      "epoch:1 step:1746 [D loss: 0.653281, acc.: 59.38%] [G loss: 0.877002]\n",
      "epoch:1 step:1747 [D loss: 0.583691, acc.: 71.88%] [G loss: 0.904761]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1748 [D loss: 0.596828, acc.: 69.53%] [G loss: 0.891655]\n",
      "epoch:1 step:1749 [D loss: 0.653785, acc.: 60.94%] [G loss: 0.976790]\n",
      "epoch:1 step:1750 [D loss: 0.687864, acc.: 54.69%] [G loss: 0.912377]\n",
      "epoch:1 step:1751 [D loss: 0.633981, acc.: 62.50%] [G loss: 0.895822]\n",
      "epoch:1 step:1752 [D loss: 0.641948, acc.: 67.19%] [G loss: 0.900727]\n",
      "epoch:1 step:1753 [D loss: 0.563764, acc.: 75.00%] [G loss: 0.973260]\n",
      "epoch:1 step:1754 [D loss: 0.630355, acc.: 67.97%] [G loss: 0.936882]\n",
      "epoch:1 step:1755 [D loss: 0.641995, acc.: 62.50%] [G loss: 0.886888]\n",
      "epoch:1 step:1756 [D loss: 0.615821, acc.: 67.19%] [G loss: 0.890928]\n",
      "epoch:1 step:1757 [D loss: 0.627607, acc.: 65.62%] [G loss: 0.922734]\n",
      "epoch:1 step:1758 [D loss: 0.624243, acc.: 63.28%] [G loss: 0.893635]\n",
      "epoch:1 step:1759 [D loss: 0.610329, acc.: 64.06%] [G loss: 0.974717]\n",
      "epoch:1 step:1760 [D loss: 0.756520, acc.: 51.56%] [G loss: 0.897577]\n",
      "epoch:1 step:1761 [D loss: 0.642795, acc.: 60.94%] [G loss: 0.882614]\n",
      "epoch:1 step:1762 [D loss: 0.618070, acc.: 66.41%] [G loss: 0.918269]\n",
      "epoch:1 step:1763 [D loss: 0.579830, acc.: 64.06%] [G loss: 0.870323]\n",
      "epoch:1 step:1764 [D loss: 0.581218, acc.: 74.22%] [G loss: 0.866039]\n",
      "epoch:1 step:1765 [D loss: 0.651608, acc.: 55.47%] [G loss: 0.839877]\n",
      "epoch:1 step:1766 [D loss: 0.600721, acc.: 69.53%] [G loss: 0.880845]\n",
      "epoch:1 step:1767 [D loss: 0.639355, acc.: 64.84%] [G loss: 0.900544]\n",
      "epoch:1 step:1768 [D loss: 0.656574, acc.: 56.25%] [G loss: 0.902387]\n",
      "epoch:1 step:1769 [D loss: 0.620676, acc.: 63.28%] [G loss: 0.894641]\n",
      "epoch:1 step:1770 [D loss: 0.684378, acc.: 59.38%] [G loss: 0.908965]\n",
      "epoch:1 step:1771 [D loss: 0.631654, acc.: 64.06%] [G loss: 0.938832]\n",
      "epoch:1 step:1772 [D loss: 0.617597, acc.: 64.84%] [G loss: 0.967662]\n",
      "epoch:1 step:1773 [D loss: 0.591904, acc.: 71.09%] [G loss: 0.918483]\n",
      "epoch:1 step:1774 [D loss: 0.653104, acc.: 61.72%] [G loss: 0.978373]\n",
      "epoch:1 step:1775 [D loss: 0.614012, acc.: 67.97%] [G loss: 0.937512]\n",
      "epoch:1 step:1776 [D loss: 0.614449, acc.: 65.62%] [G loss: 0.948689]\n",
      "epoch:1 step:1777 [D loss: 0.629944, acc.: 58.59%] [G loss: 0.914139]\n",
      "epoch:1 step:1778 [D loss: 0.597114, acc.: 66.41%] [G loss: 0.926375]\n",
      "epoch:1 step:1779 [D loss: 0.667578, acc.: 57.03%] [G loss: 0.897103]\n",
      "epoch:1 step:1780 [D loss: 0.624137, acc.: 61.72%] [G loss: 0.938422]\n",
      "epoch:1 step:1781 [D loss: 0.641765, acc.: 60.94%] [G loss: 0.927423]\n",
      "epoch:1 step:1782 [D loss: 0.646214, acc.: 61.72%] [G loss: 0.897358]\n",
      "epoch:1 step:1783 [D loss: 0.624502, acc.: 61.72%] [G loss: 0.871228]\n",
      "epoch:1 step:1784 [D loss: 0.578320, acc.: 70.31%] [G loss: 0.922225]\n",
      "epoch:1 step:1785 [D loss: 0.641345, acc.: 60.16%] [G loss: 0.954738]\n",
      "epoch:1 step:1786 [D loss: 0.620477, acc.: 70.31%] [G loss: 0.899745]\n",
      "epoch:1 step:1787 [D loss: 0.588514, acc.: 70.31%] [G loss: 0.949063]\n",
      "epoch:1 step:1788 [D loss: 0.624241, acc.: 63.28%] [G loss: 0.919544]\n",
      "epoch:1 step:1789 [D loss: 0.602217, acc.: 68.75%] [G loss: 0.929060]\n",
      "epoch:1 step:1790 [D loss: 0.624469, acc.: 68.75%] [G loss: 0.859832]\n",
      "epoch:1 step:1791 [D loss: 0.606262, acc.: 64.06%] [G loss: 0.855278]\n",
      "epoch:1 step:1792 [D loss: 0.610269, acc.: 63.28%] [G loss: 0.870919]\n",
      "epoch:1 step:1793 [D loss: 0.655042, acc.: 58.59%] [G loss: 0.863990]\n",
      "epoch:1 step:1794 [D loss: 0.621850, acc.: 64.84%] [G loss: 0.883737]\n",
      "epoch:1 step:1795 [D loss: 0.630938, acc.: 62.50%] [G loss: 0.885575]\n",
      "epoch:1 step:1796 [D loss: 0.658618, acc.: 62.50%] [G loss: 0.927839]\n",
      "epoch:1 step:1797 [D loss: 0.640239, acc.: 60.94%] [G loss: 0.915451]\n",
      "epoch:1 step:1798 [D loss: 0.611340, acc.: 69.53%] [G loss: 0.887745]\n",
      "epoch:1 step:1799 [D loss: 0.615695, acc.: 65.62%] [G loss: 0.813536]\n",
      "epoch:1 step:1800 [D loss: 0.609758, acc.: 63.28%] [G loss: 0.866030]\n",
      "##############\n",
      "[3.06653546 3.2975845  3.39348418 5.55091196 2.7606986  8.48909439\n",
      " 5.31613501 5.39575547 4.8032209  8.14868929]\n",
      "##########\n",
      "epoch:1 step:1801 [D loss: 0.652674, acc.: 60.94%] [G loss: 0.934983]\n",
      "epoch:1 step:1802 [D loss: 0.644576, acc.: 62.50%] [G loss: 0.938678]\n",
      "epoch:1 step:1803 [D loss: 0.648457, acc.: 67.19%] [G loss: 0.942672]\n",
      "epoch:1 step:1804 [D loss: 0.619625, acc.: 68.75%] [G loss: 0.961074]\n",
      "epoch:1 step:1805 [D loss: 0.643751, acc.: 57.81%] [G loss: 0.909541]\n",
      "epoch:1 step:1806 [D loss: 0.620932, acc.: 66.41%] [G loss: 0.921400]\n",
      "epoch:1 step:1807 [D loss: 0.643665, acc.: 58.59%] [G loss: 0.943881]\n",
      "epoch:1 step:1808 [D loss: 0.586039, acc.: 69.53%] [G loss: 0.939515]\n",
      "epoch:1 step:1809 [D loss: 0.654948, acc.: 58.59%] [G loss: 0.921742]\n",
      "epoch:1 step:1810 [D loss: 0.617993, acc.: 66.41%] [G loss: 0.913992]\n",
      "epoch:1 step:1811 [D loss: 0.653452, acc.: 54.69%] [G loss: 0.877670]\n",
      "epoch:1 step:1812 [D loss: 0.659557, acc.: 61.72%] [G loss: 0.920448]\n",
      "epoch:1 step:1813 [D loss: 0.650660, acc.: 60.16%] [G loss: 0.858143]\n",
      "epoch:1 step:1814 [D loss: 0.632678, acc.: 60.94%] [G loss: 0.883666]\n",
      "epoch:1 step:1815 [D loss: 0.691467, acc.: 54.69%] [G loss: 0.844871]\n",
      "epoch:1 step:1816 [D loss: 0.643556, acc.: 64.84%] [G loss: 0.859868]\n",
      "epoch:1 step:1817 [D loss: 0.619712, acc.: 64.84%] [G loss: 0.919039]\n",
      "epoch:1 step:1818 [D loss: 0.675347, acc.: 59.38%] [G loss: 0.879918]\n",
      "epoch:1 step:1819 [D loss: 0.572262, acc.: 75.00%] [G loss: 0.912733]\n",
      "epoch:1 step:1820 [D loss: 0.640797, acc.: 62.50%] [G loss: 0.927521]\n",
      "epoch:1 step:1821 [D loss: 0.630814, acc.: 65.62%] [G loss: 0.966023]\n",
      "epoch:1 step:1822 [D loss: 0.665587, acc.: 59.38%] [G loss: 0.888279]\n",
      "epoch:1 step:1823 [D loss: 0.602010, acc.: 69.53%] [G loss: 1.004838]\n",
      "epoch:1 step:1824 [D loss: 0.644409, acc.: 60.94%] [G loss: 0.958311]\n",
      "epoch:1 step:1825 [D loss: 0.632438, acc.: 63.28%] [G loss: 0.949389]\n",
      "epoch:1 step:1826 [D loss: 0.619849, acc.: 60.94%] [G loss: 0.901020]\n",
      "epoch:1 step:1827 [D loss: 0.645148, acc.: 61.72%] [G loss: 0.943689]\n",
      "epoch:1 step:1828 [D loss: 0.645548, acc.: 62.50%] [G loss: 0.989419]\n",
      "epoch:1 step:1829 [D loss: 0.615303, acc.: 67.19%] [G loss: 0.939461]\n",
      "epoch:1 step:1830 [D loss: 0.631430, acc.: 61.72%] [G loss: 0.902441]\n",
      "epoch:1 step:1831 [D loss: 0.662855, acc.: 60.16%] [G loss: 0.905052]\n",
      "epoch:1 step:1832 [D loss: 0.575996, acc.: 69.53%] [G loss: 0.847553]\n",
      "epoch:1 step:1833 [D loss: 0.633012, acc.: 59.38%] [G loss: 0.872017]\n",
      "epoch:1 step:1834 [D loss: 0.610946, acc.: 63.28%] [G loss: 0.891560]\n",
      "epoch:1 step:1835 [D loss: 0.624649, acc.: 66.41%] [G loss: 0.932841]\n",
      "epoch:1 step:1836 [D loss: 0.630242, acc.: 66.41%] [G loss: 0.946090]\n",
      "epoch:1 step:1837 [D loss: 0.606322, acc.: 64.84%] [G loss: 0.911249]\n",
      "epoch:1 step:1838 [D loss: 0.638758, acc.: 58.59%] [G loss: 0.879161]\n",
      "epoch:1 step:1839 [D loss: 0.626419, acc.: 63.28%] [G loss: 0.920598]\n",
      "epoch:1 step:1840 [D loss: 0.640717, acc.: 64.06%] [G loss: 0.969333]\n",
      "epoch:1 step:1841 [D loss: 0.616719, acc.: 65.62%] [G loss: 0.905464]\n",
      "epoch:1 step:1842 [D loss: 0.587960, acc.: 74.22%] [G loss: 0.878181]\n",
      "epoch:1 step:1843 [D loss: 0.598559, acc.: 61.72%] [G loss: 0.930633]\n",
      "epoch:1 step:1844 [D loss: 0.642120, acc.: 58.59%] [G loss: 0.935781]\n",
      "epoch:1 step:1845 [D loss: 0.608921, acc.: 64.06%] [G loss: 0.906782]\n",
      "epoch:1 step:1846 [D loss: 0.637843, acc.: 57.81%] [G loss: 0.913947]\n",
      "epoch:1 step:1847 [D loss: 0.644877, acc.: 57.03%] [G loss: 0.911571]\n",
      "epoch:1 step:1848 [D loss: 0.632990, acc.: 68.75%] [G loss: 0.858482]\n",
      "epoch:1 step:1849 [D loss: 0.624664, acc.: 62.50%] [G loss: 0.890305]\n",
      "epoch:1 step:1850 [D loss: 0.610925, acc.: 66.41%] [G loss: 0.880958]\n",
      "epoch:1 step:1851 [D loss: 0.633328, acc.: 63.28%] [G loss: 0.823390]\n",
      "epoch:1 step:1852 [D loss: 0.642250, acc.: 69.53%] [G loss: 0.923751]\n",
      "epoch:1 step:1853 [D loss: 0.624828, acc.: 67.97%] [G loss: 0.921155]\n",
      "epoch:1 step:1854 [D loss: 0.602818, acc.: 65.62%] [G loss: 0.958281]\n",
      "epoch:1 step:1855 [D loss: 0.615492, acc.: 68.75%] [G loss: 0.926054]\n",
      "epoch:1 step:1856 [D loss: 0.636455, acc.: 63.28%] [G loss: 0.909402]\n",
      "epoch:1 step:1857 [D loss: 0.612045, acc.: 66.41%] [G loss: 0.925999]\n",
      "epoch:1 step:1858 [D loss: 0.650737, acc.: 61.72%] [G loss: 0.891198]\n",
      "epoch:1 step:1859 [D loss: 0.603154, acc.: 67.97%] [G loss: 0.853207]\n",
      "epoch:1 step:1860 [D loss: 0.640363, acc.: 57.81%] [G loss: 0.965916]\n",
      "epoch:1 step:1861 [D loss: 0.668371, acc.: 56.25%] [G loss: 0.904895]\n",
      "epoch:1 step:1862 [D loss: 0.652036, acc.: 64.06%] [G loss: 0.919874]\n",
      "epoch:1 step:1863 [D loss: 0.647178, acc.: 58.59%] [G loss: 0.882526]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1 step:1864 [D loss: 0.719142, acc.: 58.59%] [G loss: 0.902235]\n",
      "epoch:1 step:1865 [D loss: 0.645075, acc.: 57.03%] [G loss: 0.939371]\n",
      "epoch:1 step:1866 [D loss: 0.665172, acc.: 59.38%] [G loss: 0.922042]\n",
      "epoch:1 step:1867 [D loss: 0.632970, acc.: 59.38%] [G loss: 0.926717]\n",
      "epoch:1 step:1868 [D loss: 0.670900, acc.: 57.03%] [G loss: 0.909285]\n",
      "epoch:1 step:1869 [D loss: 0.653999, acc.: 61.72%] [G loss: 0.908053]\n",
      "epoch:1 step:1870 [D loss: 0.661808, acc.: 56.25%] [G loss: 0.878847]\n",
      "epoch:1 step:1871 [D loss: 0.647271, acc.: 64.84%] [G loss: 0.875138]\n",
      "epoch:1 step:1872 [D loss: 0.576315, acc.: 71.88%] [G loss: 0.874744]\n",
      "epoch:1 step:1873 [D loss: 0.641195, acc.: 64.06%] [G loss: 0.841837]\n",
      "epoch:1 step:1874 [D loss: 0.655400, acc.: 60.16%] [G loss: 0.834206]\n",
      "epoch:2 step:1875 [D loss: 0.630528, acc.: 66.41%] [G loss: 0.847483]\n",
      "epoch:2 step:1876 [D loss: 0.613581, acc.: 66.41%] [G loss: 0.872979]\n",
      "epoch:2 step:1877 [D loss: 0.591057, acc.: 67.97%] [G loss: 0.878641]\n",
      "epoch:2 step:1878 [D loss: 0.632375, acc.: 63.28%] [G loss: 0.935933]\n",
      "epoch:2 step:1879 [D loss: 0.661281, acc.: 55.47%] [G loss: 0.897431]\n",
      "epoch:2 step:1880 [D loss: 0.651869, acc.: 63.28%] [G loss: 0.860775]\n",
      "epoch:2 step:1881 [D loss: 0.642434, acc.: 60.16%] [G loss: 0.922396]\n",
      "epoch:2 step:1882 [D loss: 0.631552, acc.: 63.28%] [G loss: 0.851993]\n",
      "epoch:2 step:1883 [D loss: 0.625866, acc.: 64.06%] [G loss: 0.885503]\n",
      "epoch:2 step:1884 [D loss: 0.560567, acc.: 75.78%] [G loss: 0.926166]\n",
      "epoch:2 step:1885 [D loss: 0.589298, acc.: 68.75%] [G loss: 0.908132]\n",
      "epoch:2 step:1886 [D loss: 0.601648, acc.: 70.31%] [G loss: 0.931026]\n",
      "epoch:2 step:1887 [D loss: 0.625955, acc.: 65.62%] [G loss: 0.874148]\n",
      "epoch:2 step:1888 [D loss: 0.635651, acc.: 61.72%] [G loss: 0.869611]\n",
      "epoch:2 step:1889 [D loss: 0.629902, acc.: 63.28%] [G loss: 0.914386]\n",
      "epoch:2 step:1890 [D loss: 0.635615, acc.: 65.62%] [G loss: 0.941131]\n",
      "epoch:2 step:1891 [D loss: 0.609608, acc.: 67.19%] [G loss: 0.940121]\n",
      "epoch:2 step:1892 [D loss: 0.650478, acc.: 60.16%] [G loss: 0.928275]\n",
      "epoch:2 step:1893 [D loss: 0.621172, acc.: 67.97%] [G loss: 0.896348]\n",
      "epoch:2 step:1894 [D loss: 0.645099, acc.: 64.84%] [G loss: 0.927272]\n",
      "epoch:2 step:1895 [D loss: 0.654147, acc.: 62.50%] [G loss: 0.860390]\n",
      "epoch:2 step:1896 [D loss: 0.618572, acc.: 64.84%] [G loss: 0.915581]\n",
      "epoch:2 step:1897 [D loss: 0.656605, acc.: 63.28%] [G loss: 0.911960]\n",
      "epoch:2 step:1898 [D loss: 0.638264, acc.: 61.72%] [G loss: 0.860972]\n",
      "epoch:2 step:1899 [D loss: 0.660259, acc.: 64.06%] [G loss: 0.871673]\n",
      "epoch:2 step:1900 [D loss: 0.603318, acc.: 64.84%] [G loss: 0.891053]\n",
      "epoch:2 step:1901 [D loss: 0.604511, acc.: 68.75%] [G loss: 0.951358]\n",
      "epoch:2 step:1902 [D loss: 0.633451, acc.: 67.19%] [G loss: 0.900663]\n",
      "epoch:2 step:1903 [D loss: 0.691926, acc.: 56.25%] [G loss: 0.860519]\n",
      "epoch:2 step:1904 [D loss: 0.636247, acc.: 66.41%] [G loss: 0.869986]\n",
      "epoch:2 step:1905 [D loss: 0.631213, acc.: 61.72%] [G loss: 0.868840]\n",
      "epoch:2 step:1906 [D loss: 0.609014, acc.: 68.75%] [G loss: 0.885560]\n",
      "epoch:2 step:1907 [D loss: 0.663527, acc.: 58.59%] [G loss: 0.914506]\n",
      "epoch:2 step:1908 [D loss: 0.649669, acc.: 60.94%] [G loss: 0.909196]\n",
      "epoch:2 step:1909 [D loss: 0.627129, acc.: 64.06%] [G loss: 0.895544]\n",
      "epoch:2 step:1910 [D loss: 0.595236, acc.: 66.41%] [G loss: 0.963041]\n",
      "epoch:2 step:1911 [D loss: 0.639029, acc.: 60.16%] [G loss: 0.936152]\n",
      "epoch:2 step:1912 [D loss: 0.607734, acc.: 64.84%] [G loss: 0.889988]\n",
      "epoch:2 step:1913 [D loss: 0.650416, acc.: 61.72%] [G loss: 0.872306]\n",
      "epoch:2 step:1914 [D loss: 0.648074, acc.: 60.16%] [G loss: 0.822545]\n",
      "epoch:2 step:1915 [D loss: 0.611868, acc.: 70.31%] [G loss: 0.857983]\n",
      "epoch:2 step:1916 [D loss: 0.651816, acc.: 57.81%] [G loss: 0.883373]\n",
      "epoch:2 step:1917 [D loss: 0.603384, acc.: 66.41%] [G loss: 0.952411]\n",
      "epoch:2 step:1918 [D loss: 0.641958, acc.: 57.81%] [G loss: 0.937725]\n",
      "epoch:2 step:1919 [D loss: 0.675706, acc.: 57.03%] [G loss: 0.926027]\n",
      "epoch:2 step:1920 [D loss: 0.616137, acc.: 67.97%] [G loss: 0.876726]\n",
      "epoch:2 step:1921 [D loss: 0.617661, acc.: 65.62%] [G loss: 0.912519]\n",
      "epoch:2 step:1922 [D loss: 0.616157, acc.: 64.84%] [G loss: 0.841865]\n",
      "epoch:2 step:1923 [D loss: 0.640378, acc.: 66.41%] [G loss: 0.881968]\n",
      "epoch:2 step:1924 [D loss: 0.631945, acc.: 61.72%] [G loss: 0.864547]\n",
      "epoch:2 step:1925 [D loss: 0.620526, acc.: 68.75%] [G loss: 0.927467]\n",
      "epoch:2 step:1926 [D loss: 0.631725, acc.: 67.97%] [G loss: 0.896882]\n",
      "epoch:2 step:1927 [D loss: 0.648548, acc.: 57.03%] [G loss: 0.847728]\n",
      "epoch:2 step:1928 [D loss: 0.625147, acc.: 63.28%] [G loss: 0.910162]\n",
      "epoch:2 step:1929 [D loss: 0.639676, acc.: 57.81%] [G loss: 0.928948]\n",
      "epoch:2 step:1930 [D loss: 0.632100, acc.: 63.28%] [G loss: 0.938919]\n",
      "epoch:2 step:1931 [D loss: 0.648789, acc.: 54.69%] [G loss: 0.875544]\n",
      "epoch:2 step:1932 [D loss: 0.666233, acc.: 58.59%] [G loss: 0.910024]\n",
      "epoch:2 step:1933 [D loss: 0.598245, acc.: 67.19%] [G loss: 0.921600]\n",
      "epoch:2 step:1934 [D loss: 0.588618, acc.: 64.84%] [G loss: 0.946088]\n",
      "epoch:2 step:1935 [D loss: 0.630912, acc.: 64.84%] [G loss: 0.873856]\n",
      "epoch:2 step:1936 [D loss: 0.704744, acc.: 52.34%] [G loss: 0.877819]\n",
      "epoch:2 step:1937 [D loss: 0.620735, acc.: 64.84%] [G loss: 0.949039]\n",
      "epoch:2 step:1938 [D loss: 0.589612, acc.: 67.19%] [G loss: 0.889976]\n",
      "epoch:2 step:1939 [D loss: 0.607814, acc.: 66.41%] [G loss: 0.952110]\n",
      "epoch:2 step:1940 [D loss: 0.659416, acc.: 60.94%] [G loss: 0.908521]\n",
      "epoch:2 step:1941 [D loss: 0.670584, acc.: 55.47%] [G loss: 0.899880]\n",
      "epoch:2 step:1942 [D loss: 0.621691, acc.: 72.66%] [G loss: 0.905072]\n",
      "epoch:2 step:1943 [D loss: 0.627568, acc.: 67.97%] [G loss: 0.937949]\n",
      "epoch:2 step:1944 [D loss: 0.617963, acc.: 64.06%] [G loss: 0.895550]\n",
      "epoch:2 step:1945 [D loss: 0.625366, acc.: 67.19%] [G loss: 0.901627]\n",
      "epoch:2 step:1946 [D loss: 0.590280, acc.: 69.53%] [G loss: 0.880832]\n",
      "epoch:2 step:1947 [D loss: 0.574531, acc.: 75.00%] [G loss: 0.887731]\n",
      "epoch:2 step:1948 [D loss: 0.620366, acc.: 68.75%] [G loss: 0.882707]\n",
      "epoch:2 step:1949 [D loss: 0.628788, acc.: 63.28%] [G loss: 0.885066]\n",
      "epoch:2 step:1950 [D loss: 0.628943, acc.: 67.19%] [G loss: 0.906229]\n",
      "epoch:2 step:1951 [D loss: 0.656012, acc.: 58.59%] [G loss: 0.911199]\n",
      "epoch:2 step:1952 [D loss: 0.624607, acc.: 65.62%] [G loss: 0.988601]\n",
      "epoch:2 step:1953 [D loss: 0.663105, acc.: 63.28%] [G loss: 0.957831]\n",
      "epoch:2 step:1954 [D loss: 0.649891, acc.: 55.47%] [G loss: 0.984985]\n",
      "epoch:2 step:1955 [D loss: 0.639188, acc.: 63.28%] [G loss: 0.965241]\n",
      "epoch:2 step:1956 [D loss: 0.672086, acc.: 53.91%] [G loss: 0.952314]\n",
      "epoch:2 step:1957 [D loss: 0.677198, acc.: 52.34%] [G loss: 0.865211]\n",
      "epoch:2 step:1958 [D loss: 0.691267, acc.: 53.91%] [G loss: 0.880090]\n",
      "epoch:2 step:1959 [D loss: 0.647324, acc.: 59.38%] [G loss: 0.898204]\n",
      "epoch:2 step:1960 [D loss: 0.674815, acc.: 57.81%] [G loss: 0.922236]\n",
      "epoch:2 step:1961 [D loss: 0.590401, acc.: 74.22%] [G loss: 0.944852]\n",
      "epoch:2 step:1962 [D loss: 0.597393, acc.: 69.53%] [G loss: 0.969715]\n",
      "epoch:2 step:1963 [D loss: 0.585826, acc.: 73.44%] [G loss: 0.923313]\n",
      "epoch:2 step:1964 [D loss: 0.597449, acc.: 65.62%] [G loss: 0.892372]\n",
      "epoch:2 step:1965 [D loss: 0.665896, acc.: 58.59%] [G loss: 0.865066]\n",
      "epoch:2 step:1966 [D loss: 0.642162, acc.: 64.06%] [G loss: 0.923517]\n",
      "epoch:2 step:1967 [D loss: 0.672489, acc.: 53.12%] [G loss: 0.868331]\n",
      "epoch:2 step:1968 [D loss: 0.607739, acc.: 71.88%] [G loss: 0.934537]\n",
      "epoch:2 step:1969 [D loss: 0.617867, acc.: 67.19%] [G loss: 0.925953]\n",
      "epoch:2 step:1970 [D loss: 0.581232, acc.: 69.53%] [G loss: 0.989071]\n",
      "epoch:2 step:1971 [D loss: 0.581003, acc.: 69.53%] [G loss: 0.955463]\n",
      "epoch:2 step:1972 [D loss: 0.601559, acc.: 75.00%] [G loss: 0.917772]\n",
      "epoch:2 step:1973 [D loss: 0.596368, acc.: 73.44%] [G loss: 0.896300]\n",
      "epoch:2 step:1974 [D loss: 0.633275, acc.: 68.75%] [G loss: 0.859822]\n",
      "epoch:2 step:1975 [D loss: 0.613724, acc.: 67.19%] [G loss: 0.921794]\n",
      "epoch:2 step:1976 [D loss: 0.672897, acc.: 60.16%] [G loss: 0.822417]\n",
      "epoch:2 step:1977 [D loss: 0.629422, acc.: 60.94%] [G loss: 0.846847]\n",
      "epoch:2 step:1978 [D loss: 0.625527, acc.: 66.41%] [G loss: 0.842462]\n",
      "epoch:2 step:1979 [D loss: 0.618797, acc.: 67.97%] [G loss: 0.912465]\n",
      "epoch:2 step:1980 [D loss: 0.642159, acc.: 58.59%] [G loss: 0.976838]\n",
      "epoch:2 step:1981 [D loss: 0.616718, acc.: 67.97%] [G loss: 0.924406]\n",
      "epoch:2 step:1982 [D loss: 0.637469, acc.: 62.50%] [G loss: 0.931689]\n",
      "epoch:2 step:1983 [D loss: 0.564383, acc.: 71.09%] [G loss: 0.901485]\n",
      "epoch:2 step:1984 [D loss: 0.692920, acc.: 56.25%] [G loss: 0.844134]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:1985 [D loss: 0.626105, acc.: 64.06%] [G loss: 0.906065]\n",
      "epoch:2 step:1986 [D loss: 0.662733, acc.: 55.47%] [G loss: 0.843391]\n",
      "epoch:2 step:1987 [D loss: 0.606250, acc.: 61.72%] [G loss: 0.894802]\n",
      "epoch:2 step:1988 [D loss: 0.653076, acc.: 56.25%] [G loss: 0.944321]\n",
      "epoch:2 step:1989 [D loss: 0.631194, acc.: 64.84%] [G loss: 0.937037]\n",
      "epoch:2 step:1990 [D loss: 0.630379, acc.: 65.62%] [G loss: 0.915310]\n",
      "epoch:2 step:1991 [D loss: 0.632400, acc.: 63.28%] [G loss: 0.917766]\n",
      "epoch:2 step:1992 [D loss: 0.645324, acc.: 56.25%] [G loss: 0.944106]\n",
      "epoch:2 step:1993 [D loss: 0.628405, acc.: 64.06%] [G loss: 0.915167]\n",
      "epoch:2 step:1994 [D loss: 0.664384, acc.: 58.59%] [G loss: 0.913438]\n",
      "epoch:2 step:1995 [D loss: 0.647443, acc.: 63.28%] [G loss: 0.881447]\n",
      "epoch:2 step:1996 [D loss: 0.622758, acc.: 64.84%] [G loss: 0.894466]\n",
      "epoch:2 step:1997 [D loss: 0.613654, acc.: 64.06%] [G loss: 0.949162]\n",
      "epoch:2 step:1998 [D loss: 0.677599, acc.: 56.25%] [G loss: 0.920164]\n",
      "epoch:2 step:1999 [D loss: 0.615380, acc.: 69.53%] [G loss: 0.960560]\n",
      "epoch:2 step:2000 [D loss: 0.654680, acc.: 57.81%] [G loss: 0.901099]\n",
      "##############\n",
      "[2.94027319 3.07209883 3.51669515 4.27769083 2.18391276 7.89271693\n",
      " 3.07966301 4.76944163 4.42262791 5.19734229]\n",
      "##########\n",
      "epoch:2 step:2001 [D loss: 0.631271, acc.: 68.75%] [G loss: 0.908707]\n",
      "epoch:2 step:2002 [D loss: 0.651273, acc.: 62.50%] [G loss: 0.877163]\n",
      "epoch:2 step:2003 [D loss: 0.634440, acc.: 69.53%] [G loss: 0.928710]\n",
      "epoch:2 step:2004 [D loss: 0.623223, acc.: 64.84%] [G loss: 0.842903]\n",
      "epoch:2 step:2005 [D loss: 0.607766, acc.: 67.97%] [G loss: 0.875898]\n",
      "epoch:2 step:2006 [D loss: 0.658409, acc.: 66.41%] [G loss: 0.912069]\n",
      "epoch:2 step:2007 [D loss: 0.644602, acc.: 63.28%] [G loss: 0.831463]\n",
      "epoch:2 step:2008 [D loss: 0.623695, acc.: 62.50%] [G loss: 0.823720]\n",
      "epoch:2 step:2009 [D loss: 0.636486, acc.: 67.19%] [G loss: 0.832554]\n",
      "epoch:2 step:2010 [D loss: 0.656512, acc.: 57.03%] [G loss: 0.966084]\n",
      "epoch:2 step:2011 [D loss: 0.624842, acc.: 58.59%] [G loss: 0.886632]\n",
      "epoch:2 step:2012 [D loss: 0.635053, acc.: 58.59%] [G loss: 0.857211]\n",
      "epoch:2 step:2013 [D loss: 0.596714, acc.: 64.84%] [G loss: 0.892153]\n",
      "epoch:2 step:2014 [D loss: 0.665521, acc.: 64.06%] [G loss: 0.891729]\n",
      "epoch:2 step:2015 [D loss: 0.640306, acc.: 66.41%] [G loss: 0.840461]\n",
      "epoch:2 step:2016 [D loss: 0.604635, acc.: 66.41%] [G loss: 0.910001]\n",
      "epoch:2 step:2017 [D loss: 0.650823, acc.: 60.16%] [G loss: 0.864870]\n",
      "epoch:2 step:2018 [D loss: 0.630263, acc.: 67.97%] [G loss: 0.878168]\n",
      "epoch:2 step:2019 [D loss: 0.612179, acc.: 64.84%] [G loss: 0.894020]\n",
      "epoch:2 step:2020 [D loss: 0.607478, acc.: 71.09%] [G loss: 0.921374]\n",
      "epoch:2 step:2021 [D loss: 0.638120, acc.: 59.38%] [G loss: 0.880997]\n",
      "epoch:2 step:2022 [D loss: 0.597824, acc.: 67.97%] [G loss: 0.908424]\n",
      "epoch:2 step:2023 [D loss: 0.631409, acc.: 61.72%] [G loss: 0.917995]\n",
      "epoch:2 step:2024 [D loss: 0.664438, acc.: 57.81%] [G loss: 0.880644]\n",
      "epoch:2 step:2025 [D loss: 0.649056, acc.: 66.41%] [G loss: 0.943157]\n",
      "epoch:2 step:2026 [D loss: 0.660122, acc.: 53.91%] [G loss: 0.951836]\n",
      "epoch:2 step:2027 [D loss: 0.630468, acc.: 63.28%] [G loss: 0.914599]\n",
      "epoch:2 step:2028 [D loss: 0.619369, acc.: 64.06%] [G loss: 0.973265]\n",
      "epoch:2 step:2029 [D loss: 0.612356, acc.: 67.97%] [G loss: 0.929566]\n",
      "epoch:2 step:2030 [D loss: 0.591206, acc.: 69.53%] [G loss: 0.973107]\n",
      "epoch:2 step:2031 [D loss: 0.635154, acc.: 65.62%] [G loss: 0.949852]\n",
      "epoch:2 step:2032 [D loss: 0.622173, acc.: 62.50%] [G loss: 0.913405]\n",
      "epoch:2 step:2033 [D loss: 0.605587, acc.: 67.97%] [G loss: 0.903899]\n",
      "epoch:2 step:2034 [D loss: 0.655146, acc.: 57.81%] [G loss: 0.932696]\n",
      "epoch:2 step:2035 [D loss: 0.647606, acc.: 60.16%] [G loss: 0.933317]\n",
      "epoch:2 step:2036 [D loss: 0.629539, acc.: 60.94%] [G loss: 0.922451]\n",
      "epoch:2 step:2037 [D loss: 0.650676, acc.: 61.72%] [G loss: 0.900226]\n",
      "epoch:2 step:2038 [D loss: 0.664093, acc.: 60.94%] [G loss: 0.899368]\n",
      "epoch:2 step:2039 [D loss: 0.630203, acc.: 61.72%] [G loss: 0.931359]\n",
      "epoch:2 step:2040 [D loss: 0.651310, acc.: 60.94%] [G loss: 0.905346]\n",
      "epoch:2 step:2041 [D loss: 0.620362, acc.: 67.19%] [G loss: 0.889264]\n",
      "epoch:2 step:2042 [D loss: 0.614653, acc.: 67.19%] [G loss: 0.895481]\n",
      "epoch:2 step:2043 [D loss: 0.619982, acc.: 63.28%] [G loss: 0.866858]\n",
      "epoch:2 step:2044 [D loss: 0.653972, acc.: 58.59%] [G loss: 0.873165]\n",
      "epoch:2 step:2045 [D loss: 0.655271, acc.: 60.16%] [G loss: 0.835451]\n",
      "epoch:2 step:2046 [D loss: 0.591617, acc.: 65.62%] [G loss: 0.949482]\n",
      "epoch:2 step:2047 [D loss: 0.620492, acc.: 66.41%] [G loss: 0.886258]\n",
      "epoch:2 step:2048 [D loss: 0.631057, acc.: 60.16%] [G loss: 0.907737]\n",
      "epoch:2 step:2049 [D loss: 0.634418, acc.: 62.50%] [G loss: 0.895120]\n",
      "epoch:2 step:2050 [D loss: 0.634781, acc.: 62.50%] [G loss: 0.937992]\n",
      "epoch:2 step:2051 [D loss: 0.622326, acc.: 63.28%] [G loss: 0.944221]\n",
      "epoch:2 step:2052 [D loss: 0.605916, acc.: 66.41%] [G loss: 0.941196]\n",
      "epoch:2 step:2053 [D loss: 0.651529, acc.: 60.16%] [G loss: 0.966584]\n",
      "epoch:2 step:2054 [D loss: 0.627001, acc.: 64.84%] [G loss: 0.929932]\n",
      "epoch:2 step:2055 [D loss: 0.628657, acc.: 67.19%] [G loss: 0.945826]\n",
      "epoch:2 step:2056 [D loss: 0.601046, acc.: 65.62%] [G loss: 0.932085]\n",
      "epoch:2 step:2057 [D loss: 0.619192, acc.: 67.19%] [G loss: 1.010476]\n",
      "epoch:2 step:2058 [D loss: 0.585759, acc.: 73.44%] [G loss: 1.002978]\n",
      "epoch:2 step:2059 [D loss: 0.643251, acc.: 62.50%] [G loss: 0.996882]\n",
      "epoch:2 step:2060 [D loss: 0.635152, acc.: 61.72%] [G loss: 0.907571]\n",
      "epoch:2 step:2061 [D loss: 0.632037, acc.: 65.62%] [G loss: 0.914527]\n",
      "epoch:2 step:2062 [D loss: 0.650689, acc.: 66.41%] [G loss: 0.938706]\n",
      "epoch:2 step:2063 [D loss: 0.668651, acc.: 64.06%] [G loss: 0.880309]\n",
      "epoch:2 step:2064 [D loss: 0.636248, acc.: 63.28%] [G loss: 0.846661]\n",
      "epoch:2 step:2065 [D loss: 0.621390, acc.: 68.75%] [G loss: 0.869696]\n",
      "epoch:2 step:2066 [D loss: 0.634614, acc.: 64.84%] [G loss: 0.866501]\n",
      "epoch:2 step:2067 [D loss: 0.695407, acc.: 54.69%] [G loss: 0.876798]\n",
      "epoch:2 step:2068 [D loss: 0.650960, acc.: 60.16%] [G loss: 0.862922]\n",
      "epoch:2 step:2069 [D loss: 0.612246, acc.: 68.75%] [G loss: 0.897260]\n",
      "epoch:2 step:2070 [D loss: 0.604019, acc.: 66.41%] [G loss: 0.961347]\n",
      "epoch:2 step:2071 [D loss: 0.592913, acc.: 72.66%] [G loss: 0.921133]\n",
      "epoch:2 step:2072 [D loss: 0.582381, acc.: 71.09%] [G loss: 0.965568]\n",
      "epoch:2 step:2073 [D loss: 0.626985, acc.: 67.19%] [G loss: 0.959837]\n",
      "epoch:2 step:2074 [D loss: 0.666194, acc.: 53.91%] [G loss: 0.955277]\n",
      "epoch:2 step:2075 [D loss: 0.631339, acc.: 66.41%] [G loss: 1.015102]\n",
      "epoch:2 step:2076 [D loss: 0.608827, acc.: 71.88%] [G loss: 0.902228]\n",
      "epoch:2 step:2077 [D loss: 0.613252, acc.: 63.28%] [G loss: 0.918309]\n",
      "epoch:2 step:2078 [D loss: 0.582345, acc.: 69.53%] [G loss: 0.949819]\n",
      "epoch:2 step:2079 [D loss: 0.589165, acc.: 70.31%] [G loss: 0.905817]\n",
      "epoch:2 step:2080 [D loss: 0.620353, acc.: 64.06%] [G loss: 0.963664]\n",
      "epoch:2 step:2081 [D loss: 0.574355, acc.: 71.09%] [G loss: 0.937108]\n",
      "epoch:2 step:2082 [D loss: 0.589188, acc.: 67.19%] [G loss: 0.941454]\n",
      "epoch:2 step:2083 [D loss: 0.602422, acc.: 67.19%] [G loss: 0.990997]\n",
      "epoch:2 step:2084 [D loss: 0.597755, acc.: 72.66%] [G loss: 0.967657]\n",
      "epoch:2 step:2085 [D loss: 0.629570, acc.: 58.59%] [G loss: 0.966062]\n",
      "epoch:2 step:2086 [D loss: 0.624970, acc.: 62.50%] [G loss: 0.981818]\n",
      "epoch:2 step:2087 [D loss: 0.680654, acc.: 56.25%] [G loss: 0.985199]\n",
      "epoch:2 step:2088 [D loss: 0.669863, acc.: 59.38%] [G loss: 0.879099]\n",
      "epoch:2 step:2089 [D loss: 0.673665, acc.: 53.91%] [G loss: 0.936799]\n",
      "epoch:2 step:2090 [D loss: 0.629400, acc.: 63.28%] [G loss: 0.920073]\n",
      "epoch:2 step:2091 [D loss: 0.649038, acc.: 58.59%] [G loss: 0.941362]\n",
      "epoch:2 step:2092 [D loss: 0.674181, acc.: 57.03%] [G loss: 0.904190]\n",
      "epoch:2 step:2093 [D loss: 0.662039, acc.: 61.72%] [G loss: 0.944432]\n",
      "epoch:2 step:2094 [D loss: 0.678880, acc.: 58.59%] [G loss: 0.869584]\n",
      "epoch:2 step:2095 [D loss: 0.635466, acc.: 62.50%] [G loss: 0.808535]\n",
      "epoch:2 step:2096 [D loss: 0.620491, acc.: 70.31%] [G loss: 0.921462]\n",
      "epoch:2 step:2097 [D loss: 0.587217, acc.: 71.88%] [G loss: 0.941902]\n",
      "epoch:2 step:2098 [D loss: 0.617702, acc.: 63.28%] [G loss: 0.940232]\n",
      "epoch:2 step:2099 [D loss: 0.625539, acc.: 66.41%] [G loss: 0.836735]\n",
      "epoch:2 step:2100 [D loss: 0.610213, acc.: 64.06%] [G loss: 0.793551]\n",
      "epoch:2 step:2101 [D loss: 0.628224, acc.: 67.97%] [G loss: 0.875242]\n",
      "epoch:2 step:2102 [D loss: 0.618788, acc.: 64.84%] [G loss: 0.893750]\n",
      "epoch:2 step:2103 [D loss: 0.639682, acc.: 63.28%] [G loss: 0.915650]\n",
      "epoch:2 step:2104 [D loss: 0.591483, acc.: 68.75%] [G loss: 0.925472]\n",
      "epoch:2 step:2105 [D loss: 0.622661, acc.: 67.19%] [G loss: 0.926655]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2106 [D loss: 0.645797, acc.: 57.81%] [G loss: 0.880553]\n",
      "epoch:2 step:2107 [D loss: 0.620453, acc.: 63.28%] [G loss: 0.886940]\n",
      "epoch:2 step:2108 [D loss: 0.677714, acc.: 57.03%] [G loss: 0.899410]\n",
      "epoch:2 step:2109 [D loss: 0.670827, acc.: 57.03%] [G loss: 0.884709]\n",
      "epoch:2 step:2110 [D loss: 0.653593, acc.: 58.59%] [G loss: 0.946808]\n",
      "epoch:2 step:2111 [D loss: 0.635263, acc.: 64.06%] [G loss: 0.930412]\n",
      "epoch:2 step:2112 [D loss: 0.651125, acc.: 64.06%] [G loss: 1.001830]\n",
      "epoch:2 step:2113 [D loss: 0.660126, acc.: 60.16%] [G loss: 0.939139]\n",
      "epoch:2 step:2114 [D loss: 0.621433, acc.: 64.06%] [G loss: 0.906211]\n",
      "epoch:2 step:2115 [D loss: 0.681929, acc.: 53.91%] [G loss: 0.922333]\n",
      "epoch:2 step:2116 [D loss: 0.647212, acc.: 64.06%] [G loss: 0.902923]\n",
      "epoch:2 step:2117 [D loss: 0.642416, acc.: 62.50%] [G loss: 0.884158]\n",
      "epoch:2 step:2118 [D loss: 0.651694, acc.: 59.38%] [G loss: 0.895799]\n",
      "epoch:2 step:2119 [D loss: 0.666594, acc.: 57.03%] [G loss: 0.879208]\n",
      "epoch:2 step:2120 [D loss: 0.662454, acc.: 57.03%] [G loss: 0.850217]\n",
      "epoch:2 step:2121 [D loss: 0.631006, acc.: 65.62%] [G loss: 0.890230]\n",
      "epoch:2 step:2122 [D loss: 0.626484, acc.: 57.81%] [G loss: 0.908508]\n",
      "epoch:2 step:2123 [D loss: 0.654638, acc.: 64.06%] [G loss: 0.869816]\n",
      "epoch:2 step:2124 [D loss: 0.614380, acc.: 66.41%] [G loss: 0.871052]\n",
      "epoch:2 step:2125 [D loss: 0.628795, acc.: 62.50%] [G loss: 0.873634]\n",
      "epoch:2 step:2126 [D loss: 0.643116, acc.: 57.81%] [G loss: 0.941406]\n",
      "epoch:2 step:2127 [D loss: 0.632318, acc.: 60.94%] [G loss: 0.896649]\n",
      "epoch:2 step:2128 [D loss: 0.609259, acc.: 67.97%] [G loss: 0.846033]\n",
      "epoch:2 step:2129 [D loss: 0.626844, acc.: 60.94%] [G loss: 0.901141]\n",
      "epoch:2 step:2130 [D loss: 0.650165, acc.: 61.72%] [G loss: 0.926127]\n",
      "epoch:2 step:2131 [D loss: 0.630209, acc.: 64.84%] [G loss: 0.888193]\n",
      "epoch:2 step:2132 [D loss: 0.619093, acc.: 65.62%] [G loss: 0.890241]\n",
      "epoch:2 step:2133 [D loss: 0.640215, acc.: 61.72%] [G loss: 0.869368]\n",
      "epoch:2 step:2134 [D loss: 0.669242, acc.: 61.72%] [G loss: 0.938018]\n",
      "epoch:2 step:2135 [D loss: 0.664724, acc.: 60.94%] [G loss: 0.902505]\n",
      "epoch:2 step:2136 [D loss: 0.613073, acc.: 66.41%] [G loss: 0.916720]\n",
      "epoch:2 step:2137 [D loss: 0.682856, acc.: 57.03%] [G loss: 0.953269]\n",
      "epoch:2 step:2138 [D loss: 0.607251, acc.: 66.41%] [G loss: 0.880018]\n",
      "epoch:2 step:2139 [D loss: 0.649858, acc.: 64.06%] [G loss: 0.882831]\n",
      "epoch:2 step:2140 [D loss: 0.637498, acc.: 69.53%] [G loss: 0.936713]\n",
      "epoch:2 step:2141 [D loss: 0.631691, acc.: 69.53%] [G loss: 0.990690]\n",
      "epoch:2 step:2142 [D loss: 0.617430, acc.: 72.66%] [G loss: 0.944629]\n",
      "epoch:2 step:2143 [D loss: 0.672870, acc.: 61.72%] [G loss: 0.847112]\n",
      "epoch:2 step:2144 [D loss: 0.651799, acc.: 58.59%] [G loss: 0.872859]\n",
      "epoch:2 step:2145 [D loss: 0.584771, acc.: 70.31%] [G loss: 0.851504]\n",
      "epoch:2 step:2146 [D loss: 0.696926, acc.: 52.34%] [G loss: 0.839337]\n",
      "epoch:2 step:2147 [D loss: 0.634002, acc.: 63.28%] [G loss: 0.892135]\n",
      "epoch:2 step:2148 [D loss: 0.657879, acc.: 54.69%] [G loss: 0.836274]\n",
      "epoch:2 step:2149 [D loss: 0.686828, acc.: 54.69%] [G loss: 0.954321]\n",
      "epoch:2 step:2150 [D loss: 0.675560, acc.: 53.12%] [G loss: 0.950017]\n",
      "epoch:2 step:2151 [D loss: 0.611110, acc.: 61.72%] [G loss: 0.944395]\n",
      "epoch:2 step:2152 [D loss: 0.615451, acc.: 70.31%] [G loss: 0.913591]\n",
      "epoch:2 step:2153 [D loss: 0.614575, acc.: 68.75%] [G loss: 0.887326]\n",
      "epoch:2 step:2154 [D loss: 0.614714, acc.: 65.62%] [G loss: 0.831604]\n",
      "epoch:2 step:2155 [D loss: 0.612916, acc.: 66.41%] [G loss: 0.858077]\n",
      "epoch:2 step:2156 [D loss: 0.646701, acc.: 60.94%] [G loss: 0.914284]\n",
      "epoch:2 step:2157 [D loss: 0.648376, acc.: 66.41%] [G loss: 0.896094]\n",
      "epoch:2 step:2158 [D loss: 0.589329, acc.: 71.09%] [G loss: 0.907892]\n",
      "epoch:2 step:2159 [D loss: 0.646300, acc.: 57.81%] [G loss: 0.947386]\n",
      "epoch:2 step:2160 [D loss: 0.640853, acc.: 62.50%] [G loss: 0.926975]\n",
      "epoch:2 step:2161 [D loss: 0.636990, acc.: 65.62%] [G loss: 0.912622]\n",
      "epoch:2 step:2162 [D loss: 0.654623, acc.: 58.59%] [G loss: 0.985546]\n",
      "epoch:2 step:2163 [D loss: 0.639675, acc.: 58.59%] [G loss: 0.863449]\n",
      "epoch:2 step:2164 [D loss: 0.602850, acc.: 60.16%] [G loss: 0.894889]\n",
      "epoch:2 step:2165 [D loss: 0.638572, acc.: 56.25%] [G loss: 0.885977]\n",
      "epoch:2 step:2166 [D loss: 0.636140, acc.: 61.72%] [G loss: 0.964172]\n",
      "epoch:2 step:2167 [D loss: 0.623353, acc.: 60.94%] [G loss: 0.943058]\n",
      "epoch:2 step:2168 [D loss: 0.613076, acc.: 66.41%] [G loss: 0.926991]\n",
      "epoch:2 step:2169 [D loss: 0.653869, acc.: 61.72%] [G loss: 0.891955]\n",
      "epoch:2 step:2170 [D loss: 0.643355, acc.: 66.41%] [G loss: 0.896342]\n",
      "epoch:2 step:2171 [D loss: 0.626510, acc.: 62.50%] [G loss: 0.926597]\n",
      "epoch:2 step:2172 [D loss: 0.604474, acc.: 66.41%] [G loss: 0.933561]\n",
      "epoch:2 step:2173 [D loss: 0.616549, acc.: 71.09%] [G loss: 0.858055]\n",
      "epoch:2 step:2174 [D loss: 0.590580, acc.: 67.97%] [G loss: 0.882235]\n",
      "epoch:2 step:2175 [D loss: 0.620485, acc.: 64.06%] [G loss: 0.879070]\n",
      "epoch:2 step:2176 [D loss: 0.610420, acc.: 67.97%] [G loss: 0.914168]\n",
      "epoch:2 step:2177 [D loss: 0.618835, acc.: 65.62%] [G loss: 0.918450]\n",
      "epoch:2 step:2178 [D loss: 0.610119, acc.: 66.41%] [G loss: 0.869642]\n",
      "epoch:2 step:2179 [D loss: 0.662742, acc.: 56.25%] [G loss: 0.858316]\n",
      "epoch:2 step:2180 [D loss: 0.601069, acc.: 67.97%] [G loss: 0.934236]\n",
      "epoch:2 step:2181 [D loss: 0.662037, acc.: 56.25%] [G loss: 0.914454]\n",
      "epoch:2 step:2182 [D loss: 0.620283, acc.: 64.84%] [G loss: 0.913836]\n",
      "epoch:2 step:2183 [D loss: 0.622819, acc.: 60.94%] [G loss: 0.908446]\n",
      "epoch:2 step:2184 [D loss: 0.652400, acc.: 59.38%] [G loss: 0.918924]\n",
      "epoch:2 step:2185 [D loss: 0.603603, acc.: 66.41%] [G loss: 0.905513]\n",
      "epoch:2 step:2186 [D loss: 0.687024, acc.: 59.38%] [G loss: 0.904834]\n",
      "epoch:2 step:2187 [D loss: 0.639755, acc.: 60.16%] [G loss: 0.908030]\n",
      "epoch:2 step:2188 [D loss: 0.647768, acc.: 57.81%] [G loss: 0.866742]\n",
      "epoch:2 step:2189 [D loss: 0.650986, acc.: 59.38%] [G loss: 0.869551]\n",
      "epoch:2 step:2190 [D loss: 0.590861, acc.: 68.75%] [G loss: 0.884656]\n",
      "epoch:2 step:2191 [D loss: 0.643155, acc.: 66.41%] [G loss: 0.860707]\n",
      "epoch:2 step:2192 [D loss: 0.684260, acc.: 55.47%] [G loss: 0.906777]\n",
      "epoch:2 step:2193 [D loss: 0.680694, acc.: 53.12%] [G loss: 0.915716]\n",
      "epoch:2 step:2194 [D loss: 0.637038, acc.: 66.41%] [G loss: 0.891388]\n",
      "epoch:2 step:2195 [D loss: 0.666375, acc.: 57.03%] [G loss: 0.915275]\n",
      "epoch:2 step:2196 [D loss: 0.653151, acc.: 57.81%] [G loss: 0.822318]\n",
      "epoch:2 step:2197 [D loss: 0.670154, acc.: 58.59%] [G loss: 0.857373]\n",
      "epoch:2 step:2198 [D loss: 0.612295, acc.: 67.19%] [G loss: 0.868839]\n",
      "epoch:2 step:2199 [D loss: 0.628790, acc.: 61.72%] [G loss: 0.903070]\n",
      "epoch:2 step:2200 [D loss: 0.618110, acc.: 63.28%] [G loss: 0.915756]\n",
      "##############\n",
      "[ 3.19880796  2.88349655  3.34498802  4.75645638  2.28728428 10.27426719\n",
      "  4.78837862  5.03770294  4.66032079  8.14868929]\n",
      "##########\n",
      "epoch:2 step:2201 [D loss: 0.601836, acc.: 73.44%] [G loss: 0.938976]\n",
      "epoch:2 step:2202 [D loss: 0.607084, acc.: 68.75%] [G loss: 0.891716]\n",
      "epoch:2 step:2203 [D loss: 0.676330, acc.: 59.38%] [G loss: 0.838974]\n",
      "epoch:2 step:2204 [D loss: 0.645907, acc.: 56.25%] [G loss: 0.864831]\n",
      "epoch:2 step:2205 [D loss: 0.650250, acc.: 57.81%] [G loss: 0.925135]\n",
      "epoch:2 step:2206 [D loss: 0.599393, acc.: 71.88%] [G loss: 0.986286]\n",
      "epoch:2 step:2207 [D loss: 0.665745, acc.: 57.81%] [G loss: 0.954254]\n",
      "epoch:2 step:2208 [D loss: 0.610810, acc.: 61.72%] [G loss: 0.936697]\n",
      "epoch:2 step:2209 [D loss: 0.740801, acc.: 46.88%] [G loss: 0.908083]\n",
      "epoch:2 step:2210 [D loss: 0.668169, acc.: 53.91%] [G loss: 0.945565]\n",
      "epoch:2 step:2211 [D loss: 0.613072, acc.: 70.31%] [G loss: 0.983402]\n",
      "epoch:2 step:2212 [D loss: 0.648851, acc.: 60.16%] [G loss: 0.872227]\n",
      "epoch:2 step:2213 [D loss: 0.654824, acc.: 65.62%] [G loss: 0.874843]\n",
      "epoch:2 step:2214 [D loss: 0.610321, acc.: 69.53%] [G loss: 0.841074]\n",
      "epoch:2 step:2215 [D loss: 0.644547, acc.: 66.41%] [G loss: 0.853459]\n",
      "epoch:2 step:2216 [D loss: 0.643792, acc.: 60.94%] [G loss: 0.941541]\n",
      "epoch:2 step:2217 [D loss: 0.644113, acc.: 66.41%] [G loss: 0.892961]\n",
      "epoch:2 step:2218 [D loss: 0.620561, acc.: 65.62%] [G loss: 0.779898]\n",
      "epoch:2 step:2219 [D loss: 0.669168, acc.: 60.94%] [G loss: 0.892875]\n",
      "epoch:2 step:2220 [D loss: 0.647792, acc.: 63.28%] [G loss: 0.913198]\n",
      "epoch:2 step:2221 [D loss: 0.589604, acc.: 70.31%] [G loss: 0.892378]\n",
      "epoch:2 step:2222 [D loss: 0.629093, acc.: 70.31%] [G loss: 0.870155]\n",
      "epoch:2 step:2223 [D loss: 0.608099, acc.: 63.28%] [G loss: 0.858536]\n",
      "epoch:2 step:2224 [D loss: 0.668942, acc.: 54.69%] [G loss: 0.895767]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2225 [D loss: 0.633878, acc.: 65.62%] [G loss: 0.843931]\n",
      "epoch:2 step:2226 [D loss: 0.611692, acc.: 68.75%] [G loss: 0.901516]\n",
      "epoch:2 step:2227 [D loss: 0.640159, acc.: 57.81%] [G loss: 0.933381]\n",
      "epoch:2 step:2228 [D loss: 0.638580, acc.: 60.16%] [G loss: 0.878341]\n",
      "epoch:2 step:2229 [D loss: 0.645942, acc.: 63.28%] [G loss: 0.880182]\n",
      "epoch:2 step:2230 [D loss: 0.681874, acc.: 51.56%] [G loss: 0.899115]\n",
      "epoch:2 step:2231 [D loss: 0.673640, acc.: 53.91%] [G loss: 0.916080]\n",
      "epoch:2 step:2232 [D loss: 0.680588, acc.: 56.25%] [G loss: 0.820358]\n",
      "epoch:2 step:2233 [D loss: 0.633959, acc.: 67.97%] [G loss: 0.818164]\n",
      "epoch:2 step:2234 [D loss: 0.639776, acc.: 60.94%] [G loss: 0.911287]\n",
      "epoch:2 step:2235 [D loss: 0.643120, acc.: 65.62%] [G loss: 0.807180]\n",
      "epoch:2 step:2236 [D loss: 0.613483, acc.: 63.28%] [G loss: 0.881562]\n",
      "epoch:2 step:2237 [D loss: 0.611833, acc.: 64.06%] [G loss: 0.954832]\n",
      "epoch:2 step:2238 [D loss: 0.584370, acc.: 65.62%] [G loss: 0.981091]\n",
      "epoch:2 step:2239 [D loss: 0.649744, acc.: 60.94%] [G loss: 0.971568]\n",
      "epoch:2 step:2240 [D loss: 0.634162, acc.: 64.06%] [G loss: 0.954044]\n",
      "epoch:2 step:2241 [D loss: 0.641991, acc.: 62.50%] [G loss: 0.903751]\n",
      "epoch:2 step:2242 [D loss: 0.647494, acc.: 57.81%] [G loss: 0.880837]\n",
      "epoch:2 step:2243 [D loss: 0.677014, acc.: 53.12%] [G loss: 0.851185]\n",
      "epoch:2 step:2244 [D loss: 0.643712, acc.: 59.38%] [G loss: 0.857268]\n",
      "epoch:2 step:2245 [D loss: 0.660586, acc.: 56.25%] [G loss: 0.823204]\n",
      "epoch:2 step:2246 [D loss: 0.629266, acc.: 61.72%] [G loss: 0.914440]\n",
      "epoch:2 step:2247 [D loss: 0.624766, acc.: 60.94%] [G loss: 0.907897]\n",
      "epoch:2 step:2248 [D loss: 0.627297, acc.: 72.66%] [G loss: 0.931494]\n",
      "epoch:2 step:2249 [D loss: 0.677342, acc.: 62.50%] [G loss: 0.922337]\n",
      "epoch:2 step:2250 [D loss: 0.683405, acc.: 54.69%] [G loss: 0.891109]\n",
      "epoch:2 step:2251 [D loss: 0.671157, acc.: 58.59%] [G loss: 0.900198]\n",
      "epoch:2 step:2252 [D loss: 0.636809, acc.: 58.59%] [G loss: 0.934015]\n",
      "epoch:2 step:2253 [D loss: 0.662676, acc.: 57.03%] [G loss: 0.951042]\n",
      "epoch:2 step:2254 [D loss: 0.650460, acc.: 66.41%] [G loss: 0.856970]\n",
      "epoch:2 step:2255 [D loss: 0.687522, acc.: 57.03%] [G loss: 0.842407]\n",
      "epoch:2 step:2256 [D loss: 0.616427, acc.: 67.97%] [G loss: 0.898996]\n",
      "epoch:2 step:2257 [D loss: 0.652159, acc.: 60.16%] [G loss: 0.890871]\n",
      "epoch:2 step:2258 [D loss: 0.647185, acc.: 64.84%] [G loss: 0.900431]\n",
      "epoch:2 step:2259 [D loss: 0.695879, acc.: 55.47%] [G loss: 0.891678]\n",
      "epoch:2 step:2260 [D loss: 0.663407, acc.: 51.56%] [G loss: 0.826981]\n",
      "epoch:2 step:2261 [D loss: 0.649562, acc.: 57.03%] [G loss: 0.899839]\n",
      "epoch:2 step:2262 [D loss: 0.649709, acc.: 63.28%] [G loss: 0.893564]\n",
      "epoch:2 step:2263 [D loss: 0.627785, acc.: 64.84%] [G loss: 0.826057]\n",
      "epoch:2 step:2264 [D loss: 0.612570, acc.: 70.31%] [G loss: 0.872976]\n",
      "epoch:2 step:2265 [D loss: 0.659911, acc.: 67.97%] [G loss: 0.883136]\n",
      "epoch:2 step:2266 [D loss: 0.631198, acc.: 61.72%] [G loss: 0.842524]\n",
      "epoch:2 step:2267 [D loss: 0.660710, acc.: 59.38%] [G loss: 0.887305]\n",
      "epoch:2 step:2268 [D loss: 0.612313, acc.: 57.81%] [G loss: 0.885888]\n",
      "epoch:2 step:2269 [D loss: 0.625536, acc.: 64.06%] [G loss: 0.921932]\n",
      "epoch:2 step:2270 [D loss: 0.632794, acc.: 63.28%] [G loss: 0.899204]\n",
      "epoch:2 step:2271 [D loss: 0.623536, acc.: 62.50%] [G loss: 0.867408]\n",
      "epoch:2 step:2272 [D loss: 0.592489, acc.: 71.09%] [G loss: 0.832855]\n",
      "epoch:2 step:2273 [D loss: 0.603210, acc.: 64.84%] [G loss: 0.906530]\n",
      "epoch:2 step:2274 [D loss: 0.635502, acc.: 62.50%] [G loss: 0.885122]\n",
      "epoch:2 step:2275 [D loss: 0.650370, acc.: 60.94%] [G loss: 0.930007]\n",
      "epoch:2 step:2276 [D loss: 0.637022, acc.: 67.19%] [G loss: 0.903121]\n",
      "epoch:2 step:2277 [D loss: 0.645806, acc.: 60.16%] [G loss: 0.957613]\n",
      "epoch:2 step:2278 [D loss: 0.643782, acc.: 58.59%] [G loss: 0.877362]\n",
      "epoch:2 step:2279 [D loss: 0.638559, acc.: 57.81%] [G loss: 0.874605]\n",
      "epoch:2 step:2280 [D loss: 0.602368, acc.: 65.62%] [G loss: 0.878901]\n",
      "epoch:2 step:2281 [D loss: 0.633196, acc.: 60.94%] [G loss: 0.914036]\n",
      "epoch:2 step:2282 [D loss: 0.624925, acc.: 65.62%] [G loss: 0.904919]\n",
      "epoch:2 step:2283 [D loss: 0.671353, acc.: 67.97%] [G loss: 0.851910]\n",
      "epoch:2 step:2284 [D loss: 0.670829, acc.: 59.38%] [G loss: 0.852987]\n",
      "epoch:2 step:2285 [D loss: 0.633023, acc.: 63.28%] [G loss: 0.875581]\n",
      "epoch:2 step:2286 [D loss: 0.629735, acc.: 64.06%] [G loss: 0.940198]\n",
      "epoch:2 step:2287 [D loss: 0.638753, acc.: 65.62%] [G loss: 0.947490]\n",
      "epoch:2 step:2288 [D loss: 0.666823, acc.: 60.16%] [G loss: 0.858488]\n",
      "epoch:2 step:2289 [D loss: 0.631436, acc.: 65.62%] [G loss: 0.878622]\n",
      "epoch:2 step:2290 [D loss: 0.629840, acc.: 67.97%] [G loss: 0.842526]\n",
      "epoch:2 step:2291 [D loss: 0.686091, acc.: 58.59%] [G loss: 0.833732]\n",
      "epoch:2 step:2292 [D loss: 0.647894, acc.: 57.81%] [G loss: 0.905398]\n",
      "epoch:2 step:2293 [D loss: 0.672560, acc.: 57.03%] [G loss: 0.850403]\n",
      "epoch:2 step:2294 [D loss: 0.669715, acc.: 55.47%] [G loss: 0.893352]\n",
      "epoch:2 step:2295 [D loss: 0.610371, acc.: 71.09%] [G loss: 0.914725]\n",
      "epoch:2 step:2296 [D loss: 0.631324, acc.: 61.72%] [G loss: 0.950238]\n",
      "epoch:2 step:2297 [D loss: 0.646585, acc.: 64.06%] [G loss: 0.872340]\n",
      "epoch:2 step:2298 [D loss: 0.630527, acc.: 63.28%] [G loss: 0.932698]\n",
      "epoch:2 step:2299 [D loss: 0.656356, acc.: 61.72%] [G loss: 0.905055]\n",
      "epoch:2 step:2300 [D loss: 0.645938, acc.: 64.06%] [G loss: 0.962740]\n",
      "epoch:2 step:2301 [D loss: 0.646083, acc.: 64.84%] [G loss: 0.912034]\n",
      "epoch:2 step:2302 [D loss: 0.678919, acc.: 57.03%] [G loss: 0.909294]\n",
      "epoch:2 step:2303 [D loss: 0.669166, acc.: 59.38%] [G loss: 0.881903]\n",
      "epoch:2 step:2304 [D loss: 0.667856, acc.: 61.72%] [G loss: 0.865462]\n",
      "epoch:2 step:2305 [D loss: 0.618116, acc.: 64.84%] [G loss: 0.835143]\n",
      "epoch:2 step:2306 [D loss: 0.616762, acc.: 64.06%] [G loss: 0.887047]\n",
      "epoch:2 step:2307 [D loss: 0.647262, acc.: 65.62%] [G loss: 0.903957]\n",
      "epoch:2 step:2308 [D loss: 0.644391, acc.: 60.94%] [G loss: 0.891311]\n",
      "epoch:2 step:2309 [D loss: 0.613479, acc.: 67.97%] [G loss: 0.961611]\n",
      "epoch:2 step:2310 [D loss: 0.600244, acc.: 71.09%] [G loss: 0.940129]\n",
      "epoch:2 step:2311 [D loss: 0.652337, acc.: 58.59%] [G loss: 0.872314]\n",
      "epoch:2 step:2312 [D loss: 0.680353, acc.: 57.81%] [G loss: 0.861187]\n",
      "epoch:2 step:2313 [D loss: 0.619498, acc.: 67.97%] [G loss: 0.874185]\n",
      "epoch:2 step:2314 [D loss: 0.608528, acc.: 65.62%] [G loss: 0.881431]\n",
      "epoch:2 step:2315 [D loss: 0.640899, acc.: 57.03%] [G loss: 0.944453]\n",
      "epoch:2 step:2316 [D loss: 0.645281, acc.: 63.28%] [G loss: 0.932199]\n",
      "epoch:2 step:2317 [D loss: 0.628007, acc.: 66.41%] [G loss: 0.890199]\n",
      "epoch:2 step:2318 [D loss: 0.608672, acc.: 67.19%] [G loss: 0.813351]\n",
      "epoch:2 step:2319 [D loss: 0.629223, acc.: 67.19%] [G loss: 0.939837]\n",
      "epoch:2 step:2320 [D loss: 0.664573, acc.: 58.59%] [G loss: 0.872430]\n",
      "epoch:2 step:2321 [D loss: 0.574198, acc.: 67.19%] [G loss: 0.928272]\n",
      "epoch:2 step:2322 [D loss: 0.626084, acc.: 70.31%] [G loss: 0.887213]\n",
      "epoch:2 step:2323 [D loss: 0.642009, acc.: 62.50%] [G loss: 0.855665]\n",
      "epoch:2 step:2324 [D loss: 0.611756, acc.: 67.19%] [G loss: 0.896378]\n",
      "epoch:2 step:2325 [D loss: 0.638438, acc.: 57.03%] [G loss: 0.898797]\n",
      "epoch:2 step:2326 [D loss: 0.691978, acc.: 53.91%] [G loss: 0.928427]\n",
      "epoch:2 step:2327 [D loss: 0.603907, acc.: 74.22%] [G loss: 0.958357]\n",
      "epoch:2 step:2328 [D loss: 0.685710, acc.: 57.81%] [G loss: 0.936944]\n",
      "epoch:2 step:2329 [D loss: 0.671826, acc.: 57.81%] [G loss: 0.870832]\n",
      "epoch:2 step:2330 [D loss: 0.676090, acc.: 61.72%] [G loss: 0.824942]\n",
      "epoch:2 step:2331 [D loss: 0.614627, acc.: 71.09%] [G loss: 0.905920]\n",
      "epoch:2 step:2332 [D loss: 0.628644, acc.: 62.50%] [G loss: 0.848481]\n",
      "epoch:2 step:2333 [D loss: 0.637581, acc.: 66.41%] [G loss: 0.864971]\n",
      "epoch:2 step:2334 [D loss: 0.621995, acc.: 66.41%] [G loss: 0.920155]\n",
      "epoch:2 step:2335 [D loss: 0.671478, acc.: 50.78%] [G loss: 0.914126]\n",
      "epoch:2 step:2336 [D loss: 0.675191, acc.: 60.16%] [G loss: 0.881618]\n",
      "epoch:2 step:2337 [D loss: 0.648871, acc.: 60.94%] [G loss: 0.862809]\n",
      "epoch:2 step:2338 [D loss: 0.624584, acc.: 67.97%] [G loss: 0.867436]\n",
      "epoch:2 step:2339 [D loss: 0.664097, acc.: 57.81%] [G loss: 0.892579]\n",
      "epoch:2 step:2340 [D loss: 0.650124, acc.: 57.81%] [G loss: 0.865916]\n",
      "epoch:2 step:2341 [D loss: 0.644723, acc.: 64.06%] [G loss: 0.856380]\n",
      "epoch:2 step:2342 [D loss: 0.628151, acc.: 64.84%] [G loss: 0.871846]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2343 [D loss: 0.627296, acc.: 61.72%] [G loss: 0.863662]\n",
      "epoch:2 step:2344 [D loss: 0.675454, acc.: 54.69%] [G loss: 0.827620]\n",
      "epoch:2 step:2345 [D loss: 0.666733, acc.: 64.06%] [G loss: 0.875470]\n",
      "epoch:2 step:2346 [D loss: 0.610107, acc.: 71.88%] [G loss: 0.866965]\n",
      "epoch:2 step:2347 [D loss: 0.670667, acc.: 59.38%] [G loss: 0.878630]\n",
      "epoch:2 step:2348 [D loss: 0.582739, acc.: 71.09%] [G loss: 0.893208]\n",
      "epoch:2 step:2349 [D loss: 0.627966, acc.: 64.84%] [G loss: 0.946250]\n",
      "epoch:2 step:2350 [D loss: 0.640969, acc.: 64.06%] [G loss: 0.861384]\n",
      "epoch:2 step:2351 [D loss: 0.635359, acc.: 60.16%] [G loss: 0.844070]\n",
      "epoch:2 step:2352 [D loss: 0.651644, acc.: 54.69%] [G loss: 0.863659]\n",
      "epoch:2 step:2353 [D loss: 0.597739, acc.: 70.31%] [G loss: 0.816392]\n",
      "epoch:2 step:2354 [D loss: 0.643731, acc.: 61.72%] [G loss: 0.922468]\n",
      "epoch:2 step:2355 [D loss: 0.638020, acc.: 61.72%] [G loss: 0.912831]\n",
      "epoch:2 step:2356 [D loss: 0.619871, acc.: 63.28%] [G loss: 0.907028]\n",
      "epoch:2 step:2357 [D loss: 0.647975, acc.: 64.06%] [G loss: 0.896213]\n",
      "epoch:2 step:2358 [D loss: 0.619323, acc.: 65.62%] [G loss: 0.841034]\n",
      "epoch:2 step:2359 [D loss: 0.628893, acc.: 65.62%] [G loss: 0.933676]\n",
      "epoch:2 step:2360 [D loss: 0.613816, acc.: 67.19%] [G loss: 0.810024]\n",
      "epoch:2 step:2361 [D loss: 0.684847, acc.: 51.56%] [G loss: 0.852673]\n",
      "epoch:2 step:2362 [D loss: 0.617526, acc.: 67.97%] [G loss: 0.829406]\n",
      "epoch:2 step:2363 [D loss: 0.639857, acc.: 63.28%] [G loss: 0.853648]\n",
      "epoch:2 step:2364 [D loss: 0.637192, acc.: 67.19%] [G loss: 0.865163]\n",
      "epoch:2 step:2365 [D loss: 0.624611, acc.: 68.75%] [G loss: 0.895115]\n",
      "epoch:2 step:2366 [D loss: 0.626348, acc.: 66.41%] [G loss: 0.910456]\n",
      "epoch:2 step:2367 [D loss: 0.662554, acc.: 58.59%] [G loss: 0.899197]\n",
      "epoch:2 step:2368 [D loss: 0.634234, acc.: 59.38%] [G loss: 0.929621]\n",
      "epoch:2 step:2369 [D loss: 0.669321, acc.: 58.59%] [G loss: 0.919445]\n",
      "epoch:2 step:2370 [D loss: 0.683631, acc.: 62.50%] [G loss: 0.909134]\n",
      "epoch:2 step:2371 [D loss: 0.613532, acc.: 71.88%] [G loss: 0.878795]\n",
      "epoch:2 step:2372 [D loss: 0.640019, acc.: 63.28%] [G loss: 0.895553]\n",
      "epoch:2 step:2373 [D loss: 0.668615, acc.: 55.47%] [G loss: 0.894169]\n",
      "epoch:2 step:2374 [D loss: 0.633250, acc.: 63.28%] [G loss: 0.920637]\n",
      "epoch:2 step:2375 [D loss: 0.651748, acc.: 62.50%] [G loss: 0.881947]\n",
      "epoch:2 step:2376 [D loss: 0.650287, acc.: 60.94%] [G loss: 0.861441]\n",
      "epoch:2 step:2377 [D loss: 0.575594, acc.: 72.66%] [G loss: 0.886687]\n",
      "epoch:2 step:2378 [D loss: 0.624951, acc.: 71.09%] [G loss: 0.878325]\n",
      "epoch:2 step:2379 [D loss: 0.634855, acc.: 58.59%] [G loss: 0.841465]\n",
      "epoch:2 step:2380 [D loss: 0.638221, acc.: 59.38%] [G loss: 0.869139]\n",
      "epoch:2 step:2381 [D loss: 0.644867, acc.: 57.81%] [G loss: 0.889350]\n",
      "epoch:2 step:2382 [D loss: 0.637629, acc.: 65.62%] [G loss: 0.928821]\n",
      "epoch:2 step:2383 [D loss: 0.651625, acc.: 60.94%] [G loss: 0.953750]\n",
      "epoch:2 step:2384 [D loss: 0.647435, acc.: 57.81%] [G loss: 0.886013]\n",
      "epoch:2 step:2385 [D loss: 0.633493, acc.: 66.41%] [G loss: 0.880038]\n",
      "epoch:2 step:2386 [D loss: 0.662291, acc.: 60.94%] [G loss: 0.861258]\n",
      "epoch:2 step:2387 [D loss: 0.648642, acc.: 54.69%] [G loss: 0.843992]\n",
      "epoch:2 step:2388 [D loss: 0.708262, acc.: 46.09%] [G loss: 0.925352]\n",
      "epoch:2 step:2389 [D loss: 0.627969, acc.: 62.50%] [G loss: 0.891296]\n",
      "epoch:2 step:2390 [D loss: 0.649226, acc.: 62.50%] [G loss: 0.897214]\n",
      "epoch:2 step:2391 [D loss: 0.661361, acc.: 63.28%] [G loss: 0.854014]\n",
      "epoch:2 step:2392 [D loss: 0.681463, acc.: 56.25%] [G loss: 0.872030]\n",
      "epoch:2 step:2393 [D loss: 0.627536, acc.: 64.06%] [G loss: 0.917091]\n",
      "epoch:2 step:2394 [D loss: 0.619707, acc.: 64.06%] [G loss: 0.916078]\n",
      "epoch:2 step:2395 [D loss: 0.638717, acc.: 64.06%] [G loss: 0.947610]\n",
      "epoch:2 step:2396 [D loss: 0.626421, acc.: 69.53%] [G loss: 0.890118]\n",
      "epoch:2 step:2397 [D loss: 0.617026, acc.: 67.97%] [G loss: 0.897058]\n",
      "epoch:2 step:2398 [D loss: 0.629670, acc.: 62.50%] [G loss: 0.878400]\n",
      "epoch:2 step:2399 [D loss: 0.664935, acc.: 56.25%] [G loss: 0.865729]\n",
      "epoch:2 step:2400 [D loss: 0.654352, acc.: 66.41%] [G loss: 0.885830]\n",
      "##############\n",
      "[ 3.23907261  2.71511086  3.39625348  4.36885507  2.03024396 10.27426719\n",
      "  4.01923006  5.33663451  4.66943579  8.14868929]\n",
      "##########\n",
      "epoch:2 step:2401 [D loss: 0.649429, acc.: 65.62%] [G loss: 0.907816]\n",
      "epoch:2 step:2402 [D loss: 0.649837, acc.: 63.28%] [G loss: 0.918767]\n",
      "epoch:2 step:2403 [D loss: 0.612134, acc.: 67.97%] [G loss: 0.891682]\n",
      "epoch:2 step:2404 [D loss: 0.646154, acc.: 64.84%] [G loss: 0.872772]\n",
      "epoch:2 step:2405 [D loss: 0.634008, acc.: 62.50%] [G loss: 0.879882]\n",
      "epoch:2 step:2406 [D loss: 0.692794, acc.: 54.69%] [G loss: 0.934796]\n",
      "epoch:2 step:2407 [D loss: 0.669187, acc.: 61.72%] [G loss: 0.865878]\n",
      "epoch:2 step:2408 [D loss: 0.662862, acc.: 57.81%] [G loss: 0.847211]\n",
      "epoch:2 step:2409 [D loss: 0.655912, acc.: 60.94%] [G loss: 0.834159]\n",
      "epoch:2 step:2410 [D loss: 0.667880, acc.: 62.50%] [G loss: 0.860169]\n",
      "epoch:2 step:2411 [D loss: 0.656215, acc.: 64.84%] [G loss: 0.821521]\n",
      "epoch:2 step:2412 [D loss: 0.669574, acc.: 60.16%] [G loss: 0.791529]\n",
      "epoch:2 step:2413 [D loss: 0.599485, acc.: 67.19%] [G loss: 0.916331]\n",
      "epoch:2 step:2414 [D loss: 0.588815, acc.: 70.31%] [G loss: 0.900750]\n",
      "epoch:2 step:2415 [D loss: 0.606414, acc.: 71.88%] [G loss: 0.909512]\n",
      "epoch:2 step:2416 [D loss: 0.565023, acc.: 75.78%] [G loss: 0.891626]\n",
      "epoch:2 step:2417 [D loss: 0.648534, acc.: 62.50%] [G loss: 0.890271]\n",
      "epoch:2 step:2418 [D loss: 0.611377, acc.: 67.19%] [G loss: 0.905814]\n",
      "epoch:2 step:2419 [D loss: 0.673588, acc.: 57.81%] [G loss: 0.823641]\n",
      "epoch:2 step:2420 [D loss: 0.645678, acc.: 62.50%] [G loss: 0.827110]\n",
      "epoch:2 step:2421 [D loss: 0.665079, acc.: 54.69%] [G loss: 0.904875]\n",
      "epoch:2 step:2422 [D loss: 0.644020, acc.: 65.62%] [G loss: 0.862556]\n",
      "epoch:2 step:2423 [D loss: 0.655848, acc.: 57.81%] [G loss: 0.858646]\n",
      "epoch:2 step:2424 [D loss: 0.640474, acc.: 64.06%] [G loss: 0.846758]\n",
      "epoch:2 step:2425 [D loss: 0.631156, acc.: 63.28%] [G loss: 0.924678]\n",
      "epoch:2 step:2426 [D loss: 0.627532, acc.: 63.28%] [G loss: 0.914751]\n",
      "epoch:2 step:2427 [D loss: 0.632856, acc.: 64.06%] [G loss: 0.870474]\n",
      "epoch:2 step:2428 [D loss: 0.624797, acc.: 62.50%] [G loss: 0.940443]\n",
      "epoch:2 step:2429 [D loss: 0.604982, acc.: 72.66%] [G loss: 0.885556]\n",
      "epoch:2 step:2430 [D loss: 0.658375, acc.: 60.94%] [G loss: 0.876735]\n",
      "epoch:2 step:2431 [D loss: 0.633299, acc.: 62.50%] [G loss: 0.906224]\n",
      "epoch:2 step:2432 [D loss: 0.658188, acc.: 58.59%] [G loss: 0.909077]\n",
      "epoch:2 step:2433 [D loss: 0.648872, acc.: 61.72%] [G loss: 0.881141]\n",
      "epoch:2 step:2434 [D loss: 0.664541, acc.: 57.81%] [G loss: 0.919959]\n",
      "epoch:2 step:2435 [D loss: 0.624027, acc.: 67.19%] [G loss: 0.934987]\n",
      "epoch:2 step:2436 [D loss: 0.595265, acc.: 72.66%] [G loss: 0.909380]\n",
      "epoch:2 step:2437 [D loss: 0.654978, acc.: 59.38%] [G loss: 0.882188]\n",
      "epoch:2 step:2438 [D loss: 0.609935, acc.: 65.62%] [G loss: 0.930281]\n",
      "epoch:2 step:2439 [D loss: 0.659898, acc.: 57.81%] [G loss: 0.837504]\n",
      "epoch:2 step:2440 [D loss: 0.640802, acc.: 62.50%] [G loss: 0.867251]\n",
      "epoch:2 step:2441 [D loss: 0.627845, acc.: 62.50%] [G loss: 0.921954]\n",
      "epoch:2 step:2442 [D loss: 0.691729, acc.: 54.69%] [G loss: 0.864321]\n",
      "epoch:2 step:2443 [D loss: 0.653924, acc.: 65.62%] [G loss: 0.898310]\n",
      "epoch:2 step:2444 [D loss: 0.645679, acc.: 62.50%] [G loss: 0.817758]\n",
      "epoch:2 step:2445 [D loss: 0.603194, acc.: 68.75%] [G loss: 0.856153]\n",
      "epoch:2 step:2446 [D loss: 0.603500, acc.: 71.09%] [G loss: 0.915418]\n",
      "epoch:2 step:2447 [D loss: 0.721425, acc.: 56.25%] [G loss: 0.839576]\n",
      "epoch:2 step:2448 [D loss: 0.678858, acc.: 57.81%] [G loss: 0.851605]\n",
      "epoch:2 step:2449 [D loss: 0.643367, acc.: 64.06%] [G loss: 0.929943]\n",
      "epoch:2 step:2450 [D loss: 0.606934, acc.: 64.06%] [G loss: 0.914796]\n",
      "epoch:2 step:2451 [D loss: 0.639471, acc.: 66.41%] [G loss: 0.972218]\n",
      "epoch:2 step:2452 [D loss: 0.625582, acc.: 65.62%] [G loss: 0.962177]\n",
      "epoch:2 step:2453 [D loss: 0.652837, acc.: 56.25%] [G loss: 0.899483]\n",
      "epoch:2 step:2454 [D loss: 0.710451, acc.: 50.00%] [G loss: 0.902152]\n",
      "epoch:2 step:2455 [D loss: 0.679259, acc.: 53.91%] [G loss: 0.836560]\n",
      "epoch:2 step:2456 [D loss: 0.622412, acc.: 66.41%] [G loss: 0.912965]\n",
      "epoch:2 step:2457 [D loss: 0.619500, acc.: 64.06%] [G loss: 0.922181]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2458 [D loss: 0.625865, acc.: 64.06%] [G loss: 0.966591]\n",
      "epoch:2 step:2459 [D loss: 0.647421, acc.: 59.38%] [G loss: 0.852383]\n",
      "epoch:2 step:2460 [D loss: 0.658794, acc.: 58.59%] [G loss: 0.868942]\n",
      "epoch:2 step:2461 [D loss: 0.659651, acc.: 60.16%] [G loss: 0.863949]\n",
      "epoch:2 step:2462 [D loss: 0.629000, acc.: 64.84%] [G loss: 0.893216]\n",
      "epoch:2 step:2463 [D loss: 0.606556, acc.: 67.97%] [G loss: 0.913070]\n",
      "epoch:2 step:2464 [D loss: 0.592055, acc.: 70.31%] [G loss: 0.888170]\n",
      "epoch:2 step:2465 [D loss: 0.615265, acc.: 64.84%] [G loss: 0.924335]\n",
      "epoch:2 step:2466 [D loss: 0.628283, acc.: 62.50%] [G loss: 0.936449]\n",
      "epoch:2 step:2467 [D loss: 0.638263, acc.: 64.06%] [G loss: 0.936809]\n",
      "epoch:2 step:2468 [D loss: 0.575728, acc.: 69.53%] [G loss: 0.862416]\n",
      "epoch:2 step:2469 [D loss: 0.650617, acc.: 64.84%] [G loss: 0.897538]\n",
      "epoch:2 step:2470 [D loss: 0.587613, acc.: 69.53%] [G loss: 0.927409]\n",
      "epoch:2 step:2471 [D loss: 0.644235, acc.: 64.06%] [G loss: 0.903732]\n",
      "epoch:2 step:2472 [D loss: 0.681555, acc.: 55.47%] [G loss: 0.927913]\n",
      "epoch:2 step:2473 [D loss: 0.630784, acc.: 63.28%] [G loss: 0.864169]\n",
      "epoch:2 step:2474 [D loss: 0.645413, acc.: 62.50%] [G loss: 0.901380]\n",
      "epoch:2 step:2475 [D loss: 0.670676, acc.: 61.72%] [G loss: 0.910542]\n",
      "epoch:2 step:2476 [D loss: 0.621973, acc.: 70.31%] [G loss: 0.922595]\n",
      "epoch:2 step:2477 [D loss: 0.681127, acc.: 53.12%] [G loss: 0.873234]\n",
      "epoch:2 step:2478 [D loss: 0.653560, acc.: 58.59%] [G loss: 0.937130]\n",
      "epoch:2 step:2479 [D loss: 0.675231, acc.: 57.81%] [G loss: 0.929986]\n",
      "epoch:2 step:2480 [D loss: 0.648397, acc.: 58.59%] [G loss: 0.944103]\n",
      "epoch:2 step:2481 [D loss: 0.648640, acc.: 65.62%] [G loss: 0.942638]\n",
      "epoch:2 step:2482 [D loss: 0.658918, acc.: 60.94%] [G loss: 0.872990]\n",
      "epoch:2 step:2483 [D loss: 0.600978, acc.: 69.53%] [G loss: 0.892281]\n",
      "epoch:2 step:2484 [D loss: 0.674973, acc.: 53.12%] [G loss: 0.848411]\n",
      "epoch:2 step:2485 [D loss: 0.634098, acc.: 64.06%] [G loss: 0.830234]\n",
      "epoch:2 step:2486 [D loss: 0.604303, acc.: 70.31%] [G loss: 0.851432]\n",
      "epoch:2 step:2487 [D loss: 0.662489, acc.: 53.12%] [G loss: 0.880608]\n",
      "epoch:2 step:2488 [D loss: 0.625345, acc.: 64.84%] [G loss: 0.862611]\n",
      "epoch:2 step:2489 [D loss: 0.651067, acc.: 59.38%] [G loss: 0.857499]\n",
      "epoch:2 step:2490 [D loss: 0.641312, acc.: 58.59%] [G loss: 0.915056]\n",
      "epoch:2 step:2491 [D loss: 0.649850, acc.: 60.94%] [G loss: 0.924386]\n",
      "epoch:2 step:2492 [D loss: 0.566753, acc.: 71.88%] [G loss: 0.953285]\n",
      "epoch:2 step:2493 [D loss: 0.676779, acc.: 57.81%] [G loss: 0.902775]\n",
      "epoch:2 step:2494 [D loss: 0.638957, acc.: 62.50%] [G loss: 0.891042]\n",
      "epoch:2 step:2495 [D loss: 0.622000, acc.: 62.50%] [G loss: 0.882067]\n",
      "epoch:2 step:2496 [D loss: 0.622097, acc.: 63.28%] [G loss: 0.885235]\n",
      "epoch:2 step:2497 [D loss: 0.656172, acc.: 60.16%] [G loss: 0.882216]\n",
      "epoch:2 step:2498 [D loss: 0.617458, acc.: 63.28%] [G loss: 0.845794]\n",
      "epoch:2 step:2499 [D loss: 0.669397, acc.: 62.50%] [G loss: 0.928994]\n",
      "epoch:2 step:2500 [D loss: 0.647961, acc.: 54.69%] [G loss: 0.930488]\n",
      "epoch:2 step:2501 [D loss: 0.600852, acc.: 68.75%] [G loss: 0.890188]\n",
      "epoch:2 step:2502 [D loss: 0.691268, acc.: 54.69%] [G loss: 0.864200]\n",
      "epoch:2 step:2503 [D loss: 0.662834, acc.: 57.81%] [G loss: 0.901981]\n",
      "epoch:2 step:2504 [D loss: 0.653916, acc.: 58.59%] [G loss: 0.901922]\n",
      "epoch:2 step:2505 [D loss: 0.597572, acc.: 68.75%] [G loss: 0.869812]\n",
      "epoch:2 step:2506 [D loss: 0.605709, acc.: 68.75%] [G loss: 0.893068]\n",
      "epoch:2 step:2507 [D loss: 0.631963, acc.: 60.94%] [G loss: 0.909883]\n",
      "epoch:2 step:2508 [D loss: 0.642193, acc.: 63.28%] [G loss: 0.886601]\n",
      "epoch:2 step:2509 [D loss: 0.638233, acc.: 61.72%] [G loss: 0.873057]\n",
      "epoch:2 step:2510 [D loss: 0.623396, acc.: 68.75%] [G loss: 0.901450]\n",
      "epoch:2 step:2511 [D loss: 0.649666, acc.: 62.50%] [G loss: 0.878444]\n",
      "epoch:2 step:2512 [D loss: 0.626912, acc.: 64.06%] [G loss: 0.947044]\n",
      "epoch:2 step:2513 [D loss: 0.655391, acc.: 56.25%] [G loss: 0.974369]\n",
      "epoch:2 step:2514 [D loss: 0.614619, acc.: 63.28%] [G loss: 0.877294]\n",
      "epoch:2 step:2515 [D loss: 0.627468, acc.: 70.31%] [G loss: 0.886424]\n",
      "epoch:2 step:2516 [D loss: 0.632673, acc.: 64.84%] [G loss: 0.913718]\n",
      "epoch:2 step:2517 [D loss: 0.689923, acc.: 53.91%] [G loss: 0.895361]\n",
      "epoch:2 step:2518 [D loss: 0.660491, acc.: 60.16%] [G loss: 0.888544]\n",
      "epoch:2 step:2519 [D loss: 0.629968, acc.: 59.38%] [G loss: 0.908809]\n",
      "epoch:2 step:2520 [D loss: 0.669474, acc.: 59.38%] [G loss: 0.861080]\n",
      "epoch:2 step:2521 [D loss: 0.661776, acc.: 60.94%] [G loss: 0.894397]\n",
      "epoch:2 step:2522 [D loss: 0.632592, acc.: 60.94%] [G loss: 0.916297]\n",
      "epoch:2 step:2523 [D loss: 0.661420, acc.: 56.25%] [G loss: 0.945400]\n",
      "epoch:2 step:2524 [D loss: 0.642760, acc.: 60.16%] [G loss: 0.916818]\n",
      "epoch:2 step:2525 [D loss: 0.658755, acc.: 60.16%] [G loss: 0.876913]\n",
      "epoch:2 step:2526 [D loss: 0.650429, acc.: 61.72%] [G loss: 0.907263]\n",
      "epoch:2 step:2527 [D loss: 0.647469, acc.: 60.94%] [G loss: 0.852318]\n",
      "epoch:2 step:2528 [D loss: 0.641595, acc.: 60.16%] [G loss: 0.899448]\n",
      "epoch:2 step:2529 [D loss: 0.611148, acc.: 63.28%] [G loss: 0.899277]\n",
      "epoch:2 step:2530 [D loss: 0.635263, acc.: 64.84%] [G loss: 0.862646]\n",
      "epoch:2 step:2531 [D loss: 0.684242, acc.: 54.69%] [G loss: 0.833254]\n",
      "epoch:2 step:2532 [D loss: 0.667479, acc.: 58.59%] [G loss: 0.832378]\n",
      "epoch:2 step:2533 [D loss: 0.649507, acc.: 64.06%] [G loss: 0.887371]\n",
      "epoch:2 step:2534 [D loss: 0.661407, acc.: 59.38%] [G loss: 0.873997]\n",
      "epoch:2 step:2535 [D loss: 0.643389, acc.: 61.72%] [G loss: 0.886533]\n",
      "epoch:2 step:2536 [D loss: 0.623167, acc.: 66.41%] [G loss: 0.869039]\n",
      "epoch:2 step:2537 [D loss: 0.632866, acc.: 64.06%] [G loss: 0.891526]\n",
      "epoch:2 step:2538 [D loss: 0.652281, acc.: 60.16%] [G loss: 0.870162]\n",
      "epoch:2 step:2539 [D loss: 0.653349, acc.: 63.28%] [G loss: 0.823845]\n",
      "epoch:2 step:2540 [D loss: 0.625762, acc.: 61.72%] [G loss: 0.860859]\n",
      "epoch:2 step:2541 [D loss: 0.610260, acc.: 74.22%] [G loss: 0.843577]\n",
      "epoch:2 step:2542 [D loss: 0.656968, acc.: 56.25%] [G loss: 0.821414]\n",
      "epoch:2 step:2543 [D loss: 0.665862, acc.: 62.50%] [G loss: 0.903532]\n",
      "epoch:2 step:2544 [D loss: 0.643037, acc.: 63.28%] [G loss: 0.894523]\n",
      "epoch:2 step:2545 [D loss: 0.628086, acc.: 65.62%] [G loss: 0.884338]\n",
      "epoch:2 step:2546 [D loss: 0.634070, acc.: 60.16%] [G loss: 0.924770]\n",
      "epoch:2 step:2547 [D loss: 0.656843, acc.: 60.16%] [G loss: 0.887882]\n",
      "epoch:2 step:2548 [D loss: 0.644514, acc.: 67.97%] [G loss: 0.910767]\n",
      "epoch:2 step:2549 [D loss: 0.676889, acc.: 57.03%] [G loss: 0.823124]\n",
      "epoch:2 step:2550 [D loss: 0.626216, acc.: 67.19%] [G loss: 0.832872]\n",
      "epoch:2 step:2551 [D loss: 0.702943, acc.: 50.00%] [G loss: 0.880369]\n",
      "epoch:2 step:2552 [D loss: 0.644588, acc.: 57.81%] [G loss: 0.865956]\n",
      "epoch:2 step:2553 [D loss: 0.652721, acc.: 61.72%] [G loss: 0.874137]\n",
      "epoch:2 step:2554 [D loss: 0.624153, acc.: 60.94%] [G loss: 0.870664]\n",
      "epoch:2 step:2555 [D loss: 0.631116, acc.: 62.50%] [G loss: 0.914135]\n",
      "epoch:2 step:2556 [D loss: 0.656814, acc.: 54.69%] [G loss: 0.900812]\n",
      "epoch:2 step:2557 [D loss: 0.613410, acc.: 64.84%] [G loss: 0.903838]\n",
      "epoch:2 step:2558 [D loss: 0.610437, acc.: 69.53%] [G loss: 0.875286]\n",
      "epoch:2 step:2559 [D loss: 0.664914, acc.: 62.50%] [G loss: 0.930851]\n",
      "epoch:2 step:2560 [D loss: 0.689596, acc.: 54.69%] [G loss: 0.890213]\n",
      "epoch:2 step:2561 [D loss: 0.659674, acc.: 61.72%] [G loss: 0.907795]\n",
      "epoch:2 step:2562 [D loss: 0.633057, acc.: 65.62%] [G loss: 0.900148]\n",
      "epoch:2 step:2563 [D loss: 0.621912, acc.: 64.84%] [G loss: 0.935946]\n",
      "epoch:2 step:2564 [D loss: 0.661551, acc.: 60.16%] [G loss: 0.890743]\n",
      "epoch:2 step:2565 [D loss: 0.614109, acc.: 65.62%] [G loss: 0.868631]\n",
      "epoch:2 step:2566 [D loss: 0.644595, acc.: 64.84%] [G loss: 0.859849]\n",
      "epoch:2 step:2567 [D loss: 0.611504, acc.: 64.06%] [G loss: 0.909617]\n",
      "epoch:2 step:2568 [D loss: 0.644533, acc.: 65.62%] [G loss: 0.891480]\n",
      "epoch:2 step:2569 [D loss: 0.636293, acc.: 64.06%] [G loss: 0.904335]\n",
      "epoch:2 step:2570 [D loss: 0.619950, acc.: 67.19%] [G loss: 0.860656]\n",
      "epoch:2 step:2571 [D loss: 0.645840, acc.: 60.94%] [G loss: 0.890649]\n",
      "epoch:2 step:2572 [D loss: 0.610467, acc.: 65.62%] [G loss: 0.903435]\n",
      "epoch:2 step:2573 [D loss: 0.657579, acc.: 59.38%] [G loss: 0.857851]\n",
      "epoch:2 step:2574 [D loss: 0.637590, acc.: 64.84%] [G loss: 0.895965]\n",
      "epoch:2 step:2575 [D loss: 0.614043, acc.: 67.19%] [G loss: 0.856529]\n",
      "epoch:2 step:2576 [D loss: 0.652363, acc.: 52.34%] [G loss: 0.845291]\n",
      "epoch:2 step:2577 [D loss: 0.648984, acc.: 61.72%] [G loss: 0.926583]\n",
      "epoch:2 step:2578 [D loss: 0.685809, acc.: 51.56%] [G loss: 0.851723]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2579 [D loss: 0.646141, acc.: 63.28%] [G loss: 0.906977]\n",
      "epoch:2 step:2580 [D loss: 0.649086, acc.: 66.41%] [G loss: 0.896469]\n",
      "epoch:2 step:2581 [D loss: 0.661150, acc.: 56.25%] [G loss: 0.873478]\n",
      "epoch:2 step:2582 [D loss: 0.617571, acc.: 67.19%] [G loss: 0.901802]\n",
      "epoch:2 step:2583 [D loss: 0.661603, acc.: 65.62%] [G loss: 0.908378]\n",
      "epoch:2 step:2584 [D loss: 0.624879, acc.: 68.75%] [G loss: 0.923825]\n",
      "epoch:2 step:2585 [D loss: 0.657939, acc.: 57.03%] [G loss: 0.942036]\n",
      "epoch:2 step:2586 [D loss: 0.673033, acc.: 57.81%] [G loss: 0.874474]\n",
      "epoch:2 step:2587 [D loss: 0.644969, acc.: 57.81%] [G loss: 0.912349]\n",
      "epoch:2 step:2588 [D loss: 0.676702, acc.: 65.62%] [G loss: 0.935823]\n",
      "epoch:2 step:2589 [D loss: 0.656925, acc.: 57.03%] [G loss: 0.884130]\n",
      "epoch:2 step:2590 [D loss: 0.634872, acc.: 63.28%] [G loss: 0.937595]\n",
      "epoch:2 step:2591 [D loss: 0.646006, acc.: 57.03%] [G loss: 0.839870]\n",
      "epoch:2 step:2592 [D loss: 0.625195, acc.: 65.62%] [G loss: 0.860413]\n",
      "epoch:2 step:2593 [D loss: 0.638811, acc.: 61.72%] [G loss: 0.857773]\n",
      "epoch:2 step:2594 [D loss: 0.607686, acc.: 69.53%] [G loss: 0.856211]\n",
      "epoch:2 step:2595 [D loss: 0.634506, acc.: 60.94%] [G loss: 0.781536]\n",
      "epoch:2 step:2596 [D loss: 0.641525, acc.: 64.06%] [G loss: 0.875966]\n",
      "epoch:2 step:2597 [D loss: 0.628704, acc.: 58.59%] [G loss: 0.856373]\n",
      "epoch:2 step:2598 [D loss: 0.671190, acc.: 55.47%] [G loss: 0.871815]\n",
      "epoch:2 step:2599 [D loss: 0.652522, acc.: 63.28%] [G loss: 0.835170]\n",
      "epoch:2 step:2600 [D loss: 0.657109, acc.: 60.16%] [G loss: 0.903098]\n",
      "##############\n",
      "[ 3.05766307  2.73264507  3.20528869  4.88267163  1.89190168 10.27426719\n",
      "  4.52655011  5.4980008   4.52201374  8.14868929]\n",
      "##########\n",
      "epoch:2 step:2601 [D loss: 0.635296, acc.: 65.62%] [G loss: 0.868424]\n",
      "epoch:2 step:2602 [D loss: 0.670856, acc.: 58.59%] [G loss: 0.897201]\n",
      "epoch:2 step:2603 [D loss: 0.661430, acc.: 57.81%] [G loss: 0.874050]\n",
      "epoch:2 step:2604 [D loss: 0.656701, acc.: 53.91%] [G loss: 0.863133]\n",
      "epoch:2 step:2605 [D loss: 0.656546, acc.: 64.84%] [G loss: 0.845078]\n",
      "epoch:2 step:2606 [D loss: 0.645989, acc.: 56.25%] [G loss: 0.860035]\n",
      "epoch:2 step:2607 [D loss: 0.645917, acc.: 61.72%] [G loss: 0.885540]\n",
      "epoch:2 step:2608 [D loss: 0.607355, acc.: 67.19%] [G loss: 0.845762]\n",
      "epoch:2 step:2609 [D loss: 0.644276, acc.: 61.72%] [G loss: 0.846931]\n",
      "epoch:2 step:2610 [D loss: 0.635657, acc.: 58.59%] [G loss: 0.871199]\n",
      "epoch:2 step:2611 [D loss: 0.646581, acc.: 54.69%] [G loss: 0.857087]\n",
      "epoch:2 step:2612 [D loss: 0.691259, acc.: 52.34%] [G loss: 0.844302]\n",
      "epoch:2 step:2613 [D loss: 0.622830, acc.: 64.84%] [G loss: 0.883660]\n",
      "epoch:2 step:2614 [D loss: 0.649558, acc.: 63.28%] [G loss: 0.889628]\n",
      "epoch:2 step:2615 [D loss: 0.676161, acc.: 54.69%] [G loss: 0.863222]\n",
      "epoch:2 step:2616 [D loss: 0.664022, acc.: 53.12%] [G loss: 0.920894]\n",
      "epoch:2 step:2617 [D loss: 0.702672, acc.: 54.69%] [G loss: 0.808188]\n",
      "epoch:2 step:2618 [D loss: 0.626708, acc.: 64.06%] [G loss: 0.832854]\n",
      "epoch:2 step:2619 [D loss: 0.653078, acc.: 64.06%] [G loss: 0.912416]\n",
      "epoch:2 step:2620 [D loss: 0.567455, acc.: 73.44%] [G loss: 0.890505]\n",
      "epoch:2 step:2621 [D loss: 0.643413, acc.: 60.94%] [G loss: 0.889159]\n",
      "epoch:2 step:2622 [D loss: 0.607643, acc.: 70.31%] [G loss: 0.881470]\n",
      "epoch:2 step:2623 [D loss: 0.648374, acc.: 62.50%] [G loss: 0.872610]\n",
      "epoch:2 step:2624 [D loss: 0.637479, acc.: 63.28%] [G loss: 0.847508]\n",
      "epoch:2 step:2625 [D loss: 0.607961, acc.: 67.19%] [G loss: 0.842702]\n",
      "epoch:2 step:2626 [D loss: 0.642455, acc.: 61.72%] [G loss: 0.932754]\n",
      "epoch:2 step:2627 [D loss: 0.636854, acc.: 59.38%] [G loss: 0.893668]\n",
      "epoch:2 step:2628 [D loss: 0.678806, acc.: 58.59%] [G loss: 0.869759]\n",
      "epoch:2 step:2629 [D loss: 0.621631, acc.: 67.19%] [G loss: 0.937358]\n",
      "epoch:2 step:2630 [D loss: 0.678957, acc.: 63.28%] [G loss: 0.939423]\n",
      "epoch:2 step:2631 [D loss: 0.593051, acc.: 71.88%] [G loss: 0.937044]\n",
      "epoch:2 step:2632 [D loss: 0.644136, acc.: 64.84%] [G loss: 0.931237]\n",
      "epoch:2 step:2633 [D loss: 0.626164, acc.: 62.50%] [G loss: 0.884975]\n",
      "epoch:2 step:2634 [D loss: 0.690375, acc.: 54.69%] [G loss: 0.913033]\n",
      "epoch:2 step:2635 [D loss: 0.678204, acc.: 55.47%] [G loss: 0.915213]\n",
      "epoch:2 step:2636 [D loss: 0.642129, acc.: 61.72%] [G loss: 0.851802]\n",
      "epoch:2 step:2637 [D loss: 0.622714, acc.: 64.84%] [G loss: 0.844641]\n",
      "epoch:2 step:2638 [D loss: 0.616523, acc.: 66.41%] [G loss: 0.882536]\n",
      "epoch:2 step:2639 [D loss: 0.662712, acc.: 59.38%] [G loss: 0.890040]\n",
      "epoch:2 step:2640 [D loss: 0.634290, acc.: 61.72%] [G loss: 0.906446]\n",
      "epoch:2 step:2641 [D loss: 0.656414, acc.: 61.72%] [G loss: 0.885370]\n",
      "epoch:2 step:2642 [D loss: 0.640395, acc.: 60.94%] [G loss: 0.924842]\n",
      "epoch:2 step:2643 [D loss: 0.630879, acc.: 61.72%] [G loss: 0.911648]\n",
      "epoch:2 step:2644 [D loss: 0.688010, acc.: 58.59%] [G loss: 0.824660]\n",
      "epoch:2 step:2645 [D loss: 0.657063, acc.: 57.81%] [G loss: 0.795053]\n",
      "epoch:2 step:2646 [D loss: 0.602338, acc.: 70.31%] [G loss: 0.828605]\n",
      "epoch:2 step:2647 [D loss: 0.659849, acc.: 57.81%] [G loss: 0.837938]\n",
      "epoch:2 step:2648 [D loss: 0.665147, acc.: 61.72%] [G loss: 0.807021]\n",
      "epoch:2 step:2649 [D loss: 0.639348, acc.: 65.62%] [G loss: 0.831205]\n",
      "epoch:2 step:2650 [D loss: 0.652749, acc.: 63.28%] [G loss: 0.885988]\n",
      "epoch:2 step:2651 [D loss: 0.621637, acc.: 65.62%] [G loss: 0.845119]\n",
      "epoch:2 step:2652 [D loss: 0.638106, acc.: 65.62%] [G loss: 0.834029]\n",
      "epoch:2 step:2653 [D loss: 0.654229, acc.: 58.59%] [G loss: 0.871143]\n",
      "epoch:2 step:2654 [D loss: 0.640898, acc.: 63.28%] [G loss: 0.815700]\n",
      "epoch:2 step:2655 [D loss: 0.655986, acc.: 59.38%] [G loss: 0.841614]\n",
      "epoch:2 step:2656 [D loss: 0.625360, acc.: 64.84%] [G loss: 0.860548]\n",
      "epoch:2 step:2657 [D loss: 0.626568, acc.: 60.16%] [G loss: 0.907047]\n",
      "epoch:2 step:2658 [D loss: 0.658444, acc.: 60.16%] [G loss: 0.855457]\n",
      "epoch:2 step:2659 [D loss: 0.633731, acc.: 67.19%] [G loss: 0.936094]\n",
      "epoch:2 step:2660 [D loss: 0.600648, acc.: 68.75%] [G loss: 0.834255]\n",
      "epoch:2 step:2661 [D loss: 0.650648, acc.: 56.25%] [G loss: 0.860906]\n",
      "epoch:2 step:2662 [D loss: 0.686772, acc.: 58.59%] [G loss: 0.864087]\n",
      "epoch:2 step:2663 [D loss: 0.706000, acc.: 55.47%] [G loss: 0.849756]\n",
      "epoch:2 step:2664 [D loss: 0.681373, acc.: 51.56%] [G loss: 0.948161]\n",
      "epoch:2 step:2665 [D loss: 0.632774, acc.: 67.97%] [G loss: 0.903835]\n",
      "epoch:2 step:2666 [D loss: 0.647859, acc.: 61.72%] [G loss: 0.917301]\n",
      "epoch:2 step:2667 [D loss: 0.669557, acc.: 58.59%] [G loss: 0.875437]\n",
      "epoch:2 step:2668 [D loss: 0.633935, acc.: 67.97%] [G loss: 0.851735]\n",
      "epoch:2 step:2669 [D loss: 0.663012, acc.: 58.59%] [G loss: 0.839175]\n",
      "epoch:2 step:2670 [D loss: 0.657871, acc.: 57.03%] [G loss: 0.879176]\n",
      "epoch:2 step:2671 [D loss: 0.626287, acc.: 70.31%] [G loss: 0.947788]\n",
      "epoch:2 step:2672 [D loss: 0.651454, acc.: 64.06%] [G loss: 0.921855]\n",
      "epoch:2 step:2673 [D loss: 0.665089, acc.: 56.25%] [G loss: 0.923446]\n",
      "epoch:2 step:2674 [D loss: 0.649045, acc.: 64.06%] [G loss: 0.890399]\n",
      "epoch:2 step:2675 [D loss: 0.674691, acc.: 57.81%] [G loss: 0.865774]\n",
      "epoch:2 step:2676 [D loss: 0.620016, acc.: 66.41%] [G loss: 0.892638]\n",
      "epoch:2 step:2677 [D loss: 0.680499, acc.: 53.12%] [G loss: 0.859810]\n",
      "epoch:2 step:2678 [D loss: 0.663407, acc.: 60.94%] [G loss: 0.884633]\n",
      "epoch:2 step:2679 [D loss: 0.654322, acc.: 56.25%] [G loss: 0.848019]\n",
      "epoch:2 step:2680 [D loss: 0.642330, acc.: 67.19%] [G loss: 0.826670]\n",
      "epoch:2 step:2681 [D loss: 0.642999, acc.: 58.59%] [G loss: 0.846699]\n",
      "epoch:2 step:2682 [D loss: 0.643676, acc.: 60.16%] [G loss: 0.889226]\n",
      "epoch:2 step:2683 [D loss: 0.624694, acc.: 64.06%] [G loss: 0.879813]\n",
      "epoch:2 step:2684 [D loss: 0.577815, acc.: 71.88%] [G loss: 0.866110]\n",
      "epoch:2 step:2685 [D loss: 0.653498, acc.: 59.38%] [G loss: 0.928193]\n",
      "epoch:2 step:2686 [D loss: 0.609412, acc.: 64.06%] [G loss: 0.913035]\n",
      "epoch:2 step:2687 [D loss: 0.666189, acc.: 57.81%] [G loss: 0.928536]\n",
      "epoch:2 step:2688 [D loss: 0.674998, acc.: 60.16%] [G loss: 0.880609]\n",
      "epoch:2 step:2689 [D loss: 0.662118, acc.: 59.38%] [G loss: 0.901775]\n",
      "epoch:2 step:2690 [D loss: 0.596212, acc.: 68.75%] [G loss: 0.979506]\n",
      "epoch:2 step:2691 [D loss: 0.668325, acc.: 62.50%] [G loss: 0.896987]\n",
      "epoch:2 step:2692 [D loss: 0.676309, acc.: 56.25%] [G loss: 0.898822]\n",
      "epoch:2 step:2693 [D loss: 0.623218, acc.: 63.28%] [G loss: 0.881252]\n",
      "epoch:2 step:2694 [D loss: 0.628556, acc.: 63.28%] [G loss: 0.897258]\n",
      "epoch:2 step:2695 [D loss: 0.648242, acc.: 64.06%] [G loss: 0.935240]\n",
      "epoch:2 step:2696 [D loss: 0.645081, acc.: 61.72%] [G loss: 0.882376]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:2 step:2697 [D loss: 0.667491, acc.: 59.38%] [G loss: 0.901195]\n",
      "epoch:2 step:2698 [D loss: 0.649824, acc.: 63.28%] [G loss: 0.881227]\n",
      "epoch:2 step:2699 [D loss: 0.638238, acc.: 64.84%] [G loss: 0.854245]\n",
      "epoch:2 step:2700 [D loss: 0.590016, acc.: 70.31%] [G loss: 0.868770]\n",
      "epoch:2 step:2701 [D loss: 0.641725, acc.: 58.59%] [G loss: 0.869417]\n",
      "epoch:2 step:2702 [D loss: 0.690194, acc.: 54.69%] [G loss: 0.867792]\n",
      "epoch:2 step:2703 [D loss: 0.634693, acc.: 58.59%] [G loss: 0.890324]\n",
      "epoch:2 step:2704 [D loss: 0.657222, acc.: 63.28%] [G loss: 0.891153]\n",
      "epoch:2 step:2705 [D loss: 0.677376, acc.: 60.16%] [G loss: 0.860103]\n",
      "epoch:2 step:2706 [D loss: 0.645668, acc.: 63.28%] [G loss: 0.879915]\n",
      "epoch:2 step:2707 [D loss: 0.654790, acc.: 60.94%] [G loss: 0.889246]\n",
      "epoch:2 step:2708 [D loss: 0.701341, acc.: 53.91%] [G loss: 0.876917]\n",
      "epoch:2 step:2709 [D loss: 0.662760, acc.: 60.16%] [G loss: 0.838101]\n",
      "epoch:2 step:2710 [D loss: 0.626209, acc.: 65.62%] [G loss: 0.895833]\n",
      "epoch:2 step:2711 [D loss: 0.664909, acc.: 64.06%] [G loss: 0.908229]\n",
      "epoch:2 step:2712 [D loss: 0.667946, acc.: 56.25%] [G loss: 0.931858]\n",
      "epoch:2 step:2713 [D loss: 0.663762, acc.: 54.69%] [G loss: 0.934556]\n",
      "epoch:2 step:2714 [D loss: 0.667214, acc.: 55.47%] [G loss: 0.906220]\n",
      "epoch:2 step:2715 [D loss: 0.652946, acc.: 61.72%] [G loss: 0.862027]\n",
      "epoch:2 step:2716 [D loss: 0.677940, acc.: 54.69%] [G loss: 0.931174]\n",
      "epoch:2 step:2717 [D loss: 0.681752, acc.: 50.00%] [G loss: 0.930805]\n",
      "epoch:2 step:2718 [D loss: 0.659261, acc.: 57.81%] [G loss: 0.891846]\n",
      "epoch:2 step:2719 [D loss: 0.686740, acc.: 53.91%] [G loss: 0.861817]\n",
      "epoch:2 step:2720 [D loss: 0.681451, acc.: 55.47%] [G loss: 0.865760]\n",
      "epoch:2 step:2721 [D loss: 0.645433, acc.: 63.28%] [G loss: 0.894135]\n",
      "epoch:2 step:2722 [D loss: 0.681526, acc.: 56.25%] [G loss: 0.906541]\n",
      "epoch:2 step:2723 [D loss: 0.670594, acc.: 58.59%] [G loss: 0.866894]\n",
      "epoch:2 step:2724 [D loss: 0.635321, acc.: 60.94%] [G loss: 0.854036]\n",
      "epoch:2 step:2725 [D loss: 0.630004, acc.: 67.97%] [G loss: 0.804434]\n",
      "epoch:2 step:2726 [D loss: 0.641301, acc.: 65.62%] [G loss: 0.811934]\n",
      "epoch:2 step:2727 [D loss: 0.658077, acc.: 60.94%] [G loss: 0.798872]\n",
      "epoch:2 step:2728 [D loss: 0.621238, acc.: 65.62%] [G loss: 0.841013]\n",
      "epoch:2 step:2729 [D loss: 0.642885, acc.: 65.62%] [G loss: 0.861957]\n",
      "epoch:2 step:2730 [D loss: 0.599919, acc.: 69.53%] [G loss: 0.841596]\n",
      "epoch:2 step:2731 [D loss: 0.655203, acc.: 65.62%] [G loss: 0.880922]\n",
      "epoch:2 step:2732 [D loss: 0.679391, acc.: 53.12%] [G loss: 0.866924]\n",
      "epoch:2 step:2733 [D loss: 0.605654, acc.: 65.62%] [G loss: 0.887091]\n",
      "epoch:2 step:2734 [D loss: 0.634962, acc.: 64.06%] [G loss: 0.865104]\n",
      "epoch:2 step:2735 [D loss: 0.664963, acc.: 62.50%] [G loss: 0.853145]\n",
      "epoch:2 step:2736 [D loss: 0.630677, acc.: 64.84%] [G loss: 0.834751]\n",
      "epoch:2 step:2737 [D loss: 0.646916, acc.: 64.06%] [G loss: 0.909331]\n",
      "epoch:2 step:2738 [D loss: 0.662646, acc.: 55.47%] [G loss: 0.864889]\n",
      "epoch:2 step:2739 [D loss: 0.632062, acc.: 62.50%] [G loss: 0.886246]\n",
      "epoch:2 step:2740 [D loss: 0.696970, acc.: 56.25%] [G loss: 0.846137]\n",
      "epoch:2 step:2741 [D loss: 0.687038, acc.: 50.00%] [G loss: 0.877282]\n",
      "epoch:2 step:2742 [D loss: 0.645544, acc.: 62.50%] [G loss: 0.872330]\n",
      "epoch:2 step:2743 [D loss: 0.622209, acc.: 67.97%] [G loss: 0.933322]\n",
      "epoch:2 step:2744 [D loss: 0.690577, acc.: 54.69%] [G loss: 0.882918]\n",
      "epoch:2 step:2745 [D loss: 0.662920, acc.: 60.94%] [G loss: 0.914003]\n",
      "epoch:2 step:2746 [D loss: 0.672142, acc.: 54.69%] [G loss: 0.931386]\n",
      "epoch:2 step:2747 [D loss: 0.634174, acc.: 64.84%] [G loss: 0.945373]\n",
      "epoch:2 step:2748 [D loss: 0.651301, acc.: 67.19%] [G loss: 0.912247]\n",
      "epoch:2 step:2749 [D loss: 0.665094, acc.: 57.81%] [G loss: 0.948684]\n",
      "epoch:2 step:2750 [D loss: 0.663367, acc.: 57.81%] [G loss: 0.908569]\n",
      "epoch:2 step:2751 [D loss: 0.652123, acc.: 57.81%] [G loss: 0.948101]\n",
      "epoch:2 step:2752 [D loss: 0.656184, acc.: 60.16%] [G loss: 0.876445]\n",
      "epoch:2 step:2753 [D loss: 0.668163, acc.: 55.47%] [G loss: 0.906085]\n",
      "epoch:2 step:2754 [D loss: 0.643275, acc.: 56.25%] [G loss: 0.868314]\n",
      "epoch:2 step:2755 [D loss: 0.663456, acc.: 65.62%] [G loss: 0.861748]\n",
      "epoch:2 step:2756 [D loss: 0.630504, acc.: 65.62%] [G loss: 0.858828]\n",
      "epoch:2 step:2757 [D loss: 0.651132, acc.: 58.59%] [G loss: 0.835043]\n",
      "epoch:2 step:2758 [D loss: 0.659524, acc.: 58.59%] [G loss: 0.888979]\n",
      "epoch:2 step:2759 [D loss: 0.698479, acc.: 55.47%] [G loss: 0.914074]\n",
      "epoch:2 step:2760 [D loss: 0.656786, acc.: 56.25%] [G loss: 0.916692]\n",
      "epoch:2 step:2761 [D loss: 0.640729, acc.: 64.06%] [G loss: 0.888517]\n",
      "epoch:2 step:2762 [D loss: 0.680527, acc.: 53.91%] [G loss: 0.800454]\n",
      "epoch:2 step:2763 [D loss: 0.643866, acc.: 62.50%] [G loss: 0.847741]\n",
      "epoch:2 step:2764 [D loss: 0.685834, acc.: 51.56%] [G loss: 0.849249]\n",
      "epoch:2 step:2765 [D loss: 0.692053, acc.: 51.56%] [G loss: 0.908243]\n",
      "epoch:2 step:2766 [D loss: 0.636911, acc.: 71.88%] [G loss: 0.879738]\n",
      "epoch:2 step:2767 [D loss: 0.632197, acc.: 65.62%] [G loss: 0.880540]\n",
      "epoch:2 step:2768 [D loss: 0.683281, acc.: 57.03%] [G loss: 0.867290]\n",
      "epoch:2 step:2769 [D loss: 0.645203, acc.: 59.38%] [G loss: 0.886160]\n",
      "epoch:2 step:2770 [D loss: 0.620871, acc.: 66.41%] [G loss: 0.868546]\n",
      "epoch:2 step:2771 [D loss: 0.649895, acc.: 61.72%] [G loss: 0.888120]\n",
      "epoch:2 step:2772 [D loss: 0.630867, acc.: 61.72%] [G loss: 0.827502]\n",
      "epoch:2 step:2773 [D loss: 0.621419, acc.: 67.19%] [G loss: 0.847575]\n",
      "epoch:2 step:2774 [D loss: 0.675368, acc.: 62.50%] [G loss: 0.813891]\n",
      "epoch:2 step:2775 [D loss: 0.675180, acc.: 59.38%] [G loss: 0.849247]\n",
      "epoch:2 step:2776 [D loss: 0.615592, acc.: 64.84%] [G loss: 0.871083]\n",
      "epoch:2 step:2777 [D loss: 0.611009, acc.: 69.53%] [G loss: 0.884965]\n",
      "epoch:2 step:2778 [D loss: 0.633272, acc.: 66.41%] [G loss: 0.863450]\n",
      "epoch:2 step:2779 [D loss: 0.664580, acc.: 62.50%] [G loss: 0.899235]\n",
      "epoch:2 step:2780 [D loss: 0.647934, acc.: 64.84%] [G loss: 0.919105]\n",
      "epoch:2 step:2781 [D loss: 0.637510, acc.: 60.16%] [G loss: 0.868097]\n",
      "epoch:2 step:2782 [D loss: 0.649113, acc.: 60.16%] [G loss: 0.876392]\n",
      "epoch:2 step:2783 [D loss: 0.647407, acc.: 59.38%] [G loss: 0.832777]\n",
      "epoch:2 step:2784 [D loss: 0.685359, acc.: 54.69%] [G loss: 0.882339]\n",
      "epoch:2 step:2785 [D loss: 0.644514, acc.: 61.72%] [G loss: 0.841023]\n",
      "epoch:2 step:2786 [D loss: 0.647960, acc.: 61.72%] [G loss: 0.816101]\n",
      "epoch:2 step:2787 [D loss: 0.655197, acc.: 62.50%] [G loss: 0.846920]\n",
      "epoch:2 step:2788 [D loss: 0.672297, acc.: 61.72%] [G loss: 0.837755]\n",
      "epoch:2 step:2789 [D loss: 0.660158, acc.: 57.81%] [G loss: 0.817906]\n",
      "epoch:2 step:2790 [D loss: 0.630154, acc.: 64.84%] [G loss: 0.859523]\n",
      "epoch:2 step:2791 [D loss: 0.666501, acc.: 59.38%] [G loss: 0.949824]\n",
      "epoch:2 step:2792 [D loss: 0.650475, acc.: 57.81%] [G loss: 0.912645]\n",
      "epoch:2 step:2793 [D loss: 0.633444, acc.: 62.50%] [G loss: 0.919769]\n",
      "epoch:2 step:2794 [D loss: 0.640861, acc.: 64.06%] [G loss: 0.943591]\n",
      "epoch:2 step:2795 [D loss: 0.667816, acc.: 60.16%] [G loss: 0.829626]\n",
      "epoch:2 step:2796 [D loss: 0.648825, acc.: 59.38%] [G loss: 0.834334]\n",
      "epoch:2 step:2797 [D loss: 0.691506, acc.: 50.78%] [G loss: 0.874542]\n",
      "epoch:2 step:2798 [D loss: 0.661853, acc.: 58.59%] [G loss: 0.901966]\n",
      "epoch:2 step:2799 [D loss: 0.658240, acc.: 61.72%] [G loss: 0.853130]\n",
      "epoch:2 step:2800 [D loss: 0.652275, acc.: 61.72%] [G loss: 0.857026]\n",
      "##############\n",
      "[ 2.94499458  2.93530953  2.91780589  5.11975053  2.19622596 10.27426719\n",
      "  3.82446888  4.53578223  4.42952515  8.14868929]\n",
      "##########\n",
      "epoch:2 step:2801 [D loss: 0.651994, acc.: 61.72%] [G loss: 0.798675]\n",
      "epoch:2 step:2802 [D loss: 0.669952, acc.: 53.91%] [G loss: 0.859104]\n",
      "epoch:2 step:2803 [D loss: 0.649650, acc.: 61.72%] [G loss: 0.865194]\n",
      "epoch:2 step:2804 [D loss: 0.640792, acc.: 60.16%] [G loss: 0.875660]\n",
      "epoch:2 step:2805 [D loss: 0.639495, acc.: 61.72%] [G loss: 0.832642]\n",
      "epoch:2 step:2806 [D loss: 0.671197, acc.: 56.25%] [G loss: 0.864681]\n",
      "epoch:2 step:2807 [D loss: 0.663584, acc.: 56.25%] [G loss: 0.879645]\n",
      "epoch:2 step:2808 [D loss: 0.631631, acc.: 66.41%] [G loss: 0.828510]\n",
      "epoch:2 step:2809 [D loss: 0.624671, acc.: 67.97%] [G loss: 0.869580]\n",
      "epoch:2 step:2810 [D loss: 0.621703, acc.: 64.84%] [G loss: 0.892051]\n",
      "epoch:2 step:2811 [D loss: 0.719192, acc.: 51.56%] [G loss: 0.885500]\n",
      "epoch:3 step:2812 [D loss: 0.709432, acc.: 52.34%] [G loss: 0.899160]\n",
      "epoch:3 step:2813 [D loss: 0.652574, acc.: 65.62%] [G loss: 0.840645]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2814 [D loss: 0.676273, acc.: 63.28%] [G loss: 0.889820]\n",
      "epoch:3 step:2815 [D loss: 0.637054, acc.: 66.41%] [G loss: 0.881984]\n",
      "epoch:3 step:2816 [D loss: 0.662507, acc.: 60.94%] [G loss: 0.848590]\n",
      "epoch:3 step:2817 [D loss: 0.680707, acc.: 51.56%] [G loss: 0.851108]\n",
      "epoch:3 step:2818 [D loss: 0.687415, acc.: 51.56%] [G loss: 0.938619]\n",
      "epoch:3 step:2819 [D loss: 0.669131, acc.: 56.25%] [G loss: 0.838832]\n",
      "epoch:3 step:2820 [D loss: 0.603057, acc.: 67.19%] [G loss: 0.866336]\n",
      "epoch:3 step:2821 [D loss: 0.636113, acc.: 67.97%] [G loss: 0.810958]\n",
      "epoch:3 step:2822 [D loss: 0.631564, acc.: 69.53%] [G loss: 0.834699]\n",
      "epoch:3 step:2823 [D loss: 0.656204, acc.: 61.72%] [G loss: 0.865402]\n",
      "epoch:3 step:2824 [D loss: 0.633848, acc.: 64.84%] [G loss: 0.919036]\n",
      "epoch:3 step:2825 [D loss: 0.676744, acc.: 59.38%] [G loss: 0.898822]\n",
      "epoch:3 step:2826 [D loss: 0.633424, acc.: 60.94%] [G loss: 0.852406]\n",
      "epoch:3 step:2827 [D loss: 0.613360, acc.: 69.53%] [G loss: 0.853043]\n",
      "epoch:3 step:2828 [D loss: 0.635139, acc.: 63.28%] [G loss: 0.902633]\n",
      "epoch:3 step:2829 [D loss: 0.686408, acc.: 62.50%] [G loss: 0.892022]\n",
      "epoch:3 step:2830 [D loss: 0.656143, acc.: 59.38%] [G loss: 0.859876]\n",
      "epoch:3 step:2831 [D loss: 0.643992, acc.: 60.16%] [G loss: 0.901875]\n",
      "epoch:3 step:2832 [D loss: 0.663477, acc.: 58.59%] [G loss: 0.857378]\n",
      "epoch:3 step:2833 [D loss: 0.660967, acc.: 61.72%] [G loss: 0.867123]\n",
      "epoch:3 step:2834 [D loss: 0.672340, acc.: 58.59%] [G loss: 0.781043]\n",
      "epoch:3 step:2835 [D loss: 0.607144, acc.: 69.53%] [G loss: 0.826830]\n",
      "epoch:3 step:2836 [D loss: 0.705112, acc.: 58.59%] [G loss: 0.883922]\n",
      "epoch:3 step:2837 [D loss: 0.620821, acc.: 67.97%] [G loss: 0.881190]\n",
      "epoch:3 step:2838 [D loss: 0.623468, acc.: 71.88%] [G loss: 0.862387]\n",
      "epoch:3 step:2839 [D loss: 0.643601, acc.: 60.94%] [G loss: 0.853851]\n",
      "epoch:3 step:2840 [D loss: 0.691222, acc.: 57.03%] [G loss: 0.844054]\n",
      "epoch:3 step:2841 [D loss: 0.648561, acc.: 64.06%] [G loss: 0.876079]\n",
      "epoch:3 step:2842 [D loss: 0.620203, acc.: 62.50%] [G loss: 0.893573]\n",
      "epoch:3 step:2843 [D loss: 0.616539, acc.: 65.62%] [G loss: 0.891511]\n",
      "epoch:3 step:2844 [D loss: 0.620731, acc.: 63.28%] [G loss: 0.886396]\n",
      "epoch:3 step:2845 [D loss: 0.641453, acc.: 58.59%] [G loss: 0.864662]\n",
      "epoch:3 step:2846 [D loss: 0.652495, acc.: 68.75%] [G loss: 0.890174]\n",
      "epoch:3 step:2847 [D loss: 0.596239, acc.: 68.75%] [G loss: 0.860251]\n",
      "epoch:3 step:2848 [D loss: 0.634355, acc.: 62.50%] [G loss: 0.837316]\n",
      "epoch:3 step:2849 [D loss: 0.697567, acc.: 58.59%] [G loss: 0.863982]\n",
      "epoch:3 step:2850 [D loss: 0.650730, acc.: 63.28%] [G loss: 0.901965]\n",
      "epoch:3 step:2851 [D loss: 0.646339, acc.: 67.19%] [G loss: 0.939687]\n",
      "epoch:3 step:2852 [D loss: 0.666619, acc.: 60.94%] [G loss: 0.840903]\n",
      "epoch:3 step:2853 [D loss: 0.632727, acc.: 65.62%] [G loss: 0.838976]\n",
      "epoch:3 step:2854 [D loss: 0.657384, acc.: 62.50%] [G loss: 0.922218]\n",
      "epoch:3 step:2855 [D loss: 0.678047, acc.: 55.47%] [G loss: 0.908049]\n",
      "epoch:3 step:2856 [D loss: 0.648132, acc.: 62.50%] [G loss: 0.905203]\n",
      "epoch:3 step:2857 [D loss: 0.661451, acc.: 61.72%] [G loss: 0.888221]\n",
      "epoch:3 step:2858 [D loss: 0.658929, acc.: 64.84%] [G loss: 0.887643]\n",
      "epoch:3 step:2859 [D loss: 0.639837, acc.: 64.84%] [G loss: 0.901792]\n",
      "epoch:3 step:2860 [D loss: 0.648936, acc.: 63.28%] [G loss: 0.827036]\n",
      "epoch:3 step:2861 [D loss: 0.609085, acc.: 67.97%] [G loss: 0.853050]\n",
      "epoch:3 step:2862 [D loss: 0.630438, acc.: 66.41%] [G loss: 0.856252]\n",
      "epoch:3 step:2863 [D loss: 0.659882, acc.: 63.28%] [G loss: 0.833427]\n",
      "epoch:3 step:2864 [D loss: 0.662164, acc.: 59.38%] [G loss: 0.896995]\n",
      "epoch:3 step:2865 [D loss: 0.605123, acc.: 71.09%] [G loss: 0.915816]\n",
      "epoch:3 step:2866 [D loss: 0.650483, acc.: 57.81%] [G loss: 0.873835]\n",
      "epoch:3 step:2867 [D loss: 0.681507, acc.: 56.25%] [G loss: 0.888892]\n",
      "epoch:3 step:2868 [D loss: 0.667484, acc.: 51.56%] [G loss: 0.856439]\n",
      "epoch:3 step:2869 [D loss: 0.650616, acc.: 63.28%] [G loss: 0.853714]\n",
      "epoch:3 step:2870 [D loss: 0.615527, acc.: 60.94%] [G loss: 0.864898]\n",
      "epoch:3 step:2871 [D loss: 0.638315, acc.: 58.59%] [G loss: 0.938442]\n",
      "epoch:3 step:2872 [D loss: 0.651764, acc.: 59.38%] [G loss: 0.903582]\n",
      "epoch:3 step:2873 [D loss: 0.651881, acc.: 61.72%] [G loss: 0.892280]\n",
      "epoch:3 step:2874 [D loss: 0.649740, acc.: 60.94%] [G loss: 0.901530]\n",
      "epoch:3 step:2875 [D loss: 0.613791, acc.: 67.97%] [G loss: 0.866262]\n",
      "epoch:3 step:2876 [D loss: 0.628672, acc.: 67.19%] [G loss: 0.897595]\n",
      "epoch:3 step:2877 [D loss: 0.653979, acc.: 60.94%] [G loss: 0.897920]\n",
      "epoch:3 step:2878 [D loss: 0.659770, acc.: 59.38%] [G loss: 0.861244]\n",
      "epoch:3 step:2879 [D loss: 0.631571, acc.: 62.50%] [G loss: 0.873418]\n",
      "epoch:3 step:2880 [D loss: 0.647471, acc.: 56.25%] [G loss: 0.937510]\n",
      "epoch:3 step:2881 [D loss: 0.638774, acc.: 63.28%] [G loss: 0.857324]\n",
      "epoch:3 step:2882 [D loss: 0.652941, acc.: 59.38%] [G loss: 0.940519]\n",
      "epoch:3 step:2883 [D loss: 0.654122, acc.: 62.50%] [G loss: 0.868171]\n",
      "epoch:3 step:2884 [D loss: 0.628524, acc.: 65.62%] [G loss: 0.890022]\n",
      "epoch:3 step:2885 [D loss: 0.667279, acc.: 62.50%] [G loss: 0.958360]\n",
      "epoch:3 step:2886 [D loss: 0.635972, acc.: 64.06%] [G loss: 0.920518]\n",
      "epoch:3 step:2887 [D loss: 0.651137, acc.: 64.06%] [G loss: 0.843879]\n",
      "epoch:3 step:2888 [D loss: 0.665604, acc.: 61.72%] [G loss: 0.847338]\n",
      "epoch:3 step:2889 [D loss: 0.665354, acc.: 57.81%] [G loss: 0.855746]\n",
      "epoch:3 step:2890 [D loss: 0.683911, acc.: 57.81%] [G loss: 0.869421]\n",
      "epoch:3 step:2891 [D loss: 0.634594, acc.: 67.19%] [G loss: 0.963148]\n",
      "epoch:3 step:2892 [D loss: 0.678754, acc.: 58.59%] [G loss: 0.841456]\n",
      "epoch:3 step:2893 [D loss: 0.650135, acc.: 57.81%] [G loss: 0.871431]\n",
      "epoch:3 step:2894 [D loss: 0.662253, acc.: 61.72%] [G loss: 0.858583]\n",
      "epoch:3 step:2895 [D loss: 0.679758, acc.: 53.12%] [G loss: 0.944441]\n",
      "epoch:3 step:2896 [D loss: 0.658981, acc.: 58.59%] [G loss: 0.879569]\n",
      "epoch:3 step:2897 [D loss: 0.654835, acc.: 60.16%] [G loss: 0.841151]\n",
      "epoch:3 step:2898 [D loss: 0.634958, acc.: 64.06%] [G loss: 0.786339]\n",
      "epoch:3 step:2899 [D loss: 0.641163, acc.: 58.59%] [G loss: 0.808667]\n",
      "epoch:3 step:2900 [D loss: 0.595993, acc.: 67.97%] [G loss: 0.883283]\n",
      "epoch:3 step:2901 [D loss: 0.649356, acc.: 57.81%] [G loss: 0.894137]\n",
      "epoch:3 step:2902 [D loss: 0.637086, acc.: 60.94%] [G loss: 0.900015]\n",
      "epoch:3 step:2903 [D loss: 0.649439, acc.: 64.06%] [G loss: 0.890964]\n",
      "epoch:3 step:2904 [D loss: 0.710401, acc.: 55.47%] [G loss: 0.873454]\n",
      "epoch:3 step:2905 [D loss: 0.685196, acc.: 55.47%] [G loss: 0.869453]\n",
      "epoch:3 step:2906 [D loss: 0.625926, acc.: 67.19%] [G loss: 0.898515]\n",
      "epoch:3 step:2907 [D loss: 0.611815, acc.: 63.28%] [G loss: 0.850810]\n",
      "epoch:3 step:2908 [D loss: 0.684861, acc.: 61.72%] [G loss: 0.893203]\n",
      "epoch:3 step:2909 [D loss: 0.672508, acc.: 57.03%] [G loss: 0.929231]\n",
      "epoch:3 step:2910 [D loss: 0.660349, acc.: 61.72%] [G loss: 0.886593]\n",
      "epoch:3 step:2911 [D loss: 0.664064, acc.: 60.16%] [G loss: 0.876720]\n",
      "epoch:3 step:2912 [D loss: 0.637746, acc.: 60.94%] [G loss: 0.903478]\n",
      "epoch:3 step:2913 [D loss: 0.679852, acc.: 55.47%] [G loss: 0.816746]\n",
      "epoch:3 step:2914 [D loss: 0.622843, acc.: 65.62%] [G loss: 0.804712]\n",
      "epoch:3 step:2915 [D loss: 0.648358, acc.: 63.28%] [G loss: 0.836023]\n",
      "epoch:3 step:2916 [D loss: 0.639277, acc.: 62.50%] [G loss: 0.853631]\n",
      "epoch:3 step:2917 [D loss: 0.656950, acc.: 64.84%] [G loss: 0.833291]\n",
      "epoch:3 step:2918 [D loss: 0.633881, acc.: 66.41%] [G loss: 0.912247]\n",
      "epoch:3 step:2919 [D loss: 0.647712, acc.: 64.06%] [G loss: 0.902736]\n",
      "epoch:3 step:2920 [D loss: 0.599107, acc.: 68.75%] [G loss: 0.939455]\n",
      "epoch:3 step:2921 [D loss: 0.676691, acc.: 60.16%] [G loss: 0.824116]\n",
      "epoch:3 step:2922 [D loss: 0.661616, acc.: 59.38%] [G loss: 0.861355]\n",
      "epoch:3 step:2923 [D loss: 0.642733, acc.: 59.38%] [G loss: 0.897979]\n",
      "epoch:3 step:2924 [D loss: 0.676781, acc.: 60.94%] [G loss: 0.852386]\n",
      "epoch:3 step:2925 [D loss: 0.635054, acc.: 66.41%] [G loss: 0.878610]\n",
      "epoch:3 step:2926 [D loss: 0.671591, acc.: 57.03%] [G loss: 0.924448]\n",
      "epoch:3 step:2927 [D loss: 0.667499, acc.: 56.25%] [G loss: 0.906635]\n",
      "epoch:3 step:2928 [D loss: 0.709420, acc.: 53.91%] [G loss: 0.879010]\n",
      "epoch:3 step:2929 [D loss: 0.673535, acc.: 55.47%] [G loss: 0.890387]\n",
      "epoch:3 step:2930 [D loss: 0.673461, acc.: 59.38%] [G loss: 0.882142]\n",
      "epoch:3 step:2931 [D loss: 0.710029, acc.: 54.69%] [G loss: 0.880637]\n",
      "epoch:3 step:2932 [D loss: 0.595542, acc.: 67.19%] [G loss: 0.846328]\n",
      "epoch:3 step:2933 [D loss: 0.670304, acc.: 57.03%] [G loss: 0.819308]\n",
      "epoch:3 step:2934 [D loss: 0.640625, acc.: 65.62%] [G loss: 0.852229]\n",
      "epoch:3 step:2935 [D loss: 0.621909, acc.: 64.06%] [G loss: 0.823579]\n",
      "epoch:3 step:2936 [D loss: 0.668735, acc.: 58.59%] [G loss: 0.812428]\n",
      "epoch:3 step:2937 [D loss: 0.653081, acc.: 57.03%] [G loss: 0.853723]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:2938 [D loss: 0.629999, acc.: 70.31%] [G loss: 0.838717]\n",
      "epoch:3 step:2939 [D loss: 0.668620, acc.: 58.59%] [G loss: 0.865598]\n",
      "epoch:3 step:2940 [D loss: 0.651018, acc.: 61.72%] [G loss: 0.827165]\n",
      "epoch:3 step:2941 [D loss: 0.636967, acc.: 61.72%] [G loss: 0.797351]\n",
      "epoch:3 step:2942 [D loss: 0.624679, acc.: 64.84%] [G loss: 0.835391]\n",
      "epoch:3 step:2943 [D loss: 0.679316, acc.: 56.25%] [G loss: 0.843231]\n",
      "epoch:3 step:2944 [D loss: 0.646723, acc.: 61.72%] [G loss: 0.865972]\n",
      "epoch:3 step:2945 [D loss: 0.698697, acc.: 54.69%] [G loss: 0.824084]\n",
      "epoch:3 step:2946 [D loss: 0.699580, acc.: 49.22%] [G loss: 0.868735]\n",
      "epoch:3 step:2947 [D loss: 0.674153, acc.: 59.38%] [G loss: 0.817162]\n",
      "epoch:3 step:2948 [D loss: 0.676757, acc.: 57.81%] [G loss: 0.835997]\n",
      "epoch:3 step:2949 [D loss: 0.670077, acc.: 57.81%] [G loss: 0.905180]\n",
      "epoch:3 step:2950 [D loss: 0.634959, acc.: 63.28%] [G loss: 0.878691]\n",
      "epoch:3 step:2951 [D loss: 0.716272, acc.: 46.88%] [G loss: 0.859897]\n",
      "epoch:3 step:2952 [D loss: 0.659854, acc.: 58.59%] [G loss: 0.868409]\n",
      "epoch:3 step:2953 [D loss: 0.641447, acc.: 63.28%] [G loss: 0.832106]\n",
      "epoch:3 step:2954 [D loss: 0.648956, acc.: 60.16%] [G loss: 0.888343]\n",
      "epoch:3 step:2955 [D loss: 0.661732, acc.: 60.16%] [G loss: 0.850585]\n",
      "epoch:3 step:2956 [D loss: 0.645232, acc.: 57.03%] [G loss: 0.903047]\n",
      "epoch:3 step:2957 [D loss: 0.653675, acc.: 64.06%] [G loss: 0.882645]\n",
      "epoch:3 step:2958 [D loss: 0.653052, acc.: 60.16%] [G loss: 0.878427]\n",
      "epoch:3 step:2959 [D loss: 0.614971, acc.: 65.62%] [G loss: 0.897884]\n",
      "epoch:3 step:2960 [D loss: 0.656919, acc.: 59.38%] [G loss: 0.912487]\n",
      "epoch:3 step:2961 [D loss: 0.636109, acc.: 61.72%] [G loss: 0.912090]\n",
      "epoch:3 step:2962 [D loss: 0.693541, acc.: 54.69%] [G loss: 0.856273]\n",
      "epoch:3 step:2963 [D loss: 0.661620, acc.: 59.38%] [G loss: 0.845299]\n",
      "epoch:3 step:2964 [D loss: 0.645112, acc.: 59.38%] [G loss: 0.864529]\n",
      "epoch:3 step:2965 [D loss: 0.643963, acc.: 64.84%] [G loss: 0.845758]\n",
      "epoch:3 step:2966 [D loss: 0.636187, acc.: 61.72%] [G loss: 0.870704]\n",
      "epoch:3 step:2967 [D loss: 0.644127, acc.: 57.81%] [G loss: 0.836875]\n",
      "epoch:3 step:2968 [D loss: 0.653310, acc.: 62.50%] [G loss: 0.885318]\n",
      "epoch:3 step:2969 [D loss: 0.630406, acc.: 65.62%] [G loss: 0.886343]\n",
      "epoch:3 step:2970 [D loss: 0.643068, acc.: 64.06%] [G loss: 0.919185]\n",
      "epoch:3 step:2971 [D loss: 0.691967, acc.: 57.03%] [G loss: 0.881246]\n",
      "epoch:3 step:2972 [D loss: 0.664382, acc.: 58.59%] [G loss: 0.870271]\n",
      "epoch:3 step:2973 [D loss: 0.634886, acc.: 59.38%] [G loss: 0.882054]\n",
      "epoch:3 step:2974 [D loss: 0.691964, acc.: 54.69%] [G loss: 0.898397]\n",
      "epoch:3 step:2975 [D loss: 0.662690, acc.: 60.16%] [G loss: 0.868700]\n",
      "epoch:3 step:2976 [D loss: 0.637406, acc.: 67.97%] [G loss: 0.882272]\n",
      "epoch:3 step:2977 [D loss: 0.670007, acc.: 58.59%] [G loss: 0.910325]\n",
      "epoch:3 step:2978 [D loss: 0.652495, acc.: 59.38%] [G loss: 0.899304]\n",
      "epoch:3 step:2979 [D loss: 0.631476, acc.: 60.94%] [G loss: 0.897691]\n",
      "epoch:3 step:2980 [D loss: 0.673272, acc.: 64.06%] [G loss: 0.858950]\n",
      "epoch:3 step:2981 [D loss: 0.665645, acc.: 59.38%] [G loss: 0.910490]\n",
      "epoch:3 step:2982 [D loss: 0.649525, acc.: 59.38%] [G loss: 0.892259]\n",
      "epoch:3 step:2983 [D loss: 0.639125, acc.: 61.72%] [G loss: 0.901583]\n",
      "epoch:3 step:2984 [D loss: 0.652196, acc.: 60.94%] [G loss: 0.823079]\n",
      "epoch:3 step:2985 [D loss: 0.603132, acc.: 70.31%] [G loss: 0.828881]\n",
      "epoch:3 step:2986 [D loss: 0.681474, acc.: 53.91%] [G loss: 0.811538]\n",
      "epoch:3 step:2987 [D loss: 0.585882, acc.: 69.53%] [G loss: 0.842085]\n",
      "epoch:3 step:2988 [D loss: 0.653468, acc.: 60.94%] [G loss: 0.874630]\n",
      "epoch:3 step:2989 [D loss: 0.627459, acc.: 64.06%] [G loss: 0.854196]\n",
      "epoch:3 step:2990 [D loss: 0.678774, acc.: 55.47%] [G loss: 0.880432]\n",
      "epoch:3 step:2991 [D loss: 0.668159, acc.: 59.38%] [G loss: 0.918380]\n",
      "epoch:3 step:2992 [D loss: 0.626238, acc.: 64.06%] [G loss: 0.947964]\n",
      "epoch:3 step:2993 [D loss: 0.651356, acc.: 59.38%] [G loss: 0.873136]\n",
      "epoch:3 step:2994 [D loss: 0.656406, acc.: 63.28%] [G loss: 0.857782]\n",
      "epoch:3 step:2995 [D loss: 0.659345, acc.: 66.41%] [G loss: 0.910940]\n",
      "epoch:3 step:2996 [D loss: 0.667553, acc.: 56.25%] [G loss: 0.857582]\n",
      "epoch:3 step:2997 [D loss: 0.669265, acc.: 55.47%] [G loss: 0.904477]\n",
      "epoch:3 step:2998 [D loss: 0.637966, acc.: 59.38%] [G loss: 0.855415]\n",
      "epoch:3 step:2999 [D loss: 0.646628, acc.: 62.50%] [G loss: 0.860142]\n",
      "epoch:3 step:3000 [D loss: 0.677723, acc.: 57.03%] [G loss: 0.857825]\n",
      "##############\n",
      "[3.05811244 2.78866033 3.37503976 5.2023826  2.01854036 9.27426719\n",
      " 3.53002081 4.96705816 4.50642228 8.14868929]\n",
      "##########\n",
      "epoch:3 step:3001 [D loss: 0.696099, acc.: 58.59%] [G loss: 0.857905]\n",
      "epoch:3 step:3002 [D loss: 0.635070, acc.: 62.50%] [G loss: 0.837096]\n",
      "epoch:3 step:3003 [D loss: 0.660504, acc.: 61.72%] [G loss: 0.852659]\n",
      "epoch:3 step:3004 [D loss: 0.658159, acc.: 60.94%] [G loss: 0.788300]\n",
      "epoch:3 step:3005 [D loss: 0.660240, acc.: 62.50%] [G loss: 0.811470]\n",
      "epoch:3 step:3006 [D loss: 0.640909, acc.: 64.06%] [G loss: 0.852256]\n",
      "epoch:3 step:3007 [D loss: 0.634366, acc.: 63.28%] [G loss: 0.852736]\n",
      "epoch:3 step:3008 [D loss: 0.631574, acc.: 67.19%] [G loss: 0.854401]\n",
      "epoch:3 step:3009 [D loss: 0.636272, acc.: 63.28%] [G loss: 0.877150]\n",
      "epoch:3 step:3010 [D loss: 0.657238, acc.: 62.50%] [G loss: 0.880367]\n",
      "epoch:3 step:3011 [D loss: 0.628481, acc.: 64.06%] [G loss: 0.901015]\n",
      "epoch:3 step:3012 [D loss: 0.658670, acc.: 60.94%] [G loss: 0.875436]\n",
      "epoch:3 step:3013 [D loss: 0.624559, acc.: 65.62%] [G loss: 0.906727]\n",
      "epoch:3 step:3014 [D loss: 0.613092, acc.: 70.31%] [G loss: 0.903104]\n",
      "epoch:3 step:3015 [D loss: 0.646891, acc.: 60.94%] [G loss: 0.861222]\n",
      "epoch:3 step:3016 [D loss: 0.632557, acc.: 66.41%] [G loss: 0.868986]\n",
      "epoch:3 step:3017 [D loss: 0.668738, acc.: 61.72%] [G loss: 0.878893]\n",
      "epoch:3 step:3018 [D loss: 0.644183, acc.: 64.06%] [G loss: 0.948129]\n",
      "epoch:3 step:3019 [D loss: 0.611636, acc.: 67.19%] [G loss: 0.902885]\n",
      "epoch:3 step:3020 [D loss: 0.667177, acc.: 64.06%] [G loss: 0.892245]\n",
      "epoch:3 step:3021 [D loss: 0.649567, acc.: 66.41%] [G loss: 0.871045]\n",
      "epoch:3 step:3022 [D loss: 0.617618, acc.: 65.62%] [G loss: 0.917290]\n",
      "epoch:3 step:3023 [D loss: 0.617394, acc.: 68.75%] [G loss: 0.903863]\n",
      "epoch:3 step:3024 [D loss: 0.662067, acc.: 53.91%] [G loss: 0.901634]\n",
      "epoch:3 step:3025 [D loss: 0.686107, acc.: 56.25%] [G loss: 0.899140]\n",
      "epoch:3 step:3026 [D loss: 0.679164, acc.: 57.03%] [G loss: 0.860872]\n",
      "epoch:3 step:3027 [D loss: 0.668831, acc.: 56.25%] [G loss: 0.909681]\n",
      "epoch:3 step:3028 [D loss: 0.651195, acc.: 60.94%] [G loss: 0.891909]\n",
      "epoch:3 step:3029 [D loss: 0.674425, acc.: 56.25%] [G loss: 0.855314]\n",
      "epoch:3 step:3030 [D loss: 0.675114, acc.: 59.38%] [G loss: 0.873243]\n",
      "epoch:3 step:3031 [D loss: 0.678958, acc.: 58.59%] [G loss: 0.822876]\n",
      "epoch:3 step:3032 [D loss: 0.660066, acc.: 59.38%] [G loss: 0.826382]\n",
      "epoch:3 step:3033 [D loss: 0.687195, acc.: 55.47%] [G loss: 0.868066]\n",
      "epoch:3 step:3034 [D loss: 0.671189, acc.: 58.59%] [G loss: 0.851818]\n",
      "epoch:3 step:3035 [D loss: 0.681506, acc.: 58.59%] [G loss: 0.853522]\n",
      "epoch:3 step:3036 [D loss: 0.665564, acc.: 57.03%] [G loss: 0.835523]\n",
      "epoch:3 step:3037 [D loss: 0.656074, acc.: 62.50%] [G loss: 0.868565]\n",
      "epoch:3 step:3038 [D loss: 0.654400, acc.: 58.59%] [G loss: 0.859545]\n",
      "epoch:3 step:3039 [D loss: 0.640124, acc.: 66.41%] [G loss: 0.916884]\n",
      "epoch:3 step:3040 [D loss: 0.636385, acc.: 66.41%] [G loss: 0.850029]\n",
      "epoch:3 step:3041 [D loss: 0.637726, acc.: 68.75%] [G loss: 0.862689]\n",
      "epoch:3 step:3042 [D loss: 0.667982, acc.: 63.28%] [G loss: 0.901887]\n",
      "epoch:3 step:3043 [D loss: 0.671689, acc.: 56.25%] [G loss: 0.885214]\n",
      "epoch:3 step:3044 [D loss: 0.657461, acc.: 57.81%] [G loss: 0.861126]\n",
      "epoch:3 step:3045 [D loss: 0.667841, acc.: 64.84%] [G loss: 0.865104]\n",
      "epoch:3 step:3046 [D loss: 0.658270, acc.: 61.72%] [G loss: 0.868877]\n",
      "epoch:3 step:3047 [D loss: 0.642794, acc.: 60.94%] [G loss: 0.819539]\n",
      "epoch:3 step:3048 [D loss: 0.673838, acc.: 57.03%] [G loss: 0.824687]\n",
      "epoch:3 step:3049 [D loss: 0.652858, acc.: 64.84%] [G loss: 0.846570]\n",
      "epoch:3 step:3050 [D loss: 0.639839, acc.: 60.94%] [G loss: 0.817566]\n",
      "epoch:3 step:3051 [D loss: 0.652153, acc.: 57.81%] [G loss: 0.839168]\n",
      "epoch:3 step:3052 [D loss: 0.679297, acc.: 52.34%] [G loss: 0.853773]\n",
      "epoch:3 step:3053 [D loss: 0.646580, acc.: 59.38%] [G loss: 0.879094]\n",
      "epoch:3 step:3054 [D loss: 0.643707, acc.: 59.38%] [G loss: 0.864228]\n",
      "epoch:3 step:3055 [D loss: 0.640721, acc.: 61.72%] [G loss: 0.850885]\n",
      "epoch:3 step:3056 [D loss: 0.650559, acc.: 64.06%] [G loss: 0.869087]\n",
      "epoch:3 step:3057 [D loss: 0.686276, acc.: 57.03%] [G loss: 0.862076]\n",
      "epoch:3 step:3058 [D loss: 0.638837, acc.: 64.06%] [G loss: 0.839726]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3059 [D loss: 0.617952, acc.: 65.62%] [G loss: 0.859052]\n",
      "epoch:3 step:3060 [D loss: 0.670930, acc.: 59.38%] [G loss: 0.830231]\n",
      "epoch:3 step:3061 [D loss: 0.649153, acc.: 65.62%] [G loss: 0.853475]\n",
      "epoch:3 step:3062 [D loss: 0.650782, acc.: 67.97%] [G loss: 0.878880]\n",
      "epoch:3 step:3063 [D loss: 0.624548, acc.: 67.19%] [G loss: 0.932443]\n",
      "epoch:3 step:3064 [D loss: 0.670662, acc.: 61.72%] [G loss: 0.900315]\n",
      "epoch:3 step:3065 [D loss: 0.664443, acc.: 60.94%] [G loss: 0.921826]\n",
      "epoch:3 step:3066 [D loss: 0.625758, acc.: 61.72%] [G loss: 0.909553]\n",
      "epoch:3 step:3067 [D loss: 0.676508, acc.: 57.03%] [G loss: 0.864381]\n",
      "epoch:3 step:3068 [D loss: 0.616118, acc.: 65.62%] [G loss: 0.899210]\n",
      "epoch:3 step:3069 [D loss: 0.679672, acc.: 53.12%] [G loss: 0.858545]\n",
      "epoch:3 step:3070 [D loss: 0.652331, acc.: 63.28%] [G loss: 0.818468]\n",
      "epoch:3 step:3071 [D loss: 0.675510, acc.: 60.94%] [G loss: 0.858185]\n",
      "epoch:3 step:3072 [D loss: 0.602958, acc.: 70.31%] [G loss: 0.864592]\n",
      "epoch:3 step:3073 [D loss: 0.675807, acc.: 59.38%] [G loss: 0.852465]\n",
      "epoch:3 step:3074 [D loss: 0.669021, acc.: 53.12%] [G loss: 0.822945]\n",
      "epoch:3 step:3075 [D loss: 0.649605, acc.: 57.03%] [G loss: 0.821495]\n",
      "epoch:3 step:3076 [D loss: 0.624645, acc.: 66.41%] [G loss: 0.880728]\n",
      "epoch:3 step:3077 [D loss: 0.653713, acc.: 61.72%] [G loss: 0.908149]\n",
      "epoch:3 step:3078 [D loss: 0.671970, acc.: 50.78%] [G loss: 0.865556]\n",
      "epoch:3 step:3079 [D loss: 0.682724, acc.: 53.12%] [G loss: 0.931850]\n",
      "epoch:3 step:3080 [D loss: 0.645917, acc.: 62.50%] [G loss: 0.887329]\n",
      "epoch:3 step:3081 [D loss: 0.637887, acc.: 61.72%] [G loss: 0.870463]\n",
      "epoch:3 step:3082 [D loss: 0.614467, acc.: 66.41%] [G loss: 0.837426]\n",
      "epoch:3 step:3083 [D loss: 0.685279, acc.: 55.47%] [G loss: 0.806338]\n",
      "epoch:3 step:3084 [D loss: 0.656445, acc.: 60.16%] [G loss: 0.870241]\n",
      "epoch:3 step:3085 [D loss: 0.681268, acc.: 54.69%] [G loss: 0.905728]\n",
      "epoch:3 step:3086 [D loss: 0.692342, acc.: 55.47%] [G loss: 0.865702]\n",
      "epoch:3 step:3087 [D loss: 0.677990, acc.: 53.91%] [G loss: 0.878929]\n",
      "epoch:3 step:3088 [D loss: 0.645673, acc.: 60.94%] [G loss: 0.870504]\n",
      "epoch:3 step:3089 [D loss: 0.690392, acc.: 56.25%] [G loss: 0.903178]\n",
      "epoch:3 step:3090 [D loss: 0.664997, acc.: 61.72%] [G loss: 0.891333]\n",
      "epoch:3 step:3091 [D loss: 0.633763, acc.: 63.28%] [G loss: 0.882950]\n",
      "epoch:3 step:3092 [D loss: 0.621071, acc.: 68.75%] [G loss: 0.918116]\n",
      "epoch:3 step:3093 [D loss: 0.665793, acc.: 55.47%] [G loss: 0.874415]\n",
      "epoch:3 step:3094 [D loss: 0.633839, acc.: 60.94%] [G loss: 0.894839]\n",
      "epoch:3 step:3095 [D loss: 0.618090, acc.: 65.62%] [G loss: 0.874937]\n",
      "epoch:3 step:3096 [D loss: 0.653446, acc.: 59.38%] [G loss: 0.910920]\n",
      "epoch:3 step:3097 [D loss: 0.678493, acc.: 56.25%] [G loss: 0.841837]\n",
      "epoch:3 step:3098 [D loss: 0.663491, acc.: 60.16%] [G loss: 0.925851]\n",
      "epoch:3 step:3099 [D loss: 0.653831, acc.: 65.62%] [G loss: 0.898070]\n",
      "epoch:3 step:3100 [D loss: 0.659563, acc.: 57.81%] [G loss: 0.860161]\n",
      "epoch:3 step:3101 [D loss: 0.670965, acc.: 57.81%] [G loss: 0.879118]\n",
      "epoch:3 step:3102 [D loss: 0.653873, acc.: 57.03%] [G loss: 0.907761]\n",
      "epoch:3 step:3103 [D loss: 0.633808, acc.: 63.28%] [G loss: 0.834135]\n",
      "epoch:3 step:3104 [D loss: 0.645797, acc.: 61.72%] [G loss: 0.906792]\n",
      "epoch:3 step:3105 [D loss: 0.623531, acc.: 65.62%] [G loss: 0.916945]\n",
      "epoch:3 step:3106 [D loss: 0.650628, acc.: 61.72%] [G loss: 0.869813]\n",
      "epoch:3 step:3107 [D loss: 0.701275, acc.: 57.03%] [G loss: 0.836272]\n",
      "epoch:3 step:3108 [D loss: 0.667912, acc.: 57.81%] [G loss: 0.866971]\n",
      "epoch:3 step:3109 [D loss: 0.664492, acc.: 56.25%] [G loss: 0.847133]\n",
      "epoch:3 step:3110 [D loss: 0.672873, acc.: 57.81%] [G loss: 0.840418]\n",
      "epoch:3 step:3111 [D loss: 0.672674, acc.: 57.81%] [G loss: 0.903810]\n",
      "epoch:3 step:3112 [D loss: 0.638402, acc.: 63.28%] [G loss: 0.855424]\n",
      "epoch:3 step:3113 [D loss: 0.658239, acc.: 59.38%] [G loss: 0.867656]\n",
      "epoch:3 step:3114 [D loss: 0.659030, acc.: 62.50%] [G loss: 0.851383]\n",
      "epoch:3 step:3115 [D loss: 0.647542, acc.: 67.19%] [G loss: 0.857006]\n",
      "epoch:3 step:3116 [D loss: 0.658573, acc.: 60.94%] [G loss: 0.843367]\n",
      "epoch:3 step:3117 [D loss: 0.621594, acc.: 67.97%] [G loss: 0.867474]\n",
      "epoch:3 step:3118 [D loss: 0.611754, acc.: 64.06%] [G loss: 0.885355]\n",
      "epoch:3 step:3119 [D loss: 0.671484, acc.: 61.72%] [G loss: 0.881252]\n",
      "epoch:3 step:3120 [D loss: 0.636841, acc.: 63.28%] [G loss: 0.841734]\n",
      "epoch:3 step:3121 [D loss: 0.697018, acc.: 57.81%] [G loss: 0.868421]\n",
      "epoch:3 step:3122 [D loss: 0.650106, acc.: 54.69%] [G loss: 0.905745]\n",
      "epoch:3 step:3123 [D loss: 0.721123, acc.: 50.78%] [G loss: 0.867994]\n",
      "epoch:3 step:3124 [D loss: 0.663854, acc.: 57.81%] [G loss: 0.844481]\n",
      "epoch:3 step:3125 [D loss: 0.664347, acc.: 53.12%] [G loss: 0.855266]\n",
      "epoch:3 step:3126 [D loss: 0.658534, acc.: 60.16%] [G loss: 0.849115]\n",
      "epoch:3 step:3127 [D loss: 0.642598, acc.: 61.72%] [G loss: 0.832397]\n",
      "epoch:3 step:3128 [D loss: 0.671849, acc.: 58.59%] [G loss: 0.879927]\n",
      "epoch:3 step:3129 [D loss: 0.656185, acc.: 60.16%] [G loss: 0.866831]\n",
      "epoch:3 step:3130 [D loss: 0.681308, acc.: 57.81%] [G loss: 0.858156]\n",
      "epoch:3 step:3131 [D loss: 0.668218, acc.: 55.47%] [G loss: 0.862315]\n",
      "epoch:3 step:3132 [D loss: 0.645942, acc.: 58.59%] [G loss: 0.884351]\n",
      "epoch:3 step:3133 [D loss: 0.685832, acc.: 53.12%] [G loss: 0.886142]\n",
      "epoch:3 step:3134 [D loss: 0.667515, acc.: 60.16%] [G loss: 0.848553]\n",
      "epoch:3 step:3135 [D loss: 0.649933, acc.: 57.81%] [G loss: 0.876674]\n",
      "epoch:3 step:3136 [D loss: 0.658819, acc.: 63.28%] [G loss: 0.796935]\n",
      "epoch:3 step:3137 [D loss: 0.647562, acc.: 59.38%] [G loss: 0.837700]\n",
      "epoch:3 step:3138 [D loss: 0.647389, acc.: 58.59%] [G loss: 0.885026]\n",
      "epoch:3 step:3139 [D loss: 0.619403, acc.: 65.62%] [G loss: 0.877649]\n",
      "epoch:3 step:3140 [D loss: 0.685228, acc.: 60.16%] [G loss: 0.855869]\n",
      "epoch:3 step:3141 [D loss: 0.665817, acc.: 63.28%] [G loss: 0.882628]\n",
      "epoch:3 step:3142 [D loss: 0.643861, acc.: 57.81%] [G loss: 0.869849]\n",
      "epoch:3 step:3143 [D loss: 0.621188, acc.: 64.06%] [G loss: 0.898040]\n",
      "epoch:3 step:3144 [D loss: 0.666832, acc.: 60.16%] [G loss: 0.803116]\n",
      "epoch:3 step:3145 [D loss: 0.644133, acc.: 64.06%] [G loss: 0.896637]\n",
      "epoch:3 step:3146 [D loss: 0.636097, acc.: 65.62%] [G loss: 0.877720]\n",
      "epoch:3 step:3147 [D loss: 0.636004, acc.: 65.62%] [G loss: 0.939129]\n",
      "epoch:3 step:3148 [D loss: 0.666294, acc.: 57.03%] [G loss: 0.891474]\n",
      "epoch:3 step:3149 [D loss: 0.649612, acc.: 61.72%] [G loss: 0.870336]\n",
      "epoch:3 step:3150 [D loss: 0.665613, acc.: 54.69%] [G loss: 0.878890]\n",
      "epoch:3 step:3151 [D loss: 0.632748, acc.: 66.41%] [G loss: 0.871184]\n",
      "epoch:3 step:3152 [D loss: 0.721094, acc.: 57.81%] [G loss: 0.886083]\n",
      "epoch:3 step:3153 [D loss: 0.638795, acc.: 67.19%] [G loss: 0.919631]\n",
      "epoch:3 step:3154 [D loss: 0.665137, acc.: 56.25%] [G loss: 0.866560]\n",
      "epoch:3 step:3155 [D loss: 0.670808, acc.: 60.94%] [G loss: 0.852948]\n",
      "epoch:3 step:3156 [D loss: 0.612085, acc.: 66.41%] [G loss: 0.866546]\n",
      "epoch:3 step:3157 [D loss: 0.648184, acc.: 59.38%] [G loss: 0.822872]\n",
      "epoch:3 step:3158 [D loss: 0.614597, acc.: 73.44%] [G loss: 0.831152]\n",
      "epoch:3 step:3159 [D loss: 0.636936, acc.: 69.53%] [G loss: 0.887495]\n",
      "epoch:3 step:3160 [D loss: 0.626129, acc.: 62.50%] [G loss: 0.881755]\n",
      "epoch:3 step:3161 [D loss: 0.658529, acc.: 61.72%] [G loss: 0.886941]\n",
      "epoch:3 step:3162 [D loss: 0.610844, acc.: 70.31%] [G loss: 0.884785]\n",
      "epoch:3 step:3163 [D loss: 0.640146, acc.: 59.38%] [G loss: 0.851447]\n",
      "epoch:3 step:3164 [D loss: 0.648654, acc.: 63.28%] [G loss: 0.879968]\n",
      "epoch:3 step:3165 [D loss: 0.699730, acc.: 50.78%] [G loss: 0.853351]\n",
      "epoch:3 step:3166 [D loss: 0.662340, acc.: 53.12%] [G loss: 0.840487]\n",
      "epoch:3 step:3167 [D loss: 0.691590, acc.: 50.78%] [G loss: 0.879857]\n",
      "epoch:3 step:3168 [D loss: 0.671498, acc.: 55.47%] [G loss: 0.886174]\n",
      "epoch:3 step:3169 [D loss: 0.635940, acc.: 64.06%] [G loss: 0.913770]\n",
      "epoch:3 step:3170 [D loss: 0.688003, acc.: 57.81%] [G loss: 0.882287]\n",
      "epoch:3 step:3171 [D loss: 0.663195, acc.: 57.81%] [G loss: 0.867845]\n",
      "epoch:3 step:3172 [D loss: 0.665605, acc.: 59.38%] [G loss: 0.844554]\n",
      "epoch:3 step:3173 [D loss: 0.655361, acc.: 55.47%] [G loss: 0.873262]\n",
      "epoch:3 step:3174 [D loss: 0.645972, acc.: 60.94%] [G loss: 0.891088]\n",
      "epoch:3 step:3175 [D loss: 0.641472, acc.: 58.59%] [G loss: 0.860019]\n",
      "epoch:3 step:3176 [D loss: 0.658862, acc.: 57.03%] [G loss: 0.875332]\n",
      "epoch:3 step:3177 [D loss: 0.645604, acc.: 62.50%] [G loss: 0.811340]\n",
      "epoch:3 step:3178 [D loss: 0.664770, acc.: 55.47%] [G loss: 0.830912]\n",
      "epoch:3 step:3179 [D loss: 0.679721, acc.: 55.47%] [G loss: 0.870814]\n",
      "epoch:3 step:3180 [D loss: 0.672238, acc.: 52.34%] [G loss: 0.858274]\n",
      "epoch:3 step:3181 [D loss: 0.659423, acc.: 60.94%] [G loss: 0.851805]\n",
      "epoch:3 step:3182 [D loss: 0.686700, acc.: 53.91%] [G loss: 0.840596]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3183 [D loss: 0.655479, acc.: 60.94%] [G loss: 0.864765]\n",
      "epoch:3 step:3184 [D loss: 0.660262, acc.: 57.81%] [G loss: 0.907830]\n",
      "epoch:3 step:3185 [D loss: 0.658508, acc.: 60.16%] [G loss: 0.888035]\n",
      "epoch:3 step:3186 [D loss: 0.662272, acc.: 61.72%] [G loss: 0.863306]\n",
      "epoch:3 step:3187 [D loss: 0.651414, acc.: 60.16%] [G loss: 0.863409]\n",
      "epoch:3 step:3188 [D loss: 0.636302, acc.: 60.94%] [G loss: 0.917324]\n",
      "epoch:3 step:3189 [D loss: 0.646072, acc.: 63.28%] [G loss: 0.892646]\n",
      "epoch:3 step:3190 [D loss: 0.651679, acc.: 54.69%] [G loss: 0.863763]\n",
      "epoch:3 step:3191 [D loss: 0.655376, acc.: 60.16%] [G loss: 0.838743]\n",
      "epoch:3 step:3192 [D loss: 0.662130, acc.: 62.50%] [G loss: 0.850366]\n",
      "epoch:3 step:3193 [D loss: 0.649830, acc.: 58.59%] [G loss: 0.840536]\n",
      "epoch:3 step:3194 [D loss: 0.631218, acc.: 60.94%] [G loss: 0.866421]\n",
      "epoch:3 step:3195 [D loss: 0.655620, acc.: 57.03%] [G loss: 0.827034]\n",
      "epoch:3 step:3196 [D loss: 0.644905, acc.: 64.06%] [G loss: 0.858689]\n",
      "epoch:3 step:3197 [D loss: 0.651336, acc.: 57.81%] [G loss: 0.864957]\n",
      "epoch:3 step:3198 [D loss: 0.661149, acc.: 60.16%] [G loss: 0.829647]\n",
      "epoch:3 step:3199 [D loss: 0.668610, acc.: 61.72%] [G loss: 0.927541]\n",
      "epoch:3 step:3200 [D loss: 0.647047, acc.: 58.59%] [G loss: 0.890223]\n",
      "##############\n",
      "[ 2.92287392  3.36456941  2.79736254  4.45589718  2.14602263 10.27426719\n",
      "  3.11472449  4.39202588  4.39831289  8.14868929]\n",
      "##########\n",
      "epoch:3 step:3201 [D loss: 0.621765, acc.: 71.88%] [G loss: 0.855019]\n",
      "epoch:3 step:3202 [D loss: 0.665118, acc.: 61.72%] [G loss: 0.851738]\n",
      "epoch:3 step:3203 [D loss: 0.691183, acc.: 57.81%] [G loss: 0.880513]\n",
      "epoch:3 step:3204 [D loss: 0.684897, acc.: 56.25%] [G loss: 0.877169]\n",
      "epoch:3 step:3205 [D loss: 0.692270, acc.: 55.47%] [G loss: 0.878134]\n",
      "epoch:3 step:3206 [D loss: 0.627654, acc.: 64.84%] [G loss: 0.867338]\n",
      "epoch:3 step:3207 [D loss: 0.633220, acc.: 61.72%] [G loss: 0.861657]\n",
      "epoch:3 step:3208 [D loss: 0.677835, acc.: 58.59%] [G loss: 0.867525]\n",
      "epoch:3 step:3209 [D loss: 0.662937, acc.: 58.59%] [G loss: 0.850704]\n",
      "epoch:3 step:3210 [D loss: 0.608041, acc.: 74.22%] [G loss: 0.915093]\n",
      "epoch:3 step:3211 [D loss: 0.641580, acc.: 62.50%] [G loss: 0.869514]\n",
      "epoch:3 step:3212 [D loss: 0.641143, acc.: 67.19%] [G loss: 0.854226]\n",
      "epoch:3 step:3213 [D loss: 0.614140, acc.: 65.62%] [G loss: 0.876800]\n",
      "epoch:3 step:3214 [D loss: 0.621906, acc.: 64.84%] [G loss: 0.863825]\n",
      "epoch:3 step:3215 [D loss: 0.670862, acc.: 59.38%] [G loss: 0.873255]\n",
      "epoch:3 step:3216 [D loss: 0.657217, acc.: 66.41%] [G loss: 0.818390]\n",
      "epoch:3 step:3217 [D loss: 0.610504, acc.: 64.06%] [G loss: 0.851291]\n",
      "epoch:3 step:3218 [D loss: 0.673020, acc.: 53.91%] [G loss: 0.850294]\n",
      "epoch:3 step:3219 [D loss: 0.663325, acc.: 61.72%] [G loss: 0.893185]\n",
      "epoch:3 step:3220 [D loss: 0.669299, acc.: 59.38%] [G loss: 0.866514]\n",
      "epoch:3 step:3221 [D loss: 0.661514, acc.: 60.16%] [G loss: 0.871647]\n",
      "epoch:3 step:3222 [D loss: 0.655997, acc.: 57.03%] [G loss: 0.843556]\n",
      "epoch:3 step:3223 [D loss: 0.621549, acc.: 71.88%] [G loss: 0.884528]\n",
      "epoch:3 step:3224 [D loss: 0.669948, acc.: 61.72%] [G loss: 0.849894]\n",
      "epoch:3 step:3225 [D loss: 0.658146, acc.: 59.38%] [G loss: 0.867352]\n",
      "epoch:3 step:3226 [D loss: 0.646348, acc.: 60.94%] [G loss: 0.867745]\n",
      "epoch:3 step:3227 [D loss: 0.648562, acc.: 64.06%] [G loss: 0.864227]\n",
      "epoch:3 step:3228 [D loss: 0.634277, acc.: 65.62%] [G loss: 0.869348]\n",
      "epoch:3 step:3229 [D loss: 0.654054, acc.: 60.16%] [G loss: 0.876442]\n",
      "epoch:3 step:3230 [D loss: 0.644231, acc.: 60.94%] [G loss: 0.820316]\n",
      "epoch:3 step:3231 [D loss: 0.642382, acc.: 61.72%] [G loss: 0.835632]\n",
      "epoch:3 step:3232 [D loss: 0.656851, acc.: 61.72%] [G loss: 0.851114]\n",
      "epoch:3 step:3233 [D loss: 0.654626, acc.: 60.16%] [G loss: 0.803495]\n",
      "epoch:3 step:3234 [D loss: 0.689220, acc.: 54.69%] [G loss: 0.838808]\n",
      "epoch:3 step:3235 [D loss: 0.608138, acc.: 64.06%] [G loss: 0.852502]\n",
      "epoch:3 step:3236 [D loss: 0.671395, acc.: 60.16%] [G loss: 0.806701]\n",
      "epoch:3 step:3237 [D loss: 0.659251, acc.: 55.47%] [G loss: 0.834881]\n",
      "epoch:3 step:3238 [D loss: 0.677378, acc.: 53.12%] [G loss: 0.843881]\n",
      "epoch:3 step:3239 [D loss: 0.673867, acc.: 52.34%] [G loss: 0.859128]\n",
      "epoch:3 step:3240 [D loss: 0.666540, acc.: 60.94%] [G loss: 0.840292]\n",
      "epoch:3 step:3241 [D loss: 0.678805, acc.: 59.38%] [G loss: 0.922208]\n",
      "epoch:3 step:3242 [D loss: 0.616300, acc.: 70.31%] [G loss: 0.815467]\n",
      "epoch:3 step:3243 [D loss: 0.642277, acc.: 62.50%] [G loss: 0.873509]\n",
      "epoch:3 step:3244 [D loss: 0.677427, acc.: 57.81%] [G loss: 0.847911]\n",
      "epoch:3 step:3245 [D loss: 0.658926, acc.: 53.12%] [G loss: 0.879755]\n",
      "epoch:3 step:3246 [D loss: 0.648652, acc.: 63.28%] [G loss: 0.875427]\n",
      "epoch:3 step:3247 [D loss: 0.662083, acc.: 61.72%] [G loss: 0.889539]\n",
      "epoch:3 step:3248 [D loss: 0.668808, acc.: 53.91%] [G loss: 0.877369]\n",
      "epoch:3 step:3249 [D loss: 0.660445, acc.: 57.03%] [G loss: 0.860533]\n",
      "epoch:3 step:3250 [D loss: 0.681745, acc.: 54.69%] [G loss: 0.845322]\n",
      "epoch:3 step:3251 [D loss: 0.648095, acc.: 63.28%] [G loss: 0.873570]\n",
      "epoch:3 step:3252 [D loss: 0.680253, acc.: 55.47%] [G loss: 0.856272]\n",
      "epoch:3 step:3253 [D loss: 0.639303, acc.: 61.72%] [G loss: 0.847984]\n",
      "epoch:3 step:3254 [D loss: 0.673395, acc.: 58.59%] [G loss: 0.858178]\n",
      "epoch:3 step:3255 [D loss: 0.681396, acc.: 57.81%] [G loss: 0.901747]\n",
      "epoch:3 step:3256 [D loss: 0.654249, acc.: 60.16%] [G loss: 0.940183]\n",
      "epoch:3 step:3257 [D loss: 0.665888, acc.: 53.91%] [G loss: 0.891679]\n",
      "epoch:3 step:3258 [D loss: 0.671834, acc.: 53.91%] [G loss: 0.906547]\n",
      "epoch:3 step:3259 [D loss: 0.656805, acc.: 60.16%] [G loss: 0.874115]\n",
      "epoch:3 step:3260 [D loss: 0.639916, acc.: 67.19%] [G loss: 0.897955]\n",
      "epoch:3 step:3261 [D loss: 0.640845, acc.: 63.28%] [G loss: 0.865891]\n",
      "epoch:3 step:3262 [D loss: 0.629460, acc.: 64.84%] [G loss: 0.881771]\n",
      "epoch:3 step:3263 [D loss: 0.672236, acc.: 57.81%] [G loss: 0.849684]\n",
      "epoch:3 step:3264 [D loss: 0.633456, acc.: 65.62%] [G loss: 0.814436]\n",
      "epoch:3 step:3265 [D loss: 0.664125, acc.: 61.72%] [G loss: 0.831521]\n",
      "epoch:3 step:3266 [D loss: 0.649015, acc.: 60.94%] [G loss: 0.833084]\n",
      "epoch:3 step:3267 [D loss: 0.689161, acc.: 55.47%] [G loss: 0.827696]\n",
      "epoch:3 step:3268 [D loss: 0.648668, acc.: 62.50%] [G loss: 0.844066]\n",
      "epoch:3 step:3269 [D loss: 0.582959, acc.: 74.22%] [G loss: 0.837083]\n",
      "epoch:3 step:3270 [D loss: 0.630460, acc.: 64.06%] [G loss: 0.880730]\n",
      "epoch:3 step:3271 [D loss: 0.654359, acc.: 54.69%] [G loss: 0.861504]\n",
      "epoch:3 step:3272 [D loss: 0.680204, acc.: 58.59%] [G loss: 0.936784]\n",
      "epoch:3 step:3273 [D loss: 0.655722, acc.: 60.16%] [G loss: 0.919248]\n",
      "epoch:3 step:3274 [D loss: 0.664402, acc.: 63.28%] [G loss: 0.896811]\n",
      "epoch:3 step:3275 [D loss: 0.625023, acc.: 67.97%] [G loss: 0.854876]\n",
      "epoch:3 step:3276 [D loss: 0.681569, acc.: 57.81%] [G loss: 0.868644]\n",
      "epoch:3 step:3277 [D loss: 0.632020, acc.: 65.62%] [G loss: 0.876916]\n",
      "epoch:3 step:3278 [D loss: 0.616269, acc.: 69.53%] [G loss: 0.867878]\n",
      "epoch:3 step:3279 [D loss: 0.627354, acc.: 67.19%] [G loss: 0.846378]\n",
      "epoch:3 step:3280 [D loss: 0.642793, acc.: 60.94%] [G loss: 0.817097]\n",
      "epoch:3 step:3281 [D loss: 0.693823, acc.: 55.47%] [G loss: 0.842753]\n",
      "epoch:3 step:3282 [D loss: 0.613717, acc.: 77.34%] [G loss: 0.878708]\n",
      "epoch:3 step:3283 [D loss: 0.646063, acc.: 59.38%] [G loss: 0.880610]\n",
      "epoch:3 step:3284 [D loss: 0.656863, acc.: 61.72%] [G loss: 0.902303]\n",
      "epoch:3 step:3285 [D loss: 0.613592, acc.: 65.62%] [G loss: 0.904746]\n",
      "epoch:3 step:3286 [D loss: 0.642965, acc.: 64.84%] [G loss: 0.973763]\n",
      "epoch:3 step:3287 [D loss: 0.634167, acc.: 65.62%] [G loss: 0.867418]\n",
      "epoch:3 step:3288 [D loss: 0.665866, acc.: 64.84%] [G loss: 0.862687]\n",
      "epoch:3 step:3289 [D loss: 0.647751, acc.: 64.06%] [G loss: 0.888623]\n",
      "epoch:3 step:3290 [D loss: 0.652228, acc.: 59.38%] [G loss: 0.846398]\n",
      "epoch:3 step:3291 [D loss: 0.662075, acc.: 59.38%] [G loss: 0.828097]\n",
      "epoch:3 step:3292 [D loss: 0.644571, acc.: 60.94%] [G loss: 0.881016]\n",
      "epoch:3 step:3293 [D loss: 0.638460, acc.: 63.28%] [G loss: 0.850981]\n",
      "epoch:3 step:3294 [D loss: 0.666842, acc.: 54.69%] [G loss: 0.883127]\n",
      "epoch:3 step:3295 [D loss: 0.638202, acc.: 70.31%] [G loss: 0.856225]\n",
      "epoch:3 step:3296 [D loss: 0.666530, acc.: 57.03%] [G loss: 0.882985]\n",
      "epoch:3 step:3297 [D loss: 0.647384, acc.: 61.72%] [G loss: 0.845722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3298 [D loss: 0.645969, acc.: 64.84%] [G loss: 0.843071]\n",
      "epoch:3 step:3299 [D loss: 0.641470, acc.: 66.41%] [G loss: 0.912478]\n",
      "epoch:3 step:3300 [D loss: 0.667413, acc.: 58.59%] [G loss: 0.906667]\n",
      "epoch:3 step:3301 [D loss: 0.641342, acc.: 64.84%] [G loss: 0.887750]\n",
      "epoch:3 step:3302 [D loss: 0.600850, acc.: 66.41%] [G loss: 0.858236]\n",
      "epoch:3 step:3303 [D loss: 0.650127, acc.: 60.16%] [G loss: 0.848652]\n",
      "epoch:3 step:3304 [D loss: 0.645278, acc.: 65.62%] [G loss: 0.860615]\n",
      "epoch:3 step:3305 [D loss: 0.607075, acc.: 71.09%] [G loss: 0.850780]\n",
      "epoch:3 step:3306 [D loss: 0.696075, acc.: 58.59%] [G loss: 0.818129]\n",
      "epoch:3 step:3307 [D loss: 0.643834, acc.: 64.06%] [G loss: 0.875363]\n",
      "epoch:3 step:3308 [D loss: 0.650607, acc.: 60.94%] [G loss: 0.824292]\n",
      "epoch:3 step:3309 [D loss: 0.652259, acc.: 62.50%] [G loss: 0.847512]\n",
      "epoch:3 step:3310 [D loss: 0.628816, acc.: 62.50%] [G loss: 0.863190]\n",
      "epoch:3 step:3311 [D loss: 0.693413, acc.: 53.91%] [G loss: 0.860806]\n",
      "epoch:3 step:3312 [D loss: 0.657487, acc.: 63.28%] [G loss: 0.856633]\n",
      "epoch:3 step:3313 [D loss: 0.672262, acc.: 53.12%] [G loss: 0.842054]\n",
      "epoch:3 step:3314 [D loss: 0.655654, acc.: 62.50%] [G loss: 0.834343]\n",
      "epoch:3 step:3315 [D loss: 0.645315, acc.: 63.28%] [G loss: 0.863820]\n",
      "epoch:3 step:3316 [D loss: 0.639410, acc.: 67.97%] [G loss: 0.881201]\n",
      "epoch:3 step:3317 [D loss: 0.656543, acc.: 64.06%] [G loss: 0.902333]\n",
      "epoch:3 step:3318 [D loss: 0.665098, acc.: 57.03%] [G loss: 0.859493]\n",
      "epoch:3 step:3319 [D loss: 0.638733, acc.: 63.28%] [G loss: 0.810571]\n",
      "epoch:3 step:3320 [D loss: 0.673056, acc.: 58.59%] [G loss: 0.878654]\n",
      "epoch:3 step:3321 [D loss: 0.625371, acc.: 63.28%] [G loss: 0.938450]\n",
      "epoch:3 step:3322 [D loss: 0.690634, acc.: 52.34%] [G loss: 0.862109]\n",
      "epoch:3 step:3323 [D loss: 0.745770, acc.: 48.44%] [G loss: 0.875335]\n",
      "epoch:3 step:3324 [D loss: 0.661170, acc.: 56.25%] [G loss: 0.851681]\n",
      "epoch:3 step:3325 [D loss: 0.684141, acc.: 53.91%] [G loss: 0.830467]\n",
      "epoch:3 step:3326 [D loss: 0.672201, acc.: 56.25%] [G loss: 0.867850]\n",
      "epoch:3 step:3327 [D loss: 0.672233, acc.: 57.03%] [G loss: 0.857292]\n",
      "epoch:3 step:3328 [D loss: 0.645593, acc.: 66.41%] [G loss: 0.878062]\n",
      "epoch:3 step:3329 [D loss: 0.661654, acc.: 57.03%] [G loss: 0.868758]\n",
      "epoch:3 step:3330 [D loss: 0.640411, acc.: 64.06%] [G loss: 0.881276]\n",
      "epoch:3 step:3331 [D loss: 0.677123, acc.: 59.38%] [G loss: 0.894886]\n",
      "epoch:3 step:3332 [D loss: 0.609427, acc.: 68.75%] [G loss: 0.880371]\n",
      "epoch:3 step:3333 [D loss: 0.673060, acc.: 63.28%] [G loss: 0.840290]\n",
      "epoch:3 step:3334 [D loss: 0.639953, acc.: 64.84%] [G loss: 0.870485]\n",
      "epoch:3 step:3335 [D loss: 0.633246, acc.: 69.53%] [G loss: 0.924425]\n",
      "epoch:3 step:3336 [D loss: 0.662835, acc.: 54.69%] [G loss: 0.861155]\n",
      "epoch:3 step:3337 [D loss: 0.688285, acc.: 58.59%] [G loss: 0.840005]\n",
      "epoch:3 step:3338 [D loss: 0.654153, acc.: 59.38%] [G loss: 0.840862]\n",
      "epoch:3 step:3339 [D loss: 0.668822, acc.: 51.56%] [G loss: 0.852734]\n",
      "epoch:3 step:3340 [D loss: 0.658997, acc.: 58.59%] [G loss: 0.876653]\n",
      "epoch:3 step:3341 [D loss: 0.643640, acc.: 63.28%] [G loss: 0.893916]\n",
      "epoch:3 step:3342 [D loss: 0.638678, acc.: 61.72%] [G loss: 0.973280]\n",
      "epoch:3 step:3343 [D loss: 0.657504, acc.: 63.28%] [G loss: 0.894331]\n",
      "epoch:3 step:3344 [D loss: 0.670696, acc.: 57.03%] [G loss: 0.816057]\n",
      "epoch:3 step:3345 [D loss: 0.691337, acc.: 56.25%] [G loss: 0.810418]\n",
      "epoch:3 step:3346 [D loss: 0.657423, acc.: 60.16%] [G loss: 0.876726]\n",
      "epoch:3 step:3347 [D loss: 0.665151, acc.: 60.16%] [G loss: 0.839608]\n",
      "epoch:3 step:3348 [D loss: 0.651481, acc.: 67.97%] [G loss: 0.890309]\n",
      "epoch:3 step:3349 [D loss: 0.690991, acc.: 53.12%] [G loss: 0.845573]\n",
      "epoch:3 step:3350 [D loss: 0.642980, acc.: 62.50%] [G loss: 0.823742]\n",
      "epoch:3 step:3351 [D loss: 0.644139, acc.: 62.50%] [G loss: 0.869250]\n",
      "epoch:3 step:3352 [D loss: 0.615638, acc.: 69.53%] [G loss: 0.879052]\n",
      "epoch:3 step:3353 [D loss: 0.629661, acc.: 64.84%] [G loss: 0.865540]\n",
      "epoch:3 step:3354 [D loss: 0.674753, acc.: 60.16%] [G loss: 0.847444]\n",
      "epoch:3 step:3355 [D loss: 0.660825, acc.: 64.84%] [G loss: 0.875978]\n",
      "epoch:3 step:3356 [D loss: 0.675334, acc.: 55.47%] [G loss: 0.876820]\n",
      "epoch:3 step:3357 [D loss: 0.677933, acc.: 50.78%] [G loss: 0.885198]\n",
      "epoch:3 step:3358 [D loss: 0.645759, acc.: 61.72%] [G loss: 0.889705]\n",
      "epoch:3 step:3359 [D loss: 0.635982, acc.: 62.50%] [G loss: 0.889190]\n",
      "epoch:3 step:3360 [D loss: 0.654504, acc.: 60.94%] [G loss: 0.862981]\n",
      "epoch:3 step:3361 [D loss: 0.642749, acc.: 62.50%] [G loss: 0.850948]\n",
      "epoch:3 step:3362 [D loss: 0.663394, acc.: 60.16%] [G loss: 0.890550]\n",
      "epoch:3 step:3363 [D loss: 0.657611, acc.: 59.38%] [G loss: 0.894364]\n",
      "epoch:3 step:3364 [D loss: 0.668016, acc.: 57.81%] [G loss: 0.855051]\n",
      "epoch:3 step:3365 [D loss: 0.632306, acc.: 62.50%] [G loss: 0.851004]\n",
      "epoch:3 step:3366 [D loss: 0.656695, acc.: 58.59%] [G loss: 0.844396]\n",
      "epoch:3 step:3367 [D loss: 0.640651, acc.: 67.19%] [G loss: 0.837830]\n",
      "epoch:3 step:3368 [D loss: 0.606590, acc.: 68.75%] [G loss: 0.879817]\n",
      "epoch:3 step:3369 [D loss: 0.661291, acc.: 58.59%] [G loss: 0.846894]\n",
      "epoch:3 step:3370 [D loss: 0.655778, acc.: 58.59%] [G loss: 0.854785]\n",
      "epoch:3 step:3371 [D loss: 0.628269, acc.: 66.41%] [G loss: 0.888634]\n",
      "epoch:3 step:3372 [D loss: 0.637774, acc.: 66.41%] [G loss: 0.797345]\n",
      "epoch:3 step:3373 [D loss: 0.641690, acc.: 57.81%] [G loss: 0.862655]\n",
      "epoch:3 step:3374 [D loss: 0.606302, acc.: 70.31%] [G loss: 0.859977]\n",
      "epoch:3 step:3375 [D loss: 0.623559, acc.: 64.84%] [G loss: 0.894988]\n",
      "epoch:3 step:3376 [D loss: 0.636166, acc.: 67.19%] [G loss: 0.907847]\n",
      "epoch:3 step:3377 [D loss: 0.611820, acc.: 69.53%] [G loss: 0.878307]\n",
      "epoch:3 step:3378 [D loss: 0.647701, acc.: 63.28%] [G loss: 0.904857]\n",
      "epoch:3 step:3379 [D loss: 0.679453, acc.: 54.69%] [G loss: 0.879799]\n",
      "epoch:3 step:3380 [D loss: 0.672290, acc.: 53.91%] [G loss: 0.894778]\n",
      "epoch:3 step:3381 [D loss: 0.656763, acc.: 60.16%] [G loss: 0.802792]\n",
      "epoch:3 step:3382 [D loss: 0.654123, acc.: 67.19%] [G loss: 0.863702]\n",
      "epoch:3 step:3383 [D loss: 0.613553, acc.: 69.53%] [G loss: 0.878921]\n",
      "epoch:3 step:3384 [D loss: 0.674250, acc.: 56.25%] [G loss: 0.874865]\n",
      "epoch:3 step:3385 [D loss: 0.668393, acc.: 57.03%] [G loss: 0.916945]\n",
      "epoch:3 step:3386 [D loss: 0.642102, acc.: 61.72%] [G loss: 0.899899]\n",
      "epoch:3 step:3387 [D loss: 0.685817, acc.: 61.72%] [G loss: 0.905705]\n",
      "epoch:3 step:3388 [D loss: 0.664011, acc.: 59.38%] [G loss: 0.879467]\n",
      "epoch:3 step:3389 [D loss: 0.639813, acc.: 63.28%] [G loss: 0.874468]\n",
      "epoch:3 step:3390 [D loss: 0.659462, acc.: 56.25%] [G loss: 0.849291]\n",
      "epoch:3 step:3391 [D loss: 0.672824, acc.: 57.81%] [G loss: 0.818787]\n",
      "epoch:3 step:3392 [D loss: 0.667340, acc.: 57.03%] [G loss: 0.814357]\n",
      "epoch:3 step:3393 [D loss: 0.613619, acc.: 67.97%] [G loss: 0.844321]\n",
      "epoch:3 step:3394 [D loss: 0.684454, acc.: 53.91%] [G loss: 0.851054]\n",
      "epoch:3 step:3395 [D loss: 0.640043, acc.: 61.72%] [G loss: 0.850414]\n",
      "epoch:3 step:3396 [D loss: 0.653686, acc.: 64.84%] [G loss: 0.839646]\n",
      "epoch:3 step:3397 [D loss: 0.684789, acc.: 59.38%] [G loss: 0.852922]\n",
      "epoch:3 step:3398 [D loss: 0.646578, acc.: 55.47%] [G loss: 0.853197]\n",
      "epoch:3 step:3399 [D loss: 0.655625, acc.: 60.94%] [G loss: 0.868839]\n",
      "epoch:3 step:3400 [D loss: 0.649703, acc.: 61.72%] [G loss: 0.877159]\n",
      "##############\n",
      "[ 3.12158958  2.7613003   2.83233243  4.58896771  1.97637163 10.27426719\n",
      "  3.54193796  4.36801652  4.6671777   8.14868929]\n",
      "##########\n",
      "epoch:3 step:3401 [D loss: 0.650478, acc.: 64.06%] [G loss: 0.871430]\n",
      "epoch:3 step:3402 [D loss: 0.629635, acc.: 64.84%] [G loss: 0.874123]\n",
      "epoch:3 step:3403 [D loss: 0.651008, acc.: 63.28%] [G loss: 0.834458]\n",
      "epoch:3 step:3404 [D loss: 0.666855, acc.: 60.94%] [G loss: 0.876896]\n",
      "epoch:3 step:3405 [D loss: 0.652726, acc.: 61.72%] [G loss: 0.903268]\n",
      "epoch:3 step:3406 [D loss: 0.666212, acc.: 65.62%] [G loss: 0.872355]\n",
      "epoch:3 step:3407 [D loss: 0.662555, acc.: 54.69%] [G loss: 0.865396]\n",
      "epoch:3 step:3408 [D loss: 0.651960, acc.: 59.38%] [G loss: 0.894809]\n",
      "epoch:3 step:3409 [D loss: 0.694123, acc.: 55.47%] [G loss: 0.831266]\n",
      "epoch:3 step:3410 [D loss: 0.637468, acc.: 60.16%] [G loss: 0.881465]\n",
      "epoch:3 step:3411 [D loss: 0.674121, acc.: 62.50%] [G loss: 0.896563]\n",
      "epoch:3 step:3412 [D loss: 0.687630, acc.: 60.94%] [G loss: 0.884073]\n",
      "epoch:3 step:3413 [D loss: 0.611208, acc.: 74.22%] [G loss: 0.863401]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3414 [D loss: 0.685795, acc.: 57.03%] [G loss: 0.842729]\n",
      "epoch:3 step:3415 [D loss: 0.662574, acc.: 57.81%] [G loss: 0.876632]\n",
      "epoch:3 step:3416 [D loss: 0.627194, acc.: 62.50%] [G loss: 0.887112]\n",
      "epoch:3 step:3417 [D loss: 0.660740, acc.: 61.72%] [G loss: 0.875284]\n",
      "epoch:3 step:3418 [D loss: 0.655139, acc.: 57.03%] [G loss: 0.928038]\n",
      "epoch:3 step:3419 [D loss: 0.686624, acc.: 54.69%] [G loss: 0.866094]\n",
      "epoch:3 step:3420 [D loss: 0.650417, acc.: 67.19%] [G loss: 0.847768]\n",
      "epoch:3 step:3421 [D loss: 0.683146, acc.: 57.03%] [G loss: 0.876773]\n",
      "epoch:3 step:3422 [D loss: 0.634603, acc.: 61.72%] [G loss: 0.831421]\n",
      "epoch:3 step:3423 [D loss: 0.654405, acc.: 58.59%] [G loss: 0.818416]\n",
      "epoch:3 step:3424 [D loss: 0.661108, acc.: 57.81%] [G loss: 0.887765]\n",
      "epoch:3 step:3425 [D loss: 0.628718, acc.: 60.94%] [G loss: 0.852895]\n",
      "epoch:3 step:3426 [D loss: 0.663680, acc.: 62.50%] [G loss: 0.866180]\n",
      "epoch:3 step:3427 [D loss: 0.697927, acc.: 50.78%] [G loss: 0.883581]\n",
      "epoch:3 step:3428 [D loss: 0.646446, acc.: 63.28%] [G loss: 0.853711]\n",
      "epoch:3 step:3429 [D loss: 0.646577, acc.: 63.28%] [G loss: 0.874990]\n",
      "epoch:3 step:3430 [D loss: 0.667179, acc.: 57.81%] [G loss: 0.845489]\n",
      "epoch:3 step:3431 [D loss: 0.637601, acc.: 60.16%] [G loss: 0.828903]\n",
      "epoch:3 step:3432 [D loss: 0.680388, acc.: 59.38%] [G loss: 0.857462]\n",
      "epoch:3 step:3433 [D loss: 0.627797, acc.: 65.62%] [G loss: 0.878742]\n",
      "epoch:3 step:3434 [D loss: 0.653269, acc.: 58.59%] [G loss: 0.895068]\n",
      "epoch:3 step:3435 [D loss: 0.633878, acc.: 60.94%] [G loss: 0.856436]\n",
      "epoch:3 step:3436 [D loss: 0.642084, acc.: 64.06%] [G loss: 0.834602]\n",
      "epoch:3 step:3437 [D loss: 0.675483, acc.: 52.34%] [G loss: 0.853276]\n",
      "epoch:3 step:3438 [D loss: 0.635144, acc.: 58.59%] [G loss: 0.825664]\n",
      "epoch:3 step:3439 [D loss: 0.680789, acc.: 59.38%] [G loss: 0.855744]\n",
      "epoch:3 step:3440 [D loss: 0.627280, acc.: 63.28%] [G loss: 0.854149]\n",
      "epoch:3 step:3441 [D loss: 0.659282, acc.: 59.38%] [G loss: 0.842093]\n",
      "epoch:3 step:3442 [D loss: 0.601960, acc.: 68.75%] [G loss: 0.839658]\n",
      "epoch:3 step:3443 [D loss: 0.673652, acc.: 56.25%] [G loss: 0.846501]\n",
      "epoch:3 step:3444 [D loss: 0.669594, acc.: 55.47%] [G loss: 0.769305]\n",
      "epoch:3 step:3445 [D loss: 0.670905, acc.: 57.81%] [G loss: 0.822357]\n",
      "epoch:3 step:3446 [D loss: 0.658514, acc.: 58.59%] [G loss: 0.858007]\n",
      "epoch:3 step:3447 [D loss: 0.677777, acc.: 60.16%] [G loss: 0.876627]\n",
      "epoch:3 step:3448 [D loss: 0.666012, acc.: 60.94%] [G loss: 0.900273]\n",
      "epoch:3 step:3449 [D loss: 0.659490, acc.: 60.16%] [G loss: 0.937972]\n",
      "epoch:3 step:3450 [D loss: 0.654073, acc.: 60.16%] [G loss: 0.888642]\n",
      "epoch:3 step:3451 [D loss: 0.677253, acc.: 55.47%] [G loss: 0.939200]\n",
      "epoch:3 step:3452 [D loss: 0.664135, acc.: 57.81%] [G loss: 0.914009]\n",
      "epoch:3 step:3453 [D loss: 0.669927, acc.: 62.50%] [G loss: 0.860919]\n",
      "epoch:3 step:3454 [D loss: 0.669989, acc.: 56.25%] [G loss: 0.825103]\n",
      "epoch:3 step:3455 [D loss: 0.658574, acc.: 56.25%] [G loss: 0.780930]\n",
      "epoch:3 step:3456 [D loss: 0.663159, acc.: 57.81%] [G loss: 0.830911]\n",
      "epoch:3 step:3457 [D loss: 0.635373, acc.: 65.62%] [G loss: 0.851365]\n",
      "epoch:3 step:3458 [D loss: 0.680236, acc.: 53.91%] [G loss: 0.868689]\n",
      "epoch:3 step:3459 [D loss: 0.636305, acc.: 64.06%] [G loss: 0.869922]\n",
      "epoch:3 step:3460 [D loss: 0.649872, acc.: 60.16%] [G loss: 0.825907]\n",
      "epoch:3 step:3461 [D loss: 0.664409, acc.: 60.94%] [G loss: 0.832876]\n",
      "epoch:3 step:3462 [D loss: 0.649572, acc.: 64.06%] [G loss: 0.837938]\n",
      "epoch:3 step:3463 [D loss: 0.623017, acc.: 60.16%] [G loss: 0.822780]\n",
      "epoch:3 step:3464 [D loss: 0.648816, acc.: 60.94%] [G loss: 0.830273]\n",
      "epoch:3 step:3465 [D loss: 0.615051, acc.: 63.28%] [G loss: 0.835090]\n",
      "epoch:3 step:3466 [D loss: 0.690006, acc.: 60.16%] [G loss: 0.823124]\n",
      "epoch:3 step:3467 [D loss: 0.676196, acc.: 59.38%] [G loss: 0.837006]\n",
      "epoch:3 step:3468 [D loss: 0.664679, acc.: 58.59%] [G loss: 0.835148]\n",
      "epoch:3 step:3469 [D loss: 0.693504, acc.: 59.38%] [G loss: 0.898810]\n",
      "epoch:3 step:3470 [D loss: 0.659466, acc.: 59.38%] [G loss: 0.901470]\n",
      "epoch:3 step:3471 [D loss: 0.680462, acc.: 51.56%] [G loss: 0.927572]\n",
      "epoch:3 step:3472 [D loss: 0.640134, acc.: 62.50%] [G loss: 0.933684]\n",
      "epoch:3 step:3473 [D loss: 0.629631, acc.: 66.41%] [G loss: 0.875360]\n",
      "epoch:3 step:3474 [D loss: 0.661116, acc.: 60.16%] [G loss: 0.810288]\n",
      "epoch:3 step:3475 [D loss: 0.670895, acc.: 60.94%] [G loss: 0.836322]\n",
      "epoch:3 step:3476 [D loss: 0.673479, acc.: 54.69%] [G loss: 0.797889]\n",
      "epoch:3 step:3477 [D loss: 0.604436, acc.: 64.84%] [G loss: 0.827659]\n",
      "epoch:3 step:3478 [D loss: 0.649573, acc.: 63.28%] [G loss: 0.821523]\n",
      "epoch:3 step:3479 [D loss: 0.683161, acc.: 54.69%] [G loss: 0.868284]\n",
      "epoch:3 step:3480 [D loss: 0.633460, acc.: 60.16%] [G loss: 0.857848]\n",
      "epoch:3 step:3481 [D loss: 0.623939, acc.: 65.62%] [G loss: 0.930465]\n",
      "epoch:3 step:3482 [D loss: 0.622042, acc.: 64.84%] [G loss: 0.883328]\n",
      "epoch:3 step:3483 [D loss: 0.671190, acc.: 54.69%] [G loss: 0.871631]\n",
      "epoch:3 step:3484 [D loss: 0.651867, acc.: 64.84%] [G loss: 0.883790]\n",
      "epoch:3 step:3485 [D loss: 0.684803, acc.: 54.69%] [G loss: 0.876580]\n",
      "epoch:3 step:3486 [D loss: 0.651170, acc.: 65.62%] [G loss: 0.855489]\n",
      "epoch:3 step:3487 [D loss: 0.656103, acc.: 66.41%] [G loss: 0.830036]\n",
      "epoch:3 step:3488 [D loss: 0.691822, acc.: 55.47%] [G loss: 0.844047]\n",
      "epoch:3 step:3489 [D loss: 0.631284, acc.: 64.84%] [G loss: 0.826745]\n",
      "epoch:3 step:3490 [D loss: 0.669787, acc.: 59.38%] [G loss: 0.814534]\n",
      "epoch:3 step:3491 [D loss: 0.670600, acc.: 56.25%] [G loss: 0.834318]\n",
      "epoch:3 step:3492 [D loss: 0.656658, acc.: 57.81%] [G loss: 0.851509]\n",
      "epoch:3 step:3493 [D loss: 0.627253, acc.: 63.28%] [G loss: 0.883576]\n",
      "epoch:3 step:3494 [D loss: 0.616817, acc.: 64.84%] [G loss: 0.819064]\n",
      "epoch:3 step:3495 [D loss: 0.636220, acc.: 64.06%] [G loss: 0.826815]\n",
      "epoch:3 step:3496 [D loss: 0.647285, acc.: 61.72%] [G loss: 0.889814]\n",
      "epoch:3 step:3497 [D loss: 0.666457, acc.: 57.03%] [G loss: 0.915359]\n",
      "epoch:3 step:3498 [D loss: 0.643505, acc.: 60.94%] [G loss: 0.937304]\n",
      "epoch:3 step:3499 [D loss: 0.635543, acc.: 63.28%] [G loss: 0.861381]\n",
      "epoch:3 step:3500 [D loss: 0.618058, acc.: 68.75%] [G loss: 0.878632]\n",
      "epoch:3 step:3501 [D loss: 0.670514, acc.: 57.81%] [G loss: 0.874828]\n",
      "epoch:3 step:3502 [D loss: 0.635068, acc.: 65.62%] [G loss: 0.824148]\n",
      "epoch:3 step:3503 [D loss: 0.660031, acc.: 61.72%] [G loss: 0.817832]\n",
      "epoch:3 step:3504 [D loss: 0.624087, acc.: 71.09%] [G loss: 0.851000]\n",
      "epoch:3 step:3505 [D loss: 0.636719, acc.: 65.62%] [G loss: 0.816894]\n",
      "epoch:3 step:3506 [D loss: 0.662061, acc.: 59.38%] [G loss: 0.841087]\n",
      "epoch:3 step:3507 [D loss: 0.656785, acc.: 60.94%] [G loss: 0.844112]\n",
      "epoch:3 step:3508 [D loss: 0.667273, acc.: 57.81%] [G loss: 0.874182]\n",
      "epoch:3 step:3509 [D loss: 0.604420, acc.: 67.97%] [G loss: 0.846012]\n",
      "epoch:3 step:3510 [D loss: 0.674676, acc.: 57.81%] [G loss: 0.873995]\n",
      "epoch:3 step:3511 [D loss: 0.667530, acc.: 61.72%] [G loss: 0.873019]\n",
      "epoch:3 step:3512 [D loss: 0.655101, acc.: 62.50%] [G loss: 0.924765]\n",
      "epoch:3 step:3513 [D loss: 0.630275, acc.: 60.94%] [G loss: 0.896796]\n",
      "epoch:3 step:3514 [D loss: 0.644898, acc.: 63.28%] [G loss: 0.874090]\n",
      "epoch:3 step:3515 [D loss: 0.664076, acc.: 59.38%] [G loss: 0.875520]\n",
      "epoch:3 step:3516 [D loss: 0.627848, acc.: 63.28%] [G loss: 0.914597]\n",
      "epoch:3 step:3517 [D loss: 0.647353, acc.: 60.16%] [G loss: 0.846390]\n",
      "epoch:3 step:3518 [D loss: 0.609347, acc.: 67.19%] [G loss: 0.859731]\n",
      "epoch:3 step:3519 [D loss: 0.665233, acc.: 61.72%] [G loss: 0.835170]\n",
      "epoch:3 step:3520 [D loss: 0.666952, acc.: 62.50%] [G loss: 0.856002]\n",
      "epoch:3 step:3521 [D loss: 0.607889, acc.: 67.19%] [G loss: 0.912450]\n",
      "epoch:3 step:3522 [D loss: 0.597389, acc.: 66.41%] [G loss: 0.922130]\n",
      "epoch:3 step:3523 [D loss: 0.656547, acc.: 58.59%] [G loss: 0.838076]\n",
      "epoch:3 step:3524 [D loss: 0.711077, acc.: 51.56%] [G loss: 0.873728]\n",
      "epoch:3 step:3525 [D loss: 0.689029, acc.: 55.47%] [G loss: 0.919354]\n",
      "epoch:3 step:3526 [D loss: 0.702909, acc.: 57.81%] [G loss: 0.894985]\n",
      "epoch:3 step:3527 [D loss: 0.671043, acc.: 57.81%] [G loss: 0.920792]\n",
      "epoch:3 step:3528 [D loss: 0.668948, acc.: 60.16%] [G loss: 0.884387]\n",
      "epoch:3 step:3529 [D loss: 0.680342, acc.: 57.81%] [G loss: 0.877071]\n",
      "epoch:3 step:3530 [D loss: 0.670956, acc.: 56.25%] [G loss: 0.792686]\n",
      "epoch:3 step:3531 [D loss: 0.681634, acc.: 56.25%] [G loss: 0.841146]\n",
      "epoch:3 step:3532 [D loss: 0.659144, acc.: 55.47%] [G loss: 0.872283]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3533 [D loss: 0.687680, acc.: 57.81%] [G loss: 0.817627]\n",
      "epoch:3 step:3534 [D loss: 0.673904, acc.: 57.03%] [G loss: 0.887029]\n",
      "epoch:3 step:3535 [D loss: 0.695821, acc.: 48.44%] [G loss: 0.831175]\n",
      "epoch:3 step:3536 [D loss: 0.648272, acc.: 66.41%] [G loss: 0.840390]\n",
      "epoch:3 step:3537 [D loss: 0.648206, acc.: 62.50%] [G loss: 0.827949]\n",
      "epoch:3 step:3538 [D loss: 0.659982, acc.: 64.84%] [G loss: 0.848713]\n",
      "epoch:3 step:3539 [D loss: 0.640575, acc.: 71.88%] [G loss: 0.877943]\n",
      "epoch:3 step:3540 [D loss: 0.701505, acc.: 56.25%] [G loss: 0.841724]\n",
      "epoch:3 step:3541 [D loss: 0.688666, acc.: 55.47%] [G loss: 0.885701]\n",
      "epoch:3 step:3542 [D loss: 0.663690, acc.: 59.38%] [G loss: 0.897445]\n",
      "epoch:3 step:3543 [D loss: 0.664762, acc.: 60.16%] [G loss: 0.877476]\n",
      "epoch:3 step:3544 [D loss: 0.676052, acc.: 59.38%] [G loss: 0.841037]\n",
      "epoch:3 step:3545 [D loss: 0.665272, acc.: 60.16%] [G loss: 0.861322]\n",
      "epoch:3 step:3546 [D loss: 0.676320, acc.: 60.16%] [G loss: 0.842890]\n",
      "epoch:3 step:3547 [D loss: 0.633204, acc.: 62.50%] [G loss: 0.829793]\n",
      "epoch:3 step:3548 [D loss: 0.646115, acc.: 59.38%] [G loss: 0.836379]\n",
      "epoch:3 step:3549 [D loss: 0.684740, acc.: 57.03%] [G loss: 0.850853]\n",
      "epoch:3 step:3550 [D loss: 0.635664, acc.: 65.62%] [G loss: 0.858077]\n",
      "epoch:3 step:3551 [D loss: 0.675503, acc.: 63.28%] [G loss: 0.839437]\n",
      "epoch:3 step:3552 [D loss: 0.647931, acc.: 64.06%] [G loss: 0.917005]\n",
      "epoch:3 step:3553 [D loss: 0.633224, acc.: 64.06%] [G loss: 0.907036]\n",
      "epoch:3 step:3554 [D loss: 0.686278, acc.: 53.12%] [G loss: 0.812725]\n",
      "epoch:3 step:3555 [D loss: 0.659523, acc.: 60.94%] [G loss: 0.853705]\n",
      "epoch:3 step:3556 [D loss: 0.677234, acc.: 57.81%] [G loss: 0.868546]\n",
      "epoch:3 step:3557 [D loss: 0.618640, acc.: 67.97%] [G loss: 0.913695]\n",
      "epoch:3 step:3558 [D loss: 0.700026, acc.: 52.34%] [G loss: 0.850409]\n",
      "epoch:3 step:3559 [D loss: 0.643713, acc.: 67.97%] [G loss: 0.854829]\n",
      "epoch:3 step:3560 [D loss: 0.678245, acc.: 53.91%] [G loss: 0.872535]\n",
      "epoch:3 step:3561 [D loss: 0.623844, acc.: 69.53%] [G loss: 0.883887]\n",
      "epoch:3 step:3562 [D loss: 0.633784, acc.: 64.06%] [G loss: 0.839406]\n",
      "epoch:3 step:3563 [D loss: 0.668136, acc.: 57.81%] [G loss: 0.847464]\n",
      "epoch:3 step:3564 [D loss: 0.619428, acc.: 64.84%] [G loss: 0.808398]\n",
      "epoch:3 step:3565 [D loss: 0.701593, acc.: 55.47%] [G loss: 0.855758]\n",
      "epoch:3 step:3566 [D loss: 0.650829, acc.: 61.72%] [G loss: 0.856511]\n",
      "epoch:3 step:3567 [D loss: 0.649020, acc.: 61.72%] [G loss: 0.849221]\n",
      "epoch:3 step:3568 [D loss: 0.647600, acc.: 62.50%] [G loss: 0.846162]\n",
      "epoch:3 step:3569 [D loss: 0.656209, acc.: 60.94%] [G loss: 0.903565]\n",
      "epoch:3 step:3570 [D loss: 0.653716, acc.: 64.06%] [G loss: 0.874066]\n",
      "epoch:3 step:3571 [D loss: 0.670174, acc.: 56.25%] [G loss: 0.860481]\n",
      "epoch:3 step:3572 [D loss: 0.714372, acc.: 50.00%] [G loss: 0.879902]\n",
      "epoch:3 step:3573 [D loss: 0.695771, acc.: 58.59%] [G loss: 0.855913]\n",
      "epoch:3 step:3574 [D loss: 0.651524, acc.: 60.94%] [G loss: 0.858807]\n",
      "epoch:3 step:3575 [D loss: 0.605986, acc.: 75.00%] [G loss: 0.872190]\n",
      "epoch:3 step:3576 [D loss: 0.694032, acc.: 52.34%] [G loss: 0.841028]\n",
      "epoch:3 step:3577 [D loss: 0.646712, acc.: 62.50%] [G loss: 0.886838]\n",
      "epoch:3 step:3578 [D loss: 0.656008, acc.: 61.72%] [G loss: 0.859201]\n",
      "epoch:3 step:3579 [D loss: 0.640107, acc.: 60.94%] [G loss: 0.866672]\n",
      "epoch:3 step:3580 [D loss: 0.629646, acc.: 65.62%] [G loss: 0.857843]\n",
      "epoch:3 step:3581 [D loss: 0.638085, acc.: 61.72%] [G loss: 0.880421]\n",
      "epoch:3 step:3582 [D loss: 0.683059, acc.: 56.25%] [G loss: 0.840264]\n",
      "epoch:3 step:3583 [D loss: 0.623612, acc.: 67.97%] [G loss: 0.871537]\n",
      "epoch:3 step:3584 [D loss: 0.670074, acc.: 60.94%] [G loss: 0.856633]\n",
      "epoch:3 step:3585 [D loss: 0.640807, acc.: 66.41%] [G loss: 0.877877]\n",
      "epoch:3 step:3586 [D loss: 0.648770, acc.: 63.28%] [G loss: 0.895739]\n",
      "epoch:3 step:3587 [D loss: 0.635386, acc.: 64.06%] [G loss: 0.886454]\n",
      "epoch:3 step:3588 [D loss: 0.658372, acc.: 59.38%] [G loss: 0.864805]\n",
      "epoch:3 step:3589 [D loss: 0.631726, acc.: 65.62%] [G loss: 0.877799]\n",
      "epoch:3 step:3590 [D loss: 0.635497, acc.: 63.28%] [G loss: 0.847848]\n",
      "epoch:3 step:3591 [D loss: 0.672957, acc.: 55.47%] [G loss: 0.893437]\n",
      "epoch:3 step:3592 [D loss: 0.660010, acc.: 57.03%] [G loss: 0.890072]\n",
      "epoch:3 step:3593 [D loss: 0.659999, acc.: 61.72%] [G loss: 0.880019]\n",
      "epoch:3 step:3594 [D loss: 0.648607, acc.: 62.50%] [G loss: 0.858416]\n",
      "epoch:3 step:3595 [D loss: 0.668164, acc.: 57.03%] [G loss: 0.835884]\n",
      "epoch:3 step:3596 [D loss: 0.641739, acc.: 62.50%] [G loss: 0.852512]\n",
      "epoch:3 step:3597 [D loss: 0.667092, acc.: 57.03%] [G loss: 0.836856]\n",
      "epoch:3 step:3598 [D loss: 0.657684, acc.: 60.16%] [G loss: 0.885093]\n",
      "epoch:3 step:3599 [D loss: 0.657492, acc.: 61.72%] [G loss: 0.801241]\n",
      "epoch:3 step:3600 [D loss: 0.645261, acc.: 61.72%] [G loss: 0.863805]\n",
      "##############\n",
      "[3.05947246 2.90224086 2.53466943 3.88195185 1.71591546 8.04022239\n",
      " 3.18934157 4.24609694 4.45906059 6.37461599]\n",
      "##########\n",
      "epoch:3 step:3601 [D loss: 0.669007, acc.: 59.38%] [G loss: 0.831812]\n",
      "epoch:3 step:3602 [D loss: 0.652905, acc.: 59.38%] [G loss: 0.868611]\n",
      "epoch:3 step:3603 [D loss: 0.666084, acc.: 56.25%] [G loss: 0.846755]\n",
      "epoch:3 step:3604 [D loss: 0.649035, acc.: 64.84%] [G loss: 0.895188]\n",
      "epoch:3 step:3605 [D loss: 0.608984, acc.: 67.97%] [G loss: 0.866346]\n",
      "epoch:3 step:3606 [D loss: 0.707846, acc.: 53.91%] [G loss: 0.866156]\n",
      "epoch:3 step:3607 [D loss: 0.656686, acc.: 61.72%] [G loss: 0.831555]\n",
      "epoch:3 step:3608 [D loss: 0.661494, acc.: 61.72%] [G loss: 0.821999]\n",
      "epoch:3 step:3609 [D loss: 0.666621, acc.: 57.81%] [G loss: 0.885361]\n",
      "epoch:3 step:3610 [D loss: 0.638406, acc.: 63.28%] [G loss: 0.846479]\n",
      "epoch:3 step:3611 [D loss: 0.681001, acc.: 54.69%] [G loss: 0.841784]\n",
      "epoch:3 step:3612 [D loss: 0.643195, acc.: 65.62%] [G loss: 0.835038]\n",
      "epoch:3 step:3613 [D loss: 0.652434, acc.: 59.38%] [G loss: 0.872923]\n",
      "epoch:3 step:3614 [D loss: 0.669955, acc.: 55.47%] [G loss: 0.803468]\n",
      "epoch:3 step:3615 [D loss: 0.677509, acc.: 58.59%] [G loss: 0.840264]\n",
      "epoch:3 step:3616 [D loss: 0.618484, acc.: 64.84%] [G loss: 0.816900]\n",
      "epoch:3 step:3617 [D loss: 0.608293, acc.: 66.41%] [G loss: 0.843009]\n",
      "epoch:3 step:3618 [D loss: 0.682207, acc.: 53.12%] [G loss: 0.818519]\n",
      "epoch:3 step:3619 [D loss: 0.632215, acc.: 63.28%] [G loss: 0.876461]\n",
      "epoch:3 step:3620 [D loss: 0.644143, acc.: 63.28%] [G loss: 0.827006]\n",
      "epoch:3 step:3621 [D loss: 0.654581, acc.: 62.50%] [G loss: 0.803556]\n",
      "epoch:3 step:3622 [D loss: 0.633686, acc.: 63.28%] [G loss: 0.873283]\n",
      "epoch:3 step:3623 [D loss: 0.649318, acc.: 57.81%] [G loss: 0.837424]\n",
      "epoch:3 step:3624 [D loss: 0.669629, acc.: 53.91%] [G loss: 0.836044]\n",
      "epoch:3 step:3625 [D loss: 0.683063, acc.: 60.94%] [G loss: 0.845708]\n",
      "epoch:3 step:3626 [D loss: 0.669632, acc.: 60.94%] [G loss: 0.860879]\n",
      "epoch:3 step:3627 [D loss: 0.636156, acc.: 63.28%] [G loss: 0.858891]\n",
      "epoch:3 step:3628 [D loss: 0.701498, acc.: 53.12%] [G loss: 0.858225]\n",
      "epoch:3 step:3629 [D loss: 0.665077, acc.: 57.03%] [G loss: 0.838610]\n",
      "epoch:3 step:3630 [D loss: 0.665284, acc.: 60.94%] [G loss: 0.852258]\n",
      "epoch:3 step:3631 [D loss: 0.683002, acc.: 58.59%] [G loss: 0.840112]\n",
      "epoch:3 step:3632 [D loss: 0.677090, acc.: 58.59%] [G loss: 0.849284]\n",
      "epoch:3 step:3633 [D loss: 0.642347, acc.: 61.72%] [G loss: 0.846761]\n",
      "epoch:3 step:3634 [D loss: 0.761104, acc.: 53.91%] [G loss: 0.773026]\n",
      "epoch:3 step:3635 [D loss: 0.686758, acc.: 54.69%] [G loss: 0.792884]\n",
      "epoch:3 step:3636 [D loss: 0.673018, acc.: 57.81%] [G loss: 0.799846]\n",
      "epoch:3 step:3637 [D loss: 0.640131, acc.: 64.84%] [G loss: 0.860979]\n",
      "epoch:3 step:3638 [D loss: 0.664622, acc.: 59.38%] [G loss: 0.870211]\n",
      "epoch:3 step:3639 [D loss: 0.701686, acc.: 50.78%] [G loss: 0.882886]\n",
      "epoch:3 step:3640 [D loss: 0.688694, acc.: 53.91%] [G loss: 0.859373]\n",
      "epoch:3 step:3641 [D loss: 0.658689, acc.: 56.25%] [G loss: 0.856504]\n",
      "epoch:3 step:3642 [D loss: 0.697086, acc.: 59.38%] [G loss: 0.859436]\n",
      "epoch:3 step:3643 [D loss: 0.637484, acc.: 65.62%] [G loss: 0.860175]\n",
      "epoch:3 step:3644 [D loss: 0.633239, acc.: 64.06%] [G loss: 0.832975]\n",
      "epoch:3 step:3645 [D loss: 0.675085, acc.: 60.94%] [G loss: 0.837876]\n",
      "epoch:3 step:3646 [D loss: 0.669788, acc.: 63.28%] [G loss: 0.896649]\n",
      "epoch:3 step:3647 [D loss: 0.640978, acc.: 65.62%] [G loss: 0.884015]\n",
      "epoch:3 step:3648 [D loss: 0.692984, acc.: 55.47%] [G loss: 0.842658]\n",
      "epoch:3 step:3649 [D loss: 0.661649, acc.: 59.38%] [G loss: 0.841019]\n",
      "epoch:3 step:3650 [D loss: 0.636297, acc.: 63.28%] [G loss: 0.882199]\n",
      "epoch:3 step:3651 [D loss: 0.703759, acc.: 55.47%] [G loss: 0.915471]\n",
      "epoch:3 step:3652 [D loss: 0.717590, acc.: 51.56%] [G loss: 0.806754]\n",
      "epoch:3 step:3653 [D loss: 0.694731, acc.: 53.12%] [G loss: 0.802038]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:3 step:3654 [D loss: 0.655645, acc.: 62.50%] [G loss: 0.805382]\n",
      "epoch:3 step:3655 [D loss: 0.691760, acc.: 51.56%] [G loss: 0.816605]\n",
      "epoch:3 step:3656 [D loss: 0.666284, acc.: 57.81%] [G loss: 0.826395]\n",
      "epoch:3 step:3657 [D loss: 0.663654, acc.: 60.94%] [G loss: 0.925480]\n",
      "epoch:3 step:3658 [D loss: 0.689441, acc.: 57.03%] [G loss: 0.860417]\n",
      "epoch:3 step:3659 [D loss: 0.697026, acc.: 53.12%] [G loss: 0.865887]\n",
      "epoch:3 step:3660 [D loss: 0.653031, acc.: 58.59%] [G loss: 0.819200]\n",
      "epoch:3 step:3661 [D loss: 0.651953, acc.: 60.16%] [G loss: 0.874879]\n",
      "epoch:3 step:3662 [D loss: 0.650541, acc.: 64.06%] [G loss: 0.903591]\n",
      "epoch:3 step:3663 [D loss: 0.637586, acc.: 67.97%] [G loss: 0.882363]\n",
      "epoch:3 step:3664 [D loss: 0.643867, acc.: 59.38%] [G loss: 0.883060]\n",
      "epoch:3 step:3665 [D loss: 0.656646, acc.: 64.06%] [G loss: 0.916733]\n",
      "epoch:3 step:3666 [D loss: 0.700878, acc.: 51.56%] [G loss: 0.856974]\n",
      "epoch:3 step:3667 [D loss: 0.624541, acc.: 64.06%] [G loss: 0.884901]\n",
      "epoch:3 step:3668 [D loss: 0.669696, acc.: 53.91%] [G loss: 0.846411]\n",
      "epoch:3 step:3669 [D loss: 0.652578, acc.: 59.38%] [G loss: 0.931825]\n",
      "epoch:3 step:3670 [D loss: 0.637891, acc.: 66.41%] [G loss: 0.889563]\n",
      "epoch:3 step:3671 [D loss: 0.643833, acc.: 62.50%] [G loss: 0.856044]\n",
      "epoch:3 step:3672 [D loss: 0.647712, acc.: 64.06%] [G loss: 0.869090]\n",
      "epoch:3 step:3673 [D loss: 0.632230, acc.: 66.41%] [G loss: 0.851741]\n",
      "epoch:3 step:3674 [D loss: 0.632166, acc.: 64.06%] [G loss: 0.832502]\n",
      "epoch:3 step:3675 [D loss: 0.722559, acc.: 50.00%] [G loss: 0.937150]\n",
      "epoch:3 step:3676 [D loss: 0.671328, acc.: 60.16%] [G loss: 0.851461]\n",
      "epoch:3 step:3677 [D loss: 0.635627, acc.: 60.16%] [G loss: 0.888228]\n",
      "epoch:3 step:3678 [D loss: 0.667992, acc.: 63.28%] [G loss: 0.858382]\n",
      "epoch:3 step:3679 [D loss: 0.656700, acc.: 64.06%] [G loss: 0.861730]\n",
      "epoch:3 step:3680 [D loss: 0.640537, acc.: 65.62%] [G loss: 0.819778]\n",
      "epoch:3 step:3681 [D loss: 0.676500, acc.: 56.25%] [G loss: 0.815208]\n",
      "epoch:3 step:3682 [D loss: 0.656124, acc.: 60.16%] [G loss: 0.898651]\n",
      "epoch:3 step:3683 [D loss: 0.714871, acc.: 52.34%] [G loss: 0.921151]\n",
      "epoch:3 step:3684 [D loss: 0.612081, acc.: 69.53%] [G loss: 0.872475]\n",
      "epoch:3 step:3685 [D loss: 0.615521, acc.: 68.75%] [G loss: 0.870844]\n",
      "epoch:3 step:3686 [D loss: 0.640159, acc.: 66.41%] [G loss: 0.914822]\n",
      "epoch:3 step:3687 [D loss: 0.679745, acc.: 59.38%] [G loss: 0.842510]\n",
      "epoch:3 step:3688 [D loss: 0.659948, acc.: 60.16%] [G loss: 0.871622]\n",
      "epoch:3 step:3689 [D loss: 0.673141, acc.: 51.56%] [G loss: 0.858562]\n",
      "epoch:3 step:3690 [D loss: 0.664182, acc.: 60.16%] [G loss: 0.886208]\n",
      "epoch:3 step:3691 [D loss: 0.660415, acc.: 62.50%] [G loss: 0.859333]\n",
      "epoch:3 step:3692 [D loss: 0.660287, acc.: 61.72%] [G loss: 0.819947]\n",
      "epoch:3 step:3693 [D loss: 0.660783, acc.: 64.84%] [G loss: 0.888303]\n",
      "epoch:3 step:3694 [D loss: 0.637329, acc.: 64.06%] [G loss: 0.912700]\n",
      "epoch:3 step:3695 [D loss: 0.629382, acc.: 62.50%] [G loss: 0.905900]\n",
      "epoch:3 step:3696 [D loss: 0.691984, acc.: 57.03%] [G loss: 0.834618]\n",
      "epoch:3 step:3697 [D loss: 0.658996, acc.: 55.47%] [G loss: 0.861204]\n",
      "epoch:3 step:3698 [D loss: 0.671550, acc.: 58.59%] [G loss: 0.797858]\n",
      "epoch:3 step:3699 [D loss: 0.676728, acc.: 57.03%] [G loss: 0.842481]\n",
      "epoch:3 step:3700 [D loss: 0.652191, acc.: 61.72%] [G loss: 0.842265]\n",
      "epoch:3 step:3701 [D loss: 0.673196, acc.: 54.69%] [G loss: 0.909505]\n",
      "epoch:3 step:3702 [D loss: 0.680749, acc.: 55.47%] [G loss: 0.872489]\n",
      "epoch:3 step:3703 [D loss: 0.674969, acc.: 55.47%] [G loss: 0.875421]\n",
      "epoch:3 step:3704 [D loss: 0.647270, acc.: 64.06%] [G loss: 0.844988]\n",
      "epoch:3 step:3705 [D loss: 0.698749, acc.: 52.34%] [G loss: 0.796177]\n",
      "epoch:3 step:3706 [D loss: 0.663857, acc.: 60.94%] [G loss: 0.781251]\n",
      "epoch:3 step:3707 [D loss: 0.672996, acc.: 59.38%] [G loss: 0.873679]\n",
      "epoch:3 step:3708 [D loss: 0.653941, acc.: 64.84%] [G loss: 0.848414]\n",
      "epoch:3 step:3709 [D loss: 0.622070, acc.: 65.62%] [G loss: 0.846213]\n",
      "epoch:3 step:3710 [D loss: 0.664248, acc.: 65.62%] [G loss: 0.832636]\n",
      "epoch:3 step:3711 [D loss: 0.689164, acc.: 58.59%] [G loss: 0.844974]\n",
      "epoch:3 step:3712 [D loss: 0.677312, acc.: 53.12%] [G loss: 0.861387]\n",
      "epoch:3 step:3713 [D loss: 0.673462, acc.: 53.91%] [G loss: 0.866953]\n",
      "epoch:3 step:3714 [D loss: 0.664187, acc.: 58.59%] [G loss: 0.936217]\n",
      "epoch:3 step:3715 [D loss: 0.667749, acc.: 60.94%] [G loss: 0.883543]\n",
      "epoch:3 step:3716 [D loss: 0.639126, acc.: 64.84%] [G loss: 0.865603]\n",
      "epoch:3 step:3717 [D loss: 0.638770, acc.: 67.97%] [G loss: 0.860016]\n",
      "epoch:3 step:3718 [D loss: 0.688159, acc.: 51.56%] [G loss: 0.869118]\n",
      "epoch:3 step:3719 [D loss: 0.616658, acc.: 71.88%] [G loss: 0.873455]\n",
      "epoch:3 step:3720 [D loss: 0.662349, acc.: 57.03%] [G loss: 0.871422]\n",
      "epoch:3 step:3721 [D loss: 0.703161, acc.: 53.12%] [G loss: 0.856467]\n",
      "epoch:3 step:3722 [D loss: 0.674615, acc.: 59.38%] [G loss: 0.845249]\n",
      "epoch:3 step:3723 [D loss: 0.661112, acc.: 61.72%] [G loss: 0.877464]\n",
      "epoch:3 step:3724 [D loss: 0.668777, acc.: 60.16%] [G loss: 0.892112]\n",
      "epoch:3 step:3725 [D loss: 0.664067, acc.: 60.94%] [G loss: 0.880272]\n",
      "epoch:3 step:3726 [D loss: 0.642108, acc.: 65.62%] [G loss: 0.827026]\n",
      "epoch:3 step:3727 [D loss: 0.647511, acc.: 63.28%] [G loss: 0.882406]\n",
      "epoch:3 step:3728 [D loss: 0.648678, acc.: 67.19%] [G loss: 0.836437]\n",
      "epoch:3 step:3729 [D loss: 0.624722, acc.: 67.97%] [G loss: 0.889494]\n",
      "epoch:3 step:3730 [D loss: 0.644578, acc.: 64.84%] [G loss: 0.891855]\n",
      "epoch:3 step:3731 [D loss: 0.678632, acc.: 59.38%] [G loss: 0.833069]\n",
      "epoch:3 step:3732 [D loss: 0.691229, acc.: 56.25%] [G loss: 0.820785]\n",
      "epoch:3 step:3733 [D loss: 0.634142, acc.: 68.75%] [G loss: 0.874409]\n",
      "epoch:3 step:3734 [D loss: 0.657214, acc.: 62.50%] [G loss: 0.843485]\n",
      "epoch:3 step:3735 [D loss: 0.689985, acc.: 56.25%] [G loss: 0.833325]\n",
      "epoch:3 step:3736 [D loss: 0.675840, acc.: 61.72%] [G loss: 0.861554]\n",
      "epoch:3 step:3737 [D loss: 0.659654, acc.: 57.81%] [G loss: 0.871474]\n",
      "epoch:3 step:3738 [D loss: 0.663140, acc.: 61.72%] [G loss: 0.842251]\n",
      "epoch:3 step:3739 [D loss: 0.645787, acc.: 60.94%] [G loss: 0.871952]\n",
      "epoch:3 step:3740 [D loss: 0.695006, acc.: 50.78%] [G loss: 0.902291]\n",
      "epoch:3 step:3741 [D loss: 0.654868, acc.: 61.72%] [G loss: 0.855057]\n",
      "epoch:3 step:3742 [D loss: 0.658072, acc.: 64.84%] [G loss: 0.901297]\n",
      "epoch:3 step:3743 [D loss: 0.662244, acc.: 64.84%] [G loss: 0.838075]\n",
      "epoch:3 step:3744 [D loss: 0.663208, acc.: 61.72%] [G loss: 0.788380]\n",
      "epoch:3 step:3745 [D loss: 0.645478, acc.: 63.28%] [G loss: 0.765184]\n",
      "epoch:3 step:3746 [D loss: 0.642603, acc.: 66.41%] [G loss: 0.824233]\n",
      "epoch:3 step:3747 [D loss: 0.643038, acc.: 60.94%] [G loss: 0.860448]\n",
      "epoch:3 step:3748 [D loss: 0.699225, acc.: 51.56%] [G loss: 0.850328]\n",
      "epoch:4 step:3749 [D loss: 0.662316, acc.: 60.16%] [G loss: 0.837650]\n",
      "epoch:4 step:3750 [D loss: 0.688084, acc.: 54.69%] [G loss: 0.860834]\n",
      "epoch:4 step:3751 [D loss: 0.641613, acc.: 64.84%] [G loss: 0.873020]\n",
      "epoch:4 step:3752 [D loss: 0.656027, acc.: 57.81%] [G loss: 0.878036]\n",
      "epoch:4 step:3753 [D loss: 0.657072, acc.: 62.50%] [G loss: 0.878797]\n",
      "epoch:4 step:3754 [D loss: 0.653691, acc.: 62.50%] [G loss: 0.879609]\n",
      "epoch:4 step:3755 [D loss: 0.663091, acc.: 60.16%] [G loss: 0.875013]\n",
      "epoch:4 step:3756 [D loss: 0.646238, acc.: 59.38%] [G loss: 0.863314]\n",
      "epoch:4 step:3757 [D loss: 0.641742, acc.: 64.06%] [G loss: 0.877946]\n",
      "epoch:4 step:3758 [D loss: 0.681727, acc.: 60.16%] [G loss: 0.868278]\n",
      "epoch:4 step:3759 [D loss: 0.627060, acc.: 65.62%] [G loss: 0.871453]\n",
      "epoch:4 step:3760 [D loss: 0.654798, acc.: 64.06%] [G loss: 0.881355]\n",
      "epoch:4 step:3761 [D loss: 0.678438, acc.: 61.72%] [G loss: 0.818052]\n",
      "epoch:4 step:3762 [D loss: 0.669811, acc.: 63.28%] [G loss: 0.902868]\n",
      "epoch:4 step:3763 [D loss: 0.643871, acc.: 64.84%] [G loss: 0.853550]\n",
      "epoch:4 step:3764 [D loss: 0.644300, acc.: 65.62%] [G loss: 0.900184]\n",
      "epoch:4 step:3765 [D loss: 0.625408, acc.: 67.97%] [G loss: 0.866620]\n",
      "epoch:4 step:3766 [D loss: 0.682399, acc.: 58.59%] [G loss: 0.876025]\n",
      "epoch:4 step:3767 [D loss: 0.659171, acc.: 64.84%] [G loss: 0.892822]\n",
      "epoch:4 step:3768 [D loss: 0.654555, acc.: 59.38%] [G loss: 0.905518]\n",
      "epoch:4 step:3769 [D loss: 0.663324, acc.: 56.25%] [G loss: 0.838023]\n",
      "epoch:4 step:3770 [D loss: 0.648601, acc.: 63.28%] [G loss: 0.863800]\n",
      "epoch:4 step:3771 [D loss: 0.681152, acc.: 60.94%] [G loss: 0.794581]\n",
      "epoch:4 step:3772 [D loss: 0.668117, acc.: 61.72%] [G loss: 0.840432]\n",
      "epoch:4 step:3773 [D loss: 0.675785, acc.: 58.59%] [G loss: 0.827919]\n",
      "epoch:4 step:3774 [D loss: 0.650035, acc.: 63.28%] [G loss: 0.871672]\n",
      "epoch:4 step:3775 [D loss: 0.654767, acc.: 62.50%] [G loss: 0.840354]\n",
      "epoch:4 step:3776 [D loss: 0.660256, acc.: 60.94%] [G loss: 0.865579]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3777 [D loss: 0.714281, acc.: 56.25%] [G loss: 0.851166]\n",
      "epoch:4 step:3778 [D loss: 0.640193, acc.: 59.38%] [G loss: 0.860276]\n",
      "epoch:4 step:3779 [D loss: 0.662068, acc.: 61.72%] [G loss: 0.865581]\n",
      "epoch:4 step:3780 [D loss: 0.650828, acc.: 63.28%] [G loss: 0.849901]\n",
      "epoch:4 step:3781 [D loss: 0.646256, acc.: 59.38%] [G loss: 0.846038]\n",
      "epoch:4 step:3782 [D loss: 0.674243, acc.: 53.91%] [G loss: 0.829257]\n",
      "epoch:4 step:3783 [D loss: 0.658412, acc.: 59.38%] [G loss: 0.850416]\n",
      "epoch:4 step:3784 [D loss: 0.621116, acc.: 62.50%] [G loss: 0.829881]\n",
      "epoch:4 step:3785 [D loss: 0.659642, acc.: 57.03%] [G loss: 0.855202]\n",
      "epoch:4 step:3786 [D loss: 0.652237, acc.: 60.16%] [G loss: 0.859740]\n",
      "epoch:4 step:3787 [D loss: 0.659138, acc.: 64.06%] [G loss: 0.864654]\n",
      "epoch:4 step:3788 [D loss: 0.674577, acc.: 60.94%] [G loss: 0.819195]\n",
      "epoch:4 step:3789 [D loss: 0.675839, acc.: 57.81%] [G loss: 0.895893]\n",
      "epoch:4 step:3790 [D loss: 0.661723, acc.: 56.25%] [G loss: 0.816365]\n",
      "epoch:4 step:3791 [D loss: 0.676759, acc.: 56.25%] [G loss: 0.872741]\n",
      "epoch:4 step:3792 [D loss: 0.655432, acc.: 57.81%] [G loss: 0.845822]\n",
      "epoch:4 step:3793 [D loss: 0.638471, acc.: 65.62%] [G loss: 0.881002]\n",
      "epoch:4 step:3794 [D loss: 0.653078, acc.: 63.28%] [G loss: 0.864708]\n",
      "epoch:4 step:3795 [D loss: 0.666137, acc.: 55.47%] [G loss: 0.869104]\n",
      "epoch:4 step:3796 [D loss: 0.640295, acc.: 66.41%] [G loss: 0.895066]\n",
      "epoch:4 step:3797 [D loss: 0.664439, acc.: 60.16%] [G loss: 0.831605]\n",
      "epoch:4 step:3798 [D loss: 0.634806, acc.: 65.62%] [G loss: 0.891922]\n",
      "epoch:4 step:3799 [D loss: 0.675217, acc.: 54.69%] [G loss: 0.914425]\n",
      "epoch:4 step:3800 [D loss: 0.672131, acc.: 57.03%] [G loss: 0.851774]\n",
      "##############\n",
      "[ 3.06015201  2.92864051  2.82468655  4.57327751  1.93084168 10.27426719\n",
      "  3.64833975  4.83553928  4.61523302  8.14868929]\n",
      "##########\n",
      "epoch:4 step:3801 [D loss: 0.628516, acc.: 63.28%] [G loss: 0.864984]\n",
      "epoch:4 step:3802 [D loss: 0.660152, acc.: 52.34%] [G loss: 0.853424]\n",
      "epoch:4 step:3803 [D loss: 0.662016, acc.: 61.72%] [G loss: 0.869150]\n",
      "epoch:4 step:3804 [D loss: 0.706221, acc.: 50.00%] [G loss: 0.798596]\n",
      "epoch:4 step:3805 [D loss: 0.644091, acc.: 63.28%] [G loss: 0.793515]\n",
      "epoch:4 step:3806 [D loss: 0.694386, acc.: 52.34%] [G loss: 0.886248]\n",
      "epoch:4 step:3807 [D loss: 0.625080, acc.: 67.97%] [G loss: 0.873244]\n",
      "epoch:4 step:3808 [D loss: 0.657953, acc.: 65.62%] [G loss: 0.881303]\n",
      "epoch:4 step:3809 [D loss: 0.693598, acc.: 53.91%] [G loss: 0.890790]\n",
      "epoch:4 step:3810 [D loss: 0.658255, acc.: 61.72%] [G loss: 0.878380]\n",
      "epoch:4 step:3811 [D loss: 0.656479, acc.: 59.38%] [G loss: 0.839162]\n",
      "epoch:4 step:3812 [D loss: 0.623698, acc.: 67.19%] [G loss: 0.856913]\n",
      "epoch:4 step:3813 [D loss: 0.661261, acc.: 62.50%] [G loss: 0.821973]\n",
      "epoch:4 step:3814 [D loss: 0.631368, acc.: 67.19%] [G loss: 0.886265]\n",
      "epoch:4 step:3815 [D loss: 0.716950, acc.: 53.91%] [G loss: 0.868418]\n",
      "epoch:4 step:3816 [D loss: 0.648638, acc.: 60.94%] [G loss: 0.855619]\n",
      "epoch:4 step:3817 [D loss: 0.629105, acc.: 67.97%] [G loss: 0.848561]\n",
      "epoch:4 step:3818 [D loss: 0.662352, acc.: 54.69%] [G loss: 0.875326]\n",
      "epoch:4 step:3819 [D loss: 0.664378, acc.: 60.94%] [G loss: 0.845860]\n",
      "epoch:4 step:3820 [D loss: 0.627072, acc.: 69.53%] [G loss: 0.888611]\n",
      "epoch:4 step:3821 [D loss: 0.591628, acc.: 72.66%] [G loss: 0.862448]\n",
      "epoch:4 step:3822 [D loss: 0.670729, acc.: 60.94%] [G loss: 0.865245]\n",
      "epoch:4 step:3823 [D loss: 0.651406, acc.: 60.94%] [G loss: 0.843201]\n",
      "epoch:4 step:3824 [D loss: 0.617872, acc.: 67.19%] [G loss: 0.908658]\n",
      "epoch:4 step:3825 [D loss: 0.655706, acc.: 61.72%] [G loss: 0.917427]\n",
      "epoch:4 step:3826 [D loss: 0.673832, acc.: 53.12%] [G loss: 0.857832]\n",
      "epoch:4 step:3827 [D loss: 0.646509, acc.: 60.94%] [G loss: 0.910836]\n",
      "epoch:4 step:3828 [D loss: 0.666184, acc.: 57.81%] [G loss: 0.885462]\n",
      "epoch:4 step:3829 [D loss: 0.668131, acc.: 60.16%] [G loss: 0.887309]\n",
      "epoch:4 step:3830 [D loss: 0.704778, acc.: 50.78%] [G loss: 0.859320]\n",
      "epoch:4 step:3831 [D loss: 0.658301, acc.: 63.28%] [G loss: 0.871671]\n",
      "epoch:4 step:3832 [D loss: 0.649515, acc.: 60.16%] [G loss: 0.869289]\n",
      "epoch:4 step:3833 [D loss: 0.681581, acc.: 53.91%] [G loss: 0.826407]\n",
      "epoch:4 step:3834 [D loss: 0.660293, acc.: 60.16%] [G loss: 0.836084]\n",
      "epoch:4 step:3835 [D loss: 0.651946, acc.: 67.19%] [G loss: 0.832605]\n",
      "epoch:4 step:3836 [D loss: 0.639587, acc.: 67.19%] [G loss: 0.872893]\n",
      "epoch:4 step:3837 [D loss: 0.652397, acc.: 64.84%] [G loss: 0.874670]\n",
      "epoch:4 step:3838 [D loss: 0.641768, acc.: 67.19%] [G loss: 0.835376]\n",
      "epoch:4 step:3839 [D loss: 0.661850, acc.: 61.72%] [G loss: 0.866532]\n",
      "epoch:4 step:3840 [D loss: 0.649363, acc.: 64.84%] [G loss: 0.838278]\n",
      "epoch:4 step:3841 [D loss: 0.704266, acc.: 57.81%] [G loss: 0.861318]\n",
      "epoch:4 step:3842 [D loss: 0.637518, acc.: 63.28%] [G loss: 0.857171]\n",
      "epoch:4 step:3843 [D loss: 0.639748, acc.: 62.50%] [G loss: 0.887926]\n",
      "epoch:4 step:3844 [D loss: 0.636501, acc.: 65.62%] [G loss: 0.887328]\n",
      "epoch:4 step:3845 [D loss: 0.670727, acc.: 56.25%] [G loss: 0.926576]\n",
      "epoch:4 step:3846 [D loss: 0.614113, acc.: 66.41%] [G loss: 0.918143]\n",
      "epoch:4 step:3847 [D loss: 0.662198, acc.: 57.03%] [G loss: 0.931284]\n",
      "epoch:4 step:3848 [D loss: 0.643839, acc.: 61.72%] [G loss: 0.878489]\n",
      "epoch:4 step:3849 [D loss: 0.625697, acc.: 64.84%] [G loss: 0.850990]\n",
      "epoch:4 step:3850 [D loss: 0.700876, acc.: 50.00%] [G loss: 0.849636]\n",
      "epoch:4 step:3851 [D loss: 0.637798, acc.: 66.41%] [G loss: 0.855236]\n",
      "epoch:4 step:3852 [D loss: 0.655118, acc.: 63.28%] [G loss: 0.868617]\n",
      "epoch:4 step:3853 [D loss: 0.608967, acc.: 65.62%] [G loss: 0.892842]\n",
      "epoch:4 step:3854 [D loss: 0.698674, acc.: 55.47%] [G loss: 0.884946]\n",
      "epoch:4 step:3855 [D loss: 0.639352, acc.: 63.28%] [G loss: 0.861620]\n",
      "epoch:4 step:3856 [D loss: 0.671593, acc.: 58.59%] [G loss: 0.837250]\n",
      "epoch:4 step:3857 [D loss: 0.641969, acc.: 60.94%] [G loss: 0.893978]\n",
      "epoch:4 step:3858 [D loss: 0.659040, acc.: 63.28%] [G loss: 0.858496]\n",
      "epoch:4 step:3859 [D loss: 0.666116, acc.: 59.38%] [G loss: 0.835237]\n",
      "epoch:4 step:3860 [D loss: 0.668309, acc.: 53.12%] [G loss: 0.889630]\n",
      "epoch:4 step:3861 [D loss: 0.661704, acc.: 57.03%] [G loss: 0.905791]\n",
      "epoch:4 step:3862 [D loss: 0.645542, acc.: 60.94%] [G loss: 0.899977]\n",
      "epoch:4 step:3863 [D loss: 0.676084, acc.: 54.69%] [G loss: 0.932087]\n",
      "epoch:4 step:3864 [D loss: 0.677786, acc.: 53.91%] [G loss: 0.897306]\n",
      "epoch:4 step:3865 [D loss: 0.684671, acc.: 60.94%] [G loss: 0.881341]\n",
      "epoch:4 step:3866 [D loss: 0.673330, acc.: 55.47%] [G loss: 0.882132]\n",
      "epoch:4 step:3867 [D loss: 0.678075, acc.: 59.38%] [G loss: 0.856867]\n",
      "epoch:4 step:3868 [D loss: 0.701429, acc.: 53.12%] [G loss: 0.881345]\n",
      "epoch:4 step:3869 [D loss: 0.627205, acc.: 64.06%] [G loss: 0.882507]\n",
      "epoch:4 step:3870 [D loss: 0.652829, acc.: 54.69%] [G loss: 0.882471]\n",
      "epoch:4 step:3871 [D loss: 0.684806, acc.: 55.47%] [G loss: 0.883963]\n",
      "epoch:4 step:3872 [D loss: 0.636650, acc.: 64.06%] [G loss: 0.920271]\n",
      "epoch:4 step:3873 [D loss: 0.664559, acc.: 62.50%] [G loss: 0.891885]\n",
      "epoch:4 step:3874 [D loss: 0.632834, acc.: 67.97%] [G loss: 0.896042]\n",
      "epoch:4 step:3875 [D loss: 0.655938, acc.: 63.28%] [G loss: 0.848362]\n",
      "epoch:4 step:3876 [D loss: 0.675400, acc.: 54.69%] [G loss: 0.900973]\n",
      "epoch:4 step:3877 [D loss: 0.656592, acc.: 66.41%] [G loss: 0.897694]\n",
      "epoch:4 step:3878 [D loss: 0.647947, acc.: 64.06%] [G loss: 0.881986]\n",
      "epoch:4 step:3879 [D loss: 0.625223, acc.: 69.53%] [G loss: 0.814541]\n",
      "epoch:4 step:3880 [D loss: 0.667453, acc.: 57.81%] [G loss: 0.865324]\n",
      "epoch:4 step:3881 [D loss: 0.675690, acc.: 61.72%] [G loss: 0.848595]\n",
      "epoch:4 step:3882 [D loss: 0.657189, acc.: 57.03%] [G loss: 0.845748]\n",
      "epoch:4 step:3883 [D loss: 0.656875, acc.: 61.72%] [G loss: 0.861346]\n",
      "epoch:4 step:3884 [D loss: 0.687744, acc.: 53.12%] [G loss: 0.841603]\n",
      "epoch:4 step:3885 [D loss: 0.638838, acc.: 64.84%] [G loss: 0.824863]\n",
      "epoch:4 step:3886 [D loss: 0.652915, acc.: 64.06%] [G loss: 0.809056]\n",
      "epoch:4 step:3887 [D loss: 0.667850, acc.: 58.59%] [G loss: 0.839802]\n",
      "epoch:4 step:3888 [D loss: 0.703482, acc.: 58.59%] [G loss: 0.841478]\n",
      "epoch:4 step:3889 [D loss: 0.687994, acc.: 53.91%] [G loss: 0.809205]\n",
      "epoch:4 step:3890 [D loss: 0.641250, acc.: 60.16%] [G loss: 0.822983]\n",
      "epoch:4 step:3891 [D loss: 0.643005, acc.: 66.41%] [G loss: 0.863484]\n",
      "epoch:4 step:3892 [D loss: 0.663000, acc.: 59.38%] [G loss: 0.843494]\n",
      "epoch:4 step:3893 [D loss: 0.709654, acc.: 53.91%] [G loss: 0.866285]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:3894 [D loss: 0.640960, acc.: 63.28%] [G loss: 0.851239]\n",
      "epoch:4 step:3895 [D loss: 0.712236, acc.: 46.09%] [G loss: 0.882454]\n",
      "epoch:4 step:3896 [D loss: 0.676963, acc.: 53.91%] [G loss: 0.875621]\n",
      "epoch:4 step:3897 [D loss: 0.678858, acc.: 55.47%] [G loss: 0.837789]\n",
      "epoch:4 step:3898 [D loss: 0.673005, acc.: 53.91%] [G loss: 0.898468]\n",
      "epoch:4 step:3899 [D loss: 0.686533, acc.: 54.69%] [G loss: 0.895193]\n",
      "epoch:4 step:3900 [D loss: 0.664713, acc.: 65.62%] [G loss: 0.806333]\n",
      "epoch:4 step:3901 [D loss: 0.630896, acc.: 66.41%] [G loss: 0.836386]\n",
      "epoch:4 step:3902 [D loss: 0.675757, acc.: 52.34%] [G loss: 0.832494]\n",
      "epoch:4 step:3903 [D loss: 0.663120, acc.: 57.03%] [G loss: 0.892262]\n",
      "epoch:4 step:3904 [D loss: 0.662145, acc.: 58.59%] [G loss: 0.886423]\n",
      "epoch:4 step:3905 [D loss: 0.685617, acc.: 52.34%] [G loss: 0.894676]\n",
      "epoch:4 step:3906 [D loss: 0.640260, acc.: 65.62%] [G loss: 0.910056]\n",
      "epoch:4 step:3907 [D loss: 0.646988, acc.: 64.06%] [G loss: 0.878630]\n",
      "epoch:4 step:3908 [D loss: 0.666649, acc.: 55.47%] [G loss: 0.912831]\n",
      "epoch:4 step:3909 [D loss: 0.672952, acc.: 57.81%] [G loss: 0.892236]\n",
      "epoch:4 step:3910 [D loss: 0.651561, acc.: 60.16%] [G loss: 0.860250]\n",
      "epoch:4 step:3911 [D loss: 0.659462, acc.: 63.28%] [G loss: 0.820581]\n",
      "epoch:4 step:3912 [D loss: 0.696555, acc.: 50.78%] [G loss: 0.831546]\n",
      "epoch:4 step:3913 [D loss: 0.653745, acc.: 60.16%] [G loss: 0.827861]\n",
      "epoch:4 step:3914 [D loss: 0.652055, acc.: 61.72%] [G loss: 0.844182]\n",
      "epoch:4 step:3915 [D loss: 0.663308, acc.: 58.59%] [G loss: 0.803927]\n",
      "epoch:4 step:3916 [D loss: 0.668584, acc.: 56.25%] [G loss: 0.833674]\n",
      "epoch:4 step:3917 [D loss: 0.704431, acc.: 45.31%] [G loss: 0.811678]\n",
      "epoch:4 step:3918 [D loss: 0.685246, acc.: 57.81%] [G loss: 0.860735]\n",
      "epoch:4 step:3919 [D loss: 0.663566, acc.: 55.47%] [G loss: 0.840063]\n",
      "epoch:4 step:3920 [D loss: 0.679914, acc.: 52.34%] [G loss: 0.825633]\n",
      "epoch:4 step:3921 [D loss: 0.670519, acc.: 59.38%] [G loss: 0.855069]\n",
      "epoch:4 step:3922 [D loss: 0.631841, acc.: 65.62%] [G loss: 0.808099]\n",
      "epoch:4 step:3923 [D loss: 0.669667, acc.: 57.81%] [G loss: 0.863583]\n",
      "epoch:4 step:3924 [D loss: 0.636496, acc.: 67.19%] [G loss: 0.804850]\n",
      "epoch:4 step:3925 [D loss: 0.631814, acc.: 67.97%] [G loss: 0.886118]\n",
      "epoch:4 step:3926 [D loss: 0.670485, acc.: 61.72%] [G loss: 0.937706]\n",
      "epoch:4 step:3927 [D loss: 0.673076, acc.: 58.59%] [G loss: 0.906719]\n",
      "epoch:4 step:3928 [D loss: 0.659721, acc.: 62.50%] [G loss: 0.862770]\n",
      "epoch:4 step:3929 [D loss: 0.663013, acc.: 63.28%] [G loss: 0.868254]\n",
      "epoch:4 step:3930 [D loss: 0.652262, acc.: 64.06%] [G loss: 0.898062]\n",
      "epoch:4 step:3931 [D loss: 0.646490, acc.: 66.41%] [G loss: 0.897869]\n",
      "epoch:4 step:3932 [D loss: 0.663404, acc.: 65.62%] [G loss: 0.843278]\n",
      "epoch:4 step:3933 [D loss: 0.695833, acc.: 49.22%] [G loss: 0.822861]\n",
      "epoch:4 step:3934 [D loss: 0.679458, acc.: 53.91%] [G loss: 0.866267]\n",
      "epoch:4 step:3935 [D loss: 0.656704, acc.: 57.03%] [G loss: 0.802739]\n",
      "epoch:4 step:3936 [D loss: 0.652348, acc.: 60.16%] [G loss: 0.845676]\n",
      "epoch:4 step:3937 [D loss: 0.661554, acc.: 53.91%] [G loss: 0.849961]\n",
      "epoch:4 step:3938 [D loss: 0.659023, acc.: 60.94%] [G loss: 0.812744]\n",
      "epoch:4 step:3939 [D loss: 0.662315, acc.: 58.59%] [G loss: 0.877441]\n",
      "epoch:4 step:3940 [D loss: 0.665691, acc.: 55.47%] [G loss: 0.827334]\n",
      "epoch:4 step:3941 [D loss: 0.644164, acc.: 60.94%] [G loss: 0.852393]\n",
      "epoch:4 step:3942 [D loss: 0.657906, acc.: 60.94%] [G loss: 0.842653]\n",
      "epoch:4 step:3943 [D loss: 0.652286, acc.: 59.38%] [G loss: 0.813011]\n",
      "epoch:4 step:3944 [D loss: 0.651152, acc.: 63.28%] [G loss: 0.839883]\n",
      "epoch:4 step:3945 [D loss: 0.659771, acc.: 60.94%] [G loss: 0.801580]\n",
      "epoch:4 step:3946 [D loss: 0.642397, acc.: 60.94%] [G loss: 0.888755]\n",
      "epoch:4 step:3947 [D loss: 0.629956, acc.: 67.97%] [G loss: 0.873418]\n",
      "epoch:4 step:3948 [D loss: 0.661764, acc.: 52.34%] [G loss: 0.851061]\n",
      "epoch:4 step:3949 [D loss: 0.615394, acc.: 71.88%] [G loss: 0.858197]\n",
      "epoch:4 step:3950 [D loss: 0.639094, acc.: 60.16%] [G loss: 0.860719]\n",
      "epoch:4 step:3951 [D loss: 0.633415, acc.: 66.41%] [G loss: 0.920737]\n",
      "epoch:4 step:3952 [D loss: 0.649296, acc.: 64.06%] [G loss: 0.878663]\n",
      "epoch:4 step:3953 [D loss: 0.666175, acc.: 64.06%] [G loss: 0.904008]\n",
      "epoch:4 step:3954 [D loss: 0.665433, acc.: 59.38%] [G loss: 0.898873]\n",
      "epoch:4 step:3955 [D loss: 0.671403, acc.: 58.59%] [G loss: 0.881056]\n",
      "epoch:4 step:3956 [D loss: 0.625782, acc.: 64.06%] [G loss: 0.833829]\n",
      "epoch:4 step:3957 [D loss: 0.693079, acc.: 54.69%] [G loss: 0.889596]\n",
      "epoch:4 step:3958 [D loss: 0.661648, acc.: 58.59%] [G loss: 0.966044]\n",
      "epoch:4 step:3959 [D loss: 0.648768, acc.: 64.06%] [G loss: 0.947637]\n",
      "epoch:4 step:3960 [D loss: 0.654717, acc.: 63.28%] [G loss: 0.951705]\n",
      "epoch:4 step:3961 [D loss: 0.655048, acc.: 61.72%] [G loss: 0.928714]\n",
      "epoch:4 step:3962 [D loss: 0.678697, acc.: 52.34%] [G loss: 0.881721]\n",
      "epoch:4 step:3963 [D loss: 0.669516, acc.: 59.38%] [G loss: 0.911590]\n",
      "epoch:4 step:3964 [D loss: 0.623217, acc.: 67.97%] [G loss: 0.862235]\n",
      "epoch:4 step:3965 [D loss: 0.651374, acc.: 60.94%] [G loss: 0.861997]\n",
      "epoch:4 step:3966 [D loss: 0.658446, acc.: 57.81%] [G loss: 0.906925]\n",
      "epoch:4 step:3967 [D loss: 0.705644, acc.: 53.91%] [G loss: 0.891144]\n",
      "epoch:4 step:3968 [D loss: 0.650792, acc.: 64.84%] [G loss: 0.854047]\n",
      "epoch:4 step:3969 [D loss: 0.651433, acc.: 66.41%] [G loss: 0.842615]\n",
      "epoch:4 step:3970 [D loss: 0.669410, acc.: 59.38%] [G loss: 0.825499]\n",
      "epoch:4 step:3971 [D loss: 0.651346, acc.: 64.06%] [G loss: 0.863704]\n",
      "epoch:4 step:3972 [D loss: 0.667715, acc.: 58.59%] [G loss: 0.860096]\n",
      "epoch:4 step:3973 [D loss: 0.639499, acc.: 67.19%] [G loss: 0.855533]\n",
      "epoch:4 step:3974 [D loss: 0.652715, acc.: 60.94%] [G loss: 0.891445]\n",
      "epoch:4 step:3975 [D loss: 0.648438, acc.: 55.47%] [G loss: 0.904035]\n",
      "epoch:4 step:3976 [D loss: 0.645729, acc.: 60.94%] [G loss: 0.844876]\n",
      "epoch:4 step:3977 [D loss: 0.653996, acc.: 61.72%] [G loss: 0.871410]\n",
      "epoch:4 step:3978 [D loss: 0.661214, acc.: 58.59%] [G loss: 0.830092]\n",
      "epoch:4 step:3979 [D loss: 0.671441, acc.: 57.81%] [G loss: 0.878009]\n",
      "epoch:4 step:3980 [D loss: 0.669243, acc.: 55.47%] [G loss: 0.880566]\n",
      "epoch:4 step:3981 [D loss: 0.660663, acc.: 61.72%] [G loss: 0.923736]\n",
      "epoch:4 step:3982 [D loss: 0.669480, acc.: 60.16%] [G loss: 0.907882]\n",
      "epoch:4 step:3983 [D loss: 0.662049, acc.: 59.38%] [G loss: 0.887561]\n",
      "epoch:4 step:3984 [D loss: 0.656027, acc.: 54.69%] [G loss: 0.872822]\n",
      "epoch:4 step:3985 [D loss: 0.681859, acc.: 50.78%] [G loss: 0.861074]\n",
      "epoch:4 step:3986 [D loss: 0.612391, acc.: 71.88%] [G loss: 0.878140]\n",
      "epoch:4 step:3987 [D loss: 0.681638, acc.: 60.94%] [G loss: 0.872147]\n",
      "epoch:4 step:3988 [D loss: 0.668863, acc.: 55.47%] [G loss: 0.848943]\n",
      "epoch:4 step:3989 [D loss: 0.631672, acc.: 67.97%] [G loss: 0.839664]\n",
      "epoch:4 step:3990 [D loss: 0.642672, acc.: 64.06%] [G loss: 0.877283]\n",
      "epoch:4 step:3991 [D loss: 0.648935, acc.: 64.84%] [G loss: 0.857710]\n",
      "epoch:4 step:3992 [D loss: 0.653834, acc.: 63.28%] [G loss: 0.842626]\n",
      "epoch:4 step:3993 [D loss: 0.658182, acc.: 59.38%] [G loss: 0.817635]\n",
      "epoch:4 step:3994 [D loss: 0.663963, acc.: 63.28%] [G loss: 0.885639]\n",
      "epoch:4 step:3995 [D loss: 0.664845, acc.: 56.25%] [G loss: 0.853191]\n",
      "epoch:4 step:3996 [D loss: 0.635674, acc.: 67.97%] [G loss: 0.876751]\n",
      "epoch:4 step:3997 [D loss: 0.655644, acc.: 62.50%] [G loss: 0.866672]\n",
      "epoch:4 step:3998 [D loss: 0.660845, acc.: 64.06%] [G loss: 0.902687]\n",
      "epoch:4 step:3999 [D loss: 0.641039, acc.: 66.41%] [G loss: 0.863385]\n",
      "epoch:4 step:4000 [D loss: 0.658786, acc.: 64.06%] [G loss: 0.849598]\n",
      "##############\n",
      "[3.18944401 2.66971858 2.90802204 4.10769349 1.91114988 8.29119544\n",
      " 3.46658136 4.29128633 4.3363179  6.36403813]\n",
      "##########\n",
      "epoch:4 step:4001 [D loss: 0.646138, acc.: 64.84%] [G loss: 0.871722]\n",
      "epoch:4 step:4002 [D loss: 0.696981, acc.: 55.47%] [G loss: 0.864680]\n",
      "epoch:4 step:4003 [D loss: 0.646232, acc.: 67.19%] [G loss: 0.879947]\n",
      "epoch:4 step:4004 [D loss: 0.626401, acc.: 71.88%] [G loss: 0.864001]\n",
      "epoch:4 step:4005 [D loss: 0.650701, acc.: 62.50%] [G loss: 0.864018]\n",
      "epoch:4 step:4006 [D loss: 0.677782, acc.: 57.81%] [G loss: 0.852207]\n",
      "epoch:4 step:4007 [D loss: 0.664038, acc.: 50.78%] [G loss: 0.834772]\n",
      "epoch:4 step:4008 [D loss: 0.636703, acc.: 60.16%] [G loss: 0.918860]\n",
      "epoch:4 step:4009 [D loss: 0.661281, acc.: 57.81%] [G loss: 0.889120]\n",
      "epoch:4 step:4010 [D loss: 0.674497, acc.: 58.59%] [G loss: 0.861935]\n",
      "epoch:4 step:4011 [D loss: 0.652999, acc.: 61.72%] [G loss: 0.849524]\n",
      "epoch:4 step:4012 [D loss: 0.655796, acc.: 59.38%] [G loss: 0.858695]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4013 [D loss: 0.632433, acc.: 61.72%] [G loss: 0.841815]\n",
      "epoch:4 step:4014 [D loss: 0.698098, acc.: 55.47%] [G loss: 0.821323]\n",
      "epoch:4 step:4015 [D loss: 0.695621, acc.: 50.00%] [G loss: 0.843961]\n",
      "epoch:4 step:4016 [D loss: 0.660020, acc.: 55.47%] [G loss: 0.855509]\n",
      "epoch:4 step:4017 [D loss: 0.637340, acc.: 67.97%] [G loss: 0.859436]\n",
      "epoch:4 step:4018 [D loss: 0.662803, acc.: 53.91%] [G loss: 0.870792]\n",
      "epoch:4 step:4019 [D loss: 0.629840, acc.: 60.94%] [G loss: 0.867949]\n",
      "epoch:4 step:4020 [D loss: 0.670027, acc.: 56.25%] [G loss: 0.870022]\n",
      "epoch:4 step:4021 [D loss: 0.654325, acc.: 61.72%] [G loss: 0.845730]\n",
      "epoch:4 step:4022 [D loss: 0.647280, acc.: 64.06%] [G loss: 0.823086]\n",
      "epoch:4 step:4023 [D loss: 0.692974, acc.: 53.12%] [G loss: 0.848461]\n",
      "epoch:4 step:4024 [D loss: 0.696123, acc.: 51.56%] [G loss: 0.856908]\n",
      "epoch:4 step:4025 [D loss: 0.648716, acc.: 60.16%] [G loss: 0.856370]\n",
      "epoch:4 step:4026 [D loss: 0.676445, acc.: 57.03%] [G loss: 0.872419]\n",
      "epoch:4 step:4027 [D loss: 0.676860, acc.: 60.94%] [G loss: 0.841708]\n",
      "epoch:4 step:4028 [D loss: 0.675511, acc.: 50.00%] [G loss: 0.802974]\n",
      "epoch:4 step:4029 [D loss: 0.677163, acc.: 53.91%] [G loss: 0.857385]\n",
      "epoch:4 step:4030 [D loss: 0.662210, acc.: 53.12%] [G loss: 0.890710]\n",
      "epoch:4 step:4031 [D loss: 0.656657, acc.: 57.03%] [G loss: 0.846199]\n",
      "epoch:4 step:4032 [D loss: 0.651774, acc.: 62.50%] [G loss: 0.885317]\n",
      "epoch:4 step:4033 [D loss: 0.663009, acc.: 57.03%] [G loss: 0.896489]\n",
      "epoch:4 step:4034 [D loss: 0.710353, acc.: 50.78%] [G loss: 0.907555]\n",
      "epoch:4 step:4035 [D loss: 0.664020, acc.: 63.28%] [G loss: 0.877791]\n",
      "epoch:4 step:4036 [D loss: 0.655607, acc.: 55.47%] [G loss: 0.907219]\n",
      "epoch:4 step:4037 [D loss: 0.678552, acc.: 57.81%] [G loss: 0.844643]\n",
      "epoch:4 step:4038 [D loss: 0.617732, acc.: 68.75%] [G loss: 0.874155]\n",
      "epoch:4 step:4039 [D loss: 0.665340, acc.: 53.91%] [G loss: 0.811866]\n",
      "epoch:4 step:4040 [D loss: 0.611475, acc.: 67.97%] [G loss: 0.831095]\n",
      "epoch:4 step:4041 [D loss: 0.672022, acc.: 53.12%] [G loss: 0.858655]\n",
      "epoch:4 step:4042 [D loss: 0.641787, acc.: 57.81%] [G loss: 0.875809]\n",
      "epoch:4 step:4043 [D loss: 0.654113, acc.: 64.84%] [G loss: 0.836264]\n",
      "epoch:4 step:4044 [D loss: 0.647760, acc.: 65.62%] [G loss: 0.862810]\n",
      "epoch:4 step:4045 [D loss: 0.667995, acc.: 56.25%] [G loss: 0.878565]\n",
      "epoch:4 step:4046 [D loss: 0.667875, acc.: 54.69%] [G loss: 0.922666]\n",
      "epoch:4 step:4047 [D loss: 0.702548, acc.: 54.69%] [G loss: 0.873938]\n",
      "epoch:4 step:4048 [D loss: 0.629551, acc.: 63.28%] [G loss: 0.885062]\n",
      "epoch:4 step:4049 [D loss: 0.669576, acc.: 57.03%] [G loss: 0.879998]\n",
      "epoch:4 step:4050 [D loss: 0.656048, acc.: 64.06%] [G loss: 0.857020]\n",
      "epoch:4 step:4051 [D loss: 0.655622, acc.: 62.50%] [G loss: 0.835020]\n",
      "epoch:4 step:4052 [D loss: 0.660554, acc.: 59.38%] [G loss: 0.858424]\n",
      "epoch:4 step:4053 [D loss: 0.700274, acc.: 53.91%] [G loss: 0.820678]\n",
      "epoch:4 step:4054 [D loss: 0.640093, acc.: 63.28%] [G loss: 0.820420]\n",
      "epoch:4 step:4055 [D loss: 0.631733, acc.: 68.75%] [G loss: 0.866008]\n",
      "epoch:4 step:4056 [D loss: 0.644576, acc.: 64.06%] [G loss: 0.839530]\n",
      "epoch:4 step:4057 [D loss: 0.621169, acc.: 65.62%] [G loss: 0.859124]\n",
      "epoch:4 step:4058 [D loss: 0.676045, acc.: 58.59%] [G loss: 0.852908]\n",
      "epoch:4 step:4059 [D loss: 0.629904, acc.: 63.28%] [G loss: 0.865000]\n",
      "epoch:4 step:4060 [D loss: 0.700018, acc.: 53.91%] [G loss: 0.827632]\n",
      "epoch:4 step:4061 [D loss: 0.686006, acc.: 58.59%] [G loss: 0.826404]\n",
      "epoch:4 step:4062 [D loss: 0.646590, acc.: 60.16%] [G loss: 0.782198]\n",
      "epoch:4 step:4063 [D loss: 0.634837, acc.: 67.19%] [G loss: 0.840899]\n",
      "epoch:4 step:4064 [D loss: 0.655531, acc.: 57.03%] [G loss: 0.824132]\n",
      "epoch:4 step:4065 [D loss: 0.669806, acc.: 65.62%] [G loss: 0.854866]\n",
      "epoch:4 step:4066 [D loss: 0.693515, acc.: 51.56%] [G loss: 0.850623]\n",
      "epoch:4 step:4067 [D loss: 0.696370, acc.: 50.78%] [G loss: 0.879968]\n",
      "epoch:4 step:4068 [D loss: 0.671962, acc.: 62.50%] [G loss: 0.903397]\n",
      "epoch:4 step:4069 [D loss: 0.663581, acc.: 60.16%] [G loss: 0.849436]\n",
      "epoch:4 step:4070 [D loss: 0.676317, acc.: 56.25%] [G loss: 0.869790]\n",
      "epoch:4 step:4071 [D loss: 0.654376, acc.: 66.41%] [G loss: 0.855742]\n",
      "epoch:4 step:4072 [D loss: 0.642136, acc.: 60.16%] [G loss: 0.855402]\n",
      "epoch:4 step:4073 [D loss: 0.656316, acc.: 62.50%] [G loss: 0.850785]\n",
      "epoch:4 step:4074 [D loss: 0.649037, acc.: 58.59%] [G loss: 0.832008]\n",
      "epoch:4 step:4075 [D loss: 0.622667, acc.: 64.06%] [G loss: 0.854784]\n",
      "epoch:4 step:4076 [D loss: 0.619128, acc.: 68.75%] [G loss: 0.855588]\n",
      "epoch:4 step:4077 [D loss: 0.650441, acc.: 64.84%] [G loss: 0.853899]\n",
      "epoch:4 step:4078 [D loss: 0.633494, acc.: 69.53%] [G loss: 0.854782]\n",
      "epoch:4 step:4079 [D loss: 0.652420, acc.: 58.59%] [G loss: 0.871543]\n",
      "epoch:4 step:4080 [D loss: 0.619571, acc.: 71.88%] [G loss: 0.859569]\n",
      "epoch:4 step:4081 [D loss: 0.712635, acc.: 53.91%] [G loss: 0.912747]\n",
      "epoch:4 step:4082 [D loss: 0.657703, acc.: 63.28%] [G loss: 0.887036]\n",
      "epoch:4 step:4083 [D loss: 0.644081, acc.: 67.97%] [G loss: 0.834079]\n",
      "epoch:4 step:4084 [D loss: 0.657269, acc.: 57.81%] [G loss: 0.891105]\n",
      "epoch:4 step:4085 [D loss: 0.670274, acc.: 58.59%] [G loss: 0.864628]\n",
      "epoch:4 step:4086 [D loss: 0.632781, acc.: 65.62%] [G loss: 0.873920]\n",
      "epoch:4 step:4087 [D loss: 0.647876, acc.: 60.94%] [G loss: 0.855654]\n",
      "epoch:4 step:4088 [D loss: 0.657158, acc.: 58.59%] [G loss: 0.871360]\n",
      "epoch:4 step:4089 [D loss: 0.663114, acc.: 59.38%] [G loss: 0.851246]\n",
      "epoch:4 step:4090 [D loss: 0.654150, acc.: 60.94%] [G loss: 0.858149]\n",
      "epoch:4 step:4091 [D loss: 0.702565, acc.: 48.44%] [G loss: 0.842225]\n",
      "epoch:4 step:4092 [D loss: 0.655452, acc.: 60.16%] [G loss: 0.840205]\n",
      "epoch:4 step:4093 [D loss: 0.638894, acc.: 67.19%] [G loss: 0.837114]\n",
      "epoch:4 step:4094 [D loss: 0.678654, acc.: 51.56%] [G loss: 0.847118]\n",
      "epoch:4 step:4095 [D loss: 0.602062, acc.: 71.09%] [G loss: 0.845917]\n",
      "epoch:4 step:4096 [D loss: 0.659219, acc.: 60.16%] [G loss: 0.831825]\n",
      "epoch:4 step:4097 [D loss: 0.623840, acc.: 64.06%] [G loss: 0.812105]\n",
      "epoch:4 step:4098 [D loss: 0.700354, acc.: 49.22%] [G loss: 0.844055]\n",
      "epoch:4 step:4099 [D loss: 0.699027, acc.: 56.25%] [G loss: 0.821522]\n",
      "epoch:4 step:4100 [D loss: 0.686205, acc.: 56.25%] [G loss: 0.879652]\n",
      "epoch:4 step:4101 [D loss: 0.677382, acc.: 56.25%] [G loss: 0.885728]\n",
      "epoch:4 step:4102 [D loss: 0.687357, acc.: 54.69%] [G loss: 0.821545]\n",
      "epoch:4 step:4103 [D loss: 0.670253, acc.: 50.00%] [G loss: 0.844098]\n",
      "epoch:4 step:4104 [D loss: 0.651369, acc.: 63.28%] [G loss: 0.825840]\n",
      "epoch:4 step:4105 [D loss: 0.689219, acc.: 54.69%] [G loss: 0.871688]\n",
      "epoch:4 step:4106 [D loss: 0.633194, acc.: 68.75%] [G loss: 0.843347]\n",
      "epoch:4 step:4107 [D loss: 0.662657, acc.: 54.69%] [G loss: 0.875504]\n",
      "epoch:4 step:4108 [D loss: 0.640045, acc.: 59.38%] [G loss: 0.830487]\n",
      "epoch:4 step:4109 [D loss: 0.707188, acc.: 50.00%] [G loss: 0.886912]\n",
      "epoch:4 step:4110 [D loss: 0.672525, acc.: 51.56%] [G loss: 0.843397]\n",
      "epoch:4 step:4111 [D loss: 0.651869, acc.: 56.25%] [G loss: 0.848339]\n",
      "epoch:4 step:4112 [D loss: 0.660424, acc.: 60.94%] [G loss: 0.859187]\n",
      "epoch:4 step:4113 [D loss: 0.657385, acc.: 60.94%] [G loss: 0.899624]\n",
      "epoch:4 step:4114 [D loss: 0.649089, acc.: 57.81%] [G loss: 0.875554]\n",
      "epoch:4 step:4115 [D loss: 0.711645, acc.: 54.69%] [G loss: 0.895630]\n",
      "epoch:4 step:4116 [D loss: 0.699810, acc.: 48.44%] [G loss: 0.874103]\n",
      "epoch:4 step:4117 [D loss: 0.685054, acc.: 62.50%] [G loss: 0.877254]\n",
      "epoch:4 step:4118 [D loss: 0.683089, acc.: 56.25%] [G loss: 0.848587]\n",
      "epoch:4 step:4119 [D loss: 0.687739, acc.: 46.88%] [G loss: 0.845450]\n",
      "epoch:4 step:4120 [D loss: 0.655711, acc.: 61.72%] [G loss: 0.880775]\n",
      "epoch:4 step:4121 [D loss: 0.672906, acc.: 57.03%] [G loss: 0.884772]\n",
      "epoch:4 step:4122 [D loss: 0.648409, acc.: 61.72%] [G loss: 0.866534]\n",
      "epoch:4 step:4123 [D loss: 0.689830, acc.: 57.81%] [G loss: 0.827411]\n",
      "epoch:4 step:4124 [D loss: 0.666685, acc.: 57.03%] [G loss: 0.861603]\n",
      "epoch:4 step:4125 [D loss: 0.648231, acc.: 58.59%] [G loss: 0.832326]\n",
      "epoch:4 step:4126 [D loss: 0.630698, acc.: 66.41%] [G loss: 0.861423]\n",
      "epoch:4 step:4127 [D loss: 0.642944, acc.: 57.03%] [G loss: 0.860226]\n",
      "epoch:4 step:4128 [D loss: 0.668429, acc.: 59.38%] [G loss: 0.799974]\n",
      "epoch:4 step:4129 [D loss: 0.650397, acc.: 65.62%] [G loss: 0.830218]\n",
      "epoch:4 step:4130 [D loss: 0.637762, acc.: 62.50%] [G loss: 0.836814]\n",
      "epoch:4 step:4131 [D loss: 0.647041, acc.: 62.50%] [G loss: 0.844128]\n",
      "epoch:4 step:4132 [D loss: 0.692173, acc.: 52.34%] [G loss: 0.873299]\n",
      "epoch:4 step:4133 [D loss: 0.651639, acc.: 61.72%] [G loss: 0.882001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4134 [D loss: 0.680764, acc.: 59.38%] [G loss: 0.890830]\n",
      "epoch:4 step:4135 [D loss: 0.661813, acc.: 60.16%] [G loss: 0.888428]\n",
      "epoch:4 step:4136 [D loss: 0.677677, acc.: 60.16%] [G loss: 0.860339]\n",
      "epoch:4 step:4137 [D loss: 0.680052, acc.: 53.12%] [G loss: 0.895132]\n",
      "epoch:4 step:4138 [D loss: 0.662114, acc.: 57.81%] [G loss: 0.829278]\n",
      "epoch:4 step:4139 [D loss: 0.676599, acc.: 55.47%] [G loss: 0.867649]\n",
      "epoch:4 step:4140 [D loss: 0.666847, acc.: 54.69%] [G loss: 0.830651]\n",
      "epoch:4 step:4141 [D loss: 0.714886, acc.: 49.22%] [G loss: 0.824547]\n",
      "epoch:4 step:4142 [D loss: 0.679983, acc.: 53.12%] [G loss: 0.793259]\n",
      "epoch:4 step:4143 [D loss: 0.638157, acc.: 65.62%] [G loss: 0.856662]\n",
      "epoch:4 step:4144 [D loss: 0.698917, acc.: 53.91%] [G loss: 0.785783]\n",
      "epoch:4 step:4145 [D loss: 0.689069, acc.: 55.47%] [G loss: 0.842693]\n",
      "epoch:4 step:4146 [D loss: 0.673524, acc.: 57.03%] [G loss: 0.812066]\n",
      "epoch:4 step:4147 [D loss: 0.674088, acc.: 56.25%] [G loss: 0.860601]\n",
      "epoch:4 step:4148 [D loss: 0.665210, acc.: 57.03%] [G loss: 0.925923]\n",
      "epoch:4 step:4149 [D loss: 0.659413, acc.: 60.16%] [G loss: 0.931153]\n",
      "epoch:4 step:4150 [D loss: 0.610122, acc.: 71.09%] [G loss: 0.917864]\n",
      "epoch:4 step:4151 [D loss: 0.646414, acc.: 57.03%] [G loss: 0.837551]\n",
      "epoch:4 step:4152 [D loss: 0.670661, acc.: 55.47%] [G loss: 0.893274]\n",
      "epoch:4 step:4153 [D loss: 0.642796, acc.: 67.19%] [G loss: 0.870989]\n",
      "epoch:4 step:4154 [D loss: 0.646699, acc.: 63.28%] [G loss: 0.841843]\n",
      "epoch:4 step:4155 [D loss: 0.697216, acc.: 55.47%] [G loss: 0.855513]\n",
      "epoch:4 step:4156 [D loss: 0.620909, acc.: 64.06%] [G loss: 0.845548]\n",
      "epoch:4 step:4157 [D loss: 0.641076, acc.: 65.62%] [G loss: 0.843252]\n",
      "epoch:4 step:4158 [D loss: 0.672324, acc.: 59.38%] [G loss: 0.814554]\n",
      "epoch:4 step:4159 [D loss: 0.643589, acc.: 64.84%] [G loss: 0.830003]\n",
      "epoch:4 step:4160 [D loss: 0.669719, acc.: 60.16%] [G loss: 0.853660]\n",
      "epoch:4 step:4161 [D loss: 0.634894, acc.: 65.62%] [G loss: 0.848104]\n",
      "epoch:4 step:4162 [D loss: 0.648246, acc.: 59.38%] [G loss: 0.868004]\n",
      "epoch:4 step:4163 [D loss: 0.660204, acc.: 60.94%] [G loss: 0.833831]\n",
      "epoch:4 step:4164 [D loss: 0.636911, acc.: 63.28%] [G loss: 0.861466]\n",
      "epoch:4 step:4165 [D loss: 0.639725, acc.: 63.28%] [G loss: 0.893151]\n",
      "epoch:4 step:4166 [D loss: 0.711578, acc.: 53.91%] [G loss: 0.879844]\n",
      "epoch:4 step:4167 [D loss: 0.671103, acc.: 60.16%] [G loss: 0.857273]\n",
      "epoch:4 step:4168 [D loss: 0.623290, acc.: 66.41%] [G loss: 0.864755]\n",
      "epoch:4 step:4169 [D loss: 0.622416, acc.: 63.28%] [G loss: 0.876864]\n",
      "epoch:4 step:4170 [D loss: 0.644739, acc.: 62.50%] [G loss: 0.846457]\n",
      "epoch:4 step:4171 [D loss: 0.650411, acc.: 53.91%] [G loss: 0.840344]\n",
      "epoch:4 step:4172 [D loss: 0.667598, acc.: 57.03%] [G loss: 0.862205]\n",
      "epoch:4 step:4173 [D loss: 0.650771, acc.: 60.16%] [G loss: 0.898812]\n",
      "epoch:4 step:4174 [D loss: 0.647533, acc.: 61.72%] [G loss: 0.856551]\n",
      "epoch:4 step:4175 [D loss: 0.671602, acc.: 58.59%] [G loss: 0.866432]\n",
      "epoch:4 step:4176 [D loss: 0.620070, acc.: 67.19%] [G loss: 0.880336]\n",
      "epoch:4 step:4177 [D loss: 0.651621, acc.: 59.38%] [G loss: 0.832706]\n",
      "epoch:4 step:4178 [D loss: 0.692031, acc.: 49.22%] [G loss: 0.831424]\n",
      "epoch:4 step:4179 [D loss: 0.647935, acc.: 60.16%] [G loss: 0.880742]\n",
      "epoch:4 step:4180 [D loss: 0.639391, acc.: 63.28%] [G loss: 0.897457]\n",
      "epoch:4 step:4181 [D loss: 0.640194, acc.: 65.62%] [G loss: 0.884179]\n",
      "epoch:4 step:4182 [D loss: 0.660370, acc.: 66.41%] [G loss: 0.862851]\n",
      "epoch:4 step:4183 [D loss: 0.651283, acc.: 64.06%] [G loss: 0.840339]\n",
      "epoch:4 step:4184 [D loss: 0.624300, acc.: 68.75%] [G loss: 0.914367]\n",
      "epoch:4 step:4185 [D loss: 0.656337, acc.: 60.94%] [G loss: 0.867195]\n",
      "epoch:4 step:4186 [D loss: 0.656932, acc.: 63.28%] [G loss: 0.876133]\n",
      "epoch:4 step:4187 [D loss: 0.655253, acc.: 61.72%] [G loss: 0.850249]\n",
      "epoch:4 step:4188 [D loss: 0.674472, acc.: 60.16%] [G loss: 0.899863]\n",
      "epoch:4 step:4189 [D loss: 0.650898, acc.: 64.06%] [G loss: 0.857770]\n",
      "epoch:4 step:4190 [D loss: 0.683685, acc.: 57.03%] [G loss: 0.873325]\n",
      "epoch:4 step:4191 [D loss: 0.638852, acc.: 61.72%] [G loss: 0.830877]\n",
      "epoch:4 step:4192 [D loss: 0.667074, acc.: 56.25%] [G loss: 0.883934]\n",
      "epoch:4 step:4193 [D loss: 0.641614, acc.: 59.38%] [G loss: 0.906503]\n",
      "epoch:4 step:4194 [D loss: 0.677654, acc.: 48.44%] [G loss: 0.897565]\n",
      "epoch:4 step:4195 [D loss: 0.619951, acc.: 71.88%] [G loss: 0.874995]\n",
      "epoch:4 step:4196 [D loss: 0.684092, acc.: 53.12%] [G loss: 0.846394]\n",
      "epoch:4 step:4197 [D loss: 0.638883, acc.: 67.19%] [G loss: 0.881894]\n",
      "epoch:4 step:4198 [D loss: 0.643668, acc.: 60.16%] [G loss: 0.843206]\n",
      "epoch:4 step:4199 [D loss: 0.680566, acc.: 54.69%] [G loss: 0.826795]\n",
      "epoch:4 step:4200 [D loss: 0.665204, acc.: 58.59%] [G loss: 0.851034]\n",
      "##############\n",
      "[3.11872543 3.13088573 2.75354925 4.03722337 1.5581723  8.52117538\n",
      " 3.30614407 4.37005152 4.50508249 6.41825545]\n",
      "##########\n",
      "epoch:4 step:4201 [D loss: 0.632403, acc.: 64.84%] [G loss: 0.855954]\n",
      "epoch:4 step:4202 [D loss: 0.654370, acc.: 60.16%] [G loss: 0.876815]\n",
      "epoch:4 step:4203 [D loss: 0.662681, acc.: 61.72%] [G loss: 0.832823]\n",
      "epoch:4 step:4204 [D loss: 0.658914, acc.: 57.03%] [G loss: 0.859877]\n",
      "epoch:4 step:4205 [D loss: 0.640311, acc.: 64.84%] [G loss: 0.887759]\n",
      "epoch:4 step:4206 [D loss: 0.620609, acc.: 61.72%] [G loss: 0.859802]\n",
      "epoch:4 step:4207 [D loss: 0.622684, acc.: 64.06%] [G loss: 0.883394]\n",
      "epoch:4 step:4208 [D loss: 0.661373, acc.: 58.59%] [G loss: 0.891227]\n",
      "epoch:4 step:4209 [D loss: 0.681959, acc.: 56.25%] [G loss: 0.881277]\n",
      "epoch:4 step:4210 [D loss: 0.631287, acc.: 65.62%] [G loss: 0.916027]\n",
      "epoch:4 step:4211 [D loss: 0.648258, acc.: 65.62%] [G loss: 0.910514]\n",
      "epoch:4 step:4212 [D loss: 0.636174, acc.: 60.16%] [G loss: 0.854969]\n",
      "epoch:4 step:4213 [D loss: 0.652130, acc.: 60.16%] [G loss: 0.895068]\n",
      "epoch:4 step:4214 [D loss: 0.667276, acc.: 60.94%] [G loss: 0.878909]\n",
      "epoch:4 step:4215 [D loss: 0.664570, acc.: 62.50%] [G loss: 0.898592]\n",
      "epoch:4 step:4216 [D loss: 0.647547, acc.: 64.06%] [G loss: 0.887512]\n",
      "epoch:4 step:4217 [D loss: 0.656537, acc.: 60.16%] [G loss: 0.930598]\n",
      "epoch:4 step:4218 [D loss: 0.684096, acc.: 50.00%] [G loss: 0.844756]\n",
      "epoch:4 step:4219 [D loss: 0.647983, acc.: 62.50%] [G loss: 0.880581]\n",
      "epoch:4 step:4220 [D loss: 0.648379, acc.: 61.72%] [G loss: 0.840533]\n",
      "epoch:4 step:4221 [D loss: 0.657792, acc.: 61.72%] [G loss: 0.930451]\n",
      "epoch:4 step:4222 [D loss: 0.626698, acc.: 68.75%] [G loss: 0.920082]\n",
      "epoch:4 step:4223 [D loss: 0.648084, acc.: 64.84%] [G loss: 0.910587]\n",
      "epoch:4 step:4224 [D loss: 0.673289, acc.: 58.59%] [G loss: 0.904915]\n",
      "epoch:4 step:4225 [D loss: 0.649364, acc.: 63.28%] [G loss: 0.876952]\n",
      "epoch:4 step:4226 [D loss: 0.679424, acc.: 57.03%] [G loss: 0.845988]\n",
      "epoch:4 step:4227 [D loss: 0.640501, acc.: 64.06%] [G loss: 0.892026]\n",
      "epoch:4 step:4228 [D loss: 0.680964, acc.: 57.03%] [G loss: 0.800991]\n",
      "epoch:4 step:4229 [D loss: 0.646013, acc.: 60.94%] [G loss: 0.872093]\n",
      "epoch:4 step:4230 [D loss: 0.648288, acc.: 57.81%] [G loss: 0.873692]\n",
      "epoch:4 step:4231 [D loss: 0.719490, acc.: 48.44%] [G loss: 0.832195]\n",
      "epoch:4 step:4232 [D loss: 0.640352, acc.: 61.72%] [G loss: 0.852529]\n",
      "epoch:4 step:4233 [D loss: 0.683395, acc.: 60.16%] [G loss: 0.841206]\n",
      "epoch:4 step:4234 [D loss: 0.662550, acc.: 58.59%] [G loss: 0.826329]\n",
      "epoch:4 step:4235 [D loss: 0.654194, acc.: 61.72%] [G loss: 0.831187]\n",
      "epoch:4 step:4236 [D loss: 0.658963, acc.: 55.47%] [G loss: 0.807146]\n",
      "epoch:4 step:4237 [D loss: 0.691776, acc.: 57.03%] [G loss: 0.777286]\n",
      "epoch:4 step:4238 [D loss: 0.630945, acc.: 66.41%] [G loss: 0.810155]\n",
      "epoch:4 step:4239 [D loss: 0.629377, acc.: 66.41%] [G loss: 0.808148]\n",
      "epoch:4 step:4240 [D loss: 0.652921, acc.: 63.28%] [G loss: 0.847776]\n",
      "epoch:4 step:4241 [D loss: 0.643313, acc.: 63.28%] [G loss: 0.841166]\n",
      "epoch:4 step:4242 [D loss: 0.634428, acc.: 64.06%] [G loss: 0.877074]\n",
      "epoch:4 step:4243 [D loss: 0.658633, acc.: 63.28%] [G loss: 0.805928]\n",
      "epoch:4 step:4244 [D loss: 0.685831, acc.: 53.91%] [G loss: 0.857668]\n",
      "epoch:4 step:4245 [D loss: 0.626828, acc.: 60.16%] [G loss: 0.836433]\n",
      "epoch:4 step:4246 [D loss: 0.668360, acc.: 58.59%] [G loss: 0.891261]\n",
      "epoch:4 step:4247 [D loss: 0.656520, acc.: 55.47%] [G loss: 0.876935]\n",
      "epoch:4 step:4248 [D loss: 0.687174, acc.: 50.78%] [G loss: 0.845218]\n",
      "epoch:4 step:4249 [D loss: 0.670501, acc.: 56.25%] [G loss: 0.833816]\n",
      "epoch:4 step:4250 [D loss: 0.672426, acc.: 63.28%] [G loss: 0.830026]\n",
      "epoch:4 step:4251 [D loss: 0.650007, acc.: 57.03%] [G loss: 0.848532]\n",
      "epoch:4 step:4252 [D loss: 0.687508, acc.: 55.47%] [G loss: 0.901392]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4253 [D loss: 0.642657, acc.: 64.06%] [G loss: 0.882231]\n",
      "epoch:4 step:4254 [D loss: 0.641159, acc.: 67.19%] [G loss: 0.836935]\n",
      "epoch:4 step:4255 [D loss: 0.642598, acc.: 61.72%] [G loss: 0.879138]\n",
      "epoch:4 step:4256 [D loss: 0.654089, acc.: 61.72%] [G loss: 0.817860]\n",
      "epoch:4 step:4257 [D loss: 0.668665, acc.: 60.16%] [G loss: 0.867223]\n",
      "epoch:4 step:4258 [D loss: 0.625164, acc.: 67.19%] [G loss: 0.879119]\n",
      "epoch:4 step:4259 [D loss: 0.660153, acc.: 62.50%] [G loss: 0.867395]\n",
      "epoch:4 step:4260 [D loss: 0.675690, acc.: 54.69%] [G loss: 0.847254]\n",
      "epoch:4 step:4261 [D loss: 0.682141, acc.: 57.03%] [G loss: 0.886379]\n",
      "epoch:4 step:4262 [D loss: 0.668180, acc.: 56.25%] [G loss: 0.886079]\n",
      "epoch:4 step:4263 [D loss: 0.650208, acc.: 59.38%] [G loss: 0.857564]\n",
      "epoch:4 step:4264 [D loss: 0.644738, acc.: 62.50%] [G loss: 0.917649]\n",
      "epoch:4 step:4265 [D loss: 0.669493, acc.: 57.81%] [G loss: 0.850637]\n",
      "epoch:4 step:4266 [D loss: 0.642302, acc.: 61.72%] [G loss: 0.863235]\n",
      "epoch:4 step:4267 [D loss: 0.636590, acc.: 63.28%] [G loss: 0.874002]\n",
      "epoch:4 step:4268 [D loss: 0.684231, acc.: 56.25%] [G loss: 0.867168]\n",
      "epoch:4 step:4269 [D loss: 0.658356, acc.: 55.47%] [G loss: 0.849389]\n",
      "epoch:4 step:4270 [D loss: 0.629657, acc.: 67.19%] [G loss: 0.892888]\n",
      "epoch:4 step:4271 [D loss: 0.652577, acc.: 62.50%] [G loss: 0.919809]\n",
      "epoch:4 step:4272 [D loss: 0.637109, acc.: 63.28%] [G loss: 0.923603]\n",
      "epoch:4 step:4273 [D loss: 0.657623, acc.: 58.59%] [G loss: 0.878432]\n",
      "epoch:4 step:4274 [D loss: 0.679810, acc.: 60.94%] [G loss: 0.855467]\n",
      "epoch:4 step:4275 [D loss: 0.657112, acc.: 60.16%] [G loss: 0.900420]\n",
      "epoch:4 step:4276 [D loss: 0.651124, acc.: 60.94%] [G loss: 0.878430]\n",
      "epoch:4 step:4277 [D loss: 0.625250, acc.: 60.94%] [G loss: 0.886137]\n",
      "epoch:4 step:4278 [D loss: 0.644339, acc.: 60.94%] [G loss: 0.854495]\n",
      "epoch:4 step:4279 [D loss: 0.650867, acc.: 58.59%] [G loss: 0.864222]\n",
      "epoch:4 step:4280 [D loss: 0.653481, acc.: 58.59%] [G loss: 0.899896]\n",
      "epoch:4 step:4281 [D loss: 0.671726, acc.: 57.03%] [G loss: 0.896317]\n",
      "epoch:4 step:4282 [D loss: 0.634447, acc.: 68.75%] [G loss: 0.870809]\n",
      "epoch:4 step:4283 [D loss: 0.625869, acc.: 72.66%] [G loss: 0.900962]\n",
      "epoch:4 step:4284 [D loss: 0.640344, acc.: 60.16%] [G loss: 0.869591]\n",
      "epoch:4 step:4285 [D loss: 0.676038, acc.: 57.81%] [G loss: 0.875080]\n",
      "epoch:4 step:4286 [D loss: 0.665346, acc.: 58.59%] [G loss: 0.877721]\n",
      "epoch:4 step:4287 [D loss: 0.672017, acc.: 53.12%] [G loss: 0.861165]\n",
      "epoch:4 step:4288 [D loss: 0.639783, acc.: 61.72%] [G loss: 0.871970]\n",
      "epoch:4 step:4289 [D loss: 0.630243, acc.: 64.84%] [G loss: 0.918127]\n",
      "epoch:4 step:4290 [D loss: 0.642777, acc.: 61.72%] [G loss: 0.879347]\n",
      "epoch:4 step:4291 [D loss: 0.666584, acc.: 56.25%] [G loss: 0.837769]\n",
      "epoch:4 step:4292 [D loss: 0.637856, acc.: 58.59%] [G loss: 0.902456]\n",
      "epoch:4 step:4293 [D loss: 0.686973, acc.: 54.69%] [G loss: 0.879964]\n",
      "epoch:4 step:4294 [D loss: 0.648368, acc.: 60.94%] [G loss: 0.849546]\n",
      "epoch:4 step:4295 [D loss: 0.614948, acc.: 70.31%] [G loss: 0.900635]\n",
      "epoch:4 step:4296 [D loss: 0.646693, acc.: 58.59%] [G loss: 0.866824]\n",
      "epoch:4 step:4297 [D loss: 0.647664, acc.: 60.16%] [G loss: 0.847160]\n",
      "epoch:4 step:4298 [D loss: 0.628967, acc.: 60.94%] [G loss: 0.858212]\n",
      "epoch:4 step:4299 [D loss: 0.625474, acc.: 70.31%] [G loss: 0.890727]\n",
      "epoch:4 step:4300 [D loss: 0.633950, acc.: 64.06%] [G loss: 0.862223]\n",
      "epoch:4 step:4301 [D loss: 0.701933, acc.: 56.25%] [G loss: 0.848116]\n",
      "epoch:4 step:4302 [D loss: 0.621848, acc.: 68.75%] [G loss: 0.848393]\n",
      "epoch:4 step:4303 [D loss: 0.624488, acc.: 67.97%] [G loss: 0.899358]\n",
      "epoch:4 step:4304 [D loss: 0.657143, acc.: 60.94%] [G loss: 0.856640]\n",
      "epoch:4 step:4305 [D loss: 0.626587, acc.: 67.19%] [G loss: 0.852602]\n",
      "epoch:4 step:4306 [D loss: 0.631639, acc.: 70.31%] [G loss: 0.828112]\n",
      "epoch:4 step:4307 [D loss: 0.653607, acc.: 61.72%] [G loss: 0.848888]\n",
      "epoch:4 step:4308 [D loss: 0.675643, acc.: 60.94%] [G loss: 0.888729]\n",
      "epoch:4 step:4309 [D loss: 0.677362, acc.: 59.38%] [G loss: 0.859946]\n",
      "epoch:4 step:4310 [D loss: 0.647306, acc.: 60.94%] [G loss: 0.870064]\n",
      "epoch:4 step:4311 [D loss: 0.670681, acc.: 57.81%] [G loss: 0.893513]\n",
      "epoch:4 step:4312 [D loss: 0.619348, acc.: 67.19%] [G loss: 0.862007]\n",
      "epoch:4 step:4313 [D loss: 0.612499, acc.: 67.19%] [G loss: 0.838690]\n",
      "epoch:4 step:4314 [D loss: 0.704770, acc.: 55.47%] [G loss: 0.869231]\n",
      "epoch:4 step:4315 [D loss: 0.632150, acc.: 65.62%] [G loss: 0.890312]\n",
      "epoch:4 step:4316 [D loss: 0.702580, acc.: 53.91%] [G loss: 0.930082]\n",
      "epoch:4 step:4317 [D loss: 0.651800, acc.: 65.62%] [G loss: 0.925058]\n",
      "epoch:4 step:4318 [D loss: 0.736122, acc.: 41.41%] [G loss: 0.854877]\n",
      "epoch:4 step:4319 [D loss: 0.671948, acc.: 57.03%] [G loss: 0.911150]\n",
      "epoch:4 step:4320 [D loss: 0.651731, acc.: 60.16%] [G loss: 0.876460]\n",
      "epoch:4 step:4321 [D loss: 0.680934, acc.: 55.47%] [G loss: 0.860528]\n",
      "epoch:4 step:4322 [D loss: 0.650788, acc.: 61.72%] [G loss: 0.846181]\n",
      "epoch:4 step:4323 [D loss: 0.637659, acc.: 64.06%] [G loss: 0.855918]\n",
      "epoch:4 step:4324 [D loss: 0.653759, acc.: 64.84%] [G loss: 0.860384]\n",
      "epoch:4 step:4325 [D loss: 0.619605, acc.: 68.75%] [G loss: 0.882397]\n",
      "epoch:4 step:4326 [D loss: 0.650280, acc.: 57.81%] [G loss: 0.880363]\n",
      "epoch:4 step:4327 [D loss: 0.613554, acc.: 67.97%] [G loss: 0.848827]\n",
      "epoch:4 step:4328 [D loss: 0.682556, acc.: 55.47%] [G loss: 0.839252]\n",
      "epoch:4 step:4329 [D loss: 0.672516, acc.: 61.72%] [G loss: 0.861207]\n",
      "epoch:4 step:4330 [D loss: 0.639899, acc.: 69.53%] [G loss: 0.912756]\n",
      "epoch:4 step:4331 [D loss: 0.650603, acc.: 57.03%] [G loss: 0.864272]\n",
      "epoch:4 step:4332 [D loss: 0.691073, acc.: 56.25%] [G loss: 0.848702]\n",
      "epoch:4 step:4333 [D loss: 0.633436, acc.: 62.50%] [G loss: 0.872831]\n",
      "epoch:4 step:4334 [D loss: 0.655092, acc.: 64.84%] [G loss: 0.913730]\n",
      "epoch:4 step:4335 [D loss: 0.675143, acc.: 55.47%] [G loss: 0.859124]\n",
      "epoch:4 step:4336 [D loss: 0.646056, acc.: 64.06%] [G loss: 0.882300]\n",
      "epoch:4 step:4337 [D loss: 0.621989, acc.: 68.75%] [G loss: 0.859056]\n",
      "epoch:4 step:4338 [D loss: 0.654495, acc.: 57.81%] [G loss: 0.852802]\n",
      "epoch:4 step:4339 [D loss: 0.665925, acc.: 60.16%] [G loss: 0.856957]\n",
      "epoch:4 step:4340 [D loss: 0.636647, acc.: 64.84%] [G loss: 0.955779]\n",
      "epoch:4 step:4341 [D loss: 0.675361, acc.: 57.81%] [G loss: 0.882812]\n",
      "epoch:4 step:4342 [D loss: 0.681145, acc.: 58.59%] [G loss: 0.840713]\n",
      "epoch:4 step:4343 [D loss: 0.636091, acc.: 66.41%] [G loss: 0.839656]\n",
      "epoch:4 step:4344 [D loss: 0.672694, acc.: 56.25%] [G loss: 0.816226]\n",
      "epoch:4 step:4345 [D loss: 0.663639, acc.: 59.38%] [G loss: 0.880708]\n",
      "epoch:4 step:4346 [D loss: 0.654187, acc.: 63.28%] [G loss: 0.883915]\n",
      "epoch:4 step:4347 [D loss: 0.652623, acc.: 60.94%] [G loss: 0.911534]\n",
      "epoch:4 step:4348 [D loss: 0.672082, acc.: 60.94%] [G loss: 0.831467]\n",
      "epoch:4 step:4349 [D loss: 0.684427, acc.: 56.25%] [G loss: 0.773171]\n",
      "epoch:4 step:4350 [D loss: 0.638524, acc.: 64.06%] [G loss: 0.883077]\n",
      "epoch:4 step:4351 [D loss: 0.647985, acc.: 60.16%] [G loss: 0.910981]\n",
      "epoch:4 step:4352 [D loss: 0.671623, acc.: 60.16%] [G loss: 0.896985]\n",
      "epoch:4 step:4353 [D loss: 0.664693, acc.: 60.94%] [G loss: 0.894138]\n",
      "epoch:4 step:4354 [D loss: 0.644087, acc.: 62.50%] [G loss: 0.829677]\n",
      "epoch:4 step:4355 [D loss: 0.705466, acc.: 51.56%] [G loss: 0.830904]\n",
      "epoch:4 step:4356 [D loss: 0.662280, acc.: 50.78%] [G loss: 0.883084]\n",
      "epoch:4 step:4357 [D loss: 0.628408, acc.: 64.84%] [G loss: 0.845870]\n",
      "epoch:4 step:4358 [D loss: 0.685380, acc.: 53.91%] [G loss: 0.849995]\n",
      "epoch:4 step:4359 [D loss: 0.627084, acc.: 69.53%] [G loss: 0.891876]\n",
      "epoch:4 step:4360 [D loss: 0.631193, acc.: 61.72%] [G loss: 0.812918]\n",
      "epoch:4 step:4361 [D loss: 0.647631, acc.: 65.62%] [G loss: 0.872811]\n",
      "epoch:4 step:4362 [D loss: 0.649980, acc.: 57.81%] [G loss: 0.913821]\n",
      "epoch:4 step:4363 [D loss: 0.634909, acc.: 64.06%] [G loss: 0.898524]\n",
      "epoch:4 step:4364 [D loss: 0.635459, acc.: 60.16%] [G loss: 0.838544]\n",
      "epoch:4 step:4365 [D loss: 0.660148, acc.: 53.91%] [G loss: 0.855614]\n",
      "epoch:4 step:4366 [D loss: 0.663522, acc.: 62.50%] [G loss: 0.869007]\n",
      "epoch:4 step:4367 [D loss: 0.654767, acc.: 64.06%] [G loss: 0.856058]\n",
      "epoch:4 step:4368 [D loss: 0.694319, acc.: 57.81%] [G loss: 0.827670]\n",
      "epoch:4 step:4369 [D loss: 0.683853, acc.: 55.47%] [G loss: 0.832799]\n",
      "epoch:4 step:4370 [D loss: 0.641017, acc.: 65.62%] [G loss: 0.833419]\n",
      "epoch:4 step:4371 [D loss: 0.669487, acc.: 60.94%] [G loss: 0.900155]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4372 [D loss: 0.644686, acc.: 61.72%] [G loss: 0.899419]\n",
      "epoch:4 step:4373 [D loss: 0.681374, acc.: 54.69%] [G loss: 0.833441]\n",
      "epoch:4 step:4374 [D loss: 0.682634, acc.: 52.34%] [G loss: 0.884874]\n",
      "epoch:4 step:4375 [D loss: 0.656903, acc.: 62.50%] [G loss: 0.823928]\n",
      "epoch:4 step:4376 [D loss: 0.699448, acc.: 51.56%] [G loss: 0.849585]\n",
      "epoch:4 step:4377 [D loss: 0.699216, acc.: 55.47%] [G loss: 0.850600]\n",
      "epoch:4 step:4378 [D loss: 0.671682, acc.: 59.38%] [G loss: 0.829785]\n",
      "epoch:4 step:4379 [D loss: 0.658745, acc.: 60.16%] [G loss: 0.830867]\n",
      "epoch:4 step:4380 [D loss: 0.691513, acc.: 54.69%] [G loss: 0.846917]\n",
      "epoch:4 step:4381 [D loss: 0.660477, acc.: 57.81%] [G loss: 0.853186]\n",
      "epoch:4 step:4382 [D loss: 0.649803, acc.: 63.28%] [G loss: 0.884775]\n",
      "epoch:4 step:4383 [D loss: 0.629556, acc.: 67.19%] [G loss: 0.837909]\n",
      "epoch:4 step:4384 [D loss: 0.633389, acc.: 70.31%] [G loss: 0.867015]\n",
      "epoch:4 step:4385 [D loss: 0.632605, acc.: 66.41%] [G loss: 0.858508]\n",
      "epoch:4 step:4386 [D loss: 0.670463, acc.: 57.81%] [G loss: 0.867646]\n",
      "epoch:4 step:4387 [D loss: 0.681715, acc.: 56.25%] [G loss: 0.884922]\n",
      "epoch:4 step:4388 [D loss: 0.651912, acc.: 64.06%] [G loss: 0.890927]\n",
      "epoch:4 step:4389 [D loss: 0.638958, acc.: 62.50%] [G loss: 0.907003]\n",
      "epoch:4 step:4390 [D loss: 0.650705, acc.: 59.38%] [G loss: 0.871558]\n",
      "epoch:4 step:4391 [D loss: 0.669915, acc.: 61.72%] [G loss: 0.849916]\n",
      "epoch:4 step:4392 [D loss: 0.641092, acc.: 68.75%] [G loss: 0.834734]\n",
      "epoch:4 step:4393 [D loss: 0.629682, acc.: 63.28%] [G loss: 0.804223]\n",
      "epoch:4 step:4394 [D loss: 0.725997, acc.: 50.00%] [G loss: 0.774574]\n",
      "epoch:4 step:4395 [D loss: 0.675317, acc.: 60.16%] [G loss: 0.806046]\n",
      "epoch:4 step:4396 [D loss: 0.654789, acc.: 60.94%] [G loss: 0.868972]\n",
      "epoch:4 step:4397 [D loss: 0.668679, acc.: 59.38%] [G loss: 0.878269]\n",
      "epoch:4 step:4398 [D loss: 0.650538, acc.: 64.84%] [G loss: 0.831096]\n",
      "epoch:4 step:4399 [D loss: 0.644095, acc.: 59.38%] [G loss: 0.847530]\n",
      "epoch:4 step:4400 [D loss: 0.657760, acc.: 61.72%] [G loss: 0.831129]\n",
      "##############\n",
      "[3.28746375 2.84295592 2.66773038 4.04563862 1.82595702 9.27426719\n",
      " 3.12707011 4.29912242 4.57591006 8.14868929]\n",
      "##########\n",
      "epoch:4 step:4401 [D loss: 0.660701, acc.: 58.59%] [G loss: 0.864195]\n",
      "epoch:4 step:4402 [D loss: 0.647970, acc.: 67.19%] [G loss: 0.873171]\n",
      "epoch:4 step:4403 [D loss: 0.653830, acc.: 62.50%] [G loss: 0.877261]\n",
      "epoch:4 step:4404 [D loss: 0.653702, acc.: 62.50%] [G loss: 0.869524]\n",
      "epoch:4 step:4405 [D loss: 0.643216, acc.: 60.16%] [G loss: 0.826968]\n",
      "epoch:4 step:4406 [D loss: 0.732534, acc.: 53.91%] [G loss: 0.791846]\n",
      "epoch:4 step:4407 [D loss: 0.647715, acc.: 63.28%] [G loss: 0.832652]\n",
      "epoch:4 step:4408 [D loss: 0.663192, acc.: 60.94%] [G loss: 0.825031]\n",
      "epoch:4 step:4409 [D loss: 0.679304, acc.: 58.59%] [G loss: 0.789521]\n",
      "epoch:4 step:4410 [D loss: 0.656836, acc.: 64.06%] [G loss: 0.858247]\n",
      "epoch:4 step:4411 [D loss: 0.669502, acc.: 59.38%] [G loss: 0.831588]\n",
      "epoch:4 step:4412 [D loss: 0.647651, acc.: 67.19%] [G loss: 0.888915]\n",
      "epoch:4 step:4413 [D loss: 0.704735, acc.: 54.69%] [G loss: 0.872246]\n",
      "epoch:4 step:4414 [D loss: 0.660475, acc.: 62.50%] [G loss: 0.931726]\n",
      "epoch:4 step:4415 [D loss: 0.673984, acc.: 61.72%] [G loss: 0.871826]\n",
      "epoch:4 step:4416 [D loss: 0.629624, acc.: 65.62%] [G loss: 0.911900]\n",
      "epoch:4 step:4417 [D loss: 0.653691, acc.: 61.72%] [G loss: 0.854188]\n",
      "epoch:4 step:4418 [D loss: 0.667019, acc.: 55.47%] [G loss: 0.864621]\n",
      "epoch:4 step:4419 [D loss: 0.618654, acc.: 62.50%] [G loss: 0.852655]\n",
      "epoch:4 step:4420 [D loss: 0.659620, acc.: 57.81%] [G loss: 0.852982]\n",
      "epoch:4 step:4421 [D loss: 0.686771, acc.: 56.25%] [G loss: 0.868959]\n",
      "epoch:4 step:4422 [D loss: 0.658618, acc.: 64.06%] [G loss: 0.839786]\n",
      "epoch:4 step:4423 [D loss: 0.667609, acc.: 59.38%] [G loss: 0.895441]\n",
      "epoch:4 step:4424 [D loss: 0.649146, acc.: 66.41%] [G loss: 0.835588]\n",
      "epoch:4 step:4425 [D loss: 0.678771, acc.: 57.03%] [G loss: 0.848755]\n",
      "epoch:4 step:4426 [D loss: 0.646582, acc.: 63.28%] [G loss: 0.876792]\n",
      "epoch:4 step:4427 [D loss: 0.680777, acc.: 57.81%] [G loss: 0.838682]\n",
      "epoch:4 step:4428 [D loss: 0.677890, acc.: 59.38%] [G loss: 0.875132]\n",
      "epoch:4 step:4429 [D loss: 0.682623, acc.: 53.12%] [G loss: 0.853575]\n",
      "epoch:4 step:4430 [D loss: 0.640192, acc.: 57.81%] [G loss: 0.826028]\n",
      "epoch:4 step:4431 [D loss: 0.644801, acc.: 64.84%] [G loss: 0.877260]\n",
      "epoch:4 step:4432 [D loss: 0.659407, acc.: 58.59%] [G loss: 0.870646]\n",
      "epoch:4 step:4433 [D loss: 0.706879, acc.: 53.91%] [G loss: 0.857287]\n",
      "epoch:4 step:4434 [D loss: 0.694693, acc.: 53.12%] [G loss: 0.856853]\n",
      "epoch:4 step:4435 [D loss: 0.656032, acc.: 57.81%] [G loss: 0.880476]\n",
      "epoch:4 step:4436 [D loss: 0.671819, acc.: 57.03%] [G loss: 0.893743]\n",
      "epoch:4 step:4437 [D loss: 0.676699, acc.: 57.81%] [G loss: 0.865167]\n",
      "epoch:4 step:4438 [D loss: 0.673756, acc.: 60.94%] [G loss: 0.854818]\n",
      "epoch:4 step:4439 [D loss: 0.638098, acc.: 67.19%] [G loss: 0.819349]\n",
      "epoch:4 step:4440 [D loss: 0.688048, acc.: 57.81%] [G loss: 0.841531]\n",
      "epoch:4 step:4441 [D loss: 0.659345, acc.: 58.59%] [G loss: 0.884377]\n",
      "epoch:4 step:4442 [D loss: 0.643419, acc.: 64.06%] [G loss: 0.912446]\n",
      "epoch:4 step:4443 [D loss: 0.646750, acc.: 63.28%] [G loss: 0.860812]\n",
      "epoch:4 step:4444 [D loss: 0.650552, acc.: 59.38%] [G loss: 0.865574]\n",
      "epoch:4 step:4445 [D loss: 0.684834, acc.: 56.25%] [G loss: 0.830117]\n",
      "epoch:4 step:4446 [D loss: 0.659742, acc.: 60.16%] [G loss: 0.863091]\n",
      "epoch:4 step:4447 [D loss: 0.666675, acc.: 57.03%] [G loss: 0.882774]\n",
      "epoch:4 step:4448 [D loss: 0.645116, acc.: 59.38%] [G loss: 0.865220]\n",
      "epoch:4 step:4449 [D loss: 0.652862, acc.: 61.72%] [G loss: 0.885323]\n",
      "epoch:4 step:4450 [D loss: 0.625349, acc.: 67.19%] [G loss: 0.832195]\n",
      "epoch:4 step:4451 [D loss: 0.655653, acc.: 62.50%] [G loss: 0.884015]\n",
      "epoch:4 step:4452 [D loss: 0.657232, acc.: 61.72%] [G loss: 0.931856]\n",
      "epoch:4 step:4453 [D loss: 0.633394, acc.: 60.94%] [G loss: 0.910043]\n",
      "epoch:4 step:4454 [D loss: 0.672539, acc.: 56.25%] [G loss: 0.893982]\n",
      "epoch:4 step:4455 [D loss: 0.664650, acc.: 60.94%] [G loss: 0.855658]\n",
      "epoch:4 step:4456 [D loss: 0.641201, acc.: 64.84%] [G loss: 0.817799]\n",
      "epoch:4 step:4457 [D loss: 0.677013, acc.: 57.03%] [G loss: 0.820122]\n",
      "epoch:4 step:4458 [D loss: 0.623016, acc.: 66.41%] [G loss: 0.819469]\n",
      "epoch:4 step:4459 [D loss: 0.643424, acc.: 64.84%] [G loss: 0.826390]\n",
      "epoch:4 step:4460 [D loss: 0.645074, acc.: 62.50%] [G loss: 0.872462]\n",
      "epoch:4 step:4461 [D loss: 0.658073, acc.: 57.03%] [G loss: 0.845436]\n",
      "epoch:4 step:4462 [D loss: 0.662345, acc.: 60.16%] [G loss: 0.861502]\n",
      "epoch:4 step:4463 [D loss: 0.691169, acc.: 51.56%] [G loss: 0.846766]\n",
      "epoch:4 step:4464 [D loss: 0.672592, acc.: 57.03%] [G loss: 0.905930]\n",
      "epoch:4 step:4465 [D loss: 0.644885, acc.: 67.97%] [G loss: 0.879089]\n",
      "epoch:4 step:4466 [D loss: 0.630036, acc.: 60.16%] [G loss: 0.845034]\n",
      "epoch:4 step:4467 [D loss: 0.664912, acc.: 56.25%] [G loss: 0.837947]\n",
      "epoch:4 step:4468 [D loss: 0.669527, acc.: 61.72%] [G loss: 0.913769]\n",
      "epoch:4 step:4469 [D loss: 0.640628, acc.: 62.50%] [G loss: 0.922092]\n",
      "epoch:4 step:4470 [D loss: 0.650766, acc.: 66.41%] [G loss: 0.868760]\n",
      "epoch:4 step:4471 [D loss: 0.698218, acc.: 53.12%] [G loss: 0.864719]\n",
      "epoch:4 step:4472 [D loss: 0.687012, acc.: 56.25%] [G loss: 0.941405]\n",
      "epoch:4 step:4473 [D loss: 0.650036, acc.: 62.50%] [G loss: 0.891271]\n",
      "epoch:4 step:4474 [D loss: 0.677390, acc.: 61.72%] [G loss: 0.883079]\n",
      "epoch:4 step:4475 [D loss: 0.630668, acc.: 69.53%] [G loss: 0.871626]\n",
      "epoch:4 step:4476 [D loss: 0.658356, acc.: 66.41%] [G loss: 0.855690]\n",
      "epoch:4 step:4477 [D loss: 0.685477, acc.: 56.25%] [G loss: 0.855240]\n",
      "epoch:4 step:4478 [D loss: 0.721720, acc.: 56.25%] [G loss: 0.804975]\n",
      "epoch:4 step:4479 [D loss: 0.701910, acc.: 55.47%] [G loss: 0.852462]\n",
      "epoch:4 step:4480 [D loss: 0.672766, acc.: 55.47%] [G loss: 0.882022]\n",
      "epoch:4 step:4481 [D loss: 0.660239, acc.: 59.38%] [G loss: 0.839458]\n",
      "epoch:4 step:4482 [D loss: 0.600284, acc.: 70.31%] [G loss: 0.863037]\n",
      "epoch:4 step:4483 [D loss: 0.676562, acc.: 58.59%] [G loss: 0.772747]\n",
      "epoch:4 step:4484 [D loss: 0.632397, acc.: 66.41%] [G loss: 0.836731]\n",
      "epoch:4 step:4485 [D loss: 0.714114, acc.: 46.88%] [G loss: 0.866274]\n",
      "epoch:4 step:4486 [D loss: 0.670594, acc.: 57.03%] [G loss: 0.838031]\n",
      "epoch:4 step:4487 [D loss: 0.657879, acc.: 54.69%] [G loss: 0.852828]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4488 [D loss: 0.667885, acc.: 57.03%] [G loss: 0.785477]\n",
      "epoch:4 step:4489 [D loss: 0.651146, acc.: 58.59%] [G loss: 0.809732]\n",
      "epoch:4 step:4490 [D loss: 0.653627, acc.: 56.25%] [G loss: 0.855646]\n",
      "epoch:4 step:4491 [D loss: 0.658583, acc.: 60.16%] [G loss: 0.835761]\n",
      "epoch:4 step:4492 [D loss: 0.657808, acc.: 64.06%] [G loss: 0.834235]\n",
      "epoch:4 step:4493 [D loss: 0.670147, acc.: 60.16%] [G loss: 0.892351]\n",
      "epoch:4 step:4494 [D loss: 0.641752, acc.: 60.16%] [G loss: 0.850799]\n",
      "epoch:4 step:4495 [D loss: 0.697398, acc.: 52.34%] [G loss: 0.861180]\n",
      "epoch:4 step:4496 [D loss: 0.660573, acc.: 56.25%] [G loss: 0.893625]\n",
      "epoch:4 step:4497 [D loss: 0.627008, acc.: 63.28%] [G loss: 0.886792]\n",
      "epoch:4 step:4498 [D loss: 0.659948, acc.: 55.47%] [G loss: 0.888345]\n",
      "epoch:4 step:4499 [D loss: 0.657088, acc.: 60.94%] [G loss: 0.881968]\n",
      "epoch:4 step:4500 [D loss: 0.658405, acc.: 59.38%] [G loss: 0.894404]\n",
      "epoch:4 step:4501 [D loss: 0.664960, acc.: 60.16%] [G loss: 0.899570]\n",
      "epoch:4 step:4502 [D loss: 0.662289, acc.: 60.94%] [G loss: 0.881083]\n",
      "epoch:4 step:4503 [D loss: 0.641286, acc.: 60.94%] [G loss: 0.839963]\n",
      "epoch:4 step:4504 [D loss: 0.655717, acc.: 64.06%] [G loss: 0.866718]\n",
      "epoch:4 step:4505 [D loss: 0.644882, acc.: 60.94%] [G loss: 0.833613]\n",
      "epoch:4 step:4506 [D loss: 0.679442, acc.: 62.50%] [G loss: 0.910082]\n",
      "epoch:4 step:4507 [D loss: 0.639938, acc.: 68.75%] [G loss: 0.828922]\n",
      "epoch:4 step:4508 [D loss: 0.639941, acc.: 64.06%] [G loss: 0.857525]\n",
      "epoch:4 step:4509 [D loss: 0.713582, acc.: 47.66%] [G loss: 0.826916]\n",
      "epoch:4 step:4510 [D loss: 0.650125, acc.: 61.72%] [G loss: 0.792830]\n",
      "epoch:4 step:4511 [D loss: 0.685333, acc.: 51.56%] [G loss: 0.849718]\n",
      "epoch:4 step:4512 [D loss: 0.662395, acc.: 57.81%] [G loss: 0.814590]\n",
      "epoch:4 step:4513 [D loss: 0.671054, acc.: 57.81%] [G loss: 0.878571]\n",
      "epoch:4 step:4514 [D loss: 0.693373, acc.: 51.56%] [G loss: 0.848759]\n",
      "epoch:4 step:4515 [D loss: 0.689466, acc.: 53.91%] [G loss: 0.820157]\n",
      "epoch:4 step:4516 [D loss: 0.689860, acc.: 55.47%] [G loss: 0.831092]\n",
      "epoch:4 step:4517 [D loss: 0.639175, acc.: 63.28%] [G loss: 0.890396]\n",
      "epoch:4 step:4518 [D loss: 0.693401, acc.: 52.34%] [G loss: 0.920906]\n",
      "epoch:4 step:4519 [D loss: 0.672224, acc.: 54.69%] [G loss: 0.899058]\n",
      "epoch:4 step:4520 [D loss: 0.663669, acc.: 59.38%] [G loss: 0.850647]\n",
      "epoch:4 step:4521 [D loss: 0.674739, acc.: 56.25%] [G loss: 0.866192]\n",
      "epoch:4 step:4522 [D loss: 0.674687, acc.: 57.03%] [G loss: 0.843394]\n",
      "epoch:4 step:4523 [D loss: 0.680176, acc.: 56.25%] [G loss: 0.850294]\n",
      "epoch:4 step:4524 [D loss: 0.639070, acc.: 64.06%] [G loss: 0.835340]\n",
      "epoch:4 step:4525 [D loss: 0.643496, acc.: 61.72%] [G loss: 0.834163]\n",
      "epoch:4 step:4526 [D loss: 0.660818, acc.: 63.28%] [G loss: 0.880544]\n",
      "epoch:4 step:4527 [D loss: 0.623813, acc.: 66.41%] [G loss: 0.835589]\n",
      "epoch:4 step:4528 [D loss: 0.663613, acc.: 61.72%] [G loss: 0.862283]\n",
      "epoch:4 step:4529 [D loss: 0.654803, acc.: 63.28%] [G loss: 0.820188]\n",
      "epoch:4 step:4530 [D loss: 0.620067, acc.: 64.06%] [G loss: 0.852127]\n",
      "epoch:4 step:4531 [D loss: 0.689014, acc.: 54.69%] [G loss: 0.840031]\n",
      "epoch:4 step:4532 [D loss: 0.688393, acc.: 54.69%] [G loss: 0.841944]\n",
      "epoch:4 step:4533 [D loss: 0.677902, acc.: 53.91%] [G loss: 0.854489]\n",
      "epoch:4 step:4534 [D loss: 0.675162, acc.: 53.12%] [G loss: 0.866556]\n",
      "epoch:4 step:4535 [D loss: 0.643884, acc.: 57.81%] [G loss: 0.880588]\n",
      "epoch:4 step:4536 [D loss: 0.650202, acc.: 63.28%] [G loss: 0.824692]\n",
      "epoch:4 step:4537 [D loss: 0.658831, acc.: 60.94%] [G loss: 0.835549]\n",
      "epoch:4 step:4538 [D loss: 0.676627, acc.: 53.91%] [G loss: 0.869705]\n",
      "epoch:4 step:4539 [D loss: 0.657759, acc.: 61.72%] [G loss: 0.807753]\n",
      "epoch:4 step:4540 [D loss: 0.688594, acc.: 57.03%] [G loss: 0.897517]\n",
      "epoch:4 step:4541 [D loss: 0.664449, acc.: 55.47%] [G loss: 0.878518]\n",
      "epoch:4 step:4542 [D loss: 0.647809, acc.: 67.19%] [G loss: 0.847537]\n",
      "epoch:4 step:4543 [D loss: 0.642644, acc.: 64.06%] [G loss: 0.883404]\n",
      "epoch:4 step:4544 [D loss: 0.630470, acc.: 64.84%] [G loss: 0.858537]\n",
      "epoch:4 step:4545 [D loss: 0.673122, acc.: 58.59%] [G loss: 0.872895]\n",
      "epoch:4 step:4546 [D loss: 0.653153, acc.: 65.62%] [G loss: 0.874108]\n",
      "epoch:4 step:4547 [D loss: 0.698525, acc.: 58.59%] [G loss: 0.823599]\n",
      "epoch:4 step:4548 [D loss: 0.681144, acc.: 54.69%] [G loss: 0.862182]\n",
      "epoch:4 step:4549 [D loss: 0.670388, acc.: 57.81%] [G loss: 0.916322]\n",
      "epoch:4 step:4550 [D loss: 0.662433, acc.: 60.94%] [G loss: 0.889399]\n",
      "epoch:4 step:4551 [D loss: 0.654326, acc.: 63.28%] [G loss: 0.891970]\n",
      "epoch:4 step:4552 [D loss: 0.672843, acc.: 57.81%] [G loss: 0.870132]\n",
      "epoch:4 step:4553 [D loss: 0.654694, acc.: 59.38%] [G loss: 0.883199]\n",
      "epoch:4 step:4554 [D loss: 0.649061, acc.: 63.28%] [G loss: 0.874726]\n",
      "epoch:4 step:4555 [D loss: 0.678709, acc.: 60.16%] [G loss: 0.906833]\n",
      "epoch:4 step:4556 [D loss: 0.654088, acc.: 62.50%] [G loss: 0.912085]\n",
      "epoch:4 step:4557 [D loss: 0.677520, acc.: 54.69%] [G loss: 0.846293]\n",
      "epoch:4 step:4558 [D loss: 0.653082, acc.: 64.06%] [G loss: 0.862454]\n",
      "epoch:4 step:4559 [D loss: 0.640274, acc.: 60.94%] [G loss: 0.882231]\n",
      "epoch:4 step:4560 [D loss: 0.677354, acc.: 57.03%] [G loss: 0.931594]\n",
      "epoch:4 step:4561 [D loss: 0.658453, acc.: 60.94%] [G loss: 0.924554]\n",
      "epoch:4 step:4562 [D loss: 0.617348, acc.: 67.19%] [G loss: 0.884980]\n",
      "epoch:4 step:4563 [D loss: 0.677234, acc.: 62.50%] [G loss: 0.913745]\n",
      "epoch:4 step:4564 [D loss: 0.627877, acc.: 64.84%] [G loss: 0.864046]\n",
      "epoch:4 step:4565 [D loss: 0.696316, acc.: 56.25%] [G loss: 0.897823]\n",
      "epoch:4 step:4566 [D loss: 0.667639, acc.: 60.16%] [G loss: 0.863339]\n",
      "epoch:4 step:4567 [D loss: 0.674230, acc.: 57.03%] [G loss: 0.856777]\n",
      "epoch:4 step:4568 [D loss: 0.683277, acc.: 56.25%] [G loss: 0.876091]\n",
      "epoch:4 step:4569 [D loss: 0.713392, acc.: 44.53%] [G loss: 0.846377]\n",
      "epoch:4 step:4570 [D loss: 0.664891, acc.: 57.03%] [G loss: 0.802372]\n",
      "epoch:4 step:4571 [D loss: 0.683621, acc.: 57.81%] [G loss: 0.841626]\n",
      "epoch:4 step:4572 [D loss: 0.666269, acc.: 60.16%] [G loss: 0.881976]\n",
      "epoch:4 step:4573 [D loss: 0.655586, acc.: 62.50%] [G loss: 0.909821]\n",
      "epoch:4 step:4574 [D loss: 0.639599, acc.: 60.16%] [G loss: 0.902157]\n",
      "epoch:4 step:4575 [D loss: 0.657156, acc.: 57.03%] [G loss: 0.946612]\n",
      "epoch:4 step:4576 [D loss: 0.677847, acc.: 58.59%] [G loss: 0.888785]\n",
      "epoch:4 step:4577 [D loss: 0.645915, acc.: 65.62%] [G loss: 0.835761]\n",
      "epoch:4 step:4578 [D loss: 0.653312, acc.: 61.72%] [G loss: 0.828457]\n",
      "epoch:4 step:4579 [D loss: 0.697938, acc.: 55.47%] [G loss: 0.877801]\n",
      "epoch:4 step:4580 [D loss: 0.647977, acc.: 57.81%] [G loss: 0.787760]\n",
      "epoch:4 step:4581 [D loss: 0.690138, acc.: 54.69%] [G loss: 0.866892]\n",
      "epoch:4 step:4582 [D loss: 0.656081, acc.: 63.28%] [G loss: 0.864998]\n",
      "epoch:4 step:4583 [D loss: 0.648847, acc.: 63.28%] [G loss: 0.902088]\n",
      "epoch:4 step:4584 [D loss: 0.659700, acc.: 57.81%] [G loss: 0.918901]\n",
      "epoch:4 step:4585 [D loss: 0.677860, acc.: 62.50%] [G loss: 0.847931]\n",
      "epoch:4 step:4586 [D loss: 0.693992, acc.: 47.66%] [G loss: 0.909683]\n",
      "epoch:4 step:4587 [D loss: 0.637164, acc.: 66.41%] [G loss: 0.889982]\n",
      "epoch:4 step:4588 [D loss: 0.667099, acc.: 51.56%] [G loss: 0.875209]\n",
      "epoch:4 step:4589 [D loss: 0.708262, acc.: 50.00%] [G loss: 0.829359]\n",
      "epoch:4 step:4590 [D loss: 0.664613, acc.: 55.47%] [G loss: 0.896528]\n",
      "epoch:4 step:4591 [D loss: 0.654271, acc.: 60.16%] [G loss: 0.861640]\n",
      "epoch:4 step:4592 [D loss: 0.684196, acc.: 48.44%] [G loss: 0.841056]\n",
      "epoch:4 step:4593 [D loss: 0.651939, acc.: 65.62%] [G loss: 0.851599]\n",
      "epoch:4 step:4594 [D loss: 0.668441, acc.: 62.50%] [G loss: 0.825737]\n",
      "epoch:4 step:4595 [D loss: 0.669584, acc.: 60.16%] [G loss: 0.822662]\n",
      "epoch:4 step:4596 [D loss: 0.683196, acc.: 53.91%] [G loss: 0.800417]\n",
      "epoch:4 step:4597 [D loss: 0.660967, acc.: 59.38%] [G loss: 0.852092]\n",
      "epoch:4 step:4598 [D loss: 0.667480, acc.: 53.12%] [G loss: 0.877652]\n",
      "epoch:4 step:4599 [D loss: 0.668965, acc.: 57.03%] [G loss: 0.824529]\n",
      "epoch:4 step:4600 [D loss: 0.631876, acc.: 64.06%] [G loss: 0.872834]\n",
      "##############\n",
      "[ 3.12340078  2.77244364  2.56345607  4.09035365  1.77751591 10.27426719\n",
      "  3.32880487  4.36811358  4.42488368  8.14868929]\n",
      "##########\n",
      "epoch:4 step:4601 [D loss: 0.648310, acc.: 57.81%] [G loss: 0.875872]\n",
      "epoch:4 step:4602 [D loss: 0.670229, acc.: 58.59%] [G loss: 0.818421]\n",
      "epoch:4 step:4603 [D loss: 0.676724, acc.: 52.34%] [G loss: 0.850034]\n",
      "epoch:4 step:4604 [D loss: 0.638761, acc.: 60.94%] [G loss: 0.871647]\n",
      "epoch:4 step:4605 [D loss: 0.656455, acc.: 62.50%] [G loss: 0.880235]\n",
      "epoch:4 step:4606 [D loss: 0.690690, acc.: 51.56%] [G loss: 0.874454]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:4 step:4607 [D loss: 0.686636, acc.: 54.69%] [G loss: 0.856781]\n",
      "epoch:4 step:4608 [D loss: 0.664809, acc.: 57.03%] [G loss: 0.935565]\n",
      "epoch:4 step:4609 [D loss: 0.624101, acc.: 69.53%] [G loss: 0.898619]\n",
      "epoch:4 step:4610 [D loss: 0.655039, acc.: 62.50%] [G loss: 0.827665]\n",
      "epoch:4 step:4611 [D loss: 0.670482, acc.: 53.12%] [G loss: 0.876355]\n",
      "epoch:4 step:4612 [D loss: 0.688392, acc.: 54.69%] [G loss: 0.904383]\n",
      "epoch:4 step:4613 [D loss: 0.646173, acc.: 61.72%] [G loss: 0.850409]\n",
      "epoch:4 step:4614 [D loss: 0.660897, acc.: 57.81%] [G loss: 0.840567]\n",
      "epoch:4 step:4615 [D loss: 0.665111, acc.: 54.69%] [G loss: 0.851666]\n",
      "epoch:4 step:4616 [D loss: 0.637708, acc.: 67.19%] [G loss: 0.835232]\n",
      "epoch:4 step:4617 [D loss: 0.660495, acc.: 60.16%] [G loss: 0.902394]\n",
      "epoch:4 step:4618 [D loss: 0.670888, acc.: 55.47%] [G loss: 0.871401]\n",
      "epoch:4 step:4619 [D loss: 0.668904, acc.: 61.72%] [G loss: 0.820417]\n",
      "epoch:4 step:4620 [D loss: 0.663437, acc.: 58.59%] [G loss: 0.809492]\n",
      "epoch:4 step:4621 [D loss: 0.618662, acc.: 60.94%] [G loss: 0.812719]\n",
      "epoch:4 step:4622 [D loss: 0.602363, acc.: 68.75%] [G loss: 0.820315]\n",
      "epoch:4 step:4623 [D loss: 0.647343, acc.: 63.28%] [G loss: 0.839527]\n",
      "epoch:4 step:4624 [D loss: 0.684748, acc.: 54.69%] [G loss: 0.784446]\n",
      "epoch:4 step:4625 [D loss: 0.643608, acc.: 62.50%] [G loss: 0.857241]\n",
      "epoch:4 step:4626 [D loss: 0.689290, acc.: 53.91%] [G loss: 0.834456]\n",
      "epoch:4 step:4627 [D loss: 0.677232, acc.: 58.59%] [G loss: 0.839422]\n",
      "epoch:4 step:4628 [D loss: 0.641961, acc.: 66.41%] [G loss: 0.913319]\n",
      "epoch:4 step:4629 [D loss: 0.698413, acc.: 52.34%] [G loss: 0.865540]\n",
      "epoch:4 step:4630 [D loss: 0.640352, acc.: 60.16%] [G loss: 0.825839]\n",
      "epoch:4 step:4631 [D loss: 0.678838, acc.: 55.47%] [G loss: 0.869413]\n",
      "epoch:4 step:4632 [D loss: 0.683097, acc.: 59.38%] [G loss: 0.900415]\n",
      "epoch:4 step:4633 [D loss: 0.716502, acc.: 50.00%] [G loss: 0.844429]\n",
      "epoch:4 step:4634 [D loss: 0.693013, acc.: 51.56%] [G loss: 0.849520]\n",
      "epoch:4 step:4635 [D loss: 0.639237, acc.: 60.16%] [G loss: 0.886849]\n",
      "epoch:4 step:4636 [D loss: 0.647190, acc.: 60.94%] [G loss: 0.839210]\n",
      "epoch:4 step:4637 [D loss: 0.641086, acc.: 65.62%] [G loss: 0.864122]\n",
      "epoch:4 step:4638 [D loss: 0.631521, acc.: 66.41%] [G loss: 0.880741]\n",
      "epoch:4 step:4639 [D loss: 0.655211, acc.: 61.72%] [G loss: 0.904051]\n",
      "epoch:4 step:4640 [D loss: 0.695847, acc.: 53.91%] [G loss: 0.901137]\n",
      "epoch:4 step:4641 [D loss: 0.656077, acc.: 60.94%] [G loss: 0.854538]\n",
      "epoch:4 step:4642 [D loss: 0.673142, acc.: 60.16%] [G loss: 0.807170]\n",
      "epoch:4 step:4643 [D loss: 0.620095, acc.: 63.28%] [G loss: 0.781692]\n",
      "epoch:4 step:4644 [D loss: 0.673009, acc.: 60.94%] [G loss: 0.898832]\n",
      "epoch:4 step:4645 [D loss: 0.674890, acc.: 57.81%] [G loss: 0.847467]\n",
      "epoch:4 step:4646 [D loss: 0.647352, acc.: 60.94%] [G loss: 0.815324]\n",
      "epoch:4 step:4647 [D loss: 0.662090, acc.: 60.94%] [G loss: 0.853104]\n",
      "epoch:4 step:4648 [D loss: 0.652279, acc.: 65.62%] [G loss: 0.822406]\n",
      "epoch:4 step:4649 [D loss: 0.652402, acc.: 62.50%] [G loss: 0.862908]\n",
      "epoch:4 step:4650 [D loss: 0.678529, acc.: 56.25%] [G loss: 0.852558]\n",
      "epoch:4 step:4651 [D loss: 0.622179, acc.: 67.19%] [G loss: 0.823414]\n",
      "epoch:4 step:4652 [D loss: 0.619820, acc.: 68.75%] [G loss: 0.852021]\n",
      "epoch:4 step:4653 [D loss: 0.697383, acc.: 54.69%] [G loss: 0.842492]\n",
      "epoch:4 step:4654 [D loss: 0.612287, acc.: 70.31%] [G loss: 0.832637]\n",
      "epoch:4 step:4655 [D loss: 0.683375, acc.: 54.69%] [G loss: 0.858743]\n",
      "epoch:4 step:4656 [D loss: 0.638493, acc.: 57.03%] [G loss: 0.870775]\n",
      "epoch:4 step:4657 [D loss: 0.633448, acc.: 64.84%] [G loss: 0.835719]\n",
      "epoch:4 step:4658 [D loss: 0.683659, acc.: 54.69%] [G loss: 0.843561]\n",
      "epoch:4 step:4659 [D loss: 0.660555, acc.: 59.38%] [G loss: 0.873421]\n",
      "epoch:4 step:4660 [D loss: 0.657091, acc.: 61.72%] [G loss: 0.854630]\n",
      "epoch:4 step:4661 [D loss: 0.628430, acc.: 64.06%] [G loss: 0.862033]\n",
      "epoch:4 step:4662 [D loss: 0.660048, acc.: 60.94%] [G loss: 0.864006]\n",
      "epoch:4 step:4663 [D loss: 0.684466, acc.: 57.81%] [G loss: 0.825671]\n",
      "epoch:4 step:4664 [D loss: 0.658010, acc.: 60.16%] [G loss: 0.890231]\n",
      "epoch:4 step:4665 [D loss: 0.627412, acc.: 60.94%] [G loss: 0.869605]\n",
      "epoch:4 step:4666 [D loss: 0.656185, acc.: 63.28%] [G loss: 0.843046]\n",
      "epoch:4 step:4667 [D loss: 0.661502, acc.: 61.72%] [G loss: 0.857648]\n",
      "epoch:4 step:4668 [D loss: 0.673963, acc.: 50.78%] [G loss: 0.855252]\n",
      "epoch:4 step:4669 [D loss: 0.676053, acc.: 65.62%] [G loss: 0.850646]\n",
      "epoch:4 step:4670 [D loss: 0.631846, acc.: 60.94%] [G loss: 0.870548]\n",
      "epoch:4 step:4671 [D loss: 0.676030, acc.: 56.25%] [G loss: 0.891047]\n",
      "epoch:4 step:4672 [D loss: 0.669379, acc.: 57.81%] [G loss: 0.896420]\n",
      "epoch:4 step:4673 [D loss: 0.655606, acc.: 61.72%] [G loss: 0.902910]\n",
      "epoch:4 step:4674 [D loss: 0.663648, acc.: 60.16%] [G loss: 0.854625]\n",
      "epoch:4 step:4675 [D loss: 0.681979, acc.: 53.12%] [G loss: 0.824405]\n",
      "epoch:4 step:4676 [D loss: 0.650407, acc.: 62.50%] [G loss: 0.859123]\n",
      "epoch:4 step:4677 [D loss: 0.659393, acc.: 56.25%] [G loss: 0.865320]\n",
      "epoch:4 step:4678 [D loss: 0.613693, acc.: 66.41%] [G loss: 0.867947]\n",
      "epoch:4 step:4679 [D loss: 0.695732, acc.: 60.94%] [G loss: 0.853390]\n",
      "epoch:4 step:4680 [D loss: 0.658378, acc.: 55.47%] [G loss: 0.811027]\n",
      "epoch:4 step:4681 [D loss: 0.671755, acc.: 57.81%] [G loss: 0.845465]\n",
      "epoch:4 step:4682 [D loss: 0.657466, acc.: 56.25%] [G loss: 0.861326]\n",
      "epoch:4 step:4683 [D loss: 0.622263, acc.: 63.28%] [G loss: 0.879215]\n",
      "epoch:4 step:4684 [D loss: 0.639712, acc.: 61.72%] [G loss: 0.862046]\n",
      "epoch:4 step:4685 [D loss: 0.700808, acc.: 54.69%] [G loss: 0.864914]\n",
      "epoch:5 step:4686 [D loss: 0.703286, acc.: 50.00%] [G loss: 0.818167]\n",
      "epoch:5 step:4687 [D loss: 0.618130, acc.: 67.97%] [G loss: 0.825966]\n",
      "epoch:5 step:4688 [D loss: 0.643596, acc.: 64.06%] [G loss: 0.861886]\n",
      "epoch:5 step:4689 [D loss: 0.682929, acc.: 55.47%] [G loss: 0.893337]\n",
      "epoch:5 step:4690 [D loss: 0.639899, acc.: 65.62%] [G loss: 0.851841]\n",
      "epoch:5 step:4691 [D loss: 0.664575, acc.: 61.72%] [G loss: 0.841318]\n",
      "epoch:5 step:4692 [D loss: 0.651288, acc.: 56.25%] [G loss: 0.895510]\n",
      "epoch:5 step:4693 [D loss: 0.654425, acc.: 63.28%] [G loss: 0.913351]\n",
      "epoch:5 step:4694 [D loss: 0.651917, acc.: 58.59%] [G loss: 0.856286]\n",
      "epoch:5 step:4695 [D loss: 0.666753, acc.: 56.25%] [G loss: 0.862357]\n",
      "epoch:5 step:4696 [D loss: 0.639211, acc.: 58.59%] [G loss: 0.919282]\n",
      "epoch:5 step:4697 [D loss: 0.654880, acc.: 60.94%] [G loss: 0.928628]\n",
      "epoch:5 step:4698 [D loss: 0.652118, acc.: 59.38%] [G loss: 0.907923]\n",
      "epoch:5 step:4699 [D loss: 0.674257, acc.: 60.94%] [G loss: 0.857541]\n",
      "epoch:5 step:4700 [D loss: 0.679120, acc.: 53.91%] [G loss: 0.855294]\n",
      "epoch:5 step:4701 [D loss: 0.632110, acc.: 64.84%] [G loss: 0.849482]\n",
      "epoch:5 step:4702 [D loss: 0.614830, acc.: 69.53%] [G loss: 0.806249]\n",
      "epoch:5 step:4703 [D loss: 0.685970, acc.: 54.69%] [G loss: 0.881153]\n",
      "epoch:5 step:4704 [D loss: 0.656883, acc.: 60.16%] [G loss: 0.848840]\n",
      "epoch:5 step:4705 [D loss: 0.706481, acc.: 50.00%] [G loss: 0.841868]\n",
      "epoch:5 step:4706 [D loss: 0.670282, acc.: 54.69%] [G loss: 0.819526]\n",
      "epoch:5 step:4707 [D loss: 0.673536, acc.: 53.91%] [G loss: 0.849364]\n",
      "epoch:5 step:4708 [D loss: 0.689972, acc.: 53.91%] [G loss: 0.827540]\n",
      "epoch:5 step:4709 [D loss: 0.635953, acc.: 63.28%] [G loss: 0.917234]\n",
      "epoch:5 step:4710 [D loss: 0.637937, acc.: 65.62%] [G loss: 0.864785]\n",
      "epoch:5 step:4711 [D loss: 0.665502, acc.: 57.81%] [G loss: 0.872105]\n",
      "epoch:5 step:4712 [D loss: 0.619251, acc.: 67.97%] [G loss: 0.930805]\n",
      "epoch:5 step:4713 [D loss: 0.687190, acc.: 55.47%] [G loss: 0.897819]\n",
      "epoch:5 step:4714 [D loss: 0.697523, acc.: 55.47%] [G loss: 0.873930]\n",
      "epoch:5 step:4715 [D loss: 0.648198, acc.: 60.94%] [G loss: 0.848334]\n",
      "epoch:5 step:4716 [D loss: 0.679253, acc.: 53.91%] [G loss: 0.891462]\n",
      "epoch:5 step:4717 [D loss: 0.632179, acc.: 64.84%] [G loss: 0.884763]\n",
      "epoch:5 step:4718 [D loss: 0.652551, acc.: 58.59%] [G loss: 0.868117]\n",
      "epoch:5 step:4719 [D loss: 0.685417, acc.: 57.81%] [G loss: 0.823735]\n",
      "epoch:5 step:4720 [D loss: 0.674563, acc.: 53.91%] [G loss: 0.850189]\n",
      "epoch:5 step:4721 [D loss: 0.610931, acc.: 67.97%] [G loss: 0.895201]\n",
      "epoch:5 step:4722 [D loss: 0.667006, acc.: 62.50%] [G loss: 0.882171]\n",
      "epoch:5 step:4723 [D loss: 0.688726, acc.: 55.47%] [G loss: 0.873608]\n",
      "epoch:5 step:4724 [D loss: 0.670677, acc.: 58.59%] [G loss: 0.909111]\n",
      "epoch:5 step:4725 [D loss: 0.667017, acc.: 60.16%] [G loss: 0.914328]\n",
      "epoch:5 step:4726 [D loss: 0.645814, acc.: 62.50%] [G loss: 0.840286]\n",
      "epoch:5 step:4727 [D loss: 0.651382, acc.: 63.28%] [G loss: 0.863250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4728 [D loss: 0.657521, acc.: 58.59%] [G loss: 0.879769]\n",
      "epoch:5 step:4729 [D loss: 0.679546, acc.: 59.38%] [G loss: 0.844790]\n",
      "epoch:5 step:4730 [D loss: 0.657306, acc.: 59.38%] [G loss: 0.857038]\n",
      "epoch:5 step:4731 [D loss: 0.651278, acc.: 57.81%] [G loss: 0.864966]\n",
      "epoch:5 step:4732 [D loss: 0.673628, acc.: 57.81%] [G loss: 0.875027]\n",
      "epoch:5 step:4733 [D loss: 0.644400, acc.: 64.84%] [G loss: 0.885559]\n",
      "epoch:5 step:4734 [D loss: 0.676302, acc.: 54.69%] [G loss: 0.850641]\n",
      "epoch:5 step:4735 [D loss: 0.645648, acc.: 66.41%] [G loss: 0.856828]\n",
      "epoch:5 step:4736 [D loss: 0.653906, acc.: 61.72%] [G loss: 0.887559]\n",
      "epoch:5 step:4737 [D loss: 0.677831, acc.: 57.03%] [G loss: 0.895760]\n",
      "epoch:5 step:4738 [D loss: 0.634564, acc.: 64.06%] [G loss: 0.885409]\n",
      "epoch:5 step:4739 [D loss: 0.633026, acc.: 61.72%] [G loss: 0.851276]\n",
      "epoch:5 step:4740 [D loss: 0.671908, acc.: 57.81%] [G loss: 0.863714]\n",
      "epoch:5 step:4741 [D loss: 0.680703, acc.: 55.47%] [G loss: 0.888440]\n",
      "epoch:5 step:4742 [D loss: 0.656801, acc.: 60.16%] [G loss: 0.894360]\n",
      "epoch:5 step:4743 [D loss: 0.673409, acc.: 60.94%] [G loss: 0.861432]\n",
      "epoch:5 step:4744 [D loss: 0.609225, acc.: 64.06%] [G loss: 0.821944]\n",
      "epoch:5 step:4745 [D loss: 0.660813, acc.: 60.94%] [G loss: 0.910913]\n",
      "epoch:5 step:4746 [D loss: 0.658553, acc.: 59.38%] [G loss: 0.846740]\n",
      "epoch:5 step:4747 [D loss: 0.645308, acc.: 57.81%] [G loss: 0.924847]\n",
      "epoch:5 step:4748 [D loss: 0.649857, acc.: 57.81%] [G loss: 0.856119]\n",
      "epoch:5 step:4749 [D loss: 0.662902, acc.: 64.84%] [G loss: 0.800010]\n",
      "epoch:5 step:4750 [D loss: 0.646470, acc.: 66.41%] [G loss: 0.846501]\n",
      "epoch:5 step:4751 [D loss: 0.685613, acc.: 53.91%] [G loss: 0.833772]\n",
      "epoch:5 step:4752 [D loss: 0.709994, acc.: 47.66%] [G loss: 0.944740]\n",
      "epoch:5 step:4753 [D loss: 0.648877, acc.: 57.03%] [G loss: 0.925308]\n",
      "epoch:5 step:4754 [D loss: 0.683335, acc.: 54.69%] [G loss: 0.927106]\n",
      "epoch:5 step:4755 [D loss: 0.677179, acc.: 59.38%] [G loss: 0.906690]\n",
      "epoch:5 step:4756 [D loss: 0.670708, acc.: 60.16%] [G loss: 0.814366]\n",
      "epoch:5 step:4757 [D loss: 0.638091, acc.: 63.28%] [G loss: 0.799790]\n",
      "epoch:5 step:4758 [D loss: 0.629085, acc.: 64.84%] [G loss: 0.844908]\n",
      "epoch:5 step:4759 [D loss: 0.679251, acc.: 58.59%] [G loss: 0.857649]\n",
      "epoch:5 step:4760 [D loss: 0.639057, acc.: 61.72%] [G loss: 0.869378]\n",
      "epoch:5 step:4761 [D loss: 0.637010, acc.: 63.28%] [G loss: 0.858760]\n",
      "epoch:5 step:4762 [D loss: 0.668597, acc.: 54.69%] [G loss: 0.811392]\n",
      "epoch:5 step:4763 [D loss: 0.649507, acc.: 57.03%] [G loss: 0.840179]\n",
      "epoch:5 step:4764 [D loss: 0.701178, acc.: 52.34%] [G loss: 0.830238]\n",
      "epoch:5 step:4765 [D loss: 0.599567, acc.: 68.75%] [G loss: 0.875200]\n",
      "epoch:5 step:4766 [D loss: 0.671004, acc.: 54.69%] [G loss: 0.847406]\n",
      "epoch:5 step:4767 [D loss: 0.687602, acc.: 53.91%] [G loss: 0.968089]\n",
      "epoch:5 step:4768 [D loss: 0.666422, acc.: 64.06%] [G loss: 0.877926]\n",
      "epoch:5 step:4769 [D loss: 0.645429, acc.: 60.94%] [G loss: 0.874520]\n",
      "epoch:5 step:4770 [D loss: 0.646808, acc.: 63.28%] [G loss: 0.848094]\n",
      "epoch:5 step:4771 [D loss: 0.664906, acc.: 57.81%] [G loss: 0.847038]\n",
      "epoch:5 step:4772 [D loss: 0.643214, acc.: 64.06%] [G loss: 0.803087]\n",
      "epoch:5 step:4773 [D loss: 0.662667, acc.: 59.38%] [G loss: 0.809686]\n",
      "epoch:5 step:4774 [D loss: 0.615576, acc.: 71.88%] [G loss: 0.844260]\n",
      "epoch:5 step:4775 [D loss: 0.666363, acc.: 58.59%] [G loss: 0.824561]\n",
      "epoch:5 step:4776 [D loss: 0.669090, acc.: 61.72%] [G loss: 0.842224]\n",
      "epoch:5 step:4777 [D loss: 0.681571, acc.: 56.25%] [G loss: 0.840769]\n",
      "epoch:5 step:4778 [D loss: 0.674347, acc.: 52.34%] [G loss: 0.865118]\n",
      "epoch:5 step:4779 [D loss: 0.651678, acc.: 60.94%] [G loss: 0.843962]\n",
      "epoch:5 step:4780 [D loss: 0.634151, acc.: 66.41%] [G loss: 0.870849]\n",
      "epoch:5 step:4781 [D loss: 0.639581, acc.: 59.38%] [G loss: 0.896832]\n",
      "epoch:5 step:4782 [D loss: 0.663776, acc.: 59.38%] [G loss: 0.899087]\n",
      "epoch:5 step:4783 [D loss: 0.661110, acc.: 58.59%] [G loss: 0.880124]\n",
      "epoch:5 step:4784 [D loss: 0.659124, acc.: 58.59%] [G loss: 0.909838]\n",
      "epoch:5 step:4785 [D loss: 0.671144, acc.: 61.72%] [G loss: 0.902630]\n",
      "epoch:5 step:4786 [D loss: 0.663453, acc.: 57.81%] [G loss: 0.869526]\n",
      "epoch:5 step:4787 [D loss: 0.685717, acc.: 53.12%] [G loss: 0.860913]\n",
      "epoch:5 step:4788 [D loss: 0.647439, acc.: 67.19%] [G loss: 0.883161]\n",
      "epoch:5 step:4789 [D loss: 0.651774, acc.: 63.28%] [G loss: 0.801149]\n",
      "epoch:5 step:4790 [D loss: 0.645679, acc.: 62.50%] [G loss: 0.859305]\n",
      "epoch:5 step:4791 [D loss: 0.643468, acc.: 64.84%] [G loss: 0.853038]\n",
      "epoch:5 step:4792 [D loss: 0.626233, acc.: 62.50%] [G loss: 0.883120]\n",
      "epoch:5 step:4793 [D loss: 0.668509, acc.: 54.69%] [G loss: 0.874909]\n",
      "epoch:5 step:4794 [D loss: 0.622435, acc.: 66.41%] [G loss: 0.937788]\n",
      "epoch:5 step:4795 [D loss: 0.656803, acc.: 60.16%] [G loss: 0.832293]\n",
      "epoch:5 step:4796 [D loss: 0.628280, acc.: 60.16%] [G loss: 0.871178]\n",
      "epoch:5 step:4797 [D loss: 0.656229, acc.: 60.16%] [G loss: 0.814973]\n",
      "epoch:5 step:4798 [D loss: 0.704259, acc.: 54.69%] [G loss: 0.887632]\n",
      "epoch:5 step:4799 [D loss: 0.642105, acc.: 64.84%] [G loss: 0.882111]\n",
      "epoch:5 step:4800 [D loss: 0.684417, acc.: 59.38%] [G loss: 0.936313]\n",
      "##############\n",
      "[ 2.83919588  2.82711267  2.12872633  4.10908045  1.84428521 10.27426719\n",
      "  3.04560062  4.08431368  4.23280874  8.14868929]\n",
      "##########\n",
      "epoch:5 step:4801 [D loss: 0.694275, acc.: 47.66%] [G loss: 0.900209]\n",
      "epoch:5 step:4802 [D loss: 0.637027, acc.: 70.31%] [G loss: 0.852206]\n",
      "epoch:5 step:4803 [D loss: 0.673107, acc.: 56.25%] [G loss: 0.848039]\n",
      "epoch:5 step:4804 [D loss: 0.649035, acc.: 59.38%] [G loss: 0.877922]\n",
      "epoch:5 step:4805 [D loss: 0.685539, acc.: 57.03%] [G loss: 0.855816]\n",
      "epoch:5 step:4806 [D loss: 0.636189, acc.: 63.28%] [G loss: 0.865089]\n",
      "epoch:5 step:4807 [D loss: 0.690741, acc.: 54.69%] [G loss: 0.895469]\n",
      "epoch:5 step:4808 [D loss: 0.657264, acc.: 59.38%] [G loss: 0.903407]\n",
      "epoch:5 step:4809 [D loss: 0.688188, acc.: 56.25%] [G loss: 0.893556]\n",
      "epoch:5 step:4810 [D loss: 0.662227, acc.: 60.94%] [G loss: 0.885164]\n",
      "epoch:5 step:4811 [D loss: 0.666529, acc.: 55.47%] [G loss: 0.865679]\n",
      "epoch:5 step:4812 [D loss: 0.647205, acc.: 61.72%] [G loss: 0.833667]\n",
      "epoch:5 step:4813 [D loss: 0.677893, acc.: 58.59%] [G loss: 0.848587]\n",
      "epoch:5 step:4814 [D loss: 0.687719, acc.: 54.69%] [G loss: 0.867388]\n",
      "epoch:5 step:4815 [D loss: 0.647197, acc.: 57.81%] [G loss: 0.836817]\n",
      "epoch:5 step:4816 [D loss: 0.680081, acc.: 54.69%] [G loss: 0.813015]\n",
      "epoch:5 step:4817 [D loss: 0.688077, acc.: 57.03%] [G loss: 0.899894]\n",
      "epoch:5 step:4818 [D loss: 0.667926, acc.: 57.03%] [G loss: 0.872128]\n",
      "epoch:5 step:4819 [D loss: 0.651923, acc.: 57.03%] [G loss: 0.872870]\n",
      "epoch:5 step:4820 [D loss: 0.652598, acc.: 65.62%] [G loss: 0.842944]\n",
      "epoch:5 step:4821 [D loss: 0.700787, acc.: 50.78%] [G loss: 0.809448]\n",
      "epoch:5 step:4822 [D loss: 0.637663, acc.: 58.59%] [G loss: 0.839593]\n",
      "epoch:5 step:4823 [D loss: 0.636025, acc.: 67.19%] [G loss: 0.813562]\n",
      "epoch:5 step:4824 [D loss: 0.691947, acc.: 56.25%] [G loss: 0.806798]\n",
      "epoch:5 step:4825 [D loss: 0.687358, acc.: 54.69%] [G loss: 0.821311]\n",
      "epoch:5 step:4826 [D loss: 0.691338, acc.: 56.25%] [G loss: 0.815927]\n",
      "epoch:5 step:4827 [D loss: 0.639106, acc.: 59.38%] [G loss: 0.843164]\n",
      "epoch:5 step:4828 [D loss: 0.673814, acc.: 57.03%] [G loss: 0.877649]\n",
      "epoch:5 step:4829 [D loss: 0.647652, acc.: 61.72%] [G loss: 0.856202]\n",
      "epoch:5 step:4830 [D loss: 0.635416, acc.: 62.50%] [G loss: 0.806280]\n",
      "epoch:5 step:4831 [D loss: 0.664275, acc.: 62.50%] [G loss: 0.845082]\n",
      "epoch:5 step:4832 [D loss: 0.688440, acc.: 50.00%] [G loss: 0.828790]\n",
      "epoch:5 step:4833 [D loss: 0.680681, acc.: 54.69%] [G loss: 0.834701]\n",
      "epoch:5 step:4834 [D loss: 0.671800, acc.: 53.91%] [G loss: 0.839239]\n",
      "epoch:5 step:4835 [D loss: 0.655708, acc.: 60.16%] [G loss: 0.860526]\n",
      "epoch:5 step:4836 [D loss: 0.661234, acc.: 57.81%] [G loss: 0.849008]\n",
      "epoch:5 step:4837 [D loss: 0.706084, acc.: 50.78%] [G loss: 0.820905]\n",
      "epoch:5 step:4838 [D loss: 0.656345, acc.: 60.94%] [G loss: 0.838047]\n",
      "epoch:5 step:4839 [D loss: 0.648820, acc.: 62.50%] [G loss: 0.834550]\n",
      "epoch:5 step:4840 [D loss: 0.642486, acc.: 66.41%] [G loss: 0.831907]\n",
      "epoch:5 step:4841 [D loss: 0.638555, acc.: 65.62%] [G loss: 0.861984]\n",
      "epoch:5 step:4842 [D loss: 0.664527, acc.: 58.59%] [G loss: 0.852386]\n",
      "epoch:5 step:4843 [D loss: 0.655109, acc.: 60.16%] [G loss: 0.872762]\n",
      "epoch:5 step:4844 [D loss: 0.666596, acc.: 64.84%] [G loss: 0.822538]\n",
      "epoch:5 step:4845 [D loss: 0.693513, acc.: 54.69%] [G loss: 0.874801]\n",
      "epoch:5 step:4846 [D loss: 0.660946, acc.: 58.59%] [G loss: 0.858985]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4847 [D loss: 0.660702, acc.: 58.59%] [G loss: 0.883537]\n",
      "epoch:5 step:4848 [D loss: 0.722919, acc.: 50.00%] [G loss: 0.818977]\n",
      "epoch:5 step:4849 [D loss: 0.700631, acc.: 53.12%] [G loss: 0.869516]\n",
      "epoch:5 step:4850 [D loss: 0.629408, acc.: 61.72%] [G loss: 0.807867]\n",
      "epoch:5 step:4851 [D loss: 0.702994, acc.: 52.34%] [G loss: 0.822017]\n",
      "epoch:5 step:4852 [D loss: 0.668957, acc.: 60.16%] [G loss: 0.874205]\n",
      "epoch:5 step:4853 [D loss: 0.672109, acc.: 56.25%] [G loss: 0.905470]\n",
      "epoch:5 step:4854 [D loss: 0.682679, acc.: 55.47%] [G loss: 0.862267]\n",
      "epoch:5 step:4855 [D loss: 0.689931, acc.: 54.69%] [G loss: 0.870758]\n",
      "epoch:5 step:4856 [D loss: 0.670154, acc.: 56.25%] [G loss: 0.883306]\n",
      "epoch:5 step:4857 [D loss: 0.637866, acc.: 60.16%] [G loss: 0.838070]\n",
      "epoch:5 step:4858 [D loss: 0.695090, acc.: 55.47%] [G loss: 0.839742]\n",
      "epoch:5 step:4859 [D loss: 0.648334, acc.: 70.31%] [G loss: 0.814389]\n",
      "epoch:5 step:4860 [D loss: 0.665345, acc.: 53.91%] [G loss: 0.830956]\n",
      "epoch:5 step:4861 [D loss: 0.668054, acc.: 58.59%] [G loss: 0.837146]\n",
      "epoch:5 step:4862 [D loss: 0.668047, acc.: 52.34%] [G loss: 0.912156]\n",
      "epoch:5 step:4863 [D loss: 0.640885, acc.: 63.28%] [G loss: 0.858704]\n",
      "epoch:5 step:4864 [D loss: 0.682482, acc.: 56.25%] [G loss: 0.852753]\n",
      "epoch:5 step:4865 [D loss: 0.662668, acc.: 60.16%] [G loss: 0.832021]\n",
      "epoch:5 step:4866 [D loss: 0.668299, acc.: 60.94%] [G loss: 0.914270]\n",
      "epoch:5 step:4867 [D loss: 0.603634, acc.: 73.44%] [G loss: 0.855570]\n",
      "epoch:5 step:4868 [D loss: 0.694074, acc.: 50.78%] [G loss: 0.823673]\n",
      "epoch:5 step:4869 [D loss: 0.619293, acc.: 64.84%] [G loss: 0.821581]\n",
      "epoch:5 step:4870 [D loss: 0.672306, acc.: 51.56%] [G loss: 0.813155]\n",
      "epoch:5 step:4871 [D loss: 0.640972, acc.: 64.84%] [G loss: 0.879095]\n",
      "epoch:5 step:4872 [D loss: 0.634653, acc.: 67.19%] [G loss: 0.883479]\n",
      "epoch:5 step:4873 [D loss: 0.677243, acc.: 62.50%] [G loss: 0.870236]\n",
      "epoch:5 step:4874 [D loss: 0.658763, acc.: 58.59%] [G loss: 0.849245]\n",
      "epoch:5 step:4875 [D loss: 0.665312, acc.: 59.38%] [G loss: 0.879300]\n",
      "epoch:5 step:4876 [D loss: 0.645126, acc.: 67.97%] [G loss: 0.862121]\n",
      "epoch:5 step:4877 [D loss: 0.677791, acc.: 55.47%] [G loss: 0.887495]\n",
      "epoch:5 step:4878 [D loss: 0.655767, acc.: 62.50%] [G loss: 0.884373]\n",
      "epoch:5 step:4879 [D loss: 0.668838, acc.: 59.38%] [G loss: 0.873053]\n",
      "epoch:5 step:4880 [D loss: 0.670347, acc.: 55.47%] [G loss: 0.865913]\n",
      "epoch:5 step:4881 [D loss: 0.654759, acc.: 58.59%] [G loss: 0.878192]\n",
      "epoch:5 step:4882 [D loss: 0.684353, acc.: 57.03%] [G loss: 0.861836]\n",
      "epoch:5 step:4883 [D loss: 0.647405, acc.: 61.72%] [G loss: 0.834664]\n",
      "epoch:5 step:4884 [D loss: 0.641901, acc.: 65.62%] [G loss: 0.856494]\n",
      "epoch:5 step:4885 [D loss: 0.677420, acc.: 53.91%] [G loss: 0.911640]\n",
      "epoch:5 step:4886 [D loss: 0.628816, acc.: 65.62%] [G loss: 0.884647]\n",
      "epoch:5 step:4887 [D loss: 0.612618, acc.: 68.75%] [G loss: 0.885557]\n",
      "epoch:5 step:4888 [D loss: 0.656351, acc.: 60.16%] [G loss: 0.855475]\n",
      "epoch:5 step:4889 [D loss: 0.682055, acc.: 54.69%] [G loss: 0.805307]\n",
      "epoch:5 step:4890 [D loss: 0.637991, acc.: 63.28%] [G loss: 0.840742]\n",
      "epoch:5 step:4891 [D loss: 0.697057, acc.: 53.12%] [G loss: 0.842126]\n",
      "epoch:5 step:4892 [D loss: 0.690499, acc.: 50.78%] [G loss: 0.884864]\n",
      "epoch:5 step:4893 [D loss: 0.609944, acc.: 71.09%] [G loss: 0.916403]\n",
      "epoch:5 step:4894 [D loss: 0.675198, acc.: 56.25%] [G loss: 0.901991]\n",
      "epoch:5 step:4895 [D loss: 0.649074, acc.: 60.16%] [G loss: 0.913755]\n",
      "epoch:5 step:4896 [D loss: 0.630349, acc.: 67.97%] [G loss: 0.918602]\n",
      "epoch:5 step:4897 [D loss: 0.644707, acc.: 59.38%] [G loss: 0.890908]\n",
      "epoch:5 step:4898 [D loss: 0.665380, acc.: 55.47%] [G loss: 0.887187]\n",
      "epoch:5 step:4899 [D loss: 0.633190, acc.: 64.84%] [G loss: 0.881557]\n",
      "epoch:5 step:4900 [D loss: 0.647421, acc.: 58.59%] [G loss: 0.911987]\n",
      "epoch:5 step:4901 [D loss: 0.632200, acc.: 67.97%] [G loss: 0.867791]\n",
      "epoch:5 step:4902 [D loss: 0.683671, acc.: 50.78%] [G loss: 0.891515]\n",
      "epoch:5 step:4903 [D loss: 0.658334, acc.: 57.81%] [G loss: 0.862160]\n",
      "epoch:5 step:4904 [D loss: 0.681363, acc.: 57.03%] [G loss: 0.814811]\n",
      "epoch:5 step:4905 [D loss: 0.687428, acc.: 59.38%] [G loss: 0.837389]\n",
      "epoch:5 step:4906 [D loss: 0.655332, acc.: 58.59%] [G loss: 0.840118]\n",
      "epoch:5 step:4907 [D loss: 0.634977, acc.: 66.41%] [G loss: 0.837259]\n",
      "epoch:5 step:4908 [D loss: 0.653193, acc.: 61.72%] [G loss: 0.844874]\n",
      "epoch:5 step:4909 [D loss: 0.706331, acc.: 49.22%] [G loss: 0.865350]\n",
      "epoch:5 step:4910 [D loss: 0.628761, acc.: 64.84%] [G loss: 0.878791]\n",
      "epoch:5 step:4911 [D loss: 0.664836, acc.: 58.59%] [G loss: 0.854967]\n",
      "epoch:5 step:4912 [D loss: 0.676736, acc.: 56.25%] [G loss: 0.843669]\n",
      "epoch:5 step:4913 [D loss: 0.628249, acc.: 63.28%] [G loss: 0.855207]\n",
      "epoch:5 step:4914 [D loss: 0.622553, acc.: 66.41%] [G loss: 0.838077]\n",
      "epoch:5 step:4915 [D loss: 0.664859, acc.: 62.50%] [G loss: 0.856923]\n",
      "epoch:5 step:4916 [D loss: 0.676440, acc.: 61.72%] [G loss: 0.825601]\n",
      "epoch:5 step:4917 [D loss: 0.664850, acc.: 58.59%] [G loss: 0.879616]\n",
      "epoch:5 step:4918 [D loss: 0.659302, acc.: 59.38%] [G loss: 0.875255]\n",
      "epoch:5 step:4919 [D loss: 0.673293, acc.: 60.16%] [G loss: 0.866333]\n",
      "epoch:5 step:4920 [D loss: 0.683563, acc.: 53.12%] [G loss: 0.881390]\n",
      "epoch:5 step:4921 [D loss: 0.682771, acc.: 55.47%] [G loss: 0.907409]\n",
      "epoch:5 step:4922 [D loss: 0.687997, acc.: 56.25%] [G loss: 0.920557]\n",
      "epoch:5 step:4923 [D loss: 0.668468, acc.: 60.94%] [G loss: 0.863268]\n",
      "epoch:5 step:4924 [D loss: 0.693779, acc.: 56.25%] [G loss: 0.815203]\n",
      "epoch:5 step:4925 [D loss: 0.661076, acc.: 58.59%] [G loss: 0.853064]\n",
      "epoch:5 step:4926 [D loss: 0.676965, acc.: 54.69%] [G loss: 0.835290]\n",
      "epoch:5 step:4927 [D loss: 0.679679, acc.: 57.03%] [G loss: 0.831587]\n",
      "epoch:5 step:4928 [D loss: 0.698167, acc.: 56.25%] [G loss: 0.889395]\n",
      "epoch:5 step:4929 [D loss: 0.620286, acc.: 60.16%] [G loss: 0.858531]\n",
      "epoch:5 step:4930 [D loss: 0.698006, acc.: 54.69%] [G loss: 0.913742]\n",
      "epoch:5 step:4931 [D loss: 0.623726, acc.: 65.62%] [G loss: 0.871178]\n",
      "epoch:5 step:4932 [D loss: 0.667501, acc.: 55.47%] [G loss: 0.881238]\n",
      "epoch:5 step:4933 [D loss: 0.646498, acc.: 61.72%] [G loss: 0.922788]\n",
      "epoch:5 step:4934 [D loss: 0.676521, acc.: 53.91%] [G loss: 0.832561]\n",
      "epoch:5 step:4935 [D loss: 0.657590, acc.: 64.84%] [G loss: 0.871065]\n",
      "epoch:5 step:4936 [D loss: 0.666827, acc.: 60.16%] [G loss: 0.869629]\n",
      "epoch:5 step:4937 [D loss: 0.616476, acc.: 73.44%] [G loss: 0.876070]\n",
      "epoch:5 step:4938 [D loss: 0.678969, acc.: 56.25%] [G loss: 0.840165]\n",
      "epoch:5 step:4939 [D loss: 0.642213, acc.: 63.28%] [G loss: 0.839379]\n",
      "epoch:5 step:4940 [D loss: 0.645442, acc.: 65.62%] [G loss: 0.837735]\n",
      "epoch:5 step:4941 [D loss: 0.609941, acc.: 65.62%] [G loss: 0.829016]\n",
      "epoch:5 step:4942 [D loss: 0.643584, acc.: 64.06%] [G loss: 0.890705]\n",
      "epoch:5 step:4943 [D loss: 0.669899, acc.: 61.72%] [G loss: 0.832767]\n",
      "epoch:5 step:4944 [D loss: 0.656816, acc.: 59.38%] [G loss: 0.855939]\n",
      "epoch:5 step:4945 [D loss: 0.614914, acc.: 65.62%] [G loss: 0.844406]\n",
      "epoch:5 step:4946 [D loss: 0.624522, acc.: 67.19%] [G loss: 0.891754]\n",
      "epoch:5 step:4947 [D loss: 0.673509, acc.: 53.91%] [G loss: 0.865343]\n",
      "epoch:5 step:4948 [D loss: 0.694861, acc.: 58.59%] [G loss: 0.878802]\n",
      "epoch:5 step:4949 [D loss: 0.636125, acc.: 60.16%] [G loss: 0.849970]\n",
      "epoch:5 step:4950 [D loss: 0.632031, acc.: 67.19%] [G loss: 0.909208]\n",
      "epoch:5 step:4951 [D loss: 0.632562, acc.: 65.62%] [G loss: 0.874311]\n",
      "epoch:5 step:4952 [D loss: 0.634139, acc.: 67.97%] [G loss: 0.883103]\n",
      "epoch:5 step:4953 [D loss: 0.688877, acc.: 57.81%] [G loss: 0.863127]\n",
      "epoch:5 step:4954 [D loss: 0.654102, acc.: 60.16%] [G loss: 0.877413]\n",
      "epoch:5 step:4955 [D loss: 0.640980, acc.: 61.72%] [G loss: 0.896060]\n",
      "epoch:5 step:4956 [D loss: 0.619010, acc.: 71.09%] [G loss: 0.868582]\n",
      "epoch:5 step:4957 [D loss: 0.684637, acc.: 57.81%] [G loss: 0.876234]\n",
      "epoch:5 step:4958 [D loss: 0.663950, acc.: 57.03%] [G loss: 0.874957]\n",
      "epoch:5 step:4959 [D loss: 0.648608, acc.: 63.28%] [G loss: 0.888938]\n",
      "epoch:5 step:4960 [D loss: 0.673961, acc.: 58.59%] [G loss: 0.856881]\n",
      "epoch:5 step:4961 [D loss: 0.695756, acc.: 59.38%] [G loss: 0.854666]\n",
      "epoch:5 step:4962 [D loss: 0.650306, acc.: 61.72%] [G loss: 0.859796]\n",
      "epoch:5 step:4963 [D loss: 0.657460, acc.: 63.28%] [G loss: 0.844246]\n",
      "epoch:5 step:4964 [D loss: 0.670857, acc.: 62.50%] [G loss: 0.860884]\n",
      "epoch:5 step:4965 [D loss: 0.664565, acc.: 62.50%] [G loss: 0.866163]\n",
      "epoch:5 step:4966 [D loss: 0.666399, acc.: 58.59%] [G loss: 0.879044]\n",
      "epoch:5 step:4967 [D loss: 0.660187, acc.: 60.16%] [G loss: 0.881382]\n",
      "epoch:5 step:4968 [D loss: 0.631556, acc.: 60.16%] [G loss: 0.881513]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:4969 [D loss: 0.668215, acc.: 57.81%] [G loss: 0.905615]\n",
      "epoch:5 step:4970 [D loss: 0.658326, acc.: 60.94%] [G loss: 0.942624]\n",
      "epoch:5 step:4971 [D loss: 0.656806, acc.: 60.16%] [G loss: 0.838625]\n",
      "epoch:5 step:4972 [D loss: 0.681504, acc.: 58.59%] [G loss: 0.846326]\n",
      "epoch:5 step:4973 [D loss: 0.661079, acc.: 59.38%] [G loss: 0.843141]\n",
      "epoch:5 step:4974 [D loss: 0.655770, acc.: 57.81%] [G loss: 0.835922]\n",
      "epoch:5 step:4975 [D loss: 0.663865, acc.: 60.94%] [G loss: 0.836030]\n",
      "epoch:5 step:4976 [D loss: 0.674787, acc.: 56.25%] [G loss: 0.871647]\n",
      "epoch:5 step:4977 [D loss: 0.646508, acc.: 66.41%] [G loss: 0.884230]\n",
      "epoch:5 step:4978 [D loss: 0.672685, acc.: 58.59%] [G loss: 0.902942]\n",
      "epoch:5 step:4979 [D loss: 0.635278, acc.: 62.50%] [G loss: 0.888375]\n",
      "epoch:5 step:4980 [D loss: 0.669551, acc.: 56.25%] [G loss: 0.858205]\n",
      "epoch:5 step:4981 [D loss: 0.638077, acc.: 65.62%] [G loss: 0.887284]\n",
      "epoch:5 step:4982 [D loss: 0.676759, acc.: 57.03%] [G loss: 0.851031]\n",
      "epoch:5 step:4983 [D loss: 0.655265, acc.: 64.06%] [G loss: 0.894854]\n",
      "epoch:5 step:4984 [D loss: 0.680189, acc.: 57.81%] [G loss: 0.894426]\n",
      "epoch:5 step:4985 [D loss: 0.669242, acc.: 57.03%] [G loss: 0.881618]\n",
      "epoch:5 step:4986 [D loss: 0.683140, acc.: 50.00%] [G loss: 0.910075]\n",
      "epoch:5 step:4987 [D loss: 0.638837, acc.: 67.97%] [G loss: 0.933259]\n",
      "epoch:5 step:4988 [D loss: 0.680153, acc.: 64.06%] [G loss: 0.920573]\n",
      "epoch:5 step:4989 [D loss: 0.655363, acc.: 61.72%] [G loss: 0.872659]\n",
      "epoch:5 step:4990 [D loss: 0.699063, acc.: 46.88%] [G loss: 0.857024]\n",
      "epoch:5 step:4991 [D loss: 0.676545, acc.: 53.12%] [G loss: 0.864603]\n",
      "epoch:5 step:4992 [D loss: 0.644430, acc.: 64.06%] [G loss: 0.855291]\n",
      "epoch:5 step:4993 [D loss: 0.659170, acc.: 61.72%] [G loss: 0.870678]\n",
      "epoch:5 step:4994 [D loss: 0.631600, acc.: 62.50%] [G loss: 0.881411]\n",
      "epoch:5 step:4995 [D loss: 0.696215, acc.: 56.25%] [G loss: 0.879568]\n",
      "epoch:5 step:4996 [D loss: 0.656435, acc.: 56.25%] [G loss: 0.867586]\n",
      "epoch:5 step:4997 [D loss: 0.698801, acc.: 51.56%] [G loss: 0.867470]\n",
      "epoch:5 step:4998 [D loss: 0.675129, acc.: 58.59%] [G loss: 0.883034]\n",
      "epoch:5 step:4999 [D loss: 0.664849, acc.: 55.47%] [G loss: 0.835329]\n",
      "epoch:5 step:5000 [D loss: 0.647296, acc.: 60.94%] [G loss: 0.845451]\n",
      "##############\n",
      "[ 3.20972977  2.38472808  2.6144608   4.45918194  1.84034531 10.27426719\n",
      "  2.84894289  3.63420716  4.27827973  7.14868929]\n",
      "##########\n",
      "epoch:5 step:5001 [D loss: 0.665296, acc.: 50.78%] [G loss: 0.877541]\n",
      "epoch:5 step:5002 [D loss: 0.644368, acc.: 67.19%] [G loss: 0.840766]\n",
      "epoch:5 step:5003 [D loss: 0.710256, acc.: 54.69%] [G loss: 0.873463]\n",
      "epoch:5 step:5004 [D loss: 0.691089, acc.: 50.00%] [G loss: 0.897640]\n",
      "epoch:5 step:5005 [D loss: 0.688156, acc.: 53.91%] [G loss: 0.844811]\n",
      "epoch:5 step:5006 [D loss: 0.660523, acc.: 62.50%] [G loss: 0.879055]\n",
      "epoch:5 step:5007 [D loss: 0.694488, acc.: 50.78%] [G loss: 0.836362]\n",
      "epoch:5 step:5008 [D loss: 0.662281, acc.: 58.59%] [G loss: 0.854377]\n",
      "epoch:5 step:5009 [D loss: 0.657192, acc.: 57.03%] [G loss: 0.842322]\n",
      "epoch:5 step:5010 [D loss: 0.662382, acc.: 61.72%] [G loss: 0.861789]\n",
      "epoch:5 step:5011 [D loss: 0.657913, acc.: 60.16%] [G loss: 0.831248]\n",
      "epoch:5 step:5012 [D loss: 0.622467, acc.: 62.50%] [G loss: 0.832480]\n",
      "epoch:5 step:5013 [D loss: 0.617524, acc.: 68.75%] [G loss: 0.865745]\n",
      "epoch:5 step:5014 [D loss: 0.674572, acc.: 60.16%] [G loss: 0.882883]\n",
      "epoch:5 step:5015 [D loss: 0.651303, acc.: 64.06%] [G loss: 0.872804]\n",
      "epoch:5 step:5016 [D loss: 0.670874, acc.: 57.81%] [G loss: 0.857184]\n",
      "epoch:5 step:5017 [D loss: 0.639748, acc.: 61.72%] [G loss: 0.858034]\n",
      "epoch:5 step:5018 [D loss: 0.684398, acc.: 53.91%] [G loss: 0.855587]\n",
      "epoch:5 step:5019 [D loss: 0.661497, acc.: 59.38%] [G loss: 0.862609]\n",
      "epoch:5 step:5020 [D loss: 0.679084, acc.: 56.25%] [G loss: 0.874992]\n",
      "epoch:5 step:5021 [D loss: 0.635624, acc.: 64.06%] [G loss: 0.859304]\n",
      "epoch:5 step:5022 [D loss: 0.648476, acc.: 58.59%] [G loss: 0.832140]\n",
      "epoch:5 step:5023 [D loss: 0.662338, acc.: 58.59%] [G loss: 0.895488]\n",
      "epoch:5 step:5024 [D loss: 0.623443, acc.: 69.53%] [G loss: 0.926911]\n",
      "epoch:5 step:5025 [D loss: 0.673081, acc.: 54.69%] [G loss: 0.880025]\n",
      "epoch:5 step:5026 [D loss: 0.638656, acc.: 64.84%] [G loss: 0.879455]\n",
      "epoch:5 step:5027 [D loss: 0.675449, acc.: 53.91%] [G loss: 0.843392]\n",
      "epoch:5 step:5028 [D loss: 0.704036, acc.: 51.56%] [G loss: 0.865354]\n",
      "epoch:5 step:5029 [D loss: 0.672952, acc.: 59.38%] [G loss: 0.829308]\n",
      "epoch:5 step:5030 [D loss: 0.674678, acc.: 57.03%] [G loss: 0.772189]\n",
      "epoch:5 step:5031 [D loss: 0.680607, acc.: 54.69%] [G loss: 0.803602]\n",
      "epoch:5 step:5032 [D loss: 0.636001, acc.: 67.19%] [G loss: 0.823464]\n",
      "epoch:5 step:5033 [D loss: 0.647090, acc.: 64.06%] [G loss: 0.818174]\n",
      "epoch:5 step:5034 [D loss: 0.623144, acc.: 67.19%] [G loss: 0.893585]\n",
      "epoch:5 step:5035 [D loss: 0.656258, acc.: 60.94%] [G loss: 0.836074]\n",
      "epoch:5 step:5036 [D loss: 0.649464, acc.: 61.72%] [G loss: 0.905289]\n",
      "epoch:5 step:5037 [D loss: 0.693598, acc.: 50.00%] [G loss: 0.785024]\n",
      "epoch:5 step:5038 [D loss: 0.666168, acc.: 58.59%] [G loss: 0.884174]\n",
      "epoch:5 step:5039 [D loss: 0.641433, acc.: 60.16%] [G loss: 0.850223]\n",
      "epoch:5 step:5040 [D loss: 0.642005, acc.: 61.72%] [G loss: 0.780528]\n",
      "epoch:5 step:5041 [D loss: 0.660971, acc.: 60.94%] [G loss: 0.888868]\n",
      "epoch:5 step:5042 [D loss: 0.680515, acc.: 59.38%] [G loss: 0.881662]\n",
      "epoch:5 step:5043 [D loss: 0.610854, acc.: 71.09%] [G loss: 0.893822]\n",
      "epoch:5 step:5044 [D loss: 0.649824, acc.: 62.50%] [G loss: 0.875846]\n",
      "epoch:5 step:5045 [D loss: 0.657457, acc.: 57.03%] [G loss: 0.903224]\n",
      "epoch:5 step:5046 [D loss: 0.659823, acc.: 63.28%] [G loss: 0.891503]\n",
      "epoch:5 step:5047 [D loss: 0.616555, acc.: 67.19%] [G loss: 0.834143]\n",
      "epoch:5 step:5048 [D loss: 0.634164, acc.: 62.50%] [G loss: 0.841915]\n",
      "epoch:5 step:5049 [D loss: 0.700242, acc.: 57.03%] [G loss: 0.873118]\n",
      "epoch:5 step:5050 [D loss: 0.657915, acc.: 59.38%] [G loss: 0.891411]\n",
      "epoch:5 step:5051 [D loss: 0.638396, acc.: 59.38%] [G loss: 0.908067]\n",
      "epoch:5 step:5052 [D loss: 0.679159, acc.: 57.03%] [G loss: 0.910445]\n",
      "epoch:5 step:5053 [D loss: 0.673024, acc.: 54.69%] [G loss: 0.883065]\n",
      "epoch:5 step:5054 [D loss: 0.672663, acc.: 55.47%] [G loss: 0.835009]\n",
      "epoch:5 step:5055 [D loss: 0.669082, acc.: 57.03%] [G loss: 0.859862]\n",
      "epoch:5 step:5056 [D loss: 0.671768, acc.: 58.59%] [G loss: 0.813719]\n",
      "epoch:5 step:5057 [D loss: 0.656526, acc.: 56.25%] [G loss: 0.875622]\n",
      "epoch:5 step:5058 [D loss: 0.652159, acc.: 60.94%] [G loss: 0.875170]\n",
      "epoch:5 step:5059 [D loss: 0.662431, acc.: 57.81%] [G loss: 0.896783]\n",
      "epoch:5 step:5060 [D loss: 0.688122, acc.: 55.47%] [G loss: 0.855891]\n",
      "epoch:5 step:5061 [D loss: 0.712346, acc.: 47.66%] [G loss: 0.873531]\n",
      "epoch:5 step:5062 [D loss: 0.664351, acc.: 60.16%] [G loss: 0.812876]\n",
      "epoch:5 step:5063 [D loss: 0.645900, acc.: 63.28%] [G loss: 0.909138]\n",
      "epoch:5 step:5064 [D loss: 0.652942, acc.: 62.50%] [G loss: 0.840040]\n",
      "epoch:5 step:5065 [D loss: 0.685930, acc.: 57.81%] [G loss: 0.855826]\n",
      "epoch:5 step:5066 [D loss: 0.662639, acc.: 54.69%] [G loss: 0.855448]\n",
      "epoch:5 step:5067 [D loss: 0.667756, acc.: 55.47%] [G loss: 0.841081]\n",
      "epoch:5 step:5068 [D loss: 0.627160, acc.: 64.84%] [G loss: 0.857457]\n",
      "epoch:5 step:5069 [D loss: 0.705286, acc.: 56.25%] [G loss: 0.815973]\n",
      "epoch:5 step:5070 [D loss: 0.688148, acc.: 49.22%] [G loss: 0.840884]\n",
      "epoch:5 step:5071 [D loss: 0.690956, acc.: 51.56%] [G loss: 0.853281]\n",
      "epoch:5 step:5072 [D loss: 0.654603, acc.: 57.81%] [G loss: 0.809343]\n",
      "epoch:5 step:5073 [D loss: 0.663625, acc.: 54.69%] [G loss: 0.852963]\n",
      "epoch:5 step:5074 [D loss: 0.658430, acc.: 60.94%] [G loss: 0.840212]\n",
      "epoch:5 step:5075 [D loss: 0.668560, acc.: 58.59%] [G loss: 0.835119]\n",
      "epoch:5 step:5076 [D loss: 0.675086, acc.: 57.03%] [G loss: 0.851657]\n",
      "epoch:5 step:5077 [D loss: 0.683036, acc.: 53.91%] [G loss: 0.884548]\n",
      "epoch:5 step:5078 [D loss: 0.675043, acc.: 53.12%] [G loss: 0.873469]\n",
      "epoch:5 step:5079 [D loss: 0.661340, acc.: 53.91%] [G loss: 0.903064]\n",
      "epoch:5 step:5080 [D loss: 0.662775, acc.: 60.94%] [G loss: 0.856341]\n",
      "epoch:5 step:5081 [D loss: 0.656770, acc.: 64.06%] [G loss: 0.878270]\n",
      "epoch:5 step:5082 [D loss: 0.695684, acc.: 52.34%] [G loss: 0.804440]\n",
      "epoch:5 step:5083 [D loss: 0.656061, acc.: 60.16%] [G loss: 0.854470]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5084 [D loss: 0.646474, acc.: 61.72%] [G loss: 0.858767]\n",
      "epoch:5 step:5085 [D loss: 0.671424, acc.: 63.28%] [G loss: 0.858656]\n",
      "epoch:5 step:5086 [D loss: 0.623639, acc.: 70.31%] [G loss: 0.874580]\n",
      "epoch:5 step:5087 [D loss: 0.627148, acc.: 67.19%] [G loss: 0.928929]\n",
      "epoch:5 step:5088 [D loss: 0.668745, acc.: 56.25%] [G loss: 0.848568]\n",
      "epoch:5 step:5089 [D loss: 0.712019, acc.: 50.78%] [G loss: 0.869904]\n",
      "epoch:5 step:5090 [D loss: 0.684675, acc.: 48.44%] [G loss: 0.852520]\n",
      "epoch:5 step:5091 [D loss: 0.637461, acc.: 61.72%] [G loss: 0.844045]\n",
      "epoch:5 step:5092 [D loss: 0.684938, acc.: 60.94%] [G loss: 0.817853]\n",
      "epoch:5 step:5093 [D loss: 0.654232, acc.: 54.69%] [G loss: 0.825824]\n",
      "epoch:5 step:5094 [D loss: 0.696940, acc.: 53.91%] [G loss: 0.842636]\n",
      "epoch:5 step:5095 [D loss: 0.664656, acc.: 64.84%] [G loss: 0.832430]\n",
      "epoch:5 step:5096 [D loss: 0.659200, acc.: 58.59%] [G loss: 0.873142]\n",
      "epoch:5 step:5097 [D loss: 0.687352, acc.: 59.38%] [G loss: 0.821101]\n",
      "epoch:5 step:5098 [D loss: 0.680888, acc.: 56.25%] [G loss: 0.842854]\n",
      "epoch:5 step:5099 [D loss: 0.648208, acc.: 65.62%] [G loss: 0.862062]\n",
      "epoch:5 step:5100 [D loss: 0.659992, acc.: 62.50%] [G loss: 0.879387]\n",
      "epoch:5 step:5101 [D loss: 0.676236, acc.: 55.47%] [G loss: 0.856025]\n",
      "epoch:5 step:5102 [D loss: 0.645538, acc.: 54.69%] [G loss: 0.918781]\n",
      "epoch:5 step:5103 [D loss: 0.700579, acc.: 51.56%] [G loss: 0.906626]\n",
      "epoch:5 step:5104 [D loss: 0.647197, acc.: 60.16%] [G loss: 0.871055]\n",
      "epoch:5 step:5105 [D loss: 0.659346, acc.: 59.38%] [G loss: 0.824433]\n",
      "epoch:5 step:5106 [D loss: 0.664742, acc.: 57.81%] [G loss: 0.826444]\n",
      "epoch:5 step:5107 [D loss: 0.653078, acc.: 58.59%] [G loss: 0.823956]\n",
      "epoch:5 step:5108 [D loss: 0.654287, acc.: 60.94%] [G loss: 0.847951]\n",
      "epoch:5 step:5109 [D loss: 0.673948, acc.: 55.47%] [G loss: 0.891874]\n",
      "epoch:5 step:5110 [D loss: 0.644431, acc.: 63.28%] [G loss: 0.829488]\n",
      "epoch:5 step:5111 [D loss: 0.631903, acc.: 65.62%] [G loss: 0.824137]\n",
      "epoch:5 step:5112 [D loss: 0.657642, acc.: 60.16%] [G loss: 0.800141]\n",
      "epoch:5 step:5113 [D loss: 0.677848, acc.: 50.78%] [G loss: 0.878275]\n",
      "epoch:5 step:5114 [D loss: 0.668129, acc.: 62.50%] [G loss: 0.832517]\n",
      "epoch:5 step:5115 [D loss: 0.681808, acc.: 52.34%] [G loss: 0.848830]\n",
      "epoch:5 step:5116 [D loss: 0.667031, acc.: 57.81%] [G loss: 0.849516]\n",
      "epoch:5 step:5117 [D loss: 0.660531, acc.: 53.12%] [G loss: 0.809513]\n",
      "epoch:5 step:5118 [D loss: 0.675542, acc.: 60.16%] [G loss: 0.802967]\n",
      "epoch:5 step:5119 [D loss: 0.682167, acc.: 51.56%] [G loss: 0.813386]\n",
      "epoch:5 step:5120 [D loss: 0.639633, acc.: 64.06%] [G loss: 0.844872]\n",
      "epoch:5 step:5121 [D loss: 0.676655, acc.: 59.38%] [G loss: 0.880997]\n",
      "epoch:5 step:5122 [D loss: 0.669919, acc.: 53.12%] [G loss: 0.881802]\n",
      "epoch:5 step:5123 [D loss: 0.679397, acc.: 56.25%] [G loss: 0.875072]\n",
      "epoch:5 step:5124 [D loss: 0.651870, acc.: 60.16%] [G loss: 0.881638]\n",
      "epoch:5 step:5125 [D loss: 0.682358, acc.: 53.12%] [G loss: 0.864670]\n",
      "epoch:5 step:5126 [D loss: 0.660934, acc.: 61.72%] [G loss: 0.842777]\n",
      "epoch:5 step:5127 [D loss: 0.694267, acc.: 48.44%] [G loss: 0.810497]\n",
      "epoch:5 step:5128 [D loss: 0.636315, acc.: 64.84%] [G loss: 0.878486]\n",
      "epoch:5 step:5129 [D loss: 0.621122, acc.: 63.28%] [G loss: 0.852645]\n",
      "epoch:5 step:5130 [D loss: 0.669756, acc.: 54.69%] [G loss: 0.855306]\n",
      "epoch:5 step:5131 [D loss: 0.674734, acc.: 50.00%] [G loss: 0.896526]\n",
      "epoch:5 step:5132 [D loss: 0.636506, acc.: 60.94%] [G loss: 0.895401]\n",
      "epoch:5 step:5133 [D loss: 0.669627, acc.: 60.16%] [G loss: 0.905254]\n",
      "epoch:5 step:5134 [D loss: 0.660788, acc.: 56.25%] [G loss: 0.896816]\n",
      "epoch:5 step:5135 [D loss: 0.651150, acc.: 62.50%] [G loss: 0.903690]\n",
      "epoch:5 step:5136 [D loss: 0.632783, acc.: 62.50%] [G loss: 0.881401]\n",
      "epoch:5 step:5137 [D loss: 0.643708, acc.: 60.16%] [G loss: 0.932018]\n",
      "epoch:5 step:5138 [D loss: 0.642171, acc.: 65.62%] [G loss: 0.870061]\n",
      "epoch:5 step:5139 [D loss: 0.673786, acc.: 60.16%] [G loss: 0.867772]\n",
      "epoch:5 step:5140 [D loss: 0.636783, acc.: 67.97%] [G loss: 0.876320]\n",
      "epoch:5 step:5141 [D loss: 0.649264, acc.: 58.59%] [G loss: 0.945956]\n",
      "epoch:5 step:5142 [D loss: 0.669786, acc.: 57.03%] [G loss: 0.849662]\n",
      "epoch:5 step:5143 [D loss: 0.649795, acc.: 61.72%] [G loss: 0.885077]\n",
      "epoch:5 step:5144 [D loss: 0.617431, acc.: 60.94%] [G loss: 0.872772]\n",
      "epoch:5 step:5145 [D loss: 0.680391, acc.: 53.91%] [G loss: 0.826114]\n",
      "epoch:5 step:5146 [D loss: 0.687940, acc.: 57.03%] [G loss: 0.843056]\n",
      "epoch:5 step:5147 [D loss: 0.665850, acc.: 50.78%] [G loss: 0.875782]\n",
      "epoch:5 step:5148 [D loss: 0.660408, acc.: 63.28%] [G loss: 0.866263]\n",
      "epoch:5 step:5149 [D loss: 0.691045, acc.: 54.69%] [G loss: 0.891083]\n",
      "epoch:5 step:5150 [D loss: 0.681091, acc.: 57.03%] [G loss: 0.841276]\n",
      "epoch:5 step:5151 [D loss: 0.642049, acc.: 65.62%] [G loss: 0.804107]\n",
      "epoch:5 step:5152 [D loss: 0.670779, acc.: 54.69%] [G loss: 0.861389]\n",
      "epoch:5 step:5153 [D loss: 0.670798, acc.: 58.59%] [G loss: 0.868461]\n",
      "epoch:5 step:5154 [D loss: 0.692381, acc.: 56.25%] [G loss: 0.844608]\n",
      "epoch:5 step:5155 [D loss: 0.715461, acc.: 53.12%] [G loss: 0.865533]\n",
      "epoch:5 step:5156 [D loss: 0.671420, acc.: 57.03%] [G loss: 0.895977]\n",
      "epoch:5 step:5157 [D loss: 0.625105, acc.: 61.72%] [G loss: 0.897236]\n",
      "epoch:5 step:5158 [D loss: 0.670801, acc.: 56.25%] [G loss: 0.905844]\n",
      "epoch:5 step:5159 [D loss: 0.666155, acc.: 57.03%] [G loss: 0.891618]\n",
      "epoch:5 step:5160 [D loss: 0.645442, acc.: 63.28%] [G loss: 0.954329]\n",
      "epoch:5 step:5161 [D loss: 0.674782, acc.: 57.03%] [G loss: 0.876216]\n",
      "epoch:5 step:5162 [D loss: 0.698332, acc.: 57.03%] [G loss: 0.913690]\n",
      "epoch:5 step:5163 [D loss: 0.667688, acc.: 61.72%] [G loss: 0.802052]\n",
      "epoch:5 step:5164 [D loss: 0.638742, acc.: 66.41%] [G loss: 0.865564]\n",
      "epoch:5 step:5165 [D loss: 0.686228, acc.: 53.12%] [G loss: 0.851598]\n",
      "epoch:5 step:5166 [D loss: 0.656195, acc.: 57.81%] [G loss: 0.922673]\n",
      "epoch:5 step:5167 [D loss: 0.610013, acc.: 64.84%] [G loss: 0.870443]\n",
      "epoch:5 step:5168 [D loss: 0.718128, acc.: 48.44%] [G loss: 0.880005]\n",
      "epoch:5 step:5169 [D loss: 0.641146, acc.: 67.97%] [G loss: 0.880445]\n",
      "epoch:5 step:5170 [D loss: 0.687527, acc.: 54.69%] [G loss: 0.850937]\n",
      "epoch:5 step:5171 [D loss: 0.668688, acc.: 58.59%] [G loss: 0.790100]\n",
      "epoch:5 step:5172 [D loss: 0.658270, acc.: 59.38%] [G loss: 0.833591]\n",
      "epoch:5 step:5173 [D loss: 0.651899, acc.: 57.81%] [G loss: 0.852352]\n",
      "epoch:5 step:5174 [D loss: 0.701887, acc.: 53.12%] [G loss: 0.843982]\n",
      "epoch:5 step:5175 [D loss: 0.676770, acc.: 56.25%] [G loss: 0.892322]\n",
      "epoch:5 step:5176 [D loss: 0.613751, acc.: 71.09%] [G loss: 0.879381]\n",
      "epoch:5 step:5177 [D loss: 0.664705, acc.: 55.47%] [G loss: 0.830257]\n",
      "epoch:5 step:5178 [D loss: 0.659354, acc.: 58.59%] [G loss: 0.845386]\n",
      "epoch:5 step:5179 [D loss: 0.610513, acc.: 67.19%] [G loss: 0.873101]\n",
      "epoch:5 step:5180 [D loss: 0.698330, acc.: 55.47%] [G loss: 0.856436]\n",
      "epoch:5 step:5181 [D loss: 0.643028, acc.: 60.94%] [G loss: 0.850226]\n",
      "epoch:5 step:5182 [D loss: 0.622177, acc.: 67.19%] [G loss: 0.858178]\n",
      "epoch:5 step:5183 [D loss: 0.658254, acc.: 63.28%] [G loss: 0.916589]\n",
      "epoch:5 step:5184 [D loss: 0.664480, acc.: 58.59%] [G loss: 0.890375]\n",
      "epoch:5 step:5185 [D loss: 0.668490, acc.: 56.25%] [G loss: 0.884924]\n",
      "epoch:5 step:5186 [D loss: 0.647207, acc.: 63.28%] [G loss: 0.902026]\n",
      "epoch:5 step:5187 [D loss: 0.642730, acc.: 67.19%] [G loss: 0.903304]\n",
      "epoch:5 step:5188 [D loss: 0.643051, acc.: 61.72%] [G loss: 0.874903]\n",
      "epoch:5 step:5189 [D loss: 0.640155, acc.: 67.19%] [G loss: 0.834769]\n",
      "epoch:5 step:5190 [D loss: 0.653607, acc.: 63.28%] [G loss: 0.871300]\n",
      "epoch:5 step:5191 [D loss: 0.653718, acc.: 60.94%] [G loss: 0.887495]\n",
      "epoch:5 step:5192 [D loss: 0.648625, acc.: 58.59%] [G loss: 0.911360]\n",
      "epoch:5 step:5193 [D loss: 0.668229, acc.: 57.81%] [G loss: 0.905679]\n",
      "epoch:5 step:5194 [D loss: 0.643265, acc.: 63.28%] [G loss: 0.903469]\n",
      "epoch:5 step:5195 [D loss: 0.630637, acc.: 61.72%] [G loss: 0.888555]\n",
      "epoch:5 step:5196 [D loss: 0.666066, acc.: 58.59%] [G loss: 0.913972]\n",
      "epoch:5 step:5197 [D loss: 0.661694, acc.: 60.94%] [G loss: 0.840875]\n",
      "epoch:5 step:5198 [D loss: 0.659415, acc.: 60.94%] [G loss: 0.916864]\n",
      "epoch:5 step:5199 [D loss: 0.686445, acc.: 54.69%] [G loss: 0.894236]\n",
      "epoch:5 step:5200 [D loss: 0.681342, acc.: 53.12%] [G loss: 0.880941]\n",
      "##############\n",
      "[ 3.26314604  2.82670657  2.4464321   4.31111472  1.87009141 10.27426719\n",
      "  2.98674137  4.04530706  4.41814685  7.14868929]\n",
      "##########\n",
      "epoch:5 step:5201 [D loss: 0.645452, acc.: 62.50%] [G loss: 0.877276]\n",
      "epoch:5 step:5202 [D loss: 0.652793, acc.: 58.59%] [G loss: 0.866162]\n",
      "epoch:5 step:5203 [D loss: 0.677545, acc.: 58.59%] [G loss: 0.863555]\n",
      "epoch:5 step:5204 [D loss: 0.654788, acc.: 59.38%] [G loss: 0.884713]\n",
      "epoch:5 step:5205 [D loss: 0.668165, acc.: 64.06%] [G loss: 0.861831]\n",
      "epoch:5 step:5206 [D loss: 0.681681, acc.: 51.56%] [G loss: 0.952512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5207 [D loss: 0.622970, acc.: 65.62%] [G loss: 0.859494]\n",
      "epoch:5 step:5208 [D loss: 0.635051, acc.: 66.41%] [G loss: 0.897855]\n",
      "epoch:5 step:5209 [D loss: 0.652860, acc.: 63.28%] [G loss: 0.928626]\n",
      "epoch:5 step:5210 [D loss: 0.669109, acc.: 58.59%] [G loss: 0.911147]\n",
      "epoch:5 step:5211 [D loss: 0.681006, acc.: 57.81%] [G loss: 0.861277]\n",
      "epoch:5 step:5212 [D loss: 0.650634, acc.: 60.94%] [G loss: 0.894042]\n",
      "epoch:5 step:5213 [D loss: 0.660379, acc.: 64.06%] [G loss: 0.890760]\n",
      "epoch:5 step:5214 [D loss: 0.652946, acc.: 60.94%] [G loss: 0.910434]\n",
      "epoch:5 step:5215 [D loss: 0.650372, acc.: 60.16%] [G loss: 0.851485]\n",
      "epoch:5 step:5216 [D loss: 0.639985, acc.: 63.28%] [G loss: 0.868502]\n",
      "epoch:5 step:5217 [D loss: 0.614281, acc.: 66.41%] [G loss: 0.862004]\n",
      "epoch:5 step:5218 [D loss: 0.702990, acc.: 52.34%] [G loss: 0.879019]\n",
      "epoch:5 step:5219 [D loss: 0.659261, acc.: 62.50%] [G loss: 0.872251]\n",
      "epoch:5 step:5220 [D loss: 0.688281, acc.: 57.81%] [G loss: 0.826091]\n",
      "epoch:5 step:5221 [D loss: 0.671988, acc.: 57.03%] [G loss: 0.853371]\n",
      "epoch:5 step:5222 [D loss: 0.695228, acc.: 57.03%] [G loss: 0.847480]\n",
      "epoch:5 step:5223 [D loss: 0.668968, acc.: 57.81%] [G loss: 0.819503]\n",
      "epoch:5 step:5224 [D loss: 0.672359, acc.: 47.66%] [G loss: 0.868497]\n",
      "epoch:5 step:5225 [D loss: 0.663367, acc.: 57.81%] [G loss: 0.894801]\n",
      "epoch:5 step:5226 [D loss: 0.664067, acc.: 56.25%] [G loss: 0.919677]\n",
      "epoch:5 step:5227 [D loss: 0.641415, acc.: 65.62%] [G loss: 0.904280]\n",
      "epoch:5 step:5228 [D loss: 0.668391, acc.: 58.59%] [G loss: 0.908561]\n",
      "epoch:5 step:5229 [D loss: 0.681725, acc.: 51.56%] [G loss: 0.925431]\n",
      "epoch:5 step:5230 [D loss: 0.676808, acc.: 54.69%] [G loss: 0.884351]\n",
      "epoch:5 step:5231 [D loss: 0.698664, acc.: 54.69%] [G loss: 0.907895]\n",
      "epoch:5 step:5232 [D loss: 0.641296, acc.: 68.75%] [G loss: 0.889468]\n",
      "epoch:5 step:5233 [D loss: 0.643627, acc.: 61.72%] [G loss: 0.861001]\n",
      "epoch:5 step:5234 [D loss: 0.696815, acc.: 54.69%] [G loss: 0.878950]\n",
      "epoch:5 step:5235 [D loss: 0.656623, acc.: 59.38%] [G loss: 0.827490]\n",
      "epoch:5 step:5236 [D loss: 0.660119, acc.: 60.94%] [G loss: 0.868082]\n",
      "epoch:5 step:5237 [D loss: 0.656853, acc.: 60.16%] [G loss: 0.862558]\n",
      "epoch:5 step:5238 [D loss: 0.689915, acc.: 56.25%] [G loss: 0.851852]\n",
      "epoch:5 step:5239 [D loss: 0.648564, acc.: 57.81%] [G loss: 0.858250]\n",
      "epoch:5 step:5240 [D loss: 0.658201, acc.: 55.47%] [G loss: 0.854484]\n",
      "epoch:5 step:5241 [D loss: 0.665094, acc.: 56.25%] [G loss: 0.839281]\n",
      "epoch:5 step:5242 [D loss: 0.639339, acc.: 62.50%] [G loss: 0.793698]\n",
      "epoch:5 step:5243 [D loss: 0.662812, acc.: 55.47%] [G loss: 0.810271]\n",
      "epoch:5 step:5244 [D loss: 0.659298, acc.: 58.59%] [G loss: 0.849852]\n",
      "epoch:5 step:5245 [D loss: 0.643253, acc.: 60.16%] [G loss: 0.841299]\n",
      "epoch:5 step:5246 [D loss: 0.638254, acc.: 63.28%] [G loss: 0.814405]\n",
      "epoch:5 step:5247 [D loss: 0.629264, acc.: 62.50%] [G loss: 0.839349]\n",
      "epoch:5 step:5248 [D loss: 0.643389, acc.: 63.28%] [G loss: 0.871490]\n",
      "epoch:5 step:5249 [D loss: 0.643213, acc.: 60.16%] [G loss: 0.873423]\n",
      "epoch:5 step:5250 [D loss: 0.623734, acc.: 65.62%] [G loss: 0.862862]\n",
      "epoch:5 step:5251 [D loss: 0.660727, acc.: 55.47%] [G loss: 0.849699]\n",
      "epoch:5 step:5252 [D loss: 0.655807, acc.: 56.25%] [G loss: 0.911598]\n",
      "epoch:5 step:5253 [D loss: 0.695524, acc.: 57.81%] [G loss: 0.869478]\n",
      "epoch:5 step:5254 [D loss: 0.641817, acc.: 64.06%] [G loss: 0.895959]\n",
      "epoch:5 step:5255 [D loss: 0.688817, acc.: 55.47%] [G loss: 0.892199]\n",
      "epoch:5 step:5256 [D loss: 0.677042, acc.: 53.12%] [G loss: 0.861654]\n",
      "epoch:5 step:5257 [D loss: 0.667986, acc.: 58.59%] [G loss: 0.860101]\n",
      "epoch:5 step:5258 [D loss: 0.693230, acc.: 47.66%] [G loss: 0.918675]\n",
      "epoch:5 step:5259 [D loss: 0.675088, acc.: 57.81%] [G loss: 0.832985]\n",
      "epoch:5 step:5260 [D loss: 0.678892, acc.: 52.34%] [G loss: 0.851151]\n",
      "epoch:5 step:5261 [D loss: 0.667773, acc.: 60.16%] [G loss: 0.862132]\n",
      "epoch:5 step:5262 [D loss: 0.615427, acc.: 67.19%] [G loss: 0.950477]\n",
      "epoch:5 step:5263 [D loss: 0.683957, acc.: 56.25%] [G loss: 0.885294]\n",
      "epoch:5 step:5264 [D loss: 0.663055, acc.: 54.69%] [G loss: 0.882651]\n",
      "epoch:5 step:5265 [D loss: 0.665548, acc.: 58.59%] [G loss: 0.876499]\n",
      "epoch:5 step:5266 [D loss: 0.636822, acc.: 60.94%] [G loss: 0.861651]\n",
      "epoch:5 step:5267 [D loss: 0.630375, acc.: 62.50%] [G loss: 0.913279]\n",
      "epoch:5 step:5268 [D loss: 0.662626, acc.: 60.94%] [G loss: 0.909589]\n",
      "epoch:5 step:5269 [D loss: 0.628985, acc.: 66.41%] [G loss: 0.898899]\n",
      "epoch:5 step:5270 [D loss: 0.648436, acc.: 63.28%] [G loss: 0.858408]\n",
      "epoch:5 step:5271 [D loss: 0.665433, acc.: 62.50%] [G loss: 0.843255]\n",
      "epoch:5 step:5272 [D loss: 0.658135, acc.: 59.38%] [G loss: 0.885202]\n",
      "epoch:5 step:5273 [D loss: 0.658992, acc.: 56.25%] [G loss: 0.841134]\n",
      "epoch:5 step:5274 [D loss: 0.627540, acc.: 64.84%] [G loss: 0.839726]\n",
      "epoch:5 step:5275 [D loss: 0.646382, acc.: 64.84%] [G loss: 0.833584]\n",
      "epoch:5 step:5276 [D loss: 0.667558, acc.: 54.69%] [G loss: 0.829274]\n",
      "epoch:5 step:5277 [D loss: 0.620250, acc.: 65.62%] [G loss: 0.847879]\n",
      "epoch:5 step:5278 [D loss: 0.669564, acc.: 57.81%] [G loss: 0.845728]\n",
      "epoch:5 step:5279 [D loss: 0.646532, acc.: 59.38%] [G loss: 0.881337]\n",
      "epoch:5 step:5280 [D loss: 0.649966, acc.: 59.38%] [G loss: 0.882885]\n",
      "epoch:5 step:5281 [D loss: 0.640182, acc.: 64.06%] [G loss: 0.839050]\n",
      "epoch:5 step:5282 [D loss: 0.693848, acc.: 50.78%] [G loss: 0.896613]\n",
      "epoch:5 step:5283 [D loss: 0.657692, acc.: 64.06%] [G loss: 0.868931]\n",
      "epoch:5 step:5284 [D loss: 0.671341, acc.: 55.47%] [G loss: 0.883876]\n",
      "epoch:5 step:5285 [D loss: 0.661747, acc.: 59.38%] [G loss: 0.901511]\n",
      "epoch:5 step:5286 [D loss: 0.647302, acc.: 57.03%] [G loss: 0.916039]\n",
      "epoch:5 step:5287 [D loss: 0.639909, acc.: 61.72%] [G loss: 0.924731]\n",
      "epoch:5 step:5288 [D loss: 0.636495, acc.: 60.16%] [G loss: 0.890914]\n",
      "epoch:5 step:5289 [D loss: 0.654661, acc.: 61.72%] [G loss: 0.908187]\n",
      "epoch:5 step:5290 [D loss: 0.651430, acc.: 63.28%] [G loss: 0.855730]\n",
      "epoch:5 step:5291 [D loss: 0.624259, acc.: 64.06%] [G loss: 0.858005]\n",
      "epoch:5 step:5292 [D loss: 0.681531, acc.: 54.69%] [G loss: 0.880864]\n",
      "epoch:5 step:5293 [D loss: 0.657319, acc.: 59.38%] [G loss: 0.849493]\n",
      "epoch:5 step:5294 [D loss: 0.651535, acc.: 57.81%] [G loss: 0.858976]\n",
      "epoch:5 step:5295 [D loss: 0.637012, acc.: 65.62%] [G loss: 0.837637]\n",
      "epoch:5 step:5296 [D loss: 0.636766, acc.: 60.94%] [G loss: 0.839166]\n",
      "epoch:5 step:5297 [D loss: 0.629400, acc.: 59.38%] [G loss: 0.862995]\n",
      "epoch:5 step:5298 [D loss: 0.654041, acc.: 54.69%] [G loss: 0.901539]\n",
      "epoch:5 step:5299 [D loss: 0.640161, acc.: 60.16%] [G loss: 0.885469]\n",
      "epoch:5 step:5300 [D loss: 0.668647, acc.: 57.03%] [G loss: 0.842708]\n",
      "epoch:5 step:5301 [D loss: 0.632579, acc.: 61.72%] [G loss: 0.831840]\n",
      "epoch:5 step:5302 [D loss: 0.664106, acc.: 52.34%] [G loss: 0.870127]\n",
      "epoch:5 step:5303 [D loss: 0.637436, acc.: 57.03%] [G loss: 0.852953]\n",
      "epoch:5 step:5304 [D loss: 0.644436, acc.: 60.16%] [G loss: 0.812679]\n",
      "epoch:5 step:5305 [D loss: 0.651748, acc.: 67.19%] [G loss: 0.841638]\n",
      "epoch:5 step:5306 [D loss: 0.659970, acc.: 57.03%] [G loss: 0.828664]\n",
      "epoch:5 step:5307 [D loss: 0.644355, acc.: 63.28%] [G loss: 0.844560]\n",
      "epoch:5 step:5308 [D loss: 0.658503, acc.: 60.16%] [G loss: 0.850084]\n",
      "epoch:5 step:5309 [D loss: 0.654475, acc.: 57.81%] [G loss: 0.892606]\n",
      "epoch:5 step:5310 [D loss: 0.685688, acc.: 56.25%] [G loss: 0.867488]\n",
      "epoch:5 step:5311 [D loss: 0.662535, acc.: 63.28%] [G loss: 0.888182]\n",
      "epoch:5 step:5312 [D loss: 0.662630, acc.: 57.03%] [G loss: 0.862922]\n",
      "epoch:5 step:5313 [D loss: 0.692080, acc.: 57.03%] [G loss: 0.895097]\n",
      "epoch:5 step:5314 [D loss: 0.672021, acc.: 54.69%] [G loss: 0.926083]\n",
      "epoch:5 step:5315 [D loss: 0.660376, acc.: 63.28%] [G loss: 0.926527]\n",
      "epoch:5 step:5316 [D loss: 0.654383, acc.: 60.16%] [G loss: 0.871406]\n",
      "epoch:5 step:5317 [D loss: 0.683469, acc.: 57.03%] [G loss: 0.906788]\n",
      "epoch:5 step:5318 [D loss: 0.596562, acc.: 74.22%] [G loss: 0.931164]\n",
      "epoch:5 step:5319 [D loss: 0.662703, acc.: 62.50%] [G loss: 0.915504]\n",
      "epoch:5 step:5320 [D loss: 0.642039, acc.: 64.84%] [G loss: 0.819227]\n",
      "epoch:5 step:5321 [D loss: 0.680485, acc.: 63.28%] [G loss: 0.819506]\n",
      "epoch:5 step:5322 [D loss: 0.661071, acc.: 59.38%] [G loss: 0.863767]\n",
      "epoch:5 step:5323 [D loss: 0.670076, acc.: 54.69%] [G loss: 0.861471]\n",
      "epoch:5 step:5324 [D loss: 0.684432, acc.: 53.91%] [G loss: 0.885331]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5325 [D loss: 0.686767, acc.: 57.03%] [G loss: 0.829121]\n",
      "epoch:5 step:5326 [D loss: 0.690991, acc.: 51.56%] [G loss: 0.829423]\n",
      "epoch:5 step:5327 [D loss: 0.669511, acc.: 57.03%] [G loss: 0.847686]\n",
      "epoch:5 step:5328 [D loss: 0.651504, acc.: 60.94%] [G loss: 0.845684]\n",
      "epoch:5 step:5329 [D loss: 0.640938, acc.: 61.72%] [G loss: 0.834144]\n",
      "epoch:5 step:5330 [D loss: 0.648344, acc.: 64.06%] [G loss: 0.888856]\n",
      "epoch:5 step:5331 [D loss: 0.698298, acc.: 53.12%] [G loss: 0.893706]\n",
      "epoch:5 step:5332 [D loss: 0.668556, acc.: 62.50%] [G loss: 0.866176]\n",
      "epoch:5 step:5333 [D loss: 0.619558, acc.: 67.19%] [G loss: 0.893148]\n",
      "epoch:5 step:5334 [D loss: 0.638892, acc.: 63.28%] [G loss: 0.872204]\n",
      "epoch:5 step:5335 [D loss: 0.670611, acc.: 54.69%] [G loss: 0.886784]\n",
      "epoch:5 step:5336 [D loss: 0.657224, acc.: 61.72%] [G loss: 0.826095]\n",
      "epoch:5 step:5337 [D loss: 0.632663, acc.: 66.41%] [G loss: 0.836759]\n",
      "epoch:5 step:5338 [D loss: 0.670943, acc.: 58.59%] [G loss: 0.811771]\n",
      "epoch:5 step:5339 [D loss: 0.628793, acc.: 63.28%] [G loss: 0.863432]\n",
      "epoch:5 step:5340 [D loss: 0.676975, acc.: 54.69%] [G loss: 0.816563]\n",
      "epoch:5 step:5341 [D loss: 0.658396, acc.: 64.06%] [G loss: 0.815095]\n",
      "epoch:5 step:5342 [D loss: 0.645736, acc.: 64.84%] [G loss: 0.860158]\n",
      "epoch:5 step:5343 [D loss: 0.729258, acc.: 55.47%] [G loss: 0.857523]\n",
      "epoch:5 step:5344 [D loss: 0.614118, acc.: 63.28%] [G loss: 0.911564]\n",
      "epoch:5 step:5345 [D loss: 0.650121, acc.: 61.72%] [G loss: 0.862351]\n",
      "epoch:5 step:5346 [D loss: 0.675475, acc.: 61.72%] [G loss: 0.831273]\n",
      "epoch:5 step:5347 [D loss: 0.678610, acc.: 60.16%] [G loss: 0.809919]\n",
      "epoch:5 step:5348 [D loss: 0.639398, acc.: 63.28%] [G loss: 0.886954]\n",
      "epoch:5 step:5349 [D loss: 0.703502, acc.: 52.34%] [G loss: 0.819929]\n",
      "epoch:5 step:5350 [D loss: 0.686744, acc.: 54.69%] [G loss: 0.861899]\n",
      "epoch:5 step:5351 [D loss: 0.652351, acc.: 64.84%] [G loss: 0.854563]\n",
      "epoch:5 step:5352 [D loss: 0.644378, acc.: 60.16%] [G loss: 0.854061]\n",
      "epoch:5 step:5353 [D loss: 0.641891, acc.: 64.84%] [G loss: 0.853279]\n",
      "epoch:5 step:5354 [D loss: 0.669427, acc.: 59.38%] [G loss: 0.883911]\n",
      "epoch:5 step:5355 [D loss: 0.655872, acc.: 64.06%] [G loss: 0.821154]\n",
      "epoch:5 step:5356 [D loss: 0.642571, acc.: 58.59%] [G loss: 0.861130]\n",
      "epoch:5 step:5357 [D loss: 0.664657, acc.: 53.12%] [G loss: 0.845128]\n",
      "epoch:5 step:5358 [D loss: 0.674839, acc.: 57.81%] [G loss: 0.878821]\n",
      "epoch:5 step:5359 [D loss: 0.683090, acc.: 58.59%] [G loss: 0.858137]\n",
      "epoch:5 step:5360 [D loss: 0.675067, acc.: 51.56%] [G loss: 0.835148]\n",
      "epoch:5 step:5361 [D loss: 0.671244, acc.: 55.47%] [G loss: 0.860721]\n",
      "epoch:5 step:5362 [D loss: 0.672491, acc.: 56.25%] [G loss: 0.854078]\n",
      "epoch:5 step:5363 [D loss: 0.658064, acc.: 56.25%] [G loss: 0.853157]\n",
      "epoch:5 step:5364 [D loss: 0.681311, acc.: 57.81%] [G loss: 0.793727]\n",
      "epoch:5 step:5365 [D loss: 0.691721, acc.: 58.59%] [G loss: 0.822276]\n",
      "epoch:5 step:5366 [D loss: 0.670492, acc.: 57.03%] [G loss: 0.877523]\n",
      "epoch:5 step:5367 [D loss: 0.690826, acc.: 52.34%] [G loss: 0.845523]\n",
      "epoch:5 step:5368 [D loss: 0.650893, acc.: 62.50%] [G loss: 0.799487]\n",
      "epoch:5 step:5369 [D loss: 0.699779, acc.: 50.78%] [G loss: 0.829113]\n",
      "epoch:5 step:5370 [D loss: 0.643128, acc.: 60.94%] [G loss: 0.827324]\n",
      "epoch:5 step:5371 [D loss: 0.678073, acc.: 55.47%] [G loss: 0.874020]\n",
      "epoch:5 step:5372 [D loss: 0.661182, acc.: 59.38%] [G loss: 0.865869]\n",
      "epoch:5 step:5373 [D loss: 0.653490, acc.: 58.59%] [G loss: 0.877288]\n",
      "epoch:5 step:5374 [D loss: 0.649342, acc.: 63.28%] [G loss: 0.846049]\n",
      "epoch:5 step:5375 [D loss: 0.653424, acc.: 57.03%] [G loss: 0.863117]\n",
      "epoch:5 step:5376 [D loss: 0.668462, acc.: 58.59%] [G loss: 0.805420]\n",
      "epoch:5 step:5377 [D loss: 0.631422, acc.: 62.50%] [G loss: 0.798106]\n",
      "epoch:5 step:5378 [D loss: 0.655152, acc.: 68.75%] [G loss: 0.862960]\n",
      "epoch:5 step:5379 [D loss: 0.642859, acc.: 63.28%] [G loss: 0.820414]\n",
      "epoch:5 step:5380 [D loss: 0.679300, acc.: 57.03%] [G loss: 0.895256]\n",
      "epoch:5 step:5381 [D loss: 0.655452, acc.: 64.06%] [G loss: 0.854301]\n",
      "epoch:5 step:5382 [D loss: 0.687339, acc.: 53.91%] [G loss: 0.859044]\n",
      "epoch:5 step:5383 [D loss: 0.643864, acc.: 63.28%] [G loss: 0.816072]\n",
      "epoch:5 step:5384 [D loss: 0.673404, acc.: 59.38%] [G loss: 0.861401]\n",
      "epoch:5 step:5385 [D loss: 0.658899, acc.: 60.94%] [G loss: 0.823985]\n",
      "epoch:5 step:5386 [D loss: 0.680190, acc.: 50.78%] [G loss: 0.854847]\n",
      "epoch:5 step:5387 [D loss: 0.647114, acc.: 58.59%] [G loss: 0.847709]\n",
      "epoch:5 step:5388 [D loss: 0.679706, acc.: 54.69%] [G loss: 0.818721]\n",
      "epoch:5 step:5389 [D loss: 0.668519, acc.: 58.59%] [G loss: 0.849602]\n",
      "epoch:5 step:5390 [D loss: 0.678074, acc.: 56.25%] [G loss: 0.835527]\n",
      "epoch:5 step:5391 [D loss: 0.684689, acc.: 56.25%] [G loss: 0.838068]\n",
      "epoch:5 step:5392 [D loss: 0.658197, acc.: 60.16%] [G loss: 0.873957]\n",
      "epoch:5 step:5393 [D loss: 0.637414, acc.: 69.53%] [G loss: 0.878847]\n",
      "epoch:5 step:5394 [D loss: 0.694341, acc.: 58.59%] [G loss: 0.817332]\n",
      "epoch:5 step:5395 [D loss: 0.656243, acc.: 62.50%] [G loss: 0.816588]\n",
      "epoch:5 step:5396 [D loss: 0.671034, acc.: 60.94%] [G loss: 0.840673]\n",
      "epoch:5 step:5397 [D loss: 0.641671, acc.: 58.59%] [G loss: 0.835026]\n",
      "epoch:5 step:5398 [D loss: 0.669222, acc.: 57.81%] [G loss: 0.807015]\n",
      "epoch:5 step:5399 [D loss: 0.682916, acc.: 57.81%] [G loss: 0.769182]\n",
      "epoch:5 step:5400 [D loss: 0.652284, acc.: 59.38%] [G loss: 0.791504]\n",
      "##############\n",
      "[3.11578047 3.0706288  2.06499258 4.19568696 1.26753093 8.55208047\n",
      " 2.63572947 3.88170784 4.14914981 7.14868929]\n",
      "##########\n",
      "epoch:5 step:5401 [D loss: 0.654042, acc.: 60.16%] [G loss: 0.805497]\n",
      "epoch:5 step:5402 [D loss: 0.666230, acc.: 57.03%] [G loss: 0.820694]\n",
      "epoch:5 step:5403 [D loss: 0.656861, acc.: 62.50%] [G loss: 0.844277]\n",
      "epoch:5 step:5404 [D loss: 0.650624, acc.: 60.16%] [G loss: 0.877118]\n",
      "epoch:5 step:5405 [D loss: 0.655855, acc.: 64.06%] [G loss: 0.860643]\n",
      "epoch:5 step:5406 [D loss: 0.651044, acc.: 61.72%] [G loss: 0.899886]\n",
      "epoch:5 step:5407 [D loss: 0.663428, acc.: 64.06%] [G loss: 0.861358]\n",
      "epoch:5 step:5408 [D loss: 0.648309, acc.: 60.16%] [G loss: 0.880524]\n",
      "epoch:5 step:5409 [D loss: 0.703984, acc.: 54.69%] [G loss: 0.829641]\n",
      "epoch:5 step:5410 [D loss: 0.652262, acc.: 59.38%] [G loss: 0.902987]\n",
      "epoch:5 step:5411 [D loss: 0.662259, acc.: 60.16%] [G loss: 0.864617]\n",
      "epoch:5 step:5412 [D loss: 0.660648, acc.: 60.94%] [G loss: 0.829985]\n",
      "epoch:5 step:5413 [D loss: 0.664126, acc.: 64.06%] [G loss: 0.785191]\n",
      "epoch:5 step:5414 [D loss: 0.642476, acc.: 63.28%] [G loss: 0.833608]\n",
      "epoch:5 step:5415 [D loss: 0.684457, acc.: 57.03%] [G loss: 0.835289]\n",
      "epoch:5 step:5416 [D loss: 0.686336, acc.: 57.81%] [G loss: 0.857707]\n",
      "epoch:5 step:5417 [D loss: 0.635276, acc.: 63.28%] [G loss: 0.848668]\n",
      "epoch:5 step:5418 [D loss: 0.683245, acc.: 59.38%] [G loss: 0.834270]\n",
      "epoch:5 step:5419 [D loss: 0.651085, acc.: 60.94%] [G loss: 0.839187]\n",
      "epoch:5 step:5420 [D loss: 0.666582, acc.: 54.69%] [G loss: 0.866827]\n",
      "epoch:5 step:5421 [D loss: 0.633928, acc.: 65.62%] [G loss: 0.864926]\n",
      "epoch:5 step:5422 [D loss: 0.703351, acc.: 50.78%] [G loss: 0.820679]\n",
      "epoch:5 step:5423 [D loss: 0.679798, acc.: 53.91%] [G loss: 0.808017]\n",
      "epoch:5 step:5424 [D loss: 0.660658, acc.: 55.47%] [G loss: 0.836424]\n",
      "epoch:5 step:5425 [D loss: 0.685424, acc.: 52.34%] [G loss: 0.836268]\n",
      "epoch:5 step:5426 [D loss: 0.631993, acc.: 64.84%] [G loss: 0.882824]\n",
      "epoch:5 step:5427 [D loss: 0.661528, acc.: 63.28%] [G loss: 0.829839]\n",
      "epoch:5 step:5428 [D loss: 0.672873, acc.: 53.91%] [G loss: 0.830485]\n",
      "epoch:5 step:5429 [D loss: 0.699075, acc.: 53.91%] [G loss: 0.830480]\n",
      "epoch:5 step:5430 [D loss: 0.679874, acc.: 61.72%] [G loss: 0.889301]\n",
      "epoch:5 step:5431 [D loss: 0.659927, acc.: 60.94%] [G loss: 0.914767]\n",
      "epoch:5 step:5432 [D loss: 0.656458, acc.: 64.06%] [G loss: 0.885273]\n",
      "epoch:5 step:5433 [D loss: 0.663053, acc.: 57.81%] [G loss: 0.913637]\n",
      "epoch:5 step:5434 [D loss: 0.670989, acc.: 57.81%] [G loss: 0.885132]\n",
      "epoch:5 step:5435 [D loss: 0.624293, acc.: 64.06%] [G loss: 0.821934]\n",
      "epoch:5 step:5436 [D loss: 0.659390, acc.: 57.03%] [G loss: 0.894888]\n",
      "epoch:5 step:5437 [D loss: 0.649308, acc.: 67.97%] [G loss: 0.858277]\n",
      "epoch:5 step:5438 [D loss: 0.634544, acc.: 62.50%] [G loss: 0.885666]\n",
      "epoch:5 step:5439 [D loss: 0.684793, acc.: 50.00%] [G loss: 0.842162]\n",
      "epoch:5 step:5440 [D loss: 0.667527, acc.: 58.59%] [G loss: 0.827706]\n",
      "epoch:5 step:5441 [D loss: 0.679933, acc.: 59.38%] [G loss: 0.817670]\n",
      "epoch:5 step:5442 [D loss: 0.623124, acc.: 64.06%] [G loss: 0.856079]\n",
      "epoch:5 step:5443 [D loss: 0.659573, acc.: 56.25%] [G loss: 0.804816]\n",
      "epoch:5 step:5444 [D loss: 0.683492, acc.: 57.81%] [G loss: 0.850411]\n",
      "epoch:5 step:5445 [D loss: 0.676540, acc.: 60.16%] [G loss: 0.860793]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5446 [D loss: 0.686573, acc.: 52.34%] [G loss: 0.904126]\n",
      "epoch:5 step:5447 [D loss: 0.615748, acc.: 68.75%] [G loss: 0.878139]\n",
      "epoch:5 step:5448 [D loss: 0.631253, acc.: 64.84%] [G loss: 0.846173]\n",
      "epoch:5 step:5449 [D loss: 0.642373, acc.: 65.62%] [G loss: 0.811812]\n",
      "epoch:5 step:5450 [D loss: 0.685356, acc.: 53.91%] [G loss: 0.824795]\n",
      "epoch:5 step:5451 [D loss: 0.672848, acc.: 57.03%] [G loss: 0.805275]\n",
      "epoch:5 step:5452 [D loss: 0.671455, acc.: 60.94%] [G loss: 0.833622]\n",
      "epoch:5 step:5453 [D loss: 0.630656, acc.: 59.38%] [G loss: 0.844309]\n",
      "epoch:5 step:5454 [D loss: 0.627555, acc.: 60.94%] [G loss: 0.854088]\n",
      "epoch:5 step:5455 [D loss: 0.696380, acc.: 51.56%] [G loss: 0.841431]\n",
      "epoch:5 step:5456 [D loss: 0.674425, acc.: 55.47%] [G loss: 0.828920]\n",
      "epoch:5 step:5457 [D loss: 0.668447, acc.: 57.81%] [G loss: 0.915191]\n",
      "epoch:5 step:5458 [D loss: 0.686299, acc.: 56.25%] [G loss: 0.842938]\n",
      "epoch:5 step:5459 [D loss: 0.662068, acc.: 62.50%] [G loss: 0.853515]\n",
      "epoch:5 step:5460 [D loss: 0.683450, acc.: 51.56%] [G loss: 0.883317]\n",
      "epoch:5 step:5461 [D loss: 0.630431, acc.: 62.50%] [G loss: 0.907044]\n",
      "epoch:5 step:5462 [D loss: 0.636671, acc.: 65.62%] [G loss: 0.875827]\n",
      "epoch:5 step:5463 [D loss: 0.649283, acc.: 60.94%] [G loss: 0.856409]\n",
      "epoch:5 step:5464 [D loss: 0.647879, acc.: 67.97%] [G loss: 0.857220]\n",
      "epoch:5 step:5465 [D loss: 0.651850, acc.: 59.38%] [G loss: 0.894198]\n",
      "epoch:5 step:5466 [D loss: 0.666368, acc.: 60.94%] [G loss: 0.849572]\n",
      "epoch:5 step:5467 [D loss: 0.646745, acc.: 64.06%] [G loss: 0.891048]\n",
      "epoch:5 step:5468 [D loss: 0.700027, acc.: 55.47%] [G loss: 0.971873]\n",
      "epoch:5 step:5469 [D loss: 0.656052, acc.: 60.16%] [G loss: 0.893617]\n",
      "epoch:5 step:5470 [D loss: 0.668076, acc.: 53.91%] [G loss: 0.890033]\n",
      "epoch:5 step:5471 [D loss: 0.693842, acc.: 58.59%] [G loss: 0.850885]\n",
      "epoch:5 step:5472 [D loss: 0.656050, acc.: 61.72%] [G loss: 0.865079]\n",
      "epoch:5 step:5473 [D loss: 0.643601, acc.: 60.94%] [G loss: 0.886301]\n",
      "epoch:5 step:5474 [D loss: 0.652429, acc.: 63.28%] [G loss: 0.880463]\n",
      "epoch:5 step:5475 [D loss: 0.693697, acc.: 42.97%] [G loss: 0.820735]\n",
      "epoch:5 step:5476 [D loss: 0.682509, acc.: 53.91%] [G loss: 0.874568]\n",
      "epoch:5 step:5477 [D loss: 0.688135, acc.: 53.12%] [G loss: 0.833818]\n",
      "epoch:5 step:5478 [D loss: 0.649212, acc.: 59.38%] [G loss: 0.825418]\n",
      "epoch:5 step:5479 [D loss: 0.666838, acc.: 57.81%] [G loss: 0.852324]\n",
      "epoch:5 step:5480 [D loss: 0.664124, acc.: 63.28%] [G loss: 0.893530]\n",
      "epoch:5 step:5481 [D loss: 0.656802, acc.: 56.25%] [G loss: 0.926722]\n",
      "epoch:5 step:5482 [D loss: 0.670142, acc.: 57.03%] [G loss: 0.881758]\n",
      "epoch:5 step:5483 [D loss: 0.670015, acc.: 59.38%] [G loss: 0.838124]\n",
      "epoch:5 step:5484 [D loss: 0.658425, acc.: 61.72%] [G loss: 0.860342]\n",
      "epoch:5 step:5485 [D loss: 0.689562, acc.: 57.03%] [G loss: 0.856874]\n",
      "epoch:5 step:5486 [D loss: 0.625455, acc.: 64.84%] [G loss: 0.870700]\n",
      "epoch:5 step:5487 [D loss: 0.691805, acc.: 51.56%] [G loss: 0.790578]\n",
      "epoch:5 step:5488 [D loss: 0.651001, acc.: 58.59%] [G loss: 0.789107]\n",
      "epoch:5 step:5489 [D loss: 0.659460, acc.: 60.16%] [G loss: 0.849773]\n",
      "epoch:5 step:5490 [D loss: 0.643475, acc.: 56.25%] [G loss: 0.854601]\n",
      "epoch:5 step:5491 [D loss: 0.640483, acc.: 62.50%] [G loss: 0.857920]\n",
      "epoch:5 step:5492 [D loss: 0.634345, acc.: 58.59%] [G loss: 0.854802]\n",
      "epoch:5 step:5493 [D loss: 0.650119, acc.: 58.59%] [G loss: 0.806285]\n",
      "epoch:5 step:5494 [D loss: 0.635742, acc.: 60.16%] [G loss: 0.848080]\n",
      "epoch:5 step:5495 [D loss: 0.628639, acc.: 64.84%] [G loss: 0.846526]\n",
      "epoch:5 step:5496 [D loss: 0.644023, acc.: 61.72%] [G loss: 0.902425]\n",
      "epoch:5 step:5497 [D loss: 0.657568, acc.: 62.50%] [G loss: 0.890478]\n",
      "epoch:5 step:5498 [D loss: 0.643191, acc.: 63.28%] [G loss: 0.871523]\n",
      "epoch:5 step:5499 [D loss: 0.657741, acc.: 60.16%] [G loss: 0.879837]\n",
      "epoch:5 step:5500 [D loss: 0.684757, acc.: 54.69%] [G loss: 0.895155]\n",
      "epoch:5 step:5501 [D loss: 0.625586, acc.: 62.50%] [G loss: 0.862117]\n",
      "epoch:5 step:5502 [D loss: 0.664718, acc.: 57.03%] [G loss: 0.895075]\n",
      "epoch:5 step:5503 [D loss: 0.664516, acc.: 58.59%] [G loss: 0.872449]\n",
      "epoch:5 step:5504 [D loss: 0.681718, acc.: 58.59%] [G loss: 0.857935]\n",
      "epoch:5 step:5505 [D loss: 0.700870, acc.: 51.56%] [G loss: 0.823693]\n",
      "epoch:5 step:5506 [D loss: 0.679035, acc.: 52.34%] [G loss: 0.901610]\n",
      "epoch:5 step:5507 [D loss: 0.665000, acc.: 58.59%] [G loss: 0.917489]\n",
      "epoch:5 step:5508 [D loss: 0.719641, acc.: 47.66%] [G loss: 0.838245]\n",
      "epoch:5 step:5509 [D loss: 0.687071, acc.: 58.59%] [G loss: 0.864192]\n",
      "epoch:5 step:5510 [D loss: 0.674094, acc.: 53.91%] [G loss: 0.855729]\n",
      "epoch:5 step:5511 [D loss: 0.652601, acc.: 64.84%] [G loss: 0.869964]\n",
      "epoch:5 step:5512 [D loss: 0.671831, acc.: 54.69%] [G loss: 0.892689]\n",
      "epoch:5 step:5513 [D loss: 0.695692, acc.: 55.47%] [G loss: 0.861690]\n",
      "epoch:5 step:5514 [D loss: 0.639336, acc.: 65.62%] [G loss: 0.840346]\n",
      "epoch:5 step:5515 [D loss: 0.681298, acc.: 57.03%] [G loss: 0.836527]\n",
      "epoch:5 step:5516 [D loss: 0.714656, acc.: 52.34%] [G loss: 0.841148]\n",
      "epoch:5 step:5517 [D loss: 0.664916, acc.: 58.59%] [G loss: 0.896962]\n",
      "epoch:5 step:5518 [D loss: 0.683104, acc.: 57.81%] [G loss: 0.859855]\n",
      "epoch:5 step:5519 [D loss: 0.674290, acc.: 60.16%] [G loss: 0.854561]\n",
      "epoch:5 step:5520 [D loss: 0.675362, acc.: 61.72%] [G loss: 0.832110]\n",
      "epoch:5 step:5521 [D loss: 0.657620, acc.: 60.94%] [G loss: 0.838653]\n",
      "epoch:5 step:5522 [D loss: 0.664496, acc.: 59.38%] [G loss: 0.880523]\n",
      "epoch:5 step:5523 [D loss: 0.666876, acc.: 58.59%] [G loss: 0.894319]\n",
      "epoch:5 step:5524 [D loss: 0.623946, acc.: 67.19%] [G loss: 0.898663]\n",
      "epoch:5 step:5525 [D loss: 0.687307, acc.: 53.91%] [G loss: 0.877889]\n",
      "epoch:5 step:5526 [D loss: 0.671964, acc.: 55.47%] [G loss: 0.848992]\n",
      "epoch:5 step:5527 [D loss: 0.670190, acc.: 58.59%] [G loss: 0.846629]\n",
      "epoch:5 step:5528 [D loss: 0.696831, acc.: 50.78%] [G loss: 0.829621]\n",
      "epoch:5 step:5529 [D loss: 0.686921, acc.: 52.34%] [G loss: 0.860199]\n",
      "epoch:5 step:5530 [D loss: 0.664111, acc.: 57.81%] [G loss: 0.857496]\n",
      "epoch:5 step:5531 [D loss: 0.686291, acc.: 57.03%] [G loss: 0.842933]\n",
      "epoch:5 step:5532 [D loss: 0.684056, acc.: 56.25%] [G loss: 0.821249]\n",
      "epoch:5 step:5533 [D loss: 0.641625, acc.: 59.38%] [G loss: 0.820439]\n",
      "epoch:5 step:5534 [D loss: 0.676264, acc.: 53.91%] [G loss: 0.837060]\n",
      "epoch:5 step:5535 [D loss: 0.627346, acc.: 69.53%] [G loss: 0.858827]\n",
      "epoch:5 step:5536 [D loss: 0.681571, acc.: 60.94%] [G loss: 0.901101]\n",
      "epoch:5 step:5537 [D loss: 0.620055, acc.: 67.19%] [G loss: 0.905770]\n",
      "epoch:5 step:5538 [D loss: 0.650755, acc.: 59.38%] [G loss: 0.860986]\n",
      "epoch:5 step:5539 [D loss: 0.664753, acc.: 65.62%] [G loss: 0.888862]\n",
      "epoch:5 step:5540 [D loss: 0.699565, acc.: 50.00%] [G loss: 0.884644]\n",
      "epoch:5 step:5541 [D loss: 0.673787, acc.: 59.38%] [G loss: 0.862960]\n",
      "epoch:5 step:5542 [D loss: 0.671535, acc.: 59.38%] [G loss: 0.903151]\n",
      "epoch:5 step:5543 [D loss: 0.700687, acc.: 55.47%] [G loss: 0.870896]\n",
      "epoch:5 step:5544 [D loss: 0.650838, acc.: 62.50%] [G loss: 0.869598]\n",
      "epoch:5 step:5545 [D loss: 0.667374, acc.: 57.03%] [G loss: 0.858331]\n",
      "epoch:5 step:5546 [D loss: 0.644908, acc.: 58.59%] [G loss: 0.885261]\n",
      "epoch:5 step:5547 [D loss: 0.632319, acc.: 65.62%] [G loss: 0.896995]\n",
      "epoch:5 step:5548 [D loss: 0.663575, acc.: 55.47%] [G loss: 0.873551]\n",
      "epoch:5 step:5549 [D loss: 0.688858, acc.: 57.03%] [G loss: 0.851664]\n",
      "epoch:5 step:5550 [D loss: 0.654191, acc.: 58.59%] [G loss: 0.835796]\n",
      "epoch:5 step:5551 [D loss: 0.658160, acc.: 58.59%] [G loss: 0.853867]\n",
      "epoch:5 step:5552 [D loss: 0.672446, acc.: 59.38%] [G loss: 0.811549]\n",
      "epoch:5 step:5553 [D loss: 0.630326, acc.: 67.19%] [G loss: 0.886899]\n",
      "epoch:5 step:5554 [D loss: 0.651758, acc.: 60.16%] [G loss: 0.856276]\n",
      "epoch:5 step:5555 [D loss: 0.683498, acc.: 53.91%] [G loss: 0.884158]\n",
      "epoch:5 step:5556 [D loss: 0.663153, acc.: 61.72%] [G loss: 0.890138]\n",
      "epoch:5 step:5557 [D loss: 0.666612, acc.: 59.38%] [G loss: 0.775175]\n",
      "epoch:5 step:5558 [D loss: 0.609301, acc.: 70.31%] [G loss: 0.932024]\n",
      "epoch:5 step:5559 [D loss: 0.656248, acc.: 64.84%] [G loss: 0.875817]\n",
      "epoch:5 step:5560 [D loss: 0.640105, acc.: 65.62%] [G loss: 0.916831]\n",
      "epoch:5 step:5561 [D loss: 0.673806, acc.: 59.38%] [G loss: 0.874896]\n",
      "epoch:5 step:5562 [D loss: 0.633764, acc.: 62.50%] [G loss: 0.868304]\n",
      "epoch:5 step:5563 [D loss: 0.668323, acc.: 55.47%] [G loss: 0.862786]\n",
      "epoch:5 step:5564 [D loss: 0.694270, acc.: 62.50%] [G loss: 0.847120]\n",
      "epoch:5 step:5565 [D loss: 0.638121, acc.: 60.94%] [G loss: 0.865411]\n",
      "epoch:5 step:5566 [D loss: 0.666729, acc.: 52.34%] [G loss: 0.875321]\n",
      "epoch:5 step:5567 [D loss: 0.643064, acc.: 62.50%] [G loss: 0.867873]\n",
      "epoch:5 step:5568 [D loss: 0.678047, acc.: 60.94%] [G loss: 0.880793]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:5 step:5569 [D loss: 0.676832, acc.: 61.72%] [G loss: 0.844625]\n",
      "epoch:5 step:5570 [D loss: 0.707033, acc.: 51.56%] [G loss: 0.889898]\n",
      "epoch:5 step:5571 [D loss: 0.653473, acc.: 60.94%] [G loss: 0.899060]\n",
      "epoch:5 step:5572 [D loss: 0.672669, acc.: 57.03%] [G loss: 0.903424]\n",
      "epoch:5 step:5573 [D loss: 0.642633, acc.: 62.50%] [G loss: 0.861592]\n",
      "epoch:5 step:5574 [D loss: 0.638645, acc.: 67.97%] [G loss: 0.864009]\n",
      "epoch:5 step:5575 [D loss: 0.660693, acc.: 54.69%] [G loss: 0.839265]\n",
      "epoch:5 step:5576 [D loss: 0.684218, acc.: 58.59%] [G loss: 0.855264]\n",
      "epoch:5 step:5577 [D loss: 0.675113, acc.: 55.47%] [G loss: 0.833567]\n",
      "epoch:5 step:5578 [D loss: 0.645475, acc.: 58.59%] [G loss: 0.817569]\n",
      "epoch:5 step:5579 [D loss: 0.638075, acc.: 62.50%] [G loss: 0.802234]\n",
      "epoch:5 step:5580 [D loss: 0.611359, acc.: 64.06%] [G loss: 0.842015]\n",
      "epoch:5 step:5581 [D loss: 0.642487, acc.: 65.62%] [G loss: 0.864011]\n",
      "epoch:5 step:5582 [D loss: 0.624714, acc.: 67.19%] [G loss: 0.842552]\n",
      "epoch:5 step:5583 [D loss: 0.648356, acc.: 60.94%] [G loss: 0.840562]\n",
      "epoch:5 step:5584 [D loss: 0.642061, acc.: 67.97%] [G loss: 0.829876]\n",
      "epoch:5 step:5585 [D loss: 0.669792, acc.: 60.16%] [G loss: 0.820553]\n",
      "epoch:5 step:5586 [D loss: 0.664314, acc.: 62.50%] [G loss: 0.823691]\n",
      "epoch:5 step:5587 [D loss: 0.639264, acc.: 63.28%] [G loss: 0.886951]\n",
      "epoch:5 step:5588 [D loss: 0.609871, acc.: 66.41%] [G loss: 0.836001]\n",
      "epoch:5 step:5589 [D loss: 0.677885, acc.: 59.38%] [G loss: 0.874613]\n",
      "epoch:5 step:5590 [D loss: 0.694294, acc.: 60.94%] [G loss: 0.886072]\n",
      "epoch:5 step:5591 [D loss: 0.652832, acc.: 57.81%] [G loss: 0.857859]\n",
      "epoch:5 step:5592 [D loss: 0.724542, acc.: 46.88%] [G loss: 0.863252]\n",
      "epoch:5 step:5593 [D loss: 0.665654, acc.: 57.81%] [G loss: 0.905500]\n",
      "epoch:5 step:5594 [D loss: 0.669463, acc.: 55.47%] [G loss: 0.855642]\n",
      "epoch:5 step:5595 [D loss: 0.713226, acc.: 50.00%] [G loss: 0.909658]\n",
      "epoch:5 step:5596 [D loss: 0.670884, acc.: 56.25%] [G loss: 0.890451]\n",
      "epoch:5 step:5597 [D loss: 0.674014, acc.: 58.59%] [G loss: 0.833739]\n",
      "epoch:5 step:5598 [D loss: 0.664578, acc.: 53.91%] [G loss: 0.860697]\n",
      "epoch:5 step:5599 [D loss: 0.668469, acc.: 57.03%] [G loss: 0.861553]\n",
      "epoch:5 step:5600 [D loss: 0.662338, acc.: 60.94%] [G loss: 0.858322]\n",
      "##############\n",
      "[ 3.09460062  3.12747107  2.53680641  4.57562215  1.71507134 10.27426719\n",
      "  3.0627868   4.26213993  4.49509861  8.14868929]\n",
      "##########\n",
      "epoch:5 step:5601 [D loss: 0.637701, acc.: 64.84%] [G loss: 0.794011]\n",
      "epoch:5 step:5602 [D loss: 0.680825, acc.: 56.25%] [G loss: 0.857450]\n",
      "epoch:5 step:5603 [D loss: 0.646580, acc.: 60.16%] [G loss: 0.850349]\n",
      "epoch:5 step:5604 [D loss: 0.650127, acc.: 60.16%] [G loss: 0.898753]\n",
      "epoch:5 step:5605 [D loss: 0.645481, acc.: 63.28%] [G loss: 0.870525]\n",
      "epoch:5 step:5606 [D loss: 0.708197, acc.: 49.22%] [G loss: 0.832850]\n",
      "epoch:5 step:5607 [D loss: 0.664724, acc.: 65.62%] [G loss: 0.908235]\n",
      "epoch:5 step:5608 [D loss: 0.661183, acc.: 60.16%] [G loss: 0.851738]\n",
      "epoch:5 step:5609 [D loss: 0.637705, acc.: 66.41%] [G loss: 0.889064]\n",
      "epoch:5 step:5610 [D loss: 0.676751, acc.: 64.06%] [G loss: 0.883624]\n",
      "epoch:5 step:5611 [D loss: 0.659190, acc.: 60.16%] [G loss: 0.921590]\n",
      "epoch:5 step:5612 [D loss: 0.666612, acc.: 60.94%] [G loss: 0.904095]\n",
      "epoch:5 step:5613 [D loss: 0.651971, acc.: 61.72%] [G loss: 0.875996]\n",
      "epoch:5 step:5614 [D loss: 0.644158, acc.: 60.16%] [G loss: 0.873428]\n",
      "epoch:5 step:5615 [D loss: 0.682185, acc.: 50.78%] [G loss: 0.900140]\n",
      "epoch:5 step:5616 [D loss: 0.666034, acc.: 55.47%] [G loss: 0.881969]\n",
      "epoch:5 step:5617 [D loss: 0.678955, acc.: 58.59%] [G loss: 0.951070]\n",
      "epoch:5 step:5618 [D loss: 0.639421, acc.: 63.28%] [G loss: 0.893281]\n",
      "epoch:5 step:5619 [D loss: 0.632757, acc.: 64.84%] [G loss: 0.880123]\n",
      "epoch:5 step:5620 [D loss: 0.690068, acc.: 50.78%] [G loss: 0.869673]\n",
      "epoch:5 step:5621 [D loss: 0.656867, acc.: 61.72%] [G loss: 0.906962]\n",
      "epoch:5 step:5622 [D loss: 0.657366, acc.: 61.72%] [G loss: 0.870955]\n",
      "epoch:6 step:5623 [D loss: 0.671309, acc.: 59.38%] [G loss: 0.882985]\n",
      "epoch:6 step:5624 [D loss: 0.626959, acc.: 68.75%] [G loss: 0.841156]\n",
      "epoch:6 step:5625 [D loss: 0.666857, acc.: 59.38%] [G loss: 0.850293]\n",
      "epoch:6 step:5626 [D loss: 0.667794, acc.: 60.94%] [G loss: 0.881260]\n",
      "epoch:6 step:5627 [D loss: 0.673271, acc.: 56.25%] [G loss: 0.850324]\n",
      "epoch:6 step:5628 [D loss: 0.679676, acc.: 61.72%] [G loss: 0.855139]\n",
      "epoch:6 step:5629 [D loss: 0.659777, acc.: 58.59%] [G loss: 0.897055]\n",
      "epoch:6 step:5630 [D loss: 0.677086, acc.: 55.47%] [G loss: 0.836247]\n",
      "epoch:6 step:5631 [D loss: 0.637233, acc.: 61.72%] [G loss: 0.834522]\n",
      "epoch:6 step:5632 [D loss: 0.635334, acc.: 66.41%] [G loss: 0.878004]\n",
      "epoch:6 step:5633 [D loss: 0.622421, acc.: 71.88%] [G loss: 0.871426]\n",
      "epoch:6 step:5634 [D loss: 0.642627, acc.: 62.50%] [G loss: 0.863452]\n",
      "epoch:6 step:5635 [D loss: 0.639010, acc.: 61.72%] [G loss: 0.821735]\n",
      "epoch:6 step:5636 [D loss: 0.685716, acc.: 57.81%] [G loss: 0.845005]\n",
      "epoch:6 step:5637 [D loss: 0.645190, acc.: 60.16%] [G loss: 0.823602]\n",
      "epoch:6 step:5638 [D loss: 0.657139, acc.: 60.94%] [G loss: 0.822828]\n",
      "epoch:6 step:5639 [D loss: 0.645457, acc.: 64.06%] [G loss: 0.877508]\n",
      "epoch:6 step:5640 [D loss: 0.693944, acc.: 56.25%] [G loss: 0.877347]\n",
      "epoch:6 step:5641 [D loss: 0.703156, acc.: 53.91%] [G loss: 0.862118]\n",
      "epoch:6 step:5642 [D loss: 0.688627, acc.: 56.25%] [G loss: 0.873230]\n",
      "epoch:6 step:5643 [D loss: 0.645684, acc.: 60.94%] [G loss: 0.864160]\n",
      "epoch:6 step:5644 [D loss: 0.676582, acc.: 56.25%] [G loss: 0.867240]\n",
      "epoch:6 step:5645 [D loss: 0.703758, acc.: 50.00%] [G loss: 0.828180]\n",
      "epoch:6 step:5646 [D loss: 0.664962, acc.: 60.16%] [G loss: 0.816658]\n",
      "epoch:6 step:5647 [D loss: 0.668964, acc.: 56.25%] [G loss: 0.851464]\n",
      "epoch:6 step:5648 [D loss: 0.647658, acc.: 59.38%] [G loss: 0.894225]\n",
      "epoch:6 step:5649 [D loss: 0.630119, acc.: 67.19%] [G loss: 0.906441]\n",
      "epoch:6 step:5650 [D loss: 0.651682, acc.: 66.41%] [G loss: 0.845007]\n",
      "epoch:6 step:5651 [D loss: 0.701971, acc.: 57.81%] [G loss: 0.883903]\n",
      "epoch:6 step:5652 [D loss: 0.664261, acc.: 57.81%] [G loss: 0.849942]\n",
      "epoch:6 step:5653 [D loss: 0.652223, acc.: 57.81%] [G loss: 0.908920]\n",
      "epoch:6 step:5654 [D loss: 0.611891, acc.: 64.84%] [G loss: 0.892528]\n",
      "epoch:6 step:5655 [D loss: 0.657964, acc.: 59.38%] [G loss: 0.843093]\n",
      "epoch:6 step:5656 [D loss: 0.692554, acc.: 54.69%] [G loss: 0.859843]\n",
      "epoch:6 step:5657 [D loss: 0.632767, acc.: 63.28%] [G loss: 0.913329]\n",
      "epoch:6 step:5658 [D loss: 0.623904, acc.: 67.19%] [G loss: 0.876899]\n",
      "epoch:6 step:5659 [D loss: 0.650571, acc.: 61.72%] [G loss: 0.859139]\n",
      "epoch:6 step:5660 [D loss: 0.692696, acc.: 55.47%] [G loss: 0.882169]\n",
      "epoch:6 step:5661 [D loss: 0.670956, acc.: 57.81%] [G loss: 0.886169]\n",
      "epoch:6 step:5662 [D loss: 0.657979, acc.: 56.25%] [G loss: 0.875906]\n",
      "epoch:6 step:5663 [D loss: 0.652648, acc.: 64.84%] [G loss: 0.847565]\n",
      "epoch:6 step:5664 [D loss: 0.648487, acc.: 60.16%] [G loss: 0.848883]\n",
      "epoch:6 step:5665 [D loss: 0.642357, acc.: 58.59%] [G loss: 0.846396]\n",
      "epoch:6 step:5666 [D loss: 0.656557, acc.: 57.03%] [G loss: 0.896209]\n",
      "epoch:6 step:5667 [D loss: 0.669072, acc.: 58.59%] [G loss: 0.816254]\n",
      "epoch:6 step:5668 [D loss: 0.665569, acc.: 61.72%] [G loss: 0.857869]\n",
      "epoch:6 step:5669 [D loss: 0.664979, acc.: 53.12%] [G loss: 0.860017]\n",
      "epoch:6 step:5670 [D loss: 0.647896, acc.: 64.06%] [G loss: 0.862416]\n",
      "epoch:6 step:5671 [D loss: 0.672733, acc.: 56.25%] [G loss: 0.843195]\n",
      "epoch:6 step:5672 [D loss: 0.624175, acc.: 60.16%] [G loss: 0.858106]\n",
      "epoch:6 step:5673 [D loss: 0.667918, acc.: 55.47%] [G loss: 0.897179]\n",
      "epoch:6 step:5674 [D loss: 0.650878, acc.: 62.50%] [G loss: 0.864361]\n",
      "epoch:6 step:5675 [D loss: 0.651215, acc.: 62.50%] [G loss: 0.879994]\n",
      "epoch:6 step:5676 [D loss: 0.653437, acc.: 57.81%] [G loss: 0.872442]\n",
      "epoch:6 step:5677 [D loss: 0.662990, acc.: 61.72%] [G loss: 0.893920]\n",
      "epoch:6 step:5678 [D loss: 0.652389, acc.: 58.59%] [G loss: 0.804324]\n",
      "epoch:6 step:5679 [D loss: 0.648761, acc.: 58.59%] [G loss: 0.863562]\n",
      "epoch:6 step:5680 [D loss: 0.678441, acc.: 60.16%] [G loss: 0.890942]\n",
      "epoch:6 step:5681 [D loss: 0.626516, acc.: 63.28%] [G loss: 0.868028]\n",
      "epoch:6 step:5682 [D loss: 0.658174, acc.: 59.38%] [G loss: 0.837683]\n",
      "epoch:6 step:5683 [D loss: 0.649679, acc.: 60.16%] [G loss: 0.887507]\n",
      "epoch:6 step:5684 [D loss: 0.654346, acc.: 57.81%] [G loss: 0.866188]\n",
      "epoch:6 step:5685 [D loss: 0.625597, acc.: 64.06%] [G loss: 0.863716]\n",
      "epoch:6 step:5686 [D loss: 0.669148, acc.: 50.00%] [G loss: 0.848537]\n",
      "epoch:6 step:5687 [D loss: 0.691321, acc.: 57.81%] [G loss: 0.873013]\n",
      "epoch:6 step:5688 [D loss: 0.653632, acc.: 62.50%] [G loss: 0.920625]\n",
      "epoch:6 step:5689 [D loss: 0.701884, acc.: 50.78%] [G loss: 0.877516]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5690 [D loss: 0.655954, acc.: 56.25%] [G loss: 0.839384]\n",
      "epoch:6 step:5691 [D loss: 0.649043, acc.: 56.25%] [G loss: 0.854016]\n",
      "epoch:6 step:5692 [D loss: 0.658849, acc.: 59.38%] [G loss: 0.801116]\n",
      "epoch:6 step:5693 [D loss: 0.676553, acc.: 53.91%] [G loss: 0.842133]\n",
      "epoch:6 step:5694 [D loss: 0.639603, acc.: 62.50%] [G loss: 0.882853]\n",
      "epoch:6 step:5695 [D loss: 0.610129, acc.: 67.19%] [G loss: 0.908218]\n",
      "epoch:6 step:5696 [D loss: 0.705347, acc.: 50.78%] [G loss: 0.820423]\n",
      "epoch:6 step:5697 [D loss: 0.666276, acc.: 57.81%] [G loss: 0.854776]\n",
      "epoch:6 step:5698 [D loss: 0.624637, acc.: 64.06%] [G loss: 0.882254]\n",
      "epoch:6 step:5699 [D loss: 0.668702, acc.: 56.25%] [G loss: 0.829296]\n",
      "epoch:6 step:5700 [D loss: 0.698725, acc.: 53.91%] [G loss: 0.831868]\n",
      "epoch:6 step:5701 [D loss: 0.681942, acc.: 53.12%] [G loss: 0.878209]\n",
      "epoch:6 step:5702 [D loss: 0.641246, acc.: 61.72%] [G loss: 0.929562]\n",
      "epoch:6 step:5703 [D loss: 0.653044, acc.: 58.59%] [G loss: 0.870963]\n",
      "epoch:6 step:5704 [D loss: 0.674187, acc.: 54.69%] [G loss: 0.829753]\n",
      "epoch:6 step:5705 [D loss: 0.670844, acc.: 53.91%] [G loss: 0.848120]\n",
      "epoch:6 step:5706 [D loss: 0.678854, acc.: 57.81%] [G loss: 0.863747]\n",
      "epoch:6 step:5707 [D loss: 0.675484, acc.: 53.91%] [G loss: 0.860247]\n",
      "epoch:6 step:5708 [D loss: 0.705000, acc.: 50.78%] [G loss: 0.831821]\n",
      "epoch:6 step:5709 [D loss: 0.649514, acc.: 58.59%] [G loss: 0.902282]\n",
      "epoch:6 step:5710 [D loss: 0.648423, acc.: 58.59%] [G loss: 0.868504]\n",
      "epoch:6 step:5711 [D loss: 0.634133, acc.: 64.84%] [G loss: 0.847033]\n",
      "epoch:6 step:5712 [D loss: 0.682950, acc.: 56.25%] [G loss: 0.835513]\n",
      "epoch:6 step:5713 [D loss: 0.679691, acc.: 53.91%] [G loss: 0.853979]\n",
      "epoch:6 step:5714 [D loss: 0.680789, acc.: 56.25%] [G loss: 0.841951]\n",
      "epoch:6 step:5715 [D loss: 0.658922, acc.: 60.16%] [G loss: 0.855941]\n",
      "epoch:6 step:5716 [D loss: 0.656428, acc.: 57.03%] [G loss: 0.877278]\n",
      "epoch:6 step:5717 [D loss: 0.626966, acc.: 65.62%] [G loss: 0.844039]\n",
      "epoch:6 step:5718 [D loss: 0.674801, acc.: 57.03%] [G loss: 0.859883]\n",
      "epoch:6 step:5719 [D loss: 0.644383, acc.: 62.50%] [G loss: 0.862307]\n",
      "epoch:6 step:5720 [D loss: 0.670512, acc.: 59.38%] [G loss: 0.873381]\n",
      "epoch:6 step:5721 [D loss: 0.696852, acc.: 53.12%] [G loss: 0.894550]\n",
      "epoch:6 step:5722 [D loss: 0.678576, acc.: 60.16%] [G loss: 0.893383]\n",
      "epoch:6 step:5723 [D loss: 0.676797, acc.: 58.59%] [G loss: 0.899742]\n",
      "epoch:6 step:5724 [D loss: 0.708314, acc.: 50.78%] [G loss: 0.862862]\n",
      "epoch:6 step:5725 [D loss: 0.631379, acc.: 65.62%] [G loss: 0.858714]\n",
      "epoch:6 step:5726 [D loss: 0.671531, acc.: 59.38%] [G loss: 0.894451]\n",
      "epoch:6 step:5727 [D loss: 0.645522, acc.: 58.59%] [G loss: 0.906186]\n",
      "epoch:6 step:5728 [D loss: 0.680120, acc.: 56.25%] [G loss: 0.908948]\n",
      "epoch:6 step:5729 [D loss: 0.669427, acc.: 54.69%] [G loss: 0.859741]\n",
      "epoch:6 step:5730 [D loss: 0.622904, acc.: 59.38%] [G loss: 0.921971]\n",
      "epoch:6 step:5731 [D loss: 0.619828, acc.: 68.75%] [G loss: 0.905571]\n",
      "epoch:6 step:5732 [D loss: 0.704788, acc.: 53.12%] [G loss: 0.893522]\n",
      "epoch:6 step:5733 [D loss: 0.670869, acc.: 59.38%] [G loss: 0.866320]\n",
      "epoch:6 step:5734 [D loss: 0.661402, acc.: 65.62%] [G loss: 0.885847]\n",
      "epoch:6 step:5735 [D loss: 0.652638, acc.: 60.94%] [G loss: 0.846149]\n",
      "epoch:6 step:5736 [D loss: 0.649127, acc.: 65.62%] [G loss: 0.891803]\n",
      "epoch:6 step:5737 [D loss: 0.679997, acc.: 59.38%] [G loss: 0.841668]\n",
      "epoch:6 step:5738 [D loss: 0.659426, acc.: 59.38%] [G loss: 0.848326]\n",
      "epoch:6 step:5739 [D loss: 0.686436, acc.: 55.47%] [G loss: 0.856419]\n",
      "epoch:6 step:5740 [D loss: 0.649056, acc.: 64.06%] [G loss: 0.834303]\n",
      "epoch:6 step:5741 [D loss: 0.643000, acc.: 62.50%] [G loss: 0.855983]\n",
      "epoch:6 step:5742 [D loss: 0.666661, acc.: 57.81%] [G loss: 0.848559]\n",
      "epoch:6 step:5743 [D loss: 0.667784, acc.: 58.59%] [G loss: 0.832559]\n",
      "epoch:6 step:5744 [D loss: 0.649565, acc.: 64.84%] [G loss: 0.850177]\n",
      "epoch:6 step:5745 [D loss: 0.681256, acc.: 57.81%] [G loss: 0.873827]\n",
      "epoch:6 step:5746 [D loss: 0.663799, acc.: 60.16%] [G loss: 0.889493]\n",
      "epoch:6 step:5747 [D loss: 0.660989, acc.: 56.25%] [G loss: 0.847437]\n",
      "epoch:6 step:5748 [D loss: 0.716055, acc.: 45.31%] [G loss: 0.854712]\n",
      "epoch:6 step:5749 [D loss: 0.654647, acc.: 63.28%] [G loss: 0.856879]\n",
      "epoch:6 step:5750 [D loss: 0.656356, acc.: 58.59%] [G loss: 0.905152]\n",
      "epoch:6 step:5751 [D loss: 0.647685, acc.: 64.84%] [G loss: 0.862285]\n",
      "epoch:6 step:5752 [D loss: 0.657224, acc.: 59.38%] [G loss: 0.844847]\n",
      "epoch:6 step:5753 [D loss: 0.647012, acc.: 58.59%] [G loss: 0.818139]\n",
      "epoch:6 step:5754 [D loss: 0.705604, acc.: 49.22%] [G loss: 0.845062]\n",
      "epoch:6 step:5755 [D loss: 0.662005, acc.: 63.28%] [G loss: 0.817696]\n",
      "epoch:6 step:5756 [D loss: 0.668444, acc.: 57.03%] [G loss: 0.824643]\n",
      "epoch:6 step:5757 [D loss: 0.687257, acc.: 56.25%] [G loss: 0.848591]\n",
      "epoch:6 step:5758 [D loss: 0.690738, acc.: 49.22%] [G loss: 0.870539]\n",
      "epoch:6 step:5759 [D loss: 0.647705, acc.: 64.84%] [G loss: 0.880152]\n",
      "epoch:6 step:5760 [D loss: 0.663462, acc.: 59.38%] [G loss: 0.868311]\n",
      "epoch:6 step:5761 [D loss: 0.676181, acc.: 64.06%] [G loss: 0.840404]\n",
      "epoch:6 step:5762 [D loss: 0.677684, acc.: 56.25%] [G loss: 0.828315]\n",
      "epoch:6 step:5763 [D loss: 0.656340, acc.: 57.03%] [G loss: 0.838509]\n",
      "epoch:6 step:5764 [D loss: 0.666773, acc.: 60.16%] [G loss: 0.852576]\n",
      "epoch:6 step:5765 [D loss: 0.670501, acc.: 59.38%] [G loss: 0.912531]\n",
      "epoch:6 step:5766 [D loss: 0.694641, acc.: 50.78%] [G loss: 0.874428]\n",
      "epoch:6 step:5767 [D loss: 0.666383, acc.: 49.22%] [G loss: 0.878152]\n",
      "epoch:6 step:5768 [D loss: 0.665293, acc.: 58.59%] [G loss: 0.884617]\n",
      "epoch:6 step:5769 [D loss: 0.647033, acc.: 56.25%] [G loss: 0.878771]\n",
      "epoch:6 step:5770 [D loss: 0.647201, acc.: 60.16%] [G loss: 0.851949]\n",
      "epoch:6 step:5771 [D loss: 0.634142, acc.: 65.62%] [G loss: 0.825897]\n",
      "epoch:6 step:5772 [D loss: 0.687956, acc.: 55.47%] [G loss: 0.863630]\n",
      "epoch:6 step:5773 [D loss: 0.643266, acc.: 64.84%] [G loss: 0.921967]\n",
      "epoch:6 step:5774 [D loss: 0.641750, acc.: 64.06%] [G loss: 0.874180]\n",
      "epoch:6 step:5775 [D loss: 0.656114, acc.: 57.81%] [G loss: 0.869808]\n",
      "epoch:6 step:5776 [D loss: 0.666727, acc.: 57.03%] [G loss: 0.878601]\n",
      "epoch:6 step:5777 [D loss: 0.666358, acc.: 56.25%] [G loss: 0.876588]\n",
      "epoch:6 step:5778 [D loss: 0.627536, acc.: 66.41%] [G loss: 0.899065]\n",
      "epoch:6 step:5779 [D loss: 0.687443, acc.: 57.81%] [G loss: 0.891979]\n",
      "epoch:6 step:5780 [D loss: 0.646956, acc.: 64.84%] [G loss: 0.868434]\n",
      "epoch:6 step:5781 [D loss: 0.669618, acc.: 56.25%] [G loss: 0.894289]\n",
      "epoch:6 step:5782 [D loss: 0.701987, acc.: 57.81%] [G loss: 0.892442]\n",
      "epoch:6 step:5783 [D loss: 0.646653, acc.: 64.06%] [G loss: 0.885991]\n",
      "epoch:6 step:5784 [D loss: 0.604500, acc.: 71.09%] [G loss: 0.878150]\n",
      "epoch:6 step:5785 [D loss: 0.665869, acc.: 54.69%] [G loss: 0.866300]\n",
      "epoch:6 step:5786 [D loss: 0.687684, acc.: 53.91%] [G loss: 0.863350]\n",
      "epoch:6 step:5787 [D loss: 0.673846, acc.: 57.81%] [G loss: 0.877234]\n",
      "epoch:6 step:5788 [D loss: 0.667750, acc.: 53.91%] [G loss: 0.884036]\n",
      "epoch:6 step:5789 [D loss: 0.633739, acc.: 63.28%] [G loss: 0.874562]\n",
      "epoch:6 step:5790 [D loss: 0.675044, acc.: 53.12%] [G loss: 0.900584]\n",
      "epoch:6 step:5791 [D loss: 0.663085, acc.: 59.38%] [G loss: 0.824676]\n",
      "epoch:6 step:5792 [D loss: 0.698471, acc.: 53.12%] [G loss: 0.883682]\n",
      "epoch:6 step:5793 [D loss: 0.662318, acc.: 57.81%] [G loss: 0.850140]\n",
      "epoch:6 step:5794 [D loss: 0.633990, acc.: 59.38%] [G loss: 0.864142]\n",
      "epoch:6 step:5795 [D loss: 0.689552, acc.: 51.56%] [G loss: 0.816481]\n",
      "epoch:6 step:5796 [D loss: 0.668745, acc.: 59.38%] [G loss: 0.835178]\n",
      "epoch:6 step:5797 [D loss: 0.660450, acc.: 60.16%] [G loss: 0.831960]\n",
      "epoch:6 step:5798 [D loss: 0.681723, acc.: 57.03%] [G loss: 0.798388]\n",
      "epoch:6 step:5799 [D loss: 0.664175, acc.: 61.72%] [G loss: 0.833128]\n",
      "epoch:6 step:5800 [D loss: 0.628228, acc.: 62.50%] [G loss: 0.917468]\n",
      "##############\n",
      "[ 3.07875227  2.70155025  2.31806877  4.13866771  1.81461031 10.27426719\n",
      "  3.10654297  4.0524539   4.31469587  8.14868929]\n",
      "##########\n",
      "epoch:6 step:5801 [D loss: 0.675012, acc.: 67.19%] [G loss: 0.912301]\n",
      "epoch:6 step:5802 [D loss: 0.664922, acc.: 55.47%] [G loss: 0.893574]\n",
      "epoch:6 step:5803 [D loss: 0.721243, acc.: 49.22%] [G loss: 0.848782]\n",
      "epoch:6 step:5804 [D loss: 0.651595, acc.: 63.28%] [G loss: 0.849117]\n",
      "epoch:6 step:5805 [D loss: 0.703233, acc.: 53.12%] [G loss: 0.856226]\n",
      "epoch:6 step:5806 [D loss: 0.656652, acc.: 63.28%] [G loss: 0.862700]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5807 [D loss: 0.674718, acc.: 57.81%] [G loss: 0.850033]\n",
      "epoch:6 step:5808 [D loss: 0.684265, acc.: 54.69%] [G loss: 0.847971]\n",
      "epoch:6 step:5809 [D loss: 0.634663, acc.: 63.28%] [G loss: 0.882217]\n",
      "epoch:6 step:5810 [D loss: 0.668325, acc.: 57.03%] [G loss: 0.849950]\n",
      "epoch:6 step:5811 [D loss: 0.645125, acc.: 60.94%] [G loss: 0.881834]\n",
      "epoch:6 step:5812 [D loss: 0.677143, acc.: 58.59%] [G loss: 0.894482]\n",
      "epoch:6 step:5813 [D loss: 0.650568, acc.: 61.72%] [G loss: 0.891394]\n",
      "epoch:6 step:5814 [D loss: 0.669669, acc.: 55.47%] [G loss: 0.965262]\n",
      "epoch:6 step:5815 [D loss: 0.663512, acc.: 58.59%] [G loss: 0.936061]\n",
      "epoch:6 step:5816 [D loss: 0.690185, acc.: 53.12%] [G loss: 0.853045]\n",
      "epoch:6 step:5817 [D loss: 0.638311, acc.: 65.62%] [G loss: 0.870107]\n",
      "epoch:6 step:5818 [D loss: 0.656539, acc.: 60.16%] [G loss: 0.824336]\n",
      "epoch:6 step:5819 [D loss: 0.635006, acc.: 67.19%] [G loss: 0.858040]\n",
      "epoch:6 step:5820 [D loss: 0.619001, acc.: 58.59%] [G loss: 0.884401]\n",
      "epoch:6 step:5821 [D loss: 0.637828, acc.: 60.94%] [G loss: 0.920520]\n",
      "epoch:6 step:5822 [D loss: 0.642640, acc.: 57.03%] [G loss: 0.871310]\n",
      "epoch:6 step:5823 [D loss: 0.617892, acc.: 74.22%] [G loss: 0.846333]\n",
      "epoch:6 step:5824 [D loss: 0.594677, acc.: 65.62%] [G loss: 0.893276]\n",
      "epoch:6 step:5825 [D loss: 0.689463, acc.: 53.91%] [G loss: 0.930278]\n",
      "epoch:6 step:5826 [D loss: 0.660168, acc.: 57.81%] [G loss: 0.876395]\n",
      "epoch:6 step:5827 [D loss: 0.660402, acc.: 60.16%] [G loss: 0.878231]\n",
      "epoch:6 step:5828 [D loss: 0.648443, acc.: 62.50%] [G loss: 0.880592]\n",
      "epoch:6 step:5829 [D loss: 0.641608, acc.: 63.28%] [G loss: 0.812202]\n",
      "epoch:6 step:5830 [D loss: 0.636983, acc.: 62.50%] [G loss: 0.867341]\n",
      "epoch:6 step:5831 [D loss: 0.685682, acc.: 57.03%] [G loss: 0.841155]\n",
      "epoch:6 step:5832 [D loss: 0.663940, acc.: 57.81%] [G loss: 0.840402]\n",
      "epoch:6 step:5833 [D loss: 0.658620, acc.: 60.94%] [G loss: 0.870669]\n",
      "epoch:6 step:5834 [D loss: 0.657037, acc.: 57.03%] [G loss: 0.923372]\n",
      "epoch:6 step:5835 [D loss: 0.683138, acc.: 58.59%] [G loss: 0.900844]\n",
      "epoch:6 step:5836 [D loss: 0.647932, acc.: 60.16%] [G loss: 0.904116]\n",
      "epoch:6 step:5837 [D loss: 0.682355, acc.: 57.03%] [G loss: 0.861550]\n",
      "epoch:6 step:5838 [D loss: 0.657454, acc.: 57.81%] [G loss: 0.874032]\n",
      "epoch:6 step:5839 [D loss: 0.614010, acc.: 67.19%] [G loss: 0.866505]\n",
      "epoch:6 step:5840 [D loss: 0.686655, acc.: 57.81%] [G loss: 0.848922]\n",
      "epoch:6 step:5841 [D loss: 0.669960, acc.: 57.03%] [G loss: 0.879698]\n",
      "epoch:6 step:5842 [D loss: 0.716731, acc.: 48.44%] [G loss: 0.814138]\n",
      "epoch:6 step:5843 [D loss: 0.658163, acc.: 57.03%] [G loss: 0.802604]\n",
      "epoch:6 step:5844 [D loss: 0.670026, acc.: 57.81%] [G loss: 0.822795]\n",
      "epoch:6 step:5845 [D loss: 0.664606, acc.: 56.25%] [G loss: 0.865270]\n",
      "epoch:6 step:5846 [D loss: 0.707764, acc.: 58.59%] [G loss: 0.866304]\n",
      "epoch:6 step:5847 [D loss: 0.622039, acc.: 61.72%] [G loss: 0.836763]\n",
      "epoch:6 step:5848 [D loss: 0.683406, acc.: 56.25%] [G loss: 0.873917]\n",
      "epoch:6 step:5849 [D loss: 0.662366, acc.: 57.81%] [G loss: 0.832336]\n",
      "epoch:6 step:5850 [D loss: 0.656823, acc.: 60.16%] [G loss: 0.829154]\n",
      "epoch:6 step:5851 [D loss: 0.677935, acc.: 57.03%] [G loss: 0.865585]\n",
      "epoch:6 step:5852 [D loss: 0.680539, acc.: 57.03%] [G loss: 0.818683]\n",
      "epoch:6 step:5853 [D loss: 0.669819, acc.: 59.38%] [G loss: 0.846048]\n",
      "epoch:6 step:5854 [D loss: 0.657454, acc.: 64.06%] [G loss: 0.913262]\n",
      "epoch:6 step:5855 [D loss: 0.684568, acc.: 60.94%] [G loss: 0.864216]\n",
      "epoch:6 step:5856 [D loss: 0.675916, acc.: 57.81%] [G loss: 0.893015]\n",
      "epoch:6 step:5857 [D loss: 0.684932, acc.: 56.25%] [G loss: 0.899724]\n",
      "epoch:6 step:5858 [D loss: 0.670990, acc.: 59.38%] [G loss: 0.833979]\n",
      "epoch:6 step:5859 [D loss: 0.709484, acc.: 50.78%] [G loss: 0.850402]\n",
      "epoch:6 step:5860 [D loss: 0.646671, acc.: 64.06%] [G loss: 0.817151]\n",
      "epoch:6 step:5861 [D loss: 0.670624, acc.: 58.59%] [G loss: 0.856623]\n",
      "epoch:6 step:5862 [D loss: 0.650878, acc.: 63.28%] [G loss: 0.865910]\n",
      "epoch:6 step:5863 [D loss: 0.671494, acc.: 56.25%] [G loss: 0.858905]\n",
      "epoch:6 step:5864 [D loss: 0.679866, acc.: 56.25%] [G loss: 0.841113]\n",
      "epoch:6 step:5865 [D loss: 0.643266, acc.: 61.72%] [G loss: 0.867214]\n",
      "epoch:6 step:5866 [D loss: 0.668331, acc.: 60.16%] [G loss: 0.843551]\n",
      "epoch:6 step:5867 [D loss: 0.667292, acc.: 54.69%] [G loss: 0.840829]\n",
      "epoch:6 step:5868 [D loss: 0.651513, acc.: 59.38%] [G loss: 0.823622]\n",
      "epoch:6 step:5869 [D loss: 0.673418, acc.: 50.78%] [G loss: 0.892813]\n",
      "epoch:6 step:5870 [D loss: 0.651771, acc.: 65.62%] [G loss: 0.886226]\n",
      "epoch:6 step:5871 [D loss: 0.659481, acc.: 56.25%] [G loss: 0.846705]\n",
      "epoch:6 step:5872 [D loss: 0.684057, acc.: 54.69%] [G loss: 0.856699]\n",
      "epoch:6 step:5873 [D loss: 0.675905, acc.: 57.81%] [G loss: 0.883960]\n",
      "epoch:6 step:5874 [D loss: 0.658207, acc.: 60.16%] [G loss: 0.866334]\n",
      "epoch:6 step:5875 [D loss: 0.667626, acc.: 57.81%] [G loss: 0.866394]\n",
      "epoch:6 step:5876 [D loss: 0.700414, acc.: 49.22%] [G loss: 0.864982]\n",
      "epoch:6 step:5877 [D loss: 0.653822, acc.: 57.03%] [G loss: 0.882267]\n",
      "epoch:6 step:5878 [D loss: 0.652371, acc.: 60.16%] [G loss: 0.865360]\n",
      "epoch:6 step:5879 [D loss: 0.642989, acc.: 64.84%] [G loss: 0.850100]\n",
      "epoch:6 step:5880 [D loss: 0.698425, acc.: 50.78%] [G loss: 0.880099]\n",
      "epoch:6 step:5881 [D loss: 0.650387, acc.: 58.59%] [G loss: 0.895031]\n",
      "epoch:6 step:5882 [D loss: 0.614671, acc.: 69.53%] [G loss: 0.910357]\n",
      "epoch:6 step:5883 [D loss: 0.688146, acc.: 53.91%] [G loss: 0.920425]\n",
      "epoch:6 step:5884 [D loss: 0.693174, acc.: 57.03%] [G loss: 0.890143]\n",
      "epoch:6 step:5885 [D loss: 0.681549, acc.: 60.94%] [G loss: 0.880050]\n",
      "epoch:6 step:5886 [D loss: 0.641021, acc.: 66.41%] [G loss: 0.872143]\n",
      "epoch:6 step:5887 [D loss: 0.644202, acc.: 64.06%] [G loss: 0.867062]\n",
      "epoch:6 step:5888 [D loss: 0.640234, acc.: 61.72%] [G loss: 0.863716]\n",
      "epoch:6 step:5889 [D loss: 0.673561, acc.: 56.25%] [G loss: 0.876761]\n",
      "epoch:6 step:5890 [D loss: 0.683204, acc.: 53.91%] [G loss: 0.836023]\n",
      "epoch:6 step:5891 [D loss: 0.686555, acc.: 57.81%] [G loss: 0.831756]\n",
      "epoch:6 step:5892 [D loss: 0.650285, acc.: 59.38%] [G loss: 0.870870]\n",
      "epoch:6 step:5893 [D loss: 0.668478, acc.: 57.81%] [G loss: 0.829614]\n",
      "epoch:6 step:5894 [D loss: 0.660146, acc.: 61.72%] [G loss: 0.851897]\n",
      "epoch:6 step:5895 [D loss: 0.681749, acc.: 57.81%] [G loss: 0.830183]\n",
      "epoch:6 step:5896 [D loss: 0.674741, acc.: 56.25%] [G loss: 0.790276]\n",
      "epoch:6 step:5897 [D loss: 0.697865, acc.: 56.25%] [G loss: 0.861947]\n",
      "epoch:6 step:5898 [D loss: 0.666658, acc.: 57.03%] [G loss: 0.862756]\n",
      "epoch:6 step:5899 [D loss: 0.685178, acc.: 53.91%] [G loss: 0.831323]\n",
      "epoch:6 step:5900 [D loss: 0.660894, acc.: 60.16%] [G loss: 0.891879]\n",
      "epoch:6 step:5901 [D loss: 0.696565, acc.: 59.38%] [G loss: 0.900135]\n",
      "epoch:6 step:5902 [D loss: 0.656635, acc.: 59.38%] [G loss: 0.939579]\n",
      "epoch:6 step:5903 [D loss: 0.670032, acc.: 60.16%] [G loss: 0.881566]\n",
      "epoch:6 step:5904 [D loss: 0.660290, acc.: 62.50%] [G loss: 0.877579]\n",
      "epoch:6 step:5905 [D loss: 0.635519, acc.: 57.03%] [G loss: 0.887871]\n",
      "epoch:6 step:5906 [D loss: 0.638031, acc.: 62.50%] [G loss: 0.858100]\n",
      "epoch:6 step:5907 [D loss: 0.623434, acc.: 67.97%] [G loss: 0.817552]\n",
      "epoch:6 step:5908 [D loss: 0.681253, acc.: 58.59%] [G loss: 0.826882]\n",
      "epoch:6 step:5909 [D loss: 0.655143, acc.: 60.16%] [G loss: 0.856737]\n",
      "epoch:6 step:5910 [D loss: 0.636464, acc.: 64.84%] [G loss: 0.837547]\n",
      "epoch:6 step:5911 [D loss: 0.657268, acc.: 58.59%] [G loss: 0.845781]\n",
      "epoch:6 step:5912 [D loss: 0.656544, acc.: 64.06%] [G loss: 0.896097]\n",
      "epoch:6 step:5913 [D loss: 0.650785, acc.: 57.81%] [G loss: 0.862613]\n",
      "epoch:6 step:5914 [D loss: 0.654974, acc.: 64.84%] [G loss: 0.866375]\n",
      "epoch:6 step:5915 [D loss: 0.665885, acc.: 60.94%] [G loss: 0.912421]\n",
      "epoch:6 step:5916 [D loss: 0.644219, acc.: 60.94%] [G loss: 0.878193]\n",
      "epoch:6 step:5917 [D loss: 0.663085, acc.: 57.81%] [G loss: 0.879515]\n",
      "epoch:6 step:5918 [D loss: 0.651592, acc.: 60.16%] [G loss: 0.852325]\n",
      "epoch:6 step:5919 [D loss: 0.659202, acc.: 62.50%] [G loss: 0.892249]\n",
      "epoch:6 step:5920 [D loss: 0.657850, acc.: 60.16%] [G loss: 0.937207]\n",
      "epoch:6 step:5921 [D loss: 0.663593, acc.: 57.81%] [G loss: 0.863280]\n",
      "epoch:6 step:5922 [D loss: 0.672105, acc.: 60.16%] [G loss: 0.838587]\n",
      "epoch:6 step:5923 [D loss: 0.661056, acc.: 57.81%] [G loss: 0.877357]\n",
      "epoch:6 step:5924 [D loss: 0.684892, acc.: 58.59%] [G loss: 0.821400]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:5925 [D loss: 0.651113, acc.: 63.28%] [G loss: 0.857946]\n",
      "epoch:6 step:5926 [D loss: 0.662568, acc.: 56.25%] [G loss: 0.899191]\n",
      "epoch:6 step:5927 [D loss: 0.640521, acc.: 62.50%] [G loss: 0.864993]\n",
      "epoch:6 step:5928 [D loss: 0.654309, acc.: 58.59%] [G loss: 0.850077]\n",
      "epoch:6 step:5929 [D loss: 0.697360, acc.: 58.59%] [G loss: 0.889729]\n",
      "epoch:6 step:5930 [D loss: 0.677404, acc.: 56.25%] [G loss: 0.854440]\n",
      "epoch:6 step:5931 [D loss: 0.617819, acc.: 65.62%] [G loss: 0.891286]\n",
      "epoch:6 step:5932 [D loss: 0.713575, acc.: 51.56%] [G loss: 0.884334]\n",
      "epoch:6 step:5933 [D loss: 0.683331, acc.: 50.00%] [G loss: 0.915885]\n",
      "epoch:6 step:5934 [D loss: 0.721211, acc.: 41.41%] [G loss: 0.846757]\n",
      "epoch:6 step:5935 [D loss: 0.680521, acc.: 48.44%] [G loss: 0.817872]\n",
      "epoch:6 step:5936 [D loss: 0.654809, acc.: 60.94%] [G loss: 0.804535]\n",
      "epoch:6 step:5937 [D loss: 0.657076, acc.: 58.59%] [G loss: 0.863316]\n",
      "epoch:6 step:5938 [D loss: 0.644446, acc.: 62.50%] [G loss: 0.878761]\n",
      "epoch:6 step:5939 [D loss: 0.659632, acc.: 57.81%] [G loss: 0.829900]\n",
      "epoch:6 step:5940 [D loss: 0.683680, acc.: 53.12%] [G loss: 0.855662]\n",
      "epoch:6 step:5941 [D loss: 0.662185, acc.: 64.06%] [G loss: 0.889676]\n",
      "epoch:6 step:5942 [D loss: 0.638195, acc.: 64.84%] [G loss: 0.873364]\n",
      "epoch:6 step:5943 [D loss: 0.645852, acc.: 64.84%] [G loss: 0.861165]\n",
      "epoch:6 step:5944 [D loss: 0.664832, acc.: 60.16%] [G loss: 0.858042]\n",
      "epoch:6 step:5945 [D loss: 0.677516, acc.: 58.59%] [G loss: 0.845330]\n",
      "epoch:6 step:5946 [D loss: 0.645685, acc.: 65.62%] [G loss: 0.815230]\n",
      "epoch:6 step:5947 [D loss: 0.656211, acc.: 61.72%] [G loss: 0.816927]\n",
      "epoch:6 step:5948 [D loss: 0.676172, acc.: 58.59%] [G loss: 0.873986]\n",
      "epoch:6 step:5949 [D loss: 0.625549, acc.: 66.41%] [G loss: 0.856639]\n",
      "epoch:6 step:5950 [D loss: 0.623621, acc.: 68.75%] [G loss: 0.851354]\n",
      "epoch:6 step:5951 [D loss: 0.663282, acc.: 60.16%] [G loss: 0.814429]\n",
      "epoch:6 step:5952 [D loss: 0.631346, acc.: 67.97%] [G loss: 0.815675]\n",
      "epoch:6 step:5953 [D loss: 0.668804, acc.: 56.25%] [G loss: 0.821114]\n",
      "epoch:6 step:5954 [D loss: 0.671942, acc.: 61.72%] [G loss: 0.813810]\n",
      "epoch:6 step:5955 [D loss: 0.669851, acc.: 59.38%] [G loss: 0.803383]\n",
      "epoch:6 step:5956 [D loss: 0.699986, acc.: 53.12%] [G loss: 0.801791]\n",
      "epoch:6 step:5957 [D loss: 0.660151, acc.: 59.38%] [G loss: 0.805826]\n",
      "epoch:6 step:5958 [D loss: 0.648353, acc.: 58.59%] [G loss: 0.867454]\n",
      "epoch:6 step:5959 [D loss: 0.671023, acc.: 55.47%] [G loss: 0.898406]\n",
      "epoch:6 step:5960 [D loss: 0.628782, acc.: 63.28%] [G loss: 0.891719]\n",
      "epoch:6 step:5961 [D loss: 0.625472, acc.: 60.16%] [G loss: 0.843012]\n",
      "epoch:6 step:5962 [D loss: 0.674037, acc.: 57.03%] [G loss: 0.854417]\n",
      "epoch:6 step:5963 [D loss: 0.667324, acc.: 58.59%] [G loss: 0.836865]\n",
      "epoch:6 step:5964 [D loss: 0.667910, acc.: 60.16%] [G loss: 0.860128]\n",
      "epoch:6 step:5965 [D loss: 0.705806, acc.: 50.00%] [G loss: 0.883612]\n",
      "epoch:6 step:5966 [D loss: 0.688689, acc.: 60.16%] [G loss: 0.893461]\n",
      "epoch:6 step:5967 [D loss: 0.689210, acc.: 57.03%] [G loss: 0.856874]\n",
      "epoch:6 step:5968 [D loss: 0.667516, acc.: 57.81%] [G loss: 0.836498]\n",
      "epoch:6 step:5969 [D loss: 0.665406, acc.: 57.81%] [G loss: 0.890489]\n",
      "epoch:6 step:5970 [D loss: 0.653301, acc.: 57.03%] [G loss: 0.893795]\n",
      "epoch:6 step:5971 [D loss: 0.630797, acc.: 65.62%] [G loss: 0.878771]\n",
      "epoch:6 step:5972 [D loss: 0.690314, acc.: 53.12%] [G loss: 0.850791]\n",
      "epoch:6 step:5973 [D loss: 0.640407, acc.: 67.19%] [G loss: 0.904827]\n",
      "epoch:6 step:5974 [D loss: 0.684718, acc.: 54.69%] [G loss: 0.878976]\n",
      "epoch:6 step:5975 [D loss: 0.699915, acc.: 54.69%] [G loss: 0.829439]\n",
      "epoch:6 step:5976 [D loss: 0.681340, acc.: 55.47%] [G loss: 0.831693]\n",
      "epoch:6 step:5977 [D loss: 0.655068, acc.: 57.81%] [G loss: 0.848635]\n",
      "epoch:6 step:5978 [D loss: 0.654274, acc.: 62.50%] [G loss: 0.802856]\n",
      "epoch:6 step:5979 [D loss: 0.678768, acc.: 53.91%] [G loss: 0.819296]\n",
      "epoch:6 step:5980 [D loss: 0.626750, acc.: 69.53%] [G loss: 0.885136]\n",
      "epoch:6 step:5981 [D loss: 0.712257, acc.: 46.88%] [G loss: 0.842025]\n",
      "epoch:6 step:5982 [D loss: 0.648826, acc.: 60.16%] [G loss: 0.886472]\n",
      "epoch:6 step:5983 [D loss: 0.676081, acc.: 57.81%] [G loss: 0.893142]\n",
      "epoch:6 step:5984 [D loss: 0.641120, acc.: 62.50%] [G loss: 0.859297]\n",
      "epoch:6 step:5985 [D loss: 0.686693, acc.: 53.91%] [G loss: 0.865431]\n",
      "epoch:6 step:5986 [D loss: 0.681514, acc.: 54.69%] [G loss: 0.892048]\n",
      "epoch:6 step:5987 [D loss: 0.635453, acc.: 62.50%] [G loss: 0.832057]\n",
      "epoch:6 step:5988 [D loss: 0.673413, acc.: 57.81%] [G loss: 0.881609]\n",
      "epoch:6 step:5989 [D loss: 0.708141, acc.: 50.00%] [G loss: 0.911426]\n",
      "epoch:6 step:5990 [D loss: 0.651577, acc.: 61.72%] [G loss: 0.879357]\n",
      "epoch:6 step:5991 [D loss: 0.673033, acc.: 57.81%] [G loss: 0.869641]\n",
      "epoch:6 step:5992 [D loss: 0.656409, acc.: 61.72%] [G loss: 0.852483]\n",
      "epoch:6 step:5993 [D loss: 0.665162, acc.: 57.03%] [G loss: 0.862243]\n",
      "epoch:6 step:5994 [D loss: 0.657006, acc.: 52.34%] [G loss: 0.822028]\n",
      "epoch:6 step:5995 [D loss: 0.671447, acc.: 57.03%] [G loss: 0.853109]\n",
      "epoch:6 step:5996 [D loss: 0.675363, acc.: 60.94%] [G loss: 0.847465]\n",
      "epoch:6 step:5997 [D loss: 0.695962, acc.: 51.56%] [G loss: 0.828130]\n",
      "epoch:6 step:5998 [D loss: 0.683815, acc.: 56.25%] [G loss: 0.829593]\n",
      "epoch:6 step:5999 [D loss: 0.671943, acc.: 57.03%] [G loss: 0.854927]\n",
      "epoch:6 step:6000 [D loss: 0.642874, acc.: 59.38%] [G loss: 0.832211]\n",
      "##############\n",
      "[3.17426091 2.75114839 2.23090104 3.90311224 1.5285347  7.7718154\n",
      " 3.04272736 3.90110093 4.30472374 7.14868929]\n",
      "##########\n",
      "epoch:6 step:6001 [D loss: 0.664770, acc.: 60.16%] [G loss: 0.832125]\n",
      "epoch:6 step:6002 [D loss: 0.658891, acc.: 57.81%] [G loss: 0.809461]\n",
      "epoch:6 step:6003 [D loss: 0.663095, acc.: 59.38%] [G loss: 0.816376]\n",
      "epoch:6 step:6004 [D loss: 0.662300, acc.: 59.38%] [G loss: 0.815309]\n",
      "epoch:6 step:6005 [D loss: 0.692617, acc.: 53.91%] [G loss: 0.777233]\n",
      "epoch:6 step:6006 [D loss: 0.707773, acc.: 44.53%] [G loss: 0.871448]\n",
      "epoch:6 step:6007 [D loss: 0.727010, acc.: 50.00%] [G loss: 0.836596]\n",
      "epoch:6 step:6008 [D loss: 0.694268, acc.: 56.25%] [G loss: 0.840408]\n",
      "epoch:6 step:6009 [D loss: 0.677901, acc.: 57.03%] [G loss: 0.878974]\n",
      "epoch:6 step:6010 [D loss: 0.702645, acc.: 46.88%] [G loss: 0.855298]\n",
      "epoch:6 step:6011 [D loss: 0.639034, acc.: 65.62%] [G loss: 0.841840]\n",
      "epoch:6 step:6012 [D loss: 0.672916, acc.: 58.59%] [G loss: 0.862739]\n",
      "epoch:6 step:6013 [D loss: 0.677126, acc.: 56.25%] [G loss: 0.871917]\n",
      "epoch:6 step:6014 [D loss: 0.669100, acc.: 61.72%] [G loss: 0.868466]\n",
      "epoch:6 step:6015 [D loss: 0.700809, acc.: 49.22%] [G loss: 0.851968]\n",
      "epoch:6 step:6016 [D loss: 0.719333, acc.: 53.12%] [G loss: 0.866981]\n",
      "epoch:6 step:6017 [D loss: 0.682158, acc.: 54.69%] [G loss: 0.846112]\n",
      "epoch:6 step:6018 [D loss: 0.683341, acc.: 57.03%] [G loss: 0.853089]\n",
      "epoch:6 step:6019 [D loss: 0.673465, acc.: 55.47%] [G loss: 0.883441]\n",
      "epoch:6 step:6020 [D loss: 0.673033, acc.: 57.81%] [G loss: 0.849891]\n",
      "epoch:6 step:6021 [D loss: 0.643734, acc.: 62.50%] [G loss: 0.870847]\n",
      "epoch:6 step:6022 [D loss: 0.665937, acc.: 61.72%] [G loss: 0.850496]\n",
      "epoch:6 step:6023 [D loss: 0.631277, acc.: 63.28%] [G loss: 0.854918]\n",
      "epoch:6 step:6024 [D loss: 0.629879, acc.: 64.06%] [G loss: 0.830202]\n",
      "epoch:6 step:6025 [D loss: 0.642094, acc.: 61.72%] [G loss: 0.818740]\n",
      "epoch:6 step:6026 [D loss: 0.674718, acc.: 56.25%] [G loss: 0.875762]\n",
      "epoch:6 step:6027 [D loss: 0.657643, acc.: 60.16%] [G loss: 0.852278]\n",
      "epoch:6 step:6028 [D loss: 0.665656, acc.: 57.81%] [G loss: 0.849108]\n",
      "epoch:6 step:6029 [D loss: 0.688705, acc.: 60.16%] [G loss: 0.816874]\n",
      "epoch:6 step:6030 [D loss: 0.647865, acc.: 57.03%] [G loss: 0.860852]\n",
      "epoch:6 step:6031 [D loss: 0.617029, acc.: 67.19%] [G loss: 0.838148]\n",
      "epoch:6 step:6032 [D loss: 0.661391, acc.: 61.72%] [G loss: 0.836727]\n",
      "epoch:6 step:6033 [D loss: 0.685894, acc.: 54.69%] [G loss: 0.875345]\n",
      "epoch:6 step:6034 [D loss: 0.643163, acc.: 60.94%] [G loss: 0.831371]\n",
      "epoch:6 step:6035 [D loss: 0.672787, acc.: 53.91%] [G loss: 0.859628]\n",
      "epoch:6 step:6036 [D loss: 0.652892, acc.: 61.72%] [G loss: 0.892333]\n",
      "epoch:6 step:6037 [D loss: 0.674603, acc.: 55.47%] [G loss: 0.907272]\n",
      "epoch:6 step:6038 [D loss: 0.642445, acc.: 65.62%] [G loss: 0.929250]\n",
      "epoch:6 step:6039 [D loss: 0.631021, acc.: 59.38%] [G loss: 0.899134]\n",
      "epoch:6 step:6040 [D loss: 0.663131, acc.: 58.59%] [G loss: 0.862067]\n",
      "epoch:6 step:6041 [D loss: 0.670527, acc.: 60.16%] [G loss: 0.869041]\n",
      "epoch:6 step:6042 [D loss: 0.626530, acc.: 70.31%] [G loss: 0.873117]\n",
      "epoch:6 step:6043 [D loss: 0.608430, acc.: 70.31%] [G loss: 0.889841]\n",
      "epoch:6 step:6044 [D loss: 0.698199, acc.: 56.25%] [G loss: 0.872330]\n",
      "epoch:6 step:6045 [D loss: 0.672332, acc.: 54.69%] [G loss: 0.887736]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6046 [D loss: 0.643343, acc.: 62.50%] [G loss: 0.877148]\n",
      "epoch:6 step:6047 [D loss: 0.658683, acc.: 57.03%] [G loss: 0.857524]\n",
      "epoch:6 step:6048 [D loss: 0.687219, acc.: 53.91%] [G loss: 0.844772]\n",
      "epoch:6 step:6049 [D loss: 0.682526, acc.: 56.25%] [G loss: 0.810443]\n",
      "epoch:6 step:6050 [D loss: 0.693860, acc.: 53.12%] [G loss: 0.840528]\n",
      "epoch:6 step:6051 [D loss: 0.724283, acc.: 54.69%] [G loss: 0.861153]\n",
      "epoch:6 step:6052 [D loss: 0.696185, acc.: 54.69%] [G loss: 0.917276]\n",
      "epoch:6 step:6053 [D loss: 0.634666, acc.: 64.84%] [G loss: 0.914490]\n",
      "epoch:6 step:6054 [D loss: 0.672848, acc.: 53.91%] [G loss: 0.862705]\n",
      "epoch:6 step:6055 [D loss: 0.689373, acc.: 53.12%] [G loss: 0.932162]\n",
      "epoch:6 step:6056 [D loss: 0.672887, acc.: 59.38%] [G loss: 0.861753]\n",
      "epoch:6 step:6057 [D loss: 0.663782, acc.: 55.47%] [G loss: 0.897585]\n",
      "epoch:6 step:6058 [D loss: 0.676023, acc.: 58.59%] [G loss: 0.882078]\n",
      "epoch:6 step:6059 [D loss: 0.657006, acc.: 63.28%] [G loss: 0.886270]\n",
      "epoch:6 step:6060 [D loss: 0.648413, acc.: 65.62%] [G loss: 0.842331]\n",
      "epoch:6 step:6061 [D loss: 0.668788, acc.: 56.25%] [G loss: 0.839872]\n",
      "epoch:6 step:6062 [D loss: 0.677123, acc.: 60.16%] [G loss: 0.829520]\n",
      "epoch:6 step:6063 [D loss: 0.654222, acc.: 58.59%] [G loss: 0.835583]\n",
      "epoch:6 step:6064 [D loss: 0.673801, acc.: 59.38%] [G loss: 0.798554]\n",
      "epoch:6 step:6065 [D loss: 0.661624, acc.: 63.28%] [G loss: 0.848043]\n",
      "epoch:6 step:6066 [D loss: 0.670300, acc.: 59.38%] [G loss: 0.866363]\n",
      "epoch:6 step:6067 [D loss: 0.667908, acc.: 54.69%] [G loss: 0.810845]\n",
      "epoch:6 step:6068 [D loss: 0.705511, acc.: 50.78%] [G loss: 0.842245]\n",
      "epoch:6 step:6069 [D loss: 0.683646, acc.: 57.03%] [G loss: 0.869923]\n",
      "epoch:6 step:6070 [D loss: 0.697945, acc.: 46.88%] [G loss: 0.863806]\n",
      "epoch:6 step:6071 [D loss: 0.656276, acc.: 60.94%] [G loss: 0.916723]\n",
      "epoch:6 step:6072 [D loss: 0.633515, acc.: 64.06%] [G loss: 0.862208]\n",
      "epoch:6 step:6073 [D loss: 0.642758, acc.: 70.31%] [G loss: 0.871317]\n",
      "epoch:6 step:6074 [D loss: 0.659336, acc.: 62.50%] [G loss: 0.859003]\n",
      "epoch:6 step:6075 [D loss: 0.629365, acc.: 60.94%] [G loss: 0.873514]\n",
      "epoch:6 step:6076 [D loss: 0.675800, acc.: 59.38%] [G loss: 0.851472]\n",
      "epoch:6 step:6077 [D loss: 0.623200, acc.: 68.75%] [G loss: 0.845686]\n",
      "epoch:6 step:6078 [D loss: 0.632052, acc.: 68.75%] [G loss: 0.836174]\n",
      "epoch:6 step:6079 [D loss: 0.659853, acc.: 58.59%] [G loss: 0.777425]\n",
      "epoch:6 step:6080 [D loss: 0.612130, acc.: 66.41%] [G loss: 0.808875]\n",
      "epoch:6 step:6081 [D loss: 0.632307, acc.: 65.62%] [G loss: 0.848049]\n",
      "epoch:6 step:6082 [D loss: 0.655874, acc.: 60.16%] [G loss: 0.838822]\n",
      "epoch:6 step:6083 [D loss: 0.674317, acc.: 54.69%] [G loss: 0.855794]\n",
      "epoch:6 step:6084 [D loss: 0.650135, acc.: 62.50%] [G loss: 0.902135]\n",
      "epoch:6 step:6085 [D loss: 0.679138, acc.: 57.03%] [G loss: 0.843998]\n",
      "epoch:6 step:6086 [D loss: 0.678047, acc.: 50.78%] [G loss: 0.845032]\n",
      "epoch:6 step:6087 [D loss: 0.719278, acc.: 46.09%] [G loss: 0.816198]\n",
      "epoch:6 step:6088 [D loss: 0.626462, acc.: 62.50%] [G loss: 0.810178]\n",
      "epoch:6 step:6089 [D loss: 0.660732, acc.: 58.59%] [G loss: 0.836785]\n",
      "epoch:6 step:6090 [D loss: 0.639144, acc.: 65.62%] [G loss: 0.868453]\n",
      "epoch:6 step:6091 [D loss: 0.661075, acc.: 60.16%] [G loss: 0.868457]\n",
      "epoch:6 step:6092 [D loss: 0.686700, acc.: 57.03%] [G loss: 0.835549]\n",
      "epoch:6 step:6093 [D loss: 0.670574, acc.: 58.59%] [G loss: 0.899509]\n",
      "epoch:6 step:6094 [D loss: 0.644192, acc.: 67.19%] [G loss: 0.938120]\n",
      "epoch:6 step:6095 [D loss: 0.665473, acc.: 59.38%] [G loss: 0.939207]\n",
      "epoch:6 step:6096 [D loss: 0.637966, acc.: 69.53%] [G loss: 0.926008]\n",
      "epoch:6 step:6097 [D loss: 0.650398, acc.: 66.41%] [G loss: 0.952308]\n",
      "epoch:6 step:6098 [D loss: 0.641474, acc.: 67.19%] [G loss: 0.909397]\n",
      "epoch:6 step:6099 [D loss: 0.650581, acc.: 61.72%] [G loss: 0.895781]\n",
      "epoch:6 step:6100 [D loss: 0.675456, acc.: 56.25%] [G loss: 0.882974]\n",
      "epoch:6 step:6101 [D loss: 0.620565, acc.: 66.41%] [G loss: 0.821186]\n",
      "epoch:6 step:6102 [D loss: 0.672963, acc.: 55.47%] [G loss: 0.793959]\n",
      "epoch:6 step:6103 [D loss: 0.653931, acc.: 60.94%] [G loss: 0.876206]\n",
      "epoch:6 step:6104 [D loss: 0.636231, acc.: 60.94%] [G loss: 0.889342]\n",
      "epoch:6 step:6105 [D loss: 0.711786, acc.: 51.56%] [G loss: 0.852961]\n",
      "epoch:6 step:6106 [D loss: 0.634762, acc.: 63.28%] [G loss: 0.847312]\n",
      "epoch:6 step:6107 [D loss: 0.691067, acc.: 53.12%] [G loss: 0.862911]\n",
      "epoch:6 step:6108 [D loss: 0.676653, acc.: 57.03%] [G loss: 0.833340]\n",
      "epoch:6 step:6109 [D loss: 0.700060, acc.: 55.47%] [G loss: 0.819863]\n",
      "epoch:6 step:6110 [D loss: 0.651048, acc.: 59.38%] [G loss: 0.871092]\n",
      "epoch:6 step:6111 [D loss: 0.684962, acc.: 57.81%] [G loss: 0.826415]\n",
      "epoch:6 step:6112 [D loss: 0.679280, acc.: 56.25%] [G loss: 0.835474]\n",
      "epoch:6 step:6113 [D loss: 0.658721, acc.: 59.38%] [G loss: 0.868944]\n",
      "epoch:6 step:6114 [D loss: 0.628938, acc.: 64.06%] [G loss: 0.849471]\n",
      "epoch:6 step:6115 [D loss: 0.671005, acc.: 57.03%] [G loss: 0.851998]\n",
      "epoch:6 step:6116 [D loss: 0.614638, acc.: 68.75%] [G loss: 0.846456]\n",
      "epoch:6 step:6117 [D loss: 0.717042, acc.: 54.69%] [G loss: 0.851960]\n",
      "epoch:6 step:6118 [D loss: 0.649741, acc.: 57.03%] [G loss: 0.866901]\n",
      "epoch:6 step:6119 [D loss: 0.624974, acc.: 68.75%] [G loss: 0.841212]\n",
      "epoch:6 step:6120 [D loss: 0.668408, acc.: 54.69%] [G loss: 0.868896]\n",
      "epoch:6 step:6121 [D loss: 0.654184, acc.: 59.38%] [G loss: 0.860427]\n",
      "epoch:6 step:6122 [D loss: 0.681846, acc.: 51.56%] [G loss: 0.905269]\n",
      "epoch:6 step:6123 [D loss: 0.701904, acc.: 52.34%] [G loss: 0.819830]\n",
      "epoch:6 step:6124 [D loss: 0.682055, acc.: 59.38%] [G loss: 0.885592]\n",
      "epoch:6 step:6125 [D loss: 0.636821, acc.: 67.19%] [G loss: 0.888181]\n",
      "epoch:6 step:6126 [D loss: 0.669655, acc.: 63.28%] [G loss: 0.854385]\n",
      "epoch:6 step:6127 [D loss: 0.665719, acc.: 58.59%] [G loss: 0.865324]\n",
      "epoch:6 step:6128 [D loss: 0.696323, acc.: 57.81%] [G loss: 0.891218]\n",
      "epoch:6 step:6129 [D loss: 0.630560, acc.: 61.72%] [G loss: 0.848917]\n",
      "epoch:6 step:6130 [D loss: 0.658949, acc.: 62.50%] [G loss: 0.843946]\n",
      "epoch:6 step:6131 [D loss: 0.660967, acc.: 63.28%] [G loss: 0.831593]\n",
      "epoch:6 step:6132 [D loss: 0.678748, acc.: 60.94%] [G loss: 0.832230]\n",
      "epoch:6 step:6133 [D loss: 0.626811, acc.: 65.62%] [G loss: 0.845449]\n",
      "epoch:6 step:6134 [D loss: 0.661371, acc.: 56.25%] [G loss: 0.832690]\n",
      "epoch:6 step:6135 [D loss: 0.737095, acc.: 46.88%] [G loss: 0.879123]\n",
      "epoch:6 step:6136 [D loss: 0.688716, acc.: 49.22%] [G loss: 0.866721]\n",
      "epoch:6 step:6137 [D loss: 0.668369, acc.: 57.81%] [G loss: 0.841069]\n",
      "epoch:6 step:6138 [D loss: 0.662533, acc.: 60.94%] [G loss: 0.839505]\n",
      "epoch:6 step:6139 [D loss: 0.676436, acc.: 55.47%] [G loss: 0.809987]\n",
      "epoch:6 step:6140 [D loss: 0.631997, acc.: 66.41%] [G loss: 0.824035]\n",
      "epoch:6 step:6141 [D loss: 0.628558, acc.: 67.19%] [G loss: 0.856276]\n",
      "epoch:6 step:6142 [D loss: 0.687438, acc.: 60.94%] [G loss: 0.863993]\n",
      "epoch:6 step:6143 [D loss: 0.628775, acc.: 64.84%] [G loss: 0.784387]\n",
      "epoch:6 step:6144 [D loss: 0.631187, acc.: 64.06%] [G loss: 0.883843]\n",
      "epoch:6 step:6145 [D loss: 0.659707, acc.: 60.94%] [G loss: 0.901460]\n",
      "epoch:6 step:6146 [D loss: 0.655674, acc.: 57.03%] [G loss: 0.921470]\n",
      "epoch:6 step:6147 [D loss: 0.674617, acc.: 56.25%] [G loss: 0.875083]\n",
      "epoch:6 step:6148 [D loss: 0.689540, acc.: 52.34%] [G loss: 0.845626]\n",
      "epoch:6 step:6149 [D loss: 0.680653, acc.: 60.16%] [G loss: 0.902908]\n",
      "epoch:6 step:6150 [D loss: 0.652682, acc.: 55.47%] [G loss: 0.864067]\n",
      "epoch:6 step:6151 [D loss: 0.637333, acc.: 61.72%] [G loss: 0.866841]\n",
      "epoch:6 step:6152 [D loss: 0.624413, acc.: 65.62%] [G loss: 0.858549]\n",
      "epoch:6 step:6153 [D loss: 0.674719, acc.: 53.91%] [G loss: 0.859954]\n",
      "epoch:6 step:6154 [D loss: 0.662755, acc.: 57.81%] [G loss: 0.863827]\n",
      "epoch:6 step:6155 [D loss: 0.681366, acc.: 54.69%] [G loss: 0.857495]\n",
      "epoch:6 step:6156 [D loss: 0.655928, acc.: 57.03%] [G loss: 0.830281]\n",
      "epoch:6 step:6157 [D loss: 0.666191, acc.: 64.06%] [G loss: 0.833002]\n",
      "epoch:6 step:6158 [D loss: 0.654691, acc.: 58.59%] [G loss: 0.857221]\n",
      "epoch:6 step:6159 [D loss: 0.699478, acc.: 54.69%] [G loss: 0.862205]\n",
      "epoch:6 step:6160 [D loss: 0.689533, acc.: 55.47%] [G loss: 0.852522]\n",
      "epoch:6 step:6161 [D loss: 0.666410, acc.: 50.00%] [G loss: 0.839837]\n",
      "epoch:6 step:6162 [D loss: 0.639925, acc.: 70.31%] [G loss: 0.853509]\n",
      "epoch:6 step:6163 [D loss: 0.652483, acc.: 62.50%] [G loss: 0.870859]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6164 [D loss: 0.680195, acc.: 58.59%] [G loss: 0.897802]\n",
      "epoch:6 step:6165 [D loss: 0.641116, acc.: 61.72%] [G loss: 0.868305]\n",
      "epoch:6 step:6166 [D loss: 0.623370, acc.: 66.41%] [G loss: 0.811838]\n",
      "epoch:6 step:6167 [D loss: 0.664396, acc.: 56.25%] [G loss: 0.841975]\n",
      "epoch:6 step:6168 [D loss: 0.669498, acc.: 60.16%] [G loss: 0.851443]\n",
      "epoch:6 step:6169 [D loss: 0.675840, acc.: 60.94%] [G loss: 0.793955]\n",
      "epoch:6 step:6170 [D loss: 0.655338, acc.: 61.72%] [G loss: 0.870996]\n",
      "epoch:6 step:6171 [D loss: 0.674905, acc.: 53.12%] [G loss: 0.878894]\n",
      "epoch:6 step:6172 [D loss: 0.655936, acc.: 64.06%] [G loss: 0.880946]\n",
      "epoch:6 step:6173 [D loss: 0.668845, acc.: 60.94%] [G loss: 0.849074]\n",
      "epoch:6 step:6174 [D loss: 0.669926, acc.: 64.06%] [G loss: 0.877807]\n",
      "epoch:6 step:6175 [D loss: 0.686724, acc.: 57.81%] [G loss: 0.868891]\n",
      "epoch:6 step:6176 [D loss: 0.639441, acc.: 62.50%] [G loss: 0.847869]\n",
      "epoch:6 step:6177 [D loss: 0.640899, acc.: 62.50%] [G loss: 0.818771]\n",
      "epoch:6 step:6178 [D loss: 0.665586, acc.: 55.47%] [G loss: 0.855302]\n",
      "epoch:6 step:6179 [D loss: 0.632287, acc.: 64.06%] [G loss: 0.861118]\n",
      "epoch:6 step:6180 [D loss: 0.666678, acc.: 53.12%] [G loss: 0.841651]\n",
      "epoch:6 step:6181 [D loss: 0.684060, acc.: 55.47%] [G loss: 0.831635]\n",
      "epoch:6 step:6182 [D loss: 0.663796, acc.: 50.00%] [G loss: 0.828017]\n",
      "epoch:6 step:6183 [D loss: 0.666625, acc.: 56.25%] [G loss: 0.890580]\n",
      "epoch:6 step:6184 [D loss: 0.664986, acc.: 53.91%] [G loss: 0.793857]\n",
      "epoch:6 step:6185 [D loss: 0.634303, acc.: 64.06%] [G loss: 0.833025]\n",
      "epoch:6 step:6186 [D loss: 0.660504, acc.: 59.38%] [G loss: 0.843791]\n",
      "epoch:6 step:6187 [D loss: 0.652165, acc.: 67.19%] [G loss: 0.863963]\n",
      "epoch:6 step:6188 [D loss: 0.654814, acc.: 60.94%] [G loss: 0.911287]\n",
      "epoch:6 step:6189 [D loss: 0.641618, acc.: 64.06%] [G loss: 0.881164]\n",
      "epoch:6 step:6190 [D loss: 0.666763, acc.: 60.94%] [G loss: 0.855718]\n",
      "epoch:6 step:6191 [D loss: 0.653262, acc.: 54.69%] [G loss: 0.846523]\n",
      "epoch:6 step:6192 [D loss: 0.698196, acc.: 53.12%] [G loss: 0.873013]\n",
      "epoch:6 step:6193 [D loss: 0.657579, acc.: 59.38%] [G loss: 0.856836]\n",
      "epoch:6 step:6194 [D loss: 0.657490, acc.: 59.38%] [G loss: 0.881551]\n",
      "epoch:6 step:6195 [D loss: 0.706539, acc.: 46.88%] [G loss: 0.818498]\n",
      "epoch:6 step:6196 [D loss: 0.609892, acc.: 66.41%] [G loss: 0.809028]\n",
      "epoch:6 step:6197 [D loss: 0.648414, acc.: 59.38%] [G loss: 0.869286]\n",
      "epoch:6 step:6198 [D loss: 0.647308, acc.: 66.41%] [G loss: 0.834110]\n",
      "epoch:6 step:6199 [D loss: 0.611933, acc.: 66.41%] [G loss: 0.892960]\n",
      "epoch:6 step:6200 [D loss: 0.650569, acc.: 60.16%] [G loss: 0.859449]\n",
      "##############\n",
      "[ 3.16679624  2.85148372  2.34276168  4.23495058  1.26566501 10.27426719\n",
      "  2.97911728  3.99562754  4.4146315   8.14868929]\n",
      "##########\n",
      "epoch:6 step:6201 [D loss: 0.718114, acc.: 51.56%] [G loss: 0.825517]\n",
      "epoch:6 step:6202 [D loss: 0.669630, acc.: 54.69%] [G loss: 0.874823]\n",
      "epoch:6 step:6203 [D loss: 0.655377, acc.: 63.28%] [G loss: 0.927528]\n",
      "epoch:6 step:6204 [D loss: 0.627546, acc.: 64.06%] [G loss: 0.903838]\n",
      "epoch:6 step:6205 [D loss: 0.660556, acc.: 60.16%] [G loss: 0.884672]\n",
      "epoch:6 step:6206 [D loss: 0.649465, acc.: 65.62%] [G loss: 0.868992]\n",
      "epoch:6 step:6207 [D loss: 0.632276, acc.: 70.31%] [G loss: 0.926951]\n",
      "epoch:6 step:6208 [D loss: 0.673205, acc.: 57.03%] [G loss: 0.893627]\n",
      "epoch:6 step:6209 [D loss: 0.650488, acc.: 61.72%] [G loss: 0.822014]\n",
      "epoch:6 step:6210 [D loss: 0.700072, acc.: 50.00%] [G loss: 0.822384]\n",
      "epoch:6 step:6211 [D loss: 0.595151, acc.: 71.88%] [G loss: 0.784476]\n",
      "epoch:6 step:6212 [D loss: 0.653388, acc.: 61.72%] [G loss: 0.827641]\n",
      "epoch:6 step:6213 [D loss: 0.659570, acc.: 57.03%] [G loss: 0.827364]\n",
      "epoch:6 step:6214 [D loss: 0.667530, acc.: 61.72%] [G loss: 0.848008]\n",
      "epoch:6 step:6215 [D loss: 0.711144, acc.: 52.34%] [G loss: 0.805837]\n",
      "epoch:6 step:6216 [D loss: 0.633892, acc.: 69.53%] [G loss: 0.822769]\n",
      "epoch:6 step:6217 [D loss: 0.662060, acc.: 57.81%] [G loss: 0.867701]\n",
      "epoch:6 step:6218 [D loss: 0.645468, acc.: 67.97%] [G loss: 0.875862]\n",
      "epoch:6 step:6219 [D loss: 0.670351, acc.: 63.28%] [G loss: 0.874580]\n",
      "epoch:6 step:6220 [D loss: 0.657766, acc.: 60.94%] [G loss: 0.915168]\n",
      "epoch:6 step:6221 [D loss: 0.643844, acc.: 57.03%] [G loss: 0.978244]\n",
      "epoch:6 step:6222 [D loss: 0.678221, acc.: 56.25%] [G loss: 0.911631]\n",
      "epoch:6 step:6223 [D loss: 0.676780, acc.: 54.69%] [G loss: 0.875255]\n",
      "epoch:6 step:6224 [D loss: 0.652993, acc.: 62.50%] [G loss: 0.888805]\n",
      "epoch:6 step:6225 [D loss: 0.663740, acc.: 57.81%] [G loss: 0.830271]\n",
      "epoch:6 step:6226 [D loss: 0.677398, acc.: 56.25%] [G loss: 0.823160]\n",
      "epoch:6 step:6227 [D loss: 0.622991, acc.: 67.19%] [G loss: 0.889313]\n",
      "epoch:6 step:6228 [D loss: 0.641584, acc.: 67.19%] [G loss: 0.845321]\n",
      "epoch:6 step:6229 [D loss: 0.700853, acc.: 56.25%] [G loss: 0.826679]\n",
      "epoch:6 step:6230 [D loss: 0.668845, acc.: 52.34%] [G loss: 0.817760]\n",
      "epoch:6 step:6231 [D loss: 0.634732, acc.: 64.06%] [G loss: 0.893444]\n",
      "epoch:6 step:6232 [D loss: 0.651735, acc.: 59.38%] [G loss: 0.861133]\n",
      "epoch:6 step:6233 [D loss: 0.674788, acc.: 57.03%] [G loss: 0.900334]\n",
      "epoch:6 step:6234 [D loss: 0.666007, acc.: 60.16%] [G loss: 0.838991]\n",
      "epoch:6 step:6235 [D loss: 0.648722, acc.: 60.94%] [G loss: 0.854683]\n",
      "epoch:6 step:6236 [D loss: 0.672906, acc.: 56.25%] [G loss: 0.888906]\n",
      "epoch:6 step:6237 [D loss: 0.622488, acc.: 70.31%] [G loss: 0.886045]\n",
      "epoch:6 step:6238 [D loss: 0.624417, acc.: 66.41%] [G loss: 0.895579]\n",
      "epoch:6 step:6239 [D loss: 0.640162, acc.: 65.62%] [G loss: 0.907882]\n",
      "epoch:6 step:6240 [D loss: 0.606798, acc.: 69.53%] [G loss: 0.841767]\n",
      "epoch:6 step:6241 [D loss: 0.698889, acc.: 53.91%] [G loss: 0.884885]\n",
      "epoch:6 step:6242 [D loss: 0.674653, acc.: 54.69%] [G loss: 0.910151]\n",
      "epoch:6 step:6243 [D loss: 0.683784, acc.: 51.56%] [G loss: 0.851515]\n",
      "epoch:6 step:6244 [D loss: 0.658048, acc.: 60.16%] [G loss: 0.881083]\n",
      "epoch:6 step:6245 [D loss: 0.675555, acc.: 56.25%] [G loss: 0.867553]\n",
      "epoch:6 step:6246 [D loss: 0.684333, acc.: 58.59%] [G loss: 0.897254]\n",
      "epoch:6 step:6247 [D loss: 0.651719, acc.: 67.19%] [G loss: 0.846184]\n",
      "epoch:6 step:6248 [D loss: 0.690699, acc.: 59.38%] [G loss: 0.869613]\n",
      "epoch:6 step:6249 [D loss: 0.635674, acc.: 65.62%] [G loss: 0.851236]\n",
      "epoch:6 step:6250 [D loss: 0.679103, acc.: 61.72%] [G loss: 0.866670]\n",
      "epoch:6 step:6251 [D loss: 0.677154, acc.: 59.38%] [G loss: 0.875767]\n",
      "epoch:6 step:6252 [D loss: 0.645986, acc.: 62.50%] [G loss: 0.883693]\n",
      "epoch:6 step:6253 [D loss: 0.636416, acc.: 60.16%] [G loss: 0.900591]\n",
      "epoch:6 step:6254 [D loss: 0.671717, acc.: 57.81%] [G loss: 0.889784]\n",
      "epoch:6 step:6255 [D loss: 0.619047, acc.: 64.06%] [G loss: 0.874803]\n",
      "epoch:6 step:6256 [D loss: 0.666097, acc.: 59.38%] [G loss: 0.891467]\n",
      "epoch:6 step:6257 [D loss: 0.666379, acc.: 57.81%] [G loss: 0.871298]\n",
      "epoch:6 step:6258 [D loss: 0.692084, acc.: 58.59%] [G loss: 0.836751]\n",
      "epoch:6 step:6259 [D loss: 0.665376, acc.: 57.03%] [G loss: 0.871446]\n",
      "epoch:6 step:6260 [D loss: 0.669198, acc.: 57.03%] [G loss: 0.856873]\n",
      "epoch:6 step:6261 [D loss: 0.655323, acc.: 60.16%] [G loss: 0.892413]\n",
      "epoch:6 step:6262 [D loss: 0.696449, acc.: 55.47%] [G loss: 0.806002]\n",
      "epoch:6 step:6263 [D loss: 0.723313, acc.: 50.78%] [G loss: 0.820053]\n",
      "epoch:6 step:6264 [D loss: 0.682649, acc.: 54.69%] [G loss: 0.858259]\n",
      "epoch:6 step:6265 [D loss: 0.695605, acc.: 52.34%] [G loss: 0.845318]\n",
      "epoch:6 step:6266 [D loss: 0.676148, acc.: 54.69%] [G loss: 0.841177]\n",
      "epoch:6 step:6267 [D loss: 0.676667, acc.: 53.12%] [G loss: 0.862734]\n",
      "epoch:6 step:6268 [D loss: 0.683730, acc.: 53.12%] [G loss: 0.832180]\n",
      "epoch:6 step:6269 [D loss: 0.680801, acc.: 54.69%] [G loss: 0.844286]\n",
      "epoch:6 step:6270 [D loss: 0.642843, acc.: 60.16%] [G loss: 0.851248]\n",
      "epoch:6 step:6271 [D loss: 0.639696, acc.: 64.84%] [G loss: 0.868754]\n",
      "epoch:6 step:6272 [D loss: 0.654904, acc.: 63.28%] [G loss: 0.822962]\n",
      "epoch:6 step:6273 [D loss: 0.666811, acc.: 56.25%] [G loss: 0.822136]\n",
      "epoch:6 step:6274 [D loss: 0.685270, acc.: 49.22%] [G loss: 0.826340]\n",
      "epoch:6 step:6275 [D loss: 0.684252, acc.: 55.47%] [G loss: 0.835167]\n",
      "epoch:6 step:6276 [D loss: 0.673408, acc.: 59.38%] [G loss: 0.872275]\n",
      "epoch:6 step:6277 [D loss: 0.677291, acc.: 54.69%] [G loss: 0.853001]\n",
      "epoch:6 step:6278 [D loss: 0.671823, acc.: 58.59%] [G loss: 0.820901]\n",
      "epoch:6 step:6279 [D loss: 0.689407, acc.: 56.25%] [G loss: 0.849432]\n",
      "epoch:6 step:6280 [D loss: 0.688907, acc.: 57.81%] [G loss: 0.828802]\n",
      "epoch:6 step:6281 [D loss: 0.653771, acc.: 61.72%] [G loss: 0.836342]\n",
      "epoch:6 step:6282 [D loss: 0.682963, acc.: 53.12%] [G loss: 0.891857]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6283 [D loss: 0.657621, acc.: 58.59%] [G loss: 0.875924]\n",
      "epoch:6 step:6284 [D loss: 0.695628, acc.: 57.81%] [G loss: 0.879958]\n",
      "epoch:6 step:6285 [D loss: 0.654229, acc.: 60.16%] [G loss: 0.890757]\n",
      "epoch:6 step:6286 [D loss: 0.669357, acc.: 57.81%] [G loss: 0.821657]\n",
      "epoch:6 step:6287 [D loss: 0.697493, acc.: 52.34%] [G loss: 0.879522]\n",
      "epoch:6 step:6288 [D loss: 0.651135, acc.: 63.28%] [G loss: 0.891576]\n",
      "epoch:6 step:6289 [D loss: 0.646160, acc.: 63.28%] [G loss: 0.785799]\n",
      "epoch:6 step:6290 [D loss: 0.698067, acc.: 57.81%] [G loss: 0.859314]\n",
      "epoch:6 step:6291 [D loss: 0.668894, acc.: 56.25%] [G loss: 0.912061]\n",
      "epoch:6 step:6292 [D loss: 0.644531, acc.: 63.28%] [G loss: 0.859637]\n",
      "epoch:6 step:6293 [D loss: 0.658568, acc.: 55.47%] [G loss: 0.901755]\n",
      "epoch:6 step:6294 [D loss: 0.707298, acc.: 53.12%] [G loss: 0.848823]\n",
      "epoch:6 step:6295 [D loss: 0.660803, acc.: 58.59%] [G loss: 0.852937]\n",
      "epoch:6 step:6296 [D loss: 0.694303, acc.: 53.12%] [G loss: 0.854398]\n",
      "epoch:6 step:6297 [D loss: 0.662583, acc.: 58.59%] [G loss: 0.890749]\n",
      "epoch:6 step:6298 [D loss: 0.675318, acc.: 57.81%] [G loss: 0.883147]\n",
      "epoch:6 step:6299 [D loss: 0.677762, acc.: 55.47%] [G loss: 0.842480]\n",
      "epoch:6 step:6300 [D loss: 0.626275, acc.: 67.19%] [G loss: 0.815666]\n",
      "epoch:6 step:6301 [D loss: 0.642087, acc.: 62.50%] [G loss: 0.846731]\n",
      "epoch:6 step:6302 [D loss: 0.671434, acc.: 62.50%] [G loss: 0.802926]\n",
      "epoch:6 step:6303 [D loss: 0.684130, acc.: 55.47%] [G loss: 0.789002]\n",
      "epoch:6 step:6304 [D loss: 0.638075, acc.: 57.03%] [G loss: 0.832276]\n",
      "epoch:6 step:6305 [D loss: 0.656198, acc.: 57.03%] [G loss: 0.813858]\n",
      "epoch:6 step:6306 [D loss: 0.686741, acc.: 51.56%] [G loss: 0.850589]\n",
      "epoch:6 step:6307 [D loss: 0.642450, acc.: 61.72%] [G loss: 0.876731]\n",
      "epoch:6 step:6308 [D loss: 0.666364, acc.: 54.69%] [G loss: 0.849373]\n",
      "epoch:6 step:6309 [D loss: 0.674612, acc.: 53.91%] [G loss: 0.859394]\n",
      "epoch:6 step:6310 [D loss: 0.667197, acc.: 56.25%] [G loss: 0.891490]\n",
      "epoch:6 step:6311 [D loss: 0.652965, acc.: 63.28%] [G loss: 0.885889]\n",
      "epoch:6 step:6312 [D loss: 0.676194, acc.: 57.81%] [G loss: 0.849093]\n",
      "epoch:6 step:6313 [D loss: 0.652984, acc.: 60.16%] [G loss: 0.869776]\n",
      "epoch:6 step:6314 [D loss: 0.650628, acc.: 64.84%] [G loss: 0.895919]\n",
      "epoch:6 step:6315 [D loss: 0.640649, acc.: 67.97%] [G loss: 0.877646]\n",
      "epoch:6 step:6316 [D loss: 0.638747, acc.: 61.72%] [G loss: 0.869850]\n",
      "epoch:6 step:6317 [D loss: 0.657755, acc.: 60.94%] [G loss: 0.786225]\n",
      "epoch:6 step:6318 [D loss: 0.652697, acc.: 64.84%] [G loss: 0.851508]\n",
      "epoch:6 step:6319 [D loss: 0.675867, acc.: 54.69%] [G loss: 0.822297]\n",
      "epoch:6 step:6320 [D loss: 0.610351, acc.: 70.31%] [G loss: 0.828128]\n",
      "epoch:6 step:6321 [D loss: 0.648386, acc.: 60.16%] [G loss: 0.835739]\n",
      "epoch:6 step:6322 [D loss: 0.624255, acc.: 67.19%] [G loss: 0.882690]\n",
      "epoch:6 step:6323 [D loss: 0.655864, acc.: 54.69%] [G loss: 0.845504]\n",
      "epoch:6 step:6324 [D loss: 0.647040, acc.: 58.59%] [G loss: 0.886769]\n",
      "epoch:6 step:6325 [D loss: 0.664989, acc.: 60.16%] [G loss: 0.869766]\n",
      "epoch:6 step:6326 [D loss: 0.714825, acc.: 58.59%] [G loss: 0.872322]\n",
      "epoch:6 step:6327 [D loss: 0.674077, acc.: 53.12%] [G loss: 0.858166]\n",
      "epoch:6 step:6328 [D loss: 0.691238, acc.: 53.12%] [G loss: 0.811313]\n",
      "epoch:6 step:6329 [D loss: 0.683588, acc.: 51.56%] [G loss: 0.841606]\n",
      "epoch:6 step:6330 [D loss: 0.633754, acc.: 65.62%] [G loss: 0.893787]\n",
      "epoch:6 step:6331 [D loss: 0.666700, acc.: 57.81%] [G loss: 0.909155]\n",
      "epoch:6 step:6332 [D loss: 0.660153, acc.: 61.72%] [G loss: 0.913447]\n",
      "epoch:6 step:6333 [D loss: 0.634311, acc.: 64.06%] [G loss: 0.940760]\n",
      "epoch:6 step:6334 [D loss: 0.664606, acc.: 64.06%] [G loss: 0.877124]\n",
      "epoch:6 step:6335 [D loss: 0.676610, acc.: 57.81%] [G loss: 0.860215]\n",
      "epoch:6 step:6336 [D loss: 0.684051, acc.: 57.03%] [G loss: 0.919581]\n",
      "epoch:6 step:6337 [D loss: 0.678971, acc.: 59.38%] [G loss: 0.894453]\n",
      "epoch:6 step:6338 [D loss: 0.686335, acc.: 53.12%] [G loss: 0.850670]\n",
      "epoch:6 step:6339 [D loss: 0.662446, acc.: 57.03%] [G loss: 0.893075]\n",
      "epoch:6 step:6340 [D loss: 0.661309, acc.: 56.25%] [G loss: 0.911244]\n",
      "epoch:6 step:6341 [D loss: 0.691036, acc.: 54.69%] [G loss: 0.928625]\n",
      "epoch:6 step:6342 [D loss: 0.669836, acc.: 58.59%] [G loss: 0.886613]\n",
      "epoch:6 step:6343 [D loss: 0.659733, acc.: 56.25%] [G loss: 0.894441]\n",
      "epoch:6 step:6344 [D loss: 0.674339, acc.: 56.25%] [G loss: 0.905386]\n",
      "epoch:6 step:6345 [D loss: 0.674813, acc.: 57.03%] [G loss: 0.883511]\n",
      "epoch:6 step:6346 [D loss: 0.694675, acc.: 53.91%] [G loss: 0.864611]\n",
      "epoch:6 step:6347 [D loss: 0.622631, acc.: 67.19%] [G loss: 0.858443]\n",
      "epoch:6 step:6348 [D loss: 0.660976, acc.: 60.16%] [G loss: 0.883930]\n",
      "epoch:6 step:6349 [D loss: 0.668305, acc.: 56.25%] [G loss: 0.919256]\n",
      "epoch:6 step:6350 [D loss: 0.647524, acc.: 67.97%] [G loss: 0.826628]\n",
      "epoch:6 step:6351 [D loss: 0.657068, acc.: 61.72%] [G loss: 0.893336]\n",
      "epoch:6 step:6352 [D loss: 0.663850, acc.: 58.59%] [G loss: 0.874369]\n",
      "epoch:6 step:6353 [D loss: 0.652075, acc.: 61.72%] [G loss: 0.818076]\n",
      "epoch:6 step:6354 [D loss: 0.654742, acc.: 57.03%] [G loss: 0.849058]\n",
      "epoch:6 step:6355 [D loss: 0.649206, acc.: 68.75%] [G loss: 0.852586]\n",
      "epoch:6 step:6356 [D loss: 0.621790, acc.: 67.19%] [G loss: 0.843623]\n",
      "epoch:6 step:6357 [D loss: 0.680614, acc.: 59.38%] [G loss: 0.891301]\n",
      "epoch:6 step:6358 [D loss: 0.616323, acc.: 70.31%] [G loss: 0.865545]\n",
      "epoch:6 step:6359 [D loss: 0.697531, acc.: 48.44%] [G loss: 0.847863]\n",
      "epoch:6 step:6360 [D loss: 0.663296, acc.: 58.59%] [G loss: 0.866954]\n",
      "epoch:6 step:6361 [D loss: 0.650128, acc.: 64.84%] [G loss: 0.854947]\n",
      "epoch:6 step:6362 [D loss: 0.673000, acc.: 56.25%] [G loss: 0.871824]\n",
      "epoch:6 step:6363 [D loss: 0.682010, acc.: 52.34%] [G loss: 0.880611]\n",
      "epoch:6 step:6364 [D loss: 0.688391, acc.: 57.03%] [G loss: 0.892460]\n",
      "epoch:6 step:6365 [D loss: 0.674567, acc.: 55.47%] [G loss: 0.853666]\n",
      "epoch:6 step:6366 [D loss: 0.655311, acc.: 63.28%] [G loss: 0.863015]\n",
      "epoch:6 step:6367 [D loss: 0.694231, acc.: 53.12%] [G loss: 0.833588]\n",
      "epoch:6 step:6368 [D loss: 0.657538, acc.: 64.84%] [G loss: 0.868314]\n",
      "epoch:6 step:6369 [D loss: 0.642931, acc.: 67.97%] [G loss: 0.895634]\n",
      "epoch:6 step:6370 [D loss: 0.640863, acc.: 65.62%] [G loss: 0.852497]\n",
      "epoch:6 step:6371 [D loss: 0.683444, acc.: 59.38%] [G loss: 0.845773]\n",
      "epoch:6 step:6372 [D loss: 0.645076, acc.: 71.88%] [G loss: 0.892695]\n",
      "epoch:6 step:6373 [D loss: 0.670633, acc.: 57.03%] [G loss: 0.920224]\n",
      "epoch:6 step:6374 [D loss: 0.668121, acc.: 60.16%] [G loss: 0.870436]\n",
      "epoch:6 step:6375 [D loss: 0.628149, acc.: 67.19%] [G loss: 0.914990]\n",
      "epoch:6 step:6376 [D loss: 0.695896, acc.: 57.03%] [G loss: 0.884563]\n",
      "epoch:6 step:6377 [D loss: 0.656421, acc.: 57.03%] [G loss: 0.886606]\n",
      "epoch:6 step:6378 [D loss: 0.694866, acc.: 55.47%] [G loss: 0.863494]\n",
      "epoch:6 step:6379 [D loss: 0.630403, acc.: 64.84%] [G loss: 0.885437]\n",
      "epoch:6 step:6380 [D loss: 0.720494, acc.: 49.22%] [G loss: 0.857150]\n",
      "epoch:6 step:6381 [D loss: 0.661250, acc.: 60.94%] [G loss: 0.843086]\n",
      "epoch:6 step:6382 [D loss: 0.692641, acc.: 57.03%] [G loss: 0.869577]\n",
      "epoch:6 step:6383 [D loss: 0.699746, acc.: 50.00%] [G loss: 0.873933]\n",
      "epoch:6 step:6384 [D loss: 0.690139, acc.: 51.56%] [G loss: 0.851901]\n",
      "epoch:6 step:6385 [D loss: 0.684398, acc.: 53.91%] [G loss: 0.819800]\n",
      "epoch:6 step:6386 [D loss: 0.658543, acc.: 56.25%] [G loss: 0.821010]\n",
      "epoch:6 step:6387 [D loss: 0.689333, acc.: 45.31%] [G loss: 0.813729]\n",
      "epoch:6 step:6388 [D loss: 0.698717, acc.: 57.03%] [G loss: 0.829709]\n",
      "epoch:6 step:6389 [D loss: 0.707211, acc.: 47.66%] [G loss: 0.901887]\n",
      "epoch:6 step:6390 [D loss: 0.655947, acc.: 59.38%] [G loss: 0.888997]\n",
      "epoch:6 step:6391 [D loss: 0.644305, acc.: 61.72%] [G loss: 0.838283]\n",
      "epoch:6 step:6392 [D loss: 0.649647, acc.: 62.50%] [G loss: 0.792121]\n",
      "epoch:6 step:6393 [D loss: 0.705870, acc.: 57.81%] [G loss: 0.798379]\n",
      "epoch:6 step:6394 [D loss: 0.667363, acc.: 59.38%] [G loss: 0.902847]\n",
      "epoch:6 step:6395 [D loss: 0.647168, acc.: 67.19%] [G loss: 0.866457]\n",
      "epoch:6 step:6396 [D loss: 0.661481, acc.: 61.72%] [G loss: 0.879587]\n",
      "epoch:6 step:6397 [D loss: 0.659079, acc.: 61.72%] [G loss: 0.871594]\n",
      "epoch:6 step:6398 [D loss: 0.639527, acc.: 65.62%] [G loss: 0.862948]\n",
      "epoch:6 step:6399 [D loss: 0.674171, acc.: 62.50%] [G loss: 0.863087]\n",
      "epoch:6 step:6400 [D loss: 0.657596, acc.: 60.94%] [G loss: 0.833318]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[3.04643647 2.72884669 2.44634517 4.01600748 1.70478483 8.0590088\n",
      " 2.83239754 4.2537193  4.2095224  6.78897776]\n",
      "##########\n",
      "epoch:6 step:6401 [D loss: 0.650897, acc.: 60.94%] [G loss: 0.890528]\n",
      "epoch:6 step:6402 [D loss: 0.648332, acc.: 57.03%] [G loss: 0.861503]\n",
      "epoch:6 step:6403 [D loss: 0.693340, acc.: 54.69%] [G loss: 0.858830]\n",
      "epoch:6 step:6404 [D loss: 0.646829, acc.: 64.84%] [G loss: 0.842996]\n",
      "epoch:6 step:6405 [D loss: 0.693568, acc.: 59.38%] [G loss: 0.874735]\n",
      "epoch:6 step:6406 [D loss: 0.656429, acc.: 64.84%] [G loss: 0.888026]\n",
      "epoch:6 step:6407 [D loss: 0.724658, acc.: 51.56%] [G loss: 0.878122]\n",
      "epoch:6 step:6408 [D loss: 0.676605, acc.: 60.94%] [G loss: 0.808969]\n",
      "epoch:6 step:6409 [D loss: 0.684368, acc.: 53.12%] [G loss: 0.795572]\n",
      "epoch:6 step:6410 [D loss: 0.671962, acc.: 60.16%] [G loss: 0.867052]\n",
      "epoch:6 step:6411 [D loss: 0.646491, acc.: 60.94%] [G loss: 0.865696]\n",
      "epoch:6 step:6412 [D loss: 0.678065, acc.: 52.34%] [G loss: 0.882986]\n",
      "epoch:6 step:6413 [D loss: 0.666687, acc.: 60.94%] [G loss: 0.924692]\n",
      "epoch:6 step:6414 [D loss: 0.661919, acc.: 60.16%] [G loss: 0.877635]\n",
      "epoch:6 step:6415 [D loss: 0.628291, acc.: 61.72%] [G loss: 0.885131]\n",
      "epoch:6 step:6416 [D loss: 0.675159, acc.: 60.16%] [G loss: 0.856099]\n",
      "epoch:6 step:6417 [D loss: 0.642995, acc.: 63.28%] [G loss: 0.907171]\n",
      "epoch:6 step:6418 [D loss: 0.669974, acc.: 60.16%] [G loss: 0.892396]\n",
      "epoch:6 step:6419 [D loss: 0.686278, acc.: 55.47%] [G loss: 0.865960]\n",
      "epoch:6 step:6420 [D loss: 0.686707, acc.: 61.72%] [G loss: 0.843188]\n",
      "epoch:6 step:6421 [D loss: 0.685021, acc.: 57.81%] [G loss: 0.863792]\n",
      "epoch:6 step:6422 [D loss: 0.693037, acc.: 55.47%] [G loss: 0.843298]\n",
      "epoch:6 step:6423 [D loss: 0.674887, acc.: 53.12%] [G loss: 0.850580]\n",
      "epoch:6 step:6424 [D loss: 0.701515, acc.: 54.69%] [G loss: 0.864287]\n",
      "epoch:6 step:6425 [D loss: 0.657016, acc.: 57.81%] [G loss: 0.856242]\n",
      "epoch:6 step:6426 [D loss: 0.689914, acc.: 54.69%] [G loss: 0.821496]\n",
      "epoch:6 step:6427 [D loss: 0.647275, acc.: 61.72%] [G loss: 0.869696]\n",
      "epoch:6 step:6428 [D loss: 0.643842, acc.: 55.47%] [G loss: 0.846316]\n",
      "epoch:6 step:6429 [D loss: 0.711084, acc.: 45.31%] [G loss: 0.851871]\n",
      "epoch:6 step:6430 [D loss: 0.672131, acc.: 50.00%] [G loss: 0.837136]\n",
      "epoch:6 step:6431 [D loss: 0.644574, acc.: 57.81%] [G loss: 0.831707]\n",
      "epoch:6 step:6432 [D loss: 0.660508, acc.: 57.81%] [G loss: 0.848207]\n",
      "epoch:6 step:6433 [D loss: 0.674162, acc.: 57.03%] [G loss: 0.850472]\n",
      "epoch:6 step:6434 [D loss: 0.665715, acc.: 61.72%] [G loss: 0.894890]\n",
      "epoch:6 step:6435 [D loss: 0.671730, acc.: 57.81%] [G loss: 0.917611]\n",
      "epoch:6 step:6436 [D loss: 0.663700, acc.: 61.72%] [G loss: 0.856277]\n",
      "epoch:6 step:6437 [D loss: 0.650300, acc.: 57.03%] [G loss: 0.912570]\n",
      "epoch:6 step:6438 [D loss: 0.625313, acc.: 65.62%] [G loss: 0.866860]\n",
      "epoch:6 step:6439 [D loss: 0.673912, acc.: 59.38%] [G loss: 0.877296]\n",
      "epoch:6 step:6440 [D loss: 0.698941, acc.: 51.56%] [G loss: 0.897372]\n",
      "epoch:6 step:6441 [D loss: 0.666840, acc.: 59.38%] [G loss: 0.879046]\n",
      "epoch:6 step:6442 [D loss: 0.687032, acc.: 57.81%] [G loss: 0.864948]\n",
      "epoch:6 step:6443 [D loss: 0.676689, acc.: 60.16%] [G loss: 0.841827]\n",
      "epoch:6 step:6444 [D loss: 0.675423, acc.: 54.69%] [G loss: 0.872761]\n",
      "epoch:6 step:6445 [D loss: 0.735221, acc.: 50.00%] [G loss: 0.814979]\n",
      "epoch:6 step:6446 [D loss: 0.675519, acc.: 51.56%] [G loss: 0.825422]\n",
      "epoch:6 step:6447 [D loss: 0.698547, acc.: 55.47%] [G loss: 0.808305]\n",
      "epoch:6 step:6448 [D loss: 0.686263, acc.: 52.34%] [G loss: 0.817946]\n",
      "epoch:6 step:6449 [D loss: 0.663987, acc.: 60.16%] [G loss: 0.829796]\n",
      "epoch:6 step:6450 [D loss: 0.698675, acc.: 50.00%] [G loss: 0.874384]\n",
      "epoch:6 step:6451 [D loss: 0.677350, acc.: 58.59%] [G loss: 0.836692]\n",
      "epoch:6 step:6452 [D loss: 0.652135, acc.: 62.50%] [G loss: 0.854736]\n",
      "epoch:6 step:6453 [D loss: 0.688214, acc.: 57.81%] [G loss: 0.859178]\n",
      "epoch:6 step:6454 [D loss: 0.637263, acc.: 60.94%] [G loss: 0.857611]\n",
      "epoch:6 step:6455 [D loss: 0.691643, acc.: 57.81%] [G loss: 0.830228]\n",
      "epoch:6 step:6456 [D loss: 0.690601, acc.: 60.16%] [G loss: 0.846196]\n",
      "epoch:6 step:6457 [D loss: 0.685223, acc.: 60.16%] [G loss: 0.886916]\n",
      "epoch:6 step:6458 [D loss: 0.650016, acc.: 60.16%] [G loss: 0.865592]\n",
      "epoch:6 step:6459 [D loss: 0.667130, acc.: 61.72%] [G loss: 0.882566]\n",
      "epoch:6 step:6460 [D loss: 0.669665, acc.: 61.72%] [G loss: 0.824272]\n",
      "epoch:6 step:6461 [D loss: 0.687511, acc.: 55.47%] [G loss: 0.856623]\n",
      "epoch:6 step:6462 [D loss: 0.671937, acc.: 58.59%] [G loss: 0.900561]\n",
      "epoch:6 step:6463 [D loss: 0.657647, acc.: 63.28%] [G loss: 0.886459]\n",
      "epoch:6 step:6464 [D loss: 0.690357, acc.: 56.25%] [G loss: 0.802389]\n",
      "epoch:6 step:6465 [D loss: 0.694609, acc.: 52.34%] [G loss: 0.827697]\n",
      "epoch:6 step:6466 [D loss: 0.681599, acc.: 60.94%] [G loss: 0.858186]\n",
      "epoch:6 step:6467 [D loss: 0.698587, acc.: 56.25%] [G loss: 0.863734]\n",
      "epoch:6 step:6468 [D loss: 0.665992, acc.: 63.28%] [G loss: 0.858774]\n",
      "epoch:6 step:6469 [D loss: 0.651093, acc.: 63.28%] [G loss: 0.878021]\n",
      "epoch:6 step:6470 [D loss: 0.677756, acc.: 55.47%] [G loss: 0.833269]\n",
      "epoch:6 step:6471 [D loss: 0.661927, acc.: 63.28%] [G loss: 0.826481]\n",
      "epoch:6 step:6472 [D loss: 0.663651, acc.: 60.94%] [G loss: 0.889822]\n",
      "epoch:6 step:6473 [D loss: 0.685278, acc.: 57.03%] [G loss: 0.867773]\n",
      "epoch:6 step:6474 [D loss: 0.667428, acc.: 57.81%] [G loss: 0.827914]\n",
      "epoch:6 step:6475 [D loss: 0.678079, acc.: 50.78%] [G loss: 0.855797]\n",
      "epoch:6 step:6476 [D loss: 0.649009, acc.: 60.94%] [G loss: 0.868940]\n",
      "epoch:6 step:6477 [D loss: 0.676620, acc.: 60.16%] [G loss: 0.852922]\n",
      "epoch:6 step:6478 [D loss: 0.602097, acc.: 67.19%] [G loss: 0.862269]\n",
      "epoch:6 step:6479 [D loss: 0.701271, acc.: 60.94%] [G loss: 0.853806]\n",
      "epoch:6 step:6480 [D loss: 0.674078, acc.: 60.16%] [G loss: 0.870798]\n",
      "epoch:6 step:6481 [D loss: 0.648511, acc.: 65.62%] [G loss: 0.842491]\n",
      "epoch:6 step:6482 [D loss: 0.692334, acc.: 53.91%] [G loss: 0.856131]\n",
      "epoch:6 step:6483 [D loss: 0.649264, acc.: 61.72%] [G loss: 0.863051]\n",
      "epoch:6 step:6484 [D loss: 0.690393, acc.: 52.34%] [G loss: 0.849867]\n",
      "epoch:6 step:6485 [D loss: 0.665726, acc.: 60.16%] [G loss: 0.813689]\n",
      "epoch:6 step:6486 [D loss: 0.716298, acc.: 50.78%] [G loss: 0.852023]\n",
      "epoch:6 step:6487 [D loss: 0.662171, acc.: 57.81%] [G loss: 0.839493]\n",
      "epoch:6 step:6488 [D loss: 0.645788, acc.: 60.94%] [G loss: 0.854380]\n",
      "epoch:6 step:6489 [D loss: 0.661579, acc.: 57.81%] [G loss: 0.837634]\n",
      "epoch:6 step:6490 [D loss: 0.656875, acc.: 62.50%] [G loss: 0.877517]\n",
      "epoch:6 step:6491 [D loss: 0.646392, acc.: 60.16%] [G loss: 0.871031]\n",
      "epoch:6 step:6492 [D loss: 0.659893, acc.: 59.38%] [G loss: 0.887287]\n",
      "epoch:6 step:6493 [D loss: 0.667362, acc.: 57.81%] [G loss: 0.832274]\n",
      "epoch:6 step:6494 [D loss: 0.680999, acc.: 57.03%] [G loss: 0.839787]\n",
      "epoch:6 step:6495 [D loss: 0.631470, acc.: 64.84%] [G loss: 0.884495]\n",
      "epoch:6 step:6496 [D loss: 0.675573, acc.: 54.69%] [G loss: 0.836341]\n",
      "epoch:6 step:6497 [D loss: 0.641148, acc.: 67.97%] [G loss: 0.826556]\n",
      "epoch:6 step:6498 [D loss: 0.660438, acc.: 61.72%] [G loss: 0.819547]\n",
      "epoch:6 step:6499 [D loss: 0.679688, acc.: 59.38%] [G loss: 0.817041]\n",
      "epoch:6 step:6500 [D loss: 0.716227, acc.: 47.66%] [G loss: 0.790669]\n",
      "epoch:6 step:6501 [D loss: 0.660910, acc.: 57.81%] [G loss: 0.833368]\n",
      "epoch:6 step:6502 [D loss: 0.652218, acc.: 60.94%] [G loss: 0.856707]\n",
      "epoch:6 step:6503 [D loss: 0.643202, acc.: 67.19%] [G loss: 0.833724]\n",
      "epoch:6 step:6504 [D loss: 0.653013, acc.: 64.84%] [G loss: 0.862906]\n",
      "epoch:6 step:6505 [D loss: 0.685662, acc.: 62.50%] [G loss: 0.841402]\n",
      "epoch:6 step:6506 [D loss: 0.677518, acc.: 58.59%] [G loss: 0.865654]\n",
      "epoch:6 step:6507 [D loss: 0.681002, acc.: 56.25%] [G loss: 0.849212]\n",
      "epoch:6 step:6508 [D loss: 0.679176, acc.: 57.81%] [G loss: 0.822994]\n",
      "epoch:6 step:6509 [D loss: 0.647141, acc.: 61.72%] [G loss: 0.812727]\n",
      "epoch:6 step:6510 [D loss: 0.646406, acc.: 64.84%] [G loss: 0.807365]\n",
      "epoch:6 step:6511 [D loss: 0.656656, acc.: 60.94%] [G loss: 0.818498]\n",
      "epoch:6 step:6512 [D loss: 0.658861, acc.: 56.25%] [G loss: 0.835993]\n",
      "epoch:6 step:6513 [D loss: 0.726897, acc.: 53.12%] [G loss: 0.824804]\n",
      "epoch:6 step:6514 [D loss: 0.685304, acc.: 54.69%] [G loss: 0.839182]\n",
      "epoch:6 step:6515 [D loss: 0.692692, acc.: 50.78%] [G loss: 0.861999]\n",
      "epoch:6 step:6516 [D loss: 0.686989, acc.: 55.47%] [G loss: 0.869717]\n",
      "epoch:6 step:6517 [D loss: 0.637816, acc.: 62.50%] [G loss: 0.832289]\n",
      "epoch:6 step:6518 [D loss: 0.666113, acc.: 60.94%] [G loss: 0.848966]\n",
      "epoch:6 step:6519 [D loss: 0.653234, acc.: 64.06%] [G loss: 0.808225]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:6 step:6520 [D loss: 0.647939, acc.: 64.06%] [G loss: 0.829798]\n",
      "epoch:6 step:6521 [D loss: 0.653906, acc.: 60.16%] [G loss: 0.835057]\n",
      "epoch:6 step:6522 [D loss: 0.670087, acc.: 59.38%] [G loss: 0.870926]\n",
      "epoch:6 step:6523 [D loss: 0.663792, acc.: 55.47%] [G loss: 0.811810]\n",
      "epoch:6 step:6524 [D loss: 0.663727, acc.: 58.59%] [G loss: 0.824350]\n",
      "epoch:6 step:6525 [D loss: 0.633275, acc.: 67.19%] [G loss: 0.832553]\n",
      "epoch:6 step:6526 [D loss: 0.638614, acc.: 57.03%] [G loss: 0.856533]\n",
      "epoch:6 step:6527 [D loss: 0.681036, acc.: 55.47%] [G loss: 0.806716]\n",
      "epoch:6 step:6528 [D loss: 0.645701, acc.: 61.72%] [G loss: 0.826477]\n",
      "epoch:6 step:6529 [D loss: 0.705196, acc.: 49.22%] [G loss: 0.812187]\n",
      "epoch:6 step:6530 [D loss: 0.647729, acc.: 58.59%] [G loss: 0.808313]\n",
      "epoch:6 step:6531 [D loss: 0.691309, acc.: 54.69%] [G loss: 0.825260]\n",
      "epoch:6 step:6532 [D loss: 0.680812, acc.: 52.34%] [G loss: 0.854647]\n",
      "epoch:6 step:6533 [D loss: 0.655464, acc.: 57.03%] [G loss: 0.834729]\n",
      "epoch:6 step:6534 [D loss: 0.664321, acc.: 60.94%] [G loss: 0.796189]\n",
      "epoch:6 step:6535 [D loss: 0.684903, acc.: 55.47%] [G loss: 0.843109]\n",
      "epoch:6 step:6536 [D loss: 0.663971, acc.: 54.69%] [G loss: 0.936180]\n",
      "epoch:6 step:6537 [D loss: 0.653757, acc.: 60.16%] [G loss: 0.831829]\n",
      "epoch:6 step:6538 [D loss: 0.619856, acc.: 71.09%] [G loss: 0.837322]\n",
      "epoch:6 step:6539 [D loss: 0.673893, acc.: 59.38%] [G loss: 0.849178]\n",
      "epoch:6 step:6540 [D loss: 0.657865, acc.: 57.81%] [G loss: 0.844582]\n",
      "epoch:6 step:6541 [D loss: 0.658346, acc.: 60.16%] [G loss: 0.877967]\n",
      "epoch:6 step:6542 [D loss: 0.678625, acc.: 53.12%] [G loss: 0.806806]\n",
      "epoch:6 step:6543 [D loss: 0.667476, acc.: 66.41%] [G loss: 0.831873]\n",
      "epoch:6 step:6544 [D loss: 0.643741, acc.: 60.16%] [G loss: 0.848112]\n",
      "epoch:6 step:6545 [D loss: 0.668067, acc.: 53.91%] [G loss: 0.849178]\n",
      "epoch:6 step:6546 [D loss: 0.617198, acc.: 69.53%] [G loss: 0.919458]\n",
      "epoch:6 step:6547 [D loss: 0.632532, acc.: 66.41%] [G loss: 0.839983]\n",
      "epoch:6 step:6548 [D loss: 0.654796, acc.: 59.38%] [G loss: 0.878690]\n",
      "epoch:6 step:6549 [D loss: 0.642188, acc.: 58.59%] [G loss: 0.836553]\n",
      "epoch:6 step:6550 [D loss: 0.687573, acc.: 53.12%] [G loss: 0.816382]\n",
      "epoch:6 step:6551 [D loss: 0.687517, acc.: 54.69%] [G loss: 0.837279]\n",
      "epoch:6 step:6552 [D loss: 0.667983, acc.: 57.03%] [G loss: 0.841745]\n",
      "epoch:6 step:6553 [D loss: 0.640076, acc.: 62.50%] [G loss: 0.846260]\n",
      "epoch:6 step:6554 [D loss: 0.655200, acc.: 60.94%] [G loss: 0.817695]\n",
      "epoch:6 step:6555 [D loss: 0.672995, acc.: 57.03%] [G loss: 0.860681]\n",
      "epoch:6 step:6556 [D loss: 0.664750, acc.: 57.81%] [G loss: 0.881426]\n",
      "epoch:6 step:6557 [D loss: 0.641839, acc.: 67.97%] [G loss: 0.893572]\n",
      "epoch:6 step:6558 [D loss: 0.663019, acc.: 53.12%] [G loss: 0.894915]\n",
      "epoch:6 step:6559 [D loss: 0.661085, acc.: 57.81%] [G loss: 0.869976]\n",
      "epoch:7 step:6560 [D loss: 0.673024, acc.: 58.59%] [G loss: 0.924266]\n",
      "epoch:7 step:6561 [D loss: 0.647460, acc.: 64.84%] [G loss: 0.841891]\n",
      "epoch:7 step:6562 [D loss: 0.642588, acc.: 66.41%] [G loss: 0.830769]\n",
      "epoch:7 step:6563 [D loss: 0.689070, acc.: 49.22%] [G loss: 0.867781]\n",
      "epoch:7 step:6564 [D loss: 0.668264, acc.: 61.72%] [G loss: 0.841843]\n",
      "epoch:7 step:6565 [D loss: 0.668032, acc.: 51.56%] [G loss: 0.829052]\n",
      "epoch:7 step:6566 [D loss: 0.674944, acc.: 55.47%] [G loss: 0.893809]\n",
      "epoch:7 step:6567 [D loss: 0.655951, acc.: 58.59%] [G loss: 0.853467]\n",
      "epoch:7 step:6568 [D loss: 0.634667, acc.: 67.19%] [G loss: 0.862852]\n",
      "epoch:7 step:6569 [D loss: 0.642511, acc.: 58.59%] [G loss: 0.828749]\n",
      "epoch:7 step:6570 [D loss: 0.639695, acc.: 66.41%] [G loss: 0.860198]\n",
      "epoch:7 step:6571 [D loss: 0.638188, acc.: 64.06%] [G loss: 0.906000]\n",
      "epoch:7 step:6572 [D loss: 0.656502, acc.: 64.84%] [G loss: 0.834754]\n",
      "epoch:7 step:6573 [D loss: 0.685159, acc.: 55.47%] [G loss: 0.850431]\n",
      "epoch:7 step:6574 [D loss: 0.626286, acc.: 67.19%] [G loss: 0.886884]\n",
      "epoch:7 step:6575 [D loss: 0.666956, acc.: 56.25%] [G loss: 0.810243]\n",
      "epoch:7 step:6576 [D loss: 0.653996, acc.: 64.06%] [G loss: 0.853155]\n",
      "epoch:7 step:6577 [D loss: 0.703141, acc.: 54.69%] [G loss: 0.889531]\n",
      "epoch:7 step:6578 [D loss: 0.651020, acc.: 67.19%] [G loss: 0.880921]\n",
      "epoch:7 step:6579 [D loss: 0.679044, acc.: 54.69%] [G loss: 0.931681]\n",
      "epoch:7 step:6580 [D loss: 0.656917, acc.: 61.72%] [G loss: 0.896745]\n",
      "epoch:7 step:6581 [D loss: 0.634372, acc.: 61.72%] [G loss: 0.874885]\n",
      "epoch:7 step:6582 [D loss: 0.677027, acc.: 48.44%] [G loss: 0.794490]\n",
      "epoch:7 step:6583 [D loss: 0.626179, acc.: 64.84%] [G loss: 0.825562]\n",
      "epoch:7 step:6584 [D loss: 0.674107, acc.: 60.94%] [G loss: 0.836980]\n",
      "epoch:7 step:6585 [D loss: 0.670853, acc.: 54.69%] [G loss: 0.876484]\n",
      "epoch:7 step:6586 [D loss: 0.676240, acc.: 62.50%] [G loss: 0.875806]\n",
      "epoch:7 step:6587 [D loss: 0.652260, acc.: 66.41%] [G loss: 0.851331]\n",
      "epoch:7 step:6588 [D loss: 0.720524, acc.: 52.34%] [G loss: 0.853694]\n",
      "epoch:7 step:6589 [D loss: 0.686975, acc.: 57.81%] [G loss: 0.787325]\n",
      "epoch:7 step:6590 [D loss: 0.688655, acc.: 51.56%] [G loss: 0.830565]\n",
      "epoch:7 step:6591 [D loss: 0.638625, acc.: 65.62%] [G loss: 0.867449]\n",
      "epoch:7 step:6592 [D loss: 0.633207, acc.: 64.06%] [G loss: 0.833093]\n",
      "epoch:7 step:6593 [D loss: 0.683031, acc.: 53.12%] [G loss: 0.803478]\n",
      "epoch:7 step:6594 [D loss: 0.671986, acc.: 55.47%] [G loss: 0.854072]\n",
      "epoch:7 step:6595 [D loss: 0.625635, acc.: 62.50%] [G loss: 0.872943]\n",
      "epoch:7 step:6596 [D loss: 0.685398, acc.: 57.03%] [G loss: 0.843180]\n",
      "epoch:7 step:6597 [D loss: 0.682603, acc.: 56.25%] [G loss: 0.890376]\n",
      "epoch:7 step:6598 [D loss: 0.665615, acc.: 58.59%] [G loss: 0.895938]\n",
      "epoch:7 step:6599 [D loss: 0.672466, acc.: 59.38%] [G loss: 0.861259]\n",
      "epoch:7 step:6600 [D loss: 0.651938, acc.: 64.06%] [G loss: 0.805081]\n",
      "##############\n",
      "[ 2.98268569  2.77258334  2.55481685  4.1799265   1.46905209 10.27426719\n",
      "  3.04782198  3.85162961  4.27288042  8.14868929]\n",
      "##########\n",
      "epoch:7 step:6601 [D loss: 0.636117, acc.: 64.06%] [G loss: 0.834365]\n",
      "epoch:7 step:6602 [D loss: 0.674123, acc.: 53.12%] [G loss: 0.847864]\n",
      "epoch:7 step:6603 [D loss: 0.707605, acc.: 51.56%] [G loss: 0.829241]\n",
      "epoch:7 step:6604 [D loss: 0.666723, acc.: 58.59%] [G loss: 0.843215]\n",
      "epoch:7 step:6605 [D loss: 0.664707, acc.: 57.03%] [G loss: 0.824142]\n",
      "epoch:7 step:6606 [D loss: 0.690610, acc.: 49.22%] [G loss: 0.811353]\n",
      "epoch:7 step:6607 [D loss: 0.674805, acc.: 59.38%] [G loss: 0.846508]\n",
      "epoch:7 step:6608 [D loss: 0.661444, acc.: 55.47%] [G loss: 0.795368]\n",
      "epoch:7 step:6609 [D loss: 0.652155, acc.: 57.81%] [G loss: 0.865231]\n",
      "epoch:7 step:6610 [D loss: 0.677073, acc.: 53.12%] [G loss: 0.810026]\n",
      "epoch:7 step:6611 [D loss: 0.617973, acc.: 68.75%] [G loss: 0.824299]\n",
      "epoch:7 step:6612 [D loss: 0.649783, acc.: 64.06%] [G loss: 0.796399]\n",
      "epoch:7 step:6613 [D loss: 0.654573, acc.: 58.59%] [G loss: 0.768869]\n",
      "epoch:7 step:6614 [D loss: 0.661874, acc.: 58.59%] [G loss: 0.862652]\n",
      "epoch:7 step:6615 [D loss: 0.658391, acc.: 60.16%] [G loss: 0.748212]\n",
      "epoch:7 step:6616 [D loss: 0.654780, acc.: 60.94%] [G loss: 0.826696]\n",
      "epoch:7 step:6617 [D loss: 0.670419, acc.: 57.81%] [G loss: 0.821855]\n",
      "epoch:7 step:6618 [D loss: 0.653353, acc.: 60.94%] [G loss: 0.844329]\n",
      "epoch:7 step:6619 [D loss: 0.685644, acc.: 57.03%] [G loss: 0.833645]\n",
      "epoch:7 step:6620 [D loss: 0.689407, acc.: 58.59%] [G loss: 0.835969]\n",
      "epoch:7 step:6621 [D loss: 0.683940, acc.: 59.38%] [G loss: 0.850844]\n",
      "epoch:7 step:6622 [D loss: 0.638073, acc.: 62.50%] [G loss: 0.851889]\n",
      "epoch:7 step:6623 [D loss: 0.632689, acc.: 61.72%] [G loss: 0.854355]\n",
      "epoch:7 step:6624 [D loss: 0.617543, acc.: 65.62%] [G loss: 0.812810]\n",
      "epoch:7 step:6625 [D loss: 0.677746, acc.: 60.16%] [G loss: 0.882211]\n",
      "epoch:7 step:6626 [D loss: 0.724066, acc.: 50.00%] [G loss: 0.870038]\n",
      "epoch:7 step:6627 [D loss: 0.671147, acc.: 53.91%] [G loss: 0.875071]\n",
      "epoch:7 step:6628 [D loss: 0.645860, acc.: 62.50%] [G loss: 0.890571]\n",
      "epoch:7 step:6629 [D loss: 0.653861, acc.: 58.59%] [G loss: 0.899257]\n",
      "epoch:7 step:6630 [D loss: 0.699139, acc.: 57.03%] [G loss: 0.906434]\n",
      "epoch:7 step:6631 [D loss: 0.656009, acc.: 62.50%] [G loss: 0.843466]\n",
      "epoch:7 step:6632 [D loss: 0.621293, acc.: 65.62%] [G loss: 0.885521]\n",
      "epoch:7 step:6633 [D loss: 0.685989, acc.: 55.47%] [G loss: 0.870719]\n",
      "epoch:7 step:6634 [D loss: 0.653795, acc.: 62.50%] [G loss: 0.793580]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6635 [D loss: 0.640654, acc.: 63.28%] [G loss: 0.854894]\n",
      "epoch:7 step:6636 [D loss: 0.668916, acc.: 57.81%] [G loss: 0.844165]\n",
      "epoch:7 step:6637 [D loss: 0.658002, acc.: 59.38%] [G loss: 0.848347]\n",
      "epoch:7 step:6638 [D loss: 0.695619, acc.: 53.12%] [G loss: 0.872545]\n",
      "epoch:7 step:6639 [D loss: 0.663589, acc.: 60.94%] [G loss: 0.861059]\n",
      "epoch:7 step:6640 [D loss: 0.671140, acc.: 57.81%] [G loss: 0.849311]\n",
      "epoch:7 step:6641 [D loss: 0.667926, acc.: 57.81%] [G loss: 0.889593]\n",
      "epoch:7 step:6642 [D loss: 0.658248, acc.: 63.28%] [G loss: 0.856707]\n",
      "epoch:7 step:6643 [D loss: 0.660469, acc.: 58.59%] [G loss: 0.877746]\n",
      "epoch:7 step:6644 [D loss: 0.659166, acc.: 58.59%] [G loss: 0.876715]\n",
      "epoch:7 step:6645 [D loss: 0.664309, acc.: 60.16%] [G loss: 0.878914]\n",
      "epoch:7 step:6646 [D loss: 0.642992, acc.: 64.06%] [G loss: 0.897481]\n",
      "epoch:7 step:6647 [D loss: 0.694228, acc.: 54.69%] [G loss: 0.904773]\n",
      "epoch:7 step:6648 [D loss: 0.634330, acc.: 64.84%] [G loss: 0.930509]\n",
      "epoch:7 step:6649 [D loss: 0.693396, acc.: 58.59%] [G loss: 0.868371]\n",
      "epoch:7 step:6650 [D loss: 0.691352, acc.: 58.59%] [G loss: 0.786833]\n",
      "epoch:7 step:6651 [D loss: 0.670831, acc.: 60.94%] [G loss: 0.830511]\n",
      "epoch:7 step:6652 [D loss: 0.663625, acc.: 60.16%] [G loss: 0.828913]\n",
      "epoch:7 step:6653 [D loss: 0.662565, acc.: 57.81%] [G loss: 0.863354]\n",
      "epoch:7 step:6654 [D loss: 0.654866, acc.: 64.06%] [G loss: 0.836664]\n",
      "epoch:7 step:6655 [D loss: 0.662501, acc.: 61.72%] [G loss: 0.839669]\n",
      "epoch:7 step:6656 [D loss: 0.668125, acc.: 57.81%] [G loss: 0.863172]\n",
      "epoch:7 step:6657 [D loss: 0.675692, acc.: 56.25%] [G loss: 0.844493]\n",
      "epoch:7 step:6658 [D loss: 0.660330, acc.: 62.50%] [G loss: 0.875365]\n",
      "epoch:7 step:6659 [D loss: 0.702644, acc.: 54.69%] [G loss: 0.887448]\n",
      "epoch:7 step:6660 [D loss: 0.644368, acc.: 67.19%] [G loss: 0.853931]\n",
      "epoch:7 step:6661 [D loss: 0.683962, acc.: 57.03%] [G loss: 0.926469]\n",
      "epoch:7 step:6662 [D loss: 0.665353, acc.: 60.94%] [G loss: 0.876182]\n",
      "epoch:7 step:6663 [D loss: 0.675290, acc.: 48.44%] [G loss: 0.876326]\n",
      "epoch:7 step:6664 [D loss: 0.635490, acc.: 63.28%] [G loss: 0.867580]\n",
      "epoch:7 step:6665 [D loss: 0.658478, acc.: 63.28%] [G loss: 0.817577]\n",
      "epoch:7 step:6666 [D loss: 0.615197, acc.: 67.97%] [G loss: 0.878430]\n",
      "epoch:7 step:6667 [D loss: 0.639546, acc.: 60.16%] [G loss: 0.862688]\n",
      "epoch:7 step:6668 [D loss: 0.672945, acc.: 58.59%] [G loss: 0.942846]\n",
      "epoch:7 step:6669 [D loss: 0.687584, acc.: 54.69%] [G loss: 0.895291]\n",
      "epoch:7 step:6670 [D loss: 0.689741, acc.: 54.69%] [G loss: 0.833714]\n",
      "epoch:7 step:6671 [D loss: 0.661671, acc.: 66.41%] [G loss: 0.873083]\n",
      "epoch:7 step:6672 [D loss: 0.670328, acc.: 60.94%] [G loss: 0.886646]\n",
      "epoch:7 step:6673 [D loss: 0.690929, acc.: 55.47%] [G loss: 0.840702]\n",
      "epoch:7 step:6674 [D loss: 0.685633, acc.: 57.03%] [G loss: 0.833066]\n",
      "epoch:7 step:6675 [D loss: 0.684239, acc.: 60.16%] [G loss: 0.861022]\n",
      "epoch:7 step:6676 [D loss: 0.669189, acc.: 55.47%] [G loss: 0.853100]\n",
      "epoch:7 step:6677 [D loss: 0.649562, acc.: 63.28%] [G loss: 0.824350]\n",
      "epoch:7 step:6678 [D loss: 0.658231, acc.: 62.50%] [G loss: 0.814557]\n",
      "epoch:7 step:6679 [D loss: 0.695359, acc.: 59.38%] [G loss: 0.816492]\n",
      "epoch:7 step:6680 [D loss: 0.677920, acc.: 58.59%] [G loss: 0.807601]\n",
      "epoch:7 step:6681 [D loss: 0.664368, acc.: 61.72%] [G loss: 0.847241]\n",
      "epoch:7 step:6682 [D loss: 0.637236, acc.: 60.16%] [G loss: 0.857020]\n",
      "epoch:7 step:6683 [D loss: 0.682755, acc.: 53.91%] [G loss: 0.823743]\n",
      "epoch:7 step:6684 [D loss: 0.698754, acc.: 54.69%] [G loss: 0.864748]\n",
      "epoch:7 step:6685 [D loss: 0.670869, acc.: 59.38%] [G loss: 0.885788]\n",
      "epoch:7 step:6686 [D loss: 0.663355, acc.: 57.81%] [G loss: 0.930082]\n",
      "epoch:7 step:6687 [D loss: 0.641449, acc.: 60.94%] [G loss: 0.871492]\n",
      "epoch:7 step:6688 [D loss: 0.666204, acc.: 58.59%] [G loss: 0.919891]\n",
      "epoch:7 step:6689 [D loss: 0.687171, acc.: 60.16%] [G loss: 0.811213]\n",
      "epoch:7 step:6690 [D loss: 0.631289, acc.: 67.19%] [G loss: 0.810558]\n",
      "epoch:7 step:6691 [D loss: 0.701909, acc.: 53.12%] [G loss: 0.780104]\n",
      "epoch:7 step:6692 [D loss: 0.724968, acc.: 46.09%] [G loss: 0.825201]\n",
      "epoch:7 step:6693 [D loss: 0.687220, acc.: 53.91%] [G loss: 0.842384]\n",
      "epoch:7 step:6694 [D loss: 0.674733, acc.: 57.03%] [G loss: 0.853001]\n",
      "epoch:7 step:6695 [D loss: 0.689127, acc.: 52.34%] [G loss: 0.849178]\n",
      "epoch:7 step:6696 [D loss: 0.637270, acc.: 64.84%] [G loss: 0.827600]\n",
      "epoch:7 step:6697 [D loss: 0.669851, acc.: 57.03%] [G loss: 0.859531]\n",
      "epoch:7 step:6698 [D loss: 0.702374, acc.: 54.69%] [G loss: 0.831777]\n",
      "epoch:7 step:6699 [D loss: 0.658154, acc.: 61.72%] [G loss: 0.857704]\n",
      "epoch:7 step:6700 [D loss: 0.714890, acc.: 42.97%] [G loss: 0.822595]\n",
      "epoch:7 step:6701 [D loss: 0.642127, acc.: 64.84%] [G loss: 0.845158]\n",
      "epoch:7 step:6702 [D loss: 0.665270, acc.: 60.94%] [G loss: 0.867463]\n",
      "epoch:7 step:6703 [D loss: 0.685772, acc.: 57.81%] [G loss: 0.814571]\n",
      "epoch:7 step:6704 [D loss: 0.682972, acc.: 53.91%] [G loss: 0.848000]\n",
      "epoch:7 step:6705 [D loss: 0.641990, acc.: 64.06%] [G loss: 0.856991]\n",
      "epoch:7 step:6706 [D loss: 0.682162, acc.: 55.47%] [G loss: 0.845271]\n",
      "epoch:7 step:6707 [D loss: 0.690586, acc.: 56.25%] [G loss: 0.844362]\n",
      "epoch:7 step:6708 [D loss: 0.703266, acc.: 53.12%] [G loss: 0.836428]\n",
      "epoch:7 step:6709 [D loss: 0.656482, acc.: 61.72%] [G loss: 0.868006]\n",
      "epoch:7 step:6710 [D loss: 0.660089, acc.: 57.03%] [G loss: 0.909710]\n",
      "epoch:7 step:6711 [D loss: 0.655838, acc.: 69.53%] [G loss: 0.808129]\n",
      "epoch:7 step:6712 [D loss: 0.658555, acc.: 62.50%] [G loss: 0.803704]\n",
      "epoch:7 step:6713 [D loss: 0.689918, acc.: 53.12%] [G loss: 0.790913]\n",
      "epoch:7 step:6714 [D loss: 0.651711, acc.: 60.94%] [G loss: 0.835437]\n",
      "epoch:7 step:6715 [D loss: 0.671649, acc.: 60.94%] [G loss: 0.809250]\n",
      "epoch:7 step:6716 [D loss: 0.644429, acc.: 65.62%] [G loss: 0.857495]\n",
      "epoch:7 step:6717 [D loss: 0.663842, acc.: 64.84%] [G loss: 0.878161]\n",
      "epoch:7 step:6718 [D loss: 0.655689, acc.: 64.06%] [G loss: 0.917110]\n",
      "epoch:7 step:6719 [D loss: 0.684477, acc.: 57.03%] [G loss: 0.912777]\n",
      "epoch:7 step:6720 [D loss: 0.691941, acc.: 53.12%] [G loss: 0.856966]\n",
      "epoch:7 step:6721 [D loss: 0.653486, acc.: 64.84%] [G loss: 0.858220]\n",
      "epoch:7 step:6722 [D loss: 0.659508, acc.: 64.06%] [G loss: 0.822399]\n",
      "epoch:7 step:6723 [D loss: 0.745839, acc.: 51.56%] [G loss: 0.895085]\n",
      "epoch:7 step:6724 [D loss: 0.658517, acc.: 57.03%] [G loss: 0.826076]\n",
      "epoch:7 step:6725 [D loss: 0.688101, acc.: 56.25%] [G loss: 0.853946]\n",
      "epoch:7 step:6726 [D loss: 0.661084, acc.: 58.59%] [G loss: 0.872284]\n",
      "epoch:7 step:6727 [D loss: 0.709624, acc.: 46.09%] [G loss: 0.870662]\n",
      "epoch:7 step:6728 [D loss: 0.711384, acc.: 50.00%] [G loss: 0.854069]\n",
      "epoch:7 step:6729 [D loss: 0.678032, acc.: 56.25%] [G loss: 0.870820]\n",
      "epoch:7 step:6730 [D loss: 0.674581, acc.: 58.59%] [G loss: 0.846725]\n",
      "epoch:7 step:6731 [D loss: 0.678093, acc.: 56.25%] [G loss: 0.866197]\n",
      "epoch:7 step:6732 [D loss: 0.681960, acc.: 52.34%] [G loss: 0.809601]\n",
      "epoch:7 step:6733 [D loss: 0.634220, acc.: 66.41%] [G loss: 0.846954]\n",
      "epoch:7 step:6734 [D loss: 0.687719, acc.: 55.47%] [G loss: 0.808442]\n",
      "epoch:7 step:6735 [D loss: 0.647386, acc.: 60.94%] [G loss: 0.824507]\n",
      "epoch:7 step:6736 [D loss: 0.655316, acc.: 61.72%] [G loss: 0.877045]\n",
      "epoch:7 step:6737 [D loss: 0.638208, acc.: 62.50%] [G loss: 0.841423]\n",
      "epoch:7 step:6738 [D loss: 0.656606, acc.: 64.06%] [G loss: 0.870228]\n",
      "epoch:7 step:6739 [D loss: 0.645388, acc.: 67.19%] [G loss: 0.858309]\n",
      "epoch:7 step:6740 [D loss: 0.640773, acc.: 68.75%] [G loss: 0.896223]\n",
      "epoch:7 step:6741 [D loss: 0.617844, acc.: 64.84%] [G loss: 0.866969]\n",
      "epoch:7 step:6742 [D loss: 0.671238, acc.: 59.38%] [G loss: 0.854742]\n",
      "epoch:7 step:6743 [D loss: 0.661961, acc.: 63.28%] [G loss: 0.872442]\n",
      "epoch:7 step:6744 [D loss: 0.684181, acc.: 56.25%] [G loss: 0.876509]\n",
      "epoch:7 step:6745 [D loss: 0.670621, acc.: 59.38%] [G loss: 0.885041]\n",
      "epoch:7 step:6746 [D loss: 0.623667, acc.: 72.66%] [G loss: 0.864507]\n",
      "epoch:7 step:6747 [D loss: 0.649961, acc.: 57.03%] [G loss: 0.836536]\n",
      "epoch:7 step:6748 [D loss: 0.686206, acc.: 53.91%] [G loss: 0.849721]\n",
      "epoch:7 step:6749 [D loss: 0.699203, acc.: 55.47%] [G loss: 0.865219]\n",
      "epoch:7 step:6750 [D loss: 0.623022, acc.: 61.72%] [G loss: 0.843465]\n",
      "epoch:7 step:6751 [D loss: 0.679193, acc.: 51.56%] [G loss: 0.925731]\n",
      "epoch:7 step:6752 [D loss: 0.653710, acc.: 62.50%] [G loss: 0.900113]\n",
      "epoch:7 step:6753 [D loss: 0.716569, acc.: 49.22%] [G loss: 0.816758]\n",
      "epoch:7 step:6754 [D loss: 0.666442, acc.: 60.94%] [G loss: 0.847312]\n",
      "epoch:7 step:6755 [D loss: 0.647933, acc.: 62.50%] [G loss: 0.826955]\n",
      "epoch:7 step:6756 [D loss: 0.647088, acc.: 60.16%] [G loss: 0.859445]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6757 [D loss: 0.664689, acc.: 58.59%] [G loss: 0.848808]\n",
      "epoch:7 step:6758 [D loss: 0.675767, acc.: 62.50%] [G loss: 0.810001]\n",
      "epoch:7 step:6759 [D loss: 0.650185, acc.: 58.59%] [G loss: 0.859001]\n",
      "epoch:7 step:6760 [D loss: 0.684350, acc.: 56.25%] [G loss: 0.857540]\n",
      "epoch:7 step:6761 [D loss: 0.632302, acc.: 64.84%] [G loss: 0.871821]\n",
      "epoch:7 step:6762 [D loss: 0.677298, acc.: 57.03%] [G loss: 0.853251]\n",
      "epoch:7 step:6763 [D loss: 0.682152, acc.: 51.56%] [G loss: 0.856231]\n",
      "epoch:7 step:6764 [D loss: 0.665558, acc.: 57.81%] [G loss: 0.874779]\n",
      "epoch:7 step:6765 [D loss: 0.704235, acc.: 58.59%] [G loss: 0.888572]\n",
      "epoch:7 step:6766 [D loss: 0.659576, acc.: 66.41%] [G loss: 0.874640]\n",
      "epoch:7 step:6767 [D loss: 0.658150, acc.: 59.38%] [G loss: 0.844618]\n",
      "epoch:7 step:6768 [D loss: 0.634784, acc.: 63.28%] [G loss: 0.846770]\n",
      "epoch:7 step:6769 [D loss: 0.652344, acc.: 67.97%] [G loss: 0.828574]\n",
      "epoch:7 step:6770 [D loss: 0.666752, acc.: 54.69%] [G loss: 0.831946]\n",
      "epoch:7 step:6771 [D loss: 0.682625, acc.: 56.25%] [G loss: 0.835098]\n",
      "epoch:7 step:6772 [D loss: 0.689323, acc.: 54.69%] [G loss: 0.830813]\n",
      "epoch:7 step:6773 [D loss: 0.733826, acc.: 49.22%] [G loss: 0.840667]\n",
      "epoch:7 step:6774 [D loss: 0.664459, acc.: 59.38%] [G loss: 0.829841]\n",
      "epoch:7 step:6775 [D loss: 0.676682, acc.: 54.69%] [G loss: 0.784996]\n",
      "epoch:7 step:6776 [D loss: 0.654246, acc.: 66.41%] [G loss: 0.839194]\n",
      "epoch:7 step:6777 [D loss: 0.679048, acc.: 53.91%] [G loss: 0.869533]\n",
      "epoch:7 step:6778 [D loss: 0.659706, acc.: 62.50%] [G loss: 0.813485]\n",
      "epoch:7 step:6779 [D loss: 0.661871, acc.: 60.94%] [G loss: 0.835320]\n",
      "epoch:7 step:6780 [D loss: 0.656749, acc.: 60.16%] [G loss: 0.844352]\n",
      "epoch:7 step:6781 [D loss: 0.672694, acc.: 60.94%] [G loss: 0.801932]\n",
      "epoch:7 step:6782 [D loss: 0.679603, acc.: 58.59%] [G loss: 0.843762]\n",
      "epoch:7 step:6783 [D loss: 0.671598, acc.: 58.59%] [G loss: 0.865014]\n",
      "epoch:7 step:6784 [D loss: 0.654867, acc.: 62.50%] [G loss: 0.879152]\n",
      "epoch:7 step:6785 [D loss: 0.668506, acc.: 57.03%] [G loss: 0.825588]\n",
      "epoch:7 step:6786 [D loss: 0.663735, acc.: 58.59%] [G loss: 0.869117]\n",
      "epoch:7 step:6787 [D loss: 0.670609, acc.: 57.81%] [G loss: 0.832570]\n",
      "epoch:7 step:6788 [D loss: 0.664289, acc.: 58.59%] [G loss: 0.850951]\n",
      "epoch:7 step:6789 [D loss: 0.664612, acc.: 63.28%] [G loss: 0.885993]\n",
      "epoch:7 step:6790 [D loss: 0.663335, acc.: 57.03%] [G loss: 0.852829]\n",
      "epoch:7 step:6791 [D loss: 0.667446, acc.: 60.94%] [G loss: 0.909500]\n",
      "epoch:7 step:6792 [D loss: 0.661211, acc.: 61.72%] [G loss: 0.832410]\n",
      "epoch:7 step:6793 [D loss: 0.673665, acc.: 55.47%] [G loss: 0.897954]\n",
      "epoch:7 step:6794 [D loss: 0.658987, acc.: 58.59%] [G loss: 0.779897]\n",
      "epoch:7 step:6795 [D loss: 0.665989, acc.: 57.81%] [G loss: 0.822478]\n",
      "epoch:7 step:6796 [D loss: 0.697904, acc.: 56.25%] [G loss: 0.835929]\n",
      "epoch:7 step:6797 [D loss: 0.676652, acc.: 57.81%] [G loss: 0.816328]\n",
      "epoch:7 step:6798 [D loss: 0.678929, acc.: 57.03%] [G loss: 0.807138]\n",
      "epoch:7 step:6799 [D loss: 0.692408, acc.: 57.81%] [G loss: 0.836802]\n",
      "epoch:7 step:6800 [D loss: 0.657858, acc.: 65.62%] [G loss: 0.845495]\n",
      "##############\n",
      "[2.60855652 2.42595492 2.49426363 3.76861842 1.23219075 8.30136048\n",
      " 2.93175261 3.87617501 4.24981088 7.14868929]\n",
      "##########\n",
      "epoch:7 step:6801 [D loss: 0.675368, acc.: 61.72%] [G loss: 0.867547]\n",
      "epoch:7 step:6802 [D loss: 0.659323, acc.: 56.25%] [G loss: 0.864017]\n",
      "epoch:7 step:6803 [D loss: 0.681972, acc.: 59.38%] [G loss: 0.843926]\n",
      "epoch:7 step:6804 [D loss: 0.644379, acc.: 57.03%] [G loss: 0.815909]\n",
      "epoch:7 step:6805 [D loss: 0.661731, acc.: 60.94%] [G loss: 0.874063]\n",
      "epoch:7 step:6806 [D loss: 0.667387, acc.: 56.25%] [G loss: 0.841879]\n",
      "epoch:7 step:6807 [D loss: 0.669293, acc.: 64.06%] [G loss: 0.889740]\n",
      "epoch:7 step:6808 [D loss: 0.677092, acc.: 53.12%] [G loss: 0.891397]\n",
      "epoch:7 step:6809 [D loss: 0.683389, acc.: 57.81%] [G loss: 0.827684]\n",
      "epoch:7 step:6810 [D loss: 0.687662, acc.: 57.81%] [G loss: 0.833370]\n",
      "epoch:7 step:6811 [D loss: 0.665722, acc.: 64.06%] [G loss: 0.860592]\n",
      "epoch:7 step:6812 [D loss: 0.695593, acc.: 61.72%] [G loss: 0.877153]\n",
      "epoch:7 step:6813 [D loss: 0.689069, acc.: 51.56%] [G loss: 0.811597]\n",
      "epoch:7 step:6814 [D loss: 0.679048, acc.: 59.38%] [G loss: 0.836634]\n",
      "epoch:7 step:6815 [D loss: 0.674859, acc.: 61.72%] [G loss: 0.830164]\n",
      "epoch:7 step:6816 [D loss: 0.645493, acc.: 60.16%] [G loss: 0.862892]\n",
      "epoch:7 step:6817 [D loss: 0.692526, acc.: 57.03%] [G loss: 0.793596]\n",
      "epoch:7 step:6818 [D loss: 0.644058, acc.: 61.72%] [G loss: 0.825086]\n",
      "epoch:7 step:6819 [D loss: 0.663928, acc.: 56.25%] [G loss: 0.830890]\n",
      "epoch:7 step:6820 [D loss: 0.673883, acc.: 60.16%] [G loss: 0.811966]\n",
      "epoch:7 step:6821 [D loss: 0.690077, acc.: 57.03%] [G loss: 0.867140]\n",
      "epoch:7 step:6822 [D loss: 0.681498, acc.: 59.38%] [G loss: 0.820828]\n",
      "epoch:7 step:6823 [D loss: 0.652472, acc.: 60.16%] [G loss: 0.831586]\n",
      "epoch:7 step:6824 [D loss: 0.672611, acc.: 53.91%] [G loss: 0.868762]\n",
      "epoch:7 step:6825 [D loss: 0.686589, acc.: 53.12%] [G loss: 0.864631]\n",
      "epoch:7 step:6826 [D loss: 0.674214, acc.: 56.25%] [G loss: 0.889557]\n",
      "epoch:7 step:6827 [D loss: 0.664091, acc.: 59.38%] [G loss: 0.834577]\n",
      "epoch:7 step:6828 [D loss: 0.665677, acc.: 64.06%] [G loss: 0.799319]\n",
      "epoch:7 step:6829 [D loss: 0.678863, acc.: 57.81%] [G loss: 0.868275]\n",
      "epoch:7 step:6830 [D loss: 0.683930, acc.: 55.47%] [G loss: 0.797316]\n",
      "epoch:7 step:6831 [D loss: 0.666946, acc.: 59.38%] [G loss: 0.881342]\n",
      "epoch:7 step:6832 [D loss: 0.656262, acc.: 62.50%] [G loss: 0.829739]\n",
      "epoch:7 step:6833 [D loss: 0.628384, acc.: 64.84%] [G loss: 0.864216]\n",
      "epoch:7 step:6834 [D loss: 0.689945, acc.: 52.34%] [G loss: 0.842795]\n",
      "epoch:7 step:6835 [D loss: 0.697345, acc.: 51.56%] [G loss: 0.848638]\n",
      "epoch:7 step:6836 [D loss: 0.638349, acc.: 66.41%] [G loss: 0.868087]\n",
      "epoch:7 step:6837 [D loss: 0.670989, acc.: 62.50%] [G loss: 0.864587]\n",
      "epoch:7 step:6838 [D loss: 0.675262, acc.: 61.72%] [G loss: 0.880686]\n",
      "epoch:7 step:6839 [D loss: 0.730031, acc.: 44.53%] [G loss: 0.862290]\n",
      "epoch:7 step:6840 [D loss: 0.656219, acc.: 64.84%] [G loss: 0.853326]\n",
      "epoch:7 step:6841 [D loss: 0.677091, acc.: 59.38%] [G loss: 0.847352]\n",
      "epoch:7 step:6842 [D loss: 0.635896, acc.: 63.28%] [G loss: 0.848195]\n",
      "epoch:7 step:6843 [D loss: 0.658994, acc.: 60.94%] [G loss: 0.874034]\n",
      "epoch:7 step:6844 [D loss: 0.628139, acc.: 64.84%] [G loss: 0.870787]\n",
      "epoch:7 step:6845 [D loss: 0.677070, acc.: 60.16%] [G loss: 0.855621]\n",
      "epoch:7 step:6846 [D loss: 0.649396, acc.: 64.06%] [G loss: 0.817976]\n",
      "epoch:7 step:6847 [D loss: 0.637090, acc.: 64.06%] [G loss: 0.772709]\n",
      "epoch:7 step:6848 [D loss: 0.660215, acc.: 62.50%] [G loss: 0.856665]\n",
      "epoch:7 step:6849 [D loss: 0.648029, acc.: 65.62%] [G loss: 0.834917]\n",
      "epoch:7 step:6850 [D loss: 0.684036, acc.: 57.81%] [G loss: 0.836573]\n",
      "epoch:7 step:6851 [D loss: 0.667280, acc.: 57.03%] [G loss: 0.794933]\n",
      "epoch:7 step:6852 [D loss: 0.653757, acc.: 62.50%] [G loss: 0.861078]\n",
      "epoch:7 step:6853 [D loss: 0.654835, acc.: 64.06%] [G loss: 0.833211]\n",
      "epoch:7 step:6854 [D loss: 0.688562, acc.: 52.34%] [G loss: 0.829237]\n",
      "epoch:7 step:6855 [D loss: 0.664955, acc.: 59.38%] [G loss: 0.845041]\n",
      "epoch:7 step:6856 [D loss: 0.659433, acc.: 59.38%] [G loss: 0.840573]\n",
      "epoch:7 step:6857 [D loss: 0.695192, acc.: 52.34%] [G loss: 0.759645]\n",
      "epoch:7 step:6858 [D loss: 0.687020, acc.: 57.03%] [G loss: 0.850005]\n",
      "epoch:7 step:6859 [D loss: 0.648298, acc.: 61.72%] [G loss: 0.864203]\n",
      "epoch:7 step:6860 [D loss: 0.666778, acc.: 61.72%] [G loss: 0.835214]\n",
      "epoch:7 step:6861 [D loss: 0.671992, acc.: 62.50%] [G loss: 0.789565]\n",
      "epoch:7 step:6862 [D loss: 0.671605, acc.: 60.94%] [G loss: 0.829434]\n",
      "epoch:7 step:6863 [D loss: 0.660383, acc.: 64.84%] [G loss: 0.845962]\n",
      "epoch:7 step:6864 [D loss: 0.684877, acc.: 57.81%] [G loss: 0.883840]\n",
      "epoch:7 step:6865 [D loss: 0.673150, acc.: 57.81%] [G loss: 0.881922]\n",
      "epoch:7 step:6866 [D loss: 0.688012, acc.: 55.47%] [G loss: 0.848918]\n",
      "epoch:7 step:6867 [D loss: 0.653323, acc.: 64.06%] [G loss: 0.888791]\n",
      "epoch:7 step:6868 [D loss: 0.663089, acc.: 56.25%] [G loss: 0.863913]\n",
      "epoch:7 step:6869 [D loss: 0.653018, acc.: 59.38%] [G loss: 0.872789]\n",
      "epoch:7 step:6870 [D loss: 0.684202, acc.: 50.00%] [G loss: 0.873817]\n",
      "epoch:7 step:6871 [D loss: 0.717000, acc.: 56.25%] [G loss: 0.833207]\n",
      "epoch:7 step:6872 [D loss: 0.693231, acc.: 52.34%] [G loss: 0.840017]\n",
      "epoch:7 step:6873 [D loss: 0.681284, acc.: 56.25%] [G loss: 0.849336]\n",
      "epoch:7 step:6874 [D loss: 0.645501, acc.: 60.16%] [G loss: 0.811707]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6875 [D loss: 0.660917, acc.: 55.47%] [G loss: 0.839227]\n",
      "epoch:7 step:6876 [D loss: 0.653847, acc.: 60.16%] [G loss: 0.821280]\n",
      "epoch:7 step:6877 [D loss: 0.667509, acc.: 56.25%] [G loss: 0.833414]\n",
      "epoch:7 step:6878 [D loss: 0.694210, acc.: 53.91%] [G loss: 0.851783]\n",
      "epoch:7 step:6879 [D loss: 0.657212, acc.: 63.28%] [G loss: 0.806483]\n",
      "epoch:7 step:6880 [D loss: 0.625316, acc.: 64.06%] [G loss: 0.829324]\n",
      "epoch:7 step:6881 [D loss: 0.671816, acc.: 57.81%] [G loss: 0.861206]\n",
      "epoch:7 step:6882 [D loss: 0.691686, acc.: 54.69%] [G loss: 0.866473]\n",
      "epoch:7 step:6883 [D loss: 0.651736, acc.: 58.59%] [G loss: 0.889183]\n",
      "epoch:7 step:6884 [D loss: 0.665845, acc.: 62.50%] [G loss: 0.819207]\n",
      "epoch:7 step:6885 [D loss: 0.700519, acc.: 53.12%] [G loss: 0.840475]\n",
      "epoch:7 step:6886 [D loss: 0.653591, acc.: 58.59%] [G loss: 0.885467]\n",
      "epoch:7 step:6887 [D loss: 0.661369, acc.: 57.81%] [G loss: 0.861499]\n",
      "epoch:7 step:6888 [D loss: 0.667415, acc.: 64.06%] [G loss: 0.839977]\n",
      "epoch:7 step:6889 [D loss: 0.656501, acc.: 60.94%] [G loss: 0.872550]\n",
      "epoch:7 step:6890 [D loss: 0.656561, acc.: 63.28%] [G loss: 0.859506]\n",
      "epoch:7 step:6891 [D loss: 0.654459, acc.: 60.16%] [G loss: 0.872922]\n",
      "epoch:7 step:6892 [D loss: 0.667984, acc.: 54.69%] [G loss: 0.825051]\n",
      "epoch:7 step:6893 [D loss: 0.660861, acc.: 55.47%] [G loss: 0.815530]\n",
      "epoch:7 step:6894 [D loss: 0.662134, acc.: 60.16%] [G loss: 0.825842]\n",
      "epoch:7 step:6895 [D loss: 0.632352, acc.: 66.41%] [G loss: 0.834939]\n",
      "epoch:7 step:6896 [D loss: 0.679797, acc.: 58.59%] [G loss: 0.821536]\n",
      "epoch:7 step:6897 [D loss: 0.654027, acc.: 62.50%] [G loss: 0.946743]\n",
      "epoch:7 step:6898 [D loss: 0.650676, acc.: 62.50%] [G loss: 0.893846]\n",
      "epoch:7 step:6899 [D loss: 0.675977, acc.: 53.12%] [G loss: 0.853364]\n",
      "epoch:7 step:6900 [D loss: 0.639245, acc.: 64.06%] [G loss: 0.867368]\n",
      "epoch:7 step:6901 [D loss: 0.647530, acc.: 64.06%] [G loss: 0.867353]\n",
      "epoch:7 step:6902 [D loss: 0.677981, acc.: 57.03%] [G loss: 0.795641]\n",
      "epoch:7 step:6903 [D loss: 0.665423, acc.: 60.94%] [G loss: 0.845539]\n",
      "epoch:7 step:6904 [D loss: 0.647685, acc.: 61.72%] [G loss: 0.863455]\n",
      "epoch:7 step:6905 [D loss: 0.702460, acc.: 56.25%] [G loss: 0.827819]\n",
      "epoch:7 step:6906 [D loss: 0.664353, acc.: 64.06%] [G loss: 0.829581]\n",
      "epoch:7 step:6907 [D loss: 0.652569, acc.: 62.50%] [G loss: 0.839726]\n",
      "epoch:7 step:6908 [D loss: 0.638084, acc.: 63.28%] [G loss: 0.813756]\n",
      "epoch:7 step:6909 [D loss: 0.665313, acc.: 58.59%] [G loss: 0.850289]\n",
      "epoch:7 step:6910 [D loss: 0.679348, acc.: 57.03%] [G loss: 0.821340]\n",
      "epoch:7 step:6911 [D loss: 0.705839, acc.: 53.12%] [G loss: 0.805256]\n",
      "epoch:7 step:6912 [D loss: 0.700878, acc.: 50.78%] [G loss: 0.849627]\n",
      "epoch:7 step:6913 [D loss: 0.666032, acc.: 59.38%] [G loss: 0.819299]\n",
      "epoch:7 step:6914 [D loss: 0.682338, acc.: 55.47%] [G loss: 0.825272]\n",
      "epoch:7 step:6915 [D loss: 0.672394, acc.: 60.94%] [G loss: 0.856879]\n",
      "epoch:7 step:6916 [D loss: 0.682835, acc.: 55.47%] [G loss: 0.883450]\n",
      "epoch:7 step:6917 [D loss: 0.675722, acc.: 56.25%] [G loss: 0.901931]\n",
      "epoch:7 step:6918 [D loss: 0.690883, acc.: 56.25%] [G loss: 0.914301]\n",
      "epoch:7 step:6919 [D loss: 0.651617, acc.: 57.81%] [G loss: 0.912872]\n",
      "epoch:7 step:6920 [D loss: 0.676931, acc.: 57.03%] [G loss: 0.870652]\n",
      "epoch:7 step:6921 [D loss: 0.642869, acc.: 61.72%] [G loss: 0.870845]\n",
      "epoch:7 step:6922 [D loss: 0.660442, acc.: 60.94%] [G loss: 0.883312]\n",
      "epoch:7 step:6923 [D loss: 0.696903, acc.: 50.00%] [G loss: 0.848345]\n",
      "epoch:7 step:6924 [D loss: 0.683472, acc.: 53.12%] [G loss: 0.856800]\n",
      "epoch:7 step:6925 [D loss: 0.655035, acc.: 60.16%] [G loss: 0.854535]\n",
      "epoch:7 step:6926 [D loss: 0.647321, acc.: 57.81%] [G loss: 0.859551]\n",
      "epoch:7 step:6927 [D loss: 0.671891, acc.: 54.69%] [G loss: 0.862495]\n",
      "epoch:7 step:6928 [D loss: 0.659474, acc.: 64.84%] [G loss: 0.858579]\n",
      "epoch:7 step:6929 [D loss: 0.662469, acc.: 62.50%] [G loss: 0.806370]\n",
      "epoch:7 step:6930 [D loss: 0.684517, acc.: 54.69%] [G loss: 0.827956]\n",
      "epoch:7 step:6931 [D loss: 0.638928, acc.: 63.28%] [G loss: 0.852814]\n",
      "epoch:7 step:6932 [D loss: 0.680974, acc.: 50.78%] [G loss: 0.858299]\n",
      "epoch:7 step:6933 [D loss: 0.645762, acc.: 62.50%] [G loss: 0.858090]\n",
      "epoch:7 step:6934 [D loss: 0.682377, acc.: 53.91%] [G loss: 0.821826]\n",
      "epoch:7 step:6935 [D loss: 0.678991, acc.: 57.81%] [G loss: 0.857061]\n",
      "epoch:7 step:6936 [D loss: 0.678712, acc.: 53.91%] [G loss: 0.835947]\n",
      "epoch:7 step:6937 [D loss: 0.617775, acc.: 67.19%] [G loss: 0.859296]\n",
      "epoch:7 step:6938 [D loss: 0.686874, acc.: 50.78%] [G loss: 0.895710]\n",
      "epoch:7 step:6939 [D loss: 0.678288, acc.: 60.16%] [G loss: 0.869498]\n",
      "epoch:7 step:6940 [D loss: 0.655377, acc.: 57.81%] [G loss: 0.905798]\n",
      "epoch:7 step:6941 [D loss: 0.647819, acc.: 65.62%] [G loss: 0.888324]\n",
      "epoch:7 step:6942 [D loss: 0.655017, acc.: 57.81%] [G loss: 0.888472]\n",
      "epoch:7 step:6943 [D loss: 0.676631, acc.: 58.59%] [G loss: 0.924516]\n",
      "epoch:7 step:6944 [D loss: 0.709322, acc.: 51.56%] [G loss: 0.894644]\n",
      "epoch:7 step:6945 [D loss: 0.662310, acc.: 57.03%] [G loss: 0.880190]\n",
      "epoch:7 step:6946 [D loss: 0.635680, acc.: 60.16%] [G loss: 0.819459]\n",
      "epoch:7 step:6947 [D loss: 0.677294, acc.: 57.03%] [G loss: 0.781066]\n",
      "epoch:7 step:6948 [D loss: 0.678031, acc.: 54.69%] [G loss: 0.793583]\n",
      "epoch:7 step:6949 [D loss: 0.664817, acc.: 58.59%] [G loss: 0.812794]\n",
      "epoch:7 step:6950 [D loss: 0.686774, acc.: 58.59%] [G loss: 0.889069]\n",
      "epoch:7 step:6951 [D loss: 0.673160, acc.: 59.38%] [G loss: 0.881684]\n",
      "epoch:7 step:6952 [D loss: 0.684295, acc.: 56.25%] [G loss: 0.890574]\n",
      "epoch:7 step:6953 [D loss: 0.685298, acc.: 54.69%] [G loss: 0.876922]\n",
      "epoch:7 step:6954 [D loss: 0.671043, acc.: 62.50%] [G loss: 0.862120]\n",
      "epoch:7 step:6955 [D loss: 0.640910, acc.: 63.28%] [G loss: 0.844077]\n",
      "epoch:7 step:6956 [D loss: 0.682514, acc.: 55.47%] [G loss: 0.833165]\n",
      "epoch:7 step:6957 [D loss: 0.703009, acc.: 56.25%] [G loss: 0.819518]\n",
      "epoch:7 step:6958 [D loss: 0.642933, acc.: 65.62%] [G loss: 0.845650]\n",
      "epoch:7 step:6959 [D loss: 0.646634, acc.: 67.19%] [G loss: 0.817036]\n",
      "epoch:7 step:6960 [D loss: 0.653618, acc.: 57.81%] [G loss: 0.839002]\n",
      "epoch:7 step:6961 [D loss: 0.616833, acc.: 64.84%] [G loss: 0.860346]\n",
      "epoch:7 step:6962 [D loss: 0.661826, acc.: 61.72%] [G loss: 0.882662]\n",
      "epoch:7 step:6963 [D loss: 0.659385, acc.: 59.38%] [G loss: 0.851845]\n",
      "epoch:7 step:6964 [D loss: 0.678184, acc.: 56.25%] [G loss: 0.844618]\n",
      "epoch:7 step:6965 [D loss: 0.676649, acc.: 59.38%] [G loss: 0.835491]\n",
      "epoch:7 step:6966 [D loss: 0.677127, acc.: 58.59%] [G loss: 0.863709]\n",
      "epoch:7 step:6967 [D loss: 0.647492, acc.: 65.62%] [G loss: 0.829897]\n",
      "epoch:7 step:6968 [D loss: 0.667587, acc.: 60.94%] [G loss: 0.831535]\n",
      "epoch:7 step:6969 [D loss: 0.664316, acc.: 60.16%] [G loss: 0.836501]\n",
      "epoch:7 step:6970 [D loss: 0.655405, acc.: 62.50%] [G loss: 0.817640]\n",
      "epoch:7 step:6971 [D loss: 0.656805, acc.: 59.38%] [G loss: 0.843807]\n",
      "epoch:7 step:6972 [D loss: 0.653898, acc.: 60.94%] [G loss: 0.845755]\n",
      "epoch:7 step:6973 [D loss: 0.675196, acc.: 63.28%] [G loss: 0.875185]\n",
      "epoch:7 step:6974 [D loss: 0.676618, acc.: 58.59%] [G loss: 0.814885]\n",
      "epoch:7 step:6975 [D loss: 0.670021, acc.: 60.16%] [G loss: 0.807837]\n",
      "epoch:7 step:6976 [D loss: 0.615411, acc.: 65.62%] [G loss: 0.848886]\n",
      "epoch:7 step:6977 [D loss: 0.700547, acc.: 46.88%] [G loss: 0.835634]\n",
      "epoch:7 step:6978 [D loss: 0.652034, acc.: 61.72%] [G loss: 0.840476]\n",
      "epoch:7 step:6979 [D loss: 0.656631, acc.: 62.50%] [G loss: 0.795703]\n",
      "epoch:7 step:6980 [D loss: 0.677112, acc.: 57.03%] [G loss: 0.841006]\n",
      "epoch:7 step:6981 [D loss: 0.660049, acc.: 58.59%] [G loss: 0.860107]\n",
      "epoch:7 step:6982 [D loss: 0.673815, acc.: 57.03%] [G loss: 0.825103]\n",
      "epoch:7 step:6983 [D loss: 0.676886, acc.: 57.81%] [G loss: 0.842561]\n",
      "epoch:7 step:6984 [D loss: 0.724772, acc.: 49.22%] [G loss: 0.862497]\n",
      "epoch:7 step:6985 [D loss: 0.669541, acc.: 53.91%] [G loss: 0.870583]\n",
      "epoch:7 step:6986 [D loss: 0.683180, acc.: 56.25%] [G loss: 0.849043]\n",
      "epoch:7 step:6987 [D loss: 0.711787, acc.: 54.69%] [G loss: 0.853293]\n",
      "epoch:7 step:6988 [D loss: 0.678326, acc.: 56.25%] [G loss: 0.886033]\n",
      "epoch:7 step:6989 [D loss: 0.678529, acc.: 62.50%] [G loss: 0.867727]\n",
      "epoch:7 step:6990 [D loss: 0.653700, acc.: 63.28%] [G loss: 0.904200]\n",
      "epoch:7 step:6991 [D loss: 0.645674, acc.: 60.94%] [G loss: 0.884072]\n",
      "epoch:7 step:6992 [D loss: 0.643641, acc.: 66.41%] [G loss: 0.871614]\n",
      "epoch:7 step:6993 [D loss: 0.666631, acc.: 57.81%] [G loss: 0.846082]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:6994 [D loss: 0.673058, acc.: 55.47%] [G loss: 0.871626]\n",
      "epoch:7 step:6995 [D loss: 0.699780, acc.: 54.69%] [G loss: 0.851061]\n",
      "epoch:7 step:6996 [D loss: 0.656072, acc.: 60.16%] [G loss: 0.859418]\n",
      "epoch:7 step:6997 [D loss: 0.678154, acc.: 53.12%] [G loss: 0.922857]\n",
      "epoch:7 step:6998 [D loss: 0.695784, acc.: 57.03%] [G loss: 0.894097]\n",
      "epoch:7 step:6999 [D loss: 0.692067, acc.: 53.12%] [G loss: 0.890661]\n",
      "epoch:7 step:7000 [D loss: 0.669392, acc.: 61.72%] [G loss: 0.874134]\n",
      "##############\n",
      "[3.02250158 2.53512097 2.61446284 4.22741269 1.8373187  8.14211036\n",
      " 3.11808249 3.95326173 4.24104416 8.14868929]\n",
      "##########\n",
      "epoch:7 step:7001 [D loss: 0.697925, acc.: 51.56%] [G loss: 0.847915]\n",
      "epoch:7 step:7002 [D loss: 0.684075, acc.: 57.81%] [G loss: 0.831800]\n",
      "epoch:7 step:7003 [D loss: 0.692673, acc.: 55.47%] [G loss: 0.869289]\n",
      "epoch:7 step:7004 [D loss: 0.646985, acc.: 66.41%] [G loss: 0.820050]\n",
      "epoch:7 step:7005 [D loss: 0.694789, acc.: 50.78%] [G loss: 0.841126]\n",
      "epoch:7 step:7006 [D loss: 0.657530, acc.: 63.28%] [G loss: 0.821078]\n",
      "epoch:7 step:7007 [D loss: 0.702179, acc.: 52.34%] [G loss: 0.838424]\n",
      "epoch:7 step:7008 [D loss: 0.677495, acc.: 53.91%] [G loss: 0.829350]\n",
      "epoch:7 step:7009 [D loss: 0.673796, acc.: 57.81%] [G loss: 0.834507]\n",
      "epoch:7 step:7010 [D loss: 0.689710, acc.: 56.25%] [G loss: 0.834544]\n",
      "epoch:7 step:7011 [D loss: 0.682799, acc.: 53.12%] [G loss: 0.857231]\n",
      "epoch:7 step:7012 [D loss: 0.650257, acc.: 58.59%] [G loss: 0.843747]\n",
      "epoch:7 step:7013 [D loss: 0.679098, acc.: 57.03%] [G loss: 0.890658]\n",
      "epoch:7 step:7014 [D loss: 0.669025, acc.: 60.16%] [G loss: 0.819144]\n",
      "epoch:7 step:7015 [D loss: 0.683630, acc.: 58.59%] [G loss: 0.822373]\n",
      "epoch:7 step:7016 [D loss: 0.643288, acc.: 62.50%] [G loss: 0.865160]\n",
      "epoch:7 step:7017 [D loss: 0.694018, acc.: 55.47%] [G loss: 0.867626]\n",
      "epoch:7 step:7018 [D loss: 0.640469, acc.: 61.72%] [G loss: 0.871908]\n",
      "epoch:7 step:7019 [D loss: 0.637660, acc.: 59.38%] [G loss: 0.873252]\n",
      "epoch:7 step:7020 [D loss: 0.698471, acc.: 55.47%] [G loss: 0.846625]\n",
      "epoch:7 step:7021 [D loss: 0.659362, acc.: 57.81%] [G loss: 0.862600]\n",
      "epoch:7 step:7022 [D loss: 0.702847, acc.: 47.66%] [G loss: 0.898276]\n",
      "epoch:7 step:7023 [D loss: 0.674905, acc.: 56.25%] [G loss: 0.815908]\n",
      "epoch:7 step:7024 [D loss: 0.674721, acc.: 57.03%] [G loss: 0.853577]\n",
      "epoch:7 step:7025 [D loss: 0.650972, acc.: 65.62%] [G loss: 0.836284]\n",
      "epoch:7 step:7026 [D loss: 0.650422, acc.: 60.16%] [G loss: 0.841299]\n",
      "epoch:7 step:7027 [D loss: 0.651816, acc.: 64.06%] [G loss: 0.901900]\n",
      "epoch:7 step:7028 [D loss: 0.644513, acc.: 60.94%] [G loss: 0.861778]\n",
      "epoch:7 step:7029 [D loss: 0.712825, acc.: 47.66%] [G loss: 0.829295]\n",
      "epoch:7 step:7030 [D loss: 0.647001, acc.: 58.59%] [G loss: 0.780986]\n",
      "epoch:7 step:7031 [D loss: 0.671575, acc.: 56.25%] [G loss: 0.822903]\n",
      "epoch:7 step:7032 [D loss: 0.665984, acc.: 57.03%] [G loss: 0.837201]\n",
      "epoch:7 step:7033 [D loss: 0.639457, acc.: 61.72%] [G loss: 0.817026]\n",
      "epoch:7 step:7034 [D loss: 0.651334, acc.: 64.06%] [G loss: 0.860772]\n",
      "epoch:7 step:7035 [D loss: 0.662948, acc.: 62.50%] [G loss: 0.867171]\n",
      "epoch:7 step:7036 [D loss: 0.685656, acc.: 54.69%] [G loss: 0.864105]\n",
      "epoch:7 step:7037 [D loss: 0.658847, acc.: 64.84%] [G loss: 0.872563]\n",
      "epoch:7 step:7038 [D loss: 0.688528, acc.: 54.69%] [G loss: 0.864425]\n",
      "epoch:7 step:7039 [D loss: 0.665610, acc.: 58.59%] [G loss: 0.860493]\n",
      "epoch:7 step:7040 [D loss: 0.652094, acc.: 60.94%] [G loss: 0.863510]\n",
      "epoch:7 step:7041 [D loss: 0.663096, acc.: 58.59%] [G loss: 0.900524]\n",
      "epoch:7 step:7042 [D loss: 0.710501, acc.: 47.66%] [G loss: 0.860708]\n",
      "epoch:7 step:7043 [D loss: 0.641681, acc.: 62.50%] [G loss: 0.832330]\n",
      "epoch:7 step:7044 [D loss: 0.645180, acc.: 64.06%] [G loss: 0.819798]\n",
      "epoch:7 step:7045 [D loss: 0.620812, acc.: 66.41%] [G loss: 0.821771]\n",
      "epoch:7 step:7046 [D loss: 0.686604, acc.: 53.12%] [G loss: 0.791246]\n",
      "epoch:7 step:7047 [D loss: 0.623089, acc.: 68.75%] [G loss: 0.833996]\n",
      "epoch:7 step:7048 [D loss: 0.669463, acc.: 58.59%] [G loss: 0.801039]\n",
      "epoch:7 step:7049 [D loss: 0.668379, acc.: 62.50%] [G loss: 0.825690]\n",
      "epoch:7 step:7050 [D loss: 0.622477, acc.: 65.62%] [G loss: 0.844289]\n",
      "epoch:7 step:7051 [D loss: 0.659017, acc.: 62.50%] [G loss: 0.840085]\n",
      "epoch:7 step:7052 [D loss: 0.672611, acc.: 58.59%] [G loss: 0.865529]\n",
      "epoch:7 step:7053 [D loss: 0.609316, acc.: 70.31%] [G loss: 0.898659]\n",
      "epoch:7 step:7054 [D loss: 0.666515, acc.: 57.03%] [G loss: 0.870469]\n",
      "epoch:7 step:7055 [D loss: 0.662384, acc.: 60.94%] [G loss: 0.874681]\n",
      "epoch:7 step:7056 [D loss: 0.644437, acc.: 60.94%] [G loss: 0.882969]\n",
      "epoch:7 step:7057 [D loss: 0.658137, acc.: 63.28%] [G loss: 0.870088]\n",
      "epoch:7 step:7058 [D loss: 0.678310, acc.: 56.25%] [G loss: 0.910865]\n",
      "epoch:7 step:7059 [D loss: 0.693803, acc.: 57.81%] [G loss: 0.849784]\n",
      "epoch:7 step:7060 [D loss: 0.660831, acc.: 60.94%] [G loss: 0.860214]\n",
      "epoch:7 step:7061 [D loss: 0.662975, acc.: 58.59%] [G loss: 0.874961]\n",
      "epoch:7 step:7062 [D loss: 0.661523, acc.: 61.72%] [G loss: 0.846943]\n",
      "epoch:7 step:7063 [D loss: 0.668738, acc.: 60.94%] [G loss: 0.817818]\n",
      "epoch:7 step:7064 [D loss: 0.668790, acc.: 59.38%] [G loss: 0.852284]\n",
      "epoch:7 step:7065 [D loss: 0.659552, acc.: 65.62%] [G loss: 0.846174]\n",
      "epoch:7 step:7066 [D loss: 0.651933, acc.: 59.38%] [G loss: 0.873734]\n",
      "epoch:7 step:7067 [D loss: 0.645386, acc.: 63.28%] [G loss: 0.853200]\n",
      "epoch:7 step:7068 [D loss: 0.664468, acc.: 60.16%] [G loss: 0.891178]\n",
      "epoch:7 step:7069 [D loss: 0.649798, acc.: 57.81%] [G loss: 0.874850]\n",
      "epoch:7 step:7070 [D loss: 0.660666, acc.: 60.16%] [G loss: 0.839556]\n",
      "epoch:7 step:7071 [D loss: 0.678261, acc.: 51.56%] [G loss: 0.891385]\n",
      "epoch:7 step:7072 [D loss: 0.666790, acc.: 54.69%] [G loss: 0.864606]\n",
      "epoch:7 step:7073 [D loss: 0.688346, acc.: 58.59%] [G loss: 0.856450]\n",
      "epoch:7 step:7074 [D loss: 0.660128, acc.: 60.94%] [G loss: 0.865855]\n",
      "epoch:7 step:7075 [D loss: 0.645995, acc.: 60.16%] [G loss: 0.852985]\n",
      "epoch:7 step:7076 [D loss: 0.663861, acc.: 58.59%] [G loss: 0.800546]\n",
      "epoch:7 step:7077 [D loss: 0.652865, acc.: 59.38%] [G loss: 0.865230]\n",
      "epoch:7 step:7078 [D loss: 0.635628, acc.: 70.31%] [G loss: 0.840002]\n",
      "epoch:7 step:7079 [D loss: 0.668097, acc.: 64.84%] [G loss: 0.863739]\n",
      "epoch:7 step:7080 [D loss: 0.694857, acc.: 52.34%] [G loss: 0.832934]\n",
      "epoch:7 step:7081 [D loss: 0.650540, acc.: 60.94%] [G loss: 0.907961]\n",
      "epoch:7 step:7082 [D loss: 0.672315, acc.: 58.59%] [G loss: 0.874619]\n",
      "epoch:7 step:7083 [D loss: 0.688535, acc.: 54.69%] [G loss: 0.862626]\n",
      "epoch:7 step:7084 [D loss: 0.674518, acc.: 52.34%] [G loss: 0.879350]\n",
      "epoch:7 step:7085 [D loss: 0.658424, acc.: 61.72%] [G loss: 0.832017]\n",
      "epoch:7 step:7086 [D loss: 0.715076, acc.: 53.91%] [G loss: 0.873219]\n",
      "epoch:7 step:7087 [D loss: 0.696335, acc.: 56.25%] [G loss: 0.882050]\n",
      "epoch:7 step:7088 [D loss: 0.663094, acc.: 56.25%] [G loss: 0.831804]\n",
      "epoch:7 step:7089 [D loss: 0.643375, acc.: 63.28%] [G loss: 0.863760]\n",
      "epoch:7 step:7090 [D loss: 0.700624, acc.: 57.81%] [G loss: 0.848845]\n",
      "epoch:7 step:7091 [D loss: 0.666588, acc.: 57.81%] [G loss: 0.893794]\n",
      "epoch:7 step:7092 [D loss: 0.698173, acc.: 53.12%] [G loss: 0.849299]\n",
      "epoch:7 step:7093 [D loss: 0.668808, acc.: 59.38%] [G loss: 0.816383]\n",
      "epoch:7 step:7094 [D loss: 0.689006, acc.: 57.81%] [G loss: 0.812958]\n",
      "epoch:7 step:7095 [D loss: 0.672937, acc.: 59.38%] [G loss: 0.838700]\n",
      "epoch:7 step:7096 [D loss: 0.646547, acc.: 61.72%] [G loss: 0.849831]\n",
      "epoch:7 step:7097 [D loss: 0.698362, acc.: 50.78%] [G loss: 0.830395]\n",
      "epoch:7 step:7098 [D loss: 0.657134, acc.: 53.91%] [G loss: 0.872103]\n",
      "epoch:7 step:7099 [D loss: 0.655937, acc.: 63.28%] [G loss: 0.843193]\n",
      "epoch:7 step:7100 [D loss: 0.653571, acc.: 57.81%] [G loss: 0.841645]\n",
      "epoch:7 step:7101 [D loss: 0.692705, acc.: 55.47%] [G loss: 0.854501]\n",
      "epoch:7 step:7102 [D loss: 0.691477, acc.: 56.25%] [G loss: 0.833248]\n",
      "epoch:7 step:7103 [D loss: 0.644963, acc.: 65.62%] [G loss: 0.830382]\n",
      "epoch:7 step:7104 [D loss: 0.689688, acc.: 54.69%] [G loss: 0.826366]\n",
      "epoch:7 step:7105 [D loss: 0.645227, acc.: 62.50%] [G loss: 0.878471]\n",
      "epoch:7 step:7106 [D loss: 0.667039, acc.: 57.81%] [G loss: 0.866282]\n",
      "epoch:7 step:7107 [D loss: 0.685087, acc.: 58.59%] [G loss: 0.829648]\n",
      "epoch:7 step:7108 [D loss: 0.673826, acc.: 62.50%] [G loss: 0.844896]\n",
      "epoch:7 step:7109 [D loss: 0.634947, acc.: 64.06%] [G loss: 0.837443]\n",
      "epoch:7 step:7110 [D loss: 0.676344, acc.: 62.50%] [G loss: 0.787711]\n",
      "epoch:7 step:7111 [D loss: 0.654617, acc.: 62.50%] [G loss: 0.874815]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7112 [D loss: 0.715729, acc.: 54.69%] [G loss: 0.819747]\n",
      "epoch:7 step:7113 [D loss: 0.629977, acc.: 61.72%] [G loss: 0.852670]\n",
      "epoch:7 step:7114 [D loss: 0.669470, acc.: 61.72%] [G loss: 0.856069]\n",
      "epoch:7 step:7115 [D loss: 0.644522, acc.: 62.50%] [G loss: 0.860730]\n",
      "epoch:7 step:7116 [D loss: 0.658174, acc.: 60.16%] [G loss: 0.819623]\n",
      "epoch:7 step:7117 [D loss: 0.674883, acc.: 57.81%] [G loss: 0.843849]\n",
      "epoch:7 step:7118 [D loss: 0.675386, acc.: 57.81%] [G loss: 0.830259]\n",
      "epoch:7 step:7119 [D loss: 0.678347, acc.: 58.59%] [G loss: 0.792960]\n",
      "epoch:7 step:7120 [D loss: 0.647648, acc.: 61.72%] [G loss: 0.772648]\n",
      "epoch:7 step:7121 [D loss: 0.670424, acc.: 59.38%] [G loss: 0.810970]\n",
      "epoch:7 step:7122 [D loss: 0.641993, acc.: 60.94%] [G loss: 0.869895]\n",
      "epoch:7 step:7123 [D loss: 0.653645, acc.: 69.53%] [G loss: 0.803433]\n",
      "epoch:7 step:7124 [D loss: 0.680830, acc.: 60.94%] [G loss: 0.856267]\n",
      "epoch:7 step:7125 [D loss: 0.618541, acc.: 70.31%] [G loss: 0.792007]\n",
      "epoch:7 step:7126 [D loss: 0.679826, acc.: 57.03%] [G loss: 0.881818]\n",
      "epoch:7 step:7127 [D loss: 0.704899, acc.: 57.81%] [G loss: 0.842269]\n",
      "epoch:7 step:7128 [D loss: 0.639191, acc.: 60.94%] [G loss: 0.879981]\n",
      "epoch:7 step:7129 [D loss: 0.690120, acc.: 53.12%] [G loss: 0.850638]\n",
      "epoch:7 step:7130 [D loss: 0.646213, acc.: 63.28%] [G loss: 0.878231]\n",
      "epoch:7 step:7131 [D loss: 0.673960, acc.: 60.16%] [G loss: 0.861064]\n",
      "epoch:7 step:7132 [D loss: 0.707461, acc.: 52.34%] [G loss: 0.865926]\n",
      "epoch:7 step:7133 [D loss: 0.632222, acc.: 60.16%] [G loss: 0.813744]\n",
      "epoch:7 step:7134 [D loss: 0.674528, acc.: 54.69%] [G loss: 0.857879]\n",
      "epoch:7 step:7135 [D loss: 0.678338, acc.: 60.16%] [G loss: 0.826143]\n",
      "epoch:7 step:7136 [D loss: 0.643153, acc.: 63.28%] [G loss: 0.856181]\n",
      "epoch:7 step:7137 [D loss: 0.678814, acc.: 55.47%] [G loss: 0.892691]\n",
      "epoch:7 step:7138 [D loss: 0.697320, acc.: 53.12%] [G loss: 0.863531]\n",
      "epoch:7 step:7139 [D loss: 0.683988, acc.: 50.78%] [G loss: 0.864322]\n",
      "epoch:7 step:7140 [D loss: 0.694235, acc.: 53.12%] [G loss: 0.839573]\n",
      "epoch:7 step:7141 [D loss: 0.659061, acc.: 66.41%] [G loss: 0.879808]\n",
      "epoch:7 step:7142 [D loss: 0.697986, acc.: 53.91%] [G loss: 0.869425]\n",
      "epoch:7 step:7143 [D loss: 0.673846, acc.: 57.03%] [G loss: 0.924236]\n",
      "epoch:7 step:7144 [D loss: 0.628617, acc.: 62.50%] [G loss: 0.949208]\n",
      "epoch:7 step:7145 [D loss: 0.680209, acc.: 57.03%] [G loss: 0.926840]\n",
      "epoch:7 step:7146 [D loss: 0.653984, acc.: 63.28%] [G loss: 0.922641]\n",
      "epoch:7 step:7147 [D loss: 0.644279, acc.: 64.06%] [G loss: 0.894506]\n",
      "epoch:7 step:7148 [D loss: 0.610881, acc.: 69.53%] [G loss: 0.887287]\n",
      "epoch:7 step:7149 [D loss: 0.650324, acc.: 65.62%] [G loss: 0.860871]\n",
      "epoch:7 step:7150 [D loss: 0.655454, acc.: 62.50%] [G loss: 0.836928]\n",
      "epoch:7 step:7151 [D loss: 0.630786, acc.: 67.97%] [G loss: 0.850492]\n",
      "epoch:7 step:7152 [D loss: 0.683277, acc.: 53.12%] [G loss: 0.800699]\n",
      "epoch:7 step:7153 [D loss: 0.653499, acc.: 62.50%] [G loss: 0.849899]\n",
      "epoch:7 step:7154 [D loss: 0.625819, acc.: 67.19%] [G loss: 0.841468]\n",
      "epoch:7 step:7155 [D loss: 0.672060, acc.: 62.50%] [G loss: 0.832969]\n",
      "epoch:7 step:7156 [D loss: 0.678444, acc.: 58.59%] [G loss: 0.841632]\n",
      "epoch:7 step:7157 [D loss: 0.684582, acc.: 53.12%] [G loss: 0.825843]\n",
      "epoch:7 step:7158 [D loss: 0.661422, acc.: 60.16%] [G loss: 0.873013]\n",
      "epoch:7 step:7159 [D loss: 0.666514, acc.: 55.47%] [G loss: 0.899511]\n",
      "epoch:7 step:7160 [D loss: 0.704142, acc.: 55.47%] [G loss: 0.857776]\n",
      "epoch:7 step:7161 [D loss: 0.635740, acc.: 65.62%] [G loss: 0.842064]\n",
      "epoch:7 step:7162 [D loss: 0.688505, acc.: 53.91%] [G loss: 0.865659]\n",
      "epoch:7 step:7163 [D loss: 0.698896, acc.: 57.81%] [G loss: 0.798719]\n",
      "epoch:7 step:7164 [D loss: 0.665457, acc.: 57.81%] [G loss: 0.846709]\n",
      "epoch:7 step:7165 [D loss: 0.677851, acc.: 59.38%] [G loss: 0.809715]\n",
      "epoch:7 step:7166 [D loss: 0.689909, acc.: 49.22%] [G loss: 0.826478]\n",
      "epoch:7 step:7167 [D loss: 0.680338, acc.: 57.03%] [G loss: 0.803463]\n",
      "epoch:7 step:7168 [D loss: 0.658775, acc.: 64.06%] [G loss: 0.853659]\n",
      "epoch:7 step:7169 [D loss: 0.659554, acc.: 57.03%] [G loss: 0.799272]\n",
      "epoch:7 step:7170 [D loss: 0.658206, acc.: 56.25%] [G loss: 0.805406]\n",
      "epoch:7 step:7171 [D loss: 0.680658, acc.: 55.47%] [G loss: 0.775718]\n",
      "epoch:7 step:7172 [D loss: 0.645978, acc.: 60.16%] [G loss: 0.870347]\n",
      "epoch:7 step:7173 [D loss: 0.692316, acc.: 50.78%] [G loss: 0.816215]\n",
      "epoch:7 step:7174 [D loss: 0.678396, acc.: 61.72%] [G loss: 0.811542]\n",
      "epoch:7 step:7175 [D loss: 0.628656, acc.: 64.06%] [G loss: 0.845891]\n",
      "epoch:7 step:7176 [D loss: 0.672743, acc.: 61.72%] [G loss: 0.874194]\n",
      "epoch:7 step:7177 [D loss: 0.650920, acc.: 65.62%] [G loss: 0.827240]\n",
      "epoch:7 step:7178 [D loss: 0.705944, acc.: 52.34%] [G loss: 0.819286]\n",
      "epoch:7 step:7179 [D loss: 0.622577, acc.: 63.28%] [G loss: 0.764701]\n",
      "epoch:7 step:7180 [D loss: 0.658962, acc.: 57.03%] [G loss: 0.794688]\n",
      "epoch:7 step:7181 [D loss: 0.694075, acc.: 53.91%] [G loss: 0.816206]\n",
      "epoch:7 step:7182 [D loss: 0.653027, acc.: 64.06%] [G loss: 0.855842]\n",
      "epoch:7 step:7183 [D loss: 0.664969, acc.: 55.47%] [G loss: 0.871285]\n",
      "epoch:7 step:7184 [D loss: 0.667193, acc.: 55.47%] [G loss: 0.855318]\n",
      "epoch:7 step:7185 [D loss: 0.706074, acc.: 49.22%] [G loss: 0.826221]\n",
      "epoch:7 step:7186 [D loss: 0.655960, acc.: 63.28%] [G loss: 0.876563]\n",
      "epoch:7 step:7187 [D loss: 0.686927, acc.: 53.12%] [G loss: 0.865141]\n",
      "epoch:7 step:7188 [D loss: 0.706965, acc.: 48.44%] [G loss: 0.789961]\n",
      "epoch:7 step:7189 [D loss: 0.666706, acc.: 62.50%] [G loss: 0.835931]\n",
      "epoch:7 step:7190 [D loss: 0.689309, acc.: 57.03%] [G loss: 0.831825]\n",
      "epoch:7 step:7191 [D loss: 0.638448, acc.: 67.97%] [G loss: 0.825197]\n",
      "epoch:7 step:7192 [D loss: 0.685342, acc.: 57.81%] [G loss: 0.902201]\n",
      "epoch:7 step:7193 [D loss: 0.676693, acc.: 52.34%] [G loss: 0.910292]\n",
      "epoch:7 step:7194 [D loss: 0.673474, acc.: 57.03%] [G loss: 0.920114]\n",
      "epoch:7 step:7195 [D loss: 0.682838, acc.: 55.47%] [G loss: 0.814300]\n",
      "epoch:7 step:7196 [D loss: 0.625210, acc.: 66.41%] [G loss: 0.834917]\n",
      "epoch:7 step:7197 [D loss: 0.655146, acc.: 60.16%] [G loss: 0.855121]\n",
      "epoch:7 step:7198 [D loss: 0.651622, acc.: 61.72%] [G loss: 0.863122]\n",
      "epoch:7 step:7199 [D loss: 0.708257, acc.: 50.00%] [G loss: 0.845067]\n",
      "epoch:7 step:7200 [D loss: 0.660488, acc.: 57.81%] [G loss: 0.832110]\n",
      "##############\n",
      "[ 3.01411782  2.61905324  2.47006195  4.09077726  1.3884093  10.27426719\n",
      "  2.99036853  4.78290132  4.27196071  8.14868929]\n",
      "##########\n",
      "epoch:7 step:7201 [D loss: 0.678483, acc.: 56.25%] [G loss: 0.833031]\n",
      "epoch:7 step:7202 [D loss: 0.699614, acc.: 51.56%] [G loss: 0.852094]\n",
      "epoch:7 step:7203 [D loss: 0.649562, acc.: 60.94%] [G loss: 0.873998]\n",
      "epoch:7 step:7204 [D loss: 0.696141, acc.: 48.44%] [G loss: 0.844353]\n",
      "epoch:7 step:7205 [D loss: 0.656620, acc.: 61.72%] [G loss: 0.884864]\n",
      "epoch:7 step:7206 [D loss: 0.643775, acc.: 62.50%] [G loss: 0.862550]\n",
      "epoch:7 step:7207 [D loss: 0.658774, acc.: 57.81%] [G loss: 0.852948]\n",
      "epoch:7 step:7208 [D loss: 0.685118, acc.: 55.47%] [G loss: 0.863361]\n",
      "epoch:7 step:7209 [D loss: 0.668586, acc.: 60.16%] [G loss: 0.801292]\n",
      "epoch:7 step:7210 [D loss: 0.678123, acc.: 58.59%] [G loss: 0.821331]\n",
      "epoch:7 step:7211 [D loss: 0.658608, acc.: 62.50%] [G loss: 0.781642]\n",
      "epoch:7 step:7212 [D loss: 0.691550, acc.: 51.56%] [G loss: 0.855560]\n",
      "epoch:7 step:7213 [D loss: 0.661196, acc.: 57.81%] [G loss: 0.884136]\n",
      "epoch:7 step:7214 [D loss: 0.664810, acc.: 60.16%] [G loss: 0.841928]\n",
      "epoch:7 step:7215 [D loss: 0.650038, acc.: 63.28%] [G loss: 0.843769]\n",
      "epoch:7 step:7216 [D loss: 0.710321, acc.: 52.34%] [G loss: 0.810376]\n",
      "epoch:7 step:7217 [D loss: 0.663573, acc.: 60.94%] [G loss: 0.899321]\n",
      "epoch:7 step:7218 [D loss: 0.664726, acc.: 59.38%] [G loss: 0.848528]\n",
      "epoch:7 step:7219 [D loss: 0.684096, acc.: 50.00%] [G loss: 0.843055]\n",
      "epoch:7 step:7220 [D loss: 0.657392, acc.: 57.81%] [G loss: 0.918401]\n",
      "epoch:7 step:7221 [D loss: 0.683076, acc.: 58.59%] [G loss: 0.864175]\n",
      "epoch:7 step:7222 [D loss: 0.626043, acc.: 65.62%] [G loss: 0.854129]\n",
      "epoch:7 step:7223 [D loss: 0.660997, acc.: 65.62%] [G loss: 0.837508]\n",
      "epoch:7 step:7224 [D loss: 0.721851, acc.: 47.66%] [G loss: 0.850745]\n",
      "epoch:7 step:7225 [D loss: 0.641926, acc.: 68.75%] [G loss: 0.849553]\n",
      "epoch:7 step:7226 [D loss: 0.676451, acc.: 53.12%] [G loss: 0.875210]\n",
      "epoch:7 step:7227 [D loss: 0.664588, acc.: 60.94%] [G loss: 0.852654]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7228 [D loss: 0.627020, acc.: 67.97%] [G loss: 0.841551]\n",
      "epoch:7 step:7229 [D loss: 0.651819, acc.: 64.06%] [G loss: 0.836774]\n",
      "epoch:7 step:7230 [D loss: 0.654584, acc.: 57.81%] [G loss: 0.853831]\n",
      "epoch:7 step:7231 [D loss: 0.689161, acc.: 50.78%] [G loss: 0.872744]\n",
      "epoch:7 step:7232 [D loss: 0.666130, acc.: 58.59%] [G loss: 0.844719]\n",
      "epoch:7 step:7233 [D loss: 0.691449, acc.: 58.59%] [G loss: 0.862106]\n",
      "epoch:7 step:7234 [D loss: 0.670856, acc.: 61.72%] [G loss: 0.907967]\n",
      "epoch:7 step:7235 [D loss: 0.659585, acc.: 62.50%] [G loss: 0.842428]\n",
      "epoch:7 step:7236 [D loss: 0.688557, acc.: 54.69%] [G loss: 0.836466]\n",
      "epoch:7 step:7237 [D loss: 0.664793, acc.: 61.72%] [G loss: 0.818641]\n",
      "epoch:7 step:7238 [D loss: 0.642634, acc.: 61.72%] [G loss: 0.850759]\n",
      "epoch:7 step:7239 [D loss: 0.673549, acc.: 52.34%] [G loss: 0.829298]\n",
      "epoch:7 step:7240 [D loss: 0.647046, acc.: 60.16%] [G loss: 0.854653]\n",
      "epoch:7 step:7241 [D loss: 0.641673, acc.: 60.16%] [G loss: 0.825689]\n",
      "epoch:7 step:7242 [D loss: 0.612397, acc.: 72.66%] [G loss: 0.827768]\n",
      "epoch:7 step:7243 [D loss: 0.699473, acc.: 50.78%] [G loss: 0.797993]\n",
      "epoch:7 step:7244 [D loss: 0.681746, acc.: 59.38%] [G loss: 0.863651]\n",
      "epoch:7 step:7245 [D loss: 0.669793, acc.: 53.91%] [G loss: 0.866216]\n",
      "epoch:7 step:7246 [D loss: 0.662702, acc.: 59.38%] [G loss: 0.852670]\n",
      "epoch:7 step:7247 [D loss: 0.635494, acc.: 66.41%] [G loss: 0.869127]\n",
      "epoch:7 step:7248 [D loss: 0.697914, acc.: 51.56%] [G loss: 0.881754]\n",
      "epoch:7 step:7249 [D loss: 0.649074, acc.: 64.06%] [G loss: 0.901535]\n",
      "epoch:7 step:7250 [D loss: 0.670285, acc.: 55.47%] [G loss: 0.857281]\n",
      "epoch:7 step:7251 [D loss: 0.675674, acc.: 53.91%] [G loss: 0.845605]\n",
      "epoch:7 step:7252 [D loss: 0.626351, acc.: 67.97%] [G loss: 0.852841]\n",
      "epoch:7 step:7253 [D loss: 0.640472, acc.: 61.72%] [G loss: 0.845633]\n",
      "epoch:7 step:7254 [D loss: 0.630950, acc.: 64.84%] [G loss: 0.804472]\n",
      "epoch:7 step:7255 [D loss: 0.700929, acc.: 54.69%] [G loss: 0.830077]\n",
      "epoch:7 step:7256 [D loss: 0.659452, acc.: 58.59%] [G loss: 0.880558]\n",
      "epoch:7 step:7257 [D loss: 0.654578, acc.: 60.94%] [G loss: 0.946729]\n",
      "epoch:7 step:7258 [D loss: 0.682318, acc.: 57.03%] [G loss: 0.903016]\n",
      "epoch:7 step:7259 [D loss: 0.647581, acc.: 62.50%] [G loss: 0.867350]\n",
      "epoch:7 step:7260 [D loss: 0.636812, acc.: 63.28%] [G loss: 0.926935]\n",
      "epoch:7 step:7261 [D loss: 0.658182, acc.: 57.03%] [G loss: 0.857566]\n",
      "epoch:7 step:7262 [D loss: 0.683683, acc.: 55.47%] [G loss: 0.879909]\n",
      "epoch:7 step:7263 [D loss: 0.669853, acc.: 64.84%] [G loss: 0.888124]\n",
      "epoch:7 step:7264 [D loss: 0.691997, acc.: 55.47%] [G loss: 0.891224]\n",
      "epoch:7 step:7265 [D loss: 0.713072, acc.: 50.78%] [G loss: 0.868026]\n",
      "epoch:7 step:7266 [D loss: 0.653545, acc.: 60.16%] [G loss: 0.839899]\n",
      "epoch:7 step:7267 [D loss: 0.672405, acc.: 58.59%] [G loss: 0.883990]\n",
      "epoch:7 step:7268 [D loss: 0.702649, acc.: 51.56%] [G loss: 0.914100]\n",
      "epoch:7 step:7269 [D loss: 0.674947, acc.: 60.16%] [G loss: 0.852191]\n",
      "epoch:7 step:7270 [D loss: 0.649537, acc.: 67.97%] [G loss: 0.860057]\n",
      "epoch:7 step:7271 [D loss: 0.651161, acc.: 64.06%] [G loss: 0.885958]\n",
      "epoch:7 step:7272 [D loss: 0.697412, acc.: 50.00%] [G loss: 0.872115]\n",
      "epoch:7 step:7273 [D loss: 0.627463, acc.: 67.97%] [G loss: 0.913253]\n",
      "epoch:7 step:7274 [D loss: 0.712765, acc.: 53.91%] [G loss: 0.832544]\n",
      "epoch:7 step:7275 [D loss: 0.706284, acc.: 51.56%] [G loss: 0.888426]\n",
      "epoch:7 step:7276 [D loss: 0.667694, acc.: 55.47%] [G loss: 0.846126]\n",
      "epoch:7 step:7277 [D loss: 0.669998, acc.: 53.12%] [G loss: 0.872392]\n",
      "epoch:7 step:7278 [D loss: 0.685058, acc.: 60.16%] [G loss: 0.837973]\n",
      "epoch:7 step:7279 [D loss: 0.673671, acc.: 52.34%] [G loss: 0.836266]\n",
      "epoch:7 step:7280 [D loss: 0.666413, acc.: 62.50%] [G loss: 0.835918]\n",
      "epoch:7 step:7281 [D loss: 0.659385, acc.: 59.38%] [G loss: 0.812391]\n",
      "epoch:7 step:7282 [D loss: 0.667066, acc.: 57.81%] [G loss: 0.856893]\n",
      "epoch:7 step:7283 [D loss: 0.689873, acc.: 49.22%] [G loss: 0.846590]\n",
      "epoch:7 step:7284 [D loss: 0.649585, acc.: 64.06%] [G loss: 0.869389]\n",
      "epoch:7 step:7285 [D loss: 0.685251, acc.: 51.56%] [G loss: 0.817161]\n",
      "epoch:7 step:7286 [D loss: 0.648365, acc.: 60.16%] [G loss: 0.877767]\n",
      "epoch:7 step:7287 [D loss: 0.633912, acc.: 62.50%] [G loss: 0.845708]\n",
      "epoch:7 step:7288 [D loss: 0.690709, acc.: 56.25%] [G loss: 0.867926]\n",
      "epoch:7 step:7289 [D loss: 0.684801, acc.: 54.69%] [G loss: 0.892616]\n",
      "epoch:7 step:7290 [D loss: 0.700411, acc.: 48.44%] [G loss: 0.907920]\n",
      "epoch:7 step:7291 [D loss: 0.656590, acc.: 57.03%] [G loss: 0.832256]\n",
      "epoch:7 step:7292 [D loss: 0.664870, acc.: 61.72%] [G loss: 0.833170]\n",
      "epoch:7 step:7293 [D loss: 0.627904, acc.: 67.19%] [G loss: 0.854606]\n",
      "epoch:7 step:7294 [D loss: 0.684828, acc.: 55.47%] [G loss: 0.844017]\n",
      "epoch:7 step:7295 [D loss: 0.674652, acc.: 60.16%] [G loss: 0.863855]\n",
      "epoch:7 step:7296 [D loss: 0.680820, acc.: 55.47%] [G loss: 0.868094]\n",
      "epoch:7 step:7297 [D loss: 0.674674, acc.: 53.91%] [G loss: 0.803517]\n",
      "epoch:7 step:7298 [D loss: 0.652515, acc.: 57.81%] [G loss: 0.810564]\n",
      "epoch:7 step:7299 [D loss: 0.696660, acc.: 57.03%] [G loss: 0.787212]\n",
      "epoch:7 step:7300 [D loss: 0.689223, acc.: 48.44%] [G loss: 0.846107]\n",
      "epoch:7 step:7301 [D loss: 0.660317, acc.: 60.16%] [G loss: 0.861232]\n",
      "epoch:7 step:7302 [D loss: 0.674915, acc.: 53.12%] [G loss: 0.862849]\n",
      "epoch:7 step:7303 [D loss: 0.668772, acc.: 58.59%] [G loss: 0.830507]\n",
      "epoch:7 step:7304 [D loss: 0.720597, acc.: 54.69%] [G loss: 0.866464]\n",
      "epoch:7 step:7305 [D loss: 0.674901, acc.: 60.94%] [G loss: 0.863909]\n",
      "epoch:7 step:7306 [D loss: 0.678662, acc.: 58.59%] [G loss: 0.891431]\n",
      "epoch:7 step:7307 [D loss: 0.685889, acc.: 55.47%] [G loss: 0.831009]\n",
      "epoch:7 step:7308 [D loss: 0.686898, acc.: 57.03%] [G loss: 0.808030]\n",
      "epoch:7 step:7309 [D loss: 0.650012, acc.: 66.41%] [G loss: 0.857976]\n",
      "epoch:7 step:7310 [D loss: 0.633772, acc.: 68.75%] [G loss: 0.848050]\n",
      "epoch:7 step:7311 [D loss: 0.666045, acc.: 60.94%] [G loss: 0.880529]\n",
      "epoch:7 step:7312 [D loss: 0.643425, acc.: 64.84%] [G loss: 0.893048]\n",
      "epoch:7 step:7313 [D loss: 0.686723, acc.: 60.16%] [G loss: 0.872872]\n",
      "epoch:7 step:7314 [D loss: 0.669602, acc.: 55.47%] [G loss: 0.840217]\n",
      "epoch:7 step:7315 [D loss: 0.664986, acc.: 60.16%] [G loss: 0.855317]\n",
      "epoch:7 step:7316 [D loss: 0.642596, acc.: 65.62%] [G loss: 0.816380]\n",
      "epoch:7 step:7317 [D loss: 0.686696, acc.: 56.25%] [G loss: 0.812334]\n",
      "epoch:7 step:7318 [D loss: 0.643487, acc.: 65.62%] [G loss: 0.845715]\n",
      "epoch:7 step:7319 [D loss: 0.673494, acc.: 55.47%] [G loss: 0.878345]\n",
      "epoch:7 step:7320 [D loss: 0.715660, acc.: 50.00%] [G loss: 0.844846]\n",
      "epoch:7 step:7321 [D loss: 0.677229, acc.: 53.12%] [G loss: 0.832961]\n",
      "epoch:7 step:7322 [D loss: 0.662769, acc.: 57.81%] [G loss: 0.851286]\n",
      "epoch:7 step:7323 [D loss: 0.671471, acc.: 58.59%] [G loss: 0.825696]\n",
      "epoch:7 step:7324 [D loss: 0.715394, acc.: 52.34%] [G loss: 0.868384]\n",
      "epoch:7 step:7325 [D loss: 0.658361, acc.: 57.03%] [G loss: 0.848460]\n",
      "epoch:7 step:7326 [D loss: 0.685381, acc.: 49.22%] [G loss: 0.870618]\n",
      "epoch:7 step:7327 [D loss: 0.670808, acc.: 56.25%] [G loss: 0.899009]\n",
      "epoch:7 step:7328 [D loss: 0.645839, acc.: 63.28%] [G loss: 0.890888]\n",
      "epoch:7 step:7329 [D loss: 0.673045, acc.: 60.16%] [G loss: 0.844042]\n",
      "epoch:7 step:7330 [D loss: 0.648582, acc.: 67.97%] [G loss: 0.835977]\n",
      "epoch:7 step:7331 [D loss: 0.663628, acc.: 59.38%] [G loss: 0.832711]\n",
      "epoch:7 step:7332 [D loss: 0.658983, acc.: 59.38%] [G loss: 0.849769]\n",
      "epoch:7 step:7333 [D loss: 0.671203, acc.: 54.69%] [G loss: 0.829281]\n",
      "epoch:7 step:7334 [D loss: 0.658823, acc.: 58.59%] [G loss: 0.842653]\n",
      "epoch:7 step:7335 [D loss: 0.648538, acc.: 66.41%] [G loss: 0.880460]\n",
      "epoch:7 step:7336 [D loss: 0.691769, acc.: 60.16%] [G loss: 0.864843]\n",
      "epoch:7 step:7337 [D loss: 0.660009, acc.: 59.38%] [G loss: 0.900689]\n",
      "epoch:7 step:7338 [D loss: 0.680260, acc.: 55.47%] [G loss: 0.865177]\n",
      "epoch:7 step:7339 [D loss: 0.660312, acc.: 62.50%] [G loss: 0.830312]\n",
      "epoch:7 step:7340 [D loss: 0.731732, acc.: 41.41%] [G loss: 0.849791]\n",
      "epoch:7 step:7341 [D loss: 0.626033, acc.: 67.97%] [G loss: 0.873539]\n",
      "epoch:7 step:7342 [D loss: 0.681483, acc.: 53.91%] [G loss: 0.864972]\n",
      "epoch:7 step:7343 [D loss: 0.663412, acc.: 59.38%] [G loss: 0.864815]\n",
      "epoch:7 step:7344 [D loss: 0.674810, acc.: 57.03%] [G loss: 0.874052]\n",
      "epoch:7 step:7345 [D loss: 0.690698, acc.: 56.25%] [G loss: 0.932536]\n",
      "epoch:7 step:7346 [D loss: 0.663093, acc.: 53.91%] [G loss: 0.875258]\n",
      "epoch:7 step:7347 [D loss: 0.659735, acc.: 60.94%] [G loss: 0.826103]\n",
      "epoch:7 step:7348 [D loss: 0.667575, acc.: 55.47%] [G loss: 0.796325]\n",
      "epoch:7 step:7349 [D loss: 0.712998, acc.: 50.78%] [G loss: 0.860911]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7350 [D loss: 0.664998, acc.: 55.47%] [G loss: 0.827935]\n",
      "epoch:7 step:7351 [D loss: 0.660683, acc.: 57.81%] [G loss: 0.806378]\n",
      "epoch:7 step:7352 [D loss: 0.649936, acc.: 60.16%] [G loss: 0.867474]\n",
      "epoch:7 step:7353 [D loss: 0.650705, acc.: 63.28%] [G loss: 0.843486]\n",
      "epoch:7 step:7354 [D loss: 0.669230, acc.: 58.59%] [G loss: 0.899284]\n",
      "epoch:7 step:7355 [D loss: 0.668510, acc.: 55.47%] [G loss: 0.902221]\n",
      "epoch:7 step:7356 [D loss: 0.682808, acc.: 62.50%] [G loss: 0.881654]\n",
      "epoch:7 step:7357 [D loss: 0.660166, acc.: 61.72%] [G loss: 0.847690]\n",
      "epoch:7 step:7358 [D loss: 0.661942, acc.: 60.16%] [G loss: 0.825251]\n",
      "epoch:7 step:7359 [D loss: 0.673581, acc.: 58.59%] [G loss: 0.881206]\n",
      "epoch:7 step:7360 [D loss: 0.650438, acc.: 64.84%] [G loss: 0.843886]\n",
      "epoch:7 step:7361 [D loss: 0.682631, acc.: 55.47%] [G loss: 0.855562]\n",
      "epoch:7 step:7362 [D loss: 0.618688, acc.: 69.53%] [G loss: 0.890375]\n",
      "epoch:7 step:7363 [D loss: 0.688295, acc.: 54.69%] [G loss: 0.888119]\n",
      "epoch:7 step:7364 [D loss: 0.679005, acc.: 57.81%] [G loss: 0.822716]\n",
      "epoch:7 step:7365 [D loss: 0.637891, acc.: 66.41%] [G loss: 0.872240]\n",
      "epoch:7 step:7366 [D loss: 0.657416, acc.: 59.38%] [G loss: 0.848358]\n",
      "epoch:7 step:7367 [D loss: 0.673289, acc.: 57.81%] [G loss: 0.882833]\n",
      "epoch:7 step:7368 [D loss: 0.663083, acc.: 60.94%] [G loss: 0.805531]\n",
      "epoch:7 step:7369 [D loss: 0.652146, acc.: 64.06%] [G loss: 0.835093]\n",
      "epoch:7 step:7370 [D loss: 0.639975, acc.: 59.38%] [G loss: 0.841779]\n",
      "epoch:7 step:7371 [D loss: 0.661315, acc.: 60.16%] [G loss: 0.869694]\n",
      "epoch:7 step:7372 [D loss: 0.676228, acc.: 58.59%] [G loss: 0.865273]\n",
      "epoch:7 step:7373 [D loss: 0.657222, acc.: 62.50%] [G loss: 0.870519]\n",
      "epoch:7 step:7374 [D loss: 0.680749, acc.: 55.47%] [G loss: 0.870575]\n",
      "epoch:7 step:7375 [D loss: 0.654983, acc.: 57.03%] [G loss: 0.877518]\n",
      "epoch:7 step:7376 [D loss: 0.685027, acc.: 52.34%] [G loss: 0.862679]\n",
      "epoch:7 step:7377 [D loss: 0.700274, acc.: 51.56%] [G loss: 0.831616]\n",
      "epoch:7 step:7378 [D loss: 0.649791, acc.: 65.62%] [G loss: 0.870872]\n",
      "epoch:7 step:7379 [D loss: 0.664534, acc.: 64.84%] [G loss: 0.890173]\n",
      "epoch:7 step:7380 [D loss: 0.662379, acc.: 62.50%] [G loss: 0.851491]\n",
      "epoch:7 step:7381 [D loss: 0.656415, acc.: 64.84%] [G loss: 0.903916]\n",
      "epoch:7 step:7382 [D loss: 0.770936, acc.: 42.19%] [G loss: 0.841961]\n",
      "epoch:7 step:7383 [D loss: 0.677116, acc.: 55.47%] [G loss: 0.837537]\n",
      "epoch:7 step:7384 [D loss: 0.657814, acc.: 57.03%] [G loss: 0.812403]\n",
      "epoch:7 step:7385 [D loss: 0.648773, acc.: 62.50%] [G loss: 0.859316]\n",
      "epoch:7 step:7386 [D loss: 0.668929, acc.: 64.06%] [G loss: 0.837199]\n",
      "epoch:7 step:7387 [D loss: 0.708872, acc.: 54.69%] [G loss: 0.853672]\n",
      "epoch:7 step:7388 [D loss: 0.680574, acc.: 57.81%] [G loss: 0.826827]\n",
      "epoch:7 step:7389 [D loss: 0.659414, acc.: 58.59%] [G loss: 0.820888]\n",
      "epoch:7 step:7390 [D loss: 0.697060, acc.: 48.44%] [G loss: 0.816041]\n",
      "epoch:7 step:7391 [D loss: 0.676040, acc.: 50.78%] [G loss: 0.814757]\n",
      "epoch:7 step:7392 [D loss: 0.652747, acc.: 63.28%] [G loss: 0.820699]\n",
      "epoch:7 step:7393 [D loss: 0.690143, acc.: 57.81%] [G loss: 0.824780]\n",
      "epoch:7 step:7394 [D loss: 0.688294, acc.: 57.03%] [G loss: 0.890931]\n",
      "epoch:7 step:7395 [D loss: 0.694282, acc.: 53.91%] [G loss: 0.846186]\n",
      "epoch:7 step:7396 [D loss: 0.664614, acc.: 60.16%] [G loss: 0.875118]\n",
      "epoch:7 step:7397 [D loss: 0.658378, acc.: 60.94%] [G loss: 0.841523]\n",
      "epoch:7 step:7398 [D loss: 0.659059, acc.: 58.59%] [G loss: 0.860888]\n",
      "epoch:7 step:7399 [D loss: 0.637768, acc.: 62.50%] [G loss: 0.901746]\n",
      "epoch:7 step:7400 [D loss: 0.695501, acc.: 56.25%] [G loss: 0.830122]\n",
      "##############\n",
      "[3.09031813 2.43006159 2.19477773 3.98526851 1.12020085 8.12746406\n",
      " 3.4119117  4.15097701 4.33520723 8.14868929]\n",
      "##########\n",
      "epoch:7 step:7401 [D loss: 0.699293, acc.: 55.47%] [G loss: 0.817383]\n",
      "epoch:7 step:7402 [D loss: 0.712788, acc.: 53.12%] [G loss: 0.880052]\n",
      "epoch:7 step:7403 [D loss: 0.678029, acc.: 57.03%] [G loss: 0.869645]\n",
      "epoch:7 step:7404 [D loss: 0.658676, acc.: 64.06%] [G loss: 0.852848]\n",
      "epoch:7 step:7405 [D loss: 0.675876, acc.: 55.47%] [G loss: 0.820677]\n",
      "epoch:7 step:7406 [D loss: 0.666584, acc.: 59.38%] [G loss: 0.843267]\n",
      "epoch:7 step:7407 [D loss: 0.662798, acc.: 58.59%] [G loss: 0.831358]\n",
      "epoch:7 step:7408 [D loss: 0.673712, acc.: 53.12%] [G loss: 0.806475]\n",
      "epoch:7 step:7409 [D loss: 0.669112, acc.: 63.28%] [G loss: 0.811731]\n",
      "epoch:7 step:7410 [D loss: 0.686398, acc.: 57.81%] [G loss: 0.867740]\n",
      "epoch:7 step:7411 [D loss: 0.666859, acc.: 60.94%] [G loss: 0.849762]\n",
      "epoch:7 step:7412 [D loss: 0.684829, acc.: 53.12%] [G loss: 0.937545]\n",
      "epoch:7 step:7413 [D loss: 0.664751, acc.: 61.72%] [G loss: 0.924016]\n",
      "epoch:7 step:7414 [D loss: 0.677967, acc.: 53.12%] [G loss: 0.883774]\n",
      "epoch:7 step:7415 [D loss: 0.639746, acc.: 66.41%] [G loss: 0.841522]\n",
      "epoch:7 step:7416 [D loss: 0.665225, acc.: 58.59%] [G loss: 0.826345]\n",
      "epoch:7 step:7417 [D loss: 0.692919, acc.: 57.81%] [G loss: 0.810611]\n",
      "epoch:7 step:7418 [D loss: 0.655887, acc.: 64.84%] [G loss: 0.843785]\n",
      "epoch:7 step:7419 [D loss: 0.686369, acc.: 60.16%] [G loss: 0.897996]\n",
      "epoch:7 step:7420 [D loss: 0.649750, acc.: 64.06%] [G loss: 0.858987]\n",
      "epoch:7 step:7421 [D loss: 0.675400, acc.: 56.25%] [G loss: 0.840466]\n",
      "epoch:7 step:7422 [D loss: 0.647411, acc.: 62.50%] [G loss: 0.904585]\n",
      "epoch:7 step:7423 [D loss: 0.667393, acc.: 61.72%] [G loss: 0.830794]\n",
      "epoch:7 step:7424 [D loss: 0.678474, acc.: 61.72%] [G loss: 0.796643]\n",
      "epoch:7 step:7425 [D loss: 0.686510, acc.: 54.69%] [G loss: 0.830316]\n",
      "epoch:7 step:7426 [D loss: 0.685103, acc.: 50.00%] [G loss: 0.843453]\n",
      "epoch:7 step:7427 [D loss: 0.664248, acc.: 59.38%] [G loss: 0.808952]\n",
      "epoch:7 step:7428 [D loss: 0.690440, acc.: 57.81%] [G loss: 0.842874]\n",
      "epoch:7 step:7429 [D loss: 0.667657, acc.: 53.91%] [G loss: 0.838067]\n",
      "epoch:7 step:7430 [D loss: 0.660873, acc.: 62.50%] [G loss: 0.823076]\n",
      "epoch:7 step:7431 [D loss: 0.676945, acc.: 57.03%] [G loss: 0.807004]\n",
      "epoch:7 step:7432 [D loss: 0.642650, acc.: 64.84%] [G loss: 0.846224]\n",
      "epoch:7 step:7433 [D loss: 0.676360, acc.: 57.03%] [G loss: 0.779237]\n",
      "epoch:7 step:7434 [D loss: 0.674318, acc.: 56.25%] [G loss: 0.765975]\n",
      "epoch:7 step:7435 [D loss: 0.670471, acc.: 61.72%] [G loss: 0.812148]\n",
      "epoch:7 step:7436 [D loss: 0.688036, acc.: 49.22%] [G loss: 0.793635]\n",
      "epoch:7 step:7437 [D loss: 0.682517, acc.: 51.56%] [G loss: 0.844119]\n",
      "epoch:7 step:7438 [D loss: 0.675382, acc.: 57.03%] [G loss: 0.851788]\n",
      "epoch:7 step:7439 [D loss: 0.636433, acc.: 64.84%] [G loss: 0.819964]\n",
      "epoch:7 step:7440 [D loss: 0.673613, acc.: 60.16%] [G loss: 0.830817]\n",
      "epoch:7 step:7441 [D loss: 0.634899, acc.: 66.41%] [G loss: 0.836208]\n",
      "epoch:7 step:7442 [D loss: 0.682144, acc.: 57.81%] [G loss: 0.858682]\n",
      "epoch:7 step:7443 [D loss: 0.674846, acc.: 52.34%] [G loss: 0.849916]\n",
      "epoch:7 step:7444 [D loss: 0.669338, acc.: 58.59%] [G loss: 0.812597]\n",
      "epoch:7 step:7445 [D loss: 0.679187, acc.: 60.16%] [G loss: 0.828037]\n",
      "epoch:7 step:7446 [D loss: 0.660553, acc.: 60.94%] [G loss: 0.808310]\n",
      "epoch:7 step:7447 [D loss: 0.651230, acc.: 62.50%] [G loss: 0.829500]\n",
      "epoch:7 step:7448 [D loss: 0.687859, acc.: 55.47%] [G loss: 0.792503]\n",
      "epoch:7 step:7449 [D loss: 0.653235, acc.: 60.16%] [G loss: 0.840911]\n",
      "epoch:7 step:7450 [D loss: 0.701129, acc.: 50.78%] [G loss: 0.859820]\n",
      "epoch:7 step:7451 [D loss: 0.700303, acc.: 54.69%] [G loss: 0.834123]\n",
      "epoch:7 step:7452 [D loss: 0.669747, acc.: 56.25%] [G loss: 0.838350]\n",
      "epoch:7 step:7453 [D loss: 0.667063, acc.: 62.50%] [G loss: 0.879170]\n",
      "epoch:7 step:7454 [D loss: 0.650652, acc.: 64.84%] [G loss: 0.873989]\n",
      "epoch:7 step:7455 [D loss: 0.662503, acc.: 58.59%] [G loss: 0.857911]\n",
      "epoch:7 step:7456 [D loss: 0.654157, acc.: 61.72%] [G loss: 0.833983]\n",
      "epoch:7 step:7457 [D loss: 0.669947, acc.: 53.91%] [G loss: 0.817432]\n",
      "epoch:7 step:7458 [D loss: 0.670353, acc.: 54.69%] [G loss: 0.829227]\n",
      "epoch:7 step:7459 [D loss: 0.649226, acc.: 59.38%] [G loss: 0.842520]\n",
      "epoch:7 step:7460 [D loss: 0.675311, acc.: 53.12%] [G loss: 0.787880]\n",
      "epoch:7 step:7461 [D loss: 0.656228, acc.: 62.50%] [G loss: 0.806782]\n",
      "epoch:7 step:7462 [D loss: 0.640222, acc.: 65.62%] [G loss: 0.827369]\n",
      "epoch:7 step:7463 [D loss: 0.660328, acc.: 60.94%] [G loss: 0.869448]\n",
      "epoch:7 step:7464 [D loss: 0.675019, acc.: 57.03%] [G loss: 0.828280]\n",
      "epoch:7 step:7465 [D loss: 0.653617, acc.: 57.81%] [G loss: 0.843263]\n",
      "epoch:7 step:7466 [D loss: 0.670077, acc.: 59.38%] [G loss: 0.833162]\n",
      "epoch:7 step:7467 [D loss: 0.641585, acc.: 62.50%] [G loss: 0.847099]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:7 step:7468 [D loss: 0.682437, acc.: 56.25%] [G loss: 0.831427]\n",
      "epoch:7 step:7469 [D loss: 0.705895, acc.: 50.00%] [G loss: 0.823708]\n",
      "epoch:7 step:7470 [D loss: 0.700088, acc.: 48.44%] [G loss: 0.828385]\n",
      "epoch:7 step:7471 [D loss: 0.678642, acc.: 62.50%] [G loss: 0.880937]\n",
      "epoch:7 step:7472 [D loss: 0.688272, acc.: 53.91%] [G loss: 0.851411]\n",
      "epoch:7 step:7473 [D loss: 0.656165, acc.: 60.16%] [G loss: 0.870269]\n",
      "epoch:7 step:7474 [D loss: 0.669147, acc.: 58.59%] [G loss: 0.803127]\n",
      "epoch:7 step:7475 [D loss: 0.671480, acc.: 64.84%] [G loss: 0.799071]\n",
      "epoch:7 step:7476 [D loss: 0.669248, acc.: 57.03%] [G loss: 0.865168]\n",
      "epoch:7 step:7477 [D loss: 0.659629, acc.: 57.03%] [G loss: 0.913381]\n",
      "epoch:7 step:7478 [D loss: 0.659471, acc.: 64.84%] [G loss: 0.862036]\n",
      "epoch:7 step:7479 [D loss: 0.703261, acc.: 54.69%] [G loss: 0.897092]\n",
      "epoch:7 step:7480 [D loss: 0.684764, acc.: 55.47%] [G loss: 0.841701]\n",
      "epoch:7 step:7481 [D loss: 0.633515, acc.: 64.84%] [G loss: 0.842358]\n",
      "epoch:7 step:7482 [D loss: 0.644843, acc.: 59.38%] [G loss: 0.855152]\n",
      "epoch:7 step:7483 [D loss: 0.655938, acc.: 57.81%] [G loss: 0.857493]\n",
      "epoch:7 step:7484 [D loss: 0.652277, acc.: 65.62%] [G loss: 0.852837]\n",
      "epoch:7 step:7485 [D loss: 0.671493, acc.: 60.16%] [G loss: 0.825370]\n",
      "epoch:7 step:7486 [D loss: 0.665885, acc.: 60.16%] [G loss: 0.858080]\n",
      "epoch:7 step:7487 [D loss: 0.641653, acc.: 64.84%] [G loss: 0.811145]\n",
      "epoch:7 step:7488 [D loss: 0.644810, acc.: 64.06%] [G loss: 0.765948]\n",
      "epoch:7 step:7489 [D loss: 0.636558, acc.: 61.72%] [G loss: 0.776984]\n",
      "epoch:7 step:7490 [D loss: 0.688017, acc.: 56.25%] [G loss: 0.781371]\n",
      "epoch:7 step:7491 [D loss: 0.683185, acc.: 53.91%] [G loss: 0.744322]\n",
      "epoch:7 step:7492 [D loss: 0.681897, acc.: 62.50%] [G loss: 0.772895]\n",
      "epoch:7 step:7493 [D loss: 0.639662, acc.: 60.16%] [G loss: 0.821156]\n",
      "epoch:7 step:7494 [D loss: 0.636233, acc.: 61.72%] [G loss: 0.898437]\n",
      "epoch:7 step:7495 [D loss: 0.635320, acc.: 61.72%] [G loss: 0.890283]\n",
      "epoch:7 step:7496 [D loss: 0.668626, acc.: 57.03%] [G loss: 0.884221]\n",
      "epoch:8 step:7497 [D loss: 0.715945, acc.: 61.72%] [G loss: 0.887710]\n",
      "epoch:8 step:7498 [D loss: 0.669024, acc.: 57.03%] [G loss: 0.923149]\n",
      "epoch:8 step:7499 [D loss: 0.681966, acc.: 57.03%] [G loss: 0.920774]\n",
      "epoch:8 step:7500 [D loss: 0.654878, acc.: 64.84%] [G loss: 0.844304]\n",
      "epoch:8 step:7501 [D loss: 0.674609, acc.: 56.25%] [G loss: 0.887572]\n",
      "epoch:8 step:7502 [D loss: 0.677307, acc.: 56.25%] [G loss: 0.881092]\n",
      "epoch:8 step:7503 [D loss: 0.666796, acc.: 57.03%] [G loss: 0.877597]\n",
      "epoch:8 step:7504 [D loss: 0.670147, acc.: 59.38%] [G loss: 0.862375]\n",
      "epoch:8 step:7505 [D loss: 0.653357, acc.: 60.16%] [G loss: 0.790835]\n",
      "epoch:8 step:7506 [D loss: 0.644253, acc.: 64.84%] [G loss: 0.848696]\n",
      "epoch:8 step:7507 [D loss: 0.621347, acc.: 62.50%] [G loss: 0.848575]\n",
      "epoch:8 step:7508 [D loss: 0.638287, acc.: 60.94%] [G loss: 0.841614]\n",
      "epoch:8 step:7509 [D loss: 0.691559, acc.: 55.47%] [G loss: 0.888849]\n",
      "epoch:8 step:7510 [D loss: 0.669167, acc.: 56.25%] [G loss: 0.868065]\n",
      "epoch:8 step:7511 [D loss: 0.654744, acc.: 59.38%] [G loss: 0.886699]\n",
      "epoch:8 step:7512 [D loss: 0.694204, acc.: 57.81%] [G loss: 0.835335]\n",
      "epoch:8 step:7513 [D loss: 0.670015, acc.: 61.72%] [G loss: 0.856092]\n",
      "epoch:8 step:7514 [D loss: 0.695528, acc.: 56.25%] [G loss: 0.908172]\n",
      "epoch:8 step:7515 [D loss: 0.677017, acc.: 56.25%] [G loss: 0.869303]\n",
      "epoch:8 step:7516 [D loss: 0.665973, acc.: 59.38%] [G loss: 0.916749]\n",
      "epoch:8 step:7517 [D loss: 0.667243, acc.: 55.47%] [G loss: 0.889079]\n",
      "epoch:8 step:7518 [D loss: 0.671674, acc.: 57.03%] [G loss: 0.859344]\n",
      "epoch:8 step:7519 [D loss: 0.702302, acc.: 50.00%] [G loss: 0.867776]\n",
      "epoch:8 step:7520 [D loss: 0.621795, acc.: 73.44%] [G loss: 0.865426]\n",
      "epoch:8 step:7521 [D loss: 0.671841, acc.: 62.50%] [G loss: 0.841449]\n",
      "epoch:8 step:7522 [D loss: 0.658880, acc.: 62.50%] [G loss: 0.838147]\n",
      "epoch:8 step:7523 [D loss: 0.657758, acc.: 63.28%] [G loss: 0.813499]\n",
      "epoch:8 step:7524 [D loss: 0.651285, acc.: 56.25%] [G loss: 0.848121]\n",
      "epoch:8 step:7525 [D loss: 0.666606, acc.: 58.59%] [G loss: 0.845721]\n",
      "epoch:8 step:7526 [D loss: 0.665023, acc.: 62.50%] [G loss: 0.763824]\n",
      "epoch:8 step:7527 [D loss: 0.699855, acc.: 52.34%] [G loss: 0.847953]\n",
      "epoch:8 step:7528 [D loss: 0.682997, acc.: 55.47%] [G loss: 0.828072]\n",
      "epoch:8 step:7529 [D loss: 0.667223, acc.: 62.50%] [G loss: 0.871707]\n",
      "epoch:8 step:7530 [D loss: 0.689734, acc.: 48.44%] [G loss: 0.853103]\n",
      "epoch:8 step:7531 [D loss: 0.660256, acc.: 59.38%] [G loss: 0.900507]\n",
      "epoch:8 step:7532 [D loss: 0.646569, acc.: 64.84%] [G loss: 0.884022]\n",
      "epoch:8 step:7533 [D loss: 0.671075, acc.: 57.81%] [G loss: 0.843426]\n",
      "epoch:8 step:7534 [D loss: 0.684580, acc.: 54.69%] [G loss: 0.878149]\n",
      "epoch:8 step:7535 [D loss: 0.653807, acc.: 58.59%] [G loss: 0.916760]\n",
      "epoch:8 step:7536 [D loss: 0.706877, acc.: 55.47%] [G loss: 0.857924]\n",
      "epoch:8 step:7537 [D loss: 0.676410, acc.: 58.59%] [G loss: 0.876637]\n",
      "epoch:8 step:7538 [D loss: 0.649742, acc.: 61.72%] [G loss: 0.908024]\n",
      "epoch:8 step:7539 [D loss: 0.634148, acc.: 60.94%] [G loss: 0.848242]\n",
      "epoch:8 step:7540 [D loss: 0.665474, acc.: 60.94%] [G loss: 0.882678]\n",
      "epoch:8 step:7541 [D loss: 0.680887, acc.: 56.25%] [G loss: 0.874937]\n",
      "epoch:8 step:7542 [D loss: 0.665317, acc.: 56.25%] [G loss: 0.764457]\n",
      "epoch:8 step:7543 [D loss: 0.706047, acc.: 50.00%] [G loss: 0.872721]\n",
      "epoch:8 step:7544 [D loss: 0.659254, acc.: 57.81%] [G loss: 0.793925]\n",
      "epoch:8 step:7545 [D loss: 0.680955, acc.: 55.47%] [G loss: 0.825606]\n",
      "epoch:8 step:7546 [D loss: 0.641951, acc.: 65.62%] [G loss: 0.834082]\n",
      "epoch:8 step:7547 [D loss: 0.699187, acc.: 53.12%] [G loss: 0.840951]\n",
      "epoch:8 step:7548 [D loss: 0.639633, acc.: 64.06%] [G loss: 0.843942]\n",
      "epoch:8 step:7549 [D loss: 0.691437, acc.: 58.59%] [G loss: 0.831220]\n",
      "epoch:8 step:7550 [D loss: 0.655293, acc.: 62.50%] [G loss: 0.839230]\n",
      "epoch:8 step:7551 [D loss: 0.671514, acc.: 60.16%] [G loss: 0.861573]\n",
      "epoch:8 step:7552 [D loss: 0.688485, acc.: 57.03%] [G loss: 0.871875]\n",
      "epoch:8 step:7553 [D loss: 0.674159, acc.: 57.03%] [G loss: 0.851873]\n",
      "epoch:8 step:7554 [D loss: 0.650565, acc.: 63.28%] [G loss: 0.830059]\n",
      "epoch:8 step:7555 [D loss: 0.638452, acc.: 64.84%] [G loss: 0.836260]\n",
      "epoch:8 step:7556 [D loss: 0.668489, acc.: 58.59%] [G loss: 0.823899]\n",
      "epoch:8 step:7557 [D loss: 0.703476, acc.: 52.34%] [G loss: 0.813067]\n",
      "epoch:8 step:7558 [D loss: 0.685156, acc.: 60.16%] [G loss: 0.854988]\n",
      "epoch:8 step:7559 [D loss: 0.662935, acc.: 56.25%] [G loss: 0.816475]\n",
      "epoch:8 step:7560 [D loss: 0.699379, acc.: 54.69%] [G loss: 0.838737]\n",
      "epoch:8 step:7561 [D loss: 0.654621, acc.: 62.50%] [G loss: 0.860776]\n",
      "epoch:8 step:7562 [D loss: 0.673716, acc.: 61.72%] [G loss: 0.852157]\n",
      "epoch:8 step:7563 [D loss: 0.738854, acc.: 45.31%] [G loss: 0.879474]\n",
      "epoch:8 step:7564 [D loss: 0.678040, acc.: 55.47%] [G loss: 0.902588]\n",
      "epoch:8 step:7565 [D loss: 0.650901, acc.: 57.03%] [G loss: 0.933402]\n",
      "epoch:8 step:7566 [D loss: 0.708077, acc.: 52.34%] [G loss: 0.919829]\n",
      "epoch:8 step:7567 [D loss: 0.690676, acc.: 57.03%] [G loss: 0.873041]\n",
      "epoch:8 step:7568 [D loss: 0.679077, acc.: 62.50%] [G loss: 0.870112]\n",
      "epoch:8 step:7569 [D loss: 0.633473, acc.: 64.84%] [G loss: 0.896607]\n",
      "epoch:8 step:7570 [D loss: 0.679799, acc.: 55.47%] [G loss: 0.837218]\n",
      "epoch:8 step:7571 [D loss: 0.642861, acc.: 62.50%] [G loss: 0.873188]\n",
      "epoch:8 step:7572 [D loss: 0.659885, acc.: 57.03%] [G loss: 0.904855]\n",
      "epoch:8 step:7573 [D loss: 0.683030, acc.: 53.12%] [G loss: 0.837238]\n",
      "epoch:8 step:7574 [D loss: 0.660648, acc.: 58.59%] [G loss: 0.837950]\n",
      "epoch:8 step:7575 [D loss: 0.673160, acc.: 57.81%] [G loss: 0.829213]\n",
      "epoch:8 step:7576 [D loss: 0.655123, acc.: 65.62%] [G loss: 0.855059]\n",
      "epoch:8 step:7577 [D loss: 0.678026, acc.: 53.12%] [G loss: 0.830531]\n",
      "epoch:8 step:7578 [D loss: 0.689047, acc.: 53.12%] [G loss: 0.828174]\n",
      "epoch:8 step:7579 [D loss: 0.653315, acc.: 63.28%] [G loss: 0.832929]\n",
      "epoch:8 step:7580 [D loss: 0.674383, acc.: 59.38%] [G loss: 0.818848]\n",
      "epoch:8 step:7581 [D loss: 0.699411, acc.: 49.22%] [G loss: 0.866444]\n",
      "epoch:8 step:7582 [D loss: 0.683532, acc.: 57.03%] [G loss: 0.836645]\n",
      "epoch:8 step:7583 [D loss: 0.686033, acc.: 50.78%] [G loss: 0.864742]\n",
      "epoch:8 step:7584 [D loss: 0.666888, acc.: 60.94%] [G loss: 0.903961]\n",
      "epoch:8 step:7585 [D loss: 0.680344, acc.: 58.59%] [G loss: 0.873318]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7586 [D loss: 0.669406, acc.: 60.16%] [G loss: 0.860854]\n",
      "epoch:8 step:7587 [D loss: 0.724469, acc.: 50.00%] [G loss: 0.869730]\n",
      "epoch:8 step:7588 [D loss: 0.668849, acc.: 60.16%] [G loss: 0.858600]\n",
      "epoch:8 step:7589 [D loss: 0.679958, acc.: 57.03%] [G loss: 0.890579]\n",
      "epoch:8 step:7590 [D loss: 0.672083, acc.: 60.16%] [G loss: 0.874417]\n",
      "epoch:8 step:7591 [D loss: 0.671718, acc.: 55.47%] [G loss: 0.871479]\n",
      "epoch:8 step:7592 [D loss: 0.660040, acc.: 58.59%] [G loss: 0.827725]\n",
      "epoch:8 step:7593 [D loss: 0.651616, acc.: 64.06%] [G loss: 0.826821]\n",
      "epoch:8 step:7594 [D loss: 0.680751, acc.: 56.25%] [G loss: 0.884488]\n",
      "epoch:8 step:7595 [D loss: 0.679508, acc.: 57.03%] [G loss: 0.850558]\n",
      "epoch:8 step:7596 [D loss: 0.694019, acc.: 50.78%] [G loss: 0.854702]\n",
      "epoch:8 step:7597 [D loss: 0.673440, acc.: 53.91%] [G loss: 0.871002]\n",
      "epoch:8 step:7598 [D loss: 0.697761, acc.: 54.69%] [G loss: 0.816798]\n",
      "epoch:8 step:7599 [D loss: 0.680708, acc.: 56.25%] [G loss: 0.801659]\n",
      "epoch:8 step:7600 [D loss: 0.656186, acc.: 57.03%] [G loss: 0.786258]\n",
      "##############\n",
      "[2.89520323 2.38310048 2.16752463 3.96020606 1.48427514 8.87476846\n",
      " 3.02892042 3.854404   4.05395101 7.14868929]\n",
      "##########\n",
      "epoch:8 step:7601 [D loss: 0.646361, acc.: 67.97%] [G loss: 0.879536]\n",
      "epoch:8 step:7602 [D loss: 0.677255, acc.: 55.47%] [G loss: 0.845715]\n",
      "epoch:8 step:7603 [D loss: 0.653315, acc.: 63.28%] [G loss: 0.885553]\n",
      "epoch:8 step:7604 [D loss: 0.670457, acc.: 62.50%] [G loss: 0.842340]\n",
      "epoch:8 step:7605 [D loss: 0.686400, acc.: 58.59%] [G loss: 0.854496]\n",
      "epoch:8 step:7606 [D loss: 0.678277, acc.: 54.69%] [G loss: 0.868723]\n",
      "epoch:8 step:7607 [D loss: 0.692083, acc.: 54.69%] [G loss: 0.822402]\n",
      "epoch:8 step:7608 [D loss: 0.672350, acc.: 60.16%] [G loss: 0.844334]\n",
      "epoch:8 step:7609 [D loss: 0.665121, acc.: 58.59%] [G loss: 0.879354]\n",
      "epoch:8 step:7610 [D loss: 0.664650, acc.: 58.59%] [G loss: 0.874637]\n",
      "epoch:8 step:7611 [D loss: 0.695987, acc.: 57.81%] [G loss: 0.859324]\n",
      "epoch:8 step:7612 [D loss: 0.677918, acc.: 58.59%] [G loss: 0.869558]\n",
      "epoch:8 step:7613 [D loss: 0.680952, acc.: 56.25%] [G loss: 0.860782]\n",
      "epoch:8 step:7614 [D loss: 0.659726, acc.: 60.16%] [G loss: 0.859161]\n",
      "epoch:8 step:7615 [D loss: 0.662762, acc.: 55.47%] [G loss: 0.823815]\n",
      "epoch:8 step:7616 [D loss: 0.702032, acc.: 53.91%] [G loss: 0.847208]\n",
      "epoch:8 step:7617 [D loss: 0.667626, acc.: 59.38%] [G loss: 0.818408]\n",
      "epoch:8 step:7618 [D loss: 0.661673, acc.: 57.03%] [G loss: 0.829097]\n",
      "epoch:8 step:7619 [D loss: 0.701665, acc.: 53.12%] [G loss: 0.858520]\n",
      "epoch:8 step:7620 [D loss: 0.697042, acc.: 55.47%] [G loss: 0.855223]\n",
      "epoch:8 step:7621 [D loss: 0.686407, acc.: 54.69%] [G loss: 0.813262]\n",
      "epoch:8 step:7622 [D loss: 0.687834, acc.: 57.03%] [G loss: 0.885065]\n",
      "epoch:8 step:7623 [D loss: 0.662468, acc.: 67.19%] [G loss: 0.789437]\n",
      "epoch:8 step:7624 [D loss: 0.650200, acc.: 63.28%] [G loss: 0.871474]\n",
      "epoch:8 step:7625 [D loss: 0.668136, acc.: 59.38%] [G loss: 0.868214]\n",
      "epoch:8 step:7626 [D loss: 0.665942, acc.: 54.69%] [G loss: 0.912530]\n",
      "epoch:8 step:7627 [D loss: 0.640070, acc.: 63.28%] [G loss: 0.794014]\n",
      "epoch:8 step:7628 [D loss: 0.717816, acc.: 52.34%] [G loss: 0.873428]\n",
      "epoch:8 step:7629 [D loss: 0.681590, acc.: 52.34%] [G loss: 0.838379]\n",
      "epoch:8 step:7630 [D loss: 0.685238, acc.: 57.81%] [G loss: 0.875241]\n",
      "epoch:8 step:7631 [D loss: 0.671499, acc.: 59.38%] [G loss: 0.863933]\n",
      "epoch:8 step:7632 [D loss: 0.662758, acc.: 56.25%] [G loss: 0.820091]\n",
      "epoch:8 step:7633 [D loss: 0.663141, acc.: 58.59%] [G loss: 0.796827]\n",
      "epoch:8 step:7634 [D loss: 0.686561, acc.: 59.38%] [G loss: 0.820548]\n",
      "epoch:8 step:7635 [D loss: 0.696462, acc.: 51.56%] [G loss: 0.831370]\n",
      "epoch:8 step:7636 [D loss: 0.650528, acc.: 60.16%] [G loss: 0.848467]\n",
      "epoch:8 step:7637 [D loss: 0.685652, acc.: 53.91%] [G loss: 0.799935]\n",
      "epoch:8 step:7638 [D loss: 0.646646, acc.: 64.84%] [G loss: 0.805706]\n",
      "epoch:8 step:7639 [D loss: 0.698379, acc.: 55.47%] [G loss: 0.830974]\n",
      "epoch:8 step:7640 [D loss: 0.705225, acc.: 49.22%] [G loss: 0.820209]\n",
      "epoch:8 step:7641 [D loss: 0.672957, acc.: 56.25%] [G loss: 0.830854]\n",
      "epoch:8 step:7642 [D loss: 0.666660, acc.: 53.12%] [G loss: 0.842590]\n",
      "epoch:8 step:7643 [D loss: 0.686485, acc.: 54.69%] [G loss: 0.839183]\n",
      "epoch:8 step:7644 [D loss: 0.648961, acc.: 61.72%] [G loss: 0.869985]\n",
      "epoch:8 step:7645 [D loss: 0.661582, acc.: 60.16%] [G loss: 0.843360]\n",
      "epoch:8 step:7646 [D loss: 0.689259, acc.: 53.12%] [G loss: 0.894952]\n",
      "epoch:8 step:7647 [D loss: 0.673122, acc.: 56.25%] [G loss: 0.826698]\n",
      "epoch:8 step:7648 [D loss: 0.688839, acc.: 54.69%] [G loss: 0.825083]\n",
      "epoch:8 step:7649 [D loss: 0.655372, acc.: 62.50%] [G loss: 0.805594]\n",
      "epoch:8 step:7650 [D loss: 0.655007, acc.: 58.59%] [G loss: 0.830864]\n",
      "epoch:8 step:7651 [D loss: 0.666894, acc.: 57.81%] [G loss: 0.815661]\n",
      "epoch:8 step:7652 [D loss: 0.669916, acc.: 58.59%] [G loss: 0.831528]\n",
      "epoch:8 step:7653 [D loss: 0.644704, acc.: 60.94%] [G loss: 0.864635]\n",
      "epoch:8 step:7654 [D loss: 0.678275, acc.: 59.38%] [G loss: 0.870039]\n",
      "epoch:8 step:7655 [D loss: 0.648561, acc.: 60.94%] [G loss: 0.847986]\n",
      "epoch:8 step:7656 [D loss: 0.687490, acc.: 54.69%] [G loss: 0.870883]\n",
      "epoch:8 step:7657 [D loss: 0.646807, acc.: 64.06%] [G loss: 0.911622]\n",
      "epoch:8 step:7658 [D loss: 0.665042, acc.: 63.28%] [G loss: 0.846548]\n",
      "epoch:8 step:7659 [D loss: 0.681969, acc.: 59.38%] [G loss: 0.850139]\n",
      "epoch:8 step:7660 [D loss: 0.680759, acc.: 56.25%] [G loss: 0.822411]\n",
      "epoch:8 step:7661 [D loss: 0.639782, acc.: 64.06%] [G loss: 0.855373]\n",
      "epoch:8 step:7662 [D loss: 0.690914, acc.: 56.25%] [G loss: 0.846139]\n",
      "epoch:8 step:7663 [D loss: 0.649124, acc.: 64.84%] [G loss: 0.825096]\n",
      "epoch:8 step:7664 [D loss: 0.678273, acc.: 58.59%] [G loss: 0.865114]\n",
      "epoch:8 step:7665 [D loss: 0.695482, acc.: 53.12%] [G loss: 0.830033]\n",
      "epoch:8 step:7666 [D loss: 0.673800, acc.: 57.81%] [G loss: 0.838456]\n",
      "epoch:8 step:7667 [D loss: 0.678794, acc.: 53.12%] [G loss: 0.853153]\n",
      "epoch:8 step:7668 [D loss: 0.671452, acc.: 55.47%] [G loss: 0.832714]\n",
      "epoch:8 step:7669 [D loss: 0.709696, acc.: 56.25%] [G loss: 0.887414]\n",
      "epoch:8 step:7670 [D loss: 0.624179, acc.: 67.19%] [G loss: 0.834329]\n",
      "epoch:8 step:7671 [D loss: 0.680024, acc.: 53.91%] [G loss: 0.832162]\n",
      "epoch:8 step:7672 [D loss: 0.619613, acc.: 69.53%] [G loss: 0.834282]\n",
      "epoch:8 step:7673 [D loss: 0.668901, acc.: 56.25%] [G loss: 0.871015]\n",
      "epoch:8 step:7674 [D loss: 0.646239, acc.: 62.50%] [G loss: 0.851779]\n",
      "epoch:8 step:7675 [D loss: 0.674918, acc.: 56.25%] [G loss: 0.897764]\n",
      "epoch:8 step:7676 [D loss: 0.661790, acc.: 60.94%] [G loss: 0.849693]\n",
      "epoch:8 step:7677 [D loss: 0.683009, acc.: 56.25%] [G loss: 0.881334]\n",
      "epoch:8 step:7678 [D loss: 0.651457, acc.: 64.84%] [G loss: 0.866346]\n",
      "epoch:8 step:7679 [D loss: 0.696510, acc.: 57.81%] [G loss: 0.896902]\n",
      "epoch:8 step:7680 [D loss: 0.651556, acc.: 65.62%] [G loss: 0.874714]\n",
      "epoch:8 step:7681 [D loss: 0.708161, acc.: 52.34%] [G loss: 0.856507]\n",
      "epoch:8 step:7682 [D loss: 0.664744, acc.: 59.38%] [G loss: 0.873840]\n",
      "epoch:8 step:7683 [D loss: 0.656668, acc.: 60.16%] [G loss: 0.907474]\n",
      "epoch:8 step:7684 [D loss: 0.670833, acc.: 57.81%] [G loss: 0.815445]\n",
      "epoch:8 step:7685 [D loss: 0.665742, acc.: 60.94%] [G loss: 0.857234]\n",
      "epoch:8 step:7686 [D loss: 0.671026, acc.: 59.38%] [G loss: 0.825409]\n",
      "epoch:8 step:7687 [D loss: 0.628027, acc.: 68.75%] [G loss: 0.829345]\n",
      "epoch:8 step:7688 [D loss: 0.662216, acc.: 59.38%] [G loss: 0.822926]\n",
      "epoch:8 step:7689 [D loss: 0.668085, acc.: 60.16%] [G loss: 0.851364]\n",
      "epoch:8 step:7690 [D loss: 0.688842, acc.: 56.25%] [G loss: 0.850457]\n",
      "epoch:8 step:7691 [D loss: 0.681974, acc.: 57.03%] [G loss: 0.836288]\n",
      "epoch:8 step:7692 [D loss: 0.674316, acc.: 56.25%] [G loss: 0.837372]\n",
      "epoch:8 step:7693 [D loss: 0.655378, acc.: 64.06%] [G loss: 0.828262]\n",
      "epoch:8 step:7694 [D loss: 0.632762, acc.: 64.84%] [G loss: 0.815476]\n",
      "epoch:8 step:7695 [D loss: 0.685234, acc.: 60.16%] [G loss: 0.857217]\n",
      "epoch:8 step:7696 [D loss: 0.681952, acc.: 57.03%] [G loss: 0.841181]\n",
      "epoch:8 step:7697 [D loss: 0.635743, acc.: 61.72%] [G loss: 0.826934]\n",
      "epoch:8 step:7698 [D loss: 0.658333, acc.: 56.25%] [G loss: 0.854818]\n",
      "epoch:8 step:7699 [D loss: 0.662987, acc.: 57.03%] [G loss: 0.872221]\n",
      "epoch:8 step:7700 [D loss: 0.688345, acc.: 53.91%] [G loss: 0.890356]\n",
      "epoch:8 step:7701 [D loss: 0.655552, acc.: 64.06%] [G loss: 0.823472]\n",
      "epoch:8 step:7702 [D loss: 0.674080, acc.: 61.72%] [G loss: 0.818370]\n",
      "epoch:8 step:7703 [D loss: 0.669405, acc.: 60.94%] [G loss: 0.827130]\n",
      "epoch:8 step:7704 [D loss: 0.651231, acc.: 63.28%] [G loss: 0.832518]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7705 [D loss: 0.692447, acc.: 51.56%] [G loss: 0.818912]\n",
      "epoch:8 step:7706 [D loss: 0.620660, acc.: 71.09%] [G loss: 0.857011]\n",
      "epoch:8 step:7707 [D loss: 0.647638, acc.: 61.72%] [G loss: 0.854627]\n",
      "epoch:8 step:7708 [D loss: 0.663571, acc.: 59.38%] [G loss: 0.876467]\n",
      "epoch:8 step:7709 [D loss: 0.689486, acc.: 54.69%] [G loss: 0.895169]\n",
      "epoch:8 step:7710 [D loss: 0.688101, acc.: 54.69%] [G loss: 0.868473]\n",
      "epoch:8 step:7711 [D loss: 0.669183, acc.: 54.69%] [G loss: 0.894610]\n",
      "epoch:8 step:7712 [D loss: 0.652063, acc.: 62.50%] [G loss: 0.867401]\n",
      "epoch:8 step:7713 [D loss: 0.688056, acc.: 59.38%] [G loss: 0.879912]\n",
      "epoch:8 step:7714 [D loss: 0.689380, acc.: 57.81%] [G loss: 0.862184]\n",
      "epoch:8 step:7715 [D loss: 0.660671, acc.: 62.50%] [G loss: 0.837783]\n",
      "epoch:8 step:7716 [D loss: 0.706850, acc.: 55.47%] [G loss: 0.795426]\n",
      "epoch:8 step:7717 [D loss: 0.668855, acc.: 63.28%] [G loss: 0.792322]\n",
      "epoch:8 step:7718 [D loss: 0.668919, acc.: 60.94%] [G loss: 0.789872]\n",
      "epoch:8 step:7719 [D loss: 0.673474, acc.: 58.59%] [G loss: 0.820267]\n",
      "epoch:8 step:7720 [D loss: 0.654686, acc.: 61.72%] [G loss: 0.836917]\n",
      "epoch:8 step:7721 [D loss: 0.665212, acc.: 57.81%] [G loss: 0.826421]\n",
      "epoch:8 step:7722 [D loss: 0.638812, acc.: 62.50%] [G loss: 0.844830]\n",
      "epoch:8 step:7723 [D loss: 0.666314, acc.: 62.50%] [G loss: 0.837428]\n",
      "epoch:8 step:7724 [D loss: 0.679458, acc.: 58.59%] [G loss: 0.891214]\n",
      "epoch:8 step:7725 [D loss: 0.658500, acc.: 61.72%] [G loss: 0.876544]\n",
      "epoch:8 step:7726 [D loss: 0.681089, acc.: 53.91%] [G loss: 0.887681]\n",
      "epoch:8 step:7727 [D loss: 0.691812, acc.: 57.03%] [G loss: 0.846643]\n",
      "epoch:8 step:7728 [D loss: 0.650134, acc.: 64.84%] [G loss: 0.901611]\n",
      "epoch:8 step:7729 [D loss: 0.714830, acc.: 46.09%] [G loss: 0.875103]\n",
      "epoch:8 step:7730 [D loss: 0.697128, acc.: 53.12%] [G loss: 0.877693]\n",
      "epoch:8 step:7731 [D loss: 0.707158, acc.: 53.12%] [G loss: 0.886616]\n",
      "epoch:8 step:7732 [D loss: 0.682984, acc.: 53.12%] [G loss: 0.889245]\n",
      "epoch:8 step:7733 [D loss: 0.685887, acc.: 52.34%] [G loss: 0.897536]\n",
      "epoch:8 step:7734 [D loss: 0.676069, acc.: 62.50%] [G loss: 0.841030]\n",
      "epoch:8 step:7735 [D loss: 0.673409, acc.: 56.25%] [G loss: 0.807905]\n",
      "epoch:8 step:7736 [D loss: 0.659142, acc.: 65.62%] [G loss: 0.862803]\n",
      "epoch:8 step:7737 [D loss: 0.688372, acc.: 50.78%] [G loss: 0.847898]\n",
      "epoch:8 step:7738 [D loss: 0.688578, acc.: 54.69%] [G loss: 0.813326]\n",
      "epoch:8 step:7739 [D loss: 0.649696, acc.: 60.94%] [G loss: 0.803763]\n",
      "epoch:8 step:7740 [D loss: 0.644072, acc.: 63.28%] [G loss: 0.814863]\n",
      "epoch:8 step:7741 [D loss: 0.662377, acc.: 55.47%] [G loss: 0.839591]\n",
      "epoch:8 step:7742 [D loss: 0.696518, acc.: 55.47%] [G loss: 0.828659]\n",
      "epoch:8 step:7743 [D loss: 0.666510, acc.: 58.59%] [G loss: 0.885889]\n",
      "epoch:8 step:7744 [D loss: 0.643098, acc.: 59.38%] [G loss: 0.869872]\n",
      "epoch:8 step:7745 [D loss: 0.679885, acc.: 60.94%] [G loss: 0.870069]\n",
      "epoch:8 step:7746 [D loss: 0.632187, acc.: 65.62%] [G loss: 0.863720]\n",
      "epoch:8 step:7747 [D loss: 0.649785, acc.: 70.31%] [G loss: 0.812426]\n",
      "epoch:8 step:7748 [D loss: 0.679672, acc.: 64.06%] [G loss: 0.828713]\n",
      "epoch:8 step:7749 [D loss: 0.651567, acc.: 65.62%] [G loss: 0.814897]\n",
      "epoch:8 step:7750 [D loss: 0.680819, acc.: 56.25%] [G loss: 0.838952]\n",
      "epoch:8 step:7751 [D loss: 0.671415, acc.: 63.28%] [G loss: 0.793104]\n",
      "epoch:8 step:7752 [D loss: 0.674619, acc.: 55.47%] [G loss: 0.820302]\n",
      "epoch:8 step:7753 [D loss: 0.688073, acc.: 57.81%] [G loss: 0.800501]\n",
      "epoch:8 step:7754 [D loss: 0.695854, acc.: 55.47%] [G loss: 0.841980]\n",
      "epoch:8 step:7755 [D loss: 0.700564, acc.: 52.34%] [G loss: 0.831360]\n",
      "epoch:8 step:7756 [D loss: 0.682643, acc.: 57.81%] [G loss: 0.894973]\n",
      "epoch:8 step:7757 [D loss: 0.654342, acc.: 67.19%] [G loss: 0.817385]\n",
      "epoch:8 step:7758 [D loss: 0.685077, acc.: 56.25%] [G loss: 0.838762]\n",
      "epoch:8 step:7759 [D loss: 0.656178, acc.: 60.16%] [G loss: 0.860371]\n",
      "epoch:8 step:7760 [D loss: 0.677749, acc.: 60.16%] [G loss: 0.845586]\n",
      "epoch:8 step:7761 [D loss: 0.645273, acc.: 58.59%] [G loss: 0.834051]\n",
      "epoch:8 step:7762 [D loss: 0.646930, acc.: 62.50%] [G loss: 0.840135]\n",
      "epoch:8 step:7763 [D loss: 0.678183, acc.: 55.47%] [G loss: 0.875360]\n",
      "epoch:8 step:7764 [D loss: 0.654850, acc.: 54.69%] [G loss: 0.830003]\n",
      "epoch:8 step:7765 [D loss: 0.662571, acc.: 64.06%] [G loss: 0.826389]\n",
      "epoch:8 step:7766 [D loss: 0.653488, acc.: 64.84%] [G loss: 0.865748]\n",
      "epoch:8 step:7767 [D loss: 0.679356, acc.: 58.59%] [G loss: 0.774520]\n",
      "epoch:8 step:7768 [D loss: 0.694131, acc.: 54.69%] [G loss: 0.826868]\n",
      "epoch:8 step:7769 [D loss: 0.692637, acc.: 50.78%] [G loss: 0.870860]\n",
      "epoch:8 step:7770 [D loss: 0.672724, acc.: 50.78%] [G loss: 0.908022]\n",
      "epoch:8 step:7771 [D loss: 0.676637, acc.: 60.94%] [G loss: 0.870299]\n",
      "epoch:8 step:7772 [D loss: 0.703195, acc.: 50.78%] [G loss: 0.862282]\n",
      "epoch:8 step:7773 [D loss: 0.632391, acc.: 62.50%] [G loss: 0.814687]\n",
      "epoch:8 step:7774 [D loss: 0.659409, acc.: 63.28%] [G loss: 0.793008]\n",
      "epoch:8 step:7775 [D loss: 0.684244, acc.: 59.38%] [G loss: 0.803197]\n",
      "epoch:8 step:7776 [D loss: 0.675841, acc.: 53.91%] [G loss: 0.803236]\n",
      "epoch:8 step:7777 [D loss: 0.675597, acc.: 58.59%] [G loss: 0.820868]\n",
      "epoch:8 step:7778 [D loss: 0.706128, acc.: 50.00%] [G loss: 0.821960]\n",
      "epoch:8 step:7779 [D loss: 0.641713, acc.: 58.59%] [G loss: 0.888523]\n",
      "epoch:8 step:7780 [D loss: 0.657055, acc.: 57.81%] [G loss: 0.849782]\n",
      "epoch:8 step:7781 [D loss: 0.659944, acc.: 58.59%] [G loss: 0.855902]\n",
      "epoch:8 step:7782 [D loss: 0.695451, acc.: 50.00%] [G loss: 0.829201]\n",
      "epoch:8 step:7783 [D loss: 0.648542, acc.: 64.84%] [G loss: 0.851297]\n",
      "epoch:8 step:7784 [D loss: 0.685486, acc.: 53.12%] [G loss: 0.900551]\n",
      "epoch:8 step:7785 [D loss: 0.651779, acc.: 64.06%] [G loss: 0.887253]\n",
      "epoch:8 step:7786 [D loss: 0.664624, acc.: 60.16%] [G loss: 0.875821]\n",
      "epoch:8 step:7787 [D loss: 0.663814, acc.: 60.94%] [G loss: 0.874439]\n",
      "epoch:8 step:7788 [D loss: 0.674520, acc.: 57.03%] [G loss: 0.866710]\n",
      "epoch:8 step:7789 [D loss: 0.672322, acc.: 55.47%] [G loss: 0.871933]\n",
      "epoch:8 step:7790 [D loss: 0.657077, acc.: 57.81%] [G loss: 0.871887]\n",
      "epoch:8 step:7791 [D loss: 0.658559, acc.: 60.16%] [G loss: 0.872353]\n",
      "epoch:8 step:7792 [D loss: 0.660041, acc.: 61.72%] [G loss: 0.879388]\n",
      "epoch:8 step:7793 [D loss: 0.676171, acc.: 56.25%] [G loss: 0.857129]\n",
      "epoch:8 step:7794 [D loss: 0.662350, acc.: 53.12%] [G loss: 0.890857]\n",
      "epoch:8 step:7795 [D loss: 0.716584, acc.: 53.12%] [G loss: 0.910509]\n",
      "epoch:8 step:7796 [D loss: 0.670725, acc.: 61.72%] [G loss: 0.939769]\n",
      "epoch:8 step:7797 [D loss: 0.683618, acc.: 56.25%] [G loss: 0.900204]\n",
      "epoch:8 step:7798 [D loss: 0.677397, acc.: 60.16%] [G loss: 0.874435]\n",
      "epoch:8 step:7799 [D loss: 0.665045, acc.: 61.72%] [G loss: 0.892582]\n",
      "epoch:8 step:7800 [D loss: 0.637395, acc.: 66.41%] [G loss: 0.856315]\n",
      "##############\n",
      "[2.99401621 2.6723614  2.47871826 3.94432249 1.13583345 8.2288327\n",
      " 2.92844786 3.32024926 4.22094116 6.61731656]\n",
      "##########\n",
      "epoch:8 step:7801 [D loss: 0.652744, acc.: 61.72%] [G loss: 0.826457]\n",
      "epoch:8 step:7802 [D loss: 0.678916, acc.: 58.59%] [G loss: 0.850126]\n",
      "epoch:8 step:7803 [D loss: 0.679636, acc.: 52.34%] [G loss: 0.873999]\n",
      "epoch:8 step:7804 [D loss: 0.689760, acc.: 51.56%] [G loss: 0.894800]\n",
      "epoch:8 step:7805 [D loss: 0.632161, acc.: 66.41%] [G loss: 0.858431]\n",
      "epoch:8 step:7806 [D loss: 0.662814, acc.: 60.16%] [G loss: 0.823731]\n",
      "epoch:8 step:7807 [D loss: 0.674027, acc.: 56.25%] [G loss: 0.873846]\n",
      "epoch:8 step:7808 [D loss: 0.728329, acc.: 48.44%] [G loss: 0.857328]\n",
      "epoch:8 step:7809 [D loss: 0.669981, acc.: 55.47%] [G loss: 0.862893]\n",
      "epoch:8 step:7810 [D loss: 0.659368, acc.: 57.03%] [G loss: 0.824248]\n",
      "epoch:8 step:7811 [D loss: 0.644625, acc.: 64.06%] [G loss: 0.883820]\n",
      "epoch:8 step:7812 [D loss: 0.656815, acc.: 62.50%] [G loss: 0.859166]\n",
      "epoch:8 step:7813 [D loss: 0.676094, acc.: 57.81%] [G loss: 0.815553]\n",
      "epoch:8 step:7814 [D loss: 0.667658, acc.: 57.03%] [G loss: 0.838904]\n",
      "epoch:8 step:7815 [D loss: 0.653159, acc.: 58.59%] [G loss: 0.815900]\n",
      "epoch:8 step:7816 [D loss: 0.675322, acc.: 57.81%] [G loss: 0.803829]\n",
      "epoch:8 step:7817 [D loss: 0.672223, acc.: 60.94%] [G loss: 0.848436]\n",
      "epoch:8 step:7818 [D loss: 0.701633, acc.: 46.88%] [G loss: 0.877693]\n",
      "epoch:8 step:7819 [D loss: 0.684097, acc.: 56.25%] [G loss: 0.833149]\n",
      "epoch:8 step:7820 [D loss: 0.676854, acc.: 54.69%] [G loss: 0.824011]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7821 [D loss: 0.675717, acc.: 56.25%] [G loss: 0.832541]\n",
      "epoch:8 step:7822 [D loss: 0.667600, acc.: 60.16%] [G loss: 0.848723]\n",
      "epoch:8 step:7823 [D loss: 0.636043, acc.: 57.81%] [G loss: 0.865701]\n",
      "epoch:8 step:7824 [D loss: 0.650188, acc.: 66.41%] [G loss: 0.843563]\n",
      "epoch:8 step:7825 [D loss: 0.655387, acc.: 64.06%] [G loss: 0.835062]\n",
      "epoch:8 step:7826 [D loss: 0.660883, acc.: 61.72%] [G loss: 0.857901]\n",
      "epoch:8 step:7827 [D loss: 0.676858, acc.: 60.94%] [G loss: 0.847680]\n",
      "epoch:8 step:7828 [D loss: 0.636483, acc.: 67.97%] [G loss: 0.839767]\n",
      "epoch:8 step:7829 [D loss: 0.661190, acc.: 53.12%] [G loss: 0.833457]\n",
      "epoch:8 step:7830 [D loss: 0.670742, acc.: 58.59%] [G loss: 0.803591]\n",
      "epoch:8 step:7831 [D loss: 0.638978, acc.: 60.16%] [G loss: 0.897425]\n",
      "epoch:8 step:7832 [D loss: 0.617965, acc.: 67.19%] [G loss: 0.861260]\n",
      "epoch:8 step:7833 [D loss: 0.670508, acc.: 59.38%] [G loss: 0.902992]\n",
      "epoch:8 step:7834 [D loss: 0.684474, acc.: 57.81%] [G loss: 0.830675]\n",
      "epoch:8 step:7835 [D loss: 0.681707, acc.: 54.69%] [G loss: 0.863951]\n",
      "epoch:8 step:7836 [D loss: 0.673717, acc.: 56.25%] [G loss: 0.901467]\n",
      "epoch:8 step:7837 [D loss: 0.648564, acc.: 64.84%] [G loss: 0.866224]\n",
      "epoch:8 step:7838 [D loss: 0.657473, acc.: 64.84%] [G loss: 0.876103]\n",
      "epoch:8 step:7839 [D loss: 0.672545, acc.: 57.03%] [G loss: 0.872059]\n",
      "epoch:8 step:7840 [D loss: 0.653402, acc.: 65.62%] [G loss: 0.834626]\n",
      "epoch:8 step:7841 [D loss: 0.695333, acc.: 50.78%] [G loss: 0.887566]\n",
      "epoch:8 step:7842 [D loss: 0.680943, acc.: 60.16%] [G loss: 0.863266]\n",
      "epoch:8 step:7843 [D loss: 0.638207, acc.: 61.72%] [G loss: 0.908463]\n",
      "epoch:8 step:7844 [D loss: 0.650883, acc.: 62.50%] [G loss: 0.882639]\n",
      "epoch:8 step:7845 [D loss: 0.641984, acc.: 62.50%] [G loss: 0.852614]\n",
      "epoch:8 step:7846 [D loss: 0.690526, acc.: 46.09%] [G loss: 0.833455]\n",
      "epoch:8 step:7847 [D loss: 0.654983, acc.: 67.19%] [G loss: 0.829109]\n",
      "epoch:8 step:7848 [D loss: 0.690241, acc.: 47.66%] [G loss: 0.834718]\n",
      "epoch:8 step:7849 [D loss: 0.664306, acc.: 56.25%] [G loss: 0.887793]\n",
      "epoch:8 step:7850 [D loss: 0.704645, acc.: 52.34%] [G loss: 0.801326]\n",
      "epoch:8 step:7851 [D loss: 0.665861, acc.: 57.03%] [G loss: 0.854101]\n",
      "epoch:8 step:7852 [D loss: 0.648581, acc.: 59.38%] [G loss: 0.809240]\n",
      "epoch:8 step:7853 [D loss: 0.661961, acc.: 60.94%] [G loss: 0.873865]\n",
      "epoch:8 step:7854 [D loss: 0.648675, acc.: 63.28%] [G loss: 0.826207]\n",
      "epoch:8 step:7855 [D loss: 0.677300, acc.: 53.91%] [G loss: 0.843359]\n",
      "epoch:8 step:7856 [D loss: 0.644121, acc.: 59.38%] [G loss: 0.883370]\n",
      "epoch:8 step:7857 [D loss: 0.689735, acc.: 54.69%] [G loss: 0.796484]\n",
      "epoch:8 step:7858 [D loss: 0.680787, acc.: 59.38%] [G loss: 0.830292]\n",
      "epoch:8 step:7859 [D loss: 0.667583, acc.: 53.12%] [G loss: 0.793112]\n",
      "epoch:8 step:7860 [D loss: 0.690318, acc.: 53.91%] [G loss: 0.856560]\n",
      "epoch:8 step:7861 [D loss: 0.664791, acc.: 63.28%] [G loss: 0.842612]\n",
      "epoch:8 step:7862 [D loss: 0.677936, acc.: 57.03%] [G loss: 0.838519]\n",
      "epoch:8 step:7863 [D loss: 0.659995, acc.: 60.94%] [G loss: 0.828121]\n",
      "epoch:8 step:7864 [D loss: 0.667802, acc.: 57.81%] [G loss: 0.808811]\n",
      "epoch:8 step:7865 [D loss: 0.668961, acc.: 61.72%] [G loss: 0.822233]\n",
      "epoch:8 step:7866 [D loss: 0.662192, acc.: 63.28%] [G loss: 0.840542]\n",
      "epoch:8 step:7867 [D loss: 0.671458, acc.: 58.59%] [G loss: 0.833366]\n",
      "epoch:8 step:7868 [D loss: 0.649178, acc.: 62.50%] [G loss: 0.824583]\n",
      "epoch:8 step:7869 [D loss: 0.689555, acc.: 53.91%] [G loss: 0.858671]\n",
      "epoch:8 step:7870 [D loss: 0.679942, acc.: 56.25%] [G loss: 0.877019]\n",
      "epoch:8 step:7871 [D loss: 0.677049, acc.: 62.50%] [G loss: 0.838217]\n",
      "epoch:8 step:7872 [D loss: 0.701310, acc.: 48.44%] [G loss: 0.830257]\n",
      "epoch:8 step:7873 [D loss: 0.672239, acc.: 58.59%] [G loss: 0.866630]\n",
      "epoch:8 step:7874 [D loss: 0.624738, acc.: 68.75%] [G loss: 0.841816]\n",
      "epoch:8 step:7875 [D loss: 0.655038, acc.: 60.16%] [G loss: 0.863210]\n",
      "epoch:8 step:7876 [D loss: 0.631258, acc.: 66.41%] [G loss: 0.812082]\n",
      "epoch:8 step:7877 [D loss: 0.688137, acc.: 58.59%] [G loss: 0.870394]\n",
      "epoch:8 step:7878 [D loss: 0.649138, acc.: 65.62%] [G loss: 0.851907]\n",
      "epoch:8 step:7879 [D loss: 0.671036, acc.: 60.94%] [G loss: 0.878496]\n",
      "epoch:8 step:7880 [D loss: 0.679714, acc.: 55.47%] [G loss: 0.852306]\n",
      "epoch:8 step:7881 [D loss: 0.697125, acc.: 50.00%] [G loss: 0.842279]\n",
      "epoch:8 step:7882 [D loss: 0.676646, acc.: 55.47%] [G loss: 0.839089]\n",
      "epoch:8 step:7883 [D loss: 0.702826, acc.: 55.47%] [G loss: 0.853028]\n",
      "epoch:8 step:7884 [D loss: 0.679179, acc.: 55.47%] [G loss: 0.844071]\n",
      "epoch:8 step:7885 [D loss: 0.665770, acc.: 59.38%] [G loss: 0.848195]\n",
      "epoch:8 step:7886 [D loss: 0.660991, acc.: 60.16%] [G loss: 0.846500]\n",
      "epoch:8 step:7887 [D loss: 0.669542, acc.: 57.81%] [G loss: 0.836905]\n",
      "epoch:8 step:7888 [D loss: 0.677099, acc.: 60.16%] [G loss: 0.813466]\n",
      "epoch:8 step:7889 [D loss: 0.682339, acc.: 58.59%] [G loss: 0.887422]\n",
      "epoch:8 step:7890 [D loss: 0.679063, acc.: 55.47%] [G loss: 0.834565]\n",
      "epoch:8 step:7891 [D loss: 0.692274, acc.: 53.91%] [G loss: 0.821741]\n",
      "epoch:8 step:7892 [D loss: 0.646290, acc.: 59.38%] [G loss: 0.776503]\n",
      "epoch:8 step:7893 [D loss: 0.670782, acc.: 57.03%] [G loss: 0.822582]\n",
      "epoch:8 step:7894 [D loss: 0.663815, acc.: 59.38%] [G loss: 0.826510]\n",
      "epoch:8 step:7895 [D loss: 0.665505, acc.: 58.59%] [G loss: 0.897551]\n",
      "epoch:8 step:7896 [D loss: 0.664551, acc.: 63.28%] [G loss: 0.843991]\n",
      "epoch:8 step:7897 [D loss: 0.634403, acc.: 57.81%] [G loss: 0.914775]\n",
      "epoch:8 step:7898 [D loss: 0.611808, acc.: 71.88%] [G loss: 0.889106]\n",
      "epoch:8 step:7899 [D loss: 0.660447, acc.: 60.94%] [G loss: 0.905759]\n",
      "epoch:8 step:7900 [D loss: 0.638397, acc.: 64.06%] [G loss: 0.867609]\n",
      "epoch:8 step:7901 [D loss: 0.689851, acc.: 62.50%] [G loss: 0.825132]\n",
      "epoch:8 step:7902 [D loss: 0.667994, acc.: 53.12%] [G loss: 0.822943]\n",
      "epoch:8 step:7903 [D loss: 0.685541, acc.: 57.81%] [G loss: 0.852312]\n",
      "epoch:8 step:7904 [D loss: 0.653264, acc.: 60.16%] [G loss: 0.862603]\n",
      "epoch:8 step:7905 [D loss: 0.671853, acc.: 51.56%] [G loss: 0.884110]\n",
      "epoch:8 step:7906 [D loss: 0.691543, acc.: 51.56%] [G loss: 0.830497]\n",
      "epoch:8 step:7907 [D loss: 0.649673, acc.: 61.72%] [G loss: 0.860181]\n",
      "epoch:8 step:7908 [D loss: 0.673533, acc.: 59.38%] [G loss: 0.854154]\n",
      "epoch:8 step:7909 [D loss: 0.674464, acc.: 57.03%] [G loss: 0.876216]\n",
      "epoch:8 step:7910 [D loss: 0.659937, acc.: 60.94%] [G loss: 0.850088]\n",
      "epoch:8 step:7911 [D loss: 0.668632, acc.: 57.03%] [G loss: 0.858702]\n",
      "epoch:8 step:7912 [D loss: 0.644653, acc.: 60.16%] [G loss: 0.849953]\n",
      "epoch:8 step:7913 [D loss: 0.644712, acc.: 66.41%] [G loss: 0.869187]\n",
      "epoch:8 step:7914 [D loss: 0.675117, acc.: 58.59%] [G loss: 0.834883]\n",
      "epoch:8 step:7915 [D loss: 0.668741, acc.: 56.25%] [G loss: 0.808009]\n",
      "epoch:8 step:7916 [D loss: 0.636328, acc.: 67.97%] [G loss: 0.823606]\n",
      "epoch:8 step:7917 [D loss: 0.626358, acc.: 64.06%] [G loss: 0.836394]\n",
      "epoch:8 step:7918 [D loss: 0.700782, acc.: 52.34%] [G loss: 0.867945]\n",
      "epoch:8 step:7919 [D loss: 0.666711, acc.: 57.81%] [G loss: 0.845312]\n",
      "epoch:8 step:7920 [D loss: 0.670785, acc.: 58.59%] [G loss: 0.870220]\n",
      "epoch:8 step:7921 [D loss: 0.676679, acc.: 56.25%] [G loss: 0.858256]\n",
      "epoch:8 step:7922 [D loss: 0.668333, acc.: 53.12%] [G loss: 0.902947]\n",
      "epoch:8 step:7923 [D loss: 0.695832, acc.: 52.34%] [G loss: 0.869463]\n",
      "epoch:8 step:7924 [D loss: 0.685111, acc.: 57.81%] [G loss: 0.876649]\n",
      "epoch:8 step:7925 [D loss: 0.685908, acc.: 57.03%] [G loss: 0.879552]\n",
      "epoch:8 step:7926 [D loss: 0.683528, acc.: 52.34%] [G loss: 0.862712]\n",
      "epoch:8 step:7927 [D loss: 0.647676, acc.: 57.81%] [G loss: 0.880869]\n",
      "epoch:8 step:7928 [D loss: 0.654390, acc.: 61.72%] [G loss: 0.875285]\n",
      "epoch:8 step:7929 [D loss: 0.657909, acc.: 65.62%] [G loss: 0.867876]\n",
      "epoch:8 step:7930 [D loss: 0.674870, acc.: 60.94%] [G loss: 0.845158]\n",
      "epoch:8 step:7931 [D loss: 0.653598, acc.: 59.38%] [G loss: 0.862697]\n",
      "epoch:8 step:7932 [D loss: 0.653592, acc.: 61.72%] [G loss: 0.876463]\n",
      "epoch:8 step:7933 [D loss: 0.674573, acc.: 53.12%] [G loss: 0.870650]\n",
      "epoch:8 step:7934 [D loss: 0.683104, acc.: 56.25%] [G loss: 0.884228]\n",
      "epoch:8 step:7935 [D loss: 0.642498, acc.: 67.97%] [G loss: 0.882317]\n",
      "epoch:8 step:7936 [D loss: 0.697363, acc.: 54.69%] [G loss: 0.863287]\n",
      "epoch:8 step:7937 [D loss: 0.683530, acc.: 56.25%] [G loss: 0.831587]\n",
      "epoch:8 step:7938 [D loss: 0.659920, acc.: 60.94%] [G loss: 0.826236]\n",
      "epoch:8 step:7939 [D loss: 0.685425, acc.: 53.91%] [G loss: 0.831951]\n",
      "epoch:8 step:7940 [D loss: 0.677741, acc.: 52.34%] [G loss: 0.817340]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:7941 [D loss: 0.665413, acc.: 54.69%] [G loss: 0.854331]\n",
      "epoch:8 step:7942 [D loss: 0.698762, acc.: 50.00%] [G loss: 0.836141]\n",
      "epoch:8 step:7943 [D loss: 0.650886, acc.: 59.38%] [G loss: 0.889592]\n",
      "epoch:8 step:7944 [D loss: 0.653631, acc.: 59.38%] [G loss: 0.903964]\n",
      "epoch:8 step:7945 [D loss: 0.654166, acc.: 57.03%] [G loss: 0.828501]\n",
      "epoch:8 step:7946 [D loss: 0.657111, acc.: 63.28%] [G loss: 0.845212]\n",
      "epoch:8 step:7947 [D loss: 0.684510, acc.: 59.38%] [G loss: 0.820515]\n",
      "epoch:8 step:7948 [D loss: 0.678984, acc.: 59.38%] [G loss: 0.851356]\n",
      "epoch:8 step:7949 [D loss: 0.648793, acc.: 64.06%] [G loss: 0.853464]\n",
      "epoch:8 step:7950 [D loss: 0.635347, acc.: 64.06%] [G loss: 0.890021]\n",
      "epoch:8 step:7951 [D loss: 0.663558, acc.: 61.72%] [G loss: 0.906344]\n",
      "epoch:8 step:7952 [D loss: 0.657531, acc.: 67.19%] [G loss: 0.860818]\n",
      "epoch:8 step:7953 [D loss: 0.671263, acc.: 60.94%] [G loss: 0.871057]\n",
      "epoch:8 step:7954 [D loss: 0.657288, acc.: 62.50%] [G loss: 0.864547]\n",
      "epoch:8 step:7955 [D loss: 0.617244, acc.: 71.09%] [G loss: 0.876147]\n",
      "epoch:8 step:7956 [D loss: 0.638816, acc.: 67.19%] [G loss: 0.838450]\n",
      "epoch:8 step:7957 [D loss: 0.680923, acc.: 56.25%] [G loss: 0.823308]\n",
      "epoch:8 step:7958 [D loss: 0.697174, acc.: 55.47%] [G loss: 0.867080]\n",
      "epoch:8 step:7959 [D loss: 0.668279, acc.: 59.38%] [G loss: 0.831324]\n",
      "epoch:8 step:7960 [D loss: 0.665713, acc.: 60.16%] [G loss: 0.856007]\n",
      "epoch:8 step:7961 [D loss: 0.695593, acc.: 54.69%] [G loss: 0.831323]\n",
      "epoch:8 step:7962 [D loss: 0.654677, acc.: 61.72%] [G loss: 0.905058]\n",
      "epoch:8 step:7963 [D loss: 0.652599, acc.: 61.72%] [G loss: 0.850462]\n",
      "epoch:8 step:7964 [D loss: 0.668433, acc.: 60.94%] [G loss: 0.857788]\n",
      "epoch:8 step:7965 [D loss: 0.665269, acc.: 59.38%] [G loss: 0.836576]\n",
      "epoch:8 step:7966 [D loss: 0.670788, acc.: 55.47%] [G loss: 0.815338]\n",
      "epoch:8 step:7967 [D loss: 0.686449, acc.: 59.38%] [G loss: 0.814941]\n",
      "epoch:8 step:7968 [D loss: 0.607185, acc.: 69.53%] [G loss: 0.873326]\n",
      "epoch:8 step:7969 [D loss: 0.699046, acc.: 51.56%] [G loss: 0.893383]\n",
      "epoch:8 step:7970 [D loss: 0.664532, acc.: 57.03%] [G loss: 0.887901]\n",
      "epoch:8 step:7971 [D loss: 0.632020, acc.: 64.06%] [G loss: 0.880382]\n",
      "epoch:8 step:7972 [D loss: 0.657598, acc.: 63.28%] [G loss: 0.889904]\n",
      "epoch:8 step:7973 [D loss: 0.668336, acc.: 57.03%] [G loss: 0.818375]\n",
      "epoch:8 step:7974 [D loss: 0.686131, acc.: 60.94%] [G loss: 0.851439]\n",
      "epoch:8 step:7975 [D loss: 0.665993, acc.: 58.59%] [G loss: 0.835677]\n",
      "epoch:8 step:7976 [D loss: 0.661927, acc.: 56.25%] [G loss: 0.833886]\n",
      "epoch:8 step:7977 [D loss: 0.687885, acc.: 53.12%] [G loss: 0.820223]\n",
      "epoch:8 step:7978 [D loss: 0.666696, acc.: 57.03%] [G loss: 0.870934]\n",
      "epoch:8 step:7979 [D loss: 0.667278, acc.: 58.59%] [G loss: 0.902262]\n",
      "epoch:8 step:7980 [D loss: 0.648802, acc.: 66.41%] [G loss: 0.841309]\n",
      "epoch:8 step:7981 [D loss: 0.686940, acc.: 53.12%] [G loss: 0.835499]\n",
      "epoch:8 step:7982 [D loss: 0.660099, acc.: 56.25%] [G loss: 0.815438]\n",
      "epoch:8 step:7983 [D loss: 0.709477, acc.: 47.66%] [G loss: 0.844750]\n",
      "epoch:8 step:7984 [D loss: 0.640610, acc.: 62.50%] [G loss: 0.871835]\n",
      "epoch:8 step:7985 [D loss: 0.687831, acc.: 60.16%] [G loss: 0.863330]\n",
      "epoch:8 step:7986 [D loss: 0.676790, acc.: 56.25%] [G loss: 0.847862]\n",
      "epoch:8 step:7987 [D loss: 0.629437, acc.: 63.28%] [G loss: 0.868191]\n",
      "epoch:8 step:7988 [D loss: 0.636861, acc.: 61.72%] [G loss: 0.790629]\n",
      "epoch:8 step:7989 [D loss: 0.675888, acc.: 58.59%] [G loss: 0.847113]\n",
      "epoch:8 step:7990 [D loss: 0.610187, acc.: 67.97%] [G loss: 0.893966]\n",
      "epoch:8 step:7991 [D loss: 0.700450, acc.: 53.12%] [G loss: 0.864308]\n",
      "epoch:8 step:7992 [D loss: 0.661115, acc.: 57.03%] [G loss: 0.866037]\n",
      "epoch:8 step:7993 [D loss: 0.627763, acc.: 64.84%] [G loss: 0.840110]\n",
      "epoch:8 step:7994 [D loss: 0.671546, acc.: 60.94%] [G loss: 0.882207]\n",
      "epoch:8 step:7995 [D loss: 0.645555, acc.: 60.94%] [G loss: 0.869073]\n",
      "epoch:8 step:7996 [D loss: 0.661211, acc.: 61.72%] [G loss: 0.838556]\n",
      "epoch:8 step:7997 [D loss: 0.674152, acc.: 64.84%] [G loss: 0.814732]\n",
      "epoch:8 step:7998 [D loss: 0.665976, acc.: 58.59%] [G loss: 0.894575]\n",
      "epoch:8 step:7999 [D loss: 0.647904, acc.: 60.94%] [G loss: 0.826858]\n",
      "epoch:8 step:8000 [D loss: 0.685642, acc.: 59.38%] [G loss: 0.826849]\n",
      "##############\n",
      "[3.134591   2.33186918 2.56579708 3.42847155 1.75183078 7.69713721\n",
      " 2.86533151 4.00777783 4.17896891 8.14868929]\n",
      "##########\n",
      "epoch:8 step:8001 [D loss: 0.645102, acc.: 66.41%] [G loss: 0.833089]\n",
      "epoch:8 step:8002 [D loss: 0.676118, acc.: 56.25%] [G loss: 0.854671]\n",
      "epoch:8 step:8003 [D loss: 0.700612, acc.: 52.34%] [G loss: 0.828349]\n",
      "epoch:8 step:8004 [D loss: 0.715622, acc.: 52.34%] [G loss: 0.835156]\n",
      "epoch:8 step:8005 [D loss: 0.672578, acc.: 59.38%] [G loss: 0.838540]\n",
      "epoch:8 step:8006 [D loss: 0.682304, acc.: 57.81%] [G loss: 0.857972]\n",
      "epoch:8 step:8007 [D loss: 0.682556, acc.: 53.91%] [G loss: 0.890789]\n",
      "epoch:8 step:8008 [D loss: 0.686217, acc.: 57.03%] [G loss: 0.886421]\n",
      "epoch:8 step:8009 [D loss: 0.691967, acc.: 47.66%] [G loss: 0.863097]\n",
      "epoch:8 step:8010 [D loss: 0.685948, acc.: 60.16%] [G loss: 0.886187]\n",
      "epoch:8 step:8011 [D loss: 0.663780, acc.: 63.28%] [G loss: 0.837389]\n",
      "epoch:8 step:8012 [D loss: 0.635533, acc.: 61.72%] [G loss: 0.854056]\n",
      "epoch:8 step:8013 [D loss: 0.656767, acc.: 55.47%] [G loss: 0.880875]\n",
      "epoch:8 step:8014 [D loss: 0.657520, acc.: 63.28%] [G loss: 0.895274]\n",
      "epoch:8 step:8015 [D loss: 0.657364, acc.: 59.38%] [G loss: 0.833114]\n",
      "epoch:8 step:8016 [D loss: 0.654611, acc.: 66.41%] [G loss: 0.867631]\n",
      "epoch:8 step:8017 [D loss: 0.677769, acc.: 58.59%] [G loss: 0.872305]\n",
      "epoch:8 step:8018 [D loss: 0.640035, acc.: 66.41%] [G loss: 0.802830]\n",
      "epoch:8 step:8019 [D loss: 0.646806, acc.: 64.84%] [G loss: 0.822540]\n",
      "epoch:8 step:8020 [D loss: 0.648429, acc.: 66.41%] [G loss: 0.847599]\n",
      "epoch:8 step:8021 [D loss: 0.652021, acc.: 57.81%] [G loss: 0.823842]\n",
      "epoch:8 step:8022 [D loss: 0.661647, acc.: 63.28%] [G loss: 0.834704]\n",
      "epoch:8 step:8023 [D loss: 0.692152, acc.: 57.03%] [G loss: 0.794506]\n",
      "epoch:8 step:8024 [D loss: 0.664454, acc.: 56.25%] [G loss: 0.785538]\n",
      "epoch:8 step:8025 [D loss: 0.709916, acc.: 53.12%] [G loss: 0.815172]\n",
      "epoch:8 step:8026 [D loss: 0.624230, acc.: 67.19%] [G loss: 0.838834]\n",
      "epoch:8 step:8027 [D loss: 0.696341, acc.: 51.56%] [G loss: 0.824827]\n",
      "epoch:8 step:8028 [D loss: 0.664010, acc.: 60.94%] [G loss: 0.784973]\n",
      "epoch:8 step:8029 [D loss: 0.701714, acc.: 47.66%] [G loss: 0.838365]\n",
      "epoch:8 step:8030 [D loss: 0.646852, acc.: 64.06%] [G loss: 0.839350]\n",
      "epoch:8 step:8031 [D loss: 0.681013, acc.: 57.81%] [G loss: 0.849000]\n",
      "epoch:8 step:8032 [D loss: 0.662487, acc.: 58.59%] [G loss: 0.865775]\n",
      "epoch:8 step:8033 [D loss: 0.673915, acc.: 58.59%] [G loss: 0.819386]\n",
      "epoch:8 step:8034 [D loss: 0.720137, acc.: 51.56%] [G loss: 0.838404]\n",
      "epoch:8 step:8035 [D loss: 0.625380, acc.: 62.50%] [G loss: 0.851537]\n",
      "epoch:8 step:8036 [D loss: 0.668782, acc.: 60.94%] [G loss: 0.842418]\n",
      "epoch:8 step:8037 [D loss: 0.659327, acc.: 56.25%] [G loss: 0.841066]\n",
      "epoch:8 step:8038 [D loss: 0.662933, acc.: 57.03%] [G loss: 0.852230]\n",
      "epoch:8 step:8039 [D loss: 0.703319, acc.: 56.25%] [G loss: 0.885229]\n",
      "epoch:8 step:8040 [D loss: 0.641797, acc.: 66.41%] [G loss: 0.853138]\n",
      "epoch:8 step:8041 [D loss: 0.685337, acc.: 53.91%] [G loss: 0.879909]\n",
      "epoch:8 step:8042 [D loss: 0.674429, acc.: 58.59%] [G loss: 0.881609]\n",
      "epoch:8 step:8043 [D loss: 0.669747, acc.: 55.47%] [G loss: 0.775792]\n",
      "epoch:8 step:8044 [D loss: 0.670509, acc.: 57.03%] [G loss: 0.832720]\n",
      "epoch:8 step:8045 [D loss: 0.708958, acc.: 51.56%] [G loss: 0.846850]\n",
      "epoch:8 step:8046 [D loss: 0.661590, acc.: 56.25%] [G loss: 0.810646]\n",
      "epoch:8 step:8047 [D loss: 0.687515, acc.: 57.03%] [G loss: 0.883828]\n",
      "epoch:8 step:8048 [D loss: 0.633184, acc.: 65.62%] [G loss: 0.888433]\n",
      "epoch:8 step:8049 [D loss: 0.732913, acc.: 48.44%] [G loss: 0.860154]\n",
      "epoch:8 step:8050 [D loss: 0.673600, acc.: 58.59%] [G loss: 0.847679]\n",
      "epoch:8 step:8051 [D loss: 0.672727, acc.: 51.56%] [G loss: 0.863986]\n",
      "epoch:8 step:8052 [D loss: 0.670494, acc.: 57.03%] [G loss: 0.855312]\n",
      "epoch:8 step:8053 [D loss: 0.663026, acc.: 63.28%] [G loss: 0.801283]\n",
      "epoch:8 step:8054 [D loss: 0.682119, acc.: 53.12%] [G loss: 0.821507]\n",
      "epoch:8 step:8055 [D loss: 0.716296, acc.: 46.09%] [G loss: 0.825906]\n",
      "epoch:8 step:8056 [D loss: 0.666554, acc.: 59.38%] [G loss: 0.874862]\n",
      "epoch:8 step:8057 [D loss: 0.666289, acc.: 58.59%] [G loss: 0.857645]\n",
      "epoch:8 step:8058 [D loss: 0.658841, acc.: 62.50%] [G loss: 0.834280]\n",
      "epoch:8 step:8059 [D loss: 0.682204, acc.: 57.81%] [G loss: 0.843247]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8060 [D loss: 0.663592, acc.: 62.50%] [G loss: 0.848897]\n",
      "epoch:8 step:8061 [D loss: 0.632069, acc.: 70.31%] [G loss: 0.862480]\n",
      "epoch:8 step:8062 [D loss: 0.655629, acc.: 60.94%] [G loss: 0.836815]\n",
      "epoch:8 step:8063 [D loss: 0.675753, acc.: 59.38%] [G loss: 0.882016]\n",
      "epoch:8 step:8064 [D loss: 0.696211, acc.: 55.47%] [G loss: 0.878352]\n",
      "epoch:8 step:8065 [D loss: 0.638946, acc.: 64.06%] [G loss: 0.891736]\n",
      "epoch:8 step:8066 [D loss: 0.695798, acc.: 53.91%] [G loss: 0.839288]\n",
      "epoch:8 step:8067 [D loss: 0.670706, acc.: 62.50%] [G loss: 0.869897]\n",
      "epoch:8 step:8068 [D loss: 0.670916, acc.: 53.91%] [G loss: 0.771395]\n",
      "epoch:8 step:8069 [D loss: 0.687031, acc.: 52.34%] [G loss: 0.779715]\n",
      "epoch:8 step:8070 [D loss: 0.684495, acc.: 51.56%] [G loss: 0.843000]\n",
      "epoch:8 step:8071 [D loss: 0.685926, acc.: 57.03%] [G loss: 0.859832]\n",
      "epoch:8 step:8072 [D loss: 0.667290, acc.: 58.59%] [G loss: 0.894075]\n",
      "epoch:8 step:8073 [D loss: 0.680755, acc.: 62.50%] [G loss: 0.806944]\n",
      "epoch:8 step:8074 [D loss: 0.677030, acc.: 53.91%] [G loss: 0.855918]\n",
      "epoch:8 step:8075 [D loss: 0.675163, acc.: 58.59%] [G loss: 0.888969]\n",
      "epoch:8 step:8076 [D loss: 0.674446, acc.: 57.03%] [G loss: 0.897987]\n",
      "epoch:8 step:8077 [D loss: 0.654383, acc.: 60.16%] [G loss: 0.896709]\n",
      "epoch:8 step:8078 [D loss: 0.633473, acc.: 69.53%] [G loss: 0.895111]\n",
      "epoch:8 step:8079 [D loss: 0.668660, acc.: 58.59%] [G loss: 0.922748]\n",
      "epoch:8 step:8080 [D loss: 0.660692, acc.: 60.16%] [G loss: 0.857265]\n",
      "epoch:8 step:8081 [D loss: 0.684295, acc.: 56.25%] [G loss: 0.908568]\n",
      "epoch:8 step:8082 [D loss: 0.710799, acc.: 58.59%] [G loss: 0.826681]\n",
      "epoch:8 step:8083 [D loss: 0.660588, acc.: 63.28%] [G loss: 0.838570]\n",
      "epoch:8 step:8084 [D loss: 0.663828, acc.: 58.59%] [G loss: 0.820175]\n",
      "epoch:8 step:8085 [D loss: 0.622278, acc.: 66.41%] [G loss: 0.812863]\n",
      "epoch:8 step:8086 [D loss: 0.682654, acc.: 57.03%] [G loss: 0.859877]\n",
      "epoch:8 step:8087 [D loss: 0.653623, acc.: 58.59%] [G loss: 0.835100]\n",
      "epoch:8 step:8088 [D loss: 0.676205, acc.: 53.12%] [G loss: 0.834036]\n",
      "epoch:8 step:8089 [D loss: 0.702827, acc.: 47.66%] [G loss: 0.840770]\n",
      "epoch:8 step:8090 [D loss: 0.637706, acc.: 64.84%] [G loss: 0.833408]\n",
      "epoch:8 step:8091 [D loss: 0.655465, acc.: 60.94%] [G loss: 0.828556]\n",
      "epoch:8 step:8092 [D loss: 0.665806, acc.: 60.16%] [G loss: 0.834972]\n",
      "epoch:8 step:8093 [D loss: 0.689173, acc.: 53.12%] [G loss: 0.830973]\n",
      "epoch:8 step:8094 [D loss: 0.678578, acc.: 60.16%] [G loss: 0.831160]\n",
      "epoch:8 step:8095 [D loss: 0.677948, acc.: 57.81%] [G loss: 0.798309]\n",
      "epoch:8 step:8096 [D loss: 0.661583, acc.: 61.72%] [G loss: 0.841568]\n",
      "epoch:8 step:8097 [D loss: 0.654357, acc.: 59.38%] [G loss: 0.861280]\n",
      "epoch:8 step:8098 [D loss: 0.656593, acc.: 62.50%] [G loss: 0.862568]\n",
      "epoch:8 step:8099 [D loss: 0.686031, acc.: 51.56%] [G loss: 0.809194]\n",
      "epoch:8 step:8100 [D loss: 0.692218, acc.: 51.56%] [G loss: 0.852684]\n",
      "epoch:8 step:8101 [D loss: 0.662032, acc.: 60.16%] [G loss: 0.825419]\n",
      "epoch:8 step:8102 [D loss: 0.688900, acc.: 57.81%] [G loss: 0.789598]\n",
      "epoch:8 step:8103 [D loss: 0.654428, acc.: 62.50%] [G loss: 0.836712]\n",
      "epoch:8 step:8104 [D loss: 0.671957, acc.: 58.59%] [G loss: 0.857799]\n",
      "epoch:8 step:8105 [D loss: 0.665649, acc.: 60.94%] [G loss: 0.855228]\n",
      "epoch:8 step:8106 [D loss: 0.667694, acc.: 60.16%] [G loss: 0.862396]\n",
      "epoch:8 step:8107 [D loss: 0.677793, acc.: 54.69%] [G loss: 0.857959]\n",
      "epoch:8 step:8108 [D loss: 0.689662, acc.: 53.12%] [G loss: 0.857175]\n",
      "epoch:8 step:8109 [D loss: 0.691209, acc.: 60.94%] [G loss: 0.842413]\n",
      "epoch:8 step:8110 [D loss: 0.647771, acc.: 67.97%] [G loss: 0.817145]\n",
      "epoch:8 step:8111 [D loss: 0.649139, acc.: 62.50%] [G loss: 0.815706]\n",
      "epoch:8 step:8112 [D loss: 0.645779, acc.: 63.28%] [G loss: 0.861487]\n",
      "epoch:8 step:8113 [D loss: 0.673658, acc.: 51.56%] [G loss: 0.861959]\n",
      "epoch:8 step:8114 [D loss: 0.668977, acc.: 60.16%] [G loss: 0.851973]\n",
      "epoch:8 step:8115 [D loss: 0.693580, acc.: 51.56%] [G loss: 0.827057]\n",
      "epoch:8 step:8116 [D loss: 0.675426, acc.: 55.47%] [G loss: 0.815744]\n",
      "epoch:8 step:8117 [D loss: 0.694255, acc.: 57.81%] [G loss: 0.776590]\n",
      "epoch:8 step:8118 [D loss: 0.662497, acc.: 63.28%] [G loss: 0.805014]\n",
      "epoch:8 step:8119 [D loss: 0.683084, acc.: 58.59%] [G loss: 0.858612]\n",
      "epoch:8 step:8120 [D loss: 0.646479, acc.: 60.16%] [G loss: 0.898665]\n",
      "epoch:8 step:8121 [D loss: 0.654984, acc.: 58.59%] [G loss: 0.833145]\n",
      "epoch:8 step:8122 [D loss: 0.684811, acc.: 57.81%] [G loss: 0.853548]\n",
      "epoch:8 step:8123 [D loss: 0.650426, acc.: 63.28%] [G loss: 0.831734]\n",
      "epoch:8 step:8124 [D loss: 0.670741, acc.: 55.47%] [G loss: 0.855511]\n",
      "epoch:8 step:8125 [D loss: 0.687702, acc.: 56.25%] [G loss: 0.868326]\n",
      "epoch:8 step:8126 [D loss: 0.679422, acc.: 51.56%] [G loss: 0.851658]\n",
      "epoch:8 step:8127 [D loss: 0.643192, acc.: 63.28%] [G loss: 0.825986]\n",
      "epoch:8 step:8128 [D loss: 0.697091, acc.: 49.22%] [G loss: 0.880905]\n",
      "epoch:8 step:8129 [D loss: 0.652450, acc.: 62.50%] [G loss: 0.863979]\n",
      "epoch:8 step:8130 [D loss: 0.677519, acc.: 57.03%] [G loss: 0.841776]\n",
      "epoch:8 step:8131 [D loss: 0.685771, acc.: 58.59%] [G loss: 0.826850]\n",
      "epoch:8 step:8132 [D loss: 0.642578, acc.: 64.84%] [G loss: 0.878748]\n",
      "epoch:8 step:8133 [D loss: 0.649064, acc.: 61.72%] [G loss: 0.872350]\n",
      "epoch:8 step:8134 [D loss: 0.645085, acc.: 60.16%] [G loss: 0.872722]\n",
      "epoch:8 step:8135 [D loss: 0.670530, acc.: 59.38%] [G loss: 0.845833]\n",
      "epoch:8 step:8136 [D loss: 0.660312, acc.: 58.59%] [G loss: 0.854241]\n",
      "epoch:8 step:8137 [D loss: 0.665738, acc.: 53.91%] [G loss: 0.866164]\n",
      "epoch:8 step:8138 [D loss: 0.699398, acc.: 50.00%] [G loss: 0.888380]\n",
      "epoch:8 step:8139 [D loss: 0.708491, acc.: 53.91%] [G loss: 0.801505]\n",
      "epoch:8 step:8140 [D loss: 0.670810, acc.: 61.72%] [G loss: 0.829791]\n",
      "epoch:8 step:8141 [D loss: 0.683604, acc.: 53.12%] [G loss: 0.796784]\n",
      "epoch:8 step:8142 [D loss: 0.683105, acc.: 54.69%] [G loss: 0.807724]\n",
      "epoch:8 step:8143 [D loss: 0.667437, acc.: 56.25%] [G loss: 0.860975]\n",
      "epoch:8 step:8144 [D loss: 0.649758, acc.: 64.06%] [G loss: 0.865937]\n",
      "epoch:8 step:8145 [D loss: 0.656929, acc.: 62.50%] [G loss: 0.821757]\n",
      "epoch:8 step:8146 [D loss: 0.659836, acc.: 64.06%] [G loss: 0.869903]\n",
      "epoch:8 step:8147 [D loss: 0.672645, acc.: 53.91%] [G loss: 0.798735]\n",
      "epoch:8 step:8148 [D loss: 0.663264, acc.: 63.28%] [G loss: 0.813234]\n",
      "epoch:8 step:8149 [D loss: 0.628843, acc.: 67.19%] [G loss: 0.786469]\n",
      "epoch:8 step:8150 [D loss: 0.649733, acc.: 63.28%] [G loss: 0.855271]\n",
      "epoch:8 step:8151 [D loss: 0.703255, acc.: 51.56%] [G loss: 0.844262]\n",
      "epoch:8 step:8152 [D loss: 0.692246, acc.: 59.38%] [G loss: 0.872623]\n",
      "epoch:8 step:8153 [D loss: 0.687626, acc.: 55.47%] [G loss: 0.873662]\n",
      "epoch:8 step:8154 [D loss: 0.689556, acc.: 56.25%] [G loss: 0.843189]\n",
      "epoch:8 step:8155 [D loss: 0.668429, acc.: 60.16%] [G loss: 0.845773]\n",
      "epoch:8 step:8156 [D loss: 0.689533, acc.: 53.91%] [G loss: 0.874540]\n",
      "epoch:8 step:8157 [D loss: 0.661161, acc.: 59.38%] [G loss: 0.862270]\n",
      "epoch:8 step:8158 [D loss: 0.678229, acc.: 56.25%] [G loss: 0.876436]\n",
      "epoch:8 step:8159 [D loss: 0.701700, acc.: 52.34%] [G loss: 0.822248]\n",
      "epoch:8 step:8160 [D loss: 0.681462, acc.: 59.38%] [G loss: 0.873028]\n",
      "epoch:8 step:8161 [D loss: 0.684364, acc.: 59.38%] [G loss: 0.848615]\n",
      "epoch:8 step:8162 [D loss: 0.662132, acc.: 64.84%] [G loss: 0.834077]\n",
      "epoch:8 step:8163 [D loss: 0.672597, acc.: 61.72%] [G loss: 0.788934]\n",
      "epoch:8 step:8164 [D loss: 0.669332, acc.: 55.47%] [G loss: 0.864247]\n",
      "epoch:8 step:8165 [D loss: 0.646955, acc.: 60.16%] [G loss: 0.824395]\n",
      "epoch:8 step:8166 [D loss: 0.689270, acc.: 55.47%] [G loss: 0.850873]\n",
      "epoch:8 step:8167 [D loss: 0.672781, acc.: 52.34%] [G loss: 0.916795]\n",
      "epoch:8 step:8168 [D loss: 0.684949, acc.: 52.34%] [G loss: 0.879883]\n",
      "epoch:8 step:8169 [D loss: 0.688960, acc.: 55.47%] [G loss: 0.885250]\n",
      "epoch:8 step:8170 [D loss: 0.695147, acc.: 57.81%] [G loss: 0.772556]\n",
      "epoch:8 step:8171 [D loss: 0.652226, acc.: 60.94%] [G loss: 0.837311]\n",
      "epoch:8 step:8172 [D loss: 0.672942, acc.: 63.28%] [G loss: 0.842864]\n",
      "epoch:8 step:8173 [D loss: 0.668134, acc.: 58.59%] [G loss: 0.827617]\n",
      "epoch:8 step:8174 [D loss: 0.666954, acc.: 56.25%] [G loss: 0.812349]\n",
      "epoch:8 step:8175 [D loss: 0.665332, acc.: 53.12%] [G loss: 0.839410]\n",
      "epoch:8 step:8176 [D loss: 0.679028, acc.: 53.91%] [G loss: 0.809102]\n",
      "epoch:8 step:8177 [D loss: 0.662267, acc.: 55.47%] [G loss: 0.859205]\n",
      "epoch:8 step:8178 [D loss: 0.651837, acc.: 58.59%] [G loss: 0.829637]\n",
      "epoch:8 step:8179 [D loss: 0.680485, acc.: 54.69%] [G loss: 0.888922]\n",
      "epoch:8 step:8180 [D loss: 0.653276, acc.: 61.72%] [G loss: 0.858754]\n",
      "epoch:8 step:8181 [D loss: 0.655586, acc.: 60.94%] [G loss: 0.851026]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8182 [D loss: 0.647290, acc.: 63.28%] [G loss: 0.814501]\n",
      "epoch:8 step:8183 [D loss: 0.683840, acc.: 56.25%] [G loss: 0.783608]\n",
      "epoch:8 step:8184 [D loss: 0.685622, acc.: 58.59%] [G loss: 0.821592]\n",
      "epoch:8 step:8185 [D loss: 0.704617, acc.: 52.34%] [G loss: 0.880150]\n",
      "epoch:8 step:8186 [D loss: 0.658083, acc.: 61.72%] [G loss: 0.847071]\n",
      "epoch:8 step:8187 [D loss: 0.686135, acc.: 50.00%] [G loss: 0.833039]\n",
      "epoch:8 step:8188 [D loss: 0.645775, acc.: 61.72%] [G loss: 0.832135]\n",
      "epoch:8 step:8189 [D loss: 0.682072, acc.: 60.16%] [G loss: 0.827555]\n",
      "epoch:8 step:8190 [D loss: 0.669755, acc.: 60.94%] [G loss: 0.857605]\n",
      "epoch:8 step:8191 [D loss: 0.678202, acc.: 58.59%] [G loss: 0.803113]\n",
      "epoch:8 step:8192 [D loss: 0.643021, acc.: 61.72%] [G loss: 0.868572]\n",
      "epoch:8 step:8193 [D loss: 0.666225, acc.: 57.81%] [G loss: 0.841335]\n",
      "epoch:8 step:8194 [D loss: 0.648379, acc.: 64.84%] [G loss: 0.870841]\n",
      "epoch:8 step:8195 [D loss: 0.694518, acc.: 53.91%] [G loss: 0.836110]\n",
      "epoch:8 step:8196 [D loss: 0.685574, acc.: 53.91%] [G loss: 0.903410]\n",
      "epoch:8 step:8197 [D loss: 0.667087, acc.: 54.69%] [G loss: 0.877798]\n",
      "epoch:8 step:8198 [D loss: 0.665786, acc.: 57.03%] [G loss: 0.898087]\n",
      "epoch:8 step:8199 [D loss: 0.657703, acc.: 60.94%] [G loss: 0.901232]\n",
      "epoch:8 step:8200 [D loss: 0.682896, acc.: 49.22%] [G loss: 0.859808]\n",
      "##############\n",
      "[ 2.95929443  2.58030997  2.22957307  4.61060712  1.17078921 10.27426719\n",
      "  3.20017876  4.59232368  4.18865123  7.14868929]\n",
      "##########\n",
      "epoch:8 step:8201 [D loss: 0.682212, acc.: 52.34%] [G loss: 0.849666]\n",
      "epoch:8 step:8202 [D loss: 0.686214, acc.: 60.16%] [G loss: 0.837107]\n",
      "epoch:8 step:8203 [D loss: 0.666728, acc.: 62.50%] [G loss: 0.804978]\n",
      "epoch:8 step:8204 [D loss: 0.661371, acc.: 63.28%] [G loss: 0.822166]\n",
      "epoch:8 step:8205 [D loss: 0.689820, acc.: 54.69%] [G loss: 0.884283]\n",
      "epoch:8 step:8206 [D loss: 0.634544, acc.: 64.06%] [G loss: 0.850011]\n",
      "epoch:8 step:8207 [D loss: 0.675671, acc.: 60.16%] [G loss: 0.792616]\n",
      "epoch:8 step:8208 [D loss: 0.672443, acc.: 63.28%] [G loss: 0.841170]\n",
      "epoch:8 step:8209 [D loss: 0.667627, acc.: 57.81%] [G loss: 0.881261]\n",
      "epoch:8 step:8210 [D loss: 0.672377, acc.: 59.38%] [G loss: 0.860737]\n",
      "epoch:8 step:8211 [D loss: 0.685644, acc.: 52.34%] [G loss: 0.876638]\n",
      "epoch:8 step:8212 [D loss: 0.670916, acc.: 59.38%] [G loss: 0.822606]\n",
      "epoch:8 step:8213 [D loss: 0.686514, acc.: 57.03%] [G loss: 0.825051]\n",
      "epoch:8 step:8214 [D loss: 0.687611, acc.: 53.12%] [G loss: 0.840759]\n",
      "epoch:8 step:8215 [D loss: 0.631140, acc.: 65.62%] [G loss: 0.773116]\n",
      "epoch:8 step:8216 [D loss: 0.673500, acc.: 53.12%] [G loss: 0.803017]\n",
      "epoch:8 step:8217 [D loss: 0.691175, acc.: 55.47%] [G loss: 0.827200]\n",
      "epoch:8 step:8218 [D loss: 0.666928, acc.: 53.91%] [G loss: 0.839398]\n",
      "epoch:8 step:8219 [D loss: 0.678368, acc.: 55.47%] [G loss: 0.844967]\n",
      "epoch:8 step:8220 [D loss: 0.723148, acc.: 52.34%] [G loss: 0.808058]\n",
      "epoch:8 step:8221 [D loss: 0.671527, acc.: 57.03%] [G loss: 0.872944]\n",
      "epoch:8 step:8222 [D loss: 0.670894, acc.: 60.16%] [G loss: 0.896672]\n",
      "epoch:8 step:8223 [D loss: 0.683162, acc.: 53.91%] [G loss: 0.907902]\n",
      "epoch:8 step:8224 [D loss: 0.677246, acc.: 55.47%] [G loss: 0.843400]\n",
      "epoch:8 step:8225 [D loss: 0.703633, acc.: 53.91%] [G loss: 0.848255]\n",
      "epoch:8 step:8226 [D loss: 0.685236, acc.: 57.03%] [G loss: 0.835225]\n",
      "epoch:8 step:8227 [D loss: 0.672867, acc.: 60.16%] [G loss: 0.848735]\n",
      "epoch:8 step:8228 [D loss: 0.671042, acc.: 56.25%] [G loss: 0.785992]\n",
      "epoch:8 step:8229 [D loss: 0.669587, acc.: 63.28%] [G loss: 0.846305]\n",
      "epoch:8 step:8230 [D loss: 0.662028, acc.: 57.03%] [G loss: 0.864933]\n",
      "epoch:8 step:8231 [D loss: 0.672278, acc.: 55.47%] [G loss: 0.861136]\n",
      "epoch:8 step:8232 [D loss: 0.675091, acc.: 54.69%] [G loss: 0.849821]\n",
      "epoch:8 step:8233 [D loss: 0.713577, acc.: 48.44%] [G loss: 0.877545]\n",
      "epoch:8 step:8234 [D loss: 0.718113, acc.: 44.53%] [G loss: 0.890013]\n",
      "epoch:8 step:8235 [D loss: 0.664129, acc.: 59.38%] [G loss: 0.823708]\n",
      "epoch:8 step:8236 [D loss: 0.690883, acc.: 55.47%] [G loss: 0.820673]\n",
      "epoch:8 step:8237 [D loss: 0.666606, acc.: 55.47%] [G loss: 0.811220]\n",
      "epoch:8 step:8238 [D loss: 0.692088, acc.: 52.34%] [G loss: 0.803090]\n",
      "epoch:8 step:8239 [D loss: 0.664537, acc.: 60.94%] [G loss: 0.848917]\n",
      "epoch:8 step:8240 [D loss: 0.674217, acc.: 57.81%] [G loss: 0.864580]\n",
      "epoch:8 step:8241 [D loss: 0.680040, acc.: 61.72%] [G loss: 0.850504]\n",
      "epoch:8 step:8242 [D loss: 0.682628, acc.: 57.03%] [G loss: 0.874548]\n",
      "epoch:8 step:8243 [D loss: 0.675188, acc.: 60.94%] [G loss: 0.854315]\n",
      "epoch:8 step:8244 [D loss: 0.666795, acc.: 60.94%] [G loss: 0.853159]\n",
      "epoch:8 step:8245 [D loss: 0.659819, acc.: 64.06%] [G loss: 0.821098]\n",
      "epoch:8 step:8246 [D loss: 0.677053, acc.: 61.72%] [G loss: 0.859720]\n",
      "epoch:8 step:8247 [D loss: 0.635400, acc.: 67.19%] [G loss: 0.823876]\n",
      "epoch:8 step:8248 [D loss: 0.678930, acc.: 55.47%] [G loss: 0.818629]\n",
      "epoch:8 step:8249 [D loss: 0.675974, acc.: 54.69%] [G loss: 0.852132]\n",
      "epoch:8 step:8250 [D loss: 0.674510, acc.: 57.81%] [G loss: 0.860007]\n",
      "epoch:8 step:8251 [D loss: 0.630117, acc.: 68.75%] [G loss: 0.904200]\n",
      "epoch:8 step:8252 [D loss: 0.666362, acc.: 59.38%] [G loss: 0.892192]\n",
      "epoch:8 step:8253 [D loss: 0.658136, acc.: 64.06%] [G loss: 0.845698]\n",
      "epoch:8 step:8254 [D loss: 0.684981, acc.: 50.78%] [G loss: 0.827490]\n",
      "epoch:8 step:8255 [D loss: 0.693084, acc.: 61.72%] [G loss: 0.846683]\n",
      "epoch:8 step:8256 [D loss: 0.702174, acc.: 50.78%] [G loss: 0.911797]\n",
      "epoch:8 step:8257 [D loss: 0.731073, acc.: 46.88%] [G loss: 0.882849]\n",
      "epoch:8 step:8258 [D loss: 0.677136, acc.: 55.47%] [G loss: 0.911109]\n",
      "epoch:8 step:8259 [D loss: 0.676246, acc.: 60.16%] [G loss: 0.915610]\n",
      "epoch:8 step:8260 [D loss: 0.622989, acc.: 66.41%] [G loss: 0.894577]\n",
      "epoch:8 step:8261 [D loss: 0.682937, acc.: 53.91%] [G loss: 0.875930]\n",
      "epoch:8 step:8262 [D loss: 0.707922, acc.: 60.16%] [G loss: 0.803484]\n",
      "epoch:8 step:8263 [D loss: 0.682027, acc.: 56.25%] [G loss: 0.827151]\n",
      "epoch:8 step:8264 [D loss: 0.671711, acc.: 60.94%] [G loss: 0.811846]\n",
      "epoch:8 step:8265 [D loss: 0.640888, acc.: 65.62%] [G loss: 0.780736]\n",
      "epoch:8 step:8266 [D loss: 0.631271, acc.: 68.75%] [G loss: 0.883790]\n",
      "epoch:8 step:8267 [D loss: 0.678960, acc.: 56.25%] [G loss: 0.850201]\n",
      "epoch:8 step:8268 [D loss: 0.677588, acc.: 59.38%] [G loss: 0.818289]\n",
      "epoch:8 step:8269 [D loss: 0.650338, acc.: 60.94%] [G loss: 0.836481]\n",
      "epoch:8 step:8270 [D loss: 0.658553, acc.: 60.94%] [G loss: 0.845239]\n",
      "epoch:8 step:8271 [D loss: 0.675518, acc.: 55.47%] [G loss: 0.935774]\n",
      "epoch:8 step:8272 [D loss: 0.641024, acc.: 63.28%] [G loss: 0.851542]\n",
      "epoch:8 step:8273 [D loss: 0.676285, acc.: 60.16%] [G loss: 0.836306]\n",
      "epoch:8 step:8274 [D loss: 0.686495, acc.: 57.81%] [G loss: 0.840421]\n",
      "epoch:8 step:8275 [D loss: 0.663197, acc.: 63.28%] [G loss: 0.885338]\n",
      "epoch:8 step:8276 [D loss: 0.701163, acc.: 54.69%] [G loss: 0.858884]\n",
      "epoch:8 step:8277 [D loss: 0.681316, acc.: 56.25%] [G loss: 0.828091]\n",
      "epoch:8 step:8278 [D loss: 0.668998, acc.: 61.72%] [G loss: 0.860705]\n",
      "epoch:8 step:8279 [D loss: 0.667238, acc.: 58.59%] [G loss: 0.851745]\n",
      "epoch:8 step:8280 [D loss: 0.679417, acc.: 56.25%] [G loss: 0.836969]\n",
      "epoch:8 step:8281 [D loss: 0.646550, acc.: 63.28%] [G loss: 0.842278]\n",
      "epoch:8 step:8282 [D loss: 0.689755, acc.: 57.03%] [G loss: 0.806966]\n",
      "epoch:8 step:8283 [D loss: 0.659798, acc.: 56.25%] [G loss: 0.803170]\n",
      "epoch:8 step:8284 [D loss: 0.664049, acc.: 59.38%] [G loss: 0.820008]\n",
      "epoch:8 step:8285 [D loss: 0.655614, acc.: 62.50%] [G loss: 0.822495]\n",
      "epoch:8 step:8286 [D loss: 0.662954, acc.: 60.16%] [G loss: 0.847934]\n",
      "epoch:8 step:8287 [D loss: 0.670046, acc.: 57.03%] [G loss: 0.868862]\n",
      "epoch:8 step:8288 [D loss: 0.674439, acc.: 63.28%] [G loss: 0.836862]\n",
      "epoch:8 step:8289 [D loss: 0.655208, acc.: 65.62%] [G loss: 0.816557]\n",
      "epoch:8 step:8290 [D loss: 0.646989, acc.: 63.28%] [G loss: 0.870001]\n",
      "epoch:8 step:8291 [D loss: 0.649027, acc.: 61.72%] [G loss: 0.826496]\n",
      "epoch:8 step:8292 [D loss: 0.657367, acc.: 57.03%] [G loss: 0.851679]\n",
      "epoch:8 step:8293 [D loss: 0.718353, acc.: 53.12%] [G loss: 0.864973]\n",
      "epoch:8 step:8294 [D loss: 0.675088, acc.: 59.38%] [G loss: 0.879219]\n",
      "epoch:8 step:8295 [D loss: 0.691208, acc.: 53.12%] [G loss: 0.886500]\n",
      "epoch:8 step:8296 [D loss: 0.662989, acc.: 63.28%] [G loss: 0.925906]\n",
      "epoch:8 step:8297 [D loss: 0.658907, acc.: 58.59%] [G loss: 0.871257]\n",
      "epoch:8 step:8298 [D loss: 0.677098, acc.: 57.03%] [G loss: 0.898105]\n",
      "epoch:8 step:8299 [D loss: 0.668236, acc.: 61.72%] [G loss: 0.850637]\n",
      "epoch:8 step:8300 [D loss: 0.678127, acc.: 52.34%] [G loss: 0.821461]\n",
      "epoch:8 step:8301 [D loss: 0.684019, acc.: 56.25%] [G loss: 0.791027]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8302 [D loss: 0.666784, acc.: 50.00%] [G loss: 0.893048]\n",
      "epoch:8 step:8303 [D loss: 0.649802, acc.: 64.06%] [G loss: 0.941873]\n",
      "epoch:8 step:8304 [D loss: 0.666795, acc.: 53.91%] [G loss: 0.871975]\n",
      "epoch:8 step:8305 [D loss: 0.662078, acc.: 58.59%] [G loss: 0.798287]\n",
      "epoch:8 step:8306 [D loss: 0.628787, acc.: 67.97%] [G loss: 0.792289]\n",
      "epoch:8 step:8307 [D loss: 0.655016, acc.: 60.16%] [G loss: 0.845202]\n",
      "epoch:8 step:8308 [D loss: 0.683421, acc.: 56.25%] [G loss: 0.870619]\n",
      "epoch:8 step:8309 [D loss: 0.642675, acc.: 58.59%] [G loss: 0.887306]\n",
      "epoch:8 step:8310 [D loss: 0.621873, acc.: 65.62%] [G loss: 0.878698]\n",
      "epoch:8 step:8311 [D loss: 0.711043, acc.: 53.12%] [G loss: 0.865030]\n",
      "epoch:8 step:8312 [D loss: 0.637132, acc.: 62.50%] [G loss: 0.826724]\n",
      "epoch:8 step:8313 [D loss: 0.681197, acc.: 55.47%] [G loss: 0.847840]\n",
      "epoch:8 step:8314 [D loss: 0.679028, acc.: 52.34%] [G loss: 0.851522]\n",
      "epoch:8 step:8315 [D loss: 0.670699, acc.: 57.03%] [G loss: 0.805758]\n",
      "epoch:8 step:8316 [D loss: 0.690584, acc.: 51.56%] [G loss: 0.805462]\n",
      "epoch:8 step:8317 [D loss: 0.649401, acc.: 53.91%] [G loss: 0.821724]\n",
      "epoch:8 step:8318 [D loss: 0.648307, acc.: 63.28%] [G loss: 0.896964]\n",
      "epoch:8 step:8319 [D loss: 0.791739, acc.: 39.06%] [G loss: 0.822548]\n",
      "epoch:8 step:8320 [D loss: 0.681460, acc.: 58.59%] [G loss: 0.820534]\n",
      "epoch:8 step:8321 [D loss: 0.649508, acc.: 62.50%] [G loss: 0.882998]\n",
      "epoch:8 step:8322 [D loss: 0.679393, acc.: 60.16%] [G loss: 0.867483]\n",
      "epoch:8 step:8323 [D loss: 0.666502, acc.: 59.38%] [G loss: 0.817355]\n",
      "epoch:8 step:8324 [D loss: 0.715227, acc.: 49.22%] [G loss: 0.847213]\n",
      "epoch:8 step:8325 [D loss: 0.646082, acc.: 62.50%] [G loss: 0.892736]\n",
      "epoch:8 step:8326 [D loss: 0.689273, acc.: 50.78%] [G loss: 0.802861]\n",
      "epoch:8 step:8327 [D loss: 0.705123, acc.: 48.44%] [G loss: 0.894579]\n",
      "epoch:8 step:8328 [D loss: 0.676856, acc.: 54.69%] [G loss: 0.866333]\n",
      "epoch:8 step:8329 [D loss: 0.681019, acc.: 57.03%] [G loss: 0.828543]\n",
      "epoch:8 step:8330 [D loss: 0.684745, acc.: 59.38%] [G loss: 0.812697]\n",
      "epoch:8 step:8331 [D loss: 0.691779, acc.: 57.03%] [G loss: 0.902884]\n",
      "epoch:8 step:8332 [D loss: 0.674573, acc.: 57.03%] [G loss: 0.797473]\n",
      "epoch:8 step:8333 [D loss: 0.656334, acc.: 63.28%] [G loss: 0.825463]\n",
      "epoch:8 step:8334 [D loss: 0.685742, acc.: 62.50%] [G loss: 0.808310]\n",
      "epoch:8 step:8335 [D loss: 0.657745, acc.: 64.06%] [G loss: 0.837934]\n",
      "epoch:8 step:8336 [D loss: 0.666467, acc.: 61.72%] [G loss: 0.840402]\n",
      "epoch:8 step:8337 [D loss: 0.682446, acc.: 53.12%] [G loss: 0.852169]\n",
      "epoch:8 step:8338 [D loss: 0.680089, acc.: 53.91%] [G loss: 0.862073]\n",
      "epoch:8 step:8339 [D loss: 0.693301, acc.: 56.25%] [G loss: 0.846687]\n",
      "epoch:8 step:8340 [D loss: 0.688132, acc.: 57.81%] [G loss: 0.809553]\n",
      "epoch:8 step:8341 [D loss: 0.692995, acc.: 49.22%] [G loss: 0.841923]\n",
      "epoch:8 step:8342 [D loss: 0.657505, acc.: 59.38%] [G loss: 0.841151]\n",
      "epoch:8 step:8343 [D loss: 0.661821, acc.: 57.03%] [G loss: 0.820059]\n",
      "epoch:8 step:8344 [D loss: 0.678308, acc.: 53.91%] [G loss: 0.870842]\n",
      "epoch:8 step:8345 [D loss: 0.642792, acc.: 66.41%] [G loss: 0.817878]\n",
      "epoch:8 step:8346 [D loss: 0.655098, acc.: 53.91%] [G loss: 0.840212]\n",
      "epoch:8 step:8347 [D loss: 0.686856, acc.: 55.47%] [G loss: 0.772048]\n",
      "epoch:8 step:8348 [D loss: 0.616832, acc.: 68.75%] [G loss: 0.833457]\n",
      "epoch:8 step:8349 [D loss: 0.656512, acc.: 64.84%] [G loss: 0.881455]\n",
      "epoch:8 step:8350 [D loss: 0.686229, acc.: 56.25%] [G loss: 0.852511]\n",
      "epoch:8 step:8351 [D loss: 0.708524, acc.: 45.31%] [G loss: 0.829902]\n",
      "epoch:8 step:8352 [D loss: 0.656596, acc.: 59.38%] [G loss: 0.838663]\n",
      "epoch:8 step:8353 [D loss: 0.675375, acc.: 60.94%] [G loss: 0.850674]\n",
      "epoch:8 step:8354 [D loss: 0.712711, acc.: 46.88%] [G loss: 0.869967]\n",
      "epoch:8 step:8355 [D loss: 0.643703, acc.: 67.97%] [G loss: 0.827419]\n",
      "epoch:8 step:8356 [D loss: 0.675126, acc.: 53.91%] [G loss: 0.833480]\n",
      "epoch:8 step:8357 [D loss: 0.677979, acc.: 61.72%] [G loss: 0.859475]\n",
      "epoch:8 step:8358 [D loss: 0.645827, acc.: 60.16%] [G loss: 0.857863]\n",
      "epoch:8 step:8359 [D loss: 0.666722, acc.: 61.72%] [G loss: 0.836788]\n",
      "epoch:8 step:8360 [D loss: 0.687018, acc.: 52.34%] [G loss: 0.829908]\n",
      "epoch:8 step:8361 [D loss: 0.670184, acc.: 57.81%] [G loss: 0.886388]\n",
      "epoch:8 step:8362 [D loss: 0.698415, acc.: 50.00%] [G loss: 0.844085]\n",
      "epoch:8 step:8363 [D loss: 0.692870, acc.: 59.38%] [G loss: 0.823807]\n",
      "epoch:8 step:8364 [D loss: 0.660956, acc.: 60.94%] [G loss: 0.786088]\n",
      "epoch:8 step:8365 [D loss: 0.666279, acc.: 57.03%] [G loss: 0.826666]\n",
      "epoch:8 step:8366 [D loss: 0.675181, acc.: 57.81%] [G loss: 0.843656]\n",
      "epoch:8 step:8367 [D loss: 0.666122, acc.: 58.59%] [G loss: 0.848581]\n",
      "epoch:8 step:8368 [D loss: 0.652082, acc.: 64.06%] [G loss: 0.851781]\n",
      "epoch:8 step:8369 [D loss: 0.670716, acc.: 54.69%] [G loss: 0.804677]\n",
      "epoch:8 step:8370 [D loss: 0.671080, acc.: 61.72%] [G loss: 0.823358]\n",
      "epoch:8 step:8371 [D loss: 0.667862, acc.: 61.72%] [G loss: 0.845867]\n",
      "epoch:8 step:8372 [D loss: 0.669952, acc.: 63.28%] [G loss: 0.822384]\n",
      "epoch:8 step:8373 [D loss: 0.672292, acc.: 57.03%] [G loss: 0.847939]\n",
      "epoch:8 step:8374 [D loss: 0.669578, acc.: 60.94%] [G loss: 0.852426]\n",
      "epoch:8 step:8375 [D loss: 0.678432, acc.: 57.81%] [G loss: 0.846393]\n",
      "epoch:8 step:8376 [D loss: 0.674585, acc.: 53.12%] [G loss: 0.840329]\n",
      "epoch:8 step:8377 [D loss: 0.659986, acc.: 60.16%] [G loss: 0.833167]\n",
      "epoch:8 step:8378 [D loss: 0.677973, acc.: 57.81%] [G loss: 0.845633]\n",
      "epoch:8 step:8379 [D loss: 0.681310, acc.: 59.38%] [G loss: 0.834077]\n",
      "epoch:8 step:8380 [D loss: 0.670395, acc.: 59.38%] [G loss: 0.868101]\n",
      "epoch:8 step:8381 [D loss: 0.698652, acc.: 50.00%] [G loss: 0.859927]\n",
      "epoch:8 step:8382 [D loss: 0.671303, acc.: 57.03%] [G loss: 0.839372]\n",
      "epoch:8 step:8383 [D loss: 0.678012, acc.: 60.94%] [G loss: 0.823188]\n",
      "epoch:8 step:8384 [D loss: 0.625932, acc.: 70.31%] [G loss: 0.854994]\n",
      "epoch:8 step:8385 [D loss: 0.651129, acc.: 62.50%] [G loss: 0.832996]\n",
      "epoch:8 step:8386 [D loss: 0.658001, acc.: 60.16%] [G loss: 0.790516]\n",
      "epoch:8 step:8387 [D loss: 0.722092, acc.: 50.78%] [G loss: 0.832721]\n",
      "epoch:8 step:8388 [D loss: 0.687098, acc.: 54.69%] [G loss: 0.867910]\n",
      "epoch:8 step:8389 [D loss: 0.667089, acc.: 64.84%] [G loss: 0.832448]\n",
      "epoch:8 step:8390 [D loss: 0.683926, acc.: 51.56%] [G loss: 0.853549]\n",
      "epoch:8 step:8391 [D loss: 0.656964, acc.: 63.28%] [G loss: 0.839690]\n",
      "epoch:8 step:8392 [D loss: 0.677688, acc.: 58.59%] [G loss: 0.795264]\n",
      "epoch:8 step:8393 [D loss: 0.662568, acc.: 57.03%] [G loss: 0.812559]\n",
      "epoch:8 step:8394 [D loss: 0.635259, acc.: 64.06%] [G loss: 0.825890]\n",
      "epoch:8 step:8395 [D loss: 0.651220, acc.: 63.28%] [G loss: 0.799014]\n",
      "epoch:8 step:8396 [D loss: 0.683491, acc.: 55.47%] [G loss: 0.814005]\n",
      "epoch:8 step:8397 [D loss: 0.675910, acc.: 56.25%] [G loss: 0.780721]\n",
      "epoch:8 step:8398 [D loss: 0.660440, acc.: 60.94%] [G loss: 0.835578]\n",
      "epoch:8 step:8399 [D loss: 0.643405, acc.: 64.06%] [G loss: 0.827775]\n",
      "epoch:8 step:8400 [D loss: 0.622867, acc.: 69.53%] [G loss: 0.884207]\n",
      "##############\n",
      "[2.86377462 2.72865704 2.6270568  4.22214028 1.26548469 9.27426719\n",
      " 2.78626324 4.21942604 4.25526766 7.14868929]\n",
      "##########\n",
      "epoch:8 step:8401 [D loss: 0.685494, acc.: 53.91%] [G loss: 0.838433]\n",
      "epoch:8 step:8402 [D loss: 0.651016, acc.: 62.50%] [G loss: 0.865849]\n",
      "epoch:8 step:8403 [D loss: 0.682734, acc.: 56.25%] [G loss: 0.848616]\n",
      "epoch:8 step:8404 [D loss: 0.670202, acc.: 60.94%] [G loss: 0.867632]\n",
      "epoch:8 step:8405 [D loss: 0.683149, acc.: 53.12%] [G loss: 0.839477]\n",
      "epoch:8 step:8406 [D loss: 0.693608, acc.: 46.88%] [G loss: 0.849933]\n",
      "epoch:8 step:8407 [D loss: 0.675917, acc.: 57.03%] [G loss: 0.870747]\n",
      "epoch:8 step:8408 [D loss: 0.671904, acc.: 60.16%] [G loss: 0.841572]\n",
      "epoch:8 step:8409 [D loss: 0.685644, acc.: 52.34%] [G loss: 0.859395]\n",
      "epoch:8 step:8410 [D loss: 0.648034, acc.: 64.84%] [G loss: 0.859921]\n",
      "epoch:8 step:8411 [D loss: 0.677961, acc.: 60.16%] [G loss: 0.918632]\n",
      "epoch:8 step:8412 [D loss: 0.688762, acc.: 53.91%] [G loss: 0.881092]\n",
      "epoch:8 step:8413 [D loss: 0.648055, acc.: 61.72%] [G loss: 0.872847]\n",
      "epoch:8 step:8414 [D loss: 0.694668, acc.: 52.34%] [G loss: 0.834996]\n",
      "epoch:8 step:8415 [D loss: 0.652544, acc.: 63.28%] [G loss: 0.877870]\n",
      "epoch:8 step:8416 [D loss: 0.681344, acc.: 54.69%] [G loss: 0.852461]\n",
      "epoch:8 step:8417 [D loss: 0.692788, acc.: 55.47%] [G loss: 0.858160]\n",
      "epoch:8 step:8418 [D loss: 0.695752, acc.: 57.03%] [G loss: 0.885613]\n",
      "epoch:8 step:8419 [D loss: 0.676795, acc.: 57.81%] [G loss: 0.890524]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:8 step:8420 [D loss: 0.642114, acc.: 60.94%] [G loss: 0.845700]\n",
      "epoch:8 step:8421 [D loss: 0.632676, acc.: 71.09%] [G loss: 0.880335]\n",
      "epoch:8 step:8422 [D loss: 0.644925, acc.: 63.28%] [G loss: 0.830288]\n",
      "epoch:8 step:8423 [D loss: 0.680910, acc.: 53.12%] [G loss: 0.889568]\n",
      "epoch:8 step:8424 [D loss: 0.632288, acc.: 65.62%] [G loss: 0.844234]\n",
      "epoch:8 step:8425 [D loss: 0.646174, acc.: 64.06%] [G loss: 0.867350]\n",
      "epoch:8 step:8426 [D loss: 0.632971, acc.: 60.16%] [G loss: 0.836682]\n",
      "epoch:8 step:8427 [D loss: 0.676466, acc.: 57.81%] [G loss: 0.854992]\n",
      "epoch:8 step:8428 [D loss: 0.674439, acc.: 57.81%] [G loss: 0.809854]\n",
      "epoch:8 step:8429 [D loss: 0.661769, acc.: 62.50%] [G loss: 0.827081]\n",
      "epoch:8 step:8430 [D loss: 0.640882, acc.: 59.38%] [G loss: 0.842786]\n",
      "epoch:8 step:8431 [D loss: 0.682641, acc.: 57.81%] [G loss: 0.922529]\n",
      "epoch:8 step:8432 [D loss: 0.643495, acc.: 65.62%] [G loss: 0.915098]\n",
      "epoch:8 step:8433 [D loss: 0.685492, acc.: 54.69%] [G loss: 0.964702]\n",
      "epoch:9 step:8434 [D loss: 0.682183, acc.: 55.47%] [G loss: 0.954019]\n",
      "epoch:9 step:8435 [D loss: 0.703293, acc.: 51.56%] [G loss: 0.821612]\n",
      "epoch:9 step:8436 [D loss: 0.640148, acc.: 62.50%] [G loss: 0.851156]\n",
      "epoch:9 step:8437 [D loss: 0.661261, acc.: 60.94%] [G loss: 0.858056]\n",
      "epoch:9 step:8438 [D loss: 0.656820, acc.: 60.16%] [G loss: 0.847421]\n",
      "epoch:9 step:8439 [D loss: 0.635631, acc.: 68.75%] [G loss: 0.828718]\n",
      "epoch:9 step:8440 [D loss: 0.649681, acc.: 63.28%] [G loss: 0.851147]\n",
      "epoch:9 step:8441 [D loss: 0.670156, acc.: 58.59%] [G loss: 0.859112]\n",
      "epoch:9 step:8442 [D loss: 0.675727, acc.: 64.84%] [G loss: 0.845498]\n",
      "epoch:9 step:8443 [D loss: 0.656406, acc.: 59.38%] [G loss: 0.833265]\n",
      "epoch:9 step:8444 [D loss: 0.658357, acc.: 57.81%] [G loss: 0.842454]\n",
      "epoch:9 step:8445 [D loss: 0.659015, acc.: 63.28%] [G loss: 0.814539]\n",
      "epoch:9 step:8446 [D loss: 0.652895, acc.: 57.03%] [G loss: 0.856689]\n",
      "epoch:9 step:8447 [D loss: 0.713252, acc.: 56.25%] [G loss: 0.881392]\n",
      "epoch:9 step:8448 [D loss: 0.673145, acc.: 56.25%] [G loss: 0.849548]\n",
      "epoch:9 step:8449 [D loss: 0.674877, acc.: 57.81%] [G loss: 0.827636]\n",
      "epoch:9 step:8450 [D loss: 0.656959, acc.: 57.03%] [G loss: 0.855252]\n",
      "epoch:9 step:8451 [D loss: 0.666715, acc.: 59.38%] [G loss: 0.861362]\n",
      "epoch:9 step:8452 [D loss: 0.666114, acc.: 61.72%] [G loss: 0.876718]\n",
      "epoch:9 step:8453 [D loss: 0.679275, acc.: 54.69%] [G loss: 0.895687]\n",
      "epoch:9 step:8454 [D loss: 0.621494, acc.: 65.62%] [G loss: 0.873405]\n",
      "epoch:9 step:8455 [D loss: 0.669833, acc.: 55.47%] [G loss: 0.900301]\n",
      "epoch:9 step:8456 [D loss: 0.714969, acc.: 52.34%] [G loss: 0.844146]\n",
      "epoch:9 step:8457 [D loss: 0.644494, acc.: 65.62%] [G loss: 0.857643]\n",
      "epoch:9 step:8458 [D loss: 0.680475, acc.: 62.50%] [G loss: 0.857201]\n",
      "epoch:9 step:8459 [D loss: 0.679724, acc.: 59.38%] [G loss: 0.838191]\n",
      "epoch:9 step:8460 [D loss: 0.648659, acc.: 64.06%] [G loss: 0.855053]\n",
      "epoch:9 step:8461 [D loss: 0.669021, acc.: 58.59%] [G loss: 0.827053]\n",
      "epoch:9 step:8462 [D loss: 0.678809, acc.: 56.25%] [G loss: 0.801659]\n",
      "epoch:9 step:8463 [D loss: 0.678460, acc.: 57.03%] [G loss: 0.818750]\n",
      "epoch:9 step:8464 [D loss: 0.698362, acc.: 49.22%] [G loss: 0.855761]\n",
      "epoch:9 step:8465 [D loss: 0.668954, acc.: 58.59%] [G loss: 0.859174]\n",
      "epoch:9 step:8466 [D loss: 0.651521, acc.: 58.59%] [G loss: 0.832225]\n",
      "epoch:9 step:8467 [D loss: 0.657671, acc.: 61.72%] [G loss: 0.846723]\n",
      "epoch:9 step:8468 [D loss: 0.658227, acc.: 55.47%] [G loss: 0.831299]\n",
      "epoch:9 step:8469 [D loss: 0.641367, acc.: 64.84%] [G loss: 0.847676]\n",
      "epoch:9 step:8470 [D loss: 0.652587, acc.: 59.38%] [G loss: 0.847096]\n",
      "epoch:9 step:8471 [D loss: 0.689457, acc.: 53.12%] [G loss: 0.856508]\n",
      "epoch:9 step:8472 [D loss: 0.692100, acc.: 59.38%] [G loss: 0.855938]\n",
      "epoch:9 step:8473 [D loss: 0.674277, acc.: 58.59%] [G loss: 0.825395]\n",
      "epoch:9 step:8474 [D loss: 0.686221, acc.: 57.03%] [G loss: 0.849939]\n",
      "epoch:9 step:8475 [D loss: 0.629136, acc.: 62.50%] [G loss: 0.833493]\n",
      "epoch:9 step:8476 [D loss: 0.663498, acc.: 62.50%] [G loss: 0.840821]\n",
      "epoch:9 step:8477 [D loss: 0.668726, acc.: 57.03%] [G loss: 0.815303]\n",
      "epoch:9 step:8478 [D loss: 0.695436, acc.: 56.25%] [G loss: 0.823347]\n",
      "epoch:9 step:8479 [D loss: 0.679044, acc.: 57.03%] [G loss: 0.835353]\n",
      "epoch:9 step:8480 [D loss: 0.690937, acc.: 56.25%] [G loss: 0.773554]\n",
      "epoch:9 step:8481 [D loss: 0.668326, acc.: 60.16%] [G loss: 0.807890]\n",
      "epoch:9 step:8482 [D loss: 0.658852, acc.: 63.28%] [G loss: 0.842877]\n",
      "epoch:9 step:8483 [D loss: 0.681875, acc.: 57.03%] [G loss: 0.827276]\n",
      "epoch:9 step:8484 [D loss: 0.674093, acc.: 62.50%] [G loss: 0.858090]\n",
      "epoch:9 step:8485 [D loss: 0.648943, acc.: 64.06%] [G loss: 0.843577]\n",
      "epoch:9 step:8486 [D loss: 0.692796, acc.: 57.03%] [G loss: 0.925403]\n",
      "epoch:9 step:8487 [D loss: 0.669557, acc.: 57.81%] [G loss: 0.872007]\n",
      "epoch:9 step:8488 [D loss: 0.676778, acc.: 52.34%] [G loss: 0.840850]\n",
      "epoch:9 step:8489 [D loss: 0.672090, acc.: 57.03%] [G loss: 0.780886]\n",
      "epoch:9 step:8490 [D loss: 0.661932, acc.: 58.59%] [G loss: 0.799725]\n",
      "epoch:9 step:8491 [D loss: 0.659299, acc.: 55.47%] [G loss: 0.834887]\n",
      "epoch:9 step:8492 [D loss: 0.614571, acc.: 71.09%] [G loss: 0.800183]\n",
      "epoch:9 step:8493 [D loss: 0.679581, acc.: 60.94%] [G loss: 0.819654]\n",
      "epoch:9 step:8494 [D loss: 0.648741, acc.: 61.72%] [G loss: 0.888436]\n",
      "epoch:9 step:8495 [D loss: 0.679717, acc.: 54.69%] [G loss: 0.838760]\n",
      "epoch:9 step:8496 [D loss: 0.646716, acc.: 65.62%] [G loss: 0.838854]\n",
      "epoch:9 step:8497 [D loss: 0.651081, acc.: 64.06%] [G loss: 0.832223]\n",
      "epoch:9 step:8498 [D loss: 0.678889, acc.: 55.47%] [G loss: 0.843363]\n",
      "epoch:9 step:8499 [D loss: 0.690932, acc.: 55.47%] [G loss: 0.860841]\n",
      "epoch:9 step:8500 [D loss: 0.691234, acc.: 52.34%] [G loss: 0.887409]\n",
      "epoch:9 step:8501 [D loss: 0.633266, acc.: 61.72%] [G loss: 0.886887]\n",
      "epoch:9 step:8502 [D loss: 0.652767, acc.: 57.81%] [G loss: 0.898967]\n",
      "epoch:9 step:8503 [D loss: 0.671356, acc.: 58.59%] [G loss: 0.879993]\n",
      "epoch:9 step:8504 [D loss: 0.671216, acc.: 56.25%] [G loss: 0.930401]\n",
      "epoch:9 step:8505 [D loss: 0.643546, acc.: 69.53%] [G loss: 0.888930]\n",
      "epoch:9 step:8506 [D loss: 0.618503, acc.: 71.88%] [G loss: 0.860060]\n",
      "epoch:9 step:8507 [D loss: 0.695635, acc.: 57.81%] [G loss: 0.861577]\n",
      "epoch:9 step:8508 [D loss: 0.655295, acc.: 58.59%] [G loss: 0.876358]\n",
      "epoch:9 step:8509 [D loss: 0.674767, acc.: 60.16%] [G loss: 0.877835]\n",
      "epoch:9 step:8510 [D loss: 0.676170, acc.: 54.69%] [G loss: 0.854688]\n",
      "epoch:9 step:8511 [D loss: 0.644542, acc.: 57.81%] [G loss: 0.843341]\n",
      "epoch:9 step:8512 [D loss: 0.688499, acc.: 60.16%] [G loss: 0.803495]\n",
      "epoch:9 step:8513 [D loss: 0.671043, acc.: 58.59%] [G loss: 0.840726]\n",
      "epoch:9 step:8514 [D loss: 0.678074, acc.: 57.81%] [G loss: 0.890905]\n",
      "epoch:9 step:8515 [D loss: 0.638124, acc.: 64.06%] [G loss: 0.851372]\n",
      "epoch:9 step:8516 [D loss: 0.666068, acc.: 60.94%] [G loss: 0.848206]\n",
      "epoch:9 step:8517 [D loss: 0.653600, acc.: 64.84%] [G loss: 0.843979]\n",
      "epoch:9 step:8518 [D loss: 0.665564, acc.: 60.16%] [G loss: 0.842561]\n",
      "epoch:9 step:8519 [D loss: 0.699700, acc.: 56.25%] [G loss: 0.851924]\n",
      "epoch:9 step:8520 [D loss: 0.664536, acc.: 53.12%] [G loss: 0.850296]\n",
      "epoch:9 step:8521 [D loss: 0.654261, acc.: 60.16%] [G loss: 0.845686]\n",
      "epoch:9 step:8522 [D loss: 0.660439, acc.: 65.62%] [G loss: 0.875384]\n",
      "epoch:9 step:8523 [D loss: 0.664376, acc.: 65.62%] [G loss: 0.842254]\n",
      "epoch:9 step:8524 [D loss: 0.655161, acc.: 63.28%] [G loss: 0.842213]\n",
      "epoch:9 step:8525 [D loss: 0.682297, acc.: 53.91%] [G loss: 0.833868]\n",
      "epoch:9 step:8526 [D loss: 0.667815, acc.: 55.47%] [G loss: 0.840996]\n",
      "epoch:9 step:8527 [D loss: 0.693588, acc.: 54.69%] [G loss: 0.823486]\n",
      "epoch:9 step:8528 [D loss: 0.685304, acc.: 60.94%] [G loss: 0.808307]\n",
      "epoch:9 step:8529 [D loss: 0.675977, acc.: 56.25%] [G loss: 0.817001]\n",
      "epoch:9 step:8530 [D loss: 0.674064, acc.: 59.38%] [G loss: 0.809680]\n",
      "epoch:9 step:8531 [D loss: 0.676828, acc.: 60.16%] [G loss: 0.849442]\n",
      "epoch:9 step:8532 [D loss: 0.654308, acc.: 63.28%] [G loss: 0.846745]\n",
      "epoch:9 step:8533 [D loss: 0.704978, acc.: 50.78%] [G loss: 0.834382]\n",
      "epoch:9 step:8534 [D loss: 0.676243, acc.: 57.03%] [G loss: 0.916738]\n",
      "epoch:9 step:8535 [D loss: 0.710114, acc.: 52.34%] [G loss: 0.833989]\n",
      "epoch:9 step:8536 [D loss: 0.651855, acc.: 65.62%] [G loss: 0.850453]\n",
      "epoch:9 step:8537 [D loss: 0.677699, acc.: 58.59%] [G loss: 0.867034]\n",
      "epoch:9 step:8538 [D loss: 0.645517, acc.: 64.06%] [G loss: 0.819124]\n",
      "epoch:9 step:8539 [D loss: 0.666966, acc.: 63.28%] [G loss: 0.892429]\n",
      "epoch:9 step:8540 [D loss: 0.659016, acc.: 64.84%] [G loss: 0.813035]\n",
      "epoch:9 step:8541 [D loss: 0.670646, acc.: 59.38%] [G loss: 0.825669]\n",
      "epoch:9 step:8542 [D loss: 0.628699, acc.: 65.62%] [G loss: 0.817633]\n",
      "epoch:9 step:8543 [D loss: 0.682600, acc.: 54.69%] [G loss: 0.850346]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8544 [D loss: 0.707425, acc.: 46.09%] [G loss: 0.818794]\n",
      "epoch:9 step:8545 [D loss: 0.705327, acc.: 54.69%] [G loss: 0.841383]\n",
      "epoch:9 step:8546 [D loss: 0.673379, acc.: 59.38%] [G loss: 0.852908]\n",
      "epoch:9 step:8547 [D loss: 0.685179, acc.: 59.38%] [G loss: 0.922948]\n",
      "epoch:9 step:8548 [D loss: 0.682203, acc.: 51.56%] [G loss: 0.870755]\n",
      "epoch:9 step:8549 [D loss: 0.643908, acc.: 62.50%] [G loss: 0.917170]\n",
      "epoch:9 step:8550 [D loss: 0.716998, acc.: 54.69%] [G loss: 0.808145]\n",
      "epoch:9 step:8551 [D loss: 0.683967, acc.: 57.03%] [G loss: 0.867408]\n",
      "epoch:9 step:8552 [D loss: 0.661190, acc.: 59.38%] [G loss: 0.821965]\n",
      "epoch:9 step:8553 [D loss: 0.654358, acc.: 59.38%] [G loss: 0.849856]\n",
      "epoch:9 step:8554 [D loss: 0.657946, acc.: 57.81%] [G loss: 0.847986]\n",
      "epoch:9 step:8555 [D loss: 0.674162, acc.: 63.28%] [G loss: 0.836373]\n",
      "epoch:9 step:8556 [D loss: 0.680290, acc.: 57.03%] [G loss: 0.860185]\n",
      "epoch:9 step:8557 [D loss: 0.664724, acc.: 60.94%] [G loss: 0.875016]\n",
      "epoch:9 step:8558 [D loss: 0.674290, acc.: 58.59%] [G loss: 0.834163]\n",
      "epoch:9 step:8559 [D loss: 0.657731, acc.: 57.81%] [G loss: 0.834257]\n",
      "epoch:9 step:8560 [D loss: 0.650712, acc.: 64.84%] [G loss: 0.835352]\n",
      "epoch:9 step:8561 [D loss: 0.654200, acc.: 60.94%] [G loss: 0.853676]\n",
      "epoch:9 step:8562 [D loss: 0.690932, acc.: 54.69%] [G loss: 0.836319]\n",
      "epoch:9 step:8563 [D loss: 0.667951, acc.: 57.81%] [G loss: 0.798894]\n",
      "epoch:9 step:8564 [D loss: 0.626735, acc.: 67.19%] [G loss: 0.812697]\n",
      "epoch:9 step:8565 [D loss: 0.709824, acc.: 51.56%] [G loss: 0.857827]\n",
      "epoch:9 step:8566 [D loss: 0.687630, acc.: 47.66%] [G loss: 0.798743]\n",
      "epoch:9 step:8567 [D loss: 0.653047, acc.: 62.50%] [G loss: 0.834790]\n",
      "epoch:9 step:8568 [D loss: 0.678998, acc.: 57.81%] [G loss: 0.844515]\n",
      "epoch:9 step:8569 [D loss: 0.701773, acc.: 57.03%] [G loss: 0.842077]\n",
      "epoch:9 step:8570 [D loss: 0.651613, acc.: 64.06%] [G loss: 0.804016]\n",
      "epoch:9 step:8571 [D loss: 0.661654, acc.: 61.72%] [G loss: 0.812487]\n",
      "epoch:9 step:8572 [D loss: 0.710647, acc.: 50.78%] [G loss: 0.838587]\n",
      "epoch:9 step:8573 [D loss: 0.692743, acc.: 53.12%] [G loss: 0.811842]\n",
      "epoch:9 step:8574 [D loss: 0.721957, acc.: 44.53%] [G loss: 0.818255]\n",
      "epoch:9 step:8575 [D loss: 0.655885, acc.: 56.25%] [G loss: 0.882583]\n",
      "epoch:9 step:8576 [D loss: 0.675803, acc.: 54.69%] [G loss: 0.833346]\n",
      "epoch:9 step:8577 [D loss: 0.663044, acc.: 63.28%] [G loss: 0.836244]\n",
      "epoch:9 step:8578 [D loss: 0.668255, acc.: 54.69%] [G loss: 0.864443]\n",
      "epoch:9 step:8579 [D loss: 0.655042, acc.: 59.38%] [G loss: 0.843793]\n",
      "epoch:9 step:8580 [D loss: 0.676159, acc.: 58.59%] [G loss: 0.829588]\n",
      "epoch:9 step:8581 [D loss: 0.667719, acc.: 57.81%] [G loss: 0.894900]\n",
      "epoch:9 step:8582 [D loss: 0.637612, acc.: 58.59%] [G loss: 0.834134]\n",
      "epoch:9 step:8583 [D loss: 0.666613, acc.: 57.81%] [G loss: 0.826725]\n",
      "epoch:9 step:8584 [D loss: 0.682426, acc.: 58.59%] [G loss: 0.790191]\n",
      "epoch:9 step:8585 [D loss: 0.704324, acc.: 51.56%] [G loss: 0.821791]\n",
      "epoch:9 step:8586 [D loss: 0.656754, acc.: 61.72%] [G loss: 0.832328]\n",
      "epoch:9 step:8587 [D loss: 0.665329, acc.: 63.28%] [G loss: 0.881895]\n",
      "epoch:9 step:8588 [D loss: 0.687737, acc.: 52.34%] [G loss: 0.891202]\n",
      "epoch:9 step:8589 [D loss: 0.662768, acc.: 60.94%] [G loss: 0.833925]\n",
      "epoch:9 step:8590 [D loss: 0.673048, acc.: 59.38%] [G loss: 0.892612]\n",
      "epoch:9 step:8591 [D loss: 0.649638, acc.: 65.62%] [G loss: 0.860573]\n",
      "epoch:9 step:8592 [D loss: 0.655491, acc.: 63.28%] [G loss: 0.862227]\n",
      "epoch:9 step:8593 [D loss: 0.682585, acc.: 53.91%] [G loss: 0.848774]\n",
      "epoch:9 step:8594 [D loss: 0.675584, acc.: 53.12%] [G loss: 0.846016]\n",
      "epoch:9 step:8595 [D loss: 0.648975, acc.: 61.72%] [G loss: 0.882980]\n",
      "epoch:9 step:8596 [D loss: 0.696930, acc.: 54.69%] [G loss: 0.845792]\n",
      "epoch:9 step:8597 [D loss: 0.685044, acc.: 53.91%] [G loss: 0.871486]\n",
      "epoch:9 step:8598 [D loss: 0.685187, acc.: 55.47%] [G loss: 0.851651]\n",
      "epoch:9 step:8599 [D loss: 0.684601, acc.: 53.12%] [G loss: 0.846438]\n",
      "epoch:9 step:8600 [D loss: 0.653417, acc.: 64.84%] [G loss: 0.813391]\n",
      "##############\n",
      "[ 3.18115651  2.78398922  2.50409461  3.95388075  1.64536904 10.27426719\n",
      "  3.22629201  3.58207616  4.23639916  5.95395495]\n",
      "##########\n",
      "epoch:9 step:8601 [D loss: 0.679578, acc.: 56.25%] [G loss: 0.835288]\n",
      "epoch:9 step:8602 [D loss: 0.708064, acc.: 50.00%] [G loss: 0.877943]\n",
      "epoch:9 step:8603 [D loss: 0.674810, acc.: 52.34%] [G loss: 0.848253]\n",
      "epoch:9 step:8604 [D loss: 0.665822, acc.: 58.59%] [G loss: 0.846335]\n",
      "epoch:9 step:8605 [D loss: 0.691900, acc.: 50.00%] [G loss: 0.883508]\n",
      "epoch:9 step:8606 [D loss: 0.648330, acc.: 64.06%] [G loss: 0.893926]\n",
      "epoch:9 step:8607 [D loss: 0.638004, acc.: 65.62%] [G loss: 0.797541]\n",
      "epoch:9 step:8608 [D loss: 0.684133, acc.: 53.91%] [G loss: 0.775402]\n",
      "epoch:9 step:8609 [D loss: 0.665250, acc.: 63.28%] [G loss: 0.871928]\n",
      "epoch:9 step:8610 [D loss: 0.678286, acc.: 63.28%] [G loss: 0.825211]\n",
      "epoch:9 step:8611 [D loss: 0.640372, acc.: 61.72%] [G loss: 0.849556]\n",
      "epoch:9 step:8612 [D loss: 0.675751, acc.: 57.81%] [G loss: 0.896035]\n",
      "epoch:9 step:8613 [D loss: 0.649876, acc.: 60.16%] [G loss: 0.881767]\n",
      "epoch:9 step:8614 [D loss: 0.700017, acc.: 53.91%] [G loss: 0.895667]\n",
      "epoch:9 step:8615 [D loss: 0.663615, acc.: 63.28%] [G loss: 0.881978]\n",
      "epoch:9 step:8616 [D loss: 0.669092, acc.: 62.50%] [G loss: 0.903438]\n",
      "epoch:9 step:8617 [D loss: 0.679348, acc.: 61.72%] [G loss: 0.911172]\n",
      "epoch:9 step:8618 [D loss: 0.671910, acc.: 55.47%] [G loss: 0.846570]\n",
      "epoch:9 step:8619 [D loss: 0.656434, acc.: 60.16%] [G loss: 0.856627]\n",
      "epoch:9 step:8620 [D loss: 0.672277, acc.: 60.16%] [G loss: 0.865089]\n",
      "epoch:9 step:8621 [D loss: 0.677600, acc.: 59.38%] [G loss: 0.839802]\n",
      "epoch:9 step:8622 [D loss: 0.657665, acc.: 64.06%] [G loss: 0.837543]\n",
      "epoch:9 step:8623 [D loss: 0.676412, acc.: 55.47%] [G loss: 0.813835]\n",
      "epoch:9 step:8624 [D loss: 0.634470, acc.: 63.28%] [G loss: 0.842563]\n",
      "epoch:9 step:8625 [D loss: 0.679956, acc.: 60.94%] [G loss: 0.835429]\n",
      "epoch:9 step:8626 [D loss: 0.666159, acc.: 60.94%] [G loss: 0.918842]\n",
      "epoch:9 step:8627 [D loss: 0.692656, acc.: 51.56%] [G loss: 0.853585]\n",
      "epoch:9 step:8628 [D loss: 0.634099, acc.: 66.41%] [G loss: 0.845261]\n",
      "epoch:9 step:8629 [D loss: 0.671259, acc.: 53.91%] [G loss: 0.795233]\n",
      "epoch:9 step:8630 [D loss: 0.632637, acc.: 60.94%] [G loss: 0.839610]\n",
      "epoch:9 step:8631 [D loss: 0.639262, acc.: 64.84%] [G loss: 0.845714]\n",
      "epoch:9 step:8632 [D loss: 0.621164, acc.: 67.19%] [G loss: 0.824276]\n",
      "epoch:9 step:8633 [D loss: 0.660151, acc.: 60.16%] [G loss: 0.822541]\n",
      "epoch:9 step:8634 [D loss: 0.666230, acc.: 62.50%] [G loss: 0.813680]\n",
      "epoch:9 step:8635 [D loss: 0.641492, acc.: 58.59%] [G loss: 0.803911]\n",
      "epoch:9 step:8636 [D loss: 0.694017, acc.: 55.47%] [G loss: 0.847556]\n",
      "epoch:9 step:8637 [D loss: 0.651642, acc.: 59.38%] [G loss: 0.885370]\n",
      "epoch:9 step:8638 [D loss: 0.645929, acc.: 60.16%] [G loss: 0.890512]\n",
      "epoch:9 step:8639 [D loss: 0.662021, acc.: 62.50%] [G loss: 0.789066]\n",
      "epoch:9 step:8640 [D loss: 0.680056, acc.: 61.72%] [G loss: 0.833270]\n",
      "epoch:9 step:8641 [D loss: 0.636052, acc.: 65.62%] [G loss: 0.842593]\n",
      "epoch:9 step:8642 [D loss: 0.703289, acc.: 53.12%] [G loss: 0.848019]\n",
      "epoch:9 step:8643 [D loss: 0.635406, acc.: 68.75%] [G loss: 0.879162]\n",
      "epoch:9 step:8644 [D loss: 0.672085, acc.: 58.59%] [G loss: 0.839979]\n",
      "epoch:9 step:8645 [D loss: 0.667112, acc.: 60.16%] [G loss: 0.882991]\n",
      "epoch:9 step:8646 [D loss: 0.681507, acc.: 58.59%] [G loss: 0.886666]\n",
      "epoch:9 step:8647 [D loss: 0.668385, acc.: 60.16%] [G loss: 0.856017]\n",
      "epoch:9 step:8648 [D loss: 0.698958, acc.: 54.69%] [G loss: 0.860817]\n",
      "epoch:9 step:8649 [D loss: 0.699335, acc.: 53.12%] [G loss: 0.836315]\n",
      "epoch:9 step:8650 [D loss: 0.629852, acc.: 65.62%] [G loss: 0.848889]\n",
      "epoch:9 step:8651 [D loss: 0.717461, acc.: 49.22%] [G loss: 0.864602]\n",
      "epoch:9 step:8652 [D loss: 0.673133, acc.: 56.25%] [G loss: 0.866936]\n",
      "epoch:9 step:8653 [D loss: 0.662875, acc.: 61.72%] [G loss: 0.850658]\n",
      "epoch:9 step:8654 [D loss: 0.683772, acc.: 56.25%] [G loss: 0.849861]\n",
      "epoch:9 step:8655 [D loss: 0.687367, acc.: 53.12%] [G loss: 0.853442]\n",
      "epoch:9 step:8656 [D loss: 0.681846, acc.: 52.34%] [G loss: 0.840011]\n",
      "epoch:9 step:8657 [D loss: 0.665736, acc.: 59.38%] [G loss: 0.892854]\n",
      "epoch:9 step:8658 [D loss: 0.677785, acc.: 59.38%] [G loss: 0.871967]\n",
      "epoch:9 step:8659 [D loss: 0.651766, acc.: 57.81%] [G loss: 0.842595]\n",
      "epoch:9 step:8660 [D loss: 0.642263, acc.: 60.94%] [G loss: 0.870303]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8661 [D loss: 0.649024, acc.: 64.84%] [G loss: 0.863833]\n",
      "epoch:9 step:8662 [D loss: 0.645551, acc.: 64.06%] [G loss: 0.864485]\n",
      "epoch:9 step:8663 [D loss: 0.700246, acc.: 54.69%] [G loss: 0.859572]\n",
      "epoch:9 step:8664 [D loss: 0.672413, acc.: 55.47%] [G loss: 0.886024]\n",
      "epoch:9 step:8665 [D loss: 0.662834, acc.: 60.94%] [G loss: 0.923330]\n",
      "epoch:9 step:8666 [D loss: 0.672379, acc.: 56.25%] [G loss: 0.918274]\n",
      "epoch:9 step:8667 [D loss: 0.674549, acc.: 51.56%] [G loss: 0.875709]\n",
      "epoch:9 step:8668 [D loss: 0.668485, acc.: 57.81%] [G loss: 0.847598]\n",
      "epoch:9 step:8669 [D loss: 0.655893, acc.: 58.59%] [G loss: 0.875357]\n",
      "epoch:9 step:8670 [D loss: 0.679734, acc.: 54.69%] [G loss: 0.887439]\n",
      "epoch:9 step:8671 [D loss: 0.661029, acc.: 57.03%] [G loss: 0.832668]\n",
      "epoch:9 step:8672 [D loss: 0.637862, acc.: 66.41%] [G loss: 0.842412]\n",
      "epoch:9 step:8673 [D loss: 0.666287, acc.: 64.06%] [G loss: 0.843697]\n",
      "epoch:9 step:8674 [D loss: 0.689767, acc.: 50.00%] [G loss: 0.793203]\n",
      "epoch:9 step:8675 [D loss: 0.664442, acc.: 53.12%] [G loss: 0.833568]\n",
      "epoch:9 step:8676 [D loss: 0.682159, acc.: 56.25%] [G loss: 0.816606]\n",
      "epoch:9 step:8677 [D loss: 0.657788, acc.: 58.59%] [G loss: 0.829135]\n",
      "epoch:9 step:8678 [D loss: 0.673208, acc.: 58.59%] [G loss: 0.847601]\n",
      "epoch:9 step:8679 [D loss: 0.656671, acc.: 63.28%] [G loss: 0.838672]\n",
      "epoch:9 step:8680 [D loss: 0.679903, acc.: 58.59%] [G loss: 0.829620]\n",
      "epoch:9 step:8681 [D loss: 0.620424, acc.: 71.09%] [G loss: 0.812120]\n",
      "epoch:9 step:8682 [D loss: 0.700627, acc.: 57.03%] [G loss: 0.812481]\n",
      "epoch:9 step:8683 [D loss: 0.669705, acc.: 58.59%] [G loss: 0.824679]\n",
      "epoch:9 step:8684 [D loss: 0.707217, acc.: 55.47%] [G loss: 0.850484]\n",
      "epoch:9 step:8685 [D loss: 0.668094, acc.: 62.50%] [G loss: 0.850116]\n",
      "epoch:9 step:8686 [D loss: 0.675376, acc.: 56.25%] [G loss: 0.873142]\n",
      "epoch:9 step:8687 [D loss: 0.668781, acc.: 60.16%] [G loss: 0.824961]\n",
      "epoch:9 step:8688 [D loss: 0.668111, acc.: 59.38%] [G loss: 0.815864]\n",
      "epoch:9 step:8689 [D loss: 0.669460, acc.: 60.94%] [G loss: 0.833489]\n",
      "epoch:9 step:8690 [D loss: 0.678067, acc.: 57.03%] [G loss: 0.783764]\n",
      "epoch:9 step:8691 [D loss: 0.678910, acc.: 59.38%] [G loss: 0.804774]\n",
      "epoch:9 step:8692 [D loss: 0.632523, acc.: 65.62%] [G loss: 0.842421]\n",
      "epoch:9 step:8693 [D loss: 0.674806, acc.: 47.66%] [G loss: 0.868090]\n",
      "epoch:9 step:8694 [D loss: 0.698479, acc.: 53.12%] [G loss: 0.896734]\n",
      "epoch:9 step:8695 [D loss: 0.693362, acc.: 51.56%] [G loss: 0.845965]\n",
      "epoch:9 step:8696 [D loss: 0.685068, acc.: 53.91%] [G loss: 0.860797]\n",
      "epoch:9 step:8697 [D loss: 0.676849, acc.: 53.91%] [G loss: 0.874344]\n",
      "epoch:9 step:8698 [D loss: 0.652396, acc.: 60.94%] [G loss: 0.845222]\n",
      "epoch:9 step:8699 [D loss: 0.673890, acc.: 60.16%] [G loss: 0.876361]\n",
      "epoch:9 step:8700 [D loss: 0.642117, acc.: 65.62%] [G loss: 0.864347]\n",
      "epoch:9 step:8701 [D loss: 0.656372, acc.: 59.38%] [G loss: 0.866306]\n",
      "epoch:9 step:8702 [D loss: 0.675243, acc.: 55.47%] [G loss: 0.862785]\n",
      "epoch:9 step:8703 [D loss: 0.662611, acc.: 57.81%] [G loss: 0.831616]\n",
      "epoch:9 step:8704 [D loss: 0.652800, acc.: 58.59%] [G loss: 0.842673]\n",
      "epoch:9 step:8705 [D loss: 0.654417, acc.: 60.16%] [G loss: 0.861434]\n",
      "epoch:9 step:8706 [D loss: 0.692553, acc.: 57.03%] [G loss: 0.817280]\n",
      "epoch:9 step:8707 [D loss: 0.689738, acc.: 53.12%] [G loss: 0.856669]\n",
      "epoch:9 step:8708 [D loss: 0.680192, acc.: 57.03%] [G loss: 0.822738]\n",
      "epoch:9 step:8709 [D loss: 0.686940, acc.: 54.69%] [G loss: 0.842991]\n",
      "epoch:9 step:8710 [D loss: 0.657475, acc.: 63.28%] [G loss: 0.818951]\n",
      "epoch:9 step:8711 [D loss: 0.651803, acc.: 64.06%] [G loss: 0.816876]\n",
      "epoch:9 step:8712 [D loss: 0.655780, acc.: 63.28%] [G loss: 0.845633]\n",
      "epoch:9 step:8713 [D loss: 0.698017, acc.: 53.12%] [G loss: 0.844710]\n",
      "epoch:9 step:8714 [D loss: 0.631404, acc.: 63.28%] [G loss: 0.816585]\n",
      "epoch:9 step:8715 [D loss: 0.657132, acc.: 62.50%] [G loss: 0.846862]\n",
      "epoch:9 step:8716 [D loss: 0.671033, acc.: 59.38%] [G loss: 0.872601]\n",
      "epoch:9 step:8717 [D loss: 0.640542, acc.: 63.28%] [G loss: 0.856118]\n",
      "epoch:9 step:8718 [D loss: 0.647545, acc.: 63.28%] [G loss: 0.888048]\n",
      "epoch:9 step:8719 [D loss: 0.691191, acc.: 57.03%] [G loss: 0.842360]\n",
      "epoch:9 step:8720 [D loss: 0.637498, acc.: 61.72%] [G loss: 0.830560]\n",
      "epoch:9 step:8721 [D loss: 0.647975, acc.: 63.28%] [G loss: 0.824135]\n",
      "epoch:9 step:8722 [D loss: 0.690086, acc.: 53.91%] [G loss: 0.843320]\n",
      "epoch:9 step:8723 [D loss: 0.653185, acc.: 59.38%] [G loss: 0.823639]\n",
      "epoch:9 step:8724 [D loss: 0.659781, acc.: 60.16%] [G loss: 0.838331]\n",
      "epoch:9 step:8725 [D loss: 0.682459, acc.: 57.81%] [G loss: 0.823044]\n",
      "epoch:9 step:8726 [D loss: 0.686574, acc.: 57.81%] [G loss: 0.831198]\n",
      "epoch:9 step:8727 [D loss: 0.653801, acc.: 62.50%] [G loss: 0.862251]\n",
      "epoch:9 step:8728 [D loss: 0.690256, acc.: 53.91%] [G loss: 0.880488]\n",
      "epoch:9 step:8729 [D loss: 0.665009, acc.: 63.28%] [G loss: 0.843357]\n",
      "epoch:9 step:8730 [D loss: 0.684033, acc.: 53.91%] [G loss: 0.817577]\n",
      "epoch:9 step:8731 [D loss: 0.671201, acc.: 55.47%] [G loss: 0.850941]\n",
      "epoch:9 step:8732 [D loss: 0.669826, acc.: 57.03%] [G loss: 0.872479]\n",
      "epoch:9 step:8733 [D loss: 0.656063, acc.: 62.50%] [G loss: 0.821082]\n",
      "epoch:9 step:8734 [D loss: 0.673803, acc.: 59.38%] [G loss: 0.826100]\n",
      "epoch:9 step:8735 [D loss: 0.683076, acc.: 56.25%] [G loss: 0.830607]\n",
      "epoch:9 step:8736 [D loss: 0.649326, acc.: 63.28%] [G loss: 0.837530]\n",
      "epoch:9 step:8737 [D loss: 0.646561, acc.: 64.84%] [G loss: 0.870519]\n",
      "epoch:9 step:8738 [D loss: 0.691539, acc.: 55.47%] [G loss: 0.868980]\n",
      "epoch:9 step:8739 [D loss: 0.631928, acc.: 61.72%] [G loss: 0.861579]\n",
      "epoch:9 step:8740 [D loss: 0.661917, acc.: 60.94%] [G loss: 0.845514]\n",
      "epoch:9 step:8741 [D loss: 0.667101, acc.: 58.59%] [G loss: 0.864285]\n",
      "epoch:9 step:8742 [D loss: 0.643055, acc.: 62.50%] [G loss: 0.857343]\n",
      "epoch:9 step:8743 [D loss: 0.672188, acc.: 60.16%] [G loss: 0.830521]\n",
      "epoch:9 step:8744 [D loss: 0.669183, acc.: 57.81%] [G loss: 0.871744]\n",
      "epoch:9 step:8745 [D loss: 0.719530, acc.: 46.88%] [G loss: 0.837924]\n",
      "epoch:9 step:8746 [D loss: 0.682034, acc.: 57.81%] [G loss: 0.804021]\n",
      "epoch:9 step:8747 [D loss: 0.660629, acc.: 61.72%] [G loss: 0.858847]\n",
      "epoch:9 step:8748 [D loss: 0.632308, acc.: 64.06%] [G loss: 0.798151]\n",
      "epoch:9 step:8749 [D loss: 0.680003, acc.: 57.03%] [G loss: 0.798965]\n",
      "epoch:9 step:8750 [D loss: 0.666560, acc.: 57.81%] [G loss: 0.825004]\n",
      "epoch:9 step:8751 [D loss: 0.682596, acc.: 57.03%] [G loss: 0.884821]\n",
      "epoch:9 step:8752 [D loss: 0.676018, acc.: 57.03%] [G loss: 0.856624]\n",
      "epoch:9 step:8753 [D loss: 0.668723, acc.: 61.72%] [G loss: 0.848321]\n",
      "epoch:9 step:8754 [D loss: 0.674885, acc.: 59.38%] [G loss: 0.838161]\n",
      "epoch:9 step:8755 [D loss: 0.664989, acc.: 59.38%] [G loss: 0.846583]\n",
      "epoch:9 step:8756 [D loss: 0.686893, acc.: 59.38%] [G loss: 0.868330]\n",
      "epoch:9 step:8757 [D loss: 0.690825, acc.: 51.56%] [G loss: 0.845818]\n",
      "epoch:9 step:8758 [D loss: 0.690641, acc.: 53.12%] [G loss: 0.870229]\n",
      "epoch:9 step:8759 [D loss: 0.692139, acc.: 52.34%] [G loss: 0.834372]\n",
      "epoch:9 step:8760 [D loss: 0.639268, acc.: 68.75%] [G loss: 0.854807]\n",
      "epoch:9 step:8761 [D loss: 0.630607, acc.: 64.06%] [G loss: 0.852080]\n",
      "epoch:9 step:8762 [D loss: 0.665543, acc.: 62.50%] [G loss: 0.844338]\n",
      "epoch:9 step:8763 [D loss: 0.667801, acc.: 59.38%] [G loss: 0.850648]\n",
      "epoch:9 step:8764 [D loss: 0.686594, acc.: 54.69%] [G loss: 0.840905]\n",
      "epoch:9 step:8765 [D loss: 0.668192, acc.: 60.16%] [G loss: 0.841520]\n",
      "epoch:9 step:8766 [D loss: 0.701960, acc.: 53.91%] [G loss: 0.843787]\n",
      "epoch:9 step:8767 [D loss: 0.670115, acc.: 54.69%] [G loss: 0.866047]\n",
      "epoch:9 step:8768 [D loss: 0.676733, acc.: 61.72%] [G loss: 0.857123]\n",
      "epoch:9 step:8769 [D loss: 0.622375, acc.: 64.06%] [G loss: 0.867873]\n",
      "epoch:9 step:8770 [D loss: 0.649708, acc.: 62.50%] [G loss: 0.857027]\n",
      "epoch:9 step:8771 [D loss: 0.662906, acc.: 57.81%] [G loss: 0.875701]\n",
      "epoch:9 step:8772 [D loss: 0.654059, acc.: 60.16%] [G loss: 0.877969]\n",
      "epoch:9 step:8773 [D loss: 0.667176, acc.: 64.06%] [G loss: 0.857151]\n",
      "epoch:9 step:8774 [D loss: 0.650885, acc.: 60.16%] [G loss: 0.844216]\n",
      "epoch:9 step:8775 [D loss: 0.697049, acc.: 58.59%] [G loss: 0.869866]\n",
      "epoch:9 step:8776 [D loss: 0.690777, acc.: 50.78%] [G loss: 0.878088]\n",
      "epoch:9 step:8777 [D loss: 0.682960, acc.: 60.94%] [G loss: 0.853324]\n",
      "epoch:9 step:8778 [D loss: 0.669719, acc.: 55.47%] [G loss: 0.839925]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8779 [D loss: 0.672002, acc.: 59.38%] [G loss: 0.841049]\n",
      "epoch:9 step:8780 [D loss: 0.678967, acc.: 54.69%] [G loss: 0.866522]\n",
      "epoch:9 step:8781 [D loss: 0.647516, acc.: 60.94%] [G loss: 0.871226]\n",
      "epoch:9 step:8782 [D loss: 0.637750, acc.: 63.28%] [G loss: 0.911852]\n",
      "epoch:9 step:8783 [D loss: 0.683929, acc.: 61.72%] [G loss: 0.880235]\n",
      "epoch:9 step:8784 [D loss: 0.648769, acc.: 67.97%] [G loss: 0.856751]\n",
      "epoch:9 step:8785 [D loss: 0.686848, acc.: 62.50%] [G loss: 0.855882]\n",
      "epoch:9 step:8786 [D loss: 0.663293, acc.: 63.28%] [G loss: 0.809030]\n",
      "epoch:9 step:8787 [D loss: 0.684258, acc.: 54.69%] [G loss: 0.813267]\n",
      "epoch:9 step:8788 [D loss: 0.667783, acc.: 56.25%] [G loss: 0.802178]\n",
      "epoch:9 step:8789 [D loss: 0.674815, acc.: 61.72%] [G loss: 0.842257]\n",
      "epoch:9 step:8790 [D loss: 0.646818, acc.: 55.47%] [G loss: 0.794872]\n",
      "epoch:9 step:8791 [D loss: 0.641719, acc.: 64.84%] [G loss: 0.880536]\n",
      "epoch:9 step:8792 [D loss: 0.658524, acc.: 60.16%] [G loss: 0.833988]\n",
      "epoch:9 step:8793 [D loss: 0.681304, acc.: 50.78%] [G loss: 0.825588]\n",
      "epoch:9 step:8794 [D loss: 0.701624, acc.: 54.69%] [G loss: 0.841612]\n",
      "epoch:9 step:8795 [D loss: 0.654998, acc.: 57.81%] [G loss: 0.856821]\n",
      "epoch:9 step:8796 [D loss: 0.680868, acc.: 58.59%] [G loss: 0.856404]\n",
      "epoch:9 step:8797 [D loss: 0.684586, acc.: 55.47%] [G loss: 0.866455]\n",
      "epoch:9 step:8798 [D loss: 0.700589, acc.: 50.78%] [G loss: 0.828294]\n",
      "epoch:9 step:8799 [D loss: 0.671478, acc.: 58.59%] [G loss: 0.820683]\n",
      "epoch:9 step:8800 [D loss: 0.675774, acc.: 55.47%] [G loss: 0.872390]\n",
      "##############\n",
      "[3.11828595 2.71538458 2.50819816 4.20822732 1.35776163 7.92842307\n",
      " 3.05806825 3.61526111 4.41769211 6.65823271]\n",
      "##########\n",
      "epoch:9 step:8801 [D loss: 0.671845, acc.: 60.16%] [G loss: 0.842242]\n",
      "epoch:9 step:8802 [D loss: 0.681685, acc.: 57.03%] [G loss: 0.841824]\n",
      "epoch:9 step:8803 [D loss: 0.678137, acc.: 55.47%] [G loss: 0.801427]\n",
      "epoch:9 step:8804 [D loss: 0.684664, acc.: 53.91%] [G loss: 0.775763]\n",
      "epoch:9 step:8805 [D loss: 0.666414, acc.: 59.38%] [G loss: 0.844628]\n",
      "epoch:9 step:8806 [D loss: 0.671815, acc.: 60.16%] [G loss: 0.843937]\n",
      "epoch:9 step:8807 [D loss: 0.692662, acc.: 51.56%] [G loss: 0.860016]\n",
      "epoch:9 step:8808 [D loss: 0.692629, acc.: 53.91%] [G loss: 0.825380]\n",
      "epoch:9 step:8809 [D loss: 0.672520, acc.: 60.94%] [G loss: 0.834491]\n",
      "epoch:9 step:8810 [D loss: 0.670929, acc.: 60.16%] [G loss: 0.843818]\n",
      "epoch:9 step:8811 [D loss: 0.607766, acc.: 72.66%] [G loss: 0.845500]\n",
      "epoch:9 step:8812 [D loss: 0.670352, acc.: 57.03%] [G loss: 0.867012]\n",
      "epoch:9 step:8813 [D loss: 0.671763, acc.: 54.69%] [G loss: 0.873622]\n",
      "epoch:9 step:8814 [D loss: 0.660173, acc.: 60.94%] [G loss: 0.918124]\n",
      "epoch:9 step:8815 [D loss: 0.672892, acc.: 57.03%] [G loss: 0.889176]\n",
      "epoch:9 step:8816 [D loss: 0.664782, acc.: 60.16%] [G loss: 0.850477]\n",
      "epoch:9 step:8817 [D loss: 0.669986, acc.: 55.47%] [G loss: 0.837193]\n",
      "epoch:9 step:8818 [D loss: 0.704624, acc.: 52.34%] [G loss: 0.847612]\n",
      "epoch:9 step:8819 [D loss: 0.705038, acc.: 53.12%] [G loss: 0.823502]\n",
      "epoch:9 step:8820 [D loss: 0.657873, acc.: 65.62%] [G loss: 0.868883]\n",
      "epoch:9 step:8821 [D loss: 0.653701, acc.: 61.72%] [G loss: 0.868825]\n",
      "epoch:9 step:8822 [D loss: 0.653584, acc.: 57.03%] [G loss: 0.880587]\n",
      "epoch:9 step:8823 [D loss: 0.662245, acc.: 60.16%] [G loss: 0.876666]\n",
      "epoch:9 step:8824 [D loss: 0.658606, acc.: 60.16%] [G loss: 0.819080]\n",
      "epoch:9 step:8825 [D loss: 0.652466, acc.: 60.94%] [G loss: 0.862496]\n",
      "epoch:9 step:8826 [D loss: 0.698587, acc.: 49.22%] [G loss: 0.873326]\n",
      "epoch:9 step:8827 [D loss: 0.665533, acc.: 60.94%] [G loss: 0.885086]\n",
      "epoch:9 step:8828 [D loss: 0.654629, acc.: 64.06%] [G loss: 0.867169]\n",
      "epoch:9 step:8829 [D loss: 0.665727, acc.: 57.81%] [G loss: 0.837586]\n",
      "epoch:9 step:8830 [D loss: 0.677053, acc.: 57.03%] [G loss: 0.878471]\n",
      "epoch:9 step:8831 [D loss: 0.694108, acc.: 54.69%] [G loss: 0.879920]\n",
      "epoch:9 step:8832 [D loss: 0.634074, acc.: 66.41%] [G loss: 0.916790]\n",
      "epoch:9 step:8833 [D loss: 0.629999, acc.: 67.19%] [G loss: 0.885842]\n",
      "epoch:9 step:8834 [D loss: 0.681328, acc.: 55.47%] [G loss: 0.851692]\n",
      "epoch:9 step:8835 [D loss: 0.619915, acc.: 68.75%] [G loss: 0.876204]\n",
      "epoch:9 step:8836 [D loss: 0.666873, acc.: 60.16%] [G loss: 0.894306]\n",
      "epoch:9 step:8837 [D loss: 0.657887, acc.: 63.28%] [G loss: 0.867639]\n",
      "epoch:9 step:8838 [D loss: 0.698469, acc.: 56.25%] [G loss: 0.851005]\n",
      "epoch:9 step:8839 [D loss: 0.681270, acc.: 56.25%] [G loss: 0.888306]\n",
      "epoch:9 step:8840 [D loss: 0.661231, acc.: 60.16%] [G loss: 0.915992]\n",
      "epoch:9 step:8841 [D loss: 0.671304, acc.: 58.59%] [G loss: 0.862770]\n",
      "epoch:9 step:8842 [D loss: 0.665836, acc.: 59.38%] [G loss: 0.844397]\n",
      "epoch:9 step:8843 [D loss: 0.677184, acc.: 56.25%] [G loss: 0.831356]\n",
      "epoch:9 step:8844 [D loss: 0.657536, acc.: 60.16%] [G loss: 0.810463]\n",
      "epoch:9 step:8845 [D loss: 0.652615, acc.: 65.62%] [G loss: 0.885507]\n",
      "epoch:9 step:8846 [D loss: 0.666397, acc.: 64.06%] [G loss: 0.815652]\n",
      "epoch:9 step:8847 [D loss: 0.683303, acc.: 55.47%] [G loss: 0.798219]\n",
      "epoch:9 step:8848 [D loss: 0.670773, acc.: 53.91%] [G loss: 0.857682]\n",
      "epoch:9 step:8849 [D loss: 0.640777, acc.: 67.19%] [G loss: 0.857450]\n",
      "epoch:9 step:8850 [D loss: 0.643982, acc.: 64.06%] [G loss: 0.894814]\n",
      "epoch:9 step:8851 [D loss: 0.671304, acc.: 59.38%] [G loss: 0.896133]\n",
      "epoch:9 step:8852 [D loss: 0.684736, acc.: 57.81%] [G loss: 0.869408]\n",
      "epoch:9 step:8853 [D loss: 0.665515, acc.: 59.38%] [G loss: 0.892795]\n",
      "epoch:9 step:8854 [D loss: 0.646676, acc.: 64.06%] [G loss: 0.869196]\n",
      "epoch:9 step:8855 [D loss: 0.640936, acc.: 62.50%] [G loss: 0.886592]\n",
      "epoch:9 step:8856 [D loss: 0.689667, acc.: 53.12%] [G loss: 0.868121]\n",
      "epoch:9 step:8857 [D loss: 0.666164, acc.: 59.38%] [G loss: 0.878713]\n",
      "epoch:9 step:8858 [D loss: 0.687358, acc.: 53.12%] [G loss: 0.799583]\n",
      "epoch:9 step:8859 [D loss: 0.681131, acc.: 46.88%] [G loss: 0.877362]\n",
      "epoch:9 step:8860 [D loss: 0.677028, acc.: 57.81%] [G loss: 0.894480]\n",
      "epoch:9 step:8861 [D loss: 0.703859, acc.: 54.69%] [G loss: 0.832670]\n",
      "epoch:9 step:8862 [D loss: 0.685267, acc.: 53.12%] [G loss: 0.843718]\n",
      "epoch:9 step:8863 [D loss: 0.670559, acc.: 54.69%] [G loss: 0.836537]\n",
      "epoch:9 step:8864 [D loss: 0.661369, acc.: 60.16%] [G loss: 0.823762]\n",
      "epoch:9 step:8865 [D loss: 0.671654, acc.: 56.25%] [G loss: 0.866839]\n",
      "epoch:9 step:8866 [D loss: 0.671846, acc.: 54.69%] [G loss: 0.871480]\n",
      "epoch:9 step:8867 [D loss: 0.668288, acc.: 57.03%] [G loss: 0.847089]\n",
      "epoch:9 step:8868 [D loss: 0.660359, acc.: 63.28%] [G loss: 0.840265]\n",
      "epoch:9 step:8869 [D loss: 0.667138, acc.: 57.03%] [G loss: 0.870154]\n",
      "epoch:9 step:8870 [D loss: 0.682958, acc.: 57.03%] [G loss: 0.861913]\n",
      "epoch:9 step:8871 [D loss: 0.663461, acc.: 58.59%] [G loss: 0.834700]\n",
      "epoch:9 step:8872 [D loss: 0.675713, acc.: 53.12%] [G loss: 0.848810]\n",
      "epoch:9 step:8873 [D loss: 0.680660, acc.: 61.72%] [G loss: 0.854247]\n",
      "epoch:9 step:8874 [D loss: 0.672108, acc.: 57.03%] [G loss: 0.873712]\n",
      "epoch:9 step:8875 [D loss: 0.664738, acc.: 60.16%] [G loss: 0.827163]\n",
      "epoch:9 step:8876 [D loss: 0.646479, acc.: 66.41%] [G loss: 0.830535]\n",
      "epoch:9 step:8877 [D loss: 0.676703, acc.: 57.03%] [G loss: 0.837987]\n",
      "epoch:9 step:8878 [D loss: 0.682309, acc.: 55.47%] [G loss: 0.846511]\n",
      "epoch:9 step:8879 [D loss: 0.680890, acc.: 53.12%] [G loss: 0.843581]\n",
      "epoch:9 step:8880 [D loss: 0.670402, acc.: 63.28%] [G loss: 0.849934]\n",
      "epoch:9 step:8881 [D loss: 0.690583, acc.: 54.69%] [G loss: 0.846132]\n",
      "epoch:9 step:8882 [D loss: 0.648913, acc.: 62.50%] [G loss: 0.885191]\n",
      "epoch:9 step:8883 [D loss: 0.672169, acc.: 61.72%] [G loss: 0.922525]\n",
      "epoch:9 step:8884 [D loss: 0.627234, acc.: 67.97%] [G loss: 0.866263]\n",
      "epoch:9 step:8885 [D loss: 0.658662, acc.: 59.38%] [G loss: 0.875544]\n",
      "epoch:9 step:8886 [D loss: 0.674588, acc.: 58.59%] [G loss: 0.849450]\n",
      "epoch:9 step:8887 [D loss: 0.665898, acc.: 55.47%] [G loss: 0.844421]\n",
      "epoch:9 step:8888 [D loss: 0.661109, acc.: 60.94%] [G loss: 0.859250]\n",
      "epoch:9 step:8889 [D loss: 0.699522, acc.: 57.81%] [G loss: 0.793705]\n",
      "epoch:9 step:8890 [D loss: 0.694534, acc.: 45.31%] [G loss: 0.822305]\n",
      "epoch:9 step:8891 [D loss: 0.652869, acc.: 58.59%] [G loss: 0.824282]\n",
      "epoch:9 step:8892 [D loss: 0.645095, acc.: 65.62%] [G loss: 0.826505]\n",
      "epoch:9 step:8893 [D loss: 0.665836, acc.: 59.38%] [G loss: 0.882248]\n",
      "epoch:9 step:8894 [D loss: 0.682857, acc.: 56.25%] [G loss: 0.880184]\n",
      "epoch:9 step:8895 [D loss: 0.709868, acc.: 46.09%] [G loss: 0.793105]\n",
      "epoch:9 step:8896 [D loss: 0.687853, acc.: 57.03%] [G loss: 0.842888]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:8897 [D loss: 0.695843, acc.: 59.38%] [G loss: 0.861273]\n",
      "epoch:9 step:8898 [D loss: 0.684325, acc.: 57.81%] [G loss: 0.850178]\n",
      "epoch:9 step:8899 [D loss: 0.663341, acc.: 58.59%] [G loss: 0.875297]\n",
      "epoch:9 step:8900 [D loss: 0.655589, acc.: 56.25%] [G loss: 0.854762]\n",
      "epoch:9 step:8901 [D loss: 0.700466, acc.: 55.47%] [G loss: 0.801472]\n",
      "epoch:9 step:8902 [D loss: 0.688264, acc.: 52.34%] [G loss: 0.856606]\n",
      "epoch:9 step:8903 [D loss: 0.669136, acc.: 61.72%] [G loss: 0.832735]\n",
      "epoch:9 step:8904 [D loss: 0.628796, acc.: 67.97%] [G loss: 0.833313]\n",
      "epoch:9 step:8905 [D loss: 0.619427, acc.: 67.97%] [G loss: 0.823362]\n",
      "epoch:9 step:8906 [D loss: 0.674876, acc.: 61.72%] [G loss: 0.871955]\n",
      "epoch:9 step:8907 [D loss: 0.621717, acc.: 67.19%] [G loss: 0.814820]\n",
      "epoch:9 step:8908 [D loss: 0.672241, acc.: 55.47%] [G loss: 0.886496]\n",
      "epoch:9 step:8909 [D loss: 0.681390, acc.: 54.69%] [G loss: 0.847792]\n",
      "epoch:9 step:8910 [D loss: 0.689989, acc.: 56.25%] [G loss: 0.838898]\n",
      "epoch:9 step:8911 [D loss: 0.642108, acc.: 65.62%] [G loss: 0.854120]\n",
      "epoch:9 step:8912 [D loss: 0.654760, acc.: 64.84%] [G loss: 0.849325]\n",
      "epoch:9 step:8913 [D loss: 0.651819, acc.: 60.94%] [G loss: 0.838394]\n",
      "epoch:9 step:8914 [D loss: 0.666960, acc.: 59.38%] [G loss: 0.843288]\n",
      "epoch:9 step:8915 [D loss: 0.647802, acc.: 60.94%] [G loss: 0.875738]\n",
      "epoch:9 step:8916 [D loss: 0.693263, acc.: 51.56%] [G loss: 0.841429]\n",
      "epoch:9 step:8917 [D loss: 0.653849, acc.: 61.72%] [G loss: 0.823935]\n",
      "epoch:9 step:8918 [D loss: 0.706562, acc.: 50.00%] [G loss: 0.841172]\n",
      "epoch:9 step:8919 [D loss: 0.647722, acc.: 60.16%] [G loss: 0.816486]\n",
      "epoch:9 step:8920 [D loss: 0.649444, acc.: 60.16%] [G loss: 0.833954]\n",
      "epoch:9 step:8921 [D loss: 0.650570, acc.: 62.50%] [G loss: 0.859357]\n",
      "epoch:9 step:8922 [D loss: 0.650511, acc.: 61.72%] [G loss: 0.837520]\n",
      "epoch:9 step:8923 [D loss: 0.661304, acc.: 63.28%] [G loss: 0.840075]\n",
      "epoch:9 step:8924 [D loss: 0.633102, acc.: 67.97%] [G loss: 0.861622]\n",
      "epoch:9 step:8925 [D loss: 0.650761, acc.: 58.59%] [G loss: 0.884338]\n",
      "epoch:9 step:8926 [D loss: 0.683707, acc.: 57.03%] [G loss: 0.847633]\n",
      "epoch:9 step:8927 [D loss: 0.640166, acc.: 57.81%] [G loss: 0.860194]\n",
      "epoch:9 step:8928 [D loss: 0.683275, acc.: 53.91%] [G loss: 0.853271]\n",
      "epoch:9 step:8929 [D loss: 0.700798, acc.: 49.22%] [G loss: 0.883827]\n",
      "epoch:9 step:8930 [D loss: 0.680864, acc.: 53.12%] [G loss: 0.843808]\n",
      "epoch:9 step:8931 [D loss: 0.656626, acc.: 64.06%] [G loss: 0.882926]\n",
      "epoch:9 step:8932 [D loss: 0.665635, acc.: 57.81%] [G loss: 0.930475]\n",
      "epoch:9 step:8933 [D loss: 0.682101, acc.: 54.69%] [G loss: 0.863231]\n",
      "epoch:9 step:8934 [D loss: 0.675198, acc.: 60.94%] [G loss: 0.897059]\n",
      "epoch:9 step:8935 [D loss: 0.682770, acc.: 57.81%] [G loss: 0.887353]\n",
      "epoch:9 step:8936 [D loss: 0.658818, acc.: 62.50%] [G loss: 0.819683]\n",
      "epoch:9 step:8937 [D loss: 0.674549, acc.: 60.94%] [G loss: 0.827670]\n",
      "epoch:9 step:8938 [D loss: 0.644916, acc.: 61.72%] [G loss: 0.778401]\n",
      "epoch:9 step:8939 [D loss: 0.676004, acc.: 58.59%] [G loss: 0.862930]\n",
      "epoch:9 step:8940 [D loss: 0.668400, acc.: 58.59%] [G loss: 0.895911]\n",
      "epoch:9 step:8941 [D loss: 0.642062, acc.: 59.38%] [G loss: 0.844804]\n",
      "epoch:9 step:8942 [D loss: 0.695868, acc.: 52.34%] [G loss: 0.882110]\n",
      "epoch:9 step:8943 [D loss: 0.641648, acc.: 64.84%] [G loss: 0.873289]\n",
      "epoch:9 step:8944 [D loss: 0.632454, acc.: 64.06%] [G loss: 0.869363]\n",
      "epoch:9 step:8945 [D loss: 0.726962, acc.: 43.75%] [G loss: 0.909876]\n",
      "epoch:9 step:8946 [D loss: 0.672207, acc.: 59.38%] [G loss: 0.826267]\n",
      "epoch:9 step:8947 [D loss: 0.670036, acc.: 58.59%] [G loss: 0.873783]\n",
      "epoch:9 step:8948 [D loss: 0.690065, acc.: 48.44%] [G loss: 0.870908]\n",
      "epoch:9 step:8949 [D loss: 0.640411, acc.: 64.06%] [G loss: 0.841851]\n",
      "epoch:9 step:8950 [D loss: 0.647529, acc.: 61.72%] [G loss: 0.875371]\n",
      "epoch:9 step:8951 [D loss: 0.647689, acc.: 63.28%] [G loss: 0.872548]\n",
      "epoch:9 step:8952 [D loss: 0.647941, acc.: 57.81%] [G loss: 0.861369]\n",
      "epoch:9 step:8953 [D loss: 0.667019, acc.: 59.38%] [G loss: 0.845547]\n",
      "epoch:9 step:8954 [D loss: 0.656366, acc.: 60.16%] [G loss: 0.921081]\n",
      "epoch:9 step:8955 [D loss: 0.675868, acc.: 58.59%] [G loss: 0.882713]\n",
      "epoch:9 step:8956 [D loss: 0.649789, acc.: 61.72%] [G loss: 0.915314]\n",
      "epoch:9 step:8957 [D loss: 0.688065, acc.: 57.03%] [G loss: 0.862424]\n",
      "epoch:9 step:8958 [D loss: 0.675165, acc.: 57.81%] [G loss: 0.893113]\n",
      "epoch:9 step:8959 [D loss: 0.695803, acc.: 52.34%] [G loss: 0.887973]\n",
      "epoch:9 step:8960 [D loss: 0.667105, acc.: 56.25%] [G loss: 0.829734]\n",
      "epoch:9 step:8961 [D loss: 0.712779, acc.: 60.94%] [G loss: 0.797693]\n",
      "epoch:9 step:8962 [D loss: 0.639372, acc.: 60.94%] [G loss: 0.883826]\n",
      "epoch:9 step:8963 [D loss: 0.663118, acc.: 57.81%] [G loss: 0.818779]\n",
      "epoch:9 step:8964 [D loss: 0.685599, acc.: 57.03%] [G loss: 0.888198]\n",
      "epoch:9 step:8965 [D loss: 0.671766, acc.: 57.03%] [G loss: 0.869052]\n",
      "epoch:9 step:8966 [D loss: 0.654434, acc.: 61.72%] [G loss: 0.884338]\n",
      "epoch:9 step:8967 [D loss: 0.644098, acc.: 61.72%] [G loss: 0.899870]\n",
      "epoch:9 step:8968 [D loss: 0.692652, acc.: 58.59%] [G loss: 0.872148]\n",
      "epoch:9 step:8969 [D loss: 0.681865, acc.: 52.34%] [G loss: 0.873210]\n",
      "epoch:9 step:8970 [D loss: 0.691619, acc.: 51.56%] [G loss: 0.920115]\n",
      "epoch:9 step:8971 [D loss: 0.686831, acc.: 57.81%] [G loss: 0.862052]\n",
      "epoch:9 step:8972 [D loss: 0.715001, acc.: 53.12%] [G loss: 0.801032]\n",
      "epoch:9 step:8973 [D loss: 0.676493, acc.: 59.38%] [G loss: 0.798330]\n",
      "epoch:9 step:8974 [D loss: 0.644155, acc.: 61.72%] [G loss: 0.849382]\n",
      "epoch:9 step:8975 [D loss: 0.686338, acc.: 57.81%] [G loss: 0.825781]\n",
      "epoch:9 step:8976 [D loss: 0.665702, acc.: 62.50%] [G loss: 0.889311]\n",
      "epoch:9 step:8977 [D loss: 0.646623, acc.: 62.50%] [G loss: 0.852540]\n",
      "epoch:9 step:8978 [D loss: 0.715475, acc.: 51.56%] [G loss: 0.834201]\n",
      "epoch:9 step:8979 [D loss: 0.680517, acc.: 58.59%] [G loss: 0.852989]\n",
      "epoch:9 step:8980 [D loss: 0.687929, acc.: 56.25%] [G loss: 0.886646]\n",
      "epoch:9 step:8981 [D loss: 0.646680, acc.: 66.41%] [G loss: 0.863601]\n",
      "epoch:9 step:8982 [D loss: 0.664127, acc.: 61.72%] [G loss: 0.837122]\n",
      "epoch:9 step:8983 [D loss: 0.643600, acc.: 63.28%] [G loss: 0.861457]\n",
      "epoch:9 step:8984 [D loss: 0.634783, acc.: 66.41%] [G loss: 0.850026]\n",
      "epoch:9 step:8985 [D loss: 0.666502, acc.: 56.25%] [G loss: 0.832354]\n",
      "epoch:9 step:8986 [D loss: 0.698624, acc.: 50.78%] [G loss: 0.890060]\n",
      "epoch:9 step:8987 [D loss: 0.664927, acc.: 57.81%] [G loss: 0.833052]\n",
      "epoch:9 step:8988 [D loss: 0.672613, acc.: 60.94%] [G loss: 0.812048]\n",
      "epoch:9 step:8989 [D loss: 0.688582, acc.: 50.78%] [G loss: 0.795637]\n",
      "epoch:9 step:8990 [D loss: 0.672183, acc.: 54.69%] [G loss: 0.874802]\n",
      "epoch:9 step:8991 [D loss: 0.662394, acc.: 60.94%] [G loss: 0.816358]\n",
      "epoch:9 step:8992 [D loss: 0.670196, acc.: 53.91%] [G loss: 0.815269]\n",
      "epoch:9 step:8993 [D loss: 0.652632, acc.: 60.16%] [G loss: 0.816995]\n",
      "epoch:9 step:8994 [D loss: 0.670141, acc.: 62.50%] [G loss: 0.783984]\n",
      "epoch:9 step:8995 [D loss: 0.654512, acc.: 58.59%] [G loss: 0.783909]\n",
      "epoch:9 step:8996 [D loss: 0.659518, acc.: 61.72%] [G loss: 0.885317]\n",
      "epoch:9 step:8997 [D loss: 0.645772, acc.: 61.72%] [G loss: 0.818980]\n",
      "epoch:9 step:8998 [D loss: 0.681555, acc.: 57.03%] [G loss: 0.873794]\n",
      "epoch:9 step:8999 [D loss: 0.649963, acc.: 60.16%] [G loss: 0.935286]\n",
      "epoch:9 step:9000 [D loss: 0.650121, acc.: 62.50%] [G loss: 0.837784]\n",
      "##############\n",
      "[2.89599908 2.44052058 2.39871948 3.76372371 1.47643805 8.69720077\n",
      " 2.89701174 4.09324673 4.15344572 6.08989694]\n",
      "##########\n",
      "epoch:9 step:9001 [D loss: 0.688101, acc.: 53.12%] [G loss: 0.923792]\n",
      "epoch:9 step:9002 [D loss: 0.629814, acc.: 67.19%] [G loss: 0.892999]\n",
      "epoch:9 step:9003 [D loss: 0.700630, acc.: 50.78%] [G loss: 0.890857]\n",
      "epoch:9 step:9004 [D loss: 0.692555, acc.: 55.47%] [G loss: 0.875023]\n",
      "epoch:9 step:9005 [D loss: 0.677682, acc.: 57.03%] [G loss: 0.798793]\n",
      "epoch:9 step:9006 [D loss: 0.695686, acc.: 50.00%] [G loss: 0.784161]\n",
      "epoch:9 step:9007 [D loss: 0.673003, acc.: 56.25%] [G loss: 0.839951]\n",
      "epoch:9 step:9008 [D loss: 0.649139, acc.: 64.06%] [G loss: 0.855005]\n",
      "epoch:9 step:9009 [D loss: 0.682743, acc.: 59.38%] [G loss: 0.859759]\n",
      "epoch:9 step:9010 [D loss: 0.643642, acc.: 66.41%] [G loss: 0.921694]\n",
      "epoch:9 step:9011 [D loss: 0.646049, acc.: 61.72%] [G loss: 0.909558]\n",
      "epoch:9 step:9012 [D loss: 0.672596, acc.: 57.81%] [G loss: 0.881618]\n",
      "epoch:9 step:9013 [D loss: 0.661714, acc.: 55.47%] [G loss: 0.838468]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9014 [D loss: 0.657650, acc.: 65.62%] [G loss: 0.807023]\n",
      "epoch:9 step:9015 [D loss: 0.668507, acc.: 59.38%] [G loss: 0.877961]\n",
      "epoch:9 step:9016 [D loss: 0.672763, acc.: 60.94%] [G loss: 0.903493]\n",
      "epoch:9 step:9017 [D loss: 0.662181, acc.: 57.03%] [G loss: 0.861827]\n",
      "epoch:9 step:9018 [D loss: 0.673439, acc.: 57.03%] [G loss: 0.854342]\n",
      "epoch:9 step:9019 [D loss: 0.689942, acc.: 55.47%] [G loss: 0.829832]\n",
      "epoch:9 step:9020 [D loss: 0.683288, acc.: 50.78%] [G loss: 0.823094]\n",
      "epoch:9 step:9021 [D loss: 0.691492, acc.: 57.03%] [G loss: 0.846452]\n",
      "epoch:9 step:9022 [D loss: 0.639821, acc.: 62.50%] [G loss: 0.861864]\n",
      "epoch:9 step:9023 [D loss: 0.686958, acc.: 58.59%] [G loss: 0.833967]\n",
      "epoch:9 step:9024 [D loss: 0.672586, acc.: 57.03%] [G loss: 0.841659]\n",
      "epoch:9 step:9025 [D loss: 0.640445, acc.: 60.16%] [G loss: 0.834977]\n",
      "epoch:9 step:9026 [D loss: 0.694574, acc.: 49.22%] [G loss: 0.824166]\n",
      "epoch:9 step:9027 [D loss: 0.650084, acc.: 60.94%] [G loss: 0.825373]\n",
      "epoch:9 step:9028 [D loss: 0.657503, acc.: 59.38%] [G loss: 0.790314]\n",
      "epoch:9 step:9029 [D loss: 0.681106, acc.: 58.59%] [G loss: 0.863076]\n",
      "epoch:9 step:9030 [D loss: 0.680717, acc.: 53.91%] [G loss: 0.887924]\n",
      "epoch:9 step:9031 [D loss: 0.696296, acc.: 50.00%] [G loss: 0.906814]\n",
      "epoch:9 step:9032 [D loss: 0.652061, acc.: 55.47%] [G loss: 0.876161]\n",
      "epoch:9 step:9033 [D loss: 0.686305, acc.: 57.03%] [G loss: 0.870213]\n",
      "epoch:9 step:9034 [D loss: 0.651758, acc.: 65.62%] [G loss: 0.882490]\n",
      "epoch:9 step:9035 [D loss: 0.655225, acc.: 64.84%] [G loss: 0.854574]\n",
      "epoch:9 step:9036 [D loss: 0.689487, acc.: 50.78%] [G loss: 0.887948]\n",
      "epoch:9 step:9037 [D loss: 0.712144, acc.: 50.00%] [G loss: 0.862213]\n",
      "epoch:9 step:9038 [D loss: 0.696332, acc.: 57.03%] [G loss: 0.800386]\n",
      "epoch:9 step:9039 [D loss: 0.681161, acc.: 56.25%] [G loss: 0.821190]\n",
      "epoch:9 step:9040 [D loss: 0.675430, acc.: 57.81%] [G loss: 0.826617]\n",
      "epoch:9 step:9041 [D loss: 0.683255, acc.: 53.12%] [G loss: 0.861022]\n",
      "epoch:9 step:9042 [D loss: 0.629445, acc.: 69.53%] [G loss: 0.828762]\n",
      "epoch:9 step:9043 [D loss: 0.634805, acc.: 67.97%] [G loss: 0.891884]\n",
      "epoch:9 step:9044 [D loss: 0.658649, acc.: 61.72%] [G loss: 0.896245]\n",
      "epoch:9 step:9045 [D loss: 0.661443, acc.: 58.59%] [G loss: 0.883064]\n",
      "epoch:9 step:9046 [D loss: 0.662811, acc.: 58.59%] [G loss: 0.846320]\n",
      "epoch:9 step:9047 [D loss: 0.664741, acc.: 53.12%] [G loss: 0.881737]\n",
      "epoch:9 step:9048 [D loss: 0.656523, acc.: 65.62%] [G loss: 0.849136]\n",
      "epoch:9 step:9049 [D loss: 0.683290, acc.: 57.81%] [G loss: 0.836552]\n",
      "epoch:9 step:9050 [D loss: 0.649395, acc.: 57.03%] [G loss: 0.848718]\n",
      "epoch:9 step:9051 [D loss: 0.654629, acc.: 59.38%] [G loss: 0.846746]\n",
      "epoch:9 step:9052 [D loss: 0.690371, acc.: 56.25%] [G loss: 0.877651]\n",
      "epoch:9 step:9053 [D loss: 0.645480, acc.: 64.06%] [G loss: 0.813482]\n",
      "epoch:9 step:9054 [D loss: 0.709259, acc.: 53.91%] [G loss: 0.870233]\n",
      "epoch:9 step:9055 [D loss: 0.641992, acc.: 70.31%] [G loss: 0.873398]\n",
      "epoch:9 step:9056 [D loss: 0.670565, acc.: 57.03%] [G loss: 0.857540]\n",
      "epoch:9 step:9057 [D loss: 0.687944, acc.: 55.47%] [G loss: 0.831512]\n",
      "epoch:9 step:9058 [D loss: 0.689224, acc.: 50.78%] [G loss: 0.808804]\n",
      "epoch:9 step:9059 [D loss: 0.681187, acc.: 57.81%] [G loss: 0.835553]\n",
      "epoch:9 step:9060 [D loss: 0.639980, acc.: 62.50%] [G loss: 0.827628]\n",
      "epoch:9 step:9061 [D loss: 0.688746, acc.: 53.12%] [G loss: 0.893631]\n",
      "epoch:9 step:9062 [D loss: 0.702241, acc.: 53.91%] [G loss: 0.886169]\n",
      "epoch:9 step:9063 [D loss: 0.665267, acc.: 54.69%] [G loss: 0.831454]\n",
      "epoch:9 step:9064 [D loss: 0.658674, acc.: 60.16%] [G loss: 0.845614]\n",
      "epoch:9 step:9065 [D loss: 0.664260, acc.: 57.03%] [G loss: 0.855176]\n",
      "epoch:9 step:9066 [D loss: 0.702329, acc.: 53.91%] [G loss: 0.846493]\n",
      "epoch:9 step:9067 [D loss: 0.703401, acc.: 48.44%] [G loss: 0.874917]\n",
      "epoch:9 step:9068 [D loss: 0.659318, acc.: 57.81%] [G loss: 0.900160]\n",
      "epoch:9 step:9069 [D loss: 0.659071, acc.: 62.50%] [G loss: 0.905224]\n",
      "epoch:9 step:9070 [D loss: 0.655357, acc.: 59.38%] [G loss: 0.876579]\n",
      "epoch:9 step:9071 [D loss: 0.704543, acc.: 53.91%] [G loss: 0.868047]\n",
      "epoch:9 step:9072 [D loss: 0.667352, acc.: 59.38%] [G loss: 0.843673]\n",
      "epoch:9 step:9073 [D loss: 0.678032, acc.: 54.69%] [G loss: 0.853272]\n",
      "epoch:9 step:9074 [D loss: 0.698590, acc.: 51.56%] [G loss: 0.888637]\n",
      "epoch:9 step:9075 [D loss: 0.667695, acc.: 64.06%] [G loss: 0.851504]\n",
      "epoch:9 step:9076 [D loss: 0.716025, acc.: 50.00%] [G loss: 0.823833]\n",
      "epoch:9 step:9077 [D loss: 0.686631, acc.: 53.12%] [G loss: 0.835004]\n",
      "epoch:9 step:9078 [D loss: 0.680146, acc.: 51.56%] [G loss: 0.842062]\n",
      "epoch:9 step:9079 [D loss: 0.659951, acc.: 60.16%] [G loss: 0.856140]\n",
      "epoch:9 step:9080 [D loss: 0.662461, acc.: 63.28%] [G loss: 0.841113]\n",
      "epoch:9 step:9081 [D loss: 0.661760, acc.: 59.38%] [G loss: 0.851855]\n",
      "epoch:9 step:9082 [D loss: 0.706848, acc.: 56.25%] [G loss: 0.813218]\n",
      "epoch:9 step:9083 [D loss: 0.634874, acc.: 62.50%] [G loss: 0.827704]\n",
      "epoch:9 step:9084 [D loss: 0.673039, acc.: 57.03%] [G loss: 0.801883]\n",
      "epoch:9 step:9085 [D loss: 0.654902, acc.: 61.72%] [G loss: 0.828348]\n",
      "epoch:9 step:9086 [D loss: 0.670053, acc.: 58.59%] [G loss: 0.804837]\n",
      "epoch:9 step:9087 [D loss: 0.672122, acc.: 58.59%] [G loss: 0.812342]\n",
      "epoch:9 step:9088 [D loss: 0.683596, acc.: 53.12%] [G loss: 0.845080]\n",
      "epoch:9 step:9089 [D loss: 0.677790, acc.: 61.72%] [G loss: 0.820584]\n",
      "epoch:9 step:9090 [D loss: 0.661521, acc.: 64.84%] [G loss: 0.808696]\n",
      "epoch:9 step:9091 [D loss: 0.700755, acc.: 53.12%] [G loss: 0.871779]\n",
      "epoch:9 step:9092 [D loss: 0.637867, acc.: 66.41%] [G loss: 0.857304]\n",
      "epoch:9 step:9093 [D loss: 0.670136, acc.: 59.38%] [G loss: 0.844935]\n",
      "epoch:9 step:9094 [D loss: 0.643322, acc.: 61.72%] [G loss: 0.887359]\n",
      "epoch:9 step:9095 [D loss: 0.690603, acc.: 57.03%] [G loss: 0.816635]\n",
      "epoch:9 step:9096 [D loss: 0.653359, acc.: 63.28%] [G loss: 0.805917]\n",
      "epoch:9 step:9097 [D loss: 0.640725, acc.: 60.94%] [G loss: 0.841206]\n",
      "epoch:9 step:9098 [D loss: 0.685957, acc.: 59.38%] [G loss: 0.800559]\n",
      "epoch:9 step:9099 [D loss: 0.631580, acc.: 67.97%] [G loss: 0.832643]\n",
      "epoch:9 step:9100 [D loss: 0.677887, acc.: 59.38%] [G loss: 0.817074]\n",
      "epoch:9 step:9101 [D loss: 0.661055, acc.: 61.72%] [G loss: 0.849793]\n",
      "epoch:9 step:9102 [D loss: 0.693149, acc.: 56.25%] [G loss: 0.871329]\n",
      "epoch:9 step:9103 [D loss: 0.682604, acc.: 54.69%] [G loss: 0.883783]\n",
      "epoch:9 step:9104 [D loss: 0.661676, acc.: 58.59%] [G loss: 0.917101]\n",
      "epoch:9 step:9105 [D loss: 0.675377, acc.: 56.25%] [G loss: 0.899949]\n",
      "epoch:9 step:9106 [D loss: 0.686323, acc.: 50.00%] [G loss: 0.887294]\n",
      "epoch:9 step:9107 [D loss: 0.681888, acc.: 53.91%] [G loss: 0.853187]\n",
      "epoch:9 step:9108 [D loss: 0.682490, acc.: 54.69%] [G loss: 0.860099]\n",
      "epoch:9 step:9109 [D loss: 0.678126, acc.: 61.72%] [G loss: 0.865462]\n",
      "epoch:9 step:9110 [D loss: 0.670915, acc.: 56.25%] [G loss: 0.838875]\n",
      "epoch:9 step:9111 [D loss: 0.661317, acc.: 63.28%] [G loss: 0.846667]\n",
      "epoch:9 step:9112 [D loss: 0.663886, acc.: 57.81%] [G loss: 0.822477]\n",
      "epoch:9 step:9113 [D loss: 0.696532, acc.: 48.44%] [G loss: 0.859811]\n",
      "epoch:9 step:9114 [D loss: 0.657017, acc.: 61.72%] [G loss: 0.862374]\n",
      "epoch:9 step:9115 [D loss: 0.677844, acc.: 54.69%] [G loss: 0.876177]\n",
      "epoch:9 step:9116 [D loss: 0.672788, acc.: 57.81%] [G loss: 0.857403]\n",
      "epoch:9 step:9117 [D loss: 0.672255, acc.: 57.81%] [G loss: 0.855929]\n",
      "epoch:9 step:9118 [D loss: 0.654486, acc.: 63.28%] [G loss: 0.849551]\n",
      "epoch:9 step:9119 [D loss: 0.665793, acc.: 59.38%] [G loss: 0.841490]\n",
      "epoch:9 step:9120 [D loss: 0.651994, acc.: 60.16%] [G loss: 0.854479]\n",
      "epoch:9 step:9121 [D loss: 0.656738, acc.: 62.50%] [G loss: 0.838519]\n",
      "epoch:9 step:9122 [D loss: 0.660613, acc.: 61.72%] [G loss: 0.829431]\n",
      "epoch:9 step:9123 [D loss: 0.649900, acc.: 62.50%] [G loss: 0.839390]\n",
      "epoch:9 step:9124 [D loss: 0.655012, acc.: 61.72%] [G loss: 0.831316]\n",
      "epoch:9 step:9125 [D loss: 0.645776, acc.: 64.06%] [G loss: 0.794946]\n",
      "epoch:9 step:9126 [D loss: 0.684171, acc.: 55.47%] [G loss: 0.836204]\n",
      "epoch:9 step:9127 [D loss: 0.662027, acc.: 62.50%] [G loss: 0.864818]\n",
      "epoch:9 step:9128 [D loss: 0.680236, acc.: 56.25%] [G loss: 0.851800]\n",
      "epoch:9 step:9129 [D loss: 0.653681, acc.: 61.72%] [G loss: 0.887495]\n",
      "epoch:9 step:9130 [D loss: 0.657162, acc.: 59.38%] [G loss: 0.861237]\n",
      "epoch:9 step:9131 [D loss: 0.655138, acc.: 60.16%] [G loss: 0.825903]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9132 [D loss: 0.680608, acc.: 54.69%] [G loss: 0.833884]\n",
      "epoch:9 step:9133 [D loss: 0.660570, acc.: 53.12%] [G loss: 0.801404]\n",
      "epoch:9 step:9134 [D loss: 0.614755, acc.: 71.09%] [G loss: 0.843756]\n",
      "epoch:9 step:9135 [D loss: 0.641980, acc.: 61.72%] [G loss: 0.843120]\n",
      "epoch:9 step:9136 [D loss: 0.690920, acc.: 59.38%] [G loss: 0.848382]\n",
      "epoch:9 step:9137 [D loss: 0.673416, acc.: 58.59%] [G loss: 0.792408]\n",
      "epoch:9 step:9138 [D loss: 0.690058, acc.: 50.00%] [G loss: 0.849991]\n",
      "epoch:9 step:9139 [D loss: 0.689318, acc.: 51.56%] [G loss: 0.852938]\n",
      "epoch:9 step:9140 [D loss: 0.674191, acc.: 55.47%] [G loss: 0.852714]\n",
      "epoch:9 step:9141 [D loss: 0.676388, acc.: 57.03%] [G loss: 0.883266]\n",
      "epoch:9 step:9142 [D loss: 0.696079, acc.: 53.12%] [G loss: 0.869675]\n",
      "epoch:9 step:9143 [D loss: 0.637670, acc.: 64.06%] [G loss: 0.891333]\n",
      "epoch:9 step:9144 [D loss: 0.665846, acc.: 60.94%] [G loss: 0.843251]\n",
      "epoch:9 step:9145 [D loss: 0.717229, acc.: 53.12%] [G loss: 0.851057]\n",
      "epoch:9 step:9146 [D loss: 0.671564, acc.: 59.38%] [G loss: 0.829384]\n",
      "epoch:9 step:9147 [D loss: 0.698608, acc.: 54.69%] [G loss: 0.857387]\n",
      "epoch:9 step:9148 [D loss: 0.662234, acc.: 60.94%] [G loss: 0.840319]\n",
      "epoch:9 step:9149 [D loss: 0.691497, acc.: 53.12%] [G loss: 0.839485]\n",
      "epoch:9 step:9150 [D loss: 0.641771, acc.: 62.50%] [G loss: 0.823500]\n",
      "epoch:9 step:9151 [D loss: 0.658985, acc.: 60.16%] [G loss: 0.891984]\n",
      "epoch:9 step:9152 [D loss: 0.659434, acc.: 60.94%] [G loss: 0.831008]\n",
      "epoch:9 step:9153 [D loss: 0.649878, acc.: 66.41%] [G loss: 0.825041]\n",
      "epoch:9 step:9154 [D loss: 0.677001, acc.: 57.03%] [G loss: 0.851293]\n",
      "epoch:9 step:9155 [D loss: 0.649037, acc.: 60.16%] [G loss: 0.879943]\n",
      "epoch:9 step:9156 [D loss: 0.688160, acc.: 53.91%] [G loss: 0.844620]\n",
      "epoch:9 step:9157 [D loss: 0.679452, acc.: 60.94%] [G loss: 0.837926]\n",
      "epoch:9 step:9158 [D loss: 0.651769, acc.: 63.28%] [G loss: 0.887422]\n",
      "epoch:9 step:9159 [D loss: 0.686085, acc.: 60.16%] [G loss: 0.865172]\n",
      "epoch:9 step:9160 [D loss: 0.652880, acc.: 57.81%] [G loss: 0.847756]\n",
      "epoch:9 step:9161 [D loss: 0.661904, acc.: 62.50%] [G loss: 0.855641]\n",
      "epoch:9 step:9162 [D loss: 0.678839, acc.: 57.81%] [G loss: 0.847854]\n",
      "epoch:9 step:9163 [D loss: 0.674861, acc.: 57.03%] [G loss: 0.790262]\n",
      "epoch:9 step:9164 [D loss: 0.674211, acc.: 54.69%] [G loss: 0.845544]\n",
      "epoch:9 step:9165 [D loss: 0.670712, acc.: 59.38%] [G loss: 0.808925]\n",
      "epoch:9 step:9166 [D loss: 0.674838, acc.: 60.16%] [G loss: 0.835046]\n",
      "epoch:9 step:9167 [D loss: 0.642066, acc.: 64.84%] [G loss: 0.844555]\n",
      "epoch:9 step:9168 [D loss: 0.661676, acc.: 58.59%] [G loss: 0.834613]\n",
      "epoch:9 step:9169 [D loss: 0.667672, acc.: 67.97%] [G loss: 0.817545]\n",
      "epoch:9 step:9170 [D loss: 0.680947, acc.: 58.59%] [G loss: 0.800357]\n",
      "epoch:9 step:9171 [D loss: 0.700098, acc.: 52.34%] [G loss: 0.818227]\n",
      "epoch:9 step:9172 [D loss: 0.686178, acc.: 52.34%] [G loss: 0.871438]\n",
      "epoch:9 step:9173 [D loss: 0.708536, acc.: 51.56%] [G loss: 0.878826]\n",
      "epoch:9 step:9174 [D loss: 0.638956, acc.: 57.03%] [G loss: 0.837933]\n",
      "epoch:9 step:9175 [D loss: 0.683132, acc.: 57.81%] [G loss: 0.827465]\n",
      "epoch:9 step:9176 [D loss: 0.708357, acc.: 51.56%] [G loss: 0.812184]\n",
      "epoch:9 step:9177 [D loss: 0.680394, acc.: 55.47%] [G loss: 0.815889]\n",
      "epoch:9 step:9178 [D loss: 0.714667, acc.: 53.91%] [G loss: 0.793109]\n",
      "epoch:9 step:9179 [D loss: 0.652678, acc.: 66.41%] [G loss: 0.805788]\n",
      "epoch:9 step:9180 [D loss: 0.679514, acc.: 58.59%] [G loss: 0.834313]\n",
      "epoch:9 step:9181 [D loss: 0.652937, acc.: 60.94%] [G loss: 0.852535]\n",
      "epoch:9 step:9182 [D loss: 0.679019, acc.: 56.25%] [G loss: 0.827035]\n",
      "epoch:9 step:9183 [D loss: 0.630463, acc.: 64.84%] [G loss: 0.863793]\n",
      "epoch:9 step:9184 [D loss: 0.635458, acc.: 57.81%] [G loss: 0.849879]\n",
      "epoch:9 step:9185 [D loss: 0.674002, acc.: 58.59%] [G loss: 0.874127]\n",
      "epoch:9 step:9186 [D loss: 0.652107, acc.: 61.72%] [G loss: 0.872924]\n",
      "epoch:9 step:9187 [D loss: 0.681754, acc.: 57.81%] [G loss: 0.820769]\n",
      "epoch:9 step:9188 [D loss: 0.650610, acc.: 61.72%] [G loss: 0.898589]\n",
      "epoch:9 step:9189 [D loss: 0.680185, acc.: 56.25%] [G loss: 0.845460]\n",
      "epoch:9 step:9190 [D loss: 0.644985, acc.: 61.72%] [G loss: 0.838666]\n",
      "epoch:9 step:9191 [D loss: 0.664425, acc.: 56.25%] [G loss: 0.819802]\n",
      "epoch:9 step:9192 [D loss: 0.694554, acc.: 53.91%] [G loss: 0.813806]\n",
      "epoch:9 step:9193 [D loss: 0.673716, acc.: 57.03%] [G loss: 0.832402]\n",
      "epoch:9 step:9194 [D loss: 0.677858, acc.: 55.47%] [G loss: 0.833247]\n",
      "epoch:9 step:9195 [D loss: 0.650513, acc.: 61.72%] [G loss: 0.840774]\n",
      "epoch:9 step:9196 [D loss: 0.669300, acc.: 55.47%] [G loss: 0.794708]\n",
      "epoch:9 step:9197 [D loss: 0.664507, acc.: 57.03%] [G loss: 0.841320]\n",
      "epoch:9 step:9198 [D loss: 0.664612, acc.: 58.59%] [G loss: 0.818887]\n",
      "epoch:9 step:9199 [D loss: 0.681053, acc.: 55.47%] [G loss: 0.847369]\n",
      "epoch:9 step:9200 [D loss: 0.676984, acc.: 56.25%] [G loss: 0.833914]\n",
      "##############\n",
      "[2.7406119  2.44067059 2.23172914 3.87411227 1.50478444 9.27426719\n",
      " 2.67317003 4.29500057 4.1656432  7.14868929]\n",
      "##########\n",
      "epoch:9 step:9201 [D loss: 0.657138, acc.: 59.38%] [G loss: 0.837974]\n",
      "epoch:9 step:9202 [D loss: 0.676688, acc.: 53.91%] [G loss: 0.830724]\n",
      "epoch:9 step:9203 [D loss: 0.665518, acc.: 61.72%] [G loss: 0.832971]\n",
      "epoch:9 step:9204 [D loss: 0.668808, acc.: 54.69%] [G loss: 0.767374]\n",
      "epoch:9 step:9205 [D loss: 0.685906, acc.: 54.69%] [G loss: 0.807210]\n",
      "epoch:9 step:9206 [D loss: 0.674758, acc.: 61.72%] [G loss: 0.804668]\n",
      "epoch:9 step:9207 [D loss: 0.648040, acc.: 63.28%] [G loss: 0.839607]\n",
      "epoch:9 step:9208 [D loss: 0.692571, acc.: 52.34%] [G loss: 0.848350]\n",
      "epoch:9 step:9209 [D loss: 0.638275, acc.: 69.53%] [G loss: 0.854301]\n",
      "epoch:9 step:9210 [D loss: 0.664358, acc.: 58.59%] [G loss: 0.872910]\n",
      "epoch:9 step:9211 [D loss: 0.652351, acc.: 56.25%] [G loss: 0.853895]\n",
      "epoch:9 step:9212 [D loss: 0.644101, acc.: 62.50%] [G loss: 0.888656]\n",
      "epoch:9 step:9213 [D loss: 0.672601, acc.: 57.03%] [G loss: 0.875000]\n",
      "epoch:9 step:9214 [D loss: 0.710609, acc.: 53.12%] [G loss: 0.855139]\n",
      "epoch:9 step:9215 [D loss: 0.651751, acc.: 59.38%] [G loss: 0.839283]\n",
      "epoch:9 step:9216 [D loss: 0.683938, acc.: 50.00%] [G loss: 0.843517]\n",
      "epoch:9 step:9217 [D loss: 0.684350, acc.: 58.59%] [G loss: 0.828376]\n",
      "epoch:9 step:9218 [D loss: 0.657767, acc.: 58.59%] [G loss: 0.852033]\n",
      "epoch:9 step:9219 [D loss: 0.664399, acc.: 63.28%] [G loss: 0.814651]\n",
      "epoch:9 step:9220 [D loss: 0.661112, acc.: 57.81%] [G loss: 0.847219]\n",
      "epoch:9 step:9221 [D loss: 0.656354, acc.: 60.94%] [G loss: 0.836542]\n",
      "epoch:9 step:9222 [D loss: 0.675239, acc.: 55.47%] [G loss: 0.870419]\n",
      "epoch:9 step:9223 [D loss: 0.666487, acc.: 50.78%] [G loss: 0.842521]\n",
      "epoch:9 step:9224 [D loss: 0.663215, acc.: 63.28%] [G loss: 0.817173]\n",
      "epoch:9 step:9225 [D loss: 0.649377, acc.: 61.72%] [G loss: 0.813828]\n",
      "epoch:9 step:9226 [D loss: 0.643299, acc.: 68.75%] [G loss: 0.838133]\n",
      "epoch:9 step:9227 [D loss: 0.617033, acc.: 68.75%] [G loss: 0.821276]\n",
      "epoch:9 step:9228 [D loss: 0.653781, acc.: 61.72%] [G loss: 0.817725]\n",
      "epoch:9 step:9229 [D loss: 0.617979, acc.: 64.06%] [G loss: 0.832140]\n",
      "epoch:9 step:9230 [D loss: 0.697902, acc.: 53.12%] [G loss: 0.817744]\n",
      "epoch:9 step:9231 [D loss: 0.640922, acc.: 62.50%] [G loss: 0.808516]\n",
      "epoch:9 step:9232 [D loss: 0.684216, acc.: 52.34%] [G loss: 0.876180]\n",
      "epoch:9 step:9233 [D loss: 0.667512, acc.: 60.94%] [G loss: 0.871946]\n",
      "epoch:9 step:9234 [D loss: 0.648541, acc.: 62.50%] [G loss: 0.841943]\n",
      "epoch:9 step:9235 [D loss: 0.657549, acc.: 61.72%] [G loss: 0.912148]\n",
      "epoch:9 step:9236 [D loss: 0.668472, acc.: 61.72%] [G loss: 0.904815]\n",
      "epoch:9 step:9237 [D loss: 0.707419, acc.: 52.34%] [G loss: 0.884802]\n",
      "epoch:9 step:9238 [D loss: 0.692114, acc.: 50.78%] [G loss: 0.842012]\n",
      "epoch:9 step:9239 [D loss: 0.645411, acc.: 63.28%] [G loss: 0.826912]\n",
      "epoch:9 step:9240 [D loss: 0.675792, acc.: 56.25%] [G loss: 0.845069]\n",
      "epoch:9 step:9241 [D loss: 0.670814, acc.: 57.03%] [G loss: 0.815198]\n",
      "epoch:9 step:9242 [D loss: 0.682859, acc.: 53.91%] [G loss: 0.818120]\n",
      "epoch:9 step:9243 [D loss: 0.650963, acc.: 63.28%] [G loss: 0.821076]\n",
      "epoch:9 step:9244 [D loss: 0.648991, acc.: 60.94%] [G loss: 0.835650]\n",
      "epoch:9 step:9245 [D loss: 0.708986, acc.: 51.56%] [G loss: 0.875890]\n",
      "epoch:9 step:9246 [D loss: 0.657640, acc.: 61.72%] [G loss: 0.842955]\n",
      "epoch:9 step:9247 [D loss: 0.621099, acc.: 67.19%] [G loss: 0.916346]\n",
      "epoch:9 step:9248 [D loss: 0.687738, acc.: 58.59%] [G loss: 0.886006]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9249 [D loss: 0.634462, acc.: 61.72%] [G loss: 0.860503]\n",
      "epoch:9 step:9250 [D loss: 0.707868, acc.: 48.44%] [G loss: 0.833981]\n",
      "epoch:9 step:9251 [D loss: 0.685954, acc.: 56.25%] [G loss: 0.861586]\n",
      "epoch:9 step:9252 [D loss: 0.725484, acc.: 47.66%] [G loss: 0.870505]\n",
      "epoch:9 step:9253 [D loss: 0.651736, acc.: 57.81%] [G loss: 0.838239]\n",
      "epoch:9 step:9254 [D loss: 0.675567, acc.: 58.59%] [G loss: 0.830191]\n",
      "epoch:9 step:9255 [D loss: 0.624876, acc.: 67.19%] [G loss: 0.858238]\n",
      "epoch:9 step:9256 [D loss: 0.696173, acc.: 57.81%] [G loss: 0.805637]\n",
      "epoch:9 step:9257 [D loss: 0.732656, acc.: 47.66%] [G loss: 0.809241]\n",
      "epoch:9 step:9258 [D loss: 0.706972, acc.: 50.78%] [G loss: 0.793194]\n",
      "epoch:9 step:9259 [D loss: 0.655937, acc.: 59.38%] [G loss: 0.830479]\n",
      "epoch:9 step:9260 [D loss: 0.665630, acc.: 56.25%] [G loss: 0.819394]\n",
      "epoch:9 step:9261 [D loss: 0.690359, acc.: 55.47%] [G loss: 0.810291]\n",
      "epoch:9 step:9262 [D loss: 0.671644, acc.: 56.25%] [G loss: 0.854043]\n",
      "epoch:9 step:9263 [D loss: 0.663355, acc.: 57.81%] [G loss: 0.844504]\n",
      "epoch:9 step:9264 [D loss: 0.705198, acc.: 51.56%] [G loss: 0.836280]\n",
      "epoch:9 step:9265 [D loss: 0.682180, acc.: 50.00%] [G loss: 0.865126]\n",
      "epoch:9 step:9266 [D loss: 0.685284, acc.: 54.69%] [G loss: 0.806441]\n",
      "epoch:9 step:9267 [D loss: 0.651531, acc.: 60.94%] [G loss: 0.849362]\n",
      "epoch:9 step:9268 [D loss: 0.662625, acc.: 62.50%] [G loss: 0.799319]\n",
      "epoch:9 step:9269 [D loss: 0.682106, acc.: 53.12%] [G loss: 0.799710]\n",
      "epoch:9 step:9270 [D loss: 0.638321, acc.: 65.62%] [G loss: 0.850012]\n",
      "epoch:9 step:9271 [D loss: 0.652959, acc.: 64.84%] [G loss: 0.854310]\n",
      "epoch:9 step:9272 [D loss: 0.662607, acc.: 63.28%] [G loss: 0.885009]\n",
      "epoch:9 step:9273 [D loss: 0.676904, acc.: 57.81%] [G loss: 0.863151]\n",
      "epoch:9 step:9274 [D loss: 0.704071, acc.: 50.00%] [G loss: 0.845473]\n",
      "epoch:9 step:9275 [D loss: 0.697595, acc.: 50.78%] [G loss: 0.874693]\n",
      "epoch:9 step:9276 [D loss: 0.696540, acc.: 53.12%] [G loss: 0.843177]\n",
      "epoch:9 step:9277 [D loss: 0.641613, acc.: 61.72%] [G loss: 0.888701]\n",
      "epoch:9 step:9278 [D loss: 0.672958, acc.: 58.59%] [G loss: 0.827823]\n",
      "epoch:9 step:9279 [D loss: 0.662087, acc.: 64.06%] [G loss: 0.853410]\n",
      "epoch:9 step:9280 [D loss: 0.670796, acc.: 55.47%] [G loss: 0.885270]\n",
      "epoch:9 step:9281 [D loss: 0.668581, acc.: 57.03%] [G loss: 0.865399]\n",
      "epoch:9 step:9282 [D loss: 0.657093, acc.: 61.72%] [G loss: 0.887627]\n",
      "epoch:9 step:9283 [D loss: 0.622857, acc.: 63.28%] [G loss: 0.858433]\n",
      "epoch:9 step:9284 [D loss: 0.701404, acc.: 53.91%] [G loss: 0.828373]\n",
      "epoch:9 step:9285 [D loss: 0.658912, acc.: 59.38%] [G loss: 0.796352]\n",
      "epoch:9 step:9286 [D loss: 0.658952, acc.: 57.81%] [G loss: 0.842662]\n",
      "epoch:9 step:9287 [D loss: 0.662039, acc.: 60.16%] [G loss: 0.900856]\n",
      "epoch:9 step:9288 [D loss: 0.697746, acc.: 51.56%] [G loss: 0.820655]\n",
      "epoch:9 step:9289 [D loss: 0.657964, acc.: 57.81%] [G loss: 0.894964]\n",
      "epoch:9 step:9290 [D loss: 0.666785, acc.: 57.03%] [G loss: 0.884062]\n",
      "epoch:9 step:9291 [D loss: 0.732027, acc.: 40.62%] [G loss: 0.894396]\n",
      "epoch:9 step:9292 [D loss: 0.689927, acc.: 55.47%] [G loss: 0.867059]\n",
      "epoch:9 step:9293 [D loss: 0.695938, acc.: 52.34%] [G loss: 0.886139]\n",
      "epoch:9 step:9294 [D loss: 0.657396, acc.: 62.50%] [G loss: 0.890861]\n",
      "epoch:9 step:9295 [D loss: 0.645291, acc.: 62.50%] [G loss: 0.890243]\n",
      "epoch:9 step:9296 [D loss: 0.656850, acc.: 61.72%] [G loss: 0.801924]\n",
      "epoch:9 step:9297 [D loss: 0.683791, acc.: 51.56%] [G loss: 0.802833]\n",
      "epoch:9 step:9298 [D loss: 0.682064, acc.: 52.34%] [G loss: 0.838085]\n",
      "epoch:9 step:9299 [D loss: 0.657709, acc.: 55.47%] [G loss: 0.878015]\n",
      "epoch:9 step:9300 [D loss: 0.678538, acc.: 59.38%] [G loss: 0.804574]\n",
      "epoch:9 step:9301 [D loss: 0.649528, acc.: 69.53%] [G loss: 0.866771]\n",
      "epoch:9 step:9302 [D loss: 0.662987, acc.: 58.59%] [G loss: 0.833569]\n",
      "epoch:9 step:9303 [D loss: 0.674083, acc.: 58.59%] [G loss: 0.821849]\n",
      "epoch:9 step:9304 [D loss: 0.647265, acc.: 64.84%] [G loss: 0.848276]\n",
      "epoch:9 step:9305 [D loss: 0.690039, acc.: 56.25%] [G loss: 0.863314]\n",
      "epoch:9 step:9306 [D loss: 0.641155, acc.: 66.41%] [G loss: 0.818932]\n",
      "epoch:9 step:9307 [D loss: 0.666664, acc.: 57.81%] [G loss: 0.849653]\n",
      "epoch:9 step:9308 [D loss: 0.679045, acc.: 61.72%] [G loss: 0.830794]\n",
      "epoch:9 step:9309 [D loss: 0.674725, acc.: 60.94%] [G loss: 0.893620]\n",
      "epoch:9 step:9310 [D loss: 0.654679, acc.: 62.50%] [G loss: 0.806014]\n",
      "epoch:9 step:9311 [D loss: 0.685449, acc.: 55.47%] [G loss: 0.880167]\n",
      "epoch:9 step:9312 [D loss: 0.682226, acc.: 58.59%] [G loss: 0.833568]\n",
      "epoch:9 step:9313 [D loss: 0.657118, acc.: 64.84%] [G loss: 0.873842]\n",
      "epoch:9 step:9314 [D loss: 0.682875, acc.: 48.44%] [G loss: 0.876627]\n",
      "epoch:9 step:9315 [D loss: 0.665993, acc.: 57.81%] [G loss: 0.842489]\n",
      "epoch:9 step:9316 [D loss: 0.664988, acc.: 58.59%] [G loss: 0.884119]\n",
      "epoch:9 step:9317 [D loss: 0.666519, acc.: 59.38%] [G loss: 0.880008]\n",
      "epoch:9 step:9318 [D loss: 0.651615, acc.: 64.06%] [G loss: 0.881832]\n",
      "epoch:9 step:9319 [D loss: 0.692487, acc.: 50.78%] [G loss: 0.873457]\n",
      "epoch:9 step:9320 [D loss: 0.669846, acc.: 59.38%] [G loss: 0.818753]\n",
      "epoch:9 step:9321 [D loss: 0.645924, acc.: 60.16%] [G loss: 0.884874]\n",
      "epoch:9 step:9322 [D loss: 0.671292, acc.: 60.94%] [G loss: 0.887352]\n",
      "epoch:9 step:9323 [D loss: 0.678724, acc.: 52.34%] [G loss: 0.853139]\n",
      "epoch:9 step:9324 [D loss: 0.713247, acc.: 41.41%] [G loss: 0.846834]\n",
      "epoch:9 step:9325 [D loss: 0.705742, acc.: 50.00%] [G loss: 0.834222]\n",
      "epoch:9 step:9326 [D loss: 0.685720, acc.: 57.03%] [G loss: 0.873369]\n",
      "epoch:9 step:9327 [D loss: 0.703038, acc.: 51.56%] [G loss: 0.806172]\n",
      "epoch:9 step:9328 [D loss: 0.656032, acc.: 63.28%] [G loss: 0.841474]\n",
      "epoch:9 step:9329 [D loss: 0.635231, acc.: 61.72%] [G loss: 0.876605]\n",
      "epoch:9 step:9330 [D loss: 0.675502, acc.: 57.81%] [G loss: 0.835208]\n",
      "epoch:9 step:9331 [D loss: 0.651623, acc.: 64.06%] [G loss: 0.867108]\n",
      "epoch:9 step:9332 [D loss: 0.675421, acc.: 56.25%] [G loss: 0.826633]\n",
      "epoch:9 step:9333 [D loss: 0.667257, acc.: 59.38%] [G loss: 0.823647]\n",
      "epoch:9 step:9334 [D loss: 0.692704, acc.: 54.69%] [G loss: 0.827419]\n",
      "epoch:9 step:9335 [D loss: 0.679084, acc.: 58.59%] [G loss: 0.832694]\n",
      "epoch:9 step:9336 [D loss: 0.658005, acc.: 57.81%] [G loss: 0.864765]\n",
      "epoch:9 step:9337 [D loss: 0.633059, acc.: 64.06%] [G loss: 0.904047]\n",
      "epoch:9 step:9338 [D loss: 0.656422, acc.: 62.50%] [G loss: 0.807034]\n",
      "epoch:9 step:9339 [D loss: 0.635864, acc.: 64.84%] [G loss: 0.844397]\n",
      "epoch:9 step:9340 [D loss: 0.719158, acc.: 48.44%] [G loss: 0.831056]\n",
      "epoch:9 step:9341 [D loss: 0.703416, acc.: 53.12%] [G loss: 0.891907]\n",
      "epoch:9 step:9342 [D loss: 0.694861, acc.: 53.12%] [G loss: 0.874830]\n",
      "epoch:9 step:9343 [D loss: 0.702207, acc.: 53.91%] [G loss: 0.854533]\n",
      "epoch:9 step:9344 [D loss: 0.664444, acc.: 59.38%] [G loss: 0.857598]\n",
      "epoch:9 step:9345 [D loss: 0.671861, acc.: 58.59%] [G loss: 0.919936]\n",
      "epoch:9 step:9346 [D loss: 0.668765, acc.: 58.59%] [G loss: 0.838311]\n",
      "epoch:9 step:9347 [D loss: 0.668885, acc.: 57.81%] [G loss: 0.856088]\n",
      "epoch:9 step:9348 [D loss: 0.693227, acc.: 53.91%] [G loss: 0.871999]\n",
      "epoch:9 step:9349 [D loss: 0.658213, acc.: 60.94%] [G loss: 0.798415]\n",
      "epoch:9 step:9350 [D loss: 0.655617, acc.: 64.06%] [G loss: 0.828285]\n",
      "epoch:9 step:9351 [D loss: 0.683034, acc.: 57.81%] [G loss: 0.892836]\n",
      "epoch:9 step:9352 [D loss: 0.679439, acc.: 57.03%] [G loss: 0.812914]\n",
      "epoch:9 step:9353 [D loss: 0.704217, acc.: 53.12%] [G loss: 0.885861]\n",
      "epoch:9 step:9354 [D loss: 0.685695, acc.: 57.81%] [G loss: 0.845605]\n",
      "epoch:9 step:9355 [D loss: 0.663769, acc.: 60.94%] [G loss: 0.823186]\n",
      "epoch:9 step:9356 [D loss: 0.672258, acc.: 58.59%] [G loss: 0.862969]\n",
      "epoch:9 step:9357 [D loss: 0.657461, acc.: 57.81%] [G loss: 0.817335]\n",
      "epoch:9 step:9358 [D loss: 0.671407, acc.: 59.38%] [G loss: 0.823277]\n",
      "epoch:9 step:9359 [D loss: 0.677873, acc.: 53.91%] [G loss: 0.834010]\n",
      "epoch:9 step:9360 [D loss: 0.659124, acc.: 62.50%] [G loss: 0.824704]\n",
      "epoch:9 step:9361 [D loss: 0.654568, acc.: 66.41%] [G loss: 0.821114]\n",
      "epoch:9 step:9362 [D loss: 0.675980, acc.: 57.03%] [G loss: 0.828917]\n",
      "epoch:9 step:9363 [D loss: 0.655815, acc.: 58.59%] [G loss: 0.803890]\n",
      "epoch:9 step:9364 [D loss: 0.684980, acc.: 53.12%] [G loss: 0.804187]\n",
      "epoch:9 step:9365 [D loss: 0.668658, acc.: 57.81%] [G loss: 0.849911]\n",
      "epoch:9 step:9366 [D loss: 0.675362, acc.: 55.47%] [G loss: 0.865234]\n",
      "epoch:9 step:9367 [D loss: 0.660141, acc.: 64.06%] [G loss: 0.889190]\n",
      "epoch:9 step:9368 [D loss: 0.687546, acc.: 57.81%] [G loss: 0.859995]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:9 step:9369 [D loss: 0.658972, acc.: 61.72%] [G loss: 0.848063]\n",
      "epoch:9 step:9370 [D loss: 0.678921, acc.: 54.69%] [G loss: 0.848097]\n",
      "epoch:10 step:9371 [D loss: 0.660475, acc.: 64.06%] [G loss: 0.858753]\n",
      "epoch:10 step:9372 [D loss: 0.643860, acc.: 64.84%] [G loss: 0.835001]\n",
      "epoch:10 step:9373 [D loss: 0.687944, acc.: 56.25%] [G loss: 0.818880]\n",
      "epoch:10 step:9374 [D loss: 0.641035, acc.: 67.97%] [G loss: 0.781683]\n",
      "epoch:10 step:9375 [D loss: 0.669310, acc.: 57.03%] [G loss: 0.798309]\n",
      "epoch:10 step:9376 [D loss: 0.677751, acc.: 62.50%] [G loss: 0.832560]\n",
      "epoch:10 step:9377 [D loss: 0.659231, acc.: 55.47%] [G loss: 0.826181]\n",
      "epoch:10 step:9378 [D loss: 0.658476, acc.: 63.28%] [G loss: 0.830666]\n",
      "epoch:10 step:9379 [D loss: 0.682381, acc.: 53.91%] [G loss: 0.813816]\n",
      "epoch:10 step:9380 [D loss: 0.631263, acc.: 67.19%] [G loss: 0.808258]\n",
      "epoch:10 step:9381 [D loss: 0.682981, acc.: 54.69%] [G loss: 0.844723]\n",
      "epoch:10 step:9382 [D loss: 0.639341, acc.: 64.84%] [G loss: 0.862702]\n",
      "epoch:10 step:9383 [D loss: 0.678054, acc.: 53.91%] [G loss: 0.807954]\n",
      "epoch:10 step:9384 [D loss: 0.679647, acc.: 57.03%] [G loss: 0.839346]\n",
      "epoch:10 step:9385 [D loss: 0.664859, acc.: 64.06%] [G loss: 0.817528]\n",
      "epoch:10 step:9386 [D loss: 0.640911, acc.: 70.31%] [G loss: 0.843742]\n",
      "epoch:10 step:9387 [D loss: 0.653253, acc.: 60.94%] [G loss: 0.874865]\n",
      "epoch:10 step:9388 [D loss: 0.666667, acc.: 53.91%] [G loss: 0.814597]\n",
      "epoch:10 step:9389 [D loss: 0.698067, acc.: 45.31%] [G loss: 0.821122]\n",
      "epoch:10 step:9390 [D loss: 0.682990, acc.: 57.81%] [G loss: 0.882367]\n",
      "epoch:10 step:9391 [D loss: 0.667558, acc.: 57.03%] [G loss: 0.813718]\n",
      "epoch:10 step:9392 [D loss: 0.688386, acc.: 53.91%] [G loss: 0.885389]\n",
      "epoch:10 step:9393 [D loss: 0.679059, acc.: 59.38%] [G loss: 0.798997]\n",
      "epoch:10 step:9394 [D loss: 0.680590, acc.: 57.81%] [G loss: 0.868622]\n",
      "epoch:10 step:9395 [D loss: 0.685795, acc.: 57.03%] [G loss: 0.868407]\n",
      "epoch:10 step:9396 [D loss: 0.658110, acc.: 61.72%] [G loss: 0.889951]\n",
      "epoch:10 step:9397 [D loss: 0.670004, acc.: 61.72%] [G loss: 0.820646]\n",
      "epoch:10 step:9398 [D loss: 0.654140, acc.: 60.16%] [G loss: 0.882903]\n",
      "epoch:10 step:9399 [D loss: 0.675520, acc.: 54.69%] [G loss: 0.867687]\n",
      "epoch:10 step:9400 [D loss: 0.680815, acc.: 58.59%] [G loss: 0.886544]\n",
      "##############\n",
      "[2.82295675 2.2372114  2.32139125 3.88601527 1.26553819 7.66692426\n",
      " 2.95593552 3.74689481 4.22113534 6.2685279 ]\n",
      "##########\n",
      "epoch:10 step:9401 [D loss: 0.718701, acc.: 54.69%] [G loss: 0.836732]\n",
      "epoch:10 step:9402 [D loss: 0.670503, acc.: 54.69%] [G loss: 0.841065]\n",
      "epoch:10 step:9403 [D loss: 0.662256, acc.: 53.12%] [G loss: 0.786486]\n",
      "epoch:10 step:9404 [D loss: 0.685192, acc.: 50.00%] [G loss: 0.843819]\n",
      "epoch:10 step:9405 [D loss: 0.662775, acc.: 60.16%] [G loss: 0.843016]\n",
      "epoch:10 step:9406 [D loss: 0.660727, acc.: 63.28%] [G loss: 0.852518]\n",
      "epoch:10 step:9407 [D loss: 0.705903, acc.: 50.78%] [G loss: 0.861931]\n",
      "epoch:10 step:9408 [D loss: 0.690892, acc.: 51.56%] [G loss: 0.839128]\n",
      "epoch:10 step:9409 [D loss: 0.686183, acc.: 52.34%] [G loss: 0.866249]\n",
      "epoch:10 step:9410 [D loss: 0.675410, acc.: 61.72%] [G loss: 0.886461]\n",
      "epoch:10 step:9411 [D loss: 0.660630, acc.: 65.62%] [G loss: 0.818334]\n",
      "epoch:10 step:9412 [D loss: 0.665307, acc.: 57.03%] [G loss: 0.855785]\n",
      "epoch:10 step:9413 [D loss: 0.661359, acc.: 61.72%] [G loss: 0.856527]\n",
      "epoch:10 step:9414 [D loss: 0.689336, acc.: 56.25%] [G loss: 0.872080]\n",
      "epoch:10 step:9415 [D loss: 0.724034, acc.: 46.88%] [G loss: 0.869606]\n",
      "epoch:10 step:9416 [D loss: 0.651602, acc.: 62.50%] [G loss: 0.916409]\n",
      "epoch:10 step:9417 [D loss: 0.677552, acc.: 57.81%] [G loss: 0.875575]\n",
      "epoch:10 step:9418 [D loss: 0.651023, acc.: 66.41%] [G loss: 0.875550]\n",
      "epoch:10 step:9419 [D loss: 0.676322, acc.: 60.94%] [G loss: 0.827918]\n",
      "epoch:10 step:9420 [D loss: 0.637596, acc.: 66.41%] [G loss: 0.840420]\n",
      "epoch:10 step:9421 [D loss: 0.663455, acc.: 61.72%] [G loss: 0.821324]\n",
      "epoch:10 step:9422 [D loss: 0.649530, acc.: 57.81%] [G loss: 0.835433]\n",
      "epoch:10 step:9423 [D loss: 0.659922, acc.: 60.94%] [G loss: 0.839384]\n",
      "epoch:10 step:9424 [D loss: 0.682173, acc.: 62.50%] [G loss: 0.883472]\n",
      "epoch:10 step:9425 [D loss: 0.680151, acc.: 51.56%] [G loss: 0.852738]\n",
      "epoch:10 step:9426 [D loss: 0.673695, acc.: 53.91%] [G loss: 0.900423]\n",
      "epoch:10 step:9427 [D loss: 0.697006, acc.: 53.91%] [G loss: 0.871797]\n",
      "epoch:10 step:9428 [D loss: 0.690007, acc.: 53.91%] [G loss: 0.886103]\n",
      "epoch:10 step:9429 [D loss: 0.658688, acc.: 64.84%] [G loss: 0.875779]\n",
      "epoch:10 step:9430 [D loss: 0.612502, acc.: 68.75%] [G loss: 0.846804]\n",
      "epoch:10 step:9431 [D loss: 0.693266, acc.: 54.69%] [G loss: 0.836516]\n",
      "epoch:10 step:9432 [D loss: 0.706514, acc.: 50.78%] [G loss: 0.857279]\n",
      "epoch:10 step:9433 [D loss: 0.669047, acc.: 53.91%] [G loss: 0.863299]\n",
      "epoch:10 step:9434 [D loss: 0.688725, acc.: 49.22%] [G loss: 0.839772]\n",
      "epoch:10 step:9435 [D loss: 0.667407, acc.: 53.12%] [G loss: 0.865970]\n",
      "epoch:10 step:9436 [D loss: 0.683513, acc.: 57.03%] [G loss: 0.850763]\n",
      "epoch:10 step:9437 [D loss: 0.707419, acc.: 53.91%] [G loss: 0.872395]\n",
      "epoch:10 step:9438 [D loss: 0.656446, acc.: 58.59%] [G loss: 0.912646]\n",
      "epoch:10 step:9439 [D loss: 0.678863, acc.: 57.81%] [G loss: 0.927674]\n",
      "epoch:10 step:9440 [D loss: 0.666162, acc.: 60.94%] [G loss: 0.920653]\n",
      "epoch:10 step:9441 [D loss: 0.685550, acc.: 53.91%] [G loss: 0.844291]\n",
      "epoch:10 step:9442 [D loss: 0.689517, acc.: 57.03%] [G loss: 0.827666]\n",
      "epoch:10 step:9443 [D loss: 0.621227, acc.: 66.41%] [G loss: 0.833864]\n",
      "epoch:10 step:9444 [D loss: 0.686657, acc.: 54.69%] [G loss: 0.855912]\n",
      "epoch:10 step:9445 [D loss: 0.679221, acc.: 58.59%] [G loss: 0.857237]\n",
      "epoch:10 step:9446 [D loss: 0.623262, acc.: 71.88%] [G loss: 0.804199]\n",
      "epoch:10 step:9447 [D loss: 0.711606, acc.: 50.00%] [G loss: 0.834683]\n",
      "epoch:10 step:9448 [D loss: 0.665530, acc.: 60.94%] [G loss: 0.838982]\n",
      "epoch:10 step:9449 [D loss: 0.675996, acc.: 60.16%] [G loss: 0.827175]\n",
      "epoch:10 step:9450 [D loss: 0.643460, acc.: 63.28%] [G loss: 0.815702]\n",
      "epoch:10 step:9451 [D loss: 0.713998, acc.: 50.00%] [G loss: 0.902043]\n",
      "epoch:10 step:9452 [D loss: 0.627620, acc.: 66.41%] [G loss: 0.913183]\n",
      "epoch:10 step:9453 [D loss: 0.681949, acc.: 61.72%] [G loss: 0.825626]\n",
      "epoch:10 step:9454 [D loss: 0.640941, acc.: 65.62%] [G loss: 0.870927]\n",
      "epoch:10 step:9455 [D loss: 0.649249, acc.: 60.16%] [G loss: 0.916437]\n",
      "epoch:10 step:9456 [D loss: 0.666329, acc.: 61.72%] [G loss: 0.869478]\n",
      "epoch:10 step:9457 [D loss: 0.674300, acc.: 54.69%] [G loss: 0.816390]\n",
      "epoch:10 step:9458 [D loss: 0.652776, acc.: 66.41%] [G loss: 0.831790]\n",
      "epoch:10 step:9459 [D loss: 0.656623, acc.: 60.16%] [G loss: 0.817490]\n",
      "epoch:10 step:9460 [D loss: 0.688946, acc.: 60.94%] [G loss: 0.853235]\n",
      "epoch:10 step:9461 [D loss: 0.687209, acc.: 53.12%] [G loss: 0.829107]\n",
      "epoch:10 step:9462 [D loss: 0.641451, acc.: 63.28%] [G loss: 0.824383]\n",
      "epoch:10 step:9463 [D loss: 0.666863, acc.: 58.59%] [G loss: 0.813280]\n",
      "epoch:10 step:9464 [D loss: 0.678075, acc.: 57.03%] [G loss: 0.831841]\n",
      "epoch:10 step:9465 [D loss: 0.669551, acc.: 60.16%] [G loss: 0.830795]\n",
      "epoch:10 step:9466 [D loss: 0.652327, acc.: 59.38%] [G loss: 0.808159]\n",
      "epoch:10 step:9467 [D loss: 0.646318, acc.: 60.94%] [G loss: 0.846476]\n",
      "epoch:10 step:9468 [D loss: 0.688613, acc.: 59.38%] [G loss: 0.829686]\n",
      "epoch:10 step:9469 [D loss: 0.661794, acc.: 57.81%] [G loss: 0.820606]\n",
      "epoch:10 step:9470 [D loss: 0.688594, acc.: 57.81%] [G loss: 0.851537]\n",
      "epoch:10 step:9471 [D loss: 0.641840, acc.: 64.84%] [G loss: 0.838120]\n",
      "epoch:10 step:9472 [D loss: 0.718565, acc.: 53.12%] [G loss: 0.774784]\n",
      "epoch:10 step:9473 [D loss: 0.621169, acc.: 67.97%] [G loss: 0.810854]\n",
      "epoch:10 step:9474 [D loss: 0.664641, acc.: 60.94%] [G loss: 0.808962]\n",
      "epoch:10 step:9475 [D loss: 0.620226, acc.: 67.19%] [G loss: 0.826882]\n",
      "epoch:10 step:9476 [D loss: 0.673426, acc.: 60.94%] [G loss: 0.814732]\n",
      "epoch:10 step:9477 [D loss: 0.659142, acc.: 60.16%] [G loss: 0.808470]\n",
      "epoch:10 step:9478 [D loss: 0.660223, acc.: 60.94%] [G loss: 0.797231]\n",
      "epoch:10 step:9479 [D loss: 0.673722, acc.: 54.69%] [G loss: 0.885865]\n",
      "epoch:10 step:9480 [D loss: 0.696932, acc.: 54.69%] [G loss: 0.903806]\n",
      "epoch:10 step:9481 [D loss: 0.721608, acc.: 47.66%] [G loss: 0.845222]\n",
      "epoch:10 step:9482 [D loss: 0.715595, acc.: 50.78%] [G loss: 0.834453]\n",
      "epoch:10 step:9483 [D loss: 0.667655, acc.: 57.81%] [G loss: 0.858856]\n",
      "epoch:10 step:9484 [D loss: 0.665769, acc.: 60.16%] [G loss: 0.849445]\n",
      "epoch:10 step:9485 [D loss: 0.687953, acc.: 53.91%] [G loss: 0.846238]\n",
      "epoch:10 step:9486 [D loss: 0.658807, acc.: 59.38%] [G loss: 0.828605]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9487 [D loss: 0.695803, acc.: 50.78%] [G loss: 0.827849]\n",
      "epoch:10 step:9488 [D loss: 0.672580, acc.: 51.56%] [G loss: 0.833086]\n",
      "epoch:10 step:9489 [D loss: 0.649954, acc.: 60.94%] [G loss: 0.875783]\n",
      "epoch:10 step:9490 [D loss: 0.686812, acc.: 55.47%] [G loss: 0.893865]\n",
      "epoch:10 step:9491 [D loss: 0.663345, acc.: 57.03%] [G loss: 0.854730]\n",
      "epoch:10 step:9492 [D loss: 0.681662, acc.: 55.47%] [G loss: 0.853905]\n",
      "epoch:10 step:9493 [D loss: 0.683797, acc.: 54.69%] [G loss: 0.840543]\n",
      "epoch:10 step:9494 [D loss: 0.671935, acc.: 59.38%] [G loss: 0.825814]\n",
      "epoch:10 step:9495 [D loss: 0.690181, acc.: 53.12%] [G loss: 0.834951]\n",
      "epoch:10 step:9496 [D loss: 0.668911, acc.: 57.03%] [G loss: 0.822771]\n",
      "epoch:10 step:9497 [D loss: 0.678623, acc.: 58.59%] [G loss: 0.856818]\n",
      "epoch:10 step:9498 [D loss: 0.652823, acc.: 59.38%] [G loss: 0.859003]\n",
      "epoch:10 step:9499 [D loss: 0.658565, acc.: 59.38%] [G loss: 0.810576]\n",
      "epoch:10 step:9500 [D loss: 0.673264, acc.: 57.03%] [G loss: 0.831697]\n",
      "epoch:10 step:9501 [D loss: 0.673391, acc.: 54.69%] [G loss: 0.856643]\n",
      "epoch:10 step:9502 [D loss: 0.691757, acc.: 59.38%] [G loss: 0.849751]\n",
      "epoch:10 step:9503 [D loss: 0.674816, acc.: 51.56%] [G loss: 0.872210]\n",
      "epoch:10 step:9504 [D loss: 0.659039, acc.: 63.28%] [G loss: 0.805986]\n",
      "epoch:10 step:9505 [D loss: 0.686993, acc.: 53.91%] [G loss: 0.828951]\n",
      "epoch:10 step:9506 [D loss: 0.692061, acc.: 49.22%] [G loss: 0.857482]\n",
      "epoch:10 step:9507 [D loss: 0.649048, acc.: 56.25%] [G loss: 0.841630]\n",
      "epoch:10 step:9508 [D loss: 0.679742, acc.: 56.25%] [G loss: 0.828118]\n",
      "epoch:10 step:9509 [D loss: 0.679307, acc.: 59.38%] [G loss: 0.815569]\n",
      "epoch:10 step:9510 [D loss: 0.652276, acc.: 55.47%] [G loss: 0.804114]\n",
      "epoch:10 step:9511 [D loss: 0.708097, acc.: 50.00%] [G loss: 0.797711]\n",
      "epoch:10 step:9512 [D loss: 0.636912, acc.: 60.16%] [G loss: 0.866500]\n",
      "epoch:10 step:9513 [D loss: 0.664263, acc.: 61.72%] [G loss: 0.863779]\n",
      "epoch:10 step:9514 [D loss: 0.679305, acc.: 57.81%] [G loss: 0.837562]\n",
      "epoch:10 step:9515 [D loss: 0.678072, acc.: 46.88%] [G loss: 0.840988]\n",
      "epoch:10 step:9516 [D loss: 0.670707, acc.: 59.38%] [G loss: 0.825940]\n",
      "epoch:10 step:9517 [D loss: 0.637416, acc.: 64.06%] [G loss: 0.837295]\n",
      "epoch:10 step:9518 [D loss: 0.681335, acc.: 59.38%] [G loss: 0.873931]\n",
      "epoch:10 step:9519 [D loss: 0.677764, acc.: 56.25%] [G loss: 0.837744]\n",
      "epoch:10 step:9520 [D loss: 0.689616, acc.: 52.34%] [G loss: 0.808073]\n",
      "epoch:10 step:9521 [D loss: 0.662717, acc.: 56.25%] [G loss: 0.872301]\n",
      "epoch:10 step:9522 [D loss: 0.665580, acc.: 60.94%] [G loss: 0.833347]\n",
      "epoch:10 step:9523 [D loss: 0.654687, acc.: 64.06%] [G loss: 0.837442]\n",
      "epoch:10 step:9524 [D loss: 0.679314, acc.: 50.00%] [G loss: 0.836512]\n",
      "epoch:10 step:9525 [D loss: 0.683607, acc.: 51.56%] [G loss: 0.815895]\n",
      "epoch:10 step:9526 [D loss: 0.677917, acc.: 54.69%] [G loss: 0.860864]\n",
      "epoch:10 step:9527 [D loss: 0.653352, acc.: 61.72%] [G loss: 0.796257]\n",
      "epoch:10 step:9528 [D loss: 0.671447, acc.: 60.94%] [G loss: 0.842824]\n",
      "epoch:10 step:9529 [D loss: 0.675844, acc.: 61.72%] [G loss: 0.869358]\n",
      "epoch:10 step:9530 [D loss: 0.673044, acc.: 56.25%] [G loss: 0.847209]\n",
      "epoch:10 step:9531 [D loss: 0.660682, acc.: 57.81%] [G loss: 0.884703]\n",
      "epoch:10 step:9532 [D loss: 0.660363, acc.: 61.72%] [G loss: 0.871266]\n",
      "epoch:10 step:9533 [D loss: 0.647092, acc.: 63.28%] [G loss: 0.825964]\n",
      "epoch:10 step:9534 [D loss: 0.698208, acc.: 53.91%] [G loss: 0.817922]\n",
      "epoch:10 step:9535 [D loss: 0.665068, acc.: 62.50%] [G loss: 0.874740]\n",
      "epoch:10 step:9536 [D loss: 0.686417, acc.: 53.12%] [G loss: 0.797399]\n",
      "epoch:10 step:9537 [D loss: 0.657808, acc.: 56.25%] [G loss: 0.816460]\n",
      "epoch:10 step:9538 [D loss: 0.692486, acc.: 56.25%] [G loss: 0.825551]\n",
      "epoch:10 step:9539 [D loss: 0.682876, acc.: 53.91%] [G loss: 0.872077]\n",
      "epoch:10 step:9540 [D loss: 0.643527, acc.: 63.28%] [G loss: 0.833131]\n",
      "epoch:10 step:9541 [D loss: 0.695629, acc.: 53.91%] [G loss: 0.825965]\n",
      "epoch:10 step:9542 [D loss: 0.651384, acc.: 59.38%] [G loss: 0.851766]\n",
      "epoch:10 step:9543 [D loss: 0.656963, acc.: 65.62%] [G loss: 0.795688]\n",
      "epoch:10 step:9544 [D loss: 0.644479, acc.: 66.41%] [G loss: 0.821566]\n",
      "epoch:10 step:9545 [D loss: 0.669609, acc.: 53.91%] [G loss: 0.851044]\n",
      "epoch:10 step:9546 [D loss: 0.627327, acc.: 66.41%] [G loss: 0.849056]\n",
      "epoch:10 step:9547 [D loss: 0.672456, acc.: 61.72%] [G loss: 0.854706]\n",
      "epoch:10 step:9548 [D loss: 0.643924, acc.: 60.94%] [G loss: 0.834400]\n",
      "epoch:10 step:9549 [D loss: 0.696038, acc.: 50.00%] [G loss: 0.839786]\n",
      "epoch:10 step:9550 [D loss: 0.665130, acc.: 57.03%] [G loss: 0.855299]\n",
      "epoch:10 step:9551 [D loss: 0.690934, acc.: 53.91%] [G loss: 0.868822]\n",
      "epoch:10 step:9552 [D loss: 0.645863, acc.: 61.72%] [G loss: 0.874974]\n",
      "epoch:10 step:9553 [D loss: 0.681144, acc.: 57.81%] [G loss: 0.847540]\n",
      "epoch:10 step:9554 [D loss: 0.664695, acc.: 60.16%] [G loss: 0.834938]\n",
      "epoch:10 step:9555 [D loss: 0.658553, acc.: 60.94%] [G loss: 0.867711]\n",
      "epoch:10 step:9556 [D loss: 0.647521, acc.: 68.75%] [G loss: 0.881802]\n",
      "epoch:10 step:9557 [D loss: 0.674369, acc.: 53.91%] [G loss: 0.829927]\n",
      "epoch:10 step:9558 [D loss: 0.687044, acc.: 60.16%] [G loss: 0.844941]\n",
      "epoch:10 step:9559 [D loss: 0.659234, acc.: 58.59%] [G loss: 0.838411]\n",
      "epoch:10 step:9560 [D loss: 0.706214, acc.: 52.34%] [G loss: 0.863354]\n",
      "epoch:10 step:9561 [D loss: 0.630478, acc.: 63.28%] [G loss: 0.820184]\n",
      "epoch:10 step:9562 [D loss: 0.658633, acc.: 57.81%] [G loss: 0.864567]\n",
      "epoch:10 step:9563 [D loss: 0.647839, acc.: 64.84%] [G loss: 0.878771]\n",
      "epoch:10 step:9564 [D loss: 0.684190, acc.: 54.69%] [G loss: 0.819344]\n",
      "epoch:10 step:9565 [D loss: 0.671703, acc.: 57.81%] [G loss: 0.826307]\n",
      "epoch:10 step:9566 [D loss: 0.637574, acc.: 64.06%] [G loss: 0.862576]\n",
      "epoch:10 step:9567 [D loss: 0.614488, acc.: 67.19%] [G loss: 0.881662]\n",
      "epoch:10 step:9568 [D loss: 0.605268, acc.: 70.31%] [G loss: 0.876845]\n",
      "epoch:10 step:9569 [D loss: 0.656233, acc.: 58.59%] [G loss: 0.850648]\n",
      "epoch:10 step:9570 [D loss: 0.660118, acc.: 57.81%] [G loss: 0.830047]\n",
      "epoch:10 step:9571 [D loss: 0.645258, acc.: 60.94%] [G loss: 0.844450]\n",
      "epoch:10 step:9572 [D loss: 0.632054, acc.: 67.19%] [G loss: 0.913957]\n",
      "epoch:10 step:9573 [D loss: 0.651155, acc.: 63.28%] [G loss: 0.893909]\n",
      "epoch:10 step:9574 [D loss: 0.676229, acc.: 56.25%] [G loss: 0.839804]\n",
      "epoch:10 step:9575 [D loss: 0.667273, acc.: 60.16%] [G loss: 0.874456]\n",
      "epoch:10 step:9576 [D loss: 0.655330, acc.: 63.28%] [G loss: 0.846258]\n",
      "epoch:10 step:9577 [D loss: 0.631184, acc.: 66.41%] [G loss: 0.877852]\n",
      "epoch:10 step:9578 [D loss: 0.644419, acc.: 60.16%] [G loss: 0.868690]\n",
      "epoch:10 step:9579 [D loss: 0.658730, acc.: 63.28%] [G loss: 0.855704]\n",
      "epoch:10 step:9580 [D loss: 0.628355, acc.: 65.62%] [G loss: 0.861078]\n",
      "epoch:10 step:9581 [D loss: 0.684562, acc.: 56.25%] [G loss: 0.889764]\n",
      "epoch:10 step:9582 [D loss: 0.678923, acc.: 53.12%] [G loss: 0.866617]\n",
      "epoch:10 step:9583 [D loss: 0.688444, acc.: 57.81%] [G loss: 0.876496]\n",
      "epoch:10 step:9584 [D loss: 0.676829, acc.: 58.59%] [G loss: 0.873770]\n",
      "epoch:10 step:9585 [D loss: 0.679761, acc.: 58.59%] [G loss: 0.873621]\n",
      "epoch:10 step:9586 [D loss: 0.684387, acc.: 56.25%] [G loss: 0.884916]\n",
      "epoch:10 step:9587 [D loss: 0.630034, acc.: 65.62%] [G loss: 0.890023]\n",
      "epoch:10 step:9588 [D loss: 0.673230, acc.: 55.47%] [G loss: 0.882174]\n",
      "epoch:10 step:9589 [D loss: 0.691546, acc.: 57.81%] [G loss: 0.860477]\n",
      "epoch:10 step:9590 [D loss: 0.652767, acc.: 63.28%] [G loss: 0.819907]\n",
      "epoch:10 step:9591 [D loss: 0.683049, acc.: 57.81%] [G loss: 0.828822]\n",
      "epoch:10 step:9592 [D loss: 0.722156, acc.: 46.09%] [G loss: 0.832328]\n",
      "epoch:10 step:9593 [D loss: 0.679901, acc.: 57.03%] [G loss: 0.878030]\n",
      "epoch:10 step:9594 [D loss: 0.665816, acc.: 64.84%] [G loss: 0.832905]\n",
      "epoch:10 step:9595 [D loss: 0.646010, acc.: 62.50%] [G loss: 0.794287]\n",
      "epoch:10 step:9596 [D loss: 0.648424, acc.: 59.38%] [G loss: 0.784434]\n",
      "epoch:10 step:9597 [D loss: 0.667091, acc.: 61.72%] [G loss: 0.881379]\n",
      "epoch:10 step:9598 [D loss: 0.632685, acc.: 64.84%] [G loss: 0.923936]\n",
      "epoch:10 step:9599 [D loss: 0.683784, acc.: 56.25%] [G loss: 0.809085]\n",
      "epoch:10 step:9600 [D loss: 0.691073, acc.: 55.47%] [G loss: 0.877507]\n",
      "##############\n",
      "[2.97017958 2.72043061 2.40522081 3.96090323 1.43855813 9.27426719\n",
      " 3.05809349 3.7469133  4.34305593 7.14868929]\n",
      "##########\n",
      "epoch:10 step:9601 [D loss: 0.703093, acc.: 50.00%] [G loss: 0.880180]\n",
      "epoch:10 step:9602 [D loss: 0.674094, acc.: 53.12%] [G loss: 0.888336]\n",
      "epoch:10 step:9603 [D loss: 0.654968, acc.: 61.72%] [G loss: 0.867887]\n",
      "epoch:10 step:9604 [D loss: 0.688544, acc.: 52.34%] [G loss: 0.850989]\n",
      "epoch:10 step:9605 [D loss: 0.660575, acc.: 56.25%] [G loss: 0.851138]\n",
      "epoch:10 step:9606 [D loss: 0.658186, acc.: 61.72%] [G loss: 0.828313]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9607 [D loss: 0.726442, acc.: 46.09%] [G loss: 0.848908]\n",
      "epoch:10 step:9608 [D loss: 0.668762, acc.: 60.16%] [G loss: 0.807336]\n",
      "epoch:10 step:9609 [D loss: 0.677169, acc.: 56.25%] [G loss: 0.845640]\n",
      "epoch:10 step:9610 [D loss: 0.653596, acc.: 67.19%] [G loss: 0.845816]\n",
      "epoch:10 step:9611 [D loss: 0.687189, acc.: 57.03%] [G loss: 0.834762]\n",
      "epoch:10 step:9612 [D loss: 0.685207, acc.: 59.38%] [G loss: 0.820746]\n",
      "epoch:10 step:9613 [D loss: 0.668501, acc.: 59.38%] [G loss: 0.822182]\n",
      "epoch:10 step:9614 [D loss: 0.671968, acc.: 60.16%] [G loss: 0.871847]\n",
      "epoch:10 step:9615 [D loss: 0.665626, acc.: 57.81%] [G loss: 0.904117]\n",
      "epoch:10 step:9616 [D loss: 0.667320, acc.: 60.16%] [G loss: 0.901773]\n",
      "epoch:10 step:9617 [D loss: 0.649546, acc.: 67.97%] [G loss: 0.876343]\n",
      "epoch:10 step:9618 [D loss: 0.622286, acc.: 64.06%] [G loss: 0.835977]\n",
      "epoch:10 step:9619 [D loss: 0.659712, acc.: 58.59%] [G loss: 0.838353]\n",
      "epoch:10 step:9620 [D loss: 0.631451, acc.: 67.19%] [G loss: 0.814679]\n",
      "epoch:10 step:9621 [D loss: 0.666308, acc.: 59.38%] [G loss: 0.885253]\n",
      "epoch:10 step:9622 [D loss: 0.645450, acc.: 62.50%] [G loss: 0.881441]\n",
      "epoch:10 step:9623 [D loss: 0.657109, acc.: 62.50%] [G loss: 0.813918]\n",
      "epoch:10 step:9624 [D loss: 0.690908, acc.: 54.69%] [G loss: 0.863705]\n",
      "epoch:10 step:9625 [D loss: 0.688522, acc.: 50.78%] [G loss: 0.867417]\n",
      "epoch:10 step:9626 [D loss: 0.661094, acc.: 60.94%] [G loss: 0.874928]\n",
      "epoch:10 step:9627 [D loss: 0.642849, acc.: 61.72%] [G loss: 0.856728]\n",
      "epoch:10 step:9628 [D loss: 0.654040, acc.: 55.47%] [G loss: 0.841553]\n",
      "epoch:10 step:9629 [D loss: 0.645986, acc.: 63.28%] [G loss: 0.840466]\n",
      "epoch:10 step:9630 [D loss: 0.705390, acc.: 56.25%] [G loss: 0.852616]\n",
      "epoch:10 step:9631 [D loss: 0.687431, acc.: 56.25%] [G loss: 0.871960]\n",
      "epoch:10 step:9632 [D loss: 0.675042, acc.: 56.25%] [G loss: 0.887848]\n",
      "epoch:10 step:9633 [D loss: 0.662241, acc.: 60.16%] [G loss: 0.870676]\n",
      "epoch:10 step:9634 [D loss: 0.656003, acc.: 59.38%] [G loss: 0.859053]\n",
      "epoch:10 step:9635 [D loss: 0.638030, acc.: 62.50%] [G loss: 0.858887]\n",
      "epoch:10 step:9636 [D loss: 0.615042, acc.: 68.75%] [G loss: 0.907376]\n",
      "epoch:10 step:9637 [D loss: 0.675022, acc.: 58.59%] [G loss: 0.903918]\n",
      "epoch:10 step:9638 [D loss: 0.645800, acc.: 63.28%] [G loss: 0.895179]\n",
      "epoch:10 step:9639 [D loss: 0.660175, acc.: 62.50%] [G loss: 0.853501]\n",
      "epoch:10 step:9640 [D loss: 0.658839, acc.: 64.84%] [G loss: 0.847428]\n",
      "epoch:10 step:9641 [D loss: 0.650430, acc.: 59.38%] [G loss: 0.833637]\n",
      "epoch:10 step:9642 [D loss: 0.677315, acc.: 54.69%] [G loss: 0.819459]\n",
      "epoch:10 step:9643 [D loss: 0.698032, acc.: 50.00%] [G loss: 0.852035]\n",
      "epoch:10 step:9644 [D loss: 0.716309, acc.: 46.88%] [G loss: 0.821465]\n",
      "epoch:10 step:9645 [D loss: 0.696066, acc.: 52.34%] [G loss: 0.869049]\n",
      "epoch:10 step:9646 [D loss: 0.688171, acc.: 49.22%] [G loss: 0.877691]\n",
      "epoch:10 step:9647 [D loss: 0.654359, acc.: 59.38%] [G loss: 0.849133]\n",
      "epoch:10 step:9648 [D loss: 0.699523, acc.: 58.59%] [G loss: 0.859599]\n",
      "epoch:10 step:9649 [D loss: 0.688107, acc.: 52.34%] [G loss: 0.840353]\n",
      "epoch:10 step:9650 [D loss: 0.666362, acc.: 61.72%] [G loss: 0.855789]\n",
      "epoch:10 step:9651 [D loss: 0.671273, acc.: 59.38%] [G loss: 0.849277]\n",
      "epoch:10 step:9652 [D loss: 0.672923, acc.: 59.38%] [G loss: 0.847813]\n",
      "epoch:10 step:9653 [D loss: 0.634029, acc.: 63.28%] [G loss: 0.855583]\n",
      "epoch:10 step:9654 [D loss: 0.640458, acc.: 58.59%] [G loss: 0.868419]\n",
      "epoch:10 step:9655 [D loss: 0.624838, acc.: 67.97%] [G loss: 0.893083]\n",
      "epoch:10 step:9656 [D loss: 0.687232, acc.: 56.25%] [G loss: 0.858741]\n",
      "epoch:10 step:9657 [D loss: 0.661314, acc.: 57.03%] [G loss: 0.835847]\n",
      "epoch:10 step:9658 [D loss: 0.648031, acc.: 61.72%] [G loss: 0.788688]\n",
      "epoch:10 step:9659 [D loss: 0.691417, acc.: 55.47%] [G loss: 0.842767]\n",
      "epoch:10 step:9660 [D loss: 0.656202, acc.: 60.94%] [G loss: 0.835769]\n",
      "epoch:10 step:9661 [D loss: 0.678465, acc.: 51.56%] [G loss: 0.835195]\n",
      "epoch:10 step:9662 [D loss: 0.695628, acc.: 60.94%] [G loss: 0.820644]\n",
      "epoch:10 step:9663 [D loss: 0.656991, acc.: 57.03%] [G loss: 0.830687]\n",
      "epoch:10 step:9664 [D loss: 0.664036, acc.: 58.59%] [G loss: 0.862564]\n",
      "epoch:10 step:9665 [D loss: 0.676030, acc.: 60.16%] [G loss: 0.816439]\n",
      "epoch:10 step:9666 [D loss: 0.657013, acc.: 57.81%] [G loss: 0.927057]\n",
      "epoch:10 step:9667 [D loss: 0.642983, acc.: 64.06%] [G loss: 0.839884]\n",
      "epoch:10 step:9668 [D loss: 0.681998, acc.: 57.81%] [G loss: 0.827889]\n",
      "epoch:10 step:9669 [D loss: 0.663776, acc.: 62.50%] [G loss: 0.801555]\n",
      "epoch:10 step:9670 [D loss: 0.659891, acc.: 57.81%] [G loss: 0.872169]\n",
      "epoch:10 step:9671 [D loss: 0.673654, acc.: 53.12%] [G loss: 0.849296]\n",
      "epoch:10 step:9672 [D loss: 0.661687, acc.: 67.19%] [G loss: 0.849798]\n",
      "epoch:10 step:9673 [D loss: 0.688695, acc.: 54.69%] [G loss: 0.860383]\n",
      "epoch:10 step:9674 [D loss: 0.634760, acc.: 67.97%] [G loss: 0.840407]\n",
      "epoch:10 step:9675 [D loss: 0.697425, acc.: 51.56%] [G loss: 0.826149]\n",
      "epoch:10 step:9676 [D loss: 0.657781, acc.: 58.59%] [G loss: 0.827424]\n",
      "epoch:10 step:9677 [D loss: 0.650025, acc.: 60.16%] [G loss: 0.807018]\n",
      "epoch:10 step:9678 [D loss: 0.671097, acc.: 56.25%] [G loss: 0.853943]\n",
      "epoch:10 step:9679 [D loss: 0.661520, acc.: 59.38%] [G loss: 0.823080]\n",
      "epoch:10 step:9680 [D loss: 0.672289, acc.: 54.69%] [G loss: 0.890492]\n",
      "epoch:10 step:9681 [D loss: 0.658653, acc.: 57.81%] [G loss: 0.901707]\n",
      "epoch:10 step:9682 [D loss: 0.691503, acc.: 58.59%] [G loss: 0.890612]\n",
      "epoch:10 step:9683 [D loss: 0.661257, acc.: 60.94%] [G loss: 0.862949]\n",
      "epoch:10 step:9684 [D loss: 0.653135, acc.: 53.12%] [G loss: 0.871771]\n",
      "epoch:10 step:9685 [D loss: 0.636635, acc.: 68.75%] [G loss: 0.868582]\n",
      "epoch:10 step:9686 [D loss: 0.682375, acc.: 54.69%] [G loss: 0.873526]\n",
      "epoch:10 step:9687 [D loss: 0.657113, acc.: 65.62%] [G loss: 0.848171]\n",
      "epoch:10 step:9688 [D loss: 0.704887, acc.: 50.78%] [G loss: 0.852417]\n",
      "epoch:10 step:9689 [D loss: 0.700220, acc.: 51.56%] [G loss: 0.855541]\n",
      "epoch:10 step:9690 [D loss: 0.634234, acc.: 67.19%] [G loss: 0.862191]\n",
      "epoch:10 step:9691 [D loss: 0.672007, acc.: 57.03%] [G loss: 0.836013]\n",
      "epoch:10 step:9692 [D loss: 0.700303, acc.: 51.56%] [G loss: 0.826522]\n",
      "epoch:10 step:9693 [D loss: 0.654529, acc.: 61.72%] [G loss: 0.845748]\n",
      "epoch:10 step:9694 [D loss: 0.655896, acc.: 60.16%] [G loss: 0.827288]\n",
      "epoch:10 step:9695 [D loss: 0.662570, acc.: 58.59%] [G loss: 0.804809]\n",
      "epoch:10 step:9696 [D loss: 0.691670, acc.: 54.69%] [G loss: 0.849699]\n",
      "epoch:10 step:9697 [D loss: 0.628682, acc.: 64.06%] [G loss: 0.858487]\n",
      "epoch:10 step:9698 [D loss: 0.635942, acc.: 62.50%] [G loss: 0.768851]\n",
      "epoch:10 step:9699 [D loss: 0.667584, acc.: 58.59%] [G loss: 0.858872]\n",
      "epoch:10 step:9700 [D loss: 0.646734, acc.: 61.72%] [G loss: 0.886182]\n",
      "epoch:10 step:9701 [D loss: 0.715453, acc.: 47.66%] [G loss: 0.861619]\n",
      "epoch:10 step:9702 [D loss: 0.674362, acc.: 54.69%] [G loss: 0.853756]\n",
      "epoch:10 step:9703 [D loss: 0.707423, acc.: 51.56%] [G loss: 0.799323]\n",
      "epoch:10 step:9704 [D loss: 0.675836, acc.: 60.94%] [G loss: 0.820962]\n",
      "epoch:10 step:9705 [D loss: 0.654560, acc.: 57.03%] [G loss: 0.895468]\n",
      "epoch:10 step:9706 [D loss: 0.619414, acc.: 68.75%] [G loss: 0.891329]\n",
      "epoch:10 step:9707 [D loss: 0.624203, acc.: 71.88%] [G loss: 0.920422]\n",
      "epoch:10 step:9708 [D loss: 0.667712, acc.: 59.38%] [G loss: 0.877615]\n",
      "epoch:10 step:9709 [D loss: 0.646569, acc.: 60.94%] [G loss: 0.865197]\n",
      "epoch:10 step:9710 [D loss: 0.646252, acc.: 60.94%] [G loss: 0.893321]\n",
      "epoch:10 step:9711 [D loss: 0.656645, acc.: 58.59%] [G loss: 0.885075]\n",
      "epoch:10 step:9712 [D loss: 0.663812, acc.: 55.47%] [G loss: 0.880447]\n",
      "epoch:10 step:9713 [D loss: 0.677763, acc.: 57.03%] [G loss: 0.868703]\n",
      "epoch:10 step:9714 [D loss: 0.651347, acc.: 63.28%] [G loss: 0.865252]\n",
      "epoch:10 step:9715 [D loss: 0.663198, acc.: 57.03%] [G loss: 0.806167]\n",
      "epoch:10 step:9716 [D loss: 0.669860, acc.: 55.47%] [G loss: 0.833344]\n",
      "epoch:10 step:9717 [D loss: 0.671687, acc.: 59.38%] [G loss: 0.814326]\n",
      "epoch:10 step:9718 [D loss: 0.662089, acc.: 60.94%] [G loss: 0.812056]\n",
      "epoch:10 step:9719 [D loss: 0.653111, acc.: 55.47%] [G loss: 0.849854]\n",
      "epoch:10 step:9720 [D loss: 0.684355, acc.: 57.81%] [G loss: 0.839525]\n",
      "epoch:10 step:9721 [D loss: 0.648532, acc.: 66.41%] [G loss: 0.888141]\n",
      "epoch:10 step:9722 [D loss: 0.669766, acc.: 57.81%] [G loss: 0.823049]\n",
      "epoch:10 step:9723 [D loss: 0.652740, acc.: 64.06%] [G loss: 0.834328]\n",
      "epoch:10 step:9724 [D loss: 0.663579, acc.: 56.25%] [G loss: 0.813800]\n",
      "epoch:10 step:9725 [D loss: 0.655924, acc.: 62.50%] [G loss: 0.836022]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9726 [D loss: 0.692477, acc.: 53.91%] [G loss: 0.814881]\n",
      "epoch:10 step:9727 [D loss: 0.682564, acc.: 53.91%] [G loss: 0.826559]\n",
      "epoch:10 step:9728 [D loss: 0.654526, acc.: 62.50%] [G loss: 0.865754]\n",
      "epoch:10 step:9729 [D loss: 0.696447, acc.: 50.78%] [G loss: 0.804841]\n",
      "epoch:10 step:9730 [D loss: 0.655288, acc.: 57.81%] [G loss: 0.870746]\n",
      "epoch:10 step:9731 [D loss: 0.695375, acc.: 54.69%] [G loss: 0.855054]\n",
      "epoch:10 step:9732 [D loss: 0.645644, acc.: 65.62%] [G loss: 0.828311]\n",
      "epoch:10 step:9733 [D loss: 0.667328, acc.: 56.25%] [G loss: 0.834275]\n",
      "epoch:10 step:9734 [D loss: 0.692746, acc.: 53.12%] [G loss: 0.858556]\n",
      "epoch:10 step:9735 [D loss: 0.713356, acc.: 54.69%] [G loss: 0.835439]\n",
      "epoch:10 step:9736 [D loss: 0.656085, acc.: 58.59%] [G loss: 0.892067]\n",
      "epoch:10 step:9737 [D loss: 0.668503, acc.: 60.16%] [G loss: 0.897959]\n",
      "epoch:10 step:9738 [D loss: 0.655833, acc.: 60.16%] [G loss: 0.905379]\n",
      "epoch:10 step:9739 [D loss: 0.688568, acc.: 56.25%] [G loss: 0.816138]\n",
      "epoch:10 step:9740 [D loss: 0.641219, acc.: 64.84%] [G loss: 0.857020]\n",
      "epoch:10 step:9741 [D loss: 0.665847, acc.: 53.12%] [G loss: 0.845154]\n",
      "epoch:10 step:9742 [D loss: 0.648930, acc.: 62.50%] [G loss: 0.835468]\n",
      "epoch:10 step:9743 [D loss: 0.658580, acc.: 60.94%] [G loss: 0.849461]\n",
      "epoch:10 step:9744 [D loss: 0.673748, acc.: 49.22%] [G loss: 0.823591]\n",
      "epoch:10 step:9745 [D loss: 0.725525, acc.: 49.22%] [G loss: 0.867627]\n",
      "epoch:10 step:9746 [D loss: 0.686174, acc.: 53.12%] [G loss: 0.854651]\n",
      "epoch:10 step:9747 [D loss: 0.689866, acc.: 54.69%] [G loss: 0.831667]\n",
      "epoch:10 step:9748 [D loss: 0.669642, acc.: 53.91%] [G loss: 0.831392]\n",
      "epoch:10 step:9749 [D loss: 0.646404, acc.: 61.72%] [G loss: 0.868259]\n",
      "epoch:10 step:9750 [D loss: 0.659930, acc.: 59.38%] [G loss: 0.862368]\n",
      "epoch:10 step:9751 [D loss: 0.666388, acc.: 63.28%] [G loss: 0.909320]\n",
      "epoch:10 step:9752 [D loss: 0.699117, acc.: 49.22%] [G loss: 0.841224]\n",
      "epoch:10 step:9753 [D loss: 0.679547, acc.: 56.25%] [G loss: 0.840898]\n",
      "epoch:10 step:9754 [D loss: 0.700088, acc.: 51.56%] [G loss: 0.811223]\n",
      "epoch:10 step:9755 [D loss: 0.710094, acc.: 51.56%] [G loss: 0.847756]\n",
      "epoch:10 step:9756 [D loss: 0.693014, acc.: 53.91%] [G loss: 0.889032]\n",
      "epoch:10 step:9757 [D loss: 0.640418, acc.: 61.72%] [G loss: 0.850373]\n",
      "epoch:10 step:9758 [D loss: 0.689962, acc.: 51.56%] [G loss: 0.875169]\n",
      "epoch:10 step:9759 [D loss: 0.670060, acc.: 58.59%] [G loss: 0.836813]\n",
      "epoch:10 step:9760 [D loss: 0.679869, acc.: 59.38%] [G loss: 0.810483]\n",
      "epoch:10 step:9761 [D loss: 0.663686, acc.: 57.03%] [G loss: 0.896142]\n",
      "epoch:10 step:9762 [D loss: 0.693243, acc.: 53.91%] [G loss: 0.888035]\n",
      "epoch:10 step:9763 [D loss: 0.722069, acc.: 50.78%] [G loss: 0.848202]\n",
      "epoch:10 step:9764 [D loss: 0.684240, acc.: 55.47%] [G loss: 0.875811]\n",
      "epoch:10 step:9765 [D loss: 0.685288, acc.: 60.16%] [G loss: 0.877384]\n",
      "epoch:10 step:9766 [D loss: 0.682380, acc.: 61.72%] [G loss: 0.827824]\n",
      "epoch:10 step:9767 [D loss: 0.681386, acc.: 58.59%] [G loss: 0.873807]\n",
      "epoch:10 step:9768 [D loss: 0.670278, acc.: 60.16%] [G loss: 0.853840]\n",
      "epoch:10 step:9769 [D loss: 0.654818, acc.: 60.94%] [G loss: 0.936636]\n",
      "epoch:10 step:9770 [D loss: 0.620203, acc.: 68.75%] [G loss: 0.879279]\n",
      "epoch:10 step:9771 [D loss: 0.664101, acc.: 59.38%] [G loss: 0.847257]\n",
      "epoch:10 step:9772 [D loss: 0.612573, acc.: 71.88%] [G loss: 0.844867]\n",
      "epoch:10 step:9773 [D loss: 0.684734, acc.: 57.03%] [G loss: 0.867068]\n",
      "epoch:10 step:9774 [D loss: 0.651969, acc.: 64.06%] [G loss: 0.849721]\n",
      "epoch:10 step:9775 [D loss: 0.654125, acc.: 60.16%] [G loss: 0.862527]\n",
      "epoch:10 step:9776 [D loss: 0.653971, acc.: 59.38%] [G loss: 0.872241]\n",
      "epoch:10 step:9777 [D loss: 0.685598, acc.: 54.69%] [G loss: 0.881205]\n",
      "epoch:10 step:9778 [D loss: 0.678662, acc.: 57.03%] [G loss: 0.858961]\n",
      "epoch:10 step:9779 [D loss: 0.677419, acc.: 60.94%] [G loss: 0.838323]\n",
      "epoch:10 step:9780 [D loss: 0.700113, acc.: 57.81%] [G loss: 0.845724]\n",
      "epoch:10 step:9781 [D loss: 0.681957, acc.: 54.69%] [G loss: 0.861843]\n",
      "epoch:10 step:9782 [D loss: 0.634446, acc.: 64.06%] [G loss: 0.896524]\n",
      "epoch:10 step:9783 [D loss: 0.705984, acc.: 53.12%] [G loss: 0.870549]\n",
      "epoch:10 step:9784 [D loss: 0.658918, acc.: 56.25%] [G loss: 0.847162]\n",
      "epoch:10 step:9785 [D loss: 0.640847, acc.: 62.50%] [G loss: 0.866733]\n",
      "epoch:10 step:9786 [D loss: 0.695311, acc.: 57.81%] [G loss: 0.839969]\n",
      "epoch:10 step:9787 [D loss: 0.629213, acc.: 62.50%] [G loss: 0.858439]\n",
      "epoch:10 step:9788 [D loss: 0.693315, acc.: 60.94%] [G loss: 0.867982]\n",
      "epoch:10 step:9789 [D loss: 0.668614, acc.: 56.25%] [G loss: 0.864577]\n",
      "epoch:10 step:9790 [D loss: 0.678985, acc.: 53.12%] [G loss: 0.820623]\n",
      "epoch:10 step:9791 [D loss: 0.654940, acc.: 64.06%] [G loss: 0.760739]\n",
      "epoch:10 step:9792 [D loss: 0.696610, acc.: 48.44%] [G loss: 0.846078]\n",
      "epoch:10 step:9793 [D loss: 0.674599, acc.: 52.34%] [G loss: 0.845357]\n",
      "epoch:10 step:9794 [D loss: 0.675425, acc.: 63.28%] [G loss: 0.834920]\n",
      "epoch:10 step:9795 [D loss: 0.651141, acc.: 62.50%] [G loss: 0.857797]\n",
      "epoch:10 step:9796 [D loss: 0.667390, acc.: 60.94%] [G loss: 0.808207]\n",
      "epoch:10 step:9797 [D loss: 0.679683, acc.: 57.81%] [G loss: 0.841005]\n",
      "epoch:10 step:9798 [D loss: 0.708585, acc.: 53.12%] [G loss: 0.816756]\n",
      "epoch:10 step:9799 [D loss: 0.686241, acc.: 57.03%] [G loss: 0.839485]\n",
      "epoch:10 step:9800 [D loss: 0.678329, acc.: 57.81%] [G loss: 0.850836]\n",
      "##############\n",
      "[ 2.9385323   2.1344633   2.5913071   4.20628689  1.42778389 10.27426719\n",
      "  2.81363333  3.95568306  4.14941922  7.14868929]\n",
      "##########\n",
      "epoch:10 step:9801 [D loss: 0.644471, acc.: 58.59%] [G loss: 0.904838]\n",
      "epoch:10 step:9802 [D loss: 0.667905, acc.: 59.38%] [G loss: 0.866369]\n",
      "epoch:10 step:9803 [D loss: 0.702736, acc.: 54.69%] [G loss: 0.826105]\n",
      "epoch:10 step:9804 [D loss: 0.674599, acc.: 57.03%] [G loss: 0.842691]\n",
      "epoch:10 step:9805 [D loss: 0.691040, acc.: 53.12%] [G loss: 0.861208]\n",
      "epoch:10 step:9806 [D loss: 0.649988, acc.: 58.59%] [G loss: 0.885085]\n",
      "epoch:10 step:9807 [D loss: 0.692000, acc.: 55.47%] [G loss: 0.903334]\n",
      "epoch:10 step:9808 [D loss: 0.675598, acc.: 55.47%] [G loss: 0.901258]\n",
      "epoch:10 step:9809 [D loss: 0.648150, acc.: 59.38%] [G loss: 0.897139]\n",
      "epoch:10 step:9810 [D loss: 0.680833, acc.: 59.38%] [G loss: 0.851034]\n",
      "epoch:10 step:9811 [D loss: 0.673520, acc.: 62.50%] [G loss: 0.843553]\n",
      "epoch:10 step:9812 [D loss: 0.675811, acc.: 58.59%] [G loss: 0.848643]\n",
      "epoch:10 step:9813 [D loss: 0.679310, acc.: 53.12%] [G loss: 0.808675]\n",
      "epoch:10 step:9814 [D loss: 0.691109, acc.: 53.91%] [G loss: 0.830818]\n",
      "epoch:10 step:9815 [D loss: 0.667536, acc.: 58.59%] [G loss: 0.857077]\n",
      "epoch:10 step:9816 [D loss: 0.685507, acc.: 57.81%] [G loss: 0.885682]\n",
      "epoch:10 step:9817 [D loss: 0.662540, acc.: 57.81%] [G loss: 0.884895]\n",
      "epoch:10 step:9818 [D loss: 0.682565, acc.: 56.25%] [G loss: 0.840099]\n",
      "epoch:10 step:9819 [D loss: 0.661153, acc.: 60.16%] [G loss: 0.823151]\n",
      "epoch:10 step:9820 [D loss: 0.642993, acc.: 61.72%] [G loss: 0.824951]\n",
      "epoch:10 step:9821 [D loss: 0.654278, acc.: 57.03%] [G loss: 0.880696]\n",
      "epoch:10 step:9822 [D loss: 0.654439, acc.: 60.16%] [G loss: 0.836569]\n",
      "epoch:10 step:9823 [D loss: 0.630675, acc.: 67.97%] [G loss: 0.872537]\n",
      "epoch:10 step:9824 [D loss: 0.668248, acc.: 57.03%] [G loss: 0.858784]\n",
      "epoch:10 step:9825 [D loss: 0.661309, acc.: 57.03%] [G loss: 0.801838]\n",
      "epoch:10 step:9826 [D loss: 0.672554, acc.: 61.72%] [G loss: 0.816558]\n",
      "epoch:10 step:9827 [D loss: 0.669029, acc.: 57.03%] [G loss: 0.832631]\n",
      "epoch:10 step:9828 [D loss: 0.650352, acc.: 59.38%] [G loss: 0.819375]\n",
      "epoch:10 step:9829 [D loss: 0.647232, acc.: 58.59%] [G loss: 0.899422]\n",
      "epoch:10 step:9830 [D loss: 0.650264, acc.: 58.59%] [G loss: 0.892522]\n",
      "epoch:10 step:9831 [D loss: 0.670852, acc.: 58.59%] [G loss: 0.860676]\n",
      "epoch:10 step:9832 [D loss: 0.658426, acc.: 58.59%] [G loss: 0.823243]\n",
      "epoch:10 step:9833 [D loss: 0.665102, acc.: 60.94%] [G loss: 0.809268]\n",
      "epoch:10 step:9834 [D loss: 0.693937, acc.: 54.69%] [G loss: 0.812929]\n",
      "epoch:10 step:9835 [D loss: 0.693348, acc.: 52.34%] [G loss: 0.820630]\n",
      "epoch:10 step:9836 [D loss: 0.702656, acc.: 53.91%] [G loss: 0.812919]\n",
      "epoch:10 step:9837 [D loss: 0.645073, acc.: 61.72%] [G loss: 0.823690]\n",
      "epoch:10 step:9838 [D loss: 0.634633, acc.: 68.75%] [G loss: 0.845593]\n",
      "epoch:10 step:9839 [D loss: 0.678611, acc.: 55.47%] [G loss: 0.819960]\n",
      "epoch:10 step:9840 [D loss: 0.693424, acc.: 56.25%] [G loss: 0.807938]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9841 [D loss: 0.650585, acc.: 63.28%] [G loss: 0.834631]\n",
      "epoch:10 step:9842 [D loss: 0.673798, acc.: 57.03%] [G loss: 0.843915]\n",
      "epoch:10 step:9843 [D loss: 0.701561, acc.: 50.78%] [G loss: 0.900144]\n",
      "epoch:10 step:9844 [D loss: 0.629168, acc.: 65.62%] [G loss: 0.914473]\n",
      "epoch:10 step:9845 [D loss: 0.681676, acc.: 57.03%] [G loss: 0.863908]\n",
      "epoch:10 step:9846 [D loss: 0.665833, acc.: 60.94%] [G loss: 0.830630]\n",
      "epoch:10 step:9847 [D loss: 0.699224, acc.: 54.69%] [G loss: 0.856182]\n",
      "epoch:10 step:9848 [D loss: 0.691272, acc.: 53.12%] [G loss: 0.821175]\n",
      "epoch:10 step:9849 [D loss: 0.677622, acc.: 55.47%] [G loss: 0.771280]\n",
      "epoch:10 step:9850 [D loss: 0.664648, acc.: 62.50%] [G loss: 0.785813]\n",
      "epoch:10 step:9851 [D loss: 0.675067, acc.: 56.25%] [G loss: 0.796545]\n",
      "epoch:10 step:9852 [D loss: 0.681049, acc.: 58.59%] [G loss: 0.824619]\n",
      "epoch:10 step:9853 [D loss: 0.678020, acc.: 56.25%] [G loss: 0.811054]\n",
      "epoch:10 step:9854 [D loss: 0.666288, acc.: 57.03%] [G loss: 0.851211]\n",
      "epoch:10 step:9855 [D loss: 0.677380, acc.: 53.91%] [G loss: 0.853894]\n",
      "epoch:10 step:9856 [D loss: 0.650403, acc.: 62.50%] [G loss: 0.825232]\n",
      "epoch:10 step:9857 [D loss: 0.690060, acc.: 53.12%] [G loss: 0.842162]\n",
      "epoch:10 step:9858 [D loss: 0.648739, acc.: 64.84%] [G loss: 0.832718]\n",
      "epoch:10 step:9859 [D loss: 0.647988, acc.: 67.19%] [G loss: 0.833434]\n",
      "epoch:10 step:9860 [D loss: 0.664038, acc.: 58.59%] [G loss: 0.823228]\n",
      "epoch:10 step:9861 [D loss: 0.647806, acc.: 66.41%] [G loss: 0.864937]\n",
      "epoch:10 step:9862 [D loss: 0.634610, acc.: 67.19%] [G loss: 0.802983]\n",
      "epoch:10 step:9863 [D loss: 0.663480, acc.: 58.59%] [G loss: 0.908623]\n",
      "epoch:10 step:9864 [D loss: 0.632487, acc.: 63.28%] [G loss: 0.853001]\n",
      "epoch:10 step:9865 [D loss: 0.679263, acc.: 57.81%] [G loss: 0.856330]\n",
      "epoch:10 step:9866 [D loss: 0.675746, acc.: 53.12%] [G loss: 0.848566]\n",
      "epoch:10 step:9867 [D loss: 0.641249, acc.: 65.62%] [G loss: 0.861199]\n",
      "epoch:10 step:9868 [D loss: 0.689623, acc.: 53.91%] [G loss: 0.845685]\n",
      "epoch:10 step:9869 [D loss: 0.664480, acc.: 57.81%] [G loss: 0.846129]\n",
      "epoch:10 step:9870 [D loss: 0.675315, acc.: 55.47%] [G loss: 0.891476]\n",
      "epoch:10 step:9871 [D loss: 0.669071, acc.: 59.38%] [G loss: 0.879173]\n",
      "epoch:10 step:9872 [D loss: 0.679744, acc.: 57.81%] [G loss: 0.861990]\n",
      "epoch:10 step:9873 [D loss: 0.652358, acc.: 60.94%] [G loss: 0.868613]\n",
      "epoch:10 step:9874 [D loss: 0.660923, acc.: 61.72%] [G loss: 0.845348]\n",
      "epoch:10 step:9875 [D loss: 0.665833, acc.: 57.03%] [G loss: 0.822243]\n",
      "epoch:10 step:9876 [D loss: 0.704263, acc.: 55.47%] [G loss: 0.844828]\n",
      "epoch:10 step:9877 [D loss: 0.664389, acc.: 60.94%] [G loss: 0.838574]\n",
      "epoch:10 step:9878 [D loss: 0.660573, acc.: 64.06%] [G loss: 0.797473]\n",
      "epoch:10 step:9879 [D loss: 0.679494, acc.: 56.25%] [G loss: 0.824547]\n",
      "epoch:10 step:9880 [D loss: 0.633362, acc.: 64.84%] [G loss: 0.912347]\n",
      "epoch:10 step:9881 [D loss: 0.675880, acc.: 53.12%] [G loss: 0.851821]\n",
      "epoch:10 step:9882 [D loss: 0.654446, acc.: 62.50%] [G loss: 0.856342]\n",
      "epoch:10 step:9883 [D loss: 0.652479, acc.: 63.28%] [G loss: 0.871726]\n",
      "epoch:10 step:9884 [D loss: 0.674312, acc.: 59.38%] [G loss: 0.832229]\n",
      "epoch:10 step:9885 [D loss: 0.653467, acc.: 62.50%] [G loss: 0.807831]\n",
      "epoch:10 step:9886 [D loss: 0.640460, acc.: 59.38%] [G loss: 0.866052]\n",
      "epoch:10 step:9887 [D loss: 0.627344, acc.: 61.72%] [G loss: 0.808267]\n",
      "epoch:10 step:9888 [D loss: 0.716012, acc.: 53.91%] [G loss: 0.860157]\n",
      "epoch:10 step:9889 [D loss: 0.659319, acc.: 63.28%] [G loss: 0.850295]\n",
      "epoch:10 step:9890 [D loss: 0.675819, acc.: 57.03%] [G loss: 0.896177]\n",
      "epoch:10 step:9891 [D loss: 0.630745, acc.: 60.94%] [G loss: 0.915614]\n",
      "epoch:10 step:9892 [D loss: 0.677982, acc.: 56.25%] [G loss: 0.868334]\n",
      "epoch:10 step:9893 [D loss: 0.667374, acc.: 62.50%] [G loss: 0.841804]\n",
      "epoch:10 step:9894 [D loss: 0.694479, acc.: 56.25%] [G loss: 0.833569]\n",
      "epoch:10 step:9895 [D loss: 0.693647, acc.: 53.91%] [G loss: 0.852041]\n",
      "epoch:10 step:9896 [D loss: 0.672934, acc.: 51.56%] [G loss: 0.894592]\n",
      "epoch:10 step:9897 [D loss: 0.690563, acc.: 52.34%] [G loss: 0.896680]\n",
      "epoch:10 step:9898 [D loss: 0.679887, acc.: 54.69%] [G loss: 0.883640]\n",
      "epoch:10 step:9899 [D loss: 0.678952, acc.: 53.91%] [G loss: 0.906689]\n",
      "epoch:10 step:9900 [D loss: 0.679334, acc.: 57.03%] [G loss: 0.897651]\n",
      "epoch:10 step:9901 [D loss: 0.676652, acc.: 62.50%] [G loss: 0.865773]\n",
      "epoch:10 step:9902 [D loss: 0.683306, acc.: 54.69%] [G loss: 0.877137]\n",
      "epoch:10 step:9903 [D loss: 0.669494, acc.: 55.47%] [G loss: 0.863624]\n",
      "epoch:10 step:9904 [D loss: 0.708836, acc.: 52.34%] [G loss: 0.862454]\n",
      "epoch:10 step:9905 [D loss: 0.653363, acc.: 62.50%] [G loss: 0.838401]\n",
      "epoch:10 step:9906 [D loss: 0.689577, acc.: 53.12%] [G loss: 0.866390]\n",
      "epoch:10 step:9907 [D loss: 0.702239, acc.: 53.91%] [G loss: 0.854119]\n",
      "epoch:10 step:9908 [D loss: 0.689914, acc.: 54.69%] [G loss: 0.858548]\n",
      "epoch:10 step:9909 [D loss: 0.684121, acc.: 52.34%] [G loss: 0.828780]\n",
      "epoch:10 step:9910 [D loss: 0.660881, acc.: 56.25%] [G loss: 0.848805]\n",
      "epoch:10 step:9911 [D loss: 0.664285, acc.: 57.81%] [G loss: 0.844481]\n",
      "epoch:10 step:9912 [D loss: 0.649607, acc.: 60.94%] [G loss: 0.806611]\n",
      "epoch:10 step:9913 [D loss: 0.667995, acc.: 57.03%] [G loss: 0.840547]\n",
      "epoch:10 step:9914 [D loss: 0.661924, acc.: 60.16%] [G loss: 0.861187]\n",
      "epoch:10 step:9915 [D loss: 0.696890, acc.: 54.69%] [G loss: 0.901416]\n",
      "epoch:10 step:9916 [D loss: 0.699211, acc.: 46.88%] [G loss: 0.864284]\n",
      "epoch:10 step:9917 [D loss: 0.708882, acc.: 55.47%] [G loss: 0.878422]\n",
      "epoch:10 step:9918 [D loss: 0.680681, acc.: 57.03%] [G loss: 0.828981]\n",
      "epoch:10 step:9919 [D loss: 0.722319, acc.: 46.88%] [G loss: 0.847282]\n",
      "epoch:10 step:9920 [D loss: 0.674657, acc.: 58.59%] [G loss: 0.853879]\n",
      "epoch:10 step:9921 [D loss: 0.689848, acc.: 56.25%] [G loss: 0.848831]\n",
      "epoch:10 step:9922 [D loss: 0.652038, acc.: 63.28%] [G loss: 0.885918]\n",
      "epoch:10 step:9923 [D loss: 0.727655, acc.: 43.75%] [G loss: 0.772040]\n",
      "epoch:10 step:9924 [D loss: 0.653309, acc.: 60.16%] [G loss: 0.826395]\n",
      "epoch:10 step:9925 [D loss: 0.653596, acc.: 61.72%] [G loss: 0.831549]\n",
      "epoch:10 step:9926 [D loss: 0.707865, acc.: 58.59%] [G loss: 0.864561]\n",
      "epoch:10 step:9927 [D loss: 0.656509, acc.: 60.16%] [G loss: 0.824655]\n",
      "epoch:10 step:9928 [D loss: 0.695128, acc.: 52.34%] [G loss: 0.809304]\n",
      "epoch:10 step:9929 [D loss: 0.661547, acc.: 62.50%] [G loss: 0.830925]\n",
      "epoch:10 step:9930 [D loss: 0.665514, acc.: 56.25%] [G loss: 0.831050]\n",
      "epoch:10 step:9931 [D loss: 0.654641, acc.: 62.50%] [G loss: 0.819900]\n",
      "epoch:10 step:9932 [D loss: 0.675887, acc.: 60.16%] [G loss: 0.826635]\n",
      "epoch:10 step:9933 [D loss: 0.657312, acc.: 62.50%] [G loss: 0.823611]\n",
      "epoch:10 step:9934 [D loss: 0.664370, acc.: 60.94%] [G loss: 0.861915]\n",
      "epoch:10 step:9935 [D loss: 0.654020, acc.: 64.06%] [G loss: 0.836505]\n",
      "epoch:10 step:9936 [D loss: 0.612817, acc.: 71.88%] [G loss: 0.889225]\n",
      "epoch:10 step:9937 [D loss: 0.700390, acc.: 50.00%] [G loss: 0.824832]\n",
      "epoch:10 step:9938 [D loss: 0.687435, acc.: 50.00%] [G loss: 0.845623]\n",
      "epoch:10 step:9939 [D loss: 0.639747, acc.: 68.75%] [G loss: 0.831702]\n",
      "epoch:10 step:9940 [D loss: 0.655233, acc.: 58.59%] [G loss: 0.849143]\n",
      "epoch:10 step:9941 [D loss: 0.652750, acc.: 61.72%] [G loss: 0.878900]\n",
      "epoch:10 step:9942 [D loss: 0.669888, acc.: 60.16%] [G loss: 0.822692]\n",
      "epoch:10 step:9943 [D loss: 0.675878, acc.: 55.47%] [G loss: 0.877223]\n",
      "epoch:10 step:9944 [D loss: 0.696737, acc.: 56.25%] [G loss: 0.841892]\n",
      "epoch:10 step:9945 [D loss: 0.697140, acc.: 50.78%] [G loss: 0.826071]\n",
      "epoch:10 step:9946 [D loss: 0.666717, acc.: 57.81%] [G loss: 0.910000]\n",
      "epoch:10 step:9947 [D loss: 0.630190, acc.: 66.41%] [G loss: 0.833830]\n",
      "epoch:10 step:9948 [D loss: 0.660252, acc.: 59.38%] [G loss: 0.888675]\n",
      "epoch:10 step:9949 [D loss: 0.663784, acc.: 57.81%] [G loss: 0.855558]\n",
      "epoch:10 step:9950 [D loss: 0.656139, acc.: 64.06%] [G loss: 0.885099]\n",
      "epoch:10 step:9951 [D loss: 0.677915, acc.: 53.91%] [G loss: 0.845892]\n",
      "epoch:10 step:9952 [D loss: 0.629654, acc.: 67.19%] [G loss: 0.824971]\n",
      "epoch:10 step:9953 [D loss: 0.699211, acc.: 57.03%] [G loss: 0.812129]\n",
      "epoch:10 step:9954 [D loss: 0.666557, acc.: 61.72%] [G loss: 0.831782]\n",
      "epoch:10 step:9955 [D loss: 0.669689, acc.: 62.50%] [G loss: 0.834981]\n",
      "epoch:10 step:9956 [D loss: 0.679615, acc.: 57.03%] [G loss: 0.912571]\n",
      "epoch:10 step:9957 [D loss: 0.677623, acc.: 57.03%] [G loss: 0.847688]\n",
      "epoch:10 step:9958 [D loss: 0.689452, acc.: 53.91%] [G loss: 0.877082]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:9959 [D loss: 0.674109, acc.: 64.06%] [G loss: 0.783957]\n",
      "epoch:10 step:9960 [D loss: 0.664639, acc.: 60.94%] [G loss: 0.802808]\n",
      "epoch:10 step:9961 [D loss: 0.675446, acc.: 55.47%] [G loss: 0.829764]\n",
      "epoch:10 step:9962 [D loss: 0.658504, acc.: 63.28%] [G loss: 0.831226]\n",
      "epoch:10 step:9963 [D loss: 0.714430, acc.: 44.53%] [G loss: 0.796414]\n",
      "epoch:10 step:9964 [D loss: 0.630615, acc.: 67.19%] [G loss: 0.788621]\n",
      "epoch:10 step:9965 [D loss: 0.624734, acc.: 73.44%] [G loss: 0.806193]\n",
      "epoch:10 step:9966 [D loss: 0.676383, acc.: 59.38%] [G loss: 0.839846]\n",
      "epoch:10 step:9967 [D loss: 0.660911, acc.: 57.03%] [G loss: 0.872929]\n",
      "epoch:10 step:9968 [D loss: 0.677362, acc.: 56.25%] [G loss: 0.832392]\n",
      "epoch:10 step:9969 [D loss: 0.641576, acc.: 64.84%] [G loss: 0.822523]\n",
      "epoch:10 step:9970 [D loss: 0.667761, acc.: 58.59%] [G loss: 0.868856]\n",
      "epoch:10 step:9971 [D loss: 0.713389, acc.: 53.91%] [G loss: 0.869860]\n",
      "epoch:10 step:9972 [D loss: 0.635622, acc.: 64.84%] [G loss: 0.861309]\n",
      "epoch:10 step:9973 [D loss: 0.670340, acc.: 61.72%] [G loss: 0.878551]\n",
      "epoch:10 step:9974 [D loss: 0.685742, acc.: 54.69%] [G loss: 0.864440]\n",
      "epoch:10 step:9975 [D loss: 0.663694, acc.: 60.94%] [G loss: 0.809781]\n",
      "epoch:10 step:9976 [D loss: 0.670640, acc.: 58.59%] [G loss: 0.838062]\n",
      "epoch:10 step:9977 [D loss: 0.652515, acc.: 60.16%] [G loss: 0.820510]\n",
      "epoch:10 step:9978 [D loss: 0.675240, acc.: 50.00%] [G loss: 0.832986]\n",
      "epoch:10 step:9979 [D loss: 0.636291, acc.: 71.88%] [G loss: 0.866387]\n",
      "epoch:10 step:9980 [D loss: 0.649030, acc.: 62.50%] [G loss: 0.823591]\n",
      "epoch:10 step:9981 [D loss: 0.660844, acc.: 57.03%] [G loss: 0.846937]\n",
      "epoch:10 step:9982 [D loss: 0.652003, acc.: 57.81%] [G loss: 0.897552]\n",
      "epoch:10 step:9983 [D loss: 0.660179, acc.: 62.50%] [G loss: 0.887778]\n",
      "epoch:10 step:9984 [D loss: 0.674359, acc.: 58.59%] [G loss: 0.831174]\n",
      "epoch:10 step:9985 [D loss: 0.676037, acc.: 57.81%] [G loss: 0.912896]\n",
      "epoch:10 step:9986 [D loss: 0.671084, acc.: 53.91%] [G loss: 0.881950]\n",
      "epoch:10 step:9987 [D loss: 0.690973, acc.: 57.03%] [G loss: 0.859896]\n",
      "epoch:10 step:9988 [D loss: 0.657265, acc.: 60.94%] [G loss: 0.855669]\n",
      "epoch:10 step:9989 [D loss: 0.694622, acc.: 60.94%] [G loss: 0.844227]\n",
      "epoch:10 step:9990 [D loss: 0.668327, acc.: 59.38%] [G loss: 0.833349]\n",
      "epoch:10 step:9991 [D loss: 0.674776, acc.: 60.16%] [G loss: 0.858365]\n",
      "epoch:10 step:9992 [D loss: 0.659299, acc.: 61.72%] [G loss: 0.806497]\n",
      "epoch:10 step:9993 [D loss: 0.674153, acc.: 57.03%] [G loss: 0.859248]\n",
      "epoch:10 step:9994 [D loss: 0.684362, acc.: 53.12%] [G loss: 0.818162]\n",
      "epoch:10 step:9995 [D loss: 0.626159, acc.: 66.41%] [G loss: 0.912524]\n",
      "epoch:10 step:9996 [D loss: 0.680133, acc.: 50.78%] [G loss: 0.814274]\n",
      "epoch:10 step:9997 [D loss: 0.676177, acc.: 57.81%] [G loss: 0.835906]\n",
      "epoch:10 step:9998 [D loss: 0.707895, acc.: 52.34%] [G loss: 0.801026]\n",
      "epoch:10 step:9999 [D loss: 0.664520, acc.: 60.94%] [G loss: 0.835686]\n",
      "epoch:10 step:10000 [D loss: 0.668148, acc.: 61.72%] [G loss: 0.798328]\n",
      "##############\n",
      "[2.8541543  2.41137359 2.17255326 4.09257275 1.20719831 8.34036869\n",
      " 2.82188499 4.00154556 4.11770271 7.14868929]\n",
      "##########\n",
      "epoch:10 step:10001 [D loss: 0.642739, acc.: 62.50%] [G loss: 0.826020]\n",
      "epoch:10 step:10002 [D loss: 0.695673, acc.: 52.34%] [G loss: 0.821327]\n",
      "epoch:10 step:10003 [D loss: 0.663856, acc.: 60.94%] [G loss: 0.857573]\n",
      "epoch:10 step:10004 [D loss: 0.708715, acc.: 50.00%] [G loss: 0.846609]\n",
      "epoch:10 step:10005 [D loss: 0.669177, acc.: 60.94%] [G loss: 0.901132]\n",
      "epoch:10 step:10006 [D loss: 0.633227, acc.: 67.97%] [G loss: 0.805827]\n",
      "epoch:10 step:10007 [D loss: 0.655038, acc.: 57.03%] [G loss: 0.828093]\n",
      "epoch:10 step:10008 [D loss: 0.656992, acc.: 57.03%] [G loss: 0.837278]\n",
      "epoch:10 step:10009 [D loss: 0.661503, acc.: 60.16%] [G loss: 0.857333]\n",
      "epoch:10 step:10010 [D loss: 0.694863, acc.: 57.81%] [G loss: 0.820941]\n",
      "epoch:10 step:10011 [D loss: 0.667193, acc.: 59.38%] [G loss: 0.834593]\n",
      "epoch:10 step:10012 [D loss: 0.660757, acc.: 56.25%] [G loss: 0.905567]\n",
      "epoch:10 step:10013 [D loss: 0.709007, acc.: 57.03%] [G loss: 0.838043]\n",
      "epoch:10 step:10014 [D loss: 0.679536, acc.: 58.59%] [G loss: 0.828389]\n",
      "epoch:10 step:10015 [D loss: 0.681418, acc.: 53.12%] [G loss: 0.845812]\n",
      "epoch:10 step:10016 [D loss: 0.682919, acc.: 59.38%] [G loss: 0.826714]\n",
      "epoch:10 step:10017 [D loss: 0.698773, acc.: 58.59%] [G loss: 0.849170]\n",
      "epoch:10 step:10018 [D loss: 0.631992, acc.: 64.06%] [G loss: 0.807324]\n",
      "epoch:10 step:10019 [D loss: 0.681963, acc.: 54.69%] [G loss: 0.831598]\n",
      "epoch:10 step:10020 [D loss: 0.679177, acc.: 60.16%] [G loss: 0.805247]\n",
      "epoch:10 step:10021 [D loss: 0.662334, acc.: 56.25%] [G loss: 0.848730]\n",
      "epoch:10 step:10022 [D loss: 0.645442, acc.: 63.28%] [G loss: 0.801861]\n",
      "epoch:10 step:10023 [D loss: 0.680625, acc.: 55.47%] [G loss: 0.838169]\n",
      "epoch:10 step:10024 [D loss: 0.691601, acc.: 52.34%] [G loss: 0.834436]\n",
      "epoch:10 step:10025 [D loss: 0.676660, acc.: 52.34%] [G loss: 0.825700]\n",
      "epoch:10 step:10026 [D loss: 0.653505, acc.: 68.75%] [G loss: 0.883400]\n",
      "epoch:10 step:10027 [D loss: 0.681477, acc.: 57.03%] [G loss: 0.871314]\n",
      "epoch:10 step:10028 [D loss: 0.716022, acc.: 45.31%] [G loss: 0.871242]\n",
      "epoch:10 step:10029 [D loss: 0.653550, acc.: 64.06%] [G loss: 0.900837]\n",
      "epoch:10 step:10030 [D loss: 0.653777, acc.: 63.28%] [G loss: 0.844639]\n",
      "epoch:10 step:10031 [D loss: 0.643090, acc.: 65.62%] [G loss: 0.876492]\n",
      "epoch:10 step:10032 [D loss: 0.675491, acc.: 58.59%] [G loss: 0.849121]\n",
      "epoch:10 step:10033 [D loss: 0.659124, acc.: 59.38%] [G loss: 0.863539]\n",
      "epoch:10 step:10034 [D loss: 0.689545, acc.: 60.94%] [G loss: 0.892144]\n",
      "epoch:10 step:10035 [D loss: 0.718152, acc.: 48.44%] [G loss: 0.786803]\n",
      "epoch:10 step:10036 [D loss: 0.655015, acc.: 63.28%] [G loss: 0.864936]\n",
      "epoch:10 step:10037 [D loss: 0.675497, acc.: 57.81%] [G loss: 0.772443]\n",
      "epoch:10 step:10038 [D loss: 0.690220, acc.: 53.12%] [G loss: 0.848599]\n",
      "epoch:10 step:10039 [D loss: 0.655338, acc.: 58.59%] [G loss: 0.848028]\n",
      "epoch:10 step:10040 [D loss: 0.646199, acc.: 57.03%] [G loss: 0.835408]\n",
      "epoch:10 step:10041 [D loss: 0.667337, acc.: 58.59%] [G loss: 0.839410]\n",
      "epoch:10 step:10042 [D loss: 0.704275, acc.: 49.22%] [G loss: 0.923644]\n",
      "epoch:10 step:10043 [D loss: 0.670655, acc.: 57.81%] [G loss: 0.879991]\n",
      "epoch:10 step:10044 [D loss: 0.702170, acc.: 50.78%] [G loss: 0.869184]\n",
      "epoch:10 step:10045 [D loss: 0.700104, acc.: 53.91%] [G loss: 0.819954]\n",
      "epoch:10 step:10046 [D loss: 0.668525, acc.: 55.47%] [G loss: 0.834793]\n",
      "epoch:10 step:10047 [D loss: 0.691080, acc.: 50.00%] [G loss: 0.842294]\n",
      "epoch:10 step:10048 [D loss: 0.644187, acc.: 71.88%] [G loss: 0.859045]\n",
      "epoch:10 step:10049 [D loss: 0.666967, acc.: 60.16%] [G loss: 0.836088]\n",
      "epoch:10 step:10050 [D loss: 0.677631, acc.: 57.03%] [G loss: 0.829279]\n",
      "epoch:10 step:10051 [D loss: 0.657444, acc.: 64.06%] [G loss: 0.866955]\n",
      "epoch:10 step:10052 [D loss: 0.651073, acc.: 57.81%] [G loss: 0.855329]\n",
      "epoch:10 step:10053 [D loss: 0.635774, acc.: 62.50%] [G loss: 0.848601]\n",
      "epoch:10 step:10054 [D loss: 0.650045, acc.: 59.38%] [G loss: 0.869014]\n",
      "epoch:10 step:10055 [D loss: 0.656591, acc.: 60.94%] [G loss: 0.847553]\n",
      "epoch:10 step:10056 [D loss: 0.680103, acc.: 51.56%] [G loss: 0.871433]\n",
      "epoch:10 step:10057 [D loss: 0.653454, acc.: 62.50%] [G loss: 0.836469]\n",
      "epoch:10 step:10058 [D loss: 0.644564, acc.: 63.28%] [G loss: 0.839159]\n",
      "epoch:10 step:10059 [D loss: 0.694931, acc.: 53.91%] [G loss: 0.863693]\n",
      "epoch:10 step:10060 [D loss: 0.669242, acc.: 57.03%] [G loss: 0.908509]\n",
      "epoch:10 step:10061 [D loss: 0.693166, acc.: 53.12%] [G loss: 0.881328]\n",
      "epoch:10 step:10062 [D loss: 0.686658, acc.: 55.47%] [G loss: 0.846205]\n",
      "epoch:10 step:10063 [D loss: 0.669836, acc.: 63.28%] [G loss: 0.827703]\n",
      "epoch:10 step:10064 [D loss: 0.665115, acc.: 64.06%] [G loss: 0.829418]\n",
      "epoch:10 step:10065 [D loss: 0.668044, acc.: 62.50%] [G loss: 0.837774]\n",
      "epoch:10 step:10066 [D loss: 0.680766, acc.: 57.81%] [G loss: 0.804663]\n",
      "epoch:10 step:10067 [D loss: 0.631210, acc.: 71.88%] [G loss: 0.832315]\n",
      "epoch:10 step:10068 [D loss: 0.664526, acc.: 59.38%] [G loss: 0.862038]\n",
      "epoch:10 step:10069 [D loss: 0.676330, acc.: 60.94%] [G loss: 0.823337]\n",
      "epoch:10 step:10070 [D loss: 0.697949, acc.: 52.34%] [G loss: 0.873270]\n",
      "epoch:10 step:10071 [D loss: 0.639548, acc.: 64.06%] [G loss: 0.846842]\n",
      "epoch:10 step:10072 [D loss: 0.652238, acc.: 60.16%] [G loss: 0.854126]\n",
      "epoch:10 step:10073 [D loss: 0.700513, acc.: 57.03%] [G loss: 0.841378]\n",
      "epoch:10 step:10074 [D loss: 0.688536, acc.: 58.59%] [G loss: 0.827582]\n",
      "epoch:10 step:10075 [D loss: 0.665942, acc.: 59.38%] [G loss: 0.803178]\n",
      "epoch:10 step:10076 [D loss: 0.701660, acc.: 53.12%] [G loss: 0.869431]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:10077 [D loss: 0.669846, acc.: 62.50%] [G loss: 0.835042]\n",
      "epoch:10 step:10078 [D loss: 0.689944, acc.: 59.38%] [G loss: 0.828631]\n",
      "epoch:10 step:10079 [D loss: 0.690108, acc.: 57.03%] [G loss: 0.886970]\n",
      "epoch:10 step:10080 [D loss: 0.671917, acc.: 56.25%] [G loss: 0.886748]\n",
      "epoch:10 step:10081 [D loss: 0.662561, acc.: 64.06%] [G loss: 0.870379]\n",
      "epoch:10 step:10082 [D loss: 0.710528, acc.: 54.69%] [G loss: 0.874173]\n",
      "epoch:10 step:10083 [D loss: 0.684179, acc.: 53.12%] [G loss: 0.857718]\n",
      "epoch:10 step:10084 [D loss: 0.675710, acc.: 65.62%] [G loss: 0.834036]\n",
      "epoch:10 step:10085 [D loss: 0.692021, acc.: 60.94%] [G loss: 0.856768]\n",
      "epoch:10 step:10086 [D loss: 0.720798, acc.: 53.91%] [G loss: 0.852139]\n",
      "epoch:10 step:10087 [D loss: 0.657852, acc.: 62.50%] [G loss: 0.831363]\n",
      "epoch:10 step:10088 [D loss: 0.623110, acc.: 64.06%] [G loss: 0.851422]\n",
      "epoch:10 step:10089 [D loss: 0.671231, acc.: 57.03%] [G loss: 0.830332]\n",
      "epoch:10 step:10090 [D loss: 0.656275, acc.: 56.25%] [G loss: 0.795280]\n",
      "epoch:10 step:10091 [D loss: 0.645928, acc.: 62.50%] [G loss: 0.824753]\n",
      "epoch:10 step:10092 [D loss: 0.651129, acc.: 64.84%] [G loss: 0.847347]\n",
      "epoch:10 step:10093 [D loss: 0.685768, acc.: 52.34%] [G loss: 0.856531]\n",
      "epoch:10 step:10094 [D loss: 0.680700, acc.: 58.59%] [G loss: 0.823266]\n",
      "epoch:10 step:10095 [D loss: 0.647884, acc.: 64.84%] [G loss: 0.772293]\n",
      "epoch:10 step:10096 [D loss: 0.662134, acc.: 61.72%] [G loss: 0.856774]\n",
      "epoch:10 step:10097 [D loss: 0.613627, acc.: 69.53%] [G loss: 0.852748]\n",
      "epoch:10 step:10098 [D loss: 0.676892, acc.: 58.59%] [G loss: 0.807280]\n",
      "epoch:10 step:10099 [D loss: 0.640077, acc.: 62.50%] [G loss: 0.878983]\n",
      "epoch:10 step:10100 [D loss: 0.659705, acc.: 60.94%] [G loss: 0.812581]\n",
      "epoch:10 step:10101 [D loss: 0.672054, acc.: 57.03%] [G loss: 0.858151]\n",
      "epoch:10 step:10102 [D loss: 0.692013, acc.: 53.91%] [G loss: 0.841332]\n",
      "epoch:10 step:10103 [D loss: 0.665389, acc.: 57.03%] [G loss: 0.842031]\n",
      "epoch:10 step:10104 [D loss: 0.656711, acc.: 58.59%] [G loss: 0.831897]\n",
      "epoch:10 step:10105 [D loss: 0.655499, acc.: 58.59%] [G loss: 0.919445]\n",
      "epoch:10 step:10106 [D loss: 0.628762, acc.: 66.41%] [G loss: 0.875604]\n",
      "epoch:10 step:10107 [D loss: 0.683463, acc.: 57.81%] [G loss: 0.908393]\n",
      "epoch:10 step:10108 [D loss: 0.678999, acc.: 53.91%] [G loss: 0.829351]\n",
      "epoch:10 step:10109 [D loss: 0.667541, acc.: 54.69%] [G loss: 0.882231]\n",
      "epoch:10 step:10110 [D loss: 0.664607, acc.: 57.81%] [G loss: 0.884750]\n",
      "epoch:10 step:10111 [D loss: 0.660923, acc.: 59.38%] [G loss: 0.870621]\n",
      "epoch:10 step:10112 [D loss: 0.688887, acc.: 50.00%] [G loss: 0.878552]\n",
      "epoch:10 step:10113 [D loss: 0.648461, acc.: 60.16%] [G loss: 0.864685]\n",
      "epoch:10 step:10114 [D loss: 0.659162, acc.: 60.16%] [G loss: 0.835663]\n",
      "epoch:10 step:10115 [D loss: 0.677256, acc.: 55.47%] [G loss: 0.811241]\n",
      "epoch:10 step:10116 [D loss: 0.670544, acc.: 55.47%] [G loss: 0.861878]\n",
      "epoch:10 step:10117 [D loss: 0.688963, acc.: 53.91%] [G loss: 0.823248]\n",
      "epoch:10 step:10118 [D loss: 0.657192, acc.: 57.03%] [G loss: 0.862046]\n",
      "epoch:10 step:10119 [D loss: 0.662140, acc.: 61.72%] [G loss: 0.849483]\n",
      "epoch:10 step:10120 [D loss: 0.664141, acc.: 60.94%] [G loss: 0.860613]\n",
      "epoch:10 step:10121 [D loss: 0.639397, acc.: 63.28%] [G loss: 0.879097]\n",
      "epoch:10 step:10122 [D loss: 0.651860, acc.: 60.16%] [G loss: 0.893072]\n",
      "epoch:10 step:10123 [D loss: 0.657609, acc.: 57.03%] [G loss: 0.851452]\n",
      "epoch:10 step:10124 [D loss: 0.664794, acc.: 62.50%] [G loss: 0.939534]\n",
      "epoch:10 step:10125 [D loss: 0.664031, acc.: 56.25%] [G loss: 0.902245]\n",
      "epoch:10 step:10126 [D loss: 0.649491, acc.: 60.94%] [G loss: 0.887352]\n",
      "epoch:10 step:10127 [D loss: 0.640050, acc.: 63.28%] [G loss: 0.915503]\n",
      "epoch:10 step:10128 [D loss: 0.662727, acc.: 57.03%] [G loss: 0.909339]\n",
      "epoch:10 step:10129 [D loss: 0.652334, acc.: 64.84%] [G loss: 0.900621]\n",
      "epoch:10 step:10130 [D loss: 0.666985, acc.: 57.81%] [G loss: 0.812772]\n",
      "epoch:10 step:10131 [D loss: 0.656231, acc.: 60.94%] [G loss: 0.842654]\n",
      "epoch:10 step:10132 [D loss: 0.669593, acc.: 65.62%] [G loss: 0.893471]\n",
      "epoch:10 step:10133 [D loss: 0.659614, acc.: 60.16%] [G loss: 0.899755]\n",
      "epoch:10 step:10134 [D loss: 0.638043, acc.: 68.75%] [G loss: 0.934537]\n",
      "epoch:10 step:10135 [D loss: 0.665151, acc.: 58.59%] [G loss: 0.858674]\n",
      "epoch:10 step:10136 [D loss: 0.655178, acc.: 64.06%] [G loss: 0.833802]\n",
      "epoch:10 step:10137 [D loss: 0.689397, acc.: 59.38%] [G loss: 0.872019]\n",
      "epoch:10 step:10138 [D loss: 0.655589, acc.: 60.94%] [G loss: 0.866538]\n",
      "epoch:10 step:10139 [D loss: 0.652512, acc.: 64.06%] [G loss: 0.828718]\n",
      "epoch:10 step:10140 [D loss: 0.669529, acc.: 60.94%] [G loss: 0.843000]\n",
      "epoch:10 step:10141 [D loss: 0.635762, acc.: 64.84%] [G loss: 0.853889]\n",
      "epoch:10 step:10142 [D loss: 0.646837, acc.: 60.94%] [G loss: 0.895794]\n",
      "epoch:10 step:10143 [D loss: 0.692502, acc.: 60.16%] [G loss: 0.863194]\n",
      "epoch:10 step:10144 [D loss: 0.636185, acc.: 66.41%] [G loss: 0.904200]\n",
      "epoch:10 step:10145 [D loss: 0.691987, acc.: 53.12%] [G loss: 0.833150]\n",
      "epoch:10 step:10146 [D loss: 0.670269, acc.: 56.25%] [G loss: 0.832340]\n",
      "epoch:10 step:10147 [D loss: 0.707308, acc.: 54.69%] [G loss: 0.834487]\n",
      "epoch:10 step:10148 [D loss: 0.650590, acc.: 62.50%] [G loss: 0.849107]\n",
      "epoch:10 step:10149 [D loss: 0.662555, acc.: 57.03%] [G loss: 0.847743]\n",
      "epoch:10 step:10150 [D loss: 0.662313, acc.: 58.59%] [G loss: 0.870976]\n",
      "epoch:10 step:10151 [D loss: 0.675960, acc.: 60.16%] [G loss: 0.876537]\n",
      "epoch:10 step:10152 [D loss: 0.654781, acc.: 62.50%] [G loss: 0.855462]\n",
      "epoch:10 step:10153 [D loss: 0.683461, acc.: 58.59%] [G loss: 0.914900]\n",
      "epoch:10 step:10154 [D loss: 0.628442, acc.: 65.62%] [G loss: 0.892881]\n",
      "epoch:10 step:10155 [D loss: 0.659667, acc.: 60.94%] [G loss: 0.880585]\n",
      "epoch:10 step:10156 [D loss: 0.700717, acc.: 55.47%] [G loss: 0.889791]\n",
      "epoch:10 step:10157 [D loss: 0.645632, acc.: 64.06%] [G loss: 0.851808]\n",
      "epoch:10 step:10158 [D loss: 0.650988, acc.: 59.38%] [G loss: 0.842204]\n",
      "epoch:10 step:10159 [D loss: 0.683306, acc.: 56.25%] [G loss: 0.829579]\n",
      "epoch:10 step:10160 [D loss: 0.635996, acc.: 62.50%] [G loss: 0.808557]\n",
      "epoch:10 step:10161 [D loss: 0.704429, acc.: 49.22%] [G loss: 0.825966]\n",
      "epoch:10 step:10162 [D loss: 0.660419, acc.: 56.25%] [G loss: 0.878411]\n",
      "epoch:10 step:10163 [D loss: 0.666727, acc.: 55.47%] [G loss: 0.834775]\n",
      "epoch:10 step:10164 [D loss: 0.630406, acc.: 67.19%] [G loss: 0.853014]\n",
      "epoch:10 step:10165 [D loss: 0.676129, acc.: 63.28%] [G loss: 0.861351]\n",
      "epoch:10 step:10166 [D loss: 0.665436, acc.: 59.38%] [G loss: 0.880233]\n",
      "epoch:10 step:10167 [D loss: 0.685370, acc.: 53.12%] [G loss: 0.876503]\n",
      "epoch:10 step:10168 [D loss: 0.683928, acc.: 57.81%] [G loss: 0.848689]\n",
      "epoch:10 step:10169 [D loss: 0.662648, acc.: 61.72%] [G loss: 0.870632]\n",
      "epoch:10 step:10170 [D loss: 0.679606, acc.: 57.81%] [G loss: 0.836415]\n",
      "epoch:10 step:10171 [D loss: 0.693257, acc.: 53.12%] [G loss: 0.843459]\n",
      "epoch:10 step:10172 [D loss: 0.700282, acc.: 50.78%] [G loss: 0.879275]\n",
      "epoch:10 step:10173 [D loss: 0.690954, acc.: 53.91%] [G loss: 0.890819]\n",
      "epoch:10 step:10174 [D loss: 0.693228, acc.: 60.94%] [G loss: 0.870840]\n",
      "epoch:10 step:10175 [D loss: 0.679919, acc.: 54.69%] [G loss: 0.903140]\n",
      "epoch:10 step:10176 [D loss: 0.638165, acc.: 64.84%] [G loss: 0.855484]\n",
      "epoch:10 step:10177 [D loss: 0.655126, acc.: 58.59%] [G loss: 0.838121]\n",
      "epoch:10 step:10178 [D loss: 0.679002, acc.: 60.16%] [G loss: 0.862319]\n",
      "epoch:10 step:10179 [D loss: 0.660034, acc.: 60.94%] [G loss: 0.848292]\n",
      "epoch:10 step:10180 [D loss: 0.668320, acc.: 60.16%] [G loss: 0.840185]\n",
      "epoch:10 step:10181 [D loss: 0.699004, acc.: 48.44%] [G loss: 0.830494]\n",
      "epoch:10 step:10182 [D loss: 0.666742, acc.: 53.91%] [G loss: 0.881037]\n",
      "epoch:10 step:10183 [D loss: 0.641820, acc.: 61.72%] [G loss: 0.876788]\n",
      "epoch:10 step:10184 [D loss: 0.660090, acc.: 57.03%] [G loss: 0.888867]\n",
      "epoch:10 step:10185 [D loss: 0.724470, acc.: 49.22%] [G loss: 0.871386]\n",
      "epoch:10 step:10186 [D loss: 0.649526, acc.: 62.50%] [G loss: 0.893457]\n",
      "epoch:10 step:10187 [D loss: 0.706888, acc.: 49.22%] [G loss: 0.845430]\n",
      "epoch:10 step:10188 [D loss: 0.691020, acc.: 49.22%] [G loss: 0.872846]\n",
      "epoch:10 step:10189 [D loss: 0.696943, acc.: 50.78%] [G loss: 0.826306]\n",
      "epoch:10 step:10190 [D loss: 0.699636, acc.: 50.78%] [G loss: 0.842582]\n",
      "epoch:10 step:10191 [D loss: 0.650946, acc.: 60.16%] [G loss: 0.843906]\n",
      "epoch:10 step:10192 [D loss: 0.666953, acc.: 60.94%] [G loss: 0.856970]\n",
      "epoch:10 step:10193 [D loss: 0.697373, acc.: 50.78%] [G loss: 0.832893]\n",
      "epoch:10 step:10194 [D loss: 0.675909, acc.: 51.56%] [G loss: 0.823455]\n",
      "epoch:10 step:10195 [D loss: 0.666724, acc.: 54.69%] [G loss: 0.871546]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:10 step:10196 [D loss: 0.659069, acc.: 59.38%] [G loss: 0.861569]\n",
      "epoch:10 step:10197 [D loss: 0.683503, acc.: 56.25%] [G loss: 0.893026]\n",
      "epoch:10 step:10198 [D loss: 0.682855, acc.: 53.91%] [G loss: 0.827063]\n",
      "epoch:10 step:10199 [D loss: 0.639956, acc.: 66.41%] [G loss: 0.853723]\n",
      "epoch:10 step:10200 [D loss: 0.683001, acc.: 54.69%] [G loss: 0.826166]\n",
      "##############\n",
      "[3.05671786 2.69643922 2.31243776 4.16817256 1.47149343 9.27377891\n",
      " 2.77862313 4.08836693 4.31410083 8.14868929]\n",
      "##########\n",
      "epoch:10 step:10201 [D loss: 0.693015, acc.: 53.91%] [G loss: 0.854337]\n",
      "epoch:10 step:10202 [D loss: 0.669795, acc.: 52.34%] [G loss: 0.837114]\n",
      "epoch:10 step:10203 [D loss: 0.670781, acc.: 55.47%] [G loss: 0.879740]\n",
      "epoch:10 step:10204 [D loss: 0.666442, acc.: 60.16%] [G loss: 0.844928]\n",
      "epoch:10 step:10205 [D loss: 0.648250, acc.: 61.72%] [G loss: 0.848160]\n",
      "epoch:10 step:10206 [D loss: 0.663560, acc.: 57.81%] [G loss: 0.861714]\n",
      "epoch:10 step:10207 [D loss: 0.651332, acc.: 63.28%] [G loss: 0.843325]\n",
      "epoch:10 step:10208 [D loss: 0.671620, acc.: 53.91%] [G loss: 0.831193]\n",
      "epoch:10 step:10209 [D loss: 0.666914, acc.: 59.38%] [G loss: 0.858674]\n",
      "epoch:10 step:10210 [D loss: 0.679636, acc.: 54.69%] [G loss: 0.807949]\n",
      "epoch:10 step:10211 [D loss: 0.663830, acc.: 61.72%] [G loss: 0.805655]\n",
      "epoch:10 step:10212 [D loss: 0.693048, acc.: 48.44%] [G loss: 0.857232]\n",
      "epoch:10 step:10213 [D loss: 0.707175, acc.: 50.78%] [G loss: 0.855252]\n",
      "epoch:10 step:10214 [D loss: 0.643814, acc.: 64.84%] [G loss: 0.875925]\n",
      "epoch:10 step:10215 [D loss: 0.680082, acc.: 55.47%] [G loss: 0.882664]\n",
      "epoch:10 step:10216 [D loss: 0.670700, acc.: 55.47%] [G loss: 0.849574]\n",
      "epoch:10 step:10217 [D loss: 0.673152, acc.: 60.16%] [G loss: 0.867009]\n",
      "epoch:10 step:10218 [D loss: 0.686904, acc.: 53.12%] [G loss: 0.855951]\n",
      "epoch:10 step:10219 [D loss: 0.649776, acc.: 60.94%] [G loss: 0.854264]\n",
      "epoch:10 step:10220 [D loss: 0.675424, acc.: 60.16%] [G loss: 0.869792]\n",
      "epoch:10 step:10221 [D loss: 0.703587, acc.: 49.22%] [G loss: 0.842084]\n",
      "epoch:10 step:10222 [D loss: 0.663448, acc.: 64.06%] [G loss: 0.837684]\n",
      "epoch:10 step:10223 [D loss: 0.639029, acc.: 59.38%] [G loss: 0.869625]\n",
      "epoch:10 step:10224 [D loss: 0.673838, acc.: 57.81%] [G loss: 0.867217]\n",
      "epoch:10 step:10225 [D loss: 0.681301, acc.: 57.03%] [G loss: 0.879327]\n",
      "epoch:10 step:10226 [D loss: 0.652911, acc.: 57.81%] [G loss: 0.855380]\n",
      "epoch:10 step:10227 [D loss: 0.668126, acc.: 60.16%] [G loss: 0.810369]\n",
      "epoch:10 step:10228 [D loss: 0.675210, acc.: 57.03%] [G loss: 0.854836]\n",
      "epoch:10 step:10229 [D loss: 0.655017, acc.: 57.81%] [G loss: 0.873201]\n",
      "epoch:10 step:10230 [D loss: 0.667313, acc.: 61.72%] [G loss: 0.857050]\n",
      "epoch:10 step:10231 [D loss: 0.646798, acc.: 64.06%] [G loss: 0.814297]\n",
      "epoch:10 step:10232 [D loss: 0.661179, acc.: 64.06%] [G loss: 0.871994]\n",
      "epoch:10 step:10233 [D loss: 0.641677, acc.: 60.94%] [G loss: 0.878197]\n",
      "epoch:10 step:10234 [D loss: 0.669189, acc.: 60.94%] [G loss: 0.861363]\n",
      "epoch:10 step:10235 [D loss: 0.651377, acc.: 53.12%] [G loss: 0.842504]\n",
      "epoch:10 step:10236 [D loss: 0.657221, acc.: 61.72%] [G loss: 0.830851]\n",
      "epoch:10 step:10237 [D loss: 0.690550, acc.: 54.69%] [G loss: 0.783188]\n",
      "epoch:10 step:10238 [D loss: 0.641679, acc.: 67.19%] [G loss: 0.823360]\n",
      "epoch:10 step:10239 [D loss: 0.658067, acc.: 57.81%] [G loss: 0.870251]\n",
      "epoch:10 step:10240 [D loss: 0.694769, acc.: 48.44%] [G loss: 0.813957]\n",
      "epoch:10 step:10241 [D loss: 0.658564, acc.: 59.38%] [G loss: 0.870363]\n",
      "epoch:10 step:10242 [D loss: 0.689074, acc.: 54.69%] [G loss: 0.819320]\n",
      "epoch:10 step:10243 [D loss: 0.686016, acc.: 56.25%] [G loss: 0.852529]\n",
      "epoch:10 step:10244 [D loss: 0.680499, acc.: 58.59%] [G loss: 0.846262]\n",
      "epoch:10 step:10245 [D loss: 0.644588, acc.: 65.62%] [G loss: 0.869015]\n",
      "epoch:10 step:10246 [D loss: 0.660016, acc.: 66.41%] [G loss: 0.893742]\n",
      "epoch:10 step:10247 [D loss: 0.640814, acc.: 61.72%] [G loss: 0.881296]\n",
      "epoch:10 step:10248 [D loss: 0.667566, acc.: 55.47%] [G loss: 0.908470]\n",
      "epoch:10 step:10249 [D loss: 0.664544, acc.: 58.59%] [G loss: 0.889004]\n",
      "epoch:10 step:10250 [D loss: 0.689005, acc.: 54.69%] [G loss: 0.847465]\n",
      "epoch:10 step:10251 [D loss: 0.671191, acc.: 58.59%] [G loss: 0.841101]\n",
      "epoch:10 step:10252 [D loss: 0.657259, acc.: 60.94%] [G loss: 0.823975]\n",
      "epoch:10 step:10253 [D loss: 0.642959, acc.: 63.28%] [G loss: 0.876265]\n",
      "epoch:10 step:10254 [D loss: 0.651181, acc.: 64.06%] [G loss: 0.875924]\n",
      "epoch:10 step:10255 [D loss: 0.657729, acc.: 60.94%] [G loss: 0.799755]\n",
      "epoch:10 step:10256 [D loss: 0.662644, acc.: 55.47%] [G loss: 0.860304]\n",
      "epoch:10 step:10257 [D loss: 0.672810, acc.: 58.59%] [G loss: 0.836107]\n",
      "epoch:10 step:10258 [D loss: 0.666335, acc.: 54.69%] [G loss: 0.829924]\n",
      "epoch:10 step:10259 [D loss: 0.658111, acc.: 58.59%] [G loss: 0.858769]\n",
      "epoch:10 step:10260 [D loss: 0.674387, acc.: 53.91%] [G loss: 0.861457]\n",
      "epoch:10 step:10261 [D loss: 0.662126, acc.: 58.59%] [G loss: 0.864934]\n",
      "epoch:10 step:10262 [D loss: 0.684855, acc.: 49.22%] [G loss: 0.816539]\n",
      "epoch:10 step:10263 [D loss: 0.690392, acc.: 50.78%] [G loss: 0.815845]\n",
      "epoch:10 step:10264 [D loss: 0.699887, acc.: 50.00%] [G loss: 0.810230]\n",
      "epoch:10 step:10265 [D loss: 0.627492, acc.: 68.75%] [G loss: 0.871693]\n",
      "epoch:10 step:10266 [D loss: 0.662184, acc.: 60.16%] [G loss: 0.847792]\n",
      "epoch:10 step:10267 [D loss: 0.654888, acc.: 63.28%] [G loss: 0.854299]\n",
      "epoch:10 step:10268 [D loss: 0.663953, acc.: 60.94%] [G loss: 0.802309]\n",
      "epoch:10 step:10269 [D loss: 0.692000, acc.: 57.81%] [G loss: 0.814691]\n",
      "epoch:10 step:10270 [D loss: 0.630404, acc.: 65.62%] [G loss: 0.840086]\n",
      "epoch:10 step:10271 [D loss: 0.683302, acc.: 60.16%] [G loss: 0.824290]\n",
      "epoch:10 step:10272 [D loss: 0.665718, acc.: 57.03%] [G loss: 0.868483]\n",
      "epoch:10 step:10273 [D loss: 0.634142, acc.: 67.19%] [G loss: 0.818647]\n",
      "epoch:10 step:10274 [D loss: 0.642347, acc.: 60.94%] [G loss: 0.839799]\n",
      "epoch:10 step:10275 [D loss: 0.654685, acc.: 61.72%] [G loss: 0.865211]\n",
      "epoch:10 step:10276 [D loss: 0.652659, acc.: 61.72%] [G loss: 0.857592]\n",
      "epoch:10 step:10277 [D loss: 0.711026, acc.: 47.66%] [G loss: 0.867485]\n",
      "epoch:10 step:10278 [D loss: 0.676956, acc.: 53.91%] [G loss: 0.860585]\n",
      "epoch:10 step:10279 [D loss: 0.692116, acc.: 53.91%] [G loss: 0.812274]\n",
      "epoch:10 step:10280 [D loss: 0.690602, acc.: 52.34%] [G loss: 0.855158]\n",
      "epoch:10 step:10281 [D loss: 0.657152, acc.: 59.38%] [G loss: 0.857499]\n",
      "epoch:10 step:10282 [D loss: 0.668628, acc.: 64.84%] [G loss: 0.816221]\n",
      "epoch:10 step:10283 [D loss: 0.652252, acc.: 61.72%] [G loss: 0.845544]\n",
      "epoch:10 step:10284 [D loss: 0.644829, acc.: 62.50%] [G loss: 0.921940]\n",
      "epoch:10 step:10285 [D loss: 0.662230, acc.: 60.94%] [G loss: 0.908899]\n",
      "epoch:10 step:10286 [D loss: 0.685095, acc.: 54.69%] [G loss: 0.817206]\n",
      "epoch:10 step:10287 [D loss: 0.647574, acc.: 61.72%] [G loss: 0.831709]\n",
      "epoch:10 step:10288 [D loss: 0.665472, acc.: 63.28%] [G loss: 0.870660]\n",
      "epoch:10 step:10289 [D loss: 0.653116, acc.: 63.28%] [G loss: 0.858844]\n",
      "epoch:10 step:10290 [D loss: 0.681650, acc.: 56.25%] [G loss: 0.872405]\n",
      "epoch:10 step:10291 [D loss: 0.681309, acc.: 60.16%] [G loss: 0.856949]\n",
      "epoch:10 step:10292 [D loss: 0.658816, acc.: 62.50%] [G loss: 0.815055]\n",
      "epoch:10 step:10293 [D loss: 0.659984, acc.: 55.47%] [G loss: 0.830915]\n",
      "epoch:10 step:10294 [D loss: 0.648701, acc.: 66.41%] [G loss: 0.874589]\n",
      "epoch:10 step:10295 [D loss: 0.688500, acc.: 55.47%] [G loss: 0.824227]\n",
      "epoch:10 step:10296 [D loss: 0.687278, acc.: 56.25%] [G loss: 0.855700]\n",
      "epoch:10 step:10297 [D loss: 0.669832, acc.: 59.38%] [G loss: 0.811928]\n",
      "epoch:10 step:10298 [D loss: 0.667609, acc.: 59.38%] [G loss: 0.822537]\n",
      "epoch:10 step:10299 [D loss: 0.667659, acc.: 63.28%] [G loss: 0.861984]\n",
      "epoch:10 step:10300 [D loss: 0.657494, acc.: 57.81%] [G loss: 0.863873]\n",
      "epoch:10 step:10301 [D loss: 0.702737, acc.: 50.78%] [G loss: 0.843532]\n",
      "epoch:10 step:10302 [D loss: 0.648170, acc.: 58.59%] [G loss: 0.879430]\n",
      "epoch:10 step:10303 [D loss: 0.668865, acc.: 54.69%] [G loss: 0.833283]\n",
      "epoch:10 step:10304 [D loss: 0.642128, acc.: 64.84%] [G loss: 0.873701]\n",
      "epoch:10 step:10305 [D loss: 0.669655, acc.: 62.50%] [G loss: 0.859133]\n",
      "epoch:10 step:10306 [D loss: 0.650713, acc.: 60.16%] [G loss: 0.904860]\n",
      "epoch:10 step:10307 [D loss: 0.651122, acc.: 56.25%] [G loss: 0.874911]\n",
      "epoch:11 step:10308 [D loss: 0.679648, acc.: 61.72%] [G loss: 0.850461]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10309 [D loss: 0.679647, acc.: 53.12%] [G loss: 0.829048]\n",
      "epoch:11 step:10310 [D loss: 0.646569, acc.: 60.16%] [G loss: 0.863226]\n",
      "epoch:11 step:10311 [D loss: 0.687302, acc.: 50.78%] [G loss: 0.846886]\n",
      "epoch:11 step:10312 [D loss: 0.660969, acc.: 62.50%] [G loss: 0.845994]\n",
      "epoch:11 step:10313 [D loss: 0.644012, acc.: 62.50%] [G loss: 0.842085]\n",
      "epoch:11 step:10314 [D loss: 0.680385, acc.: 53.91%] [G loss: 0.885927]\n",
      "epoch:11 step:10315 [D loss: 0.677857, acc.: 57.03%] [G loss: 0.827689]\n",
      "epoch:11 step:10316 [D loss: 0.665685, acc.: 58.59%] [G loss: 0.796134]\n",
      "epoch:11 step:10317 [D loss: 0.670509, acc.: 52.34%] [G loss: 0.789868]\n",
      "epoch:11 step:10318 [D loss: 0.645640, acc.: 61.72%] [G loss: 0.799438]\n",
      "epoch:11 step:10319 [D loss: 0.685244, acc.: 57.03%] [G loss: 0.815573]\n",
      "epoch:11 step:10320 [D loss: 0.622788, acc.: 65.62%] [G loss: 0.860817]\n",
      "epoch:11 step:10321 [D loss: 0.687705, acc.: 53.91%] [G loss: 0.883602]\n",
      "epoch:11 step:10322 [D loss: 0.651787, acc.: 62.50%] [G loss: 0.868100]\n",
      "epoch:11 step:10323 [D loss: 0.719178, acc.: 50.00%] [G loss: 0.869501]\n",
      "epoch:11 step:10324 [D loss: 0.706778, acc.: 48.44%] [G loss: 0.928465]\n",
      "epoch:11 step:10325 [D loss: 0.674849, acc.: 57.81%] [G loss: 0.898168]\n",
      "epoch:11 step:10326 [D loss: 0.645744, acc.: 57.81%] [G loss: 0.816724]\n",
      "epoch:11 step:10327 [D loss: 0.660899, acc.: 57.81%] [G loss: 0.801298]\n",
      "epoch:11 step:10328 [D loss: 0.670232, acc.: 60.94%] [G loss: 0.802349]\n",
      "epoch:11 step:10329 [D loss: 0.718008, acc.: 44.53%] [G loss: 0.851168]\n",
      "epoch:11 step:10330 [D loss: 0.646023, acc.: 64.06%] [G loss: 0.871939]\n",
      "epoch:11 step:10331 [D loss: 0.690508, acc.: 57.81%] [G loss: 0.859417]\n",
      "epoch:11 step:10332 [D loss: 0.667755, acc.: 62.50%] [G loss: 0.872213]\n",
      "epoch:11 step:10333 [D loss: 0.652921, acc.: 61.72%] [G loss: 0.861311]\n",
      "epoch:11 step:10334 [D loss: 0.602934, acc.: 75.78%] [G loss: 0.828799]\n",
      "epoch:11 step:10335 [D loss: 0.648162, acc.: 65.62%] [G loss: 0.797461]\n",
      "epoch:11 step:10336 [D loss: 0.692144, acc.: 57.81%] [G loss: 0.795151]\n",
      "epoch:11 step:10337 [D loss: 0.656295, acc.: 57.03%] [G loss: 0.802361]\n",
      "epoch:11 step:10338 [D loss: 0.672474, acc.: 57.03%] [G loss: 0.826253]\n",
      "epoch:11 step:10339 [D loss: 0.652386, acc.: 56.25%] [G loss: 0.855399]\n",
      "epoch:11 step:10340 [D loss: 0.692299, acc.: 53.12%] [G loss: 0.839647]\n",
      "epoch:11 step:10341 [D loss: 0.653814, acc.: 60.94%] [G loss: 0.877219]\n",
      "epoch:11 step:10342 [D loss: 0.667310, acc.: 55.47%] [G loss: 0.866899]\n",
      "epoch:11 step:10343 [D loss: 0.626274, acc.: 71.09%] [G loss: 0.867884]\n",
      "epoch:11 step:10344 [D loss: 0.665348, acc.: 57.81%] [G loss: 0.902714]\n",
      "epoch:11 step:10345 [D loss: 0.693901, acc.: 56.25%] [G loss: 0.868780]\n",
      "epoch:11 step:10346 [D loss: 0.698067, acc.: 52.34%] [G loss: 0.863184]\n",
      "epoch:11 step:10347 [D loss: 0.696678, acc.: 54.69%] [G loss: 0.889740]\n",
      "epoch:11 step:10348 [D loss: 0.695040, acc.: 53.91%] [G loss: 0.871803]\n",
      "epoch:11 step:10349 [D loss: 0.672275, acc.: 56.25%] [G loss: 0.826230]\n",
      "epoch:11 step:10350 [D loss: 0.682404, acc.: 57.81%] [G loss: 0.791895]\n",
      "epoch:11 step:10351 [D loss: 0.683998, acc.: 56.25%] [G loss: 0.799274]\n",
      "epoch:11 step:10352 [D loss: 0.680061, acc.: 58.59%] [G loss: 0.826451]\n",
      "epoch:11 step:10353 [D loss: 0.658722, acc.: 61.72%] [G loss: 0.858687]\n",
      "epoch:11 step:10354 [D loss: 0.681366, acc.: 53.91%] [G loss: 0.880604]\n",
      "epoch:11 step:10355 [D loss: 0.662736, acc.: 57.81%] [G loss: 0.827428]\n",
      "epoch:11 step:10356 [D loss: 0.694306, acc.: 50.78%] [G loss: 0.818163]\n",
      "epoch:11 step:10357 [D loss: 0.661711, acc.: 60.94%] [G loss: 0.868631]\n",
      "epoch:11 step:10358 [D loss: 0.640015, acc.: 65.62%] [G loss: 0.829688]\n",
      "epoch:11 step:10359 [D loss: 0.649968, acc.: 60.16%] [G loss: 0.859276]\n",
      "epoch:11 step:10360 [D loss: 0.650734, acc.: 60.16%] [G loss: 0.843108]\n",
      "epoch:11 step:10361 [D loss: 0.650664, acc.: 60.16%] [G loss: 0.852331]\n",
      "epoch:11 step:10362 [D loss: 0.683886, acc.: 57.03%] [G loss: 0.869201]\n",
      "epoch:11 step:10363 [D loss: 0.681280, acc.: 60.94%] [G loss: 0.850603]\n",
      "epoch:11 step:10364 [D loss: 0.674323, acc.: 56.25%] [G loss: 0.879416]\n",
      "epoch:11 step:10365 [D loss: 0.658544, acc.: 57.81%] [G loss: 0.911291]\n",
      "epoch:11 step:10366 [D loss: 0.639884, acc.: 61.72%] [G loss: 0.912615]\n",
      "epoch:11 step:10367 [D loss: 0.683831, acc.: 60.94%] [G loss: 0.868739]\n",
      "epoch:11 step:10368 [D loss: 0.650662, acc.: 63.28%] [G loss: 0.836767]\n",
      "epoch:11 step:10369 [D loss: 0.684782, acc.: 57.81%] [G loss: 0.828808]\n",
      "epoch:11 step:10370 [D loss: 0.671638, acc.: 54.69%] [G loss: 0.842657]\n",
      "epoch:11 step:10371 [D loss: 0.652340, acc.: 60.16%] [G loss: 0.884082]\n",
      "epoch:11 step:10372 [D loss: 0.661081, acc.: 55.47%] [G loss: 0.811284]\n",
      "epoch:11 step:10373 [D loss: 0.678019, acc.: 59.38%] [G loss: 0.830634]\n",
      "epoch:11 step:10374 [D loss: 0.662060, acc.: 59.38%] [G loss: 0.860360]\n",
      "epoch:11 step:10375 [D loss: 0.664139, acc.: 55.47%] [G loss: 0.855849]\n",
      "epoch:11 step:10376 [D loss: 0.669689, acc.: 56.25%] [G loss: 0.817268]\n",
      "epoch:11 step:10377 [D loss: 0.678305, acc.: 57.81%] [G loss: 0.843773]\n",
      "epoch:11 step:10378 [D loss: 0.658817, acc.: 59.38%] [G loss: 0.837282]\n",
      "epoch:11 step:10379 [D loss: 0.663399, acc.: 60.16%] [G loss: 0.830676]\n",
      "epoch:11 step:10380 [D loss: 0.616998, acc.: 68.75%] [G loss: 0.792039]\n",
      "epoch:11 step:10381 [D loss: 0.703120, acc.: 49.22%] [G loss: 0.846757]\n",
      "epoch:11 step:10382 [D loss: 0.653486, acc.: 58.59%] [G loss: 0.843279]\n",
      "epoch:11 step:10383 [D loss: 0.688010, acc.: 57.81%] [G loss: 0.867718]\n",
      "epoch:11 step:10384 [D loss: 0.688110, acc.: 51.56%] [G loss: 0.875906]\n",
      "epoch:11 step:10385 [D loss: 0.670473, acc.: 57.03%] [G loss: 0.853628]\n",
      "epoch:11 step:10386 [D loss: 0.662953, acc.: 56.25%] [G loss: 0.872646]\n",
      "epoch:11 step:10387 [D loss: 0.645804, acc.: 66.41%] [G loss: 0.864084]\n",
      "epoch:11 step:10388 [D loss: 0.712453, acc.: 44.53%] [G loss: 0.808689]\n",
      "epoch:11 step:10389 [D loss: 0.679017, acc.: 52.34%] [G loss: 0.867525]\n",
      "epoch:11 step:10390 [D loss: 0.656311, acc.: 62.50%] [G loss: 0.846306]\n",
      "epoch:11 step:10391 [D loss: 0.668833, acc.: 60.16%] [G loss: 0.830589]\n",
      "epoch:11 step:10392 [D loss: 0.658836, acc.: 53.91%] [G loss: 0.821335]\n",
      "epoch:11 step:10393 [D loss: 0.691268, acc.: 57.81%] [G loss: 0.894981]\n",
      "epoch:11 step:10394 [D loss: 0.668264, acc.: 57.03%] [G loss: 0.871271]\n",
      "epoch:11 step:10395 [D loss: 0.652697, acc.: 64.84%] [G loss: 0.874165]\n",
      "epoch:11 step:10396 [D loss: 0.638598, acc.: 65.62%] [G loss: 0.854217]\n",
      "epoch:11 step:10397 [D loss: 0.668839, acc.: 60.16%] [G loss: 0.876154]\n",
      "epoch:11 step:10398 [D loss: 0.675104, acc.: 57.81%] [G loss: 0.849019]\n",
      "epoch:11 step:10399 [D loss: 0.669265, acc.: 54.69%] [G loss: 0.840829]\n",
      "epoch:11 step:10400 [D loss: 0.674232, acc.: 56.25%] [G loss: 0.821708]\n",
      "##############\n",
      "[ 2.93658601  2.47318312  2.35316383  3.7525101   1.33306488 10.27426719\n",
      "  3.08758634  3.89086198  4.21660828  6.48301144]\n",
      "##########\n",
      "epoch:11 step:10401 [D loss: 0.650009, acc.: 67.97%] [G loss: 0.870489]\n",
      "epoch:11 step:10402 [D loss: 0.681818, acc.: 53.12%] [G loss: 0.882682]\n",
      "epoch:11 step:10403 [D loss: 0.686356, acc.: 52.34%] [G loss: 0.884759]\n",
      "epoch:11 step:10404 [D loss: 0.671502, acc.: 58.59%] [G loss: 0.860779]\n",
      "epoch:11 step:10405 [D loss: 0.648897, acc.: 59.38%] [G loss: 0.850037]\n",
      "epoch:11 step:10406 [D loss: 0.707981, acc.: 49.22%] [G loss: 0.833497]\n",
      "epoch:11 step:10407 [D loss: 0.659424, acc.: 62.50%] [G loss: 0.828653]\n",
      "epoch:11 step:10408 [D loss: 0.656545, acc.: 57.81%] [G loss: 0.855555]\n",
      "epoch:11 step:10409 [D loss: 0.711779, acc.: 47.66%] [G loss: 0.821875]\n",
      "epoch:11 step:10410 [D loss: 0.652732, acc.: 58.59%] [G loss: 0.829575]\n",
      "epoch:11 step:10411 [D loss: 0.659680, acc.: 63.28%] [G loss: 0.850932]\n",
      "epoch:11 step:10412 [D loss: 0.648205, acc.: 60.16%] [G loss: 0.845972]\n",
      "epoch:11 step:10413 [D loss: 0.656865, acc.: 57.03%] [G loss: 0.857359]\n",
      "epoch:11 step:10414 [D loss: 0.644068, acc.: 61.72%] [G loss: 0.851991]\n",
      "epoch:11 step:10415 [D loss: 0.682920, acc.: 61.72%] [G loss: 0.841294]\n",
      "epoch:11 step:10416 [D loss: 0.660678, acc.: 60.16%] [G loss: 0.870637]\n",
      "epoch:11 step:10417 [D loss: 0.679783, acc.: 58.59%] [G loss: 0.845120]\n",
      "epoch:11 step:10418 [D loss: 0.669233, acc.: 60.16%] [G loss: 0.818337]\n",
      "epoch:11 step:10419 [D loss: 0.689640, acc.: 56.25%] [G loss: 0.828108]\n",
      "epoch:11 step:10420 [D loss: 0.638230, acc.: 63.28%] [G loss: 0.855231]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10421 [D loss: 0.661182, acc.: 60.94%] [G loss: 0.836372]\n",
      "epoch:11 step:10422 [D loss: 0.695717, acc.: 50.78%] [G loss: 0.837958]\n",
      "epoch:11 step:10423 [D loss: 0.670898, acc.: 60.94%] [G loss: 0.887944]\n",
      "epoch:11 step:10424 [D loss: 0.693283, acc.: 50.00%] [G loss: 0.802218]\n",
      "epoch:11 step:10425 [D loss: 0.668185, acc.: 58.59%] [G loss: 0.837704]\n",
      "epoch:11 step:10426 [D loss: 0.649714, acc.: 60.94%] [G loss: 0.836785]\n",
      "epoch:11 step:10427 [D loss: 0.704197, acc.: 57.03%] [G loss: 0.825421]\n",
      "epoch:11 step:10428 [D loss: 0.653626, acc.: 60.94%] [G loss: 0.839059]\n",
      "epoch:11 step:10429 [D loss: 0.695579, acc.: 47.66%] [G loss: 0.878855]\n",
      "epoch:11 step:10430 [D loss: 0.650892, acc.: 63.28%] [G loss: 0.869685]\n",
      "epoch:11 step:10431 [D loss: 0.680961, acc.: 54.69%] [G loss: 0.852421]\n",
      "epoch:11 step:10432 [D loss: 0.672423, acc.: 58.59%] [G loss: 0.814546]\n",
      "epoch:11 step:10433 [D loss: 0.673604, acc.: 53.91%] [G loss: 0.834733]\n",
      "epoch:11 step:10434 [D loss: 0.639947, acc.: 64.84%] [G loss: 0.905155]\n",
      "epoch:11 step:10435 [D loss: 0.645984, acc.: 64.84%] [G loss: 0.843358]\n",
      "epoch:11 step:10436 [D loss: 0.694966, acc.: 54.69%] [G loss: 0.876498]\n",
      "epoch:11 step:10437 [D loss: 0.685026, acc.: 57.03%] [G loss: 0.887050]\n",
      "epoch:11 step:10438 [D loss: 0.663927, acc.: 55.47%] [G loss: 0.852721]\n",
      "epoch:11 step:10439 [D loss: 0.683961, acc.: 53.12%] [G loss: 0.868515]\n",
      "epoch:11 step:10440 [D loss: 0.671213, acc.: 64.06%] [G loss: 0.912715]\n",
      "epoch:11 step:10441 [D loss: 0.666162, acc.: 61.72%] [G loss: 0.892541]\n",
      "epoch:11 step:10442 [D loss: 0.681867, acc.: 57.81%] [G loss: 0.881175]\n",
      "epoch:11 step:10443 [D loss: 0.688645, acc.: 55.47%] [G loss: 0.889030]\n",
      "epoch:11 step:10444 [D loss: 0.653036, acc.: 60.16%] [G loss: 0.836658]\n",
      "epoch:11 step:10445 [D loss: 0.661773, acc.: 60.16%] [G loss: 0.854556]\n",
      "epoch:11 step:10446 [D loss: 0.676034, acc.: 60.16%] [G loss: 0.840621]\n",
      "epoch:11 step:10447 [D loss: 0.661058, acc.: 58.59%] [G loss: 0.806088]\n",
      "epoch:11 step:10448 [D loss: 0.679816, acc.: 57.03%] [G loss: 0.794418]\n",
      "epoch:11 step:10449 [D loss: 0.668658, acc.: 63.28%] [G loss: 0.853141]\n",
      "epoch:11 step:10450 [D loss: 0.682829, acc.: 57.03%] [G loss: 0.851058]\n",
      "epoch:11 step:10451 [D loss: 0.678394, acc.: 58.59%] [G loss: 0.864826]\n",
      "epoch:11 step:10452 [D loss: 0.665174, acc.: 56.25%] [G loss: 0.850747]\n",
      "epoch:11 step:10453 [D loss: 0.652805, acc.: 60.16%] [G loss: 0.872606]\n",
      "epoch:11 step:10454 [D loss: 0.695172, acc.: 53.12%] [G loss: 0.805961]\n",
      "epoch:11 step:10455 [D loss: 0.661760, acc.: 54.69%] [G loss: 0.878017]\n",
      "epoch:11 step:10456 [D loss: 0.673546, acc.: 58.59%] [G loss: 0.891342]\n",
      "epoch:11 step:10457 [D loss: 0.639016, acc.: 62.50%] [G loss: 0.838707]\n",
      "epoch:11 step:10458 [D loss: 0.655562, acc.: 60.16%] [G loss: 0.877015]\n",
      "epoch:11 step:10459 [D loss: 0.680990, acc.: 58.59%] [G loss: 0.858574]\n",
      "epoch:11 step:10460 [D loss: 0.625225, acc.: 67.19%] [G loss: 0.848177]\n",
      "epoch:11 step:10461 [D loss: 0.712715, acc.: 53.91%] [G loss: 0.886464]\n",
      "epoch:11 step:10462 [D loss: 0.664875, acc.: 59.38%] [G loss: 0.875160]\n",
      "epoch:11 step:10463 [D loss: 0.635273, acc.: 62.50%] [G loss: 0.869608]\n",
      "epoch:11 step:10464 [D loss: 0.677213, acc.: 55.47%] [G loss: 0.785016]\n",
      "epoch:11 step:10465 [D loss: 0.640311, acc.: 65.62%] [G loss: 0.833361]\n",
      "epoch:11 step:10466 [D loss: 0.645997, acc.: 64.06%] [G loss: 0.876507]\n",
      "epoch:11 step:10467 [D loss: 0.708787, acc.: 53.91%] [G loss: 0.874147]\n",
      "epoch:11 step:10468 [D loss: 0.673110, acc.: 58.59%] [G loss: 0.887610]\n",
      "epoch:11 step:10469 [D loss: 0.652696, acc.: 68.75%] [G loss: 0.807487]\n",
      "epoch:11 step:10470 [D loss: 0.684463, acc.: 53.91%] [G loss: 0.850756]\n",
      "epoch:11 step:10471 [D loss: 0.700819, acc.: 47.66%] [G loss: 0.799650]\n",
      "epoch:11 step:10472 [D loss: 0.672753, acc.: 57.81%] [G loss: 0.804050]\n",
      "epoch:11 step:10473 [D loss: 0.671277, acc.: 60.16%] [G loss: 0.817587]\n",
      "epoch:11 step:10474 [D loss: 0.649884, acc.: 64.06%] [G loss: 0.799342]\n",
      "epoch:11 step:10475 [D loss: 0.675333, acc.: 58.59%] [G loss: 0.824771]\n",
      "epoch:11 step:10476 [D loss: 0.707776, acc.: 47.66%] [G loss: 0.839599]\n",
      "epoch:11 step:10477 [D loss: 0.651309, acc.: 62.50%] [G loss: 0.898615]\n",
      "epoch:11 step:10478 [D loss: 0.682789, acc.: 58.59%] [G loss: 0.859937]\n",
      "epoch:11 step:10479 [D loss: 0.633584, acc.: 64.06%] [G loss: 0.892854]\n",
      "epoch:11 step:10480 [D loss: 0.675583, acc.: 57.81%] [G loss: 0.854143]\n",
      "epoch:11 step:10481 [D loss: 0.638898, acc.: 64.84%] [G loss: 0.855334]\n",
      "epoch:11 step:10482 [D loss: 0.683851, acc.: 53.91%] [G loss: 0.829474]\n",
      "epoch:11 step:10483 [D loss: 0.673952, acc.: 57.03%] [G loss: 0.937539]\n",
      "epoch:11 step:10484 [D loss: 0.640633, acc.: 57.03%] [G loss: 0.844534]\n",
      "epoch:11 step:10485 [D loss: 0.655506, acc.: 56.25%] [G loss: 0.803569]\n",
      "epoch:11 step:10486 [D loss: 0.640698, acc.: 67.97%] [G loss: 0.903973]\n",
      "epoch:11 step:10487 [D loss: 0.651706, acc.: 64.06%] [G loss: 0.884203]\n",
      "epoch:11 step:10488 [D loss: 0.688910, acc.: 57.81%] [G loss: 0.848575]\n",
      "epoch:11 step:10489 [D loss: 0.651516, acc.: 60.94%] [G loss: 0.829360]\n",
      "epoch:11 step:10490 [D loss: 0.675909, acc.: 59.38%] [G loss: 0.893028]\n",
      "epoch:11 step:10491 [D loss: 0.699223, acc.: 53.91%] [G loss: 0.923917]\n",
      "epoch:11 step:10492 [D loss: 0.659162, acc.: 58.59%] [G loss: 0.850219]\n",
      "epoch:11 step:10493 [D loss: 0.675582, acc.: 58.59%] [G loss: 0.870175]\n",
      "epoch:11 step:10494 [D loss: 0.667898, acc.: 64.06%] [G loss: 0.856315]\n",
      "epoch:11 step:10495 [D loss: 0.682129, acc.: 53.91%] [G loss: 0.862033]\n",
      "epoch:11 step:10496 [D loss: 0.694942, acc.: 57.81%] [G loss: 0.818891]\n",
      "epoch:11 step:10497 [D loss: 0.684318, acc.: 56.25%] [G loss: 0.836555]\n",
      "epoch:11 step:10498 [D loss: 0.642787, acc.: 62.50%] [G loss: 0.822223]\n",
      "epoch:11 step:10499 [D loss: 0.659410, acc.: 57.81%] [G loss: 0.862077]\n",
      "epoch:11 step:10500 [D loss: 0.641958, acc.: 65.62%] [G loss: 0.830269]\n",
      "epoch:11 step:10501 [D loss: 0.690712, acc.: 53.91%] [G loss: 0.829504]\n",
      "epoch:11 step:10502 [D loss: 0.659228, acc.: 61.72%] [G loss: 0.858413]\n",
      "epoch:11 step:10503 [D loss: 0.651136, acc.: 61.72%] [G loss: 0.831909]\n",
      "epoch:11 step:10504 [D loss: 0.661948, acc.: 55.47%] [G loss: 0.895362]\n",
      "epoch:11 step:10505 [D loss: 0.666137, acc.: 60.16%] [G loss: 0.868446]\n",
      "epoch:11 step:10506 [D loss: 0.616659, acc.: 69.53%] [G loss: 0.851626]\n",
      "epoch:11 step:10507 [D loss: 0.660243, acc.: 57.03%] [G loss: 0.931227]\n",
      "epoch:11 step:10508 [D loss: 0.646290, acc.: 66.41%] [G loss: 0.853065]\n",
      "epoch:11 step:10509 [D loss: 0.656369, acc.: 60.16%] [G loss: 0.895403]\n",
      "epoch:11 step:10510 [D loss: 0.670787, acc.: 53.12%] [G loss: 0.902224]\n",
      "epoch:11 step:10511 [D loss: 0.638962, acc.: 66.41%] [G loss: 0.948168]\n",
      "epoch:11 step:10512 [D loss: 0.699000, acc.: 51.56%] [G loss: 0.884816]\n",
      "epoch:11 step:10513 [D loss: 0.659775, acc.: 60.16%] [G loss: 0.868358]\n",
      "epoch:11 step:10514 [D loss: 0.661607, acc.: 64.06%] [G loss: 0.820721]\n",
      "epoch:11 step:10515 [D loss: 0.680420, acc.: 57.81%] [G loss: 0.753659]\n",
      "epoch:11 step:10516 [D loss: 0.677027, acc.: 56.25%] [G loss: 0.788001]\n",
      "epoch:11 step:10517 [D loss: 0.678167, acc.: 59.38%] [G loss: 0.827692]\n",
      "epoch:11 step:10518 [D loss: 0.675561, acc.: 53.91%] [G loss: 0.862124]\n",
      "epoch:11 step:10519 [D loss: 0.639461, acc.: 62.50%] [G loss: 0.848920]\n",
      "epoch:11 step:10520 [D loss: 0.689419, acc.: 54.69%] [G loss: 0.814528]\n",
      "epoch:11 step:10521 [D loss: 0.693177, acc.: 54.69%] [G loss: 0.884330]\n",
      "epoch:11 step:10522 [D loss: 0.680522, acc.: 54.69%] [G loss: 0.850375]\n",
      "epoch:11 step:10523 [D loss: 0.662232, acc.: 59.38%] [G loss: 0.814834]\n",
      "epoch:11 step:10524 [D loss: 0.625695, acc.: 64.84%] [G loss: 0.850661]\n",
      "epoch:11 step:10525 [D loss: 0.672849, acc.: 60.16%] [G loss: 0.863089]\n",
      "epoch:11 step:10526 [D loss: 0.666007, acc.: 60.16%] [G loss: 0.844837]\n",
      "epoch:11 step:10527 [D loss: 0.674591, acc.: 56.25%] [G loss: 0.849143]\n",
      "epoch:11 step:10528 [D loss: 0.658781, acc.: 62.50%] [G loss: 0.814663]\n",
      "epoch:11 step:10529 [D loss: 0.700710, acc.: 56.25%] [G loss: 0.866779]\n",
      "epoch:11 step:10530 [D loss: 0.676923, acc.: 59.38%] [G loss: 0.848172]\n",
      "epoch:11 step:10531 [D loss: 0.679409, acc.: 57.03%] [G loss: 0.864930]\n",
      "epoch:11 step:10532 [D loss: 0.662280, acc.: 62.50%] [G loss: 0.827772]\n",
      "epoch:11 step:10533 [D loss: 0.692157, acc.: 57.03%] [G loss: 0.855514]\n",
      "epoch:11 step:10534 [D loss: 0.682836, acc.: 53.91%] [G loss: 0.865509]\n",
      "epoch:11 step:10535 [D loss: 0.671089, acc.: 54.69%] [G loss: 0.840918]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10536 [D loss: 0.655819, acc.: 58.59%] [G loss: 0.846295]\n",
      "epoch:11 step:10537 [D loss: 0.658477, acc.: 59.38%] [G loss: 0.888234]\n",
      "epoch:11 step:10538 [D loss: 0.669782, acc.: 62.50%] [G loss: 0.857699]\n",
      "epoch:11 step:10539 [D loss: 0.684136, acc.: 50.00%] [G loss: 0.852032]\n",
      "epoch:11 step:10540 [D loss: 0.660504, acc.: 60.94%] [G loss: 0.928063]\n",
      "epoch:11 step:10541 [D loss: 0.673718, acc.: 53.91%] [G loss: 0.824900]\n",
      "epoch:11 step:10542 [D loss: 0.669803, acc.: 55.47%] [G loss: 0.835019]\n",
      "epoch:11 step:10543 [D loss: 0.677755, acc.: 55.47%] [G loss: 0.839159]\n",
      "epoch:11 step:10544 [D loss: 0.696718, acc.: 53.12%] [G loss: 0.811106]\n",
      "epoch:11 step:10545 [D loss: 0.676874, acc.: 57.03%] [G loss: 0.848121]\n",
      "epoch:11 step:10546 [D loss: 0.699676, acc.: 51.56%] [G loss: 0.800933]\n",
      "epoch:11 step:10547 [D loss: 0.678214, acc.: 58.59%] [G loss: 0.837837]\n",
      "epoch:11 step:10548 [D loss: 0.669661, acc.: 60.16%] [G loss: 0.849533]\n",
      "epoch:11 step:10549 [D loss: 0.667761, acc.: 60.16%] [G loss: 0.884331]\n",
      "epoch:11 step:10550 [D loss: 0.680915, acc.: 54.69%] [G loss: 0.841549]\n",
      "epoch:11 step:10551 [D loss: 0.666433, acc.: 62.50%] [G loss: 0.869454]\n",
      "epoch:11 step:10552 [D loss: 0.650094, acc.: 61.72%] [G loss: 0.824302]\n",
      "epoch:11 step:10553 [D loss: 0.680030, acc.: 60.16%] [G loss: 0.777672]\n",
      "epoch:11 step:10554 [D loss: 0.678196, acc.: 61.72%] [G loss: 0.842153]\n",
      "epoch:11 step:10555 [D loss: 0.641937, acc.: 62.50%] [G loss: 0.876758]\n",
      "epoch:11 step:10556 [D loss: 0.670074, acc.: 60.16%] [G loss: 0.867853]\n",
      "epoch:11 step:10557 [D loss: 0.650777, acc.: 63.28%] [G loss: 0.874440]\n",
      "epoch:11 step:10558 [D loss: 0.674004, acc.: 56.25%] [G loss: 0.864879]\n",
      "epoch:11 step:10559 [D loss: 0.660062, acc.: 60.16%] [G loss: 0.819615]\n",
      "epoch:11 step:10560 [D loss: 0.693725, acc.: 56.25%] [G loss: 0.854390]\n",
      "epoch:11 step:10561 [D loss: 0.706107, acc.: 55.47%] [G loss: 0.861909]\n",
      "epoch:11 step:10562 [D loss: 0.658035, acc.: 58.59%] [G loss: 0.841999]\n",
      "epoch:11 step:10563 [D loss: 0.627649, acc.: 64.84%] [G loss: 0.889984]\n",
      "epoch:11 step:10564 [D loss: 0.692604, acc.: 53.91%] [G loss: 0.872918]\n",
      "epoch:11 step:10565 [D loss: 0.661772, acc.: 58.59%] [G loss: 0.844899]\n",
      "epoch:11 step:10566 [D loss: 0.663771, acc.: 53.91%] [G loss: 0.828178]\n",
      "epoch:11 step:10567 [D loss: 0.647863, acc.: 55.47%] [G loss: 0.861864]\n",
      "epoch:11 step:10568 [D loss: 0.666272, acc.: 57.03%] [G loss: 0.915102]\n",
      "epoch:11 step:10569 [D loss: 0.713719, acc.: 49.22%] [G loss: 0.858995]\n",
      "epoch:11 step:10570 [D loss: 0.658091, acc.: 61.72%] [G loss: 0.899325]\n",
      "epoch:11 step:10571 [D loss: 0.671403, acc.: 52.34%] [G loss: 0.870762]\n",
      "epoch:11 step:10572 [D loss: 0.640136, acc.: 64.84%] [G loss: 0.862150]\n",
      "epoch:11 step:10573 [D loss: 0.638491, acc.: 62.50%] [G loss: 0.924804]\n",
      "epoch:11 step:10574 [D loss: 0.655799, acc.: 61.72%] [G loss: 0.901505]\n",
      "epoch:11 step:10575 [D loss: 0.666064, acc.: 57.81%] [G loss: 0.956989]\n",
      "epoch:11 step:10576 [D loss: 0.681823, acc.: 57.81%] [G loss: 0.884379]\n",
      "epoch:11 step:10577 [D loss: 0.668144, acc.: 57.81%] [G loss: 0.814804]\n",
      "epoch:11 step:10578 [D loss: 0.668031, acc.: 56.25%] [G loss: 0.879145]\n",
      "epoch:11 step:10579 [D loss: 0.649574, acc.: 64.06%] [G loss: 0.839812]\n",
      "epoch:11 step:10580 [D loss: 0.696358, acc.: 57.03%] [G loss: 0.866672]\n",
      "epoch:11 step:10581 [D loss: 0.692246, acc.: 54.69%] [G loss: 0.903851]\n",
      "epoch:11 step:10582 [D loss: 0.688796, acc.: 54.69%] [G loss: 0.860776]\n",
      "epoch:11 step:10583 [D loss: 0.665031, acc.: 57.03%] [G loss: 0.842367]\n",
      "epoch:11 step:10584 [D loss: 0.690496, acc.: 49.22%] [G loss: 0.836085]\n",
      "epoch:11 step:10585 [D loss: 0.705956, acc.: 49.22%] [G loss: 0.825616]\n",
      "epoch:11 step:10586 [D loss: 0.691831, acc.: 53.91%] [G loss: 0.834973]\n",
      "epoch:11 step:10587 [D loss: 0.687940, acc.: 52.34%] [G loss: 0.835639]\n",
      "epoch:11 step:10588 [D loss: 0.653121, acc.: 64.06%] [G loss: 0.823474]\n",
      "epoch:11 step:10589 [D loss: 0.685059, acc.: 58.59%] [G loss: 0.852100]\n",
      "epoch:11 step:10590 [D loss: 0.617434, acc.: 68.75%] [G loss: 0.855260]\n",
      "epoch:11 step:10591 [D loss: 0.643520, acc.: 64.06%] [G loss: 0.810272]\n",
      "epoch:11 step:10592 [D loss: 0.671323, acc.: 60.94%] [G loss: 0.838122]\n",
      "epoch:11 step:10593 [D loss: 0.654242, acc.: 60.16%] [G loss: 0.867833]\n",
      "epoch:11 step:10594 [D loss: 0.683500, acc.: 56.25%] [G loss: 0.828356]\n",
      "epoch:11 step:10595 [D loss: 0.661784, acc.: 57.03%] [G loss: 0.833415]\n",
      "epoch:11 step:10596 [D loss: 0.674658, acc.: 53.12%] [G loss: 0.837757]\n",
      "epoch:11 step:10597 [D loss: 0.646227, acc.: 63.28%] [G loss: 0.845681]\n",
      "epoch:11 step:10598 [D loss: 0.682438, acc.: 56.25%] [G loss: 0.849747]\n",
      "epoch:11 step:10599 [D loss: 0.702905, acc.: 54.69%] [G loss: 0.858852]\n",
      "epoch:11 step:10600 [D loss: 0.641161, acc.: 64.84%] [G loss: 0.852710]\n",
      "##############\n",
      "[3.16838246 2.40137455 2.43790421 3.67146873 0.94490749 7.94025152\n",
      " 3.16858123 3.58481611 4.34115107 7.14868929]\n",
      "##########\n",
      "epoch:11 step:10601 [D loss: 0.675771, acc.: 55.47%] [G loss: 0.901559]\n",
      "epoch:11 step:10602 [D loss: 0.693780, acc.: 49.22%] [G loss: 0.842372]\n",
      "epoch:11 step:10603 [D loss: 0.704262, acc.: 48.44%] [G loss: 0.848677]\n",
      "epoch:11 step:10604 [D loss: 0.661821, acc.: 60.94%] [G loss: 0.876335]\n",
      "epoch:11 step:10605 [D loss: 0.663857, acc.: 58.59%] [G loss: 0.852649]\n",
      "epoch:11 step:10606 [D loss: 0.676346, acc.: 57.81%] [G loss: 0.824489]\n",
      "epoch:11 step:10607 [D loss: 0.647230, acc.: 60.94%] [G loss: 0.844131]\n",
      "epoch:11 step:10608 [D loss: 0.676717, acc.: 58.59%] [G loss: 0.839769]\n",
      "epoch:11 step:10609 [D loss: 0.642700, acc.: 65.62%] [G loss: 0.858277]\n",
      "epoch:11 step:10610 [D loss: 0.672176, acc.: 60.16%] [G loss: 0.823360]\n",
      "epoch:11 step:10611 [D loss: 0.629028, acc.: 64.84%] [G loss: 0.906504]\n",
      "epoch:11 step:10612 [D loss: 0.670815, acc.: 54.69%] [G loss: 0.861316]\n",
      "epoch:11 step:10613 [D loss: 0.667980, acc.: 60.94%] [G loss: 0.857042]\n",
      "epoch:11 step:10614 [D loss: 0.695321, acc.: 50.00%] [G loss: 0.825997]\n",
      "epoch:11 step:10615 [D loss: 0.681148, acc.: 57.81%] [G loss: 0.837744]\n",
      "epoch:11 step:10616 [D loss: 0.645175, acc.: 63.28%] [G loss: 0.867736]\n",
      "epoch:11 step:10617 [D loss: 0.671848, acc.: 54.69%] [G loss: 0.864817]\n",
      "epoch:11 step:10618 [D loss: 0.660970, acc.: 60.16%] [G loss: 0.886533]\n",
      "epoch:11 step:10619 [D loss: 0.676446, acc.: 55.47%] [G loss: 0.869554]\n",
      "epoch:11 step:10620 [D loss: 0.666587, acc.: 57.81%] [G loss: 0.841104]\n",
      "epoch:11 step:10621 [D loss: 0.645441, acc.: 61.72%] [G loss: 0.862910]\n",
      "epoch:11 step:10622 [D loss: 0.638009, acc.: 67.97%] [G loss: 0.854558]\n",
      "epoch:11 step:10623 [D loss: 0.670138, acc.: 60.94%] [G loss: 0.878386]\n",
      "epoch:11 step:10624 [D loss: 0.645688, acc.: 68.75%] [G loss: 0.845875]\n",
      "epoch:11 step:10625 [D loss: 0.683225, acc.: 57.81%] [G loss: 0.815184]\n",
      "epoch:11 step:10626 [D loss: 0.668833, acc.: 57.03%] [G loss: 0.842620]\n",
      "epoch:11 step:10627 [D loss: 0.673099, acc.: 57.03%] [G loss: 0.842300]\n",
      "epoch:11 step:10628 [D loss: 0.648485, acc.: 64.84%] [G loss: 0.824918]\n",
      "epoch:11 step:10629 [D loss: 0.649074, acc.: 60.16%] [G loss: 0.866117]\n",
      "epoch:11 step:10630 [D loss: 0.654705, acc.: 58.59%] [G loss: 0.842571]\n",
      "epoch:11 step:10631 [D loss: 0.688583, acc.: 54.69%] [G loss: 0.851622]\n",
      "epoch:11 step:10632 [D loss: 0.673407, acc.: 60.94%] [G loss: 0.885042]\n",
      "epoch:11 step:10633 [D loss: 0.695314, acc.: 53.91%] [G loss: 0.850971]\n",
      "epoch:11 step:10634 [D loss: 0.631808, acc.: 71.09%] [G loss: 0.855614]\n",
      "epoch:11 step:10635 [D loss: 0.654694, acc.: 56.25%] [G loss: 0.896089]\n",
      "epoch:11 step:10636 [D loss: 0.667201, acc.: 56.25%] [G loss: 0.842370]\n",
      "epoch:11 step:10637 [D loss: 0.658487, acc.: 63.28%] [G loss: 0.855513]\n",
      "epoch:11 step:10638 [D loss: 0.681441, acc.: 52.34%] [G loss: 0.880900]\n",
      "epoch:11 step:10639 [D loss: 0.660140, acc.: 58.59%] [G loss: 0.862542]\n",
      "epoch:11 step:10640 [D loss: 0.672442, acc.: 54.69%] [G loss: 0.839403]\n",
      "epoch:11 step:10641 [D loss: 0.659967, acc.: 62.50%] [G loss: 0.880160]\n",
      "epoch:11 step:10642 [D loss: 0.696361, acc.: 53.91%] [G loss: 0.850701]\n",
      "epoch:11 step:10643 [D loss: 0.649334, acc.: 63.28%] [G loss: 0.822357]\n",
      "epoch:11 step:10644 [D loss: 0.676448, acc.: 58.59%] [G loss: 0.881623]\n",
      "epoch:11 step:10645 [D loss: 0.678382, acc.: 57.81%] [G loss: 0.880618]\n",
      "epoch:11 step:10646 [D loss: 0.657233, acc.: 58.59%] [G loss: 0.881630]\n",
      "epoch:11 step:10647 [D loss: 0.656282, acc.: 60.94%] [G loss: 0.906103]\n",
      "epoch:11 step:10648 [D loss: 0.649655, acc.: 63.28%] [G loss: 0.884366]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10649 [D loss: 0.649390, acc.: 64.84%] [G loss: 0.888422]\n",
      "epoch:11 step:10650 [D loss: 0.693456, acc.: 48.44%] [G loss: 0.860639]\n",
      "epoch:11 step:10651 [D loss: 0.657092, acc.: 59.38%] [G loss: 0.858162]\n",
      "epoch:11 step:10652 [D loss: 0.683906, acc.: 60.94%] [G loss: 0.914227]\n",
      "epoch:11 step:10653 [D loss: 0.686443, acc.: 47.66%] [G loss: 0.780753]\n",
      "epoch:11 step:10654 [D loss: 0.640650, acc.: 64.84%] [G loss: 0.858897]\n",
      "epoch:11 step:10655 [D loss: 0.675875, acc.: 59.38%] [G loss: 0.860592]\n",
      "epoch:11 step:10656 [D loss: 0.641423, acc.: 66.41%] [G loss: 0.854132]\n",
      "epoch:11 step:10657 [D loss: 0.654050, acc.: 58.59%] [G loss: 0.888259]\n",
      "epoch:11 step:10658 [D loss: 0.668901, acc.: 54.69%] [G loss: 0.854255]\n",
      "epoch:11 step:10659 [D loss: 0.688359, acc.: 51.56%] [G loss: 0.811358]\n",
      "epoch:11 step:10660 [D loss: 0.681963, acc.: 53.91%] [G loss: 0.839260]\n",
      "epoch:11 step:10661 [D loss: 0.696371, acc.: 52.34%] [G loss: 0.802412]\n",
      "epoch:11 step:10662 [D loss: 0.667332, acc.: 57.81%] [G loss: 0.843801]\n",
      "epoch:11 step:10663 [D loss: 0.676130, acc.: 57.81%] [G loss: 0.820893]\n",
      "epoch:11 step:10664 [D loss: 0.681110, acc.: 57.03%] [G loss: 0.873680]\n",
      "epoch:11 step:10665 [D loss: 0.648572, acc.: 64.84%] [G loss: 0.861023]\n",
      "epoch:11 step:10666 [D loss: 0.696362, acc.: 54.69%] [G loss: 0.840243]\n",
      "epoch:11 step:10667 [D loss: 0.662125, acc.: 60.94%] [G loss: 0.880959]\n",
      "epoch:11 step:10668 [D loss: 0.679956, acc.: 62.50%] [G loss: 0.934739]\n",
      "epoch:11 step:10669 [D loss: 0.648499, acc.: 67.19%] [G loss: 0.880980]\n",
      "epoch:11 step:10670 [D loss: 0.672054, acc.: 50.78%] [G loss: 0.834204]\n",
      "epoch:11 step:10671 [D loss: 0.708975, acc.: 45.31%] [G loss: 0.872633]\n",
      "epoch:11 step:10672 [D loss: 0.703456, acc.: 50.00%] [G loss: 0.866008]\n",
      "epoch:11 step:10673 [D loss: 0.692783, acc.: 51.56%] [G loss: 0.827523]\n",
      "epoch:11 step:10674 [D loss: 0.699287, acc.: 46.88%] [G loss: 0.826296]\n",
      "epoch:11 step:10675 [D loss: 0.671398, acc.: 64.06%] [G loss: 0.826316]\n",
      "epoch:11 step:10676 [D loss: 0.690774, acc.: 53.12%] [G loss: 0.812935]\n",
      "epoch:11 step:10677 [D loss: 0.663454, acc.: 56.25%] [G loss: 0.820001]\n",
      "epoch:11 step:10678 [D loss: 0.689109, acc.: 53.12%] [G loss: 0.858927]\n",
      "epoch:11 step:10679 [D loss: 0.655318, acc.: 57.81%] [G loss: 0.837316]\n",
      "epoch:11 step:10680 [D loss: 0.645378, acc.: 58.59%] [G loss: 0.855482]\n",
      "epoch:11 step:10681 [D loss: 0.700651, acc.: 50.78%] [G loss: 0.899860]\n",
      "epoch:11 step:10682 [D loss: 0.669566, acc.: 60.16%] [G loss: 0.858550]\n",
      "epoch:11 step:10683 [D loss: 0.707944, acc.: 54.69%] [G loss: 0.829324]\n",
      "epoch:11 step:10684 [D loss: 0.695867, acc.: 54.69%] [G loss: 0.819618]\n",
      "epoch:11 step:10685 [D loss: 0.652648, acc.: 63.28%] [G loss: 0.858640]\n",
      "epoch:11 step:10686 [D loss: 0.629943, acc.: 67.97%] [G loss: 0.824098]\n",
      "epoch:11 step:10687 [D loss: 0.646009, acc.: 65.62%] [G loss: 0.803218]\n",
      "epoch:11 step:10688 [D loss: 0.659909, acc.: 57.81%] [G loss: 0.833635]\n",
      "epoch:11 step:10689 [D loss: 0.671278, acc.: 61.72%] [G loss: 0.883121]\n",
      "epoch:11 step:10690 [D loss: 0.672207, acc.: 61.72%] [G loss: 0.866482]\n",
      "epoch:11 step:10691 [D loss: 0.664490, acc.: 57.03%] [G loss: 0.916881]\n",
      "epoch:11 step:10692 [D loss: 0.682983, acc.: 64.84%] [G loss: 0.833282]\n",
      "epoch:11 step:10693 [D loss: 0.661164, acc.: 56.25%] [G loss: 0.818632]\n",
      "epoch:11 step:10694 [D loss: 0.668606, acc.: 58.59%] [G loss: 0.772868]\n",
      "epoch:11 step:10695 [D loss: 0.728523, acc.: 46.09%] [G loss: 0.798312]\n",
      "epoch:11 step:10696 [D loss: 0.647381, acc.: 59.38%] [G loss: 0.830094]\n",
      "epoch:11 step:10697 [D loss: 0.680615, acc.: 59.38%] [G loss: 0.845911]\n",
      "epoch:11 step:10698 [D loss: 0.667145, acc.: 56.25%] [G loss: 0.863826]\n",
      "epoch:11 step:10699 [D loss: 0.664670, acc.: 59.38%] [G loss: 0.904637]\n",
      "epoch:11 step:10700 [D loss: 0.702194, acc.: 53.12%] [G loss: 0.873168]\n",
      "epoch:11 step:10701 [D loss: 0.670578, acc.: 57.03%] [G loss: 0.878833]\n",
      "epoch:11 step:10702 [D loss: 0.688879, acc.: 57.03%] [G loss: 0.794427]\n",
      "epoch:11 step:10703 [D loss: 0.680210, acc.: 58.59%] [G loss: 0.843805]\n",
      "epoch:11 step:10704 [D loss: 0.670729, acc.: 59.38%] [G loss: 0.819900]\n",
      "epoch:11 step:10705 [D loss: 0.687263, acc.: 53.12%] [G loss: 0.824295]\n",
      "epoch:11 step:10706 [D loss: 0.642456, acc.: 62.50%] [G loss: 0.845934]\n",
      "epoch:11 step:10707 [D loss: 0.652798, acc.: 64.06%] [G loss: 0.883855]\n",
      "epoch:11 step:10708 [D loss: 0.658062, acc.: 61.72%] [G loss: 0.869048]\n",
      "epoch:11 step:10709 [D loss: 0.627101, acc.: 66.41%] [G loss: 0.852193]\n",
      "epoch:11 step:10710 [D loss: 0.660668, acc.: 58.59%] [G loss: 0.885528]\n",
      "epoch:11 step:10711 [D loss: 0.668148, acc.: 54.69%] [G loss: 0.850678]\n",
      "epoch:11 step:10712 [D loss: 0.634472, acc.: 64.06%] [G loss: 0.854779]\n",
      "epoch:11 step:10713 [D loss: 0.640965, acc.: 59.38%] [G loss: 0.823010]\n",
      "epoch:11 step:10714 [D loss: 0.703888, acc.: 53.91%] [G loss: 0.846431]\n",
      "epoch:11 step:10715 [D loss: 0.672092, acc.: 57.03%] [G loss: 0.827223]\n",
      "epoch:11 step:10716 [D loss: 0.692199, acc.: 53.91%] [G loss: 0.837207]\n",
      "epoch:11 step:10717 [D loss: 0.684243, acc.: 55.47%] [G loss: 0.859666]\n",
      "epoch:11 step:10718 [D loss: 0.660148, acc.: 57.81%] [G loss: 0.832244]\n",
      "epoch:11 step:10719 [D loss: 0.672405, acc.: 57.03%] [G loss: 0.884194]\n",
      "epoch:11 step:10720 [D loss: 0.695023, acc.: 55.47%] [G loss: 0.856210]\n",
      "epoch:11 step:10721 [D loss: 0.676452, acc.: 55.47%] [G loss: 0.872684]\n",
      "epoch:11 step:10722 [D loss: 0.650034, acc.: 63.28%] [G loss: 0.846536]\n",
      "epoch:11 step:10723 [D loss: 0.634726, acc.: 67.97%] [G loss: 0.893078]\n",
      "epoch:11 step:10724 [D loss: 0.652448, acc.: 61.72%] [G loss: 0.850194]\n",
      "epoch:11 step:10725 [D loss: 0.709023, acc.: 50.78%] [G loss: 0.839538]\n",
      "epoch:11 step:10726 [D loss: 0.673861, acc.: 57.03%] [G loss: 0.838072]\n",
      "epoch:11 step:10727 [D loss: 0.643723, acc.: 63.28%] [G loss: 0.862793]\n",
      "epoch:11 step:10728 [D loss: 0.633942, acc.: 67.19%] [G loss: 0.828692]\n",
      "epoch:11 step:10729 [D loss: 0.716276, acc.: 53.12%] [G loss: 0.859399]\n",
      "epoch:11 step:10730 [D loss: 0.635725, acc.: 64.84%] [G loss: 0.864645]\n",
      "epoch:11 step:10731 [D loss: 0.654533, acc.: 63.28%] [G loss: 0.889217]\n",
      "epoch:11 step:10732 [D loss: 0.700635, acc.: 53.91%] [G loss: 0.862823]\n",
      "epoch:11 step:10733 [D loss: 0.654985, acc.: 63.28%] [G loss: 0.887800]\n",
      "epoch:11 step:10734 [D loss: 0.689486, acc.: 57.03%] [G loss: 0.857745]\n",
      "epoch:11 step:10735 [D loss: 0.681157, acc.: 59.38%] [G loss: 0.875040]\n",
      "epoch:11 step:10736 [D loss: 0.676343, acc.: 62.50%] [G loss: 0.891217]\n",
      "epoch:11 step:10737 [D loss: 0.653908, acc.: 57.03%] [G loss: 0.879149]\n",
      "epoch:11 step:10738 [D loss: 0.656078, acc.: 60.16%] [G loss: 0.834925]\n",
      "epoch:11 step:10739 [D loss: 0.657403, acc.: 61.72%] [G loss: 0.842913]\n",
      "epoch:11 step:10740 [D loss: 0.644984, acc.: 62.50%] [G loss: 0.786689]\n",
      "epoch:11 step:10741 [D loss: 0.677545, acc.: 58.59%] [G loss: 0.820219]\n",
      "epoch:11 step:10742 [D loss: 0.657335, acc.: 61.72%] [G loss: 0.850895]\n",
      "epoch:11 step:10743 [D loss: 0.649094, acc.: 61.72%] [G loss: 0.833024]\n",
      "epoch:11 step:10744 [D loss: 0.652013, acc.: 58.59%] [G loss: 0.827368]\n",
      "epoch:11 step:10745 [D loss: 0.648563, acc.: 64.06%] [G loss: 0.862579]\n",
      "epoch:11 step:10746 [D loss: 0.678029, acc.: 59.38%] [G loss: 0.895231]\n",
      "epoch:11 step:10747 [D loss: 0.695383, acc.: 53.91%] [G loss: 0.879200]\n",
      "epoch:11 step:10748 [D loss: 0.678546, acc.: 56.25%] [G loss: 0.817557]\n",
      "epoch:11 step:10749 [D loss: 0.670224, acc.: 62.50%] [G loss: 0.874732]\n",
      "epoch:11 step:10750 [D loss: 0.665575, acc.: 60.16%] [G loss: 0.812248]\n",
      "epoch:11 step:10751 [D loss: 0.663085, acc.: 56.25%] [G loss: 0.864190]\n",
      "epoch:11 step:10752 [D loss: 0.647068, acc.: 62.50%] [G loss: 0.879570]\n",
      "epoch:11 step:10753 [D loss: 0.672522, acc.: 53.12%] [G loss: 0.815576]\n",
      "epoch:11 step:10754 [D loss: 0.678712, acc.: 56.25%] [G loss: 0.853923]\n",
      "epoch:11 step:10755 [D loss: 0.688246, acc.: 58.59%] [G loss: 0.819516]\n",
      "epoch:11 step:10756 [D loss: 0.657892, acc.: 58.59%] [G loss: 0.881699]\n",
      "epoch:11 step:10757 [D loss: 0.648318, acc.: 61.72%] [G loss: 0.836712]\n",
      "epoch:11 step:10758 [D loss: 0.652354, acc.: 64.84%] [G loss: 0.859575]\n",
      "epoch:11 step:10759 [D loss: 0.691456, acc.: 51.56%] [G loss: 0.841218]\n",
      "epoch:11 step:10760 [D loss: 0.659219, acc.: 62.50%] [G loss: 0.896818]\n",
      "epoch:11 step:10761 [D loss: 0.687724, acc.: 53.12%] [G loss: 0.854074]\n",
      "epoch:11 step:10762 [D loss: 0.679273, acc.: 59.38%] [G loss: 0.848209]\n",
      "epoch:11 step:10763 [D loss: 0.668820, acc.: 60.16%] [G loss: 0.812260]\n",
      "epoch:11 step:10764 [D loss: 0.704181, acc.: 43.75%] [G loss: 0.836298]\n",
      "epoch:11 step:10765 [D loss: 0.684979, acc.: 54.69%] [G loss: 0.819734]\n",
      "epoch:11 step:10766 [D loss: 0.625442, acc.: 67.19%] [G loss: 0.838604]\n",
      "epoch:11 step:10767 [D loss: 0.667732, acc.: 58.59%] [G loss: 0.864488]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10768 [D loss: 0.682148, acc.: 60.16%] [G loss: 0.866656]\n",
      "epoch:11 step:10769 [D loss: 0.694152, acc.: 54.69%] [G loss: 0.833497]\n",
      "epoch:11 step:10770 [D loss: 0.673457, acc.: 55.47%] [G loss: 0.855742]\n",
      "epoch:11 step:10771 [D loss: 0.672392, acc.: 57.03%] [G loss: 0.829786]\n",
      "epoch:11 step:10772 [D loss: 0.702072, acc.: 53.91%] [G loss: 0.778221]\n",
      "epoch:11 step:10773 [D loss: 0.650008, acc.: 61.72%] [G loss: 0.830020]\n",
      "epoch:11 step:10774 [D loss: 0.638265, acc.: 64.84%] [G loss: 0.833696]\n",
      "epoch:11 step:10775 [D loss: 0.665734, acc.: 61.72%] [G loss: 0.804334]\n",
      "epoch:11 step:10776 [D loss: 0.672576, acc.: 58.59%] [G loss: 0.900745]\n",
      "epoch:11 step:10777 [D loss: 0.696741, acc.: 57.03%] [G loss: 0.819456]\n",
      "epoch:11 step:10778 [D loss: 0.660329, acc.: 61.72%] [G loss: 0.871986]\n",
      "epoch:11 step:10779 [D loss: 0.626145, acc.: 64.84%] [G loss: 0.853217]\n",
      "epoch:11 step:10780 [D loss: 0.684148, acc.: 51.56%] [G loss: 0.895614]\n",
      "epoch:11 step:10781 [D loss: 0.651987, acc.: 62.50%] [G loss: 0.841785]\n",
      "epoch:11 step:10782 [D loss: 0.647378, acc.: 60.94%] [G loss: 0.866343]\n",
      "epoch:11 step:10783 [D loss: 0.672200, acc.: 60.94%] [G loss: 0.890863]\n",
      "epoch:11 step:10784 [D loss: 0.667344, acc.: 59.38%] [G loss: 0.875414]\n",
      "epoch:11 step:10785 [D loss: 0.669624, acc.: 54.69%] [G loss: 0.900650]\n",
      "epoch:11 step:10786 [D loss: 0.670481, acc.: 58.59%] [G loss: 0.794146]\n",
      "epoch:11 step:10787 [D loss: 0.660085, acc.: 59.38%] [G loss: 0.855155]\n",
      "epoch:11 step:10788 [D loss: 0.659861, acc.: 55.47%] [G loss: 0.838118]\n",
      "epoch:11 step:10789 [D loss: 0.628634, acc.: 62.50%] [G loss: 0.853015]\n",
      "epoch:11 step:10790 [D loss: 0.681060, acc.: 52.34%] [G loss: 0.871091]\n",
      "epoch:11 step:10791 [D loss: 0.663575, acc.: 64.06%] [G loss: 0.841998]\n",
      "epoch:11 step:10792 [D loss: 0.646032, acc.: 64.06%] [G loss: 0.829917]\n",
      "epoch:11 step:10793 [D loss: 0.682571, acc.: 53.91%] [G loss: 0.886688]\n",
      "epoch:11 step:10794 [D loss: 0.676287, acc.: 57.03%] [G loss: 0.822037]\n",
      "epoch:11 step:10795 [D loss: 0.641321, acc.: 65.62%] [G loss: 0.871834]\n",
      "epoch:11 step:10796 [D loss: 0.654188, acc.: 60.16%] [G loss: 0.829635]\n",
      "epoch:11 step:10797 [D loss: 0.656032, acc.: 64.84%] [G loss: 0.820098]\n",
      "epoch:11 step:10798 [D loss: 0.649268, acc.: 64.06%] [G loss: 0.830312]\n",
      "epoch:11 step:10799 [D loss: 0.618363, acc.: 72.66%] [G loss: 0.831714]\n",
      "epoch:11 step:10800 [D loss: 0.679489, acc.: 60.16%] [G loss: 0.821069]\n",
      "##############\n",
      "[3.07775699 2.34143813 2.7768027  4.15086867 1.43068184 7.46901829\n",
      " 2.94485179 3.06657629 4.24755668 7.14868929]\n",
      "##########\n",
      "epoch:11 step:10801 [D loss: 0.629373, acc.: 60.94%] [G loss: 0.854299]\n",
      "epoch:11 step:10802 [D loss: 0.660267, acc.: 55.47%] [G loss: 0.859845]\n",
      "epoch:11 step:10803 [D loss: 0.665407, acc.: 60.16%] [G loss: 0.868235]\n",
      "epoch:11 step:10804 [D loss: 0.639488, acc.: 60.94%] [G loss: 0.874263]\n",
      "epoch:11 step:10805 [D loss: 0.689644, acc.: 56.25%] [G loss: 0.822310]\n",
      "epoch:11 step:10806 [D loss: 0.669313, acc.: 59.38%] [G loss: 0.918756]\n",
      "epoch:11 step:10807 [D loss: 0.673995, acc.: 57.03%] [G loss: 0.878284]\n",
      "epoch:11 step:10808 [D loss: 0.672436, acc.: 57.81%] [G loss: 0.911197]\n",
      "epoch:11 step:10809 [D loss: 0.672607, acc.: 59.38%] [G loss: 0.818516]\n",
      "epoch:11 step:10810 [D loss: 0.664851, acc.: 59.38%] [G loss: 0.835344]\n",
      "epoch:11 step:10811 [D loss: 0.664453, acc.: 58.59%] [G loss: 0.851909]\n",
      "epoch:11 step:10812 [D loss: 0.653287, acc.: 62.50%] [G loss: 0.843076]\n",
      "epoch:11 step:10813 [D loss: 0.661918, acc.: 62.50%] [G loss: 0.853668]\n",
      "epoch:11 step:10814 [D loss: 0.681157, acc.: 60.94%] [G loss: 0.832503]\n",
      "epoch:11 step:10815 [D loss: 0.650646, acc.: 62.50%] [G loss: 0.908739]\n",
      "epoch:11 step:10816 [D loss: 0.652490, acc.: 63.28%] [G loss: 0.915876]\n",
      "epoch:11 step:10817 [D loss: 0.629413, acc.: 65.62%] [G loss: 0.900982]\n",
      "epoch:11 step:10818 [D loss: 0.636178, acc.: 67.97%] [G loss: 0.836532]\n",
      "epoch:11 step:10819 [D loss: 0.657458, acc.: 57.03%] [G loss: 0.839842]\n",
      "epoch:11 step:10820 [D loss: 0.675466, acc.: 55.47%] [G loss: 0.844792]\n",
      "epoch:11 step:10821 [D loss: 0.705228, acc.: 55.47%] [G loss: 0.841244]\n",
      "epoch:11 step:10822 [D loss: 0.647788, acc.: 63.28%] [G loss: 0.841991]\n",
      "epoch:11 step:10823 [D loss: 0.648297, acc.: 63.28%] [G loss: 0.874977]\n",
      "epoch:11 step:10824 [D loss: 0.667949, acc.: 56.25%] [G loss: 0.868109]\n",
      "epoch:11 step:10825 [D loss: 0.641477, acc.: 69.53%] [G loss: 0.823187]\n",
      "epoch:11 step:10826 [D loss: 0.664330, acc.: 57.03%] [G loss: 0.874561]\n",
      "epoch:11 step:10827 [D loss: 0.628343, acc.: 69.53%] [G loss: 0.840853]\n",
      "epoch:11 step:10828 [D loss: 0.656178, acc.: 60.94%] [G loss: 0.866074]\n",
      "epoch:11 step:10829 [D loss: 0.634586, acc.: 67.19%] [G loss: 0.857635]\n",
      "epoch:11 step:10830 [D loss: 0.683482, acc.: 51.56%] [G loss: 0.879916]\n",
      "epoch:11 step:10831 [D loss: 0.658876, acc.: 60.94%] [G loss: 0.849571]\n",
      "epoch:11 step:10832 [D loss: 0.694599, acc.: 53.12%] [G loss: 0.850374]\n",
      "epoch:11 step:10833 [D loss: 0.677998, acc.: 57.03%] [G loss: 0.829773]\n",
      "epoch:11 step:10834 [D loss: 0.665743, acc.: 61.72%] [G loss: 0.851563]\n",
      "epoch:11 step:10835 [D loss: 0.671402, acc.: 56.25%] [G loss: 0.841810]\n",
      "epoch:11 step:10836 [D loss: 0.678824, acc.: 55.47%] [G loss: 0.836193]\n",
      "epoch:11 step:10837 [D loss: 0.677806, acc.: 56.25%] [G loss: 0.822372]\n",
      "epoch:11 step:10838 [D loss: 0.672110, acc.: 58.59%] [G loss: 0.855870]\n",
      "epoch:11 step:10839 [D loss: 0.701857, acc.: 52.34%] [G loss: 0.893295]\n",
      "epoch:11 step:10840 [D loss: 0.704569, acc.: 52.34%] [G loss: 0.813594]\n",
      "epoch:11 step:10841 [D loss: 0.700009, acc.: 50.78%] [G loss: 0.876748]\n",
      "epoch:11 step:10842 [D loss: 0.713275, acc.: 53.12%] [G loss: 0.855487]\n",
      "epoch:11 step:10843 [D loss: 0.697460, acc.: 49.22%] [G loss: 0.850509]\n",
      "epoch:11 step:10844 [D loss: 0.692416, acc.: 50.00%] [G loss: 0.845441]\n",
      "epoch:11 step:10845 [D loss: 0.690042, acc.: 60.16%] [G loss: 0.827025]\n",
      "epoch:11 step:10846 [D loss: 0.657853, acc.: 57.03%] [G loss: 0.817148]\n",
      "epoch:11 step:10847 [D loss: 0.664908, acc.: 58.59%] [G loss: 0.852684]\n",
      "epoch:11 step:10848 [D loss: 0.647270, acc.: 61.72%] [G loss: 0.843458]\n",
      "epoch:11 step:10849 [D loss: 0.690972, acc.: 59.38%] [G loss: 0.817619]\n",
      "epoch:11 step:10850 [D loss: 0.653895, acc.: 57.03%] [G loss: 0.845284]\n",
      "epoch:11 step:10851 [D loss: 0.627184, acc.: 66.41%] [G loss: 0.814211]\n",
      "epoch:11 step:10852 [D loss: 0.673503, acc.: 60.94%] [G loss: 0.849198]\n",
      "epoch:11 step:10853 [D loss: 0.654948, acc.: 60.16%] [G loss: 0.843081]\n",
      "epoch:11 step:10854 [D loss: 0.670435, acc.: 65.62%] [G loss: 0.868744]\n",
      "epoch:11 step:10855 [D loss: 0.686697, acc.: 58.59%] [G loss: 0.809553]\n",
      "epoch:11 step:10856 [D loss: 0.705008, acc.: 50.00%] [G loss: 0.868067]\n",
      "epoch:11 step:10857 [D loss: 0.669672, acc.: 50.00%] [G loss: 0.814520]\n",
      "epoch:11 step:10858 [D loss: 0.671948, acc.: 60.16%] [G loss: 0.883291]\n",
      "epoch:11 step:10859 [D loss: 0.655375, acc.: 60.16%] [G loss: 0.858518]\n",
      "epoch:11 step:10860 [D loss: 0.665767, acc.: 57.81%] [G loss: 0.898369]\n",
      "epoch:11 step:10861 [D loss: 0.624745, acc.: 67.19%] [G loss: 0.852715]\n",
      "epoch:11 step:10862 [D loss: 0.646286, acc.: 63.28%] [G loss: 0.812552]\n",
      "epoch:11 step:10863 [D loss: 0.674415, acc.: 59.38%] [G loss: 0.828198]\n",
      "epoch:11 step:10864 [D loss: 0.665018, acc.: 61.72%] [G loss: 0.853114]\n",
      "epoch:11 step:10865 [D loss: 0.666514, acc.: 56.25%] [G loss: 0.805759]\n",
      "epoch:11 step:10866 [D loss: 0.686332, acc.: 57.81%] [G loss: 0.874163]\n",
      "epoch:11 step:10867 [D loss: 0.685225, acc.: 53.91%] [G loss: 0.846105]\n",
      "epoch:11 step:10868 [D loss: 0.667932, acc.: 63.28%] [G loss: 0.905596]\n",
      "epoch:11 step:10869 [D loss: 0.662867, acc.: 64.84%] [G loss: 0.885829]\n",
      "epoch:11 step:10870 [D loss: 0.674091, acc.: 56.25%] [G loss: 0.850954]\n",
      "epoch:11 step:10871 [D loss: 0.687313, acc.: 58.59%] [G loss: 0.801946]\n",
      "epoch:11 step:10872 [D loss: 0.664799, acc.: 57.81%] [G loss: 0.836827]\n",
      "epoch:11 step:10873 [D loss: 0.622495, acc.: 68.75%] [G loss: 0.830489]\n",
      "epoch:11 step:10874 [D loss: 0.659133, acc.: 58.59%] [G loss: 0.866975]\n",
      "epoch:11 step:10875 [D loss: 0.705674, acc.: 49.22%] [G loss: 0.892237]\n",
      "epoch:11 step:10876 [D loss: 0.632236, acc.: 61.72%] [G loss: 0.836196]\n",
      "epoch:11 step:10877 [D loss: 0.719965, acc.: 47.66%] [G loss: 0.814560]\n",
      "epoch:11 step:10878 [D loss: 0.682349, acc.: 54.69%] [G loss: 0.828287]\n",
      "epoch:11 step:10879 [D loss: 0.649516, acc.: 60.16%] [G loss: 0.863943]\n",
      "epoch:11 step:10880 [D loss: 0.674755, acc.: 57.03%] [G loss: 0.870673]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10881 [D loss: 0.654752, acc.: 60.94%] [G loss: 0.897826]\n",
      "epoch:11 step:10882 [D loss: 0.657716, acc.: 59.38%] [G loss: 0.841541]\n",
      "epoch:11 step:10883 [D loss: 0.674180, acc.: 53.12%] [G loss: 0.870075]\n",
      "epoch:11 step:10884 [D loss: 0.660944, acc.: 58.59%] [G loss: 0.854014]\n",
      "epoch:11 step:10885 [D loss: 0.647220, acc.: 61.72%] [G loss: 0.830217]\n",
      "epoch:11 step:10886 [D loss: 0.648339, acc.: 60.16%] [G loss: 0.851722]\n",
      "epoch:11 step:10887 [D loss: 0.671466, acc.: 55.47%] [G loss: 0.838242]\n",
      "epoch:11 step:10888 [D loss: 0.677833, acc.: 57.81%] [G loss: 0.895668]\n",
      "epoch:11 step:10889 [D loss: 0.668933, acc.: 60.16%] [G loss: 0.849798]\n",
      "epoch:11 step:10890 [D loss: 0.686745, acc.: 50.78%] [G loss: 0.895287]\n",
      "epoch:11 step:10891 [D loss: 0.661948, acc.: 59.38%] [G loss: 0.852985]\n",
      "epoch:11 step:10892 [D loss: 0.657781, acc.: 59.38%] [G loss: 0.814728]\n",
      "epoch:11 step:10893 [D loss: 0.678367, acc.: 58.59%] [G loss: 0.854209]\n",
      "epoch:11 step:10894 [D loss: 0.670186, acc.: 53.91%] [G loss: 0.871307]\n",
      "epoch:11 step:10895 [D loss: 0.691136, acc.: 53.91%] [G loss: 0.841262]\n",
      "epoch:11 step:10896 [D loss: 0.655396, acc.: 58.59%] [G loss: 0.841044]\n",
      "epoch:11 step:10897 [D loss: 0.673162, acc.: 61.72%] [G loss: 0.811662]\n",
      "epoch:11 step:10898 [D loss: 0.661462, acc.: 59.38%] [G loss: 0.759994]\n",
      "epoch:11 step:10899 [D loss: 0.688581, acc.: 58.59%] [G loss: 0.778443]\n",
      "epoch:11 step:10900 [D loss: 0.716319, acc.: 48.44%] [G loss: 0.780788]\n",
      "epoch:11 step:10901 [D loss: 0.643840, acc.: 63.28%] [G loss: 0.826121]\n",
      "epoch:11 step:10902 [D loss: 0.664800, acc.: 60.16%] [G loss: 0.799334]\n",
      "epoch:11 step:10903 [D loss: 0.675540, acc.: 57.81%] [G loss: 0.884665]\n",
      "epoch:11 step:10904 [D loss: 0.687127, acc.: 56.25%] [G loss: 0.840183]\n",
      "epoch:11 step:10905 [D loss: 0.675437, acc.: 53.91%] [G loss: 0.858302]\n",
      "epoch:11 step:10906 [D loss: 0.642720, acc.: 61.72%] [G loss: 0.903064]\n",
      "epoch:11 step:10907 [D loss: 0.666865, acc.: 57.03%] [G loss: 0.880418]\n",
      "epoch:11 step:10908 [D loss: 0.669109, acc.: 60.94%] [G loss: 0.876492]\n",
      "epoch:11 step:10909 [D loss: 0.656316, acc.: 62.50%] [G loss: 0.823085]\n",
      "epoch:11 step:10910 [D loss: 0.691988, acc.: 51.56%] [G loss: 0.868577]\n",
      "epoch:11 step:10911 [D loss: 0.690111, acc.: 57.03%] [G loss: 0.817435]\n",
      "epoch:11 step:10912 [D loss: 0.645791, acc.: 63.28%] [G loss: 0.850323]\n",
      "epoch:11 step:10913 [D loss: 0.655955, acc.: 63.28%] [G loss: 0.854223]\n",
      "epoch:11 step:10914 [D loss: 0.667677, acc.: 57.81%] [G loss: 0.858656]\n",
      "epoch:11 step:10915 [D loss: 0.669713, acc.: 57.03%] [G loss: 0.879864]\n",
      "epoch:11 step:10916 [D loss: 0.641798, acc.: 68.75%] [G loss: 0.836007]\n",
      "epoch:11 step:10917 [D loss: 0.650984, acc.: 61.72%] [G loss: 0.836040]\n",
      "epoch:11 step:10918 [D loss: 0.653803, acc.: 58.59%] [G loss: 0.834402]\n",
      "epoch:11 step:10919 [D loss: 0.660883, acc.: 61.72%] [G loss: 0.835769]\n",
      "epoch:11 step:10920 [D loss: 0.660155, acc.: 61.72%] [G loss: 0.854884]\n",
      "epoch:11 step:10921 [D loss: 0.666071, acc.: 64.06%] [G loss: 0.856746]\n",
      "epoch:11 step:10922 [D loss: 0.705571, acc.: 53.91%] [G loss: 0.868473]\n",
      "epoch:11 step:10923 [D loss: 0.676392, acc.: 55.47%] [G loss: 0.898673]\n",
      "epoch:11 step:10924 [D loss: 0.669786, acc.: 55.47%] [G loss: 0.866086]\n",
      "epoch:11 step:10925 [D loss: 0.646802, acc.: 58.59%] [G loss: 0.834270]\n",
      "epoch:11 step:10926 [D loss: 0.709970, acc.: 51.56%] [G loss: 0.833373]\n",
      "epoch:11 step:10927 [D loss: 0.651918, acc.: 60.94%] [G loss: 0.826399]\n",
      "epoch:11 step:10928 [D loss: 0.680578, acc.: 56.25%] [G loss: 0.788899]\n",
      "epoch:11 step:10929 [D loss: 0.672784, acc.: 57.81%] [G loss: 0.875041]\n",
      "epoch:11 step:10930 [D loss: 0.668869, acc.: 59.38%] [G loss: 0.823962]\n",
      "epoch:11 step:10931 [D loss: 0.659016, acc.: 58.59%] [G loss: 0.815330]\n",
      "epoch:11 step:10932 [D loss: 0.655498, acc.: 61.72%] [G loss: 0.862138]\n",
      "epoch:11 step:10933 [D loss: 0.717141, acc.: 50.78%] [G loss: 0.852382]\n",
      "epoch:11 step:10934 [D loss: 0.670940, acc.: 58.59%] [G loss: 0.913238]\n",
      "epoch:11 step:10935 [D loss: 0.684405, acc.: 51.56%] [G loss: 0.869817]\n",
      "epoch:11 step:10936 [D loss: 0.697561, acc.: 53.91%] [G loss: 0.811897]\n",
      "epoch:11 step:10937 [D loss: 0.681027, acc.: 54.69%] [G loss: 0.825152]\n",
      "epoch:11 step:10938 [D loss: 0.643838, acc.: 64.06%] [G loss: 0.825212]\n",
      "epoch:11 step:10939 [D loss: 0.674701, acc.: 56.25%] [G loss: 0.807806]\n",
      "epoch:11 step:10940 [D loss: 0.643384, acc.: 63.28%] [G loss: 0.818465]\n",
      "epoch:11 step:10941 [D loss: 0.683440, acc.: 57.81%] [G loss: 0.893846]\n",
      "epoch:11 step:10942 [D loss: 0.690186, acc.: 54.69%] [G loss: 0.833132]\n",
      "epoch:11 step:10943 [D loss: 0.633982, acc.: 62.50%] [G loss: 0.863837]\n",
      "epoch:11 step:10944 [D loss: 0.646583, acc.: 60.16%] [G loss: 0.841265]\n",
      "epoch:11 step:10945 [D loss: 0.697946, acc.: 56.25%] [G loss: 0.850213]\n",
      "epoch:11 step:10946 [D loss: 0.699776, acc.: 52.34%] [G loss: 0.829857]\n",
      "epoch:11 step:10947 [D loss: 0.658193, acc.: 61.72%] [G loss: 0.859780]\n",
      "epoch:11 step:10948 [D loss: 0.704227, acc.: 53.12%] [G loss: 0.823146]\n",
      "epoch:11 step:10949 [D loss: 0.691229, acc.: 55.47%] [G loss: 0.839768]\n",
      "epoch:11 step:10950 [D loss: 0.683159, acc.: 55.47%] [G loss: 0.813321]\n",
      "epoch:11 step:10951 [D loss: 0.648340, acc.: 63.28%] [G loss: 0.854658]\n",
      "epoch:11 step:10952 [D loss: 0.672133, acc.: 55.47%] [G loss: 0.823861]\n",
      "epoch:11 step:10953 [D loss: 0.666861, acc.: 60.94%] [G loss: 0.845493]\n",
      "epoch:11 step:10954 [D loss: 0.705426, acc.: 53.12%] [G loss: 0.894145]\n",
      "epoch:11 step:10955 [D loss: 0.635843, acc.: 60.16%] [G loss: 0.831077]\n",
      "epoch:11 step:10956 [D loss: 0.686499, acc.: 54.69%] [G loss: 0.914370]\n",
      "epoch:11 step:10957 [D loss: 0.727107, acc.: 49.22%] [G loss: 0.836346]\n",
      "epoch:11 step:10958 [D loss: 0.646492, acc.: 64.06%] [G loss: 0.869268]\n",
      "epoch:11 step:10959 [D loss: 0.675873, acc.: 56.25%] [G loss: 0.833780]\n",
      "epoch:11 step:10960 [D loss: 0.673448, acc.: 54.69%] [G loss: 0.905840]\n",
      "epoch:11 step:10961 [D loss: 0.650426, acc.: 64.06%] [G loss: 0.876700]\n",
      "epoch:11 step:10962 [D loss: 0.657804, acc.: 54.69%] [G loss: 0.843769]\n",
      "epoch:11 step:10963 [D loss: 0.693478, acc.: 57.03%] [G loss: 0.812534]\n",
      "epoch:11 step:10964 [D loss: 0.711363, acc.: 46.09%] [G loss: 0.844004]\n",
      "epoch:11 step:10965 [D loss: 0.696775, acc.: 55.47%] [G loss: 0.875558]\n",
      "epoch:11 step:10966 [D loss: 0.651225, acc.: 64.06%] [G loss: 0.869412]\n",
      "epoch:11 step:10967 [D loss: 0.675579, acc.: 61.72%] [G loss: 0.895973]\n",
      "epoch:11 step:10968 [D loss: 0.656934, acc.: 63.28%] [G loss: 0.905743]\n",
      "epoch:11 step:10969 [D loss: 0.683998, acc.: 60.16%] [G loss: 0.856578]\n",
      "epoch:11 step:10970 [D loss: 0.703110, acc.: 58.59%] [G loss: 0.871645]\n",
      "epoch:11 step:10971 [D loss: 0.677786, acc.: 56.25%] [G loss: 0.890004]\n",
      "epoch:11 step:10972 [D loss: 0.673304, acc.: 62.50%] [G loss: 0.848132]\n",
      "epoch:11 step:10973 [D loss: 0.668149, acc.: 61.72%] [G loss: 0.833218]\n",
      "epoch:11 step:10974 [D loss: 0.661532, acc.: 57.03%] [G loss: 0.844938]\n",
      "epoch:11 step:10975 [D loss: 0.670895, acc.: 63.28%] [G loss: 0.844462]\n",
      "epoch:11 step:10976 [D loss: 0.673202, acc.: 60.94%] [G loss: 0.826340]\n",
      "epoch:11 step:10977 [D loss: 0.648943, acc.: 64.84%] [G loss: 0.896719]\n",
      "epoch:11 step:10978 [D loss: 0.677907, acc.: 57.03%] [G loss: 0.850787]\n",
      "epoch:11 step:10979 [D loss: 0.681461, acc.: 51.56%] [G loss: 0.855422]\n",
      "epoch:11 step:10980 [D loss: 0.670041, acc.: 58.59%] [G loss: 0.811476]\n",
      "epoch:11 step:10981 [D loss: 0.691578, acc.: 57.03%] [G loss: 0.818738]\n",
      "epoch:11 step:10982 [D loss: 0.713432, acc.: 47.66%] [G loss: 0.838292]\n",
      "epoch:11 step:10983 [D loss: 0.648863, acc.: 56.25%] [G loss: 0.833605]\n",
      "epoch:11 step:10984 [D loss: 0.672461, acc.: 60.16%] [G loss: 0.849711]\n",
      "epoch:11 step:10985 [D loss: 0.652422, acc.: 65.62%] [G loss: 0.834309]\n",
      "epoch:11 step:10986 [D loss: 0.677590, acc.: 57.03%] [G loss: 0.829205]\n",
      "epoch:11 step:10987 [D loss: 0.661857, acc.: 60.16%] [G loss: 0.838323]\n",
      "epoch:11 step:10988 [D loss: 0.657522, acc.: 64.06%] [G loss: 0.811360]\n",
      "epoch:11 step:10989 [D loss: 0.645223, acc.: 59.38%] [G loss: 0.817674]\n",
      "epoch:11 step:10990 [D loss: 0.656147, acc.: 60.16%] [G loss: 0.813000]\n",
      "epoch:11 step:10991 [D loss: 0.670863, acc.: 58.59%] [G loss: 0.796541]\n",
      "epoch:11 step:10992 [D loss: 0.660608, acc.: 63.28%] [G loss: 0.813048]\n",
      "epoch:11 step:10993 [D loss: 0.666198, acc.: 60.16%] [G loss: 0.787694]\n",
      "epoch:11 step:10994 [D loss: 0.667011, acc.: 60.16%] [G loss: 0.879622]\n",
      "epoch:11 step:10995 [D loss: 0.644060, acc.: 67.19%] [G loss: 0.837511]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:10996 [D loss: 0.715031, acc.: 51.56%] [G loss: 0.844933]\n",
      "epoch:11 step:10997 [D loss: 0.669651, acc.: 54.69%] [G loss: 0.882122]\n",
      "epoch:11 step:10998 [D loss: 0.638753, acc.: 64.06%] [G loss: 0.854321]\n",
      "epoch:11 step:10999 [D loss: 0.687710, acc.: 53.12%] [G loss: 0.840374]\n",
      "epoch:11 step:11000 [D loss: 0.646519, acc.: 65.62%] [G loss: 0.845452]\n",
      "##############\n",
      "[ 2.91769041  2.55871318  2.17142714  4.14576851  1.35874043 10.27426719\n",
      "  2.80158962  3.90034763  4.24984917  6.68168981]\n",
      "##########\n",
      "epoch:11 step:11001 [D loss: 0.674266, acc.: 60.94%] [G loss: 0.845989]\n",
      "epoch:11 step:11002 [D loss: 0.648612, acc.: 60.16%] [G loss: 0.856339]\n",
      "epoch:11 step:11003 [D loss: 0.647722, acc.: 65.62%] [G loss: 0.860950]\n",
      "epoch:11 step:11004 [D loss: 0.658710, acc.: 62.50%] [G loss: 0.847389]\n",
      "epoch:11 step:11005 [D loss: 0.626210, acc.: 67.97%] [G loss: 0.873022]\n",
      "epoch:11 step:11006 [D loss: 0.653894, acc.: 60.94%] [G loss: 0.829092]\n",
      "epoch:11 step:11007 [D loss: 0.660502, acc.: 58.59%] [G loss: 0.851915]\n",
      "epoch:11 step:11008 [D loss: 0.650586, acc.: 60.16%] [G loss: 0.832739]\n",
      "epoch:11 step:11009 [D loss: 0.641925, acc.: 60.94%] [G loss: 0.850891]\n",
      "epoch:11 step:11010 [D loss: 0.685292, acc.: 54.69%] [G loss: 0.856535]\n",
      "epoch:11 step:11011 [D loss: 0.665160, acc.: 59.38%] [G loss: 0.899733]\n",
      "epoch:11 step:11012 [D loss: 0.675587, acc.: 57.81%] [G loss: 0.800514]\n",
      "epoch:11 step:11013 [D loss: 0.683911, acc.: 60.16%] [G loss: 0.805992]\n",
      "epoch:11 step:11014 [D loss: 0.703535, acc.: 55.47%] [G loss: 0.831277]\n",
      "epoch:11 step:11015 [D loss: 0.689439, acc.: 53.12%] [G loss: 0.870750]\n",
      "epoch:11 step:11016 [D loss: 0.665105, acc.: 58.59%] [G loss: 0.892329]\n",
      "epoch:11 step:11017 [D loss: 0.654567, acc.: 60.16%] [G loss: 0.870013]\n",
      "epoch:11 step:11018 [D loss: 0.674261, acc.: 56.25%] [G loss: 0.889169]\n",
      "epoch:11 step:11019 [D loss: 0.691823, acc.: 58.59%] [G loss: 0.845841]\n",
      "epoch:11 step:11020 [D loss: 0.666147, acc.: 63.28%] [G loss: 0.836226]\n",
      "epoch:11 step:11021 [D loss: 0.701004, acc.: 52.34%] [G loss: 0.819787]\n",
      "epoch:11 step:11022 [D loss: 0.694024, acc.: 53.12%] [G loss: 0.865057]\n",
      "epoch:11 step:11023 [D loss: 0.698843, acc.: 53.91%] [G loss: 0.845646]\n",
      "epoch:11 step:11024 [D loss: 0.674561, acc.: 53.91%] [G loss: 0.853215]\n",
      "epoch:11 step:11025 [D loss: 0.647962, acc.: 63.28%] [G loss: 0.882724]\n",
      "epoch:11 step:11026 [D loss: 0.668124, acc.: 57.81%] [G loss: 0.873084]\n",
      "epoch:11 step:11027 [D loss: 0.667420, acc.: 64.84%] [G loss: 0.849645]\n",
      "epoch:11 step:11028 [D loss: 0.662474, acc.: 62.50%] [G loss: 0.884605]\n",
      "epoch:11 step:11029 [D loss: 0.645345, acc.: 64.84%] [G loss: 0.881832]\n",
      "epoch:11 step:11030 [D loss: 0.688862, acc.: 55.47%] [G loss: 0.841101]\n",
      "epoch:11 step:11031 [D loss: 0.676063, acc.: 56.25%] [G loss: 0.841028]\n",
      "epoch:11 step:11032 [D loss: 0.668334, acc.: 62.50%] [G loss: 0.812798]\n",
      "epoch:11 step:11033 [D loss: 0.706957, acc.: 55.47%] [G loss: 0.862276]\n",
      "epoch:11 step:11034 [D loss: 0.629675, acc.: 66.41%] [G loss: 0.873015]\n",
      "epoch:11 step:11035 [D loss: 0.688565, acc.: 56.25%] [G loss: 0.861984]\n",
      "epoch:11 step:11036 [D loss: 0.651858, acc.: 63.28%] [G loss: 0.826738]\n",
      "epoch:11 step:11037 [D loss: 0.663267, acc.: 62.50%] [G loss: 0.878455]\n",
      "epoch:11 step:11038 [D loss: 0.661806, acc.: 64.06%] [G loss: 0.890090]\n",
      "epoch:11 step:11039 [D loss: 0.676788, acc.: 54.69%] [G loss: 0.820474]\n",
      "epoch:11 step:11040 [D loss: 0.639375, acc.: 63.28%] [G loss: 0.850108]\n",
      "epoch:11 step:11041 [D loss: 0.641210, acc.: 64.84%] [G loss: 0.883063]\n",
      "epoch:11 step:11042 [D loss: 0.686945, acc.: 56.25%] [G loss: 0.859710]\n",
      "epoch:11 step:11043 [D loss: 0.654221, acc.: 64.06%] [G loss: 0.809713]\n",
      "epoch:11 step:11044 [D loss: 0.681481, acc.: 54.69%] [G loss: 0.870826]\n",
      "epoch:11 step:11045 [D loss: 0.726077, acc.: 48.44%] [G loss: 0.816933]\n",
      "epoch:11 step:11046 [D loss: 0.650971, acc.: 61.72%] [G loss: 0.848347]\n",
      "epoch:11 step:11047 [D loss: 0.677004, acc.: 54.69%] [G loss: 0.851533]\n",
      "epoch:11 step:11048 [D loss: 0.682560, acc.: 56.25%] [G loss: 0.837052]\n",
      "epoch:11 step:11049 [D loss: 0.684272, acc.: 61.72%] [G loss: 0.835548]\n",
      "epoch:11 step:11050 [D loss: 0.665199, acc.: 53.12%] [G loss: 0.795940]\n",
      "epoch:11 step:11051 [D loss: 0.672572, acc.: 60.16%] [G loss: 0.807825]\n",
      "epoch:11 step:11052 [D loss: 0.679702, acc.: 59.38%] [G loss: 0.852354]\n",
      "epoch:11 step:11053 [D loss: 0.663541, acc.: 58.59%] [G loss: 0.898337]\n",
      "epoch:11 step:11054 [D loss: 0.652459, acc.: 64.84%] [G loss: 0.799224]\n",
      "epoch:11 step:11055 [D loss: 0.665971, acc.: 57.81%] [G loss: 0.870498]\n",
      "epoch:11 step:11056 [D loss: 0.688494, acc.: 52.34%] [G loss: 0.847350]\n",
      "epoch:11 step:11057 [D loss: 0.655218, acc.: 59.38%] [G loss: 0.853268]\n",
      "epoch:11 step:11058 [D loss: 0.663740, acc.: 56.25%] [G loss: 0.890997]\n",
      "epoch:11 step:11059 [D loss: 0.684852, acc.: 54.69%] [G loss: 0.877301]\n",
      "epoch:11 step:11060 [D loss: 0.655401, acc.: 57.81%] [G loss: 0.889034]\n",
      "epoch:11 step:11061 [D loss: 0.662742, acc.: 61.72%] [G loss: 0.842910]\n",
      "epoch:11 step:11062 [D loss: 0.648478, acc.: 60.94%] [G loss: 0.894622]\n",
      "epoch:11 step:11063 [D loss: 0.672167, acc.: 60.16%] [G loss: 0.854739]\n",
      "epoch:11 step:11064 [D loss: 0.654920, acc.: 60.16%] [G loss: 0.911341]\n",
      "epoch:11 step:11065 [D loss: 0.682724, acc.: 56.25%] [G loss: 0.892440]\n",
      "epoch:11 step:11066 [D loss: 0.656483, acc.: 65.62%] [G loss: 0.812410]\n",
      "epoch:11 step:11067 [D loss: 0.662176, acc.: 59.38%] [G loss: 0.890895]\n",
      "epoch:11 step:11068 [D loss: 0.686560, acc.: 59.38%] [G loss: 0.873389]\n",
      "epoch:11 step:11069 [D loss: 0.677555, acc.: 56.25%] [G loss: 0.859604]\n",
      "epoch:11 step:11070 [D loss: 0.678352, acc.: 54.69%] [G loss: 0.833286]\n",
      "epoch:11 step:11071 [D loss: 0.663679, acc.: 67.19%] [G loss: 0.834391]\n",
      "epoch:11 step:11072 [D loss: 0.637509, acc.: 68.75%] [G loss: 0.882609]\n",
      "epoch:11 step:11073 [D loss: 0.681134, acc.: 56.25%] [G loss: 0.853065]\n",
      "epoch:11 step:11074 [D loss: 0.659233, acc.: 60.16%] [G loss: 0.851180]\n",
      "epoch:11 step:11075 [D loss: 0.677834, acc.: 59.38%] [G loss: 0.838583]\n",
      "epoch:11 step:11076 [D loss: 0.663276, acc.: 62.50%] [G loss: 0.858968]\n",
      "epoch:11 step:11077 [D loss: 0.658818, acc.: 56.25%] [G loss: 0.865409]\n",
      "epoch:11 step:11078 [D loss: 0.675259, acc.: 54.69%] [G loss: 0.844154]\n",
      "epoch:11 step:11079 [D loss: 0.646317, acc.: 62.50%] [G loss: 0.828331]\n",
      "epoch:11 step:11080 [D loss: 0.671918, acc.: 58.59%] [G loss: 0.837061]\n",
      "epoch:11 step:11081 [D loss: 0.685332, acc.: 57.03%] [G loss: 0.873535]\n",
      "epoch:11 step:11082 [D loss: 0.634061, acc.: 60.94%] [G loss: 0.883427]\n",
      "epoch:11 step:11083 [D loss: 0.679421, acc.: 57.81%] [G loss: 0.815179]\n",
      "epoch:11 step:11084 [D loss: 0.665609, acc.: 58.59%] [G loss: 0.909681]\n",
      "epoch:11 step:11085 [D loss: 0.642933, acc.: 61.72%] [G loss: 0.886699]\n",
      "epoch:11 step:11086 [D loss: 0.662014, acc.: 61.72%] [G loss: 0.854260]\n",
      "epoch:11 step:11087 [D loss: 0.687315, acc.: 52.34%] [G loss: 0.860211]\n",
      "epoch:11 step:11088 [D loss: 0.691914, acc.: 54.69%] [G loss: 0.861418]\n",
      "epoch:11 step:11089 [D loss: 0.642262, acc.: 64.84%] [G loss: 0.916713]\n",
      "epoch:11 step:11090 [D loss: 0.707797, acc.: 51.56%] [G loss: 0.833411]\n",
      "epoch:11 step:11091 [D loss: 0.658131, acc.: 60.94%] [G loss: 0.825140]\n",
      "epoch:11 step:11092 [D loss: 0.666731, acc.: 57.81%] [G loss: 0.806287]\n",
      "epoch:11 step:11093 [D loss: 0.676721, acc.: 52.34%] [G loss: 0.827027]\n",
      "epoch:11 step:11094 [D loss: 0.678114, acc.: 50.78%] [G loss: 0.824332]\n",
      "epoch:11 step:11095 [D loss: 0.675050, acc.: 53.91%] [G loss: 0.835608]\n",
      "epoch:11 step:11096 [D loss: 0.665770, acc.: 57.81%] [G loss: 0.842461]\n",
      "epoch:11 step:11097 [D loss: 0.675239, acc.: 53.12%] [G loss: 0.815565]\n",
      "epoch:11 step:11098 [D loss: 0.664997, acc.: 58.59%] [G loss: 0.811358]\n",
      "epoch:11 step:11099 [D loss: 0.674834, acc.: 53.91%] [G loss: 0.844872]\n",
      "epoch:11 step:11100 [D loss: 0.670850, acc.: 59.38%] [G loss: 0.840588]\n",
      "epoch:11 step:11101 [D loss: 0.675288, acc.: 58.59%] [G loss: 0.895123]\n",
      "epoch:11 step:11102 [D loss: 0.676164, acc.: 55.47%] [G loss: 0.833575]\n",
      "epoch:11 step:11103 [D loss: 0.667221, acc.: 62.50%] [G loss: 0.880014]\n",
      "epoch:11 step:11104 [D loss: 0.688108, acc.: 53.91%] [G loss: 0.897840]\n",
      "epoch:11 step:11105 [D loss: 0.652001, acc.: 64.84%] [G loss: 0.840216]\n",
      "epoch:11 step:11106 [D loss: 0.695340, acc.: 53.12%] [G loss: 0.848858]\n",
      "epoch:11 step:11107 [D loss: 0.649996, acc.: 63.28%] [G loss: 0.868558]\n",
      "epoch:11 step:11108 [D loss: 0.660106, acc.: 61.72%] [G loss: 0.828129]\n",
      "epoch:11 step:11109 [D loss: 0.675027, acc.: 55.47%] [G loss: 0.801888]\n",
      "epoch:11 step:11110 [D loss: 0.693316, acc.: 53.91%] [G loss: 0.806607]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:11111 [D loss: 0.666521, acc.: 61.72%] [G loss: 0.815873]\n",
      "epoch:11 step:11112 [D loss: 0.664594, acc.: 60.94%] [G loss: 0.858895]\n",
      "epoch:11 step:11113 [D loss: 0.652273, acc.: 57.81%] [G loss: 0.888550]\n",
      "epoch:11 step:11114 [D loss: 0.686681, acc.: 57.03%] [G loss: 0.819443]\n",
      "epoch:11 step:11115 [D loss: 0.670686, acc.: 53.12%] [G loss: 0.855564]\n",
      "epoch:11 step:11116 [D loss: 0.662124, acc.: 64.06%] [G loss: 0.858074]\n",
      "epoch:11 step:11117 [D loss: 0.641569, acc.: 66.41%] [G loss: 0.795985]\n",
      "epoch:11 step:11118 [D loss: 0.667708, acc.: 57.81%] [G loss: 0.875211]\n",
      "epoch:11 step:11119 [D loss: 0.664522, acc.: 56.25%] [G loss: 0.853623]\n",
      "epoch:11 step:11120 [D loss: 0.660070, acc.: 61.72%] [G loss: 0.835916]\n",
      "epoch:11 step:11121 [D loss: 0.659750, acc.: 57.03%] [G loss: 0.836338]\n",
      "epoch:11 step:11122 [D loss: 0.678456, acc.: 59.38%] [G loss: 0.843647]\n",
      "epoch:11 step:11123 [D loss: 0.633261, acc.: 63.28%] [G loss: 0.920388]\n",
      "epoch:11 step:11124 [D loss: 0.685269, acc.: 53.12%] [G loss: 0.895875]\n",
      "epoch:11 step:11125 [D loss: 0.689358, acc.: 53.91%] [G loss: 0.887684]\n",
      "epoch:11 step:11126 [D loss: 0.700344, acc.: 51.56%] [G loss: 0.889183]\n",
      "epoch:11 step:11127 [D loss: 0.675225, acc.: 59.38%] [G loss: 0.871356]\n",
      "epoch:11 step:11128 [D loss: 0.668048, acc.: 61.72%] [G loss: 0.852186]\n",
      "epoch:11 step:11129 [D loss: 0.654528, acc.: 57.03%] [G loss: 0.905044]\n",
      "epoch:11 step:11130 [D loss: 0.702864, acc.: 57.03%] [G loss: 0.845271]\n",
      "epoch:11 step:11131 [D loss: 0.665730, acc.: 63.28%] [G loss: 0.817616]\n",
      "epoch:11 step:11132 [D loss: 0.644159, acc.: 60.16%] [G loss: 0.835081]\n",
      "epoch:11 step:11133 [D loss: 0.655700, acc.: 63.28%] [G loss: 0.884690]\n",
      "epoch:11 step:11134 [D loss: 0.688374, acc.: 53.12%] [G loss: 0.847522]\n",
      "epoch:11 step:11135 [D loss: 0.684499, acc.: 56.25%] [G loss: 0.841304]\n",
      "epoch:11 step:11136 [D loss: 0.641419, acc.: 64.06%] [G loss: 0.824216]\n",
      "epoch:11 step:11137 [D loss: 0.663323, acc.: 62.50%] [G loss: 0.808533]\n",
      "epoch:11 step:11138 [D loss: 0.694698, acc.: 50.78%] [G loss: 0.807531]\n",
      "epoch:11 step:11139 [D loss: 0.679797, acc.: 56.25%] [G loss: 0.842377]\n",
      "epoch:11 step:11140 [D loss: 0.661921, acc.: 57.81%] [G loss: 0.874965]\n",
      "epoch:11 step:11141 [D loss: 0.670854, acc.: 56.25%] [G loss: 0.819603]\n",
      "epoch:11 step:11142 [D loss: 0.686174, acc.: 56.25%] [G loss: 0.818356]\n",
      "epoch:11 step:11143 [D loss: 0.648435, acc.: 57.03%] [G loss: 0.825781]\n",
      "epoch:11 step:11144 [D loss: 0.676695, acc.: 55.47%] [G loss: 0.785056]\n",
      "epoch:11 step:11145 [D loss: 0.694617, acc.: 52.34%] [G loss: 0.812026]\n",
      "epoch:11 step:11146 [D loss: 0.651350, acc.: 60.16%] [G loss: 0.861090]\n",
      "epoch:11 step:11147 [D loss: 0.677074, acc.: 54.69%] [G loss: 0.817599]\n",
      "epoch:11 step:11148 [D loss: 0.673879, acc.: 57.81%] [G loss: 0.782713]\n",
      "epoch:11 step:11149 [D loss: 0.688177, acc.: 51.56%] [G loss: 0.824689]\n",
      "epoch:11 step:11150 [D loss: 0.698427, acc.: 53.12%] [G loss: 0.831254]\n",
      "epoch:11 step:11151 [D loss: 0.684317, acc.: 55.47%] [G loss: 0.870223]\n",
      "epoch:11 step:11152 [D loss: 0.680955, acc.: 52.34%] [G loss: 0.878633]\n",
      "epoch:11 step:11153 [D loss: 0.700189, acc.: 50.78%] [G loss: 0.856561]\n",
      "epoch:11 step:11154 [D loss: 0.647505, acc.: 60.16%] [G loss: 0.874747]\n",
      "epoch:11 step:11155 [D loss: 0.690633, acc.: 50.78%] [G loss: 0.849615]\n",
      "epoch:11 step:11156 [D loss: 0.667818, acc.: 53.91%] [G loss: 0.843263]\n",
      "epoch:11 step:11157 [D loss: 0.692660, acc.: 54.69%] [G loss: 0.839587]\n",
      "epoch:11 step:11158 [D loss: 0.687010, acc.: 52.34%] [G loss: 0.827354]\n",
      "epoch:11 step:11159 [D loss: 0.666165, acc.: 60.94%] [G loss: 0.846971]\n",
      "epoch:11 step:11160 [D loss: 0.649962, acc.: 62.50%] [G loss: 0.857050]\n",
      "epoch:11 step:11161 [D loss: 0.632226, acc.: 63.28%] [G loss: 0.835002]\n",
      "epoch:11 step:11162 [D loss: 0.681297, acc.: 57.03%] [G loss: 0.872684]\n",
      "epoch:11 step:11163 [D loss: 0.639655, acc.: 62.50%] [G loss: 0.849256]\n",
      "epoch:11 step:11164 [D loss: 0.678515, acc.: 60.16%] [G loss: 0.834472]\n",
      "epoch:11 step:11165 [D loss: 0.658281, acc.: 61.72%] [G loss: 0.847661]\n",
      "epoch:11 step:11166 [D loss: 0.655331, acc.: 58.59%] [G loss: 0.769744]\n",
      "epoch:11 step:11167 [D loss: 0.681297, acc.: 62.50%] [G loss: 0.811495]\n",
      "epoch:11 step:11168 [D loss: 0.658357, acc.: 60.16%] [G loss: 0.807899]\n",
      "epoch:11 step:11169 [D loss: 0.686477, acc.: 55.47%] [G loss: 0.849854]\n",
      "epoch:11 step:11170 [D loss: 0.673929, acc.: 59.38%] [G loss: 0.832319]\n",
      "epoch:11 step:11171 [D loss: 0.672930, acc.: 54.69%] [G loss: 0.841452]\n",
      "epoch:11 step:11172 [D loss: 0.720504, acc.: 46.09%] [G loss: 0.849224]\n",
      "epoch:11 step:11173 [D loss: 0.655957, acc.: 57.03%] [G loss: 0.866230]\n",
      "epoch:11 step:11174 [D loss: 0.700573, acc.: 52.34%] [G loss: 0.851547]\n",
      "epoch:11 step:11175 [D loss: 0.664247, acc.: 60.16%] [G loss: 0.851986]\n",
      "epoch:11 step:11176 [D loss: 0.695425, acc.: 50.00%] [G loss: 0.874360]\n",
      "epoch:11 step:11177 [D loss: 0.702758, acc.: 50.78%] [G loss: 0.872773]\n",
      "epoch:11 step:11178 [D loss: 0.665063, acc.: 62.50%] [G loss: 0.914171]\n",
      "epoch:11 step:11179 [D loss: 0.671527, acc.: 53.91%] [G loss: 0.903595]\n",
      "epoch:11 step:11180 [D loss: 0.652038, acc.: 60.16%] [G loss: 0.885572]\n",
      "epoch:11 step:11181 [D loss: 0.711484, acc.: 53.12%] [G loss: 0.853554]\n",
      "epoch:11 step:11182 [D loss: 0.666994, acc.: 60.16%] [G loss: 0.882483]\n",
      "epoch:11 step:11183 [D loss: 0.647108, acc.: 63.28%] [G loss: 0.833866]\n",
      "epoch:11 step:11184 [D loss: 0.684596, acc.: 53.12%] [G loss: 0.905964]\n",
      "epoch:11 step:11185 [D loss: 0.663933, acc.: 60.16%] [G loss: 0.847875]\n",
      "epoch:11 step:11186 [D loss: 0.691449, acc.: 52.34%] [G loss: 0.860697]\n",
      "epoch:11 step:11187 [D loss: 0.664469, acc.: 58.59%] [G loss: 0.829547]\n",
      "epoch:11 step:11188 [D loss: 0.676647, acc.: 53.91%] [G loss: 0.833650]\n",
      "epoch:11 step:11189 [D loss: 0.653849, acc.: 64.84%] [G loss: 0.823602]\n",
      "epoch:11 step:11190 [D loss: 0.655581, acc.: 57.03%] [G loss: 0.874988]\n",
      "epoch:11 step:11191 [D loss: 0.643322, acc.: 60.16%] [G loss: 0.852429]\n",
      "epoch:11 step:11192 [D loss: 0.647549, acc.: 64.84%] [G loss: 0.839262]\n",
      "epoch:11 step:11193 [D loss: 0.716646, acc.: 52.34%] [G loss: 0.858020]\n",
      "epoch:11 step:11194 [D loss: 0.685041, acc.: 55.47%] [G loss: 0.836756]\n",
      "epoch:11 step:11195 [D loss: 0.647965, acc.: 61.72%] [G loss: 0.820829]\n",
      "epoch:11 step:11196 [D loss: 0.664437, acc.: 59.38%] [G loss: 0.826030]\n",
      "epoch:11 step:11197 [D loss: 0.700787, acc.: 55.47%] [G loss: 0.843480]\n",
      "epoch:11 step:11198 [D loss: 0.685232, acc.: 55.47%] [G loss: 0.866697]\n",
      "epoch:11 step:11199 [D loss: 0.677544, acc.: 50.00%] [G loss: 0.849656]\n",
      "epoch:11 step:11200 [D loss: 0.657954, acc.: 55.47%] [G loss: 0.860997]\n",
      "##############\n",
      "[3.14651862 2.33179792 2.34875931 3.75454944 1.46993544 9.27377891\n",
      " 2.78867449 3.28234746 4.27225343 8.14868929]\n",
      "##########\n",
      "epoch:11 step:11201 [D loss: 0.681127, acc.: 50.78%] [G loss: 0.861205]\n",
      "epoch:11 step:11202 [D loss: 0.693537, acc.: 55.47%] [G loss: 0.810328]\n",
      "epoch:11 step:11203 [D loss: 0.676404, acc.: 58.59%] [G loss: 0.841661]\n",
      "epoch:11 step:11204 [D loss: 0.671821, acc.: 58.59%] [G loss: 0.861880]\n",
      "epoch:11 step:11205 [D loss: 0.670430, acc.: 55.47%] [G loss: 0.835769]\n",
      "epoch:11 step:11206 [D loss: 0.670323, acc.: 59.38%] [G loss: 0.822077]\n",
      "epoch:11 step:11207 [D loss: 0.653578, acc.: 62.50%] [G loss: 0.839612]\n",
      "epoch:11 step:11208 [D loss: 0.692285, acc.: 51.56%] [G loss: 0.830576]\n",
      "epoch:11 step:11209 [D loss: 0.646599, acc.: 64.06%] [G loss: 0.842668]\n",
      "epoch:11 step:11210 [D loss: 0.648923, acc.: 61.72%] [G loss: 0.839389]\n",
      "epoch:11 step:11211 [D loss: 0.633589, acc.: 66.41%] [G loss: 0.878278]\n",
      "epoch:11 step:11212 [D loss: 0.693504, acc.: 53.91%] [G loss: 0.817862]\n",
      "epoch:11 step:11213 [D loss: 0.671328, acc.: 58.59%] [G loss: 0.802910]\n",
      "epoch:11 step:11214 [D loss: 0.685745, acc.: 51.56%] [G loss: 0.865094]\n",
      "epoch:11 step:11215 [D loss: 0.665375, acc.: 59.38%] [G loss: 0.871855]\n",
      "epoch:11 step:11216 [D loss: 0.639039, acc.: 65.62%] [G loss: 0.853151]\n",
      "epoch:11 step:11217 [D loss: 0.700396, acc.: 55.47%] [G loss: 0.906114]\n",
      "epoch:11 step:11218 [D loss: 0.656746, acc.: 60.94%] [G loss: 0.839496]\n",
      "epoch:11 step:11219 [D loss: 0.691062, acc.: 56.25%] [G loss: 0.848298]\n",
      "epoch:11 step:11220 [D loss: 0.666494, acc.: 54.69%] [G loss: 0.875998]\n",
      "epoch:11 step:11221 [D loss: 0.650383, acc.: 70.31%] [G loss: 0.842835]\n",
      "epoch:11 step:11222 [D loss: 0.663836, acc.: 64.06%] [G loss: 0.881692]\n",
      "epoch:11 step:11223 [D loss: 0.667162, acc.: 63.28%] [G loss: 0.865170]\n",
      "epoch:11 step:11224 [D loss: 0.648455, acc.: 64.84%] [G loss: 0.859330]\n",
      "epoch:11 step:11225 [D loss: 0.660369, acc.: 64.06%] [G loss: 0.862133]\n",
      "epoch:11 step:11226 [D loss: 0.663084, acc.: 61.72%] [G loss: 0.838034]\n",
      "epoch:11 step:11227 [D loss: 0.659550, acc.: 61.72%] [G loss: 0.821104]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:11 step:11228 [D loss: 0.662481, acc.: 61.72%] [G loss: 0.858199]\n",
      "epoch:11 step:11229 [D loss: 0.644060, acc.: 64.06%] [G loss: 0.834936]\n",
      "epoch:11 step:11230 [D loss: 0.661710, acc.: 58.59%] [G loss: 0.849367]\n",
      "epoch:11 step:11231 [D loss: 0.662150, acc.: 60.16%] [G loss: 0.850376]\n",
      "epoch:11 step:11232 [D loss: 0.669127, acc.: 61.72%] [G loss: 0.852399]\n",
      "epoch:11 step:11233 [D loss: 0.671956, acc.: 54.69%] [G loss: 0.914689]\n",
      "epoch:11 step:11234 [D loss: 0.670674, acc.: 59.38%] [G loss: 0.802742]\n",
      "epoch:11 step:11235 [D loss: 0.679493, acc.: 57.81%] [G loss: 0.818253]\n",
      "epoch:11 step:11236 [D loss: 0.668539, acc.: 56.25%] [G loss: 0.885825]\n",
      "epoch:11 step:11237 [D loss: 0.643852, acc.: 60.16%] [G loss: 0.844212]\n",
      "epoch:11 step:11238 [D loss: 0.668269, acc.: 61.72%] [G loss: 0.878954]\n",
      "epoch:11 step:11239 [D loss: 0.649522, acc.: 60.94%] [G loss: 0.840979]\n",
      "epoch:11 step:11240 [D loss: 0.695077, acc.: 54.69%] [G loss: 0.857639]\n",
      "epoch:11 step:11241 [D loss: 0.665908, acc.: 58.59%] [G loss: 0.873834]\n",
      "epoch:11 step:11242 [D loss: 0.663333, acc.: 53.12%] [G loss: 0.835455]\n",
      "epoch:11 step:11243 [D loss: 0.658876, acc.: 54.69%] [G loss: 0.853052]\n",
      "epoch:11 step:11244 [D loss: 0.668097, acc.: 59.38%] [G loss: 0.887337]\n",
      "epoch:12 step:11245 [D loss: 0.692258, acc.: 53.12%] [G loss: 0.922067]\n",
      "epoch:12 step:11246 [D loss: 0.653523, acc.: 64.06%] [G loss: 0.896335]\n",
      "epoch:12 step:11247 [D loss: 0.652786, acc.: 65.62%] [G loss: 0.898534]\n",
      "epoch:12 step:11248 [D loss: 0.658310, acc.: 62.50%] [G loss: 0.870440]\n",
      "epoch:12 step:11249 [D loss: 0.663792, acc.: 60.94%] [G loss: 0.834716]\n",
      "epoch:12 step:11250 [D loss: 0.662819, acc.: 64.06%] [G loss: 0.847308]\n",
      "epoch:12 step:11251 [D loss: 0.675727, acc.: 54.69%] [G loss: 0.821278]\n",
      "epoch:12 step:11252 [D loss: 0.655213, acc.: 58.59%] [G loss: 0.831348]\n",
      "epoch:12 step:11253 [D loss: 0.650726, acc.: 63.28%] [G loss: 0.789387]\n",
      "epoch:12 step:11254 [D loss: 0.663892, acc.: 60.16%] [G loss: 0.787701]\n",
      "epoch:12 step:11255 [D loss: 0.635865, acc.: 64.06%] [G loss: 0.805082]\n",
      "epoch:12 step:11256 [D loss: 0.674033, acc.: 59.38%] [G loss: 0.820323]\n",
      "epoch:12 step:11257 [D loss: 0.638373, acc.: 64.84%] [G loss: 0.840701]\n",
      "epoch:12 step:11258 [D loss: 0.719649, acc.: 50.78%] [G loss: 0.874380]\n",
      "epoch:12 step:11259 [D loss: 0.660034, acc.: 57.81%] [G loss: 0.878352]\n",
      "epoch:12 step:11260 [D loss: 0.651564, acc.: 64.06%] [G loss: 0.847045]\n",
      "epoch:12 step:11261 [D loss: 0.647749, acc.: 64.06%] [G loss: 0.861351]\n",
      "epoch:12 step:11262 [D loss: 0.665556, acc.: 61.72%] [G loss: 0.851420]\n",
      "epoch:12 step:11263 [D loss: 0.661188, acc.: 58.59%] [G loss: 0.888347]\n",
      "epoch:12 step:11264 [D loss: 0.658681, acc.: 57.03%] [G loss: 0.891174]\n",
      "epoch:12 step:11265 [D loss: 0.645072, acc.: 61.72%] [G loss: 0.853308]\n",
      "epoch:12 step:11266 [D loss: 0.684517, acc.: 57.81%] [G loss: 0.868064]\n",
      "epoch:12 step:11267 [D loss: 0.673835, acc.: 56.25%] [G loss: 0.858133]\n",
      "epoch:12 step:11268 [D loss: 0.646766, acc.: 64.06%] [G loss: 0.881861]\n",
      "epoch:12 step:11269 [D loss: 0.644810, acc.: 64.06%] [G loss: 0.826262]\n",
      "epoch:12 step:11270 [D loss: 0.643552, acc.: 64.06%] [G loss: 0.879307]\n",
      "epoch:12 step:11271 [D loss: 0.621135, acc.: 67.19%] [G loss: 0.854319]\n",
      "epoch:12 step:11272 [D loss: 0.679504, acc.: 59.38%] [G loss: 0.865607]\n",
      "epoch:12 step:11273 [D loss: 0.674320, acc.: 57.81%] [G loss: 0.902708]\n",
      "epoch:12 step:11274 [D loss: 0.676687, acc.: 56.25%] [G loss: 0.903372]\n",
      "epoch:12 step:11275 [D loss: 0.675291, acc.: 55.47%] [G loss: 0.895738]\n",
      "epoch:12 step:11276 [D loss: 0.673122, acc.: 61.72%] [G loss: 0.849928]\n",
      "epoch:12 step:11277 [D loss: 0.640509, acc.: 59.38%] [G loss: 0.898397]\n",
      "epoch:12 step:11278 [D loss: 0.671088, acc.: 50.00%] [G loss: 0.909205]\n",
      "epoch:12 step:11279 [D loss: 0.674192, acc.: 57.03%] [G loss: 0.900630]\n",
      "epoch:12 step:11280 [D loss: 0.666623, acc.: 54.69%] [G loss: 0.943296]\n",
      "epoch:12 step:11281 [D loss: 0.687670, acc.: 53.12%] [G loss: 0.944821]\n",
      "epoch:12 step:11282 [D loss: 0.703245, acc.: 50.00%] [G loss: 0.928410]\n",
      "epoch:12 step:11283 [D loss: 0.694795, acc.: 50.78%] [G loss: 0.902868]\n",
      "epoch:12 step:11284 [D loss: 0.694207, acc.: 53.91%] [G loss: 0.899375]\n",
      "epoch:12 step:11285 [D loss: 0.676595, acc.: 59.38%] [G loss: 0.850070]\n",
      "epoch:12 step:11286 [D loss: 0.654172, acc.: 57.03%] [G loss: 0.870750]\n",
      "epoch:12 step:11287 [D loss: 0.661497, acc.: 60.94%] [G loss: 0.908425]\n",
      "epoch:12 step:11288 [D loss: 0.704856, acc.: 53.12%] [G loss: 0.885481]\n",
      "epoch:12 step:11289 [D loss: 0.673446, acc.: 56.25%] [G loss: 0.899380]\n",
      "epoch:12 step:11290 [D loss: 0.648488, acc.: 60.94%] [G loss: 0.847547]\n",
      "epoch:12 step:11291 [D loss: 0.670467, acc.: 57.03%] [G loss: 0.891779]\n",
      "epoch:12 step:11292 [D loss: 0.644981, acc.: 59.38%] [G loss: 0.828796]\n",
      "epoch:12 step:11293 [D loss: 0.674349, acc.: 58.59%] [G loss: 0.836146]\n",
      "epoch:12 step:11294 [D loss: 0.690436, acc.: 50.78%] [G loss: 0.859832]\n",
      "epoch:12 step:11295 [D loss: 0.660718, acc.: 53.12%] [G loss: 0.855380]\n",
      "epoch:12 step:11296 [D loss: 0.654727, acc.: 61.72%] [G loss: 0.825768]\n",
      "epoch:12 step:11297 [D loss: 0.670578, acc.: 61.72%] [G loss: 0.822338]\n",
      "epoch:12 step:11298 [D loss: 0.637720, acc.: 60.94%] [G loss: 0.876915]\n",
      "epoch:12 step:11299 [D loss: 0.653716, acc.: 58.59%] [G loss: 0.821812]\n",
      "epoch:12 step:11300 [D loss: 0.668632, acc.: 61.72%] [G loss: 0.818395]\n",
      "epoch:12 step:11301 [D loss: 0.667856, acc.: 63.28%] [G loss: 0.854395]\n",
      "epoch:12 step:11302 [D loss: 0.660070, acc.: 64.06%] [G loss: 0.837753]\n",
      "epoch:12 step:11303 [D loss: 0.610782, acc.: 67.19%] [G loss: 0.806662]\n",
      "epoch:12 step:11304 [D loss: 0.660278, acc.: 59.38%] [G loss: 0.787131]\n",
      "epoch:12 step:11305 [D loss: 0.694879, acc.: 52.34%] [G loss: 0.851837]\n",
      "epoch:12 step:11306 [D loss: 0.667483, acc.: 60.94%] [G loss: 0.811689]\n",
      "epoch:12 step:11307 [D loss: 0.646495, acc.: 59.38%] [G loss: 0.811910]\n",
      "epoch:12 step:11308 [D loss: 0.682026, acc.: 57.03%] [G loss: 0.890457]\n",
      "epoch:12 step:11309 [D loss: 0.666515, acc.: 55.47%] [G loss: 0.822083]\n",
      "epoch:12 step:11310 [D loss: 0.651069, acc.: 57.81%] [G loss: 0.857912]\n",
      "epoch:12 step:11311 [D loss: 0.715399, acc.: 47.66%] [G loss: 0.821607]\n",
      "epoch:12 step:11312 [D loss: 0.645681, acc.: 62.50%] [G loss: 0.873377]\n",
      "epoch:12 step:11313 [D loss: 0.646123, acc.: 58.59%] [G loss: 0.870186]\n",
      "epoch:12 step:11314 [D loss: 0.676751, acc.: 55.47%] [G loss: 0.901655]\n",
      "epoch:12 step:11315 [D loss: 0.687769, acc.: 59.38%] [G loss: 0.881349]\n",
      "epoch:12 step:11316 [D loss: 0.653295, acc.: 57.81%] [G loss: 0.847703]\n",
      "epoch:12 step:11317 [D loss: 0.611047, acc.: 69.53%] [G loss: 0.889356]\n",
      "epoch:12 step:11318 [D loss: 0.683990, acc.: 49.22%] [G loss: 0.850598]\n",
      "epoch:12 step:11319 [D loss: 0.646564, acc.: 63.28%] [G loss: 0.864814]\n",
      "epoch:12 step:11320 [D loss: 0.653772, acc.: 66.41%] [G loss: 0.849318]\n",
      "epoch:12 step:11321 [D loss: 0.661035, acc.: 56.25%] [G loss: 0.853979]\n",
      "epoch:12 step:11322 [D loss: 0.693579, acc.: 52.34%] [G loss: 0.868358]\n",
      "epoch:12 step:11323 [D loss: 0.661027, acc.: 62.50%] [G loss: 0.868865]\n",
      "epoch:12 step:11324 [D loss: 0.674753, acc.: 58.59%] [G loss: 0.872375]\n",
      "epoch:12 step:11325 [D loss: 0.684549, acc.: 55.47%] [G loss: 0.870018]\n",
      "epoch:12 step:11326 [D loss: 0.655440, acc.: 59.38%] [G loss: 0.933451]\n",
      "epoch:12 step:11327 [D loss: 0.650318, acc.: 61.72%] [G loss: 0.857324]\n",
      "epoch:12 step:11328 [D loss: 0.665007, acc.: 57.81%] [G loss: 0.898574]\n",
      "epoch:12 step:11329 [D loss: 0.674223, acc.: 53.91%] [G loss: 0.846335]\n",
      "epoch:12 step:11330 [D loss: 0.707165, acc.: 52.34%] [G loss: 0.799218]\n",
      "epoch:12 step:11331 [D loss: 0.670272, acc.: 53.91%] [G loss: 0.821306]\n",
      "epoch:12 step:11332 [D loss: 0.662624, acc.: 60.16%] [G loss: 0.860874]\n",
      "epoch:12 step:11333 [D loss: 0.654709, acc.: 64.06%] [G loss: 0.890354]\n",
      "epoch:12 step:11334 [D loss: 0.663981, acc.: 55.47%] [G loss: 0.904445]\n",
      "epoch:12 step:11335 [D loss: 0.658378, acc.: 62.50%] [G loss: 0.852946]\n",
      "epoch:12 step:11336 [D loss: 0.660249, acc.: 57.81%] [G loss: 0.855533]\n",
      "epoch:12 step:11337 [D loss: 0.669679, acc.: 59.38%] [G loss: 0.834953]\n",
      "epoch:12 step:11338 [D loss: 0.658151, acc.: 60.94%] [G loss: 0.827059]\n",
      "epoch:12 step:11339 [D loss: 0.649247, acc.: 61.72%] [G loss: 0.839302]\n",
      "epoch:12 step:11340 [D loss: 0.651630, acc.: 60.16%] [G loss: 0.830301]\n",
      "epoch:12 step:11341 [D loss: 0.685659, acc.: 56.25%] [G loss: 0.820509]\n",
      "epoch:12 step:11342 [D loss: 0.642002, acc.: 62.50%] [G loss: 0.827258]\n",
      "epoch:12 step:11343 [D loss: 0.630657, acc.: 66.41%] [G loss: 0.825852]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11344 [D loss: 0.707468, acc.: 50.78%] [G loss: 0.856090]\n",
      "epoch:12 step:11345 [D loss: 0.670880, acc.: 59.38%] [G loss: 0.850759]\n",
      "epoch:12 step:11346 [D loss: 0.704343, acc.: 46.88%] [G loss: 0.866802]\n",
      "epoch:12 step:11347 [D loss: 0.640512, acc.: 63.28%] [G loss: 0.878970]\n",
      "epoch:12 step:11348 [D loss: 0.676020, acc.: 54.69%] [G loss: 0.858943]\n",
      "epoch:12 step:11349 [D loss: 0.648651, acc.: 60.94%] [G loss: 0.867611]\n",
      "epoch:12 step:11350 [D loss: 0.693034, acc.: 56.25%] [G loss: 0.817111]\n",
      "epoch:12 step:11351 [D loss: 0.696279, acc.: 53.12%] [G loss: 0.817971]\n",
      "epoch:12 step:11352 [D loss: 0.691843, acc.: 54.69%] [G loss: 0.802002]\n",
      "epoch:12 step:11353 [D loss: 0.673117, acc.: 57.81%] [G loss: 0.867130]\n",
      "epoch:12 step:11354 [D loss: 0.710696, acc.: 48.44%] [G loss: 0.822303]\n",
      "epoch:12 step:11355 [D loss: 0.716909, acc.: 47.66%] [G loss: 0.797670]\n",
      "epoch:12 step:11356 [D loss: 0.705249, acc.: 51.56%] [G loss: 0.815867]\n",
      "epoch:12 step:11357 [D loss: 0.636910, acc.: 65.62%] [G loss: 0.879058]\n",
      "epoch:12 step:11358 [D loss: 0.669487, acc.: 63.28%] [G loss: 0.817368]\n",
      "epoch:12 step:11359 [D loss: 0.703806, acc.: 53.91%] [G loss: 0.867498]\n",
      "epoch:12 step:11360 [D loss: 0.673010, acc.: 57.03%] [G loss: 0.893724]\n",
      "epoch:12 step:11361 [D loss: 0.692598, acc.: 51.56%] [G loss: 0.834281]\n",
      "epoch:12 step:11362 [D loss: 0.680286, acc.: 53.12%] [G loss: 0.867390]\n",
      "epoch:12 step:11363 [D loss: 0.652551, acc.: 64.84%] [G loss: 0.842845]\n",
      "epoch:12 step:11364 [D loss: 0.681779, acc.: 53.91%] [G loss: 0.858662]\n",
      "epoch:12 step:11365 [D loss: 0.630034, acc.: 62.50%] [G loss: 0.883486]\n",
      "epoch:12 step:11366 [D loss: 0.704544, acc.: 52.34%] [G loss: 0.784962]\n",
      "epoch:12 step:11367 [D loss: 0.681250, acc.: 57.81%] [G loss: 0.799452]\n",
      "epoch:12 step:11368 [D loss: 0.704951, acc.: 47.66%] [G loss: 0.784410]\n",
      "epoch:12 step:11369 [D loss: 0.677411, acc.: 56.25%] [G loss: 0.799120]\n",
      "epoch:12 step:11370 [D loss: 0.688527, acc.: 53.91%] [G loss: 0.847153]\n",
      "epoch:12 step:11371 [D loss: 0.671057, acc.: 54.69%] [G loss: 0.822794]\n",
      "epoch:12 step:11372 [D loss: 0.697230, acc.: 51.56%] [G loss: 0.891433]\n",
      "epoch:12 step:11373 [D loss: 0.678349, acc.: 59.38%] [G loss: 0.873875]\n",
      "epoch:12 step:11374 [D loss: 0.650838, acc.: 64.84%] [G loss: 0.883804]\n",
      "epoch:12 step:11375 [D loss: 0.659509, acc.: 60.94%] [G loss: 0.863471]\n",
      "epoch:12 step:11376 [D loss: 0.695316, acc.: 55.47%] [G loss: 0.896632]\n",
      "epoch:12 step:11377 [D loss: 0.702846, acc.: 57.03%] [G loss: 0.813256]\n",
      "epoch:12 step:11378 [D loss: 0.661133, acc.: 56.25%] [G loss: 0.856028]\n",
      "epoch:12 step:11379 [D loss: 0.747580, acc.: 43.75%] [G loss: 0.870921]\n",
      "epoch:12 step:11380 [D loss: 0.665922, acc.: 59.38%] [G loss: 0.854028]\n",
      "epoch:12 step:11381 [D loss: 0.661204, acc.: 60.16%] [G loss: 0.782442]\n",
      "epoch:12 step:11382 [D loss: 0.662491, acc.: 61.72%] [G loss: 0.813132]\n",
      "epoch:12 step:11383 [D loss: 0.659885, acc.: 59.38%] [G loss: 0.817194]\n",
      "epoch:12 step:11384 [D loss: 0.657158, acc.: 60.16%] [G loss: 0.848337]\n",
      "epoch:12 step:11385 [D loss: 0.700102, acc.: 50.00%] [G loss: 0.846253]\n",
      "epoch:12 step:11386 [D loss: 0.656067, acc.: 57.03%] [G loss: 0.814537]\n",
      "epoch:12 step:11387 [D loss: 0.663401, acc.: 63.28%] [G loss: 0.871001]\n",
      "epoch:12 step:11388 [D loss: 0.667904, acc.: 61.72%] [G loss: 0.857563]\n",
      "epoch:12 step:11389 [D loss: 0.665359, acc.: 59.38%] [G loss: 0.865759]\n",
      "epoch:12 step:11390 [D loss: 0.660574, acc.: 58.59%] [G loss: 0.790532]\n",
      "epoch:12 step:11391 [D loss: 0.670547, acc.: 57.81%] [G loss: 0.839466]\n",
      "epoch:12 step:11392 [D loss: 0.668548, acc.: 56.25%] [G loss: 0.829314]\n",
      "epoch:12 step:11393 [D loss: 0.643173, acc.: 64.84%] [G loss: 0.830234]\n",
      "epoch:12 step:11394 [D loss: 0.708694, acc.: 52.34%] [G loss: 0.783282]\n",
      "epoch:12 step:11395 [D loss: 0.663319, acc.: 57.81%] [G loss: 0.861011]\n",
      "epoch:12 step:11396 [D loss: 0.681392, acc.: 51.56%] [G loss: 0.798095]\n",
      "epoch:12 step:11397 [D loss: 0.658711, acc.: 59.38%] [G loss: 0.791993]\n",
      "epoch:12 step:11398 [D loss: 0.660132, acc.: 57.03%] [G loss: 0.843251]\n",
      "epoch:12 step:11399 [D loss: 0.687855, acc.: 56.25%] [G loss: 0.866326]\n",
      "epoch:12 step:11400 [D loss: 0.649815, acc.: 63.28%] [G loss: 0.897148]\n",
      "##############\n",
      "[3.34949076 1.88013585 2.25985867 3.88331755 0.98792924 7.65790218\n",
      " 2.79638267 3.84750243 4.21468307 5.86508721]\n",
      "##########\n",
      "epoch:12 step:11401 [D loss: 0.673728, acc.: 60.16%] [G loss: 0.835564]\n",
      "epoch:12 step:11402 [D loss: 0.678871, acc.: 56.25%] [G loss: 0.813462]\n",
      "epoch:12 step:11403 [D loss: 0.633873, acc.: 63.28%] [G loss: 0.841524]\n",
      "epoch:12 step:11404 [D loss: 0.663275, acc.: 55.47%] [G loss: 0.852756]\n",
      "epoch:12 step:11405 [D loss: 0.660448, acc.: 60.16%] [G loss: 0.870739]\n",
      "epoch:12 step:11406 [D loss: 0.638798, acc.: 66.41%] [G loss: 0.877939]\n",
      "epoch:12 step:11407 [D loss: 0.692341, acc.: 56.25%] [G loss: 0.838047]\n",
      "epoch:12 step:11408 [D loss: 0.695589, acc.: 52.34%] [G loss: 0.861720]\n",
      "epoch:12 step:11409 [D loss: 0.664596, acc.: 60.16%] [G loss: 0.792485]\n",
      "epoch:12 step:11410 [D loss: 0.681904, acc.: 57.03%] [G loss: 0.895890]\n",
      "epoch:12 step:11411 [D loss: 0.653056, acc.: 59.38%] [G loss: 0.810116]\n",
      "epoch:12 step:11412 [D loss: 0.690666, acc.: 50.78%] [G loss: 0.810861]\n",
      "epoch:12 step:11413 [D loss: 0.693629, acc.: 49.22%] [G loss: 0.784149]\n",
      "epoch:12 step:11414 [D loss: 0.667633, acc.: 55.47%] [G loss: 0.876307]\n",
      "epoch:12 step:11415 [D loss: 0.689479, acc.: 55.47%] [G loss: 0.841871]\n",
      "epoch:12 step:11416 [D loss: 0.676648, acc.: 57.03%] [G loss: 0.859561]\n",
      "epoch:12 step:11417 [D loss: 0.684446, acc.: 49.22%] [G loss: 0.859765]\n",
      "epoch:12 step:11418 [D loss: 0.644888, acc.: 62.50%] [G loss: 0.841513]\n",
      "epoch:12 step:11419 [D loss: 0.662054, acc.: 57.81%] [G loss: 0.816749]\n",
      "epoch:12 step:11420 [D loss: 0.624526, acc.: 65.62%] [G loss: 0.832582]\n",
      "epoch:12 step:11421 [D loss: 0.628214, acc.: 67.19%] [G loss: 0.853327]\n",
      "epoch:12 step:11422 [D loss: 0.674549, acc.: 56.25%] [G loss: 0.853529]\n",
      "epoch:12 step:11423 [D loss: 0.649471, acc.: 68.75%] [G loss: 0.891173]\n",
      "epoch:12 step:11424 [D loss: 0.664285, acc.: 60.94%] [G loss: 0.820284]\n",
      "epoch:12 step:11425 [D loss: 0.698509, acc.: 57.81%] [G loss: 0.880250]\n",
      "epoch:12 step:11426 [D loss: 0.646412, acc.: 58.59%] [G loss: 0.870065]\n",
      "epoch:12 step:11427 [D loss: 0.665043, acc.: 58.59%] [G loss: 0.841878]\n",
      "epoch:12 step:11428 [D loss: 0.694810, acc.: 50.00%] [G loss: 0.851062]\n",
      "epoch:12 step:11429 [D loss: 0.679737, acc.: 49.22%] [G loss: 0.857500]\n",
      "epoch:12 step:11430 [D loss: 0.667798, acc.: 56.25%] [G loss: 0.880874]\n",
      "epoch:12 step:11431 [D loss: 0.648156, acc.: 60.94%] [G loss: 0.855416]\n",
      "epoch:12 step:11432 [D loss: 0.698241, acc.: 53.91%] [G loss: 0.792756]\n",
      "epoch:12 step:11433 [D loss: 0.700246, acc.: 48.44%] [G loss: 0.818755]\n",
      "epoch:12 step:11434 [D loss: 0.679130, acc.: 60.16%] [G loss: 0.858038]\n",
      "epoch:12 step:11435 [D loss: 0.643072, acc.: 64.84%] [G loss: 0.812741]\n",
      "epoch:12 step:11436 [D loss: 0.668152, acc.: 57.03%] [G loss: 0.884417]\n",
      "epoch:12 step:11437 [D loss: 0.640855, acc.: 61.72%] [G loss: 0.884912]\n",
      "epoch:12 step:11438 [D loss: 0.724519, acc.: 50.78%] [G loss: 0.876452]\n",
      "epoch:12 step:11439 [D loss: 0.656019, acc.: 60.94%] [G loss: 0.840603]\n",
      "epoch:12 step:11440 [D loss: 0.652720, acc.: 63.28%] [G loss: 0.845997]\n",
      "epoch:12 step:11441 [D loss: 0.619195, acc.: 68.75%] [G loss: 0.815335]\n",
      "epoch:12 step:11442 [D loss: 0.649980, acc.: 65.62%] [G loss: 0.868271]\n",
      "epoch:12 step:11443 [D loss: 0.684722, acc.: 58.59%] [G loss: 0.852662]\n",
      "epoch:12 step:11444 [D loss: 0.657431, acc.: 57.03%] [G loss: 0.880660]\n",
      "epoch:12 step:11445 [D loss: 0.640969, acc.: 60.16%] [G loss: 0.920524]\n",
      "epoch:12 step:11446 [D loss: 0.601380, acc.: 74.22%] [G loss: 0.890422]\n",
      "epoch:12 step:11447 [D loss: 0.695511, acc.: 57.03%] [G loss: 0.886192]\n",
      "epoch:12 step:11448 [D loss: 0.659487, acc.: 57.81%] [G loss: 0.855123]\n",
      "epoch:12 step:11449 [D loss: 0.664580, acc.: 59.38%] [G loss: 0.853915]\n",
      "epoch:12 step:11450 [D loss: 0.695197, acc.: 56.25%] [G loss: 0.843358]\n",
      "epoch:12 step:11451 [D loss: 0.658670, acc.: 59.38%] [G loss: 0.871780]\n",
      "epoch:12 step:11452 [D loss: 0.660751, acc.: 58.59%] [G loss: 0.895607]\n",
      "epoch:12 step:11453 [D loss: 0.680792, acc.: 61.72%] [G loss: 0.856788]\n",
      "epoch:12 step:11454 [D loss: 0.647303, acc.: 66.41%] [G loss: 0.870470]\n",
      "epoch:12 step:11455 [D loss: 0.670637, acc.: 58.59%] [G loss: 0.893867]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11456 [D loss: 0.672339, acc.: 58.59%] [G loss: 0.897282]\n",
      "epoch:12 step:11457 [D loss: 0.684079, acc.: 56.25%] [G loss: 0.934622]\n",
      "epoch:12 step:11458 [D loss: 0.665557, acc.: 58.59%] [G loss: 0.864348]\n",
      "epoch:12 step:11459 [D loss: 0.696871, acc.: 57.03%] [G loss: 0.844664]\n",
      "epoch:12 step:11460 [D loss: 0.677125, acc.: 55.47%] [G loss: 0.823509]\n",
      "epoch:12 step:11461 [D loss: 0.657779, acc.: 63.28%] [G loss: 0.896393]\n",
      "epoch:12 step:11462 [D loss: 0.711538, acc.: 50.00%] [G loss: 0.857677]\n",
      "epoch:12 step:11463 [D loss: 0.685501, acc.: 55.47%] [G loss: 0.863734]\n",
      "epoch:12 step:11464 [D loss: 0.673777, acc.: 59.38%] [G loss: 0.862826]\n",
      "epoch:12 step:11465 [D loss: 0.668160, acc.: 60.16%] [G loss: 0.875780]\n",
      "epoch:12 step:11466 [D loss: 0.690413, acc.: 54.69%] [G loss: 0.859404]\n",
      "epoch:12 step:11467 [D loss: 0.645399, acc.: 64.84%] [G loss: 0.848800]\n",
      "epoch:12 step:11468 [D loss: 0.678009, acc.: 53.91%] [G loss: 0.829632]\n",
      "epoch:12 step:11469 [D loss: 0.675148, acc.: 53.91%] [G loss: 0.842880]\n",
      "epoch:12 step:11470 [D loss: 0.672083, acc.: 57.81%] [G loss: 0.875921]\n",
      "epoch:12 step:11471 [D loss: 0.684458, acc.: 57.03%] [G loss: 0.832298]\n",
      "epoch:12 step:11472 [D loss: 0.662975, acc.: 54.69%] [G loss: 0.826961]\n",
      "epoch:12 step:11473 [D loss: 0.653556, acc.: 67.19%] [G loss: 0.900277]\n",
      "epoch:12 step:11474 [D loss: 0.683876, acc.: 58.59%] [G loss: 0.865768]\n",
      "epoch:12 step:11475 [D loss: 0.664610, acc.: 60.94%] [G loss: 0.878823]\n",
      "epoch:12 step:11476 [D loss: 0.661333, acc.: 62.50%] [G loss: 0.864669]\n",
      "epoch:12 step:11477 [D loss: 0.667693, acc.: 61.72%] [G loss: 0.819283]\n",
      "epoch:12 step:11478 [D loss: 0.673267, acc.: 53.91%] [G loss: 0.850140]\n",
      "epoch:12 step:11479 [D loss: 0.683432, acc.: 54.69%] [G loss: 0.835415]\n",
      "epoch:12 step:11480 [D loss: 0.682739, acc.: 59.38%] [G loss: 0.827707]\n",
      "epoch:12 step:11481 [D loss: 0.684104, acc.: 53.12%] [G loss: 0.831956]\n",
      "epoch:12 step:11482 [D loss: 0.672017, acc.: 57.03%] [G loss: 0.833118]\n",
      "epoch:12 step:11483 [D loss: 0.682446, acc.: 57.03%] [G loss: 0.820971]\n",
      "epoch:12 step:11484 [D loss: 0.712283, acc.: 51.56%] [G loss: 0.799497]\n",
      "epoch:12 step:11485 [D loss: 0.630835, acc.: 67.19%] [G loss: 0.860438]\n",
      "epoch:12 step:11486 [D loss: 0.695490, acc.: 50.78%] [G loss: 0.859001]\n",
      "epoch:12 step:11487 [D loss: 0.654788, acc.: 62.50%] [G loss: 0.824301]\n",
      "epoch:12 step:11488 [D loss: 0.677112, acc.: 63.28%] [G loss: 0.826387]\n",
      "epoch:12 step:11489 [D loss: 0.655621, acc.: 62.50%] [G loss: 0.877019]\n",
      "epoch:12 step:11490 [D loss: 0.694820, acc.: 50.78%] [G loss: 0.856312]\n",
      "epoch:12 step:11491 [D loss: 0.682403, acc.: 60.16%] [G loss: 0.846528]\n",
      "epoch:12 step:11492 [D loss: 0.665978, acc.: 59.38%] [G loss: 0.842855]\n",
      "epoch:12 step:11493 [D loss: 0.651221, acc.: 64.06%] [G loss: 0.831435]\n",
      "epoch:12 step:11494 [D loss: 0.636357, acc.: 65.62%] [G loss: 0.867959]\n",
      "epoch:12 step:11495 [D loss: 0.658927, acc.: 63.28%] [G loss: 0.885699]\n",
      "epoch:12 step:11496 [D loss: 0.663136, acc.: 52.34%] [G loss: 0.873910]\n",
      "epoch:12 step:11497 [D loss: 0.648717, acc.: 63.28%] [G loss: 0.923624]\n",
      "epoch:12 step:11498 [D loss: 0.652692, acc.: 60.16%] [G loss: 0.834517]\n",
      "epoch:12 step:11499 [D loss: 0.667740, acc.: 61.72%] [G loss: 0.822539]\n",
      "epoch:12 step:11500 [D loss: 0.670446, acc.: 57.03%] [G loss: 0.801994]\n",
      "epoch:12 step:11501 [D loss: 0.680854, acc.: 59.38%] [G loss: 0.817531]\n",
      "epoch:12 step:11502 [D loss: 0.677191, acc.: 55.47%] [G loss: 0.843483]\n",
      "epoch:12 step:11503 [D loss: 0.684333, acc.: 56.25%] [G loss: 0.866488]\n",
      "epoch:12 step:11504 [D loss: 0.694674, acc.: 57.81%] [G loss: 0.875893]\n",
      "epoch:12 step:11505 [D loss: 0.693651, acc.: 60.16%] [G loss: 0.846923]\n",
      "epoch:12 step:11506 [D loss: 0.701414, acc.: 53.91%] [G loss: 0.824128]\n",
      "epoch:12 step:11507 [D loss: 0.667182, acc.: 57.81%] [G loss: 0.857058]\n",
      "epoch:12 step:11508 [D loss: 0.696777, acc.: 52.34%] [G loss: 0.812760]\n",
      "epoch:12 step:11509 [D loss: 0.643509, acc.: 60.16%] [G loss: 0.840199]\n",
      "epoch:12 step:11510 [D loss: 0.658184, acc.: 56.25%] [G loss: 0.837273]\n",
      "epoch:12 step:11511 [D loss: 0.673214, acc.: 52.34%] [G loss: 0.833509]\n",
      "epoch:12 step:11512 [D loss: 0.648179, acc.: 60.16%] [G loss: 0.836724]\n",
      "epoch:12 step:11513 [D loss: 0.656403, acc.: 66.41%] [G loss: 0.845142]\n",
      "epoch:12 step:11514 [D loss: 0.671034, acc.: 57.81%] [G loss: 0.862872]\n",
      "epoch:12 step:11515 [D loss: 0.646524, acc.: 60.94%] [G loss: 0.874760]\n",
      "epoch:12 step:11516 [D loss: 0.653020, acc.: 60.16%] [G loss: 0.889266]\n",
      "epoch:12 step:11517 [D loss: 0.700421, acc.: 54.69%] [G loss: 0.872443]\n",
      "epoch:12 step:11518 [D loss: 0.709806, acc.: 46.88%] [G loss: 0.814967]\n",
      "epoch:12 step:11519 [D loss: 0.678354, acc.: 58.59%] [G loss: 0.867864]\n",
      "epoch:12 step:11520 [D loss: 0.685089, acc.: 50.78%] [G loss: 0.860527]\n",
      "epoch:12 step:11521 [D loss: 0.676353, acc.: 50.00%] [G loss: 0.893937]\n",
      "epoch:12 step:11522 [D loss: 0.678096, acc.: 57.03%] [G loss: 0.834553]\n",
      "epoch:12 step:11523 [D loss: 0.678142, acc.: 59.38%] [G loss: 0.872829]\n",
      "epoch:12 step:11524 [D loss: 0.680318, acc.: 58.59%] [G loss: 0.843751]\n",
      "epoch:12 step:11525 [D loss: 0.672380, acc.: 59.38%] [G loss: 0.823850]\n",
      "epoch:12 step:11526 [D loss: 0.660816, acc.: 64.06%] [G loss: 0.877857]\n",
      "epoch:12 step:11527 [D loss: 0.657549, acc.: 62.50%] [G loss: 0.904554]\n",
      "epoch:12 step:11528 [D loss: 0.628449, acc.: 64.84%] [G loss: 0.879066]\n",
      "epoch:12 step:11529 [D loss: 0.631696, acc.: 65.62%] [G loss: 0.879498]\n",
      "epoch:12 step:11530 [D loss: 0.655672, acc.: 60.94%] [G loss: 0.899955]\n",
      "epoch:12 step:11531 [D loss: 0.659911, acc.: 58.59%] [G loss: 0.849531]\n",
      "epoch:12 step:11532 [D loss: 0.662170, acc.: 64.84%] [G loss: 0.844280]\n",
      "epoch:12 step:11533 [D loss: 0.676326, acc.: 57.03%] [G loss: 0.877652]\n",
      "epoch:12 step:11534 [D loss: 0.648183, acc.: 60.94%] [G loss: 0.838940]\n",
      "epoch:12 step:11535 [D loss: 0.693117, acc.: 55.47%] [G loss: 0.879640]\n",
      "epoch:12 step:11536 [D loss: 0.665253, acc.: 59.38%] [G loss: 0.748570]\n",
      "epoch:12 step:11537 [D loss: 0.676043, acc.: 57.81%] [G loss: 0.812406]\n",
      "epoch:12 step:11538 [D loss: 0.628625, acc.: 64.84%] [G loss: 0.830057]\n",
      "epoch:12 step:11539 [D loss: 0.704603, acc.: 53.12%] [G loss: 0.874978]\n",
      "epoch:12 step:11540 [D loss: 0.700603, acc.: 53.12%] [G loss: 0.847980]\n",
      "epoch:12 step:11541 [D loss: 0.667641, acc.: 60.16%] [G loss: 0.853682]\n",
      "epoch:12 step:11542 [D loss: 0.701935, acc.: 52.34%] [G loss: 0.853841]\n",
      "epoch:12 step:11543 [D loss: 0.698713, acc.: 53.12%] [G loss: 0.859874]\n",
      "epoch:12 step:11544 [D loss: 0.665777, acc.: 57.03%] [G loss: 0.940104]\n",
      "epoch:12 step:11545 [D loss: 0.667639, acc.: 60.16%] [G loss: 0.879761]\n",
      "epoch:12 step:11546 [D loss: 0.653611, acc.: 62.50%] [G loss: 0.879096]\n",
      "epoch:12 step:11547 [D loss: 0.673005, acc.: 54.69%] [G loss: 0.929786]\n",
      "epoch:12 step:11548 [D loss: 0.696943, acc.: 55.47%] [G loss: 0.872281]\n",
      "epoch:12 step:11549 [D loss: 0.680551, acc.: 55.47%] [G loss: 0.876905]\n",
      "epoch:12 step:11550 [D loss: 0.661589, acc.: 57.81%] [G loss: 0.864374]\n",
      "epoch:12 step:11551 [D loss: 0.702026, acc.: 53.12%] [G loss: 0.845042]\n",
      "epoch:12 step:11552 [D loss: 0.659843, acc.: 55.47%] [G loss: 0.862718]\n",
      "epoch:12 step:11553 [D loss: 0.643981, acc.: 62.50%] [G loss: 0.831301]\n",
      "epoch:12 step:11554 [D loss: 0.694709, acc.: 58.59%] [G loss: 0.866968]\n",
      "epoch:12 step:11555 [D loss: 0.673536, acc.: 55.47%] [G loss: 0.844018]\n",
      "epoch:12 step:11556 [D loss: 0.701080, acc.: 51.56%] [G loss: 0.870005]\n",
      "epoch:12 step:11557 [D loss: 0.671963, acc.: 57.81%] [G loss: 0.846803]\n",
      "epoch:12 step:11558 [D loss: 0.635187, acc.: 64.84%] [G loss: 0.806240]\n",
      "epoch:12 step:11559 [D loss: 0.635541, acc.: 67.19%] [G loss: 0.852641]\n",
      "epoch:12 step:11560 [D loss: 0.654154, acc.: 60.94%] [G loss: 0.848959]\n",
      "epoch:12 step:11561 [D loss: 0.668539, acc.: 63.28%] [G loss: 0.867858]\n",
      "epoch:12 step:11562 [D loss: 0.673212, acc.: 56.25%] [G loss: 0.878932]\n",
      "epoch:12 step:11563 [D loss: 0.676675, acc.: 56.25%] [G loss: 0.876817]\n",
      "epoch:12 step:11564 [D loss: 0.654665, acc.: 62.50%] [G loss: 0.906808]\n",
      "epoch:12 step:11565 [D loss: 0.677953, acc.: 55.47%] [G loss: 0.848569]\n",
      "epoch:12 step:11566 [D loss: 0.681986, acc.: 57.81%] [G loss: 0.810508]\n",
      "epoch:12 step:11567 [D loss: 0.667699, acc.: 65.62%] [G loss: 0.887634]\n",
      "epoch:12 step:11568 [D loss: 0.673963, acc.: 56.25%] [G loss: 0.828647]\n",
      "epoch:12 step:11569 [D loss: 0.625869, acc.: 65.62%] [G loss: 0.775275]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11570 [D loss: 0.668653, acc.: 54.69%] [G loss: 0.840118]\n",
      "epoch:12 step:11571 [D loss: 0.656201, acc.: 56.25%] [G loss: 0.851715]\n",
      "epoch:12 step:11572 [D loss: 0.650918, acc.: 57.81%] [G loss: 0.868529]\n",
      "epoch:12 step:11573 [D loss: 0.676194, acc.: 57.03%] [G loss: 0.885479]\n",
      "epoch:12 step:11574 [D loss: 0.658247, acc.: 57.81%] [G loss: 0.858896]\n",
      "epoch:12 step:11575 [D loss: 0.702767, acc.: 55.47%] [G loss: 0.888679]\n",
      "epoch:12 step:11576 [D loss: 0.642274, acc.: 62.50%] [G loss: 0.858239]\n",
      "epoch:12 step:11577 [D loss: 0.710094, acc.: 55.47%] [G loss: 0.827263]\n",
      "epoch:12 step:11578 [D loss: 0.669835, acc.: 56.25%] [G loss: 0.876178]\n",
      "epoch:12 step:11579 [D loss: 0.706828, acc.: 46.88%] [G loss: 0.819589]\n",
      "epoch:12 step:11580 [D loss: 0.642301, acc.: 59.38%] [G loss: 0.864744]\n",
      "epoch:12 step:11581 [D loss: 0.666854, acc.: 61.72%] [G loss: 0.842103]\n",
      "epoch:12 step:11582 [D loss: 0.671737, acc.: 53.12%] [G loss: 0.848468]\n",
      "epoch:12 step:11583 [D loss: 0.678175, acc.: 53.91%] [G loss: 0.838830]\n",
      "epoch:12 step:11584 [D loss: 0.668713, acc.: 55.47%] [G loss: 0.803368]\n",
      "epoch:12 step:11585 [D loss: 0.673132, acc.: 63.28%] [G loss: 0.848661]\n",
      "epoch:12 step:11586 [D loss: 0.630822, acc.: 66.41%] [G loss: 0.855356]\n",
      "epoch:12 step:11587 [D loss: 0.689110, acc.: 59.38%] [G loss: 0.806756]\n",
      "epoch:12 step:11588 [D loss: 0.649440, acc.: 63.28%] [G loss: 0.799741]\n",
      "epoch:12 step:11589 [D loss: 0.669702, acc.: 54.69%] [G loss: 0.887214]\n",
      "epoch:12 step:11590 [D loss: 0.686997, acc.: 53.12%] [G loss: 0.840133]\n",
      "epoch:12 step:11591 [D loss: 0.668358, acc.: 55.47%] [G loss: 0.805914]\n",
      "epoch:12 step:11592 [D loss: 0.669275, acc.: 60.16%] [G loss: 0.838703]\n",
      "epoch:12 step:11593 [D loss: 0.661954, acc.: 60.16%] [G loss: 0.839608]\n",
      "epoch:12 step:11594 [D loss: 0.657153, acc.: 63.28%] [G loss: 0.864849]\n",
      "epoch:12 step:11595 [D loss: 0.654445, acc.: 62.50%] [G loss: 0.874988]\n",
      "epoch:12 step:11596 [D loss: 0.669193, acc.: 58.59%] [G loss: 0.833404]\n",
      "epoch:12 step:11597 [D loss: 0.647316, acc.: 58.59%] [G loss: 0.857506]\n",
      "epoch:12 step:11598 [D loss: 0.664058, acc.: 63.28%] [G loss: 0.859862]\n",
      "epoch:12 step:11599 [D loss: 0.647950, acc.: 65.62%] [G loss: 0.881717]\n",
      "epoch:12 step:11600 [D loss: 0.698174, acc.: 49.22%] [G loss: 0.796930]\n",
      "##############\n",
      "[ 2.76169625  2.4816456   2.19515798  3.69259987  1.17881228 10.27426719\n",
      "  2.76277891  3.5652074   4.28768336  7.14868929]\n",
      "##########\n",
      "epoch:12 step:11601 [D loss: 0.649841, acc.: 61.72%] [G loss: 0.875589]\n",
      "epoch:12 step:11602 [D loss: 0.650305, acc.: 60.94%] [G loss: 0.864345]\n",
      "epoch:12 step:11603 [D loss: 0.665939, acc.: 54.69%] [G loss: 0.823034]\n",
      "epoch:12 step:11604 [D loss: 0.666762, acc.: 57.03%] [G loss: 0.814395]\n",
      "epoch:12 step:11605 [D loss: 0.684637, acc.: 54.69%] [G loss: 0.832808]\n",
      "epoch:12 step:11606 [D loss: 0.684659, acc.: 55.47%] [G loss: 0.896497]\n",
      "epoch:12 step:11607 [D loss: 0.676669, acc.: 59.38%] [G loss: 0.841284]\n",
      "epoch:12 step:11608 [D loss: 0.694518, acc.: 50.00%] [G loss: 0.852849]\n",
      "epoch:12 step:11609 [D loss: 0.704435, acc.: 51.56%] [G loss: 0.826409]\n",
      "epoch:12 step:11610 [D loss: 0.694646, acc.: 47.66%] [G loss: 0.854819]\n",
      "epoch:12 step:11611 [D loss: 0.682022, acc.: 52.34%] [G loss: 0.848073]\n",
      "epoch:12 step:11612 [D loss: 0.660404, acc.: 62.50%] [G loss: 0.843585]\n",
      "epoch:12 step:11613 [D loss: 0.699247, acc.: 57.03%] [G loss: 0.801031]\n",
      "epoch:12 step:11614 [D loss: 0.702311, acc.: 47.66%] [G loss: 0.838037]\n",
      "epoch:12 step:11615 [D loss: 0.683153, acc.: 50.78%] [G loss: 0.854805]\n",
      "epoch:12 step:11616 [D loss: 0.651188, acc.: 67.19%] [G loss: 0.829205]\n",
      "epoch:12 step:11617 [D loss: 0.670083, acc.: 58.59%] [G loss: 0.864298]\n",
      "epoch:12 step:11618 [D loss: 0.669806, acc.: 56.25%] [G loss: 0.796237]\n",
      "epoch:12 step:11619 [D loss: 0.681152, acc.: 56.25%] [G loss: 0.830831]\n",
      "epoch:12 step:11620 [D loss: 0.672034, acc.: 54.69%] [G loss: 0.834728]\n",
      "epoch:12 step:11621 [D loss: 0.680962, acc.: 55.47%] [G loss: 0.865302]\n",
      "epoch:12 step:11622 [D loss: 0.632473, acc.: 63.28%] [G loss: 0.862462]\n",
      "epoch:12 step:11623 [D loss: 0.648784, acc.: 64.06%] [G loss: 0.826063]\n",
      "epoch:12 step:11624 [D loss: 0.658033, acc.: 62.50%] [G loss: 0.809502]\n",
      "epoch:12 step:11625 [D loss: 0.676616, acc.: 61.72%] [G loss: 0.874480]\n",
      "epoch:12 step:11626 [D loss: 0.635425, acc.: 69.53%] [G loss: 0.888446]\n",
      "epoch:12 step:11627 [D loss: 0.643605, acc.: 67.19%] [G loss: 0.865020]\n",
      "epoch:12 step:11628 [D loss: 0.680427, acc.: 58.59%] [G loss: 0.883416]\n",
      "epoch:12 step:11629 [D loss: 0.685956, acc.: 53.91%] [G loss: 0.793668]\n",
      "epoch:12 step:11630 [D loss: 0.679971, acc.: 51.56%] [G loss: 0.827544]\n",
      "epoch:12 step:11631 [D loss: 0.677448, acc.: 60.94%] [G loss: 0.798415]\n",
      "epoch:12 step:11632 [D loss: 0.708957, acc.: 48.44%] [G loss: 0.796834]\n",
      "epoch:12 step:11633 [D loss: 0.645300, acc.: 63.28%] [G loss: 0.819688]\n",
      "epoch:12 step:11634 [D loss: 0.672491, acc.: 57.81%] [G loss: 0.861475]\n",
      "epoch:12 step:11635 [D loss: 0.690264, acc.: 50.00%] [G loss: 0.809911]\n",
      "epoch:12 step:11636 [D loss: 0.665266, acc.: 57.81%] [G loss: 0.841821]\n",
      "epoch:12 step:11637 [D loss: 0.705776, acc.: 52.34%] [G loss: 0.801597]\n",
      "epoch:12 step:11638 [D loss: 0.668205, acc.: 59.38%] [G loss: 0.829405]\n",
      "epoch:12 step:11639 [D loss: 0.676539, acc.: 57.81%] [G loss: 0.798637]\n",
      "epoch:12 step:11640 [D loss: 0.685699, acc.: 57.81%] [G loss: 0.837777]\n",
      "epoch:12 step:11641 [D loss: 0.677924, acc.: 57.81%] [G loss: 0.792558]\n",
      "epoch:12 step:11642 [D loss: 0.675535, acc.: 55.47%] [G loss: 0.844509]\n",
      "epoch:12 step:11643 [D loss: 0.644458, acc.: 67.19%] [G loss: 0.859973]\n",
      "epoch:12 step:11644 [D loss: 0.660461, acc.: 57.81%] [G loss: 0.816152]\n",
      "epoch:12 step:11645 [D loss: 0.642241, acc.: 57.81%] [G loss: 0.862015]\n",
      "epoch:12 step:11646 [D loss: 0.636865, acc.: 66.41%] [G loss: 0.854820]\n",
      "epoch:12 step:11647 [D loss: 0.639980, acc.: 64.06%] [G loss: 0.881256]\n",
      "epoch:12 step:11648 [D loss: 0.654319, acc.: 60.94%] [G loss: 0.903871]\n",
      "epoch:12 step:11649 [D loss: 0.644852, acc.: 64.84%] [G loss: 0.844802]\n",
      "epoch:12 step:11650 [D loss: 0.665344, acc.: 60.94%] [G loss: 0.814023]\n",
      "epoch:12 step:11651 [D loss: 0.668584, acc.: 56.25%] [G loss: 0.835169]\n",
      "epoch:12 step:11652 [D loss: 0.691523, acc.: 49.22%] [G loss: 0.864496]\n",
      "epoch:12 step:11653 [D loss: 0.680166, acc.: 53.12%] [G loss: 0.862936]\n",
      "epoch:12 step:11654 [D loss: 0.668458, acc.: 61.72%] [G loss: 0.876070]\n",
      "epoch:12 step:11655 [D loss: 0.661917, acc.: 59.38%] [G loss: 0.858087]\n",
      "epoch:12 step:11656 [D loss: 0.695597, acc.: 59.38%] [G loss: 0.794051]\n",
      "epoch:12 step:11657 [D loss: 0.686834, acc.: 55.47%] [G loss: 0.864606]\n",
      "epoch:12 step:11658 [D loss: 0.665314, acc.: 57.81%] [G loss: 0.844614]\n",
      "epoch:12 step:11659 [D loss: 0.634460, acc.: 63.28%] [G loss: 0.863848]\n",
      "epoch:12 step:11660 [D loss: 0.645548, acc.: 65.62%] [G loss: 0.826377]\n",
      "epoch:12 step:11661 [D loss: 0.634559, acc.: 65.62%] [G loss: 0.852661]\n",
      "epoch:12 step:11662 [D loss: 0.678884, acc.: 57.81%] [G loss: 0.832363]\n",
      "epoch:12 step:11663 [D loss: 0.651416, acc.: 63.28%] [G loss: 0.850899]\n",
      "epoch:12 step:11664 [D loss: 0.662949, acc.: 56.25%] [G loss: 0.807075]\n",
      "epoch:12 step:11665 [D loss: 0.641942, acc.: 64.06%] [G loss: 0.792340]\n",
      "epoch:12 step:11666 [D loss: 0.671066, acc.: 57.03%] [G loss: 0.803470]\n",
      "epoch:12 step:11667 [D loss: 0.641495, acc.: 69.53%] [G loss: 0.840135]\n",
      "epoch:12 step:11668 [D loss: 0.674296, acc.: 56.25%] [G loss: 0.872501]\n",
      "epoch:12 step:11669 [D loss: 0.660484, acc.: 60.16%] [G loss: 0.909306]\n",
      "epoch:12 step:11670 [D loss: 0.654915, acc.: 64.06%] [G loss: 0.859156]\n",
      "epoch:12 step:11671 [D loss: 0.698281, acc.: 50.78%] [G loss: 0.884854]\n",
      "epoch:12 step:11672 [D loss: 0.682997, acc.: 61.72%] [G loss: 0.865630]\n",
      "epoch:12 step:11673 [D loss: 0.680867, acc.: 57.81%] [G loss: 0.795927]\n",
      "epoch:12 step:11674 [D loss: 0.661316, acc.: 60.16%] [G loss: 0.787346]\n",
      "epoch:12 step:11675 [D loss: 0.688416, acc.: 58.59%] [G loss: 0.826973]\n",
      "epoch:12 step:11676 [D loss: 0.699980, acc.: 50.78%] [G loss: 0.909009]\n",
      "epoch:12 step:11677 [D loss: 0.669023, acc.: 58.59%] [G loss: 0.900617]\n",
      "epoch:12 step:11678 [D loss: 0.698141, acc.: 53.12%] [G loss: 0.906335]\n",
      "epoch:12 step:11679 [D loss: 0.673713, acc.: 59.38%] [G loss: 0.803184]\n",
      "epoch:12 step:11680 [D loss: 0.659815, acc.: 57.81%] [G loss: 0.804209]\n",
      "epoch:12 step:11681 [D loss: 0.683268, acc.: 54.69%] [G loss: 0.806449]\n",
      "epoch:12 step:11682 [D loss: 0.669669, acc.: 57.03%] [G loss: 0.857494]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11683 [D loss: 0.652584, acc.: 60.94%] [G loss: 0.862606]\n",
      "epoch:12 step:11684 [D loss: 0.670966, acc.: 60.16%] [G loss: 0.869010]\n",
      "epoch:12 step:11685 [D loss: 0.670977, acc.: 61.72%] [G loss: 0.856420]\n",
      "epoch:12 step:11686 [D loss: 0.655456, acc.: 60.16%] [G loss: 0.838492]\n",
      "epoch:12 step:11687 [D loss: 0.672406, acc.: 63.28%] [G loss: 0.884247]\n",
      "epoch:12 step:11688 [D loss: 0.658498, acc.: 62.50%] [G loss: 0.849408]\n",
      "epoch:12 step:11689 [D loss: 0.654096, acc.: 67.97%] [G loss: 0.819765]\n",
      "epoch:12 step:11690 [D loss: 0.694324, acc.: 47.66%] [G loss: 0.822530]\n",
      "epoch:12 step:11691 [D loss: 0.677269, acc.: 55.47%] [G loss: 0.820218]\n",
      "epoch:12 step:11692 [D loss: 0.701106, acc.: 50.78%] [G loss: 0.807662]\n",
      "epoch:12 step:11693 [D loss: 0.652906, acc.: 57.81%] [G loss: 0.821789]\n",
      "epoch:12 step:11694 [D loss: 0.671478, acc.: 54.69%] [G loss: 0.816646]\n",
      "epoch:12 step:11695 [D loss: 0.628590, acc.: 67.97%] [G loss: 0.854535]\n",
      "epoch:12 step:11696 [D loss: 0.665253, acc.: 58.59%] [G loss: 0.830882]\n",
      "epoch:12 step:11697 [D loss: 0.657868, acc.: 60.16%] [G loss: 0.814268]\n",
      "epoch:12 step:11698 [D loss: 0.650058, acc.: 62.50%] [G loss: 0.831622]\n",
      "epoch:12 step:11699 [D loss: 0.671202, acc.: 57.81%] [G loss: 0.857444]\n",
      "epoch:12 step:11700 [D loss: 0.678029, acc.: 62.50%] [G loss: 0.806901]\n",
      "epoch:12 step:11701 [D loss: 0.678238, acc.: 53.12%] [G loss: 0.828893]\n",
      "epoch:12 step:11702 [D loss: 0.669931, acc.: 60.94%] [G loss: 0.797776]\n",
      "epoch:12 step:11703 [D loss: 0.635680, acc.: 64.06%] [G loss: 0.814164]\n",
      "epoch:12 step:11704 [D loss: 0.632652, acc.: 65.62%] [G loss: 0.814450]\n",
      "epoch:12 step:11705 [D loss: 0.681703, acc.: 61.72%] [G loss: 0.825241]\n",
      "epoch:12 step:11706 [D loss: 0.683466, acc.: 50.78%] [G loss: 0.826694]\n",
      "epoch:12 step:11707 [D loss: 0.649901, acc.: 62.50%] [G loss: 0.810762]\n",
      "epoch:12 step:11708 [D loss: 0.699571, acc.: 47.66%] [G loss: 0.876083]\n",
      "epoch:12 step:11709 [D loss: 0.684961, acc.: 53.12%] [G loss: 0.789284]\n",
      "epoch:12 step:11710 [D loss: 0.668788, acc.: 58.59%] [G loss: 0.867543]\n",
      "epoch:12 step:11711 [D loss: 0.684780, acc.: 60.16%] [G loss: 0.868283]\n",
      "epoch:12 step:11712 [D loss: 0.684019, acc.: 56.25%] [G loss: 0.877685]\n",
      "epoch:12 step:11713 [D loss: 0.661440, acc.: 50.78%] [G loss: 0.862415]\n",
      "epoch:12 step:11714 [D loss: 0.685847, acc.: 53.91%] [G loss: 0.835511]\n",
      "epoch:12 step:11715 [D loss: 0.650513, acc.: 66.41%] [G loss: 0.840361]\n",
      "epoch:12 step:11716 [D loss: 0.657667, acc.: 66.41%] [G loss: 0.820822]\n",
      "epoch:12 step:11717 [D loss: 0.673242, acc.: 59.38%] [G loss: 0.823659]\n",
      "epoch:12 step:11718 [D loss: 0.651550, acc.: 64.84%] [G loss: 0.856782]\n",
      "epoch:12 step:11719 [D loss: 0.650914, acc.: 59.38%] [G loss: 0.855739]\n",
      "epoch:12 step:11720 [D loss: 0.667247, acc.: 61.72%] [G loss: 0.866820]\n",
      "epoch:12 step:11721 [D loss: 0.668930, acc.: 64.06%] [G loss: 0.818109]\n",
      "epoch:12 step:11722 [D loss: 0.695940, acc.: 53.12%] [G loss: 0.828439]\n",
      "epoch:12 step:11723 [D loss: 0.661062, acc.: 57.81%] [G loss: 0.796844]\n",
      "epoch:12 step:11724 [D loss: 0.668972, acc.: 57.81%] [G loss: 0.800686]\n",
      "epoch:12 step:11725 [D loss: 0.646136, acc.: 61.72%] [G loss: 0.773713]\n",
      "epoch:12 step:11726 [D loss: 0.640661, acc.: 64.84%] [G loss: 0.768973]\n",
      "epoch:12 step:11727 [D loss: 0.683082, acc.: 57.03%] [G loss: 0.858297]\n",
      "epoch:12 step:11728 [D loss: 0.709274, acc.: 51.56%] [G loss: 0.805286]\n",
      "epoch:12 step:11729 [D loss: 0.696849, acc.: 49.22%] [G loss: 0.857921]\n",
      "epoch:12 step:11730 [D loss: 0.656584, acc.: 55.47%] [G loss: 0.827963]\n",
      "epoch:12 step:11731 [D loss: 0.679408, acc.: 53.12%] [G loss: 0.848676]\n",
      "epoch:12 step:11732 [D loss: 0.622288, acc.: 68.75%] [G loss: 0.851032]\n",
      "epoch:12 step:11733 [D loss: 0.647607, acc.: 62.50%] [G loss: 0.866919]\n",
      "epoch:12 step:11734 [D loss: 0.660490, acc.: 61.72%] [G loss: 0.843678]\n",
      "epoch:12 step:11735 [D loss: 0.654879, acc.: 60.16%] [G loss: 0.833230]\n",
      "epoch:12 step:11736 [D loss: 0.645295, acc.: 65.62%] [G loss: 0.822598]\n",
      "epoch:12 step:11737 [D loss: 0.675289, acc.: 59.38%] [G loss: 0.839370]\n",
      "epoch:12 step:11738 [D loss: 0.654169, acc.: 57.81%] [G loss: 0.872001]\n",
      "epoch:12 step:11739 [D loss: 0.659512, acc.: 61.72%] [G loss: 0.841732]\n",
      "epoch:12 step:11740 [D loss: 0.674864, acc.: 56.25%] [G loss: 0.787250]\n",
      "epoch:12 step:11741 [D loss: 0.657174, acc.: 60.16%] [G loss: 0.849081]\n",
      "epoch:12 step:11742 [D loss: 0.683375, acc.: 57.81%] [G loss: 0.806203]\n",
      "epoch:12 step:11743 [D loss: 0.698704, acc.: 50.00%] [G loss: 0.818327]\n",
      "epoch:12 step:11744 [D loss: 0.688769, acc.: 49.22%] [G loss: 0.892448]\n",
      "epoch:12 step:11745 [D loss: 0.655863, acc.: 60.16%] [G loss: 0.849524]\n",
      "epoch:12 step:11746 [D loss: 0.668008, acc.: 57.03%] [G loss: 0.889804]\n",
      "epoch:12 step:11747 [D loss: 0.652868, acc.: 62.50%] [G loss: 0.874893]\n",
      "epoch:12 step:11748 [D loss: 0.696602, acc.: 52.34%] [G loss: 0.814148]\n",
      "epoch:12 step:11749 [D loss: 0.693007, acc.: 56.25%] [G loss: 0.824810]\n",
      "epoch:12 step:11750 [D loss: 0.674305, acc.: 51.56%] [G loss: 0.855341]\n",
      "epoch:12 step:11751 [D loss: 0.653938, acc.: 64.06%] [G loss: 0.879370]\n",
      "epoch:12 step:11752 [D loss: 0.679296, acc.: 59.38%] [G loss: 0.878561]\n",
      "epoch:12 step:11753 [D loss: 0.646915, acc.: 61.72%] [G loss: 0.877588]\n",
      "epoch:12 step:11754 [D loss: 0.668537, acc.: 57.03%] [G loss: 0.878046]\n",
      "epoch:12 step:11755 [D loss: 0.648817, acc.: 62.50%] [G loss: 0.845028]\n",
      "epoch:12 step:11756 [D loss: 0.651077, acc.: 60.16%] [G loss: 0.866804]\n",
      "epoch:12 step:11757 [D loss: 0.670400, acc.: 57.03%] [G loss: 0.881249]\n",
      "epoch:12 step:11758 [D loss: 0.694051, acc.: 50.78%] [G loss: 0.859084]\n",
      "epoch:12 step:11759 [D loss: 0.656373, acc.: 62.50%] [G loss: 0.831037]\n",
      "epoch:12 step:11760 [D loss: 0.657377, acc.: 62.50%] [G loss: 0.831375]\n",
      "epoch:12 step:11761 [D loss: 0.672956, acc.: 58.59%] [G loss: 0.861683]\n",
      "epoch:12 step:11762 [D loss: 0.656009, acc.: 60.94%] [G loss: 0.871572]\n",
      "epoch:12 step:11763 [D loss: 0.666902, acc.: 62.50%] [G loss: 0.838293]\n",
      "epoch:12 step:11764 [D loss: 0.649157, acc.: 60.16%] [G loss: 0.887670]\n",
      "epoch:12 step:11765 [D loss: 0.660911, acc.: 59.38%] [G loss: 0.909218]\n",
      "epoch:12 step:11766 [D loss: 0.655608, acc.: 57.81%] [G loss: 0.882546]\n",
      "epoch:12 step:11767 [D loss: 0.650661, acc.: 60.16%] [G loss: 0.928617]\n",
      "epoch:12 step:11768 [D loss: 0.646457, acc.: 53.91%] [G loss: 0.868546]\n",
      "epoch:12 step:11769 [D loss: 0.666119, acc.: 58.59%] [G loss: 0.892681]\n",
      "epoch:12 step:11770 [D loss: 0.684971, acc.: 58.59%] [G loss: 0.866556]\n",
      "epoch:12 step:11771 [D loss: 0.667533, acc.: 54.69%] [G loss: 0.834384]\n",
      "epoch:12 step:11772 [D loss: 0.665785, acc.: 63.28%] [G loss: 0.848123]\n",
      "epoch:12 step:11773 [D loss: 0.664374, acc.: 61.72%] [G loss: 0.851589]\n",
      "epoch:12 step:11774 [D loss: 0.642756, acc.: 64.06%] [G loss: 0.847102]\n",
      "epoch:12 step:11775 [D loss: 0.685040, acc.: 59.38%] [G loss: 0.886891]\n",
      "epoch:12 step:11776 [D loss: 0.677709, acc.: 57.81%] [G loss: 0.837567]\n",
      "epoch:12 step:11777 [D loss: 0.673754, acc.: 60.94%] [G loss: 0.889199]\n",
      "epoch:12 step:11778 [D loss: 0.667348, acc.: 64.06%] [G loss: 0.830071]\n",
      "epoch:12 step:11779 [D loss: 0.660454, acc.: 57.81%] [G loss: 0.845348]\n",
      "epoch:12 step:11780 [D loss: 0.673817, acc.: 60.16%] [G loss: 0.846302]\n",
      "epoch:12 step:11781 [D loss: 0.674769, acc.: 56.25%] [G loss: 0.818587]\n",
      "epoch:12 step:11782 [D loss: 0.681289, acc.: 57.03%] [G loss: 0.817618]\n",
      "epoch:12 step:11783 [D loss: 0.670418, acc.: 57.81%] [G loss: 0.802808]\n",
      "epoch:12 step:11784 [D loss: 0.644301, acc.: 61.72%] [G loss: 0.825072]\n",
      "epoch:12 step:11785 [D loss: 0.639155, acc.: 60.94%] [G loss: 0.827893]\n",
      "epoch:12 step:11786 [D loss: 0.646135, acc.: 66.41%] [G loss: 0.826309]\n",
      "epoch:12 step:11787 [D loss: 0.649071, acc.: 60.16%] [G loss: 0.850894]\n",
      "epoch:12 step:11788 [D loss: 0.626611, acc.: 71.09%] [G loss: 0.831239]\n",
      "epoch:12 step:11789 [D loss: 0.679762, acc.: 54.69%] [G loss: 0.876297]\n",
      "epoch:12 step:11790 [D loss: 0.682386, acc.: 55.47%] [G loss: 0.836845]\n",
      "epoch:12 step:11791 [D loss: 0.671309, acc.: 58.59%] [G loss: 0.833734]\n",
      "epoch:12 step:11792 [D loss: 0.667063, acc.: 54.69%] [G loss: 0.871344]\n",
      "epoch:12 step:11793 [D loss: 0.700359, acc.: 55.47%] [G loss: 0.871545]\n",
      "epoch:12 step:11794 [D loss: 0.642420, acc.: 62.50%] [G loss: 0.840907]\n",
      "epoch:12 step:11795 [D loss: 0.678111, acc.: 53.91%] [G loss: 0.814521]\n",
      "epoch:12 step:11796 [D loss: 0.672072, acc.: 56.25%] [G loss: 0.801589]\n",
      "epoch:12 step:11797 [D loss: 0.684442, acc.: 53.12%] [G loss: 0.815680]\n",
      "epoch:12 step:11798 [D loss: 0.657217, acc.: 64.06%] [G loss: 0.787017]\n",
      "epoch:12 step:11799 [D loss: 0.662432, acc.: 54.69%] [G loss: 0.849431]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11800 [D loss: 0.662701, acc.: 59.38%] [G loss: 0.811669]\n",
      "##############\n",
      "[2.8981711  2.34788714 2.20455787 3.70270947 1.41244447 7.81702963\n",
      " 2.96504129 3.69963982 4.20127872 5.37891264]\n",
      "##########\n",
      "epoch:12 step:11801 [D loss: 0.633731, acc.: 67.97%] [G loss: 0.836093]\n",
      "epoch:12 step:11802 [D loss: 0.664900, acc.: 57.81%] [G loss: 0.845456]\n",
      "epoch:12 step:11803 [D loss: 0.700561, acc.: 53.12%] [G loss: 0.833338]\n",
      "epoch:12 step:11804 [D loss: 0.680897, acc.: 52.34%] [G loss: 0.821640]\n",
      "epoch:12 step:11805 [D loss: 0.704911, acc.: 46.09%] [G loss: 0.825073]\n",
      "epoch:12 step:11806 [D loss: 0.678388, acc.: 54.69%] [G loss: 0.833400]\n",
      "epoch:12 step:11807 [D loss: 0.645044, acc.: 60.16%] [G loss: 0.804502]\n",
      "epoch:12 step:11808 [D loss: 0.678794, acc.: 58.59%] [G loss: 0.841107]\n",
      "epoch:12 step:11809 [D loss: 0.660539, acc.: 55.47%] [G loss: 0.893952]\n",
      "epoch:12 step:11810 [D loss: 0.677627, acc.: 61.72%] [G loss: 0.872466]\n",
      "epoch:12 step:11811 [D loss: 0.670079, acc.: 57.03%] [G loss: 0.880768]\n",
      "epoch:12 step:11812 [D loss: 0.688294, acc.: 52.34%] [G loss: 0.858932]\n",
      "epoch:12 step:11813 [D loss: 0.662078, acc.: 59.38%] [G loss: 0.871957]\n",
      "epoch:12 step:11814 [D loss: 0.682776, acc.: 55.47%] [G loss: 0.847987]\n",
      "epoch:12 step:11815 [D loss: 0.642831, acc.: 64.84%] [G loss: 0.788030]\n",
      "epoch:12 step:11816 [D loss: 0.674476, acc.: 59.38%] [G loss: 0.861706]\n",
      "epoch:12 step:11817 [D loss: 0.673102, acc.: 56.25%] [G loss: 0.814238]\n",
      "epoch:12 step:11818 [D loss: 0.678973, acc.: 57.81%] [G loss: 0.816715]\n",
      "epoch:12 step:11819 [D loss: 0.668080, acc.: 57.03%] [G loss: 0.838480]\n",
      "epoch:12 step:11820 [D loss: 0.657761, acc.: 64.06%] [G loss: 0.905610]\n",
      "epoch:12 step:11821 [D loss: 0.676219, acc.: 53.12%] [G loss: 0.846093]\n",
      "epoch:12 step:11822 [D loss: 0.656089, acc.: 59.38%] [G loss: 0.833748]\n",
      "epoch:12 step:11823 [D loss: 0.674808, acc.: 60.94%] [G loss: 0.841087]\n",
      "epoch:12 step:11824 [D loss: 0.676629, acc.: 64.06%] [G loss: 0.851015]\n",
      "epoch:12 step:11825 [D loss: 0.670195, acc.: 59.38%] [G loss: 0.819829]\n",
      "epoch:12 step:11826 [D loss: 0.670423, acc.: 59.38%] [G loss: 0.861783]\n",
      "epoch:12 step:11827 [D loss: 0.688058, acc.: 54.69%] [G loss: 0.854833]\n",
      "epoch:12 step:11828 [D loss: 0.624141, acc.: 64.84%] [G loss: 0.889528]\n",
      "epoch:12 step:11829 [D loss: 0.663705, acc.: 59.38%] [G loss: 0.836557]\n",
      "epoch:12 step:11830 [D loss: 0.683704, acc.: 54.69%] [G loss: 0.781393]\n",
      "epoch:12 step:11831 [D loss: 0.670064, acc.: 57.81%] [G loss: 0.875863]\n",
      "epoch:12 step:11832 [D loss: 0.656011, acc.: 66.41%] [G loss: 0.896666]\n",
      "epoch:12 step:11833 [D loss: 0.647727, acc.: 62.50%] [G loss: 0.799103]\n",
      "epoch:12 step:11834 [D loss: 0.681999, acc.: 57.03%] [G loss: 0.852879]\n",
      "epoch:12 step:11835 [D loss: 0.682638, acc.: 57.81%] [G loss: 0.854813]\n",
      "epoch:12 step:11836 [D loss: 0.651924, acc.: 68.75%] [G loss: 0.881239]\n",
      "epoch:12 step:11837 [D loss: 0.707918, acc.: 42.97%] [G loss: 0.869040]\n",
      "epoch:12 step:11838 [D loss: 0.618084, acc.: 64.84%] [G loss: 0.879066]\n",
      "epoch:12 step:11839 [D loss: 0.615428, acc.: 71.09%] [G loss: 0.902671]\n",
      "epoch:12 step:11840 [D loss: 0.678200, acc.: 59.38%] [G loss: 0.881893]\n",
      "epoch:12 step:11841 [D loss: 0.678587, acc.: 62.50%] [G loss: 0.842149]\n",
      "epoch:12 step:11842 [D loss: 0.672383, acc.: 58.59%] [G loss: 0.856136]\n",
      "epoch:12 step:11843 [D loss: 0.652464, acc.: 60.16%] [G loss: 0.847860]\n",
      "epoch:12 step:11844 [D loss: 0.662540, acc.: 60.16%] [G loss: 0.853057]\n",
      "epoch:12 step:11845 [D loss: 0.691631, acc.: 52.34%] [G loss: 0.861339]\n",
      "epoch:12 step:11846 [D loss: 0.634852, acc.: 59.38%] [G loss: 0.873819]\n",
      "epoch:12 step:11847 [D loss: 0.656738, acc.: 57.03%] [G loss: 0.855271]\n",
      "epoch:12 step:11848 [D loss: 0.659410, acc.: 59.38%] [G loss: 0.819286]\n",
      "epoch:12 step:11849 [D loss: 0.676478, acc.: 61.72%] [G loss: 0.829594]\n",
      "epoch:12 step:11850 [D loss: 0.595404, acc.: 72.66%] [G loss: 0.844213]\n",
      "epoch:12 step:11851 [D loss: 0.662503, acc.: 60.94%] [G loss: 0.856695]\n",
      "epoch:12 step:11852 [D loss: 0.697395, acc.: 53.91%] [G loss: 0.892370]\n",
      "epoch:12 step:11853 [D loss: 0.632575, acc.: 66.41%] [G loss: 0.864638]\n",
      "epoch:12 step:11854 [D loss: 0.650435, acc.: 62.50%] [G loss: 0.860110]\n",
      "epoch:12 step:11855 [D loss: 0.652099, acc.: 60.94%] [G loss: 0.886779]\n",
      "epoch:12 step:11856 [D loss: 0.685211, acc.: 53.12%] [G loss: 0.844711]\n",
      "epoch:12 step:11857 [D loss: 0.645214, acc.: 67.97%] [G loss: 0.874144]\n",
      "epoch:12 step:11858 [D loss: 0.659017, acc.: 57.03%] [G loss: 0.830876]\n",
      "epoch:12 step:11859 [D loss: 0.671985, acc.: 55.47%] [G loss: 0.840976]\n",
      "epoch:12 step:11860 [D loss: 0.640350, acc.: 61.72%] [G loss: 0.918911]\n",
      "epoch:12 step:11861 [D loss: 0.666092, acc.: 53.91%] [G loss: 0.877406]\n",
      "epoch:12 step:11862 [D loss: 0.641368, acc.: 61.72%] [G loss: 0.868788]\n",
      "epoch:12 step:11863 [D loss: 0.700876, acc.: 57.81%] [G loss: 0.880539]\n",
      "epoch:12 step:11864 [D loss: 0.642488, acc.: 60.94%] [G loss: 0.887481]\n",
      "epoch:12 step:11865 [D loss: 0.676064, acc.: 54.69%] [G loss: 0.877439]\n",
      "epoch:12 step:11866 [D loss: 0.694072, acc.: 55.47%] [G loss: 0.857341]\n",
      "epoch:12 step:11867 [D loss: 0.678590, acc.: 56.25%] [G loss: 0.853849]\n",
      "epoch:12 step:11868 [D loss: 0.673067, acc.: 55.47%] [G loss: 0.837362]\n",
      "epoch:12 step:11869 [D loss: 0.645024, acc.: 61.72%] [G loss: 0.889148]\n",
      "epoch:12 step:11870 [D loss: 0.689182, acc.: 47.66%] [G loss: 0.807153]\n",
      "epoch:12 step:11871 [D loss: 0.668329, acc.: 54.69%] [G loss: 0.815077]\n",
      "epoch:12 step:11872 [D loss: 0.710134, acc.: 47.66%] [G loss: 0.867551]\n",
      "epoch:12 step:11873 [D loss: 0.677758, acc.: 58.59%] [G loss: 0.842313]\n",
      "epoch:12 step:11874 [D loss: 0.642539, acc.: 68.75%] [G loss: 0.843777]\n",
      "epoch:12 step:11875 [D loss: 0.656612, acc.: 64.06%] [G loss: 0.817670]\n",
      "epoch:12 step:11876 [D loss: 0.660501, acc.: 60.94%] [G loss: 0.843938]\n",
      "epoch:12 step:11877 [D loss: 0.638291, acc.: 64.84%] [G loss: 0.858594]\n",
      "epoch:12 step:11878 [D loss: 0.674377, acc.: 56.25%] [G loss: 0.889799]\n",
      "epoch:12 step:11879 [D loss: 0.665377, acc.: 60.94%] [G loss: 0.835389]\n",
      "epoch:12 step:11880 [D loss: 0.660624, acc.: 60.16%] [G loss: 0.831274]\n",
      "epoch:12 step:11881 [D loss: 0.611527, acc.: 69.53%] [G loss: 0.875034]\n",
      "epoch:12 step:11882 [D loss: 0.663478, acc.: 58.59%] [G loss: 0.877571]\n",
      "epoch:12 step:11883 [D loss: 0.667584, acc.: 58.59%] [G loss: 0.884989]\n",
      "epoch:12 step:11884 [D loss: 0.671155, acc.: 63.28%] [G loss: 0.892941]\n",
      "epoch:12 step:11885 [D loss: 0.683148, acc.: 55.47%] [G loss: 0.893610]\n",
      "epoch:12 step:11886 [D loss: 0.663279, acc.: 59.38%] [G loss: 0.870525]\n",
      "epoch:12 step:11887 [D loss: 0.686133, acc.: 56.25%] [G loss: 0.854053]\n",
      "epoch:12 step:11888 [D loss: 0.666485, acc.: 59.38%] [G loss: 0.849420]\n",
      "epoch:12 step:11889 [D loss: 0.635229, acc.: 61.72%] [G loss: 0.813840]\n",
      "epoch:12 step:11890 [D loss: 0.672907, acc.: 59.38%] [G loss: 0.863101]\n",
      "epoch:12 step:11891 [D loss: 0.664556, acc.: 61.72%] [G loss: 0.830058]\n",
      "epoch:12 step:11892 [D loss: 0.647457, acc.: 63.28%] [G loss: 0.849009]\n",
      "epoch:12 step:11893 [D loss: 0.685981, acc.: 52.34%] [G loss: 0.807767]\n",
      "epoch:12 step:11894 [D loss: 0.694960, acc.: 53.12%] [G loss: 0.833801]\n",
      "epoch:12 step:11895 [D loss: 0.658563, acc.: 56.25%] [G loss: 0.835266]\n",
      "epoch:12 step:11896 [D loss: 0.634241, acc.: 66.41%] [G loss: 0.863042]\n",
      "epoch:12 step:11897 [D loss: 0.664162, acc.: 57.03%] [G loss: 0.865109]\n",
      "epoch:12 step:11898 [D loss: 0.663726, acc.: 53.91%] [G loss: 0.839404]\n",
      "epoch:12 step:11899 [D loss: 0.691219, acc.: 55.47%] [G loss: 0.886853]\n",
      "epoch:12 step:11900 [D loss: 0.654612, acc.: 63.28%] [G loss: 0.927850]\n",
      "epoch:12 step:11901 [D loss: 0.683683, acc.: 52.34%] [G loss: 0.835967]\n",
      "epoch:12 step:11902 [D loss: 0.688295, acc.: 54.69%] [G loss: 0.867997]\n",
      "epoch:12 step:11903 [D loss: 0.666900, acc.: 57.81%] [G loss: 0.836199]\n",
      "epoch:12 step:11904 [D loss: 0.662027, acc.: 60.16%] [G loss: 0.836908]\n",
      "epoch:12 step:11905 [D loss: 0.643690, acc.: 61.72%] [G loss: 0.909151]\n",
      "epoch:12 step:11906 [D loss: 0.682934, acc.: 57.03%] [G loss: 0.845348]\n",
      "epoch:12 step:11907 [D loss: 0.652772, acc.: 64.06%] [G loss: 0.850420]\n",
      "epoch:12 step:11908 [D loss: 0.677811, acc.: 59.38%] [G loss: 0.864071]\n",
      "epoch:12 step:11909 [D loss: 0.701804, acc.: 54.69%] [G loss: 0.827590]\n",
      "epoch:12 step:11910 [D loss: 0.660504, acc.: 59.38%] [G loss: 0.866647]\n",
      "epoch:12 step:11911 [D loss: 0.651728, acc.: 62.50%] [G loss: 0.852699]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:11912 [D loss: 0.644571, acc.: 60.94%] [G loss: 0.895621]\n",
      "epoch:12 step:11913 [D loss: 0.655357, acc.: 59.38%] [G loss: 0.905144]\n",
      "epoch:12 step:11914 [D loss: 0.666277, acc.: 58.59%] [G loss: 0.925496]\n",
      "epoch:12 step:11915 [D loss: 0.645813, acc.: 62.50%] [G loss: 0.919400]\n",
      "epoch:12 step:11916 [D loss: 0.672610, acc.: 53.91%] [G loss: 0.866798]\n",
      "epoch:12 step:11917 [D loss: 0.689300, acc.: 51.56%] [G loss: 0.858706]\n",
      "epoch:12 step:11918 [D loss: 0.675912, acc.: 55.47%] [G loss: 0.842109]\n",
      "epoch:12 step:11919 [D loss: 0.674301, acc.: 57.03%] [G loss: 0.847225]\n",
      "epoch:12 step:11920 [D loss: 0.664759, acc.: 57.03%] [G loss: 0.821796]\n",
      "epoch:12 step:11921 [D loss: 0.670891, acc.: 57.03%] [G loss: 0.838748]\n",
      "epoch:12 step:11922 [D loss: 0.679688, acc.: 54.69%] [G loss: 0.891754]\n",
      "epoch:12 step:11923 [D loss: 0.669096, acc.: 58.59%] [G loss: 0.834670]\n",
      "epoch:12 step:11924 [D loss: 0.668793, acc.: 55.47%] [G loss: 0.873530]\n",
      "epoch:12 step:11925 [D loss: 0.688820, acc.: 48.44%] [G loss: 0.822264]\n",
      "epoch:12 step:11926 [D loss: 0.671113, acc.: 57.03%] [G loss: 0.826377]\n",
      "epoch:12 step:11927 [D loss: 0.646658, acc.: 64.84%] [G loss: 0.828443]\n",
      "epoch:12 step:11928 [D loss: 0.672608, acc.: 53.91%] [G loss: 0.853032]\n",
      "epoch:12 step:11929 [D loss: 0.656645, acc.: 62.50%] [G loss: 0.874629]\n",
      "epoch:12 step:11930 [D loss: 0.678565, acc.: 56.25%] [G loss: 0.873264]\n",
      "epoch:12 step:11931 [D loss: 0.631596, acc.: 69.53%] [G loss: 0.823825]\n",
      "epoch:12 step:11932 [D loss: 0.634732, acc.: 64.06%] [G loss: 0.841178]\n",
      "epoch:12 step:11933 [D loss: 0.660172, acc.: 54.69%] [G loss: 0.905395]\n",
      "epoch:12 step:11934 [D loss: 0.704193, acc.: 53.91%] [G loss: 0.869269]\n",
      "epoch:12 step:11935 [D loss: 0.669203, acc.: 57.81%] [G loss: 0.883553]\n",
      "epoch:12 step:11936 [D loss: 0.675731, acc.: 54.69%] [G loss: 0.800287]\n",
      "epoch:12 step:11937 [D loss: 0.671252, acc.: 61.72%] [G loss: 0.840653]\n",
      "epoch:12 step:11938 [D loss: 0.660383, acc.: 61.72%] [G loss: 0.867807]\n",
      "epoch:12 step:11939 [D loss: 0.670799, acc.: 54.69%] [G loss: 0.855792]\n",
      "epoch:12 step:11940 [D loss: 0.668029, acc.: 59.38%] [G loss: 0.807599]\n",
      "epoch:12 step:11941 [D loss: 0.695908, acc.: 50.00%] [G loss: 0.846506]\n",
      "epoch:12 step:11942 [D loss: 0.660049, acc.: 60.94%] [G loss: 0.854938]\n",
      "epoch:12 step:11943 [D loss: 0.656965, acc.: 63.28%] [G loss: 0.819750]\n",
      "epoch:12 step:11944 [D loss: 0.675575, acc.: 51.56%] [G loss: 0.882161]\n",
      "epoch:12 step:11945 [D loss: 0.667733, acc.: 59.38%] [G loss: 0.933031]\n",
      "epoch:12 step:11946 [D loss: 0.659624, acc.: 56.25%] [G loss: 0.897773]\n",
      "epoch:12 step:11947 [D loss: 0.689537, acc.: 53.12%] [G loss: 0.908915]\n",
      "epoch:12 step:11948 [D loss: 0.685203, acc.: 57.81%] [G loss: 0.897368]\n",
      "epoch:12 step:11949 [D loss: 0.649696, acc.: 62.50%] [G loss: 0.891223]\n",
      "epoch:12 step:11950 [D loss: 0.683779, acc.: 57.03%] [G loss: 0.884973]\n",
      "epoch:12 step:11951 [D loss: 0.682976, acc.: 54.69%] [G loss: 0.830413]\n",
      "epoch:12 step:11952 [D loss: 0.684519, acc.: 57.03%] [G loss: 0.886501]\n",
      "epoch:12 step:11953 [D loss: 0.679077, acc.: 51.56%] [G loss: 0.912959]\n",
      "epoch:12 step:11954 [D loss: 0.645715, acc.: 64.84%] [G loss: 0.875803]\n",
      "epoch:12 step:11955 [D loss: 0.683078, acc.: 54.69%] [G loss: 0.853743]\n",
      "epoch:12 step:11956 [D loss: 0.672800, acc.: 59.38%] [G loss: 0.836487]\n",
      "epoch:12 step:11957 [D loss: 0.695026, acc.: 53.91%] [G loss: 0.821644]\n",
      "epoch:12 step:11958 [D loss: 0.691832, acc.: 51.56%] [G loss: 0.800989]\n",
      "epoch:12 step:11959 [D loss: 0.685153, acc.: 53.91%] [G loss: 0.862452]\n",
      "epoch:12 step:11960 [D loss: 0.675043, acc.: 57.03%] [G loss: 0.801735]\n",
      "epoch:12 step:11961 [D loss: 0.681582, acc.: 55.47%] [G loss: 0.827871]\n",
      "epoch:12 step:11962 [D loss: 0.648459, acc.: 64.84%] [G loss: 0.906012]\n",
      "epoch:12 step:11963 [D loss: 0.664779, acc.: 55.47%] [G loss: 0.830105]\n",
      "epoch:12 step:11964 [D loss: 0.671469, acc.: 60.94%] [G loss: 0.847959]\n",
      "epoch:12 step:11965 [D loss: 0.688993, acc.: 52.34%] [G loss: 0.832436]\n",
      "epoch:12 step:11966 [D loss: 0.650617, acc.: 60.94%] [G loss: 0.873521]\n",
      "epoch:12 step:11967 [D loss: 0.633688, acc.: 60.94%] [G loss: 0.857325]\n",
      "epoch:12 step:11968 [D loss: 0.694005, acc.: 58.59%] [G loss: 0.871810]\n",
      "epoch:12 step:11969 [D loss: 0.633250, acc.: 66.41%] [G loss: 0.905822]\n",
      "epoch:12 step:11970 [D loss: 0.669205, acc.: 59.38%] [G loss: 0.845365]\n",
      "epoch:12 step:11971 [D loss: 0.636381, acc.: 64.84%] [G loss: 0.835336]\n",
      "epoch:12 step:11972 [D loss: 0.640743, acc.: 69.53%] [G loss: 0.819550]\n",
      "epoch:12 step:11973 [D loss: 0.683310, acc.: 60.16%] [G loss: 0.824104]\n",
      "epoch:12 step:11974 [D loss: 0.674972, acc.: 62.50%] [G loss: 0.835906]\n",
      "epoch:12 step:11975 [D loss: 0.683220, acc.: 64.06%] [G loss: 0.833457]\n",
      "epoch:12 step:11976 [D loss: 0.657169, acc.: 56.25%] [G loss: 0.878314]\n",
      "epoch:12 step:11977 [D loss: 0.658186, acc.: 60.16%] [G loss: 0.906613]\n",
      "epoch:12 step:11978 [D loss: 0.625747, acc.: 63.28%] [G loss: 0.914403]\n",
      "epoch:12 step:11979 [D loss: 0.674071, acc.: 61.72%] [G loss: 0.883293]\n",
      "epoch:12 step:11980 [D loss: 0.663447, acc.: 60.16%] [G loss: 0.825264]\n",
      "epoch:12 step:11981 [D loss: 0.662800, acc.: 59.38%] [G loss: 0.815609]\n",
      "epoch:12 step:11982 [D loss: 0.682241, acc.: 52.34%] [G loss: 0.880939]\n",
      "epoch:12 step:11983 [D loss: 0.670516, acc.: 53.12%] [G loss: 0.846962]\n",
      "epoch:12 step:11984 [D loss: 0.670595, acc.: 57.03%] [G loss: 0.872960]\n",
      "epoch:12 step:11985 [D loss: 0.662756, acc.: 57.81%] [G loss: 0.851503]\n",
      "epoch:12 step:11986 [D loss: 0.691154, acc.: 55.47%] [G loss: 0.831073]\n",
      "epoch:12 step:11987 [D loss: 0.676048, acc.: 50.78%] [G loss: 0.832477]\n",
      "epoch:12 step:11988 [D loss: 0.692085, acc.: 54.69%] [G loss: 0.826635]\n",
      "epoch:12 step:11989 [D loss: 0.667028, acc.: 60.16%] [G loss: 0.884161]\n",
      "epoch:12 step:11990 [D loss: 0.657534, acc.: 56.25%] [G loss: 0.798282]\n",
      "epoch:12 step:11991 [D loss: 0.671449, acc.: 53.12%] [G loss: 0.834592]\n",
      "epoch:12 step:11992 [D loss: 0.614585, acc.: 64.84%] [G loss: 0.844160]\n",
      "epoch:12 step:11993 [D loss: 0.673812, acc.: 55.47%] [G loss: 0.815305]\n",
      "epoch:12 step:11994 [D loss: 0.674949, acc.: 64.06%] [G loss: 0.850328]\n",
      "epoch:12 step:11995 [D loss: 0.644922, acc.: 61.72%] [G loss: 0.788765]\n",
      "epoch:12 step:11996 [D loss: 0.679930, acc.: 55.47%] [G loss: 0.833489]\n",
      "epoch:12 step:11997 [D loss: 0.656243, acc.: 57.81%] [G loss: 0.854731]\n",
      "epoch:12 step:11998 [D loss: 0.663695, acc.: 56.25%] [G loss: 0.899823]\n",
      "epoch:12 step:11999 [D loss: 0.674656, acc.: 57.03%] [G loss: 0.915934]\n",
      "epoch:12 step:12000 [D loss: 0.672014, acc.: 58.59%] [G loss: 0.885617]\n",
      "##############\n",
      "[3.06622924 2.22931974 2.16458612 3.73294165 1.11817582 7.39909632\n",
      " 2.44120007 4.25325284 4.21818656 6.03641554]\n",
      "##########\n",
      "epoch:12 step:12001 [D loss: 0.634910, acc.: 64.84%] [G loss: 0.876002]\n",
      "epoch:12 step:12002 [D loss: 0.696012, acc.: 53.12%] [G loss: 0.853417]\n",
      "epoch:12 step:12003 [D loss: 0.690638, acc.: 56.25%] [G loss: 0.870427]\n",
      "epoch:12 step:12004 [D loss: 0.677388, acc.: 58.59%] [G loss: 0.854441]\n",
      "epoch:12 step:12005 [D loss: 0.700406, acc.: 49.22%] [G loss: 0.821740]\n",
      "epoch:12 step:12006 [D loss: 0.683225, acc.: 55.47%] [G loss: 0.875934]\n",
      "epoch:12 step:12007 [D loss: 0.666620, acc.: 54.69%] [G loss: 0.886951]\n",
      "epoch:12 step:12008 [D loss: 0.645210, acc.: 65.62%] [G loss: 0.865880]\n",
      "epoch:12 step:12009 [D loss: 0.660920, acc.: 60.16%] [G loss: 0.819226]\n",
      "epoch:12 step:12010 [D loss: 0.656190, acc.: 63.28%] [G loss: 0.867679]\n",
      "epoch:12 step:12011 [D loss: 0.690380, acc.: 56.25%] [G loss: 0.838953]\n",
      "epoch:12 step:12012 [D loss: 0.651432, acc.: 67.97%] [G loss: 0.834515]\n",
      "epoch:12 step:12013 [D loss: 0.653035, acc.: 64.84%] [G loss: 0.785126]\n",
      "epoch:12 step:12014 [D loss: 0.676044, acc.: 55.47%] [G loss: 0.802636]\n",
      "epoch:12 step:12015 [D loss: 0.678962, acc.: 58.59%] [G loss: 0.820097]\n",
      "epoch:12 step:12016 [D loss: 0.633036, acc.: 64.06%] [G loss: 0.824001]\n",
      "epoch:12 step:12017 [D loss: 0.673531, acc.: 64.06%] [G loss: 0.794934]\n",
      "epoch:12 step:12018 [D loss: 0.641363, acc.: 64.06%] [G loss: 0.858272]\n",
      "epoch:12 step:12019 [D loss: 0.647905, acc.: 59.38%] [G loss: 0.865699]\n",
      "epoch:12 step:12020 [D loss: 0.680612, acc.: 54.69%] [G loss: 0.874594]\n",
      "epoch:12 step:12021 [D loss: 0.678367, acc.: 57.03%] [G loss: 0.907600]\n",
      "epoch:12 step:12022 [D loss: 0.641465, acc.: 67.19%] [G loss: 0.869187]\n",
      "epoch:12 step:12023 [D loss: 0.643439, acc.: 60.94%] [G loss: 0.850271]\n",
      "epoch:12 step:12024 [D loss: 0.695468, acc.: 59.38%] [G loss: 0.863518]\n",
      "epoch:12 step:12025 [D loss: 0.706287, acc.: 56.25%] [G loss: 0.847729]\n",
      "epoch:12 step:12026 [D loss: 0.649647, acc.: 59.38%] [G loss: 0.802363]\n",
      "epoch:12 step:12027 [D loss: 0.698344, acc.: 53.12%] [G loss: 0.869880]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:12028 [D loss: 0.654890, acc.: 61.72%] [G loss: 0.943811]\n",
      "epoch:12 step:12029 [D loss: 0.676826, acc.: 61.72%] [G loss: 0.949879]\n",
      "epoch:12 step:12030 [D loss: 0.713480, acc.: 47.66%] [G loss: 0.836725]\n",
      "epoch:12 step:12031 [D loss: 0.660627, acc.: 59.38%] [G loss: 0.828507]\n",
      "epoch:12 step:12032 [D loss: 0.661663, acc.: 53.12%] [G loss: 0.836662]\n",
      "epoch:12 step:12033 [D loss: 0.662247, acc.: 55.47%] [G loss: 0.849905]\n",
      "epoch:12 step:12034 [D loss: 0.652614, acc.: 61.72%] [G loss: 0.872753]\n",
      "epoch:12 step:12035 [D loss: 0.638148, acc.: 63.28%] [G loss: 0.845940]\n",
      "epoch:12 step:12036 [D loss: 0.659833, acc.: 57.03%] [G loss: 0.857288]\n",
      "epoch:12 step:12037 [D loss: 0.670277, acc.: 57.03%] [G loss: 0.848027]\n",
      "epoch:12 step:12038 [D loss: 0.621778, acc.: 67.97%] [G loss: 0.848748]\n",
      "epoch:12 step:12039 [D loss: 0.671426, acc.: 60.94%] [G loss: 0.854584]\n",
      "epoch:12 step:12040 [D loss: 0.693159, acc.: 52.34%] [G loss: 0.840612]\n",
      "epoch:12 step:12041 [D loss: 0.660074, acc.: 58.59%] [G loss: 0.834472]\n",
      "epoch:12 step:12042 [D loss: 0.686563, acc.: 57.81%] [G loss: 0.842616]\n",
      "epoch:12 step:12043 [D loss: 0.708014, acc.: 51.56%] [G loss: 0.877294]\n",
      "epoch:12 step:12044 [D loss: 0.665983, acc.: 54.69%] [G loss: 0.857703]\n",
      "epoch:12 step:12045 [D loss: 0.633039, acc.: 71.88%] [G loss: 0.866089]\n",
      "epoch:12 step:12046 [D loss: 0.684011, acc.: 57.03%] [G loss: 0.873954]\n",
      "epoch:12 step:12047 [D loss: 0.655716, acc.: 64.06%] [G loss: 0.826881]\n",
      "epoch:12 step:12048 [D loss: 0.705954, acc.: 57.03%] [G loss: 0.800214]\n",
      "epoch:12 step:12049 [D loss: 0.674889, acc.: 55.47%] [G loss: 0.804802]\n",
      "epoch:12 step:12050 [D loss: 0.675967, acc.: 55.47%] [G loss: 0.820180]\n",
      "epoch:12 step:12051 [D loss: 0.677570, acc.: 50.00%] [G loss: 0.870542]\n",
      "epoch:12 step:12052 [D loss: 0.651992, acc.: 59.38%] [G loss: 0.827596]\n",
      "epoch:12 step:12053 [D loss: 0.662995, acc.: 53.91%] [G loss: 0.885008]\n",
      "epoch:12 step:12054 [D loss: 0.671881, acc.: 60.94%] [G loss: 0.862346]\n",
      "epoch:12 step:12055 [D loss: 0.648801, acc.: 60.94%] [G loss: 0.843167]\n",
      "epoch:12 step:12056 [D loss: 0.685335, acc.: 63.28%] [G loss: 0.870300]\n",
      "epoch:12 step:12057 [D loss: 0.688452, acc.: 50.78%] [G loss: 0.898605]\n",
      "epoch:12 step:12058 [D loss: 0.646999, acc.: 60.94%] [G loss: 0.898221]\n",
      "epoch:12 step:12059 [D loss: 0.666666, acc.: 57.03%] [G loss: 0.869705]\n",
      "epoch:12 step:12060 [D loss: 0.634318, acc.: 61.72%] [G loss: 0.865211]\n",
      "epoch:12 step:12061 [D loss: 0.696289, acc.: 57.81%] [G loss: 0.843390]\n",
      "epoch:12 step:12062 [D loss: 0.687391, acc.: 53.12%] [G loss: 0.854030]\n",
      "epoch:12 step:12063 [D loss: 0.719158, acc.: 49.22%] [G loss: 0.865765]\n",
      "epoch:12 step:12064 [D loss: 0.666418, acc.: 56.25%] [G loss: 0.877460]\n",
      "epoch:12 step:12065 [D loss: 0.688085, acc.: 53.12%] [G loss: 0.851774]\n",
      "epoch:12 step:12066 [D loss: 0.661690, acc.: 63.28%] [G loss: 0.884697]\n",
      "epoch:12 step:12067 [D loss: 0.724457, acc.: 47.66%] [G loss: 0.842003]\n",
      "epoch:12 step:12068 [D loss: 0.655169, acc.: 63.28%] [G loss: 0.849324]\n",
      "epoch:12 step:12069 [D loss: 0.638722, acc.: 64.84%] [G loss: 0.856363]\n",
      "epoch:12 step:12070 [D loss: 0.636508, acc.: 66.41%] [G loss: 0.888631]\n",
      "epoch:12 step:12071 [D loss: 0.676981, acc.: 60.94%] [G loss: 0.844776]\n",
      "epoch:12 step:12072 [D loss: 0.661637, acc.: 60.94%] [G loss: 0.823803]\n",
      "epoch:12 step:12073 [D loss: 0.651617, acc.: 62.50%] [G loss: 0.875956]\n",
      "epoch:12 step:12074 [D loss: 0.675092, acc.: 51.56%] [G loss: 0.830198]\n",
      "epoch:12 step:12075 [D loss: 0.683256, acc.: 54.69%] [G loss: 0.868975]\n",
      "epoch:12 step:12076 [D loss: 0.684301, acc.: 51.56%] [G loss: 0.848439]\n",
      "epoch:12 step:12077 [D loss: 0.654926, acc.: 65.62%] [G loss: 0.893584]\n",
      "epoch:12 step:12078 [D loss: 0.688110, acc.: 58.59%] [G loss: 0.861824]\n",
      "epoch:12 step:12079 [D loss: 0.645238, acc.: 66.41%] [G loss: 0.822123]\n",
      "epoch:12 step:12080 [D loss: 0.656535, acc.: 64.84%] [G loss: 0.829649]\n",
      "epoch:12 step:12081 [D loss: 0.652139, acc.: 61.72%] [G loss: 0.830286]\n",
      "epoch:12 step:12082 [D loss: 0.652869, acc.: 57.81%] [G loss: 0.786822]\n",
      "epoch:12 step:12083 [D loss: 0.662936, acc.: 57.03%] [G loss: 0.844396]\n",
      "epoch:12 step:12084 [D loss: 0.682843, acc.: 54.69%] [G loss: 0.879052]\n",
      "epoch:12 step:12085 [D loss: 0.684362, acc.: 59.38%] [G loss: 0.851487]\n",
      "epoch:12 step:12086 [D loss: 0.698880, acc.: 56.25%] [G loss: 0.874329]\n",
      "epoch:12 step:12087 [D loss: 0.705703, acc.: 54.69%] [G loss: 0.815621]\n",
      "epoch:12 step:12088 [D loss: 0.664600, acc.: 64.84%] [G loss: 0.833338]\n",
      "epoch:12 step:12089 [D loss: 0.699268, acc.: 45.31%] [G loss: 0.843856]\n",
      "epoch:12 step:12090 [D loss: 0.664974, acc.: 60.94%] [G loss: 0.882167]\n",
      "epoch:12 step:12091 [D loss: 0.670586, acc.: 59.38%] [G loss: 0.856091]\n",
      "epoch:12 step:12092 [D loss: 0.664267, acc.: 57.03%] [G loss: 0.874057]\n",
      "epoch:12 step:12093 [D loss: 0.684957, acc.: 59.38%] [G loss: 0.895502]\n",
      "epoch:12 step:12094 [D loss: 0.682203, acc.: 61.72%] [G loss: 0.865205]\n",
      "epoch:12 step:12095 [D loss: 0.652349, acc.: 59.38%] [G loss: 0.894794]\n",
      "epoch:12 step:12096 [D loss: 0.647003, acc.: 61.72%] [G loss: 0.922577]\n",
      "epoch:12 step:12097 [D loss: 0.670190, acc.: 60.94%] [G loss: 0.877283]\n",
      "epoch:12 step:12098 [D loss: 0.668049, acc.: 58.59%] [G loss: 0.851520]\n",
      "epoch:12 step:12099 [D loss: 0.700869, acc.: 54.69%] [G loss: 0.832180]\n",
      "epoch:12 step:12100 [D loss: 0.608887, acc.: 67.19%] [G loss: 0.840045]\n",
      "epoch:12 step:12101 [D loss: 0.668439, acc.: 63.28%] [G loss: 0.874668]\n",
      "epoch:12 step:12102 [D loss: 0.670096, acc.: 62.50%] [G loss: 0.905076]\n",
      "epoch:12 step:12103 [D loss: 0.671068, acc.: 58.59%] [G loss: 0.859270]\n",
      "epoch:12 step:12104 [D loss: 0.673295, acc.: 57.03%] [G loss: 0.820450]\n",
      "epoch:12 step:12105 [D loss: 0.645156, acc.: 69.53%] [G loss: 0.883917]\n",
      "epoch:12 step:12106 [D loss: 0.653688, acc.: 64.84%] [G loss: 0.863147]\n",
      "epoch:12 step:12107 [D loss: 0.655390, acc.: 61.72%] [G loss: 0.873492]\n",
      "epoch:12 step:12108 [D loss: 0.674335, acc.: 57.81%] [G loss: 0.879214]\n",
      "epoch:12 step:12109 [D loss: 0.670789, acc.: 53.91%] [G loss: 0.842931]\n",
      "epoch:12 step:12110 [D loss: 0.679370, acc.: 53.12%] [G loss: 0.839871]\n",
      "epoch:12 step:12111 [D loss: 0.694997, acc.: 51.56%] [G loss: 0.819577]\n",
      "epoch:12 step:12112 [D loss: 0.677154, acc.: 53.12%] [G loss: 0.839770]\n",
      "epoch:12 step:12113 [D loss: 0.661494, acc.: 56.25%] [G loss: 0.829335]\n",
      "epoch:12 step:12114 [D loss: 0.689233, acc.: 53.12%] [G loss: 0.820790]\n",
      "epoch:12 step:12115 [D loss: 0.652889, acc.: 62.50%] [G loss: 0.845236]\n",
      "epoch:12 step:12116 [D loss: 0.677736, acc.: 56.25%] [G loss: 0.869311]\n",
      "epoch:12 step:12117 [D loss: 0.633556, acc.: 64.84%] [G loss: 0.880887]\n",
      "epoch:12 step:12118 [D loss: 0.718689, acc.: 58.59%] [G loss: 0.861956]\n",
      "epoch:12 step:12119 [D loss: 0.667544, acc.: 56.25%] [G loss: 0.870449]\n",
      "epoch:12 step:12120 [D loss: 0.678950, acc.: 55.47%] [G loss: 0.831441]\n",
      "epoch:12 step:12121 [D loss: 0.711698, acc.: 46.09%] [G loss: 0.858881]\n",
      "epoch:12 step:12122 [D loss: 0.671037, acc.: 52.34%] [G loss: 0.856731]\n",
      "epoch:12 step:12123 [D loss: 0.671709, acc.: 57.81%] [G loss: 0.802454]\n",
      "epoch:12 step:12124 [D loss: 0.679994, acc.: 57.03%] [G loss: 0.780249]\n",
      "epoch:12 step:12125 [D loss: 0.655005, acc.: 60.94%] [G loss: 0.813123]\n",
      "epoch:12 step:12126 [D loss: 0.642167, acc.: 67.19%] [G loss: 0.818077]\n",
      "epoch:12 step:12127 [D loss: 0.664889, acc.: 59.38%] [G loss: 0.848510]\n",
      "epoch:12 step:12128 [D loss: 0.650685, acc.: 62.50%] [G loss: 0.850664]\n",
      "epoch:12 step:12129 [D loss: 0.681522, acc.: 50.78%] [G loss: 0.835137]\n",
      "epoch:12 step:12130 [D loss: 0.671394, acc.: 59.38%] [G loss: 0.817024]\n",
      "epoch:12 step:12131 [D loss: 0.643217, acc.: 64.06%] [G loss: 0.841546]\n",
      "epoch:12 step:12132 [D loss: 0.622748, acc.: 67.97%] [G loss: 0.815187]\n",
      "epoch:12 step:12133 [D loss: 0.647464, acc.: 63.28%] [G loss: 0.834146]\n",
      "epoch:12 step:12134 [D loss: 0.668384, acc.: 52.34%] [G loss: 0.811843]\n",
      "epoch:12 step:12135 [D loss: 0.674619, acc.: 59.38%] [G loss: 0.818889]\n",
      "epoch:12 step:12136 [D loss: 0.690904, acc.: 53.91%] [G loss: 0.837266]\n",
      "epoch:12 step:12137 [D loss: 0.675763, acc.: 53.12%] [G loss: 0.844261]\n",
      "epoch:12 step:12138 [D loss: 0.657101, acc.: 59.38%] [G loss: 0.796324]\n",
      "epoch:12 step:12139 [D loss: 0.677467, acc.: 59.38%] [G loss: 0.857825]\n",
      "epoch:12 step:12140 [D loss: 0.661335, acc.: 62.50%] [G loss: 0.868245]\n",
      "epoch:12 step:12141 [D loss: 0.661289, acc.: 57.81%] [G loss: 0.817889]\n",
      "epoch:12 step:12142 [D loss: 0.704311, acc.: 50.78%] [G loss: 0.843034]\n",
      "epoch:12 step:12143 [D loss: 0.686164, acc.: 53.12%] [G loss: 0.821284]\n",
      "epoch:12 step:12144 [D loss: 0.681194, acc.: 50.78%] [G loss: 0.826178]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:12 step:12145 [D loss: 0.672550, acc.: 59.38%] [G loss: 0.850256]\n",
      "epoch:12 step:12146 [D loss: 0.639225, acc.: 60.94%] [G loss: 0.837067]\n",
      "epoch:12 step:12147 [D loss: 0.626088, acc.: 65.62%] [G loss: 0.856523]\n",
      "epoch:12 step:12148 [D loss: 0.636954, acc.: 69.53%] [G loss: 0.856044]\n",
      "epoch:12 step:12149 [D loss: 0.684711, acc.: 59.38%] [G loss: 0.850188]\n",
      "epoch:12 step:12150 [D loss: 0.648778, acc.: 67.97%] [G loss: 0.897372]\n",
      "epoch:12 step:12151 [D loss: 0.672575, acc.: 55.47%] [G loss: 0.840106]\n",
      "epoch:12 step:12152 [D loss: 0.695533, acc.: 51.56%] [G loss: 0.812247]\n",
      "epoch:12 step:12153 [D loss: 0.695941, acc.: 50.78%] [G loss: 0.836227]\n",
      "epoch:12 step:12154 [D loss: 0.666740, acc.: 60.16%] [G loss: 0.840147]\n",
      "epoch:12 step:12155 [D loss: 0.650871, acc.: 62.50%] [G loss: 0.915439]\n",
      "epoch:12 step:12156 [D loss: 0.682172, acc.: 56.25%] [G loss: 0.854537]\n",
      "epoch:12 step:12157 [D loss: 0.659152, acc.: 57.81%] [G loss: 0.874800]\n",
      "epoch:12 step:12158 [D loss: 0.676799, acc.: 60.16%] [G loss: 0.892569]\n",
      "epoch:12 step:12159 [D loss: 0.640904, acc.: 67.19%] [G loss: 0.793978]\n",
      "epoch:12 step:12160 [D loss: 0.675936, acc.: 55.47%] [G loss: 0.887309]\n",
      "epoch:12 step:12161 [D loss: 0.626032, acc.: 66.41%] [G loss: 0.849706]\n",
      "epoch:12 step:12162 [D loss: 0.642523, acc.: 63.28%] [G loss: 0.824713]\n",
      "epoch:12 step:12163 [D loss: 0.655927, acc.: 62.50%] [G loss: 0.864092]\n",
      "epoch:12 step:12164 [D loss: 0.670950, acc.: 59.38%] [G loss: 0.883133]\n",
      "epoch:12 step:12165 [D loss: 0.677478, acc.: 57.03%] [G loss: 0.814144]\n",
      "epoch:12 step:12166 [D loss: 0.660359, acc.: 60.16%] [G loss: 0.830421]\n",
      "epoch:12 step:12167 [D loss: 0.664454, acc.: 59.38%] [G loss: 0.855126]\n",
      "epoch:12 step:12168 [D loss: 0.667510, acc.: 57.03%] [G loss: 0.833417]\n",
      "epoch:12 step:12169 [D loss: 0.669158, acc.: 57.81%] [G loss: 0.835561]\n",
      "epoch:12 step:12170 [D loss: 0.659478, acc.: 59.38%] [G loss: 0.818836]\n",
      "epoch:12 step:12171 [D loss: 0.673293, acc.: 59.38%] [G loss: 0.829693]\n",
      "epoch:12 step:12172 [D loss: 0.637482, acc.: 62.50%] [G loss: 0.834992]\n",
      "epoch:12 step:12173 [D loss: 0.696755, acc.: 55.47%] [G loss: 0.854952]\n",
      "epoch:12 step:12174 [D loss: 0.654019, acc.: 64.06%] [G loss: 0.914129]\n",
      "epoch:12 step:12175 [D loss: 0.653490, acc.: 57.03%] [G loss: 0.855426]\n",
      "epoch:12 step:12176 [D loss: 0.663245, acc.: 62.50%] [G loss: 0.868347]\n",
      "epoch:12 step:12177 [D loss: 0.673422, acc.: 60.16%] [G loss: 0.805978]\n",
      "epoch:12 step:12178 [D loss: 0.662442, acc.: 62.50%] [G loss: 0.797764]\n",
      "epoch:12 step:12179 [D loss: 0.621995, acc.: 65.62%] [G loss: 0.810659]\n",
      "epoch:12 step:12180 [D loss: 0.654130, acc.: 62.50%] [G loss: 0.843519]\n",
      "epoch:12 step:12181 [D loss: 0.669341, acc.: 59.38%] [G loss: 0.827402]\n",
      "epoch:13 step:12182 [D loss: 0.687437, acc.: 57.03%] [G loss: 0.874779]\n",
      "epoch:13 step:12183 [D loss: 0.649290, acc.: 57.81%] [G loss: 0.842667]\n",
      "epoch:13 step:12184 [D loss: 0.684909, acc.: 58.59%] [G loss: 0.848349]\n",
      "epoch:13 step:12185 [D loss: 0.655769, acc.: 61.72%] [G loss: 0.880512]\n",
      "epoch:13 step:12186 [D loss: 0.654203, acc.: 60.16%] [G loss: 0.908224]\n",
      "epoch:13 step:12187 [D loss: 0.655833, acc.: 64.06%] [G loss: 0.905649]\n",
      "epoch:13 step:12188 [D loss: 0.674710, acc.: 53.91%] [G loss: 0.962141]\n",
      "epoch:13 step:12189 [D loss: 0.679360, acc.: 60.16%] [G loss: 0.841498]\n",
      "epoch:13 step:12190 [D loss: 0.706024, acc.: 53.12%] [G loss: 0.873724]\n",
      "epoch:13 step:12191 [D loss: 0.649330, acc.: 57.81%] [G loss: 0.876250]\n",
      "epoch:13 step:12192 [D loss: 0.626567, acc.: 64.84%] [G loss: 0.880992]\n",
      "epoch:13 step:12193 [D loss: 0.662122, acc.: 58.59%] [G loss: 0.855975]\n",
      "epoch:13 step:12194 [D loss: 0.631029, acc.: 64.84%] [G loss: 0.867830]\n",
      "epoch:13 step:12195 [D loss: 0.684625, acc.: 56.25%] [G loss: 0.863258]\n",
      "epoch:13 step:12196 [D loss: 0.661341, acc.: 61.72%] [G loss: 0.825966]\n",
      "epoch:13 step:12197 [D loss: 0.653712, acc.: 59.38%] [G loss: 0.853132]\n",
      "epoch:13 step:12198 [D loss: 0.624443, acc.: 67.97%] [G loss: 0.824975]\n",
      "epoch:13 step:12199 [D loss: 0.645567, acc.: 60.94%] [G loss: 0.826630]\n",
      "epoch:13 step:12200 [D loss: 0.681167, acc.: 54.69%] [G loss: 0.821816]\n",
      "##############\n",
      "[2.7746745  2.11587279 2.2372254  4.18954324 1.47629666 9.27426719\n",
      " 2.48168913 3.82604148 4.36520765 8.14868929]\n",
      "##########\n",
      "epoch:13 step:12201 [D loss: 0.689822, acc.: 53.12%] [G loss: 0.828435]\n",
      "epoch:13 step:12202 [D loss: 0.679878, acc.: 55.47%] [G loss: 0.876181]\n",
      "epoch:13 step:12203 [D loss: 0.680805, acc.: 60.94%] [G loss: 0.844852]\n",
      "epoch:13 step:12204 [D loss: 0.668666, acc.: 55.47%] [G loss: 0.872738]\n",
      "epoch:13 step:12205 [D loss: 0.671945, acc.: 58.59%] [G loss: 0.820832]\n",
      "epoch:13 step:12206 [D loss: 0.651079, acc.: 62.50%] [G loss: 0.851590]\n",
      "epoch:13 step:12207 [D loss: 0.694372, acc.: 55.47%] [G loss: 0.872463]\n",
      "epoch:13 step:12208 [D loss: 0.668502, acc.: 60.16%] [G loss: 0.873670]\n",
      "epoch:13 step:12209 [D loss: 0.639480, acc.: 62.50%] [G loss: 0.906734]\n",
      "epoch:13 step:12210 [D loss: 0.683696, acc.: 55.47%] [G loss: 0.877373]\n",
      "epoch:13 step:12211 [D loss: 0.680737, acc.: 56.25%] [G loss: 0.844307]\n",
      "epoch:13 step:12212 [D loss: 0.658896, acc.: 58.59%] [G loss: 0.875228]\n",
      "epoch:13 step:12213 [D loss: 0.650178, acc.: 61.72%] [G loss: 0.862735]\n",
      "epoch:13 step:12214 [D loss: 0.650910, acc.: 59.38%] [G loss: 0.861104]\n",
      "epoch:13 step:12215 [D loss: 0.683152, acc.: 53.91%] [G loss: 0.854758]\n",
      "epoch:13 step:12216 [D loss: 0.688751, acc.: 57.81%] [G loss: 0.873535]\n",
      "epoch:13 step:12217 [D loss: 0.657838, acc.: 63.28%] [G loss: 0.890671]\n",
      "epoch:13 step:12218 [D loss: 0.658453, acc.: 59.38%] [G loss: 0.846335]\n",
      "epoch:13 step:12219 [D loss: 0.689529, acc.: 54.69%] [G loss: 0.868919]\n",
      "epoch:13 step:12220 [D loss: 0.672783, acc.: 59.38%] [G loss: 0.936681]\n",
      "epoch:13 step:12221 [D loss: 0.691325, acc.: 56.25%] [G loss: 0.888315]\n",
      "epoch:13 step:12222 [D loss: 0.675475, acc.: 57.03%] [G loss: 0.898274]\n",
      "epoch:13 step:12223 [D loss: 0.656572, acc.: 60.16%] [G loss: 0.863230]\n",
      "epoch:13 step:12224 [D loss: 0.677215, acc.: 57.03%] [G loss: 0.814323]\n",
      "epoch:13 step:12225 [D loss: 0.649839, acc.: 62.50%] [G loss: 0.800888]\n",
      "epoch:13 step:12226 [D loss: 0.714354, acc.: 53.12%] [G loss: 0.811818]\n",
      "epoch:13 step:12227 [D loss: 0.687703, acc.: 54.69%] [G loss: 0.851833]\n",
      "epoch:13 step:12228 [D loss: 0.713250, acc.: 49.22%] [G loss: 0.870482]\n",
      "epoch:13 step:12229 [D loss: 0.635434, acc.: 65.62%] [G loss: 0.833872]\n",
      "epoch:13 step:12230 [D loss: 0.641522, acc.: 65.62%] [G loss: 0.805455]\n",
      "epoch:13 step:12231 [D loss: 0.624906, acc.: 69.53%] [G loss: 0.815394]\n",
      "epoch:13 step:12232 [D loss: 0.647696, acc.: 62.50%] [G loss: 0.820221]\n",
      "epoch:13 step:12233 [D loss: 0.659177, acc.: 59.38%] [G loss: 0.809913]\n",
      "epoch:13 step:12234 [D loss: 0.689399, acc.: 56.25%] [G loss: 0.858095]\n",
      "epoch:13 step:12235 [D loss: 0.627715, acc.: 67.97%] [G loss: 0.898970]\n",
      "epoch:13 step:12236 [D loss: 0.674801, acc.: 59.38%] [G loss: 0.837271]\n",
      "epoch:13 step:12237 [D loss: 0.657591, acc.: 62.50%] [G loss: 0.826761]\n",
      "epoch:13 step:12238 [D loss: 0.662076, acc.: 61.72%] [G loss: 0.850372]\n",
      "epoch:13 step:12239 [D loss: 0.673940, acc.: 60.16%] [G loss: 0.837250]\n",
      "epoch:13 step:12240 [D loss: 0.632509, acc.: 61.72%] [G loss: 0.879063]\n",
      "epoch:13 step:12241 [D loss: 0.662353, acc.: 62.50%] [G loss: 0.857816]\n",
      "epoch:13 step:12242 [D loss: 0.697295, acc.: 55.47%] [G loss: 0.899992]\n",
      "epoch:13 step:12243 [D loss: 0.655767, acc.: 60.16%] [G loss: 0.902310]\n",
      "epoch:13 step:12244 [D loss: 0.651352, acc.: 59.38%] [G loss: 0.927285]\n",
      "epoch:13 step:12245 [D loss: 0.639543, acc.: 63.28%] [G loss: 0.822581]\n",
      "epoch:13 step:12246 [D loss: 0.667517, acc.: 57.81%] [G loss: 0.883519]\n",
      "epoch:13 step:12247 [D loss: 0.633785, acc.: 63.28%] [G loss: 0.857489]\n",
      "epoch:13 step:12248 [D loss: 0.655662, acc.: 60.94%] [G loss: 0.868535]\n",
      "epoch:13 step:12249 [D loss: 0.707895, acc.: 48.44%] [G loss: 0.874251]\n",
      "epoch:13 step:12250 [D loss: 0.645852, acc.: 60.16%] [G loss: 0.847379]\n",
      "epoch:13 step:12251 [D loss: 0.674993, acc.: 60.16%] [G loss: 0.897005]\n",
      "epoch:13 step:12252 [D loss: 0.666488, acc.: 60.94%] [G loss: 0.865716]\n",
      "epoch:13 step:12253 [D loss: 0.669144, acc.: 57.81%] [G loss: 0.889441]\n",
      "epoch:13 step:12254 [D loss: 0.675806, acc.: 58.59%] [G loss: 0.828669]\n",
      "epoch:13 step:12255 [D loss: 0.690035, acc.: 58.59%] [G loss: 0.875701]\n",
      "epoch:13 step:12256 [D loss: 0.660377, acc.: 61.72%] [G loss: 0.972706]\n",
      "epoch:13 step:12257 [D loss: 0.641765, acc.: 66.41%] [G loss: 0.896817]\n",
      "epoch:13 step:12258 [D loss: 0.678836, acc.: 58.59%] [G loss: 0.852735]\n",
      "epoch:13 step:12259 [D loss: 0.637184, acc.: 60.94%] [G loss: 0.876391]\n",
      "epoch:13 step:12260 [D loss: 0.632837, acc.: 64.06%] [G loss: 0.855224]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12261 [D loss: 0.640529, acc.: 60.94%] [G loss: 0.862920]\n",
      "epoch:13 step:12262 [D loss: 0.695257, acc.: 50.78%] [G loss: 0.877886]\n",
      "epoch:13 step:12263 [D loss: 0.674770, acc.: 57.81%] [G loss: 0.863099]\n",
      "epoch:13 step:12264 [D loss: 0.659101, acc.: 60.94%] [G loss: 0.873409]\n",
      "epoch:13 step:12265 [D loss: 0.650620, acc.: 60.16%] [G loss: 0.869847]\n",
      "epoch:13 step:12266 [D loss: 0.671690, acc.: 56.25%] [G loss: 0.891865]\n",
      "epoch:13 step:12267 [D loss: 0.669098, acc.: 58.59%] [G loss: 0.852067]\n",
      "epoch:13 step:12268 [D loss: 0.655381, acc.: 58.59%] [G loss: 0.906562]\n",
      "epoch:13 step:12269 [D loss: 0.640648, acc.: 66.41%] [G loss: 0.883055]\n",
      "epoch:13 step:12270 [D loss: 0.633582, acc.: 66.41%] [G loss: 0.905645]\n",
      "epoch:13 step:12271 [D loss: 0.643414, acc.: 64.06%] [G loss: 0.888592]\n",
      "epoch:13 step:12272 [D loss: 0.666299, acc.: 57.81%] [G loss: 0.881062]\n",
      "epoch:13 step:12273 [D loss: 0.646930, acc.: 58.59%] [G loss: 0.901295]\n",
      "epoch:13 step:12274 [D loss: 0.654072, acc.: 62.50%] [G loss: 0.919947]\n",
      "epoch:13 step:12275 [D loss: 0.646319, acc.: 63.28%] [G loss: 0.931298]\n",
      "epoch:13 step:12276 [D loss: 0.656288, acc.: 57.81%] [G loss: 0.900321]\n",
      "epoch:13 step:12277 [D loss: 0.646787, acc.: 58.59%] [G loss: 0.891273]\n",
      "epoch:13 step:12278 [D loss: 0.641995, acc.: 63.28%] [G loss: 0.835516]\n",
      "epoch:13 step:12279 [D loss: 0.677923, acc.: 59.38%] [G loss: 0.870832]\n",
      "epoch:13 step:12280 [D loss: 0.659415, acc.: 61.72%] [G loss: 0.871063]\n",
      "epoch:13 step:12281 [D loss: 0.671709, acc.: 56.25%] [G loss: 0.837277]\n",
      "epoch:13 step:12282 [D loss: 0.668424, acc.: 57.81%] [G loss: 0.873993]\n",
      "epoch:13 step:12283 [D loss: 0.670974, acc.: 57.81%] [G loss: 0.864309]\n",
      "epoch:13 step:12284 [D loss: 0.638120, acc.: 61.72%] [G loss: 0.929829]\n",
      "epoch:13 step:12285 [D loss: 0.659562, acc.: 60.16%] [G loss: 0.815589]\n",
      "epoch:13 step:12286 [D loss: 0.667364, acc.: 54.69%] [G loss: 0.818400]\n",
      "epoch:13 step:12287 [D loss: 0.662675, acc.: 53.12%] [G loss: 0.818013]\n",
      "epoch:13 step:12288 [D loss: 0.657270, acc.: 57.81%] [G loss: 0.853777]\n",
      "epoch:13 step:12289 [D loss: 0.661089, acc.: 64.84%] [G loss: 0.822207]\n",
      "epoch:13 step:12290 [D loss: 0.697422, acc.: 55.47%] [G loss: 0.854818]\n",
      "epoch:13 step:12291 [D loss: 0.652546, acc.: 63.28%] [G loss: 0.854375]\n",
      "epoch:13 step:12292 [D loss: 0.681332, acc.: 60.16%] [G loss: 0.839377]\n",
      "epoch:13 step:12293 [D loss: 0.669234, acc.: 59.38%] [G loss: 0.844622]\n",
      "epoch:13 step:12294 [D loss: 0.717586, acc.: 53.12%] [G loss: 0.840089]\n",
      "epoch:13 step:12295 [D loss: 0.649613, acc.: 64.84%] [G loss: 0.849083]\n",
      "epoch:13 step:12296 [D loss: 0.690686, acc.: 58.59%] [G loss: 0.883449]\n",
      "epoch:13 step:12297 [D loss: 0.686633, acc.: 57.81%] [G loss: 0.886954]\n",
      "epoch:13 step:12298 [D loss: 0.678645, acc.: 55.47%] [G loss: 0.840177]\n",
      "epoch:13 step:12299 [D loss: 0.690294, acc.: 55.47%] [G loss: 0.812020]\n",
      "epoch:13 step:12300 [D loss: 0.687620, acc.: 50.00%] [G loss: 0.832442]\n",
      "epoch:13 step:12301 [D loss: 0.675361, acc.: 56.25%] [G loss: 0.871083]\n",
      "epoch:13 step:12302 [D loss: 0.609726, acc.: 69.53%] [G loss: 0.886825]\n",
      "epoch:13 step:12303 [D loss: 0.686160, acc.: 55.47%] [G loss: 0.837849]\n",
      "epoch:13 step:12304 [D loss: 0.651254, acc.: 64.06%] [G loss: 0.812675]\n",
      "epoch:13 step:12305 [D loss: 0.693690, acc.: 49.22%] [G loss: 0.809407]\n",
      "epoch:13 step:12306 [D loss: 0.674424, acc.: 62.50%] [G loss: 0.801198]\n",
      "epoch:13 step:12307 [D loss: 0.683041, acc.: 57.81%] [G loss: 0.809154]\n",
      "epoch:13 step:12308 [D loss: 0.612384, acc.: 71.88%] [G loss: 0.823305]\n",
      "epoch:13 step:12309 [D loss: 0.706156, acc.: 56.25%] [G loss: 0.876677]\n",
      "epoch:13 step:12310 [D loss: 0.656306, acc.: 62.50%] [G loss: 0.849031]\n",
      "epoch:13 step:12311 [D loss: 0.648445, acc.: 59.38%] [G loss: 0.844926]\n",
      "epoch:13 step:12312 [D loss: 0.684988, acc.: 55.47%] [G loss: 0.870600]\n",
      "epoch:13 step:12313 [D loss: 0.687791, acc.: 53.12%] [G loss: 0.856250]\n",
      "epoch:13 step:12314 [D loss: 0.671070, acc.: 61.72%] [G loss: 0.843232]\n",
      "epoch:13 step:12315 [D loss: 0.678639, acc.: 56.25%] [G loss: 0.820915]\n",
      "epoch:13 step:12316 [D loss: 0.735958, acc.: 50.00%] [G loss: 0.834679]\n",
      "epoch:13 step:12317 [D loss: 0.688907, acc.: 57.81%] [G loss: 0.840754]\n",
      "epoch:13 step:12318 [D loss: 0.671845, acc.: 63.28%] [G loss: 0.858382]\n",
      "epoch:13 step:12319 [D loss: 0.669017, acc.: 62.50%] [G loss: 0.843584]\n",
      "epoch:13 step:12320 [D loss: 0.670456, acc.: 58.59%] [G loss: 0.874870]\n",
      "epoch:13 step:12321 [D loss: 0.671830, acc.: 62.50%] [G loss: 0.842036]\n",
      "epoch:13 step:12322 [D loss: 0.690068, acc.: 52.34%] [G loss: 0.793908]\n",
      "epoch:13 step:12323 [D loss: 0.655398, acc.: 61.72%] [G loss: 0.827625]\n",
      "epoch:13 step:12324 [D loss: 0.679872, acc.: 60.94%] [G loss: 0.794449]\n",
      "epoch:13 step:12325 [D loss: 0.664715, acc.: 53.12%] [G loss: 0.837004]\n",
      "epoch:13 step:12326 [D loss: 0.680814, acc.: 53.91%] [G loss: 0.832148]\n",
      "epoch:13 step:12327 [D loss: 0.693454, acc.: 49.22%] [G loss: 0.801315]\n",
      "epoch:13 step:12328 [D loss: 0.668925, acc.: 55.47%] [G loss: 0.853421]\n",
      "epoch:13 step:12329 [D loss: 0.681397, acc.: 53.12%] [G loss: 0.779576]\n",
      "epoch:13 step:12330 [D loss: 0.676824, acc.: 57.81%] [G loss: 0.777835]\n",
      "epoch:13 step:12331 [D loss: 0.688680, acc.: 45.31%] [G loss: 0.803832]\n",
      "epoch:13 step:12332 [D loss: 0.685994, acc.: 55.47%] [G loss: 0.797784]\n",
      "epoch:13 step:12333 [D loss: 0.637262, acc.: 64.84%] [G loss: 0.825413]\n",
      "epoch:13 step:12334 [D loss: 0.686964, acc.: 54.69%] [G loss: 0.817073]\n",
      "epoch:13 step:12335 [D loss: 0.670087, acc.: 58.59%] [G loss: 0.852682]\n",
      "epoch:13 step:12336 [D loss: 0.687813, acc.: 56.25%] [G loss: 0.884665]\n",
      "epoch:13 step:12337 [D loss: 0.640912, acc.: 64.84%] [G loss: 0.834137]\n",
      "epoch:13 step:12338 [D loss: 0.676751, acc.: 53.12%] [G loss: 0.799631]\n",
      "epoch:13 step:12339 [D loss: 0.669421, acc.: 59.38%] [G loss: 0.792480]\n",
      "epoch:13 step:12340 [D loss: 0.659234, acc.: 58.59%] [G loss: 0.857589]\n",
      "epoch:13 step:12341 [D loss: 0.664163, acc.: 62.50%] [G loss: 0.874026]\n",
      "epoch:13 step:12342 [D loss: 0.659826, acc.: 57.03%] [G loss: 0.856528]\n",
      "epoch:13 step:12343 [D loss: 0.648568, acc.: 60.94%] [G loss: 0.877358]\n",
      "epoch:13 step:12344 [D loss: 0.714531, acc.: 53.12%] [G loss: 0.840767]\n",
      "epoch:13 step:12345 [D loss: 0.714100, acc.: 46.88%] [G loss: 0.814269]\n",
      "epoch:13 step:12346 [D loss: 0.656607, acc.: 62.50%] [G loss: 0.822372]\n",
      "epoch:13 step:12347 [D loss: 0.688402, acc.: 56.25%] [G loss: 0.785222]\n",
      "epoch:13 step:12348 [D loss: 0.674234, acc.: 59.38%] [G loss: 0.860893]\n",
      "epoch:13 step:12349 [D loss: 0.691679, acc.: 56.25%] [G loss: 0.862487]\n",
      "epoch:13 step:12350 [D loss: 0.672826, acc.: 57.03%] [G loss: 0.876616]\n",
      "epoch:13 step:12351 [D loss: 0.662225, acc.: 57.03%] [G loss: 0.886128]\n",
      "epoch:13 step:12352 [D loss: 0.695755, acc.: 49.22%] [G loss: 0.867406]\n",
      "epoch:13 step:12353 [D loss: 0.663047, acc.: 60.16%] [G loss: 0.891904]\n",
      "epoch:13 step:12354 [D loss: 0.691730, acc.: 55.47%] [G loss: 0.792722]\n",
      "epoch:13 step:12355 [D loss: 0.678434, acc.: 58.59%] [G loss: 0.826591]\n",
      "epoch:13 step:12356 [D loss: 0.641265, acc.: 66.41%] [G loss: 0.818060]\n",
      "epoch:13 step:12357 [D loss: 0.644632, acc.: 64.06%] [G loss: 0.834641]\n",
      "epoch:13 step:12358 [D loss: 0.676757, acc.: 58.59%] [G loss: 0.795541]\n",
      "epoch:13 step:12359 [D loss: 0.667856, acc.: 58.59%] [G loss: 0.813794]\n",
      "epoch:13 step:12360 [D loss: 0.671603, acc.: 57.03%] [G loss: 0.865062]\n",
      "epoch:13 step:12361 [D loss: 0.617324, acc.: 67.97%] [G loss: 0.828448]\n",
      "epoch:13 step:12362 [D loss: 0.699312, acc.: 50.78%] [G loss: 0.851749]\n",
      "epoch:13 step:12363 [D loss: 0.663406, acc.: 62.50%] [G loss: 0.779602]\n",
      "epoch:13 step:12364 [D loss: 0.672925, acc.: 53.91%] [G loss: 0.848858]\n",
      "epoch:13 step:12365 [D loss: 0.670405, acc.: 64.84%] [G loss: 0.844556]\n",
      "epoch:13 step:12366 [D loss: 0.686983, acc.: 57.81%] [G loss: 0.848247]\n",
      "epoch:13 step:12367 [D loss: 0.685092, acc.: 54.69%] [G loss: 0.876254]\n",
      "epoch:13 step:12368 [D loss: 0.657382, acc.: 64.84%] [G loss: 0.861074]\n",
      "epoch:13 step:12369 [D loss: 0.651143, acc.: 64.84%] [G loss: 0.838816]\n",
      "epoch:13 step:12370 [D loss: 0.671378, acc.: 58.59%] [G loss: 0.825672]\n",
      "epoch:13 step:12371 [D loss: 0.668273, acc.: 55.47%] [G loss: 0.820373]\n",
      "epoch:13 step:12372 [D loss: 0.707277, acc.: 51.56%] [G loss: 0.846105]\n",
      "epoch:13 step:12373 [D loss: 0.671118, acc.: 59.38%] [G loss: 0.874014]\n",
      "epoch:13 step:12374 [D loss: 0.632355, acc.: 64.06%] [G loss: 0.880129]\n",
      "epoch:13 step:12375 [D loss: 0.679181, acc.: 60.94%] [G loss: 0.873423]\n",
      "epoch:13 step:12376 [D loss: 0.668178, acc.: 60.16%] [G loss: 0.825062]\n",
      "epoch:13 step:12377 [D loss: 0.659814, acc.: 62.50%] [G loss: 0.853744]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12378 [D loss: 0.636231, acc.: 64.06%] [G loss: 0.868019]\n",
      "epoch:13 step:12379 [D loss: 0.621076, acc.: 66.41%] [G loss: 0.888438]\n",
      "epoch:13 step:12380 [D loss: 0.636099, acc.: 64.06%] [G loss: 0.856402]\n",
      "epoch:13 step:12381 [D loss: 0.637252, acc.: 64.06%] [G loss: 0.840739]\n",
      "epoch:13 step:12382 [D loss: 0.668797, acc.: 60.16%] [G loss: 0.885828]\n",
      "epoch:13 step:12383 [D loss: 0.624738, acc.: 60.16%] [G loss: 0.850560]\n",
      "epoch:13 step:12384 [D loss: 0.660447, acc.: 60.94%] [G loss: 0.896671]\n",
      "epoch:13 step:12385 [D loss: 0.650293, acc.: 56.25%] [G loss: 0.872296]\n",
      "epoch:13 step:12386 [D loss: 0.673584, acc.: 60.16%] [G loss: 0.874592]\n",
      "epoch:13 step:12387 [D loss: 0.668839, acc.: 61.72%] [G loss: 0.879766]\n",
      "epoch:13 step:12388 [D loss: 0.642125, acc.: 60.94%] [G loss: 0.868804]\n",
      "epoch:13 step:12389 [D loss: 0.625124, acc.: 65.62%] [G loss: 0.916301]\n",
      "epoch:13 step:12390 [D loss: 0.636862, acc.: 65.62%] [G loss: 0.930446]\n",
      "epoch:13 step:12391 [D loss: 0.652004, acc.: 64.06%] [G loss: 0.887772]\n",
      "epoch:13 step:12392 [D loss: 0.655697, acc.: 60.94%] [G loss: 0.854832]\n",
      "epoch:13 step:12393 [D loss: 0.643816, acc.: 62.50%] [G loss: 0.846251]\n",
      "epoch:13 step:12394 [D loss: 0.696325, acc.: 57.81%] [G loss: 0.867074]\n",
      "epoch:13 step:12395 [D loss: 0.662011, acc.: 61.72%] [G loss: 0.876366]\n",
      "epoch:13 step:12396 [D loss: 0.660865, acc.: 60.94%] [G loss: 0.855126]\n",
      "epoch:13 step:12397 [D loss: 0.688097, acc.: 51.56%] [G loss: 0.897513]\n",
      "epoch:13 step:12398 [D loss: 0.659906, acc.: 64.84%] [G loss: 0.836139]\n",
      "epoch:13 step:12399 [D loss: 0.665188, acc.: 57.03%] [G loss: 0.819360]\n",
      "epoch:13 step:12400 [D loss: 0.694417, acc.: 54.69%] [G loss: 0.854301]\n",
      "##############\n",
      "[2.89535416 2.61276874 2.58254351 4.0778561  1.62061083 8.4540022\n",
      " 2.78590712 4.03372111 4.22623457 5.93349565]\n",
      "##########\n",
      "epoch:13 step:12401 [D loss: 0.672291, acc.: 55.47%] [G loss: 0.829870]\n",
      "epoch:13 step:12402 [D loss: 0.644438, acc.: 62.50%] [G loss: 0.817670]\n",
      "epoch:13 step:12403 [D loss: 0.687817, acc.: 55.47%] [G loss: 0.824542]\n",
      "epoch:13 step:12404 [D loss: 0.651914, acc.: 65.62%] [G loss: 0.851589]\n",
      "epoch:13 step:12405 [D loss: 0.681403, acc.: 57.03%] [G loss: 0.878484]\n",
      "epoch:13 step:12406 [D loss: 0.647835, acc.: 63.28%] [G loss: 0.843709]\n",
      "epoch:13 step:12407 [D loss: 0.672715, acc.: 50.00%] [G loss: 0.831788]\n",
      "epoch:13 step:12408 [D loss: 0.640591, acc.: 63.28%] [G loss: 0.890867]\n",
      "epoch:13 step:12409 [D loss: 0.686178, acc.: 53.91%] [G loss: 0.806014]\n",
      "epoch:13 step:12410 [D loss: 0.682007, acc.: 60.16%] [G loss: 0.836429]\n",
      "epoch:13 step:12411 [D loss: 0.660501, acc.: 56.25%] [G loss: 0.848669]\n",
      "epoch:13 step:12412 [D loss: 0.676396, acc.: 54.69%] [G loss: 0.853282]\n",
      "epoch:13 step:12413 [D loss: 0.692875, acc.: 55.47%] [G loss: 0.867707]\n",
      "epoch:13 step:12414 [D loss: 0.647164, acc.: 66.41%] [G loss: 0.852294]\n",
      "epoch:13 step:12415 [D loss: 0.660576, acc.: 57.03%] [G loss: 0.847452]\n",
      "epoch:13 step:12416 [D loss: 0.668056, acc.: 59.38%] [G loss: 0.820174]\n",
      "epoch:13 step:12417 [D loss: 0.675959, acc.: 56.25%] [G loss: 0.866242]\n",
      "epoch:13 step:12418 [D loss: 0.678155, acc.: 58.59%] [G loss: 0.843252]\n",
      "epoch:13 step:12419 [D loss: 0.663843, acc.: 60.16%] [G loss: 0.848656]\n",
      "epoch:13 step:12420 [D loss: 0.686812, acc.: 62.50%] [G loss: 0.829524]\n",
      "epoch:13 step:12421 [D loss: 0.657345, acc.: 59.38%] [G loss: 0.828528]\n",
      "epoch:13 step:12422 [D loss: 0.688003, acc.: 57.03%] [G loss: 0.842382]\n",
      "epoch:13 step:12423 [D loss: 0.668326, acc.: 64.06%] [G loss: 0.799764]\n",
      "epoch:13 step:12424 [D loss: 0.659436, acc.: 57.81%] [G loss: 0.887422]\n",
      "epoch:13 step:12425 [D loss: 0.675342, acc.: 54.69%] [G loss: 0.886535]\n",
      "epoch:13 step:12426 [D loss: 0.654927, acc.: 57.81%] [G loss: 0.867513]\n",
      "epoch:13 step:12427 [D loss: 0.692486, acc.: 52.34%] [G loss: 0.868982]\n",
      "epoch:13 step:12428 [D loss: 0.648163, acc.: 60.16%] [G loss: 0.855841]\n",
      "epoch:13 step:12429 [D loss: 0.668664, acc.: 60.94%] [G loss: 0.853572]\n",
      "epoch:13 step:12430 [D loss: 0.707907, acc.: 48.44%] [G loss: 0.854069]\n",
      "epoch:13 step:12431 [D loss: 0.664668, acc.: 61.72%] [G loss: 0.860990]\n",
      "epoch:13 step:12432 [D loss: 0.652193, acc.: 64.06%] [G loss: 0.849741]\n",
      "epoch:13 step:12433 [D loss: 0.657857, acc.: 62.50%] [G loss: 0.828405]\n",
      "epoch:13 step:12434 [D loss: 0.670062, acc.: 61.72%] [G loss: 0.825827]\n",
      "epoch:13 step:12435 [D loss: 0.688889, acc.: 60.16%] [G loss: 0.873805]\n",
      "epoch:13 step:12436 [D loss: 0.726654, acc.: 47.66%] [G loss: 0.815950]\n",
      "epoch:13 step:12437 [D loss: 0.667832, acc.: 54.69%] [G loss: 0.863160]\n",
      "epoch:13 step:12438 [D loss: 0.669861, acc.: 60.16%] [G loss: 0.844858]\n",
      "epoch:13 step:12439 [D loss: 0.647812, acc.: 60.94%] [G loss: 0.849987]\n",
      "epoch:13 step:12440 [D loss: 0.636821, acc.: 68.75%] [G loss: 0.816324]\n",
      "epoch:13 step:12441 [D loss: 0.625352, acc.: 66.41%] [G loss: 0.847689]\n",
      "epoch:13 step:12442 [D loss: 0.714033, acc.: 53.91%] [G loss: 0.829378]\n",
      "epoch:13 step:12443 [D loss: 0.684750, acc.: 58.59%] [G loss: 0.858464]\n",
      "epoch:13 step:12444 [D loss: 0.703136, acc.: 53.91%] [G loss: 0.876707]\n",
      "epoch:13 step:12445 [D loss: 0.697021, acc.: 53.12%] [G loss: 0.868017]\n",
      "epoch:13 step:12446 [D loss: 0.631851, acc.: 64.06%] [G loss: 0.843003]\n",
      "epoch:13 step:12447 [D loss: 0.643492, acc.: 65.62%] [G loss: 0.869424]\n",
      "epoch:13 step:12448 [D loss: 0.663086, acc.: 60.94%] [G loss: 0.831185]\n",
      "epoch:13 step:12449 [D loss: 0.661387, acc.: 57.03%] [G loss: 0.901065]\n",
      "epoch:13 step:12450 [D loss: 0.686296, acc.: 56.25%] [G loss: 0.885466]\n",
      "epoch:13 step:12451 [D loss: 0.661232, acc.: 60.94%] [G loss: 0.808384]\n",
      "epoch:13 step:12452 [D loss: 0.647523, acc.: 58.59%] [G loss: 0.853948]\n",
      "epoch:13 step:12453 [D loss: 0.666193, acc.: 60.16%] [G loss: 0.833045]\n",
      "epoch:13 step:12454 [D loss: 0.701701, acc.: 51.56%] [G loss: 0.866382]\n",
      "epoch:13 step:12455 [D loss: 0.669643, acc.: 53.91%] [G loss: 0.869740]\n",
      "epoch:13 step:12456 [D loss: 0.690075, acc.: 50.00%] [G loss: 0.851450]\n",
      "epoch:13 step:12457 [D loss: 0.688695, acc.: 53.12%] [G loss: 0.850146]\n",
      "epoch:13 step:12458 [D loss: 0.673856, acc.: 57.81%] [G loss: 0.860514]\n",
      "epoch:13 step:12459 [D loss: 0.668962, acc.: 54.69%] [G loss: 0.899928]\n",
      "epoch:13 step:12460 [D loss: 0.681975, acc.: 53.91%] [G loss: 0.851431]\n",
      "epoch:13 step:12461 [D loss: 0.653300, acc.: 60.16%] [G loss: 0.837225]\n",
      "epoch:13 step:12462 [D loss: 0.653352, acc.: 64.06%] [G loss: 0.866119]\n",
      "epoch:13 step:12463 [D loss: 0.656605, acc.: 58.59%] [G loss: 0.847232]\n",
      "epoch:13 step:12464 [D loss: 0.670294, acc.: 58.59%] [G loss: 0.883211]\n",
      "epoch:13 step:12465 [D loss: 0.643881, acc.: 65.62%] [G loss: 0.862366]\n",
      "epoch:13 step:12466 [D loss: 0.668916, acc.: 56.25%] [G loss: 0.836899]\n",
      "epoch:13 step:12467 [D loss: 0.670076, acc.: 61.72%] [G loss: 0.847156]\n",
      "epoch:13 step:12468 [D loss: 0.665193, acc.: 57.81%] [G loss: 0.873593]\n",
      "epoch:13 step:12469 [D loss: 0.651168, acc.: 60.94%] [G loss: 0.829015]\n",
      "epoch:13 step:12470 [D loss: 0.702855, acc.: 53.12%] [G loss: 0.867318]\n",
      "epoch:13 step:12471 [D loss: 0.650190, acc.: 61.72%] [G loss: 0.852355]\n",
      "epoch:13 step:12472 [D loss: 0.680784, acc.: 53.91%] [G loss: 0.824014]\n",
      "epoch:13 step:12473 [D loss: 0.684321, acc.: 61.72%] [G loss: 0.833122]\n",
      "epoch:13 step:12474 [D loss: 0.678625, acc.: 54.69%] [G loss: 0.839863]\n",
      "epoch:13 step:12475 [D loss: 0.696604, acc.: 56.25%] [G loss: 0.851323]\n",
      "epoch:13 step:12476 [D loss: 0.687529, acc.: 60.94%] [G loss: 0.911893]\n",
      "epoch:13 step:12477 [D loss: 0.684931, acc.: 56.25%] [G loss: 0.879715]\n",
      "epoch:13 step:12478 [D loss: 0.643738, acc.: 58.59%] [G loss: 0.833765]\n",
      "epoch:13 step:12479 [D loss: 0.666720, acc.: 57.03%] [G loss: 0.865293]\n",
      "epoch:13 step:12480 [D loss: 0.660558, acc.: 62.50%] [G loss: 0.863348]\n",
      "epoch:13 step:12481 [D loss: 0.670737, acc.: 59.38%] [G loss: 0.826630]\n",
      "epoch:13 step:12482 [D loss: 0.682139, acc.: 55.47%] [G loss: 0.838513]\n",
      "epoch:13 step:12483 [D loss: 0.666101, acc.: 60.16%] [G loss: 0.828256]\n",
      "epoch:13 step:12484 [D loss: 0.677445, acc.: 59.38%] [G loss: 0.807959]\n",
      "epoch:13 step:12485 [D loss: 0.677258, acc.: 58.59%] [G loss: 0.843245]\n",
      "epoch:13 step:12486 [D loss: 0.682805, acc.: 46.09%] [G loss: 0.828743]\n",
      "epoch:13 step:12487 [D loss: 0.641623, acc.: 59.38%] [G loss: 0.818788]\n",
      "epoch:13 step:12488 [D loss: 0.694479, acc.: 53.91%] [G loss: 0.820084]\n",
      "epoch:13 step:12489 [D loss: 0.679340, acc.: 57.03%] [G loss: 0.827888]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12490 [D loss: 0.674369, acc.: 57.03%] [G loss: 0.876512]\n",
      "epoch:13 step:12491 [D loss: 0.690787, acc.: 48.44%] [G loss: 0.874207]\n",
      "epoch:13 step:12492 [D loss: 0.684950, acc.: 54.69%] [G loss: 0.853153]\n",
      "epoch:13 step:12493 [D loss: 0.660565, acc.: 58.59%] [G loss: 0.866390]\n",
      "epoch:13 step:12494 [D loss: 0.680957, acc.: 58.59%] [G loss: 0.885362]\n",
      "epoch:13 step:12495 [D loss: 0.643899, acc.: 60.16%] [G loss: 0.849176]\n",
      "epoch:13 step:12496 [D loss: 0.665306, acc.: 58.59%] [G loss: 0.810753]\n",
      "epoch:13 step:12497 [D loss: 0.664465, acc.: 62.50%] [G loss: 0.862761]\n",
      "epoch:13 step:12498 [D loss: 0.636010, acc.: 62.50%] [G loss: 0.852498]\n",
      "epoch:13 step:12499 [D loss: 0.674757, acc.: 57.03%] [G loss: 0.843375]\n",
      "epoch:13 step:12500 [D loss: 0.689313, acc.: 54.69%] [G loss: 0.884189]\n",
      "epoch:13 step:12501 [D loss: 0.640790, acc.: 64.06%] [G loss: 0.838967]\n",
      "epoch:13 step:12502 [D loss: 0.659555, acc.: 60.94%] [G loss: 0.862005]\n",
      "epoch:13 step:12503 [D loss: 0.670698, acc.: 57.81%] [G loss: 0.834199]\n",
      "epoch:13 step:12504 [D loss: 0.670449, acc.: 52.34%] [G loss: 0.828798]\n",
      "epoch:13 step:12505 [D loss: 0.677026, acc.: 55.47%] [G loss: 0.886468]\n",
      "epoch:13 step:12506 [D loss: 0.677556, acc.: 54.69%] [G loss: 0.822055]\n",
      "epoch:13 step:12507 [D loss: 0.685144, acc.: 56.25%] [G loss: 0.829371]\n",
      "epoch:13 step:12508 [D loss: 0.630862, acc.: 67.19%] [G loss: 0.870136]\n",
      "epoch:13 step:12509 [D loss: 0.677895, acc.: 53.91%] [G loss: 0.874229]\n",
      "epoch:13 step:12510 [D loss: 0.685665, acc.: 53.91%] [G loss: 0.871358]\n",
      "epoch:13 step:12511 [D loss: 0.650893, acc.: 67.19%] [G loss: 0.891085]\n",
      "epoch:13 step:12512 [D loss: 0.639391, acc.: 71.09%] [G loss: 0.871960]\n",
      "epoch:13 step:12513 [D loss: 0.669679, acc.: 59.38%] [G loss: 0.863254]\n",
      "epoch:13 step:12514 [D loss: 0.708596, acc.: 49.22%] [G loss: 0.878027]\n",
      "epoch:13 step:12515 [D loss: 0.658593, acc.: 62.50%] [G loss: 0.877196]\n",
      "epoch:13 step:12516 [D loss: 0.669289, acc.: 55.47%] [G loss: 0.839205]\n",
      "epoch:13 step:12517 [D loss: 0.648991, acc.: 61.72%] [G loss: 0.879964]\n",
      "epoch:13 step:12518 [D loss: 0.647988, acc.: 58.59%] [G loss: 0.882742]\n",
      "epoch:13 step:12519 [D loss: 0.653579, acc.: 60.94%] [G loss: 0.905433]\n",
      "epoch:13 step:12520 [D loss: 0.655853, acc.: 58.59%] [G loss: 0.899441]\n",
      "epoch:13 step:12521 [D loss: 0.680507, acc.: 56.25%] [G loss: 0.819605]\n",
      "epoch:13 step:12522 [D loss: 0.642319, acc.: 64.06%] [G loss: 0.843570]\n",
      "epoch:13 step:12523 [D loss: 0.654408, acc.: 59.38%] [G loss: 0.848416]\n",
      "epoch:13 step:12524 [D loss: 0.686210, acc.: 57.81%] [G loss: 0.845103]\n",
      "epoch:13 step:12525 [D loss: 0.668279, acc.: 57.81%] [G loss: 0.879893]\n",
      "epoch:13 step:12526 [D loss: 0.663604, acc.: 57.81%] [G loss: 0.860667]\n",
      "epoch:13 step:12527 [D loss: 0.675021, acc.: 49.22%] [G loss: 0.855524]\n",
      "epoch:13 step:12528 [D loss: 0.655847, acc.: 60.94%] [G loss: 0.850552]\n",
      "epoch:13 step:12529 [D loss: 0.682913, acc.: 57.81%] [G loss: 0.875155]\n",
      "epoch:13 step:12530 [D loss: 0.664557, acc.: 58.59%] [G loss: 0.839306]\n",
      "epoch:13 step:12531 [D loss: 0.700153, acc.: 53.12%] [G loss: 0.879638]\n",
      "epoch:13 step:12532 [D loss: 0.667178, acc.: 56.25%] [G loss: 0.859301]\n",
      "epoch:13 step:12533 [D loss: 0.676396, acc.: 56.25%] [G loss: 0.824450]\n",
      "epoch:13 step:12534 [D loss: 0.637744, acc.: 65.62%] [G loss: 0.842560]\n",
      "epoch:13 step:12535 [D loss: 0.659928, acc.: 63.28%] [G loss: 0.865769]\n",
      "epoch:13 step:12536 [D loss: 0.657971, acc.: 60.16%] [G loss: 0.883681]\n",
      "epoch:13 step:12537 [D loss: 0.658549, acc.: 60.16%] [G loss: 0.818950]\n",
      "epoch:13 step:12538 [D loss: 0.666310, acc.: 60.94%] [G loss: 0.825502]\n",
      "epoch:13 step:12539 [D loss: 0.663455, acc.: 54.69%] [G loss: 0.909637]\n",
      "epoch:13 step:12540 [D loss: 0.708791, acc.: 50.78%] [G loss: 0.899597]\n",
      "epoch:13 step:12541 [D loss: 0.658984, acc.: 60.16%] [G loss: 0.911728]\n",
      "epoch:13 step:12542 [D loss: 0.687141, acc.: 54.69%] [G loss: 0.857464]\n",
      "epoch:13 step:12543 [D loss: 0.681242, acc.: 56.25%] [G loss: 0.908033]\n",
      "epoch:13 step:12544 [D loss: 0.694836, acc.: 51.56%] [G loss: 0.887497]\n",
      "epoch:13 step:12545 [D loss: 0.693858, acc.: 52.34%] [G loss: 0.876209]\n",
      "epoch:13 step:12546 [D loss: 0.693725, acc.: 53.12%] [G loss: 0.851192]\n",
      "epoch:13 step:12547 [D loss: 0.683941, acc.: 52.34%] [G loss: 0.868512]\n",
      "epoch:13 step:12548 [D loss: 0.686789, acc.: 50.78%] [G loss: 0.851357]\n",
      "epoch:13 step:12549 [D loss: 0.682589, acc.: 58.59%] [G loss: 0.869778]\n",
      "epoch:13 step:12550 [D loss: 0.670698, acc.: 57.81%] [G loss: 0.883213]\n",
      "epoch:13 step:12551 [D loss: 0.671403, acc.: 56.25%] [G loss: 0.833388]\n",
      "epoch:13 step:12552 [D loss: 0.691837, acc.: 58.59%] [G loss: 0.832689]\n",
      "epoch:13 step:12553 [D loss: 0.638195, acc.: 64.84%] [G loss: 0.837670]\n",
      "epoch:13 step:12554 [D loss: 0.643787, acc.: 64.84%] [G loss: 0.816721]\n",
      "epoch:13 step:12555 [D loss: 0.652340, acc.: 57.81%] [G loss: 0.843846]\n",
      "epoch:13 step:12556 [D loss: 0.681602, acc.: 54.69%] [G loss: 0.851341]\n",
      "epoch:13 step:12557 [D loss: 0.667776, acc.: 58.59%] [G loss: 0.839238]\n",
      "epoch:13 step:12558 [D loss: 0.677493, acc.: 56.25%] [G loss: 0.836710]\n",
      "epoch:13 step:12559 [D loss: 0.644287, acc.: 62.50%] [G loss: 0.872352]\n",
      "epoch:13 step:12560 [D loss: 0.651930, acc.: 63.28%] [G loss: 0.852954]\n",
      "epoch:13 step:12561 [D loss: 0.653046, acc.: 63.28%] [G loss: 0.844835]\n",
      "epoch:13 step:12562 [D loss: 0.627884, acc.: 67.19%] [G loss: 0.875224]\n",
      "epoch:13 step:12563 [D loss: 0.627605, acc.: 67.19%] [G loss: 0.884732]\n",
      "epoch:13 step:12564 [D loss: 0.640832, acc.: 67.97%] [G loss: 0.903257]\n",
      "epoch:13 step:12565 [D loss: 0.686350, acc.: 49.22%] [G loss: 0.907977]\n",
      "epoch:13 step:12566 [D loss: 0.672617, acc.: 55.47%] [G loss: 0.856173]\n",
      "epoch:13 step:12567 [D loss: 0.637940, acc.: 66.41%] [G loss: 0.850548]\n",
      "epoch:13 step:12568 [D loss: 0.677224, acc.: 55.47%] [G loss: 0.862699]\n",
      "epoch:13 step:12569 [D loss: 0.686391, acc.: 53.12%] [G loss: 0.894246]\n",
      "epoch:13 step:12570 [D loss: 0.691606, acc.: 53.91%] [G loss: 0.867486]\n",
      "epoch:13 step:12571 [D loss: 0.646115, acc.: 62.50%] [G loss: 0.823224]\n",
      "epoch:13 step:12572 [D loss: 0.657408, acc.: 60.16%] [G loss: 0.847306]\n",
      "epoch:13 step:12573 [D loss: 0.693039, acc.: 53.12%] [G loss: 0.858346]\n",
      "epoch:13 step:12574 [D loss: 0.715964, acc.: 48.44%] [G loss: 0.904114]\n",
      "epoch:13 step:12575 [D loss: 0.656253, acc.: 59.38%] [G loss: 0.833436]\n",
      "epoch:13 step:12576 [D loss: 0.684469, acc.: 60.16%] [G loss: 0.849719]\n",
      "epoch:13 step:12577 [D loss: 0.687359, acc.: 58.59%] [G loss: 0.841962]\n",
      "epoch:13 step:12578 [D loss: 0.675972, acc.: 51.56%] [G loss: 0.860284]\n",
      "epoch:13 step:12579 [D loss: 0.682214, acc.: 59.38%] [G loss: 0.842294]\n",
      "epoch:13 step:12580 [D loss: 0.696406, acc.: 56.25%] [G loss: 0.848113]\n",
      "epoch:13 step:12581 [D loss: 0.647004, acc.: 58.59%] [G loss: 0.831419]\n",
      "epoch:13 step:12582 [D loss: 0.647878, acc.: 57.81%] [G loss: 0.833294]\n",
      "epoch:13 step:12583 [D loss: 0.633548, acc.: 65.62%] [G loss: 0.864906]\n",
      "epoch:13 step:12584 [D loss: 0.634222, acc.: 64.84%] [G loss: 0.841480]\n",
      "epoch:13 step:12585 [D loss: 0.694219, acc.: 50.78%] [G loss: 0.880322]\n",
      "epoch:13 step:12586 [D loss: 0.636034, acc.: 69.53%] [G loss: 0.840669]\n",
      "epoch:13 step:12587 [D loss: 0.647994, acc.: 59.38%] [G loss: 0.855117]\n",
      "epoch:13 step:12588 [D loss: 0.653149, acc.: 64.06%] [G loss: 0.858907]\n",
      "epoch:13 step:12589 [D loss: 0.642443, acc.: 62.50%] [G loss: 0.861530]\n",
      "epoch:13 step:12590 [D loss: 0.643361, acc.: 59.38%] [G loss: 0.846426]\n",
      "epoch:13 step:12591 [D loss: 0.718246, acc.: 53.91%] [G loss: 0.828773]\n",
      "epoch:13 step:12592 [D loss: 0.628476, acc.: 67.97%] [G loss: 0.856478]\n",
      "epoch:13 step:12593 [D loss: 0.640036, acc.: 65.62%] [G loss: 0.914839]\n",
      "epoch:13 step:12594 [D loss: 0.673461, acc.: 57.03%] [G loss: 0.816060]\n",
      "epoch:13 step:12595 [D loss: 0.647491, acc.: 59.38%] [G loss: 0.849600]\n",
      "epoch:13 step:12596 [D loss: 0.651333, acc.: 60.16%] [G loss: 0.863803]\n",
      "epoch:13 step:12597 [D loss: 0.619480, acc.: 67.97%] [G loss: 0.930365]\n",
      "epoch:13 step:12598 [D loss: 0.620433, acc.: 68.75%] [G loss: 0.860770]\n",
      "epoch:13 step:12599 [D loss: 0.695244, acc.: 56.25%] [G loss: 0.848134]\n",
      "epoch:13 step:12600 [D loss: 0.658808, acc.: 63.28%] [G loss: 0.834462]\n",
      "##############\n",
      "[3.03349405 2.58443637 2.16088941 3.8768865  1.55644963 7.99628379\n",
      " 2.60540507 3.99452101 4.18344696 6.27521813]\n",
      "##########\n",
      "epoch:13 step:12601 [D loss: 0.625050, acc.: 67.19%] [G loss: 0.863304]\n",
      "epoch:13 step:12602 [D loss: 0.626625, acc.: 60.94%] [G loss: 0.843739]\n",
      "epoch:13 step:12603 [D loss: 0.663536, acc.: 57.81%] [G loss: 0.896731]\n",
      "epoch:13 step:12604 [D loss: 0.630742, acc.: 60.94%] [G loss: 0.873529]\n",
      "epoch:13 step:12605 [D loss: 0.657156, acc.: 57.81%] [G loss: 0.846231]\n",
      "epoch:13 step:12606 [D loss: 0.655193, acc.: 62.50%] [G loss: 0.850237]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12607 [D loss: 0.662099, acc.: 57.03%] [G loss: 0.868891]\n",
      "epoch:13 step:12608 [D loss: 0.670967, acc.: 62.50%] [G loss: 0.863920]\n",
      "epoch:13 step:12609 [D loss: 0.726829, acc.: 53.12%] [G loss: 0.901614]\n",
      "epoch:13 step:12610 [D loss: 0.647042, acc.: 62.50%] [G loss: 0.878450]\n",
      "epoch:13 step:12611 [D loss: 0.673773, acc.: 58.59%] [G loss: 0.889556]\n",
      "epoch:13 step:12612 [D loss: 0.645136, acc.: 62.50%] [G loss: 0.850705]\n",
      "epoch:13 step:12613 [D loss: 0.645734, acc.: 63.28%] [G loss: 0.886006]\n",
      "epoch:13 step:12614 [D loss: 0.669230, acc.: 57.03%] [G loss: 0.838156]\n",
      "epoch:13 step:12615 [D loss: 0.676859, acc.: 57.03%] [G loss: 0.868067]\n",
      "epoch:13 step:12616 [D loss: 0.688932, acc.: 58.59%] [G loss: 0.881319]\n",
      "epoch:13 step:12617 [D loss: 0.688257, acc.: 55.47%] [G loss: 0.890969]\n",
      "epoch:13 step:12618 [D loss: 0.682342, acc.: 57.03%] [G loss: 0.849420]\n",
      "epoch:13 step:12619 [D loss: 0.682250, acc.: 53.12%] [G loss: 0.845716]\n",
      "epoch:13 step:12620 [D loss: 0.650172, acc.: 61.72%] [G loss: 0.890848]\n",
      "epoch:13 step:12621 [D loss: 0.689311, acc.: 60.16%] [G loss: 0.851359]\n",
      "epoch:13 step:12622 [D loss: 0.681082, acc.: 52.34%] [G loss: 0.831492]\n",
      "epoch:13 step:12623 [D loss: 0.633174, acc.: 59.38%] [G loss: 0.859111]\n",
      "epoch:13 step:12624 [D loss: 0.678053, acc.: 56.25%] [G loss: 0.879260]\n",
      "epoch:13 step:12625 [D loss: 0.635648, acc.: 63.28%] [G loss: 0.842328]\n",
      "epoch:13 step:12626 [D loss: 0.642959, acc.: 61.72%] [G loss: 0.906798]\n",
      "epoch:13 step:12627 [D loss: 0.682717, acc.: 54.69%] [G loss: 0.861203]\n",
      "epoch:13 step:12628 [D loss: 0.685144, acc.: 57.03%] [G loss: 0.889121]\n",
      "epoch:13 step:12629 [D loss: 0.681118, acc.: 55.47%] [G loss: 0.859490]\n",
      "epoch:13 step:12630 [D loss: 0.642532, acc.: 63.28%] [G loss: 0.845755]\n",
      "epoch:13 step:12631 [D loss: 0.652896, acc.: 66.41%] [G loss: 0.886921]\n",
      "epoch:13 step:12632 [D loss: 0.683488, acc.: 55.47%] [G loss: 0.924818]\n",
      "epoch:13 step:12633 [D loss: 0.682033, acc.: 53.91%] [G loss: 0.873828]\n",
      "epoch:13 step:12634 [D loss: 0.630042, acc.: 62.50%] [G loss: 0.875817]\n",
      "epoch:13 step:12635 [D loss: 0.657773, acc.: 61.72%] [G loss: 0.876044]\n",
      "epoch:13 step:12636 [D loss: 0.675145, acc.: 50.78%] [G loss: 0.841611]\n",
      "epoch:13 step:12637 [D loss: 0.655105, acc.: 64.84%] [G loss: 0.843270]\n",
      "epoch:13 step:12638 [D loss: 0.649635, acc.: 59.38%] [G loss: 0.896009]\n",
      "epoch:13 step:12639 [D loss: 0.667148, acc.: 58.59%] [G loss: 0.856383]\n",
      "epoch:13 step:12640 [D loss: 0.631243, acc.: 62.50%] [G loss: 0.894453]\n",
      "epoch:13 step:12641 [D loss: 0.656565, acc.: 62.50%] [G loss: 0.874057]\n",
      "epoch:13 step:12642 [D loss: 0.687425, acc.: 55.47%] [G loss: 0.840344]\n",
      "epoch:13 step:12643 [D loss: 0.699131, acc.: 46.88%] [G loss: 0.839993]\n",
      "epoch:13 step:12644 [D loss: 0.663698, acc.: 64.06%] [G loss: 0.875768]\n",
      "epoch:13 step:12645 [D loss: 0.665079, acc.: 61.72%] [G loss: 0.875788]\n",
      "epoch:13 step:12646 [D loss: 0.685048, acc.: 55.47%] [G loss: 0.849040]\n",
      "epoch:13 step:12647 [D loss: 0.631297, acc.: 67.19%] [G loss: 0.872972]\n",
      "epoch:13 step:12648 [D loss: 0.636751, acc.: 65.62%] [G loss: 0.907540]\n",
      "epoch:13 step:12649 [D loss: 0.665996, acc.: 58.59%] [G loss: 0.867981]\n",
      "epoch:13 step:12650 [D loss: 0.634991, acc.: 61.72%] [G loss: 0.898062]\n",
      "epoch:13 step:12651 [D loss: 0.715057, acc.: 46.09%] [G loss: 0.850056]\n",
      "epoch:13 step:12652 [D loss: 0.643039, acc.: 67.97%] [G loss: 0.838936]\n",
      "epoch:13 step:12653 [D loss: 0.668836, acc.: 53.91%] [G loss: 0.825644]\n",
      "epoch:13 step:12654 [D loss: 0.674598, acc.: 50.78%] [G loss: 0.862198]\n",
      "epoch:13 step:12655 [D loss: 0.642706, acc.: 62.50%] [G loss: 0.872742]\n",
      "epoch:13 step:12656 [D loss: 0.667323, acc.: 55.47%] [G loss: 0.884833]\n",
      "epoch:13 step:12657 [D loss: 0.652203, acc.: 64.06%] [G loss: 0.880977]\n",
      "epoch:13 step:12658 [D loss: 0.691436, acc.: 52.34%] [G loss: 0.906473]\n",
      "epoch:13 step:12659 [D loss: 0.649311, acc.: 64.84%] [G loss: 0.886163]\n",
      "epoch:13 step:12660 [D loss: 0.661371, acc.: 56.25%] [G loss: 0.828083]\n",
      "epoch:13 step:12661 [D loss: 0.677647, acc.: 57.81%] [G loss: 0.794513]\n",
      "epoch:13 step:12662 [D loss: 0.654073, acc.: 57.81%] [G loss: 0.841146]\n",
      "epoch:13 step:12663 [D loss: 0.683869, acc.: 56.25%] [G loss: 0.867495]\n",
      "epoch:13 step:12664 [D loss: 0.703048, acc.: 49.22%] [G loss: 0.847660]\n",
      "epoch:13 step:12665 [D loss: 0.653708, acc.: 59.38%] [G loss: 0.866002]\n",
      "epoch:13 step:12666 [D loss: 0.680327, acc.: 58.59%] [G loss: 0.860465]\n",
      "epoch:13 step:12667 [D loss: 0.620754, acc.: 68.75%] [G loss: 0.804813]\n",
      "epoch:13 step:12668 [D loss: 0.674937, acc.: 55.47%] [G loss: 0.858523]\n",
      "epoch:13 step:12669 [D loss: 0.662201, acc.: 64.06%] [G loss: 0.820900]\n",
      "epoch:13 step:12670 [D loss: 0.661375, acc.: 56.25%] [G loss: 0.835623]\n",
      "epoch:13 step:12671 [D loss: 0.629809, acc.: 67.97%] [G loss: 0.852182]\n",
      "epoch:13 step:12672 [D loss: 0.668164, acc.: 60.16%] [G loss: 0.871625]\n",
      "epoch:13 step:12673 [D loss: 0.683130, acc.: 54.69%] [G loss: 0.849841]\n",
      "epoch:13 step:12674 [D loss: 0.686308, acc.: 56.25%] [G loss: 0.889956]\n",
      "epoch:13 step:12675 [D loss: 0.623346, acc.: 64.06%] [G loss: 0.911065]\n",
      "epoch:13 step:12676 [D loss: 0.687701, acc.: 54.69%] [G loss: 0.909439]\n",
      "epoch:13 step:12677 [D loss: 0.629237, acc.: 58.59%] [G loss: 0.915667]\n",
      "epoch:13 step:12678 [D loss: 0.629991, acc.: 57.81%] [G loss: 0.884740]\n",
      "epoch:13 step:12679 [D loss: 0.673706, acc.: 57.81%] [G loss: 0.871877]\n",
      "epoch:13 step:12680 [D loss: 0.646307, acc.: 64.84%] [G loss: 0.850089]\n",
      "epoch:13 step:12681 [D loss: 0.682840, acc.: 54.69%] [G loss: 0.850219]\n",
      "epoch:13 step:12682 [D loss: 0.673914, acc.: 60.16%] [G loss: 0.840482]\n",
      "epoch:13 step:12683 [D loss: 0.675289, acc.: 57.03%] [G loss: 0.805605]\n",
      "epoch:13 step:12684 [D loss: 0.696495, acc.: 50.78%] [G loss: 0.865777]\n",
      "epoch:13 step:12685 [D loss: 0.657319, acc.: 64.06%] [G loss: 0.875561]\n",
      "epoch:13 step:12686 [D loss: 0.673873, acc.: 64.84%] [G loss: 0.855074]\n",
      "epoch:13 step:12687 [D loss: 0.685380, acc.: 53.91%] [G loss: 0.821277]\n",
      "epoch:13 step:12688 [D loss: 0.643437, acc.: 64.06%] [G loss: 0.835800]\n",
      "epoch:13 step:12689 [D loss: 0.643017, acc.: 64.84%] [G loss: 0.829887]\n",
      "epoch:13 step:12690 [D loss: 0.651671, acc.: 59.38%] [G loss: 0.861469]\n",
      "epoch:13 step:12691 [D loss: 0.634360, acc.: 67.19%] [G loss: 0.828539]\n",
      "epoch:13 step:12692 [D loss: 0.651158, acc.: 63.28%] [G loss: 0.862125]\n",
      "epoch:13 step:12693 [D loss: 0.689147, acc.: 55.47%] [G loss: 0.838625]\n",
      "epoch:13 step:12694 [D loss: 0.680035, acc.: 59.38%] [G loss: 0.900631]\n",
      "epoch:13 step:12695 [D loss: 0.652290, acc.: 57.81%] [G loss: 0.927789]\n",
      "epoch:13 step:12696 [D loss: 0.644552, acc.: 63.28%] [G loss: 0.884604]\n",
      "epoch:13 step:12697 [D loss: 0.641096, acc.: 60.94%] [G loss: 0.892531]\n",
      "epoch:13 step:12698 [D loss: 0.645390, acc.: 61.72%] [G loss: 0.873972]\n",
      "epoch:13 step:12699 [D loss: 0.665873, acc.: 62.50%] [G loss: 0.821729]\n",
      "epoch:13 step:12700 [D loss: 0.647686, acc.: 58.59%] [G loss: 0.838247]\n",
      "epoch:13 step:12701 [D loss: 0.654489, acc.: 67.19%] [G loss: 0.855927]\n",
      "epoch:13 step:12702 [D loss: 0.668013, acc.: 60.16%] [G loss: 0.837296]\n",
      "epoch:13 step:12703 [D loss: 0.652566, acc.: 64.06%] [G loss: 0.900735]\n",
      "epoch:13 step:12704 [D loss: 0.634443, acc.: 63.28%] [G loss: 0.902431]\n",
      "epoch:13 step:12705 [D loss: 0.667779, acc.: 58.59%] [G loss: 0.899634]\n",
      "epoch:13 step:12706 [D loss: 0.696387, acc.: 49.22%] [G loss: 0.906866]\n",
      "epoch:13 step:12707 [D loss: 0.682405, acc.: 57.81%] [G loss: 0.904719]\n",
      "epoch:13 step:12708 [D loss: 0.652254, acc.: 64.06%] [G loss: 0.874708]\n",
      "epoch:13 step:12709 [D loss: 0.666625, acc.: 62.50%] [G loss: 0.857305]\n",
      "epoch:13 step:12710 [D loss: 0.671208, acc.: 55.47%] [G loss: 0.823263]\n",
      "epoch:13 step:12711 [D loss: 0.643083, acc.: 65.62%] [G loss: 0.886439]\n",
      "epoch:13 step:12712 [D loss: 0.669513, acc.: 63.28%] [G loss: 0.896906]\n",
      "epoch:13 step:12713 [D loss: 0.646148, acc.: 59.38%] [G loss: 0.895253]\n",
      "epoch:13 step:12714 [D loss: 0.664933, acc.: 57.81%] [G loss: 0.846798]\n",
      "epoch:13 step:12715 [D loss: 0.676446, acc.: 58.59%] [G loss: 0.828977]\n",
      "epoch:13 step:12716 [D loss: 0.681066, acc.: 60.16%] [G loss: 0.854689]\n",
      "epoch:13 step:12717 [D loss: 0.677756, acc.: 53.91%] [G loss: 0.883662]\n",
      "epoch:13 step:12718 [D loss: 0.678508, acc.: 62.50%] [G loss: 0.890136]\n",
      "epoch:13 step:12719 [D loss: 0.670544, acc.: 64.84%] [G loss: 0.840001]\n",
      "epoch:13 step:12720 [D loss: 0.708576, acc.: 48.44%] [G loss: 0.798693]\n",
      "epoch:13 step:12721 [D loss: 0.657389, acc.: 60.16%] [G loss: 0.842150]\n",
      "epoch:13 step:12722 [D loss: 0.661926, acc.: 57.03%] [G loss: 0.840483]\n",
      "epoch:13 step:12723 [D loss: 0.666069, acc.: 59.38%] [G loss: 0.892830]\n",
      "epoch:13 step:12724 [D loss: 0.640129, acc.: 60.94%] [G loss: 0.888515]\n",
      "epoch:13 step:12725 [D loss: 0.628748, acc.: 63.28%] [G loss: 0.860912]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12726 [D loss: 0.671022, acc.: 59.38%] [G loss: 0.870919]\n",
      "epoch:13 step:12727 [D loss: 0.692276, acc.: 57.03%] [G loss: 0.867108]\n",
      "epoch:13 step:12728 [D loss: 0.671488, acc.: 56.25%] [G loss: 0.887567]\n",
      "epoch:13 step:12729 [D loss: 0.668713, acc.: 60.16%] [G loss: 0.855017]\n",
      "epoch:13 step:12730 [D loss: 0.703256, acc.: 53.91%] [G loss: 0.852721]\n",
      "epoch:13 step:12731 [D loss: 0.655134, acc.: 60.94%] [G loss: 0.896041]\n",
      "epoch:13 step:12732 [D loss: 0.667155, acc.: 62.50%] [G loss: 0.910634]\n",
      "epoch:13 step:12733 [D loss: 0.677621, acc.: 60.94%] [G loss: 0.883160]\n",
      "epoch:13 step:12734 [D loss: 0.703320, acc.: 62.50%] [G loss: 0.839118]\n",
      "epoch:13 step:12735 [D loss: 0.681094, acc.: 59.38%] [G loss: 0.838164]\n",
      "epoch:13 step:12736 [D loss: 0.667632, acc.: 59.38%] [G loss: 0.839834]\n",
      "epoch:13 step:12737 [D loss: 0.672625, acc.: 60.16%] [G loss: 0.881804]\n",
      "epoch:13 step:12738 [D loss: 0.638446, acc.: 64.06%] [G loss: 0.850587]\n",
      "epoch:13 step:12739 [D loss: 0.655359, acc.: 57.03%] [G loss: 0.867017]\n",
      "epoch:13 step:12740 [D loss: 0.685692, acc.: 52.34%] [G loss: 0.805342]\n",
      "epoch:13 step:12741 [D loss: 0.642295, acc.: 60.16%] [G loss: 0.887205]\n",
      "epoch:13 step:12742 [D loss: 0.665437, acc.: 60.16%] [G loss: 0.878684]\n",
      "epoch:13 step:12743 [D loss: 0.672150, acc.: 60.94%] [G loss: 0.816538]\n",
      "epoch:13 step:12744 [D loss: 0.626603, acc.: 67.97%] [G loss: 0.858813]\n",
      "epoch:13 step:12745 [D loss: 0.638248, acc.: 65.62%] [G loss: 0.883284]\n",
      "epoch:13 step:12746 [D loss: 0.624815, acc.: 64.84%] [G loss: 0.860895]\n",
      "epoch:13 step:12747 [D loss: 0.679048, acc.: 56.25%] [G loss: 0.822285]\n",
      "epoch:13 step:12748 [D loss: 0.627454, acc.: 64.06%] [G loss: 0.895046]\n",
      "epoch:13 step:12749 [D loss: 0.713114, acc.: 50.00%] [G loss: 0.831718]\n",
      "epoch:13 step:12750 [D loss: 0.640609, acc.: 63.28%] [G loss: 0.876656]\n",
      "epoch:13 step:12751 [D loss: 0.668426, acc.: 62.50%] [G loss: 0.868528]\n",
      "epoch:13 step:12752 [D loss: 0.676932, acc.: 60.16%] [G loss: 0.891002]\n",
      "epoch:13 step:12753 [D loss: 0.657418, acc.: 60.94%] [G loss: 0.867658]\n",
      "epoch:13 step:12754 [D loss: 0.696800, acc.: 53.91%] [G loss: 0.869076]\n",
      "epoch:13 step:12755 [D loss: 0.651190, acc.: 60.16%] [G loss: 0.881555]\n",
      "epoch:13 step:12756 [D loss: 0.692505, acc.: 52.34%] [G loss: 0.863667]\n",
      "epoch:13 step:12757 [D loss: 0.667482, acc.: 62.50%] [G loss: 0.807698]\n",
      "epoch:13 step:12758 [D loss: 0.653568, acc.: 62.50%] [G loss: 0.871089]\n",
      "epoch:13 step:12759 [D loss: 0.650864, acc.: 64.06%] [G loss: 0.814685]\n",
      "epoch:13 step:12760 [D loss: 0.677243, acc.: 54.69%] [G loss: 0.751820]\n",
      "epoch:13 step:12761 [D loss: 0.672097, acc.: 57.03%] [G loss: 0.810616]\n",
      "epoch:13 step:12762 [D loss: 0.651077, acc.: 62.50%] [G loss: 0.858159]\n",
      "epoch:13 step:12763 [D loss: 0.674604, acc.: 64.06%] [G loss: 0.907659]\n",
      "epoch:13 step:12764 [D loss: 0.692353, acc.: 55.47%] [G loss: 0.800144]\n",
      "epoch:13 step:12765 [D loss: 0.651892, acc.: 63.28%] [G loss: 0.842716]\n",
      "epoch:13 step:12766 [D loss: 0.661896, acc.: 59.38%] [G loss: 0.870890]\n",
      "epoch:13 step:12767 [D loss: 0.684109, acc.: 58.59%] [G loss: 0.848803]\n",
      "epoch:13 step:12768 [D loss: 0.654470, acc.: 59.38%] [G loss: 0.857994]\n",
      "epoch:13 step:12769 [D loss: 0.664895, acc.: 59.38%] [G loss: 0.855801]\n",
      "epoch:13 step:12770 [D loss: 0.649879, acc.: 60.94%] [G loss: 0.822643]\n",
      "epoch:13 step:12771 [D loss: 0.669709, acc.: 55.47%] [G loss: 0.814379]\n",
      "epoch:13 step:12772 [D loss: 0.695085, acc.: 52.34%] [G loss: 0.849315]\n",
      "epoch:13 step:12773 [D loss: 0.689075, acc.: 51.56%] [G loss: 0.898322]\n",
      "epoch:13 step:12774 [D loss: 0.708261, acc.: 48.44%] [G loss: 0.811480]\n",
      "epoch:13 step:12775 [D loss: 0.677502, acc.: 56.25%] [G loss: 0.904317]\n",
      "epoch:13 step:12776 [D loss: 0.655612, acc.: 61.72%] [G loss: 0.911743]\n",
      "epoch:13 step:12777 [D loss: 0.660782, acc.: 57.03%] [G loss: 0.870092]\n",
      "epoch:13 step:12778 [D loss: 0.700447, acc.: 54.69%] [G loss: 0.802548]\n",
      "epoch:13 step:12779 [D loss: 0.695526, acc.: 53.91%] [G loss: 0.856312]\n",
      "epoch:13 step:12780 [D loss: 0.645021, acc.: 62.50%] [G loss: 0.854947]\n",
      "epoch:13 step:12781 [D loss: 0.686684, acc.: 50.00%] [G loss: 0.878246]\n",
      "epoch:13 step:12782 [D loss: 0.664067, acc.: 60.94%] [G loss: 0.884375]\n",
      "epoch:13 step:12783 [D loss: 0.643836, acc.: 66.41%] [G loss: 0.881148]\n",
      "epoch:13 step:12784 [D loss: 0.666342, acc.: 54.69%] [G loss: 0.823201]\n",
      "epoch:13 step:12785 [D loss: 0.695579, acc.: 49.22%] [G loss: 0.812580]\n",
      "epoch:13 step:12786 [D loss: 0.680236, acc.: 52.34%] [G loss: 0.845169]\n",
      "epoch:13 step:12787 [D loss: 0.667596, acc.: 59.38%] [G loss: 0.818712]\n",
      "epoch:13 step:12788 [D loss: 0.709912, acc.: 45.31%] [G loss: 0.840011]\n",
      "epoch:13 step:12789 [D loss: 0.667167, acc.: 58.59%] [G loss: 0.857764]\n",
      "epoch:13 step:12790 [D loss: 0.664212, acc.: 59.38%] [G loss: 0.860586]\n",
      "epoch:13 step:12791 [D loss: 0.661635, acc.: 57.81%] [G loss: 0.859574]\n",
      "epoch:13 step:12792 [D loss: 0.647939, acc.: 65.62%] [G loss: 0.824714]\n",
      "epoch:13 step:12793 [D loss: 0.652391, acc.: 60.94%] [G loss: 0.892403]\n",
      "epoch:13 step:12794 [D loss: 0.674591, acc.: 60.16%] [G loss: 0.858016]\n",
      "epoch:13 step:12795 [D loss: 0.648198, acc.: 61.72%] [G loss: 0.810359]\n",
      "epoch:13 step:12796 [D loss: 0.678204, acc.: 57.03%] [G loss: 0.809744]\n",
      "epoch:13 step:12797 [D loss: 0.669715, acc.: 57.03%] [G loss: 0.865357]\n",
      "epoch:13 step:12798 [D loss: 0.642862, acc.: 61.72%] [G loss: 0.828322]\n",
      "epoch:13 step:12799 [D loss: 0.636677, acc.: 66.41%] [G loss: 0.899729]\n",
      "epoch:13 step:12800 [D loss: 0.678984, acc.: 59.38%] [G loss: 0.842567]\n",
      "##############\n",
      "[2.92206806 2.25975757 1.97543015 4.40675009 1.21799311 9.27426719\n",
      " 2.84951804 3.29522518 4.15156084 6.31899078]\n",
      "##########\n",
      "epoch:13 step:12801 [D loss: 0.662458, acc.: 57.81%] [G loss: 0.846509]\n",
      "epoch:13 step:12802 [D loss: 0.661967, acc.: 62.50%] [G loss: 0.847505]\n",
      "epoch:13 step:12803 [D loss: 0.676557, acc.: 57.81%] [G loss: 0.866104]\n",
      "epoch:13 step:12804 [D loss: 0.657991, acc.: 60.94%] [G loss: 0.806766]\n",
      "epoch:13 step:12805 [D loss: 0.661914, acc.: 60.94%] [G loss: 0.875116]\n",
      "epoch:13 step:12806 [D loss: 0.685177, acc.: 53.91%] [G loss: 0.868311]\n",
      "epoch:13 step:12807 [D loss: 0.672554, acc.: 58.59%] [G loss: 0.850472]\n",
      "epoch:13 step:12808 [D loss: 0.626352, acc.: 67.19%] [G loss: 0.810473]\n",
      "epoch:13 step:12809 [D loss: 0.707610, acc.: 54.69%] [G loss: 0.854561]\n",
      "epoch:13 step:12810 [D loss: 0.642918, acc.: 66.41%] [G loss: 0.814844]\n",
      "epoch:13 step:12811 [D loss: 0.664736, acc.: 56.25%] [G loss: 0.862950]\n",
      "epoch:13 step:12812 [D loss: 0.659996, acc.: 60.16%] [G loss: 0.877242]\n",
      "epoch:13 step:12813 [D loss: 0.662411, acc.: 58.59%] [G loss: 0.840973]\n",
      "epoch:13 step:12814 [D loss: 0.652332, acc.: 62.50%] [G loss: 0.890093]\n",
      "epoch:13 step:12815 [D loss: 0.667205, acc.: 61.72%] [G loss: 0.872350]\n",
      "epoch:13 step:12816 [D loss: 0.695442, acc.: 56.25%] [G loss: 0.899362]\n",
      "epoch:13 step:12817 [D loss: 0.638112, acc.: 64.84%] [G loss: 0.861470]\n",
      "epoch:13 step:12818 [D loss: 0.648981, acc.: 60.94%] [G loss: 0.811383]\n",
      "epoch:13 step:12819 [D loss: 0.673746, acc.: 58.59%] [G loss: 0.845465]\n",
      "epoch:13 step:12820 [D loss: 0.679552, acc.: 56.25%] [G loss: 0.901200]\n",
      "epoch:13 step:12821 [D loss: 0.667889, acc.: 59.38%] [G loss: 0.836618]\n",
      "epoch:13 step:12822 [D loss: 0.692681, acc.: 56.25%] [G loss: 0.883125]\n",
      "epoch:13 step:12823 [D loss: 0.661884, acc.: 63.28%] [G loss: 0.830610]\n",
      "epoch:13 step:12824 [D loss: 0.716115, acc.: 48.44%] [G loss: 0.813378]\n",
      "epoch:13 step:12825 [D loss: 0.669104, acc.: 56.25%] [G loss: 0.855393]\n",
      "epoch:13 step:12826 [D loss: 0.657058, acc.: 54.69%] [G loss: 0.839577]\n",
      "epoch:13 step:12827 [D loss: 0.676028, acc.: 56.25%] [G loss: 0.857206]\n",
      "epoch:13 step:12828 [D loss: 0.693820, acc.: 55.47%] [G loss: 0.891396]\n",
      "epoch:13 step:12829 [D loss: 0.613616, acc.: 66.41%] [G loss: 0.910840]\n",
      "epoch:13 step:12830 [D loss: 0.654782, acc.: 59.38%] [G loss: 0.901072]\n",
      "epoch:13 step:12831 [D loss: 0.652649, acc.: 64.84%] [G loss: 0.897942]\n",
      "epoch:13 step:12832 [D loss: 0.632568, acc.: 60.94%] [G loss: 0.912734]\n",
      "epoch:13 step:12833 [D loss: 0.686511, acc.: 56.25%] [G loss: 0.872420]\n",
      "epoch:13 step:12834 [D loss: 0.637338, acc.: 58.59%] [G loss: 0.880505]\n",
      "epoch:13 step:12835 [D loss: 0.655926, acc.: 57.81%] [G loss: 0.808134]\n",
      "epoch:13 step:12836 [D loss: 0.689338, acc.: 54.69%] [G loss: 0.874010]\n",
      "epoch:13 step:12837 [D loss: 0.678311, acc.: 59.38%] [G loss: 0.846139]\n",
      "epoch:13 step:12838 [D loss: 0.657746, acc.: 58.59%] [G loss: 0.860758]\n",
      "epoch:13 step:12839 [D loss: 0.664855, acc.: 53.91%] [G loss: 0.846936]\n",
      "epoch:13 step:12840 [D loss: 0.652608, acc.: 63.28%] [G loss: 0.901676]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12841 [D loss: 0.685229, acc.: 58.59%] [G loss: 0.853491]\n",
      "epoch:13 step:12842 [D loss: 0.666655, acc.: 60.16%] [G loss: 0.912093]\n",
      "epoch:13 step:12843 [D loss: 0.697100, acc.: 58.59%] [G loss: 0.908806]\n",
      "epoch:13 step:12844 [D loss: 0.643198, acc.: 60.94%] [G loss: 0.904866]\n",
      "epoch:13 step:12845 [D loss: 0.676594, acc.: 60.16%] [G loss: 0.880787]\n",
      "epoch:13 step:12846 [D loss: 0.684172, acc.: 57.03%] [G loss: 0.841697]\n",
      "epoch:13 step:12847 [D loss: 0.664489, acc.: 61.72%] [G loss: 0.870299]\n",
      "epoch:13 step:12848 [D loss: 0.671977, acc.: 58.59%] [G loss: 0.834388]\n",
      "epoch:13 step:12849 [D loss: 0.693331, acc.: 58.59%] [G loss: 0.884794]\n",
      "epoch:13 step:12850 [D loss: 0.652679, acc.: 60.16%] [G loss: 0.870298]\n",
      "epoch:13 step:12851 [D loss: 0.665585, acc.: 54.69%] [G loss: 0.819885]\n",
      "epoch:13 step:12852 [D loss: 0.674204, acc.: 53.91%] [G loss: 0.850271]\n",
      "epoch:13 step:12853 [D loss: 0.676504, acc.: 53.12%] [G loss: 0.831253]\n",
      "epoch:13 step:12854 [D loss: 0.627095, acc.: 61.72%] [G loss: 0.847209]\n",
      "epoch:13 step:12855 [D loss: 0.678580, acc.: 53.91%] [G loss: 0.832065]\n",
      "epoch:13 step:12856 [D loss: 0.706798, acc.: 53.12%] [G loss: 0.856761]\n",
      "epoch:13 step:12857 [D loss: 0.651386, acc.: 57.81%] [G loss: 0.841905]\n",
      "epoch:13 step:12858 [D loss: 0.712421, acc.: 51.56%] [G loss: 0.843734]\n",
      "epoch:13 step:12859 [D loss: 0.667873, acc.: 57.03%] [G loss: 0.821068]\n",
      "epoch:13 step:12860 [D loss: 0.660425, acc.: 53.91%] [G loss: 0.828109]\n",
      "epoch:13 step:12861 [D loss: 0.692415, acc.: 50.78%] [G loss: 0.854711]\n",
      "epoch:13 step:12862 [D loss: 0.636182, acc.: 63.28%] [G loss: 0.840961]\n",
      "epoch:13 step:12863 [D loss: 0.677894, acc.: 55.47%] [G loss: 0.936712]\n",
      "epoch:13 step:12864 [D loss: 0.644745, acc.: 61.72%] [G loss: 0.867261]\n",
      "epoch:13 step:12865 [D loss: 0.661976, acc.: 54.69%] [G loss: 0.878505]\n",
      "epoch:13 step:12866 [D loss: 0.662948, acc.: 60.94%] [G loss: 0.867873]\n",
      "epoch:13 step:12867 [D loss: 0.659843, acc.: 59.38%] [G loss: 0.867185]\n",
      "epoch:13 step:12868 [D loss: 0.649101, acc.: 66.41%] [G loss: 0.849142]\n",
      "epoch:13 step:12869 [D loss: 0.621299, acc.: 65.62%] [G loss: 0.915158]\n",
      "epoch:13 step:12870 [D loss: 0.656412, acc.: 60.16%] [G loss: 0.899191]\n",
      "epoch:13 step:12871 [D loss: 0.659406, acc.: 60.16%] [G loss: 0.892958]\n",
      "epoch:13 step:12872 [D loss: 0.701795, acc.: 53.91%] [G loss: 0.822835]\n",
      "epoch:13 step:12873 [D loss: 0.688404, acc.: 60.16%] [G loss: 0.805376]\n",
      "epoch:13 step:12874 [D loss: 0.649932, acc.: 63.28%] [G loss: 0.839033]\n",
      "epoch:13 step:12875 [D loss: 0.670725, acc.: 64.06%] [G loss: 0.848716]\n",
      "epoch:13 step:12876 [D loss: 0.651428, acc.: 62.50%] [G loss: 0.836539]\n",
      "epoch:13 step:12877 [D loss: 0.661508, acc.: 61.72%] [G loss: 0.868110]\n",
      "epoch:13 step:12878 [D loss: 0.618593, acc.: 67.97%] [G loss: 0.871870]\n",
      "epoch:13 step:12879 [D loss: 0.669904, acc.: 57.03%] [G loss: 0.878880]\n",
      "epoch:13 step:12880 [D loss: 0.648918, acc.: 62.50%] [G loss: 0.878727]\n",
      "epoch:13 step:12881 [D loss: 0.678134, acc.: 52.34%] [G loss: 0.857412]\n",
      "epoch:13 step:12882 [D loss: 0.636228, acc.: 67.97%] [G loss: 0.904183]\n",
      "epoch:13 step:12883 [D loss: 0.643344, acc.: 61.72%] [G loss: 0.856054]\n",
      "epoch:13 step:12884 [D loss: 0.698990, acc.: 50.78%] [G loss: 0.850504]\n",
      "epoch:13 step:12885 [D loss: 0.659071, acc.: 60.94%] [G loss: 0.892730]\n",
      "epoch:13 step:12886 [D loss: 0.661590, acc.: 61.72%] [G loss: 0.863185]\n",
      "epoch:13 step:12887 [D loss: 0.687918, acc.: 59.38%] [G loss: 0.884552]\n",
      "epoch:13 step:12888 [D loss: 0.694184, acc.: 54.69%] [G loss: 0.845091]\n",
      "epoch:13 step:12889 [D loss: 0.669956, acc.: 55.47%] [G loss: 0.823191]\n",
      "epoch:13 step:12890 [D loss: 0.699182, acc.: 53.12%] [G loss: 0.812378]\n",
      "epoch:13 step:12891 [D loss: 0.641024, acc.: 64.06%] [G loss: 0.866442]\n",
      "epoch:13 step:12892 [D loss: 0.649108, acc.: 53.12%] [G loss: 0.813937]\n",
      "epoch:13 step:12893 [D loss: 0.706013, acc.: 53.91%] [G loss: 0.830247]\n",
      "epoch:13 step:12894 [D loss: 0.630533, acc.: 68.75%] [G loss: 0.876998]\n",
      "epoch:13 step:12895 [D loss: 0.701221, acc.: 50.78%] [G loss: 0.857439]\n",
      "epoch:13 step:12896 [D loss: 0.679565, acc.: 57.81%] [G loss: 0.828169]\n",
      "epoch:13 step:12897 [D loss: 0.670409, acc.: 60.16%] [G loss: 0.824940]\n",
      "epoch:13 step:12898 [D loss: 0.652360, acc.: 60.94%] [G loss: 0.841535]\n",
      "epoch:13 step:12899 [D loss: 0.658737, acc.: 60.16%] [G loss: 0.898703]\n",
      "epoch:13 step:12900 [D loss: 0.663190, acc.: 61.72%] [G loss: 0.895466]\n",
      "epoch:13 step:12901 [D loss: 0.657067, acc.: 59.38%] [G loss: 0.857485]\n",
      "epoch:13 step:12902 [D loss: 0.652267, acc.: 59.38%] [G loss: 0.841298]\n",
      "epoch:13 step:12903 [D loss: 0.630400, acc.: 64.06%] [G loss: 0.840129]\n",
      "epoch:13 step:12904 [D loss: 0.679267, acc.: 58.59%] [G loss: 0.898882]\n",
      "epoch:13 step:12905 [D loss: 0.683668, acc.: 56.25%] [G loss: 0.810765]\n",
      "epoch:13 step:12906 [D loss: 0.642446, acc.: 60.94%] [G loss: 0.849912]\n",
      "epoch:13 step:12907 [D loss: 0.664931, acc.: 58.59%] [G loss: 0.823869]\n",
      "epoch:13 step:12908 [D loss: 0.637291, acc.: 64.06%] [G loss: 0.848167]\n",
      "epoch:13 step:12909 [D loss: 0.695257, acc.: 53.91%] [G loss: 0.841627]\n",
      "epoch:13 step:12910 [D loss: 0.658388, acc.: 56.25%] [G loss: 0.828079]\n",
      "epoch:13 step:12911 [D loss: 0.676613, acc.: 57.81%] [G loss: 0.850586]\n",
      "epoch:13 step:12912 [D loss: 0.698615, acc.: 56.25%] [G loss: 0.890154]\n",
      "epoch:13 step:12913 [D loss: 0.654576, acc.: 62.50%] [G loss: 0.894518]\n",
      "epoch:13 step:12914 [D loss: 0.669881, acc.: 56.25%] [G loss: 0.851980]\n",
      "epoch:13 step:12915 [D loss: 0.658589, acc.: 59.38%] [G loss: 0.832103]\n",
      "epoch:13 step:12916 [D loss: 0.673753, acc.: 63.28%] [G loss: 0.838797]\n",
      "epoch:13 step:12917 [D loss: 0.631741, acc.: 66.41%] [G loss: 0.788659]\n",
      "epoch:13 step:12918 [D loss: 0.727588, acc.: 48.44%] [G loss: 0.850068]\n",
      "epoch:13 step:12919 [D loss: 0.690211, acc.: 51.56%] [G loss: 0.849232]\n",
      "epoch:13 step:12920 [D loss: 0.696069, acc.: 46.88%] [G loss: 0.894047]\n",
      "epoch:13 step:12921 [D loss: 0.690707, acc.: 54.69%] [G loss: 0.852142]\n",
      "epoch:13 step:12922 [D loss: 0.657409, acc.: 57.03%] [G loss: 0.871996]\n",
      "epoch:13 step:12923 [D loss: 0.676589, acc.: 57.81%] [G loss: 0.852998]\n",
      "epoch:13 step:12924 [D loss: 0.679259, acc.: 49.22%] [G loss: 0.864334]\n",
      "epoch:13 step:12925 [D loss: 0.641497, acc.: 59.38%] [G loss: 0.845840]\n",
      "epoch:13 step:12926 [D loss: 0.661629, acc.: 65.62%] [G loss: 0.822901]\n",
      "epoch:13 step:12927 [D loss: 0.702127, acc.: 51.56%] [G loss: 0.840677]\n",
      "epoch:13 step:12928 [D loss: 0.673939, acc.: 58.59%] [G loss: 0.854268]\n",
      "epoch:13 step:12929 [D loss: 0.663538, acc.: 57.81%] [G loss: 0.821732]\n",
      "epoch:13 step:12930 [D loss: 0.660809, acc.: 62.50%] [G loss: 0.870009]\n",
      "epoch:13 step:12931 [D loss: 0.646440, acc.: 63.28%] [G loss: 0.829228]\n",
      "epoch:13 step:12932 [D loss: 0.655751, acc.: 61.72%] [G loss: 0.844971]\n",
      "epoch:13 step:12933 [D loss: 0.656237, acc.: 60.94%] [G loss: 0.837243]\n",
      "epoch:13 step:12934 [D loss: 0.681822, acc.: 59.38%] [G loss: 0.873470]\n",
      "epoch:13 step:12935 [D loss: 0.687431, acc.: 59.38%] [G loss: 0.905771]\n",
      "epoch:13 step:12936 [D loss: 0.673939, acc.: 58.59%] [G loss: 0.906865]\n",
      "epoch:13 step:12937 [D loss: 0.675285, acc.: 59.38%] [G loss: 0.877349]\n",
      "epoch:13 step:12938 [D loss: 0.661703, acc.: 55.47%] [G loss: 0.879805]\n",
      "epoch:13 step:12939 [D loss: 0.729712, acc.: 46.09%] [G loss: 0.868365]\n",
      "epoch:13 step:12940 [D loss: 0.665404, acc.: 59.38%] [G loss: 0.826443]\n",
      "epoch:13 step:12941 [D loss: 0.673862, acc.: 57.03%] [G loss: 0.843307]\n",
      "epoch:13 step:12942 [D loss: 0.656192, acc.: 57.81%] [G loss: 0.860147]\n",
      "epoch:13 step:12943 [D loss: 0.690535, acc.: 50.00%] [G loss: 0.852114]\n",
      "epoch:13 step:12944 [D loss: 0.664612, acc.: 57.81%] [G loss: 0.864183]\n",
      "epoch:13 step:12945 [D loss: 0.671023, acc.: 57.81%] [G loss: 0.876873]\n",
      "epoch:13 step:12946 [D loss: 0.655342, acc.: 58.59%] [G loss: 0.855200]\n",
      "epoch:13 step:12947 [D loss: 0.683425, acc.: 53.91%] [G loss: 0.878694]\n",
      "epoch:13 step:12948 [D loss: 0.690087, acc.: 54.69%] [G loss: 0.864273]\n",
      "epoch:13 step:12949 [D loss: 0.636110, acc.: 63.28%] [G loss: 0.855621]\n",
      "epoch:13 step:12950 [D loss: 0.672040, acc.: 61.72%] [G loss: 0.867923]\n",
      "epoch:13 step:12951 [D loss: 0.713219, acc.: 47.66%] [G loss: 0.891363]\n",
      "epoch:13 step:12952 [D loss: 0.639486, acc.: 70.31%] [G loss: 0.903326]\n",
      "epoch:13 step:12953 [D loss: 0.657524, acc.: 57.03%] [G loss: 0.878905]\n",
      "epoch:13 step:12954 [D loss: 0.659613, acc.: 58.59%] [G loss: 0.868013]\n",
      "epoch:13 step:12955 [D loss: 0.667335, acc.: 56.25%] [G loss: 0.879235]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:12956 [D loss: 0.674237, acc.: 60.16%] [G loss: 0.849312]\n",
      "epoch:13 step:12957 [D loss: 0.670605, acc.: 62.50%] [G loss: 0.857027]\n",
      "epoch:13 step:12958 [D loss: 0.679847, acc.: 52.34%] [G loss: 0.866237]\n",
      "epoch:13 step:12959 [D loss: 0.653749, acc.: 66.41%] [G loss: 0.896859]\n",
      "epoch:13 step:12960 [D loss: 0.680413, acc.: 55.47%] [G loss: 0.843946]\n",
      "epoch:13 step:12961 [D loss: 0.694385, acc.: 56.25%] [G loss: 0.867259]\n",
      "epoch:13 step:12962 [D loss: 0.691932, acc.: 56.25%] [G loss: 0.876921]\n",
      "epoch:13 step:12963 [D loss: 0.640617, acc.: 61.72%] [G loss: 0.907340]\n",
      "epoch:13 step:12964 [D loss: 0.662138, acc.: 60.16%] [G loss: 0.878871]\n",
      "epoch:13 step:12965 [D loss: 0.641966, acc.: 65.62%] [G loss: 0.889181]\n",
      "epoch:13 step:12966 [D loss: 0.694196, acc.: 50.78%] [G loss: 0.888919]\n",
      "epoch:13 step:12967 [D loss: 0.661928, acc.: 57.03%] [G loss: 0.846862]\n",
      "epoch:13 step:12968 [D loss: 0.672681, acc.: 60.16%] [G loss: 0.869320]\n",
      "epoch:13 step:12969 [D loss: 0.658181, acc.: 62.50%] [G loss: 0.853368]\n",
      "epoch:13 step:12970 [D loss: 0.625684, acc.: 64.84%] [G loss: 0.862901]\n",
      "epoch:13 step:12971 [D loss: 0.644830, acc.: 67.19%] [G loss: 0.858585]\n",
      "epoch:13 step:12972 [D loss: 0.664955, acc.: 57.81%] [G loss: 0.853988]\n",
      "epoch:13 step:12973 [D loss: 0.665128, acc.: 56.25%] [G loss: 0.870658]\n",
      "epoch:13 step:12974 [D loss: 0.674794, acc.: 58.59%] [G loss: 0.875993]\n",
      "epoch:13 step:12975 [D loss: 0.664893, acc.: 60.94%] [G loss: 0.911803]\n",
      "epoch:13 step:12976 [D loss: 0.660460, acc.: 57.81%] [G loss: 0.897647]\n",
      "epoch:13 step:12977 [D loss: 0.682893, acc.: 56.25%] [G loss: 0.850956]\n",
      "epoch:13 step:12978 [D loss: 0.688667, acc.: 55.47%] [G loss: 0.874670]\n",
      "epoch:13 step:12979 [D loss: 0.669139, acc.: 56.25%] [G loss: 0.841842]\n",
      "epoch:13 step:12980 [D loss: 0.691156, acc.: 56.25%] [G loss: 0.864771]\n",
      "epoch:13 step:12981 [D loss: 0.642528, acc.: 60.94%] [G loss: 0.877158]\n",
      "epoch:13 step:12982 [D loss: 0.640274, acc.: 62.50%] [G loss: 0.898597]\n",
      "epoch:13 step:12983 [D loss: 0.711937, acc.: 54.69%] [G loss: 0.843252]\n",
      "epoch:13 step:12984 [D loss: 0.666189, acc.: 64.84%] [G loss: 0.889594]\n",
      "epoch:13 step:12985 [D loss: 0.734079, acc.: 46.88%] [G loss: 0.815860]\n",
      "epoch:13 step:12986 [D loss: 0.688317, acc.: 55.47%] [G loss: 0.834569]\n",
      "epoch:13 step:12987 [D loss: 0.646941, acc.: 66.41%] [G loss: 0.838695]\n",
      "epoch:13 step:12988 [D loss: 0.647533, acc.: 59.38%] [G loss: 0.819468]\n",
      "epoch:13 step:12989 [D loss: 0.661469, acc.: 60.16%] [G loss: 0.858222]\n",
      "epoch:13 step:12990 [D loss: 0.632123, acc.: 64.84%] [G loss: 0.850444]\n",
      "epoch:13 step:12991 [D loss: 0.637704, acc.: 61.72%] [G loss: 0.830611]\n",
      "epoch:13 step:12992 [D loss: 0.656904, acc.: 57.81%] [G loss: 0.818073]\n",
      "epoch:13 step:12993 [D loss: 0.692304, acc.: 56.25%] [G loss: 0.875540]\n",
      "epoch:13 step:12994 [D loss: 0.641976, acc.: 63.28%] [G loss: 0.899224]\n",
      "epoch:13 step:12995 [D loss: 0.645501, acc.: 69.53%] [G loss: 0.881336]\n",
      "epoch:13 step:12996 [D loss: 0.679787, acc.: 56.25%] [G loss: 0.891046]\n",
      "epoch:13 step:12997 [D loss: 0.635989, acc.: 60.16%] [G loss: 0.893566]\n",
      "epoch:13 step:12998 [D loss: 0.666457, acc.: 57.81%] [G loss: 0.892636]\n",
      "epoch:13 step:12999 [D loss: 0.688405, acc.: 52.34%] [G loss: 0.849668]\n",
      "epoch:13 step:13000 [D loss: 0.707073, acc.: 50.78%] [G loss: 0.834086]\n",
      "##############\n",
      "[3.07928876 2.50572139 2.21446502 4.00053501 1.59656794 8.33907869\n",
      " 3.04433223 3.9499066  4.29189493 8.14868929]\n",
      "##########\n",
      "epoch:13 step:13001 [D loss: 0.662214, acc.: 60.94%] [G loss: 0.802650]\n",
      "epoch:13 step:13002 [D loss: 0.681503, acc.: 57.81%] [G loss: 0.891167]\n",
      "epoch:13 step:13003 [D loss: 0.652305, acc.: 62.50%] [G loss: 0.804023]\n",
      "epoch:13 step:13004 [D loss: 0.698767, acc.: 51.56%] [G loss: 0.813541]\n",
      "epoch:13 step:13005 [D loss: 0.661321, acc.: 57.81%] [G loss: 0.826909]\n",
      "epoch:13 step:13006 [D loss: 0.659915, acc.: 54.69%] [G loss: 0.855209]\n",
      "epoch:13 step:13007 [D loss: 0.671833, acc.: 56.25%] [G loss: 0.853818]\n",
      "epoch:13 step:13008 [D loss: 0.687589, acc.: 56.25%] [G loss: 0.833501]\n",
      "epoch:13 step:13009 [D loss: 0.689503, acc.: 51.56%] [G loss: 0.841026]\n",
      "epoch:13 step:13010 [D loss: 0.654325, acc.: 60.16%] [G loss: 0.817150]\n",
      "epoch:13 step:13011 [D loss: 0.679124, acc.: 58.59%] [G loss: 0.854752]\n",
      "epoch:13 step:13012 [D loss: 0.680699, acc.: 54.69%] [G loss: 0.813302]\n",
      "epoch:13 step:13013 [D loss: 0.684107, acc.: 51.56%] [G loss: 0.837285]\n",
      "epoch:13 step:13014 [D loss: 0.686112, acc.: 53.12%] [G loss: 0.827986]\n",
      "epoch:13 step:13015 [D loss: 0.672855, acc.: 60.16%] [G loss: 0.856727]\n",
      "epoch:13 step:13016 [D loss: 0.664750, acc.: 66.41%] [G loss: 0.851755]\n",
      "epoch:13 step:13017 [D loss: 0.664687, acc.: 56.25%] [G loss: 0.826689]\n",
      "epoch:13 step:13018 [D loss: 0.694371, acc.: 56.25%] [G loss: 0.845587]\n",
      "epoch:13 step:13019 [D loss: 0.685764, acc.: 59.38%] [G loss: 0.826159]\n",
      "epoch:13 step:13020 [D loss: 0.645941, acc.: 63.28%] [G loss: 0.849368]\n",
      "epoch:13 step:13021 [D loss: 0.704684, acc.: 52.34%] [G loss: 0.841220]\n",
      "epoch:13 step:13022 [D loss: 0.702690, acc.: 46.09%] [G loss: 0.795460]\n",
      "epoch:13 step:13023 [D loss: 0.719611, acc.: 46.09%] [G loss: 0.805275]\n",
      "epoch:13 step:13024 [D loss: 0.692545, acc.: 50.00%] [G loss: 0.811725]\n",
      "epoch:13 step:13025 [D loss: 0.687960, acc.: 57.03%] [G loss: 0.846670]\n",
      "epoch:13 step:13026 [D loss: 0.704686, acc.: 51.56%] [G loss: 0.803762]\n",
      "epoch:13 step:13027 [D loss: 0.659038, acc.: 63.28%] [G loss: 0.842003]\n",
      "epoch:13 step:13028 [D loss: 0.661889, acc.: 61.72%] [G loss: 0.847428]\n",
      "epoch:13 step:13029 [D loss: 0.636372, acc.: 67.19%] [G loss: 0.865783]\n",
      "epoch:13 step:13030 [D loss: 0.658795, acc.: 60.16%] [G loss: 0.879366]\n",
      "epoch:13 step:13031 [D loss: 0.627648, acc.: 70.31%] [G loss: 0.858003]\n",
      "epoch:13 step:13032 [D loss: 0.688681, acc.: 57.03%] [G loss: 0.859799]\n",
      "epoch:13 step:13033 [D loss: 0.677435, acc.: 58.59%] [G loss: 0.826601]\n",
      "epoch:13 step:13034 [D loss: 0.669222, acc.: 61.72%] [G loss: 0.898018]\n",
      "epoch:13 step:13035 [D loss: 0.678736, acc.: 56.25%] [G loss: 0.836544]\n",
      "epoch:13 step:13036 [D loss: 0.710968, acc.: 55.47%] [G loss: 0.862720]\n",
      "epoch:13 step:13037 [D loss: 0.650265, acc.: 62.50%] [G loss: 0.854223]\n",
      "epoch:13 step:13038 [D loss: 0.680986, acc.: 56.25%] [G loss: 0.900500]\n",
      "epoch:13 step:13039 [D loss: 0.682428, acc.: 55.47%] [G loss: 0.884572]\n",
      "epoch:13 step:13040 [D loss: 0.661615, acc.: 60.94%] [G loss: 0.825484]\n",
      "epoch:13 step:13041 [D loss: 0.667371, acc.: 58.59%] [G loss: 0.814903]\n",
      "epoch:13 step:13042 [D loss: 0.627093, acc.: 61.72%] [G loss: 0.811588]\n",
      "epoch:13 step:13043 [D loss: 0.646711, acc.: 62.50%] [G loss: 0.763375]\n",
      "epoch:13 step:13044 [D loss: 0.691837, acc.: 56.25%] [G loss: 0.799222]\n",
      "epoch:13 step:13045 [D loss: 0.662414, acc.: 58.59%] [G loss: 0.843964]\n",
      "epoch:13 step:13046 [D loss: 0.670470, acc.: 53.91%] [G loss: 0.869839]\n",
      "epoch:13 step:13047 [D loss: 0.676050, acc.: 57.81%] [G loss: 0.918549]\n",
      "epoch:13 step:13048 [D loss: 0.690882, acc.: 57.81%] [G loss: 0.889771]\n",
      "epoch:13 step:13049 [D loss: 0.667720, acc.: 62.50%] [G loss: 0.910178]\n",
      "epoch:13 step:13050 [D loss: 0.678500, acc.: 57.81%] [G loss: 0.834560]\n",
      "epoch:13 step:13051 [D loss: 0.667272, acc.: 57.03%] [G loss: 0.880276]\n",
      "epoch:13 step:13052 [D loss: 0.637303, acc.: 67.97%] [G loss: 0.923254]\n",
      "epoch:13 step:13053 [D loss: 0.677987, acc.: 53.12%] [G loss: 0.867593]\n",
      "epoch:13 step:13054 [D loss: 0.643233, acc.: 61.72%] [G loss: 0.830119]\n",
      "epoch:13 step:13055 [D loss: 0.663312, acc.: 58.59%] [G loss: 0.861403]\n",
      "epoch:13 step:13056 [D loss: 0.627281, acc.: 65.62%] [G loss: 0.876724]\n",
      "epoch:13 step:13057 [D loss: 0.677123, acc.: 57.81%] [G loss: 0.828744]\n",
      "epoch:13 step:13058 [D loss: 0.643851, acc.: 64.06%] [G loss: 0.842714]\n",
      "epoch:13 step:13059 [D loss: 0.680365, acc.: 55.47%] [G loss: 0.821103]\n",
      "epoch:13 step:13060 [D loss: 0.661087, acc.: 57.81%] [G loss: 0.797941]\n",
      "epoch:13 step:13061 [D loss: 0.669108, acc.: 57.81%] [G loss: 0.845382]\n",
      "epoch:13 step:13062 [D loss: 0.669399, acc.: 55.47%] [G loss: 0.824009]\n",
      "epoch:13 step:13063 [D loss: 0.674651, acc.: 56.25%] [G loss: 0.775701]\n",
      "epoch:13 step:13064 [D loss: 0.689127, acc.: 55.47%] [G loss: 0.844082]\n",
      "epoch:13 step:13065 [D loss: 0.643846, acc.: 60.94%] [G loss: 0.811589]\n",
      "epoch:13 step:13066 [D loss: 0.681132, acc.: 59.38%] [G loss: 0.848923]\n",
      "epoch:13 step:13067 [D loss: 0.676793, acc.: 53.12%] [G loss: 0.842571]\n",
      "epoch:13 step:13068 [D loss: 0.656951, acc.: 61.72%] [G loss: 0.867832]\n",
      "epoch:13 step:13069 [D loss: 0.662073, acc.: 61.72%] [G loss: 0.895009]\n",
      "epoch:13 step:13070 [D loss: 0.677195, acc.: 59.38%] [G loss: 0.890425]\n",
      "epoch:13 step:13071 [D loss: 0.648241, acc.: 66.41%] [G loss: 0.923475]\n",
      "epoch:13 step:13072 [D loss: 0.686465, acc.: 50.00%] [G loss: 0.856693]\n",
      "epoch:13 step:13073 [D loss: 0.652135, acc.: 63.28%] [G loss: 0.872523]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:13 step:13074 [D loss: 0.661296, acc.: 60.94%] [G loss: 0.822148]\n",
      "epoch:13 step:13075 [D loss: 0.651403, acc.: 64.06%] [G loss: 0.832282]\n",
      "epoch:13 step:13076 [D loss: 0.646451, acc.: 65.62%] [G loss: 0.813480]\n",
      "epoch:13 step:13077 [D loss: 0.671589, acc.: 57.03%] [G loss: 0.859532]\n",
      "epoch:13 step:13078 [D loss: 0.650134, acc.: 63.28%] [G loss: 0.840724]\n",
      "epoch:13 step:13079 [D loss: 0.675493, acc.: 60.94%] [G loss: 0.838312]\n",
      "epoch:13 step:13080 [D loss: 0.648687, acc.: 65.62%] [G loss: 0.862614]\n",
      "epoch:13 step:13081 [D loss: 0.684411, acc.: 58.59%] [G loss: 0.850688]\n",
      "epoch:13 step:13082 [D loss: 0.667231, acc.: 57.81%] [G loss: 0.860856]\n",
      "epoch:13 step:13083 [D loss: 0.660393, acc.: 59.38%] [G loss: 0.873901]\n",
      "epoch:13 step:13084 [D loss: 0.626646, acc.: 66.41%] [G loss: 0.846038]\n",
      "epoch:13 step:13085 [D loss: 0.660138, acc.: 58.59%] [G loss: 0.886420]\n",
      "epoch:13 step:13086 [D loss: 0.671204, acc.: 55.47%] [G loss: 0.832112]\n",
      "epoch:13 step:13087 [D loss: 0.646110, acc.: 62.50%] [G loss: 0.864129]\n",
      "epoch:13 step:13088 [D loss: 0.697942, acc.: 54.69%] [G loss: 0.843246]\n",
      "epoch:13 step:13089 [D loss: 0.700180, acc.: 53.91%] [G loss: 0.820082]\n",
      "epoch:13 step:13090 [D loss: 0.669803, acc.: 58.59%] [G loss: 0.870101]\n",
      "epoch:13 step:13091 [D loss: 0.684325, acc.: 53.12%] [G loss: 0.844048]\n",
      "epoch:13 step:13092 [D loss: 0.681812, acc.: 57.03%] [G loss: 0.884942]\n",
      "epoch:13 step:13093 [D loss: 0.671294, acc.: 53.91%] [G loss: 0.902762]\n",
      "epoch:13 step:13094 [D loss: 0.666184, acc.: 57.03%] [G loss: 0.865351]\n",
      "epoch:13 step:13095 [D loss: 0.667556, acc.: 59.38%] [G loss: 0.874795]\n",
      "epoch:13 step:13096 [D loss: 0.663867, acc.: 56.25%] [G loss: 0.837497]\n",
      "epoch:13 step:13097 [D loss: 0.673246, acc.: 56.25%] [G loss: 0.821147]\n",
      "epoch:13 step:13098 [D loss: 0.652246, acc.: 63.28%] [G loss: 0.852754]\n",
      "epoch:13 step:13099 [D loss: 0.660363, acc.: 59.38%] [G loss: 0.821468]\n",
      "epoch:13 step:13100 [D loss: 0.681878, acc.: 55.47%] [G loss: 0.842748]\n",
      "epoch:13 step:13101 [D loss: 0.663250, acc.: 60.16%] [G loss: 0.824506]\n",
      "epoch:13 step:13102 [D loss: 0.657587, acc.: 58.59%] [G loss: 0.829479]\n",
      "epoch:13 step:13103 [D loss: 0.650632, acc.: 64.84%] [G loss: 0.829951]\n",
      "epoch:13 step:13104 [D loss: 0.643121, acc.: 60.16%] [G loss: 0.812880]\n",
      "epoch:13 step:13105 [D loss: 0.675134, acc.: 57.81%] [G loss: 0.810410]\n",
      "epoch:13 step:13106 [D loss: 0.660194, acc.: 56.25%] [G loss: 0.835379]\n",
      "epoch:13 step:13107 [D loss: 0.676014, acc.: 57.03%] [G loss: 0.859514]\n",
      "epoch:13 step:13108 [D loss: 0.683320, acc.: 58.59%] [G loss: 0.854209]\n",
      "epoch:13 step:13109 [D loss: 0.665375, acc.: 59.38%] [G loss: 0.858571]\n",
      "epoch:13 step:13110 [D loss: 0.666438, acc.: 63.28%] [G loss: 0.836798]\n",
      "epoch:13 step:13111 [D loss: 0.668269, acc.: 52.34%] [G loss: 0.800162]\n",
      "epoch:13 step:13112 [D loss: 0.681731, acc.: 58.59%] [G loss: 0.835239]\n",
      "epoch:13 step:13113 [D loss: 0.656721, acc.: 56.25%] [G loss: 0.855492]\n",
      "epoch:13 step:13114 [D loss: 0.664358, acc.: 57.81%] [G loss: 0.817068]\n",
      "epoch:13 step:13115 [D loss: 0.660048, acc.: 58.59%] [G loss: 0.811763]\n",
      "epoch:13 step:13116 [D loss: 0.655844, acc.: 63.28%] [G loss: 0.769178]\n",
      "epoch:13 step:13117 [D loss: 0.637744, acc.: 62.50%] [G loss: 0.861486]\n",
      "epoch:13 step:13118 [D loss: 0.660220, acc.: 57.81%] [G loss: 0.834535]\n",
      "epoch:14 step:13119 [D loss: 0.699374, acc.: 53.91%] [G loss: 0.854737]\n",
      "epoch:14 step:13120 [D loss: 0.633777, acc.: 67.19%] [G loss: 0.850110]\n",
      "epoch:14 step:13121 [D loss: 0.681740, acc.: 53.12%] [G loss: 0.835687]\n",
      "epoch:14 step:13122 [D loss: 0.683379, acc.: 56.25%] [G loss: 0.851520]\n",
      "epoch:14 step:13123 [D loss: 0.678858, acc.: 55.47%] [G loss: 0.848955]\n",
      "epoch:14 step:13124 [D loss: 0.684680, acc.: 60.16%] [G loss: 0.875311]\n",
      "epoch:14 step:13125 [D loss: 0.693846, acc.: 54.69%] [G loss: 0.893698]\n",
      "epoch:14 step:13126 [D loss: 0.699452, acc.: 55.47%] [G loss: 0.836975]\n",
      "epoch:14 step:13127 [D loss: 0.675503, acc.: 57.03%] [G loss: 0.836355]\n",
      "epoch:14 step:13128 [D loss: 0.637056, acc.: 66.41%] [G loss: 0.831694]\n",
      "epoch:14 step:13129 [D loss: 0.637259, acc.: 62.50%] [G loss: 0.861466]\n",
      "epoch:14 step:13130 [D loss: 0.668587, acc.: 54.69%] [G loss: 0.791270]\n",
      "epoch:14 step:13131 [D loss: 0.664164, acc.: 61.72%] [G loss: 0.790116]\n",
      "epoch:14 step:13132 [D loss: 0.681176, acc.: 57.81%] [G loss: 0.819191]\n",
      "epoch:14 step:13133 [D loss: 0.654815, acc.: 64.06%] [G loss: 0.851230]\n",
      "epoch:14 step:13134 [D loss: 0.655622, acc.: 57.03%] [G loss: 0.814457]\n",
      "epoch:14 step:13135 [D loss: 0.675163, acc.: 57.81%] [G loss: 0.863987]\n",
      "epoch:14 step:13136 [D loss: 0.665408, acc.: 60.16%] [G loss: 0.818738]\n",
      "epoch:14 step:13137 [D loss: 0.716888, acc.: 53.12%] [G loss: 0.787178]\n",
      "epoch:14 step:13138 [D loss: 0.693847, acc.: 53.12%] [G loss: 0.847748]\n",
      "epoch:14 step:13139 [D loss: 0.682258, acc.: 52.34%] [G loss: 0.909187]\n",
      "epoch:14 step:13140 [D loss: 0.663569, acc.: 59.38%] [G loss: 0.883649]\n",
      "epoch:14 step:13141 [D loss: 0.658900, acc.: 60.94%] [G loss: 0.893095]\n",
      "epoch:14 step:13142 [D loss: 0.702898, acc.: 50.00%] [G loss: 0.892668]\n",
      "epoch:14 step:13143 [D loss: 0.667070, acc.: 58.59%] [G loss: 0.893664]\n",
      "epoch:14 step:13144 [D loss: 0.683048, acc.: 54.69%] [G loss: 0.868392]\n",
      "epoch:14 step:13145 [D loss: 0.658732, acc.: 59.38%] [G loss: 0.819117]\n",
      "epoch:14 step:13146 [D loss: 0.694333, acc.: 53.91%] [G loss: 0.788410]\n",
      "epoch:14 step:13147 [D loss: 0.668169, acc.: 60.16%] [G loss: 0.865146]\n",
      "epoch:14 step:13148 [D loss: 0.658667, acc.: 62.50%] [G loss: 0.854082]\n",
      "epoch:14 step:13149 [D loss: 0.699605, acc.: 53.12%] [G loss: 0.856284]\n",
      "epoch:14 step:13150 [D loss: 0.680133, acc.: 53.91%] [G loss: 0.843869]\n",
      "epoch:14 step:13151 [D loss: 0.683579, acc.: 55.47%] [G loss: 0.811089]\n",
      "epoch:14 step:13152 [D loss: 0.686156, acc.: 51.56%] [G loss: 0.810032]\n",
      "epoch:14 step:13153 [D loss: 0.652198, acc.: 62.50%] [G loss: 0.830063]\n",
      "epoch:14 step:13154 [D loss: 0.640069, acc.: 62.50%] [G loss: 0.873746]\n",
      "epoch:14 step:13155 [D loss: 0.652669, acc.: 60.16%] [G loss: 0.847496]\n",
      "epoch:14 step:13156 [D loss: 0.702813, acc.: 52.34%] [G loss: 0.884007]\n",
      "epoch:14 step:13157 [D loss: 0.687654, acc.: 50.78%] [G loss: 0.840120]\n",
      "epoch:14 step:13158 [D loss: 0.676224, acc.: 56.25%] [G loss: 0.902691]\n",
      "epoch:14 step:13159 [D loss: 0.682077, acc.: 55.47%] [G loss: 0.893458]\n",
      "epoch:14 step:13160 [D loss: 0.686661, acc.: 55.47%] [G loss: 0.823443]\n",
      "epoch:14 step:13161 [D loss: 0.679598, acc.: 58.59%] [G loss: 0.847462]\n",
      "epoch:14 step:13162 [D loss: 0.654618, acc.: 60.16%] [G loss: 0.802105]\n",
      "epoch:14 step:13163 [D loss: 0.719209, acc.: 52.34%] [G loss: 0.837931]\n",
      "epoch:14 step:13164 [D loss: 0.664885, acc.: 57.03%] [G loss: 0.798010]\n",
      "epoch:14 step:13165 [D loss: 0.677337, acc.: 55.47%] [G loss: 0.811413]\n",
      "epoch:14 step:13166 [D loss: 0.636696, acc.: 66.41%] [G loss: 0.805144]\n",
      "epoch:14 step:13167 [D loss: 0.681972, acc.: 57.03%] [G loss: 0.862038]\n",
      "epoch:14 step:13168 [D loss: 0.654903, acc.: 62.50%] [G loss: 0.889731]\n",
      "epoch:14 step:13169 [D loss: 0.665655, acc.: 61.72%] [G loss: 0.847814]\n",
      "epoch:14 step:13170 [D loss: 0.677379, acc.: 56.25%] [G loss: 0.847834]\n",
      "epoch:14 step:13171 [D loss: 0.642801, acc.: 67.19%] [G loss: 0.814868]\n",
      "epoch:14 step:13172 [D loss: 0.681330, acc.: 57.03%] [G loss: 0.844146]\n",
      "epoch:14 step:13173 [D loss: 0.676231, acc.: 57.81%] [G loss: 0.854056]\n",
      "epoch:14 step:13174 [D loss: 0.663017, acc.: 60.94%] [G loss: 0.824667]\n",
      "epoch:14 step:13175 [D loss: 0.675384, acc.: 56.25%] [G loss: 0.819868]\n",
      "epoch:14 step:13176 [D loss: 0.672640, acc.: 60.16%] [G loss: 0.846187]\n",
      "epoch:14 step:13177 [D loss: 0.641594, acc.: 60.16%] [G loss: 0.841136]\n",
      "epoch:14 step:13178 [D loss: 0.668063, acc.: 53.91%] [G loss: 0.861181]\n",
      "epoch:14 step:13179 [D loss: 0.671037, acc.: 62.50%] [G loss: 0.885973]\n",
      "epoch:14 step:13180 [D loss: 0.652251, acc.: 60.94%] [G loss: 0.901007]\n",
      "epoch:14 step:13181 [D loss: 0.667769, acc.: 60.16%] [G loss: 0.855575]\n",
      "epoch:14 step:13182 [D loss: 0.681588, acc.: 53.91%] [G loss: 0.860019]\n",
      "epoch:14 step:13183 [D loss: 0.652903, acc.: 66.41%] [G loss: 0.914442]\n",
      "epoch:14 step:13184 [D loss: 0.668968, acc.: 55.47%] [G loss: 0.882525]\n",
      "epoch:14 step:13185 [D loss: 0.641971, acc.: 63.28%] [G loss: 0.860755]\n",
      "epoch:14 step:13186 [D loss: 0.671828, acc.: 58.59%] [G loss: 0.894947]\n",
      "epoch:14 step:13187 [D loss: 0.638585, acc.: 66.41%] [G loss: 0.884883]\n",
      "epoch:14 step:13188 [D loss: 0.656969, acc.: 59.38%] [G loss: 0.879947]\n",
      "epoch:14 step:13189 [D loss: 0.656641, acc.: 64.06%] [G loss: 0.901829]\n",
      "epoch:14 step:13190 [D loss: 0.621830, acc.: 68.75%] [G loss: 0.833213]\n",
      "epoch:14 step:13191 [D loss: 0.638496, acc.: 63.28%] [G loss: 0.914908]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13192 [D loss: 0.688897, acc.: 55.47%] [G loss: 0.883074]\n",
      "epoch:14 step:13193 [D loss: 0.645770, acc.: 62.50%] [G loss: 0.884413]\n",
      "epoch:14 step:13194 [D loss: 0.656531, acc.: 63.28%] [G loss: 0.837750]\n",
      "epoch:14 step:13195 [D loss: 0.687407, acc.: 52.34%] [G loss: 0.794902]\n",
      "epoch:14 step:13196 [D loss: 0.650716, acc.: 57.03%] [G loss: 0.816980]\n",
      "epoch:14 step:13197 [D loss: 0.674920, acc.: 64.06%] [G loss: 0.806650]\n",
      "epoch:14 step:13198 [D loss: 0.690240, acc.: 60.16%] [G loss: 0.884057]\n",
      "epoch:14 step:13199 [D loss: 0.674967, acc.: 58.59%] [G loss: 0.872799]\n",
      "epoch:14 step:13200 [D loss: 0.649194, acc.: 63.28%] [G loss: 0.820203]\n",
      "##############\n",
      "[2.86612594 2.33244071 2.50663923 3.9079702  1.37818877 7.72200059\n",
      " 2.72049774 3.92043335 4.38276161 8.14868929]\n",
      "##########\n",
      "epoch:14 step:13201 [D loss: 0.665258, acc.: 60.16%] [G loss: 0.889621]\n",
      "epoch:14 step:13202 [D loss: 0.668636, acc.: 59.38%] [G loss: 0.893326]\n",
      "epoch:14 step:13203 [D loss: 0.663108, acc.: 57.03%] [G loss: 0.919035]\n",
      "epoch:14 step:13204 [D loss: 0.662451, acc.: 59.38%] [G loss: 0.887750]\n",
      "epoch:14 step:13205 [D loss: 0.651555, acc.: 59.38%] [G loss: 0.896258]\n",
      "epoch:14 step:13206 [D loss: 0.661380, acc.: 62.50%] [G loss: 0.871889]\n",
      "epoch:14 step:13207 [D loss: 0.648195, acc.: 67.97%] [G loss: 0.892165]\n",
      "epoch:14 step:13208 [D loss: 0.667238, acc.: 58.59%] [G loss: 0.892398]\n",
      "epoch:14 step:13209 [D loss: 0.692324, acc.: 52.34%] [G loss: 0.869151]\n",
      "epoch:14 step:13210 [D loss: 0.632039, acc.: 65.62%] [G loss: 0.870241]\n",
      "epoch:14 step:13211 [D loss: 0.656274, acc.: 60.16%] [G loss: 0.844374]\n",
      "epoch:14 step:13212 [D loss: 0.653440, acc.: 60.16%] [G loss: 0.864561]\n",
      "epoch:14 step:13213 [D loss: 0.652067, acc.: 61.72%] [G loss: 0.901737]\n",
      "epoch:14 step:13214 [D loss: 0.664296, acc.: 60.16%] [G loss: 0.841264]\n",
      "epoch:14 step:13215 [D loss: 0.671706, acc.: 62.50%] [G loss: 0.871385]\n",
      "epoch:14 step:13216 [D loss: 0.686804, acc.: 55.47%] [G loss: 0.886512]\n",
      "epoch:14 step:13217 [D loss: 0.668045, acc.: 62.50%] [G loss: 0.830596]\n",
      "epoch:14 step:13218 [D loss: 0.697654, acc.: 53.91%] [G loss: 0.857823]\n",
      "epoch:14 step:13219 [D loss: 0.668941, acc.: 56.25%] [G loss: 0.884843]\n",
      "epoch:14 step:13220 [D loss: 0.704317, acc.: 48.44%] [G loss: 0.884519]\n",
      "epoch:14 step:13221 [D loss: 0.640564, acc.: 60.16%] [G loss: 0.839693]\n",
      "epoch:14 step:13222 [D loss: 0.666044, acc.: 60.94%] [G loss: 0.924129]\n",
      "epoch:14 step:13223 [D loss: 0.653897, acc.: 61.72%] [G loss: 0.837608]\n",
      "epoch:14 step:13224 [D loss: 0.637442, acc.: 62.50%] [G loss: 0.860837]\n",
      "epoch:14 step:13225 [D loss: 0.638796, acc.: 61.72%] [G loss: 0.863505]\n",
      "epoch:14 step:13226 [D loss: 0.663679, acc.: 60.16%] [G loss: 0.881773]\n",
      "epoch:14 step:13227 [D loss: 0.639743, acc.: 61.72%] [G loss: 0.875967]\n",
      "epoch:14 step:13228 [D loss: 0.664128, acc.: 61.72%] [G loss: 0.869052]\n",
      "epoch:14 step:13229 [D loss: 0.641903, acc.: 62.50%] [G loss: 0.873369]\n",
      "epoch:14 step:13230 [D loss: 0.641696, acc.: 64.06%] [G loss: 0.897786]\n",
      "epoch:14 step:13231 [D loss: 0.672361, acc.: 54.69%] [G loss: 0.864592]\n",
      "epoch:14 step:13232 [D loss: 0.655103, acc.: 62.50%] [G loss: 0.907677]\n",
      "epoch:14 step:13233 [D loss: 0.687789, acc.: 52.34%] [G loss: 0.878160]\n",
      "epoch:14 step:13234 [D loss: 0.651628, acc.: 60.16%] [G loss: 0.889769]\n",
      "epoch:14 step:13235 [D loss: 0.660982, acc.: 66.41%] [G loss: 0.877055]\n",
      "epoch:14 step:13236 [D loss: 0.657537, acc.: 59.38%] [G loss: 0.852300]\n",
      "epoch:14 step:13237 [D loss: 0.652981, acc.: 61.72%] [G loss: 0.856720]\n",
      "epoch:14 step:13238 [D loss: 0.703570, acc.: 49.22%] [G loss: 0.823667]\n",
      "epoch:14 step:13239 [D loss: 0.599258, acc.: 68.75%] [G loss: 0.901267]\n",
      "epoch:14 step:13240 [D loss: 0.640209, acc.: 64.06%] [G loss: 0.942504]\n",
      "epoch:14 step:13241 [D loss: 0.689574, acc.: 59.38%] [G loss: 0.861837]\n",
      "epoch:14 step:13242 [D loss: 0.676877, acc.: 58.59%] [G loss: 0.776837]\n",
      "epoch:14 step:13243 [D loss: 0.663806, acc.: 57.81%] [G loss: 0.809167]\n",
      "epoch:14 step:13244 [D loss: 0.726759, acc.: 41.41%] [G loss: 0.853789]\n",
      "epoch:14 step:13245 [D loss: 0.622833, acc.: 71.88%] [G loss: 0.860356]\n",
      "epoch:14 step:13246 [D loss: 0.666514, acc.: 57.81%] [G loss: 0.895182]\n",
      "epoch:14 step:13247 [D loss: 0.668478, acc.: 59.38%] [G loss: 0.888810]\n",
      "epoch:14 step:13248 [D loss: 0.661533, acc.: 61.72%] [G loss: 0.890731]\n",
      "epoch:14 step:13249 [D loss: 0.657348, acc.: 56.25%] [G loss: 0.864416]\n",
      "epoch:14 step:13250 [D loss: 0.694722, acc.: 55.47%] [G loss: 0.871791]\n",
      "epoch:14 step:13251 [D loss: 0.654265, acc.: 60.16%] [G loss: 0.880639]\n",
      "epoch:14 step:13252 [D loss: 0.650382, acc.: 62.50%] [G loss: 0.825712]\n",
      "epoch:14 step:13253 [D loss: 0.678181, acc.: 55.47%] [G loss: 0.851961]\n",
      "epoch:14 step:13254 [D loss: 0.672927, acc.: 58.59%] [G loss: 0.816997]\n",
      "epoch:14 step:13255 [D loss: 0.628310, acc.: 65.62%] [G loss: 0.870877]\n",
      "epoch:14 step:13256 [D loss: 0.664371, acc.: 65.62%] [G loss: 0.821353]\n",
      "epoch:14 step:13257 [D loss: 0.677618, acc.: 57.81%] [G loss: 0.837293]\n",
      "epoch:14 step:13258 [D loss: 0.671068, acc.: 53.12%] [G loss: 0.876536]\n",
      "epoch:14 step:13259 [D loss: 0.653800, acc.: 60.94%] [G loss: 0.840259]\n",
      "epoch:14 step:13260 [D loss: 0.637570, acc.: 69.53%] [G loss: 0.885182]\n",
      "epoch:14 step:13261 [D loss: 0.681967, acc.: 52.34%] [G loss: 0.852856]\n",
      "epoch:14 step:13262 [D loss: 0.663999, acc.: 56.25%] [G loss: 0.782686]\n",
      "epoch:14 step:13263 [D loss: 0.681545, acc.: 57.81%] [G loss: 0.827570]\n",
      "epoch:14 step:13264 [D loss: 0.655601, acc.: 57.81%] [G loss: 0.804237]\n",
      "epoch:14 step:13265 [D loss: 0.665738, acc.: 62.50%] [G loss: 0.809232]\n",
      "epoch:14 step:13266 [D loss: 0.690094, acc.: 54.69%] [G loss: 0.869711]\n",
      "epoch:14 step:13267 [D loss: 0.657833, acc.: 60.16%] [G loss: 0.877576]\n",
      "epoch:14 step:13268 [D loss: 0.655847, acc.: 57.03%] [G loss: 0.834385]\n",
      "epoch:14 step:13269 [D loss: 0.658115, acc.: 64.06%] [G loss: 0.896172]\n",
      "epoch:14 step:13270 [D loss: 0.678196, acc.: 56.25%] [G loss: 0.811526]\n",
      "epoch:14 step:13271 [D loss: 0.645852, acc.: 69.53%] [G loss: 0.818896]\n",
      "epoch:14 step:13272 [D loss: 0.646851, acc.: 63.28%] [G loss: 0.833450]\n",
      "epoch:14 step:13273 [D loss: 0.648361, acc.: 63.28%] [G loss: 0.837368]\n",
      "epoch:14 step:13274 [D loss: 0.640409, acc.: 61.72%] [G loss: 0.882861]\n",
      "epoch:14 step:13275 [D loss: 0.647464, acc.: 66.41%] [G loss: 0.888918]\n",
      "epoch:14 step:13276 [D loss: 0.645275, acc.: 63.28%] [G loss: 0.859842]\n",
      "epoch:14 step:13277 [D loss: 0.620006, acc.: 63.28%] [G loss: 0.882832]\n",
      "epoch:14 step:13278 [D loss: 0.683376, acc.: 55.47%] [G loss: 0.816627]\n",
      "epoch:14 step:13279 [D loss: 0.654361, acc.: 63.28%] [G loss: 0.863525]\n",
      "epoch:14 step:13280 [D loss: 0.668048, acc.: 57.81%] [G loss: 0.909815]\n",
      "epoch:14 step:13281 [D loss: 0.693431, acc.: 56.25%] [G loss: 0.880613]\n",
      "epoch:14 step:13282 [D loss: 0.664668, acc.: 62.50%] [G loss: 0.814531]\n",
      "epoch:14 step:13283 [D loss: 0.645955, acc.: 64.06%] [G loss: 0.842465]\n",
      "epoch:14 step:13284 [D loss: 0.697137, acc.: 50.78%] [G loss: 0.883730]\n",
      "epoch:14 step:13285 [D loss: 0.639333, acc.: 57.81%] [G loss: 0.923372]\n",
      "epoch:14 step:13286 [D loss: 0.682958, acc.: 57.03%] [G loss: 0.905201]\n",
      "epoch:14 step:13287 [D loss: 0.695141, acc.: 52.34%] [G loss: 0.863441]\n",
      "epoch:14 step:13288 [D loss: 0.650314, acc.: 60.94%] [G loss: 0.903147]\n",
      "epoch:14 step:13289 [D loss: 0.673200, acc.: 60.16%] [G loss: 0.884000]\n",
      "epoch:14 step:13290 [D loss: 0.656443, acc.: 58.59%] [G loss: 0.888148]\n",
      "epoch:14 step:13291 [D loss: 0.659881, acc.: 62.50%] [G loss: 0.892441]\n",
      "epoch:14 step:13292 [D loss: 0.663390, acc.: 62.50%] [G loss: 0.810490]\n",
      "epoch:14 step:13293 [D loss: 0.703009, acc.: 53.12%] [G loss: 0.828457]\n",
      "epoch:14 step:13294 [D loss: 0.685600, acc.: 59.38%] [G loss: 0.814650]\n",
      "epoch:14 step:13295 [D loss: 0.658099, acc.: 63.28%] [G loss: 0.885346]\n",
      "epoch:14 step:13296 [D loss: 0.670736, acc.: 52.34%] [G loss: 0.890936]\n",
      "epoch:14 step:13297 [D loss: 0.682321, acc.: 51.56%] [G loss: 0.888216]\n",
      "epoch:14 step:13298 [D loss: 0.653441, acc.: 64.84%] [G loss: 0.898138]\n",
      "epoch:14 step:13299 [D loss: 0.739723, acc.: 45.31%] [G loss: 0.878871]\n",
      "epoch:14 step:13300 [D loss: 0.659904, acc.: 57.03%] [G loss: 0.884095]\n",
      "epoch:14 step:13301 [D loss: 0.687984, acc.: 54.69%] [G loss: 0.869616]\n",
      "epoch:14 step:13302 [D loss: 0.654215, acc.: 63.28%] [G loss: 0.894763]\n",
      "epoch:14 step:13303 [D loss: 0.663743, acc.: 58.59%] [G loss: 0.922467]\n",
      "epoch:14 step:13304 [D loss: 0.663040, acc.: 58.59%] [G loss: 0.883451]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13305 [D loss: 0.663130, acc.: 57.81%] [G loss: 0.849622]\n",
      "epoch:14 step:13306 [D loss: 0.682762, acc.: 58.59%] [G loss: 0.894114]\n",
      "epoch:14 step:13307 [D loss: 0.659529, acc.: 63.28%] [G loss: 0.865773]\n",
      "epoch:14 step:13308 [D loss: 0.669463, acc.: 58.59%] [G loss: 0.849849]\n",
      "epoch:14 step:13309 [D loss: 0.653455, acc.: 57.03%] [G loss: 0.887413]\n",
      "epoch:14 step:13310 [D loss: 0.680617, acc.: 59.38%] [G loss: 0.842434]\n",
      "epoch:14 step:13311 [D loss: 0.641460, acc.: 64.06%] [G loss: 0.905095]\n",
      "epoch:14 step:13312 [D loss: 0.674663, acc.: 57.03%] [G loss: 0.888459]\n",
      "epoch:14 step:13313 [D loss: 0.642932, acc.: 63.28%] [G loss: 0.848410]\n",
      "epoch:14 step:13314 [D loss: 0.663993, acc.: 58.59%] [G loss: 0.845951]\n",
      "epoch:14 step:13315 [D loss: 0.639876, acc.: 62.50%] [G loss: 0.887680]\n",
      "epoch:14 step:13316 [D loss: 0.620583, acc.: 69.53%] [G loss: 0.856280]\n",
      "epoch:14 step:13317 [D loss: 0.654599, acc.: 64.84%] [G loss: 0.826169]\n",
      "epoch:14 step:13318 [D loss: 0.668043, acc.: 57.03%] [G loss: 0.865396]\n",
      "epoch:14 step:13319 [D loss: 0.646721, acc.: 65.62%] [G loss: 0.859736]\n",
      "epoch:14 step:13320 [D loss: 0.649742, acc.: 57.81%] [G loss: 0.859565]\n",
      "epoch:14 step:13321 [D loss: 0.667671, acc.: 60.16%] [G loss: 0.912969]\n",
      "epoch:14 step:13322 [D loss: 0.661365, acc.: 60.16%] [G loss: 0.884917]\n",
      "epoch:14 step:13323 [D loss: 0.622225, acc.: 64.84%] [G loss: 0.899856]\n",
      "epoch:14 step:13324 [D loss: 0.663732, acc.: 61.72%] [G loss: 0.889947]\n",
      "epoch:14 step:13325 [D loss: 0.620792, acc.: 62.50%] [G loss: 0.884562]\n",
      "epoch:14 step:13326 [D loss: 0.650624, acc.: 61.72%] [G loss: 0.843361]\n",
      "epoch:14 step:13327 [D loss: 0.667881, acc.: 60.16%] [G loss: 0.817667]\n",
      "epoch:14 step:13328 [D loss: 0.614056, acc.: 71.09%] [G loss: 0.841229]\n",
      "epoch:14 step:13329 [D loss: 0.675677, acc.: 57.81%] [G loss: 0.916773]\n",
      "epoch:14 step:13330 [D loss: 0.665126, acc.: 57.81%] [G loss: 0.890038]\n",
      "epoch:14 step:13331 [D loss: 0.661955, acc.: 60.16%] [G loss: 0.851872]\n",
      "epoch:14 step:13332 [D loss: 0.661498, acc.: 55.47%] [G loss: 0.860830]\n",
      "epoch:14 step:13333 [D loss: 0.688085, acc.: 59.38%] [G loss: 0.837637]\n",
      "epoch:14 step:13334 [D loss: 0.677599, acc.: 51.56%] [G loss: 0.803081]\n",
      "epoch:14 step:13335 [D loss: 0.668441, acc.: 58.59%] [G loss: 0.812127]\n",
      "epoch:14 step:13336 [D loss: 0.644824, acc.: 64.06%] [G loss: 0.858785]\n",
      "epoch:14 step:13337 [D loss: 0.692280, acc.: 51.56%] [G loss: 0.841748]\n",
      "epoch:14 step:13338 [D loss: 0.702419, acc.: 54.69%] [G loss: 0.829266]\n",
      "epoch:14 step:13339 [D loss: 0.674182, acc.: 52.34%] [G loss: 0.777549]\n",
      "epoch:14 step:13340 [D loss: 0.684356, acc.: 62.50%] [G loss: 0.804403]\n",
      "epoch:14 step:13341 [D loss: 0.644219, acc.: 61.72%] [G loss: 0.829781]\n",
      "epoch:14 step:13342 [D loss: 0.652577, acc.: 64.84%] [G loss: 0.810581]\n",
      "epoch:14 step:13343 [D loss: 0.643530, acc.: 62.50%] [G loss: 0.851616]\n",
      "epoch:14 step:13344 [D loss: 0.675454, acc.: 60.16%] [G loss: 0.863121]\n",
      "epoch:14 step:13345 [D loss: 0.666610, acc.: 56.25%] [G loss: 0.879550]\n",
      "epoch:14 step:13346 [D loss: 0.664734, acc.: 60.16%] [G loss: 0.855416]\n",
      "epoch:14 step:13347 [D loss: 0.655654, acc.: 57.03%] [G loss: 0.874339]\n",
      "epoch:14 step:13348 [D loss: 0.674299, acc.: 60.16%] [G loss: 0.864742]\n",
      "epoch:14 step:13349 [D loss: 0.686084, acc.: 53.91%] [G loss: 0.865200]\n",
      "epoch:14 step:13350 [D loss: 0.675293, acc.: 56.25%] [G loss: 0.884174]\n",
      "epoch:14 step:13351 [D loss: 0.645614, acc.: 66.41%] [G loss: 0.882967]\n",
      "epoch:14 step:13352 [D loss: 0.649755, acc.: 61.72%] [G loss: 0.851080]\n",
      "epoch:14 step:13353 [D loss: 0.677013, acc.: 55.47%] [G loss: 0.908885]\n",
      "epoch:14 step:13354 [D loss: 0.681594, acc.: 55.47%] [G loss: 0.880228]\n",
      "epoch:14 step:13355 [D loss: 0.686442, acc.: 56.25%] [G loss: 0.860922]\n",
      "epoch:14 step:13356 [D loss: 0.654110, acc.: 60.16%] [G loss: 0.868024]\n",
      "epoch:14 step:13357 [D loss: 0.653164, acc.: 63.28%] [G loss: 0.839226]\n",
      "epoch:14 step:13358 [D loss: 0.720534, acc.: 53.12%] [G loss: 0.839040]\n",
      "epoch:14 step:13359 [D loss: 0.657760, acc.: 56.25%] [G loss: 0.885831]\n",
      "epoch:14 step:13360 [D loss: 0.684420, acc.: 57.03%] [G loss: 0.888236]\n",
      "epoch:14 step:13361 [D loss: 0.680509, acc.: 57.81%] [G loss: 0.864557]\n",
      "epoch:14 step:13362 [D loss: 0.654128, acc.: 64.06%] [G loss: 0.830637]\n",
      "epoch:14 step:13363 [D loss: 0.671548, acc.: 59.38%] [G loss: 0.841706]\n",
      "epoch:14 step:13364 [D loss: 0.695265, acc.: 53.12%] [G loss: 0.830903]\n",
      "epoch:14 step:13365 [D loss: 0.648225, acc.: 61.72%] [G loss: 0.862295]\n",
      "epoch:14 step:13366 [D loss: 0.668205, acc.: 59.38%] [G loss: 0.871838]\n",
      "epoch:14 step:13367 [D loss: 0.651766, acc.: 61.72%] [G loss: 0.843366]\n",
      "epoch:14 step:13368 [D loss: 0.669399, acc.: 63.28%] [G loss: 0.883630]\n",
      "epoch:14 step:13369 [D loss: 0.674154, acc.: 58.59%] [G loss: 0.885234]\n",
      "epoch:14 step:13370 [D loss: 0.687771, acc.: 53.91%] [G loss: 0.871140]\n",
      "epoch:14 step:13371 [D loss: 0.655628, acc.: 61.72%] [G loss: 0.891358]\n",
      "epoch:14 step:13372 [D loss: 0.699221, acc.: 55.47%] [G loss: 0.865037]\n",
      "epoch:14 step:13373 [D loss: 0.655702, acc.: 64.06%] [G loss: 0.841899]\n",
      "epoch:14 step:13374 [D loss: 0.671640, acc.: 58.59%] [G loss: 0.866532]\n",
      "epoch:14 step:13375 [D loss: 0.625789, acc.: 67.97%] [G loss: 0.895840]\n",
      "epoch:14 step:13376 [D loss: 0.695892, acc.: 56.25%] [G loss: 0.875296]\n",
      "epoch:14 step:13377 [D loss: 0.693826, acc.: 53.12%] [G loss: 0.896458]\n",
      "epoch:14 step:13378 [D loss: 0.661455, acc.: 62.50%] [G loss: 0.845588]\n",
      "epoch:14 step:13379 [D loss: 0.671979, acc.: 59.38%] [G loss: 0.837942]\n",
      "epoch:14 step:13380 [D loss: 0.683738, acc.: 52.34%] [G loss: 0.830644]\n",
      "epoch:14 step:13381 [D loss: 0.635254, acc.: 62.50%] [G loss: 0.858276]\n",
      "epoch:14 step:13382 [D loss: 0.669106, acc.: 57.81%] [G loss: 0.832928]\n",
      "epoch:14 step:13383 [D loss: 0.666797, acc.: 57.03%] [G loss: 0.901617]\n",
      "epoch:14 step:13384 [D loss: 0.641326, acc.: 57.81%] [G loss: 0.899172]\n",
      "epoch:14 step:13385 [D loss: 0.658415, acc.: 62.50%] [G loss: 0.904930]\n",
      "epoch:14 step:13386 [D loss: 0.669320, acc.: 58.59%] [G loss: 0.838702]\n",
      "epoch:14 step:13387 [D loss: 0.626135, acc.: 60.94%] [G loss: 0.883208]\n",
      "epoch:14 step:13388 [D loss: 0.648020, acc.: 65.62%] [G loss: 0.927775]\n",
      "epoch:14 step:13389 [D loss: 0.658235, acc.: 60.16%] [G loss: 0.853261]\n",
      "epoch:14 step:13390 [D loss: 0.638086, acc.: 68.75%] [G loss: 0.899440]\n",
      "epoch:14 step:13391 [D loss: 0.685050, acc.: 54.69%] [G loss: 0.859757]\n",
      "epoch:14 step:13392 [D loss: 0.645553, acc.: 62.50%] [G loss: 0.862481]\n",
      "epoch:14 step:13393 [D loss: 0.667835, acc.: 60.94%] [G loss: 0.874203]\n",
      "epoch:14 step:13394 [D loss: 0.677220, acc.: 60.16%] [G loss: 0.878456]\n",
      "epoch:14 step:13395 [D loss: 0.657260, acc.: 58.59%] [G loss: 0.869496]\n",
      "epoch:14 step:13396 [D loss: 0.723179, acc.: 46.88%] [G loss: 0.818106]\n",
      "epoch:14 step:13397 [D loss: 0.700555, acc.: 49.22%] [G loss: 0.812984]\n",
      "epoch:14 step:13398 [D loss: 0.691094, acc.: 54.69%] [G loss: 0.846542]\n",
      "epoch:14 step:13399 [D loss: 0.656076, acc.: 58.59%] [G loss: 0.817760]\n",
      "epoch:14 step:13400 [D loss: 0.660298, acc.: 57.81%] [G loss: 0.863546]\n",
      "##############\n",
      "[2.68455074 2.27639129 2.32260739 4.09051824 1.71097371 7.82964432\n",
      " 2.9309485  3.76500177 4.36971614 6.0823958 ]\n",
      "##########\n",
      "epoch:14 step:13401 [D loss: 0.642168, acc.: 65.62%] [G loss: 0.847653]\n",
      "epoch:14 step:13402 [D loss: 0.646706, acc.: 65.62%] [G loss: 0.840759]\n",
      "epoch:14 step:13403 [D loss: 0.629557, acc.: 64.06%] [G loss: 0.819445]\n",
      "epoch:14 step:13404 [D loss: 0.643151, acc.: 63.28%] [G loss: 0.868961]\n",
      "epoch:14 step:13405 [D loss: 0.642591, acc.: 59.38%] [G loss: 0.835717]\n",
      "epoch:14 step:13406 [D loss: 0.683306, acc.: 56.25%] [G loss: 0.843388]\n",
      "epoch:14 step:13407 [D loss: 0.677740, acc.: 54.69%] [G loss: 0.824931]\n",
      "epoch:14 step:13408 [D loss: 0.657593, acc.: 63.28%] [G loss: 0.912609]\n",
      "epoch:14 step:13409 [D loss: 0.672000, acc.: 59.38%] [G loss: 0.824669]\n",
      "epoch:14 step:13410 [D loss: 0.677537, acc.: 61.72%] [G loss: 0.824008]\n",
      "epoch:14 step:13411 [D loss: 0.653653, acc.: 61.72%] [G loss: 0.874428]\n",
      "epoch:14 step:13412 [D loss: 0.656403, acc.: 57.03%] [G loss: 0.841563]\n",
      "epoch:14 step:13413 [D loss: 0.695357, acc.: 60.94%] [G loss: 0.832982]\n",
      "epoch:14 step:13414 [D loss: 0.661699, acc.: 61.72%] [G loss: 0.810840]\n",
      "epoch:14 step:13415 [D loss: 0.692114, acc.: 55.47%] [G loss: 0.795736]\n",
      "epoch:14 step:13416 [D loss: 0.681830, acc.: 57.03%] [G loss: 0.787931]\n",
      "epoch:14 step:13417 [D loss: 0.673617, acc.: 55.47%] [G loss: 0.862299]\n",
      "epoch:14 step:13418 [D loss: 0.686445, acc.: 57.03%] [G loss: 0.842100]\n",
      "epoch:14 step:13419 [D loss: 0.675119, acc.: 57.81%] [G loss: 0.867657]\n",
      "epoch:14 step:13420 [D loss: 0.686832, acc.: 53.91%] [G loss: 0.842065]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13421 [D loss: 0.685203, acc.: 54.69%] [G loss: 0.846368]\n",
      "epoch:14 step:13422 [D loss: 0.651900, acc.: 64.06%] [G loss: 0.868755]\n",
      "epoch:14 step:13423 [D loss: 0.658191, acc.: 62.50%] [G loss: 0.826386]\n",
      "epoch:14 step:13424 [D loss: 0.689431, acc.: 53.91%] [G loss: 0.815562]\n",
      "epoch:14 step:13425 [D loss: 0.674239, acc.: 60.94%] [G loss: 0.864037]\n",
      "epoch:14 step:13426 [D loss: 0.668620, acc.: 56.25%] [G loss: 0.833732]\n",
      "epoch:14 step:13427 [D loss: 0.669472, acc.: 59.38%] [G loss: 0.869749]\n",
      "epoch:14 step:13428 [D loss: 0.679164, acc.: 61.72%] [G loss: 0.837200]\n",
      "epoch:14 step:13429 [D loss: 0.673005, acc.: 55.47%] [G loss: 0.840152]\n",
      "epoch:14 step:13430 [D loss: 0.692621, acc.: 51.56%] [G loss: 0.831207]\n",
      "epoch:14 step:13431 [D loss: 0.663222, acc.: 56.25%] [G loss: 0.883039]\n",
      "epoch:14 step:13432 [D loss: 0.684393, acc.: 54.69%] [G loss: 0.847753]\n",
      "epoch:14 step:13433 [D loss: 0.645746, acc.: 64.06%] [G loss: 0.833756]\n",
      "epoch:14 step:13434 [D loss: 0.694085, acc.: 52.34%] [G loss: 0.858345]\n",
      "epoch:14 step:13435 [D loss: 0.634906, acc.: 65.62%] [G loss: 0.831849]\n",
      "epoch:14 step:13436 [D loss: 0.680882, acc.: 61.72%] [G loss: 0.837780]\n",
      "epoch:14 step:13437 [D loss: 0.711745, acc.: 54.69%] [G loss: 0.839849]\n",
      "epoch:14 step:13438 [D loss: 0.686665, acc.: 54.69%] [G loss: 0.850858]\n",
      "epoch:14 step:13439 [D loss: 0.665893, acc.: 61.72%] [G loss: 0.831112]\n",
      "epoch:14 step:13440 [D loss: 0.682201, acc.: 50.78%] [G loss: 0.800656]\n",
      "epoch:14 step:13441 [D loss: 0.681172, acc.: 53.91%] [G loss: 0.846261]\n",
      "epoch:14 step:13442 [D loss: 0.646125, acc.: 60.16%] [G loss: 0.830759]\n",
      "epoch:14 step:13443 [D loss: 0.670212, acc.: 58.59%] [G loss: 0.802922]\n",
      "epoch:14 step:13444 [D loss: 0.697388, acc.: 51.56%] [G loss: 0.807296]\n",
      "epoch:14 step:13445 [D loss: 0.640956, acc.: 60.16%] [G loss: 0.857590]\n",
      "epoch:14 step:13446 [D loss: 0.712428, acc.: 53.91%] [G loss: 0.830643]\n",
      "epoch:14 step:13447 [D loss: 0.683818, acc.: 50.00%] [G loss: 0.829634]\n",
      "epoch:14 step:13448 [D loss: 0.652758, acc.: 60.94%] [G loss: 0.905642]\n",
      "epoch:14 step:13449 [D loss: 0.670924, acc.: 59.38%] [G loss: 0.864054]\n",
      "epoch:14 step:13450 [D loss: 0.653121, acc.: 58.59%] [G loss: 0.805106]\n",
      "epoch:14 step:13451 [D loss: 0.679419, acc.: 57.03%] [G loss: 0.843292]\n",
      "epoch:14 step:13452 [D loss: 0.681556, acc.: 52.34%] [G loss: 0.817106]\n",
      "epoch:14 step:13453 [D loss: 0.676427, acc.: 57.03%] [G loss: 0.835150]\n",
      "epoch:14 step:13454 [D loss: 0.630157, acc.: 57.81%] [G loss: 0.880202]\n",
      "epoch:14 step:13455 [D loss: 0.637816, acc.: 61.72%] [G loss: 0.792596]\n",
      "epoch:14 step:13456 [D loss: 0.674381, acc.: 60.94%] [G loss: 0.815309]\n",
      "epoch:14 step:13457 [D loss: 0.673112, acc.: 57.03%] [G loss: 0.867781]\n",
      "epoch:14 step:13458 [D loss: 0.656084, acc.: 66.41%] [G loss: 0.890178]\n",
      "epoch:14 step:13459 [D loss: 0.665433, acc.: 56.25%] [G loss: 0.861942]\n",
      "epoch:14 step:13460 [D loss: 0.657631, acc.: 60.16%] [G loss: 0.872905]\n",
      "epoch:14 step:13461 [D loss: 0.709015, acc.: 54.69%] [G loss: 0.872538]\n",
      "epoch:14 step:13462 [D loss: 0.655284, acc.: 63.28%] [G loss: 0.906505]\n",
      "epoch:14 step:13463 [D loss: 0.663991, acc.: 57.03%] [G loss: 0.902235]\n",
      "epoch:14 step:13464 [D loss: 0.657615, acc.: 60.94%] [G loss: 0.827592]\n",
      "epoch:14 step:13465 [D loss: 0.660163, acc.: 60.16%] [G loss: 0.883775]\n",
      "epoch:14 step:13466 [D loss: 0.703377, acc.: 53.91%] [G loss: 0.846156]\n",
      "epoch:14 step:13467 [D loss: 0.673679, acc.: 55.47%] [G loss: 0.855394]\n",
      "epoch:14 step:13468 [D loss: 0.683824, acc.: 55.47%] [G loss: 0.878465]\n",
      "epoch:14 step:13469 [D loss: 0.662226, acc.: 59.38%] [G loss: 0.859484]\n",
      "epoch:14 step:13470 [D loss: 0.701979, acc.: 51.56%] [G loss: 0.832589]\n",
      "epoch:14 step:13471 [D loss: 0.695994, acc.: 53.91%] [G loss: 0.829180]\n",
      "epoch:14 step:13472 [D loss: 0.662646, acc.: 59.38%] [G loss: 0.832746]\n",
      "epoch:14 step:13473 [D loss: 0.673451, acc.: 58.59%] [G loss: 0.816589]\n",
      "epoch:14 step:13474 [D loss: 0.661039, acc.: 60.16%] [G loss: 0.860718]\n",
      "epoch:14 step:13475 [D loss: 0.631069, acc.: 67.97%] [G loss: 0.852061]\n",
      "epoch:14 step:13476 [D loss: 0.619862, acc.: 71.88%] [G loss: 0.857667]\n",
      "epoch:14 step:13477 [D loss: 0.695518, acc.: 59.38%] [G loss: 0.881570]\n",
      "epoch:14 step:13478 [D loss: 0.640329, acc.: 55.47%] [G loss: 0.894711]\n",
      "epoch:14 step:13479 [D loss: 0.716084, acc.: 50.78%] [G loss: 0.926276]\n",
      "epoch:14 step:13480 [D loss: 0.673129, acc.: 60.16%] [G loss: 0.920700]\n",
      "epoch:14 step:13481 [D loss: 0.661763, acc.: 60.16%] [G loss: 0.847765]\n",
      "epoch:14 step:13482 [D loss: 0.681007, acc.: 53.91%] [G loss: 0.877663]\n",
      "epoch:14 step:13483 [D loss: 0.683438, acc.: 60.94%] [G loss: 0.847948]\n",
      "epoch:14 step:13484 [D loss: 0.689772, acc.: 58.59%] [G loss: 0.873440]\n",
      "epoch:14 step:13485 [D loss: 0.636952, acc.: 63.28%] [G loss: 0.847438]\n",
      "epoch:14 step:13486 [D loss: 0.677306, acc.: 57.81%] [G loss: 0.884595]\n",
      "epoch:14 step:13487 [D loss: 0.667819, acc.: 60.16%] [G loss: 0.812842]\n",
      "epoch:14 step:13488 [D loss: 0.674794, acc.: 60.16%] [G loss: 0.856711]\n",
      "epoch:14 step:13489 [D loss: 0.692374, acc.: 53.12%] [G loss: 0.857859]\n",
      "epoch:14 step:13490 [D loss: 0.660355, acc.: 62.50%] [G loss: 0.892888]\n",
      "epoch:14 step:13491 [D loss: 0.658158, acc.: 57.81%] [G loss: 0.878357]\n",
      "epoch:14 step:13492 [D loss: 0.647411, acc.: 64.06%] [G loss: 0.833291]\n",
      "epoch:14 step:13493 [D loss: 0.717731, acc.: 53.12%] [G loss: 0.868434]\n",
      "epoch:14 step:13494 [D loss: 0.691230, acc.: 54.69%] [G loss: 0.888399]\n",
      "epoch:14 step:13495 [D loss: 0.671022, acc.: 59.38%] [G loss: 0.803041]\n",
      "epoch:14 step:13496 [D loss: 0.672761, acc.: 57.03%] [G loss: 0.834321]\n",
      "epoch:14 step:13497 [D loss: 0.658988, acc.: 56.25%] [G loss: 0.880853]\n",
      "epoch:14 step:13498 [D loss: 0.662677, acc.: 60.16%] [G loss: 0.857421]\n",
      "epoch:14 step:13499 [D loss: 0.648026, acc.: 60.94%] [G loss: 0.917418]\n",
      "epoch:14 step:13500 [D loss: 0.638858, acc.: 65.62%] [G loss: 0.912496]\n",
      "epoch:14 step:13501 [D loss: 0.639203, acc.: 60.94%] [G loss: 0.910512]\n",
      "epoch:14 step:13502 [D loss: 0.678106, acc.: 60.16%] [G loss: 0.846450]\n",
      "epoch:14 step:13503 [D loss: 0.668467, acc.: 55.47%] [G loss: 0.796417]\n",
      "epoch:14 step:13504 [D loss: 0.676441, acc.: 52.34%] [G loss: 0.836383]\n",
      "epoch:14 step:13505 [D loss: 0.658609, acc.: 59.38%] [G loss: 0.846705]\n",
      "epoch:14 step:13506 [D loss: 0.670993, acc.: 63.28%] [G loss: 0.870915]\n",
      "epoch:14 step:13507 [D loss: 0.695952, acc.: 50.00%] [G loss: 0.825472]\n",
      "epoch:14 step:13508 [D loss: 0.689637, acc.: 53.91%] [G loss: 0.869413]\n",
      "epoch:14 step:13509 [D loss: 0.665147, acc.: 59.38%] [G loss: 0.860478]\n",
      "epoch:14 step:13510 [D loss: 0.656992, acc.: 60.16%] [G loss: 0.821234]\n",
      "epoch:14 step:13511 [D loss: 0.698640, acc.: 47.66%] [G loss: 0.845471]\n",
      "epoch:14 step:13512 [D loss: 0.663400, acc.: 54.69%] [G loss: 0.882045]\n",
      "epoch:14 step:13513 [D loss: 0.686625, acc.: 53.12%] [G loss: 0.848169]\n",
      "epoch:14 step:13514 [D loss: 0.655075, acc.: 65.62%] [G loss: 0.817672]\n",
      "epoch:14 step:13515 [D loss: 0.699916, acc.: 50.78%] [G loss: 0.831260]\n",
      "epoch:14 step:13516 [D loss: 0.650874, acc.: 60.94%] [G loss: 0.853471]\n",
      "epoch:14 step:13517 [D loss: 0.661254, acc.: 57.81%] [G loss: 0.844035]\n",
      "epoch:14 step:13518 [D loss: 0.670272, acc.: 56.25%] [G loss: 0.793154]\n",
      "epoch:14 step:13519 [D loss: 0.673597, acc.: 56.25%] [G loss: 0.888056]\n",
      "epoch:14 step:13520 [D loss: 0.652612, acc.: 60.16%] [G loss: 0.912362]\n",
      "epoch:14 step:13521 [D loss: 0.642411, acc.: 62.50%] [G loss: 0.914205]\n",
      "epoch:14 step:13522 [D loss: 0.661895, acc.: 60.16%] [G loss: 0.930347]\n",
      "epoch:14 step:13523 [D loss: 0.637623, acc.: 60.94%] [G loss: 0.861752]\n",
      "epoch:14 step:13524 [D loss: 0.663485, acc.: 57.81%] [G loss: 0.867652]\n",
      "epoch:14 step:13525 [D loss: 0.690834, acc.: 57.81%] [G loss: 0.835706]\n",
      "epoch:14 step:13526 [D loss: 0.653185, acc.: 60.16%] [G loss: 0.844111]\n",
      "epoch:14 step:13527 [D loss: 0.666207, acc.: 58.59%] [G loss: 0.847287]\n",
      "epoch:14 step:13528 [D loss: 0.669692, acc.: 60.16%] [G loss: 0.840467]\n",
      "epoch:14 step:13529 [D loss: 0.651634, acc.: 62.50%] [G loss: 0.852978]\n",
      "epoch:14 step:13530 [D loss: 0.658650, acc.: 59.38%] [G loss: 0.867063]\n",
      "epoch:14 step:13531 [D loss: 0.664102, acc.: 59.38%] [G loss: 0.863088]\n",
      "epoch:14 step:13532 [D loss: 0.631267, acc.: 62.50%] [G loss: 0.868720]\n",
      "epoch:14 step:13533 [D loss: 0.648425, acc.: 60.94%] [G loss: 0.824771]\n",
      "epoch:14 step:13534 [D loss: 0.662153, acc.: 60.16%] [G loss: 0.839102]\n",
      "epoch:14 step:13535 [D loss: 0.634193, acc.: 62.50%] [G loss: 0.823418]\n",
      "epoch:14 step:13536 [D loss: 0.667513, acc.: 57.81%] [G loss: 0.851551]\n",
      "epoch:14 step:13537 [D loss: 0.662238, acc.: 57.81%] [G loss: 0.868887]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13538 [D loss: 0.655470, acc.: 64.06%] [G loss: 0.914528]\n",
      "epoch:14 step:13539 [D loss: 0.652854, acc.: 61.72%] [G loss: 0.874462]\n",
      "epoch:14 step:13540 [D loss: 0.703095, acc.: 53.12%] [G loss: 0.883809]\n",
      "epoch:14 step:13541 [D loss: 0.699977, acc.: 58.59%] [G loss: 0.833367]\n",
      "epoch:14 step:13542 [D loss: 0.690123, acc.: 54.69%] [G loss: 0.863463]\n",
      "epoch:14 step:13543 [D loss: 0.681657, acc.: 55.47%] [G loss: 0.871968]\n",
      "epoch:14 step:13544 [D loss: 0.679638, acc.: 60.16%] [G loss: 0.862101]\n",
      "epoch:14 step:13545 [D loss: 0.652884, acc.: 65.62%] [G loss: 0.860827]\n",
      "epoch:14 step:13546 [D loss: 0.676202, acc.: 62.50%] [G loss: 0.834598]\n",
      "epoch:14 step:13547 [D loss: 0.663152, acc.: 58.59%] [G loss: 0.860940]\n",
      "epoch:14 step:13548 [D loss: 0.673120, acc.: 56.25%] [G loss: 0.839750]\n",
      "epoch:14 step:13549 [D loss: 0.669927, acc.: 61.72%] [G loss: 0.862415]\n",
      "epoch:14 step:13550 [D loss: 0.657823, acc.: 62.50%] [G loss: 0.846342]\n",
      "epoch:14 step:13551 [D loss: 0.676711, acc.: 53.12%] [G loss: 0.867925]\n",
      "epoch:14 step:13552 [D loss: 0.646557, acc.: 61.72%] [G loss: 0.861402]\n",
      "epoch:14 step:13553 [D loss: 0.623885, acc.: 68.75%] [G loss: 0.848017]\n",
      "epoch:14 step:13554 [D loss: 0.651508, acc.: 64.06%] [G loss: 0.804506]\n",
      "epoch:14 step:13555 [D loss: 0.665197, acc.: 60.16%] [G loss: 0.848388]\n",
      "epoch:14 step:13556 [D loss: 0.684614, acc.: 54.69%] [G loss: 0.853356]\n",
      "epoch:14 step:13557 [D loss: 0.655773, acc.: 59.38%] [G loss: 0.893128]\n",
      "epoch:14 step:13558 [D loss: 0.697675, acc.: 55.47%] [G loss: 0.864141]\n",
      "epoch:14 step:13559 [D loss: 0.670258, acc.: 57.03%] [G loss: 0.875963]\n",
      "epoch:14 step:13560 [D loss: 0.668083, acc.: 56.25%] [G loss: 0.929722]\n",
      "epoch:14 step:13561 [D loss: 0.669916, acc.: 57.81%] [G loss: 0.944708]\n",
      "epoch:14 step:13562 [D loss: 0.682751, acc.: 57.03%] [G loss: 0.861636]\n",
      "epoch:14 step:13563 [D loss: 0.649070, acc.: 60.94%] [G loss: 0.853122]\n",
      "epoch:14 step:13564 [D loss: 0.685254, acc.: 50.00%] [G loss: 0.890073]\n",
      "epoch:14 step:13565 [D loss: 0.620133, acc.: 68.75%] [G loss: 0.840407]\n",
      "epoch:14 step:13566 [D loss: 0.690050, acc.: 56.25%] [G loss: 0.837053]\n",
      "epoch:14 step:13567 [D loss: 0.658763, acc.: 55.47%] [G loss: 0.874948]\n",
      "epoch:14 step:13568 [D loss: 0.647876, acc.: 58.59%] [G loss: 0.871471]\n",
      "epoch:14 step:13569 [D loss: 0.655323, acc.: 53.91%] [G loss: 0.875254]\n",
      "epoch:14 step:13570 [D loss: 0.702655, acc.: 49.22%] [G loss: 0.858472]\n",
      "epoch:14 step:13571 [D loss: 0.667981, acc.: 57.81%] [G loss: 0.867188]\n",
      "epoch:14 step:13572 [D loss: 0.655272, acc.: 58.59%] [G loss: 0.855656]\n",
      "epoch:14 step:13573 [D loss: 0.664186, acc.: 60.94%] [G loss: 0.821733]\n",
      "epoch:14 step:13574 [D loss: 0.683076, acc.: 57.03%] [G loss: 0.848629]\n",
      "epoch:14 step:13575 [D loss: 0.687453, acc.: 57.81%] [G loss: 0.875211]\n",
      "epoch:14 step:13576 [D loss: 0.647612, acc.: 64.84%] [G loss: 0.881807]\n",
      "epoch:14 step:13577 [D loss: 0.621837, acc.: 67.19%] [G loss: 0.927849]\n",
      "epoch:14 step:13578 [D loss: 0.645226, acc.: 64.06%] [G loss: 0.963142]\n",
      "epoch:14 step:13579 [D loss: 0.707006, acc.: 49.22%] [G loss: 0.882011]\n",
      "epoch:14 step:13580 [D loss: 0.675568, acc.: 56.25%] [G loss: 0.872988]\n",
      "epoch:14 step:13581 [D loss: 0.665184, acc.: 60.16%] [G loss: 0.861052]\n",
      "epoch:14 step:13582 [D loss: 0.680730, acc.: 53.91%] [G loss: 0.864504]\n",
      "epoch:14 step:13583 [D loss: 0.663194, acc.: 61.72%] [G loss: 0.872131]\n",
      "epoch:14 step:13584 [D loss: 0.631658, acc.: 65.62%] [G loss: 0.823305]\n",
      "epoch:14 step:13585 [D loss: 0.689128, acc.: 57.03%] [G loss: 0.808560]\n",
      "epoch:14 step:13586 [D loss: 0.665634, acc.: 58.59%] [G loss: 0.872821]\n",
      "epoch:14 step:13587 [D loss: 0.644145, acc.: 64.84%] [G loss: 0.857784]\n",
      "epoch:14 step:13588 [D loss: 0.701724, acc.: 52.34%] [G loss: 0.846877]\n",
      "epoch:14 step:13589 [D loss: 0.667119, acc.: 57.03%] [G loss: 0.889165]\n",
      "epoch:14 step:13590 [D loss: 0.662073, acc.: 60.94%] [G loss: 0.876547]\n",
      "epoch:14 step:13591 [D loss: 0.671687, acc.: 61.72%] [G loss: 0.882093]\n",
      "epoch:14 step:13592 [D loss: 0.637591, acc.: 67.19%] [G loss: 0.877030]\n",
      "epoch:14 step:13593 [D loss: 0.632693, acc.: 67.97%] [G loss: 0.858410]\n",
      "epoch:14 step:13594 [D loss: 0.648537, acc.: 60.16%] [G loss: 0.876748]\n",
      "epoch:14 step:13595 [D loss: 0.687464, acc.: 53.91%] [G loss: 0.848982]\n",
      "epoch:14 step:13596 [D loss: 0.659420, acc.: 64.84%] [G loss: 0.824065]\n",
      "epoch:14 step:13597 [D loss: 0.705784, acc.: 49.22%] [G loss: 0.839589]\n",
      "epoch:14 step:13598 [D loss: 0.671230, acc.: 56.25%] [G loss: 0.902032]\n",
      "epoch:14 step:13599 [D loss: 0.668122, acc.: 60.94%] [G loss: 0.926341]\n",
      "epoch:14 step:13600 [D loss: 0.659016, acc.: 59.38%] [G loss: 0.875636]\n",
      "##############\n",
      "[3.01098468 2.10285161 2.05902363 4.03908633 1.42994685 7.98165953\n",
      " 2.63036262 2.97515869 4.23967675 7.14799875]\n",
      "##########\n",
      "epoch:14 step:13601 [D loss: 0.669626, acc.: 63.28%] [G loss: 0.902737]\n",
      "epoch:14 step:13602 [D loss: 0.657163, acc.: 62.50%] [G loss: 0.804414]\n",
      "epoch:14 step:13603 [D loss: 0.650130, acc.: 66.41%] [G loss: 0.848301]\n",
      "epoch:14 step:13604 [D loss: 0.660075, acc.: 60.94%] [G loss: 0.790299]\n",
      "epoch:14 step:13605 [D loss: 0.678656, acc.: 53.91%] [G loss: 0.858903]\n",
      "epoch:14 step:13606 [D loss: 0.650324, acc.: 59.38%] [G loss: 0.833513]\n",
      "epoch:14 step:13607 [D loss: 0.653989, acc.: 62.50%] [G loss: 0.895623]\n",
      "epoch:14 step:13608 [D loss: 0.653021, acc.: 64.06%] [G loss: 0.836266]\n",
      "epoch:14 step:13609 [D loss: 0.666211, acc.: 57.81%] [G loss: 0.904046]\n",
      "epoch:14 step:13610 [D loss: 0.677490, acc.: 55.47%] [G loss: 0.889394]\n",
      "epoch:14 step:13611 [D loss: 0.674597, acc.: 57.81%] [G loss: 0.886094]\n",
      "epoch:14 step:13612 [D loss: 0.646570, acc.: 63.28%] [G loss: 0.794907]\n",
      "epoch:14 step:13613 [D loss: 0.703892, acc.: 53.12%] [G loss: 0.839193]\n",
      "epoch:14 step:13614 [D loss: 0.671866, acc.: 54.69%] [G loss: 0.845012]\n",
      "epoch:14 step:13615 [D loss: 0.631737, acc.: 65.62%] [G loss: 0.889749]\n",
      "epoch:14 step:13616 [D loss: 0.657043, acc.: 60.94%] [G loss: 0.943194]\n",
      "epoch:14 step:13617 [D loss: 0.684113, acc.: 56.25%] [G loss: 0.946123]\n",
      "epoch:14 step:13618 [D loss: 0.656476, acc.: 63.28%] [G loss: 0.921508]\n",
      "epoch:14 step:13619 [D loss: 0.674369, acc.: 59.38%] [G loss: 0.925214]\n",
      "epoch:14 step:13620 [D loss: 0.679900, acc.: 55.47%] [G loss: 0.849419]\n",
      "epoch:14 step:13621 [D loss: 0.692021, acc.: 58.59%] [G loss: 0.856515]\n",
      "epoch:14 step:13622 [D loss: 0.676608, acc.: 60.94%] [G loss: 0.862278]\n",
      "epoch:14 step:13623 [D loss: 0.638934, acc.: 64.84%] [G loss: 0.873729]\n",
      "epoch:14 step:13624 [D loss: 0.704489, acc.: 49.22%] [G loss: 0.854718]\n",
      "epoch:14 step:13625 [D loss: 0.663839, acc.: 65.62%] [G loss: 0.856440]\n",
      "epoch:14 step:13626 [D loss: 0.651136, acc.: 62.50%] [G loss: 0.837909]\n",
      "epoch:14 step:13627 [D loss: 0.642596, acc.: 64.06%] [G loss: 0.832463]\n",
      "epoch:14 step:13628 [D loss: 0.652482, acc.: 60.16%] [G loss: 0.889005]\n",
      "epoch:14 step:13629 [D loss: 0.648928, acc.: 60.16%] [G loss: 0.883561]\n",
      "epoch:14 step:13630 [D loss: 0.689097, acc.: 54.69%] [G loss: 0.886079]\n",
      "epoch:14 step:13631 [D loss: 0.653217, acc.: 58.59%] [G loss: 0.832339]\n",
      "epoch:14 step:13632 [D loss: 0.678468, acc.: 57.81%] [G loss: 0.842767]\n",
      "epoch:14 step:13633 [D loss: 0.668758, acc.: 59.38%] [G loss: 0.891355]\n",
      "epoch:14 step:13634 [D loss: 0.642210, acc.: 62.50%] [G loss: 0.875012]\n",
      "epoch:14 step:13635 [D loss: 0.669539, acc.: 57.03%] [G loss: 0.861400]\n",
      "epoch:14 step:13636 [D loss: 0.675663, acc.: 53.12%] [G loss: 0.840184]\n",
      "epoch:14 step:13637 [D loss: 0.638145, acc.: 71.09%] [G loss: 0.848103]\n",
      "epoch:14 step:13638 [D loss: 0.640344, acc.: 64.06%] [G loss: 0.854160]\n",
      "epoch:14 step:13639 [D loss: 0.642030, acc.: 56.25%] [G loss: 0.823636]\n",
      "epoch:14 step:13640 [D loss: 0.648337, acc.: 60.16%] [G loss: 0.876355]\n",
      "epoch:14 step:13641 [D loss: 0.635456, acc.: 69.53%] [G loss: 0.861021]\n",
      "epoch:14 step:13642 [D loss: 0.673259, acc.: 57.03%] [G loss: 0.868443]\n",
      "epoch:14 step:13643 [D loss: 0.656431, acc.: 64.84%] [G loss: 0.926827]\n",
      "epoch:14 step:13644 [D loss: 0.718142, acc.: 50.78%] [G loss: 0.856867]\n",
      "epoch:14 step:13645 [D loss: 0.698109, acc.: 53.91%] [G loss: 0.849194]\n",
      "epoch:14 step:13646 [D loss: 0.677939, acc.: 57.03%] [G loss: 0.893133]\n",
      "epoch:14 step:13647 [D loss: 0.648113, acc.: 60.94%] [G loss: 0.918387]\n",
      "epoch:14 step:13648 [D loss: 0.678525, acc.: 54.69%] [G loss: 0.867106]\n",
      "epoch:14 step:13649 [D loss: 0.649800, acc.: 66.41%] [G loss: 0.867292]\n",
      "epoch:14 step:13650 [D loss: 0.678018, acc.: 57.03%] [G loss: 0.833662]\n",
      "epoch:14 step:13651 [D loss: 0.654182, acc.: 62.50%] [G loss: 0.833899]\n",
      "epoch:14 step:13652 [D loss: 0.682584, acc.: 55.47%] [G loss: 0.833385]\n",
      "epoch:14 step:13653 [D loss: 0.632534, acc.: 64.06%] [G loss: 0.791258]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13654 [D loss: 0.653324, acc.: 56.25%] [G loss: 0.827651]\n",
      "epoch:14 step:13655 [D loss: 0.674416, acc.: 60.16%] [G loss: 0.822479]\n",
      "epoch:14 step:13656 [D loss: 0.708293, acc.: 50.78%] [G loss: 0.803293]\n",
      "epoch:14 step:13657 [D loss: 0.649763, acc.: 57.03%] [G loss: 0.803577]\n",
      "epoch:14 step:13658 [D loss: 0.636442, acc.: 65.62%] [G loss: 0.861118]\n",
      "epoch:14 step:13659 [D loss: 0.680328, acc.: 56.25%] [G loss: 0.876575]\n",
      "epoch:14 step:13660 [D loss: 0.677281, acc.: 60.16%] [G loss: 0.853976]\n",
      "epoch:14 step:13661 [D loss: 0.627806, acc.: 65.62%] [G loss: 0.891632]\n",
      "epoch:14 step:13662 [D loss: 0.639746, acc.: 65.62%] [G loss: 0.903618]\n",
      "epoch:14 step:13663 [D loss: 0.684403, acc.: 56.25%] [G loss: 0.863914]\n",
      "epoch:14 step:13664 [D loss: 0.627031, acc.: 62.50%] [G loss: 0.839166]\n",
      "epoch:14 step:13665 [D loss: 0.686092, acc.: 54.69%] [G loss: 0.834661]\n",
      "epoch:14 step:13666 [D loss: 0.660672, acc.: 58.59%] [G loss: 0.800750]\n",
      "epoch:14 step:13667 [D loss: 0.667430, acc.: 62.50%] [G loss: 0.829858]\n",
      "epoch:14 step:13668 [D loss: 0.673089, acc.: 56.25%] [G loss: 0.942691]\n",
      "epoch:14 step:13669 [D loss: 0.690662, acc.: 57.03%] [G loss: 0.866479]\n",
      "epoch:14 step:13670 [D loss: 0.645423, acc.: 60.94%] [G loss: 0.864319]\n",
      "epoch:14 step:13671 [D loss: 0.691949, acc.: 52.34%] [G loss: 0.881162]\n",
      "epoch:14 step:13672 [D loss: 0.643854, acc.: 59.38%] [G loss: 0.798286]\n",
      "epoch:14 step:13673 [D loss: 0.677221, acc.: 56.25%] [G loss: 0.810233]\n",
      "epoch:14 step:13674 [D loss: 0.685138, acc.: 52.34%] [G loss: 0.844063]\n",
      "epoch:14 step:13675 [D loss: 0.661672, acc.: 60.16%] [G loss: 0.874580]\n",
      "epoch:14 step:13676 [D loss: 0.674462, acc.: 59.38%] [G loss: 0.886584]\n",
      "epoch:14 step:13677 [D loss: 0.670985, acc.: 57.81%] [G loss: 0.844953]\n",
      "epoch:14 step:13678 [D loss: 0.658123, acc.: 60.94%] [G loss: 0.830210]\n",
      "epoch:14 step:13679 [D loss: 0.674082, acc.: 53.12%] [G loss: 0.848817]\n",
      "epoch:14 step:13680 [D loss: 0.679312, acc.: 58.59%] [G loss: 0.825073]\n",
      "epoch:14 step:13681 [D loss: 0.659026, acc.: 62.50%] [G loss: 0.797785]\n",
      "epoch:14 step:13682 [D loss: 0.666761, acc.: 59.38%] [G loss: 0.780667]\n",
      "epoch:14 step:13683 [D loss: 0.670586, acc.: 56.25%] [G loss: 0.851473]\n",
      "epoch:14 step:13684 [D loss: 0.627850, acc.: 65.62%] [G loss: 0.866499]\n",
      "epoch:14 step:13685 [D loss: 0.654756, acc.: 56.25%] [G loss: 0.855734]\n",
      "epoch:14 step:13686 [D loss: 0.709026, acc.: 56.25%] [G loss: 0.869315]\n",
      "epoch:14 step:13687 [D loss: 0.677367, acc.: 59.38%] [G loss: 0.872386]\n",
      "epoch:14 step:13688 [D loss: 0.660191, acc.: 60.16%] [G loss: 0.893259]\n",
      "epoch:14 step:13689 [D loss: 0.694032, acc.: 52.34%] [G loss: 0.840732]\n",
      "epoch:14 step:13690 [D loss: 0.677330, acc.: 55.47%] [G loss: 0.840868]\n",
      "epoch:14 step:13691 [D loss: 0.693814, acc.: 52.34%] [G loss: 0.829894]\n",
      "epoch:14 step:13692 [D loss: 0.653978, acc.: 60.16%] [G loss: 0.862948]\n",
      "epoch:14 step:13693 [D loss: 0.678024, acc.: 57.03%] [G loss: 0.835228]\n",
      "epoch:14 step:13694 [D loss: 0.652648, acc.: 67.19%] [G loss: 0.814767]\n",
      "epoch:14 step:13695 [D loss: 0.650764, acc.: 60.94%] [G loss: 0.855563]\n",
      "epoch:14 step:13696 [D loss: 0.689060, acc.: 57.81%] [G loss: 0.888005]\n",
      "epoch:14 step:13697 [D loss: 0.669613, acc.: 57.03%] [G loss: 0.842433]\n",
      "epoch:14 step:13698 [D loss: 0.692668, acc.: 51.56%] [G loss: 0.868097]\n",
      "epoch:14 step:13699 [D loss: 0.668933, acc.: 59.38%] [G loss: 0.845132]\n",
      "epoch:14 step:13700 [D loss: 0.657686, acc.: 64.06%] [G loss: 0.884036]\n",
      "epoch:14 step:13701 [D loss: 0.681651, acc.: 57.03%] [G loss: 0.859556]\n",
      "epoch:14 step:13702 [D loss: 0.667200, acc.: 56.25%] [G loss: 0.839054]\n",
      "epoch:14 step:13703 [D loss: 0.675320, acc.: 60.94%] [G loss: 0.840396]\n",
      "epoch:14 step:13704 [D loss: 0.669305, acc.: 53.12%] [G loss: 0.873294]\n",
      "epoch:14 step:13705 [D loss: 0.675673, acc.: 60.16%] [G loss: 0.848453]\n",
      "epoch:14 step:13706 [D loss: 0.667161, acc.: 56.25%] [G loss: 0.798351]\n",
      "epoch:14 step:13707 [D loss: 0.609862, acc.: 71.88%] [G loss: 0.855024]\n",
      "epoch:14 step:13708 [D loss: 0.688342, acc.: 60.16%] [G loss: 0.895938]\n",
      "epoch:14 step:13709 [D loss: 0.666528, acc.: 59.38%] [G loss: 0.818282]\n",
      "epoch:14 step:13710 [D loss: 0.671379, acc.: 54.69%] [G loss: 0.853780]\n",
      "epoch:14 step:13711 [D loss: 0.698634, acc.: 50.00%] [G loss: 0.837659]\n",
      "epoch:14 step:13712 [D loss: 0.666368, acc.: 58.59%] [G loss: 0.864285]\n",
      "epoch:14 step:13713 [D loss: 0.661999, acc.: 64.84%] [G loss: 0.854828]\n",
      "epoch:14 step:13714 [D loss: 0.656430, acc.: 58.59%] [G loss: 0.936490]\n",
      "epoch:14 step:13715 [D loss: 0.659947, acc.: 69.53%] [G loss: 0.875547]\n",
      "epoch:14 step:13716 [D loss: 0.659297, acc.: 58.59%] [G loss: 0.921166]\n",
      "epoch:14 step:13717 [D loss: 0.656003, acc.: 66.41%] [G loss: 0.939953]\n",
      "epoch:14 step:13718 [D loss: 0.664737, acc.: 58.59%] [G loss: 0.910387]\n",
      "epoch:14 step:13719 [D loss: 0.684264, acc.: 57.81%] [G loss: 0.883156]\n",
      "epoch:14 step:13720 [D loss: 0.654840, acc.: 62.50%] [G loss: 0.842977]\n",
      "epoch:14 step:13721 [D loss: 0.690891, acc.: 53.12%] [G loss: 0.912845]\n",
      "epoch:14 step:13722 [D loss: 0.673840, acc.: 57.81%] [G loss: 0.886924]\n",
      "epoch:14 step:13723 [D loss: 0.676958, acc.: 57.81%] [G loss: 0.841531]\n",
      "epoch:14 step:13724 [D loss: 0.670980, acc.: 66.41%] [G loss: 0.835583]\n",
      "epoch:14 step:13725 [D loss: 0.653030, acc.: 56.25%] [G loss: 0.839226]\n",
      "epoch:14 step:13726 [D loss: 0.672963, acc.: 57.03%] [G loss: 0.863948]\n",
      "epoch:14 step:13727 [D loss: 0.626902, acc.: 71.09%] [G loss: 0.875376]\n",
      "epoch:14 step:13728 [D loss: 0.680923, acc.: 58.59%] [G loss: 0.930407]\n",
      "epoch:14 step:13729 [D loss: 0.659785, acc.: 58.59%] [G loss: 0.890823]\n",
      "epoch:14 step:13730 [D loss: 0.644010, acc.: 60.94%] [G loss: 0.858816]\n",
      "epoch:14 step:13731 [D loss: 0.668713, acc.: 52.34%] [G loss: 0.836445]\n",
      "epoch:14 step:13732 [D loss: 0.694116, acc.: 50.78%] [G loss: 0.864974]\n",
      "epoch:14 step:13733 [D loss: 0.695349, acc.: 57.81%] [G loss: 0.873168]\n",
      "epoch:14 step:13734 [D loss: 0.645299, acc.: 64.84%] [G loss: 0.865971]\n",
      "epoch:14 step:13735 [D loss: 0.653291, acc.: 60.16%] [G loss: 0.883735]\n",
      "epoch:14 step:13736 [D loss: 0.661518, acc.: 60.94%] [G loss: 0.835920]\n",
      "epoch:14 step:13737 [D loss: 0.697862, acc.: 53.12%] [G loss: 0.803071]\n",
      "epoch:14 step:13738 [D loss: 0.663246, acc.: 53.12%] [G loss: 0.822582]\n",
      "epoch:14 step:13739 [D loss: 0.698166, acc.: 57.03%] [G loss: 0.816056]\n",
      "epoch:14 step:13740 [D loss: 0.643900, acc.: 67.19%] [G loss: 0.909199]\n",
      "epoch:14 step:13741 [D loss: 0.651206, acc.: 60.16%] [G loss: 0.869972]\n",
      "epoch:14 step:13742 [D loss: 0.692777, acc.: 52.34%] [G loss: 0.871974]\n",
      "epoch:14 step:13743 [D loss: 0.678000, acc.: 58.59%] [G loss: 0.914358]\n",
      "epoch:14 step:13744 [D loss: 0.661761, acc.: 60.16%] [G loss: 0.884332]\n",
      "epoch:14 step:13745 [D loss: 0.644480, acc.: 60.94%] [G loss: 0.876870]\n",
      "epoch:14 step:13746 [D loss: 0.697121, acc.: 56.25%] [G loss: 0.830836]\n",
      "epoch:14 step:13747 [D loss: 0.698970, acc.: 53.91%] [G loss: 0.835659]\n",
      "epoch:14 step:13748 [D loss: 0.656358, acc.: 60.94%] [G loss: 0.848506]\n",
      "epoch:14 step:13749 [D loss: 0.671870, acc.: 53.12%] [G loss: 0.860395]\n",
      "epoch:14 step:13750 [D loss: 0.670544, acc.: 60.94%] [G loss: 0.884386]\n",
      "epoch:14 step:13751 [D loss: 0.635340, acc.: 62.50%] [G loss: 0.885224]\n",
      "epoch:14 step:13752 [D loss: 0.669947, acc.: 57.03%] [G loss: 0.877204]\n",
      "epoch:14 step:13753 [D loss: 0.647458, acc.: 61.72%] [G loss: 0.843048]\n",
      "epoch:14 step:13754 [D loss: 0.611088, acc.: 67.19%] [G loss: 0.879074]\n",
      "epoch:14 step:13755 [D loss: 0.671387, acc.: 59.38%] [G loss: 0.896906]\n",
      "epoch:14 step:13756 [D loss: 0.683820, acc.: 56.25%] [G loss: 0.868255]\n",
      "epoch:14 step:13757 [D loss: 0.714964, acc.: 50.00%] [G loss: 0.881708]\n",
      "epoch:14 step:13758 [D loss: 0.677257, acc.: 56.25%] [G loss: 0.884875]\n",
      "epoch:14 step:13759 [D loss: 0.684185, acc.: 57.03%] [G loss: 0.853795]\n",
      "epoch:14 step:13760 [D loss: 0.704009, acc.: 50.78%] [G loss: 0.887488]\n",
      "epoch:14 step:13761 [D loss: 0.690727, acc.: 57.81%] [G loss: 0.896150]\n",
      "epoch:14 step:13762 [D loss: 0.661397, acc.: 61.72%] [G loss: 0.868434]\n",
      "epoch:14 step:13763 [D loss: 0.678530, acc.: 50.00%] [G loss: 0.852084]\n",
      "epoch:14 step:13764 [D loss: 0.684981, acc.: 60.94%] [G loss: 0.856615]\n",
      "epoch:14 step:13765 [D loss: 0.688441, acc.: 52.34%] [G loss: 0.839212]\n",
      "epoch:14 step:13766 [D loss: 0.613619, acc.: 68.75%] [G loss: 0.845267]\n",
      "epoch:14 step:13767 [D loss: 0.714921, acc.: 50.78%] [G loss: 0.821116]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13768 [D loss: 0.669283, acc.: 57.03%] [G loss: 0.829855]\n",
      "epoch:14 step:13769 [D loss: 0.660007, acc.: 58.59%] [G loss: 0.839264]\n",
      "epoch:14 step:13770 [D loss: 0.682075, acc.: 55.47%] [G loss: 0.813405]\n",
      "epoch:14 step:13771 [D loss: 0.650256, acc.: 59.38%] [G loss: 0.838745]\n",
      "epoch:14 step:13772 [D loss: 0.672748, acc.: 54.69%] [G loss: 0.807459]\n",
      "epoch:14 step:13773 [D loss: 0.676146, acc.: 57.81%] [G loss: 0.824846]\n",
      "epoch:14 step:13774 [D loss: 0.664020, acc.: 60.94%] [G loss: 0.838675]\n",
      "epoch:14 step:13775 [D loss: 0.684110, acc.: 57.03%] [G loss: 0.816817]\n",
      "epoch:14 step:13776 [D loss: 0.662952, acc.: 62.50%] [G loss: 0.844456]\n",
      "epoch:14 step:13777 [D loss: 0.692287, acc.: 56.25%] [G loss: 0.847648]\n",
      "epoch:14 step:13778 [D loss: 0.671175, acc.: 60.94%] [G loss: 0.841354]\n",
      "epoch:14 step:13779 [D loss: 0.671650, acc.: 57.03%] [G loss: 0.824621]\n",
      "epoch:14 step:13780 [D loss: 0.702343, acc.: 56.25%] [G loss: 0.787421]\n",
      "epoch:14 step:13781 [D loss: 0.687870, acc.: 54.69%] [G loss: 0.847981]\n",
      "epoch:14 step:13782 [D loss: 0.705916, acc.: 53.12%] [G loss: 0.869544]\n",
      "epoch:14 step:13783 [D loss: 0.690271, acc.: 53.91%] [G loss: 0.878333]\n",
      "epoch:14 step:13784 [D loss: 0.636829, acc.: 68.75%] [G loss: 0.837095]\n",
      "epoch:14 step:13785 [D loss: 0.662636, acc.: 57.81%] [G loss: 0.861531]\n",
      "epoch:14 step:13786 [D loss: 0.664487, acc.: 57.03%] [G loss: 0.833819]\n",
      "epoch:14 step:13787 [D loss: 0.628924, acc.: 64.06%] [G loss: 0.852175]\n",
      "epoch:14 step:13788 [D loss: 0.627114, acc.: 65.62%] [G loss: 0.888202]\n",
      "epoch:14 step:13789 [D loss: 0.643578, acc.: 67.19%] [G loss: 0.873543]\n",
      "epoch:14 step:13790 [D loss: 0.684333, acc.: 54.69%] [G loss: 0.862044]\n",
      "epoch:14 step:13791 [D loss: 0.664342, acc.: 57.81%] [G loss: 0.847759]\n",
      "epoch:14 step:13792 [D loss: 0.701647, acc.: 50.78%] [G loss: 0.878950]\n",
      "epoch:14 step:13793 [D loss: 0.683482, acc.: 54.69%] [G loss: 0.852693]\n",
      "epoch:14 step:13794 [D loss: 0.680733, acc.: 59.38%] [G loss: 0.872274]\n",
      "epoch:14 step:13795 [D loss: 0.658449, acc.: 59.38%] [G loss: 0.892539]\n",
      "epoch:14 step:13796 [D loss: 0.643670, acc.: 64.06%] [G loss: 0.816529]\n",
      "epoch:14 step:13797 [D loss: 0.659845, acc.: 60.16%] [G loss: 0.834136]\n",
      "epoch:14 step:13798 [D loss: 0.661773, acc.: 61.72%] [G loss: 0.813511]\n",
      "epoch:14 step:13799 [D loss: 0.670011, acc.: 58.59%] [G loss: 0.862871]\n",
      "epoch:14 step:13800 [D loss: 0.668481, acc.: 58.59%] [G loss: 0.855239]\n",
      "##############\n",
      "[3.29899286 2.13117199 2.51059603 4.08372057 1.60953837 8.79397624\n",
      " 3.18189113 3.0519298  4.18544979 7.14868929]\n",
      "##########\n",
      "epoch:14 step:13801 [D loss: 0.655673, acc.: 63.28%] [G loss: 0.838349]\n",
      "epoch:14 step:13802 [D loss: 0.690303, acc.: 49.22%] [G loss: 0.836945]\n",
      "epoch:14 step:13803 [D loss: 0.622109, acc.: 64.84%] [G loss: 0.845912]\n",
      "epoch:14 step:13804 [D loss: 0.681221, acc.: 56.25%] [G loss: 0.843554]\n",
      "epoch:14 step:13805 [D loss: 0.668305, acc.: 61.72%] [G loss: 0.821638]\n",
      "epoch:14 step:13806 [D loss: 0.643413, acc.: 66.41%] [G loss: 0.783932]\n",
      "epoch:14 step:13807 [D loss: 0.694776, acc.: 52.34%] [G loss: 0.796515]\n",
      "epoch:14 step:13808 [D loss: 0.692335, acc.: 54.69%] [G loss: 0.844280]\n",
      "epoch:14 step:13809 [D loss: 0.687610, acc.: 55.47%] [G loss: 0.855600]\n",
      "epoch:14 step:13810 [D loss: 0.654271, acc.: 62.50%] [G loss: 0.851111]\n",
      "epoch:14 step:13811 [D loss: 0.653736, acc.: 61.72%] [G loss: 0.854171]\n",
      "epoch:14 step:13812 [D loss: 0.699371, acc.: 52.34%] [G loss: 0.826094]\n",
      "epoch:14 step:13813 [D loss: 0.668007, acc.: 57.81%] [G loss: 0.836715]\n",
      "epoch:14 step:13814 [D loss: 0.639764, acc.: 63.28%] [G loss: 0.899315]\n",
      "epoch:14 step:13815 [D loss: 0.657255, acc.: 59.38%] [G loss: 0.862506]\n",
      "epoch:14 step:13816 [D loss: 0.653908, acc.: 61.72%] [G loss: 0.795864]\n",
      "epoch:14 step:13817 [D loss: 0.668386, acc.: 57.81%] [G loss: 0.818940]\n",
      "epoch:14 step:13818 [D loss: 0.652489, acc.: 60.94%] [G loss: 0.827317]\n",
      "epoch:14 step:13819 [D loss: 0.670483, acc.: 58.59%] [G loss: 0.812793]\n",
      "epoch:14 step:13820 [D loss: 0.657497, acc.: 62.50%] [G loss: 0.808348]\n",
      "epoch:14 step:13821 [D loss: 0.664762, acc.: 57.03%] [G loss: 0.842735]\n",
      "epoch:14 step:13822 [D loss: 0.672024, acc.: 55.47%] [G loss: 0.862115]\n",
      "epoch:14 step:13823 [D loss: 0.667962, acc.: 56.25%] [G loss: 0.866143]\n",
      "epoch:14 step:13824 [D loss: 0.683871, acc.: 55.47%] [G loss: 0.875175]\n",
      "epoch:14 step:13825 [D loss: 0.673229, acc.: 57.81%] [G loss: 0.838597]\n",
      "epoch:14 step:13826 [D loss: 0.679293, acc.: 56.25%] [G loss: 0.825615]\n",
      "epoch:14 step:13827 [D loss: 0.727867, acc.: 45.31%] [G loss: 0.844815]\n",
      "epoch:14 step:13828 [D loss: 0.667195, acc.: 60.94%] [G loss: 0.899858]\n",
      "epoch:14 step:13829 [D loss: 0.686775, acc.: 58.59%] [G loss: 0.892915]\n",
      "epoch:14 step:13830 [D loss: 0.692218, acc.: 56.25%] [G loss: 0.852589]\n",
      "epoch:14 step:13831 [D loss: 0.695155, acc.: 51.56%] [G loss: 0.844815]\n",
      "epoch:14 step:13832 [D loss: 0.672304, acc.: 55.47%] [G loss: 0.876371]\n",
      "epoch:14 step:13833 [D loss: 0.691819, acc.: 49.22%] [G loss: 0.845931]\n",
      "epoch:14 step:13834 [D loss: 0.679164, acc.: 55.47%] [G loss: 0.861069]\n",
      "epoch:14 step:13835 [D loss: 0.663286, acc.: 64.06%] [G loss: 0.866662]\n",
      "epoch:14 step:13836 [D loss: 0.652660, acc.: 60.16%] [G loss: 0.843580]\n",
      "epoch:14 step:13837 [D loss: 0.657441, acc.: 61.72%] [G loss: 0.836068]\n",
      "epoch:14 step:13838 [D loss: 0.637272, acc.: 63.28%] [G loss: 0.877361]\n",
      "epoch:14 step:13839 [D loss: 0.685206, acc.: 57.81%] [G loss: 0.853938]\n",
      "epoch:14 step:13840 [D loss: 0.683963, acc.: 54.69%] [G loss: 0.907483]\n",
      "epoch:14 step:13841 [D loss: 0.647038, acc.: 62.50%] [G loss: 0.893994]\n",
      "epoch:14 step:13842 [D loss: 0.643322, acc.: 67.97%] [G loss: 0.785524]\n",
      "epoch:14 step:13843 [D loss: 0.666802, acc.: 60.16%] [G loss: 0.893019]\n",
      "epoch:14 step:13844 [D loss: 0.664575, acc.: 58.59%] [G loss: 0.921815]\n",
      "epoch:14 step:13845 [D loss: 0.635822, acc.: 62.50%] [G loss: 0.900576]\n",
      "epoch:14 step:13846 [D loss: 0.673906, acc.: 66.41%] [G loss: 0.849175]\n",
      "epoch:14 step:13847 [D loss: 0.671765, acc.: 60.16%] [G loss: 0.848492]\n",
      "epoch:14 step:13848 [D loss: 0.658784, acc.: 67.19%] [G loss: 0.884147]\n",
      "epoch:14 step:13849 [D loss: 0.682870, acc.: 57.81%] [G loss: 0.888406]\n",
      "epoch:14 step:13850 [D loss: 0.653497, acc.: 60.94%] [G loss: 0.884948]\n",
      "epoch:14 step:13851 [D loss: 0.664079, acc.: 62.50%] [G loss: 0.875996]\n",
      "epoch:14 step:13852 [D loss: 0.630278, acc.: 67.97%] [G loss: 0.896951]\n",
      "epoch:14 step:13853 [D loss: 0.643003, acc.: 68.75%] [G loss: 0.864431]\n",
      "epoch:14 step:13854 [D loss: 0.648835, acc.: 62.50%] [G loss: 0.829021]\n",
      "epoch:14 step:13855 [D loss: 0.688897, acc.: 59.38%] [G loss: 0.826845]\n",
      "epoch:14 step:13856 [D loss: 0.671113, acc.: 53.91%] [G loss: 0.841631]\n",
      "epoch:14 step:13857 [D loss: 0.665879, acc.: 57.81%] [G loss: 0.842427]\n",
      "epoch:14 step:13858 [D loss: 0.688279, acc.: 53.12%] [G loss: 0.870134]\n",
      "epoch:14 step:13859 [D loss: 0.676144, acc.: 57.81%] [G loss: 0.903201]\n",
      "epoch:14 step:13860 [D loss: 0.675277, acc.: 57.03%] [G loss: 0.872090]\n",
      "epoch:14 step:13861 [D loss: 0.689218, acc.: 51.56%] [G loss: 0.893067]\n",
      "epoch:14 step:13862 [D loss: 0.648447, acc.: 67.19%] [G loss: 0.874931]\n",
      "epoch:14 step:13863 [D loss: 0.643399, acc.: 61.72%] [G loss: 0.918863]\n",
      "epoch:14 step:13864 [D loss: 0.653546, acc.: 63.28%] [G loss: 0.901878]\n",
      "epoch:14 step:13865 [D loss: 0.659511, acc.: 58.59%] [G loss: 0.861969]\n",
      "epoch:14 step:13866 [D loss: 0.635356, acc.: 65.62%] [G loss: 0.849572]\n",
      "epoch:14 step:13867 [D loss: 0.684097, acc.: 53.12%] [G loss: 0.864415]\n",
      "epoch:14 step:13868 [D loss: 0.624492, acc.: 66.41%] [G loss: 0.892457]\n",
      "epoch:14 step:13869 [D loss: 0.669339, acc.: 55.47%] [G loss: 0.870946]\n",
      "epoch:14 step:13870 [D loss: 0.671301, acc.: 58.59%] [G loss: 0.840187]\n",
      "epoch:14 step:13871 [D loss: 0.680511, acc.: 64.84%] [G loss: 0.837858]\n",
      "epoch:14 step:13872 [D loss: 0.641760, acc.: 70.31%] [G loss: 0.783956]\n",
      "epoch:14 step:13873 [D loss: 0.695691, acc.: 54.69%] [G loss: 0.808895]\n",
      "epoch:14 step:13874 [D loss: 0.654430, acc.: 63.28%] [G loss: 0.857554]\n",
      "epoch:14 step:13875 [D loss: 0.635524, acc.: 64.06%] [G loss: 0.917125]\n",
      "epoch:14 step:13876 [D loss: 0.674459, acc.: 56.25%] [G loss: 0.896040]\n",
      "epoch:14 step:13877 [D loss: 0.659181, acc.: 63.28%] [G loss: 0.867550]\n",
      "epoch:14 step:13878 [D loss: 0.631952, acc.: 65.62%] [G loss: 0.901811]\n",
      "epoch:14 step:13879 [D loss: 0.682465, acc.: 55.47%] [G loss: 0.831659]\n",
      "epoch:14 step:13880 [D loss: 0.669705, acc.: 53.91%] [G loss: 0.863629]\n",
      "epoch:14 step:13881 [D loss: 0.643298, acc.: 58.59%] [G loss: 0.824994]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13882 [D loss: 0.648229, acc.: 59.38%] [G loss: 0.842422]\n",
      "epoch:14 step:13883 [D loss: 0.653635, acc.: 62.50%] [G loss: 0.831174]\n",
      "epoch:14 step:13884 [D loss: 0.655889, acc.: 60.94%] [G loss: 0.852906]\n",
      "epoch:14 step:13885 [D loss: 0.675101, acc.: 51.56%] [G loss: 0.834823]\n",
      "epoch:14 step:13886 [D loss: 0.634989, acc.: 66.41%] [G loss: 0.915645]\n",
      "epoch:14 step:13887 [D loss: 0.660706, acc.: 60.94%] [G loss: 0.902280]\n",
      "epoch:14 step:13888 [D loss: 0.684903, acc.: 55.47%] [G loss: 0.858786]\n",
      "epoch:14 step:13889 [D loss: 0.680178, acc.: 55.47%] [G loss: 0.876790]\n",
      "epoch:14 step:13890 [D loss: 0.685539, acc.: 56.25%] [G loss: 0.866789]\n",
      "epoch:14 step:13891 [D loss: 0.658248, acc.: 59.38%] [G loss: 0.820780]\n",
      "epoch:14 step:13892 [D loss: 0.645060, acc.: 60.16%] [G loss: 0.867842]\n",
      "epoch:14 step:13893 [D loss: 0.653999, acc.: 58.59%] [G loss: 0.827211]\n",
      "epoch:14 step:13894 [D loss: 0.688670, acc.: 53.12%] [G loss: 0.810815]\n",
      "epoch:14 step:13895 [D loss: 0.665226, acc.: 60.94%] [G loss: 0.855613]\n",
      "epoch:14 step:13896 [D loss: 0.643948, acc.: 64.06%] [G loss: 0.843104]\n",
      "epoch:14 step:13897 [D loss: 0.648267, acc.: 64.06%] [G loss: 0.839988]\n",
      "epoch:14 step:13898 [D loss: 0.715527, acc.: 50.78%] [G loss: 0.844804]\n",
      "epoch:14 step:13899 [D loss: 0.690087, acc.: 53.12%] [G loss: 0.876001]\n",
      "epoch:14 step:13900 [D loss: 0.675495, acc.: 53.91%] [G loss: 0.879468]\n",
      "epoch:14 step:13901 [D loss: 0.667524, acc.: 57.81%] [G loss: 0.839527]\n",
      "epoch:14 step:13902 [D loss: 0.648038, acc.: 58.59%] [G loss: 0.902089]\n",
      "epoch:14 step:13903 [D loss: 0.667513, acc.: 57.03%] [G loss: 0.896508]\n",
      "epoch:14 step:13904 [D loss: 0.686867, acc.: 57.03%] [G loss: 0.816353]\n",
      "epoch:14 step:13905 [D loss: 0.678026, acc.: 49.22%] [G loss: 0.892849]\n",
      "epoch:14 step:13906 [D loss: 0.678567, acc.: 55.47%] [G loss: 0.829862]\n",
      "epoch:14 step:13907 [D loss: 0.634117, acc.: 65.62%] [G loss: 0.833355]\n",
      "epoch:14 step:13908 [D loss: 0.653221, acc.: 59.38%] [G loss: 0.877695]\n",
      "epoch:14 step:13909 [D loss: 0.664610, acc.: 57.81%] [G loss: 0.850678]\n",
      "epoch:14 step:13910 [D loss: 0.652587, acc.: 58.59%] [G loss: 0.817068]\n",
      "epoch:14 step:13911 [D loss: 0.654548, acc.: 64.84%] [G loss: 0.858369]\n",
      "epoch:14 step:13912 [D loss: 0.654070, acc.: 63.28%] [G loss: 0.893665]\n",
      "epoch:14 step:13913 [D loss: 0.643200, acc.: 63.28%] [G loss: 0.862579]\n",
      "epoch:14 step:13914 [D loss: 0.648457, acc.: 59.38%] [G loss: 0.860897]\n",
      "epoch:14 step:13915 [D loss: 0.684076, acc.: 53.12%] [G loss: 0.934067]\n",
      "epoch:14 step:13916 [D loss: 0.647626, acc.: 64.06%] [G loss: 0.860375]\n",
      "epoch:14 step:13917 [D loss: 0.659062, acc.: 65.62%] [G loss: 0.867521]\n",
      "epoch:14 step:13918 [D loss: 0.635231, acc.: 70.31%] [G loss: 0.851564]\n",
      "epoch:14 step:13919 [D loss: 0.644863, acc.: 57.03%] [G loss: 0.899386]\n",
      "epoch:14 step:13920 [D loss: 0.668627, acc.: 64.84%] [G loss: 0.874187]\n",
      "epoch:14 step:13921 [D loss: 0.663817, acc.: 63.28%] [G loss: 0.820736]\n",
      "epoch:14 step:13922 [D loss: 0.698987, acc.: 50.78%] [G loss: 0.879690]\n",
      "epoch:14 step:13923 [D loss: 0.666644, acc.: 59.38%] [G loss: 0.886453]\n",
      "epoch:14 step:13924 [D loss: 0.663753, acc.: 64.06%] [G loss: 0.870844]\n",
      "epoch:14 step:13925 [D loss: 0.637822, acc.: 67.19%] [G loss: 0.797398]\n",
      "epoch:14 step:13926 [D loss: 0.668034, acc.: 56.25%] [G loss: 0.855270]\n",
      "epoch:14 step:13927 [D loss: 0.658668, acc.: 59.38%] [G loss: 0.861395]\n",
      "epoch:14 step:13928 [D loss: 0.653503, acc.: 57.81%] [G loss: 0.841858]\n",
      "epoch:14 step:13929 [D loss: 0.675065, acc.: 54.69%] [G loss: 0.859066]\n",
      "epoch:14 step:13930 [D loss: 0.682938, acc.: 60.16%] [G loss: 0.871889]\n",
      "epoch:14 step:13931 [D loss: 0.676750, acc.: 57.03%] [G loss: 0.890948]\n",
      "epoch:14 step:13932 [D loss: 0.639220, acc.: 64.84%] [G loss: 0.892961]\n",
      "epoch:14 step:13933 [D loss: 0.657720, acc.: 63.28%] [G loss: 0.934750]\n",
      "epoch:14 step:13934 [D loss: 0.630509, acc.: 67.97%] [G loss: 0.870602]\n",
      "epoch:14 step:13935 [D loss: 0.703228, acc.: 56.25%] [G loss: 0.904899]\n",
      "epoch:14 step:13936 [D loss: 0.703327, acc.: 50.78%] [G loss: 0.846656]\n",
      "epoch:14 step:13937 [D loss: 0.689411, acc.: 54.69%] [G loss: 0.831450]\n",
      "epoch:14 step:13938 [D loss: 0.697954, acc.: 53.12%] [G loss: 0.886850]\n",
      "epoch:14 step:13939 [D loss: 0.662485, acc.: 61.72%] [G loss: 0.862229]\n",
      "epoch:14 step:13940 [D loss: 0.633437, acc.: 64.84%] [G loss: 0.940525]\n",
      "epoch:14 step:13941 [D loss: 0.707530, acc.: 53.91%] [G loss: 0.870203]\n",
      "epoch:14 step:13942 [D loss: 0.700529, acc.: 63.28%] [G loss: 0.860366]\n",
      "epoch:14 step:13943 [D loss: 0.619925, acc.: 63.28%] [G loss: 0.892860]\n",
      "epoch:14 step:13944 [D loss: 0.654774, acc.: 57.81%] [G loss: 0.892259]\n",
      "epoch:14 step:13945 [D loss: 0.686257, acc.: 53.12%] [G loss: 0.869295]\n",
      "epoch:14 step:13946 [D loss: 0.694199, acc.: 51.56%] [G loss: 0.812623]\n",
      "epoch:14 step:13947 [D loss: 0.657931, acc.: 60.16%] [G loss: 0.886945]\n",
      "epoch:14 step:13948 [D loss: 0.660913, acc.: 59.38%] [G loss: 0.812539]\n",
      "epoch:14 step:13949 [D loss: 0.687127, acc.: 50.00%] [G loss: 0.857361]\n",
      "epoch:14 step:13950 [D loss: 0.671311, acc.: 59.38%] [G loss: 0.885023]\n",
      "epoch:14 step:13951 [D loss: 0.669436, acc.: 56.25%] [G loss: 0.890710]\n",
      "epoch:14 step:13952 [D loss: 0.707135, acc.: 57.81%] [G loss: 0.836784]\n",
      "epoch:14 step:13953 [D loss: 0.645241, acc.: 68.75%] [G loss: 0.883403]\n",
      "epoch:14 step:13954 [D loss: 0.691142, acc.: 51.56%] [G loss: 0.881320]\n",
      "epoch:14 step:13955 [D loss: 0.632108, acc.: 62.50%] [G loss: 0.853105]\n",
      "epoch:14 step:13956 [D loss: 0.708492, acc.: 54.69%] [G loss: 0.827524]\n",
      "epoch:14 step:13957 [D loss: 0.668905, acc.: 60.16%] [G loss: 0.870178]\n",
      "epoch:14 step:13958 [D loss: 0.694717, acc.: 54.69%] [G loss: 0.884823]\n",
      "epoch:14 step:13959 [D loss: 0.683499, acc.: 59.38%] [G loss: 0.857095]\n",
      "epoch:14 step:13960 [D loss: 0.672674, acc.: 58.59%] [G loss: 0.846032]\n",
      "epoch:14 step:13961 [D loss: 0.712525, acc.: 53.12%] [G loss: 0.795975]\n",
      "epoch:14 step:13962 [D loss: 0.710729, acc.: 53.12%] [G loss: 0.844923]\n",
      "epoch:14 step:13963 [D loss: 0.707581, acc.: 51.56%] [G loss: 0.817410]\n",
      "epoch:14 step:13964 [D loss: 0.680781, acc.: 58.59%] [G loss: 0.857489]\n",
      "epoch:14 step:13965 [D loss: 0.664445, acc.: 60.94%] [G loss: 0.887997]\n",
      "epoch:14 step:13966 [D loss: 0.674343, acc.: 53.91%] [G loss: 0.841923]\n",
      "epoch:14 step:13967 [D loss: 0.650131, acc.: 60.16%] [G loss: 0.855678]\n",
      "epoch:14 step:13968 [D loss: 0.647493, acc.: 63.28%] [G loss: 0.861644]\n",
      "epoch:14 step:13969 [D loss: 0.665505, acc.: 59.38%] [G loss: 0.888552]\n",
      "epoch:14 step:13970 [D loss: 0.655584, acc.: 62.50%] [G loss: 0.916629]\n",
      "epoch:14 step:13971 [D loss: 0.689967, acc.: 54.69%] [G loss: 0.886711]\n",
      "epoch:14 step:13972 [D loss: 0.664623, acc.: 57.81%] [G loss: 0.917402]\n",
      "epoch:14 step:13973 [D loss: 0.705658, acc.: 53.12%] [G loss: 0.857694]\n",
      "epoch:14 step:13974 [D loss: 0.681807, acc.: 60.16%] [G loss: 0.801728]\n",
      "epoch:14 step:13975 [D loss: 0.685287, acc.: 60.16%] [G loss: 0.869114]\n",
      "epoch:14 step:13976 [D loss: 0.664797, acc.: 57.03%] [G loss: 0.858776]\n",
      "epoch:14 step:13977 [D loss: 0.670258, acc.: 57.03%] [G loss: 0.842058]\n",
      "epoch:14 step:13978 [D loss: 0.660465, acc.: 56.25%] [G loss: 0.883403]\n",
      "epoch:14 step:13979 [D loss: 0.642992, acc.: 61.72%] [G loss: 0.834165]\n",
      "epoch:14 step:13980 [D loss: 0.640144, acc.: 64.06%] [G loss: 0.850192]\n",
      "epoch:14 step:13981 [D loss: 0.665208, acc.: 58.59%] [G loss: 0.836503]\n",
      "epoch:14 step:13982 [D loss: 0.684151, acc.: 57.03%] [G loss: 0.895980]\n",
      "epoch:14 step:13983 [D loss: 0.654051, acc.: 62.50%] [G loss: 0.847361]\n",
      "epoch:14 step:13984 [D loss: 0.709060, acc.: 58.59%] [G loss: 0.868612]\n",
      "epoch:14 step:13985 [D loss: 0.701518, acc.: 54.69%] [G loss: 0.865842]\n",
      "epoch:14 step:13986 [D loss: 0.647432, acc.: 60.94%] [G loss: 0.824457]\n",
      "epoch:14 step:13987 [D loss: 0.677139, acc.: 56.25%] [G loss: 0.853890]\n",
      "epoch:14 step:13988 [D loss: 0.686640, acc.: 60.16%] [G loss: 0.881901]\n",
      "epoch:14 step:13989 [D loss: 0.667913, acc.: 65.62%] [G loss: 0.859122]\n",
      "epoch:14 step:13990 [D loss: 0.668543, acc.: 57.81%] [G loss: 0.863468]\n",
      "epoch:14 step:13991 [D loss: 0.626660, acc.: 67.19%] [G loss: 0.859034]\n",
      "epoch:14 step:13992 [D loss: 0.671412, acc.: 61.72%] [G loss: 0.822892]\n",
      "epoch:14 step:13993 [D loss: 0.686476, acc.: 58.59%] [G loss: 0.866920]\n",
      "epoch:14 step:13994 [D loss: 0.675779, acc.: 60.16%] [G loss: 0.870725]\n",
      "epoch:14 step:13995 [D loss: 0.666802, acc.: 57.81%] [G loss: 0.850933]\n",
      "epoch:14 step:13996 [D loss: 0.678120, acc.: 56.25%] [G loss: 0.833975]\n",
      "epoch:14 step:13997 [D loss: 0.681473, acc.: 57.03%] [G loss: 0.805219]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:14 step:13998 [D loss: 0.671085, acc.: 53.12%] [G loss: 0.812315]\n",
      "epoch:14 step:13999 [D loss: 0.689109, acc.: 53.91%] [G loss: 0.836522]\n",
      "epoch:14 step:14000 [D loss: 0.637547, acc.: 69.53%] [G loss: 0.829203]\n",
      "##############\n",
      "[ 3.03957856  2.59963328  2.18205843  4.05121375  1.51499884 10.27426719\n",
      "  2.42867065  4.05907825  4.23236711  8.14868929]\n",
      "##########\n",
      "epoch:14 step:14001 [D loss: 0.662525, acc.: 60.94%] [G loss: 0.812629]\n",
      "epoch:14 step:14002 [D loss: 0.639692, acc.: 59.38%] [G loss: 0.815871]\n",
      "epoch:14 step:14003 [D loss: 0.684653, acc.: 53.12%] [G loss: 0.848158]\n",
      "epoch:14 step:14004 [D loss: 0.695357, acc.: 50.00%] [G loss: 0.860815]\n",
      "epoch:14 step:14005 [D loss: 0.657510, acc.: 57.81%] [G loss: 0.839132]\n",
      "epoch:14 step:14006 [D loss: 0.654737, acc.: 63.28%] [G loss: 0.879850]\n",
      "epoch:14 step:14007 [D loss: 0.672381, acc.: 57.81%] [G loss: 0.923528]\n",
      "epoch:14 step:14008 [D loss: 0.670566, acc.: 56.25%] [G loss: 0.914649]\n",
      "epoch:14 step:14009 [D loss: 0.682698, acc.: 55.47%] [G loss: 0.915037]\n",
      "epoch:14 step:14010 [D loss: 0.696262, acc.: 58.59%] [G loss: 0.890217]\n",
      "epoch:14 step:14011 [D loss: 0.690697, acc.: 50.78%] [G loss: 0.815680]\n",
      "epoch:14 step:14012 [D loss: 0.692364, acc.: 55.47%] [G loss: 0.826318]\n",
      "epoch:14 step:14013 [D loss: 0.692343, acc.: 55.47%] [G loss: 0.853412]\n",
      "epoch:14 step:14014 [D loss: 0.664430, acc.: 54.69%] [G loss: 0.841176]\n",
      "epoch:14 step:14015 [D loss: 0.642040, acc.: 60.16%] [G loss: 0.842896]\n",
      "epoch:14 step:14016 [D loss: 0.661453, acc.: 57.03%] [G loss: 0.825236]\n",
      "epoch:14 step:14017 [D loss: 0.688464, acc.: 59.38%] [G loss: 0.832832]\n",
      "epoch:14 step:14018 [D loss: 0.662131, acc.: 59.38%] [G loss: 0.814868]\n",
      "epoch:14 step:14019 [D loss: 0.637724, acc.: 65.62%] [G loss: 0.815715]\n",
      "epoch:14 step:14020 [D loss: 0.656575, acc.: 60.94%] [G loss: 0.837588]\n",
      "epoch:14 step:14021 [D loss: 0.631069, acc.: 67.19%] [G loss: 0.819394]\n",
      "epoch:14 step:14022 [D loss: 0.640419, acc.: 65.62%] [G loss: 0.831954]\n",
      "epoch:14 step:14023 [D loss: 0.718998, acc.: 49.22%] [G loss: 0.844941]\n",
      "epoch:14 step:14024 [D loss: 0.657889, acc.: 60.94%] [G loss: 0.841235]\n",
      "epoch:14 step:14025 [D loss: 0.690926, acc.: 53.91%] [G loss: 0.824034]\n",
      "epoch:14 step:14026 [D loss: 0.724058, acc.: 45.31%] [G loss: 0.808517]\n",
      "epoch:14 step:14027 [D loss: 0.666521, acc.: 60.16%] [G loss: 0.843188]\n",
      "epoch:14 step:14028 [D loss: 0.687904, acc.: 56.25%] [G loss: 0.859080]\n",
      "epoch:14 step:14029 [D loss: 0.665525, acc.: 59.38%] [G loss: 0.870047]\n",
      "epoch:14 step:14030 [D loss: 0.676757, acc.: 53.91%] [G loss: 0.860474]\n",
      "epoch:14 step:14031 [D loss: 0.699592, acc.: 51.56%] [G loss: 0.850898]\n",
      "epoch:14 step:14032 [D loss: 0.656049, acc.: 64.06%] [G loss: 0.879839]\n",
      "epoch:14 step:14033 [D loss: 0.706896, acc.: 50.78%] [G loss: 0.834154]\n",
      "epoch:14 step:14034 [D loss: 0.669384, acc.: 55.47%] [G loss: 0.793844]\n",
      "epoch:14 step:14035 [D loss: 0.646054, acc.: 60.94%] [G loss: 0.849092]\n",
      "epoch:14 step:14036 [D loss: 0.666757, acc.: 62.50%] [G loss: 0.842069]\n",
      "epoch:14 step:14037 [D loss: 0.651940, acc.: 57.03%] [G loss: 0.828884]\n",
      "epoch:14 step:14038 [D loss: 0.651631, acc.: 61.72%] [G loss: 0.862966]\n",
      "epoch:14 step:14039 [D loss: 0.677883, acc.: 53.91%] [G loss: 0.801813]\n",
      "epoch:14 step:14040 [D loss: 0.658600, acc.: 61.72%] [G loss: 0.826291]\n",
      "epoch:14 step:14041 [D loss: 0.705172, acc.: 46.88%] [G loss: 0.865917]\n",
      "epoch:14 step:14042 [D loss: 0.647000, acc.: 59.38%] [G loss: 0.855026]\n",
      "epoch:14 step:14043 [D loss: 0.677485, acc.: 60.94%] [G loss: 0.892333]\n",
      "epoch:14 step:14044 [D loss: 0.654725, acc.: 63.28%] [G loss: 0.884354]\n",
      "epoch:14 step:14045 [D loss: 0.669309, acc.: 54.69%] [G loss: 0.851364]\n",
      "epoch:14 step:14046 [D loss: 0.643624, acc.: 62.50%] [G loss: 0.861877]\n",
      "epoch:14 step:14047 [D loss: 0.674464, acc.: 57.03%] [G loss: 0.873987]\n",
      "epoch:14 step:14048 [D loss: 0.666550, acc.: 60.16%] [G loss: 0.900983]\n",
      "epoch:14 step:14049 [D loss: 0.654624, acc.: 63.28%] [G loss: 0.866931]\n",
      "epoch:14 step:14050 [D loss: 0.661406, acc.: 68.75%] [G loss: 0.850076]\n",
      "epoch:14 step:14051 [D loss: 0.698105, acc.: 56.25%] [G loss: 0.824234]\n",
      "epoch:14 step:14052 [D loss: 0.662592, acc.: 61.72%] [G loss: 0.846071]\n",
      "epoch:14 step:14053 [D loss: 0.669301, acc.: 58.59%] [G loss: 0.850161]\n",
      "epoch:14 step:14054 [D loss: 0.653884, acc.: 62.50%] [G loss: 0.846943]\n",
      "epoch:14 step:14055 [D loss: 0.664065, acc.: 61.72%] [G loss: 0.851255]\n",
      "epoch:15 step:14056 [D loss: 0.647287, acc.: 59.38%] [G loss: 0.884146]\n",
      "epoch:15 step:14057 [D loss: 0.647002, acc.: 60.94%] [G loss: 0.872226]\n",
      "epoch:15 step:14058 [D loss: 0.632242, acc.: 61.72%] [G loss: 0.870925]\n",
      "epoch:15 step:14059 [D loss: 0.646245, acc.: 67.97%] [G loss: 0.852910]\n",
      "epoch:15 step:14060 [D loss: 0.667969, acc.: 58.59%] [G loss: 0.847574]\n",
      "epoch:15 step:14061 [D loss: 0.633682, acc.: 67.19%] [G loss: 0.829103]\n",
      "epoch:15 step:14062 [D loss: 0.664084, acc.: 57.81%] [G loss: 0.841655]\n",
      "epoch:15 step:14063 [D loss: 0.624627, acc.: 66.41%] [G loss: 0.865922]\n",
      "epoch:15 step:14064 [D loss: 0.644225, acc.: 62.50%] [G loss: 0.823108]\n",
      "epoch:15 step:14065 [D loss: 0.655261, acc.: 66.41%] [G loss: 0.832171]\n",
      "epoch:15 step:14066 [D loss: 0.648110, acc.: 59.38%] [G loss: 0.832382]\n",
      "epoch:15 step:14067 [D loss: 0.665068, acc.: 58.59%] [G loss: 0.829967]\n",
      "epoch:15 step:14068 [D loss: 0.654226, acc.: 59.38%] [G loss: 0.827876]\n",
      "epoch:15 step:14069 [D loss: 0.680160, acc.: 58.59%] [G loss: 0.837715]\n",
      "epoch:15 step:14070 [D loss: 0.686776, acc.: 56.25%] [G loss: 0.880507]\n",
      "epoch:15 step:14071 [D loss: 0.633436, acc.: 67.19%] [G loss: 0.870009]\n",
      "epoch:15 step:14072 [D loss: 0.653246, acc.: 60.94%] [G loss: 0.797157]\n",
      "epoch:15 step:14073 [D loss: 0.676032, acc.: 57.03%] [G loss: 0.880419]\n",
      "epoch:15 step:14074 [D loss: 0.693645, acc.: 60.16%] [G loss: 0.909544]\n",
      "epoch:15 step:14075 [D loss: 0.654132, acc.: 64.84%] [G loss: 0.836002]\n",
      "epoch:15 step:14076 [D loss: 0.634685, acc.: 64.06%] [G loss: 0.946307]\n",
      "epoch:15 step:14077 [D loss: 0.650997, acc.: 65.62%] [G loss: 0.925543]\n",
      "epoch:15 step:14078 [D loss: 0.649485, acc.: 64.06%] [G loss: 0.903286]\n",
      "epoch:15 step:14079 [D loss: 0.687131, acc.: 51.56%] [G loss: 0.853304]\n",
      "epoch:15 step:14080 [D loss: 0.645561, acc.: 66.41%] [G loss: 0.853354]\n",
      "epoch:15 step:14081 [D loss: 0.658562, acc.: 57.81%] [G loss: 0.851271]\n",
      "epoch:15 step:14082 [D loss: 0.651079, acc.: 59.38%] [G loss: 0.932878]\n",
      "epoch:15 step:14083 [D loss: 0.669240, acc.: 64.06%] [G loss: 0.900952]\n",
      "epoch:15 step:14084 [D loss: 0.646880, acc.: 67.97%] [G loss: 0.877646]\n",
      "epoch:15 step:14085 [D loss: 0.654045, acc.: 62.50%] [G loss: 0.870776]\n",
      "epoch:15 step:14086 [D loss: 0.666875, acc.: 58.59%] [G loss: 0.853626]\n",
      "epoch:15 step:14087 [D loss: 0.650345, acc.: 59.38%] [G loss: 0.855883]\n",
      "epoch:15 step:14088 [D loss: 0.648047, acc.: 59.38%] [G loss: 0.899851]\n",
      "epoch:15 step:14089 [D loss: 0.666344, acc.: 57.81%] [G loss: 0.829715]\n",
      "epoch:15 step:14090 [D loss: 0.667754, acc.: 55.47%] [G loss: 0.839390]\n",
      "epoch:15 step:14091 [D loss: 0.633500, acc.: 65.62%] [G loss: 0.803737]\n",
      "epoch:15 step:14092 [D loss: 0.644945, acc.: 62.50%] [G loss: 0.891213]\n",
      "epoch:15 step:14093 [D loss: 0.703453, acc.: 51.56%] [G loss: 0.901896]\n",
      "epoch:15 step:14094 [D loss: 0.632180, acc.: 64.84%] [G loss: 0.854699]\n",
      "epoch:15 step:14095 [D loss: 0.683859, acc.: 60.94%] [G loss: 0.831567]\n",
      "epoch:15 step:14096 [D loss: 0.665013, acc.: 62.50%] [G loss: 0.832761]\n",
      "epoch:15 step:14097 [D loss: 0.665545, acc.: 57.03%] [G loss: 0.847273]\n",
      "epoch:15 step:14098 [D loss: 0.683542, acc.: 57.03%] [G loss: 0.841212]\n",
      "epoch:15 step:14099 [D loss: 0.643971, acc.: 60.16%] [G loss: 0.885655]\n",
      "epoch:15 step:14100 [D loss: 0.698743, acc.: 53.91%] [G loss: 0.864487]\n",
      "epoch:15 step:14101 [D loss: 0.660273, acc.: 53.12%] [G loss: 0.846089]\n",
      "epoch:15 step:14102 [D loss: 0.733469, acc.: 50.78%] [G loss: 0.847946]\n",
      "epoch:15 step:14103 [D loss: 0.677217, acc.: 57.03%] [G loss: 0.845999]\n",
      "epoch:15 step:14104 [D loss: 0.682149, acc.: 57.03%] [G loss: 0.799396]\n",
      "epoch:15 step:14105 [D loss: 0.633007, acc.: 59.38%] [G loss: 0.815761]\n",
      "epoch:15 step:14106 [D loss: 0.655447, acc.: 63.28%] [G loss: 0.875079]\n",
      "epoch:15 step:14107 [D loss: 0.658348, acc.: 59.38%] [G loss: 0.871710]\n",
      "epoch:15 step:14108 [D loss: 0.650720, acc.: 62.50%] [G loss: 0.879329]\n",
      "epoch:15 step:14109 [D loss: 0.618868, acc.: 66.41%] [G loss: 0.872706]\n",
      "epoch:15 step:14110 [D loss: 0.723582, acc.: 49.22%] [G loss: 0.860864]\n",
      "epoch:15 step:14111 [D loss: 0.681203, acc.: 58.59%] [G loss: 0.900339]\n",
      "epoch:15 step:14112 [D loss: 0.686232, acc.: 55.47%] [G loss: 0.833078]\n",
      "epoch:15 step:14113 [D loss: 0.658866, acc.: 60.94%] [G loss: 0.887212]\n",
      "epoch:15 step:14114 [D loss: 0.649657, acc.: 65.62%] [G loss: 0.874283]\n",
      "epoch:15 step:14115 [D loss: 0.646100, acc.: 62.50%] [G loss: 0.871267]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14116 [D loss: 0.648886, acc.: 65.62%] [G loss: 0.858196]\n",
      "epoch:15 step:14117 [D loss: 0.671687, acc.: 58.59%] [G loss: 0.900137]\n",
      "epoch:15 step:14118 [D loss: 0.673149, acc.: 58.59%] [G loss: 0.872714]\n",
      "epoch:15 step:14119 [D loss: 0.676996, acc.: 54.69%] [G loss: 0.830255]\n",
      "epoch:15 step:14120 [D loss: 0.672388, acc.: 60.94%] [G loss: 0.867844]\n",
      "epoch:15 step:14121 [D loss: 0.654997, acc.: 65.62%] [G loss: 0.927421]\n",
      "epoch:15 step:14122 [D loss: 0.711573, acc.: 50.78%] [G loss: 0.896658]\n",
      "epoch:15 step:14123 [D loss: 0.676497, acc.: 56.25%] [G loss: 0.875544]\n",
      "epoch:15 step:14124 [D loss: 0.633948, acc.: 65.62%] [G loss: 0.957365]\n",
      "epoch:15 step:14125 [D loss: 0.676912, acc.: 58.59%] [G loss: 0.900764]\n",
      "epoch:15 step:14126 [D loss: 0.705498, acc.: 54.69%] [G loss: 0.882511]\n",
      "epoch:15 step:14127 [D loss: 0.702484, acc.: 50.00%] [G loss: 0.823733]\n",
      "epoch:15 step:14128 [D loss: 0.640963, acc.: 67.97%] [G loss: 0.874568]\n",
      "epoch:15 step:14129 [D loss: 0.687432, acc.: 59.38%] [G loss: 0.852695]\n",
      "epoch:15 step:14130 [D loss: 0.664759, acc.: 58.59%] [G loss: 0.844016]\n",
      "epoch:15 step:14131 [D loss: 0.632807, acc.: 67.19%] [G loss: 0.857484]\n",
      "epoch:15 step:14132 [D loss: 0.710555, acc.: 50.00%] [G loss: 0.839153]\n",
      "epoch:15 step:14133 [D loss: 0.664063, acc.: 57.81%] [G loss: 0.839035]\n",
      "epoch:15 step:14134 [D loss: 0.671554, acc.: 55.47%] [G loss: 0.844171]\n",
      "epoch:15 step:14135 [D loss: 0.662595, acc.: 54.69%] [G loss: 0.853389]\n",
      "epoch:15 step:14136 [D loss: 0.662788, acc.: 60.16%] [G loss: 0.851825]\n",
      "epoch:15 step:14137 [D loss: 0.670566, acc.: 52.34%] [G loss: 0.855172]\n",
      "epoch:15 step:14138 [D loss: 0.657797, acc.: 57.81%] [G loss: 0.872981]\n",
      "epoch:15 step:14139 [D loss: 0.677964, acc.: 53.12%] [G loss: 0.893156]\n",
      "epoch:15 step:14140 [D loss: 0.652065, acc.: 58.59%] [G loss: 0.884230]\n",
      "epoch:15 step:14141 [D loss: 0.685417, acc.: 51.56%] [G loss: 0.835490]\n",
      "epoch:15 step:14142 [D loss: 0.642446, acc.: 61.72%] [G loss: 0.880306]\n",
      "epoch:15 step:14143 [D loss: 0.667440, acc.: 63.28%] [G loss: 0.866812]\n",
      "epoch:15 step:14144 [D loss: 0.642240, acc.: 67.19%] [G loss: 0.882188]\n",
      "epoch:15 step:14145 [D loss: 0.671906, acc.: 57.81%] [G loss: 0.824983]\n",
      "epoch:15 step:14146 [D loss: 0.683784, acc.: 54.69%] [G loss: 0.855529]\n",
      "epoch:15 step:14147 [D loss: 0.655245, acc.: 58.59%] [G loss: 0.840170]\n",
      "epoch:15 step:14148 [D loss: 0.667454, acc.: 57.81%] [G loss: 0.864639]\n",
      "epoch:15 step:14149 [D loss: 0.692453, acc.: 52.34%] [G loss: 0.906870]\n",
      "epoch:15 step:14150 [D loss: 0.676630, acc.: 52.34%] [G loss: 0.852929]\n",
      "epoch:15 step:14151 [D loss: 0.680646, acc.: 56.25%] [G loss: 0.804095]\n",
      "epoch:15 step:14152 [D loss: 0.672893, acc.: 64.06%] [G loss: 0.840776]\n",
      "epoch:15 step:14153 [D loss: 0.656510, acc.: 58.59%] [G loss: 0.833844]\n",
      "epoch:15 step:14154 [D loss: 0.684229, acc.: 53.91%] [G loss: 0.861704]\n",
      "epoch:15 step:14155 [D loss: 0.698543, acc.: 49.22%] [G loss: 0.843617]\n",
      "epoch:15 step:14156 [D loss: 0.636465, acc.: 64.06%] [G loss: 0.944957]\n",
      "epoch:15 step:14157 [D loss: 0.692765, acc.: 57.81%] [G loss: 0.882797]\n",
      "epoch:15 step:14158 [D loss: 0.679569, acc.: 60.16%] [G loss: 0.854433]\n",
      "epoch:15 step:14159 [D loss: 0.664428, acc.: 57.03%] [G loss: 0.897520]\n",
      "epoch:15 step:14160 [D loss: 0.649360, acc.: 67.19%] [G loss: 0.846987]\n",
      "epoch:15 step:14161 [D loss: 0.656114, acc.: 63.28%] [G loss: 0.887886]\n",
      "epoch:15 step:14162 [D loss: 0.660438, acc.: 57.81%] [G loss: 0.888299]\n",
      "epoch:15 step:14163 [D loss: 0.683065, acc.: 54.69%] [G loss: 0.842535]\n",
      "epoch:15 step:14164 [D loss: 0.656981, acc.: 57.81%] [G loss: 0.817994]\n",
      "epoch:15 step:14165 [D loss: 0.685228, acc.: 52.34%] [G loss: 0.891799]\n",
      "epoch:15 step:14166 [D loss: 0.677167, acc.: 54.69%] [G loss: 0.910147]\n",
      "epoch:15 step:14167 [D loss: 0.656538, acc.: 58.59%] [G loss: 0.844519]\n",
      "epoch:15 step:14168 [D loss: 0.663855, acc.: 61.72%] [G loss: 0.888196]\n",
      "epoch:15 step:14169 [D loss: 0.661245, acc.: 62.50%] [G loss: 0.881854]\n",
      "epoch:15 step:14170 [D loss: 0.669604, acc.: 59.38%] [G loss: 0.889644]\n",
      "epoch:15 step:14171 [D loss: 0.651949, acc.: 57.81%] [G loss: 0.950679]\n",
      "epoch:15 step:14172 [D loss: 0.671904, acc.: 57.81%] [G loss: 0.824158]\n",
      "epoch:15 step:14173 [D loss: 0.665299, acc.: 60.94%] [G loss: 0.873960]\n",
      "epoch:15 step:14174 [D loss: 0.669397, acc.: 58.59%] [G loss: 0.876892]\n",
      "epoch:15 step:14175 [D loss: 0.666575, acc.: 60.94%] [G loss: 0.826858]\n",
      "epoch:15 step:14176 [D loss: 0.659402, acc.: 59.38%] [G loss: 0.859293]\n",
      "epoch:15 step:14177 [D loss: 0.671140, acc.: 59.38%] [G loss: 0.826497]\n",
      "epoch:15 step:14178 [D loss: 0.645944, acc.: 57.81%] [G loss: 0.858240]\n",
      "epoch:15 step:14179 [D loss: 0.670662, acc.: 56.25%] [G loss: 0.819700]\n",
      "epoch:15 step:14180 [D loss: 0.647482, acc.: 64.06%] [G loss: 0.826880]\n",
      "epoch:15 step:14181 [D loss: 0.692389, acc.: 49.22%] [G loss: 0.824217]\n",
      "epoch:15 step:14182 [D loss: 0.621042, acc.: 67.97%] [G loss: 0.816714]\n",
      "epoch:15 step:14183 [D loss: 0.658427, acc.: 61.72%] [G loss: 0.868287]\n",
      "epoch:15 step:14184 [D loss: 0.660508, acc.: 64.84%] [G loss: 0.834398]\n",
      "epoch:15 step:14185 [D loss: 0.645522, acc.: 66.41%] [G loss: 0.872173]\n",
      "epoch:15 step:14186 [D loss: 0.640124, acc.: 67.97%] [G loss: 0.886148]\n",
      "epoch:15 step:14187 [D loss: 0.720606, acc.: 51.56%] [G loss: 0.931828]\n",
      "epoch:15 step:14188 [D loss: 0.683857, acc.: 57.03%] [G loss: 0.909576]\n",
      "epoch:15 step:14189 [D loss: 0.656702, acc.: 60.94%] [G loss: 0.858000]\n",
      "epoch:15 step:14190 [D loss: 0.682956, acc.: 56.25%] [G loss: 0.909482]\n",
      "epoch:15 step:14191 [D loss: 0.680095, acc.: 54.69%] [G loss: 0.841710]\n",
      "epoch:15 step:14192 [D loss: 0.668330, acc.: 61.72%] [G loss: 0.824748]\n",
      "epoch:15 step:14193 [D loss: 0.652252, acc.: 60.16%] [G loss: 0.777059]\n",
      "epoch:15 step:14194 [D loss: 0.692540, acc.: 53.91%] [G loss: 0.855970]\n",
      "epoch:15 step:14195 [D loss: 0.640426, acc.: 58.59%] [G loss: 0.830972]\n",
      "epoch:15 step:14196 [D loss: 0.678046, acc.: 55.47%] [G loss: 0.812869]\n",
      "epoch:15 step:14197 [D loss: 0.661149, acc.: 57.03%] [G loss: 0.858520]\n",
      "epoch:15 step:14198 [D loss: 0.657038, acc.: 67.19%] [G loss: 0.819567]\n",
      "epoch:15 step:14199 [D loss: 0.643794, acc.: 63.28%] [G loss: 0.796014]\n",
      "epoch:15 step:14200 [D loss: 0.690584, acc.: 51.56%] [G loss: 0.843514]\n",
      "##############\n",
      "[2.91974171 2.62690388 2.32107762 3.9252147  1.27113966 7.84611844\n",
      " 2.76523884 3.96282846 4.32913584 8.14868929]\n",
      "##########\n",
      "epoch:15 step:14201 [D loss: 0.646813, acc.: 58.59%] [G loss: 0.828579]\n",
      "epoch:15 step:14202 [D loss: 0.668114, acc.: 57.81%] [G loss: 0.899494]\n",
      "epoch:15 step:14203 [D loss: 0.673485, acc.: 54.69%] [G loss: 0.859849]\n",
      "epoch:15 step:14204 [D loss: 0.654675, acc.: 55.47%] [G loss: 0.828945]\n",
      "epoch:15 step:14205 [D loss: 0.678254, acc.: 53.12%] [G loss: 0.841324]\n",
      "epoch:15 step:14206 [D loss: 0.688228, acc.: 52.34%] [G loss: 0.816536]\n",
      "epoch:15 step:14207 [D loss: 0.638871, acc.: 69.53%] [G loss: 0.838646]\n",
      "epoch:15 step:14208 [D loss: 0.634783, acc.: 60.94%] [G loss: 0.839202]\n",
      "epoch:15 step:14209 [D loss: 0.671214, acc.: 58.59%] [G loss: 0.836501]\n",
      "epoch:15 step:14210 [D loss: 0.666310, acc.: 50.78%] [G loss: 0.874264]\n",
      "epoch:15 step:14211 [D loss: 0.649166, acc.: 61.72%] [G loss: 0.875482]\n",
      "epoch:15 step:14212 [D loss: 0.697586, acc.: 55.47%] [G loss: 0.851236]\n",
      "epoch:15 step:14213 [D loss: 0.672495, acc.: 58.59%] [G loss: 0.803176]\n",
      "epoch:15 step:14214 [D loss: 0.657144, acc.: 64.06%] [G loss: 0.826903]\n",
      "epoch:15 step:14215 [D loss: 0.688938, acc.: 56.25%] [G loss: 0.867350]\n",
      "epoch:15 step:14216 [D loss: 0.681676, acc.: 50.78%] [G loss: 0.846564]\n",
      "epoch:15 step:14217 [D loss: 0.657990, acc.: 58.59%] [G loss: 0.817372]\n",
      "epoch:15 step:14218 [D loss: 0.687285, acc.: 58.59%] [G loss: 0.840062]\n",
      "epoch:15 step:14219 [D loss: 0.668537, acc.: 54.69%] [G loss: 0.852234]\n",
      "epoch:15 step:14220 [D loss: 0.682488, acc.: 54.69%] [G loss: 0.844371]\n",
      "epoch:15 step:14221 [D loss: 0.666739, acc.: 64.06%] [G loss: 0.872539]\n",
      "epoch:15 step:14222 [D loss: 0.656710, acc.: 58.59%] [G loss: 0.922956]\n",
      "epoch:15 step:14223 [D loss: 0.652076, acc.: 62.50%] [G loss: 0.897010]\n",
      "epoch:15 step:14224 [D loss: 0.668827, acc.: 60.16%] [G loss: 0.866863]\n",
      "epoch:15 step:14225 [D loss: 0.662845, acc.: 56.25%] [G loss: 0.882410]\n",
      "epoch:15 step:14226 [D loss: 0.676292, acc.: 60.16%] [G loss: 0.893512]\n",
      "epoch:15 step:14227 [D loss: 0.670420, acc.: 53.91%] [G loss: 0.817062]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14228 [D loss: 0.687185, acc.: 50.78%] [G loss: 0.825756]\n",
      "epoch:15 step:14229 [D loss: 0.650314, acc.: 63.28%] [G loss: 0.839469]\n",
      "epoch:15 step:14230 [D loss: 0.684256, acc.: 57.81%] [G loss: 0.854690]\n",
      "epoch:15 step:14231 [D loss: 0.628996, acc.: 67.19%] [G loss: 0.858124]\n",
      "epoch:15 step:14232 [D loss: 0.640051, acc.: 64.84%] [G loss: 0.910343]\n",
      "epoch:15 step:14233 [D loss: 0.683196, acc.: 54.69%] [G loss: 0.880176]\n",
      "epoch:15 step:14234 [D loss: 0.660157, acc.: 59.38%] [G loss: 0.871123]\n",
      "epoch:15 step:14235 [D loss: 0.630388, acc.: 67.97%] [G loss: 0.820051]\n",
      "epoch:15 step:14236 [D loss: 0.706398, acc.: 51.56%] [G loss: 0.852644]\n",
      "epoch:15 step:14237 [D loss: 0.656805, acc.: 61.72%] [G loss: 0.858527]\n",
      "epoch:15 step:14238 [D loss: 0.664048, acc.: 57.81%] [G loss: 0.854112]\n",
      "epoch:15 step:14239 [D loss: 0.691938, acc.: 56.25%] [G loss: 0.871372]\n",
      "epoch:15 step:14240 [D loss: 0.685402, acc.: 59.38%] [G loss: 0.850920]\n",
      "epoch:15 step:14241 [D loss: 0.674535, acc.: 55.47%] [G loss: 0.855901]\n",
      "epoch:15 step:14242 [D loss: 0.676630, acc.: 61.72%] [G loss: 0.836579]\n",
      "epoch:15 step:14243 [D loss: 0.689411, acc.: 54.69%] [G loss: 0.810607]\n",
      "epoch:15 step:14244 [D loss: 0.682937, acc.: 49.22%] [G loss: 0.848205]\n",
      "epoch:15 step:14245 [D loss: 0.667034, acc.: 55.47%] [G loss: 0.816665]\n",
      "epoch:15 step:14246 [D loss: 0.626326, acc.: 63.28%] [G loss: 0.786595]\n",
      "epoch:15 step:14247 [D loss: 0.653397, acc.: 61.72%] [G loss: 0.839578]\n",
      "epoch:15 step:14248 [D loss: 0.662400, acc.: 59.38%] [G loss: 0.792646]\n",
      "epoch:15 step:14249 [D loss: 0.679186, acc.: 57.03%] [G loss: 0.877016]\n",
      "epoch:15 step:14250 [D loss: 0.644281, acc.: 57.03%] [G loss: 0.854608]\n",
      "epoch:15 step:14251 [D loss: 0.643426, acc.: 62.50%] [G loss: 0.870010]\n",
      "epoch:15 step:14252 [D loss: 0.639392, acc.: 58.59%] [G loss: 0.885658]\n",
      "epoch:15 step:14253 [D loss: 0.629108, acc.: 67.19%] [G loss: 0.921952]\n",
      "epoch:15 step:14254 [D loss: 0.666949, acc.: 60.16%] [G loss: 0.857151]\n",
      "epoch:15 step:14255 [D loss: 0.644789, acc.: 60.16%] [G loss: 0.857020]\n",
      "epoch:15 step:14256 [D loss: 0.671585, acc.: 59.38%] [G loss: 0.842010]\n",
      "epoch:15 step:14257 [D loss: 0.610025, acc.: 67.19%] [G loss: 0.904653]\n",
      "epoch:15 step:14258 [D loss: 0.651609, acc.: 63.28%] [G loss: 0.876855]\n",
      "epoch:15 step:14259 [D loss: 0.642813, acc.: 63.28%] [G loss: 0.814817]\n",
      "epoch:15 step:14260 [D loss: 0.677065, acc.: 61.72%] [G loss: 0.837508]\n",
      "epoch:15 step:14261 [D loss: 0.692555, acc.: 56.25%] [G loss: 0.841741]\n",
      "epoch:15 step:14262 [D loss: 0.637563, acc.: 60.94%] [G loss: 0.873781]\n",
      "epoch:15 step:14263 [D loss: 0.667971, acc.: 62.50%] [G loss: 0.894930]\n",
      "epoch:15 step:14264 [D loss: 0.662255, acc.: 61.72%] [G loss: 0.872314]\n",
      "epoch:15 step:14265 [D loss: 0.650759, acc.: 63.28%] [G loss: 0.936971]\n",
      "epoch:15 step:14266 [D loss: 0.688283, acc.: 58.59%] [G loss: 0.924713]\n",
      "epoch:15 step:14267 [D loss: 0.656723, acc.: 63.28%] [G loss: 0.869527]\n",
      "epoch:15 step:14268 [D loss: 0.714972, acc.: 46.09%] [G loss: 0.875817]\n",
      "epoch:15 step:14269 [D loss: 0.680275, acc.: 60.16%] [G loss: 0.873245]\n",
      "epoch:15 step:14270 [D loss: 0.687561, acc.: 54.69%] [G loss: 0.880774]\n",
      "epoch:15 step:14271 [D loss: 0.692060, acc.: 50.78%] [G loss: 0.873810]\n",
      "epoch:15 step:14272 [D loss: 0.666136, acc.: 58.59%] [G loss: 0.846879]\n",
      "epoch:15 step:14273 [D loss: 0.654268, acc.: 59.38%] [G loss: 0.866048]\n",
      "epoch:15 step:14274 [D loss: 0.690366, acc.: 57.81%] [G loss: 0.835452]\n",
      "epoch:15 step:14275 [D loss: 0.667046, acc.: 59.38%] [G loss: 0.814399]\n",
      "epoch:15 step:14276 [D loss: 0.644328, acc.: 60.94%] [G loss: 0.820913]\n",
      "epoch:15 step:14277 [D loss: 0.684709, acc.: 58.59%] [G loss: 0.809922]\n",
      "epoch:15 step:14278 [D loss: 0.661023, acc.: 63.28%] [G loss: 0.867915]\n",
      "epoch:15 step:14279 [D loss: 0.675733, acc.: 53.12%] [G loss: 0.844668]\n",
      "epoch:15 step:14280 [D loss: 0.675333, acc.: 60.94%] [G loss: 0.900566]\n",
      "epoch:15 step:14281 [D loss: 0.621163, acc.: 64.84%] [G loss: 0.918379]\n",
      "epoch:15 step:14282 [D loss: 0.664550, acc.: 58.59%] [G loss: 0.902334]\n",
      "epoch:15 step:14283 [D loss: 0.683692, acc.: 55.47%] [G loss: 0.890086]\n",
      "epoch:15 step:14284 [D loss: 0.651804, acc.: 58.59%] [G loss: 0.917120]\n",
      "epoch:15 step:14285 [D loss: 0.672507, acc.: 58.59%] [G loss: 0.881327]\n",
      "epoch:15 step:14286 [D loss: 0.672194, acc.: 60.16%] [G loss: 0.894701]\n",
      "epoch:15 step:14287 [D loss: 0.658045, acc.: 60.94%] [G loss: 0.838686]\n",
      "epoch:15 step:14288 [D loss: 0.679632, acc.: 53.12%] [G loss: 0.848744]\n",
      "epoch:15 step:14289 [D loss: 0.683361, acc.: 60.94%] [G loss: 0.837861]\n",
      "epoch:15 step:14290 [D loss: 0.680815, acc.: 50.00%] [G loss: 0.834980]\n",
      "epoch:15 step:14291 [D loss: 0.643010, acc.: 66.41%] [G loss: 0.863293]\n",
      "epoch:15 step:14292 [D loss: 0.696776, acc.: 54.69%] [G loss: 0.864332]\n",
      "epoch:15 step:14293 [D loss: 0.670822, acc.: 57.81%] [G loss: 0.847694]\n",
      "epoch:15 step:14294 [D loss: 0.692126, acc.: 50.78%] [G loss: 0.799374]\n",
      "epoch:15 step:14295 [D loss: 0.669674, acc.: 62.50%] [G loss: 0.801935]\n",
      "epoch:15 step:14296 [D loss: 0.660423, acc.: 60.94%] [G loss: 0.864516]\n",
      "epoch:15 step:14297 [D loss: 0.646063, acc.: 66.41%] [G loss: 0.886419]\n",
      "epoch:15 step:14298 [D loss: 0.679701, acc.: 57.81%] [G loss: 0.865505]\n",
      "epoch:15 step:14299 [D loss: 0.687124, acc.: 53.91%] [G loss: 0.802679]\n",
      "epoch:15 step:14300 [D loss: 0.679810, acc.: 63.28%] [G loss: 0.804753]\n",
      "epoch:15 step:14301 [D loss: 0.659482, acc.: 60.16%] [G loss: 0.878695]\n",
      "epoch:15 step:14302 [D loss: 0.652820, acc.: 64.84%] [G loss: 0.856822]\n",
      "epoch:15 step:14303 [D loss: 0.684882, acc.: 55.47%] [G loss: 0.847082]\n",
      "epoch:15 step:14304 [D loss: 0.686812, acc.: 47.66%] [G loss: 0.891371]\n",
      "epoch:15 step:14305 [D loss: 0.649952, acc.: 63.28%] [G loss: 0.916575]\n",
      "epoch:15 step:14306 [D loss: 0.654937, acc.: 60.16%] [G loss: 0.865893]\n",
      "epoch:15 step:14307 [D loss: 0.656969, acc.: 63.28%] [G loss: 0.865931]\n",
      "epoch:15 step:14308 [D loss: 0.666705, acc.: 61.72%] [G loss: 0.851727]\n",
      "epoch:15 step:14309 [D loss: 0.687466, acc.: 53.91%] [G loss: 0.861383]\n",
      "epoch:15 step:14310 [D loss: 0.672699, acc.: 57.81%] [G loss: 0.855117]\n",
      "epoch:15 step:14311 [D loss: 0.660922, acc.: 59.38%] [G loss: 0.862541]\n",
      "epoch:15 step:14312 [D loss: 0.644863, acc.: 59.38%] [G loss: 0.888022]\n",
      "epoch:15 step:14313 [D loss: 0.684295, acc.: 62.50%] [G loss: 0.888076]\n",
      "epoch:15 step:14314 [D loss: 0.657450, acc.: 60.94%] [G loss: 0.850794]\n",
      "epoch:15 step:14315 [D loss: 0.660404, acc.: 57.03%] [G loss: 0.858732]\n",
      "epoch:15 step:14316 [D loss: 0.691560, acc.: 50.00%] [G loss: 0.830148]\n",
      "epoch:15 step:14317 [D loss: 0.690885, acc.: 52.34%] [G loss: 0.819116]\n",
      "epoch:15 step:14318 [D loss: 0.677106, acc.: 56.25%] [G loss: 0.871778]\n",
      "epoch:15 step:14319 [D loss: 0.661307, acc.: 57.03%] [G loss: 0.863229]\n",
      "epoch:15 step:14320 [D loss: 0.631168, acc.: 68.75%] [G loss: 0.877969]\n",
      "epoch:15 step:14321 [D loss: 0.643512, acc.: 64.84%] [G loss: 0.918555]\n",
      "epoch:15 step:14322 [D loss: 0.660984, acc.: 57.81%] [G loss: 0.861147]\n",
      "epoch:15 step:14323 [D loss: 0.683910, acc.: 55.47%] [G loss: 0.851701]\n",
      "epoch:15 step:14324 [D loss: 0.657523, acc.: 60.16%] [G loss: 0.887362]\n",
      "epoch:15 step:14325 [D loss: 0.617366, acc.: 69.53%] [G loss: 0.857077]\n",
      "epoch:15 step:14326 [D loss: 0.625408, acc.: 63.28%] [G loss: 0.818377]\n",
      "epoch:15 step:14327 [D loss: 0.687167, acc.: 50.78%] [G loss: 0.851373]\n",
      "epoch:15 step:14328 [D loss: 0.677296, acc.: 56.25%] [G loss: 0.862617]\n",
      "epoch:15 step:14329 [D loss: 0.645086, acc.: 62.50%] [G loss: 0.915081]\n",
      "epoch:15 step:14330 [D loss: 0.691550, acc.: 58.59%] [G loss: 0.839370]\n",
      "epoch:15 step:14331 [D loss: 0.690528, acc.: 50.78%] [G loss: 0.854054]\n",
      "epoch:15 step:14332 [D loss: 0.670997, acc.: 56.25%] [G loss: 0.866014]\n",
      "epoch:15 step:14333 [D loss: 0.704923, acc.: 55.47%] [G loss: 0.880901]\n",
      "epoch:15 step:14334 [D loss: 0.707629, acc.: 50.00%] [G loss: 0.876704]\n",
      "epoch:15 step:14335 [D loss: 0.671688, acc.: 57.03%] [G loss: 0.888504]\n",
      "epoch:15 step:14336 [D loss: 0.665870, acc.: 58.59%] [G loss: 0.870966]\n",
      "epoch:15 step:14337 [D loss: 0.660716, acc.: 58.59%] [G loss: 0.878580]\n",
      "epoch:15 step:14338 [D loss: 0.646205, acc.: 64.06%] [G loss: 0.823374]\n",
      "epoch:15 step:14339 [D loss: 0.645184, acc.: 64.84%] [G loss: 0.875492]\n",
      "epoch:15 step:14340 [D loss: 0.632300, acc.: 64.84%] [G loss: 0.850785]\n",
      "epoch:15 step:14341 [D loss: 0.629512, acc.: 71.09%] [G loss: 0.916843]\n",
      "epoch:15 step:14342 [D loss: 0.657038, acc.: 60.16%] [G loss: 0.894978]\n",
      "epoch:15 step:14343 [D loss: 0.689032, acc.: 53.12%] [G loss: 0.828054]\n",
      "epoch:15 step:14344 [D loss: 0.687407, acc.: 53.91%] [G loss: 0.871237]\n",
      "epoch:15 step:14345 [D loss: 0.625830, acc.: 69.53%] [G loss: 0.864610]\n",
      "epoch:15 step:14346 [D loss: 0.651258, acc.: 60.16%] [G loss: 0.850566]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14347 [D loss: 0.646053, acc.: 65.62%] [G loss: 0.841441]\n",
      "epoch:15 step:14348 [D loss: 0.704489, acc.: 50.78%] [G loss: 0.831362]\n",
      "epoch:15 step:14349 [D loss: 0.663117, acc.: 55.47%] [G loss: 0.854109]\n",
      "epoch:15 step:14350 [D loss: 0.673503, acc.: 57.03%] [G loss: 0.842622]\n",
      "epoch:15 step:14351 [D loss: 0.690853, acc.: 54.69%] [G loss: 0.851719]\n",
      "epoch:15 step:14352 [D loss: 0.670723, acc.: 54.69%] [G loss: 0.853207]\n",
      "epoch:15 step:14353 [D loss: 0.674972, acc.: 53.91%] [G loss: 0.893851]\n",
      "epoch:15 step:14354 [D loss: 0.693469, acc.: 56.25%] [G loss: 0.862576]\n",
      "epoch:15 step:14355 [D loss: 0.667271, acc.: 55.47%] [G loss: 0.928800]\n",
      "epoch:15 step:14356 [D loss: 0.684896, acc.: 59.38%] [G loss: 0.846039]\n",
      "epoch:15 step:14357 [D loss: 0.659557, acc.: 57.81%] [G loss: 0.857343]\n",
      "epoch:15 step:14358 [D loss: 0.675726, acc.: 59.38%] [G loss: 0.879656]\n",
      "epoch:15 step:14359 [D loss: 0.648247, acc.: 61.72%] [G loss: 0.842657]\n",
      "epoch:15 step:14360 [D loss: 0.674714, acc.: 54.69%] [G loss: 0.818005]\n",
      "epoch:15 step:14361 [D loss: 0.661954, acc.: 56.25%] [G loss: 0.846381]\n",
      "epoch:15 step:14362 [D loss: 0.660684, acc.: 60.16%] [G loss: 0.873028]\n",
      "epoch:15 step:14363 [D loss: 0.653711, acc.: 61.72%] [G loss: 0.838664]\n",
      "epoch:15 step:14364 [D loss: 0.667818, acc.: 53.12%] [G loss: 0.840208]\n",
      "epoch:15 step:14365 [D loss: 0.686280, acc.: 61.72%] [G loss: 0.875349]\n",
      "epoch:15 step:14366 [D loss: 0.641609, acc.: 65.62%] [G loss: 0.901000]\n",
      "epoch:15 step:14367 [D loss: 0.683521, acc.: 57.81%] [G loss: 0.869599]\n",
      "epoch:15 step:14368 [D loss: 0.702381, acc.: 50.78%] [G loss: 0.817633]\n",
      "epoch:15 step:14369 [D loss: 0.662595, acc.: 61.72%] [G loss: 0.823460]\n",
      "epoch:15 step:14370 [D loss: 0.680152, acc.: 56.25%] [G loss: 0.842484]\n",
      "epoch:15 step:14371 [D loss: 0.660065, acc.: 59.38%] [G loss: 0.874016]\n",
      "epoch:15 step:14372 [D loss: 0.650992, acc.: 62.50%] [G loss: 0.871853]\n",
      "epoch:15 step:14373 [D loss: 0.645692, acc.: 63.28%] [G loss: 0.919382]\n",
      "epoch:15 step:14374 [D loss: 0.674281, acc.: 58.59%] [G loss: 0.940851]\n",
      "epoch:15 step:14375 [D loss: 0.654882, acc.: 59.38%] [G loss: 0.867806]\n",
      "epoch:15 step:14376 [D loss: 0.674174, acc.: 55.47%] [G loss: 0.900387]\n",
      "epoch:15 step:14377 [D loss: 0.668842, acc.: 56.25%] [G loss: 0.830885]\n",
      "epoch:15 step:14378 [D loss: 0.671907, acc.: 60.16%] [G loss: 0.846285]\n",
      "epoch:15 step:14379 [D loss: 0.669551, acc.: 59.38%] [G loss: 0.835175]\n",
      "epoch:15 step:14380 [D loss: 0.655819, acc.: 59.38%] [G loss: 0.868877]\n",
      "epoch:15 step:14381 [D loss: 0.683847, acc.: 48.44%] [G loss: 0.827543]\n",
      "epoch:15 step:14382 [D loss: 0.635784, acc.: 58.59%] [G loss: 0.825598]\n",
      "epoch:15 step:14383 [D loss: 0.633929, acc.: 63.28%] [G loss: 0.835699]\n",
      "epoch:15 step:14384 [D loss: 0.682790, acc.: 50.78%] [G loss: 0.867477]\n",
      "epoch:15 step:14385 [D loss: 0.642838, acc.: 61.72%] [G loss: 0.861067]\n",
      "epoch:15 step:14386 [D loss: 0.699245, acc.: 52.34%] [G loss: 0.882489]\n",
      "epoch:15 step:14387 [D loss: 0.642630, acc.: 66.41%] [G loss: 0.807605]\n",
      "epoch:15 step:14388 [D loss: 0.683675, acc.: 51.56%] [G loss: 0.809609]\n",
      "epoch:15 step:14389 [D loss: 0.657060, acc.: 61.72%] [G loss: 0.843800]\n",
      "epoch:15 step:14390 [D loss: 0.709537, acc.: 47.66%] [G loss: 0.851461]\n",
      "epoch:15 step:14391 [D loss: 0.661752, acc.: 60.16%] [G loss: 0.824369]\n",
      "epoch:15 step:14392 [D loss: 0.688572, acc.: 49.22%] [G loss: 0.886317]\n",
      "epoch:15 step:14393 [D loss: 0.662825, acc.: 57.03%] [G loss: 0.895685]\n",
      "epoch:15 step:14394 [D loss: 0.655561, acc.: 57.81%] [G loss: 0.872182]\n",
      "epoch:15 step:14395 [D loss: 0.699439, acc.: 47.66%] [G loss: 0.885328]\n",
      "epoch:15 step:14396 [D loss: 0.675890, acc.: 58.59%] [G loss: 0.828514]\n",
      "epoch:15 step:14397 [D loss: 0.635622, acc.: 69.53%] [G loss: 0.865892]\n",
      "epoch:15 step:14398 [D loss: 0.690391, acc.: 57.81%] [G loss: 0.840433]\n",
      "epoch:15 step:14399 [D loss: 0.685103, acc.: 53.91%] [G loss: 0.865696]\n",
      "epoch:15 step:14400 [D loss: 0.666091, acc.: 61.72%] [G loss: 0.851700]\n",
      "##############\n",
      "[2.90700814 2.80241131 2.38988092 3.61517746 1.64221901 8.57988923\n",
      " 2.86891318 3.53625608 4.1341201  5.29858182]\n",
      "##########\n",
      "epoch:15 step:14401 [D loss: 0.686330, acc.: 53.91%] [G loss: 0.842693]\n",
      "epoch:15 step:14402 [D loss: 0.655880, acc.: 62.50%] [G loss: 0.850205]\n",
      "epoch:15 step:14403 [D loss: 0.679223, acc.: 59.38%] [G loss: 0.872414]\n",
      "epoch:15 step:14404 [D loss: 0.668972, acc.: 54.69%] [G loss: 0.881183]\n",
      "epoch:15 step:14405 [D loss: 0.651149, acc.: 60.94%] [G loss: 0.851649]\n",
      "epoch:15 step:14406 [D loss: 0.665927, acc.: 57.81%] [G loss: 0.855997]\n",
      "epoch:15 step:14407 [D loss: 0.648276, acc.: 64.84%] [G loss: 0.854728]\n",
      "epoch:15 step:14408 [D loss: 0.641469, acc.: 66.41%] [G loss: 0.890157]\n",
      "epoch:15 step:14409 [D loss: 0.706235, acc.: 50.78%] [G loss: 0.882724]\n",
      "epoch:15 step:14410 [D loss: 0.682426, acc.: 59.38%] [G loss: 0.865046]\n",
      "epoch:15 step:14411 [D loss: 0.660874, acc.: 57.03%] [G loss: 0.869648]\n",
      "epoch:15 step:14412 [D loss: 0.680457, acc.: 50.78%] [G loss: 0.843535]\n",
      "epoch:15 step:14413 [D loss: 0.661098, acc.: 60.94%] [G loss: 0.901768]\n",
      "epoch:15 step:14414 [D loss: 0.683928, acc.: 52.34%] [G loss: 0.836615]\n",
      "epoch:15 step:14415 [D loss: 0.630635, acc.: 68.75%] [G loss: 0.903525]\n",
      "epoch:15 step:14416 [D loss: 0.694809, acc.: 53.12%] [G loss: 0.853953]\n",
      "epoch:15 step:14417 [D loss: 0.667889, acc.: 64.06%] [G loss: 0.895917]\n",
      "epoch:15 step:14418 [D loss: 0.681508, acc.: 50.78%] [G loss: 0.859905]\n",
      "epoch:15 step:14419 [D loss: 0.689418, acc.: 53.12%] [G loss: 0.830958]\n",
      "epoch:15 step:14420 [D loss: 0.698447, acc.: 53.12%] [G loss: 0.834194]\n",
      "epoch:15 step:14421 [D loss: 0.672417, acc.: 54.69%] [G loss: 0.817808]\n",
      "epoch:15 step:14422 [D loss: 0.676579, acc.: 53.91%] [G loss: 0.807953]\n",
      "epoch:15 step:14423 [D loss: 0.655755, acc.: 58.59%] [G loss: 0.850647]\n",
      "epoch:15 step:14424 [D loss: 0.671206, acc.: 65.62%] [G loss: 0.822092]\n",
      "epoch:15 step:14425 [D loss: 0.660545, acc.: 60.16%] [G loss: 0.866533]\n",
      "epoch:15 step:14426 [D loss: 0.673656, acc.: 57.03%] [G loss: 0.833010]\n",
      "epoch:15 step:14427 [D loss: 0.648284, acc.: 60.94%] [G loss: 0.813034]\n",
      "epoch:15 step:14428 [D loss: 0.673884, acc.: 56.25%] [G loss: 0.837802]\n",
      "epoch:15 step:14429 [D loss: 0.660441, acc.: 62.50%] [G loss: 0.829068]\n",
      "epoch:15 step:14430 [D loss: 0.628254, acc.: 66.41%] [G loss: 0.830184]\n",
      "epoch:15 step:14431 [D loss: 0.684725, acc.: 58.59%] [G loss: 0.800627]\n",
      "epoch:15 step:14432 [D loss: 0.692228, acc.: 55.47%] [G loss: 0.834662]\n",
      "epoch:15 step:14433 [D loss: 0.629936, acc.: 65.62%] [G loss: 0.791867]\n",
      "epoch:15 step:14434 [D loss: 0.642599, acc.: 60.94%] [G loss: 0.825895]\n",
      "epoch:15 step:14435 [D loss: 0.684269, acc.: 59.38%] [G loss: 0.853276]\n",
      "epoch:15 step:14436 [D loss: 0.693027, acc.: 57.03%] [G loss: 0.852477]\n",
      "epoch:15 step:14437 [D loss: 0.659709, acc.: 57.03%] [G loss: 0.876552]\n",
      "epoch:15 step:14438 [D loss: 0.666908, acc.: 60.94%] [G loss: 0.870270]\n",
      "epoch:15 step:14439 [D loss: 0.694842, acc.: 52.34%] [G loss: 0.883628]\n",
      "epoch:15 step:14440 [D loss: 0.681260, acc.: 53.91%] [G loss: 0.857086]\n",
      "epoch:15 step:14441 [D loss: 0.669520, acc.: 54.69%] [G loss: 0.859651]\n",
      "epoch:15 step:14442 [D loss: 0.664964, acc.: 56.25%] [G loss: 0.876476]\n",
      "epoch:15 step:14443 [D loss: 0.681600, acc.: 50.78%] [G loss: 0.847682]\n",
      "epoch:15 step:14444 [D loss: 0.653695, acc.: 52.34%] [G loss: 0.865792]\n",
      "epoch:15 step:14445 [D loss: 0.665459, acc.: 62.50%] [G loss: 0.842585]\n",
      "epoch:15 step:14446 [D loss: 0.655193, acc.: 62.50%] [G loss: 0.850942]\n",
      "epoch:15 step:14447 [D loss: 0.665295, acc.: 56.25%] [G loss: 0.844833]\n",
      "epoch:15 step:14448 [D loss: 0.686822, acc.: 59.38%] [G loss: 0.845720]\n",
      "epoch:15 step:14449 [D loss: 0.680696, acc.: 55.47%] [G loss: 0.840446]\n",
      "epoch:15 step:14450 [D loss: 0.678703, acc.: 58.59%] [G loss: 0.807944]\n",
      "epoch:15 step:14451 [D loss: 0.689221, acc.: 53.12%] [G loss: 0.754416]\n",
      "epoch:15 step:14452 [D loss: 0.691205, acc.: 53.91%] [G loss: 0.867612]\n",
      "epoch:15 step:14453 [D loss: 0.679992, acc.: 59.38%] [G loss: 0.836871]\n",
      "epoch:15 step:14454 [D loss: 0.630234, acc.: 67.19%] [G loss: 0.835339]\n",
      "epoch:15 step:14455 [D loss: 0.624732, acc.: 67.19%] [G loss: 0.843492]\n",
      "epoch:15 step:14456 [D loss: 0.647791, acc.: 60.94%] [G loss: 0.818270]\n",
      "epoch:15 step:14457 [D loss: 0.638357, acc.: 60.94%] [G loss: 0.861132]\n",
      "epoch:15 step:14458 [D loss: 0.685616, acc.: 54.69%] [G loss: 0.863530]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14459 [D loss: 0.622921, acc.: 67.97%] [G loss: 0.930503]\n",
      "epoch:15 step:14460 [D loss: 0.662470, acc.: 58.59%] [G loss: 0.845782]\n",
      "epoch:15 step:14461 [D loss: 0.653819, acc.: 59.38%] [G loss: 0.878129]\n",
      "epoch:15 step:14462 [D loss: 0.630734, acc.: 66.41%] [G loss: 0.891373]\n",
      "epoch:15 step:14463 [D loss: 0.644162, acc.: 60.94%] [G loss: 0.865652]\n",
      "epoch:15 step:14464 [D loss: 0.655704, acc.: 63.28%] [G loss: 0.846205]\n",
      "epoch:15 step:14465 [D loss: 0.677688, acc.: 61.72%] [G loss: 0.842346]\n",
      "epoch:15 step:14466 [D loss: 0.654718, acc.: 57.03%] [G loss: 0.907110]\n",
      "epoch:15 step:14467 [D loss: 0.712395, acc.: 50.78%] [G loss: 0.854838]\n",
      "epoch:15 step:14468 [D loss: 0.694801, acc.: 56.25%] [G loss: 0.848534]\n",
      "epoch:15 step:14469 [D loss: 0.633204, acc.: 64.84%] [G loss: 0.862394]\n",
      "epoch:15 step:14470 [D loss: 0.719140, acc.: 55.47%] [G loss: 0.889758]\n",
      "epoch:15 step:14471 [D loss: 0.646338, acc.: 58.59%] [G loss: 0.855828]\n",
      "epoch:15 step:14472 [D loss: 0.633509, acc.: 64.84%] [G loss: 0.849560]\n",
      "epoch:15 step:14473 [D loss: 0.684147, acc.: 56.25%] [G loss: 0.837216]\n",
      "epoch:15 step:14474 [D loss: 0.664224, acc.: 56.25%] [G loss: 0.859353]\n",
      "epoch:15 step:14475 [D loss: 0.644754, acc.: 66.41%] [G loss: 0.865174]\n",
      "epoch:15 step:14476 [D loss: 0.641137, acc.: 67.97%] [G loss: 0.949806]\n",
      "epoch:15 step:14477 [D loss: 0.676913, acc.: 55.47%] [G loss: 0.930200]\n",
      "epoch:15 step:14478 [D loss: 0.612185, acc.: 69.53%] [G loss: 0.809209]\n",
      "epoch:15 step:14479 [D loss: 0.629949, acc.: 71.09%] [G loss: 0.892198]\n",
      "epoch:15 step:14480 [D loss: 0.647599, acc.: 64.06%] [G loss: 0.862909]\n",
      "epoch:15 step:14481 [D loss: 0.645662, acc.: 67.19%] [G loss: 0.822937]\n",
      "epoch:15 step:14482 [D loss: 0.701751, acc.: 53.91%] [G loss: 0.847946]\n",
      "epoch:15 step:14483 [D loss: 0.694646, acc.: 54.69%] [G loss: 0.818313]\n",
      "epoch:15 step:14484 [D loss: 0.652664, acc.: 61.72%] [G loss: 0.842939]\n",
      "epoch:15 step:14485 [D loss: 0.700712, acc.: 57.81%] [G loss: 0.873306]\n",
      "epoch:15 step:14486 [D loss: 0.655843, acc.: 59.38%] [G loss: 0.893198]\n",
      "epoch:15 step:14487 [D loss: 0.653364, acc.: 60.16%] [G loss: 0.911183]\n",
      "epoch:15 step:14488 [D loss: 0.657018, acc.: 61.72%] [G loss: 0.862904]\n",
      "epoch:15 step:14489 [D loss: 0.664780, acc.: 61.72%] [G loss: 0.856752]\n",
      "epoch:15 step:14490 [D loss: 0.673344, acc.: 57.03%] [G loss: 0.873324]\n",
      "epoch:15 step:14491 [D loss: 0.654494, acc.: 60.16%] [G loss: 0.864435]\n",
      "epoch:15 step:14492 [D loss: 0.679647, acc.: 57.81%] [G loss: 0.878943]\n",
      "epoch:15 step:14493 [D loss: 0.646514, acc.: 62.50%] [G loss: 0.910988]\n",
      "epoch:15 step:14494 [D loss: 0.643223, acc.: 57.81%] [G loss: 0.944693]\n",
      "epoch:15 step:14495 [D loss: 0.668507, acc.: 60.94%] [G loss: 0.861243]\n",
      "epoch:15 step:14496 [D loss: 0.722153, acc.: 55.47%] [G loss: 0.853051]\n",
      "epoch:15 step:14497 [D loss: 0.685214, acc.: 53.91%] [G loss: 0.825003]\n",
      "epoch:15 step:14498 [D loss: 0.651643, acc.: 67.19%] [G loss: 0.896803]\n",
      "epoch:15 step:14499 [D loss: 0.683578, acc.: 54.69%] [G loss: 0.871590]\n",
      "epoch:15 step:14500 [D loss: 0.633870, acc.: 61.72%] [G loss: 0.875922]\n",
      "epoch:15 step:14501 [D loss: 0.706937, acc.: 50.00%] [G loss: 0.846296]\n",
      "epoch:15 step:14502 [D loss: 0.673380, acc.: 60.94%] [G loss: 0.893391]\n",
      "epoch:15 step:14503 [D loss: 0.663056, acc.: 58.59%] [G loss: 0.841505]\n",
      "epoch:15 step:14504 [D loss: 0.667750, acc.: 56.25%] [G loss: 0.832063]\n",
      "epoch:15 step:14505 [D loss: 0.672916, acc.: 57.03%] [G loss: 0.865406]\n",
      "epoch:15 step:14506 [D loss: 0.655152, acc.: 61.72%] [G loss: 0.916485]\n",
      "epoch:15 step:14507 [D loss: 0.670013, acc.: 55.47%] [G loss: 0.899811]\n",
      "epoch:15 step:14508 [D loss: 0.685408, acc.: 56.25%] [G loss: 0.875204]\n",
      "epoch:15 step:14509 [D loss: 0.666035, acc.: 54.69%] [G loss: 0.878019]\n",
      "epoch:15 step:14510 [D loss: 0.657814, acc.: 63.28%] [G loss: 0.871891]\n",
      "epoch:15 step:14511 [D loss: 0.667605, acc.: 59.38%] [G loss: 0.877376]\n",
      "epoch:15 step:14512 [D loss: 0.677594, acc.: 53.12%] [G loss: 0.806253]\n",
      "epoch:15 step:14513 [D loss: 0.645798, acc.: 60.16%] [G loss: 0.836667]\n",
      "epoch:15 step:14514 [D loss: 0.616281, acc.: 66.41%] [G loss: 0.815796]\n",
      "epoch:15 step:14515 [D loss: 0.628304, acc.: 63.28%] [G loss: 0.865779]\n",
      "epoch:15 step:14516 [D loss: 0.732566, acc.: 48.44%] [G loss: 0.802248]\n",
      "epoch:15 step:14517 [D loss: 0.688111, acc.: 50.78%] [G loss: 0.895871]\n",
      "epoch:15 step:14518 [D loss: 0.684293, acc.: 53.12%] [G loss: 0.806331]\n",
      "epoch:15 step:14519 [D loss: 0.672560, acc.: 58.59%] [G loss: 0.816536]\n",
      "epoch:15 step:14520 [D loss: 0.680084, acc.: 57.03%] [G loss: 0.869158]\n",
      "epoch:15 step:14521 [D loss: 0.673578, acc.: 55.47%] [G loss: 0.867559]\n",
      "epoch:15 step:14522 [D loss: 0.694579, acc.: 55.47%] [G loss: 0.850648]\n",
      "epoch:15 step:14523 [D loss: 0.679492, acc.: 57.03%] [G loss: 0.796295]\n",
      "epoch:15 step:14524 [D loss: 0.664197, acc.: 52.34%] [G loss: 0.852023]\n",
      "epoch:15 step:14525 [D loss: 0.690301, acc.: 52.34%] [G loss: 0.794734]\n",
      "epoch:15 step:14526 [D loss: 0.648247, acc.: 64.84%] [G loss: 0.833013]\n",
      "epoch:15 step:14527 [D loss: 0.689038, acc.: 53.91%] [G loss: 0.841059]\n",
      "epoch:15 step:14528 [D loss: 0.678515, acc.: 60.16%] [G loss: 0.853564]\n",
      "epoch:15 step:14529 [D loss: 0.645852, acc.: 63.28%] [G loss: 0.872580]\n",
      "epoch:15 step:14530 [D loss: 0.650685, acc.: 61.72%] [G loss: 0.862512]\n",
      "epoch:15 step:14531 [D loss: 0.684530, acc.: 53.91%] [G loss: 0.806753]\n",
      "epoch:15 step:14532 [D loss: 0.688648, acc.: 50.78%] [G loss: 0.861134]\n",
      "epoch:15 step:14533 [D loss: 0.684689, acc.: 54.69%] [G loss: 0.838075]\n",
      "epoch:15 step:14534 [D loss: 0.644691, acc.: 62.50%] [G loss: 0.853476]\n",
      "epoch:15 step:14535 [D loss: 0.666741, acc.: 60.94%] [G loss: 0.850378]\n",
      "epoch:15 step:14536 [D loss: 0.668905, acc.: 57.03%] [G loss: 0.830976]\n",
      "epoch:15 step:14537 [D loss: 0.665768, acc.: 61.72%] [G loss: 0.831488]\n",
      "epoch:15 step:14538 [D loss: 0.715104, acc.: 46.88%] [G loss: 0.850230]\n",
      "epoch:15 step:14539 [D loss: 0.656505, acc.: 53.91%] [G loss: 0.888495]\n",
      "epoch:15 step:14540 [D loss: 0.674485, acc.: 55.47%] [G loss: 0.835339]\n",
      "epoch:15 step:14541 [D loss: 0.655521, acc.: 57.03%] [G loss: 0.831061]\n",
      "epoch:15 step:14542 [D loss: 0.650930, acc.: 58.59%] [G loss: 0.783959]\n",
      "epoch:15 step:14543 [D loss: 0.636070, acc.: 61.72%] [G loss: 0.787391]\n",
      "epoch:15 step:14544 [D loss: 0.673305, acc.: 62.50%] [G loss: 0.806274]\n",
      "epoch:15 step:14545 [D loss: 0.641973, acc.: 64.06%] [G loss: 0.846288]\n",
      "epoch:15 step:14546 [D loss: 0.639902, acc.: 66.41%] [G loss: 0.868405]\n",
      "epoch:15 step:14547 [D loss: 0.651847, acc.: 63.28%] [G loss: 0.855200]\n",
      "epoch:15 step:14548 [D loss: 0.673681, acc.: 62.50%] [G loss: 0.899282]\n",
      "epoch:15 step:14549 [D loss: 0.645540, acc.: 62.50%] [G loss: 0.889229]\n",
      "epoch:15 step:14550 [D loss: 0.679950, acc.: 53.91%] [G loss: 0.882618]\n",
      "epoch:15 step:14551 [D loss: 0.671358, acc.: 52.34%] [G loss: 0.832747]\n",
      "epoch:15 step:14552 [D loss: 0.657954, acc.: 64.06%] [G loss: 0.852900]\n",
      "epoch:15 step:14553 [D loss: 0.678603, acc.: 60.94%] [G loss: 0.909283]\n",
      "epoch:15 step:14554 [D loss: 0.670546, acc.: 59.38%] [G loss: 0.848471]\n",
      "epoch:15 step:14555 [D loss: 0.682930, acc.: 51.56%] [G loss: 0.861178]\n",
      "epoch:15 step:14556 [D loss: 0.636861, acc.: 64.06%] [G loss: 0.836926]\n",
      "epoch:15 step:14557 [D loss: 0.649968, acc.: 60.94%] [G loss: 0.846488]\n",
      "epoch:15 step:14558 [D loss: 0.661809, acc.: 63.28%] [G loss: 0.812467]\n",
      "epoch:15 step:14559 [D loss: 0.674553, acc.: 61.72%] [G loss: 0.874494]\n",
      "epoch:15 step:14560 [D loss: 0.659284, acc.: 60.16%] [G loss: 0.872604]\n",
      "epoch:15 step:14561 [D loss: 0.659999, acc.: 67.97%] [G loss: 0.848982]\n",
      "epoch:15 step:14562 [D loss: 0.665054, acc.: 57.81%] [G loss: 0.819378]\n",
      "epoch:15 step:14563 [D loss: 0.649174, acc.: 64.06%] [G loss: 0.849080]\n",
      "epoch:15 step:14564 [D loss: 0.656163, acc.: 62.50%] [G loss: 0.848361]\n",
      "epoch:15 step:14565 [D loss: 0.650833, acc.: 65.62%] [G loss: 0.887854]\n",
      "epoch:15 step:14566 [D loss: 0.637224, acc.: 59.38%] [G loss: 0.845986]\n",
      "epoch:15 step:14567 [D loss: 0.713982, acc.: 53.12%] [G loss: 0.872164]\n",
      "epoch:15 step:14568 [D loss: 0.651101, acc.: 61.72%] [G loss: 0.884219]\n",
      "epoch:15 step:14569 [D loss: 0.677155, acc.: 60.94%] [G loss: 0.855159]\n",
      "epoch:15 step:14570 [D loss: 0.679185, acc.: 53.12%] [G loss: 0.876718]\n",
      "epoch:15 step:14571 [D loss: 0.677967, acc.: 57.03%] [G loss: 0.877771]\n",
      "epoch:15 step:14572 [D loss: 0.660197, acc.: 59.38%] [G loss: 0.866690]\n",
      "epoch:15 step:14573 [D loss: 0.660360, acc.: 60.94%] [G loss: 0.882896]\n",
      "epoch:15 step:14574 [D loss: 0.641045, acc.: 62.50%] [G loss: 0.865715]\n",
      "epoch:15 step:14575 [D loss: 0.643941, acc.: 63.28%] [G loss: 0.877488]\n",
      "epoch:15 step:14576 [D loss: 0.675112, acc.: 59.38%] [G loss: 0.856009]\n",
      "epoch:15 step:14577 [D loss: 0.652108, acc.: 57.03%] [G loss: 0.920106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14578 [D loss: 0.659409, acc.: 57.81%] [G loss: 0.974793]\n",
      "epoch:15 step:14579 [D loss: 0.657717, acc.: 64.06%] [G loss: 0.956483]\n",
      "epoch:15 step:14580 [D loss: 0.684306, acc.: 57.03%] [G loss: 0.849734]\n",
      "epoch:15 step:14581 [D loss: 0.683684, acc.: 53.91%] [G loss: 0.881375]\n",
      "epoch:15 step:14582 [D loss: 0.703261, acc.: 49.22%] [G loss: 0.869494]\n",
      "epoch:15 step:14583 [D loss: 0.664872, acc.: 58.59%] [G loss: 0.906487]\n",
      "epoch:15 step:14584 [D loss: 0.649787, acc.: 60.94%] [G loss: 0.913580]\n",
      "epoch:15 step:14585 [D loss: 0.629026, acc.: 64.84%] [G loss: 0.897536]\n",
      "epoch:15 step:14586 [D loss: 0.659983, acc.: 59.38%] [G loss: 0.884978]\n",
      "epoch:15 step:14587 [D loss: 0.668548, acc.: 57.81%] [G loss: 0.889338]\n",
      "epoch:15 step:14588 [D loss: 0.686359, acc.: 53.12%] [G loss: 0.886148]\n",
      "epoch:15 step:14589 [D loss: 0.685920, acc.: 54.69%] [G loss: 0.827411]\n",
      "epoch:15 step:14590 [D loss: 0.631452, acc.: 64.84%] [G loss: 0.808533]\n",
      "epoch:15 step:14591 [D loss: 0.679297, acc.: 56.25%] [G loss: 0.830346]\n",
      "epoch:15 step:14592 [D loss: 0.712494, acc.: 50.00%] [G loss: 0.844079]\n",
      "epoch:15 step:14593 [D loss: 0.693412, acc.: 59.38%] [G loss: 0.831884]\n",
      "epoch:15 step:14594 [D loss: 0.644384, acc.: 65.62%] [G loss: 0.800978]\n",
      "epoch:15 step:14595 [D loss: 0.666942, acc.: 59.38%] [G loss: 0.835686]\n",
      "epoch:15 step:14596 [D loss: 0.655841, acc.: 60.94%] [G loss: 0.880775]\n",
      "epoch:15 step:14597 [D loss: 0.678690, acc.: 57.03%] [G loss: 0.876908]\n",
      "epoch:15 step:14598 [D loss: 0.648082, acc.: 60.16%] [G loss: 0.871157]\n",
      "epoch:15 step:14599 [D loss: 0.668965, acc.: 60.94%] [G loss: 0.871789]\n",
      "epoch:15 step:14600 [D loss: 0.669810, acc.: 59.38%] [G loss: 0.868044]\n",
      "##############\n",
      "[2.77776217 2.56816205 2.06673699 3.95894415 1.40064437 7.59538326\n",
      " 2.89352231 3.86708908 4.43214767 6.54045319]\n",
      "##########\n",
      "epoch:15 step:14601 [D loss: 0.645223, acc.: 67.19%] [G loss: 0.842650]\n",
      "epoch:15 step:14602 [D loss: 0.660836, acc.: 57.03%] [G loss: 0.863888]\n",
      "epoch:15 step:14603 [D loss: 0.689081, acc.: 60.94%] [G loss: 0.836090]\n",
      "epoch:15 step:14604 [D loss: 0.696183, acc.: 54.69%] [G loss: 0.822727]\n",
      "epoch:15 step:14605 [D loss: 0.648214, acc.: 63.28%] [G loss: 0.830407]\n",
      "epoch:15 step:14606 [D loss: 0.672905, acc.: 60.16%] [G loss: 0.847346]\n",
      "epoch:15 step:14607 [D loss: 0.656465, acc.: 55.47%] [G loss: 0.837544]\n",
      "epoch:15 step:14608 [D loss: 0.670644, acc.: 57.03%] [G loss: 0.879694]\n",
      "epoch:15 step:14609 [D loss: 0.657578, acc.: 61.72%] [G loss: 0.906515]\n",
      "epoch:15 step:14610 [D loss: 0.636822, acc.: 64.84%] [G loss: 0.838190]\n",
      "epoch:15 step:14611 [D loss: 0.655249, acc.: 61.72%] [G loss: 0.823774]\n",
      "epoch:15 step:14612 [D loss: 0.658007, acc.: 58.59%] [G loss: 0.823753]\n",
      "epoch:15 step:14613 [D loss: 0.646781, acc.: 67.19%] [G loss: 0.778605]\n",
      "epoch:15 step:14614 [D loss: 0.676936, acc.: 56.25%] [G loss: 0.807829]\n",
      "epoch:15 step:14615 [D loss: 0.688430, acc.: 53.91%] [G loss: 0.809203]\n",
      "epoch:15 step:14616 [D loss: 0.641288, acc.: 60.16%] [G loss: 0.843951]\n",
      "epoch:15 step:14617 [D loss: 0.714645, acc.: 46.88%] [G loss: 0.844995]\n",
      "epoch:15 step:14618 [D loss: 0.666859, acc.: 62.50%] [G loss: 0.860994]\n",
      "epoch:15 step:14619 [D loss: 0.661007, acc.: 58.59%] [G loss: 0.872995]\n",
      "epoch:15 step:14620 [D loss: 0.671157, acc.: 54.69%] [G loss: 0.890783]\n",
      "epoch:15 step:14621 [D loss: 0.636601, acc.: 64.06%] [G loss: 0.875709]\n",
      "epoch:15 step:14622 [D loss: 0.637645, acc.: 65.62%] [G loss: 0.893352]\n",
      "epoch:15 step:14623 [D loss: 0.692128, acc.: 55.47%] [G loss: 0.976799]\n",
      "epoch:15 step:14624 [D loss: 0.668886, acc.: 60.16%] [G loss: 0.900365]\n",
      "epoch:15 step:14625 [D loss: 0.679772, acc.: 59.38%] [G loss: 0.832754]\n",
      "epoch:15 step:14626 [D loss: 0.653409, acc.: 60.94%] [G loss: 0.837895]\n",
      "epoch:15 step:14627 [D loss: 0.704713, acc.: 54.69%] [G loss: 0.780382]\n",
      "epoch:15 step:14628 [D loss: 0.704971, acc.: 55.47%] [G loss: 0.795525]\n",
      "epoch:15 step:14629 [D loss: 0.669777, acc.: 55.47%] [G loss: 0.825130]\n",
      "epoch:15 step:14630 [D loss: 0.683786, acc.: 55.47%] [G loss: 0.801543]\n",
      "epoch:15 step:14631 [D loss: 0.679590, acc.: 57.81%] [G loss: 0.847881]\n",
      "epoch:15 step:14632 [D loss: 0.661019, acc.: 61.72%] [G loss: 0.851240]\n",
      "epoch:15 step:14633 [D loss: 0.670296, acc.: 65.62%] [G loss: 0.865259]\n",
      "epoch:15 step:14634 [D loss: 0.665629, acc.: 57.81%] [G loss: 0.913822]\n",
      "epoch:15 step:14635 [D loss: 0.685757, acc.: 50.78%] [G loss: 0.860164]\n",
      "epoch:15 step:14636 [D loss: 0.671405, acc.: 57.81%] [G loss: 0.893987]\n",
      "epoch:15 step:14637 [D loss: 0.637320, acc.: 66.41%] [G loss: 0.873123]\n",
      "epoch:15 step:14638 [D loss: 0.685811, acc.: 57.81%] [G loss: 0.908384]\n",
      "epoch:15 step:14639 [D loss: 0.647567, acc.: 62.50%] [G loss: 0.883451]\n",
      "epoch:15 step:14640 [D loss: 0.658173, acc.: 59.38%] [G loss: 0.851665]\n",
      "epoch:15 step:14641 [D loss: 0.650592, acc.: 60.94%] [G loss: 0.831192]\n",
      "epoch:15 step:14642 [D loss: 0.687834, acc.: 52.34%] [G loss: 0.877904]\n",
      "epoch:15 step:14643 [D loss: 0.693934, acc.: 56.25%] [G loss: 0.835644]\n",
      "epoch:15 step:14644 [D loss: 0.649516, acc.: 61.72%] [G loss: 0.848993]\n",
      "epoch:15 step:14645 [D loss: 0.641851, acc.: 60.16%] [G loss: 0.804302]\n",
      "epoch:15 step:14646 [D loss: 0.689267, acc.: 59.38%] [G loss: 0.822762]\n",
      "epoch:15 step:14647 [D loss: 0.668640, acc.: 58.59%] [G loss: 0.819323]\n",
      "epoch:15 step:14648 [D loss: 0.689073, acc.: 56.25%] [G loss: 0.869781]\n",
      "epoch:15 step:14649 [D loss: 0.658021, acc.: 60.94%] [G loss: 0.864759]\n",
      "epoch:15 step:14650 [D loss: 0.682500, acc.: 57.81%] [G loss: 0.874619]\n",
      "epoch:15 step:14651 [D loss: 0.675530, acc.: 60.16%] [G loss: 0.892619]\n",
      "epoch:15 step:14652 [D loss: 0.647349, acc.: 63.28%] [G loss: 0.880269]\n",
      "epoch:15 step:14653 [D loss: 0.679824, acc.: 57.03%] [G loss: 0.908328]\n",
      "epoch:15 step:14654 [D loss: 0.644358, acc.: 63.28%] [G loss: 0.873262]\n",
      "epoch:15 step:14655 [D loss: 0.661178, acc.: 52.34%] [G loss: 0.889655]\n",
      "epoch:15 step:14656 [D loss: 0.663886, acc.: 55.47%] [G loss: 0.900408]\n",
      "epoch:15 step:14657 [D loss: 0.636632, acc.: 67.97%] [G loss: 0.893818]\n",
      "epoch:15 step:14658 [D loss: 0.683019, acc.: 51.56%] [G loss: 0.854788]\n",
      "epoch:15 step:14659 [D loss: 0.699142, acc.: 55.47%] [G loss: 0.852692]\n",
      "epoch:15 step:14660 [D loss: 0.662338, acc.: 63.28%] [G loss: 0.839911]\n",
      "epoch:15 step:14661 [D loss: 0.664165, acc.: 63.28%] [G loss: 0.831502]\n",
      "epoch:15 step:14662 [D loss: 0.663329, acc.: 62.50%] [G loss: 0.865272]\n",
      "epoch:15 step:14663 [D loss: 0.650470, acc.: 62.50%] [G loss: 0.824941]\n",
      "epoch:15 step:14664 [D loss: 0.627094, acc.: 73.44%] [G loss: 0.836819]\n",
      "epoch:15 step:14665 [D loss: 0.658414, acc.: 62.50%] [G loss: 0.855840]\n",
      "epoch:15 step:14666 [D loss: 0.644036, acc.: 64.06%] [G loss: 0.835754]\n",
      "epoch:15 step:14667 [D loss: 0.645955, acc.: 60.16%] [G loss: 0.801293]\n",
      "epoch:15 step:14668 [D loss: 0.635926, acc.: 67.97%] [G loss: 0.865329]\n",
      "epoch:15 step:14669 [D loss: 0.685850, acc.: 57.81%] [G loss: 0.869400]\n",
      "epoch:15 step:14670 [D loss: 0.669756, acc.: 64.06%] [G loss: 0.900974]\n",
      "epoch:15 step:14671 [D loss: 0.635742, acc.: 64.84%] [G loss: 0.895841]\n",
      "epoch:15 step:14672 [D loss: 0.664131, acc.: 64.84%] [G loss: 0.863667]\n",
      "epoch:15 step:14673 [D loss: 0.675527, acc.: 56.25%] [G loss: 0.888839]\n",
      "epoch:15 step:14674 [D loss: 0.702620, acc.: 55.47%] [G loss: 0.893662]\n",
      "epoch:15 step:14675 [D loss: 0.673732, acc.: 57.03%] [G loss: 0.807267]\n",
      "epoch:15 step:14676 [D loss: 0.674442, acc.: 57.81%] [G loss: 0.807063]\n",
      "epoch:15 step:14677 [D loss: 0.673109, acc.: 60.94%] [G loss: 0.822969]\n",
      "epoch:15 step:14678 [D loss: 0.659075, acc.: 58.59%] [G loss: 0.852277]\n",
      "epoch:15 step:14679 [D loss: 0.667560, acc.: 58.59%] [G loss: 0.883573]\n",
      "epoch:15 step:14680 [D loss: 0.646044, acc.: 65.62%] [G loss: 0.879367]\n",
      "epoch:15 step:14681 [D loss: 0.664258, acc.: 57.81%] [G loss: 0.863625]\n",
      "epoch:15 step:14682 [D loss: 0.631901, acc.: 64.84%] [G loss: 0.835861]\n",
      "epoch:15 step:14683 [D loss: 0.645008, acc.: 62.50%] [G loss: 0.835366]\n",
      "epoch:15 step:14684 [D loss: 0.657362, acc.: 60.16%] [G loss: 0.789280]\n",
      "epoch:15 step:14685 [D loss: 0.707507, acc.: 49.22%] [G loss: 0.836933]\n",
      "epoch:15 step:14686 [D loss: 0.667759, acc.: 59.38%] [G loss: 0.807588]\n",
      "epoch:15 step:14687 [D loss: 0.644461, acc.: 65.62%] [G loss: 0.844320]\n",
      "epoch:15 step:14688 [D loss: 0.640439, acc.: 65.62%] [G loss: 0.872336]\n",
      "epoch:15 step:14689 [D loss: 0.665599, acc.: 63.28%] [G loss: 0.842827]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14690 [D loss: 0.653252, acc.: 60.94%] [G loss: 0.861172]\n",
      "epoch:15 step:14691 [D loss: 0.626200, acc.: 66.41%] [G loss: 0.908551]\n",
      "epoch:15 step:14692 [D loss: 0.650705, acc.: 59.38%] [G loss: 0.887136]\n",
      "epoch:15 step:14693 [D loss: 0.662360, acc.: 60.16%] [G loss: 0.826408]\n",
      "epoch:15 step:14694 [D loss: 0.696647, acc.: 57.03%] [G loss: 0.823346]\n",
      "epoch:15 step:14695 [D loss: 0.655134, acc.: 64.06%] [G loss: 0.882712]\n",
      "epoch:15 step:14696 [D loss: 0.680221, acc.: 62.50%] [G loss: 0.850906]\n",
      "epoch:15 step:14697 [D loss: 0.665939, acc.: 57.81%] [G loss: 0.879287]\n",
      "epoch:15 step:14698 [D loss: 0.723436, acc.: 53.91%] [G loss: 0.900626]\n",
      "epoch:15 step:14699 [D loss: 0.657163, acc.: 59.38%] [G loss: 0.823136]\n",
      "epoch:15 step:14700 [D loss: 0.667551, acc.: 60.16%] [G loss: 0.840319]\n",
      "epoch:15 step:14701 [D loss: 0.685407, acc.: 56.25%] [G loss: 0.879958]\n",
      "epoch:15 step:14702 [D loss: 0.666366, acc.: 58.59%] [G loss: 0.843937]\n",
      "epoch:15 step:14703 [D loss: 0.667850, acc.: 58.59%] [G loss: 0.864435]\n",
      "epoch:15 step:14704 [D loss: 0.652857, acc.: 60.16%] [G loss: 0.835796]\n",
      "epoch:15 step:14705 [D loss: 0.640752, acc.: 65.62%] [G loss: 0.844323]\n",
      "epoch:15 step:14706 [D loss: 0.713822, acc.: 54.69%] [G loss: 0.874140]\n",
      "epoch:15 step:14707 [D loss: 0.656942, acc.: 63.28%] [G loss: 0.849488]\n",
      "epoch:15 step:14708 [D loss: 0.675761, acc.: 53.91%] [G loss: 0.867594]\n",
      "epoch:15 step:14709 [D loss: 0.654032, acc.: 67.19%] [G loss: 0.831191]\n",
      "epoch:15 step:14710 [D loss: 0.727145, acc.: 48.44%] [G loss: 0.867800]\n",
      "epoch:15 step:14711 [D loss: 0.652374, acc.: 61.72%] [G loss: 0.814614]\n",
      "epoch:15 step:14712 [D loss: 0.693980, acc.: 52.34%] [G loss: 0.860673]\n",
      "epoch:15 step:14713 [D loss: 0.706457, acc.: 50.78%] [G loss: 0.814878]\n",
      "epoch:15 step:14714 [D loss: 0.652759, acc.: 58.59%] [G loss: 0.851518]\n",
      "epoch:15 step:14715 [D loss: 0.658962, acc.: 62.50%] [G loss: 0.795730]\n",
      "epoch:15 step:14716 [D loss: 0.639616, acc.: 62.50%] [G loss: 0.831678]\n",
      "epoch:15 step:14717 [D loss: 0.695517, acc.: 56.25%] [G loss: 0.841295]\n",
      "epoch:15 step:14718 [D loss: 0.663248, acc.: 62.50%] [G loss: 0.831215]\n",
      "epoch:15 step:14719 [D loss: 0.685723, acc.: 60.94%] [G loss: 0.787705]\n",
      "epoch:15 step:14720 [D loss: 0.697744, acc.: 54.69%] [G loss: 0.798839]\n",
      "epoch:15 step:14721 [D loss: 0.638919, acc.: 66.41%] [G loss: 0.819586]\n",
      "epoch:15 step:14722 [D loss: 0.678250, acc.: 51.56%] [G loss: 0.823936]\n",
      "epoch:15 step:14723 [D loss: 0.645165, acc.: 61.72%] [G loss: 0.817903]\n",
      "epoch:15 step:14724 [D loss: 0.644742, acc.: 63.28%] [G loss: 0.802284]\n",
      "epoch:15 step:14725 [D loss: 0.640976, acc.: 64.06%] [G loss: 0.810299]\n",
      "epoch:15 step:14726 [D loss: 0.705215, acc.: 52.34%] [G loss: 0.877395]\n",
      "epoch:15 step:14727 [D loss: 0.694292, acc.: 49.22%] [G loss: 0.796745]\n",
      "epoch:15 step:14728 [D loss: 0.666051, acc.: 59.38%] [G loss: 0.877323]\n",
      "epoch:15 step:14729 [D loss: 0.647801, acc.: 63.28%] [G loss: 0.850296]\n",
      "epoch:15 step:14730 [D loss: 0.686053, acc.: 53.91%] [G loss: 0.831753]\n",
      "epoch:15 step:14731 [D loss: 0.693065, acc.: 53.12%] [G loss: 0.786722]\n",
      "epoch:15 step:14732 [D loss: 0.712698, acc.: 45.31%] [G loss: 0.838868]\n",
      "epoch:15 step:14733 [D loss: 0.649985, acc.: 59.38%] [G loss: 0.849222]\n",
      "epoch:15 step:14734 [D loss: 0.666457, acc.: 60.16%] [G loss: 0.832240]\n",
      "epoch:15 step:14735 [D loss: 0.686920, acc.: 57.81%] [G loss: 0.804518]\n",
      "epoch:15 step:14736 [D loss: 0.683068, acc.: 58.59%] [G loss: 0.824515]\n",
      "epoch:15 step:14737 [D loss: 0.623828, acc.: 66.41%] [G loss: 0.850637]\n",
      "epoch:15 step:14738 [D loss: 0.638535, acc.: 63.28%] [G loss: 0.877479]\n",
      "epoch:15 step:14739 [D loss: 0.644690, acc.: 64.84%] [G loss: 0.842431]\n",
      "epoch:15 step:14740 [D loss: 0.661141, acc.: 56.25%] [G loss: 0.838241]\n",
      "epoch:15 step:14741 [D loss: 0.640075, acc.: 69.53%] [G loss: 0.909010]\n",
      "epoch:15 step:14742 [D loss: 0.615203, acc.: 68.75%] [G loss: 0.897121]\n",
      "epoch:15 step:14743 [D loss: 0.635773, acc.: 63.28%] [G loss: 0.891888]\n",
      "epoch:15 step:14744 [D loss: 0.676531, acc.: 59.38%] [G loss: 0.850114]\n",
      "epoch:15 step:14745 [D loss: 0.664833, acc.: 56.25%] [G loss: 0.876817]\n",
      "epoch:15 step:14746 [D loss: 0.705088, acc.: 50.78%] [G loss: 0.846915]\n",
      "epoch:15 step:14747 [D loss: 0.683761, acc.: 53.91%] [G loss: 0.859170]\n",
      "epoch:15 step:14748 [D loss: 0.645901, acc.: 64.84%] [G loss: 0.941595]\n",
      "epoch:15 step:14749 [D loss: 0.654248, acc.: 59.38%] [G loss: 0.879144]\n",
      "epoch:15 step:14750 [D loss: 0.649660, acc.: 63.28%] [G loss: 0.858882]\n",
      "epoch:15 step:14751 [D loss: 0.674444, acc.: 50.00%] [G loss: 0.886960]\n",
      "epoch:15 step:14752 [D loss: 0.627856, acc.: 64.06%] [G loss: 0.858835]\n",
      "epoch:15 step:14753 [D loss: 0.643227, acc.: 64.06%] [G loss: 0.875275]\n",
      "epoch:15 step:14754 [D loss: 0.665476, acc.: 60.16%] [G loss: 0.843330]\n",
      "epoch:15 step:14755 [D loss: 0.678843, acc.: 51.56%] [G loss: 0.794137]\n",
      "epoch:15 step:14756 [D loss: 0.658824, acc.: 57.81%] [G loss: 0.815416]\n",
      "epoch:15 step:14757 [D loss: 0.646323, acc.: 60.94%] [G loss: 0.838415]\n",
      "epoch:15 step:14758 [D loss: 0.665804, acc.: 58.59%] [G loss: 0.801249]\n",
      "epoch:15 step:14759 [D loss: 0.694733, acc.: 53.91%] [G loss: 0.821126]\n",
      "epoch:15 step:14760 [D loss: 0.650045, acc.: 61.72%] [G loss: 0.834020]\n",
      "epoch:15 step:14761 [D loss: 0.670597, acc.: 60.94%] [G loss: 0.807336]\n",
      "epoch:15 step:14762 [D loss: 0.672919, acc.: 55.47%] [G loss: 0.831784]\n",
      "epoch:15 step:14763 [D loss: 0.652762, acc.: 62.50%] [G loss: 0.885602]\n",
      "epoch:15 step:14764 [D loss: 0.665862, acc.: 60.16%] [G loss: 0.864369]\n",
      "epoch:15 step:14765 [D loss: 0.652119, acc.: 56.25%] [G loss: 0.864371]\n",
      "epoch:15 step:14766 [D loss: 0.654546, acc.: 63.28%] [G loss: 0.823530]\n",
      "epoch:15 step:14767 [D loss: 0.689017, acc.: 52.34%] [G loss: 0.875037]\n",
      "epoch:15 step:14768 [D loss: 0.672791, acc.: 56.25%] [G loss: 0.843159]\n",
      "epoch:15 step:14769 [D loss: 0.717350, acc.: 53.91%] [G loss: 0.852683]\n",
      "epoch:15 step:14770 [D loss: 0.703594, acc.: 50.00%] [G loss: 0.875128]\n",
      "epoch:15 step:14771 [D loss: 0.709064, acc.: 53.91%] [G loss: 0.839854]\n",
      "epoch:15 step:14772 [D loss: 0.630080, acc.: 67.19%] [G loss: 0.838911]\n",
      "epoch:15 step:14773 [D loss: 0.658492, acc.: 59.38%] [G loss: 0.914204]\n",
      "epoch:15 step:14774 [D loss: 0.671262, acc.: 59.38%] [G loss: 0.887105]\n",
      "epoch:15 step:14775 [D loss: 0.675232, acc.: 58.59%] [G loss: 0.854266]\n",
      "epoch:15 step:14776 [D loss: 0.676377, acc.: 55.47%] [G loss: 0.874775]\n",
      "epoch:15 step:14777 [D loss: 0.651472, acc.: 56.25%] [G loss: 0.859626]\n",
      "epoch:15 step:14778 [D loss: 0.647087, acc.: 63.28%] [G loss: 0.862109]\n",
      "epoch:15 step:14779 [D loss: 0.681327, acc.: 59.38%] [G loss: 0.848496]\n",
      "epoch:15 step:14780 [D loss: 0.662939, acc.: 57.81%] [G loss: 0.855500]\n",
      "epoch:15 step:14781 [D loss: 0.634282, acc.: 66.41%] [G loss: 0.903196]\n",
      "epoch:15 step:14782 [D loss: 0.631046, acc.: 65.62%] [G loss: 0.828935]\n",
      "epoch:15 step:14783 [D loss: 0.698450, acc.: 49.22%] [G loss: 0.859562]\n",
      "epoch:15 step:14784 [D loss: 0.616614, acc.: 69.53%] [G loss: 0.865905]\n",
      "epoch:15 step:14785 [D loss: 0.659429, acc.: 55.47%] [G loss: 0.862012]\n",
      "epoch:15 step:14786 [D loss: 0.703598, acc.: 54.69%] [G loss: 0.884067]\n",
      "epoch:15 step:14787 [D loss: 0.634801, acc.: 67.97%] [G loss: 0.922234]\n",
      "epoch:15 step:14788 [D loss: 0.649867, acc.: 59.38%] [G loss: 0.869619]\n",
      "epoch:15 step:14789 [D loss: 0.648784, acc.: 57.81%] [G loss: 0.886248]\n",
      "epoch:15 step:14790 [D loss: 0.670716, acc.: 60.16%] [G loss: 0.882472]\n",
      "epoch:15 step:14791 [D loss: 0.631962, acc.: 66.41%] [G loss: 0.866828]\n",
      "epoch:15 step:14792 [D loss: 0.675127, acc.: 53.12%] [G loss: 0.870141]\n",
      "epoch:15 step:14793 [D loss: 0.687459, acc.: 49.22%] [G loss: 0.841212]\n",
      "epoch:15 step:14794 [D loss: 0.701158, acc.: 50.78%] [G loss: 0.872640]\n",
      "epoch:15 step:14795 [D loss: 0.697895, acc.: 53.12%] [G loss: 0.882252]\n",
      "epoch:15 step:14796 [D loss: 0.663539, acc.: 58.59%] [G loss: 0.940197]\n",
      "epoch:15 step:14797 [D loss: 0.648450, acc.: 61.72%] [G loss: 0.871209]\n",
      "epoch:15 step:14798 [D loss: 0.683240, acc.: 51.56%] [G loss: 0.872522]\n",
      "epoch:15 step:14799 [D loss: 0.668213, acc.: 59.38%] [G loss: 0.851689]\n",
      "epoch:15 step:14800 [D loss: 0.645572, acc.: 63.28%] [G loss: 0.853112]\n",
      "##############\n",
      "[2.95306373 2.68116726 2.39064989 4.12862627 1.24623297 8.04984802\n",
      " 2.61382774 3.65513766 4.28771512 8.14868929]\n",
      "##########\n",
      "epoch:15 step:14801 [D loss: 0.644299, acc.: 64.06%] [G loss: 0.798756]\n",
      "epoch:15 step:14802 [D loss: 0.626416, acc.: 67.19%] [G loss: 0.814682]\n",
      "epoch:15 step:14803 [D loss: 0.661059, acc.: 58.59%] [G loss: 0.843052]\n",
      "epoch:15 step:14804 [D loss: 0.678734, acc.: 60.94%] [G loss: 0.820454]\n",
      "epoch:15 step:14805 [D loss: 0.658658, acc.: 66.41%] [G loss: 0.867692]\n",
      "epoch:15 step:14806 [D loss: 0.649223, acc.: 62.50%] [G loss: 0.889565]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14807 [D loss: 0.680699, acc.: 55.47%] [G loss: 0.912121]\n",
      "epoch:15 step:14808 [D loss: 0.641995, acc.: 64.84%] [G loss: 0.898893]\n",
      "epoch:15 step:14809 [D loss: 0.638993, acc.: 60.94%] [G loss: 0.865553]\n",
      "epoch:15 step:14810 [D loss: 0.683647, acc.: 57.03%] [G loss: 0.872427]\n",
      "epoch:15 step:14811 [D loss: 0.636350, acc.: 68.75%] [G loss: 0.901395]\n",
      "epoch:15 step:14812 [D loss: 0.625346, acc.: 68.75%] [G loss: 0.892882]\n",
      "epoch:15 step:14813 [D loss: 0.688554, acc.: 60.16%] [G loss: 0.849730]\n",
      "epoch:15 step:14814 [D loss: 0.648965, acc.: 63.28%] [G loss: 0.858630]\n",
      "epoch:15 step:14815 [D loss: 0.643254, acc.: 60.16%] [G loss: 0.896431]\n",
      "epoch:15 step:14816 [D loss: 0.691372, acc.: 52.34%] [G loss: 0.919930]\n",
      "epoch:15 step:14817 [D loss: 0.684181, acc.: 58.59%] [G loss: 0.890976]\n",
      "epoch:15 step:14818 [D loss: 0.691092, acc.: 55.47%] [G loss: 0.894078]\n",
      "epoch:15 step:14819 [D loss: 0.629756, acc.: 65.62%] [G loss: 0.854739]\n",
      "epoch:15 step:14820 [D loss: 0.652051, acc.: 62.50%] [G loss: 0.830161]\n",
      "epoch:15 step:14821 [D loss: 0.687906, acc.: 57.03%] [G loss: 0.833020]\n",
      "epoch:15 step:14822 [D loss: 0.660877, acc.: 60.16%] [G loss: 0.833646]\n",
      "epoch:15 step:14823 [D loss: 0.659689, acc.: 57.81%] [G loss: 0.820910]\n",
      "epoch:15 step:14824 [D loss: 0.657749, acc.: 61.72%] [G loss: 0.828609]\n",
      "epoch:15 step:14825 [D loss: 0.711314, acc.: 51.56%] [G loss: 0.848368]\n",
      "epoch:15 step:14826 [D loss: 0.657992, acc.: 64.84%] [G loss: 0.857951]\n",
      "epoch:15 step:14827 [D loss: 0.672812, acc.: 59.38%] [G loss: 0.810758]\n",
      "epoch:15 step:14828 [D loss: 0.693762, acc.: 50.00%] [G loss: 0.853966]\n",
      "epoch:15 step:14829 [D loss: 0.632020, acc.: 63.28%] [G loss: 0.855197]\n",
      "epoch:15 step:14830 [D loss: 0.681626, acc.: 56.25%] [G loss: 0.875848]\n",
      "epoch:15 step:14831 [D loss: 0.671900, acc.: 60.94%] [G loss: 0.880038]\n",
      "epoch:15 step:14832 [D loss: 0.670674, acc.: 57.81%] [G loss: 0.850827]\n",
      "epoch:15 step:14833 [D loss: 0.632571, acc.: 67.19%] [G loss: 0.934460]\n",
      "epoch:15 step:14834 [D loss: 0.632947, acc.: 62.50%] [G loss: 0.883626]\n",
      "epoch:15 step:14835 [D loss: 0.699813, acc.: 57.03%] [G loss: 0.853421]\n",
      "epoch:15 step:14836 [D loss: 0.707047, acc.: 54.69%] [G loss: 0.868630]\n",
      "epoch:15 step:14837 [D loss: 0.637371, acc.: 62.50%] [G loss: 0.856386]\n",
      "epoch:15 step:14838 [D loss: 0.659466, acc.: 57.81%] [G loss: 0.887204]\n",
      "epoch:15 step:14839 [D loss: 0.667543, acc.: 54.69%] [G loss: 0.888465]\n",
      "epoch:15 step:14840 [D loss: 0.673104, acc.: 53.91%] [G loss: 0.823240]\n",
      "epoch:15 step:14841 [D loss: 0.676482, acc.: 61.72%] [G loss: 0.834775]\n",
      "epoch:15 step:14842 [D loss: 0.682544, acc.: 59.38%] [G loss: 0.855566]\n",
      "epoch:15 step:14843 [D loss: 0.645472, acc.: 65.62%] [G loss: 0.848463]\n",
      "epoch:15 step:14844 [D loss: 0.651319, acc.: 65.62%] [G loss: 0.893931]\n",
      "epoch:15 step:14845 [D loss: 0.644593, acc.: 59.38%] [G loss: 0.834830]\n",
      "epoch:15 step:14846 [D loss: 0.631068, acc.: 63.28%] [G loss: 0.870848]\n",
      "epoch:15 step:14847 [D loss: 0.666107, acc.: 60.16%] [G loss: 0.877808]\n",
      "epoch:15 step:14848 [D loss: 0.628832, acc.: 62.50%] [G loss: 0.887781]\n",
      "epoch:15 step:14849 [D loss: 0.639112, acc.: 64.84%] [G loss: 0.899361]\n",
      "epoch:15 step:14850 [D loss: 0.660467, acc.: 57.81%] [G loss: 0.834306]\n",
      "epoch:15 step:14851 [D loss: 0.690399, acc.: 55.47%] [G loss: 0.875069]\n",
      "epoch:15 step:14852 [D loss: 0.650615, acc.: 60.94%] [G loss: 0.855084]\n",
      "epoch:15 step:14853 [D loss: 0.637485, acc.: 65.62%] [G loss: 0.877483]\n",
      "epoch:15 step:14854 [D loss: 0.680759, acc.: 57.03%] [G loss: 0.835890]\n",
      "epoch:15 step:14855 [D loss: 0.669137, acc.: 56.25%] [G loss: 0.886642]\n",
      "epoch:15 step:14856 [D loss: 0.640819, acc.: 64.06%] [G loss: 0.884620]\n",
      "epoch:15 step:14857 [D loss: 0.681842, acc.: 55.47%] [G loss: 0.883885]\n",
      "epoch:15 step:14858 [D loss: 0.702605, acc.: 51.56%] [G loss: 0.832421]\n",
      "epoch:15 step:14859 [D loss: 0.707249, acc.: 50.78%] [G loss: 0.814739]\n",
      "epoch:15 step:14860 [D loss: 0.689020, acc.: 55.47%] [G loss: 0.791658]\n",
      "epoch:15 step:14861 [D loss: 0.681855, acc.: 60.94%] [G loss: 0.914057]\n",
      "epoch:15 step:14862 [D loss: 0.646845, acc.: 58.59%] [G loss: 0.839742]\n",
      "epoch:15 step:14863 [D loss: 0.693245, acc.: 53.91%] [G loss: 0.869490]\n",
      "epoch:15 step:14864 [D loss: 0.656449, acc.: 53.91%] [G loss: 0.925961]\n",
      "epoch:15 step:14865 [D loss: 0.634718, acc.: 63.28%] [G loss: 0.827276]\n",
      "epoch:15 step:14866 [D loss: 0.650113, acc.: 58.59%] [G loss: 0.836812]\n",
      "epoch:15 step:14867 [D loss: 0.661230, acc.: 59.38%] [G loss: 0.840544]\n",
      "epoch:15 step:14868 [D loss: 0.691998, acc.: 53.91%] [G loss: 0.842771]\n",
      "epoch:15 step:14869 [D loss: 0.654362, acc.: 62.50%] [G loss: 0.819970]\n",
      "epoch:15 step:14870 [D loss: 0.669299, acc.: 58.59%] [G loss: 0.876658]\n",
      "epoch:15 step:14871 [D loss: 0.646163, acc.: 57.81%] [G loss: 0.832760]\n",
      "epoch:15 step:14872 [D loss: 0.700479, acc.: 59.38%] [G loss: 0.895080]\n",
      "epoch:15 step:14873 [D loss: 0.668500, acc.: 60.94%] [G loss: 0.880060]\n",
      "epoch:15 step:14874 [D loss: 0.687686, acc.: 54.69%] [G loss: 0.900903]\n",
      "epoch:15 step:14875 [D loss: 0.685663, acc.: 55.47%] [G loss: 0.866841]\n",
      "epoch:15 step:14876 [D loss: 0.659901, acc.: 60.94%] [G loss: 0.797381]\n",
      "epoch:15 step:14877 [D loss: 0.652415, acc.: 61.72%] [G loss: 0.843345]\n",
      "epoch:15 step:14878 [D loss: 0.735024, acc.: 46.88%] [G loss: 0.823292]\n",
      "epoch:15 step:14879 [D loss: 0.664186, acc.: 60.16%] [G loss: 0.867697]\n",
      "epoch:15 step:14880 [D loss: 0.664861, acc.: 57.81%] [G loss: 0.887140]\n",
      "epoch:15 step:14881 [D loss: 0.655771, acc.: 65.62%] [G loss: 0.858535]\n",
      "epoch:15 step:14882 [D loss: 0.673090, acc.: 58.59%] [G loss: 0.829159]\n",
      "epoch:15 step:14883 [D loss: 0.650463, acc.: 59.38%] [G loss: 0.864475]\n",
      "epoch:15 step:14884 [D loss: 0.658749, acc.: 61.72%] [G loss: 0.829966]\n",
      "epoch:15 step:14885 [D loss: 0.691025, acc.: 58.59%] [G loss: 0.884761]\n",
      "epoch:15 step:14886 [D loss: 0.679388, acc.: 61.72%] [G loss: 0.895135]\n",
      "epoch:15 step:14887 [D loss: 0.659078, acc.: 58.59%] [G loss: 0.874592]\n",
      "epoch:15 step:14888 [D loss: 0.677353, acc.: 61.72%] [G loss: 0.895724]\n",
      "epoch:15 step:14889 [D loss: 0.660781, acc.: 57.81%] [G loss: 0.864439]\n",
      "epoch:15 step:14890 [D loss: 0.687643, acc.: 64.06%] [G loss: 0.847162]\n",
      "epoch:15 step:14891 [D loss: 0.692557, acc.: 53.91%] [G loss: 0.841922]\n",
      "epoch:15 step:14892 [D loss: 0.648440, acc.: 61.72%] [G loss: 0.826059]\n",
      "epoch:15 step:14893 [D loss: 0.683325, acc.: 52.34%] [G loss: 0.832822]\n",
      "epoch:15 step:14894 [D loss: 0.666836, acc.: 58.59%] [G loss: 0.862029]\n",
      "epoch:15 step:14895 [D loss: 0.665940, acc.: 57.81%] [G loss: 0.886869]\n",
      "epoch:15 step:14896 [D loss: 0.654712, acc.: 59.38%] [G loss: 0.830528]\n",
      "epoch:15 step:14897 [D loss: 0.684254, acc.: 52.34%] [G loss: 0.894436]\n",
      "epoch:15 step:14898 [D loss: 0.695947, acc.: 50.00%] [G loss: 0.842287]\n",
      "epoch:15 step:14899 [D loss: 0.650719, acc.: 60.94%] [G loss: 0.851402]\n",
      "epoch:15 step:14900 [D loss: 0.665529, acc.: 53.91%] [G loss: 0.823731]\n",
      "epoch:15 step:14901 [D loss: 0.693497, acc.: 53.91%] [G loss: 0.825957]\n",
      "epoch:15 step:14902 [D loss: 0.649294, acc.: 60.16%] [G loss: 0.878111]\n",
      "epoch:15 step:14903 [D loss: 0.666558, acc.: 58.59%] [G loss: 0.819057]\n",
      "epoch:15 step:14904 [D loss: 0.676534, acc.: 53.12%] [G loss: 0.874624]\n",
      "epoch:15 step:14905 [D loss: 0.636286, acc.: 60.16%] [G loss: 0.812753]\n",
      "epoch:15 step:14906 [D loss: 0.711411, acc.: 54.69%] [G loss: 0.840300]\n",
      "epoch:15 step:14907 [D loss: 0.656396, acc.: 64.84%] [G loss: 0.943625]\n",
      "epoch:15 step:14908 [D loss: 0.672660, acc.: 57.03%] [G loss: 0.841413]\n",
      "epoch:15 step:14909 [D loss: 0.665826, acc.: 55.47%] [G loss: 0.831556]\n",
      "epoch:15 step:14910 [D loss: 0.687426, acc.: 53.12%] [G loss: 0.812569]\n",
      "epoch:15 step:14911 [D loss: 0.606996, acc.: 68.75%] [G loss: 0.839829]\n",
      "epoch:15 step:14912 [D loss: 0.676592, acc.: 57.03%] [G loss: 0.861843]\n",
      "epoch:15 step:14913 [D loss: 0.667973, acc.: 57.03%] [G loss: 0.846205]\n",
      "epoch:15 step:14914 [D loss: 0.677662, acc.: 59.38%] [G loss: 0.862799]\n",
      "epoch:15 step:14915 [D loss: 0.671483, acc.: 53.91%] [G loss: 0.854431]\n",
      "epoch:15 step:14916 [D loss: 0.660592, acc.: 58.59%] [G loss: 0.845731]\n",
      "epoch:15 step:14917 [D loss: 0.652042, acc.: 60.94%] [G loss: 0.877032]\n",
      "epoch:15 step:14918 [D loss: 0.668315, acc.: 60.16%] [G loss: 0.875167]\n",
      "epoch:15 step:14919 [D loss: 0.698703, acc.: 54.69%] [G loss: 0.850526]\n",
      "epoch:15 step:14920 [D loss: 0.669277, acc.: 53.12%] [G loss: 0.819971]\n",
      "epoch:15 step:14921 [D loss: 0.646311, acc.: 59.38%] [G loss: 0.806787]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:15 step:14922 [D loss: 0.664129, acc.: 58.59%] [G loss: 0.810494]\n",
      "epoch:15 step:14923 [D loss: 0.671185, acc.: 60.16%] [G loss: 0.844219]\n",
      "epoch:15 step:14924 [D loss: 0.649397, acc.: 58.59%] [G loss: 0.834212]\n",
      "epoch:15 step:14925 [D loss: 0.680336, acc.: 49.22%] [G loss: 0.818008]\n",
      "epoch:15 step:14926 [D loss: 0.669995, acc.: 58.59%] [G loss: 0.813123]\n",
      "epoch:15 step:14927 [D loss: 0.696181, acc.: 53.91%] [G loss: 0.830153]\n",
      "epoch:15 step:14928 [D loss: 0.652490, acc.: 66.41%] [G loss: 0.832439]\n",
      "epoch:15 step:14929 [D loss: 0.687512, acc.: 57.03%] [G loss: 0.792880]\n",
      "epoch:15 step:14930 [D loss: 0.619105, acc.: 69.53%] [G loss: 0.824687]\n",
      "epoch:15 step:14931 [D loss: 0.686078, acc.: 54.69%] [G loss: 0.866425]\n",
      "epoch:15 step:14932 [D loss: 0.669694, acc.: 60.94%] [G loss: 0.840569]\n",
      "epoch:15 step:14933 [D loss: 0.688498, acc.: 51.56%] [G loss: 0.865741]\n",
      "epoch:15 step:14934 [D loss: 0.673748, acc.: 53.91%] [G loss: 0.862779]\n",
      "epoch:15 step:14935 [D loss: 0.654287, acc.: 58.59%] [G loss: 0.875918]\n",
      "epoch:15 step:14936 [D loss: 0.674820, acc.: 60.16%] [G loss: 0.859228]\n",
      "epoch:15 step:14937 [D loss: 0.654085, acc.: 60.16%] [G loss: 0.856373]\n",
      "epoch:15 step:14938 [D loss: 0.684573, acc.: 53.91%] [G loss: 0.838393]\n",
      "epoch:15 step:14939 [D loss: 0.682798, acc.: 58.59%] [G loss: 0.887891]\n",
      "epoch:15 step:14940 [D loss: 0.661284, acc.: 60.94%] [G loss: 0.842126]\n",
      "epoch:15 step:14941 [D loss: 0.656416, acc.: 60.16%] [G loss: 0.843266]\n",
      "epoch:15 step:14942 [D loss: 0.642704, acc.: 59.38%] [G loss: 0.842169]\n",
      "epoch:15 step:14943 [D loss: 0.671863, acc.: 59.38%] [G loss: 0.849723]\n",
      "epoch:15 step:14944 [D loss: 0.674688, acc.: 60.16%] [G loss: 0.813495]\n",
      "epoch:15 step:14945 [D loss: 0.665936, acc.: 54.69%] [G loss: 0.878176]\n",
      "epoch:15 step:14946 [D loss: 0.683058, acc.: 52.34%] [G loss: 0.841302]\n",
      "epoch:15 step:14947 [D loss: 0.692955, acc.: 51.56%] [G loss: 0.872828]\n",
      "epoch:15 step:14948 [D loss: 0.695229, acc.: 52.34%] [G loss: 0.848294]\n",
      "epoch:15 step:14949 [D loss: 0.704390, acc.: 48.44%] [G loss: 0.847864]\n",
      "epoch:15 step:14950 [D loss: 0.704857, acc.: 53.91%] [G loss: 0.812557]\n",
      "epoch:15 step:14951 [D loss: 0.655248, acc.: 61.72%] [G loss: 0.862814]\n",
      "epoch:15 step:14952 [D loss: 0.677040, acc.: 53.91%] [G loss: 0.831405]\n",
      "epoch:15 step:14953 [D loss: 0.675122, acc.: 57.03%] [G loss: 0.839144]\n",
      "epoch:15 step:14954 [D loss: 0.659268, acc.: 67.97%] [G loss: 0.859496]\n",
      "epoch:15 step:14955 [D loss: 0.647454, acc.: 60.16%] [G loss: 0.829130]\n",
      "epoch:15 step:14956 [D loss: 0.709810, acc.: 50.78%] [G loss: 0.817385]\n",
      "epoch:15 step:14957 [D loss: 0.637684, acc.: 63.28%] [G loss: 0.810509]\n",
      "epoch:15 step:14958 [D loss: 0.646981, acc.: 64.06%] [G loss: 0.860041]\n",
      "epoch:15 step:14959 [D loss: 0.661753, acc.: 65.62%] [G loss: 0.813780]\n",
      "epoch:15 step:14960 [D loss: 0.693827, acc.: 50.78%] [G loss: 0.856834]\n",
      "epoch:15 step:14961 [D loss: 0.667472, acc.: 57.81%] [G loss: 0.823497]\n",
      "epoch:15 step:14962 [D loss: 0.703009, acc.: 49.22%] [G loss: 0.850186]\n",
      "epoch:15 step:14963 [D loss: 0.657498, acc.: 55.47%] [G loss: 0.823701]\n",
      "epoch:15 step:14964 [D loss: 0.673562, acc.: 58.59%] [G loss: 0.833114]\n",
      "epoch:15 step:14965 [D loss: 0.689132, acc.: 49.22%] [G loss: 0.845124]\n",
      "epoch:15 step:14966 [D loss: 0.648288, acc.: 62.50%] [G loss: 0.850614]\n",
      "epoch:15 step:14967 [D loss: 0.659598, acc.: 57.03%] [G loss: 0.851361]\n",
      "epoch:15 step:14968 [D loss: 0.672986, acc.: 55.47%] [G loss: 0.855320]\n",
      "epoch:15 step:14969 [D loss: 0.682596, acc.: 60.16%] [G loss: 0.870705]\n",
      "epoch:15 step:14970 [D loss: 0.701375, acc.: 50.00%] [G loss: 0.848485]\n",
      "epoch:15 step:14971 [D loss: 0.698349, acc.: 53.12%] [G loss: 0.865040]\n",
      "epoch:15 step:14972 [D loss: 0.654349, acc.: 63.28%] [G loss: 0.900278]\n",
      "epoch:15 step:14973 [D loss: 0.639763, acc.: 64.84%] [G loss: 0.884489]\n",
      "epoch:15 step:14974 [D loss: 0.654226, acc.: 58.59%] [G loss: 0.861160]\n",
      "epoch:15 step:14975 [D loss: 0.659943, acc.: 63.28%] [G loss: 0.866079]\n",
      "epoch:15 step:14976 [D loss: 0.657297, acc.: 61.72%] [G loss: 0.877996]\n",
      "epoch:15 step:14977 [D loss: 0.702693, acc.: 55.47%] [G loss: 0.860886]\n",
      "epoch:15 step:14978 [D loss: 0.673920, acc.: 51.56%] [G loss: 0.852921]\n",
      "epoch:15 step:14979 [D loss: 0.662713, acc.: 57.03%] [G loss: 0.868026]\n",
      "epoch:15 step:14980 [D loss: 0.681153, acc.: 57.03%] [G loss: 0.856305]\n",
      "epoch:15 step:14981 [D loss: 0.653638, acc.: 60.94%] [G loss: 0.873413]\n",
      "epoch:15 step:14982 [D loss: 0.682825, acc.: 57.81%] [G loss: 0.841985]\n",
      "epoch:15 step:14983 [D loss: 0.668956, acc.: 55.47%] [G loss: 0.863841]\n",
      "epoch:15 step:14984 [D loss: 0.661661, acc.: 61.72%] [G loss: 0.887400]\n",
      "epoch:15 step:14985 [D loss: 0.661589, acc.: 57.03%] [G loss: 0.864855]\n",
      "epoch:15 step:14986 [D loss: 0.660098, acc.: 56.25%] [G loss: 0.846631]\n",
      "epoch:15 step:14987 [D loss: 0.661161, acc.: 59.38%] [G loss: 0.870317]\n",
      "epoch:15 step:14988 [D loss: 0.693154, acc.: 57.03%] [G loss: 0.852679]\n",
      "epoch:15 step:14989 [D loss: 0.648671, acc.: 62.50%] [G loss: 0.840214]\n",
      "epoch:15 step:14990 [D loss: 0.666099, acc.: 56.25%] [G loss: 0.862544]\n",
      "epoch:15 step:14991 [D loss: 0.671037, acc.: 58.59%] [G loss: 0.853928]\n",
      "epoch:15 step:14992 [D loss: 0.678656, acc.: 57.03%] [G loss: 0.878873]\n",
      "epoch:16 step:14993 [D loss: 0.681316, acc.: 57.03%] [G loss: 0.920733]\n",
      "epoch:16 step:14994 [D loss: 0.678345, acc.: 57.81%] [G loss: 0.859741]\n",
      "epoch:16 step:14995 [D loss: 0.642821, acc.: 63.28%] [G loss: 0.906738]\n",
      "epoch:16 step:14996 [D loss: 0.645094, acc.: 66.41%] [G loss: 0.903398]\n",
      "epoch:16 step:14997 [D loss: 0.659827, acc.: 60.94%] [G loss: 0.855448]\n",
      "epoch:16 step:14998 [D loss: 0.653150, acc.: 60.94%] [G loss: 0.926183]\n",
      "epoch:16 step:14999 [D loss: 0.686734, acc.: 51.56%] [G loss: 0.909992]\n",
      "epoch:16 step:15000 [D loss: 0.692873, acc.: 50.00%] [G loss: 0.857692]\n",
      "##############\n",
      "[2.97740381 2.66046145 2.43420144 3.90781832 1.56955403 7.1457417\n",
      " 2.51047583 3.59748345 4.37983895 7.14868929]\n",
      "##########\n",
      "epoch:16 step:15001 [D loss: 0.653385, acc.: 64.06%] [G loss: 0.853140]\n",
      "epoch:16 step:15002 [D loss: 0.643122, acc.: 67.19%] [G loss: 0.848872]\n",
      "epoch:16 step:15003 [D loss: 0.628495, acc.: 67.19%] [G loss: 0.841254]\n",
      "epoch:16 step:15004 [D loss: 0.663144, acc.: 63.28%] [G loss: 0.847412]\n",
      "epoch:16 step:15005 [D loss: 0.634107, acc.: 67.97%] [G loss: 0.841102]\n",
      "epoch:16 step:15006 [D loss: 0.654981, acc.: 63.28%] [G loss: 0.849363]\n",
      "epoch:16 step:15007 [D loss: 0.685714, acc.: 57.81%] [G loss: 0.830744]\n",
      "epoch:16 step:15008 [D loss: 0.642731, acc.: 65.62%] [G loss: 0.829472]\n",
      "epoch:16 step:15009 [D loss: 0.672331, acc.: 61.72%] [G loss: 0.815232]\n",
      "epoch:16 step:15010 [D loss: 0.697561, acc.: 51.56%] [G loss: 0.816265]\n",
      "epoch:16 step:15011 [D loss: 0.686065, acc.: 52.34%] [G loss: 0.864629]\n",
      "epoch:16 step:15012 [D loss: 0.669751, acc.: 57.81%] [G loss: 0.937467]\n",
      "epoch:16 step:15013 [D loss: 0.651398, acc.: 63.28%] [G loss: 0.864663]\n",
      "epoch:16 step:15014 [D loss: 0.659931, acc.: 60.94%] [G loss: 0.947127]\n",
      "epoch:16 step:15015 [D loss: 0.677999, acc.: 55.47%] [G loss: 0.914537]\n",
      "epoch:16 step:15016 [D loss: 0.643517, acc.: 60.94%] [G loss: 0.864766]\n",
      "epoch:16 step:15017 [D loss: 0.643663, acc.: 62.50%] [G loss: 0.863553]\n",
      "epoch:16 step:15018 [D loss: 0.657818, acc.: 57.81%] [G loss: 0.851826]\n",
      "epoch:16 step:15019 [D loss: 0.642443, acc.: 60.16%] [G loss: 0.857721]\n",
      "epoch:16 step:15020 [D loss: 0.634743, acc.: 63.28%] [G loss: 0.872255]\n",
      "epoch:16 step:15021 [D loss: 0.678294, acc.: 57.81%] [G loss: 0.865663]\n",
      "epoch:16 step:15022 [D loss: 0.685478, acc.: 58.59%] [G loss: 0.842989]\n",
      "epoch:16 step:15023 [D loss: 0.671135, acc.: 58.59%] [G loss: 0.865860]\n",
      "epoch:16 step:15024 [D loss: 0.652740, acc.: 62.50%] [G loss: 0.854974]\n",
      "epoch:16 step:15025 [D loss: 0.692535, acc.: 52.34%] [G loss: 0.943869]\n",
      "epoch:16 step:15026 [D loss: 0.659806, acc.: 55.47%] [G loss: 0.899543]\n",
      "epoch:16 step:15027 [D loss: 0.651184, acc.: 60.16%] [G loss: 0.852495]\n",
      "epoch:16 step:15028 [D loss: 0.636418, acc.: 66.41%] [G loss: 0.892289]\n",
      "epoch:16 step:15029 [D loss: 0.669612, acc.: 60.16%] [G loss: 0.824186]\n",
      "epoch:16 step:15030 [D loss: 0.677385, acc.: 57.81%] [G loss: 0.868620]\n",
      "epoch:16 step:15031 [D loss: 0.645094, acc.: 62.50%] [G loss: 0.921020]\n",
      "epoch:16 step:15032 [D loss: 0.680061, acc.: 55.47%] [G loss: 0.912448]\n",
      "epoch:16 step:15033 [D loss: 0.672249, acc.: 57.81%] [G loss: 0.906067]\n",
      "epoch:16 step:15034 [D loss: 0.634216, acc.: 62.50%] [G loss: 0.886704]\n",
      "epoch:16 step:15035 [D loss: 0.646836, acc.: 60.94%] [G loss: 0.861496]\n",
      "epoch:16 step:15036 [D loss: 0.660288, acc.: 57.03%] [G loss: 0.881086]\n",
      "epoch:16 step:15037 [D loss: 0.708219, acc.: 50.78%] [G loss: 0.823256]\n",
      "epoch:16 step:15038 [D loss: 0.673033, acc.: 55.47%] [G loss: 0.783943]\n",
      "epoch:16 step:15039 [D loss: 0.726716, acc.: 44.53%] [G loss: 0.818483]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15040 [D loss: 0.673332, acc.: 54.69%] [G loss: 0.828273]\n",
      "epoch:16 step:15041 [D loss: 0.688803, acc.: 53.91%] [G loss: 0.868934]\n",
      "epoch:16 step:15042 [D loss: 0.663191, acc.: 60.16%] [G loss: 0.872137]\n",
      "epoch:16 step:15043 [D loss: 0.677095, acc.: 60.94%] [G loss: 0.874279]\n",
      "epoch:16 step:15044 [D loss: 0.646616, acc.: 58.59%] [G loss: 0.900528]\n",
      "epoch:16 step:15045 [D loss: 0.641751, acc.: 61.72%] [G loss: 0.888090]\n",
      "epoch:16 step:15046 [D loss: 0.650084, acc.: 67.19%] [G loss: 0.888930]\n",
      "epoch:16 step:15047 [D loss: 0.692722, acc.: 56.25%] [G loss: 0.832551]\n",
      "epoch:16 step:15048 [D loss: 0.660641, acc.: 54.69%] [G loss: 0.901157]\n",
      "epoch:16 step:15049 [D loss: 0.667573, acc.: 57.03%] [G loss: 0.863973]\n",
      "epoch:16 step:15050 [D loss: 0.699601, acc.: 55.47%] [G loss: 0.894622]\n",
      "epoch:16 step:15051 [D loss: 0.648357, acc.: 61.72%] [G loss: 0.849492]\n",
      "epoch:16 step:15052 [D loss: 0.676149, acc.: 59.38%] [G loss: 0.900269]\n",
      "epoch:16 step:15053 [D loss: 0.689450, acc.: 57.03%] [G loss: 0.844522]\n",
      "epoch:16 step:15054 [D loss: 0.675576, acc.: 59.38%] [G loss: 0.911352]\n",
      "epoch:16 step:15055 [D loss: 0.697879, acc.: 49.22%] [G loss: 0.853932]\n",
      "epoch:16 step:15056 [D loss: 0.659472, acc.: 54.69%] [G loss: 0.879292]\n",
      "epoch:16 step:15057 [D loss: 0.666665, acc.: 60.94%] [G loss: 0.850598]\n",
      "epoch:16 step:15058 [D loss: 0.660562, acc.: 59.38%] [G loss: 0.817243]\n",
      "epoch:16 step:15059 [D loss: 0.672130, acc.: 62.50%] [G loss: 0.872527]\n",
      "epoch:16 step:15060 [D loss: 0.660170, acc.: 57.03%] [G loss: 0.853603]\n",
      "epoch:16 step:15061 [D loss: 0.669900, acc.: 60.16%] [G loss: 0.864495]\n",
      "epoch:16 step:15062 [D loss: 0.641934, acc.: 70.31%] [G loss: 0.922195]\n",
      "epoch:16 step:15063 [D loss: 0.654850, acc.: 61.72%] [G loss: 0.927491]\n",
      "epoch:16 step:15064 [D loss: 0.671639, acc.: 60.16%] [G loss: 0.881798]\n",
      "epoch:16 step:15065 [D loss: 0.642498, acc.: 66.41%] [G loss: 0.822596]\n",
      "epoch:16 step:15066 [D loss: 0.632466, acc.: 64.06%] [G loss: 0.827236]\n",
      "epoch:16 step:15067 [D loss: 0.660278, acc.: 59.38%] [G loss: 0.814843]\n",
      "epoch:16 step:15068 [D loss: 0.627533, acc.: 66.41%] [G loss: 0.840090]\n",
      "epoch:16 step:15069 [D loss: 0.668248, acc.: 57.81%] [G loss: 0.795033]\n",
      "epoch:16 step:15070 [D loss: 0.657602, acc.: 57.03%] [G loss: 0.812108]\n",
      "epoch:16 step:15071 [D loss: 0.684075, acc.: 57.81%] [G loss: 0.871796]\n",
      "epoch:16 step:15072 [D loss: 0.667642, acc.: 57.03%] [G loss: 0.884005]\n",
      "epoch:16 step:15073 [D loss: 0.682810, acc.: 53.12%] [G loss: 0.846595]\n",
      "epoch:16 step:15074 [D loss: 0.630410, acc.: 66.41%] [G loss: 0.866311]\n",
      "epoch:16 step:15075 [D loss: 0.638033, acc.: 64.84%] [G loss: 0.857977]\n",
      "epoch:16 step:15076 [D loss: 0.659017, acc.: 58.59%] [G loss: 0.866688]\n",
      "epoch:16 step:15077 [D loss: 0.676686, acc.: 53.91%] [G loss: 0.834954]\n",
      "epoch:16 step:15078 [D loss: 0.648484, acc.: 61.72%] [G loss: 0.838368]\n",
      "epoch:16 step:15079 [D loss: 0.668013, acc.: 57.81%] [G loss: 0.878536]\n",
      "epoch:16 step:15080 [D loss: 0.664652, acc.: 60.16%] [G loss: 0.870502]\n",
      "epoch:16 step:15081 [D loss: 0.651108, acc.: 66.41%] [G loss: 0.837445]\n",
      "epoch:16 step:15082 [D loss: 0.650631, acc.: 64.84%] [G loss: 0.867495]\n",
      "epoch:16 step:15083 [D loss: 0.684110, acc.: 57.81%] [G loss: 0.898811]\n",
      "epoch:16 step:15084 [D loss: 0.657022, acc.: 59.38%] [G loss: 0.867640]\n",
      "epoch:16 step:15085 [D loss: 0.669695, acc.: 53.91%] [G loss: 0.865980]\n",
      "epoch:16 step:15086 [D loss: 0.678967, acc.: 51.56%] [G loss: 0.819160]\n",
      "epoch:16 step:15087 [D loss: 0.690258, acc.: 53.91%] [G loss: 0.845658]\n",
      "epoch:16 step:15088 [D loss: 0.676960, acc.: 55.47%] [G loss: 0.821716]\n",
      "epoch:16 step:15089 [D loss: 0.674302, acc.: 57.03%] [G loss: 0.851171]\n",
      "epoch:16 step:15090 [D loss: 0.653858, acc.: 61.72%] [G loss: 0.834974]\n",
      "epoch:16 step:15091 [D loss: 0.670894, acc.: 58.59%] [G loss: 0.840633]\n",
      "epoch:16 step:15092 [D loss: 0.673697, acc.: 58.59%] [G loss: 0.860372]\n",
      "epoch:16 step:15093 [D loss: 0.668684, acc.: 56.25%] [G loss: 0.858227]\n",
      "epoch:16 step:15094 [D loss: 0.699440, acc.: 49.22%] [G loss: 0.867782]\n",
      "epoch:16 step:15095 [D loss: 0.619319, acc.: 65.62%] [G loss: 0.895390]\n",
      "epoch:16 step:15096 [D loss: 0.664725, acc.: 64.06%] [G loss: 0.916152]\n",
      "epoch:16 step:15097 [D loss: 0.653210, acc.: 60.16%] [G loss: 0.838755]\n",
      "epoch:16 step:15098 [D loss: 0.657320, acc.: 66.41%] [G loss: 0.880414]\n",
      "epoch:16 step:15099 [D loss: 0.677564, acc.: 51.56%] [G loss: 0.859289]\n",
      "epoch:16 step:15100 [D loss: 0.647057, acc.: 64.84%] [G loss: 0.814075]\n",
      "epoch:16 step:15101 [D loss: 0.648159, acc.: 61.72%] [G loss: 0.820510]\n",
      "epoch:16 step:15102 [D loss: 0.715294, acc.: 50.78%] [G loss: 0.864910]\n",
      "epoch:16 step:15103 [D loss: 0.702782, acc.: 53.91%] [G loss: 0.822502]\n",
      "epoch:16 step:15104 [D loss: 0.735407, acc.: 53.91%] [G loss: 0.848808]\n",
      "epoch:16 step:15105 [D loss: 0.674171, acc.: 61.72%] [G loss: 0.913737]\n",
      "epoch:16 step:15106 [D loss: 0.648324, acc.: 65.62%] [G loss: 0.909465]\n",
      "epoch:16 step:15107 [D loss: 0.695689, acc.: 53.12%] [G loss: 0.890526]\n",
      "epoch:16 step:15108 [D loss: 0.658060, acc.: 60.16%] [G loss: 0.870980]\n",
      "epoch:16 step:15109 [D loss: 0.680910, acc.: 56.25%] [G loss: 0.810001]\n",
      "epoch:16 step:15110 [D loss: 0.645958, acc.: 61.72%] [G loss: 0.792331]\n",
      "epoch:16 step:15111 [D loss: 0.641653, acc.: 60.94%] [G loss: 0.847857]\n",
      "epoch:16 step:15112 [D loss: 0.671234, acc.: 54.69%] [G loss: 0.887404]\n",
      "epoch:16 step:15113 [D loss: 0.642501, acc.: 59.38%] [G loss: 0.865712]\n",
      "epoch:16 step:15114 [D loss: 0.681569, acc.: 55.47%] [G loss: 0.837802]\n",
      "epoch:16 step:15115 [D loss: 0.678800, acc.: 56.25%] [G loss: 0.815962]\n",
      "epoch:16 step:15116 [D loss: 0.660107, acc.: 62.50%] [G loss: 0.796328]\n",
      "epoch:16 step:15117 [D loss: 0.659532, acc.: 57.03%] [G loss: 0.825314]\n",
      "epoch:16 step:15118 [D loss: 0.713191, acc.: 48.44%] [G loss: 0.821034]\n",
      "epoch:16 step:15119 [D loss: 0.614626, acc.: 67.19%] [G loss: 0.843527]\n",
      "epoch:16 step:15120 [D loss: 0.651644, acc.: 65.62%] [G loss: 0.914039]\n",
      "epoch:16 step:15121 [D loss: 0.676242, acc.: 58.59%] [G loss: 0.835323]\n",
      "epoch:16 step:15122 [D loss: 0.649782, acc.: 57.03%] [G loss: 0.863090]\n",
      "epoch:16 step:15123 [D loss: 0.663041, acc.: 56.25%] [G loss: 0.821396]\n",
      "epoch:16 step:15124 [D loss: 0.689210, acc.: 51.56%] [G loss: 0.849401]\n",
      "epoch:16 step:15125 [D loss: 0.687647, acc.: 57.81%] [G loss: 0.841439]\n",
      "epoch:16 step:15126 [D loss: 0.658943, acc.: 60.16%] [G loss: 0.844816]\n",
      "epoch:16 step:15127 [D loss: 0.691899, acc.: 50.00%] [G loss: 0.879256]\n",
      "epoch:16 step:15128 [D loss: 0.672458, acc.: 58.59%] [G loss: 0.848389]\n",
      "epoch:16 step:15129 [D loss: 0.685061, acc.: 60.94%] [G loss: 0.882827]\n",
      "epoch:16 step:15130 [D loss: 0.671454, acc.: 58.59%] [G loss: 0.810100]\n",
      "epoch:16 step:15131 [D loss: 0.642025, acc.: 61.72%] [G loss: 0.852043]\n",
      "epoch:16 step:15132 [D loss: 0.672954, acc.: 56.25%] [G loss: 0.843851]\n",
      "epoch:16 step:15133 [D loss: 0.698353, acc.: 53.12%] [G loss: 0.864021]\n",
      "epoch:16 step:15134 [D loss: 0.632874, acc.: 67.19%] [G loss: 0.822507]\n",
      "epoch:16 step:15135 [D loss: 0.664950, acc.: 62.50%] [G loss: 0.837676]\n",
      "epoch:16 step:15136 [D loss: 0.662911, acc.: 54.69%] [G loss: 0.851458]\n",
      "epoch:16 step:15137 [D loss: 0.669572, acc.: 60.16%] [G loss: 0.841681]\n",
      "epoch:16 step:15138 [D loss: 0.658601, acc.: 59.38%] [G loss: 0.864396]\n",
      "epoch:16 step:15139 [D loss: 0.648623, acc.: 63.28%] [G loss: 0.838089]\n",
      "epoch:16 step:15140 [D loss: 0.670478, acc.: 56.25%] [G loss: 0.860068]\n",
      "epoch:16 step:15141 [D loss: 0.670334, acc.: 53.91%] [G loss: 0.871761]\n",
      "epoch:16 step:15142 [D loss: 0.662731, acc.: 57.03%] [G loss: 0.843305]\n",
      "epoch:16 step:15143 [D loss: 0.697274, acc.: 52.34%] [G loss: 0.835461]\n",
      "epoch:16 step:15144 [D loss: 0.657924, acc.: 59.38%] [G loss: 0.832178]\n",
      "epoch:16 step:15145 [D loss: 0.700598, acc.: 47.66%] [G loss: 0.890831]\n",
      "epoch:16 step:15146 [D loss: 0.662734, acc.: 58.59%] [G loss: 0.865734]\n",
      "epoch:16 step:15147 [D loss: 0.692907, acc.: 49.22%] [G loss: 0.878277]\n",
      "epoch:16 step:15148 [D loss: 0.624509, acc.: 63.28%] [G loss: 0.842632]\n",
      "epoch:16 step:15149 [D loss: 0.710095, acc.: 53.12%] [G loss: 0.848751]\n",
      "epoch:16 step:15150 [D loss: 0.672823, acc.: 59.38%] [G loss: 0.859988]\n",
      "epoch:16 step:15151 [D loss: 0.655770, acc.: 63.28%] [G loss: 0.880363]\n",
      "epoch:16 step:15152 [D loss: 0.675739, acc.: 60.16%] [G loss: 0.883133]\n",
      "epoch:16 step:15153 [D loss: 0.652575, acc.: 60.94%] [G loss: 0.908715]\n",
      "epoch:16 step:15154 [D loss: 0.667291, acc.: 55.47%] [G loss: 0.853772]\n",
      "epoch:16 step:15155 [D loss: 0.689715, acc.: 58.59%] [G loss: 0.869636]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15156 [D loss: 0.686221, acc.: 53.91%] [G loss: 0.863146]\n",
      "epoch:16 step:15157 [D loss: 0.663761, acc.: 58.59%] [G loss: 0.867235]\n",
      "epoch:16 step:15158 [D loss: 0.666171, acc.: 54.69%] [G loss: 0.874328]\n",
      "epoch:16 step:15159 [D loss: 0.653466, acc.: 61.72%] [G loss: 0.875457]\n",
      "epoch:16 step:15160 [D loss: 0.669164, acc.: 59.38%] [G loss: 0.841205]\n",
      "epoch:16 step:15161 [D loss: 0.696325, acc.: 55.47%] [G loss: 0.859994]\n",
      "epoch:16 step:15162 [D loss: 0.635241, acc.: 70.31%] [G loss: 0.872447]\n",
      "epoch:16 step:15163 [D loss: 0.698726, acc.: 51.56%] [G loss: 0.883244]\n",
      "epoch:16 step:15164 [D loss: 0.649938, acc.: 63.28%] [G loss: 0.908221]\n",
      "epoch:16 step:15165 [D loss: 0.693098, acc.: 60.94%] [G loss: 0.883759]\n",
      "epoch:16 step:15166 [D loss: 0.678162, acc.: 60.94%] [G loss: 0.867530]\n",
      "epoch:16 step:15167 [D loss: 0.703628, acc.: 53.91%] [G loss: 0.855369]\n",
      "epoch:16 step:15168 [D loss: 0.618637, acc.: 67.19%] [G loss: 0.863177]\n",
      "epoch:16 step:15169 [D loss: 0.653322, acc.: 64.06%] [G loss: 0.843325]\n",
      "epoch:16 step:15170 [D loss: 0.652068, acc.: 62.50%] [G loss: 0.884154]\n",
      "epoch:16 step:15171 [D loss: 0.667536, acc.: 56.25%] [G loss: 0.861173]\n",
      "epoch:16 step:15172 [D loss: 0.674797, acc.: 53.91%] [G loss: 0.829195]\n",
      "epoch:16 step:15173 [D loss: 0.683562, acc.: 58.59%] [G loss: 0.855786]\n",
      "epoch:16 step:15174 [D loss: 0.634474, acc.: 67.19%] [G loss: 0.827484]\n",
      "epoch:16 step:15175 [D loss: 0.654167, acc.: 60.16%] [G loss: 0.864421]\n",
      "epoch:16 step:15176 [D loss: 0.673326, acc.: 59.38%] [G loss: 0.819074]\n",
      "epoch:16 step:15177 [D loss: 0.638097, acc.: 58.59%] [G loss: 0.900731]\n",
      "epoch:16 step:15178 [D loss: 0.663804, acc.: 60.16%] [G loss: 0.833316]\n",
      "epoch:16 step:15179 [D loss: 0.670688, acc.: 64.06%] [G loss: 0.898322]\n",
      "epoch:16 step:15180 [D loss: 0.691406, acc.: 55.47%] [G loss: 0.861305]\n",
      "epoch:16 step:15181 [D loss: 0.678486, acc.: 57.03%] [G loss: 0.863495]\n",
      "epoch:16 step:15182 [D loss: 0.659003, acc.: 60.94%] [G loss: 0.857818]\n",
      "epoch:16 step:15183 [D loss: 0.626322, acc.: 62.50%] [G loss: 0.886276]\n",
      "epoch:16 step:15184 [D loss: 0.675234, acc.: 52.34%] [G loss: 0.871972]\n",
      "epoch:16 step:15185 [D loss: 0.662725, acc.: 60.94%] [G loss: 0.884775]\n",
      "epoch:16 step:15186 [D loss: 0.710359, acc.: 50.00%] [G loss: 0.830832]\n",
      "epoch:16 step:15187 [D loss: 0.638673, acc.: 58.59%] [G loss: 0.843660]\n",
      "epoch:16 step:15188 [D loss: 0.658019, acc.: 63.28%] [G loss: 0.835056]\n",
      "epoch:16 step:15189 [D loss: 0.648728, acc.: 61.72%] [G loss: 0.920743]\n",
      "epoch:16 step:15190 [D loss: 0.629575, acc.: 68.75%] [G loss: 0.889461]\n",
      "epoch:16 step:15191 [D loss: 0.606255, acc.: 67.97%] [G loss: 0.872164]\n",
      "epoch:16 step:15192 [D loss: 0.637580, acc.: 64.84%] [G loss: 0.913099]\n",
      "epoch:16 step:15193 [D loss: 0.684764, acc.: 60.16%] [G loss: 0.880305]\n",
      "epoch:16 step:15194 [D loss: 0.617679, acc.: 65.62%] [G loss: 0.890565]\n",
      "epoch:16 step:15195 [D loss: 0.654617, acc.: 60.16%] [G loss: 0.892696]\n",
      "epoch:16 step:15196 [D loss: 0.675533, acc.: 55.47%] [G loss: 0.842655]\n",
      "epoch:16 step:15197 [D loss: 0.707222, acc.: 53.12%] [G loss: 0.834321]\n",
      "epoch:16 step:15198 [D loss: 0.701440, acc.: 54.69%] [G loss: 0.921009]\n",
      "epoch:16 step:15199 [D loss: 0.624432, acc.: 62.50%] [G loss: 0.910339]\n",
      "epoch:16 step:15200 [D loss: 0.643198, acc.: 64.06%] [G loss: 0.864771]\n",
      "##############\n",
      "[2.96043444 2.32329287 2.36297795 3.74296718 1.55108454 7.69119286\n",
      " 3.08035355 4.11727169 4.25088399 7.14868929]\n",
      "##########\n",
      "epoch:16 step:15201 [D loss: 0.682362, acc.: 59.38%] [G loss: 0.880940]\n",
      "epoch:16 step:15202 [D loss: 0.638846, acc.: 66.41%] [G loss: 0.848907]\n",
      "epoch:16 step:15203 [D loss: 0.694882, acc.: 52.34%] [G loss: 0.903022]\n",
      "epoch:16 step:15204 [D loss: 0.658385, acc.: 58.59%] [G loss: 0.861930]\n",
      "epoch:16 step:15205 [D loss: 0.668255, acc.: 60.94%] [G loss: 0.833586]\n",
      "epoch:16 step:15206 [D loss: 0.635120, acc.: 69.53%] [G loss: 0.905606]\n",
      "epoch:16 step:15207 [D loss: 0.704008, acc.: 53.91%] [G loss: 0.840355]\n",
      "epoch:16 step:15208 [D loss: 0.693272, acc.: 56.25%] [G loss: 0.836390]\n",
      "epoch:16 step:15209 [D loss: 0.664490, acc.: 60.16%] [G loss: 0.860235]\n",
      "epoch:16 step:15210 [D loss: 0.672098, acc.: 57.03%] [G loss: 0.872123]\n",
      "epoch:16 step:15211 [D loss: 0.669435, acc.: 60.16%] [G loss: 0.818742]\n",
      "epoch:16 step:15212 [D loss: 0.673546, acc.: 64.84%] [G loss: 0.826212]\n",
      "epoch:16 step:15213 [D loss: 0.659231, acc.: 62.50%] [G loss: 0.827903]\n",
      "epoch:16 step:15214 [D loss: 0.657804, acc.: 63.28%] [G loss: 0.864092]\n",
      "epoch:16 step:15215 [D loss: 0.655236, acc.: 57.81%] [G loss: 0.860452]\n",
      "epoch:16 step:15216 [D loss: 0.669967, acc.: 58.59%] [G loss: 0.914876]\n",
      "epoch:16 step:15217 [D loss: 0.675796, acc.: 54.69%] [G loss: 0.860093]\n",
      "epoch:16 step:15218 [D loss: 0.667333, acc.: 63.28%] [G loss: 0.825588]\n",
      "epoch:16 step:15219 [D loss: 0.675525, acc.: 57.81%] [G loss: 0.850168]\n",
      "epoch:16 step:15220 [D loss: 0.653711, acc.: 60.94%] [G loss: 0.843061]\n",
      "epoch:16 step:15221 [D loss: 0.671341, acc.: 56.25%] [G loss: 0.865197]\n",
      "epoch:16 step:15222 [D loss: 0.665416, acc.: 60.16%] [G loss: 0.836538]\n",
      "epoch:16 step:15223 [D loss: 0.689022, acc.: 58.59%] [G loss: 0.833598]\n",
      "epoch:16 step:15224 [D loss: 0.657145, acc.: 58.59%] [G loss: 0.896010]\n",
      "epoch:16 step:15225 [D loss: 0.678612, acc.: 59.38%] [G loss: 0.870799]\n",
      "epoch:16 step:15226 [D loss: 0.654415, acc.: 64.06%] [G loss: 0.846736]\n",
      "epoch:16 step:15227 [D loss: 0.687406, acc.: 55.47%] [G loss: 0.835625]\n",
      "epoch:16 step:15228 [D loss: 0.670393, acc.: 55.47%] [G loss: 0.822473]\n",
      "epoch:16 step:15229 [D loss: 0.683490, acc.: 56.25%] [G loss: 0.861659]\n",
      "epoch:16 step:15230 [D loss: 0.656683, acc.: 60.16%] [G loss: 0.819357]\n",
      "epoch:16 step:15231 [D loss: 0.673819, acc.: 55.47%] [G loss: 0.814965]\n",
      "epoch:16 step:15232 [D loss: 0.678396, acc.: 50.78%] [G loss: 0.838672]\n",
      "epoch:16 step:15233 [D loss: 0.676344, acc.: 53.12%] [G loss: 0.915609]\n",
      "epoch:16 step:15234 [D loss: 0.672953, acc.: 56.25%] [G loss: 0.865096]\n",
      "epoch:16 step:15235 [D loss: 0.668119, acc.: 62.50%] [G loss: 0.841666]\n",
      "epoch:16 step:15236 [D loss: 0.664207, acc.: 63.28%] [G loss: 0.870744]\n",
      "epoch:16 step:15237 [D loss: 0.667631, acc.: 60.94%] [G loss: 0.833281]\n",
      "epoch:16 step:15238 [D loss: 0.673080, acc.: 60.16%] [G loss: 0.851016]\n",
      "epoch:16 step:15239 [D loss: 0.693598, acc.: 51.56%] [G loss: 0.846719]\n",
      "epoch:16 step:15240 [D loss: 0.658472, acc.: 60.94%] [G loss: 0.854171]\n",
      "epoch:16 step:15241 [D loss: 0.660251, acc.: 58.59%] [G loss: 0.893215]\n",
      "epoch:16 step:15242 [D loss: 0.655814, acc.: 64.84%] [G loss: 0.885225]\n",
      "epoch:16 step:15243 [D loss: 0.670226, acc.: 63.28%] [G loss: 0.812345]\n",
      "epoch:16 step:15244 [D loss: 0.659617, acc.: 58.59%] [G loss: 0.903898]\n",
      "epoch:16 step:15245 [D loss: 0.682032, acc.: 59.38%] [G loss: 0.884038]\n",
      "epoch:16 step:15246 [D loss: 0.692302, acc.: 57.81%] [G loss: 0.851813]\n",
      "epoch:16 step:15247 [D loss: 0.660743, acc.: 56.25%] [G loss: 0.812591]\n",
      "epoch:16 step:15248 [D loss: 0.645102, acc.: 63.28%] [G loss: 0.914676]\n",
      "epoch:16 step:15249 [D loss: 0.649001, acc.: 57.81%] [G loss: 0.943335]\n",
      "epoch:16 step:15250 [D loss: 0.653780, acc.: 62.50%] [G loss: 0.866631]\n",
      "epoch:16 step:15251 [D loss: 0.715980, acc.: 53.91%] [G loss: 0.888403]\n",
      "epoch:16 step:15252 [D loss: 0.651265, acc.: 57.81%] [G loss: 0.880815]\n",
      "epoch:16 step:15253 [D loss: 0.701735, acc.: 53.91%] [G loss: 0.844668]\n",
      "epoch:16 step:15254 [D loss: 0.662597, acc.: 60.94%] [G loss: 0.878669]\n",
      "epoch:16 step:15255 [D loss: 0.656981, acc.: 60.94%] [G loss: 0.853891]\n",
      "epoch:16 step:15256 [D loss: 0.668621, acc.: 54.69%] [G loss: 0.928375]\n",
      "epoch:16 step:15257 [D loss: 0.663432, acc.: 58.59%] [G loss: 0.867161]\n",
      "epoch:16 step:15258 [D loss: 0.624148, acc.: 67.97%] [G loss: 0.901393]\n",
      "epoch:16 step:15259 [D loss: 0.650814, acc.: 58.59%] [G loss: 0.886506]\n",
      "epoch:16 step:15260 [D loss: 0.637688, acc.: 64.06%] [G loss: 0.874705]\n",
      "epoch:16 step:15261 [D loss: 0.653509, acc.: 59.38%] [G loss: 0.836610]\n",
      "epoch:16 step:15262 [D loss: 0.649061, acc.: 64.84%] [G loss: 0.822568]\n",
      "epoch:16 step:15263 [D loss: 0.659816, acc.: 57.03%] [G loss: 0.822885]\n",
      "epoch:16 step:15264 [D loss: 0.639660, acc.: 64.84%] [G loss: 0.854152]\n",
      "epoch:16 step:15265 [D loss: 0.686316, acc.: 56.25%] [G loss: 0.881357]\n",
      "epoch:16 step:15266 [D loss: 0.682668, acc.: 57.03%] [G loss: 0.891544]\n",
      "epoch:16 step:15267 [D loss: 0.715873, acc.: 55.47%] [G loss: 0.849600]\n",
      "epoch:16 step:15268 [D loss: 0.668135, acc.: 51.56%] [G loss: 0.834133]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15269 [D loss: 0.639850, acc.: 63.28%] [G loss: 0.871712]\n",
      "epoch:16 step:15270 [D loss: 0.669412, acc.: 60.16%] [G loss: 0.851442]\n",
      "epoch:16 step:15271 [D loss: 0.704220, acc.: 53.91%] [G loss: 0.863088]\n",
      "epoch:16 step:15272 [D loss: 0.686967, acc.: 54.69%] [G loss: 0.815836]\n",
      "epoch:16 step:15273 [D loss: 0.668921, acc.: 59.38%] [G loss: 0.809277]\n",
      "epoch:16 step:15274 [D loss: 0.664809, acc.: 54.69%] [G loss: 0.874295]\n",
      "epoch:16 step:15275 [D loss: 0.653147, acc.: 57.81%] [G loss: 0.833612]\n",
      "epoch:16 step:15276 [D loss: 0.626968, acc.: 65.62%] [G loss: 0.859470]\n",
      "epoch:16 step:15277 [D loss: 0.614920, acc.: 69.53%] [G loss: 0.858714]\n",
      "epoch:16 step:15278 [D loss: 0.643228, acc.: 60.16%] [G loss: 0.854893]\n",
      "epoch:16 step:15279 [D loss: 0.665714, acc.: 58.59%] [G loss: 0.962078]\n",
      "epoch:16 step:15280 [D loss: 0.658569, acc.: 57.03%] [G loss: 0.892484]\n",
      "epoch:16 step:15281 [D loss: 0.647478, acc.: 63.28%] [G loss: 0.876785]\n",
      "epoch:16 step:15282 [D loss: 0.645883, acc.: 65.62%] [G loss: 0.880850]\n",
      "epoch:16 step:15283 [D loss: 0.675073, acc.: 56.25%] [G loss: 0.843714]\n",
      "epoch:16 step:15284 [D loss: 0.657299, acc.: 60.16%] [G loss: 0.856853]\n",
      "epoch:16 step:15285 [D loss: 0.653307, acc.: 59.38%] [G loss: 0.878451]\n",
      "epoch:16 step:15286 [D loss: 0.658338, acc.: 60.94%] [G loss: 0.902079]\n",
      "epoch:16 step:15287 [D loss: 0.648187, acc.: 61.72%] [G loss: 0.872422]\n",
      "epoch:16 step:15288 [D loss: 0.680476, acc.: 56.25%] [G loss: 0.855975]\n",
      "epoch:16 step:15289 [D loss: 0.649008, acc.: 60.94%] [G loss: 0.895383]\n",
      "epoch:16 step:15290 [D loss: 0.663418, acc.: 57.03%] [G loss: 0.869926]\n",
      "epoch:16 step:15291 [D loss: 0.650464, acc.: 60.94%] [G loss: 0.905021]\n",
      "epoch:16 step:15292 [D loss: 0.668223, acc.: 58.59%] [G loss: 0.852469]\n",
      "epoch:16 step:15293 [D loss: 0.657356, acc.: 60.94%] [G loss: 0.908347]\n",
      "epoch:16 step:15294 [D loss: 0.694147, acc.: 54.69%] [G loss: 0.837525]\n",
      "epoch:16 step:15295 [D loss: 0.652981, acc.: 62.50%] [G loss: 0.836132]\n",
      "epoch:16 step:15296 [D loss: 0.692401, acc.: 56.25%] [G loss: 0.864412]\n",
      "epoch:16 step:15297 [D loss: 0.667907, acc.: 55.47%] [G loss: 0.865014]\n",
      "epoch:16 step:15298 [D loss: 0.639942, acc.: 61.72%] [G loss: 0.900755]\n",
      "epoch:16 step:15299 [D loss: 0.688346, acc.: 57.81%] [G loss: 0.831486]\n",
      "epoch:16 step:15300 [D loss: 0.672890, acc.: 56.25%] [G loss: 0.854251]\n",
      "epoch:16 step:15301 [D loss: 0.690200, acc.: 54.69%] [G loss: 0.821065]\n",
      "epoch:16 step:15302 [D loss: 0.655763, acc.: 63.28%] [G loss: 0.844394]\n",
      "epoch:16 step:15303 [D loss: 0.666545, acc.: 57.81%] [G loss: 0.840699]\n",
      "epoch:16 step:15304 [D loss: 0.698403, acc.: 53.12%] [G loss: 0.890510]\n",
      "epoch:16 step:15305 [D loss: 0.699282, acc.: 57.81%] [G loss: 0.854410]\n",
      "epoch:16 step:15306 [D loss: 0.693662, acc.: 54.69%] [G loss: 0.880430]\n",
      "epoch:16 step:15307 [D loss: 0.640654, acc.: 63.28%] [G loss: 0.944878]\n",
      "epoch:16 step:15308 [D loss: 0.633859, acc.: 63.28%] [G loss: 0.915031]\n",
      "epoch:16 step:15309 [D loss: 0.653099, acc.: 64.84%] [G loss: 0.930562]\n",
      "epoch:16 step:15310 [D loss: 0.658086, acc.: 61.72%] [G loss: 0.895272]\n",
      "epoch:16 step:15311 [D loss: 0.676830, acc.: 53.12%] [G loss: 0.835550]\n",
      "epoch:16 step:15312 [D loss: 0.648418, acc.: 62.50%] [G loss: 0.874682]\n",
      "epoch:16 step:15313 [D loss: 0.635620, acc.: 64.06%] [G loss: 0.841009]\n",
      "epoch:16 step:15314 [D loss: 0.674653, acc.: 57.81%] [G loss: 0.892639]\n",
      "epoch:16 step:15315 [D loss: 0.697742, acc.: 50.78%] [G loss: 0.894796]\n",
      "epoch:16 step:15316 [D loss: 0.674519, acc.: 57.81%] [G loss: 0.848052]\n",
      "epoch:16 step:15317 [D loss: 0.676381, acc.: 58.59%] [G loss: 0.893996]\n",
      "epoch:16 step:15318 [D loss: 0.695339, acc.: 54.69%] [G loss: 0.806805]\n",
      "epoch:16 step:15319 [D loss: 0.659192, acc.: 57.03%] [G loss: 0.839613]\n",
      "epoch:16 step:15320 [D loss: 0.686032, acc.: 53.91%] [G loss: 0.835610]\n",
      "epoch:16 step:15321 [D loss: 0.678492, acc.: 57.03%] [G loss: 0.868017]\n",
      "epoch:16 step:15322 [D loss: 0.666081, acc.: 56.25%] [G loss: 0.885137]\n",
      "epoch:16 step:15323 [D loss: 0.660636, acc.: 60.94%] [G loss: 0.848809]\n",
      "epoch:16 step:15324 [D loss: 0.652475, acc.: 64.84%] [G loss: 0.846218]\n",
      "epoch:16 step:15325 [D loss: 0.665729, acc.: 54.69%] [G loss: 0.857465]\n",
      "epoch:16 step:15326 [D loss: 0.658912, acc.: 59.38%] [G loss: 0.886196]\n",
      "epoch:16 step:15327 [D loss: 0.733557, acc.: 50.78%] [G loss: 0.871240]\n",
      "epoch:16 step:15328 [D loss: 0.633056, acc.: 67.97%] [G loss: 0.871833]\n",
      "epoch:16 step:15329 [D loss: 0.636809, acc.: 59.38%] [G loss: 0.854526]\n",
      "epoch:16 step:15330 [D loss: 0.645879, acc.: 63.28%] [G loss: 0.883758]\n",
      "epoch:16 step:15331 [D loss: 0.653027, acc.: 66.41%] [G loss: 0.885501]\n",
      "epoch:16 step:15332 [D loss: 0.660367, acc.: 60.94%] [G loss: 0.816691]\n",
      "epoch:16 step:15333 [D loss: 0.673312, acc.: 59.38%] [G loss: 0.881388]\n",
      "epoch:16 step:15334 [D loss: 0.672258, acc.: 60.16%] [G loss: 0.846044]\n",
      "epoch:16 step:15335 [D loss: 0.713297, acc.: 45.31%] [G loss: 0.903037]\n",
      "epoch:16 step:15336 [D loss: 0.644817, acc.: 67.97%] [G loss: 0.965120]\n",
      "epoch:16 step:15337 [D loss: 0.640842, acc.: 64.84%] [G loss: 0.913701]\n",
      "epoch:16 step:15338 [D loss: 0.672112, acc.: 60.16%] [G loss: 0.909138]\n",
      "epoch:16 step:15339 [D loss: 0.644038, acc.: 61.72%] [G loss: 0.858809]\n",
      "epoch:16 step:15340 [D loss: 0.642456, acc.: 67.19%] [G loss: 0.855112]\n",
      "epoch:16 step:15341 [D loss: 0.621743, acc.: 67.97%] [G loss: 0.852754]\n",
      "epoch:16 step:15342 [D loss: 0.657372, acc.: 60.16%] [G loss: 0.879248]\n",
      "epoch:16 step:15343 [D loss: 0.641875, acc.: 58.59%] [G loss: 0.899424]\n",
      "epoch:16 step:15344 [D loss: 0.677962, acc.: 53.91%] [G loss: 0.868197]\n",
      "epoch:16 step:15345 [D loss: 0.664498, acc.: 58.59%] [G loss: 0.875839]\n",
      "epoch:16 step:15346 [D loss: 0.668455, acc.: 57.03%] [G loss: 0.822401]\n",
      "epoch:16 step:15347 [D loss: 0.656042, acc.: 63.28%] [G loss: 0.845407]\n",
      "epoch:16 step:15348 [D loss: 0.661772, acc.: 57.81%] [G loss: 0.858169]\n",
      "epoch:16 step:15349 [D loss: 0.671251, acc.: 58.59%] [G loss: 0.830257]\n",
      "epoch:16 step:15350 [D loss: 0.651783, acc.: 60.16%] [G loss: 0.867012]\n",
      "epoch:16 step:15351 [D loss: 0.690067, acc.: 57.03%] [G loss: 0.816315]\n",
      "epoch:16 step:15352 [D loss: 0.649758, acc.: 61.72%] [G loss: 0.860702]\n",
      "epoch:16 step:15353 [D loss: 0.691473, acc.: 56.25%] [G loss: 0.966802]\n",
      "epoch:16 step:15354 [D loss: 0.688113, acc.: 51.56%] [G loss: 0.835917]\n",
      "epoch:16 step:15355 [D loss: 0.691185, acc.: 57.81%] [G loss: 0.847609]\n",
      "epoch:16 step:15356 [D loss: 0.683934, acc.: 55.47%] [G loss: 0.925313]\n",
      "epoch:16 step:15357 [D loss: 0.657599, acc.: 59.38%] [G loss: 0.918647]\n",
      "epoch:16 step:15358 [D loss: 0.688009, acc.: 54.69%] [G loss: 0.924288]\n",
      "epoch:16 step:15359 [D loss: 0.674801, acc.: 57.81%] [G loss: 0.900729]\n",
      "epoch:16 step:15360 [D loss: 0.682062, acc.: 57.03%] [G loss: 0.886007]\n",
      "epoch:16 step:15361 [D loss: 0.656896, acc.: 67.19%] [G loss: 0.856163]\n",
      "epoch:16 step:15362 [D loss: 0.665034, acc.: 59.38%] [G loss: 0.875328]\n",
      "epoch:16 step:15363 [D loss: 0.684813, acc.: 56.25%] [G loss: 0.877656]\n",
      "epoch:16 step:15364 [D loss: 0.638282, acc.: 64.06%] [G loss: 0.846137]\n",
      "epoch:16 step:15365 [D loss: 0.667088, acc.: 57.81%] [G loss: 0.845726]\n",
      "epoch:16 step:15366 [D loss: 0.671683, acc.: 50.78%] [G loss: 0.848996]\n",
      "epoch:16 step:15367 [D loss: 0.718185, acc.: 53.12%] [G loss: 0.795601]\n",
      "epoch:16 step:15368 [D loss: 0.702383, acc.: 57.03%] [G loss: 0.812482]\n",
      "epoch:16 step:15369 [D loss: 0.672094, acc.: 60.16%] [G loss: 0.890335]\n",
      "epoch:16 step:15370 [D loss: 0.628882, acc.: 65.62%] [G loss: 0.905086]\n",
      "epoch:16 step:15371 [D loss: 0.641663, acc.: 58.59%] [G loss: 0.866591]\n",
      "epoch:16 step:15372 [D loss: 0.641088, acc.: 64.06%] [G loss: 0.876707]\n",
      "epoch:16 step:15373 [D loss: 0.659228, acc.: 58.59%] [G loss: 0.870175]\n",
      "epoch:16 step:15374 [D loss: 0.650488, acc.: 64.06%] [G loss: 0.846738]\n",
      "epoch:16 step:15375 [D loss: 0.644233, acc.: 64.84%] [G loss: 0.816445]\n",
      "epoch:16 step:15376 [D loss: 0.680385, acc.: 53.12%] [G loss: 0.849216]\n",
      "epoch:16 step:15377 [D loss: 0.701020, acc.: 55.47%] [G loss: 0.788693]\n",
      "epoch:16 step:15378 [D loss: 0.701717, acc.: 55.47%] [G loss: 0.845592]\n",
      "epoch:16 step:15379 [D loss: 0.674342, acc.: 60.94%] [G loss: 0.856611]\n",
      "epoch:16 step:15380 [D loss: 0.670119, acc.: 57.81%] [G loss: 0.904824]\n",
      "epoch:16 step:15381 [D loss: 0.668203, acc.: 58.59%] [G loss: 0.862891]\n",
      "epoch:16 step:15382 [D loss: 0.666270, acc.: 64.06%] [G loss: 0.856301]\n",
      "epoch:16 step:15383 [D loss: 0.662259, acc.: 60.94%] [G loss: 0.851973]\n",
      "epoch:16 step:15384 [D loss: 0.668383, acc.: 61.72%] [G loss: 0.916664]\n",
      "epoch:16 step:15385 [D loss: 0.702674, acc.: 55.47%] [G loss: 0.867475]\n",
      "epoch:16 step:15386 [D loss: 0.646883, acc.: 61.72%] [G loss: 0.864512]\n",
      "epoch:16 step:15387 [D loss: 0.671355, acc.: 54.69%] [G loss: 0.810666]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15388 [D loss: 0.644867, acc.: 58.59%] [G loss: 0.819357]\n",
      "epoch:16 step:15389 [D loss: 0.698683, acc.: 58.59%] [G loss: 0.821799]\n",
      "epoch:16 step:15390 [D loss: 0.696419, acc.: 52.34%] [G loss: 0.837624]\n",
      "epoch:16 step:15391 [D loss: 0.655503, acc.: 60.16%] [G loss: 0.876280]\n",
      "epoch:16 step:15392 [D loss: 0.660755, acc.: 65.62%] [G loss: 0.840513]\n",
      "epoch:16 step:15393 [D loss: 0.637684, acc.: 64.06%] [G loss: 0.895793]\n",
      "epoch:16 step:15394 [D loss: 0.604332, acc.: 71.88%] [G loss: 0.874112]\n",
      "epoch:16 step:15395 [D loss: 0.685486, acc.: 57.81%] [G loss: 0.882574]\n",
      "epoch:16 step:15396 [D loss: 0.632853, acc.: 64.06%] [G loss: 0.884179]\n",
      "epoch:16 step:15397 [D loss: 0.674061, acc.: 53.12%] [G loss: 0.866016]\n",
      "epoch:16 step:15398 [D loss: 0.652152, acc.: 57.81%] [G loss: 0.829421]\n",
      "epoch:16 step:15399 [D loss: 0.647828, acc.: 60.16%] [G loss: 0.917311]\n",
      "epoch:16 step:15400 [D loss: 0.653423, acc.: 60.94%] [G loss: 0.867106]\n",
      "##############\n",
      "[3.05870218 2.58830851 2.3564642  3.62090162 1.5250367  9.27426719\n",
      " 2.55774099 3.68385635 4.26987106 5.91436637]\n",
      "##########\n",
      "epoch:16 step:15401 [D loss: 0.662955, acc.: 59.38%] [G loss: 0.790872]\n",
      "epoch:16 step:15402 [D loss: 0.663602, acc.: 58.59%] [G loss: 0.815148]\n",
      "epoch:16 step:15403 [D loss: 0.634882, acc.: 65.62%] [G loss: 0.915992]\n",
      "epoch:16 step:15404 [D loss: 0.648928, acc.: 64.84%] [G loss: 0.862110]\n",
      "epoch:16 step:15405 [D loss: 0.671911, acc.: 58.59%] [G loss: 0.840253]\n",
      "epoch:16 step:15406 [D loss: 0.660366, acc.: 60.16%] [G loss: 0.900041]\n",
      "epoch:16 step:15407 [D loss: 0.664326, acc.: 57.81%] [G loss: 0.848197]\n",
      "epoch:16 step:15408 [D loss: 0.634698, acc.: 64.06%] [G loss: 0.830096]\n",
      "epoch:16 step:15409 [D loss: 0.613176, acc.: 64.84%] [G loss: 0.874651]\n",
      "epoch:16 step:15410 [D loss: 0.668117, acc.: 55.47%] [G loss: 0.875921]\n",
      "epoch:16 step:15411 [D loss: 0.661369, acc.: 64.06%] [G loss: 0.851528]\n",
      "epoch:16 step:15412 [D loss: 0.658467, acc.: 58.59%] [G loss: 0.877615]\n",
      "epoch:16 step:15413 [D loss: 0.660989, acc.: 60.16%] [G loss: 0.896698]\n",
      "epoch:16 step:15414 [D loss: 0.669458, acc.: 59.38%] [G loss: 0.912255]\n",
      "epoch:16 step:15415 [D loss: 0.628503, acc.: 66.41%] [G loss: 0.841817]\n",
      "epoch:16 step:15416 [D loss: 0.650277, acc.: 59.38%] [G loss: 0.809756]\n",
      "epoch:16 step:15417 [D loss: 0.692704, acc.: 56.25%] [G loss: 0.904455]\n",
      "epoch:16 step:15418 [D loss: 0.651581, acc.: 63.28%] [G loss: 0.867354]\n",
      "epoch:16 step:15419 [D loss: 0.666932, acc.: 53.91%] [G loss: 0.832895]\n",
      "epoch:16 step:15420 [D loss: 0.691058, acc.: 50.78%] [G loss: 0.832323]\n",
      "epoch:16 step:15421 [D loss: 0.652495, acc.: 61.72%] [G loss: 0.830680]\n",
      "epoch:16 step:15422 [D loss: 0.700900, acc.: 54.69%] [G loss: 0.793808]\n",
      "epoch:16 step:15423 [D loss: 0.709051, acc.: 54.69%] [G loss: 0.867409]\n",
      "epoch:16 step:15424 [D loss: 0.641765, acc.: 64.06%] [G loss: 0.939824]\n",
      "epoch:16 step:15425 [D loss: 0.674838, acc.: 57.03%] [G loss: 0.972293]\n",
      "epoch:16 step:15426 [D loss: 0.644630, acc.: 64.84%] [G loss: 0.963656]\n",
      "epoch:16 step:15427 [D loss: 0.624938, acc.: 73.44%] [G loss: 0.875679]\n",
      "epoch:16 step:15428 [D loss: 0.670992, acc.: 62.50%] [G loss: 0.842703]\n",
      "epoch:16 step:15429 [D loss: 0.682138, acc.: 56.25%] [G loss: 0.890191]\n",
      "epoch:16 step:15430 [D loss: 0.682366, acc.: 57.81%] [G loss: 0.878635]\n",
      "epoch:16 step:15431 [D loss: 0.640295, acc.: 63.28%] [G loss: 0.894218]\n",
      "epoch:16 step:15432 [D loss: 0.682407, acc.: 55.47%] [G loss: 0.880441]\n",
      "epoch:16 step:15433 [D loss: 0.675827, acc.: 60.16%] [G loss: 0.871530]\n",
      "epoch:16 step:15434 [D loss: 0.645806, acc.: 62.50%] [G loss: 0.893584]\n",
      "epoch:16 step:15435 [D loss: 0.676967, acc.: 57.03%] [G loss: 0.872634]\n",
      "epoch:16 step:15436 [D loss: 0.673170, acc.: 57.81%] [G loss: 0.834292]\n",
      "epoch:16 step:15437 [D loss: 0.627072, acc.: 67.97%] [G loss: 0.862482]\n",
      "epoch:16 step:15438 [D loss: 0.676099, acc.: 52.34%] [G loss: 0.828771]\n",
      "epoch:16 step:15439 [D loss: 0.644082, acc.: 57.03%] [G loss: 0.918860]\n",
      "epoch:16 step:15440 [D loss: 0.672653, acc.: 59.38%] [G loss: 0.865592]\n",
      "epoch:16 step:15441 [D loss: 0.648083, acc.: 65.62%] [G loss: 0.875870]\n",
      "epoch:16 step:15442 [D loss: 0.631702, acc.: 65.62%] [G loss: 0.892085]\n",
      "epoch:16 step:15443 [D loss: 0.663523, acc.: 57.81%] [G loss: 0.839129]\n",
      "epoch:16 step:15444 [D loss: 0.680051, acc.: 48.44%] [G loss: 0.853976]\n",
      "epoch:16 step:15445 [D loss: 0.657526, acc.: 62.50%] [G loss: 0.853467]\n",
      "epoch:16 step:15446 [D loss: 0.686502, acc.: 57.81%] [G loss: 0.832245]\n",
      "epoch:16 step:15447 [D loss: 0.652335, acc.: 61.72%] [G loss: 0.866929]\n",
      "epoch:16 step:15448 [D loss: 0.662290, acc.: 62.50%] [G loss: 0.804709]\n",
      "epoch:16 step:15449 [D loss: 0.665853, acc.: 62.50%] [G loss: 0.834369]\n",
      "epoch:16 step:15450 [D loss: 0.666231, acc.: 57.03%] [G loss: 0.870098]\n",
      "epoch:16 step:15451 [D loss: 0.624586, acc.: 64.06%] [G loss: 0.838331]\n",
      "epoch:16 step:15452 [D loss: 0.636332, acc.: 60.16%] [G loss: 0.891936]\n",
      "epoch:16 step:15453 [D loss: 0.647314, acc.: 63.28%] [G loss: 0.889875]\n",
      "epoch:16 step:15454 [D loss: 0.715806, acc.: 45.31%] [G loss: 0.935293]\n",
      "epoch:16 step:15455 [D loss: 0.641834, acc.: 63.28%] [G loss: 0.912048]\n",
      "epoch:16 step:15456 [D loss: 0.648191, acc.: 60.16%] [G loss: 0.892094]\n",
      "epoch:16 step:15457 [D loss: 0.675373, acc.: 60.16%] [G loss: 0.956002]\n",
      "epoch:16 step:15458 [D loss: 0.661935, acc.: 57.81%] [G loss: 0.849515]\n",
      "epoch:16 step:15459 [D loss: 0.639806, acc.: 63.28%] [G loss: 0.873327]\n",
      "epoch:16 step:15460 [D loss: 0.675951, acc.: 57.03%] [G loss: 0.857771]\n",
      "epoch:16 step:15461 [D loss: 0.624587, acc.: 67.19%] [G loss: 0.893487]\n",
      "epoch:16 step:15462 [D loss: 0.665700, acc.: 53.12%] [G loss: 0.839857]\n",
      "epoch:16 step:15463 [D loss: 0.626651, acc.: 67.19%] [G loss: 0.861803]\n",
      "epoch:16 step:15464 [D loss: 0.668386, acc.: 62.50%] [G loss: 0.857525]\n",
      "epoch:16 step:15465 [D loss: 0.656962, acc.: 61.72%] [G loss: 0.847640]\n",
      "epoch:16 step:15466 [D loss: 0.618277, acc.: 69.53%] [G loss: 0.891004]\n",
      "epoch:16 step:15467 [D loss: 0.651102, acc.: 63.28%] [G loss: 0.915044]\n",
      "epoch:16 step:15468 [D loss: 0.655822, acc.: 67.19%] [G loss: 0.915649]\n",
      "epoch:16 step:15469 [D loss: 0.685208, acc.: 56.25%] [G loss: 0.943754]\n",
      "epoch:16 step:15470 [D loss: 0.696184, acc.: 60.16%] [G loss: 0.914289]\n",
      "epoch:16 step:15471 [D loss: 0.659434, acc.: 53.91%] [G loss: 0.878241]\n",
      "epoch:16 step:15472 [D loss: 0.709602, acc.: 53.12%] [G loss: 0.898908]\n",
      "epoch:16 step:15473 [D loss: 0.673990, acc.: 58.59%] [G loss: 0.870789]\n",
      "epoch:16 step:15474 [D loss: 0.685209, acc.: 55.47%] [G loss: 0.838814]\n",
      "epoch:16 step:15475 [D loss: 0.692783, acc.: 53.12%] [G loss: 0.812955]\n",
      "epoch:16 step:15476 [D loss: 0.670367, acc.: 56.25%] [G loss: 0.910972]\n",
      "epoch:16 step:15477 [D loss: 0.678796, acc.: 59.38%] [G loss: 0.923253]\n",
      "epoch:16 step:15478 [D loss: 0.674612, acc.: 56.25%] [G loss: 0.892116]\n",
      "epoch:16 step:15479 [D loss: 0.673769, acc.: 58.59%] [G loss: 0.877288]\n",
      "epoch:16 step:15480 [D loss: 0.628639, acc.: 64.84%] [G loss: 0.882953]\n",
      "epoch:16 step:15481 [D loss: 0.645538, acc.: 66.41%] [G loss: 0.915641]\n",
      "epoch:16 step:15482 [D loss: 0.677047, acc.: 59.38%] [G loss: 0.870425]\n",
      "epoch:16 step:15483 [D loss: 0.681876, acc.: 56.25%] [G loss: 0.831956]\n",
      "epoch:16 step:15484 [D loss: 0.663804, acc.: 61.72%] [G loss: 0.823338]\n",
      "epoch:16 step:15485 [D loss: 0.700885, acc.: 48.44%] [G loss: 0.853031]\n",
      "epoch:16 step:15486 [D loss: 0.664553, acc.: 53.91%] [G loss: 0.855309]\n",
      "epoch:16 step:15487 [D loss: 0.673661, acc.: 56.25%] [G loss: 0.836496]\n",
      "epoch:16 step:15488 [D loss: 0.668496, acc.: 53.91%] [G loss: 0.865315]\n",
      "epoch:16 step:15489 [D loss: 0.660890, acc.: 60.16%] [G loss: 0.844481]\n",
      "epoch:16 step:15490 [D loss: 0.668440, acc.: 60.16%] [G loss: 0.846426]\n",
      "epoch:16 step:15491 [D loss: 0.708786, acc.: 50.78%] [G loss: 0.845763]\n",
      "epoch:16 step:15492 [D loss: 0.671634, acc.: 57.81%] [G loss: 0.882108]\n",
      "epoch:16 step:15493 [D loss: 0.661037, acc.: 53.12%] [G loss: 0.870015]\n",
      "epoch:16 step:15494 [D loss: 0.677185, acc.: 53.12%] [G loss: 0.886513]\n",
      "epoch:16 step:15495 [D loss: 0.670522, acc.: 50.00%] [G loss: 0.829534]\n",
      "epoch:16 step:15496 [D loss: 0.704700, acc.: 53.12%] [G loss: 0.845596]\n",
      "epoch:16 step:15497 [D loss: 0.643741, acc.: 64.84%] [G loss: 0.850436]\n",
      "epoch:16 step:15498 [D loss: 0.674547, acc.: 57.81%] [G loss: 0.904751]\n",
      "epoch:16 step:15499 [D loss: 0.666846, acc.: 63.28%] [G loss: 0.808321]\n",
      "epoch:16 step:15500 [D loss: 0.659805, acc.: 59.38%] [G loss: 0.883066]\n",
      "epoch:16 step:15501 [D loss: 0.639933, acc.: 64.06%] [G loss: 0.834167]\n",
      "epoch:16 step:15502 [D loss: 0.646128, acc.: 61.72%] [G loss: 0.867905]\n",
      "epoch:16 step:15503 [D loss: 0.665548, acc.: 61.72%] [G loss: 0.915533]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15504 [D loss: 0.712873, acc.: 54.69%] [G loss: 0.856524]\n",
      "epoch:16 step:15505 [D loss: 0.663381, acc.: 59.38%] [G loss: 0.874036]\n",
      "epoch:16 step:15506 [D loss: 0.678446, acc.: 53.91%] [G loss: 0.838352]\n",
      "epoch:16 step:15507 [D loss: 0.650835, acc.: 64.84%] [G loss: 0.829714]\n",
      "epoch:16 step:15508 [D loss: 0.671042, acc.: 56.25%] [G loss: 0.909110]\n",
      "epoch:16 step:15509 [D loss: 0.674761, acc.: 58.59%] [G loss: 0.892435]\n",
      "epoch:16 step:15510 [D loss: 0.701799, acc.: 52.34%] [G loss: 0.853603]\n",
      "epoch:16 step:15511 [D loss: 0.621985, acc.: 68.75%] [G loss: 0.844462]\n",
      "epoch:16 step:15512 [D loss: 0.665310, acc.: 64.06%] [G loss: 0.858217]\n",
      "epoch:16 step:15513 [D loss: 0.629348, acc.: 60.94%] [G loss: 0.874290]\n",
      "epoch:16 step:15514 [D loss: 0.606633, acc.: 73.44%] [G loss: 0.881287]\n",
      "epoch:16 step:15515 [D loss: 0.629239, acc.: 64.06%] [G loss: 0.891779]\n",
      "epoch:16 step:15516 [D loss: 0.606981, acc.: 69.53%] [G loss: 0.817142]\n",
      "epoch:16 step:15517 [D loss: 0.678257, acc.: 53.91%] [G loss: 0.882475]\n",
      "epoch:16 step:15518 [D loss: 0.670993, acc.: 59.38%] [G loss: 0.837174]\n",
      "epoch:16 step:15519 [D loss: 0.645073, acc.: 62.50%] [G loss: 0.865914]\n",
      "epoch:16 step:15520 [D loss: 0.659831, acc.: 63.28%] [G loss: 0.869767]\n",
      "epoch:16 step:15521 [D loss: 0.647162, acc.: 62.50%] [G loss: 0.885124]\n",
      "epoch:16 step:15522 [D loss: 0.649646, acc.: 57.81%] [G loss: 0.910758]\n",
      "epoch:16 step:15523 [D loss: 0.683339, acc.: 56.25%] [G loss: 0.858132]\n",
      "epoch:16 step:15524 [D loss: 0.702994, acc.: 54.69%] [G loss: 0.833561]\n",
      "epoch:16 step:15525 [D loss: 0.673784, acc.: 57.03%] [G loss: 0.893719]\n",
      "epoch:16 step:15526 [D loss: 0.676988, acc.: 57.03%] [G loss: 0.858328]\n",
      "epoch:16 step:15527 [D loss: 0.688290, acc.: 57.03%] [G loss: 0.880731]\n",
      "epoch:16 step:15528 [D loss: 0.674072, acc.: 55.47%] [G loss: 0.844444]\n",
      "epoch:16 step:15529 [D loss: 0.663001, acc.: 61.72%] [G loss: 0.835002]\n",
      "epoch:16 step:15530 [D loss: 0.657502, acc.: 62.50%] [G loss: 0.848856]\n",
      "epoch:16 step:15531 [D loss: 0.717957, acc.: 50.78%] [G loss: 0.877075]\n",
      "epoch:16 step:15532 [D loss: 0.610390, acc.: 69.53%] [G loss: 0.813974]\n",
      "epoch:16 step:15533 [D loss: 0.691252, acc.: 57.03%] [G loss: 0.879282]\n",
      "epoch:16 step:15534 [D loss: 0.662308, acc.: 66.41%] [G loss: 0.915570]\n",
      "epoch:16 step:15535 [D loss: 0.651079, acc.: 62.50%] [G loss: 0.825585]\n",
      "epoch:16 step:15536 [D loss: 0.648220, acc.: 60.16%] [G loss: 0.839651]\n",
      "epoch:16 step:15537 [D loss: 0.679382, acc.: 60.16%] [G loss: 0.878514]\n",
      "epoch:16 step:15538 [D loss: 0.624758, acc.: 67.19%] [G loss: 0.837636]\n",
      "epoch:16 step:15539 [D loss: 0.683574, acc.: 56.25%] [G loss: 0.879449]\n",
      "epoch:16 step:15540 [D loss: 0.685600, acc.: 55.47%] [G loss: 0.830010]\n",
      "epoch:16 step:15541 [D loss: 0.636810, acc.: 60.94%] [G loss: 0.826138]\n",
      "epoch:16 step:15542 [D loss: 0.711437, acc.: 53.91%] [G loss: 0.819986]\n",
      "epoch:16 step:15543 [D loss: 0.678473, acc.: 55.47%] [G loss: 0.802476]\n",
      "epoch:16 step:15544 [D loss: 0.709129, acc.: 51.56%] [G loss: 0.854543]\n",
      "epoch:16 step:15545 [D loss: 0.677517, acc.: 57.03%] [G loss: 0.873042]\n",
      "epoch:16 step:15546 [D loss: 0.643217, acc.: 64.06%] [G loss: 0.871393]\n",
      "epoch:16 step:15547 [D loss: 0.630121, acc.: 66.41%] [G loss: 0.851826]\n",
      "epoch:16 step:15548 [D loss: 0.684930, acc.: 55.47%] [G loss: 0.844621]\n",
      "epoch:16 step:15549 [D loss: 0.665439, acc.: 62.50%] [G loss: 0.847982]\n",
      "epoch:16 step:15550 [D loss: 0.680048, acc.: 53.12%] [G loss: 0.859510]\n",
      "epoch:16 step:15551 [D loss: 0.669751, acc.: 59.38%] [G loss: 0.885932]\n",
      "epoch:16 step:15552 [D loss: 0.662877, acc.: 60.16%] [G loss: 0.845083]\n",
      "epoch:16 step:15553 [D loss: 0.678241, acc.: 55.47%] [G loss: 0.873908]\n",
      "epoch:16 step:15554 [D loss: 0.687168, acc.: 59.38%] [G loss: 0.857434]\n",
      "epoch:16 step:15555 [D loss: 0.651102, acc.: 62.50%] [G loss: 0.877223]\n",
      "epoch:16 step:15556 [D loss: 0.654686, acc.: 60.16%] [G loss: 0.847592]\n",
      "epoch:16 step:15557 [D loss: 0.672733, acc.: 63.28%] [G loss: 0.868637]\n",
      "epoch:16 step:15558 [D loss: 0.627020, acc.: 61.72%] [G loss: 0.863480]\n",
      "epoch:16 step:15559 [D loss: 0.654672, acc.: 62.50%] [G loss: 0.903121]\n",
      "epoch:16 step:15560 [D loss: 0.706048, acc.: 55.47%] [G loss: 0.899017]\n",
      "epoch:16 step:15561 [D loss: 0.642940, acc.: 64.06%] [G loss: 0.903054]\n",
      "epoch:16 step:15562 [D loss: 0.674758, acc.: 56.25%] [G loss: 0.878807]\n",
      "epoch:16 step:15563 [D loss: 0.669310, acc.: 57.81%] [G loss: 0.888980]\n",
      "epoch:16 step:15564 [D loss: 0.670286, acc.: 57.81%] [G loss: 0.842218]\n",
      "epoch:16 step:15565 [D loss: 0.697409, acc.: 50.00%] [G loss: 0.843553]\n",
      "epoch:16 step:15566 [D loss: 0.666027, acc.: 58.59%] [G loss: 0.872567]\n",
      "epoch:16 step:15567 [D loss: 0.663919, acc.: 60.94%] [G loss: 0.946188]\n",
      "epoch:16 step:15568 [D loss: 0.636215, acc.: 65.62%] [G loss: 0.870793]\n",
      "epoch:16 step:15569 [D loss: 0.647367, acc.: 62.50%] [G loss: 0.850496]\n",
      "epoch:16 step:15570 [D loss: 0.674133, acc.: 58.59%] [G loss: 0.883384]\n",
      "epoch:16 step:15571 [D loss: 0.668403, acc.: 57.03%] [G loss: 0.834771]\n",
      "epoch:16 step:15572 [D loss: 0.679213, acc.: 53.91%] [G loss: 0.887593]\n",
      "epoch:16 step:15573 [D loss: 0.704251, acc.: 50.00%] [G loss: 0.869391]\n",
      "epoch:16 step:15574 [D loss: 0.626311, acc.: 68.75%] [G loss: 0.854240]\n",
      "epoch:16 step:15575 [D loss: 0.662002, acc.: 59.38%] [G loss: 0.832128]\n",
      "epoch:16 step:15576 [D loss: 0.627292, acc.: 60.94%] [G loss: 0.885761]\n",
      "epoch:16 step:15577 [D loss: 0.686883, acc.: 55.47%] [G loss: 0.896158]\n",
      "epoch:16 step:15578 [D loss: 0.674195, acc.: 58.59%] [G loss: 0.859298]\n",
      "epoch:16 step:15579 [D loss: 0.671738, acc.: 64.06%] [G loss: 0.843806]\n",
      "epoch:16 step:15580 [D loss: 0.669755, acc.: 56.25%] [G loss: 0.821017]\n",
      "epoch:16 step:15581 [D loss: 0.664771, acc.: 61.72%] [G loss: 0.862487]\n",
      "epoch:16 step:15582 [D loss: 0.685347, acc.: 55.47%] [G loss: 0.853600]\n",
      "epoch:16 step:15583 [D loss: 0.671795, acc.: 57.81%] [G loss: 0.892552]\n",
      "epoch:16 step:15584 [D loss: 0.646396, acc.: 62.50%] [G loss: 0.922122]\n",
      "epoch:16 step:15585 [D loss: 0.697808, acc.: 53.12%] [G loss: 0.832152]\n",
      "epoch:16 step:15586 [D loss: 0.635534, acc.: 65.62%] [G loss: 0.833227]\n",
      "epoch:16 step:15587 [D loss: 0.664691, acc.: 62.50%] [G loss: 0.837584]\n",
      "epoch:16 step:15588 [D loss: 0.651181, acc.: 59.38%] [G loss: 0.865719]\n",
      "epoch:16 step:15589 [D loss: 0.657171, acc.: 60.94%] [G loss: 0.873486]\n",
      "epoch:16 step:15590 [D loss: 0.638643, acc.: 62.50%] [G loss: 0.884504]\n",
      "epoch:16 step:15591 [D loss: 0.642119, acc.: 67.97%] [G loss: 0.865683]\n",
      "epoch:16 step:15592 [D loss: 0.670309, acc.: 57.03%] [G loss: 0.862752]\n",
      "epoch:16 step:15593 [D loss: 0.691588, acc.: 54.69%] [G loss: 0.867821]\n",
      "epoch:16 step:15594 [D loss: 0.604367, acc.: 67.97%] [G loss: 0.826535]\n",
      "epoch:16 step:15595 [D loss: 0.679790, acc.: 57.81%] [G loss: 0.855945]\n",
      "epoch:16 step:15596 [D loss: 0.690536, acc.: 56.25%] [G loss: 0.870594]\n",
      "epoch:16 step:15597 [D loss: 0.689860, acc.: 55.47%] [G loss: 0.844612]\n",
      "epoch:16 step:15598 [D loss: 0.651441, acc.: 62.50%] [G loss: 0.839831]\n",
      "epoch:16 step:15599 [D loss: 0.654656, acc.: 64.06%] [G loss: 0.836692]\n",
      "epoch:16 step:15600 [D loss: 0.686502, acc.: 57.03%] [G loss: 0.833417]\n",
      "##############\n",
      "[3.27278521 2.4195415  2.20107544 3.69250829 1.20083744 7.5706502\n",
      " 2.66532628 3.95254478 4.45777018 6.58148046]\n",
      "##########\n",
      "epoch:16 step:15601 [D loss: 0.658886, acc.: 59.38%] [G loss: 0.862689]\n",
      "epoch:16 step:15602 [D loss: 0.654521, acc.: 65.62%] [G loss: 0.851176]\n",
      "epoch:16 step:15603 [D loss: 0.660213, acc.: 65.62%] [G loss: 0.852984]\n",
      "epoch:16 step:15604 [D loss: 0.667083, acc.: 57.03%] [G loss: 0.851404]\n",
      "epoch:16 step:15605 [D loss: 0.686747, acc.: 57.03%] [G loss: 0.856554]\n",
      "epoch:16 step:15606 [D loss: 0.701427, acc.: 50.00%] [G loss: 0.862121]\n",
      "epoch:16 step:15607 [D loss: 0.725420, acc.: 50.78%] [G loss: 0.888021]\n",
      "epoch:16 step:15608 [D loss: 0.657326, acc.: 58.59%] [G loss: 0.898720]\n",
      "epoch:16 step:15609 [D loss: 0.674629, acc.: 52.34%] [G loss: 0.850513]\n",
      "epoch:16 step:15610 [D loss: 0.655475, acc.: 62.50%] [G loss: 0.876448]\n",
      "epoch:16 step:15611 [D loss: 0.673177, acc.: 55.47%] [G loss: 0.893726]\n",
      "epoch:16 step:15612 [D loss: 0.680553, acc.: 51.56%] [G loss: 0.809307]\n",
      "epoch:16 step:15613 [D loss: 0.717308, acc.: 48.44%] [G loss: 0.827430]\n",
      "epoch:16 step:15614 [D loss: 0.686376, acc.: 59.38%] [G loss: 0.857679]\n",
      "epoch:16 step:15615 [D loss: 0.641177, acc.: 62.50%] [G loss: 0.878708]\n",
      "epoch:16 step:15616 [D loss: 0.668345, acc.: 60.16%] [G loss: 0.911359]\n",
      "epoch:16 step:15617 [D loss: 0.688642, acc.: 54.69%] [G loss: 0.886767]\n",
      "epoch:16 step:15618 [D loss: 0.682042, acc.: 57.03%] [G loss: 0.886029]\n",
      "epoch:16 step:15619 [D loss: 0.628483, acc.: 64.84%] [G loss: 0.872182]\n",
      "epoch:16 step:15620 [D loss: 0.670943, acc.: 53.91%] [G loss: 0.914929]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15621 [D loss: 0.676833, acc.: 57.03%] [G loss: 0.813678]\n",
      "epoch:16 step:15622 [D loss: 0.698850, acc.: 50.00%] [G loss: 0.821460]\n",
      "epoch:16 step:15623 [D loss: 0.675993, acc.: 58.59%] [G loss: 0.841357]\n",
      "epoch:16 step:15624 [D loss: 0.668220, acc.: 56.25%] [G loss: 0.888262]\n",
      "epoch:16 step:15625 [D loss: 0.670151, acc.: 60.16%] [G loss: 0.813970]\n",
      "epoch:16 step:15626 [D loss: 0.658335, acc.: 61.72%] [G loss: 0.849363]\n",
      "epoch:16 step:15627 [D loss: 0.645438, acc.: 67.19%] [G loss: 0.872799]\n",
      "epoch:16 step:15628 [D loss: 0.639356, acc.: 66.41%] [G loss: 0.895435]\n",
      "epoch:16 step:15629 [D loss: 0.648075, acc.: 60.16%] [G loss: 0.859902]\n",
      "epoch:16 step:15630 [D loss: 0.637625, acc.: 64.06%] [G loss: 0.831698]\n",
      "epoch:16 step:15631 [D loss: 0.658442, acc.: 63.28%] [G loss: 0.845818]\n",
      "epoch:16 step:15632 [D loss: 0.678008, acc.: 57.81%] [G loss: 0.782169]\n",
      "epoch:16 step:15633 [D loss: 0.699132, acc.: 60.94%] [G loss: 0.854305]\n",
      "epoch:16 step:15634 [D loss: 0.653670, acc.: 64.06%] [G loss: 0.850669]\n",
      "epoch:16 step:15635 [D loss: 0.710252, acc.: 54.69%] [G loss: 0.867901]\n",
      "epoch:16 step:15636 [D loss: 0.656319, acc.: 62.50%] [G loss: 0.889421]\n",
      "epoch:16 step:15637 [D loss: 0.656079, acc.: 68.75%] [G loss: 0.842639]\n",
      "epoch:16 step:15638 [D loss: 0.684543, acc.: 55.47%] [G loss: 0.849148]\n",
      "epoch:16 step:15639 [D loss: 0.693539, acc.: 53.91%] [G loss: 0.816985]\n",
      "epoch:16 step:15640 [D loss: 0.634070, acc.: 69.53%] [G loss: 0.828016]\n",
      "epoch:16 step:15641 [D loss: 0.667513, acc.: 58.59%] [G loss: 0.855763]\n",
      "epoch:16 step:15642 [D loss: 0.707115, acc.: 50.78%] [G loss: 0.784081]\n",
      "epoch:16 step:15643 [D loss: 0.628225, acc.: 64.06%] [G loss: 0.817589]\n",
      "epoch:16 step:15644 [D loss: 0.638260, acc.: 65.62%] [G loss: 0.794832]\n",
      "epoch:16 step:15645 [D loss: 0.674198, acc.: 54.69%] [G loss: 0.834232]\n",
      "epoch:16 step:15646 [D loss: 0.647746, acc.: 61.72%] [G loss: 0.807788]\n",
      "epoch:16 step:15647 [D loss: 0.682889, acc.: 57.81%] [G loss: 0.859063]\n",
      "epoch:16 step:15648 [D loss: 0.654165, acc.: 57.81%] [G loss: 0.834747]\n",
      "epoch:16 step:15649 [D loss: 0.673963, acc.: 57.81%] [G loss: 0.812370]\n",
      "epoch:16 step:15650 [D loss: 0.713993, acc.: 46.88%] [G loss: 0.912986]\n",
      "epoch:16 step:15651 [D loss: 0.671971, acc.: 62.50%] [G loss: 0.858708]\n",
      "epoch:16 step:15652 [D loss: 0.668123, acc.: 57.03%] [G loss: 0.859714]\n",
      "epoch:16 step:15653 [D loss: 0.626062, acc.: 67.19%] [G loss: 0.827358]\n",
      "epoch:16 step:15654 [D loss: 0.684754, acc.: 58.59%] [G loss: 0.841564]\n",
      "epoch:16 step:15655 [D loss: 0.675529, acc.: 56.25%] [G loss: 0.827451]\n",
      "epoch:16 step:15656 [D loss: 0.674349, acc.: 57.03%] [G loss: 0.866804]\n",
      "epoch:16 step:15657 [D loss: 0.696757, acc.: 55.47%] [G loss: 0.838574]\n",
      "epoch:16 step:15658 [D loss: 0.659971, acc.: 64.06%] [G loss: 0.856647]\n",
      "epoch:16 step:15659 [D loss: 0.678647, acc.: 54.69%] [G loss: 0.865806]\n",
      "epoch:16 step:15660 [D loss: 0.666214, acc.: 61.72%] [G loss: 0.851937]\n",
      "epoch:16 step:15661 [D loss: 0.657932, acc.: 60.94%] [G loss: 0.847833]\n",
      "epoch:16 step:15662 [D loss: 0.649466, acc.: 61.72%] [G loss: 0.862639]\n",
      "epoch:16 step:15663 [D loss: 0.681694, acc.: 57.81%] [G loss: 0.894053]\n",
      "epoch:16 step:15664 [D loss: 0.693060, acc.: 52.34%] [G loss: 0.857485]\n",
      "epoch:16 step:15665 [D loss: 0.659293, acc.: 58.59%] [G loss: 0.882523]\n",
      "epoch:16 step:15666 [D loss: 0.648193, acc.: 61.72%] [G loss: 0.843584]\n",
      "epoch:16 step:15667 [D loss: 0.697804, acc.: 50.00%] [G loss: 0.818468]\n",
      "epoch:16 step:15668 [D loss: 0.686379, acc.: 53.12%] [G loss: 0.801706]\n",
      "epoch:16 step:15669 [D loss: 0.675540, acc.: 57.81%] [G loss: 0.816497]\n",
      "epoch:16 step:15670 [D loss: 0.665804, acc.: 58.59%] [G loss: 0.823096]\n",
      "epoch:16 step:15671 [D loss: 0.684280, acc.: 51.56%] [G loss: 0.889934]\n",
      "epoch:16 step:15672 [D loss: 0.680679, acc.: 51.56%] [G loss: 0.846776]\n",
      "epoch:16 step:15673 [D loss: 0.637270, acc.: 66.41%] [G loss: 0.855620]\n",
      "epoch:16 step:15674 [D loss: 0.680601, acc.: 57.81%] [G loss: 0.821166]\n",
      "epoch:16 step:15675 [D loss: 0.682476, acc.: 53.91%] [G loss: 0.877203]\n",
      "epoch:16 step:15676 [D loss: 0.703655, acc.: 46.88%] [G loss: 0.878253]\n",
      "epoch:16 step:15677 [D loss: 0.642523, acc.: 64.06%] [G loss: 0.897702]\n",
      "epoch:16 step:15678 [D loss: 0.653007, acc.: 58.59%] [G loss: 0.937970]\n",
      "epoch:16 step:15679 [D loss: 0.643547, acc.: 63.28%] [G loss: 0.860489]\n",
      "epoch:16 step:15680 [D loss: 0.630429, acc.: 65.62%] [G loss: 0.845114]\n",
      "epoch:16 step:15681 [D loss: 0.662267, acc.: 64.84%] [G loss: 0.843275]\n",
      "epoch:16 step:15682 [D loss: 0.679996, acc.: 51.56%] [G loss: 0.869751]\n",
      "epoch:16 step:15683 [D loss: 0.701689, acc.: 52.34%] [G loss: 0.800758]\n",
      "epoch:16 step:15684 [D loss: 0.679059, acc.: 58.59%] [G loss: 0.855300]\n",
      "epoch:16 step:15685 [D loss: 0.660247, acc.: 64.06%] [G loss: 0.834610]\n",
      "epoch:16 step:15686 [D loss: 0.648134, acc.: 62.50%] [G loss: 0.864993]\n",
      "epoch:16 step:15687 [D loss: 0.686656, acc.: 57.81%] [G loss: 0.898196]\n",
      "epoch:16 step:15688 [D loss: 0.643119, acc.: 58.59%] [G loss: 0.909168]\n",
      "epoch:16 step:15689 [D loss: 0.639962, acc.: 67.97%] [G loss: 0.921828]\n",
      "epoch:16 step:15690 [D loss: 0.680541, acc.: 60.16%] [G loss: 0.872503]\n",
      "epoch:16 step:15691 [D loss: 0.678886, acc.: 60.16%] [G loss: 0.893722]\n",
      "epoch:16 step:15692 [D loss: 0.675627, acc.: 53.12%] [G loss: 0.872052]\n",
      "epoch:16 step:15693 [D loss: 0.655619, acc.: 60.94%] [G loss: 0.851895]\n",
      "epoch:16 step:15694 [D loss: 0.674452, acc.: 56.25%] [G loss: 0.874055]\n",
      "epoch:16 step:15695 [D loss: 0.681751, acc.: 53.91%] [G loss: 0.845946]\n",
      "epoch:16 step:15696 [D loss: 0.699744, acc.: 56.25%] [G loss: 0.854573]\n",
      "epoch:16 step:15697 [D loss: 0.696642, acc.: 49.22%] [G loss: 0.883113]\n",
      "epoch:16 step:15698 [D loss: 0.706257, acc.: 50.78%] [G loss: 0.868702]\n",
      "epoch:16 step:15699 [D loss: 0.677908, acc.: 54.69%] [G loss: 0.848734]\n",
      "epoch:16 step:15700 [D loss: 0.651569, acc.: 62.50%] [G loss: 0.877046]\n",
      "epoch:16 step:15701 [D loss: 0.686576, acc.: 57.81%] [G loss: 0.829923]\n",
      "epoch:16 step:15702 [D loss: 0.633248, acc.: 64.06%] [G loss: 0.842817]\n",
      "epoch:16 step:15703 [D loss: 0.664359, acc.: 61.72%] [G loss: 0.908106]\n",
      "epoch:16 step:15704 [D loss: 0.670017, acc.: 62.50%] [G loss: 0.856036]\n",
      "epoch:16 step:15705 [D loss: 0.687954, acc.: 52.34%] [G loss: 0.874375]\n",
      "epoch:16 step:15706 [D loss: 0.672393, acc.: 60.94%] [G loss: 0.869985]\n",
      "epoch:16 step:15707 [D loss: 0.695106, acc.: 52.34%] [G loss: 0.846331]\n",
      "epoch:16 step:15708 [D loss: 0.690714, acc.: 50.78%] [G loss: 0.861553]\n",
      "epoch:16 step:15709 [D loss: 0.656734, acc.: 62.50%] [G loss: 0.864084]\n",
      "epoch:16 step:15710 [D loss: 0.649148, acc.: 60.16%] [G loss: 0.827794]\n",
      "epoch:16 step:15711 [D loss: 0.672776, acc.: 53.12%] [G loss: 0.844358]\n",
      "epoch:16 step:15712 [D loss: 0.660525, acc.: 60.94%] [G loss: 0.905000]\n",
      "epoch:16 step:15713 [D loss: 0.694288, acc.: 60.16%] [G loss: 0.873275]\n",
      "epoch:16 step:15714 [D loss: 0.672602, acc.: 57.81%] [G loss: 0.880028]\n",
      "epoch:16 step:15715 [D loss: 0.663456, acc.: 60.16%] [G loss: 0.826722]\n",
      "epoch:16 step:15716 [D loss: 0.669986, acc.: 57.03%] [G loss: 0.855979]\n",
      "epoch:16 step:15717 [D loss: 0.675987, acc.: 57.03%] [G loss: 0.857820]\n",
      "epoch:16 step:15718 [D loss: 0.681044, acc.: 57.03%] [G loss: 0.832156]\n",
      "epoch:16 step:15719 [D loss: 0.623768, acc.: 70.31%] [G loss: 0.906072]\n",
      "epoch:16 step:15720 [D loss: 0.720872, acc.: 51.56%] [G loss: 0.835468]\n",
      "epoch:16 step:15721 [D loss: 0.678475, acc.: 55.47%] [G loss: 0.848062]\n",
      "epoch:16 step:15722 [D loss: 0.673302, acc.: 53.91%] [G loss: 0.870415]\n",
      "epoch:16 step:15723 [D loss: 0.688401, acc.: 57.03%] [G loss: 0.860167]\n",
      "epoch:16 step:15724 [D loss: 0.638314, acc.: 65.62%] [G loss: 0.857421]\n",
      "epoch:16 step:15725 [D loss: 0.658338, acc.: 61.72%] [G loss: 0.890520]\n",
      "epoch:16 step:15726 [D loss: 0.623543, acc.: 67.97%] [G loss: 0.833131]\n",
      "epoch:16 step:15727 [D loss: 0.710556, acc.: 52.34%] [G loss: 0.879618]\n",
      "epoch:16 step:15728 [D loss: 0.652738, acc.: 58.59%] [G loss: 0.880777]\n",
      "epoch:16 step:15729 [D loss: 0.687383, acc.: 56.25%] [G loss: 0.814841]\n",
      "epoch:16 step:15730 [D loss: 0.667985, acc.: 60.16%] [G loss: 0.869377]\n",
      "epoch:16 step:15731 [D loss: 0.668402, acc.: 57.81%] [G loss: 0.859341]\n",
      "epoch:16 step:15732 [D loss: 0.674209, acc.: 54.69%] [G loss: 0.848997]\n",
      "epoch:16 step:15733 [D loss: 0.654818, acc.: 57.03%] [G loss: 0.918420]\n",
      "epoch:16 step:15734 [D loss: 0.669649, acc.: 59.38%] [G loss: 0.830719]\n",
      "epoch:16 step:15735 [D loss: 0.669561, acc.: 57.81%] [G loss: 0.806934]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15736 [D loss: 0.673311, acc.: 59.38%] [G loss: 0.838377]\n",
      "epoch:16 step:15737 [D loss: 0.674770, acc.: 60.94%] [G loss: 0.886950]\n",
      "epoch:16 step:15738 [D loss: 0.651565, acc.: 61.72%] [G loss: 0.897479]\n",
      "epoch:16 step:15739 [D loss: 0.661821, acc.: 61.72%] [G loss: 0.844757]\n",
      "epoch:16 step:15740 [D loss: 0.653993, acc.: 57.81%] [G loss: 0.927108]\n",
      "epoch:16 step:15741 [D loss: 0.696213, acc.: 50.00%] [G loss: 0.856160]\n",
      "epoch:16 step:15742 [D loss: 0.664803, acc.: 60.94%] [G loss: 0.879072]\n",
      "epoch:16 step:15743 [D loss: 0.618779, acc.: 70.31%] [G loss: 0.878254]\n",
      "epoch:16 step:15744 [D loss: 0.659010, acc.: 60.16%] [G loss: 0.838490]\n",
      "epoch:16 step:15745 [D loss: 0.638800, acc.: 64.84%] [G loss: 0.855197]\n",
      "epoch:16 step:15746 [D loss: 0.699288, acc.: 53.12%] [G loss: 0.869407]\n",
      "epoch:16 step:15747 [D loss: 0.651131, acc.: 62.50%] [G loss: 0.929432]\n",
      "epoch:16 step:15748 [D loss: 0.634820, acc.: 64.06%] [G loss: 0.918036]\n",
      "epoch:16 step:15749 [D loss: 0.651748, acc.: 58.59%] [G loss: 0.957585]\n",
      "epoch:16 step:15750 [D loss: 0.642475, acc.: 66.41%] [G loss: 0.927824]\n",
      "epoch:16 step:15751 [D loss: 0.654361, acc.: 63.28%] [G loss: 0.887084]\n",
      "epoch:16 step:15752 [D loss: 0.642931, acc.: 65.62%] [G loss: 0.870334]\n",
      "epoch:16 step:15753 [D loss: 0.679260, acc.: 56.25%] [G loss: 0.897863]\n",
      "epoch:16 step:15754 [D loss: 0.677575, acc.: 57.03%] [G loss: 0.859071]\n",
      "epoch:16 step:15755 [D loss: 0.639894, acc.: 60.16%] [G loss: 0.915013]\n",
      "epoch:16 step:15756 [D loss: 0.643392, acc.: 62.50%] [G loss: 0.953637]\n",
      "epoch:16 step:15757 [D loss: 0.671409, acc.: 61.72%] [G loss: 0.879661]\n",
      "epoch:16 step:15758 [D loss: 0.645340, acc.: 61.72%] [G loss: 0.812121]\n",
      "epoch:16 step:15759 [D loss: 0.675764, acc.: 54.69%] [G loss: 0.840286]\n",
      "epoch:16 step:15760 [D loss: 0.657768, acc.: 64.06%] [G loss: 0.894891]\n",
      "epoch:16 step:15761 [D loss: 0.666273, acc.: 60.94%] [G loss: 0.854344]\n",
      "epoch:16 step:15762 [D loss: 0.657764, acc.: 59.38%] [G loss: 0.836153]\n",
      "epoch:16 step:15763 [D loss: 0.690675, acc.: 57.81%] [G loss: 0.825452]\n",
      "epoch:16 step:15764 [D loss: 0.654167, acc.: 60.94%] [G loss: 0.864902]\n",
      "epoch:16 step:15765 [D loss: 0.656982, acc.: 63.28%] [G loss: 0.871647]\n",
      "epoch:16 step:15766 [D loss: 0.623906, acc.: 67.19%] [G loss: 0.825050]\n",
      "epoch:16 step:15767 [D loss: 0.655925, acc.: 56.25%] [G loss: 0.917874]\n",
      "epoch:16 step:15768 [D loss: 0.654411, acc.: 58.59%] [G loss: 0.890321]\n",
      "epoch:16 step:15769 [D loss: 0.656776, acc.: 62.50%] [G loss: 0.885664]\n",
      "epoch:16 step:15770 [D loss: 0.649744, acc.: 62.50%] [G loss: 0.852118]\n",
      "epoch:16 step:15771 [D loss: 0.658833, acc.: 60.16%] [G loss: 0.863889]\n",
      "epoch:16 step:15772 [D loss: 0.637477, acc.: 64.06%] [G loss: 0.869608]\n",
      "epoch:16 step:15773 [D loss: 0.677821, acc.: 60.16%] [G loss: 0.832035]\n",
      "epoch:16 step:15774 [D loss: 0.641719, acc.: 60.94%] [G loss: 0.851930]\n",
      "epoch:16 step:15775 [D loss: 0.665849, acc.: 57.81%] [G loss: 0.880370]\n",
      "epoch:16 step:15776 [D loss: 0.690826, acc.: 49.22%] [G loss: 0.858108]\n",
      "epoch:16 step:15777 [D loss: 0.665516, acc.: 60.16%] [G loss: 0.890701]\n",
      "epoch:16 step:15778 [D loss: 0.668068, acc.: 57.81%] [G loss: 0.838752]\n",
      "epoch:16 step:15779 [D loss: 0.662172, acc.: 63.28%] [G loss: 0.843218]\n",
      "epoch:16 step:15780 [D loss: 0.662963, acc.: 60.16%] [G loss: 0.898408]\n",
      "epoch:16 step:15781 [D loss: 0.672256, acc.: 59.38%] [G loss: 0.865090]\n",
      "epoch:16 step:15782 [D loss: 0.688179, acc.: 56.25%] [G loss: 0.844076]\n",
      "epoch:16 step:15783 [D loss: 0.655243, acc.: 67.19%] [G loss: 0.850590]\n",
      "epoch:16 step:15784 [D loss: 0.640608, acc.: 63.28%] [G loss: 0.845343]\n",
      "epoch:16 step:15785 [D loss: 0.634522, acc.: 61.72%] [G loss: 0.850880]\n",
      "epoch:16 step:15786 [D loss: 0.650473, acc.: 57.81%] [G loss: 0.863176]\n",
      "epoch:16 step:15787 [D loss: 0.692394, acc.: 49.22%] [G loss: 0.850707]\n",
      "epoch:16 step:15788 [D loss: 0.671582, acc.: 54.69%] [G loss: 0.847288]\n",
      "epoch:16 step:15789 [D loss: 0.681614, acc.: 53.12%] [G loss: 0.860655]\n",
      "epoch:16 step:15790 [D loss: 0.648345, acc.: 59.38%] [G loss: 0.845522]\n",
      "epoch:16 step:15791 [D loss: 0.664237, acc.: 57.81%] [G loss: 0.852000]\n",
      "epoch:16 step:15792 [D loss: 0.646443, acc.: 63.28%] [G loss: 0.874539]\n",
      "epoch:16 step:15793 [D loss: 0.661714, acc.: 55.47%] [G loss: 0.901779]\n",
      "epoch:16 step:15794 [D loss: 0.677009, acc.: 57.03%] [G loss: 0.877168]\n",
      "epoch:16 step:15795 [D loss: 0.687001, acc.: 56.25%] [G loss: 0.894724]\n",
      "epoch:16 step:15796 [D loss: 0.691886, acc.: 53.91%] [G loss: 0.847354]\n",
      "epoch:16 step:15797 [D loss: 0.648241, acc.: 62.50%] [G loss: 0.834124]\n",
      "epoch:16 step:15798 [D loss: 0.637433, acc.: 64.06%] [G loss: 0.864223]\n",
      "epoch:16 step:15799 [D loss: 0.687240, acc.: 54.69%] [G loss: 0.833004]\n",
      "epoch:16 step:15800 [D loss: 0.681701, acc.: 55.47%] [G loss: 0.865678]\n",
      "##############\n",
      "[3.13281328 2.48976819 2.17622046 3.47086083 1.37124654 8.4926052\n",
      " 2.6811158  3.45001928 4.45240359 6.19150375]\n",
      "##########\n",
      "epoch:16 step:15801 [D loss: 0.636980, acc.: 66.41%] [G loss: 0.877561]\n",
      "epoch:16 step:15802 [D loss: 0.676373, acc.: 60.94%] [G loss: 0.887490]\n",
      "epoch:16 step:15803 [D loss: 0.647566, acc.: 60.16%] [G loss: 0.842394]\n",
      "epoch:16 step:15804 [D loss: 0.672565, acc.: 59.38%] [G loss: 0.891030]\n",
      "epoch:16 step:15805 [D loss: 0.655133, acc.: 63.28%] [G loss: 0.878675]\n",
      "epoch:16 step:15806 [D loss: 0.629750, acc.: 66.41%] [G loss: 0.956751]\n",
      "epoch:16 step:15807 [D loss: 0.681975, acc.: 46.88%] [G loss: 0.869411]\n",
      "epoch:16 step:15808 [D loss: 0.653352, acc.: 57.03%] [G loss: 0.917923]\n",
      "epoch:16 step:15809 [D loss: 0.676570, acc.: 54.69%] [G loss: 0.924561]\n",
      "epoch:16 step:15810 [D loss: 0.667614, acc.: 53.91%] [G loss: 0.893071]\n",
      "epoch:16 step:15811 [D loss: 0.646929, acc.: 66.41%] [G loss: 0.890104]\n",
      "epoch:16 step:15812 [D loss: 0.685048, acc.: 50.78%] [G loss: 0.863375]\n",
      "epoch:16 step:15813 [D loss: 0.675341, acc.: 55.47%] [G loss: 0.854876]\n",
      "epoch:16 step:15814 [D loss: 0.634740, acc.: 67.19%] [G loss: 0.869023]\n",
      "epoch:16 step:15815 [D loss: 0.693716, acc.: 57.81%] [G loss: 0.819871]\n",
      "epoch:16 step:15816 [D loss: 0.696102, acc.: 52.34%] [G loss: 0.805034]\n",
      "epoch:16 step:15817 [D loss: 0.673428, acc.: 58.59%] [G loss: 0.838114]\n",
      "epoch:16 step:15818 [D loss: 0.634990, acc.: 60.94%] [G loss: 0.867605]\n",
      "epoch:16 step:15819 [D loss: 0.688395, acc.: 56.25%] [G loss: 0.823814]\n",
      "epoch:16 step:15820 [D loss: 0.695333, acc.: 56.25%] [G loss: 0.843937]\n",
      "epoch:16 step:15821 [D loss: 0.666142, acc.: 57.03%] [G loss: 0.911257]\n",
      "epoch:16 step:15822 [D loss: 0.658395, acc.: 59.38%] [G loss: 0.863750]\n",
      "epoch:16 step:15823 [D loss: 0.682528, acc.: 60.94%] [G loss: 0.847800]\n",
      "epoch:16 step:15824 [D loss: 0.667084, acc.: 58.59%] [G loss: 0.893648]\n",
      "epoch:16 step:15825 [D loss: 0.664249, acc.: 60.16%] [G loss: 0.886905]\n",
      "epoch:16 step:15826 [D loss: 0.650104, acc.: 65.62%] [G loss: 0.821148]\n",
      "epoch:16 step:15827 [D loss: 0.666313, acc.: 64.84%] [G loss: 0.849496]\n",
      "epoch:16 step:15828 [D loss: 0.671201, acc.: 56.25%] [G loss: 0.861186]\n",
      "epoch:16 step:15829 [D loss: 0.680368, acc.: 60.94%] [G loss: 0.848839]\n",
      "epoch:16 step:15830 [D loss: 0.713390, acc.: 46.88%] [G loss: 0.833268]\n",
      "epoch:16 step:15831 [D loss: 0.630144, acc.: 60.94%] [G loss: 0.874663]\n",
      "epoch:16 step:15832 [D loss: 0.654536, acc.: 62.50%] [G loss: 0.859710]\n",
      "epoch:16 step:15833 [D loss: 0.643503, acc.: 60.16%] [G loss: 0.845834]\n",
      "epoch:16 step:15834 [D loss: 0.686937, acc.: 56.25%] [G loss: 0.876523]\n",
      "epoch:16 step:15835 [D loss: 0.691140, acc.: 57.81%] [G loss: 0.878756]\n",
      "epoch:16 step:15836 [D loss: 0.683946, acc.: 51.56%] [G loss: 0.823263]\n",
      "epoch:16 step:15837 [D loss: 0.687768, acc.: 53.91%] [G loss: 0.813748]\n",
      "epoch:16 step:15838 [D loss: 0.658277, acc.: 55.47%] [G loss: 0.857840]\n",
      "epoch:16 step:15839 [D loss: 0.660988, acc.: 60.94%] [G loss: 0.824125]\n",
      "epoch:16 step:15840 [D loss: 0.661303, acc.: 60.94%] [G loss: 0.918064]\n",
      "epoch:16 step:15841 [D loss: 0.663506, acc.: 57.81%] [G loss: 0.874131]\n",
      "epoch:16 step:15842 [D loss: 0.618788, acc.: 69.53%] [G loss: 0.886670]\n",
      "epoch:16 step:15843 [D loss: 0.653537, acc.: 62.50%] [G loss: 0.892600]\n",
      "epoch:16 step:15844 [D loss: 0.650228, acc.: 70.31%] [G loss: 0.875041]\n",
      "epoch:16 step:15845 [D loss: 0.691271, acc.: 53.91%] [G loss: 0.887939]\n",
      "epoch:16 step:15846 [D loss: 0.653403, acc.: 65.62%] [G loss: 0.826906]\n",
      "epoch:16 step:15847 [D loss: 0.682906, acc.: 53.91%] [G loss: 0.868080]\n",
      "epoch:16 step:15848 [D loss: 0.655811, acc.: 57.81%] [G loss: 0.828829]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:16 step:15849 [D loss: 0.679886, acc.: 56.25%] [G loss: 0.811426]\n",
      "epoch:16 step:15850 [D loss: 0.699544, acc.: 51.56%] [G loss: 0.816292]\n",
      "epoch:16 step:15851 [D loss: 0.659743, acc.: 64.06%] [G loss: 0.823503]\n",
      "epoch:16 step:15852 [D loss: 0.657193, acc.: 61.72%] [G loss: 0.859755]\n",
      "epoch:16 step:15853 [D loss: 0.639766, acc.: 70.31%] [G loss: 0.879791]\n",
      "epoch:16 step:15854 [D loss: 0.629376, acc.: 64.84%] [G loss: 0.842580]\n",
      "epoch:16 step:15855 [D loss: 0.657044, acc.: 57.81%] [G loss: 0.867710]\n",
      "epoch:16 step:15856 [D loss: 0.661653, acc.: 60.94%] [G loss: 0.874843]\n",
      "epoch:16 step:15857 [D loss: 0.676971, acc.: 50.78%] [G loss: 0.844886]\n",
      "epoch:16 step:15858 [D loss: 0.653058, acc.: 57.81%] [G loss: 0.837799]\n",
      "epoch:16 step:15859 [D loss: 0.703990, acc.: 56.25%] [G loss: 0.818576]\n",
      "epoch:16 step:15860 [D loss: 0.668422, acc.: 53.91%] [G loss: 0.833430]\n",
      "epoch:16 step:15861 [D loss: 0.646886, acc.: 61.72%] [G loss: 0.865151]\n",
      "epoch:16 step:15862 [D loss: 0.676585, acc.: 57.81%] [G loss: 0.862384]\n",
      "epoch:16 step:15863 [D loss: 0.657747, acc.: 56.25%] [G loss: 0.920057]\n",
      "epoch:16 step:15864 [D loss: 0.665299, acc.: 57.81%] [G loss: 0.909221]\n",
      "epoch:16 step:15865 [D loss: 0.648182, acc.: 64.06%] [G loss: 0.873042]\n",
      "epoch:16 step:15866 [D loss: 0.648515, acc.: 63.28%] [G loss: 0.893499]\n",
      "epoch:16 step:15867 [D loss: 0.669112, acc.: 60.94%] [G loss: 0.873909]\n",
      "epoch:16 step:15868 [D loss: 0.670085, acc.: 54.69%] [G loss: 0.863611]\n",
      "epoch:16 step:15869 [D loss: 0.664076, acc.: 59.38%] [G loss: 0.852684]\n",
      "epoch:16 step:15870 [D loss: 0.676889, acc.: 57.81%] [G loss: 0.849913]\n",
      "epoch:16 step:15871 [D loss: 0.646653, acc.: 62.50%] [G loss: 0.855115]\n",
      "epoch:16 step:15872 [D loss: 0.670675, acc.: 64.84%] [G loss: 0.881187]\n",
      "epoch:16 step:15873 [D loss: 0.694502, acc.: 50.78%] [G loss: 0.865383]\n",
      "epoch:16 step:15874 [D loss: 0.668796, acc.: 62.50%] [G loss: 0.851451]\n",
      "epoch:16 step:15875 [D loss: 0.666394, acc.: 60.94%] [G loss: 0.883526]\n",
      "epoch:16 step:15876 [D loss: 0.671854, acc.: 53.91%] [G loss: 0.854723]\n",
      "epoch:16 step:15877 [D loss: 0.654692, acc.: 62.50%] [G loss: 0.865923]\n",
      "epoch:16 step:15878 [D loss: 0.642071, acc.: 64.84%] [G loss: 0.874117]\n",
      "epoch:16 step:15879 [D loss: 0.644035, acc.: 61.72%] [G loss: 0.881977]\n",
      "epoch:16 step:15880 [D loss: 0.630757, acc.: 66.41%] [G loss: 0.833877]\n",
      "epoch:16 step:15881 [D loss: 0.671782, acc.: 63.28%] [G loss: 0.875323]\n",
      "epoch:16 step:15882 [D loss: 0.685409, acc.: 56.25%] [G loss: 0.945747]\n",
      "epoch:16 step:15883 [D loss: 0.653292, acc.: 62.50%] [G loss: 0.894343]\n",
      "epoch:16 step:15884 [D loss: 0.685623, acc.: 56.25%] [G loss: 0.893292]\n",
      "epoch:16 step:15885 [D loss: 0.654610, acc.: 61.72%] [G loss: 0.900747]\n",
      "epoch:16 step:15886 [D loss: 0.668733, acc.: 57.81%] [G loss: 0.849240]\n",
      "epoch:16 step:15887 [D loss: 0.640760, acc.: 64.06%] [G loss: 0.862575]\n",
      "epoch:16 step:15888 [D loss: 0.643116, acc.: 60.16%] [G loss: 0.859263]\n",
      "epoch:16 step:15889 [D loss: 0.660455, acc.: 58.59%] [G loss: 0.828755]\n",
      "epoch:16 step:15890 [D loss: 0.674794, acc.: 57.03%] [G loss: 0.861496]\n",
      "epoch:16 step:15891 [D loss: 0.676067, acc.: 59.38%] [G loss: 0.855605]\n",
      "epoch:16 step:15892 [D loss: 0.647772, acc.: 54.69%] [G loss: 0.920972]\n",
      "epoch:16 step:15893 [D loss: 0.671029, acc.: 58.59%] [G loss: 0.841648]\n",
      "epoch:16 step:15894 [D loss: 0.649589, acc.: 60.94%] [G loss: 0.855313]\n",
      "epoch:16 step:15895 [D loss: 0.685097, acc.: 62.50%] [G loss: 0.936241]\n",
      "epoch:16 step:15896 [D loss: 0.656715, acc.: 61.72%] [G loss: 0.902816]\n",
      "epoch:16 step:15897 [D loss: 0.682062, acc.: 50.78%] [G loss: 0.889389]\n",
      "epoch:16 step:15898 [D loss: 0.642421, acc.: 63.28%] [G loss: 0.892963]\n",
      "epoch:16 step:15899 [D loss: 0.679766, acc.: 56.25%] [G loss: 0.849880]\n",
      "epoch:16 step:15900 [D loss: 0.687936, acc.: 55.47%] [G loss: 0.879102]\n",
      "epoch:16 step:15901 [D loss: 0.690553, acc.: 53.12%] [G loss: 0.870763]\n",
      "epoch:16 step:15902 [D loss: 0.677536, acc.: 52.34%] [G loss: 0.863321]\n",
      "epoch:16 step:15903 [D loss: 0.656828, acc.: 61.72%] [G loss: 0.901106]\n",
      "epoch:16 step:15904 [D loss: 0.678147, acc.: 57.81%] [G loss: 0.867226]\n",
      "epoch:16 step:15905 [D loss: 0.677662, acc.: 56.25%] [G loss: 0.850052]\n",
      "epoch:16 step:15906 [D loss: 0.684233, acc.: 64.06%] [G loss: 0.833887]\n",
      "epoch:16 step:15907 [D loss: 0.676040, acc.: 56.25%] [G loss: 0.862377]\n",
      "epoch:16 step:15908 [D loss: 0.664919, acc.: 60.94%] [G loss: 0.814485]\n",
      "epoch:16 step:15909 [D loss: 0.610880, acc.: 69.53%] [G loss: 0.857097]\n",
      "epoch:16 step:15910 [D loss: 0.655986, acc.: 62.50%] [G loss: 0.899826]\n",
      "epoch:16 step:15911 [D loss: 0.647759, acc.: 64.84%] [G loss: 0.809423]\n",
      "epoch:16 step:15912 [D loss: 0.650910, acc.: 63.28%] [G loss: 0.818431]\n",
      "epoch:16 step:15913 [D loss: 0.670973, acc.: 58.59%] [G loss: 0.830690]\n",
      "epoch:16 step:15914 [D loss: 0.677421, acc.: 64.06%] [G loss: 0.837464]\n",
      "epoch:16 step:15915 [D loss: 0.672957, acc.: 62.50%] [G loss: 0.863627]\n",
      "epoch:16 step:15916 [D loss: 0.660983, acc.: 55.47%] [G loss: 0.906474]\n",
      "epoch:16 step:15917 [D loss: 0.649117, acc.: 64.06%] [G loss: 0.836723]\n",
      "epoch:16 step:15918 [D loss: 0.652952, acc.: 61.72%] [G loss: 0.831141]\n",
      "epoch:16 step:15919 [D loss: 0.649587, acc.: 63.28%] [G loss: 0.841242]\n",
      "epoch:16 step:15920 [D loss: 0.689163, acc.: 56.25%] [G loss: 0.822963]\n",
      "epoch:16 step:15921 [D loss: 0.675373, acc.: 56.25%] [G loss: 0.801556]\n",
      "epoch:16 step:15922 [D loss: 0.655623, acc.: 62.50%] [G loss: 0.825791]\n",
      "epoch:16 step:15923 [D loss: 0.692523, acc.: 56.25%] [G loss: 0.809407]\n",
      "epoch:16 step:15924 [D loss: 0.645657, acc.: 60.16%] [G loss: 0.824125]\n",
      "epoch:16 step:15925 [D loss: 0.674439, acc.: 60.94%] [G loss: 0.889192]\n",
      "epoch:16 step:15926 [D loss: 0.656207, acc.: 64.84%] [G loss: 0.863460]\n",
      "epoch:16 step:15927 [D loss: 0.661094, acc.: 58.59%] [G loss: 0.868329]\n",
      "epoch:16 step:15928 [D loss: 0.685771, acc.: 59.38%] [G loss: 0.895706]\n",
      "epoch:16 step:15929 [D loss: 0.653641, acc.: 65.62%] [G loss: 0.869526]\n",
      "epoch:17 step:15930 [D loss: 0.682985, acc.: 56.25%] [G loss: 0.891102]\n",
      "epoch:17 step:15931 [D loss: 0.663528, acc.: 64.84%] [G loss: 0.825113]\n",
      "epoch:17 step:15932 [D loss: 0.642491, acc.: 64.84%] [G loss: 0.863647]\n",
      "epoch:17 step:15933 [D loss: 0.659543, acc.: 56.25%] [G loss: 0.870774]\n",
      "epoch:17 step:15934 [D loss: 0.680189, acc.: 53.12%] [G loss: 0.875526]\n",
      "epoch:17 step:15935 [D loss: 0.626693, acc.: 67.97%] [G loss: 0.895011]\n",
      "epoch:17 step:15936 [D loss: 0.710670, acc.: 54.69%] [G loss: 0.848521]\n",
      "epoch:17 step:15937 [D loss: 0.684482, acc.: 53.91%] [G loss: 0.820548]\n",
      "epoch:17 step:15938 [D loss: 0.685177, acc.: 56.25%] [G loss: 0.841640]\n",
      "epoch:17 step:15939 [D loss: 0.644090, acc.: 62.50%] [G loss: 0.840036]\n",
      "epoch:17 step:15940 [D loss: 0.640299, acc.: 62.50%] [G loss: 0.907700]\n",
      "epoch:17 step:15941 [D loss: 0.641490, acc.: 61.72%] [G loss: 0.856827]\n",
      "epoch:17 step:15942 [D loss: 0.667443, acc.: 56.25%] [G loss: 0.848841]\n",
      "epoch:17 step:15943 [D loss: 0.697888, acc.: 57.81%] [G loss: 0.865613]\n",
      "epoch:17 step:15944 [D loss: 0.616261, acc.: 69.53%] [G loss: 0.883760]\n",
      "epoch:17 step:15945 [D loss: 0.710737, acc.: 50.78%] [G loss: 0.845887]\n",
      "epoch:17 step:15946 [D loss: 0.640163, acc.: 61.72%] [G loss: 0.838643]\n",
      "epoch:17 step:15947 [D loss: 0.672943, acc.: 56.25%] [G loss: 0.885526]\n",
      "epoch:17 step:15948 [D loss: 0.673716, acc.: 59.38%] [G loss: 0.849655]\n",
      "epoch:17 step:15949 [D loss: 0.691580, acc.: 48.44%] [G loss: 0.880541]\n",
      "epoch:17 step:15950 [D loss: 0.690619, acc.: 50.78%] [G loss: 0.897692]\n",
      "epoch:17 step:15951 [D loss: 0.658271, acc.: 61.72%] [G loss: 0.865730]\n",
      "epoch:17 step:15952 [D loss: 0.698051, acc.: 51.56%] [G loss: 0.828696]\n",
      "epoch:17 step:15953 [D loss: 0.679275, acc.: 55.47%] [G loss: 0.871420]\n",
      "epoch:17 step:15954 [D loss: 0.676482, acc.: 61.72%] [G loss: 0.884774]\n",
      "epoch:17 step:15955 [D loss: 0.670269, acc.: 60.94%] [G loss: 0.864519]\n",
      "epoch:17 step:15956 [D loss: 0.651155, acc.: 64.84%] [G loss: 0.851464]\n",
      "epoch:17 step:15957 [D loss: 0.659858, acc.: 59.38%] [G loss: 0.816438]\n",
      "epoch:17 step:15958 [D loss: 0.678740, acc.: 60.16%] [G loss: 0.834330]\n",
      "epoch:17 step:15959 [D loss: 0.680057, acc.: 53.91%] [G loss: 0.878694]\n",
      "epoch:17 step:15960 [D loss: 0.649673, acc.: 62.50%] [G loss: 0.861423]\n",
      "epoch:17 step:15961 [D loss: 0.665330, acc.: 57.81%] [G loss: 0.903305]\n",
      "epoch:17 step:15962 [D loss: 0.639761, acc.: 58.59%] [G loss: 0.871770]\n",
      "epoch:17 step:15963 [D loss: 0.663082, acc.: 56.25%] [G loss: 0.820627]\n",
      "epoch:17 step:15964 [D loss: 0.677281, acc.: 56.25%] [G loss: 0.861730]\n",
      "epoch:17 step:15965 [D loss: 0.650643, acc.: 60.94%] [G loss: 0.902665]\n",
      "epoch:17 step:15966 [D loss: 0.668536, acc.: 59.38%] [G loss: 0.915443]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:15967 [D loss: 0.661456, acc.: 61.72%] [G loss: 0.958018]\n",
      "epoch:17 step:15968 [D loss: 0.637570, acc.: 60.16%] [G loss: 0.902350]\n",
      "epoch:17 step:15969 [D loss: 0.686761, acc.: 53.91%] [G loss: 0.888699]\n",
      "epoch:17 step:15970 [D loss: 0.667504, acc.: 58.59%] [G loss: 0.870828]\n",
      "epoch:17 step:15971 [D loss: 0.661237, acc.: 58.59%] [G loss: 0.844632]\n",
      "epoch:17 step:15972 [D loss: 0.685696, acc.: 57.81%] [G loss: 0.869660]\n",
      "epoch:17 step:15973 [D loss: 0.649576, acc.: 57.03%] [G loss: 0.895505]\n",
      "epoch:17 step:15974 [D loss: 0.682577, acc.: 56.25%] [G loss: 0.850749]\n",
      "epoch:17 step:15975 [D loss: 0.651071, acc.: 63.28%] [G loss: 0.905068]\n",
      "epoch:17 step:15976 [D loss: 0.709710, acc.: 53.91%] [G loss: 0.916877]\n",
      "epoch:17 step:15977 [D loss: 0.647193, acc.: 63.28%] [G loss: 0.902027]\n",
      "epoch:17 step:15978 [D loss: 0.656898, acc.: 57.81%] [G loss: 0.909877]\n",
      "epoch:17 step:15979 [D loss: 0.641049, acc.: 69.53%] [G loss: 0.863211]\n",
      "epoch:17 step:15980 [D loss: 0.644226, acc.: 60.16%] [G loss: 0.871735]\n",
      "epoch:17 step:15981 [D loss: 0.632967, acc.: 65.62%] [G loss: 0.855270]\n",
      "epoch:17 step:15982 [D loss: 0.655160, acc.: 57.81%] [G loss: 0.876596]\n",
      "epoch:17 step:15983 [D loss: 0.646398, acc.: 61.72%] [G loss: 0.893597]\n",
      "epoch:17 step:15984 [D loss: 0.663421, acc.: 56.25%] [G loss: 0.936064]\n",
      "epoch:17 step:15985 [D loss: 0.700491, acc.: 55.47%] [G loss: 0.858652]\n",
      "epoch:17 step:15986 [D loss: 0.672355, acc.: 53.12%] [G loss: 0.893251]\n",
      "epoch:17 step:15987 [D loss: 0.697628, acc.: 53.91%] [G loss: 0.895327]\n",
      "epoch:17 step:15988 [D loss: 0.653024, acc.: 63.28%] [G loss: 0.913384]\n",
      "epoch:17 step:15989 [D loss: 0.637393, acc.: 57.81%] [G loss: 0.912477]\n",
      "epoch:17 step:15990 [D loss: 0.685339, acc.: 53.91%] [G loss: 0.894197]\n",
      "epoch:17 step:15991 [D loss: 0.668602, acc.: 53.91%] [G loss: 0.848573]\n",
      "epoch:17 step:15992 [D loss: 0.652279, acc.: 59.38%] [G loss: 0.835290]\n",
      "epoch:17 step:15993 [D loss: 0.634201, acc.: 64.84%] [G loss: 0.839828]\n",
      "epoch:17 step:15994 [D loss: 0.647673, acc.: 60.94%] [G loss: 0.878231]\n",
      "epoch:17 step:15995 [D loss: 0.666846, acc.: 57.03%] [G loss: 0.887331]\n",
      "epoch:17 step:15996 [D loss: 0.701184, acc.: 53.91%] [G loss: 0.917753]\n",
      "epoch:17 step:15997 [D loss: 0.658767, acc.: 60.16%] [G loss: 0.870282]\n",
      "epoch:17 step:15998 [D loss: 0.661142, acc.: 57.81%] [G loss: 0.874283]\n",
      "epoch:17 step:15999 [D loss: 0.664181, acc.: 60.16%] [G loss: 0.867334]\n",
      "epoch:17 step:16000 [D loss: 0.650534, acc.: 61.72%] [G loss: 0.904347]\n",
      "##############\n",
      "[2.82836091 2.3179364  2.05474761 3.52626016 1.23207413 7.14901113\n",
      " 2.67356559 3.15414728 4.25624354 6.10788788]\n",
      "##########\n",
      "epoch:17 step:16001 [D loss: 0.659004, acc.: 60.94%] [G loss: 0.892930]\n",
      "epoch:17 step:16002 [D loss: 0.669472, acc.: 61.72%] [G loss: 0.856100]\n",
      "epoch:17 step:16003 [D loss: 0.683087, acc.: 54.69%] [G loss: 0.907977]\n",
      "epoch:17 step:16004 [D loss: 0.643372, acc.: 60.94%] [G loss: 0.866852]\n",
      "epoch:17 step:16005 [D loss: 0.630732, acc.: 63.28%] [G loss: 0.848760]\n",
      "epoch:17 step:16006 [D loss: 0.695281, acc.: 53.12%] [G loss: 0.782248]\n",
      "epoch:17 step:16007 [D loss: 0.646071, acc.: 60.94%] [G loss: 0.784205]\n",
      "epoch:17 step:16008 [D loss: 0.657537, acc.: 62.50%] [G loss: 0.890377]\n",
      "epoch:17 step:16009 [D loss: 0.687672, acc.: 49.22%] [G loss: 0.848997]\n",
      "epoch:17 step:16010 [D loss: 0.675387, acc.: 55.47%] [G loss: 0.869485]\n",
      "epoch:17 step:16011 [D loss: 0.627866, acc.: 62.50%] [G loss: 0.896004]\n",
      "epoch:17 step:16012 [D loss: 0.689385, acc.: 52.34%] [G loss: 0.858578]\n",
      "epoch:17 step:16013 [D loss: 0.650379, acc.: 62.50%] [G loss: 0.865834]\n",
      "epoch:17 step:16014 [D loss: 0.648688, acc.: 56.25%] [G loss: 0.848056]\n",
      "epoch:17 step:16015 [D loss: 0.685778, acc.: 56.25%] [G loss: 0.841437]\n",
      "epoch:17 step:16016 [D loss: 0.642700, acc.: 64.06%] [G loss: 0.848316]\n",
      "epoch:17 step:16017 [D loss: 0.683805, acc.: 58.59%] [G loss: 0.865227]\n",
      "epoch:17 step:16018 [D loss: 0.643194, acc.: 67.19%] [G loss: 0.880255]\n",
      "epoch:17 step:16019 [D loss: 0.669917, acc.: 55.47%] [G loss: 0.873345]\n",
      "epoch:17 step:16020 [D loss: 0.649815, acc.: 64.06%] [G loss: 0.875370]\n",
      "epoch:17 step:16021 [D loss: 0.641048, acc.: 64.84%] [G loss: 0.889613]\n",
      "epoch:17 step:16022 [D loss: 0.657622, acc.: 60.16%] [G loss: 0.877180]\n",
      "epoch:17 step:16023 [D loss: 0.659432, acc.: 63.28%] [G loss: 0.904266]\n",
      "epoch:17 step:16024 [D loss: 0.660402, acc.: 62.50%] [G loss: 0.830577]\n",
      "epoch:17 step:16025 [D loss: 0.656651, acc.: 62.50%] [G loss: 0.832421]\n",
      "epoch:17 step:16026 [D loss: 0.627378, acc.: 64.84%] [G loss: 0.849220]\n",
      "epoch:17 step:16027 [D loss: 0.693142, acc.: 50.00%] [G loss: 0.869333]\n",
      "epoch:17 step:16028 [D loss: 0.670679, acc.: 57.81%] [G loss: 0.904647]\n",
      "epoch:17 step:16029 [D loss: 0.670438, acc.: 57.03%] [G loss: 0.873087]\n",
      "epoch:17 step:16030 [D loss: 0.645238, acc.: 67.19%] [G loss: 0.897448]\n",
      "epoch:17 step:16031 [D loss: 0.686023, acc.: 57.81%] [G loss: 0.848848]\n",
      "epoch:17 step:16032 [D loss: 0.641600, acc.: 65.62%] [G loss: 0.873740]\n",
      "epoch:17 step:16033 [D loss: 0.659135, acc.: 62.50%] [G loss: 0.836570]\n",
      "epoch:17 step:16034 [D loss: 0.655325, acc.: 63.28%] [G loss: 0.818782]\n",
      "epoch:17 step:16035 [D loss: 0.680893, acc.: 59.38%] [G loss: 0.879020]\n",
      "epoch:17 step:16036 [D loss: 0.635417, acc.: 64.06%] [G loss: 0.822572]\n",
      "epoch:17 step:16037 [D loss: 0.681042, acc.: 54.69%] [G loss: 0.836906]\n",
      "epoch:17 step:16038 [D loss: 0.663590, acc.: 60.94%] [G loss: 0.892520]\n",
      "epoch:17 step:16039 [D loss: 0.682432, acc.: 55.47%] [G loss: 0.863110]\n",
      "epoch:17 step:16040 [D loss: 0.672688, acc.: 59.38%] [G loss: 0.906384]\n",
      "epoch:17 step:16041 [D loss: 0.650527, acc.: 59.38%] [G loss: 0.888203]\n",
      "epoch:17 step:16042 [D loss: 0.631739, acc.: 60.94%] [G loss: 0.911607]\n",
      "epoch:17 step:16043 [D loss: 0.655748, acc.: 64.84%] [G loss: 0.854492]\n",
      "epoch:17 step:16044 [D loss: 0.658384, acc.: 58.59%] [G loss: 0.903149]\n",
      "epoch:17 step:16045 [D loss: 0.633556, acc.: 66.41%] [G loss: 0.826796]\n",
      "epoch:17 step:16046 [D loss: 0.659916, acc.: 64.06%] [G loss: 0.829498]\n",
      "epoch:17 step:16047 [D loss: 0.643485, acc.: 61.72%] [G loss: 0.844956]\n",
      "epoch:17 step:16048 [D loss: 0.695230, acc.: 56.25%] [G loss: 0.822410]\n",
      "epoch:17 step:16049 [D loss: 0.683613, acc.: 53.91%] [G loss: 0.825571]\n",
      "epoch:17 step:16050 [D loss: 0.628788, acc.: 69.53%] [G loss: 0.828523]\n",
      "epoch:17 step:16051 [D loss: 0.714344, acc.: 52.34%] [G loss: 0.839120]\n",
      "epoch:17 step:16052 [D loss: 0.652081, acc.: 62.50%] [G loss: 0.853414]\n",
      "epoch:17 step:16053 [D loss: 0.651425, acc.: 63.28%] [G loss: 0.881815]\n",
      "epoch:17 step:16054 [D loss: 0.697960, acc.: 50.00%] [G loss: 0.934643]\n",
      "epoch:17 step:16055 [D loss: 0.643036, acc.: 64.84%] [G loss: 0.933015]\n",
      "epoch:17 step:16056 [D loss: 0.604560, acc.: 70.31%] [G loss: 0.905593]\n",
      "epoch:17 step:16057 [D loss: 0.654516, acc.: 60.94%] [G loss: 0.838093]\n",
      "epoch:17 step:16058 [D loss: 0.670126, acc.: 57.03%] [G loss: 0.845477]\n",
      "epoch:17 step:16059 [D loss: 0.613484, acc.: 64.06%] [G loss: 0.882563]\n",
      "epoch:17 step:16060 [D loss: 0.644301, acc.: 60.16%] [G loss: 0.838799]\n",
      "epoch:17 step:16061 [D loss: 0.648473, acc.: 60.94%] [G loss: 0.870648]\n",
      "epoch:17 step:16062 [D loss: 0.656370, acc.: 60.94%] [G loss: 0.827971]\n",
      "epoch:17 step:16063 [D loss: 0.666814, acc.: 54.69%] [G loss: 0.834303]\n",
      "epoch:17 step:16064 [D loss: 0.694225, acc.: 54.69%] [G loss: 0.856026]\n",
      "epoch:17 step:16065 [D loss: 0.696244, acc.: 46.88%] [G loss: 0.875875]\n",
      "epoch:17 step:16066 [D loss: 0.673414, acc.: 60.16%] [G loss: 0.814118]\n",
      "epoch:17 step:16067 [D loss: 0.634685, acc.: 64.84%] [G loss: 0.880471]\n",
      "epoch:17 step:16068 [D loss: 0.676905, acc.: 54.69%] [G loss: 0.869642]\n",
      "epoch:17 step:16069 [D loss: 0.687910, acc.: 52.34%] [G loss: 0.861413]\n",
      "epoch:17 step:16070 [D loss: 0.694025, acc.: 50.78%] [G loss: 0.920186]\n",
      "epoch:17 step:16071 [D loss: 0.601715, acc.: 64.84%] [G loss: 0.887365]\n",
      "epoch:17 step:16072 [D loss: 0.681413, acc.: 60.94%] [G loss: 0.878261]\n",
      "epoch:17 step:16073 [D loss: 0.653380, acc.: 59.38%] [G loss: 0.855217]\n",
      "epoch:17 step:16074 [D loss: 0.692562, acc.: 57.03%] [G loss: 0.831782]\n",
      "epoch:17 step:16075 [D loss: 0.643883, acc.: 69.53%] [G loss: 0.843100]\n",
      "epoch:17 step:16076 [D loss: 0.675914, acc.: 57.81%] [G loss: 0.832233]\n",
      "epoch:17 step:16077 [D loss: 0.654081, acc.: 57.81%] [G loss: 0.856914]\n",
      "epoch:17 step:16078 [D loss: 0.656394, acc.: 59.38%] [G loss: 0.866492]\n",
      "epoch:17 step:16079 [D loss: 0.680863, acc.: 58.59%] [G loss: 0.879729]\n",
      "epoch:17 step:16080 [D loss: 0.702318, acc.: 53.12%] [G loss: 0.887250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16081 [D loss: 0.653097, acc.: 62.50%] [G loss: 0.835224]\n",
      "epoch:17 step:16082 [D loss: 0.677062, acc.: 54.69%] [G loss: 0.837694]\n",
      "epoch:17 step:16083 [D loss: 0.647544, acc.: 58.59%] [G loss: 0.848219]\n",
      "epoch:17 step:16084 [D loss: 0.663893, acc.: 57.03%] [G loss: 0.847790]\n",
      "epoch:17 step:16085 [D loss: 0.616735, acc.: 67.97%] [G loss: 0.820172]\n",
      "epoch:17 step:16086 [D loss: 0.686157, acc.: 55.47%] [G loss: 0.846439]\n",
      "epoch:17 step:16087 [D loss: 0.652300, acc.: 60.94%] [G loss: 0.861403]\n",
      "epoch:17 step:16088 [D loss: 0.646652, acc.: 64.06%] [G loss: 0.864667]\n",
      "epoch:17 step:16089 [D loss: 0.695047, acc.: 53.12%] [G loss: 0.901521]\n",
      "epoch:17 step:16090 [D loss: 0.633918, acc.: 66.41%] [G loss: 0.910567]\n",
      "epoch:17 step:16091 [D loss: 0.631647, acc.: 63.28%] [G loss: 0.864653]\n",
      "epoch:17 step:16092 [D loss: 0.699754, acc.: 52.34%] [G loss: 0.822841]\n",
      "epoch:17 step:16093 [D loss: 0.667383, acc.: 62.50%] [G loss: 0.827268]\n",
      "epoch:17 step:16094 [D loss: 0.629437, acc.: 66.41%] [G loss: 0.825616]\n",
      "epoch:17 step:16095 [D loss: 0.666870, acc.: 57.81%] [G loss: 0.875434]\n",
      "epoch:17 step:16096 [D loss: 0.668251, acc.: 58.59%] [G loss: 0.911444]\n",
      "epoch:17 step:16097 [D loss: 0.643581, acc.: 60.94%] [G loss: 0.854433]\n",
      "epoch:17 step:16098 [D loss: 0.674673, acc.: 56.25%] [G loss: 0.955622]\n",
      "epoch:17 step:16099 [D loss: 0.673419, acc.: 53.91%] [G loss: 0.944670]\n",
      "epoch:17 step:16100 [D loss: 0.715544, acc.: 50.00%] [G loss: 0.897736]\n",
      "epoch:17 step:16101 [D loss: 0.697322, acc.: 53.12%] [G loss: 0.920745]\n",
      "epoch:17 step:16102 [D loss: 0.689626, acc.: 55.47%] [G loss: 0.868636]\n",
      "epoch:17 step:16103 [D loss: 0.643701, acc.: 65.62%] [G loss: 0.877562]\n",
      "epoch:17 step:16104 [D loss: 0.662196, acc.: 57.81%] [G loss: 0.876951]\n",
      "epoch:17 step:16105 [D loss: 0.614007, acc.: 70.31%] [G loss: 0.883454]\n",
      "epoch:17 step:16106 [D loss: 0.650613, acc.: 58.59%] [G loss: 0.883377]\n",
      "epoch:17 step:16107 [D loss: 0.682504, acc.: 53.91%] [G loss: 0.781706]\n",
      "epoch:17 step:16108 [D loss: 0.695746, acc.: 51.56%] [G loss: 0.864335]\n",
      "epoch:17 step:16109 [D loss: 0.635159, acc.: 60.16%] [G loss: 0.878220]\n",
      "epoch:17 step:16110 [D loss: 0.681021, acc.: 51.56%] [G loss: 0.872365]\n",
      "epoch:17 step:16111 [D loss: 0.644366, acc.: 63.28%] [G loss: 0.874653]\n",
      "epoch:17 step:16112 [D loss: 0.691282, acc.: 56.25%] [G loss: 0.805490]\n",
      "epoch:17 step:16113 [D loss: 0.668571, acc.: 59.38%] [G loss: 0.852454]\n",
      "epoch:17 step:16114 [D loss: 0.660476, acc.: 59.38%] [G loss: 0.890381]\n",
      "epoch:17 step:16115 [D loss: 0.659747, acc.: 59.38%] [G loss: 0.937477]\n",
      "epoch:17 step:16116 [D loss: 0.644313, acc.: 61.72%] [G loss: 0.876563]\n",
      "epoch:17 step:16117 [D loss: 0.664287, acc.: 63.28%] [G loss: 0.847505]\n",
      "epoch:17 step:16118 [D loss: 0.681034, acc.: 59.38%] [G loss: 0.808429]\n",
      "epoch:17 step:16119 [D loss: 0.676564, acc.: 53.12%] [G loss: 0.831411]\n",
      "epoch:17 step:16120 [D loss: 0.640607, acc.: 60.94%] [G loss: 0.892185]\n",
      "epoch:17 step:16121 [D loss: 0.691872, acc.: 59.38%] [G loss: 0.841170]\n",
      "epoch:17 step:16122 [D loss: 0.666824, acc.: 57.81%] [G loss: 0.874328]\n",
      "epoch:17 step:16123 [D loss: 0.692055, acc.: 53.91%] [G loss: 0.872837]\n",
      "epoch:17 step:16124 [D loss: 0.636985, acc.: 71.88%] [G loss: 0.857310]\n",
      "epoch:17 step:16125 [D loss: 0.641549, acc.: 68.75%] [G loss: 0.891350]\n",
      "epoch:17 step:16126 [D loss: 0.624770, acc.: 60.94%] [G loss: 0.874131]\n",
      "epoch:17 step:16127 [D loss: 0.632484, acc.: 67.19%] [G loss: 0.864001]\n",
      "epoch:17 step:16128 [D loss: 0.653615, acc.: 64.84%] [G loss: 0.831885]\n",
      "epoch:17 step:16129 [D loss: 0.651119, acc.: 61.72%] [G loss: 0.870566]\n",
      "epoch:17 step:16130 [D loss: 0.663382, acc.: 57.81%] [G loss: 0.836151]\n",
      "epoch:17 step:16131 [D loss: 0.635681, acc.: 64.06%] [G loss: 0.885000]\n",
      "epoch:17 step:16132 [D loss: 0.671960, acc.: 56.25%] [G loss: 0.871109]\n",
      "epoch:17 step:16133 [D loss: 0.672424, acc.: 58.59%] [G loss: 0.887021]\n",
      "epoch:17 step:16134 [D loss: 0.643221, acc.: 67.19%] [G loss: 0.881834]\n",
      "epoch:17 step:16135 [D loss: 0.687978, acc.: 59.38%] [G loss: 0.899823]\n",
      "epoch:17 step:16136 [D loss: 0.637575, acc.: 65.62%] [G loss: 0.872172]\n",
      "epoch:17 step:16137 [D loss: 0.684494, acc.: 56.25%] [G loss: 0.908148]\n",
      "epoch:17 step:16138 [D loss: 0.695503, acc.: 57.81%] [G loss: 0.856927]\n",
      "epoch:17 step:16139 [D loss: 0.646224, acc.: 58.59%] [G loss: 0.886142]\n",
      "epoch:17 step:16140 [D loss: 0.667420, acc.: 60.16%] [G loss: 0.853877]\n",
      "epoch:17 step:16141 [D loss: 0.675778, acc.: 54.69%] [G loss: 0.850069]\n",
      "epoch:17 step:16142 [D loss: 0.700911, acc.: 57.03%] [G loss: 0.800426]\n",
      "epoch:17 step:16143 [D loss: 0.686001, acc.: 54.69%] [G loss: 0.821490]\n",
      "epoch:17 step:16144 [D loss: 0.692689, acc.: 53.12%] [G loss: 0.840272]\n",
      "epoch:17 step:16145 [D loss: 0.674482, acc.: 53.12%] [G loss: 0.847662]\n",
      "epoch:17 step:16146 [D loss: 0.665856, acc.: 58.59%] [G loss: 0.881040]\n",
      "epoch:17 step:16147 [D loss: 0.677658, acc.: 60.16%] [G loss: 0.844124]\n",
      "epoch:17 step:16148 [D loss: 0.673217, acc.: 58.59%] [G loss: 0.843849]\n",
      "epoch:17 step:16149 [D loss: 0.667109, acc.: 58.59%] [G loss: 0.814783]\n",
      "epoch:17 step:16150 [D loss: 0.670835, acc.: 57.81%] [G loss: 0.843008]\n",
      "epoch:17 step:16151 [D loss: 0.702435, acc.: 52.34%] [G loss: 0.901418]\n",
      "epoch:17 step:16152 [D loss: 0.707995, acc.: 50.00%] [G loss: 0.884223]\n",
      "epoch:17 step:16153 [D loss: 0.671185, acc.: 60.16%] [G loss: 0.849916]\n",
      "epoch:17 step:16154 [D loss: 0.670322, acc.: 58.59%] [G loss: 0.855917]\n",
      "epoch:17 step:16155 [D loss: 0.689499, acc.: 55.47%] [G loss: 0.904553]\n",
      "epoch:17 step:16156 [D loss: 0.677842, acc.: 55.47%] [G loss: 0.889282]\n",
      "epoch:17 step:16157 [D loss: 0.662918, acc.: 63.28%] [G loss: 0.878463]\n",
      "epoch:17 step:16158 [D loss: 0.645105, acc.: 65.62%] [G loss: 0.894108]\n",
      "epoch:17 step:16159 [D loss: 0.682300, acc.: 53.12%] [G loss: 0.828619]\n",
      "epoch:17 step:16160 [D loss: 0.681835, acc.: 52.34%] [G loss: 0.828514]\n",
      "epoch:17 step:16161 [D loss: 0.672230, acc.: 60.16%] [G loss: 0.883933]\n",
      "epoch:17 step:16162 [D loss: 0.652639, acc.: 62.50%] [G loss: 0.891996]\n",
      "epoch:17 step:16163 [D loss: 0.642727, acc.: 64.06%] [G loss: 0.864836]\n",
      "epoch:17 step:16164 [D loss: 0.642188, acc.: 67.19%] [G loss: 0.858547]\n",
      "epoch:17 step:16165 [D loss: 0.636478, acc.: 64.06%] [G loss: 0.857639]\n",
      "epoch:17 step:16166 [D loss: 0.704977, acc.: 51.56%] [G loss: 0.805606]\n",
      "epoch:17 step:16167 [D loss: 0.669129, acc.: 60.16%] [G loss: 0.857326]\n",
      "epoch:17 step:16168 [D loss: 0.672960, acc.: 60.94%] [G loss: 0.867157]\n",
      "epoch:17 step:16169 [D loss: 0.626754, acc.: 67.19%] [G loss: 0.836226]\n",
      "epoch:17 step:16170 [D loss: 0.655391, acc.: 57.81%] [G loss: 0.859072]\n",
      "epoch:17 step:16171 [D loss: 0.651088, acc.: 60.16%] [G loss: 0.838919]\n",
      "epoch:17 step:16172 [D loss: 0.665215, acc.: 59.38%] [G loss: 0.877081]\n",
      "epoch:17 step:16173 [D loss: 0.686350, acc.: 56.25%] [G loss: 0.839853]\n",
      "epoch:17 step:16174 [D loss: 0.650644, acc.: 60.94%] [G loss: 0.840074]\n",
      "epoch:17 step:16175 [D loss: 0.682938, acc.: 51.56%] [G loss: 0.842671]\n",
      "epoch:17 step:16176 [D loss: 0.658402, acc.: 60.16%] [G loss: 0.848408]\n",
      "epoch:17 step:16177 [D loss: 0.650013, acc.: 63.28%] [G loss: 0.831985]\n",
      "epoch:17 step:16178 [D loss: 0.668214, acc.: 56.25%] [G loss: 0.836991]\n",
      "epoch:17 step:16179 [D loss: 0.654592, acc.: 66.41%] [G loss: 0.830215]\n",
      "epoch:17 step:16180 [D loss: 0.679979, acc.: 54.69%] [G loss: 0.841786]\n",
      "epoch:17 step:16181 [D loss: 0.668826, acc.: 55.47%] [G loss: 0.874866]\n",
      "epoch:17 step:16182 [D loss: 0.680928, acc.: 53.12%] [G loss: 0.878768]\n",
      "epoch:17 step:16183 [D loss: 0.698121, acc.: 57.03%] [G loss: 0.888550]\n",
      "epoch:17 step:16184 [D loss: 0.646949, acc.: 60.16%] [G loss: 0.877338]\n",
      "epoch:17 step:16185 [D loss: 0.657911, acc.: 65.62%] [G loss: 0.909643]\n",
      "epoch:17 step:16186 [D loss: 0.668090, acc.: 54.69%] [G loss: 0.885365]\n",
      "epoch:17 step:16187 [D loss: 0.669595, acc.: 60.94%] [G loss: 0.907463]\n",
      "epoch:17 step:16188 [D loss: 0.677285, acc.: 57.03%] [G loss: 0.967337]\n",
      "epoch:17 step:16189 [D loss: 0.662750, acc.: 61.72%] [G loss: 0.912726]\n",
      "epoch:17 step:16190 [D loss: 0.675613, acc.: 54.69%] [G loss: 0.916847]\n",
      "epoch:17 step:16191 [D loss: 0.679824, acc.: 54.69%] [G loss: 0.910832]\n",
      "epoch:17 step:16192 [D loss: 0.645113, acc.: 59.38%] [G loss: 0.909189]\n",
      "epoch:17 step:16193 [D loss: 0.685339, acc.: 52.34%] [G loss: 0.886859]\n",
      "epoch:17 step:16194 [D loss: 0.642441, acc.: 59.38%] [G loss: 0.893749]\n",
      "epoch:17 step:16195 [D loss: 0.654801, acc.: 60.16%] [G loss: 0.929885]\n",
      "epoch:17 step:16196 [D loss: 0.616789, acc.: 71.09%] [G loss: 0.865992]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16197 [D loss: 0.645360, acc.: 60.94%] [G loss: 0.923002]\n",
      "epoch:17 step:16198 [D loss: 0.680457, acc.: 55.47%] [G loss: 0.917125]\n",
      "epoch:17 step:16199 [D loss: 0.637633, acc.: 62.50%] [G loss: 0.913487]\n",
      "epoch:17 step:16200 [D loss: 0.650692, acc.: 60.94%] [G loss: 0.856703]\n",
      "##############\n",
      "[2.75216921 1.95892034 2.37829956 3.73600145 1.45166399 6.97186681\n",
      " 2.73201873 3.67203545 4.18360981 8.14868929]\n",
      "##########\n",
      "epoch:17 step:16201 [D loss: 0.652151, acc.: 59.38%] [G loss: 0.831686]\n",
      "epoch:17 step:16202 [D loss: 0.701077, acc.: 55.47%] [G loss: 0.827847]\n",
      "epoch:17 step:16203 [D loss: 0.657294, acc.: 61.72%] [G loss: 0.873662]\n",
      "epoch:17 step:16204 [D loss: 0.663531, acc.: 54.69%] [G loss: 0.817963]\n",
      "epoch:17 step:16205 [D loss: 0.710057, acc.: 52.34%] [G loss: 0.873006]\n",
      "epoch:17 step:16206 [D loss: 0.656749, acc.: 64.06%] [G loss: 0.852478]\n",
      "epoch:17 step:16207 [D loss: 0.690375, acc.: 57.03%] [G loss: 0.859051]\n",
      "epoch:17 step:16208 [D loss: 0.702364, acc.: 53.91%] [G loss: 0.861269]\n",
      "epoch:17 step:16209 [D loss: 0.676471, acc.: 55.47%] [G loss: 0.841559]\n",
      "epoch:17 step:16210 [D loss: 0.637678, acc.: 61.72%] [G loss: 0.802244]\n",
      "epoch:17 step:16211 [D loss: 0.673486, acc.: 57.03%] [G loss: 0.821330]\n",
      "epoch:17 step:16212 [D loss: 0.643228, acc.: 64.06%] [G loss: 0.873120]\n",
      "epoch:17 step:16213 [D loss: 0.635972, acc.: 68.75%] [G loss: 0.852026]\n",
      "epoch:17 step:16214 [D loss: 0.611959, acc.: 70.31%] [G loss: 0.859953]\n",
      "epoch:17 step:16215 [D loss: 0.659013, acc.: 64.84%] [G loss: 0.875312]\n",
      "epoch:17 step:16216 [D loss: 0.643937, acc.: 67.97%] [G loss: 0.882630]\n",
      "epoch:17 step:16217 [D loss: 0.623123, acc.: 66.41%] [G loss: 0.867309]\n",
      "epoch:17 step:16218 [D loss: 0.646283, acc.: 62.50%] [G loss: 0.835307]\n",
      "epoch:17 step:16219 [D loss: 0.655346, acc.: 61.72%] [G loss: 0.867521]\n",
      "epoch:17 step:16220 [D loss: 0.684376, acc.: 54.69%] [G loss: 0.827543]\n",
      "epoch:17 step:16221 [D loss: 0.688028, acc.: 56.25%] [G loss: 0.896777]\n",
      "epoch:17 step:16222 [D loss: 0.653777, acc.: 61.72%] [G loss: 0.867998]\n",
      "epoch:17 step:16223 [D loss: 0.650703, acc.: 54.69%] [G loss: 0.905606]\n",
      "epoch:17 step:16224 [D loss: 0.684480, acc.: 54.69%] [G loss: 0.934576]\n",
      "epoch:17 step:16225 [D loss: 0.675690, acc.: 59.38%] [G loss: 0.882148]\n",
      "epoch:17 step:16226 [D loss: 0.633715, acc.: 67.97%] [G loss: 0.911864]\n",
      "epoch:17 step:16227 [D loss: 0.685175, acc.: 52.34%] [G loss: 0.878124]\n",
      "epoch:17 step:16228 [D loss: 0.662117, acc.: 60.94%] [G loss: 0.875582]\n",
      "epoch:17 step:16229 [D loss: 0.665630, acc.: 61.72%] [G loss: 0.890693]\n",
      "epoch:17 step:16230 [D loss: 0.686424, acc.: 56.25%] [G loss: 0.848322]\n",
      "epoch:17 step:16231 [D loss: 0.652357, acc.: 64.06%] [G loss: 0.849805]\n",
      "epoch:17 step:16232 [D loss: 0.660998, acc.: 60.94%] [G loss: 0.877658]\n",
      "epoch:17 step:16233 [D loss: 0.638078, acc.: 62.50%] [G loss: 0.867625]\n",
      "epoch:17 step:16234 [D loss: 0.655126, acc.: 62.50%] [G loss: 0.876990]\n",
      "epoch:17 step:16235 [D loss: 0.641812, acc.: 55.47%] [G loss: 0.893027]\n",
      "epoch:17 step:16236 [D loss: 0.676200, acc.: 56.25%] [G loss: 0.849748]\n",
      "epoch:17 step:16237 [D loss: 0.674375, acc.: 56.25%] [G loss: 0.933876]\n",
      "epoch:17 step:16238 [D loss: 0.671689, acc.: 51.56%] [G loss: 0.887886]\n",
      "epoch:17 step:16239 [D loss: 0.657711, acc.: 55.47%] [G loss: 0.866759]\n",
      "epoch:17 step:16240 [D loss: 0.651969, acc.: 59.38%] [G loss: 0.875042]\n",
      "epoch:17 step:16241 [D loss: 0.647826, acc.: 60.94%] [G loss: 0.861969]\n",
      "epoch:17 step:16242 [D loss: 0.683268, acc.: 59.38%] [G loss: 0.878381]\n",
      "epoch:17 step:16243 [D loss: 0.665168, acc.: 55.47%] [G loss: 0.867751]\n",
      "epoch:17 step:16244 [D loss: 0.651633, acc.: 62.50%] [G loss: 0.824364]\n",
      "epoch:17 step:16245 [D loss: 0.655450, acc.: 57.03%] [G loss: 0.821832]\n",
      "epoch:17 step:16246 [D loss: 0.655309, acc.: 61.72%] [G loss: 0.809798]\n",
      "epoch:17 step:16247 [D loss: 0.667731, acc.: 62.50%] [G loss: 0.880205]\n",
      "epoch:17 step:16248 [D loss: 0.680638, acc.: 53.91%] [G loss: 0.883328]\n",
      "epoch:17 step:16249 [D loss: 0.682290, acc.: 59.38%] [G loss: 0.894355]\n",
      "epoch:17 step:16250 [D loss: 0.654200, acc.: 60.16%] [G loss: 0.906180]\n",
      "epoch:17 step:16251 [D loss: 0.640341, acc.: 60.16%] [G loss: 0.880568]\n",
      "epoch:17 step:16252 [D loss: 0.686004, acc.: 57.81%] [G loss: 0.842768]\n",
      "epoch:17 step:16253 [D loss: 0.644872, acc.: 60.94%] [G loss: 0.882065]\n",
      "epoch:17 step:16254 [D loss: 0.673779, acc.: 55.47%] [G loss: 0.902470]\n",
      "epoch:17 step:16255 [D loss: 0.730181, acc.: 42.97%] [G loss: 0.835605]\n",
      "epoch:17 step:16256 [D loss: 0.668644, acc.: 59.38%] [G loss: 0.880000]\n",
      "epoch:17 step:16257 [D loss: 0.639150, acc.: 65.62%] [G loss: 0.850104]\n",
      "epoch:17 step:16258 [D loss: 0.690094, acc.: 53.12%] [G loss: 0.883250]\n",
      "epoch:17 step:16259 [D loss: 0.693313, acc.: 57.03%] [G loss: 0.884849]\n",
      "epoch:17 step:16260 [D loss: 0.672008, acc.: 57.03%] [G loss: 0.926902]\n",
      "epoch:17 step:16261 [D loss: 0.643744, acc.: 60.94%] [G loss: 0.880756]\n",
      "epoch:17 step:16262 [D loss: 0.671106, acc.: 62.50%] [G loss: 0.887882]\n",
      "epoch:17 step:16263 [D loss: 0.646509, acc.: 64.84%] [G loss: 0.838358]\n",
      "epoch:17 step:16264 [D loss: 0.669216, acc.: 56.25%] [G loss: 0.826456]\n",
      "epoch:17 step:16265 [D loss: 0.643966, acc.: 58.59%] [G loss: 0.849056]\n",
      "epoch:17 step:16266 [D loss: 0.684483, acc.: 53.12%] [G loss: 0.879288]\n",
      "epoch:17 step:16267 [D loss: 0.645169, acc.: 60.94%] [G loss: 0.891364]\n",
      "epoch:17 step:16268 [D loss: 0.662497, acc.: 59.38%] [G loss: 0.866085]\n",
      "epoch:17 step:16269 [D loss: 0.665944, acc.: 59.38%] [G loss: 0.886997]\n",
      "epoch:17 step:16270 [D loss: 0.665669, acc.: 57.03%] [G loss: 0.928699]\n",
      "epoch:17 step:16271 [D loss: 0.649027, acc.: 61.72%] [G loss: 0.970851]\n",
      "epoch:17 step:16272 [D loss: 0.688423, acc.: 55.47%] [G loss: 0.876792]\n",
      "epoch:17 step:16273 [D loss: 0.655794, acc.: 57.03%] [G loss: 0.915930]\n",
      "epoch:17 step:16274 [D loss: 0.664151, acc.: 60.94%] [G loss: 0.871109]\n",
      "epoch:17 step:16275 [D loss: 0.673067, acc.: 57.03%] [G loss: 0.841402]\n",
      "epoch:17 step:16276 [D loss: 0.629819, acc.: 61.72%] [G loss: 0.841483]\n",
      "epoch:17 step:16277 [D loss: 0.699997, acc.: 55.47%] [G loss: 0.831357]\n",
      "epoch:17 step:16278 [D loss: 0.639175, acc.: 60.94%] [G loss: 0.847708]\n",
      "epoch:17 step:16279 [D loss: 0.692411, acc.: 51.56%] [G loss: 0.858832]\n",
      "epoch:17 step:16280 [D loss: 0.668950, acc.: 59.38%] [G loss: 0.923968]\n",
      "epoch:17 step:16281 [D loss: 0.700681, acc.: 53.12%] [G loss: 0.908052]\n",
      "epoch:17 step:16282 [D loss: 0.652717, acc.: 63.28%] [G loss: 0.972040]\n",
      "epoch:17 step:16283 [D loss: 0.697388, acc.: 53.91%] [G loss: 0.872334]\n",
      "epoch:17 step:16284 [D loss: 0.689660, acc.: 56.25%] [G loss: 0.858967]\n",
      "epoch:17 step:16285 [D loss: 0.661776, acc.: 60.16%] [G loss: 0.897368]\n",
      "epoch:17 step:16286 [D loss: 0.691570, acc.: 53.91%] [G loss: 0.890821]\n",
      "epoch:17 step:16287 [D loss: 0.603727, acc.: 73.44%] [G loss: 0.863880]\n",
      "epoch:17 step:16288 [D loss: 0.677043, acc.: 54.69%] [G loss: 0.883580]\n",
      "epoch:17 step:16289 [D loss: 0.641439, acc.: 65.62%] [G loss: 0.853696]\n",
      "epoch:17 step:16290 [D loss: 0.654972, acc.: 59.38%] [G loss: 0.850162]\n",
      "epoch:17 step:16291 [D loss: 0.648188, acc.: 65.62%] [G loss: 0.890787]\n",
      "epoch:17 step:16292 [D loss: 0.673966, acc.: 57.03%] [G loss: 0.871655]\n",
      "epoch:17 step:16293 [D loss: 0.663713, acc.: 57.81%] [G loss: 0.915914]\n",
      "epoch:17 step:16294 [D loss: 0.651163, acc.: 64.06%] [G loss: 0.840712]\n",
      "epoch:17 step:16295 [D loss: 0.677523, acc.: 58.59%] [G loss: 0.906972]\n",
      "epoch:17 step:16296 [D loss: 0.639212, acc.: 64.84%] [G loss: 0.827879]\n",
      "epoch:17 step:16297 [D loss: 0.664675, acc.: 56.25%] [G loss: 0.846986]\n",
      "epoch:17 step:16298 [D loss: 0.669159, acc.: 58.59%] [G loss: 0.825980]\n",
      "epoch:17 step:16299 [D loss: 0.670001, acc.: 52.34%] [G loss: 0.884291]\n",
      "epoch:17 step:16300 [D loss: 0.653795, acc.: 56.25%] [G loss: 0.834392]\n",
      "epoch:17 step:16301 [D loss: 0.654695, acc.: 55.47%] [G loss: 0.872786]\n",
      "epoch:17 step:16302 [D loss: 0.651497, acc.: 60.94%] [G loss: 0.870530]\n",
      "epoch:17 step:16303 [D loss: 0.661336, acc.: 60.94%] [G loss: 0.843811]\n",
      "epoch:17 step:16304 [D loss: 0.670301, acc.: 59.38%] [G loss: 0.910384]\n",
      "epoch:17 step:16305 [D loss: 0.686208, acc.: 54.69%] [G loss: 0.852149]\n",
      "epoch:17 step:16306 [D loss: 0.670337, acc.: 61.72%] [G loss: 0.874865]\n",
      "epoch:17 step:16307 [D loss: 0.624463, acc.: 64.84%] [G loss: 0.893902]\n",
      "epoch:17 step:16308 [D loss: 0.648773, acc.: 61.72%] [G loss: 0.875555]\n",
      "epoch:17 step:16309 [D loss: 0.654816, acc.: 64.06%] [G loss: 0.900423]\n",
      "epoch:17 step:16310 [D loss: 0.659728, acc.: 64.84%] [G loss: 0.902303]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16311 [D loss: 0.661733, acc.: 58.59%] [G loss: 0.918625]\n",
      "epoch:17 step:16312 [D loss: 0.646643, acc.: 64.84%] [G loss: 0.919987]\n",
      "epoch:17 step:16313 [D loss: 0.667223, acc.: 58.59%] [G loss: 0.868020]\n",
      "epoch:17 step:16314 [D loss: 0.663163, acc.: 60.16%] [G loss: 0.884432]\n",
      "epoch:17 step:16315 [D loss: 0.667119, acc.: 57.81%] [G loss: 0.874845]\n",
      "epoch:17 step:16316 [D loss: 0.667692, acc.: 57.81%] [G loss: 0.862955]\n",
      "epoch:17 step:16317 [D loss: 0.662082, acc.: 57.81%] [G loss: 0.911339]\n",
      "epoch:17 step:16318 [D loss: 0.664179, acc.: 58.59%] [G loss: 0.878803]\n",
      "epoch:17 step:16319 [D loss: 0.647938, acc.: 64.84%] [G loss: 0.900327]\n",
      "epoch:17 step:16320 [D loss: 0.719870, acc.: 52.34%] [G loss: 0.884553]\n",
      "epoch:17 step:16321 [D loss: 0.628526, acc.: 64.06%] [G loss: 0.893265]\n",
      "epoch:17 step:16322 [D loss: 0.723475, acc.: 44.53%] [G loss: 0.845630]\n",
      "epoch:17 step:16323 [D loss: 0.642292, acc.: 66.41%] [G loss: 0.908167]\n",
      "epoch:17 step:16324 [D loss: 0.671807, acc.: 57.03%] [G loss: 0.830242]\n",
      "epoch:17 step:16325 [D loss: 0.658950, acc.: 60.94%] [G loss: 0.864412]\n",
      "epoch:17 step:16326 [D loss: 0.683637, acc.: 56.25%] [G loss: 0.875947]\n",
      "epoch:17 step:16327 [D loss: 0.669991, acc.: 57.03%] [G loss: 0.854098]\n",
      "epoch:17 step:16328 [D loss: 0.644648, acc.: 57.81%] [G loss: 0.903522]\n",
      "epoch:17 step:16329 [D loss: 0.643522, acc.: 60.94%] [G loss: 0.873036]\n",
      "epoch:17 step:16330 [D loss: 0.630384, acc.: 64.84%] [G loss: 0.875652]\n",
      "epoch:17 step:16331 [D loss: 0.620690, acc.: 63.28%] [G loss: 0.899539]\n",
      "epoch:17 step:16332 [D loss: 0.623156, acc.: 66.41%] [G loss: 0.949732]\n",
      "epoch:17 step:16333 [D loss: 0.638350, acc.: 64.06%] [G loss: 0.844448]\n",
      "epoch:17 step:16334 [D loss: 0.642667, acc.: 63.28%] [G loss: 0.909913]\n",
      "epoch:17 step:16335 [D loss: 0.687993, acc.: 57.81%] [G loss: 0.886145]\n",
      "epoch:17 step:16336 [D loss: 0.653273, acc.: 65.62%] [G loss: 0.947796]\n",
      "epoch:17 step:16337 [D loss: 0.689383, acc.: 50.78%] [G loss: 0.938359]\n",
      "epoch:17 step:16338 [D loss: 0.649220, acc.: 64.06%] [G loss: 0.860757]\n",
      "epoch:17 step:16339 [D loss: 0.670400, acc.: 60.16%] [G loss: 0.878815]\n",
      "epoch:17 step:16340 [D loss: 0.643333, acc.: 65.62%] [G loss: 0.871976]\n",
      "epoch:17 step:16341 [D loss: 0.658502, acc.: 57.03%] [G loss: 0.834916]\n",
      "epoch:17 step:16342 [D loss: 0.698140, acc.: 50.78%] [G loss: 0.860589]\n",
      "epoch:17 step:16343 [D loss: 0.673542, acc.: 53.91%] [G loss: 0.847502]\n",
      "epoch:17 step:16344 [D loss: 0.691664, acc.: 50.78%] [G loss: 0.873366]\n",
      "epoch:17 step:16345 [D loss: 0.644636, acc.: 62.50%] [G loss: 0.864258]\n",
      "epoch:17 step:16346 [D loss: 0.633953, acc.: 62.50%] [G loss: 0.853137]\n",
      "epoch:17 step:16347 [D loss: 0.717430, acc.: 44.53%] [G loss: 0.822689]\n",
      "epoch:17 step:16348 [D loss: 0.695815, acc.: 49.22%] [G loss: 0.901678]\n",
      "epoch:17 step:16349 [D loss: 0.671904, acc.: 61.72%] [G loss: 0.921916]\n",
      "epoch:17 step:16350 [D loss: 0.663361, acc.: 54.69%] [G loss: 0.918176]\n",
      "epoch:17 step:16351 [D loss: 0.652573, acc.: 60.16%] [G loss: 0.903055]\n",
      "epoch:17 step:16352 [D loss: 0.632630, acc.: 60.94%] [G loss: 0.868680]\n",
      "epoch:17 step:16353 [D loss: 0.627032, acc.: 64.06%] [G loss: 0.937687]\n",
      "epoch:17 step:16354 [D loss: 0.677753, acc.: 51.56%] [G loss: 0.897435]\n",
      "epoch:17 step:16355 [D loss: 0.644377, acc.: 63.28%] [G loss: 0.901366]\n",
      "epoch:17 step:16356 [D loss: 0.697835, acc.: 56.25%] [G loss: 0.889315]\n",
      "epoch:17 step:16357 [D loss: 0.674558, acc.: 63.28%] [G loss: 0.861997]\n",
      "epoch:17 step:16358 [D loss: 0.667412, acc.: 57.03%] [G loss: 0.856321]\n",
      "epoch:17 step:16359 [D loss: 0.709612, acc.: 51.56%] [G loss: 0.839611]\n",
      "epoch:17 step:16360 [D loss: 0.660556, acc.: 64.06%] [G loss: 0.902843]\n",
      "epoch:17 step:16361 [D loss: 0.686810, acc.: 55.47%] [G loss: 0.865630]\n",
      "epoch:17 step:16362 [D loss: 0.669424, acc.: 54.69%] [G loss: 0.851335]\n",
      "epoch:17 step:16363 [D loss: 0.657796, acc.: 60.16%] [G loss: 0.906612]\n",
      "epoch:17 step:16364 [D loss: 0.663872, acc.: 64.06%] [G loss: 0.907939]\n",
      "epoch:17 step:16365 [D loss: 0.682739, acc.: 58.59%] [G loss: 0.856751]\n",
      "epoch:17 step:16366 [D loss: 0.681219, acc.: 57.03%] [G loss: 0.849833]\n",
      "epoch:17 step:16367 [D loss: 0.649116, acc.: 60.94%] [G loss: 0.877020]\n",
      "epoch:17 step:16368 [D loss: 0.677252, acc.: 57.03%] [G loss: 0.887661]\n",
      "epoch:17 step:16369 [D loss: 0.647612, acc.: 64.84%] [G loss: 0.862846]\n",
      "epoch:17 step:16370 [D loss: 0.668905, acc.: 60.94%] [G loss: 0.822998]\n",
      "epoch:17 step:16371 [D loss: 0.647951, acc.: 63.28%] [G loss: 0.875056]\n",
      "epoch:17 step:16372 [D loss: 0.669441, acc.: 60.94%] [G loss: 0.846815]\n",
      "epoch:17 step:16373 [D loss: 0.638608, acc.: 61.72%] [G loss: 0.804808]\n",
      "epoch:17 step:16374 [D loss: 0.644848, acc.: 61.72%] [G loss: 0.801531]\n",
      "epoch:17 step:16375 [D loss: 0.668391, acc.: 55.47%] [G loss: 0.860223]\n",
      "epoch:17 step:16376 [D loss: 0.665327, acc.: 62.50%] [G loss: 0.853421]\n",
      "epoch:17 step:16377 [D loss: 0.674184, acc.: 55.47%] [G loss: 0.848459]\n",
      "epoch:17 step:16378 [D loss: 0.645739, acc.: 58.59%] [G loss: 0.852410]\n",
      "epoch:17 step:16379 [D loss: 0.672771, acc.: 57.81%] [G loss: 0.865366]\n",
      "epoch:17 step:16380 [D loss: 0.649914, acc.: 63.28%] [G loss: 0.866236]\n",
      "epoch:17 step:16381 [D loss: 0.653039, acc.: 58.59%] [G loss: 0.913756]\n",
      "epoch:17 step:16382 [D loss: 0.651090, acc.: 60.16%] [G loss: 0.823799]\n",
      "epoch:17 step:16383 [D loss: 0.668335, acc.: 57.03%] [G loss: 0.908659]\n",
      "epoch:17 step:16384 [D loss: 0.693313, acc.: 52.34%] [G loss: 0.910963]\n",
      "epoch:17 step:16385 [D loss: 0.703395, acc.: 54.69%] [G loss: 0.906319]\n",
      "epoch:17 step:16386 [D loss: 0.640919, acc.: 61.72%] [G loss: 0.907803]\n",
      "epoch:17 step:16387 [D loss: 0.675115, acc.: 59.38%] [G loss: 0.877967]\n",
      "epoch:17 step:16388 [D loss: 0.612483, acc.: 64.84%] [G loss: 0.885747]\n",
      "epoch:17 step:16389 [D loss: 0.662205, acc.: 58.59%] [G loss: 0.906972]\n",
      "epoch:17 step:16390 [D loss: 0.698266, acc.: 51.56%] [G loss: 0.905993]\n",
      "epoch:17 step:16391 [D loss: 0.638332, acc.: 59.38%] [G loss: 0.968418]\n",
      "epoch:17 step:16392 [D loss: 0.629143, acc.: 66.41%] [G loss: 0.836091]\n",
      "epoch:17 step:16393 [D loss: 0.659261, acc.: 58.59%] [G loss: 0.842105]\n",
      "epoch:17 step:16394 [D loss: 0.678556, acc.: 57.81%] [G loss: 0.846675]\n",
      "epoch:17 step:16395 [D loss: 0.640316, acc.: 65.62%] [G loss: 0.781883]\n",
      "epoch:17 step:16396 [D loss: 0.666083, acc.: 57.81%] [G loss: 0.847311]\n",
      "epoch:17 step:16397 [D loss: 0.636244, acc.: 70.31%] [G loss: 0.892158]\n",
      "epoch:17 step:16398 [D loss: 0.628427, acc.: 65.62%] [G loss: 0.844342]\n",
      "epoch:17 step:16399 [D loss: 0.684337, acc.: 54.69%] [G loss: 0.834706]\n",
      "epoch:17 step:16400 [D loss: 0.653569, acc.: 57.03%] [G loss: 0.833119]\n",
      "##############\n",
      "[3.02530476 2.36818017 2.03015323 3.82751812 1.32056612 9.27329063\n",
      " 2.57949366 3.66031367 4.0281212  8.14868929]\n",
      "##########\n",
      "epoch:17 step:16401 [D loss: 0.645755, acc.: 62.50%] [G loss: 0.903287]\n",
      "epoch:17 step:16402 [D loss: 0.642070, acc.: 65.62%] [G loss: 0.870581]\n",
      "epoch:17 step:16403 [D loss: 0.628929, acc.: 67.97%] [G loss: 0.888231]\n",
      "epoch:17 step:16404 [D loss: 0.646231, acc.: 67.19%] [G loss: 0.895314]\n",
      "epoch:17 step:16405 [D loss: 0.638961, acc.: 65.62%] [G loss: 0.965655]\n",
      "epoch:17 step:16406 [D loss: 0.673371, acc.: 63.28%] [G loss: 0.953349]\n",
      "epoch:17 step:16407 [D loss: 0.626915, acc.: 64.06%] [G loss: 0.858814]\n",
      "epoch:17 step:16408 [D loss: 0.644937, acc.: 69.53%] [G loss: 0.890564]\n",
      "epoch:17 step:16409 [D loss: 0.686287, acc.: 57.03%] [G loss: 0.825582]\n",
      "epoch:17 step:16410 [D loss: 0.663982, acc.: 58.59%] [G loss: 0.837091]\n",
      "epoch:17 step:16411 [D loss: 0.652701, acc.: 65.62%] [G loss: 0.837335]\n",
      "epoch:17 step:16412 [D loss: 0.692660, acc.: 54.69%] [G loss: 0.886139]\n",
      "epoch:17 step:16413 [D loss: 0.652371, acc.: 57.03%] [G loss: 0.890414]\n",
      "epoch:17 step:16414 [D loss: 0.700213, acc.: 57.03%] [G loss: 0.908692]\n",
      "epoch:17 step:16415 [D loss: 0.652514, acc.: 60.16%] [G loss: 0.908407]\n",
      "epoch:17 step:16416 [D loss: 0.668836, acc.: 61.72%] [G loss: 0.851772]\n",
      "epoch:17 step:16417 [D loss: 0.608685, acc.: 70.31%] [G loss: 0.871686]\n",
      "epoch:17 step:16418 [D loss: 0.636864, acc.: 67.19%] [G loss: 0.874120]\n",
      "epoch:17 step:16419 [D loss: 0.678220, acc.: 60.94%] [G loss: 0.889021]\n",
      "epoch:17 step:16420 [D loss: 0.637752, acc.: 61.72%] [G loss: 0.788170]\n",
      "epoch:17 step:16421 [D loss: 0.639501, acc.: 66.41%] [G loss: 0.809955]\n",
      "epoch:17 step:16422 [D loss: 0.704039, acc.: 59.38%] [G loss: 0.850682]\n",
      "epoch:17 step:16423 [D loss: 0.648930, acc.: 59.38%] [G loss: 0.817119]\n",
      "epoch:17 step:16424 [D loss: 0.688607, acc.: 57.03%] [G loss: 0.877381]\n",
      "epoch:17 step:16425 [D loss: 0.687421, acc.: 53.91%] [G loss: 0.903389]\n",
      "epoch:17 step:16426 [D loss: 0.634672, acc.: 59.38%] [G loss: 0.891672]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16427 [D loss: 0.654184, acc.: 60.16%] [G loss: 0.912398]\n",
      "epoch:17 step:16428 [D loss: 0.672185, acc.: 62.50%] [G loss: 0.923543]\n",
      "epoch:17 step:16429 [D loss: 0.644586, acc.: 63.28%] [G loss: 0.932349]\n",
      "epoch:17 step:16430 [D loss: 0.634252, acc.: 67.97%] [G loss: 0.902048]\n",
      "epoch:17 step:16431 [D loss: 0.659396, acc.: 61.72%] [G loss: 0.857975]\n",
      "epoch:17 step:16432 [D loss: 0.667703, acc.: 57.81%] [G loss: 0.871492]\n",
      "epoch:17 step:16433 [D loss: 0.684360, acc.: 54.69%] [G loss: 0.862393]\n",
      "epoch:17 step:16434 [D loss: 0.662903, acc.: 60.16%] [G loss: 0.852015]\n",
      "epoch:17 step:16435 [D loss: 0.664161, acc.: 57.81%] [G loss: 0.864169]\n",
      "epoch:17 step:16436 [D loss: 0.651033, acc.: 64.06%] [G loss: 0.849015]\n",
      "epoch:17 step:16437 [D loss: 0.670824, acc.: 61.72%] [G loss: 0.853107]\n",
      "epoch:17 step:16438 [D loss: 0.644964, acc.: 63.28%] [G loss: 0.880762]\n",
      "epoch:17 step:16439 [D loss: 0.637985, acc.: 59.38%] [G loss: 0.885627]\n",
      "epoch:17 step:16440 [D loss: 0.660068, acc.: 62.50%] [G loss: 0.944138]\n",
      "epoch:17 step:16441 [D loss: 0.690305, acc.: 57.81%] [G loss: 0.890862]\n",
      "epoch:17 step:16442 [D loss: 0.630925, acc.: 64.06%] [G loss: 0.855616]\n",
      "epoch:17 step:16443 [D loss: 0.662238, acc.: 55.47%] [G loss: 0.817962]\n",
      "epoch:17 step:16444 [D loss: 0.655701, acc.: 59.38%] [G loss: 0.844831]\n",
      "epoch:17 step:16445 [D loss: 0.651350, acc.: 57.03%] [G loss: 0.804158]\n",
      "epoch:17 step:16446 [D loss: 0.659498, acc.: 59.38%] [G loss: 0.863023]\n",
      "epoch:17 step:16447 [D loss: 0.677076, acc.: 58.59%] [G loss: 0.901963]\n",
      "epoch:17 step:16448 [D loss: 0.642703, acc.: 60.94%] [G loss: 0.863469]\n",
      "epoch:17 step:16449 [D loss: 0.634739, acc.: 65.62%] [G loss: 0.875579]\n",
      "epoch:17 step:16450 [D loss: 0.625858, acc.: 66.41%] [G loss: 0.856477]\n",
      "epoch:17 step:16451 [D loss: 0.670207, acc.: 58.59%] [G loss: 0.883788]\n",
      "epoch:17 step:16452 [D loss: 0.637258, acc.: 62.50%] [G loss: 0.865361]\n",
      "epoch:17 step:16453 [D loss: 0.676077, acc.: 59.38%] [G loss: 0.911222]\n",
      "epoch:17 step:16454 [D loss: 0.679357, acc.: 59.38%] [G loss: 0.902497]\n",
      "epoch:17 step:16455 [D loss: 0.670617, acc.: 64.06%] [G loss: 0.900392]\n",
      "epoch:17 step:16456 [D loss: 0.667214, acc.: 59.38%] [G loss: 0.847317]\n",
      "epoch:17 step:16457 [D loss: 0.657478, acc.: 65.62%] [G loss: 0.876792]\n",
      "epoch:17 step:16458 [D loss: 0.654091, acc.: 57.03%] [G loss: 0.829068]\n",
      "epoch:17 step:16459 [D loss: 0.671311, acc.: 60.94%] [G loss: 0.869277]\n",
      "epoch:17 step:16460 [D loss: 0.683990, acc.: 59.38%] [G loss: 0.870978]\n",
      "epoch:17 step:16461 [D loss: 0.654363, acc.: 62.50%] [G loss: 0.818450]\n",
      "epoch:17 step:16462 [D loss: 0.678754, acc.: 56.25%] [G loss: 0.876250]\n",
      "epoch:17 step:16463 [D loss: 0.678120, acc.: 61.72%] [G loss: 0.900530]\n",
      "epoch:17 step:16464 [D loss: 0.689336, acc.: 51.56%] [G loss: 0.815291]\n",
      "epoch:17 step:16465 [D loss: 0.665652, acc.: 59.38%] [G loss: 0.802611]\n",
      "epoch:17 step:16466 [D loss: 0.682258, acc.: 53.91%] [G loss: 0.873779]\n",
      "epoch:17 step:16467 [D loss: 0.670361, acc.: 60.16%] [G loss: 0.873499]\n",
      "epoch:17 step:16468 [D loss: 0.673382, acc.: 63.28%] [G loss: 0.879540]\n",
      "epoch:17 step:16469 [D loss: 0.666128, acc.: 57.03%] [G loss: 0.815354]\n",
      "epoch:17 step:16470 [D loss: 0.651579, acc.: 65.62%] [G loss: 0.894839]\n",
      "epoch:17 step:16471 [D loss: 0.653104, acc.: 64.06%] [G loss: 0.818994]\n",
      "epoch:17 step:16472 [D loss: 0.668880, acc.: 57.03%] [G loss: 0.814002]\n",
      "epoch:17 step:16473 [D loss: 0.649591, acc.: 64.84%] [G loss: 0.827621]\n",
      "epoch:17 step:16474 [D loss: 0.656789, acc.: 60.94%] [G loss: 0.837076]\n",
      "epoch:17 step:16475 [D loss: 0.645210, acc.: 64.84%] [G loss: 0.841596]\n",
      "epoch:17 step:16476 [D loss: 0.679388, acc.: 59.38%] [G loss: 0.849432]\n",
      "epoch:17 step:16477 [D loss: 0.687432, acc.: 60.16%] [G loss: 0.868289]\n",
      "epoch:17 step:16478 [D loss: 0.678824, acc.: 53.91%] [G loss: 0.835013]\n",
      "epoch:17 step:16479 [D loss: 0.679555, acc.: 57.81%] [G loss: 0.860387]\n",
      "epoch:17 step:16480 [D loss: 0.710208, acc.: 51.56%] [G loss: 0.860974]\n",
      "epoch:17 step:16481 [D loss: 0.656055, acc.: 60.94%] [G loss: 0.911556]\n",
      "epoch:17 step:16482 [D loss: 0.677979, acc.: 56.25%] [G loss: 0.877812]\n",
      "epoch:17 step:16483 [D loss: 0.696124, acc.: 51.56%] [G loss: 0.911245]\n",
      "epoch:17 step:16484 [D loss: 0.683772, acc.: 55.47%] [G loss: 0.892985]\n",
      "epoch:17 step:16485 [D loss: 0.638433, acc.: 64.84%] [G loss: 0.919276]\n",
      "epoch:17 step:16486 [D loss: 0.716020, acc.: 48.44%] [G loss: 0.887470]\n",
      "epoch:17 step:16487 [D loss: 0.660636, acc.: 60.94%] [G loss: 0.901999]\n",
      "epoch:17 step:16488 [D loss: 0.708662, acc.: 53.91%] [G loss: 0.852627]\n",
      "epoch:17 step:16489 [D loss: 0.663410, acc.: 57.81%] [G loss: 0.885751]\n",
      "epoch:17 step:16490 [D loss: 0.643853, acc.: 71.09%] [G loss: 0.821651]\n",
      "epoch:17 step:16491 [D loss: 0.625887, acc.: 66.41%] [G loss: 0.830166]\n",
      "epoch:17 step:16492 [D loss: 0.625938, acc.: 65.62%] [G loss: 0.840585]\n",
      "epoch:17 step:16493 [D loss: 0.640825, acc.: 64.06%] [G loss: 0.878885]\n",
      "epoch:17 step:16494 [D loss: 0.687589, acc.: 53.91%] [G loss: 0.869459]\n",
      "epoch:17 step:16495 [D loss: 0.603595, acc.: 70.31%] [G loss: 0.886712]\n",
      "epoch:17 step:16496 [D loss: 0.639755, acc.: 61.72%] [G loss: 0.871522]\n",
      "epoch:17 step:16497 [D loss: 0.654163, acc.: 60.16%] [G loss: 0.832196]\n",
      "epoch:17 step:16498 [D loss: 0.645681, acc.: 66.41%] [G loss: 0.881945]\n",
      "epoch:17 step:16499 [D loss: 0.673410, acc.: 60.16%] [G loss: 0.825421]\n",
      "epoch:17 step:16500 [D loss: 0.665538, acc.: 58.59%] [G loss: 0.814827]\n",
      "epoch:17 step:16501 [D loss: 0.644299, acc.: 67.19%] [G loss: 0.880438]\n",
      "epoch:17 step:16502 [D loss: 0.672468, acc.: 62.50%] [G loss: 0.845949]\n",
      "epoch:17 step:16503 [D loss: 0.700192, acc.: 51.56%] [G loss: 0.860771]\n",
      "epoch:17 step:16504 [D loss: 0.692782, acc.: 53.91%] [G loss: 0.898016]\n",
      "epoch:17 step:16505 [D loss: 0.662362, acc.: 65.62%] [G loss: 0.871890]\n",
      "epoch:17 step:16506 [D loss: 0.671702, acc.: 54.69%] [G loss: 0.919435]\n",
      "epoch:17 step:16507 [D loss: 0.659423, acc.: 57.03%] [G loss: 0.856819]\n",
      "epoch:17 step:16508 [D loss: 0.669106, acc.: 59.38%] [G loss: 0.846292]\n",
      "epoch:17 step:16509 [D loss: 0.684235, acc.: 53.91%] [G loss: 0.839301]\n",
      "epoch:17 step:16510 [D loss: 0.653475, acc.: 60.16%] [G loss: 0.845370]\n",
      "epoch:17 step:16511 [D loss: 0.663294, acc.: 63.28%] [G loss: 0.838119]\n",
      "epoch:17 step:16512 [D loss: 0.688192, acc.: 56.25%] [G loss: 0.859832]\n",
      "epoch:17 step:16513 [D loss: 0.623537, acc.: 68.75%] [G loss: 0.869769]\n",
      "epoch:17 step:16514 [D loss: 0.653285, acc.: 62.50%] [G loss: 0.819577]\n",
      "epoch:17 step:16515 [D loss: 0.703629, acc.: 55.47%] [G loss: 0.891142]\n",
      "epoch:17 step:16516 [D loss: 0.663581, acc.: 61.72%] [G loss: 0.875458]\n",
      "epoch:17 step:16517 [D loss: 0.701561, acc.: 46.88%] [G loss: 0.920292]\n",
      "epoch:17 step:16518 [D loss: 0.648907, acc.: 64.84%] [G loss: 0.892660]\n",
      "epoch:17 step:16519 [D loss: 0.649623, acc.: 62.50%] [G loss: 0.841720]\n",
      "epoch:17 step:16520 [D loss: 0.662963, acc.: 59.38%] [G loss: 0.842198]\n",
      "epoch:17 step:16521 [D loss: 0.647606, acc.: 59.38%] [G loss: 0.903190]\n",
      "epoch:17 step:16522 [D loss: 0.678814, acc.: 50.00%] [G loss: 0.860985]\n",
      "epoch:17 step:16523 [D loss: 0.630926, acc.: 67.97%] [G loss: 0.854054]\n",
      "epoch:17 step:16524 [D loss: 0.620991, acc.: 67.19%] [G loss: 0.867169]\n",
      "epoch:17 step:16525 [D loss: 0.703020, acc.: 55.47%] [G loss: 0.818031]\n",
      "epoch:17 step:16526 [D loss: 0.672189, acc.: 61.72%] [G loss: 0.824931]\n",
      "epoch:17 step:16527 [D loss: 0.648147, acc.: 60.16%] [G loss: 0.842577]\n",
      "epoch:17 step:16528 [D loss: 0.635292, acc.: 61.72%] [G loss: 0.894909]\n",
      "epoch:17 step:16529 [D loss: 0.662954, acc.: 52.34%] [G loss: 0.905185]\n",
      "epoch:17 step:16530 [D loss: 0.692622, acc.: 57.03%] [G loss: 0.868768]\n",
      "epoch:17 step:16531 [D loss: 0.643655, acc.: 63.28%] [G loss: 0.906674]\n",
      "epoch:17 step:16532 [D loss: 0.684404, acc.: 59.38%] [G loss: 0.843916]\n",
      "epoch:17 step:16533 [D loss: 0.680001, acc.: 56.25%] [G loss: 0.882096]\n",
      "epoch:17 step:16534 [D loss: 0.672591, acc.: 63.28%] [G loss: 0.890336]\n",
      "epoch:17 step:16535 [D loss: 0.648232, acc.: 63.28%] [G loss: 0.924852]\n",
      "epoch:17 step:16536 [D loss: 0.663508, acc.: 63.28%] [G loss: 0.909934]\n",
      "epoch:17 step:16537 [D loss: 0.658440, acc.: 57.81%] [G loss: 0.874025]\n",
      "epoch:17 step:16538 [D loss: 0.631447, acc.: 66.41%] [G loss: 0.825613]\n",
      "epoch:17 step:16539 [D loss: 0.668150, acc.: 59.38%] [G loss: 0.835683]\n",
      "epoch:17 step:16540 [D loss: 0.662857, acc.: 60.16%] [G loss: 0.811545]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16541 [D loss: 0.661853, acc.: 61.72%] [G loss: 0.763397]\n",
      "epoch:17 step:16542 [D loss: 0.633045, acc.: 66.41%] [G loss: 0.842466]\n",
      "epoch:17 step:16543 [D loss: 0.645482, acc.: 63.28%] [G loss: 0.847465]\n",
      "epoch:17 step:16544 [D loss: 0.705098, acc.: 55.47%] [G loss: 0.842194]\n",
      "epoch:17 step:16545 [D loss: 0.650131, acc.: 64.84%] [G loss: 0.903171]\n",
      "epoch:17 step:16546 [D loss: 0.656466, acc.: 60.94%] [G loss: 0.892011]\n",
      "epoch:17 step:16547 [D loss: 0.638554, acc.: 60.94%] [G loss: 0.896126]\n",
      "epoch:17 step:16548 [D loss: 0.675424, acc.: 60.94%] [G loss: 0.923824]\n",
      "epoch:17 step:16549 [D loss: 0.678980, acc.: 55.47%] [G loss: 0.838631]\n",
      "epoch:17 step:16550 [D loss: 0.682869, acc.: 54.69%] [G loss: 0.898586]\n",
      "epoch:17 step:16551 [D loss: 0.638889, acc.: 66.41%] [G loss: 0.871742]\n",
      "epoch:17 step:16552 [D loss: 0.687404, acc.: 61.72%] [G loss: 0.876998]\n",
      "epoch:17 step:16553 [D loss: 0.677325, acc.: 57.03%] [G loss: 0.860189]\n",
      "epoch:17 step:16554 [D loss: 0.620088, acc.: 67.19%] [G loss: 0.884008]\n",
      "epoch:17 step:16555 [D loss: 0.722682, acc.: 43.75%] [G loss: 0.873523]\n",
      "epoch:17 step:16556 [D loss: 0.615415, acc.: 68.75%] [G loss: 0.847708]\n",
      "epoch:17 step:16557 [D loss: 0.704420, acc.: 54.69%] [G loss: 0.873292]\n",
      "epoch:17 step:16558 [D loss: 0.699532, acc.: 55.47%] [G loss: 0.794101]\n",
      "epoch:17 step:16559 [D loss: 0.667013, acc.: 58.59%] [G loss: 0.819576]\n",
      "epoch:17 step:16560 [D loss: 0.657939, acc.: 63.28%] [G loss: 0.838190]\n",
      "epoch:17 step:16561 [D loss: 0.649040, acc.: 67.19%] [G loss: 0.907977]\n",
      "epoch:17 step:16562 [D loss: 0.642354, acc.: 70.31%] [G loss: 0.879057]\n",
      "epoch:17 step:16563 [D loss: 0.630693, acc.: 70.31%] [G loss: 0.889916]\n",
      "epoch:17 step:16564 [D loss: 0.660057, acc.: 64.84%] [G loss: 0.860203]\n",
      "epoch:17 step:16565 [D loss: 0.650763, acc.: 65.62%] [G loss: 0.867319]\n",
      "epoch:17 step:16566 [D loss: 0.647900, acc.: 62.50%] [G loss: 0.917797]\n",
      "epoch:17 step:16567 [D loss: 0.679560, acc.: 56.25%] [G loss: 0.912642]\n",
      "epoch:17 step:16568 [D loss: 0.667934, acc.: 64.84%] [G loss: 0.856664]\n",
      "epoch:17 step:16569 [D loss: 0.652509, acc.: 58.59%] [G loss: 0.932775]\n",
      "epoch:17 step:16570 [D loss: 0.709170, acc.: 53.12%] [G loss: 0.901403]\n",
      "epoch:17 step:16571 [D loss: 0.650476, acc.: 56.25%] [G loss: 0.877587]\n",
      "epoch:17 step:16572 [D loss: 0.693932, acc.: 57.03%] [G loss: 0.896424]\n",
      "epoch:17 step:16573 [D loss: 0.687458, acc.: 55.47%] [G loss: 0.878349]\n",
      "epoch:17 step:16574 [D loss: 0.656632, acc.: 58.59%] [G loss: 0.863464]\n",
      "epoch:17 step:16575 [D loss: 0.680302, acc.: 50.00%] [G loss: 0.868312]\n",
      "epoch:17 step:16576 [D loss: 0.686077, acc.: 60.94%] [G loss: 0.871291]\n",
      "epoch:17 step:16577 [D loss: 0.618499, acc.: 67.97%] [G loss: 0.837735]\n",
      "epoch:17 step:16578 [D loss: 0.670065, acc.: 54.69%] [G loss: 0.891502]\n",
      "epoch:17 step:16579 [D loss: 0.703259, acc.: 57.81%] [G loss: 0.866995]\n",
      "epoch:17 step:16580 [D loss: 0.670042, acc.: 54.69%] [G loss: 0.861096]\n",
      "epoch:17 step:16581 [D loss: 0.701227, acc.: 58.59%] [G loss: 0.845880]\n",
      "epoch:17 step:16582 [D loss: 0.648676, acc.: 64.06%] [G loss: 0.831347]\n",
      "epoch:17 step:16583 [D loss: 0.679060, acc.: 51.56%] [G loss: 0.861715]\n",
      "epoch:17 step:16584 [D loss: 0.705829, acc.: 52.34%] [G loss: 0.793148]\n",
      "epoch:17 step:16585 [D loss: 0.684366, acc.: 52.34%] [G loss: 0.852802]\n",
      "epoch:17 step:16586 [D loss: 0.658216, acc.: 56.25%] [G loss: 0.820772]\n",
      "epoch:17 step:16587 [D loss: 0.687953, acc.: 58.59%] [G loss: 0.848212]\n",
      "epoch:17 step:16588 [D loss: 0.662802, acc.: 57.03%] [G loss: 0.780862]\n",
      "epoch:17 step:16589 [D loss: 0.680456, acc.: 59.38%] [G loss: 0.824234]\n",
      "epoch:17 step:16590 [D loss: 0.681390, acc.: 57.03%] [G loss: 0.888530]\n",
      "epoch:17 step:16591 [D loss: 0.703822, acc.: 51.56%] [G loss: 0.857305]\n",
      "epoch:17 step:16592 [D loss: 0.663444, acc.: 57.81%] [G loss: 0.879143]\n",
      "epoch:17 step:16593 [D loss: 0.668478, acc.: 59.38%] [G loss: 0.823204]\n",
      "epoch:17 step:16594 [D loss: 0.651881, acc.: 61.72%] [G loss: 0.867941]\n",
      "epoch:17 step:16595 [D loss: 0.654160, acc.: 60.94%] [G loss: 0.842779]\n",
      "epoch:17 step:16596 [D loss: 0.692821, acc.: 55.47%] [G loss: 0.816163]\n",
      "epoch:17 step:16597 [D loss: 0.674501, acc.: 59.38%] [G loss: 0.798824]\n",
      "epoch:17 step:16598 [D loss: 0.641697, acc.: 60.94%] [G loss: 0.843045]\n",
      "epoch:17 step:16599 [D loss: 0.645432, acc.: 63.28%] [G loss: 0.848481]\n",
      "epoch:17 step:16600 [D loss: 0.658046, acc.: 61.72%] [G loss: 0.832711]\n",
      "##############\n",
      "[3.1208758  2.39157351 2.28427884 3.83980387 1.37337118 9.27426719\n",
      " 2.90467314 3.69453908 4.28837408 5.88263513]\n",
      "##########\n",
      "epoch:17 step:16601 [D loss: 0.695346, acc.: 51.56%] [G loss: 0.813556]\n",
      "epoch:17 step:16602 [D loss: 0.666464, acc.: 61.72%] [G loss: 0.843630]\n",
      "epoch:17 step:16603 [D loss: 0.680896, acc.: 59.38%] [G loss: 0.890860]\n",
      "epoch:17 step:16604 [D loss: 0.653322, acc.: 57.81%] [G loss: 0.858070]\n",
      "epoch:17 step:16605 [D loss: 0.664989, acc.: 60.16%] [G loss: 0.836350]\n",
      "epoch:17 step:16606 [D loss: 0.693598, acc.: 52.34%] [G loss: 0.790661]\n",
      "epoch:17 step:16607 [D loss: 0.689274, acc.: 56.25%] [G loss: 0.841636]\n",
      "epoch:17 step:16608 [D loss: 0.646707, acc.: 63.28%] [G loss: 0.821542]\n",
      "epoch:17 step:16609 [D loss: 0.677118, acc.: 53.12%] [G loss: 0.765389]\n",
      "epoch:17 step:16610 [D loss: 0.641536, acc.: 64.06%] [G loss: 0.824266]\n",
      "epoch:17 step:16611 [D loss: 0.668652, acc.: 59.38%] [G loss: 0.795778]\n",
      "epoch:17 step:16612 [D loss: 0.653214, acc.: 58.59%] [G loss: 0.826064]\n",
      "epoch:17 step:16613 [D loss: 0.669324, acc.: 64.06%] [G loss: 0.835458]\n",
      "epoch:17 step:16614 [D loss: 0.691284, acc.: 58.59%] [G loss: 0.865003]\n",
      "epoch:17 step:16615 [D loss: 0.688830, acc.: 55.47%] [G loss: 0.853365]\n",
      "epoch:17 step:16616 [D loss: 0.674129, acc.: 55.47%] [G loss: 0.909982]\n",
      "epoch:17 step:16617 [D loss: 0.631317, acc.: 60.94%] [G loss: 0.916116]\n",
      "epoch:17 step:16618 [D loss: 0.654425, acc.: 57.03%] [G loss: 0.920044]\n",
      "epoch:17 step:16619 [D loss: 0.676980, acc.: 58.59%] [G loss: 0.834031]\n",
      "epoch:17 step:16620 [D loss: 0.687616, acc.: 52.34%] [G loss: 0.862106]\n",
      "epoch:17 step:16621 [D loss: 0.675547, acc.: 59.38%] [G loss: 0.858913]\n",
      "epoch:17 step:16622 [D loss: 0.668289, acc.: 63.28%] [G loss: 0.844074]\n",
      "epoch:17 step:16623 [D loss: 0.663927, acc.: 62.50%] [G loss: 0.855807]\n",
      "epoch:17 step:16624 [D loss: 0.672789, acc.: 61.72%] [G loss: 0.853045]\n",
      "epoch:17 step:16625 [D loss: 0.654949, acc.: 65.62%] [G loss: 0.868532]\n",
      "epoch:17 step:16626 [D loss: 0.650118, acc.: 63.28%] [G loss: 0.907987]\n",
      "epoch:17 step:16627 [D loss: 0.675286, acc.: 57.81%] [G loss: 0.898250]\n",
      "epoch:17 step:16628 [D loss: 0.667134, acc.: 60.16%] [G loss: 0.864209]\n",
      "epoch:17 step:16629 [D loss: 0.660284, acc.: 62.50%] [G loss: 0.841680]\n",
      "epoch:17 step:16630 [D loss: 0.674746, acc.: 55.47%] [G loss: 0.935323]\n",
      "epoch:17 step:16631 [D loss: 0.679128, acc.: 54.69%] [G loss: 0.877433]\n",
      "epoch:17 step:16632 [D loss: 0.699525, acc.: 57.03%] [G loss: 0.856334]\n",
      "epoch:17 step:16633 [D loss: 0.641603, acc.: 60.16%] [G loss: 0.825008]\n",
      "epoch:17 step:16634 [D loss: 0.660243, acc.: 60.94%] [G loss: 0.863013]\n",
      "epoch:17 step:16635 [D loss: 0.672839, acc.: 53.91%] [G loss: 0.853215]\n",
      "epoch:17 step:16636 [D loss: 0.673275, acc.: 58.59%] [G loss: 0.876964]\n",
      "epoch:17 step:16637 [D loss: 0.659813, acc.: 57.03%] [G loss: 0.817320]\n",
      "epoch:17 step:16638 [D loss: 0.689486, acc.: 57.03%] [G loss: 0.836156]\n",
      "epoch:17 step:16639 [D loss: 0.618460, acc.: 73.44%] [G loss: 0.914338]\n",
      "epoch:17 step:16640 [D loss: 0.656165, acc.: 60.94%] [G loss: 0.882165]\n",
      "epoch:17 step:16641 [D loss: 0.713546, acc.: 50.78%] [G loss: 0.865798]\n",
      "epoch:17 step:16642 [D loss: 0.696812, acc.: 60.94%] [G loss: 0.922056]\n",
      "epoch:17 step:16643 [D loss: 0.699549, acc.: 54.69%] [G loss: 0.851531]\n",
      "epoch:17 step:16644 [D loss: 0.708052, acc.: 52.34%] [G loss: 0.864921]\n",
      "epoch:17 step:16645 [D loss: 0.679756, acc.: 53.91%] [G loss: 0.897130]\n",
      "epoch:17 step:16646 [D loss: 0.649670, acc.: 59.38%] [G loss: 0.905862]\n",
      "epoch:17 step:16647 [D loss: 0.654992, acc.: 61.72%] [G loss: 0.912272]\n",
      "epoch:17 step:16648 [D loss: 0.664200, acc.: 62.50%] [G loss: 0.896327]\n",
      "epoch:17 step:16649 [D loss: 0.650712, acc.: 60.16%] [G loss: 0.844545]\n",
      "epoch:17 step:16650 [D loss: 0.698982, acc.: 59.38%] [G loss: 0.867145]\n",
      "epoch:17 step:16651 [D loss: 0.637488, acc.: 60.94%] [G loss: 0.852363]\n",
      "epoch:17 step:16652 [D loss: 0.673464, acc.: 55.47%] [G loss: 0.810113]\n",
      "epoch:17 step:16653 [D loss: 0.690367, acc.: 52.34%] [G loss: 0.869068]\n",
      "epoch:17 step:16654 [D loss: 0.680029, acc.: 58.59%] [G loss: 0.818330]\n",
      "epoch:17 step:16655 [D loss: 0.658604, acc.: 60.16%] [G loss: 0.864297]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16656 [D loss: 0.651626, acc.: 62.50%] [G loss: 0.911462]\n",
      "epoch:17 step:16657 [D loss: 0.676850, acc.: 60.16%] [G loss: 0.809511]\n",
      "epoch:17 step:16658 [D loss: 0.669809, acc.: 57.81%] [G loss: 0.894523]\n",
      "epoch:17 step:16659 [D loss: 0.673685, acc.: 53.12%] [G loss: 0.869334]\n",
      "epoch:17 step:16660 [D loss: 0.630059, acc.: 67.97%] [G loss: 0.906991]\n",
      "epoch:17 step:16661 [D loss: 0.643272, acc.: 64.06%] [G loss: 0.951390]\n",
      "epoch:17 step:16662 [D loss: 0.639450, acc.: 67.19%] [G loss: 0.917345]\n",
      "epoch:17 step:16663 [D loss: 0.670538, acc.: 57.81%] [G loss: 0.886653]\n",
      "epoch:17 step:16664 [D loss: 0.672582, acc.: 57.03%] [G loss: 0.848280]\n",
      "epoch:17 step:16665 [D loss: 0.656698, acc.: 60.16%] [G loss: 0.848304]\n",
      "epoch:17 step:16666 [D loss: 0.685152, acc.: 51.56%] [G loss: 0.879465]\n",
      "epoch:17 step:16667 [D loss: 0.664461, acc.: 57.03%] [G loss: 0.902142]\n",
      "epoch:17 step:16668 [D loss: 0.656380, acc.: 56.25%] [G loss: 0.843917]\n",
      "epoch:17 step:16669 [D loss: 0.677062, acc.: 60.94%] [G loss: 0.895422]\n",
      "epoch:17 step:16670 [D loss: 0.658643, acc.: 61.72%] [G loss: 0.872999]\n",
      "epoch:17 step:16671 [D loss: 0.657841, acc.: 65.62%] [G loss: 0.873961]\n",
      "epoch:17 step:16672 [D loss: 0.669366, acc.: 52.34%] [G loss: 0.863971]\n",
      "epoch:17 step:16673 [D loss: 0.679492, acc.: 53.12%] [G loss: 0.850883]\n",
      "epoch:17 step:16674 [D loss: 0.632387, acc.: 68.75%] [G loss: 0.874901]\n",
      "epoch:17 step:16675 [D loss: 0.692278, acc.: 56.25%] [G loss: 0.825842]\n",
      "epoch:17 step:16676 [D loss: 0.663697, acc.: 57.81%] [G loss: 0.861723]\n",
      "epoch:17 step:16677 [D loss: 0.666276, acc.: 60.94%] [G loss: 0.898064]\n",
      "epoch:17 step:16678 [D loss: 0.650439, acc.: 61.72%] [G loss: 0.846025]\n",
      "epoch:17 step:16679 [D loss: 0.626238, acc.: 67.97%] [G loss: 0.873896]\n",
      "epoch:17 step:16680 [D loss: 0.605285, acc.: 71.88%] [G loss: 0.928980]\n",
      "epoch:17 step:16681 [D loss: 0.657397, acc.: 57.03%] [G loss: 0.881321]\n",
      "epoch:17 step:16682 [D loss: 0.655196, acc.: 60.16%] [G loss: 0.905929]\n",
      "epoch:17 step:16683 [D loss: 0.674733, acc.: 61.72%] [G loss: 0.922234]\n",
      "epoch:17 step:16684 [D loss: 0.690070, acc.: 57.81%] [G loss: 0.899743]\n",
      "epoch:17 step:16685 [D loss: 0.646777, acc.: 63.28%] [G loss: 0.899964]\n",
      "epoch:17 step:16686 [D loss: 0.643708, acc.: 64.06%] [G loss: 0.817578]\n",
      "epoch:17 step:16687 [D loss: 0.669759, acc.: 57.81%] [G loss: 0.895979]\n",
      "epoch:17 step:16688 [D loss: 0.665780, acc.: 63.28%] [G loss: 0.906151]\n",
      "epoch:17 step:16689 [D loss: 0.647867, acc.: 60.94%] [G loss: 0.889411]\n",
      "epoch:17 step:16690 [D loss: 0.688463, acc.: 55.47%] [G loss: 0.854487]\n",
      "epoch:17 step:16691 [D loss: 0.672544, acc.: 57.03%] [G loss: 0.820962]\n",
      "epoch:17 step:16692 [D loss: 0.631830, acc.: 62.50%] [G loss: 0.818124]\n",
      "epoch:17 step:16693 [D loss: 0.641888, acc.: 67.19%] [G loss: 0.858403]\n",
      "epoch:17 step:16694 [D loss: 0.673331, acc.: 61.72%] [G loss: 0.854266]\n",
      "epoch:17 step:16695 [D loss: 0.670453, acc.: 57.81%] [G loss: 0.823106]\n",
      "epoch:17 step:16696 [D loss: 0.672944, acc.: 57.81%] [G loss: 0.818777]\n",
      "epoch:17 step:16697 [D loss: 0.630586, acc.: 64.84%] [G loss: 0.837199]\n",
      "epoch:17 step:16698 [D loss: 0.626588, acc.: 71.09%] [G loss: 0.865877]\n",
      "epoch:17 step:16699 [D loss: 0.709650, acc.: 48.44%] [G loss: 0.855347]\n",
      "epoch:17 step:16700 [D loss: 0.665737, acc.: 57.03%] [G loss: 0.830892]\n",
      "epoch:17 step:16701 [D loss: 0.660833, acc.: 65.62%] [G loss: 0.862331]\n",
      "epoch:17 step:16702 [D loss: 0.691788, acc.: 52.34%] [G loss: 0.820152]\n",
      "epoch:17 step:16703 [D loss: 0.668689, acc.: 58.59%] [G loss: 0.868475]\n",
      "epoch:17 step:16704 [D loss: 0.639353, acc.: 60.94%] [G loss: 0.886297]\n",
      "epoch:17 step:16705 [D loss: 0.683528, acc.: 50.00%] [G loss: 0.927132]\n",
      "epoch:17 step:16706 [D loss: 0.663764, acc.: 57.81%] [G loss: 0.892203]\n",
      "epoch:17 step:16707 [D loss: 0.644315, acc.: 66.41%] [G loss: 0.910204]\n",
      "epoch:17 step:16708 [D loss: 0.660960, acc.: 63.28%] [G loss: 0.843815]\n",
      "epoch:17 step:16709 [D loss: 0.658609, acc.: 60.16%] [G loss: 0.857505]\n",
      "epoch:17 step:16710 [D loss: 0.650626, acc.: 68.75%] [G loss: 0.885520]\n",
      "epoch:17 step:16711 [D loss: 0.649801, acc.: 64.84%] [G loss: 0.818615]\n",
      "epoch:17 step:16712 [D loss: 0.651273, acc.: 58.59%] [G loss: 0.836592]\n",
      "epoch:17 step:16713 [D loss: 0.664102, acc.: 56.25%] [G loss: 0.842341]\n",
      "epoch:17 step:16714 [D loss: 0.669640, acc.: 60.94%] [G loss: 0.863616]\n",
      "epoch:17 step:16715 [D loss: 0.670087, acc.: 53.91%] [G loss: 0.842366]\n",
      "epoch:17 step:16716 [D loss: 0.692800, acc.: 55.47%] [G loss: 0.863645]\n",
      "epoch:17 step:16717 [D loss: 0.645762, acc.: 63.28%] [G loss: 0.895275]\n",
      "epoch:17 step:16718 [D loss: 0.673218, acc.: 59.38%] [G loss: 0.866528]\n",
      "epoch:17 step:16719 [D loss: 0.648553, acc.: 60.16%] [G loss: 0.902945]\n",
      "epoch:17 step:16720 [D loss: 0.631202, acc.: 64.84%] [G loss: 0.859833]\n",
      "epoch:17 step:16721 [D loss: 0.650922, acc.: 62.50%] [G loss: 0.882884]\n",
      "epoch:17 step:16722 [D loss: 0.645381, acc.: 64.84%] [G loss: 0.878131]\n",
      "epoch:17 step:16723 [D loss: 0.642677, acc.: 63.28%] [G loss: 0.886057]\n",
      "epoch:17 step:16724 [D loss: 0.686414, acc.: 50.78%] [G loss: 0.863360]\n",
      "epoch:17 step:16725 [D loss: 0.687232, acc.: 59.38%] [G loss: 0.812141]\n",
      "epoch:17 step:16726 [D loss: 0.676332, acc.: 61.72%] [G loss: 0.927859]\n",
      "epoch:17 step:16727 [D loss: 0.646357, acc.: 60.94%] [G loss: 0.950442]\n",
      "epoch:17 step:16728 [D loss: 0.663834, acc.: 58.59%] [G loss: 0.928357]\n",
      "epoch:17 step:16729 [D loss: 0.660838, acc.: 60.16%] [G loss: 0.907890]\n",
      "epoch:17 step:16730 [D loss: 0.661192, acc.: 61.72%] [G loss: 0.848539]\n",
      "epoch:17 step:16731 [D loss: 0.708855, acc.: 49.22%] [G loss: 0.868973]\n",
      "epoch:17 step:16732 [D loss: 0.681560, acc.: 57.81%] [G loss: 0.832942]\n",
      "epoch:17 step:16733 [D loss: 0.675051, acc.: 60.94%] [G loss: 0.843014]\n",
      "epoch:17 step:16734 [D loss: 0.661291, acc.: 57.03%] [G loss: 0.846684]\n",
      "epoch:17 step:16735 [D loss: 0.634837, acc.: 63.28%] [G loss: 0.863667]\n",
      "epoch:17 step:16736 [D loss: 0.678011, acc.: 58.59%] [G loss: 0.887714]\n",
      "epoch:17 step:16737 [D loss: 0.642711, acc.: 60.16%] [G loss: 0.905187]\n",
      "epoch:17 step:16738 [D loss: 0.666862, acc.: 53.91%] [G loss: 0.900414]\n",
      "epoch:17 step:16739 [D loss: 0.666680, acc.: 57.81%] [G loss: 0.878461]\n",
      "epoch:17 step:16740 [D loss: 0.669578, acc.: 52.34%] [G loss: 0.846881]\n",
      "epoch:17 step:16741 [D loss: 0.681347, acc.: 53.91%] [G loss: 0.922008]\n",
      "epoch:17 step:16742 [D loss: 0.654504, acc.: 60.94%] [G loss: 0.839743]\n",
      "epoch:17 step:16743 [D loss: 0.666734, acc.: 58.59%] [G loss: 0.896008]\n",
      "epoch:17 step:16744 [D loss: 0.682006, acc.: 58.59%] [G loss: 0.887129]\n",
      "epoch:17 step:16745 [D loss: 0.635311, acc.: 63.28%] [G loss: 0.878892]\n",
      "epoch:17 step:16746 [D loss: 0.682429, acc.: 57.81%] [G loss: 0.886975]\n",
      "epoch:17 step:16747 [D loss: 0.640929, acc.: 61.72%] [G loss: 0.890663]\n",
      "epoch:17 step:16748 [D loss: 0.663136, acc.: 61.72%] [G loss: 0.864095]\n",
      "epoch:17 step:16749 [D loss: 0.700459, acc.: 52.34%] [G loss: 0.850579]\n",
      "epoch:17 step:16750 [D loss: 0.668892, acc.: 58.59%] [G loss: 0.881639]\n",
      "epoch:17 step:16751 [D loss: 0.655442, acc.: 64.06%] [G loss: 0.883608]\n",
      "epoch:17 step:16752 [D loss: 0.701762, acc.: 63.28%] [G loss: 0.824486]\n",
      "epoch:17 step:16753 [D loss: 0.689554, acc.: 55.47%] [G loss: 0.819250]\n",
      "epoch:17 step:16754 [D loss: 0.656225, acc.: 60.94%] [G loss: 0.871939]\n",
      "epoch:17 step:16755 [D loss: 0.647199, acc.: 63.28%] [G loss: 0.882479]\n",
      "epoch:17 step:16756 [D loss: 0.671194, acc.: 54.69%] [G loss: 0.857042]\n",
      "epoch:17 step:16757 [D loss: 0.666819, acc.: 58.59%] [G loss: 0.860648]\n",
      "epoch:17 step:16758 [D loss: 0.671477, acc.: 57.03%] [G loss: 0.866961]\n",
      "epoch:17 step:16759 [D loss: 0.668760, acc.: 58.59%] [G loss: 0.854110]\n",
      "epoch:17 step:16760 [D loss: 0.662901, acc.: 59.38%] [G loss: 0.853180]\n",
      "epoch:17 step:16761 [D loss: 0.636050, acc.: 64.84%] [G loss: 0.858131]\n",
      "epoch:17 step:16762 [D loss: 0.647866, acc.: 64.84%] [G loss: 0.879573]\n",
      "epoch:17 step:16763 [D loss: 0.686090, acc.: 58.59%] [G loss: 0.849814]\n",
      "epoch:17 step:16764 [D loss: 0.666905, acc.: 67.19%] [G loss: 0.874883]\n",
      "epoch:17 step:16765 [D loss: 0.633067, acc.: 68.75%] [G loss: 0.864000]\n",
      "epoch:17 step:16766 [D loss: 0.614948, acc.: 67.19%] [G loss: 0.879099]\n",
      "epoch:17 step:16767 [D loss: 0.645336, acc.: 64.06%] [G loss: 0.812576]\n",
      "epoch:17 step:16768 [D loss: 0.639420, acc.: 67.97%] [G loss: 0.874057]\n",
      "epoch:17 step:16769 [D loss: 0.701807, acc.: 54.69%] [G loss: 0.884544]\n",
      "epoch:17 step:16770 [D loss: 0.676898, acc.: 53.12%] [G loss: 0.911155]\n",
      "epoch:17 step:16771 [D loss: 0.684394, acc.: 56.25%] [G loss: 0.837045]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:17 step:16772 [D loss: 0.699171, acc.: 53.91%] [G loss: 0.912491]\n",
      "epoch:17 step:16773 [D loss: 0.682196, acc.: 52.34%] [G loss: 0.837306]\n",
      "epoch:17 step:16774 [D loss: 0.684999, acc.: 55.47%] [G loss: 0.846539]\n",
      "epoch:17 step:16775 [D loss: 0.636953, acc.: 60.16%] [G loss: 0.879419]\n",
      "epoch:17 step:16776 [D loss: 0.675101, acc.: 60.16%] [G loss: 0.874674]\n",
      "epoch:17 step:16777 [D loss: 0.681183, acc.: 53.12%] [G loss: 0.855594]\n",
      "epoch:17 step:16778 [D loss: 0.674817, acc.: 57.81%] [G loss: 0.878110]\n",
      "epoch:17 step:16779 [D loss: 0.655737, acc.: 60.16%] [G loss: 0.894301]\n",
      "epoch:17 step:16780 [D loss: 0.668775, acc.: 57.81%] [G loss: 0.886200]\n",
      "epoch:17 step:16781 [D loss: 0.649890, acc.: 67.97%] [G loss: 0.952428]\n",
      "epoch:17 step:16782 [D loss: 0.665657, acc.: 57.81%] [G loss: 0.893720]\n",
      "epoch:17 step:16783 [D loss: 0.648367, acc.: 67.19%] [G loss: 0.871094]\n",
      "epoch:17 step:16784 [D loss: 0.694427, acc.: 54.69%] [G loss: 0.785632]\n",
      "epoch:17 step:16785 [D loss: 0.666457, acc.: 58.59%] [G loss: 0.790147]\n",
      "epoch:17 step:16786 [D loss: 0.700331, acc.: 54.69%] [G loss: 0.846590]\n",
      "epoch:17 step:16787 [D loss: 0.657535, acc.: 62.50%] [G loss: 0.909760]\n",
      "epoch:17 step:16788 [D loss: 0.665574, acc.: 57.03%] [G loss: 0.865193]\n",
      "epoch:17 step:16789 [D loss: 0.687076, acc.: 55.47%] [G loss: 0.808986]\n",
      "epoch:17 step:16790 [D loss: 0.651809, acc.: 60.16%] [G loss: 0.819364]\n",
      "epoch:17 step:16791 [D loss: 0.660259, acc.: 60.16%] [G loss: 0.873945]\n",
      "epoch:17 step:16792 [D loss: 0.647504, acc.: 57.03%] [G loss: 0.839576]\n",
      "epoch:17 step:16793 [D loss: 0.675745, acc.: 56.25%] [G loss: 0.879048]\n",
      "epoch:17 step:16794 [D loss: 0.667640, acc.: 57.81%] [G loss: 0.887567]\n",
      "epoch:17 step:16795 [D loss: 0.665604, acc.: 59.38%] [G loss: 0.864053]\n",
      "epoch:17 step:16796 [D loss: 0.676270, acc.: 59.38%] [G loss: 0.873787]\n",
      "epoch:17 step:16797 [D loss: 0.656552, acc.: 63.28%] [G loss: 0.914070]\n",
      "epoch:17 step:16798 [D loss: 0.656152, acc.: 58.59%] [G loss: 0.876712]\n",
      "epoch:17 step:16799 [D loss: 0.714177, acc.: 50.00%] [G loss: 0.828767]\n",
      "epoch:17 step:16800 [D loss: 0.648482, acc.: 60.94%] [G loss: 0.803434]\n",
      "##############\n",
      "[3.01932719 2.59304263 1.98852639 4.12553671 1.28095449 8.05660521\n",
      " 2.94432693 3.5481751  4.2579151  7.14868929]\n",
      "##########\n",
      "epoch:17 step:16801 [D loss: 0.673439, acc.: 54.69%] [G loss: 0.866322]\n",
      "epoch:17 step:16802 [D loss: 0.675531, acc.: 58.59%] [G loss: 0.891943]\n",
      "epoch:17 step:16803 [D loss: 0.654948, acc.: 60.94%] [G loss: 0.891944]\n",
      "epoch:17 step:16804 [D loss: 0.663449, acc.: 58.59%] [G loss: 0.926119]\n",
      "epoch:17 step:16805 [D loss: 0.680747, acc.: 58.59%] [G loss: 0.870905]\n",
      "epoch:17 step:16806 [D loss: 0.654732, acc.: 64.84%] [G loss: 0.885155]\n",
      "epoch:17 step:16807 [D loss: 0.686718, acc.: 56.25%] [G loss: 0.879358]\n",
      "epoch:17 step:16808 [D loss: 0.663289, acc.: 60.94%] [G loss: 0.886491]\n",
      "epoch:17 step:16809 [D loss: 0.665848, acc.: 60.16%] [G loss: 0.860718]\n",
      "epoch:17 step:16810 [D loss: 0.679891, acc.: 60.16%] [G loss: 0.859711]\n",
      "epoch:17 step:16811 [D loss: 0.637077, acc.: 67.19%] [G loss: 0.828827]\n",
      "epoch:17 step:16812 [D loss: 0.670627, acc.: 53.12%] [G loss: 0.845197]\n",
      "epoch:17 step:16813 [D loss: 0.627806, acc.: 63.28%] [G loss: 0.814198]\n",
      "epoch:17 step:16814 [D loss: 0.648979, acc.: 60.16%] [G loss: 0.857772]\n",
      "epoch:17 step:16815 [D loss: 0.637129, acc.: 62.50%] [G loss: 0.804469]\n",
      "epoch:17 step:16816 [D loss: 0.651859, acc.: 60.16%] [G loss: 0.787074]\n",
      "epoch:17 step:16817 [D loss: 0.652911, acc.: 60.94%] [G loss: 0.836230]\n",
      "epoch:17 step:16818 [D loss: 0.655913, acc.: 64.84%] [G loss: 0.844214]\n",
      "epoch:17 step:16819 [D loss: 0.685980, acc.: 54.69%] [G loss: 0.862904]\n",
      "epoch:17 step:16820 [D loss: 0.700735, acc.: 51.56%] [G loss: 0.831702]\n",
      "epoch:17 step:16821 [D loss: 0.673175, acc.: 58.59%] [G loss: 0.819587]\n",
      "epoch:17 step:16822 [D loss: 0.662821, acc.: 60.94%] [G loss: 0.931670]\n",
      "epoch:17 step:16823 [D loss: 0.661599, acc.: 58.59%] [G loss: 0.830110]\n",
      "epoch:17 step:16824 [D loss: 0.669977, acc.: 59.38%] [G loss: 0.831865]\n",
      "epoch:17 step:16825 [D loss: 0.688006, acc.: 51.56%] [G loss: 0.868202]\n",
      "epoch:17 step:16826 [D loss: 0.658958, acc.: 57.81%] [G loss: 0.806044]\n",
      "epoch:17 step:16827 [D loss: 0.679529, acc.: 57.81%] [G loss: 0.872905]\n",
      "epoch:17 step:16828 [D loss: 0.664469, acc.: 57.81%] [G loss: 0.864349]\n",
      "epoch:17 step:16829 [D loss: 0.656752, acc.: 56.25%] [G loss: 0.885455]\n",
      "epoch:17 step:16830 [D loss: 0.659371, acc.: 57.03%] [G loss: 0.847220]\n",
      "epoch:17 step:16831 [D loss: 0.682345, acc.: 57.03%] [G loss: 0.807935]\n",
      "epoch:17 step:16832 [D loss: 0.660711, acc.: 62.50%] [G loss: 0.833003]\n",
      "epoch:17 step:16833 [D loss: 0.620339, acc.: 67.97%] [G loss: 0.905911]\n",
      "epoch:17 step:16834 [D loss: 0.695155, acc.: 48.44%] [G loss: 0.862464]\n",
      "epoch:17 step:16835 [D loss: 0.657577, acc.: 64.06%] [G loss: 0.912384]\n",
      "epoch:17 step:16836 [D loss: 0.669354, acc.: 60.94%] [G loss: 0.886812]\n",
      "epoch:17 step:16837 [D loss: 0.669235, acc.: 56.25%] [G loss: 0.829903]\n",
      "epoch:17 step:16838 [D loss: 0.641035, acc.: 60.16%] [G loss: 0.844432]\n",
      "epoch:17 step:16839 [D loss: 0.700257, acc.: 55.47%] [G loss: 0.883049]\n",
      "epoch:17 step:16840 [D loss: 0.613141, acc.: 68.75%] [G loss: 0.889032]\n",
      "epoch:17 step:16841 [D loss: 0.683022, acc.: 60.94%] [G loss: 0.857275]\n",
      "epoch:17 step:16842 [D loss: 0.642832, acc.: 60.16%] [G loss: 0.827303]\n",
      "epoch:17 step:16843 [D loss: 0.692913, acc.: 53.91%] [G loss: 0.855837]\n",
      "epoch:17 step:16844 [D loss: 0.684540, acc.: 61.72%] [G loss: 0.812218]\n",
      "epoch:17 step:16845 [D loss: 0.661815, acc.: 64.06%] [G loss: 0.844543]\n",
      "epoch:17 step:16846 [D loss: 0.658515, acc.: 62.50%] [G loss: 0.864110]\n",
      "epoch:17 step:16847 [D loss: 0.693320, acc.: 57.03%] [G loss: 0.877368]\n",
      "epoch:17 step:16848 [D loss: 0.642773, acc.: 60.94%] [G loss: 0.881772]\n",
      "epoch:17 step:16849 [D loss: 0.660378, acc.: 61.72%] [G loss: 0.833691]\n",
      "epoch:17 step:16850 [D loss: 0.682474, acc.: 56.25%] [G loss: 0.831157]\n",
      "epoch:17 step:16851 [D loss: 0.681597, acc.: 56.25%] [G loss: 0.778149]\n",
      "epoch:17 step:16852 [D loss: 0.692691, acc.: 53.12%] [G loss: 0.848177]\n",
      "epoch:17 step:16853 [D loss: 0.705504, acc.: 54.69%] [G loss: 0.862076]\n",
      "epoch:17 step:16854 [D loss: 0.655535, acc.: 59.38%] [G loss: 0.903273]\n",
      "epoch:17 step:16855 [D loss: 0.650345, acc.: 64.84%] [G loss: 0.914676]\n",
      "epoch:17 step:16856 [D loss: 0.672264, acc.: 56.25%] [G loss: 0.869730]\n",
      "epoch:17 step:16857 [D loss: 0.668684, acc.: 57.81%] [G loss: 0.857459]\n",
      "epoch:17 step:16858 [D loss: 0.668809, acc.: 63.28%] [G loss: 0.847750]\n",
      "epoch:17 step:16859 [D loss: 0.646539, acc.: 60.94%] [G loss: 0.841461]\n",
      "epoch:17 step:16860 [D loss: 0.703548, acc.: 50.78%] [G loss: 0.865299]\n",
      "epoch:17 step:16861 [D loss: 0.660145, acc.: 62.50%] [G loss: 0.829104]\n",
      "epoch:17 step:16862 [D loss: 0.684654, acc.: 58.59%] [G loss: 0.817243]\n",
      "epoch:17 step:16863 [D loss: 0.667617, acc.: 58.59%] [G loss: 0.873677]\n",
      "epoch:17 step:16864 [D loss: 0.649492, acc.: 60.94%] [G loss: 0.853758]\n",
      "epoch:17 step:16865 [D loss: 0.652561, acc.: 60.16%] [G loss: 0.893542]\n",
      "epoch:17 step:16866 [D loss: 0.655868, acc.: 66.41%] [G loss: 0.904927]\n",
      "epoch:18 step:16867 [D loss: 0.655528, acc.: 56.25%] [G loss: 0.937899]\n",
      "epoch:18 step:16868 [D loss: 0.643989, acc.: 63.28%] [G loss: 0.896875]\n",
      "epoch:18 step:16869 [D loss: 0.653172, acc.: 64.06%] [G loss: 0.880341]\n",
      "epoch:18 step:16870 [D loss: 0.642399, acc.: 67.19%] [G loss: 0.874053]\n",
      "epoch:18 step:16871 [D loss: 0.678735, acc.: 63.28%] [G loss: 0.860649]\n",
      "epoch:18 step:16872 [D loss: 0.634507, acc.: 63.28%] [G loss: 0.850855]\n",
      "epoch:18 step:16873 [D loss: 0.691063, acc.: 53.12%] [G loss: 0.837246]\n",
      "epoch:18 step:16874 [D loss: 0.659368, acc.: 57.03%] [G loss: 0.826755]\n",
      "epoch:18 step:16875 [D loss: 0.697720, acc.: 57.03%] [G loss: 0.820798]\n",
      "epoch:18 step:16876 [D loss: 0.639047, acc.: 65.62%] [G loss: 0.832956]\n",
      "epoch:18 step:16877 [D loss: 0.646485, acc.: 58.59%] [G loss: 0.867632]\n",
      "epoch:18 step:16878 [D loss: 0.628835, acc.: 64.84%] [G loss: 0.874756]\n",
      "epoch:18 step:16879 [D loss: 0.635423, acc.: 64.06%] [G loss: 0.895980]\n",
      "epoch:18 step:16880 [D loss: 0.672283, acc.: 60.16%] [G loss: 0.866052]\n",
      "epoch:18 step:16881 [D loss: 0.640445, acc.: 59.38%] [G loss: 0.826719]\n",
      "epoch:18 step:16882 [D loss: 0.665468, acc.: 61.72%] [G loss: 0.844682]\n",
      "epoch:18 step:16883 [D loss: 0.630283, acc.: 64.84%] [G loss: 0.823267]\n",
      "epoch:18 step:16884 [D loss: 0.664925, acc.: 60.16%] [G loss: 0.845142]\n",
      "epoch:18 step:16885 [D loss: 0.655768, acc.: 61.72%] [G loss: 0.799903]\n",
      "epoch:18 step:16886 [D loss: 0.661719, acc.: 58.59%] [G loss: 0.857717]\n",
      "epoch:18 step:16887 [D loss: 0.648530, acc.: 58.59%] [G loss: 0.826357]\n",
      "epoch:18 step:16888 [D loss: 0.658707, acc.: 60.16%] [G loss: 0.846821]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:16889 [D loss: 0.640673, acc.: 62.50%] [G loss: 0.785962]\n",
      "epoch:18 step:16890 [D loss: 0.687117, acc.: 58.59%] [G loss: 0.865706]\n",
      "epoch:18 step:16891 [D loss: 0.688777, acc.: 56.25%] [G loss: 0.843616]\n",
      "epoch:18 step:16892 [D loss: 0.689883, acc.: 55.47%] [G loss: 0.882125]\n",
      "epoch:18 step:16893 [D loss: 0.639850, acc.: 64.06%] [G loss: 0.903053]\n",
      "epoch:18 step:16894 [D loss: 0.671945, acc.: 60.16%] [G loss: 0.898581]\n",
      "epoch:18 step:16895 [D loss: 0.700665, acc.: 53.12%] [G loss: 0.902036]\n",
      "epoch:18 step:16896 [D loss: 0.672798, acc.: 59.38%] [G loss: 0.869358]\n",
      "epoch:18 step:16897 [D loss: 0.682146, acc.: 54.69%] [G loss: 0.870796]\n",
      "epoch:18 step:16898 [D loss: 0.646898, acc.: 69.53%] [G loss: 0.873051]\n",
      "epoch:18 step:16899 [D loss: 0.669520, acc.: 57.03%] [G loss: 0.888139]\n",
      "epoch:18 step:16900 [D loss: 0.638558, acc.: 61.72%] [G loss: 0.852286]\n",
      "epoch:18 step:16901 [D loss: 0.672017, acc.: 50.00%] [G loss: 0.895684]\n",
      "epoch:18 step:16902 [D loss: 0.661770, acc.: 64.06%] [G loss: 0.889886]\n",
      "epoch:18 step:16903 [D loss: 0.646914, acc.: 62.50%] [G loss: 0.897826]\n",
      "epoch:18 step:16904 [D loss: 0.712577, acc.: 49.22%] [G loss: 0.903731]\n",
      "epoch:18 step:16905 [D loss: 0.670235, acc.: 64.06%] [G loss: 0.886141]\n",
      "epoch:18 step:16906 [D loss: 0.659525, acc.: 60.16%] [G loss: 0.868339]\n",
      "epoch:18 step:16907 [D loss: 0.689954, acc.: 53.12%] [G loss: 0.836730]\n",
      "epoch:18 step:16908 [D loss: 0.680257, acc.: 56.25%] [G loss: 0.833776]\n",
      "epoch:18 step:16909 [D loss: 0.683711, acc.: 58.59%] [G loss: 0.903492]\n",
      "epoch:18 step:16910 [D loss: 0.678753, acc.: 54.69%] [G loss: 0.855361]\n",
      "epoch:18 step:16911 [D loss: 0.707098, acc.: 50.00%] [G loss: 0.868059]\n",
      "epoch:18 step:16912 [D loss: 0.683499, acc.: 54.69%] [G loss: 0.865340]\n",
      "epoch:18 step:16913 [D loss: 0.682573, acc.: 55.47%] [G loss: 0.862453]\n",
      "epoch:18 step:16914 [D loss: 0.647218, acc.: 60.94%] [G loss: 0.880120]\n",
      "epoch:18 step:16915 [D loss: 0.686264, acc.: 56.25%] [G loss: 0.860837]\n",
      "epoch:18 step:16916 [D loss: 0.672968, acc.: 57.81%] [G loss: 0.826367]\n",
      "epoch:18 step:16917 [D loss: 0.650155, acc.: 63.28%] [G loss: 0.878265]\n",
      "epoch:18 step:16918 [D loss: 0.666494, acc.: 57.03%] [G loss: 0.847543]\n",
      "epoch:18 step:16919 [D loss: 0.673830, acc.: 64.06%] [G loss: 0.889314]\n",
      "epoch:18 step:16920 [D loss: 0.621385, acc.: 72.66%] [G loss: 0.865471]\n",
      "epoch:18 step:16921 [D loss: 0.657643, acc.: 57.03%] [G loss: 0.868749]\n",
      "epoch:18 step:16922 [D loss: 0.701556, acc.: 53.12%] [G loss: 0.898359]\n",
      "epoch:18 step:16923 [D loss: 0.674347, acc.: 57.81%] [G loss: 0.848158]\n",
      "epoch:18 step:16924 [D loss: 0.693118, acc.: 57.81%] [G loss: 0.832224]\n",
      "epoch:18 step:16925 [D loss: 0.665440, acc.: 55.47%] [G loss: 0.905877]\n",
      "epoch:18 step:16926 [D loss: 0.639165, acc.: 65.62%] [G loss: 0.904743]\n",
      "epoch:18 step:16927 [D loss: 0.657770, acc.: 60.94%] [G loss: 0.868385]\n",
      "epoch:18 step:16928 [D loss: 0.616668, acc.: 69.53%] [G loss: 0.922533]\n",
      "epoch:18 step:16929 [D loss: 0.683384, acc.: 51.56%] [G loss: 0.842187]\n",
      "epoch:18 step:16930 [D loss: 0.683815, acc.: 56.25%] [G loss: 0.875019]\n",
      "epoch:18 step:16931 [D loss: 0.624799, acc.: 67.97%] [G loss: 0.876568]\n",
      "epoch:18 step:16932 [D loss: 0.644349, acc.: 61.72%] [G loss: 0.891635]\n",
      "epoch:18 step:16933 [D loss: 0.693648, acc.: 62.50%] [G loss: 0.859183]\n",
      "epoch:18 step:16934 [D loss: 0.636499, acc.: 64.06%] [G loss: 0.871888]\n",
      "epoch:18 step:16935 [D loss: 0.667303, acc.: 60.94%] [G loss: 0.836075]\n",
      "epoch:18 step:16936 [D loss: 0.641710, acc.: 67.97%] [G loss: 0.890045]\n",
      "epoch:18 step:16937 [D loss: 0.680539, acc.: 61.72%] [G loss: 0.840314]\n",
      "epoch:18 step:16938 [D loss: 0.675134, acc.: 56.25%] [G loss: 0.855878]\n",
      "epoch:18 step:16939 [D loss: 0.655116, acc.: 58.59%] [G loss: 0.841556]\n",
      "epoch:18 step:16940 [D loss: 0.667053, acc.: 60.16%] [G loss: 0.874296]\n",
      "epoch:18 step:16941 [D loss: 0.658826, acc.: 60.16%] [G loss: 0.870030]\n",
      "epoch:18 step:16942 [D loss: 0.645201, acc.: 61.72%] [G loss: 0.898809]\n",
      "epoch:18 step:16943 [D loss: 0.682509, acc.: 54.69%] [G loss: 0.862108]\n",
      "epoch:18 step:16944 [D loss: 0.653380, acc.: 60.94%] [G loss: 0.884132]\n",
      "epoch:18 step:16945 [D loss: 0.659645, acc.: 62.50%] [G loss: 0.878295]\n",
      "epoch:18 step:16946 [D loss: 0.682470, acc.: 57.81%] [G loss: 0.864628]\n",
      "epoch:18 step:16947 [D loss: 0.691605, acc.: 53.91%] [G loss: 0.871688]\n",
      "epoch:18 step:16948 [D loss: 0.647249, acc.: 62.50%] [G loss: 0.842177]\n",
      "epoch:18 step:16949 [D loss: 0.648078, acc.: 62.50%] [G loss: 0.865392]\n",
      "epoch:18 step:16950 [D loss: 0.665828, acc.: 58.59%] [G loss: 0.895280]\n",
      "epoch:18 step:16951 [D loss: 0.680108, acc.: 53.91%] [G loss: 0.877751]\n",
      "epoch:18 step:16952 [D loss: 0.651773, acc.: 60.16%] [G loss: 0.862129]\n",
      "epoch:18 step:16953 [D loss: 0.659860, acc.: 59.38%] [G loss: 0.887617]\n",
      "epoch:18 step:16954 [D loss: 0.665811, acc.: 62.50%] [G loss: 0.860820]\n",
      "epoch:18 step:16955 [D loss: 0.631912, acc.: 68.75%] [G loss: 0.810909]\n",
      "epoch:18 step:16956 [D loss: 0.640918, acc.: 61.72%] [G loss: 0.825588]\n",
      "epoch:18 step:16957 [D loss: 0.721920, acc.: 51.56%] [G loss: 0.901187]\n",
      "epoch:18 step:16958 [D loss: 0.644698, acc.: 59.38%] [G loss: 0.852475]\n",
      "epoch:18 step:16959 [D loss: 0.653192, acc.: 60.94%] [G loss: 0.859974]\n",
      "epoch:18 step:16960 [D loss: 0.649197, acc.: 61.72%] [G loss: 0.876451]\n",
      "epoch:18 step:16961 [D loss: 0.674050, acc.: 50.78%] [G loss: 0.807750]\n",
      "epoch:18 step:16962 [D loss: 0.692528, acc.: 50.78%] [G loss: 0.839706]\n",
      "epoch:18 step:16963 [D loss: 0.658632, acc.: 60.16%] [G loss: 0.832241]\n",
      "epoch:18 step:16964 [D loss: 0.654229, acc.: 57.03%] [G loss: 0.829298]\n",
      "epoch:18 step:16965 [D loss: 0.674247, acc.: 59.38%] [G loss: 0.841824]\n",
      "epoch:18 step:16966 [D loss: 0.669421, acc.: 56.25%] [G loss: 0.854477]\n",
      "epoch:18 step:16967 [D loss: 0.651658, acc.: 60.94%] [G loss: 0.836127]\n",
      "epoch:18 step:16968 [D loss: 0.699061, acc.: 58.59%] [G loss: 0.845270]\n",
      "epoch:18 step:16969 [D loss: 0.643782, acc.: 62.50%] [G loss: 0.820983]\n",
      "epoch:18 step:16970 [D loss: 0.671686, acc.: 59.38%] [G loss: 0.896928]\n",
      "epoch:18 step:16971 [D loss: 0.664257, acc.: 57.81%] [G loss: 0.858537]\n",
      "epoch:18 step:16972 [D loss: 0.663454, acc.: 60.16%] [G loss: 0.916140]\n",
      "epoch:18 step:16973 [D loss: 0.639967, acc.: 57.03%] [G loss: 0.874870]\n",
      "epoch:18 step:16974 [D loss: 0.661356, acc.: 58.59%] [G loss: 0.890553]\n",
      "epoch:18 step:16975 [D loss: 0.646964, acc.: 59.38%] [G loss: 0.847404]\n",
      "epoch:18 step:16976 [D loss: 0.664358, acc.: 58.59%] [G loss: 0.833670]\n",
      "epoch:18 step:16977 [D loss: 0.694409, acc.: 52.34%] [G loss: 0.872519]\n",
      "epoch:18 step:16978 [D loss: 0.686580, acc.: 56.25%] [G loss: 0.841697]\n",
      "epoch:18 step:16979 [D loss: 0.679510, acc.: 54.69%] [G loss: 0.917584]\n",
      "epoch:18 step:16980 [D loss: 0.649395, acc.: 63.28%] [G loss: 0.912260]\n",
      "epoch:18 step:16981 [D loss: 0.681841, acc.: 57.81%] [G loss: 0.894952]\n",
      "epoch:18 step:16982 [D loss: 0.655315, acc.: 64.84%] [G loss: 0.824422]\n",
      "epoch:18 step:16983 [D loss: 0.681858, acc.: 53.91%] [G loss: 0.899706]\n",
      "epoch:18 step:16984 [D loss: 0.666092, acc.: 54.69%] [G loss: 0.819276]\n",
      "epoch:18 step:16985 [D loss: 0.661287, acc.: 60.94%] [G loss: 0.893590]\n",
      "epoch:18 step:16986 [D loss: 0.641568, acc.: 67.97%] [G loss: 0.889026]\n",
      "epoch:18 step:16987 [D loss: 0.627185, acc.: 65.62%] [G loss: 0.913202]\n",
      "epoch:18 step:16988 [D loss: 0.642865, acc.: 61.72%] [G loss: 0.834004]\n",
      "epoch:18 step:16989 [D loss: 0.657161, acc.: 60.94%] [G loss: 0.843051]\n",
      "epoch:18 step:16990 [D loss: 0.683610, acc.: 57.03%] [G loss: 0.840678]\n",
      "epoch:18 step:16991 [D loss: 0.698339, acc.: 52.34%] [G loss: 0.850831]\n",
      "epoch:18 step:16992 [D loss: 0.674061, acc.: 56.25%] [G loss: 0.888551]\n",
      "epoch:18 step:16993 [D loss: 0.631177, acc.: 67.97%] [G loss: 0.882299]\n",
      "epoch:18 step:16994 [D loss: 0.643433, acc.: 60.94%] [G loss: 0.900432]\n",
      "epoch:18 step:16995 [D loss: 0.665238, acc.: 60.94%] [G loss: 0.914728]\n",
      "epoch:18 step:16996 [D loss: 0.649764, acc.: 65.62%] [G loss: 0.890362]\n",
      "epoch:18 step:16997 [D loss: 0.683177, acc.: 54.69%] [G loss: 0.881144]\n",
      "epoch:18 step:16998 [D loss: 0.681394, acc.: 57.81%] [G loss: 0.849495]\n",
      "epoch:18 step:16999 [D loss: 0.703535, acc.: 48.44%] [G loss: 0.871552]\n",
      "epoch:18 step:17000 [D loss: 0.667249, acc.: 57.81%] [G loss: 0.873329]\n",
      "##############\n",
      "[3.01371799 2.26076976 2.1895338  3.74727422 1.4587366  7.80241882\n",
      " 2.67548269 3.63801826 4.32915243 7.14771273]\n",
      "##########\n",
      "epoch:18 step:17001 [D loss: 0.663516, acc.: 54.69%] [G loss: 0.880324]\n",
      "epoch:18 step:17002 [D loss: 0.700405, acc.: 57.03%] [G loss: 0.907727]\n",
      "epoch:18 step:17003 [D loss: 0.705279, acc.: 56.25%] [G loss: 0.864424]\n",
      "epoch:18 step:17004 [D loss: 0.659915, acc.: 57.81%] [G loss: 0.871795]\n",
      "epoch:18 step:17005 [D loss: 0.628137, acc.: 64.84%] [G loss: 0.865896]\n",
      "epoch:18 step:17006 [D loss: 0.661736, acc.: 60.94%] [G loss: 0.863905]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17007 [D loss: 0.682969, acc.: 51.56%] [G loss: 0.790338]\n",
      "epoch:18 step:17008 [D loss: 0.646705, acc.: 59.38%] [G loss: 0.882786]\n",
      "epoch:18 step:17009 [D loss: 0.656315, acc.: 60.16%] [G loss: 0.850764]\n",
      "epoch:18 step:17010 [D loss: 0.667849, acc.: 58.59%] [G loss: 0.812632]\n",
      "epoch:18 step:17011 [D loss: 0.654624, acc.: 57.03%] [G loss: 0.915794]\n",
      "epoch:18 step:17012 [D loss: 0.663801, acc.: 60.16%] [G loss: 0.845251]\n",
      "epoch:18 step:17013 [D loss: 0.663292, acc.: 61.72%] [G loss: 0.852109]\n",
      "epoch:18 step:17014 [D loss: 0.652033, acc.: 60.16%] [G loss: 0.840603]\n",
      "epoch:18 step:17015 [D loss: 0.674008, acc.: 56.25%] [G loss: 0.836328]\n",
      "epoch:18 step:17016 [D loss: 0.718687, acc.: 52.34%] [G loss: 0.815341]\n",
      "epoch:18 step:17017 [D loss: 0.696055, acc.: 57.03%] [G loss: 0.855743]\n",
      "epoch:18 step:17018 [D loss: 0.668714, acc.: 56.25%] [G loss: 0.851993]\n",
      "epoch:18 step:17019 [D loss: 0.653958, acc.: 59.38%] [G loss: 0.836542]\n",
      "epoch:18 step:17020 [D loss: 0.656080, acc.: 58.59%] [G loss: 0.801150]\n",
      "epoch:18 step:17021 [D loss: 0.676200, acc.: 56.25%] [G loss: 0.850075]\n",
      "epoch:18 step:17022 [D loss: 0.623918, acc.: 66.41%] [G loss: 0.874734]\n",
      "epoch:18 step:17023 [D loss: 0.693871, acc.: 53.91%] [G loss: 0.841632]\n",
      "epoch:18 step:17024 [D loss: 0.669237, acc.: 61.72%] [G loss: 0.872769]\n",
      "epoch:18 step:17025 [D loss: 0.668097, acc.: 60.16%] [G loss: 0.889669]\n",
      "epoch:18 step:17026 [D loss: 0.655045, acc.: 59.38%] [G loss: 0.937420]\n",
      "epoch:18 step:17027 [D loss: 0.649245, acc.: 60.16%] [G loss: 0.935263]\n",
      "epoch:18 step:17028 [D loss: 0.644237, acc.: 60.94%] [G loss: 0.859024]\n",
      "epoch:18 step:17029 [D loss: 0.657825, acc.: 57.03%] [G loss: 0.853248]\n",
      "epoch:18 step:17030 [D loss: 0.690982, acc.: 51.56%] [G loss: 0.889774]\n",
      "epoch:18 step:17031 [D loss: 0.680071, acc.: 58.59%] [G loss: 0.862381]\n",
      "epoch:18 step:17032 [D loss: 0.687359, acc.: 51.56%] [G loss: 0.854243]\n",
      "epoch:18 step:17033 [D loss: 0.655389, acc.: 58.59%] [G loss: 0.797642]\n",
      "epoch:18 step:17034 [D loss: 0.677629, acc.: 55.47%] [G loss: 0.869975]\n",
      "epoch:18 step:17035 [D loss: 0.660099, acc.: 61.72%] [G loss: 0.847376]\n",
      "epoch:18 step:17036 [D loss: 0.653932, acc.: 60.16%] [G loss: 0.884245]\n",
      "epoch:18 step:17037 [D loss: 0.655828, acc.: 62.50%] [G loss: 0.864287]\n",
      "epoch:18 step:17038 [D loss: 0.673093, acc.: 58.59%] [G loss: 0.804500]\n",
      "epoch:18 step:17039 [D loss: 0.665689, acc.: 57.81%] [G loss: 0.828851]\n",
      "epoch:18 step:17040 [D loss: 0.663475, acc.: 58.59%] [G loss: 0.842157]\n",
      "epoch:18 step:17041 [D loss: 0.683736, acc.: 59.38%] [G loss: 0.839247]\n",
      "epoch:18 step:17042 [D loss: 0.657008, acc.: 62.50%] [G loss: 0.890763]\n",
      "epoch:18 step:17043 [D loss: 0.645909, acc.: 58.59%] [G loss: 0.850508]\n",
      "epoch:18 step:17044 [D loss: 0.675105, acc.: 59.38%] [G loss: 0.893847]\n",
      "epoch:18 step:17045 [D loss: 0.634584, acc.: 59.38%] [G loss: 0.896036]\n",
      "epoch:18 step:17046 [D loss: 0.668794, acc.: 59.38%] [G loss: 0.833310]\n",
      "epoch:18 step:17047 [D loss: 0.685326, acc.: 53.12%] [G loss: 0.935089]\n",
      "epoch:18 step:17048 [D loss: 0.621169, acc.: 69.53%] [G loss: 0.914391]\n",
      "epoch:18 step:17049 [D loss: 0.638600, acc.: 60.94%] [G loss: 0.901721]\n",
      "epoch:18 step:17050 [D loss: 0.654843, acc.: 63.28%] [G loss: 0.896673]\n",
      "epoch:18 step:17051 [D loss: 0.686217, acc.: 51.56%] [G loss: 0.897625]\n",
      "epoch:18 step:17052 [D loss: 0.693183, acc.: 54.69%] [G loss: 0.883619]\n",
      "epoch:18 step:17053 [D loss: 0.671388, acc.: 61.72%] [G loss: 0.852966]\n",
      "epoch:18 step:17054 [D loss: 0.672289, acc.: 57.81%] [G loss: 0.826318]\n",
      "epoch:18 step:17055 [D loss: 0.660756, acc.: 62.50%] [G loss: 0.844895]\n",
      "epoch:18 step:17056 [D loss: 0.714082, acc.: 50.78%] [G loss: 0.856397]\n",
      "epoch:18 step:17057 [D loss: 0.628439, acc.: 66.41%] [G loss: 0.834470]\n",
      "epoch:18 step:17058 [D loss: 0.681579, acc.: 57.81%] [G loss: 0.863167]\n",
      "epoch:18 step:17059 [D loss: 0.641072, acc.: 65.62%] [G loss: 0.908759]\n",
      "epoch:18 step:17060 [D loss: 0.688944, acc.: 57.03%] [G loss: 0.855184]\n",
      "epoch:18 step:17061 [D loss: 0.617696, acc.: 69.53%] [G loss: 0.844948]\n",
      "epoch:18 step:17062 [D loss: 0.635890, acc.: 62.50%] [G loss: 0.855114]\n",
      "epoch:18 step:17063 [D loss: 0.623480, acc.: 63.28%] [G loss: 0.856627]\n",
      "epoch:18 step:17064 [D loss: 0.662107, acc.: 58.59%] [G loss: 0.884040]\n",
      "epoch:18 step:17065 [D loss: 0.626805, acc.: 60.94%] [G loss: 0.869399]\n",
      "epoch:18 step:17066 [D loss: 0.671191, acc.: 54.69%] [G loss: 0.868428]\n",
      "epoch:18 step:17067 [D loss: 0.663376, acc.: 56.25%] [G loss: 0.894342]\n",
      "epoch:18 step:17068 [D loss: 0.647609, acc.: 62.50%] [G loss: 0.924223]\n",
      "epoch:18 step:17069 [D loss: 0.660474, acc.: 58.59%] [G loss: 0.896306]\n",
      "epoch:18 step:17070 [D loss: 0.680279, acc.: 55.47%] [G loss: 0.899312]\n",
      "epoch:18 step:17071 [D loss: 0.660565, acc.: 57.03%] [G loss: 0.856789]\n",
      "epoch:18 step:17072 [D loss: 0.642751, acc.: 64.06%] [G loss: 0.820209]\n",
      "epoch:18 step:17073 [D loss: 0.623937, acc.: 64.84%] [G loss: 0.883641]\n",
      "epoch:18 step:17074 [D loss: 0.660435, acc.: 60.94%] [G loss: 0.888271]\n",
      "epoch:18 step:17075 [D loss: 0.674773, acc.: 57.81%] [G loss: 0.922833]\n",
      "epoch:18 step:17076 [D loss: 0.676923, acc.: 64.06%] [G loss: 0.930675]\n",
      "epoch:18 step:17077 [D loss: 0.648551, acc.: 60.94%] [G loss: 0.979502]\n",
      "epoch:18 step:17078 [D loss: 0.639778, acc.: 61.72%] [G loss: 0.966600]\n",
      "epoch:18 step:17079 [D loss: 0.726621, acc.: 48.44%] [G loss: 0.906135]\n",
      "epoch:18 step:17080 [D loss: 0.686062, acc.: 50.78%] [G loss: 0.889256]\n",
      "epoch:18 step:17081 [D loss: 0.669142, acc.: 60.16%] [G loss: 0.855235]\n",
      "epoch:18 step:17082 [D loss: 0.664049, acc.: 56.25%] [G loss: 0.870933]\n",
      "epoch:18 step:17083 [D loss: 0.607378, acc.: 71.88%] [G loss: 0.880310]\n",
      "epoch:18 step:17084 [D loss: 0.664908, acc.: 58.59%] [G loss: 0.869131]\n",
      "epoch:18 step:17085 [D loss: 0.671190, acc.: 58.59%] [G loss: 0.862947]\n",
      "epoch:18 step:17086 [D loss: 0.662877, acc.: 58.59%] [G loss: 0.870265]\n",
      "epoch:18 step:17087 [D loss: 0.646030, acc.: 61.72%] [G loss: 0.828879]\n",
      "epoch:18 step:17088 [D loss: 0.670770, acc.: 60.16%] [G loss: 0.840267]\n",
      "epoch:18 step:17089 [D loss: 0.675763, acc.: 55.47%] [G loss: 0.823436]\n",
      "epoch:18 step:17090 [D loss: 0.701955, acc.: 53.91%] [G loss: 0.853864]\n",
      "epoch:18 step:17091 [D loss: 0.661010, acc.: 64.06%] [G loss: 0.861329]\n",
      "epoch:18 step:17092 [D loss: 0.662320, acc.: 60.16%] [G loss: 0.821700]\n",
      "epoch:18 step:17093 [D loss: 0.637822, acc.: 63.28%] [G loss: 0.876940]\n",
      "epoch:18 step:17094 [D loss: 0.685935, acc.: 51.56%] [G loss: 0.888836]\n",
      "epoch:18 step:17095 [D loss: 0.633755, acc.: 66.41%] [G loss: 0.863490]\n",
      "epoch:18 step:17096 [D loss: 0.635420, acc.: 61.72%] [G loss: 0.834375]\n",
      "epoch:18 step:17097 [D loss: 0.700814, acc.: 54.69%] [G loss: 0.863196]\n",
      "epoch:18 step:17098 [D loss: 0.676874, acc.: 56.25%] [G loss: 0.860455]\n",
      "epoch:18 step:17099 [D loss: 0.670555, acc.: 55.47%] [G loss: 0.871514]\n",
      "epoch:18 step:17100 [D loss: 0.685857, acc.: 50.78%] [G loss: 0.878908]\n",
      "epoch:18 step:17101 [D loss: 0.667544, acc.: 62.50%] [G loss: 0.864945]\n",
      "epoch:18 step:17102 [D loss: 0.666633, acc.: 60.16%] [G loss: 0.871525]\n",
      "epoch:18 step:17103 [D loss: 0.666705, acc.: 60.94%] [G loss: 0.923557]\n",
      "epoch:18 step:17104 [D loss: 0.690637, acc.: 59.38%] [G loss: 0.857683]\n",
      "epoch:18 step:17105 [D loss: 0.670284, acc.: 57.81%] [G loss: 0.847249]\n",
      "epoch:18 step:17106 [D loss: 0.681358, acc.: 53.91%] [G loss: 0.856751]\n",
      "epoch:18 step:17107 [D loss: 0.624670, acc.: 69.53%] [G loss: 0.854441]\n",
      "epoch:18 step:17108 [D loss: 0.681623, acc.: 59.38%] [G loss: 0.845822]\n",
      "epoch:18 step:17109 [D loss: 0.689572, acc.: 54.69%] [G loss: 0.846611]\n",
      "epoch:18 step:17110 [D loss: 0.651768, acc.: 64.06%] [G loss: 0.867829]\n",
      "epoch:18 step:17111 [D loss: 0.685216, acc.: 53.91%] [G loss: 0.851642]\n",
      "epoch:18 step:17112 [D loss: 0.638708, acc.: 67.97%] [G loss: 0.823950]\n",
      "epoch:18 step:17113 [D loss: 0.655370, acc.: 60.94%] [G loss: 0.842732]\n",
      "epoch:18 step:17114 [D loss: 0.699820, acc.: 53.91%] [G loss: 0.859692]\n",
      "epoch:18 step:17115 [D loss: 0.672883, acc.: 57.81%] [G loss: 0.861749]\n",
      "epoch:18 step:17116 [D loss: 0.659111, acc.: 61.72%] [G loss: 0.889439]\n",
      "epoch:18 step:17117 [D loss: 0.681826, acc.: 54.69%] [G loss: 0.832936]\n",
      "epoch:18 step:17118 [D loss: 0.649449, acc.: 59.38%] [G loss: 0.863326]\n",
      "epoch:18 step:17119 [D loss: 0.639573, acc.: 64.06%] [G loss: 0.824859]\n",
      "epoch:18 step:17120 [D loss: 0.677558, acc.: 57.03%] [G loss: 0.866293]\n",
      "epoch:18 step:17121 [D loss: 0.662313, acc.: 59.38%] [G loss: 0.897645]\n",
      "epoch:18 step:17122 [D loss: 0.650348, acc.: 64.06%] [G loss: 0.896584]\n",
      "epoch:18 step:17123 [D loss: 0.652196, acc.: 57.81%] [G loss: 0.864647]\n",
      "epoch:18 step:17124 [D loss: 0.680867, acc.: 56.25%] [G loss: 0.864120]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17125 [D loss: 0.669822, acc.: 52.34%] [G loss: 0.876982]\n",
      "epoch:18 step:17126 [D loss: 0.699757, acc.: 50.78%] [G loss: 0.890062]\n",
      "epoch:18 step:17127 [D loss: 0.679769, acc.: 53.12%] [G loss: 0.895635]\n",
      "epoch:18 step:17128 [D loss: 0.689536, acc.: 52.34%] [G loss: 0.909590]\n",
      "epoch:18 step:17129 [D loss: 0.685472, acc.: 57.03%] [G loss: 0.891384]\n",
      "epoch:18 step:17130 [D loss: 0.673325, acc.: 57.81%] [G loss: 0.930935]\n",
      "epoch:18 step:17131 [D loss: 0.669098, acc.: 62.50%] [G loss: 0.953805]\n",
      "epoch:18 step:17132 [D loss: 0.626282, acc.: 64.06%] [G loss: 0.895769]\n",
      "epoch:18 step:17133 [D loss: 0.636972, acc.: 64.06%] [G loss: 0.863821]\n",
      "epoch:18 step:17134 [D loss: 0.663029, acc.: 60.16%] [G loss: 0.848780]\n",
      "epoch:18 step:17135 [D loss: 0.668746, acc.: 59.38%] [G loss: 0.852317]\n",
      "epoch:18 step:17136 [D loss: 0.664703, acc.: 59.38%] [G loss: 0.822749]\n",
      "epoch:18 step:17137 [D loss: 0.676556, acc.: 52.34%] [G loss: 0.850101]\n",
      "epoch:18 step:17138 [D loss: 0.667662, acc.: 55.47%] [G loss: 0.891366]\n",
      "epoch:18 step:17139 [D loss: 0.671714, acc.: 57.03%] [G loss: 0.900507]\n",
      "epoch:18 step:17140 [D loss: 0.678676, acc.: 53.12%] [G loss: 0.876433]\n",
      "epoch:18 step:17141 [D loss: 0.663340, acc.: 56.25%] [G loss: 0.868982]\n",
      "epoch:18 step:17142 [D loss: 0.690180, acc.: 53.12%] [G loss: 0.883938]\n",
      "epoch:18 step:17143 [D loss: 0.652701, acc.: 57.03%] [G loss: 0.882369]\n",
      "epoch:18 step:17144 [D loss: 0.668853, acc.: 60.94%] [G loss: 0.832572]\n",
      "epoch:18 step:17145 [D loss: 0.676787, acc.: 57.03%] [G loss: 0.847831]\n",
      "epoch:18 step:17146 [D loss: 0.675695, acc.: 59.38%] [G loss: 0.851543]\n",
      "epoch:18 step:17147 [D loss: 0.660103, acc.: 56.25%] [G loss: 0.844971]\n",
      "epoch:18 step:17148 [D loss: 0.635374, acc.: 68.75%] [G loss: 0.914520]\n",
      "epoch:18 step:17149 [D loss: 0.643949, acc.: 62.50%] [G loss: 0.922048]\n",
      "epoch:18 step:17150 [D loss: 0.644752, acc.: 61.72%] [G loss: 0.977951]\n",
      "epoch:18 step:17151 [D loss: 0.626309, acc.: 68.75%] [G loss: 0.879522]\n",
      "epoch:18 step:17152 [D loss: 0.642173, acc.: 63.28%] [G loss: 0.881558]\n",
      "epoch:18 step:17153 [D loss: 0.648698, acc.: 64.06%] [G loss: 0.858130]\n",
      "epoch:18 step:17154 [D loss: 0.648886, acc.: 60.16%] [G loss: 0.826786]\n",
      "epoch:18 step:17155 [D loss: 0.651765, acc.: 67.19%] [G loss: 0.875510]\n",
      "epoch:18 step:17156 [D loss: 0.662333, acc.: 58.59%] [G loss: 0.829671]\n",
      "epoch:18 step:17157 [D loss: 0.694176, acc.: 56.25%] [G loss: 0.890718]\n",
      "epoch:18 step:17158 [D loss: 0.698676, acc.: 60.94%] [G loss: 0.836613]\n",
      "epoch:18 step:17159 [D loss: 0.659121, acc.: 63.28%] [G loss: 0.801405]\n",
      "epoch:18 step:17160 [D loss: 0.633229, acc.: 63.28%] [G loss: 0.881739]\n",
      "epoch:18 step:17161 [D loss: 0.684524, acc.: 53.91%] [G loss: 0.931833]\n",
      "epoch:18 step:17162 [D loss: 0.678847, acc.: 64.06%] [G loss: 0.867253]\n",
      "epoch:18 step:17163 [D loss: 0.655070, acc.: 62.50%] [G loss: 0.864958]\n",
      "epoch:18 step:17164 [D loss: 0.673603, acc.: 57.03%] [G loss: 0.882638]\n",
      "epoch:18 step:17165 [D loss: 0.673538, acc.: 57.03%] [G loss: 0.927078]\n",
      "epoch:18 step:17166 [D loss: 0.662001, acc.: 59.38%] [G loss: 0.966548]\n",
      "epoch:18 step:17167 [D loss: 0.679634, acc.: 52.34%] [G loss: 0.889775]\n",
      "epoch:18 step:17168 [D loss: 0.655728, acc.: 60.16%] [G loss: 0.887366]\n",
      "epoch:18 step:17169 [D loss: 0.663691, acc.: 55.47%] [G loss: 0.840456]\n",
      "epoch:18 step:17170 [D loss: 0.629801, acc.: 60.94%] [G loss: 0.874232]\n",
      "epoch:18 step:17171 [D loss: 0.665391, acc.: 60.94%] [G loss: 0.830795]\n",
      "epoch:18 step:17172 [D loss: 0.649673, acc.: 61.72%] [G loss: 0.877442]\n",
      "epoch:18 step:17173 [D loss: 0.648217, acc.: 66.41%] [G loss: 0.876766]\n",
      "epoch:18 step:17174 [D loss: 0.652055, acc.: 61.72%] [G loss: 0.857212]\n",
      "epoch:18 step:17175 [D loss: 0.669788, acc.: 53.91%] [G loss: 0.852148]\n",
      "epoch:18 step:17176 [D loss: 0.650431, acc.: 63.28%] [G loss: 0.862831]\n",
      "epoch:18 step:17177 [D loss: 0.657894, acc.: 60.94%] [G loss: 0.868672]\n",
      "epoch:18 step:17178 [D loss: 0.647363, acc.: 64.06%] [G loss: 0.823675]\n",
      "epoch:18 step:17179 [D loss: 0.641467, acc.: 61.72%] [G loss: 0.856539]\n",
      "epoch:18 step:17180 [D loss: 0.661962, acc.: 58.59%] [G loss: 0.827293]\n",
      "epoch:18 step:17181 [D loss: 0.629963, acc.: 62.50%] [G loss: 0.808186]\n",
      "epoch:18 step:17182 [D loss: 0.672638, acc.: 54.69%] [G loss: 0.815530]\n",
      "epoch:18 step:17183 [D loss: 0.676438, acc.: 57.03%] [G loss: 0.896564]\n",
      "epoch:18 step:17184 [D loss: 0.653704, acc.: 64.06%] [G loss: 0.959638]\n",
      "epoch:18 step:17185 [D loss: 0.683801, acc.: 57.03%] [G loss: 0.941446]\n",
      "epoch:18 step:17186 [D loss: 0.663045, acc.: 59.38%] [G loss: 0.929384]\n",
      "epoch:18 step:17187 [D loss: 0.665951, acc.: 59.38%] [G loss: 0.900729]\n",
      "epoch:18 step:17188 [D loss: 0.681972, acc.: 57.81%] [G loss: 0.860774]\n",
      "epoch:18 step:17189 [D loss: 0.677719, acc.: 57.81%] [G loss: 0.887029]\n",
      "epoch:18 step:17190 [D loss: 0.654552, acc.: 60.16%] [G loss: 0.871631]\n",
      "epoch:18 step:17191 [D loss: 0.647757, acc.: 60.94%] [G loss: 0.838596]\n",
      "epoch:18 step:17192 [D loss: 0.690185, acc.: 54.69%] [G loss: 0.824189]\n",
      "epoch:18 step:17193 [D loss: 0.626656, acc.: 64.84%] [G loss: 0.846642]\n",
      "epoch:18 step:17194 [D loss: 0.643739, acc.: 64.06%] [G loss: 0.849223]\n",
      "epoch:18 step:17195 [D loss: 0.665658, acc.: 58.59%] [G loss: 0.933337]\n",
      "epoch:18 step:17196 [D loss: 0.669068, acc.: 56.25%] [G loss: 0.880310]\n",
      "epoch:18 step:17197 [D loss: 0.687924, acc.: 56.25%] [G loss: 0.869899]\n",
      "epoch:18 step:17198 [D loss: 0.620341, acc.: 71.09%] [G loss: 0.855134]\n",
      "epoch:18 step:17199 [D loss: 0.659307, acc.: 58.59%] [G loss: 0.893680]\n",
      "epoch:18 step:17200 [D loss: 0.669523, acc.: 57.81%] [G loss: 0.853924]\n",
      "##############\n",
      "[2.97568438 2.4809116  2.36073652 3.92693752 1.29015835 8.21823671\n",
      " 2.73642614 3.18195146 4.32812791 5.92645357]\n",
      "##########\n",
      "epoch:18 step:17201 [D loss: 0.660491, acc.: 56.25%] [G loss: 0.905778]\n",
      "epoch:18 step:17202 [D loss: 0.605493, acc.: 67.19%] [G loss: 0.876241]\n",
      "epoch:18 step:17203 [D loss: 0.670181, acc.: 57.03%] [G loss: 0.854100]\n",
      "epoch:18 step:17204 [D loss: 0.662050, acc.: 57.03%] [G loss: 0.907369]\n",
      "epoch:18 step:17205 [D loss: 0.631543, acc.: 63.28%] [G loss: 0.831071]\n",
      "epoch:18 step:17206 [D loss: 0.635500, acc.: 66.41%] [G loss: 0.903530]\n",
      "epoch:18 step:17207 [D loss: 0.658265, acc.: 57.03%] [G loss: 0.890875]\n",
      "epoch:18 step:17208 [D loss: 0.640069, acc.: 63.28%] [G loss: 0.930952]\n",
      "epoch:18 step:17209 [D loss: 0.689793, acc.: 53.12%] [G loss: 0.897496]\n",
      "epoch:18 step:17210 [D loss: 0.638352, acc.: 62.50%] [G loss: 0.907073]\n",
      "epoch:18 step:17211 [D loss: 0.678664, acc.: 58.59%] [G loss: 0.874553]\n",
      "epoch:18 step:17212 [D loss: 0.715474, acc.: 47.66%] [G loss: 0.894898]\n",
      "epoch:18 step:17213 [D loss: 0.665471, acc.: 61.72%] [G loss: 0.875023]\n",
      "epoch:18 step:17214 [D loss: 0.638019, acc.: 64.84%] [G loss: 0.839264]\n",
      "epoch:18 step:17215 [D loss: 0.674161, acc.: 55.47%] [G loss: 0.852969]\n",
      "epoch:18 step:17216 [D loss: 0.658666, acc.: 61.72%] [G loss: 0.893948]\n",
      "epoch:18 step:17217 [D loss: 0.654914, acc.: 64.06%] [G loss: 0.903740]\n",
      "epoch:18 step:17218 [D loss: 0.703022, acc.: 55.47%] [G loss: 0.836127]\n",
      "epoch:18 step:17219 [D loss: 0.650965, acc.: 61.72%] [G loss: 0.839368]\n",
      "epoch:18 step:17220 [D loss: 0.674576, acc.: 52.34%] [G loss: 0.820914]\n",
      "epoch:18 step:17221 [D loss: 0.642215, acc.: 63.28%] [G loss: 0.824495]\n",
      "epoch:18 step:17222 [D loss: 0.644977, acc.: 64.06%] [G loss: 0.883112]\n",
      "epoch:18 step:17223 [D loss: 0.683262, acc.: 53.12%] [G loss: 0.869879]\n",
      "epoch:18 step:17224 [D loss: 0.663535, acc.: 58.59%] [G loss: 0.844893]\n",
      "epoch:18 step:17225 [D loss: 0.712934, acc.: 50.78%] [G loss: 0.926537]\n",
      "epoch:18 step:17226 [D loss: 0.611619, acc.: 72.66%] [G loss: 0.883869]\n",
      "epoch:18 step:17227 [D loss: 0.673931, acc.: 60.94%] [G loss: 0.897493]\n",
      "epoch:18 step:17228 [D loss: 0.699192, acc.: 55.47%] [G loss: 0.861121]\n",
      "epoch:18 step:17229 [D loss: 0.679728, acc.: 60.16%] [G loss: 0.859556]\n",
      "epoch:18 step:17230 [D loss: 0.672429, acc.: 57.81%] [G loss: 0.831965]\n",
      "epoch:18 step:17231 [D loss: 0.702328, acc.: 51.56%] [G loss: 0.861202]\n",
      "epoch:18 step:17232 [D loss: 0.654367, acc.: 62.50%] [G loss: 0.843668]\n",
      "epoch:18 step:17233 [D loss: 0.652121, acc.: 55.47%] [G loss: 0.834776]\n",
      "epoch:18 step:17234 [D loss: 0.680386, acc.: 51.56%] [G loss: 0.849272]\n",
      "epoch:18 step:17235 [D loss: 0.682437, acc.: 59.38%] [G loss: 0.829991]\n",
      "epoch:18 step:17236 [D loss: 0.673930, acc.: 59.38%] [G loss: 0.809540]\n",
      "epoch:18 step:17237 [D loss: 0.684786, acc.: 52.34%] [G loss: 0.839941]\n",
      "epoch:18 step:17238 [D loss: 0.645278, acc.: 60.16%] [G loss: 0.875222]\n",
      "epoch:18 step:17239 [D loss: 0.663905, acc.: 57.81%] [G loss: 0.876109]\n",
      "epoch:18 step:17240 [D loss: 0.665574, acc.: 61.72%] [G loss: 0.868901]\n",
      "epoch:18 step:17241 [D loss: 0.719609, acc.: 49.22%] [G loss: 0.796782]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17242 [D loss: 0.688856, acc.: 55.47%] [G loss: 0.784934]\n",
      "epoch:18 step:17243 [D loss: 0.663718, acc.: 58.59%] [G loss: 0.843730]\n",
      "epoch:18 step:17244 [D loss: 0.659577, acc.: 64.06%] [G loss: 0.883009]\n",
      "epoch:18 step:17245 [D loss: 0.661264, acc.: 54.69%] [G loss: 0.843058]\n",
      "epoch:18 step:17246 [D loss: 0.675573, acc.: 60.94%] [G loss: 0.850731]\n",
      "epoch:18 step:17247 [D loss: 0.649982, acc.: 62.50%] [G loss: 0.886622]\n",
      "epoch:18 step:17248 [D loss: 0.641373, acc.: 64.84%] [G loss: 0.892248]\n",
      "epoch:18 step:17249 [D loss: 0.657168, acc.: 59.38%] [G loss: 0.871522]\n",
      "epoch:18 step:17250 [D loss: 0.681827, acc.: 55.47%] [G loss: 0.907426]\n",
      "epoch:18 step:17251 [D loss: 0.674392, acc.: 59.38%] [G loss: 0.902731]\n",
      "epoch:18 step:17252 [D loss: 0.669893, acc.: 56.25%] [G loss: 0.859997]\n",
      "epoch:18 step:17253 [D loss: 0.633366, acc.: 67.97%] [G loss: 0.879597]\n",
      "epoch:18 step:17254 [D loss: 0.672357, acc.: 54.69%] [G loss: 0.804614]\n",
      "epoch:18 step:17255 [D loss: 0.667684, acc.: 59.38%] [G loss: 0.845138]\n",
      "epoch:18 step:17256 [D loss: 0.674025, acc.: 59.38%] [G loss: 0.820053]\n",
      "epoch:18 step:17257 [D loss: 0.655865, acc.: 60.94%] [G loss: 0.820741]\n",
      "epoch:18 step:17258 [D loss: 0.657164, acc.: 56.25%] [G loss: 0.803996]\n",
      "epoch:18 step:17259 [D loss: 0.712138, acc.: 44.53%] [G loss: 0.888872]\n",
      "epoch:18 step:17260 [D loss: 0.673496, acc.: 53.12%] [G loss: 0.822835]\n",
      "epoch:18 step:17261 [D loss: 0.666818, acc.: 57.81%] [G loss: 0.869230]\n",
      "epoch:18 step:17262 [D loss: 0.673685, acc.: 58.59%] [G loss: 0.872834]\n",
      "epoch:18 step:17263 [D loss: 0.638645, acc.: 65.62%] [G loss: 0.857685]\n",
      "epoch:18 step:17264 [D loss: 0.640153, acc.: 62.50%] [G loss: 0.936039]\n",
      "epoch:18 step:17265 [D loss: 0.649873, acc.: 60.94%] [G loss: 0.853754]\n",
      "epoch:18 step:17266 [D loss: 0.637279, acc.: 67.19%] [G loss: 0.799988]\n",
      "epoch:18 step:17267 [D loss: 0.659679, acc.: 61.72%] [G loss: 0.886869]\n",
      "epoch:18 step:17268 [D loss: 0.616929, acc.: 71.09%] [G loss: 0.874189]\n",
      "epoch:18 step:17269 [D loss: 0.668963, acc.: 66.41%] [G loss: 0.902912]\n",
      "epoch:18 step:17270 [D loss: 0.653639, acc.: 62.50%] [G loss: 0.886448]\n",
      "epoch:18 step:17271 [D loss: 0.625177, acc.: 68.75%] [G loss: 0.886471]\n",
      "epoch:18 step:17272 [D loss: 0.618942, acc.: 67.19%] [G loss: 0.900173]\n",
      "epoch:18 step:17273 [D loss: 0.654933, acc.: 58.59%] [G loss: 0.835578]\n",
      "epoch:18 step:17274 [D loss: 0.644058, acc.: 60.16%] [G loss: 0.932999]\n",
      "epoch:18 step:17275 [D loss: 0.679750, acc.: 57.81%] [G loss: 0.859684]\n",
      "epoch:18 step:17276 [D loss: 0.675930, acc.: 58.59%] [G loss: 0.890193]\n",
      "epoch:18 step:17277 [D loss: 0.659981, acc.: 61.72%] [G loss: 0.875322]\n",
      "epoch:18 step:17278 [D loss: 0.680805, acc.: 52.34%] [G loss: 0.865216]\n",
      "epoch:18 step:17279 [D loss: 0.703332, acc.: 53.91%] [G loss: 0.874829]\n",
      "epoch:18 step:17280 [D loss: 0.635385, acc.: 62.50%] [G loss: 0.854574]\n",
      "epoch:18 step:17281 [D loss: 0.665944, acc.: 55.47%] [G loss: 0.847663]\n",
      "epoch:18 step:17282 [D loss: 0.659209, acc.: 62.50%] [G loss: 0.872409]\n",
      "epoch:18 step:17283 [D loss: 0.671760, acc.: 55.47%] [G loss: 0.883440]\n",
      "epoch:18 step:17284 [D loss: 0.661752, acc.: 62.50%] [G loss: 0.855016]\n",
      "epoch:18 step:17285 [D loss: 0.674817, acc.: 60.16%] [G loss: 0.852948]\n",
      "epoch:18 step:17286 [D loss: 0.649744, acc.: 64.06%] [G loss: 0.842526]\n",
      "epoch:18 step:17287 [D loss: 0.660260, acc.: 59.38%] [G loss: 0.864673]\n",
      "epoch:18 step:17288 [D loss: 0.691387, acc.: 52.34%] [G loss: 0.923236]\n",
      "epoch:18 step:17289 [D loss: 0.689616, acc.: 55.47%] [G loss: 0.891920]\n",
      "epoch:18 step:17290 [D loss: 0.641386, acc.: 62.50%] [G loss: 0.845906]\n",
      "epoch:18 step:17291 [D loss: 0.691544, acc.: 46.88%] [G loss: 0.850320]\n",
      "epoch:18 step:17292 [D loss: 0.674986, acc.: 56.25%] [G loss: 0.803938]\n",
      "epoch:18 step:17293 [D loss: 0.716150, acc.: 54.69%] [G loss: 0.872667]\n",
      "epoch:18 step:17294 [D loss: 0.713831, acc.: 51.56%] [G loss: 0.932133]\n",
      "epoch:18 step:17295 [D loss: 0.659706, acc.: 57.81%] [G loss: 0.870911]\n",
      "epoch:18 step:17296 [D loss: 0.671162, acc.: 59.38%] [G loss: 0.844905]\n",
      "epoch:18 step:17297 [D loss: 0.677526, acc.: 53.12%] [G loss: 0.889250]\n",
      "epoch:18 step:17298 [D loss: 0.692564, acc.: 57.03%] [G loss: 0.879342]\n",
      "epoch:18 step:17299 [D loss: 0.656378, acc.: 61.72%] [G loss: 0.867884]\n",
      "epoch:18 step:17300 [D loss: 0.677449, acc.: 57.03%] [G loss: 0.864561]\n",
      "epoch:18 step:17301 [D loss: 0.658543, acc.: 57.03%] [G loss: 0.860278]\n",
      "epoch:18 step:17302 [D loss: 0.682558, acc.: 53.12%] [G loss: 0.835286]\n",
      "epoch:18 step:17303 [D loss: 0.658551, acc.: 60.94%] [G loss: 0.819083]\n",
      "epoch:18 step:17304 [D loss: 0.673205, acc.: 59.38%] [G loss: 0.860848]\n",
      "epoch:18 step:17305 [D loss: 0.669007, acc.: 57.81%] [G loss: 0.866108]\n",
      "epoch:18 step:17306 [D loss: 0.693700, acc.: 57.81%] [G loss: 0.870357]\n",
      "epoch:18 step:17307 [D loss: 0.676369, acc.: 55.47%] [G loss: 0.855566]\n",
      "epoch:18 step:17308 [D loss: 0.655218, acc.: 59.38%] [G loss: 0.872944]\n",
      "epoch:18 step:17309 [D loss: 0.664443, acc.: 60.16%] [G loss: 0.845410]\n",
      "epoch:18 step:17310 [D loss: 0.686205, acc.: 53.91%] [G loss: 0.857786]\n",
      "epoch:18 step:17311 [D loss: 0.662757, acc.: 63.28%] [G loss: 0.863762]\n",
      "epoch:18 step:17312 [D loss: 0.686348, acc.: 55.47%] [G loss: 0.835034]\n",
      "epoch:18 step:17313 [D loss: 0.627392, acc.: 64.84%] [G loss: 0.901825]\n",
      "epoch:18 step:17314 [D loss: 0.692845, acc.: 55.47%] [G loss: 0.795452]\n",
      "epoch:18 step:17315 [D loss: 0.640174, acc.: 63.28%] [G loss: 0.882452]\n",
      "epoch:18 step:17316 [D loss: 0.663387, acc.: 57.03%] [G loss: 0.828121]\n",
      "epoch:18 step:17317 [D loss: 0.645259, acc.: 64.06%] [G loss: 0.859841]\n",
      "epoch:18 step:17318 [D loss: 0.675181, acc.: 57.03%] [G loss: 0.833679]\n",
      "epoch:18 step:17319 [D loss: 0.635606, acc.: 63.28%] [G loss: 0.848938]\n",
      "epoch:18 step:17320 [D loss: 0.647750, acc.: 62.50%] [G loss: 0.943232]\n",
      "epoch:18 step:17321 [D loss: 0.622889, acc.: 67.97%] [G loss: 0.847529]\n",
      "epoch:18 step:17322 [D loss: 0.657372, acc.: 63.28%] [G loss: 0.850404]\n",
      "epoch:18 step:17323 [D loss: 0.647207, acc.: 60.94%] [G loss: 0.842137]\n",
      "epoch:18 step:17324 [D loss: 0.665838, acc.: 59.38%] [G loss: 0.825614]\n",
      "epoch:18 step:17325 [D loss: 0.633950, acc.: 63.28%] [G loss: 0.865364]\n",
      "epoch:18 step:17326 [D loss: 0.649891, acc.: 55.47%] [G loss: 0.885925]\n",
      "epoch:18 step:17327 [D loss: 0.661954, acc.: 55.47%] [G loss: 0.902270]\n",
      "epoch:18 step:17328 [D loss: 0.680792, acc.: 55.47%] [G loss: 0.929327]\n",
      "epoch:18 step:17329 [D loss: 0.661481, acc.: 58.59%] [G loss: 0.986209]\n",
      "epoch:18 step:17330 [D loss: 0.684459, acc.: 51.56%] [G loss: 0.924495]\n",
      "epoch:18 step:17331 [D loss: 0.656484, acc.: 57.03%] [G loss: 0.899957]\n",
      "epoch:18 step:17332 [D loss: 0.648989, acc.: 60.16%] [G loss: 0.866185]\n",
      "epoch:18 step:17333 [D loss: 0.680962, acc.: 56.25%] [G loss: 0.877609]\n",
      "epoch:18 step:17334 [D loss: 0.625740, acc.: 67.97%] [G loss: 0.909871]\n",
      "epoch:18 step:17335 [D loss: 0.636594, acc.: 61.72%] [G loss: 0.893866]\n",
      "epoch:18 step:17336 [D loss: 0.687234, acc.: 60.94%] [G loss: 0.858704]\n",
      "epoch:18 step:17337 [D loss: 0.654991, acc.: 56.25%] [G loss: 0.929038]\n",
      "epoch:18 step:17338 [D loss: 0.664019, acc.: 60.94%] [G loss: 0.880707]\n",
      "epoch:18 step:17339 [D loss: 0.647447, acc.: 60.16%] [G loss: 0.933845]\n",
      "epoch:18 step:17340 [D loss: 0.648680, acc.: 67.97%] [G loss: 0.934548]\n",
      "epoch:18 step:17341 [D loss: 0.659202, acc.: 58.59%] [G loss: 0.924172]\n",
      "epoch:18 step:17342 [D loss: 0.653161, acc.: 64.84%] [G loss: 0.891327]\n",
      "epoch:18 step:17343 [D loss: 0.667783, acc.: 63.28%] [G loss: 0.878949]\n",
      "epoch:18 step:17344 [D loss: 0.645828, acc.: 65.62%] [G loss: 0.838368]\n",
      "epoch:18 step:17345 [D loss: 0.706179, acc.: 50.78%] [G loss: 0.875397]\n",
      "epoch:18 step:17346 [D loss: 0.673848, acc.: 58.59%] [G loss: 0.864334]\n",
      "epoch:18 step:17347 [D loss: 0.681318, acc.: 58.59%] [G loss: 0.836273]\n",
      "epoch:18 step:17348 [D loss: 0.664314, acc.: 58.59%] [G loss: 0.837633]\n",
      "epoch:18 step:17349 [D loss: 0.662010, acc.: 55.47%] [G loss: 0.883149]\n",
      "epoch:18 step:17350 [D loss: 0.696448, acc.: 50.78%] [G loss: 0.884395]\n",
      "epoch:18 step:17351 [D loss: 0.663203, acc.: 56.25%] [G loss: 0.872647]\n",
      "epoch:18 step:17352 [D loss: 0.634835, acc.: 62.50%] [G loss: 0.830131]\n",
      "epoch:18 step:17353 [D loss: 0.672253, acc.: 58.59%] [G loss: 0.884233]\n",
      "epoch:18 step:17354 [D loss: 0.634749, acc.: 64.06%] [G loss: 0.885373]\n",
      "epoch:18 step:17355 [D loss: 0.669122, acc.: 55.47%] [G loss: 0.855555]\n",
      "epoch:18 step:17356 [D loss: 0.660652, acc.: 60.16%] [G loss: 0.904873]\n",
      "epoch:18 step:17357 [D loss: 0.643912, acc.: 60.94%] [G loss: 0.857858]\n",
      "epoch:18 step:17358 [D loss: 0.630750, acc.: 66.41%] [G loss: 0.868404]\n",
      "epoch:18 step:17359 [D loss: 0.675648, acc.: 59.38%] [G loss: 0.874504]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17360 [D loss: 0.673114, acc.: 60.94%] [G loss: 0.844002]\n",
      "epoch:18 step:17361 [D loss: 0.681207, acc.: 56.25%] [G loss: 0.850233]\n",
      "epoch:18 step:17362 [D loss: 0.692207, acc.: 51.56%] [G loss: 0.871827]\n",
      "epoch:18 step:17363 [D loss: 0.643607, acc.: 62.50%] [G loss: 0.901067]\n",
      "epoch:18 step:17364 [D loss: 0.703283, acc.: 48.44%] [G loss: 0.924036]\n",
      "epoch:18 step:17365 [D loss: 0.681954, acc.: 52.34%] [G loss: 0.880570]\n",
      "epoch:18 step:17366 [D loss: 0.673804, acc.: 60.94%] [G loss: 0.934588]\n",
      "epoch:18 step:17367 [D loss: 0.640522, acc.: 64.84%] [G loss: 0.852098]\n",
      "epoch:18 step:17368 [D loss: 0.656532, acc.: 59.38%] [G loss: 0.854393]\n",
      "epoch:18 step:17369 [D loss: 0.646611, acc.: 67.97%] [G loss: 0.851952]\n",
      "epoch:18 step:17370 [D loss: 0.684878, acc.: 56.25%] [G loss: 0.852093]\n",
      "epoch:18 step:17371 [D loss: 0.646100, acc.: 67.19%] [G loss: 0.863313]\n",
      "epoch:18 step:17372 [D loss: 0.656986, acc.: 64.06%] [G loss: 0.831219]\n",
      "epoch:18 step:17373 [D loss: 0.643771, acc.: 61.72%] [G loss: 0.845133]\n",
      "epoch:18 step:17374 [D loss: 0.655725, acc.: 56.25%] [G loss: 0.819135]\n",
      "epoch:18 step:17375 [D loss: 0.661542, acc.: 59.38%] [G loss: 0.812012]\n",
      "epoch:18 step:17376 [D loss: 0.628940, acc.: 67.97%] [G loss: 0.848131]\n",
      "epoch:18 step:17377 [D loss: 0.622160, acc.: 64.06%] [G loss: 0.889499]\n",
      "epoch:18 step:17378 [D loss: 0.669799, acc.: 55.47%] [G loss: 0.850055]\n",
      "epoch:18 step:17379 [D loss: 0.679502, acc.: 56.25%] [G loss: 0.876126]\n",
      "epoch:18 step:17380 [D loss: 0.674619, acc.: 54.69%] [G loss: 0.859268]\n",
      "epoch:18 step:17381 [D loss: 0.657114, acc.: 62.50%] [G loss: 0.898875]\n",
      "epoch:18 step:17382 [D loss: 0.648960, acc.: 62.50%] [G loss: 0.881269]\n",
      "epoch:18 step:17383 [D loss: 0.643679, acc.: 61.72%] [G loss: 0.860234]\n",
      "epoch:18 step:17384 [D loss: 0.671450, acc.: 60.94%] [G loss: 0.888747]\n",
      "epoch:18 step:17385 [D loss: 0.674416, acc.: 58.59%] [G loss: 0.872090]\n",
      "epoch:18 step:17386 [D loss: 0.647742, acc.: 57.81%] [G loss: 0.855606]\n",
      "epoch:18 step:17387 [D loss: 0.629522, acc.: 59.38%] [G loss: 0.897381]\n",
      "epoch:18 step:17388 [D loss: 0.623159, acc.: 67.97%] [G loss: 0.880197]\n",
      "epoch:18 step:17389 [D loss: 0.637112, acc.: 67.19%] [G loss: 0.850931]\n",
      "epoch:18 step:17390 [D loss: 0.646002, acc.: 68.75%] [G loss: 0.849387]\n",
      "epoch:18 step:17391 [D loss: 0.666654, acc.: 60.16%] [G loss: 0.842091]\n",
      "epoch:18 step:17392 [D loss: 0.664032, acc.: 58.59%] [G loss: 0.846650]\n",
      "epoch:18 step:17393 [D loss: 0.654642, acc.: 60.94%] [G loss: 0.812921]\n",
      "epoch:18 step:17394 [D loss: 0.663851, acc.: 59.38%] [G loss: 0.851471]\n",
      "epoch:18 step:17395 [D loss: 0.678987, acc.: 57.03%] [G loss: 0.891046]\n",
      "epoch:18 step:17396 [D loss: 0.636936, acc.: 64.84%] [G loss: 0.852148]\n",
      "epoch:18 step:17397 [D loss: 0.645539, acc.: 64.06%] [G loss: 0.909349]\n",
      "epoch:18 step:17398 [D loss: 0.669147, acc.: 59.38%] [G loss: 0.912255]\n",
      "epoch:18 step:17399 [D loss: 0.667102, acc.: 57.81%] [G loss: 0.860504]\n",
      "epoch:18 step:17400 [D loss: 0.699725, acc.: 51.56%] [G loss: 0.832223]\n",
      "##############\n",
      "[ 2.94929475  2.44429841  2.25801336  3.85513339  1.54783885 10.27426719\n",
      "  2.93242487  3.81324329  4.43307334  6.73753901]\n",
      "##########\n",
      "epoch:18 step:17401 [D loss: 0.644305, acc.: 66.41%] [G loss: 0.852879]\n",
      "epoch:18 step:17402 [D loss: 0.685427, acc.: 54.69%] [G loss: 0.846262]\n",
      "epoch:18 step:17403 [D loss: 0.716299, acc.: 49.22%] [G loss: 0.803084]\n",
      "epoch:18 step:17404 [D loss: 0.672097, acc.: 60.94%] [G loss: 0.833927]\n",
      "epoch:18 step:17405 [D loss: 0.677218, acc.: 60.16%] [G loss: 0.834855]\n",
      "epoch:18 step:17406 [D loss: 0.679574, acc.: 61.72%] [G loss: 0.863661]\n",
      "epoch:18 step:17407 [D loss: 0.652508, acc.: 60.94%] [G loss: 0.903761]\n",
      "epoch:18 step:17408 [D loss: 0.672637, acc.: 61.72%] [G loss: 0.870609]\n",
      "epoch:18 step:17409 [D loss: 0.630963, acc.: 68.75%] [G loss: 0.906405]\n",
      "epoch:18 step:17410 [D loss: 0.648983, acc.: 61.72%] [G loss: 0.906304]\n",
      "epoch:18 step:17411 [D loss: 0.662334, acc.: 56.25%] [G loss: 0.872713]\n",
      "epoch:18 step:17412 [D loss: 0.664049, acc.: 53.91%] [G loss: 0.892811]\n",
      "epoch:18 step:17413 [D loss: 0.662480, acc.: 55.47%] [G loss: 0.889957]\n",
      "epoch:18 step:17414 [D loss: 0.673296, acc.: 62.50%] [G loss: 0.841986]\n",
      "epoch:18 step:17415 [D loss: 0.676595, acc.: 55.47%] [G loss: 0.856249]\n",
      "epoch:18 step:17416 [D loss: 0.683001, acc.: 60.94%] [G loss: 0.910150]\n",
      "epoch:18 step:17417 [D loss: 0.689372, acc.: 59.38%] [G loss: 0.883804]\n",
      "epoch:18 step:17418 [D loss: 0.691065, acc.: 54.69%] [G loss: 0.851333]\n",
      "epoch:18 step:17419 [D loss: 0.652699, acc.: 65.62%] [G loss: 0.856593]\n",
      "epoch:18 step:17420 [D loss: 0.657250, acc.: 60.94%] [G loss: 0.896472]\n",
      "epoch:18 step:17421 [D loss: 0.679556, acc.: 58.59%] [G loss: 0.849882]\n",
      "epoch:18 step:17422 [D loss: 0.664033, acc.: 60.94%] [G loss: 0.855747]\n",
      "epoch:18 step:17423 [D loss: 0.651744, acc.: 62.50%] [G loss: 0.853887]\n",
      "epoch:18 step:17424 [D loss: 0.660404, acc.: 61.72%] [G loss: 0.831266]\n",
      "epoch:18 step:17425 [D loss: 0.670892, acc.: 55.47%] [G loss: 0.859213]\n",
      "epoch:18 step:17426 [D loss: 0.653936, acc.: 56.25%] [G loss: 0.820789]\n",
      "epoch:18 step:17427 [D loss: 0.670966, acc.: 57.03%] [G loss: 0.879602]\n",
      "epoch:18 step:17428 [D loss: 0.675542, acc.: 59.38%] [G loss: 0.839182]\n",
      "epoch:18 step:17429 [D loss: 0.657123, acc.: 64.84%] [G loss: 0.890003]\n",
      "epoch:18 step:17430 [D loss: 0.655593, acc.: 60.94%] [G loss: 0.895701]\n",
      "epoch:18 step:17431 [D loss: 0.662320, acc.: 61.72%] [G loss: 0.858289]\n",
      "epoch:18 step:17432 [D loss: 0.621557, acc.: 67.97%] [G loss: 0.879457]\n",
      "epoch:18 step:17433 [D loss: 0.635068, acc.: 60.94%] [G loss: 0.899418]\n",
      "epoch:18 step:17434 [D loss: 0.702166, acc.: 54.69%] [G loss: 0.911215]\n",
      "epoch:18 step:17435 [D loss: 0.623983, acc.: 66.41%] [G loss: 0.879112]\n",
      "epoch:18 step:17436 [D loss: 0.679196, acc.: 57.81%] [G loss: 0.903160]\n",
      "epoch:18 step:17437 [D loss: 0.693396, acc.: 50.78%] [G loss: 0.880959]\n",
      "epoch:18 step:17438 [D loss: 0.645524, acc.: 64.84%] [G loss: 0.809465]\n",
      "epoch:18 step:17439 [D loss: 0.693160, acc.: 46.88%] [G loss: 0.821769]\n",
      "epoch:18 step:17440 [D loss: 0.661657, acc.: 59.38%] [G loss: 0.821550]\n",
      "epoch:18 step:17441 [D loss: 0.690279, acc.: 52.34%] [G loss: 0.808192]\n",
      "epoch:18 step:17442 [D loss: 0.639520, acc.: 64.84%] [G loss: 0.922660]\n",
      "epoch:18 step:17443 [D loss: 0.638151, acc.: 67.97%] [G loss: 0.849638]\n",
      "epoch:18 step:17444 [D loss: 0.650234, acc.: 62.50%] [G loss: 0.830402]\n",
      "epoch:18 step:17445 [D loss: 0.685996, acc.: 56.25%] [G loss: 0.893319]\n",
      "epoch:18 step:17446 [D loss: 0.682912, acc.: 55.47%] [G loss: 0.867850]\n",
      "epoch:18 step:17447 [D loss: 0.648258, acc.: 65.62%] [G loss: 0.856952]\n",
      "epoch:18 step:17448 [D loss: 0.659247, acc.: 63.28%] [G loss: 0.795836]\n",
      "epoch:18 step:17449 [D loss: 0.674217, acc.: 59.38%] [G loss: 0.851981]\n",
      "epoch:18 step:17450 [D loss: 0.665155, acc.: 60.16%] [G loss: 0.808135]\n",
      "epoch:18 step:17451 [D loss: 0.642169, acc.: 63.28%] [G loss: 0.831544]\n",
      "epoch:18 step:17452 [D loss: 0.668050, acc.: 59.38%] [G loss: 0.889472]\n",
      "epoch:18 step:17453 [D loss: 0.659263, acc.: 61.72%] [G loss: 0.848504]\n",
      "epoch:18 step:17454 [D loss: 0.679272, acc.: 54.69%] [G loss: 0.843834]\n",
      "epoch:18 step:17455 [D loss: 0.664482, acc.: 59.38%] [G loss: 0.863167]\n",
      "epoch:18 step:17456 [D loss: 0.662283, acc.: 64.06%] [G loss: 0.929148]\n",
      "epoch:18 step:17457 [D loss: 0.690545, acc.: 55.47%] [G loss: 0.911418]\n",
      "epoch:18 step:17458 [D loss: 0.662386, acc.: 59.38%] [G loss: 0.861995]\n",
      "epoch:18 step:17459 [D loss: 0.688849, acc.: 56.25%] [G loss: 0.890823]\n",
      "epoch:18 step:17460 [D loss: 0.636798, acc.: 68.75%] [G loss: 0.838086]\n",
      "epoch:18 step:17461 [D loss: 0.661770, acc.: 57.81%] [G loss: 0.890143]\n",
      "epoch:18 step:17462 [D loss: 0.668507, acc.: 56.25%] [G loss: 0.874175]\n",
      "epoch:18 step:17463 [D loss: 0.636990, acc.: 63.28%] [G loss: 0.883318]\n",
      "epoch:18 step:17464 [D loss: 0.636717, acc.: 60.94%] [G loss: 0.860639]\n",
      "epoch:18 step:17465 [D loss: 0.673928, acc.: 59.38%] [G loss: 0.873322]\n",
      "epoch:18 step:17466 [D loss: 0.662222, acc.: 55.47%] [G loss: 0.874439]\n",
      "epoch:18 step:17467 [D loss: 0.653264, acc.: 59.38%] [G loss: 0.863992]\n",
      "epoch:18 step:17468 [D loss: 0.666810, acc.: 57.03%] [G loss: 0.881899]\n",
      "epoch:18 step:17469 [D loss: 0.670918, acc.: 56.25%] [G loss: 0.844129]\n",
      "epoch:18 step:17470 [D loss: 0.659761, acc.: 61.72%] [G loss: 0.825258]\n",
      "epoch:18 step:17471 [D loss: 0.704519, acc.: 53.91%] [G loss: 0.859367]\n",
      "epoch:18 step:17472 [D loss: 0.676538, acc.: 56.25%] [G loss: 0.824809]\n",
      "epoch:18 step:17473 [D loss: 0.713736, acc.: 46.09%] [G loss: 0.844195]\n",
      "epoch:18 step:17474 [D loss: 0.661555, acc.: 53.91%] [G loss: 0.902562]\n",
      "epoch:18 step:17475 [D loss: 0.623259, acc.: 67.97%] [G loss: 0.861761]\n",
      "epoch:18 step:17476 [D loss: 0.659760, acc.: 59.38%] [G loss: 0.852853]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17477 [D loss: 0.647710, acc.: 67.19%] [G loss: 0.851223]\n",
      "epoch:18 step:17478 [D loss: 0.646582, acc.: 64.84%] [G loss: 0.824830]\n",
      "epoch:18 step:17479 [D loss: 0.691502, acc.: 57.03%] [G loss: 0.825912]\n",
      "epoch:18 step:17480 [D loss: 0.667843, acc.: 60.16%] [G loss: 0.861554]\n",
      "epoch:18 step:17481 [D loss: 0.686886, acc.: 60.16%] [G loss: 0.853181]\n",
      "epoch:18 step:17482 [D loss: 0.638241, acc.: 69.53%] [G loss: 0.933946]\n",
      "epoch:18 step:17483 [D loss: 0.683699, acc.: 54.69%] [G loss: 0.913052]\n",
      "epoch:18 step:17484 [D loss: 0.649408, acc.: 60.16%] [G loss: 0.884478]\n",
      "epoch:18 step:17485 [D loss: 0.659190, acc.: 59.38%] [G loss: 0.886226]\n",
      "epoch:18 step:17486 [D loss: 0.663405, acc.: 57.81%] [G loss: 0.833302]\n",
      "epoch:18 step:17487 [D loss: 0.699325, acc.: 52.34%] [G loss: 0.847296]\n",
      "epoch:18 step:17488 [D loss: 0.641362, acc.: 59.38%] [G loss: 0.879374]\n",
      "epoch:18 step:17489 [D loss: 0.629779, acc.: 65.62%] [G loss: 0.879933]\n",
      "epoch:18 step:17490 [D loss: 0.665045, acc.: 60.94%] [G loss: 0.844461]\n",
      "epoch:18 step:17491 [D loss: 0.663393, acc.: 57.03%] [G loss: 0.878447]\n",
      "epoch:18 step:17492 [D loss: 0.711477, acc.: 48.44%] [G loss: 0.856297]\n",
      "epoch:18 step:17493 [D loss: 0.650024, acc.: 63.28%] [G loss: 0.852006]\n",
      "epoch:18 step:17494 [D loss: 0.689545, acc.: 51.56%] [G loss: 0.938175]\n",
      "epoch:18 step:17495 [D loss: 0.666222, acc.: 59.38%] [G loss: 0.822353]\n",
      "epoch:18 step:17496 [D loss: 0.663673, acc.: 63.28%] [G loss: 0.839532]\n",
      "epoch:18 step:17497 [D loss: 0.663790, acc.: 57.81%] [G loss: 0.885135]\n",
      "epoch:18 step:17498 [D loss: 0.675240, acc.: 60.16%] [G loss: 0.838485]\n",
      "epoch:18 step:17499 [D loss: 0.647418, acc.: 63.28%] [G loss: 0.849071]\n",
      "epoch:18 step:17500 [D loss: 0.686831, acc.: 59.38%] [G loss: 0.883935]\n",
      "epoch:18 step:17501 [D loss: 0.644412, acc.: 66.41%] [G loss: 0.920950]\n",
      "epoch:18 step:17502 [D loss: 0.621523, acc.: 64.84%] [G loss: 0.911970]\n",
      "epoch:18 step:17503 [D loss: 0.663486, acc.: 60.94%] [G loss: 0.847695]\n",
      "epoch:18 step:17504 [D loss: 0.666300, acc.: 58.59%] [G loss: 0.880067]\n",
      "epoch:18 step:17505 [D loss: 0.658671, acc.: 57.03%] [G loss: 0.848752]\n",
      "epoch:18 step:17506 [D loss: 0.642999, acc.: 63.28%] [G loss: 0.897753]\n",
      "epoch:18 step:17507 [D loss: 0.674248, acc.: 54.69%] [G loss: 0.927831]\n",
      "epoch:18 step:17508 [D loss: 0.662422, acc.: 60.16%] [G loss: 0.872096]\n",
      "epoch:18 step:17509 [D loss: 0.658654, acc.: 62.50%] [G loss: 0.840471]\n",
      "epoch:18 step:17510 [D loss: 0.672127, acc.: 57.81%] [G loss: 0.856371]\n",
      "epoch:18 step:17511 [D loss: 0.653421, acc.: 63.28%] [G loss: 0.874414]\n",
      "epoch:18 step:17512 [D loss: 0.668889, acc.: 59.38%] [G loss: 0.867668]\n",
      "epoch:18 step:17513 [D loss: 0.706783, acc.: 57.81%] [G loss: 0.849103]\n",
      "epoch:18 step:17514 [D loss: 0.654548, acc.: 60.16%] [G loss: 0.887579]\n",
      "epoch:18 step:17515 [D loss: 0.657280, acc.: 60.94%] [G loss: 0.887344]\n",
      "epoch:18 step:17516 [D loss: 0.671115, acc.: 61.72%] [G loss: 0.850535]\n",
      "epoch:18 step:17517 [D loss: 0.653044, acc.: 60.16%] [G loss: 0.826280]\n",
      "epoch:18 step:17518 [D loss: 0.641824, acc.: 62.50%] [G loss: 0.827936]\n",
      "epoch:18 step:17519 [D loss: 0.660295, acc.: 58.59%] [G loss: 0.776057]\n",
      "epoch:18 step:17520 [D loss: 0.676659, acc.: 56.25%] [G loss: 0.827567]\n",
      "epoch:18 step:17521 [D loss: 0.692290, acc.: 50.78%] [G loss: 0.850920]\n",
      "epoch:18 step:17522 [D loss: 0.629435, acc.: 67.19%] [G loss: 0.873195]\n",
      "epoch:18 step:17523 [D loss: 0.653129, acc.: 55.47%] [G loss: 0.851682]\n",
      "epoch:18 step:17524 [D loss: 0.672153, acc.: 59.38%] [G loss: 0.849525]\n",
      "epoch:18 step:17525 [D loss: 0.663185, acc.: 62.50%] [G loss: 0.814738]\n",
      "epoch:18 step:17526 [D loss: 0.658338, acc.: 57.81%] [G loss: 0.804112]\n",
      "epoch:18 step:17527 [D loss: 0.656097, acc.: 60.16%] [G loss: 0.869146]\n",
      "epoch:18 step:17528 [D loss: 0.684696, acc.: 57.03%] [G loss: 0.847953]\n",
      "epoch:18 step:17529 [D loss: 0.625219, acc.: 67.97%] [G loss: 0.804113]\n",
      "epoch:18 step:17530 [D loss: 0.679161, acc.: 62.50%] [G loss: 0.845255]\n",
      "epoch:18 step:17531 [D loss: 0.662942, acc.: 59.38%] [G loss: 0.813703]\n",
      "epoch:18 step:17532 [D loss: 0.646734, acc.: 65.62%] [G loss: 0.824308]\n",
      "epoch:18 step:17533 [D loss: 0.695680, acc.: 56.25%] [G loss: 0.858473]\n",
      "epoch:18 step:17534 [D loss: 0.682237, acc.: 60.16%] [G loss: 0.882388]\n",
      "epoch:18 step:17535 [D loss: 0.641459, acc.: 67.19%] [G loss: 0.869688]\n",
      "epoch:18 step:17536 [D loss: 0.656152, acc.: 57.03%] [G loss: 0.852558]\n",
      "epoch:18 step:17537 [D loss: 0.684546, acc.: 57.81%] [G loss: 0.847207]\n",
      "epoch:18 step:17538 [D loss: 0.705670, acc.: 49.22%] [G loss: 0.877903]\n",
      "epoch:18 step:17539 [D loss: 0.671684, acc.: 58.59%] [G loss: 0.907039]\n",
      "epoch:18 step:17540 [D loss: 0.668125, acc.: 57.81%] [G loss: 0.873896]\n",
      "epoch:18 step:17541 [D loss: 0.680966, acc.: 56.25%] [G loss: 0.855492]\n",
      "epoch:18 step:17542 [D loss: 0.643732, acc.: 65.62%] [G loss: 0.870470]\n",
      "epoch:18 step:17543 [D loss: 0.678245, acc.: 53.91%] [G loss: 0.842924]\n",
      "epoch:18 step:17544 [D loss: 0.668645, acc.: 58.59%] [G loss: 0.828761]\n",
      "epoch:18 step:17545 [D loss: 0.651720, acc.: 58.59%] [G loss: 0.881665]\n",
      "epoch:18 step:17546 [D loss: 0.683062, acc.: 55.47%] [G loss: 0.870161]\n",
      "epoch:18 step:17547 [D loss: 0.642963, acc.: 66.41%] [G loss: 0.890384]\n",
      "epoch:18 step:17548 [D loss: 0.677553, acc.: 61.72%] [G loss: 0.883852]\n",
      "epoch:18 step:17549 [D loss: 0.663941, acc.: 51.56%] [G loss: 0.907994]\n",
      "epoch:18 step:17550 [D loss: 0.653510, acc.: 62.50%] [G loss: 0.867155]\n",
      "epoch:18 step:17551 [D loss: 0.664053, acc.: 61.72%] [G loss: 0.819363]\n",
      "epoch:18 step:17552 [D loss: 0.662158, acc.: 62.50%] [G loss: 0.908784]\n",
      "epoch:18 step:17553 [D loss: 0.638360, acc.: 62.50%] [G loss: 0.849712]\n",
      "epoch:18 step:17554 [D loss: 0.654850, acc.: 53.12%] [G loss: 0.851050]\n",
      "epoch:18 step:17555 [D loss: 0.661555, acc.: 60.16%] [G loss: 0.826609]\n",
      "epoch:18 step:17556 [D loss: 0.687928, acc.: 55.47%] [G loss: 0.869295]\n",
      "epoch:18 step:17557 [D loss: 0.687442, acc.: 53.12%] [G loss: 0.814419]\n",
      "epoch:18 step:17558 [D loss: 0.669441, acc.: 60.94%] [G loss: 0.848032]\n",
      "epoch:18 step:17559 [D loss: 0.665356, acc.: 62.50%] [G loss: 0.877033]\n",
      "epoch:18 step:17560 [D loss: 0.655527, acc.: 60.94%] [G loss: 0.855490]\n",
      "epoch:18 step:17561 [D loss: 0.637644, acc.: 65.62%] [G loss: 0.867953]\n",
      "epoch:18 step:17562 [D loss: 0.668267, acc.: 54.69%] [G loss: 0.911185]\n",
      "epoch:18 step:17563 [D loss: 0.669758, acc.: 61.72%] [G loss: 0.888244]\n",
      "epoch:18 step:17564 [D loss: 0.662525, acc.: 64.06%] [G loss: 0.884673]\n",
      "epoch:18 step:17565 [D loss: 0.674269, acc.: 54.69%] [G loss: 0.856800]\n",
      "epoch:18 step:17566 [D loss: 0.679164, acc.: 60.16%] [G loss: 0.847398]\n",
      "epoch:18 step:17567 [D loss: 0.635654, acc.: 64.84%] [G loss: 0.840108]\n",
      "epoch:18 step:17568 [D loss: 0.660325, acc.: 57.03%] [G loss: 0.876944]\n",
      "epoch:18 step:17569 [D loss: 0.682915, acc.: 53.91%] [G loss: 0.851809]\n",
      "epoch:18 step:17570 [D loss: 0.686159, acc.: 57.03%] [G loss: 0.873160]\n",
      "epoch:18 step:17571 [D loss: 0.660319, acc.: 56.25%] [G loss: 0.859757]\n",
      "epoch:18 step:17572 [D loss: 0.668289, acc.: 60.94%] [G loss: 0.854797]\n",
      "epoch:18 step:17573 [D loss: 0.674019, acc.: 53.91%] [G loss: 0.850884]\n",
      "epoch:18 step:17574 [D loss: 0.666789, acc.: 58.59%] [G loss: 0.875901]\n",
      "epoch:18 step:17575 [D loss: 0.666234, acc.: 60.16%] [G loss: 0.943250]\n",
      "epoch:18 step:17576 [D loss: 0.609443, acc.: 68.75%] [G loss: 0.991753]\n",
      "epoch:18 step:17577 [D loss: 0.688914, acc.: 51.56%] [G loss: 0.961786]\n",
      "epoch:18 step:17578 [D loss: 0.662468, acc.: 64.06%] [G loss: 0.898584]\n",
      "epoch:18 step:17579 [D loss: 0.675669, acc.: 58.59%] [G loss: 0.881232]\n",
      "epoch:18 step:17580 [D loss: 0.673453, acc.: 58.59%] [G loss: 0.880953]\n",
      "epoch:18 step:17581 [D loss: 0.660094, acc.: 63.28%] [G loss: 0.887749]\n",
      "epoch:18 step:17582 [D loss: 0.669880, acc.: 57.03%] [G loss: 0.879382]\n",
      "epoch:18 step:17583 [D loss: 0.654151, acc.: 59.38%] [G loss: 0.922220]\n",
      "epoch:18 step:17584 [D loss: 0.629757, acc.: 66.41%] [G loss: 0.910001]\n",
      "epoch:18 step:17585 [D loss: 0.680712, acc.: 60.16%] [G loss: 0.867871]\n",
      "epoch:18 step:17586 [D loss: 0.662449, acc.: 56.25%] [G loss: 0.928302]\n",
      "epoch:18 step:17587 [D loss: 0.669677, acc.: 59.38%] [G loss: 0.887835]\n",
      "epoch:18 step:17588 [D loss: 0.662714, acc.: 61.72%] [G loss: 0.900769]\n",
      "epoch:18 step:17589 [D loss: 0.694046, acc.: 54.69%] [G loss: 0.854962]\n",
      "epoch:18 step:17590 [D loss: 0.652617, acc.: 60.94%] [G loss: 0.879552]\n",
      "epoch:18 step:17591 [D loss: 0.649805, acc.: 58.59%] [G loss: 0.828130]\n",
      "epoch:18 step:17592 [D loss: 0.675422, acc.: 57.03%] [G loss: 0.873455]\n",
      "epoch:18 step:17593 [D loss: 0.642069, acc.: 64.06%] [G loss: 0.870257]\n",
      "epoch:18 step:17594 [D loss: 0.653551, acc.: 60.94%] [G loss: 0.844232]\n",
      "epoch:18 step:17595 [D loss: 0.680667, acc.: 57.81%] [G loss: 0.898209]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17596 [D loss: 0.656204, acc.: 63.28%] [G loss: 0.844921]\n",
      "epoch:18 step:17597 [D loss: 0.705734, acc.: 57.03%] [G loss: 0.869303]\n",
      "epoch:18 step:17598 [D loss: 0.676355, acc.: 59.38%] [G loss: 0.881470]\n",
      "epoch:18 step:17599 [D loss: 0.647683, acc.: 59.38%] [G loss: 0.920283]\n",
      "epoch:18 step:17600 [D loss: 0.624707, acc.: 64.06%] [G loss: 0.858858]\n",
      "##############\n",
      "[2.96088324 2.74727149 2.14213969 3.64811189 1.3549684  6.57629288\n",
      " 2.98233225 3.61425095 4.26393233 7.14868929]\n",
      "##########\n",
      "epoch:18 step:17601 [D loss: 0.670561, acc.: 58.59%] [G loss: 0.845492]\n",
      "epoch:18 step:17602 [D loss: 0.657992, acc.: 56.25%] [G loss: 0.870222]\n",
      "epoch:18 step:17603 [D loss: 0.670331, acc.: 60.16%] [G loss: 0.881486]\n",
      "epoch:18 step:17604 [D loss: 0.680589, acc.: 52.34%] [G loss: 0.870224]\n",
      "epoch:18 step:17605 [D loss: 0.685404, acc.: 53.12%] [G loss: 0.900796]\n",
      "epoch:18 step:17606 [D loss: 0.677147, acc.: 55.47%] [G loss: 0.882332]\n",
      "epoch:18 step:17607 [D loss: 0.659420, acc.: 58.59%] [G loss: 0.847463]\n",
      "epoch:18 step:17608 [D loss: 0.683044, acc.: 63.28%] [G loss: 0.843732]\n",
      "epoch:18 step:17609 [D loss: 0.677927, acc.: 48.44%] [G loss: 0.818441]\n",
      "epoch:18 step:17610 [D loss: 0.653785, acc.: 58.59%] [G loss: 0.827987]\n",
      "epoch:18 step:17611 [D loss: 0.663866, acc.: 56.25%] [G loss: 0.828625]\n",
      "epoch:18 step:17612 [D loss: 0.664365, acc.: 61.72%] [G loss: 0.894838]\n",
      "epoch:18 step:17613 [D loss: 0.660115, acc.: 57.81%] [G loss: 0.864312]\n",
      "epoch:18 step:17614 [D loss: 0.622779, acc.: 64.84%] [G loss: 0.898893]\n",
      "epoch:18 step:17615 [D loss: 0.652088, acc.: 57.81%] [G loss: 0.862772]\n",
      "epoch:18 step:17616 [D loss: 0.659454, acc.: 60.16%] [G loss: 0.861201]\n",
      "epoch:18 step:17617 [D loss: 0.638962, acc.: 60.16%] [G loss: 0.846713]\n",
      "epoch:18 step:17618 [D loss: 0.649594, acc.: 60.16%] [G loss: 0.879514]\n",
      "epoch:18 step:17619 [D loss: 0.677799, acc.: 53.91%] [G loss: 0.854203]\n",
      "epoch:18 step:17620 [D loss: 0.698498, acc.: 53.12%] [G loss: 0.834348]\n",
      "epoch:18 step:17621 [D loss: 0.650686, acc.: 59.38%] [G loss: 0.790863]\n",
      "epoch:18 step:17622 [D loss: 0.687414, acc.: 53.91%] [G loss: 0.869698]\n",
      "epoch:18 step:17623 [D loss: 0.622135, acc.: 69.53%] [G loss: 0.906492]\n",
      "epoch:18 step:17624 [D loss: 0.675734, acc.: 59.38%] [G loss: 0.867355]\n",
      "epoch:18 step:17625 [D loss: 0.677510, acc.: 63.28%] [G loss: 0.817443]\n",
      "epoch:18 step:17626 [D loss: 0.688819, acc.: 56.25%] [G loss: 0.872406]\n",
      "epoch:18 step:17627 [D loss: 0.690842, acc.: 57.03%] [G loss: 0.888821]\n",
      "epoch:18 step:17628 [D loss: 0.677510, acc.: 57.03%] [G loss: 0.844260]\n",
      "epoch:18 step:17629 [D loss: 0.667395, acc.: 62.50%] [G loss: 0.923006]\n",
      "epoch:18 step:17630 [D loss: 0.637928, acc.: 63.28%] [G loss: 0.895467]\n",
      "epoch:18 step:17631 [D loss: 0.691839, acc.: 47.66%] [G loss: 0.877106]\n",
      "epoch:18 step:17632 [D loss: 0.666557, acc.: 60.16%] [G loss: 0.890557]\n",
      "epoch:18 step:17633 [D loss: 0.654987, acc.: 61.72%] [G loss: 0.863831]\n",
      "epoch:18 step:17634 [D loss: 0.636449, acc.: 70.31%] [G loss: 0.855488]\n",
      "epoch:18 step:17635 [D loss: 0.634355, acc.: 71.09%] [G loss: 0.825857]\n",
      "epoch:18 step:17636 [D loss: 0.675604, acc.: 56.25%] [G loss: 0.892380]\n",
      "epoch:18 step:17637 [D loss: 0.672674, acc.: 62.50%] [G loss: 0.822873]\n",
      "epoch:18 step:17638 [D loss: 0.733215, acc.: 48.44%] [G loss: 0.813445]\n",
      "epoch:18 step:17639 [D loss: 0.689119, acc.: 50.78%] [G loss: 0.892045]\n",
      "epoch:18 step:17640 [D loss: 0.654843, acc.: 60.94%] [G loss: 0.884173]\n",
      "epoch:18 step:17641 [D loss: 0.643205, acc.: 60.94%] [G loss: 0.910013]\n",
      "epoch:18 step:17642 [D loss: 0.658691, acc.: 64.06%] [G loss: 0.841664]\n",
      "epoch:18 step:17643 [D loss: 0.671610, acc.: 61.72%] [G loss: 0.857760]\n",
      "epoch:18 step:17644 [D loss: 0.648469, acc.: 66.41%] [G loss: 0.894567]\n",
      "epoch:18 step:17645 [D loss: 0.655831, acc.: 59.38%] [G loss: 0.838114]\n",
      "epoch:18 step:17646 [D loss: 0.679507, acc.: 50.78%] [G loss: 0.892809]\n",
      "epoch:18 step:17647 [D loss: 0.745601, acc.: 47.66%] [G loss: 0.833553]\n",
      "epoch:18 step:17648 [D loss: 0.684256, acc.: 56.25%] [G loss: 0.823864]\n",
      "epoch:18 step:17649 [D loss: 0.684022, acc.: 55.47%] [G loss: 0.877279]\n",
      "epoch:18 step:17650 [D loss: 0.663302, acc.: 60.16%] [G loss: 0.863184]\n",
      "epoch:18 step:17651 [D loss: 0.693969, acc.: 57.81%] [G loss: 0.816764]\n",
      "epoch:18 step:17652 [D loss: 0.669195, acc.: 62.50%] [G loss: 0.854873]\n",
      "epoch:18 step:17653 [D loss: 0.679707, acc.: 58.59%] [G loss: 0.889888]\n",
      "epoch:18 step:17654 [D loss: 0.633386, acc.: 64.06%] [G loss: 0.870587]\n",
      "epoch:18 step:17655 [D loss: 0.636723, acc.: 64.06%] [G loss: 0.886579]\n",
      "epoch:18 step:17656 [D loss: 0.645463, acc.: 61.72%] [G loss: 0.894349]\n",
      "epoch:18 step:17657 [D loss: 0.666441, acc.: 56.25%] [G loss: 0.898393]\n",
      "epoch:18 step:17658 [D loss: 0.645280, acc.: 63.28%] [G loss: 0.901834]\n",
      "epoch:18 step:17659 [D loss: 0.648997, acc.: 66.41%] [G loss: 0.836435]\n",
      "epoch:18 step:17660 [D loss: 0.636207, acc.: 67.97%] [G loss: 0.829807]\n",
      "epoch:18 step:17661 [D loss: 0.637671, acc.: 67.97%] [G loss: 0.854500]\n",
      "epoch:18 step:17662 [D loss: 0.695157, acc.: 56.25%] [G loss: 0.895895]\n",
      "epoch:18 step:17663 [D loss: 0.653467, acc.: 60.16%] [G loss: 0.890311]\n",
      "epoch:18 step:17664 [D loss: 0.647027, acc.: 61.72%] [G loss: 0.871318]\n",
      "epoch:18 step:17665 [D loss: 0.665939, acc.: 60.16%] [G loss: 0.898786]\n",
      "epoch:18 step:17666 [D loss: 0.687560, acc.: 54.69%] [G loss: 0.870952]\n",
      "epoch:18 step:17667 [D loss: 0.661690, acc.: 62.50%] [G loss: 0.870659]\n",
      "epoch:18 step:17668 [D loss: 0.679089, acc.: 57.81%] [G loss: 0.913856]\n",
      "epoch:18 step:17669 [D loss: 0.657503, acc.: 62.50%] [G loss: 0.876396]\n",
      "epoch:18 step:17670 [D loss: 0.695507, acc.: 55.47%] [G loss: 0.870606]\n",
      "epoch:18 step:17671 [D loss: 0.647484, acc.: 64.84%] [G loss: 0.841888]\n",
      "epoch:18 step:17672 [D loss: 0.612658, acc.: 70.31%] [G loss: 0.832152]\n",
      "epoch:18 step:17673 [D loss: 0.683846, acc.: 57.03%] [G loss: 0.882997]\n",
      "epoch:18 step:17674 [D loss: 0.639101, acc.: 63.28%] [G loss: 0.885293]\n",
      "epoch:18 step:17675 [D loss: 0.636068, acc.: 66.41%] [G loss: 0.854563]\n",
      "epoch:18 step:17676 [D loss: 0.637522, acc.: 60.16%] [G loss: 0.880219]\n",
      "epoch:18 step:17677 [D loss: 0.628234, acc.: 68.75%] [G loss: 0.926472]\n",
      "epoch:18 step:17678 [D loss: 0.666103, acc.: 59.38%] [G loss: 0.910930]\n",
      "epoch:18 step:17679 [D loss: 0.650122, acc.: 65.62%] [G loss: 0.908605]\n",
      "epoch:18 step:17680 [D loss: 0.615136, acc.: 69.53%] [G loss: 0.926227]\n",
      "epoch:18 step:17681 [D loss: 0.661272, acc.: 60.16%] [G loss: 0.919182]\n",
      "epoch:18 step:17682 [D loss: 0.638294, acc.: 62.50%] [G loss: 0.852133]\n",
      "epoch:18 step:17683 [D loss: 0.715121, acc.: 48.44%] [G loss: 0.844641]\n",
      "epoch:18 step:17684 [D loss: 0.667744, acc.: 57.03%] [G loss: 0.880229]\n",
      "epoch:18 step:17685 [D loss: 0.740030, acc.: 46.88%] [G loss: 0.869170]\n",
      "epoch:18 step:17686 [D loss: 0.678993, acc.: 53.12%] [G loss: 0.860630]\n",
      "epoch:18 step:17687 [D loss: 0.689920, acc.: 53.12%] [G loss: 0.904546]\n",
      "epoch:18 step:17688 [D loss: 0.606539, acc.: 67.97%] [G loss: 0.896837]\n",
      "epoch:18 step:17689 [D loss: 0.691949, acc.: 54.69%] [G loss: 0.821030]\n",
      "epoch:18 step:17690 [D loss: 0.682196, acc.: 58.59%] [G loss: 0.824564]\n",
      "epoch:18 step:17691 [D loss: 0.657247, acc.: 61.72%] [G loss: 0.859924]\n",
      "epoch:18 step:17692 [D loss: 0.600489, acc.: 71.88%] [G loss: 0.871860]\n",
      "epoch:18 step:17693 [D loss: 0.645949, acc.: 61.72%] [G loss: 0.854742]\n",
      "epoch:18 step:17694 [D loss: 0.654703, acc.: 59.38%] [G loss: 0.897467]\n",
      "epoch:18 step:17695 [D loss: 0.671338, acc.: 57.81%] [G loss: 0.851041]\n",
      "epoch:18 step:17696 [D loss: 0.656506, acc.: 57.03%] [G loss: 0.851750]\n",
      "epoch:18 step:17697 [D loss: 0.683040, acc.: 54.69%] [G loss: 0.876321]\n",
      "epoch:18 step:17698 [D loss: 0.663805, acc.: 57.03%] [G loss: 0.854952]\n",
      "epoch:18 step:17699 [D loss: 0.655739, acc.: 65.62%] [G loss: 0.882365]\n",
      "epoch:18 step:17700 [D loss: 0.695343, acc.: 55.47%] [G loss: 0.894388]\n",
      "epoch:18 step:17701 [D loss: 0.661384, acc.: 61.72%] [G loss: 0.903495]\n",
      "epoch:18 step:17702 [D loss: 0.687767, acc.: 50.78%] [G loss: 0.851951]\n",
      "epoch:18 step:17703 [D loss: 0.659848, acc.: 60.16%] [G loss: 0.847077]\n",
      "epoch:18 step:17704 [D loss: 0.667042, acc.: 60.16%] [G loss: 0.848617]\n",
      "epoch:18 step:17705 [D loss: 0.701174, acc.: 52.34%] [G loss: 0.837985]\n",
      "epoch:18 step:17706 [D loss: 0.672478, acc.: 59.38%] [G loss: 0.869742]\n",
      "epoch:18 step:17707 [D loss: 0.663712, acc.: 56.25%] [G loss: 0.842285]\n",
      "epoch:18 step:17708 [D loss: 0.695998, acc.: 53.12%] [G loss: 0.862607]\n",
      "epoch:18 step:17709 [D loss: 0.705626, acc.: 50.78%] [G loss: 0.867795]\n",
      "epoch:18 step:17710 [D loss: 0.651217, acc.: 64.84%] [G loss: 0.864950]\n",
      "epoch:18 step:17711 [D loss: 0.693689, acc.: 56.25%] [G loss: 0.893171]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:18 step:17712 [D loss: 0.672909, acc.: 55.47%] [G loss: 0.903492]\n",
      "epoch:18 step:17713 [D loss: 0.638682, acc.: 63.28%] [G loss: 0.860466]\n",
      "epoch:18 step:17714 [D loss: 0.649572, acc.: 60.16%] [G loss: 0.860504]\n",
      "epoch:18 step:17715 [D loss: 0.661999, acc.: 60.94%] [G loss: 0.821759]\n",
      "epoch:18 step:17716 [D loss: 0.660294, acc.: 60.16%] [G loss: 0.877017]\n",
      "epoch:18 step:17717 [D loss: 0.660607, acc.: 60.16%] [G loss: 0.810005]\n",
      "epoch:18 step:17718 [D loss: 0.639684, acc.: 62.50%] [G loss: 0.883571]\n",
      "epoch:18 step:17719 [D loss: 0.655274, acc.: 60.16%] [G loss: 0.862937]\n",
      "epoch:18 step:17720 [D loss: 0.606590, acc.: 71.09%] [G loss: 0.819641]\n",
      "epoch:18 step:17721 [D loss: 0.681923, acc.: 54.69%] [G loss: 0.852645]\n",
      "epoch:18 step:17722 [D loss: 0.633566, acc.: 65.62%] [G loss: 0.880356]\n",
      "epoch:18 step:17723 [D loss: 0.637010, acc.: 63.28%] [G loss: 0.911323]\n",
      "epoch:18 step:17724 [D loss: 0.635157, acc.: 60.94%] [G loss: 0.905730]\n",
      "epoch:18 step:17725 [D loss: 0.682001, acc.: 58.59%] [G loss: 0.901250]\n",
      "epoch:18 step:17726 [D loss: 0.661493, acc.: 61.72%] [G loss: 0.889546]\n",
      "epoch:18 step:17727 [D loss: 0.623625, acc.: 67.97%] [G loss: 0.925072]\n",
      "epoch:18 step:17728 [D loss: 0.654402, acc.: 58.59%] [G loss: 0.883490]\n",
      "epoch:18 step:17729 [D loss: 0.635266, acc.: 66.41%] [G loss: 0.910091]\n",
      "epoch:18 step:17730 [D loss: 0.672091, acc.: 55.47%] [G loss: 0.867737]\n",
      "epoch:18 step:17731 [D loss: 0.689868, acc.: 51.56%] [G loss: 0.869028]\n",
      "epoch:18 step:17732 [D loss: 0.658529, acc.: 58.59%] [G loss: 0.878619]\n",
      "epoch:18 step:17733 [D loss: 0.698374, acc.: 51.56%] [G loss: 0.858177]\n",
      "epoch:18 step:17734 [D loss: 0.639352, acc.: 65.62%] [G loss: 0.880379]\n",
      "epoch:18 step:17735 [D loss: 0.693318, acc.: 51.56%] [G loss: 0.839637]\n",
      "epoch:18 step:17736 [D loss: 0.663745, acc.: 58.59%] [G loss: 0.870233]\n",
      "epoch:18 step:17737 [D loss: 0.610118, acc.: 70.31%] [G loss: 0.911614]\n",
      "epoch:18 step:17738 [D loss: 0.679817, acc.: 54.69%] [G loss: 0.873599]\n",
      "epoch:18 step:17739 [D loss: 0.656937, acc.: 62.50%] [G loss: 0.840026]\n",
      "epoch:18 step:17740 [D loss: 0.701784, acc.: 53.91%] [G loss: 0.899222]\n",
      "epoch:18 step:17741 [D loss: 0.666436, acc.: 60.94%] [G loss: 0.926929]\n",
      "epoch:18 step:17742 [D loss: 0.687373, acc.: 54.69%] [G loss: 0.896150]\n",
      "epoch:18 step:17743 [D loss: 0.679672, acc.: 59.38%] [G loss: 0.925994]\n",
      "epoch:18 step:17744 [D loss: 0.675250, acc.: 60.16%] [G loss: 0.929316]\n",
      "epoch:18 step:17745 [D loss: 0.649794, acc.: 59.38%] [G loss: 0.914408]\n",
      "epoch:18 step:17746 [D loss: 0.628467, acc.: 71.09%] [G loss: 0.871030]\n",
      "epoch:18 step:17747 [D loss: 0.699371, acc.: 52.34%] [G loss: 0.831450]\n",
      "epoch:18 step:17748 [D loss: 0.648668, acc.: 64.06%] [G loss: 0.837183]\n",
      "epoch:18 step:17749 [D loss: 0.677639, acc.: 52.34%] [G loss: 0.798556]\n",
      "epoch:18 step:17750 [D loss: 0.662284, acc.: 60.16%] [G loss: 0.806823]\n",
      "epoch:18 step:17751 [D loss: 0.692268, acc.: 58.59%] [G loss: 0.837760]\n",
      "epoch:18 step:17752 [D loss: 0.680682, acc.: 60.16%] [G loss: 0.842286]\n",
      "epoch:18 step:17753 [D loss: 0.691353, acc.: 57.03%] [G loss: 0.818013]\n",
      "epoch:18 step:17754 [D loss: 0.666329, acc.: 58.59%] [G loss: 0.868893]\n",
      "epoch:18 step:17755 [D loss: 0.665700, acc.: 60.16%] [G loss: 0.874769]\n",
      "epoch:18 step:17756 [D loss: 0.687175, acc.: 56.25%] [G loss: 0.861009]\n",
      "epoch:18 step:17757 [D loss: 0.680145, acc.: 55.47%] [G loss: 0.829316]\n",
      "epoch:18 step:17758 [D loss: 0.703745, acc.: 50.78%] [G loss: 0.872308]\n",
      "epoch:18 step:17759 [D loss: 0.655425, acc.: 60.94%] [G loss: 0.843203]\n",
      "epoch:18 step:17760 [D loss: 0.662943, acc.: 59.38%] [G loss: 0.855283]\n",
      "epoch:18 step:17761 [D loss: 0.668170, acc.: 57.81%] [G loss: 0.852345]\n",
      "epoch:18 step:17762 [D loss: 0.661394, acc.: 54.69%] [G loss: 0.873662]\n",
      "epoch:18 step:17763 [D loss: 0.644495, acc.: 64.06%] [G loss: 0.837947]\n",
      "epoch:18 step:17764 [D loss: 0.696880, acc.: 51.56%] [G loss: 0.810899]\n",
      "epoch:18 step:17765 [D loss: 0.660854, acc.: 65.62%] [G loss: 0.839411]\n",
      "epoch:18 step:17766 [D loss: 0.665460, acc.: 62.50%] [G loss: 0.843745]\n",
      "epoch:18 step:17767 [D loss: 0.678524, acc.: 50.78%] [G loss: 0.866248]\n",
      "epoch:18 step:17768 [D loss: 0.677183, acc.: 55.47%] [G loss: 0.834099]\n",
      "epoch:18 step:17769 [D loss: 0.654576, acc.: 61.72%] [G loss: 0.841042]\n",
      "epoch:18 step:17770 [D loss: 0.644790, acc.: 57.03%] [G loss: 0.841423]\n",
      "epoch:18 step:17771 [D loss: 0.678373, acc.: 54.69%] [G loss: 0.870747]\n",
      "epoch:18 step:17772 [D loss: 0.640534, acc.: 54.69%] [G loss: 0.872210]\n",
      "epoch:18 step:17773 [D loss: 0.689872, acc.: 55.47%] [G loss: 0.844823]\n",
      "epoch:18 step:17774 [D loss: 0.641849, acc.: 60.16%] [G loss: 0.850667]\n",
      "epoch:18 step:17775 [D loss: 0.681532, acc.: 54.69%] [G loss: 0.841634]\n",
      "epoch:18 step:17776 [D loss: 0.729925, acc.: 46.09%] [G loss: 0.891160]\n",
      "epoch:18 step:17777 [D loss: 0.683872, acc.: 50.78%] [G loss: 0.840114]\n",
      "epoch:18 step:17778 [D loss: 0.663451, acc.: 57.03%] [G loss: 0.874451]\n",
      "epoch:18 step:17779 [D loss: 0.669630, acc.: 48.44%] [G loss: 0.903838]\n",
      "epoch:18 step:17780 [D loss: 0.660318, acc.: 60.94%] [G loss: 0.890861]\n",
      "epoch:18 step:17781 [D loss: 0.677608, acc.: 62.50%] [G loss: 0.917579]\n",
      "epoch:18 step:17782 [D loss: 0.650148, acc.: 63.28%] [G loss: 0.887389]\n",
      "epoch:18 step:17783 [D loss: 0.628310, acc.: 68.75%] [G loss: 0.909708]\n",
      "epoch:18 step:17784 [D loss: 0.665410, acc.: 57.81%] [G loss: 0.845665]\n",
      "epoch:18 step:17785 [D loss: 0.668814, acc.: 57.81%] [G loss: 0.858468]\n",
      "epoch:18 step:17786 [D loss: 0.643979, acc.: 63.28%] [G loss: 0.873573]\n",
      "epoch:18 step:17787 [D loss: 0.704679, acc.: 50.78%] [G loss: 0.834870]\n",
      "epoch:18 step:17788 [D loss: 0.664719, acc.: 60.94%] [G loss: 0.851977]\n",
      "epoch:18 step:17789 [D loss: 0.684414, acc.: 59.38%] [G loss: 0.888309]\n",
      "epoch:18 step:17790 [D loss: 0.639927, acc.: 67.97%] [G loss: 0.868642]\n",
      "epoch:18 step:17791 [D loss: 0.661744, acc.: 56.25%] [G loss: 0.864280]\n",
      "epoch:18 step:17792 [D loss: 0.648846, acc.: 66.41%] [G loss: 0.853392]\n",
      "epoch:18 step:17793 [D loss: 0.696424, acc.: 55.47%] [G loss: 0.891787]\n",
      "epoch:18 step:17794 [D loss: 0.655032, acc.: 65.62%] [G loss: 0.887305]\n",
      "epoch:18 step:17795 [D loss: 0.690351, acc.: 52.34%] [G loss: 0.837867]\n",
      "epoch:18 step:17796 [D loss: 0.661710, acc.: 61.72%] [G loss: 0.892639]\n",
      "epoch:18 step:17797 [D loss: 0.672088, acc.: 57.81%] [G loss: 0.906141]\n",
      "epoch:18 step:17798 [D loss: 0.647385, acc.: 67.19%] [G loss: 0.840121]\n",
      "epoch:18 step:17799 [D loss: 0.664662, acc.: 60.16%] [G loss: 0.841875]\n",
      "epoch:18 step:17800 [D loss: 0.647623, acc.: 64.06%] [G loss: 0.847812]\n",
      "##############\n",
      "[ 3.05362519  2.73667942  2.46308557  3.790394    1.37943162 10.27426719\n",
      "  2.93723162  3.3808307   4.04739838  6.22884889]\n",
      "##########\n",
      "epoch:18 step:17801 [D loss: 0.654816, acc.: 60.16%] [G loss: 0.833971]\n",
      "epoch:18 step:17802 [D loss: 0.636730, acc.: 67.19%] [G loss: 0.841391]\n",
      "epoch:18 step:17803 [D loss: 0.661234, acc.: 61.72%] [G loss: 0.870224]\n",
      "epoch:19 step:17804 [D loss: 0.643564, acc.: 64.06%] [G loss: 0.912657]\n",
      "epoch:19 step:17805 [D loss: 0.707573, acc.: 50.00%] [G loss: 0.886012]\n",
      "epoch:19 step:17806 [D loss: 0.662538, acc.: 58.59%] [G loss: 0.870109]\n",
      "epoch:19 step:17807 [D loss: 0.687582, acc.: 57.81%] [G loss: 0.855731]\n",
      "epoch:19 step:17808 [D loss: 0.662856, acc.: 60.94%] [G loss: 0.925181]\n",
      "epoch:19 step:17809 [D loss: 0.657049, acc.: 60.94%] [G loss: 0.859109]\n",
      "epoch:19 step:17810 [D loss: 0.655402, acc.: 62.50%] [G loss: 0.925319]\n",
      "epoch:19 step:17811 [D loss: 0.627737, acc.: 64.84%] [G loss: 0.890676]\n",
      "epoch:19 step:17812 [D loss: 0.689259, acc.: 53.91%] [G loss: 0.902902]\n",
      "epoch:19 step:17813 [D loss: 0.645036, acc.: 63.28%] [G loss: 0.846001]\n",
      "epoch:19 step:17814 [D loss: 0.599709, acc.: 69.53%] [G loss: 0.852770]\n",
      "epoch:19 step:17815 [D loss: 0.645699, acc.: 57.81%] [G loss: 0.908460]\n",
      "epoch:19 step:17816 [D loss: 0.635348, acc.: 65.62%] [G loss: 0.864156]\n",
      "epoch:19 step:17817 [D loss: 0.656995, acc.: 59.38%] [G loss: 0.871415]\n",
      "epoch:19 step:17818 [D loss: 0.671780, acc.: 60.16%] [G loss: 0.901554]\n",
      "epoch:19 step:17819 [D loss: 0.660305, acc.: 60.16%] [G loss: 0.916618]\n",
      "epoch:19 step:17820 [D loss: 0.651737, acc.: 60.16%] [G loss: 0.829718]\n",
      "epoch:19 step:17821 [D loss: 0.691882, acc.: 51.56%] [G loss: 0.883571]\n",
      "epoch:19 step:17822 [D loss: 0.664222, acc.: 63.28%] [G loss: 0.868951]\n",
      "epoch:19 step:17823 [D loss: 0.681844, acc.: 55.47%] [G loss: 0.843550]\n",
      "epoch:19 step:17824 [D loss: 0.645384, acc.: 64.06%] [G loss: 0.910081]\n",
      "epoch:19 step:17825 [D loss: 0.643399, acc.: 64.06%] [G loss: 0.879405]\n",
      "epoch:19 step:17826 [D loss: 0.656984, acc.: 60.94%] [G loss: 0.824706]\n",
      "epoch:19 step:17827 [D loss: 0.705971, acc.: 53.91%] [G loss: 0.868945]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:17828 [D loss: 0.629149, acc.: 67.19%] [G loss: 0.827938]\n",
      "epoch:19 step:17829 [D loss: 0.661490, acc.: 64.84%] [G loss: 0.868793]\n",
      "epoch:19 step:17830 [D loss: 0.630263, acc.: 65.62%] [G loss: 0.822267]\n",
      "epoch:19 step:17831 [D loss: 0.664145, acc.: 64.06%] [G loss: 0.824553]\n",
      "epoch:19 step:17832 [D loss: 0.670633, acc.: 59.38%] [G loss: 0.867156]\n",
      "epoch:19 step:17833 [D loss: 0.659309, acc.: 60.94%] [G loss: 0.860943]\n",
      "epoch:19 step:17834 [D loss: 0.663312, acc.: 64.06%] [G loss: 0.895578]\n",
      "epoch:19 step:17835 [D loss: 0.644570, acc.: 67.97%] [G loss: 0.838190]\n",
      "epoch:19 step:17836 [D loss: 0.667285, acc.: 61.72%] [G loss: 0.889794]\n",
      "epoch:19 step:17837 [D loss: 0.679269, acc.: 55.47%] [G loss: 0.888461]\n",
      "epoch:19 step:17838 [D loss: 0.701271, acc.: 50.00%] [G loss: 0.805467]\n",
      "epoch:19 step:17839 [D loss: 0.641503, acc.: 60.94%] [G loss: 0.867942]\n",
      "epoch:19 step:17840 [D loss: 0.688463, acc.: 53.91%] [G loss: 0.821947]\n",
      "epoch:19 step:17841 [D loss: 0.693273, acc.: 55.47%] [G loss: 0.859195]\n",
      "epoch:19 step:17842 [D loss: 0.670133, acc.: 60.16%] [G loss: 0.924133]\n",
      "epoch:19 step:17843 [D loss: 0.651164, acc.: 57.81%] [G loss: 0.855267]\n",
      "epoch:19 step:17844 [D loss: 0.676114, acc.: 58.59%] [G loss: 0.896564]\n",
      "epoch:19 step:17845 [D loss: 0.645651, acc.: 61.72%] [G loss: 0.837117]\n",
      "epoch:19 step:17846 [D loss: 0.683931, acc.: 51.56%] [G loss: 0.827001]\n",
      "epoch:19 step:17847 [D loss: 0.614083, acc.: 63.28%] [G loss: 0.838607]\n",
      "epoch:19 step:17848 [D loss: 0.714374, acc.: 51.56%] [G loss: 0.822346]\n",
      "epoch:19 step:17849 [D loss: 0.653283, acc.: 64.06%] [G loss: 0.860817]\n",
      "epoch:19 step:17850 [D loss: 0.660133, acc.: 61.72%] [G loss: 0.860979]\n",
      "epoch:19 step:17851 [D loss: 0.654461, acc.: 66.41%] [G loss: 0.796008]\n",
      "epoch:19 step:17852 [D loss: 0.646095, acc.: 61.72%] [G loss: 0.885047]\n",
      "epoch:19 step:17853 [D loss: 0.675062, acc.: 58.59%] [G loss: 0.859944]\n",
      "epoch:19 step:17854 [D loss: 0.673398, acc.: 57.81%] [G loss: 0.909503]\n",
      "epoch:19 step:17855 [D loss: 0.656092, acc.: 63.28%] [G loss: 0.902299]\n",
      "epoch:19 step:17856 [D loss: 0.688040, acc.: 55.47%] [G loss: 0.918070]\n",
      "epoch:19 step:17857 [D loss: 0.658091, acc.: 62.50%] [G loss: 0.942880]\n",
      "epoch:19 step:17858 [D loss: 0.708429, acc.: 51.56%] [G loss: 0.903012]\n",
      "epoch:19 step:17859 [D loss: 0.695313, acc.: 58.59%] [G loss: 0.863417]\n",
      "epoch:19 step:17860 [D loss: 0.668959, acc.: 61.72%] [G loss: 0.914131]\n",
      "epoch:19 step:17861 [D loss: 0.712518, acc.: 56.25%] [G loss: 0.831252]\n",
      "epoch:19 step:17862 [D loss: 0.615155, acc.: 70.31%] [G loss: 0.841350]\n",
      "epoch:19 step:17863 [D loss: 0.642226, acc.: 65.62%] [G loss: 0.892107]\n",
      "epoch:19 step:17864 [D loss: 0.658042, acc.: 62.50%] [G loss: 0.883909]\n",
      "epoch:19 step:17865 [D loss: 0.665996, acc.: 55.47%] [G loss: 0.918789]\n",
      "epoch:19 step:17866 [D loss: 0.682009, acc.: 55.47%] [G loss: 0.880456]\n",
      "epoch:19 step:17867 [D loss: 0.648394, acc.: 69.53%] [G loss: 0.881926]\n",
      "epoch:19 step:17868 [D loss: 0.598224, acc.: 72.66%] [G loss: 0.857472]\n",
      "epoch:19 step:17869 [D loss: 0.639878, acc.: 68.75%] [G loss: 0.854046]\n",
      "epoch:19 step:17870 [D loss: 0.746039, acc.: 47.66%] [G loss: 0.807240]\n",
      "epoch:19 step:17871 [D loss: 0.664432, acc.: 58.59%] [G loss: 0.843193]\n",
      "epoch:19 step:17872 [D loss: 0.649851, acc.: 56.25%] [G loss: 0.901575]\n",
      "epoch:19 step:17873 [D loss: 0.647941, acc.: 64.84%] [G loss: 0.874635]\n",
      "epoch:19 step:17874 [D loss: 0.645029, acc.: 62.50%] [G loss: 0.877129]\n",
      "epoch:19 step:17875 [D loss: 0.680108, acc.: 60.16%] [G loss: 0.807590]\n",
      "epoch:19 step:17876 [D loss: 0.654638, acc.: 59.38%] [G loss: 0.879723]\n",
      "epoch:19 step:17877 [D loss: 0.699220, acc.: 55.47%] [G loss: 0.877635]\n",
      "epoch:19 step:17878 [D loss: 0.654199, acc.: 60.16%] [G loss: 0.977254]\n",
      "epoch:19 step:17879 [D loss: 0.674208, acc.: 60.16%] [G loss: 0.925036]\n",
      "epoch:19 step:17880 [D loss: 0.695226, acc.: 53.91%] [G loss: 0.874850]\n",
      "epoch:19 step:17881 [D loss: 0.664982, acc.: 64.84%] [G loss: 0.905604]\n",
      "epoch:19 step:17882 [D loss: 0.653551, acc.: 58.59%] [G loss: 0.864270]\n",
      "epoch:19 step:17883 [D loss: 0.671644, acc.: 57.81%] [G loss: 0.881840]\n",
      "epoch:19 step:17884 [D loss: 0.703240, acc.: 50.78%] [G loss: 0.843379]\n",
      "epoch:19 step:17885 [D loss: 0.672417, acc.: 57.03%] [G loss: 0.857695]\n",
      "epoch:19 step:17886 [D loss: 0.682870, acc.: 57.03%] [G loss: 0.867765]\n",
      "epoch:19 step:17887 [D loss: 0.666651, acc.: 57.03%] [G loss: 0.871501]\n",
      "epoch:19 step:17888 [D loss: 0.649287, acc.: 56.25%] [G loss: 0.828071]\n",
      "epoch:19 step:17889 [D loss: 0.673868, acc.: 57.03%] [G loss: 0.859307]\n",
      "epoch:19 step:17890 [D loss: 0.659415, acc.: 58.59%] [G loss: 0.876744]\n",
      "epoch:19 step:17891 [D loss: 0.654930, acc.: 61.72%] [G loss: 0.806893]\n",
      "epoch:19 step:17892 [D loss: 0.688173, acc.: 55.47%] [G loss: 0.874079]\n",
      "epoch:19 step:17893 [D loss: 0.667686, acc.: 57.03%] [G loss: 0.868423]\n",
      "epoch:19 step:17894 [D loss: 0.656999, acc.: 58.59%] [G loss: 0.884842]\n",
      "epoch:19 step:17895 [D loss: 0.622702, acc.: 65.62%] [G loss: 0.916509]\n",
      "epoch:19 step:17896 [D loss: 0.677420, acc.: 55.47%] [G loss: 0.864514]\n",
      "epoch:19 step:17897 [D loss: 0.663661, acc.: 57.03%] [G loss: 0.814180]\n",
      "epoch:19 step:17898 [D loss: 0.718944, acc.: 50.00%] [G loss: 0.835585]\n",
      "epoch:19 step:17899 [D loss: 0.653261, acc.: 61.72%] [G loss: 0.837693]\n",
      "epoch:19 step:17900 [D loss: 0.682515, acc.: 52.34%] [G loss: 0.852497]\n",
      "epoch:19 step:17901 [D loss: 0.669196, acc.: 62.50%] [G loss: 0.875796]\n",
      "epoch:19 step:17902 [D loss: 0.662277, acc.: 64.84%] [G loss: 0.894508]\n",
      "epoch:19 step:17903 [D loss: 0.687744, acc.: 56.25%] [G loss: 0.921924]\n",
      "epoch:19 step:17904 [D loss: 0.639758, acc.: 64.06%] [G loss: 0.884494]\n",
      "epoch:19 step:17905 [D loss: 0.680393, acc.: 57.81%] [G loss: 0.855830]\n",
      "epoch:19 step:17906 [D loss: 0.650427, acc.: 60.94%] [G loss: 0.899175]\n",
      "epoch:19 step:17907 [D loss: 0.672913, acc.: 63.28%] [G loss: 0.914821]\n",
      "epoch:19 step:17908 [D loss: 0.639556, acc.: 64.84%] [G loss: 0.906489]\n",
      "epoch:19 step:17909 [D loss: 0.642493, acc.: 66.41%] [G loss: 0.919667]\n",
      "epoch:19 step:17910 [D loss: 0.675144, acc.: 53.12%] [G loss: 0.936202]\n",
      "epoch:19 step:17911 [D loss: 0.641343, acc.: 65.62%] [G loss: 0.887370]\n",
      "epoch:19 step:17912 [D loss: 0.616581, acc.: 65.62%] [G loss: 0.858387]\n",
      "epoch:19 step:17913 [D loss: 0.681305, acc.: 53.91%] [G loss: 0.933759]\n",
      "epoch:19 step:17914 [D loss: 0.705448, acc.: 53.91%] [G loss: 0.878742]\n",
      "epoch:19 step:17915 [D loss: 0.672376, acc.: 57.81%] [G loss: 0.883529]\n",
      "epoch:19 step:17916 [D loss: 0.676004, acc.: 55.47%] [G loss: 0.912885]\n",
      "epoch:19 step:17917 [D loss: 0.654453, acc.: 58.59%] [G loss: 0.833055]\n",
      "epoch:19 step:17918 [D loss: 0.672461, acc.: 56.25%] [G loss: 0.875170]\n",
      "epoch:19 step:17919 [D loss: 0.674463, acc.: 62.50%] [G loss: 0.816156]\n",
      "epoch:19 step:17920 [D loss: 0.683918, acc.: 53.91%] [G loss: 0.816137]\n",
      "epoch:19 step:17921 [D loss: 0.682342, acc.: 53.12%] [G loss: 0.838911]\n",
      "epoch:19 step:17922 [D loss: 0.640900, acc.: 64.06%] [G loss: 0.881075]\n",
      "epoch:19 step:17923 [D loss: 0.677872, acc.: 57.03%] [G loss: 0.901925]\n",
      "epoch:19 step:17924 [D loss: 0.656581, acc.: 60.94%] [G loss: 0.842024]\n",
      "epoch:19 step:17925 [D loss: 0.672066, acc.: 63.28%] [G loss: 0.858984]\n",
      "epoch:19 step:17926 [D loss: 0.713146, acc.: 50.78%] [G loss: 0.835922]\n",
      "epoch:19 step:17927 [D loss: 0.675486, acc.: 52.34%] [G loss: 0.853831]\n",
      "epoch:19 step:17928 [D loss: 0.685651, acc.: 57.03%] [G loss: 0.834664]\n",
      "epoch:19 step:17929 [D loss: 0.675651, acc.: 59.38%] [G loss: 0.848823]\n",
      "epoch:19 step:17930 [D loss: 0.620079, acc.: 71.09%] [G loss: 0.851424]\n",
      "epoch:19 step:17931 [D loss: 0.646522, acc.: 60.94%] [G loss: 0.872361]\n",
      "epoch:19 step:17932 [D loss: 0.662823, acc.: 58.59%] [G loss: 0.855592]\n",
      "epoch:19 step:17933 [D loss: 0.637473, acc.: 64.84%] [G loss: 0.838561]\n",
      "epoch:19 step:17934 [D loss: 0.641004, acc.: 67.19%] [G loss: 0.861823]\n",
      "epoch:19 step:17935 [D loss: 0.689197, acc.: 50.00%] [G loss: 0.894679]\n",
      "epoch:19 step:17936 [D loss: 0.681636, acc.: 55.47%] [G loss: 0.857145]\n",
      "epoch:19 step:17937 [D loss: 0.678975, acc.: 54.69%] [G loss: 0.833486]\n",
      "epoch:19 step:17938 [D loss: 0.700070, acc.: 50.78%] [G loss: 0.849372]\n",
      "epoch:19 step:17939 [D loss: 0.682390, acc.: 57.81%] [G loss: 0.843549]\n",
      "epoch:19 step:17940 [D loss: 0.699540, acc.: 53.12%] [G loss: 0.849535]\n",
      "epoch:19 step:17941 [D loss: 0.685254, acc.: 55.47%] [G loss: 0.800206]\n",
      "epoch:19 step:17942 [D loss: 0.662053, acc.: 55.47%] [G loss: 0.790051]\n",
      "epoch:19 step:17943 [D loss: 0.674238, acc.: 53.91%] [G loss: 0.871405]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:17944 [D loss: 0.689302, acc.: 50.78%] [G loss: 0.835128]\n",
      "epoch:19 step:17945 [D loss: 0.616102, acc.: 67.19%] [G loss: 0.836902]\n",
      "epoch:19 step:17946 [D loss: 0.632101, acc.: 71.09%] [G loss: 0.793805]\n",
      "epoch:19 step:17947 [D loss: 0.639083, acc.: 65.62%] [G loss: 0.774351]\n",
      "epoch:19 step:17948 [D loss: 0.691594, acc.: 58.59%] [G loss: 0.891437]\n",
      "epoch:19 step:17949 [D loss: 0.682640, acc.: 55.47%] [G loss: 0.840227]\n",
      "epoch:19 step:17950 [D loss: 0.657533, acc.: 63.28%] [G loss: 0.881819]\n",
      "epoch:19 step:17951 [D loss: 0.650858, acc.: 57.81%] [G loss: 0.847204]\n",
      "epoch:19 step:17952 [D loss: 0.646554, acc.: 63.28%] [G loss: 0.908974]\n",
      "epoch:19 step:17953 [D loss: 0.693717, acc.: 52.34%] [G loss: 0.867892]\n",
      "epoch:19 step:17954 [D loss: 0.670214, acc.: 58.59%] [G loss: 0.917960]\n",
      "epoch:19 step:17955 [D loss: 0.659986, acc.: 59.38%] [G loss: 0.936950]\n",
      "epoch:19 step:17956 [D loss: 0.660193, acc.: 57.81%] [G loss: 0.880397]\n",
      "epoch:19 step:17957 [D loss: 0.696100, acc.: 56.25%] [G loss: 0.845099]\n",
      "epoch:19 step:17958 [D loss: 0.634182, acc.: 60.16%] [G loss: 0.928395]\n",
      "epoch:19 step:17959 [D loss: 0.632201, acc.: 69.53%] [G loss: 0.875418]\n",
      "epoch:19 step:17960 [D loss: 0.650999, acc.: 62.50%] [G loss: 0.869784]\n",
      "epoch:19 step:17961 [D loss: 0.639875, acc.: 64.06%] [G loss: 0.925938]\n",
      "epoch:19 step:17962 [D loss: 0.666567, acc.: 54.69%] [G loss: 0.863015]\n",
      "epoch:19 step:17963 [D loss: 0.693091, acc.: 59.38%] [G loss: 0.869957]\n",
      "epoch:19 step:17964 [D loss: 0.658276, acc.: 59.38%] [G loss: 0.915342]\n",
      "epoch:19 step:17965 [D loss: 0.641534, acc.: 64.84%] [G loss: 0.857643]\n",
      "epoch:19 step:17966 [D loss: 0.657653, acc.: 60.94%] [G loss: 0.866627]\n",
      "epoch:19 step:17967 [D loss: 0.671054, acc.: 60.16%] [G loss: 0.893025]\n",
      "epoch:19 step:17968 [D loss: 0.640733, acc.: 64.84%] [G loss: 0.835555]\n",
      "epoch:19 step:17969 [D loss: 0.665931, acc.: 55.47%] [G loss: 0.892138]\n",
      "epoch:19 step:17970 [D loss: 0.657305, acc.: 58.59%] [G loss: 0.814983]\n",
      "epoch:19 step:17971 [D loss: 0.660304, acc.: 56.25%] [G loss: 0.858242]\n",
      "epoch:19 step:17972 [D loss: 0.701144, acc.: 50.78%] [G loss: 0.862469]\n",
      "epoch:19 step:17973 [D loss: 0.646376, acc.: 59.38%] [G loss: 0.872421]\n",
      "epoch:19 step:17974 [D loss: 0.697704, acc.: 53.12%] [G loss: 0.890790]\n",
      "epoch:19 step:17975 [D loss: 0.625428, acc.: 67.97%] [G loss: 0.887030]\n",
      "epoch:19 step:17976 [D loss: 0.663618, acc.: 61.72%] [G loss: 0.827014]\n",
      "epoch:19 step:17977 [D loss: 0.667526, acc.: 57.81%] [G loss: 0.839203]\n",
      "epoch:19 step:17978 [D loss: 0.666645, acc.: 60.94%] [G loss: 0.805422]\n",
      "epoch:19 step:17979 [D loss: 0.620727, acc.: 68.75%] [G loss: 0.862720]\n",
      "epoch:19 step:17980 [D loss: 0.627435, acc.: 64.84%] [G loss: 0.918376]\n",
      "epoch:19 step:17981 [D loss: 0.683143, acc.: 55.47%] [G loss: 0.835661]\n",
      "epoch:19 step:17982 [D loss: 0.671888, acc.: 60.94%] [G loss: 0.855278]\n",
      "epoch:19 step:17983 [D loss: 0.639702, acc.: 64.06%] [G loss: 0.855765]\n",
      "epoch:19 step:17984 [D loss: 0.701017, acc.: 46.09%] [G loss: 0.871064]\n",
      "epoch:19 step:17985 [D loss: 0.655996, acc.: 62.50%] [G loss: 0.872577]\n",
      "epoch:19 step:17986 [D loss: 0.626484, acc.: 65.62%] [G loss: 0.917741]\n",
      "epoch:19 step:17987 [D loss: 0.686038, acc.: 60.94%] [G loss: 0.841202]\n",
      "epoch:19 step:17988 [D loss: 0.656296, acc.: 60.94%] [G loss: 0.855429]\n",
      "epoch:19 step:17989 [D loss: 0.641909, acc.: 65.62%] [G loss: 0.856154]\n",
      "epoch:19 step:17990 [D loss: 0.661065, acc.: 59.38%] [G loss: 0.851947]\n",
      "epoch:19 step:17991 [D loss: 0.672367, acc.: 57.81%] [G loss: 0.867027]\n",
      "epoch:19 step:17992 [D loss: 0.679217, acc.: 60.94%] [G loss: 0.882788]\n",
      "epoch:19 step:17993 [D loss: 0.689928, acc.: 54.69%] [G loss: 0.828571]\n",
      "epoch:19 step:17994 [D loss: 0.650076, acc.: 58.59%] [G loss: 0.840765]\n",
      "epoch:19 step:17995 [D loss: 0.647445, acc.: 66.41%] [G loss: 0.868713]\n",
      "epoch:19 step:17996 [D loss: 0.638170, acc.: 66.41%] [G loss: 0.905833]\n",
      "epoch:19 step:17997 [D loss: 0.684429, acc.: 59.38%] [G loss: 0.858552]\n",
      "epoch:19 step:17998 [D loss: 0.640521, acc.: 66.41%] [G loss: 0.873037]\n",
      "epoch:19 step:17999 [D loss: 0.676005, acc.: 57.81%] [G loss: 0.839998]\n",
      "epoch:19 step:18000 [D loss: 0.640619, acc.: 61.72%] [G loss: 0.863547]\n",
      "##############\n",
      "[2.93658659 2.48734785 2.25602575 3.92489157 1.40947509 7.20766258\n",
      " 2.78985686 3.60132012 4.40846711 8.14868929]\n",
      "##########\n",
      "epoch:19 step:18001 [D loss: 0.692539, acc.: 64.06%] [G loss: 0.896863]\n",
      "epoch:19 step:18002 [D loss: 0.647743, acc.: 64.84%] [G loss: 0.867973]\n",
      "epoch:19 step:18003 [D loss: 0.639612, acc.: 67.19%] [G loss: 0.852271]\n",
      "epoch:19 step:18004 [D loss: 0.676270, acc.: 57.03%] [G loss: 0.867591]\n",
      "epoch:19 step:18005 [D loss: 0.601268, acc.: 71.09%] [G loss: 0.869936]\n",
      "epoch:19 step:18006 [D loss: 0.659630, acc.: 62.50%] [G loss: 0.908214]\n",
      "epoch:19 step:18007 [D loss: 0.647794, acc.: 59.38%] [G loss: 0.906003]\n",
      "epoch:19 step:18008 [D loss: 0.679129, acc.: 61.72%] [G loss: 0.868984]\n",
      "epoch:19 step:18009 [D loss: 0.704593, acc.: 55.47%] [G loss: 0.890853]\n",
      "epoch:19 step:18010 [D loss: 0.666057, acc.: 61.72%] [G loss: 0.875274]\n",
      "epoch:19 step:18011 [D loss: 0.652182, acc.: 63.28%] [G loss: 0.913386]\n",
      "epoch:19 step:18012 [D loss: 0.660618, acc.: 61.72%] [G loss: 0.911218]\n",
      "epoch:19 step:18013 [D loss: 0.674143, acc.: 57.81%] [G loss: 0.853442]\n",
      "epoch:19 step:18014 [D loss: 0.665705, acc.: 57.03%] [G loss: 0.861825]\n",
      "epoch:19 step:18015 [D loss: 0.670406, acc.: 54.69%] [G loss: 0.880373]\n",
      "epoch:19 step:18016 [D loss: 0.701043, acc.: 57.81%] [G loss: 0.877250]\n",
      "epoch:19 step:18017 [D loss: 0.666118, acc.: 63.28%] [G loss: 0.903659]\n",
      "epoch:19 step:18018 [D loss: 0.683280, acc.: 56.25%] [G loss: 0.828506]\n",
      "epoch:19 step:18019 [D loss: 0.645054, acc.: 60.16%] [G loss: 0.842297]\n",
      "epoch:19 step:18020 [D loss: 0.647918, acc.: 64.84%] [G loss: 0.925640]\n",
      "epoch:19 step:18021 [D loss: 0.667608, acc.: 59.38%] [G loss: 0.881019]\n",
      "epoch:19 step:18022 [D loss: 0.692001, acc.: 54.69%] [G loss: 0.859438]\n",
      "epoch:19 step:18023 [D loss: 0.678267, acc.: 57.81%] [G loss: 0.894415]\n",
      "epoch:19 step:18024 [D loss: 0.653593, acc.: 57.81%] [G loss: 0.874570]\n",
      "epoch:19 step:18025 [D loss: 0.688412, acc.: 50.78%] [G loss: 0.915230]\n",
      "epoch:19 step:18026 [D loss: 0.687033, acc.: 59.38%] [G loss: 0.919952]\n",
      "epoch:19 step:18027 [D loss: 0.673542, acc.: 58.59%] [G loss: 0.821521]\n",
      "epoch:19 step:18028 [D loss: 0.669637, acc.: 60.94%] [G loss: 0.854784]\n",
      "epoch:19 step:18029 [D loss: 0.657487, acc.: 60.94%] [G loss: 0.846092]\n",
      "epoch:19 step:18030 [D loss: 0.647668, acc.: 60.16%] [G loss: 0.814971]\n",
      "epoch:19 step:18031 [D loss: 0.662301, acc.: 62.50%] [G loss: 0.879949]\n",
      "epoch:19 step:18032 [D loss: 0.677973, acc.: 54.69%] [G loss: 0.846723]\n",
      "epoch:19 step:18033 [D loss: 0.709111, acc.: 57.03%] [G loss: 0.924656]\n",
      "epoch:19 step:18034 [D loss: 0.688950, acc.: 54.69%] [G loss: 0.917099]\n",
      "epoch:19 step:18035 [D loss: 0.685394, acc.: 54.69%] [G loss: 0.936601]\n",
      "epoch:19 step:18036 [D loss: 0.651232, acc.: 66.41%] [G loss: 0.897421]\n",
      "epoch:19 step:18037 [D loss: 0.675290, acc.: 54.69%] [G loss: 0.880358]\n",
      "epoch:19 step:18038 [D loss: 0.669561, acc.: 60.16%] [G loss: 0.835097]\n",
      "epoch:19 step:18039 [D loss: 0.658610, acc.: 57.03%] [G loss: 0.846103]\n",
      "epoch:19 step:18040 [D loss: 0.669369, acc.: 59.38%] [G loss: 0.848707]\n",
      "epoch:19 step:18041 [D loss: 0.691345, acc.: 53.12%] [G loss: 0.874719]\n",
      "epoch:19 step:18042 [D loss: 0.674907, acc.: 57.03%] [G loss: 0.829824]\n",
      "epoch:19 step:18043 [D loss: 0.647769, acc.: 61.72%] [G loss: 0.894095]\n",
      "epoch:19 step:18044 [D loss: 0.661228, acc.: 57.81%] [G loss: 0.890577]\n",
      "epoch:19 step:18045 [D loss: 0.650623, acc.: 64.84%] [G loss: 0.847601]\n",
      "epoch:19 step:18046 [D loss: 0.648578, acc.: 66.41%] [G loss: 0.872714]\n",
      "epoch:19 step:18047 [D loss: 0.673158, acc.: 55.47%] [G loss: 0.860727]\n",
      "epoch:19 step:18048 [D loss: 0.672377, acc.: 58.59%] [G loss: 0.854171]\n",
      "epoch:19 step:18049 [D loss: 0.669862, acc.: 57.81%] [G loss: 0.828331]\n",
      "epoch:19 step:18050 [D loss: 0.644369, acc.: 64.06%] [G loss: 0.886114]\n",
      "epoch:19 step:18051 [D loss: 0.701072, acc.: 57.03%] [G loss: 0.859592]\n",
      "epoch:19 step:18052 [D loss: 0.665389, acc.: 59.38%] [G loss: 0.901339]\n",
      "epoch:19 step:18053 [D loss: 0.641622, acc.: 61.72%] [G loss: 0.873484]\n",
      "epoch:19 step:18054 [D loss: 0.657449, acc.: 62.50%] [G loss: 0.829761]\n",
      "epoch:19 step:18055 [D loss: 0.670423, acc.: 60.94%] [G loss: 0.819345]\n",
      "epoch:19 step:18056 [D loss: 0.709693, acc.: 57.03%] [G loss: 0.861801]\n",
      "epoch:19 step:18057 [D loss: 0.668730, acc.: 56.25%] [G loss: 0.868459]\n",
      "epoch:19 step:18058 [D loss: 0.688584, acc.: 54.69%] [G loss: 0.883048]\n",
      "epoch:19 step:18059 [D loss: 0.664264, acc.: 57.03%] [G loss: 0.874796]\n",
      "epoch:19 step:18060 [D loss: 0.670158, acc.: 57.81%] [G loss: 0.881166]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18061 [D loss: 0.672202, acc.: 54.69%] [G loss: 0.864224]\n",
      "epoch:19 step:18062 [D loss: 0.644636, acc.: 66.41%] [G loss: 0.826797]\n",
      "epoch:19 step:18063 [D loss: 0.649496, acc.: 61.72%] [G loss: 0.857396]\n",
      "epoch:19 step:18064 [D loss: 0.711030, acc.: 54.69%] [G loss: 0.893468]\n",
      "epoch:19 step:18065 [D loss: 0.727844, acc.: 52.34%] [G loss: 0.879730]\n",
      "epoch:19 step:18066 [D loss: 0.662914, acc.: 63.28%] [G loss: 0.876401]\n",
      "epoch:19 step:18067 [D loss: 0.717652, acc.: 54.69%] [G loss: 0.875183]\n",
      "epoch:19 step:18068 [D loss: 0.640604, acc.: 67.19%] [G loss: 0.904550]\n",
      "epoch:19 step:18069 [D loss: 0.659869, acc.: 57.03%] [G loss: 0.913593]\n",
      "epoch:19 step:18070 [D loss: 0.647238, acc.: 60.94%] [G loss: 0.874496]\n",
      "epoch:19 step:18071 [D loss: 0.639464, acc.: 60.94%] [G loss: 0.887772]\n",
      "epoch:19 step:18072 [D loss: 0.645434, acc.: 60.94%] [G loss: 0.863927]\n",
      "epoch:19 step:18073 [D loss: 0.637820, acc.: 62.50%] [G loss: 0.873024]\n",
      "epoch:19 step:18074 [D loss: 0.673276, acc.: 57.03%] [G loss: 0.844502]\n",
      "epoch:19 step:18075 [D loss: 0.664734, acc.: 56.25%] [G loss: 0.891577]\n",
      "epoch:19 step:18076 [D loss: 0.679281, acc.: 60.94%] [G loss: 0.874515]\n",
      "epoch:19 step:18077 [D loss: 0.664875, acc.: 56.25%] [G loss: 0.861304]\n",
      "epoch:19 step:18078 [D loss: 0.669886, acc.: 61.72%] [G loss: 0.889692]\n",
      "epoch:19 step:18079 [D loss: 0.636428, acc.: 62.50%] [G loss: 0.864520]\n",
      "epoch:19 step:18080 [D loss: 0.643104, acc.: 61.72%] [G loss: 0.835288]\n",
      "epoch:19 step:18081 [D loss: 0.682965, acc.: 59.38%] [G loss: 0.840537]\n",
      "epoch:19 step:18082 [D loss: 0.680462, acc.: 53.91%] [G loss: 0.833475]\n",
      "epoch:19 step:18083 [D loss: 0.682669, acc.: 54.69%] [G loss: 0.908516]\n",
      "epoch:19 step:18084 [D loss: 0.641249, acc.: 60.94%] [G loss: 0.877887]\n",
      "epoch:19 step:18085 [D loss: 0.660666, acc.: 62.50%] [G loss: 0.908546]\n",
      "epoch:19 step:18086 [D loss: 0.653653, acc.: 59.38%] [G loss: 0.855897]\n",
      "epoch:19 step:18087 [D loss: 0.632958, acc.: 64.84%] [G loss: 0.859555]\n",
      "epoch:19 step:18088 [D loss: 0.646265, acc.: 60.94%] [G loss: 0.877805]\n",
      "epoch:19 step:18089 [D loss: 0.649719, acc.: 61.72%] [G loss: 0.872567]\n",
      "epoch:19 step:18090 [D loss: 0.637532, acc.: 63.28%] [G loss: 0.891238]\n",
      "epoch:19 step:18091 [D loss: 0.712479, acc.: 46.88%] [G loss: 0.936712]\n",
      "epoch:19 step:18092 [D loss: 0.651411, acc.: 60.94%] [G loss: 0.890282]\n",
      "epoch:19 step:18093 [D loss: 0.662409, acc.: 55.47%] [G loss: 0.862200]\n",
      "epoch:19 step:18094 [D loss: 0.681669, acc.: 57.03%] [G loss: 0.911177]\n",
      "epoch:19 step:18095 [D loss: 0.667997, acc.: 58.59%] [G loss: 0.908556]\n",
      "epoch:19 step:18096 [D loss: 0.668263, acc.: 57.81%] [G loss: 0.885165]\n",
      "epoch:19 step:18097 [D loss: 0.646125, acc.: 60.16%] [G loss: 0.882529]\n",
      "epoch:19 step:18098 [D loss: 0.644893, acc.: 62.50%] [G loss: 0.832908]\n",
      "epoch:19 step:18099 [D loss: 0.711501, acc.: 50.00%] [G loss: 0.866421]\n",
      "epoch:19 step:18100 [D loss: 0.628318, acc.: 60.16%] [G loss: 0.825038]\n",
      "epoch:19 step:18101 [D loss: 0.673944, acc.: 58.59%] [G loss: 0.810779]\n",
      "epoch:19 step:18102 [D loss: 0.698283, acc.: 53.12%] [G loss: 0.849719]\n",
      "epoch:19 step:18103 [D loss: 0.630785, acc.: 64.84%] [G loss: 0.933614]\n",
      "epoch:19 step:18104 [D loss: 0.677042, acc.: 53.12%] [G loss: 0.897348]\n",
      "epoch:19 step:18105 [D loss: 0.656966, acc.: 61.72%] [G loss: 0.891564]\n",
      "epoch:19 step:18106 [D loss: 0.676293, acc.: 55.47%] [G loss: 0.876451]\n",
      "epoch:19 step:18107 [D loss: 0.646732, acc.: 60.94%] [G loss: 0.852890]\n",
      "epoch:19 step:18108 [D loss: 0.656609, acc.: 60.94%] [G loss: 0.814861]\n",
      "epoch:19 step:18109 [D loss: 0.646656, acc.: 67.19%] [G loss: 0.875486]\n",
      "epoch:19 step:18110 [D loss: 0.684860, acc.: 57.81%] [G loss: 0.843538]\n",
      "epoch:19 step:18111 [D loss: 0.667963, acc.: 53.12%] [G loss: 0.844846]\n",
      "epoch:19 step:18112 [D loss: 0.648009, acc.: 62.50%] [G loss: 0.854190]\n",
      "epoch:19 step:18113 [D loss: 0.638348, acc.: 60.16%] [G loss: 0.896841]\n",
      "epoch:19 step:18114 [D loss: 0.674784, acc.: 54.69%] [G loss: 0.908471]\n",
      "epoch:19 step:18115 [D loss: 0.687987, acc.: 52.34%] [G loss: 0.838733]\n",
      "epoch:19 step:18116 [D loss: 0.661121, acc.: 57.03%] [G loss: 0.877926]\n",
      "epoch:19 step:18117 [D loss: 0.649698, acc.: 64.06%] [G loss: 0.886889]\n",
      "epoch:19 step:18118 [D loss: 0.637827, acc.: 63.28%] [G loss: 0.887645]\n",
      "epoch:19 step:18119 [D loss: 0.671215, acc.: 62.50%] [G loss: 0.849293]\n",
      "epoch:19 step:18120 [D loss: 0.631118, acc.: 64.06%] [G loss: 0.871083]\n",
      "epoch:19 step:18121 [D loss: 0.649936, acc.: 62.50%] [G loss: 0.862002]\n",
      "epoch:19 step:18122 [D loss: 0.656068, acc.: 50.78%] [G loss: 0.852899]\n",
      "epoch:19 step:18123 [D loss: 0.674941, acc.: 54.69%] [G loss: 0.842928]\n",
      "epoch:19 step:18124 [D loss: 0.643587, acc.: 62.50%] [G loss: 0.831749]\n",
      "epoch:19 step:18125 [D loss: 0.682146, acc.: 57.03%] [G loss: 0.877050]\n",
      "epoch:19 step:18126 [D loss: 0.676895, acc.: 55.47%] [G loss: 0.829223]\n",
      "epoch:19 step:18127 [D loss: 0.657758, acc.: 60.16%] [G loss: 0.885889]\n",
      "epoch:19 step:18128 [D loss: 0.650597, acc.: 62.50%] [G loss: 0.873103]\n",
      "epoch:19 step:18129 [D loss: 0.680929, acc.: 57.03%] [G loss: 0.840380]\n",
      "epoch:19 step:18130 [D loss: 0.643289, acc.: 60.94%] [G loss: 0.805731]\n",
      "epoch:19 step:18131 [D loss: 0.622813, acc.: 67.97%] [G loss: 0.883588]\n",
      "epoch:19 step:18132 [D loss: 0.647578, acc.: 60.16%] [G loss: 0.885219]\n",
      "epoch:19 step:18133 [D loss: 0.650455, acc.: 63.28%] [G loss: 0.848259]\n",
      "epoch:19 step:18134 [D loss: 0.651815, acc.: 61.72%] [G loss: 0.878640]\n",
      "epoch:19 step:18135 [D loss: 0.638351, acc.: 60.16%] [G loss: 0.837493]\n",
      "epoch:19 step:18136 [D loss: 0.711089, acc.: 54.69%] [G loss: 0.892451]\n",
      "epoch:19 step:18137 [D loss: 0.643341, acc.: 61.72%] [G loss: 0.856567]\n",
      "epoch:19 step:18138 [D loss: 0.645248, acc.: 60.94%] [G loss: 0.859402]\n",
      "epoch:19 step:18139 [D loss: 0.663528, acc.: 62.50%] [G loss: 0.929028]\n",
      "epoch:19 step:18140 [D loss: 0.657951, acc.: 57.03%] [G loss: 0.945586]\n",
      "epoch:19 step:18141 [D loss: 0.653947, acc.: 63.28%] [G loss: 0.885119]\n",
      "epoch:19 step:18142 [D loss: 0.638379, acc.: 64.84%] [G loss: 0.834909]\n",
      "epoch:19 step:18143 [D loss: 0.659209, acc.: 59.38%] [G loss: 0.873358]\n",
      "epoch:19 step:18144 [D loss: 0.642769, acc.: 63.28%] [G loss: 0.848818]\n",
      "epoch:19 step:18145 [D loss: 0.683802, acc.: 59.38%] [G loss: 0.869579]\n",
      "epoch:19 step:18146 [D loss: 0.683801, acc.: 52.34%] [G loss: 0.857301]\n",
      "epoch:19 step:18147 [D loss: 0.682804, acc.: 53.12%] [G loss: 0.865886]\n",
      "epoch:19 step:18148 [D loss: 0.662789, acc.: 60.16%] [G loss: 0.841244]\n",
      "epoch:19 step:18149 [D loss: 0.679497, acc.: 52.34%] [G loss: 0.897473]\n",
      "epoch:19 step:18150 [D loss: 0.643881, acc.: 64.06%] [G loss: 0.878331]\n",
      "epoch:19 step:18151 [D loss: 0.673637, acc.: 57.03%] [G loss: 0.848914]\n",
      "epoch:19 step:18152 [D loss: 0.598034, acc.: 72.66%] [G loss: 0.839209]\n",
      "epoch:19 step:18153 [D loss: 0.649753, acc.: 67.19%] [G loss: 0.830239]\n",
      "epoch:19 step:18154 [D loss: 0.669943, acc.: 54.69%] [G loss: 0.862201]\n",
      "epoch:19 step:18155 [D loss: 0.637236, acc.: 65.62%] [G loss: 0.866603]\n",
      "epoch:19 step:18156 [D loss: 0.643785, acc.: 64.84%] [G loss: 0.873323]\n",
      "epoch:19 step:18157 [D loss: 0.687238, acc.: 50.00%] [G loss: 0.842855]\n",
      "epoch:19 step:18158 [D loss: 0.666864, acc.: 63.28%] [G loss: 0.866391]\n",
      "epoch:19 step:18159 [D loss: 0.628045, acc.: 64.06%] [G loss: 0.921739]\n",
      "epoch:19 step:18160 [D loss: 0.643855, acc.: 59.38%] [G loss: 0.859649]\n",
      "epoch:19 step:18161 [D loss: 0.645965, acc.: 62.50%] [G loss: 0.902221]\n",
      "epoch:19 step:18162 [D loss: 0.704072, acc.: 51.56%] [G loss: 0.888757]\n",
      "epoch:19 step:18163 [D loss: 0.624120, acc.: 67.97%] [G loss: 0.853908]\n",
      "epoch:19 step:18164 [D loss: 0.640391, acc.: 63.28%] [G loss: 0.857152]\n",
      "epoch:19 step:18165 [D loss: 0.667794, acc.: 62.50%] [G loss: 0.812337]\n",
      "epoch:19 step:18166 [D loss: 0.678360, acc.: 53.12%] [G loss: 0.852395]\n",
      "epoch:19 step:18167 [D loss: 0.675836, acc.: 59.38%] [G loss: 0.885791]\n",
      "epoch:19 step:18168 [D loss: 0.650501, acc.: 61.72%] [G loss: 0.885896]\n",
      "epoch:19 step:18169 [D loss: 0.650358, acc.: 66.41%] [G loss: 0.878950]\n",
      "epoch:19 step:18170 [D loss: 0.646514, acc.: 62.50%] [G loss: 0.828255]\n",
      "epoch:19 step:18171 [D loss: 0.677671, acc.: 51.56%] [G loss: 0.854912]\n",
      "epoch:19 step:18172 [D loss: 0.688972, acc.: 57.81%] [G loss: 0.840124]\n",
      "epoch:19 step:18173 [D loss: 0.641753, acc.: 63.28%] [G loss: 0.849397]\n",
      "epoch:19 step:18174 [D loss: 0.666998, acc.: 57.81%] [G loss: 0.850937]\n",
      "epoch:19 step:18175 [D loss: 0.632466, acc.: 67.97%] [G loss: 0.922155]\n",
      "epoch:19 step:18176 [D loss: 0.671228, acc.: 57.81%] [G loss: 0.894051]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18177 [D loss: 0.691654, acc.: 50.78%] [G loss: 0.822266]\n",
      "epoch:19 step:18178 [D loss: 0.696017, acc.: 53.91%] [G loss: 0.834733]\n",
      "epoch:19 step:18179 [D loss: 0.714698, acc.: 53.12%] [G loss: 0.840792]\n",
      "epoch:19 step:18180 [D loss: 0.671973, acc.: 54.69%] [G loss: 0.864345]\n",
      "epoch:19 step:18181 [D loss: 0.638306, acc.: 66.41%] [G loss: 0.882162]\n",
      "epoch:19 step:18182 [D loss: 0.644528, acc.: 64.84%] [G loss: 0.887908]\n",
      "epoch:19 step:18183 [D loss: 0.684442, acc.: 60.94%] [G loss: 0.859311]\n",
      "epoch:19 step:18184 [D loss: 0.647022, acc.: 66.41%] [G loss: 0.835323]\n",
      "epoch:19 step:18185 [D loss: 0.655226, acc.: 57.03%] [G loss: 0.895885]\n",
      "epoch:19 step:18186 [D loss: 0.648700, acc.: 56.25%] [G loss: 0.836826]\n",
      "epoch:19 step:18187 [D loss: 0.681359, acc.: 56.25%] [G loss: 0.822103]\n",
      "epoch:19 step:18188 [D loss: 0.686432, acc.: 52.34%] [G loss: 0.844857]\n",
      "epoch:19 step:18189 [D loss: 0.690103, acc.: 46.88%] [G loss: 0.847497]\n",
      "epoch:19 step:18190 [D loss: 0.679698, acc.: 57.81%] [G loss: 0.876451]\n",
      "epoch:19 step:18191 [D loss: 0.696355, acc.: 55.47%] [G loss: 0.863410]\n",
      "epoch:19 step:18192 [D loss: 0.667404, acc.: 53.91%] [G loss: 0.831938]\n",
      "epoch:19 step:18193 [D loss: 0.646541, acc.: 64.84%] [G loss: 0.852936]\n",
      "epoch:19 step:18194 [D loss: 0.656901, acc.: 58.59%] [G loss: 0.842963]\n",
      "epoch:19 step:18195 [D loss: 0.649528, acc.: 64.84%] [G loss: 0.855217]\n",
      "epoch:19 step:18196 [D loss: 0.710313, acc.: 53.91%] [G loss: 0.784468]\n",
      "epoch:19 step:18197 [D loss: 0.653749, acc.: 66.41%] [G loss: 0.878134]\n",
      "epoch:19 step:18198 [D loss: 0.671882, acc.: 62.50%] [G loss: 0.859792]\n",
      "epoch:19 step:18199 [D loss: 0.666627, acc.: 57.03%] [G loss: 0.865676]\n",
      "epoch:19 step:18200 [D loss: 0.647847, acc.: 60.94%] [G loss: 0.858155]\n",
      "##############\n",
      "[2.95491179 2.37950971 2.06018705 3.74803319 1.04518416 7.2961489\n",
      " 2.87796751 3.1006326  4.33173581 6.84186907]\n",
      "##########\n",
      "epoch:19 step:18201 [D loss: 0.685709, acc.: 51.56%] [G loss: 0.888493]\n",
      "epoch:19 step:18202 [D loss: 0.653958, acc.: 59.38%] [G loss: 0.860884]\n",
      "epoch:19 step:18203 [D loss: 0.644517, acc.: 62.50%] [G loss: 0.842993]\n",
      "epoch:19 step:18204 [D loss: 0.636885, acc.: 64.84%] [G loss: 0.869943]\n",
      "epoch:19 step:18205 [D loss: 0.678735, acc.: 55.47%] [G loss: 0.849754]\n",
      "epoch:19 step:18206 [D loss: 0.651591, acc.: 61.72%] [G loss: 0.884162]\n",
      "epoch:19 step:18207 [D loss: 0.656049, acc.: 60.94%] [G loss: 0.865916]\n",
      "epoch:19 step:18208 [D loss: 0.685906, acc.: 54.69%] [G loss: 0.891634]\n",
      "epoch:19 step:18209 [D loss: 0.661554, acc.: 61.72%] [G loss: 0.866507]\n",
      "epoch:19 step:18210 [D loss: 0.678275, acc.: 57.81%] [G loss: 0.870223]\n",
      "epoch:19 step:18211 [D loss: 0.654076, acc.: 55.47%] [G loss: 0.864485]\n",
      "epoch:19 step:18212 [D loss: 0.681010, acc.: 53.12%] [G loss: 0.871497]\n",
      "epoch:19 step:18213 [D loss: 0.679254, acc.: 54.69%] [G loss: 0.836992]\n",
      "epoch:19 step:18214 [D loss: 0.668013, acc.: 60.16%] [G loss: 0.858228]\n",
      "epoch:19 step:18215 [D loss: 0.695347, acc.: 53.12%] [G loss: 0.884092]\n",
      "epoch:19 step:18216 [D loss: 0.668557, acc.: 60.16%] [G loss: 0.855545]\n",
      "epoch:19 step:18217 [D loss: 0.696038, acc.: 54.69%] [G loss: 0.873025]\n",
      "epoch:19 step:18218 [D loss: 0.667050, acc.: 58.59%] [G loss: 0.884647]\n",
      "epoch:19 step:18219 [D loss: 0.660164, acc.: 58.59%] [G loss: 0.877766]\n",
      "epoch:19 step:18220 [D loss: 0.687611, acc.: 46.88%] [G loss: 0.864449]\n",
      "epoch:19 step:18221 [D loss: 0.674230, acc.: 53.91%] [G loss: 0.824832]\n",
      "epoch:19 step:18222 [D loss: 0.637460, acc.: 68.75%] [G loss: 0.831992]\n",
      "epoch:19 step:18223 [D loss: 0.623318, acc.: 60.16%] [G loss: 0.851462]\n",
      "epoch:19 step:18224 [D loss: 0.660587, acc.: 57.03%] [G loss: 0.887896]\n",
      "epoch:19 step:18225 [D loss: 0.648142, acc.: 63.28%] [G loss: 0.862287]\n",
      "epoch:19 step:18226 [D loss: 0.636461, acc.: 64.84%] [G loss: 0.836558]\n",
      "epoch:19 step:18227 [D loss: 0.625481, acc.: 73.44%] [G loss: 0.845889]\n",
      "epoch:19 step:18228 [D loss: 0.689149, acc.: 57.81%] [G loss: 0.836304]\n",
      "epoch:19 step:18229 [D loss: 0.642878, acc.: 65.62%] [G loss: 0.811605]\n",
      "epoch:19 step:18230 [D loss: 0.690811, acc.: 57.81%] [G loss: 0.829368]\n",
      "epoch:19 step:18231 [D loss: 0.677365, acc.: 61.72%] [G loss: 0.839813]\n",
      "epoch:19 step:18232 [D loss: 0.673688, acc.: 55.47%] [G loss: 0.900776]\n",
      "epoch:19 step:18233 [D loss: 0.671448, acc.: 61.72%] [G loss: 0.838527]\n",
      "epoch:19 step:18234 [D loss: 0.659402, acc.: 62.50%] [G loss: 0.871926]\n",
      "epoch:19 step:18235 [D loss: 0.681753, acc.: 50.78%] [G loss: 0.900299]\n",
      "epoch:19 step:18236 [D loss: 0.646135, acc.: 57.03%] [G loss: 0.891784]\n",
      "epoch:19 step:18237 [D loss: 0.656003, acc.: 65.62%] [G loss: 0.911565]\n",
      "epoch:19 step:18238 [D loss: 0.671193, acc.: 57.03%] [G loss: 0.902439]\n",
      "epoch:19 step:18239 [D loss: 0.678325, acc.: 57.81%] [G loss: 0.853028]\n",
      "epoch:19 step:18240 [D loss: 0.669805, acc.: 57.03%] [G loss: 0.817524]\n",
      "epoch:19 step:18241 [D loss: 0.656846, acc.: 63.28%] [G loss: 0.849440]\n",
      "epoch:19 step:18242 [D loss: 0.651923, acc.: 63.28%] [G loss: 0.899157]\n",
      "epoch:19 step:18243 [D loss: 0.677671, acc.: 57.81%] [G loss: 0.877468]\n",
      "epoch:19 step:18244 [D loss: 0.670106, acc.: 58.59%] [G loss: 0.880081]\n",
      "epoch:19 step:18245 [D loss: 0.646775, acc.: 63.28%] [G loss: 0.883393]\n",
      "epoch:19 step:18246 [D loss: 0.668585, acc.: 59.38%] [G loss: 0.908975]\n",
      "epoch:19 step:18247 [D loss: 0.652864, acc.: 60.94%] [G loss: 0.887380]\n",
      "epoch:19 step:18248 [D loss: 0.682238, acc.: 54.69%] [G loss: 0.879313]\n",
      "epoch:19 step:18249 [D loss: 0.697727, acc.: 53.12%] [G loss: 0.844113]\n",
      "epoch:19 step:18250 [D loss: 0.676981, acc.: 60.16%] [G loss: 0.893679]\n",
      "epoch:19 step:18251 [D loss: 0.669796, acc.: 54.69%] [G loss: 0.900644]\n",
      "epoch:19 step:18252 [D loss: 0.638409, acc.: 62.50%] [G loss: 0.900720]\n",
      "epoch:19 step:18253 [D loss: 0.640255, acc.: 64.06%] [G loss: 0.933675]\n",
      "epoch:19 step:18254 [D loss: 0.657418, acc.: 59.38%] [G loss: 0.837995]\n",
      "epoch:19 step:18255 [D loss: 0.658208, acc.: 60.16%] [G loss: 0.872180]\n",
      "epoch:19 step:18256 [D loss: 0.657420, acc.: 56.25%] [G loss: 0.859367]\n",
      "epoch:19 step:18257 [D loss: 0.679994, acc.: 57.81%] [G loss: 0.875799]\n",
      "epoch:19 step:18258 [D loss: 0.663693, acc.: 60.16%] [G loss: 0.873185]\n",
      "epoch:19 step:18259 [D loss: 0.663685, acc.: 64.06%] [G loss: 0.876613]\n",
      "epoch:19 step:18260 [D loss: 0.639618, acc.: 61.72%] [G loss: 0.851033]\n",
      "epoch:19 step:18261 [D loss: 0.658642, acc.: 57.03%] [G loss: 0.870972]\n",
      "epoch:19 step:18262 [D loss: 0.622641, acc.: 67.97%] [G loss: 0.850536]\n",
      "epoch:19 step:18263 [D loss: 0.669225, acc.: 55.47%] [G loss: 0.839489]\n",
      "epoch:19 step:18264 [D loss: 0.646342, acc.: 66.41%] [G loss: 0.852214]\n",
      "epoch:19 step:18265 [D loss: 0.672851, acc.: 56.25%] [G loss: 0.881514]\n",
      "epoch:19 step:18266 [D loss: 0.662178, acc.: 60.94%] [G loss: 0.901246]\n",
      "epoch:19 step:18267 [D loss: 0.666103, acc.: 59.38%] [G loss: 0.888964]\n",
      "epoch:19 step:18268 [D loss: 0.663484, acc.: 66.41%] [G loss: 0.926899]\n",
      "epoch:19 step:18269 [D loss: 0.682456, acc.: 59.38%] [G loss: 0.897493]\n",
      "epoch:19 step:18270 [D loss: 0.666080, acc.: 62.50%] [G loss: 0.874042]\n",
      "epoch:19 step:18271 [D loss: 0.663595, acc.: 62.50%] [G loss: 0.850657]\n",
      "epoch:19 step:18272 [D loss: 0.656116, acc.: 58.59%] [G loss: 0.842946]\n",
      "epoch:19 step:18273 [D loss: 0.673277, acc.: 54.69%] [G loss: 0.843471]\n",
      "epoch:19 step:18274 [D loss: 0.655251, acc.: 60.94%] [G loss: 0.812988]\n",
      "epoch:19 step:18275 [D loss: 0.647918, acc.: 63.28%] [G loss: 0.864378]\n",
      "epoch:19 step:18276 [D loss: 0.625526, acc.: 62.50%] [G loss: 0.876401]\n",
      "epoch:19 step:18277 [D loss: 0.641939, acc.: 64.06%] [G loss: 0.891563]\n",
      "epoch:19 step:18278 [D loss: 0.639636, acc.: 60.16%] [G loss: 0.909281]\n",
      "epoch:19 step:18279 [D loss: 0.677826, acc.: 59.38%] [G loss: 0.840037]\n",
      "epoch:19 step:18280 [D loss: 0.691362, acc.: 55.47%] [G loss: 0.907659]\n",
      "epoch:19 step:18281 [D loss: 0.667749, acc.: 57.81%] [G loss: 0.925748]\n",
      "epoch:19 step:18282 [D loss: 0.663009, acc.: 56.25%] [G loss: 0.832553]\n",
      "epoch:19 step:18283 [D loss: 0.661436, acc.: 54.69%] [G loss: 0.792117]\n",
      "epoch:19 step:18284 [D loss: 0.676324, acc.: 54.69%] [G loss: 0.889622]\n",
      "epoch:19 step:18285 [D loss: 0.665555, acc.: 58.59%] [G loss: 0.827806]\n",
      "epoch:19 step:18286 [D loss: 0.685845, acc.: 53.12%] [G loss: 0.832803]\n",
      "epoch:19 step:18287 [D loss: 0.671670, acc.: 54.69%] [G loss: 0.885935]\n",
      "epoch:19 step:18288 [D loss: 0.632908, acc.: 66.41%] [G loss: 0.915499]\n",
      "epoch:19 step:18289 [D loss: 0.644589, acc.: 61.72%] [G loss: 0.949235]\n",
      "epoch:19 step:18290 [D loss: 0.656908, acc.: 58.59%] [G loss: 0.934275]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18291 [D loss: 0.626675, acc.: 60.94%] [G loss: 0.899922]\n",
      "epoch:19 step:18292 [D loss: 0.669195, acc.: 57.03%] [G loss: 0.956584]\n",
      "epoch:19 step:18293 [D loss: 0.637039, acc.: 60.16%] [G loss: 0.927035]\n",
      "epoch:19 step:18294 [D loss: 0.681928, acc.: 52.34%] [G loss: 0.869232]\n",
      "epoch:19 step:18295 [D loss: 0.611102, acc.: 74.22%] [G loss: 0.848300]\n",
      "epoch:19 step:18296 [D loss: 0.666492, acc.: 58.59%] [G loss: 0.911427]\n",
      "epoch:19 step:18297 [D loss: 0.625401, acc.: 68.75%] [G loss: 0.918741]\n",
      "epoch:19 step:18298 [D loss: 0.668958, acc.: 60.16%] [G loss: 0.911690]\n",
      "epoch:19 step:18299 [D loss: 0.680325, acc.: 53.12%] [G loss: 0.893397]\n",
      "epoch:19 step:18300 [D loss: 0.621928, acc.: 64.84%] [G loss: 0.912577]\n",
      "epoch:19 step:18301 [D loss: 0.675478, acc.: 54.69%] [G loss: 0.889992]\n",
      "epoch:19 step:18302 [D loss: 0.667968, acc.: 58.59%] [G loss: 0.885557]\n",
      "epoch:19 step:18303 [D loss: 0.656705, acc.: 58.59%] [G loss: 0.858240]\n",
      "epoch:19 step:18304 [D loss: 0.662423, acc.: 54.69%] [G loss: 0.897738]\n",
      "epoch:19 step:18305 [D loss: 0.652882, acc.: 62.50%] [G loss: 0.897979]\n",
      "epoch:19 step:18306 [D loss: 0.669794, acc.: 59.38%] [G loss: 0.909300]\n",
      "epoch:19 step:18307 [D loss: 0.692762, acc.: 57.81%] [G loss: 0.876881]\n",
      "epoch:19 step:18308 [D loss: 0.672268, acc.: 59.38%] [G loss: 0.898633]\n",
      "epoch:19 step:18309 [D loss: 0.679368, acc.: 59.38%] [G loss: 0.884023]\n",
      "epoch:19 step:18310 [D loss: 0.650223, acc.: 60.94%] [G loss: 0.883823]\n",
      "epoch:19 step:18311 [D loss: 0.632367, acc.: 64.84%] [G loss: 0.874836]\n",
      "epoch:19 step:18312 [D loss: 0.641562, acc.: 63.28%] [G loss: 0.883180]\n",
      "epoch:19 step:18313 [D loss: 0.620091, acc.: 64.84%] [G loss: 0.909179]\n",
      "epoch:19 step:18314 [D loss: 0.637155, acc.: 63.28%] [G loss: 0.893566]\n",
      "epoch:19 step:18315 [D loss: 0.686202, acc.: 54.69%] [G loss: 0.909740]\n",
      "epoch:19 step:18316 [D loss: 0.664013, acc.: 57.03%] [G loss: 0.930789]\n",
      "epoch:19 step:18317 [D loss: 0.679256, acc.: 55.47%] [G loss: 0.916726]\n",
      "epoch:19 step:18318 [D loss: 0.659318, acc.: 62.50%] [G loss: 0.916540]\n",
      "epoch:19 step:18319 [D loss: 0.631851, acc.: 70.31%] [G loss: 0.908066]\n",
      "epoch:19 step:18320 [D loss: 0.656714, acc.: 60.94%] [G loss: 0.858626]\n",
      "epoch:19 step:18321 [D loss: 0.661554, acc.: 57.81%] [G loss: 0.840025]\n",
      "epoch:19 step:18322 [D loss: 0.648189, acc.: 64.84%] [G loss: 0.882444]\n",
      "epoch:19 step:18323 [D loss: 0.652772, acc.: 64.84%] [G loss: 0.918642]\n",
      "epoch:19 step:18324 [D loss: 0.676986, acc.: 58.59%] [G loss: 0.919343]\n",
      "epoch:19 step:18325 [D loss: 0.658483, acc.: 63.28%] [G loss: 0.889565]\n",
      "epoch:19 step:18326 [D loss: 0.649839, acc.: 60.16%] [G loss: 0.906289]\n",
      "epoch:19 step:18327 [D loss: 0.658527, acc.: 54.69%] [G loss: 0.887051]\n",
      "epoch:19 step:18328 [D loss: 0.683559, acc.: 54.69%] [G loss: 0.892921]\n",
      "epoch:19 step:18329 [D loss: 0.681083, acc.: 50.78%] [G loss: 0.865263]\n",
      "epoch:19 step:18330 [D loss: 0.679632, acc.: 56.25%] [G loss: 0.822914]\n",
      "epoch:19 step:18331 [D loss: 0.711070, acc.: 53.12%] [G loss: 0.904955]\n",
      "epoch:19 step:18332 [D loss: 0.644354, acc.: 62.50%] [G loss: 0.899108]\n",
      "epoch:19 step:18333 [D loss: 0.641399, acc.: 67.19%] [G loss: 0.917728]\n",
      "epoch:19 step:18334 [D loss: 0.671575, acc.: 59.38%] [G loss: 0.894534]\n",
      "epoch:19 step:18335 [D loss: 0.693148, acc.: 49.22%] [G loss: 0.879484]\n",
      "epoch:19 step:18336 [D loss: 0.666810, acc.: 59.38%] [G loss: 0.885672]\n",
      "epoch:19 step:18337 [D loss: 0.674521, acc.: 62.50%] [G loss: 0.884090]\n",
      "epoch:19 step:18338 [D loss: 0.665283, acc.: 56.25%] [G loss: 0.793827]\n",
      "epoch:19 step:18339 [D loss: 0.687253, acc.: 47.66%] [G loss: 0.910599]\n",
      "epoch:19 step:18340 [D loss: 0.686044, acc.: 51.56%] [G loss: 0.832736]\n",
      "epoch:19 step:18341 [D loss: 0.688134, acc.: 54.69%] [G loss: 0.787976]\n",
      "epoch:19 step:18342 [D loss: 0.690940, acc.: 52.34%] [G loss: 0.795296]\n",
      "epoch:19 step:18343 [D loss: 0.660545, acc.: 61.72%] [G loss: 0.856728]\n",
      "epoch:19 step:18344 [D loss: 0.639319, acc.: 64.06%] [G loss: 0.879627]\n",
      "epoch:19 step:18345 [D loss: 0.666999, acc.: 60.94%] [G loss: 0.900573]\n",
      "epoch:19 step:18346 [D loss: 0.650731, acc.: 64.06%] [G loss: 0.838269]\n",
      "epoch:19 step:18347 [D loss: 0.636638, acc.: 60.16%] [G loss: 0.865332]\n",
      "epoch:19 step:18348 [D loss: 0.645970, acc.: 58.59%] [G loss: 0.932947]\n",
      "epoch:19 step:18349 [D loss: 0.627687, acc.: 66.41%] [G loss: 0.889597]\n",
      "epoch:19 step:18350 [D loss: 0.662567, acc.: 53.12%] [G loss: 0.866456]\n",
      "epoch:19 step:18351 [D loss: 0.666476, acc.: 60.94%] [G loss: 0.868921]\n",
      "epoch:19 step:18352 [D loss: 0.652311, acc.: 60.16%] [G loss: 0.872214]\n",
      "epoch:19 step:18353 [D loss: 0.672609, acc.: 61.72%] [G loss: 0.846727]\n",
      "epoch:19 step:18354 [D loss: 0.654920, acc.: 57.81%] [G loss: 0.908643]\n",
      "epoch:19 step:18355 [D loss: 0.690329, acc.: 53.12%] [G loss: 0.889462]\n",
      "epoch:19 step:18356 [D loss: 0.678079, acc.: 57.81%] [G loss: 0.901588]\n",
      "epoch:19 step:18357 [D loss: 0.653584, acc.: 62.50%] [G loss: 0.887846]\n",
      "epoch:19 step:18358 [D loss: 0.672483, acc.: 60.16%] [G loss: 0.914107]\n",
      "epoch:19 step:18359 [D loss: 0.659307, acc.: 58.59%] [G loss: 0.923647]\n",
      "epoch:19 step:18360 [D loss: 0.635057, acc.: 64.84%] [G loss: 0.804616]\n",
      "epoch:19 step:18361 [D loss: 0.663932, acc.: 56.25%] [G loss: 0.868018]\n",
      "epoch:19 step:18362 [D loss: 0.725285, acc.: 54.69%] [G loss: 0.834935]\n",
      "epoch:19 step:18363 [D loss: 0.655719, acc.: 56.25%] [G loss: 0.863689]\n",
      "epoch:19 step:18364 [D loss: 0.667221, acc.: 57.81%] [G loss: 0.877667]\n",
      "epoch:19 step:18365 [D loss: 0.649076, acc.: 63.28%] [G loss: 0.847118]\n",
      "epoch:19 step:18366 [D loss: 0.647692, acc.: 60.94%] [G loss: 0.854948]\n",
      "epoch:19 step:18367 [D loss: 0.659414, acc.: 60.16%] [G loss: 0.799546]\n",
      "epoch:19 step:18368 [D loss: 0.685378, acc.: 55.47%] [G loss: 0.894567]\n",
      "epoch:19 step:18369 [D loss: 0.627075, acc.: 63.28%] [G loss: 0.926162]\n",
      "epoch:19 step:18370 [D loss: 0.675809, acc.: 53.12%] [G loss: 0.916548]\n",
      "epoch:19 step:18371 [D loss: 0.671721, acc.: 57.03%] [G loss: 0.973451]\n",
      "epoch:19 step:18372 [D loss: 0.663027, acc.: 59.38%] [G loss: 0.902624]\n",
      "epoch:19 step:18373 [D loss: 0.685841, acc.: 54.69%] [G loss: 0.895742]\n",
      "epoch:19 step:18374 [D loss: 0.640674, acc.: 60.94%] [G loss: 0.841685]\n",
      "epoch:19 step:18375 [D loss: 0.660274, acc.: 67.97%] [G loss: 0.824986]\n",
      "epoch:19 step:18376 [D loss: 0.673988, acc.: 54.69%] [G loss: 0.808090]\n",
      "epoch:19 step:18377 [D loss: 0.661648, acc.: 57.03%] [G loss: 0.829024]\n",
      "epoch:19 step:18378 [D loss: 0.693894, acc.: 53.91%] [G loss: 0.899247]\n",
      "epoch:19 step:18379 [D loss: 0.673879, acc.: 60.16%] [G loss: 0.954961]\n",
      "epoch:19 step:18380 [D loss: 0.660750, acc.: 62.50%] [G loss: 0.915795]\n",
      "epoch:19 step:18381 [D loss: 0.662092, acc.: 64.84%] [G loss: 0.870349]\n",
      "epoch:19 step:18382 [D loss: 0.641393, acc.: 65.62%] [G loss: 0.925995]\n",
      "epoch:19 step:18383 [D loss: 0.676329, acc.: 52.34%] [G loss: 0.880353]\n",
      "epoch:19 step:18384 [D loss: 0.643874, acc.: 59.38%] [G loss: 0.922753]\n",
      "epoch:19 step:18385 [D loss: 0.616316, acc.: 69.53%] [G loss: 0.869923]\n",
      "epoch:19 step:18386 [D loss: 0.674564, acc.: 60.16%] [G loss: 0.837959]\n",
      "epoch:19 step:18387 [D loss: 0.656354, acc.: 62.50%] [G loss: 0.845275]\n",
      "epoch:19 step:18388 [D loss: 0.623222, acc.: 67.97%] [G loss: 0.869946]\n",
      "epoch:19 step:18389 [D loss: 0.705565, acc.: 54.69%] [G loss: 0.872727]\n",
      "epoch:19 step:18390 [D loss: 0.661702, acc.: 55.47%] [G loss: 0.852216]\n",
      "epoch:19 step:18391 [D loss: 0.685068, acc.: 53.91%] [G loss: 0.872760]\n",
      "epoch:19 step:18392 [D loss: 0.671213, acc.: 59.38%] [G loss: 0.879984]\n",
      "epoch:19 step:18393 [D loss: 0.647103, acc.: 56.25%] [G loss: 0.858625]\n",
      "epoch:19 step:18394 [D loss: 0.669624, acc.: 53.12%] [G loss: 0.848271]\n",
      "epoch:19 step:18395 [D loss: 0.685107, acc.: 57.81%] [G loss: 0.824756]\n",
      "epoch:19 step:18396 [D loss: 0.683951, acc.: 52.34%] [G loss: 0.863597]\n",
      "epoch:19 step:18397 [D loss: 0.632484, acc.: 64.84%] [G loss: 0.872063]\n",
      "epoch:19 step:18398 [D loss: 0.646112, acc.: 64.06%] [G loss: 0.833550]\n",
      "epoch:19 step:18399 [D loss: 0.625828, acc.: 65.62%] [G loss: 0.873385]\n",
      "epoch:19 step:18400 [D loss: 0.692319, acc.: 52.34%] [G loss: 0.872151]\n",
      "##############\n",
      "[3.11356552 2.17184596 2.17883659 3.92072732 1.33333997 9.27426719\n",
      " 2.70575355 3.53526901 4.17948015 6.24796494]\n",
      "##########\n",
      "epoch:19 step:18401 [D loss: 0.657477, acc.: 61.72%] [G loss: 0.893236]\n",
      "epoch:19 step:18402 [D loss: 0.639242, acc.: 55.47%] [G loss: 0.901650]\n",
      "epoch:19 step:18403 [D loss: 0.622448, acc.: 66.41%] [G loss: 0.946031]\n",
      "epoch:19 step:18404 [D loss: 0.690687, acc.: 53.12%] [G loss: 0.912562]\n",
      "epoch:19 step:18405 [D loss: 0.648485, acc.: 64.84%] [G loss: 0.865646]\n",
      "epoch:19 step:18406 [D loss: 0.679348, acc.: 51.56%] [G loss: 0.876457]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18407 [D loss: 0.667512, acc.: 59.38%] [G loss: 0.872630]\n",
      "epoch:19 step:18408 [D loss: 0.666779, acc.: 60.94%] [G loss: 0.844094]\n",
      "epoch:19 step:18409 [D loss: 0.661494, acc.: 60.94%] [G loss: 0.837189]\n",
      "epoch:19 step:18410 [D loss: 0.696731, acc.: 50.78%] [G loss: 0.855141]\n",
      "epoch:19 step:18411 [D loss: 0.665184, acc.: 53.91%] [G loss: 0.861337]\n",
      "epoch:19 step:18412 [D loss: 0.684190, acc.: 56.25%] [G loss: 0.841134]\n",
      "epoch:19 step:18413 [D loss: 0.648782, acc.: 63.28%] [G loss: 0.847091]\n",
      "epoch:19 step:18414 [D loss: 0.654931, acc.: 57.03%] [G loss: 0.859345]\n",
      "epoch:19 step:18415 [D loss: 0.660028, acc.: 60.94%] [G loss: 0.858023]\n",
      "epoch:19 step:18416 [D loss: 0.651726, acc.: 64.84%] [G loss: 0.887623]\n",
      "epoch:19 step:18417 [D loss: 0.660447, acc.: 59.38%] [G loss: 0.831645]\n",
      "epoch:19 step:18418 [D loss: 0.696479, acc.: 54.69%] [G loss: 0.859106]\n",
      "epoch:19 step:18419 [D loss: 0.629741, acc.: 62.50%] [G loss: 0.859950]\n",
      "epoch:19 step:18420 [D loss: 0.685987, acc.: 50.78%] [G loss: 0.847990]\n",
      "epoch:19 step:18421 [D loss: 0.635167, acc.: 59.38%] [G loss: 0.887298]\n",
      "epoch:19 step:18422 [D loss: 0.696443, acc.: 53.12%] [G loss: 0.840973]\n",
      "epoch:19 step:18423 [D loss: 0.631375, acc.: 66.41%] [G loss: 0.886892]\n",
      "epoch:19 step:18424 [D loss: 0.670196, acc.: 59.38%] [G loss: 0.881013]\n",
      "epoch:19 step:18425 [D loss: 0.658872, acc.: 60.94%] [G loss: 0.850424]\n",
      "epoch:19 step:18426 [D loss: 0.635078, acc.: 64.84%] [G loss: 0.871080]\n",
      "epoch:19 step:18427 [D loss: 0.648079, acc.: 57.03%] [G loss: 0.921349]\n",
      "epoch:19 step:18428 [D loss: 0.659182, acc.: 60.16%] [G loss: 0.896996]\n",
      "epoch:19 step:18429 [D loss: 0.711586, acc.: 47.66%] [G loss: 0.859570]\n",
      "epoch:19 step:18430 [D loss: 0.681387, acc.: 55.47%] [G loss: 0.838352]\n",
      "epoch:19 step:18431 [D loss: 0.697336, acc.: 52.34%] [G loss: 0.813728]\n",
      "epoch:19 step:18432 [D loss: 0.644575, acc.: 64.84%] [G loss: 0.847044]\n",
      "epoch:19 step:18433 [D loss: 0.645411, acc.: 64.84%] [G loss: 0.816641]\n",
      "epoch:19 step:18434 [D loss: 0.660196, acc.: 59.38%] [G loss: 0.852918]\n",
      "epoch:19 step:18435 [D loss: 0.669394, acc.: 58.59%] [G loss: 0.818113]\n",
      "epoch:19 step:18436 [D loss: 0.683104, acc.: 55.47%] [G loss: 0.858250]\n",
      "epoch:19 step:18437 [D loss: 0.677626, acc.: 59.38%] [G loss: 0.905695]\n",
      "epoch:19 step:18438 [D loss: 0.671008, acc.: 56.25%] [G loss: 0.933169]\n",
      "epoch:19 step:18439 [D loss: 0.616762, acc.: 67.97%] [G loss: 0.916140]\n",
      "epoch:19 step:18440 [D loss: 0.639240, acc.: 61.72%] [G loss: 0.902274]\n",
      "epoch:19 step:18441 [D loss: 0.653684, acc.: 59.38%] [G loss: 0.868238]\n",
      "epoch:19 step:18442 [D loss: 0.686242, acc.: 53.91%] [G loss: 0.819496]\n",
      "epoch:19 step:18443 [D loss: 0.628969, acc.: 67.19%] [G loss: 0.878498]\n",
      "epoch:19 step:18444 [D loss: 0.707940, acc.: 52.34%] [G loss: 0.815875]\n",
      "epoch:19 step:18445 [D loss: 0.688116, acc.: 59.38%] [G loss: 0.860164]\n",
      "epoch:19 step:18446 [D loss: 0.687996, acc.: 57.81%] [G loss: 0.869430]\n",
      "epoch:19 step:18447 [D loss: 0.654778, acc.: 58.59%] [G loss: 0.832565]\n",
      "epoch:19 step:18448 [D loss: 0.626542, acc.: 58.59%] [G loss: 0.906624]\n",
      "epoch:19 step:18449 [D loss: 0.677035, acc.: 60.16%] [G loss: 0.894885]\n",
      "epoch:19 step:18450 [D loss: 0.673956, acc.: 59.38%] [G loss: 0.886024]\n",
      "epoch:19 step:18451 [D loss: 0.620372, acc.: 69.53%] [G loss: 0.940976]\n",
      "epoch:19 step:18452 [D loss: 0.668032, acc.: 58.59%] [G loss: 0.877378]\n",
      "epoch:19 step:18453 [D loss: 0.672383, acc.: 57.81%] [G loss: 0.822777]\n",
      "epoch:19 step:18454 [D loss: 0.659399, acc.: 56.25%] [G loss: 0.838357]\n",
      "epoch:19 step:18455 [D loss: 0.658230, acc.: 57.03%] [G loss: 0.873783]\n",
      "epoch:19 step:18456 [D loss: 0.628357, acc.: 66.41%] [G loss: 0.825209]\n",
      "epoch:19 step:18457 [D loss: 0.673819, acc.: 53.12%] [G loss: 0.834245]\n",
      "epoch:19 step:18458 [D loss: 0.687213, acc.: 54.69%] [G loss: 0.868096]\n",
      "epoch:19 step:18459 [D loss: 0.657183, acc.: 62.50%] [G loss: 0.807803]\n",
      "epoch:19 step:18460 [D loss: 0.694879, acc.: 49.22%] [G loss: 0.889965]\n",
      "epoch:19 step:18461 [D loss: 0.675914, acc.: 59.38%] [G loss: 0.905659]\n",
      "epoch:19 step:18462 [D loss: 0.673470, acc.: 54.69%] [G loss: 0.882295]\n",
      "epoch:19 step:18463 [D loss: 0.672794, acc.: 58.59%] [G loss: 0.906830]\n",
      "epoch:19 step:18464 [D loss: 0.669846, acc.: 61.72%] [G loss: 0.899247]\n",
      "epoch:19 step:18465 [D loss: 0.687400, acc.: 58.59%] [G loss: 0.929133]\n",
      "epoch:19 step:18466 [D loss: 0.651822, acc.: 60.94%] [G loss: 0.921570]\n",
      "epoch:19 step:18467 [D loss: 0.668365, acc.: 61.72%] [G loss: 0.854466]\n",
      "epoch:19 step:18468 [D loss: 0.677798, acc.: 60.16%] [G loss: 0.904342]\n",
      "epoch:19 step:18469 [D loss: 0.675436, acc.: 56.25%] [G loss: 0.848216]\n",
      "epoch:19 step:18470 [D loss: 0.661919, acc.: 62.50%] [G loss: 0.857390]\n",
      "epoch:19 step:18471 [D loss: 0.669079, acc.: 58.59%] [G loss: 0.860764]\n",
      "epoch:19 step:18472 [D loss: 0.663035, acc.: 67.97%] [G loss: 0.849048]\n",
      "epoch:19 step:18473 [D loss: 0.666913, acc.: 57.81%] [G loss: 0.935848]\n",
      "epoch:19 step:18474 [D loss: 0.652496, acc.: 60.94%] [G loss: 0.860831]\n",
      "epoch:19 step:18475 [D loss: 0.675322, acc.: 52.34%] [G loss: 0.836768]\n",
      "epoch:19 step:18476 [D loss: 0.677016, acc.: 57.03%] [G loss: 0.845871]\n",
      "epoch:19 step:18477 [D loss: 0.673226, acc.: 60.16%] [G loss: 0.843865]\n",
      "epoch:19 step:18478 [D loss: 0.672885, acc.: 60.94%] [G loss: 0.862153]\n",
      "epoch:19 step:18479 [D loss: 0.664034, acc.: 58.59%] [G loss: 0.859811]\n",
      "epoch:19 step:18480 [D loss: 0.687558, acc.: 59.38%] [G loss: 0.865941]\n",
      "epoch:19 step:18481 [D loss: 0.648336, acc.: 61.72%] [G loss: 0.874721]\n",
      "epoch:19 step:18482 [D loss: 0.667674, acc.: 58.59%] [G loss: 0.867335]\n",
      "epoch:19 step:18483 [D loss: 0.662177, acc.: 55.47%] [G loss: 0.824878]\n",
      "epoch:19 step:18484 [D loss: 0.615648, acc.: 69.53%] [G loss: 0.835581]\n",
      "epoch:19 step:18485 [D loss: 0.649281, acc.: 64.06%] [G loss: 0.844429]\n",
      "epoch:19 step:18486 [D loss: 0.661617, acc.: 57.03%] [G loss: 0.848604]\n",
      "epoch:19 step:18487 [D loss: 0.670293, acc.: 57.03%] [G loss: 0.885814]\n",
      "epoch:19 step:18488 [D loss: 0.624413, acc.: 64.06%] [G loss: 0.822565]\n",
      "epoch:19 step:18489 [D loss: 0.664597, acc.: 57.81%] [G loss: 0.860266]\n",
      "epoch:19 step:18490 [D loss: 0.648686, acc.: 63.28%] [G loss: 0.831740]\n",
      "epoch:19 step:18491 [D loss: 0.650524, acc.: 58.59%] [G loss: 0.809922]\n",
      "epoch:19 step:18492 [D loss: 0.715672, acc.: 46.88%] [G loss: 0.855156]\n",
      "epoch:19 step:18493 [D loss: 0.654460, acc.: 62.50%] [G loss: 0.861025]\n",
      "epoch:19 step:18494 [D loss: 0.687228, acc.: 57.81%] [G loss: 0.842346]\n",
      "epoch:19 step:18495 [D loss: 0.681580, acc.: 51.56%] [G loss: 0.868324]\n",
      "epoch:19 step:18496 [D loss: 0.670789, acc.: 60.16%] [G loss: 0.839667]\n",
      "epoch:19 step:18497 [D loss: 0.658261, acc.: 60.94%] [G loss: 0.814125]\n",
      "epoch:19 step:18498 [D loss: 0.637437, acc.: 62.50%] [G loss: 0.851650]\n",
      "epoch:19 step:18499 [D loss: 0.640123, acc.: 62.50%] [G loss: 0.880839]\n",
      "epoch:19 step:18500 [D loss: 0.642651, acc.: 64.84%] [G loss: 0.837280]\n",
      "epoch:19 step:18501 [D loss: 0.675998, acc.: 55.47%] [G loss: 0.838381]\n",
      "epoch:19 step:18502 [D loss: 0.665260, acc.: 57.03%] [G loss: 0.814325]\n",
      "epoch:19 step:18503 [D loss: 0.626091, acc.: 66.41%] [G loss: 0.950591]\n",
      "epoch:19 step:18504 [D loss: 0.681337, acc.: 54.69%] [G loss: 0.898414]\n",
      "epoch:19 step:18505 [D loss: 0.651930, acc.: 66.41%] [G loss: 0.878872]\n",
      "epoch:19 step:18506 [D loss: 0.680639, acc.: 53.91%] [G loss: 0.917018]\n",
      "epoch:19 step:18507 [D loss: 0.673983, acc.: 57.81%] [G loss: 0.877963]\n",
      "epoch:19 step:18508 [D loss: 0.673324, acc.: 53.91%] [G loss: 0.910350]\n",
      "epoch:19 step:18509 [D loss: 0.676274, acc.: 56.25%] [G loss: 0.853771]\n",
      "epoch:19 step:18510 [D loss: 0.654346, acc.: 58.59%] [G loss: 0.871681]\n",
      "epoch:19 step:18511 [D loss: 0.640371, acc.: 61.72%] [G loss: 0.947776]\n",
      "epoch:19 step:18512 [D loss: 0.704717, acc.: 56.25%] [G loss: 0.938156]\n",
      "epoch:19 step:18513 [D loss: 0.651457, acc.: 59.38%] [G loss: 0.881798]\n",
      "epoch:19 step:18514 [D loss: 0.636764, acc.: 60.94%] [G loss: 0.861789]\n",
      "epoch:19 step:18515 [D loss: 0.655397, acc.: 60.16%] [G loss: 0.848182]\n",
      "epoch:19 step:18516 [D loss: 0.681520, acc.: 55.47%] [G loss: 0.878123]\n",
      "epoch:19 step:18517 [D loss: 0.677071, acc.: 56.25%] [G loss: 0.848772]\n",
      "epoch:19 step:18518 [D loss: 0.668791, acc.: 58.59%] [G loss: 0.826339]\n",
      "epoch:19 step:18519 [D loss: 0.665536, acc.: 65.62%] [G loss: 0.843821]\n",
      "epoch:19 step:18520 [D loss: 0.634387, acc.: 65.62%] [G loss: 0.833465]\n",
      "epoch:19 step:18521 [D loss: 0.667214, acc.: 60.16%] [G loss: 0.911858]\n",
      "epoch:19 step:18522 [D loss: 0.661911, acc.: 56.25%] [G loss: 0.909169]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18523 [D loss: 0.630259, acc.: 65.62%] [G loss: 0.873368]\n",
      "epoch:19 step:18524 [D loss: 0.701519, acc.: 54.69%] [G loss: 0.850735]\n",
      "epoch:19 step:18525 [D loss: 0.637348, acc.: 62.50%] [G loss: 0.860558]\n",
      "epoch:19 step:18526 [D loss: 0.658143, acc.: 56.25%] [G loss: 0.853450]\n",
      "epoch:19 step:18527 [D loss: 0.683044, acc.: 58.59%] [G loss: 0.848321]\n",
      "epoch:19 step:18528 [D loss: 0.670017, acc.: 57.03%] [G loss: 0.856713]\n",
      "epoch:19 step:18529 [D loss: 0.655946, acc.: 61.72%] [G loss: 0.862007]\n",
      "epoch:19 step:18530 [D loss: 0.655031, acc.: 57.03%] [G loss: 0.872339]\n",
      "epoch:19 step:18531 [D loss: 0.634049, acc.: 65.62%] [G loss: 0.876086]\n",
      "epoch:19 step:18532 [D loss: 0.648264, acc.: 67.19%] [G loss: 0.864447]\n",
      "epoch:19 step:18533 [D loss: 0.685605, acc.: 48.44%] [G loss: 0.867724]\n",
      "epoch:19 step:18534 [D loss: 0.655715, acc.: 64.84%] [G loss: 0.846085]\n",
      "epoch:19 step:18535 [D loss: 0.660192, acc.: 65.62%] [G loss: 0.860408]\n",
      "epoch:19 step:18536 [D loss: 0.689563, acc.: 60.94%] [G loss: 0.848093]\n",
      "epoch:19 step:18537 [D loss: 0.644081, acc.: 64.06%] [G loss: 0.850657]\n",
      "epoch:19 step:18538 [D loss: 0.649712, acc.: 64.84%] [G loss: 0.892759]\n",
      "epoch:19 step:18539 [D loss: 0.619958, acc.: 64.84%] [G loss: 0.892615]\n",
      "epoch:19 step:18540 [D loss: 0.658686, acc.: 60.16%] [G loss: 0.882853]\n",
      "epoch:19 step:18541 [D loss: 0.687764, acc.: 55.47%] [G loss: 0.902133]\n",
      "epoch:19 step:18542 [D loss: 0.621395, acc.: 64.06%] [G loss: 0.852880]\n",
      "epoch:19 step:18543 [D loss: 0.673640, acc.: 59.38%] [G loss: 0.843817]\n",
      "epoch:19 step:18544 [D loss: 0.682166, acc.: 59.38%] [G loss: 0.848136]\n",
      "epoch:19 step:18545 [D loss: 0.709871, acc.: 56.25%] [G loss: 0.829286]\n",
      "epoch:19 step:18546 [D loss: 0.698686, acc.: 51.56%] [G loss: 0.843882]\n",
      "epoch:19 step:18547 [D loss: 0.699617, acc.: 52.34%] [G loss: 0.907387]\n",
      "epoch:19 step:18548 [D loss: 0.640003, acc.: 66.41%] [G loss: 0.916003]\n",
      "epoch:19 step:18549 [D loss: 0.652824, acc.: 64.84%] [G loss: 0.933871]\n",
      "epoch:19 step:18550 [D loss: 0.642346, acc.: 64.84%] [G loss: 0.892074]\n",
      "epoch:19 step:18551 [D loss: 0.648649, acc.: 66.41%] [G loss: 0.893419]\n",
      "epoch:19 step:18552 [D loss: 0.701956, acc.: 55.47%] [G loss: 0.897356]\n",
      "epoch:19 step:18553 [D loss: 0.666901, acc.: 57.81%] [G loss: 0.835056]\n",
      "epoch:19 step:18554 [D loss: 0.640867, acc.: 60.16%] [G loss: 0.885048]\n",
      "epoch:19 step:18555 [D loss: 0.660605, acc.: 57.03%] [G loss: 0.841479]\n",
      "epoch:19 step:18556 [D loss: 0.653099, acc.: 58.59%] [G loss: 0.896461]\n",
      "epoch:19 step:18557 [D loss: 0.674475, acc.: 57.81%] [G loss: 0.919910]\n",
      "epoch:19 step:18558 [D loss: 0.664605, acc.: 61.72%] [G loss: 0.857050]\n",
      "epoch:19 step:18559 [D loss: 0.661993, acc.: 57.03%] [G loss: 0.851828]\n",
      "epoch:19 step:18560 [D loss: 0.675653, acc.: 57.81%] [G loss: 0.867479]\n",
      "epoch:19 step:18561 [D loss: 0.674375, acc.: 53.91%] [G loss: 0.863220]\n",
      "epoch:19 step:18562 [D loss: 0.646580, acc.: 64.84%] [G loss: 0.826159]\n",
      "epoch:19 step:18563 [D loss: 0.654639, acc.: 59.38%] [G loss: 0.867354]\n",
      "epoch:19 step:18564 [D loss: 0.678616, acc.: 57.03%] [G loss: 0.839276]\n",
      "epoch:19 step:18565 [D loss: 0.672310, acc.: 61.72%] [G loss: 0.866561]\n",
      "epoch:19 step:18566 [D loss: 0.640314, acc.: 59.38%] [G loss: 0.855643]\n",
      "epoch:19 step:18567 [D loss: 0.648936, acc.: 64.84%] [G loss: 0.869427]\n",
      "epoch:19 step:18568 [D loss: 0.665582, acc.: 57.03%] [G loss: 0.864731]\n",
      "epoch:19 step:18569 [D loss: 0.666000, acc.: 55.47%] [G loss: 0.869541]\n",
      "epoch:19 step:18570 [D loss: 0.675596, acc.: 55.47%] [G loss: 0.912398]\n",
      "epoch:19 step:18571 [D loss: 0.630871, acc.: 66.41%] [G loss: 0.882500]\n",
      "epoch:19 step:18572 [D loss: 0.638080, acc.: 69.53%] [G loss: 0.908042]\n",
      "epoch:19 step:18573 [D loss: 0.658063, acc.: 58.59%] [G loss: 0.903109]\n",
      "epoch:19 step:18574 [D loss: 0.659780, acc.: 64.84%] [G loss: 0.845093]\n",
      "epoch:19 step:18575 [D loss: 0.677901, acc.: 59.38%] [G loss: 0.896399]\n",
      "epoch:19 step:18576 [D loss: 0.670256, acc.: 63.28%] [G loss: 0.866000]\n",
      "epoch:19 step:18577 [D loss: 0.624547, acc.: 67.97%] [G loss: 0.912984]\n",
      "epoch:19 step:18578 [D loss: 0.640154, acc.: 57.81%] [G loss: 0.868269]\n",
      "epoch:19 step:18579 [D loss: 0.666271, acc.: 57.03%] [G loss: 0.919087]\n",
      "epoch:19 step:18580 [D loss: 0.673825, acc.: 59.38%] [G loss: 0.870696]\n",
      "epoch:19 step:18581 [D loss: 0.642426, acc.: 61.72%] [G loss: 0.900514]\n",
      "epoch:19 step:18582 [D loss: 0.679516, acc.: 55.47%] [G loss: 0.942964]\n",
      "epoch:19 step:18583 [D loss: 0.668410, acc.: 60.94%] [G loss: 0.915725]\n",
      "epoch:19 step:18584 [D loss: 0.689885, acc.: 59.38%] [G loss: 0.874278]\n",
      "epoch:19 step:18585 [D loss: 0.676786, acc.: 57.81%] [G loss: 0.858931]\n",
      "epoch:19 step:18586 [D loss: 0.635523, acc.: 64.06%] [G loss: 0.885587]\n",
      "epoch:19 step:18587 [D loss: 0.675407, acc.: 53.91%] [G loss: 0.905956]\n",
      "epoch:19 step:18588 [D loss: 0.703183, acc.: 53.12%] [G loss: 0.886439]\n",
      "epoch:19 step:18589 [D loss: 0.667169, acc.: 56.25%] [G loss: 0.910966]\n",
      "epoch:19 step:18590 [D loss: 0.650898, acc.: 53.91%] [G loss: 0.824167]\n",
      "epoch:19 step:18591 [D loss: 0.649427, acc.: 65.62%] [G loss: 0.884605]\n",
      "epoch:19 step:18592 [D loss: 0.649534, acc.: 60.16%] [G loss: 0.877010]\n",
      "epoch:19 step:18593 [D loss: 0.670236, acc.: 56.25%] [G loss: 0.881565]\n",
      "epoch:19 step:18594 [D loss: 0.633596, acc.: 66.41%] [G loss: 0.889292]\n",
      "epoch:19 step:18595 [D loss: 0.675227, acc.: 53.12%] [G loss: 0.895559]\n",
      "epoch:19 step:18596 [D loss: 0.656087, acc.: 55.47%] [G loss: 0.919953]\n",
      "epoch:19 step:18597 [D loss: 0.644497, acc.: 67.19%] [G loss: 0.895770]\n",
      "epoch:19 step:18598 [D loss: 0.647690, acc.: 63.28%] [G loss: 0.884169]\n",
      "epoch:19 step:18599 [D loss: 0.639683, acc.: 63.28%] [G loss: 0.826605]\n",
      "epoch:19 step:18600 [D loss: 0.687294, acc.: 53.12%] [G loss: 0.892270]\n",
      "##############\n",
      "[3.06331867 2.68753809 2.0765882  3.96630982 1.38093903 7.42015308\n",
      " 2.74476561 3.52890059 4.24061705 8.14868929]\n",
      "##########\n",
      "epoch:19 step:18601 [D loss: 0.662181, acc.: 59.38%] [G loss: 0.872082]\n",
      "epoch:19 step:18602 [D loss: 0.672484, acc.: 60.16%] [G loss: 0.856432]\n",
      "epoch:19 step:18603 [D loss: 0.633170, acc.: 68.75%] [G loss: 0.888053]\n",
      "epoch:19 step:18604 [D loss: 0.614241, acc.: 68.75%] [G loss: 0.927988]\n",
      "epoch:19 step:18605 [D loss: 0.671019, acc.: 57.81%] [G loss: 0.880663]\n",
      "epoch:19 step:18606 [D loss: 0.703281, acc.: 53.12%] [G loss: 0.836477]\n",
      "epoch:19 step:18607 [D loss: 0.664982, acc.: 60.94%] [G loss: 0.866063]\n",
      "epoch:19 step:18608 [D loss: 0.666269, acc.: 51.56%] [G loss: 0.899850]\n",
      "epoch:19 step:18609 [D loss: 0.640828, acc.: 64.06%] [G loss: 0.837942]\n",
      "epoch:19 step:18610 [D loss: 0.676252, acc.: 56.25%] [G loss: 0.895475]\n",
      "epoch:19 step:18611 [D loss: 0.651598, acc.: 61.72%] [G loss: 0.881092]\n",
      "epoch:19 step:18612 [D loss: 0.670741, acc.: 57.81%] [G loss: 0.861574]\n",
      "epoch:19 step:18613 [D loss: 0.644776, acc.: 61.72%] [G loss: 0.897936]\n",
      "epoch:19 step:18614 [D loss: 0.663653, acc.: 59.38%] [G loss: 0.805516]\n",
      "epoch:19 step:18615 [D loss: 0.672760, acc.: 53.91%] [G loss: 0.856764]\n",
      "epoch:19 step:18616 [D loss: 0.633675, acc.: 62.50%] [G loss: 0.833569]\n",
      "epoch:19 step:18617 [D loss: 0.625777, acc.: 63.28%] [G loss: 0.966652]\n",
      "epoch:19 step:18618 [D loss: 0.682826, acc.: 52.34%] [G loss: 0.913305]\n",
      "epoch:19 step:18619 [D loss: 0.671439, acc.: 58.59%] [G loss: 0.843101]\n",
      "epoch:19 step:18620 [D loss: 0.684028, acc.: 64.06%] [G loss: 0.905655]\n",
      "epoch:19 step:18621 [D loss: 0.655924, acc.: 60.16%] [G loss: 0.882757]\n",
      "epoch:19 step:18622 [D loss: 0.668110, acc.: 59.38%] [G loss: 0.884149]\n",
      "epoch:19 step:18623 [D loss: 0.666035, acc.: 51.56%] [G loss: 0.845993]\n",
      "epoch:19 step:18624 [D loss: 0.663292, acc.: 62.50%] [G loss: 0.834885]\n",
      "epoch:19 step:18625 [D loss: 0.657320, acc.: 64.06%] [G loss: 0.880891]\n",
      "epoch:19 step:18626 [D loss: 0.694377, acc.: 51.56%] [G loss: 0.882238]\n",
      "epoch:19 step:18627 [D loss: 0.644697, acc.: 64.84%] [G loss: 0.882637]\n",
      "epoch:19 step:18628 [D loss: 0.658636, acc.: 62.50%] [G loss: 0.867093]\n",
      "epoch:19 step:18629 [D loss: 0.641955, acc.: 64.06%] [G loss: 0.845033]\n",
      "epoch:19 step:18630 [D loss: 0.670221, acc.: 59.38%] [G loss: 0.915865]\n",
      "epoch:19 step:18631 [D loss: 0.676831, acc.: 57.03%] [G loss: 0.884816]\n",
      "epoch:19 step:18632 [D loss: 0.647788, acc.: 60.16%] [G loss: 0.835862]\n",
      "epoch:19 step:18633 [D loss: 0.653344, acc.: 62.50%] [G loss: 0.872888]\n",
      "epoch:19 step:18634 [D loss: 0.676766, acc.: 60.94%] [G loss: 0.897106]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:19 step:18635 [D loss: 0.660341, acc.: 54.69%] [G loss: 0.846796]\n",
      "epoch:19 step:18636 [D loss: 0.638311, acc.: 62.50%] [G loss: 0.798745]\n",
      "epoch:19 step:18637 [D loss: 0.661907, acc.: 60.16%] [G loss: 0.890044]\n",
      "epoch:19 step:18638 [D loss: 0.687757, acc.: 54.69%] [G loss: 0.899120]\n",
      "epoch:19 step:18639 [D loss: 0.681804, acc.: 59.38%] [G loss: 0.866589]\n",
      "epoch:19 step:18640 [D loss: 0.693343, acc.: 50.78%] [G loss: 0.860766]\n",
      "epoch:19 step:18641 [D loss: 0.680368, acc.: 52.34%] [G loss: 0.870656]\n",
      "epoch:19 step:18642 [D loss: 0.654285, acc.: 58.59%] [G loss: 0.881783]\n",
      "epoch:19 step:18643 [D loss: 0.659908, acc.: 60.94%] [G loss: 0.848751]\n",
      "epoch:19 step:18644 [D loss: 0.654682, acc.: 54.69%] [G loss: 0.891283]\n",
      "epoch:19 step:18645 [D loss: 0.676324, acc.: 56.25%] [G loss: 0.875255]\n",
      "epoch:19 step:18646 [D loss: 0.714953, acc.: 53.91%] [G loss: 0.827009]\n",
      "epoch:19 step:18647 [D loss: 0.648930, acc.: 62.50%] [G loss: 0.846331]\n",
      "epoch:19 step:18648 [D loss: 0.669350, acc.: 57.81%] [G loss: 0.881007]\n",
      "epoch:19 step:18649 [D loss: 0.638730, acc.: 62.50%] [G loss: 0.886851]\n",
      "epoch:19 step:18650 [D loss: 0.665424, acc.: 61.72%] [G loss: 0.887395]\n",
      "epoch:19 step:18651 [D loss: 0.689065, acc.: 57.03%] [G loss: 0.946189]\n",
      "epoch:19 step:18652 [D loss: 0.660502, acc.: 54.69%] [G loss: 0.881311]\n",
      "epoch:19 step:18653 [D loss: 0.680383, acc.: 54.69%] [G loss: 0.882553]\n",
      "epoch:19 step:18654 [D loss: 0.668158, acc.: 57.03%] [G loss: 0.882189]\n",
      "epoch:19 step:18655 [D loss: 0.652843, acc.: 59.38%] [G loss: 0.883823]\n",
      "epoch:19 step:18656 [D loss: 0.666454, acc.: 57.81%] [G loss: 0.902880]\n",
      "epoch:19 step:18657 [D loss: 0.622366, acc.: 67.97%] [G loss: 0.882553]\n",
      "epoch:19 step:18658 [D loss: 0.673867, acc.: 56.25%] [G loss: 0.852422]\n",
      "epoch:19 step:18659 [D loss: 0.627741, acc.: 71.09%] [G loss: 0.879212]\n",
      "epoch:19 step:18660 [D loss: 0.665032, acc.: 58.59%] [G loss: 0.863585]\n",
      "epoch:19 step:18661 [D loss: 0.651692, acc.: 62.50%] [G loss: 0.919656]\n",
      "epoch:19 step:18662 [D loss: 0.691442, acc.: 51.56%] [G loss: 0.891624]\n",
      "epoch:19 step:18663 [D loss: 0.683888, acc.: 60.16%] [G loss: 0.785151]\n",
      "epoch:19 step:18664 [D loss: 0.655876, acc.: 60.16%] [G loss: 0.839889]\n",
      "epoch:19 step:18665 [D loss: 0.636591, acc.: 60.16%] [G loss: 0.886874]\n",
      "epoch:19 step:18666 [D loss: 0.670485, acc.: 62.50%] [G loss: 0.882498]\n",
      "epoch:19 step:18667 [D loss: 0.683642, acc.: 56.25%] [G loss: 0.899159]\n",
      "epoch:19 step:18668 [D loss: 0.658546, acc.: 57.03%] [G loss: 0.907807]\n",
      "epoch:19 step:18669 [D loss: 0.667377, acc.: 55.47%] [G loss: 0.852276]\n",
      "epoch:19 step:18670 [D loss: 0.709476, acc.: 50.00%] [G loss: 0.858015]\n",
      "epoch:19 step:18671 [D loss: 0.669537, acc.: 61.72%] [G loss: 0.872267]\n",
      "epoch:19 step:18672 [D loss: 0.648166, acc.: 60.94%] [G loss: 0.825738]\n",
      "epoch:19 step:18673 [D loss: 0.645876, acc.: 63.28%] [G loss: 0.866275]\n",
      "epoch:19 step:18674 [D loss: 0.653361, acc.: 57.03%] [G loss: 0.903081]\n",
      "epoch:19 step:18675 [D loss: 0.662097, acc.: 63.28%] [G loss: 0.894322]\n",
      "epoch:19 step:18676 [D loss: 0.643058, acc.: 61.72%] [G loss: 0.834987]\n",
      "epoch:19 step:18677 [D loss: 0.651048, acc.: 58.59%] [G loss: 0.856179]\n",
      "epoch:19 step:18678 [D loss: 0.652140, acc.: 60.94%] [G loss: 0.934994]\n",
      "epoch:19 step:18679 [D loss: 0.661982, acc.: 55.47%] [G loss: 0.968621]\n",
      "epoch:19 step:18680 [D loss: 0.653682, acc.: 56.25%] [G loss: 0.906416]\n",
      "epoch:19 step:18681 [D loss: 0.671131, acc.: 57.81%] [G loss: 0.924888]\n",
      "epoch:19 step:18682 [D loss: 0.677044, acc.: 54.69%] [G loss: 0.910473]\n",
      "epoch:19 step:18683 [D loss: 0.647035, acc.: 60.94%] [G loss: 0.868131]\n",
      "epoch:19 step:18684 [D loss: 0.702653, acc.: 52.34%] [G loss: 0.838445]\n",
      "epoch:19 step:18685 [D loss: 0.656550, acc.: 60.16%] [G loss: 0.852956]\n",
      "epoch:19 step:18686 [D loss: 0.631947, acc.: 66.41%] [G loss: 0.849348]\n",
      "epoch:19 step:18687 [D loss: 0.629032, acc.: 60.94%] [G loss: 0.833573]\n",
      "epoch:19 step:18688 [D loss: 0.692500, acc.: 53.91%] [G loss: 0.843263]\n",
      "epoch:19 step:18689 [D loss: 0.653254, acc.: 62.50%] [G loss: 0.887006]\n",
      "epoch:19 step:18690 [D loss: 0.623075, acc.: 64.84%] [G loss: 0.893944]\n",
      "epoch:19 step:18691 [D loss: 0.610738, acc.: 74.22%] [G loss: 0.869259]\n",
      "epoch:19 step:18692 [D loss: 0.667461, acc.: 64.06%] [G loss: 0.913661]\n",
      "epoch:19 step:18693 [D loss: 0.656222, acc.: 61.72%] [G loss: 0.882000]\n",
      "epoch:19 step:18694 [D loss: 0.701308, acc.: 55.47%] [G loss: 0.933439]\n",
      "epoch:19 step:18695 [D loss: 0.670866, acc.: 57.03%] [G loss: 0.932231]\n",
      "epoch:19 step:18696 [D loss: 0.656510, acc.: 63.28%] [G loss: 0.867257]\n",
      "epoch:19 step:18697 [D loss: 0.691889, acc.: 51.56%] [G loss: 0.839025]\n",
      "epoch:19 step:18698 [D loss: 0.621544, acc.: 73.44%] [G loss: 0.875909]\n",
      "epoch:19 step:18699 [D loss: 0.641155, acc.: 64.84%] [G loss: 0.858778]\n",
      "epoch:19 step:18700 [D loss: 0.670361, acc.: 59.38%] [G loss: 0.883409]\n",
      "epoch:19 step:18701 [D loss: 0.687123, acc.: 53.12%] [G loss: 0.876756]\n",
      "epoch:19 step:18702 [D loss: 0.667882, acc.: 58.59%] [G loss: 0.887267]\n",
      "epoch:19 step:18703 [D loss: 0.684598, acc.: 54.69%] [G loss: 0.916485]\n",
      "epoch:19 step:18704 [D loss: 0.679610, acc.: 54.69%] [G loss: 0.913149]\n",
      "epoch:19 step:18705 [D loss: 0.627863, acc.: 62.50%] [G loss: 0.875732]\n",
      "epoch:19 step:18706 [D loss: 0.653134, acc.: 62.50%] [G loss: 0.870020]\n",
      "epoch:19 step:18707 [D loss: 0.631418, acc.: 66.41%] [G loss: 0.915321]\n",
      "epoch:19 step:18708 [D loss: 0.673811, acc.: 58.59%] [G loss: 0.829320]\n",
      "epoch:19 step:18709 [D loss: 0.636633, acc.: 65.62%] [G loss: 0.904483]\n",
      "epoch:19 step:18710 [D loss: 0.675427, acc.: 54.69%] [G loss: 0.842882]\n",
      "epoch:19 step:18711 [D loss: 0.692523, acc.: 54.69%] [G loss: 0.848769]\n",
      "epoch:19 step:18712 [D loss: 0.692185, acc.: 56.25%] [G loss: 0.871383]\n",
      "epoch:19 step:18713 [D loss: 0.717507, acc.: 46.09%] [G loss: 0.849251]\n",
      "epoch:19 step:18714 [D loss: 0.666231, acc.: 56.25%] [G loss: 0.892251]\n",
      "epoch:19 step:18715 [D loss: 0.678037, acc.: 59.38%] [G loss: 0.870137]\n",
      "epoch:19 step:18716 [D loss: 0.685371, acc.: 55.47%] [G loss: 0.820814]\n",
      "epoch:19 step:18717 [D loss: 0.657210, acc.: 60.16%] [G loss: 0.855761]\n",
      "epoch:19 step:18718 [D loss: 0.707096, acc.: 50.78%] [G loss: 0.855249]\n",
      "epoch:19 step:18719 [D loss: 0.664049, acc.: 65.62%] [G loss: 0.869505]\n",
      "epoch:19 step:18720 [D loss: 0.614282, acc.: 66.41%] [G loss: 0.862813]\n",
      "epoch:19 step:18721 [D loss: 0.676729, acc.: 57.03%] [G loss: 0.819531]\n",
      "epoch:19 step:18722 [D loss: 0.687604, acc.: 57.03%] [G loss: 0.847295]\n",
      "epoch:19 step:18723 [D loss: 0.642575, acc.: 64.84%] [G loss: 0.860378]\n",
      "epoch:19 step:18724 [D loss: 0.695590, acc.: 57.03%] [G loss: 0.818203]\n",
      "epoch:19 step:18725 [D loss: 0.674597, acc.: 53.91%] [G loss: 0.845971]\n",
      "epoch:19 step:18726 [D loss: 0.671649, acc.: 57.81%] [G loss: 0.868056]\n",
      "epoch:19 step:18727 [D loss: 0.649842, acc.: 63.28%] [G loss: 0.891863]\n",
      "epoch:19 step:18728 [D loss: 0.662938, acc.: 60.94%] [G loss: 0.913314]\n",
      "epoch:19 step:18729 [D loss: 0.634406, acc.: 68.75%] [G loss: 0.898152]\n",
      "epoch:19 step:18730 [D loss: 0.677010, acc.: 52.34%] [G loss: 0.850276]\n",
      "epoch:19 step:18731 [D loss: 0.629704, acc.: 63.28%] [G loss: 0.870206]\n",
      "epoch:19 step:18732 [D loss: 0.638003, acc.: 59.38%] [G loss: 0.847704]\n",
      "epoch:19 step:18733 [D loss: 0.640535, acc.: 65.62%] [G loss: 0.894961]\n",
      "epoch:19 step:18734 [D loss: 0.654537, acc.: 60.94%] [G loss: 0.868869]\n",
      "epoch:19 step:18735 [D loss: 0.606730, acc.: 69.53%] [G loss: 0.878083]\n",
      "epoch:19 step:18736 [D loss: 0.632997, acc.: 62.50%] [G loss: 0.856421]\n",
      "epoch:19 step:18737 [D loss: 0.611939, acc.: 67.97%] [G loss: 0.884041]\n",
      "epoch:19 step:18738 [D loss: 0.692168, acc.: 55.47%] [G loss: 0.875655]\n",
      "epoch:19 step:18739 [D loss: 0.637662, acc.: 61.72%] [G loss: 0.824347]\n",
      "epoch:19 step:18740 [D loss: 0.657858, acc.: 57.03%] [G loss: 0.920047]\n",
      "epoch:20 step:18741 [D loss: 0.653608, acc.: 63.28%] [G loss: 0.873076]\n",
      "epoch:20 step:18742 [D loss: 0.625296, acc.: 64.06%] [G loss: 0.888928]\n",
      "epoch:20 step:18743 [D loss: 0.654275, acc.: 60.94%] [G loss: 0.842716]\n",
      "epoch:20 step:18744 [D loss: 0.625754, acc.: 60.16%] [G loss: 0.847621]\n",
      "epoch:20 step:18745 [D loss: 0.667921, acc.: 53.12%] [G loss: 0.823869]\n",
      "epoch:20 step:18746 [D loss: 0.688056, acc.: 51.56%] [G loss: 0.873046]\n",
      "epoch:20 step:18747 [D loss: 0.684805, acc.: 60.16%] [G loss: 0.845020]\n",
      "epoch:20 step:18748 [D loss: 0.652177, acc.: 63.28%] [G loss: 0.882075]\n",
      "epoch:20 step:18749 [D loss: 0.708879, acc.: 56.25%] [G loss: 0.877433]\n",
      "epoch:20 step:18750 [D loss: 0.630412, acc.: 64.84%] [G loss: 0.848875]\n",
      "epoch:20 step:18751 [D loss: 0.599217, acc.: 67.97%] [G loss: 0.898404]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:18752 [D loss: 0.673440, acc.: 56.25%] [G loss: 0.903152]\n",
      "epoch:20 step:18753 [D loss: 0.668402, acc.: 57.81%] [G loss: 0.880039]\n",
      "epoch:20 step:18754 [D loss: 0.674367, acc.: 59.38%] [G loss: 0.915079]\n",
      "epoch:20 step:18755 [D loss: 0.653653, acc.: 57.81%] [G loss: 0.917364]\n",
      "epoch:20 step:18756 [D loss: 0.623199, acc.: 66.41%] [G loss: 0.899530]\n",
      "epoch:20 step:18757 [D loss: 0.633418, acc.: 66.41%] [G loss: 0.844225]\n",
      "epoch:20 step:18758 [D loss: 0.680196, acc.: 56.25%] [G loss: 0.873809]\n",
      "epoch:20 step:18759 [D loss: 0.669219, acc.: 57.03%] [G loss: 0.847754]\n",
      "epoch:20 step:18760 [D loss: 0.660350, acc.: 60.94%] [G loss: 0.837626]\n",
      "epoch:20 step:18761 [D loss: 0.662349, acc.: 59.38%] [G loss: 0.868710]\n",
      "epoch:20 step:18762 [D loss: 0.665864, acc.: 56.25%] [G loss: 0.847291]\n",
      "epoch:20 step:18763 [D loss: 0.680453, acc.: 52.34%] [G loss: 0.848283]\n",
      "epoch:20 step:18764 [D loss: 0.663586, acc.: 67.19%] [G loss: 0.901035]\n",
      "epoch:20 step:18765 [D loss: 0.633286, acc.: 67.19%] [G loss: 0.882564]\n",
      "epoch:20 step:18766 [D loss: 0.646334, acc.: 60.16%] [G loss: 0.870990]\n",
      "epoch:20 step:18767 [D loss: 0.632865, acc.: 66.41%] [G loss: 0.939210]\n",
      "epoch:20 step:18768 [D loss: 0.628023, acc.: 64.06%] [G loss: 0.881762]\n",
      "epoch:20 step:18769 [D loss: 0.683108, acc.: 53.12%] [G loss: 0.929090]\n",
      "epoch:20 step:18770 [D loss: 0.663799, acc.: 60.94%] [G loss: 0.915733]\n",
      "epoch:20 step:18771 [D loss: 0.670920, acc.: 57.81%] [G loss: 0.928907]\n",
      "epoch:20 step:18772 [D loss: 0.706277, acc.: 53.12%] [G loss: 0.873239]\n",
      "epoch:20 step:18773 [D loss: 0.651308, acc.: 59.38%] [G loss: 0.875727]\n",
      "epoch:20 step:18774 [D loss: 0.697169, acc.: 46.09%] [G loss: 0.907620]\n",
      "epoch:20 step:18775 [D loss: 0.682823, acc.: 56.25%] [G loss: 0.856582]\n",
      "epoch:20 step:18776 [D loss: 0.662898, acc.: 58.59%] [G loss: 0.815706]\n",
      "epoch:20 step:18777 [D loss: 0.630455, acc.: 61.72%] [G loss: 0.853949]\n",
      "epoch:20 step:18778 [D loss: 0.708739, acc.: 53.12%] [G loss: 0.864013]\n",
      "epoch:20 step:18779 [D loss: 0.651927, acc.: 63.28%] [G loss: 0.864060]\n",
      "epoch:20 step:18780 [D loss: 0.680381, acc.: 53.91%] [G loss: 0.908481]\n",
      "epoch:20 step:18781 [D loss: 0.702854, acc.: 52.34%] [G loss: 0.872195]\n",
      "epoch:20 step:18782 [D loss: 0.660366, acc.: 58.59%] [G loss: 0.894341]\n",
      "epoch:20 step:18783 [D loss: 0.657369, acc.: 64.06%] [G loss: 0.910106]\n",
      "epoch:20 step:18784 [D loss: 0.645997, acc.: 59.38%] [G loss: 0.868312]\n",
      "epoch:20 step:18785 [D loss: 0.673249, acc.: 57.81%] [G loss: 0.866882]\n",
      "epoch:20 step:18786 [D loss: 0.662265, acc.: 61.72%] [G loss: 0.865563]\n",
      "epoch:20 step:18787 [D loss: 0.680591, acc.: 57.03%] [G loss: 0.854720]\n",
      "epoch:20 step:18788 [D loss: 0.677011, acc.: 57.03%] [G loss: 0.849360]\n",
      "epoch:20 step:18789 [D loss: 0.662802, acc.: 62.50%] [G loss: 0.906270]\n",
      "epoch:20 step:18790 [D loss: 0.659127, acc.: 65.62%] [G loss: 0.916906]\n",
      "epoch:20 step:18791 [D loss: 0.640424, acc.: 64.84%] [G loss: 0.906493]\n",
      "epoch:20 step:18792 [D loss: 0.630631, acc.: 63.28%] [G loss: 0.865449]\n",
      "epoch:20 step:18793 [D loss: 0.646362, acc.: 63.28%] [G loss: 0.839548]\n",
      "epoch:20 step:18794 [D loss: 0.672465, acc.: 57.03%] [G loss: 0.851003]\n",
      "epoch:20 step:18795 [D loss: 0.658807, acc.: 61.72%] [G loss: 0.902300]\n",
      "epoch:20 step:18796 [D loss: 0.653386, acc.: 57.03%] [G loss: 0.880898]\n",
      "epoch:20 step:18797 [D loss: 0.655595, acc.: 58.59%] [G loss: 0.839213]\n",
      "epoch:20 step:18798 [D loss: 0.663389, acc.: 59.38%] [G loss: 0.870486]\n",
      "epoch:20 step:18799 [D loss: 0.607259, acc.: 73.44%] [G loss: 0.888949]\n",
      "epoch:20 step:18800 [D loss: 0.657468, acc.: 58.59%] [G loss: 0.909209]\n",
      "##############\n",
      "[3.0918801  2.41311862 2.36471688 4.51423338 1.37180608 7.61381276\n",
      " 2.59070902 3.85533818 4.43292099 8.14868929]\n",
      "##########\n",
      "epoch:20 step:18801 [D loss: 0.667954, acc.: 54.69%] [G loss: 0.940487]\n",
      "epoch:20 step:18802 [D loss: 0.639350, acc.: 60.94%] [G loss: 0.896332]\n",
      "epoch:20 step:18803 [D loss: 0.666643, acc.: 54.69%] [G loss: 0.821213]\n",
      "epoch:20 step:18804 [D loss: 0.651445, acc.: 57.03%] [G loss: 0.864841]\n",
      "epoch:20 step:18805 [D loss: 0.630710, acc.: 65.62%] [G loss: 0.968847]\n",
      "epoch:20 step:18806 [D loss: 0.678589, acc.: 53.91%] [G loss: 0.909934]\n",
      "epoch:20 step:18807 [D loss: 0.736252, acc.: 50.78%] [G loss: 0.900502]\n",
      "epoch:20 step:18808 [D loss: 0.642563, acc.: 62.50%] [G loss: 0.942020]\n",
      "epoch:20 step:18809 [D loss: 0.651614, acc.: 60.94%] [G loss: 0.952844]\n",
      "epoch:20 step:18810 [D loss: 0.668976, acc.: 54.69%] [G loss: 0.928505]\n",
      "epoch:20 step:18811 [D loss: 0.672227, acc.: 56.25%] [G loss: 0.918599]\n",
      "epoch:20 step:18812 [D loss: 0.662997, acc.: 60.16%] [G loss: 0.880722]\n",
      "epoch:20 step:18813 [D loss: 0.612890, acc.: 71.88%] [G loss: 0.886045]\n",
      "epoch:20 step:18814 [D loss: 0.692609, acc.: 54.69%] [G loss: 0.881112]\n",
      "epoch:20 step:18815 [D loss: 0.650922, acc.: 62.50%] [G loss: 0.814840]\n",
      "epoch:20 step:18816 [D loss: 0.636458, acc.: 62.50%] [G loss: 0.886512]\n",
      "epoch:20 step:18817 [D loss: 0.680021, acc.: 57.03%] [G loss: 0.886891]\n",
      "epoch:20 step:18818 [D loss: 0.676418, acc.: 57.03%] [G loss: 0.871497]\n",
      "epoch:20 step:18819 [D loss: 0.675412, acc.: 56.25%] [G loss: 0.845522]\n",
      "epoch:20 step:18820 [D loss: 0.684054, acc.: 55.47%] [G loss: 0.849898]\n",
      "epoch:20 step:18821 [D loss: 0.687501, acc.: 50.78%] [G loss: 0.831281]\n",
      "epoch:20 step:18822 [D loss: 0.650043, acc.: 61.72%] [G loss: 0.847100]\n",
      "epoch:20 step:18823 [D loss: 0.646063, acc.: 66.41%] [G loss: 0.833064]\n",
      "epoch:20 step:18824 [D loss: 0.696502, acc.: 52.34%] [G loss: 0.912635]\n",
      "epoch:20 step:18825 [D loss: 0.658672, acc.: 59.38%] [G loss: 0.875093]\n",
      "epoch:20 step:18826 [D loss: 0.666073, acc.: 66.41%] [G loss: 0.873332]\n",
      "epoch:20 step:18827 [D loss: 0.662636, acc.: 59.38%] [G loss: 0.911024]\n",
      "epoch:20 step:18828 [D loss: 0.649186, acc.: 66.41%] [G loss: 0.883236]\n",
      "epoch:20 step:18829 [D loss: 0.608071, acc.: 66.41%] [G loss: 0.915153]\n",
      "epoch:20 step:18830 [D loss: 0.657970, acc.: 62.50%] [G loss: 0.942862]\n",
      "epoch:20 step:18831 [D loss: 0.705676, acc.: 51.56%] [G loss: 0.884894]\n",
      "epoch:20 step:18832 [D loss: 0.647340, acc.: 61.72%] [G loss: 0.865487]\n",
      "epoch:20 step:18833 [D loss: 0.684678, acc.: 53.91%] [G loss: 0.843361]\n",
      "epoch:20 step:18834 [D loss: 0.658201, acc.: 57.03%] [G loss: 0.890957]\n",
      "epoch:20 step:18835 [D loss: 0.680789, acc.: 60.16%] [G loss: 0.860061]\n",
      "epoch:20 step:18836 [D loss: 0.675790, acc.: 61.72%] [G loss: 0.875856]\n",
      "epoch:20 step:18837 [D loss: 0.676610, acc.: 57.81%] [G loss: 0.844622]\n",
      "epoch:20 step:18838 [D loss: 0.636765, acc.: 66.41%] [G loss: 0.897047]\n",
      "epoch:20 step:18839 [D loss: 0.649160, acc.: 62.50%] [G loss: 0.897315]\n",
      "epoch:20 step:18840 [D loss: 0.666251, acc.: 59.38%] [G loss: 0.955137]\n",
      "epoch:20 step:18841 [D loss: 0.645465, acc.: 59.38%] [G loss: 0.895179]\n",
      "epoch:20 step:18842 [D loss: 0.649937, acc.: 63.28%] [G loss: 0.887846]\n",
      "epoch:20 step:18843 [D loss: 0.664689, acc.: 57.81%] [G loss: 0.881263]\n",
      "epoch:20 step:18844 [D loss: 0.665087, acc.: 58.59%] [G loss: 0.951986]\n",
      "epoch:20 step:18845 [D loss: 0.645156, acc.: 60.94%] [G loss: 0.872652]\n",
      "epoch:20 step:18846 [D loss: 0.662970, acc.: 57.03%] [G loss: 0.864129]\n",
      "epoch:20 step:18847 [D loss: 0.641962, acc.: 61.72%] [G loss: 0.883302]\n",
      "epoch:20 step:18848 [D loss: 0.672290, acc.: 57.03%] [G loss: 0.932001]\n",
      "epoch:20 step:18849 [D loss: 0.642390, acc.: 65.62%] [G loss: 0.921203]\n",
      "epoch:20 step:18850 [D loss: 0.681798, acc.: 56.25%] [G loss: 0.938903]\n",
      "epoch:20 step:18851 [D loss: 0.677309, acc.: 61.72%] [G loss: 0.866903]\n",
      "epoch:20 step:18852 [D loss: 0.669671, acc.: 61.72%] [G loss: 0.881044]\n",
      "epoch:20 step:18853 [D loss: 0.643895, acc.: 62.50%] [G loss: 0.890659]\n",
      "epoch:20 step:18854 [D loss: 0.635849, acc.: 67.97%] [G loss: 0.865772]\n",
      "epoch:20 step:18855 [D loss: 0.691172, acc.: 54.69%] [G loss: 0.883825]\n",
      "epoch:20 step:18856 [D loss: 0.645856, acc.: 65.62%] [G loss: 0.850067]\n",
      "epoch:20 step:18857 [D loss: 0.673453, acc.: 56.25%] [G loss: 0.832454]\n",
      "epoch:20 step:18858 [D loss: 0.675921, acc.: 53.12%] [G loss: 0.849618]\n",
      "epoch:20 step:18859 [D loss: 0.671808, acc.: 56.25%] [G loss: 0.809642]\n",
      "epoch:20 step:18860 [D loss: 0.684472, acc.: 56.25%] [G loss: 0.794879]\n",
      "epoch:20 step:18861 [D loss: 0.624475, acc.: 64.06%] [G loss: 0.869630]\n",
      "epoch:20 step:18862 [D loss: 0.667400, acc.: 56.25%] [G loss: 0.835535]\n",
      "epoch:20 step:18863 [D loss: 0.640428, acc.: 67.97%] [G loss: 0.852133]\n",
      "epoch:20 step:18864 [D loss: 0.652670, acc.: 59.38%] [G loss: 0.878231]\n",
      "epoch:20 step:18865 [D loss: 0.666888, acc.: 59.38%] [G loss: 0.916541]\n",
      "epoch:20 step:18866 [D loss: 0.661469, acc.: 55.47%] [G loss: 0.886062]\n",
      "epoch:20 step:18867 [D loss: 0.632363, acc.: 62.50%] [G loss: 0.942401]\n",
      "epoch:20 step:18868 [D loss: 0.639698, acc.: 59.38%] [G loss: 0.888571]\n",
      "epoch:20 step:18869 [D loss: 0.650302, acc.: 60.16%] [G loss: 0.854499]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:18870 [D loss: 0.616571, acc.: 68.75%] [G loss: 0.917349]\n",
      "epoch:20 step:18871 [D loss: 0.650246, acc.: 67.19%] [G loss: 0.895661]\n",
      "epoch:20 step:18872 [D loss: 0.702794, acc.: 51.56%] [G loss: 0.898407]\n",
      "epoch:20 step:18873 [D loss: 0.695391, acc.: 53.91%] [G loss: 0.898082]\n",
      "epoch:20 step:18874 [D loss: 0.658491, acc.: 53.12%] [G loss: 0.894018]\n",
      "epoch:20 step:18875 [D loss: 0.665789, acc.: 54.69%] [G loss: 0.868083]\n",
      "epoch:20 step:18876 [D loss: 0.677261, acc.: 54.69%] [G loss: 0.871202]\n",
      "epoch:20 step:18877 [D loss: 0.640258, acc.: 63.28%] [G loss: 0.792720]\n",
      "epoch:20 step:18878 [D loss: 0.680624, acc.: 54.69%] [G loss: 0.835001]\n",
      "epoch:20 step:18879 [D loss: 0.693635, acc.: 57.03%] [G loss: 0.877205]\n",
      "epoch:20 step:18880 [D loss: 0.657828, acc.: 60.16%] [G loss: 0.862713]\n",
      "epoch:20 step:18881 [D loss: 0.720469, acc.: 44.53%] [G loss: 0.859456]\n",
      "epoch:20 step:18882 [D loss: 0.614294, acc.: 72.66%] [G loss: 0.855049]\n",
      "epoch:20 step:18883 [D loss: 0.670161, acc.: 55.47%] [G loss: 0.843279]\n",
      "epoch:20 step:18884 [D loss: 0.662351, acc.: 58.59%] [G loss: 0.841352]\n",
      "epoch:20 step:18885 [D loss: 0.667852, acc.: 53.12%] [G loss: 0.819281]\n",
      "epoch:20 step:18886 [D loss: 0.660475, acc.: 60.16%] [G loss: 0.895156]\n",
      "epoch:20 step:18887 [D loss: 0.650889, acc.: 63.28%] [G loss: 0.828044]\n",
      "epoch:20 step:18888 [D loss: 0.644735, acc.: 56.25%] [G loss: 0.865938]\n",
      "epoch:20 step:18889 [D loss: 0.650648, acc.: 56.25%] [G loss: 0.879793]\n",
      "epoch:20 step:18890 [D loss: 0.664420, acc.: 57.81%] [G loss: 0.913291]\n",
      "epoch:20 step:18891 [D loss: 0.650801, acc.: 63.28%] [G loss: 0.861534]\n",
      "epoch:20 step:18892 [D loss: 0.650648, acc.: 64.06%] [G loss: 0.898270]\n",
      "epoch:20 step:18893 [D loss: 0.668377, acc.: 60.16%] [G loss: 0.872355]\n",
      "epoch:20 step:18894 [D loss: 0.667152, acc.: 55.47%] [G loss: 0.858501]\n",
      "epoch:20 step:18895 [D loss: 0.659883, acc.: 57.81%] [G loss: 0.867211]\n",
      "epoch:20 step:18896 [D loss: 0.648689, acc.: 67.97%] [G loss: 0.873859]\n",
      "epoch:20 step:18897 [D loss: 0.675185, acc.: 54.69%] [G loss: 0.855079]\n",
      "epoch:20 step:18898 [D loss: 0.650097, acc.: 64.06%] [G loss: 0.854324]\n",
      "epoch:20 step:18899 [D loss: 0.626041, acc.: 64.06%] [G loss: 0.849908]\n",
      "epoch:20 step:18900 [D loss: 0.674615, acc.: 60.94%] [G loss: 0.890614]\n",
      "epoch:20 step:18901 [D loss: 0.646689, acc.: 58.59%] [G loss: 0.907969]\n",
      "epoch:20 step:18902 [D loss: 0.652583, acc.: 64.06%] [G loss: 0.863795]\n",
      "epoch:20 step:18903 [D loss: 0.651204, acc.: 59.38%] [G loss: 0.859581]\n",
      "epoch:20 step:18904 [D loss: 0.695440, acc.: 54.69%] [G loss: 0.795982]\n",
      "epoch:20 step:18905 [D loss: 0.627793, acc.: 65.62%] [G loss: 0.805007]\n",
      "epoch:20 step:18906 [D loss: 0.651211, acc.: 64.84%] [G loss: 0.848438]\n",
      "epoch:20 step:18907 [D loss: 0.690841, acc.: 57.81%] [G loss: 0.865084]\n",
      "epoch:20 step:18908 [D loss: 0.645863, acc.: 63.28%] [G loss: 0.909150]\n",
      "epoch:20 step:18909 [D loss: 0.666214, acc.: 60.16%] [G loss: 0.865450]\n",
      "epoch:20 step:18910 [D loss: 0.642798, acc.: 62.50%] [G loss: 0.845572]\n",
      "epoch:20 step:18911 [D loss: 0.664038, acc.: 59.38%] [G loss: 0.846587]\n",
      "epoch:20 step:18912 [D loss: 0.644605, acc.: 60.94%] [G loss: 0.870709]\n",
      "epoch:20 step:18913 [D loss: 0.658792, acc.: 64.84%] [G loss: 0.874239]\n",
      "epoch:20 step:18914 [D loss: 0.657998, acc.: 63.28%] [G loss: 0.851893]\n",
      "epoch:20 step:18915 [D loss: 0.687149, acc.: 53.91%] [G loss: 0.868825]\n",
      "epoch:20 step:18916 [D loss: 0.631166, acc.: 64.84%] [G loss: 0.879887]\n",
      "epoch:20 step:18917 [D loss: 0.614281, acc.: 68.75%] [G loss: 0.830288]\n",
      "epoch:20 step:18918 [D loss: 0.642161, acc.: 59.38%] [G loss: 0.906721]\n",
      "epoch:20 step:18919 [D loss: 0.637764, acc.: 67.19%] [G loss: 0.893708]\n",
      "epoch:20 step:18920 [D loss: 0.619425, acc.: 64.06%] [G loss: 0.956009]\n",
      "epoch:20 step:18921 [D loss: 0.652277, acc.: 57.81%] [G loss: 0.938738]\n",
      "epoch:20 step:18922 [D loss: 0.615553, acc.: 70.31%] [G loss: 0.940366]\n",
      "epoch:20 step:18923 [D loss: 0.646583, acc.: 64.06%] [G loss: 0.974127]\n",
      "epoch:20 step:18924 [D loss: 0.704407, acc.: 59.38%] [G loss: 0.876466]\n",
      "epoch:20 step:18925 [D loss: 0.686638, acc.: 56.25%] [G loss: 0.835738]\n",
      "epoch:20 step:18926 [D loss: 0.634113, acc.: 67.19%] [G loss: 0.912486]\n",
      "epoch:20 step:18927 [D loss: 0.670903, acc.: 57.81%] [G loss: 0.908103]\n",
      "epoch:20 step:18928 [D loss: 0.669450, acc.: 60.16%] [G loss: 0.917567]\n",
      "epoch:20 step:18929 [D loss: 0.664182, acc.: 58.59%] [G loss: 0.948361]\n",
      "epoch:20 step:18930 [D loss: 0.666871, acc.: 61.72%] [G loss: 0.873358]\n",
      "epoch:20 step:18931 [D loss: 0.664291, acc.: 59.38%] [G loss: 0.891657]\n",
      "epoch:20 step:18932 [D loss: 0.624365, acc.: 71.09%] [G loss: 0.929101]\n",
      "epoch:20 step:18933 [D loss: 0.637568, acc.: 60.94%] [G loss: 0.907244]\n",
      "epoch:20 step:18934 [D loss: 0.707359, acc.: 57.03%] [G loss: 0.873918]\n",
      "epoch:20 step:18935 [D loss: 0.631881, acc.: 68.75%] [G loss: 0.864857]\n",
      "epoch:20 step:18936 [D loss: 0.644331, acc.: 61.72%] [G loss: 0.913286]\n",
      "epoch:20 step:18937 [D loss: 0.629158, acc.: 65.62%] [G loss: 0.886678]\n",
      "epoch:20 step:18938 [D loss: 0.610899, acc.: 69.53%] [G loss: 0.875278]\n",
      "epoch:20 step:18939 [D loss: 0.628825, acc.: 64.06%] [G loss: 0.855112]\n",
      "epoch:20 step:18940 [D loss: 0.680323, acc.: 56.25%] [G loss: 0.885245]\n",
      "epoch:20 step:18941 [D loss: 0.650028, acc.: 61.72%] [G loss: 0.862285]\n",
      "epoch:20 step:18942 [D loss: 0.647252, acc.: 61.72%] [G loss: 0.926620]\n",
      "epoch:20 step:18943 [D loss: 0.691460, acc.: 57.03%] [G loss: 0.984521]\n",
      "epoch:20 step:18944 [D loss: 0.655533, acc.: 57.81%] [G loss: 0.894008]\n",
      "epoch:20 step:18945 [D loss: 0.672520, acc.: 60.16%] [G loss: 0.929884]\n",
      "epoch:20 step:18946 [D loss: 0.731918, acc.: 55.47%] [G loss: 0.906989]\n",
      "epoch:20 step:18947 [D loss: 0.656337, acc.: 62.50%] [G loss: 0.916241]\n",
      "epoch:20 step:18948 [D loss: 0.637863, acc.: 66.41%] [G loss: 0.848257]\n",
      "epoch:20 step:18949 [D loss: 0.687510, acc.: 54.69%] [G loss: 0.851489]\n",
      "epoch:20 step:18950 [D loss: 0.670454, acc.: 62.50%] [G loss: 0.902952]\n",
      "epoch:20 step:18951 [D loss: 0.659319, acc.: 60.16%] [G loss: 0.900181]\n",
      "epoch:20 step:18952 [D loss: 0.633448, acc.: 64.84%] [G loss: 0.968100]\n",
      "epoch:20 step:18953 [D loss: 0.659088, acc.: 61.72%] [G loss: 0.877814]\n",
      "epoch:20 step:18954 [D loss: 0.650414, acc.: 63.28%] [G loss: 0.927630]\n",
      "epoch:20 step:18955 [D loss: 0.660123, acc.: 60.16%] [G loss: 0.883213]\n",
      "epoch:20 step:18956 [D loss: 0.661847, acc.: 60.16%] [G loss: 0.860901]\n",
      "epoch:20 step:18957 [D loss: 0.648585, acc.: 57.03%] [G loss: 0.923130]\n",
      "epoch:20 step:18958 [D loss: 0.657968, acc.: 57.81%] [G loss: 0.861804]\n",
      "epoch:20 step:18959 [D loss: 0.691497, acc.: 54.69%] [G loss: 0.891104]\n",
      "epoch:20 step:18960 [D loss: 0.676751, acc.: 51.56%] [G loss: 0.885061]\n",
      "epoch:20 step:18961 [D loss: 0.632398, acc.: 61.72%] [G loss: 0.849400]\n",
      "epoch:20 step:18962 [D loss: 0.658632, acc.: 64.84%] [G loss: 0.842914]\n",
      "epoch:20 step:18963 [D loss: 0.647254, acc.: 60.94%] [G loss: 0.882410]\n",
      "epoch:20 step:18964 [D loss: 0.661929, acc.: 56.25%] [G loss: 0.865229]\n",
      "epoch:20 step:18965 [D loss: 0.670613, acc.: 60.16%] [G loss: 0.893515]\n",
      "epoch:20 step:18966 [D loss: 0.646418, acc.: 60.16%] [G loss: 0.865246]\n",
      "epoch:20 step:18967 [D loss: 0.664551, acc.: 57.81%] [G loss: 0.852813]\n",
      "epoch:20 step:18968 [D loss: 0.661363, acc.: 59.38%] [G loss: 0.863907]\n",
      "epoch:20 step:18969 [D loss: 0.679161, acc.: 57.03%] [G loss: 0.903461]\n",
      "epoch:20 step:18970 [D loss: 0.664109, acc.: 54.69%] [G loss: 0.872681]\n",
      "epoch:20 step:18971 [D loss: 0.668146, acc.: 59.38%] [G loss: 0.902908]\n",
      "epoch:20 step:18972 [D loss: 0.664050, acc.: 56.25%] [G loss: 0.892318]\n",
      "epoch:20 step:18973 [D loss: 0.652907, acc.: 55.47%] [G loss: 0.901403]\n",
      "epoch:20 step:18974 [D loss: 0.647873, acc.: 63.28%] [G loss: 0.913948]\n",
      "epoch:20 step:18975 [D loss: 0.652643, acc.: 61.72%] [G loss: 0.873222]\n",
      "epoch:20 step:18976 [D loss: 0.653016, acc.: 57.81%] [G loss: 0.851281]\n",
      "epoch:20 step:18977 [D loss: 0.675619, acc.: 57.03%] [G loss: 0.882792]\n",
      "epoch:20 step:18978 [D loss: 0.687269, acc.: 55.47%] [G loss: 0.893168]\n",
      "epoch:20 step:18979 [D loss: 0.663769, acc.: 57.81%] [G loss: 0.923871]\n",
      "epoch:20 step:18980 [D loss: 0.666649, acc.: 65.62%] [G loss: 0.917209]\n",
      "epoch:20 step:18981 [D loss: 0.638159, acc.: 61.72%] [G loss: 0.952585]\n",
      "epoch:20 step:18982 [D loss: 0.682854, acc.: 60.94%] [G loss: 0.949376]\n",
      "epoch:20 step:18983 [D loss: 0.666157, acc.: 55.47%] [G loss: 0.918580]\n",
      "epoch:20 step:18984 [D loss: 0.665170, acc.: 60.16%] [G loss: 0.848844]\n",
      "epoch:20 step:18985 [D loss: 0.695542, acc.: 49.22%] [G loss: 0.847343]\n",
      "epoch:20 step:18986 [D loss: 0.693009, acc.: 53.91%] [G loss: 0.841591]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:18987 [D loss: 0.675242, acc.: 57.03%] [G loss: 0.861388]\n",
      "epoch:20 step:18988 [D loss: 0.682625, acc.: 53.91%] [G loss: 0.856028]\n",
      "epoch:20 step:18989 [D loss: 0.675433, acc.: 59.38%] [G loss: 0.821216]\n",
      "epoch:20 step:18990 [D loss: 0.661436, acc.: 60.16%] [G loss: 0.871461]\n",
      "epoch:20 step:18991 [D loss: 0.661974, acc.: 61.72%] [G loss: 0.878567]\n",
      "epoch:20 step:18992 [D loss: 0.652861, acc.: 65.62%] [G loss: 0.829126]\n",
      "epoch:20 step:18993 [D loss: 0.684473, acc.: 55.47%] [G loss: 0.847956]\n",
      "epoch:20 step:18994 [D loss: 0.649056, acc.: 61.72%] [G loss: 0.887579]\n",
      "epoch:20 step:18995 [D loss: 0.657499, acc.: 60.94%] [G loss: 0.880484]\n",
      "epoch:20 step:18996 [D loss: 0.663303, acc.: 58.59%] [G loss: 0.884780]\n",
      "epoch:20 step:18997 [D loss: 0.649907, acc.: 62.50%] [G loss: 0.854370]\n",
      "epoch:20 step:18998 [D loss: 0.695281, acc.: 57.03%] [G loss: 0.892597]\n",
      "epoch:20 step:18999 [D loss: 0.654123, acc.: 58.59%] [G loss: 0.886155]\n",
      "epoch:20 step:19000 [D loss: 0.668850, acc.: 60.94%] [G loss: 0.877641]\n",
      "##############\n",
      "[2.94051283 2.04396806 2.29948239 3.89168925 1.45570756 7.19343185\n",
      " 2.70672028 3.7235732  4.11560907 6.43724867]\n",
      "##########\n",
      "epoch:20 step:19001 [D loss: 0.685855, acc.: 59.38%] [G loss: 0.861418]\n",
      "epoch:20 step:19002 [D loss: 0.707115, acc.: 55.47%] [G loss: 0.839233]\n",
      "epoch:20 step:19003 [D loss: 0.643937, acc.: 64.06%] [G loss: 0.902274]\n",
      "epoch:20 step:19004 [D loss: 0.661982, acc.: 59.38%] [G loss: 0.875451]\n",
      "epoch:20 step:19005 [D loss: 0.671782, acc.: 57.03%] [G loss: 0.848585]\n",
      "epoch:20 step:19006 [D loss: 0.675641, acc.: 57.03%] [G loss: 0.923480]\n",
      "epoch:20 step:19007 [D loss: 0.668613, acc.: 57.03%] [G loss: 0.888080]\n",
      "epoch:20 step:19008 [D loss: 0.636325, acc.: 59.38%] [G loss: 0.949760]\n",
      "epoch:20 step:19009 [D loss: 0.651764, acc.: 60.94%] [G loss: 0.863932]\n",
      "epoch:20 step:19010 [D loss: 0.675664, acc.: 54.69%] [G loss: 0.884734]\n",
      "epoch:20 step:19011 [D loss: 0.665063, acc.: 60.16%] [G loss: 0.898129]\n",
      "epoch:20 step:19012 [D loss: 0.650869, acc.: 63.28%] [G loss: 0.883344]\n",
      "epoch:20 step:19013 [D loss: 0.671930, acc.: 59.38%] [G loss: 0.888541]\n",
      "epoch:20 step:19014 [D loss: 0.688032, acc.: 47.66%] [G loss: 0.824826]\n",
      "epoch:20 step:19015 [D loss: 0.671099, acc.: 60.16%] [G loss: 0.902908]\n",
      "epoch:20 step:19016 [D loss: 0.654139, acc.: 63.28%] [G loss: 0.947128]\n",
      "epoch:20 step:19017 [D loss: 0.625210, acc.: 57.03%] [G loss: 0.894723]\n",
      "epoch:20 step:19018 [D loss: 0.662322, acc.: 60.94%] [G loss: 0.855557]\n",
      "epoch:20 step:19019 [D loss: 0.674722, acc.: 60.16%] [G loss: 0.880379]\n",
      "epoch:20 step:19020 [D loss: 0.659059, acc.: 57.03%] [G loss: 0.863775]\n",
      "epoch:20 step:19021 [D loss: 0.647562, acc.: 64.06%] [G loss: 0.814667]\n",
      "epoch:20 step:19022 [D loss: 0.629382, acc.: 67.19%] [G loss: 0.874495]\n",
      "epoch:20 step:19023 [D loss: 0.648199, acc.: 58.59%] [G loss: 0.870134]\n",
      "epoch:20 step:19024 [D loss: 0.625015, acc.: 67.97%] [G loss: 0.896344]\n",
      "epoch:20 step:19025 [D loss: 0.642520, acc.: 61.72%] [G loss: 0.852970]\n",
      "epoch:20 step:19026 [D loss: 0.634177, acc.: 64.84%] [G loss: 0.875554]\n",
      "epoch:20 step:19027 [D loss: 0.640148, acc.: 60.16%] [G loss: 0.893541]\n",
      "epoch:20 step:19028 [D loss: 0.658482, acc.: 61.72%] [G loss: 0.832519]\n",
      "epoch:20 step:19029 [D loss: 0.703152, acc.: 51.56%] [G loss: 0.864591]\n",
      "epoch:20 step:19030 [D loss: 0.628373, acc.: 64.84%] [G loss: 0.852030]\n",
      "epoch:20 step:19031 [D loss: 0.679997, acc.: 57.81%] [G loss: 0.847317]\n",
      "epoch:20 step:19032 [D loss: 0.656114, acc.: 61.72%] [G loss: 0.896606]\n",
      "epoch:20 step:19033 [D loss: 0.659519, acc.: 57.03%] [G loss: 0.819010]\n",
      "epoch:20 step:19034 [D loss: 0.661551, acc.: 56.25%] [G loss: 0.859102]\n",
      "epoch:20 step:19035 [D loss: 0.661149, acc.: 56.25%] [G loss: 0.872182]\n",
      "epoch:20 step:19036 [D loss: 0.689417, acc.: 57.81%] [G loss: 0.866389]\n",
      "epoch:20 step:19037 [D loss: 0.630033, acc.: 69.53%] [G loss: 0.884401]\n",
      "epoch:20 step:19038 [D loss: 0.655783, acc.: 60.16%] [G loss: 0.881789]\n",
      "epoch:20 step:19039 [D loss: 0.683265, acc.: 56.25%] [G loss: 0.858009]\n",
      "epoch:20 step:19040 [D loss: 0.698505, acc.: 56.25%] [G loss: 0.893114]\n",
      "epoch:20 step:19041 [D loss: 0.711108, acc.: 53.91%] [G loss: 0.852407]\n",
      "epoch:20 step:19042 [D loss: 0.656865, acc.: 58.59%] [G loss: 0.940284]\n",
      "epoch:20 step:19043 [D loss: 0.695012, acc.: 52.34%] [G loss: 0.904006]\n",
      "epoch:20 step:19044 [D loss: 0.630807, acc.: 65.62%] [G loss: 0.911429]\n",
      "epoch:20 step:19045 [D loss: 0.674027, acc.: 53.12%] [G loss: 0.910505]\n",
      "epoch:20 step:19046 [D loss: 0.666775, acc.: 60.16%] [G loss: 0.828231]\n",
      "epoch:20 step:19047 [D loss: 0.677476, acc.: 57.03%] [G loss: 0.889097]\n",
      "epoch:20 step:19048 [D loss: 0.668502, acc.: 57.81%] [G loss: 0.854116]\n",
      "epoch:20 step:19049 [D loss: 0.663368, acc.: 57.81%] [G loss: 0.945285]\n",
      "epoch:20 step:19050 [D loss: 0.672422, acc.: 60.16%] [G loss: 0.898641]\n",
      "epoch:20 step:19051 [D loss: 0.686682, acc.: 57.81%] [G loss: 0.859282]\n",
      "epoch:20 step:19052 [D loss: 0.670876, acc.: 54.69%] [G loss: 0.864785]\n",
      "epoch:20 step:19053 [D loss: 0.668496, acc.: 57.03%] [G loss: 0.855032]\n",
      "epoch:20 step:19054 [D loss: 0.632574, acc.: 64.06%] [G loss: 0.874497]\n",
      "epoch:20 step:19055 [D loss: 0.637594, acc.: 63.28%] [G loss: 0.863604]\n",
      "epoch:20 step:19056 [D loss: 0.676566, acc.: 57.81%] [G loss: 0.876317]\n",
      "epoch:20 step:19057 [D loss: 0.697867, acc.: 57.03%] [G loss: 0.913197]\n",
      "epoch:20 step:19058 [D loss: 0.651085, acc.: 62.50%] [G loss: 0.897818]\n",
      "epoch:20 step:19059 [D loss: 0.668153, acc.: 59.38%] [G loss: 1.004263]\n",
      "epoch:20 step:19060 [D loss: 0.667137, acc.: 57.03%] [G loss: 0.943406]\n",
      "epoch:20 step:19061 [D loss: 0.635398, acc.: 69.53%] [G loss: 0.914007]\n",
      "epoch:20 step:19062 [D loss: 0.663339, acc.: 60.16%] [G loss: 0.886069]\n",
      "epoch:20 step:19063 [D loss: 0.668955, acc.: 64.06%] [G loss: 0.889638]\n",
      "epoch:20 step:19064 [D loss: 0.674039, acc.: 55.47%] [G loss: 0.930398]\n",
      "epoch:20 step:19065 [D loss: 0.654896, acc.: 56.25%] [G loss: 0.881644]\n",
      "epoch:20 step:19066 [D loss: 0.674874, acc.: 53.91%] [G loss: 0.891095]\n",
      "epoch:20 step:19067 [D loss: 0.625702, acc.: 67.19%] [G loss: 0.887276]\n",
      "epoch:20 step:19068 [D loss: 0.623894, acc.: 66.41%] [G loss: 0.887654]\n",
      "epoch:20 step:19069 [D loss: 0.628697, acc.: 66.41%] [G loss: 0.881538]\n",
      "epoch:20 step:19070 [D loss: 0.662768, acc.: 53.91%] [G loss: 0.844261]\n",
      "epoch:20 step:19071 [D loss: 0.654849, acc.: 60.16%] [G loss: 0.823208]\n",
      "epoch:20 step:19072 [D loss: 0.617491, acc.: 70.31%] [G loss: 0.848333]\n",
      "epoch:20 step:19073 [D loss: 0.665754, acc.: 61.72%] [G loss: 0.864075]\n",
      "epoch:20 step:19074 [D loss: 0.670550, acc.: 53.12%] [G loss: 0.870473]\n",
      "epoch:20 step:19075 [D loss: 0.691890, acc.: 54.69%] [G loss: 0.873525]\n",
      "epoch:20 step:19076 [D loss: 0.621149, acc.: 67.97%] [G loss: 0.929377]\n",
      "epoch:20 step:19077 [D loss: 0.645997, acc.: 64.06%] [G loss: 0.889808]\n",
      "epoch:20 step:19078 [D loss: 0.653933, acc.: 60.16%] [G loss: 0.865938]\n",
      "epoch:20 step:19079 [D loss: 0.659444, acc.: 59.38%] [G loss: 0.837982]\n",
      "epoch:20 step:19080 [D loss: 0.647381, acc.: 61.72%] [G loss: 0.920855]\n",
      "epoch:20 step:19081 [D loss: 0.660391, acc.: 58.59%] [G loss: 0.868506]\n",
      "epoch:20 step:19082 [D loss: 0.646758, acc.: 64.06%] [G loss: 0.863811]\n",
      "epoch:20 step:19083 [D loss: 0.672221, acc.: 56.25%] [G loss: 0.858089]\n",
      "epoch:20 step:19084 [D loss: 0.672656, acc.: 59.38%] [G loss: 0.864528]\n",
      "epoch:20 step:19085 [D loss: 0.649058, acc.: 64.84%] [G loss: 0.891449]\n",
      "epoch:20 step:19086 [D loss: 0.697649, acc.: 54.69%] [G loss: 0.872883]\n",
      "epoch:20 step:19087 [D loss: 0.675049, acc.: 58.59%] [G loss: 0.824924]\n",
      "epoch:20 step:19088 [D loss: 0.648089, acc.: 61.72%] [G loss: 0.852476]\n",
      "epoch:20 step:19089 [D loss: 0.692313, acc.: 54.69%] [G loss: 0.873078]\n",
      "epoch:20 step:19090 [D loss: 0.650258, acc.: 64.06%] [G loss: 0.867223]\n",
      "epoch:20 step:19091 [D loss: 0.652438, acc.: 62.50%] [G loss: 0.926200]\n",
      "epoch:20 step:19092 [D loss: 0.673533, acc.: 63.28%] [G loss: 0.902585]\n",
      "epoch:20 step:19093 [D loss: 0.616152, acc.: 69.53%] [G loss: 0.893591]\n",
      "epoch:20 step:19094 [D loss: 0.697285, acc.: 53.91%] [G loss: 0.877826]\n",
      "epoch:20 step:19095 [D loss: 0.683040, acc.: 60.16%] [G loss: 0.850185]\n",
      "epoch:20 step:19096 [D loss: 0.653764, acc.: 61.72%] [G loss: 0.843692]\n",
      "epoch:20 step:19097 [D loss: 0.678742, acc.: 59.38%] [G loss: 0.815573]\n",
      "epoch:20 step:19098 [D loss: 0.624598, acc.: 64.84%] [G loss: 0.876358]\n",
      "epoch:20 step:19099 [D loss: 0.670382, acc.: 56.25%] [G loss: 0.838281]\n",
      "epoch:20 step:19100 [D loss: 0.617433, acc.: 64.84%] [G loss: 0.818901]\n",
      "epoch:20 step:19101 [D loss: 0.683925, acc.: 57.81%] [G loss: 0.803586]\n",
      "epoch:20 step:19102 [D loss: 0.650412, acc.: 62.50%] [G loss: 0.869404]\n",
      "epoch:20 step:19103 [D loss: 0.659938, acc.: 60.94%] [G loss: 0.815689]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19104 [D loss: 0.650158, acc.: 61.72%] [G loss: 0.876334]\n",
      "epoch:20 step:19105 [D loss: 0.674012, acc.: 54.69%] [G loss: 0.806997]\n",
      "epoch:20 step:19106 [D loss: 0.656053, acc.: 57.81%] [G loss: 0.827857]\n",
      "epoch:20 step:19107 [D loss: 0.682387, acc.: 56.25%] [G loss: 0.905736]\n",
      "epoch:20 step:19108 [D loss: 0.646001, acc.: 62.50%] [G loss: 0.923579]\n",
      "epoch:20 step:19109 [D loss: 0.674008, acc.: 55.47%] [G loss: 0.886173]\n",
      "epoch:20 step:19110 [D loss: 0.647805, acc.: 61.72%] [G loss: 0.867613]\n",
      "epoch:20 step:19111 [D loss: 0.687632, acc.: 54.69%] [G loss: 0.860442]\n",
      "epoch:20 step:19112 [D loss: 0.675441, acc.: 54.69%] [G loss: 0.869378]\n",
      "epoch:20 step:19113 [D loss: 0.641957, acc.: 61.72%] [G loss: 0.848904]\n",
      "epoch:20 step:19114 [D loss: 0.667956, acc.: 60.16%] [G loss: 0.899277]\n",
      "epoch:20 step:19115 [D loss: 0.687314, acc.: 56.25%] [G loss: 0.883077]\n",
      "epoch:20 step:19116 [D loss: 0.680654, acc.: 51.56%] [G loss: 0.890782]\n",
      "epoch:20 step:19117 [D loss: 0.648827, acc.: 63.28%] [G loss: 0.823239]\n",
      "epoch:20 step:19118 [D loss: 0.628566, acc.: 66.41%] [G loss: 0.827835]\n",
      "epoch:20 step:19119 [D loss: 0.618408, acc.: 67.19%] [G loss: 0.863038]\n",
      "epoch:20 step:19120 [D loss: 0.701243, acc.: 58.59%] [G loss: 0.873827]\n",
      "epoch:20 step:19121 [D loss: 0.642049, acc.: 63.28%] [G loss: 0.802038]\n",
      "epoch:20 step:19122 [D loss: 0.635390, acc.: 64.06%] [G loss: 0.860221]\n",
      "epoch:20 step:19123 [D loss: 0.666188, acc.: 62.50%] [G loss: 0.843878]\n",
      "epoch:20 step:19124 [D loss: 0.669717, acc.: 56.25%] [G loss: 0.924345]\n",
      "epoch:20 step:19125 [D loss: 0.678005, acc.: 56.25%] [G loss: 0.941107]\n",
      "epoch:20 step:19126 [D loss: 0.664680, acc.: 63.28%] [G loss: 0.874702]\n",
      "epoch:20 step:19127 [D loss: 0.667014, acc.: 60.94%] [G loss: 0.887879]\n",
      "epoch:20 step:19128 [D loss: 0.653030, acc.: 65.62%] [G loss: 0.881281]\n",
      "epoch:20 step:19129 [D loss: 0.646740, acc.: 59.38%] [G loss: 0.827496]\n",
      "epoch:20 step:19130 [D loss: 0.655489, acc.: 64.84%] [G loss: 0.865793]\n",
      "epoch:20 step:19131 [D loss: 0.650212, acc.: 57.81%] [G loss: 0.847447]\n",
      "epoch:20 step:19132 [D loss: 0.707530, acc.: 54.69%] [G loss: 0.864572]\n",
      "epoch:20 step:19133 [D loss: 0.690097, acc.: 56.25%] [G loss: 0.872010]\n",
      "epoch:20 step:19134 [D loss: 0.644194, acc.: 60.94%] [G loss: 0.867396]\n",
      "epoch:20 step:19135 [D loss: 0.670675, acc.: 61.72%] [G loss: 0.793986]\n",
      "epoch:20 step:19136 [D loss: 0.683873, acc.: 55.47%] [G loss: 0.851357]\n",
      "epoch:20 step:19137 [D loss: 0.696690, acc.: 57.03%] [G loss: 0.840899]\n",
      "epoch:20 step:19138 [D loss: 0.654789, acc.: 60.16%] [G loss: 0.859250]\n",
      "epoch:20 step:19139 [D loss: 0.654195, acc.: 62.50%] [G loss: 0.869664]\n",
      "epoch:20 step:19140 [D loss: 0.624638, acc.: 67.97%] [G loss: 0.925910]\n",
      "epoch:20 step:19141 [D loss: 0.645126, acc.: 60.16%] [G loss: 0.861527]\n",
      "epoch:20 step:19142 [D loss: 0.616857, acc.: 62.50%] [G loss: 0.899582]\n",
      "epoch:20 step:19143 [D loss: 0.634179, acc.: 64.84%] [G loss: 0.872849]\n",
      "epoch:20 step:19144 [D loss: 0.707458, acc.: 53.91%] [G loss: 0.894212]\n",
      "epoch:20 step:19145 [D loss: 0.636931, acc.: 68.75%] [G loss: 0.908818]\n",
      "epoch:20 step:19146 [D loss: 0.636898, acc.: 65.62%] [G loss: 0.898029]\n",
      "epoch:20 step:19147 [D loss: 0.638163, acc.: 63.28%] [G loss: 0.897149]\n",
      "epoch:20 step:19148 [D loss: 0.623303, acc.: 64.84%] [G loss: 0.868020]\n",
      "epoch:20 step:19149 [D loss: 0.673080, acc.: 55.47%] [G loss: 0.871985]\n",
      "epoch:20 step:19150 [D loss: 0.674930, acc.: 56.25%] [G loss: 0.904395]\n",
      "epoch:20 step:19151 [D loss: 0.658683, acc.: 59.38%] [G loss: 0.866280]\n",
      "epoch:20 step:19152 [D loss: 0.684468, acc.: 53.12%] [G loss: 0.845119]\n",
      "epoch:20 step:19153 [D loss: 0.686279, acc.: 55.47%] [G loss: 0.887344]\n",
      "epoch:20 step:19154 [D loss: 0.644448, acc.: 65.62%] [G loss: 0.841896]\n",
      "epoch:20 step:19155 [D loss: 0.663454, acc.: 60.94%] [G loss: 0.818085]\n",
      "epoch:20 step:19156 [D loss: 0.643446, acc.: 59.38%] [G loss: 0.904066]\n",
      "epoch:20 step:19157 [D loss: 0.627172, acc.: 64.84%] [G loss: 0.901715]\n",
      "epoch:20 step:19158 [D loss: 0.701827, acc.: 49.22%] [G loss: 0.853209]\n",
      "epoch:20 step:19159 [D loss: 0.610271, acc.: 70.31%] [G loss: 0.841575]\n",
      "epoch:20 step:19160 [D loss: 0.652372, acc.: 59.38%] [G loss: 0.865401]\n",
      "epoch:20 step:19161 [D loss: 0.653872, acc.: 62.50%] [G loss: 0.859885]\n",
      "epoch:20 step:19162 [D loss: 0.689535, acc.: 57.81%] [G loss: 0.898341]\n",
      "epoch:20 step:19163 [D loss: 0.671029, acc.: 57.81%] [G loss: 0.933179]\n",
      "epoch:20 step:19164 [D loss: 0.635146, acc.: 65.62%] [G loss: 0.962213]\n",
      "epoch:20 step:19165 [D loss: 0.691810, acc.: 55.47%] [G loss: 0.856643]\n",
      "epoch:20 step:19166 [D loss: 0.652305, acc.: 65.62%] [G loss: 0.869969]\n",
      "epoch:20 step:19167 [D loss: 0.665795, acc.: 56.25%] [G loss: 0.821584]\n",
      "epoch:20 step:19168 [D loss: 0.693736, acc.: 53.91%] [G loss: 0.906104]\n",
      "epoch:20 step:19169 [D loss: 0.650541, acc.: 57.03%] [G loss: 0.848729]\n",
      "epoch:20 step:19170 [D loss: 0.694995, acc.: 50.78%] [G loss: 0.838030]\n",
      "epoch:20 step:19171 [D loss: 0.654280, acc.: 58.59%] [G loss: 0.887629]\n",
      "epoch:20 step:19172 [D loss: 0.655325, acc.: 60.16%] [G loss: 0.910162]\n",
      "epoch:20 step:19173 [D loss: 0.659861, acc.: 64.84%] [G loss: 0.897931]\n",
      "epoch:20 step:19174 [D loss: 0.662262, acc.: 60.16%] [G loss: 0.866404]\n",
      "epoch:20 step:19175 [D loss: 0.645260, acc.: 64.84%] [G loss: 0.842155]\n",
      "epoch:20 step:19176 [D loss: 0.634861, acc.: 65.62%] [G loss: 0.805059]\n",
      "epoch:20 step:19177 [D loss: 0.707261, acc.: 48.44%] [G loss: 0.854079]\n",
      "epoch:20 step:19178 [D loss: 0.660385, acc.: 58.59%] [G loss: 0.939756]\n",
      "epoch:20 step:19179 [D loss: 0.651115, acc.: 61.72%] [G loss: 0.876640]\n",
      "epoch:20 step:19180 [D loss: 0.687165, acc.: 60.16%] [G loss: 0.901536]\n",
      "epoch:20 step:19181 [D loss: 0.680818, acc.: 51.56%] [G loss: 0.861246]\n",
      "epoch:20 step:19182 [D loss: 0.662027, acc.: 60.16%] [G loss: 0.903927]\n",
      "epoch:20 step:19183 [D loss: 0.656019, acc.: 64.06%] [G loss: 0.926266]\n",
      "epoch:20 step:19184 [D loss: 0.647415, acc.: 59.38%] [G loss: 0.895773]\n",
      "epoch:20 step:19185 [D loss: 0.668787, acc.: 60.94%] [G loss: 0.872620]\n",
      "epoch:20 step:19186 [D loss: 0.687747, acc.: 54.69%] [G loss: 0.902871]\n",
      "epoch:20 step:19187 [D loss: 0.642611, acc.: 61.72%] [G loss: 0.891694]\n",
      "epoch:20 step:19188 [D loss: 0.691367, acc.: 55.47%] [G loss: 0.883954]\n",
      "epoch:20 step:19189 [D loss: 0.639919, acc.: 65.62%] [G loss: 0.899965]\n",
      "epoch:20 step:19190 [D loss: 0.612010, acc.: 75.78%] [G loss: 0.901135]\n",
      "epoch:20 step:19191 [D loss: 0.659668, acc.: 60.94%] [G loss: 0.851522]\n",
      "epoch:20 step:19192 [D loss: 0.655820, acc.: 58.59%] [G loss: 0.900655]\n",
      "epoch:20 step:19193 [D loss: 0.641610, acc.: 57.03%] [G loss: 0.845806]\n",
      "epoch:20 step:19194 [D loss: 0.658037, acc.: 55.47%] [G loss: 0.899800]\n",
      "epoch:20 step:19195 [D loss: 0.648255, acc.: 58.59%] [G loss: 0.893021]\n",
      "epoch:20 step:19196 [D loss: 0.656889, acc.: 60.94%] [G loss: 0.823431]\n",
      "epoch:20 step:19197 [D loss: 0.642103, acc.: 59.38%] [G loss: 0.850169]\n",
      "epoch:20 step:19198 [D loss: 0.641822, acc.: 69.53%] [G loss: 0.882805]\n",
      "epoch:20 step:19199 [D loss: 0.632020, acc.: 67.19%] [G loss: 0.854908]\n",
      "epoch:20 step:19200 [D loss: 0.651131, acc.: 57.03%] [G loss: 0.927375]\n",
      "##############\n",
      "[3.0897993  2.59886627 2.48356685 3.85448006 1.42405759 8.00646601\n",
      " 2.78145064 3.0762627  4.23792549 7.14834402]\n",
      "##########\n",
      "epoch:20 step:19201 [D loss: 0.674940, acc.: 51.56%] [G loss: 0.911599]\n",
      "epoch:20 step:19202 [D loss: 0.668660, acc.: 55.47%] [G loss: 0.908391]\n",
      "epoch:20 step:19203 [D loss: 0.677734, acc.: 58.59%] [G loss: 0.860857]\n",
      "epoch:20 step:19204 [D loss: 0.683823, acc.: 57.81%] [G loss: 0.850132]\n",
      "epoch:20 step:19205 [D loss: 0.681456, acc.: 53.12%] [G loss: 0.827811]\n",
      "epoch:20 step:19206 [D loss: 0.636117, acc.: 66.41%] [G loss: 0.871427]\n",
      "epoch:20 step:19207 [D loss: 0.679228, acc.: 57.03%] [G loss: 0.853120]\n",
      "epoch:20 step:19208 [D loss: 0.673988, acc.: 61.72%] [G loss: 0.896134]\n",
      "epoch:20 step:19209 [D loss: 0.646779, acc.: 60.94%] [G loss: 0.881398]\n",
      "epoch:20 step:19210 [D loss: 0.681693, acc.: 60.16%] [G loss: 0.861721]\n",
      "epoch:20 step:19211 [D loss: 0.651182, acc.: 60.16%] [G loss: 0.849561]\n",
      "epoch:20 step:19212 [D loss: 0.650995, acc.: 64.84%] [G loss: 0.878926]\n",
      "epoch:20 step:19213 [D loss: 0.670255, acc.: 56.25%] [G loss: 0.928142]\n",
      "epoch:20 step:19214 [D loss: 0.671915, acc.: 52.34%] [G loss: 0.877519]\n",
      "epoch:20 step:19215 [D loss: 0.608536, acc.: 67.97%] [G loss: 0.847447]\n",
      "epoch:20 step:19216 [D loss: 0.683889, acc.: 56.25%] [G loss: 0.818373]\n",
      "epoch:20 step:19217 [D loss: 0.679563, acc.: 59.38%] [G loss: 0.832217]\n",
      "epoch:20 step:19218 [D loss: 0.663403, acc.: 57.81%] [G loss: 0.826513]\n",
      "epoch:20 step:19219 [D loss: 0.684065, acc.: 50.00%] [G loss: 0.879788]\n",
      "epoch:20 step:19220 [D loss: 0.672537, acc.: 54.69%] [G loss: 0.846000]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19221 [D loss: 0.643216, acc.: 57.03%] [G loss: 0.860155]\n",
      "epoch:20 step:19222 [D loss: 0.662519, acc.: 58.59%] [G loss: 0.899269]\n",
      "epoch:20 step:19223 [D loss: 0.663995, acc.: 59.38%] [G loss: 0.828333]\n",
      "epoch:20 step:19224 [D loss: 0.629099, acc.: 65.62%] [G loss: 0.859327]\n",
      "epoch:20 step:19225 [D loss: 0.676050, acc.: 57.03%] [G loss: 0.845857]\n",
      "epoch:20 step:19226 [D loss: 0.646058, acc.: 59.38%] [G loss: 0.913112]\n",
      "epoch:20 step:19227 [D loss: 0.701069, acc.: 53.12%] [G loss: 0.875992]\n",
      "epoch:20 step:19228 [D loss: 0.640404, acc.: 62.50%] [G loss: 0.919750]\n",
      "epoch:20 step:19229 [D loss: 0.668883, acc.: 59.38%] [G loss: 0.933344]\n",
      "epoch:20 step:19230 [D loss: 0.633446, acc.: 64.84%] [G loss: 0.895953]\n",
      "epoch:20 step:19231 [D loss: 0.617619, acc.: 71.09%] [G loss: 0.897311]\n",
      "epoch:20 step:19232 [D loss: 0.663010, acc.: 59.38%] [G loss: 0.905060]\n",
      "epoch:20 step:19233 [D loss: 0.683414, acc.: 54.69%] [G loss: 0.899949]\n",
      "epoch:20 step:19234 [D loss: 0.643639, acc.: 61.72%] [G loss: 0.929966]\n",
      "epoch:20 step:19235 [D loss: 0.695183, acc.: 57.03%] [G loss: 0.926975]\n",
      "epoch:20 step:19236 [D loss: 0.651460, acc.: 63.28%] [G loss: 0.928787]\n",
      "epoch:20 step:19237 [D loss: 0.650605, acc.: 62.50%] [G loss: 0.939268]\n",
      "epoch:20 step:19238 [D loss: 0.671269, acc.: 56.25%] [G loss: 0.856596]\n",
      "epoch:20 step:19239 [D loss: 0.682039, acc.: 57.81%] [G loss: 0.923195]\n",
      "epoch:20 step:19240 [D loss: 0.635996, acc.: 68.75%] [G loss: 0.883214]\n",
      "epoch:20 step:19241 [D loss: 0.656124, acc.: 55.47%] [G loss: 0.867005]\n",
      "epoch:20 step:19242 [D loss: 0.663563, acc.: 60.16%] [G loss: 0.848852]\n",
      "epoch:20 step:19243 [D loss: 0.643173, acc.: 62.50%] [G loss: 0.864754]\n",
      "epoch:20 step:19244 [D loss: 0.664070, acc.: 57.81%] [G loss: 0.882485]\n",
      "epoch:20 step:19245 [D loss: 0.653479, acc.: 60.94%] [G loss: 0.828008]\n",
      "epoch:20 step:19246 [D loss: 0.667973, acc.: 64.06%] [G loss: 0.816236]\n",
      "epoch:20 step:19247 [D loss: 0.661111, acc.: 60.16%] [G loss: 0.863125]\n",
      "epoch:20 step:19248 [D loss: 0.640889, acc.: 63.28%] [G loss: 0.876985]\n",
      "epoch:20 step:19249 [D loss: 0.619882, acc.: 65.62%] [G loss: 0.926505]\n",
      "epoch:20 step:19250 [D loss: 0.647421, acc.: 60.16%] [G loss: 0.931702]\n",
      "epoch:20 step:19251 [D loss: 0.645148, acc.: 60.94%] [G loss: 0.884518]\n",
      "epoch:20 step:19252 [D loss: 0.675849, acc.: 57.03%] [G loss: 0.908869]\n",
      "epoch:20 step:19253 [D loss: 0.660050, acc.: 63.28%] [G loss: 0.922283]\n",
      "epoch:20 step:19254 [D loss: 0.664784, acc.: 53.91%] [G loss: 0.820613]\n",
      "epoch:20 step:19255 [D loss: 0.667178, acc.: 60.16%] [G loss: 0.856872]\n",
      "epoch:20 step:19256 [D loss: 0.677855, acc.: 58.59%] [G loss: 0.856942]\n",
      "epoch:20 step:19257 [D loss: 0.656348, acc.: 62.50%] [G loss: 0.894032]\n",
      "epoch:20 step:19258 [D loss: 0.656587, acc.: 58.59%] [G loss: 0.858506]\n",
      "epoch:20 step:19259 [D loss: 0.636353, acc.: 67.97%] [G loss: 0.832754]\n",
      "epoch:20 step:19260 [D loss: 0.651281, acc.: 61.72%] [G loss: 0.889451]\n",
      "epoch:20 step:19261 [D loss: 0.647816, acc.: 60.16%] [G loss: 0.896885]\n",
      "epoch:20 step:19262 [D loss: 0.668708, acc.: 62.50%] [G loss: 0.872828]\n",
      "epoch:20 step:19263 [D loss: 0.633052, acc.: 67.97%] [G loss: 0.904863]\n",
      "epoch:20 step:19264 [D loss: 0.631856, acc.: 62.50%] [G loss: 0.988452]\n",
      "epoch:20 step:19265 [D loss: 0.683920, acc.: 57.81%] [G loss: 0.961121]\n",
      "epoch:20 step:19266 [D loss: 0.695036, acc.: 57.03%] [G loss: 0.875002]\n",
      "epoch:20 step:19267 [D loss: 0.651834, acc.: 64.06%] [G loss: 0.887773]\n",
      "epoch:20 step:19268 [D loss: 0.673005, acc.: 53.12%] [G loss: 0.864305]\n",
      "epoch:20 step:19269 [D loss: 0.644537, acc.: 60.94%] [G loss: 0.861909]\n",
      "epoch:20 step:19270 [D loss: 0.663073, acc.: 60.94%] [G loss: 0.891552]\n",
      "epoch:20 step:19271 [D loss: 0.678904, acc.: 55.47%] [G loss: 0.838756]\n",
      "epoch:20 step:19272 [D loss: 0.670885, acc.: 56.25%] [G loss: 0.918244]\n",
      "epoch:20 step:19273 [D loss: 0.634720, acc.: 67.97%] [G loss: 0.884718]\n",
      "epoch:20 step:19274 [D loss: 0.664272, acc.: 62.50%] [G loss: 0.880212]\n",
      "epoch:20 step:19275 [D loss: 0.671039, acc.: 56.25%] [G loss: 0.837950]\n",
      "epoch:20 step:19276 [D loss: 0.701964, acc.: 53.91%] [G loss: 0.887933]\n",
      "epoch:20 step:19277 [D loss: 0.649728, acc.: 64.06%] [G loss: 0.888029]\n",
      "epoch:20 step:19278 [D loss: 0.664259, acc.: 59.38%] [G loss: 0.813200]\n",
      "epoch:20 step:19279 [D loss: 0.686201, acc.: 51.56%] [G loss: 0.807342]\n",
      "epoch:20 step:19280 [D loss: 0.641268, acc.: 69.53%] [G loss: 0.853321]\n",
      "epoch:20 step:19281 [D loss: 0.677296, acc.: 60.16%] [G loss: 0.831598]\n",
      "epoch:20 step:19282 [D loss: 0.665542, acc.: 61.72%] [G loss: 0.866161]\n",
      "epoch:20 step:19283 [D loss: 0.639097, acc.: 67.19%] [G loss: 0.889526]\n",
      "epoch:20 step:19284 [D loss: 0.643423, acc.: 64.84%] [G loss: 0.873692]\n",
      "epoch:20 step:19285 [D loss: 0.664090, acc.: 62.50%] [G loss: 0.851493]\n",
      "epoch:20 step:19286 [D loss: 0.658336, acc.: 60.16%] [G loss: 0.888032]\n",
      "epoch:20 step:19287 [D loss: 0.650710, acc.: 64.84%] [G loss: 0.879758]\n",
      "epoch:20 step:19288 [D loss: 0.665384, acc.: 56.25%] [G loss: 0.826116]\n",
      "epoch:20 step:19289 [D loss: 0.704493, acc.: 50.00%] [G loss: 0.833982]\n",
      "epoch:20 step:19290 [D loss: 0.646787, acc.: 64.84%] [G loss: 0.957340]\n",
      "epoch:20 step:19291 [D loss: 0.674941, acc.: 64.06%] [G loss: 0.799513]\n",
      "epoch:20 step:19292 [D loss: 0.669997, acc.: 60.94%] [G loss: 0.867556]\n",
      "epoch:20 step:19293 [D loss: 0.676305, acc.: 54.69%] [G loss: 0.864618]\n",
      "epoch:20 step:19294 [D loss: 0.673929, acc.: 55.47%] [G loss: 0.830968]\n",
      "epoch:20 step:19295 [D loss: 0.645454, acc.: 63.28%] [G loss: 0.824040]\n",
      "epoch:20 step:19296 [D loss: 0.691604, acc.: 54.69%] [G loss: 0.846300]\n",
      "epoch:20 step:19297 [D loss: 0.643418, acc.: 63.28%] [G loss: 0.874749]\n",
      "epoch:20 step:19298 [D loss: 0.686770, acc.: 52.34%] [G loss: 0.914207]\n",
      "epoch:20 step:19299 [D loss: 0.670645, acc.: 55.47%] [G loss: 0.908516]\n",
      "epoch:20 step:19300 [D loss: 0.693732, acc.: 53.91%] [G loss: 0.895245]\n",
      "epoch:20 step:19301 [D loss: 0.662508, acc.: 60.94%] [G loss: 0.825383]\n",
      "epoch:20 step:19302 [D loss: 0.669229, acc.: 53.12%] [G loss: 0.855797]\n",
      "epoch:20 step:19303 [D loss: 0.635298, acc.: 67.19%] [G loss: 0.870081]\n",
      "epoch:20 step:19304 [D loss: 0.644696, acc.: 62.50%] [G loss: 0.818922]\n",
      "epoch:20 step:19305 [D loss: 0.647654, acc.: 59.38%] [G loss: 0.848726]\n",
      "epoch:20 step:19306 [D loss: 0.637292, acc.: 65.62%] [G loss: 0.873189]\n",
      "epoch:20 step:19307 [D loss: 0.636546, acc.: 62.50%] [G loss: 0.857443]\n",
      "epoch:20 step:19308 [D loss: 0.696522, acc.: 51.56%] [G loss: 0.841856]\n",
      "epoch:20 step:19309 [D loss: 0.657520, acc.: 62.50%] [G loss: 0.924690]\n",
      "epoch:20 step:19310 [D loss: 0.689345, acc.: 54.69%] [G loss: 0.934278]\n",
      "epoch:20 step:19311 [D loss: 0.663488, acc.: 60.16%] [G loss: 0.922809]\n",
      "epoch:20 step:19312 [D loss: 0.667908, acc.: 57.81%] [G loss: 0.828655]\n",
      "epoch:20 step:19313 [D loss: 0.665171, acc.: 57.03%] [G loss: 0.860265]\n",
      "epoch:20 step:19314 [D loss: 0.658952, acc.: 59.38%] [G loss: 0.861572]\n",
      "epoch:20 step:19315 [D loss: 0.679870, acc.: 53.12%] [G loss: 0.859130]\n",
      "epoch:20 step:19316 [D loss: 0.625391, acc.: 71.09%] [G loss: 0.854141]\n",
      "epoch:20 step:19317 [D loss: 0.679417, acc.: 60.16%] [G loss: 0.880187]\n",
      "epoch:20 step:19318 [D loss: 0.673151, acc.: 60.16%] [G loss: 0.887543]\n",
      "epoch:20 step:19319 [D loss: 0.666498, acc.: 57.03%] [G loss: 0.860240]\n",
      "epoch:20 step:19320 [D loss: 0.654148, acc.: 56.25%] [G loss: 0.837202]\n",
      "epoch:20 step:19321 [D loss: 0.668090, acc.: 58.59%] [G loss: 0.909870]\n",
      "epoch:20 step:19322 [D loss: 0.622930, acc.: 67.97%] [G loss: 0.872551]\n",
      "epoch:20 step:19323 [D loss: 0.675197, acc.: 57.81%] [G loss: 0.911524]\n",
      "epoch:20 step:19324 [D loss: 0.631307, acc.: 64.84%] [G loss: 0.907751]\n",
      "epoch:20 step:19325 [D loss: 0.666887, acc.: 60.16%] [G loss: 0.882616]\n",
      "epoch:20 step:19326 [D loss: 0.653216, acc.: 63.28%] [G loss: 0.904762]\n",
      "epoch:20 step:19327 [D loss: 0.648005, acc.: 57.03%] [G loss: 0.854678]\n",
      "epoch:20 step:19328 [D loss: 0.657421, acc.: 57.81%] [G loss: 0.898362]\n",
      "epoch:20 step:19329 [D loss: 0.661011, acc.: 60.16%] [G loss: 0.878924]\n",
      "epoch:20 step:19330 [D loss: 0.657506, acc.: 62.50%] [G loss: 0.926500]\n",
      "epoch:20 step:19331 [D loss: 0.676689, acc.: 60.16%] [G loss: 0.878496]\n",
      "epoch:20 step:19332 [D loss: 0.647955, acc.: 64.84%] [G loss: 0.909297]\n",
      "epoch:20 step:19333 [D loss: 0.670806, acc.: 54.69%] [G loss: 0.911305]\n",
      "epoch:20 step:19334 [D loss: 0.638481, acc.: 60.94%] [G loss: 0.932644]\n",
      "epoch:20 step:19335 [D loss: 0.642498, acc.: 66.41%] [G loss: 0.869898]\n",
      "epoch:20 step:19336 [D loss: 0.652571, acc.: 62.50%] [G loss: 0.890118]\n",
      "epoch:20 step:19337 [D loss: 0.659096, acc.: 57.03%] [G loss: 0.858646]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19338 [D loss: 0.658825, acc.: 62.50%] [G loss: 0.875592]\n",
      "epoch:20 step:19339 [D loss: 0.632441, acc.: 64.84%] [G loss: 0.862446]\n",
      "epoch:20 step:19340 [D loss: 0.664561, acc.: 57.81%] [G loss: 0.875832]\n",
      "epoch:20 step:19341 [D loss: 0.658577, acc.: 62.50%] [G loss: 0.972782]\n",
      "epoch:20 step:19342 [D loss: 0.630633, acc.: 71.09%] [G loss: 0.891112]\n",
      "epoch:20 step:19343 [D loss: 0.683734, acc.: 54.69%] [G loss: 0.921713]\n",
      "epoch:20 step:19344 [D loss: 0.683593, acc.: 61.72%] [G loss: 0.884744]\n",
      "epoch:20 step:19345 [D loss: 0.664644, acc.: 58.59%] [G loss: 0.848808]\n",
      "epoch:20 step:19346 [D loss: 0.681481, acc.: 57.03%] [G loss: 0.853117]\n",
      "epoch:20 step:19347 [D loss: 0.667595, acc.: 62.50%] [G loss: 0.902867]\n",
      "epoch:20 step:19348 [D loss: 0.679408, acc.: 47.66%] [G loss: 0.839775]\n",
      "epoch:20 step:19349 [D loss: 0.642275, acc.: 65.62%] [G loss: 0.811702]\n",
      "epoch:20 step:19350 [D loss: 0.631998, acc.: 66.41%] [G loss: 0.847495]\n",
      "epoch:20 step:19351 [D loss: 0.667310, acc.: 59.38%] [G loss: 0.856375]\n",
      "epoch:20 step:19352 [D loss: 0.638033, acc.: 65.62%] [G loss: 0.854891]\n",
      "epoch:20 step:19353 [D loss: 0.639020, acc.: 67.19%] [G loss: 0.865575]\n",
      "epoch:20 step:19354 [D loss: 0.671955, acc.: 56.25%] [G loss: 0.886116]\n",
      "epoch:20 step:19355 [D loss: 0.705095, acc.: 53.91%] [G loss: 0.849922]\n",
      "epoch:20 step:19356 [D loss: 0.643413, acc.: 60.94%] [G loss: 0.899916]\n",
      "epoch:20 step:19357 [D loss: 0.649816, acc.: 61.72%] [G loss: 0.876202]\n",
      "epoch:20 step:19358 [D loss: 0.655356, acc.: 64.84%] [G loss: 0.888021]\n",
      "epoch:20 step:19359 [D loss: 0.687932, acc.: 58.59%] [G loss: 0.849852]\n",
      "epoch:20 step:19360 [D loss: 0.630879, acc.: 65.62%] [G loss: 0.864388]\n",
      "epoch:20 step:19361 [D loss: 0.703653, acc.: 51.56%] [G loss: 0.878587]\n",
      "epoch:20 step:19362 [D loss: 0.652276, acc.: 63.28%] [G loss: 0.876216]\n",
      "epoch:20 step:19363 [D loss: 0.642436, acc.: 66.41%] [G loss: 0.903106]\n",
      "epoch:20 step:19364 [D loss: 0.668632, acc.: 60.94%] [G loss: 0.922225]\n",
      "epoch:20 step:19365 [D loss: 0.667010, acc.: 58.59%] [G loss: 0.865720]\n",
      "epoch:20 step:19366 [D loss: 0.690671, acc.: 55.47%] [G loss: 0.929575]\n",
      "epoch:20 step:19367 [D loss: 0.641955, acc.: 63.28%] [G loss: 0.899252]\n",
      "epoch:20 step:19368 [D loss: 0.733648, acc.: 50.00%] [G loss: 0.901262]\n",
      "epoch:20 step:19369 [D loss: 0.631030, acc.: 64.06%] [G loss: 0.896782]\n",
      "epoch:20 step:19370 [D loss: 0.671507, acc.: 62.50%] [G loss: 0.881146]\n",
      "epoch:20 step:19371 [D loss: 0.651163, acc.: 57.81%] [G loss: 0.809060]\n",
      "epoch:20 step:19372 [D loss: 0.665246, acc.: 66.41%] [G loss: 0.868047]\n",
      "epoch:20 step:19373 [D loss: 0.667466, acc.: 64.84%] [G loss: 0.876236]\n",
      "epoch:20 step:19374 [D loss: 0.655732, acc.: 62.50%] [G loss: 0.919891]\n",
      "epoch:20 step:19375 [D loss: 0.661475, acc.: 64.84%] [G loss: 0.936942]\n",
      "epoch:20 step:19376 [D loss: 0.625305, acc.: 62.50%] [G loss: 0.853541]\n",
      "epoch:20 step:19377 [D loss: 0.634446, acc.: 65.62%] [G loss: 0.927707]\n",
      "epoch:20 step:19378 [D loss: 0.636577, acc.: 67.97%] [G loss: 0.930356]\n",
      "epoch:20 step:19379 [D loss: 0.691895, acc.: 51.56%] [G loss: 0.827545]\n",
      "epoch:20 step:19380 [D loss: 0.651413, acc.: 55.47%] [G loss: 0.877681]\n",
      "epoch:20 step:19381 [D loss: 0.694538, acc.: 58.59%] [G loss: 0.852514]\n",
      "epoch:20 step:19382 [D loss: 0.674032, acc.: 57.03%] [G loss: 0.840776]\n",
      "epoch:20 step:19383 [D loss: 0.701827, acc.: 52.34%] [G loss: 0.790913]\n",
      "epoch:20 step:19384 [D loss: 0.687068, acc.: 59.38%] [G loss: 0.853691]\n",
      "epoch:20 step:19385 [D loss: 0.639457, acc.: 61.72%] [G loss: 0.862284]\n",
      "epoch:20 step:19386 [D loss: 0.655269, acc.: 67.97%] [G loss: 0.870556]\n",
      "epoch:20 step:19387 [D loss: 0.702641, acc.: 57.81%] [G loss: 0.827009]\n",
      "epoch:20 step:19388 [D loss: 0.635845, acc.: 64.84%] [G loss: 0.881543]\n",
      "epoch:20 step:19389 [D loss: 0.675739, acc.: 55.47%] [G loss: 0.859422]\n",
      "epoch:20 step:19390 [D loss: 0.684962, acc.: 54.69%] [G loss: 0.829554]\n",
      "epoch:20 step:19391 [D loss: 0.649475, acc.: 62.50%] [G loss: 0.886949]\n",
      "epoch:20 step:19392 [D loss: 0.655378, acc.: 60.94%] [G loss: 0.853498]\n",
      "epoch:20 step:19393 [D loss: 0.653569, acc.: 60.94%] [G loss: 0.900007]\n",
      "epoch:20 step:19394 [D loss: 0.690604, acc.: 53.12%] [G loss: 0.925863]\n",
      "epoch:20 step:19395 [D loss: 0.654748, acc.: 60.94%] [G loss: 0.864276]\n",
      "epoch:20 step:19396 [D loss: 0.670658, acc.: 61.72%] [G loss: 0.939949]\n",
      "epoch:20 step:19397 [D loss: 0.646104, acc.: 62.50%] [G loss: 0.891735]\n",
      "epoch:20 step:19398 [D loss: 0.700687, acc.: 52.34%] [G loss: 0.846510]\n",
      "epoch:20 step:19399 [D loss: 0.654488, acc.: 60.16%] [G loss: 0.927645]\n",
      "epoch:20 step:19400 [D loss: 0.684527, acc.: 53.91%] [G loss: 0.877675]\n",
      "##############\n",
      "[3.08088332 2.31122306 1.98608578 3.69599026 1.45534594 9.27426719\n",
      " 2.64344504 3.6662231  4.30617144 6.29654197]\n",
      "##########\n",
      "epoch:20 step:19401 [D loss: 0.631124, acc.: 70.31%] [G loss: 0.858030]\n",
      "epoch:20 step:19402 [D loss: 0.683638, acc.: 57.03%] [G loss: 0.850205]\n",
      "epoch:20 step:19403 [D loss: 0.692914, acc.: 54.69%] [G loss: 0.866112]\n",
      "epoch:20 step:19404 [D loss: 0.644342, acc.: 62.50%] [G loss: 0.897461]\n",
      "epoch:20 step:19405 [D loss: 0.701746, acc.: 56.25%] [G loss: 0.890157]\n",
      "epoch:20 step:19406 [D loss: 0.656484, acc.: 59.38%] [G loss: 0.868306]\n",
      "epoch:20 step:19407 [D loss: 0.681418, acc.: 51.56%] [G loss: 0.841479]\n",
      "epoch:20 step:19408 [D loss: 0.678492, acc.: 55.47%] [G loss: 0.847561]\n",
      "epoch:20 step:19409 [D loss: 0.673405, acc.: 56.25%] [G loss: 0.862099]\n",
      "epoch:20 step:19410 [D loss: 0.652067, acc.: 57.03%] [G loss: 0.878243]\n",
      "epoch:20 step:19411 [D loss: 0.637644, acc.: 64.06%] [G loss: 0.875569]\n",
      "epoch:20 step:19412 [D loss: 0.667697, acc.: 57.81%] [G loss: 0.904340]\n",
      "epoch:20 step:19413 [D loss: 0.667047, acc.: 57.81%] [G loss: 0.859523]\n",
      "epoch:20 step:19414 [D loss: 0.655150, acc.: 60.16%] [G loss: 0.861091]\n",
      "epoch:20 step:19415 [D loss: 0.668969, acc.: 57.81%] [G loss: 0.885804]\n",
      "epoch:20 step:19416 [D loss: 0.659469, acc.: 59.38%] [G loss: 0.869995]\n",
      "epoch:20 step:19417 [D loss: 0.658690, acc.: 57.81%] [G loss: 0.796118]\n",
      "epoch:20 step:19418 [D loss: 0.666437, acc.: 57.03%] [G loss: 0.802809]\n",
      "epoch:20 step:19419 [D loss: 0.677603, acc.: 57.03%] [G loss: 0.876229]\n",
      "epoch:20 step:19420 [D loss: 0.702650, acc.: 49.22%] [G loss: 0.880852]\n",
      "epoch:20 step:19421 [D loss: 0.626351, acc.: 69.53%] [G loss: 0.875193]\n",
      "epoch:20 step:19422 [D loss: 0.642774, acc.: 63.28%] [G loss: 0.905984]\n",
      "epoch:20 step:19423 [D loss: 0.666307, acc.: 62.50%] [G loss: 0.872020]\n",
      "epoch:20 step:19424 [D loss: 0.661152, acc.: 60.94%] [G loss: 0.851463]\n",
      "epoch:20 step:19425 [D loss: 0.637846, acc.: 65.62%] [G loss: 0.869570]\n",
      "epoch:20 step:19426 [D loss: 0.662187, acc.: 63.28%] [G loss: 0.885649]\n",
      "epoch:20 step:19427 [D loss: 0.640317, acc.: 59.38%] [G loss: 0.880225]\n",
      "epoch:20 step:19428 [D loss: 0.626452, acc.: 63.28%] [G loss: 0.911855]\n",
      "epoch:20 step:19429 [D loss: 0.624303, acc.: 63.28%] [G loss: 0.867427]\n",
      "epoch:20 step:19430 [D loss: 0.657376, acc.: 57.03%] [G loss: 0.860745]\n",
      "epoch:20 step:19431 [D loss: 0.748775, acc.: 49.22%] [G loss: 0.873697]\n",
      "epoch:20 step:19432 [D loss: 0.664714, acc.: 57.81%] [G loss: 0.887674]\n",
      "epoch:20 step:19433 [D loss: 0.649625, acc.: 60.16%] [G loss: 0.868659]\n",
      "epoch:20 step:19434 [D loss: 0.644960, acc.: 64.06%] [G loss: 0.900265]\n",
      "epoch:20 step:19435 [D loss: 0.635397, acc.: 66.41%] [G loss: 0.837643]\n",
      "epoch:20 step:19436 [D loss: 0.645340, acc.: 60.94%] [G loss: 0.880658]\n",
      "epoch:20 step:19437 [D loss: 0.661412, acc.: 64.84%] [G loss: 0.881471]\n",
      "epoch:20 step:19438 [D loss: 0.665379, acc.: 59.38%] [G loss: 0.866079]\n",
      "epoch:20 step:19439 [D loss: 0.671232, acc.: 58.59%] [G loss: 0.821312]\n",
      "epoch:20 step:19440 [D loss: 0.650160, acc.: 59.38%] [G loss: 0.842909]\n",
      "epoch:20 step:19441 [D loss: 0.636207, acc.: 64.06%] [G loss: 0.862062]\n",
      "epoch:20 step:19442 [D loss: 0.657256, acc.: 57.81%] [G loss: 0.840195]\n",
      "epoch:20 step:19443 [D loss: 0.676009, acc.: 59.38%] [G loss: 0.832348]\n",
      "epoch:20 step:19444 [D loss: 0.661980, acc.: 61.72%] [G loss: 0.873632]\n",
      "epoch:20 step:19445 [D loss: 0.684010, acc.: 61.72%] [G loss: 0.894032]\n",
      "epoch:20 step:19446 [D loss: 0.661464, acc.: 61.72%] [G loss: 0.902862]\n",
      "epoch:20 step:19447 [D loss: 0.658293, acc.: 65.62%] [G loss: 0.898225]\n",
      "epoch:20 step:19448 [D loss: 0.665335, acc.: 57.03%] [G loss: 0.869567]\n",
      "epoch:20 step:19449 [D loss: 0.691880, acc.: 57.81%] [G loss: 0.851736]\n",
      "epoch:20 step:19450 [D loss: 0.628824, acc.: 66.41%] [G loss: 0.934312]\n",
      "epoch:20 step:19451 [D loss: 0.668922, acc.: 60.16%] [G loss: 0.893398]\n",
      "epoch:20 step:19452 [D loss: 0.686268, acc.: 60.16%] [G loss: 0.941462]\n",
      "epoch:20 step:19453 [D loss: 0.681378, acc.: 52.34%] [G loss: 0.889866]\n",
      "epoch:20 step:19454 [D loss: 0.685518, acc.: 55.47%] [G loss: 0.832516]\n",
      "epoch:20 step:19455 [D loss: 0.686350, acc.: 57.81%] [G loss: 0.900523]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19456 [D loss: 0.680270, acc.: 56.25%] [G loss: 0.856559]\n",
      "epoch:20 step:19457 [D loss: 0.672759, acc.: 53.12%] [G loss: 0.924868]\n",
      "epoch:20 step:19458 [D loss: 0.663714, acc.: 57.03%] [G loss: 0.922920]\n",
      "epoch:20 step:19459 [D loss: 0.685368, acc.: 53.91%] [G loss: 0.933465]\n",
      "epoch:20 step:19460 [D loss: 0.674586, acc.: 58.59%] [G loss: 0.889410]\n",
      "epoch:20 step:19461 [D loss: 0.678753, acc.: 59.38%] [G loss: 0.909627]\n",
      "epoch:20 step:19462 [D loss: 0.646112, acc.: 61.72%] [G loss: 0.894638]\n",
      "epoch:20 step:19463 [D loss: 0.663687, acc.: 53.91%] [G loss: 0.932098]\n",
      "epoch:20 step:19464 [D loss: 0.664453, acc.: 60.94%] [G loss: 0.849591]\n",
      "epoch:20 step:19465 [D loss: 0.664776, acc.: 60.94%] [G loss: 0.893404]\n",
      "epoch:20 step:19466 [D loss: 0.695630, acc.: 54.69%] [G loss: 0.873794]\n",
      "epoch:20 step:19467 [D loss: 0.661575, acc.: 61.72%] [G loss: 0.889364]\n",
      "epoch:20 step:19468 [D loss: 0.672106, acc.: 56.25%] [G loss: 0.892260]\n",
      "epoch:20 step:19469 [D loss: 0.653618, acc.: 63.28%] [G loss: 0.828866]\n",
      "epoch:20 step:19470 [D loss: 0.692550, acc.: 53.91%] [G loss: 0.878086]\n",
      "epoch:20 step:19471 [D loss: 0.670006, acc.: 62.50%] [G loss: 0.923831]\n",
      "epoch:20 step:19472 [D loss: 0.633949, acc.: 64.06%] [G loss: 0.874872]\n",
      "epoch:20 step:19473 [D loss: 0.655115, acc.: 63.28%] [G loss: 0.871482]\n",
      "epoch:20 step:19474 [D loss: 0.651811, acc.: 58.59%] [G loss: 0.895502]\n",
      "epoch:20 step:19475 [D loss: 0.664186, acc.: 64.06%] [G loss: 0.841413]\n",
      "epoch:20 step:19476 [D loss: 0.672100, acc.: 55.47%] [G loss: 0.911350]\n",
      "epoch:20 step:19477 [D loss: 0.676031, acc.: 58.59%] [G loss: 0.836220]\n",
      "epoch:20 step:19478 [D loss: 0.679163, acc.: 53.12%] [G loss: 0.864433]\n",
      "epoch:20 step:19479 [D loss: 0.658925, acc.: 62.50%] [G loss: 0.869368]\n",
      "epoch:20 step:19480 [D loss: 0.670238, acc.: 57.03%] [G loss: 0.883360]\n",
      "epoch:20 step:19481 [D loss: 0.675812, acc.: 56.25%] [G loss: 0.838239]\n",
      "epoch:20 step:19482 [D loss: 0.665082, acc.: 60.94%] [G loss: 0.853491]\n",
      "epoch:20 step:19483 [D loss: 0.683330, acc.: 60.94%] [G loss: 0.844555]\n",
      "epoch:20 step:19484 [D loss: 0.656057, acc.: 62.50%] [G loss: 0.840290]\n",
      "epoch:20 step:19485 [D loss: 0.633836, acc.: 59.38%] [G loss: 0.918983]\n",
      "epoch:20 step:19486 [D loss: 0.659913, acc.: 60.94%] [G loss: 0.827294]\n",
      "epoch:20 step:19487 [D loss: 0.649516, acc.: 63.28%] [G loss: 0.845979]\n",
      "epoch:20 step:19488 [D loss: 0.616405, acc.: 62.50%] [G loss: 0.840489]\n",
      "epoch:20 step:19489 [D loss: 0.674423, acc.: 58.59%] [G loss: 0.840069]\n",
      "epoch:20 step:19490 [D loss: 0.647283, acc.: 64.06%] [G loss: 0.932339]\n",
      "epoch:20 step:19491 [D loss: 0.663505, acc.: 60.16%] [G loss: 0.927377]\n",
      "epoch:20 step:19492 [D loss: 0.646588, acc.: 59.38%] [G loss: 0.963872]\n",
      "epoch:20 step:19493 [D loss: 0.679499, acc.: 50.78%] [G loss: 0.899058]\n",
      "epoch:20 step:19494 [D loss: 0.664025, acc.: 60.16%] [G loss: 0.893614]\n",
      "epoch:20 step:19495 [D loss: 0.692894, acc.: 57.03%] [G loss: 0.929255]\n",
      "epoch:20 step:19496 [D loss: 0.678460, acc.: 59.38%] [G loss: 0.892662]\n",
      "epoch:20 step:19497 [D loss: 0.618741, acc.: 70.31%] [G loss: 0.876648]\n",
      "epoch:20 step:19498 [D loss: 0.655414, acc.: 59.38%] [G loss: 0.870031]\n",
      "epoch:20 step:19499 [D loss: 0.655757, acc.: 65.62%] [G loss: 0.850871]\n",
      "epoch:20 step:19500 [D loss: 0.650374, acc.: 63.28%] [G loss: 0.841581]\n",
      "epoch:20 step:19501 [D loss: 0.675172, acc.: 58.59%] [G loss: 0.859090]\n",
      "epoch:20 step:19502 [D loss: 0.674553, acc.: 50.78%] [G loss: 0.869135]\n",
      "epoch:20 step:19503 [D loss: 0.665543, acc.: 57.03%] [G loss: 0.842457]\n",
      "epoch:20 step:19504 [D loss: 0.665923, acc.: 64.06%] [G loss: 0.881564]\n",
      "epoch:20 step:19505 [D loss: 0.668607, acc.: 57.03%] [G loss: 0.873844]\n",
      "epoch:20 step:19506 [D loss: 0.644107, acc.: 65.62%] [G loss: 0.870898]\n",
      "epoch:20 step:19507 [D loss: 0.671443, acc.: 57.81%] [G loss: 0.842771]\n",
      "epoch:20 step:19508 [D loss: 0.647785, acc.: 62.50%] [G loss: 0.889215]\n",
      "epoch:20 step:19509 [D loss: 0.677004, acc.: 60.16%] [G loss: 0.853471]\n",
      "epoch:20 step:19510 [D loss: 0.631750, acc.: 64.84%] [G loss: 0.833317]\n",
      "epoch:20 step:19511 [D loss: 0.683790, acc.: 58.59%] [G loss: 0.823520]\n",
      "epoch:20 step:19512 [D loss: 0.684581, acc.: 64.06%] [G loss: 0.851700]\n",
      "epoch:20 step:19513 [D loss: 0.673477, acc.: 55.47%] [G loss: 0.879027]\n",
      "epoch:20 step:19514 [D loss: 0.656059, acc.: 59.38%] [G loss: 0.864365]\n",
      "epoch:20 step:19515 [D loss: 0.653476, acc.: 59.38%] [G loss: 0.908918]\n",
      "epoch:20 step:19516 [D loss: 0.677546, acc.: 52.34%] [G loss: 0.898465]\n",
      "epoch:20 step:19517 [D loss: 0.679000, acc.: 57.81%] [G loss: 0.858068]\n",
      "epoch:20 step:19518 [D loss: 0.631546, acc.: 65.62%] [G loss: 0.840266]\n",
      "epoch:20 step:19519 [D loss: 0.658489, acc.: 60.16%] [G loss: 0.853973]\n",
      "epoch:20 step:19520 [D loss: 0.659161, acc.: 60.16%] [G loss: 0.833934]\n",
      "epoch:20 step:19521 [D loss: 0.673502, acc.: 55.47%] [G loss: 0.876044]\n",
      "epoch:20 step:19522 [D loss: 0.641883, acc.: 62.50%] [G loss: 0.793549]\n",
      "epoch:20 step:19523 [D loss: 0.676787, acc.: 53.12%] [G loss: 0.853765]\n",
      "epoch:20 step:19524 [D loss: 0.688256, acc.: 56.25%] [G loss: 0.848495]\n",
      "epoch:20 step:19525 [D loss: 0.670981, acc.: 56.25%] [G loss: 0.871845]\n",
      "epoch:20 step:19526 [D loss: 0.676619, acc.: 58.59%] [G loss: 0.870194]\n",
      "epoch:20 step:19527 [D loss: 0.655905, acc.: 53.91%] [G loss: 0.890643]\n",
      "epoch:20 step:19528 [D loss: 0.662045, acc.: 59.38%] [G loss: 0.896533]\n",
      "epoch:20 step:19529 [D loss: 0.658122, acc.: 61.72%] [G loss: 0.911654]\n",
      "epoch:20 step:19530 [D loss: 0.655071, acc.: 58.59%] [G loss: 0.926624]\n",
      "epoch:20 step:19531 [D loss: 0.643310, acc.: 59.38%] [G loss: 0.935912]\n",
      "epoch:20 step:19532 [D loss: 0.665323, acc.: 57.81%] [G loss: 0.924307]\n",
      "epoch:20 step:19533 [D loss: 0.643954, acc.: 64.06%] [G loss: 0.864783]\n",
      "epoch:20 step:19534 [D loss: 0.646472, acc.: 64.06%] [G loss: 0.833947]\n",
      "epoch:20 step:19535 [D loss: 0.657699, acc.: 62.50%] [G loss: 0.891360]\n",
      "epoch:20 step:19536 [D loss: 0.639743, acc.: 64.06%] [G loss: 0.881146]\n",
      "epoch:20 step:19537 [D loss: 0.680491, acc.: 56.25%] [G loss: 0.902515]\n",
      "epoch:20 step:19538 [D loss: 0.648238, acc.: 60.16%] [G loss: 0.880728]\n",
      "epoch:20 step:19539 [D loss: 0.652197, acc.: 61.72%] [G loss: 0.854918]\n",
      "epoch:20 step:19540 [D loss: 0.645996, acc.: 61.72%] [G loss: 0.896540]\n",
      "epoch:20 step:19541 [D loss: 0.637313, acc.: 65.62%] [G loss: 0.862241]\n",
      "epoch:20 step:19542 [D loss: 0.652842, acc.: 62.50%] [G loss: 0.871921]\n",
      "epoch:20 step:19543 [D loss: 0.666739, acc.: 60.94%] [G loss: 0.869279]\n",
      "epoch:20 step:19544 [D loss: 0.670541, acc.: 56.25%] [G loss: 0.848511]\n",
      "epoch:20 step:19545 [D loss: 0.664743, acc.: 61.72%] [G loss: 0.866478]\n",
      "epoch:20 step:19546 [D loss: 0.634577, acc.: 64.06%] [G loss: 0.899265]\n",
      "epoch:20 step:19547 [D loss: 0.668236, acc.: 53.12%] [G loss: 0.910471]\n",
      "epoch:20 step:19548 [D loss: 0.646105, acc.: 64.06%] [G loss: 0.878736]\n",
      "epoch:20 step:19549 [D loss: 0.638947, acc.: 67.19%] [G loss: 0.920126]\n",
      "epoch:20 step:19550 [D loss: 0.624725, acc.: 62.50%] [G loss: 0.851162]\n",
      "epoch:20 step:19551 [D loss: 0.673136, acc.: 58.59%] [G loss: 0.834302]\n",
      "epoch:20 step:19552 [D loss: 0.656398, acc.: 61.72%] [G loss: 0.911872]\n",
      "epoch:20 step:19553 [D loss: 0.695723, acc.: 57.03%] [G loss: 0.851095]\n",
      "epoch:20 step:19554 [D loss: 0.677227, acc.: 54.69%] [G loss: 0.891822]\n",
      "epoch:20 step:19555 [D loss: 0.676326, acc.: 54.69%] [G loss: 0.877556]\n",
      "epoch:20 step:19556 [D loss: 0.643602, acc.: 64.84%] [G loss: 0.889905]\n",
      "epoch:20 step:19557 [D loss: 0.657428, acc.: 57.03%] [G loss: 0.877415]\n",
      "epoch:20 step:19558 [D loss: 0.658438, acc.: 57.03%] [G loss: 0.850118]\n",
      "epoch:20 step:19559 [D loss: 0.669453, acc.: 60.94%] [G loss: 0.888936]\n",
      "epoch:20 step:19560 [D loss: 0.701002, acc.: 53.12%] [G loss: 0.835628]\n",
      "epoch:20 step:19561 [D loss: 0.668852, acc.: 55.47%] [G loss: 0.903304]\n",
      "epoch:20 step:19562 [D loss: 0.666751, acc.: 60.16%] [G loss: 0.882813]\n",
      "epoch:20 step:19563 [D loss: 0.707335, acc.: 50.00%] [G loss: 0.807761]\n",
      "epoch:20 step:19564 [D loss: 0.690225, acc.: 58.59%] [G loss: 0.887258]\n",
      "epoch:20 step:19565 [D loss: 0.660765, acc.: 57.03%] [G loss: 0.892234]\n",
      "epoch:20 step:19566 [D loss: 0.638186, acc.: 61.72%] [G loss: 0.931316]\n",
      "epoch:20 step:19567 [D loss: 0.649953, acc.: 67.97%] [G loss: 0.871873]\n",
      "epoch:20 step:19568 [D loss: 0.657702, acc.: 65.62%] [G loss: 0.895577]\n",
      "epoch:20 step:19569 [D loss: 0.641132, acc.: 60.94%] [G loss: 0.864829]\n",
      "epoch:20 step:19570 [D loss: 0.672917, acc.: 50.78%] [G loss: 0.871841]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:20 step:19571 [D loss: 0.667406, acc.: 60.16%] [G loss: 0.853445]\n",
      "epoch:20 step:19572 [D loss: 0.683230, acc.: 57.03%] [G loss: 0.850726]\n",
      "epoch:20 step:19573 [D loss: 0.719142, acc.: 46.88%] [G loss: 0.898103]\n",
      "epoch:20 step:19574 [D loss: 0.657676, acc.: 57.81%] [G loss: 0.858705]\n",
      "epoch:20 step:19575 [D loss: 0.653700, acc.: 63.28%] [G loss: 0.894996]\n",
      "epoch:20 step:19576 [D loss: 0.640304, acc.: 68.75%] [G loss: 0.890316]\n",
      "epoch:20 step:19577 [D loss: 0.710922, acc.: 53.12%] [G loss: 0.879632]\n",
      "epoch:20 step:19578 [D loss: 0.666963, acc.: 54.69%] [G loss: 0.892748]\n",
      "epoch:20 step:19579 [D loss: 0.680426, acc.: 54.69%] [G loss: 0.908511]\n",
      "epoch:20 step:19580 [D loss: 0.656651, acc.: 62.50%] [G loss: 0.837014]\n",
      "epoch:20 step:19581 [D loss: 0.651820, acc.: 60.94%] [G loss: 0.895519]\n",
      "epoch:20 step:19582 [D loss: 0.662388, acc.: 58.59%] [G loss: 0.898293]\n",
      "epoch:20 step:19583 [D loss: 0.712180, acc.: 50.00%] [G loss: 0.875670]\n",
      "epoch:20 step:19584 [D loss: 0.666409, acc.: 61.72%] [G loss: 0.979728]\n",
      "epoch:20 step:19585 [D loss: 0.664298, acc.: 57.81%] [G loss: 0.947388]\n",
      "epoch:20 step:19586 [D loss: 0.656298, acc.: 63.28%] [G loss: 0.837719]\n",
      "epoch:20 step:19587 [D loss: 0.661169, acc.: 59.38%] [G loss: 0.842503]\n",
      "epoch:20 step:19588 [D loss: 0.636816, acc.: 62.50%] [G loss: 0.867606]\n",
      "epoch:20 step:19589 [D loss: 0.665909, acc.: 59.38%] [G loss: 0.832056]\n",
      "epoch:20 step:19590 [D loss: 0.656341, acc.: 59.38%] [G loss: 0.838361]\n",
      "epoch:20 step:19591 [D loss: 0.673503, acc.: 59.38%] [G loss: 0.861307]\n",
      "epoch:20 step:19592 [D loss: 0.654676, acc.: 63.28%] [G loss: 0.839367]\n",
      "epoch:20 step:19593 [D loss: 0.710344, acc.: 52.34%] [G loss: 0.840303]\n",
      "epoch:20 step:19594 [D loss: 0.649761, acc.: 63.28%] [G loss: 0.877897]\n",
      "epoch:20 step:19595 [D loss: 0.680327, acc.: 57.81%] [G loss: 0.860426]\n",
      "epoch:20 step:19596 [D loss: 0.636301, acc.: 65.62%] [G loss: 0.859188]\n",
      "epoch:20 step:19597 [D loss: 0.678733, acc.: 57.03%] [G loss: 0.836230]\n",
      "epoch:20 step:19598 [D loss: 0.671610, acc.: 56.25%] [G loss: 0.877356]\n",
      "epoch:20 step:19599 [D loss: 0.682764, acc.: 54.69%] [G loss: 0.893032]\n",
      "epoch:20 step:19600 [D loss: 0.694712, acc.: 54.69%] [G loss: 0.892510]\n",
      "##############\n",
      "[2.69880125 2.38711251 2.08359124 3.75078459 1.50358772 6.01230692\n",
      " 2.72263713 3.54106308 4.28203129 7.14868929]\n",
      "##########\n",
      "epoch:20 step:19601 [D loss: 0.674072, acc.: 57.81%] [G loss: 0.878717]\n",
      "epoch:20 step:19602 [D loss: 0.658869, acc.: 58.59%] [G loss: 0.876550]\n",
      "epoch:20 step:19603 [D loss: 0.664873, acc.: 65.62%] [G loss: 0.866958]\n",
      "epoch:20 step:19604 [D loss: 0.677805, acc.: 56.25%] [G loss: 0.891095]\n",
      "epoch:20 step:19605 [D loss: 0.657362, acc.: 58.59%] [G loss: 0.875875]\n",
      "epoch:20 step:19606 [D loss: 0.713710, acc.: 52.34%] [G loss: 0.879992]\n",
      "epoch:20 step:19607 [D loss: 0.691160, acc.: 53.91%] [G loss: 0.896958]\n",
      "epoch:20 step:19608 [D loss: 0.659333, acc.: 62.50%] [G loss: 0.825299]\n",
      "epoch:20 step:19609 [D loss: 0.636990, acc.: 64.84%] [G loss: 0.885335]\n",
      "epoch:20 step:19610 [D loss: 0.663589, acc.: 57.03%] [G loss: 0.839926]\n",
      "epoch:20 step:19611 [D loss: 0.644788, acc.: 64.06%] [G loss: 0.881747]\n",
      "epoch:20 step:19612 [D loss: 0.667210, acc.: 60.16%] [G loss: 0.820017]\n",
      "epoch:20 step:19613 [D loss: 0.665145, acc.: 53.91%] [G loss: 0.829238]\n",
      "epoch:20 step:19614 [D loss: 0.653932, acc.: 58.59%] [G loss: 0.861442]\n",
      "epoch:20 step:19615 [D loss: 0.653777, acc.: 57.81%] [G loss: 0.841833]\n",
      "epoch:20 step:19616 [D loss: 0.678844, acc.: 58.59%] [G loss: 0.897928]\n",
      "epoch:20 step:19617 [D loss: 0.648776, acc.: 59.38%] [G loss: 0.903193]\n",
      "epoch:20 step:19618 [D loss: 0.646586, acc.: 62.50%] [G loss: 0.897193]\n",
      "epoch:20 step:19619 [D loss: 0.673295, acc.: 56.25%] [G loss: 0.836906]\n",
      "epoch:20 step:19620 [D loss: 0.656241, acc.: 60.94%] [G loss: 0.868928]\n",
      "epoch:20 step:19621 [D loss: 0.664599, acc.: 60.16%] [G loss: 0.892830]\n",
      "epoch:20 step:19622 [D loss: 0.636283, acc.: 66.41%] [G loss: 0.890220]\n",
      "epoch:20 step:19623 [D loss: 0.654563, acc.: 64.84%] [G loss: 0.938442]\n",
      "epoch:20 step:19624 [D loss: 0.654634, acc.: 57.03%] [G loss: 0.853552]\n",
      "epoch:20 step:19625 [D loss: 0.678142, acc.: 57.03%] [G loss: 0.877019]\n",
      "epoch:20 step:19626 [D loss: 0.690428, acc.: 53.91%] [G loss: 0.862534]\n",
      "epoch:20 step:19627 [D loss: 0.651311, acc.: 61.72%] [G loss: 0.866151]\n",
      "epoch:20 step:19628 [D loss: 0.632646, acc.: 66.41%] [G loss: 0.890739]\n",
      "epoch:20 step:19629 [D loss: 0.666040, acc.: 60.94%] [G loss: 0.870331]\n",
      "epoch:20 step:19630 [D loss: 0.668825, acc.: 57.81%] [G loss: 0.842325]\n",
      "epoch:20 step:19631 [D loss: 0.664661, acc.: 60.94%] [G loss: 0.857606]\n",
      "epoch:20 step:19632 [D loss: 0.623144, acc.: 67.19%] [G loss: 0.867113]\n",
      "epoch:20 step:19633 [D loss: 0.681548, acc.: 56.25%] [G loss: 0.856975]\n",
      "epoch:20 step:19634 [D loss: 0.650391, acc.: 60.94%] [G loss: 0.899582]\n",
      "epoch:20 step:19635 [D loss: 0.632654, acc.: 66.41%] [G loss: 0.818542]\n",
      "epoch:20 step:19636 [D loss: 0.663176, acc.: 56.25%] [G loss: 0.868420]\n",
      "epoch:20 step:19637 [D loss: 0.644604, acc.: 65.62%] [G loss: 0.818511]\n",
      "epoch:20 step:19638 [D loss: 0.637735, acc.: 63.28%] [G loss: 0.835616]\n",
      "epoch:20 step:19639 [D loss: 0.655240, acc.: 59.38%] [G loss: 0.893483]\n",
      "epoch:20 step:19640 [D loss: 0.660205, acc.: 57.03%] [G loss: 0.945624]\n",
      "epoch:20 step:19641 [D loss: 0.673393, acc.: 57.81%] [G loss: 0.879711]\n",
      "epoch:20 step:19642 [D loss: 0.664179, acc.: 55.47%] [G loss: 0.819035]\n",
      "epoch:20 step:19643 [D loss: 0.658139, acc.: 62.50%] [G loss: 0.837364]\n",
      "epoch:20 step:19644 [D loss: 0.647686, acc.: 60.94%] [G loss: 0.858070]\n",
      "epoch:20 step:19645 [D loss: 0.689624, acc.: 56.25%] [G loss: 0.889479]\n",
      "epoch:20 step:19646 [D loss: 0.667533, acc.: 58.59%] [G loss: 0.962001]\n",
      "epoch:20 step:19647 [D loss: 0.656911, acc.: 57.81%] [G loss: 0.902549]\n",
      "epoch:20 step:19648 [D loss: 0.685016, acc.: 57.03%] [G loss: 0.974657]\n",
      "epoch:20 step:19649 [D loss: 0.664823, acc.: 60.16%] [G loss: 0.945156]\n",
      "epoch:20 step:19650 [D loss: 0.687585, acc.: 49.22%] [G loss: 0.915422]\n",
      "epoch:20 step:19651 [D loss: 0.635076, acc.: 64.84%] [G loss: 0.995931]\n",
      "epoch:20 step:19652 [D loss: 0.672935, acc.: 63.28%] [G loss: 0.905141]\n",
      "epoch:20 step:19653 [D loss: 0.686619, acc.: 51.56%] [G loss: 0.826997]\n",
      "epoch:20 step:19654 [D loss: 0.684472, acc.: 53.91%] [G loss: 0.879919]\n",
      "epoch:20 step:19655 [D loss: 0.701452, acc.: 50.78%] [G loss: 0.825450]\n",
      "epoch:20 step:19656 [D loss: 0.666057, acc.: 60.94%] [G loss: 0.854358]\n",
      "epoch:20 step:19657 [D loss: 0.659924, acc.: 56.25%] [G loss: 0.800393]\n",
      "epoch:20 step:19658 [D loss: 0.707097, acc.: 57.03%] [G loss: 0.833849]\n",
      "epoch:20 step:19659 [D loss: 0.626982, acc.: 65.62%] [G loss: 0.815153]\n",
      "epoch:20 step:19660 [D loss: 0.653805, acc.: 62.50%] [G loss: 0.855356]\n",
      "epoch:20 step:19661 [D loss: 0.713765, acc.: 47.66%] [G loss: 0.903326]\n",
      "epoch:20 step:19662 [D loss: 0.653114, acc.: 60.16%] [G loss: 0.904254]\n",
      "epoch:20 step:19663 [D loss: 0.641847, acc.: 60.94%] [G loss: 0.836181]\n",
      "epoch:20 step:19664 [D loss: 0.631405, acc.: 65.62%] [G loss: 0.886210]\n",
      "epoch:20 step:19665 [D loss: 0.658944, acc.: 58.59%] [G loss: 0.834949]\n",
      "epoch:20 step:19666 [D loss: 0.659212, acc.: 61.72%] [G loss: 0.888505]\n",
      "epoch:20 step:19667 [D loss: 0.662939, acc.: 55.47%] [G loss: 0.872153]\n",
      "epoch:20 step:19668 [D loss: 0.614146, acc.: 71.09%] [G loss: 0.805828]\n",
      "epoch:20 step:19669 [D loss: 0.696099, acc.: 54.69%] [G loss: 0.826644]\n",
      "epoch:20 step:19670 [D loss: 0.616525, acc.: 70.31%] [G loss: 0.858377]\n",
      "epoch:20 step:19671 [D loss: 0.683988, acc.: 53.91%] [G loss: 0.803027]\n",
      "epoch:20 step:19672 [D loss: 0.635387, acc.: 67.19%] [G loss: 0.868762]\n",
      "epoch:20 step:19673 [D loss: 0.649967, acc.: 58.59%] [G loss: 0.868598]\n",
      "epoch:20 step:19674 [D loss: 0.644569, acc.: 66.41%] [G loss: 0.869669]\n",
      "epoch:20 step:19675 [D loss: 0.655553, acc.: 57.81%] [G loss: 0.888749]\n",
      "epoch:20 step:19676 [D loss: 0.649104, acc.: 63.28%] [G loss: 0.905623]\n",
      "epoch:20 step:19677 [D loss: 0.668514, acc.: 57.03%] [G loss: 0.825758]\n",
      "epoch:21 step:19678 [D loss: 0.680911, acc.: 58.59%] [G loss: 0.888038]\n",
      "epoch:21 step:19679 [D loss: 0.640328, acc.: 66.41%] [G loss: 0.900220]\n",
      "epoch:21 step:19680 [D loss: 0.664914, acc.: 57.81%] [G loss: 0.924051]\n",
      "epoch:21 step:19681 [D loss: 0.633278, acc.: 63.28%] [G loss: 0.955996]\n",
      "epoch:21 step:19682 [D loss: 0.640359, acc.: 62.50%] [G loss: 0.880063]\n",
      "epoch:21 step:19683 [D loss: 0.655408, acc.: 56.25%] [G loss: 0.883153]\n",
      "epoch:21 step:19684 [D loss: 0.705956, acc.: 50.00%] [G loss: 0.865021]\n",
      "epoch:21 step:19685 [D loss: 0.670461, acc.: 55.47%] [G loss: 0.875258]\n",
      "epoch:21 step:19686 [D loss: 0.655043, acc.: 60.16%] [G loss: 0.853683]\n",
      "epoch:21 step:19687 [D loss: 0.661105, acc.: 65.62%] [G loss: 0.861138]\n",
      "epoch:21 step:19688 [D loss: 0.630784, acc.: 67.97%] [G loss: 0.855282]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:19689 [D loss: 0.642788, acc.: 64.06%] [G loss: 0.866138]\n",
      "epoch:21 step:19690 [D loss: 0.641661, acc.: 60.94%] [G loss: 0.896922]\n",
      "epoch:21 step:19691 [D loss: 0.657251, acc.: 62.50%] [G loss: 0.912534]\n",
      "epoch:21 step:19692 [D loss: 0.662618, acc.: 64.06%] [G loss: 0.862459]\n",
      "epoch:21 step:19693 [D loss: 0.653037, acc.: 59.38%] [G loss: 0.925294]\n",
      "epoch:21 step:19694 [D loss: 0.677359, acc.: 57.81%] [G loss: 0.871822]\n",
      "epoch:21 step:19695 [D loss: 0.698411, acc.: 52.34%] [G loss: 0.854948]\n",
      "epoch:21 step:19696 [D loss: 0.649978, acc.: 64.06%] [G loss: 0.875468]\n",
      "epoch:21 step:19697 [D loss: 0.683452, acc.: 60.16%] [G loss: 0.854830]\n",
      "epoch:21 step:19698 [D loss: 0.633679, acc.: 65.62%] [G loss: 0.901803]\n",
      "epoch:21 step:19699 [D loss: 0.683438, acc.: 53.12%] [G loss: 0.889858]\n",
      "epoch:21 step:19700 [D loss: 0.655387, acc.: 58.59%] [G loss: 0.891145]\n",
      "epoch:21 step:19701 [D loss: 0.693610, acc.: 59.38%] [G loss: 0.899871]\n",
      "epoch:21 step:19702 [D loss: 0.644352, acc.: 63.28%] [G loss: 0.951137]\n",
      "epoch:21 step:19703 [D loss: 0.633742, acc.: 67.19%] [G loss: 0.930870]\n",
      "epoch:21 step:19704 [D loss: 0.649501, acc.: 60.94%] [G loss: 0.876827]\n",
      "epoch:21 step:19705 [D loss: 0.628433, acc.: 63.28%] [G loss: 0.830233]\n",
      "epoch:21 step:19706 [D loss: 0.673683, acc.: 57.81%] [G loss: 0.908005]\n",
      "epoch:21 step:19707 [D loss: 0.665827, acc.: 57.81%] [G loss: 0.886532]\n",
      "epoch:21 step:19708 [D loss: 0.683253, acc.: 57.81%] [G loss: 0.853704]\n",
      "epoch:21 step:19709 [D loss: 0.652109, acc.: 64.06%] [G loss: 0.880659]\n",
      "epoch:21 step:19710 [D loss: 0.661954, acc.: 62.50%] [G loss: 0.890137]\n",
      "epoch:21 step:19711 [D loss: 0.656642, acc.: 63.28%] [G loss: 0.898857]\n",
      "epoch:21 step:19712 [D loss: 0.695099, acc.: 50.00%] [G loss: 0.880053]\n",
      "epoch:21 step:19713 [D loss: 0.646911, acc.: 64.06%] [G loss: 0.956013]\n",
      "epoch:21 step:19714 [D loss: 0.658094, acc.: 63.28%] [G loss: 0.930409]\n",
      "epoch:21 step:19715 [D loss: 0.707611, acc.: 54.69%] [G loss: 0.934083]\n",
      "epoch:21 step:19716 [D loss: 0.673299, acc.: 57.81%] [G loss: 0.914235]\n",
      "epoch:21 step:19717 [D loss: 0.714852, acc.: 52.34%] [G loss: 0.881704]\n",
      "epoch:21 step:19718 [D loss: 0.649784, acc.: 61.72%] [G loss: 0.861013]\n",
      "epoch:21 step:19719 [D loss: 0.655356, acc.: 57.81%] [G loss: 0.944275]\n",
      "epoch:21 step:19720 [D loss: 0.668459, acc.: 57.03%] [G loss: 0.857687]\n",
      "epoch:21 step:19721 [D loss: 0.649112, acc.: 56.25%] [G loss: 0.917059]\n",
      "epoch:21 step:19722 [D loss: 0.675253, acc.: 58.59%] [G loss: 0.854245]\n",
      "epoch:21 step:19723 [D loss: 0.654776, acc.: 57.81%] [G loss: 0.831697]\n",
      "epoch:21 step:19724 [D loss: 0.675532, acc.: 56.25%] [G loss: 0.866820]\n",
      "epoch:21 step:19725 [D loss: 0.632005, acc.: 68.75%] [G loss: 0.849893]\n",
      "epoch:21 step:19726 [D loss: 0.635878, acc.: 67.97%] [G loss: 0.895809]\n",
      "epoch:21 step:19727 [D loss: 0.650552, acc.: 60.16%] [G loss: 0.891631]\n",
      "epoch:21 step:19728 [D loss: 0.652804, acc.: 58.59%] [G loss: 0.935763]\n",
      "epoch:21 step:19729 [D loss: 0.628579, acc.: 64.84%] [G loss: 0.877424]\n",
      "epoch:21 step:19730 [D loss: 0.651688, acc.: 64.06%] [G loss: 0.864346]\n",
      "epoch:21 step:19731 [D loss: 0.657151, acc.: 59.38%] [G loss: 0.901018]\n",
      "epoch:21 step:19732 [D loss: 0.688827, acc.: 58.59%] [G loss: 0.891599]\n",
      "epoch:21 step:19733 [D loss: 0.644683, acc.: 64.06%] [G loss: 0.881659]\n",
      "epoch:21 step:19734 [D loss: 0.667803, acc.: 57.81%] [G loss: 0.870900]\n",
      "epoch:21 step:19735 [D loss: 0.665226, acc.: 60.16%] [G loss: 0.828476]\n",
      "epoch:21 step:19736 [D loss: 0.657282, acc.: 61.72%] [G loss: 0.869353]\n",
      "epoch:21 step:19737 [D loss: 0.683395, acc.: 56.25%] [G loss: 0.862048]\n",
      "epoch:21 step:19738 [D loss: 0.678950, acc.: 52.34%] [G loss: 0.893268]\n",
      "epoch:21 step:19739 [D loss: 0.627518, acc.: 67.97%] [G loss: 0.841837]\n",
      "epoch:21 step:19740 [D loss: 0.643541, acc.: 66.41%] [G loss: 0.831822]\n",
      "epoch:21 step:19741 [D loss: 0.690743, acc.: 53.12%] [G loss: 0.901938]\n",
      "epoch:21 step:19742 [D loss: 0.666879, acc.: 56.25%] [G loss: 0.850534]\n",
      "epoch:21 step:19743 [D loss: 0.651014, acc.: 58.59%] [G loss: 0.889365]\n",
      "epoch:21 step:19744 [D loss: 0.654662, acc.: 60.94%] [G loss: 0.875268]\n",
      "epoch:21 step:19745 [D loss: 0.657822, acc.: 62.50%] [G loss: 0.833350]\n",
      "epoch:21 step:19746 [D loss: 0.684922, acc.: 52.34%] [G loss: 0.857074]\n",
      "epoch:21 step:19747 [D loss: 0.661203, acc.: 55.47%] [G loss: 0.861771]\n",
      "epoch:21 step:19748 [D loss: 0.671245, acc.: 63.28%] [G loss: 0.929304]\n",
      "epoch:21 step:19749 [D loss: 0.650884, acc.: 60.94%] [G loss: 0.883180]\n",
      "epoch:21 step:19750 [D loss: 0.610575, acc.: 71.09%] [G loss: 0.887333]\n",
      "epoch:21 step:19751 [D loss: 0.691129, acc.: 59.38%] [G loss: 0.871595]\n",
      "epoch:21 step:19752 [D loss: 0.674545, acc.: 62.50%] [G loss: 0.900529]\n",
      "epoch:21 step:19753 [D loss: 0.666083, acc.: 57.81%] [G loss: 0.851875]\n",
      "epoch:21 step:19754 [D loss: 0.626996, acc.: 67.19%] [G loss: 0.837058]\n",
      "epoch:21 step:19755 [D loss: 0.682386, acc.: 56.25%] [G loss: 0.874436]\n",
      "epoch:21 step:19756 [D loss: 0.649556, acc.: 59.38%] [G loss: 0.899692]\n",
      "epoch:21 step:19757 [D loss: 0.680761, acc.: 52.34%] [G loss: 1.001408]\n",
      "epoch:21 step:19758 [D loss: 0.671521, acc.: 57.03%] [G loss: 0.872278]\n",
      "epoch:21 step:19759 [D loss: 0.632086, acc.: 65.62%] [G loss: 0.895484]\n",
      "epoch:21 step:19760 [D loss: 0.627748, acc.: 71.88%] [G loss: 0.840207]\n",
      "epoch:21 step:19761 [D loss: 0.661528, acc.: 66.41%] [G loss: 0.835718]\n",
      "epoch:21 step:19762 [D loss: 0.655774, acc.: 58.59%] [G loss: 0.847995]\n",
      "epoch:21 step:19763 [D loss: 0.647823, acc.: 65.62%] [G loss: 0.879433]\n",
      "epoch:21 step:19764 [D loss: 0.661578, acc.: 60.94%] [G loss: 0.849583]\n",
      "epoch:21 step:19765 [D loss: 0.679847, acc.: 58.59%] [G loss: 0.806038]\n",
      "epoch:21 step:19766 [D loss: 0.661358, acc.: 64.84%] [G loss: 0.857731]\n",
      "epoch:21 step:19767 [D loss: 0.687557, acc.: 57.81%] [G loss: 0.855712]\n",
      "epoch:21 step:19768 [D loss: 0.691873, acc.: 56.25%] [G loss: 0.905248]\n",
      "epoch:21 step:19769 [D loss: 0.648038, acc.: 63.28%] [G loss: 0.931323]\n",
      "epoch:21 step:19770 [D loss: 0.625456, acc.: 67.97%] [G loss: 0.939558]\n",
      "epoch:21 step:19771 [D loss: 0.654209, acc.: 65.62%] [G loss: 0.858083]\n",
      "epoch:21 step:19772 [D loss: 0.684879, acc.: 55.47%] [G loss: 0.869507]\n",
      "epoch:21 step:19773 [D loss: 0.696771, acc.: 60.16%] [G loss: 0.864019]\n",
      "epoch:21 step:19774 [D loss: 0.652251, acc.: 65.62%] [G loss: 0.873067]\n",
      "epoch:21 step:19775 [D loss: 0.651042, acc.: 64.06%] [G loss: 0.847247]\n",
      "epoch:21 step:19776 [D loss: 0.666820, acc.: 61.72%] [G loss: 0.851515]\n",
      "epoch:21 step:19777 [D loss: 0.675812, acc.: 57.03%] [G loss: 0.876102]\n",
      "epoch:21 step:19778 [D loss: 0.642581, acc.: 65.62%] [G loss: 0.919797]\n",
      "epoch:21 step:19779 [D loss: 0.690298, acc.: 60.16%] [G loss: 0.855060]\n",
      "epoch:21 step:19780 [D loss: 0.628778, acc.: 63.28%] [G loss: 0.867978]\n",
      "epoch:21 step:19781 [D loss: 0.690087, acc.: 56.25%] [G loss: 0.868374]\n",
      "epoch:21 step:19782 [D loss: 0.669374, acc.: 58.59%] [G loss: 0.890881]\n",
      "epoch:21 step:19783 [D loss: 0.627345, acc.: 64.06%] [G loss: 0.902982]\n",
      "epoch:21 step:19784 [D loss: 0.664412, acc.: 59.38%] [G loss: 0.856265]\n",
      "epoch:21 step:19785 [D loss: 0.672944, acc.: 60.16%] [G loss: 0.864536]\n",
      "epoch:21 step:19786 [D loss: 0.654065, acc.: 57.81%] [G loss: 0.887378]\n",
      "epoch:21 step:19787 [D loss: 0.656808, acc.: 54.69%] [G loss: 0.889117]\n",
      "epoch:21 step:19788 [D loss: 0.682436, acc.: 54.69%] [G loss: 0.852786]\n",
      "epoch:21 step:19789 [D loss: 0.665546, acc.: 60.94%] [G loss: 0.853142]\n",
      "epoch:21 step:19790 [D loss: 0.647830, acc.: 60.16%] [G loss: 0.948021]\n",
      "epoch:21 step:19791 [D loss: 0.643222, acc.: 60.94%] [G loss: 0.900694]\n",
      "epoch:21 step:19792 [D loss: 0.683404, acc.: 55.47%] [G loss: 0.891488]\n",
      "epoch:21 step:19793 [D loss: 0.653934, acc.: 64.06%] [G loss: 0.787927]\n",
      "epoch:21 step:19794 [D loss: 0.675913, acc.: 56.25%] [G loss: 0.832034]\n",
      "epoch:21 step:19795 [D loss: 0.681354, acc.: 58.59%] [G loss: 0.820482]\n",
      "epoch:21 step:19796 [D loss: 0.659987, acc.: 57.81%] [G loss: 0.867293]\n",
      "epoch:21 step:19797 [D loss: 0.691727, acc.: 57.81%] [G loss: 0.900765]\n",
      "epoch:21 step:19798 [D loss: 0.618288, acc.: 69.53%] [G loss: 0.893346]\n",
      "epoch:21 step:19799 [D loss: 0.695618, acc.: 53.91%] [G loss: 0.881639]\n",
      "epoch:21 step:19800 [D loss: 0.661599, acc.: 57.03%] [G loss: 0.873960]\n",
      "##############\n",
      "[3.21078534 2.32984103 2.61654552 3.65878214 1.5902434  7.25492526\n",
      " 2.65215054 3.4317416  4.16242619 7.14868929]\n",
      "##########\n",
      "epoch:21 step:19801 [D loss: 0.701247, acc.: 52.34%] [G loss: 0.855229]\n",
      "epoch:21 step:19802 [D loss: 0.670259, acc.: 57.81%] [G loss: 0.822284]\n",
      "epoch:21 step:19803 [D loss: 0.702181, acc.: 46.88%] [G loss: 0.829566]\n",
      "epoch:21 step:19804 [D loss: 0.645012, acc.: 64.06%] [G loss: 0.825933]\n",
      "epoch:21 step:19805 [D loss: 0.624495, acc.: 69.53%] [G loss: 0.830018]\n",
      "epoch:21 step:19806 [D loss: 0.630761, acc.: 62.50%] [G loss: 0.856636]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:19807 [D loss: 0.660935, acc.: 64.06%] [G loss: 0.877060]\n",
      "epoch:21 step:19808 [D loss: 0.627253, acc.: 67.19%] [G loss: 0.896567]\n",
      "epoch:21 step:19809 [D loss: 0.675116, acc.: 53.91%] [G loss: 0.911292]\n",
      "epoch:21 step:19810 [D loss: 0.659657, acc.: 59.38%] [G loss: 0.862443]\n",
      "epoch:21 step:19811 [D loss: 0.690839, acc.: 51.56%] [G loss: 0.894847]\n",
      "epoch:21 step:19812 [D loss: 0.669707, acc.: 56.25%] [G loss: 0.863798]\n",
      "epoch:21 step:19813 [D loss: 0.661750, acc.: 58.59%] [G loss: 0.882352]\n",
      "epoch:21 step:19814 [D loss: 0.665124, acc.: 58.59%] [G loss: 0.827991]\n",
      "epoch:21 step:19815 [D loss: 0.653350, acc.: 60.16%] [G loss: 0.817071]\n",
      "epoch:21 step:19816 [D loss: 0.634167, acc.: 67.97%] [G loss: 0.832287]\n",
      "epoch:21 step:19817 [D loss: 0.697987, acc.: 54.69%] [G loss: 0.837680]\n",
      "epoch:21 step:19818 [D loss: 0.692463, acc.: 50.78%] [G loss: 0.864160]\n",
      "epoch:21 step:19819 [D loss: 0.649432, acc.: 64.84%] [G loss: 0.817238]\n",
      "epoch:21 step:19820 [D loss: 0.664273, acc.: 58.59%] [G loss: 0.852988]\n",
      "epoch:21 step:19821 [D loss: 0.665164, acc.: 57.03%] [G loss: 0.880670]\n",
      "epoch:21 step:19822 [D loss: 0.674720, acc.: 57.03%] [G loss: 0.838153]\n",
      "epoch:21 step:19823 [D loss: 0.675037, acc.: 58.59%] [G loss: 0.848804]\n",
      "epoch:21 step:19824 [D loss: 0.667415, acc.: 60.16%] [G loss: 0.851934]\n",
      "epoch:21 step:19825 [D loss: 0.647094, acc.: 61.72%] [G loss: 0.911919]\n",
      "epoch:21 step:19826 [D loss: 0.686453, acc.: 53.91%] [G loss: 0.853226]\n",
      "epoch:21 step:19827 [D loss: 0.665735, acc.: 60.94%] [G loss: 0.915806]\n",
      "epoch:21 step:19828 [D loss: 0.673396, acc.: 55.47%] [G loss: 0.897679]\n",
      "epoch:21 step:19829 [D loss: 0.682268, acc.: 53.91%] [G loss: 0.839264]\n",
      "epoch:21 step:19830 [D loss: 0.653039, acc.: 59.38%] [G loss: 0.868895]\n",
      "epoch:21 step:19831 [D loss: 0.641519, acc.: 60.16%] [G loss: 0.796768]\n",
      "epoch:21 step:19832 [D loss: 0.642582, acc.: 60.94%] [G loss: 0.842791]\n",
      "epoch:21 step:19833 [D loss: 0.654353, acc.: 60.94%] [G loss: 0.877648]\n",
      "epoch:21 step:19834 [D loss: 0.655412, acc.: 58.59%] [G loss: 0.804768]\n",
      "epoch:21 step:19835 [D loss: 0.643496, acc.: 69.53%] [G loss: 0.883069]\n",
      "epoch:21 step:19836 [D loss: 0.620890, acc.: 64.06%] [G loss: 0.903449]\n",
      "epoch:21 step:19837 [D loss: 0.656051, acc.: 57.81%] [G loss: 0.847787]\n",
      "epoch:21 step:19838 [D loss: 0.681969, acc.: 58.59%] [G loss: 0.862900]\n",
      "epoch:21 step:19839 [D loss: 0.653884, acc.: 64.84%] [G loss: 0.879601]\n",
      "epoch:21 step:19840 [D loss: 0.667701, acc.: 57.81%] [G loss: 0.881516]\n",
      "epoch:21 step:19841 [D loss: 0.679990, acc.: 57.03%] [G loss: 0.878018]\n",
      "epoch:21 step:19842 [D loss: 0.689151, acc.: 55.47%] [G loss: 0.880467]\n",
      "epoch:21 step:19843 [D loss: 0.646863, acc.: 62.50%] [G loss: 0.891749]\n",
      "epoch:21 step:19844 [D loss: 0.631796, acc.: 62.50%] [G loss: 0.872940]\n",
      "epoch:21 step:19845 [D loss: 0.643637, acc.: 60.94%] [G loss: 0.852178]\n",
      "epoch:21 step:19846 [D loss: 0.663273, acc.: 61.72%] [G loss: 0.889296]\n",
      "epoch:21 step:19847 [D loss: 0.643792, acc.: 65.62%] [G loss: 0.898714]\n",
      "epoch:21 step:19848 [D loss: 0.664723, acc.: 56.25%] [G loss: 0.950968]\n",
      "epoch:21 step:19849 [D loss: 0.671714, acc.: 57.03%] [G loss: 0.917953]\n",
      "epoch:21 step:19850 [D loss: 0.693673, acc.: 53.12%] [G loss: 0.829108]\n",
      "epoch:21 step:19851 [D loss: 0.643429, acc.: 65.62%] [G loss: 0.876587]\n",
      "epoch:21 step:19852 [D loss: 0.691036, acc.: 60.94%] [G loss: 0.862751]\n",
      "epoch:21 step:19853 [D loss: 0.642155, acc.: 62.50%] [G loss: 0.882237]\n",
      "epoch:21 step:19854 [D loss: 0.646322, acc.: 61.72%] [G loss: 0.898251]\n",
      "epoch:21 step:19855 [D loss: 0.673705, acc.: 54.69%] [G loss: 0.886886]\n",
      "epoch:21 step:19856 [D loss: 0.673932, acc.: 56.25%] [G loss: 0.854631]\n",
      "epoch:21 step:19857 [D loss: 0.652807, acc.: 62.50%] [G loss: 0.855322]\n",
      "epoch:21 step:19858 [D loss: 0.697417, acc.: 54.69%] [G loss: 0.860449]\n",
      "epoch:21 step:19859 [D loss: 0.666656, acc.: 59.38%] [G loss: 0.884648]\n",
      "epoch:21 step:19860 [D loss: 0.678050, acc.: 55.47%] [G loss: 0.866022]\n",
      "epoch:21 step:19861 [D loss: 0.663101, acc.: 59.38%] [G loss: 0.911902]\n",
      "epoch:21 step:19862 [D loss: 0.678397, acc.: 55.47%] [G loss: 0.880206]\n",
      "epoch:21 step:19863 [D loss: 0.664909, acc.: 57.03%] [G loss: 0.900858]\n",
      "epoch:21 step:19864 [D loss: 0.657242, acc.: 61.72%] [G loss: 0.902417]\n",
      "epoch:21 step:19865 [D loss: 0.671689, acc.: 60.94%] [G loss: 0.846471]\n",
      "epoch:21 step:19866 [D loss: 0.668753, acc.: 57.81%] [G loss: 0.905218]\n",
      "epoch:21 step:19867 [D loss: 0.643969, acc.: 64.06%] [G loss: 0.909897]\n",
      "epoch:21 step:19868 [D loss: 0.680900, acc.: 57.81%] [G loss: 0.902384]\n",
      "epoch:21 step:19869 [D loss: 0.662318, acc.: 58.59%] [G loss: 0.910496]\n",
      "epoch:21 step:19870 [D loss: 0.633105, acc.: 64.84%] [G loss: 0.880338]\n",
      "epoch:21 step:19871 [D loss: 0.673699, acc.: 60.16%] [G loss: 0.931790]\n",
      "epoch:21 step:19872 [D loss: 0.670093, acc.: 59.38%] [G loss: 0.943517]\n",
      "epoch:21 step:19873 [D loss: 0.676982, acc.: 51.56%] [G loss: 0.892300]\n",
      "epoch:21 step:19874 [D loss: 0.612530, acc.: 64.84%] [G loss: 0.815709]\n",
      "epoch:21 step:19875 [D loss: 0.618154, acc.: 66.41%] [G loss: 0.896005]\n",
      "epoch:21 step:19876 [D loss: 0.665125, acc.: 64.06%] [G loss: 0.956272]\n",
      "epoch:21 step:19877 [D loss: 0.630939, acc.: 66.41%] [G loss: 0.846724]\n",
      "epoch:21 step:19878 [D loss: 0.668123, acc.: 57.03%] [G loss: 0.911832]\n",
      "epoch:21 step:19879 [D loss: 0.607631, acc.: 66.41%] [G loss: 0.851005]\n",
      "epoch:21 step:19880 [D loss: 0.646214, acc.: 60.94%] [G loss: 0.860499]\n",
      "epoch:21 step:19881 [D loss: 0.659684, acc.: 61.72%] [G loss: 0.855341]\n",
      "epoch:21 step:19882 [D loss: 0.656818, acc.: 59.38%] [G loss: 0.873375]\n",
      "epoch:21 step:19883 [D loss: 0.676291, acc.: 56.25%] [G loss: 0.838604]\n",
      "epoch:21 step:19884 [D loss: 0.650511, acc.: 60.16%] [G loss: 0.852040]\n",
      "epoch:21 step:19885 [D loss: 0.669490, acc.: 60.94%] [G loss: 0.859349]\n",
      "epoch:21 step:19886 [D loss: 0.681661, acc.: 51.56%] [G loss: 0.799757]\n",
      "epoch:21 step:19887 [D loss: 0.634671, acc.: 65.62%] [G loss: 0.842443]\n",
      "epoch:21 step:19888 [D loss: 0.661367, acc.: 57.81%] [G loss: 0.848737]\n",
      "epoch:21 step:19889 [D loss: 0.678404, acc.: 54.69%] [G loss: 0.880399]\n",
      "epoch:21 step:19890 [D loss: 0.667722, acc.: 57.81%] [G loss: 0.891045]\n",
      "epoch:21 step:19891 [D loss: 0.654390, acc.: 59.38%] [G loss: 0.921535]\n",
      "epoch:21 step:19892 [D loss: 0.675240, acc.: 60.94%] [G loss: 0.895170]\n",
      "epoch:21 step:19893 [D loss: 0.667321, acc.: 53.12%] [G loss: 0.840343]\n",
      "epoch:21 step:19894 [D loss: 0.645037, acc.: 59.38%] [G loss: 0.814050]\n",
      "epoch:21 step:19895 [D loss: 0.670908, acc.: 55.47%] [G loss: 0.791201]\n",
      "epoch:21 step:19896 [D loss: 0.690281, acc.: 60.16%] [G loss: 0.815383]\n",
      "epoch:21 step:19897 [D loss: 0.664196, acc.: 59.38%] [G loss: 0.820649]\n",
      "epoch:21 step:19898 [D loss: 0.674913, acc.: 53.12%] [G loss: 0.820348]\n",
      "epoch:21 step:19899 [D loss: 0.691676, acc.: 52.34%] [G loss: 0.843294]\n",
      "epoch:21 step:19900 [D loss: 0.662982, acc.: 58.59%] [G loss: 0.859640]\n",
      "epoch:21 step:19901 [D loss: 0.669380, acc.: 57.03%] [G loss: 0.879381]\n",
      "epoch:21 step:19902 [D loss: 0.644815, acc.: 62.50%] [G loss: 0.893158]\n",
      "epoch:21 step:19903 [D loss: 0.661501, acc.: 60.94%] [G loss: 0.848906]\n",
      "epoch:21 step:19904 [D loss: 0.634191, acc.: 67.19%] [G loss: 0.877517]\n",
      "epoch:21 step:19905 [D loss: 0.691916, acc.: 56.25%] [G loss: 0.887220]\n",
      "epoch:21 step:19906 [D loss: 0.650720, acc.: 60.94%] [G loss: 0.906461]\n",
      "epoch:21 step:19907 [D loss: 0.692134, acc.: 52.34%] [G loss: 0.886733]\n",
      "epoch:21 step:19908 [D loss: 0.648292, acc.: 66.41%] [G loss: 0.879158]\n",
      "epoch:21 step:19909 [D loss: 0.637144, acc.: 59.38%] [G loss: 0.917787]\n",
      "epoch:21 step:19910 [D loss: 0.649476, acc.: 59.38%] [G loss: 0.894831]\n",
      "epoch:21 step:19911 [D loss: 0.645271, acc.: 63.28%] [G loss: 0.888059]\n",
      "epoch:21 step:19912 [D loss: 0.679180, acc.: 56.25%] [G loss: 0.876200]\n",
      "epoch:21 step:19913 [D loss: 0.652428, acc.: 60.94%] [G loss: 0.859855]\n",
      "epoch:21 step:19914 [D loss: 0.643357, acc.: 63.28%] [G loss: 0.948417]\n",
      "epoch:21 step:19915 [D loss: 0.647299, acc.: 61.72%] [G loss: 0.848821]\n",
      "epoch:21 step:19916 [D loss: 0.719412, acc.: 49.22%] [G loss: 0.830218]\n",
      "epoch:21 step:19917 [D loss: 0.658827, acc.: 57.81%] [G loss: 0.815669]\n",
      "epoch:21 step:19918 [D loss: 0.640784, acc.: 64.06%] [G loss: 0.824706]\n",
      "epoch:21 step:19919 [D loss: 0.673453, acc.: 56.25%] [G loss: 0.874961]\n",
      "epoch:21 step:19920 [D loss: 0.684232, acc.: 53.12%] [G loss: 0.861203]\n",
      "epoch:21 step:19921 [D loss: 0.667818, acc.: 59.38%] [G loss: 0.904985]\n",
      "epoch:21 step:19922 [D loss: 0.647810, acc.: 60.16%] [G loss: 0.917320]\n",
      "epoch:21 step:19923 [D loss: 0.634288, acc.: 65.62%] [G loss: 0.897803]\n",
      "epoch:21 step:19924 [D loss: 0.648374, acc.: 60.94%] [G loss: 0.898074]\n",
      "epoch:21 step:19925 [D loss: 0.657442, acc.: 59.38%] [G loss: 0.870367]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:19926 [D loss: 0.686157, acc.: 51.56%] [G loss: 0.858865]\n",
      "epoch:21 step:19927 [D loss: 0.638288, acc.: 67.19%] [G loss: 0.860615]\n",
      "epoch:21 step:19928 [D loss: 0.671060, acc.: 57.81%] [G loss: 0.843886]\n",
      "epoch:21 step:19929 [D loss: 0.681567, acc.: 57.03%] [G loss: 0.834078]\n",
      "epoch:21 step:19930 [D loss: 0.650550, acc.: 64.84%] [G loss: 0.864651]\n",
      "epoch:21 step:19931 [D loss: 0.666992, acc.: 59.38%] [G loss: 0.832933]\n",
      "epoch:21 step:19932 [D loss: 0.662810, acc.: 57.81%] [G loss: 0.824463]\n",
      "epoch:21 step:19933 [D loss: 0.662115, acc.: 58.59%] [G loss: 0.875315]\n",
      "epoch:21 step:19934 [D loss: 0.686970, acc.: 58.59%] [G loss: 0.899612]\n",
      "epoch:21 step:19935 [D loss: 0.679104, acc.: 53.12%] [G loss: 0.906864]\n",
      "epoch:21 step:19936 [D loss: 0.708135, acc.: 54.69%] [G loss: 0.892946]\n",
      "epoch:21 step:19937 [D loss: 0.671331, acc.: 61.72%] [G loss: 0.917286]\n",
      "epoch:21 step:19938 [D loss: 0.659136, acc.: 55.47%] [G loss: 0.843098]\n",
      "epoch:21 step:19939 [D loss: 0.711566, acc.: 49.22%] [G loss: 0.841017]\n",
      "epoch:21 step:19940 [D loss: 0.726635, acc.: 50.00%] [G loss: 0.906102]\n",
      "epoch:21 step:19941 [D loss: 0.688626, acc.: 57.03%] [G loss: 0.872262]\n",
      "epoch:21 step:19942 [D loss: 0.641084, acc.: 67.19%] [G loss: 0.862045]\n",
      "epoch:21 step:19943 [D loss: 0.636253, acc.: 63.28%] [G loss: 0.872760]\n",
      "epoch:21 step:19944 [D loss: 0.648410, acc.: 57.03%] [G loss: 0.942483]\n",
      "epoch:21 step:19945 [D loss: 0.690678, acc.: 50.00%] [G loss: 0.868069]\n",
      "epoch:21 step:19946 [D loss: 0.623983, acc.: 67.19%] [G loss: 0.883264]\n",
      "epoch:21 step:19947 [D loss: 0.694626, acc.: 53.91%] [G loss: 0.867553]\n",
      "epoch:21 step:19948 [D loss: 0.665646, acc.: 53.12%] [G loss: 0.899851]\n",
      "epoch:21 step:19949 [D loss: 0.677533, acc.: 60.16%] [G loss: 0.869331]\n",
      "epoch:21 step:19950 [D loss: 0.685664, acc.: 56.25%] [G loss: 0.859062]\n",
      "epoch:21 step:19951 [D loss: 0.684606, acc.: 53.91%] [G loss: 0.899975]\n",
      "epoch:21 step:19952 [D loss: 0.713123, acc.: 50.78%] [G loss: 0.892834]\n",
      "epoch:21 step:19953 [D loss: 0.671089, acc.: 60.16%] [G loss: 0.823036]\n",
      "epoch:21 step:19954 [D loss: 0.665129, acc.: 53.12%] [G loss: 0.864986]\n",
      "epoch:21 step:19955 [D loss: 0.670891, acc.: 54.69%] [G loss: 0.919609]\n",
      "epoch:21 step:19956 [D loss: 0.696606, acc.: 55.47%] [G loss: 0.887915]\n",
      "epoch:21 step:19957 [D loss: 0.661360, acc.: 60.94%] [G loss: 0.849420]\n",
      "epoch:21 step:19958 [D loss: 0.633508, acc.: 65.62%] [G loss: 0.922439]\n",
      "epoch:21 step:19959 [D loss: 0.664294, acc.: 58.59%] [G loss: 0.910485]\n",
      "epoch:21 step:19960 [D loss: 0.631308, acc.: 64.06%] [G loss: 0.888871]\n",
      "epoch:21 step:19961 [D loss: 0.607526, acc.: 66.41%] [G loss: 0.877642]\n",
      "epoch:21 step:19962 [D loss: 0.616331, acc.: 68.75%] [G loss: 0.889530]\n",
      "epoch:21 step:19963 [D loss: 0.697196, acc.: 52.34%] [G loss: 0.826664]\n",
      "epoch:21 step:19964 [D loss: 0.674203, acc.: 56.25%] [G loss: 0.867888]\n",
      "epoch:21 step:19965 [D loss: 0.645707, acc.: 62.50%] [G loss: 0.853851]\n",
      "epoch:21 step:19966 [D loss: 0.659821, acc.: 61.72%] [G loss: 0.903554]\n",
      "epoch:21 step:19967 [D loss: 0.657574, acc.: 60.94%] [G loss: 0.896587]\n",
      "epoch:21 step:19968 [D loss: 0.665297, acc.: 57.81%] [G loss: 0.875746]\n",
      "epoch:21 step:19969 [D loss: 0.677274, acc.: 59.38%] [G loss: 0.858856]\n",
      "epoch:21 step:19970 [D loss: 0.683027, acc.: 57.81%] [G loss: 0.902597]\n",
      "epoch:21 step:19971 [D loss: 0.652072, acc.: 65.62%] [G loss: 0.852546]\n",
      "epoch:21 step:19972 [D loss: 0.650990, acc.: 59.38%] [G loss: 0.869686]\n",
      "epoch:21 step:19973 [D loss: 0.648099, acc.: 64.06%] [G loss: 0.853240]\n",
      "epoch:21 step:19974 [D loss: 0.655762, acc.: 60.16%] [G loss: 0.854923]\n",
      "epoch:21 step:19975 [D loss: 0.637771, acc.: 65.62%] [G loss: 0.852830]\n",
      "epoch:21 step:19976 [D loss: 0.687941, acc.: 57.81%] [G loss: 0.885383]\n",
      "epoch:21 step:19977 [D loss: 0.650792, acc.: 53.12%] [G loss: 0.881050]\n",
      "epoch:21 step:19978 [D loss: 0.693737, acc.: 54.69%] [G loss: 0.866039]\n",
      "epoch:21 step:19979 [D loss: 0.623820, acc.: 68.75%] [G loss: 0.900118]\n",
      "epoch:21 step:19980 [D loss: 0.667685, acc.: 57.81%] [G loss: 0.852418]\n",
      "epoch:21 step:19981 [D loss: 0.595732, acc.: 70.31%] [G loss: 0.823511]\n",
      "epoch:21 step:19982 [D loss: 0.674750, acc.: 56.25%] [G loss: 0.842335]\n",
      "epoch:21 step:19983 [D loss: 0.660204, acc.: 52.34%] [G loss: 0.868739]\n",
      "epoch:21 step:19984 [D loss: 0.685710, acc.: 53.12%] [G loss: 0.890261]\n",
      "epoch:21 step:19985 [D loss: 0.642753, acc.: 59.38%] [G loss: 0.897819]\n",
      "epoch:21 step:19986 [D loss: 0.602791, acc.: 67.19%] [G loss: 0.862037]\n",
      "epoch:21 step:19987 [D loss: 0.685609, acc.: 57.03%] [G loss: 0.863996]\n",
      "epoch:21 step:19988 [D loss: 0.660174, acc.: 56.25%] [G loss: 0.839256]\n",
      "epoch:21 step:19989 [D loss: 0.670914, acc.: 57.03%] [G loss: 0.903393]\n",
      "epoch:21 step:19990 [D loss: 0.675410, acc.: 58.59%] [G loss: 0.860366]\n",
      "epoch:21 step:19991 [D loss: 0.645305, acc.: 58.59%] [G loss: 0.892058]\n",
      "epoch:21 step:19992 [D loss: 0.632274, acc.: 67.19%] [G loss: 0.952264]\n",
      "epoch:21 step:19993 [D loss: 0.671621, acc.: 59.38%] [G loss: 0.948479]\n",
      "epoch:21 step:19994 [D loss: 0.668922, acc.: 62.50%] [G loss: 0.879727]\n",
      "epoch:21 step:19995 [D loss: 0.688593, acc.: 52.34%] [G loss: 0.913381]\n",
      "epoch:21 step:19996 [D loss: 0.672650, acc.: 57.03%] [G loss: 0.928732]\n",
      "epoch:21 step:19997 [D loss: 0.651676, acc.: 64.84%] [G loss: 0.958782]\n",
      "epoch:21 step:19998 [D loss: 0.662959, acc.: 57.81%] [G loss: 0.911483]\n",
      "epoch:21 step:19999 [D loss: 0.671055, acc.: 57.81%] [G loss: 0.849766]\n",
      "epoch:21 step:20000 [D loss: 0.666328, acc.: 57.03%] [G loss: 0.872301]\n",
      "##############\n",
      "[ 3.07437054  2.41310209  2.09393378  3.94101055  1.56262641 10.27426719\n",
      "  2.80734912  4.12692089  4.19747886  6.37494725]\n",
      "##########\n",
      "epoch:21 step:20001 [D loss: 0.645185, acc.: 60.16%] [G loss: 0.903278]\n",
      "epoch:21 step:20002 [D loss: 0.709052, acc.: 55.47%] [G loss: 0.938308]\n",
      "epoch:21 step:20003 [D loss: 0.691840, acc.: 53.12%] [G loss: 0.874454]\n",
      "epoch:21 step:20004 [D loss: 0.615291, acc.: 67.97%] [G loss: 0.876248]\n",
      "epoch:21 step:20005 [D loss: 0.624595, acc.: 66.41%] [G loss: 0.907335]\n",
      "epoch:21 step:20006 [D loss: 0.650652, acc.: 58.59%] [G loss: 0.788033]\n",
      "epoch:21 step:20007 [D loss: 0.703000, acc.: 53.12%] [G loss: 0.822286]\n",
      "epoch:21 step:20008 [D loss: 0.672424, acc.: 57.03%] [G loss: 0.862309]\n",
      "epoch:21 step:20009 [D loss: 0.614498, acc.: 66.41%] [G loss: 0.895963]\n",
      "epoch:21 step:20010 [D loss: 0.682860, acc.: 56.25%] [G loss: 0.857960]\n",
      "epoch:21 step:20011 [D loss: 0.660279, acc.: 59.38%] [G loss: 0.863379]\n",
      "epoch:21 step:20012 [D loss: 0.672127, acc.: 56.25%] [G loss: 0.866392]\n",
      "epoch:21 step:20013 [D loss: 0.626103, acc.: 61.72%] [G loss: 0.868244]\n",
      "epoch:21 step:20014 [D loss: 0.662208, acc.: 57.81%] [G loss: 0.906793]\n",
      "epoch:21 step:20015 [D loss: 0.657598, acc.: 61.72%] [G loss: 0.921382]\n",
      "epoch:21 step:20016 [D loss: 0.637884, acc.: 68.75%] [G loss: 0.890553]\n",
      "epoch:21 step:20017 [D loss: 0.644959, acc.: 64.84%] [G loss: 0.866998]\n",
      "epoch:21 step:20018 [D loss: 0.655998, acc.: 64.06%] [G loss: 0.899917]\n",
      "epoch:21 step:20019 [D loss: 0.631859, acc.: 70.31%] [G loss: 0.895916]\n",
      "epoch:21 step:20020 [D loss: 0.669991, acc.: 59.38%] [G loss: 0.886312]\n",
      "epoch:21 step:20021 [D loss: 0.622786, acc.: 71.09%] [G loss: 0.922692]\n",
      "epoch:21 step:20022 [D loss: 0.631517, acc.: 64.06%] [G loss: 0.923534]\n",
      "epoch:21 step:20023 [D loss: 0.694506, acc.: 50.78%] [G loss: 0.892593]\n",
      "epoch:21 step:20024 [D loss: 0.632577, acc.: 63.28%] [G loss: 0.874948]\n",
      "epoch:21 step:20025 [D loss: 0.679700, acc.: 55.47%] [G loss: 0.863606]\n",
      "epoch:21 step:20026 [D loss: 0.610065, acc.: 71.88%] [G loss: 0.863521]\n",
      "epoch:21 step:20027 [D loss: 0.685042, acc.: 53.12%] [G loss: 0.874464]\n",
      "epoch:21 step:20028 [D loss: 0.641269, acc.: 60.94%] [G loss: 0.897540]\n",
      "epoch:21 step:20029 [D loss: 0.655691, acc.: 64.06%] [G loss: 0.941296]\n",
      "epoch:21 step:20030 [D loss: 0.668082, acc.: 57.03%] [G loss: 0.858746]\n",
      "epoch:21 step:20031 [D loss: 0.676148, acc.: 50.78%] [G loss: 0.890107]\n",
      "epoch:21 step:20032 [D loss: 0.674788, acc.: 59.38%] [G loss: 0.911559]\n",
      "epoch:21 step:20033 [D loss: 0.663759, acc.: 58.59%] [G loss: 0.985566]\n",
      "epoch:21 step:20034 [D loss: 0.701962, acc.: 51.56%] [G loss: 0.870871]\n",
      "epoch:21 step:20035 [D loss: 0.670432, acc.: 58.59%] [G loss: 0.883183]\n",
      "epoch:21 step:20036 [D loss: 0.680106, acc.: 51.56%] [G loss: 0.902246]\n",
      "epoch:21 step:20037 [D loss: 0.644542, acc.: 62.50%] [G loss: 0.889898]\n",
      "epoch:21 step:20038 [D loss: 0.664765, acc.: 60.16%] [G loss: 0.889967]\n",
      "epoch:21 step:20039 [D loss: 0.668638, acc.: 58.59%] [G loss: 0.821538]\n",
      "epoch:21 step:20040 [D loss: 0.684051, acc.: 52.34%] [G loss: 0.866575]\n",
      "epoch:21 step:20041 [D loss: 0.673446, acc.: 57.03%] [G loss: 0.860083]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20042 [D loss: 0.641237, acc.: 62.50%] [G loss: 0.887750]\n",
      "epoch:21 step:20043 [D loss: 0.642154, acc.: 63.28%] [G loss: 0.865568]\n",
      "epoch:21 step:20044 [D loss: 0.668771, acc.: 60.94%] [G loss: 0.881914]\n",
      "epoch:21 step:20045 [D loss: 0.671736, acc.: 56.25%] [G loss: 0.886301]\n",
      "epoch:21 step:20046 [D loss: 0.646898, acc.: 62.50%] [G loss: 0.821057]\n",
      "epoch:21 step:20047 [D loss: 0.673420, acc.: 57.03%] [G loss: 0.864383]\n",
      "epoch:21 step:20048 [D loss: 0.665647, acc.: 59.38%] [G loss: 0.896193]\n",
      "epoch:21 step:20049 [D loss: 0.649820, acc.: 58.59%] [G loss: 0.806984]\n",
      "epoch:21 step:20050 [D loss: 0.678549, acc.: 53.12%] [G loss: 0.873648]\n",
      "epoch:21 step:20051 [D loss: 0.667630, acc.: 56.25%] [G loss: 0.882050]\n",
      "epoch:21 step:20052 [D loss: 0.681165, acc.: 57.03%] [G loss: 0.846774]\n",
      "epoch:21 step:20053 [D loss: 0.652102, acc.: 63.28%] [G loss: 0.850938]\n",
      "epoch:21 step:20054 [D loss: 0.660109, acc.: 59.38%] [G loss: 0.844838]\n",
      "epoch:21 step:20055 [D loss: 0.620322, acc.: 63.28%] [G loss: 0.822402]\n",
      "epoch:21 step:20056 [D loss: 0.661503, acc.: 56.25%] [G loss: 0.876907]\n",
      "epoch:21 step:20057 [D loss: 0.687152, acc.: 63.28%] [G loss: 0.908942]\n",
      "epoch:21 step:20058 [D loss: 0.637430, acc.: 64.06%] [G loss: 0.889544]\n",
      "epoch:21 step:20059 [D loss: 0.654373, acc.: 58.59%] [G loss: 0.903076]\n",
      "epoch:21 step:20060 [D loss: 0.660522, acc.: 60.94%] [G loss: 0.887485]\n",
      "epoch:21 step:20061 [D loss: 0.687656, acc.: 49.22%] [G loss: 0.894081]\n",
      "epoch:21 step:20062 [D loss: 0.690888, acc.: 55.47%] [G loss: 0.931174]\n",
      "epoch:21 step:20063 [D loss: 0.683821, acc.: 56.25%] [G loss: 0.856549]\n",
      "epoch:21 step:20064 [D loss: 0.651090, acc.: 61.72%] [G loss: 0.855020]\n",
      "epoch:21 step:20065 [D loss: 0.681705, acc.: 50.78%] [G loss: 0.945462]\n",
      "epoch:21 step:20066 [D loss: 0.635890, acc.: 64.06%] [G loss: 0.846974]\n",
      "epoch:21 step:20067 [D loss: 0.643855, acc.: 67.19%] [G loss: 0.890084]\n",
      "epoch:21 step:20068 [D loss: 0.624955, acc.: 68.75%] [G loss: 0.894133]\n",
      "epoch:21 step:20069 [D loss: 0.666454, acc.: 60.94%] [G loss: 0.918465]\n",
      "epoch:21 step:20070 [D loss: 0.695598, acc.: 49.22%] [G loss: 0.894836]\n",
      "epoch:21 step:20071 [D loss: 0.638282, acc.: 61.72%] [G loss: 0.931228]\n",
      "epoch:21 step:20072 [D loss: 0.695344, acc.: 50.78%] [G loss: 0.862202]\n",
      "epoch:21 step:20073 [D loss: 0.658671, acc.: 60.16%] [G loss: 0.855396]\n",
      "epoch:21 step:20074 [D loss: 0.697324, acc.: 56.25%] [G loss: 0.850535]\n",
      "epoch:21 step:20075 [D loss: 0.672637, acc.: 57.81%] [G loss: 0.835905]\n",
      "epoch:21 step:20076 [D loss: 0.648828, acc.: 62.50%] [G loss: 0.884871]\n",
      "epoch:21 step:20077 [D loss: 0.620336, acc.: 64.84%] [G loss: 0.846168]\n",
      "epoch:21 step:20078 [D loss: 0.616155, acc.: 62.50%] [G loss: 0.854541]\n",
      "epoch:21 step:20079 [D loss: 0.608942, acc.: 71.88%] [G loss: 0.869591]\n",
      "epoch:21 step:20080 [D loss: 0.658669, acc.: 61.72%] [G loss: 0.855960]\n",
      "epoch:21 step:20081 [D loss: 0.648927, acc.: 64.06%] [G loss: 0.889117]\n",
      "epoch:21 step:20082 [D loss: 0.637803, acc.: 67.97%] [G loss: 0.917086]\n",
      "epoch:21 step:20083 [D loss: 0.638278, acc.: 68.75%] [G loss: 0.918174]\n",
      "epoch:21 step:20084 [D loss: 0.642894, acc.: 65.62%] [G loss: 0.923117]\n",
      "epoch:21 step:20085 [D loss: 0.646994, acc.: 64.06%] [G loss: 0.874181]\n",
      "epoch:21 step:20086 [D loss: 0.708710, acc.: 54.69%] [G loss: 0.879777]\n",
      "epoch:21 step:20087 [D loss: 0.666747, acc.: 60.94%] [G loss: 0.897638]\n",
      "epoch:21 step:20088 [D loss: 0.637449, acc.: 65.62%] [G loss: 0.933348]\n",
      "epoch:21 step:20089 [D loss: 0.636801, acc.: 63.28%] [G loss: 0.918341]\n",
      "epoch:21 step:20090 [D loss: 0.688564, acc.: 58.59%] [G loss: 0.909899]\n",
      "epoch:21 step:20091 [D loss: 0.656503, acc.: 61.72%] [G loss: 0.915528]\n",
      "epoch:21 step:20092 [D loss: 0.650598, acc.: 62.50%] [G loss: 0.900981]\n",
      "epoch:21 step:20093 [D loss: 0.652501, acc.: 64.06%] [G loss: 0.843335]\n",
      "epoch:21 step:20094 [D loss: 0.646075, acc.: 64.06%] [G loss: 0.876202]\n",
      "epoch:21 step:20095 [D loss: 0.695158, acc.: 57.81%] [G loss: 0.922206]\n",
      "epoch:21 step:20096 [D loss: 0.658556, acc.: 60.16%] [G loss: 0.868557]\n",
      "epoch:21 step:20097 [D loss: 0.651538, acc.: 53.91%] [G loss: 0.899182]\n",
      "epoch:21 step:20098 [D loss: 0.646982, acc.: 65.62%] [G loss: 0.944854]\n",
      "epoch:21 step:20099 [D loss: 0.671755, acc.: 55.47%] [G loss: 0.926430]\n",
      "epoch:21 step:20100 [D loss: 0.644936, acc.: 58.59%] [G loss: 0.869736]\n",
      "epoch:21 step:20101 [D loss: 0.639723, acc.: 65.62%] [G loss: 0.835152]\n",
      "epoch:21 step:20102 [D loss: 0.652763, acc.: 60.94%] [G loss: 0.862278]\n",
      "epoch:21 step:20103 [D loss: 0.680480, acc.: 60.16%] [G loss: 0.944911]\n",
      "epoch:21 step:20104 [D loss: 0.703525, acc.: 57.03%] [G loss: 0.943811]\n",
      "epoch:21 step:20105 [D loss: 0.657446, acc.: 63.28%] [G loss: 0.926096]\n",
      "epoch:21 step:20106 [D loss: 0.693280, acc.: 51.56%] [G loss: 0.888770]\n",
      "epoch:21 step:20107 [D loss: 0.671898, acc.: 56.25%] [G loss: 0.898703]\n",
      "epoch:21 step:20108 [D loss: 0.651698, acc.: 59.38%] [G loss: 0.905457]\n",
      "epoch:21 step:20109 [D loss: 0.635312, acc.: 63.28%] [G loss: 0.944269]\n",
      "epoch:21 step:20110 [D loss: 0.653769, acc.: 58.59%] [G loss: 0.861156]\n",
      "epoch:21 step:20111 [D loss: 0.624642, acc.: 65.62%] [G loss: 0.877138]\n",
      "epoch:21 step:20112 [D loss: 0.672620, acc.: 59.38%] [G loss: 0.866044]\n",
      "epoch:21 step:20113 [D loss: 0.662687, acc.: 60.16%] [G loss: 0.852110]\n",
      "epoch:21 step:20114 [D loss: 0.655459, acc.: 61.72%] [G loss: 0.863961]\n",
      "epoch:21 step:20115 [D loss: 0.635537, acc.: 61.72%] [G loss: 0.888666]\n",
      "epoch:21 step:20116 [D loss: 0.631608, acc.: 67.97%] [G loss: 0.924297]\n",
      "epoch:21 step:20117 [D loss: 0.671392, acc.: 60.94%] [G loss: 0.890544]\n",
      "epoch:21 step:20118 [D loss: 0.655219, acc.: 64.06%] [G loss: 0.905015]\n",
      "epoch:21 step:20119 [D loss: 0.635296, acc.: 65.62%] [G loss: 0.935486]\n",
      "epoch:21 step:20120 [D loss: 0.659498, acc.: 60.16%] [G loss: 0.931463]\n",
      "epoch:21 step:20121 [D loss: 0.670321, acc.: 55.47%] [G loss: 0.834716]\n",
      "epoch:21 step:20122 [D loss: 0.632704, acc.: 64.06%] [G loss: 0.826188]\n",
      "epoch:21 step:20123 [D loss: 0.672716, acc.: 58.59%] [G loss: 0.863134]\n",
      "epoch:21 step:20124 [D loss: 0.615302, acc.: 65.62%] [G loss: 0.846086]\n",
      "epoch:21 step:20125 [D loss: 0.690778, acc.: 51.56%] [G loss: 0.810238]\n",
      "epoch:21 step:20126 [D loss: 0.671620, acc.: 57.81%] [G loss: 0.853502]\n",
      "epoch:21 step:20127 [D loss: 0.633913, acc.: 64.06%] [G loss: 0.922425]\n",
      "epoch:21 step:20128 [D loss: 0.641129, acc.: 62.50%] [G loss: 0.894965]\n",
      "epoch:21 step:20129 [D loss: 0.645657, acc.: 58.59%] [G loss: 0.907465]\n",
      "epoch:21 step:20130 [D loss: 0.657692, acc.: 60.16%] [G loss: 0.917610]\n",
      "epoch:21 step:20131 [D loss: 0.668907, acc.: 55.47%] [G loss: 0.869824]\n",
      "epoch:21 step:20132 [D loss: 0.673402, acc.: 53.91%] [G loss: 0.858830]\n",
      "epoch:21 step:20133 [D loss: 0.666035, acc.: 58.59%] [G loss: 0.892417]\n",
      "epoch:21 step:20134 [D loss: 0.654076, acc.: 60.94%] [G loss: 0.881113]\n",
      "epoch:21 step:20135 [D loss: 0.669837, acc.: 57.81%] [G loss: 0.851756]\n",
      "epoch:21 step:20136 [D loss: 0.619840, acc.: 67.19%] [G loss: 0.854967]\n",
      "epoch:21 step:20137 [D loss: 0.668629, acc.: 57.03%] [G loss: 0.844144]\n",
      "epoch:21 step:20138 [D loss: 0.653459, acc.: 60.16%] [G loss: 0.889914]\n",
      "epoch:21 step:20139 [D loss: 0.671193, acc.: 54.69%] [G loss: 0.866609]\n",
      "epoch:21 step:20140 [D loss: 0.667769, acc.: 57.03%] [G loss: 0.914150]\n",
      "epoch:21 step:20141 [D loss: 0.686975, acc.: 56.25%] [G loss: 0.861452]\n",
      "epoch:21 step:20142 [D loss: 0.643999, acc.: 65.62%] [G loss: 0.862262]\n",
      "epoch:21 step:20143 [D loss: 0.653067, acc.: 60.16%] [G loss: 0.826417]\n",
      "epoch:21 step:20144 [D loss: 0.617128, acc.: 70.31%] [G loss: 0.882667]\n",
      "epoch:21 step:20145 [D loss: 0.640603, acc.: 60.94%] [G loss: 0.850971]\n",
      "epoch:21 step:20146 [D loss: 0.626740, acc.: 60.94%] [G loss: 0.901223]\n",
      "epoch:21 step:20147 [D loss: 0.701528, acc.: 53.91%] [G loss: 0.921520]\n",
      "epoch:21 step:20148 [D loss: 0.659284, acc.: 64.84%] [G loss: 0.934757]\n",
      "epoch:21 step:20149 [D loss: 0.609343, acc.: 71.09%] [G loss: 0.920444]\n",
      "epoch:21 step:20150 [D loss: 0.659900, acc.: 61.72%] [G loss: 0.869285]\n",
      "epoch:21 step:20151 [D loss: 0.655549, acc.: 57.81%] [G loss: 0.896013]\n",
      "epoch:21 step:20152 [D loss: 0.617641, acc.: 64.06%] [G loss: 0.889360]\n",
      "epoch:21 step:20153 [D loss: 0.657280, acc.: 51.56%] [G loss: 0.883913]\n",
      "epoch:21 step:20154 [D loss: 0.689103, acc.: 53.91%] [G loss: 0.832808]\n",
      "epoch:21 step:20155 [D loss: 0.663039, acc.: 59.38%] [G loss: 0.831696]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20156 [D loss: 0.685978, acc.: 51.56%] [G loss: 0.856420]\n",
      "epoch:21 step:20157 [D loss: 0.648779, acc.: 61.72%] [G loss: 0.873988]\n",
      "epoch:21 step:20158 [D loss: 0.666686, acc.: 56.25%] [G loss: 0.898757]\n",
      "epoch:21 step:20159 [D loss: 0.660015, acc.: 63.28%] [G loss: 0.870610]\n",
      "epoch:21 step:20160 [D loss: 0.637259, acc.: 61.72%] [G loss: 0.905921]\n",
      "epoch:21 step:20161 [D loss: 0.628229, acc.: 69.53%] [G loss: 0.874477]\n",
      "epoch:21 step:20162 [D loss: 0.634465, acc.: 60.16%] [G loss: 0.867552]\n",
      "epoch:21 step:20163 [D loss: 0.624681, acc.: 63.28%] [G loss: 0.901447]\n",
      "epoch:21 step:20164 [D loss: 0.681506, acc.: 57.81%] [G loss: 0.860269]\n",
      "epoch:21 step:20165 [D loss: 0.639003, acc.: 66.41%] [G loss: 0.892126]\n",
      "epoch:21 step:20166 [D loss: 0.659481, acc.: 64.06%] [G loss: 0.905249]\n",
      "epoch:21 step:20167 [D loss: 0.644699, acc.: 60.16%] [G loss: 0.937286]\n",
      "epoch:21 step:20168 [D loss: 0.662336, acc.: 57.81%] [G loss: 0.885170]\n",
      "epoch:21 step:20169 [D loss: 0.640900, acc.: 64.06%] [G loss: 0.884769]\n",
      "epoch:21 step:20170 [D loss: 0.683318, acc.: 55.47%] [G loss: 0.847132]\n",
      "epoch:21 step:20171 [D loss: 0.627582, acc.: 67.19%] [G loss: 0.826178]\n",
      "epoch:21 step:20172 [D loss: 0.675878, acc.: 53.12%] [G loss: 0.862955]\n",
      "epoch:21 step:20173 [D loss: 0.667312, acc.: 55.47%] [G loss: 0.878640]\n",
      "epoch:21 step:20174 [D loss: 0.681436, acc.: 53.91%] [G loss: 0.910168]\n",
      "epoch:21 step:20175 [D loss: 0.670265, acc.: 54.69%] [G loss: 0.889828]\n",
      "epoch:21 step:20176 [D loss: 0.645618, acc.: 62.50%] [G loss: 0.883728]\n",
      "epoch:21 step:20177 [D loss: 0.659972, acc.: 59.38%] [G loss: 0.897557]\n",
      "epoch:21 step:20178 [D loss: 0.695717, acc.: 53.12%] [G loss: 0.921477]\n",
      "epoch:21 step:20179 [D loss: 0.652601, acc.: 64.06%] [G loss: 0.906678]\n",
      "epoch:21 step:20180 [D loss: 0.670463, acc.: 60.16%] [G loss: 0.845487]\n",
      "epoch:21 step:20181 [D loss: 0.670331, acc.: 62.50%] [G loss: 0.878549]\n",
      "epoch:21 step:20182 [D loss: 0.652958, acc.: 65.62%] [G loss: 0.834616]\n",
      "epoch:21 step:20183 [D loss: 0.681665, acc.: 60.16%] [G loss: 0.840806]\n",
      "epoch:21 step:20184 [D loss: 0.663504, acc.: 55.47%] [G loss: 0.871392]\n",
      "epoch:21 step:20185 [D loss: 0.645298, acc.: 63.28%] [G loss: 0.889451]\n",
      "epoch:21 step:20186 [D loss: 0.655470, acc.: 60.94%] [G loss: 0.893848]\n",
      "epoch:21 step:20187 [D loss: 0.652353, acc.: 60.16%] [G loss: 0.882949]\n",
      "epoch:21 step:20188 [D loss: 0.603366, acc.: 67.19%] [G loss: 0.893771]\n",
      "epoch:21 step:20189 [D loss: 0.679685, acc.: 55.47%] [G loss: 0.920416]\n",
      "epoch:21 step:20190 [D loss: 0.670935, acc.: 57.03%] [G loss: 0.852783]\n",
      "epoch:21 step:20191 [D loss: 0.633138, acc.: 60.16%] [G loss: 0.844320]\n",
      "epoch:21 step:20192 [D loss: 0.653628, acc.: 60.94%] [G loss: 0.862379]\n",
      "epoch:21 step:20193 [D loss: 0.665126, acc.: 64.06%] [G loss: 0.961901]\n",
      "epoch:21 step:20194 [D loss: 0.647178, acc.: 61.72%] [G loss: 0.879728]\n",
      "epoch:21 step:20195 [D loss: 0.640931, acc.: 65.62%] [G loss: 0.899505]\n",
      "epoch:21 step:20196 [D loss: 0.638353, acc.: 60.94%] [G loss: 0.879489]\n",
      "epoch:21 step:20197 [D loss: 0.653286, acc.: 64.06%] [G loss: 0.900216]\n",
      "epoch:21 step:20198 [D loss: 0.675632, acc.: 61.72%] [G loss: 0.817616]\n",
      "epoch:21 step:20199 [D loss: 0.653901, acc.: 64.06%] [G loss: 0.885793]\n",
      "epoch:21 step:20200 [D loss: 0.624266, acc.: 67.19%] [G loss: 0.915961]\n",
      "##############\n",
      "[3.02401393 2.0742367  2.40781727 4.15580403 1.60650965 7.97932799\n",
      " 3.00323871 3.82174306 4.09425496 8.14868929]\n",
      "##########\n",
      "epoch:21 step:20201 [D loss: 0.617480, acc.: 66.41%] [G loss: 0.916743]\n",
      "epoch:21 step:20202 [D loss: 0.722570, acc.: 55.47%] [G loss: 0.875269]\n",
      "epoch:21 step:20203 [D loss: 0.691195, acc.: 56.25%] [G loss: 0.920016]\n",
      "epoch:21 step:20204 [D loss: 0.666015, acc.: 58.59%] [G loss: 0.861399]\n",
      "epoch:21 step:20205 [D loss: 0.668034, acc.: 54.69%] [G loss: 0.865117]\n",
      "epoch:21 step:20206 [D loss: 0.633497, acc.: 64.06%] [G loss: 0.890109]\n",
      "epoch:21 step:20207 [D loss: 0.596998, acc.: 69.53%] [G loss: 0.920004]\n",
      "epoch:21 step:20208 [D loss: 0.678603, acc.: 57.03%] [G loss: 0.918083]\n",
      "epoch:21 step:20209 [D loss: 0.655013, acc.: 59.38%] [G loss: 0.882903]\n",
      "epoch:21 step:20210 [D loss: 0.659557, acc.: 59.38%] [G loss: 0.815772]\n",
      "epoch:21 step:20211 [D loss: 0.669243, acc.: 59.38%] [G loss: 0.838134]\n",
      "epoch:21 step:20212 [D loss: 0.675978, acc.: 57.03%] [G loss: 0.910543]\n",
      "epoch:21 step:20213 [D loss: 0.653141, acc.: 59.38%] [G loss: 0.919865]\n",
      "epoch:21 step:20214 [D loss: 0.688273, acc.: 54.69%] [G loss: 0.959189]\n",
      "epoch:21 step:20215 [D loss: 0.643165, acc.: 67.19%] [G loss: 0.915671]\n",
      "epoch:21 step:20216 [D loss: 0.663589, acc.: 60.16%] [G loss: 0.890203]\n",
      "epoch:21 step:20217 [D loss: 0.645358, acc.: 65.62%] [G loss: 0.857018]\n",
      "epoch:21 step:20218 [D loss: 0.646376, acc.: 61.72%] [G loss: 0.903597]\n",
      "epoch:21 step:20219 [D loss: 0.628115, acc.: 71.09%] [G loss: 0.892636]\n",
      "epoch:21 step:20220 [D loss: 0.645084, acc.: 61.72%] [G loss: 0.811138]\n",
      "epoch:21 step:20221 [D loss: 0.670456, acc.: 59.38%] [G loss: 0.864936]\n",
      "epoch:21 step:20222 [D loss: 0.636439, acc.: 59.38%] [G loss: 0.868015]\n",
      "epoch:21 step:20223 [D loss: 0.639697, acc.: 66.41%] [G loss: 0.903466]\n",
      "epoch:21 step:20224 [D loss: 0.673454, acc.: 57.81%] [G loss: 0.892954]\n",
      "epoch:21 step:20225 [D loss: 0.687432, acc.: 54.69%] [G loss: 0.853895]\n",
      "epoch:21 step:20226 [D loss: 0.658400, acc.: 60.94%] [G loss: 0.845130]\n",
      "epoch:21 step:20227 [D loss: 0.634142, acc.: 67.97%] [G loss: 0.887773]\n",
      "epoch:21 step:20228 [D loss: 0.689188, acc.: 63.28%] [G loss: 0.871012]\n",
      "epoch:21 step:20229 [D loss: 0.659911, acc.: 60.16%] [G loss: 0.915613]\n",
      "epoch:21 step:20230 [D loss: 0.640548, acc.: 61.72%] [G loss: 0.868096]\n",
      "epoch:21 step:20231 [D loss: 0.652692, acc.: 63.28%] [G loss: 0.904674]\n",
      "epoch:21 step:20232 [D loss: 0.665646, acc.: 60.16%] [G loss: 0.846420]\n",
      "epoch:21 step:20233 [D loss: 0.680648, acc.: 55.47%] [G loss: 0.905043]\n",
      "epoch:21 step:20234 [D loss: 0.651700, acc.: 67.97%] [G loss: 0.933834]\n",
      "epoch:21 step:20235 [D loss: 0.658905, acc.: 57.81%] [G loss: 0.875800]\n",
      "epoch:21 step:20236 [D loss: 0.675798, acc.: 50.78%] [G loss: 0.866218]\n",
      "epoch:21 step:20237 [D loss: 0.669909, acc.: 60.16%] [G loss: 0.918699]\n",
      "epoch:21 step:20238 [D loss: 0.683518, acc.: 57.03%] [G loss: 0.877804]\n",
      "epoch:21 step:20239 [D loss: 0.628168, acc.: 64.84%] [G loss: 0.850640]\n",
      "epoch:21 step:20240 [D loss: 0.676792, acc.: 52.34%] [G loss: 0.861266]\n",
      "epoch:21 step:20241 [D loss: 0.672005, acc.: 56.25%] [G loss: 0.899533]\n",
      "epoch:21 step:20242 [D loss: 0.665893, acc.: 58.59%] [G loss: 0.879495]\n",
      "epoch:21 step:20243 [D loss: 0.647067, acc.: 62.50%] [G loss: 0.827750]\n",
      "epoch:21 step:20244 [D loss: 0.642918, acc.: 64.06%] [G loss: 0.876193]\n",
      "epoch:21 step:20245 [D loss: 0.670641, acc.: 57.81%] [G loss: 0.848271]\n",
      "epoch:21 step:20246 [D loss: 0.643062, acc.: 60.94%] [G loss: 0.892095]\n",
      "epoch:21 step:20247 [D loss: 0.706629, acc.: 54.69%] [G loss: 0.892655]\n",
      "epoch:21 step:20248 [D loss: 0.686222, acc.: 57.81%] [G loss: 0.865952]\n",
      "epoch:21 step:20249 [D loss: 0.663972, acc.: 55.47%] [G loss: 0.876487]\n",
      "epoch:21 step:20250 [D loss: 0.653967, acc.: 63.28%] [G loss: 0.860693]\n",
      "epoch:21 step:20251 [D loss: 0.677376, acc.: 57.03%] [G loss: 0.873935]\n",
      "epoch:21 step:20252 [D loss: 0.666962, acc.: 58.59%] [G loss: 0.860733]\n",
      "epoch:21 step:20253 [D loss: 0.635681, acc.: 68.75%] [G loss: 0.892835]\n",
      "epoch:21 step:20254 [D loss: 0.635516, acc.: 63.28%] [G loss: 0.829485]\n",
      "epoch:21 step:20255 [D loss: 0.649773, acc.: 60.94%] [G loss: 0.901107]\n",
      "epoch:21 step:20256 [D loss: 0.684347, acc.: 54.69%] [G loss: 0.863850]\n",
      "epoch:21 step:20257 [D loss: 0.698451, acc.: 51.56%] [G loss: 0.922815]\n",
      "epoch:21 step:20258 [D loss: 0.641747, acc.: 59.38%] [G loss: 0.823712]\n",
      "epoch:21 step:20259 [D loss: 0.638801, acc.: 60.16%] [G loss: 0.924171]\n",
      "epoch:21 step:20260 [D loss: 0.708812, acc.: 49.22%] [G loss: 0.942748]\n",
      "epoch:21 step:20261 [D loss: 0.647698, acc.: 54.69%] [G loss: 0.874647]\n",
      "epoch:21 step:20262 [D loss: 0.642307, acc.: 62.50%] [G loss: 0.853529]\n",
      "epoch:21 step:20263 [D loss: 0.666106, acc.: 62.50%] [G loss: 0.868673]\n",
      "epoch:21 step:20264 [D loss: 0.650784, acc.: 60.94%] [G loss: 0.902777]\n",
      "epoch:21 step:20265 [D loss: 0.676613, acc.: 55.47%] [G loss: 0.904482]\n",
      "epoch:21 step:20266 [D loss: 0.643542, acc.: 63.28%] [G loss: 0.904178]\n",
      "epoch:21 step:20267 [D loss: 0.665415, acc.: 59.38%] [G loss: 0.846556]\n",
      "epoch:21 step:20268 [D loss: 0.665276, acc.: 57.81%] [G loss: 0.893094]\n",
      "epoch:21 step:20269 [D loss: 0.636363, acc.: 65.62%] [G loss: 0.856485]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20270 [D loss: 0.677685, acc.: 53.91%] [G loss: 0.891960]\n",
      "epoch:21 step:20271 [D loss: 0.607992, acc.: 70.31%] [G loss: 0.895612]\n",
      "epoch:21 step:20272 [D loss: 0.663731, acc.: 58.59%] [G loss: 0.897667]\n",
      "epoch:21 step:20273 [D loss: 0.652546, acc.: 60.94%] [G loss: 0.881234]\n",
      "epoch:21 step:20274 [D loss: 0.645260, acc.: 65.62%] [G loss: 0.948884]\n",
      "epoch:21 step:20275 [D loss: 0.654341, acc.: 63.28%] [G loss: 0.942318]\n",
      "epoch:21 step:20276 [D loss: 0.633412, acc.: 60.94%] [G loss: 0.911950]\n",
      "epoch:21 step:20277 [D loss: 0.678373, acc.: 56.25%] [G loss: 0.910518]\n",
      "epoch:21 step:20278 [D loss: 0.689318, acc.: 53.12%] [G loss: 0.871681]\n",
      "epoch:21 step:20279 [D loss: 0.632249, acc.: 69.53%] [G loss: 0.874655]\n",
      "epoch:21 step:20280 [D loss: 0.666154, acc.: 53.12%] [G loss: 0.905925]\n",
      "epoch:21 step:20281 [D loss: 0.673458, acc.: 54.69%] [G loss: 0.809787]\n",
      "epoch:21 step:20282 [D loss: 0.699263, acc.: 53.91%] [G loss: 0.894953]\n",
      "epoch:21 step:20283 [D loss: 0.676963, acc.: 55.47%] [G loss: 0.878642]\n",
      "epoch:21 step:20284 [D loss: 0.663119, acc.: 57.03%] [G loss: 0.883318]\n",
      "epoch:21 step:20285 [D loss: 0.674728, acc.: 51.56%] [G loss: 0.875048]\n",
      "epoch:21 step:20286 [D loss: 0.619986, acc.: 69.53%] [G loss: 0.919759]\n",
      "epoch:21 step:20287 [D loss: 0.665219, acc.: 55.47%] [G loss: 0.891542]\n",
      "epoch:21 step:20288 [D loss: 0.648203, acc.: 59.38%] [G loss: 0.895250]\n",
      "epoch:21 step:20289 [D loss: 0.656189, acc.: 60.94%] [G loss: 0.924613]\n",
      "epoch:21 step:20290 [D loss: 0.631686, acc.: 66.41%] [G loss: 0.944534]\n",
      "epoch:21 step:20291 [D loss: 0.649061, acc.: 62.50%] [G loss: 0.925569]\n",
      "epoch:21 step:20292 [D loss: 0.665250, acc.: 61.72%] [G loss: 0.835550]\n",
      "epoch:21 step:20293 [D loss: 0.636984, acc.: 65.62%] [G loss: 0.820066]\n",
      "epoch:21 step:20294 [D loss: 0.644925, acc.: 60.94%] [G loss: 0.882977]\n",
      "epoch:21 step:20295 [D loss: 0.646736, acc.: 61.72%] [G loss: 0.810407]\n",
      "epoch:21 step:20296 [D loss: 0.706998, acc.: 49.22%] [G loss: 0.920730]\n",
      "epoch:21 step:20297 [D loss: 0.647825, acc.: 60.16%] [G loss: 0.902826]\n",
      "epoch:21 step:20298 [D loss: 0.679590, acc.: 55.47%] [G loss: 0.917830]\n",
      "epoch:21 step:20299 [D loss: 0.636872, acc.: 66.41%] [G loss: 0.915137]\n",
      "epoch:21 step:20300 [D loss: 0.624263, acc.: 67.19%] [G loss: 0.927779]\n",
      "epoch:21 step:20301 [D loss: 0.685869, acc.: 57.03%] [G loss: 0.886528]\n",
      "epoch:21 step:20302 [D loss: 0.649982, acc.: 63.28%] [G loss: 0.869841]\n",
      "epoch:21 step:20303 [D loss: 0.679011, acc.: 59.38%] [G loss: 0.874707]\n",
      "epoch:21 step:20304 [D loss: 0.623756, acc.: 69.53%] [G loss: 0.848903]\n",
      "epoch:21 step:20305 [D loss: 0.657731, acc.: 59.38%] [G loss: 0.874575]\n",
      "epoch:21 step:20306 [D loss: 0.636917, acc.: 67.19%] [G loss: 0.891791]\n",
      "epoch:21 step:20307 [D loss: 0.658010, acc.: 59.38%] [G loss: 0.900375]\n",
      "epoch:21 step:20308 [D loss: 0.649830, acc.: 61.72%] [G loss: 0.897772]\n",
      "epoch:21 step:20309 [D loss: 0.650141, acc.: 60.16%] [G loss: 0.886248]\n",
      "epoch:21 step:20310 [D loss: 0.626614, acc.: 69.53%] [G loss: 0.906630]\n",
      "epoch:21 step:20311 [D loss: 0.641341, acc.: 66.41%] [G loss: 0.893331]\n",
      "epoch:21 step:20312 [D loss: 0.648053, acc.: 64.06%] [G loss: 0.891808]\n",
      "epoch:21 step:20313 [D loss: 0.621548, acc.: 66.41%] [G loss: 0.904575]\n",
      "epoch:21 step:20314 [D loss: 0.659456, acc.: 63.28%] [G loss: 0.906885]\n",
      "epoch:21 step:20315 [D loss: 0.660204, acc.: 58.59%] [G loss: 0.886824]\n",
      "epoch:21 step:20316 [D loss: 0.696269, acc.: 50.00%] [G loss: 0.817572]\n",
      "epoch:21 step:20317 [D loss: 0.650696, acc.: 62.50%] [G loss: 0.832284]\n",
      "epoch:21 step:20318 [D loss: 0.693847, acc.: 53.12%] [G loss: 0.892803]\n",
      "epoch:21 step:20319 [D loss: 0.679043, acc.: 59.38%] [G loss: 0.892621]\n",
      "epoch:21 step:20320 [D loss: 0.689377, acc.: 55.47%] [G loss: 0.861998]\n",
      "epoch:21 step:20321 [D loss: 0.651152, acc.: 64.84%] [G loss: 0.906101]\n",
      "epoch:21 step:20322 [D loss: 0.628437, acc.: 67.19%] [G loss: 0.935943]\n",
      "epoch:21 step:20323 [D loss: 0.684338, acc.: 56.25%] [G loss: 0.884989]\n",
      "epoch:21 step:20324 [D loss: 0.670887, acc.: 60.94%] [G loss: 0.959666]\n",
      "epoch:21 step:20325 [D loss: 0.646265, acc.: 64.06%] [G loss: 0.903940]\n",
      "epoch:21 step:20326 [D loss: 0.669434, acc.: 54.69%] [G loss: 0.904260]\n",
      "epoch:21 step:20327 [D loss: 0.671041, acc.: 60.16%] [G loss: 0.962935]\n",
      "epoch:21 step:20328 [D loss: 0.650092, acc.: 66.41%] [G loss: 0.926491]\n",
      "epoch:21 step:20329 [D loss: 0.696247, acc.: 53.91%] [G loss: 0.833157]\n",
      "epoch:21 step:20330 [D loss: 0.664995, acc.: 61.72%] [G loss: 0.921256]\n",
      "epoch:21 step:20331 [D loss: 0.656014, acc.: 58.59%] [G loss: 0.890350]\n",
      "epoch:21 step:20332 [D loss: 0.683643, acc.: 53.12%] [G loss: 0.874111]\n",
      "epoch:21 step:20333 [D loss: 0.642702, acc.: 59.38%] [G loss: 0.906987]\n",
      "epoch:21 step:20334 [D loss: 0.638764, acc.: 64.84%] [G loss: 0.886718]\n",
      "epoch:21 step:20335 [D loss: 0.734214, acc.: 47.66%] [G loss: 0.870143]\n",
      "epoch:21 step:20336 [D loss: 0.664379, acc.: 57.81%] [G loss: 0.871779]\n",
      "epoch:21 step:20337 [D loss: 0.655317, acc.: 64.84%] [G loss: 0.874910]\n",
      "epoch:21 step:20338 [D loss: 0.632516, acc.: 64.06%] [G loss: 0.835148]\n",
      "epoch:21 step:20339 [D loss: 0.655079, acc.: 61.72%] [G loss: 0.878193]\n",
      "epoch:21 step:20340 [D loss: 0.619857, acc.: 65.62%] [G loss: 0.902531]\n",
      "epoch:21 step:20341 [D loss: 0.645718, acc.: 60.16%] [G loss: 0.890627]\n",
      "epoch:21 step:20342 [D loss: 0.684819, acc.: 58.59%] [G loss: 0.884921]\n",
      "epoch:21 step:20343 [D loss: 0.656164, acc.: 60.16%] [G loss: 0.866650]\n",
      "epoch:21 step:20344 [D loss: 0.642850, acc.: 64.84%] [G loss: 0.860051]\n",
      "epoch:21 step:20345 [D loss: 0.691357, acc.: 60.16%] [G loss: 0.837489]\n",
      "epoch:21 step:20346 [D loss: 0.649996, acc.: 60.94%] [G loss: 0.885195]\n",
      "epoch:21 step:20347 [D loss: 0.643280, acc.: 60.94%] [G loss: 0.904249]\n",
      "epoch:21 step:20348 [D loss: 0.662319, acc.: 60.94%] [G loss: 0.953699]\n",
      "epoch:21 step:20349 [D loss: 0.660174, acc.: 57.81%] [G loss: 0.863555]\n",
      "epoch:21 step:20350 [D loss: 0.654000, acc.: 59.38%] [G loss: 0.929438]\n",
      "epoch:21 step:20351 [D loss: 0.654714, acc.: 62.50%] [G loss: 0.833176]\n",
      "epoch:21 step:20352 [D loss: 0.674159, acc.: 60.94%] [G loss: 0.845403]\n",
      "epoch:21 step:20353 [D loss: 0.673961, acc.: 57.03%] [G loss: 0.777797]\n",
      "epoch:21 step:20354 [D loss: 0.687505, acc.: 53.12%] [G loss: 0.819955]\n",
      "epoch:21 step:20355 [D loss: 0.663122, acc.: 62.50%] [G loss: 0.851396]\n",
      "epoch:21 step:20356 [D loss: 0.643564, acc.: 62.50%] [G loss: 0.836764]\n",
      "epoch:21 step:20357 [D loss: 0.676147, acc.: 56.25%] [G loss: 0.860748]\n",
      "epoch:21 step:20358 [D loss: 0.659736, acc.: 57.03%] [G loss: 0.831285]\n",
      "epoch:21 step:20359 [D loss: 0.671072, acc.: 64.84%] [G loss: 0.881846]\n",
      "epoch:21 step:20360 [D loss: 0.696750, acc.: 49.22%] [G loss: 0.851138]\n",
      "epoch:21 step:20361 [D loss: 0.640733, acc.: 56.25%] [G loss: 0.892090]\n",
      "epoch:21 step:20362 [D loss: 0.694732, acc.: 56.25%] [G loss: 0.871564]\n",
      "epoch:21 step:20363 [D loss: 0.669856, acc.: 55.47%] [G loss: 0.875233]\n",
      "epoch:21 step:20364 [D loss: 0.653432, acc.: 62.50%] [G loss: 0.851044]\n",
      "epoch:21 step:20365 [D loss: 0.612430, acc.: 64.84%] [G loss: 0.877905]\n",
      "epoch:21 step:20366 [D loss: 0.646451, acc.: 60.94%] [G loss: 0.904578]\n",
      "epoch:21 step:20367 [D loss: 0.641421, acc.: 65.62%] [G loss: 0.871388]\n",
      "epoch:21 step:20368 [D loss: 0.669822, acc.: 58.59%] [G loss: 0.884097]\n",
      "epoch:21 step:20369 [D loss: 0.632440, acc.: 60.94%] [G loss: 0.875478]\n",
      "epoch:21 step:20370 [D loss: 0.636701, acc.: 62.50%] [G loss: 0.850912]\n",
      "epoch:21 step:20371 [D loss: 0.642115, acc.: 65.62%] [G loss: 0.867358]\n",
      "epoch:21 step:20372 [D loss: 0.616891, acc.: 71.88%] [G loss: 0.879989]\n",
      "epoch:21 step:20373 [D loss: 0.650761, acc.: 60.94%] [G loss: 0.858013]\n",
      "epoch:21 step:20374 [D loss: 0.642123, acc.: 64.84%] [G loss: 0.851293]\n",
      "epoch:21 step:20375 [D loss: 0.623694, acc.: 66.41%] [G loss: 0.847839]\n",
      "epoch:21 step:20376 [D loss: 0.687159, acc.: 53.12%] [G loss: 0.905406]\n",
      "epoch:21 step:20377 [D loss: 0.665024, acc.: 63.28%] [G loss: 0.859068]\n",
      "epoch:21 step:20378 [D loss: 0.654701, acc.: 62.50%] [G loss: 0.863911]\n",
      "epoch:21 step:20379 [D loss: 0.635867, acc.: 64.84%] [G loss: 0.917489]\n",
      "epoch:21 step:20380 [D loss: 0.661369, acc.: 57.81%] [G loss: 0.937378]\n",
      "epoch:21 step:20381 [D loss: 0.677185, acc.: 56.25%] [G loss: 0.914259]\n",
      "epoch:21 step:20382 [D loss: 0.678933, acc.: 56.25%] [G loss: 0.891598]\n",
      "epoch:21 step:20383 [D loss: 0.676608, acc.: 59.38%] [G loss: 0.902977]\n",
      "epoch:21 step:20384 [D loss: 0.652325, acc.: 56.25%] [G loss: 0.858438]\n",
      "epoch:21 step:20385 [D loss: 0.641204, acc.: 59.38%] [G loss: 0.869710]\n",
      "epoch:21 step:20386 [D loss: 0.714198, acc.: 49.22%] [G loss: 0.860766]\n",
      "epoch:21 step:20387 [D loss: 0.668703, acc.: 60.94%] [G loss: 0.943055]\n",
      "epoch:21 step:20388 [D loss: 0.642302, acc.: 64.06%] [G loss: 0.875726]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20389 [D loss: 0.674740, acc.: 61.72%] [G loss: 0.906260]\n",
      "epoch:21 step:20390 [D loss: 0.695501, acc.: 58.59%] [G loss: 0.858449]\n",
      "epoch:21 step:20391 [D loss: 0.657512, acc.: 57.03%] [G loss: 0.848641]\n",
      "epoch:21 step:20392 [D loss: 0.719085, acc.: 47.66%] [G loss: 0.827081]\n",
      "epoch:21 step:20393 [D loss: 0.669904, acc.: 59.38%] [G loss: 0.879332]\n",
      "epoch:21 step:20394 [D loss: 0.631397, acc.: 64.84%] [G loss: 0.908586]\n",
      "epoch:21 step:20395 [D loss: 0.644289, acc.: 60.16%] [G loss: 0.904631]\n",
      "epoch:21 step:20396 [D loss: 0.676376, acc.: 55.47%] [G loss: 0.807850]\n",
      "epoch:21 step:20397 [D loss: 0.670149, acc.: 57.03%] [G loss: 0.891753]\n",
      "epoch:21 step:20398 [D loss: 0.655742, acc.: 60.94%] [G loss: 0.853372]\n",
      "epoch:21 step:20399 [D loss: 0.645280, acc.: 64.84%] [G loss: 0.880710]\n",
      "epoch:21 step:20400 [D loss: 0.680417, acc.: 55.47%] [G loss: 0.860743]\n",
      "##############\n",
      "[2.9884638  2.45046139 2.05092398 3.84032563 1.14124442 7.70095896\n",
      " 2.48344654 2.94666462 4.42826624 5.79969652]\n",
      "##########\n",
      "epoch:21 step:20401 [D loss: 0.662255, acc.: 57.81%] [G loss: 0.937749]\n",
      "epoch:21 step:20402 [D loss: 0.657496, acc.: 58.59%] [G loss: 0.870084]\n",
      "epoch:21 step:20403 [D loss: 0.673478, acc.: 61.72%] [G loss: 0.849666]\n",
      "epoch:21 step:20404 [D loss: 0.681602, acc.: 56.25%] [G loss: 0.925367]\n",
      "epoch:21 step:20405 [D loss: 0.681181, acc.: 53.91%] [G loss: 0.834323]\n",
      "epoch:21 step:20406 [D loss: 0.669760, acc.: 56.25%] [G loss: 0.849829]\n",
      "epoch:21 step:20407 [D loss: 0.643902, acc.: 62.50%] [G loss: 0.902341]\n",
      "epoch:21 step:20408 [D loss: 0.657547, acc.: 57.81%] [G loss: 0.871795]\n",
      "epoch:21 step:20409 [D loss: 0.663983, acc.: 54.69%] [G loss: 0.889031]\n",
      "epoch:21 step:20410 [D loss: 0.698995, acc.: 52.34%] [G loss: 0.857654]\n",
      "epoch:21 step:20411 [D loss: 0.624821, acc.: 67.97%] [G loss: 0.928184]\n",
      "epoch:21 step:20412 [D loss: 0.656926, acc.: 60.94%] [G loss: 0.890310]\n",
      "epoch:21 step:20413 [D loss: 0.607126, acc.: 64.06%] [G loss: 0.867202]\n",
      "epoch:21 step:20414 [D loss: 0.652836, acc.: 63.28%] [G loss: 0.858292]\n",
      "epoch:21 step:20415 [D loss: 0.661332, acc.: 54.69%] [G loss: 0.845940]\n",
      "epoch:21 step:20416 [D loss: 0.673279, acc.: 60.16%] [G loss: 0.887106]\n",
      "epoch:21 step:20417 [D loss: 0.645419, acc.: 64.06%] [G loss: 0.877775]\n",
      "epoch:21 step:20418 [D loss: 0.641973, acc.: 63.28%] [G loss: 0.880088]\n",
      "epoch:21 step:20419 [D loss: 0.671514, acc.: 60.94%] [G loss: 0.834936]\n",
      "epoch:21 step:20420 [D loss: 0.676189, acc.: 57.03%] [G loss: 0.822774]\n",
      "epoch:21 step:20421 [D loss: 0.636604, acc.: 60.16%] [G loss: 0.854727]\n",
      "epoch:21 step:20422 [D loss: 0.630975, acc.: 66.41%] [G loss: 0.810384]\n",
      "epoch:21 step:20423 [D loss: 0.632080, acc.: 62.50%] [G loss: 0.903194]\n",
      "epoch:21 step:20424 [D loss: 0.651201, acc.: 63.28%] [G loss: 0.879523]\n",
      "epoch:21 step:20425 [D loss: 0.617944, acc.: 61.72%] [G loss: 0.917874]\n",
      "epoch:21 step:20426 [D loss: 0.692860, acc.: 55.47%] [G loss: 0.905972]\n",
      "epoch:21 step:20427 [D loss: 0.634971, acc.: 69.53%] [G loss: 0.893632]\n",
      "epoch:21 step:20428 [D loss: 0.640420, acc.: 66.41%] [G loss: 0.867418]\n",
      "epoch:21 step:20429 [D loss: 0.675300, acc.: 60.16%] [G loss: 0.869110]\n",
      "epoch:21 step:20430 [D loss: 0.644784, acc.: 65.62%] [G loss: 0.945528]\n",
      "epoch:21 step:20431 [D loss: 0.666602, acc.: 63.28%] [G loss: 0.909476]\n",
      "epoch:21 step:20432 [D loss: 0.703319, acc.: 59.38%] [G loss: 0.900932]\n",
      "epoch:21 step:20433 [D loss: 0.646899, acc.: 62.50%] [G loss: 0.838411]\n",
      "epoch:21 step:20434 [D loss: 0.635330, acc.: 59.38%] [G loss: 0.936105]\n",
      "epoch:21 step:20435 [D loss: 0.645389, acc.: 61.72%] [G loss: 0.852756]\n",
      "epoch:21 step:20436 [D loss: 0.651912, acc.: 63.28%] [G loss: 0.924667]\n",
      "epoch:21 step:20437 [D loss: 0.643312, acc.: 63.28%] [G loss: 0.915975]\n",
      "epoch:21 step:20438 [D loss: 0.692224, acc.: 54.69%] [G loss: 0.860848]\n",
      "epoch:21 step:20439 [D loss: 0.710354, acc.: 52.34%] [G loss: 0.871369]\n",
      "epoch:21 step:20440 [D loss: 0.641240, acc.: 65.62%] [G loss: 0.914811]\n",
      "epoch:21 step:20441 [D loss: 0.637485, acc.: 60.94%] [G loss: 0.938359]\n",
      "epoch:21 step:20442 [D loss: 0.672365, acc.: 51.56%] [G loss: 0.843509]\n",
      "epoch:21 step:20443 [D loss: 0.663050, acc.: 60.94%] [G loss: 0.824127]\n",
      "epoch:21 step:20444 [D loss: 0.672630, acc.: 55.47%] [G loss: 0.879931]\n",
      "epoch:21 step:20445 [D loss: 0.633349, acc.: 63.28%] [G loss: 0.877013]\n",
      "epoch:21 step:20446 [D loss: 0.656488, acc.: 64.06%] [G loss: 0.852238]\n",
      "epoch:21 step:20447 [D loss: 0.684650, acc.: 57.81%] [G loss: 0.856219]\n",
      "epoch:21 step:20448 [D loss: 0.663215, acc.: 57.81%] [G loss: 0.850417]\n",
      "epoch:21 step:20449 [D loss: 0.615602, acc.: 68.75%] [G loss: 0.817969]\n",
      "epoch:21 step:20450 [D loss: 0.667314, acc.: 61.72%] [G loss: 0.854492]\n",
      "epoch:21 step:20451 [D loss: 0.653495, acc.: 66.41%] [G loss: 0.887082]\n",
      "epoch:21 step:20452 [D loss: 0.627356, acc.: 65.62%] [G loss: 0.901019]\n",
      "epoch:21 step:20453 [D loss: 0.640122, acc.: 67.19%] [G loss: 0.905691]\n",
      "epoch:21 step:20454 [D loss: 0.651148, acc.: 63.28%] [G loss: 0.874718]\n",
      "epoch:21 step:20455 [D loss: 0.622404, acc.: 61.72%] [G loss: 0.852810]\n",
      "epoch:21 step:20456 [D loss: 0.676684, acc.: 59.38%] [G loss: 0.895130]\n",
      "epoch:21 step:20457 [D loss: 0.664679, acc.: 62.50%] [G loss: 0.900357]\n",
      "epoch:21 step:20458 [D loss: 0.646991, acc.: 63.28%] [G loss: 0.913618]\n",
      "epoch:21 step:20459 [D loss: 0.659289, acc.: 60.16%] [G loss: 0.896218]\n",
      "epoch:21 step:20460 [D loss: 0.665685, acc.: 57.03%] [G loss: 0.935637]\n",
      "epoch:21 step:20461 [D loss: 0.653375, acc.: 57.81%] [G loss: 0.950798]\n",
      "epoch:21 step:20462 [D loss: 0.661885, acc.: 64.06%] [G loss: 0.895131]\n",
      "epoch:21 step:20463 [D loss: 0.653483, acc.: 66.41%] [G loss: 0.844811]\n",
      "epoch:21 step:20464 [D loss: 0.653701, acc.: 59.38%] [G loss: 0.903417]\n",
      "epoch:21 step:20465 [D loss: 0.678513, acc.: 57.81%] [G loss: 0.859501]\n",
      "epoch:21 step:20466 [D loss: 0.637905, acc.: 67.19%] [G loss: 0.857710]\n",
      "epoch:21 step:20467 [D loss: 0.678151, acc.: 55.47%] [G loss: 0.828376]\n",
      "epoch:21 step:20468 [D loss: 0.638443, acc.: 67.97%] [G loss: 0.878263]\n",
      "epoch:21 step:20469 [D loss: 0.651928, acc.: 62.50%] [G loss: 0.895117]\n",
      "epoch:21 step:20470 [D loss: 0.628468, acc.: 62.50%] [G loss: 0.924095]\n",
      "epoch:21 step:20471 [D loss: 0.629070, acc.: 69.53%] [G loss: 0.868505]\n",
      "epoch:21 step:20472 [D loss: 0.658551, acc.: 66.41%] [G loss: 0.906389]\n",
      "epoch:21 step:20473 [D loss: 0.643305, acc.: 62.50%] [G loss: 0.886490]\n",
      "epoch:21 step:20474 [D loss: 0.663205, acc.: 60.16%] [G loss: 0.854826]\n",
      "epoch:21 step:20475 [D loss: 0.626833, acc.: 62.50%] [G loss: 0.875446]\n",
      "epoch:21 step:20476 [D loss: 0.659234, acc.: 60.94%] [G loss: 0.922435]\n",
      "epoch:21 step:20477 [D loss: 0.644787, acc.: 62.50%] [G loss: 0.891604]\n",
      "epoch:21 step:20478 [D loss: 0.641047, acc.: 60.94%] [G loss: 0.896910]\n",
      "epoch:21 step:20479 [D loss: 0.718169, acc.: 52.34%] [G loss: 0.934801]\n",
      "epoch:21 step:20480 [D loss: 0.668307, acc.: 57.03%] [G loss: 0.883598]\n",
      "epoch:21 step:20481 [D loss: 0.664978, acc.: 58.59%] [G loss: 0.867690]\n",
      "epoch:21 step:20482 [D loss: 0.649204, acc.: 60.94%] [G loss: 0.829846]\n",
      "epoch:21 step:20483 [D loss: 0.613002, acc.: 73.44%] [G loss: 0.868623]\n",
      "epoch:21 step:20484 [D loss: 0.630641, acc.: 65.62%] [G loss: 0.894160]\n",
      "epoch:21 step:20485 [D loss: 0.658448, acc.: 63.28%] [G loss: 0.912611]\n",
      "epoch:21 step:20486 [D loss: 0.673677, acc.: 49.22%] [G loss: 0.862501]\n",
      "epoch:21 step:20487 [D loss: 0.656884, acc.: 62.50%] [G loss: 0.829824]\n",
      "epoch:21 step:20488 [D loss: 0.664721, acc.: 59.38%] [G loss: 0.821828]\n",
      "epoch:21 step:20489 [D loss: 0.653130, acc.: 60.94%] [G loss: 0.927290]\n",
      "epoch:21 step:20490 [D loss: 0.635887, acc.: 65.62%] [G loss: 0.911598]\n",
      "epoch:21 step:20491 [D loss: 0.625553, acc.: 68.75%] [G loss: 0.905798]\n",
      "epoch:21 step:20492 [D loss: 0.685293, acc.: 57.81%] [G loss: 0.892404]\n",
      "epoch:21 step:20493 [D loss: 0.624861, acc.: 64.06%] [G loss: 0.904427]\n",
      "epoch:21 step:20494 [D loss: 0.679542, acc.: 62.50%] [G loss: 0.882088]\n",
      "epoch:21 step:20495 [D loss: 0.686504, acc.: 55.47%] [G loss: 0.851707]\n",
      "epoch:21 step:20496 [D loss: 0.666325, acc.: 54.69%] [G loss: 0.855414]\n",
      "epoch:21 step:20497 [D loss: 0.675962, acc.: 60.16%] [G loss: 0.888007]\n",
      "epoch:21 step:20498 [D loss: 0.683630, acc.: 58.59%] [G loss: 0.891664]\n",
      "epoch:21 step:20499 [D loss: 0.615307, acc.: 61.72%] [G loss: 0.856656]\n",
      "epoch:21 step:20500 [D loss: 0.678588, acc.: 57.03%] [G loss: 0.856546]\n",
      "epoch:21 step:20501 [D loss: 0.668940, acc.: 58.59%] [G loss: 0.847512]\n",
      "epoch:21 step:20502 [D loss: 0.626752, acc.: 61.72%] [G loss: 0.886361]\n",
      "epoch:21 step:20503 [D loss: 0.648810, acc.: 58.59%] [G loss: 0.884787]\n",
      "epoch:21 step:20504 [D loss: 0.655635, acc.: 59.38%] [G loss: 0.898114]\n",
      "epoch:21 step:20505 [D loss: 0.704033, acc.: 51.56%] [G loss: 0.896529]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:21 step:20506 [D loss: 0.659632, acc.: 60.16%] [G loss: 0.905192]\n",
      "epoch:21 step:20507 [D loss: 0.661240, acc.: 53.12%] [G loss: 0.886801]\n",
      "epoch:21 step:20508 [D loss: 0.678850, acc.: 54.69%] [G loss: 0.806699]\n",
      "epoch:21 step:20509 [D loss: 0.652260, acc.: 57.03%] [G loss: 0.850667]\n",
      "epoch:21 step:20510 [D loss: 0.631727, acc.: 62.50%] [G loss: 0.909429]\n",
      "epoch:21 step:20511 [D loss: 0.630644, acc.: 66.41%] [G loss: 0.855338]\n",
      "epoch:21 step:20512 [D loss: 0.631707, acc.: 68.75%] [G loss: 0.844681]\n",
      "epoch:21 step:20513 [D loss: 0.695581, acc.: 59.38%] [G loss: 0.831473]\n",
      "epoch:21 step:20514 [D loss: 0.634497, acc.: 64.84%] [G loss: 0.837256]\n",
      "epoch:21 step:20515 [D loss: 0.661991, acc.: 59.38%] [G loss: 0.882995]\n",
      "epoch:21 step:20516 [D loss: 0.679591, acc.: 61.72%] [G loss: 0.845039]\n",
      "epoch:21 step:20517 [D loss: 0.682059, acc.: 58.59%] [G loss: 0.823051]\n",
      "epoch:21 step:20518 [D loss: 0.650069, acc.: 64.84%] [G loss: 0.853355]\n",
      "epoch:21 step:20519 [D loss: 0.692516, acc.: 49.22%] [G loss: 0.832103]\n",
      "epoch:21 step:20520 [D loss: 0.701381, acc.: 54.69%] [G loss: 0.868447]\n",
      "epoch:21 step:20521 [D loss: 0.636128, acc.: 65.62%] [G loss: 0.847182]\n",
      "epoch:21 step:20522 [D loss: 0.670122, acc.: 56.25%] [G loss: 0.917446]\n",
      "epoch:21 step:20523 [D loss: 0.658566, acc.: 63.28%] [G loss: 0.880911]\n",
      "epoch:21 step:20524 [D loss: 0.668128, acc.: 56.25%] [G loss: 0.915925]\n",
      "epoch:21 step:20525 [D loss: 0.708887, acc.: 51.56%] [G loss: 0.883004]\n",
      "epoch:21 step:20526 [D loss: 0.627388, acc.: 66.41%] [G loss: 0.867714]\n",
      "epoch:21 step:20527 [D loss: 0.639565, acc.: 60.16%] [G loss: 0.863232]\n",
      "epoch:21 step:20528 [D loss: 0.679346, acc.: 57.81%] [G loss: 0.952839]\n",
      "epoch:21 step:20529 [D loss: 0.635592, acc.: 61.72%] [G loss: 0.844075]\n",
      "epoch:21 step:20530 [D loss: 0.661423, acc.: 55.47%] [G loss: 0.866378]\n",
      "epoch:21 step:20531 [D loss: 0.651734, acc.: 59.38%] [G loss: 0.887679]\n",
      "epoch:21 step:20532 [D loss: 0.707659, acc.: 51.56%] [G loss: 0.895640]\n",
      "epoch:21 step:20533 [D loss: 0.607463, acc.: 68.75%] [G loss: 0.822128]\n",
      "epoch:21 step:20534 [D loss: 0.648582, acc.: 56.25%] [G loss: 0.844484]\n",
      "epoch:21 step:20535 [D loss: 0.674439, acc.: 53.12%] [G loss: 0.823538]\n",
      "epoch:21 step:20536 [D loss: 0.685769, acc.: 54.69%] [G loss: 0.852496]\n",
      "epoch:21 step:20537 [D loss: 0.658868, acc.: 59.38%] [G loss: 0.884565]\n",
      "epoch:21 step:20538 [D loss: 0.609757, acc.: 69.53%] [G loss: 1.021420]\n",
      "epoch:21 step:20539 [D loss: 0.674062, acc.: 58.59%] [G loss: 0.896859]\n",
      "epoch:21 step:20540 [D loss: 0.654543, acc.: 60.94%] [G loss: 0.907221]\n",
      "epoch:21 step:20541 [D loss: 0.653060, acc.: 61.72%] [G loss: 0.952327]\n",
      "epoch:21 step:20542 [D loss: 0.680286, acc.: 53.91%] [G loss: 0.916375]\n",
      "epoch:21 step:20543 [D loss: 0.630241, acc.: 66.41%] [G loss: 0.876383]\n",
      "epoch:21 step:20544 [D loss: 0.668781, acc.: 60.94%] [G loss: 0.883864]\n",
      "epoch:21 step:20545 [D loss: 0.638370, acc.: 66.41%] [G loss: 0.862749]\n",
      "epoch:21 step:20546 [D loss: 0.655334, acc.: 60.16%] [G loss: 0.826351]\n",
      "epoch:21 step:20547 [D loss: 0.674073, acc.: 53.12%] [G loss: 0.861894]\n",
      "epoch:21 step:20548 [D loss: 0.621597, acc.: 64.84%] [G loss: 0.868357]\n",
      "epoch:21 step:20549 [D loss: 0.680455, acc.: 60.94%] [G loss: 0.884715]\n",
      "epoch:21 step:20550 [D loss: 0.658389, acc.: 58.59%] [G loss: 0.820431]\n",
      "epoch:21 step:20551 [D loss: 0.648248, acc.: 59.38%] [G loss: 0.842550]\n",
      "epoch:21 step:20552 [D loss: 0.653033, acc.: 57.81%] [G loss: 0.879369]\n",
      "epoch:21 step:20553 [D loss: 0.684305, acc.: 57.03%] [G loss: 0.842659]\n",
      "epoch:21 step:20554 [D loss: 0.645499, acc.: 67.19%] [G loss: 0.890598]\n",
      "epoch:21 step:20555 [D loss: 0.657222, acc.: 62.50%] [G loss: 0.897501]\n",
      "epoch:21 step:20556 [D loss: 0.675715, acc.: 58.59%] [G loss: 0.884073]\n",
      "epoch:21 step:20557 [D loss: 0.656093, acc.: 62.50%] [G loss: 0.888856]\n",
      "epoch:21 step:20558 [D loss: 0.684492, acc.: 49.22%] [G loss: 0.869357]\n",
      "epoch:21 step:20559 [D loss: 0.636681, acc.: 60.16%] [G loss: 0.835996]\n",
      "epoch:21 step:20560 [D loss: 0.642749, acc.: 60.16%] [G loss: 0.883297]\n",
      "epoch:21 step:20561 [D loss: 0.639661, acc.: 61.72%] [G loss: 0.908222]\n",
      "epoch:21 step:20562 [D loss: 0.659502, acc.: 56.25%] [G loss: 0.906112]\n",
      "epoch:21 step:20563 [D loss: 0.696934, acc.: 53.12%] [G loss: 0.878836]\n",
      "epoch:21 step:20564 [D loss: 0.646777, acc.: 61.72%] [G loss: 0.922679]\n",
      "epoch:21 step:20565 [D loss: 0.671932, acc.: 60.16%] [G loss: 0.910449]\n",
      "epoch:21 step:20566 [D loss: 0.662902, acc.: 62.50%] [G loss: 0.965883]\n",
      "epoch:21 step:20567 [D loss: 0.646457, acc.: 60.16%] [G loss: 0.903571]\n",
      "epoch:21 step:20568 [D loss: 0.683754, acc.: 52.34%] [G loss: 0.946824]\n",
      "epoch:21 step:20569 [D loss: 0.673073, acc.: 55.47%] [G loss: 0.953097]\n",
      "epoch:21 step:20570 [D loss: 0.686546, acc.: 57.81%] [G loss: 0.909473]\n",
      "epoch:21 step:20571 [D loss: 0.672000, acc.: 60.94%] [G loss: 0.930263]\n",
      "epoch:21 step:20572 [D loss: 0.621106, acc.: 68.75%] [G loss: 0.940533]\n",
      "epoch:21 step:20573 [D loss: 0.625982, acc.: 62.50%] [G loss: 0.873721]\n",
      "epoch:21 step:20574 [D loss: 0.632530, acc.: 62.50%] [G loss: 0.899668]\n",
      "epoch:21 step:20575 [D loss: 0.706344, acc.: 53.12%] [G loss: 0.904844]\n",
      "epoch:21 step:20576 [D loss: 0.658539, acc.: 63.28%] [G loss: 0.895079]\n",
      "epoch:21 step:20577 [D loss: 0.660203, acc.: 61.72%] [G loss: 0.831618]\n",
      "epoch:21 step:20578 [D loss: 0.647968, acc.: 60.16%] [G loss: 0.838991]\n",
      "epoch:21 step:20579 [D loss: 0.702651, acc.: 50.78%] [G loss: 0.818896]\n",
      "epoch:21 step:20580 [D loss: 0.698110, acc.: 56.25%] [G loss: 0.888579]\n",
      "epoch:21 step:20581 [D loss: 0.663535, acc.: 61.72%] [G loss: 0.858946]\n",
      "epoch:21 step:20582 [D loss: 0.640454, acc.: 64.84%] [G loss: 0.868355]\n",
      "epoch:21 step:20583 [D loss: 0.668504, acc.: 55.47%] [G loss: 0.850623]\n",
      "epoch:21 step:20584 [D loss: 0.696246, acc.: 53.91%] [G loss: 0.889926]\n",
      "epoch:21 step:20585 [D loss: 0.684184, acc.: 60.16%] [G loss: 0.950745]\n",
      "epoch:21 step:20586 [D loss: 0.678210, acc.: 57.03%] [G loss: 0.940397]\n",
      "epoch:21 step:20587 [D loss: 0.684473, acc.: 57.03%] [G loss: 0.919121]\n",
      "epoch:21 step:20588 [D loss: 0.634029, acc.: 66.41%] [G loss: 0.944782]\n",
      "epoch:21 step:20589 [D loss: 0.680663, acc.: 59.38%] [G loss: 0.881492]\n",
      "epoch:21 step:20590 [D loss: 0.709556, acc.: 48.44%] [G loss: 0.867696]\n",
      "epoch:21 step:20591 [D loss: 0.691794, acc.: 55.47%] [G loss: 0.892520]\n",
      "epoch:21 step:20592 [D loss: 0.671893, acc.: 58.59%] [G loss: 0.913792]\n",
      "epoch:21 step:20593 [D loss: 0.638362, acc.: 62.50%] [G loss: 0.844234]\n",
      "epoch:21 step:20594 [D loss: 0.659106, acc.: 65.62%] [G loss: 0.841772]\n",
      "epoch:21 step:20595 [D loss: 0.672213, acc.: 57.03%] [G loss: 0.877961]\n",
      "epoch:21 step:20596 [D loss: 0.639133, acc.: 59.38%] [G loss: 0.877910]\n",
      "epoch:21 step:20597 [D loss: 0.647167, acc.: 62.50%] [G loss: 0.899539]\n",
      "epoch:21 step:20598 [D loss: 0.709419, acc.: 50.00%] [G loss: 0.853773]\n",
      "epoch:21 step:20599 [D loss: 0.653165, acc.: 65.62%] [G loss: 0.874580]\n",
      "epoch:21 step:20600 [D loss: 0.699028, acc.: 56.25%] [G loss: 0.855379]\n",
      "##############\n",
      "[2.81172844 2.30788472 2.33159117 3.66969803 1.25997959 9.27426719\n",
      " 2.80312861 3.21639799 4.32037013 5.48931124]\n",
      "##########\n",
      "epoch:21 step:20601 [D loss: 0.662062, acc.: 59.38%] [G loss: 0.908766]\n",
      "epoch:21 step:20602 [D loss: 0.677278, acc.: 56.25%] [G loss: 0.843505]\n",
      "epoch:21 step:20603 [D loss: 0.655621, acc.: 57.81%] [G loss: 0.835104]\n",
      "epoch:21 step:20604 [D loss: 0.670444, acc.: 59.38%] [G loss: 0.882366]\n",
      "epoch:21 step:20605 [D loss: 0.662456, acc.: 62.50%] [G loss: 0.872828]\n",
      "epoch:21 step:20606 [D loss: 0.671368, acc.: 57.81%] [G loss: 0.853202]\n",
      "epoch:21 step:20607 [D loss: 0.680336, acc.: 54.69%] [G loss: 0.858360]\n",
      "epoch:21 step:20608 [D loss: 0.667532, acc.: 58.59%] [G loss: 0.845647]\n",
      "epoch:21 step:20609 [D loss: 0.635981, acc.: 60.94%] [G loss: 0.848040]\n",
      "epoch:21 step:20610 [D loss: 0.674329, acc.: 58.59%] [G loss: 0.904035]\n",
      "epoch:21 step:20611 [D loss: 0.648608, acc.: 67.97%] [G loss: 0.770766]\n",
      "epoch:21 step:20612 [D loss: 0.664603, acc.: 56.25%] [G loss: 0.837923]\n",
      "epoch:21 step:20613 [D loss: 0.641912, acc.: 60.16%] [G loss: 0.902813]\n",
      "epoch:21 step:20614 [D loss: 0.653438, acc.: 57.81%] [G loss: 0.923062]\n",
      "epoch:22 step:20615 [D loss: 0.658523, acc.: 58.59%] [G loss: 0.970396]\n",
      "epoch:22 step:20616 [D loss: 0.673478, acc.: 56.25%] [G loss: 0.890334]\n",
      "epoch:22 step:20617 [D loss: 0.663986, acc.: 63.28%] [G loss: 0.861600]\n",
      "epoch:22 step:20618 [D loss: 0.699699, acc.: 56.25%] [G loss: 0.934196]\n",
      "epoch:22 step:20619 [D loss: 0.663850, acc.: 60.94%] [G loss: 0.935549]\n",
      "epoch:22 step:20620 [D loss: 0.654853, acc.: 59.38%] [G loss: 0.933389]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20621 [D loss: 0.720632, acc.: 45.31%] [G loss: 0.871159]\n",
      "epoch:22 step:20622 [D loss: 0.691834, acc.: 53.91%] [G loss: 0.923704]\n",
      "epoch:22 step:20623 [D loss: 0.662713, acc.: 57.81%] [G loss: 0.896903]\n",
      "epoch:22 step:20624 [D loss: 0.623233, acc.: 62.50%] [G loss: 0.955055]\n",
      "epoch:22 step:20625 [D loss: 0.626954, acc.: 67.19%] [G loss: 0.905773]\n",
      "epoch:22 step:20626 [D loss: 0.647208, acc.: 62.50%] [G loss: 0.925149]\n",
      "epoch:22 step:20627 [D loss: 0.656819, acc.: 58.59%] [G loss: 0.879553]\n",
      "epoch:22 step:20628 [D loss: 0.645635, acc.: 61.72%] [G loss: 0.843350]\n",
      "epoch:22 step:20629 [D loss: 0.686135, acc.: 57.81%] [G loss: 0.848567]\n",
      "epoch:22 step:20630 [D loss: 0.632477, acc.: 60.94%] [G loss: 0.870665]\n",
      "epoch:22 step:20631 [D loss: 0.648234, acc.: 59.38%] [G loss: 0.919162]\n",
      "epoch:22 step:20632 [D loss: 0.694251, acc.: 54.69%] [G loss: 0.892417]\n",
      "epoch:22 step:20633 [D loss: 0.677030, acc.: 55.47%] [G loss: 0.867209]\n",
      "epoch:22 step:20634 [D loss: 0.670280, acc.: 57.03%] [G loss: 0.865151]\n",
      "epoch:22 step:20635 [D loss: 0.684348, acc.: 57.81%] [G loss: 0.863801]\n",
      "epoch:22 step:20636 [D loss: 0.685388, acc.: 61.72%] [G loss: 0.892519]\n",
      "epoch:22 step:20637 [D loss: 0.674208, acc.: 53.12%] [G loss: 0.832781]\n",
      "epoch:22 step:20638 [D loss: 0.644861, acc.: 67.19%] [G loss: 0.834647]\n",
      "epoch:22 step:20639 [D loss: 0.650523, acc.: 61.72%] [G loss: 0.878380]\n",
      "epoch:22 step:20640 [D loss: 0.643698, acc.: 63.28%] [G loss: 0.933819]\n",
      "epoch:22 step:20641 [D loss: 0.628463, acc.: 61.72%] [G loss: 0.917688]\n",
      "epoch:22 step:20642 [D loss: 0.631263, acc.: 60.16%] [G loss: 0.907721]\n",
      "epoch:22 step:20643 [D loss: 0.675889, acc.: 60.16%] [G loss: 0.837042]\n",
      "epoch:22 step:20644 [D loss: 0.667068, acc.: 60.94%] [G loss: 0.857565]\n",
      "epoch:22 step:20645 [D loss: 0.648316, acc.: 60.16%] [G loss: 0.843660]\n",
      "epoch:22 step:20646 [D loss: 0.658572, acc.: 61.72%] [G loss: 0.843390]\n",
      "epoch:22 step:20647 [D loss: 0.673693, acc.: 56.25%] [G loss: 0.846427]\n",
      "epoch:22 step:20648 [D loss: 0.654353, acc.: 57.03%] [G loss: 0.881672]\n",
      "epoch:22 step:20649 [D loss: 0.641563, acc.: 61.72%] [G loss: 0.839991]\n",
      "epoch:22 step:20650 [D loss: 0.632671, acc.: 64.06%] [G loss: 0.845445]\n",
      "epoch:22 step:20651 [D loss: 0.706654, acc.: 54.69%] [G loss: 0.898548]\n",
      "epoch:22 step:20652 [D loss: 0.697214, acc.: 53.12%] [G loss: 0.877324]\n",
      "epoch:22 step:20653 [D loss: 0.622593, acc.: 68.75%] [G loss: 0.886283]\n",
      "epoch:22 step:20654 [D loss: 0.644417, acc.: 64.84%] [G loss: 0.885655]\n",
      "epoch:22 step:20655 [D loss: 0.665502, acc.: 65.62%] [G loss: 0.835607]\n",
      "epoch:22 step:20656 [D loss: 0.681386, acc.: 56.25%] [G loss: 0.893424]\n",
      "epoch:22 step:20657 [D loss: 0.667827, acc.: 60.16%] [G loss: 0.866135]\n",
      "epoch:22 step:20658 [D loss: 0.634046, acc.: 59.38%] [G loss: 0.864212]\n",
      "epoch:22 step:20659 [D loss: 0.626579, acc.: 67.19%] [G loss: 0.922153]\n",
      "epoch:22 step:20660 [D loss: 0.646177, acc.: 62.50%] [G loss: 0.885775]\n",
      "epoch:22 step:20661 [D loss: 0.690285, acc.: 55.47%] [G loss: 0.856633]\n",
      "epoch:22 step:20662 [D loss: 0.623765, acc.: 69.53%] [G loss: 0.886707]\n",
      "epoch:22 step:20663 [D loss: 0.652929, acc.: 62.50%] [G loss: 0.886702]\n",
      "epoch:22 step:20664 [D loss: 0.618719, acc.: 68.75%] [G loss: 0.907983]\n",
      "epoch:22 step:20665 [D loss: 0.677810, acc.: 57.03%] [G loss: 0.891556]\n",
      "epoch:22 step:20666 [D loss: 0.619989, acc.: 60.94%] [G loss: 0.890419]\n",
      "epoch:22 step:20667 [D loss: 0.629228, acc.: 63.28%] [G loss: 0.846081]\n",
      "epoch:22 step:20668 [D loss: 0.635106, acc.: 68.75%] [G loss: 0.896827]\n",
      "epoch:22 step:20669 [D loss: 0.675659, acc.: 59.38%] [G loss: 0.826215]\n",
      "epoch:22 step:20670 [D loss: 0.646252, acc.: 64.84%] [G loss: 0.900322]\n",
      "epoch:22 step:20671 [D loss: 0.673215, acc.: 57.81%] [G loss: 0.880192]\n",
      "epoch:22 step:20672 [D loss: 0.690837, acc.: 56.25%] [G loss: 0.876269]\n",
      "epoch:22 step:20673 [D loss: 0.622035, acc.: 72.66%] [G loss: 0.892761]\n",
      "epoch:22 step:20674 [D loss: 0.625858, acc.: 66.41%] [G loss: 0.869220]\n",
      "epoch:22 step:20675 [D loss: 0.677257, acc.: 54.69%] [G loss: 0.895942]\n",
      "epoch:22 step:20676 [D loss: 0.655360, acc.: 59.38%] [G loss: 0.924200]\n",
      "epoch:22 step:20677 [D loss: 0.674494, acc.: 58.59%] [G loss: 0.891599]\n",
      "epoch:22 step:20678 [D loss: 0.671798, acc.: 54.69%] [G loss: 0.886897]\n",
      "epoch:22 step:20679 [D loss: 0.667335, acc.: 55.47%] [G loss: 0.882559]\n",
      "epoch:22 step:20680 [D loss: 0.646622, acc.: 59.38%] [G loss: 0.896902]\n",
      "epoch:22 step:20681 [D loss: 0.671077, acc.: 60.16%] [G loss: 0.884985]\n",
      "epoch:22 step:20682 [D loss: 0.652983, acc.: 55.47%] [G loss: 0.906500]\n",
      "epoch:22 step:20683 [D loss: 0.630985, acc.: 62.50%] [G loss: 0.893008]\n",
      "epoch:22 step:20684 [D loss: 0.665162, acc.: 61.72%] [G loss: 0.899220]\n",
      "epoch:22 step:20685 [D loss: 0.653373, acc.: 62.50%] [G loss: 0.887753]\n",
      "epoch:22 step:20686 [D loss: 0.639866, acc.: 57.03%] [G loss: 0.846742]\n",
      "epoch:22 step:20687 [D loss: 0.597767, acc.: 67.97%] [G loss: 0.866205]\n",
      "epoch:22 step:20688 [D loss: 0.672920, acc.: 59.38%] [G loss: 0.862250]\n",
      "epoch:22 step:20689 [D loss: 0.627580, acc.: 69.53%] [G loss: 0.863164]\n",
      "epoch:22 step:20690 [D loss: 0.671971, acc.: 54.69%] [G loss: 0.885259]\n",
      "epoch:22 step:20691 [D loss: 0.652702, acc.: 61.72%] [G loss: 0.870221]\n",
      "epoch:22 step:20692 [D loss: 0.655603, acc.: 57.03%] [G loss: 0.899349]\n",
      "epoch:22 step:20693 [D loss: 0.641596, acc.: 62.50%] [G loss: 0.925570]\n",
      "epoch:22 step:20694 [D loss: 0.691472, acc.: 53.91%] [G loss: 0.841794]\n",
      "epoch:22 step:20695 [D loss: 0.688582, acc.: 54.69%] [G loss: 0.869450]\n",
      "epoch:22 step:20696 [D loss: 0.674388, acc.: 60.16%] [G loss: 0.927085]\n",
      "epoch:22 step:20697 [D loss: 0.654590, acc.: 64.84%] [G loss: 0.912081]\n",
      "epoch:22 step:20698 [D loss: 0.649225, acc.: 64.84%] [G loss: 0.904912]\n",
      "epoch:22 step:20699 [D loss: 0.650736, acc.: 57.81%] [G loss: 0.956668]\n",
      "epoch:22 step:20700 [D loss: 0.683095, acc.: 57.81%] [G loss: 0.872876]\n",
      "epoch:22 step:20701 [D loss: 0.643694, acc.: 65.62%] [G loss: 0.866584]\n",
      "epoch:22 step:20702 [D loss: 0.675364, acc.: 60.94%] [G loss: 0.891679]\n",
      "epoch:22 step:20703 [D loss: 0.656107, acc.: 60.94%] [G loss: 0.868748]\n",
      "epoch:22 step:20704 [D loss: 0.663655, acc.: 60.16%] [G loss: 0.876912]\n",
      "epoch:22 step:20705 [D loss: 0.651977, acc.: 67.19%] [G loss: 0.808097]\n",
      "epoch:22 step:20706 [D loss: 0.647142, acc.: 60.16%] [G loss: 0.851323]\n",
      "epoch:22 step:20707 [D loss: 0.637921, acc.: 66.41%] [G loss: 0.811865]\n",
      "epoch:22 step:20708 [D loss: 0.681942, acc.: 59.38%] [G loss: 0.872188]\n",
      "epoch:22 step:20709 [D loss: 0.682897, acc.: 57.03%] [G loss: 0.876266]\n",
      "epoch:22 step:20710 [D loss: 0.642836, acc.: 64.06%] [G loss: 0.846012]\n",
      "epoch:22 step:20711 [D loss: 0.636812, acc.: 62.50%] [G loss: 0.857351]\n",
      "epoch:22 step:20712 [D loss: 0.647872, acc.: 63.28%] [G loss: 0.942272]\n",
      "epoch:22 step:20713 [D loss: 0.664284, acc.: 63.28%] [G loss: 0.814633]\n",
      "epoch:22 step:20714 [D loss: 0.662458, acc.: 56.25%] [G loss: 0.873443]\n",
      "epoch:22 step:20715 [D loss: 0.641051, acc.: 64.84%] [G loss: 0.862721]\n",
      "epoch:22 step:20716 [D loss: 0.676855, acc.: 57.81%] [G loss: 0.841564]\n",
      "epoch:22 step:20717 [D loss: 0.666129, acc.: 62.50%] [G loss: 0.861010]\n",
      "epoch:22 step:20718 [D loss: 0.652892, acc.: 57.81%] [G loss: 0.922838]\n",
      "epoch:22 step:20719 [D loss: 0.639861, acc.: 66.41%] [G loss: 0.874431]\n",
      "epoch:22 step:20720 [D loss: 0.626536, acc.: 67.19%] [G loss: 0.894213]\n",
      "epoch:22 step:20721 [D loss: 0.672676, acc.: 53.91%] [G loss: 0.842579]\n",
      "epoch:22 step:20722 [D loss: 0.649546, acc.: 64.06%] [G loss: 0.884634]\n",
      "epoch:22 step:20723 [D loss: 0.689946, acc.: 55.47%] [G loss: 0.843208]\n",
      "epoch:22 step:20724 [D loss: 0.699925, acc.: 51.56%] [G loss: 0.881440]\n",
      "epoch:22 step:20725 [D loss: 0.666477, acc.: 60.16%] [G loss: 0.888564]\n",
      "epoch:22 step:20726 [D loss: 0.685628, acc.: 62.50%] [G loss: 0.911385]\n",
      "epoch:22 step:20727 [D loss: 0.653952, acc.: 57.81%] [G loss: 0.930116]\n",
      "epoch:22 step:20728 [D loss: 0.640260, acc.: 59.38%] [G loss: 0.871140]\n",
      "epoch:22 step:20729 [D loss: 0.676088, acc.: 57.03%] [G loss: 0.937139]\n",
      "epoch:22 step:20730 [D loss: 0.670091, acc.: 60.94%] [G loss: 0.897424]\n",
      "epoch:22 step:20731 [D loss: 0.646792, acc.: 66.41%] [G loss: 0.910688]\n",
      "epoch:22 step:20732 [D loss: 0.654590, acc.: 59.38%] [G loss: 0.894649]\n",
      "epoch:22 step:20733 [D loss: 0.697991, acc.: 53.91%] [G loss: 0.866460]\n",
      "epoch:22 step:20734 [D loss: 0.716106, acc.: 52.34%] [G loss: 0.874489]\n",
      "epoch:22 step:20735 [D loss: 0.649467, acc.: 63.28%] [G loss: 0.883492]\n",
      "epoch:22 step:20736 [D loss: 0.708242, acc.: 57.81%] [G loss: 0.844986]\n",
      "epoch:22 step:20737 [D loss: 0.691614, acc.: 58.59%] [G loss: 0.890108]\n",
      "epoch:22 step:20738 [D loss: 0.701589, acc.: 53.12%] [G loss: 0.908820]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20739 [D loss: 0.683227, acc.: 53.91%] [G loss: 0.903789]\n",
      "epoch:22 step:20740 [D loss: 0.674202, acc.: 57.03%] [G loss: 0.869016]\n",
      "epoch:22 step:20741 [D loss: 0.604235, acc.: 72.66%] [G loss: 0.891561]\n",
      "epoch:22 step:20742 [D loss: 0.645944, acc.: 61.72%] [G loss: 0.866796]\n",
      "epoch:22 step:20743 [D loss: 0.686025, acc.: 56.25%] [G loss: 0.853193]\n",
      "epoch:22 step:20744 [D loss: 0.683272, acc.: 57.03%] [G loss: 0.848174]\n",
      "epoch:22 step:20745 [D loss: 0.654482, acc.: 65.62%] [G loss: 0.867782]\n",
      "epoch:22 step:20746 [D loss: 0.657267, acc.: 59.38%] [G loss: 0.888437]\n",
      "epoch:22 step:20747 [D loss: 0.684539, acc.: 55.47%] [G loss: 0.867894]\n",
      "epoch:22 step:20748 [D loss: 0.679438, acc.: 56.25%] [G loss: 0.885859]\n",
      "epoch:22 step:20749 [D loss: 0.688710, acc.: 51.56%] [G loss: 0.866410]\n",
      "epoch:22 step:20750 [D loss: 0.692869, acc.: 56.25%] [G loss: 0.862645]\n",
      "epoch:22 step:20751 [D loss: 0.685563, acc.: 54.69%] [G loss: 0.845035]\n",
      "epoch:22 step:20752 [D loss: 0.672047, acc.: 60.16%] [G loss: 0.851310]\n",
      "epoch:22 step:20753 [D loss: 0.672125, acc.: 58.59%] [G loss: 0.870668]\n",
      "epoch:22 step:20754 [D loss: 0.681007, acc.: 57.03%] [G loss: 0.853595]\n",
      "epoch:22 step:20755 [D loss: 0.668121, acc.: 62.50%] [G loss: 0.818356]\n",
      "epoch:22 step:20756 [D loss: 0.616080, acc.: 65.62%] [G loss: 0.845999]\n",
      "epoch:22 step:20757 [D loss: 0.631197, acc.: 63.28%] [G loss: 0.869408]\n",
      "epoch:22 step:20758 [D loss: 0.667880, acc.: 57.03%] [G loss: 0.850638]\n",
      "epoch:22 step:20759 [D loss: 0.668837, acc.: 54.69%] [G loss: 0.901591]\n",
      "epoch:22 step:20760 [D loss: 0.658586, acc.: 60.94%] [G loss: 0.841547]\n",
      "epoch:22 step:20761 [D loss: 0.685193, acc.: 50.00%] [G loss: 0.876173]\n",
      "epoch:22 step:20762 [D loss: 0.647384, acc.: 63.28%] [G loss: 0.910052]\n",
      "epoch:22 step:20763 [D loss: 0.653878, acc.: 63.28%] [G loss: 0.925426]\n",
      "epoch:22 step:20764 [D loss: 0.673864, acc.: 55.47%] [G loss: 0.926815]\n",
      "epoch:22 step:20765 [D loss: 0.664164, acc.: 59.38%] [G loss: 0.910164]\n",
      "epoch:22 step:20766 [D loss: 0.650528, acc.: 62.50%] [G loss: 0.900186]\n",
      "epoch:22 step:20767 [D loss: 0.660253, acc.: 60.94%] [G loss: 0.878725]\n",
      "epoch:22 step:20768 [D loss: 0.671655, acc.: 54.69%] [G loss: 0.869590]\n",
      "epoch:22 step:20769 [D loss: 0.681113, acc.: 57.81%] [G loss: 0.827673]\n",
      "epoch:22 step:20770 [D loss: 0.614875, acc.: 70.31%] [G loss: 0.852555]\n",
      "epoch:22 step:20771 [D loss: 0.642316, acc.: 61.72%] [G loss: 0.868599]\n",
      "epoch:22 step:20772 [D loss: 0.643933, acc.: 63.28%] [G loss: 0.843464]\n",
      "epoch:22 step:20773 [D loss: 0.660411, acc.: 60.16%] [G loss: 0.895123]\n",
      "epoch:22 step:20774 [D loss: 0.686982, acc.: 50.78%] [G loss: 0.909909]\n",
      "epoch:22 step:20775 [D loss: 0.661092, acc.: 58.59%] [G loss: 0.960339]\n",
      "epoch:22 step:20776 [D loss: 0.656077, acc.: 63.28%] [G loss: 0.878877]\n",
      "epoch:22 step:20777 [D loss: 0.663829, acc.: 53.91%] [G loss: 0.949896]\n",
      "epoch:22 step:20778 [D loss: 0.678134, acc.: 53.91%] [G loss: 0.905614]\n",
      "epoch:22 step:20779 [D loss: 0.665305, acc.: 56.25%] [G loss: 0.897405]\n",
      "epoch:22 step:20780 [D loss: 0.661521, acc.: 61.72%] [G loss: 0.874472]\n",
      "epoch:22 step:20781 [D loss: 0.670088, acc.: 59.38%] [G loss: 0.917123]\n",
      "epoch:22 step:20782 [D loss: 0.679252, acc.: 54.69%] [G loss: 0.922621]\n",
      "epoch:22 step:20783 [D loss: 0.669106, acc.: 62.50%] [G loss: 0.899199]\n",
      "epoch:22 step:20784 [D loss: 0.702754, acc.: 54.69%] [G loss: 0.874577]\n",
      "epoch:22 step:20785 [D loss: 0.687889, acc.: 53.12%] [G loss: 0.878003]\n",
      "epoch:22 step:20786 [D loss: 0.625359, acc.: 65.62%] [G loss: 0.879925]\n",
      "epoch:22 step:20787 [D loss: 0.663853, acc.: 56.25%] [G loss: 0.851996]\n",
      "epoch:22 step:20788 [D loss: 0.644594, acc.: 61.72%] [G loss: 0.899973]\n",
      "epoch:22 step:20789 [D loss: 0.689347, acc.: 52.34%] [G loss: 0.888536]\n",
      "epoch:22 step:20790 [D loss: 0.636370, acc.: 66.41%] [G loss: 0.953789]\n",
      "epoch:22 step:20791 [D loss: 0.626535, acc.: 59.38%] [G loss: 0.929628]\n",
      "epoch:22 step:20792 [D loss: 0.647955, acc.: 58.59%] [G loss: 0.907713]\n",
      "epoch:22 step:20793 [D loss: 0.636638, acc.: 65.62%] [G loss: 0.899663]\n",
      "epoch:22 step:20794 [D loss: 0.648666, acc.: 60.94%] [G loss: 0.880450]\n",
      "epoch:22 step:20795 [D loss: 0.693928, acc.: 53.91%] [G loss: 0.891070]\n",
      "epoch:22 step:20796 [D loss: 0.637015, acc.: 60.16%] [G loss: 0.876101]\n",
      "epoch:22 step:20797 [D loss: 0.634877, acc.: 64.84%] [G loss: 0.946113]\n",
      "epoch:22 step:20798 [D loss: 0.674786, acc.: 62.50%] [G loss: 0.887257]\n",
      "epoch:22 step:20799 [D loss: 0.642586, acc.: 59.38%] [G loss: 0.872551]\n",
      "epoch:22 step:20800 [D loss: 0.650504, acc.: 57.81%] [G loss: 0.882450]\n",
      "##############\n",
      "[2.83124328 2.67029061 2.43230596 3.47708641 1.62276237 7.19041983\n",
      " 2.31413081 4.05126791 4.13321728 5.72750291]\n",
      "##########\n",
      "epoch:22 step:20801 [D loss: 0.664551, acc.: 65.62%] [G loss: 0.905168]\n",
      "epoch:22 step:20802 [D loss: 0.644410, acc.: 62.50%] [G loss: 0.900786]\n",
      "epoch:22 step:20803 [D loss: 0.639245, acc.: 65.62%] [G loss: 0.905479]\n",
      "epoch:22 step:20804 [D loss: 0.667674, acc.: 61.72%] [G loss: 0.872718]\n",
      "epoch:22 step:20805 [D loss: 0.633900, acc.: 62.50%] [G loss: 0.924030]\n",
      "epoch:22 step:20806 [D loss: 0.659130, acc.: 64.06%] [G loss: 0.895943]\n",
      "epoch:22 step:20807 [D loss: 0.656716, acc.: 57.03%] [G loss: 0.908171]\n",
      "epoch:22 step:20808 [D loss: 0.700703, acc.: 56.25%] [G loss: 0.935016]\n",
      "epoch:22 step:20809 [D loss: 0.616025, acc.: 64.84%] [G loss: 0.897410]\n",
      "epoch:22 step:20810 [D loss: 0.644246, acc.: 58.59%] [G loss: 0.854252]\n",
      "epoch:22 step:20811 [D loss: 0.607645, acc.: 66.41%] [G loss: 0.882787]\n",
      "epoch:22 step:20812 [D loss: 0.662656, acc.: 61.72%] [G loss: 0.901915]\n",
      "epoch:22 step:20813 [D loss: 0.651670, acc.: 59.38%] [G loss: 0.875319]\n",
      "epoch:22 step:20814 [D loss: 0.638700, acc.: 65.62%] [G loss: 0.929658]\n",
      "epoch:22 step:20815 [D loss: 0.634686, acc.: 62.50%] [G loss: 0.900437]\n",
      "epoch:22 step:20816 [D loss: 0.619523, acc.: 64.06%] [G loss: 0.891485]\n",
      "epoch:22 step:20817 [D loss: 0.675236, acc.: 51.56%] [G loss: 0.883666]\n",
      "epoch:22 step:20818 [D loss: 0.636232, acc.: 61.72%] [G loss: 0.898607]\n",
      "epoch:22 step:20819 [D loss: 0.615057, acc.: 62.50%] [G loss: 0.818551]\n",
      "epoch:22 step:20820 [D loss: 0.657114, acc.: 62.50%] [G loss: 0.867796]\n",
      "epoch:22 step:20821 [D loss: 0.635440, acc.: 63.28%] [G loss: 0.910576]\n",
      "epoch:22 step:20822 [D loss: 0.655631, acc.: 56.25%] [G loss: 0.887955]\n",
      "epoch:22 step:20823 [D loss: 0.673076, acc.: 58.59%] [G loss: 0.860797]\n",
      "epoch:22 step:20824 [D loss: 0.656523, acc.: 62.50%] [G loss: 0.918562]\n",
      "epoch:22 step:20825 [D loss: 0.667862, acc.: 59.38%] [G loss: 0.886340]\n",
      "epoch:22 step:20826 [D loss: 0.650949, acc.: 61.72%] [G loss: 0.877312]\n",
      "epoch:22 step:20827 [D loss: 0.711507, acc.: 48.44%] [G loss: 0.897597]\n",
      "epoch:22 step:20828 [D loss: 0.677078, acc.: 55.47%] [G loss: 0.835438]\n",
      "epoch:22 step:20829 [D loss: 0.627693, acc.: 62.50%] [G loss: 0.881482]\n",
      "epoch:22 step:20830 [D loss: 0.659976, acc.: 54.69%] [G loss: 0.875315]\n",
      "epoch:22 step:20831 [D loss: 0.647166, acc.: 65.62%] [G loss: 0.843525]\n",
      "epoch:22 step:20832 [D loss: 0.682577, acc.: 50.00%] [G loss: 0.866033]\n",
      "epoch:22 step:20833 [D loss: 0.724528, acc.: 52.34%] [G loss: 0.877209]\n",
      "epoch:22 step:20834 [D loss: 0.653967, acc.: 53.12%] [G loss: 0.863057]\n",
      "epoch:22 step:20835 [D loss: 0.653674, acc.: 56.25%] [G loss: 0.872193]\n",
      "epoch:22 step:20836 [D loss: 0.683225, acc.: 57.81%] [G loss: 0.877583]\n",
      "epoch:22 step:20837 [D loss: 0.662143, acc.: 57.03%] [G loss: 0.874433]\n",
      "epoch:22 step:20838 [D loss: 0.686194, acc.: 53.12%] [G loss: 0.871396]\n",
      "epoch:22 step:20839 [D loss: 0.636264, acc.: 64.06%] [G loss: 0.891044]\n",
      "epoch:22 step:20840 [D loss: 0.621801, acc.: 67.97%] [G loss: 0.810240]\n",
      "epoch:22 step:20841 [D loss: 0.669142, acc.: 60.16%] [G loss: 0.866433]\n",
      "epoch:22 step:20842 [D loss: 0.660492, acc.: 57.03%] [G loss: 0.828701]\n",
      "epoch:22 step:20843 [D loss: 0.641845, acc.: 67.97%] [G loss: 0.839608]\n",
      "epoch:22 step:20844 [D loss: 0.683487, acc.: 60.16%] [G loss: 0.934342]\n",
      "epoch:22 step:20845 [D loss: 0.672280, acc.: 55.47%] [G loss: 0.921199]\n",
      "epoch:22 step:20846 [D loss: 0.706937, acc.: 52.34%] [G loss: 0.935794]\n",
      "epoch:22 step:20847 [D loss: 0.636534, acc.: 60.94%] [G loss: 0.905019]\n",
      "epoch:22 step:20848 [D loss: 0.688235, acc.: 55.47%] [G loss: 0.941914]\n",
      "epoch:22 step:20849 [D loss: 0.693491, acc.: 53.91%] [G loss: 0.946125]\n",
      "epoch:22 step:20850 [D loss: 0.654435, acc.: 64.06%] [G loss: 0.914861]\n",
      "epoch:22 step:20851 [D loss: 0.708925, acc.: 54.69%] [G loss: 0.897906]\n",
      "epoch:22 step:20852 [D loss: 0.633381, acc.: 65.62%] [G loss: 0.906179]\n",
      "epoch:22 step:20853 [D loss: 0.639717, acc.: 64.84%] [G loss: 0.948071]\n",
      "epoch:22 step:20854 [D loss: 0.668075, acc.: 60.94%] [G loss: 0.905650]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20855 [D loss: 0.696271, acc.: 54.69%] [G loss: 0.887259]\n",
      "epoch:22 step:20856 [D loss: 0.677665, acc.: 58.59%] [G loss: 0.876081]\n",
      "epoch:22 step:20857 [D loss: 0.650945, acc.: 60.16%] [G loss: 0.882311]\n",
      "epoch:22 step:20858 [D loss: 0.691289, acc.: 55.47%] [G loss: 0.854550]\n",
      "epoch:22 step:20859 [D loss: 0.664877, acc.: 57.03%] [G loss: 0.847612]\n",
      "epoch:22 step:20860 [D loss: 0.652975, acc.: 57.81%] [G loss: 0.817979]\n",
      "epoch:22 step:20861 [D loss: 0.667624, acc.: 60.94%] [G loss: 0.838449]\n",
      "epoch:22 step:20862 [D loss: 0.649432, acc.: 58.59%] [G loss: 0.833762]\n",
      "epoch:22 step:20863 [D loss: 0.690973, acc.: 55.47%] [G loss: 0.895428]\n",
      "epoch:22 step:20864 [D loss: 0.682416, acc.: 60.16%] [G loss: 0.858179]\n",
      "epoch:22 step:20865 [D loss: 0.672964, acc.: 55.47%] [G loss: 0.877028]\n",
      "epoch:22 step:20866 [D loss: 0.662832, acc.: 57.81%] [G loss: 0.908759]\n",
      "epoch:22 step:20867 [D loss: 0.646586, acc.: 64.06%] [G loss: 0.867950]\n",
      "epoch:22 step:20868 [D loss: 0.640057, acc.: 69.53%] [G loss: 0.890704]\n",
      "epoch:22 step:20869 [D loss: 0.653428, acc.: 64.06%] [G loss: 0.825827]\n",
      "epoch:22 step:20870 [D loss: 0.650275, acc.: 60.94%] [G loss: 0.853672]\n",
      "epoch:22 step:20871 [D loss: 0.638631, acc.: 66.41%] [G loss: 0.871800]\n",
      "epoch:22 step:20872 [D loss: 0.674114, acc.: 53.91%] [G loss: 0.922038]\n",
      "epoch:22 step:20873 [D loss: 0.674591, acc.: 57.03%] [G loss: 0.866376]\n",
      "epoch:22 step:20874 [D loss: 0.670461, acc.: 59.38%] [G loss: 0.875626]\n",
      "epoch:22 step:20875 [D loss: 0.711842, acc.: 55.47%] [G loss: 0.880557]\n",
      "epoch:22 step:20876 [D loss: 0.722074, acc.: 46.88%] [G loss: 0.919462]\n",
      "epoch:22 step:20877 [D loss: 0.673115, acc.: 57.81%] [G loss: 0.893943]\n",
      "epoch:22 step:20878 [D loss: 0.668321, acc.: 58.59%] [G loss: 0.886532]\n",
      "epoch:22 step:20879 [D loss: 0.617249, acc.: 67.19%] [G loss: 0.893277]\n",
      "epoch:22 step:20880 [D loss: 0.629010, acc.: 66.41%] [G loss: 0.892629]\n",
      "epoch:22 step:20881 [D loss: 0.638477, acc.: 61.72%] [G loss: 0.914286]\n",
      "epoch:22 step:20882 [D loss: 0.666229, acc.: 57.03%] [G loss: 0.943418]\n",
      "epoch:22 step:20883 [D loss: 0.623939, acc.: 65.62%] [G loss: 0.921477]\n",
      "epoch:22 step:20884 [D loss: 0.643671, acc.: 62.50%] [G loss: 0.869143]\n",
      "epoch:22 step:20885 [D loss: 0.650418, acc.: 63.28%] [G loss: 0.859779]\n",
      "epoch:22 step:20886 [D loss: 0.657552, acc.: 61.72%] [G loss: 0.880825]\n",
      "epoch:22 step:20887 [D loss: 0.627637, acc.: 67.97%] [G loss: 0.852516]\n",
      "epoch:22 step:20888 [D loss: 0.691484, acc.: 53.12%] [G loss: 0.860293]\n",
      "epoch:22 step:20889 [D loss: 0.707808, acc.: 53.91%] [G loss: 0.848582]\n",
      "epoch:22 step:20890 [D loss: 0.679855, acc.: 55.47%] [G loss: 0.833695]\n",
      "epoch:22 step:20891 [D loss: 0.658704, acc.: 60.16%] [G loss: 0.900441]\n",
      "epoch:22 step:20892 [D loss: 0.677816, acc.: 60.16%] [G loss: 0.873987]\n",
      "epoch:22 step:20893 [D loss: 0.657244, acc.: 60.16%] [G loss: 0.875023]\n",
      "epoch:22 step:20894 [D loss: 0.678873, acc.: 56.25%] [G loss: 0.874920]\n",
      "epoch:22 step:20895 [D loss: 0.645326, acc.: 63.28%] [G loss: 0.890177]\n",
      "epoch:22 step:20896 [D loss: 0.652974, acc.: 60.16%] [G loss: 0.894475]\n",
      "epoch:22 step:20897 [D loss: 0.628494, acc.: 66.41%] [G loss: 0.883598]\n",
      "epoch:22 step:20898 [D loss: 0.624566, acc.: 67.19%] [G loss: 0.900152]\n",
      "epoch:22 step:20899 [D loss: 0.636216, acc.: 62.50%] [G loss: 0.887671]\n",
      "epoch:22 step:20900 [D loss: 0.652786, acc.: 67.19%] [G loss: 0.861587]\n",
      "epoch:22 step:20901 [D loss: 0.646878, acc.: 57.81%] [G loss: 0.862996]\n",
      "epoch:22 step:20902 [D loss: 0.645478, acc.: 61.72%] [G loss: 0.903369]\n",
      "epoch:22 step:20903 [D loss: 0.682351, acc.: 63.28%] [G loss: 0.909840]\n",
      "epoch:22 step:20904 [D loss: 0.613747, acc.: 66.41%] [G loss: 0.951064]\n",
      "epoch:22 step:20905 [D loss: 0.660659, acc.: 60.94%] [G loss: 0.887546]\n",
      "epoch:22 step:20906 [D loss: 0.686656, acc.: 55.47%] [G loss: 0.890022]\n",
      "epoch:22 step:20907 [D loss: 0.639215, acc.: 62.50%] [G loss: 0.895245]\n",
      "epoch:22 step:20908 [D loss: 0.673630, acc.: 57.81%] [G loss: 0.888204]\n",
      "epoch:22 step:20909 [D loss: 0.642991, acc.: 60.16%] [G loss: 0.872418]\n",
      "epoch:22 step:20910 [D loss: 0.663623, acc.: 57.81%] [G loss: 0.856331]\n",
      "epoch:22 step:20911 [D loss: 0.644220, acc.: 63.28%] [G loss: 0.842784]\n",
      "epoch:22 step:20912 [D loss: 0.639444, acc.: 61.72%] [G loss: 0.939956]\n",
      "epoch:22 step:20913 [D loss: 0.668315, acc.: 60.16%] [G loss: 0.952518]\n",
      "epoch:22 step:20914 [D loss: 0.647659, acc.: 60.16%] [G loss: 0.935388]\n",
      "epoch:22 step:20915 [D loss: 0.688717, acc.: 57.03%] [G loss: 0.888313]\n",
      "epoch:22 step:20916 [D loss: 0.649346, acc.: 61.72%] [G loss: 0.894835]\n",
      "epoch:22 step:20917 [D loss: 0.656786, acc.: 65.62%] [G loss: 0.851955]\n",
      "epoch:22 step:20918 [D loss: 0.647766, acc.: 69.53%] [G loss: 0.842629]\n",
      "epoch:22 step:20919 [D loss: 0.683583, acc.: 55.47%] [G loss: 0.830044]\n",
      "epoch:22 step:20920 [D loss: 0.643674, acc.: 66.41%] [G loss: 0.911741]\n",
      "epoch:22 step:20921 [D loss: 0.711157, acc.: 49.22%] [G loss: 0.888610]\n",
      "epoch:22 step:20922 [D loss: 0.640397, acc.: 62.50%] [G loss: 0.859764]\n",
      "epoch:22 step:20923 [D loss: 0.672830, acc.: 59.38%] [G loss: 0.852483]\n",
      "epoch:22 step:20924 [D loss: 0.653179, acc.: 60.16%] [G loss: 0.946375]\n",
      "epoch:22 step:20925 [D loss: 0.648722, acc.: 59.38%] [G loss: 0.892702]\n",
      "epoch:22 step:20926 [D loss: 0.668331, acc.: 53.12%] [G loss: 0.935169]\n",
      "epoch:22 step:20927 [D loss: 0.674667, acc.: 60.94%] [G loss: 0.907939]\n",
      "epoch:22 step:20928 [D loss: 0.645564, acc.: 58.59%] [G loss: 0.935277]\n",
      "epoch:22 step:20929 [D loss: 0.615946, acc.: 67.97%] [G loss: 0.892277]\n",
      "epoch:22 step:20930 [D loss: 0.635711, acc.: 67.97%] [G loss: 0.941621]\n",
      "epoch:22 step:20931 [D loss: 0.649294, acc.: 65.62%] [G loss: 0.930955]\n",
      "epoch:22 step:20932 [D loss: 0.623889, acc.: 65.62%] [G loss: 0.902215]\n",
      "epoch:22 step:20933 [D loss: 0.660698, acc.: 58.59%] [G loss: 0.903820]\n",
      "epoch:22 step:20934 [D loss: 0.682258, acc.: 59.38%] [G loss: 0.887651]\n",
      "epoch:22 step:20935 [D loss: 0.668090, acc.: 61.72%] [G loss: 0.844964]\n",
      "epoch:22 step:20936 [D loss: 0.640097, acc.: 61.72%] [G loss: 0.843577]\n",
      "epoch:22 step:20937 [D loss: 0.634977, acc.: 64.84%] [G loss: 0.928035]\n",
      "epoch:22 step:20938 [D loss: 0.643288, acc.: 61.72%] [G loss: 0.889651]\n",
      "epoch:22 step:20939 [D loss: 0.646224, acc.: 54.69%] [G loss: 0.904498]\n",
      "epoch:22 step:20940 [D loss: 0.709745, acc.: 46.88%] [G loss: 0.867752]\n",
      "epoch:22 step:20941 [D loss: 0.650632, acc.: 65.62%] [G loss: 0.862050]\n",
      "epoch:22 step:20942 [D loss: 0.658971, acc.: 56.25%] [G loss: 0.873415]\n",
      "epoch:22 step:20943 [D loss: 0.657934, acc.: 59.38%] [G loss: 0.862218]\n",
      "epoch:22 step:20944 [D loss: 0.653122, acc.: 62.50%] [G loss: 0.914693]\n",
      "epoch:22 step:20945 [D loss: 0.662603, acc.: 60.16%] [G loss: 0.887491]\n",
      "epoch:22 step:20946 [D loss: 0.646191, acc.: 60.94%] [G loss: 0.856821]\n",
      "epoch:22 step:20947 [D loss: 0.632836, acc.: 63.28%] [G loss: 0.930787]\n",
      "epoch:22 step:20948 [D loss: 0.646383, acc.: 60.94%] [G loss: 0.923553]\n",
      "epoch:22 step:20949 [D loss: 0.703914, acc.: 55.47%] [G loss: 0.843795]\n",
      "epoch:22 step:20950 [D loss: 0.605756, acc.: 68.75%] [G loss: 0.960256]\n",
      "epoch:22 step:20951 [D loss: 0.644051, acc.: 63.28%] [G loss: 0.919823]\n",
      "epoch:22 step:20952 [D loss: 0.650422, acc.: 64.06%] [G loss: 0.907359]\n",
      "epoch:22 step:20953 [D loss: 0.642454, acc.: 65.62%] [G loss: 0.907829]\n",
      "epoch:22 step:20954 [D loss: 0.628894, acc.: 70.31%] [G loss: 0.919653]\n",
      "epoch:22 step:20955 [D loss: 0.653619, acc.: 60.94%] [G loss: 0.886957]\n",
      "epoch:22 step:20956 [D loss: 0.603328, acc.: 72.66%] [G loss: 0.878107]\n",
      "epoch:22 step:20957 [D loss: 0.715937, acc.: 51.56%] [G loss: 0.880030]\n",
      "epoch:22 step:20958 [D loss: 0.664650, acc.: 62.50%] [G loss: 0.917719]\n",
      "epoch:22 step:20959 [D loss: 0.658376, acc.: 56.25%] [G loss: 0.839933]\n",
      "epoch:22 step:20960 [D loss: 0.685728, acc.: 53.12%] [G loss: 0.862458]\n",
      "epoch:22 step:20961 [D loss: 0.674086, acc.: 61.72%] [G loss: 0.831099]\n",
      "epoch:22 step:20962 [D loss: 0.667904, acc.: 60.16%] [G loss: 0.887612]\n",
      "epoch:22 step:20963 [D loss: 0.643447, acc.: 60.94%] [G loss: 0.878483]\n",
      "epoch:22 step:20964 [D loss: 0.649476, acc.: 57.03%] [G loss: 0.861553]\n",
      "epoch:22 step:20965 [D loss: 0.670052, acc.: 61.72%] [G loss: 0.826121]\n",
      "epoch:22 step:20966 [D loss: 0.682366, acc.: 53.91%] [G loss: 0.838495]\n",
      "epoch:22 step:20967 [D loss: 0.655932, acc.: 61.72%] [G loss: 0.862491]\n",
      "epoch:22 step:20968 [D loss: 0.677606, acc.: 58.59%] [G loss: 0.849594]\n",
      "epoch:22 step:20969 [D loss: 0.676797, acc.: 60.94%] [G loss: 0.841449]\n",
      "epoch:22 step:20970 [D loss: 0.650221, acc.: 61.72%] [G loss: 0.843608]\n",
      "epoch:22 step:20971 [D loss: 0.667845, acc.: 59.38%] [G loss: 0.834986]\n",
      "epoch:22 step:20972 [D loss: 0.637631, acc.: 61.72%] [G loss: 0.906833]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:20973 [D loss: 0.679559, acc.: 55.47%] [G loss: 0.898596]\n",
      "epoch:22 step:20974 [D loss: 0.632408, acc.: 64.06%] [G loss: 0.913836]\n",
      "epoch:22 step:20975 [D loss: 0.661398, acc.: 56.25%] [G loss: 0.891841]\n",
      "epoch:22 step:20976 [D loss: 0.660078, acc.: 60.94%] [G loss: 0.942663]\n",
      "epoch:22 step:20977 [D loss: 0.673724, acc.: 59.38%] [G loss: 0.861306]\n",
      "epoch:22 step:20978 [D loss: 0.662330, acc.: 60.94%] [G loss: 0.837657]\n",
      "epoch:22 step:20979 [D loss: 0.659769, acc.: 57.81%] [G loss: 0.855849]\n",
      "epoch:22 step:20980 [D loss: 0.640113, acc.: 64.06%] [G loss: 0.877995]\n",
      "epoch:22 step:20981 [D loss: 0.670446, acc.: 59.38%] [G loss: 0.891851]\n",
      "epoch:22 step:20982 [D loss: 0.652745, acc.: 62.50%] [G loss: 0.821298]\n",
      "epoch:22 step:20983 [D loss: 0.674884, acc.: 58.59%] [G loss: 0.908696]\n",
      "epoch:22 step:20984 [D loss: 0.649115, acc.: 60.94%] [G loss: 0.843953]\n",
      "epoch:22 step:20985 [D loss: 0.673346, acc.: 53.12%] [G loss: 0.930678]\n",
      "epoch:22 step:20986 [D loss: 0.654136, acc.: 59.38%] [G loss: 0.876274]\n",
      "epoch:22 step:20987 [D loss: 0.665537, acc.: 57.81%] [G loss: 0.887847]\n",
      "epoch:22 step:20988 [D loss: 0.645902, acc.: 65.62%] [G loss: 0.839558]\n",
      "epoch:22 step:20989 [D loss: 0.681199, acc.: 54.69%] [G loss: 0.888190]\n",
      "epoch:22 step:20990 [D loss: 0.710140, acc.: 52.34%] [G loss: 0.867927]\n",
      "epoch:22 step:20991 [D loss: 0.662606, acc.: 62.50%] [G loss: 0.872273]\n",
      "epoch:22 step:20992 [D loss: 0.654001, acc.: 57.03%] [G loss: 0.842446]\n",
      "epoch:22 step:20993 [D loss: 0.638936, acc.: 63.28%] [G loss: 0.879476]\n",
      "epoch:22 step:20994 [D loss: 0.676491, acc.: 60.16%] [G loss: 0.880676]\n",
      "epoch:22 step:20995 [D loss: 0.679340, acc.: 53.12%] [G loss: 0.884074]\n",
      "epoch:22 step:20996 [D loss: 0.632929, acc.: 67.19%] [G loss: 0.893174]\n",
      "epoch:22 step:20997 [D loss: 0.654737, acc.: 58.59%] [G loss: 0.872942]\n",
      "epoch:22 step:20998 [D loss: 0.668050, acc.: 60.16%] [G loss: 0.909711]\n",
      "epoch:22 step:20999 [D loss: 0.694301, acc.: 52.34%] [G loss: 0.820701]\n",
      "epoch:22 step:21000 [D loss: 0.646853, acc.: 62.50%] [G loss: 0.875751]\n",
      "##############\n",
      "[3.02441397 2.30341934 2.15787025 3.904693   1.36587456 8.52260768\n",
      " 2.65769625 2.64646588 4.20012964 7.14868929]\n",
      "##########\n",
      "epoch:22 step:21001 [D loss: 0.645410, acc.: 61.72%] [G loss: 0.875136]\n",
      "epoch:22 step:21002 [D loss: 0.709029, acc.: 51.56%] [G loss: 0.846716]\n",
      "epoch:22 step:21003 [D loss: 0.657823, acc.: 59.38%] [G loss: 0.846919]\n",
      "epoch:22 step:21004 [D loss: 0.653910, acc.: 64.84%] [G loss: 0.872762]\n",
      "epoch:22 step:21005 [D loss: 0.622348, acc.: 69.53%] [G loss: 0.832502]\n",
      "epoch:22 step:21006 [D loss: 0.672366, acc.: 57.81%] [G loss: 0.836048]\n",
      "epoch:22 step:21007 [D loss: 0.691908, acc.: 55.47%] [G loss: 0.818623]\n",
      "epoch:22 step:21008 [D loss: 0.664436, acc.: 56.25%] [G loss: 0.875638]\n",
      "epoch:22 step:21009 [D loss: 0.659682, acc.: 64.06%] [G loss: 0.860503]\n",
      "epoch:22 step:21010 [D loss: 0.672687, acc.: 62.50%] [G loss: 0.873741]\n",
      "epoch:22 step:21011 [D loss: 0.693574, acc.: 53.91%] [G loss: 0.892540]\n",
      "epoch:22 step:21012 [D loss: 0.687292, acc.: 60.16%] [G loss: 0.860876]\n",
      "epoch:22 step:21013 [D loss: 0.665789, acc.: 60.16%] [G loss: 0.894666]\n",
      "epoch:22 step:21014 [D loss: 0.670596, acc.: 58.59%] [G loss: 0.854199]\n",
      "epoch:22 step:21015 [D loss: 0.642113, acc.: 59.38%] [G loss: 0.835206]\n",
      "epoch:22 step:21016 [D loss: 0.609164, acc.: 67.19%] [G loss: 0.917099]\n",
      "epoch:22 step:21017 [D loss: 0.638705, acc.: 60.94%] [G loss: 0.889339]\n",
      "epoch:22 step:21018 [D loss: 0.645685, acc.: 59.38%] [G loss: 0.883228]\n",
      "epoch:22 step:21019 [D loss: 0.636981, acc.: 62.50%] [G loss: 0.870219]\n",
      "epoch:22 step:21020 [D loss: 0.672132, acc.: 62.50%] [G loss: 0.847797]\n",
      "epoch:22 step:21021 [D loss: 0.656145, acc.: 62.50%] [G loss: 0.869504]\n",
      "epoch:22 step:21022 [D loss: 0.670666, acc.: 56.25%] [G loss: 0.876447]\n",
      "epoch:22 step:21023 [D loss: 0.659717, acc.: 60.94%] [G loss: 0.876450]\n",
      "epoch:22 step:21024 [D loss: 0.679883, acc.: 58.59%] [G loss: 0.895092]\n",
      "epoch:22 step:21025 [D loss: 0.657621, acc.: 58.59%] [G loss: 0.863727]\n",
      "epoch:22 step:21026 [D loss: 0.655887, acc.: 59.38%] [G loss: 0.883553]\n",
      "epoch:22 step:21027 [D loss: 0.755867, acc.: 48.44%] [G loss: 0.854911]\n",
      "epoch:22 step:21028 [D loss: 0.640082, acc.: 64.06%] [G loss: 0.872207]\n",
      "epoch:22 step:21029 [D loss: 0.658568, acc.: 65.62%] [G loss: 0.895122]\n",
      "epoch:22 step:21030 [D loss: 0.638214, acc.: 57.81%] [G loss: 0.894582]\n",
      "epoch:22 step:21031 [D loss: 0.604735, acc.: 70.31%] [G loss: 0.925842]\n",
      "epoch:22 step:21032 [D loss: 0.689577, acc.: 55.47%] [G loss: 0.915845]\n",
      "epoch:22 step:21033 [D loss: 0.678366, acc.: 60.16%] [G loss: 0.876129]\n",
      "epoch:22 step:21034 [D loss: 0.645838, acc.: 67.19%] [G loss: 0.838810]\n",
      "epoch:22 step:21035 [D loss: 0.682880, acc.: 62.50%] [G loss: 0.884194]\n",
      "epoch:22 step:21036 [D loss: 0.658125, acc.: 60.94%] [G loss: 0.922989]\n",
      "epoch:22 step:21037 [D loss: 0.650254, acc.: 60.94%] [G loss: 0.907647]\n",
      "epoch:22 step:21038 [D loss: 0.623410, acc.: 69.53%] [G loss: 0.897697]\n",
      "epoch:22 step:21039 [D loss: 0.700947, acc.: 53.91%] [G loss: 0.876840]\n",
      "epoch:22 step:21040 [D loss: 0.680558, acc.: 56.25%] [G loss: 0.841945]\n",
      "epoch:22 step:21041 [D loss: 0.665197, acc.: 60.94%] [G loss: 0.849848]\n",
      "epoch:22 step:21042 [D loss: 0.657419, acc.: 57.03%] [G loss: 0.876454]\n",
      "epoch:22 step:21043 [D loss: 0.668404, acc.: 64.06%] [G loss: 0.891278]\n",
      "epoch:22 step:21044 [D loss: 0.691777, acc.: 56.25%] [G loss: 0.935058]\n",
      "epoch:22 step:21045 [D loss: 0.650901, acc.: 59.38%] [G loss: 0.933617]\n",
      "epoch:22 step:21046 [D loss: 0.643236, acc.: 60.94%] [G loss: 0.900250]\n",
      "epoch:22 step:21047 [D loss: 0.644766, acc.: 60.16%] [G loss: 0.969861]\n",
      "epoch:22 step:21048 [D loss: 0.653245, acc.: 61.72%] [G loss: 0.895447]\n",
      "epoch:22 step:21049 [D loss: 0.649065, acc.: 62.50%] [G loss: 0.924826]\n",
      "epoch:22 step:21050 [D loss: 0.674247, acc.: 57.03%] [G loss: 1.003297]\n",
      "epoch:22 step:21051 [D loss: 0.673299, acc.: 57.03%] [G loss: 0.923369]\n",
      "epoch:22 step:21052 [D loss: 0.662491, acc.: 61.72%] [G loss: 0.883765]\n",
      "epoch:22 step:21053 [D loss: 0.653742, acc.: 54.69%] [G loss: 0.875921]\n",
      "epoch:22 step:21054 [D loss: 0.655217, acc.: 59.38%] [G loss: 0.836873]\n",
      "epoch:22 step:21055 [D loss: 0.671186, acc.: 55.47%] [G loss: 0.856513]\n",
      "epoch:22 step:21056 [D loss: 0.644971, acc.: 61.72%] [G loss: 0.866470]\n",
      "epoch:22 step:21057 [D loss: 0.651061, acc.: 59.38%] [G loss: 0.955810]\n",
      "epoch:22 step:21058 [D loss: 0.696807, acc.: 53.12%] [G loss: 0.906220]\n",
      "epoch:22 step:21059 [D loss: 0.667230, acc.: 62.50%] [G loss: 0.868007]\n",
      "epoch:22 step:21060 [D loss: 0.651451, acc.: 59.38%] [G loss: 0.897371]\n",
      "epoch:22 step:21061 [D loss: 0.661231, acc.: 62.50%] [G loss: 0.865608]\n",
      "epoch:22 step:21062 [D loss: 0.683650, acc.: 56.25%] [G loss: 0.873676]\n",
      "epoch:22 step:21063 [D loss: 0.666541, acc.: 54.69%] [G loss: 0.887344]\n",
      "epoch:22 step:21064 [D loss: 0.644410, acc.: 62.50%] [G loss: 0.854002]\n",
      "epoch:22 step:21065 [D loss: 0.688225, acc.: 57.81%] [G loss: 0.870699]\n",
      "epoch:22 step:21066 [D loss: 0.666540, acc.: 54.69%] [G loss: 0.822698]\n",
      "epoch:22 step:21067 [D loss: 0.639650, acc.: 63.28%] [G loss: 0.864944]\n",
      "epoch:22 step:21068 [D loss: 0.651237, acc.: 62.50%] [G loss: 0.825078]\n",
      "epoch:22 step:21069 [D loss: 0.674952, acc.: 58.59%] [G loss: 0.897240]\n",
      "epoch:22 step:21070 [D loss: 0.661330, acc.: 59.38%] [G loss: 0.914214]\n",
      "epoch:22 step:21071 [D loss: 0.618742, acc.: 64.84%] [G loss: 0.928512]\n",
      "epoch:22 step:21072 [D loss: 0.650018, acc.: 62.50%] [G loss: 0.897410]\n",
      "epoch:22 step:21073 [D loss: 0.608520, acc.: 69.53%] [G loss: 0.881830]\n",
      "epoch:22 step:21074 [D loss: 0.657682, acc.: 60.94%] [G loss: 0.898607]\n",
      "epoch:22 step:21075 [D loss: 0.683396, acc.: 59.38%] [G loss: 0.918449]\n",
      "epoch:22 step:21076 [D loss: 0.658081, acc.: 57.03%] [G loss: 0.906475]\n",
      "epoch:22 step:21077 [D loss: 0.633381, acc.: 66.41%] [G loss: 0.899981]\n",
      "epoch:22 step:21078 [D loss: 0.703567, acc.: 51.56%] [G loss: 0.852795]\n",
      "epoch:22 step:21079 [D loss: 0.659887, acc.: 56.25%] [G loss: 0.864694]\n",
      "epoch:22 step:21080 [D loss: 0.664965, acc.: 60.16%] [G loss: 0.867573]\n",
      "epoch:22 step:21081 [D loss: 0.660530, acc.: 60.16%] [G loss: 0.848694]\n",
      "epoch:22 step:21082 [D loss: 0.653510, acc.: 57.81%] [G loss: 0.835525]\n",
      "epoch:22 step:21083 [D loss: 0.654415, acc.: 64.06%] [G loss: 0.863128]\n",
      "epoch:22 step:21084 [D loss: 0.647277, acc.: 62.50%] [G loss: 0.899013]\n",
      "epoch:22 step:21085 [D loss: 0.626626, acc.: 68.75%] [G loss: 0.849573]\n",
      "epoch:22 step:21086 [D loss: 0.640150, acc.: 63.28%] [G loss: 0.905052]\n",
      "epoch:22 step:21087 [D loss: 0.674157, acc.: 57.03%] [G loss: 0.869927]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21088 [D loss: 0.663673, acc.: 61.72%] [G loss: 0.943882]\n",
      "epoch:22 step:21089 [D loss: 0.640219, acc.: 66.41%] [G loss: 0.943009]\n",
      "epoch:22 step:21090 [D loss: 0.633084, acc.: 65.62%] [G loss: 0.888981]\n",
      "epoch:22 step:21091 [D loss: 0.660679, acc.: 62.50%] [G loss: 0.906754]\n",
      "epoch:22 step:21092 [D loss: 0.695113, acc.: 51.56%] [G loss: 0.857925]\n",
      "epoch:22 step:21093 [D loss: 0.682986, acc.: 57.03%] [G loss: 0.921986]\n",
      "epoch:22 step:21094 [D loss: 0.653910, acc.: 61.72%] [G loss: 0.905998]\n",
      "epoch:22 step:21095 [D loss: 0.676515, acc.: 56.25%] [G loss: 0.881173]\n",
      "epoch:22 step:21096 [D loss: 0.658590, acc.: 60.16%] [G loss: 0.820536]\n",
      "epoch:22 step:21097 [D loss: 0.653888, acc.: 57.81%] [G loss: 0.890723]\n",
      "epoch:22 step:21098 [D loss: 0.639162, acc.: 60.94%] [G loss: 0.904705]\n",
      "epoch:22 step:21099 [D loss: 0.648135, acc.: 60.16%] [G loss: 0.848631]\n",
      "epoch:22 step:21100 [D loss: 0.640164, acc.: 65.62%] [G loss: 0.838713]\n",
      "epoch:22 step:21101 [D loss: 0.656728, acc.: 63.28%] [G loss: 0.813494]\n",
      "epoch:22 step:21102 [D loss: 0.630659, acc.: 64.84%] [G loss: 0.924713]\n",
      "epoch:22 step:21103 [D loss: 0.642362, acc.: 62.50%] [G loss: 0.879779]\n",
      "epoch:22 step:21104 [D loss: 0.630373, acc.: 67.97%] [G loss: 0.813026]\n",
      "epoch:22 step:21105 [D loss: 0.651805, acc.: 57.03%] [G loss: 0.843920]\n",
      "epoch:22 step:21106 [D loss: 0.654794, acc.: 61.72%] [G loss: 0.844500]\n",
      "epoch:22 step:21107 [D loss: 0.648758, acc.: 64.84%] [G loss: 0.849987]\n",
      "epoch:22 step:21108 [D loss: 0.659770, acc.: 59.38%] [G loss: 0.855669]\n",
      "epoch:22 step:21109 [D loss: 0.674319, acc.: 54.69%] [G loss: 0.878356]\n",
      "epoch:22 step:21110 [D loss: 0.682163, acc.: 53.91%] [G loss: 0.824382]\n",
      "epoch:22 step:21111 [D loss: 0.657212, acc.: 66.41%] [G loss: 0.881130]\n",
      "epoch:22 step:21112 [D loss: 0.686360, acc.: 59.38%] [G loss: 0.835568]\n",
      "epoch:22 step:21113 [D loss: 0.674356, acc.: 51.56%] [G loss: 0.903046]\n",
      "epoch:22 step:21114 [D loss: 0.685552, acc.: 58.59%] [G loss: 0.877214]\n",
      "epoch:22 step:21115 [D loss: 0.666656, acc.: 54.69%] [G loss: 0.880085]\n",
      "epoch:22 step:21116 [D loss: 0.632265, acc.: 64.84%] [G loss: 0.895195]\n",
      "epoch:22 step:21117 [D loss: 0.635137, acc.: 60.94%] [G loss: 0.867491]\n",
      "epoch:22 step:21118 [D loss: 0.693615, acc.: 51.56%] [G loss: 0.810795]\n",
      "epoch:22 step:21119 [D loss: 0.649516, acc.: 60.16%] [G loss: 0.844085]\n",
      "epoch:22 step:21120 [D loss: 0.690112, acc.: 56.25%] [G loss: 0.833032]\n",
      "epoch:22 step:21121 [D loss: 0.639764, acc.: 64.84%] [G loss: 0.905619]\n",
      "epoch:22 step:21122 [D loss: 0.644665, acc.: 68.75%] [G loss: 0.886672]\n",
      "epoch:22 step:21123 [D loss: 0.626449, acc.: 64.06%] [G loss: 0.927853]\n",
      "epoch:22 step:21124 [D loss: 0.645379, acc.: 65.62%] [G loss: 0.898465]\n",
      "epoch:22 step:21125 [D loss: 0.661309, acc.: 55.47%] [G loss: 0.880511]\n",
      "epoch:22 step:21126 [D loss: 0.684991, acc.: 57.81%] [G loss: 0.855136]\n",
      "epoch:22 step:21127 [D loss: 0.664039, acc.: 62.50%] [G loss: 0.885731]\n",
      "epoch:22 step:21128 [D loss: 0.646084, acc.: 62.50%] [G loss: 0.893333]\n",
      "epoch:22 step:21129 [D loss: 0.664763, acc.: 60.16%] [G loss: 0.891452]\n",
      "epoch:22 step:21130 [D loss: 0.624072, acc.: 65.62%] [G loss: 0.921483]\n",
      "epoch:22 step:21131 [D loss: 0.673981, acc.: 58.59%] [G loss: 0.887290]\n",
      "epoch:22 step:21132 [D loss: 0.660422, acc.: 63.28%] [G loss: 0.891482]\n",
      "epoch:22 step:21133 [D loss: 0.637709, acc.: 64.06%] [G loss: 0.804055]\n",
      "epoch:22 step:21134 [D loss: 0.628864, acc.: 67.97%] [G loss: 0.832014]\n",
      "epoch:22 step:21135 [D loss: 0.663268, acc.: 57.03%] [G loss: 0.823981]\n",
      "epoch:22 step:21136 [D loss: 0.629410, acc.: 64.06%] [G loss: 0.860744]\n",
      "epoch:22 step:21137 [D loss: 0.647715, acc.: 64.06%] [G loss: 0.851295]\n",
      "epoch:22 step:21138 [D loss: 0.672837, acc.: 57.03%] [G loss: 0.906188]\n",
      "epoch:22 step:21139 [D loss: 0.710555, acc.: 46.09%] [G loss: 0.850618]\n",
      "epoch:22 step:21140 [D loss: 0.722735, acc.: 50.00%] [G loss: 0.840894]\n",
      "epoch:22 step:21141 [D loss: 0.609592, acc.: 69.53%] [G loss: 0.902619]\n",
      "epoch:22 step:21142 [D loss: 0.665347, acc.: 63.28%] [G loss: 0.874557]\n",
      "epoch:22 step:21143 [D loss: 0.643780, acc.: 57.81%] [G loss: 0.858661]\n",
      "epoch:22 step:21144 [D loss: 0.662889, acc.: 59.38%] [G loss: 0.857718]\n",
      "epoch:22 step:21145 [D loss: 0.671825, acc.: 56.25%] [G loss: 0.857915]\n",
      "epoch:22 step:21146 [D loss: 0.710690, acc.: 47.66%] [G loss: 0.924716]\n",
      "epoch:22 step:21147 [D loss: 0.649243, acc.: 64.06%] [G loss: 0.942330]\n",
      "epoch:22 step:21148 [D loss: 0.636261, acc.: 64.06%] [G loss: 0.882710]\n",
      "epoch:22 step:21149 [D loss: 0.661863, acc.: 59.38%] [G loss: 0.906473]\n",
      "epoch:22 step:21150 [D loss: 0.675152, acc.: 57.81%] [G loss: 0.888205]\n",
      "epoch:22 step:21151 [D loss: 0.664043, acc.: 63.28%] [G loss: 0.841465]\n",
      "epoch:22 step:21152 [D loss: 0.670996, acc.: 61.72%] [G loss: 0.855913]\n",
      "epoch:22 step:21153 [D loss: 0.655131, acc.: 58.59%] [G loss: 0.847022]\n",
      "epoch:22 step:21154 [D loss: 0.622489, acc.: 66.41%] [G loss: 0.839761]\n",
      "epoch:22 step:21155 [D loss: 0.659295, acc.: 59.38%] [G loss: 0.859460]\n",
      "epoch:22 step:21156 [D loss: 0.708197, acc.: 54.69%] [G loss: 0.846976]\n",
      "epoch:22 step:21157 [D loss: 0.630169, acc.: 62.50%] [G loss: 0.926429]\n",
      "epoch:22 step:21158 [D loss: 0.702165, acc.: 49.22%] [G loss: 0.869022]\n",
      "epoch:22 step:21159 [D loss: 0.660891, acc.: 58.59%] [G loss: 0.919359]\n",
      "epoch:22 step:21160 [D loss: 0.683695, acc.: 57.81%] [G loss: 0.931541]\n",
      "epoch:22 step:21161 [D loss: 0.697923, acc.: 55.47%] [G loss: 0.890324]\n",
      "epoch:22 step:21162 [D loss: 0.662686, acc.: 64.84%] [G loss: 0.837800]\n",
      "epoch:22 step:21163 [D loss: 0.691563, acc.: 51.56%] [G loss: 0.887948]\n",
      "epoch:22 step:21164 [D loss: 0.670810, acc.: 60.94%] [G loss: 0.888358]\n",
      "epoch:22 step:21165 [D loss: 0.657643, acc.: 57.03%] [G loss: 0.829613]\n",
      "epoch:22 step:21166 [D loss: 0.672334, acc.: 59.38%] [G loss: 0.880383]\n",
      "epoch:22 step:21167 [D loss: 0.706398, acc.: 44.53%] [G loss: 0.898714]\n",
      "epoch:22 step:21168 [D loss: 0.694782, acc.: 53.12%] [G loss: 0.893940]\n",
      "epoch:22 step:21169 [D loss: 0.635170, acc.: 64.84%] [G loss: 0.878191]\n",
      "epoch:22 step:21170 [D loss: 0.661185, acc.: 60.16%] [G loss: 0.889187]\n",
      "epoch:22 step:21171 [D loss: 0.670109, acc.: 59.38%] [G loss: 0.845268]\n",
      "epoch:22 step:21172 [D loss: 0.692152, acc.: 57.81%] [G loss: 0.852681]\n",
      "epoch:22 step:21173 [D loss: 0.667250, acc.: 57.03%] [G loss: 0.852365]\n",
      "epoch:22 step:21174 [D loss: 0.664474, acc.: 58.59%] [G loss: 0.841528]\n",
      "epoch:22 step:21175 [D loss: 0.680665, acc.: 58.59%] [G loss: 0.838399]\n",
      "epoch:22 step:21176 [D loss: 0.679031, acc.: 60.16%] [G loss: 0.886044]\n",
      "epoch:22 step:21177 [D loss: 0.668496, acc.: 58.59%] [G loss: 0.912495]\n",
      "epoch:22 step:21178 [D loss: 0.644976, acc.: 62.50%] [G loss: 0.881202]\n",
      "epoch:22 step:21179 [D loss: 0.686321, acc.: 57.81%] [G loss: 0.844926]\n",
      "epoch:22 step:21180 [D loss: 0.658752, acc.: 58.59%] [G loss: 0.947974]\n",
      "epoch:22 step:21181 [D loss: 0.640114, acc.: 66.41%] [G loss: 0.907826]\n",
      "epoch:22 step:21182 [D loss: 0.689077, acc.: 56.25%] [G loss: 0.891889]\n",
      "epoch:22 step:21183 [D loss: 0.654063, acc.: 60.94%] [G loss: 0.881167]\n",
      "epoch:22 step:21184 [D loss: 0.655042, acc.: 65.62%] [G loss: 0.863100]\n",
      "epoch:22 step:21185 [D loss: 0.654898, acc.: 60.94%] [G loss: 0.851922]\n",
      "epoch:22 step:21186 [D loss: 0.681736, acc.: 51.56%] [G loss: 0.859122]\n",
      "epoch:22 step:21187 [D loss: 0.652972, acc.: 64.84%] [G loss: 0.904051]\n",
      "epoch:22 step:21188 [D loss: 0.663046, acc.: 64.06%] [G loss: 0.874950]\n",
      "epoch:22 step:21189 [D loss: 0.671759, acc.: 57.81%] [G loss: 0.871568]\n",
      "epoch:22 step:21190 [D loss: 0.620850, acc.: 68.75%] [G loss: 0.880085]\n",
      "epoch:22 step:21191 [D loss: 0.659374, acc.: 61.72%] [G loss: 0.901703]\n",
      "epoch:22 step:21192 [D loss: 0.653678, acc.: 63.28%] [G loss: 0.890221]\n",
      "epoch:22 step:21193 [D loss: 0.674748, acc.: 53.12%] [G loss: 0.866356]\n",
      "epoch:22 step:21194 [D loss: 0.675438, acc.: 57.03%] [G loss: 0.904415]\n",
      "epoch:22 step:21195 [D loss: 0.627889, acc.: 64.84%] [G loss: 0.897619]\n",
      "epoch:22 step:21196 [D loss: 0.637213, acc.: 57.03%] [G loss: 0.934162]\n",
      "epoch:22 step:21197 [D loss: 0.715407, acc.: 49.22%] [G loss: 0.921340]\n",
      "epoch:22 step:21198 [D loss: 0.656980, acc.: 60.94%] [G loss: 0.932018]\n",
      "epoch:22 step:21199 [D loss: 0.638406, acc.: 66.41%] [G loss: 0.918158]\n",
      "epoch:22 step:21200 [D loss: 0.678338, acc.: 57.03%] [G loss: 0.895594]\n",
      "##############\n",
      "[2.93612235 2.26629379 2.484494   3.63674716 1.54100619 7.35600915\n",
      " 3.00543987 3.46378914 4.28438497 7.14868929]\n",
      "##########\n",
      "epoch:22 step:21201 [D loss: 0.644220, acc.: 61.72%] [G loss: 0.904473]\n",
      "epoch:22 step:21202 [D loss: 0.650939, acc.: 62.50%] [G loss: 0.878972]\n",
      "epoch:22 step:21203 [D loss: 0.659576, acc.: 66.41%] [G loss: 0.913250]\n",
      "epoch:22 step:21204 [D loss: 0.653851, acc.: 59.38%] [G loss: 0.883545]\n",
      "epoch:22 step:21205 [D loss: 0.654212, acc.: 61.72%] [G loss: 0.860794]\n",
      "epoch:22 step:21206 [D loss: 0.668633, acc.: 57.81%] [G loss: 0.895346]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21207 [D loss: 0.675340, acc.: 57.03%] [G loss: 0.868206]\n",
      "epoch:22 step:21208 [D loss: 0.664369, acc.: 56.25%] [G loss: 0.841267]\n",
      "epoch:22 step:21209 [D loss: 0.632157, acc.: 67.97%] [G loss: 0.824103]\n",
      "epoch:22 step:21210 [D loss: 0.666998, acc.: 63.28%] [G loss: 0.866979]\n",
      "epoch:22 step:21211 [D loss: 0.677372, acc.: 56.25%] [G loss: 0.917600]\n",
      "epoch:22 step:21212 [D loss: 0.635032, acc.: 64.06%] [G loss: 0.949286]\n",
      "epoch:22 step:21213 [D loss: 0.645896, acc.: 57.81%] [G loss: 0.925209]\n",
      "epoch:22 step:21214 [D loss: 0.668639, acc.: 53.91%] [G loss: 0.942137]\n",
      "epoch:22 step:21215 [D loss: 0.669062, acc.: 58.59%] [G loss: 0.839336]\n",
      "epoch:22 step:21216 [D loss: 0.654275, acc.: 64.84%] [G loss: 0.930341]\n",
      "epoch:22 step:21217 [D loss: 0.699353, acc.: 55.47%] [G loss: 0.901951]\n",
      "epoch:22 step:21218 [D loss: 0.689081, acc.: 57.03%] [G loss: 0.860816]\n",
      "epoch:22 step:21219 [D loss: 0.684618, acc.: 52.34%] [G loss: 0.868348]\n",
      "epoch:22 step:21220 [D loss: 0.694635, acc.: 53.12%] [G loss: 0.860674]\n",
      "epoch:22 step:21221 [D loss: 0.652332, acc.: 64.06%] [G loss: 0.876136]\n",
      "epoch:22 step:21222 [D loss: 0.651737, acc.: 63.28%] [G loss: 0.827887]\n",
      "epoch:22 step:21223 [D loss: 0.647430, acc.: 62.50%] [G loss: 0.841047]\n",
      "epoch:22 step:21224 [D loss: 0.653009, acc.: 56.25%] [G loss: 0.860432]\n",
      "epoch:22 step:21225 [D loss: 0.662235, acc.: 60.94%] [G loss: 0.812848]\n",
      "epoch:22 step:21226 [D loss: 0.677553, acc.: 56.25%] [G loss: 0.830463]\n",
      "epoch:22 step:21227 [D loss: 0.669640, acc.: 57.03%] [G loss: 0.893413]\n",
      "epoch:22 step:21228 [D loss: 0.636895, acc.: 58.59%] [G loss: 0.889187]\n",
      "epoch:22 step:21229 [D loss: 0.687846, acc.: 57.81%] [G loss: 0.853065]\n",
      "epoch:22 step:21230 [D loss: 0.644826, acc.: 62.50%] [G loss: 0.885643]\n",
      "epoch:22 step:21231 [D loss: 0.696263, acc.: 54.69%] [G loss: 0.853143]\n",
      "epoch:22 step:21232 [D loss: 0.617572, acc.: 65.62%] [G loss: 0.884737]\n",
      "epoch:22 step:21233 [D loss: 0.653185, acc.: 59.38%] [G loss: 0.862297]\n",
      "epoch:22 step:21234 [D loss: 0.664658, acc.: 57.81%] [G loss: 0.831561]\n",
      "epoch:22 step:21235 [D loss: 0.700343, acc.: 54.69%] [G loss: 0.821083]\n",
      "epoch:22 step:21236 [D loss: 0.663250, acc.: 54.69%] [G loss: 0.892411]\n",
      "epoch:22 step:21237 [D loss: 0.638264, acc.: 62.50%] [G loss: 0.891842]\n",
      "epoch:22 step:21238 [D loss: 0.655975, acc.: 60.16%] [G loss: 0.928303]\n",
      "epoch:22 step:21239 [D loss: 0.687575, acc.: 55.47%] [G loss: 0.890808]\n",
      "epoch:22 step:21240 [D loss: 0.678933, acc.: 57.81%] [G loss: 0.841161]\n",
      "epoch:22 step:21241 [D loss: 0.679651, acc.: 57.81%] [G loss: 0.901048]\n",
      "epoch:22 step:21242 [D loss: 0.672071, acc.: 59.38%] [G loss: 0.903077]\n",
      "epoch:22 step:21243 [D loss: 0.652131, acc.: 63.28%] [G loss: 0.855910]\n",
      "epoch:22 step:21244 [D loss: 0.665524, acc.: 54.69%] [G loss: 0.844934]\n",
      "epoch:22 step:21245 [D loss: 0.638231, acc.: 61.72%] [G loss: 0.841349]\n",
      "epoch:22 step:21246 [D loss: 0.657131, acc.: 56.25%] [G loss: 0.917406]\n",
      "epoch:22 step:21247 [D loss: 0.670027, acc.: 62.50%] [G loss: 0.861231]\n",
      "epoch:22 step:21248 [D loss: 0.659794, acc.: 57.03%] [G loss: 0.874265]\n",
      "epoch:22 step:21249 [D loss: 0.656322, acc.: 62.50%] [G loss: 0.922806]\n",
      "epoch:22 step:21250 [D loss: 0.645164, acc.: 65.62%] [G loss: 0.925317]\n",
      "epoch:22 step:21251 [D loss: 0.625246, acc.: 63.28%] [G loss: 0.876473]\n",
      "epoch:22 step:21252 [D loss: 0.667538, acc.: 57.81%] [G loss: 0.907176]\n",
      "epoch:22 step:21253 [D loss: 0.685509, acc.: 54.69%] [G loss: 0.881478]\n",
      "epoch:22 step:21254 [D loss: 0.647935, acc.: 61.72%] [G loss: 0.864832]\n",
      "epoch:22 step:21255 [D loss: 0.694923, acc.: 52.34%] [G loss: 0.889200]\n",
      "epoch:22 step:21256 [D loss: 0.690374, acc.: 52.34%] [G loss: 0.904313]\n",
      "epoch:22 step:21257 [D loss: 0.677588, acc.: 58.59%] [G loss: 0.875048]\n",
      "epoch:22 step:21258 [D loss: 0.658098, acc.: 62.50%] [G loss: 0.896875]\n",
      "epoch:22 step:21259 [D loss: 0.663307, acc.: 58.59%] [G loss: 0.901707]\n",
      "epoch:22 step:21260 [D loss: 0.664124, acc.: 58.59%] [G loss: 0.866381]\n",
      "epoch:22 step:21261 [D loss: 0.673335, acc.: 64.84%] [G loss: 0.878585]\n",
      "epoch:22 step:21262 [D loss: 0.635096, acc.: 64.06%] [G loss: 0.888021]\n",
      "epoch:22 step:21263 [D loss: 0.648409, acc.: 64.06%] [G loss: 0.893150]\n",
      "epoch:22 step:21264 [D loss: 0.670339, acc.: 59.38%] [G loss: 0.847960]\n",
      "epoch:22 step:21265 [D loss: 0.676773, acc.: 56.25%] [G loss: 0.859731]\n",
      "epoch:22 step:21266 [D loss: 0.670107, acc.: 60.16%] [G loss: 0.876770]\n",
      "epoch:22 step:21267 [D loss: 0.652851, acc.: 62.50%] [G loss: 0.887862]\n",
      "epoch:22 step:21268 [D loss: 0.634438, acc.: 64.06%] [G loss: 0.904490]\n",
      "epoch:22 step:21269 [D loss: 0.711285, acc.: 50.00%] [G loss: 0.842087]\n",
      "epoch:22 step:21270 [D loss: 0.635250, acc.: 66.41%] [G loss: 0.905553]\n",
      "epoch:22 step:21271 [D loss: 0.649853, acc.: 64.84%] [G loss: 0.893247]\n",
      "epoch:22 step:21272 [D loss: 0.685584, acc.: 52.34%] [G loss: 0.847172]\n",
      "epoch:22 step:21273 [D loss: 0.649245, acc.: 62.50%] [G loss: 0.840548]\n",
      "epoch:22 step:21274 [D loss: 0.716766, acc.: 50.78%] [G loss: 0.834909]\n",
      "epoch:22 step:21275 [D loss: 0.653801, acc.: 64.06%] [G loss: 0.851293]\n",
      "epoch:22 step:21276 [D loss: 0.680150, acc.: 57.81%] [G loss: 0.850256]\n",
      "epoch:22 step:21277 [D loss: 0.630156, acc.: 64.06%] [G loss: 0.875851]\n",
      "epoch:22 step:21278 [D loss: 0.635053, acc.: 67.19%] [G loss: 0.871784]\n",
      "epoch:22 step:21279 [D loss: 0.665059, acc.: 60.16%] [G loss: 0.914607]\n",
      "epoch:22 step:21280 [D loss: 0.675406, acc.: 54.69%] [G loss: 0.878051]\n",
      "epoch:22 step:21281 [D loss: 0.689259, acc.: 58.59%] [G loss: 0.871202]\n",
      "epoch:22 step:21282 [D loss: 0.689270, acc.: 53.12%] [G loss: 0.893985]\n",
      "epoch:22 step:21283 [D loss: 0.655016, acc.: 61.72%] [G loss: 0.885732]\n",
      "epoch:22 step:21284 [D loss: 0.611303, acc.: 69.53%] [G loss: 0.901468]\n",
      "epoch:22 step:21285 [D loss: 0.651021, acc.: 61.72%] [G loss: 0.854061]\n",
      "epoch:22 step:21286 [D loss: 0.688608, acc.: 55.47%] [G loss: 0.902235]\n",
      "epoch:22 step:21287 [D loss: 0.680457, acc.: 55.47%] [G loss: 0.956518]\n",
      "epoch:22 step:21288 [D loss: 0.660519, acc.: 61.72%] [G loss: 0.939569]\n",
      "epoch:22 step:21289 [D loss: 0.663918, acc.: 60.94%] [G loss: 0.868981]\n",
      "epoch:22 step:21290 [D loss: 0.645816, acc.: 61.72%] [G loss: 0.875253]\n",
      "epoch:22 step:21291 [D loss: 0.675310, acc.: 55.47%] [G loss: 0.870180]\n",
      "epoch:22 step:21292 [D loss: 0.676165, acc.: 54.69%] [G loss: 0.927475]\n",
      "epoch:22 step:21293 [D loss: 0.661443, acc.: 54.69%] [G loss: 0.882430]\n",
      "epoch:22 step:21294 [D loss: 0.654837, acc.: 61.72%] [G loss: 0.843873]\n",
      "epoch:22 step:21295 [D loss: 0.651004, acc.: 60.94%] [G loss: 0.853691]\n",
      "epoch:22 step:21296 [D loss: 0.656637, acc.: 56.25%] [G loss: 0.832280]\n",
      "epoch:22 step:21297 [D loss: 0.641904, acc.: 60.16%] [G loss: 0.883712]\n",
      "epoch:22 step:21298 [D loss: 0.648051, acc.: 54.69%] [G loss: 0.816340]\n",
      "epoch:22 step:21299 [D loss: 0.688338, acc.: 51.56%] [G loss: 0.886427]\n",
      "epoch:22 step:21300 [D loss: 0.644290, acc.: 59.38%] [G loss: 0.848669]\n",
      "epoch:22 step:21301 [D loss: 0.656812, acc.: 64.84%] [G loss: 0.896938]\n",
      "epoch:22 step:21302 [D loss: 0.663040, acc.: 56.25%] [G loss: 0.917891]\n",
      "epoch:22 step:21303 [D loss: 0.651040, acc.: 63.28%] [G loss: 0.915820]\n",
      "epoch:22 step:21304 [D loss: 0.635581, acc.: 61.72%] [G loss: 0.924441]\n",
      "epoch:22 step:21305 [D loss: 0.680564, acc.: 55.47%] [G loss: 0.836238]\n",
      "epoch:22 step:21306 [D loss: 0.663962, acc.: 60.94%] [G loss: 0.847504]\n",
      "epoch:22 step:21307 [D loss: 0.653815, acc.: 64.84%] [G loss: 0.888654]\n",
      "epoch:22 step:21308 [D loss: 0.604308, acc.: 73.44%] [G loss: 0.858882]\n",
      "epoch:22 step:21309 [D loss: 0.648641, acc.: 61.72%] [G loss: 0.855564]\n",
      "epoch:22 step:21310 [D loss: 0.625445, acc.: 64.84%] [G loss: 0.889023]\n",
      "epoch:22 step:21311 [D loss: 0.679776, acc.: 57.81%] [G loss: 0.911985]\n",
      "epoch:22 step:21312 [D loss: 0.676907, acc.: 55.47%] [G loss: 0.891050]\n",
      "epoch:22 step:21313 [D loss: 0.681269, acc.: 58.59%] [G loss: 0.849810]\n",
      "epoch:22 step:21314 [D loss: 0.652977, acc.: 60.94%] [G loss: 0.916821]\n",
      "epoch:22 step:21315 [D loss: 0.650352, acc.: 61.72%] [G loss: 0.905960]\n",
      "epoch:22 step:21316 [D loss: 0.632761, acc.: 64.84%] [G loss: 0.891629]\n",
      "epoch:22 step:21317 [D loss: 0.648214, acc.: 64.06%] [G loss: 0.884820]\n",
      "epoch:22 step:21318 [D loss: 0.636040, acc.: 61.72%] [G loss: 0.853820]\n",
      "epoch:22 step:21319 [D loss: 0.659029, acc.: 58.59%] [G loss: 0.875789]\n",
      "epoch:22 step:21320 [D loss: 0.680384, acc.: 53.91%] [G loss: 0.866184]\n",
      "epoch:22 step:21321 [D loss: 0.673457, acc.: 49.22%] [G loss: 0.838066]\n",
      "epoch:22 step:21322 [D loss: 0.681397, acc.: 51.56%] [G loss: 0.913601]\n",
      "epoch:22 step:21323 [D loss: 0.691221, acc.: 56.25%] [G loss: 0.905482]\n",
      "epoch:22 step:21324 [D loss: 0.678387, acc.: 53.91%] [G loss: 0.895297]\n",
      "epoch:22 step:21325 [D loss: 0.645772, acc.: 63.28%] [G loss: 0.837533]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21326 [D loss: 0.685064, acc.: 59.38%] [G loss: 0.923671]\n",
      "epoch:22 step:21327 [D loss: 0.705096, acc.: 57.03%] [G loss: 0.887523]\n",
      "epoch:22 step:21328 [D loss: 0.650356, acc.: 61.72%] [G loss: 0.893577]\n",
      "epoch:22 step:21329 [D loss: 0.683539, acc.: 53.12%] [G loss: 0.838723]\n",
      "epoch:22 step:21330 [D loss: 0.661946, acc.: 53.91%] [G loss: 0.847084]\n",
      "epoch:22 step:21331 [D loss: 0.654071, acc.: 62.50%] [G loss: 0.934942]\n",
      "epoch:22 step:21332 [D loss: 0.645933, acc.: 60.16%] [G loss: 0.902980]\n",
      "epoch:22 step:21333 [D loss: 0.639429, acc.: 64.06%] [G loss: 0.858946]\n",
      "epoch:22 step:21334 [D loss: 0.682397, acc.: 58.59%] [G loss: 0.902136]\n",
      "epoch:22 step:21335 [D loss: 0.678606, acc.: 53.91%] [G loss: 0.822314]\n",
      "epoch:22 step:21336 [D loss: 0.646774, acc.: 63.28%] [G loss: 0.903357]\n",
      "epoch:22 step:21337 [D loss: 0.663981, acc.: 57.03%] [G loss: 0.845861]\n",
      "epoch:22 step:21338 [D loss: 0.679414, acc.: 62.50%] [G loss: 0.882812]\n",
      "epoch:22 step:21339 [D loss: 0.648920, acc.: 59.38%] [G loss: 0.878761]\n",
      "epoch:22 step:21340 [D loss: 0.687753, acc.: 58.59%] [G loss: 0.853527]\n",
      "epoch:22 step:21341 [D loss: 0.646132, acc.: 63.28%] [G loss: 0.934962]\n",
      "epoch:22 step:21342 [D loss: 0.655673, acc.: 64.84%] [G loss: 0.927061]\n",
      "epoch:22 step:21343 [D loss: 0.668924, acc.: 59.38%] [G loss: 0.871249]\n",
      "epoch:22 step:21344 [D loss: 0.655279, acc.: 59.38%] [G loss: 0.955811]\n",
      "epoch:22 step:21345 [D loss: 0.691042, acc.: 59.38%] [G loss: 0.925453]\n",
      "epoch:22 step:21346 [D loss: 0.640035, acc.: 65.62%] [G loss: 0.882318]\n",
      "epoch:22 step:21347 [D loss: 0.652281, acc.: 60.94%] [G loss: 0.911717]\n",
      "epoch:22 step:21348 [D loss: 0.646205, acc.: 66.41%] [G loss: 0.865219]\n",
      "epoch:22 step:21349 [D loss: 0.647847, acc.: 60.94%] [G loss: 0.848549]\n",
      "epoch:22 step:21350 [D loss: 0.629328, acc.: 64.06%] [G loss: 0.783726]\n",
      "epoch:22 step:21351 [D loss: 0.656686, acc.: 58.59%] [G loss: 0.810540]\n",
      "epoch:22 step:21352 [D loss: 0.651125, acc.: 61.72%] [G loss: 0.841906]\n",
      "epoch:22 step:21353 [D loss: 0.664120, acc.: 60.16%] [G loss: 0.814222]\n",
      "epoch:22 step:21354 [D loss: 0.693081, acc.: 49.22%] [G loss: 0.835914]\n",
      "epoch:22 step:21355 [D loss: 0.663839, acc.: 57.81%] [G loss: 0.836993]\n",
      "epoch:22 step:21356 [D loss: 0.648437, acc.: 67.19%] [G loss: 0.902092]\n",
      "epoch:22 step:21357 [D loss: 0.675985, acc.: 58.59%] [G loss: 0.865128]\n",
      "epoch:22 step:21358 [D loss: 0.628302, acc.: 61.72%] [G loss: 0.897365]\n",
      "epoch:22 step:21359 [D loss: 0.629059, acc.: 68.75%] [G loss: 0.976179]\n",
      "epoch:22 step:21360 [D loss: 0.663002, acc.: 61.72%] [G loss: 0.905961]\n",
      "epoch:22 step:21361 [D loss: 0.640916, acc.: 62.50%] [G loss: 0.881102]\n",
      "epoch:22 step:21362 [D loss: 0.637323, acc.: 65.62%] [G loss: 0.829222]\n",
      "epoch:22 step:21363 [D loss: 0.696384, acc.: 52.34%] [G loss: 0.875111]\n",
      "epoch:22 step:21364 [D loss: 0.620488, acc.: 64.84%] [G loss: 0.827332]\n",
      "epoch:22 step:21365 [D loss: 0.645172, acc.: 65.62%] [G loss: 0.826307]\n",
      "epoch:22 step:21366 [D loss: 0.640912, acc.: 66.41%] [G loss: 0.884761]\n",
      "epoch:22 step:21367 [D loss: 0.652119, acc.: 57.03%] [G loss: 0.879441]\n",
      "epoch:22 step:21368 [D loss: 0.732112, acc.: 51.56%] [G loss: 0.881050]\n",
      "epoch:22 step:21369 [D loss: 0.672645, acc.: 60.16%] [G loss: 0.867372]\n",
      "epoch:22 step:21370 [D loss: 0.673078, acc.: 60.94%] [G loss: 0.868987]\n",
      "epoch:22 step:21371 [D loss: 0.646669, acc.: 56.25%] [G loss: 0.919408]\n",
      "epoch:22 step:21372 [D loss: 0.671230, acc.: 57.81%] [G loss: 0.874427]\n",
      "epoch:22 step:21373 [D loss: 0.684974, acc.: 60.16%] [G loss: 0.873383]\n",
      "epoch:22 step:21374 [D loss: 0.626976, acc.: 65.62%] [G loss: 0.869122]\n",
      "epoch:22 step:21375 [D loss: 0.666637, acc.: 60.94%] [G loss: 0.879713]\n",
      "epoch:22 step:21376 [D loss: 0.665015, acc.: 59.38%] [G loss: 0.903241]\n",
      "epoch:22 step:21377 [D loss: 0.639388, acc.: 66.41%] [G loss: 0.924896]\n",
      "epoch:22 step:21378 [D loss: 0.628902, acc.: 66.41%] [G loss: 0.908645]\n",
      "epoch:22 step:21379 [D loss: 0.649180, acc.: 60.16%] [G loss: 0.881425]\n",
      "epoch:22 step:21380 [D loss: 0.638492, acc.: 62.50%] [G loss: 0.935077]\n",
      "epoch:22 step:21381 [D loss: 0.639936, acc.: 66.41%] [G loss: 0.961746]\n",
      "epoch:22 step:21382 [D loss: 0.662473, acc.: 60.16%] [G loss: 0.940119]\n",
      "epoch:22 step:21383 [D loss: 0.637002, acc.: 65.62%] [G loss: 0.908757]\n",
      "epoch:22 step:21384 [D loss: 0.652075, acc.: 56.25%] [G loss: 0.865064]\n",
      "epoch:22 step:21385 [D loss: 0.625526, acc.: 59.38%] [G loss: 0.880864]\n",
      "epoch:22 step:21386 [D loss: 0.660527, acc.: 57.03%] [G loss: 0.895711]\n",
      "epoch:22 step:21387 [D loss: 0.653731, acc.: 62.50%] [G loss: 0.898579]\n",
      "epoch:22 step:21388 [D loss: 0.625272, acc.: 60.94%] [G loss: 0.932419]\n",
      "epoch:22 step:21389 [D loss: 0.635351, acc.: 62.50%] [G loss: 0.915280]\n",
      "epoch:22 step:21390 [D loss: 0.645515, acc.: 62.50%] [G loss: 0.899025]\n",
      "epoch:22 step:21391 [D loss: 0.668570, acc.: 62.50%] [G loss: 0.859387]\n",
      "epoch:22 step:21392 [D loss: 0.631634, acc.: 64.06%] [G loss: 0.960239]\n",
      "epoch:22 step:21393 [D loss: 0.621103, acc.: 63.28%] [G loss: 0.914375]\n",
      "epoch:22 step:21394 [D loss: 0.681351, acc.: 54.69%] [G loss: 0.916384]\n",
      "epoch:22 step:21395 [D loss: 0.663952, acc.: 60.94%] [G loss: 0.935713]\n",
      "epoch:22 step:21396 [D loss: 0.638047, acc.: 64.06%] [G loss: 0.945476]\n",
      "epoch:22 step:21397 [D loss: 0.676540, acc.: 57.03%] [G loss: 0.863552]\n",
      "epoch:22 step:21398 [D loss: 0.668284, acc.: 59.38%] [G loss: 0.882279]\n",
      "epoch:22 step:21399 [D loss: 0.666394, acc.: 60.16%] [G loss: 0.843511]\n",
      "epoch:22 step:21400 [D loss: 0.690011, acc.: 52.34%] [G loss: 0.916417]\n",
      "##############\n",
      "[3.04511449 2.3903365  2.00950333 4.02188603 1.6451311  7.29400459\n",
      " 2.33912833 3.71809784 4.31585567 7.14868929]\n",
      "##########\n",
      "epoch:22 step:21401 [D loss: 0.656486, acc.: 58.59%] [G loss: 0.922239]\n",
      "epoch:22 step:21402 [D loss: 0.647783, acc.: 60.16%] [G loss: 0.904173]\n",
      "epoch:22 step:21403 [D loss: 0.647122, acc.: 62.50%] [G loss: 0.827809]\n",
      "epoch:22 step:21404 [D loss: 0.670071, acc.: 56.25%] [G loss: 0.886011]\n",
      "epoch:22 step:21405 [D loss: 0.653845, acc.: 57.81%] [G loss: 0.887935]\n",
      "epoch:22 step:21406 [D loss: 0.661815, acc.: 62.50%] [G loss: 0.829287]\n",
      "epoch:22 step:21407 [D loss: 0.626611, acc.: 66.41%] [G loss: 0.838268]\n",
      "epoch:22 step:21408 [D loss: 0.635223, acc.: 67.97%] [G loss: 0.883671]\n",
      "epoch:22 step:21409 [D loss: 0.644768, acc.: 62.50%] [G loss: 0.864901]\n",
      "epoch:22 step:21410 [D loss: 0.638054, acc.: 64.84%] [G loss: 0.922829]\n",
      "epoch:22 step:21411 [D loss: 0.650404, acc.: 61.72%] [G loss: 0.911946]\n",
      "epoch:22 step:21412 [D loss: 0.641351, acc.: 62.50%] [G loss: 0.892212]\n",
      "epoch:22 step:21413 [D loss: 0.631658, acc.: 67.19%] [G loss: 0.913155]\n",
      "epoch:22 step:21414 [D loss: 0.642535, acc.: 60.94%] [G loss: 0.896299]\n",
      "epoch:22 step:21415 [D loss: 0.658764, acc.: 62.50%] [G loss: 0.866990]\n",
      "epoch:22 step:21416 [D loss: 0.674557, acc.: 58.59%] [G loss: 0.911534]\n",
      "epoch:22 step:21417 [D loss: 0.638644, acc.: 67.97%] [G loss: 0.856577]\n",
      "epoch:22 step:21418 [D loss: 0.677334, acc.: 60.16%] [G loss: 0.858762]\n",
      "epoch:22 step:21419 [D loss: 0.690809, acc.: 50.78%] [G loss: 0.880974]\n",
      "epoch:22 step:21420 [D loss: 0.648364, acc.: 64.84%] [G loss: 0.861793]\n",
      "epoch:22 step:21421 [D loss: 0.662174, acc.: 53.12%] [G loss: 0.843444]\n",
      "epoch:22 step:21422 [D loss: 0.651032, acc.: 63.28%] [G loss: 0.893793]\n",
      "epoch:22 step:21423 [D loss: 0.638366, acc.: 64.84%] [G loss: 0.908819]\n",
      "epoch:22 step:21424 [D loss: 0.644445, acc.: 61.72%] [G loss: 0.907854]\n",
      "epoch:22 step:21425 [D loss: 0.661889, acc.: 59.38%] [G loss: 0.892282]\n",
      "epoch:22 step:21426 [D loss: 0.651097, acc.: 62.50%] [G loss: 0.878696]\n",
      "epoch:22 step:21427 [D loss: 0.699797, acc.: 57.81%] [G loss: 0.900108]\n",
      "epoch:22 step:21428 [D loss: 0.605443, acc.: 68.75%] [G loss: 0.874130]\n",
      "epoch:22 step:21429 [D loss: 0.649136, acc.: 63.28%] [G loss: 0.888059]\n",
      "epoch:22 step:21430 [D loss: 0.628700, acc.: 60.16%] [G loss: 0.892363]\n",
      "epoch:22 step:21431 [D loss: 0.687316, acc.: 58.59%] [G loss: 0.868131]\n",
      "epoch:22 step:21432 [D loss: 0.677900, acc.: 59.38%] [G loss: 0.958265]\n",
      "epoch:22 step:21433 [D loss: 0.655076, acc.: 64.06%] [G loss: 0.857277]\n",
      "epoch:22 step:21434 [D loss: 0.671940, acc.: 56.25%] [G loss: 0.938036]\n",
      "epoch:22 step:21435 [D loss: 0.635360, acc.: 67.97%] [G loss: 0.856760]\n",
      "epoch:22 step:21436 [D loss: 0.630273, acc.: 62.50%] [G loss: 0.930304]\n",
      "epoch:22 step:21437 [D loss: 0.669280, acc.: 59.38%] [G loss: 0.914286]\n",
      "epoch:22 step:21438 [D loss: 0.675295, acc.: 62.50%] [G loss: 0.917719]\n",
      "epoch:22 step:21439 [D loss: 0.663839, acc.: 62.50%] [G loss: 0.861966]\n",
      "epoch:22 step:21440 [D loss: 0.617175, acc.: 71.88%] [G loss: 0.933021]\n",
      "epoch:22 step:21441 [D loss: 0.654904, acc.: 60.94%] [G loss: 0.871474]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:22 step:21442 [D loss: 0.693927, acc.: 53.12%] [G loss: 0.806834]\n",
      "epoch:22 step:21443 [D loss: 0.629864, acc.: 69.53%] [G loss: 0.845080]\n",
      "epoch:22 step:21444 [D loss: 0.652377, acc.: 61.72%] [G loss: 0.864321]\n",
      "epoch:22 step:21445 [D loss: 0.685177, acc.: 63.28%] [G loss: 0.915446]\n",
      "epoch:22 step:21446 [D loss: 0.634033, acc.: 60.94%] [G loss: 0.916934]\n",
      "epoch:22 step:21447 [D loss: 0.639521, acc.: 68.75%] [G loss: 0.854316]\n",
      "epoch:22 step:21448 [D loss: 0.659505, acc.: 59.38%] [G loss: 0.845576]\n",
      "epoch:22 step:21449 [D loss: 0.705135, acc.: 55.47%] [G loss: 0.851359]\n",
      "epoch:22 step:21450 [D loss: 0.691133, acc.: 55.47%] [G loss: 0.913393]\n",
      "epoch:22 step:21451 [D loss: 0.647523, acc.: 62.50%] [G loss: 0.865322]\n",
      "epoch:22 step:21452 [D loss: 0.671031, acc.: 57.81%] [G loss: 0.880192]\n",
      "epoch:22 step:21453 [D loss: 0.666482, acc.: 53.12%] [G loss: 0.901455]\n",
      "epoch:22 step:21454 [D loss: 0.641031, acc.: 63.28%] [G loss: 0.946400]\n",
      "epoch:22 step:21455 [D loss: 0.662049, acc.: 60.94%] [G loss: 0.873809]\n",
      "epoch:22 step:21456 [D loss: 0.687669, acc.: 53.12%] [G loss: 0.885321]\n",
      "epoch:22 step:21457 [D loss: 0.703129, acc.: 55.47%] [G loss: 0.892625]\n",
      "epoch:22 step:21458 [D loss: 0.689999, acc.: 54.69%] [G loss: 0.860705]\n",
      "epoch:22 step:21459 [D loss: 0.680040, acc.: 59.38%] [G loss: 0.865067]\n",
      "epoch:22 step:21460 [D loss: 0.640912, acc.: 63.28%] [G loss: 0.849350]\n",
      "epoch:22 step:21461 [D loss: 0.672500, acc.: 57.81%] [G loss: 0.901186]\n",
      "epoch:22 step:21462 [D loss: 0.688971, acc.: 57.81%] [G loss: 0.890017]\n",
      "epoch:22 step:21463 [D loss: 0.661389, acc.: 57.81%] [G loss: 0.855690]\n",
      "epoch:22 step:21464 [D loss: 0.639799, acc.: 60.16%] [G loss: 0.869138]\n",
      "epoch:22 step:21465 [D loss: 0.670502, acc.: 64.06%] [G loss: 0.828363]\n",
      "epoch:22 step:21466 [D loss: 0.668455, acc.: 54.69%] [G loss: 0.893313]\n",
      "epoch:22 step:21467 [D loss: 0.695179, acc.: 53.91%] [G loss: 0.920965]\n",
      "epoch:22 step:21468 [D loss: 0.638172, acc.: 62.50%] [G loss: 0.860014]\n",
      "epoch:22 step:21469 [D loss: 0.686643, acc.: 58.59%] [G loss: 0.885288]\n",
      "epoch:22 step:21470 [D loss: 0.636073, acc.: 60.94%] [G loss: 0.908864]\n",
      "epoch:22 step:21471 [D loss: 0.673046, acc.: 55.47%] [G loss: 0.945571]\n",
      "epoch:22 step:21472 [D loss: 0.670003, acc.: 55.47%] [G loss: 0.960806]\n",
      "epoch:22 step:21473 [D loss: 0.661626, acc.: 57.03%] [G loss: 0.886446]\n",
      "epoch:22 step:21474 [D loss: 0.671944, acc.: 56.25%] [G loss: 0.829246]\n",
      "epoch:22 step:21475 [D loss: 0.617532, acc.: 69.53%] [G loss: 0.871101]\n",
      "epoch:22 step:21476 [D loss: 0.662122, acc.: 62.50%] [G loss: 0.869020]\n",
      "epoch:22 step:21477 [D loss: 0.659115, acc.: 64.06%] [G loss: 0.901654]\n",
      "epoch:22 step:21478 [D loss: 0.693509, acc.: 56.25%] [G loss: 0.923282]\n",
      "epoch:22 step:21479 [D loss: 0.659332, acc.: 59.38%] [G loss: 0.896907]\n",
      "epoch:22 step:21480 [D loss: 0.633661, acc.: 63.28%] [G loss: 0.905652]\n",
      "epoch:22 step:21481 [D loss: 0.690779, acc.: 57.81%] [G loss: 0.838754]\n",
      "epoch:22 step:21482 [D loss: 0.649257, acc.: 60.94%] [G loss: 0.875784]\n",
      "epoch:22 step:21483 [D loss: 0.647021, acc.: 63.28%] [G loss: 0.870292]\n",
      "epoch:22 step:21484 [D loss: 0.689979, acc.: 53.91%] [G loss: 0.828083]\n",
      "epoch:22 step:21485 [D loss: 0.648285, acc.: 63.28%] [G loss: 0.897152]\n",
      "epoch:22 step:21486 [D loss: 0.674942, acc.: 53.12%] [G loss: 0.938383]\n",
      "epoch:22 step:21487 [D loss: 0.623450, acc.: 67.19%] [G loss: 0.923198]\n",
      "epoch:22 step:21488 [D loss: 0.657695, acc.: 57.03%] [G loss: 0.926332]\n",
      "epoch:22 step:21489 [D loss: 0.634462, acc.: 68.75%] [G loss: 0.871129]\n",
      "epoch:22 step:21490 [D loss: 0.669644, acc.: 62.50%] [G loss: 0.838099]\n",
      "epoch:22 step:21491 [D loss: 0.685656, acc.: 59.38%] [G loss: 0.855782]\n",
      "epoch:22 step:21492 [D loss: 0.660839, acc.: 53.12%] [G loss: 0.890554]\n",
      "epoch:22 step:21493 [D loss: 0.659917, acc.: 55.47%] [G loss: 0.883820]\n",
      "epoch:22 step:21494 [D loss: 0.666103, acc.: 57.81%] [G loss: 0.868965]\n",
      "epoch:22 step:21495 [D loss: 0.684775, acc.: 56.25%] [G loss: 0.894312]\n",
      "epoch:22 step:21496 [D loss: 0.622722, acc.: 70.31%] [G loss: 0.865580]\n",
      "epoch:22 step:21497 [D loss: 0.652482, acc.: 60.16%] [G loss: 0.878920]\n",
      "epoch:22 step:21498 [D loss: 0.642726, acc.: 63.28%] [G loss: 0.862454]\n",
      "epoch:22 step:21499 [D loss: 0.664963, acc.: 57.03%] [G loss: 0.869250]\n",
      "epoch:22 step:21500 [D loss: 0.699354, acc.: 51.56%] [G loss: 0.930230]\n",
      "epoch:22 step:21501 [D loss: 0.636961, acc.: 57.03%] [G loss: 0.918428]\n",
      "epoch:22 step:21502 [D loss: 0.670129, acc.: 60.16%] [G loss: 0.876524]\n",
      "epoch:22 step:21503 [D loss: 0.681730, acc.: 58.59%] [G loss: 0.865133]\n",
      "epoch:22 step:21504 [D loss: 0.668441, acc.: 60.94%] [G loss: 0.906359]\n",
      "epoch:22 step:21505 [D loss: 0.667576, acc.: 58.59%] [G loss: 0.893463]\n",
      "epoch:22 step:21506 [D loss: 0.613216, acc.: 67.19%] [G loss: 0.887234]\n",
      "epoch:22 step:21507 [D loss: 0.692724, acc.: 55.47%] [G loss: 0.867442]\n",
      "epoch:22 step:21508 [D loss: 0.684457, acc.: 57.81%] [G loss: 0.884341]\n",
      "epoch:22 step:21509 [D loss: 0.608260, acc.: 69.53%] [G loss: 0.918052]\n",
      "epoch:22 step:21510 [D loss: 0.623350, acc.: 64.84%] [G loss: 0.955204]\n",
      "epoch:22 step:21511 [D loss: 0.654759, acc.: 61.72%] [G loss: 0.916487]\n",
      "epoch:22 step:21512 [D loss: 0.703453, acc.: 53.12%] [G loss: 0.938523]\n",
      "epoch:22 step:21513 [D loss: 0.658829, acc.: 57.03%] [G loss: 0.885274]\n",
      "epoch:22 step:21514 [D loss: 0.630877, acc.: 66.41%] [G loss: 0.892221]\n",
      "epoch:22 step:21515 [D loss: 0.687979, acc.: 53.91%] [G loss: 0.847307]\n",
      "epoch:22 step:21516 [D loss: 0.653302, acc.: 62.50%] [G loss: 0.830800]\n",
      "epoch:22 step:21517 [D loss: 0.632268, acc.: 65.62%] [G loss: 0.857403]\n",
      "epoch:22 step:21518 [D loss: 0.618033, acc.: 68.75%] [G loss: 0.866113]\n",
      "epoch:22 step:21519 [D loss: 0.694064, acc.: 54.69%] [G loss: 0.860099]\n",
      "epoch:22 step:21520 [D loss: 0.662662, acc.: 57.81%] [G loss: 0.870580]\n",
      "epoch:22 step:21521 [D loss: 0.676553, acc.: 59.38%] [G loss: 0.874469]\n",
      "epoch:22 step:21522 [D loss: 0.694519, acc.: 53.12%] [G loss: 0.871449]\n",
      "epoch:22 step:21523 [D loss: 0.664325, acc.: 57.81%] [G loss: 0.918885]\n",
      "epoch:22 step:21524 [D loss: 0.666087, acc.: 57.03%] [G loss: 0.904806]\n",
      "epoch:22 step:21525 [D loss: 0.655992, acc.: 60.16%] [G loss: 0.918516]\n",
      "epoch:22 step:21526 [D loss: 0.653492, acc.: 59.38%] [G loss: 0.979332]\n",
      "epoch:22 step:21527 [D loss: 0.678867, acc.: 57.03%] [G loss: 0.835701]\n",
      "epoch:22 step:21528 [D loss: 0.663466, acc.: 63.28%] [G loss: 0.867091]\n",
      "epoch:22 step:21529 [D loss: 0.665877, acc.: 60.94%] [G loss: 0.876367]\n",
      "epoch:22 step:21530 [D loss: 0.657160, acc.: 58.59%] [G loss: 0.851851]\n",
      "epoch:22 step:21531 [D loss: 0.640456, acc.: 63.28%] [G loss: 0.881320]\n",
      "epoch:22 step:21532 [D loss: 0.690318, acc.: 50.00%] [G loss: 0.909002]\n",
      "epoch:22 step:21533 [D loss: 0.622023, acc.: 69.53%] [G loss: 0.877954]\n",
      "epoch:22 step:21534 [D loss: 0.636280, acc.: 60.94%] [G loss: 0.873379]\n",
      "epoch:22 step:21535 [D loss: 0.685586, acc.: 53.12%] [G loss: 0.854985]\n",
      "epoch:22 step:21536 [D loss: 0.644005, acc.: 60.94%] [G loss: 0.908178]\n",
      "epoch:22 step:21537 [D loss: 0.647241, acc.: 55.47%] [G loss: 0.945285]\n",
      "epoch:22 step:21538 [D loss: 0.671543, acc.: 60.16%] [G loss: 0.847238]\n",
      "epoch:22 step:21539 [D loss: 0.671579, acc.: 57.81%] [G loss: 0.874588]\n",
      "epoch:22 step:21540 [D loss: 0.636994, acc.: 63.28%] [G loss: 0.890329]\n",
      "epoch:22 step:21541 [D loss: 0.636021, acc.: 61.72%] [G loss: 0.907309]\n",
      "epoch:22 step:21542 [D loss: 0.666463, acc.: 58.59%] [G loss: 0.880191]\n",
      "epoch:22 step:21543 [D loss: 0.637817, acc.: 63.28%] [G loss: 0.868970]\n",
      "epoch:22 step:21544 [D loss: 0.679258, acc.: 59.38%] [G loss: 0.852923]\n",
      "epoch:22 step:21545 [D loss: 0.657531, acc.: 57.03%] [G loss: 0.862559]\n",
      "epoch:22 step:21546 [D loss: 0.612166, acc.: 68.75%] [G loss: 0.860023]\n",
      "epoch:22 step:21547 [D loss: 0.675351, acc.: 57.03%] [G loss: 0.884357]\n",
      "epoch:22 step:21548 [D loss: 0.649700, acc.: 62.50%] [G loss: 0.845728]\n",
      "epoch:22 step:21549 [D loss: 0.645846, acc.: 62.50%] [G loss: 0.851702]\n",
      "epoch:22 step:21550 [D loss: 0.641858, acc.: 63.28%] [G loss: 0.860313]\n",
      "epoch:22 step:21551 [D loss: 0.642285, acc.: 64.84%] [G loss: 0.887945]\n",
      "epoch:23 step:21552 [D loss: 0.686541, acc.: 51.56%] [G loss: 0.852199]\n",
      "epoch:23 step:21553 [D loss: 0.651297, acc.: 62.50%] [G loss: 0.861691]\n",
      "epoch:23 step:21554 [D loss: 0.698975, acc.: 54.69%] [G loss: 0.915782]\n",
      "epoch:23 step:21555 [D loss: 0.645887, acc.: 59.38%] [G loss: 0.854483]\n",
      "epoch:23 step:21556 [D loss: 0.679969, acc.: 56.25%] [G loss: 0.909366]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21557 [D loss: 0.638842, acc.: 64.84%] [G loss: 0.879117]\n",
      "epoch:23 step:21558 [D loss: 0.688458, acc.: 57.03%] [G loss: 0.841168]\n",
      "epoch:23 step:21559 [D loss: 0.694068, acc.: 55.47%] [G loss: 0.847291]\n",
      "epoch:23 step:21560 [D loss: 0.667790, acc.: 60.16%] [G loss: 0.851012]\n",
      "epoch:23 step:21561 [D loss: 0.623630, acc.: 64.06%] [G loss: 0.826384]\n",
      "epoch:23 step:21562 [D loss: 0.618204, acc.: 65.62%] [G loss: 0.875256]\n",
      "epoch:23 step:21563 [D loss: 0.641824, acc.: 65.62%] [G loss: 0.891188]\n",
      "epoch:23 step:21564 [D loss: 0.675729, acc.: 57.81%] [G loss: 0.914415]\n",
      "epoch:23 step:21565 [D loss: 0.663691, acc.: 60.94%] [G loss: 0.866261]\n",
      "epoch:23 step:21566 [D loss: 0.663446, acc.: 57.81%] [G loss: 0.948816]\n",
      "epoch:23 step:21567 [D loss: 0.612279, acc.: 69.53%] [G loss: 0.884776]\n",
      "epoch:23 step:21568 [D loss: 0.611207, acc.: 71.09%] [G loss: 0.909072]\n",
      "epoch:23 step:21569 [D loss: 0.673338, acc.: 56.25%] [G loss: 0.900098]\n",
      "epoch:23 step:21570 [D loss: 0.628575, acc.: 66.41%] [G loss: 0.861118]\n",
      "epoch:23 step:21571 [D loss: 0.639876, acc.: 62.50%] [G loss: 0.873867]\n",
      "epoch:23 step:21572 [D loss: 0.671597, acc.: 60.94%] [G loss: 0.866806]\n",
      "epoch:23 step:21573 [D loss: 0.651686, acc.: 62.50%] [G loss: 0.881305]\n",
      "epoch:23 step:21574 [D loss: 0.657526, acc.: 61.72%] [G loss: 0.864261]\n",
      "epoch:23 step:21575 [D loss: 0.661259, acc.: 60.16%] [G loss: 0.865404]\n",
      "epoch:23 step:21576 [D loss: 0.634035, acc.: 64.84%] [G loss: 0.905550]\n",
      "epoch:23 step:21577 [D loss: 0.627687, acc.: 61.72%] [G loss: 0.986405]\n",
      "epoch:23 step:21578 [D loss: 0.672862, acc.: 57.03%] [G loss: 0.894551]\n",
      "epoch:23 step:21579 [D loss: 0.649188, acc.: 61.72%] [G loss: 0.856822]\n",
      "epoch:23 step:21580 [D loss: 0.653760, acc.: 60.16%] [G loss: 0.846771]\n",
      "epoch:23 step:21581 [D loss: 0.648634, acc.: 63.28%] [G loss: 0.895547]\n",
      "epoch:23 step:21582 [D loss: 0.693064, acc.: 52.34%] [G loss: 0.861907]\n",
      "epoch:23 step:21583 [D loss: 0.644443, acc.: 64.06%] [G loss: 0.845664]\n",
      "epoch:23 step:21584 [D loss: 0.698303, acc.: 53.91%] [G loss: 0.917406]\n",
      "epoch:23 step:21585 [D loss: 0.671897, acc.: 56.25%] [G loss: 0.887403]\n",
      "epoch:23 step:21586 [D loss: 0.654955, acc.: 60.16%] [G loss: 0.832325]\n",
      "epoch:23 step:21587 [D loss: 0.631501, acc.: 67.19%] [G loss: 0.859221]\n",
      "epoch:23 step:21588 [D loss: 0.666974, acc.: 57.81%] [G loss: 0.874377]\n",
      "epoch:23 step:21589 [D loss: 0.688541, acc.: 57.03%] [G loss: 0.872961]\n",
      "epoch:23 step:21590 [D loss: 0.640647, acc.: 62.50%] [G loss: 0.890537]\n",
      "epoch:23 step:21591 [D loss: 0.658883, acc.: 60.94%] [G loss: 0.909052]\n",
      "epoch:23 step:21592 [D loss: 0.678673, acc.: 57.03%] [G loss: 0.854999]\n",
      "epoch:23 step:21593 [D loss: 0.677193, acc.: 57.81%] [G loss: 0.844747]\n",
      "epoch:23 step:21594 [D loss: 0.688520, acc.: 54.69%] [G loss: 0.874532]\n",
      "epoch:23 step:21595 [D loss: 0.647377, acc.: 57.81%] [G loss: 0.867038]\n",
      "epoch:23 step:21596 [D loss: 0.671606, acc.: 54.69%] [G loss: 0.844562]\n",
      "epoch:23 step:21597 [D loss: 0.656978, acc.: 58.59%] [G loss: 0.879767]\n",
      "epoch:23 step:21598 [D loss: 0.714832, acc.: 49.22%] [G loss: 0.933053]\n",
      "epoch:23 step:21599 [D loss: 0.661867, acc.: 58.59%] [G loss: 0.916942]\n",
      "epoch:23 step:21600 [D loss: 0.627178, acc.: 65.62%] [G loss: 0.948177]\n",
      "##############\n",
      "[2.97617812 2.54379738 2.06753588 3.66789461 1.13995017 7.64346101\n",
      " 2.91185658 3.37830118 4.40514907 6.02691419]\n",
      "##########\n",
      "epoch:23 step:21601 [D loss: 0.653643, acc.: 60.94%] [G loss: 0.910177]\n",
      "epoch:23 step:21602 [D loss: 0.653344, acc.: 64.84%] [G loss: 0.896780]\n",
      "epoch:23 step:21603 [D loss: 0.630754, acc.: 65.62%] [G loss: 0.891505]\n",
      "epoch:23 step:21604 [D loss: 0.648996, acc.: 64.84%] [G loss: 0.890801]\n",
      "epoch:23 step:21605 [D loss: 0.661817, acc.: 61.72%] [G loss: 0.884655]\n",
      "epoch:23 step:21606 [D loss: 0.714981, acc.: 54.69%] [G loss: 0.872246]\n",
      "epoch:23 step:21607 [D loss: 0.633010, acc.: 64.84%] [G loss: 0.848513]\n",
      "epoch:23 step:21608 [D loss: 0.680291, acc.: 57.03%] [G loss: 0.867918]\n",
      "epoch:23 step:21609 [D loss: 0.666007, acc.: 60.94%] [G loss: 0.908529]\n",
      "epoch:23 step:21610 [D loss: 0.622066, acc.: 67.19%] [G loss: 0.882857]\n",
      "epoch:23 step:21611 [D loss: 0.641155, acc.: 65.62%] [G loss: 0.928026]\n",
      "epoch:23 step:21612 [D loss: 0.627600, acc.: 65.62%] [G loss: 0.931515]\n",
      "epoch:23 step:21613 [D loss: 0.623217, acc.: 63.28%] [G loss: 0.978807]\n",
      "epoch:23 step:21614 [D loss: 0.660573, acc.: 60.94%] [G loss: 0.951090]\n",
      "epoch:23 step:21615 [D loss: 0.647152, acc.: 57.03%] [G loss: 0.868174]\n",
      "epoch:23 step:21616 [D loss: 0.633372, acc.: 63.28%] [G loss: 0.848864]\n",
      "epoch:23 step:21617 [D loss: 0.630399, acc.: 62.50%] [G loss: 0.875982]\n",
      "epoch:23 step:21618 [D loss: 0.671873, acc.: 55.47%] [G loss: 0.922697]\n",
      "epoch:23 step:21619 [D loss: 0.646225, acc.: 61.72%] [G loss: 0.917897]\n",
      "epoch:23 step:21620 [D loss: 0.616865, acc.: 64.84%] [G loss: 0.937998]\n",
      "epoch:23 step:21621 [D loss: 0.666183, acc.: 62.50%] [G loss: 0.959345]\n",
      "epoch:23 step:21622 [D loss: 0.621196, acc.: 64.84%] [G loss: 0.943627]\n",
      "epoch:23 step:21623 [D loss: 0.665988, acc.: 60.16%] [G loss: 0.939511]\n",
      "epoch:23 step:21624 [D loss: 0.621005, acc.: 64.84%] [G loss: 0.960271]\n",
      "epoch:23 step:21625 [D loss: 0.682139, acc.: 56.25%] [G loss: 0.897816]\n",
      "epoch:23 step:21626 [D loss: 0.612776, acc.: 67.97%] [G loss: 0.966027]\n",
      "epoch:23 step:21627 [D loss: 0.624657, acc.: 67.97%] [G loss: 0.938075]\n",
      "epoch:23 step:21628 [D loss: 0.673791, acc.: 57.81%] [G loss: 0.915344]\n",
      "epoch:23 step:21629 [D loss: 0.648042, acc.: 58.59%] [G loss: 0.837401]\n",
      "epoch:23 step:21630 [D loss: 0.676047, acc.: 59.38%] [G loss: 0.858026]\n",
      "epoch:23 step:21631 [D loss: 0.675017, acc.: 59.38%] [G loss: 0.932644]\n",
      "epoch:23 step:21632 [D loss: 0.692157, acc.: 50.00%] [G loss: 0.887854]\n",
      "epoch:23 step:21633 [D loss: 0.664730, acc.: 62.50%] [G loss: 0.890622]\n",
      "epoch:23 step:21634 [D loss: 0.656599, acc.: 60.94%] [G loss: 0.930197]\n",
      "epoch:23 step:21635 [D loss: 0.698141, acc.: 51.56%] [G loss: 0.845625]\n",
      "epoch:23 step:21636 [D loss: 0.675678, acc.: 56.25%] [G loss: 0.917520]\n",
      "epoch:23 step:21637 [D loss: 0.670150, acc.: 58.59%] [G loss: 0.885215]\n",
      "epoch:23 step:21638 [D loss: 0.676592, acc.: 56.25%] [G loss: 0.933989]\n",
      "epoch:23 step:21639 [D loss: 0.695696, acc.: 53.91%] [G loss: 0.915141]\n",
      "epoch:23 step:21640 [D loss: 0.660528, acc.: 56.25%] [G loss: 0.899961]\n",
      "epoch:23 step:21641 [D loss: 0.629173, acc.: 67.19%] [G loss: 0.901807]\n",
      "epoch:23 step:21642 [D loss: 0.652692, acc.: 63.28%] [G loss: 0.889228]\n",
      "epoch:23 step:21643 [D loss: 0.671304, acc.: 59.38%] [G loss: 0.899803]\n",
      "epoch:23 step:21644 [D loss: 0.657285, acc.: 61.72%] [G loss: 0.871174]\n",
      "epoch:23 step:21645 [D loss: 0.668323, acc.: 60.94%] [G loss: 0.855793]\n",
      "epoch:23 step:21646 [D loss: 0.665851, acc.: 61.72%] [G loss: 0.909175]\n",
      "epoch:23 step:21647 [D loss: 0.637555, acc.: 60.94%] [G loss: 0.863629]\n",
      "epoch:23 step:21648 [D loss: 0.647726, acc.: 64.06%] [G loss: 0.888711]\n",
      "epoch:23 step:21649 [D loss: 0.650400, acc.: 61.72%] [G loss: 0.889696]\n",
      "epoch:23 step:21650 [D loss: 0.676643, acc.: 57.81%] [G loss: 0.861202]\n",
      "epoch:23 step:21651 [D loss: 0.641566, acc.: 59.38%] [G loss: 0.926733]\n",
      "epoch:23 step:21652 [D loss: 0.646802, acc.: 60.16%] [G loss: 0.881959]\n",
      "epoch:23 step:21653 [D loss: 0.678697, acc.: 58.59%] [G loss: 0.847371]\n",
      "epoch:23 step:21654 [D loss: 0.649000, acc.: 59.38%] [G loss: 0.876647]\n",
      "epoch:23 step:21655 [D loss: 0.671882, acc.: 60.16%] [G loss: 0.879691]\n",
      "epoch:23 step:21656 [D loss: 0.661206, acc.: 57.81%] [G loss: 0.879527]\n",
      "epoch:23 step:21657 [D loss: 0.627686, acc.: 66.41%] [G loss: 0.881716]\n",
      "epoch:23 step:21658 [D loss: 0.638985, acc.: 65.62%] [G loss: 0.897383]\n",
      "epoch:23 step:21659 [D loss: 0.656160, acc.: 63.28%] [G loss: 0.902925]\n",
      "epoch:23 step:21660 [D loss: 0.654185, acc.: 62.50%] [G loss: 0.911365]\n",
      "epoch:23 step:21661 [D loss: 0.675857, acc.: 62.50%] [G loss: 0.888423]\n",
      "epoch:23 step:21662 [D loss: 0.659161, acc.: 66.41%] [G loss: 0.896556]\n",
      "epoch:23 step:21663 [D loss: 0.669899, acc.: 57.03%] [G loss: 0.903396]\n",
      "epoch:23 step:21664 [D loss: 0.630497, acc.: 66.41%] [G loss: 0.888775]\n",
      "epoch:23 step:21665 [D loss: 0.648625, acc.: 60.16%] [G loss: 0.971122]\n",
      "epoch:23 step:21666 [D loss: 0.691527, acc.: 60.16%] [G loss: 0.916024]\n",
      "epoch:23 step:21667 [D loss: 0.670875, acc.: 63.28%] [G loss: 0.957361]\n",
      "epoch:23 step:21668 [D loss: 0.671570, acc.: 55.47%] [G loss: 0.892482]\n",
      "epoch:23 step:21669 [D loss: 0.640445, acc.: 65.62%] [G loss: 0.915298]\n",
      "epoch:23 step:21670 [D loss: 0.625942, acc.: 60.94%] [G loss: 0.889361]\n",
      "epoch:23 step:21671 [D loss: 0.678979, acc.: 58.59%] [G loss: 0.871740]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21672 [D loss: 0.660058, acc.: 62.50%] [G loss: 0.921126]\n",
      "epoch:23 step:21673 [D loss: 0.676950, acc.: 60.94%] [G loss: 0.868958]\n",
      "epoch:23 step:21674 [D loss: 0.678440, acc.: 62.50%] [G loss: 0.872383]\n",
      "epoch:23 step:21675 [D loss: 0.649167, acc.: 62.50%] [G loss: 0.900054]\n",
      "epoch:23 step:21676 [D loss: 0.647027, acc.: 60.94%] [G loss: 0.888274]\n",
      "epoch:23 step:21677 [D loss: 0.662117, acc.: 62.50%] [G loss: 0.904708]\n",
      "epoch:23 step:21678 [D loss: 0.612160, acc.: 70.31%] [G loss: 0.917297]\n",
      "epoch:23 step:21679 [D loss: 0.683439, acc.: 56.25%] [G loss: 0.865027]\n",
      "epoch:23 step:21680 [D loss: 0.677422, acc.: 58.59%] [G loss: 0.909770]\n",
      "epoch:23 step:21681 [D loss: 0.661252, acc.: 59.38%] [G loss: 0.913696]\n",
      "epoch:23 step:21682 [D loss: 0.635473, acc.: 63.28%] [G loss: 0.915985]\n",
      "epoch:23 step:21683 [D loss: 0.677485, acc.: 53.12%] [G loss: 0.904911]\n",
      "epoch:23 step:21684 [D loss: 0.649133, acc.: 59.38%] [G loss: 0.814585]\n",
      "epoch:23 step:21685 [D loss: 0.661079, acc.: 59.38%] [G loss: 0.834039]\n",
      "epoch:23 step:21686 [D loss: 0.706357, acc.: 48.44%] [G loss: 0.785569]\n",
      "epoch:23 step:21687 [D loss: 0.677665, acc.: 57.81%] [G loss: 0.855120]\n",
      "epoch:23 step:21688 [D loss: 0.646495, acc.: 60.16%] [G loss: 0.914895]\n",
      "epoch:23 step:21689 [D loss: 0.664853, acc.: 60.94%] [G loss: 0.898790]\n",
      "epoch:23 step:21690 [D loss: 0.680979, acc.: 59.38%] [G loss: 0.883713]\n",
      "epoch:23 step:21691 [D loss: 0.660910, acc.: 58.59%] [G loss: 0.903359]\n",
      "epoch:23 step:21692 [D loss: 0.686310, acc.: 59.38%] [G loss: 0.814001]\n",
      "epoch:23 step:21693 [D loss: 0.643857, acc.: 60.94%] [G loss: 0.836503]\n",
      "epoch:23 step:21694 [D loss: 0.671280, acc.: 56.25%] [G loss: 0.855613]\n",
      "epoch:23 step:21695 [D loss: 0.639644, acc.: 67.19%] [G loss: 0.863716]\n",
      "epoch:23 step:21696 [D loss: 0.675792, acc.: 53.12%] [G loss: 0.803022]\n",
      "epoch:23 step:21697 [D loss: 0.649367, acc.: 63.28%] [G loss: 0.885190]\n",
      "epoch:23 step:21698 [D loss: 0.656511, acc.: 60.16%] [G loss: 0.857157]\n",
      "epoch:23 step:21699 [D loss: 0.690818, acc.: 53.12%] [G loss: 0.829787]\n",
      "epoch:23 step:21700 [D loss: 0.647513, acc.: 67.19%] [G loss: 0.973214]\n",
      "epoch:23 step:21701 [D loss: 0.675005, acc.: 54.69%] [G loss: 0.832027]\n",
      "epoch:23 step:21702 [D loss: 0.684214, acc.: 58.59%] [G loss: 0.948708]\n",
      "epoch:23 step:21703 [D loss: 0.654749, acc.: 62.50%] [G loss: 0.870480]\n",
      "epoch:23 step:21704 [D loss: 0.668513, acc.: 56.25%] [G loss: 0.841288]\n",
      "epoch:23 step:21705 [D loss: 0.637841, acc.: 64.84%] [G loss: 0.864105]\n",
      "epoch:23 step:21706 [D loss: 0.651735, acc.: 60.94%] [G loss: 0.846001]\n",
      "epoch:23 step:21707 [D loss: 0.659922, acc.: 60.16%] [G loss: 0.814498]\n",
      "epoch:23 step:21708 [D loss: 0.701322, acc.: 57.81%] [G loss: 0.817800]\n",
      "epoch:23 step:21709 [D loss: 0.690334, acc.: 55.47%] [G loss: 0.903148]\n",
      "epoch:23 step:21710 [D loss: 0.633838, acc.: 69.53%] [G loss: 0.886339]\n",
      "epoch:23 step:21711 [D loss: 0.674350, acc.: 54.69%] [G loss: 0.881943]\n",
      "epoch:23 step:21712 [D loss: 0.628869, acc.: 64.84%] [G loss: 0.970943]\n",
      "epoch:23 step:21713 [D loss: 0.664813, acc.: 59.38%] [G loss: 0.926296]\n",
      "epoch:23 step:21714 [D loss: 0.642212, acc.: 65.62%] [G loss: 0.887973]\n",
      "epoch:23 step:21715 [D loss: 0.683722, acc.: 48.44%] [G loss: 0.878770]\n",
      "epoch:23 step:21716 [D loss: 0.674926, acc.: 61.72%] [G loss: 0.824715]\n",
      "epoch:23 step:21717 [D loss: 0.675196, acc.: 57.03%] [G loss: 0.861687]\n",
      "epoch:23 step:21718 [D loss: 0.671858, acc.: 57.81%] [G loss: 0.806548]\n",
      "epoch:23 step:21719 [D loss: 0.677816, acc.: 57.81%] [G loss: 0.888514]\n",
      "epoch:23 step:21720 [D loss: 0.689797, acc.: 58.59%] [G loss: 0.886628]\n",
      "epoch:23 step:21721 [D loss: 0.661950, acc.: 67.97%] [G loss: 0.952297]\n",
      "epoch:23 step:21722 [D loss: 0.635904, acc.: 64.06%] [G loss: 0.876044]\n",
      "epoch:23 step:21723 [D loss: 0.637760, acc.: 63.28%] [G loss: 0.855322]\n",
      "epoch:23 step:21724 [D loss: 0.660492, acc.: 60.94%] [G loss: 0.858490]\n",
      "epoch:23 step:21725 [D loss: 0.642885, acc.: 65.62%] [G loss: 0.881694]\n",
      "epoch:23 step:21726 [D loss: 0.677642, acc.: 54.69%] [G loss: 0.909582]\n",
      "epoch:23 step:21727 [D loss: 0.622911, acc.: 64.84%] [G loss: 0.877663]\n",
      "epoch:23 step:21728 [D loss: 0.625971, acc.: 64.84%] [G loss: 0.889335]\n",
      "epoch:23 step:21729 [D loss: 0.655331, acc.: 56.25%] [G loss: 0.873867]\n",
      "epoch:23 step:21730 [D loss: 0.646963, acc.: 62.50%] [G loss: 0.880177]\n",
      "epoch:23 step:21731 [D loss: 0.654532, acc.: 64.06%] [G loss: 0.826872]\n",
      "epoch:23 step:21732 [D loss: 0.676609, acc.: 55.47%] [G loss: 0.879153]\n",
      "epoch:23 step:21733 [D loss: 0.640667, acc.: 64.84%] [G loss: 0.854015]\n",
      "epoch:23 step:21734 [D loss: 0.665788, acc.: 60.16%] [G loss: 0.866489]\n",
      "epoch:23 step:21735 [D loss: 0.639798, acc.: 65.62%] [G loss: 0.917682]\n",
      "epoch:23 step:21736 [D loss: 0.663416, acc.: 53.12%] [G loss: 0.895673]\n",
      "epoch:23 step:21737 [D loss: 0.679744, acc.: 53.12%] [G loss: 0.880281]\n",
      "epoch:23 step:21738 [D loss: 0.646938, acc.: 65.62%] [G loss: 0.860418]\n",
      "epoch:23 step:21739 [D loss: 0.705605, acc.: 46.09%] [G loss: 0.867674]\n",
      "epoch:23 step:21740 [D loss: 0.647630, acc.: 62.50%] [G loss: 0.869620]\n",
      "epoch:23 step:21741 [D loss: 0.670934, acc.: 55.47%] [G loss: 0.853831]\n",
      "epoch:23 step:21742 [D loss: 0.636042, acc.: 65.62%] [G loss: 0.878427]\n",
      "epoch:23 step:21743 [D loss: 0.688593, acc.: 50.78%] [G loss: 0.859088]\n",
      "epoch:23 step:21744 [D loss: 0.642148, acc.: 65.62%] [G loss: 0.868340]\n",
      "epoch:23 step:21745 [D loss: 0.698890, acc.: 54.69%] [G loss: 0.840263]\n",
      "epoch:23 step:21746 [D loss: 0.644733, acc.: 63.28%] [G loss: 0.868459]\n",
      "epoch:23 step:21747 [D loss: 0.660301, acc.: 53.91%] [G loss: 0.848629]\n",
      "epoch:23 step:21748 [D loss: 0.673626, acc.: 51.56%] [G loss: 0.876577]\n",
      "epoch:23 step:21749 [D loss: 0.670561, acc.: 60.16%] [G loss: 0.865520]\n",
      "epoch:23 step:21750 [D loss: 0.664384, acc.: 58.59%] [G loss: 0.897266]\n",
      "epoch:23 step:21751 [D loss: 0.648370, acc.: 61.72%] [G loss: 0.849292]\n",
      "epoch:23 step:21752 [D loss: 0.652888, acc.: 62.50%] [G loss: 0.850852]\n",
      "epoch:23 step:21753 [D loss: 0.611246, acc.: 67.19%] [G loss: 0.837931]\n",
      "epoch:23 step:21754 [D loss: 0.679784, acc.: 60.16%] [G loss: 0.921288]\n",
      "epoch:23 step:21755 [D loss: 0.680829, acc.: 57.03%] [G loss: 0.924809]\n",
      "epoch:23 step:21756 [D loss: 0.669909, acc.: 60.16%] [G loss: 0.916931]\n",
      "epoch:23 step:21757 [D loss: 0.648026, acc.: 60.94%] [G loss: 0.891764]\n",
      "epoch:23 step:21758 [D loss: 0.618935, acc.: 64.84%] [G loss: 0.884853]\n",
      "epoch:23 step:21759 [D loss: 0.641472, acc.: 59.38%] [G loss: 0.915203]\n",
      "epoch:23 step:21760 [D loss: 0.699471, acc.: 52.34%] [G loss: 0.881688]\n",
      "epoch:23 step:21761 [D loss: 0.668362, acc.: 59.38%] [G loss: 0.849692]\n",
      "epoch:23 step:21762 [D loss: 0.649300, acc.: 53.91%] [G loss: 0.859846]\n",
      "epoch:23 step:21763 [D loss: 0.645588, acc.: 62.50%] [G loss: 0.838550]\n",
      "epoch:23 step:21764 [D loss: 0.670147, acc.: 59.38%] [G loss: 0.853025]\n",
      "epoch:23 step:21765 [D loss: 0.672334, acc.: 61.72%] [G loss: 0.906839]\n",
      "epoch:23 step:21766 [D loss: 0.662886, acc.: 57.81%] [G loss: 0.879312]\n",
      "epoch:23 step:21767 [D loss: 0.685772, acc.: 53.12%] [G loss: 0.865285]\n",
      "epoch:23 step:21768 [D loss: 0.651525, acc.: 57.81%] [G loss: 0.912884]\n",
      "epoch:23 step:21769 [D loss: 0.657077, acc.: 56.25%] [G loss: 0.945925]\n",
      "epoch:23 step:21770 [D loss: 0.683108, acc.: 61.72%] [G loss: 0.891007]\n",
      "epoch:23 step:21771 [D loss: 0.658125, acc.: 60.94%] [G loss: 0.873327]\n",
      "epoch:23 step:21772 [D loss: 0.657016, acc.: 62.50%] [G loss: 0.898027]\n",
      "epoch:23 step:21773 [D loss: 0.684536, acc.: 53.91%] [G loss: 0.864702]\n",
      "epoch:23 step:21774 [D loss: 0.672751, acc.: 55.47%] [G loss: 0.878202]\n",
      "epoch:23 step:21775 [D loss: 0.673982, acc.: 59.38%] [G loss: 0.886388]\n",
      "epoch:23 step:21776 [D loss: 0.657412, acc.: 61.72%] [G loss: 0.907625]\n",
      "epoch:23 step:21777 [D loss: 0.660324, acc.: 64.84%] [G loss: 0.873046]\n",
      "epoch:23 step:21778 [D loss: 0.650970, acc.: 67.19%] [G loss: 0.868638]\n",
      "epoch:23 step:21779 [D loss: 0.667844, acc.: 62.50%] [G loss: 0.845643]\n",
      "epoch:23 step:21780 [D loss: 0.656340, acc.: 57.03%] [G loss: 0.908400]\n",
      "epoch:23 step:21781 [D loss: 0.654529, acc.: 63.28%] [G loss: 0.951437]\n",
      "epoch:23 step:21782 [D loss: 0.677512, acc.: 54.69%] [G loss: 0.947470]\n",
      "epoch:23 step:21783 [D loss: 0.652077, acc.: 57.81%] [G loss: 0.887803]\n",
      "epoch:23 step:21784 [D loss: 0.655587, acc.: 64.06%] [G loss: 0.912580]\n",
      "epoch:23 step:21785 [D loss: 0.644813, acc.: 64.06%] [G loss: 0.892067]\n",
      "epoch:23 step:21786 [D loss: 0.649123, acc.: 60.16%] [G loss: 0.857089]\n",
      "epoch:23 step:21787 [D loss: 0.648202, acc.: 64.84%] [G loss: 0.939722]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21788 [D loss: 0.647109, acc.: 64.06%] [G loss: 0.858789]\n",
      "epoch:23 step:21789 [D loss: 0.662585, acc.: 55.47%] [G loss: 0.776392]\n",
      "epoch:23 step:21790 [D loss: 0.690810, acc.: 57.03%] [G loss: 0.872211]\n",
      "epoch:23 step:21791 [D loss: 0.651158, acc.: 61.72%] [G loss: 0.906385]\n",
      "epoch:23 step:21792 [D loss: 0.660759, acc.: 59.38%] [G loss: 0.872503]\n",
      "epoch:23 step:21793 [D loss: 0.705362, acc.: 53.12%] [G loss: 0.832892]\n",
      "epoch:23 step:21794 [D loss: 0.617110, acc.: 70.31%] [G loss: 0.870652]\n",
      "epoch:23 step:21795 [D loss: 0.664661, acc.: 63.28%] [G loss: 0.816511]\n",
      "epoch:23 step:21796 [D loss: 0.641785, acc.: 65.62%] [G loss: 0.844396]\n",
      "epoch:23 step:21797 [D loss: 0.654869, acc.: 60.94%] [G loss: 0.947489]\n",
      "epoch:23 step:21798 [D loss: 0.626813, acc.: 66.41%] [G loss: 0.868201]\n",
      "epoch:23 step:21799 [D loss: 0.655217, acc.: 63.28%] [G loss: 0.920074]\n",
      "epoch:23 step:21800 [D loss: 0.692229, acc.: 55.47%] [G loss: 0.819932]\n",
      "##############\n",
      "[2.82674063 2.21673328 2.05424524 3.71540406 1.1068069  8.12561374\n",
      " 2.72509026 3.01704347 4.1347012  5.9471476 ]\n",
      "##########\n",
      "epoch:23 step:21801 [D loss: 0.651724, acc.: 60.94%] [G loss: 0.899182]\n",
      "epoch:23 step:21802 [D loss: 0.626723, acc.: 71.88%] [G loss: 0.876932]\n",
      "epoch:23 step:21803 [D loss: 0.633713, acc.: 62.50%] [G loss: 0.911208]\n",
      "epoch:23 step:21804 [D loss: 0.640671, acc.: 64.84%] [G loss: 0.889802]\n",
      "epoch:23 step:21805 [D loss: 0.663854, acc.: 57.81%] [G loss: 0.902981]\n",
      "epoch:23 step:21806 [D loss: 0.674706, acc.: 59.38%] [G loss: 0.851590]\n",
      "epoch:23 step:21807 [D loss: 0.657796, acc.: 61.72%] [G loss: 0.877860]\n",
      "epoch:23 step:21808 [D loss: 0.665705, acc.: 55.47%] [G loss: 0.876171]\n",
      "epoch:23 step:21809 [D loss: 0.666570, acc.: 57.81%] [G loss: 0.915097]\n",
      "epoch:23 step:21810 [D loss: 0.690561, acc.: 60.16%] [G loss: 0.905358]\n",
      "epoch:23 step:21811 [D loss: 0.680728, acc.: 53.91%] [G loss: 0.892454]\n",
      "epoch:23 step:21812 [D loss: 0.649355, acc.: 58.59%] [G loss: 0.857989]\n",
      "epoch:23 step:21813 [D loss: 0.701580, acc.: 51.56%] [G loss: 0.870217]\n",
      "epoch:23 step:21814 [D loss: 0.641790, acc.: 62.50%] [G loss: 0.861519]\n",
      "epoch:23 step:21815 [D loss: 0.664003, acc.: 64.06%] [G loss: 0.944063]\n",
      "epoch:23 step:21816 [D loss: 0.651355, acc.: 55.47%] [G loss: 0.930083]\n",
      "epoch:23 step:21817 [D loss: 0.633048, acc.: 64.06%] [G loss: 0.961129]\n",
      "epoch:23 step:21818 [D loss: 0.693416, acc.: 51.56%] [G loss: 0.905736]\n",
      "epoch:23 step:21819 [D loss: 0.628177, acc.: 66.41%] [G loss: 0.830178]\n",
      "epoch:23 step:21820 [D loss: 0.646960, acc.: 58.59%] [G loss: 0.879747]\n",
      "epoch:23 step:21821 [D loss: 0.651698, acc.: 61.72%] [G loss: 0.885067]\n",
      "epoch:23 step:21822 [D loss: 0.641346, acc.: 58.59%] [G loss: 0.857759]\n",
      "epoch:23 step:21823 [D loss: 0.625585, acc.: 60.16%] [G loss: 0.909866]\n",
      "epoch:23 step:21824 [D loss: 0.689941, acc.: 53.12%] [G loss: 0.955611]\n",
      "epoch:23 step:21825 [D loss: 0.665481, acc.: 57.03%] [G loss: 0.923455]\n",
      "epoch:23 step:21826 [D loss: 0.681283, acc.: 58.59%] [G loss: 0.867863]\n",
      "epoch:23 step:21827 [D loss: 0.671639, acc.: 59.38%] [G loss: 0.849973]\n",
      "epoch:23 step:21828 [D loss: 0.653068, acc.: 59.38%] [G loss: 0.877616]\n",
      "epoch:23 step:21829 [D loss: 0.666145, acc.: 55.47%] [G loss: 0.826988]\n",
      "epoch:23 step:21830 [D loss: 0.637891, acc.: 64.06%] [G loss: 0.901959]\n",
      "epoch:23 step:21831 [D loss: 0.693290, acc.: 50.78%] [G loss: 0.848164]\n",
      "epoch:23 step:21832 [D loss: 0.651777, acc.: 58.59%] [G loss: 0.914143]\n",
      "epoch:23 step:21833 [D loss: 0.645872, acc.: 57.81%] [G loss: 0.883052]\n",
      "epoch:23 step:21834 [D loss: 0.626805, acc.: 66.41%] [G loss: 0.875754]\n",
      "epoch:23 step:21835 [D loss: 0.626018, acc.: 67.19%] [G loss: 0.851908]\n",
      "epoch:23 step:21836 [D loss: 0.620557, acc.: 68.75%] [G loss: 0.900304]\n",
      "epoch:23 step:21837 [D loss: 0.661400, acc.: 56.25%] [G loss: 0.896635]\n",
      "epoch:23 step:21838 [D loss: 0.640346, acc.: 58.59%] [G loss: 0.924479]\n",
      "epoch:23 step:21839 [D loss: 0.624565, acc.: 64.84%] [G loss: 0.862980]\n",
      "epoch:23 step:21840 [D loss: 0.666865, acc.: 60.94%] [G loss: 0.929892]\n",
      "epoch:23 step:21841 [D loss: 0.671945, acc.: 58.59%] [G loss: 0.862583]\n",
      "epoch:23 step:21842 [D loss: 0.672543, acc.: 55.47%] [G loss: 0.848314]\n",
      "epoch:23 step:21843 [D loss: 0.645422, acc.: 65.62%] [G loss: 0.875792]\n",
      "epoch:23 step:21844 [D loss: 0.699437, acc.: 52.34%] [G loss: 0.905659]\n",
      "epoch:23 step:21845 [D loss: 0.623456, acc.: 65.62%] [G loss: 0.910427]\n",
      "epoch:23 step:21846 [D loss: 0.675674, acc.: 57.03%] [G loss: 0.971448]\n",
      "epoch:23 step:21847 [D loss: 0.654462, acc.: 62.50%] [G loss: 0.895551]\n",
      "epoch:23 step:21848 [D loss: 0.617154, acc.: 67.97%] [G loss: 0.906981]\n",
      "epoch:23 step:21849 [D loss: 0.638680, acc.: 61.72%] [G loss: 0.865703]\n",
      "epoch:23 step:21850 [D loss: 0.663498, acc.: 60.16%] [G loss: 0.882922]\n",
      "epoch:23 step:21851 [D loss: 0.678156, acc.: 55.47%] [G loss: 0.962692]\n",
      "epoch:23 step:21852 [D loss: 0.686118, acc.: 57.03%] [G loss: 0.905136]\n",
      "epoch:23 step:21853 [D loss: 0.632503, acc.: 67.97%] [G loss: 0.932524]\n",
      "epoch:23 step:21854 [D loss: 0.674735, acc.: 57.81%] [G loss: 0.924166]\n",
      "epoch:23 step:21855 [D loss: 0.652125, acc.: 60.16%] [G loss: 0.882225]\n",
      "epoch:23 step:21856 [D loss: 0.666549, acc.: 59.38%] [G loss: 0.920300]\n",
      "epoch:23 step:21857 [D loss: 0.617441, acc.: 67.19%] [G loss: 0.863454]\n",
      "epoch:23 step:21858 [D loss: 0.665941, acc.: 57.03%] [G loss: 0.877553]\n",
      "epoch:23 step:21859 [D loss: 0.643400, acc.: 64.06%] [G loss: 0.833110]\n",
      "epoch:23 step:21860 [D loss: 0.662521, acc.: 55.47%] [G loss: 0.836897]\n",
      "epoch:23 step:21861 [D loss: 0.683550, acc.: 57.03%] [G loss: 0.876913]\n",
      "epoch:23 step:21862 [D loss: 0.646900, acc.: 62.50%] [G loss: 0.924571]\n",
      "epoch:23 step:21863 [D loss: 0.641110, acc.: 67.19%] [G loss: 0.880450]\n",
      "epoch:23 step:21864 [D loss: 0.673753, acc.: 58.59%] [G loss: 0.896226]\n",
      "epoch:23 step:21865 [D loss: 0.670240, acc.: 54.69%] [G loss: 0.881368]\n",
      "epoch:23 step:21866 [D loss: 0.648416, acc.: 57.81%] [G loss: 0.931932]\n",
      "epoch:23 step:21867 [D loss: 0.683692, acc.: 58.59%] [G loss: 0.975290]\n",
      "epoch:23 step:21868 [D loss: 0.687606, acc.: 56.25%] [G loss: 0.909304]\n",
      "epoch:23 step:21869 [D loss: 0.632780, acc.: 65.62%] [G loss: 0.990768]\n",
      "epoch:23 step:21870 [D loss: 0.684713, acc.: 54.69%] [G loss: 0.920906]\n",
      "epoch:23 step:21871 [D loss: 0.644118, acc.: 65.62%] [G loss: 0.964932]\n",
      "epoch:23 step:21872 [D loss: 0.664025, acc.: 56.25%] [G loss: 0.945654]\n",
      "epoch:23 step:21873 [D loss: 0.662548, acc.: 60.94%] [G loss: 0.894217]\n",
      "epoch:23 step:21874 [D loss: 0.637271, acc.: 66.41%] [G loss: 0.868251]\n",
      "epoch:23 step:21875 [D loss: 0.682430, acc.: 53.91%] [G loss: 0.826125]\n",
      "epoch:23 step:21876 [D loss: 0.664576, acc.: 60.94%] [G loss: 0.865274]\n",
      "epoch:23 step:21877 [D loss: 0.695974, acc.: 53.91%] [G loss: 0.795949]\n",
      "epoch:23 step:21878 [D loss: 0.679090, acc.: 57.81%] [G loss: 0.878376]\n",
      "epoch:23 step:21879 [D loss: 0.639343, acc.: 65.62%] [G loss: 0.893718]\n",
      "epoch:23 step:21880 [D loss: 0.636726, acc.: 64.06%] [G loss: 0.972687]\n",
      "epoch:23 step:21881 [D loss: 0.628081, acc.: 64.06%] [G loss: 0.910735]\n",
      "epoch:23 step:21882 [D loss: 0.667873, acc.: 57.03%] [G loss: 0.917723]\n",
      "epoch:23 step:21883 [D loss: 0.666989, acc.: 59.38%] [G loss: 0.829044]\n",
      "epoch:23 step:21884 [D loss: 0.664881, acc.: 57.03%] [G loss: 0.905001]\n",
      "epoch:23 step:21885 [D loss: 0.668011, acc.: 53.91%] [G loss: 0.918223]\n",
      "epoch:23 step:21886 [D loss: 0.661951, acc.: 56.25%] [G loss: 0.876398]\n",
      "epoch:23 step:21887 [D loss: 0.619128, acc.: 66.41%] [G loss: 0.932756]\n",
      "epoch:23 step:21888 [D loss: 0.653185, acc.: 63.28%] [G loss: 0.895722]\n",
      "epoch:23 step:21889 [D loss: 0.645825, acc.: 61.72%] [G loss: 0.918161]\n",
      "epoch:23 step:21890 [D loss: 0.656628, acc.: 60.16%] [G loss: 0.888863]\n",
      "epoch:23 step:21891 [D loss: 0.636328, acc.: 63.28%] [G loss: 0.925895]\n",
      "epoch:23 step:21892 [D loss: 0.654521, acc.: 59.38%] [G loss: 0.863441]\n",
      "epoch:23 step:21893 [D loss: 0.645322, acc.: 60.94%] [G loss: 0.884666]\n",
      "epoch:23 step:21894 [D loss: 0.692791, acc.: 53.91%] [G loss: 0.884150]\n",
      "epoch:23 step:21895 [D loss: 0.668945, acc.: 60.94%] [G loss: 0.927679]\n",
      "epoch:23 step:21896 [D loss: 0.658260, acc.: 60.16%] [G loss: 0.956969]\n",
      "epoch:23 step:21897 [D loss: 0.692908, acc.: 56.25%] [G loss: 0.975950]\n",
      "epoch:23 step:21898 [D loss: 0.688042, acc.: 56.25%] [G loss: 0.902033]\n",
      "epoch:23 step:21899 [D loss: 0.672836, acc.: 57.81%] [G loss: 0.950215]\n",
      "epoch:23 step:21900 [D loss: 0.652697, acc.: 59.38%] [G loss: 0.908632]\n",
      "epoch:23 step:21901 [D loss: 0.652226, acc.: 58.59%] [G loss: 0.877859]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:21902 [D loss: 0.647982, acc.: 58.59%] [G loss: 0.916765]\n",
      "epoch:23 step:21903 [D loss: 0.688561, acc.: 57.03%] [G loss: 0.893277]\n",
      "epoch:23 step:21904 [D loss: 0.644043, acc.: 64.06%] [G loss: 0.877521]\n",
      "epoch:23 step:21905 [D loss: 0.700249, acc.: 55.47%] [G loss: 0.853391]\n",
      "epoch:23 step:21906 [D loss: 0.671674, acc.: 58.59%] [G loss: 0.853945]\n",
      "epoch:23 step:21907 [D loss: 0.630988, acc.: 64.06%] [G loss: 0.873816]\n",
      "epoch:23 step:21908 [D loss: 0.682311, acc.: 59.38%] [G loss: 0.820868]\n",
      "epoch:23 step:21909 [D loss: 0.655644, acc.: 62.50%] [G loss: 0.847799]\n",
      "epoch:23 step:21910 [D loss: 0.650353, acc.: 64.84%] [G loss: 0.868537]\n",
      "epoch:23 step:21911 [D loss: 0.644129, acc.: 61.72%] [G loss: 0.870874]\n",
      "epoch:23 step:21912 [D loss: 0.659595, acc.: 57.03%] [G loss: 0.887225]\n",
      "epoch:23 step:21913 [D loss: 0.689516, acc.: 54.69%] [G loss: 0.869170]\n",
      "epoch:23 step:21914 [D loss: 0.661897, acc.: 64.06%] [G loss: 0.887448]\n",
      "epoch:23 step:21915 [D loss: 0.640272, acc.: 63.28%] [G loss: 0.945068]\n",
      "epoch:23 step:21916 [D loss: 0.653179, acc.: 57.81%] [G loss: 0.880733]\n",
      "epoch:23 step:21917 [D loss: 0.649189, acc.: 64.06%] [G loss: 0.927481]\n",
      "epoch:23 step:21918 [D loss: 0.627207, acc.: 63.28%] [G loss: 0.890612]\n",
      "epoch:23 step:21919 [D loss: 0.677906, acc.: 57.03%] [G loss: 0.879545]\n",
      "epoch:23 step:21920 [D loss: 0.655684, acc.: 65.62%] [G loss: 0.890814]\n",
      "epoch:23 step:21921 [D loss: 0.683290, acc.: 59.38%] [G loss: 0.931082]\n",
      "epoch:23 step:21922 [D loss: 0.635935, acc.: 67.19%] [G loss: 0.908891]\n",
      "epoch:23 step:21923 [D loss: 0.643272, acc.: 65.62%] [G loss: 0.893331]\n",
      "epoch:23 step:21924 [D loss: 0.637637, acc.: 64.06%] [G loss: 0.902094]\n",
      "epoch:23 step:21925 [D loss: 0.637991, acc.: 64.06%] [G loss: 0.901343]\n",
      "epoch:23 step:21926 [D loss: 0.657111, acc.: 57.81%] [G loss: 0.856317]\n",
      "epoch:23 step:21927 [D loss: 0.655937, acc.: 58.59%] [G loss: 0.844163]\n",
      "epoch:23 step:21928 [D loss: 0.666718, acc.: 56.25%] [G loss: 0.855647]\n",
      "epoch:23 step:21929 [D loss: 0.613363, acc.: 65.62%] [G loss: 0.827568]\n",
      "epoch:23 step:21930 [D loss: 0.650378, acc.: 60.16%] [G loss: 0.878875]\n",
      "epoch:23 step:21931 [D loss: 0.687623, acc.: 57.03%] [G loss: 0.912682]\n",
      "epoch:23 step:21932 [D loss: 0.662177, acc.: 61.72%] [G loss: 0.885085]\n",
      "epoch:23 step:21933 [D loss: 0.672978, acc.: 59.38%] [G loss: 0.947291]\n",
      "epoch:23 step:21934 [D loss: 0.694818, acc.: 57.03%] [G loss: 0.893977]\n",
      "epoch:23 step:21935 [D loss: 0.655117, acc.: 57.03%] [G loss: 0.982864]\n",
      "epoch:23 step:21936 [D loss: 0.723755, acc.: 49.22%] [G loss: 0.905175]\n",
      "epoch:23 step:21937 [D loss: 0.645232, acc.: 64.84%] [G loss: 0.883858]\n",
      "epoch:23 step:21938 [D loss: 0.607262, acc.: 73.44%] [G loss: 0.932370]\n",
      "epoch:23 step:21939 [D loss: 0.688538, acc.: 55.47%] [G loss: 0.886602]\n",
      "epoch:23 step:21940 [D loss: 0.638893, acc.: 62.50%] [G loss: 0.834183]\n",
      "epoch:23 step:21941 [D loss: 0.646178, acc.: 64.84%] [G loss: 0.829574]\n",
      "epoch:23 step:21942 [D loss: 0.671670, acc.: 53.91%] [G loss: 0.895572]\n",
      "epoch:23 step:21943 [D loss: 0.683503, acc.: 57.03%] [G loss: 0.868289]\n",
      "epoch:23 step:21944 [D loss: 0.719636, acc.: 43.75%] [G loss: 0.856755]\n",
      "epoch:23 step:21945 [D loss: 0.657012, acc.: 54.69%] [G loss: 0.894361]\n",
      "epoch:23 step:21946 [D loss: 0.668992, acc.: 57.03%] [G loss: 0.891160]\n",
      "epoch:23 step:21947 [D loss: 0.635414, acc.: 64.84%] [G loss: 0.885294]\n",
      "epoch:23 step:21948 [D loss: 0.672129, acc.: 63.28%] [G loss: 0.910731]\n",
      "epoch:23 step:21949 [D loss: 0.670444, acc.: 58.59%] [G loss: 0.897446]\n",
      "epoch:23 step:21950 [D loss: 0.636532, acc.: 61.72%] [G loss: 0.848202]\n",
      "epoch:23 step:21951 [D loss: 0.637115, acc.: 60.94%] [G loss: 0.876046]\n",
      "epoch:23 step:21952 [D loss: 0.639497, acc.: 61.72%] [G loss: 0.844660]\n",
      "epoch:23 step:21953 [D loss: 0.652709, acc.: 61.72%] [G loss: 0.931818]\n",
      "epoch:23 step:21954 [D loss: 0.631997, acc.: 65.62%] [G loss: 0.873218]\n",
      "epoch:23 step:21955 [D loss: 0.661443, acc.: 56.25%] [G loss: 0.886537]\n",
      "epoch:23 step:21956 [D loss: 0.625452, acc.: 64.06%] [G loss: 0.862571]\n",
      "epoch:23 step:21957 [D loss: 0.654516, acc.: 58.59%] [G loss: 0.822500]\n",
      "epoch:23 step:21958 [D loss: 0.624189, acc.: 67.19%] [G loss: 0.923036]\n",
      "epoch:23 step:21959 [D loss: 0.653184, acc.: 55.47%] [G loss: 0.908432]\n",
      "epoch:23 step:21960 [D loss: 0.690609, acc.: 53.12%] [G loss: 0.899256]\n",
      "epoch:23 step:21961 [D loss: 0.698268, acc.: 51.56%] [G loss: 0.822610]\n",
      "epoch:23 step:21962 [D loss: 0.636666, acc.: 60.94%] [G loss: 0.853496]\n",
      "epoch:23 step:21963 [D loss: 0.695868, acc.: 51.56%] [G loss: 0.881584]\n",
      "epoch:23 step:21964 [D loss: 0.649588, acc.: 62.50%] [G loss: 0.836672]\n",
      "epoch:23 step:21965 [D loss: 0.627650, acc.: 62.50%] [G loss: 0.887162]\n",
      "epoch:23 step:21966 [D loss: 0.659608, acc.: 56.25%] [G loss: 0.876912]\n",
      "epoch:23 step:21967 [D loss: 0.612676, acc.: 65.62%] [G loss: 0.888609]\n",
      "epoch:23 step:21968 [D loss: 0.626357, acc.: 68.75%] [G loss: 0.890392]\n",
      "epoch:23 step:21969 [D loss: 0.678169, acc.: 57.03%] [G loss: 0.871861]\n",
      "epoch:23 step:21970 [D loss: 0.659655, acc.: 60.16%] [G loss: 0.922564]\n",
      "epoch:23 step:21971 [D loss: 0.636145, acc.: 60.94%] [G loss: 0.803227]\n",
      "epoch:23 step:21972 [D loss: 0.652883, acc.: 68.75%] [G loss: 0.835917]\n",
      "epoch:23 step:21973 [D loss: 0.662068, acc.: 59.38%] [G loss: 0.820537]\n",
      "epoch:23 step:21974 [D loss: 0.676675, acc.: 57.81%] [G loss: 0.829198]\n",
      "epoch:23 step:21975 [D loss: 0.646397, acc.: 59.38%] [G loss: 0.866637]\n",
      "epoch:23 step:21976 [D loss: 0.693515, acc.: 57.03%] [G loss: 0.847944]\n",
      "epoch:23 step:21977 [D loss: 0.656680, acc.: 60.94%] [G loss: 0.902465]\n",
      "epoch:23 step:21978 [D loss: 0.680890, acc.: 61.72%] [G loss: 0.917708]\n",
      "epoch:23 step:21979 [D loss: 0.685922, acc.: 52.34%] [G loss: 0.854589]\n",
      "epoch:23 step:21980 [D loss: 0.657237, acc.: 63.28%] [G loss: 0.927507]\n",
      "epoch:23 step:21981 [D loss: 0.686971, acc.: 60.16%] [G loss: 0.899157]\n",
      "epoch:23 step:21982 [D loss: 0.666144, acc.: 60.94%] [G loss: 0.891023]\n",
      "epoch:23 step:21983 [D loss: 0.646366, acc.: 60.16%] [G loss: 0.877717]\n",
      "epoch:23 step:21984 [D loss: 0.661913, acc.: 57.03%] [G loss: 0.876802]\n",
      "epoch:23 step:21985 [D loss: 0.667276, acc.: 61.72%] [G loss: 0.902916]\n",
      "epoch:23 step:21986 [D loss: 0.665648, acc.: 63.28%] [G loss: 0.913949]\n",
      "epoch:23 step:21987 [D loss: 0.654041, acc.: 61.72%] [G loss: 0.826216]\n",
      "epoch:23 step:21988 [D loss: 0.664192, acc.: 55.47%] [G loss: 0.939437]\n",
      "epoch:23 step:21989 [D loss: 0.676383, acc.: 55.47%] [G loss: 0.898330]\n",
      "epoch:23 step:21990 [D loss: 0.624254, acc.: 63.28%] [G loss: 0.925948]\n",
      "epoch:23 step:21991 [D loss: 0.673963, acc.: 54.69%] [G loss: 0.867236]\n",
      "epoch:23 step:21992 [D loss: 0.659830, acc.: 62.50%] [G loss: 0.865232]\n",
      "epoch:23 step:21993 [D loss: 0.662782, acc.: 63.28%] [G loss: 0.863463]\n",
      "epoch:23 step:21994 [D loss: 0.659401, acc.: 57.03%] [G loss: 0.891421]\n",
      "epoch:23 step:21995 [D loss: 0.667119, acc.: 65.62%] [G loss: 0.831486]\n",
      "epoch:23 step:21996 [D loss: 0.629938, acc.: 64.06%] [G loss: 0.831970]\n",
      "epoch:23 step:21997 [D loss: 0.660302, acc.: 60.94%] [G loss: 0.885703]\n",
      "epoch:23 step:21998 [D loss: 0.646209, acc.: 58.59%] [G loss: 0.794198]\n",
      "epoch:23 step:21999 [D loss: 0.666626, acc.: 58.59%] [G loss: 0.854485]\n",
      "epoch:23 step:22000 [D loss: 0.694034, acc.: 53.12%] [G loss: 0.811325]\n",
      "##############\n",
      "[2.87869768 2.58690738 2.34899776 3.8222865  1.57859028 8.7722727\n",
      " 2.36502304 3.53013157 4.17451399 7.14868929]\n",
      "##########\n",
      "epoch:23 step:22001 [D loss: 0.676160, acc.: 53.91%] [G loss: 0.890336]\n",
      "epoch:23 step:22002 [D loss: 0.635745, acc.: 62.50%] [G loss: 0.865906]\n",
      "epoch:23 step:22003 [D loss: 0.671789, acc.: 62.50%] [G loss: 0.822271]\n",
      "epoch:23 step:22004 [D loss: 0.645723, acc.: 66.41%] [G loss: 0.867850]\n",
      "epoch:23 step:22005 [D loss: 0.680294, acc.: 58.59%] [G loss: 0.866665]\n",
      "epoch:23 step:22006 [D loss: 0.658757, acc.: 57.03%] [G loss: 0.877454]\n",
      "epoch:23 step:22007 [D loss: 0.641106, acc.: 64.84%] [G loss: 0.904313]\n",
      "epoch:23 step:22008 [D loss: 0.676053, acc.: 53.12%] [G loss: 0.874623]\n",
      "epoch:23 step:22009 [D loss: 0.644076, acc.: 61.72%] [G loss: 0.899746]\n",
      "epoch:23 step:22010 [D loss: 0.649550, acc.: 60.16%] [G loss: 0.848807]\n",
      "epoch:23 step:22011 [D loss: 0.617326, acc.: 64.84%] [G loss: 0.949607]\n",
      "epoch:23 step:22012 [D loss: 0.665142, acc.: 54.69%] [G loss: 0.959039]\n",
      "epoch:23 step:22013 [D loss: 0.666908, acc.: 56.25%] [G loss: 0.886334]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22014 [D loss: 0.693789, acc.: 55.47%] [G loss: 0.886168]\n",
      "epoch:23 step:22015 [D loss: 0.675956, acc.: 56.25%] [G loss: 0.862972]\n",
      "epoch:23 step:22016 [D loss: 0.674821, acc.: 57.03%] [G loss: 0.854378]\n",
      "epoch:23 step:22017 [D loss: 0.640406, acc.: 64.84%] [G loss: 0.924958]\n",
      "epoch:23 step:22018 [D loss: 0.638742, acc.: 65.62%] [G loss: 0.849530]\n",
      "epoch:23 step:22019 [D loss: 0.653417, acc.: 61.72%] [G loss: 0.884099]\n",
      "epoch:23 step:22020 [D loss: 0.648061, acc.: 63.28%] [G loss: 0.899405]\n",
      "epoch:23 step:22021 [D loss: 0.668129, acc.: 51.56%] [G loss: 0.895685]\n",
      "epoch:23 step:22022 [D loss: 0.638147, acc.: 61.72%] [G loss: 0.884033]\n",
      "epoch:23 step:22023 [D loss: 0.664565, acc.: 60.16%] [G loss: 0.908375]\n",
      "epoch:23 step:22024 [D loss: 0.642044, acc.: 64.06%] [G loss: 0.884832]\n",
      "epoch:23 step:22025 [D loss: 0.663674, acc.: 53.91%] [G loss: 0.926265]\n",
      "epoch:23 step:22026 [D loss: 0.636589, acc.: 64.84%] [G loss: 0.921509]\n",
      "epoch:23 step:22027 [D loss: 0.666925, acc.: 57.81%] [G loss: 0.929601]\n",
      "epoch:23 step:22028 [D loss: 0.670531, acc.: 59.38%] [G loss: 0.949734]\n",
      "epoch:23 step:22029 [D loss: 0.669022, acc.: 56.25%] [G loss: 0.842120]\n",
      "epoch:23 step:22030 [D loss: 0.680843, acc.: 56.25%] [G loss: 0.901999]\n",
      "epoch:23 step:22031 [D loss: 0.673398, acc.: 58.59%] [G loss: 0.848896]\n",
      "epoch:23 step:22032 [D loss: 0.685483, acc.: 52.34%] [G loss: 0.877942]\n",
      "epoch:23 step:22033 [D loss: 0.680400, acc.: 60.16%] [G loss: 0.860132]\n",
      "epoch:23 step:22034 [D loss: 0.700365, acc.: 47.66%] [G loss: 0.916356]\n",
      "epoch:23 step:22035 [D loss: 0.645704, acc.: 57.03%] [G loss: 0.855491]\n",
      "epoch:23 step:22036 [D loss: 0.645778, acc.: 64.06%] [G loss: 0.897319]\n",
      "epoch:23 step:22037 [D loss: 0.638317, acc.: 62.50%] [G loss: 0.821882]\n",
      "epoch:23 step:22038 [D loss: 0.646481, acc.: 62.50%] [G loss: 0.863251]\n",
      "epoch:23 step:22039 [D loss: 0.619782, acc.: 71.09%] [G loss: 0.886673]\n",
      "epoch:23 step:22040 [D loss: 0.639174, acc.: 64.06%] [G loss: 0.855672]\n",
      "epoch:23 step:22041 [D loss: 0.669796, acc.: 57.81%] [G loss: 0.905961]\n",
      "epoch:23 step:22042 [D loss: 0.661814, acc.: 58.59%] [G loss: 0.793264]\n",
      "epoch:23 step:22043 [D loss: 0.654664, acc.: 58.59%] [G loss: 0.878988]\n",
      "epoch:23 step:22044 [D loss: 0.677804, acc.: 62.50%] [G loss: 0.854181]\n",
      "epoch:23 step:22045 [D loss: 0.645110, acc.: 57.81%] [G loss: 0.929086]\n",
      "epoch:23 step:22046 [D loss: 0.661693, acc.: 60.16%] [G loss: 0.908360]\n",
      "epoch:23 step:22047 [D loss: 0.628227, acc.: 67.19%] [G loss: 0.883895]\n",
      "epoch:23 step:22048 [D loss: 0.664665, acc.: 63.28%] [G loss: 0.856313]\n",
      "epoch:23 step:22049 [D loss: 0.660576, acc.: 61.72%] [G loss: 0.854745]\n",
      "epoch:23 step:22050 [D loss: 0.654272, acc.: 58.59%] [G loss: 0.915586]\n",
      "epoch:23 step:22051 [D loss: 0.644170, acc.: 61.72%] [G loss: 0.871432]\n",
      "epoch:23 step:22052 [D loss: 0.656888, acc.: 57.81%] [G loss: 0.853837]\n",
      "epoch:23 step:22053 [D loss: 0.667561, acc.: 56.25%] [G loss: 0.827977]\n",
      "epoch:23 step:22054 [D loss: 0.654448, acc.: 58.59%] [G loss: 0.810916]\n",
      "epoch:23 step:22055 [D loss: 0.697874, acc.: 60.94%] [G loss: 0.809495]\n",
      "epoch:23 step:22056 [D loss: 0.678692, acc.: 56.25%] [G loss: 0.846415]\n",
      "epoch:23 step:22057 [D loss: 0.684283, acc.: 52.34%] [G loss: 0.893847]\n",
      "epoch:23 step:22058 [D loss: 0.693500, acc.: 51.56%] [G loss: 0.892415]\n",
      "epoch:23 step:22059 [D loss: 0.683445, acc.: 60.16%] [G loss: 0.934843]\n",
      "epoch:23 step:22060 [D loss: 0.648543, acc.: 60.94%] [G loss: 0.909958]\n",
      "epoch:23 step:22061 [D loss: 0.632549, acc.: 67.97%] [G loss: 0.915953]\n",
      "epoch:23 step:22062 [D loss: 0.620587, acc.: 71.88%] [G loss: 0.950330]\n",
      "epoch:23 step:22063 [D loss: 0.707709, acc.: 56.25%] [G loss: 0.924080]\n",
      "epoch:23 step:22064 [D loss: 0.641274, acc.: 58.59%] [G loss: 0.921611]\n",
      "epoch:23 step:22065 [D loss: 0.671928, acc.: 60.16%] [G loss: 0.877638]\n",
      "epoch:23 step:22066 [D loss: 0.637502, acc.: 64.84%] [G loss: 0.881013]\n",
      "epoch:23 step:22067 [D loss: 0.662911, acc.: 61.72%] [G loss: 0.910266]\n",
      "epoch:23 step:22068 [D loss: 0.655968, acc.: 65.62%] [G loss: 0.870476]\n",
      "epoch:23 step:22069 [D loss: 0.681460, acc.: 60.94%] [G loss: 0.910595]\n",
      "epoch:23 step:22070 [D loss: 0.593606, acc.: 69.53%] [G loss: 0.900437]\n",
      "epoch:23 step:22071 [D loss: 0.679130, acc.: 57.03%] [G loss: 0.868093]\n",
      "epoch:23 step:22072 [D loss: 0.638880, acc.: 59.38%] [G loss: 0.895307]\n",
      "epoch:23 step:22073 [D loss: 0.648684, acc.: 59.38%] [G loss: 0.932844]\n",
      "epoch:23 step:22074 [D loss: 0.664398, acc.: 59.38%] [G loss: 0.905710]\n",
      "epoch:23 step:22075 [D loss: 0.624679, acc.: 65.62%] [G loss: 0.940359]\n",
      "epoch:23 step:22076 [D loss: 0.656153, acc.: 57.81%] [G loss: 0.892927]\n",
      "epoch:23 step:22077 [D loss: 0.655142, acc.: 62.50%] [G loss: 0.888564]\n",
      "epoch:23 step:22078 [D loss: 0.643497, acc.: 61.72%] [G loss: 0.881714]\n",
      "epoch:23 step:22079 [D loss: 0.688384, acc.: 58.59%] [G loss: 0.866546]\n",
      "epoch:23 step:22080 [D loss: 0.662024, acc.: 56.25%] [G loss: 0.881234]\n",
      "epoch:23 step:22081 [D loss: 0.716116, acc.: 56.25%] [G loss: 0.900415]\n",
      "epoch:23 step:22082 [D loss: 0.686774, acc.: 57.81%] [G loss: 0.934410]\n",
      "epoch:23 step:22083 [D loss: 0.666532, acc.: 60.94%] [G loss: 0.973723]\n",
      "epoch:23 step:22084 [D loss: 0.684786, acc.: 56.25%] [G loss: 0.874354]\n",
      "epoch:23 step:22085 [D loss: 0.699996, acc.: 55.47%] [G loss: 0.834625]\n",
      "epoch:23 step:22086 [D loss: 0.640952, acc.: 65.62%] [G loss: 0.937952]\n",
      "epoch:23 step:22087 [D loss: 0.702885, acc.: 51.56%] [G loss: 0.898379]\n",
      "epoch:23 step:22088 [D loss: 0.656902, acc.: 59.38%] [G loss: 0.862481]\n",
      "epoch:23 step:22089 [D loss: 0.698664, acc.: 56.25%] [G loss: 0.834638]\n",
      "epoch:23 step:22090 [D loss: 0.665179, acc.: 59.38%] [G loss: 0.905383]\n",
      "epoch:23 step:22091 [D loss: 0.662449, acc.: 61.72%] [G loss: 0.878023]\n",
      "epoch:23 step:22092 [D loss: 0.621717, acc.: 68.75%] [G loss: 0.853027]\n",
      "epoch:23 step:22093 [D loss: 0.664678, acc.: 60.94%] [G loss: 0.915673]\n",
      "epoch:23 step:22094 [D loss: 0.637589, acc.: 61.72%] [G loss: 0.917287]\n",
      "epoch:23 step:22095 [D loss: 0.625518, acc.: 67.19%] [G loss: 0.893545]\n",
      "epoch:23 step:22096 [D loss: 0.631405, acc.: 61.72%] [G loss: 0.891029]\n",
      "epoch:23 step:22097 [D loss: 0.676966, acc.: 55.47%] [G loss: 0.904020]\n",
      "epoch:23 step:22098 [D loss: 0.657525, acc.: 56.25%] [G loss: 0.906288]\n",
      "epoch:23 step:22099 [D loss: 0.663758, acc.: 55.47%] [G loss: 0.856586]\n",
      "epoch:23 step:22100 [D loss: 0.664657, acc.: 60.94%] [G loss: 0.888551]\n",
      "epoch:23 step:22101 [D loss: 0.653732, acc.: 57.03%] [G loss: 0.923843]\n",
      "epoch:23 step:22102 [D loss: 0.676201, acc.: 61.72%] [G loss: 0.845651]\n",
      "epoch:23 step:22103 [D loss: 0.644546, acc.: 64.06%] [G loss: 0.834022]\n",
      "epoch:23 step:22104 [D loss: 0.647862, acc.: 63.28%] [G loss: 0.911512]\n",
      "epoch:23 step:22105 [D loss: 0.677907, acc.: 57.81%] [G loss: 0.918237]\n",
      "epoch:23 step:22106 [D loss: 0.665479, acc.: 60.94%] [G loss: 0.864527]\n",
      "epoch:23 step:22107 [D loss: 0.687348, acc.: 56.25%] [G loss: 0.877237]\n",
      "epoch:23 step:22108 [D loss: 0.671556, acc.: 60.94%] [G loss: 0.899964]\n",
      "epoch:23 step:22109 [D loss: 0.661136, acc.: 58.59%] [G loss: 0.863785]\n",
      "epoch:23 step:22110 [D loss: 0.690235, acc.: 54.69%] [G loss: 0.875949]\n",
      "epoch:23 step:22111 [D loss: 0.658532, acc.: 64.84%] [G loss: 0.849736]\n",
      "epoch:23 step:22112 [D loss: 0.693976, acc.: 53.91%] [G loss: 0.845033]\n",
      "epoch:23 step:22113 [D loss: 0.665956, acc.: 64.06%] [G loss: 0.918055]\n",
      "epoch:23 step:22114 [D loss: 0.659819, acc.: 57.81%] [G loss: 0.904844]\n",
      "epoch:23 step:22115 [D loss: 0.654137, acc.: 62.50%] [G loss: 0.881491]\n",
      "epoch:23 step:22116 [D loss: 0.673852, acc.: 53.91%] [G loss: 0.920089]\n",
      "epoch:23 step:22117 [D loss: 0.609649, acc.: 69.53%] [G loss: 0.901418]\n",
      "epoch:23 step:22118 [D loss: 0.644380, acc.: 63.28%] [G loss: 0.933725]\n",
      "epoch:23 step:22119 [D loss: 0.687380, acc.: 53.91%] [G loss: 0.903935]\n",
      "epoch:23 step:22120 [D loss: 0.649349, acc.: 65.62%] [G loss: 0.930583]\n",
      "epoch:23 step:22121 [D loss: 0.652572, acc.: 64.06%] [G loss: 0.882210]\n",
      "epoch:23 step:22122 [D loss: 0.718397, acc.: 44.53%] [G loss: 0.876558]\n",
      "epoch:23 step:22123 [D loss: 0.668309, acc.: 59.38%] [G loss: 0.820072]\n",
      "epoch:23 step:22124 [D loss: 0.674505, acc.: 57.81%] [G loss: 0.799396]\n",
      "epoch:23 step:22125 [D loss: 0.689338, acc.: 51.56%] [G loss: 0.840109]\n",
      "epoch:23 step:22126 [D loss: 0.637735, acc.: 63.28%] [G loss: 0.868775]\n",
      "epoch:23 step:22127 [D loss: 0.626117, acc.: 67.97%] [G loss: 0.873386]\n",
      "epoch:23 step:22128 [D loss: 0.612664, acc.: 62.50%] [G loss: 0.883497]\n",
      "epoch:23 step:22129 [D loss: 0.641384, acc.: 67.19%] [G loss: 0.905880]\n",
      "epoch:23 step:22130 [D loss: 0.755094, acc.: 44.53%] [G loss: 0.841166]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22131 [D loss: 0.633822, acc.: 61.72%] [G loss: 0.897762]\n",
      "epoch:23 step:22132 [D loss: 0.665942, acc.: 59.38%] [G loss: 0.857233]\n",
      "epoch:23 step:22133 [D loss: 0.649438, acc.: 62.50%] [G loss: 0.835043]\n",
      "epoch:23 step:22134 [D loss: 0.686171, acc.: 54.69%] [G loss: 0.862554]\n",
      "epoch:23 step:22135 [D loss: 0.623794, acc.: 66.41%] [G loss: 0.840609]\n",
      "epoch:23 step:22136 [D loss: 0.639977, acc.: 63.28%] [G loss: 0.836701]\n",
      "epoch:23 step:22137 [D loss: 0.615073, acc.: 68.75%] [G loss: 0.808871]\n",
      "epoch:23 step:22138 [D loss: 0.657960, acc.: 59.38%] [G loss: 0.823970]\n",
      "epoch:23 step:22139 [D loss: 0.655331, acc.: 61.72%] [G loss: 0.886595]\n",
      "epoch:23 step:22140 [D loss: 0.643186, acc.: 64.06%] [G loss: 0.895518]\n",
      "epoch:23 step:22141 [D loss: 0.652349, acc.: 66.41%] [G loss: 0.871688]\n",
      "epoch:23 step:22142 [D loss: 0.657598, acc.: 57.81%] [G loss: 0.869478]\n",
      "epoch:23 step:22143 [D loss: 0.646448, acc.: 60.94%] [G loss: 0.921856]\n",
      "epoch:23 step:22144 [D loss: 0.682293, acc.: 50.00%] [G loss: 0.980363]\n",
      "epoch:23 step:22145 [D loss: 0.608317, acc.: 71.88%] [G loss: 0.924095]\n",
      "epoch:23 step:22146 [D loss: 0.633083, acc.: 69.53%] [G loss: 0.852271]\n",
      "epoch:23 step:22147 [D loss: 0.638506, acc.: 65.62%] [G loss: 0.897438]\n",
      "epoch:23 step:22148 [D loss: 0.669653, acc.: 56.25%] [G loss: 0.861588]\n",
      "epoch:23 step:22149 [D loss: 0.645726, acc.: 62.50%] [G loss: 0.883686]\n",
      "epoch:23 step:22150 [D loss: 0.634302, acc.: 64.06%] [G loss: 0.849866]\n",
      "epoch:23 step:22151 [D loss: 0.639942, acc.: 67.97%] [G loss: 0.920357]\n",
      "epoch:23 step:22152 [D loss: 0.663472, acc.: 63.28%] [G loss: 0.866005]\n",
      "epoch:23 step:22153 [D loss: 0.674703, acc.: 61.72%] [G loss: 0.845641]\n",
      "epoch:23 step:22154 [D loss: 0.687689, acc.: 56.25%] [G loss: 0.916762]\n",
      "epoch:23 step:22155 [D loss: 0.656013, acc.: 64.84%] [G loss: 0.901912]\n",
      "epoch:23 step:22156 [D loss: 0.655926, acc.: 60.16%] [G loss: 0.911561]\n",
      "epoch:23 step:22157 [D loss: 0.640559, acc.: 71.88%] [G loss: 0.969011]\n",
      "epoch:23 step:22158 [D loss: 0.643723, acc.: 59.38%] [G loss: 0.931744]\n",
      "epoch:23 step:22159 [D loss: 0.673538, acc.: 55.47%] [G loss: 0.919325]\n",
      "epoch:23 step:22160 [D loss: 0.654310, acc.: 67.19%] [G loss: 0.869699]\n",
      "epoch:23 step:22161 [D loss: 0.639673, acc.: 61.72%] [G loss: 0.877068]\n",
      "epoch:23 step:22162 [D loss: 0.665584, acc.: 58.59%] [G loss: 0.884053]\n",
      "epoch:23 step:22163 [D loss: 0.666432, acc.: 61.72%] [G loss: 0.897422]\n",
      "epoch:23 step:22164 [D loss: 0.655475, acc.: 59.38%] [G loss: 0.910831]\n",
      "epoch:23 step:22165 [D loss: 0.678212, acc.: 54.69%] [G loss: 0.920606]\n",
      "epoch:23 step:22166 [D loss: 0.657564, acc.: 65.62%] [G loss: 0.917877]\n",
      "epoch:23 step:22167 [D loss: 0.611797, acc.: 69.53%] [G loss: 0.941102]\n",
      "epoch:23 step:22168 [D loss: 0.695594, acc.: 59.38%] [G loss: 0.927189]\n",
      "epoch:23 step:22169 [D loss: 0.628832, acc.: 66.41%] [G loss: 0.891172]\n",
      "epoch:23 step:22170 [D loss: 0.683672, acc.: 58.59%] [G loss: 0.857745]\n",
      "epoch:23 step:22171 [D loss: 0.640916, acc.: 61.72%] [G loss: 0.900060]\n",
      "epoch:23 step:22172 [D loss: 0.664750, acc.: 62.50%] [G loss: 0.889849]\n",
      "epoch:23 step:22173 [D loss: 0.656675, acc.: 60.94%] [G loss: 0.861024]\n",
      "epoch:23 step:22174 [D loss: 0.648296, acc.: 65.62%] [G loss: 0.877074]\n",
      "epoch:23 step:22175 [D loss: 0.643473, acc.: 65.62%] [G loss: 0.883276]\n",
      "epoch:23 step:22176 [D loss: 0.659412, acc.: 58.59%] [G loss: 0.893071]\n",
      "epoch:23 step:22177 [D loss: 0.696667, acc.: 55.47%] [G loss: 0.904029]\n",
      "epoch:23 step:22178 [D loss: 0.615199, acc.: 65.62%] [G loss: 0.869899]\n",
      "epoch:23 step:22179 [D loss: 0.682902, acc.: 54.69%] [G loss: 0.903464]\n",
      "epoch:23 step:22180 [D loss: 0.637136, acc.: 61.72%] [G loss: 0.914734]\n",
      "epoch:23 step:22181 [D loss: 0.678127, acc.: 59.38%] [G loss: 0.868940]\n",
      "epoch:23 step:22182 [D loss: 0.634332, acc.: 57.03%] [G loss: 0.903552]\n",
      "epoch:23 step:22183 [D loss: 0.650746, acc.: 60.94%] [G loss: 0.913397]\n",
      "epoch:23 step:22184 [D loss: 0.632675, acc.: 66.41%] [G loss: 0.898158]\n",
      "epoch:23 step:22185 [D loss: 0.670201, acc.: 60.94%] [G loss: 0.887111]\n",
      "epoch:23 step:22186 [D loss: 0.618302, acc.: 69.53%] [G loss: 0.910772]\n",
      "epoch:23 step:22187 [D loss: 0.615715, acc.: 64.84%] [G loss: 0.956027]\n",
      "epoch:23 step:22188 [D loss: 0.626583, acc.: 64.06%] [G loss: 0.902079]\n",
      "epoch:23 step:22189 [D loss: 0.692222, acc.: 53.12%] [G loss: 0.899163]\n",
      "epoch:23 step:22190 [D loss: 0.672477, acc.: 59.38%] [G loss: 0.930053]\n",
      "epoch:23 step:22191 [D loss: 0.661371, acc.: 60.16%] [G loss: 0.959370]\n",
      "epoch:23 step:22192 [D loss: 0.679519, acc.: 64.84%] [G loss: 0.910125]\n",
      "epoch:23 step:22193 [D loss: 0.672976, acc.: 55.47%] [G loss: 0.876767]\n",
      "epoch:23 step:22194 [D loss: 0.717609, acc.: 46.88%] [G loss: 0.947014]\n",
      "epoch:23 step:22195 [D loss: 0.655220, acc.: 59.38%] [G loss: 0.885967]\n",
      "epoch:23 step:22196 [D loss: 0.668568, acc.: 53.12%] [G loss: 0.863155]\n",
      "epoch:23 step:22197 [D loss: 0.659794, acc.: 60.16%] [G loss: 0.914150]\n",
      "epoch:23 step:22198 [D loss: 0.692435, acc.: 57.03%] [G loss: 0.922714]\n",
      "epoch:23 step:22199 [D loss: 0.683867, acc.: 54.69%] [G loss: 0.911736]\n",
      "epoch:23 step:22200 [D loss: 0.652977, acc.: 62.50%] [G loss: 0.953023]\n",
      "##############\n",
      "[2.7937372  2.24936726 2.26377455 3.58981352 1.29288527 7.34898686\n",
      " 2.60361139 3.68717206 4.15185104 7.14868929]\n",
      "##########\n",
      "epoch:23 step:22201 [D loss: 0.645315, acc.: 62.50%] [G loss: 0.922763]\n",
      "epoch:23 step:22202 [D loss: 0.615000, acc.: 68.75%] [G loss: 0.921865]\n",
      "epoch:23 step:22203 [D loss: 0.669977, acc.: 61.72%] [G loss: 0.884585]\n",
      "epoch:23 step:22204 [D loss: 0.671806, acc.: 60.94%] [G loss: 0.822594]\n",
      "epoch:23 step:22205 [D loss: 0.640618, acc.: 67.97%] [G loss: 0.838298]\n",
      "epoch:23 step:22206 [D loss: 0.654188, acc.: 57.03%] [G loss: 0.821639]\n",
      "epoch:23 step:22207 [D loss: 0.639195, acc.: 64.06%] [G loss: 0.863118]\n",
      "epoch:23 step:22208 [D loss: 0.663783, acc.: 64.06%] [G loss: 0.903350]\n",
      "epoch:23 step:22209 [D loss: 0.703792, acc.: 57.03%] [G loss: 0.934467]\n",
      "epoch:23 step:22210 [D loss: 0.657391, acc.: 57.81%] [G loss: 0.839047]\n",
      "epoch:23 step:22211 [D loss: 0.676691, acc.: 51.56%] [G loss: 0.850056]\n",
      "epoch:23 step:22212 [D loss: 0.658683, acc.: 60.16%] [G loss: 0.828069]\n",
      "epoch:23 step:22213 [D loss: 0.676371, acc.: 59.38%] [G loss: 0.854173]\n",
      "epoch:23 step:22214 [D loss: 0.646717, acc.: 64.84%] [G loss: 0.895385]\n",
      "epoch:23 step:22215 [D loss: 0.647685, acc.: 60.94%] [G loss: 0.949612]\n",
      "epoch:23 step:22216 [D loss: 0.670412, acc.: 58.59%] [G loss: 0.931260]\n",
      "epoch:23 step:22217 [D loss: 0.658898, acc.: 59.38%] [G loss: 0.889535]\n",
      "epoch:23 step:22218 [D loss: 0.652407, acc.: 58.59%] [G loss: 0.899436]\n",
      "epoch:23 step:22219 [D loss: 0.665445, acc.: 60.16%] [G loss: 0.930352]\n",
      "epoch:23 step:22220 [D loss: 0.639713, acc.: 61.72%] [G loss: 0.865688]\n",
      "epoch:23 step:22221 [D loss: 0.643333, acc.: 58.59%] [G loss: 0.897220]\n",
      "epoch:23 step:22222 [D loss: 0.616994, acc.: 69.53%] [G loss: 0.863796]\n",
      "epoch:23 step:22223 [D loss: 0.668176, acc.: 50.00%] [G loss: 0.866444]\n",
      "epoch:23 step:22224 [D loss: 0.688076, acc.: 57.03%] [G loss: 0.906039]\n",
      "epoch:23 step:22225 [D loss: 0.666799, acc.: 56.25%] [G loss: 0.849800]\n",
      "epoch:23 step:22226 [D loss: 0.640951, acc.: 58.59%] [G loss: 0.827330]\n",
      "epoch:23 step:22227 [D loss: 0.657996, acc.: 59.38%] [G loss: 0.916927]\n",
      "epoch:23 step:22228 [D loss: 0.684642, acc.: 55.47%] [G loss: 0.908528]\n",
      "epoch:23 step:22229 [D loss: 0.635956, acc.: 66.41%] [G loss: 0.909964]\n",
      "epoch:23 step:22230 [D loss: 0.648237, acc.: 64.06%] [G loss: 0.881390]\n",
      "epoch:23 step:22231 [D loss: 0.698273, acc.: 50.00%] [G loss: 0.867592]\n",
      "epoch:23 step:22232 [D loss: 0.652281, acc.: 62.50%] [G loss: 0.870953]\n",
      "epoch:23 step:22233 [D loss: 0.637908, acc.: 63.28%] [G loss: 0.923409]\n",
      "epoch:23 step:22234 [D loss: 0.679647, acc.: 54.69%] [G loss: 0.869852]\n",
      "epoch:23 step:22235 [D loss: 0.647235, acc.: 60.94%] [G loss: 0.841452]\n",
      "epoch:23 step:22236 [D loss: 0.651438, acc.: 57.03%] [G loss: 0.848955]\n",
      "epoch:23 step:22237 [D loss: 0.661460, acc.: 59.38%] [G loss: 0.880435]\n",
      "epoch:23 step:22238 [D loss: 0.653005, acc.: 60.94%] [G loss: 0.934383]\n",
      "epoch:23 step:22239 [D loss: 0.700051, acc.: 50.78%] [G loss: 0.904586]\n",
      "epoch:23 step:22240 [D loss: 0.664678, acc.: 60.94%] [G loss: 0.933942]\n",
      "epoch:23 step:22241 [D loss: 0.648620, acc.: 58.59%] [G loss: 0.954516]\n",
      "epoch:23 step:22242 [D loss: 0.681030, acc.: 52.34%] [G loss: 0.910560]\n",
      "epoch:23 step:22243 [D loss: 0.686479, acc.: 50.78%] [G loss: 0.892134]\n",
      "epoch:23 step:22244 [D loss: 0.660792, acc.: 56.25%] [G loss: 0.840581]\n",
      "epoch:23 step:22245 [D loss: 0.642730, acc.: 62.50%] [G loss: 0.893318]\n",
      "epoch:23 step:22246 [D loss: 0.658257, acc.: 65.62%] [G loss: 0.969970]\n",
      "epoch:23 step:22247 [D loss: 0.657001, acc.: 58.59%] [G loss: 0.867307]\n",
      "epoch:23 step:22248 [D loss: 0.659735, acc.: 62.50%] [G loss: 0.921386]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22249 [D loss: 0.650118, acc.: 60.94%] [G loss: 0.917761]\n",
      "epoch:23 step:22250 [D loss: 0.659833, acc.: 60.16%] [G loss: 0.894314]\n",
      "epoch:23 step:22251 [D loss: 0.653226, acc.: 57.81%] [G loss: 0.859924]\n",
      "epoch:23 step:22252 [D loss: 0.658507, acc.: 63.28%] [G loss: 0.898223]\n",
      "epoch:23 step:22253 [D loss: 0.654585, acc.: 60.16%] [G loss: 0.890976]\n",
      "epoch:23 step:22254 [D loss: 0.701167, acc.: 52.34%] [G loss: 0.895293]\n",
      "epoch:23 step:22255 [D loss: 0.681360, acc.: 56.25%] [G loss: 0.885993]\n",
      "epoch:23 step:22256 [D loss: 0.657314, acc.: 58.59%] [G loss: 0.875756]\n",
      "epoch:23 step:22257 [D loss: 0.654912, acc.: 60.94%] [G loss: 0.830418]\n",
      "epoch:23 step:22258 [D loss: 0.667480, acc.: 60.16%] [G loss: 0.874300]\n",
      "epoch:23 step:22259 [D loss: 0.669147, acc.: 54.69%] [G loss: 0.917627]\n",
      "epoch:23 step:22260 [D loss: 0.707476, acc.: 54.69%] [G loss: 0.893653]\n",
      "epoch:23 step:22261 [D loss: 0.610090, acc.: 66.41%] [G loss: 0.919805]\n",
      "epoch:23 step:22262 [D loss: 0.661066, acc.: 60.16%] [G loss: 0.909858]\n",
      "epoch:23 step:22263 [D loss: 0.667643, acc.: 60.94%] [G loss: 0.882705]\n",
      "epoch:23 step:22264 [D loss: 0.674983, acc.: 55.47%] [G loss: 0.872823]\n",
      "epoch:23 step:22265 [D loss: 0.674790, acc.: 56.25%] [G loss: 0.857971]\n",
      "epoch:23 step:22266 [D loss: 0.705463, acc.: 50.00%] [G loss: 0.826901]\n",
      "epoch:23 step:22267 [D loss: 0.700488, acc.: 49.22%] [G loss: 0.873245]\n",
      "epoch:23 step:22268 [D loss: 0.625202, acc.: 63.28%] [G loss: 0.915776]\n",
      "epoch:23 step:22269 [D loss: 0.648779, acc.: 62.50%] [G loss: 0.860265]\n",
      "epoch:23 step:22270 [D loss: 0.681955, acc.: 57.03%] [G loss: 0.901737]\n",
      "epoch:23 step:22271 [D loss: 0.631970, acc.: 67.19%] [G loss: 0.863537]\n",
      "epoch:23 step:22272 [D loss: 0.655488, acc.: 64.06%] [G loss: 0.882363]\n",
      "epoch:23 step:22273 [D loss: 0.629053, acc.: 64.06%] [G loss: 0.884042]\n",
      "epoch:23 step:22274 [D loss: 0.706801, acc.: 49.22%] [G loss: 0.919450]\n",
      "epoch:23 step:22275 [D loss: 0.681781, acc.: 53.12%] [G loss: 0.908363]\n",
      "epoch:23 step:22276 [D loss: 0.645735, acc.: 64.84%] [G loss: 0.903321]\n",
      "epoch:23 step:22277 [D loss: 0.666881, acc.: 62.50%] [G loss: 0.857660]\n",
      "epoch:23 step:22278 [D loss: 0.656737, acc.: 60.16%] [G loss: 0.906932]\n",
      "epoch:23 step:22279 [D loss: 0.729540, acc.: 45.31%] [G loss: 0.877014]\n",
      "epoch:23 step:22280 [D loss: 0.660398, acc.: 57.81%] [G loss: 0.887521]\n",
      "epoch:23 step:22281 [D loss: 0.670275, acc.: 57.81%] [G loss: 0.858509]\n",
      "epoch:23 step:22282 [D loss: 0.686594, acc.: 56.25%] [G loss: 0.939857]\n",
      "epoch:23 step:22283 [D loss: 0.649624, acc.: 62.50%] [G loss: 0.905641]\n",
      "epoch:23 step:22284 [D loss: 0.627480, acc.: 66.41%] [G loss: 0.955870]\n",
      "epoch:23 step:22285 [D loss: 0.647428, acc.: 63.28%] [G loss: 0.927264]\n",
      "epoch:23 step:22286 [D loss: 0.637876, acc.: 66.41%] [G loss: 0.866767]\n",
      "epoch:23 step:22287 [D loss: 0.668958, acc.: 54.69%] [G loss: 0.886823]\n",
      "epoch:23 step:22288 [D loss: 0.645878, acc.: 60.16%] [G loss: 0.836093]\n",
      "epoch:23 step:22289 [D loss: 0.663760, acc.: 55.47%] [G loss: 0.850282]\n",
      "epoch:23 step:22290 [D loss: 0.667407, acc.: 54.69%] [G loss: 0.869665]\n",
      "epoch:23 step:22291 [D loss: 0.673426, acc.: 57.81%] [G loss: 0.886838]\n",
      "epoch:23 step:22292 [D loss: 0.654406, acc.: 58.59%] [G loss: 0.867521]\n",
      "epoch:23 step:22293 [D loss: 0.677600, acc.: 59.38%] [G loss: 0.890192]\n",
      "epoch:23 step:22294 [D loss: 0.711466, acc.: 47.66%] [G loss: 0.837754]\n",
      "epoch:23 step:22295 [D loss: 0.655433, acc.: 63.28%] [G loss: 0.861884]\n",
      "epoch:23 step:22296 [D loss: 0.665888, acc.: 59.38%] [G loss: 0.883222]\n",
      "epoch:23 step:22297 [D loss: 0.656380, acc.: 61.72%] [G loss: 0.912710]\n",
      "epoch:23 step:22298 [D loss: 0.668881, acc.: 60.94%] [G loss: 0.824357]\n",
      "epoch:23 step:22299 [D loss: 0.634543, acc.: 62.50%] [G loss: 0.868193]\n",
      "epoch:23 step:22300 [D loss: 0.689705, acc.: 57.03%] [G loss: 0.873929]\n",
      "epoch:23 step:22301 [D loss: 0.635615, acc.: 68.75%] [G loss: 0.875890]\n",
      "epoch:23 step:22302 [D loss: 0.641377, acc.: 62.50%] [G loss: 0.914815]\n",
      "epoch:23 step:22303 [D loss: 0.656522, acc.: 57.81%] [G loss: 0.912038]\n",
      "epoch:23 step:22304 [D loss: 0.652593, acc.: 60.94%] [G loss: 0.997048]\n",
      "epoch:23 step:22305 [D loss: 0.666160, acc.: 64.06%] [G loss: 0.918676]\n",
      "epoch:23 step:22306 [D loss: 0.677823, acc.: 64.84%] [G loss: 0.902604]\n",
      "epoch:23 step:22307 [D loss: 0.651758, acc.: 60.94%] [G loss: 0.819990]\n",
      "epoch:23 step:22308 [D loss: 0.636194, acc.: 64.06%] [G loss: 0.925969]\n",
      "epoch:23 step:22309 [D loss: 0.655611, acc.: 59.38%] [G loss: 0.885122]\n",
      "epoch:23 step:22310 [D loss: 0.665923, acc.: 61.72%] [G loss: 0.907313]\n",
      "epoch:23 step:22311 [D loss: 0.697265, acc.: 53.91%] [G loss: 0.907000]\n",
      "epoch:23 step:22312 [D loss: 0.675175, acc.: 52.34%] [G loss: 0.919316]\n",
      "epoch:23 step:22313 [D loss: 0.685527, acc.: 57.81%] [G loss: 0.928366]\n",
      "epoch:23 step:22314 [D loss: 0.655662, acc.: 63.28%] [G loss: 0.913076]\n",
      "epoch:23 step:22315 [D loss: 0.633366, acc.: 64.06%] [G loss: 0.883440]\n",
      "epoch:23 step:22316 [D loss: 0.659515, acc.: 64.06%] [G loss: 0.865384]\n",
      "epoch:23 step:22317 [D loss: 0.667972, acc.: 56.25%] [G loss: 0.902678]\n",
      "epoch:23 step:22318 [D loss: 0.674068, acc.: 55.47%] [G loss: 0.904612]\n",
      "epoch:23 step:22319 [D loss: 0.683815, acc.: 60.16%] [G loss: 0.894080]\n",
      "epoch:23 step:22320 [D loss: 0.624270, acc.: 69.53%] [G loss: 0.938772]\n",
      "epoch:23 step:22321 [D loss: 0.649000, acc.: 64.84%] [G loss: 0.918043]\n",
      "epoch:23 step:22322 [D loss: 0.686832, acc.: 60.94%] [G loss: 0.885927]\n",
      "epoch:23 step:22323 [D loss: 0.668797, acc.: 56.25%] [G loss: 0.940463]\n",
      "epoch:23 step:22324 [D loss: 0.682878, acc.: 53.12%] [G loss: 0.898633]\n",
      "epoch:23 step:22325 [D loss: 0.636918, acc.: 65.62%] [G loss: 0.902639]\n",
      "epoch:23 step:22326 [D loss: 0.643838, acc.: 64.84%] [G loss: 0.876972]\n",
      "epoch:23 step:22327 [D loss: 0.659816, acc.: 63.28%] [G loss: 0.867315]\n",
      "epoch:23 step:22328 [D loss: 0.662444, acc.: 62.50%] [G loss: 0.899152]\n",
      "epoch:23 step:22329 [D loss: 0.635266, acc.: 63.28%] [G loss: 0.957986]\n",
      "epoch:23 step:22330 [D loss: 0.676492, acc.: 57.03%] [G loss: 0.933182]\n",
      "epoch:23 step:22331 [D loss: 0.674960, acc.: 60.16%] [G loss: 0.872901]\n",
      "epoch:23 step:22332 [D loss: 0.678580, acc.: 58.59%] [G loss: 0.885664]\n",
      "epoch:23 step:22333 [D loss: 0.625274, acc.: 67.19%] [G loss: 0.875763]\n",
      "epoch:23 step:22334 [D loss: 0.659265, acc.: 58.59%] [G loss: 0.858362]\n",
      "epoch:23 step:22335 [D loss: 0.642856, acc.: 59.38%] [G loss: 0.812448]\n",
      "epoch:23 step:22336 [D loss: 0.678272, acc.: 56.25%] [G loss: 0.881992]\n",
      "epoch:23 step:22337 [D loss: 0.666800, acc.: 60.94%] [G loss: 0.920948]\n",
      "epoch:23 step:22338 [D loss: 0.655246, acc.: 58.59%] [G loss: 0.883802]\n",
      "epoch:23 step:22339 [D loss: 0.651323, acc.: 62.50%] [G loss: 0.908026]\n",
      "epoch:23 step:22340 [D loss: 0.663890, acc.: 59.38%] [G loss: 0.918320]\n",
      "epoch:23 step:22341 [D loss: 0.631822, acc.: 61.72%] [G loss: 0.906133]\n",
      "epoch:23 step:22342 [D loss: 0.645065, acc.: 64.84%] [G loss: 0.937959]\n",
      "epoch:23 step:22343 [D loss: 0.655143, acc.: 66.41%] [G loss: 0.892716]\n",
      "epoch:23 step:22344 [D loss: 0.639356, acc.: 66.41%] [G loss: 0.873092]\n",
      "epoch:23 step:22345 [D loss: 0.626346, acc.: 64.84%] [G loss: 0.904741]\n",
      "epoch:23 step:22346 [D loss: 0.638933, acc.: 64.06%] [G loss: 0.884732]\n",
      "epoch:23 step:22347 [D loss: 0.631793, acc.: 62.50%] [G loss: 0.884881]\n",
      "epoch:23 step:22348 [D loss: 0.640070, acc.: 62.50%] [G loss: 0.882660]\n",
      "epoch:23 step:22349 [D loss: 0.673300, acc.: 59.38%] [G loss: 0.853834]\n",
      "epoch:23 step:22350 [D loss: 0.655722, acc.: 60.16%] [G loss: 0.912482]\n",
      "epoch:23 step:22351 [D loss: 0.674915, acc.: 60.16%] [G loss: 0.907747]\n",
      "epoch:23 step:22352 [D loss: 0.659912, acc.: 57.81%] [G loss: 0.911858]\n",
      "epoch:23 step:22353 [D loss: 0.644554, acc.: 64.84%] [G loss: 0.894781]\n",
      "epoch:23 step:22354 [D loss: 0.668706, acc.: 58.59%] [G loss: 0.907761]\n",
      "epoch:23 step:22355 [D loss: 0.676592, acc.: 54.69%] [G loss: 0.826012]\n",
      "epoch:23 step:22356 [D loss: 0.646089, acc.: 59.38%] [G loss: 0.847644]\n",
      "epoch:23 step:22357 [D loss: 0.633811, acc.: 67.19%] [G loss: 0.890120]\n",
      "epoch:23 step:22358 [D loss: 0.653079, acc.: 60.94%] [G loss: 0.901819]\n",
      "epoch:23 step:22359 [D loss: 0.625595, acc.: 64.84%] [G loss: 0.933606]\n",
      "epoch:23 step:22360 [D loss: 0.657210, acc.: 53.12%] [G loss: 0.931879]\n",
      "epoch:23 step:22361 [D loss: 0.666319, acc.: 55.47%] [G loss: 0.952164]\n",
      "epoch:23 step:22362 [D loss: 0.650086, acc.: 59.38%] [G loss: 0.904409]\n",
      "epoch:23 step:22363 [D loss: 0.652967, acc.: 56.25%] [G loss: 0.883093]\n",
      "epoch:23 step:22364 [D loss: 0.657108, acc.: 60.16%] [G loss: 0.912364]\n",
      "epoch:23 step:22365 [D loss: 0.659832, acc.: 60.16%] [G loss: 0.901166]\n",
      "epoch:23 step:22366 [D loss: 0.653444, acc.: 58.59%] [G loss: 0.947770]\n",
      "epoch:23 step:22367 [D loss: 0.632502, acc.: 67.19%] [G loss: 0.888605]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22368 [D loss: 0.719560, acc.: 53.91%] [G loss: 0.884729]\n",
      "epoch:23 step:22369 [D loss: 0.672749, acc.: 55.47%] [G loss: 0.905998]\n",
      "epoch:23 step:22370 [D loss: 0.644510, acc.: 62.50%] [G loss: 0.834595]\n",
      "epoch:23 step:22371 [D loss: 0.666985, acc.: 57.03%] [G loss: 0.854085]\n",
      "epoch:23 step:22372 [D loss: 0.632773, acc.: 63.28%] [G loss: 0.899126]\n",
      "epoch:23 step:22373 [D loss: 0.606162, acc.: 65.62%] [G loss: 0.864485]\n",
      "epoch:23 step:22374 [D loss: 0.697416, acc.: 50.78%] [G loss: 0.852502]\n",
      "epoch:23 step:22375 [D loss: 0.643926, acc.: 61.72%] [G loss: 0.879179]\n",
      "epoch:23 step:22376 [D loss: 0.626624, acc.: 68.75%] [G loss: 0.873926]\n",
      "epoch:23 step:22377 [D loss: 0.623207, acc.: 64.84%] [G loss: 0.853703]\n",
      "epoch:23 step:22378 [D loss: 0.660319, acc.: 64.84%] [G loss: 0.846978]\n",
      "epoch:23 step:22379 [D loss: 0.659221, acc.: 56.25%] [G loss: 0.827248]\n",
      "epoch:23 step:22380 [D loss: 0.664355, acc.: 60.16%] [G loss: 0.815992]\n",
      "epoch:23 step:22381 [D loss: 0.663173, acc.: 57.03%] [G loss: 0.861850]\n",
      "epoch:23 step:22382 [D loss: 0.665226, acc.: 57.81%] [G loss: 0.884461]\n",
      "epoch:23 step:22383 [D loss: 0.646297, acc.: 58.59%] [G loss: 0.911621]\n",
      "epoch:23 step:22384 [D loss: 0.656312, acc.: 63.28%] [G loss: 0.938554]\n",
      "epoch:23 step:22385 [D loss: 0.696068, acc.: 55.47%] [G loss: 0.885542]\n",
      "epoch:23 step:22386 [D loss: 0.661885, acc.: 61.72%] [G loss: 0.857732]\n",
      "epoch:23 step:22387 [D loss: 0.668667, acc.: 55.47%] [G loss: 0.870744]\n",
      "epoch:23 step:22388 [D loss: 0.664884, acc.: 53.91%] [G loss: 0.903848]\n",
      "epoch:23 step:22389 [D loss: 0.651404, acc.: 64.84%] [G loss: 0.942883]\n",
      "epoch:23 step:22390 [D loss: 0.630279, acc.: 62.50%] [G loss: 0.998270]\n",
      "epoch:23 step:22391 [D loss: 0.664893, acc.: 58.59%] [G loss: 0.932847]\n",
      "epoch:23 step:22392 [D loss: 0.665285, acc.: 59.38%] [G loss: 0.912289]\n",
      "epoch:23 step:22393 [D loss: 0.709642, acc.: 51.56%] [G loss: 0.847399]\n",
      "epoch:23 step:22394 [D loss: 0.682246, acc.: 53.91%] [G loss: 0.854682]\n",
      "epoch:23 step:22395 [D loss: 0.656979, acc.: 60.94%] [G loss: 0.851025]\n",
      "epoch:23 step:22396 [D loss: 0.672391, acc.: 58.59%] [G loss: 0.880743]\n",
      "epoch:23 step:22397 [D loss: 0.680636, acc.: 57.03%] [G loss: 0.879339]\n",
      "epoch:23 step:22398 [D loss: 0.669464, acc.: 62.50%] [G loss: 0.874004]\n",
      "epoch:23 step:22399 [D loss: 0.640862, acc.: 63.28%] [G loss: 0.874743]\n",
      "epoch:23 step:22400 [D loss: 0.633566, acc.: 65.62%] [G loss: 0.933872]\n",
      "##############\n",
      "[2.87184789 2.56948954 2.14480211 4.05128091 1.52021743 7.3285619\n",
      " 2.93207797 3.23579731 4.2604511  8.14868929]\n",
      "##########\n",
      "epoch:23 step:22401 [D loss: 0.618568, acc.: 64.84%] [G loss: 0.909234]\n",
      "epoch:23 step:22402 [D loss: 0.659959, acc.: 59.38%] [G loss: 0.882669]\n",
      "epoch:23 step:22403 [D loss: 0.625418, acc.: 65.62%] [G loss: 0.909939]\n",
      "epoch:23 step:22404 [D loss: 0.631909, acc.: 65.62%] [G loss: 0.902800]\n",
      "epoch:23 step:22405 [D loss: 0.645518, acc.: 65.62%] [G loss: 0.874592]\n",
      "epoch:23 step:22406 [D loss: 0.653794, acc.: 59.38%] [G loss: 0.898430]\n",
      "epoch:23 step:22407 [D loss: 0.650816, acc.: 60.16%] [G loss: 0.886145]\n",
      "epoch:23 step:22408 [D loss: 0.684791, acc.: 56.25%] [G loss: 0.907330]\n",
      "epoch:23 step:22409 [D loss: 0.674337, acc.: 54.69%] [G loss: 0.822283]\n",
      "epoch:23 step:22410 [D loss: 0.655983, acc.: 59.38%] [G loss: 0.881132]\n",
      "epoch:23 step:22411 [D loss: 0.639112, acc.: 62.50%] [G loss: 0.845056]\n",
      "epoch:23 step:22412 [D loss: 0.657912, acc.: 59.38%] [G loss: 0.903052]\n",
      "epoch:23 step:22413 [D loss: 0.627865, acc.: 63.28%] [G loss: 0.884828]\n",
      "epoch:23 step:22414 [D loss: 0.598543, acc.: 74.22%] [G loss: 0.897508]\n",
      "epoch:23 step:22415 [D loss: 0.670680, acc.: 60.16%] [G loss: 0.878013]\n",
      "epoch:23 step:22416 [D loss: 0.654889, acc.: 59.38%] [G loss: 0.925749]\n",
      "epoch:23 step:22417 [D loss: 0.621703, acc.: 68.75%] [G loss: 0.946788]\n",
      "epoch:23 step:22418 [D loss: 0.683419, acc.: 56.25%] [G loss: 0.897275]\n",
      "epoch:23 step:22419 [D loss: 0.625857, acc.: 64.84%] [G loss: 0.910404]\n",
      "epoch:23 step:22420 [D loss: 0.646970, acc.: 58.59%] [G loss: 0.924649]\n",
      "epoch:23 step:22421 [D loss: 0.675130, acc.: 57.03%] [G loss: 0.861333]\n",
      "epoch:23 step:22422 [D loss: 0.615926, acc.: 64.84%] [G loss: 0.863280]\n",
      "epoch:23 step:22423 [D loss: 0.662361, acc.: 53.91%] [G loss: 0.881433]\n",
      "epoch:23 step:22424 [D loss: 0.628114, acc.: 66.41%] [G loss: 0.894100]\n",
      "epoch:23 step:22425 [D loss: 0.679242, acc.: 60.94%] [G loss: 0.898357]\n",
      "epoch:23 step:22426 [D loss: 0.626964, acc.: 66.41%] [G loss: 0.915684]\n",
      "epoch:23 step:22427 [D loss: 0.667535, acc.: 55.47%] [G loss: 0.932293]\n",
      "epoch:23 step:22428 [D loss: 0.623455, acc.: 63.28%] [G loss: 0.878737]\n",
      "epoch:23 step:22429 [D loss: 0.637663, acc.: 64.84%] [G loss: 0.916167]\n",
      "epoch:23 step:22430 [D loss: 0.654995, acc.: 60.94%] [G loss: 0.895348]\n",
      "epoch:23 step:22431 [D loss: 0.657769, acc.: 63.28%] [G loss: 0.888720]\n",
      "epoch:23 step:22432 [D loss: 0.692025, acc.: 50.78%] [G loss: 0.911226]\n",
      "epoch:23 step:22433 [D loss: 0.652692, acc.: 63.28%] [G loss: 0.889996]\n",
      "epoch:23 step:22434 [D loss: 0.642321, acc.: 61.72%] [G loss: 0.945735]\n",
      "epoch:23 step:22435 [D loss: 0.623930, acc.: 69.53%] [G loss: 0.879660]\n",
      "epoch:23 step:22436 [D loss: 0.650393, acc.: 62.50%] [G loss: 0.871072]\n",
      "epoch:23 step:22437 [D loss: 0.674291, acc.: 60.94%] [G loss: 0.895062]\n",
      "epoch:23 step:22438 [D loss: 0.638373, acc.: 59.38%] [G loss: 0.891717]\n",
      "epoch:23 step:22439 [D loss: 0.660148, acc.: 58.59%] [G loss: 0.841102]\n",
      "epoch:23 step:22440 [D loss: 0.673859, acc.: 54.69%] [G loss: 0.823840]\n",
      "epoch:23 step:22441 [D loss: 0.683874, acc.: 60.16%] [G loss: 0.852841]\n",
      "epoch:23 step:22442 [D loss: 0.686790, acc.: 56.25%] [G loss: 0.846637]\n",
      "epoch:23 step:22443 [D loss: 0.661341, acc.: 61.72%] [G loss: 0.819713]\n",
      "epoch:23 step:22444 [D loss: 0.661224, acc.: 59.38%] [G loss: 0.873589]\n",
      "epoch:23 step:22445 [D loss: 0.647168, acc.: 61.72%] [G loss: 0.856834]\n",
      "epoch:23 step:22446 [D loss: 0.670388, acc.: 58.59%] [G loss: 0.858299]\n",
      "epoch:23 step:22447 [D loss: 0.647016, acc.: 59.38%] [G loss: 0.866134]\n",
      "epoch:23 step:22448 [D loss: 0.640097, acc.: 60.94%] [G loss: 0.898326]\n",
      "epoch:23 step:22449 [D loss: 0.642649, acc.: 57.81%] [G loss: 0.896281]\n",
      "epoch:23 step:22450 [D loss: 0.671877, acc.: 52.34%] [G loss: 0.850727]\n",
      "epoch:23 step:22451 [D loss: 0.658473, acc.: 61.72%] [G loss: 0.848864]\n",
      "epoch:23 step:22452 [D loss: 0.662067, acc.: 56.25%] [G loss: 0.903628]\n",
      "epoch:23 step:22453 [D loss: 0.645224, acc.: 65.62%] [G loss: 0.843171]\n",
      "epoch:23 step:22454 [D loss: 0.677125, acc.: 60.16%] [G loss: 0.886321]\n",
      "epoch:23 step:22455 [D loss: 0.656148, acc.: 63.28%] [G loss: 0.847305]\n",
      "epoch:23 step:22456 [D loss: 0.662132, acc.: 62.50%] [G loss: 0.942563]\n",
      "epoch:23 step:22457 [D loss: 0.652181, acc.: 57.03%] [G loss: 0.874667]\n",
      "epoch:23 step:22458 [D loss: 0.714319, acc.: 47.66%] [G loss: 0.894819]\n",
      "epoch:23 step:22459 [D loss: 0.651448, acc.: 61.72%] [G loss: 0.892612]\n",
      "epoch:23 step:22460 [D loss: 0.692234, acc.: 57.03%] [G loss: 0.903828]\n",
      "epoch:23 step:22461 [D loss: 0.697220, acc.: 57.81%] [G loss: 0.904697]\n",
      "epoch:23 step:22462 [D loss: 0.655304, acc.: 61.72%] [G loss: 0.910167]\n",
      "epoch:23 step:22463 [D loss: 0.688766, acc.: 53.91%] [G loss: 0.923904]\n",
      "epoch:23 step:22464 [D loss: 0.697417, acc.: 56.25%] [G loss: 0.869889]\n",
      "epoch:23 step:22465 [D loss: 0.642099, acc.: 63.28%] [G loss: 0.896399]\n",
      "epoch:23 step:22466 [D loss: 0.674215, acc.: 56.25%] [G loss: 0.834733]\n",
      "epoch:23 step:22467 [D loss: 0.699244, acc.: 56.25%] [G loss: 0.861299]\n",
      "epoch:23 step:22468 [D loss: 0.663695, acc.: 60.16%] [G loss: 0.878195]\n",
      "epoch:23 step:22469 [D loss: 0.680294, acc.: 54.69%] [G loss: 0.867507]\n",
      "epoch:23 step:22470 [D loss: 0.641641, acc.: 60.94%] [G loss: 0.900591]\n",
      "epoch:23 step:22471 [D loss: 0.655471, acc.: 62.50%] [G loss: 0.857465]\n",
      "epoch:23 step:22472 [D loss: 0.691859, acc.: 57.03%] [G loss: 0.919613]\n",
      "epoch:23 step:22473 [D loss: 0.621066, acc.: 64.84%] [G loss: 0.833405]\n",
      "epoch:23 step:22474 [D loss: 0.664283, acc.: 55.47%] [G loss: 0.870981]\n",
      "epoch:23 step:22475 [D loss: 0.664583, acc.: 53.91%] [G loss: 0.828086]\n",
      "epoch:23 step:22476 [D loss: 0.665091, acc.: 53.12%] [G loss: 0.873121]\n",
      "epoch:23 step:22477 [D loss: 0.643533, acc.: 60.94%] [G loss: 0.878264]\n",
      "epoch:23 step:22478 [D loss: 0.654528, acc.: 65.62%] [G loss: 0.814079]\n",
      "epoch:23 step:22479 [D loss: 0.651449, acc.: 63.28%] [G loss: 0.893680]\n",
      "epoch:23 step:22480 [D loss: 0.684080, acc.: 58.59%] [G loss: 0.892262]\n",
      "epoch:23 step:22481 [D loss: 0.686021, acc.: 55.47%] [G loss: 0.847070]\n",
      "epoch:23 step:22482 [D loss: 0.711851, acc.: 51.56%] [G loss: 0.895245]\n",
      "epoch:23 step:22483 [D loss: 0.638696, acc.: 65.62%] [G loss: 0.904673]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:23 step:22484 [D loss: 0.698816, acc.: 50.00%] [G loss: 0.923020]\n",
      "epoch:23 step:22485 [D loss: 0.646633, acc.: 58.59%] [G loss: 0.882368]\n",
      "epoch:23 step:22486 [D loss: 0.627691, acc.: 64.84%] [G loss: 0.880182]\n",
      "epoch:23 step:22487 [D loss: 0.635602, acc.: 64.06%] [G loss: 0.911613]\n",
      "epoch:23 step:22488 [D loss: 0.656914, acc.: 62.50%] [G loss: 0.895535]\n",
      "epoch:24 step:22489 [D loss: 0.658765, acc.: 61.72%] [G loss: 0.921888]\n",
      "epoch:24 step:22490 [D loss: 0.702068, acc.: 48.44%] [G loss: 0.997032]\n",
      "epoch:24 step:22491 [D loss: 0.639889, acc.: 63.28%] [G loss: 0.863332]\n",
      "epoch:24 step:22492 [D loss: 0.649838, acc.: 67.97%] [G loss: 0.882927]\n",
      "epoch:24 step:22493 [D loss: 0.686307, acc.: 51.56%] [G loss: 0.866173]\n",
      "epoch:24 step:22494 [D loss: 0.633303, acc.: 66.41%] [G loss: 0.884131]\n",
      "epoch:24 step:22495 [D loss: 0.676897, acc.: 59.38%] [G loss: 0.878979]\n",
      "epoch:24 step:22496 [D loss: 0.676046, acc.: 55.47%] [G loss: 0.869211]\n",
      "epoch:24 step:22497 [D loss: 0.703850, acc.: 50.78%] [G loss: 0.868223]\n",
      "epoch:24 step:22498 [D loss: 0.682480, acc.: 60.16%] [G loss: 0.836735]\n",
      "epoch:24 step:22499 [D loss: 0.647440, acc.: 58.59%] [G loss: 0.920400]\n",
      "epoch:24 step:22500 [D loss: 0.630204, acc.: 67.19%] [G loss: 0.915495]\n",
      "epoch:24 step:22501 [D loss: 0.655890, acc.: 62.50%] [G loss: 0.905761]\n",
      "epoch:24 step:22502 [D loss: 0.715780, acc.: 55.47%] [G loss: 0.896199]\n",
      "epoch:24 step:22503 [D loss: 0.656119, acc.: 55.47%] [G loss: 0.908730]\n",
      "epoch:24 step:22504 [D loss: 0.629212, acc.: 67.19%] [G loss: 0.875060]\n",
      "epoch:24 step:22505 [D loss: 0.625887, acc.: 66.41%] [G loss: 0.897267]\n",
      "epoch:24 step:22506 [D loss: 0.659737, acc.: 62.50%] [G loss: 0.859544]\n",
      "epoch:24 step:22507 [D loss: 0.660281, acc.: 64.06%] [G loss: 0.865111]\n",
      "epoch:24 step:22508 [D loss: 0.666634, acc.: 60.16%] [G loss: 0.880666]\n",
      "epoch:24 step:22509 [D loss: 0.655811, acc.: 60.94%] [G loss: 0.901721]\n",
      "epoch:24 step:22510 [D loss: 0.668793, acc.: 58.59%] [G loss: 0.930503]\n",
      "epoch:24 step:22511 [D loss: 0.667408, acc.: 60.16%] [G loss: 0.867635]\n",
      "epoch:24 step:22512 [D loss: 0.658339, acc.: 61.72%] [G loss: 0.929129]\n",
      "epoch:24 step:22513 [D loss: 0.625512, acc.: 60.94%] [G loss: 0.911938]\n",
      "epoch:24 step:22514 [D loss: 0.691883, acc.: 55.47%] [G loss: 0.943079]\n",
      "epoch:24 step:22515 [D loss: 0.660709, acc.: 59.38%] [G loss: 0.908530]\n",
      "epoch:24 step:22516 [D loss: 0.673041, acc.: 57.03%] [G loss: 0.911530]\n",
      "epoch:24 step:22517 [D loss: 0.673630, acc.: 58.59%] [G loss: 0.880001]\n",
      "epoch:24 step:22518 [D loss: 0.677173, acc.: 57.81%] [G loss: 0.871210]\n",
      "epoch:24 step:22519 [D loss: 0.664347, acc.: 62.50%] [G loss: 0.866879]\n",
      "epoch:24 step:22520 [D loss: 0.667657, acc.: 57.81%] [G loss: 0.892327]\n",
      "epoch:24 step:22521 [D loss: 0.655404, acc.: 57.81%] [G loss: 0.891246]\n",
      "epoch:24 step:22522 [D loss: 0.687774, acc.: 57.03%] [G loss: 0.894877]\n",
      "epoch:24 step:22523 [D loss: 0.669317, acc.: 61.72%] [G loss: 0.838207]\n",
      "epoch:24 step:22524 [D loss: 0.631385, acc.: 69.53%] [G loss: 0.879680]\n",
      "epoch:24 step:22525 [D loss: 0.676256, acc.: 55.47%] [G loss: 0.853908]\n",
      "epoch:24 step:22526 [D loss: 0.701298, acc.: 56.25%] [G loss: 0.862905]\n",
      "epoch:24 step:22527 [D loss: 0.667217, acc.: 53.91%] [G loss: 0.871366]\n",
      "epoch:24 step:22528 [D loss: 0.682997, acc.: 58.59%] [G loss: 0.929516]\n",
      "epoch:24 step:22529 [D loss: 0.637122, acc.: 67.19%] [G loss: 0.829027]\n",
      "epoch:24 step:22530 [D loss: 0.667116, acc.: 53.91%] [G loss: 0.833830]\n",
      "epoch:24 step:22531 [D loss: 0.659390, acc.: 61.72%] [G loss: 0.821655]\n",
      "epoch:24 step:22532 [D loss: 0.658619, acc.: 57.03%] [G loss: 0.885488]\n",
      "epoch:24 step:22533 [D loss: 0.655986, acc.: 59.38%] [G loss: 0.869814]\n",
      "epoch:24 step:22534 [D loss: 0.674664, acc.: 57.03%] [G loss: 0.863398]\n",
      "epoch:24 step:22535 [D loss: 0.701165, acc.: 54.69%] [G loss: 0.874322]\n",
      "epoch:24 step:22536 [D loss: 0.626739, acc.: 67.97%] [G loss: 0.880228]\n",
      "epoch:24 step:22537 [D loss: 0.651247, acc.: 67.19%] [G loss: 0.829516]\n",
      "epoch:24 step:22538 [D loss: 0.652046, acc.: 61.72%] [G loss: 0.845016]\n",
      "epoch:24 step:22539 [D loss: 0.647039, acc.: 60.94%] [G loss: 0.851139]\n",
      "epoch:24 step:22540 [D loss: 0.633721, acc.: 64.84%] [G loss: 0.830543]\n",
      "epoch:24 step:22541 [D loss: 0.656465, acc.: 57.03%] [G loss: 0.847862]\n",
      "epoch:24 step:22542 [D loss: 0.643204, acc.: 65.62%] [G loss: 0.850419]\n",
      "epoch:24 step:22543 [D loss: 0.679676, acc.: 63.28%] [G loss: 0.897084]\n",
      "epoch:24 step:22544 [D loss: 0.669191, acc.: 57.81%] [G loss: 0.906315]\n",
      "epoch:24 step:22545 [D loss: 0.672588, acc.: 62.50%] [G loss: 0.833324]\n",
      "epoch:24 step:22546 [D loss: 0.673933, acc.: 57.81%] [G loss: 0.884169]\n",
      "epoch:24 step:22547 [D loss: 0.645560, acc.: 64.84%] [G loss: 0.869156]\n",
      "epoch:24 step:22548 [D loss: 0.617823, acc.: 68.75%] [G loss: 0.878309]\n",
      "epoch:24 step:22549 [D loss: 0.662154, acc.: 60.16%] [G loss: 0.894464]\n",
      "epoch:24 step:22550 [D loss: 0.649764, acc.: 60.16%] [G loss: 0.886585]\n",
      "epoch:24 step:22551 [D loss: 0.626100, acc.: 64.84%] [G loss: 0.911704]\n",
      "epoch:24 step:22552 [D loss: 0.667268, acc.: 60.94%] [G loss: 0.896467]\n",
      "epoch:24 step:22553 [D loss: 0.648261, acc.: 62.50%] [G loss: 0.911462]\n",
      "epoch:24 step:22554 [D loss: 0.659477, acc.: 57.03%] [G loss: 0.891344]\n",
      "epoch:24 step:22555 [D loss: 0.667230, acc.: 59.38%] [G loss: 0.915739]\n",
      "epoch:24 step:22556 [D loss: 0.660726, acc.: 59.38%] [G loss: 0.959614]\n",
      "epoch:24 step:22557 [D loss: 0.630666, acc.: 66.41%] [G loss: 0.948782]\n",
      "epoch:24 step:22558 [D loss: 0.679705, acc.: 60.16%] [G loss: 0.927048]\n",
      "epoch:24 step:22559 [D loss: 0.624328, acc.: 65.62%] [G loss: 0.931498]\n",
      "epoch:24 step:22560 [D loss: 0.670588, acc.: 57.03%] [G loss: 0.873019]\n",
      "epoch:24 step:22561 [D loss: 0.640139, acc.: 65.62%] [G loss: 0.898823]\n",
      "epoch:24 step:22562 [D loss: 0.650852, acc.: 57.03%] [G loss: 0.866324]\n",
      "epoch:24 step:22563 [D loss: 0.636639, acc.: 63.28%] [G loss: 0.882425]\n",
      "epoch:24 step:22564 [D loss: 0.640487, acc.: 67.19%] [G loss: 0.860168]\n",
      "epoch:24 step:22565 [D loss: 0.698963, acc.: 59.38%] [G loss: 0.926301]\n",
      "epoch:24 step:22566 [D loss: 0.680575, acc.: 57.03%] [G loss: 0.880623]\n",
      "epoch:24 step:22567 [D loss: 0.643566, acc.: 62.50%] [G loss: 0.922401]\n",
      "epoch:24 step:22568 [D loss: 0.682258, acc.: 57.03%] [G loss: 0.872757]\n",
      "epoch:24 step:22569 [D loss: 0.676747, acc.: 57.03%] [G loss: 0.943861]\n",
      "epoch:24 step:22570 [D loss: 0.651281, acc.: 60.16%] [G loss: 0.883983]\n",
      "epoch:24 step:22571 [D loss: 0.668430, acc.: 61.72%] [G loss: 0.881682]\n",
      "epoch:24 step:22572 [D loss: 0.657202, acc.: 57.03%] [G loss: 0.890648]\n",
      "epoch:24 step:22573 [D loss: 0.658364, acc.: 57.81%] [G loss: 0.929929]\n",
      "epoch:24 step:22574 [D loss: 0.690974, acc.: 56.25%] [G loss: 0.893471]\n",
      "epoch:24 step:22575 [D loss: 0.643023, acc.: 64.06%] [G loss: 0.904646]\n",
      "epoch:24 step:22576 [D loss: 0.660083, acc.: 59.38%] [G loss: 0.883702]\n",
      "epoch:24 step:22577 [D loss: 0.622514, acc.: 70.31%] [G loss: 0.860649]\n",
      "epoch:24 step:22578 [D loss: 0.657867, acc.: 65.62%] [G loss: 0.929455]\n",
      "epoch:24 step:22579 [D loss: 0.670811, acc.: 57.03%] [G loss: 0.875602]\n",
      "epoch:24 step:22580 [D loss: 0.659820, acc.: 62.50%] [G loss: 0.854077]\n",
      "epoch:24 step:22581 [D loss: 0.673233, acc.: 56.25%] [G loss: 0.873389]\n",
      "epoch:24 step:22582 [D loss: 0.677343, acc.: 54.69%] [G loss: 0.870238]\n",
      "epoch:24 step:22583 [D loss: 0.694657, acc.: 51.56%] [G loss: 0.867653]\n",
      "epoch:24 step:22584 [D loss: 0.667029, acc.: 55.47%] [G loss: 0.908834]\n",
      "epoch:24 step:22585 [D loss: 0.640357, acc.: 60.16%] [G loss: 0.852254]\n",
      "epoch:24 step:22586 [D loss: 0.668740, acc.: 60.94%] [G loss: 0.890298]\n",
      "epoch:24 step:22587 [D loss: 0.663642, acc.: 60.16%] [G loss: 0.923279]\n",
      "epoch:24 step:22588 [D loss: 0.666255, acc.: 58.59%] [G loss: 0.858882]\n",
      "epoch:24 step:22589 [D loss: 0.633544, acc.: 61.72%] [G loss: 0.868972]\n",
      "epoch:24 step:22590 [D loss: 0.715977, acc.: 50.78%] [G loss: 0.842214]\n",
      "epoch:24 step:22591 [D loss: 0.635802, acc.: 67.19%] [G loss: 0.825971]\n",
      "epoch:24 step:22592 [D loss: 0.674696, acc.: 61.72%] [G loss: 0.824064]\n",
      "epoch:24 step:22593 [D loss: 0.653323, acc.: 60.16%] [G loss: 0.897334]\n",
      "epoch:24 step:22594 [D loss: 0.659451, acc.: 59.38%] [G loss: 0.888054]\n",
      "epoch:24 step:22595 [D loss: 0.642660, acc.: 59.38%] [G loss: 0.827166]\n",
      "epoch:24 step:22596 [D loss: 0.659581, acc.: 58.59%] [G loss: 0.833101]\n",
      "epoch:24 step:22597 [D loss: 0.646001, acc.: 61.72%] [G loss: 0.850797]\n",
      "epoch:24 step:22598 [D loss: 0.673244, acc.: 55.47%] [G loss: 0.913993]\n",
      "epoch:24 step:22599 [D loss: 0.682785, acc.: 54.69%] [G loss: 0.855593]\n",
      "epoch:24 step:22600 [D loss: 0.692884, acc.: 52.34%] [G loss: 0.860647]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[3.17744652 2.24396532 2.15158179 3.92946533 0.90486218 8.05787701\n",
      " 3.02423569 3.52580515 4.30780384 6.36489894]\n",
      "##########\n",
      "epoch:24 step:22601 [D loss: 0.633730, acc.: 62.50%] [G loss: 0.852110]\n",
      "epoch:24 step:22602 [D loss: 0.654280, acc.: 60.94%] [G loss: 0.877376]\n",
      "epoch:24 step:22603 [D loss: 0.646319, acc.: 67.97%] [G loss: 0.904148]\n",
      "epoch:24 step:22604 [D loss: 0.616835, acc.: 66.41%] [G loss: 0.872018]\n",
      "epoch:24 step:22605 [D loss: 0.654339, acc.: 58.59%] [G loss: 0.876899]\n",
      "epoch:24 step:22606 [D loss: 0.659239, acc.: 58.59%] [G loss: 0.830052]\n",
      "epoch:24 step:22607 [D loss: 0.656328, acc.: 64.84%] [G loss: 0.864611]\n",
      "epoch:24 step:22608 [D loss: 0.677978, acc.: 58.59%] [G loss: 0.855128]\n",
      "epoch:24 step:22609 [D loss: 0.618089, acc.: 68.75%] [G loss: 0.892681]\n",
      "epoch:24 step:22610 [D loss: 0.687160, acc.: 54.69%] [G loss: 0.935616]\n",
      "epoch:24 step:22611 [D loss: 0.681521, acc.: 55.47%] [G loss: 0.894185]\n",
      "epoch:24 step:22612 [D loss: 0.649049, acc.: 58.59%] [G loss: 0.929931]\n",
      "epoch:24 step:22613 [D loss: 0.660997, acc.: 57.81%] [G loss: 0.886882]\n",
      "epoch:24 step:22614 [D loss: 0.668996, acc.: 56.25%] [G loss: 0.855156]\n",
      "epoch:24 step:22615 [D loss: 0.638143, acc.: 64.84%] [G loss: 0.872963]\n",
      "epoch:24 step:22616 [D loss: 0.642224, acc.: 62.50%] [G loss: 0.849836]\n",
      "epoch:24 step:22617 [D loss: 0.657261, acc.: 61.72%] [G loss: 0.909919]\n",
      "epoch:24 step:22618 [D loss: 0.642312, acc.: 61.72%] [G loss: 0.830047]\n",
      "epoch:24 step:22619 [D loss: 0.663495, acc.: 57.03%] [G loss: 0.858804]\n",
      "epoch:24 step:22620 [D loss: 0.657890, acc.: 58.59%] [G loss: 0.854818]\n",
      "epoch:24 step:22621 [D loss: 0.694599, acc.: 55.47%] [G loss: 0.864047]\n",
      "epoch:24 step:22622 [D loss: 0.691006, acc.: 52.34%] [G loss: 0.870926]\n",
      "epoch:24 step:22623 [D loss: 0.660371, acc.: 57.03%] [G loss: 0.840813]\n",
      "epoch:24 step:22624 [D loss: 0.677618, acc.: 56.25%] [G loss: 0.850433]\n",
      "epoch:24 step:22625 [D loss: 0.673400, acc.: 54.69%] [G loss: 0.867225]\n",
      "epoch:24 step:22626 [D loss: 0.649555, acc.: 59.38%] [G loss: 0.873158]\n",
      "epoch:24 step:22627 [D loss: 0.680509, acc.: 63.28%] [G loss: 0.890906]\n",
      "epoch:24 step:22628 [D loss: 0.667091, acc.: 62.50%] [G loss: 0.882499]\n",
      "epoch:24 step:22629 [D loss: 0.682593, acc.: 55.47%] [G loss: 0.857308]\n",
      "epoch:24 step:22630 [D loss: 0.648457, acc.: 62.50%] [G loss: 0.838174]\n",
      "epoch:24 step:22631 [D loss: 0.640899, acc.: 60.94%] [G loss: 0.874758]\n",
      "epoch:24 step:22632 [D loss: 0.664226, acc.: 60.94%] [G loss: 0.888620]\n",
      "epoch:24 step:22633 [D loss: 0.675015, acc.: 56.25%] [G loss: 0.904052]\n",
      "epoch:24 step:22634 [D loss: 0.634312, acc.: 60.16%] [G loss: 0.911597]\n",
      "epoch:24 step:22635 [D loss: 0.665758, acc.: 51.56%] [G loss: 0.887502]\n",
      "epoch:24 step:22636 [D loss: 0.650759, acc.: 60.94%] [G loss: 0.893989]\n",
      "epoch:24 step:22637 [D loss: 0.657959, acc.: 60.16%] [G loss: 0.904153]\n",
      "epoch:24 step:22638 [D loss: 0.649072, acc.: 59.38%] [G loss: 0.939746]\n",
      "epoch:24 step:22639 [D loss: 0.660072, acc.: 64.06%] [G loss: 0.902057]\n",
      "epoch:24 step:22640 [D loss: 0.626840, acc.: 63.28%] [G loss: 0.869210]\n",
      "epoch:24 step:22641 [D loss: 0.647270, acc.: 59.38%] [G loss: 0.883940]\n",
      "epoch:24 step:22642 [D loss: 0.631007, acc.: 68.75%] [G loss: 0.888368]\n",
      "epoch:24 step:22643 [D loss: 0.624570, acc.: 67.19%] [G loss: 0.923666]\n",
      "epoch:24 step:22644 [D loss: 0.645303, acc.: 56.25%] [G loss: 0.813382]\n",
      "epoch:24 step:22645 [D loss: 0.678170, acc.: 56.25%] [G loss: 0.842725]\n",
      "epoch:24 step:22646 [D loss: 0.656014, acc.: 59.38%] [G loss: 0.871507]\n",
      "epoch:24 step:22647 [D loss: 0.603728, acc.: 73.44%] [G loss: 0.928152]\n",
      "epoch:24 step:22648 [D loss: 0.654055, acc.: 58.59%] [G loss: 0.831926]\n",
      "epoch:24 step:22649 [D loss: 0.651105, acc.: 58.59%] [G loss: 0.891857]\n",
      "epoch:24 step:22650 [D loss: 0.628593, acc.: 63.28%] [G loss: 0.942286]\n",
      "epoch:24 step:22651 [D loss: 0.682348, acc.: 54.69%] [G loss: 0.867330]\n",
      "epoch:24 step:22652 [D loss: 0.665941, acc.: 58.59%] [G loss: 0.866064]\n",
      "epoch:24 step:22653 [D loss: 0.649116, acc.: 62.50%] [G loss: 0.827114]\n",
      "epoch:24 step:22654 [D loss: 0.655567, acc.: 60.94%] [G loss: 0.888569]\n",
      "epoch:24 step:22655 [D loss: 0.651170, acc.: 61.72%] [G loss: 0.884148]\n",
      "epoch:24 step:22656 [D loss: 0.622020, acc.: 60.16%] [G loss: 0.972434]\n",
      "epoch:24 step:22657 [D loss: 0.663500, acc.: 62.50%] [G loss: 0.914484]\n",
      "epoch:24 step:22658 [D loss: 0.649186, acc.: 62.50%] [G loss: 0.910741]\n",
      "epoch:24 step:22659 [D loss: 0.681311, acc.: 56.25%] [G loss: 0.919487]\n",
      "epoch:24 step:22660 [D loss: 0.643820, acc.: 65.62%] [G loss: 0.905653]\n",
      "epoch:24 step:22661 [D loss: 0.666263, acc.: 55.47%] [G loss: 0.878678]\n",
      "epoch:24 step:22662 [D loss: 0.641800, acc.: 66.41%] [G loss: 0.871720]\n",
      "epoch:24 step:22663 [D loss: 0.668658, acc.: 59.38%] [G loss: 0.877949]\n",
      "epoch:24 step:22664 [D loss: 0.587161, acc.: 71.88%] [G loss: 0.884668]\n",
      "epoch:24 step:22665 [D loss: 0.637073, acc.: 64.06%] [G loss: 0.880834]\n",
      "epoch:24 step:22666 [D loss: 0.690934, acc.: 53.12%] [G loss: 0.883660]\n",
      "epoch:24 step:22667 [D loss: 0.649044, acc.: 57.81%] [G loss: 0.857221]\n",
      "epoch:24 step:22668 [D loss: 0.611533, acc.: 67.97%] [G loss: 0.884081]\n",
      "epoch:24 step:22669 [D loss: 0.647493, acc.: 57.81%] [G loss: 0.836336]\n",
      "epoch:24 step:22670 [D loss: 0.626873, acc.: 66.41%] [G loss: 0.828447]\n",
      "epoch:24 step:22671 [D loss: 0.682314, acc.: 59.38%] [G loss: 0.904232]\n",
      "epoch:24 step:22672 [D loss: 0.637637, acc.: 64.84%] [G loss: 0.909665]\n",
      "epoch:24 step:22673 [D loss: 0.661879, acc.: 60.94%] [G loss: 0.901061]\n",
      "epoch:24 step:22674 [D loss: 0.653682, acc.: 61.72%] [G loss: 0.937681]\n",
      "epoch:24 step:22675 [D loss: 0.636382, acc.: 66.41%] [G loss: 0.948019]\n",
      "epoch:24 step:22676 [D loss: 0.682484, acc.: 52.34%] [G loss: 0.880715]\n",
      "epoch:24 step:22677 [D loss: 0.669472, acc.: 60.16%] [G loss: 0.881719]\n",
      "epoch:24 step:22678 [D loss: 0.651307, acc.: 64.06%] [G loss: 0.910941]\n",
      "epoch:24 step:22679 [D loss: 0.620708, acc.: 67.19%] [G loss: 0.866668]\n",
      "epoch:24 step:22680 [D loss: 0.656009, acc.: 58.59%] [G loss: 0.881461]\n",
      "epoch:24 step:22681 [D loss: 0.638841, acc.: 65.62%] [G loss: 0.929897]\n",
      "epoch:24 step:22682 [D loss: 0.672145, acc.: 57.81%] [G loss: 0.843313]\n",
      "epoch:24 step:22683 [D loss: 0.650431, acc.: 58.59%] [G loss: 0.883082]\n",
      "epoch:24 step:22684 [D loss: 0.646991, acc.: 62.50%] [G loss: 0.915024]\n",
      "epoch:24 step:22685 [D loss: 0.642376, acc.: 58.59%] [G loss: 0.895156]\n",
      "epoch:24 step:22686 [D loss: 0.650348, acc.: 61.72%] [G loss: 0.893853]\n",
      "epoch:24 step:22687 [D loss: 0.661338, acc.: 57.81%] [G loss: 0.947067]\n",
      "epoch:24 step:22688 [D loss: 0.650802, acc.: 64.84%] [G loss: 0.919088]\n",
      "epoch:24 step:22689 [D loss: 0.640944, acc.: 62.50%] [G loss: 0.883245]\n",
      "epoch:24 step:22690 [D loss: 0.635523, acc.: 64.06%] [G loss: 0.853477]\n",
      "epoch:24 step:22691 [D loss: 0.647769, acc.: 56.25%] [G loss: 0.889358]\n",
      "epoch:24 step:22692 [D loss: 0.645172, acc.: 64.06%] [G loss: 0.852655]\n",
      "epoch:24 step:22693 [D loss: 0.635637, acc.: 61.72%] [G loss: 0.835129]\n",
      "epoch:24 step:22694 [D loss: 0.679885, acc.: 60.16%] [G loss: 0.835509]\n",
      "epoch:24 step:22695 [D loss: 0.623912, acc.: 65.62%] [G loss: 0.796015]\n",
      "epoch:24 step:22696 [D loss: 0.663339, acc.: 56.25%] [G loss: 0.861514]\n",
      "epoch:24 step:22697 [D loss: 0.672222, acc.: 52.34%] [G loss: 0.875701]\n",
      "epoch:24 step:22698 [D loss: 0.646635, acc.: 65.62%] [G loss: 0.942655]\n",
      "epoch:24 step:22699 [D loss: 0.622769, acc.: 64.06%] [G loss: 0.907560]\n",
      "epoch:24 step:22700 [D loss: 0.656197, acc.: 57.03%] [G loss: 0.894178]\n",
      "epoch:24 step:22701 [D loss: 0.689213, acc.: 53.91%] [G loss: 0.892109]\n",
      "epoch:24 step:22702 [D loss: 0.667962, acc.: 60.16%] [G loss: 0.889059]\n",
      "epoch:24 step:22703 [D loss: 0.642842, acc.: 61.72%] [G loss: 0.882938]\n",
      "epoch:24 step:22704 [D loss: 0.677409, acc.: 53.12%] [G loss: 0.873077]\n",
      "epoch:24 step:22705 [D loss: 0.647569, acc.: 64.06%] [G loss: 0.849464]\n",
      "epoch:24 step:22706 [D loss: 0.687427, acc.: 53.12%] [G loss: 0.882270]\n",
      "epoch:24 step:22707 [D loss: 0.693564, acc.: 57.03%] [G loss: 0.864770]\n",
      "epoch:24 step:22708 [D loss: 0.678885, acc.: 57.03%] [G loss: 0.878870]\n",
      "epoch:24 step:22709 [D loss: 0.640661, acc.: 62.50%] [G loss: 0.877115]\n",
      "epoch:24 step:22710 [D loss: 0.695896, acc.: 46.09%] [G loss: 0.844895]\n",
      "epoch:24 step:22711 [D loss: 0.684196, acc.: 52.34%] [G loss: 0.895646]\n",
      "epoch:24 step:22712 [D loss: 0.679533, acc.: 55.47%] [G loss: 0.860748]\n",
      "epoch:24 step:22713 [D loss: 0.689036, acc.: 54.69%] [G loss: 0.869822]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22714 [D loss: 0.682487, acc.: 50.78%] [G loss: 0.895383]\n",
      "epoch:24 step:22715 [D loss: 0.660404, acc.: 60.16%] [G loss: 0.861882]\n",
      "epoch:24 step:22716 [D loss: 0.663815, acc.: 60.16%] [G loss: 0.887659]\n",
      "epoch:24 step:22717 [D loss: 0.688495, acc.: 50.78%] [G loss: 0.930805]\n",
      "epoch:24 step:22718 [D loss: 0.671458, acc.: 58.59%] [G loss: 0.882660]\n",
      "epoch:24 step:22719 [D loss: 0.692603, acc.: 57.03%] [G loss: 0.893529]\n",
      "epoch:24 step:22720 [D loss: 0.634355, acc.: 63.28%] [G loss: 0.849072]\n",
      "epoch:24 step:22721 [D loss: 0.651885, acc.: 62.50%] [G loss: 0.899665]\n",
      "epoch:24 step:22722 [D loss: 0.666786, acc.: 57.03%] [G loss: 0.880960]\n",
      "epoch:24 step:22723 [D loss: 0.680148, acc.: 57.03%] [G loss: 0.910016]\n",
      "epoch:24 step:22724 [D loss: 0.665088, acc.: 54.69%] [G loss: 0.886234]\n",
      "epoch:24 step:22725 [D loss: 0.700385, acc.: 54.69%] [G loss: 0.837257]\n",
      "epoch:24 step:22726 [D loss: 0.675980, acc.: 58.59%] [G loss: 0.831441]\n",
      "epoch:24 step:22727 [D loss: 0.688056, acc.: 56.25%] [G loss: 0.835112]\n",
      "epoch:24 step:22728 [D loss: 0.650710, acc.: 60.94%] [G loss: 0.817221]\n",
      "epoch:24 step:22729 [D loss: 0.632791, acc.: 60.16%] [G loss: 0.866730]\n",
      "epoch:24 step:22730 [D loss: 0.668783, acc.: 57.81%] [G loss: 0.853024]\n",
      "epoch:24 step:22731 [D loss: 0.664634, acc.: 59.38%] [G loss: 0.879962]\n",
      "epoch:24 step:22732 [D loss: 0.702264, acc.: 51.56%] [G loss: 0.862607]\n",
      "epoch:24 step:22733 [D loss: 0.648837, acc.: 59.38%] [G loss: 0.889839]\n",
      "epoch:24 step:22734 [D loss: 0.678051, acc.: 57.03%] [G loss: 0.878253]\n",
      "epoch:24 step:22735 [D loss: 0.675269, acc.: 58.59%] [G loss: 0.885199]\n",
      "epoch:24 step:22736 [D loss: 0.614506, acc.: 60.94%] [G loss: 0.902676]\n",
      "epoch:24 step:22737 [D loss: 0.670891, acc.: 58.59%] [G loss: 0.849847]\n",
      "epoch:24 step:22738 [D loss: 0.681007, acc.: 59.38%] [G loss: 0.826253]\n",
      "epoch:24 step:22739 [D loss: 0.680955, acc.: 54.69%] [G loss: 0.823989]\n",
      "epoch:24 step:22740 [D loss: 0.647557, acc.: 58.59%] [G loss: 0.870518]\n",
      "epoch:24 step:22741 [D loss: 0.667773, acc.: 55.47%] [G loss: 0.870786]\n",
      "epoch:24 step:22742 [D loss: 0.706687, acc.: 52.34%] [G loss: 0.861677]\n",
      "epoch:24 step:22743 [D loss: 0.670872, acc.: 63.28%] [G loss: 0.848936]\n",
      "epoch:24 step:22744 [D loss: 0.667559, acc.: 50.78%] [G loss: 0.874777]\n",
      "epoch:24 step:22745 [D loss: 0.673803, acc.: 54.69%] [G loss: 0.865975]\n",
      "epoch:24 step:22746 [D loss: 0.660017, acc.: 60.94%] [G loss: 0.896383]\n",
      "epoch:24 step:22747 [D loss: 0.708337, acc.: 57.03%] [G loss: 0.915904]\n",
      "epoch:24 step:22748 [D loss: 0.635034, acc.: 62.50%] [G loss: 0.898305]\n",
      "epoch:24 step:22749 [D loss: 0.692597, acc.: 57.81%] [G loss: 0.897050]\n",
      "epoch:24 step:22750 [D loss: 0.672323, acc.: 58.59%] [G loss: 0.875084]\n",
      "epoch:24 step:22751 [D loss: 0.666076, acc.: 57.81%] [G loss: 0.917139]\n",
      "epoch:24 step:22752 [D loss: 0.628484, acc.: 63.28%] [G loss: 0.934149]\n",
      "epoch:24 step:22753 [D loss: 0.641456, acc.: 60.16%] [G loss: 0.885063]\n",
      "epoch:24 step:22754 [D loss: 0.636305, acc.: 60.94%] [G loss: 0.908416]\n",
      "epoch:24 step:22755 [D loss: 0.623757, acc.: 63.28%] [G loss: 0.888800]\n",
      "epoch:24 step:22756 [D loss: 0.662486, acc.: 57.81%] [G loss: 0.889487]\n",
      "epoch:24 step:22757 [D loss: 0.586730, acc.: 72.66%] [G loss: 0.906579]\n",
      "epoch:24 step:22758 [D loss: 0.666492, acc.: 58.59%] [G loss: 0.906754]\n",
      "epoch:24 step:22759 [D loss: 0.652606, acc.: 60.94%] [G loss: 0.910146]\n",
      "epoch:24 step:22760 [D loss: 0.676004, acc.: 60.94%] [G loss: 0.869583]\n",
      "epoch:24 step:22761 [D loss: 0.647001, acc.: 60.94%] [G loss: 0.926799]\n",
      "epoch:24 step:22762 [D loss: 0.699357, acc.: 48.44%] [G loss: 0.888345]\n",
      "epoch:24 step:22763 [D loss: 0.653654, acc.: 62.50%] [G loss: 0.968092]\n",
      "epoch:24 step:22764 [D loss: 0.687268, acc.: 53.91%] [G loss: 0.913394]\n",
      "epoch:24 step:22765 [D loss: 0.649514, acc.: 58.59%] [G loss: 0.900431]\n",
      "epoch:24 step:22766 [D loss: 0.684219, acc.: 57.03%] [G loss: 0.885527]\n",
      "epoch:24 step:22767 [D loss: 0.652579, acc.: 63.28%] [G loss: 0.814950]\n",
      "epoch:24 step:22768 [D loss: 0.702395, acc.: 55.47%] [G loss: 0.859116]\n",
      "epoch:24 step:22769 [D loss: 0.655339, acc.: 56.25%] [G loss: 0.838392]\n",
      "epoch:24 step:22770 [D loss: 0.634449, acc.: 64.06%] [G loss: 0.863864]\n",
      "epoch:24 step:22771 [D loss: 0.671396, acc.: 57.81%] [G loss: 0.932528]\n",
      "epoch:24 step:22772 [D loss: 0.617451, acc.: 70.31%] [G loss: 0.878889]\n",
      "epoch:24 step:22773 [D loss: 0.666594, acc.: 58.59%] [G loss: 0.928247]\n",
      "epoch:24 step:22774 [D loss: 0.636950, acc.: 63.28%] [G loss: 0.946994]\n",
      "epoch:24 step:22775 [D loss: 0.651716, acc.: 60.16%] [G loss: 0.945263]\n",
      "epoch:24 step:22776 [D loss: 0.620676, acc.: 65.62%] [G loss: 0.903970]\n",
      "epoch:24 step:22777 [D loss: 0.641023, acc.: 67.97%] [G loss: 0.859487]\n",
      "epoch:24 step:22778 [D loss: 0.664952, acc.: 57.81%] [G loss: 0.859933]\n",
      "epoch:24 step:22779 [D loss: 0.684963, acc.: 52.34%] [G loss: 0.879880]\n",
      "epoch:24 step:22780 [D loss: 0.665025, acc.: 57.03%] [G loss: 0.872145]\n",
      "epoch:24 step:22781 [D loss: 0.707471, acc.: 54.69%] [G loss: 0.844771]\n",
      "epoch:24 step:22782 [D loss: 0.670694, acc.: 56.25%] [G loss: 0.940830]\n",
      "epoch:24 step:22783 [D loss: 0.639456, acc.: 64.06%] [G loss: 0.953557]\n",
      "epoch:24 step:22784 [D loss: 0.700573, acc.: 57.03%] [G loss: 0.911874]\n",
      "epoch:24 step:22785 [D loss: 0.647847, acc.: 60.16%] [G loss: 0.895638]\n",
      "epoch:24 step:22786 [D loss: 0.641164, acc.: 63.28%] [G loss: 0.893540]\n",
      "epoch:24 step:22787 [D loss: 0.666168, acc.: 59.38%] [G loss: 0.896841]\n",
      "epoch:24 step:22788 [D loss: 0.678531, acc.: 54.69%] [G loss: 0.902903]\n",
      "epoch:24 step:22789 [D loss: 0.675026, acc.: 56.25%] [G loss: 0.905997]\n",
      "epoch:24 step:22790 [D loss: 0.676087, acc.: 59.38%] [G loss: 0.902913]\n",
      "epoch:24 step:22791 [D loss: 0.653937, acc.: 57.81%] [G loss: 0.910528]\n",
      "epoch:24 step:22792 [D loss: 0.645989, acc.: 64.06%] [G loss: 0.898964]\n",
      "epoch:24 step:22793 [D loss: 0.682142, acc.: 60.16%] [G loss: 0.919750]\n",
      "epoch:24 step:22794 [D loss: 0.651380, acc.: 64.06%] [G loss: 0.886818]\n",
      "epoch:24 step:22795 [D loss: 0.703525, acc.: 53.12%] [G loss: 0.842189]\n",
      "epoch:24 step:22796 [D loss: 0.683079, acc.: 56.25%] [G loss: 0.894509]\n",
      "epoch:24 step:22797 [D loss: 0.631820, acc.: 62.50%] [G loss: 0.920995]\n",
      "epoch:24 step:22798 [D loss: 0.692174, acc.: 51.56%] [G loss: 0.970071]\n",
      "epoch:24 step:22799 [D loss: 0.666805, acc.: 57.81%] [G loss: 0.891236]\n",
      "epoch:24 step:22800 [D loss: 0.664490, acc.: 64.06%] [G loss: 0.912840]\n",
      "##############\n",
      "[3.14048646 2.54111312 2.23200762 4.13417036 1.17027888 9.27426719\n",
      " 2.49447041 3.56802594 4.27802378 8.14868929]\n",
      "##########\n",
      "epoch:24 step:22801 [D loss: 0.656058, acc.: 64.84%] [G loss: 0.946096]\n",
      "epoch:24 step:22802 [D loss: 0.658531, acc.: 60.94%] [G loss: 0.908117]\n",
      "epoch:24 step:22803 [D loss: 0.617660, acc.: 69.53%] [G loss: 0.913741]\n",
      "epoch:24 step:22804 [D loss: 0.669913, acc.: 55.47%] [G loss: 0.927408]\n",
      "epoch:24 step:22805 [D loss: 0.652932, acc.: 62.50%] [G loss: 0.891348]\n",
      "epoch:24 step:22806 [D loss: 0.681765, acc.: 59.38%] [G loss: 0.930173]\n",
      "epoch:24 step:22807 [D loss: 0.655686, acc.: 65.62%] [G loss: 0.883601]\n",
      "epoch:24 step:22808 [D loss: 0.642360, acc.: 60.16%] [G loss: 0.902301]\n",
      "epoch:24 step:22809 [D loss: 0.655824, acc.: 63.28%] [G loss: 0.884066]\n",
      "epoch:24 step:22810 [D loss: 0.678774, acc.: 55.47%] [G loss: 0.922307]\n",
      "epoch:24 step:22811 [D loss: 0.647891, acc.: 60.16%] [G loss: 0.879179]\n",
      "epoch:24 step:22812 [D loss: 0.635750, acc.: 59.38%] [G loss: 0.892748]\n",
      "epoch:24 step:22813 [D loss: 0.687671, acc.: 50.78%] [G loss: 0.849638]\n",
      "epoch:24 step:22814 [D loss: 0.685983, acc.: 56.25%] [G loss: 0.838852]\n",
      "epoch:24 step:22815 [D loss: 0.641588, acc.: 64.84%] [G loss: 0.828963]\n",
      "epoch:24 step:22816 [D loss: 0.644663, acc.: 54.69%] [G loss: 0.845279]\n",
      "epoch:24 step:22817 [D loss: 0.692196, acc.: 50.00%] [G loss: 0.910043]\n",
      "epoch:24 step:22818 [D loss: 0.618760, acc.: 60.94%] [G loss: 0.955223]\n",
      "epoch:24 step:22819 [D loss: 0.672454, acc.: 54.69%] [G loss: 0.959564]\n",
      "epoch:24 step:22820 [D loss: 0.651060, acc.: 57.81%] [G loss: 0.877027]\n",
      "epoch:24 step:22821 [D loss: 0.674224, acc.: 54.69%] [G loss: 0.895901]\n",
      "epoch:24 step:22822 [D loss: 0.643442, acc.: 60.94%] [G loss: 0.883238]\n",
      "epoch:24 step:22823 [D loss: 0.670845, acc.: 58.59%] [G loss: 0.876894]\n",
      "epoch:24 step:22824 [D loss: 0.620383, acc.: 69.53%] [G loss: 0.882883]\n",
      "epoch:24 step:22825 [D loss: 0.636699, acc.: 64.84%] [G loss: 0.871422]\n",
      "epoch:24 step:22826 [D loss: 0.672147, acc.: 54.69%] [G loss: 0.870210]\n",
      "epoch:24 step:22827 [D loss: 0.637247, acc.: 61.72%] [G loss: 0.858623]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22828 [D loss: 0.663598, acc.: 59.38%] [G loss: 0.995294]\n",
      "epoch:24 step:22829 [D loss: 0.647673, acc.: 58.59%] [G loss: 0.905065]\n",
      "epoch:24 step:22830 [D loss: 0.658252, acc.: 62.50%] [G loss: 0.865125]\n",
      "epoch:24 step:22831 [D loss: 0.670734, acc.: 57.81%] [G loss: 0.907129]\n",
      "epoch:24 step:22832 [D loss: 0.675921, acc.: 57.03%] [G loss: 0.873523]\n",
      "epoch:24 step:22833 [D loss: 0.653047, acc.: 60.16%] [G loss: 0.884884]\n",
      "epoch:24 step:22834 [D loss: 0.671526, acc.: 55.47%] [G loss: 0.836181]\n",
      "epoch:24 step:22835 [D loss: 0.644528, acc.: 57.81%] [G loss: 0.879075]\n",
      "epoch:24 step:22836 [D loss: 0.686154, acc.: 56.25%] [G loss: 0.818251]\n",
      "epoch:24 step:22837 [D loss: 0.640740, acc.: 57.81%] [G loss: 0.883800]\n",
      "epoch:24 step:22838 [D loss: 0.650123, acc.: 63.28%] [G loss: 0.902819]\n",
      "epoch:24 step:22839 [D loss: 0.676031, acc.: 58.59%] [G loss: 0.840353]\n",
      "epoch:24 step:22840 [D loss: 0.666471, acc.: 61.72%] [G loss: 0.879776]\n",
      "epoch:24 step:22841 [D loss: 0.645501, acc.: 60.16%] [G loss: 0.870228]\n",
      "epoch:24 step:22842 [D loss: 0.672091, acc.: 58.59%] [G loss: 0.869991]\n",
      "epoch:24 step:22843 [D loss: 0.648706, acc.: 61.72%] [G loss: 0.874488]\n",
      "epoch:24 step:22844 [D loss: 0.657056, acc.: 54.69%] [G loss: 0.870642]\n",
      "epoch:24 step:22845 [D loss: 0.661315, acc.: 57.03%] [G loss: 0.944718]\n",
      "epoch:24 step:22846 [D loss: 0.650949, acc.: 63.28%] [G loss: 0.873829]\n",
      "epoch:24 step:22847 [D loss: 0.662189, acc.: 57.03%] [G loss: 0.839756]\n",
      "epoch:24 step:22848 [D loss: 0.616331, acc.: 69.53%] [G loss: 0.917205]\n",
      "epoch:24 step:22849 [D loss: 0.632637, acc.: 65.62%] [G loss: 0.898769]\n",
      "epoch:24 step:22850 [D loss: 0.652570, acc.: 65.62%] [G loss: 0.896081]\n",
      "epoch:24 step:22851 [D loss: 0.671125, acc.: 54.69%] [G loss: 0.914718]\n",
      "epoch:24 step:22852 [D loss: 0.642347, acc.: 64.84%] [G loss: 0.861083]\n",
      "epoch:24 step:22853 [D loss: 0.696344, acc.: 53.12%] [G loss: 0.843022]\n",
      "epoch:24 step:22854 [D loss: 0.671648, acc.: 56.25%] [G loss: 0.892520]\n",
      "epoch:24 step:22855 [D loss: 0.624124, acc.: 66.41%] [G loss: 0.834490]\n",
      "epoch:24 step:22856 [D loss: 0.652607, acc.: 62.50%] [G loss: 0.892389]\n",
      "epoch:24 step:22857 [D loss: 0.632046, acc.: 67.19%] [G loss: 0.898336]\n",
      "epoch:24 step:22858 [D loss: 0.641510, acc.: 64.06%] [G loss: 0.861657]\n",
      "epoch:24 step:22859 [D loss: 0.684803, acc.: 54.69%] [G loss: 0.920120]\n",
      "epoch:24 step:22860 [D loss: 0.640367, acc.: 59.38%] [G loss: 0.899464]\n",
      "epoch:24 step:22861 [D loss: 0.648140, acc.: 61.72%] [G loss: 0.955959]\n",
      "epoch:24 step:22862 [D loss: 0.718451, acc.: 46.88%] [G loss: 0.861330]\n",
      "epoch:24 step:22863 [D loss: 0.698707, acc.: 53.91%] [G loss: 0.887378]\n",
      "epoch:24 step:22864 [D loss: 0.678278, acc.: 53.91%] [G loss: 0.941935]\n",
      "epoch:24 step:22865 [D loss: 0.662038, acc.: 60.16%] [G loss: 0.916259]\n",
      "epoch:24 step:22866 [D loss: 0.628627, acc.: 62.50%] [G loss: 0.910814]\n",
      "epoch:24 step:22867 [D loss: 0.647186, acc.: 60.16%] [G loss: 0.929524]\n",
      "epoch:24 step:22868 [D loss: 0.661308, acc.: 60.16%] [G loss: 0.901719]\n",
      "epoch:24 step:22869 [D loss: 0.678715, acc.: 53.12%] [G loss: 0.915732]\n",
      "epoch:24 step:22870 [D loss: 0.630872, acc.: 62.50%] [G loss: 0.877991]\n",
      "epoch:24 step:22871 [D loss: 0.664911, acc.: 61.72%] [G loss: 0.853894]\n",
      "epoch:24 step:22872 [D loss: 0.658549, acc.: 62.50%] [G loss: 0.901039]\n",
      "epoch:24 step:22873 [D loss: 0.656882, acc.: 60.94%] [G loss: 0.895609]\n",
      "epoch:24 step:22874 [D loss: 0.698245, acc.: 55.47%] [G loss: 0.880922]\n",
      "epoch:24 step:22875 [D loss: 0.655528, acc.: 65.62%] [G loss: 0.850412]\n",
      "epoch:24 step:22876 [D loss: 0.713231, acc.: 53.12%] [G loss: 0.876635]\n",
      "epoch:24 step:22877 [D loss: 0.654410, acc.: 60.94%] [G loss: 0.876956]\n",
      "epoch:24 step:22878 [D loss: 0.673447, acc.: 61.72%] [G loss: 0.881624]\n",
      "epoch:24 step:22879 [D loss: 0.637686, acc.: 61.72%] [G loss: 0.887247]\n",
      "epoch:24 step:22880 [D loss: 0.628726, acc.: 67.19%] [G loss: 0.901575]\n",
      "epoch:24 step:22881 [D loss: 0.692578, acc.: 48.44%] [G loss: 0.889719]\n",
      "epoch:24 step:22882 [D loss: 0.653458, acc.: 60.94%] [G loss: 0.840603]\n",
      "epoch:24 step:22883 [D loss: 0.665099, acc.: 66.41%] [G loss: 0.878115]\n",
      "epoch:24 step:22884 [D loss: 0.625945, acc.: 64.06%] [G loss: 0.875068]\n",
      "epoch:24 step:22885 [D loss: 0.677199, acc.: 57.81%] [G loss: 0.906932]\n",
      "epoch:24 step:22886 [D loss: 0.668759, acc.: 57.81%] [G loss: 0.824408]\n",
      "epoch:24 step:22887 [D loss: 0.658876, acc.: 58.59%] [G loss: 0.880173]\n",
      "epoch:24 step:22888 [D loss: 0.641029, acc.: 64.06%] [G loss: 0.900495]\n",
      "epoch:24 step:22889 [D loss: 0.633977, acc.: 60.16%] [G loss: 0.894945]\n",
      "epoch:24 step:22890 [D loss: 0.626805, acc.: 62.50%] [G loss: 0.862397]\n",
      "epoch:24 step:22891 [D loss: 0.643164, acc.: 64.84%] [G loss: 0.929422]\n",
      "epoch:24 step:22892 [D loss: 0.636453, acc.: 66.41%] [G loss: 0.936069]\n",
      "epoch:24 step:22893 [D loss: 0.653136, acc.: 61.72%] [G loss: 0.898553]\n",
      "epoch:24 step:22894 [D loss: 0.664025, acc.: 60.94%] [G loss: 0.829871]\n",
      "epoch:24 step:22895 [D loss: 0.653489, acc.: 60.94%] [G loss: 0.869222]\n",
      "epoch:24 step:22896 [D loss: 0.639625, acc.: 62.50%] [G loss: 0.885857]\n",
      "epoch:24 step:22897 [D loss: 0.692262, acc.: 53.91%] [G loss: 0.871442]\n",
      "epoch:24 step:22898 [D loss: 0.704485, acc.: 51.56%] [G loss: 0.837754]\n",
      "epoch:24 step:22899 [D loss: 0.653926, acc.: 63.28%] [G loss: 0.863616]\n",
      "epoch:24 step:22900 [D loss: 0.687418, acc.: 49.22%] [G loss: 0.953434]\n",
      "epoch:24 step:22901 [D loss: 0.673265, acc.: 58.59%] [G loss: 0.876648]\n",
      "epoch:24 step:22902 [D loss: 0.615246, acc.: 64.84%] [G loss: 0.902363]\n",
      "epoch:24 step:22903 [D loss: 0.682553, acc.: 54.69%] [G loss: 0.890060]\n",
      "epoch:24 step:22904 [D loss: 0.653440, acc.: 60.16%] [G loss: 0.887458]\n",
      "epoch:24 step:22905 [D loss: 0.610271, acc.: 67.97%] [G loss: 0.890471]\n",
      "epoch:24 step:22906 [D loss: 0.659338, acc.: 62.50%] [G loss: 0.902606]\n",
      "epoch:24 step:22907 [D loss: 0.681238, acc.: 56.25%] [G loss: 0.897045]\n",
      "epoch:24 step:22908 [D loss: 0.649317, acc.: 62.50%] [G loss: 0.864027]\n",
      "epoch:24 step:22909 [D loss: 0.669668, acc.: 59.38%] [G loss: 0.909260]\n",
      "epoch:24 step:22910 [D loss: 0.625491, acc.: 60.16%] [G loss: 0.953537]\n",
      "epoch:24 step:22911 [D loss: 0.688041, acc.: 54.69%] [G loss: 0.929025]\n",
      "epoch:24 step:22912 [D loss: 0.653269, acc.: 60.94%] [G loss: 0.813787]\n",
      "epoch:24 step:22913 [D loss: 0.694178, acc.: 54.69%] [G loss: 0.878644]\n",
      "epoch:24 step:22914 [D loss: 0.658648, acc.: 65.62%] [G loss: 0.891457]\n",
      "epoch:24 step:22915 [D loss: 0.663642, acc.: 53.91%] [G loss: 0.935198]\n",
      "epoch:24 step:22916 [D loss: 0.664764, acc.: 59.38%] [G loss: 0.848288]\n",
      "epoch:24 step:22917 [D loss: 0.636289, acc.: 63.28%] [G loss: 0.848499]\n",
      "epoch:24 step:22918 [D loss: 0.673629, acc.: 57.03%] [G loss: 0.843692]\n",
      "epoch:24 step:22919 [D loss: 0.632336, acc.: 65.62%] [G loss: 0.889294]\n",
      "epoch:24 step:22920 [D loss: 0.628006, acc.: 67.97%] [G loss: 0.832857]\n",
      "epoch:24 step:22921 [D loss: 0.647768, acc.: 59.38%] [G loss: 0.915538]\n",
      "epoch:24 step:22922 [D loss: 0.630296, acc.: 65.62%] [G loss: 0.899084]\n",
      "epoch:24 step:22923 [D loss: 0.650781, acc.: 58.59%] [G loss: 0.826105]\n",
      "epoch:24 step:22924 [D loss: 0.627240, acc.: 66.41%] [G loss: 0.893764]\n",
      "epoch:24 step:22925 [D loss: 0.691874, acc.: 60.16%] [G loss: 0.857858]\n",
      "epoch:24 step:22926 [D loss: 0.681094, acc.: 64.06%] [G loss: 0.856402]\n",
      "epoch:24 step:22927 [D loss: 0.649486, acc.: 61.72%] [G loss: 0.949382]\n",
      "epoch:24 step:22928 [D loss: 0.670243, acc.: 59.38%] [G loss: 0.977451]\n",
      "epoch:24 step:22929 [D loss: 0.625415, acc.: 65.62%] [G loss: 1.029953]\n",
      "epoch:24 step:22930 [D loss: 0.665360, acc.: 59.38%] [G loss: 0.894106]\n",
      "epoch:24 step:22931 [D loss: 0.666335, acc.: 56.25%] [G loss: 0.954767]\n",
      "epoch:24 step:22932 [D loss: 0.609807, acc.: 67.97%] [G loss: 0.841162]\n",
      "epoch:24 step:22933 [D loss: 0.653141, acc.: 60.16%] [G loss: 0.894999]\n",
      "epoch:24 step:22934 [D loss: 0.673908, acc.: 53.91%] [G loss: 0.883720]\n",
      "epoch:24 step:22935 [D loss: 0.650161, acc.: 57.81%] [G loss: 0.824222]\n",
      "epoch:24 step:22936 [D loss: 0.696582, acc.: 55.47%] [G loss: 0.845198]\n",
      "epoch:24 step:22937 [D loss: 0.652117, acc.: 54.69%] [G loss: 0.906172]\n",
      "epoch:24 step:22938 [D loss: 0.632832, acc.: 61.72%] [G loss: 0.900599]\n",
      "epoch:24 step:22939 [D loss: 0.648728, acc.: 62.50%] [G loss: 0.902519]\n",
      "epoch:24 step:22940 [D loss: 0.656497, acc.: 57.81%] [G loss: 0.893085]\n",
      "epoch:24 step:22941 [D loss: 0.659210, acc.: 56.25%] [G loss: 0.926284]\n",
      "epoch:24 step:22942 [D loss: 0.652932, acc.: 54.69%] [G loss: 0.939834]\n",
      "epoch:24 step:22943 [D loss: 0.617945, acc.: 65.62%] [G loss: 0.863657]\n",
      "epoch:24 step:22944 [D loss: 0.677687, acc.: 60.16%] [G loss: 0.915740]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:22945 [D loss: 0.646139, acc.: 60.16%] [G loss: 0.913074]\n",
      "epoch:24 step:22946 [D loss: 0.679357, acc.: 57.81%] [G loss: 0.890449]\n",
      "epoch:24 step:22947 [D loss: 0.610918, acc.: 64.06%] [G loss: 0.903738]\n",
      "epoch:24 step:22948 [D loss: 0.634195, acc.: 59.38%] [G loss: 0.931944]\n",
      "epoch:24 step:22949 [D loss: 0.678725, acc.: 50.00%] [G loss: 0.845389]\n",
      "epoch:24 step:22950 [D loss: 0.676461, acc.: 53.12%] [G loss: 0.903418]\n",
      "epoch:24 step:22951 [D loss: 0.674606, acc.: 58.59%] [G loss: 0.857574]\n",
      "epoch:24 step:22952 [D loss: 0.655594, acc.: 56.25%] [G loss: 0.880054]\n",
      "epoch:24 step:22953 [D loss: 0.639664, acc.: 62.50%] [G loss: 0.892283]\n",
      "epoch:24 step:22954 [D loss: 0.665455, acc.: 60.16%] [G loss: 0.917363]\n",
      "epoch:24 step:22955 [D loss: 0.652119, acc.: 64.06%] [G loss: 0.871479]\n",
      "epoch:24 step:22956 [D loss: 0.637347, acc.: 61.72%] [G loss: 0.849476]\n",
      "epoch:24 step:22957 [D loss: 0.615164, acc.: 67.97%] [G loss: 0.931018]\n",
      "epoch:24 step:22958 [D loss: 0.644256, acc.: 64.06%] [G loss: 0.881064]\n",
      "epoch:24 step:22959 [D loss: 0.660159, acc.: 65.62%] [G loss: 0.885547]\n",
      "epoch:24 step:22960 [D loss: 0.653785, acc.: 61.72%] [G loss: 0.963641]\n",
      "epoch:24 step:22961 [D loss: 0.664632, acc.: 56.25%] [G loss: 1.003294]\n",
      "epoch:24 step:22962 [D loss: 0.645462, acc.: 62.50%] [G loss: 0.969638]\n",
      "epoch:24 step:22963 [D loss: 0.626837, acc.: 68.75%] [G loss: 0.911955]\n",
      "epoch:24 step:22964 [D loss: 0.668733, acc.: 59.38%] [G loss: 0.941818]\n",
      "epoch:24 step:22965 [D loss: 0.678806, acc.: 58.59%] [G loss: 0.942805]\n",
      "epoch:24 step:22966 [D loss: 0.668261, acc.: 62.50%] [G loss: 0.884620]\n",
      "epoch:24 step:22967 [D loss: 0.714145, acc.: 54.69%] [G loss: 0.909665]\n",
      "epoch:24 step:22968 [D loss: 0.653929, acc.: 66.41%] [G loss: 0.877482]\n",
      "epoch:24 step:22969 [D loss: 0.681318, acc.: 57.81%] [G loss: 0.855391]\n",
      "epoch:24 step:22970 [D loss: 0.686320, acc.: 51.56%] [G loss: 0.928570]\n",
      "epoch:24 step:22971 [D loss: 0.691890, acc.: 51.56%] [G loss: 0.951169]\n",
      "epoch:24 step:22972 [D loss: 0.650709, acc.: 61.72%] [G loss: 0.910595]\n",
      "epoch:24 step:22973 [D loss: 0.645202, acc.: 64.84%] [G loss: 0.862042]\n",
      "epoch:24 step:22974 [D loss: 0.620938, acc.: 66.41%] [G loss: 0.868966]\n",
      "epoch:24 step:22975 [D loss: 0.652639, acc.: 63.28%] [G loss: 0.888330]\n",
      "epoch:24 step:22976 [D loss: 0.578684, acc.: 73.44%] [G loss: 0.904782]\n",
      "epoch:24 step:22977 [D loss: 0.628170, acc.: 65.62%] [G loss: 0.876798]\n",
      "epoch:24 step:22978 [D loss: 0.635070, acc.: 67.19%] [G loss: 0.889326]\n",
      "epoch:24 step:22979 [D loss: 0.641914, acc.: 64.06%] [G loss: 0.856663]\n",
      "epoch:24 step:22980 [D loss: 0.646134, acc.: 62.50%] [G loss: 0.835349]\n",
      "epoch:24 step:22981 [D loss: 0.648445, acc.: 62.50%] [G loss: 0.850356]\n",
      "epoch:24 step:22982 [D loss: 0.654338, acc.: 64.84%] [G loss: 0.884505]\n",
      "epoch:24 step:22983 [D loss: 0.705968, acc.: 55.47%] [G loss: 0.884121]\n",
      "epoch:24 step:22984 [D loss: 0.709855, acc.: 53.91%] [G loss: 0.933667]\n",
      "epoch:24 step:22985 [D loss: 0.655126, acc.: 62.50%] [G loss: 0.839572]\n",
      "epoch:24 step:22986 [D loss: 0.658933, acc.: 57.03%] [G loss: 0.923747]\n",
      "epoch:24 step:22987 [D loss: 0.634472, acc.: 63.28%] [G loss: 0.910073]\n",
      "epoch:24 step:22988 [D loss: 0.692867, acc.: 52.34%] [G loss: 0.879473]\n",
      "epoch:24 step:22989 [D loss: 0.652699, acc.: 64.06%] [G loss: 0.856644]\n",
      "epoch:24 step:22990 [D loss: 0.650976, acc.: 60.94%] [G loss: 0.850625]\n",
      "epoch:24 step:22991 [D loss: 0.682148, acc.: 59.38%] [G loss: 0.935153]\n",
      "epoch:24 step:22992 [D loss: 0.688250, acc.: 50.78%] [G loss: 0.858122]\n",
      "epoch:24 step:22993 [D loss: 0.637410, acc.: 64.06%] [G loss: 0.886550]\n",
      "epoch:24 step:22994 [D loss: 0.663157, acc.: 59.38%] [G loss: 0.860851]\n",
      "epoch:24 step:22995 [D loss: 0.680742, acc.: 57.03%] [G loss: 0.910058]\n",
      "epoch:24 step:22996 [D loss: 0.649126, acc.: 64.06%] [G loss: 0.888542]\n",
      "epoch:24 step:22997 [D loss: 0.623516, acc.: 64.84%] [G loss: 0.841095]\n",
      "epoch:24 step:22998 [D loss: 0.610552, acc.: 70.31%] [G loss: 0.846164]\n",
      "epoch:24 step:22999 [D loss: 0.649617, acc.: 62.50%] [G loss: 0.854797]\n",
      "epoch:24 step:23000 [D loss: 0.696276, acc.: 54.69%] [G loss: 0.872020]\n",
      "##############\n",
      "[2.97273135 2.32583811 2.22665919 3.95999019 1.43311305 9.27426719\n",
      " 2.7658434  3.46495924 4.25140013 8.14868929]\n",
      "##########\n",
      "epoch:24 step:23001 [D loss: 0.654902, acc.: 57.81%] [G loss: 0.872153]\n",
      "epoch:24 step:23002 [D loss: 0.651649, acc.: 60.16%] [G loss: 0.869863]\n",
      "epoch:24 step:23003 [D loss: 0.673754, acc.: 60.16%] [G loss: 0.854888]\n",
      "epoch:24 step:23004 [D loss: 0.654882, acc.: 57.81%] [G loss: 0.935305]\n",
      "epoch:24 step:23005 [D loss: 0.638393, acc.: 64.06%] [G loss: 0.860061]\n",
      "epoch:24 step:23006 [D loss: 0.670198, acc.: 62.50%] [G loss: 0.888086]\n",
      "epoch:24 step:23007 [D loss: 0.644097, acc.: 64.06%] [G loss: 0.943623]\n",
      "epoch:24 step:23008 [D loss: 0.664060, acc.: 63.28%] [G loss: 0.895915]\n",
      "epoch:24 step:23009 [D loss: 0.670137, acc.: 59.38%] [G loss: 0.887629]\n",
      "epoch:24 step:23010 [D loss: 0.611681, acc.: 68.75%] [G loss: 0.886129]\n",
      "epoch:24 step:23011 [D loss: 0.633024, acc.: 61.72%] [G loss: 0.913730]\n",
      "epoch:24 step:23012 [D loss: 0.644192, acc.: 66.41%] [G loss: 0.998019]\n",
      "epoch:24 step:23013 [D loss: 0.627438, acc.: 64.84%] [G loss: 0.916056]\n",
      "epoch:24 step:23014 [D loss: 0.710264, acc.: 46.88%] [G loss: 0.879649]\n",
      "epoch:24 step:23015 [D loss: 0.643066, acc.: 64.06%] [G loss: 0.902173]\n",
      "epoch:24 step:23016 [D loss: 0.663133, acc.: 58.59%] [G loss: 0.870137]\n",
      "epoch:24 step:23017 [D loss: 0.632256, acc.: 64.06%] [G loss: 0.910801]\n",
      "epoch:24 step:23018 [D loss: 0.633111, acc.: 63.28%] [G loss: 0.915863]\n",
      "epoch:24 step:23019 [D loss: 0.653148, acc.: 60.16%] [G loss: 0.872684]\n",
      "epoch:24 step:23020 [D loss: 0.672645, acc.: 57.03%] [G loss: 0.859652]\n",
      "epoch:24 step:23021 [D loss: 0.619491, acc.: 64.84%] [G loss: 0.838215]\n",
      "epoch:24 step:23022 [D loss: 0.635288, acc.: 65.62%] [G loss: 0.847308]\n",
      "epoch:24 step:23023 [D loss: 0.671334, acc.: 53.91%] [G loss: 0.935659]\n",
      "epoch:24 step:23024 [D loss: 0.711238, acc.: 50.00%] [G loss: 0.884048]\n",
      "epoch:24 step:23025 [D loss: 0.681258, acc.: 60.16%] [G loss: 0.888946]\n",
      "epoch:24 step:23026 [D loss: 0.662736, acc.: 59.38%] [G loss: 0.855177]\n",
      "epoch:24 step:23027 [D loss: 0.679937, acc.: 57.81%] [G loss: 0.853854]\n",
      "epoch:24 step:23028 [D loss: 0.642701, acc.: 60.16%] [G loss: 0.879003]\n",
      "epoch:24 step:23029 [D loss: 0.626495, acc.: 64.06%] [G loss: 0.875574]\n",
      "epoch:24 step:23030 [D loss: 0.663165, acc.: 59.38%] [G loss: 0.881484]\n",
      "epoch:24 step:23031 [D loss: 0.631005, acc.: 65.62%] [G loss: 0.895972]\n",
      "epoch:24 step:23032 [D loss: 0.646706, acc.: 64.06%] [G loss: 0.861113]\n",
      "epoch:24 step:23033 [D loss: 0.637350, acc.: 60.16%] [G loss: 0.878778]\n",
      "epoch:24 step:23034 [D loss: 0.673451, acc.: 61.72%] [G loss: 0.943207]\n",
      "epoch:24 step:23035 [D loss: 0.673215, acc.: 57.81%] [G loss: 0.947263]\n",
      "epoch:24 step:23036 [D loss: 0.680421, acc.: 55.47%] [G loss: 0.912804]\n",
      "epoch:24 step:23037 [D loss: 0.677311, acc.: 55.47%] [G loss: 0.853836]\n",
      "epoch:24 step:23038 [D loss: 0.648757, acc.: 63.28%] [G loss: 0.902764]\n",
      "epoch:24 step:23039 [D loss: 0.668535, acc.: 56.25%] [G loss: 0.935515]\n",
      "epoch:24 step:23040 [D loss: 0.666837, acc.: 61.72%] [G loss: 0.889287]\n",
      "epoch:24 step:23041 [D loss: 0.642641, acc.: 62.50%] [G loss: 0.847399]\n",
      "epoch:24 step:23042 [D loss: 0.673575, acc.: 57.81%] [G loss: 0.855941]\n",
      "epoch:24 step:23043 [D loss: 0.654919, acc.: 62.50%] [G loss: 0.880884]\n",
      "epoch:24 step:23044 [D loss: 0.670941, acc.: 53.91%] [G loss: 0.809282]\n",
      "epoch:24 step:23045 [D loss: 0.634770, acc.: 64.84%] [G loss: 0.816400]\n",
      "epoch:24 step:23046 [D loss: 0.631554, acc.: 59.38%] [G loss: 0.884938]\n",
      "epoch:24 step:23047 [D loss: 0.686054, acc.: 58.59%] [G loss: 0.836535]\n",
      "epoch:24 step:23048 [D loss: 0.630606, acc.: 65.62%] [G loss: 0.834451]\n",
      "epoch:24 step:23049 [D loss: 0.681874, acc.: 56.25%] [G loss: 0.895034]\n",
      "epoch:24 step:23050 [D loss: 0.628784, acc.: 66.41%] [G loss: 0.876496]\n",
      "epoch:24 step:23051 [D loss: 0.663748, acc.: 59.38%] [G loss: 0.889814]\n",
      "epoch:24 step:23052 [D loss: 0.637215, acc.: 62.50%] [G loss: 0.879134]\n",
      "epoch:24 step:23053 [D loss: 0.647259, acc.: 64.06%] [G loss: 0.902770]\n",
      "epoch:24 step:23054 [D loss: 0.612007, acc.: 66.41%] [G loss: 0.882039]\n",
      "epoch:24 step:23055 [D loss: 0.667137, acc.: 59.38%] [G loss: 0.943040]\n",
      "epoch:24 step:23056 [D loss: 0.689836, acc.: 52.34%] [G loss: 0.870704]\n",
      "epoch:24 step:23057 [D loss: 0.655551, acc.: 64.06%] [G loss: 0.896532]\n",
      "epoch:24 step:23058 [D loss: 0.708449, acc.: 53.91%] [G loss: 0.882313]\n",
      "epoch:24 step:23059 [D loss: 0.694984, acc.: 53.91%] [G loss: 0.877220]\n",
      "epoch:24 step:23060 [D loss: 0.666176, acc.: 59.38%] [G loss: 0.776198]\n",
      "epoch:24 step:23061 [D loss: 0.645858, acc.: 64.84%] [G loss: 0.829233]\n",
      "epoch:24 step:23062 [D loss: 0.649407, acc.: 58.59%] [G loss: 0.851590]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:23063 [D loss: 0.689801, acc.: 52.34%] [G loss: 0.885877]\n",
      "epoch:24 step:23064 [D loss: 0.655376, acc.: 62.50%] [G loss: 0.906464]\n",
      "epoch:24 step:23065 [D loss: 0.662364, acc.: 60.16%] [G loss: 0.896711]\n",
      "epoch:24 step:23066 [D loss: 0.638086, acc.: 66.41%] [G loss: 0.909916]\n",
      "epoch:24 step:23067 [D loss: 0.643577, acc.: 63.28%] [G loss: 0.875723]\n",
      "epoch:24 step:23068 [D loss: 0.674407, acc.: 53.12%] [G loss: 0.922957]\n",
      "epoch:24 step:23069 [D loss: 0.630268, acc.: 66.41%] [G loss: 0.900272]\n",
      "epoch:24 step:23070 [D loss: 0.632707, acc.: 64.84%] [G loss: 0.858327]\n",
      "epoch:24 step:23071 [D loss: 0.681827, acc.: 53.12%] [G loss: 0.862521]\n",
      "epoch:24 step:23072 [D loss: 0.623074, acc.: 64.06%] [G loss: 0.827387]\n",
      "epoch:24 step:23073 [D loss: 0.694517, acc.: 54.69%] [G loss: 0.883072]\n",
      "epoch:24 step:23074 [D loss: 0.680694, acc.: 55.47%] [G loss: 0.924242]\n",
      "epoch:24 step:23075 [D loss: 0.635274, acc.: 64.06%] [G loss: 0.910115]\n",
      "epoch:24 step:23076 [D loss: 0.691470, acc.: 55.47%] [G loss: 0.877543]\n",
      "epoch:24 step:23077 [D loss: 0.667246, acc.: 55.47%] [G loss: 0.895634]\n",
      "epoch:24 step:23078 [D loss: 0.651394, acc.: 66.41%] [G loss: 0.883351]\n",
      "epoch:24 step:23079 [D loss: 0.627839, acc.: 63.28%] [G loss: 0.955002]\n",
      "epoch:24 step:23080 [D loss: 0.672998, acc.: 60.94%] [G loss: 0.875448]\n",
      "epoch:24 step:23081 [D loss: 0.658267, acc.: 61.72%] [G loss: 0.933283]\n",
      "epoch:24 step:23082 [D loss: 0.636034, acc.: 62.50%] [G loss: 0.863611]\n",
      "epoch:24 step:23083 [D loss: 0.646427, acc.: 61.72%] [G loss: 0.883938]\n",
      "epoch:24 step:23084 [D loss: 0.655432, acc.: 65.62%] [G loss: 0.864525]\n",
      "epoch:24 step:23085 [D loss: 0.647269, acc.: 58.59%] [G loss: 0.890286]\n",
      "epoch:24 step:23086 [D loss: 0.655162, acc.: 64.84%] [G loss: 0.896679]\n",
      "epoch:24 step:23087 [D loss: 0.608682, acc.: 70.31%] [G loss: 1.006593]\n",
      "epoch:24 step:23088 [D loss: 0.634046, acc.: 63.28%] [G loss: 0.977849]\n",
      "epoch:24 step:23089 [D loss: 0.649734, acc.: 60.94%] [G loss: 0.899406]\n",
      "epoch:24 step:23090 [D loss: 0.668190, acc.: 64.06%] [G loss: 0.929915]\n",
      "epoch:24 step:23091 [D loss: 0.668215, acc.: 57.81%] [G loss: 0.906810]\n",
      "epoch:24 step:23092 [D loss: 0.683819, acc.: 63.28%] [G loss: 0.887209]\n",
      "epoch:24 step:23093 [D loss: 0.643227, acc.: 62.50%] [G loss: 0.861977]\n",
      "epoch:24 step:23094 [D loss: 0.612208, acc.: 68.75%] [G loss: 0.865380]\n",
      "epoch:24 step:23095 [D loss: 0.676020, acc.: 53.12%] [G loss: 0.909405]\n",
      "epoch:24 step:23096 [D loss: 0.677267, acc.: 54.69%] [G loss: 0.922383]\n",
      "epoch:24 step:23097 [D loss: 0.625746, acc.: 67.97%] [G loss: 0.890756]\n",
      "epoch:24 step:23098 [D loss: 0.680506, acc.: 54.69%] [G loss: 0.858829]\n",
      "epoch:24 step:23099 [D loss: 0.689151, acc.: 50.00%] [G loss: 0.944214]\n",
      "epoch:24 step:23100 [D loss: 0.667889, acc.: 57.03%] [G loss: 0.940041]\n",
      "epoch:24 step:23101 [D loss: 0.638411, acc.: 63.28%] [G loss: 0.926437]\n",
      "epoch:24 step:23102 [D loss: 0.674860, acc.: 59.38%] [G loss: 0.893614]\n",
      "epoch:24 step:23103 [D loss: 0.685492, acc.: 60.94%] [G loss: 0.941921]\n",
      "epoch:24 step:23104 [D loss: 0.649635, acc.: 62.50%] [G loss: 0.895252]\n",
      "epoch:24 step:23105 [D loss: 0.664535, acc.: 60.16%] [G loss: 0.872983]\n",
      "epoch:24 step:23106 [D loss: 0.652830, acc.: 55.47%] [G loss: 0.886245]\n",
      "epoch:24 step:23107 [D loss: 0.734208, acc.: 51.56%] [G loss: 0.835140]\n",
      "epoch:24 step:23108 [D loss: 0.677262, acc.: 52.34%] [G loss: 0.878309]\n",
      "epoch:24 step:23109 [D loss: 0.675248, acc.: 58.59%] [G loss: 0.863710]\n",
      "epoch:24 step:23110 [D loss: 0.655651, acc.: 59.38%] [G loss: 0.888753]\n",
      "epoch:24 step:23111 [D loss: 0.622964, acc.: 71.09%] [G loss: 0.868444]\n",
      "epoch:24 step:23112 [D loss: 0.668866, acc.: 57.81%] [G loss: 0.871641]\n",
      "epoch:24 step:23113 [D loss: 0.679662, acc.: 57.81%] [G loss: 0.857377]\n",
      "epoch:24 step:23114 [D loss: 0.682534, acc.: 58.59%] [G loss: 0.867628]\n",
      "epoch:24 step:23115 [D loss: 0.649111, acc.: 59.38%] [G loss: 0.872543]\n",
      "epoch:24 step:23116 [D loss: 0.700306, acc.: 54.69%] [G loss: 0.914891]\n",
      "epoch:24 step:23117 [D loss: 0.642409, acc.: 63.28%] [G loss: 0.851602]\n",
      "epoch:24 step:23118 [D loss: 0.707894, acc.: 56.25%] [G loss: 0.859842]\n",
      "epoch:24 step:23119 [D loss: 0.610271, acc.: 66.41%] [G loss: 0.892534]\n",
      "epoch:24 step:23120 [D loss: 0.653930, acc.: 59.38%] [G loss: 0.862945]\n",
      "epoch:24 step:23121 [D loss: 0.648372, acc.: 62.50%] [G loss: 0.898806]\n",
      "epoch:24 step:23122 [D loss: 0.652206, acc.: 62.50%] [G loss: 0.879278]\n",
      "epoch:24 step:23123 [D loss: 0.653701, acc.: 64.06%] [G loss: 0.861495]\n",
      "epoch:24 step:23124 [D loss: 0.630602, acc.: 62.50%] [G loss: 0.902700]\n",
      "epoch:24 step:23125 [D loss: 0.626143, acc.: 68.75%] [G loss: 0.894274]\n",
      "epoch:24 step:23126 [D loss: 0.660378, acc.: 59.38%] [G loss: 0.867618]\n",
      "epoch:24 step:23127 [D loss: 0.695879, acc.: 55.47%] [G loss: 0.910141]\n",
      "epoch:24 step:23128 [D loss: 0.620435, acc.: 70.31%] [G loss: 0.914951]\n",
      "epoch:24 step:23129 [D loss: 0.639109, acc.: 66.41%] [G loss: 0.829132]\n",
      "epoch:24 step:23130 [D loss: 0.632535, acc.: 67.97%] [G loss: 0.864836]\n",
      "epoch:24 step:23131 [D loss: 0.684115, acc.: 62.50%] [G loss: 0.880549]\n",
      "epoch:24 step:23132 [D loss: 0.666980, acc.: 57.81%] [G loss: 0.864246]\n",
      "epoch:24 step:23133 [D loss: 0.647555, acc.: 63.28%] [G loss: 0.941462]\n",
      "epoch:24 step:23134 [D loss: 0.693954, acc.: 56.25%] [G loss: 0.916702]\n",
      "epoch:24 step:23135 [D loss: 0.695331, acc.: 50.78%] [G loss: 0.891228]\n",
      "epoch:24 step:23136 [D loss: 0.620942, acc.: 64.84%] [G loss: 0.846727]\n",
      "epoch:24 step:23137 [D loss: 0.657297, acc.: 57.03%] [G loss: 0.871550]\n",
      "epoch:24 step:23138 [D loss: 0.653481, acc.: 59.38%] [G loss: 0.866843]\n",
      "epoch:24 step:23139 [D loss: 0.639728, acc.: 57.81%] [G loss: 0.847856]\n",
      "epoch:24 step:23140 [D loss: 0.705485, acc.: 53.12%] [G loss: 0.874065]\n",
      "epoch:24 step:23141 [D loss: 0.650577, acc.: 63.28%] [G loss: 0.872325]\n",
      "epoch:24 step:23142 [D loss: 0.654925, acc.: 62.50%] [G loss: 0.872016]\n",
      "epoch:24 step:23143 [D loss: 0.693519, acc.: 53.91%] [G loss: 0.878172]\n",
      "epoch:24 step:23144 [D loss: 0.621530, acc.: 65.62%] [G loss: 0.878048]\n",
      "epoch:24 step:23145 [D loss: 0.642788, acc.: 57.81%] [G loss: 0.967001]\n",
      "epoch:24 step:23146 [D loss: 0.703256, acc.: 50.78%] [G loss: 0.893515]\n",
      "epoch:24 step:23147 [D loss: 0.667904, acc.: 53.12%] [G loss: 0.876704]\n",
      "epoch:24 step:23148 [D loss: 0.665056, acc.: 60.94%] [G loss: 0.878675]\n",
      "epoch:24 step:23149 [D loss: 0.652393, acc.: 61.72%] [G loss: 0.892036]\n",
      "epoch:24 step:23150 [D loss: 0.676070, acc.: 58.59%] [G loss: 0.870746]\n",
      "epoch:24 step:23151 [D loss: 0.671543, acc.: 56.25%] [G loss: 0.916781]\n",
      "epoch:24 step:23152 [D loss: 0.656503, acc.: 59.38%] [G loss: 0.846449]\n",
      "epoch:24 step:23153 [D loss: 0.676033, acc.: 61.72%] [G loss: 0.885549]\n",
      "epoch:24 step:23154 [D loss: 0.661290, acc.: 59.38%] [G loss: 0.829842]\n",
      "epoch:24 step:23155 [D loss: 0.683183, acc.: 55.47%] [G loss: 0.848151]\n",
      "epoch:24 step:23156 [D loss: 0.656300, acc.: 58.59%] [G loss: 0.898649]\n",
      "epoch:24 step:23157 [D loss: 0.660173, acc.: 59.38%] [G loss: 0.886944]\n",
      "epoch:24 step:23158 [D loss: 0.631432, acc.: 62.50%] [G loss: 0.903624]\n",
      "epoch:24 step:23159 [D loss: 0.656520, acc.: 58.59%] [G loss: 0.910483]\n",
      "epoch:24 step:23160 [D loss: 0.648283, acc.: 57.03%] [G loss: 0.930277]\n",
      "epoch:24 step:23161 [D loss: 0.671070, acc.: 60.94%] [G loss: 0.920735]\n",
      "epoch:24 step:23162 [D loss: 0.632996, acc.: 63.28%] [G loss: 0.824530]\n",
      "epoch:24 step:23163 [D loss: 0.638456, acc.: 57.03%] [G loss: 0.907230]\n",
      "epoch:24 step:23164 [D loss: 0.628998, acc.: 67.97%] [G loss: 0.912851]\n",
      "epoch:24 step:23165 [D loss: 0.637095, acc.: 62.50%] [G loss: 0.856858]\n",
      "epoch:24 step:23166 [D loss: 0.664942, acc.: 57.81%] [G loss: 0.831403]\n",
      "epoch:24 step:23167 [D loss: 0.692115, acc.: 50.00%] [G loss: 0.850590]\n",
      "epoch:24 step:23168 [D loss: 0.673142, acc.: 52.34%] [G loss: 0.854399]\n",
      "epoch:24 step:23169 [D loss: 0.645853, acc.: 69.53%] [G loss: 0.930167]\n",
      "epoch:24 step:23170 [D loss: 0.648212, acc.: 60.16%] [G loss: 0.829775]\n",
      "epoch:24 step:23171 [D loss: 0.632840, acc.: 62.50%] [G loss: 0.829751]\n",
      "epoch:24 step:23172 [D loss: 0.686707, acc.: 60.16%] [G loss: 0.892315]\n",
      "epoch:24 step:23173 [D loss: 0.642928, acc.: 65.62%] [G loss: 0.867213]\n",
      "epoch:24 step:23174 [D loss: 0.627717, acc.: 67.19%] [G loss: 0.854660]\n",
      "epoch:24 step:23175 [D loss: 0.642169, acc.: 63.28%] [G loss: 0.900606]\n",
      "epoch:24 step:23176 [D loss: 0.644337, acc.: 61.72%] [G loss: 0.891618]\n",
      "epoch:24 step:23177 [D loss: 0.643219, acc.: 63.28%] [G loss: 0.892377]\n",
      "epoch:24 step:23178 [D loss: 0.672499, acc.: 56.25%] [G loss: 0.879951]\n",
      "epoch:24 step:23179 [D loss: 0.683281, acc.: 53.12%] [G loss: 0.874807]\n",
      "epoch:24 step:23180 [D loss: 0.674992, acc.: 60.16%] [G loss: 0.876613]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:23181 [D loss: 0.643025, acc.: 67.19%] [G loss: 0.872675]\n",
      "epoch:24 step:23182 [D loss: 0.657140, acc.: 60.16%] [G loss: 0.870766]\n",
      "epoch:24 step:23183 [D loss: 0.649537, acc.: 60.94%] [G loss: 0.891411]\n",
      "epoch:24 step:23184 [D loss: 0.640265, acc.: 64.84%] [G loss: 0.914147]\n",
      "epoch:24 step:23185 [D loss: 0.687903, acc.: 57.81%] [G loss: 0.892150]\n",
      "epoch:24 step:23186 [D loss: 0.672845, acc.: 51.56%] [G loss: 0.854893]\n",
      "epoch:24 step:23187 [D loss: 0.665894, acc.: 57.81%] [G loss: 0.862840]\n",
      "epoch:24 step:23188 [D loss: 0.660262, acc.: 60.94%] [G loss: 0.879175]\n",
      "epoch:24 step:23189 [D loss: 0.651191, acc.: 60.94%] [G loss: 0.932764]\n",
      "epoch:24 step:23190 [D loss: 0.635459, acc.: 60.94%] [G loss: 0.853932]\n",
      "epoch:24 step:23191 [D loss: 0.654752, acc.: 63.28%] [G loss: 0.892583]\n",
      "epoch:24 step:23192 [D loss: 0.672967, acc.: 56.25%] [G loss: 0.823101]\n",
      "epoch:24 step:23193 [D loss: 0.642162, acc.: 60.16%] [G loss: 0.824854]\n",
      "epoch:24 step:23194 [D loss: 0.685313, acc.: 57.03%] [G loss: 0.851213]\n",
      "epoch:24 step:23195 [D loss: 0.641776, acc.: 60.94%] [G loss: 0.861139]\n",
      "epoch:24 step:23196 [D loss: 0.684031, acc.: 54.69%] [G loss: 0.835244]\n",
      "epoch:24 step:23197 [D loss: 0.705696, acc.: 57.81%] [G loss: 0.872920]\n",
      "epoch:24 step:23198 [D loss: 0.632379, acc.: 58.59%] [G loss: 0.902484]\n",
      "epoch:24 step:23199 [D loss: 0.637613, acc.: 60.94%] [G loss: 0.882046]\n",
      "epoch:24 step:23200 [D loss: 0.623717, acc.: 68.75%] [G loss: 0.834027]\n",
      "##############\n",
      "[2.92262943 2.3507445  1.94343567 4.16227007 1.07480479 8.42524045\n",
      " 2.60859048 3.23197492 4.38399093 8.14868929]\n",
      "##########\n",
      "epoch:24 step:23201 [D loss: 0.690262, acc.: 54.69%] [G loss: 0.828124]\n",
      "epoch:24 step:23202 [D loss: 0.672578, acc.: 58.59%] [G loss: 0.871741]\n",
      "epoch:24 step:23203 [D loss: 0.665262, acc.: 57.81%] [G loss: 0.874141]\n",
      "epoch:24 step:23204 [D loss: 0.607832, acc.: 67.97%] [G loss: 0.834059]\n",
      "epoch:24 step:23205 [D loss: 0.635244, acc.: 67.97%] [G loss: 0.893239]\n",
      "epoch:24 step:23206 [D loss: 0.617424, acc.: 69.53%] [G loss: 0.905439]\n",
      "epoch:24 step:23207 [D loss: 0.676995, acc.: 55.47%] [G loss: 0.840838]\n",
      "epoch:24 step:23208 [D loss: 0.663538, acc.: 57.03%] [G loss: 0.858297]\n",
      "epoch:24 step:23209 [D loss: 0.680011, acc.: 56.25%] [G loss: 0.868255]\n",
      "epoch:24 step:23210 [D loss: 0.649266, acc.: 60.94%] [G loss: 0.848730]\n",
      "epoch:24 step:23211 [D loss: 0.655555, acc.: 60.94%] [G loss: 0.878968]\n",
      "epoch:24 step:23212 [D loss: 0.673066, acc.: 60.94%] [G loss: 0.877387]\n",
      "epoch:24 step:23213 [D loss: 0.646255, acc.: 61.72%] [G loss: 0.864553]\n",
      "epoch:24 step:23214 [D loss: 0.695853, acc.: 53.12%] [G loss: 0.929451]\n",
      "epoch:24 step:23215 [D loss: 0.658890, acc.: 60.16%] [G loss: 0.879767]\n",
      "epoch:24 step:23216 [D loss: 0.681514, acc.: 57.81%] [G loss: 0.888911]\n",
      "epoch:24 step:23217 [D loss: 0.624397, acc.: 64.84%] [G loss: 0.875653]\n",
      "epoch:24 step:23218 [D loss: 0.672526, acc.: 59.38%] [G loss: 0.872227]\n",
      "epoch:24 step:23219 [D loss: 0.671554, acc.: 58.59%] [G loss: 0.953051]\n",
      "epoch:24 step:23220 [D loss: 0.642756, acc.: 63.28%] [G loss: 0.949465]\n",
      "epoch:24 step:23221 [D loss: 0.628383, acc.: 64.84%] [G loss: 0.892554]\n",
      "epoch:24 step:23222 [D loss: 0.626841, acc.: 62.50%] [G loss: 0.903767]\n",
      "epoch:24 step:23223 [D loss: 0.703055, acc.: 54.69%] [G loss: 0.917351]\n",
      "epoch:24 step:23224 [D loss: 0.626657, acc.: 66.41%] [G loss: 0.873131]\n",
      "epoch:24 step:23225 [D loss: 0.677467, acc.: 53.12%] [G loss: 0.883836]\n",
      "epoch:24 step:23226 [D loss: 0.700180, acc.: 46.88%] [G loss: 0.897108]\n",
      "epoch:24 step:23227 [D loss: 0.675557, acc.: 58.59%] [G loss: 0.867116]\n",
      "epoch:24 step:23228 [D loss: 0.648521, acc.: 59.38%] [G loss: 0.884500]\n",
      "epoch:24 step:23229 [D loss: 0.641387, acc.: 59.38%] [G loss: 0.876400]\n",
      "epoch:24 step:23230 [D loss: 0.678216, acc.: 58.59%] [G loss: 0.900457]\n",
      "epoch:24 step:23231 [D loss: 0.643631, acc.: 64.06%] [G loss: 0.866503]\n",
      "epoch:24 step:23232 [D loss: 0.645946, acc.: 64.06%] [G loss: 0.860730]\n",
      "epoch:24 step:23233 [D loss: 0.650972, acc.: 61.72%] [G loss: 0.895782]\n",
      "epoch:24 step:23234 [D loss: 0.633681, acc.: 67.19%] [G loss: 0.947499]\n",
      "epoch:24 step:23235 [D loss: 0.654800, acc.: 58.59%] [G loss: 0.913269]\n",
      "epoch:24 step:23236 [D loss: 0.631529, acc.: 61.72%] [G loss: 0.880770]\n",
      "epoch:24 step:23237 [D loss: 0.634318, acc.: 64.06%] [G loss: 0.969577]\n",
      "epoch:24 step:23238 [D loss: 0.631438, acc.: 66.41%] [G loss: 0.963210]\n",
      "epoch:24 step:23239 [D loss: 0.638253, acc.: 65.62%] [G loss: 0.923884]\n",
      "epoch:24 step:23240 [D loss: 0.676979, acc.: 60.94%] [G loss: 0.875371]\n",
      "epoch:24 step:23241 [D loss: 0.627296, acc.: 63.28%] [G loss: 0.872160]\n",
      "epoch:24 step:23242 [D loss: 0.651387, acc.: 64.06%] [G loss: 0.825658]\n",
      "epoch:24 step:23243 [D loss: 0.674187, acc.: 55.47%] [G loss: 0.913126]\n",
      "epoch:24 step:23244 [D loss: 0.642433, acc.: 64.84%] [G loss: 0.895959]\n",
      "epoch:24 step:23245 [D loss: 0.642429, acc.: 64.84%] [G loss: 0.953072]\n",
      "epoch:24 step:23246 [D loss: 0.677916, acc.: 53.12%] [G loss: 0.995006]\n",
      "epoch:24 step:23247 [D loss: 0.672321, acc.: 58.59%] [G loss: 0.915340]\n",
      "epoch:24 step:23248 [D loss: 0.611343, acc.: 67.19%] [G loss: 0.905703]\n",
      "epoch:24 step:23249 [D loss: 0.680998, acc.: 59.38%] [G loss: 0.883129]\n",
      "epoch:24 step:23250 [D loss: 0.677816, acc.: 63.28%] [G loss: 0.858318]\n",
      "epoch:24 step:23251 [D loss: 0.634225, acc.: 64.06%] [G loss: 0.793347]\n",
      "epoch:24 step:23252 [D loss: 0.615437, acc.: 65.62%] [G loss: 0.855471]\n",
      "epoch:24 step:23253 [D loss: 0.662586, acc.: 59.38%] [G loss: 0.882417]\n",
      "epoch:24 step:23254 [D loss: 0.655329, acc.: 63.28%] [G loss: 0.897116]\n",
      "epoch:24 step:23255 [D loss: 0.668032, acc.: 57.81%] [G loss: 0.936918]\n",
      "epoch:24 step:23256 [D loss: 0.622478, acc.: 65.62%] [G loss: 0.955759]\n",
      "epoch:24 step:23257 [D loss: 0.621224, acc.: 70.31%] [G loss: 0.959267]\n",
      "epoch:24 step:23258 [D loss: 0.663941, acc.: 59.38%] [G loss: 0.905016]\n",
      "epoch:24 step:23259 [D loss: 0.641926, acc.: 64.06%] [G loss: 0.960264]\n",
      "epoch:24 step:23260 [D loss: 0.624685, acc.: 64.06%] [G loss: 0.937519]\n",
      "epoch:24 step:23261 [D loss: 0.678358, acc.: 55.47%] [G loss: 0.896446]\n",
      "epoch:24 step:23262 [D loss: 0.582070, acc.: 75.78%] [G loss: 0.984302]\n",
      "epoch:24 step:23263 [D loss: 0.648971, acc.: 58.59%] [G loss: 0.978534]\n",
      "epoch:24 step:23264 [D loss: 0.663082, acc.: 60.94%] [G loss: 0.920074]\n",
      "epoch:24 step:23265 [D loss: 0.652852, acc.: 57.81%] [G loss: 0.891633]\n",
      "epoch:24 step:23266 [D loss: 0.645294, acc.: 60.94%] [G loss: 0.905203]\n",
      "epoch:24 step:23267 [D loss: 0.627036, acc.: 64.06%] [G loss: 0.899030]\n",
      "epoch:24 step:23268 [D loss: 0.671138, acc.: 57.81%] [G loss: 0.901087]\n",
      "epoch:24 step:23269 [D loss: 0.705323, acc.: 52.34%] [G loss: 0.894107]\n",
      "epoch:24 step:23270 [D loss: 0.633823, acc.: 61.72%] [G loss: 0.886149]\n",
      "epoch:24 step:23271 [D loss: 0.695733, acc.: 57.03%] [G loss: 0.900614]\n",
      "epoch:24 step:23272 [D loss: 0.654316, acc.: 63.28%] [G loss: 0.930651]\n",
      "epoch:24 step:23273 [D loss: 0.692015, acc.: 56.25%] [G loss: 0.908188]\n",
      "epoch:24 step:23274 [D loss: 0.682967, acc.: 53.91%] [G loss: 0.905940]\n",
      "epoch:24 step:23275 [D loss: 0.651694, acc.: 62.50%] [G loss: 0.913429]\n",
      "epoch:24 step:23276 [D loss: 0.649682, acc.: 63.28%] [G loss: 0.885455]\n",
      "epoch:24 step:23277 [D loss: 0.632560, acc.: 59.38%] [G loss: 0.935684]\n",
      "epoch:24 step:23278 [D loss: 0.660799, acc.: 61.72%] [G loss: 0.854476]\n",
      "epoch:24 step:23279 [D loss: 0.661431, acc.: 57.03%] [G loss: 0.929219]\n",
      "epoch:24 step:23280 [D loss: 0.624156, acc.: 67.19%] [G loss: 0.951511]\n",
      "epoch:24 step:23281 [D loss: 0.644161, acc.: 62.50%] [G loss: 0.946479]\n",
      "epoch:24 step:23282 [D loss: 0.629858, acc.: 68.75%] [G loss: 0.891911]\n",
      "epoch:24 step:23283 [D loss: 0.656044, acc.: 61.72%] [G loss: 0.872389]\n",
      "epoch:24 step:23284 [D loss: 0.671612, acc.: 56.25%] [G loss: 0.922645]\n",
      "epoch:24 step:23285 [D loss: 0.644577, acc.: 61.72%] [G loss: 0.897668]\n",
      "epoch:24 step:23286 [D loss: 0.626697, acc.: 63.28%] [G loss: 0.880698]\n",
      "epoch:24 step:23287 [D loss: 0.644913, acc.: 64.84%] [G loss: 0.853088]\n",
      "epoch:24 step:23288 [D loss: 0.632770, acc.: 64.84%] [G loss: 0.901624]\n",
      "epoch:24 step:23289 [D loss: 0.653296, acc.: 59.38%] [G loss: 0.926416]\n",
      "epoch:24 step:23290 [D loss: 0.674994, acc.: 58.59%] [G loss: 0.913990]\n",
      "epoch:24 step:23291 [D loss: 0.633575, acc.: 65.62%] [G loss: 0.867587]\n",
      "epoch:24 step:23292 [D loss: 0.684302, acc.: 57.81%] [G loss: 0.861756]\n",
      "epoch:24 step:23293 [D loss: 0.631193, acc.: 67.97%] [G loss: 0.866788]\n",
      "epoch:24 step:23294 [D loss: 0.639968, acc.: 63.28%] [G loss: 0.882016]\n",
      "epoch:24 step:23295 [D loss: 0.678250, acc.: 50.78%] [G loss: 0.832435]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:23296 [D loss: 0.661629, acc.: 62.50%] [G loss: 0.910169]\n",
      "epoch:24 step:23297 [D loss: 0.613619, acc.: 62.50%] [G loss: 0.948696]\n",
      "epoch:24 step:23298 [D loss: 0.648589, acc.: 62.50%] [G loss: 0.861007]\n",
      "epoch:24 step:23299 [D loss: 0.626784, acc.: 62.50%] [G loss: 0.904240]\n",
      "epoch:24 step:23300 [D loss: 0.634221, acc.: 65.62%] [G loss: 0.909599]\n",
      "epoch:24 step:23301 [D loss: 0.664311, acc.: 56.25%] [G loss: 0.919918]\n",
      "epoch:24 step:23302 [D loss: 0.621020, acc.: 68.75%] [G loss: 0.942901]\n",
      "epoch:24 step:23303 [D loss: 0.620497, acc.: 65.62%] [G loss: 0.928393]\n",
      "epoch:24 step:23304 [D loss: 0.598779, acc.: 71.09%] [G loss: 0.926490]\n",
      "epoch:24 step:23305 [D loss: 0.751910, acc.: 48.44%] [G loss: 0.910854]\n",
      "epoch:24 step:23306 [D loss: 0.668994, acc.: 54.69%] [G loss: 0.945541]\n",
      "epoch:24 step:23307 [D loss: 0.652886, acc.: 62.50%] [G loss: 0.882249]\n",
      "epoch:24 step:23308 [D loss: 0.659011, acc.: 61.72%] [G loss: 0.907948]\n",
      "epoch:24 step:23309 [D loss: 0.625198, acc.: 66.41%] [G loss: 0.904927]\n",
      "epoch:24 step:23310 [D loss: 0.619185, acc.: 65.62%] [G loss: 0.910107]\n",
      "epoch:24 step:23311 [D loss: 0.685801, acc.: 52.34%] [G loss: 0.907459]\n",
      "epoch:24 step:23312 [D loss: 0.644706, acc.: 62.50%] [G loss: 0.904663]\n",
      "epoch:24 step:23313 [D loss: 0.638036, acc.: 59.38%] [G loss: 0.883707]\n",
      "epoch:24 step:23314 [D loss: 0.633630, acc.: 64.84%] [G loss: 0.944900]\n",
      "epoch:24 step:23315 [D loss: 0.666219, acc.: 56.25%] [G loss: 0.909642]\n",
      "epoch:24 step:23316 [D loss: 0.684929, acc.: 56.25%] [G loss: 0.889441]\n",
      "epoch:24 step:23317 [D loss: 0.655701, acc.: 64.84%] [G loss: 0.827414]\n",
      "epoch:24 step:23318 [D loss: 0.673879, acc.: 52.34%] [G loss: 0.867574]\n",
      "epoch:24 step:23319 [D loss: 0.669277, acc.: 53.91%] [G loss: 0.836771]\n",
      "epoch:24 step:23320 [D loss: 0.665688, acc.: 55.47%] [G loss: 0.857935]\n",
      "epoch:24 step:23321 [D loss: 0.642766, acc.: 62.50%] [G loss: 0.847352]\n",
      "epoch:24 step:23322 [D loss: 0.669719, acc.: 59.38%] [G loss: 0.847150]\n",
      "epoch:24 step:23323 [D loss: 0.653520, acc.: 62.50%] [G loss: 0.889239]\n",
      "epoch:24 step:23324 [D loss: 0.647217, acc.: 61.72%] [G loss: 0.921177]\n",
      "epoch:24 step:23325 [D loss: 0.666297, acc.: 59.38%] [G loss: 0.862398]\n",
      "epoch:24 step:23326 [D loss: 0.667313, acc.: 57.81%] [G loss: 0.892030]\n",
      "epoch:24 step:23327 [D loss: 0.653148, acc.: 61.72%] [G loss: 0.884805]\n",
      "epoch:24 step:23328 [D loss: 0.643647, acc.: 60.16%] [G loss: 0.996374]\n",
      "epoch:24 step:23329 [D loss: 0.631594, acc.: 64.06%] [G loss: 0.879664]\n",
      "epoch:24 step:23330 [D loss: 0.682875, acc.: 55.47%] [G loss: 0.932077]\n",
      "epoch:24 step:23331 [D loss: 0.657144, acc.: 60.16%] [G loss: 0.855429]\n",
      "epoch:24 step:23332 [D loss: 0.628575, acc.: 65.62%] [G loss: 0.839192]\n",
      "epoch:24 step:23333 [D loss: 0.697803, acc.: 55.47%] [G loss: 0.874666]\n",
      "epoch:24 step:23334 [D loss: 0.676232, acc.: 58.59%] [G loss: 0.908374]\n",
      "epoch:24 step:23335 [D loss: 0.630008, acc.: 65.62%] [G loss: 0.865108]\n",
      "epoch:24 step:23336 [D loss: 0.682137, acc.: 54.69%] [G loss: 0.907278]\n",
      "epoch:24 step:23337 [D loss: 0.658325, acc.: 67.97%] [G loss: 0.926729]\n",
      "epoch:24 step:23338 [D loss: 0.634483, acc.: 61.72%] [G loss: 0.900777]\n",
      "epoch:24 step:23339 [D loss: 0.649636, acc.: 66.41%] [G loss: 0.855969]\n",
      "epoch:24 step:23340 [D loss: 0.640159, acc.: 63.28%] [G loss: 0.874872]\n",
      "epoch:24 step:23341 [D loss: 0.648928, acc.: 58.59%] [G loss: 0.955052]\n",
      "epoch:24 step:23342 [D loss: 0.618552, acc.: 71.09%] [G loss: 0.916310]\n",
      "epoch:24 step:23343 [D loss: 0.687263, acc.: 56.25%] [G loss: 0.911903]\n",
      "epoch:24 step:23344 [D loss: 0.656123, acc.: 57.03%] [G loss: 0.885308]\n",
      "epoch:24 step:23345 [D loss: 0.627441, acc.: 63.28%] [G loss: 0.907665]\n",
      "epoch:24 step:23346 [D loss: 0.651363, acc.: 61.72%] [G loss: 0.919312]\n",
      "epoch:24 step:23347 [D loss: 0.709206, acc.: 58.59%] [G loss: 0.868068]\n",
      "epoch:24 step:23348 [D loss: 0.658467, acc.: 57.03%] [G loss: 0.863926]\n",
      "epoch:24 step:23349 [D loss: 0.604318, acc.: 67.97%] [G loss: 0.837030]\n",
      "epoch:24 step:23350 [D loss: 0.626556, acc.: 69.53%] [G loss: 0.892177]\n",
      "epoch:24 step:23351 [D loss: 0.657010, acc.: 60.94%] [G loss: 0.850422]\n",
      "epoch:24 step:23352 [D loss: 0.683793, acc.: 57.81%] [G loss: 0.848618]\n",
      "epoch:24 step:23353 [D loss: 0.657292, acc.: 51.56%] [G loss: 0.880082]\n",
      "epoch:24 step:23354 [D loss: 0.621841, acc.: 64.06%] [G loss: 0.836727]\n",
      "epoch:24 step:23355 [D loss: 0.683773, acc.: 57.03%] [G loss: 0.895133]\n",
      "epoch:24 step:23356 [D loss: 0.664272, acc.: 59.38%] [G loss: 0.791573]\n",
      "epoch:24 step:23357 [D loss: 0.648623, acc.: 58.59%] [G loss: 0.938221]\n",
      "epoch:24 step:23358 [D loss: 0.652956, acc.: 62.50%] [G loss: 0.870483]\n",
      "epoch:24 step:23359 [D loss: 0.648215, acc.: 62.50%] [G loss: 0.919688]\n",
      "epoch:24 step:23360 [D loss: 0.632987, acc.: 65.62%] [G loss: 0.942878]\n",
      "epoch:24 step:23361 [D loss: 0.658405, acc.: 58.59%] [G loss: 0.903073]\n",
      "epoch:24 step:23362 [D loss: 0.658178, acc.: 57.81%] [G loss: 0.888849]\n",
      "epoch:24 step:23363 [D loss: 0.677630, acc.: 57.03%] [G loss: 0.896551]\n",
      "epoch:24 step:23364 [D loss: 0.642432, acc.: 68.75%] [G loss: 0.887075]\n",
      "epoch:24 step:23365 [D loss: 0.626523, acc.: 63.28%] [G loss: 0.927315]\n",
      "epoch:24 step:23366 [D loss: 0.686499, acc.: 50.00%] [G loss: 0.927415]\n",
      "epoch:24 step:23367 [D loss: 0.669970, acc.: 57.03%] [G loss: 0.896642]\n",
      "epoch:24 step:23368 [D loss: 0.635088, acc.: 63.28%] [G loss: 0.917159]\n",
      "epoch:24 step:23369 [D loss: 0.666639, acc.: 63.28%] [G loss: 0.852898]\n",
      "epoch:24 step:23370 [D loss: 0.653384, acc.: 60.16%] [G loss: 0.884724]\n",
      "epoch:24 step:23371 [D loss: 0.618654, acc.: 66.41%] [G loss: 0.914591]\n",
      "epoch:24 step:23372 [D loss: 0.666547, acc.: 59.38%] [G loss: 0.862389]\n",
      "epoch:24 step:23373 [D loss: 0.649376, acc.: 59.38%] [G loss: 0.867953]\n",
      "epoch:24 step:23374 [D loss: 0.676810, acc.: 60.94%] [G loss: 0.868093]\n",
      "epoch:24 step:23375 [D loss: 0.659433, acc.: 60.94%] [G loss: 0.923496]\n",
      "epoch:24 step:23376 [D loss: 0.641103, acc.: 68.75%] [G loss: 0.873183]\n",
      "epoch:24 step:23377 [D loss: 0.684070, acc.: 59.38%] [G loss: 0.882104]\n",
      "epoch:24 step:23378 [D loss: 0.650450, acc.: 60.16%] [G loss: 0.858428]\n",
      "epoch:24 step:23379 [D loss: 0.683700, acc.: 50.00%] [G loss: 0.913259]\n",
      "epoch:24 step:23380 [D loss: 0.655783, acc.: 61.72%] [G loss: 0.911266]\n",
      "epoch:24 step:23381 [D loss: 0.630951, acc.: 59.38%] [G loss: 0.931587]\n",
      "epoch:24 step:23382 [D loss: 0.665458, acc.: 58.59%] [G loss: 0.893331]\n",
      "epoch:24 step:23383 [D loss: 0.669859, acc.: 57.03%] [G loss: 0.924215]\n",
      "epoch:24 step:23384 [D loss: 0.643608, acc.: 60.16%] [G loss: 0.960657]\n",
      "epoch:24 step:23385 [D loss: 0.640815, acc.: 66.41%] [G loss: 0.922811]\n",
      "epoch:24 step:23386 [D loss: 0.703641, acc.: 49.22%] [G loss: 0.869904]\n",
      "epoch:24 step:23387 [D loss: 0.664721, acc.: 55.47%] [G loss: 0.844437]\n",
      "epoch:24 step:23388 [D loss: 0.622463, acc.: 63.28%] [G loss: 0.905882]\n",
      "epoch:24 step:23389 [D loss: 0.688702, acc.: 53.91%] [G loss: 0.876663]\n",
      "epoch:24 step:23390 [D loss: 0.700570, acc.: 55.47%] [G loss: 0.877992]\n",
      "epoch:24 step:23391 [D loss: 0.651035, acc.: 66.41%] [G loss: 0.923238]\n",
      "epoch:24 step:23392 [D loss: 0.615311, acc.: 71.88%] [G loss: 0.883518]\n",
      "epoch:24 step:23393 [D loss: 0.685762, acc.: 57.81%] [G loss: 0.909056]\n",
      "epoch:24 step:23394 [D loss: 0.647738, acc.: 60.94%] [G loss: 0.908128]\n",
      "epoch:24 step:23395 [D loss: 0.685618, acc.: 55.47%] [G loss: 0.955968]\n",
      "epoch:24 step:23396 [D loss: 0.704843, acc.: 50.78%] [G loss: 0.939299]\n",
      "epoch:24 step:23397 [D loss: 0.687830, acc.: 50.78%] [G loss: 0.888351]\n",
      "epoch:24 step:23398 [D loss: 0.662408, acc.: 60.16%] [G loss: 0.897679]\n",
      "epoch:24 step:23399 [D loss: 0.627481, acc.: 66.41%] [G loss: 0.905999]\n",
      "epoch:24 step:23400 [D loss: 0.663064, acc.: 57.03%] [G loss: 0.911737]\n",
      "##############\n",
      "[2.88229977 2.31809114 2.22949058 3.60410428 1.02477775 7.08236575\n",
      " 2.68500905 3.16715028 4.32305406 8.14868929]\n",
      "##########\n",
      "epoch:24 step:23401 [D loss: 0.657353, acc.: 61.72%] [G loss: 0.856690]\n",
      "epoch:24 step:23402 [D loss: 0.631745, acc.: 60.16%] [G loss: 0.904879]\n",
      "epoch:24 step:23403 [D loss: 0.639618, acc.: 64.06%] [G loss: 0.902442]\n",
      "epoch:24 step:23404 [D loss: 0.689066, acc.: 56.25%] [G loss: 0.886911]\n",
      "epoch:24 step:23405 [D loss: 0.677679, acc.: 51.56%] [G loss: 0.908000]\n",
      "epoch:24 step:23406 [D loss: 0.660927, acc.: 60.94%] [G loss: 0.863782]\n",
      "epoch:24 step:23407 [D loss: 0.642619, acc.: 67.97%] [G loss: 0.877004]\n",
      "epoch:24 step:23408 [D loss: 0.612606, acc.: 66.41%] [G loss: 0.876534]\n",
      "epoch:24 step:23409 [D loss: 0.682653, acc.: 56.25%] [G loss: 0.909917]\n",
      "epoch:24 step:23410 [D loss: 0.695535, acc.: 56.25%] [G loss: 0.878399]\n",
      "epoch:24 step:23411 [D loss: 0.651582, acc.: 61.72%] [G loss: 0.867245]\n",
      "epoch:24 step:23412 [D loss: 0.670312, acc.: 57.81%] [G loss: 0.893659]\n",
      "epoch:24 step:23413 [D loss: 0.669620, acc.: 60.94%] [G loss: 0.882329]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:24 step:23414 [D loss: 0.646889, acc.: 60.16%] [G loss: 0.849913]\n",
      "epoch:24 step:23415 [D loss: 0.663058, acc.: 60.94%] [G loss: 0.936999]\n",
      "epoch:24 step:23416 [D loss: 0.665774, acc.: 55.47%] [G loss: 0.946164]\n",
      "epoch:24 step:23417 [D loss: 0.663065, acc.: 59.38%] [G loss: 0.987537]\n",
      "epoch:24 step:23418 [D loss: 0.656141, acc.: 59.38%] [G loss: 0.919186]\n",
      "epoch:24 step:23419 [D loss: 0.665249, acc.: 58.59%] [G loss: 0.865795]\n",
      "epoch:24 step:23420 [D loss: 0.663143, acc.: 60.16%] [G loss: 0.900884]\n",
      "epoch:24 step:23421 [D loss: 0.653445, acc.: 62.50%] [G loss: 0.876680]\n",
      "epoch:24 step:23422 [D loss: 0.643461, acc.: 60.94%] [G loss: 0.842192]\n",
      "epoch:24 step:23423 [D loss: 0.656369, acc.: 56.25%] [G loss: 0.924442]\n",
      "epoch:24 step:23424 [D loss: 0.683826, acc.: 54.69%] [G loss: 0.850603]\n",
      "epoch:24 step:23425 [D loss: 0.662435, acc.: 63.28%] [G loss: 0.936949]\n",
      "epoch:25 step:23426 [D loss: 0.684853, acc.: 54.69%] [G loss: 0.851604]\n",
      "epoch:25 step:23427 [D loss: 0.681787, acc.: 54.69%] [G loss: 0.849089]\n",
      "epoch:25 step:23428 [D loss: 0.642046, acc.: 62.50%] [G loss: 0.896484]\n",
      "epoch:25 step:23429 [D loss: 0.682565, acc.: 57.81%] [G loss: 0.936931]\n",
      "epoch:25 step:23430 [D loss: 0.658049, acc.: 57.81%] [G loss: 0.959036]\n",
      "epoch:25 step:23431 [D loss: 0.645135, acc.: 64.84%] [G loss: 0.922936]\n",
      "epoch:25 step:23432 [D loss: 0.696503, acc.: 53.91%] [G loss: 0.909863]\n",
      "epoch:25 step:23433 [D loss: 0.705087, acc.: 56.25%] [G loss: 0.928886]\n",
      "epoch:25 step:23434 [D loss: 0.702699, acc.: 51.56%] [G loss: 0.858713]\n",
      "epoch:25 step:23435 [D loss: 0.640325, acc.: 63.28%] [G loss: 0.813302]\n",
      "epoch:25 step:23436 [D loss: 0.666696, acc.: 56.25%] [G loss: 0.846091]\n",
      "epoch:25 step:23437 [D loss: 0.649269, acc.: 58.59%] [G loss: 0.850383]\n",
      "epoch:25 step:23438 [D loss: 0.605886, acc.: 70.31%] [G loss: 0.900432]\n",
      "epoch:25 step:23439 [D loss: 0.687163, acc.: 57.03%] [G loss: 0.882590]\n",
      "epoch:25 step:23440 [D loss: 0.651854, acc.: 60.16%] [G loss: 0.888164]\n",
      "epoch:25 step:23441 [D loss: 0.639291, acc.: 66.41%] [G loss: 0.792917]\n",
      "epoch:25 step:23442 [D loss: 0.646986, acc.: 63.28%] [G loss: 0.890881]\n",
      "epoch:25 step:23443 [D loss: 0.675221, acc.: 55.47%] [G loss: 0.900289]\n",
      "epoch:25 step:23444 [D loss: 0.647515, acc.: 63.28%] [G loss: 0.893561]\n",
      "epoch:25 step:23445 [D loss: 0.672464, acc.: 59.38%] [G loss: 0.980851]\n",
      "epoch:25 step:23446 [D loss: 0.629772, acc.: 69.53%] [G loss: 0.917465]\n",
      "epoch:25 step:23447 [D loss: 0.654107, acc.: 60.94%] [G loss: 0.959376]\n",
      "epoch:25 step:23448 [D loss: 0.643351, acc.: 60.94%] [G loss: 0.880234]\n",
      "epoch:25 step:23449 [D loss: 0.671055, acc.: 54.69%] [G loss: 0.875638]\n",
      "epoch:25 step:23450 [D loss: 0.674244, acc.: 60.94%] [G loss: 0.903370]\n",
      "epoch:25 step:23451 [D loss: 0.621115, acc.: 67.97%] [G loss: 0.921728]\n",
      "epoch:25 step:23452 [D loss: 0.658352, acc.: 53.12%] [G loss: 0.857318]\n",
      "epoch:25 step:23453 [D loss: 0.619917, acc.: 64.84%] [G loss: 0.877977]\n",
      "epoch:25 step:23454 [D loss: 0.679553, acc.: 59.38%] [G loss: 0.791982]\n",
      "epoch:25 step:23455 [D loss: 0.696881, acc.: 57.81%] [G loss: 0.891525]\n",
      "epoch:25 step:23456 [D loss: 0.674711, acc.: 53.91%] [G loss: 0.820330]\n",
      "epoch:25 step:23457 [D loss: 0.642815, acc.: 68.75%] [G loss: 0.927053]\n",
      "epoch:25 step:23458 [D loss: 0.672469, acc.: 57.81%] [G loss: 0.895832]\n",
      "epoch:25 step:23459 [D loss: 0.681862, acc.: 60.16%] [G loss: 0.893269]\n",
      "epoch:25 step:23460 [D loss: 0.643708, acc.: 66.41%] [G loss: 0.837848]\n",
      "epoch:25 step:23461 [D loss: 0.626167, acc.: 67.19%] [G loss: 0.919014]\n",
      "epoch:25 step:23462 [D loss: 0.656750, acc.: 64.06%] [G loss: 0.933035]\n",
      "epoch:25 step:23463 [D loss: 0.688233, acc.: 59.38%] [G loss: 0.906872]\n",
      "epoch:25 step:23464 [D loss: 0.656965, acc.: 62.50%] [G loss: 0.889782]\n",
      "epoch:25 step:23465 [D loss: 0.647094, acc.: 60.16%] [G loss: 0.911307]\n",
      "epoch:25 step:23466 [D loss: 0.663247, acc.: 59.38%] [G loss: 0.858991]\n",
      "epoch:25 step:23467 [D loss: 0.657639, acc.: 61.72%] [G loss: 0.851557]\n",
      "epoch:25 step:23468 [D loss: 0.664660, acc.: 58.59%] [G loss: 0.894140]\n",
      "epoch:25 step:23469 [D loss: 0.658153, acc.: 59.38%] [G loss: 0.833137]\n",
      "epoch:25 step:23470 [D loss: 0.649835, acc.: 60.94%] [G loss: 0.902645]\n",
      "epoch:25 step:23471 [D loss: 0.629052, acc.: 65.62%] [G loss: 0.937909]\n",
      "epoch:25 step:23472 [D loss: 0.717214, acc.: 43.75%] [G loss: 0.880905]\n",
      "epoch:25 step:23473 [D loss: 0.682733, acc.: 55.47%] [G loss: 0.864299]\n",
      "epoch:25 step:23474 [D loss: 0.659006, acc.: 55.47%] [G loss: 0.918941]\n",
      "epoch:25 step:23475 [D loss: 0.632135, acc.: 62.50%] [G loss: 0.908642]\n",
      "epoch:25 step:23476 [D loss: 0.624731, acc.: 64.84%] [G loss: 0.899714]\n",
      "epoch:25 step:23477 [D loss: 0.650045, acc.: 59.38%] [G loss: 0.928788]\n",
      "epoch:25 step:23478 [D loss: 0.674205, acc.: 57.81%] [G loss: 0.916312]\n",
      "epoch:25 step:23479 [D loss: 0.660920, acc.: 61.72%] [G loss: 0.878341]\n",
      "epoch:25 step:23480 [D loss: 0.671655, acc.: 55.47%] [G loss: 0.911560]\n",
      "epoch:25 step:23481 [D loss: 0.662086, acc.: 56.25%] [G loss: 0.984550]\n",
      "epoch:25 step:23482 [D loss: 0.674860, acc.: 56.25%] [G loss: 0.987989]\n",
      "epoch:25 step:23483 [D loss: 0.651521, acc.: 64.06%] [G loss: 0.910722]\n",
      "epoch:25 step:23484 [D loss: 0.642871, acc.: 60.16%] [G loss: 0.948591]\n",
      "epoch:25 step:23485 [D loss: 0.632389, acc.: 58.59%] [G loss: 0.956666]\n",
      "epoch:25 step:23486 [D loss: 0.624082, acc.: 67.97%] [G loss: 0.896822]\n",
      "epoch:25 step:23487 [D loss: 0.632886, acc.: 64.84%] [G loss: 0.953945]\n",
      "epoch:25 step:23488 [D loss: 0.653132, acc.: 65.62%] [G loss: 0.924958]\n",
      "epoch:25 step:23489 [D loss: 0.625913, acc.: 62.50%] [G loss: 0.903024]\n",
      "epoch:25 step:23490 [D loss: 0.662319, acc.: 59.38%] [G loss: 0.863805]\n",
      "epoch:25 step:23491 [D loss: 0.659678, acc.: 64.84%] [G loss: 0.920650]\n",
      "epoch:25 step:23492 [D loss: 0.666225, acc.: 55.47%] [G loss: 0.898543]\n",
      "epoch:25 step:23493 [D loss: 0.669594, acc.: 57.03%] [G loss: 0.949611]\n",
      "epoch:25 step:23494 [D loss: 0.615194, acc.: 67.97%] [G loss: 0.901267]\n",
      "epoch:25 step:23495 [D loss: 0.653508, acc.: 61.72%] [G loss: 0.981997]\n",
      "epoch:25 step:23496 [D loss: 0.620285, acc.: 64.84%] [G loss: 0.931727]\n",
      "epoch:25 step:23497 [D loss: 0.667111, acc.: 61.72%] [G loss: 0.915503]\n",
      "epoch:25 step:23498 [D loss: 0.613899, acc.: 64.84%] [G loss: 0.879161]\n",
      "epoch:25 step:23499 [D loss: 0.624051, acc.: 64.06%] [G loss: 0.881398]\n",
      "epoch:25 step:23500 [D loss: 0.641112, acc.: 59.38%] [G loss: 0.864173]\n",
      "epoch:25 step:23501 [D loss: 0.627233, acc.: 66.41%] [G loss: 0.903891]\n",
      "epoch:25 step:23502 [D loss: 0.667313, acc.: 58.59%] [G loss: 0.949557]\n",
      "epoch:25 step:23503 [D loss: 0.635925, acc.: 65.62%] [G loss: 0.929723]\n",
      "epoch:25 step:23504 [D loss: 0.661114, acc.: 64.84%] [G loss: 1.012409]\n",
      "epoch:25 step:23505 [D loss: 0.663504, acc.: 58.59%] [G loss: 0.942690]\n",
      "epoch:25 step:23506 [D loss: 0.641719, acc.: 68.75%] [G loss: 0.977655]\n",
      "epoch:25 step:23507 [D loss: 0.645154, acc.: 57.81%] [G loss: 0.970092]\n",
      "epoch:25 step:23508 [D loss: 0.653673, acc.: 60.94%] [G loss: 0.940055]\n",
      "epoch:25 step:23509 [D loss: 0.634591, acc.: 57.81%] [G loss: 0.929329]\n",
      "epoch:25 step:23510 [D loss: 0.640561, acc.: 60.16%] [G loss: 0.890292]\n",
      "epoch:25 step:23511 [D loss: 0.670390, acc.: 60.16%] [G loss: 0.903329]\n",
      "epoch:25 step:23512 [D loss: 0.664416, acc.: 56.25%] [G loss: 0.918803]\n",
      "epoch:25 step:23513 [D loss: 0.672453, acc.: 60.16%] [G loss: 0.913628]\n",
      "epoch:25 step:23514 [D loss: 0.652485, acc.: 65.62%] [G loss: 0.922982]\n",
      "epoch:25 step:23515 [D loss: 0.677008, acc.: 57.81%] [G loss: 0.867695]\n",
      "epoch:25 step:23516 [D loss: 0.664152, acc.: 64.84%] [G loss: 0.873216]\n",
      "epoch:25 step:23517 [D loss: 0.642012, acc.: 60.94%] [G loss: 0.892252]\n",
      "epoch:25 step:23518 [D loss: 0.654776, acc.: 61.72%] [G loss: 0.896014]\n",
      "epoch:25 step:23519 [D loss: 0.661713, acc.: 60.94%] [G loss: 0.905716]\n",
      "epoch:25 step:23520 [D loss: 0.670411, acc.: 56.25%] [G loss: 0.905585]\n",
      "epoch:25 step:23521 [D loss: 0.637315, acc.: 66.41%] [G loss: 0.945845]\n",
      "epoch:25 step:23522 [D loss: 0.629083, acc.: 65.62%] [G loss: 0.917516]\n",
      "epoch:25 step:23523 [D loss: 0.654982, acc.: 65.62%] [G loss: 0.885724]\n",
      "epoch:25 step:23524 [D loss: 0.671756, acc.: 60.94%] [G loss: 0.955471]\n",
      "epoch:25 step:23525 [D loss: 0.665407, acc.: 56.25%] [G loss: 0.899849]\n",
      "epoch:25 step:23526 [D loss: 0.658314, acc.: 62.50%] [G loss: 0.908526]\n",
      "epoch:25 step:23527 [D loss: 0.707810, acc.: 53.91%] [G loss: 0.842869]\n",
      "epoch:25 step:23528 [D loss: 0.656924, acc.: 60.16%] [G loss: 0.856250]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23529 [D loss: 0.626695, acc.: 64.84%] [G loss: 0.909314]\n",
      "epoch:25 step:23530 [D loss: 0.598921, acc.: 68.75%] [G loss: 0.929704]\n",
      "epoch:25 step:23531 [D loss: 0.655540, acc.: 63.28%] [G loss: 0.866804]\n",
      "epoch:25 step:23532 [D loss: 0.632356, acc.: 64.84%] [G loss: 0.912885]\n",
      "epoch:25 step:23533 [D loss: 0.681231, acc.: 57.03%] [G loss: 0.891783]\n",
      "epoch:25 step:23534 [D loss: 0.630067, acc.: 63.28%] [G loss: 0.885380]\n",
      "epoch:25 step:23535 [D loss: 0.659482, acc.: 56.25%] [G loss: 0.937098]\n",
      "epoch:25 step:23536 [D loss: 0.663875, acc.: 60.94%] [G loss: 0.900384]\n",
      "epoch:25 step:23537 [D loss: 0.674116, acc.: 58.59%] [G loss: 0.922416]\n",
      "epoch:25 step:23538 [D loss: 0.618525, acc.: 60.94%] [G loss: 0.945240]\n",
      "epoch:25 step:23539 [D loss: 0.661705, acc.: 56.25%] [G loss: 0.888693]\n",
      "epoch:25 step:23540 [D loss: 0.670174, acc.: 60.16%] [G loss: 0.886841]\n",
      "epoch:25 step:23541 [D loss: 0.654780, acc.: 57.81%] [G loss: 0.850093]\n",
      "epoch:25 step:23542 [D loss: 0.679329, acc.: 57.03%] [G loss: 0.824215]\n",
      "epoch:25 step:23543 [D loss: 0.665464, acc.: 60.16%] [G loss: 0.888502]\n",
      "epoch:25 step:23544 [D loss: 0.661764, acc.: 63.28%] [G loss: 0.887927]\n",
      "epoch:25 step:23545 [D loss: 0.663690, acc.: 55.47%] [G loss: 0.975750]\n",
      "epoch:25 step:23546 [D loss: 0.620694, acc.: 63.28%] [G loss: 0.878854]\n",
      "epoch:25 step:23547 [D loss: 0.707115, acc.: 45.31%] [G loss: 0.876292]\n",
      "epoch:25 step:23548 [D loss: 0.663156, acc.: 57.03%] [G loss: 0.900559]\n",
      "epoch:25 step:23549 [D loss: 0.666481, acc.: 58.59%] [G loss: 0.807220]\n",
      "epoch:25 step:23550 [D loss: 0.671180, acc.: 56.25%] [G loss: 0.831613]\n",
      "epoch:25 step:23551 [D loss: 0.652379, acc.: 60.16%] [G loss: 0.879065]\n",
      "epoch:25 step:23552 [D loss: 0.617596, acc.: 67.19%] [G loss: 0.915846]\n",
      "epoch:25 step:23553 [D loss: 0.657762, acc.: 57.81%] [G loss: 0.909180]\n",
      "epoch:25 step:23554 [D loss: 0.614933, acc.: 71.88%] [G loss: 0.939050]\n",
      "epoch:25 step:23555 [D loss: 0.661662, acc.: 60.16%] [G loss: 0.899497]\n",
      "epoch:25 step:23556 [D loss: 0.642806, acc.: 60.94%] [G loss: 0.910263]\n",
      "epoch:25 step:23557 [D loss: 0.686935, acc.: 54.69%] [G loss: 0.910235]\n",
      "epoch:25 step:23558 [D loss: 0.669816, acc.: 62.50%] [G loss: 0.939858]\n",
      "epoch:25 step:23559 [D loss: 0.673677, acc.: 50.78%] [G loss: 0.931970]\n",
      "epoch:25 step:23560 [D loss: 0.687232, acc.: 56.25%] [G loss: 0.967424]\n",
      "epoch:25 step:23561 [D loss: 0.674618, acc.: 60.94%] [G loss: 0.895524]\n",
      "epoch:25 step:23562 [D loss: 0.649369, acc.: 57.03%] [G loss: 0.879711]\n",
      "epoch:25 step:23563 [D loss: 0.626232, acc.: 67.19%] [G loss: 0.910675]\n",
      "epoch:25 step:23564 [D loss: 0.680539, acc.: 56.25%] [G loss: 0.940223]\n",
      "epoch:25 step:23565 [D loss: 0.665320, acc.: 58.59%] [G loss: 0.869898]\n",
      "epoch:25 step:23566 [D loss: 0.698166, acc.: 52.34%] [G loss: 0.921745]\n",
      "epoch:25 step:23567 [D loss: 0.645878, acc.: 60.16%] [G loss: 0.844120]\n",
      "epoch:25 step:23568 [D loss: 0.661027, acc.: 59.38%] [G loss: 0.882924]\n",
      "epoch:25 step:23569 [D loss: 0.666310, acc.: 54.69%] [G loss: 0.897966]\n",
      "epoch:25 step:23570 [D loss: 0.673638, acc.: 57.03%] [G loss: 0.912014]\n",
      "epoch:25 step:23571 [D loss: 0.630434, acc.: 64.06%] [G loss: 0.905120]\n",
      "epoch:25 step:23572 [D loss: 0.660952, acc.: 59.38%] [G loss: 0.886326]\n",
      "epoch:25 step:23573 [D loss: 0.681044, acc.: 57.81%] [G loss: 0.931654]\n",
      "epoch:25 step:23574 [D loss: 0.655277, acc.: 56.25%] [G loss: 0.968330]\n",
      "epoch:25 step:23575 [D loss: 0.696212, acc.: 51.56%] [G loss: 0.897995]\n",
      "epoch:25 step:23576 [D loss: 0.633872, acc.: 63.28%] [G loss: 0.862273]\n",
      "epoch:25 step:23577 [D loss: 0.653482, acc.: 62.50%] [G loss: 0.827059]\n",
      "epoch:25 step:23578 [D loss: 0.647596, acc.: 60.16%] [G loss: 0.853107]\n",
      "epoch:25 step:23579 [D loss: 0.692879, acc.: 48.44%] [G loss: 0.894335]\n",
      "epoch:25 step:23580 [D loss: 0.671172, acc.: 55.47%] [G loss: 0.830930]\n",
      "epoch:25 step:23581 [D loss: 0.630275, acc.: 66.41%] [G loss: 0.857005]\n",
      "epoch:25 step:23582 [D loss: 0.666372, acc.: 59.38%] [G loss: 0.949565]\n",
      "epoch:25 step:23583 [D loss: 0.620391, acc.: 67.19%] [G loss: 0.909189]\n",
      "epoch:25 step:23584 [D loss: 0.647222, acc.: 68.75%] [G loss: 0.948512]\n",
      "epoch:25 step:23585 [D loss: 0.663333, acc.: 59.38%] [G loss: 0.986847]\n",
      "epoch:25 step:23586 [D loss: 0.648405, acc.: 63.28%] [G loss: 0.966083]\n",
      "epoch:25 step:23587 [D loss: 0.639288, acc.: 63.28%] [G loss: 0.941300]\n",
      "epoch:25 step:23588 [D loss: 0.675025, acc.: 54.69%] [G loss: 0.836901]\n",
      "epoch:25 step:23589 [D loss: 0.697923, acc.: 60.94%] [G loss: 0.827356]\n",
      "epoch:25 step:23590 [D loss: 0.691333, acc.: 58.59%] [G loss: 0.851923]\n",
      "epoch:25 step:23591 [D loss: 0.654922, acc.: 60.16%] [G loss: 0.856699]\n",
      "epoch:25 step:23592 [D loss: 0.629361, acc.: 62.50%] [G loss: 0.853803]\n",
      "epoch:25 step:23593 [D loss: 0.680135, acc.: 53.12%] [G loss: 0.869727]\n",
      "epoch:25 step:23594 [D loss: 0.633011, acc.: 67.97%] [G loss: 0.890696]\n",
      "epoch:25 step:23595 [D loss: 0.667716, acc.: 54.69%] [G loss: 0.892551]\n",
      "epoch:25 step:23596 [D loss: 0.671940, acc.: 55.47%] [G loss: 0.900176]\n",
      "epoch:25 step:23597 [D loss: 0.700924, acc.: 57.81%] [G loss: 0.881621]\n",
      "epoch:25 step:23598 [D loss: 0.673377, acc.: 58.59%] [G loss: 0.903544]\n",
      "epoch:25 step:23599 [D loss: 0.716390, acc.: 51.56%] [G loss: 0.920028]\n",
      "epoch:25 step:23600 [D loss: 0.652413, acc.: 63.28%] [G loss: 0.880817]\n",
      "##############\n",
      "[2.68730022 2.60559012 2.09505583 3.79513285 1.38566923 6.99329839\n",
      " 2.69291333 3.77636386 4.0716778  6.62066424]\n",
      "##########\n",
      "epoch:25 step:23601 [D loss: 0.627847, acc.: 72.66%] [G loss: 0.888304]\n",
      "epoch:25 step:23602 [D loss: 0.602577, acc.: 68.75%] [G loss: 0.912552]\n",
      "epoch:25 step:23603 [D loss: 0.661094, acc.: 63.28%] [G loss: 0.943023]\n",
      "epoch:25 step:23604 [D loss: 0.648899, acc.: 61.72%] [G loss: 0.941784]\n",
      "epoch:25 step:23605 [D loss: 0.636172, acc.: 61.72%] [G loss: 0.873208]\n",
      "epoch:25 step:23606 [D loss: 0.648857, acc.: 67.19%] [G loss: 0.863259]\n",
      "epoch:25 step:23607 [D loss: 0.617158, acc.: 69.53%] [G loss: 0.864846]\n",
      "epoch:25 step:23608 [D loss: 0.662553, acc.: 63.28%] [G loss: 0.857899]\n",
      "epoch:25 step:23609 [D loss: 0.657277, acc.: 64.84%] [G loss: 0.868317]\n",
      "epoch:25 step:23610 [D loss: 0.663438, acc.: 60.94%] [G loss: 0.842637]\n",
      "epoch:25 step:23611 [D loss: 0.633189, acc.: 64.84%] [G loss: 0.851840]\n",
      "epoch:25 step:23612 [D loss: 0.659918, acc.: 61.72%] [G loss: 0.892561]\n",
      "epoch:25 step:23613 [D loss: 0.697287, acc.: 55.47%] [G loss: 0.911556]\n",
      "epoch:25 step:23614 [D loss: 0.662808, acc.: 58.59%] [G loss: 0.864696]\n",
      "epoch:25 step:23615 [D loss: 0.682306, acc.: 55.47%] [G loss: 0.874720]\n",
      "epoch:25 step:23616 [D loss: 0.641350, acc.: 60.16%] [G loss: 0.900257]\n",
      "epoch:25 step:23617 [D loss: 0.646157, acc.: 64.06%] [G loss: 0.889120]\n",
      "epoch:25 step:23618 [D loss: 0.628137, acc.: 62.50%] [G loss: 0.881492]\n",
      "epoch:25 step:23619 [D loss: 0.702689, acc.: 55.47%] [G loss: 0.876426]\n",
      "epoch:25 step:23620 [D loss: 0.647233, acc.: 62.50%] [G loss: 0.853539]\n",
      "epoch:25 step:23621 [D loss: 0.677409, acc.: 57.81%] [G loss: 0.927893]\n",
      "epoch:25 step:23622 [D loss: 0.644757, acc.: 57.81%] [G loss: 0.781931]\n",
      "epoch:25 step:23623 [D loss: 0.641279, acc.: 64.84%] [G loss: 0.882218]\n",
      "epoch:25 step:23624 [D loss: 0.609426, acc.: 66.41%] [G loss: 0.898367]\n",
      "epoch:25 step:23625 [D loss: 0.687642, acc.: 55.47%] [G loss: 0.828593]\n",
      "epoch:25 step:23626 [D loss: 0.675972, acc.: 55.47%] [G loss: 0.866840]\n",
      "epoch:25 step:23627 [D loss: 0.617522, acc.: 67.97%] [G loss: 0.944179]\n",
      "epoch:25 step:23628 [D loss: 0.635875, acc.: 65.62%] [G loss: 0.873039]\n",
      "epoch:25 step:23629 [D loss: 0.645207, acc.: 58.59%] [G loss: 0.890452]\n",
      "epoch:25 step:23630 [D loss: 0.671108, acc.: 57.81%] [G loss: 0.845882]\n",
      "epoch:25 step:23631 [D loss: 0.648894, acc.: 61.72%] [G loss: 0.932360]\n",
      "epoch:25 step:23632 [D loss: 0.630987, acc.: 65.62%] [G loss: 0.867678]\n",
      "epoch:25 step:23633 [D loss: 0.642581, acc.: 66.41%] [G loss: 0.931942]\n",
      "epoch:25 step:23634 [D loss: 0.686159, acc.: 59.38%] [G loss: 0.864407]\n",
      "epoch:25 step:23635 [D loss: 0.662831, acc.: 65.62%] [G loss: 0.870615]\n",
      "epoch:25 step:23636 [D loss: 0.657467, acc.: 61.72%] [G loss: 0.905597]\n",
      "epoch:25 step:23637 [D loss: 0.691446, acc.: 57.03%] [G loss: 0.922542]\n",
      "epoch:25 step:23638 [D loss: 0.676530, acc.: 59.38%] [G loss: 0.888113]\n",
      "epoch:25 step:23639 [D loss: 0.677227, acc.: 55.47%] [G loss: 0.890235]\n",
      "epoch:25 step:23640 [D loss: 0.659581, acc.: 60.16%] [G loss: 0.887765]\n",
      "epoch:25 step:23641 [D loss: 0.671100, acc.: 60.16%] [G loss: 0.907733]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23642 [D loss: 0.643885, acc.: 57.81%] [G loss: 0.866006]\n",
      "epoch:25 step:23643 [D loss: 0.664000, acc.: 60.16%] [G loss: 0.893411]\n",
      "epoch:25 step:23644 [D loss: 0.692787, acc.: 53.12%] [G loss: 0.862460]\n",
      "epoch:25 step:23645 [D loss: 0.665962, acc.: 63.28%] [G loss: 0.900025]\n",
      "epoch:25 step:23646 [D loss: 0.637502, acc.: 64.84%] [G loss: 0.871005]\n",
      "epoch:25 step:23647 [D loss: 0.682738, acc.: 56.25%] [G loss: 0.873446]\n",
      "epoch:25 step:23648 [D loss: 0.640515, acc.: 64.06%] [G loss: 0.890348]\n",
      "epoch:25 step:23649 [D loss: 0.660309, acc.: 52.34%] [G loss: 0.891476]\n",
      "epoch:25 step:23650 [D loss: 0.648723, acc.: 65.62%] [G loss: 0.877860]\n",
      "epoch:25 step:23651 [D loss: 0.667983, acc.: 61.72%] [G loss: 0.916363]\n",
      "epoch:25 step:23652 [D loss: 0.678490, acc.: 53.91%] [G loss: 0.895708]\n",
      "epoch:25 step:23653 [D loss: 0.660339, acc.: 65.62%] [G loss: 0.872591]\n",
      "epoch:25 step:23654 [D loss: 0.634986, acc.: 65.62%] [G loss: 0.904453]\n",
      "epoch:25 step:23655 [D loss: 0.662183, acc.: 58.59%] [G loss: 0.867925]\n",
      "epoch:25 step:23656 [D loss: 0.666182, acc.: 65.62%] [G loss: 0.850070]\n",
      "epoch:25 step:23657 [D loss: 0.666284, acc.: 57.81%] [G loss: 0.912858]\n",
      "epoch:25 step:23658 [D loss: 0.643327, acc.: 62.50%] [G loss: 0.871181]\n",
      "epoch:25 step:23659 [D loss: 0.695632, acc.: 57.81%] [G loss: 0.875575]\n",
      "epoch:25 step:23660 [D loss: 0.669274, acc.: 55.47%] [G loss: 0.858829]\n",
      "epoch:25 step:23661 [D loss: 0.645354, acc.: 60.16%] [G loss: 0.894565]\n",
      "epoch:25 step:23662 [D loss: 0.674166, acc.: 58.59%] [G loss: 0.859291]\n",
      "epoch:25 step:23663 [D loss: 0.680082, acc.: 60.16%] [G loss: 0.907215]\n",
      "epoch:25 step:23664 [D loss: 0.663552, acc.: 56.25%] [G loss: 0.916574]\n",
      "epoch:25 step:23665 [D loss: 0.651004, acc.: 60.16%] [G loss: 0.884759]\n",
      "epoch:25 step:23666 [D loss: 0.632557, acc.: 64.06%] [G loss: 0.906354]\n",
      "epoch:25 step:23667 [D loss: 0.659019, acc.: 62.50%] [G loss: 0.885682]\n",
      "epoch:25 step:23668 [D loss: 0.664139, acc.: 57.81%] [G loss: 0.871714]\n",
      "epoch:25 step:23669 [D loss: 0.675148, acc.: 60.16%] [G loss: 0.863970]\n",
      "epoch:25 step:23670 [D loss: 0.691274, acc.: 53.12%] [G loss: 0.894630]\n",
      "epoch:25 step:23671 [D loss: 0.637416, acc.: 64.84%] [G loss: 0.882093]\n",
      "epoch:25 step:23672 [D loss: 0.635178, acc.: 64.06%] [G loss: 0.864285]\n",
      "epoch:25 step:23673 [D loss: 0.678930, acc.: 54.69%] [G loss: 0.835511]\n",
      "epoch:25 step:23674 [D loss: 0.671575, acc.: 53.12%] [G loss: 0.898256]\n",
      "epoch:25 step:23675 [D loss: 0.675595, acc.: 57.81%] [G loss: 0.839008]\n",
      "epoch:25 step:23676 [D loss: 0.685076, acc.: 53.12%] [G loss: 0.832122]\n",
      "epoch:25 step:23677 [D loss: 0.634212, acc.: 60.94%] [G loss: 0.839730]\n",
      "epoch:25 step:23678 [D loss: 0.682299, acc.: 57.03%] [G loss: 0.900405]\n",
      "epoch:25 step:23679 [D loss: 0.678891, acc.: 57.81%] [G loss: 0.850991]\n",
      "epoch:25 step:23680 [D loss: 0.652036, acc.: 59.38%] [G loss: 0.902672]\n",
      "epoch:25 step:23681 [D loss: 0.663961, acc.: 57.03%] [G loss: 0.832776]\n",
      "epoch:25 step:23682 [D loss: 0.645675, acc.: 58.59%] [G loss: 0.846175]\n",
      "epoch:25 step:23683 [D loss: 0.645438, acc.: 63.28%] [G loss: 0.906269]\n",
      "epoch:25 step:23684 [D loss: 0.705038, acc.: 59.38%] [G loss: 0.903683]\n",
      "epoch:25 step:23685 [D loss: 0.668818, acc.: 62.50%] [G loss: 0.936570]\n",
      "epoch:25 step:23686 [D loss: 0.694822, acc.: 51.56%] [G loss: 0.900708]\n",
      "epoch:25 step:23687 [D loss: 0.685907, acc.: 55.47%] [G loss: 0.861781]\n",
      "epoch:25 step:23688 [D loss: 0.656499, acc.: 60.94%] [G loss: 0.901298]\n",
      "epoch:25 step:23689 [D loss: 0.627997, acc.: 64.84%] [G loss: 0.883569]\n",
      "epoch:25 step:23690 [D loss: 0.632614, acc.: 67.19%] [G loss: 0.927870]\n",
      "epoch:25 step:23691 [D loss: 0.648321, acc.: 64.06%] [G loss: 0.883973]\n",
      "epoch:25 step:23692 [D loss: 0.659067, acc.: 62.50%] [G loss: 0.875920]\n",
      "epoch:25 step:23693 [D loss: 0.639127, acc.: 64.84%] [G loss: 0.881773]\n",
      "epoch:25 step:23694 [D loss: 0.641158, acc.: 59.38%] [G loss: 0.871720]\n",
      "epoch:25 step:23695 [D loss: 0.632958, acc.: 63.28%] [G loss: 0.889758]\n",
      "epoch:25 step:23696 [D loss: 0.615300, acc.: 71.09%] [G loss: 0.887842]\n",
      "epoch:25 step:23697 [D loss: 0.676792, acc.: 56.25%] [G loss: 0.880420]\n",
      "epoch:25 step:23698 [D loss: 0.656566, acc.: 62.50%] [G loss: 0.850332]\n",
      "epoch:25 step:23699 [D loss: 0.671983, acc.: 58.59%] [G loss: 0.889271]\n",
      "epoch:25 step:23700 [D loss: 0.648831, acc.: 62.50%] [G loss: 0.931359]\n",
      "epoch:25 step:23701 [D loss: 0.674489, acc.: 56.25%] [G loss: 0.882444]\n",
      "epoch:25 step:23702 [D loss: 0.649872, acc.: 61.72%] [G loss: 0.879553]\n",
      "epoch:25 step:23703 [D loss: 0.639454, acc.: 62.50%] [G loss: 0.890601]\n",
      "epoch:25 step:23704 [D loss: 0.682847, acc.: 57.03%] [G loss: 0.868629]\n",
      "epoch:25 step:23705 [D loss: 0.681652, acc.: 57.03%] [G loss: 0.842385]\n",
      "epoch:25 step:23706 [D loss: 0.637380, acc.: 65.62%] [G loss: 0.864053]\n",
      "epoch:25 step:23707 [D loss: 0.622825, acc.: 71.88%] [G loss: 0.859608]\n",
      "epoch:25 step:23708 [D loss: 0.631407, acc.: 64.06%] [G loss: 0.913095]\n",
      "epoch:25 step:23709 [D loss: 0.669481, acc.: 56.25%] [G loss: 0.881773]\n",
      "epoch:25 step:23710 [D loss: 0.660746, acc.: 60.94%] [G loss: 0.947071]\n",
      "epoch:25 step:23711 [D loss: 0.633523, acc.: 64.06%] [G loss: 0.950460]\n",
      "epoch:25 step:23712 [D loss: 0.632425, acc.: 67.97%] [G loss: 0.868632]\n",
      "epoch:25 step:23713 [D loss: 0.648854, acc.: 62.50%] [G loss: 0.885221]\n",
      "epoch:25 step:23714 [D loss: 0.674474, acc.: 53.12%] [G loss: 0.921156]\n",
      "epoch:25 step:23715 [D loss: 0.619200, acc.: 64.06%] [G loss: 0.835820]\n",
      "epoch:25 step:23716 [D loss: 0.701527, acc.: 57.03%] [G loss: 0.839461]\n",
      "epoch:25 step:23717 [D loss: 0.670511, acc.: 64.06%] [G loss: 0.875358]\n",
      "epoch:25 step:23718 [D loss: 0.690502, acc.: 54.69%] [G loss: 0.900935]\n",
      "epoch:25 step:23719 [D loss: 0.652985, acc.: 61.72%] [G loss: 0.909540]\n",
      "epoch:25 step:23720 [D loss: 0.674111, acc.: 50.78%] [G loss: 0.916240]\n",
      "epoch:25 step:23721 [D loss: 0.643209, acc.: 65.62%] [G loss: 0.837784]\n",
      "epoch:25 step:23722 [D loss: 0.645160, acc.: 57.81%] [G loss: 0.905452]\n",
      "epoch:25 step:23723 [D loss: 0.664059, acc.: 58.59%] [G loss: 0.912171]\n",
      "epoch:25 step:23724 [D loss: 0.677176, acc.: 56.25%] [G loss: 0.881035]\n",
      "epoch:25 step:23725 [D loss: 0.639287, acc.: 60.94%] [G loss: 0.917001]\n",
      "epoch:25 step:23726 [D loss: 0.695262, acc.: 53.91%] [G loss: 0.918464]\n",
      "epoch:25 step:23727 [D loss: 0.676625, acc.: 60.16%] [G loss: 0.913636]\n",
      "epoch:25 step:23728 [D loss: 0.661292, acc.: 58.59%] [G loss: 0.874369]\n",
      "epoch:25 step:23729 [D loss: 0.651405, acc.: 61.72%] [G loss: 0.861395]\n",
      "epoch:25 step:23730 [D loss: 0.659294, acc.: 59.38%] [G loss: 0.843908]\n",
      "epoch:25 step:23731 [D loss: 0.649539, acc.: 64.06%] [G loss: 0.883944]\n",
      "epoch:25 step:23732 [D loss: 0.648422, acc.: 60.94%] [G loss: 0.839992]\n",
      "epoch:25 step:23733 [D loss: 0.668352, acc.: 51.56%] [G loss: 0.871331]\n",
      "epoch:25 step:23734 [D loss: 0.658767, acc.: 60.16%] [G loss: 0.904982]\n",
      "epoch:25 step:23735 [D loss: 0.639374, acc.: 63.28%] [G loss: 0.910721]\n",
      "epoch:25 step:23736 [D loss: 0.654281, acc.: 62.50%] [G loss: 0.905351]\n",
      "epoch:25 step:23737 [D loss: 0.689137, acc.: 50.78%] [G loss: 0.906796]\n",
      "epoch:25 step:23738 [D loss: 0.675897, acc.: 52.34%] [G loss: 0.854099]\n",
      "epoch:25 step:23739 [D loss: 0.630214, acc.: 60.16%] [G loss: 0.897666]\n",
      "epoch:25 step:23740 [D loss: 0.640311, acc.: 68.75%] [G loss: 0.960747]\n",
      "epoch:25 step:23741 [D loss: 0.626790, acc.: 64.84%] [G loss: 0.967021]\n",
      "epoch:25 step:23742 [D loss: 0.639621, acc.: 64.84%] [G loss: 0.889456]\n",
      "epoch:25 step:23743 [D loss: 0.661437, acc.: 64.84%] [G loss: 0.909756]\n",
      "epoch:25 step:23744 [D loss: 0.648417, acc.: 58.59%] [G loss: 0.908215]\n",
      "epoch:25 step:23745 [D loss: 0.635151, acc.: 64.06%] [G loss: 0.932284]\n",
      "epoch:25 step:23746 [D loss: 0.650365, acc.: 60.16%] [G loss: 0.954881]\n",
      "epoch:25 step:23747 [D loss: 0.652044, acc.: 60.94%] [G loss: 0.941477]\n",
      "epoch:25 step:23748 [D loss: 0.678439, acc.: 54.69%] [G loss: 0.884319]\n",
      "epoch:25 step:23749 [D loss: 0.634006, acc.: 59.38%] [G loss: 0.909497]\n",
      "epoch:25 step:23750 [D loss: 0.649043, acc.: 63.28%] [G loss: 0.869736]\n",
      "epoch:25 step:23751 [D loss: 0.695377, acc.: 54.69%] [G loss: 0.871000]\n",
      "epoch:25 step:23752 [D loss: 0.646115, acc.: 60.94%] [G loss: 0.849452]\n",
      "epoch:25 step:23753 [D loss: 0.616835, acc.: 64.84%] [G loss: 0.861329]\n",
      "epoch:25 step:23754 [D loss: 0.641921, acc.: 64.06%] [G loss: 0.860059]\n",
      "epoch:25 step:23755 [D loss: 0.650663, acc.: 59.38%] [G loss: 0.878897]\n",
      "epoch:25 step:23756 [D loss: 0.614001, acc.: 62.50%] [G loss: 0.937735]\n",
      "epoch:25 step:23757 [D loss: 0.638431, acc.: 64.06%] [G loss: 0.968082]\n",
      "epoch:25 step:23758 [D loss: 0.666339, acc.: 56.25%] [G loss: 0.901748]\n",
      "epoch:25 step:23759 [D loss: 0.614672, acc.: 67.19%] [G loss: 0.869271]\n",
      "epoch:25 step:23760 [D loss: 0.643058, acc.: 61.72%] [G loss: 0.861356]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23761 [D loss: 0.606764, acc.: 66.41%] [G loss: 0.914070]\n",
      "epoch:25 step:23762 [D loss: 0.640282, acc.: 62.50%] [G loss: 0.868410]\n",
      "epoch:25 step:23763 [D loss: 0.629290, acc.: 60.94%] [G loss: 0.899677]\n",
      "epoch:25 step:23764 [D loss: 0.658232, acc.: 58.59%] [G loss: 0.897095]\n",
      "epoch:25 step:23765 [D loss: 0.667955, acc.: 65.62%] [G loss: 0.930652]\n",
      "epoch:25 step:23766 [D loss: 0.654656, acc.: 59.38%] [G loss: 0.929888]\n",
      "epoch:25 step:23767 [D loss: 0.655149, acc.: 57.81%] [G loss: 0.964175]\n",
      "epoch:25 step:23768 [D loss: 0.674696, acc.: 57.03%] [G loss: 0.965473]\n",
      "epoch:25 step:23769 [D loss: 0.641621, acc.: 64.06%] [G loss: 0.860888]\n",
      "epoch:25 step:23770 [D loss: 0.685224, acc.: 57.81%] [G loss: 0.941051]\n",
      "epoch:25 step:23771 [D loss: 0.665140, acc.: 60.94%] [G loss: 0.894163]\n",
      "epoch:25 step:23772 [D loss: 0.646572, acc.: 60.94%] [G loss: 0.912260]\n",
      "epoch:25 step:23773 [D loss: 0.653215, acc.: 64.06%] [G loss: 0.883228]\n",
      "epoch:25 step:23774 [D loss: 0.647761, acc.: 60.94%] [G loss: 0.911885]\n",
      "epoch:25 step:23775 [D loss: 0.655729, acc.: 58.59%] [G loss: 0.946285]\n",
      "epoch:25 step:23776 [D loss: 0.620833, acc.: 67.97%] [G loss: 0.903133]\n",
      "epoch:25 step:23777 [D loss: 0.671453, acc.: 60.16%] [G loss: 0.913545]\n",
      "epoch:25 step:23778 [D loss: 0.645306, acc.: 61.72%] [G loss: 0.857422]\n",
      "epoch:25 step:23779 [D loss: 0.662675, acc.: 59.38%] [G loss: 0.910826]\n",
      "epoch:25 step:23780 [D loss: 0.657042, acc.: 59.38%] [G loss: 0.873927]\n",
      "epoch:25 step:23781 [D loss: 0.669765, acc.: 60.16%] [G loss: 0.889430]\n",
      "epoch:25 step:23782 [D loss: 0.656140, acc.: 64.06%] [G loss: 0.857501]\n",
      "epoch:25 step:23783 [D loss: 0.654399, acc.: 59.38%] [G loss: 0.911412]\n",
      "epoch:25 step:23784 [D loss: 0.691004, acc.: 53.91%] [G loss: 0.837403]\n",
      "epoch:25 step:23785 [D loss: 0.636877, acc.: 61.72%] [G loss: 0.919132]\n",
      "epoch:25 step:23786 [D loss: 0.645573, acc.: 60.94%] [G loss: 0.912545]\n",
      "epoch:25 step:23787 [D loss: 0.681401, acc.: 57.81%] [G loss: 0.881819]\n",
      "epoch:25 step:23788 [D loss: 0.688835, acc.: 53.12%] [G loss: 0.862200]\n",
      "epoch:25 step:23789 [D loss: 0.633263, acc.: 62.50%] [G loss: 0.877254]\n",
      "epoch:25 step:23790 [D loss: 0.648366, acc.: 60.16%] [G loss: 0.920960]\n",
      "epoch:25 step:23791 [D loss: 0.652080, acc.: 63.28%] [G loss: 0.900498]\n",
      "epoch:25 step:23792 [D loss: 0.676467, acc.: 54.69%] [G loss: 0.935989]\n",
      "epoch:25 step:23793 [D loss: 0.669613, acc.: 57.81%] [G loss: 0.905502]\n",
      "epoch:25 step:23794 [D loss: 0.691584, acc.: 54.69%] [G loss: 0.901974]\n",
      "epoch:25 step:23795 [D loss: 0.652839, acc.: 62.50%] [G loss: 0.878632]\n",
      "epoch:25 step:23796 [D loss: 0.649066, acc.: 60.16%] [G loss: 0.908893]\n",
      "epoch:25 step:23797 [D loss: 0.671924, acc.: 58.59%] [G loss: 0.873139]\n",
      "epoch:25 step:23798 [D loss: 0.627188, acc.: 67.97%] [G loss: 0.874789]\n",
      "epoch:25 step:23799 [D loss: 0.657689, acc.: 66.41%] [G loss: 0.913530]\n",
      "epoch:25 step:23800 [D loss: 0.658900, acc.: 56.25%] [G loss: 0.880878]\n",
      "##############\n",
      "[2.82601949 2.51963871 2.22604133 3.86353781 1.40182461 7.41587448\n",
      " 3.09705981 3.46214136 4.1484397  7.14868929]\n",
      "##########\n",
      "epoch:25 step:23801 [D loss: 0.698636, acc.: 50.78%] [G loss: 0.916639]\n",
      "epoch:25 step:23802 [D loss: 0.679946, acc.: 60.16%] [G loss: 0.895383]\n",
      "epoch:25 step:23803 [D loss: 0.603978, acc.: 69.53%] [G loss: 0.881407]\n",
      "epoch:25 step:23804 [D loss: 0.643811, acc.: 63.28%] [G loss: 0.967370]\n",
      "epoch:25 step:23805 [D loss: 0.627859, acc.: 67.97%] [G loss: 0.888763]\n",
      "epoch:25 step:23806 [D loss: 0.637376, acc.: 65.62%] [G loss: 0.872494]\n",
      "epoch:25 step:23807 [D loss: 0.617069, acc.: 62.50%] [G loss: 0.897467]\n",
      "epoch:25 step:23808 [D loss: 0.668743, acc.: 58.59%] [G loss: 0.902004]\n",
      "epoch:25 step:23809 [D loss: 0.689667, acc.: 53.91%] [G loss: 0.859125]\n",
      "epoch:25 step:23810 [D loss: 0.633250, acc.: 58.59%] [G loss: 0.893130]\n",
      "epoch:25 step:23811 [D loss: 0.654137, acc.: 64.84%] [G loss: 0.832995]\n",
      "epoch:25 step:23812 [D loss: 0.632835, acc.: 60.94%] [G loss: 0.847878]\n",
      "epoch:25 step:23813 [D loss: 0.713021, acc.: 52.34%] [G loss: 0.845960]\n",
      "epoch:25 step:23814 [D loss: 0.621537, acc.: 65.62%] [G loss: 0.929717]\n",
      "epoch:25 step:23815 [D loss: 0.672926, acc.: 60.16%] [G loss: 0.914358]\n",
      "epoch:25 step:23816 [D loss: 0.619237, acc.: 67.19%] [G loss: 0.903761]\n",
      "epoch:25 step:23817 [D loss: 0.662597, acc.: 60.94%] [G loss: 0.871484]\n",
      "epoch:25 step:23818 [D loss: 0.679992, acc.: 50.78%] [G loss: 0.851411]\n",
      "epoch:25 step:23819 [D loss: 0.617208, acc.: 60.94%] [G loss: 0.877566]\n",
      "epoch:25 step:23820 [D loss: 0.704644, acc.: 54.69%] [G loss: 0.840984]\n",
      "epoch:25 step:23821 [D loss: 0.634499, acc.: 71.09%] [G loss: 0.860735]\n",
      "epoch:25 step:23822 [D loss: 0.648262, acc.: 62.50%] [G loss: 0.842916]\n",
      "epoch:25 step:23823 [D loss: 0.657693, acc.: 60.16%] [G loss: 0.853655]\n",
      "epoch:25 step:23824 [D loss: 0.651442, acc.: 59.38%] [G loss: 0.901191]\n",
      "epoch:25 step:23825 [D loss: 0.661437, acc.: 64.84%] [G loss: 0.878978]\n",
      "epoch:25 step:23826 [D loss: 0.647986, acc.: 60.94%] [G loss: 0.903263]\n",
      "epoch:25 step:23827 [D loss: 0.597270, acc.: 67.97%] [G loss: 0.978959]\n",
      "epoch:25 step:23828 [D loss: 0.627921, acc.: 67.19%] [G loss: 0.899415]\n",
      "epoch:25 step:23829 [D loss: 0.657887, acc.: 57.03%] [G loss: 0.977051]\n",
      "epoch:25 step:23830 [D loss: 0.609589, acc.: 66.41%] [G loss: 0.893902]\n",
      "epoch:25 step:23831 [D loss: 0.679764, acc.: 57.81%] [G loss: 0.937109]\n",
      "epoch:25 step:23832 [D loss: 0.659733, acc.: 57.03%] [G loss: 0.968437]\n",
      "epoch:25 step:23833 [D loss: 0.645486, acc.: 68.75%] [G loss: 0.882328]\n",
      "epoch:25 step:23834 [D loss: 0.695606, acc.: 52.34%] [G loss: 0.804837]\n",
      "epoch:25 step:23835 [D loss: 0.674787, acc.: 63.28%] [G loss: 0.868881]\n",
      "epoch:25 step:23836 [D loss: 0.616993, acc.: 66.41%] [G loss: 0.871195]\n",
      "epoch:25 step:23837 [D loss: 0.628512, acc.: 67.19%] [G loss: 0.948490]\n",
      "epoch:25 step:23838 [D loss: 0.708935, acc.: 58.59%] [G loss: 0.876358]\n",
      "epoch:25 step:23839 [D loss: 0.665352, acc.: 57.03%] [G loss: 0.869824]\n",
      "epoch:25 step:23840 [D loss: 0.660130, acc.: 57.03%] [G loss: 0.881540]\n",
      "epoch:25 step:23841 [D loss: 0.660309, acc.: 57.81%] [G loss: 0.951870]\n",
      "epoch:25 step:23842 [D loss: 0.663467, acc.: 61.72%] [G loss: 0.903326]\n",
      "epoch:25 step:23843 [D loss: 0.728938, acc.: 47.66%] [G loss: 0.774731]\n",
      "epoch:25 step:23844 [D loss: 0.652730, acc.: 63.28%] [G loss: 0.854046]\n",
      "epoch:25 step:23845 [D loss: 0.662018, acc.: 60.16%] [G loss: 0.926003]\n",
      "epoch:25 step:23846 [D loss: 0.674482, acc.: 57.03%] [G loss: 0.898002]\n",
      "epoch:25 step:23847 [D loss: 0.676829, acc.: 55.47%] [G loss: 0.832078]\n",
      "epoch:25 step:23848 [D loss: 0.664507, acc.: 57.03%] [G loss: 0.865360]\n",
      "epoch:25 step:23849 [D loss: 0.622595, acc.: 68.75%] [G loss: 0.888171]\n",
      "epoch:25 step:23850 [D loss: 0.692574, acc.: 58.59%] [G loss: 0.877451]\n",
      "epoch:25 step:23851 [D loss: 0.672142, acc.: 59.38%] [G loss: 0.862693]\n",
      "epoch:25 step:23852 [D loss: 0.740039, acc.: 48.44%] [G loss: 0.869001]\n",
      "epoch:25 step:23853 [D loss: 0.705429, acc.: 48.44%] [G loss: 0.855952]\n",
      "epoch:25 step:23854 [D loss: 0.642264, acc.: 62.50%] [G loss: 0.886630]\n",
      "epoch:25 step:23855 [D loss: 0.693840, acc.: 57.81%] [G loss: 0.886314]\n",
      "epoch:25 step:23856 [D loss: 0.623009, acc.: 65.62%] [G loss: 0.859413]\n",
      "epoch:25 step:23857 [D loss: 0.663532, acc.: 62.50%] [G loss: 0.913045]\n",
      "epoch:25 step:23858 [D loss: 0.659046, acc.: 55.47%] [G loss: 0.892699]\n",
      "epoch:25 step:23859 [D loss: 0.621696, acc.: 64.84%] [G loss: 0.853805]\n",
      "epoch:25 step:23860 [D loss: 0.659243, acc.: 63.28%] [G loss: 0.909676]\n",
      "epoch:25 step:23861 [D loss: 0.611465, acc.: 66.41%] [G loss: 0.905349]\n",
      "epoch:25 step:23862 [D loss: 0.691179, acc.: 58.59%] [G loss: 0.899579]\n",
      "epoch:25 step:23863 [D loss: 0.706767, acc.: 50.78%] [G loss: 0.854794]\n",
      "epoch:25 step:23864 [D loss: 0.657201, acc.: 59.38%] [G loss: 0.810367]\n",
      "epoch:25 step:23865 [D loss: 0.628124, acc.: 66.41%] [G loss: 0.851596]\n",
      "epoch:25 step:23866 [D loss: 0.640705, acc.: 59.38%] [G loss: 0.893115]\n",
      "epoch:25 step:23867 [D loss: 0.672073, acc.: 60.94%] [G loss: 0.895345]\n",
      "epoch:25 step:23868 [D loss: 0.647763, acc.: 59.38%] [G loss: 0.897180]\n",
      "epoch:25 step:23869 [D loss: 0.684077, acc.: 52.34%] [G loss: 0.883774]\n",
      "epoch:25 step:23870 [D loss: 0.650110, acc.: 60.94%] [G loss: 0.906083]\n",
      "epoch:25 step:23871 [D loss: 0.675859, acc.: 57.03%] [G loss: 0.870804]\n",
      "epoch:25 step:23872 [D loss: 0.648491, acc.: 60.16%] [G loss: 0.862648]\n",
      "epoch:25 step:23873 [D loss: 0.660480, acc.: 58.59%] [G loss: 0.869279]\n",
      "epoch:25 step:23874 [D loss: 0.665644, acc.: 61.72%] [G loss: 0.960039]\n",
      "epoch:25 step:23875 [D loss: 0.655256, acc.: 57.03%] [G loss: 0.866348]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23876 [D loss: 0.666363, acc.: 58.59%] [G loss: 0.889358]\n",
      "epoch:25 step:23877 [D loss: 0.643397, acc.: 62.50%] [G loss: 0.906425]\n",
      "epoch:25 step:23878 [D loss: 0.646280, acc.: 67.19%] [G loss: 0.936400]\n",
      "epoch:25 step:23879 [D loss: 0.639200, acc.: 61.72%] [G loss: 0.922061]\n",
      "epoch:25 step:23880 [D loss: 0.642380, acc.: 64.06%] [G loss: 0.897038]\n",
      "epoch:25 step:23881 [D loss: 0.659482, acc.: 59.38%] [G loss: 0.938913]\n",
      "epoch:25 step:23882 [D loss: 0.674547, acc.: 63.28%] [G loss: 0.887366]\n",
      "epoch:25 step:23883 [D loss: 0.675111, acc.: 57.03%] [G loss: 0.888996]\n",
      "epoch:25 step:23884 [D loss: 0.597291, acc.: 72.66%] [G loss: 0.917303]\n",
      "epoch:25 step:23885 [D loss: 0.676377, acc.: 55.47%] [G loss: 0.908362]\n",
      "epoch:25 step:23886 [D loss: 0.651077, acc.: 62.50%] [G loss: 0.971209]\n",
      "epoch:25 step:23887 [D loss: 0.658690, acc.: 56.25%] [G loss: 0.927980]\n",
      "epoch:25 step:23888 [D loss: 0.641214, acc.: 64.06%] [G loss: 0.913056]\n",
      "epoch:25 step:23889 [D loss: 0.680192, acc.: 53.12%] [G loss: 0.863150]\n",
      "epoch:25 step:23890 [D loss: 0.641621, acc.: 67.19%] [G loss: 0.923538]\n",
      "epoch:25 step:23891 [D loss: 0.626474, acc.: 66.41%] [G loss: 0.870946]\n",
      "epoch:25 step:23892 [D loss: 0.663198, acc.: 58.59%] [G loss: 0.933059]\n",
      "epoch:25 step:23893 [D loss: 0.613032, acc.: 64.84%] [G loss: 0.850778]\n",
      "epoch:25 step:23894 [D loss: 0.623593, acc.: 67.97%] [G loss: 0.824590]\n",
      "epoch:25 step:23895 [D loss: 0.664371, acc.: 58.59%] [G loss: 0.851007]\n",
      "epoch:25 step:23896 [D loss: 0.633669, acc.: 60.94%] [G loss: 0.840952]\n",
      "epoch:25 step:23897 [D loss: 0.654616, acc.: 59.38%] [G loss: 0.927385]\n",
      "epoch:25 step:23898 [D loss: 0.666687, acc.: 60.94%] [G loss: 0.940659]\n",
      "epoch:25 step:23899 [D loss: 0.633767, acc.: 58.59%] [G loss: 0.874195]\n",
      "epoch:25 step:23900 [D loss: 0.657572, acc.: 60.16%] [G loss: 0.862575]\n",
      "epoch:25 step:23901 [D loss: 0.674314, acc.: 57.03%] [G loss: 0.885610]\n",
      "epoch:25 step:23902 [D loss: 0.676898, acc.: 57.03%] [G loss: 0.828385]\n",
      "epoch:25 step:23903 [D loss: 0.642678, acc.: 65.62%] [G loss: 0.845888]\n",
      "epoch:25 step:23904 [D loss: 0.673510, acc.: 56.25%] [G loss: 0.922097]\n",
      "epoch:25 step:23905 [D loss: 0.684768, acc.: 56.25%] [G loss: 0.870102]\n",
      "epoch:25 step:23906 [D loss: 0.679712, acc.: 59.38%] [G loss: 0.908203]\n",
      "epoch:25 step:23907 [D loss: 0.642606, acc.: 64.06%] [G loss: 0.901023]\n",
      "epoch:25 step:23908 [D loss: 0.712295, acc.: 53.12%] [G loss: 0.940542]\n",
      "epoch:25 step:23909 [D loss: 0.635256, acc.: 62.50%] [G loss: 0.951614]\n",
      "epoch:25 step:23910 [D loss: 0.629219, acc.: 64.06%] [G loss: 0.994537]\n",
      "epoch:25 step:23911 [D loss: 0.626393, acc.: 71.88%] [G loss: 0.908564]\n",
      "epoch:25 step:23912 [D loss: 0.676074, acc.: 57.81%] [G loss: 0.873048]\n",
      "epoch:25 step:23913 [D loss: 0.625123, acc.: 65.62%] [G loss: 0.885490]\n",
      "epoch:25 step:23914 [D loss: 0.653656, acc.: 61.72%] [G loss: 0.859787]\n",
      "epoch:25 step:23915 [D loss: 0.645251, acc.: 62.50%] [G loss: 0.853974]\n",
      "epoch:25 step:23916 [D loss: 0.662047, acc.: 58.59%] [G loss: 0.887299]\n",
      "epoch:25 step:23917 [D loss: 0.652725, acc.: 60.16%] [G loss: 0.872156]\n",
      "epoch:25 step:23918 [D loss: 0.669979, acc.: 59.38%] [G loss: 0.921499]\n",
      "epoch:25 step:23919 [D loss: 0.665475, acc.: 55.47%] [G loss: 0.936058]\n",
      "epoch:25 step:23920 [D loss: 0.656356, acc.: 60.16%] [G loss: 0.965867]\n",
      "epoch:25 step:23921 [D loss: 0.643854, acc.: 63.28%] [G loss: 0.895390]\n",
      "epoch:25 step:23922 [D loss: 0.658077, acc.: 59.38%] [G loss: 0.904703]\n",
      "epoch:25 step:23923 [D loss: 0.655118, acc.: 56.25%] [G loss: 0.910966]\n",
      "epoch:25 step:23924 [D loss: 0.646125, acc.: 63.28%] [G loss: 0.900310]\n",
      "epoch:25 step:23925 [D loss: 0.665327, acc.: 58.59%] [G loss: 0.922418]\n",
      "epoch:25 step:23926 [D loss: 0.640072, acc.: 63.28%] [G loss: 0.873557]\n",
      "epoch:25 step:23927 [D loss: 0.660689, acc.: 61.72%] [G loss: 0.854027]\n",
      "epoch:25 step:23928 [D loss: 0.663216, acc.: 64.84%] [G loss: 0.878113]\n",
      "epoch:25 step:23929 [D loss: 0.671322, acc.: 59.38%] [G loss: 0.917395]\n",
      "epoch:25 step:23930 [D loss: 0.637642, acc.: 64.84%] [G loss: 0.921628]\n",
      "epoch:25 step:23931 [D loss: 0.619988, acc.: 67.19%] [G loss: 0.927925]\n",
      "epoch:25 step:23932 [D loss: 0.663162, acc.: 60.16%] [G loss: 0.920471]\n",
      "epoch:25 step:23933 [D loss: 0.662518, acc.: 57.03%] [G loss: 0.918243]\n",
      "epoch:25 step:23934 [D loss: 0.641357, acc.: 64.06%] [G loss: 0.875777]\n",
      "epoch:25 step:23935 [D loss: 0.654245, acc.: 55.47%] [G loss: 0.904781]\n",
      "epoch:25 step:23936 [D loss: 0.605468, acc.: 71.09%] [G loss: 0.878809]\n",
      "epoch:25 step:23937 [D loss: 0.667367, acc.: 57.03%] [G loss: 0.899426]\n",
      "epoch:25 step:23938 [D loss: 0.625995, acc.: 64.84%] [G loss: 0.928105]\n",
      "epoch:25 step:23939 [D loss: 0.652752, acc.: 64.84%] [G loss: 0.924896]\n",
      "epoch:25 step:23940 [D loss: 0.628065, acc.: 70.31%] [G loss: 0.917934]\n",
      "epoch:25 step:23941 [D loss: 0.623463, acc.: 64.84%] [G loss: 0.925276]\n",
      "epoch:25 step:23942 [D loss: 0.618402, acc.: 67.19%] [G loss: 0.894687]\n",
      "epoch:25 step:23943 [D loss: 0.673488, acc.: 57.03%] [G loss: 0.867803]\n",
      "epoch:25 step:23944 [D loss: 0.632914, acc.: 66.41%] [G loss: 0.893234]\n",
      "epoch:25 step:23945 [D loss: 0.678719, acc.: 58.59%] [G loss: 0.909365]\n",
      "epoch:25 step:23946 [D loss: 0.661802, acc.: 55.47%] [G loss: 0.911808]\n",
      "epoch:25 step:23947 [D loss: 0.624677, acc.: 64.84%] [G loss: 0.906052]\n",
      "epoch:25 step:23948 [D loss: 0.644125, acc.: 63.28%] [G loss: 1.012019]\n",
      "epoch:25 step:23949 [D loss: 0.651890, acc.: 60.16%] [G loss: 0.870405]\n",
      "epoch:25 step:23950 [D loss: 0.675231, acc.: 62.50%] [G loss: 0.961732]\n",
      "epoch:25 step:23951 [D loss: 0.670526, acc.: 57.81%] [G loss: 0.940844]\n",
      "epoch:25 step:23952 [D loss: 0.658646, acc.: 56.25%] [G loss: 0.890200]\n",
      "epoch:25 step:23953 [D loss: 0.704500, acc.: 53.12%] [G loss: 0.890690]\n",
      "epoch:25 step:23954 [D loss: 0.660560, acc.: 63.28%] [G loss: 0.849644]\n",
      "epoch:25 step:23955 [D loss: 0.652476, acc.: 64.06%] [G loss: 0.906430]\n",
      "epoch:25 step:23956 [D loss: 0.663633, acc.: 61.72%] [G loss: 0.944551]\n",
      "epoch:25 step:23957 [D loss: 0.654312, acc.: 57.03%] [G loss: 0.877203]\n",
      "epoch:25 step:23958 [D loss: 0.672824, acc.: 61.72%] [G loss: 0.843651]\n",
      "epoch:25 step:23959 [D loss: 0.657447, acc.: 62.50%] [G loss: 0.829496]\n",
      "epoch:25 step:23960 [D loss: 0.652109, acc.: 63.28%] [G loss: 0.866754]\n",
      "epoch:25 step:23961 [D loss: 0.636770, acc.: 64.84%] [G loss: 0.895819]\n",
      "epoch:25 step:23962 [D loss: 0.702724, acc.: 54.69%] [G loss: 0.928688]\n",
      "epoch:25 step:23963 [D loss: 0.663611, acc.: 60.94%] [G loss: 0.923568]\n",
      "epoch:25 step:23964 [D loss: 0.643003, acc.: 60.16%] [G loss: 0.896810]\n",
      "epoch:25 step:23965 [D loss: 0.633571, acc.: 64.84%] [G loss: 0.868662]\n",
      "epoch:25 step:23966 [D loss: 0.693824, acc.: 57.81%] [G loss: 0.865656]\n",
      "epoch:25 step:23967 [D loss: 0.698447, acc.: 57.81%] [G loss: 0.900368]\n",
      "epoch:25 step:23968 [D loss: 0.639312, acc.: 65.62%] [G loss: 0.963118]\n",
      "epoch:25 step:23969 [D loss: 0.636324, acc.: 63.28%] [G loss: 0.909444]\n",
      "epoch:25 step:23970 [D loss: 0.645712, acc.: 62.50%] [G loss: 0.952481]\n",
      "epoch:25 step:23971 [D loss: 0.638349, acc.: 60.94%] [G loss: 0.912282]\n",
      "epoch:25 step:23972 [D loss: 0.678474, acc.: 57.81%] [G loss: 0.907927]\n",
      "epoch:25 step:23973 [D loss: 0.641423, acc.: 63.28%] [G loss: 0.926438]\n",
      "epoch:25 step:23974 [D loss: 0.644676, acc.: 66.41%] [G loss: 0.898492]\n",
      "epoch:25 step:23975 [D loss: 0.655451, acc.: 57.81%] [G loss: 0.856222]\n",
      "epoch:25 step:23976 [D loss: 0.642899, acc.: 61.72%] [G loss: 0.893465]\n",
      "epoch:25 step:23977 [D loss: 0.627716, acc.: 68.75%] [G loss: 0.945481]\n",
      "epoch:25 step:23978 [D loss: 0.695020, acc.: 53.91%] [G loss: 0.923926]\n",
      "epoch:25 step:23979 [D loss: 0.652473, acc.: 67.19%] [G loss: 0.920997]\n",
      "epoch:25 step:23980 [D loss: 0.657042, acc.: 59.38%] [G loss: 0.958105]\n",
      "epoch:25 step:23981 [D loss: 0.694184, acc.: 52.34%] [G loss: 0.896742]\n",
      "epoch:25 step:23982 [D loss: 0.669584, acc.: 55.47%] [G loss: 0.884308]\n",
      "epoch:25 step:23983 [D loss: 0.675512, acc.: 55.47%] [G loss: 0.913479]\n",
      "epoch:25 step:23984 [D loss: 0.692774, acc.: 56.25%] [G loss: 0.907216]\n",
      "epoch:25 step:23985 [D loss: 0.646816, acc.: 56.25%] [G loss: 0.912144]\n",
      "epoch:25 step:23986 [D loss: 0.673898, acc.: 55.47%] [G loss: 0.901413]\n",
      "epoch:25 step:23987 [D loss: 0.654607, acc.: 64.06%] [G loss: 0.898887]\n",
      "epoch:25 step:23988 [D loss: 0.664219, acc.: 57.81%] [G loss: 0.869267]\n",
      "epoch:25 step:23989 [D loss: 0.667791, acc.: 59.38%] [G loss: 0.931852]\n",
      "epoch:25 step:23990 [D loss: 0.640448, acc.: 60.16%] [G loss: 0.923427]\n",
      "epoch:25 step:23991 [D loss: 0.618946, acc.: 66.41%] [G loss: 0.926040]\n",
      "epoch:25 step:23992 [D loss: 0.635290, acc.: 64.84%] [G loss: 0.866482]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:23993 [D loss: 0.737911, acc.: 53.91%] [G loss: 0.917469]\n",
      "epoch:25 step:23994 [D loss: 0.642340, acc.: 65.62%] [G loss: 0.957352]\n",
      "epoch:25 step:23995 [D loss: 0.661934, acc.: 58.59%] [G loss: 0.937074]\n",
      "epoch:25 step:23996 [D loss: 0.672860, acc.: 57.81%] [G loss: 0.899664]\n",
      "epoch:25 step:23997 [D loss: 0.679639, acc.: 63.28%] [G loss: 0.900701]\n",
      "epoch:25 step:23998 [D loss: 0.671129, acc.: 60.94%] [G loss: 0.912856]\n",
      "epoch:25 step:23999 [D loss: 0.676417, acc.: 55.47%] [G loss: 0.891019]\n",
      "epoch:25 step:24000 [D loss: 0.669843, acc.: 57.03%] [G loss: 0.935076]\n",
      "##############\n",
      "[3.06039353 2.89270409 2.19459944 4.00126318 1.29442789 7.9295568\n",
      " 2.84059489 3.68622577 4.14192354 7.14868929]\n",
      "##########\n",
      "epoch:25 step:24001 [D loss: 0.634194, acc.: 63.28%] [G loss: 0.901306]\n",
      "epoch:25 step:24002 [D loss: 0.679828, acc.: 58.59%] [G loss: 0.842552]\n",
      "epoch:25 step:24003 [D loss: 0.666057, acc.: 58.59%] [G loss: 0.850940]\n",
      "epoch:25 step:24004 [D loss: 0.659299, acc.: 67.97%] [G loss: 0.866182]\n",
      "epoch:25 step:24005 [D loss: 0.681269, acc.: 53.91%] [G loss: 0.856298]\n",
      "epoch:25 step:24006 [D loss: 0.637131, acc.: 61.72%] [G loss: 0.800320]\n",
      "epoch:25 step:24007 [D loss: 0.616699, acc.: 74.22%] [G loss: 0.871962]\n",
      "epoch:25 step:24008 [D loss: 0.705671, acc.: 51.56%] [G loss: 0.857589]\n",
      "epoch:25 step:24009 [D loss: 0.641776, acc.: 61.72%] [G loss: 0.921255]\n",
      "epoch:25 step:24010 [D loss: 0.623169, acc.: 71.09%] [G loss: 0.938777]\n",
      "epoch:25 step:24011 [D loss: 0.672541, acc.: 59.38%] [G loss: 0.887051]\n",
      "epoch:25 step:24012 [D loss: 0.658166, acc.: 57.81%] [G loss: 0.872846]\n",
      "epoch:25 step:24013 [D loss: 0.690901, acc.: 55.47%] [G loss: 0.862319]\n",
      "epoch:25 step:24014 [D loss: 0.638014, acc.: 64.06%] [G loss: 0.867954]\n",
      "epoch:25 step:24015 [D loss: 0.645259, acc.: 64.06%] [G loss: 0.892180]\n",
      "epoch:25 step:24016 [D loss: 0.664141, acc.: 62.50%] [G loss: 0.892728]\n",
      "epoch:25 step:24017 [D loss: 0.662758, acc.: 60.94%] [G loss: 0.932263]\n",
      "epoch:25 step:24018 [D loss: 0.682495, acc.: 52.34%] [G loss: 0.945782]\n",
      "epoch:25 step:24019 [D loss: 0.615146, acc.: 69.53%] [G loss: 0.971418]\n",
      "epoch:25 step:24020 [D loss: 0.646443, acc.: 60.94%] [G loss: 0.975373]\n",
      "epoch:25 step:24021 [D loss: 0.660267, acc.: 61.72%] [G loss: 0.896283]\n",
      "epoch:25 step:24022 [D loss: 0.646657, acc.: 60.94%] [G loss: 0.914168]\n",
      "epoch:25 step:24023 [D loss: 0.654082, acc.: 57.03%] [G loss: 0.884348]\n",
      "epoch:25 step:24024 [D loss: 0.653551, acc.: 57.81%] [G loss: 0.896125]\n",
      "epoch:25 step:24025 [D loss: 0.649955, acc.: 60.16%] [G loss: 0.922845]\n",
      "epoch:25 step:24026 [D loss: 0.668497, acc.: 57.03%] [G loss: 0.874055]\n",
      "epoch:25 step:24027 [D loss: 0.635570, acc.: 64.06%] [G loss: 0.925097]\n",
      "epoch:25 step:24028 [D loss: 0.685164, acc.: 56.25%] [G loss: 0.913589]\n",
      "epoch:25 step:24029 [D loss: 0.679967, acc.: 57.81%] [G loss: 0.868342]\n",
      "epoch:25 step:24030 [D loss: 0.668281, acc.: 57.03%] [G loss: 0.867635]\n",
      "epoch:25 step:24031 [D loss: 0.634079, acc.: 64.06%] [G loss: 0.863424]\n",
      "epoch:25 step:24032 [D loss: 0.657480, acc.: 56.25%] [G loss: 0.864752]\n",
      "epoch:25 step:24033 [D loss: 0.649495, acc.: 58.59%] [G loss: 0.865392]\n",
      "epoch:25 step:24034 [D loss: 0.638954, acc.: 64.84%] [G loss: 0.886214]\n",
      "epoch:25 step:24035 [D loss: 0.666085, acc.: 59.38%] [G loss: 0.872574]\n",
      "epoch:25 step:24036 [D loss: 0.685975, acc.: 51.56%] [G loss: 0.889728]\n",
      "epoch:25 step:24037 [D loss: 0.681463, acc.: 57.81%] [G loss: 0.906369]\n",
      "epoch:25 step:24038 [D loss: 0.644929, acc.: 64.84%] [G loss: 0.879717]\n",
      "epoch:25 step:24039 [D loss: 0.669607, acc.: 59.38%] [G loss: 0.863198]\n",
      "epoch:25 step:24040 [D loss: 0.672799, acc.: 61.72%] [G loss: 0.837324]\n",
      "epoch:25 step:24041 [D loss: 0.637205, acc.: 67.19%] [G loss: 0.876810]\n",
      "epoch:25 step:24042 [D loss: 0.661120, acc.: 54.69%] [G loss: 0.928052]\n",
      "epoch:25 step:24043 [D loss: 0.620911, acc.: 65.62%] [G loss: 0.923547]\n",
      "epoch:25 step:24044 [D loss: 0.668183, acc.: 58.59%] [G loss: 0.909231]\n",
      "epoch:25 step:24045 [D loss: 0.647110, acc.: 66.41%] [G loss: 0.920280]\n",
      "epoch:25 step:24046 [D loss: 0.688941, acc.: 53.91%] [G loss: 0.849758]\n",
      "epoch:25 step:24047 [D loss: 0.637521, acc.: 67.97%] [G loss: 0.838888]\n",
      "epoch:25 step:24048 [D loss: 0.630501, acc.: 66.41%] [G loss: 0.862309]\n",
      "epoch:25 step:24049 [D loss: 0.666814, acc.: 59.38%] [G loss: 0.896773]\n",
      "epoch:25 step:24050 [D loss: 0.659436, acc.: 58.59%] [G loss: 0.932530]\n",
      "epoch:25 step:24051 [D loss: 0.646326, acc.: 66.41%] [G loss: 0.928202]\n",
      "epoch:25 step:24052 [D loss: 0.610272, acc.: 68.75%] [G loss: 0.890831]\n",
      "epoch:25 step:24053 [D loss: 0.695838, acc.: 50.78%] [G loss: 0.902314]\n",
      "epoch:25 step:24054 [D loss: 0.660788, acc.: 57.81%] [G loss: 0.819275]\n",
      "epoch:25 step:24055 [D loss: 0.673785, acc.: 54.69%] [G loss: 0.879666]\n",
      "epoch:25 step:24056 [D loss: 0.631838, acc.: 61.72%] [G loss: 0.842859]\n",
      "epoch:25 step:24057 [D loss: 0.655061, acc.: 54.69%] [G loss: 0.869320]\n",
      "epoch:25 step:24058 [D loss: 0.619625, acc.: 73.44%] [G loss: 0.893221]\n",
      "epoch:25 step:24059 [D loss: 0.651359, acc.: 64.06%] [G loss: 0.896987]\n",
      "epoch:25 step:24060 [D loss: 0.654295, acc.: 64.06%] [G loss: 0.864970]\n",
      "epoch:25 step:24061 [D loss: 0.648027, acc.: 66.41%] [G loss: 0.915897]\n",
      "epoch:25 step:24062 [D loss: 0.668437, acc.: 57.03%] [G loss: 0.964681]\n",
      "epoch:25 step:24063 [D loss: 0.668124, acc.: 60.94%] [G loss: 0.923074]\n",
      "epoch:25 step:24064 [D loss: 0.689059, acc.: 53.12%] [G loss: 0.899872]\n",
      "epoch:25 step:24065 [D loss: 0.648078, acc.: 58.59%] [G loss: 0.943607]\n",
      "epoch:25 step:24066 [D loss: 0.682091, acc.: 57.81%] [G loss: 0.923940]\n",
      "epoch:25 step:24067 [D loss: 0.692203, acc.: 62.50%] [G loss: 0.916616]\n",
      "epoch:25 step:24068 [D loss: 0.699317, acc.: 53.91%] [G loss: 0.924028]\n",
      "epoch:25 step:24069 [D loss: 0.661961, acc.: 55.47%] [G loss: 0.921781]\n",
      "epoch:25 step:24070 [D loss: 0.674176, acc.: 58.59%] [G loss: 0.892709]\n",
      "epoch:25 step:24071 [D loss: 0.623593, acc.: 67.19%] [G loss: 0.827916]\n",
      "epoch:25 step:24072 [D loss: 0.740846, acc.: 45.31%] [G loss: 0.837824]\n",
      "epoch:25 step:24073 [D loss: 0.624804, acc.: 69.53%] [G loss: 0.824109]\n",
      "epoch:25 step:24074 [D loss: 0.650639, acc.: 60.94%] [G loss: 0.956790]\n",
      "epoch:25 step:24075 [D loss: 0.689152, acc.: 52.34%] [G loss: 0.900373]\n",
      "epoch:25 step:24076 [D loss: 0.609666, acc.: 65.62%] [G loss: 0.912358]\n",
      "epoch:25 step:24077 [D loss: 0.687477, acc.: 57.81%] [G loss: 0.859104]\n",
      "epoch:25 step:24078 [D loss: 0.645268, acc.: 67.97%] [G loss: 0.922103]\n",
      "epoch:25 step:24079 [D loss: 0.696349, acc.: 50.78%] [G loss: 0.884625]\n",
      "epoch:25 step:24080 [D loss: 0.687943, acc.: 54.69%] [G loss: 0.918400]\n",
      "epoch:25 step:24081 [D loss: 0.659526, acc.: 56.25%] [G loss: 0.899799]\n",
      "epoch:25 step:24082 [D loss: 0.635684, acc.: 64.84%] [G loss: 0.892262]\n",
      "epoch:25 step:24083 [D loss: 0.674110, acc.: 56.25%] [G loss: 0.866655]\n",
      "epoch:25 step:24084 [D loss: 0.674482, acc.: 59.38%] [G loss: 0.876021]\n",
      "epoch:25 step:24085 [D loss: 0.663317, acc.: 60.16%] [G loss: 0.906592]\n",
      "epoch:25 step:24086 [D loss: 0.653049, acc.: 66.41%] [G loss: 0.882672]\n",
      "epoch:25 step:24087 [D loss: 0.682241, acc.: 57.81%] [G loss: 0.859242]\n",
      "epoch:25 step:24088 [D loss: 0.640382, acc.: 64.06%] [G loss: 0.854126]\n",
      "epoch:25 step:24089 [D loss: 0.636640, acc.: 66.41%] [G loss: 0.870269]\n",
      "epoch:25 step:24090 [D loss: 0.715522, acc.: 57.81%] [G loss: 0.869645]\n",
      "epoch:25 step:24091 [D loss: 0.658051, acc.: 63.28%] [G loss: 0.940175]\n",
      "epoch:25 step:24092 [D loss: 0.670727, acc.: 57.03%] [G loss: 0.875433]\n",
      "epoch:25 step:24093 [D loss: 0.686073, acc.: 61.72%] [G loss: 0.911852]\n",
      "epoch:25 step:24094 [D loss: 0.652326, acc.: 61.72%] [G loss: 0.907127]\n",
      "epoch:25 step:24095 [D loss: 0.642218, acc.: 57.03%] [G loss: 0.903897]\n",
      "epoch:25 step:24096 [D loss: 0.682923, acc.: 57.81%] [G loss: 0.869326]\n",
      "epoch:25 step:24097 [D loss: 0.654063, acc.: 58.59%] [G loss: 0.880770]\n",
      "epoch:25 step:24098 [D loss: 0.699654, acc.: 54.69%] [G loss: 0.879568]\n",
      "epoch:25 step:24099 [D loss: 0.635424, acc.: 64.06%] [G loss: 0.859499]\n",
      "epoch:25 step:24100 [D loss: 0.655832, acc.: 59.38%] [G loss: 0.882596]\n",
      "epoch:25 step:24101 [D loss: 0.655474, acc.: 59.38%] [G loss: 0.898164]\n",
      "epoch:25 step:24102 [D loss: 0.668755, acc.: 55.47%] [G loss: 0.891187]\n",
      "epoch:25 step:24103 [D loss: 0.636535, acc.: 69.53%] [G loss: 0.892518]\n",
      "epoch:25 step:24104 [D loss: 0.650679, acc.: 64.84%] [G loss: 0.916665]\n",
      "epoch:25 step:24105 [D loss: 0.682145, acc.: 51.56%] [G loss: 0.887859]\n",
      "epoch:25 step:24106 [D loss: 0.669753, acc.: 61.72%] [G loss: 0.870332]\n",
      "epoch:25 step:24107 [D loss: 0.644280, acc.: 59.38%] [G loss: 0.908476]\n",
      "epoch:25 step:24108 [D loss: 0.681540, acc.: 53.91%] [G loss: 0.894618]\n",
      "epoch:25 step:24109 [D loss: 0.638279, acc.: 67.19%] [G loss: 0.881328]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:24110 [D loss: 0.672391, acc.: 53.91%] [G loss: 0.892139]\n",
      "epoch:25 step:24111 [D loss: 0.646350, acc.: 60.94%] [G loss: 0.934839]\n",
      "epoch:25 step:24112 [D loss: 0.655228, acc.: 60.94%] [G loss: 0.923041]\n",
      "epoch:25 step:24113 [D loss: 0.645769, acc.: 60.94%] [G loss: 0.853173]\n",
      "epoch:25 step:24114 [D loss: 0.656328, acc.: 60.94%] [G loss: 0.929110]\n",
      "epoch:25 step:24115 [D loss: 0.681715, acc.: 60.16%] [G loss: 0.873120]\n",
      "epoch:25 step:24116 [D loss: 0.689957, acc.: 51.56%] [G loss: 0.901289]\n",
      "epoch:25 step:24117 [D loss: 0.624176, acc.: 64.84%] [G loss: 0.898361]\n",
      "epoch:25 step:24118 [D loss: 0.670285, acc.: 54.69%] [G loss: 0.903945]\n",
      "epoch:25 step:24119 [D loss: 0.661703, acc.: 63.28%] [G loss: 0.882766]\n",
      "epoch:25 step:24120 [D loss: 0.630207, acc.: 60.94%] [G loss: 0.869157]\n",
      "epoch:25 step:24121 [D loss: 0.647181, acc.: 63.28%] [G loss: 0.907822]\n",
      "epoch:25 step:24122 [D loss: 0.632886, acc.: 64.84%] [G loss: 0.971397]\n",
      "epoch:25 step:24123 [D loss: 0.665976, acc.: 57.03%] [G loss: 0.833259]\n",
      "epoch:25 step:24124 [D loss: 0.683910, acc.: 55.47%] [G loss: 0.936098]\n",
      "epoch:25 step:24125 [D loss: 0.655390, acc.: 61.72%] [G loss: 0.835620]\n",
      "epoch:25 step:24126 [D loss: 0.678835, acc.: 58.59%] [G loss: 0.859981]\n",
      "epoch:25 step:24127 [D loss: 0.663890, acc.: 55.47%] [G loss: 0.899143]\n",
      "epoch:25 step:24128 [D loss: 0.675057, acc.: 54.69%] [G loss: 0.919118]\n",
      "epoch:25 step:24129 [D loss: 0.651496, acc.: 64.84%] [G loss: 0.973177]\n",
      "epoch:25 step:24130 [D loss: 0.663233, acc.: 59.38%] [G loss: 0.910942]\n",
      "epoch:25 step:24131 [D loss: 0.661188, acc.: 63.28%] [G loss: 0.900153]\n",
      "epoch:25 step:24132 [D loss: 0.661058, acc.: 61.72%] [G loss: 0.953409]\n",
      "epoch:25 step:24133 [D loss: 0.664910, acc.: 59.38%] [G loss: 0.886785]\n",
      "epoch:25 step:24134 [D loss: 0.690577, acc.: 58.59%] [G loss: 0.860562]\n",
      "epoch:25 step:24135 [D loss: 0.600488, acc.: 68.75%] [G loss: 0.927835]\n",
      "epoch:25 step:24136 [D loss: 0.629800, acc.: 61.72%] [G loss: 0.879455]\n",
      "epoch:25 step:24137 [D loss: 0.690991, acc.: 57.81%] [G loss: 1.001551]\n",
      "epoch:25 step:24138 [D loss: 0.672174, acc.: 57.03%] [G loss: 0.873662]\n",
      "epoch:25 step:24139 [D loss: 0.661736, acc.: 57.03%] [G loss: 0.912624]\n",
      "epoch:25 step:24140 [D loss: 0.675264, acc.: 59.38%] [G loss: 0.875771]\n",
      "epoch:25 step:24141 [D loss: 0.658403, acc.: 60.94%] [G loss: 0.869448]\n",
      "epoch:25 step:24142 [D loss: 0.644421, acc.: 64.06%] [G loss: 0.920656]\n",
      "epoch:25 step:24143 [D loss: 0.611995, acc.: 67.19%] [G loss: 0.911532]\n",
      "epoch:25 step:24144 [D loss: 0.669312, acc.: 64.84%] [G loss: 0.888057]\n",
      "epoch:25 step:24145 [D loss: 0.629455, acc.: 63.28%] [G loss: 0.895342]\n",
      "epoch:25 step:24146 [D loss: 0.635008, acc.: 63.28%] [G loss: 0.940133]\n",
      "epoch:25 step:24147 [D loss: 0.636271, acc.: 64.84%] [G loss: 0.925556]\n",
      "epoch:25 step:24148 [D loss: 0.672616, acc.: 54.69%] [G loss: 0.906503]\n",
      "epoch:25 step:24149 [D loss: 0.642317, acc.: 65.62%] [G loss: 0.889889]\n",
      "epoch:25 step:24150 [D loss: 0.644051, acc.: 62.50%] [G loss: 0.883641]\n",
      "epoch:25 step:24151 [D loss: 0.718176, acc.: 50.78%] [G loss: 0.909594]\n",
      "epoch:25 step:24152 [D loss: 0.608383, acc.: 70.31%] [G loss: 0.966968]\n",
      "epoch:25 step:24153 [D loss: 0.682483, acc.: 54.69%] [G loss: 0.899654]\n",
      "epoch:25 step:24154 [D loss: 0.623160, acc.: 66.41%] [G loss: 0.928605]\n",
      "epoch:25 step:24155 [D loss: 0.675168, acc.: 56.25%] [G loss: 0.930455]\n",
      "epoch:25 step:24156 [D loss: 0.639858, acc.: 61.72%] [G loss: 0.895299]\n",
      "epoch:25 step:24157 [D loss: 0.622781, acc.: 66.41%] [G loss: 0.978384]\n",
      "epoch:25 step:24158 [D loss: 0.647287, acc.: 63.28%] [G loss: 0.894527]\n",
      "epoch:25 step:24159 [D loss: 0.615187, acc.: 67.19%] [G loss: 0.873570]\n",
      "epoch:25 step:24160 [D loss: 0.665864, acc.: 51.56%] [G loss: 0.916900]\n",
      "epoch:25 step:24161 [D loss: 0.647718, acc.: 57.81%] [G loss: 0.888534]\n",
      "epoch:25 step:24162 [D loss: 0.663806, acc.: 64.06%] [G loss: 0.897367]\n",
      "epoch:25 step:24163 [D loss: 0.685653, acc.: 53.12%] [G loss: 0.853419]\n",
      "epoch:25 step:24164 [D loss: 0.665654, acc.: 57.81%] [G loss: 0.865970]\n",
      "epoch:25 step:24165 [D loss: 0.674065, acc.: 64.84%] [G loss: 0.886721]\n",
      "epoch:25 step:24166 [D loss: 0.641588, acc.: 61.72%] [G loss: 0.882490]\n",
      "epoch:25 step:24167 [D loss: 0.653239, acc.: 64.06%] [G loss: 0.915582]\n",
      "epoch:25 step:24168 [D loss: 0.703752, acc.: 56.25%] [G loss: 0.902238]\n",
      "epoch:25 step:24169 [D loss: 0.646521, acc.: 66.41%] [G loss: 0.840846]\n",
      "epoch:25 step:24170 [D loss: 0.681214, acc.: 59.38%] [G loss: 0.897503]\n",
      "epoch:25 step:24171 [D loss: 0.649067, acc.: 63.28%] [G loss: 0.891295]\n",
      "epoch:25 step:24172 [D loss: 0.645912, acc.: 63.28%] [G loss: 0.919352]\n",
      "epoch:25 step:24173 [D loss: 0.677443, acc.: 57.81%] [G loss: 0.950154]\n",
      "epoch:25 step:24174 [D loss: 0.658237, acc.: 60.16%] [G loss: 1.032858]\n",
      "epoch:25 step:24175 [D loss: 0.675582, acc.: 59.38%] [G loss: 0.922286]\n",
      "epoch:25 step:24176 [D loss: 0.654390, acc.: 64.06%] [G loss: 0.866805]\n",
      "epoch:25 step:24177 [D loss: 0.664874, acc.: 58.59%] [G loss: 0.893443]\n",
      "epoch:25 step:24178 [D loss: 0.651462, acc.: 58.59%] [G loss: 0.895693]\n",
      "epoch:25 step:24179 [D loss: 0.700932, acc.: 57.03%] [G loss: 0.964085]\n",
      "epoch:25 step:24180 [D loss: 0.709229, acc.: 56.25%] [G loss: 0.970840]\n",
      "epoch:25 step:24181 [D loss: 0.630613, acc.: 58.59%] [G loss: 0.912118]\n",
      "epoch:25 step:24182 [D loss: 0.612486, acc.: 64.84%] [G loss: 0.954345]\n",
      "epoch:25 step:24183 [D loss: 0.660590, acc.: 63.28%] [G loss: 0.848530]\n",
      "epoch:25 step:24184 [D loss: 0.665178, acc.: 61.72%] [G loss: 0.880713]\n",
      "epoch:25 step:24185 [D loss: 0.681752, acc.: 58.59%] [G loss: 0.854773]\n",
      "epoch:25 step:24186 [D loss: 0.662560, acc.: 53.91%] [G loss: 0.901811]\n",
      "epoch:25 step:24187 [D loss: 0.676123, acc.: 57.81%] [G loss: 0.804311]\n",
      "epoch:25 step:24188 [D loss: 0.649768, acc.: 64.84%] [G loss: 0.882853]\n",
      "epoch:25 step:24189 [D loss: 0.620866, acc.: 65.62%] [G loss: 0.915935]\n",
      "epoch:25 step:24190 [D loss: 0.661769, acc.: 57.03%] [G loss: 0.910400]\n",
      "epoch:25 step:24191 [D loss: 0.655882, acc.: 60.94%] [G loss: 0.887446]\n",
      "epoch:25 step:24192 [D loss: 0.651730, acc.: 62.50%] [G loss: 0.884006]\n",
      "epoch:25 step:24193 [D loss: 0.649580, acc.: 64.84%] [G loss: 0.867334]\n",
      "epoch:25 step:24194 [D loss: 0.647739, acc.: 66.41%] [G loss: 0.929899]\n",
      "epoch:25 step:24195 [D loss: 0.647132, acc.: 59.38%] [G loss: 0.904831]\n",
      "epoch:25 step:24196 [D loss: 0.670081, acc.: 58.59%] [G loss: 0.944342]\n",
      "epoch:25 step:24197 [D loss: 0.622049, acc.: 67.19%] [G loss: 0.945906]\n",
      "epoch:25 step:24198 [D loss: 0.643876, acc.: 61.72%] [G loss: 0.914431]\n",
      "epoch:25 step:24199 [D loss: 0.658560, acc.: 57.03%] [G loss: 0.924150]\n",
      "epoch:25 step:24200 [D loss: 0.675642, acc.: 59.38%] [G loss: 0.935300]\n",
      "##############\n",
      "[2.66060777 2.25205315 2.05914085 3.57960993 1.24131345 8.05891513\n",
      " 2.76708918 3.48491043 4.26224158 8.14868929]\n",
      "##########\n",
      "epoch:25 step:24201 [D loss: 0.668864, acc.: 64.84%] [G loss: 0.875156]\n",
      "epoch:25 step:24202 [D loss: 0.626945, acc.: 65.62%] [G loss: 0.923533]\n",
      "epoch:25 step:24203 [D loss: 0.611641, acc.: 67.19%] [G loss: 0.959975]\n",
      "epoch:25 step:24204 [D loss: 0.668085, acc.: 64.06%] [G loss: 0.847335]\n",
      "epoch:25 step:24205 [D loss: 0.641665, acc.: 60.16%] [G loss: 0.907360]\n",
      "epoch:25 step:24206 [D loss: 0.675434, acc.: 57.81%] [G loss: 0.919727]\n",
      "epoch:25 step:24207 [D loss: 0.629775, acc.: 65.62%] [G loss: 0.929366]\n",
      "epoch:25 step:24208 [D loss: 0.667524, acc.: 60.16%] [G loss: 0.933061]\n",
      "epoch:25 step:24209 [D loss: 0.633597, acc.: 60.94%] [G loss: 0.921872]\n",
      "epoch:25 step:24210 [D loss: 0.639639, acc.: 63.28%] [G loss: 0.853732]\n",
      "epoch:25 step:24211 [D loss: 0.711692, acc.: 49.22%] [G loss: 0.912653]\n",
      "epoch:25 step:24212 [D loss: 0.658971, acc.: 57.81%] [G loss: 0.896750]\n",
      "epoch:25 step:24213 [D loss: 0.632551, acc.: 62.50%] [G loss: 0.912750]\n",
      "epoch:25 step:24214 [D loss: 0.657839, acc.: 61.72%] [G loss: 0.870378]\n",
      "epoch:25 step:24215 [D loss: 0.645458, acc.: 64.06%] [G loss: 0.889133]\n",
      "epoch:25 step:24216 [D loss: 0.583223, acc.: 75.00%] [G loss: 0.880655]\n",
      "epoch:25 step:24217 [D loss: 0.651729, acc.: 69.53%] [G loss: 0.900173]\n",
      "epoch:25 step:24218 [D loss: 0.630481, acc.: 62.50%] [G loss: 0.918046]\n",
      "epoch:25 step:24219 [D loss: 0.648345, acc.: 58.59%] [G loss: 0.927651]\n",
      "epoch:25 step:24220 [D loss: 0.655217, acc.: 60.16%] [G loss: 0.891750]\n",
      "epoch:25 step:24221 [D loss: 0.659955, acc.: 60.94%] [G loss: 0.891716]\n",
      "epoch:25 step:24222 [D loss: 0.673517, acc.: 58.59%] [G loss: 0.875801]\n",
      "epoch:25 step:24223 [D loss: 0.677868, acc.: 53.91%] [G loss: 0.862764]\n",
      "epoch:25 step:24224 [D loss: 0.669261, acc.: 59.38%] [G loss: 0.875202]\n",
      "epoch:25 step:24225 [D loss: 0.679583, acc.: 57.81%] [G loss: 0.926721]\n",
      "epoch:25 step:24226 [D loss: 0.642747, acc.: 61.72%] [G loss: 0.856344]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:24227 [D loss: 0.678958, acc.: 56.25%] [G loss: 0.955668]\n",
      "epoch:25 step:24228 [D loss: 0.679859, acc.: 57.03%] [G loss: 0.865844]\n",
      "epoch:25 step:24229 [D loss: 0.686703, acc.: 53.91%] [G loss: 0.864311]\n",
      "epoch:25 step:24230 [D loss: 0.673461, acc.: 57.81%] [G loss: 0.889225]\n",
      "epoch:25 step:24231 [D loss: 0.659090, acc.: 60.16%] [G loss: 0.856977]\n",
      "epoch:25 step:24232 [D loss: 0.654962, acc.: 62.50%] [G loss: 0.910540]\n",
      "epoch:25 step:24233 [D loss: 0.605929, acc.: 70.31%] [G loss: 0.877489]\n",
      "epoch:25 step:24234 [D loss: 0.637821, acc.: 62.50%] [G loss: 0.868971]\n",
      "epoch:25 step:24235 [D loss: 0.683144, acc.: 55.47%] [G loss: 0.891001]\n",
      "epoch:25 step:24236 [D loss: 0.684562, acc.: 58.59%] [G loss: 0.910272]\n",
      "epoch:25 step:24237 [D loss: 0.680382, acc.: 57.81%] [G loss: 0.926730]\n",
      "epoch:25 step:24238 [D loss: 0.670888, acc.: 53.91%] [G loss: 0.955964]\n",
      "epoch:25 step:24239 [D loss: 0.654343, acc.: 62.50%] [G loss: 0.987717]\n",
      "epoch:25 step:24240 [D loss: 0.658609, acc.: 64.06%] [G loss: 0.936954]\n",
      "epoch:25 step:24241 [D loss: 0.639063, acc.: 61.72%] [G loss: 0.925114]\n",
      "epoch:25 step:24242 [D loss: 0.718114, acc.: 48.44%] [G loss: 0.907552]\n",
      "epoch:25 step:24243 [D loss: 0.666024, acc.: 58.59%] [G loss: 0.902029]\n",
      "epoch:25 step:24244 [D loss: 0.670017, acc.: 53.91%] [G loss: 0.853818]\n",
      "epoch:25 step:24245 [D loss: 0.655522, acc.: 60.16%] [G loss: 0.881688]\n",
      "epoch:25 step:24246 [D loss: 0.652818, acc.: 57.81%] [G loss: 0.881038]\n",
      "epoch:25 step:24247 [D loss: 0.635662, acc.: 65.62%] [G loss: 0.921596]\n",
      "epoch:25 step:24248 [D loss: 0.688940, acc.: 50.78%] [G loss: 0.892332]\n",
      "epoch:25 step:24249 [D loss: 0.649293, acc.: 60.16%] [G loss: 0.872078]\n",
      "epoch:25 step:24250 [D loss: 0.633338, acc.: 62.50%] [G loss: 0.885651]\n",
      "epoch:25 step:24251 [D loss: 0.627285, acc.: 64.84%] [G loss: 0.891491]\n",
      "epoch:25 step:24252 [D loss: 0.670882, acc.: 58.59%] [G loss: 0.840037]\n",
      "epoch:25 step:24253 [D loss: 0.667750, acc.: 59.38%] [G loss: 0.883334]\n",
      "epoch:25 step:24254 [D loss: 0.635622, acc.: 61.72%] [G loss: 0.940956]\n",
      "epoch:25 step:24255 [D loss: 0.671497, acc.: 52.34%] [G loss: 0.891297]\n",
      "epoch:25 step:24256 [D loss: 0.672329, acc.: 59.38%] [G loss: 0.850663]\n",
      "epoch:25 step:24257 [D loss: 0.642491, acc.: 59.38%] [G loss: 0.890582]\n",
      "epoch:25 step:24258 [D loss: 0.645979, acc.: 62.50%] [G loss: 0.877210]\n",
      "epoch:25 step:24259 [D loss: 0.656225, acc.: 60.94%] [G loss: 0.870792]\n",
      "epoch:25 step:24260 [D loss: 0.681072, acc.: 58.59%] [G loss: 0.837649]\n",
      "epoch:25 step:24261 [D loss: 0.665980, acc.: 58.59%] [G loss: 0.868535]\n",
      "epoch:25 step:24262 [D loss: 0.644270, acc.: 60.16%] [G loss: 0.924342]\n",
      "epoch:25 step:24263 [D loss: 0.674907, acc.: 56.25%] [G loss: 0.905380]\n",
      "epoch:25 step:24264 [D loss: 0.692058, acc.: 56.25%] [G loss: 0.902200]\n",
      "epoch:25 step:24265 [D loss: 0.640894, acc.: 60.94%] [G loss: 0.895067]\n",
      "epoch:25 step:24266 [D loss: 0.708895, acc.: 51.56%] [G loss: 0.873382]\n",
      "epoch:25 step:24267 [D loss: 0.675702, acc.: 57.03%] [G loss: 0.915393]\n",
      "epoch:25 step:24268 [D loss: 0.688237, acc.: 62.50%] [G loss: 0.873068]\n",
      "epoch:25 step:24269 [D loss: 0.660396, acc.: 60.16%] [G loss: 0.901002]\n",
      "epoch:25 step:24270 [D loss: 0.693893, acc.: 53.91%] [G loss: 0.837022]\n",
      "epoch:25 step:24271 [D loss: 0.668448, acc.: 59.38%] [G loss: 0.880995]\n",
      "epoch:25 step:24272 [D loss: 0.628744, acc.: 63.28%] [G loss: 0.911389]\n",
      "epoch:25 step:24273 [D loss: 0.646176, acc.: 59.38%] [G loss: 0.864385]\n",
      "epoch:25 step:24274 [D loss: 0.633506, acc.: 60.94%] [G loss: 0.910013]\n",
      "epoch:25 step:24275 [D loss: 0.619710, acc.: 63.28%] [G loss: 0.926314]\n",
      "epoch:25 step:24276 [D loss: 0.676736, acc.: 60.16%] [G loss: 0.914479]\n",
      "epoch:25 step:24277 [D loss: 0.648117, acc.: 64.84%] [G loss: 0.919037]\n",
      "epoch:25 step:24278 [D loss: 0.668316, acc.: 57.03%] [G loss: 0.854139]\n",
      "epoch:25 step:24279 [D loss: 0.654756, acc.: 61.72%] [G loss: 0.885784]\n",
      "epoch:25 step:24280 [D loss: 0.655523, acc.: 60.16%] [G loss: 0.904285]\n",
      "epoch:25 step:24281 [D loss: 0.619510, acc.: 65.62%] [G loss: 0.854098]\n",
      "epoch:25 step:24282 [D loss: 0.675451, acc.: 53.91%] [G loss: 0.867707]\n",
      "epoch:25 step:24283 [D loss: 0.660901, acc.: 58.59%] [G loss: 0.850720]\n",
      "epoch:25 step:24284 [D loss: 0.686999, acc.: 57.03%] [G loss: 0.836640]\n",
      "epoch:25 step:24285 [D loss: 0.672060, acc.: 55.47%] [G loss: 0.913510]\n",
      "epoch:25 step:24286 [D loss: 0.626385, acc.: 65.62%] [G loss: 0.889770]\n",
      "epoch:25 step:24287 [D loss: 0.641770, acc.: 66.41%] [G loss: 0.823186]\n",
      "epoch:25 step:24288 [D loss: 0.671137, acc.: 58.59%] [G loss: 0.883074]\n",
      "epoch:25 step:24289 [D loss: 0.675400, acc.: 57.81%] [G loss: 0.888462]\n",
      "epoch:25 step:24290 [D loss: 0.640244, acc.: 60.16%] [G loss: 0.887980]\n",
      "epoch:25 step:24291 [D loss: 0.644678, acc.: 60.16%] [G loss: 0.906311]\n",
      "epoch:25 step:24292 [D loss: 0.664735, acc.: 57.81%] [G loss: 0.866953]\n",
      "epoch:25 step:24293 [D loss: 0.629051, acc.: 65.62%] [G loss: 0.859382]\n",
      "epoch:25 step:24294 [D loss: 0.697438, acc.: 56.25%] [G loss: 0.878836]\n",
      "epoch:25 step:24295 [D loss: 0.668880, acc.: 54.69%] [G loss: 0.840888]\n",
      "epoch:25 step:24296 [D loss: 0.656455, acc.: 60.16%] [G loss: 0.959231]\n",
      "epoch:25 step:24297 [D loss: 0.656156, acc.: 61.72%] [G loss: 0.916354]\n",
      "epoch:25 step:24298 [D loss: 0.623084, acc.: 64.06%] [G loss: 0.899155]\n",
      "epoch:25 step:24299 [D loss: 0.620410, acc.: 69.53%] [G loss: 0.868931]\n",
      "epoch:25 step:24300 [D loss: 0.646911, acc.: 60.94%] [G loss: 0.883275]\n",
      "epoch:25 step:24301 [D loss: 0.680818, acc.: 56.25%] [G loss: 0.888679]\n",
      "epoch:25 step:24302 [D loss: 0.654711, acc.: 60.16%] [G loss: 0.940118]\n",
      "epoch:25 step:24303 [D loss: 0.638909, acc.: 64.84%] [G loss: 0.899788]\n",
      "epoch:25 step:24304 [D loss: 0.678135, acc.: 57.03%] [G loss: 0.938942]\n",
      "epoch:25 step:24305 [D loss: 0.631432, acc.: 65.62%] [G loss: 0.949859]\n",
      "epoch:25 step:24306 [D loss: 0.668729, acc.: 60.16%] [G loss: 0.869569]\n",
      "epoch:25 step:24307 [D loss: 0.648513, acc.: 63.28%] [G loss: 0.838246]\n",
      "epoch:25 step:24308 [D loss: 0.649029, acc.: 61.72%] [G loss: 0.853612]\n",
      "epoch:25 step:24309 [D loss: 0.676252, acc.: 56.25%] [G loss: 0.880467]\n",
      "epoch:25 step:24310 [D loss: 0.647555, acc.: 59.38%] [G loss: 0.844323]\n",
      "epoch:25 step:24311 [D loss: 0.650931, acc.: 59.38%] [G loss: 0.892905]\n",
      "epoch:25 step:24312 [D loss: 0.635939, acc.: 64.06%] [G loss: 0.870885]\n",
      "epoch:25 step:24313 [D loss: 0.647011, acc.: 62.50%] [G loss: 0.934529]\n",
      "epoch:25 step:24314 [D loss: 0.629915, acc.: 64.84%] [G loss: 0.926801]\n",
      "epoch:25 step:24315 [D loss: 0.709640, acc.: 49.22%] [G loss: 0.882472]\n",
      "epoch:25 step:24316 [D loss: 0.668335, acc.: 58.59%] [G loss: 0.892166]\n",
      "epoch:25 step:24317 [D loss: 0.660599, acc.: 59.38%] [G loss: 0.892340]\n",
      "epoch:25 step:24318 [D loss: 0.660310, acc.: 64.84%] [G loss: 0.887444]\n",
      "epoch:25 step:24319 [D loss: 0.620653, acc.: 65.62%] [G loss: 0.864046]\n",
      "epoch:25 step:24320 [D loss: 0.650882, acc.: 59.38%] [G loss: 0.884201]\n",
      "epoch:25 step:24321 [D loss: 0.666201, acc.: 57.03%] [G loss: 0.886100]\n",
      "epoch:25 step:24322 [D loss: 0.606937, acc.: 65.62%] [G loss: 0.889260]\n",
      "epoch:25 step:24323 [D loss: 0.663991, acc.: 63.28%] [G loss: 0.857862]\n",
      "epoch:25 step:24324 [D loss: 0.661331, acc.: 57.81%] [G loss: 0.836990]\n",
      "epoch:25 step:24325 [D loss: 0.679233, acc.: 58.59%] [G loss: 0.935802]\n",
      "epoch:25 step:24326 [D loss: 0.640232, acc.: 67.97%] [G loss: 0.886779]\n",
      "epoch:25 step:24327 [D loss: 0.675303, acc.: 57.03%] [G loss: 0.878321]\n",
      "epoch:25 step:24328 [D loss: 0.645729, acc.: 64.84%] [G loss: 0.868362]\n",
      "epoch:25 step:24329 [D loss: 0.642110, acc.: 60.94%] [G loss: 0.879211]\n",
      "epoch:25 step:24330 [D loss: 0.696881, acc.: 52.34%] [G loss: 0.871366]\n",
      "epoch:25 step:24331 [D loss: 0.608602, acc.: 66.41%] [G loss: 0.891488]\n",
      "epoch:25 step:24332 [D loss: 0.657185, acc.: 58.59%] [G loss: 0.933088]\n",
      "epoch:25 step:24333 [D loss: 0.687512, acc.: 58.59%] [G loss: 0.858822]\n",
      "epoch:25 step:24334 [D loss: 0.676702, acc.: 53.91%] [G loss: 0.836398]\n",
      "epoch:25 step:24335 [D loss: 0.691549, acc.: 50.78%] [G loss: 0.891641]\n",
      "epoch:25 step:24336 [D loss: 0.632522, acc.: 67.97%] [G loss: 0.927764]\n",
      "epoch:25 step:24337 [D loss: 0.698137, acc.: 54.69%] [G loss: 0.895890]\n",
      "epoch:25 step:24338 [D loss: 0.672670, acc.: 57.81%] [G loss: 0.898867]\n",
      "epoch:25 step:24339 [D loss: 0.658889, acc.: 61.72%] [G loss: 0.895192]\n",
      "epoch:25 step:24340 [D loss: 0.651595, acc.: 63.28%] [G loss: 0.857899]\n",
      "epoch:25 step:24341 [D loss: 0.673403, acc.: 54.69%] [G loss: 0.848192]\n",
      "epoch:25 step:24342 [D loss: 0.624384, acc.: 66.41%] [G loss: 0.857762]\n",
      "epoch:25 step:24343 [D loss: 0.684564, acc.: 57.03%] [G loss: 0.915484]\n",
      "epoch:25 step:24344 [D loss: 0.652579, acc.: 59.38%] [G loss: 0.845754]\n",
      "epoch:25 step:24345 [D loss: 0.629233, acc.: 65.62%] [G loss: 0.922417]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:25 step:24346 [D loss: 0.698456, acc.: 59.38%] [G loss: 0.872874]\n",
      "epoch:25 step:24347 [D loss: 0.662936, acc.: 60.16%] [G loss: 0.883306]\n",
      "epoch:25 step:24348 [D loss: 0.663417, acc.: 57.81%] [G loss: 0.881234]\n",
      "epoch:25 step:24349 [D loss: 0.665940, acc.: 60.94%] [G loss: 0.934956]\n",
      "epoch:25 step:24350 [D loss: 0.646157, acc.: 63.28%] [G loss: 0.885325]\n",
      "epoch:25 step:24351 [D loss: 0.654035, acc.: 57.81%] [G loss: 0.874519]\n",
      "epoch:25 step:24352 [D loss: 0.638091, acc.: 58.59%] [G loss: 0.856104]\n",
      "epoch:25 step:24353 [D loss: 0.657532, acc.: 57.81%] [G loss: 0.891501]\n",
      "epoch:25 step:24354 [D loss: 0.665078, acc.: 62.50%] [G loss: 0.827528]\n",
      "epoch:25 step:24355 [D loss: 0.636919, acc.: 63.28%] [G loss: 0.821741]\n",
      "epoch:25 step:24356 [D loss: 0.662117, acc.: 54.69%] [G loss: 0.927956]\n",
      "epoch:25 step:24357 [D loss: 0.642210, acc.: 62.50%] [G loss: 0.872892]\n",
      "epoch:25 step:24358 [D loss: 0.676197, acc.: 58.59%] [G loss: 0.843446]\n",
      "epoch:25 step:24359 [D loss: 0.629837, acc.: 66.41%] [G loss: 0.867864]\n",
      "epoch:25 step:24360 [D loss: 0.675976, acc.: 54.69%] [G loss: 0.884584]\n",
      "epoch:25 step:24361 [D loss: 0.669034, acc.: 58.59%] [G loss: 0.944473]\n",
      "epoch:25 step:24362 [D loss: 0.633738, acc.: 67.19%] [G loss: 0.926597]\n",
      "epoch:26 step:24363 [D loss: 0.650083, acc.: 63.28%] [G loss: 0.919771]\n",
      "epoch:26 step:24364 [D loss: 0.636163, acc.: 64.84%] [G loss: 0.867278]\n",
      "epoch:26 step:24365 [D loss: 0.649154, acc.: 60.94%] [G loss: 0.867832]\n",
      "epoch:26 step:24366 [D loss: 0.653271, acc.: 64.06%] [G loss: 0.865781]\n",
      "epoch:26 step:24367 [D loss: 0.660089, acc.: 60.16%] [G loss: 0.926667]\n",
      "epoch:26 step:24368 [D loss: 0.654195, acc.: 64.06%] [G loss: 0.867798]\n",
      "epoch:26 step:24369 [D loss: 0.680411, acc.: 60.16%] [G loss: 0.905566]\n",
      "epoch:26 step:24370 [D loss: 0.664096, acc.: 54.69%] [G loss: 0.851938]\n",
      "epoch:26 step:24371 [D loss: 0.660049, acc.: 61.72%] [G loss: 0.872626]\n",
      "epoch:26 step:24372 [D loss: 0.637635, acc.: 68.75%] [G loss: 0.940537]\n",
      "epoch:26 step:24373 [D loss: 0.666950, acc.: 55.47%] [G loss: 0.836991]\n",
      "epoch:26 step:24374 [D loss: 0.668359, acc.: 55.47%] [G loss: 0.897111]\n",
      "epoch:26 step:24375 [D loss: 0.686333, acc.: 54.69%] [G loss: 0.900960]\n",
      "epoch:26 step:24376 [D loss: 0.668130, acc.: 64.84%] [G loss: 0.886293]\n",
      "epoch:26 step:24377 [D loss: 0.638962, acc.: 62.50%] [G loss: 0.923766]\n",
      "epoch:26 step:24378 [D loss: 0.634850, acc.: 64.06%] [G loss: 0.839865]\n",
      "epoch:26 step:24379 [D loss: 0.690911, acc.: 62.50%] [G loss: 0.884984]\n",
      "epoch:26 step:24380 [D loss: 0.672429, acc.: 62.50%] [G loss: 0.876042]\n",
      "epoch:26 step:24381 [D loss: 0.655449, acc.: 65.62%] [G loss: 0.849580]\n",
      "epoch:26 step:24382 [D loss: 0.661994, acc.: 56.25%] [G loss: 0.909044]\n",
      "epoch:26 step:24383 [D loss: 0.654179, acc.: 58.59%] [G loss: 0.911088]\n",
      "epoch:26 step:24384 [D loss: 0.671660, acc.: 57.81%] [G loss: 0.931947]\n",
      "epoch:26 step:24385 [D loss: 0.665549, acc.: 59.38%] [G loss: 0.876041]\n",
      "epoch:26 step:24386 [D loss: 0.677156, acc.: 50.00%] [G loss: 0.865806]\n",
      "epoch:26 step:24387 [D loss: 0.632343, acc.: 64.84%] [G loss: 0.903580]\n",
      "epoch:26 step:24388 [D loss: 0.643701, acc.: 59.38%] [G loss: 0.908175]\n",
      "epoch:26 step:24389 [D loss: 0.653355, acc.: 59.38%] [G loss: 0.883443]\n",
      "epoch:26 step:24390 [D loss: 0.635391, acc.: 67.19%] [G loss: 0.915676]\n",
      "epoch:26 step:24391 [D loss: 0.627709, acc.: 66.41%] [G loss: 0.910237]\n",
      "epoch:26 step:24392 [D loss: 0.654088, acc.: 60.94%] [G loss: 0.923654]\n",
      "epoch:26 step:24393 [D loss: 0.650444, acc.: 67.19%] [G loss: 0.907914]\n",
      "epoch:26 step:24394 [D loss: 0.674897, acc.: 58.59%] [G loss: 0.916726]\n",
      "epoch:26 step:24395 [D loss: 0.648575, acc.: 63.28%] [G loss: 0.916484]\n",
      "epoch:26 step:24396 [D loss: 0.655148, acc.: 61.72%] [G loss: 0.919149]\n",
      "epoch:26 step:24397 [D loss: 0.676451, acc.: 55.47%] [G loss: 0.892142]\n",
      "epoch:26 step:24398 [D loss: 0.658716, acc.: 58.59%] [G loss: 0.937001]\n",
      "epoch:26 step:24399 [D loss: 0.681844, acc.: 52.34%] [G loss: 0.863604]\n",
      "epoch:26 step:24400 [D loss: 0.674129, acc.: 57.03%] [G loss: 0.889236]\n",
      "##############\n",
      "[3.03701656 2.05228008 2.40349326 3.37461213 1.14456749 7.47142398\n",
      " 2.86439856 3.4624047  4.18221189 7.14799875]\n",
      "##########\n",
      "epoch:26 step:24401 [D loss: 0.658965, acc.: 60.16%] [G loss: 0.878140]\n",
      "epoch:26 step:24402 [D loss: 0.659750, acc.: 59.38%] [G loss: 0.907416]\n",
      "epoch:26 step:24403 [D loss: 0.685558, acc.: 57.03%] [G loss: 0.893251]\n",
      "epoch:26 step:24404 [D loss: 0.647555, acc.: 60.16%] [G loss: 0.870588]\n",
      "epoch:26 step:24405 [D loss: 0.653146, acc.: 57.03%] [G loss: 0.870842]\n",
      "epoch:26 step:24406 [D loss: 0.641111, acc.: 57.81%] [G loss: 0.934921]\n",
      "epoch:26 step:24407 [D loss: 0.670806, acc.: 57.81%] [G loss: 0.893925]\n",
      "epoch:26 step:24408 [D loss: 0.632148, acc.: 63.28%] [G loss: 0.896639]\n",
      "epoch:26 step:24409 [D loss: 0.684149, acc.: 54.69%] [G loss: 0.868822]\n",
      "epoch:26 step:24410 [D loss: 0.650551, acc.: 60.94%] [G loss: 0.896813]\n",
      "epoch:26 step:24411 [D loss: 0.626200, acc.: 62.50%] [G loss: 0.877093]\n",
      "epoch:26 step:24412 [D loss: 0.647277, acc.: 61.72%] [G loss: 0.875884]\n",
      "epoch:26 step:24413 [D loss: 0.650907, acc.: 64.84%] [G loss: 0.900174]\n",
      "epoch:26 step:24414 [D loss: 0.625045, acc.: 61.72%] [G loss: 0.917068]\n",
      "epoch:26 step:24415 [D loss: 0.637570, acc.: 66.41%] [G loss: 0.899648]\n",
      "epoch:26 step:24416 [D loss: 0.654553, acc.: 61.72%] [G loss: 0.880929]\n",
      "epoch:26 step:24417 [D loss: 0.639612, acc.: 63.28%] [G loss: 0.894945]\n",
      "epoch:26 step:24418 [D loss: 0.672899, acc.: 57.03%] [G loss: 0.896581]\n",
      "epoch:26 step:24419 [D loss: 0.686977, acc.: 58.59%] [G loss: 0.884212]\n",
      "epoch:26 step:24420 [D loss: 0.683942, acc.: 61.72%] [G loss: 0.920702]\n",
      "epoch:26 step:24421 [D loss: 0.615291, acc.: 69.53%] [G loss: 0.940262]\n",
      "epoch:26 step:24422 [D loss: 0.666155, acc.: 61.72%] [G loss: 0.954685]\n",
      "epoch:26 step:24423 [D loss: 0.689347, acc.: 50.78%] [G loss: 0.878187]\n",
      "epoch:26 step:24424 [D loss: 0.659956, acc.: 57.81%] [G loss: 0.872610]\n",
      "epoch:26 step:24425 [D loss: 0.659847, acc.: 59.38%] [G loss: 0.912057]\n",
      "epoch:26 step:24426 [D loss: 0.658448, acc.: 65.62%] [G loss: 0.909404]\n",
      "epoch:26 step:24427 [D loss: 0.675417, acc.: 56.25%] [G loss: 0.905082]\n",
      "epoch:26 step:24428 [D loss: 0.665535, acc.: 56.25%] [G loss: 0.911119]\n",
      "epoch:26 step:24429 [D loss: 0.687323, acc.: 57.03%] [G loss: 0.916821]\n",
      "epoch:26 step:24430 [D loss: 0.635432, acc.: 60.94%] [G loss: 0.936377]\n",
      "epoch:26 step:24431 [D loss: 0.615681, acc.: 64.06%] [G loss: 0.917753]\n",
      "epoch:26 step:24432 [D loss: 0.641372, acc.: 64.06%] [G loss: 0.929837]\n",
      "epoch:26 step:24433 [D loss: 0.629097, acc.: 62.50%] [G loss: 0.919430]\n",
      "epoch:26 step:24434 [D loss: 0.653856, acc.: 61.72%] [G loss: 0.940416]\n",
      "epoch:26 step:24435 [D loss: 0.602281, acc.: 75.78%] [G loss: 0.916736]\n",
      "epoch:26 step:24436 [D loss: 0.606679, acc.: 70.31%] [G loss: 0.980906]\n",
      "epoch:26 step:24437 [D loss: 0.674866, acc.: 50.78%] [G loss: 0.882338]\n",
      "epoch:26 step:24438 [D loss: 0.645579, acc.: 64.84%] [G loss: 0.879669]\n",
      "epoch:26 step:24439 [D loss: 0.688341, acc.: 57.03%] [G loss: 0.926337]\n",
      "epoch:26 step:24440 [D loss: 0.628620, acc.: 67.19%] [G loss: 0.931812]\n",
      "epoch:26 step:24441 [D loss: 0.653546, acc.: 64.06%] [G loss: 0.904522]\n",
      "epoch:26 step:24442 [D loss: 0.651074, acc.: 61.72%] [G loss: 0.904929]\n",
      "epoch:26 step:24443 [D loss: 0.658260, acc.: 60.16%] [G loss: 0.895972]\n",
      "epoch:26 step:24444 [D loss: 0.638875, acc.: 61.72%] [G loss: 0.868856]\n",
      "epoch:26 step:24445 [D loss: 0.637558, acc.: 63.28%] [G loss: 0.878111]\n",
      "epoch:26 step:24446 [D loss: 0.694751, acc.: 52.34%] [G loss: 0.901389]\n",
      "epoch:26 step:24447 [D loss: 0.658637, acc.: 58.59%] [G loss: 0.908877]\n",
      "epoch:26 step:24448 [D loss: 0.649236, acc.: 64.06%] [G loss: 0.927383]\n",
      "epoch:26 step:24449 [D loss: 0.669347, acc.: 59.38%] [G loss: 0.871334]\n",
      "epoch:26 step:24450 [D loss: 0.711420, acc.: 50.78%] [G loss: 0.895295]\n",
      "epoch:26 step:24451 [D loss: 0.644792, acc.: 65.62%] [G loss: 0.933597]\n",
      "epoch:26 step:24452 [D loss: 0.658472, acc.: 59.38%] [G loss: 0.923001]\n",
      "epoch:26 step:24453 [D loss: 0.690385, acc.: 53.12%] [G loss: 0.842733]\n",
      "epoch:26 step:24454 [D loss: 0.650162, acc.: 57.03%] [G loss: 0.878918]\n",
      "epoch:26 step:24455 [D loss: 0.652164, acc.: 64.06%] [G loss: 0.913251]\n",
      "epoch:26 step:24456 [D loss: 0.644744, acc.: 59.38%] [G loss: 0.887316]\n",
      "epoch:26 step:24457 [D loss: 0.640967, acc.: 64.84%] [G loss: 0.862660]\n",
      "epoch:26 step:24458 [D loss: 0.661568, acc.: 62.50%] [G loss: 0.878602]\n",
      "epoch:26 step:24459 [D loss: 0.639937, acc.: 62.50%] [G loss: 0.846580]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24460 [D loss: 0.692318, acc.: 57.03%] [G loss: 0.906793]\n",
      "epoch:26 step:24461 [D loss: 0.651282, acc.: 65.62%] [G loss: 0.879841]\n",
      "epoch:26 step:24462 [D loss: 0.691565, acc.: 53.91%] [G loss: 0.903222]\n",
      "epoch:26 step:24463 [D loss: 0.649083, acc.: 60.16%] [G loss: 0.946428]\n",
      "epoch:26 step:24464 [D loss: 0.732252, acc.: 46.09%] [G loss: 0.845673]\n",
      "epoch:26 step:24465 [D loss: 0.666370, acc.: 54.69%] [G loss: 0.892878]\n",
      "epoch:26 step:24466 [D loss: 0.628625, acc.: 67.19%] [G loss: 0.899998]\n",
      "epoch:26 step:24467 [D loss: 0.632833, acc.: 70.31%] [G loss: 0.867079]\n",
      "epoch:26 step:24468 [D loss: 0.638514, acc.: 66.41%] [G loss: 0.901700]\n",
      "epoch:26 step:24469 [D loss: 0.644714, acc.: 64.84%] [G loss: 0.883720]\n",
      "epoch:26 step:24470 [D loss: 0.638923, acc.: 65.62%] [G loss: 0.903456]\n",
      "epoch:26 step:24471 [D loss: 0.648555, acc.: 63.28%] [G loss: 0.932160]\n",
      "epoch:26 step:24472 [D loss: 0.649443, acc.: 61.72%] [G loss: 0.855652]\n",
      "epoch:26 step:24473 [D loss: 0.680977, acc.: 63.28%] [G loss: 0.909809]\n",
      "epoch:26 step:24474 [D loss: 0.649004, acc.: 60.16%] [G loss: 0.897922]\n",
      "epoch:26 step:24475 [D loss: 0.652718, acc.: 64.06%] [G loss: 0.890213]\n",
      "epoch:26 step:24476 [D loss: 0.665155, acc.: 62.50%] [G loss: 0.843864]\n",
      "epoch:26 step:24477 [D loss: 0.656712, acc.: 64.06%] [G loss: 0.868199]\n",
      "epoch:26 step:24478 [D loss: 0.647308, acc.: 60.94%] [G loss: 0.821225]\n",
      "epoch:26 step:24479 [D loss: 0.697030, acc.: 57.03%] [G loss: 0.889913]\n",
      "epoch:26 step:24480 [D loss: 0.677519, acc.: 56.25%] [G loss: 0.904150]\n",
      "epoch:26 step:24481 [D loss: 0.655589, acc.: 64.84%] [G loss: 0.930135]\n",
      "epoch:26 step:24482 [D loss: 0.643692, acc.: 65.62%] [G loss: 0.976458]\n",
      "epoch:26 step:24483 [D loss: 0.626247, acc.: 68.75%] [G loss: 0.982635]\n",
      "epoch:26 step:24484 [D loss: 0.693296, acc.: 56.25%] [G loss: 0.841815]\n",
      "epoch:26 step:24485 [D loss: 0.673868, acc.: 55.47%] [G loss: 0.848477]\n",
      "epoch:26 step:24486 [D loss: 0.635543, acc.: 66.41%] [G loss: 0.853722]\n",
      "epoch:26 step:24487 [D loss: 0.686292, acc.: 53.91%] [G loss: 0.895899]\n",
      "epoch:26 step:24488 [D loss: 0.676514, acc.: 59.38%] [G loss: 0.907877]\n",
      "epoch:26 step:24489 [D loss: 0.616046, acc.: 69.53%] [G loss: 0.953075]\n",
      "epoch:26 step:24490 [D loss: 0.671751, acc.: 56.25%] [G loss: 0.991528]\n",
      "epoch:26 step:24491 [D loss: 0.669041, acc.: 64.06%] [G loss: 0.961563]\n",
      "epoch:26 step:24492 [D loss: 0.628511, acc.: 64.84%] [G loss: 0.904819]\n",
      "epoch:26 step:24493 [D loss: 0.635598, acc.: 60.94%] [G loss: 0.998627]\n",
      "epoch:26 step:24494 [D loss: 0.650297, acc.: 60.94%] [G loss: 0.888123]\n",
      "epoch:26 step:24495 [D loss: 0.650576, acc.: 60.16%] [G loss: 0.896722]\n",
      "epoch:26 step:24496 [D loss: 0.612560, acc.: 66.41%] [G loss: 0.929478]\n",
      "epoch:26 step:24497 [D loss: 0.699956, acc.: 57.03%] [G loss: 0.935308]\n",
      "epoch:26 step:24498 [D loss: 0.698428, acc.: 53.91%] [G loss: 0.877418]\n",
      "epoch:26 step:24499 [D loss: 0.659179, acc.: 59.38%] [G loss: 0.883200]\n",
      "epoch:26 step:24500 [D loss: 0.667178, acc.: 58.59%] [G loss: 0.899910]\n",
      "epoch:26 step:24501 [D loss: 0.657229, acc.: 58.59%] [G loss: 0.870871]\n",
      "epoch:26 step:24502 [D loss: 0.614552, acc.: 67.97%] [G loss: 0.928840]\n",
      "epoch:26 step:24503 [D loss: 0.692523, acc.: 50.78%] [G loss: 0.880317]\n",
      "epoch:26 step:24504 [D loss: 0.633499, acc.: 62.50%] [G loss: 0.863606]\n",
      "epoch:26 step:24505 [D loss: 0.662817, acc.: 56.25%] [G loss: 0.902047]\n",
      "epoch:26 step:24506 [D loss: 0.626807, acc.: 63.28%] [G loss: 0.888443]\n",
      "epoch:26 step:24507 [D loss: 0.671564, acc.: 58.59%] [G loss: 0.839419]\n",
      "epoch:26 step:24508 [D loss: 0.687384, acc.: 57.03%] [G loss: 0.845078]\n",
      "epoch:26 step:24509 [D loss: 0.656761, acc.: 60.94%] [G loss: 0.935776]\n",
      "epoch:26 step:24510 [D loss: 0.628822, acc.: 64.84%] [G loss: 0.937861]\n",
      "epoch:26 step:24511 [D loss: 0.666994, acc.: 57.81%] [G loss: 0.886226]\n",
      "epoch:26 step:24512 [D loss: 0.664669, acc.: 59.38%] [G loss: 0.902166]\n",
      "epoch:26 step:24513 [D loss: 0.647110, acc.: 60.16%] [G loss: 0.977081]\n",
      "epoch:26 step:24514 [D loss: 0.604483, acc.: 67.19%] [G loss: 0.915904]\n",
      "epoch:26 step:24515 [D loss: 0.625116, acc.: 64.06%] [G loss: 0.858701]\n",
      "epoch:26 step:24516 [D loss: 0.657765, acc.: 59.38%] [G loss: 0.932711]\n",
      "epoch:26 step:24517 [D loss: 0.642222, acc.: 59.38%] [G loss: 0.891534]\n",
      "epoch:26 step:24518 [D loss: 0.652735, acc.: 60.94%] [G loss: 0.883725]\n",
      "epoch:26 step:24519 [D loss: 0.692404, acc.: 53.91%] [G loss: 0.846712]\n",
      "epoch:26 step:24520 [D loss: 0.659732, acc.: 56.25%] [G loss: 0.866049]\n",
      "epoch:26 step:24521 [D loss: 0.640703, acc.: 62.50%] [G loss: 0.966353]\n",
      "epoch:26 step:24522 [D loss: 0.640868, acc.: 60.16%] [G loss: 0.908152]\n",
      "epoch:26 step:24523 [D loss: 0.646688, acc.: 63.28%] [G loss: 0.950437]\n",
      "epoch:26 step:24524 [D loss: 0.665407, acc.: 57.81%] [G loss: 0.938348]\n",
      "epoch:26 step:24525 [D loss: 0.665308, acc.: 60.16%] [G loss: 0.955459]\n",
      "epoch:26 step:24526 [D loss: 0.678884, acc.: 58.59%] [G loss: 0.924232]\n",
      "epoch:26 step:24527 [D loss: 0.642865, acc.: 61.72%] [G loss: 0.965150]\n",
      "epoch:26 step:24528 [D loss: 0.652677, acc.: 62.50%] [G loss: 0.908902]\n",
      "epoch:26 step:24529 [D loss: 0.683202, acc.: 51.56%] [G loss: 0.872943]\n",
      "epoch:26 step:24530 [D loss: 0.649201, acc.: 63.28%] [G loss: 0.888310]\n",
      "epoch:26 step:24531 [D loss: 0.643134, acc.: 64.84%] [G loss: 0.847596]\n",
      "epoch:26 step:24532 [D loss: 0.646128, acc.: 58.59%] [G loss: 0.900711]\n",
      "epoch:26 step:24533 [D loss: 0.667123, acc.: 57.81%] [G loss: 0.868030]\n",
      "epoch:26 step:24534 [D loss: 0.718785, acc.: 46.88%] [G loss: 0.866261]\n",
      "epoch:26 step:24535 [D loss: 0.680352, acc.: 53.12%] [G loss: 0.884871]\n",
      "epoch:26 step:24536 [D loss: 0.644460, acc.: 68.75%] [G loss: 0.856229]\n",
      "epoch:26 step:24537 [D loss: 0.651205, acc.: 61.72%] [G loss: 0.862473]\n",
      "epoch:26 step:24538 [D loss: 0.634801, acc.: 60.16%] [G loss: 0.883043]\n",
      "epoch:26 step:24539 [D loss: 0.645420, acc.: 57.81%] [G loss: 0.922057]\n",
      "epoch:26 step:24540 [D loss: 0.687350, acc.: 53.12%] [G loss: 0.941872]\n",
      "epoch:26 step:24541 [D loss: 0.678488, acc.: 57.03%] [G loss: 0.886247]\n",
      "epoch:26 step:24542 [D loss: 0.624418, acc.: 62.50%] [G loss: 1.059424]\n",
      "epoch:26 step:24543 [D loss: 0.663369, acc.: 50.78%] [G loss: 0.913462]\n",
      "epoch:26 step:24544 [D loss: 0.659224, acc.: 60.94%] [G loss: 0.943522]\n",
      "epoch:26 step:24545 [D loss: 0.658786, acc.: 64.84%] [G loss: 0.892958]\n",
      "epoch:26 step:24546 [D loss: 0.637452, acc.: 66.41%] [G loss: 0.892616]\n",
      "epoch:26 step:24547 [D loss: 0.658098, acc.: 60.16%] [G loss: 0.884848]\n",
      "epoch:26 step:24548 [D loss: 0.678998, acc.: 53.12%] [G loss: 0.942621]\n",
      "epoch:26 step:24549 [D loss: 0.635559, acc.: 66.41%] [G loss: 0.891169]\n",
      "epoch:26 step:24550 [D loss: 0.667793, acc.: 60.16%] [G loss: 0.882901]\n",
      "epoch:26 step:24551 [D loss: 0.654446, acc.: 57.81%] [G loss: 0.907606]\n",
      "epoch:26 step:24552 [D loss: 0.689375, acc.: 57.03%] [G loss: 0.900059]\n",
      "epoch:26 step:24553 [D loss: 0.666853, acc.: 61.72%] [G loss: 0.952310]\n",
      "epoch:26 step:24554 [D loss: 0.654556, acc.: 60.94%] [G loss: 0.892316]\n",
      "epoch:26 step:24555 [D loss: 0.624379, acc.: 66.41%] [G loss: 0.842545]\n",
      "epoch:26 step:24556 [D loss: 0.678198, acc.: 56.25%] [G loss: 0.878867]\n",
      "epoch:26 step:24557 [D loss: 0.636565, acc.: 64.84%] [G loss: 0.865237]\n",
      "epoch:26 step:24558 [D loss: 0.668315, acc.: 57.03%] [G loss: 0.890794]\n",
      "epoch:26 step:24559 [D loss: 0.633832, acc.: 57.81%] [G loss: 0.900369]\n",
      "epoch:26 step:24560 [D loss: 0.636857, acc.: 64.06%] [G loss: 0.903462]\n",
      "epoch:26 step:24561 [D loss: 0.650798, acc.: 55.47%] [G loss: 0.903588]\n",
      "epoch:26 step:24562 [D loss: 0.650296, acc.: 60.16%] [G loss: 0.897927]\n",
      "epoch:26 step:24563 [D loss: 0.658536, acc.: 57.81%] [G loss: 0.939613]\n",
      "epoch:26 step:24564 [D loss: 0.632038, acc.: 60.94%] [G loss: 0.926293]\n",
      "epoch:26 step:24565 [D loss: 0.651049, acc.: 61.72%] [G loss: 0.912401]\n",
      "epoch:26 step:24566 [D loss: 0.680985, acc.: 51.56%] [G loss: 0.959442]\n",
      "epoch:26 step:24567 [D loss: 0.653472, acc.: 66.41%] [G loss: 0.880273]\n",
      "epoch:26 step:24568 [D loss: 0.639974, acc.: 64.84%] [G loss: 0.872216]\n",
      "epoch:26 step:24569 [D loss: 0.582593, acc.: 69.53%] [G loss: 0.863280]\n",
      "epoch:26 step:24570 [D loss: 0.658140, acc.: 66.41%] [G loss: 0.967181]\n",
      "epoch:26 step:24571 [D loss: 0.626012, acc.: 63.28%] [G loss: 0.924733]\n",
      "epoch:26 step:24572 [D loss: 0.627167, acc.: 63.28%] [G loss: 0.905549]\n",
      "epoch:26 step:24573 [D loss: 0.658347, acc.: 62.50%] [G loss: 0.909918]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24574 [D loss: 0.632459, acc.: 59.38%] [G loss: 0.888749]\n",
      "epoch:26 step:24575 [D loss: 0.673260, acc.: 56.25%] [G loss: 0.897024]\n",
      "epoch:26 step:24576 [D loss: 0.663739, acc.: 58.59%] [G loss: 0.928563]\n",
      "epoch:26 step:24577 [D loss: 0.650894, acc.: 61.72%] [G loss: 0.871337]\n",
      "epoch:26 step:24578 [D loss: 0.687108, acc.: 50.78%] [G loss: 0.876324]\n",
      "epoch:26 step:24579 [D loss: 0.643767, acc.: 61.72%] [G loss: 0.917193]\n",
      "epoch:26 step:24580 [D loss: 0.717803, acc.: 53.91%] [G loss: 0.896774]\n",
      "epoch:26 step:24581 [D loss: 0.688531, acc.: 53.91%] [G loss: 0.918879]\n",
      "epoch:26 step:24582 [D loss: 0.697004, acc.: 48.44%] [G loss: 0.864018]\n",
      "epoch:26 step:24583 [D loss: 0.651913, acc.: 59.38%] [G loss: 0.933925]\n",
      "epoch:26 step:24584 [D loss: 0.721401, acc.: 55.47%] [G loss: 0.868893]\n",
      "epoch:26 step:24585 [D loss: 0.669110, acc.: 54.69%] [G loss: 0.923157]\n",
      "epoch:26 step:24586 [D loss: 0.633083, acc.: 64.06%] [G loss: 0.833309]\n",
      "epoch:26 step:24587 [D loss: 0.643144, acc.: 64.06%] [G loss: 0.861830]\n",
      "epoch:26 step:24588 [D loss: 0.682350, acc.: 56.25%] [G loss: 0.845389]\n",
      "epoch:26 step:24589 [D loss: 0.653801, acc.: 59.38%] [G loss: 0.863403]\n",
      "epoch:26 step:24590 [D loss: 0.629288, acc.: 65.62%] [G loss: 0.833402]\n",
      "epoch:26 step:24591 [D loss: 0.644630, acc.: 60.94%] [G loss: 0.873874]\n",
      "epoch:26 step:24592 [D loss: 0.670688, acc.: 57.81%] [G loss: 0.866347]\n",
      "epoch:26 step:24593 [D loss: 0.680514, acc.: 55.47%] [G loss: 0.865116]\n",
      "epoch:26 step:24594 [D loss: 0.670827, acc.: 57.03%] [G loss: 0.947801]\n",
      "epoch:26 step:24595 [D loss: 0.655094, acc.: 58.59%] [G loss: 0.932007]\n",
      "epoch:26 step:24596 [D loss: 0.672324, acc.: 57.81%] [G loss: 0.927936]\n",
      "epoch:26 step:24597 [D loss: 0.682711, acc.: 57.03%] [G loss: 0.885305]\n",
      "epoch:26 step:24598 [D loss: 0.623221, acc.: 63.28%] [G loss: 0.860315]\n",
      "epoch:26 step:24599 [D loss: 0.688039, acc.: 52.34%] [G loss: 0.866223]\n",
      "epoch:26 step:24600 [D loss: 0.657428, acc.: 60.94%] [G loss: 0.861683]\n",
      "##############\n",
      "[2.96362753 2.32527455 2.26487525 4.07915171 1.12953249 7.98432328\n",
      " 3.00013686 3.3420971  4.24728881 7.14771273]\n",
      "##########\n",
      "epoch:26 step:24601 [D loss: 0.649430, acc.: 58.59%] [G loss: 0.849249]\n",
      "epoch:26 step:24602 [D loss: 0.644909, acc.: 64.84%] [G loss: 0.856831]\n",
      "epoch:26 step:24603 [D loss: 0.635488, acc.: 62.50%] [G loss: 0.871617]\n",
      "epoch:26 step:24604 [D loss: 0.673423, acc.: 58.59%] [G loss: 0.928204]\n",
      "epoch:26 step:24605 [D loss: 0.646581, acc.: 64.06%] [G loss: 0.923798]\n",
      "epoch:26 step:24606 [D loss: 0.681655, acc.: 53.91%] [G loss: 0.866896]\n",
      "epoch:26 step:24607 [D loss: 0.661190, acc.: 56.25%] [G loss: 0.868981]\n",
      "epoch:26 step:24608 [D loss: 0.652073, acc.: 55.47%] [G loss: 0.939930]\n",
      "epoch:26 step:24609 [D loss: 0.687875, acc.: 53.12%] [G loss: 0.846587]\n",
      "epoch:26 step:24610 [D loss: 0.647751, acc.: 59.38%] [G loss: 0.802150]\n",
      "epoch:26 step:24611 [D loss: 0.710975, acc.: 51.56%] [G loss: 0.849301]\n",
      "epoch:26 step:24612 [D loss: 0.674272, acc.: 64.06%] [G loss: 0.860662]\n",
      "epoch:26 step:24613 [D loss: 0.675421, acc.: 57.81%] [G loss: 0.881452]\n",
      "epoch:26 step:24614 [D loss: 0.638474, acc.: 65.62%] [G loss: 0.948408]\n",
      "epoch:26 step:24615 [D loss: 0.631354, acc.: 67.97%] [G loss: 0.919751]\n",
      "epoch:26 step:24616 [D loss: 0.699726, acc.: 57.81%] [G loss: 0.869672]\n",
      "epoch:26 step:24617 [D loss: 0.630364, acc.: 60.16%] [G loss: 0.944492]\n",
      "epoch:26 step:24618 [D loss: 0.664188, acc.: 63.28%] [G loss: 0.915650]\n",
      "epoch:26 step:24619 [D loss: 0.634366, acc.: 64.06%] [G loss: 0.948993]\n",
      "epoch:26 step:24620 [D loss: 0.627568, acc.: 68.75%] [G loss: 0.936259]\n",
      "epoch:26 step:24621 [D loss: 0.682236, acc.: 57.03%] [G loss: 0.908795]\n",
      "epoch:26 step:24622 [D loss: 0.670766, acc.: 63.28%] [G loss: 0.853302]\n",
      "epoch:26 step:24623 [D loss: 0.661631, acc.: 63.28%] [G loss: 0.843770]\n",
      "epoch:26 step:24624 [D loss: 0.663522, acc.: 57.03%] [G loss: 0.890171]\n",
      "epoch:26 step:24625 [D loss: 0.658385, acc.: 55.47%] [G loss: 0.900652]\n",
      "epoch:26 step:24626 [D loss: 0.691424, acc.: 52.34%] [G loss: 0.903438]\n",
      "epoch:26 step:24627 [D loss: 0.625534, acc.: 69.53%] [G loss: 0.976081]\n",
      "epoch:26 step:24628 [D loss: 0.640641, acc.: 64.84%] [G loss: 0.954242]\n",
      "epoch:26 step:24629 [D loss: 0.640124, acc.: 63.28%] [G loss: 0.936682]\n",
      "epoch:26 step:24630 [D loss: 0.649911, acc.: 62.50%] [G loss: 0.962390]\n",
      "epoch:26 step:24631 [D loss: 0.653649, acc.: 57.81%] [G loss: 0.909589]\n",
      "epoch:26 step:24632 [D loss: 0.647144, acc.: 60.16%] [G loss: 0.905558]\n",
      "epoch:26 step:24633 [D loss: 0.642153, acc.: 64.84%] [G loss: 0.871250]\n",
      "epoch:26 step:24634 [D loss: 0.659497, acc.: 61.72%] [G loss: 0.846520]\n",
      "epoch:26 step:24635 [D loss: 0.689913, acc.: 54.69%] [G loss: 0.890977]\n",
      "epoch:26 step:24636 [D loss: 0.652382, acc.: 64.06%] [G loss: 0.890577]\n",
      "epoch:26 step:24637 [D loss: 0.652312, acc.: 59.38%] [G loss: 0.862575]\n",
      "epoch:26 step:24638 [D loss: 0.681335, acc.: 53.12%] [G loss: 0.850638]\n",
      "epoch:26 step:24639 [D loss: 0.639728, acc.: 64.84%] [G loss: 0.844460]\n",
      "epoch:26 step:24640 [D loss: 0.685090, acc.: 53.12%] [G loss: 0.932601]\n",
      "epoch:26 step:24641 [D loss: 0.684807, acc.: 58.59%] [G loss: 0.889668]\n",
      "epoch:26 step:24642 [D loss: 0.681071, acc.: 52.34%] [G loss: 0.897441]\n",
      "epoch:26 step:24643 [D loss: 0.664070, acc.: 59.38%] [G loss: 0.841179]\n",
      "epoch:26 step:24644 [D loss: 0.634220, acc.: 65.62%] [G loss: 0.864595]\n",
      "epoch:26 step:24645 [D loss: 0.647666, acc.: 64.06%] [G loss: 0.848385]\n",
      "epoch:26 step:24646 [D loss: 0.631113, acc.: 60.94%] [G loss: 0.877891]\n",
      "epoch:26 step:24647 [D loss: 0.590071, acc.: 71.88%] [G loss: 0.888421]\n",
      "epoch:26 step:24648 [D loss: 0.663759, acc.: 60.16%] [G loss: 0.846740]\n",
      "epoch:26 step:24649 [D loss: 0.658860, acc.: 64.06%] [G loss: 0.894504]\n",
      "epoch:26 step:24650 [D loss: 0.650368, acc.: 60.94%] [G loss: 0.829611]\n",
      "epoch:26 step:24651 [D loss: 0.689306, acc.: 56.25%] [G loss: 0.904513]\n",
      "epoch:26 step:24652 [D loss: 0.679769, acc.: 54.69%] [G loss: 0.927615]\n",
      "epoch:26 step:24653 [D loss: 0.665474, acc.: 55.47%] [G loss: 0.891146]\n",
      "epoch:26 step:24654 [D loss: 0.685369, acc.: 57.03%] [G loss: 0.871439]\n",
      "epoch:26 step:24655 [D loss: 0.650050, acc.: 59.38%] [G loss: 0.910200]\n",
      "epoch:26 step:24656 [D loss: 0.647690, acc.: 62.50%] [G loss: 0.887042]\n",
      "epoch:26 step:24657 [D loss: 0.650466, acc.: 62.50%] [G loss: 0.864810]\n",
      "epoch:26 step:24658 [D loss: 0.651552, acc.: 57.81%] [G loss: 0.846901]\n",
      "epoch:26 step:24659 [D loss: 0.632280, acc.: 68.75%] [G loss: 0.923527]\n",
      "epoch:26 step:24660 [D loss: 0.667488, acc.: 54.69%] [G loss: 0.864638]\n",
      "epoch:26 step:24661 [D loss: 0.682742, acc.: 58.59%] [G loss: 0.908632]\n",
      "epoch:26 step:24662 [D loss: 0.654939, acc.: 56.25%] [G loss: 0.896557]\n",
      "epoch:26 step:24663 [D loss: 0.650479, acc.: 61.72%] [G loss: 0.912344]\n",
      "epoch:26 step:24664 [D loss: 0.644111, acc.: 59.38%] [G loss: 0.887725]\n",
      "epoch:26 step:24665 [D loss: 0.659101, acc.: 64.84%] [G loss: 0.830491]\n",
      "epoch:26 step:24666 [D loss: 0.624003, acc.: 65.62%] [G loss: 0.782880]\n",
      "epoch:26 step:24667 [D loss: 0.679674, acc.: 57.03%] [G loss: 0.848099]\n",
      "epoch:26 step:24668 [D loss: 0.663140, acc.: 58.59%] [G loss: 0.848393]\n",
      "epoch:26 step:24669 [D loss: 0.672608, acc.: 58.59%] [G loss: 0.922417]\n",
      "epoch:26 step:24670 [D loss: 0.667881, acc.: 56.25%] [G loss: 0.853986]\n",
      "epoch:26 step:24671 [D loss: 0.666116, acc.: 57.81%] [G loss: 0.869321]\n",
      "epoch:26 step:24672 [D loss: 0.660520, acc.: 56.25%] [G loss: 0.900020]\n",
      "epoch:26 step:24673 [D loss: 0.657030, acc.: 60.94%] [G loss: 0.944471]\n",
      "epoch:26 step:24674 [D loss: 0.646291, acc.: 64.06%] [G loss: 0.826856]\n",
      "epoch:26 step:24675 [D loss: 0.674833, acc.: 59.38%] [G loss: 0.857531]\n",
      "epoch:26 step:24676 [D loss: 0.617844, acc.: 67.19%] [G loss: 0.978692]\n",
      "epoch:26 step:24677 [D loss: 0.657219, acc.: 53.91%] [G loss: 0.876368]\n",
      "epoch:26 step:24678 [D loss: 0.650818, acc.: 57.03%] [G loss: 0.954215]\n",
      "epoch:26 step:24679 [D loss: 0.649252, acc.: 59.38%] [G loss: 0.913124]\n",
      "epoch:26 step:24680 [D loss: 0.637249, acc.: 64.84%] [G loss: 0.860526]\n",
      "epoch:26 step:24681 [D loss: 0.697605, acc.: 50.78%] [G loss: 0.858088]\n",
      "epoch:26 step:24682 [D loss: 0.627145, acc.: 67.19%] [G loss: 0.892338]\n",
      "epoch:26 step:24683 [D loss: 0.629296, acc.: 68.75%] [G loss: 0.884520]\n",
      "epoch:26 step:24684 [D loss: 0.697731, acc.: 54.69%] [G loss: 0.854570]\n",
      "epoch:26 step:24685 [D loss: 0.685417, acc.: 56.25%] [G loss: 0.894640]\n",
      "epoch:26 step:24686 [D loss: 0.679885, acc.: 55.47%] [G loss: 0.847726]\n",
      "epoch:26 step:24687 [D loss: 0.641375, acc.: 59.38%] [G loss: 0.879561]\n",
      "epoch:26 step:24688 [D loss: 0.671557, acc.: 62.50%] [G loss: 0.834685]\n",
      "epoch:26 step:24689 [D loss: 0.615112, acc.: 68.75%] [G loss: 0.867301]\n",
      "epoch:26 step:24690 [D loss: 0.640738, acc.: 69.53%] [G loss: 0.866831]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24691 [D loss: 0.661544, acc.: 56.25%] [G loss: 0.859635]\n",
      "epoch:26 step:24692 [D loss: 0.671177, acc.: 60.94%] [G loss: 0.888210]\n",
      "epoch:26 step:24693 [D loss: 0.653917, acc.: 62.50%] [G loss: 0.931459]\n",
      "epoch:26 step:24694 [D loss: 0.666635, acc.: 57.03%] [G loss: 0.910287]\n",
      "epoch:26 step:24695 [D loss: 0.682743, acc.: 56.25%] [G loss: 0.921075]\n",
      "epoch:26 step:24696 [D loss: 0.678866, acc.: 57.81%] [G loss: 0.867077]\n",
      "epoch:26 step:24697 [D loss: 0.633483, acc.: 64.06%] [G loss: 0.936716]\n",
      "epoch:26 step:24698 [D loss: 0.613535, acc.: 64.84%] [G loss: 0.922253]\n",
      "epoch:26 step:24699 [D loss: 0.669793, acc.: 59.38%] [G loss: 0.936495]\n",
      "epoch:26 step:24700 [D loss: 0.651648, acc.: 61.72%] [G loss: 0.884770]\n",
      "epoch:26 step:24701 [D loss: 0.638239, acc.: 67.19%] [G loss: 0.916754]\n",
      "epoch:26 step:24702 [D loss: 0.630264, acc.: 63.28%] [G loss: 0.930363]\n",
      "epoch:26 step:24703 [D loss: 0.664431, acc.: 60.16%] [G loss: 0.880261]\n",
      "epoch:26 step:24704 [D loss: 0.651599, acc.: 60.94%] [G loss: 0.942195]\n",
      "epoch:26 step:24705 [D loss: 0.647114, acc.: 64.06%] [G loss: 0.915994]\n",
      "epoch:26 step:24706 [D loss: 0.659404, acc.: 57.03%] [G loss: 0.916019]\n",
      "epoch:26 step:24707 [D loss: 0.670156, acc.: 51.56%] [G loss: 0.810973]\n",
      "epoch:26 step:24708 [D loss: 0.678465, acc.: 59.38%] [G loss: 0.962205]\n",
      "epoch:26 step:24709 [D loss: 0.630568, acc.: 70.31%] [G loss: 0.900027]\n",
      "epoch:26 step:24710 [D loss: 0.697969, acc.: 54.69%] [G loss: 0.852469]\n",
      "epoch:26 step:24711 [D loss: 0.609474, acc.: 69.53%] [G loss: 0.925411]\n",
      "epoch:26 step:24712 [D loss: 0.675073, acc.: 57.81%] [G loss: 0.907504]\n",
      "epoch:26 step:24713 [D loss: 0.675282, acc.: 54.69%] [G loss: 0.895369]\n",
      "epoch:26 step:24714 [D loss: 0.684873, acc.: 57.03%] [G loss: 0.925319]\n",
      "epoch:26 step:24715 [D loss: 0.672347, acc.: 58.59%] [G loss: 0.848006]\n",
      "epoch:26 step:24716 [D loss: 0.692738, acc.: 55.47%] [G loss: 0.852352]\n",
      "epoch:26 step:24717 [D loss: 0.704192, acc.: 50.78%] [G loss: 0.828141]\n",
      "epoch:26 step:24718 [D loss: 0.665360, acc.: 56.25%] [G loss: 0.835711]\n",
      "epoch:26 step:24719 [D loss: 0.656205, acc.: 60.94%] [G loss: 0.872261]\n",
      "epoch:26 step:24720 [D loss: 0.647696, acc.: 60.94%] [G loss: 0.932648]\n",
      "epoch:26 step:24721 [D loss: 0.652296, acc.: 61.72%] [G loss: 0.936867]\n",
      "epoch:26 step:24722 [D loss: 0.620801, acc.: 67.97%] [G loss: 0.889101]\n",
      "epoch:26 step:24723 [D loss: 0.653424, acc.: 61.72%] [G loss: 0.909418]\n",
      "epoch:26 step:24724 [D loss: 0.636134, acc.: 62.50%] [G loss: 0.862012]\n",
      "epoch:26 step:24725 [D loss: 0.670295, acc.: 57.03%] [G loss: 0.846592]\n",
      "epoch:26 step:24726 [D loss: 0.692694, acc.: 53.12%] [G loss: 0.833013]\n",
      "epoch:26 step:24727 [D loss: 0.635728, acc.: 60.94%] [G loss: 0.938567]\n",
      "epoch:26 step:24728 [D loss: 0.653650, acc.: 59.38%] [G loss: 0.904657]\n",
      "epoch:26 step:24729 [D loss: 0.652012, acc.: 66.41%] [G loss: 0.902038]\n",
      "epoch:26 step:24730 [D loss: 0.677830, acc.: 56.25%] [G loss: 0.945094]\n",
      "epoch:26 step:24731 [D loss: 0.662421, acc.: 59.38%] [G loss: 0.913620]\n",
      "epoch:26 step:24732 [D loss: 0.682085, acc.: 58.59%] [G loss: 0.930883]\n",
      "epoch:26 step:24733 [D loss: 0.677691, acc.: 62.50%] [G loss: 0.961106]\n",
      "epoch:26 step:24734 [D loss: 0.637052, acc.: 68.75%] [G loss: 0.930460]\n",
      "epoch:26 step:24735 [D loss: 0.643465, acc.: 58.59%] [G loss: 0.877363]\n",
      "epoch:26 step:24736 [D loss: 0.671008, acc.: 61.72%] [G loss: 0.865641]\n",
      "epoch:26 step:24737 [D loss: 0.637777, acc.: 64.06%] [G loss: 0.849521]\n",
      "epoch:26 step:24738 [D loss: 0.683767, acc.: 55.47%] [G loss: 0.885630]\n",
      "epoch:26 step:24739 [D loss: 0.660138, acc.: 61.72%] [G loss: 0.842691]\n",
      "epoch:26 step:24740 [D loss: 0.653927, acc.: 62.50%] [G loss: 0.900625]\n",
      "epoch:26 step:24741 [D loss: 0.659271, acc.: 58.59%] [G loss: 0.920966]\n",
      "epoch:26 step:24742 [D loss: 0.670521, acc.: 60.94%] [G loss: 0.939130]\n",
      "epoch:26 step:24743 [D loss: 0.655341, acc.: 60.94%] [G loss: 0.917277]\n",
      "epoch:26 step:24744 [D loss: 0.645509, acc.: 64.06%] [G loss: 0.889151]\n",
      "epoch:26 step:24745 [D loss: 0.653906, acc.: 63.28%] [G loss: 0.890498]\n",
      "epoch:26 step:24746 [D loss: 0.679191, acc.: 55.47%] [G loss: 0.898591]\n",
      "epoch:26 step:24747 [D loss: 0.700295, acc.: 51.56%] [G loss: 0.931735]\n",
      "epoch:26 step:24748 [D loss: 0.684243, acc.: 63.28%] [G loss: 0.817723]\n",
      "epoch:26 step:24749 [D loss: 0.668315, acc.: 57.03%] [G loss: 0.944731]\n",
      "epoch:26 step:24750 [D loss: 0.660672, acc.: 64.06%] [G loss: 0.918461]\n",
      "epoch:26 step:24751 [D loss: 0.680490, acc.: 51.56%] [G loss: 0.866935]\n",
      "epoch:26 step:24752 [D loss: 0.686584, acc.: 56.25%] [G loss: 0.852577]\n",
      "epoch:26 step:24753 [D loss: 0.665522, acc.: 61.72%] [G loss: 0.922335]\n",
      "epoch:26 step:24754 [D loss: 0.616361, acc.: 67.97%] [G loss: 0.891160]\n",
      "epoch:26 step:24755 [D loss: 0.677788, acc.: 53.91%] [G loss: 0.886755]\n",
      "epoch:26 step:24756 [D loss: 0.705056, acc.: 50.78%] [G loss: 0.891515]\n",
      "epoch:26 step:24757 [D loss: 0.668602, acc.: 54.69%] [G loss: 0.884308]\n",
      "epoch:26 step:24758 [D loss: 0.691944, acc.: 53.91%] [G loss: 0.873446]\n",
      "epoch:26 step:24759 [D loss: 0.651114, acc.: 57.81%] [G loss: 0.901084]\n",
      "epoch:26 step:24760 [D loss: 0.623605, acc.: 64.84%] [G loss: 0.911404]\n",
      "epoch:26 step:24761 [D loss: 0.671069, acc.: 61.72%] [G loss: 0.846940]\n",
      "epoch:26 step:24762 [D loss: 0.653299, acc.: 61.72%] [G loss: 0.912309]\n",
      "epoch:26 step:24763 [D loss: 0.641702, acc.: 63.28%] [G loss: 0.913760]\n",
      "epoch:26 step:24764 [D loss: 0.606019, acc.: 70.31%] [G loss: 0.892462]\n",
      "epoch:26 step:24765 [D loss: 0.605061, acc.: 71.09%] [G loss: 0.893081]\n",
      "epoch:26 step:24766 [D loss: 0.631687, acc.: 63.28%] [G loss: 0.862387]\n",
      "epoch:26 step:24767 [D loss: 0.617415, acc.: 68.75%] [G loss: 0.844532]\n",
      "epoch:26 step:24768 [D loss: 0.642154, acc.: 66.41%] [G loss: 0.902332]\n",
      "epoch:26 step:24769 [D loss: 0.661139, acc.: 63.28%] [G loss: 0.889436]\n",
      "epoch:26 step:24770 [D loss: 0.639928, acc.: 61.72%] [G loss: 0.906754]\n",
      "epoch:26 step:24771 [D loss: 0.691092, acc.: 57.03%] [G loss: 0.836496]\n",
      "epoch:26 step:24772 [D loss: 0.674888, acc.: 57.81%] [G loss: 0.897312]\n",
      "epoch:26 step:24773 [D loss: 0.635873, acc.: 64.06%] [G loss: 0.931872]\n",
      "epoch:26 step:24774 [D loss: 0.635890, acc.: 67.19%] [G loss: 0.927534]\n",
      "epoch:26 step:24775 [D loss: 0.670001, acc.: 51.56%] [G loss: 0.843278]\n",
      "epoch:26 step:24776 [D loss: 0.679706, acc.: 56.25%] [G loss: 0.898398]\n",
      "epoch:26 step:24777 [D loss: 0.648720, acc.: 62.50%] [G loss: 0.900817]\n",
      "epoch:26 step:24778 [D loss: 0.625940, acc.: 65.62%] [G loss: 0.939334]\n",
      "epoch:26 step:24779 [D loss: 0.621440, acc.: 71.09%] [G loss: 0.903170]\n",
      "epoch:26 step:24780 [D loss: 0.680990, acc.: 56.25%] [G loss: 0.916380]\n",
      "epoch:26 step:24781 [D loss: 0.658761, acc.: 53.91%] [G loss: 0.868407]\n",
      "epoch:26 step:24782 [D loss: 0.638155, acc.: 64.84%] [G loss: 0.920178]\n",
      "epoch:26 step:24783 [D loss: 0.636199, acc.: 69.53%] [G loss: 0.948624]\n",
      "epoch:26 step:24784 [D loss: 0.689322, acc.: 50.00%] [G loss: 0.880087]\n",
      "epoch:26 step:24785 [D loss: 0.641980, acc.: 61.72%] [G loss: 0.876873]\n",
      "epoch:26 step:24786 [D loss: 0.660365, acc.: 64.06%] [G loss: 0.963207]\n",
      "epoch:26 step:24787 [D loss: 0.642457, acc.: 64.06%] [G loss: 0.909187]\n",
      "epoch:26 step:24788 [D loss: 0.683633, acc.: 57.81%] [G loss: 0.885179]\n",
      "epoch:26 step:24789 [D loss: 0.663335, acc.: 56.25%] [G loss: 0.872964]\n",
      "epoch:26 step:24790 [D loss: 0.703544, acc.: 54.69%] [G loss: 0.867623]\n",
      "epoch:26 step:24791 [D loss: 0.642667, acc.: 62.50%] [G loss: 0.848651]\n",
      "epoch:26 step:24792 [D loss: 0.718027, acc.: 56.25%] [G loss: 0.911098]\n",
      "epoch:26 step:24793 [D loss: 0.675640, acc.: 60.16%] [G loss: 0.911517]\n",
      "epoch:26 step:24794 [D loss: 0.675457, acc.: 50.00%] [G loss: 0.981555]\n",
      "epoch:26 step:24795 [D loss: 0.643671, acc.: 57.81%] [G loss: 0.967799]\n",
      "epoch:26 step:24796 [D loss: 0.633968, acc.: 64.06%] [G loss: 0.907305]\n",
      "epoch:26 step:24797 [D loss: 0.685275, acc.: 60.16%] [G loss: 0.882625]\n",
      "epoch:26 step:24798 [D loss: 0.676729, acc.: 52.34%] [G loss: 0.928106]\n",
      "epoch:26 step:24799 [D loss: 0.670927, acc.: 58.59%] [G loss: 0.905287]\n",
      "epoch:26 step:24800 [D loss: 0.668601, acc.: 60.16%] [G loss: 0.949774]\n",
      "##############\n",
      "[2.90500063 2.74789712 2.20857496 4.16020301 1.5068134  9.27426719\n",
      " 2.79621586 3.68384692 4.29866373 6.01500203]\n",
      "##########\n",
      "epoch:26 step:24801 [D loss: 0.612888, acc.: 66.41%] [G loss: 0.919283]\n",
      "epoch:26 step:24802 [D loss: 0.637903, acc.: 61.72%] [G loss: 0.955461]\n",
      "epoch:26 step:24803 [D loss: 0.695824, acc.: 54.69%] [G loss: 0.853520]\n",
      "epoch:26 step:24804 [D loss: 0.660908, acc.: 58.59%] [G loss: 0.876129]\n",
      "epoch:26 step:24805 [D loss: 0.662748, acc.: 54.69%] [G loss: 0.947477]\n",
      "epoch:26 step:24806 [D loss: 0.656155, acc.: 62.50%] [G loss: 0.896579]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24807 [D loss: 0.649428, acc.: 64.06%] [G loss: 0.850310]\n",
      "epoch:26 step:24808 [D loss: 0.688552, acc.: 52.34%] [G loss: 0.885043]\n",
      "epoch:26 step:24809 [D loss: 0.669347, acc.: 56.25%] [G loss: 0.873415]\n",
      "epoch:26 step:24810 [D loss: 0.665191, acc.: 58.59%] [G loss: 0.915699]\n",
      "epoch:26 step:24811 [D loss: 0.660143, acc.: 57.03%] [G loss: 0.899406]\n",
      "epoch:26 step:24812 [D loss: 0.649874, acc.: 57.81%] [G loss: 0.903129]\n",
      "epoch:26 step:24813 [D loss: 0.647368, acc.: 65.62%] [G loss: 0.914171]\n",
      "epoch:26 step:24814 [D loss: 0.675631, acc.: 56.25%] [G loss: 0.904297]\n",
      "epoch:26 step:24815 [D loss: 0.630158, acc.: 69.53%] [G loss: 0.915284]\n",
      "epoch:26 step:24816 [D loss: 0.655077, acc.: 63.28%] [G loss: 0.871064]\n",
      "epoch:26 step:24817 [D loss: 0.629178, acc.: 67.19%] [G loss: 0.895635]\n",
      "epoch:26 step:24818 [D loss: 0.641767, acc.: 71.09%] [G loss: 0.886398]\n",
      "epoch:26 step:24819 [D loss: 0.710015, acc.: 53.91%] [G loss: 0.845806]\n",
      "epoch:26 step:24820 [D loss: 0.664517, acc.: 57.03%] [G loss: 0.920664]\n",
      "epoch:26 step:24821 [D loss: 0.613520, acc.: 63.28%] [G loss: 0.911164]\n",
      "epoch:26 step:24822 [D loss: 0.636668, acc.: 64.84%] [G loss: 0.902377]\n",
      "epoch:26 step:24823 [D loss: 0.618949, acc.: 64.84%] [G loss: 0.896215]\n",
      "epoch:26 step:24824 [D loss: 0.643841, acc.: 55.47%] [G loss: 0.886451]\n",
      "epoch:26 step:24825 [D loss: 0.667065, acc.: 60.94%] [G loss: 0.868581]\n",
      "epoch:26 step:24826 [D loss: 0.660291, acc.: 59.38%] [G loss: 0.859466]\n",
      "epoch:26 step:24827 [D loss: 0.641241, acc.: 67.97%] [G loss: 0.827282]\n",
      "epoch:26 step:24828 [D loss: 0.689198, acc.: 57.81%] [G loss: 0.859694]\n",
      "epoch:26 step:24829 [D loss: 0.641298, acc.: 64.84%] [G loss: 0.924857]\n",
      "epoch:26 step:24830 [D loss: 0.658983, acc.: 57.81%] [G loss: 0.904252]\n",
      "epoch:26 step:24831 [D loss: 0.648445, acc.: 57.81%] [G loss: 0.875139]\n",
      "epoch:26 step:24832 [D loss: 0.660806, acc.: 62.50%] [G loss: 0.887053]\n",
      "epoch:26 step:24833 [D loss: 0.615201, acc.: 67.19%] [G loss: 0.824433]\n",
      "epoch:26 step:24834 [D loss: 0.637996, acc.: 64.06%] [G loss: 0.811952]\n",
      "epoch:26 step:24835 [D loss: 0.681507, acc.: 54.69%] [G loss: 0.870137]\n",
      "epoch:26 step:24836 [D loss: 0.622077, acc.: 66.41%] [G loss: 0.945434]\n",
      "epoch:26 step:24837 [D loss: 0.654897, acc.: 61.72%] [G loss: 0.919848]\n",
      "epoch:26 step:24838 [D loss: 0.683670, acc.: 55.47%] [G loss: 0.966044]\n",
      "epoch:26 step:24839 [D loss: 0.683542, acc.: 53.91%] [G loss: 1.018449]\n",
      "epoch:26 step:24840 [D loss: 0.668867, acc.: 59.38%] [G loss: 0.932276]\n",
      "epoch:26 step:24841 [D loss: 0.664558, acc.: 56.25%] [G loss: 0.871728]\n",
      "epoch:26 step:24842 [D loss: 0.717807, acc.: 48.44%] [G loss: 0.866113]\n",
      "epoch:26 step:24843 [D loss: 0.644844, acc.: 60.94%] [G loss: 0.823040]\n",
      "epoch:26 step:24844 [D loss: 0.642133, acc.: 64.84%] [G loss: 0.898406]\n",
      "epoch:26 step:24845 [D loss: 0.662696, acc.: 54.69%] [G loss: 0.909758]\n",
      "epoch:26 step:24846 [D loss: 0.641503, acc.: 60.16%] [G loss: 0.897254]\n",
      "epoch:26 step:24847 [D loss: 0.640310, acc.: 64.84%] [G loss: 0.870474]\n",
      "epoch:26 step:24848 [D loss: 0.641550, acc.: 63.28%] [G loss: 0.866172]\n",
      "epoch:26 step:24849 [D loss: 0.669416, acc.: 54.69%] [G loss: 0.884620]\n",
      "epoch:26 step:24850 [D loss: 0.617842, acc.: 67.97%] [G loss: 0.847764]\n",
      "epoch:26 step:24851 [D loss: 0.639935, acc.: 61.72%] [G loss: 0.830420]\n",
      "epoch:26 step:24852 [D loss: 0.603880, acc.: 72.66%] [G loss: 0.835000]\n",
      "epoch:26 step:24853 [D loss: 0.667870, acc.: 61.72%] [G loss: 0.843139]\n",
      "epoch:26 step:24854 [D loss: 0.660912, acc.: 60.16%] [G loss: 0.895526]\n",
      "epoch:26 step:24855 [D loss: 0.678053, acc.: 57.81%] [G loss: 0.891279]\n",
      "epoch:26 step:24856 [D loss: 0.636735, acc.: 64.06%] [G loss: 0.889884]\n",
      "epoch:26 step:24857 [D loss: 0.671057, acc.: 59.38%] [G loss: 0.938675]\n",
      "epoch:26 step:24858 [D loss: 0.631200, acc.: 65.62%] [G loss: 0.903823]\n",
      "epoch:26 step:24859 [D loss: 0.643585, acc.: 65.62%] [G loss: 0.932525]\n",
      "epoch:26 step:24860 [D loss: 0.653425, acc.: 61.72%] [G loss: 0.963556]\n",
      "epoch:26 step:24861 [D loss: 0.653709, acc.: 61.72%] [G loss: 0.916835]\n",
      "epoch:26 step:24862 [D loss: 0.656002, acc.: 58.59%] [G loss: 0.855331]\n",
      "epoch:26 step:24863 [D loss: 0.676567, acc.: 58.59%] [G loss: 0.799755]\n",
      "epoch:26 step:24864 [D loss: 0.648318, acc.: 64.06%] [G loss: 0.824340]\n",
      "epoch:26 step:24865 [D loss: 0.654869, acc.: 64.06%] [G loss: 0.837392]\n",
      "epoch:26 step:24866 [D loss: 0.670769, acc.: 51.56%] [G loss: 0.869697]\n",
      "epoch:26 step:24867 [D loss: 0.630133, acc.: 64.06%] [G loss: 0.856581]\n",
      "epoch:26 step:24868 [D loss: 0.664589, acc.: 55.47%] [G loss: 0.823486]\n",
      "epoch:26 step:24869 [D loss: 0.644921, acc.: 64.06%] [G loss: 0.879755]\n",
      "epoch:26 step:24870 [D loss: 0.677294, acc.: 53.12%] [G loss: 0.917656]\n",
      "epoch:26 step:24871 [D loss: 0.636891, acc.: 62.50%] [G loss: 0.944461]\n",
      "epoch:26 step:24872 [D loss: 0.618768, acc.: 61.72%] [G loss: 0.923186]\n",
      "epoch:26 step:24873 [D loss: 0.648663, acc.: 61.72%] [G loss: 0.877181]\n",
      "epoch:26 step:24874 [D loss: 0.668533, acc.: 59.38%] [G loss: 0.872322]\n",
      "epoch:26 step:24875 [D loss: 0.647015, acc.: 60.94%] [G loss: 0.864119]\n",
      "epoch:26 step:24876 [D loss: 0.663174, acc.: 60.94%] [G loss: 0.858057]\n",
      "epoch:26 step:24877 [D loss: 0.662896, acc.: 60.16%] [G loss: 0.891669]\n",
      "epoch:26 step:24878 [D loss: 0.668288, acc.: 60.16%] [G loss: 0.898591]\n",
      "epoch:26 step:24879 [D loss: 0.629081, acc.: 71.88%] [G loss: 0.876817]\n",
      "epoch:26 step:24880 [D loss: 0.671446, acc.: 53.91%] [G loss: 0.873972]\n",
      "epoch:26 step:24881 [D loss: 0.637889, acc.: 64.06%] [G loss: 0.942584]\n",
      "epoch:26 step:24882 [D loss: 0.688819, acc.: 57.03%] [G loss: 0.836264]\n",
      "epoch:26 step:24883 [D loss: 0.656022, acc.: 60.94%] [G loss: 0.881352]\n",
      "epoch:26 step:24884 [D loss: 0.624669, acc.: 70.31%] [G loss: 0.902203]\n",
      "epoch:26 step:24885 [D loss: 0.626809, acc.: 68.75%] [G loss: 0.832432]\n",
      "epoch:26 step:24886 [D loss: 0.617508, acc.: 65.62%] [G loss: 0.902536]\n",
      "epoch:26 step:24887 [D loss: 0.667366, acc.: 58.59%] [G loss: 0.827693]\n",
      "epoch:26 step:24888 [D loss: 0.646680, acc.: 62.50%] [G loss: 0.903061]\n",
      "epoch:26 step:24889 [D loss: 0.694715, acc.: 46.88%] [G loss: 0.825682]\n",
      "epoch:26 step:24890 [D loss: 0.641951, acc.: 67.19%] [G loss: 0.830350]\n",
      "epoch:26 step:24891 [D loss: 0.655640, acc.: 57.81%] [G loss: 0.843721]\n",
      "epoch:26 step:24892 [D loss: 0.653751, acc.: 60.16%] [G loss: 0.862435]\n",
      "epoch:26 step:24893 [D loss: 0.678464, acc.: 55.47%] [G loss: 0.871269]\n",
      "epoch:26 step:24894 [D loss: 0.648962, acc.: 60.94%] [G loss: 0.891446]\n",
      "epoch:26 step:24895 [D loss: 0.676895, acc.: 58.59%] [G loss: 0.879040]\n",
      "epoch:26 step:24896 [D loss: 0.679237, acc.: 55.47%] [G loss: 0.870845]\n",
      "epoch:26 step:24897 [D loss: 0.638710, acc.: 62.50%] [G loss: 0.833005]\n",
      "epoch:26 step:24898 [D loss: 0.701366, acc.: 55.47%] [G loss: 0.919867]\n",
      "epoch:26 step:24899 [D loss: 0.671655, acc.: 54.69%] [G loss: 0.904220]\n",
      "epoch:26 step:24900 [D loss: 0.694264, acc.: 56.25%] [G loss: 0.898136]\n",
      "epoch:26 step:24901 [D loss: 0.669390, acc.: 61.72%] [G loss: 0.843635]\n",
      "epoch:26 step:24902 [D loss: 0.637064, acc.: 60.94%] [G loss: 0.837368]\n",
      "epoch:26 step:24903 [D loss: 0.645755, acc.: 63.28%] [G loss: 0.813426]\n",
      "epoch:26 step:24904 [D loss: 0.674674, acc.: 60.16%] [G loss: 0.873956]\n",
      "epoch:26 step:24905 [D loss: 0.639737, acc.: 63.28%] [G loss: 0.906080]\n",
      "epoch:26 step:24906 [D loss: 0.637176, acc.: 66.41%] [G loss: 0.858094]\n",
      "epoch:26 step:24907 [D loss: 0.668773, acc.: 57.81%] [G loss: 0.839658]\n",
      "epoch:26 step:24908 [D loss: 0.631284, acc.: 65.62%] [G loss: 0.872714]\n",
      "epoch:26 step:24909 [D loss: 0.675957, acc.: 57.03%] [G loss: 0.871233]\n",
      "epoch:26 step:24910 [D loss: 0.672123, acc.: 54.69%] [G loss: 0.895315]\n",
      "epoch:26 step:24911 [D loss: 0.632828, acc.: 64.06%] [G loss: 0.859990]\n",
      "epoch:26 step:24912 [D loss: 0.654585, acc.: 63.28%] [G loss: 0.904730]\n",
      "epoch:26 step:24913 [D loss: 0.644092, acc.: 60.94%] [G loss: 0.881087]\n",
      "epoch:26 step:24914 [D loss: 0.647730, acc.: 60.94%] [G loss: 0.944578]\n",
      "epoch:26 step:24915 [D loss: 0.666626, acc.: 57.81%] [G loss: 0.915230]\n",
      "epoch:26 step:24916 [D loss: 0.668271, acc.: 60.94%] [G loss: 0.914957]\n",
      "epoch:26 step:24917 [D loss: 0.645897, acc.: 62.50%] [G loss: 0.839793]\n",
      "epoch:26 step:24918 [D loss: 0.686503, acc.: 53.91%] [G loss: 0.889957]\n",
      "epoch:26 step:24919 [D loss: 0.651683, acc.: 61.72%] [G loss: 0.908777]\n",
      "epoch:26 step:24920 [D loss: 0.644701, acc.: 63.28%] [G loss: 0.926838]\n",
      "epoch:26 step:24921 [D loss: 0.694900, acc.: 53.91%] [G loss: 0.930043]\n",
      "epoch:26 step:24922 [D loss: 0.646839, acc.: 60.16%] [G loss: 0.902377]\n",
      "epoch:26 step:24923 [D loss: 0.673941, acc.: 60.94%] [G loss: 0.855647]\n",
      "epoch:26 step:24924 [D loss: 0.659604, acc.: 64.06%] [G loss: 0.856383]\n",
      "epoch:26 step:24925 [D loss: 0.635602, acc.: 67.19%] [G loss: 0.875435]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:24926 [D loss: 0.638325, acc.: 58.59%] [G loss: 0.881130]\n",
      "epoch:26 step:24927 [D loss: 0.644661, acc.: 60.94%] [G loss: 0.895171]\n",
      "epoch:26 step:24928 [D loss: 0.591993, acc.: 69.53%] [G loss: 0.882404]\n",
      "epoch:26 step:24929 [D loss: 0.657443, acc.: 59.38%] [G loss: 0.868508]\n",
      "epoch:26 step:24930 [D loss: 0.707931, acc.: 53.91%] [G loss: 0.875500]\n",
      "epoch:26 step:24931 [D loss: 0.651772, acc.: 59.38%] [G loss: 0.928481]\n",
      "epoch:26 step:24932 [D loss: 0.642728, acc.: 63.28%] [G loss: 0.963112]\n",
      "epoch:26 step:24933 [D loss: 0.679594, acc.: 53.91%] [G loss: 0.853682]\n",
      "epoch:26 step:24934 [D loss: 0.673791, acc.: 54.69%] [G loss: 0.899442]\n",
      "epoch:26 step:24935 [D loss: 0.671146, acc.: 62.50%] [G loss: 0.865182]\n",
      "epoch:26 step:24936 [D loss: 0.684431, acc.: 50.78%] [G loss: 0.900248]\n",
      "epoch:26 step:24937 [D loss: 0.704651, acc.: 49.22%] [G loss: 0.864025]\n",
      "epoch:26 step:24938 [D loss: 0.653724, acc.: 64.84%] [G loss: 0.880455]\n",
      "epoch:26 step:24939 [D loss: 0.618928, acc.: 66.41%] [G loss: 0.916377]\n",
      "epoch:26 step:24940 [D loss: 0.673639, acc.: 56.25%] [G loss: 0.866516]\n",
      "epoch:26 step:24941 [D loss: 0.649791, acc.: 59.38%] [G loss: 0.898006]\n",
      "epoch:26 step:24942 [D loss: 0.666237, acc.: 59.38%] [G loss: 0.919792]\n",
      "epoch:26 step:24943 [D loss: 0.664929, acc.: 55.47%] [G loss: 0.899774]\n",
      "epoch:26 step:24944 [D loss: 0.642668, acc.: 67.97%] [G loss: 0.931105]\n",
      "epoch:26 step:24945 [D loss: 0.665727, acc.: 58.59%] [G loss: 0.917208]\n",
      "epoch:26 step:24946 [D loss: 0.627917, acc.: 65.62%] [G loss: 0.899914]\n",
      "epoch:26 step:24947 [D loss: 0.636569, acc.: 63.28%] [G loss: 0.905637]\n",
      "epoch:26 step:24948 [D loss: 0.651415, acc.: 64.06%] [G loss: 0.850793]\n",
      "epoch:26 step:24949 [D loss: 0.659227, acc.: 55.47%] [G loss: 0.847613]\n",
      "epoch:26 step:24950 [D loss: 0.669424, acc.: 56.25%] [G loss: 0.887248]\n",
      "epoch:26 step:24951 [D loss: 0.645763, acc.: 64.06%] [G loss: 0.854512]\n",
      "epoch:26 step:24952 [D loss: 0.642441, acc.: 63.28%] [G loss: 0.876540]\n",
      "epoch:26 step:24953 [D loss: 0.678686, acc.: 57.81%] [G loss: 0.944855]\n",
      "epoch:26 step:24954 [D loss: 0.640070, acc.: 64.84%] [G loss: 0.841060]\n",
      "epoch:26 step:24955 [D loss: 0.678166, acc.: 53.91%] [G loss: 0.911904]\n",
      "epoch:26 step:24956 [D loss: 0.635797, acc.: 65.62%] [G loss: 0.958453]\n",
      "epoch:26 step:24957 [D loss: 0.640170, acc.: 64.06%] [G loss: 0.889656]\n",
      "epoch:26 step:24958 [D loss: 0.674951, acc.: 54.69%] [G loss: 0.933699]\n",
      "epoch:26 step:24959 [D loss: 0.640657, acc.: 60.94%] [G loss: 0.924169]\n",
      "epoch:26 step:24960 [D loss: 0.656698, acc.: 62.50%] [G loss: 0.965921]\n",
      "epoch:26 step:24961 [D loss: 0.612607, acc.: 68.75%] [G loss: 0.934144]\n",
      "epoch:26 step:24962 [D loss: 0.622729, acc.: 62.50%] [G loss: 0.921956]\n",
      "epoch:26 step:24963 [D loss: 0.676638, acc.: 55.47%] [G loss: 0.838817]\n",
      "epoch:26 step:24964 [D loss: 0.642371, acc.: 63.28%] [G loss: 0.862048]\n",
      "epoch:26 step:24965 [D loss: 0.668624, acc.: 54.69%] [G loss: 0.865424]\n",
      "epoch:26 step:24966 [D loss: 0.680606, acc.: 50.78%] [G loss: 0.866389]\n",
      "epoch:26 step:24967 [D loss: 0.640548, acc.: 57.81%] [G loss: 0.878463]\n",
      "epoch:26 step:24968 [D loss: 0.662235, acc.: 60.94%] [G loss: 0.894507]\n",
      "epoch:26 step:24969 [D loss: 0.667658, acc.: 60.94%] [G loss: 0.881734]\n",
      "epoch:26 step:24970 [D loss: 0.669490, acc.: 62.50%] [G loss: 0.898788]\n",
      "epoch:26 step:24971 [D loss: 0.654988, acc.: 67.19%] [G loss: 0.964022]\n",
      "epoch:26 step:24972 [D loss: 0.655871, acc.: 63.28%] [G loss: 0.921561]\n",
      "epoch:26 step:24973 [D loss: 0.669005, acc.: 57.81%] [G loss: 0.951791]\n",
      "epoch:26 step:24974 [D loss: 0.656203, acc.: 60.94%] [G loss: 0.928666]\n",
      "epoch:26 step:24975 [D loss: 0.645103, acc.: 65.62%] [G loss: 0.935367]\n",
      "epoch:26 step:24976 [D loss: 0.651084, acc.: 62.50%] [G loss: 0.890583]\n",
      "epoch:26 step:24977 [D loss: 0.654117, acc.: 64.84%] [G loss: 0.878429]\n",
      "epoch:26 step:24978 [D loss: 0.616696, acc.: 71.88%] [G loss: 0.893605]\n",
      "epoch:26 step:24979 [D loss: 0.644974, acc.: 64.06%] [G loss: 0.923898]\n",
      "epoch:26 step:24980 [D loss: 0.675777, acc.: 57.03%] [G loss: 0.951525]\n",
      "epoch:26 step:24981 [D loss: 0.672372, acc.: 60.16%] [G loss: 0.909067]\n",
      "epoch:26 step:24982 [D loss: 0.645744, acc.: 59.38%] [G loss: 0.923330]\n",
      "epoch:26 step:24983 [D loss: 0.654926, acc.: 55.47%] [G loss: 0.865051]\n",
      "epoch:26 step:24984 [D loss: 0.643323, acc.: 60.94%] [G loss: 0.862188]\n",
      "epoch:26 step:24985 [D loss: 0.638969, acc.: 62.50%] [G loss: 0.887484]\n",
      "epoch:26 step:24986 [D loss: 0.643688, acc.: 60.16%] [G loss: 0.935199]\n",
      "epoch:26 step:24987 [D loss: 0.607831, acc.: 68.75%] [G loss: 0.912102]\n",
      "epoch:26 step:24988 [D loss: 0.655388, acc.: 59.38%] [G loss: 0.928391]\n",
      "epoch:26 step:24989 [D loss: 0.649852, acc.: 59.38%] [G loss: 0.904897]\n",
      "epoch:26 step:24990 [D loss: 0.674143, acc.: 59.38%] [G loss: 0.935684]\n",
      "epoch:26 step:24991 [D loss: 0.637377, acc.: 67.19%] [G loss: 0.870487]\n",
      "epoch:26 step:24992 [D loss: 0.690631, acc.: 50.00%] [G loss: 0.828989]\n",
      "epoch:26 step:24993 [D loss: 0.630962, acc.: 64.06%] [G loss: 0.853927]\n",
      "epoch:26 step:24994 [D loss: 0.661519, acc.: 58.59%] [G loss: 0.902531]\n",
      "epoch:26 step:24995 [D loss: 0.627042, acc.: 64.06%] [G loss: 0.883318]\n",
      "epoch:26 step:24996 [D loss: 0.626365, acc.: 64.84%] [G loss: 0.922282]\n",
      "epoch:26 step:24997 [D loss: 0.630047, acc.: 62.50%] [G loss: 0.922742]\n",
      "epoch:26 step:24998 [D loss: 0.631848, acc.: 68.75%] [G loss: 0.920757]\n",
      "epoch:26 step:24999 [D loss: 0.604824, acc.: 70.31%] [G loss: 0.950100]\n",
      "epoch:26 step:25000 [D loss: 0.649692, acc.: 57.81%] [G loss: 0.930882]\n",
      "##############\n",
      "[2.68437947 2.53132546 2.0763449  3.59173396 1.20709319 7.59277987\n",
      " 2.70538931 3.40516281 4.17360928 8.14868929]\n",
      "##########\n",
      "epoch:26 step:25001 [D loss: 0.655760, acc.: 61.72%] [G loss: 0.910082]\n",
      "epoch:26 step:25002 [D loss: 0.625328, acc.: 66.41%] [G loss: 0.890112]\n",
      "epoch:26 step:25003 [D loss: 0.658095, acc.: 60.94%] [G loss: 0.948129]\n",
      "epoch:26 step:25004 [D loss: 0.649995, acc.: 63.28%] [G loss: 0.908640]\n",
      "epoch:26 step:25005 [D loss: 0.699227, acc.: 50.78%] [G loss: 0.885321]\n",
      "epoch:26 step:25006 [D loss: 0.638372, acc.: 60.94%] [G loss: 0.852525]\n",
      "epoch:26 step:25007 [D loss: 0.655238, acc.: 59.38%] [G loss: 0.851844]\n",
      "epoch:26 step:25008 [D loss: 0.674214, acc.: 56.25%] [G loss: 0.879294]\n",
      "epoch:26 step:25009 [D loss: 0.710267, acc.: 54.69%] [G loss: 0.837585]\n",
      "epoch:26 step:25010 [D loss: 0.613933, acc.: 64.84%] [G loss: 0.885831]\n",
      "epoch:26 step:25011 [D loss: 0.646012, acc.: 64.06%] [G loss: 0.968039]\n",
      "epoch:26 step:25012 [D loss: 0.617222, acc.: 64.84%] [G loss: 0.955039]\n",
      "epoch:26 step:25013 [D loss: 0.621563, acc.: 66.41%] [G loss: 0.922423]\n",
      "epoch:26 step:25014 [D loss: 0.635951, acc.: 60.94%] [G loss: 0.900275]\n",
      "epoch:26 step:25015 [D loss: 0.619776, acc.: 67.19%] [G loss: 0.894624]\n",
      "epoch:26 step:25016 [D loss: 0.622023, acc.: 64.06%] [G loss: 0.869414]\n",
      "epoch:26 step:25017 [D loss: 0.669311, acc.: 57.81%] [G loss: 0.875665]\n",
      "epoch:26 step:25018 [D loss: 0.620725, acc.: 65.62%] [G loss: 0.870775]\n",
      "epoch:26 step:25019 [D loss: 0.655854, acc.: 57.81%] [G loss: 0.891973]\n",
      "epoch:26 step:25020 [D loss: 0.723621, acc.: 52.34%] [G loss: 0.853337]\n",
      "epoch:26 step:25021 [D loss: 0.654577, acc.: 60.16%] [G loss: 0.857082]\n",
      "epoch:26 step:25022 [D loss: 0.677904, acc.: 56.25%] [G loss: 0.878832]\n",
      "epoch:26 step:25023 [D loss: 0.639351, acc.: 66.41%] [G loss: 0.855511]\n",
      "epoch:26 step:25024 [D loss: 0.671420, acc.: 60.16%] [G loss: 0.861097]\n",
      "epoch:26 step:25025 [D loss: 0.657002, acc.: 59.38%] [G loss: 0.909543]\n",
      "epoch:26 step:25026 [D loss: 0.641140, acc.: 66.41%] [G loss: 0.925317]\n",
      "epoch:26 step:25027 [D loss: 0.673740, acc.: 64.06%] [G loss: 0.925306]\n",
      "epoch:26 step:25028 [D loss: 0.630649, acc.: 67.19%] [G loss: 0.992270]\n",
      "epoch:26 step:25029 [D loss: 0.684503, acc.: 59.38%] [G loss: 0.941916]\n",
      "epoch:26 step:25030 [D loss: 0.638381, acc.: 64.84%] [G loss: 0.922813]\n",
      "epoch:26 step:25031 [D loss: 0.673302, acc.: 58.59%] [G loss: 0.864583]\n",
      "epoch:26 step:25032 [D loss: 0.646682, acc.: 63.28%] [G loss: 0.915501]\n",
      "epoch:26 step:25033 [D loss: 0.649478, acc.: 64.84%] [G loss: 0.880254]\n",
      "epoch:26 step:25034 [D loss: 0.665050, acc.: 54.69%] [G loss: 0.853138]\n",
      "epoch:26 step:25035 [D loss: 0.686457, acc.: 56.25%] [G loss: 0.858993]\n",
      "epoch:26 step:25036 [D loss: 0.666013, acc.: 54.69%] [G loss: 0.867808]\n",
      "epoch:26 step:25037 [D loss: 0.639131, acc.: 64.06%] [G loss: 0.832685]\n",
      "epoch:26 step:25038 [D loss: 0.650758, acc.: 63.28%] [G loss: 0.908213]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:25039 [D loss: 0.670298, acc.: 57.03%] [G loss: 0.888680]\n",
      "epoch:26 step:25040 [D loss: 0.669378, acc.: 57.81%] [G loss: 0.924703]\n",
      "epoch:26 step:25041 [D loss: 0.650873, acc.: 64.84%] [G loss: 0.904997]\n",
      "epoch:26 step:25042 [D loss: 0.699054, acc.: 55.47%] [G loss: 0.817303]\n",
      "epoch:26 step:25043 [D loss: 0.694276, acc.: 60.16%] [G loss: 0.872703]\n",
      "epoch:26 step:25044 [D loss: 0.651587, acc.: 57.81%] [G loss: 0.914696]\n",
      "epoch:26 step:25045 [D loss: 0.621538, acc.: 67.97%] [G loss: 0.884228]\n",
      "epoch:26 step:25046 [D loss: 0.699111, acc.: 53.12%] [G loss: 0.869513]\n",
      "epoch:26 step:25047 [D loss: 0.656062, acc.: 57.81%] [G loss: 0.942680]\n",
      "epoch:26 step:25048 [D loss: 0.655017, acc.: 60.94%] [G loss: 0.921797]\n",
      "epoch:26 step:25049 [D loss: 0.665960, acc.: 58.59%] [G loss: 0.964754]\n",
      "epoch:26 step:25050 [D loss: 0.647969, acc.: 64.06%] [G loss: 0.917733]\n",
      "epoch:26 step:25051 [D loss: 0.661161, acc.: 61.72%] [G loss: 0.902829]\n",
      "epoch:26 step:25052 [D loss: 0.616694, acc.: 66.41%] [G loss: 0.937809]\n",
      "epoch:26 step:25053 [D loss: 0.686522, acc.: 55.47%] [G loss: 0.938657]\n",
      "epoch:26 step:25054 [D loss: 0.632763, acc.: 60.94%] [G loss: 0.892683]\n",
      "epoch:26 step:25055 [D loss: 0.674924, acc.: 60.94%] [G loss: 0.874324]\n",
      "epoch:26 step:25056 [D loss: 0.640370, acc.: 67.97%] [G loss: 0.903645]\n",
      "epoch:26 step:25057 [D loss: 0.656263, acc.: 67.97%] [G loss: 0.861659]\n",
      "epoch:26 step:25058 [D loss: 0.636856, acc.: 66.41%] [G loss: 0.939922]\n",
      "epoch:26 step:25059 [D loss: 0.644195, acc.: 61.72%] [G loss: 0.902512]\n",
      "epoch:26 step:25060 [D loss: 0.657011, acc.: 63.28%] [G loss: 0.855914]\n",
      "epoch:26 step:25061 [D loss: 0.657978, acc.: 59.38%] [G loss: 0.841408]\n",
      "epoch:26 step:25062 [D loss: 0.658260, acc.: 63.28%] [G loss: 0.862802]\n",
      "epoch:26 step:25063 [D loss: 0.696130, acc.: 58.59%] [G loss: 0.920449]\n",
      "epoch:26 step:25064 [D loss: 0.627410, acc.: 64.06%] [G loss: 0.919782]\n",
      "epoch:26 step:25065 [D loss: 0.711696, acc.: 53.12%] [G loss: 0.876610]\n",
      "epoch:26 step:25066 [D loss: 0.671889, acc.: 57.81%] [G loss: 0.919895]\n",
      "epoch:26 step:25067 [D loss: 0.630537, acc.: 61.72%] [G loss: 0.857637]\n",
      "epoch:26 step:25068 [D loss: 0.671822, acc.: 58.59%] [G loss: 0.897269]\n",
      "epoch:26 step:25069 [D loss: 0.648432, acc.: 60.94%] [G loss: 0.855639]\n",
      "epoch:26 step:25070 [D loss: 0.645464, acc.: 62.50%] [G loss: 0.848536]\n",
      "epoch:26 step:25071 [D loss: 0.676602, acc.: 54.69%] [G loss: 0.894398]\n",
      "epoch:26 step:25072 [D loss: 0.610500, acc.: 67.19%] [G loss: 0.912450]\n",
      "epoch:26 step:25073 [D loss: 0.642798, acc.: 64.06%] [G loss: 0.928652]\n",
      "epoch:26 step:25074 [D loss: 0.695204, acc.: 58.59%] [G loss: 0.873715]\n",
      "epoch:26 step:25075 [D loss: 0.671881, acc.: 55.47%] [G loss: 0.937732]\n",
      "epoch:26 step:25076 [D loss: 0.619864, acc.: 64.06%] [G loss: 0.883546]\n",
      "epoch:26 step:25077 [D loss: 0.709080, acc.: 53.12%] [G loss: 0.830209]\n",
      "epoch:26 step:25078 [D loss: 0.658162, acc.: 61.72%] [G loss: 0.881127]\n",
      "epoch:26 step:25079 [D loss: 0.653027, acc.: 60.16%] [G loss: 0.936793]\n",
      "epoch:26 step:25080 [D loss: 0.631746, acc.: 61.72%] [G loss: 0.989095]\n",
      "epoch:26 step:25081 [D loss: 0.658713, acc.: 59.38%] [G loss: 0.840731]\n",
      "epoch:26 step:25082 [D loss: 0.651417, acc.: 56.25%] [G loss: 0.913162]\n",
      "epoch:26 step:25083 [D loss: 0.662162, acc.: 54.69%] [G loss: 0.887503]\n",
      "epoch:26 step:25084 [D loss: 0.633861, acc.: 62.50%] [G loss: 0.896300]\n",
      "epoch:26 step:25085 [D loss: 0.701843, acc.: 55.47%] [G loss: 0.910431]\n",
      "epoch:26 step:25086 [D loss: 0.633423, acc.: 64.84%] [G loss: 0.916967]\n",
      "epoch:26 step:25087 [D loss: 0.607232, acc.: 71.09%] [G loss: 0.922343]\n",
      "epoch:26 step:25088 [D loss: 0.667046, acc.: 61.72%] [G loss: 0.881399]\n",
      "epoch:26 step:25089 [D loss: 0.699810, acc.: 49.22%] [G loss: 0.815737]\n",
      "epoch:26 step:25090 [D loss: 0.653977, acc.: 64.84%] [G loss: 0.855336]\n",
      "epoch:26 step:25091 [D loss: 0.636750, acc.: 57.81%] [G loss: 0.809103]\n",
      "epoch:26 step:25092 [D loss: 0.657177, acc.: 53.91%] [G loss: 0.857120]\n",
      "epoch:26 step:25093 [D loss: 0.631326, acc.: 64.84%] [G loss: 0.876019]\n",
      "epoch:26 step:25094 [D loss: 0.637458, acc.: 61.72%] [G loss: 0.932350]\n",
      "epoch:26 step:25095 [D loss: 0.642691, acc.: 63.28%] [G loss: 0.935734]\n",
      "epoch:26 step:25096 [D loss: 0.655951, acc.: 59.38%] [G loss: 0.920129]\n",
      "epoch:26 step:25097 [D loss: 0.661361, acc.: 62.50%] [G loss: 0.828333]\n",
      "epoch:26 step:25098 [D loss: 0.615360, acc.: 65.62%] [G loss: 0.879335]\n",
      "epoch:26 step:25099 [D loss: 0.683195, acc.: 57.03%] [G loss: 0.924738]\n",
      "epoch:26 step:25100 [D loss: 0.673903, acc.: 50.00%] [G loss: 0.845337]\n",
      "epoch:26 step:25101 [D loss: 0.627705, acc.: 66.41%] [G loss: 0.869773]\n",
      "epoch:26 step:25102 [D loss: 0.679600, acc.: 52.34%] [G loss: 0.950000]\n",
      "epoch:26 step:25103 [D loss: 0.689525, acc.: 56.25%] [G loss: 0.898648]\n",
      "epoch:26 step:25104 [D loss: 0.648422, acc.: 60.94%] [G loss: 0.907776]\n",
      "epoch:26 step:25105 [D loss: 0.688816, acc.: 50.00%] [G loss: 0.874354]\n",
      "epoch:26 step:25106 [D loss: 0.650292, acc.: 62.50%] [G loss: 0.864819]\n",
      "epoch:26 step:25107 [D loss: 0.641199, acc.: 67.19%] [G loss: 0.923723]\n",
      "epoch:26 step:25108 [D loss: 0.639850, acc.: 64.06%] [G loss: 0.893479]\n",
      "epoch:26 step:25109 [D loss: 0.623321, acc.: 67.19%] [G loss: 0.906581]\n",
      "epoch:26 step:25110 [D loss: 0.628768, acc.: 65.62%] [G loss: 0.918185]\n",
      "epoch:26 step:25111 [D loss: 0.625872, acc.: 68.75%] [G loss: 0.863392]\n",
      "epoch:26 step:25112 [D loss: 0.656973, acc.: 59.38%] [G loss: 0.928230]\n",
      "epoch:26 step:25113 [D loss: 0.598359, acc.: 69.53%] [G loss: 0.914489]\n",
      "epoch:26 step:25114 [D loss: 0.626500, acc.: 65.62%] [G loss: 0.929685]\n",
      "epoch:26 step:25115 [D loss: 0.672944, acc.: 60.94%] [G loss: 0.879721]\n",
      "epoch:26 step:25116 [D loss: 0.646207, acc.: 62.50%] [G loss: 0.945094]\n",
      "epoch:26 step:25117 [D loss: 0.675049, acc.: 54.69%] [G loss: 0.914534]\n",
      "epoch:26 step:25118 [D loss: 0.655112, acc.: 58.59%] [G loss: 0.888405]\n",
      "epoch:26 step:25119 [D loss: 0.656624, acc.: 60.16%] [G loss: 0.955847]\n",
      "epoch:26 step:25120 [D loss: 0.669039, acc.: 61.72%] [G loss: 0.942692]\n",
      "epoch:26 step:25121 [D loss: 0.670508, acc.: 59.38%] [G loss: 0.807623]\n",
      "epoch:26 step:25122 [D loss: 0.625702, acc.: 63.28%] [G loss: 0.851490]\n",
      "epoch:26 step:25123 [D loss: 0.629178, acc.: 67.19%] [G loss: 0.867738]\n",
      "epoch:26 step:25124 [D loss: 0.624249, acc.: 67.19%] [G loss: 0.858387]\n",
      "epoch:26 step:25125 [D loss: 0.660430, acc.: 60.94%] [G loss: 0.842054]\n",
      "epoch:26 step:25126 [D loss: 0.664250, acc.: 64.84%] [G loss: 0.851130]\n",
      "epoch:26 step:25127 [D loss: 0.686094, acc.: 48.44%] [G loss: 0.898843]\n",
      "epoch:26 step:25128 [D loss: 0.640463, acc.: 62.50%] [G loss: 0.858047]\n",
      "epoch:26 step:25129 [D loss: 0.648626, acc.: 60.16%] [G loss: 0.846308]\n",
      "epoch:26 step:25130 [D loss: 0.629552, acc.: 64.84%] [G loss: 0.835185]\n",
      "epoch:26 step:25131 [D loss: 0.634379, acc.: 65.62%] [G loss: 0.926311]\n",
      "epoch:26 step:25132 [D loss: 0.662545, acc.: 60.94%] [G loss: 0.917247]\n",
      "epoch:26 step:25133 [D loss: 0.683581, acc.: 53.12%] [G loss: 0.899099]\n",
      "epoch:26 step:25134 [D loss: 0.654676, acc.: 64.84%] [G loss: 0.916798]\n",
      "epoch:26 step:25135 [D loss: 0.652970, acc.: 60.16%] [G loss: 0.864837]\n",
      "epoch:26 step:25136 [D loss: 0.612412, acc.: 64.84%] [G loss: 0.887587]\n",
      "epoch:26 step:25137 [D loss: 0.639231, acc.: 62.50%] [G loss: 0.927139]\n",
      "epoch:26 step:25138 [D loss: 0.675787, acc.: 54.69%] [G loss: 0.891348]\n",
      "epoch:26 step:25139 [D loss: 0.681496, acc.: 52.34%] [G loss: 0.873277]\n",
      "epoch:26 step:25140 [D loss: 0.656847, acc.: 57.81%] [G loss: 0.887188]\n",
      "epoch:26 step:25141 [D loss: 0.631303, acc.: 69.53%] [G loss: 0.834081]\n",
      "epoch:26 step:25142 [D loss: 0.659810, acc.: 59.38%] [G loss: 0.901121]\n",
      "epoch:26 step:25143 [D loss: 0.680262, acc.: 62.50%] [G loss: 0.863267]\n",
      "epoch:26 step:25144 [D loss: 0.640556, acc.: 63.28%] [G loss: 0.913523]\n",
      "epoch:26 step:25145 [D loss: 0.606332, acc.: 61.72%] [G loss: 0.914235]\n",
      "epoch:26 step:25146 [D loss: 0.644181, acc.: 54.69%] [G loss: 0.860135]\n",
      "epoch:26 step:25147 [D loss: 0.702259, acc.: 53.12%] [G loss: 0.866020]\n",
      "epoch:26 step:25148 [D loss: 0.676909, acc.: 59.38%] [G loss: 0.869345]\n",
      "epoch:26 step:25149 [D loss: 0.655304, acc.: 56.25%] [G loss: 0.827284]\n",
      "epoch:26 step:25150 [D loss: 0.624871, acc.: 67.19%] [G loss: 0.912508]\n",
      "epoch:26 step:25151 [D loss: 0.623586, acc.: 67.97%] [G loss: 0.893135]\n",
      "epoch:26 step:25152 [D loss: 0.682537, acc.: 59.38%] [G loss: 0.838451]\n",
      "epoch:26 step:25153 [D loss: 0.648447, acc.: 63.28%] [G loss: 0.889599]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:25154 [D loss: 0.651404, acc.: 59.38%] [G loss: 0.887785]\n",
      "epoch:26 step:25155 [D loss: 0.621819, acc.: 67.19%] [G loss: 0.878087]\n",
      "epoch:26 step:25156 [D loss: 0.620944, acc.: 70.31%] [G loss: 0.800291]\n",
      "epoch:26 step:25157 [D loss: 0.667643, acc.: 57.81%] [G loss: 0.890990]\n",
      "epoch:26 step:25158 [D loss: 0.661132, acc.: 59.38%] [G loss: 0.983225]\n",
      "epoch:26 step:25159 [D loss: 0.661837, acc.: 55.47%] [G loss: 0.915299]\n",
      "epoch:26 step:25160 [D loss: 0.655020, acc.: 66.41%] [G loss: 0.905064]\n",
      "epoch:26 step:25161 [D loss: 0.642701, acc.: 65.62%] [G loss: 0.916914]\n",
      "epoch:26 step:25162 [D loss: 0.632936, acc.: 67.19%] [G loss: 0.913857]\n",
      "epoch:26 step:25163 [D loss: 0.650560, acc.: 63.28%] [G loss: 0.959630]\n",
      "epoch:26 step:25164 [D loss: 0.640824, acc.: 64.84%] [G loss: 0.891285]\n",
      "epoch:26 step:25165 [D loss: 0.650729, acc.: 65.62%] [G loss: 0.922644]\n",
      "epoch:26 step:25166 [D loss: 0.666385, acc.: 59.38%] [G loss: 0.866528]\n",
      "epoch:26 step:25167 [D loss: 0.650765, acc.: 58.59%] [G loss: 0.830196]\n",
      "epoch:26 step:25168 [D loss: 0.661798, acc.: 56.25%] [G loss: 0.841740]\n",
      "epoch:26 step:25169 [D loss: 0.623365, acc.: 66.41%] [G loss: 0.883429]\n",
      "epoch:26 step:25170 [D loss: 0.650890, acc.: 62.50%] [G loss: 0.919954]\n",
      "epoch:26 step:25171 [D loss: 0.642247, acc.: 61.72%] [G loss: 0.881422]\n",
      "epoch:26 step:25172 [D loss: 0.685560, acc.: 55.47%] [G loss: 0.881395]\n",
      "epoch:26 step:25173 [D loss: 0.651057, acc.: 59.38%] [G loss: 0.899355]\n",
      "epoch:26 step:25174 [D loss: 0.644715, acc.: 62.50%] [G loss: 0.916092]\n",
      "epoch:26 step:25175 [D loss: 0.653135, acc.: 60.16%] [G loss: 0.931854]\n",
      "epoch:26 step:25176 [D loss: 0.620560, acc.: 65.62%] [G loss: 0.872149]\n",
      "epoch:26 step:25177 [D loss: 0.666569, acc.: 64.06%] [G loss: 0.893736]\n",
      "epoch:26 step:25178 [D loss: 0.607975, acc.: 68.75%] [G loss: 0.928654]\n",
      "epoch:26 step:25179 [D loss: 0.706070, acc.: 57.03%] [G loss: 0.855079]\n",
      "epoch:26 step:25180 [D loss: 0.650077, acc.: 60.94%] [G loss: 0.897543]\n",
      "epoch:26 step:25181 [D loss: 0.668128, acc.: 56.25%] [G loss: 0.943467]\n",
      "epoch:26 step:25182 [D loss: 0.663665, acc.: 60.16%] [G loss: 0.911453]\n",
      "epoch:26 step:25183 [D loss: 0.683113, acc.: 57.03%] [G loss: 0.988500]\n",
      "epoch:26 step:25184 [D loss: 0.625097, acc.: 64.84%] [G loss: 0.923238]\n",
      "epoch:26 step:25185 [D loss: 0.690988, acc.: 54.69%] [G loss: 0.927041]\n",
      "epoch:26 step:25186 [D loss: 0.648925, acc.: 64.06%] [G loss: 0.827589]\n",
      "epoch:26 step:25187 [D loss: 0.687297, acc.: 55.47%] [G loss: 0.852912]\n",
      "epoch:26 step:25188 [D loss: 0.595992, acc.: 73.44%] [G loss: 0.897213]\n",
      "epoch:26 step:25189 [D loss: 0.670533, acc.: 59.38%] [G loss: 0.941155]\n",
      "epoch:26 step:25190 [D loss: 0.668372, acc.: 59.38%] [G loss: 0.869778]\n",
      "epoch:26 step:25191 [D loss: 0.663480, acc.: 63.28%] [G loss: 0.873612]\n",
      "epoch:26 step:25192 [D loss: 0.665644, acc.: 55.47%] [G loss: 0.968714]\n",
      "epoch:26 step:25193 [D loss: 0.651787, acc.: 63.28%] [G loss: 0.885532]\n",
      "epoch:26 step:25194 [D loss: 0.605818, acc.: 72.66%] [G loss: 0.949876]\n",
      "epoch:26 step:25195 [D loss: 0.645020, acc.: 62.50%] [G loss: 0.885936]\n",
      "epoch:26 step:25196 [D loss: 0.669501, acc.: 58.59%] [G loss: 0.932310]\n",
      "epoch:26 step:25197 [D loss: 0.672185, acc.: 58.59%] [G loss: 0.897472]\n",
      "epoch:26 step:25198 [D loss: 0.717312, acc.: 51.56%] [G loss: 0.891004]\n",
      "epoch:26 step:25199 [D loss: 0.644614, acc.: 60.94%] [G loss: 0.932650]\n",
      "epoch:26 step:25200 [D loss: 0.628083, acc.: 60.94%] [G loss: 0.925835]\n",
      "##############\n",
      "[2.94549975 2.6904167  2.25071037 3.8474784  1.5936167  7.42863349\n",
      " 2.66120949 3.62913343 4.39492036 7.14868929]\n",
      "##########\n",
      "epoch:26 step:25201 [D loss: 0.619552, acc.: 61.72%] [G loss: 0.951113]\n",
      "epoch:26 step:25202 [D loss: 0.645050, acc.: 59.38%] [G loss: 0.928267]\n",
      "epoch:26 step:25203 [D loss: 0.666712, acc.: 60.16%] [G loss: 0.902004]\n",
      "epoch:26 step:25204 [D loss: 0.654229, acc.: 60.16%] [G loss: 0.862962]\n",
      "epoch:26 step:25205 [D loss: 0.677038, acc.: 55.47%] [G loss: 0.816269]\n",
      "epoch:26 step:25206 [D loss: 0.630608, acc.: 61.72%] [G loss: 0.882710]\n",
      "epoch:26 step:25207 [D loss: 0.676169, acc.: 57.81%] [G loss: 0.821167]\n",
      "epoch:26 step:25208 [D loss: 0.651656, acc.: 60.16%] [G loss: 0.910727]\n",
      "epoch:26 step:25209 [D loss: 0.658789, acc.: 57.03%] [G loss: 0.920738]\n",
      "epoch:26 step:25210 [D loss: 0.671504, acc.: 59.38%] [G loss: 0.913234]\n",
      "epoch:26 step:25211 [D loss: 0.670177, acc.: 61.72%] [G loss: 0.940916]\n",
      "epoch:26 step:25212 [D loss: 0.625335, acc.: 68.75%] [G loss: 0.928347]\n",
      "epoch:26 step:25213 [D loss: 0.638602, acc.: 65.62%] [G loss: 0.978899]\n",
      "epoch:26 step:25214 [D loss: 0.645224, acc.: 59.38%] [G loss: 0.896558]\n",
      "epoch:26 step:25215 [D loss: 0.643227, acc.: 58.59%] [G loss: 0.890609]\n",
      "epoch:26 step:25216 [D loss: 0.634047, acc.: 67.19%] [G loss: 0.859199]\n",
      "epoch:26 step:25217 [D loss: 0.683424, acc.: 57.81%] [G loss: 0.929026]\n",
      "epoch:26 step:25218 [D loss: 0.627578, acc.: 66.41%] [G loss: 0.923811]\n",
      "epoch:26 step:25219 [D loss: 0.702676, acc.: 54.69%] [G loss: 0.889691]\n",
      "epoch:26 step:25220 [D loss: 0.628639, acc.: 64.84%] [G loss: 0.917040]\n",
      "epoch:26 step:25221 [D loss: 0.654547, acc.: 62.50%] [G loss: 0.894579]\n",
      "epoch:26 step:25222 [D loss: 0.648004, acc.: 57.81%] [G loss: 0.924667]\n",
      "epoch:26 step:25223 [D loss: 0.631345, acc.: 68.75%] [G loss: 0.920712]\n",
      "epoch:26 step:25224 [D loss: 0.657204, acc.: 65.62%] [G loss: 0.898836]\n",
      "epoch:26 step:25225 [D loss: 0.660061, acc.: 57.03%] [G loss: 0.921032]\n",
      "epoch:26 step:25226 [D loss: 0.681755, acc.: 57.03%] [G loss: 0.891152]\n",
      "epoch:26 step:25227 [D loss: 0.638612, acc.: 59.38%] [G loss: 0.867245]\n",
      "epoch:26 step:25228 [D loss: 0.673566, acc.: 57.81%] [G loss: 0.906504]\n",
      "epoch:26 step:25229 [D loss: 0.662243, acc.: 60.16%] [G loss: 0.858518]\n",
      "epoch:26 step:25230 [D loss: 0.645754, acc.: 65.62%] [G loss: 0.854541]\n",
      "epoch:26 step:25231 [D loss: 0.653145, acc.: 62.50%] [G loss: 0.863710]\n",
      "epoch:26 step:25232 [D loss: 0.691801, acc.: 50.78%] [G loss: 0.899722]\n",
      "epoch:26 step:25233 [D loss: 0.623790, acc.: 71.09%] [G loss: 0.872910]\n",
      "epoch:26 step:25234 [D loss: 0.649060, acc.: 61.72%] [G loss: 0.940061]\n",
      "epoch:26 step:25235 [D loss: 0.623854, acc.: 64.06%] [G loss: 0.958068]\n",
      "epoch:26 step:25236 [D loss: 0.670105, acc.: 60.94%] [G loss: 0.924192]\n",
      "epoch:26 step:25237 [D loss: 0.626471, acc.: 64.84%] [G loss: 0.872550]\n",
      "epoch:26 step:25238 [D loss: 0.684504, acc.: 53.91%] [G loss: 0.893134]\n",
      "epoch:26 step:25239 [D loss: 0.624438, acc.: 64.84%] [G loss: 0.899928]\n",
      "epoch:26 step:25240 [D loss: 0.644167, acc.: 65.62%] [G loss: 0.989297]\n",
      "epoch:26 step:25241 [D loss: 0.631377, acc.: 67.19%] [G loss: 0.936793]\n",
      "epoch:26 step:25242 [D loss: 0.631481, acc.: 65.62%] [G loss: 0.913932]\n",
      "epoch:26 step:25243 [D loss: 0.696663, acc.: 48.44%] [G loss: 0.929300]\n",
      "epoch:26 step:25244 [D loss: 0.629974, acc.: 67.19%] [G loss: 0.923055]\n",
      "epoch:26 step:25245 [D loss: 0.638134, acc.: 61.72%] [G loss: 0.870113]\n",
      "epoch:26 step:25246 [D loss: 0.644795, acc.: 62.50%] [G loss: 0.922054]\n",
      "epoch:26 step:25247 [D loss: 0.622293, acc.: 62.50%] [G loss: 0.890723]\n",
      "epoch:26 step:25248 [D loss: 0.614814, acc.: 72.66%] [G loss: 0.998428]\n",
      "epoch:26 step:25249 [D loss: 0.654258, acc.: 63.28%] [G loss: 0.886516]\n",
      "epoch:26 step:25250 [D loss: 0.696460, acc.: 54.69%] [G loss: 0.878740]\n",
      "epoch:26 step:25251 [D loss: 0.655172, acc.: 58.59%] [G loss: 0.934882]\n",
      "epoch:26 step:25252 [D loss: 0.632180, acc.: 65.62%] [G loss: 0.956071]\n",
      "epoch:26 step:25253 [D loss: 0.680525, acc.: 54.69%] [G loss: 0.914421]\n",
      "epoch:26 step:25254 [D loss: 0.669236, acc.: 57.03%] [G loss: 0.902499]\n",
      "epoch:26 step:25255 [D loss: 0.652507, acc.: 60.94%] [G loss: 0.885064]\n",
      "epoch:26 step:25256 [D loss: 0.685709, acc.: 57.81%] [G loss: 0.849813]\n",
      "epoch:26 step:25257 [D loss: 0.626430, acc.: 70.31%] [G loss: 0.884535]\n",
      "epoch:26 step:25258 [D loss: 0.645942, acc.: 61.72%] [G loss: 0.939018]\n",
      "epoch:26 step:25259 [D loss: 0.633971, acc.: 64.06%] [G loss: 0.854138]\n",
      "epoch:26 step:25260 [D loss: 0.635323, acc.: 61.72%] [G loss: 0.896794]\n",
      "epoch:26 step:25261 [D loss: 0.657073, acc.: 59.38%] [G loss: 0.848091]\n",
      "epoch:26 step:25262 [D loss: 0.615240, acc.: 67.19%] [G loss: 0.853905]\n",
      "epoch:26 step:25263 [D loss: 0.655372, acc.: 59.38%] [G loss: 0.923411]\n",
      "epoch:26 step:25264 [D loss: 0.659691, acc.: 60.94%] [G loss: 0.908063]\n",
      "epoch:26 step:25265 [D loss: 0.598048, acc.: 71.09%] [G loss: 0.923349]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:26 step:25266 [D loss: 0.611013, acc.: 67.97%] [G loss: 0.922270]\n",
      "epoch:26 step:25267 [D loss: 0.674973, acc.: 57.81%] [G loss: 0.860472]\n",
      "epoch:26 step:25268 [D loss: 0.631000, acc.: 66.41%] [G loss: 0.870996]\n",
      "epoch:26 step:25269 [D loss: 0.738172, acc.: 50.78%] [G loss: 0.910668]\n",
      "epoch:26 step:25270 [D loss: 0.661043, acc.: 57.03%] [G loss: 0.897972]\n",
      "epoch:26 step:25271 [D loss: 0.696561, acc.: 52.34%] [G loss: 0.855974]\n",
      "epoch:26 step:25272 [D loss: 0.684016, acc.: 54.69%] [G loss: 0.940104]\n",
      "epoch:26 step:25273 [D loss: 0.623207, acc.: 67.97%] [G loss: 0.892179]\n",
      "epoch:26 step:25274 [D loss: 0.671663, acc.: 55.47%] [G loss: 0.911818]\n",
      "epoch:26 step:25275 [D loss: 0.689497, acc.: 53.91%] [G loss: 0.903297]\n",
      "epoch:26 step:25276 [D loss: 0.700622, acc.: 53.91%] [G loss: 0.926430]\n",
      "epoch:26 step:25277 [D loss: 0.670778, acc.: 58.59%] [G loss: 0.886311]\n",
      "epoch:26 step:25278 [D loss: 0.659902, acc.: 64.84%] [G loss: 0.923408]\n",
      "epoch:26 step:25279 [D loss: 0.642414, acc.: 64.06%] [G loss: 0.896477]\n",
      "epoch:26 step:25280 [D loss: 0.648830, acc.: 59.38%] [G loss: 0.847791]\n",
      "epoch:26 step:25281 [D loss: 0.672600, acc.: 57.81%] [G loss: 0.911967]\n",
      "epoch:26 step:25282 [D loss: 0.665602, acc.: 57.03%] [G loss: 0.857726]\n",
      "epoch:26 step:25283 [D loss: 0.664947, acc.: 59.38%] [G loss: 0.931010]\n",
      "epoch:26 step:25284 [D loss: 0.679229, acc.: 56.25%] [G loss: 0.902301]\n",
      "epoch:26 step:25285 [D loss: 0.657200, acc.: 54.69%] [G loss: 0.896816]\n",
      "epoch:26 step:25286 [D loss: 0.665063, acc.: 61.72%] [G loss: 0.957833]\n",
      "epoch:26 step:25287 [D loss: 0.658976, acc.: 62.50%] [G loss: 0.860748]\n",
      "epoch:26 step:25288 [D loss: 0.651048, acc.: 60.94%] [G loss: 0.908104]\n",
      "epoch:26 step:25289 [D loss: 0.665837, acc.: 56.25%] [G loss: 0.883079]\n",
      "epoch:26 step:25290 [D loss: 0.653269, acc.: 61.72%] [G loss: 0.884901]\n",
      "epoch:26 step:25291 [D loss: 0.691061, acc.: 53.91%] [G loss: 0.898815]\n",
      "epoch:26 step:25292 [D loss: 0.637074, acc.: 63.28%] [G loss: 0.943401]\n",
      "epoch:26 step:25293 [D loss: 0.666767, acc.: 56.25%] [G loss: 0.899962]\n",
      "epoch:26 step:25294 [D loss: 0.653390, acc.: 64.06%] [G loss: 0.874045]\n",
      "epoch:26 step:25295 [D loss: 0.726622, acc.: 48.44%] [G loss: 0.858956]\n",
      "epoch:26 step:25296 [D loss: 0.647079, acc.: 58.59%] [G loss: 0.856786]\n",
      "epoch:26 step:25297 [D loss: 0.650042, acc.: 60.16%] [G loss: 0.870576]\n",
      "epoch:26 step:25298 [D loss: 0.685909, acc.: 57.81%] [G loss: 0.885396]\n",
      "epoch:26 step:25299 [D loss: 0.635898, acc.: 67.19%] [G loss: 0.974060]\n",
      "epoch:27 step:25300 [D loss: 0.679628, acc.: 56.25%] [G loss: 0.919711]\n",
      "epoch:27 step:25301 [D loss: 0.699417, acc.: 54.69%] [G loss: 0.893913]\n",
      "epoch:27 step:25302 [D loss: 0.626497, acc.: 67.97%] [G loss: 0.847189]\n",
      "epoch:27 step:25303 [D loss: 0.658236, acc.: 58.59%] [G loss: 0.958416]\n",
      "epoch:27 step:25304 [D loss: 0.656034, acc.: 60.16%] [G loss: 0.895214]\n",
      "epoch:27 step:25305 [D loss: 0.655706, acc.: 57.03%] [G loss: 0.902647]\n",
      "epoch:27 step:25306 [D loss: 0.647329, acc.: 62.50%] [G loss: 0.875682]\n",
      "epoch:27 step:25307 [D loss: 0.650203, acc.: 65.62%] [G loss: 0.905524]\n",
      "epoch:27 step:25308 [D loss: 0.653566, acc.: 61.72%] [G loss: 0.847093]\n",
      "epoch:27 step:25309 [D loss: 0.640435, acc.: 63.28%] [G loss: 0.922184]\n",
      "epoch:27 step:25310 [D loss: 0.634133, acc.: 63.28%] [G loss: 0.929786]\n",
      "epoch:27 step:25311 [D loss: 0.650912, acc.: 66.41%] [G loss: 0.889602]\n",
      "epoch:27 step:25312 [D loss: 0.640304, acc.: 67.19%] [G loss: 0.960917]\n",
      "epoch:27 step:25313 [D loss: 0.670311, acc.: 58.59%] [G loss: 0.887666]\n",
      "epoch:27 step:25314 [D loss: 0.664499, acc.: 60.94%] [G loss: 0.906646]\n",
      "epoch:27 step:25315 [D loss: 0.621707, acc.: 66.41%] [G loss: 0.890331]\n",
      "epoch:27 step:25316 [D loss: 0.669183, acc.: 60.16%] [G loss: 0.880098]\n",
      "epoch:27 step:25317 [D loss: 0.670962, acc.: 54.69%] [G loss: 0.912170]\n",
      "epoch:27 step:25318 [D loss: 0.674528, acc.: 61.72%] [G loss: 0.956404]\n",
      "epoch:27 step:25319 [D loss: 0.646877, acc.: 62.50%] [G loss: 0.925354]\n",
      "epoch:27 step:25320 [D loss: 0.650471, acc.: 63.28%] [G loss: 0.914176]\n",
      "epoch:27 step:25321 [D loss: 0.656960, acc.: 60.94%] [G loss: 0.924815]\n",
      "epoch:27 step:25322 [D loss: 0.667612, acc.: 59.38%] [G loss: 0.907858]\n",
      "epoch:27 step:25323 [D loss: 0.638824, acc.: 61.72%] [G loss: 0.820882]\n",
      "epoch:27 step:25324 [D loss: 0.662809, acc.: 60.94%] [G loss: 0.896156]\n",
      "epoch:27 step:25325 [D loss: 0.704352, acc.: 56.25%] [G loss: 0.894360]\n",
      "epoch:27 step:25326 [D loss: 0.637880, acc.: 65.62%] [G loss: 0.970496]\n",
      "epoch:27 step:25327 [D loss: 0.605154, acc.: 73.44%] [G loss: 0.922922]\n",
      "epoch:27 step:25328 [D loss: 0.647556, acc.: 59.38%] [G loss: 0.925397]\n",
      "epoch:27 step:25329 [D loss: 0.667111, acc.: 63.28%] [G loss: 0.918691]\n",
      "epoch:27 step:25330 [D loss: 0.667086, acc.: 63.28%] [G loss: 0.905277]\n",
      "epoch:27 step:25331 [D loss: 0.628712, acc.: 68.75%] [G loss: 0.928644]\n",
      "epoch:27 step:25332 [D loss: 0.644509, acc.: 55.47%] [G loss: 0.896533]\n",
      "epoch:27 step:25333 [D loss: 0.632878, acc.: 64.06%] [G loss: 0.903335]\n",
      "epoch:27 step:25334 [D loss: 0.640126, acc.: 60.94%] [G loss: 0.912468]\n",
      "epoch:27 step:25335 [D loss: 0.648021, acc.: 62.50%] [G loss: 0.913990]\n",
      "epoch:27 step:25336 [D loss: 0.669240, acc.: 56.25%] [G loss: 0.870872]\n",
      "epoch:27 step:25337 [D loss: 0.658140, acc.: 57.03%] [G loss: 0.887695]\n",
      "epoch:27 step:25338 [D loss: 0.650901, acc.: 60.16%] [G loss: 0.905546]\n",
      "epoch:27 step:25339 [D loss: 0.689457, acc.: 56.25%] [G loss: 0.933008]\n",
      "epoch:27 step:25340 [D loss: 0.653533, acc.: 63.28%] [G loss: 0.914040]\n",
      "epoch:27 step:25341 [D loss: 0.688035, acc.: 54.69%] [G loss: 0.880469]\n",
      "epoch:27 step:25342 [D loss: 0.644799, acc.: 59.38%] [G loss: 0.855411]\n",
      "epoch:27 step:25343 [D loss: 0.643123, acc.: 60.94%] [G loss: 0.893989]\n",
      "epoch:27 step:25344 [D loss: 0.649931, acc.: 65.62%] [G loss: 0.884767]\n",
      "epoch:27 step:25345 [D loss: 0.653760, acc.: 60.94%] [G loss: 0.944566]\n",
      "epoch:27 step:25346 [D loss: 0.690265, acc.: 53.91%] [G loss: 0.904569]\n",
      "epoch:27 step:25347 [D loss: 0.625962, acc.: 66.41%] [G loss: 0.907400]\n",
      "epoch:27 step:25348 [D loss: 0.633578, acc.: 65.62%] [G loss: 0.889923]\n",
      "epoch:27 step:25349 [D loss: 0.659909, acc.: 56.25%] [G loss: 0.908505]\n",
      "epoch:27 step:25350 [D loss: 0.640375, acc.: 64.84%] [G loss: 0.898402]\n",
      "epoch:27 step:25351 [D loss: 0.639325, acc.: 62.50%] [G loss: 0.893605]\n",
      "epoch:27 step:25352 [D loss: 0.651761, acc.: 64.06%] [G loss: 0.907542]\n",
      "epoch:27 step:25353 [D loss: 0.608536, acc.: 66.41%] [G loss: 0.873698]\n",
      "epoch:27 step:25354 [D loss: 0.669123, acc.: 60.94%] [G loss: 0.915330]\n",
      "epoch:27 step:25355 [D loss: 0.671479, acc.: 55.47%] [G loss: 0.904710]\n",
      "epoch:27 step:25356 [D loss: 0.656019, acc.: 60.16%] [G loss: 0.875169]\n",
      "epoch:27 step:25357 [D loss: 0.646597, acc.: 62.50%] [G loss: 0.917878]\n",
      "epoch:27 step:25358 [D loss: 0.640525, acc.: 63.28%] [G loss: 0.940386]\n",
      "epoch:27 step:25359 [D loss: 0.666298, acc.: 58.59%] [G loss: 0.964164]\n",
      "epoch:27 step:25360 [D loss: 0.657814, acc.: 53.12%] [G loss: 0.931820]\n",
      "epoch:27 step:25361 [D loss: 0.623672, acc.: 65.62%] [G loss: 0.960764]\n",
      "epoch:27 step:25362 [D loss: 0.637536, acc.: 60.16%] [G loss: 1.003118]\n",
      "epoch:27 step:25363 [D loss: 0.647746, acc.: 60.16%] [G loss: 0.843889]\n",
      "epoch:27 step:25364 [D loss: 0.668715, acc.: 59.38%] [G loss: 0.891920]\n",
      "epoch:27 step:25365 [D loss: 0.651003, acc.: 61.72%] [G loss: 0.904233]\n",
      "epoch:27 step:25366 [D loss: 0.670767, acc.: 54.69%] [G loss: 0.873278]\n",
      "epoch:27 step:25367 [D loss: 0.666977, acc.: 57.81%] [G loss: 0.872787]\n",
      "epoch:27 step:25368 [D loss: 0.635785, acc.: 63.28%] [G loss: 0.870883]\n",
      "epoch:27 step:25369 [D loss: 0.650501, acc.: 60.94%] [G loss: 0.964673]\n",
      "epoch:27 step:25370 [D loss: 0.668828, acc.: 55.47%] [G loss: 0.934233]\n",
      "epoch:27 step:25371 [D loss: 0.679395, acc.: 60.16%] [G loss: 0.937535]\n",
      "epoch:27 step:25372 [D loss: 0.644806, acc.: 61.72%] [G loss: 0.847320]\n",
      "epoch:27 step:25373 [D loss: 0.686517, acc.: 52.34%] [G loss: 0.888893]\n",
      "epoch:27 step:25374 [D loss: 0.649639, acc.: 58.59%] [G loss: 0.863716]\n",
      "epoch:27 step:25375 [D loss: 0.644316, acc.: 64.06%] [G loss: 0.919609]\n",
      "epoch:27 step:25376 [D loss: 0.657048, acc.: 61.72%] [G loss: 0.887818]\n",
      "epoch:27 step:25377 [D loss: 0.654170, acc.: 60.94%] [G loss: 0.935973]\n",
      "epoch:27 step:25378 [D loss: 0.650692, acc.: 61.72%] [G loss: 0.934266]\n",
      "epoch:27 step:25379 [D loss: 0.667498, acc.: 63.28%] [G loss: 0.890860]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25380 [D loss: 0.644419, acc.: 59.38%] [G loss: 0.887794]\n",
      "epoch:27 step:25381 [D loss: 0.652863, acc.: 62.50%] [G loss: 0.902679]\n",
      "epoch:27 step:25382 [D loss: 0.639049, acc.: 60.16%] [G loss: 0.865601]\n",
      "epoch:27 step:25383 [D loss: 0.653591, acc.: 63.28%] [G loss: 0.866741]\n",
      "epoch:27 step:25384 [D loss: 0.668509, acc.: 55.47%] [G loss: 0.993544]\n",
      "epoch:27 step:25385 [D loss: 0.641960, acc.: 63.28%] [G loss: 0.935101]\n",
      "epoch:27 step:25386 [D loss: 0.643148, acc.: 61.72%] [G loss: 0.907715]\n",
      "epoch:27 step:25387 [D loss: 0.664336, acc.: 59.38%] [G loss: 0.853481]\n",
      "epoch:27 step:25388 [D loss: 0.652895, acc.: 58.59%] [G loss: 0.895617]\n",
      "epoch:27 step:25389 [D loss: 0.642399, acc.: 61.72%] [G loss: 0.872359]\n",
      "epoch:27 step:25390 [D loss: 0.669692, acc.: 57.81%] [G loss: 0.887628]\n",
      "epoch:27 step:25391 [D loss: 0.622737, acc.: 69.53%] [G loss: 0.927736]\n",
      "epoch:27 step:25392 [D loss: 0.628633, acc.: 60.16%] [G loss: 0.885576]\n",
      "epoch:27 step:25393 [D loss: 0.640310, acc.: 64.84%] [G loss: 0.884651]\n",
      "epoch:27 step:25394 [D loss: 0.657677, acc.: 56.25%] [G loss: 0.912436]\n",
      "epoch:27 step:25395 [D loss: 0.677415, acc.: 61.72%] [G loss: 0.890785]\n",
      "epoch:27 step:25396 [D loss: 0.652708, acc.: 61.72%] [G loss: 0.914837]\n",
      "epoch:27 step:25397 [D loss: 0.681284, acc.: 55.47%] [G loss: 0.856937]\n",
      "epoch:27 step:25398 [D loss: 0.665905, acc.: 65.62%] [G loss: 0.901086]\n",
      "epoch:27 step:25399 [D loss: 0.644610, acc.: 60.94%] [G loss: 0.912259]\n",
      "epoch:27 step:25400 [D loss: 0.660280, acc.: 58.59%] [G loss: 0.817240]\n",
      "##############\n",
      "[3.0583285  2.57730184 2.30860051 4.1953326  1.43106472 7.04814433\n",
      " 2.6303742  3.54765006 4.33547381 8.14868929]\n",
      "##########\n",
      "epoch:27 step:25401 [D loss: 0.713666, acc.: 53.91%] [G loss: 0.852051]\n",
      "epoch:27 step:25402 [D loss: 0.638114, acc.: 60.16%] [G loss: 0.916421]\n",
      "epoch:27 step:25403 [D loss: 0.643190, acc.: 60.94%] [G loss: 0.858963]\n",
      "epoch:27 step:25404 [D loss: 0.647529, acc.: 60.16%] [G loss: 0.954500]\n",
      "epoch:27 step:25405 [D loss: 0.640079, acc.: 64.06%] [G loss: 0.856476]\n",
      "epoch:27 step:25406 [D loss: 0.635056, acc.: 64.84%] [G loss: 0.900969]\n",
      "epoch:27 step:25407 [D loss: 0.635659, acc.: 64.84%] [G loss: 0.893934]\n",
      "epoch:27 step:25408 [D loss: 0.661786, acc.: 63.28%] [G loss: 0.882177]\n",
      "epoch:27 step:25409 [D loss: 0.666800, acc.: 52.34%] [G loss: 0.909930]\n",
      "epoch:27 step:25410 [D loss: 0.705359, acc.: 56.25%] [G loss: 0.910906]\n",
      "epoch:27 step:25411 [D loss: 0.659725, acc.: 56.25%] [G loss: 0.926824]\n",
      "epoch:27 step:25412 [D loss: 0.669155, acc.: 61.72%] [G loss: 0.872552]\n",
      "epoch:27 step:25413 [D loss: 0.634405, acc.: 60.94%] [G loss: 0.941532]\n",
      "epoch:27 step:25414 [D loss: 0.656604, acc.: 60.94%] [G loss: 0.879280]\n",
      "epoch:27 step:25415 [D loss: 0.629256, acc.: 64.06%] [G loss: 0.865222]\n",
      "epoch:27 step:25416 [D loss: 0.656292, acc.: 62.50%] [G loss: 0.928655]\n",
      "epoch:27 step:25417 [D loss: 0.638037, acc.: 67.19%] [G loss: 0.919529]\n",
      "epoch:27 step:25418 [D loss: 0.656011, acc.: 59.38%] [G loss: 0.885390]\n",
      "epoch:27 step:25419 [D loss: 0.665194, acc.: 58.59%] [G loss: 0.900135]\n",
      "epoch:27 step:25420 [D loss: 0.623424, acc.: 72.66%] [G loss: 0.842580]\n",
      "epoch:27 step:25421 [D loss: 0.650177, acc.: 59.38%] [G loss: 0.865633]\n",
      "epoch:27 step:25422 [D loss: 0.674687, acc.: 57.03%] [G loss: 0.852698]\n",
      "epoch:27 step:25423 [D loss: 0.637834, acc.: 63.28%] [G loss: 0.892152]\n",
      "epoch:27 step:25424 [D loss: 0.665938, acc.: 59.38%] [G loss: 0.925877]\n",
      "epoch:27 step:25425 [D loss: 0.673679, acc.: 57.81%] [G loss: 0.907390]\n",
      "epoch:27 step:25426 [D loss: 0.623022, acc.: 70.31%] [G loss: 0.957539]\n",
      "epoch:27 step:25427 [D loss: 0.645840, acc.: 58.59%] [G loss: 0.899359]\n",
      "epoch:27 step:25428 [D loss: 0.643752, acc.: 64.84%] [G loss: 0.898237]\n",
      "epoch:27 step:25429 [D loss: 0.622833, acc.: 73.44%] [G loss: 0.944229]\n",
      "epoch:27 step:25430 [D loss: 0.614028, acc.: 67.97%] [G loss: 0.856645]\n",
      "epoch:27 step:25431 [D loss: 0.641906, acc.: 60.94%] [G loss: 0.890246]\n",
      "epoch:27 step:25432 [D loss: 0.672791, acc.: 58.59%] [G loss: 0.844563]\n",
      "epoch:27 step:25433 [D loss: 0.675697, acc.: 58.59%] [G loss: 0.892752]\n",
      "epoch:27 step:25434 [D loss: 0.664086, acc.: 60.16%] [G loss: 0.855196]\n",
      "epoch:27 step:25435 [D loss: 0.644886, acc.: 59.38%] [G loss: 0.872003]\n",
      "epoch:27 step:25436 [D loss: 0.635743, acc.: 61.72%] [G loss: 0.835097]\n",
      "epoch:27 step:25437 [D loss: 0.668915, acc.: 64.84%] [G loss: 0.915399]\n",
      "epoch:27 step:25438 [D loss: 0.651858, acc.: 63.28%] [G loss: 0.910092]\n",
      "epoch:27 step:25439 [D loss: 0.682915, acc.: 52.34%] [G loss: 0.871750]\n",
      "epoch:27 step:25440 [D loss: 0.693030, acc.: 52.34%] [G loss: 0.975651]\n",
      "epoch:27 step:25441 [D loss: 0.623372, acc.: 63.28%] [G loss: 0.965912]\n",
      "epoch:27 step:25442 [D loss: 0.639590, acc.: 60.16%] [G loss: 0.885603]\n",
      "epoch:27 step:25443 [D loss: 0.654392, acc.: 66.41%] [G loss: 0.871302]\n",
      "epoch:27 step:25444 [D loss: 0.674271, acc.: 53.12%] [G loss: 0.849082]\n",
      "epoch:27 step:25445 [D loss: 0.671140, acc.: 58.59%] [G loss: 0.844041]\n",
      "epoch:27 step:25446 [D loss: 0.626409, acc.: 62.50%] [G loss: 0.939645]\n",
      "epoch:27 step:25447 [D loss: 0.620274, acc.: 61.72%] [G loss: 0.854467]\n",
      "epoch:27 step:25448 [D loss: 0.645866, acc.: 57.81%] [G loss: 0.853469]\n",
      "epoch:27 step:25449 [D loss: 0.672061, acc.: 53.12%] [G loss: 0.862878]\n",
      "epoch:27 step:25450 [D loss: 0.678803, acc.: 51.56%] [G loss: 0.941213]\n",
      "epoch:27 step:25451 [D loss: 0.621928, acc.: 68.75%] [G loss: 0.843538]\n",
      "epoch:27 step:25452 [D loss: 0.621662, acc.: 66.41%] [G loss: 0.890981]\n",
      "epoch:27 step:25453 [D loss: 0.625983, acc.: 63.28%] [G loss: 0.873245]\n",
      "epoch:27 step:25454 [D loss: 0.704766, acc.: 52.34%] [G loss: 0.872286]\n",
      "epoch:27 step:25455 [D loss: 0.602142, acc.: 69.53%] [G loss: 0.891103]\n",
      "epoch:27 step:25456 [D loss: 0.681670, acc.: 47.66%] [G loss: 0.938155]\n",
      "epoch:27 step:25457 [D loss: 0.633739, acc.: 63.28%] [G loss: 0.921380]\n",
      "epoch:27 step:25458 [D loss: 0.608979, acc.: 68.75%] [G loss: 0.936124]\n",
      "epoch:27 step:25459 [D loss: 0.653610, acc.: 64.84%] [G loss: 0.924497]\n",
      "epoch:27 step:25460 [D loss: 0.637871, acc.: 64.06%] [G loss: 0.930497]\n",
      "epoch:27 step:25461 [D loss: 0.654985, acc.: 61.72%] [G loss: 0.875522]\n",
      "epoch:27 step:25462 [D loss: 0.679354, acc.: 53.12%] [G loss: 0.899587]\n",
      "epoch:27 step:25463 [D loss: 0.646978, acc.: 62.50%] [G loss: 0.902508]\n",
      "epoch:27 step:25464 [D loss: 0.633460, acc.: 65.62%] [G loss: 0.878662]\n",
      "epoch:27 step:25465 [D loss: 0.644662, acc.: 64.84%] [G loss: 0.931361]\n",
      "epoch:27 step:25466 [D loss: 0.648943, acc.: 60.94%] [G loss: 0.889414]\n",
      "epoch:27 step:25467 [D loss: 0.639060, acc.: 66.41%] [G loss: 0.933831]\n",
      "epoch:27 step:25468 [D loss: 0.653736, acc.: 64.06%] [G loss: 0.938797]\n",
      "epoch:27 step:25469 [D loss: 0.661218, acc.: 53.91%] [G loss: 0.922888]\n",
      "epoch:27 step:25470 [D loss: 0.680735, acc.: 54.69%] [G loss: 0.964821]\n",
      "epoch:27 step:25471 [D loss: 0.689356, acc.: 60.16%] [G loss: 0.936696]\n",
      "epoch:27 step:25472 [D loss: 0.647244, acc.: 64.84%] [G loss: 0.919256]\n",
      "epoch:27 step:25473 [D loss: 0.626603, acc.: 64.06%] [G loss: 0.865235]\n",
      "epoch:27 step:25474 [D loss: 0.694140, acc.: 53.12%] [G loss: 0.844107]\n",
      "epoch:27 step:25475 [D loss: 0.620078, acc.: 67.97%] [G loss: 0.889957]\n",
      "epoch:27 step:25476 [D loss: 0.631247, acc.: 61.72%] [G loss: 0.886286]\n",
      "epoch:27 step:25477 [D loss: 0.667411, acc.: 58.59%] [G loss: 0.883585]\n",
      "epoch:27 step:25478 [D loss: 0.662201, acc.: 52.34%] [G loss: 0.917496]\n",
      "epoch:27 step:25479 [D loss: 0.626130, acc.: 66.41%] [G loss: 0.975537]\n",
      "epoch:27 step:25480 [D loss: 0.660808, acc.: 64.84%] [G loss: 0.934237]\n",
      "epoch:27 step:25481 [D loss: 0.651781, acc.: 58.59%] [G loss: 0.921284]\n",
      "epoch:27 step:25482 [D loss: 0.645306, acc.: 65.62%] [G loss: 0.928818]\n",
      "epoch:27 step:25483 [D loss: 0.662172, acc.: 59.38%] [G loss: 0.889740]\n",
      "epoch:27 step:25484 [D loss: 0.672041, acc.: 57.81%] [G loss: 0.936900]\n",
      "epoch:27 step:25485 [D loss: 0.672935, acc.: 57.03%] [G loss: 0.970233]\n",
      "epoch:27 step:25486 [D loss: 0.643103, acc.: 65.62%] [G loss: 0.910759]\n",
      "epoch:27 step:25487 [D loss: 0.685094, acc.: 60.16%] [G loss: 0.945256]\n",
      "epoch:27 step:25488 [D loss: 0.633117, acc.: 67.97%] [G loss: 0.898021]\n",
      "epoch:27 step:25489 [D loss: 0.668028, acc.: 58.59%] [G loss: 0.883424]\n",
      "epoch:27 step:25490 [D loss: 0.648177, acc.: 63.28%] [G loss: 0.876325]\n",
      "epoch:27 step:25491 [D loss: 0.682311, acc.: 58.59%] [G loss: 0.916749]\n",
      "epoch:27 step:25492 [D loss: 0.628805, acc.: 64.84%] [G loss: 0.916587]\n",
      "epoch:27 step:25493 [D loss: 0.669064, acc.: 57.81%] [G loss: 0.857905]\n",
      "epoch:27 step:25494 [D loss: 0.663353, acc.: 59.38%] [G loss: 0.901464]\n",
      "epoch:27 step:25495 [D loss: 0.660797, acc.: 54.69%] [G loss: 0.928024]\n",
      "epoch:27 step:25496 [D loss: 0.634036, acc.: 64.06%] [G loss: 0.892582]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25497 [D loss: 0.643825, acc.: 60.16%] [G loss: 0.904187]\n",
      "epoch:27 step:25498 [D loss: 0.623550, acc.: 67.97%] [G loss: 0.950921]\n",
      "epoch:27 step:25499 [D loss: 0.644294, acc.: 60.94%] [G loss: 0.911725]\n",
      "epoch:27 step:25500 [D loss: 0.642280, acc.: 62.50%] [G loss: 0.960088]\n",
      "epoch:27 step:25501 [D loss: 0.611253, acc.: 70.31%] [G loss: 0.922192]\n",
      "epoch:27 step:25502 [D loss: 0.628649, acc.: 63.28%] [G loss: 0.944329]\n",
      "epoch:27 step:25503 [D loss: 0.617381, acc.: 67.19%] [G loss: 0.928124]\n",
      "epoch:27 step:25504 [D loss: 0.678181, acc.: 59.38%] [G loss: 0.896835]\n",
      "epoch:27 step:25505 [D loss: 0.652252, acc.: 59.38%] [G loss: 0.983531]\n",
      "epoch:27 step:25506 [D loss: 0.639465, acc.: 64.84%] [G loss: 0.932001]\n",
      "epoch:27 step:25507 [D loss: 0.630939, acc.: 67.97%] [G loss: 0.910324]\n",
      "epoch:27 step:25508 [D loss: 0.679542, acc.: 57.03%] [G loss: 0.945052]\n",
      "epoch:27 step:25509 [D loss: 0.628394, acc.: 64.84%] [G loss: 0.892281]\n",
      "epoch:27 step:25510 [D loss: 0.671561, acc.: 55.47%] [G loss: 0.848285]\n",
      "epoch:27 step:25511 [D loss: 0.631064, acc.: 65.62%] [G loss: 0.928711]\n",
      "epoch:27 step:25512 [D loss: 0.641952, acc.: 64.84%] [G loss: 0.867537]\n",
      "epoch:27 step:25513 [D loss: 0.693400, acc.: 54.69%] [G loss: 0.853772]\n",
      "epoch:27 step:25514 [D loss: 0.648578, acc.: 60.16%] [G loss: 0.911425]\n",
      "epoch:27 step:25515 [D loss: 0.667173, acc.: 54.69%] [G loss: 0.852408]\n",
      "epoch:27 step:25516 [D loss: 0.612018, acc.: 67.97%] [G loss: 0.948597]\n",
      "epoch:27 step:25517 [D loss: 0.654549, acc.: 57.03%] [G loss: 0.862939]\n",
      "epoch:27 step:25518 [D loss: 0.686135, acc.: 56.25%] [G loss: 0.854348]\n",
      "epoch:27 step:25519 [D loss: 0.692015, acc.: 56.25%] [G loss: 0.895438]\n",
      "epoch:27 step:25520 [D loss: 0.657887, acc.: 60.94%] [G loss: 0.855010]\n",
      "epoch:27 step:25521 [D loss: 0.647531, acc.: 63.28%] [G loss: 0.851238]\n",
      "epoch:27 step:25522 [D loss: 0.708008, acc.: 52.34%] [G loss: 0.868126]\n",
      "epoch:27 step:25523 [D loss: 0.634916, acc.: 60.94%] [G loss: 0.806869]\n",
      "epoch:27 step:25524 [D loss: 0.665877, acc.: 63.28%] [G loss: 0.909474]\n",
      "epoch:27 step:25525 [D loss: 0.684116, acc.: 57.03%] [G loss: 0.879542]\n",
      "epoch:27 step:25526 [D loss: 0.660765, acc.: 59.38%] [G loss: 0.940809]\n",
      "epoch:27 step:25527 [D loss: 0.625900, acc.: 67.97%] [G loss: 0.906043]\n",
      "epoch:27 step:25528 [D loss: 0.653209, acc.: 60.94%] [G loss: 0.989765]\n",
      "epoch:27 step:25529 [D loss: 0.654224, acc.: 65.62%] [G loss: 0.914351]\n",
      "epoch:27 step:25530 [D loss: 0.674799, acc.: 62.50%] [G loss: 0.896182]\n",
      "epoch:27 step:25531 [D loss: 0.656271, acc.: 58.59%] [G loss: 0.953719]\n",
      "epoch:27 step:25532 [D loss: 0.671200, acc.: 59.38%] [G loss: 0.883258]\n",
      "epoch:27 step:25533 [D loss: 0.640247, acc.: 59.38%] [G loss: 0.930402]\n",
      "epoch:27 step:25534 [D loss: 0.676917, acc.: 56.25%] [G loss: 0.879238]\n",
      "epoch:27 step:25535 [D loss: 0.644638, acc.: 61.72%] [G loss: 0.861760]\n",
      "epoch:27 step:25536 [D loss: 0.676057, acc.: 56.25%] [G loss: 0.885106]\n",
      "epoch:27 step:25537 [D loss: 0.690302, acc.: 53.12%] [G loss: 0.871272]\n",
      "epoch:27 step:25538 [D loss: 0.675546, acc.: 59.38%] [G loss: 0.856915]\n",
      "epoch:27 step:25539 [D loss: 0.649083, acc.: 61.72%] [G loss: 0.888039]\n",
      "epoch:27 step:25540 [D loss: 0.649193, acc.: 58.59%] [G loss: 0.892483]\n",
      "epoch:27 step:25541 [D loss: 0.648830, acc.: 62.50%] [G loss: 0.923972]\n",
      "epoch:27 step:25542 [D loss: 0.661808, acc.: 62.50%] [G loss: 0.914806]\n",
      "epoch:27 step:25543 [D loss: 0.645490, acc.: 66.41%] [G loss: 0.887722]\n",
      "epoch:27 step:25544 [D loss: 0.674897, acc.: 59.38%] [G loss: 0.855924]\n",
      "epoch:27 step:25545 [D loss: 0.640507, acc.: 66.41%] [G loss: 0.889768]\n",
      "epoch:27 step:25546 [D loss: 0.691219, acc.: 50.78%] [G loss: 0.908074]\n",
      "epoch:27 step:25547 [D loss: 0.632462, acc.: 64.84%] [G loss: 0.871548]\n",
      "epoch:27 step:25548 [D loss: 0.665106, acc.: 58.59%] [G loss: 0.878743]\n",
      "epoch:27 step:25549 [D loss: 0.691484, acc.: 58.59%] [G loss: 0.864619]\n",
      "epoch:27 step:25550 [D loss: 0.648357, acc.: 59.38%] [G loss: 0.871726]\n",
      "epoch:27 step:25551 [D loss: 0.674887, acc.: 58.59%] [G loss: 0.903318]\n",
      "epoch:27 step:25552 [D loss: 0.648687, acc.: 60.94%] [G loss: 0.920729]\n",
      "epoch:27 step:25553 [D loss: 0.659088, acc.: 58.59%] [G loss: 0.890056]\n",
      "epoch:27 step:25554 [D loss: 0.658290, acc.: 57.81%] [G loss: 0.926094]\n",
      "epoch:27 step:25555 [D loss: 0.657143, acc.: 62.50%] [G loss: 0.874500]\n",
      "epoch:27 step:25556 [D loss: 0.637328, acc.: 64.84%] [G loss: 0.860732]\n",
      "epoch:27 step:25557 [D loss: 0.651428, acc.: 56.25%] [G loss: 0.894322]\n",
      "epoch:27 step:25558 [D loss: 0.685858, acc.: 55.47%] [G loss: 0.882057]\n",
      "epoch:27 step:25559 [D loss: 0.658731, acc.: 61.72%] [G loss: 0.856693]\n",
      "epoch:27 step:25560 [D loss: 0.685532, acc.: 57.81%] [G loss: 0.896707]\n",
      "epoch:27 step:25561 [D loss: 0.661105, acc.: 60.16%] [G loss: 0.931165]\n",
      "epoch:27 step:25562 [D loss: 0.660174, acc.: 60.16%] [G loss: 0.892043]\n",
      "epoch:27 step:25563 [D loss: 0.637001, acc.: 58.59%] [G loss: 0.951421]\n",
      "epoch:27 step:25564 [D loss: 0.629294, acc.: 67.97%] [G loss: 0.899589]\n",
      "epoch:27 step:25565 [D loss: 0.619959, acc.: 69.53%] [G loss: 0.917355]\n",
      "epoch:27 step:25566 [D loss: 0.632583, acc.: 63.28%] [G loss: 0.823632]\n",
      "epoch:27 step:25567 [D loss: 0.672518, acc.: 55.47%] [G loss: 0.906890]\n",
      "epoch:27 step:25568 [D loss: 0.639924, acc.: 67.19%] [G loss: 0.892245]\n",
      "epoch:27 step:25569 [D loss: 0.677404, acc.: 56.25%] [G loss: 0.860288]\n",
      "epoch:27 step:25570 [D loss: 0.650379, acc.: 66.41%] [G loss: 0.864482]\n",
      "epoch:27 step:25571 [D loss: 0.656310, acc.: 59.38%] [G loss: 0.913766]\n",
      "epoch:27 step:25572 [D loss: 0.668401, acc.: 58.59%] [G loss: 0.929420]\n",
      "epoch:27 step:25573 [D loss: 0.670563, acc.: 54.69%] [G loss: 0.887178]\n",
      "epoch:27 step:25574 [D loss: 0.670070, acc.: 54.69%] [G loss: 0.886584]\n",
      "epoch:27 step:25575 [D loss: 0.704655, acc.: 48.44%] [G loss: 0.878966]\n",
      "epoch:27 step:25576 [D loss: 0.661688, acc.: 61.72%] [G loss: 0.882089]\n",
      "epoch:27 step:25577 [D loss: 0.689612, acc.: 53.91%] [G loss: 0.859120]\n",
      "epoch:27 step:25578 [D loss: 0.688594, acc.: 54.69%] [G loss: 0.916454]\n",
      "epoch:27 step:25579 [D loss: 0.684527, acc.: 59.38%] [G loss: 0.892067]\n",
      "epoch:27 step:25580 [D loss: 0.637003, acc.: 67.19%] [G loss: 0.931318]\n",
      "epoch:27 step:25581 [D loss: 0.648941, acc.: 60.16%] [G loss: 0.932365]\n",
      "epoch:27 step:25582 [D loss: 0.617630, acc.: 67.97%] [G loss: 0.876073]\n",
      "epoch:27 step:25583 [D loss: 0.638709, acc.: 63.28%] [G loss: 0.935975]\n",
      "epoch:27 step:25584 [D loss: 0.640858, acc.: 58.59%] [G loss: 0.910414]\n",
      "epoch:27 step:25585 [D loss: 0.670793, acc.: 60.94%] [G loss: 0.919800]\n",
      "epoch:27 step:25586 [D loss: 0.652569, acc.: 57.81%] [G loss: 0.886121]\n",
      "epoch:27 step:25587 [D loss: 0.646258, acc.: 64.84%] [G loss: 0.863555]\n",
      "epoch:27 step:25588 [D loss: 0.677917, acc.: 59.38%] [G loss: 0.850523]\n",
      "epoch:27 step:25589 [D loss: 0.621496, acc.: 66.41%] [G loss: 0.842063]\n",
      "epoch:27 step:25590 [D loss: 0.697880, acc.: 56.25%] [G loss: 0.863966]\n",
      "epoch:27 step:25591 [D loss: 0.631374, acc.: 70.31%] [G loss: 0.868671]\n",
      "epoch:27 step:25592 [D loss: 0.656863, acc.: 61.72%] [G loss: 0.866595]\n",
      "epoch:27 step:25593 [D loss: 0.665640, acc.: 60.94%] [G loss: 0.913709]\n",
      "epoch:27 step:25594 [D loss: 0.650251, acc.: 58.59%] [G loss: 0.952279]\n",
      "epoch:27 step:25595 [D loss: 0.647573, acc.: 65.62%] [G loss: 0.882560]\n",
      "epoch:27 step:25596 [D loss: 0.653185, acc.: 55.47%] [G loss: 0.948495]\n",
      "epoch:27 step:25597 [D loss: 0.652072, acc.: 61.72%] [G loss: 0.864405]\n",
      "epoch:27 step:25598 [D loss: 0.669987, acc.: 56.25%] [G loss: 0.931822]\n",
      "epoch:27 step:25599 [D loss: 0.654069, acc.: 57.81%] [G loss: 0.932320]\n",
      "epoch:27 step:25600 [D loss: 0.685225, acc.: 57.03%] [G loss: 0.921866]\n",
      "##############\n",
      "[2.96614904 2.3939604  2.23742886 4.08916221 1.20332295 7.55730533\n",
      " 2.53734151 3.96730856 4.14519117 6.31071998]\n",
      "##########\n",
      "epoch:27 step:25601 [D loss: 0.639714, acc.: 64.84%] [G loss: 0.880186]\n",
      "epoch:27 step:25602 [D loss: 0.668310, acc.: 59.38%] [G loss: 0.882459]\n",
      "epoch:27 step:25603 [D loss: 0.634721, acc.: 67.19%] [G loss: 0.853402]\n",
      "epoch:27 step:25604 [D loss: 0.677789, acc.: 55.47%] [G loss: 0.875001]\n",
      "epoch:27 step:25605 [D loss: 0.622934, acc.: 65.62%] [G loss: 0.923585]\n",
      "epoch:27 step:25606 [D loss: 0.658422, acc.: 55.47%] [G loss: 0.873319]\n",
      "epoch:27 step:25607 [D loss: 0.635835, acc.: 60.94%] [G loss: 0.865714]\n",
      "epoch:27 step:25608 [D loss: 0.617342, acc.: 66.41%] [G loss: 0.871812]\n",
      "epoch:27 step:25609 [D loss: 0.632734, acc.: 67.19%] [G loss: 0.920420]\n",
      "epoch:27 step:25610 [D loss: 0.614793, acc.: 64.84%] [G loss: 0.880084]\n",
      "epoch:27 step:25611 [D loss: 0.694950, acc.: 52.34%] [G loss: 0.881380]\n",
      "epoch:27 step:25612 [D loss: 0.649925, acc.: 57.81%] [G loss: 0.848384]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25613 [D loss: 0.619059, acc.: 71.09%] [G loss: 0.921925]\n",
      "epoch:27 step:25614 [D loss: 0.629568, acc.: 65.62%] [G loss: 0.921454]\n",
      "epoch:27 step:25615 [D loss: 0.663952, acc.: 58.59%] [G loss: 0.932075]\n",
      "epoch:27 step:25616 [D loss: 0.654936, acc.: 60.94%] [G loss: 0.930978]\n",
      "epoch:27 step:25617 [D loss: 0.693421, acc.: 51.56%] [G loss: 0.928789]\n",
      "epoch:27 step:25618 [D loss: 0.643202, acc.: 60.16%] [G loss: 0.939332]\n",
      "epoch:27 step:25619 [D loss: 0.656298, acc.: 60.94%] [G loss: 0.894066]\n",
      "epoch:27 step:25620 [D loss: 0.678163, acc.: 60.94%] [G loss: 0.883086]\n",
      "epoch:27 step:25621 [D loss: 0.672140, acc.: 56.25%] [G loss: 0.862396]\n",
      "epoch:27 step:25622 [D loss: 0.625018, acc.: 65.62%] [G loss: 0.892286]\n",
      "epoch:27 step:25623 [D loss: 0.643110, acc.: 60.94%] [G loss: 0.913413]\n",
      "epoch:27 step:25624 [D loss: 0.692154, acc.: 56.25%] [G loss: 0.900427]\n",
      "epoch:27 step:25625 [D loss: 0.678893, acc.: 56.25%] [G loss: 0.945743]\n",
      "epoch:27 step:25626 [D loss: 0.633568, acc.: 60.94%] [G loss: 0.899985]\n",
      "epoch:27 step:25627 [D loss: 0.650251, acc.: 57.03%] [G loss: 0.881158]\n",
      "epoch:27 step:25628 [D loss: 0.682448, acc.: 58.59%] [G loss: 0.899127]\n",
      "epoch:27 step:25629 [D loss: 0.620743, acc.: 67.19%] [G loss: 0.938697]\n",
      "epoch:27 step:25630 [D loss: 0.657605, acc.: 56.25%] [G loss: 0.883049]\n",
      "epoch:27 step:25631 [D loss: 0.652515, acc.: 57.81%] [G loss: 0.929673]\n",
      "epoch:27 step:25632 [D loss: 0.677945, acc.: 57.81%] [G loss: 0.933854]\n",
      "epoch:27 step:25633 [D loss: 0.650039, acc.: 64.84%] [G loss: 0.920414]\n",
      "epoch:27 step:25634 [D loss: 0.671949, acc.: 57.81%] [G loss: 0.870089]\n",
      "epoch:27 step:25635 [D loss: 0.620031, acc.: 66.41%] [G loss: 0.910697]\n",
      "epoch:27 step:25636 [D loss: 0.649236, acc.: 59.38%] [G loss: 0.919690]\n",
      "epoch:27 step:25637 [D loss: 0.658750, acc.: 59.38%] [G loss: 0.931416]\n",
      "epoch:27 step:25638 [D loss: 0.640925, acc.: 66.41%] [G loss: 0.972496]\n",
      "epoch:27 step:25639 [D loss: 0.671160, acc.: 58.59%] [G loss: 0.888939]\n",
      "epoch:27 step:25640 [D loss: 0.673556, acc.: 60.16%] [G loss: 0.844642]\n",
      "epoch:27 step:25641 [D loss: 0.672843, acc.: 60.16%] [G loss: 0.876821]\n",
      "epoch:27 step:25642 [D loss: 0.661923, acc.: 61.72%] [G loss: 0.872771]\n",
      "epoch:27 step:25643 [D loss: 0.640885, acc.: 63.28%] [G loss: 0.865903]\n",
      "epoch:27 step:25644 [D loss: 0.654126, acc.: 63.28%] [G loss: 0.871658]\n",
      "epoch:27 step:25645 [D loss: 0.661327, acc.: 58.59%] [G loss: 0.904157]\n",
      "epoch:27 step:25646 [D loss: 0.630551, acc.: 68.75%] [G loss: 0.901286]\n",
      "epoch:27 step:25647 [D loss: 0.670440, acc.: 57.81%] [G loss: 0.923179]\n",
      "epoch:27 step:25648 [D loss: 0.611786, acc.: 67.97%] [G loss: 0.921139]\n",
      "epoch:27 step:25649 [D loss: 0.594651, acc.: 69.53%] [G loss: 0.918032]\n",
      "epoch:27 step:25650 [D loss: 0.659254, acc.: 63.28%] [G loss: 0.881937]\n",
      "epoch:27 step:25651 [D loss: 0.659294, acc.: 64.06%] [G loss: 0.846908]\n",
      "epoch:27 step:25652 [D loss: 0.693097, acc.: 58.59%] [G loss: 0.849104]\n",
      "epoch:27 step:25653 [D loss: 0.640262, acc.: 60.16%] [G loss: 0.883375]\n",
      "epoch:27 step:25654 [D loss: 0.669607, acc.: 59.38%] [G loss: 0.879786]\n",
      "epoch:27 step:25655 [D loss: 0.639610, acc.: 59.38%] [G loss: 0.948750]\n",
      "epoch:27 step:25656 [D loss: 0.700440, acc.: 56.25%] [G loss: 0.926196]\n",
      "epoch:27 step:25657 [D loss: 0.621388, acc.: 67.19%] [G loss: 0.891138]\n",
      "epoch:27 step:25658 [D loss: 0.651243, acc.: 58.59%] [G loss: 0.912846]\n",
      "epoch:27 step:25659 [D loss: 0.667966, acc.: 60.16%] [G loss: 0.900498]\n",
      "epoch:27 step:25660 [D loss: 0.607625, acc.: 69.53%] [G loss: 0.923179]\n",
      "epoch:27 step:25661 [D loss: 0.631762, acc.: 66.41%] [G loss: 0.911988]\n",
      "epoch:27 step:25662 [D loss: 0.666165, acc.: 61.72%] [G loss: 0.875953]\n",
      "epoch:27 step:25663 [D loss: 0.692200, acc.: 58.59%] [G loss: 0.891403]\n",
      "epoch:27 step:25664 [D loss: 0.632462, acc.: 64.06%] [G loss: 0.846799]\n",
      "epoch:27 step:25665 [D loss: 0.672714, acc.: 57.81%] [G loss: 0.901497]\n",
      "epoch:27 step:25666 [D loss: 0.670142, acc.: 58.59%] [G loss: 0.937875]\n",
      "epoch:27 step:25667 [D loss: 0.655687, acc.: 60.94%] [G loss: 0.867678]\n",
      "epoch:27 step:25668 [D loss: 0.682650, acc.: 51.56%] [G loss: 0.901772]\n",
      "epoch:27 step:25669 [D loss: 0.642479, acc.: 63.28%] [G loss: 0.929274]\n",
      "epoch:27 step:25670 [D loss: 0.635517, acc.: 66.41%] [G loss: 0.917701]\n",
      "epoch:27 step:25671 [D loss: 0.615512, acc.: 65.62%] [G loss: 0.854636]\n",
      "epoch:27 step:25672 [D loss: 0.653659, acc.: 60.16%] [G loss: 0.924040]\n",
      "epoch:27 step:25673 [D loss: 0.636212, acc.: 63.28%] [G loss: 0.884452]\n",
      "epoch:27 step:25674 [D loss: 0.653185, acc.: 66.41%] [G loss: 0.946525]\n",
      "epoch:27 step:25675 [D loss: 0.674899, acc.: 55.47%] [G loss: 0.923442]\n",
      "epoch:27 step:25676 [D loss: 0.653506, acc.: 60.16%] [G loss: 0.944573]\n",
      "epoch:27 step:25677 [D loss: 0.657514, acc.: 60.16%] [G loss: 0.904151]\n",
      "epoch:27 step:25678 [D loss: 0.672283, acc.: 54.69%] [G loss: 0.898785]\n",
      "epoch:27 step:25679 [D loss: 0.660454, acc.: 64.06%] [G loss: 0.886531]\n",
      "epoch:27 step:25680 [D loss: 0.661804, acc.: 60.16%] [G loss: 0.932210]\n",
      "epoch:27 step:25681 [D loss: 0.624383, acc.: 62.50%] [G loss: 0.908199]\n",
      "epoch:27 step:25682 [D loss: 0.646531, acc.: 64.06%] [G loss: 0.896018]\n",
      "epoch:27 step:25683 [D loss: 0.668985, acc.: 58.59%] [G loss: 0.828384]\n",
      "epoch:27 step:25684 [D loss: 0.701601, acc.: 54.69%] [G loss: 0.868972]\n",
      "epoch:27 step:25685 [D loss: 0.627210, acc.: 66.41%] [G loss: 0.974981]\n",
      "epoch:27 step:25686 [D loss: 0.627565, acc.: 60.16%] [G loss: 0.875489]\n",
      "epoch:27 step:25687 [D loss: 0.658885, acc.: 61.72%] [G loss: 0.887788]\n",
      "epoch:27 step:25688 [D loss: 0.614164, acc.: 67.19%] [G loss: 0.911368]\n",
      "epoch:27 step:25689 [D loss: 0.685006, acc.: 55.47%] [G loss: 0.859117]\n",
      "epoch:27 step:25690 [D loss: 0.659928, acc.: 58.59%] [G loss: 0.907347]\n",
      "epoch:27 step:25691 [D loss: 0.637723, acc.: 64.06%] [G loss: 0.962858]\n",
      "epoch:27 step:25692 [D loss: 0.715928, acc.: 53.91%] [G loss: 0.906964]\n",
      "epoch:27 step:25693 [D loss: 0.648645, acc.: 63.28%] [G loss: 0.943733]\n",
      "epoch:27 step:25694 [D loss: 0.676444, acc.: 55.47%] [G loss: 0.889378]\n",
      "epoch:27 step:25695 [D loss: 0.663831, acc.: 57.03%] [G loss: 0.897997]\n",
      "epoch:27 step:25696 [D loss: 0.649677, acc.: 60.94%] [G loss: 0.906735]\n",
      "epoch:27 step:25697 [D loss: 0.680895, acc.: 56.25%] [G loss: 0.946532]\n",
      "epoch:27 step:25698 [D loss: 0.601647, acc.: 67.97%] [G loss: 0.906998]\n",
      "epoch:27 step:25699 [D loss: 0.645019, acc.: 64.84%] [G loss: 0.939318]\n",
      "epoch:27 step:25700 [D loss: 0.655256, acc.: 60.16%] [G loss: 0.874375]\n",
      "epoch:27 step:25701 [D loss: 0.640306, acc.: 62.50%] [G loss: 0.893370]\n",
      "epoch:27 step:25702 [D loss: 0.630783, acc.: 66.41%] [G loss: 0.930317]\n",
      "epoch:27 step:25703 [D loss: 0.623659, acc.: 67.19%] [G loss: 0.898711]\n",
      "epoch:27 step:25704 [D loss: 0.631448, acc.: 67.19%] [G loss: 0.914516]\n",
      "epoch:27 step:25705 [D loss: 0.671818, acc.: 60.94%] [G loss: 0.931019]\n",
      "epoch:27 step:25706 [D loss: 0.673379, acc.: 61.72%] [G loss: 0.885717]\n",
      "epoch:27 step:25707 [D loss: 0.647518, acc.: 59.38%] [G loss: 0.915697]\n",
      "epoch:27 step:25708 [D loss: 0.633150, acc.: 63.28%] [G loss: 0.887408]\n",
      "epoch:27 step:25709 [D loss: 0.683336, acc.: 59.38%] [G loss: 0.931870]\n",
      "epoch:27 step:25710 [D loss: 0.605051, acc.: 66.41%] [G loss: 0.898604]\n",
      "epoch:27 step:25711 [D loss: 0.678468, acc.: 57.81%] [G loss: 0.902180]\n",
      "epoch:27 step:25712 [D loss: 0.692720, acc.: 58.59%] [G loss: 0.881675]\n",
      "epoch:27 step:25713 [D loss: 0.653738, acc.: 64.06%] [G loss: 0.847443]\n",
      "epoch:27 step:25714 [D loss: 0.654590, acc.: 59.38%] [G loss: 0.905645]\n",
      "epoch:27 step:25715 [D loss: 0.625064, acc.: 62.50%] [G loss: 0.973304]\n",
      "epoch:27 step:25716 [D loss: 0.599173, acc.: 75.78%] [G loss: 0.919841]\n",
      "epoch:27 step:25717 [D loss: 0.674903, acc.: 57.81%] [G loss: 0.912158]\n",
      "epoch:27 step:25718 [D loss: 0.641127, acc.: 63.28%] [G loss: 0.881126]\n",
      "epoch:27 step:25719 [D loss: 0.658929, acc.: 58.59%] [G loss: 0.900148]\n",
      "epoch:27 step:25720 [D loss: 0.650805, acc.: 63.28%] [G loss: 0.918278]\n",
      "epoch:27 step:25721 [D loss: 0.666791, acc.: 58.59%] [G loss: 0.901432]\n",
      "epoch:27 step:25722 [D loss: 0.641668, acc.: 64.84%] [G loss: 0.922418]\n",
      "epoch:27 step:25723 [D loss: 0.680942, acc.: 57.03%] [G loss: 0.845637]\n",
      "epoch:27 step:25724 [D loss: 0.683733, acc.: 56.25%] [G loss: 0.873608]\n",
      "epoch:27 step:25725 [D loss: 0.641373, acc.: 64.84%] [G loss: 0.899902]\n",
      "epoch:27 step:25726 [D loss: 0.636800, acc.: 67.19%] [G loss: 0.841907]\n",
      "epoch:27 step:25727 [D loss: 0.689004, acc.: 58.59%] [G loss: 0.876513]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25728 [D loss: 0.663033, acc.: 59.38%] [G loss: 0.895319]\n",
      "epoch:27 step:25729 [D loss: 0.677064, acc.: 62.50%] [G loss: 0.855037]\n",
      "epoch:27 step:25730 [D loss: 0.619689, acc.: 64.06%] [G loss: 0.883533]\n",
      "epoch:27 step:25731 [D loss: 0.628497, acc.: 64.84%] [G loss: 0.894093]\n",
      "epoch:27 step:25732 [D loss: 0.639091, acc.: 64.06%] [G loss: 0.822582]\n",
      "epoch:27 step:25733 [D loss: 0.673163, acc.: 54.69%] [G loss: 0.879605]\n",
      "epoch:27 step:25734 [D loss: 0.638869, acc.: 63.28%] [G loss: 0.874982]\n",
      "epoch:27 step:25735 [D loss: 0.673241, acc.: 52.34%] [G loss: 0.897469]\n",
      "epoch:27 step:25736 [D loss: 0.715703, acc.: 50.00%] [G loss: 0.870171]\n",
      "epoch:27 step:25737 [D loss: 0.657647, acc.: 61.72%] [G loss: 0.897065]\n",
      "epoch:27 step:25738 [D loss: 0.653235, acc.: 65.62%] [G loss: 0.901274]\n",
      "epoch:27 step:25739 [D loss: 0.630625, acc.: 64.84%] [G loss: 0.917274]\n",
      "epoch:27 step:25740 [D loss: 0.655382, acc.: 54.69%] [G loss: 0.870949]\n",
      "epoch:27 step:25741 [D loss: 0.661378, acc.: 62.50%] [G loss: 0.925331]\n",
      "epoch:27 step:25742 [D loss: 0.645233, acc.: 60.16%] [G loss: 0.905504]\n",
      "epoch:27 step:25743 [D loss: 0.643070, acc.: 60.94%] [G loss: 0.916421]\n",
      "epoch:27 step:25744 [D loss: 0.681323, acc.: 54.69%] [G loss: 0.914088]\n",
      "epoch:27 step:25745 [D loss: 0.653130, acc.: 64.06%] [G loss: 0.892046]\n",
      "epoch:27 step:25746 [D loss: 0.663841, acc.: 57.03%] [G loss: 0.911614]\n",
      "epoch:27 step:25747 [D loss: 0.659144, acc.: 57.03%] [G loss: 0.873738]\n",
      "epoch:27 step:25748 [D loss: 0.686904, acc.: 54.69%] [G loss: 0.955623]\n",
      "epoch:27 step:25749 [D loss: 0.623381, acc.: 68.75%] [G loss: 0.952905]\n",
      "epoch:27 step:25750 [D loss: 0.624488, acc.: 66.41%] [G loss: 0.872308]\n",
      "epoch:27 step:25751 [D loss: 0.664428, acc.: 59.38%] [G loss: 0.853242]\n",
      "epoch:27 step:25752 [D loss: 0.622147, acc.: 64.06%] [G loss: 0.921911]\n",
      "epoch:27 step:25753 [D loss: 0.654864, acc.: 56.25%] [G loss: 0.947911]\n",
      "epoch:27 step:25754 [D loss: 0.640009, acc.: 62.50%] [G loss: 0.880532]\n",
      "epoch:27 step:25755 [D loss: 0.636721, acc.: 66.41%] [G loss: 0.865829]\n",
      "epoch:27 step:25756 [D loss: 0.645384, acc.: 63.28%] [G loss: 0.884396]\n",
      "epoch:27 step:25757 [D loss: 0.610791, acc.: 63.28%] [G loss: 0.922237]\n",
      "epoch:27 step:25758 [D loss: 0.603568, acc.: 67.19%] [G loss: 0.896086]\n",
      "epoch:27 step:25759 [D loss: 0.619710, acc.: 59.38%] [G loss: 0.869163]\n",
      "epoch:27 step:25760 [D loss: 0.655255, acc.: 54.69%] [G loss: 0.934941]\n",
      "epoch:27 step:25761 [D loss: 0.673503, acc.: 56.25%] [G loss: 0.898177]\n",
      "epoch:27 step:25762 [D loss: 0.679037, acc.: 60.94%] [G loss: 0.970533]\n",
      "epoch:27 step:25763 [D loss: 0.650127, acc.: 57.03%] [G loss: 0.965480]\n",
      "epoch:27 step:25764 [D loss: 0.679033, acc.: 57.03%] [G loss: 0.888189]\n",
      "epoch:27 step:25765 [D loss: 0.630881, acc.: 67.97%] [G loss: 0.928841]\n",
      "epoch:27 step:25766 [D loss: 0.660072, acc.: 64.06%] [G loss: 0.957622]\n",
      "epoch:27 step:25767 [D loss: 0.611144, acc.: 69.53%] [G loss: 0.954843]\n",
      "epoch:27 step:25768 [D loss: 0.622815, acc.: 71.88%] [G loss: 0.988082]\n",
      "epoch:27 step:25769 [D loss: 0.637736, acc.: 66.41%] [G loss: 0.940944]\n",
      "epoch:27 step:25770 [D loss: 0.638688, acc.: 67.19%] [G loss: 0.960353]\n",
      "epoch:27 step:25771 [D loss: 0.649745, acc.: 57.81%] [G loss: 0.963172]\n",
      "epoch:27 step:25772 [D loss: 0.637755, acc.: 61.72%] [G loss: 0.948091]\n",
      "epoch:27 step:25773 [D loss: 0.610587, acc.: 67.97%] [G loss: 0.899904]\n",
      "epoch:27 step:25774 [D loss: 0.614652, acc.: 64.06%] [G loss: 0.927310]\n",
      "epoch:27 step:25775 [D loss: 0.705458, acc.: 54.69%] [G loss: 0.940367]\n",
      "epoch:27 step:25776 [D loss: 0.689747, acc.: 54.69%] [G loss: 0.909558]\n",
      "epoch:27 step:25777 [D loss: 0.644521, acc.: 61.72%] [G loss: 0.900043]\n",
      "epoch:27 step:25778 [D loss: 0.655469, acc.: 62.50%] [G loss: 0.901274]\n",
      "epoch:27 step:25779 [D loss: 0.666194, acc.: 60.16%] [G loss: 0.868638]\n",
      "epoch:27 step:25780 [D loss: 0.687879, acc.: 48.44%] [G loss: 0.904636]\n",
      "epoch:27 step:25781 [D loss: 0.620071, acc.: 67.97%] [G loss: 0.835700]\n",
      "epoch:27 step:25782 [D loss: 0.675676, acc.: 55.47%] [G loss: 0.844051]\n",
      "epoch:27 step:25783 [D loss: 0.636615, acc.: 60.16%] [G loss: 0.901886]\n",
      "epoch:27 step:25784 [D loss: 0.630001, acc.: 64.84%] [G loss: 0.917119]\n",
      "epoch:27 step:25785 [D loss: 0.631964, acc.: 63.28%] [G loss: 0.920589]\n",
      "epoch:27 step:25786 [D loss: 0.700349, acc.: 56.25%] [G loss: 0.939229]\n",
      "epoch:27 step:25787 [D loss: 0.593382, acc.: 67.97%] [G loss: 0.967882]\n",
      "epoch:27 step:25788 [D loss: 0.624096, acc.: 68.75%] [G loss: 0.930597]\n",
      "epoch:27 step:25789 [D loss: 0.682869, acc.: 56.25%] [G loss: 0.931787]\n",
      "epoch:27 step:25790 [D loss: 0.649677, acc.: 61.72%] [G loss: 0.910219]\n",
      "epoch:27 step:25791 [D loss: 0.642275, acc.: 58.59%] [G loss: 0.943622]\n",
      "epoch:27 step:25792 [D loss: 0.650752, acc.: 64.06%] [G loss: 0.904383]\n",
      "epoch:27 step:25793 [D loss: 0.657129, acc.: 60.16%] [G loss: 0.918199]\n",
      "epoch:27 step:25794 [D loss: 0.675191, acc.: 54.69%] [G loss: 0.903062]\n",
      "epoch:27 step:25795 [D loss: 0.638549, acc.: 66.41%] [G loss: 0.934754]\n",
      "epoch:27 step:25796 [D loss: 0.657998, acc.: 63.28%] [G loss: 0.899969]\n",
      "epoch:27 step:25797 [D loss: 0.663551, acc.: 56.25%] [G loss: 0.901515]\n",
      "epoch:27 step:25798 [D loss: 0.667991, acc.: 61.72%] [G loss: 0.891609]\n",
      "epoch:27 step:25799 [D loss: 0.652704, acc.: 62.50%] [G loss: 0.876069]\n",
      "epoch:27 step:25800 [D loss: 0.653799, acc.: 58.59%] [G loss: 0.876302]\n",
      "##############\n",
      "[2.98710068 2.24985846 2.13182045 4.0881333  1.27693445 9.27426719\n",
      " 3.22373579 3.85008587 4.30761319 8.14868929]\n",
      "##########\n",
      "epoch:27 step:25801 [D loss: 0.632874, acc.: 63.28%] [G loss: 0.902763]\n",
      "epoch:27 step:25802 [D loss: 0.621606, acc.: 67.97%] [G loss: 0.918868]\n",
      "epoch:27 step:25803 [D loss: 0.660484, acc.: 59.38%] [G loss: 0.940887]\n",
      "epoch:27 step:25804 [D loss: 0.668069, acc.: 59.38%] [G loss: 0.910907]\n",
      "epoch:27 step:25805 [D loss: 0.643676, acc.: 62.50%] [G loss: 0.923683]\n",
      "epoch:27 step:25806 [D loss: 0.669037, acc.: 60.94%] [G loss: 0.917504]\n",
      "epoch:27 step:25807 [D loss: 0.677514, acc.: 62.50%] [G loss: 0.962006]\n",
      "epoch:27 step:25808 [D loss: 0.649050, acc.: 60.94%] [G loss: 0.915801]\n",
      "epoch:27 step:25809 [D loss: 0.614615, acc.: 63.28%] [G loss: 1.008882]\n",
      "epoch:27 step:25810 [D loss: 0.639031, acc.: 58.59%] [G loss: 0.891344]\n",
      "epoch:27 step:25811 [D loss: 0.684254, acc.: 57.03%] [G loss: 0.882434]\n",
      "epoch:27 step:25812 [D loss: 0.626817, acc.: 62.50%] [G loss: 0.916507]\n",
      "epoch:27 step:25813 [D loss: 0.617324, acc.: 67.19%] [G loss: 0.858913]\n",
      "epoch:27 step:25814 [D loss: 0.639307, acc.: 61.72%] [G loss: 0.843719]\n",
      "epoch:27 step:25815 [D loss: 0.640791, acc.: 61.72%] [G loss: 0.850051]\n",
      "epoch:27 step:25816 [D loss: 0.600038, acc.: 71.09%] [G loss: 0.887491]\n",
      "epoch:27 step:25817 [D loss: 0.648104, acc.: 59.38%] [G loss: 0.905186]\n",
      "epoch:27 step:25818 [D loss: 0.672606, acc.: 53.12%] [G loss: 0.958744]\n",
      "epoch:27 step:25819 [D loss: 0.657420, acc.: 65.62%] [G loss: 0.963545]\n",
      "epoch:27 step:25820 [D loss: 0.639821, acc.: 65.62%] [G loss: 0.975658]\n",
      "epoch:27 step:25821 [D loss: 0.617234, acc.: 67.97%] [G loss: 0.954159]\n",
      "epoch:27 step:25822 [D loss: 0.651863, acc.: 64.06%] [G loss: 0.916608]\n",
      "epoch:27 step:25823 [D loss: 0.607927, acc.: 64.84%] [G loss: 0.976619]\n",
      "epoch:27 step:25824 [D loss: 0.706650, acc.: 52.34%] [G loss: 0.955408]\n",
      "epoch:27 step:25825 [D loss: 0.677903, acc.: 59.38%] [G loss: 0.902443]\n",
      "epoch:27 step:25826 [D loss: 0.643536, acc.: 57.03%] [G loss: 0.975227]\n",
      "epoch:27 step:25827 [D loss: 0.674410, acc.: 55.47%] [G loss: 0.982704]\n",
      "epoch:27 step:25828 [D loss: 0.683080, acc.: 59.38%] [G loss: 0.989479]\n",
      "epoch:27 step:25829 [D loss: 0.647340, acc.: 64.84%] [G loss: 0.892937]\n",
      "epoch:27 step:25830 [D loss: 0.688650, acc.: 57.03%] [G loss: 0.920648]\n",
      "epoch:27 step:25831 [D loss: 0.637757, acc.: 66.41%] [G loss: 0.866734]\n",
      "epoch:27 step:25832 [D loss: 0.656017, acc.: 60.16%] [G loss: 0.902623]\n",
      "epoch:27 step:25833 [D loss: 0.675571, acc.: 60.16%] [G loss: 0.843477]\n",
      "epoch:27 step:25834 [D loss: 0.639399, acc.: 62.50%] [G loss: 0.867910]\n",
      "epoch:27 step:25835 [D loss: 0.677226, acc.: 53.91%] [G loss: 0.865514]\n",
      "epoch:27 step:25836 [D loss: 0.662585, acc.: 67.19%] [G loss: 0.894926]\n",
      "epoch:27 step:25837 [D loss: 0.649953, acc.: 62.50%] [G loss: 0.889404]\n",
      "epoch:27 step:25838 [D loss: 0.661953, acc.: 60.16%] [G loss: 0.913477]\n",
      "epoch:27 step:25839 [D loss: 0.627308, acc.: 63.28%] [G loss: 0.878407]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25840 [D loss: 0.657080, acc.: 59.38%] [G loss: 0.899699]\n",
      "epoch:27 step:25841 [D loss: 0.666993, acc.: 60.94%] [G loss: 0.872097]\n",
      "epoch:27 step:25842 [D loss: 0.631845, acc.: 66.41%] [G loss: 0.905963]\n",
      "epoch:27 step:25843 [D loss: 0.652144, acc.: 65.62%] [G loss: 0.960523]\n",
      "epoch:27 step:25844 [D loss: 0.633085, acc.: 67.97%] [G loss: 0.927598]\n",
      "epoch:27 step:25845 [D loss: 0.651525, acc.: 64.06%] [G loss: 0.975646]\n",
      "epoch:27 step:25846 [D loss: 0.633638, acc.: 64.84%] [G loss: 0.918152]\n",
      "epoch:27 step:25847 [D loss: 0.701006, acc.: 57.03%] [G loss: 0.894973]\n",
      "epoch:27 step:25848 [D loss: 0.652362, acc.: 60.16%] [G loss: 0.888375]\n",
      "epoch:27 step:25849 [D loss: 0.648292, acc.: 59.38%] [G loss: 0.887084]\n",
      "epoch:27 step:25850 [D loss: 0.637746, acc.: 65.62%] [G loss: 0.939776]\n",
      "epoch:27 step:25851 [D loss: 0.627844, acc.: 64.06%] [G loss: 0.986359]\n",
      "epoch:27 step:25852 [D loss: 0.632840, acc.: 62.50%] [G loss: 0.908703]\n",
      "epoch:27 step:25853 [D loss: 0.645389, acc.: 64.06%] [G loss: 0.918936]\n",
      "epoch:27 step:25854 [D loss: 0.636962, acc.: 64.06%] [G loss: 0.905896]\n",
      "epoch:27 step:25855 [D loss: 0.655540, acc.: 64.06%] [G loss: 0.868732]\n",
      "epoch:27 step:25856 [D loss: 0.679788, acc.: 53.12%] [G loss: 0.901116]\n",
      "epoch:27 step:25857 [D loss: 0.675433, acc.: 60.16%] [G loss: 0.877200]\n",
      "epoch:27 step:25858 [D loss: 0.666967, acc.: 58.59%] [G loss: 0.871389]\n",
      "epoch:27 step:25859 [D loss: 0.651007, acc.: 57.81%] [G loss: 0.892402]\n",
      "epoch:27 step:25860 [D loss: 0.668485, acc.: 57.03%] [G loss: 0.933507]\n",
      "epoch:27 step:25861 [D loss: 0.657002, acc.: 60.16%] [G loss: 0.975297]\n",
      "epoch:27 step:25862 [D loss: 0.636755, acc.: 63.28%] [G loss: 0.917061]\n",
      "epoch:27 step:25863 [D loss: 0.636559, acc.: 68.75%] [G loss: 0.905903]\n",
      "epoch:27 step:25864 [D loss: 0.647114, acc.: 59.38%] [G loss: 0.935128]\n",
      "epoch:27 step:25865 [D loss: 0.628685, acc.: 68.75%] [G loss: 0.881159]\n",
      "epoch:27 step:25866 [D loss: 0.624425, acc.: 67.19%] [G loss: 0.903193]\n",
      "epoch:27 step:25867 [D loss: 0.653793, acc.: 59.38%] [G loss: 0.901664]\n",
      "epoch:27 step:25868 [D loss: 0.628569, acc.: 66.41%] [G loss: 0.972165]\n",
      "epoch:27 step:25869 [D loss: 0.654102, acc.: 60.94%] [G loss: 0.899136]\n",
      "epoch:27 step:25870 [D loss: 0.697901, acc.: 58.59%] [G loss: 0.851711]\n",
      "epoch:27 step:25871 [D loss: 0.664175, acc.: 61.72%] [G loss: 0.830113]\n",
      "epoch:27 step:25872 [D loss: 0.668019, acc.: 60.94%] [G loss: 0.873990]\n",
      "epoch:27 step:25873 [D loss: 0.645699, acc.: 58.59%] [G loss: 0.873395]\n",
      "epoch:27 step:25874 [D loss: 0.669479, acc.: 55.47%] [G loss: 0.917173]\n",
      "epoch:27 step:25875 [D loss: 0.638873, acc.: 70.31%] [G loss: 0.936201]\n",
      "epoch:27 step:25876 [D loss: 0.654833, acc.: 62.50%] [G loss: 0.906665]\n",
      "epoch:27 step:25877 [D loss: 0.636967, acc.: 62.50%] [G loss: 0.929408]\n",
      "epoch:27 step:25878 [D loss: 0.630680, acc.: 65.62%] [G loss: 0.913834]\n",
      "epoch:27 step:25879 [D loss: 0.667162, acc.: 54.69%] [G loss: 0.846609]\n",
      "epoch:27 step:25880 [D loss: 0.657285, acc.: 60.16%] [G loss: 0.889313]\n",
      "epoch:27 step:25881 [D loss: 0.646170, acc.: 60.16%] [G loss: 0.896432]\n",
      "epoch:27 step:25882 [D loss: 0.684298, acc.: 57.81%] [G loss: 0.936200]\n",
      "epoch:27 step:25883 [D loss: 0.633068, acc.: 65.62%] [G loss: 0.888128]\n",
      "epoch:27 step:25884 [D loss: 0.647837, acc.: 63.28%] [G loss: 0.875842]\n",
      "epoch:27 step:25885 [D loss: 0.667716, acc.: 57.03%] [G loss: 0.897455]\n",
      "epoch:27 step:25886 [D loss: 0.649679, acc.: 60.16%] [G loss: 0.906848]\n",
      "epoch:27 step:25887 [D loss: 0.669622, acc.: 59.38%] [G loss: 0.939680]\n",
      "epoch:27 step:25888 [D loss: 0.618524, acc.: 64.06%] [G loss: 0.933029]\n",
      "epoch:27 step:25889 [D loss: 0.653366, acc.: 61.72%] [G loss: 0.899924]\n",
      "epoch:27 step:25890 [D loss: 0.649987, acc.: 60.94%] [G loss: 0.959733]\n",
      "epoch:27 step:25891 [D loss: 0.661483, acc.: 60.94%] [G loss: 0.920868]\n",
      "epoch:27 step:25892 [D loss: 0.661131, acc.: 59.38%] [G loss: 0.860401]\n",
      "epoch:27 step:25893 [D loss: 0.662357, acc.: 60.94%] [G loss: 0.927325]\n",
      "epoch:27 step:25894 [D loss: 0.661732, acc.: 64.84%] [G loss: 0.919094]\n",
      "epoch:27 step:25895 [D loss: 0.642298, acc.: 63.28%] [G loss: 0.925178]\n",
      "epoch:27 step:25896 [D loss: 0.661604, acc.: 60.94%] [G loss: 0.943722]\n",
      "epoch:27 step:25897 [D loss: 0.650913, acc.: 58.59%] [G loss: 0.955482]\n",
      "epoch:27 step:25898 [D loss: 0.613469, acc.: 68.75%] [G loss: 0.985008]\n",
      "epoch:27 step:25899 [D loss: 0.637392, acc.: 61.72%] [G loss: 0.989666]\n",
      "epoch:27 step:25900 [D loss: 0.619960, acc.: 68.75%] [G loss: 0.912254]\n",
      "epoch:27 step:25901 [D loss: 0.595258, acc.: 70.31%] [G loss: 0.887594]\n",
      "epoch:27 step:25902 [D loss: 0.677972, acc.: 59.38%] [G loss: 0.896125]\n",
      "epoch:27 step:25903 [D loss: 0.680960, acc.: 60.94%] [G loss: 0.904610]\n",
      "epoch:27 step:25904 [D loss: 0.685202, acc.: 56.25%] [G loss: 0.907277]\n",
      "epoch:27 step:25905 [D loss: 0.682865, acc.: 53.12%] [G loss: 0.846223]\n",
      "epoch:27 step:25906 [D loss: 0.642516, acc.: 65.62%] [G loss: 0.897147]\n",
      "epoch:27 step:25907 [D loss: 0.661536, acc.: 57.81%] [G loss: 0.877054]\n",
      "epoch:27 step:25908 [D loss: 0.620520, acc.: 66.41%] [G loss: 0.904848]\n",
      "epoch:27 step:25909 [D loss: 0.673823, acc.: 58.59%] [G loss: 0.870849]\n",
      "epoch:27 step:25910 [D loss: 0.681706, acc.: 54.69%] [G loss: 0.890422]\n",
      "epoch:27 step:25911 [D loss: 0.673169, acc.: 57.03%] [G loss: 0.914203]\n",
      "epoch:27 step:25912 [D loss: 0.690328, acc.: 50.00%] [G loss: 0.918155]\n",
      "epoch:27 step:25913 [D loss: 0.663951, acc.: 56.25%] [G loss: 0.878134]\n",
      "epoch:27 step:25914 [D loss: 0.679112, acc.: 57.03%] [G loss: 0.884810]\n",
      "epoch:27 step:25915 [D loss: 0.621027, acc.: 65.62%] [G loss: 0.877522]\n",
      "epoch:27 step:25916 [D loss: 0.667384, acc.: 57.81%] [G loss: 0.957392]\n",
      "epoch:27 step:25917 [D loss: 0.592784, acc.: 68.75%] [G loss: 0.902038]\n",
      "epoch:27 step:25918 [D loss: 0.648990, acc.: 57.81%] [G loss: 0.838541]\n",
      "epoch:27 step:25919 [D loss: 0.667589, acc.: 55.47%] [G loss: 0.861353]\n",
      "epoch:27 step:25920 [D loss: 0.674065, acc.: 57.81%] [G loss: 0.893279]\n",
      "epoch:27 step:25921 [D loss: 0.666303, acc.: 59.38%] [G loss: 0.879940]\n",
      "epoch:27 step:25922 [D loss: 0.600692, acc.: 67.97%] [G loss: 0.881221]\n",
      "epoch:27 step:25923 [D loss: 0.646540, acc.: 64.84%] [G loss: 0.945456]\n",
      "epoch:27 step:25924 [D loss: 0.642152, acc.: 64.84%] [G loss: 0.879945]\n",
      "epoch:27 step:25925 [D loss: 0.658811, acc.: 58.59%] [G loss: 0.906247]\n",
      "epoch:27 step:25926 [D loss: 0.613433, acc.: 67.19%] [G loss: 0.901229]\n",
      "epoch:27 step:25927 [D loss: 0.664791, acc.: 59.38%] [G loss: 0.908637]\n",
      "epoch:27 step:25928 [D loss: 0.656816, acc.: 60.16%] [G loss: 0.890237]\n",
      "epoch:27 step:25929 [D loss: 0.664172, acc.: 57.03%] [G loss: 0.884974]\n",
      "epoch:27 step:25930 [D loss: 0.602535, acc.: 69.53%] [G loss: 0.949406]\n",
      "epoch:27 step:25931 [D loss: 0.680459, acc.: 54.69%] [G loss: 0.887201]\n",
      "epoch:27 step:25932 [D loss: 0.663485, acc.: 58.59%] [G loss: 0.960611]\n",
      "epoch:27 step:25933 [D loss: 0.640323, acc.: 58.59%] [G loss: 0.889338]\n",
      "epoch:27 step:25934 [D loss: 0.651729, acc.: 63.28%] [G loss: 0.915357]\n",
      "epoch:27 step:25935 [D loss: 0.644932, acc.: 62.50%] [G loss: 0.915509]\n",
      "epoch:27 step:25936 [D loss: 0.642559, acc.: 62.50%] [G loss: 0.872574]\n",
      "epoch:27 step:25937 [D loss: 0.629781, acc.: 60.94%] [G loss: 0.822148]\n",
      "epoch:27 step:25938 [D loss: 0.662386, acc.: 65.62%] [G loss: 0.887868]\n",
      "epoch:27 step:25939 [D loss: 0.599271, acc.: 68.75%] [G loss: 0.899859]\n",
      "epoch:27 step:25940 [D loss: 0.716305, acc.: 55.47%] [G loss: 0.895164]\n",
      "epoch:27 step:25941 [D loss: 0.652129, acc.: 63.28%] [G loss: 0.856475]\n",
      "epoch:27 step:25942 [D loss: 0.699292, acc.: 60.94%] [G loss: 0.865904]\n",
      "epoch:27 step:25943 [D loss: 0.639238, acc.: 59.38%] [G loss: 0.884884]\n",
      "epoch:27 step:25944 [D loss: 0.640037, acc.: 65.62%] [G loss: 0.897467]\n",
      "epoch:27 step:25945 [D loss: 0.682344, acc.: 60.94%] [G loss: 0.890807]\n",
      "epoch:27 step:25946 [D loss: 0.649039, acc.: 63.28%] [G loss: 0.911579]\n",
      "epoch:27 step:25947 [D loss: 0.679372, acc.: 59.38%] [G loss: 0.883862]\n",
      "epoch:27 step:25948 [D loss: 0.632011, acc.: 64.06%] [G loss: 0.947072]\n",
      "epoch:27 step:25949 [D loss: 0.625580, acc.: 71.09%] [G loss: 0.904111]\n",
      "epoch:27 step:25950 [D loss: 0.626433, acc.: 68.75%] [G loss: 0.873984]\n",
      "epoch:27 step:25951 [D loss: 0.670995, acc.: 60.16%] [G loss: 0.842500]\n",
      "epoch:27 step:25952 [D loss: 0.621538, acc.: 67.97%] [G loss: 0.926645]\n",
      "epoch:27 step:25953 [D loss: 0.645109, acc.: 59.38%] [G loss: 0.911569]\n",
      "epoch:27 step:25954 [D loss: 0.695738, acc.: 53.91%] [G loss: 0.874456]\n",
      "epoch:27 step:25955 [D loss: 0.599184, acc.: 73.44%] [G loss: 0.860206]\n",
      "epoch:27 step:25956 [D loss: 0.688548, acc.: 53.91%] [G loss: 0.886355]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:25957 [D loss: 0.728733, acc.: 50.00%] [G loss: 0.889411]\n",
      "epoch:27 step:25958 [D loss: 0.660023, acc.: 58.59%] [G loss: 0.918312]\n",
      "epoch:27 step:25959 [D loss: 0.661266, acc.: 57.81%] [G loss: 0.881122]\n",
      "epoch:27 step:25960 [D loss: 0.653126, acc.: 64.06%] [G loss: 0.885487]\n",
      "epoch:27 step:25961 [D loss: 0.687710, acc.: 60.94%] [G loss: 0.936076]\n",
      "epoch:27 step:25962 [D loss: 0.630894, acc.: 64.84%] [G loss: 0.943642]\n",
      "epoch:27 step:25963 [D loss: 0.635131, acc.: 64.06%] [G loss: 0.894535]\n",
      "epoch:27 step:25964 [D loss: 0.614372, acc.: 67.97%] [G loss: 0.930913]\n",
      "epoch:27 step:25965 [D loss: 0.672700, acc.: 56.25%] [G loss: 0.842604]\n",
      "epoch:27 step:25966 [D loss: 0.608691, acc.: 69.53%] [G loss: 0.854894]\n",
      "epoch:27 step:25967 [D loss: 0.627233, acc.: 68.75%] [G loss: 0.851900]\n",
      "epoch:27 step:25968 [D loss: 0.628572, acc.: 61.72%] [G loss: 0.882998]\n",
      "epoch:27 step:25969 [D loss: 0.615259, acc.: 62.50%] [G loss: 0.852161]\n",
      "epoch:27 step:25970 [D loss: 0.633226, acc.: 64.84%] [G loss: 0.839820]\n",
      "epoch:27 step:25971 [D loss: 0.683597, acc.: 55.47%] [G loss: 0.899196]\n",
      "epoch:27 step:25972 [D loss: 0.662414, acc.: 62.50%] [G loss: 0.850930]\n",
      "epoch:27 step:25973 [D loss: 0.688923, acc.: 55.47%] [G loss: 0.864939]\n",
      "epoch:27 step:25974 [D loss: 0.663843, acc.: 55.47%] [G loss: 0.870508]\n",
      "epoch:27 step:25975 [D loss: 0.658626, acc.: 61.72%] [G loss: 0.895508]\n",
      "epoch:27 step:25976 [D loss: 0.667907, acc.: 54.69%] [G loss: 0.910038]\n",
      "epoch:27 step:25977 [D loss: 0.645047, acc.: 63.28%] [G loss: 0.909817]\n",
      "epoch:27 step:25978 [D loss: 0.646998, acc.: 60.94%] [G loss: 0.887805]\n",
      "epoch:27 step:25979 [D loss: 0.667363, acc.: 54.69%] [G loss: 0.879193]\n",
      "epoch:27 step:25980 [D loss: 0.613532, acc.: 72.66%] [G loss: 0.897192]\n",
      "epoch:27 step:25981 [D loss: 0.681922, acc.: 57.03%] [G loss: 0.930237]\n",
      "epoch:27 step:25982 [D loss: 0.651534, acc.: 57.03%] [G loss: 0.895923]\n",
      "epoch:27 step:25983 [D loss: 0.648749, acc.: 61.72%] [G loss: 0.915220]\n",
      "epoch:27 step:25984 [D loss: 0.704577, acc.: 51.56%] [G loss: 0.945380]\n",
      "epoch:27 step:25985 [D loss: 0.654413, acc.: 61.72%] [G loss: 0.935246]\n",
      "epoch:27 step:25986 [D loss: 0.643485, acc.: 60.94%] [G loss: 0.938878]\n",
      "epoch:27 step:25987 [D loss: 0.647739, acc.: 63.28%] [G loss: 1.017686]\n",
      "epoch:27 step:25988 [D loss: 0.619882, acc.: 65.62%] [G loss: 0.968163]\n",
      "epoch:27 step:25989 [D loss: 0.626266, acc.: 61.72%] [G loss: 0.919927]\n",
      "epoch:27 step:25990 [D loss: 0.663671, acc.: 61.72%] [G loss: 0.911380]\n",
      "epoch:27 step:25991 [D loss: 0.652950, acc.: 56.25%] [G loss: 0.911649]\n",
      "epoch:27 step:25992 [D loss: 0.659291, acc.: 62.50%] [G loss: 0.890483]\n",
      "epoch:27 step:25993 [D loss: 0.644514, acc.: 60.94%] [G loss: 0.899921]\n",
      "epoch:27 step:25994 [D loss: 0.641707, acc.: 60.16%] [G loss: 0.896113]\n",
      "epoch:27 step:25995 [D loss: 0.660349, acc.: 60.94%] [G loss: 0.879610]\n",
      "epoch:27 step:25996 [D loss: 0.702295, acc.: 53.91%] [G loss: 0.895940]\n",
      "epoch:27 step:25997 [D loss: 0.658028, acc.: 53.12%] [G loss: 0.850886]\n",
      "epoch:27 step:25998 [D loss: 0.676934, acc.: 56.25%] [G loss: 0.884323]\n",
      "epoch:27 step:25999 [D loss: 0.650124, acc.: 58.59%] [G loss: 0.890021]\n",
      "epoch:27 step:26000 [D loss: 0.688514, acc.: 52.34%] [G loss: 0.929067]\n",
      "##############\n",
      "[2.93016255 2.37966629 2.30419266 4.32634846 1.21731866 9.27426719\n",
      " 2.70491162 3.42138942 4.22941229 7.14868929]\n",
      "##########\n",
      "epoch:27 step:26001 [D loss: 0.650646, acc.: 58.59%] [G loss: 0.907291]\n",
      "epoch:27 step:26002 [D loss: 0.689926, acc.: 53.12%] [G loss: 0.905139]\n",
      "epoch:27 step:26003 [D loss: 0.659432, acc.: 57.81%] [G loss: 0.887563]\n",
      "epoch:27 step:26004 [D loss: 0.642784, acc.: 60.94%] [G loss: 0.925017]\n",
      "epoch:27 step:26005 [D loss: 0.673630, acc.: 59.38%] [G loss: 0.953982]\n",
      "epoch:27 step:26006 [D loss: 0.638038, acc.: 64.06%] [G loss: 0.926811]\n",
      "epoch:27 step:26007 [D loss: 0.654395, acc.: 57.03%] [G loss: 0.950505]\n",
      "epoch:27 step:26008 [D loss: 0.677687, acc.: 56.25%] [G loss: 0.941916]\n",
      "epoch:27 step:26009 [D loss: 0.621376, acc.: 69.53%] [G loss: 0.893925]\n",
      "epoch:27 step:26010 [D loss: 0.647760, acc.: 62.50%] [G loss: 0.969582]\n",
      "epoch:27 step:26011 [D loss: 0.664455, acc.: 56.25%] [G loss: 0.964171]\n",
      "epoch:27 step:26012 [D loss: 0.669897, acc.: 57.81%] [G loss: 0.858473]\n",
      "epoch:27 step:26013 [D loss: 0.683469, acc.: 55.47%] [G loss: 0.940800]\n",
      "epoch:27 step:26014 [D loss: 0.660707, acc.: 60.94%] [G loss: 0.881002]\n",
      "epoch:27 step:26015 [D loss: 0.642143, acc.: 61.72%] [G loss: 0.916463]\n",
      "epoch:27 step:26016 [D loss: 0.623480, acc.: 64.84%] [G loss: 0.885944]\n",
      "epoch:27 step:26017 [D loss: 0.634530, acc.: 64.84%] [G loss: 0.924386]\n",
      "epoch:27 step:26018 [D loss: 0.658039, acc.: 64.84%] [G loss: 0.853966]\n",
      "epoch:27 step:26019 [D loss: 0.597040, acc.: 68.75%] [G loss: 0.936892]\n",
      "epoch:27 step:26020 [D loss: 0.657569, acc.: 60.16%] [G loss: 0.847677]\n",
      "epoch:27 step:26021 [D loss: 0.687998, acc.: 53.12%] [G loss: 0.944840]\n",
      "epoch:27 step:26022 [D loss: 0.658136, acc.: 57.03%] [G loss: 0.911102]\n",
      "epoch:27 step:26023 [D loss: 0.657595, acc.: 53.91%] [G loss: 0.929312]\n",
      "epoch:27 step:26024 [D loss: 0.601609, acc.: 72.66%] [G loss: 0.948160]\n",
      "epoch:27 step:26025 [D loss: 0.664665, acc.: 57.03%] [G loss: 0.917299]\n",
      "epoch:27 step:26026 [D loss: 0.630280, acc.: 66.41%] [G loss: 0.917312]\n",
      "epoch:27 step:26027 [D loss: 0.668495, acc.: 63.28%] [G loss: 0.926651]\n",
      "epoch:27 step:26028 [D loss: 0.631085, acc.: 62.50%] [G loss: 0.938823]\n",
      "epoch:27 step:26029 [D loss: 0.653076, acc.: 60.94%] [G loss: 0.866062]\n",
      "epoch:27 step:26030 [D loss: 0.626424, acc.: 67.97%] [G loss: 0.940923]\n",
      "epoch:27 step:26031 [D loss: 0.642650, acc.: 63.28%] [G loss: 0.931212]\n",
      "epoch:27 step:26032 [D loss: 0.618335, acc.: 64.84%] [G loss: 0.918800]\n",
      "epoch:27 step:26033 [D loss: 0.621211, acc.: 64.84%] [G loss: 0.943312]\n",
      "epoch:27 step:26034 [D loss: 0.622002, acc.: 67.19%] [G loss: 0.905965]\n",
      "epoch:27 step:26035 [D loss: 0.633654, acc.: 64.84%] [G loss: 0.901377]\n",
      "epoch:27 step:26036 [D loss: 0.690007, acc.: 54.69%] [G loss: 0.910206]\n",
      "epoch:27 step:26037 [D loss: 0.684697, acc.: 50.00%] [G loss: 0.871710]\n",
      "epoch:27 step:26038 [D loss: 0.678760, acc.: 60.94%] [G loss: 0.893462]\n",
      "epoch:27 step:26039 [D loss: 0.642098, acc.: 63.28%] [G loss: 0.845985]\n",
      "epoch:27 step:26040 [D loss: 0.620778, acc.: 63.28%] [G loss: 0.925733]\n",
      "epoch:27 step:26041 [D loss: 0.687501, acc.: 63.28%] [G loss: 0.895948]\n",
      "epoch:27 step:26042 [D loss: 0.635632, acc.: 60.94%] [G loss: 0.916830]\n",
      "epoch:27 step:26043 [D loss: 0.638415, acc.: 64.06%] [G loss: 0.888587]\n",
      "epoch:27 step:26044 [D loss: 0.647192, acc.: 66.41%] [G loss: 0.907588]\n",
      "epoch:27 step:26045 [D loss: 0.638388, acc.: 60.16%] [G loss: 0.863837]\n",
      "epoch:27 step:26046 [D loss: 0.657987, acc.: 64.06%] [G loss: 0.910657]\n",
      "epoch:27 step:26047 [D loss: 0.637076, acc.: 60.16%] [G loss: 0.923928]\n",
      "epoch:27 step:26048 [D loss: 0.663483, acc.: 59.38%] [G loss: 0.993761]\n",
      "epoch:27 step:26049 [D loss: 0.654279, acc.: 68.75%] [G loss: 0.915850]\n",
      "epoch:27 step:26050 [D loss: 0.635459, acc.: 60.94%] [G loss: 0.922306]\n",
      "epoch:27 step:26051 [D loss: 0.639956, acc.: 64.06%] [G loss: 0.936121]\n",
      "epoch:27 step:26052 [D loss: 0.628360, acc.: 64.84%] [G loss: 0.913923]\n",
      "epoch:27 step:26053 [D loss: 0.688822, acc.: 54.69%] [G loss: 0.951734]\n",
      "epoch:27 step:26054 [D loss: 0.640773, acc.: 65.62%] [G loss: 0.904783]\n",
      "epoch:27 step:26055 [D loss: 0.629307, acc.: 64.06%] [G loss: 0.891660]\n",
      "epoch:27 step:26056 [D loss: 0.593845, acc.: 75.78%] [G loss: 0.894944]\n",
      "epoch:27 step:26057 [D loss: 0.656878, acc.: 65.62%] [G loss: 0.860717]\n",
      "epoch:27 step:26058 [D loss: 0.662301, acc.: 67.19%] [G loss: 0.840446]\n",
      "epoch:27 step:26059 [D loss: 0.645017, acc.: 66.41%] [G loss: 0.935944]\n",
      "epoch:27 step:26060 [D loss: 0.693540, acc.: 52.34%] [G loss: 0.940252]\n",
      "epoch:27 step:26061 [D loss: 0.662172, acc.: 62.50%] [G loss: 0.948221]\n",
      "epoch:27 step:26062 [D loss: 0.657790, acc.: 64.84%] [G loss: 0.870053]\n",
      "epoch:27 step:26063 [D loss: 0.630850, acc.: 64.06%] [G loss: 0.881557]\n",
      "epoch:27 step:26064 [D loss: 0.672348, acc.: 58.59%] [G loss: 0.942418]\n",
      "epoch:27 step:26065 [D loss: 0.658889, acc.: 58.59%] [G loss: 0.841723]\n",
      "epoch:27 step:26066 [D loss: 0.661118, acc.: 57.03%] [G loss: 0.870994]\n",
      "epoch:27 step:26067 [D loss: 0.635909, acc.: 66.41%] [G loss: 0.877747]\n",
      "epoch:27 step:26068 [D loss: 0.648468, acc.: 64.06%] [G loss: 0.925328]\n",
      "epoch:27 step:26069 [D loss: 0.671918, acc.: 60.16%] [G loss: 0.897456]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:26070 [D loss: 0.663898, acc.: 64.06%] [G loss: 0.856986]\n",
      "epoch:27 step:26071 [D loss: 0.597176, acc.: 67.97%] [G loss: 0.857439]\n",
      "epoch:27 step:26072 [D loss: 0.660072, acc.: 59.38%] [G loss: 0.879551]\n",
      "epoch:27 step:26073 [D loss: 0.651262, acc.: 60.94%] [G loss: 0.938114]\n",
      "epoch:27 step:26074 [D loss: 0.609147, acc.: 68.75%] [G loss: 0.903515]\n",
      "epoch:27 step:26075 [D loss: 0.693927, acc.: 56.25%] [G loss: 0.932741]\n",
      "epoch:27 step:26076 [D loss: 0.641162, acc.: 61.72%] [G loss: 0.929647]\n",
      "epoch:27 step:26077 [D loss: 0.616882, acc.: 63.28%] [G loss: 0.880683]\n",
      "epoch:27 step:26078 [D loss: 0.617216, acc.: 65.62%] [G loss: 0.892173]\n",
      "epoch:27 step:26079 [D loss: 0.630917, acc.: 63.28%] [G loss: 0.906410]\n",
      "epoch:27 step:26080 [D loss: 0.700526, acc.: 56.25%] [G loss: 0.885846]\n",
      "epoch:27 step:26081 [D loss: 0.627338, acc.: 66.41%] [G loss: 0.883865]\n",
      "epoch:27 step:26082 [D loss: 0.690127, acc.: 56.25%] [G loss: 0.891297]\n",
      "epoch:27 step:26083 [D loss: 0.652539, acc.: 56.25%] [G loss: 0.856249]\n",
      "epoch:27 step:26084 [D loss: 0.665057, acc.: 57.81%] [G loss: 0.902877]\n",
      "epoch:27 step:26085 [D loss: 0.681749, acc.: 48.44%] [G loss: 0.900596]\n",
      "epoch:27 step:26086 [D loss: 0.627966, acc.: 64.06%] [G loss: 0.896322]\n",
      "epoch:27 step:26087 [D loss: 0.636098, acc.: 63.28%] [G loss: 0.849899]\n",
      "epoch:27 step:26088 [D loss: 0.650467, acc.: 62.50%] [G loss: 0.892974]\n",
      "epoch:27 step:26089 [D loss: 0.664663, acc.: 59.38%] [G loss: 0.912624]\n",
      "epoch:27 step:26090 [D loss: 0.620394, acc.: 67.19%] [G loss: 0.865736]\n",
      "epoch:27 step:26091 [D loss: 0.637626, acc.: 65.62%] [G loss: 0.855508]\n",
      "epoch:27 step:26092 [D loss: 0.603220, acc.: 74.22%] [G loss: 0.917727]\n",
      "epoch:27 step:26093 [D loss: 0.646380, acc.: 67.19%] [G loss: 0.878348]\n",
      "epoch:27 step:26094 [D loss: 0.643723, acc.: 64.84%] [G loss: 0.888902]\n",
      "epoch:27 step:26095 [D loss: 0.670185, acc.: 59.38%] [G loss: 0.891757]\n",
      "epoch:27 step:26096 [D loss: 0.652654, acc.: 60.94%] [G loss: 0.894214]\n",
      "epoch:27 step:26097 [D loss: 0.660815, acc.: 64.06%] [G loss: 0.905115]\n",
      "epoch:27 step:26098 [D loss: 0.684921, acc.: 57.03%] [G loss: 0.966731]\n",
      "epoch:27 step:26099 [D loss: 0.649477, acc.: 63.28%] [G loss: 0.920714]\n",
      "epoch:27 step:26100 [D loss: 0.618745, acc.: 67.97%] [G loss: 0.987449]\n",
      "epoch:27 step:26101 [D loss: 0.679588, acc.: 57.03%] [G loss: 0.843922]\n",
      "epoch:27 step:26102 [D loss: 0.650822, acc.: 63.28%] [G loss: 0.854680]\n",
      "epoch:27 step:26103 [D loss: 0.693249, acc.: 53.12%] [G loss: 0.937443]\n",
      "epoch:27 step:26104 [D loss: 0.664917, acc.: 55.47%] [G loss: 0.891263]\n",
      "epoch:27 step:26105 [D loss: 0.655363, acc.: 62.50%] [G loss: 0.882564]\n",
      "epoch:27 step:26106 [D loss: 0.642579, acc.: 57.03%] [G loss: 0.859945]\n",
      "epoch:27 step:26107 [D loss: 0.675597, acc.: 60.16%] [G loss: 0.900576]\n",
      "epoch:27 step:26108 [D loss: 0.639702, acc.: 62.50%] [G loss: 0.986682]\n",
      "epoch:27 step:26109 [D loss: 0.668632, acc.: 57.03%] [G loss: 0.905944]\n",
      "epoch:27 step:26110 [D loss: 0.670197, acc.: 56.25%] [G loss: 0.888606]\n",
      "epoch:27 step:26111 [D loss: 0.686688, acc.: 55.47%] [G loss: 0.917505]\n",
      "epoch:27 step:26112 [D loss: 0.667623, acc.: 60.16%] [G loss: 0.951834]\n",
      "epoch:27 step:26113 [D loss: 0.643246, acc.: 59.38%] [G loss: 0.911263]\n",
      "epoch:27 step:26114 [D loss: 0.653539, acc.: 64.06%] [G loss: 0.848464]\n",
      "epoch:27 step:26115 [D loss: 0.649411, acc.: 59.38%] [G loss: 0.893770]\n",
      "epoch:27 step:26116 [D loss: 0.715528, acc.: 50.00%] [G loss: 0.892775]\n",
      "epoch:27 step:26117 [D loss: 0.636832, acc.: 62.50%] [G loss: 0.858368]\n",
      "epoch:27 step:26118 [D loss: 0.669915, acc.: 62.50%] [G loss: 0.926762]\n",
      "epoch:27 step:26119 [D loss: 0.640738, acc.: 62.50%] [G loss: 0.904339]\n",
      "epoch:27 step:26120 [D loss: 0.647328, acc.: 60.16%] [G loss: 0.908828]\n",
      "epoch:27 step:26121 [D loss: 0.606439, acc.: 67.19%] [G loss: 0.902658]\n",
      "epoch:27 step:26122 [D loss: 0.689956, acc.: 59.38%] [G loss: 0.881841]\n",
      "epoch:27 step:26123 [D loss: 0.653423, acc.: 63.28%] [G loss: 0.917413]\n",
      "epoch:27 step:26124 [D loss: 0.652112, acc.: 61.72%] [G loss: 0.915837]\n",
      "epoch:27 step:26125 [D loss: 0.655605, acc.: 65.62%] [G loss: 1.021998]\n",
      "epoch:27 step:26126 [D loss: 0.648337, acc.: 64.06%] [G loss: 0.876364]\n",
      "epoch:27 step:26127 [D loss: 0.648630, acc.: 60.94%] [G loss: 0.902205]\n",
      "epoch:27 step:26128 [D loss: 0.671267, acc.: 59.38%] [G loss: 0.893629]\n",
      "epoch:27 step:26129 [D loss: 0.687208, acc.: 57.81%] [G loss: 0.884655]\n",
      "epoch:27 step:26130 [D loss: 0.693917, acc.: 57.03%] [G loss: 0.880462]\n",
      "epoch:27 step:26131 [D loss: 0.649559, acc.: 58.59%] [G loss: 0.886780]\n",
      "epoch:27 step:26132 [D loss: 0.627248, acc.: 61.72%] [G loss: 0.940638]\n",
      "epoch:27 step:26133 [D loss: 0.689346, acc.: 50.78%] [G loss: 0.975970]\n",
      "epoch:27 step:26134 [D loss: 0.661146, acc.: 64.84%] [G loss: 0.928677]\n",
      "epoch:27 step:26135 [D loss: 0.643857, acc.: 66.41%] [G loss: 0.856649]\n",
      "epoch:27 step:26136 [D loss: 0.643950, acc.: 60.94%] [G loss: 0.920307]\n",
      "epoch:27 step:26137 [D loss: 0.657073, acc.: 62.50%] [G loss: 0.899541]\n",
      "epoch:27 step:26138 [D loss: 0.652604, acc.: 61.72%] [G loss: 0.975582]\n",
      "epoch:27 step:26139 [D loss: 0.681922, acc.: 57.03%] [G loss: 0.944297]\n",
      "epoch:27 step:26140 [D loss: 0.649316, acc.: 64.84%] [G loss: 0.933485]\n",
      "epoch:27 step:26141 [D loss: 0.660617, acc.: 61.72%] [G loss: 0.921177]\n",
      "epoch:27 step:26142 [D loss: 0.665824, acc.: 55.47%] [G loss: 0.924444]\n",
      "epoch:27 step:26143 [D loss: 0.643119, acc.: 63.28%] [G loss: 0.863348]\n",
      "epoch:27 step:26144 [D loss: 0.687132, acc.: 53.91%] [G loss: 0.852638]\n",
      "epoch:27 step:26145 [D loss: 0.664474, acc.: 58.59%] [G loss: 0.846678]\n",
      "epoch:27 step:26146 [D loss: 0.611454, acc.: 68.75%] [G loss: 0.885132]\n",
      "epoch:27 step:26147 [D loss: 0.641956, acc.: 64.84%] [G loss: 0.876980]\n",
      "epoch:27 step:26148 [D loss: 0.627882, acc.: 62.50%] [G loss: 0.908946]\n",
      "epoch:27 step:26149 [D loss: 0.669070, acc.: 56.25%] [G loss: 0.916376]\n",
      "epoch:27 step:26150 [D loss: 0.661295, acc.: 59.38%] [G loss: 0.920865]\n",
      "epoch:27 step:26151 [D loss: 0.630525, acc.: 67.97%] [G loss: 0.887115]\n",
      "epoch:27 step:26152 [D loss: 0.650505, acc.: 62.50%] [G loss: 0.955070]\n",
      "epoch:27 step:26153 [D loss: 0.626071, acc.: 68.75%] [G loss: 0.896946]\n",
      "epoch:27 step:26154 [D loss: 0.643933, acc.: 61.72%] [G loss: 0.891729]\n",
      "epoch:27 step:26155 [D loss: 0.622858, acc.: 66.41%] [G loss: 0.888872]\n",
      "epoch:27 step:26156 [D loss: 0.695781, acc.: 59.38%] [G loss: 0.905088]\n",
      "epoch:27 step:26157 [D loss: 0.649500, acc.: 63.28%] [G loss: 0.915769]\n",
      "epoch:27 step:26158 [D loss: 0.663704, acc.: 57.81%] [G loss: 0.880563]\n",
      "epoch:27 step:26159 [D loss: 0.639238, acc.: 62.50%] [G loss: 0.925230]\n",
      "epoch:27 step:26160 [D loss: 0.602049, acc.: 67.19%] [G loss: 0.920611]\n",
      "epoch:27 step:26161 [D loss: 0.623456, acc.: 68.75%] [G loss: 0.958943]\n",
      "epoch:27 step:26162 [D loss: 0.641370, acc.: 62.50%] [G loss: 0.909936]\n",
      "epoch:27 step:26163 [D loss: 0.680391, acc.: 53.12%] [G loss: 0.931299]\n",
      "epoch:27 step:26164 [D loss: 0.636891, acc.: 64.06%] [G loss: 0.941736]\n",
      "epoch:27 step:26165 [D loss: 0.642380, acc.: 64.84%] [G loss: 0.963856]\n",
      "epoch:27 step:26166 [D loss: 0.689296, acc.: 55.47%] [G loss: 0.903675]\n",
      "epoch:27 step:26167 [D loss: 0.626798, acc.: 64.06%] [G loss: 0.918926]\n",
      "epoch:27 step:26168 [D loss: 0.640822, acc.: 64.06%] [G loss: 0.913390]\n",
      "epoch:27 step:26169 [D loss: 0.650070, acc.: 60.16%] [G loss: 0.902216]\n",
      "epoch:27 step:26170 [D loss: 0.641762, acc.: 60.94%] [G loss: 0.966370]\n",
      "epoch:27 step:26171 [D loss: 0.702660, acc.: 50.00%] [G loss: 0.938080]\n",
      "epoch:27 step:26172 [D loss: 0.633543, acc.: 65.62%] [G loss: 0.910482]\n",
      "epoch:27 step:26173 [D loss: 0.702656, acc.: 55.47%] [G loss: 0.928413]\n",
      "epoch:27 step:26174 [D loss: 0.655495, acc.: 60.16%] [G loss: 0.975294]\n",
      "epoch:27 step:26175 [D loss: 0.697074, acc.: 52.34%] [G loss: 0.908488]\n",
      "epoch:27 step:26176 [D loss: 0.611120, acc.: 68.75%] [G loss: 0.943375]\n",
      "epoch:27 step:26177 [D loss: 0.639412, acc.: 63.28%] [G loss: 0.923453]\n",
      "epoch:27 step:26178 [D loss: 0.656745, acc.: 62.50%] [G loss: 0.915313]\n",
      "epoch:27 step:26179 [D loss: 0.651680, acc.: 60.16%] [G loss: 0.918236]\n",
      "epoch:27 step:26180 [D loss: 0.685634, acc.: 57.81%] [G loss: 0.932287]\n",
      "epoch:27 step:26181 [D loss: 0.619198, acc.: 70.31%] [G loss: 0.853278]\n",
      "epoch:27 step:26182 [D loss: 0.648482, acc.: 61.72%] [G loss: 0.944691]\n",
      "epoch:27 step:26183 [D loss: 0.643746, acc.: 61.72%] [G loss: 0.924938]\n",
      "epoch:27 step:26184 [D loss: 0.658450, acc.: 59.38%] [G loss: 0.913338]\n",
      "epoch:27 step:26185 [D loss: 0.670861, acc.: 57.81%] [G loss: 0.892084]\n",
      "epoch:27 step:26186 [D loss: 0.622432, acc.: 64.84%] [G loss: 0.914283]\n",
      "epoch:27 step:26187 [D loss: 0.640516, acc.: 64.06%] [G loss: 0.893157]\n",
      "epoch:27 step:26188 [D loss: 0.673076, acc.: 54.69%] [G loss: 0.919905]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:27 step:26189 [D loss: 0.630766, acc.: 66.41%] [G loss: 0.911902]\n",
      "epoch:27 step:26190 [D loss: 0.687733, acc.: 54.69%] [G loss: 0.925059]\n",
      "epoch:27 step:26191 [D loss: 0.679629, acc.: 60.94%] [G loss: 0.915389]\n",
      "epoch:27 step:26192 [D loss: 0.674574, acc.: 60.16%] [G loss: 0.893543]\n",
      "epoch:27 step:26193 [D loss: 0.663079, acc.: 58.59%] [G loss: 0.923293]\n",
      "epoch:27 step:26194 [D loss: 0.638122, acc.: 64.06%] [G loss: 0.886958]\n",
      "epoch:27 step:26195 [D loss: 0.645589, acc.: 62.50%] [G loss: 0.882017]\n",
      "epoch:27 step:26196 [D loss: 0.636628, acc.: 66.41%] [G loss: 0.855251]\n",
      "epoch:27 step:26197 [D loss: 0.654728, acc.: 53.12%] [G loss: 0.866689]\n",
      "epoch:27 step:26198 [D loss: 0.667534, acc.: 57.03%] [G loss: 0.913416]\n",
      "epoch:27 step:26199 [D loss: 0.660466, acc.: 60.16%] [G loss: 0.943168]\n",
      "epoch:27 step:26200 [D loss: 0.674681, acc.: 57.03%] [G loss: 0.992180]\n",
      "##############\n",
      "[2.85609741 2.36833668 2.4944652  3.92437729 1.09876988 8.01213052\n",
      " 2.66485801 2.61099974 4.11770629 8.14868929]\n",
      "##########\n",
      "epoch:27 step:26201 [D loss: 0.650858, acc.: 60.94%] [G loss: 0.944434]\n",
      "epoch:27 step:26202 [D loss: 0.641267, acc.: 66.41%] [G loss: 0.921338]\n",
      "epoch:27 step:26203 [D loss: 0.619061, acc.: 68.75%] [G loss: 0.940458]\n",
      "epoch:27 step:26204 [D loss: 0.684099, acc.: 51.56%] [G loss: 0.945613]\n",
      "epoch:27 step:26205 [D loss: 0.620770, acc.: 64.84%] [G loss: 0.934877]\n",
      "epoch:27 step:26206 [D loss: 0.672895, acc.: 57.81%] [G loss: 0.981227]\n",
      "epoch:27 step:26207 [D loss: 0.675535, acc.: 55.47%] [G loss: 0.964291]\n",
      "epoch:27 step:26208 [D loss: 0.672225, acc.: 53.91%] [G loss: 0.914988]\n",
      "epoch:27 step:26209 [D loss: 0.658252, acc.: 60.94%] [G loss: 0.977975]\n",
      "epoch:27 step:26210 [D loss: 0.641342, acc.: 65.62%] [G loss: 1.010394]\n",
      "epoch:27 step:26211 [D loss: 0.667555, acc.: 58.59%] [G loss: 0.909420]\n",
      "epoch:27 step:26212 [D loss: 0.644068, acc.: 60.94%] [G loss: 0.879921]\n",
      "epoch:27 step:26213 [D loss: 0.651224, acc.: 64.84%] [G loss: 0.856658]\n",
      "epoch:27 step:26214 [D loss: 0.672381, acc.: 58.59%] [G loss: 0.839435]\n",
      "epoch:27 step:26215 [D loss: 0.687452, acc.: 59.38%] [G loss: 0.908566]\n",
      "epoch:27 step:26216 [D loss: 0.636658, acc.: 62.50%] [G loss: 0.922522]\n",
      "epoch:27 step:26217 [D loss: 0.663110, acc.: 57.81%] [G loss: 0.897074]\n",
      "epoch:27 step:26218 [D loss: 0.687784, acc.: 56.25%] [G loss: 0.881749]\n",
      "epoch:27 step:26219 [D loss: 0.608586, acc.: 65.62%] [G loss: 0.899948]\n",
      "epoch:27 step:26220 [D loss: 0.689945, acc.: 53.91%] [G loss: 0.894355]\n",
      "epoch:27 step:26221 [D loss: 0.640730, acc.: 58.59%] [G loss: 0.873284]\n",
      "epoch:27 step:26222 [D loss: 0.673911, acc.: 55.47%] [G loss: 0.879035]\n",
      "epoch:27 step:26223 [D loss: 0.639461, acc.: 64.84%] [G loss: 0.858527]\n",
      "epoch:27 step:26224 [D loss: 0.643284, acc.: 62.50%] [G loss: 0.938165]\n",
      "epoch:27 step:26225 [D loss: 0.637271, acc.: 64.84%] [G loss: 0.887249]\n",
      "epoch:27 step:26226 [D loss: 0.683270, acc.: 56.25%] [G loss: 0.900605]\n",
      "epoch:27 step:26227 [D loss: 0.665342, acc.: 56.25%] [G loss: 0.901075]\n",
      "epoch:27 step:26228 [D loss: 0.684894, acc.: 55.47%] [G loss: 0.859117]\n",
      "epoch:27 step:26229 [D loss: 0.679915, acc.: 53.12%] [G loss: 0.887520]\n",
      "epoch:27 step:26230 [D loss: 0.652581, acc.: 63.28%] [G loss: 0.837719]\n",
      "epoch:27 step:26231 [D loss: 0.630993, acc.: 62.50%] [G loss: 0.854775]\n",
      "epoch:27 step:26232 [D loss: 0.685577, acc.: 55.47%] [G loss: 0.919036]\n",
      "epoch:27 step:26233 [D loss: 0.608636, acc.: 72.66%] [G loss: 0.872785]\n",
      "epoch:27 step:26234 [D loss: 0.674772, acc.: 54.69%] [G loss: 0.923814]\n",
      "epoch:27 step:26235 [D loss: 0.682050, acc.: 57.03%] [G loss: 0.893888]\n",
      "epoch:27 step:26236 [D loss: 0.674500, acc.: 52.34%] [G loss: 0.872916]\n",
      "epoch:28 step:26237 [D loss: 0.686810, acc.: 50.00%] [G loss: 0.907968]\n",
      "epoch:28 step:26238 [D loss: 0.642099, acc.: 65.62%] [G loss: 0.868106]\n",
      "epoch:28 step:26239 [D loss: 0.633300, acc.: 60.16%] [G loss: 0.914014]\n",
      "epoch:28 step:26240 [D loss: 0.647704, acc.: 64.06%] [G loss: 0.909629]\n",
      "epoch:28 step:26241 [D loss: 0.663303, acc.: 58.59%] [G loss: 0.923210]\n",
      "epoch:28 step:26242 [D loss: 0.669322, acc.: 60.16%] [G loss: 0.858747]\n",
      "epoch:28 step:26243 [D loss: 0.682350, acc.: 56.25%] [G loss: 0.869762]\n",
      "epoch:28 step:26244 [D loss: 0.674667, acc.: 56.25%] [G loss: 0.906933]\n",
      "epoch:28 step:26245 [D loss: 0.674244, acc.: 55.47%] [G loss: 0.824476]\n",
      "epoch:28 step:26246 [D loss: 0.640927, acc.: 61.72%] [G loss: 0.841869]\n",
      "epoch:28 step:26247 [D loss: 0.661977, acc.: 64.06%] [G loss: 0.909130]\n",
      "epoch:28 step:26248 [D loss: 0.651726, acc.: 60.94%] [G loss: 0.878693]\n",
      "epoch:28 step:26249 [D loss: 0.625249, acc.: 62.50%] [G loss: 0.931519]\n",
      "epoch:28 step:26250 [D loss: 0.647261, acc.: 64.84%] [G loss: 0.856001]\n",
      "epoch:28 step:26251 [D loss: 0.690816, acc.: 56.25%] [G loss: 0.883801]\n",
      "epoch:28 step:26252 [D loss: 0.625500, acc.: 64.84%] [G loss: 0.947682]\n",
      "epoch:28 step:26253 [D loss: 0.644829, acc.: 61.72%] [G loss: 0.886737]\n",
      "epoch:28 step:26254 [D loss: 0.624130, acc.: 66.41%] [G loss: 0.903939]\n",
      "epoch:28 step:26255 [D loss: 0.663516, acc.: 61.72%] [G loss: 0.910115]\n",
      "epoch:28 step:26256 [D loss: 0.660831, acc.: 56.25%] [G loss: 0.931235]\n",
      "epoch:28 step:26257 [D loss: 0.643568, acc.: 59.38%] [G loss: 0.917020]\n",
      "epoch:28 step:26258 [D loss: 0.644712, acc.: 59.38%] [G loss: 0.906953]\n",
      "epoch:28 step:26259 [D loss: 0.652450, acc.: 59.38%] [G loss: 0.925539]\n",
      "epoch:28 step:26260 [D loss: 0.647403, acc.: 60.16%] [G loss: 0.917179]\n",
      "epoch:28 step:26261 [D loss: 0.621801, acc.: 66.41%] [G loss: 0.906867]\n",
      "epoch:28 step:26262 [D loss: 0.635057, acc.: 64.84%] [G loss: 0.891393]\n",
      "epoch:28 step:26263 [D loss: 0.623131, acc.: 64.84%] [G loss: 0.882729]\n",
      "epoch:28 step:26264 [D loss: 0.651212, acc.: 62.50%] [G loss: 0.879550]\n",
      "epoch:28 step:26265 [D loss: 0.695943, acc.: 56.25%] [G loss: 0.943653]\n",
      "epoch:28 step:26266 [D loss: 0.659603, acc.: 57.81%] [G loss: 0.879816]\n",
      "epoch:28 step:26267 [D loss: 0.621082, acc.: 71.09%] [G loss: 0.951685]\n",
      "epoch:28 step:26268 [D loss: 0.674895, acc.: 58.59%] [G loss: 0.890974]\n",
      "epoch:28 step:26269 [D loss: 0.650730, acc.: 54.69%] [G loss: 0.853602]\n",
      "epoch:28 step:26270 [D loss: 0.686312, acc.: 55.47%] [G loss: 0.922544]\n",
      "epoch:28 step:26271 [D loss: 0.665394, acc.: 54.69%] [G loss: 0.894223]\n",
      "epoch:28 step:26272 [D loss: 0.611543, acc.: 67.19%] [G loss: 0.888966]\n",
      "epoch:28 step:26273 [D loss: 0.671515, acc.: 58.59%] [G loss: 0.877175]\n",
      "epoch:28 step:26274 [D loss: 0.650290, acc.: 61.72%] [G loss: 0.887839]\n",
      "epoch:28 step:26275 [D loss: 0.647464, acc.: 62.50%] [G loss: 0.876640]\n",
      "epoch:28 step:26276 [D loss: 0.664642, acc.: 60.16%] [G loss: 0.878246]\n",
      "epoch:28 step:26277 [D loss: 0.679360, acc.: 53.12%] [G loss: 0.868488]\n",
      "epoch:28 step:26278 [D loss: 0.668546, acc.: 58.59%] [G loss: 0.900518]\n",
      "epoch:28 step:26279 [D loss: 0.629381, acc.: 64.06%] [G loss: 0.883850]\n",
      "epoch:28 step:26280 [D loss: 0.613337, acc.: 62.50%] [G loss: 0.814703]\n",
      "epoch:28 step:26281 [D loss: 0.684237, acc.: 59.38%] [G loss: 0.849607]\n",
      "epoch:28 step:26282 [D loss: 0.655241, acc.: 59.38%] [G loss: 0.925765]\n",
      "epoch:28 step:26283 [D loss: 0.669851, acc.: 60.94%] [G loss: 0.842511]\n",
      "epoch:28 step:26284 [D loss: 0.632798, acc.: 64.84%] [G loss: 0.867858]\n",
      "epoch:28 step:26285 [D loss: 0.682314, acc.: 61.72%] [G loss: 0.899260]\n",
      "epoch:28 step:26286 [D loss: 0.645897, acc.: 63.28%] [G loss: 0.938089]\n",
      "epoch:28 step:26287 [D loss: 0.652854, acc.: 60.16%] [G loss: 0.863039]\n",
      "epoch:28 step:26288 [D loss: 0.620309, acc.: 64.06%] [G loss: 0.876825]\n",
      "epoch:28 step:26289 [D loss: 0.644840, acc.: 66.41%] [G loss: 0.944477]\n",
      "epoch:28 step:26290 [D loss: 0.689198, acc.: 57.03%] [G loss: 0.927536]\n",
      "epoch:28 step:26291 [D loss: 0.677291, acc.: 58.59%] [G loss: 0.908003]\n",
      "epoch:28 step:26292 [D loss: 0.656183, acc.: 58.59%] [G loss: 0.900366]\n",
      "epoch:28 step:26293 [D loss: 0.695607, acc.: 58.59%] [G loss: 0.915264]\n",
      "epoch:28 step:26294 [D loss: 0.646957, acc.: 64.84%] [G loss: 0.875017]\n",
      "epoch:28 step:26295 [D loss: 0.605026, acc.: 65.62%] [G loss: 0.849983]\n",
      "epoch:28 step:26296 [D loss: 0.635569, acc.: 62.50%] [G loss: 0.953233]\n",
      "epoch:28 step:26297 [D loss: 0.670274, acc.: 56.25%] [G loss: 0.911948]\n",
      "epoch:28 step:26298 [D loss: 0.652118, acc.: 55.47%] [G loss: 0.896378]\n",
      "epoch:28 step:26299 [D loss: 0.625566, acc.: 67.97%] [G loss: 0.935812]\n",
      "epoch:28 step:26300 [D loss: 0.656660, acc.: 57.03%] [G loss: 0.871614]\n",
      "epoch:28 step:26301 [D loss: 0.673908, acc.: 58.59%] [G loss: 0.938571]\n",
      "epoch:28 step:26302 [D loss: 0.645352, acc.: 64.06%] [G loss: 0.904060]\n",
      "epoch:28 step:26303 [D loss: 0.667949, acc.: 53.91%] [G loss: 0.892704]\n",
      "epoch:28 step:26304 [D loss: 0.683852, acc.: 53.12%] [G loss: 0.828321]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26305 [D loss: 0.654843, acc.: 57.81%] [G loss: 0.919116]\n",
      "epoch:28 step:26306 [D loss: 0.667058, acc.: 64.84%] [G loss: 0.979863]\n",
      "epoch:28 step:26307 [D loss: 0.659257, acc.: 63.28%] [G loss: 0.929183]\n",
      "epoch:28 step:26308 [D loss: 0.664478, acc.: 63.28%] [G loss: 0.921908]\n",
      "epoch:28 step:26309 [D loss: 0.604131, acc.: 67.97%] [G loss: 0.952642]\n",
      "epoch:28 step:26310 [D loss: 0.667412, acc.: 60.94%] [G loss: 0.877885]\n",
      "epoch:28 step:26311 [D loss: 0.655370, acc.: 60.16%] [G loss: 0.928734]\n",
      "epoch:28 step:26312 [D loss: 0.649574, acc.: 60.94%] [G loss: 0.956978]\n",
      "epoch:28 step:26313 [D loss: 0.662773, acc.: 55.47%] [G loss: 0.874668]\n",
      "epoch:28 step:26314 [D loss: 0.670618, acc.: 60.94%] [G loss: 0.872988]\n",
      "epoch:28 step:26315 [D loss: 0.686047, acc.: 59.38%] [G loss: 0.864879]\n",
      "epoch:28 step:26316 [D loss: 0.651800, acc.: 65.62%] [G loss: 0.986316]\n",
      "epoch:28 step:26317 [D loss: 0.674173, acc.: 53.91%] [G loss: 0.911073]\n",
      "epoch:28 step:26318 [D loss: 0.646791, acc.: 58.59%] [G loss: 0.892803]\n",
      "epoch:28 step:26319 [D loss: 0.658939, acc.: 60.94%] [G loss: 0.915809]\n",
      "epoch:28 step:26320 [D loss: 0.651952, acc.: 63.28%] [G loss: 0.949004]\n",
      "epoch:28 step:26321 [D loss: 0.631737, acc.: 57.81%] [G loss: 0.891436]\n",
      "epoch:28 step:26322 [D loss: 0.688400, acc.: 60.16%] [G loss: 0.864016]\n",
      "epoch:28 step:26323 [D loss: 0.663487, acc.: 62.50%] [G loss: 0.890357]\n",
      "epoch:28 step:26324 [D loss: 0.633055, acc.: 65.62%] [G loss: 0.841989]\n",
      "epoch:28 step:26325 [D loss: 0.663834, acc.: 64.84%] [G loss: 0.905549]\n",
      "epoch:28 step:26326 [D loss: 0.647759, acc.: 59.38%] [G loss: 0.903037]\n",
      "epoch:28 step:26327 [D loss: 0.683273, acc.: 60.16%] [G loss: 0.861412]\n",
      "epoch:28 step:26328 [D loss: 0.663395, acc.: 62.50%] [G loss: 0.923129]\n",
      "epoch:28 step:26329 [D loss: 0.672707, acc.: 57.81%] [G loss: 0.905092]\n",
      "epoch:28 step:26330 [D loss: 0.659260, acc.: 55.47%] [G loss: 0.884506]\n",
      "epoch:28 step:26331 [D loss: 0.673603, acc.: 55.47%] [G loss: 0.883434]\n",
      "epoch:28 step:26332 [D loss: 0.660790, acc.: 61.72%] [G loss: 0.857003]\n",
      "epoch:28 step:26333 [D loss: 0.645582, acc.: 63.28%] [G loss: 0.886910]\n",
      "epoch:28 step:26334 [D loss: 0.646491, acc.: 59.38%] [G loss: 0.875139]\n",
      "epoch:28 step:26335 [D loss: 0.676929, acc.: 62.50%] [G loss: 0.875210]\n",
      "epoch:28 step:26336 [D loss: 0.657394, acc.: 59.38%] [G loss: 0.932768]\n",
      "epoch:28 step:26337 [D loss: 0.648051, acc.: 60.16%] [G loss: 0.889064]\n",
      "epoch:28 step:26338 [D loss: 0.701118, acc.: 59.38%] [G loss: 0.890387]\n",
      "epoch:28 step:26339 [D loss: 0.604198, acc.: 66.41%] [G loss: 0.957301]\n",
      "epoch:28 step:26340 [D loss: 0.658778, acc.: 60.94%] [G loss: 0.906272]\n",
      "epoch:28 step:26341 [D loss: 0.638483, acc.: 60.94%] [G loss: 0.962070]\n",
      "epoch:28 step:26342 [D loss: 0.634140, acc.: 67.97%] [G loss: 0.908151]\n",
      "epoch:28 step:26343 [D loss: 0.631783, acc.: 66.41%] [G loss: 0.934230]\n",
      "epoch:28 step:26344 [D loss: 0.698085, acc.: 50.78%] [G loss: 0.879883]\n",
      "epoch:28 step:26345 [D loss: 0.636378, acc.: 70.31%] [G loss: 0.824975]\n",
      "epoch:28 step:26346 [D loss: 0.648568, acc.: 62.50%] [G loss: 0.939441]\n",
      "epoch:28 step:26347 [D loss: 0.697689, acc.: 55.47%] [G loss: 0.893343]\n",
      "epoch:28 step:26348 [D loss: 0.657466, acc.: 61.72%] [G loss: 0.923693]\n",
      "epoch:28 step:26349 [D loss: 0.657725, acc.: 59.38%] [G loss: 0.971502]\n",
      "epoch:28 step:26350 [D loss: 0.680567, acc.: 61.72%] [G loss: 0.875584]\n",
      "epoch:28 step:26351 [D loss: 0.652091, acc.: 63.28%] [G loss: 0.899840]\n",
      "epoch:28 step:26352 [D loss: 0.642303, acc.: 67.97%] [G loss: 0.922641]\n",
      "epoch:28 step:26353 [D loss: 0.679441, acc.: 53.91%] [G loss: 0.875795]\n",
      "epoch:28 step:26354 [D loss: 0.661674, acc.: 57.81%] [G loss: 0.827683]\n",
      "epoch:28 step:26355 [D loss: 0.660268, acc.: 56.25%] [G loss: 0.936916]\n",
      "epoch:28 step:26356 [D loss: 0.657752, acc.: 62.50%] [G loss: 0.926720]\n",
      "epoch:28 step:26357 [D loss: 0.646912, acc.: 64.06%] [G loss: 0.845359]\n",
      "epoch:28 step:26358 [D loss: 0.625815, acc.: 67.19%] [G loss: 0.886423]\n",
      "epoch:28 step:26359 [D loss: 0.683972, acc.: 60.16%] [G loss: 0.908486]\n",
      "epoch:28 step:26360 [D loss: 0.658187, acc.: 63.28%] [G loss: 0.876741]\n",
      "epoch:28 step:26361 [D loss: 0.614630, acc.: 62.50%] [G loss: 0.897229]\n",
      "epoch:28 step:26362 [D loss: 0.664836, acc.: 63.28%] [G loss: 0.951537]\n",
      "epoch:28 step:26363 [D loss: 0.642002, acc.: 67.19%] [G loss: 1.015993]\n",
      "epoch:28 step:26364 [D loss: 0.683056, acc.: 54.69%] [G loss: 0.924458]\n",
      "epoch:28 step:26365 [D loss: 0.616049, acc.: 64.84%] [G loss: 0.970707]\n",
      "epoch:28 step:26366 [D loss: 0.657671, acc.: 61.72%] [G loss: 0.879577]\n",
      "epoch:28 step:26367 [D loss: 0.652789, acc.: 60.16%] [G loss: 0.869923]\n",
      "epoch:28 step:26368 [D loss: 0.707602, acc.: 50.00%] [G loss: 0.964494]\n",
      "epoch:28 step:26369 [D loss: 0.660155, acc.: 59.38%] [G loss: 0.942647]\n",
      "epoch:28 step:26370 [D loss: 0.679930, acc.: 53.91%] [G loss: 0.915345]\n",
      "epoch:28 step:26371 [D loss: 0.674284, acc.: 56.25%] [G loss: 0.940871]\n",
      "epoch:28 step:26372 [D loss: 0.658035, acc.: 59.38%] [G loss: 0.897436]\n",
      "epoch:28 step:26373 [D loss: 0.666770, acc.: 60.16%] [G loss: 0.891606]\n",
      "epoch:28 step:26374 [D loss: 0.640321, acc.: 58.59%] [G loss: 0.911398]\n",
      "epoch:28 step:26375 [D loss: 0.664671, acc.: 62.50%] [G loss: 0.870023]\n",
      "epoch:28 step:26376 [D loss: 0.681993, acc.: 53.91%] [G loss: 0.905781]\n",
      "epoch:28 step:26377 [D loss: 0.656206, acc.: 58.59%] [G loss: 0.910150]\n",
      "epoch:28 step:26378 [D loss: 0.655715, acc.: 57.03%] [G loss: 0.832549]\n",
      "epoch:28 step:26379 [D loss: 0.659414, acc.: 56.25%] [G loss: 0.882376]\n",
      "epoch:28 step:26380 [D loss: 0.643669, acc.: 63.28%] [G loss: 0.890757]\n",
      "epoch:28 step:26381 [D loss: 0.664315, acc.: 57.81%] [G loss: 0.934530]\n",
      "epoch:28 step:26382 [D loss: 0.625598, acc.: 67.97%] [G loss: 0.880704]\n",
      "epoch:28 step:26383 [D loss: 0.659585, acc.: 58.59%] [G loss: 0.962033]\n",
      "epoch:28 step:26384 [D loss: 0.656057, acc.: 60.94%] [G loss: 0.914289]\n",
      "epoch:28 step:26385 [D loss: 0.662242, acc.: 54.69%] [G loss: 0.946770]\n",
      "epoch:28 step:26386 [D loss: 0.658945, acc.: 60.16%] [G loss: 0.909124]\n",
      "epoch:28 step:26387 [D loss: 0.647323, acc.: 59.38%] [G loss: 0.921010]\n",
      "epoch:28 step:26388 [D loss: 0.719775, acc.: 50.00%] [G loss: 0.877984]\n",
      "epoch:28 step:26389 [D loss: 0.644248, acc.: 61.72%] [G loss: 0.898576]\n",
      "epoch:28 step:26390 [D loss: 0.645256, acc.: 60.94%] [G loss: 0.927250]\n",
      "epoch:28 step:26391 [D loss: 0.686821, acc.: 57.03%] [G loss: 0.975057]\n",
      "epoch:28 step:26392 [D loss: 0.625545, acc.: 67.97%] [G loss: 0.913243]\n",
      "epoch:28 step:26393 [D loss: 0.634678, acc.: 61.72%] [G loss: 0.984656]\n",
      "epoch:28 step:26394 [D loss: 0.611411, acc.: 69.53%] [G loss: 0.893853]\n",
      "epoch:28 step:26395 [D loss: 0.629272, acc.: 67.19%] [G loss: 0.960513]\n",
      "epoch:28 step:26396 [D loss: 0.616456, acc.: 70.31%] [G loss: 0.923249]\n",
      "epoch:28 step:26397 [D loss: 0.634468, acc.: 64.06%] [G loss: 0.897129]\n",
      "epoch:28 step:26398 [D loss: 0.660638, acc.: 59.38%] [G loss: 0.918972]\n",
      "epoch:28 step:26399 [D loss: 0.632195, acc.: 70.31%] [G loss: 0.988393]\n",
      "epoch:28 step:26400 [D loss: 0.666750, acc.: 58.59%] [G loss: 0.954922]\n",
      "##############\n",
      "[2.97046886 2.41382432 1.94482783 4.03857392 1.37233066 9.27426719\n",
      " 2.70913658 3.26770492 4.26239251 8.14868929]\n",
      "##########\n",
      "epoch:28 step:26401 [D loss: 0.636744, acc.: 63.28%] [G loss: 0.867476]\n",
      "epoch:28 step:26402 [D loss: 0.700300, acc.: 58.59%] [G loss: 0.910627]\n",
      "epoch:28 step:26403 [D loss: 0.620888, acc.: 60.16%] [G loss: 0.923226]\n",
      "epoch:28 step:26404 [D loss: 0.637384, acc.: 57.81%] [G loss: 0.921837]\n",
      "epoch:28 step:26405 [D loss: 0.681963, acc.: 58.59%] [G loss: 0.878044]\n",
      "epoch:28 step:26406 [D loss: 0.636908, acc.: 61.72%] [G loss: 0.930351]\n",
      "epoch:28 step:26407 [D loss: 0.661600, acc.: 65.62%] [G loss: 0.865285]\n",
      "epoch:28 step:26408 [D loss: 0.686491, acc.: 51.56%] [G loss: 0.907355]\n",
      "epoch:28 step:26409 [D loss: 0.653202, acc.: 59.38%] [G loss: 0.878599]\n",
      "epoch:28 step:26410 [D loss: 0.622116, acc.: 62.50%] [G loss: 0.907373]\n",
      "epoch:28 step:26411 [D loss: 0.652988, acc.: 61.72%] [G loss: 0.912253]\n",
      "epoch:28 step:26412 [D loss: 0.619209, acc.: 68.75%] [G loss: 0.915585]\n",
      "epoch:28 step:26413 [D loss: 0.628479, acc.: 64.06%] [G loss: 0.866894]\n",
      "epoch:28 step:26414 [D loss: 0.684653, acc.: 53.12%] [G loss: 0.903023]\n",
      "epoch:28 step:26415 [D loss: 0.627071, acc.: 64.84%] [G loss: 0.926375]\n",
      "epoch:28 step:26416 [D loss: 0.568491, acc.: 73.44%] [G loss: 0.890940]\n",
      "epoch:28 step:26417 [D loss: 0.644017, acc.: 65.62%] [G loss: 0.837925]\n",
      "epoch:28 step:26418 [D loss: 0.645630, acc.: 63.28%] [G loss: 0.892206]\n",
      "epoch:28 step:26419 [D loss: 0.647291, acc.: 62.50%] [G loss: 0.909241]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26420 [D loss: 0.660648, acc.: 57.81%] [G loss: 0.853313]\n",
      "epoch:28 step:26421 [D loss: 0.661234, acc.: 60.94%] [G loss: 0.851144]\n",
      "epoch:28 step:26422 [D loss: 0.629032, acc.: 68.75%] [G loss: 0.920287]\n",
      "epoch:28 step:26423 [D loss: 0.618176, acc.: 67.19%] [G loss: 0.940435]\n",
      "epoch:28 step:26424 [D loss: 0.655922, acc.: 63.28%] [G loss: 0.977396]\n",
      "epoch:28 step:26425 [D loss: 0.659625, acc.: 64.06%] [G loss: 0.924991]\n",
      "epoch:28 step:26426 [D loss: 0.681902, acc.: 54.69%] [G loss: 0.936812]\n",
      "epoch:28 step:26427 [D loss: 0.653176, acc.: 58.59%] [G loss: 0.967827]\n",
      "epoch:28 step:26428 [D loss: 0.627737, acc.: 67.19%] [G loss: 0.978715]\n",
      "epoch:28 step:26429 [D loss: 0.580104, acc.: 71.09%] [G loss: 0.935000]\n",
      "epoch:28 step:26430 [D loss: 0.687768, acc.: 58.59%] [G loss: 0.881750]\n",
      "epoch:28 step:26431 [D loss: 0.624789, acc.: 65.62%] [G loss: 0.914099]\n",
      "epoch:28 step:26432 [D loss: 0.702928, acc.: 53.91%] [G loss: 0.879949]\n",
      "epoch:28 step:26433 [D loss: 0.595715, acc.: 71.09%] [G loss: 0.924430]\n",
      "epoch:28 step:26434 [D loss: 0.610700, acc.: 67.97%] [G loss: 0.910406]\n",
      "epoch:28 step:26435 [D loss: 0.642641, acc.: 62.50%] [G loss: 0.987285]\n",
      "epoch:28 step:26436 [D loss: 0.642825, acc.: 64.06%] [G loss: 0.976317]\n",
      "epoch:28 step:26437 [D loss: 0.648887, acc.: 60.94%] [G loss: 0.978204]\n",
      "epoch:28 step:26438 [D loss: 0.601641, acc.: 72.66%] [G loss: 0.984272]\n",
      "epoch:28 step:26439 [D loss: 0.680556, acc.: 57.03%] [G loss: 0.939762]\n",
      "epoch:28 step:26440 [D loss: 0.656326, acc.: 59.38%] [G loss: 0.974798]\n",
      "epoch:28 step:26441 [D loss: 0.664978, acc.: 61.72%] [G loss: 0.912091]\n",
      "epoch:28 step:26442 [D loss: 0.711439, acc.: 53.91%] [G loss: 0.874781]\n",
      "epoch:28 step:26443 [D loss: 0.626567, acc.: 64.06%] [G loss: 0.876204]\n",
      "epoch:28 step:26444 [D loss: 0.647196, acc.: 62.50%] [G loss: 0.931550]\n",
      "epoch:28 step:26445 [D loss: 0.655837, acc.: 59.38%] [G loss: 0.900943]\n",
      "epoch:28 step:26446 [D loss: 0.694087, acc.: 54.69%] [G loss: 0.937175]\n",
      "epoch:28 step:26447 [D loss: 0.676587, acc.: 57.03%] [G loss: 0.914662]\n",
      "epoch:28 step:26448 [D loss: 0.663682, acc.: 59.38%] [G loss: 0.915298]\n",
      "epoch:28 step:26449 [D loss: 0.694570, acc.: 56.25%] [G loss: 0.879338]\n",
      "epoch:28 step:26450 [D loss: 0.647357, acc.: 57.81%] [G loss: 0.878539]\n",
      "epoch:28 step:26451 [D loss: 0.678601, acc.: 57.81%] [G loss: 0.935663]\n",
      "epoch:28 step:26452 [D loss: 0.664279, acc.: 53.91%] [G loss: 0.899491]\n",
      "epoch:28 step:26453 [D loss: 0.620558, acc.: 63.28%] [G loss: 0.922654]\n",
      "epoch:28 step:26454 [D loss: 0.677027, acc.: 56.25%] [G loss: 0.902330]\n",
      "epoch:28 step:26455 [D loss: 0.691949, acc.: 54.69%] [G loss: 0.865844]\n",
      "epoch:28 step:26456 [D loss: 0.674418, acc.: 57.03%] [G loss: 0.855702]\n",
      "epoch:28 step:26457 [D loss: 0.645857, acc.: 58.59%] [G loss: 0.832123]\n",
      "epoch:28 step:26458 [D loss: 0.724565, acc.: 51.56%] [G loss: 0.841962]\n",
      "epoch:28 step:26459 [D loss: 0.672205, acc.: 58.59%] [G loss: 0.872899]\n",
      "epoch:28 step:26460 [D loss: 0.640120, acc.: 63.28%] [G loss: 0.834705]\n",
      "epoch:28 step:26461 [D loss: 0.639679, acc.: 61.72%] [G loss: 0.849022]\n",
      "epoch:28 step:26462 [D loss: 0.622393, acc.: 65.62%] [G loss: 0.909637]\n",
      "epoch:28 step:26463 [D loss: 0.674361, acc.: 61.72%] [G loss: 0.936474]\n",
      "epoch:28 step:26464 [D loss: 0.643601, acc.: 64.06%] [G loss: 0.837372]\n",
      "epoch:28 step:26465 [D loss: 0.653072, acc.: 60.94%] [G loss: 0.852354]\n",
      "epoch:28 step:26466 [D loss: 0.689874, acc.: 57.03%] [G loss: 0.876186]\n",
      "epoch:28 step:26467 [D loss: 0.683146, acc.: 57.03%] [G loss: 0.906992]\n",
      "epoch:28 step:26468 [D loss: 0.672258, acc.: 59.38%] [G loss: 0.888873]\n",
      "epoch:28 step:26469 [D loss: 0.639915, acc.: 64.06%] [G loss: 0.902436]\n",
      "epoch:28 step:26470 [D loss: 0.643447, acc.: 62.50%] [G loss: 0.903183]\n",
      "epoch:28 step:26471 [D loss: 0.656214, acc.: 63.28%] [G loss: 0.912207]\n",
      "epoch:28 step:26472 [D loss: 0.631926, acc.: 64.06%] [G loss: 0.878789]\n",
      "epoch:28 step:26473 [D loss: 0.667814, acc.: 59.38%] [G loss: 0.897574]\n",
      "epoch:28 step:26474 [D loss: 0.653479, acc.: 61.72%] [G loss: 0.879893]\n",
      "epoch:28 step:26475 [D loss: 0.681660, acc.: 58.59%] [G loss: 0.869133]\n",
      "epoch:28 step:26476 [D loss: 0.660379, acc.: 63.28%] [G loss: 0.888475]\n",
      "epoch:28 step:26477 [D loss: 0.650045, acc.: 62.50%] [G loss: 0.901525]\n",
      "epoch:28 step:26478 [D loss: 0.648045, acc.: 59.38%] [G loss: 0.901982]\n",
      "epoch:28 step:26479 [D loss: 0.649815, acc.: 60.94%] [G loss: 0.898982]\n",
      "epoch:28 step:26480 [D loss: 0.692101, acc.: 53.91%] [G loss: 0.857253]\n",
      "epoch:28 step:26481 [D loss: 0.684565, acc.: 50.00%] [G loss: 0.872239]\n",
      "epoch:28 step:26482 [D loss: 0.653652, acc.: 64.84%] [G loss: 0.898436]\n",
      "epoch:28 step:26483 [D loss: 0.684841, acc.: 54.69%] [G loss: 0.880468]\n",
      "epoch:28 step:26484 [D loss: 0.669668, acc.: 53.91%] [G loss: 0.861946]\n",
      "epoch:28 step:26485 [D loss: 0.658022, acc.: 60.94%] [G loss: 0.894759]\n",
      "epoch:28 step:26486 [D loss: 0.658319, acc.: 60.16%] [G loss: 0.915892]\n",
      "epoch:28 step:26487 [D loss: 0.632843, acc.: 64.06%] [G loss: 0.862266]\n",
      "epoch:28 step:26488 [D loss: 0.645657, acc.: 59.38%] [G loss: 0.858384]\n",
      "epoch:28 step:26489 [D loss: 0.670112, acc.: 57.81%] [G loss: 0.884399]\n",
      "epoch:28 step:26490 [D loss: 0.691155, acc.: 59.38%] [G loss: 0.896498]\n",
      "epoch:28 step:26491 [D loss: 0.654657, acc.: 59.38%] [G loss: 0.907094]\n",
      "epoch:28 step:26492 [D loss: 0.676452, acc.: 53.12%] [G loss: 0.895259]\n",
      "epoch:28 step:26493 [D loss: 0.633132, acc.: 62.50%] [G loss: 0.877063]\n",
      "epoch:28 step:26494 [D loss: 0.669626, acc.: 57.03%] [G loss: 0.892920]\n",
      "epoch:28 step:26495 [D loss: 0.657532, acc.: 57.81%] [G loss: 0.831552]\n",
      "epoch:28 step:26496 [D loss: 0.629893, acc.: 66.41%] [G loss: 0.888236]\n",
      "epoch:28 step:26497 [D loss: 0.705002, acc.: 51.56%] [G loss: 0.896944]\n",
      "epoch:28 step:26498 [D loss: 0.679829, acc.: 53.91%] [G loss: 0.949999]\n",
      "epoch:28 step:26499 [D loss: 0.636894, acc.: 60.94%] [G loss: 0.918440]\n",
      "epoch:28 step:26500 [D loss: 0.674938, acc.: 57.81%] [G loss: 0.892005]\n",
      "epoch:28 step:26501 [D loss: 0.644391, acc.: 61.72%] [G loss: 0.884353]\n",
      "epoch:28 step:26502 [D loss: 0.625274, acc.: 65.62%] [G loss: 0.916151]\n",
      "epoch:28 step:26503 [D loss: 0.636208, acc.: 64.84%] [G loss: 0.925952]\n",
      "epoch:28 step:26504 [D loss: 0.643551, acc.: 60.94%] [G loss: 0.924918]\n",
      "epoch:28 step:26505 [D loss: 0.656760, acc.: 57.03%] [G loss: 0.915438]\n",
      "epoch:28 step:26506 [D loss: 0.659062, acc.: 56.25%] [G loss: 0.861777]\n",
      "epoch:28 step:26507 [D loss: 0.611844, acc.: 67.19%] [G loss: 0.895842]\n",
      "epoch:28 step:26508 [D loss: 0.678683, acc.: 53.12%] [G loss: 0.852396]\n",
      "epoch:28 step:26509 [D loss: 0.662994, acc.: 60.16%] [G loss: 0.921393]\n",
      "epoch:28 step:26510 [D loss: 0.661154, acc.: 55.47%] [G loss: 0.885356]\n",
      "epoch:28 step:26511 [D loss: 0.656679, acc.: 62.50%] [G loss: 0.887897]\n",
      "epoch:28 step:26512 [D loss: 0.668749, acc.: 60.16%] [G loss: 0.928391]\n",
      "epoch:28 step:26513 [D loss: 0.654464, acc.: 55.47%] [G loss: 0.946063]\n",
      "epoch:28 step:26514 [D loss: 0.704400, acc.: 57.03%] [G loss: 0.873574]\n",
      "epoch:28 step:26515 [D loss: 0.694110, acc.: 53.12%] [G loss: 0.878363]\n",
      "epoch:28 step:26516 [D loss: 0.683613, acc.: 55.47%] [G loss: 0.888158]\n",
      "epoch:28 step:26517 [D loss: 0.635453, acc.: 62.50%] [G loss: 0.888083]\n",
      "epoch:28 step:26518 [D loss: 0.667902, acc.: 60.16%] [G loss: 0.888111]\n",
      "epoch:28 step:26519 [D loss: 0.632723, acc.: 65.62%] [G loss: 0.889299]\n",
      "epoch:28 step:26520 [D loss: 0.597004, acc.: 71.09%] [G loss: 0.905200]\n",
      "epoch:28 step:26521 [D loss: 0.622820, acc.: 65.62%] [G loss: 0.898972]\n",
      "epoch:28 step:26522 [D loss: 0.634482, acc.: 70.31%] [G loss: 0.928517]\n",
      "epoch:28 step:26523 [D loss: 0.615619, acc.: 66.41%] [G loss: 0.928219]\n",
      "epoch:28 step:26524 [D loss: 0.668967, acc.: 61.72%] [G loss: 0.869057]\n",
      "epoch:28 step:26525 [D loss: 0.700464, acc.: 53.91%] [G loss: 0.817015]\n",
      "epoch:28 step:26526 [D loss: 0.659323, acc.: 62.50%] [G loss: 0.821730]\n",
      "epoch:28 step:26527 [D loss: 0.683956, acc.: 56.25%] [G loss: 0.892479]\n",
      "epoch:28 step:26528 [D loss: 0.676010, acc.: 58.59%] [G loss: 0.894591]\n",
      "epoch:28 step:26529 [D loss: 0.644448, acc.: 60.16%] [G loss: 0.945680]\n",
      "epoch:28 step:26530 [D loss: 0.669501, acc.: 62.50%] [G loss: 0.918707]\n",
      "epoch:28 step:26531 [D loss: 0.671629, acc.: 56.25%] [G loss: 0.885401]\n",
      "epoch:28 step:26532 [D loss: 0.670923, acc.: 58.59%] [G loss: 0.917757]\n",
      "epoch:28 step:26533 [D loss: 0.632018, acc.: 63.28%] [G loss: 0.924083]\n",
      "epoch:28 step:26534 [D loss: 0.656820, acc.: 59.38%] [G loss: 0.966749]\n",
      "epoch:28 step:26535 [D loss: 0.652566, acc.: 59.38%] [G loss: 0.940624]\n",
      "epoch:28 step:26536 [D loss: 0.635760, acc.: 54.69%] [G loss: 0.915829]\n",
      "epoch:28 step:26537 [D loss: 0.666758, acc.: 62.50%] [G loss: 0.852357]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26538 [D loss: 0.643884, acc.: 65.62%] [G loss: 0.885930]\n",
      "epoch:28 step:26539 [D loss: 0.686702, acc.: 51.56%] [G loss: 0.924163]\n",
      "epoch:28 step:26540 [D loss: 0.655013, acc.: 60.94%] [G loss: 0.935389]\n",
      "epoch:28 step:26541 [D loss: 0.661601, acc.: 56.25%] [G loss: 0.928148]\n",
      "epoch:28 step:26542 [D loss: 0.658347, acc.: 62.50%] [G loss: 0.918552]\n",
      "epoch:28 step:26543 [D loss: 0.652197, acc.: 58.59%] [G loss: 0.881498]\n",
      "epoch:28 step:26544 [D loss: 0.659017, acc.: 58.59%] [G loss: 0.823913]\n",
      "epoch:28 step:26545 [D loss: 0.671104, acc.: 58.59%] [G loss: 0.851622]\n",
      "epoch:28 step:26546 [D loss: 0.670114, acc.: 57.81%] [G loss: 0.863834]\n",
      "epoch:28 step:26547 [D loss: 0.646246, acc.: 63.28%] [G loss: 0.835622]\n",
      "epoch:28 step:26548 [D loss: 0.681205, acc.: 59.38%] [G loss: 0.885380]\n",
      "epoch:28 step:26549 [D loss: 0.663552, acc.: 60.94%] [G loss: 0.927261]\n",
      "epoch:28 step:26550 [D loss: 0.631859, acc.: 60.16%] [G loss: 0.911799]\n",
      "epoch:28 step:26551 [D loss: 0.607075, acc.: 68.75%] [G loss: 0.922513]\n",
      "epoch:28 step:26552 [D loss: 0.665102, acc.: 61.72%] [G loss: 0.965918]\n",
      "epoch:28 step:26553 [D loss: 0.644036, acc.: 57.03%] [G loss: 0.990646]\n",
      "epoch:28 step:26554 [D loss: 0.648169, acc.: 59.38%] [G loss: 0.937776]\n",
      "epoch:28 step:26555 [D loss: 0.697367, acc.: 50.78%] [G loss: 0.918572]\n",
      "epoch:28 step:26556 [D loss: 0.631318, acc.: 64.06%] [G loss: 0.999905]\n",
      "epoch:28 step:26557 [D loss: 0.659266, acc.: 61.72%] [G loss: 0.863510]\n",
      "epoch:28 step:26558 [D loss: 0.683712, acc.: 57.03%] [G loss: 0.887723]\n",
      "epoch:28 step:26559 [D loss: 0.652624, acc.: 62.50%] [G loss: 0.901528]\n",
      "epoch:28 step:26560 [D loss: 0.625752, acc.: 57.81%] [G loss: 0.873344]\n",
      "epoch:28 step:26561 [D loss: 0.683786, acc.: 54.69%] [G loss: 0.945969]\n",
      "epoch:28 step:26562 [D loss: 0.709791, acc.: 56.25%] [G loss: 0.861604]\n",
      "epoch:28 step:26563 [D loss: 0.628539, acc.: 64.84%] [G loss: 0.899606]\n",
      "epoch:28 step:26564 [D loss: 0.670774, acc.: 58.59%] [G loss: 0.934491]\n",
      "epoch:28 step:26565 [D loss: 0.664032, acc.: 54.69%] [G loss: 0.939808]\n",
      "epoch:28 step:26566 [D loss: 0.605420, acc.: 63.28%] [G loss: 0.926503]\n",
      "epoch:28 step:26567 [D loss: 0.679958, acc.: 56.25%] [G loss: 0.887671]\n",
      "epoch:28 step:26568 [D loss: 0.631003, acc.: 66.41%] [G loss: 0.907711]\n",
      "epoch:28 step:26569 [D loss: 0.673597, acc.: 59.38%] [G loss: 0.933653]\n",
      "epoch:28 step:26570 [D loss: 0.654756, acc.: 63.28%] [G loss: 0.993074]\n",
      "epoch:28 step:26571 [D loss: 0.667672, acc.: 57.03%] [G loss: 0.950491]\n",
      "epoch:28 step:26572 [D loss: 0.634632, acc.: 62.50%] [G loss: 0.921178]\n",
      "epoch:28 step:26573 [D loss: 0.624784, acc.: 61.72%] [G loss: 0.950690]\n",
      "epoch:28 step:26574 [D loss: 0.625970, acc.: 60.16%] [G loss: 0.929419]\n",
      "epoch:28 step:26575 [D loss: 0.578491, acc.: 75.00%] [G loss: 0.878965]\n",
      "epoch:28 step:26576 [D loss: 0.654446, acc.: 63.28%] [G loss: 0.909906]\n",
      "epoch:28 step:26577 [D loss: 0.649317, acc.: 60.16%] [G loss: 0.951561]\n",
      "epoch:28 step:26578 [D loss: 0.647872, acc.: 60.16%] [G loss: 0.855024]\n",
      "epoch:28 step:26579 [D loss: 0.662234, acc.: 58.59%] [G loss: 0.942272]\n",
      "epoch:28 step:26580 [D loss: 0.647179, acc.: 60.94%] [G loss: 0.897233]\n",
      "epoch:28 step:26581 [D loss: 0.615640, acc.: 64.84%] [G loss: 0.879411]\n",
      "epoch:28 step:26582 [D loss: 0.669766, acc.: 56.25%] [G loss: 0.869580]\n",
      "epoch:28 step:26583 [D loss: 0.613141, acc.: 67.19%] [G loss: 0.874251]\n",
      "epoch:28 step:26584 [D loss: 0.655577, acc.: 63.28%] [G loss: 0.883923]\n",
      "epoch:28 step:26585 [D loss: 0.630640, acc.: 64.84%] [G loss: 0.876880]\n",
      "epoch:28 step:26586 [D loss: 0.716800, acc.: 57.03%] [G loss: 0.951804]\n",
      "epoch:28 step:26587 [D loss: 0.659746, acc.: 60.94%] [G loss: 0.907921]\n",
      "epoch:28 step:26588 [D loss: 0.665792, acc.: 60.16%] [G loss: 0.908548]\n",
      "epoch:28 step:26589 [D loss: 0.662467, acc.: 57.81%] [G loss: 0.837028]\n",
      "epoch:28 step:26590 [D loss: 0.687448, acc.: 55.47%] [G loss: 0.892148]\n",
      "epoch:28 step:26591 [D loss: 0.641185, acc.: 60.94%] [G loss: 0.900891]\n",
      "epoch:28 step:26592 [D loss: 0.652341, acc.: 59.38%] [G loss: 0.936642]\n",
      "epoch:28 step:26593 [D loss: 0.655854, acc.: 60.16%] [G loss: 0.905204]\n",
      "epoch:28 step:26594 [D loss: 0.646898, acc.: 66.41%] [G loss: 0.878153]\n",
      "epoch:28 step:26595 [D loss: 0.681213, acc.: 57.03%] [G loss: 0.888822]\n",
      "epoch:28 step:26596 [D loss: 0.611782, acc.: 68.75%] [G loss: 0.918872]\n",
      "epoch:28 step:26597 [D loss: 0.649033, acc.: 63.28%] [G loss: 0.913846]\n",
      "epoch:28 step:26598 [D loss: 0.658721, acc.: 61.72%] [G loss: 0.851773]\n",
      "epoch:28 step:26599 [D loss: 0.688337, acc.: 52.34%] [G loss: 0.891928]\n",
      "epoch:28 step:26600 [D loss: 0.662296, acc.: 60.16%] [G loss: 0.951975]\n",
      "##############\n",
      "[2.94896303 2.51053186 2.29685511 3.59847543 1.47626762 6.78296518\n",
      " 3.31454146 3.13940421 4.31935785 8.14868929]\n",
      "##########\n",
      "epoch:28 step:26601 [D loss: 0.637514, acc.: 62.50%] [G loss: 0.925856]\n",
      "epoch:28 step:26602 [D loss: 0.634731, acc.: 66.41%] [G loss: 0.883940]\n",
      "epoch:28 step:26603 [D loss: 0.652527, acc.: 60.94%] [G loss: 0.945875]\n",
      "epoch:28 step:26604 [D loss: 0.647180, acc.: 58.59%] [G loss: 0.884496]\n",
      "epoch:28 step:26605 [D loss: 0.619313, acc.: 66.41%] [G loss: 0.916094]\n",
      "epoch:28 step:26606 [D loss: 0.642849, acc.: 64.84%] [G loss: 0.859165]\n",
      "epoch:28 step:26607 [D loss: 0.669652, acc.: 61.72%] [G loss: 0.852288]\n",
      "epoch:28 step:26608 [D loss: 0.660408, acc.: 61.72%] [G loss: 0.918893]\n",
      "epoch:28 step:26609 [D loss: 0.635607, acc.: 65.62%] [G loss: 0.892945]\n",
      "epoch:28 step:26610 [D loss: 0.692068, acc.: 55.47%] [G loss: 0.949017]\n",
      "epoch:28 step:26611 [D loss: 0.683199, acc.: 58.59%] [G loss: 0.897973]\n",
      "epoch:28 step:26612 [D loss: 0.688608, acc.: 58.59%] [G loss: 0.901268]\n",
      "epoch:28 step:26613 [D loss: 0.644603, acc.: 60.16%] [G loss: 0.924168]\n",
      "epoch:28 step:26614 [D loss: 0.637653, acc.: 63.28%] [G loss: 0.891656]\n",
      "epoch:28 step:26615 [D loss: 0.678439, acc.: 57.81%] [G loss: 0.959680]\n",
      "epoch:28 step:26616 [D loss: 0.661548, acc.: 62.50%] [G loss: 0.926299]\n",
      "epoch:28 step:26617 [D loss: 0.696841, acc.: 53.12%] [G loss: 0.854038]\n",
      "epoch:28 step:26618 [D loss: 0.601069, acc.: 71.09%] [G loss: 0.904391]\n",
      "epoch:28 step:26619 [D loss: 0.673345, acc.: 56.25%] [G loss: 0.850017]\n",
      "epoch:28 step:26620 [D loss: 0.666534, acc.: 57.81%] [G loss: 0.929535]\n",
      "epoch:28 step:26621 [D loss: 0.657357, acc.: 63.28%] [G loss: 0.898147]\n",
      "epoch:28 step:26622 [D loss: 0.651067, acc.: 61.72%] [G loss: 0.885970]\n",
      "epoch:28 step:26623 [D loss: 0.640801, acc.: 62.50%] [G loss: 0.899671]\n",
      "epoch:28 step:26624 [D loss: 0.688480, acc.: 56.25%] [G loss: 0.880743]\n",
      "epoch:28 step:26625 [D loss: 0.639127, acc.: 60.94%] [G loss: 0.914987]\n",
      "epoch:28 step:26626 [D loss: 0.679296, acc.: 60.94%] [G loss: 0.925618]\n",
      "epoch:28 step:26627 [D loss: 0.615484, acc.: 66.41%] [G loss: 0.983051]\n",
      "epoch:28 step:26628 [D loss: 0.681262, acc.: 56.25%] [G loss: 0.950835]\n",
      "epoch:28 step:26629 [D loss: 0.683071, acc.: 53.12%] [G loss: 0.957217]\n",
      "epoch:28 step:26630 [D loss: 0.650249, acc.: 59.38%] [G loss: 0.957144]\n",
      "epoch:28 step:26631 [D loss: 0.684575, acc.: 59.38%] [G loss: 0.911934]\n",
      "epoch:28 step:26632 [D loss: 0.639179, acc.: 58.59%] [G loss: 0.916454]\n",
      "epoch:28 step:26633 [D loss: 0.702585, acc.: 53.12%] [G loss: 0.902291]\n",
      "epoch:28 step:26634 [D loss: 0.674714, acc.: 55.47%] [G loss: 0.963816]\n",
      "epoch:28 step:26635 [D loss: 0.637282, acc.: 65.62%] [G loss: 0.911438]\n",
      "epoch:28 step:26636 [D loss: 0.619991, acc.: 67.19%] [G loss: 0.964388]\n",
      "epoch:28 step:26637 [D loss: 0.584009, acc.: 73.44%] [G loss: 0.902169]\n",
      "epoch:28 step:26638 [D loss: 0.608185, acc.: 63.28%] [G loss: 0.953773]\n",
      "epoch:28 step:26639 [D loss: 0.659621, acc.: 61.72%] [G loss: 0.918470]\n",
      "epoch:28 step:26640 [D loss: 0.647403, acc.: 60.16%] [G loss: 0.928936]\n",
      "epoch:28 step:26641 [D loss: 0.650344, acc.: 64.06%] [G loss: 0.931258]\n",
      "epoch:28 step:26642 [D loss: 0.653245, acc.: 62.50%] [G loss: 0.938565]\n",
      "epoch:28 step:26643 [D loss: 0.636814, acc.: 64.06%] [G loss: 0.911578]\n",
      "epoch:28 step:26644 [D loss: 0.694924, acc.: 56.25%] [G loss: 0.963698]\n",
      "epoch:28 step:26645 [D loss: 0.688988, acc.: 57.03%] [G loss: 0.886102]\n",
      "epoch:28 step:26646 [D loss: 0.663232, acc.: 57.81%] [G loss: 0.905172]\n",
      "epoch:28 step:26647 [D loss: 0.636412, acc.: 63.28%] [G loss: 0.933909]\n",
      "epoch:28 step:26648 [D loss: 0.643375, acc.: 65.62%] [G loss: 0.920149]\n",
      "epoch:28 step:26649 [D loss: 0.640681, acc.: 62.50%] [G loss: 0.885523]\n",
      "epoch:28 step:26650 [D loss: 0.625741, acc.: 67.97%] [G loss: 0.910595]\n",
      "epoch:28 step:26651 [D loss: 0.627454, acc.: 64.84%] [G loss: 0.881162]\n",
      "epoch:28 step:26652 [D loss: 0.610777, acc.: 67.19%] [G loss: 0.915492]\n",
      "epoch:28 step:26653 [D loss: 0.619713, acc.: 67.19%] [G loss: 0.913247]\n",
      "epoch:28 step:26654 [D loss: 0.671052, acc.: 53.91%] [G loss: 0.894203]\n",
      "epoch:28 step:26655 [D loss: 0.663649, acc.: 62.50%] [G loss: 0.943934]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26656 [D loss: 0.625366, acc.: 63.28%] [G loss: 0.859505]\n",
      "epoch:28 step:26657 [D loss: 0.644674, acc.: 63.28%] [G loss: 0.907970]\n",
      "epoch:28 step:26658 [D loss: 0.688201, acc.: 57.03%] [G loss: 0.865436]\n",
      "epoch:28 step:26659 [D loss: 0.657508, acc.: 56.25%] [G loss: 0.865144]\n",
      "epoch:28 step:26660 [D loss: 0.632415, acc.: 64.84%] [G loss: 0.902371]\n",
      "epoch:28 step:26661 [D loss: 0.652940, acc.: 61.72%] [G loss: 0.893495]\n",
      "epoch:28 step:26662 [D loss: 0.683256, acc.: 57.03%] [G loss: 0.883107]\n",
      "epoch:28 step:26663 [D loss: 0.633579, acc.: 61.72%] [G loss: 0.893875]\n",
      "epoch:28 step:26664 [D loss: 0.702853, acc.: 50.78%] [G loss: 0.958307]\n",
      "epoch:28 step:26665 [D loss: 0.657226, acc.: 58.59%] [G loss: 0.940623]\n",
      "epoch:28 step:26666 [D loss: 0.678527, acc.: 61.72%] [G loss: 0.860629]\n",
      "epoch:28 step:26667 [D loss: 0.636593, acc.: 66.41%] [G loss: 0.910663]\n",
      "epoch:28 step:26668 [D loss: 0.641438, acc.: 67.19%] [G loss: 0.903650]\n",
      "epoch:28 step:26669 [D loss: 0.684139, acc.: 56.25%] [G loss: 0.896515]\n",
      "epoch:28 step:26670 [D loss: 0.629204, acc.: 65.62%] [G loss: 0.887196]\n",
      "epoch:28 step:26671 [D loss: 0.642250, acc.: 62.50%] [G loss: 0.876270]\n",
      "epoch:28 step:26672 [D loss: 0.684872, acc.: 56.25%] [G loss: 0.834053]\n",
      "epoch:28 step:26673 [D loss: 0.650454, acc.: 62.50%] [G loss: 0.915291]\n",
      "epoch:28 step:26674 [D loss: 0.650098, acc.: 62.50%] [G loss: 0.860059]\n",
      "epoch:28 step:26675 [D loss: 0.623249, acc.: 64.84%] [G loss: 0.878831]\n",
      "epoch:28 step:26676 [D loss: 0.681846, acc.: 55.47%] [G loss: 0.872569]\n",
      "epoch:28 step:26677 [D loss: 0.682050, acc.: 52.34%] [G loss: 0.819245]\n",
      "epoch:28 step:26678 [D loss: 0.653079, acc.: 59.38%] [G loss: 0.860658]\n",
      "epoch:28 step:26679 [D loss: 0.637296, acc.: 59.38%] [G loss: 0.896962]\n",
      "epoch:28 step:26680 [D loss: 0.618926, acc.: 68.75%] [G loss: 0.919438]\n",
      "epoch:28 step:26681 [D loss: 0.685246, acc.: 57.03%] [G loss: 0.894458]\n",
      "epoch:28 step:26682 [D loss: 0.675428, acc.: 57.03%] [G loss: 0.891559]\n",
      "epoch:28 step:26683 [D loss: 0.616452, acc.: 68.75%] [G loss: 0.888561]\n",
      "epoch:28 step:26684 [D loss: 0.714739, acc.: 50.78%] [G loss: 0.871062]\n",
      "epoch:28 step:26685 [D loss: 0.667219, acc.: 57.03%] [G loss: 0.848719]\n",
      "epoch:28 step:26686 [D loss: 0.664849, acc.: 60.94%] [G loss: 0.954778]\n",
      "epoch:28 step:26687 [D loss: 0.618069, acc.: 67.97%] [G loss: 0.928465]\n",
      "epoch:28 step:26688 [D loss: 0.642136, acc.: 58.59%] [G loss: 0.873191]\n",
      "epoch:28 step:26689 [D loss: 0.643234, acc.: 63.28%] [G loss: 0.879868]\n",
      "epoch:28 step:26690 [D loss: 0.644855, acc.: 57.03%] [G loss: 0.873973]\n",
      "epoch:28 step:26691 [D loss: 0.653755, acc.: 61.72%] [G loss: 0.875725]\n",
      "epoch:28 step:26692 [D loss: 0.660209, acc.: 64.06%] [G loss: 0.907499]\n",
      "epoch:28 step:26693 [D loss: 0.610229, acc.: 71.09%] [G loss: 0.893422]\n",
      "epoch:28 step:26694 [D loss: 0.635787, acc.: 59.38%] [G loss: 0.895531]\n",
      "epoch:28 step:26695 [D loss: 0.598514, acc.: 66.41%] [G loss: 0.883478]\n",
      "epoch:28 step:26696 [D loss: 0.636613, acc.: 56.25%] [G loss: 0.953316]\n",
      "epoch:28 step:26697 [D loss: 0.623955, acc.: 61.72%] [G loss: 0.895195]\n",
      "epoch:28 step:26698 [D loss: 0.641399, acc.: 57.03%] [G loss: 0.856843]\n",
      "epoch:28 step:26699 [D loss: 0.625924, acc.: 59.38%] [G loss: 0.904929]\n",
      "epoch:28 step:26700 [D loss: 0.653837, acc.: 60.16%] [G loss: 0.892562]\n",
      "epoch:28 step:26701 [D loss: 0.644115, acc.: 60.94%] [G loss: 0.877186]\n",
      "epoch:28 step:26702 [D loss: 0.629331, acc.: 64.84%] [G loss: 0.928923]\n",
      "epoch:28 step:26703 [D loss: 0.668689, acc.: 57.03%] [G loss: 0.898824]\n",
      "epoch:28 step:26704 [D loss: 0.633291, acc.: 63.28%] [G loss: 0.930329]\n",
      "epoch:28 step:26705 [D loss: 0.616957, acc.: 68.75%] [G loss: 0.905675]\n",
      "epoch:28 step:26706 [D loss: 0.680691, acc.: 54.69%] [G loss: 0.910436]\n",
      "epoch:28 step:26707 [D loss: 0.630137, acc.: 63.28%] [G loss: 0.885770]\n",
      "epoch:28 step:26708 [D loss: 0.644504, acc.: 61.72%] [G loss: 0.954350]\n",
      "epoch:28 step:26709 [D loss: 0.633419, acc.: 63.28%] [G loss: 0.894517]\n",
      "epoch:28 step:26710 [D loss: 0.599990, acc.: 69.53%] [G loss: 0.973955]\n",
      "epoch:28 step:26711 [D loss: 0.615513, acc.: 66.41%] [G loss: 0.967830]\n",
      "epoch:28 step:26712 [D loss: 0.657050, acc.: 59.38%] [G loss: 1.005787]\n",
      "epoch:28 step:26713 [D loss: 0.684445, acc.: 57.81%] [G loss: 0.934080]\n",
      "epoch:28 step:26714 [D loss: 0.650280, acc.: 60.94%] [G loss: 0.880833]\n",
      "epoch:28 step:26715 [D loss: 0.671337, acc.: 57.03%] [G loss: 0.877876]\n",
      "epoch:28 step:26716 [D loss: 0.643656, acc.: 59.38%] [G loss: 0.895691]\n",
      "epoch:28 step:26717 [D loss: 0.659434, acc.: 57.81%] [G loss: 0.910329]\n",
      "epoch:28 step:26718 [D loss: 0.652914, acc.: 59.38%] [G loss: 0.901213]\n",
      "epoch:28 step:26719 [D loss: 0.650793, acc.: 61.72%] [G loss: 0.889561]\n",
      "epoch:28 step:26720 [D loss: 0.663296, acc.: 58.59%] [G loss: 0.878041]\n",
      "epoch:28 step:26721 [D loss: 0.650512, acc.: 67.97%] [G loss: 0.879014]\n",
      "epoch:28 step:26722 [D loss: 0.627253, acc.: 65.62%] [G loss: 0.859375]\n",
      "epoch:28 step:26723 [D loss: 0.652572, acc.: 60.16%] [G loss: 0.864399]\n",
      "epoch:28 step:26724 [D loss: 0.607383, acc.: 67.97%] [G loss: 0.968843]\n",
      "epoch:28 step:26725 [D loss: 0.635382, acc.: 62.50%] [G loss: 0.950682]\n",
      "epoch:28 step:26726 [D loss: 0.600774, acc.: 70.31%] [G loss: 0.918476]\n",
      "epoch:28 step:26727 [D loss: 0.693455, acc.: 60.94%] [G loss: 0.929747]\n",
      "epoch:28 step:26728 [D loss: 0.634412, acc.: 60.94%] [G loss: 0.880855]\n",
      "epoch:28 step:26729 [D loss: 0.664096, acc.: 57.81%] [G loss: 0.871542]\n",
      "epoch:28 step:26730 [D loss: 0.603593, acc.: 68.75%] [G loss: 0.910979]\n",
      "epoch:28 step:26731 [D loss: 0.637165, acc.: 60.16%] [G loss: 0.857084]\n",
      "epoch:28 step:26732 [D loss: 0.664609, acc.: 47.66%] [G loss: 0.876279]\n",
      "epoch:28 step:26733 [D loss: 0.642652, acc.: 66.41%] [G loss: 0.881535]\n",
      "epoch:28 step:26734 [D loss: 0.638764, acc.: 61.72%] [G loss: 0.903333]\n",
      "epoch:28 step:26735 [D loss: 0.640420, acc.: 62.50%] [G loss: 0.888360]\n",
      "epoch:28 step:26736 [D loss: 0.661992, acc.: 64.06%] [G loss: 0.959497]\n",
      "epoch:28 step:26737 [D loss: 0.635456, acc.: 64.06%] [G loss: 0.852889]\n",
      "epoch:28 step:26738 [D loss: 0.647308, acc.: 57.81%] [G loss: 0.936422]\n",
      "epoch:28 step:26739 [D loss: 0.669950, acc.: 61.72%] [G loss: 0.886228]\n",
      "epoch:28 step:26740 [D loss: 0.665957, acc.: 60.94%] [G loss: 0.887885]\n",
      "epoch:28 step:26741 [D loss: 0.664196, acc.: 55.47%] [G loss: 0.935236]\n",
      "epoch:28 step:26742 [D loss: 0.674395, acc.: 58.59%] [G loss: 0.911627]\n",
      "epoch:28 step:26743 [D loss: 0.643814, acc.: 66.41%] [G loss: 0.887722]\n",
      "epoch:28 step:26744 [D loss: 0.623891, acc.: 65.62%] [G loss: 0.919014]\n",
      "epoch:28 step:26745 [D loss: 0.641954, acc.: 60.94%] [G loss: 0.907694]\n",
      "epoch:28 step:26746 [D loss: 0.600454, acc.: 68.75%] [G loss: 0.913650]\n",
      "epoch:28 step:26747 [D loss: 0.616600, acc.: 69.53%] [G loss: 0.995463]\n",
      "epoch:28 step:26748 [D loss: 0.672177, acc.: 58.59%] [G loss: 0.932665]\n",
      "epoch:28 step:26749 [D loss: 0.670120, acc.: 57.03%] [G loss: 0.896592]\n",
      "epoch:28 step:26750 [D loss: 0.637591, acc.: 60.94%] [G loss: 0.895127]\n",
      "epoch:28 step:26751 [D loss: 0.658252, acc.: 60.94%] [G loss: 0.890472]\n",
      "epoch:28 step:26752 [D loss: 0.683426, acc.: 52.34%] [G loss: 0.927839]\n",
      "epoch:28 step:26753 [D loss: 0.644007, acc.: 64.06%] [G loss: 0.922513]\n",
      "epoch:28 step:26754 [D loss: 0.638073, acc.: 64.06%] [G loss: 0.910793]\n",
      "epoch:28 step:26755 [D loss: 0.651497, acc.: 60.16%] [G loss: 0.906479]\n",
      "epoch:28 step:26756 [D loss: 0.636996, acc.: 64.84%] [G loss: 0.855666]\n",
      "epoch:28 step:26757 [D loss: 0.631324, acc.: 64.06%] [G loss: 0.897310]\n",
      "epoch:28 step:26758 [D loss: 0.639575, acc.: 64.06%] [G loss: 0.942128]\n",
      "epoch:28 step:26759 [D loss: 0.627586, acc.: 64.84%] [G loss: 0.910287]\n",
      "epoch:28 step:26760 [D loss: 0.616248, acc.: 68.75%] [G loss: 0.887986]\n",
      "epoch:28 step:26761 [D loss: 0.669331, acc.: 56.25%] [G loss: 0.904807]\n",
      "epoch:28 step:26762 [D loss: 0.683630, acc.: 57.81%] [G loss: 0.854960]\n",
      "epoch:28 step:26763 [D loss: 0.673041, acc.: 52.34%] [G loss: 0.938612]\n",
      "epoch:28 step:26764 [D loss: 0.627239, acc.: 63.28%] [G loss: 0.924341]\n",
      "epoch:28 step:26765 [D loss: 0.639717, acc.: 63.28%] [G loss: 0.926295]\n",
      "epoch:28 step:26766 [D loss: 0.650648, acc.: 60.94%] [G loss: 0.884376]\n",
      "epoch:28 step:26767 [D loss: 0.647255, acc.: 61.72%] [G loss: 0.911889]\n",
      "epoch:28 step:26768 [D loss: 0.661634, acc.: 58.59%] [G loss: 0.884485]\n",
      "epoch:28 step:26769 [D loss: 0.654822, acc.: 58.59%] [G loss: 0.923787]\n",
      "epoch:28 step:26770 [D loss: 0.714893, acc.: 50.78%] [G loss: 0.940071]\n",
      "epoch:28 step:26771 [D loss: 0.612499, acc.: 64.84%] [G loss: 0.886263]\n",
      "epoch:28 step:26772 [D loss: 0.684206, acc.: 53.91%] [G loss: 0.962554]\n",
      "epoch:28 step:26773 [D loss: 0.672888, acc.: 60.16%] [G loss: 0.875610]\n",
      "epoch:28 step:26774 [D loss: 0.694956, acc.: 53.91%] [G loss: 0.899488]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26775 [D loss: 0.640522, acc.: 64.06%] [G loss: 0.897942]\n",
      "epoch:28 step:26776 [D loss: 0.645385, acc.: 66.41%] [G loss: 0.887289]\n",
      "epoch:28 step:26777 [D loss: 0.661223, acc.: 60.16%] [G loss: 0.895840]\n",
      "epoch:28 step:26778 [D loss: 0.670722, acc.: 59.38%] [G loss: 0.867297]\n",
      "epoch:28 step:26779 [D loss: 0.643867, acc.: 60.16%] [G loss: 0.872371]\n",
      "epoch:28 step:26780 [D loss: 0.670791, acc.: 55.47%] [G loss: 0.904240]\n",
      "epoch:28 step:26781 [D loss: 0.657353, acc.: 58.59%] [G loss: 0.928673]\n",
      "epoch:28 step:26782 [D loss: 0.653196, acc.: 63.28%] [G loss: 0.936601]\n",
      "epoch:28 step:26783 [D loss: 0.665836, acc.: 55.47%] [G loss: 0.942147]\n",
      "epoch:28 step:26784 [D loss: 0.668840, acc.: 57.81%] [G loss: 0.923333]\n",
      "epoch:28 step:26785 [D loss: 0.650066, acc.: 62.50%] [G loss: 0.885532]\n",
      "epoch:28 step:26786 [D loss: 0.643251, acc.: 67.97%] [G loss: 0.942427]\n",
      "epoch:28 step:26787 [D loss: 0.642118, acc.: 63.28%] [G loss: 0.905398]\n",
      "epoch:28 step:26788 [D loss: 0.626281, acc.: 61.72%] [G loss: 0.917691]\n",
      "epoch:28 step:26789 [D loss: 0.676432, acc.: 56.25%] [G loss: 0.909720]\n",
      "epoch:28 step:26790 [D loss: 0.671339, acc.: 60.94%] [G loss: 0.954052]\n",
      "epoch:28 step:26791 [D loss: 0.635509, acc.: 63.28%] [G loss: 0.930252]\n",
      "epoch:28 step:26792 [D loss: 0.643685, acc.: 62.50%] [G loss: 0.872625]\n",
      "epoch:28 step:26793 [D loss: 0.641465, acc.: 63.28%] [G loss: 0.849053]\n",
      "epoch:28 step:26794 [D loss: 0.655797, acc.: 59.38%] [G loss: 0.824420]\n",
      "epoch:28 step:26795 [D loss: 0.727623, acc.: 44.53%] [G loss: 0.896536]\n",
      "epoch:28 step:26796 [D loss: 0.656096, acc.: 57.03%] [G loss: 0.902767]\n",
      "epoch:28 step:26797 [D loss: 0.633701, acc.: 67.19%] [G loss: 0.861921]\n",
      "epoch:28 step:26798 [D loss: 0.659058, acc.: 61.72%] [G loss: 0.930670]\n",
      "epoch:28 step:26799 [D loss: 0.642420, acc.: 65.62%] [G loss: 0.971475]\n",
      "epoch:28 step:26800 [D loss: 0.655542, acc.: 64.84%] [G loss: 0.965593]\n",
      "##############\n",
      "[3.02906007 2.31717481 1.89902446 3.86029939 1.32017008 9.27426719\n",
      " 2.8372869  3.55042777 4.36115953 8.14868929]\n",
      "##########\n",
      "epoch:28 step:26801 [D loss: 0.620024, acc.: 67.19%] [G loss: 0.904194]\n",
      "epoch:28 step:26802 [D loss: 0.642105, acc.: 61.72%] [G loss: 1.015470]\n",
      "epoch:28 step:26803 [D loss: 0.615331, acc.: 68.75%] [G loss: 0.851337]\n",
      "epoch:28 step:26804 [D loss: 0.680347, acc.: 54.69%] [G loss: 0.909201]\n",
      "epoch:28 step:26805 [D loss: 0.621060, acc.: 65.62%] [G loss: 0.923553]\n",
      "epoch:28 step:26806 [D loss: 0.671601, acc.: 64.06%] [G loss: 0.924389]\n",
      "epoch:28 step:26807 [D loss: 0.630506, acc.: 69.53%] [G loss: 0.962549]\n",
      "epoch:28 step:26808 [D loss: 0.637984, acc.: 62.50%] [G loss: 0.878419]\n",
      "epoch:28 step:26809 [D loss: 0.711828, acc.: 53.91%] [G loss: 0.891460]\n",
      "epoch:28 step:26810 [D loss: 0.686228, acc.: 53.91%] [G loss: 0.987286]\n",
      "epoch:28 step:26811 [D loss: 0.659527, acc.: 57.81%] [G loss: 0.974355]\n",
      "epoch:28 step:26812 [D loss: 0.638203, acc.: 67.97%] [G loss: 0.933940]\n",
      "epoch:28 step:26813 [D loss: 0.677279, acc.: 62.50%] [G loss: 0.883617]\n",
      "epoch:28 step:26814 [D loss: 0.638060, acc.: 58.59%] [G loss: 0.875270]\n",
      "epoch:28 step:26815 [D loss: 0.629808, acc.: 65.62%] [G loss: 0.876408]\n",
      "epoch:28 step:26816 [D loss: 0.693799, acc.: 57.03%] [G loss: 0.903467]\n",
      "epoch:28 step:26817 [D loss: 0.629559, acc.: 62.50%] [G loss: 0.903314]\n",
      "epoch:28 step:26818 [D loss: 0.637665, acc.: 60.94%] [G loss: 0.922812]\n",
      "epoch:28 step:26819 [D loss: 0.676969, acc.: 60.16%] [G loss: 0.889723]\n",
      "epoch:28 step:26820 [D loss: 0.607095, acc.: 65.62%] [G loss: 0.924918]\n",
      "epoch:28 step:26821 [D loss: 0.610466, acc.: 68.75%] [G loss: 0.939133]\n",
      "epoch:28 step:26822 [D loss: 0.669561, acc.: 57.81%] [G loss: 0.900851]\n",
      "epoch:28 step:26823 [D loss: 0.621780, acc.: 64.06%] [G loss: 0.892145]\n",
      "epoch:28 step:26824 [D loss: 0.645207, acc.: 62.50%] [G loss: 0.931682]\n",
      "epoch:28 step:26825 [D loss: 0.646954, acc.: 59.38%] [G loss: 0.915260]\n",
      "epoch:28 step:26826 [D loss: 0.648345, acc.: 65.62%] [G loss: 0.893983]\n",
      "epoch:28 step:26827 [D loss: 0.637200, acc.: 66.41%] [G loss: 0.912809]\n",
      "epoch:28 step:26828 [D loss: 0.619559, acc.: 70.31%] [G loss: 0.852861]\n",
      "epoch:28 step:26829 [D loss: 0.683177, acc.: 58.59%] [G loss: 0.900903]\n",
      "epoch:28 step:26830 [D loss: 0.619097, acc.: 67.19%] [G loss: 0.834415]\n",
      "epoch:28 step:26831 [D loss: 0.651560, acc.: 61.72%] [G loss: 0.883790]\n",
      "epoch:28 step:26832 [D loss: 0.636391, acc.: 66.41%] [G loss: 0.853147]\n",
      "epoch:28 step:26833 [D loss: 0.681550, acc.: 58.59%] [G loss: 0.884651]\n",
      "epoch:28 step:26834 [D loss: 0.664716, acc.: 62.50%] [G loss: 0.951275]\n",
      "epoch:28 step:26835 [D loss: 0.614585, acc.: 69.53%] [G loss: 1.025445]\n",
      "epoch:28 step:26836 [D loss: 0.665720, acc.: 60.94%] [G loss: 0.893773]\n",
      "epoch:28 step:26837 [D loss: 0.698478, acc.: 55.47%] [G loss: 0.937838]\n",
      "epoch:28 step:26838 [D loss: 0.635772, acc.: 67.97%] [G loss: 0.961364]\n",
      "epoch:28 step:26839 [D loss: 0.668029, acc.: 58.59%] [G loss: 0.915828]\n",
      "epoch:28 step:26840 [D loss: 0.689204, acc.: 58.59%] [G loss: 0.932417]\n",
      "epoch:28 step:26841 [D loss: 0.693899, acc.: 52.34%] [G loss: 0.914139]\n",
      "epoch:28 step:26842 [D loss: 0.655436, acc.: 61.72%] [G loss: 0.904647]\n",
      "epoch:28 step:26843 [D loss: 0.663157, acc.: 62.50%] [G loss: 0.880125]\n",
      "epoch:28 step:26844 [D loss: 0.662575, acc.: 54.69%] [G loss: 0.977284]\n",
      "epoch:28 step:26845 [D loss: 0.602623, acc.: 70.31%] [G loss: 0.881625]\n",
      "epoch:28 step:26846 [D loss: 0.638988, acc.: 66.41%] [G loss: 0.924160]\n",
      "epoch:28 step:26847 [D loss: 0.651384, acc.: 63.28%] [G loss: 0.813388]\n",
      "epoch:28 step:26848 [D loss: 0.676341, acc.: 53.12%] [G loss: 0.925494]\n",
      "epoch:28 step:26849 [D loss: 0.635539, acc.: 64.06%] [G loss: 0.942282]\n",
      "epoch:28 step:26850 [D loss: 0.637722, acc.: 57.81%] [G loss: 0.929139]\n",
      "epoch:28 step:26851 [D loss: 0.688549, acc.: 56.25%] [G loss: 0.895569]\n",
      "epoch:28 step:26852 [D loss: 0.634546, acc.: 65.62%] [G loss: 0.927153]\n",
      "epoch:28 step:26853 [D loss: 0.670520, acc.: 56.25%] [G loss: 0.907018]\n",
      "epoch:28 step:26854 [D loss: 0.663536, acc.: 62.50%] [G loss: 0.896491]\n",
      "epoch:28 step:26855 [D loss: 0.646462, acc.: 64.84%] [G loss: 0.912362]\n",
      "epoch:28 step:26856 [D loss: 0.658438, acc.: 57.81%] [G loss: 0.903228]\n",
      "epoch:28 step:26857 [D loss: 0.672644, acc.: 61.72%] [G loss: 0.926656]\n",
      "epoch:28 step:26858 [D loss: 0.635958, acc.: 60.16%] [G loss: 0.903604]\n",
      "epoch:28 step:26859 [D loss: 0.633262, acc.: 64.84%] [G loss: 0.878199]\n",
      "epoch:28 step:26860 [D loss: 0.639974, acc.: 60.16%] [G loss: 0.903816]\n",
      "epoch:28 step:26861 [D loss: 0.671834, acc.: 57.81%] [G loss: 0.918542]\n",
      "epoch:28 step:26862 [D loss: 0.630746, acc.: 64.06%] [G loss: 0.943827]\n",
      "epoch:28 step:26863 [D loss: 0.656546, acc.: 57.81%] [G loss: 0.865315]\n",
      "epoch:28 step:26864 [D loss: 0.664315, acc.: 59.38%] [G loss: 0.846194]\n",
      "epoch:28 step:26865 [D loss: 0.642509, acc.: 61.72%] [G loss: 0.872846]\n",
      "epoch:28 step:26866 [D loss: 0.645712, acc.: 57.81%] [G loss: 0.812650]\n",
      "epoch:28 step:26867 [D loss: 0.593298, acc.: 70.31%] [G loss: 0.836938]\n",
      "epoch:28 step:26868 [D loss: 0.628553, acc.: 64.06%] [G loss: 0.896779]\n",
      "epoch:28 step:26869 [D loss: 0.597964, acc.: 65.62%] [G loss: 0.911510]\n",
      "epoch:28 step:26870 [D loss: 0.591409, acc.: 69.53%] [G loss: 0.900434]\n",
      "epoch:28 step:26871 [D loss: 0.639722, acc.: 63.28%] [G loss: 0.982273]\n",
      "epoch:28 step:26872 [D loss: 0.634117, acc.: 61.72%] [G loss: 0.943492]\n",
      "epoch:28 step:26873 [D loss: 0.634831, acc.: 59.38%] [G loss: 0.934488]\n",
      "epoch:28 step:26874 [D loss: 0.629210, acc.: 64.06%] [G loss: 0.943022]\n",
      "epoch:28 step:26875 [D loss: 0.681202, acc.: 56.25%] [G loss: 0.905780]\n",
      "epoch:28 step:26876 [D loss: 0.634521, acc.: 64.06%] [G loss: 0.910452]\n",
      "epoch:28 step:26877 [D loss: 0.635373, acc.: 64.84%] [G loss: 0.876554]\n",
      "epoch:28 step:26878 [D loss: 0.676610, acc.: 59.38%] [G loss: 0.945411]\n",
      "epoch:28 step:26879 [D loss: 0.662041, acc.: 59.38%] [G loss: 0.915439]\n",
      "epoch:28 step:26880 [D loss: 0.654454, acc.: 58.59%] [G loss: 0.898355]\n",
      "epoch:28 step:26881 [D loss: 0.642368, acc.: 62.50%] [G loss: 0.883159]\n",
      "epoch:28 step:26882 [D loss: 0.636100, acc.: 67.19%] [G loss: 0.969768]\n",
      "epoch:28 step:26883 [D loss: 0.679152, acc.: 53.91%] [G loss: 0.971920]\n",
      "epoch:28 step:26884 [D loss: 0.634936, acc.: 64.06%] [G loss: 0.939218]\n",
      "epoch:28 step:26885 [D loss: 0.628196, acc.: 60.94%] [G loss: 0.906431]\n",
      "epoch:28 step:26886 [D loss: 0.651640, acc.: 61.72%] [G loss: 0.890417]\n",
      "epoch:28 step:26887 [D loss: 0.611360, acc.: 67.19%] [G loss: 0.886438]\n",
      "epoch:28 step:26888 [D loss: 0.642087, acc.: 63.28%] [G loss: 0.924401]\n",
      "epoch:28 step:26889 [D loss: 0.641669, acc.: 63.28%] [G loss: 0.889452]\n",
      "epoch:28 step:26890 [D loss: 0.643199, acc.: 59.38%] [G loss: 0.890569]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:26891 [D loss: 0.661514, acc.: 53.91%] [G loss: 0.921580]\n",
      "epoch:28 step:26892 [D loss: 0.612606, acc.: 69.53%] [G loss: 0.900480]\n",
      "epoch:28 step:26893 [D loss: 0.639696, acc.: 57.81%] [G loss: 0.898628]\n",
      "epoch:28 step:26894 [D loss: 0.699347, acc.: 50.78%] [G loss: 0.882087]\n",
      "epoch:28 step:26895 [D loss: 0.637372, acc.: 64.84%] [G loss: 0.893600]\n",
      "epoch:28 step:26896 [D loss: 0.657699, acc.: 53.12%] [G loss: 0.906241]\n",
      "epoch:28 step:26897 [D loss: 0.619762, acc.: 66.41%] [G loss: 0.974983]\n",
      "epoch:28 step:26898 [D loss: 0.656200, acc.: 61.72%] [G loss: 0.924452]\n",
      "epoch:28 step:26899 [D loss: 0.636127, acc.: 58.59%] [G loss: 0.903647]\n",
      "epoch:28 step:26900 [D loss: 0.615063, acc.: 69.53%] [G loss: 0.955465]\n",
      "epoch:28 step:26901 [D loss: 0.687121, acc.: 55.47%] [G loss: 0.908357]\n",
      "epoch:28 step:26902 [D loss: 0.622115, acc.: 65.62%] [G loss: 0.909509]\n",
      "epoch:28 step:26903 [D loss: 0.657078, acc.: 63.28%] [G loss: 0.896028]\n",
      "epoch:28 step:26904 [D loss: 0.630701, acc.: 64.06%] [G loss: 0.939898]\n",
      "epoch:28 step:26905 [D loss: 0.674418, acc.: 56.25%] [G loss: 0.910081]\n",
      "epoch:28 step:26906 [D loss: 0.670382, acc.: 55.47%] [G loss: 0.932843]\n",
      "epoch:28 step:26907 [D loss: 0.629247, acc.: 67.19%] [G loss: 0.917268]\n",
      "epoch:28 step:26908 [D loss: 0.662130, acc.: 59.38%] [G loss: 0.876840]\n",
      "epoch:28 step:26909 [D loss: 0.679042, acc.: 57.03%] [G loss: 0.874642]\n",
      "epoch:28 step:26910 [D loss: 0.661898, acc.: 57.81%] [G loss: 0.933917]\n",
      "epoch:28 step:26911 [D loss: 0.642945, acc.: 62.50%] [G loss: 0.908768]\n",
      "epoch:28 step:26912 [D loss: 0.671525, acc.: 64.06%] [G loss: 0.931867]\n",
      "epoch:28 step:26913 [D loss: 0.674371, acc.: 59.38%] [G loss: 0.920143]\n",
      "epoch:28 step:26914 [D loss: 0.663837, acc.: 57.03%] [G loss: 0.936787]\n",
      "epoch:28 step:26915 [D loss: 0.684082, acc.: 57.03%] [G loss: 0.922743]\n",
      "epoch:28 step:26916 [D loss: 0.661376, acc.: 59.38%] [G loss: 0.908026]\n",
      "epoch:28 step:26917 [D loss: 0.648589, acc.: 64.84%] [G loss: 0.907862]\n",
      "epoch:28 step:26918 [D loss: 0.637424, acc.: 60.94%] [G loss: 0.962110]\n",
      "epoch:28 step:26919 [D loss: 0.628827, acc.: 63.28%] [G loss: 0.936508]\n",
      "epoch:28 step:26920 [D loss: 0.652543, acc.: 57.03%] [G loss: 0.953137]\n",
      "epoch:28 step:26921 [D loss: 0.653553, acc.: 65.62%] [G loss: 0.887779]\n",
      "epoch:28 step:26922 [D loss: 0.651217, acc.: 63.28%] [G loss: 0.875899]\n",
      "epoch:28 step:26923 [D loss: 0.643303, acc.: 62.50%] [G loss: 0.980524]\n",
      "epoch:28 step:26924 [D loss: 0.662140, acc.: 59.38%] [G loss: 0.975737]\n",
      "epoch:28 step:26925 [D loss: 0.671300, acc.: 57.03%] [G loss: 0.906193]\n",
      "epoch:28 step:26926 [D loss: 0.674842, acc.: 55.47%] [G loss: 0.862236]\n",
      "epoch:28 step:26927 [D loss: 0.649225, acc.: 60.94%] [G loss: 0.859578]\n",
      "epoch:28 step:26928 [D loss: 0.659846, acc.: 66.41%] [G loss: 0.922127]\n",
      "epoch:28 step:26929 [D loss: 0.634765, acc.: 66.41%] [G loss: 0.806267]\n",
      "epoch:28 step:26930 [D loss: 0.619951, acc.: 67.97%] [G loss: 0.874317]\n",
      "epoch:28 step:26931 [D loss: 0.613653, acc.: 65.62%] [G loss: 0.884499]\n",
      "epoch:28 step:26932 [D loss: 0.615731, acc.: 67.97%] [G loss: 0.912050]\n",
      "epoch:28 step:26933 [D loss: 0.660880, acc.: 61.72%] [G loss: 0.900766]\n",
      "epoch:28 step:26934 [D loss: 0.648883, acc.: 60.94%] [G loss: 0.930069]\n",
      "epoch:28 step:26935 [D loss: 0.633911, acc.: 60.94%] [G loss: 0.974667]\n",
      "epoch:28 step:26936 [D loss: 0.638584, acc.: 61.72%] [G loss: 0.872229]\n",
      "epoch:28 step:26937 [D loss: 0.662104, acc.: 57.81%] [G loss: 0.883201]\n",
      "epoch:28 step:26938 [D loss: 0.639653, acc.: 59.38%] [G loss: 0.887243]\n",
      "epoch:28 step:26939 [D loss: 0.696899, acc.: 57.03%] [G loss: 0.913666]\n",
      "epoch:28 step:26940 [D loss: 0.657220, acc.: 62.50%] [G loss: 0.909941]\n",
      "epoch:28 step:26941 [D loss: 0.642850, acc.: 60.16%] [G loss: 0.924585]\n",
      "epoch:28 step:26942 [D loss: 0.660392, acc.: 55.47%] [G loss: 0.906962]\n",
      "epoch:28 step:26943 [D loss: 0.647356, acc.: 64.06%] [G loss: 0.956944]\n",
      "epoch:28 step:26944 [D loss: 0.648174, acc.: 63.28%] [G loss: 0.896303]\n",
      "epoch:28 step:26945 [D loss: 0.656600, acc.: 61.72%] [G loss: 0.909547]\n",
      "epoch:28 step:26946 [D loss: 0.626178, acc.: 68.75%] [G loss: 1.015773]\n",
      "epoch:28 step:26947 [D loss: 0.669448, acc.: 57.03%] [G loss: 0.959596]\n",
      "epoch:28 step:26948 [D loss: 0.686365, acc.: 60.94%] [G loss: 0.933051]\n",
      "epoch:28 step:26949 [D loss: 0.645769, acc.: 59.38%] [G loss: 0.938742]\n",
      "epoch:28 step:26950 [D loss: 0.643147, acc.: 61.72%] [G loss: 0.994902]\n",
      "epoch:28 step:26951 [D loss: 0.699575, acc.: 48.44%] [G loss: 0.935514]\n",
      "epoch:28 step:26952 [D loss: 0.631117, acc.: 63.28%] [G loss: 0.935684]\n",
      "epoch:28 step:26953 [D loss: 0.661574, acc.: 59.38%] [G loss: 0.924417]\n",
      "epoch:28 step:26954 [D loss: 0.626123, acc.: 67.19%] [G loss: 0.964454]\n",
      "epoch:28 step:26955 [D loss: 0.666043, acc.: 60.94%] [G loss: 0.904247]\n",
      "epoch:28 step:26956 [D loss: 0.626071, acc.: 67.19%] [G loss: 0.953649]\n",
      "epoch:28 step:26957 [D loss: 0.614701, acc.: 66.41%] [G loss: 0.973117]\n",
      "epoch:28 step:26958 [D loss: 0.676475, acc.: 62.50%] [G loss: 0.925637]\n",
      "epoch:28 step:26959 [D loss: 0.643360, acc.: 60.16%] [G loss: 0.931086]\n",
      "epoch:28 step:26960 [D loss: 0.652097, acc.: 58.59%] [G loss: 0.857454]\n",
      "epoch:28 step:26961 [D loss: 0.633019, acc.: 65.62%] [G loss: 0.840731]\n",
      "epoch:28 step:26962 [D loss: 0.668740, acc.: 65.62%] [G loss: 0.891699]\n",
      "epoch:28 step:26963 [D loss: 0.607338, acc.: 62.50%] [G loss: 0.928939]\n",
      "epoch:28 step:26964 [D loss: 0.705998, acc.: 53.91%] [G loss: 0.836043]\n",
      "epoch:28 step:26965 [D loss: 0.646645, acc.: 63.28%] [G loss: 0.874346]\n",
      "epoch:28 step:26966 [D loss: 0.683663, acc.: 54.69%] [G loss: 0.916623]\n",
      "epoch:28 step:26967 [D loss: 0.661277, acc.: 61.72%] [G loss: 0.897917]\n",
      "epoch:28 step:26968 [D loss: 0.671388, acc.: 54.69%] [G loss: 0.922143]\n",
      "epoch:28 step:26969 [D loss: 0.669660, acc.: 60.16%] [G loss: 0.949725]\n",
      "epoch:28 step:26970 [D loss: 0.639508, acc.: 64.06%] [G loss: 0.942078]\n",
      "epoch:28 step:26971 [D loss: 0.627910, acc.: 64.84%] [G loss: 0.956082]\n",
      "epoch:28 step:26972 [D loss: 0.656174, acc.: 57.81%] [G loss: 0.950224]\n",
      "epoch:28 step:26973 [D loss: 0.624769, acc.: 67.19%] [G loss: 0.923217]\n",
      "epoch:28 step:26974 [D loss: 0.680919, acc.: 53.12%] [G loss: 0.936491]\n",
      "epoch:28 step:26975 [D loss: 0.641044, acc.: 63.28%] [G loss: 0.907334]\n",
      "epoch:28 step:26976 [D loss: 0.667719, acc.: 53.91%] [G loss: 0.888525]\n",
      "epoch:28 step:26977 [D loss: 0.680199, acc.: 55.47%] [G loss: 0.910675]\n",
      "epoch:28 step:26978 [D loss: 0.703708, acc.: 54.69%] [G loss: 0.908227]\n",
      "epoch:28 step:26979 [D loss: 0.660382, acc.: 60.16%] [G loss: 0.841350]\n",
      "epoch:28 step:26980 [D loss: 0.651559, acc.: 62.50%] [G loss: 0.878309]\n",
      "epoch:28 step:26981 [D loss: 0.636399, acc.: 69.53%] [G loss: 0.927730]\n",
      "epoch:28 step:26982 [D loss: 0.654277, acc.: 59.38%] [G loss: 0.876716]\n",
      "epoch:28 step:26983 [D loss: 0.639303, acc.: 64.06%] [G loss: 0.896718]\n",
      "epoch:28 step:26984 [D loss: 0.643666, acc.: 60.16%] [G loss: 0.917680]\n",
      "epoch:28 step:26985 [D loss: 0.622700, acc.: 68.75%] [G loss: 0.950571]\n",
      "epoch:28 step:26986 [D loss: 0.624848, acc.: 64.84%] [G loss: 0.901105]\n",
      "epoch:28 step:26987 [D loss: 0.612154, acc.: 70.31%] [G loss: 0.884155]\n",
      "epoch:28 step:26988 [D loss: 0.634229, acc.: 65.62%] [G loss: 0.916300]\n",
      "epoch:28 step:26989 [D loss: 0.617146, acc.: 67.97%] [G loss: 0.898439]\n",
      "epoch:28 step:26990 [D loss: 0.646832, acc.: 64.06%] [G loss: 0.893304]\n",
      "epoch:28 step:26991 [D loss: 0.661723, acc.: 61.72%] [G loss: 0.875719]\n",
      "epoch:28 step:26992 [D loss: 0.668516, acc.: 60.94%] [G loss: 0.878445]\n",
      "epoch:28 step:26993 [D loss: 0.609744, acc.: 67.97%] [G loss: 0.897228]\n",
      "epoch:28 step:26994 [D loss: 0.609034, acc.: 66.41%] [G loss: 0.911582]\n",
      "epoch:28 step:26995 [D loss: 0.622710, acc.: 69.53%] [G loss: 0.880700]\n",
      "epoch:28 step:26996 [D loss: 0.653379, acc.: 65.62%] [G loss: 0.973147]\n",
      "epoch:28 step:26997 [D loss: 0.654894, acc.: 64.06%] [G loss: 0.947639]\n",
      "epoch:28 step:26998 [D loss: 0.641688, acc.: 64.06%] [G loss: 0.934707]\n",
      "epoch:28 step:26999 [D loss: 0.636978, acc.: 62.50%] [G loss: 0.938167]\n",
      "epoch:28 step:27000 [D loss: 0.599827, acc.: 73.44%] [G loss: 0.966920]\n",
      "##############\n",
      "[2.84211774 2.56192711 2.20645189 3.85680716 1.37735473 6.38299572\n",
      " 2.64061967 3.22531558 4.22727088 7.14868929]\n",
      "##########\n",
      "epoch:28 step:27001 [D loss: 0.677333, acc.: 54.69%] [G loss: 0.888664]\n",
      "epoch:28 step:27002 [D loss: 0.640905, acc.: 60.94%] [G loss: 0.925022]\n",
      "epoch:28 step:27003 [D loss: 0.645796, acc.: 57.03%] [G loss: 0.900789]\n",
      "epoch:28 step:27004 [D loss: 0.662993, acc.: 65.62%] [G loss: 1.001326]\n",
      "epoch:28 step:27005 [D loss: 0.652999, acc.: 62.50%] [G loss: 0.973723]\n",
      "epoch:28 step:27006 [D loss: 0.647112, acc.: 63.28%] [G loss: 0.905249]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:27007 [D loss: 0.674682, acc.: 59.38%] [G loss: 0.920365]\n",
      "epoch:28 step:27008 [D loss: 0.605695, acc.: 70.31%] [G loss: 0.904097]\n",
      "epoch:28 step:27009 [D loss: 0.683703, acc.: 55.47%] [G loss: 0.847218]\n",
      "epoch:28 step:27010 [D loss: 0.642892, acc.: 62.50%] [G loss: 0.913569]\n",
      "epoch:28 step:27011 [D loss: 0.630234, acc.: 64.84%] [G loss: 0.896792]\n",
      "epoch:28 step:27012 [D loss: 0.663163, acc.: 61.72%] [G loss: 0.978040]\n",
      "epoch:28 step:27013 [D loss: 0.637207, acc.: 63.28%] [G loss: 0.964601]\n",
      "epoch:28 step:27014 [D loss: 0.640904, acc.: 62.50%] [G loss: 0.983915]\n",
      "epoch:28 step:27015 [D loss: 0.637272, acc.: 64.84%] [G loss: 0.929769]\n",
      "epoch:28 step:27016 [D loss: 0.659594, acc.: 58.59%] [G loss: 0.918893]\n",
      "epoch:28 step:27017 [D loss: 0.666871, acc.: 64.84%] [G loss: 0.884880]\n",
      "epoch:28 step:27018 [D loss: 0.639499, acc.: 60.16%] [G loss: 0.933410]\n",
      "epoch:28 step:27019 [D loss: 0.668913, acc.: 57.03%] [G loss: 0.963768]\n",
      "epoch:28 step:27020 [D loss: 0.646212, acc.: 57.81%] [G loss: 0.902838]\n",
      "epoch:28 step:27021 [D loss: 0.637028, acc.: 64.84%] [G loss: 0.908186]\n",
      "epoch:28 step:27022 [D loss: 0.659948, acc.: 64.06%] [G loss: 0.875408]\n",
      "epoch:28 step:27023 [D loss: 0.654702, acc.: 60.16%] [G loss: 0.935867]\n",
      "epoch:28 step:27024 [D loss: 0.633697, acc.: 66.41%] [G loss: 0.863437]\n",
      "epoch:28 step:27025 [D loss: 0.646774, acc.: 64.06%] [G loss: 0.843448]\n",
      "epoch:28 step:27026 [D loss: 0.635358, acc.: 60.94%] [G loss: 0.932316]\n",
      "epoch:28 step:27027 [D loss: 0.605525, acc.: 67.19%] [G loss: 0.895804]\n",
      "epoch:28 step:27028 [D loss: 0.633175, acc.: 71.09%] [G loss: 0.882880]\n",
      "epoch:28 step:27029 [D loss: 0.615850, acc.: 64.84%] [G loss: 0.810547]\n",
      "epoch:28 step:27030 [D loss: 0.629836, acc.: 64.84%] [G loss: 0.912046]\n",
      "epoch:28 step:27031 [D loss: 0.680780, acc.: 57.03%] [G loss: 0.889120]\n",
      "epoch:28 step:27032 [D loss: 0.647988, acc.: 58.59%] [G loss: 0.912373]\n",
      "epoch:28 step:27033 [D loss: 0.660512, acc.: 57.81%] [G loss: 0.957738]\n",
      "epoch:28 step:27034 [D loss: 0.633896, acc.: 67.19%] [G loss: 1.006475]\n",
      "epoch:28 step:27035 [D loss: 0.662836, acc.: 60.94%] [G loss: 0.934811]\n",
      "epoch:28 step:27036 [D loss: 0.671079, acc.: 60.16%] [G loss: 0.946432]\n",
      "epoch:28 step:27037 [D loss: 0.646477, acc.: 58.59%] [G loss: 0.903064]\n",
      "epoch:28 step:27038 [D loss: 0.696228, acc.: 55.47%] [G loss: 0.959097]\n",
      "epoch:28 step:27039 [D loss: 0.701952, acc.: 53.91%] [G loss: 0.897506]\n",
      "epoch:28 step:27040 [D loss: 0.685964, acc.: 53.12%] [G loss: 0.877532]\n",
      "epoch:28 step:27041 [D loss: 0.654638, acc.: 60.16%] [G loss: 0.902021]\n",
      "epoch:28 step:27042 [D loss: 0.640976, acc.: 57.03%] [G loss: 0.898072]\n",
      "epoch:28 step:27043 [D loss: 0.664023, acc.: 55.47%] [G loss: 0.922258]\n",
      "epoch:28 step:27044 [D loss: 0.680966, acc.: 59.38%] [G loss: 0.892313]\n",
      "epoch:28 step:27045 [D loss: 0.638640, acc.: 62.50%] [G loss: 0.898805]\n",
      "epoch:28 step:27046 [D loss: 0.667536, acc.: 53.91%] [G loss: 0.841884]\n",
      "epoch:28 step:27047 [D loss: 0.671896, acc.: 58.59%] [G loss: 0.898003]\n",
      "epoch:28 step:27048 [D loss: 0.657223, acc.: 60.16%] [G loss: 0.886348]\n",
      "epoch:28 step:27049 [D loss: 0.630905, acc.: 66.41%] [G loss: 0.871388]\n",
      "epoch:28 step:27050 [D loss: 0.661083, acc.: 55.47%] [G loss: 0.867132]\n",
      "epoch:28 step:27051 [D loss: 0.642307, acc.: 61.72%] [G loss: 0.880772]\n",
      "epoch:28 step:27052 [D loss: 0.614491, acc.: 67.97%] [G loss: 0.863527]\n",
      "epoch:28 step:27053 [D loss: 0.690149, acc.: 60.16%] [G loss: 0.820093]\n",
      "epoch:28 step:27054 [D loss: 0.637529, acc.: 60.16%] [G loss: 0.859497]\n",
      "epoch:28 step:27055 [D loss: 0.693002, acc.: 54.69%] [G loss: 0.807359]\n",
      "epoch:28 step:27056 [D loss: 0.639210, acc.: 67.97%] [G loss: 0.913541]\n",
      "epoch:28 step:27057 [D loss: 0.637017, acc.: 62.50%] [G loss: 0.917462]\n",
      "epoch:28 step:27058 [D loss: 0.622775, acc.: 64.84%] [G loss: 0.855067]\n",
      "epoch:28 step:27059 [D loss: 0.682727, acc.: 60.94%] [G loss: 0.896060]\n",
      "epoch:28 step:27060 [D loss: 0.674641, acc.: 57.81%] [G loss: 0.907631]\n",
      "epoch:28 step:27061 [D loss: 0.689282, acc.: 49.22%] [G loss: 0.875796]\n",
      "epoch:28 step:27062 [D loss: 0.647444, acc.: 58.59%] [G loss: 0.924594]\n",
      "epoch:28 step:27063 [D loss: 0.677206, acc.: 55.47%] [G loss: 0.857479]\n",
      "epoch:28 step:27064 [D loss: 0.695159, acc.: 51.56%] [G loss: 0.887955]\n",
      "epoch:28 step:27065 [D loss: 0.641278, acc.: 64.84%] [G loss: 0.918524]\n",
      "epoch:28 step:27066 [D loss: 0.670009, acc.: 57.03%] [G loss: 0.879310]\n",
      "epoch:28 step:27067 [D loss: 0.680849, acc.: 51.56%] [G loss: 0.927846]\n",
      "epoch:28 step:27068 [D loss: 0.668618, acc.: 57.81%] [G loss: 0.930991]\n",
      "epoch:28 step:27069 [D loss: 0.674033, acc.: 57.03%] [G loss: 0.882219]\n",
      "epoch:28 step:27070 [D loss: 0.640545, acc.: 65.62%] [G loss: 0.876884]\n",
      "epoch:28 step:27071 [D loss: 0.691167, acc.: 59.38%] [G loss: 0.896131]\n",
      "epoch:28 step:27072 [D loss: 0.657278, acc.: 57.81%] [G loss: 0.934820]\n",
      "epoch:28 step:27073 [D loss: 0.673033, acc.: 55.47%] [G loss: 0.906160]\n",
      "epoch:28 step:27074 [D loss: 0.655749, acc.: 57.81%] [G loss: 0.866515]\n",
      "epoch:28 step:27075 [D loss: 0.605655, acc.: 71.09%] [G loss: 0.962365]\n",
      "epoch:28 step:27076 [D loss: 0.652950, acc.: 60.16%] [G loss: 0.969166]\n",
      "epoch:28 step:27077 [D loss: 0.652427, acc.: 60.16%] [G loss: 0.860550]\n",
      "epoch:28 step:27078 [D loss: 0.674209, acc.: 56.25%] [G loss: 0.881938]\n",
      "epoch:28 step:27079 [D loss: 0.711520, acc.: 54.69%] [G loss: 0.877690]\n",
      "epoch:28 step:27080 [D loss: 0.670490, acc.: 56.25%] [G loss: 0.862741]\n",
      "epoch:28 step:27081 [D loss: 0.669976, acc.: 61.72%] [G loss: 0.855944]\n",
      "epoch:28 step:27082 [D loss: 0.632779, acc.: 65.62%] [G loss: 0.913069]\n",
      "epoch:28 step:27083 [D loss: 0.660147, acc.: 60.16%] [G loss: 0.865452]\n",
      "epoch:28 step:27084 [D loss: 0.637459, acc.: 61.72%] [G loss: 0.790151]\n",
      "epoch:28 step:27085 [D loss: 0.648443, acc.: 64.06%] [G loss: 0.863042]\n",
      "epoch:28 step:27086 [D loss: 0.657433, acc.: 65.62%] [G loss: 0.890380]\n",
      "epoch:28 step:27087 [D loss: 0.671475, acc.: 55.47%] [G loss: 0.875873]\n",
      "epoch:28 step:27088 [D loss: 0.669438, acc.: 58.59%] [G loss: 0.926430]\n",
      "epoch:28 step:27089 [D loss: 0.640587, acc.: 58.59%] [G loss: 0.952011]\n",
      "epoch:28 step:27090 [D loss: 0.659957, acc.: 59.38%] [G loss: 0.880791]\n",
      "epoch:28 step:27091 [D loss: 0.692633, acc.: 52.34%] [G loss: 0.890686]\n",
      "epoch:28 step:27092 [D loss: 0.606138, acc.: 65.62%] [G loss: 0.890210]\n",
      "epoch:28 step:27093 [D loss: 0.666247, acc.: 65.62%] [G loss: 0.849822]\n",
      "epoch:28 step:27094 [D loss: 0.687109, acc.: 55.47%] [G loss: 0.912920]\n",
      "epoch:28 step:27095 [D loss: 0.704554, acc.: 54.69%] [G loss: 0.884077]\n",
      "epoch:28 step:27096 [D loss: 0.673377, acc.: 54.69%] [G loss: 0.894354]\n",
      "epoch:28 step:27097 [D loss: 0.622438, acc.: 64.84%] [G loss: 0.870450]\n",
      "epoch:28 step:27098 [D loss: 0.651092, acc.: 64.06%] [G loss: 0.891320]\n",
      "epoch:28 step:27099 [D loss: 0.647443, acc.: 64.84%] [G loss: 0.900625]\n",
      "epoch:28 step:27100 [D loss: 0.680112, acc.: 59.38%] [G loss: 0.858606]\n",
      "epoch:28 step:27101 [D loss: 0.630604, acc.: 64.84%] [G loss: 0.941892]\n",
      "epoch:28 step:27102 [D loss: 0.648783, acc.: 61.72%] [G loss: 0.953979]\n",
      "epoch:28 step:27103 [D loss: 0.679230, acc.: 60.94%] [G loss: 0.866593]\n",
      "epoch:28 step:27104 [D loss: 0.630470, acc.: 64.84%] [G loss: 0.855747]\n",
      "epoch:28 step:27105 [D loss: 0.621206, acc.: 66.41%] [G loss: 0.857520]\n",
      "epoch:28 step:27106 [D loss: 0.670067, acc.: 60.16%] [G loss: 0.852254]\n",
      "epoch:28 step:27107 [D loss: 0.649138, acc.: 59.38%] [G loss: 0.894392]\n",
      "epoch:28 step:27108 [D loss: 0.673283, acc.: 57.81%] [G loss: 0.922377]\n",
      "epoch:28 step:27109 [D loss: 0.655999, acc.: 60.94%] [G loss: 0.892728]\n",
      "epoch:28 step:27110 [D loss: 0.664226, acc.: 58.59%] [G loss: 0.943510]\n",
      "epoch:28 step:27111 [D loss: 0.626944, acc.: 67.19%] [G loss: 0.915059]\n",
      "epoch:28 step:27112 [D loss: 0.684470, acc.: 54.69%] [G loss: 0.907595]\n",
      "epoch:28 step:27113 [D loss: 0.659996, acc.: 57.81%] [G loss: 0.886539]\n",
      "epoch:28 step:27114 [D loss: 0.651580, acc.: 57.03%] [G loss: 0.932504]\n",
      "epoch:28 step:27115 [D loss: 0.665834, acc.: 57.03%] [G loss: 0.898051]\n",
      "epoch:28 step:27116 [D loss: 0.649732, acc.: 63.28%] [G loss: 0.939143]\n",
      "epoch:28 step:27117 [D loss: 0.676016, acc.: 56.25%] [G loss: 0.905288]\n",
      "epoch:28 step:27118 [D loss: 0.618400, acc.: 69.53%] [G loss: 0.927466]\n",
      "epoch:28 step:27119 [D loss: 0.617350, acc.: 70.31%] [G loss: 0.937409]\n",
      "epoch:28 step:27120 [D loss: 0.640200, acc.: 63.28%] [G loss: 0.943020]\n",
      "epoch:28 step:27121 [D loss: 0.671072, acc.: 53.91%] [G loss: 0.930956]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:28 step:27122 [D loss: 0.663808, acc.: 59.38%] [G loss: 0.858819]\n",
      "epoch:28 step:27123 [D loss: 0.612589, acc.: 67.97%] [G loss: 0.850469]\n",
      "epoch:28 step:27124 [D loss: 0.633292, acc.: 64.06%] [G loss: 0.887521]\n",
      "epoch:28 step:27125 [D loss: 0.645725, acc.: 60.94%] [G loss: 0.854469]\n",
      "epoch:28 step:27126 [D loss: 0.659121, acc.: 59.38%] [G loss: 0.944997]\n",
      "epoch:28 step:27127 [D loss: 0.710993, acc.: 52.34%] [G loss: 0.910146]\n",
      "epoch:28 step:27128 [D loss: 0.664907, acc.: 60.16%] [G loss: 0.926562]\n",
      "epoch:28 step:27129 [D loss: 0.682518, acc.: 59.38%] [G loss: 0.971196]\n",
      "epoch:28 step:27130 [D loss: 0.674016, acc.: 54.69%] [G loss: 0.842633]\n",
      "epoch:28 step:27131 [D loss: 0.620675, acc.: 61.72%] [G loss: 0.910551]\n",
      "epoch:28 step:27132 [D loss: 0.642962, acc.: 61.72%] [G loss: 0.899136]\n",
      "epoch:28 step:27133 [D loss: 0.663307, acc.: 57.81%] [G loss: 0.859935]\n",
      "epoch:28 step:27134 [D loss: 0.668743, acc.: 56.25%] [G loss: 0.873855]\n",
      "epoch:28 step:27135 [D loss: 0.652099, acc.: 61.72%] [G loss: 0.807676]\n",
      "epoch:28 step:27136 [D loss: 0.673730, acc.: 58.59%] [G loss: 0.919274]\n",
      "epoch:28 step:27137 [D loss: 0.645695, acc.: 64.06%] [G loss: 0.971048]\n",
      "epoch:28 step:27138 [D loss: 0.639189, acc.: 59.38%] [G loss: 0.847692]\n",
      "epoch:28 step:27139 [D loss: 0.611865, acc.: 67.97%] [G loss: 0.895864]\n",
      "epoch:28 step:27140 [D loss: 0.626814, acc.: 66.41%] [G loss: 0.955339]\n",
      "epoch:28 step:27141 [D loss: 0.710339, acc.: 53.12%] [G loss: 0.931694]\n",
      "epoch:28 step:27142 [D loss: 0.602020, acc.: 68.75%] [G loss: 0.899585]\n",
      "epoch:28 step:27143 [D loss: 0.720325, acc.: 47.66%] [G loss: 0.887687]\n",
      "epoch:28 step:27144 [D loss: 0.666429, acc.: 57.81%] [G loss: 0.904796]\n",
      "epoch:28 step:27145 [D loss: 0.673434, acc.: 53.91%] [G loss: 0.878556]\n",
      "epoch:28 step:27146 [D loss: 0.696130, acc.: 52.34%] [G loss: 0.911985]\n",
      "epoch:28 step:27147 [D loss: 0.668896, acc.: 56.25%] [G loss: 0.921201]\n",
      "epoch:28 step:27148 [D loss: 0.647602, acc.: 64.84%] [G loss: 0.896073]\n",
      "epoch:28 step:27149 [D loss: 0.679448, acc.: 57.81%] [G loss: 0.900875]\n",
      "epoch:28 step:27150 [D loss: 0.674528, acc.: 61.72%] [G loss: 0.886725]\n",
      "epoch:28 step:27151 [D loss: 0.641368, acc.: 60.94%] [G loss: 0.901313]\n",
      "epoch:28 step:27152 [D loss: 0.631822, acc.: 64.84%] [G loss: 0.897509]\n",
      "epoch:28 step:27153 [D loss: 0.622543, acc.: 66.41%] [G loss: 0.905207]\n",
      "epoch:28 step:27154 [D loss: 0.643894, acc.: 59.38%] [G loss: 0.923842]\n",
      "epoch:28 step:27155 [D loss: 0.654771, acc.: 60.16%] [G loss: 0.911442]\n",
      "epoch:28 step:27156 [D loss: 0.642346, acc.: 63.28%] [G loss: 0.909825]\n",
      "epoch:28 step:27157 [D loss: 0.685932, acc.: 58.59%] [G loss: 0.861973]\n",
      "epoch:28 step:27158 [D loss: 0.682628, acc.: 58.59%] [G loss: 0.865549]\n",
      "epoch:28 step:27159 [D loss: 0.686986, acc.: 51.56%] [G loss: 0.884981]\n",
      "epoch:28 step:27160 [D loss: 0.665698, acc.: 58.59%] [G loss: 0.803267]\n",
      "epoch:28 step:27161 [D loss: 0.646613, acc.: 63.28%] [G loss: 0.882751]\n",
      "epoch:28 step:27162 [D loss: 0.667543, acc.: 57.03%] [G loss: 0.954362]\n",
      "epoch:28 step:27163 [D loss: 0.656321, acc.: 58.59%] [G loss: 0.896946]\n",
      "epoch:28 step:27164 [D loss: 0.634648, acc.: 60.94%] [G loss: 0.903356]\n",
      "epoch:28 step:27165 [D loss: 0.693544, acc.: 55.47%] [G loss: 0.896352]\n",
      "epoch:28 step:27166 [D loss: 0.622461, acc.: 67.19%] [G loss: 0.991791]\n",
      "epoch:28 step:27167 [D loss: 0.660765, acc.: 56.25%] [G loss: 0.924794]\n",
      "epoch:28 step:27168 [D loss: 0.633066, acc.: 60.94%] [G loss: 0.886308]\n",
      "epoch:28 step:27169 [D loss: 0.673480, acc.: 57.81%] [G loss: 0.897317]\n",
      "epoch:28 step:27170 [D loss: 0.639906, acc.: 64.06%] [G loss: 0.873407]\n",
      "epoch:28 step:27171 [D loss: 0.635107, acc.: 62.50%] [G loss: 0.871896]\n",
      "epoch:28 step:27172 [D loss: 0.637458, acc.: 60.16%] [G loss: 0.874640]\n",
      "epoch:28 step:27173 [D loss: 0.614206, acc.: 65.62%] [G loss: 0.835992]\n",
      "epoch:29 step:27174 [D loss: 0.658082, acc.: 59.38%] [G loss: 0.898080]\n",
      "epoch:29 step:27175 [D loss: 0.638741, acc.: 64.84%] [G loss: 0.881494]\n",
      "epoch:29 step:27176 [D loss: 0.637813, acc.: 64.06%] [G loss: 0.917397]\n",
      "epoch:29 step:27177 [D loss: 0.685424, acc.: 57.03%] [G loss: 0.955412]\n",
      "epoch:29 step:27178 [D loss: 0.672757, acc.: 57.03%] [G loss: 0.873362]\n",
      "epoch:29 step:27179 [D loss: 0.630594, acc.: 63.28%] [G loss: 0.891193]\n",
      "epoch:29 step:27180 [D loss: 0.638143, acc.: 62.50%] [G loss: 0.940963]\n",
      "epoch:29 step:27181 [D loss: 0.690626, acc.: 52.34%] [G loss: 0.961653]\n",
      "epoch:29 step:27182 [D loss: 0.632549, acc.: 67.19%] [G loss: 0.892954]\n",
      "epoch:29 step:27183 [D loss: 0.649786, acc.: 59.38%] [G loss: 0.906631]\n",
      "epoch:29 step:27184 [D loss: 0.641202, acc.: 60.94%] [G loss: 0.961947]\n",
      "epoch:29 step:27185 [D loss: 0.631022, acc.: 63.28%] [G loss: 0.906747]\n",
      "epoch:29 step:27186 [D loss: 0.636248, acc.: 61.72%] [G loss: 0.903887]\n",
      "epoch:29 step:27187 [D loss: 0.640407, acc.: 65.62%] [G loss: 0.893837]\n",
      "epoch:29 step:27188 [D loss: 0.667643, acc.: 57.81%] [G loss: 0.873377]\n",
      "epoch:29 step:27189 [D loss: 0.650926, acc.: 59.38%] [G loss: 0.912005]\n",
      "epoch:29 step:27190 [D loss: 0.639306, acc.: 57.81%] [G loss: 0.910550]\n",
      "epoch:29 step:27191 [D loss: 0.632026, acc.: 64.06%] [G loss: 0.873545]\n",
      "epoch:29 step:27192 [D loss: 0.650727, acc.: 57.03%] [G loss: 0.901053]\n",
      "epoch:29 step:27193 [D loss: 0.624037, acc.: 61.72%] [G loss: 0.958226]\n",
      "epoch:29 step:27194 [D loss: 0.659320, acc.: 62.50%] [G loss: 0.944383]\n",
      "epoch:29 step:27195 [D loss: 0.726183, acc.: 53.91%] [G loss: 0.940112]\n",
      "epoch:29 step:27196 [D loss: 0.655469, acc.: 64.06%] [G loss: 1.040913]\n",
      "epoch:29 step:27197 [D loss: 0.638531, acc.: 68.75%] [G loss: 0.923558]\n",
      "epoch:29 step:27198 [D loss: 0.618687, acc.: 64.06%] [G loss: 0.954211]\n",
      "epoch:29 step:27199 [D loss: 0.662190, acc.: 58.59%] [G loss: 0.985357]\n",
      "epoch:29 step:27200 [D loss: 0.628889, acc.: 61.72%] [G loss: 0.949523]\n",
      "##############\n",
      "[3.01527753 2.35672089 2.49488861 3.57623966 1.30241225 7.93026173\n",
      " 2.76904412 3.82145711 4.30399758 5.78050446]\n",
      "##########\n",
      "epoch:29 step:27201 [D loss: 0.655060, acc.: 62.50%] [G loss: 0.915248]\n",
      "epoch:29 step:27202 [D loss: 0.662417, acc.: 61.72%] [G loss: 0.802179]\n",
      "epoch:29 step:27203 [D loss: 0.671350, acc.: 57.81%] [G loss: 0.859711]\n",
      "epoch:29 step:27204 [D loss: 0.629419, acc.: 66.41%] [G loss: 0.845430]\n",
      "epoch:29 step:27205 [D loss: 0.614351, acc.: 64.84%] [G loss: 0.902876]\n",
      "epoch:29 step:27206 [D loss: 0.643991, acc.: 60.94%] [G loss: 0.872371]\n",
      "epoch:29 step:27207 [D loss: 0.668419, acc.: 63.28%] [G loss: 0.887879]\n",
      "epoch:29 step:27208 [D loss: 0.709749, acc.: 48.44%] [G loss: 0.858445]\n",
      "epoch:29 step:27209 [D loss: 0.638727, acc.: 62.50%] [G loss: 0.891183]\n",
      "epoch:29 step:27210 [D loss: 0.643198, acc.: 60.94%] [G loss: 0.884813]\n",
      "epoch:29 step:27211 [D loss: 0.668482, acc.: 56.25%] [G loss: 0.852596]\n",
      "epoch:29 step:27212 [D loss: 0.666820, acc.: 53.91%] [G loss: 0.917749]\n",
      "epoch:29 step:27213 [D loss: 0.673304, acc.: 58.59%] [G loss: 0.891092]\n",
      "epoch:29 step:27214 [D loss: 0.701268, acc.: 57.03%] [G loss: 0.919703]\n",
      "epoch:29 step:27215 [D loss: 0.692465, acc.: 55.47%] [G loss: 0.851863]\n",
      "epoch:29 step:27216 [D loss: 0.667696, acc.: 61.72%] [G loss: 0.952352]\n",
      "epoch:29 step:27217 [D loss: 0.629159, acc.: 66.41%] [G loss: 0.947621]\n",
      "epoch:29 step:27218 [D loss: 0.664791, acc.: 58.59%] [G loss: 0.886050]\n",
      "epoch:29 step:27219 [D loss: 0.647111, acc.: 59.38%] [G loss: 0.935721]\n",
      "epoch:29 step:27220 [D loss: 0.680773, acc.: 52.34%] [G loss: 0.907294]\n",
      "epoch:29 step:27221 [D loss: 0.653630, acc.: 63.28%] [G loss: 0.926304]\n",
      "epoch:29 step:27222 [D loss: 0.666775, acc.: 58.59%] [G loss: 0.891375]\n",
      "epoch:29 step:27223 [D loss: 0.643773, acc.: 57.81%] [G loss: 0.838202]\n",
      "epoch:29 step:27224 [D loss: 0.670153, acc.: 58.59%] [G loss: 0.808557]\n",
      "epoch:29 step:27225 [D loss: 0.616356, acc.: 65.62%] [G loss: 0.840068]\n",
      "epoch:29 step:27226 [D loss: 0.661765, acc.: 60.94%] [G loss: 0.875816]\n",
      "epoch:29 step:27227 [D loss: 0.627589, acc.: 62.50%] [G loss: 0.902560]\n",
      "epoch:29 step:27228 [D loss: 0.649337, acc.: 57.03%] [G loss: 0.888063]\n",
      "epoch:29 step:27229 [D loss: 0.692298, acc.: 59.38%] [G loss: 0.835276]\n",
      "epoch:29 step:27230 [D loss: 0.661358, acc.: 59.38%] [G loss: 0.894535]\n",
      "epoch:29 step:27231 [D loss: 0.651596, acc.: 65.62%] [G loss: 0.897059]\n",
      "epoch:29 step:27232 [D loss: 0.646351, acc.: 63.28%] [G loss: 0.930709]\n",
      "epoch:29 step:27233 [D loss: 0.610949, acc.: 69.53%] [G loss: 0.907950]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27234 [D loss: 0.636800, acc.: 66.41%] [G loss: 0.941098]\n",
      "epoch:29 step:27235 [D loss: 0.632027, acc.: 63.28%] [G loss: 0.887300]\n",
      "epoch:29 step:27236 [D loss: 0.631259, acc.: 61.72%] [G loss: 0.894789]\n",
      "epoch:29 step:27237 [D loss: 0.632880, acc.: 58.59%] [G loss: 0.921389]\n",
      "epoch:29 step:27238 [D loss: 0.659712, acc.: 61.72%] [G loss: 0.897498]\n",
      "epoch:29 step:27239 [D loss: 0.639674, acc.: 68.75%] [G loss: 0.890933]\n",
      "epoch:29 step:27240 [D loss: 0.666614, acc.: 58.59%] [G loss: 0.858055]\n",
      "epoch:29 step:27241 [D loss: 0.624443, acc.: 67.97%] [G loss: 0.887520]\n",
      "epoch:29 step:27242 [D loss: 0.673924, acc.: 57.03%] [G loss: 0.980605]\n",
      "epoch:29 step:27243 [D loss: 0.644921, acc.: 60.16%] [G loss: 0.980772]\n",
      "epoch:29 step:27244 [D loss: 0.625481, acc.: 64.84%] [G loss: 0.942420]\n",
      "epoch:29 step:27245 [D loss: 0.674673, acc.: 57.03%] [G loss: 0.869001]\n",
      "epoch:29 step:27246 [D loss: 0.617694, acc.: 63.28%] [G loss: 0.937007]\n",
      "epoch:29 step:27247 [D loss: 0.672165, acc.: 60.94%] [G loss: 0.896924]\n",
      "epoch:29 step:27248 [D loss: 0.652317, acc.: 63.28%] [G loss: 0.881402]\n",
      "epoch:29 step:27249 [D loss: 0.627059, acc.: 65.62%] [G loss: 0.875374]\n",
      "epoch:29 step:27250 [D loss: 0.694172, acc.: 53.91%] [G loss: 0.897303]\n",
      "epoch:29 step:27251 [D loss: 0.671984, acc.: 54.69%] [G loss: 0.849692]\n",
      "epoch:29 step:27252 [D loss: 0.670905, acc.: 59.38%] [G loss: 0.897312]\n",
      "epoch:29 step:27253 [D loss: 0.661074, acc.: 60.16%] [G loss: 0.916162]\n",
      "epoch:29 step:27254 [D loss: 0.665708, acc.: 57.81%] [G loss: 0.882456]\n",
      "epoch:29 step:27255 [D loss: 0.661707, acc.: 60.16%] [G loss: 0.958816]\n",
      "epoch:29 step:27256 [D loss: 0.641014, acc.: 63.28%] [G loss: 1.023938]\n",
      "epoch:29 step:27257 [D loss: 0.662153, acc.: 57.03%] [G loss: 0.970134]\n",
      "epoch:29 step:27258 [D loss: 0.657931, acc.: 56.25%] [G loss: 0.978134]\n",
      "epoch:29 step:27259 [D loss: 0.656828, acc.: 60.16%] [G loss: 0.922206]\n",
      "epoch:29 step:27260 [D loss: 0.636321, acc.: 67.97%] [G loss: 0.949138]\n",
      "epoch:29 step:27261 [D loss: 0.671524, acc.: 64.06%] [G loss: 0.964553]\n",
      "epoch:29 step:27262 [D loss: 0.612975, acc.: 71.88%] [G loss: 0.935574]\n",
      "epoch:29 step:27263 [D loss: 0.654276, acc.: 59.38%] [G loss: 0.876880]\n",
      "epoch:29 step:27264 [D loss: 0.687038, acc.: 58.59%] [G loss: 0.919052]\n",
      "epoch:29 step:27265 [D loss: 0.667780, acc.: 60.94%] [G loss: 0.935437]\n",
      "epoch:29 step:27266 [D loss: 0.687110, acc.: 57.81%] [G loss: 0.932431]\n",
      "epoch:29 step:27267 [D loss: 0.649696, acc.: 60.94%] [G loss: 0.879320]\n",
      "epoch:29 step:27268 [D loss: 0.679075, acc.: 60.94%] [G loss: 0.821040]\n",
      "epoch:29 step:27269 [D loss: 0.658703, acc.: 59.38%] [G loss: 0.875640]\n",
      "epoch:29 step:27270 [D loss: 0.647800, acc.: 67.19%] [G loss: 0.897682]\n",
      "epoch:29 step:27271 [D loss: 0.638713, acc.: 63.28%] [G loss: 0.908487]\n",
      "epoch:29 step:27272 [D loss: 0.658639, acc.: 59.38%] [G loss: 0.877313]\n",
      "epoch:29 step:27273 [D loss: 0.623306, acc.: 65.62%] [G loss: 0.952003]\n",
      "epoch:29 step:27274 [D loss: 0.616891, acc.: 66.41%] [G loss: 0.977772]\n",
      "epoch:29 step:27275 [D loss: 0.686811, acc.: 60.94%] [G loss: 0.861332]\n",
      "epoch:29 step:27276 [D loss: 0.637849, acc.: 62.50%] [G loss: 0.898865]\n",
      "epoch:29 step:27277 [D loss: 0.665829, acc.: 53.91%] [G loss: 0.868814]\n",
      "epoch:29 step:27278 [D loss: 0.625943, acc.: 67.19%] [G loss: 0.803512]\n",
      "epoch:29 step:27279 [D loss: 0.602874, acc.: 67.19%] [G loss: 0.912807]\n",
      "epoch:29 step:27280 [D loss: 0.652938, acc.: 62.50%] [G loss: 0.882276]\n",
      "epoch:29 step:27281 [D loss: 0.678128, acc.: 57.81%] [G loss: 0.911504]\n",
      "epoch:29 step:27282 [D loss: 0.628730, acc.: 66.41%] [G loss: 0.910907]\n",
      "epoch:29 step:27283 [D loss: 0.673530, acc.: 60.16%] [G loss: 0.883718]\n",
      "epoch:29 step:27284 [D loss: 0.708857, acc.: 51.56%] [G loss: 0.918265]\n",
      "epoch:29 step:27285 [D loss: 0.684208, acc.: 60.16%] [G loss: 0.856616]\n",
      "epoch:29 step:27286 [D loss: 0.608125, acc.: 67.19%] [G loss: 0.859739]\n",
      "epoch:29 step:27287 [D loss: 0.657077, acc.: 58.59%] [G loss: 0.941520]\n",
      "epoch:29 step:27288 [D loss: 0.643625, acc.: 65.62%] [G loss: 0.878378]\n",
      "epoch:29 step:27289 [D loss: 0.647257, acc.: 64.06%] [G loss: 0.901116]\n",
      "epoch:29 step:27290 [D loss: 0.693686, acc.: 57.03%] [G loss: 0.862476]\n",
      "epoch:29 step:27291 [D loss: 0.666771, acc.: 60.16%] [G loss: 0.870770]\n",
      "epoch:29 step:27292 [D loss: 0.664378, acc.: 59.38%] [G loss: 0.875403]\n",
      "epoch:29 step:27293 [D loss: 0.694053, acc.: 52.34%] [G loss: 0.858010]\n",
      "epoch:29 step:27294 [D loss: 0.642143, acc.: 61.72%] [G loss: 0.861530]\n",
      "epoch:29 step:27295 [D loss: 0.676605, acc.: 59.38%] [G loss: 0.914461]\n",
      "epoch:29 step:27296 [D loss: 0.649829, acc.: 63.28%] [G loss: 0.804793]\n",
      "epoch:29 step:27297 [D loss: 0.679102, acc.: 57.81%] [G loss: 0.870347]\n",
      "epoch:29 step:27298 [D loss: 0.640474, acc.: 63.28%] [G loss: 0.950906]\n",
      "epoch:29 step:27299 [D loss: 0.663629, acc.: 56.25%] [G loss: 0.867915]\n",
      "epoch:29 step:27300 [D loss: 0.630761, acc.: 67.19%] [G loss: 0.897772]\n",
      "epoch:29 step:27301 [D loss: 0.661762, acc.: 58.59%] [G loss: 0.886082]\n",
      "epoch:29 step:27302 [D loss: 0.633772, acc.: 59.38%] [G loss: 0.949641]\n",
      "epoch:29 step:27303 [D loss: 0.636896, acc.: 64.84%] [G loss: 0.936794]\n",
      "epoch:29 step:27304 [D loss: 0.621026, acc.: 65.62%] [G loss: 0.906318]\n",
      "epoch:29 step:27305 [D loss: 0.692831, acc.: 54.69%] [G loss: 0.896766]\n",
      "epoch:29 step:27306 [D loss: 0.686950, acc.: 57.81%] [G loss: 0.907756]\n",
      "epoch:29 step:27307 [D loss: 0.662511, acc.: 58.59%] [G loss: 0.815731]\n",
      "epoch:29 step:27308 [D loss: 0.672695, acc.: 57.81%] [G loss: 0.857614]\n",
      "epoch:29 step:27309 [D loss: 0.655129, acc.: 63.28%] [G loss: 0.808688]\n",
      "epoch:29 step:27310 [D loss: 0.631808, acc.: 67.19%] [G loss: 0.898243]\n",
      "epoch:29 step:27311 [D loss: 0.688463, acc.: 57.81%] [G loss: 0.850044]\n",
      "epoch:29 step:27312 [D loss: 0.631952, acc.: 65.62%] [G loss: 0.918983]\n",
      "epoch:29 step:27313 [D loss: 0.626073, acc.: 64.06%] [G loss: 0.931487]\n",
      "epoch:29 step:27314 [D loss: 0.665449, acc.: 59.38%] [G loss: 0.908029]\n",
      "epoch:29 step:27315 [D loss: 0.641092, acc.: 57.81%] [G loss: 0.860529]\n",
      "epoch:29 step:27316 [D loss: 0.646491, acc.: 66.41%] [G loss: 0.913758]\n",
      "epoch:29 step:27317 [D loss: 0.626859, acc.: 66.41%] [G loss: 0.888721]\n",
      "epoch:29 step:27318 [D loss: 0.672793, acc.: 60.94%] [G loss: 0.961246]\n",
      "epoch:29 step:27319 [D loss: 0.641273, acc.: 65.62%] [G loss: 0.961272]\n",
      "epoch:29 step:27320 [D loss: 0.659513, acc.: 57.03%] [G loss: 0.922876]\n",
      "epoch:29 step:27321 [D loss: 0.647406, acc.: 64.84%] [G loss: 0.881778]\n",
      "epoch:29 step:27322 [D loss: 0.648393, acc.: 60.16%] [G loss: 0.882391]\n",
      "epoch:29 step:27323 [D loss: 0.685996, acc.: 51.56%] [G loss: 0.864688]\n",
      "epoch:29 step:27324 [D loss: 0.651921, acc.: 58.59%] [G loss: 0.901284]\n",
      "epoch:29 step:27325 [D loss: 0.672483, acc.: 56.25%] [G loss: 0.906179]\n",
      "epoch:29 step:27326 [D loss: 0.617458, acc.: 70.31%] [G loss: 0.929362]\n",
      "epoch:29 step:27327 [D loss: 0.623012, acc.: 66.41%] [G loss: 0.879703]\n",
      "epoch:29 step:27328 [D loss: 0.643751, acc.: 63.28%] [G loss: 0.867739]\n",
      "epoch:29 step:27329 [D loss: 0.652836, acc.: 56.25%] [G loss: 0.927706]\n",
      "epoch:29 step:27330 [D loss: 0.648994, acc.: 60.16%] [G loss: 0.862240]\n",
      "epoch:29 step:27331 [D loss: 0.649453, acc.: 62.50%] [G loss: 0.878126]\n",
      "epoch:29 step:27332 [D loss: 0.621243, acc.: 66.41%] [G loss: 0.912492]\n",
      "epoch:29 step:27333 [D loss: 0.659862, acc.: 57.81%] [G loss: 0.916152]\n",
      "epoch:29 step:27334 [D loss: 0.633812, acc.: 62.50%] [G loss: 0.882470]\n",
      "epoch:29 step:27335 [D loss: 0.645739, acc.: 62.50%] [G loss: 0.903955]\n",
      "epoch:29 step:27336 [D loss: 0.694504, acc.: 56.25%] [G loss: 0.971540]\n",
      "epoch:29 step:27337 [D loss: 0.686621, acc.: 53.12%] [G loss: 0.929440]\n",
      "epoch:29 step:27338 [D loss: 0.648333, acc.: 67.19%] [G loss: 0.890318]\n",
      "epoch:29 step:27339 [D loss: 0.630512, acc.: 62.50%] [G loss: 0.892046]\n",
      "epoch:29 step:27340 [D loss: 0.653310, acc.: 60.94%] [G loss: 0.802252]\n",
      "epoch:29 step:27341 [D loss: 0.639610, acc.: 63.28%] [G loss: 0.856561]\n",
      "epoch:29 step:27342 [D loss: 0.639559, acc.: 62.50%] [G loss: 0.850318]\n",
      "epoch:29 step:27343 [D loss: 0.652400, acc.: 60.16%] [G loss: 0.843541]\n",
      "epoch:29 step:27344 [D loss: 0.661539, acc.: 62.50%] [G loss: 0.883574]\n",
      "epoch:29 step:27345 [D loss: 0.683780, acc.: 54.69%] [G loss: 0.895944]\n",
      "epoch:29 step:27346 [D loss: 0.662840, acc.: 59.38%] [G loss: 0.937726]\n",
      "epoch:29 step:27347 [D loss: 0.639835, acc.: 65.62%] [G loss: 0.894412]\n",
      "epoch:29 step:27348 [D loss: 0.676639, acc.: 56.25%] [G loss: 0.937890]\n",
      "epoch:29 step:27349 [D loss: 0.591818, acc.: 73.44%] [G loss: 0.970329]\n",
      "epoch:29 step:27350 [D loss: 0.630239, acc.: 64.06%] [G loss: 0.915021]\n",
      "epoch:29 step:27351 [D loss: 0.644752, acc.: 65.62%] [G loss: 0.860255]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27352 [D loss: 0.671217, acc.: 53.12%] [G loss: 0.880648]\n",
      "epoch:29 step:27353 [D loss: 0.641189, acc.: 65.62%] [G loss: 0.938983]\n",
      "epoch:29 step:27354 [D loss: 0.677607, acc.: 56.25%] [G loss: 0.911421]\n",
      "epoch:29 step:27355 [D loss: 0.638054, acc.: 65.62%] [G loss: 0.896192]\n",
      "epoch:29 step:27356 [D loss: 0.614267, acc.: 67.19%] [G loss: 0.921802]\n",
      "epoch:29 step:27357 [D loss: 0.637668, acc.: 66.41%] [G loss: 0.907719]\n",
      "epoch:29 step:27358 [D loss: 0.660477, acc.: 57.81%] [G loss: 0.936781]\n",
      "epoch:29 step:27359 [D loss: 0.646082, acc.: 60.94%] [G loss: 0.878093]\n",
      "epoch:29 step:27360 [D loss: 0.610239, acc.: 70.31%] [G loss: 0.883989]\n",
      "epoch:29 step:27361 [D loss: 0.666033, acc.: 59.38%] [G loss: 0.927724]\n",
      "epoch:29 step:27362 [D loss: 0.656114, acc.: 61.72%] [G loss: 0.885671]\n",
      "epoch:29 step:27363 [D loss: 0.646529, acc.: 61.72%] [G loss: 0.883910]\n",
      "epoch:29 step:27364 [D loss: 0.642032, acc.: 59.38%] [G loss: 0.878098]\n",
      "epoch:29 step:27365 [D loss: 0.657688, acc.: 66.41%] [G loss: 0.897388]\n",
      "epoch:29 step:27366 [D loss: 0.571762, acc.: 74.22%] [G loss: 0.925571]\n",
      "epoch:29 step:27367 [D loss: 0.640614, acc.: 64.06%] [G loss: 0.951110]\n",
      "epoch:29 step:27368 [D loss: 0.639646, acc.: 60.16%] [G loss: 0.899132]\n",
      "epoch:29 step:27369 [D loss: 0.649935, acc.: 59.38%] [G loss: 0.947041]\n",
      "epoch:29 step:27370 [D loss: 0.640835, acc.: 61.72%] [G loss: 0.926934]\n",
      "epoch:29 step:27371 [D loss: 0.631314, acc.: 66.41%] [G loss: 0.836732]\n",
      "epoch:29 step:27372 [D loss: 0.598877, acc.: 70.31%] [G loss: 0.959237]\n",
      "epoch:29 step:27373 [D loss: 0.660399, acc.: 60.16%] [G loss: 0.897397]\n",
      "epoch:29 step:27374 [D loss: 0.636260, acc.: 64.06%] [G loss: 0.898940]\n",
      "epoch:29 step:27375 [D loss: 0.620111, acc.: 66.41%] [G loss: 0.940180]\n",
      "epoch:29 step:27376 [D loss: 0.658541, acc.: 64.06%] [G loss: 0.940299]\n",
      "epoch:29 step:27377 [D loss: 0.636279, acc.: 60.94%] [G loss: 0.919886]\n",
      "epoch:29 step:27378 [D loss: 0.698418, acc.: 61.72%] [G loss: 0.879147]\n",
      "epoch:29 step:27379 [D loss: 0.665730, acc.: 55.47%] [G loss: 0.853728]\n",
      "epoch:29 step:27380 [D loss: 0.661105, acc.: 60.16%] [G loss: 0.922794]\n",
      "epoch:29 step:27381 [D loss: 0.661620, acc.: 60.94%] [G loss: 0.952759]\n",
      "epoch:29 step:27382 [D loss: 0.645907, acc.: 64.06%] [G loss: 0.977229]\n",
      "epoch:29 step:27383 [D loss: 0.644195, acc.: 63.28%] [G loss: 0.908474]\n",
      "epoch:29 step:27384 [D loss: 0.645654, acc.: 63.28%] [G loss: 0.921632]\n",
      "epoch:29 step:27385 [D loss: 0.622501, acc.: 64.84%] [G loss: 0.947668]\n",
      "epoch:29 step:27386 [D loss: 0.706469, acc.: 51.56%] [G loss: 0.905780]\n",
      "epoch:29 step:27387 [D loss: 0.667178, acc.: 61.72%] [G loss: 0.925968]\n",
      "epoch:29 step:27388 [D loss: 0.643998, acc.: 64.84%] [G loss: 0.914133]\n",
      "epoch:29 step:27389 [D loss: 0.669673, acc.: 53.91%] [G loss: 0.983830]\n",
      "epoch:29 step:27390 [D loss: 0.600254, acc.: 66.41%] [G loss: 0.905648]\n",
      "epoch:29 step:27391 [D loss: 0.659463, acc.: 60.94%] [G loss: 0.973137]\n",
      "epoch:29 step:27392 [D loss: 0.720971, acc.: 53.91%] [G loss: 0.889153]\n",
      "epoch:29 step:27393 [D loss: 0.624374, acc.: 62.50%] [G loss: 0.894659]\n",
      "epoch:29 step:27394 [D loss: 0.651605, acc.: 64.06%] [G loss: 0.890125]\n",
      "epoch:29 step:27395 [D loss: 0.674001, acc.: 57.03%] [G loss: 0.859359]\n",
      "epoch:29 step:27396 [D loss: 0.644134, acc.: 64.06%] [G loss: 0.917529]\n",
      "epoch:29 step:27397 [D loss: 0.686080, acc.: 52.34%] [G loss: 0.866624]\n",
      "epoch:29 step:27398 [D loss: 0.664125, acc.: 60.16%] [G loss: 0.885942]\n",
      "epoch:29 step:27399 [D loss: 0.643664, acc.: 60.94%] [G loss: 0.920120]\n",
      "epoch:29 step:27400 [D loss: 0.674169, acc.: 60.16%] [G loss: 0.822930]\n",
      "##############\n",
      "[2.94342908 2.55291159 2.28184407 4.18296113 1.16014369 9.27288612\n",
      " 2.2791387  2.81484947 4.06290723 6.65906357]\n",
      "##########\n",
      "epoch:29 step:27401 [D loss: 0.692669, acc.: 56.25%] [G loss: 0.830606]\n",
      "epoch:29 step:27402 [D loss: 0.622203, acc.: 67.19%] [G loss: 0.869711]\n",
      "epoch:29 step:27403 [D loss: 0.661863, acc.: 57.81%] [G loss: 0.911732]\n",
      "epoch:29 step:27404 [D loss: 0.663453, acc.: 58.59%] [G loss: 0.889108]\n",
      "epoch:29 step:27405 [D loss: 0.645728, acc.: 67.97%] [G loss: 0.975544]\n",
      "epoch:29 step:27406 [D loss: 0.643201, acc.: 64.06%] [G loss: 0.960473]\n",
      "epoch:29 step:27407 [D loss: 0.686645, acc.: 57.03%] [G loss: 0.923785]\n",
      "epoch:29 step:27408 [D loss: 0.639782, acc.: 66.41%] [G loss: 0.931389]\n",
      "epoch:29 step:27409 [D loss: 0.650016, acc.: 60.16%] [G loss: 0.914063]\n",
      "epoch:29 step:27410 [D loss: 0.685608, acc.: 60.94%] [G loss: 0.908027]\n",
      "epoch:29 step:27411 [D loss: 0.679914, acc.: 55.47%] [G loss: 0.891566]\n",
      "epoch:29 step:27412 [D loss: 0.673272, acc.: 57.81%] [G loss: 0.847817]\n",
      "epoch:29 step:27413 [D loss: 0.648423, acc.: 61.72%] [G loss: 0.914257]\n",
      "epoch:29 step:27414 [D loss: 0.657735, acc.: 64.84%] [G loss: 0.880635]\n",
      "epoch:29 step:27415 [D loss: 0.649504, acc.: 60.94%] [G loss: 0.899088]\n",
      "epoch:29 step:27416 [D loss: 0.669605, acc.: 56.25%] [G loss: 0.858880]\n",
      "epoch:29 step:27417 [D loss: 0.692026, acc.: 49.22%] [G loss: 0.835510]\n",
      "epoch:29 step:27418 [D loss: 0.663547, acc.: 56.25%] [G loss: 0.899567]\n",
      "epoch:29 step:27419 [D loss: 0.671584, acc.: 60.16%] [G loss: 0.942173]\n",
      "epoch:29 step:27420 [D loss: 0.645069, acc.: 60.94%] [G loss: 0.962489]\n",
      "epoch:29 step:27421 [D loss: 0.656095, acc.: 58.59%] [G loss: 0.902415]\n",
      "epoch:29 step:27422 [D loss: 0.684962, acc.: 53.12%] [G loss: 0.950869]\n",
      "epoch:29 step:27423 [D loss: 0.669977, acc.: 57.03%] [G loss: 0.919279]\n",
      "epoch:29 step:27424 [D loss: 0.629214, acc.: 67.19%] [G loss: 0.891257]\n",
      "epoch:29 step:27425 [D loss: 0.669833, acc.: 60.16%] [G loss: 0.863885]\n",
      "epoch:29 step:27426 [D loss: 0.632762, acc.: 64.84%] [G loss: 0.831815]\n",
      "epoch:29 step:27427 [D loss: 0.731392, acc.: 50.00%] [G loss: 0.854363]\n",
      "epoch:29 step:27428 [D loss: 0.635441, acc.: 64.84%] [G loss: 0.934812]\n",
      "epoch:29 step:27429 [D loss: 0.670941, acc.: 58.59%] [G loss: 0.901783]\n",
      "epoch:29 step:27430 [D loss: 0.647259, acc.: 61.72%] [G loss: 0.909521]\n",
      "epoch:29 step:27431 [D loss: 0.646189, acc.: 59.38%] [G loss: 0.936936]\n",
      "epoch:29 step:27432 [D loss: 0.712676, acc.: 53.12%] [G loss: 0.882626]\n",
      "epoch:29 step:27433 [D loss: 0.670292, acc.: 57.03%] [G loss: 0.874685]\n",
      "epoch:29 step:27434 [D loss: 0.681438, acc.: 58.59%] [G loss: 0.949435]\n",
      "epoch:29 step:27435 [D loss: 0.656160, acc.: 57.81%] [G loss: 0.922931]\n",
      "epoch:29 step:27436 [D loss: 0.622324, acc.: 64.84%] [G loss: 0.984061]\n",
      "epoch:29 step:27437 [D loss: 0.615982, acc.: 69.53%] [G loss: 0.945610]\n",
      "epoch:29 step:27438 [D loss: 0.612518, acc.: 67.19%] [G loss: 0.929941]\n",
      "epoch:29 step:27439 [D loss: 0.648069, acc.: 61.72%] [G loss: 0.915016]\n",
      "epoch:29 step:27440 [D loss: 0.666329, acc.: 56.25%] [G loss: 0.916943]\n",
      "epoch:29 step:27441 [D loss: 0.652026, acc.: 58.59%] [G loss: 0.891939]\n",
      "epoch:29 step:27442 [D loss: 0.614863, acc.: 70.31%] [G loss: 0.963937]\n",
      "epoch:29 step:27443 [D loss: 0.619659, acc.: 60.94%] [G loss: 0.927489]\n",
      "epoch:29 step:27444 [D loss: 0.624085, acc.: 64.06%] [G loss: 0.888511]\n",
      "epoch:29 step:27445 [D loss: 0.644926, acc.: 57.03%] [G loss: 0.989083]\n",
      "epoch:29 step:27446 [D loss: 0.649936, acc.: 58.59%] [G loss: 0.882806]\n",
      "epoch:29 step:27447 [D loss: 0.656277, acc.: 53.12%] [G loss: 0.902396]\n",
      "epoch:29 step:27448 [D loss: 0.648162, acc.: 61.72%] [G loss: 0.906427]\n",
      "epoch:29 step:27449 [D loss: 0.660222, acc.: 53.91%] [G loss: 0.913795]\n",
      "epoch:29 step:27450 [D loss: 0.635101, acc.: 60.94%] [G loss: 0.924226]\n",
      "epoch:29 step:27451 [D loss: 0.676535, acc.: 57.81%] [G loss: 0.896545]\n",
      "epoch:29 step:27452 [D loss: 0.687077, acc.: 54.69%] [G loss: 0.918722]\n",
      "epoch:29 step:27453 [D loss: 0.671508, acc.: 57.03%] [G loss: 0.887453]\n",
      "epoch:29 step:27454 [D loss: 0.612009, acc.: 66.41%] [G loss: 0.967061]\n",
      "epoch:29 step:27455 [D loss: 0.615260, acc.: 64.84%] [G loss: 0.974501]\n",
      "epoch:29 step:27456 [D loss: 0.642416, acc.: 59.38%] [G loss: 1.015327]\n",
      "epoch:29 step:27457 [D loss: 0.634930, acc.: 64.06%] [G loss: 0.970483]\n",
      "epoch:29 step:27458 [D loss: 0.566120, acc.: 69.53%] [G loss: 0.942208]\n",
      "epoch:29 step:27459 [D loss: 0.624502, acc.: 67.97%] [G loss: 0.884526]\n",
      "epoch:29 step:27460 [D loss: 0.597374, acc.: 71.09%] [G loss: 0.938161]\n",
      "epoch:29 step:27461 [D loss: 0.655458, acc.: 60.94%] [G loss: 0.904953]\n",
      "epoch:29 step:27462 [D loss: 0.680084, acc.: 53.91%] [G loss: 0.921455]\n",
      "epoch:29 step:27463 [D loss: 0.622318, acc.: 65.62%] [G loss: 0.924176]\n",
      "epoch:29 step:27464 [D loss: 0.657421, acc.: 60.94%] [G loss: 0.959422]\n",
      "epoch:29 step:27465 [D loss: 0.664468, acc.: 57.81%] [G loss: 0.900420]\n",
      "epoch:29 step:27466 [D loss: 0.649051, acc.: 61.72%] [G loss: 0.845491]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27467 [D loss: 0.626419, acc.: 62.50%] [G loss: 0.931882]\n",
      "epoch:29 step:27468 [D loss: 0.663906, acc.: 60.94%] [G loss: 0.867978]\n",
      "epoch:29 step:27469 [D loss: 0.665218, acc.: 67.19%] [G loss: 0.845894]\n",
      "epoch:29 step:27470 [D loss: 0.615292, acc.: 66.41%] [G loss: 0.871485]\n",
      "epoch:29 step:27471 [D loss: 0.662513, acc.: 56.25%] [G loss: 0.897867]\n",
      "epoch:29 step:27472 [D loss: 0.705807, acc.: 50.00%] [G loss: 0.866078]\n",
      "epoch:29 step:27473 [D loss: 0.625595, acc.: 64.06%] [G loss: 0.894126]\n",
      "epoch:29 step:27474 [D loss: 0.688254, acc.: 52.34%] [G loss: 0.939979]\n",
      "epoch:29 step:27475 [D loss: 0.650624, acc.: 62.50%] [G loss: 0.950168]\n",
      "epoch:29 step:27476 [D loss: 0.666013, acc.: 57.03%] [G loss: 0.971813]\n",
      "epoch:29 step:27477 [D loss: 0.677526, acc.: 57.03%] [G loss: 0.892522]\n",
      "epoch:29 step:27478 [D loss: 0.643843, acc.: 60.16%] [G loss: 0.927979]\n",
      "epoch:29 step:27479 [D loss: 0.660043, acc.: 60.16%] [G loss: 0.960383]\n",
      "epoch:29 step:27480 [D loss: 0.704316, acc.: 52.34%] [G loss: 0.890385]\n",
      "epoch:29 step:27481 [D loss: 0.657521, acc.: 58.59%] [G loss: 0.904502]\n",
      "epoch:29 step:27482 [D loss: 0.650944, acc.: 60.94%] [G loss: 0.929115]\n",
      "epoch:29 step:27483 [D loss: 0.632595, acc.: 60.94%] [G loss: 0.948283]\n",
      "epoch:29 step:27484 [D loss: 0.637159, acc.: 60.16%] [G loss: 0.936494]\n",
      "epoch:29 step:27485 [D loss: 0.672997, acc.: 58.59%] [G loss: 0.904620]\n",
      "epoch:29 step:27486 [D loss: 0.663400, acc.: 59.38%] [G loss: 0.863707]\n",
      "epoch:29 step:27487 [D loss: 0.631717, acc.: 61.72%] [G loss: 0.900363]\n",
      "epoch:29 step:27488 [D loss: 0.657193, acc.: 59.38%] [G loss: 0.900125]\n",
      "epoch:29 step:27489 [D loss: 0.677288, acc.: 57.03%] [G loss: 0.869049]\n",
      "epoch:29 step:27490 [D loss: 0.658960, acc.: 57.03%] [G loss: 0.921316]\n",
      "epoch:29 step:27491 [D loss: 0.654374, acc.: 56.25%] [G loss: 0.934627]\n",
      "epoch:29 step:27492 [D loss: 0.632989, acc.: 68.75%] [G loss: 0.958456]\n",
      "epoch:29 step:27493 [D loss: 0.645144, acc.: 60.94%] [G loss: 0.940724]\n",
      "epoch:29 step:27494 [D loss: 0.652791, acc.: 60.16%] [G loss: 0.883424]\n",
      "epoch:29 step:27495 [D loss: 0.654194, acc.: 60.16%] [G loss: 0.896956]\n",
      "epoch:29 step:27496 [D loss: 0.635324, acc.: 59.38%] [G loss: 0.921026]\n",
      "epoch:29 step:27497 [D loss: 0.620024, acc.: 65.62%] [G loss: 0.915455]\n",
      "epoch:29 step:27498 [D loss: 0.655875, acc.: 63.28%] [G loss: 0.947386]\n",
      "epoch:29 step:27499 [D loss: 0.688519, acc.: 56.25%] [G loss: 0.895812]\n",
      "epoch:29 step:27500 [D loss: 0.622975, acc.: 67.19%] [G loss: 0.960550]\n",
      "epoch:29 step:27501 [D loss: 0.619722, acc.: 67.97%] [G loss: 0.907113]\n",
      "epoch:29 step:27502 [D loss: 0.705235, acc.: 50.78%] [G loss: 0.945834]\n",
      "epoch:29 step:27503 [D loss: 0.640339, acc.: 57.81%] [G loss: 0.953027]\n",
      "epoch:29 step:27504 [D loss: 0.656267, acc.: 57.81%] [G loss: 0.965750]\n",
      "epoch:29 step:27505 [D loss: 0.644133, acc.: 60.16%] [G loss: 0.951061]\n",
      "epoch:29 step:27506 [D loss: 0.640781, acc.: 62.50%] [G loss: 0.931499]\n",
      "epoch:29 step:27507 [D loss: 0.644299, acc.: 64.06%] [G loss: 0.906724]\n",
      "epoch:29 step:27508 [D loss: 0.681336, acc.: 58.59%] [G loss: 0.888273]\n",
      "epoch:29 step:27509 [D loss: 0.633528, acc.: 57.81%] [G loss: 0.865132]\n",
      "epoch:29 step:27510 [D loss: 0.624979, acc.: 67.19%] [G loss: 0.841135]\n",
      "epoch:29 step:27511 [D loss: 0.612653, acc.: 68.75%] [G loss: 0.905097]\n",
      "epoch:29 step:27512 [D loss: 0.645552, acc.: 63.28%] [G loss: 0.869560]\n",
      "epoch:29 step:27513 [D loss: 0.639776, acc.: 62.50%] [G loss: 0.980302]\n",
      "epoch:29 step:27514 [D loss: 0.668524, acc.: 57.03%] [G loss: 0.864006]\n",
      "epoch:29 step:27515 [D loss: 0.654305, acc.: 60.94%] [G loss: 0.865392]\n",
      "epoch:29 step:27516 [D loss: 0.662848, acc.: 58.59%] [G loss: 0.866750]\n",
      "epoch:29 step:27517 [D loss: 0.644832, acc.: 63.28%] [G loss: 0.950263]\n",
      "epoch:29 step:27518 [D loss: 0.661380, acc.: 61.72%] [G loss: 0.870361]\n",
      "epoch:29 step:27519 [D loss: 0.676905, acc.: 58.59%] [G loss: 0.924522]\n",
      "epoch:29 step:27520 [D loss: 0.647378, acc.: 64.06%] [G loss: 0.888752]\n",
      "epoch:29 step:27521 [D loss: 0.691783, acc.: 57.03%] [G loss: 0.830935]\n",
      "epoch:29 step:27522 [D loss: 0.660223, acc.: 60.16%] [G loss: 0.888186]\n",
      "epoch:29 step:27523 [D loss: 0.645446, acc.: 67.97%] [G loss: 0.905557]\n",
      "epoch:29 step:27524 [D loss: 0.640586, acc.: 61.72%] [G loss: 0.909720]\n",
      "epoch:29 step:27525 [D loss: 0.660577, acc.: 61.72%] [G loss: 0.921376]\n",
      "epoch:29 step:27526 [D loss: 0.620135, acc.: 59.38%] [G loss: 0.839401]\n",
      "epoch:29 step:27527 [D loss: 0.640015, acc.: 63.28%] [G loss: 0.834570]\n",
      "epoch:29 step:27528 [D loss: 0.630800, acc.: 68.75%] [G loss: 0.917814]\n",
      "epoch:29 step:27529 [D loss: 0.646655, acc.: 60.94%] [G loss: 0.954436]\n",
      "epoch:29 step:27530 [D loss: 0.621558, acc.: 67.97%] [G loss: 0.876061]\n",
      "epoch:29 step:27531 [D loss: 0.645118, acc.: 66.41%] [G loss: 0.888046]\n",
      "epoch:29 step:27532 [D loss: 0.634873, acc.: 62.50%] [G loss: 0.906361]\n",
      "epoch:29 step:27533 [D loss: 0.597661, acc.: 66.41%] [G loss: 0.963759]\n",
      "epoch:29 step:27534 [D loss: 0.636103, acc.: 61.72%] [G loss: 0.922012]\n",
      "epoch:29 step:27535 [D loss: 0.676211, acc.: 58.59%] [G loss: 0.840262]\n",
      "epoch:29 step:27536 [D loss: 0.667451, acc.: 62.50%] [G loss: 0.876502]\n",
      "epoch:29 step:27537 [D loss: 0.664968, acc.: 57.81%] [G loss: 0.944064]\n",
      "epoch:29 step:27538 [D loss: 0.676222, acc.: 56.25%] [G loss: 0.863251]\n",
      "epoch:29 step:27539 [D loss: 0.650578, acc.: 61.72%] [G loss: 0.947834]\n",
      "epoch:29 step:27540 [D loss: 0.672432, acc.: 54.69%] [G loss: 0.917269]\n",
      "epoch:29 step:27541 [D loss: 0.660165, acc.: 61.72%] [G loss: 0.887609]\n",
      "epoch:29 step:27542 [D loss: 0.665683, acc.: 64.84%] [G loss: 0.880020]\n",
      "epoch:29 step:27543 [D loss: 0.645897, acc.: 62.50%] [G loss: 0.894422]\n",
      "epoch:29 step:27544 [D loss: 0.638711, acc.: 64.84%] [G loss: 0.962034]\n",
      "epoch:29 step:27545 [D loss: 0.635339, acc.: 68.75%] [G loss: 0.940725]\n",
      "epoch:29 step:27546 [D loss: 0.644176, acc.: 59.38%] [G loss: 0.909519]\n",
      "epoch:29 step:27547 [D loss: 0.674477, acc.: 56.25%] [G loss: 0.939508]\n",
      "epoch:29 step:27548 [D loss: 0.654939, acc.: 64.06%] [G loss: 0.902089]\n",
      "epoch:29 step:27549 [D loss: 0.641145, acc.: 57.81%] [G loss: 0.843377]\n",
      "epoch:29 step:27550 [D loss: 0.653024, acc.: 62.50%] [G loss: 0.878746]\n",
      "epoch:29 step:27551 [D loss: 0.629953, acc.: 68.75%] [G loss: 0.853601]\n",
      "epoch:29 step:27552 [D loss: 0.649048, acc.: 62.50%] [G loss: 0.938815]\n",
      "epoch:29 step:27553 [D loss: 0.661250, acc.: 61.72%] [G loss: 0.896555]\n",
      "epoch:29 step:27554 [D loss: 0.654591, acc.: 60.94%] [G loss: 0.989069]\n",
      "epoch:29 step:27555 [D loss: 0.650650, acc.: 57.03%] [G loss: 0.893739]\n",
      "epoch:29 step:27556 [D loss: 0.632405, acc.: 62.50%] [G loss: 0.936383]\n",
      "epoch:29 step:27557 [D loss: 0.667651, acc.: 57.03%] [G loss: 0.946049]\n",
      "epoch:29 step:27558 [D loss: 0.664958, acc.: 60.94%] [G loss: 0.959432]\n",
      "epoch:29 step:27559 [D loss: 0.655078, acc.: 57.81%] [G loss: 0.893837]\n",
      "epoch:29 step:27560 [D loss: 0.646940, acc.: 62.50%] [G loss: 0.911700]\n",
      "epoch:29 step:27561 [D loss: 0.654779, acc.: 61.72%] [G loss: 0.968494]\n",
      "epoch:29 step:27562 [D loss: 0.667373, acc.: 60.16%] [G loss: 0.914476]\n",
      "epoch:29 step:27563 [D loss: 0.689358, acc.: 59.38%] [G loss: 0.878614]\n",
      "epoch:29 step:27564 [D loss: 0.607963, acc.: 68.75%] [G loss: 0.912345]\n",
      "epoch:29 step:27565 [D loss: 0.634564, acc.: 65.62%] [G loss: 0.902202]\n",
      "epoch:29 step:27566 [D loss: 0.696049, acc.: 52.34%] [G loss: 0.915589]\n",
      "epoch:29 step:27567 [D loss: 0.642472, acc.: 59.38%] [G loss: 0.915749]\n",
      "epoch:29 step:27568 [D loss: 0.665567, acc.: 60.94%] [G loss: 0.868470]\n",
      "epoch:29 step:27569 [D loss: 0.668121, acc.: 56.25%] [G loss: 0.878420]\n",
      "epoch:29 step:27570 [D loss: 0.649312, acc.: 59.38%] [G loss: 0.918375]\n",
      "epoch:29 step:27571 [D loss: 0.684233, acc.: 54.69%] [G loss: 0.899767]\n",
      "epoch:29 step:27572 [D loss: 0.619641, acc.: 68.75%] [G loss: 0.921598]\n",
      "epoch:29 step:27573 [D loss: 0.663413, acc.: 55.47%] [G loss: 0.871911]\n",
      "epoch:29 step:27574 [D loss: 0.633323, acc.: 65.62%] [G loss: 0.896605]\n",
      "epoch:29 step:27575 [D loss: 0.596359, acc.: 67.19%] [G loss: 0.905164]\n",
      "epoch:29 step:27576 [D loss: 0.635493, acc.: 64.84%] [G loss: 0.922523]\n",
      "epoch:29 step:27577 [D loss: 0.625529, acc.: 63.28%] [G loss: 0.936717]\n",
      "epoch:29 step:27578 [D loss: 0.638163, acc.: 64.06%] [G loss: 0.912442]\n",
      "epoch:29 step:27579 [D loss: 0.644514, acc.: 59.38%] [G loss: 0.884546]\n",
      "epoch:29 step:27580 [D loss: 0.675071, acc.: 61.72%] [G loss: 0.889349]\n",
      "epoch:29 step:27581 [D loss: 0.648649, acc.: 59.38%] [G loss: 0.965781]\n",
      "epoch:29 step:27582 [D loss: 0.672809, acc.: 56.25%] [G loss: 0.912443]\n",
      "epoch:29 step:27583 [D loss: 0.673917, acc.: 60.94%] [G loss: 0.950063]\n",
      "epoch:29 step:27584 [D loss: 0.622053, acc.: 64.06%] [G loss: 0.931416]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27585 [D loss: 0.626166, acc.: 60.94%] [G loss: 0.946609]\n",
      "epoch:29 step:27586 [D loss: 0.674958, acc.: 60.16%] [G loss: 0.935176]\n",
      "epoch:29 step:27587 [D loss: 0.642343, acc.: 60.16%] [G loss: 0.832493]\n",
      "epoch:29 step:27588 [D loss: 0.612382, acc.: 70.31%] [G loss: 0.853262]\n",
      "epoch:29 step:27589 [D loss: 0.615412, acc.: 64.84%] [G loss: 0.858867]\n",
      "epoch:29 step:27590 [D loss: 0.600386, acc.: 74.22%] [G loss: 0.936238]\n",
      "epoch:29 step:27591 [D loss: 0.673505, acc.: 60.16%] [G loss: 0.866327]\n",
      "epoch:29 step:27592 [D loss: 0.626499, acc.: 58.59%] [G loss: 0.859986]\n",
      "epoch:29 step:27593 [D loss: 0.618446, acc.: 65.62%] [G loss: 0.929227]\n",
      "epoch:29 step:27594 [D loss: 0.674223, acc.: 60.94%] [G loss: 0.898002]\n",
      "epoch:29 step:27595 [D loss: 0.681665, acc.: 55.47%] [G loss: 0.871838]\n",
      "epoch:29 step:27596 [D loss: 0.658278, acc.: 55.47%] [G loss: 0.876514]\n",
      "epoch:29 step:27597 [D loss: 0.622742, acc.: 65.62%] [G loss: 0.921286]\n",
      "epoch:29 step:27598 [D loss: 0.708511, acc.: 47.66%] [G loss: 0.931753]\n",
      "epoch:29 step:27599 [D loss: 0.646894, acc.: 60.16%] [G loss: 0.941586]\n",
      "epoch:29 step:27600 [D loss: 0.693446, acc.: 51.56%] [G loss: 0.967681]\n",
      "##############\n",
      "[2.95620858 2.44282582 2.28417754 3.6636779  1.23967261 7.15057966\n",
      " 2.75928815 3.20585647 4.32225159 7.14868929]\n",
      "##########\n",
      "epoch:29 step:27601 [D loss: 0.644323, acc.: 66.41%] [G loss: 0.919541]\n",
      "epoch:29 step:27602 [D loss: 0.633890, acc.: 64.84%] [G loss: 0.908785]\n",
      "epoch:29 step:27603 [D loss: 0.669733, acc.: 56.25%] [G loss: 0.890492]\n",
      "epoch:29 step:27604 [D loss: 0.659150, acc.: 60.94%] [G loss: 0.902541]\n",
      "epoch:29 step:27605 [D loss: 0.702639, acc.: 49.22%] [G loss: 0.936192]\n",
      "epoch:29 step:27606 [D loss: 0.674209, acc.: 55.47%] [G loss: 0.902790]\n",
      "epoch:29 step:27607 [D loss: 0.675037, acc.: 56.25%] [G loss: 0.931262]\n",
      "epoch:29 step:27608 [D loss: 0.639436, acc.: 62.50%] [G loss: 0.944429]\n",
      "epoch:29 step:27609 [D loss: 0.674270, acc.: 60.94%] [G loss: 0.976483]\n",
      "epoch:29 step:27610 [D loss: 0.632801, acc.: 63.28%] [G loss: 0.948696]\n",
      "epoch:29 step:27611 [D loss: 0.684513, acc.: 57.81%] [G loss: 0.994414]\n",
      "epoch:29 step:27612 [D loss: 0.634774, acc.: 64.06%] [G loss: 0.975990]\n",
      "epoch:29 step:27613 [D loss: 0.648062, acc.: 64.06%] [G loss: 0.903639]\n",
      "epoch:29 step:27614 [D loss: 0.672815, acc.: 57.81%] [G loss: 0.903983]\n",
      "epoch:29 step:27615 [D loss: 0.664355, acc.: 60.16%] [G loss: 0.879397]\n",
      "epoch:29 step:27616 [D loss: 0.637748, acc.: 64.06%] [G loss: 0.930277]\n",
      "epoch:29 step:27617 [D loss: 0.640674, acc.: 60.94%] [G loss: 0.896672]\n",
      "epoch:29 step:27618 [D loss: 0.646531, acc.: 60.16%] [G loss: 0.938841]\n",
      "epoch:29 step:27619 [D loss: 0.662369, acc.: 61.72%] [G loss: 0.948449]\n",
      "epoch:29 step:27620 [D loss: 0.647675, acc.: 64.06%] [G loss: 0.920801]\n",
      "epoch:29 step:27621 [D loss: 0.677631, acc.: 62.50%] [G loss: 0.902157]\n",
      "epoch:29 step:27622 [D loss: 0.617334, acc.: 68.75%] [G loss: 0.895829]\n",
      "epoch:29 step:27623 [D loss: 0.628725, acc.: 61.72%] [G loss: 0.960536]\n",
      "epoch:29 step:27624 [D loss: 0.658928, acc.: 58.59%] [G loss: 0.913733]\n",
      "epoch:29 step:27625 [D loss: 0.652123, acc.: 60.16%] [G loss: 0.895016]\n",
      "epoch:29 step:27626 [D loss: 0.641016, acc.: 61.72%] [G loss: 0.854157]\n",
      "epoch:29 step:27627 [D loss: 0.645029, acc.: 60.16%] [G loss: 0.904095]\n",
      "epoch:29 step:27628 [D loss: 0.633175, acc.: 62.50%] [G loss: 0.914440]\n",
      "epoch:29 step:27629 [D loss: 0.677921, acc.: 60.16%] [G loss: 0.868390]\n",
      "epoch:29 step:27630 [D loss: 0.656111, acc.: 62.50%] [G loss: 0.879981]\n",
      "epoch:29 step:27631 [D loss: 0.625034, acc.: 66.41%] [G loss: 0.864691]\n",
      "epoch:29 step:27632 [D loss: 0.602216, acc.: 69.53%] [G loss: 0.952475]\n",
      "epoch:29 step:27633 [D loss: 0.603485, acc.: 66.41%] [G loss: 0.980986]\n",
      "epoch:29 step:27634 [D loss: 0.643062, acc.: 57.81%] [G loss: 0.950204]\n",
      "epoch:29 step:27635 [D loss: 0.658979, acc.: 53.91%] [G loss: 0.907182]\n",
      "epoch:29 step:27636 [D loss: 0.651192, acc.: 64.84%] [G loss: 0.942146]\n",
      "epoch:29 step:27637 [D loss: 0.657010, acc.: 56.25%] [G loss: 0.928520]\n",
      "epoch:29 step:27638 [D loss: 0.641535, acc.: 67.97%] [G loss: 0.890640]\n",
      "epoch:29 step:27639 [D loss: 0.683516, acc.: 60.94%] [G loss: 0.871411]\n",
      "epoch:29 step:27640 [D loss: 0.646764, acc.: 60.94%] [G loss: 0.942647]\n",
      "epoch:29 step:27641 [D loss: 0.599668, acc.: 71.88%] [G loss: 0.938725]\n",
      "epoch:29 step:27642 [D loss: 0.663407, acc.: 57.03%] [G loss: 0.963308]\n",
      "epoch:29 step:27643 [D loss: 0.691890, acc.: 58.59%] [G loss: 0.845883]\n",
      "epoch:29 step:27644 [D loss: 0.631750, acc.: 62.50%] [G loss: 0.894463]\n",
      "epoch:29 step:27645 [D loss: 0.630009, acc.: 66.41%] [G loss: 0.880705]\n",
      "epoch:29 step:27646 [D loss: 0.630105, acc.: 69.53%] [G loss: 0.938461]\n",
      "epoch:29 step:27647 [D loss: 0.613947, acc.: 65.62%] [G loss: 0.947773]\n",
      "epoch:29 step:27648 [D loss: 0.666325, acc.: 59.38%] [G loss: 0.880297]\n",
      "epoch:29 step:27649 [D loss: 0.696355, acc.: 53.91%] [G loss: 0.922529]\n",
      "epoch:29 step:27650 [D loss: 0.691044, acc.: 51.56%] [G loss: 0.943783]\n",
      "epoch:29 step:27651 [D loss: 0.663891, acc.: 60.16%] [G loss: 0.905315]\n",
      "epoch:29 step:27652 [D loss: 0.670472, acc.: 56.25%] [G loss: 0.871733]\n",
      "epoch:29 step:27653 [D loss: 0.696188, acc.: 57.03%] [G loss: 0.863636]\n",
      "epoch:29 step:27654 [D loss: 0.649536, acc.: 58.59%] [G loss: 0.804399]\n",
      "epoch:29 step:27655 [D loss: 0.666324, acc.: 57.81%] [G loss: 0.891034]\n",
      "epoch:29 step:27656 [D loss: 0.692585, acc.: 52.34%] [G loss: 0.896308]\n",
      "epoch:29 step:27657 [D loss: 0.637232, acc.: 60.94%] [G loss: 0.893761]\n",
      "epoch:29 step:27658 [D loss: 0.666572, acc.: 59.38%] [G loss: 0.876441]\n",
      "epoch:29 step:27659 [D loss: 0.644794, acc.: 61.72%] [G loss: 0.880524]\n",
      "epoch:29 step:27660 [D loss: 0.645185, acc.: 61.72%] [G loss: 0.922360]\n",
      "epoch:29 step:27661 [D loss: 0.638154, acc.: 60.94%] [G loss: 0.937449]\n",
      "epoch:29 step:27662 [D loss: 0.641254, acc.: 62.50%] [G loss: 0.928580]\n",
      "epoch:29 step:27663 [D loss: 0.648688, acc.: 60.94%] [G loss: 0.897665]\n",
      "epoch:29 step:27664 [D loss: 0.627972, acc.: 68.75%] [G loss: 0.886986]\n",
      "epoch:29 step:27665 [D loss: 0.636816, acc.: 64.06%] [G loss: 0.915391]\n",
      "epoch:29 step:27666 [D loss: 0.673175, acc.: 54.69%] [G loss: 0.906117]\n",
      "epoch:29 step:27667 [D loss: 0.652384, acc.: 60.16%] [G loss: 0.905039]\n",
      "epoch:29 step:27668 [D loss: 0.676037, acc.: 53.12%] [G loss: 0.875126]\n",
      "epoch:29 step:27669 [D loss: 0.652851, acc.: 60.94%] [G loss: 0.900040]\n",
      "epoch:29 step:27670 [D loss: 0.663282, acc.: 64.06%] [G loss: 0.958148]\n",
      "epoch:29 step:27671 [D loss: 0.658459, acc.: 62.50%] [G loss: 0.903533]\n",
      "epoch:29 step:27672 [D loss: 0.668638, acc.: 60.94%] [G loss: 0.920773]\n",
      "epoch:29 step:27673 [D loss: 0.648484, acc.: 59.38%] [G loss: 0.964399]\n",
      "epoch:29 step:27674 [D loss: 0.667230, acc.: 59.38%] [G loss: 0.937104]\n",
      "epoch:29 step:27675 [D loss: 0.654091, acc.: 59.38%] [G loss: 0.885285]\n",
      "epoch:29 step:27676 [D loss: 0.632976, acc.: 64.84%] [G loss: 0.974854]\n",
      "epoch:29 step:27677 [D loss: 0.636631, acc.: 67.97%] [G loss: 0.927498]\n",
      "epoch:29 step:27678 [D loss: 0.677379, acc.: 55.47%] [G loss: 0.976461]\n",
      "epoch:29 step:27679 [D loss: 0.716397, acc.: 53.91%] [G loss: 0.881283]\n",
      "epoch:29 step:27680 [D loss: 0.662750, acc.: 57.81%] [G loss: 0.939124]\n",
      "epoch:29 step:27681 [D loss: 0.662205, acc.: 62.50%] [G loss: 0.913569]\n",
      "epoch:29 step:27682 [D loss: 0.684120, acc.: 54.69%] [G loss: 0.892827]\n",
      "epoch:29 step:27683 [D loss: 0.642837, acc.: 57.03%] [G loss: 0.978752]\n",
      "epoch:29 step:27684 [D loss: 0.618746, acc.: 71.09%] [G loss: 0.948025]\n",
      "epoch:29 step:27685 [D loss: 0.651453, acc.: 60.16%] [G loss: 0.926059]\n",
      "epoch:29 step:27686 [D loss: 0.658885, acc.: 57.03%] [G loss: 0.896132]\n",
      "epoch:29 step:27687 [D loss: 0.646766, acc.: 57.81%] [G loss: 0.932851]\n",
      "epoch:29 step:27688 [D loss: 0.656260, acc.: 65.62%] [G loss: 0.851470]\n",
      "epoch:29 step:27689 [D loss: 0.680552, acc.: 57.81%] [G loss: 0.918378]\n",
      "epoch:29 step:27690 [D loss: 0.639006, acc.: 64.06%] [G loss: 0.888075]\n",
      "epoch:29 step:27691 [D loss: 0.598788, acc.: 70.31%] [G loss: 0.854932]\n",
      "epoch:29 step:27692 [D loss: 0.587457, acc.: 71.09%] [G loss: 0.940217]\n",
      "epoch:29 step:27693 [D loss: 0.710411, acc.: 57.03%] [G loss: 0.917877]\n",
      "epoch:29 step:27694 [D loss: 0.659984, acc.: 62.50%] [G loss: 0.955670]\n",
      "epoch:29 step:27695 [D loss: 0.637305, acc.: 62.50%] [G loss: 0.911072]\n",
      "epoch:29 step:27696 [D loss: 0.612758, acc.: 70.31%] [G loss: 0.890285]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27697 [D loss: 0.664188, acc.: 60.94%] [G loss: 0.875569]\n",
      "epoch:29 step:27698 [D loss: 0.668177, acc.: 60.16%] [G loss: 0.931804]\n",
      "epoch:29 step:27699 [D loss: 0.668294, acc.: 58.59%] [G loss: 0.959114]\n",
      "epoch:29 step:27700 [D loss: 0.655216, acc.: 55.47%] [G loss: 0.906940]\n",
      "epoch:29 step:27701 [D loss: 0.686293, acc.: 55.47%] [G loss: 0.931956]\n",
      "epoch:29 step:27702 [D loss: 0.632739, acc.: 60.16%] [G loss: 0.930230]\n",
      "epoch:29 step:27703 [D loss: 0.613181, acc.: 69.53%] [G loss: 0.860568]\n",
      "epoch:29 step:27704 [D loss: 0.681590, acc.: 51.56%] [G loss: 0.868247]\n",
      "epoch:29 step:27705 [D loss: 0.667101, acc.: 57.81%] [G loss: 0.905613]\n",
      "epoch:29 step:27706 [D loss: 0.633048, acc.: 59.38%] [G loss: 0.880605]\n",
      "epoch:29 step:27707 [D loss: 0.679877, acc.: 54.69%] [G loss: 0.920219]\n",
      "epoch:29 step:27708 [D loss: 0.661358, acc.: 62.50%] [G loss: 0.883673]\n",
      "epoch:29 step:27709 [D loss: 0.681458, acc.: 56.25%] [G loss: 0.937280]\n",
      "epoch:29 step:27710 [D loss: 0.671133, acc.: 57.81%] [G loss: 0.914540]\n",
      "epoch:29 step:27711 [D loss: 0.678304, acc.: 57.03%] [G loss: 0.921298]\n",
      "epoch:29 step:27712 [D loss: 0.681956, acc.: 53.91%] [G loss: 0.889974]\n",
      "epoch:29 step:27713 [D loss: 0.660828, acc.: 57.81%] [G loss: 0.862747]\n",
      "epoch:29 step:27714 [D loss: 0.644900, acc.: 64.06%] [G loss: 0.946540]\n",
      "epoch:29 step:27715 [D loss: 0.652059, acc.: 60.94%] [G loss: 0.931908]\n",
      "epoch:29 step:27716 [D loss: 0.647857, acc.: 60.16%] [G loss: 0.948416]\n",
      "epoch:29 step:27717 [D loss: 0.677912, acc.: 60.94%] [G loss: 0.908945]\n",
      "epoch:29 step:27718 [D loss: 0.646984, acc.: 64.06%] [G loss: 0.905337]\n",
      "epoch:29 step:27719 [D loss: 0.677300, acc.: 56.25%] [G loss: 0.899278]\n",
      "epoch:29 step:27720 [D loss: 0.640776, acc.: 63.28%] [G loss: 0.891839]\n",
      "epoch:29 step:27721 [D loss: 0.689940, acc.: 57.81%] [G loss: 0.869776]\n",
      "epoch:29 step:27722 [D loss: 0.680160, acc.: 56.25%] [G loss: 0.897970]\n",
      "epoch:29 step:27723 [D loss: 0.637437, acc.: 62.50%] [G loss: 0.895416]\n",
      "epoch:29 step:27724 [D loss: 0.653689, acc.: 58.59%] [G loss: 0.928488]\n",
      "epoch:29 step:27725 [D loss: 0.651821, acc.: 59.38%] [G loss: 0.912346]\n",
      "epoch:29 step:27726 [D loss: 0.639790, acc.: 62.50%] [G loss: 0.921048]\n",
      "epoch:29 step:27727 [D loss: 0.667076, acc.: 57.03%] [G loss: 0.896764]\n",
      "epoch:29 step:27728 [D loss: 0.642762, acc.: 60.94%] [G loss: 0.907611]\n",
      "epoch:29 step:27729 [D loss: 0.666084, acc.: 60.94%] [G loss: 0.999556]\n",
      "epoch:29 step:27730 [D loss: 0.671687, acc.: 57.81%] [G loss: 0.932851]\n",
      "epoch:29 step:27731 [D loss: 0.618876, acc.: 68.75%] [G loss: 0.952685]\n",
      "epoch:29 step:27732 [D loss: 0.683605, acc.: 55.47%] [G loss: 0.864529]\n",
      "epoch:29 step:27733 [D loss: 0.619832, acc.: 58.59%] [G loss: 0.859601]\n",
      "epoch:29 step:27734 [D loss: 0.690623, acc.: 53.91%] [G loss: 0.843991]\n",
      "epoch:29 step:27735 [D loss: 0.636426, acc.: 67.97%] [G loss: 0.840654]\n",
      "epoch:29 step:27736 [D loss: 0.664982, acc.: 57.03%] [G loss: 0.857361]\n",
      "epoch:29 step:27737 [D loss: 0.680129, acc.: 59.38%] [G loss: 0.881706]\n",
      "epoch:29 step:27738 [D loss: 0.663238, acc.: 60.94%] [G loss: 0.898548]\n",
      "epoch:29 step:27739 [D loss: 0.599055, acc.: 67.97%] [G loss: 1.007278]\n",
      "epoch:29 step:27740 [D loss: 0.619667, acc.: 68.75%] [G loss: 0.942398]\n",
      "epoch:29 step:27741 [D loss: 0.679672, acc.: 63.28%] [G loss: 0.934444]\n",
      "epoch:29 step:27742 [D loss: 0.658495, acc.: 58.59%] [G loss: 0.945679]\n",
      "epoch:29 step:27743 [D loss: 0.657843, acc.: 64.06%] [G loss: 0.937519]\n",
      "epoch:29 step:27744 [D loss: 0.663907, acc.: 53.91%] [G loss: 0.949885]\n",
      "epoch:29 step:27745 [D loss: 0.655703, acc.: 61.72%] [G loss: 0.923098]\n",
      "epoch:29 step:27746 [D loss: 0.654776, acc.: 62.50%] [G loss: 0.903656]\n",
      "epoch:29 step:27747 [D loss: 0.664737, acc.: 57.03%] [G loss: 0.914989]\n",
      "epoch:29 step:27748 [D loss: 0.698488, acc.: 52.34%] [G loss: 0.860177]\n",
      "epoch:29 step:27749 [D loss: 0.605947, acc.: 73.44%] [G loss: 0.881123]\n",
      "epoch:29 step:27750 [D loss: 0.628596, acc.: 67.19%] [G loss: 0.849279]\n",
      "epoch:29 step:27751 [D loss: 0.637734, acc.: 61.72%] [G loss: 0.873122]\n",
      "epoch:29 step:27752 [D loss: 0.640912, acc.: 64.84%] [G loss: 0.882976]\n",
      "epoch:29 step:27753 [D loss: 0.671331, acc.: 51.56%] [G loss: 0.853258]\n",
      "epoch:29 step:27754 [D loss: 0.647472, acc.: 57.03%] [G loss: 0.878266]\n",
      "epoch:29 step:27755 [D loss: 0.639311, acc.: 61.72%] [G loss: 0.948135]\n",
      "epoch:29 step:27756 [D loss: 0.669021, acc.: 57.81%] [G loss: 0.887481]\n",
      "epoch:29 step:27757 [D loss: 0.642069, acc.: 63.28%] [G loss: 0.914001]\n",
      "epoch:29 step:27758 [D loss: 0.629091, acc.: 65.62%] [G loss: 0.936686]\n",
      "epoch:29 step:27759 [D loss: 0.642403, acc.: 61.72%] [G loss: 0.934117]\n",
      "epoch:29 step:27760 [D loss: 0.637454, acc.: 62.50%] [G loss: 0.878942]\n",
      "epoch:29 step:27761 [D loss: 0.655229, acc.: 63.28%] [G loss: 0.842237]\n",
      "epoch:29 step:27762 [D loss: 0.620741, acc.: 70.31%] [G loss: 0.891825]\n",
      "epoch:29 step:27763 [D loss: 0.679480, acc.: 59.38%] [G loss: 0.897216]\n",
      "epoch:29 step:27764 [D loss: 0.650526, acc.: 62.50%] [G loss: 0.885758]\n",
      "epoch:29 step:27765 [D loss: 0.703049, acc.: 50.00%] [G loss: 0.855982]\n",
      "epoch:29 step:27766 [D loss: 0.676459, acc.: 57.03%] [G loss: 0.887855]\n",
      "epoch:29 step:27767 [D loss: 0.585337, acc.: 70.31%] [G loss: 0.950889]\n",
      "epoch:29 step:27768 [D loss: 0.663667, acc.: 62.50%] [G loss: 0.881800]\n",
      "epoch:29 step:27769 [D loss: 0.674357, acc.: 55.47%] [G loss: 0.910887]\n",
      "epoch:29 step:27770 [D loss: 0.631599, acc.: 65.62%] [G loss: 0.913333]\n",
      "epoch:29 step:27771 [D loss: 0.628624, acc.: 67.19%] [G loss: 0.888518]\n",
      "epoch:29 step:27772 [D loss: 0.608632, acc.: 67.19%] [G loss: 0.872313]\n",
      "epoch:29 step:27773 [D loss: 0.696850, acc.: 57.03%] [G loss: 0.816577]\n",
      "epoch:29 step:27774 [D loss: 0.641196, acc.: 67.19%] [G loss: 0.833582]\n",
      "epoch:29 step:27775 [D loss: 0.640997, acc.: 71.09%] [G loss: 0.826208]\n",
      "epoch:29 step:27776 [D loss: 0.702222, acc.: 54.69%] [G loss: 0.873881]\n",
      "epoch:29 step:27777 [D loss: 0.713622, acc.: 49.22%] [G loss: 0.855464]\n",
      "epoch:29 step:27778 [D loss: 0.686378, acc.: 59.38%] [G loss: 0.848837]\n",
      "epoch:29 step:27779 [D loss: 0.655716, acc.: 59.38%] [G loss: 0.896221]\n",
      "epoch:29 step:27780 [D loss: 0.659055, acc.: 57.81%] [G loss: 0.850817]\n",
      "epoch:29 step:27781 [D loss: 0.658078, acc.: 55.47%] [G loss: 0.927866]\n",
      "epoch:29 step:27782 [D loss: 0.646112, acc.: 63.28%] [G loss: 0.902415]\n",
      "epoch:29 step:27783 [D loss: 0.639811, acc.: 60.16%] [G loss: 0.878354]\n",
      "epoch:29 step:27784 [D loss: 0.673344, acc.: 57.03%] [G loss: 0.929693]\n",
      "epoch:29 step:27785 [D loss: 0.648007, acc.: 57.03%] [G loss: 0.883848]\n",
      "epoch:29 step:27786 [D loss: 0.671102, acc.: 58.59%] [G loss: 0.907155]\n",
      "epoch:29 step:27787 [D loss: 0.626843, acc.: 61.72%] [G loss: 0.929285]\n",
      "epoch:29 step:27788 [D loss: 0.679584, acc.: 57.03%] [G loss: 0.834495]\n",
      "epoch:29 step:27789 [D loss: 0.627454, acc.: 68.75%] [G loss: 0.869764]\n",
      "epoch:29 step:27790 [D loss: 0.667995, acc.: 61.72%] [G loss: 0.894833]\n",
      "epoch:29 step:27791 [D loss: 0.682257, acc.: 51.56%] [G loss: 0.879605]\n",
      "epoch:29 step:27792 [D loss: 0.619300, acc.: 68.75%] [G loss: 0.905577]\n",
      "epoch:29 step:27793 [D loss: 0.675325, acc.: 60.94%] [G loss: 0.846531]\n",
      "epoch:29 step:27794 [D loss: 0.703201, acc.: 53.12%] [G loss: 0.838310]\n",
      "epoch:29 step:27795 [D loss: 0.645168, acc.: 59.38%] [G loss: 0.849631]\n",
      "epoch:29 step:27796 [D loss: 0.631550, acc.: 63.28%] [G loss: 0.912546]\n",
      "epoch:29 step:27797 [D loss: 0.642193, acc.: 61.72%] [G loss: 0.942746]\n",
      "epoch:29 step:27798 [D loss: 0.661004, acc.: 56.25%] [G loss: 0.902564]\n",
      "epoch:29 step:27799 [D loss: 0.681669, acc.: 52.34%] [G loss: 0.893754]\n",
      "epoch:29 step:27800 [D loss: 0.645717, acc.: 62.50%] [G loss: 0.920359]\n",
      "##############\n",
      "[2.94998649 2.43182685 2.41818137 3.38225672 1.33058395 7.02841377\n",
      " 2.63694229 3.49824419 4.0777165  8.14868929]\n",
      "##########\n",
      "epoch:29 step:27801 [D loss: 0.673684, acc.: 51.56%] [G loss: 0.915291]\n",
      "epoch:29 step:27802 [D loss: 0.634465, acc.: 64.06%] [G loss: 0.865398]\n",
      "epoch:29 step:27803 [D loss: 0.669378, acc.: 56.25%] [G loss: 0.865494]\n",
      "epoch:29 step:27804 [D loss: 0.647018, acc.: 63.28%] [G loss: 0.874325]\n",
      "epoch:29 step:27805 [D loss: 0.640645, acc.: 67.19%] [G loss: 0.876217]\n",
      "epoch:29 step:27806 [D loss: 0.638101, acc.: 69.53%] [G loss: 0.890985]\n",
      "epoch:29 step:27807 [D loss: 0.626420, acc.: 63.28%] [G loss: 0.938962]\n",
      "epoch:29 step:27808 [D loss: 0.656489, acc.: 56.25%] [G loss: 0.946299]\n",
      "epoch:29 step:27809 [D loss: 0.612627, acc.: 66.41%] [G loss: 1.008263]\n",
      "epoch:29 step:27810 [D loss: 0.629125, acc.: 61.72%] [G loss: 0.910163]\n",
      "epoch:29 step:27811 [D loss: 0.646660, acc.: 60.16%] [G loss: 0.883288]\n",
      "epoch:29 step:27812 [D loss: 0.667772, acc.: 56.25%] [G loss: 0.879445]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27813 [D loss: 0.626454, acc.: 63.28%] [G loss: 0.929590]\n",
      "epoch:29 step:27814 [D loss: 0.704856, acc.: 53.12%] [G loss: 0.879749]\n",
      "epoch:29 step:27815 [D loss: 0.654370, acc.: 60.94%] [G loss: 0.939714]\n",
      "epoch:29 step:27816 [D loss: 0.676572, acc.: 60.94%] [G loss: 0.912993]\n",
      "epoch:29 step:27817 [D loss: 0.618048, acc.: 65.62%] [G loss: 0.881534]\n",
      "epoch:29 step:27818 [D loss: 0.647473, acc.: 64.06%] [G loss: 0.960945]\n",
      "epoch:29 step:27819 [D loss: 0.682649, acc.: 57.81%] [G loss: 0.889494]\n",
      "epoch:29 step:27820 [D loss: 0.688857, acc.: 54.69%] [G loss: 0.908414]\n",
      "epoch:29 step:27821 [D loss: 0.664030, acc.: 59.38%] [G loss: 0.913487]\n",
      "epoch:29 step:27822 [D loss: 0.676642, acc.: 58.59%] [G loss: 0.899786]\n",
      "epoch:29 step:27823 [D loss: 0.651836, acc.: 63.28%] [G loss: 0.871428]\n",
      "epoch:29 step:27824 [D loss: 0.636167, acc.: 62.50%] [G loss: 0.857631]\n",
      "epoch:29 step:27825 [D loss: 0.657767, acc.: 61.72%] [G loss: 0.821328]\n",
      "epoch:29 step:27826 [D loss: 0.632127, acc.: 63.28%] [G loss: 0.892009]\n",
      "epoch:29 step:27827 [D loss: 0.664246, acc.: 56.25%] [G loss: 0.881900]\n",
      "epoch:29 step:27828 [D loss: 0.662099, acc.: 57.03%] [G loss: 0.888136]\n",
      "epoch:29 step:27829 [D loss: 0.631796, acc.: 64.84%] [G loss: 0.952030]\n",
      "epoch:29 step:27830 [D loss: 0.661959, acc.: 60.94%] [G loss: 0.907880]\n",
      "epoch:29 step:27831 [D loss: 0.705685, acc.: 54.69%] [G loss: 0.936614]\n",
      "epoch:29 step:27832 [D loss: 0.655827, acc.: 57.81%] [G loss: 0.905897]\n",
      "epoch:29 step:27833 [D loss: 0.667567, acc.: 59.38%] [G loss: 0.869551]\n",
      "epoch:29 step:27834 [D loss: 0.637416, acc.: 67.19%] [G loss: 0.892462]\n",
      "epoch:29 step:27835 [D loss: 0.653902, acc.: 62.50%] [G loss: 0.850602]\n",
      "epoch:29 step:27836 [D loss: 0.675297, acc.: 54.69%] [G loss: 0.902528]\n",
      "epoch:29 step:27837 [D loss: 0.616734, acc.: 64.06%] [G loss: 0.842370]\n",
      "epoch:29 step:27838 [D loss: 0.663770, acc.: 63.28%] [G loss: 0.851608]\n",
      "epoch:29 step:27839 [D loss: 0.643513, acc.: 64.06%] [G loss: 0.866114]\n",
      "epoch:29 step:27840 [D loss: 0.643128, acc.: 57.03%] [G loss: 0.863417]\n",
      "epoch:29 step:27841 [D loss: 0.680570, acc.: 63.28%] [G loss: 0.893252]\n",
      "epoch:29 step:27842 [D loss: 0.622417, acc.: 60.16%] [G loss: 0.949200]\n",
      "epoch:29 step:27843 [D loss: 0.624557, acc.: 64.06%] [G loss: 0.901825]\n",
      "epoch:29 step:27844 [D loss: 0.668486, acc.: 60.16%] [G loss: 0.891330]\n",
      "epoch:29 step:27845 [D loss: 0.663279, acc.: 63.28%] [G loss: 0.899192]\n",
      "epoch:29 step:27846 [D loss: 0.673912, acc.: 57.81%] [G loss: 0.882748]\n",
      "epoch:29 step:27847 [D loss: 0.628987, acc.: 69.53%] [G loss: 0.863704]\n",
      "epoch:29 step:27848 [D loss: 0.654307, acc.: 62.50%] [G loss: 0.885611]\n",
      "epoch:29 step:27849 [D loss: 0.649264, acc.: 63.28%] [G loss: 0.882557]\n",
      "epoch:29 step:27850 [D loss: 0.680842, acc.: 54.69%] [G loss: 0.926665]\n",
      "epoch:29 step:27851 [D loss: 0.691993, acc.: 53.91%] [G loss: 0.920758]\n",
      "epoch:29 step:27852 [D loss: 0.633110, acc.: 56.25%] [G loss: 0.882248]\n",
      "epoch:29 step:27853 [D loss: 0.678132, acc.: 55.47%] [G loss: 0.887246]\n",
      "epoch:29 step:27854 [D loss: 0.696502, acc.: 56.25%] [G loss: 0.876296]\n",
      "epoch:29 step:27855 [D loss: 0.679186, acc.: 60.94%] [G loss: 0.896724]\n",
      "epoch:29 step:27856 [D loss: 0.650822, acc.: 60.16%] [G loss: 0.962152]\n",
      "epoch:29 step:27857 [D loss: 0.628126, acc.: 67.19%] [G loss: 0.938635]\n",
      "epoch:29 step:27858 [D loss: 0.601384, acc.: 69.53%] [G loss: 0.954425]\n",
      "epoch:29 step:27859 [D loss: 0.618614, acc.: 70.31%] [G loss: 0.892562]\n",
      "epoch:29 step:27860 [D loss: 0.629894, acc.: 58.59%] [G loss: 0.888091]\n",
      "epoch:29 step:27861 [D loss: 0.660936, acc.: 60.94%] [G loss: 0.917758]\n",
      "epoch:29 step:27862 [D loss: 0.636016, acc.: 64.84%] [G loss: 0.957000]\n",
      "epoch:29 step:27863 [D loss: 0.672139, acc.: 54.69%] [G loss: 0.920861]\n",
      "epoch:29 step:27864 [D loss: 0.696305, acc.: 56.25%] [G loss: 0.898527]\n",
      "epoch:29 step:27865 [D loss: 0.646367, acc.: 62.50%] [G loss: 0.941542]\n",
      "epoch:29 step:27866 [D loss: 0.622509, acc.: 65.62%] [G loss: 0.850243]\n",
      "epoch:29 step:27867 [D loss: 0.664788, acc.: 56.25%] [G loss: 0.874057]\n",
      "epoch:29 step:27868 [D loss: 0.686378, acc.: 55.47%] [G loss: 0.915321]\n",
      "epoch:29 step:27869 [D loss: 0.653358, acc.: 63.28%] [G loss: 0.970568]\n",
      "epoch:29 step:27870 [D loss: 0.653311, acc.: 65.62%] [G loss: 1.014268]\n",
      "epoch:29 step:27871 [D loss: 0.643072, acc.: 60.94%] [G loss: 0.927236]\n",
      "epoch:29 step:27872 [D loss: 0.615072, acc.: 64.84%] [G loss: 0.923081]\n",
      "epoch:29 step:27873 [D loss: 0.665619, acc.: 62.50%] [G loss: 0.908034]\n",
      "epoch:29 step:27874 [D loss: 0.653187, acc.: 59.38%] [G loss: 0.912754]\n",
      "epoch:29 step:27875 [D loss: 0.652900, acc.: 62.50%] [G loss: 0.914892]\n",
      "epoch:29 step:27876 [D loss: 0.701167, acc.: 54.69%] [G loss: 0.929421]\n",
      "epoch:29 step:27877 [D loss: 0.650764, acc.: 60.94%] [G loss: 0.923819]\n",
      "epoch:29 step:27878 [D loss: 0.649790, acc.: 65.62%] [G loss: 0.879268]\n",
      "epoch:29 step:27879 [D loss: 0.681472, acc.: 58.59%] [G loss: 0.896592]\n",
      "epoch:29 step:27880 [D loss: 0.647902, acc.: 60.16%] [G loss: 0.911314]\n",
      "epoch:29 step:27881 [D loss: 0.660091, acc.: 63.28%] [G loss: 0.931521]\n",
      "epoch:29 step:27882 [D loss: 0.714157, acc.: 50.00%] [G loss: 0.901546]\n",
      "epoch:29 step:27883 [D loss: 0.611703, acc.: 63.28%] [G loss: 0.908568]\n",
      "epoch:29 step:27884 [D loss: 0.628998, acc.: 65.62%] [G loss: 0.864290]\n",
      "epoch:29 step:27885 [D loss: 0.694933, acc.: 51.56%] [G loss: 0.916672]\n",
      "epoch:29 step:27886 [D loss: 0.654870, acc.: 64.06%] [G loss: 0.883228]\n",
      "epoch:29 step:27887 [D loss: 0.646284, acc.: 58.59%] [G loss: 0.887035]\n",
      "epoch:29 step:27888 [D loss: 0.671667, acc.: 55.47%] [G loss: 0.842944]\n",
      "epoch:29 step:27889 [D loss: 0.631042, acc.: 58.59%] [G loss: 0.881792]\n",
      "epoch:29 step:27890 [D loss: 0.628775, acc.: 63.28%] [G loss: 0.845423]\n",
      "epoch:29 step:27891 [D loss: 0.616704, acc.: 64.84%] [G loss: 0.908028]\n",
      "epoch:29 step:27892 [D loss: 0.600183, acc.: 71.09%] [G loss: 0.900420]\n",
      "epoch:29 step:27893 [D loss: 0.640184, acc.: 61.72%] [G loss: 0.857387]\n",
      "epoch:29 step:27894 [D loss: 0.659388, acc.: 58.59%] [G loss: 0.904442]\n",
      "epoch:29 step:27895 [D loss: 0.632994, acc.: 68.75%] [G loss: 0.881868]\n",
      "epoch:29 step:27896 [D loss: 0.631418, acc.: 60.94%] [G loss: 0.967774]\n",
      "epoch:29 step:27897 [D loss: 0.666761, acc.: 58.59%] [G loss: 0.888399]\n",
      "epoch:29 step:27898 [D loss: 0.657718, acc.: 61.72%] [G loss: 0.874622]\n",
      "epoch:29 step:27899 [D loss: 0.643640, acc.: 60.16%] [G loss: 0.933880]\n",
      "epoch:29 step:27900 [D loss: 0.643504, acc.: 62.50%] [G loss: 0.945942]\n",
      "epoch:29 step:27901 [D loss: 0.660281, acc.: 64.06%] [G loss: 0.941927]\n",
      "epoch:29 step:27902 [D loss: 0.647036, acc.: 63.28%] [G loss: 0.840727]\n",
      "epoch:29 step:27903 [D loss: 0.657228, acc.: 60.94%] [G loss: 0.932352]\n",
      "epoch:29 step:27904 [D loss: 0.629835, acc.: 67.19%] [G loss: 0.924790]\n",
      "epoch:29 step:27905 [D loss: 0.660992, acc.: 55.47%] [G loss: 0.900751]\n",
      "epoch:29 step:27906 [D loss: 0.652852, acc.: 62.50%] [G loss: 0.951364]\n",
      "epoch:29 step:27907 [D loss: 0.629515, acc.: 64.84%] [G loss: 0.958530]\n",
      "epoch:29 step:27908 [D loss: 0.662236, acc.: 56.25%] [G loss: 0.926064]\n",
      "epoch:29 step:27909 [D loss: 0.630619, acc.: 67.19%] [G loss: 0.929737]\n",
      "epoch:29 step:27910 [D loss: 0.663893, acc.: 55.47%] [G loss: 0.920874]\n",
      "epoch:29 step:27911 [D loss: 0.665066, acc.: 56.25%] [G loss: 0.988952]\n",
      "epoch:29 step:27912 [D loss: 0.644633, acc.: 64.06%] [G loss: 0.935733]\n",
      "epoch:29 step:27913 [D loss: 0.665805, acc.: 58.59%] [G loss: 0.964244]\n",
      "epoch:29 step:27914 [D loss: 0.632567, acc.: 59.38%] [G loss: 0.890115]\n",
      "epoch:29 step:27915 [D loss: 0.648644, acc.: 61.72%] [G loss: 0.940207]\n",
      "epoch:29 step:27916 [D loss: 0.660950, acc.: 61.72%] [G loss: 0.884482]\n",
      "epoch:29 step:27917 [D loss: 0.672009, acc.: 63.28%] [G loss: 0.847872]\n",
      "epoch:29 step:27918 [D loss: 0.645929, acc.: 60.16%] [G loss: 0.959402]\n",
      "epoch:29 step:27919 [D loss: 0.651477, acc.: 59.38%] [G loss: 0.937917]\n",
      "epoch:29 step:27920 [D loss: 0.620564, acc.: 60.94%] [G loss: 0.923774]\n",
      "epoch:29 step:27921 [D loss: 0.601680, acc.: 67.19%] [G loss: 0.925621]\n",
      "epoch:29 step:27922 [D loss: 0.649314, acc.: 57.81%] [G loss: 0.930861]\n",
      "epoch:29 step:27923 [D loss: 0.604935, acc.: 71.88%] [G loss: 0.952607]\n",
      "epoch:29 step:27924 [D loss: 0.614638, acc.: 63.28%] [G loss: 0.931511]\n",
      "epoch:29 step:27925 [D loss: 0.631387, acc.: 66.41%] [G loss: 0.920627]\n",
      "epoch:29 step:27926 [D loss: 0.639757, acc.: 62.50%] [G loss: 0.930559]\n",
      "epoch:29 step:27927 [D loss: 0.673003, acc.: 60.16%] [G loss: 0.936448]\n",
      "epoch:29 step:27928 [D loss: 0.646920, acc.: 64.06%] [G loss: 0.940882]\n",
      "epoch:29 step:27929 [D loss: 0.642075, acc.: 64.84%] [G loss: 0.978919]\n",
      "epoch:29 step:27930 [D loss: 0.620305, acc.: 65.62%] [G loss: 0.986413]\n",
      "epoch:29 step:27931 [D loss: 0.631119, acc.: 65.62%] [G loss: 0.932082]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:27932 [D loss: 0.652351, acc.: 64.06%] [G loss: 0.906279]\n",
      "epoch:29 step:27933 [D loss: 0.663381, acc.: 59.38%] [G loss: 0.900072]\n",
      "epoch:29 step:27934 [D loss: 0.643329, acc.: 60.16%] [G loss: 0.908070]\n",
      "epoch:29 step:27935 [D loss: 0.698255, acc.: 46.88%] [G loss: 0.796758]\n",
      "epoch:29 step:27936 [D loss: 0.624223, acc.: 71.09%] [G loss: 0.867867]\n",
      "epoch:29 step:27937 [D loss: 0.643843, acc.: 61.72%] [G loss: 0.897193]\n",
      "epoch:29 step:27938 [D loss: 0.652766, acc.: 60.94%] [G loss: 0.878180]\n",
      "epoch:29 step:27939 [D loss: 0.649749, acc.: 60.16%] [G loss: 0.858331]\n",
      "epoch:29 step:27940 [D loss: 0.653882, acc.: 60.16%] [G loss: 0.875220]\n",
      "epoch:29 step:27941 [D loss: 0.668566, acc.: 58.59%] [G loss: 0.897457]\n",
      "epoch:29 step:27942 [D loss: 0.638348, acc.: 66.41%] [G loss: 1.018943]\n",
      "epoch:29 step:27943 [D loss: 0.659823, acc.: 60.16%] [G loss: 0.978060]\n",
      "epoch:29 step:27944 [D loss: 0.673811, acc.: 53.12%] [G loss: 0.977639]\n",
      "epoch:29 step:27945 [D loss: 0.624914, acc.: 64.84%] [G loss: 0.934320]\n",
      "epoch:29 step:27946 [D loss: 0.663911, acc.: 54.69%] [G loss: 0.901209]\n",
      "epoch:29 step:27947 [D loss: 0.671204, acc.: 60.16%] [G loss: 0.963140]\n",
      "epoch:29 step:27948 [D loss: 0.616693, acc.: 72.66%] [G loss: 0.929180]\n",
      "epoch:29 step:27949 [D loss: 0.650292, acc.: 59.38%] [G loss: 0.956143]\n",
      "epoch:29 step:27950 [D loss: 0.635631, acc.: 62.50%] [G loss: 0.923069]\n",
      "epoch:29 step:27951 [D loss: 0.619756, acc.: 67.19%] [G loss: 0.910808]\n",
      "epoch:29 step:27952 [D loss: 0.655650, acc.: 62.50%] [G loss: 0.931915]\n",
      "epoch:29 step:27953 [D loss: 0.652636, acc.: 59.38%] [G loss: 0.963169]\n",
      "epoch:29 step:27954 [D loss: 0.682839, acc.: 56.25%] [G loss: 0.970984]\n",
      "epoch:29 step:27955 [D loss: 0.629595, acc.: 67.97%] [G loss: 0.944046]\n",
      "epoch:29 step:27956 [D loss: 0.635756, acc.: 64.06%] [G loss: 0.986478]\n",
      "epoch:29 step:27957 [D loss: 0.647947, acc.: 61.72%] [G loss: 0.916250]\n",
      "epoch:29 step:27958 [D loss: 0.640144, acc.: 63.28%] [G loss: 0.900787]\n",
      "epoch:29 step:27959 [D loss: 0.682187, acc.: 57.81%] [G loss: 0.942058]\n",
      "epoch:29 step:27960 [D loss: 0.636354, acc.: 56.25%] [G loss: 0.913580]\n",
      "epoch:29 step:27961 [D loss: 0.641424, acc.: 61.72%] [G loss: 0.872430]\n",
      "epoch:29 step:27962 [D loss: 0.648885, acc.: 64.84%] [G loss: 0.854957]\n",
      "epoch:29 step:27963 [D loss: 0.655036, acc.: 58.59%] [G loss: 0.892795]\n",
      "epoch:29 step:27964 [D loss: 0.621506, acc.: 60.16%] [G loss: 0.903826]\n",
      "epoch:29 step:27965 [D loss: 0.655719, acc.: 62.50%] [G loss: 0.925004]\n",
      "epoch:29 step:27966 [D loss: 0.610555, acc.: 69.53%] [G loss: 0.926997]\n",
      "epoch:29 step:27967 [D loss: 0.647278, acc.: 64.84%] [G loss: 0.940483]\n",
      "epoch:29 step:27968 [D loss: 0.623700, acc.: 57.81%] [G loss: 0.929899]\n",
      "epoch:29 step:27969 [D loss: 0.648331, acc.: 63.28%] [G loss: 1.002185]\n",
      "epoch:29 step:27970 [D loss: 0.649442, acc.: 61.72%] [G loss: 0.943290]\n",
      "epoch:29 step:27971 [D loss: 0.628182, acc.: 67.19%] [G loss: 0.901468]\n",
      "epoch:29 step:27972 [D loss: 0.672005, acc.: 61.72%] [G loss: 0.955563]\n",
      "epoch:29 step:27973 [D loss: 0.643001, acc.: 65.62%] [G loss: 0.874966]\n",
      "epoch:29 step:27974 [D loss: 0.624171, acc.: 67.19%] [G loss: 0.984440]\n",
      "epoch:29 step:27975 [D loss: 0.647941, acc.: 64.06%] [G loss: 0.929026]\n",
      "epoch:29 step:27976 [D loss: 0.612724, acc.: 68.75%] [G loss: 0.932378]\n",
      "epoch:29 step:27977 [D loss: 0.682947, acc.: 52.34%] [G loss: 0.904545]\n",
      "epoch:29 step:27978 [D loss: 0.648446, acc.: 63.28%] [G loss: 0.937268]\n",
      "epoch:29 step:27979 [D loss: 0.627642, acc.: 66.41%] [G loss: 0.946104]\n",
      "epoch:29 step:27980 [D loss: 0.706712, acc.: 50.78%] [G loss: 0.898123]\n",
      "epoch:29 step:27981 [D loss: 0.658859, acc.: 63.28%] [G loss: 0.829989]\n",
      "epoch:29 step:27982 [D loss: 0.627053, acc.: 61.72%] [G loss: 0.864028]\n",
      "epoch:29 step:27983 [D loss: 0.656335, acc.: 56.25%] [G loss: 0.873656]\n",
      "epoch:29 step:27984 [D loss: 0.659414, acc.: 55.47%] [G loss: 0.854074]\n",
      "epoch:29 step:27985 [D loss: 0.668748, acc.: 51.56%] [G loss: 0.877914]\n",
      "epoch:29 step:27986 [D loss: 0.678138, acc.: 57.81%] [G loss: 0.927403]\n",
      "epoch:29 step:27987 [D loss: 0.642914, acc.: 61.72%] [G loss: 0.923774]\n",
      "epoch:29 step:27988 [D loss: 0.645608, acc.: 67.19%] [G loss: 1.042254]\n",
      "epoch:29 step:27989 [D loss: 0.638623, acc.: 62.50%] [G loss: 0.925980]\n",
      "epoch:29 step:27990 [D loss: 0.704807, acc.: 55.47%] [G loss: 0.891434]\n",
      "epoch:29 step:27991 [D loss: 0.705894, acc.: 50.00%] [G loss: 0.905461]\n",
      "epoch:29 step:27992 [D loss: 0.657626, acc.: 63.28%] [G loss: 0.932644]\n",
      "epoch:29 step:27993 [D loss: 0.635274, acc.: 64.06%] [G loss: 0.906171]\n",
      "epoch:29 step:27994 [D loss: 0.676093, acc.: 57.81%] [G loss: 0.914258]\n",
      "epoch:29 step:27995 [D loss: 0.618683, acc.: 65.62%] [G loss: 0.968017]\n",
      "epoch:29 step:27996 [D loss: 0.643371, acc.: 64.06%] [G loss: 0.960921]\n",
      "epoch:29 step:27997 [D loss: 0.644268, acc.: 64.84%] [G loss: 0.980469]\n",
      "epoch:29 step:27998 [D loss: 0.668073, acc.: 57.81%] [G loss: 0.863124]\n",
      "epoch:29 step:27999 [D loss: 0.634688, acc.: 63.28%] [G loss: 0.906094]\n",
      "epoch:29 step:28000 [D loss: 0.660059, acc.: 61.72%] [G loss: 0.863461]\n",
      "##############\n",
      "[2.90281201 2.68260676 2.2029462  3.62696705 1.08532403 7.08011669\n",
      " 2.77144543 3.46248215 4.30608118 5.53827923]\n",
      "##########\n",
      "epoch:29 step:28001 [D loss: 0.642018, acc.: 57.81%] [G loss: 0.862478]\n",
      "epoch:29 step:28002 [D loss: 0.663579, acc.: 59.38%] [G loss: 0.895725]\n",
      "epoch:29 step:28003 [D loss: 0.662590, acc.: 63.28%] [G loss: 0.924213]\n",
      "epoch:29 step:28004 [D loss: 0.643777, acc.: 64.84%] [G loss: 0.942314]\n",
      "epoch:29 step:28005 [D loss: 0.648945, acc.: 64.06%] [G loss: 0.920801]\n",
      "epoch:29 step:28006 [D loss: 0.671972, acc.: 56.25%] [G loss: 0.976656]\n",
      "epoch:29 step:28007 [D loss: 0.673142, acc.: 60.94%] [G loss: 0.913396]\n",
      "epoch:29 step:28008 [D loss: 0.690461, acc.: 54.69%] [G loss: 0.998808]\n",
      "epoch:29 step:28009 [D loss: 0.673999, acc.: 60.16%] [G loss: 0.838050]\n",
      "epoch:29 step:28010 [D loss: 0.678923, acc.: 56.25%] [G loss: 0.955569]\n",
      "epoch:29 step:28011 [D loss: 0.640947, acc.: 66.41%] [G loss: 0.862679]\n",
      "epoch:29 step:28012 [D loss: 0.658071, acc.: 60.16%] [G loss: 0.883021]\n",
      "epoch:29 step:28013 [D loss: 0.648988, acc.: 63.28%] [G loss: 0.877634]\n",
      "epoch:29 step:28014 [D loss: 0.677684, acc.: 58.59%] [G loss: 0.897435]\n",
      "epoch:29 step:28015 [D loss: 0.683534, acc.: 57.81%] [G loss: 0.871033]\n",
      "epoch:29 step:28016 [D loss: 0.699126, acc.: 55.47%] [G loss: 0.958607]\n",
      "epoch:29 step:28017 [D loss: 0.635676, acc.: 60.94%] [G loss: 0.904422]\n",
      "epoch:29 step:28018 [D loss: 0.638035, acc.: 65.62%] [G loss: 0.871808]\n",
      "epoch:29 step:28019 [D loss: 0.646502, acc.: 63.28%] [G loss: 0.966361]\n",
      "epoch:29 step:28020 [D loss: 0.598442, acc.: 69.53%] [G loss: 0.959162]\n",
      "epoch:29 step:28021 [D loss: 0.676432, acc.: 64.06%] [G loss: 0.903501]\n",
      "epoch:29 step:28022 [D loss: 0.667821, acc.: 60.16%] [G loss: 0.974204]\n",
      "epoch:29 step:28023 [D loss: 0.622553, acc.: 63.28%] [G loss: 0.951904]\n",
      "epoch:29 step:28024 [D loss: 0.683502, acc.: 57.81%] [G loss: 0.890289]\n",
      "epoch:29 step:28025 [D loss: 0.623892, acc.: 61.72%] [G loss: 0.907082]\n",
      "epoch:29 step:28026 [D loss: 0.670901, acc.: 57.03%] [G loss: 0.926757]\n",
      "epoch:29 step:28027 [D loss: 0.634478, acc.: 67.19%] [G loss: 0.918236]\n",
      "epoch:29 step:28028 [D loss: 0.647562, acc.: 62.50%] [G loss: 0.903830]\n",
      "epoch:29 step:28029 [D loss: 0.642942, acc.: 58.59%] [G loss: 0.963905]\n",
      "epoch:29 step:28030 [D loss: 0.636281, acc.: 64.06%] [G loss: 0.967061]\n",
      "epoch:29 step:28031 [D loss: 0.609375, acc.: 74.22%] [G loss: 0.947270]\n",
      "epoch:29 step:28032 [D loss: 0.640545, acc.: 60.94%] [G loss: 0.886456]\n",
      "epoch:29 step:28033 [D loss: 0.655715, acc.: 62.50%] [G loss: 0.928825]\n",
      "epoch:29 step:28034 [D loss: 0.613260, acc.: 69.53%] [G loss: 0.861372]\n",
      "epoch:29 step:28035 [D loss: 0.639991, acc.: 61.72%] [G loss: 0.829960]\n",
      "epoch:29 step:28036 [D loss: 0.646422, acc.: 59.38%] [G loss: 0.887124]\n",
      "epoch:29 step:28037 [D loss: 0.708234, acc.: 54.69%] [G loss: 0.903422]\n",
      "epoch:29 step:28038 [D loss: 0.639385, acc.: 59.38%] [G loss: 0.915427]\n",
      "epoch:29 step:28039 [D loss: 0.653179, acc.: 54.69%] [G loss: 0.929929]\n",
      "epoch:29 step:28040 [D loss: 0.687987, acc.: 57.81%] [G loss: 0.885360]\n",
      "epoch:29 step:28041 [D loss: 0.672781, acc.: 57.03%] [G loss: 0.910627]\n",
      "epoch:29 step:28042 [D loss: 0.630779, acc.: 67.19%] [G loss: 0.965787]\n",
      "epoch:29 step:28043 [D loss: 0.660713, acc.: 60.94%] [G loss: 0.970682]\n",
      "epoch:29 step:28044 [D loss: 0.640306, acc.: 58.59%] [G loss: 0.903472]\n",
      "epoch:29 step:28045 [D loss: 0.660399, acc.: 57.81%] [G loss: 0.894552]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:29 step:28046 [D loss: 0.648293, acc.: 62.50%] [G loss: 0.992260]\n",
      "epoch:29 step:28047 [D loss: 0.660421, acc.: 57.03%] [G loss: 0.992044]\n",
      "epoch:29 step:28048 [D loss: 0.626941, acc.: 71.09%] [G loss: 0.927487]\n",
      "epoch:29 step:28049 [D loss: 0.639789, acc.: 63.28%] [G loss: 0.949984]\n",
      "epoch:29 step:28050 [D loss: 0.619220, acc.: 67.97%] [G loss: 0.864234]\n",
      "epoch:29 step:28051 [D loss: 0.684636, acc.: 53.91%] [G loss: 0.872122]\n",
      "epoch:29 step:28052 [D loss: 0.655971, acc.: 56.25%] [G loss: 0.941457]\n",
      "epoch:29 step:28053 [D loss: 0.653811, acc.: 57.03%] [G loss: 0.935117]\n",
      "epoch:29 step:28054 [D loss: 0.668715, acc.: 57.81%] [G loss: 0.866485]\n",
      "epoch:29 step:28055 [D loss: 0.623056, acc.: 61.72%] [G loss: 0.898411]\n",
      "epoch:29 step:28056 [D loss: 0.656810, acc.: 57.03%] [G loss: 0.916695]\n",
      "epoch:29 step:28057 [D loss: 0.648309, acc.: 57.03%] [G loss: 0.918017]\n",
      "epoch:29 step:28058 [D loss: 0.675371, acc.: 54.69%] [G loss: 0.882638]\n",
      "epoch:29 step:28059 [D loss: 0.672849, acc.: 58.59%] [G loss: 0.956315]\n",
      "epoch:29 step:28060 [D loss: 0.646162, acc.: 58.59%] [G loss: 0.943515]\n",
      "epoch:29 step:28061 [D loss: 0.625640, acc.: 64.06%] [G loss: 0.937463]\n",
      "epoch:29 step:28062 [D loss: 0.630811, acc.: 60.94%] [G loss: 0.893862]\n",
      "epoch:29 step:28063 [D loss: 0.642836, acc.: 60.16%] [G loss: 0.904507]\n",
      "epoch:29 step:28064 [D loss: 0.657622, acc.: 60.16%] [G loss: 0.882627]\n",
      "epoch:29 step:28065 [D loss: 0.623014, acc.: 65.62%] [G loss: 0.870348]\n",
      "epoch:29 step:28066 [D loss: 0.647856, acc.: 64.84%] [G loss: 0.830287]\n",
      "epoch:29 step:28067 [D loss: 0.670937, acc.: 56.25%] [G loss: 0.881741]\n",
      "epoch:29 step:28068 [D loss: 0.593168, acc.: 68.75%] [G loss: 0.851018]\n",
      "epoch:29 step:28069 [D loss: 0.650979, acc.: 57.81%] [G loss: 0.819604]\n",
      "epoch:29 step:28070 [D loss: 0.637380, acc.: 60.94%] [G loss: 0.833333]\n",
      "epoch:29 step:28071 [D loss: 0.665216, acc.: 57.03%] [G loss: 0.838848]\n",
      "epoch:29 step:28072 [D loss: 0.655485, acc.: 60.94%] [G loss: 0.855769]\n",
      "epoch:29 step:28073 [D loss: 0.630381, acc.: 65.62%] [G loss: 0.872070]\n",
      "epoch:29 step:28074 [D loss: 0.662185, acc.: 60.16%] [G loss: 0.903794]\n",
      "epoch:29 step:28075 [D loss: 0.678011, acc.: 57.03%] [G loss: 0.873592]\n",
      "epoch:29 step:28076 [D loss: 0.654695, acc.: 60.16%] [G loss: 0.854793]\n",
      "epoch:29 step:28077 [D loss: 0.647953, acc.: 62.50%] [G loss: 0.960447]\n",
      "epoch:29 step:28078 [D loss: 0.695045, acc.: 57.03%] [G loss: 0.906062]\n",
      "epoch:29 step:28079 [D loss: 0.642619, acc.: 60.16%] [G loss: 0.878498]\n",
      "epoch:29 step:28080 [D loss: 0.700516, acc.: 56.25%] [G loss: 0.859015]\n",
      "epoch:29 step:28081 [D loss: 0.666097, acc.: 61.72%] [G loss: 0.937712]\n",
      "epoch:29 step:28082 [D loss: 0.702693, acc.: 55.47%] [G loss: 0.908306]\n",
      "epoch:29 step:28083 [D loss: 0.684894, acc.: 52.34%] [G loss: 0.951746]\n",
      "epoch:29 step:28084 [D loss: 0.606712, acc.: 67.19%] [G loss: 0.887791]\n",
      "epoch:29 step:28085 [D loss: 0.656467, acc.: 56.25%] [G loss: 0.927264]\n",
      "epoch:29 step:28086 [D loss: 0.664750, acc.: 61.72%] [G loss: 0.924143]\n",
      "epoch:29 step:28087 [D loss: 0.643150, acc.: 63.28%] [G loss: 0.947936]\n",
      "epoch:29 step:28088 [D loss: 0.633806, acc.: 67.19%] [G loss: 0.829856]\n",
      "epoch:29 step:28089 [D loss: 0.673888, acc.: 57.81%] [G loss: 0.844257]\n",
      "epoch:29 step:28090 [D loss: 0.670033, acc.: 57.81%] [G loss: 0.899373]\n",
      "epoch:29 step:28091 [D loss: 0.659265, acc.: 60.16%] [G loss: 0.895063]\n",
      "epoch:29 step:28092 [D loss: 0.659993, acc.: 60.94%] [G loss: 0.878709]\n",
      "epoch:29 step:28093 [D loss: 0.651816, acc.: 58.59%] [G loss: 0.968257]\n",
      "epoch:29 step:28094 [D loss: 0.645795, acc.: 64.84%] [G loss: 0.916347]\n",
      "epoch:29 step:28095 [D loss: 0.656312, acc.: 59.38%] [G loss: 0.932649]\n",
      "epoch:29 step:28096 [D loss: 0.646245, acc.: 65.62%] [G loss: 0.891907]\n",
      "epoch:29 step:28097 [D loss: 0.660886, acc.: 60.16%] [G loss: 0.905449]\n",
      "epoch:29 step:28098 [D loss: 0.653430, acc.: 62.50%] [G loss: 0.908557]\n",
      "epoch:29 step:28099 [D loss: 0.636743, acc.: 61.72%] [G loss: 0.887453]\n",
      "epoch:29 step:28100 [D loss: 0.669108, acc.: 59.38%] [G loss: 0.912203]\n",
      "epoch:29 step:28101 [D loss: 0.636043, acc.: 57.81%] [G loss: 0.925797]\n",
      "epoch:29 step:28102 [D loss: 0.670234, acc.: 57.03%] [G loss: 0.879754]\n",
      "epoch:29 step:28103 [D loss: 0.620453, acc.: 64.84%] [G loss: 0.929201]\n",
      "epoch:29 step:28104 [D loss: 0.656139, acc.: 62.50%] [G loss: 0.896197]\n",
      "epoch:29 step:28105 [D loss: 0.635318, acc.: 64.84%] [G loss: 0.836932]\n",
      "epoch:29 step:28106 [D loss: 0.672621, acc.: 56.25%] [G loss: 0.860911]\n",
      "epoch:29 step:28107 [D loss: 0.623132, acc.: 64.06%] [G loss: 0.862841]\n",
      "epoch:29 step:28108 [D loss: 0.683710, acc.: 55.47%] [G loss: 0.889021]\n",
      "epoch:29 step:28109 [D loss: 0.674148, acc.: 60.16%] [G loss: 0.865567]\n",
      "epoch:29 step:28110 [D loss: 0.610867, acc.: 64.06%] [G loss: 0.910352]\n",
      "epoch:30 step:28111 [D loss: 0.695079, acc.: 59.38%] [G loss: 0.908668]\n",
      "epoch:30 step:28112 [D loss: 0.668557, acc.: 59.38%] [G loss: 0.897277]\n",
      "epoch:30 step:28113 [D loss: 0.643465, acc.: 61.72%] [G loss: 0.906928]\n",
      "epoch:30 step:28114 [D loss: 0.641053, acc.: 64.84%] [G loss: 0.933761]\n",
      "epoch:30 step:28115 [D loss: 0.666977, acc.: 60.16%] [G loss: 0.908685]\n",
      "epoch:30 step:28116 [D loss: 0.652745, acc.: 63.28%] [G loss: 0.932067]\n",
      "epoch:30 step:28117 [D loss: 0.663921, acc.: 55.47%] [G loss: 0.866581]\n",
      "epoch:30 step:28118 [D loss: 0.688867, acc.: 55.47%] [G loss: 0.850184]\n",
      "epoch:30 step:28119 [D loss: 0.641276, acc.: 58.59%] [G loss: 0.876160]\n",
      "epoch:30 step:28120 [D loss: 0.615782, acc.: 67.97%] [G loss: 0.927000]\n",
      "epoch:30 step:28121 [D loss: 0.616752, acc.: 63.28%] [G loss: 0.905346]\n",
      "epoch:30 step:28122 [D loss: 0.628229, acc.: 61.72%] [G loss: 0.824791]\n",
      "epoch:30 step:28123 [D loss: 0.644906, acc.: 59.38%] [G loss: 0.899177]\n",
      "epoch:30 step:28124 [D loss: 0.684508, acc.: 56.25%] [G loss: 0.901684]\n",
      "epoch:30 step:28125 [D loss: 0.639128, acc.: 63.28%] [G loss: 0.962542]\n",
      "epoch:30 step:28126 [D loss: 0.618736, acc.: 68.75%] [G loss: 0.856179]\n",
      "epoch:30 step:28127 [D loss: 0.601175, acc.: 71.88%] [G loss: 0.869291]\n",
      "epoch:30 step:28128 [D loss: 0.668816, acc.: 56.25%] [G loss: 0.905886]\n",
      "epoch:30 step:28129 [D loss: 0.676451, acc.: 56.25%] [G loss: 0.973404]\n",
      "epoch:30 step:28130 [D loss: 0.648830, acc.: 57.81%] [G loss: 0.908425]\n",
      "epoch:30 step:28131 [D loss: 0.666999, acc.: 57.81%] [G loss: 0.866809]\n",
      "epoch:30 step:28132 [D loss: 0.663331, acc.: 61.72%] [G loss: 0.855259]\n",
      "epoch:30 step:28133 [D loss: 0.620190, acc.: 69.53%] [G loss: 0.893917]\n",
      "epoch:30 step:28134 [D loss: 0.686352, acc.: 54.69%] [G loss: 0.852134]\n",
      "epoch:30 step:28135 [D loss: 0.634322, acc.: 60.94%] [G loss: 0.863008]\n",
      "epoch:30 step:28136 [D loss: 0.681683, acc.: 59.38%] [G loss: 0.925324]\n",
      "epoch:30 step:28137 [D loss: 0.701787, acc.: 52.34%] [G loss: 0.909627]\n",
      "epoch:30 step:28138 [D loss: 0.648127, acc.: 64.84%] [G loss: 0.892533]\n",
      "epoch:30 step:28139 [D loss: 0.646326, acc.: 69.53%] [G loss: 0.865448]\n",
      "epoch:30 step:28140 [D loss: 0.667344, acc.: 60.16%] [G loss: 0.894546]\n",
      "epoch:30 step:28141 [D loss: 0.660464, acc.: 64.06%] [G loss: 0.946683]\n",
      "epoch:30 step:28142 [D loss: 0.646738, acc.: 64.06%] [G loss: 0.944921]\n",
      "epoch:30 step:28143 [D loss: 0.658997, acc.: 58.59%] [G loss: 0.952720]\n",
      "epoch:30 step:28144 [D loss: 0.659612, acc.: 60.94%] [G loss: 0.919310]\n",
      "epoch:30 step:28145 [D loss: 0.689074, acc.: 51.56%] [G loss: 0.925518]\n",
      "epoch:30 step:28146 [D loss: 0.618866, acc.: 73.44%] [G loss: 0.900874]\n",
      "epoch:30 step:28147 [D loss: 0.626763, acc.: 65.62%] [G loss: 0.897357]\n",
      "epoch:30 step:28148 [D loss: 0.725900, acc.: 51.56%] [G loss: 0.916728]\n",
      "epoch:30 step:28149 [D loss: 0.624805, acc.: 67.19%] [G loss: 0.930540]\n",
      "epoch:30 step:28150 [D loss: 0.676523, acc.: 53.91%] [G loss: 0.884644]\n",
      "epoch:30 step:28151 [D loss: 0.630151, acc.: 65.62%] [G loss: 0.912694]\n",
      "epoch:30 step:28152 [D loss: 0.650195, acc.: 60.16%] [G loss: 0.922992]\n",
      "epoch:30 step:28153 [D loss: 0.632768, acc.: 65.62%] [G loss: 0.927190]\n",
      "epoch:30 step:28154 [D loss: 0.636261, acc.: 65.62%] [G loss: 0.912449]\n",
      "epoch:30 step:28155 [D loss: 0.697427, acc.: 57.81%] [G loss: 0.926955]\n",
      "epoch:30 step:28156 [D loss: 0.655086, acc.: 60.16%] [G loss: 0.931618]\n",
      "epoch:30 step:28157 [D loss: 0.669659, acc.: 58.59%] [G loss: 0.904125]\n",
      "epoch:30 step:28158 [D loss: 0.632962, acc.: 67.97%] [G loss: 0.950066]\n",
      "epoch:30 step:28159 [D loss: 0.647437, acc.: 63.28%] [G loss: 0.898727]\n",
      "epoch:30 step:28160 [D loss: 0.618520, acc.: 63.28%] [G loss: 0.875320]\n",
      "epoch:30 step:28161 [D loss: 0.633734, acc.: 64.84%] [G loss: 0.869334]\n",
      "epoch:30 step:28162 [D loss: 0.601040, acc.: 67.19%] [G loss: 0.887383]\n",
      "epoch:30 step:28163 [D loss: 0.671344, acc.: 64.06%] [G loss: 0.957547]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:28164 [D loss: 0.627574, acc.: 68.75%] [G loss: 0.971359]\n",
      "epoch:30 step:28165 [D loss: 0.636884, acc.: 69.53%] [G loss: 0.968972]\n",
      "epoch:30 step:28166 [D loss: 0.635733, acc.: 63.28%] [G loss: 0.906727]\n",
      "epoch:30 step:28167 [D loss: 0.645801, acc.: 61.72%] [G loss: 0.940495]\n",
      "epoch:30 step:28168 [D loss: 0.675423, acc.: 59.38%] [G loss: 0.919375]\n",
      "epoch:30 step:28169 [D loss: 0.625067, acc.: 67.97%] [G loss: 0.950166]\n",
      "epoch:30 step:28170 [D loss: 0.643601, acc.: 66.41%] [G loss: 0.944496]\n",
      "epoch:30 step:28171 [D loss: 0.635635, acc.: 62.50%] [G loss: 0.909105]\n",
      "epoch:30 step:28172 [D loss: 0.612910, acc.: 67.97%] [G loss: 0.873949]\n",
      "epoch:30 step:28173 [D loss: 0.623575, acc.: 67.97%] [G loss: 0.902371]\n",
      "epoch:30 step:28174 [D loss: 0.637540, acc.: 63.28%] [G loss: 0.868004]\n",
      "epoch:30 step:28175 [D loss: 0.650386, acc.: 60.94%] [G loss: 0.929386]\n",
      "epoch:30 step:28176 [D loss: 0.691377, acc.: 57.03%] [G loss: 0.925935]\n",
      "epoch:30 step:28177 [D loss: 0.672028, acc.: 57.81%] [G loss: 0.969544]\n",
      "epoch:30 step:28178 [D loss: 0.646045, acc.: 61.72%] [G loss: 0.932075]\n",
      "epoch:30 step:28179 [D loss: 0.637181, acc.: 61.72%] [G loss: 0.924012]\n",
      "epoch:30 step:28180 [D loss: 0.607106, acc.: 69.53%] [G loss: 0.953529]\n",
      "epoch:30 step:28181 [D loss: 0.612993, acc.: 67.19%] [G loss: 0.936844]\n",
      "epoch:30 step:28182 [D loss: 0.686643, acc.: 56.25%] [G loss: 0.901809]\n",
      "epoch:30 step:28183 [D loss: 0.609261, acc.: 66.41%] [G loss: 0.854207]\n",
      "epoch:30 step:28184 [D loss: 0.648240, acc.: 64.06%] [G loss: 0.924766]\n",
      "epoch:30 step:28185 [D loss: 0.644159, acc.: 54.69%] [G loss: 0.894380]\n",
      "epoch:30 step:28186 [D loss: 0.620301, acc.: 63.28%] [G loss: 0.905985]\n",
      "epoch:30 step:28187 [D loss: 0.675954, acc.: 56.25%] [G loss: 0.952962]\n",
      "epoch:30 step:28188 [D loss: 0.655084, acc.: 58.59%] [G loss: 0.921331]\n",
      "epoch:30 step:28189 [D loss: 0.667256, acc.: 56.25%] [G loss: 0.896351]\n",
      "epoch:30 step:28190 [D loss: 0.654265, acc.: 58.59%] [G loss: 0.934100]\n",
      "epoch:30 step:28191 [D loss: 0.657230, acc.: 60.16%] [G loss: 0.860168]\n",
      "epoch:30 step:28192 [D loss: 0.617082, acc.: 66.41%] [G loss: 0.879589]\n",
      "epoch:30 step:28193 [D loss: 0.664187, acc.: 60.94%] [G loss: 0.909076]\n",
      "epoch:30 step:28194 [D loss: 0.631644, acc.: 60.16%] [G loss: 0.883873]\n",
      "epoch:30 step:28195 [D loss: 0.665076, acc.: 59.38%] [G loss: 0.944048]\n",
      "epoch:30 step:28196 [D loss: 0.685536, acc.: 50.78%] [G loss: 0.898563]\n",
      "epoch:30 step:28197 [D loss: 0.631555, acc.: 67.97%] [G loss: 0.949450]\n",
      "epoch:30 step:28198 [D loss: 0.671659, acc.: 60.94%] [G loss: 0.884131]\n",
      "epoch:30 step:28199 [D loss: 0.666459, acc.: 62.50%] [G loss: 0.883055]\n",
      "epoch:30 step:28200 [D loss: 0.643191, acc.: 61.72%] [G loss: 0.909285]\n",
      "##############\n",
      "[2.97155769 2.26788506 2.29104411 3.85977272 1.12419266 7.17451774\n",
      " 2.79401444 3.2382813  4.21506372 8.14868929]\n",
      "##########\n",
      "epoch:30 step:28201 [D loss: 0.681883, acc.: 56.25%] [G loss: 0.944186]\n",
      "epoch:30 step:28202 [D loss: 0.638969, acc.: 66.41%] [G loss: 0.918442]\n",
      "epoch:30 step:28203 [D loss: 0.647152, acc.: 56.25%] [G loss: 0.922502]\n",
      "epoch:30 step:28204 [D loss: 0.647295, acc.: 60.16%] [G loss: 0.887603]\n",
      "epoch:30 step:28205 [D loss: 0.661226, acc.: 61.72%] [G loss: 0.948747]\n",
      "epoch:30 step:28206 [D loss: 0.628060, acc.: 67.97%] [G loss: 0.932952]\n",
      "epoch:30 step:28207 [D loss: 0.622282, acc.: 66.41%] [G loss: 0.911863]\n",
      "epoch:30 step:28208 [D loss: 0.641005, acc.: 57.81%] [G loss: 0.865676]\n",
      "epoch:30 step:28209 [D loss: 0.642643, acc.: 65.62%] [G loss: 0.866326]\n",
      "epoch:30 step:28210 [D loss: 0.685241, acc.: 59.38%] [G loss: 0.893157]\n",
      "epoch:30 step:28211 [D loss: 0.676273, acc.: 53.91%] [G loss: 0.857809]\n",
      "epoch:30 step:28212 [D loss: 0.677409, acc.: 58.59%] [G loss: 0.905493]\n",
      "epoch:30 step:28213 [D loss: 0.651048, acc.: 62.50%] [G loss: 0.879324]\n",
      "epoch:30 step:28214 [D loss: 0.663675, acc.: 60.94%] [G loss: 0.926300]\n",
      "epoch:30 step:28215 [D loss: 0.605963, acc.: 68.75%] [G loss: 0.887943]\n",
      "epoch:30 step:28216 [D loss: 0.642852, acc.: 64.84%] [G loss: 0.883575]\n",
      "epoch:30 step:28217 [D loss: 0.661785, acc.: 56.25%] [G loss: 0.894834]\n",
      "epoch:30 step:28218 [D loss: 0.665886, acc.: 64.06%] [G loss: 0.907928]\n",
      "epoch:30 step:28219 [D loss: 0.617679, acc.: 67.19%] [G loss: 0.918362]\n",
      "epoch:30 step:28220 [D loss: 0.663545, acc.: 57.81%] [G loss: 0.903897]\n",
      "epoch:30 step:28221 [D loss: 0.648665, acc.: 59.38%] [G loss: 0.890814]\n",
      "epoch:30 step:28222 [D loss: 0.693491, acc.: 58.59%] [G loss: 0.932697]\n",
      "epoch:30 step:28223 [D loss: 0.677545, acc.: 57.03%] [G loss: 0.905643]\n",
      "epoch:30 step:28224 [D loss: 0.652380, acc.: 59.38%] [G loss: 0.932217]\n",
      "epoch:30 step:28225 [D loss: 0.636739, acc.: 66.41%] [G loss: 0.960781]\n",
      "epoch:30 step:28226 [D loss: 0.660615, acc.: 62.50%] [G loss: 0.918906]\n",
      "epoch:30 step:28227 [D loss: 0.681287, acc.: 56.25%] [G loss: 0.885930]\n",
      "epoch:30 step:28228 [D loss: 0.666561, acc.: 57.81%] [G loss: 0.848762]\n",
      "epoch:30 step:28229 [D loss: 0.668627, acc.: 58.59%] [G loss: 0.903924]\n",
      "epoch:30 step:28230 [D loss: 0.667803, acc.: 59.38%] [G loss: 0.881304]\n",
      "epoch:30 step:28231 [D loss: 0.617711, acc.: 68.75%] [G loss: 0.861069]\n",
      "epoch:30 step:28232 [D loss: 0.635756, acc.: 61.72%] [G loss: 0.891151]\n",
      "epoch:30 step:28233 [D loss: 0.716849, acc.: 56.25%] [G loss: 0.894363]\n",
      "epoch:30 step:28234 [D loss: 0.656041, acc.: 60.16%] [G loss: 0.915527]\n",
      "epoch:30 step:28235 [D loss: 0.632959, acc.: 64.06%] [G loss: 0.920819]\n",
      "epoch:30 step:28236 [D loss: 0.701267, acc.: 53.91%] [G loss: 0.899060]\n",
      "epoch:30 step:28237 [D loss: 0.628239, acc.: 66.41%] [G loss: 0.921339]\n",
      "epoch:30 step:28238 [D loss: 0.651127, acc.: 58.59%] [G loss: 0.908360]\n",
      "epoch:30 step:28239 [D loss: 0.630052, acc.: 63.28%] [G loss: 0.898754]\n",
      "epoch:30 step:28240 [D loss: 0.612601, acc.: 67.19%] [G loss: 0.910743]\n",
      "epoch:30 step:28241 [D loss: 0.641478, acc.: 60.94%] [G loss: 0.866129]\n",
      "epoch:30 step:28242 [D loss: 0.667023, acc.: 55.47%] [G loss: 0.891434]\n",
      "epoch:30 step:28243 [D loss: 0.660167, acc.: 59.38%] [G loss: 0.890667]\n",
      "epoch:30 step:28244 [D loss: 0.669082, acc.: 55.47%] [G loss: 0.827223]\n",
      "epoch:30 step:28245 [D loss: 0.701861, acc.: 55.47%] [G loss: 0.842189]\n",
      "epoch:30 step:28246 [D loss: 0.657967, acc.: 57.81%] [G loss: 0.821111]\n",
      "epoch:30 step:28247 [D loss: 0.665371, acc.: 57.81%] [G loss: 0.879045]\n",
      "epoch:30 step:28248 [D loss: 0.648855, acc.: 58.59%] [G loss: 0.894097]\n",
      "epoch:30 step:28249 [D loss: 0.666875, acc.: 64.06%] [G loss: 0.895897]\n",
      "epoch:30 step:28250 [D loss: 0.674874, acc.: 56.25%] [G loss: 0.878760]\n",
      "epoch:30 step:28251 [D loss: 0.670534, acc.: 57.03%] [G loss: 0.898702]\n",
      "epoch:30 step:28252 [D loss: 0.661247, acc.: 59.38%] [G loss: 0.912816]\n",
      "epoch:30 step:28253 [D loss: 0.617734, acc.: 65.62%] [G loss: 0.975627]\n",
      "epoch:30 step:28254 [D loss: 0.691387, acc.: 55.47%] [G loss: 0.907055]\n",
      "epoch:30 step:28255 [D loss: 0.686139, acc.: 54.69%] [G loss: 0.872308]\n",
      "epoch:30 step:28256 [D loss: 0.647842, acc.: 60.16%] [G loss: 0.938824]\n",
      "epoch:30 step:28257 [D loss: 0.691733, acc.: 52.34%] [G loss: 0.941806]\n",
      "epoch:30 step:28258 [D loss: 0.671423, acc.: 59.38%] [G loss: 0.939833]\n",
      "epoch:30 step:28259 [D loss: 0.663668, acc.: 55.47%] [G loss: 0.909732]\n",
      "epoch:30 step:28260 [D loss: 0.644207, acc.: 60.94%] [G loss: 0.849560]\n",
      "epoch:30 step:28261 [D loss: 0.643947, acc.: 62.50%] [G loss: 1.024576]\n",
      "epoch:30 step:28262 [D loss: 0.658023, acc.: 57.03%] [G loss: 0.933624]\n",
      "epoch:30 step:28263 [D loss: 0.636861, acc.: 67.19%] [G loss: 0.946496]\n",
      "epoch:30 step:28264 [D loss: 0.675940, acc.: 57.81%] [G loss: 0.956794]\n",
      "epoch:30 step:28265 [D loss: 0.649780, acc.: 61.72%] [G loss: 0.906698]\n",
      "epoch:30 step:28266 [D loss: 0.634875, acc.: 64.06%] [G loss: 0.897173]\n",
      "epoch:30 step:28267 [D loss: 0.642438, acc.: 58.59%] [G loss: 0.926768]\n",
      "epoch:30 step:28268 [D loss: 0.642924, acc.: 60.94%] [G loss: 0.895090]\n",
      "epoch:30 step:28269 [D loss: 0.655295, acc.: 62.50%] [G loss: 0.898107]\n",
      "epoch:30 step:28270 [D loss: 0.636701, acc.: 59.38%] [G loss: 0.869428]\n",
      "epoch:30 step:28271 [D loss: 0.652387, acc.: 64.84%] [G loss: 0.917523]\n",
      "epoch:30 step:28272 [D loss: 0.633406, acc.: 64.06%] [G loss: 0.976831]\n",
      "epoch:30 step:28273 [D loss: 0.665038, acc.: 60.16%] [G loss: 0.908069]\n",
      "epoch:30 step:28274 [D loss: 0.675082, acc.: 57.81%] [G loss: 0.892693]\n",
      "epoch:30 step:28275 [D loss: 0.655153, acc.: 61.72%] [G loss: 0.913197]\n",
      "epoch:30 step:28276 [D loss: 0.679733, acc.: 57.03%] [G loss: 0.885347]\n",
      "epoch:30 step:28277 [D loss: 0.636205, acc.: 64.06%] [G loss: 0.954389]\n",
      "epoch:30 step:28278 [D loss: 0.609739, acc.: 70.31%] [G loss: 0.893949]\n",
      "epoch:30 step:28279 [D loss: 0.691445, acc.: 51.56%] [G loss: 0.859586]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:28280 [D loss: 0.597330, acc.: 68.75%] [G loss: 0.926423]\n",
      "epoch:30 step:28281 [D loss: 0.671180, acc.: 56.25%] [G loss: 0.888708]\n",
      "epoch:30 step:28282 [D loss: 0.690052, acc.: 53.91%] [G loss: 0.896240]\n",
      "epoch:30 step:28283 [D loss: 0.621176, acc.: 67.19%] [G loss: 0.887355]\n",
      "epoch:30 step:28284 [D loss: 0.655957, acc.: 60.94%] [G loss: 0.935772]\n",
      "epoch:30 step:28285 [D loss: 0.631872, acc.: 64.84%] [G loss: 0.899985]\n",
      "epoch:30 step:28286 [D loss: 0.613107, acc.: 69.53%] [G loss: 0.918553]\n",
      "epoch:30 step:28287 [D loss: 0.621203, acc.: 71.09%] [G loss: 0.965398]\n",
      "epoch:30 step:28288 [D loss: 0.647149, acc.: 59.38%] [G loss: 0.967102]\n",
      "epoch:30 step:28289 [D loss: 0.630338, acc.: 61.72%] [G loss: 0.912583]\n",
      "epoch:30 step:28290 [D loss: 0.642819, acc.: 65.62%] [G loss: 0.901430]\n",
      "epoch:30 step:28291 [D loss: 0.699233, acc.: 50.00%] [G loss: 0.922525]\n",
      "epoch:30 step:28292 [D loss: 0.652524, acc.: 65.62%] [G loss: 0.902767]\n",
      "epoch:30 step:28293 [D loss: 0.638199, acc.: 60.94%] [G loss: 0.902845]\n",
      "epoch:30 step:28294 [D loss: 0.658286, acc.: 62.50%] [G loss: 0.926077]\n",
      "epoch:30 step:28295 [D loss: 0.636053, acc.: 64.06%] [G loss: 0.904255]\n",
      "epoch:30 step:28296 [D loss: 0.636100, acc.: 58.59%] [G loss: 0.927491]\n",
      "epoch:30 step:28297 [D loss: 0.660697, acc.: 57.81%] [G loss: 0.926433]\n",
      "epoch:30 step:28298 [D loss: 0.672497, acc.: 55.47%] [G loss: 0.899875]\n",
      "epoch:30 step:28299 [D loss: 0.628599, acc.: 64.06%] [G loss: 0.865895]\n",
      "epoch:30 step:28300 [D loss: 0.647944, acc.: 62.50%] [G loss: 0.913488]\n",
      "epoch:30 step:28301 [D loss: 0.624173, acc.: 63.28%] [G loss: 0.909197]\n",
      "epoch:30 step:28302 [D loss: 0.680094, acc.: 60.94%] [G loss: 0.864377]\n",
      "epoch:30 step:28303 [D loss: 0.635611, acc.: 64.84%] [G loss: 0.933998]\n",
      "epoch:30 step:28304 [D loss: 0.693155, acc.: 57.03%] [G loss: 0.946995]\n",
      "epoch:30 step:28305 [D loss: 0.618823, acc.: 67.19%] [G loss: 0.912022]\n",
      "epoch:30 step:28306 [D loss: 0.665384, acc.: 58.59%] [G loss: 0.956209]\n",
      "epoch:30 step:28307 [D loss: 0.588356, acc.: 70.31%] [G loss: 0.939902]\n",
      "epoch:30 step:28308 [D loss: 0.625484, acc.: 66.41%] [G loss: 1.002893]\n",
      "epoch:30 step:28309 [D loss: 0.621369, acc.: 66.41%] [G loss: 0.969690]\n",
      "epoch:30 step:28310 [D loss: 0.611219, acc.: 69.53%] [G loss: 0.884741]\n",
      "epoch:30 step:28311 [D loss: 0.663939, acc.: 61.72%] [G loss: 0.888125]\n",
      "epoch:30 step:28312 [D loss: 0.582816, acc.: 67.97%] [G loss: 0.881995]\n",
      "epoch:30 step:28313 [D loss: 0.650503, acc.: 62.50%] [G loss: 0.955339]\n",
      "epoch:30 step:28314 [D loss: 0.599742, acc.: 67.97%] [G loss: 1.008994]\n",
      "epoch:30 step:28315 [D loss: 0.608302, acc.: 67.97%] [G loss: 0.892952]\n",
      "epoch:30 step:28316 [D loss: 0.645345, acc.: 64.84%] [G loss: 0.895085]\n",
      "epoch:30 step:28317 [D loss: 0.643502, acc.: 60.94%] [G loss: 0.913200]\n",
      "epoch:30 step:28318 [D loss: 0.640387, acc.: 64.84%] [G loss: 0.895693]\n",
      "epoch:30 step:28319 [D loss: 0.647891, acc.: 60.94%] [G loss: 0.932809]\n",
      "epoch:30 step:28320 [D loss: 0.678483, acc.: 64.06%] [G loss: 0.880434]\n",
      "epoch:30 step:28321 [D loss: 0.649383, acc.: 57.81%] [G loss: 0.891486]\n",
      "epoch:30 step:28322 [D loss: 0.625620, acc.: 66.41%] [G loss: 0.926934]\n",
      "epoch:30 step:28323 [D loss: 0.652130, acc.: 63.28%] [G loss: 0.934312]\n",
      "epoch:30 step:28324 [D loss: 0.668580, acc.: 59.38%] [G loss: 0.907964]\n",
      "epoch:30 step:28325 [D loss: 0.639887, acc.: 63.28%] [G loss: 0.900299]\n",
      "epoch:30 step:28326 [D loss: 0.672224, acc.: 57.03%] [G loss: 0.912761]\n",
      "epoch:30 step:28327 [D loss: 0.602912, acc.: 66.41%] [G loss: 0.896203]\n",
      "epoch:30 step:28328 [D loss: 0.666590, acc.: 56.25%] [G loss: 0.950575]\n",
      "epoch:30 step:28329 [D loss: 0.679997, acc.: 54.69%] [G loss: 0.909463]\n",
      "epoch:30 step:28330 [D loss: 0.660872, acc.: 58.59%] [G loss: 0.857279]\n",
      "epoch:30 step:28331 [D loss: 0.629037, acc.: 62.50%] [G loss: 0.857351]\n",
      "epoch:30 step:28332 [D loss: 0.656422, acc.: 57.03%] [G loss: 0.901547]\n",
      "epoch:30 step:28333 [D loss: 0.645399, acc.: 59.38%] [G loss: 0.949354]\n",
      "epoch:30 step:28334 [D loss: 0.665406, acc.: 58.59%] [G loss: 0.869230]\n",
      "epoch:30 step:28335 [D loss: 0.674773, acc.: 54.69%] [G loss: 0.921122]\n",
      "epoch:30 step:28336 [D loss: 0.651354, acc.: 64.84%] [G loss: 0.948442]\n",
      "epoch:30 step:28337 [D loss: 0.630339, acc.: 60.94%] [G loss: 0.948379]\n",
      "epoch:30 step:28338 [D loss: 0.596879, acc.: 69.53%] [G loss: 0.934955]\n",
      "epoch:30 step:28339 [D loss: 0.670858, acc.: 57.81%] [G loss: 0.868576]\n",
      "epoch:30 step:28340 [D loss: 0.620446, acc.: 70.31%] [G loss: 0.880179]\n",
      "epoch:30 step:28341 [D loss: 0.663985, acc.: 58.59%] [G loss: 0.899362]\n",
      "epoch:30 step:28342 [D loss: 0.659343, acc.: 59.38%] [G loss: 0.900631]\n",
      "epoch:30 step:28343 [D loss: 0.640944, acc.: 64.06%] [G loss: 0.857956]\n",
      "epoch:30 step:28344 [D loss: 0.621241, acc.: 64.84%] [G loss: 0.896499]\n",
      "epoch:30 step:28345 [D loss: 0.645715, acc.: 61.72%] [G loss: 0.865008]\n",
      "epoch:30 step:28346 [D loss: 0.650456, acc.: 61.72%] [G loss: 0.965750]\n",
      "epoch:30 step:28347 [D loss: 0.672555, acc.: 60.94%] [G loss: 0.850029]\n",
      "epoch:30 step:28348 [D loss: 0.659701, acc.: 57.81%] [G loss: 0.865982]\n",
      "epoch:30 step:28349 [D loss: 0.665443, acc.: 53.91%] [G loss: 0.971478]\n",
      "epoch:30 step:28350 [D loss: 0.637517, acc.: 60.16%] [G loss: 0.952877]\n",
      "epoch:30 step:28351 [D loss: 0.632497, acc.: 60.94%] [G loss: 0.913112]\n",
      "epoch:30 step:28352 [D loss: 0.635862, acc.: 67.97%] [G loss: 0.915377]\n",
      "epoch:30 step:28353 [D loss: 0.631282, acc.: 63.28%] [G loss: 0.887045]\n",
      "epoch:30 step:28354 [D loss: 0.680448, acc.: 58.59%] [G loss: 0.877262]\n",
      "epoch:30 step:28355 [D loss: 0.675355, acc.: 57.03%] [G loss: 0.887911]\n",
      "epoch:30 step:28356 [D loss: 0.650617, acc.: 64.06%] [G loss: 0.908615]\n",
      "epoch:30 step:28357 [D loss: 0.639340, acc.: 62.50%] [G loss: 0.913895]\n",
      "epoch:30 step:28358 [D loss: 0.633182, acc.: 61.72%] [G loss: 0.870164]\n",
      "epoch:30 step:28359 [D loss: 0.656497, acc.: 67.97%] [G loss: 0.885034]\n",
      "epoch:30 step:28360 [D loss: 0.602760, acc.: 69.53%] [G loss: 0.827296]\n",
      "epoch:30 step:28361 [D loss: 0.656121, acc.: 63.28%] [G loss: 0.920473]\n",
      "epoch:30 step:28362 [D loss: 0.645538, acc.: 62.50%] [G loss: 0.882788]\n",
      "epoch:30 step:28363 [D loss: 0.681272, acc.: 63.28%] [G loss: 0.944420]\n",
      "epoch:30 step:28364 [D loss: 0.686399, acc.: 56.25%] [G loss: 0.897807]\n",
      "epoch:30 step:28365 [D loss: 0.660884, acc.: 60.16%] [G loss: 0.938195]\n",
      "epoch:30 step:28366 [D loss: 0.672605, acc.: 57.03%] [G loss: 0.954917]\n",
      "epoch:30 step:28367 [D loss: 0.661946, acc.: 61.72%] [G loss: 0.926284]\n",
      "epoch:30 step:28368 [D loss: 0.665749, acc.: 55.47%] [G loss: 0.913912]\n",
      "epoch:30 step:28369 [D loss: 0.692226, acc.: 50.78%] [G loss: 0.856051]\n",
      "epoch:30 step:28370 [D loss: 0.650201, acc.: 60.16%] [G loss: 0.946945]\n",
      "epoch:30 step:28371 [D loss: 0.679726, acc.: 57.81%] [G loss: 0.876368]\n",
      "epoch:30 step:28372 [D loss: 0.680047, acc.: 57.03%] [G loss: 0.894198]\n",
      "epoch:30 step:28373 [D loss: 0.626795, acc.: 63.28%] [G loss: 0.936697]\n",
      "epoch:30 step:28374 [D loss: 0.617182, acc.: 61.72%] [G loss: 0.888473]\n",
      "epoch:30 step:28375 [D loss: 0.642412, acc.: 64.06%] [G loss: 0.911308]\n",
      "epoch:30 step:28376 [D loss: 0.617083, acc.: 64.84%] [G loss: 0.921577]\n",
      "epoch:30 step:28377 [D loss: 0.642483, acc.: 63.28%] [G loss: 0.896605]\n",
      "epoch:30 step:28378 [D loss: 0.678069, acc.: 56.25%] [G loss: 0.906869]\n",
      "epoch:30 step:28379 [D loss: 0.632521, acc.: 63.28%] [G loss: 0.991045]\n",
      "epoch:30 step:28380 [D loss: 0.699001, acc.: 51.56%] [G loss: 0.921279]\n",
      "epoch:30 step:28381 [D loss: 0.662204, acc.: 60.94%] [G loss: 0.919379]\n",
      "epoch:30 step:28382 [D loss: 0.648172, acc.: 59.38%] [G loss: 1.021544]\n",
      "epoch:30 step:28383 [D loss: 0.690589, acc.: 52.34%] [G loss: 0.908215]\n",
      "epoch:30 step:28384 [D loss: 0.647681, acc.: 62.50%] [G loss: 0.934333]\n",
      "epoch:30 step:28385 [D loss: 0.666969, acc.: 60.94%] [G loss: 0.874846]\n",
      "epoch:30 step:28386 [D loss: 0.700551, acc.: 52.34%] [G loss: 0.921718]\n",
      "epoch:30 step:28387 [D loss: 0.664620, acc.: 56.25%] [G loss: 0.939883]\n",
      "epoch:30 step:28388 [D loss: 0.661528, acc.: 61.72%] [G loss: 0.869439]\n",
      "epoch:30 step:28389 [D loss: 0.662128, acc.: 61.72%] [G loss: 0.912789]\n",
      "epoch:30 step:28390 [D loss: 0.649679, acc.: 59.38%] [G loss: 0.834742]\n",
      "epoch:30 step:28391 [D loss: 0.637840, acc.: 60.16%] [G loss: 0.911673]\n",
      "epoch:30 step:28392 [D loss: 0.633977, acc.: 60.94%] [G loss: 0.902705]\n",
      "epoch:30 step:28393 [D loss: 0.640044, acc.: 60.16%] [G loss: 0.935122]\n",
      "epoch:30 step:28394 [D loss: 0.614765, acc.: 68.75%] [G loss: 1.017524]\n",
      "epoch:30 step:28395 [D loss: 0.612624, acc.: 66.41%] [G loss: 0.890697]\n",
      "epoch:30 step:28396 [D loss: 0.621961, acc.: 65.62%] [G loss: 0.900462]\n",
      "epoch:30 step:28397 [D loss: 0.634135, acc.: 59.38%] [G loss: 0.944401]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:28398 [D loss: 0.647881, acc.: 60.94%] [G loss: 0.924300]\n",
      "epoch:30 step:28399 [D loss: 0.673508, acc.: 55.47%] [G loss: 0.867638]\n",
      "epoch:30 step:28400 [D loss: 0.603908, acc.: 67.97%] [G loss: 0.939122]\n",
      "##############\n",
      "[2.90524092 2.52408172 2.24032712 4.10153316 1.24617085 6.36416731\n",
      " 2.6832561  3.69847829 4.26694674 7.14799875]\n",
      "##########\n",
      "epoch:30 step:28401 [D loss: 0.650432, acc.: 63.28%] [G loss: 0.928894]\n",
      "epoch:30 step:28402 [D loss: 0.649350, acc.: 63.28%] [G loss: 0.943686]\n",
      "epoch:30 step:28403 [D loss: 0.671057, acc.: 57.03%] [G loss: 0.935960]\n",
      "epoch:30 step:28404 [D loss: 0.648995, acc.: 57.81%] [G loss: 0.909479]\n",
      "epoch:30 step:28405 [D loss: 0.688834, acc.: 54.69%] [G loss: 0.951203]\n",
      "epoch:30 step:28406 [D loss: 0.631502, acc.: 64.06%] [G loss: 0.897668]\n",
      "epoch:30 step:28407 [D loss: 0.641778, acc.: 64.06%] [G loss: 0.910187]\n",
      "epoch:30 step:28408 [D loss: 0.674595, acc.: 57.03%] [G loss: 0.924709]\n",
      "epoch:30 step:28409 [D loss: 0.652940, acc.: 57.03%] [G loss: 0.904503]\n",
      "epoch:30 step:28410 [D loss: 0.629233, acc.: 60.94%] [G loss: 0.925737]\n",
      "epoch:30 step:28411 [D loss: 0.668237, acc.: 58.59%] [G loss: 0.967101]\n",
      "epoch:30 step:28412 [D loss: 0.642296, acc.: 67.97%] [G loss: 0.915406]\n",
      "epoch:30 step:28413 [D loss: 0.707060, acc.: 53.91%] [G loss: 0.910128]\n",
      "epoch:30 step:28414 [D loss: 0.623161, acc.: 63.28%] [G loss: 0.944364]\n",
      "epoch:30 step:28415 [D loss: 0.668158, acc.: 56.25%] [G loss: 0.920461]\n",
      "epoch:30 step:28416 [D loss: 0.676795, acc.: 63.28%] [G loss: 0.937442]\n",
      "epoch:30 step:28417 [D loss: 0.648836, acc.: 61.72%] [G loss: 0.913761]\n",
      "epoch:30 step:28418 [D loss: 0.603654, acc.: 66.41%] [G loss: 0.905351]\n",
      "epoch:30 step:28419 [D loss: 0.637314, acc.: 62.50%] [G loss: 0.864663]\n",
      "epoch:30 step:28420 [D loss: 0.642151, acc.: 61.72%] [G loss: 0.941163]\n",
      "epoch:30 step:28421 [D loss: 0.652432, acc.: 59.38%] [G loss: 0.944492]\n",
      "epoch:30 step:28422 [D loss: 0.644221, acc.: 63.28%] [G loss: 0.912360]\n",
      "epoch:30 step:28423 [D loss: 0.725956, acc.: 49.22%] [G loss: 0.900878]\n",
      "epoch:30 step:28424 [D loss: 0.634578, acc.: 59.38%] [G loss: 0.925439]\n",
      "epoch:30 step:28425 [D loss: 0.612364, acc.: 64.84%] [G loss: 0.929725]\n",
      "epoch:30 step:28426 [D loss: 0.662924, acc.: 59.38%] [G loss: 0.943344]\n",
      "epoch:30 step:28427 [D loss: 0.620611, acc.: 65.62%] [G loss: 0.957539]\n",
      "epoch:30 step:28428 [D loss: 0.651082, acc.: 57.81%] [G loss: 0.973734]\n",
      "epoch:30 step:28429 [D loss: 0.635629, acc.: 63.28%] [G loss: 0.932893]\n",
      "epoch:30 step:28430 [D loss: 0.660310, acc.: 59.38%] [G loss: 0.908554]\n",
      "epoch:30 step:28431 [D loss: 0.609355, acc.: 68.75%] [G loss: 0.879699]\n",
      "epoch:30 step:28432 [D loss: 0.676981, acc.: 60.94%] [G loss: 0.850788]\n",
      "epoch:30 step:28433 [D loss: 0.660257, acc.: 58.59%] [G loss: 0.891769]\n",
      "epoch:30 step:28434 [D loss: 0.641381, acc.: 61.72%] [G loss: 0.910188]\n",
      "epoch:30 step:28435 [D loss: 0.662396, acc.: 58.59%] [G loss: 0.858483]\n",
      "epoch:30 step:28436 [D loss: 0.703542, acc.: 53.12%] [G loss: 0.875881]\n",
      "epoch:30 step:28437 [D loss: 0.639143, acc.: 62.50%] [G loss: 0.880655]\n",
      "epoch:30 step:28438 [D loss: 0.649662, acc.: 62.50%] [G loss: 0.896105]\n",
      "epoch:30 step:28439 [D loss: 0.667853, acc.: 57.03%] [G loss: 0.844481]\n",
      "epoch:30 step:28440 [D loss: 0.634918, acc.: 61.72%] [G loss: 0.837857]\n",
      "epoch:30 step:28441 [D loss: 0.630966, acc.: 64.06%] [G loss: 0.975470]\n",
      "epoch:30 step:28442 [D loss: 0.638816, acc.: 67.19%] [G loss: 0.901204]\n",
      "epoch:30 step:28443 [D loss: 0.661303, acc.: 58.59%] [G loss: 0.938423]\n",
      "epoch:30 step:28444 [D loss: 0.655865, acc.: 55.47%] [G loss: 0.965522]\n",
      "epoch:30 step:28445 [D loss: 0.634615, acc.: 67.97%] [G loss: 0.948253]\n",
      "epoch:30 step:28446 [D loss: 0.644038, acc.: 62.50%] [G loss: 0.889477]\n",
      "epoch:30 step:28447 [D loss: 0.680949, acc.: 58.59%] [G loss: 0.894074]\n",
      "epoch:30 step:28448 [D loss: 0.638103, acc.: 61.72%] [G loss: 0.951927]\n",
      "epoch:30 step:28449 [D loss: 0.646710, acc.: 60.94%] [G loss: 0.909747]\n",
      "epoch:30 step:28450 [D loss: 0.667360, acc.: 60.16%] [G loss: 0.905764]\n",
      "epoch:30 step:28451 [D loss: 0.644048, acc.: 58.59%] [G loss: 0.940230]\n",
      "epoch:30 step:28452 [D loss: 0.653594, acc.: 63.28%] [G loss: 0.911579]\n",
      "epoch:30 step:28453 [D loss: 0.670298, acc.: 54.69%] [G loss: 0.944650]\n",
      "epoch:30 step:28454 [D loss: 0.686576, acc.: 54.69%] [G loss: 0.888309]\n",
      "epoch:30 step:28455 [D loss: 0.661909, acc.: 60.16%] [G loss: 0.961037]\n",
      "epoch:30 step:28456 [D loss: 0.658903, acc.: 60.16%] [G loss: 0.949920]\n",
      "epoch:30 step:28457 [D loss: 0.631031, acc.: 69.53%] [G loss: 0.948980]\n",
      "epoch:30 step:28458 [D loss: 0.642273, acc.: 64.84%] [G loss: 0.877462]\n",
      "epoch:30 step:28459 [D loss: 0.595015, acc.: 73.44%] [G loss: 0.948145]\n",
      "epoch:30 step:28460 [D loss: 0.651273, acc.: 57.81%] [G loss: 0.924304]\n",
      "epoch:30 step:28461 [D loss: 0.672708, acc.: 57.81%] [G loss: 0.911125]\n",
      "epoch:30 step:28462 [D loss: 0.686089, acc.: 58.59%] [G loss: 0.900125]\n",
      "epoch:30 step:28463 [D loss: 0.675584, acc.: 57.03%] [G loss: 0.888272]\n",
      "epoch:30 step:28464 [D loss: 0.675669, acc.: 53.91%] [G loss: 0.928707]\n",
      "epoch:30 step:28465 [D loss: 0.635238, acc.: 62.50%] [G loss: 0.895904]\n",
      "epoch:30 step:28466 [D loss: 0.630324, acc.: 65.62%] [G loss: 0.918028]\n",
      "epoch:30 step:28467 [D loss: 0.681467, acc.: 54.69%] [G loss: 0.863538]\n",
      "epoch:30 step:28468 [D loss: 0.659580, acc.: 56.25%] [G loss: 0.903206]\n",
      "epoch:30 step:28469 [D loss: 0.701191, acc.: 49.22%] [G loss: 0.829745]\n",
      "epoch:30 step:28470 [D loss: 0.602836, acc.: 70.31%] [G loss: 0.941589]\n",
      "epoch:30 step:28471 [D loss: 0.646699, acc.: 59.38%] [G loss: 0.956679]\n",
      "epoch:30 step:28472 [D loss: 0.639540, acc.: 63.28%] [G loss: 0.921876]\n",
      "epoch:30 step:28473 [D loss: 0.657856, acc.: 61.72%] [G loss: 0.940502]\n",
      "epoch:30 step:28474 [D loss: 0.623343, acc.: 66.41%] [G loss: 0.938204]\n",
      "epoch:30 step:28475 [D loss: 0.645727, acc.: 58.59%] [G loss: 0.934649]\n",
      "epoch:30 step:28476 [D loss: 0.666598, acc.: 55.47%] [G loss: 0.918419]\n",
      "epoch:30 step:28477 [D loss: 0.668558, acc.: 54.69%] [G loss: 0.937212]\n",
      "epoch:30 step:28478 [D loss: 0.684928, acc.: 53.12%] [G loss: 0.912066]\n",
      "epoch:30 step:28479 [D loss: 0.672016, acc.: 64.06%] [G loss: 0.948658]\n",
      "epoch:30 step:28480 [D loss: 0.633331, acc.: 64.84%] [G loss: 0.946272]\n",
      "epoch:30 step:28481 [D loss: 0.635057, acc.: 64.06%] [G loss: 0.934278]\n",
      "epoch:30 step:28482 [D loss: 0.689379, acc.: 53.91%] [G loss: 0.899018]\n",
      "epoch:30 step:28483 [D loss: 0.652483, acc.: 62.50%] [G loss: 0.936736]\n",
      "epoch:30 step:28484 [D loss: 0.690797, acc.: 56.25%] [G loss: 0.915573]\n",
      "epoch:30 step:28485 [D loss: 0.677570, acc.: 58.59%] [G loss: 0.887717]\n",
      "epoch:30 step:28486 [D loss: 0.671504, acc.: 54.69%] [G loss: 0.863855]\n",
      "epoch:30 step:28487 [D loss: 0.656745, acc.: 58.59%] [G loss: 0.862898]\n",
      "epoch:30 step:28488 [D loss: 0.614990, acc.: 66.41%] [G loss: 0.900564]\n",
      "epoch:30 step:28489 [D loss: 0.635814, acc.: 65.62%] [G loss: 0.887416]\n",
      "epoch:30 step:28490 [D loss: 0.636989, acc.: 66.41%] [G loss: 0.870473]\n",
      "epoch:30 step:28491 [D loss: 0.658071, acc.: 61.72%] [G loss: 0.874470]\n",
      "epoch:30 step:28492 [D loss: 0.628528, acc.: 63.28%] [G loss: 0.869826]\n",
      "epoch:30 step:28493 [D loss: 0.636229, acc.: 60.16%] [G loss: 0.842982]\n",
      "epoch:30 step:28494 [D loss: 0.691074, acc.: 60.94%] [G loss: 0.861691]\n",
      "epoch:30 step:28495 [D loss: 0.686017, acc.: 54.69%] [G loss: 0.864547]\n",
      "epoch:30 step:28496 [D loss: 0.609093, acc.: 65.62%] [G loss: 0.884564]\n",
      "epoch:30 step:28497 [D loss: 0.622951, acc.: 66.41%] [G loss: 0.865862]\n",
      "epoch:30 step:28498 [D loss: 0.677554, acc.: 56.25%] [G loss: 0.849026]\n",
      "epoch:30 step:28499 [D loss: 0.663364, acc.: 61.72%] [G loss: 0.914349]\n",
      "epoch:30 step:28500 [D loss: 0.634529, acc.: 62.50%] [G loss: 0.884257]\n",
      "epoch:30 step:28501 [D loss: 0.653551, acc.: 57.03%] [G loss: 0.897843]\n",
      "epoch:30 step:28502 [D loss: 0.640570, acc.: 62.50%] [G loss: 0.919596]\n",
      "epoch:30 step:28503 [D loss: 0.736192, acc.: 50.00%] [G loss: 0.953239]\n",
      "epoch:30 step:28504 [D loss: 0.683846, acc.: 56.25%] [G loss: 0.926169]\n",
      "epoch:30 step:28505 [D loss: 0.637249, acc.: 61.72%] [G loss: 0.841004]\n",
      "epoch:30 step:28506 [D loss: 0.656056, acc.: 60.16%] [G loss: 0.882562]\n",
      "epoch:30 step:28507 [D loss: 0.642822, acc.: 60.16%] [G loss: 0.933118]\n",
      "epoch:30 step:28508 [D loss: 0.668161, acc.: 58.59%] [G loss: 0.895079]\n",
      "epoch:30 step:28509 [D loss: 0.638138, acc.: 59.38%] [G loss: 0.915554]\n",
      "epoch:30 step:28510 [D loss: 0.604272, acc.: 68.75%] [G loss: 0.960327]\n",
      "epoch:30 step:28511 [D loss: 0.639248, acc.: 64.84%] [G loss: 0.922740]\n",
      "epoch:30 step:28512 [D loss: 0.645670, acc.: 61.72%] [G loss: 0.997478]\n",
      "epoch:30 step:28513 [D loss: 0.625784, acc.: 67.19%] [G loss: 0.958267]\n",
      "epoch:30 step:28514 [D loss: 0.623029, acc.: 62.50%] [G loss: 0.967690]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:28515 [D loss: 0.600552, acc.: 70.31%] [G loss: 0.941145]\n",
      "epoch:30 step:28516 [D loss: 0.663198, acc.: 60.16%] [G loss: 0.931896]\n",
      "epoch:30 step:28517 [D loss: 0.642439, acc.: 60.16%] [G loss: 0.953308]\n",
      "epoch:30 step:28518 [D loss: 0.621129, acc.: 69.53%] [G loss: 0.970075]\n",
      "epoch:30 step:28519 [D loss: 0.700813, acc.: 52.34%] [G loss: 0.925571]\n",
      "epoch:30 step:28520 [D loss: 0.702753, acc.: 57.03%] [G loss: 0.965683]\n",
      "epoch:30 step:28521 [D loss: 0.617510, acc.: 67.19%] [G loss: 0.906541]\n",
      "epoch:30 step:28522 [D loss: 0.640600, acc.: 67.97%] [G loss: 0.887141]\n",
      "epoch:30 step:28523 [D loss: 0.646109, acc.: 64.84%] [G loss: 0.912992]\n",
      "epoch:30 step:28524 [D loss: 0.646923, acc.: 63.28%] [G loss: 0.974478]\n",
      "epoch:30 step:28525 [D loss: 0.606000, acc.: 66.41%] [G loss: 1.047171]\n",
      "epoch:30 step:28526 [D loss: 0.617216, acc.: 71.09%] [G loss: 1.013888]\n",
      "epoch:30 step:28527 [D loss: 0.606184, acc.: 67.97%] [G loss: 0.968848]\n",
      "epoch:30 step:28528 [D loss: 0.656584, acc.: 63.28%] [G loss: 0.894091]\n",
      "epoch:30 step:28529 [D loss: 0.603721, acc.: 68.75%] [G loss: 0.887596]\n",
      "epoch:30 step:28530 [D loss: 0.625217, acc.: 64.84%] [G loss: 0.872012]\n",
      "epoch:30 step:28531 [D loss: 0.628171, acc.: 69.53%] [G loss: 0.887515]\n",
      "epoch:30 step:28532 [D loss: 0.661148, acc.: 61.72%] [G loss: 0.929606]\n",
      "epoch:30 step:28533 [D loss: 0.635744, acc.: 60.16%] [G loss: 0.838804]\n",
      "epoch:30 step:28534 [D loss: 0.665701, acc.: 60.94%] [G loss: 0.879632]\n",
      "epoch:30 step:28535 [D loss: 0.686036, acc.: 51.56%] [G loss: 0.945420]\n",
      "epoch:30 step:28536 [D loss: 0.667484, acc.: 57.03%] [G loss: 0.885580]\n",
      "epoch:30 step:28537 [D loss: 0.654220, acc.: 59.38%] [G loss: 0.955508]\n",
      "epoch:30 step:28538 [D loss: 0.711557, acc.: 54.69%] [G loss: 0.943581]\n",
      "epoch:30 step:28539 [D loss: 0.645498, acc.: 63.28%] [G loss: 0.894193]\n",
      "epoch:30 step:28540 [D loss: 0.658964, acc.: 57.03%] [G loss: 0.990624]\n",
      "epoch:30 step:28541 [D loss: 0.647966, acc.: 63.28%] [G loss: 0.960852]\n",
      "epoch:30 step:28542 [D loss: 0.653949, acc.: 62.50%] [G loss: 0.978132]\n",
      "epoch:30 step:28543 [D loss: 0.637393, acc.: 69.53%] [G loss: 0.915563]\n",
      "epoch:30 step:28544 [D loss: 0.666874, acc.: 62.50%] [G loss: 0.870013]\n",
      "epoch:30 step:28545 [D loss: 0.649811, acc.: 61.72%] [G loss: 0.923761]\n",
      "epoch:30 step:28546 [D loss: 0.639813, acc.: 67.97%] [G loss: 0.912713]\n",
      "epoch:30 step:28547 [D loss: 0.643726, acc.: 62.50%] [G loss: 0.948109]\n",
      "epoch:30 step:28548 [D loss: 0.699678, acc.: 50.78%] [G loss: 0.983489]\n",
      "epoch:30 step:28549 [D loss: 0.653041, acc.: 60.94%] [G loss: 0.944399]\n",
      "epoch:30 step:28550 [D loss: 0.638373, acc.: 57.81%] [G loss: 0.939228]\n",
      "epoch:30 step:28551 [D loss: 0.630748, acc.: 66.41%] [G loss: 0.877111]\n",
      "epoch:30 step:28552 [D loss: 0.656721, acc.: 57.03%] [G loss: 0.934192]\n",
      "epoch:30 step:28553 [D loss: 0.631213, acc.: 57.03%] [G loss: 0.907414]\n",
      "epoch:30 step:28554 [D loss: 0.637540, acc.: 62.50%] [G loss: 0.895046]\n",
      "epoch:30 step:28555 [D loss: 0.689982, acc.: 59.38%] [G loss: 0.907699]\n",
      "epoch:30 step:28556 [D loss: 0.679563, acc.: 57.03%] [G loss: 0.887529]\n",
      "epoch:30 step:28557 [D loss: 0.670834, acc.: 60.16%] [G loss: 0.888193]\n",
      "epoch:30 step:28558 [D loss: 0.676079, acc.: 52.34%] [G loss: 0.879611]\n",
      "epoch:30 step:28559 [D loss: 0.662416, acc.: 52.34%] [G loss: 0.908516]\n",
      "epoch:30 step:28560 [D loss: 0.660858, acc.: 60.16%] [G loss: 0.914036]\n",
      "epoch:30 step:28561 [D loss: 0.620219, acc.: 64.84%] [G loss: 0.905032]\n",
      "epoch:30 step:28562 [D loss: 0.645428, acc.: 60.94%] [G loss: 0.886711]\n",
      "epoch:30 step:28563 [D loss: 0.657696, acc.: 60.16%] [G loss: 0.915977]\n",
      "epoch:30 step:28564 [D loss: 0.662358, acc.: 61.72%] [G loss: 0.829570]\n",
      "epoch:30 step:28565 [D loss: 0.653333, acc.: 65.62%] [G loss: 0.892596]\n",
      "epoch:30 step:28566 [D loss: 0.632469, acc.: 69.53%] [G loss: 0.888618]\n",
      "epoch:30 step:28567 [D loss: 0.670373, acc.: 57.81%] [G loss: 0.838194]\n",
      "epoch:30 step:28568 [D loss: 0.625378, acc.: 64.84%] [G loss: 0.864628]\n",
      "epoch:30 step:28569 [D loss: 0.614735, acc.: 62.50%] [G loss: 0.929105]\n",
      "epoch:30 step:28570 [D loss: 0.630447, acc.: 60.94%] [G loss: 0.924585]\n",
      "epoch:30 step:28571 [D loss: 0.670082, acc.: 57.03%] [G loss: 0.959043]\n",
      "epoch:30 step:28572 [D loss: 0.682556, acc.: 53.91%] [G loss: 0.930601]\n",
      "epoch:30 step:28573 [D loss: 0.624511, acc.: 70.31%] [G loss: 1.021433]\n",
      "epoch:30 step:28574 [D loss: 0.688671, acc.: 59.38%] [G loss: 0.887689]\n",
      "epoch:30 step:28575 [D loss: 0.670259, acc.: 57.03%] [G loss: 0.899014]\n",
      "epoch:30 step:28576 [D loss: 0.671652, acc.: 60.94%] [G loss: 0.887002]\n",
      "epoch:30 step:28577 [D loss: 0.644830, acc.: 62.50%] [G loss: 0.925186]\n",
      "epoch:30 step:28578 [D loss: 0.624662, acc.: 64.84%] [G loss: 0.934981]\n",
      "epoch:30 step:28579 [D loss: 0.610553, acc.: 67.97%] [G loss: 0.965353]\n",
      "epoch:30 step:28580 [D loss: 0.713674, acc.: 48.44%] [G loss: 0.913897]\n",
      "epoch:30 step:28581 [D loss: 0.619667, acc.: 67.97%] [G loss: 0.968592]\n",
      "epoch:30 step:28582 [D loss: 0.604262, acc.: 72.66%] [G loss: 0.936888]\n",
      "epoch:30 step:28583 [D loss: 0.678101, acc.: 58.59%] [G loss: 0.870313]\n",
      "epoch:30 step:28584 [D loss: 0.621249, acc.: 64.84%] [G loss: 0.907701]\n",
      "epoch:30 step:28585 [D loss: 0.635367, acc.: 66.41%] [G loss: 0.893435]\n",
      "epoch:30 step:28586 [D loss: 0.631675, acc.: 67.19%] [G loss: 0.862709]\n",
      "epoch:30 step:28587 [D loss: 0.657715, acc.: 63.28%] [G loss: 0.971224]\n",
      "epoch:30 step:28588 [D loss: 0.626623, acc.: 69.53%] [G loss: 0.928809]\n",
      "epoch:30 step:28589 [D loss: 0.650654, acc.: 64.06%] [G loss: 0.847547]\n",
      "epoch:30 step:28590 [D loss: 0.654909, acc.: 61.72%] [G loss: 0.873716]\n",
      "epoch:30 step:28591 [D loss: 0.692953, acc.: 50.78%] [G loss: 0.872602]\n",
      "epoch:30 step:28592 [D loss: 0.668720, acc.: 59.38%] [G loss: 0.931560]\n",
      "epoch:30 step:28593 [D loss: 0.680436, acc.: 55.47%] [G loss: 0.879081]\n",
      "epoch:30 step:28594 [D loss: 0.609357, acc.: 68.75%] [G loss: 0.923164]\n",
      "epoch:30 step:28595 [D loss: 0.637924, acc.: 60.16%] [G loss: 0.905127]\n",
      "epoch:30 step:28596 [D loss: 0.653736, acc.: 58.59%] [G loss: 0.856874]\n",
      "epoch:30 step:28597 [D loss: 0.652607, acc.: 60.16%] [G loss: 0.821762]\n",
      "epoch:30 step:28598 [D loss: 0.601714, acc.: 67.97%] [G loss: 0.919073]\n",
      "epoch:30 step:28599 [D loss: 0.653206, acc.: 57.81%] [G loss: 0.888738]\n",
      "epoch:30 step:28600 [D loss: 0.644172, acc.: 63.28%] [G loss: 0.913029]\n",
      "##############\n",
      "[3.0819257  2.53480771 2.40716846 3.97166582 1.03226975 6.42996096\n",
      " 2.87027485 3.19834229 4.14358007 6.2032918 ]\n",
      "##########\n",
      "epoch:30 step:28601 [D loss: 0.644564, acc.: 58.59%] [G loss: 0.983579]\n",
      "epoch:30 step:28602 [D loss: 0.648013, acc.: 62.50%] [G loss: 0.862238]\n",
      "epoch:30 step:28603 [D loss: 0.722567, acc.: 50.78%] [G loss: 0.901708]\n",
      "epoch:30 step:28604 [D loss: 0.641857, acc.: 57.03%] [G loss: 0.927433]\n",
      "epoch:30 step:28605 [D loss: 0.644180, acc.: 64.06%] [G loss: 0.946857]\n",
      "epoch:30 step:28606 [D loss: 0.631281, acc.: 65.62%] [G loss: 0.918744]\n",
      "epoch:30 step:28607 [D loss: 0.666319, acc.: 60.16%] [G loss: 0.953081]\n",
      "epoch:30 step:28608 [D loss: 0.672932, acc.: 60.94%] [G loss: 0.951563]\n",
      "epoch:30 step:28609 [D loss: 0.643013, acc.: 61.72%] [G loss: 0.993142]\n",
      "epoch:30 step:28610 [D loss: 0.690025, acc.: 57.03%] [G loss: 0.892804]\n",
      "epoch:30 step:28611 [D loss: 0.643976, acc.: 60.94%] [G loss: 0.900783]\n",
      "epoch:30 step:28612 [D loss: 0.665790, acc.: 59.38%] [G loss: 0.927082]\n",
      "epoch:30 step:28613 [D loss: 0.629669, acc.: 67.97%] [G loss: 0.898523]\n",
      "epoch:30 step:28614 [D loss: 0.628293, acc.: 64.84%] [G loss: 0.935791]\n",
      "epoch:30 step:28615 [D loss: 0.645078, acc.: 63.28%] [G loss: 0.962347]\n",
      "epoch:30 step:28616 [D loss: 0.630509, acc.: 67.19%] [G loss: 0.891566]\n",
      "epoch:30 step:28617 [D loss: 0.669248, acc.: 60.94%] [G loss: 0.903206]\n",
      "epoch:30 step:28618 [D loss: 0.634640, acc.: 59.38%] [G loss: 0.931451]\n",
      "epoch:30 step:28619 [D loss: 0.638023, acc.: 57.81%] [G loss: 0.901182]\n",
      "epoch:30 step:28620 [D loss: 0.626099, acc.: 61.72%] [G loss: 0.941213]\n",
      "epoch:30 step:28621 [D loss: 0.629203, acc.: 66.41%] [G loss: 0.945766]\n",
      "epoch:30 step:28622 [D loss: 0.670309, acc.: 55.47%] [G loss: 0.921110]\n",
      "epoch:30 step:28623 [D loss: 0.648868, acc.: 61.72%] [G loss: 0.913199]\n",
      "epoch:30 step:28624 [D loss: 0.652757, acc.: 64.84%] [G loss: 0.916249]\n",
      "epoch:30 step:28625 [D loss: 0.658373, acc.: 64.06%] [G loss: 0.884847]\n",
      "epoch:30 step:28626 [D loss: 0.633798, acc.: 64.84%] [G loss: 0.930770]\n",
      "epoch:30 step:28627 [D loss: 0.670576, acc.: 59.38%] [G loss: 0.862196]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:28628 [D loss: 0.677828, acc.: 58.59%] [G loss: 0.994780]\n",
      "epoch:30 step:28629 [D loss: 0.664038, acc.: 64.84%] [G loss: 0.964061]\n",
      "epoch:30 step:28630 [D loss: 0.668295, acc.: 55.47%] [G loss: 0.962738]\n",
      "epoch:30 step:28631 [D loss: 0.664136, acc.: 57.03%] [G loss: 0.932725]\n",
      "epoch:30 step:28632 [D loss: 0.646068, acc.: 60.16%] [G loss: 0.935854]\n",
      "epoch:30 step:28633 [D loss: 0.620756, acc.: 66.41%] [G loss: 0.939242]\n",
      "epoch:30 step:28634 [D loss: 0.652472, acc.: 64.84%] [G loss: 0.954312]\n",
      "epoch:30 step:28635 [D loss: 0.640333, acc.: 61.72%] [G loss: 0.941470]\n",
      "epoch:30 step:28636 [D loss: 0.690308, acc.: 52.34%] [G loss: 0.887737]\n",
      "epoch:30 step:28637 [D loss: 0.683621, acc.: 57.81%] [G loss: 0.917804]\n",
      "epoch:30 step:28638 [D loss: 0.644209, acc.: 63.28%] [G loss: 0.891329]\n",
      "epoch:30 step:28639 [D loss: 0.614435, acc.: 66.41%] [G loss: 0.939944]\n",
      "epoch:30 step:28640 [D loss: 0.654164, acc.: 60.16%] [G loss: 0.883145]\n",
      "epoch:30 step:28641 [D loss: 0.672591, acc.: 58.59%] [G loss: 0.867640]\n",
      "epoch:30 step:28642 [D loss: 0.658902, acc.: 63.28%] [G loss: 0.932078]\n",
      "epoch:30 step:28643 [D loss: 0.642046, acc.: 67.19%] [G loss: 0.926956]\n",
      "epoch:30 step:28644 [D loss: 0.605270, acc.: 66.41%] [G loss: 0.907612]\n",
      "epoch:30 step:28645 [D loss: 0.637746, acc.: 60.94%] [G loss: 0.833915]\n",
      "epoch:30 step:28646 [D loss: 0.700094, acc.: 53.91%] [G loss: 0.908940]\n",
      "epoch:30 step:28647 [D loss: 0.669963, acc.: 60.94%] [G loss: 0.879175]\n",
      "epoch:30 step:28648 [D loss: 0.685274, acc.: 57.03%] [G loss: 0.901325]\n",
      "epoch:30 step:28649 [D loss: 0.688104, acc.: 57.03%] [G loss: 0.897123]\n",
      "epoch:30 step:28650 [D loss: 0.645298, acc.: 60.94%] [G loss: 0.845668]\n",
      "epoch:30 step:28651 [D loss: 0.662168, acc.: 57.03%] [G loss: 0.840132]\n",
      "epoch:30 step:28652 [D loss: 0.690431, acc.: 54.69%] [G loss: 0.862882]\n",
      "epoch:30 step:28653 [D loss: 0.640129, acc.: 57.81%] [G loss: 0.909654]\n",
      "epoch:30 step:28654 [D loss: 0.669509, acc.: 63.28%] [G loss: 0.958915]\n",
      "epoch:30 step:28655 [D loss: 0.630554, acc.: 60.16%] [G loss: 0.913405]\n",
      "epoch:30 step:28656 [D loss: 0.640849, acc.: 65.62%] [G loss: 0.933152]\n",
      "epoch:30 step:28657 [D loss: 0.651315, acc.: 60.16%] [G loss: 0.969621]\n",
      "epoch:30 step:28658 [D loss: 0.645338, acc.: 62.50%] [G loss: 0.883012]\n",
      "epoch:30 step:28659 [D loss: 0.668670, acc.: 59.38%] [G loss: 0.828915]\n",
      "epoch:30 step:28660 [D loss: 0.669537, acc.: 52.34%] [G loss: 0.872142]\n",
      "epoch:30 step:28661 [D loss: 0.685710, acc.: 53.91%] [G loss: 0.895332]\n",
      "epoch:30 step:28662 [D loss: 0.631484, acc.: 62.50%] [G loss: 0.929180]\n",
      "epoch:30 step:28663 [D loss: 0.651180, acc.: 58.59%] [G loss: 0.917597]\n",
      "epoch:30 step:28664 [D loss: 0.661331, acc.: 62.50%] [G loss: 0.915012]\n",
      "epoch:30 step:28665 [D loss: 0.628698, acc.: 68.75%] [G loss: 0.868087]\n",
      "epoch:30 step:28666 [D loss: 0.674190, acc.: 64.06%] [G loss: 0.888721]\n",
      "epoch:30 step:28667 [D loss: 0.638151, acc.: 65.62%] [G loss: 0.971001]\n",
      "epoch:30 step:28668 [D loss: 0.640496, acc.: 61.72%] [G loss: 0.941445]\n",
      "epoch:30 step:28669 [D loss: 0.653388, acc.: 62.50%] [G loss: 0.946703]\n",
      "epoch:30 step:28670 [D loss: 0.640267, acc.: 61.72%] [G loss: 0.941208]\n",
      "epoch:30 step:28671 [D loss: 0.645118, acc.: 63.28%] [G loss: 0.925160]\n",
      "epoch:30 step:28672 [D loss: 0.624400, acc.: 64.06%] [G loss: 0.955342]\n",
      "epoch:30 step:28673 [D loss: 0.625512, acc.: 64.84%] [G loss: 0.938227]\n",
      "epoch:30 step:28674 [D loss: 0.593815, acc.: 72.66%] [G loss: 0.914796]\n",
      "epoch:30 step:28675 [D loss: 0.651583, acc.: 57.03%] [G loss: 0.950412]\n",
      "epoch:30 step:28676 [D loss: 0.605319, acc.: 68.75%] [G loss: 0.866908]\n",
      "epoch:30 step:28677 [D loss: 0.632460, acc.: 61.72%] [G loss: 0.932664]\n",
      "epoch:30 step:28678 [D loss: 0.703102, acc.: 55.47%] [G loss: 0.940117]\n",
      "epoch:30 step:28679 [D loss: 0.628374, acc.: 62.50%] [G loss: 0.958679]\n",
      "epoch:30 step:28680 [D loss: 0.649412, acc.: 62.50%] [G loss: 0.996983]\n",
      "epoch:30 step:28681 [D loss: 0.621253, acc.: 64.06%] [G loss: 0.912791]\n",
      "epoch:30 step:28682 [D loss: 0.631919, acc.: 62.50%] [G loss: 0.934107]\n",
      "epoch:30 step:28683 [D loss: 0.632082, acc.: 63.28%] [G loss: 0.931028]\n",
      "epoch:30 step:28684 [D loss: 0.662799, acc.: 53.91%] [G loss: 0.881964]\n",
      "epoch:30 step:28685 [D loss: 0.641858, acc.: 56.25%] [G loss: 0.917310]\n",
      "epoch:30 step:28686 [D loss: 0.616856, acc.: 68.75%] [G loss: 0.885364]\n",
      "epoch:30 step:28687 [D loss: 0.640014, acc.: 66.41%] [G loss: 0.848331]\n",
      "epoch:30 step:28688 [D loss: 0.664417, acc.: 63.28%] [G loss: 0.834558]\n",
      "epoch:30 step:28689 [D loss: 0.660495, acc.: 57.81%] [G loss: 0.861629]\n",
      "epoch:30 step:28690 [D loss: 0.656442, acc.: 58.59%] [G loss: 0.917522]\n",
      "epoch:30 step:28691 [D loss: 0.631779, acc.: 64.84%] [G loss: 0.862685]\n",
      "epoch:30 step:28692 [D loss: 0.629206, acc.: 63.28%] [G loss: 0.930198]\n",
      "epoch:30 step:28693 [D loss: 0.689511, acc.: 55.47%] [G loss: 0.931192]\n",
      "epoch:30 step:28694 [D loss: 0.639781, acc.: 65.62%] [G loss: 0.944831]\n",
      "epoch:30 step:28695 [D loss: 0.632877, acc.: 62.50%] [G loss: 0.948129]\n",
      "epoch:30 step:28696 [D loss: 0.630214, acc.: 64.84%] [G loss: 0.869619]\n",
      "epoch:30 step:28697 [D loss: 0.621020, acc.: 65.62%] [G loss: 0.952223]\n",
      "epoch:30 step:28698 [D loss: 0.646826, acc.: 57.03%] [G loss: 0.847540]\n",
      "epoch:30 step:28699 [D loss: 0.657055, acc.: 63.28%] [G loss: 0.880922]\n",
      "epoch:30 step:28700 [D loss: 0.654930, acc.: 63.28%] [G loss: 0.885371]\n",
      "epoch:30 step:28701 [D loss: 0.662020, acc.: 60.16%] [G loss: 0.985402]\n",
      "epoch:30 step:28702 [D loss: 0.648227, acc.: 62.50%] [G loss: 0.969880]\n",
      "epoch:30 step:28703 [D loss: 0.673044, acc.: 59.38%] [G loss: 0.941562]\n",
      "epoch:30 step:28704 [D loss: 0.594619, acc.: 68.75%] [G loss: 0.960768]\n",
      "epoch:30 step:28705 [D loss: 0.654940, acc.: 61.72%] [G loss: 0.970099]\n",
      "epoch:30 step:28706 [D loss: 0.617019, acc.: 71.88%] [G loss: 0.938918]\n",
      "epoch:30 step:28707 [D loss: 0.643871, acc.: 60.94%] [G loss: 0.998172]\n",
      "epoch:30 step:28708 [D loss: 0.661618, acc.: 60.16%] [G loss: 0.962862]\n",
      "epoch:30 step:28709 [D loss: 0.671329, acc.: 61.72%] [G loss: 0.994110]\n",
      "epoch:30 step:28710 [D loss: 0.612434, acc.: 64.06%] [G loss: 1.036420]\n",
      "epoch:30 step:28711 [D loss: 0.691497, acc.: 56.25%] [G loss: 0.931162]\n",
      "epoch:30 step:28712 [D loss: 0.643240, acc.: 64.84%] [G loss: 0.926203]\n",
      "epoch:30 step:28713 [D loss: 0.668348, acc.: 54.69%] [G loss: 0.970034]\n",
      "epoch:30 step:28714 [D loss: 0.645190, acc.: 61.72%] [G loss: 0.851736]\n",
      "epoch:30 step:28715 [D loss: 0.666233, acc.: 57.81%] [G loss: 0.919630]\n",
      "epoch:30 step:28716 [D loss: 0.635769, acc.: 60.16%] [G loss: 0.914732]\n",
      "epoch:30 step:28717 [D loss: 0.653619, acc.: 61.72%] [G loss: 0.924153]\n",
      "epoch:30 step:28718 [D loss: 0.630355, acc.: 62.50%] [G loss: 0.905934]\n",
      "epoch:30 step:28719 [D loss: 0.587122, acc.: 71.88%] [G loss: 0.893139]\n",
      "epoch:30 step:28720 [D loss: 0.644037, acc.: 62.50%] [G loss: 0.844815]\n",
      "epoch:30 step:28721 [D loss: 0.651518, acc.: 60.16%] [G loss: 0.856479]\n",
      "epoch:30 step:28722 [D loss: 0.663556, acc.: 57.03%] [G loss: 0.822855]\n",
      "epoch:30 step:28723 [D loss: 0.647065, acc.: 60.16%] [G loss: 0.916572]\n",
      "epoch:30 step:28724 [D loss: 0.645181, acc.: 60.16%] [G loss: 0.910106]\n",
      "epoch:30 step:28725 [D loss: 0.684108, acc.: 60.94%] [G loss: 0.936276]\n",
      "epoch:30 step:28726 [D loss: 0.651238, acc.: 65.62%] [G loss: 0.936939]\n",
      "epoch:30 step:28727 [D loss: 0.671408, acc.: 61.72%] [G loss: 0.972855]\n",
      "epoch:30 step:28728 [D loss: 0.647130, acc.: 60.16%] [G loss: 0.897755]\n",
      "epoch:30 step:28729 [D loss: 0.680084, acc.: 56.25%] [G loss: 0.875777]\n",
      "epoch:30 step:28730 [D loss: 0.650147, acc.: 63.28%] [G loss: 0.868153]\n",
      "epoch:30 step:28731 [D loss: 0.646955, acc.: 60.94%] [G loss: 0.851222]\n",
      "epoch:30 step:28732 [D loss: 0.645420, acc.: 59.38%] [G loss: 0.826439]\n",
      "epoch:30 step:28733 [D loss: 0.653681, acc.: 61.72%] [G loss: 0.852362]\n",
      "epoch:30 step:28734 [D loss: 0.660070, acc.: 61.72%] [G loss: 0.870870]\n",
      "epoch:30 step:28735 [D loss: 0.634260, acc.: 64.06%] [G loss: 0.966230]\n",
      "epoch:30 step:28736 [D loss: 0.654412, acc.: 62.50%] [G loss: 0.944438]\n",
      "epoch:30 step:28737 [D loss: 0.631538, acc.: 64.06%] [G loss: 0.941504]\n",
      "epoch:30 step:28738 [D loss: 0.648893, acc.: 64.06%] [G loss: 0.965147]\n",
      "epoch:30 step:28739 [D loss: 0.666349, acc.: 61.72%] [G loss: 0.847301]\n",
      "epoch:30 step:28740 [D loss: 0.652316, acc.: 63.28%] [G loss: 0.906247]\n",
      "epoch:30 step:28741 [D loss: 0.622346, acc.: 66.41%] [G loss: 0.836193]\n",
      "epoch:30 step:28742 [D loss: 0.647213, acc.: 65.62%] [G loss: 0.839251]\n",
      "epoch:30 step:28743 [D loss: 0.635813, acc.: 64.06%] [G loss: 0.897575]\n",
      "epoch:30 step:28744 [D loss: 0.637416, acc.: 66.41%] [G loss: 0.809090]\n",
      "epoch:30 step:28745 [D loss: 0.683826, acc.: 53.91%] [G loss: 0.894443]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:28746 [D loss: 0.651334, acc.: 64.06%] [G loss: 0.882047]\n",
      "epoch:30 step:28747 [D loss: 0.655403, acc.: 60.94%] [G loss: 0.893953]\n",
      "epoch:30 step:28748 [D loss: 0.647102, acc.: 57.81%] [G loss: 0.899519]\n",
      "epoch:30 step:28749 [D loss: 0.681575, acc.: 58.59%] [G loss: 0.908518]\n",
      "epoch:30 step:28750 [D loss: 0.647911, acc.: 58.59%] [G loss: 0.931684]\n",
      "epoch:30 step:28751 [D loss: 0.693929, acc.: 53.91%] [G loss: 0.891919]\n",
      "epoch:30 step:28752 [D loss: 0.653003, acc.: 57.81%] [G loss: 0.883300]\n",
      "epoch:30 step:28753 [D loss: 0.705058, acc.: 53.91%] [G loss: 0.928947]\n",
      "epoch:30 step:28754 [D loss: 0.655468, acc.: 63.28%] [G loss: 0.917968]\n",
      "epoch:30 step:28755 [D loss: 0.645822, acc.: 62.50%] [G loss: 0.897072]\n",
      "epoch:30 step:28756 [D loss: 0.667419, acc.: 57.81%] [G loss: 0.955558]\n",
      "epoch:30 step:28757 [D loss: 0.698100, acc.: 57.03%] [G loss: 0.908318]\n",
      "epoch:30 step:28758 [D loss: 0.625259, acc.: 63.28%] [G loss: 0.941709]\n",
      "epoch:30 step:28759 [D loss: 0.668487, acc.: 56.25%] [G loss: 0.886268]\n",
      "epoch:30 step:28760 [D loss: 0.675009, acc.: 56.25%] [G loss: 0.848979]\n",
      "epoch:30 step:28761 [D loss: 0.661975, acc.: 57.81%] [G loss: 0.853858]\n",
      "epoch:30 step:28762 [D loss: 0.666930, acc.: 58.59%] [G loss: 0.913265]\n",
      "epoch:30 step:28763 [D loss: 0.634552, acc.: 56.25%] [G loss: 0.887298]\n",
      "epoch:30 step:28764 [D loss: 0.636407, acc.: 64.06%] [G loss: 0.873631]\n",
      "epoch:30 step:28765 [D loss: 0.707797, acc.: 51.56%] [G loss: 0.838343]\n",
      "epoch:30 step:28766 [D loss: 0.640711, acc.: 58.59%] [G loss: 0.902809]\n",
      "epoch:30 step:28767 [D loss: 0.668263, acc.: 57.03%] [G loss: 0.946769]\n",
      "epoch:30 step:28768 [D loss: 0.697096, acc.: 55.47%] [G loss: 0.896597]\n",
      "epoch:30 step:28769 [D loss: 0.712904, acc.: 49.22%] [G loss: 0.886641]\n",
      "epoch:30 step:28770 [D loss: 0.673282, acc.: 59.38%] [G loss: 0.882659]\n",
      "epoch:30 step:28771 [D loss: 0.668028, acc.: 58.59%] [G loss: 0.935649]\n",
      "epoch:30 step:28772 [D loss: 0.695389, acc.: 52.34%] [G loss: 0.880592]\n",
      "epoch:30 step:28773 [D loss: 0.668560, acc.: 62.50%] [G loss: 0.888910]\n",
      "epoch:30 step:28774 [D loss: 0.622182, acc.: 69.53%] [G loss: 0.879987]\n",
      "epoch:30 step:28775 [D loss: 0.689676, acc.: 55.47%] [G loss: 0.868382]\n",
      "epoch:30 step:28776 [D loss: 0.634823, acc.: 65.62%] [G loss: 0.905915]\n",
      "epoch:30 step:28777 [D loss: 0.607517, acc.: 68.75%] [G loss: 0.933781]\n",
      "epoch:30 step:28778 [D loss: 0.671916, acc.: 60.16%] [G loss: 0.861739]\n",
      "epoch:30 step:28779 [D loss: 0.659604, acc.: 57.81%] [G loss: 0.936261]\n",
      "epoch:30 step:28780 [D loss: 0.633947, acc.: 60.94%] [G loss: 0.926343]\n",
      "epoch:30 step:28781 [D loss: 0.631795, acc.: 65.62%] [G loss: 0.955604]\n",
      "epoch:30 step:28782 [D loss: 0.688821, acc.: 57.81%] [G loss: 0.927831]\n",
      "epoch:30 step:28783 [D loss: 0.687986, acc.: 59.38%] [G loss: 0.926273]\n",
      "epoch:30 step:28784 [D loss: 0.672327, acc.: 56.25%] [G loss: 0.984505]\n",
      "epoch:30 step:28785 [D loss: 0.626013, acc.: 62.50%] [G loss: 0.985474]\n",
      "epoch:30 step:28786 [D loss: 0.693651, acc.: 53.91%] [G loss: 0.952613]\n",
      "epoch:30 step:28787 [D loss: 0.688746, acc.: 59.38%] [G loss: 0.951880]\n",
      "epoch:30 step:28788 [D loss: 0.669433, acc.: 58.59%] [G loss: 0.912828]\n",
      "epoch:30 step:28789 [D loss: 0.681058, acc.: 51.56%] [G loss: 0.939498]\n",
      "epoch:30 step:28790 [D loss: 0.671512, acc.: 53.91%] [G loss: 0.917363]\n",
      "epoch:30 step:28791 [D loss: 0.644886, acc.: 64.06%] [G loss: 0.915863]\n",
      "epoch:30 step:28792 [D loss: 0.677473, acc.: 59.38%] [G loss: 0.962899]\n",
      "epoch:30 step:28793 [D loss: 0.641273, acc.: 66.41%] [G loss: 0.928867]\n",
      "epoch:30 step:28794 [D loss: 0.589533, acc.: 73.44%] [G loss: 0.857778]\n",
      "epoch:30 step:28795 [D loss: 0.642920, acc.: 60.94%] [G loss: 0.905574]\n",
      "epoch:30 step:28796 [D loss: 0.675500, acc.: 53.91%] [G loss: 0.911720]\n",
      "epoch:30 step:28797 [D loss: 0.627293, acc.: 64.06%] [G loss: 0.970790]\n",
      "epoch:30 step:28798 [D loss: 0.674660, acc.: 61.72%] [G loss: 0.961222]\n",
      "epoch:30 step:28799 [D loss: 0.647834, acc.: 61.72%] [G loss: 0.902803]\n",
      "epoch:30 step:28800 [D loss: 0.676925, acc.: 59.38%] [G loss: 0.922125]\n",
      "##############\n",
      "[3.18026369 2.48212217 2.39169545 4.1350415  1.25488078 6.90632523\n",
      " 2.49687445 2.7779594  4.28693438 5.29073574]\n",
      "##########\n",
      "epoch:30 step:28801 [D loss: 0.667976, acc.: 54.69%] [G loss: 0.948763]\n",
      "epoch:30 step:28802 [D loss: 0.646671, acc.: 60.16%] [G loss: 0.962347]\n",
      "epoch:30 step:28803 [D loss: 0.666042, acc.: 61.72%] [G loss: 0.961409]\n",
      "epoch:30 step:28804 [D loss: 0.664780, acc.: 60.94%] [G loss: 0.875579]\n",
      "epoch:30 step:28805 [D loss: 0.624786, acc.: 67.97%] [G loss: 0.870054]\n",
      "epoch:30 step:28806 [D loss: 0.599641, acc.: 67.19%] [G loss: 0.859970]\n",
      "epoch:30 step:28807 [D loss: 0.629866, acc.: 66.41%] [G loss: 0.941335]\n",
      "epoch:30 step:28808 [D loss: 0.623297, acc.: 67.97%] [G loss: 0.887093]\n",
      "epoch:30 step:28809 [D loss: 0.689246, acc.: 55.47%] [G loss: 0.896659]\n",
      "epoch:30 step:28810 [D loss: 0.626682, acc.: 67.19%] [G loss: 0.859290]\n",
      "epoch:30 step:28811 [D loss: 0.656613, acc.: 60.16%] [G loss: 0.888889]\n",
      "epoch:30 step:28812 [D loss: 0.667355, acc.: 60.16%] [G loss: 0.926767]\n",
      "epoch:30 step:28813 [D loss: 0.662484, acc.: 60.94%] [G loss: 0.905308]\n",
      "epoch:30 step:28814 [D loss: 0.624567, acc.: 64.84%] [G loss: 0.903263]\n",
      "epoch:30 step:28815 [D loss: 0.632458, acc.: 67.97%] [G loss: 0.883629]\n",
      "epoch:30 step:28816 [D loss: 0.680373, acc.: 57.03%] [G loss: 0.878987]\n",
      "epoch:30 step:28817 [D loss: 0.658725, acc.: 55.47%] [G loss: 0.929034]\n",
      "epoch:30 step:28818 [D loss: 0.643356, acc.: 60.16%] [G loss: 0.893730]\n",
      "epoch:30 step:28819 [D loss: 0.692705, acc.: 47.66%] [G loss: 0.887654]\n",
      "epoch:30 step:28820 [D loss: 0.602084, acc.: 74.22%] [G loss: 0.944032]\n",
      "epoch:30 step:28821 [D loss: 0.672656, acc.: 59.38%] [G loss: 0.974815]\n",
      "epoch:30 step:28822 [D loss: 0.685225, acc.: 59.38%] [G loss: 0.890160]\n",
      "epoch:30 step:28823 [D loss: 0.647494, acc.: 60.94%] [G loss: 0.933476]\n",
      "epoch:30 step:28824 [D loss: 0.636217, acc.: 63.28%] [G loss: 0.965032]\n",
      "epoch:30 step:28825 [D loss: 0.664668, acc.: 60.16%] [G loss: 0.888905]\n",
      "epoch:30 step:28826 [D loss: 0.626498, acc.: 64.06%] [G loss: 0.946861]\n",
      "epoch:30 step:28827 [D loss: 0.634068, acc.: 64.06%] [G loss: 0.921000]\n",
      "epoch:30 step:28828 [D loss: 0.610318, acc.: 67.19%] [G loss: 0.985140]\n",
      "epoch:30 step:28829 [D loss: 0.653409, acc.: 62.50%] [G loss: 0.918769]\n",
      "epoch:30 step:28830 [D loss: 0.666485, acc.: 63.28%] [G loss: 0.879414]\n",
      "epoch:30 step:28831 [D loss: 0.673847, acc.: 61.72%] [G loss: 0.915936]\n",
      "epoch:30 step:28832 [D loss: 0.610604, acc.: 66.41%] [G loss: 0.926608]\n",
      "epoch:30 step:28833 [D loss: 0.683016, acc.: 51.56%] [G loss: 0.906832]\n",
      "epoch:30 step:28834 [D loss: 0.650972, acc.: 61.72%] [G loss: 0.968885]\n",
      "epoch:30 step:28835 [D loss: 0.627756, acc.: 63.28%] [G loss: 0.988089]\n",
      "epoch:30 step:28836 [D loss: 0.661274, acc.: 60.16%] [G loss: 0.947392]\n",
      "epoch:30 step:28837 [D loss: 0.653384, acc.: 57.81%] [G loss: 0.872042]\n",
      "epoch:30 step:28838 [D loss: 0.655056, acc.: 62.50%] [G loss: 0.896238]\n",
      "epoch:30 step:28839 [D loss: 0.630961, acc.: 60.16%] [G loss: 0.860091]\n",
      "epoch:30 step:28840 [D loss: 0.643823, acc.: 58.59%] [G loss: 0.931463]\n",
      "epoch:30 step:28841 [D loss: 0.645170, acc.: 63.28%] [G loss: 0.904827]\n",
      "epoch:30 step:28842 [D loss: 0.658249, acc.: 63.28%] [G loss: 0.853937]\n",
      "epoch:30 step:28843 [D loss: 0.641927, acc.: 63.28%] [G loss: 0.917152]\n",
      "epoch:30 step:28844 [D loss: 0.671724, acc.: 54.69%] [G loss: 0.911280]\n",
      "epoch:30 step:28845 [D loss: 0.672281, acc.: 56.25%] [G loss: 0.892735]\n",
      "epoch:30 step:28846 [D loss: 0.653243, acc.: 62.50%] [G loss: 0.891424]\n",
      "epoch:30 step:28847 [D loss: 0.646200, acc.: 59.38%] [G loss: 0.922540]\n",
      "epoch:30 step:28848 [D loss: 0.691873, acc.: 55.47%] [G loss: 0.940399]\n",
      "epoch:30 step:28849 [D loss: 0.639410, acc.: 64.06%] [G loss: 0.944999]\n",
      "epoch:30 step:28850 [D loss: 0.689452, acc.: 57.81%] [G loss: 0.963283]\n",
      "epoch:30 step:28851 [D loss: 0.634302, acc.: 65.62%] [G loss: 0.880300]\n",
      "epoch:30 step:28852 [D loss: 0.649312, acc.: 67.97%] [G loss: 0.850680]\n",
      "epoch:30 step:28853 [D loss: 0.677667, acc.: 54.69%] [G loss: 0.903576]\n",
      "epoch:30 step:28854 [D loss: 0.635515, acc.: 66.41%] [G loss: 0.895648]\n",
      "epoch:30 step:28855 [D loss: 0.671847, acc.: 55.47%] [G loss: 0.954010]\n",
      "epoch:30 step:28856 [D loss: 0.613341, acc.: 68.75%] [G loss: 0.916880]\n",
      "epoch:30 step:28857 [D loss: 0.671613, acc.: 57.81%] [G loss: 0.926713]\n",
      "epoch:30 step:28858 [D loss: 0.608576, acc.: 66.41%] [G loss: 0.987043]\n",
      "epoch:30 step:28859 [D loss: 0.637753, acc.: 63.28%] [G loss: 0.950189]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:28860 [D loss: 0.657686, acc.: 64.06%] [G loss: 0.920265]\n",
      "epoch:30 step:28861 [D loss: 0.636920, acc.: 60.94%] [G loss: 0.947584]\n",
      "epoch:30 step:28862 [D loss: 0.669380, acc.: 57.03%] [G loss: 0.926533]\n",
      "epoch:30 step:28863 [D loss: 0.634385, acc.: 64.84%] [G loss: 0.966601]\n",
      "epoch:30 step:28864 [D loss: 0.659969, acc.: 60.94%] [G loss: 0.931333]\n",
      "epoch:30 step:28865 [D loss: 0.662778, acc.: 59.38%] [G loss: 0.928886]\n",
      "epoch:30 step:28866 [D loss: 0.621941, acc.: 67.19%] [G loss: 0.876269]\n",
      "epoch:30 step:28867 [D loss: 0.624344, acc.: 59.38%] [G loss: 0.861030]\n",
      "epoch:30 step:28868 [D loss: 0.606386, acc.: 66.41%] [G loss: 0.917522]\n",
      "epoch:30 step:28869 [D loss: 0.648715, acc.: 61.72%] [G loss: 0.913418]\n",
      "epoch:30 step:28870 [D loss: 0.641929, acc.: 62.50%] [G loss: 0.949068]\n",
      "epoch:30 step:28871 [D loss: 0.649423, acc.: 58.59%] [G loss: 0.935516]\n",
      "epoch:30 step:28872 [D loss: 0.680727, acc.: 60.16%] [G loss: 0.917348]\n",
      "epoch:30 step:28873 [D loss: 0.665611, acc.: 65.62%] [G loss: 0.912662]\n",
      "epoch:30 step:28874 [D loss: 0.618871, acc.: 65.62%] [G loss: 0.906772]\n",
      "epoch:30 step:28875 [D loss: 0.642423, acc.: 64.06%] [G loss: 0.928771]\n",
      "epoch:30 step:28876 [D loss: 0.655141, acc.: 57.81%] [G loss: 0.874480]\n",
      "epoch:30 step:28877 [D loss: 0.647164, acc.: 62.50%] [G loss: 0.850193]\n",
      "epoch:30 step:28878 [D loss: 0.630223, acc.: 64.06%] [G loss: 0.859603]\n",
      "epoch:30 step:28879 [D loss: 0.607076, acc.: 68.75%] [G loss: 0.939517]\n",
      "epoch:30 step:28880 [D loss: 0.645353, acc.: 56.25%] [G loss: 0.910063]\n",
      "epoch:30 step:28881 [D loss: 0.647018, acc.: 60.16%] [G loss: 0.954056]\n",
      "epoch:30 step:28882 [D loss: 0.623230, acc.: 63.28%] [G loss: 0.969914]\n",
      "epoch:30 step:28883 [D loss: 0.694689, acc.: 48.44%] [G loss: 0.822762]\n",
      "epoch:30 step:28884 [D loss: 0.622406, acc.: 64.06%] [G loss: 0.919310]\n",
      "epoch:30 step:28885 [D loss: 0.576668, acc.: 71.88%] [G loss: 0.995580]\n",
      "epoch:30 step:28886 [D loss: 0.638949, acc.: 62.50%] [G loss: 0.961264]\n",
      "epoch:30 step:28887 [D loss: 0.669428, acc.: 57.81%] [G loss: 0.921261]\n",
      "epoch:30 step:28888 [D loss: 0.655673, acc.: 60.16%] [G loss: 0.937926]\n",
      "epoch:30 step:28889 [D loss: 0.669421, acc.: 65.62%] [G loss: 0.944252]\n",
      "epoch:30 step:28890 [D loss: 0.634970, acc.: 60.94%] [G loss: 0.946794]\n",
      "epoch:30 step:28891 [D loss: 0.687170, acc.: 57.03%] [G loss: 0.938883]\n",
      "epoch:30 step:28892 [D loss: 0.636264, acc.: 60.94%] [G loss: 0.926865]\n",
      "epoch:30 step:28893 [D loss: 0.672988, acc.: 53.12%] [G loss: 0.929676]\n",
      "epoch:30 step:28894 [D loss: 0.677702, acc.: 59.38%] [G loss: 0.898276]\n",
      "epoch:30 step:28895 [D loss: 0.681414, acc.: 63.28%] [G loss: 0.877730]\n",
      "epoch:30 step:28896 [D loss: 0.691212, acc.: 54.69%] [G loss: 0.893457]\n",
      "epoch:30 step:28897 [D loss: 0.641910, acc.: 55.47%] [G loss: 0.934805]\n",
      "epoch:30 step:28898 [D loss: 0.646703, acc.: 57.81%] [G loss: 0.842587]\n",
      "epoch:30 step:28899 [D loss: 0.643726, acc.: 59.38%] [G loss: 0.892265]\n",
      "epoch:30 step:28900 [D loss: 0.670570, acc.: 53.91%] [G loss: 0.908561]\n",
      "epoch:30 step:28901 [D loss: 0.609045, acc.: 71.09%] [G loss: 0.925177]\n",
      "epoch:30 step:28902 [D loss: 0.623321, acc.: 64.84%] [G loss: 0.907019]\n",
      "epoch:30 step:28903 [D loss: 0.612016, acc.: 71.09%] [G loss: 0.944060]\n",
      "epoch:30 step:28904 [D loss: 0.640699, acc.: 64.84%] [G loss: 0.898130]\n",
      "epoch:30 step:28905 [D loss: 0.598544, acc.: 69.53%] [G loss: 0.942828]\n",
      "epoch:30 step:28906 [D loss: 0.645003, acc.: 60.16%] [G loss: 0.906381]\n",
      "epoch:30 step:28907 [D loss: 0.638794, acc.: 62.50%] [G loss: 0.911380]\n",
      "epoch:30 step:28908 [D loss: 0.643637, acc.: 62.50%] [G loss: 0.873867]\n",
      "epoch:30 step:28909 [D loss: 0.668146, acc.: 58.59%] [G loss: 0.899918]\n",
      "epoch:30 step:28910 [D loss: 0.675005, acc.: 60.94%] [G loss: 0.887741]\n",
      "epoch:30 step:28911 [D loss: 0.670178, acc.: 54.69%] [G loss: 0.938548]\n",
      "epoch:30 step:28912 [D loss: 0.670692, acc.: 60.94%] [G loss: 0.911909]\n",
      "epoch:30 step:28913 [D loss: 0.685302, acc.: 58.59%] [G loss: 0.884592]\n",
      "epoch:30 step:28914 [D loss: 0.668204, acc.: 55.47%] [G loss: 0.885521]\n",
      "epoch:30 step:28915 [D loss: 0.652123, acc.: 58.59%] [G loss: 0.909804]\n",
      "epoch:30 step:28916 [D loss: 0.642094, acc.: 64.84%] [G loss: 0.908579]\n",
      "epoch:30 step:28917 [D loss: 0.648589, acc.: 57.81%] [G loss: 0.908783]\n",
      "epoch:30 step:28918 [D loss: 0.669062, acc.: 60.94%] [G loss: 0.951072]\n",
      "epoch:30 step:28919 [D loss: 0.625062, acc.: 65.62%] [G loss: 0.911166]\n",
      "epoch:30 step:28920 [D loss: 0.648362, acc.: 58.59%] [G loss: 0.860845]\n",
      "epoch:30 step:28921 [D loss: 0.675886, acc.: 53.91%] [G loss: 0.839632]\n",
      "epoch:30 step:28922 [D loss: 0.655477, acc.: 64.06%] [G loss: 0.896515]\n",
      "epoch:30 step:28923 [D loss: 0.657670, acc.: 64.84%] [G loss: 0.928696]\n",
      "epoch:30 step:28924 [D loss: 0.644980, acc.: 60.16%] [G loss: 0.909007]\n",
      "epoch:30 step:28925 [D loss: 0.646875, acc.: 65.62%] [G loss: 0.889127]\n",
      "epoch:30 step:28926 [D loss: 0.609345, acc.: 64.06%] [G loss: 0.943190]\n",
      "epoch:30 step:28927 [D loss: 0.706000, acc.: 56.25%] [G loss: 0.839462]\n",
      "epoch:30 step:28928 [D loss: 0.660340, acc.: 57.03%] [G loss: 0.855754]\n",
      "epoch:30 step:28929 [D loss: 0.661913, acc.: 62.50%] [G loss: 0.945430]\n",
      "epoch:30 step:28930 [D loss: 0.646539, acc.: 61.72%] [G loss: 0.860097]\n",
      "epoch:30 step:28931 [D loss: 0.666554, acc.: 57.81%] [G loss: 0.954750]\n",
      "epoch:30 step:28932 [D loss: 0.607497, acc.: 68.75%] [G loss: 0.929135]\n",
      "epoch:30 step:28933 [D loss: 0.686959, acc.: 55.47%] [G loss: 0.948107]\n",
      "epoch:30 step:28934 [D loss: 0.674088, acc.: 54.69%] [G loss: 0.888895]\n",
      "epoch:30 step:28935 [D loss: 0.647218, acc.: 61.72%] [G loss: 0.891106]\n",
      "epoch:30 step:28936 [D loss: 0.653450, acc.: 57.81%] [G loss: 0.836650]\n",
      "epoch:30 step:28937 [D loss: 0.691297, acc.: 51.56%] [G loss: 0.890536]\n",
      "epoch:30 step:28938 [D loss: 0.677544, acc.: 52.34%] [G loss: 0.827798]\n",
      "epoch:30 step:28939 [D loss: 0.635605, acc.: 63.28%] [G loss: 0.927934]\n",
      "epoch:30 step:28940 [D loss: 0.702281, acc.: 60.16%] [G loss: 0.854751]\n",
      "epoch:30 step:28941 [D loss: 0.646659, acc.: 65.62%] [G loss: 0.865577]\n",
      "epoch:30 step:28942 [D loss: 0.627250, acc.: 61.72%] [G loss: 0.803211]\n",
      "epoch:30 step:28943 [D loss: 0.638745, acc.: 64.84%] [G loss: 0.854636]\n",
      "epoch:30 step:28944 [D loss: 0.650805, acc.: 57.03%] [G loss: 0.909117]\n",
      "epoch:30 step:28945 [D loss: 0.682496, acc.: 56.25%] [G loss: 0.904877]\n",
      "epoch:30 step:28946 [D loss: 0.640695, acc.: 63.28%] [G loss: 0.895920]\n",
      "epoch:30 step:28947 [D loss: 0.665081, acc.: 57.81%] [G loss: 0.911352]\n",
      "epoch:30 step:28948 [D loss: 0.668823, acc.: 60.94%] [G loss: 0.861961]\n",
      "epoch:30 step:28949 [D loss: 0.654618, acc.: 66.41%] [G loss: 0.919527]\n",
      "epoch:30 step:28950 [D loss: 0.601420, acc.: 69.53%] [G loss: 0.943238]\n",
      "epoch:30 step:28951 [D loss: 0.633374, acc.: 67.97%] [G loss: 0.903708]\n",
      "epoch:30 step:28952 [D loss: 0.691392, acc.: 56.25%] [G loss: 0.899169]\n",
      "epoch:30 step:28953 [D loss: 0.669290, acc.: 60.16%] [G loss: 0.849273]\n",
      "epoch:30 step:28954 [D loss: 0.722762, acc.: 50.78%] [G loss: 0.925687]\n",
      "epoch:30 step:28955 [D loss: 0.669953, acc.: 60.16%] [G loss: 0.905362]\n",
      "epoch:30 step:28956 [D loss: 0.661549, acc.: 64.84%] [G loss: 0.878576]\n",
      "epoch:30 step:28957 [D loss: 0.653549, acc.: 59.38%] [G loss: 0.867598]\n",
      "epoch:30 step:28958 [D loss: 0.654345, acc.: 61.72%] [G loss: 0.912979]\n",
      "epoch:30 step:28959 [D loss: 0.621702, acc.: 71.88%] [G loss: 0.856564]\n",
      "epoch:30 step:28960 [D loss: 0.696202, acc.: 55.47%] [G loss: 0.881759]\n",
      "epoch:30 step:28961 [D loss: 0.668304, acc.: 60.94%] [G loss: 0.894338]\n",
      "epoch:30 step:28962 [D loss: 0.637361, acc.: 65.62%] [G loss: 0.913791]\n",
      "epoch:30 step:28963 [D loss: 0.695660, acc.: 60.94%] [G loss: 0.959841]\n",
      "epoch:30 step:28964 [D loss: 0.626968, acc.: 63.28%] [G loss: 0.914087]\n",
      "epoch:30 step:28965 [D loss: 0.698338, acc.: 57.81%] [G loss: 0.856144]\n",
      "epoch:30 step:28966 [D loss: 0.634963, acc.: 59.38%] [G loss: 0.905751]\n",
      "epoch:30 step:28967 [D loss: 0.687487, acc.: 53.12%] [G loss: 0.880847]\n",
      "epoch:30 step:28968 [D loss: 0.674002, acc.: 61.72%] [G loss: 0.877535]\n",
      "epoch:30 step:28969 [D loss: 0.628237, acc.: 64.06%] [G loss: 0.834759]\n",
      "epoch:30 step:28970 [D loss: 0.645775, acc.: 60.16%] [G loss: 0.887924]\n",
      "epoch:30 step:28971 [D loss: 0.612975, acc.: 68.75%] [G loss: 0.919262]\n",
      "epoch:30 step:28972 [D loss: 0.640765, acc.: 61.72%] [G loss: 0.883242]\n",
      "epoch:30 step:28973 [D loss: 0.620161, acc.: 64.06%] [G loss: 0.897543]\n",
      "epoch:30 step:28974 [D loss: 0.692466, acc.: 53.91%] [G loss: 0.883311]\n",
      "epoch:30 step:28975 [D loss: 0.646533, acc.: 59.38%] [G loss: 0.927952]\n",
      "epoch:30 step:28976 [D loss: 0.665992, acc.: 56.25%] [G loss: 0.912636]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:30 step:28977 [D loss: 0.659046, acc.: 60.94%] [G loss: 0.938266]\n",
      "epoch:30 step:28978 [D loss: 0.639192, acc.: 64.06%] [G loss: 0.887479]\n",
      "epoch:30 step:28979 [D loss: 0.635037, acc.: 63.28%] [G loss: 0.922068]\n",
      "epoch:30 step:28980 [D loss: 0.631826, acc.: 61.72%] [G loss: 0.933833]\n",
      "epoch:30 step:28981 [D loss: 0.678713, acc.: 53.12%] [G loss: 0.915261]\n",
      "epoch:30 step:28982 [D loss: 0.657894, acc.: 59.38%] [G loss: 0.908530]\n",
      "epoch:30 step:28983 [D loss: 0.671729, acc.: 57.03%] [G loss: 0.907019]\n",
      "epoch:30 step:28984 [D loss: 0.626805, acc.: 64.84%] [G loss: 0.934698]\n",
      "epoch:30 step:28985 [D loss: 0.626880, acc.: 60.94%] [G loss: 1.010190]\n",
      "epoch:30 step:28986 [D loss: 0.655179, acc.: 60.16%] [G loss: 0.889334]\n",
      "epoch:30 step:28987 [D loss: 0.631558, acc.: 65.62%] [G loss: 0.921522]\n",
      "epoch:30 step:28988 [D loss: 0.608458, acc.: 65.62%] [G loss: 0.901462]\n",
      "epoch:30 step:28989 [D loss: 0.671858, acc.: 60.94%] [G loss: 0.858095]\n",
      "epoch:30 step:28990 [D loss: 0.654624, acc.: 59.38%] [G loss: 0.908671]\n",
      "epoch:30 step:28991 [D loss: 0.675564, acc.: 57.03%] [G loss: 0.910142]\n",
      "epoch:30 step:28992 [D loss: 0.629380, acc.: 69.53%] [G loss: 1.002010]\n",
      "epoch:30 step:28993 [D loss: 0.647195, acc.: 61.72%] [G loss: 0.923182]\n",
      "epoch:30 step:28994 [D loss: 0.626332, acc.: 64.06%] [G loss: 0.984296]\n",
      "epoch:30 step:28995 [D loss: 0.634832, acc.: 59.38%] [G loss: 0.929157]\n",
      "epoch:30 step:28996 [D loss: 0.626895, acc.: 60.94%] [G loss: 0.929185]\n",
      "epoch:30 step:28997 [D loss: 0.696164, acc.: 53.91%] [G loss: 0.903928]\n",
      "epoch:30 step:28998 [D loss: 0.613996, acc.: 71.09%] [G loss: 0.863184]\n",
      "epoch:30 step:28999 [D loss: 0.625569, acc.: 66.41%] [G loss: 0.894134]\n",
      "epoch:30 step:29000 [D loss: 0.667092, acc.: 57.03%] [G loss: 0.869419]\n",
      "##############\n",
      "[2.94441557 2.28513965 2.53533541 3.75759279 1.39058862 7.44221623\n",
      " 2.86573317 3.59763369 4.33155311 4.89893224]\n",
      "##########\n",
      "epoch:30 step:29001 [D loss: 0.640226, acc.: 63.28%] [G loss: 0.869511]\n",
      "epoch:30 step:29002 [D loss: 0.680942, acc.: 63.28%] [G loss: 0.859686]\n",
      "epoch:30 step:29003 [D loss: 0.639128, acc.: 60.94%] [G loss: 0.924060]\n",
      "epoch:30 step:29004 [D loss: 0.671040, acc.: 60.16%] [G loss: 0.895942]\n",
      "epoch:30 step:29005 [D loss: 0.626342, acc.: 68.75%] [G loss: 0.910733]\n",
      "epoch:30 step:29006 [D loss: 0.630249, acc.: 67.97%] [G loss: 0.977455]\n",
      "epoch:30 step:29007 [D loss: 0.647757, acc.: 68.75%] [G loss: 0.846004]\n",
      "epoch:30 step:29008 [D loss: 0.669690, acc.: 56.25%] [G loss: 0.876243]\n",
      "epoch:30 step:29009 [D loss: 0.678232, acc.: 54.69%] [G loss: 0.949858]\n",
      "epoch:30 step:29010 [D loss: 0.638660, acc.: 64.06%] [G loss: 0.930441]\n",
      "epoch:30 step:29011 [D loss: 0.665175, acc.: 53.12%] [G loss: 0.909613]\n",
      "epoch:30 step:29012 [D loss: 0.660271, acc.: 53.91%] [G loss: 0.903183]\n",
      "epoch:30 step:29013 [D loss: 0.631023, acc.: 62.50%] [G loss: 0.929686]\n",
      "epoch:30 step:29014 [D loss: 0.618635, acc.: 68.75%] [G loss: 0.959751]\n",
      "epoch:30 step:29015 [D loss: 0.699570, acc.: 54.69%] [G loss: 0.921231]\n",
      "epoch:30 step:29016 [D loss: 0.591586, acc.: 71.88%] [G loss: 0.925249]\n",
      "epoch:30 step:29017 [D loss: 0.685342, acc.: 57.03%] [G loss: 0.878921]\n",
      "epoch:30 step:29018 [D loss: 0.717793, acc.: 52.34%] [G loss: 0.836090]\n",
      "epoch:30 step:29019 [D loss: 0.647343, acc.: 64.84%] [G loss: 0.864841]\n",
      "epoch:30 step:29020 [D loss: 0.688375, acc.: 54.69%] [G loss: 0.899312]\n",
      "epoch:30 step:29021 [D loss: 0.643057, acc.: 60.16%] [G loss: 0.914123]\n",
      "epoch:30 step:29022 [D loss: 0.674310, acc.: 57.03%] [G loss: 0.904485]\n",
      "epoch:30 step:29023 [D loss: 0.667166, acc.: 56.25%] [G loss: 0.898854]\n",
      "epoch:30 step:29024 [D loss: 0.684554, acc.: 57.81%] [G loss: 0.925374]\n",
      "epoch:30 step:29025 [D loss: 0.675351, acc.: 53.12%] [G loss: 0.945023]\n",
      "epoch:30 step:29026 [D loss: 0.666745, acc.: 59.38%] [G loss: 0.903338]\n",
      "epoch:30 step:29027 [D loss: 0.626909, acc.: 61.72%] [G loss: 0.927289]\n",
      "epoch:30 step:29028 [D loss: 0.687710, acc.: 53.91%] [G loss: 0.925052]\n",
      "epoch:30 step:29029 [D loss: 0.620076, acc.: 66.41%] [G loss: 0.964132]\n",
      "epoch:30 step:29030 [D loss: 0.622665, acc.: 64.84%] [G loss: 0.881521]\n",
      "epoch:30 step:29031 [D loss: 0.682334, acc.: 55.47%] [G loss: 0.848990]\n",
      "epoch:30 step:29032 [D loss: 0.662130, acc.: 57.81%] [G loss: 0.911585]\n",
      "epoch:30 step:29033 [D loss: 0.624724, acc.: 69.53%] [G loss: 0.852583]\n",
      "epoch:30 step:29034 [D loss: 0.627977, acc.: 64.84%] [G loss: 0.954588]\n",
      "epoch:30 step:29035 [D loss: 0.636401, acc.: 62.50%] [G loss: 0.941172]\n",
      "epoch:30 step:29036 [D loss: 0.649888, acc.: 57.03%] [G loss: 0.875878]\n",
      "epoch:30 step:29037 [D loss: 0.627532, acc.: 67.97%] [G loss: 0.943352]\n",
      "epoch:30 step:29038 [D loss: 0.637134, acc.: 63.28%] [G loss: 0.868501]\n",
      "epoch:30 step:29039 [D loss: 0.640643, acc.: 59.38%] [G loss: 0.903039]\n",
      "epoch:30 step:29040 [D loss: 0.643089, acc.: 59.38%] [G loss: 0.923827]\n",
      "epoch:30 step:29041 [D loss: 0.689122, acc.: 53.91%] [G loss: 0.866132]\n",
      "epoch:30 step:29042 [D loss: 0.613053, acc.: 71.88%] [G loss: 0.881557]\n",
      "epoch:30 step:29043 [D loss: 0.684550, acc.: 61.72%] [G loss: 0.861937]\n",
      "epoch:30 step:29044 [D loss: 0.632591, acc.: 67.19%] [G loss: 0.904870]\n",
      "epoch:30 step:29045 [D loss: 0.629395, acc.: 60.16%] [G loss: 0.884794]\n",
      "epoch:30 step:29046 [D loss: 0.612120, acc.: 67.97%] [G loss: 0.926219]\n",
      "epoch:30 step:29047 [D loss: 0.630179, acc.: 58.59%] [G loss: 0.925281]\n",
      "epoch:31 step:29048 [D loss: 0.659906, acc.: 55.47%] [G loss: 0.942313]\n",
      "epoch:31 step:29049 [D loss: 0.648674, acc.: 64.06%] [G loss: 0.926271]\n",
      "epoch:31 step:29050 [D loss: 0.675674, acc.: 54.69%] [G loss: 0.897390]\n",
      "epoch:31 step:29051 [D loss: 0.627361, acc.: 64.84%] [G loss: 0.892726]\n",
      "epoch:31 step:29052 [D loss: 0.640195, acc.: 64.06%] [G loss: 0.909150]\n",
      "epoch:31 step:29053 [D loss: 0.629904, acc.: 67.19%] [G loss: 0.934383]\n",
      "epoch:31 step:29054 [D loss: 0.720204, acc.: 49.22%] [G loss: 0.922819]\n",
      "epoch:31 step:29055 [D loss: 0.653805, acc.: 59.38%] [G loss: 0.890290]\n",
      "epoch:31 step:29056 [D loss: 0.662568, acc.: 59.38%] [G loss: 0.920704]\n",
      "epoch:31 step:29057 [D loss: 0.619678, acc.: 67.19%] [G loss: 0.895632]\n",
      "epoch:31 step:29058 [D loss: 0.660547, acc.: 62.50%] [G loss: 0.931152]\n",
      "epoch:31 step:29059 [D loss: 0.649178, acc.: 63.28%] [G loss: 0.898096]\n",
      "epoch:31 step:29060 [D loss: 0.689021, acc.: 57.03%] [G loss: 0.964553]\n",
      "epoch:31 step:29061 [D loss: 0.648450, acc.: 63.28%] [G loss: 0.958401]\n",
      "epoch:31 step:29062 [D loss: 0.631077, acc.: 64.06%] [G loss: 0.898089]\n",
      "epoch:31 step:29063 [D loss: 0.628821, acc.: 68.75%] [G loss: 0.938559]\n",
      "epoch:31 step:29064 [D loss: 0.647816, acc.: 60.16%] [G loss: 0.910524]\n",
      "epoch:31 step:29065 [D loss: 0.662902, acc.: 56.25%] [G loss: 0.916939]\n",
      "epoch:31 step:29066 [D loss: 0.671288, acc.: 61.72%] [G loss: 0.921958]\n",
      "epoch:31 step:29067 [D loss: 0.656281, acc.: 61.72%] [G loss: 0.915807]\n",
      "epoch:31 step:29068 [D loss: 0.656054, acc.: 58.59%] [G loss: 0.910981]\n",
      "epoch:31 step:29069 [D loss: 0.705269, acc.: 57.03%] [G loss: 0.907356]\n",
      "epoch:31 step:29070 [D loss: 0.642428, acc.: 62.50%] [G loss: 0.898599]\n",
      "epoch:31 step:29071 [D loss: 0.659459, acc.: 62.50%] [G loss: 0.942685]\n",
      "epoch:31 step:29072 [D loss: 0.654174, acc.: 60.16%] [G loss: 0.878627]\n",
      "epoch:31 step:29073 [D loss: 0.686849, acc.: 58.59%] [G loss: 0.888989]\n",
      "epoch:31 step:29074 [D loss: 0.620129, acc.: 64.84%] [G loss: 0.858257]\n",
      "epoch:31 step:29075 [D loss: 0.661921, acc.: 59.38%] [G loss: 0.861061]\n",
      "epoch:31 step:29076 [D loss: 0.650103, acc.: 64.06%] [G loss: 0.876388]\n",
      "epoch:31 step:29077 [D loss: 0.682754, acc.: 59.38%] [G loss: 0.933927]\n",
      "epoch:31 step:29078 [D loss: 0.700065, acc.: 55.47%] [G loss: 0.964647]\n",
      "epoch:31 step:29079 [D loss: 0.652174, acc.: 61.72%] [G loss: 0.934775]\n",
      "epoch:31 step:29080 [D loss: 0.636991, acc.: 62.50%] [G loss: 0.964848]\n",
      "epoch:31 step:29081 [D loss: 0.626385, acc.: 66.41%] [G loss: 0.930654]\n",
      "epoch:31 step:29082 [D loss: 0.662203, acc.: 61.72%] [G loss: 0.807422]\n",
      "epoch:31 step:29083 [D loss: 0.638997, acc.: 66.41%] [G loss: 0.846305]\n",
      "epoch:31 step:29084 [D loss: 0.655329, acc.: 63.28%] [G loss: 0.904519]\n",
      "epoch:31 step:29085 [D loss: 0.693947, acc.: 58.59%] [G loss: 0.953865]\n",
      "epoch:31 step:29086 [D loss: 0.635118, acc.: 62.50%] [G loss: 0.939942]\n",
      "epoch:31 step:29087 [D loss: 0.656008, acc.: 60.94%] [G loss: 0.874684]\n",
      "epoch:31 step:29088 [D loss: 0.668102, acc.: 60.16%] [G loss: 0.845732]\n",
      "epoch:31 step:29089 [D loss: 0.666563, acc.: 59.38%] [G loss: 0.888520]\n",
      "epoch:31 step:29090 [D loss: 0.636219, acc.: 62.50%] [G loss: 0.872640]\n",
      "epoch:31 step:29091 [D loss: 0.609950, acc.: 65.62%] [G loss: 0.935883]\n",
      "epoch:31 step:29092 [D loss: 0.681414, acc.: 58.59%] [G loss: 0.917190]\n",
      "epoch:31 step:29093 [D loss: 0.626382, acc.: 64.06%] [G loss: 0.916382]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:29094 [D loss: 0.676434, acc.: 58.59%] [G loss: 0.879491]\n",
      "epoch:31 step:29095 [D loss: 0.605008, acc.: 69.53%] [G loss: 0.861486]\n",
      "epoch:31 step:29096 [D loss: 0.623038, acc.: 61.72%] [G loss: 0.953498]\n",
      "epoch:31 step:29097 [D loss: 0.646137, acc.: 57.81%] [G loss: 0.886049]\n",
      "epoch:31 step:29098 [D loss: 0.611476, acc.: 67.97%] [G loss: 0.886859]\n",
      "epoch:31 step:29099 [D loss: 0.610747, acc.: 71.88%] [G loss: 0.883600]\n",
      "epoch:31 step:29100 [D loss: 0.633026, acc.: 64.84%] [G loss: 0.897663]\n",
      "epoch:31 step:29101 [D loss: 0.647046, acc.: 56.25%] [G loss: 0.906713]\n",
      "epoch:31 step:29102 [D loss: 0.667723, acc.: 58.59%] [G loss: 0.890234]\n",
      "epoch:31 step:29103 [D loss: 0.647198, acc.: 64.06%] [G loss: 0.968465]\n",
      "epoch:31 step:29104 [D loss: 0.618870, acc.: 67.97%] [G loss: 0.888569]\n",
      "epoch:31 step:29105 [D loss: 0.673602, acc.: 58.59%] [G loss: 0.872293]\n",
      "epoch:31 step:29106 [D loss: 0.562171, acc.: 73.44%] [G loss: 0.981157]\n",
      "epoch:31 step:29107 [D loss: 0.602506, acc.: 67.97%] [G loss: 0.880152]\n",
      "epoch:31 step:29108 [D loss: 0.650537, acc.: 61.72%] [G loss: 0.936414]\n",
      "epoch:31 step:29109 [D loss: 0.615080, acc.: 62.50%] [G loss: 0.907663]\n",
      "epoch:31 step:29110 [D loss: 0.642056, acc.: 63.28%] [G loss: 0.937253]\n",
      "epoch:31 step:29111 [D loss: 0.611652, acc.: 66.41%] [G loss: 0.951849]\n",
      "epoch:31 step:29112 [D loss: 0.657742, acc.: 59.38%] [G loss: 0.923071]\n",
      "epoch:31 step:29113 [D loss: 0.602945, acc.: 66.41%] [G loss: 0.943982]\n",
      "epoch:31 step:29114 [D loss: 0.686955, acc.: 57.03%] [G loss: 0.905582]\n",
      "epoch:31 step:29115 [D loss: 0.669577, acc.: 57.81%] [G loss: 0.961177]\n",
      "epoch:31 step:29116 [D loss: 0.610406, acc.: 64.84%] [G loss: 1.010156]\n",
      "epoch:31 step:29117 [D loss: 0.665005, acc.: 62.50%] [G loss: 1.007314]\n",
      "epoch:31 step:29118 [D loss: 0.619120, acc.: 68.75%] [G loss: 0.957973]\n",
      "epoch:31 step:29119 [D loss: 0.661826, acc.: 57.03%] [G loss: 0.893866]\n",
      "epoch:31 step:29120 [D loss: 0.658091, acc.: 60.94%] [G loss: 0.865705]\n",
      "epoch:31 step:29121 [D loss: 0.633438, acc.: 65.62%] [G loss: 0.817362]\n",
      "epoch:31 step:29122 [D loss: 0.664944, acc.: 59.38%] [G loss: 0.932677]\n",
      "epoch:31 step:29123 [D loss: 0.637907, acc.: 62.50%] [G loss: 0.886891]\n",
      "epoch:31 step:29124 [D loss: 0.661028, acc.: 57.81%] [G loss: 0.867379]\n",
      "epoch:31 step:29125 [D loss: 0.624573, acc.: 66.41%] [G loss: 0.970950]\n",
      "epoch:31 step:29126 [D loss: 0.631050, acc.: 67.19%] [G loss: 0.890837]\n",
      "epoch:31 step:29127 [D loss: 0.638865, acc.: 64.06%] [G loss: 0.866212]\n",
      "epoch:31 step:29128 [D loss: 0.690305, acc.: 56.25%] [G loss: 0.871505]\n",
      "epoch:31 step:29129 [D loss: 0.632126, acc.: 64.84%] [G loss: 0.929832]\n",
      "epoch:31 step:29130 [D loss: 0.667398, acc.: 57.81%] [G loss: 0.949414]\n",
      "epoch:31 step:29131 [D loss: 0.632574, acc.: 67.97%] [G loss: 0.915540]\n",
      "epoch:31 step:29132 [D loss: 0.639199, acc.: 57.03%] [G loss: 0.978701]\n",
      "epoch:31 step:29133 [D loss: 0.683864, acc.: 58.59%] [G loss: 0.936301]\n",
      "epoch:31 step:29134 [D loss: 0.633349, acc.: 68.75%] [G loss: 0.942115]\n",
      "epoch:31 step:29135 [D loss: 0.665853, acc.: 64.06%] [G loss: 0.938872]\n",
      "epoch:31 step:29136 [D loss: 0.637360, acc.: 64.06%] [G loss: 0.882802]\n",
      "epoch:31 step:29137 [D loss: 0.647628, acc.: 62.50%] [G loss: 0.855691]\n",
      "epoch:31 step:29138 [D loss: 0.650322, acc.: 62.50%] [G loss: 0.900845]\n",
      "epoch:31 step:29139 [D loss: 0.605330, acc.: 66.41%] [G loss: 0.914099]\n",
      "epoch:31 step:29140 [D loss: 0.634389, acc.: 58.59%] [G loss: 0.885259]\n",
      "epoch:31 step:29141 [D loss: 0.614946, acc.: 69.53%] [G loss: 0.928122]\n",
      "epoch:31 step:29142 [D loss: 0.666739, acc.: 59.38%] [G loss: 0.909515]\n",
      "epoch:31 step:29143 [D loss: 0.657159, acc.: 58.59%] [G loss: 0.906954]\n",
      "epoch:31 step:29144 [D loss: 0.639374, acc.: 60.94%] [G loss: 0.842231]\n",
      "epoch:31 step:29145 [D loss: 0.682236, acc.: 53.91%] [G loss: 0.879043]\n",
      "epoch:31 step:29146 [D loss: 0.669957, acc.: 57.81%] [G loss: 0.971391]\n",
      "epoch:31 step:29147 [D loss: 0.664765, acc.: 51.56%] [G loss: 0.924212]\n",
      "epoch:31 step:29148 [D loss: 0.637595, acc.: 68.75%] [G loss: 0.915732]\n",
      "epoch:31 step:29149 [D loss: 0.689852, acc.: 57.81%] [G loss: 0.952737]\n",
      "epoch:31 step:29150 [D loss: 0.619280, acc.: 64.84%] [G loss: 0.954531]\n",
      "epoch:31 step:29151 [D loss: 0.636681, acc.: 64.84%] [G loss: 0.914391]\n",
      "epoch:31 step:29152 [D loss: 0.654483, acc.: 60.16%] [G loss: 0.923465]\n",
      "epoch:31 step:29153 [D loss: 0.608869, acc.: 71.09%] [G loss: 0.901224]\n",
      "epoch:31 step:29154 [D loss: 0.643338, acc.: 61.72%] [G loss: 0.963327]\n",
      "epoch:31 step:29155 [D loss: 0.683239, acc.: 57.03%] [G loss: 0.878432]\n",
      "epoch:31 step:29156 [D loss: 0.629208, acc.: 65.62%] [G loss: 0.891882]\n",
      "epoch:31 step:29157 [D loss: 0.653594, acc.: 61.72%] [G loss: 0.940840]\n",
      "epoch:31 step:29158 [D loss: 0.623946, acc.: 64.06%] [G loss: 0.900777]\n",
      "epoch:31 step:29159 [D loss: 0.686031, acc.: 58.59%] [G loss: 0.926263]\n",
      "epoch:31 step:29160 [D loss: 0.665986, acc.: 57.81%] [G loss: 0.968264]\n",
      "epoch:31 step:29161 [D loss: 0.656447, acc.: 59.38%] [G loss: 0.977743]\n",
      "epoch:31 step:29162 [D loss: 0.671190, acc.: 60.94%] [G loss: 0.924160]\n",
      "epoch:31 step:29163 [D loss: 0.653358, acc.: 57.81%] [G loss: 0.953630]\n",
      "epoch:31 step:29164 [D loss: 0.621835, acc.: 64.06%] [G loss: 0.904892]\n",
      "epoch:31 step:29165 [D loss: 0.681270, acc.: 57.03%] [G loss: 0.919266]\n",
      "epoch:31 step:29166 [D loss: 0.627205, acc.: 64.84%] [G loss: 0.980613]\n",
      "epoch:31 step:29167 [D loss: 0.686935, acc.: 54.69%] [G loss: 0.962450]\n",
      "epoch:31 step:29168 [D loss: 0.619313, acc.: 68.75%] [G loss: 0.969446]\n",
      "epoch:31 step:29169 [D loss: 0.678682, acc.: 53.91%] [G loss: 0.886334]\n",
      "epoch:31 step:29170 [D loss: 0.653318, acc.: 63.28%] [G loss: 0.886478]\n",
      "epoch:31 step:29171 [D loss: 0.623525, acc.: 65.62%] [G loss: 0.898416]\n",
      "epoch:31 step:29172 [D loss: 0.643101, acc.: 60.94%] [G loss: 0.973072]\n",
      "epoch:31 step:29173 [D loss: 0.686713, acc.: 53.12%] [G loss: 0.899682]\n",
      "epoch:31 step:29174 [D loss: 0.641901, acc.: 66.41%] [G loss: 0.950715]\n",
      "epoch:31 step:29175 [D loss: 0.613385, acc.: 66.41%] [G loss: 0.997818]\n",
      "epoch:31 step:29176 [D loss: 0.620948, acc.: 66.41%] [G loss: 0.863000]\n",
      "epoch:31 step:29177 [D loss: 0.626956, acc.: 66.41%] [G loss: 0.881662]\n",
      "epoch:31 step:29178 [D loss: 0.632659, acc.: 65.62%] [G loss: 0.940981]\n",
      "epoch:31 step:29179 [D loss: 0.689590, acc.: 52.34%] [G loss: 0.861043]\n",
      "epoch:31 step:29180 [D loss: 0.655992, acc.: 60.16%] [G loss: 0.881120]\n",
      "epoch:31 step:29181 [D loss: 0.626234, acc.: 67.97%] [G loss: 0.889033]\n",
      "epoch:31 step:29182 [D loss: 0.672048, acc.: 57.03%] [G loss: 0.890075]\n",
      "epoch:31 step:29183 [D loss: 0.696153, acc.: 52.34%] [G loss: 0.892646]\n",
      "epoch:31 step:29184 [D loss: 0.634419, acc.: 69.53%] [G loss: 0.927924]\n",
      "epoch:31 step:29185 [D loss: 0.628497, acc.: 66.41%] [G loss: 0.992327]\n",
      "epoch:31 step:29186 [D loss: 0.651393, acc.: 60.94%] [G loss: 0.911540]\n",
      "epoch:31 step:29187 [D loss: 0.630518, acc.: 61.72%] [G loss: 0.947291]\n",
      "epoch:31 step:29188 [D loss: 0.701619, acc.: 51.56%] [G loss: 0.906523]\n",
      "epoch:31 step:29189 [D loss: 0.637273, acc.: 61.72%] [G loss: 0.943501]\n",
      "epoch:31 step:29190 [D loss: 0.624630, acc.: 64.06%] [G loss: 0.873028]\n",
      "epoch:31 step:29191 [D loss: 0.640905, acc.: 61.72%] [G loss: 0.892021]\n",
      "epoch:31 step:29192 [D loss: 0.646858, acc.: 60.16%] [G loss: 0.954240]\n",
      "epoch:31 step:29193 [D loss: 0.652315, acc.: 60.94%] [G loss: 0.911798]\n",
      "epoch:31 step:29194 [D loss: 0.646818, acc.: 57.03%] [G loss: 0.839117]\n",
      "epoch:31 step:29195 [D loss: 0.619706, acc.: 68.75%] [G loss: 0.960078]\n",
      "epoch:31 step:29196 [D loss: 0.667277, acc.: 53.91%] [G loss: 0.928639]\n",
      "epoch:31 step:29197 [D loss: 0.665467, acc.: 57.81%] [G loss: 0.873584]\n",
      "epoch:31 step:29198 [D loss: 0.640483, acc.: 61.72%] [G loss: 0.886291]\n",
      "epoch:31 step:29199 [D loss: 0.640206, acc.: 57.03%] [G loss: 0.911955]\n",
      "epoch:31 step:29200 [D loss: 0.620186, acc.: 64.06%] [G loss: 0.946000]\n",
      "##############\n",
      "[2.88493673 2.32243684 2.29877086 3.87667538 1.38016345 9.27357666\n",
      " 2.9480146  3.93231142 4.36859755 7.14868929]\n",
      "##########\n",
      "epoch:31 step:29201 [D loss: 0.632893, acc.: 63.28%] [G loss: 0.974677]\n",
      "epoch:31 step:29202 [D loss: 0.639804, acc.: 64.84%] [G loss: 0.879719]\n",
      "epoch:31 step:29203 [D loss: 0.581185, acc.: 71.09%] [G loss: 0.894654]\n",
      "epoch:31 step:29204 [D loss: 0.679161, acc.: 52.34%] [G loss: 0.893270]\n",
      "epoch:31 step:29205 [D loss: 0.621264, acc.: 67.97%] [G loss: 0.887986]\n",
      "epoch:31 step:29206 [D loss: 0.630696, acc.: 67.19%] [G loss: 0.916818]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:29207 [D loss: 0.679148, acc.: 57.03%] [G loss: 0.884895]\n",
      "epoch:31 step:29208 [D loss: 0.627025, acc.: 60.16%] [G loss: 0.945304]\n",
      "epoch:31 step:29209 [D loss: 0.652727, acc.: 65.62%] [G loss: 0.902838]\n",
      "epoch:31 step:29210 [D loss: 0.664067, acc.: 61.72%] [G loss: 0.949314]\n",
      "epoch:31 step:29211 [D loss: 0.651788, acc.: 63.28%] [G loss: 0.872954]\n",
      "epoch:31 step:29212 [D loss: 0.633111, acc.: 66.41%] [G loss: 0.876339]\n",
      "epoch:31 step:29213 [D loss: 0.606896, acc.: 64.84%] [G loss: 0.905150]\n",
      "epoch:31 step:29214 [D loss: 0.631907, acc.: 66.41%] [G loss: 0.900685]\n",
      "epoch:31 step:29215 [D loss: 0.646654, acc.: 60.16%] [G loss: 0.916895]\n",
      "epoch:31 step:29216 [D loss: 0.640385, acc.: 57.81%] [G loss: 0.894846]\n",
      "epoch:31 step:29217 [D loss: 0.653385, acc.: 60.16%] [G loss: 0.905417]\n",
      "epoch:31 step:29218 [D loss: 0.671057, acc.: 56.25%] [G loss: 0.921193]\n",
      "epoch:31 step:29219 [D loss: 0.689096, acc.: 54.69%] [G loss: 0.970085]\n",
      "epoch:31 step:29220 [D loss: 0.668646, acc.: 59.38%] [G loss: 0.967195]\n",
      "epoch:31 step:29221 [D loss: 0.621258, acc.: 66.41%] [G loss: 1.023731]\n",
      "epoch:31 step:29222 [D loss: 0.617772, acc.: 67.19%] [G loss: 0.951889]\n",
      "epoch:31 step:29223 [D loss: 0.577116, acc.: 75.78%] [G loss: 0.875819]\n",
      "epoch:31 step:29224 [D loss: 0.604631, acc.: 66.41%] [G loss: 0.962450]\n",
      "epoch:31 step:29225 [D loss: 0.601437, acc.: 65.62%] [G loss: 0.971952]\n",
      "epoch:31 step:29226 [D loss: 0.653708, acc.: 56.25%] [G loss: 0.845263]\n",
      "epoch:31 step:29227 [D loss: 0.612809, acc.: 70.31%] [G loss: 0.947315]\n",
      "epoch:31 step:29228 [D loss: 0.651459, acc.: 57.81%] [G loss: 0.886023]\n",
      "epoch:31 step:29229 [D loss: 0.604419, acc.: 71.88%] [G loss: 0.892896]\n",
      "epoch:31 step:29230 [D loss: 0.672346, acc.: 57.81%] [G loss: 0.902605]\n",
      "epoch:31 step:29231 [D loss: 0.673713, acc.: 56.25%] [G loss: 0.954471]\n",
      "epoch:31 step:29232 [D loss: 0.720361, acc.: 49.22%] [G loss: 0.932197]\n",
      "epoch:31 step:29233 [D loss: 0.645971, acc.: 58.59%] [G loss: 0.953206]\n",
      "epoch:31 step:29234 [D loss: 0.622641, acc.: 62.50%] [G loss: 0.933794]\n",
      "epoch:31 step:29235 [D loss: 0.673813, acc.: 55.47%] [G loss: 0.917275]\n",
      "epoch:31 step:29236 [D loss: 0.654729, acc.: 64.06%] [G loss: 0.922580]\n",
      "epoch:31 step:29237 [D loss: 0.683265, acc.: 57.03%] [G loss: 0.877975]\n",
      "epoch:31 step:29238 [D loss: 0.628029, acc.: 57.81%] [G loss: 0.872197]\n",
      "epoch:31 step:29239 [D loss: 0.655794, acc.: 62.50%] [G loss: 0.922677]\n",
      "epoch:31 step:29240 [D loss: 0.647434, acc.: 60.16%] [G loss: 0.933851]\n",
      "epoch:31 step:29241 [D loss: 0.670580, acc.: 55.47%] [G loss: 0.953467]\n",
      "epoch:31 step:29242 [D loss: 0.664359, acc.: 60.16%] [G loss: 0.893777]\n",
      "epoch:31 step:29243 [D loss: 0.658706, acc.: 58.59%] [G loss: 0.800657]\n",
      "epoch:31 step:29244 [D loss: 0.659443, acc.: 60.16%] [G loss: 0.892655]\n",
      "epoch:31 step:29245 [D loss: 0.626714, acc.: 66.41%] [G loss: 0.860882]\n",
      "epoch:31 step:29246 [D loss: 0.649487, acc.: 58.59%] [G loss: 0.893513]\n",
      "epoch:31 step:29247 [D loss: 0.682756, acc.: 58.59%] [G loss: 0.853080]\n",
      "epoch:31 step:29248 [D loss: 0.667484, acc.: 59.38%] [G loss: 0.877991]\n",
      "epoch:31 step:29249 [D loss: 0.608923, acc.: 67.19%] [G loss: 0.965381]\n",
      "epoch:31 step:29250 [D loss: 0.644308, acc.: 66.41%] [G loss: 0.965598]\n",
      "epoch:31 step:29251 [D loss: 0.661686, acc.: 58.59%] [G loss: 0.934271]\n",
      "epoch:31 step:29252 [D loss: 0.640525, acc.: 67.97%] [G loss: 0.989717]\n",
      "epoch:31 step:29253 [D loss: 0.660533, acc.: 59.38%] [G loss: 0.940010]\n",
      "epoch:31 step:29254 [D loss: 0.626687, acc.: 62.50%] [G loss: 0.898483]\n",
      "epoch:31 step:29255 [D loss: 0.699199, acc.: 57.81%] [G loss: 0.937353]\n",
      "epoch:31 step:29256 [D loss: 0.639328, acc.: 63.28%] [G loss: 0.855392]\n",
      "epoch:31 step:29257 [D loss: 0.641585, acc.: 61.72%] [G loss: 0.897338]\n",
      "epoch:31 step:29258 [D loss: 0.675102, acc.: 63.28%] [G loss: 0.924284]\n",
      "epoch:31 step:29259 [D loss: 0.648640, acc.: 60.94%] [G loss: 0.964621]\n",
      "epoch:31 step:29260 [D loss: 0.642361, acc.: 67.19%] [G loss: 1.032063]\n",
      "epoch:31 step:29261 [D loss: 0.643514, acc.: 67.19%] [G loss: 0.953820]\n",
      "epoch:31 step:29262 [D loss: 0.644653, acc.: 63.28%] [G loss: 0.895105]\n",
      "epoch:31 step:29263 [D loss: 0.702646, acc.: 52.34%] [G loss: 0.919306]\n",
      "epoch:31 step:29264 [D loss: 0.630108, acc.: 64.06%] [G loss: 0.913720]\n",
      "epoch:31 step:29265 [D loss: 0.664051, acc.: 55.47%] [G loss: 0.928313]\n",
      "epoch:31 step:29266 [D loss: 0.676149, acc.: 58.59%] [G loss: 0.880190]\n",
      "epoch:31 step:29267 [D loss: 0.705130, acc.: 54.69%] [G loss: 0.883871]\n",
      "epoch:31 step:29268 [D loss: 0.638292, acc.: 64.84%] [G loss: 0.890211]\n",
      "epoch:31 step:29269 [D loss: 0.701963, acc.: 52.34%] [G loss: 0.842784]\n",
      "epoch:31 step:29270 [D loss: 0.649708, acc.: 55.47%] [G loss: 0.928328]\n",
      "epoch:31 step:29271 [D loss: 0.656893, acc.: 59.38%] [G loss: 0.919206]\n",
      "epoch:31 step:29272 [D loss: 0.647155, acc.: 60.94%] [G loss: 0.862382]\n",
      "epoch:31 step:29273 [D loss: 0.647171, acc.: 64.06%] [G loss: 0.916503]\n",
      "epoch:31 step:29274 [D loss: 0.661691, acc.: 57.81%] [G loss: 0.950355]\n",
      "epoch:31 step:29275 [D loss: 0.618806, acc.: 64.06%] [G loss: 0.921101]\n",
      "epoch:31 step:29276 [D loss: 0.639435, acc.: 64.84%] [G loss: 0.885466]\n",
      "epoch:31 step:29277 [D loss: 0.698568, acc.: 53.12%] [G loss: 0.924858]\n",
      "epoch:31 step:29278 [D loss: 0.671739, acc.: 59.38%] [G loss: 0.928024]\n",
      "epoch:31 step:29279 [D loss: 0.645391, acc.: 64.06%] [G loss: 0.986849]\n",
      "epoch:31 step:29280 [D loss: 0.679166, acc.: 56.25%] [G loss: 0.912849]\n",
      "epoch:31 step:29281 [D loss: 0.686990, acc.: 59.38%] [G loss: 0.911823]\n",
      "epoch:31 step:29282 [D loss: 0.685125, acc.: 52.34%] [G loss: 0.895593]\n",
      "epoch:31 step:29283 [D loss: 0.665505, acc.: 61.72%] [G loss: 0.901634]\n",
      "epoch:31 step:29284 [D loss: 0.661335, acc.: 59.38%] [G loss: 0.917851]\n",
      "epoch:31 step:29285 [D loss: 0.653980, acc.: 58.59%] [G loss: 0.871532]\n",
      "epoch:31 step:29286 [D loss: 0.653214, acc.: 59.38%] [G loss: 0.931684]\n",
      "epoch:31 step:29287 [D loss: 0.637587, acc.: 60.94%] [G loss: 0.901539]\n",
      "epoch:31 step:29288 [D loss: 0.620875, acc.: 65.62%] [G loss: 0.883697]\n",
      "epoch:31 step:29289 [D loss: 0.647998, acc.: 62.50%] [G loss: 0.898280]\n",
      "epoch:31 step:29290 [D loss: 0.654138, acc.: 57.81%] [G loss: 0.863525]\n",
      "epoch:31 step:29291 [D loss: 0.658223, acc.: 57.81%] [G loss: 0.869309]\n",
      "epoch:31 step:29292 [D loss: 0.674308, acc.: 53.12%] [G loss: 0.891339]\n",
      "epoch:31 step:29293 [D loss: 0.662172, acc.: 54.69%] [G loss: 0.858259]\n",
      "epoch:31 step:29294 [D loss: 0.640391, acc.: 57.81%] [G loss: 0.916800]\n",
      "epoch:31 step:29295 [D loss: 0.607120, acc.: 67.19%] [G loss: 0.901897]\n",
      "epoch:31 step:29296 [D loss: 0.748656, acc.: 50.78%] [G loss: 0.921637]\n",
      "epoch:31 step:29297 [D loss: 0.683858, acc.: 57.81%] [G loss: 0.927324]\n",
      "epoch:31 step:29298 [D loss: 0.653592, acc.: 60.16%] [G loss: 0.901263]\n",
      "epoch:31 step:29299 [D loss: 0.634394, acc.: 65.62%] [G loss: 0.937907]\n",
      "epoch:31 step:29300 [D loss: 0.649835, acc.: 61.72%] [G loss: 0.933262]\n",
      "epoch:31 step:29301 [D loss: 0.673020, acc.: 55.47%] [G loss: 0.914592]\n",
      "epoch:31 step:29302 [D loss: 0.641277, acc.: 64.84%] [G loss: 0.894077]\n",
      "epoch:31 step:29303 [D loss: 0.670001, acc.: 60.16%] [G loss: 0.875017]\n",
      "epoch:31 step:29304 [D loss: 0.637690, acc.: 62.50%] [G loss: 0.894227]\n",
      "epoch:31 step:29305 [D loss: 0.663355, acc.: 60.94%] [G loss: 0.946328]\n",
      "epoch:31 step:29306 [D loss: 0.716915, acc.: 54.69%] [G loss: 0.863065]\n",
      "epoch:31 step:29307 [D loss: 0.673388, acc.: 57.03%] [G loss: 0.941616]\n",
      "epoch:31 step:29308 [D loss: 0.656604, acc.: 62.50%] [G loss: 0.968484]\n",
      "epoch:31 step:29309 [D loss: 0.655255, acc.: 58.59%] [G loss: 0.958788]\n",
      "epoch:31 step:29310 [D loss: 0.636959, acc.: 60.16%] [G loss: 1.003990]\n",
      "epoch:31 step:29311 [D loss: 0.640244, acc.: 67.19%] [G loss: 0.987140]\n",
      "epoch:31 step:29312 [D loss: 0.646292, acc.: 63.28%] [G loss: 0.959472]\n",
      "epoch:31 step:29313 [D loss: 0.613688, acc.: 64.84%] [G loss: 0.936296]\n",
      "epoch:31 step:29314 [D loss: 0.652168, acc.: 60.94%] [G loss: 0.947285]\n",
      "epoch:31 step:29315 [D loss: 0.653788, acc.: 60.94%] [G loss: 0.900555]\n",
      "epoch:31 step:29316 [D loss: 0.633782, acc.: 67.19%] [G loss: 0.839990]\n",
      "epoch:31 step:29317 [D loss: 0.669942, acc.: 60.16%] [G loss: 0.824741]\n",
      "epoch:31 step:29318 [D loss: 0.607264, acc.: 71.88%] [G loss: 0.883156]\n",
      "epoch:31 step:29319 [D loss: 0.650031, acc.: 60.16%] [G loss: 0.892459]\n",
      "epoch:31 step:29320 [D loss: 0.668683, acc.: 57.81%] [G loss: 0.866626]\n",
      "epoch:31 step:29321 [D loss: 0.653277, acc.: 57.81%] [G loss: 0.977275]\n",
      "epoch:31 step:29322 [D loss: 0.650832, acc.: 62.50%] [G loss: 0.932995]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:29323 [D loss: 0.657577, acc.: 61.72%] [G loss: 0.951881]\n",
      "epoch:31 step:29324 [D loss: 0.603860, acc.: 68.75%] [G loss: 0.909472]\n",
      "epoch:31 step:29325 [D loss: 0.717767, acc.: 50.00%] [G loss: 0.901898]\n",
      "epoch:31 step:29326 [D loss: 0.700106, acc.: 56.25%] [G loss: 0.923199]\n",
      "epoch:31 step:29327 [D loss: 0.656228, acc.: 57.03%] [G loss: 0.856260]\n",
      "epoch:31 step:29328 [D loss: 0.652918, acc.: 57.81%] [G loss: 0.840840]\n",
      "epoch:31 step:29329 [D loss: 0.642880, acc.: 62.50%] [G loss: 0.905453]\n",
      "epoch:31 step:29330 [D loss: 0.651974, acc.: 60.16%] [G loss: 0.881598]\n",
      "epoch:31 step:29331 [D loss: 0.612458, acc.: 66.41%] [G loss: 0.904136]\n",
      "epoch:31 step:29332 [D loss: 0.629653, acc.: 60.94%] [G loss: 0.935837]\n",
      "epoch:31 step:29333 [D loss: 0.638373, acc.: 60.94%] [G loss: 0.946844]\n",
      "epoch:31 step:29334 [D loss: 0.624969, acc.: 61.72%] [G loss: 0.984295]\n",
      "epoch:31 step:29335 [D loss: 0.651279, acc.: 60.94%] [G loss: 0.941472]\n",
      "epoch:31 step:29336 [D loss: 0.658385, acc.: 61.72%] [G loss: 0.949187]\n",
      "epoch:31 step:29337 [D loss: 0.615022, acc.: 62.50%] [G loss: 0.923206]\n",
      "epoch:31 step:29338 [D loss: 0.687820, acc.: 59.38%] [G loss: 0.856957]\n",
      "epoch:31 step:29339 [D loss: 0.669585, acc.: 56.25%] [G loss: 0.925473]\n",
      "epoch:31 step:29340 [D loss: 0.661487, acc.: 60.94%] [G loss: 0.890476]\n",
      "epoch:31 step:29341 [D loss: 0.660730, acc.: 56.25%] [G loss: 0.906101]\n",
      "epoch:31 step:29342 [D loss: 0.704168, acc.: 56.25%] [G loss: 0.912716]\n",
      "epoch:31 step:29343 [D loss: 0.684515, acc.: 60.16%] [G loss: 0.946624]\n",
      "epoch:31 step:29344 [D loss: 0.618018, acc.: 66.41%] [G loss: 0.947178]\n",
      "epoch:31 step:29345 [D loss: 0.660209, acc.: 57.03%] [G loss: 0.953371]\n",
      "epoch:31 step:29346 [D loss: 0.676509, acc.: 63.28%] [G loss: 0.906538]\n",
      "epoch:31 step:29347 [D loss: 0.638397, acc.: 58.59%] [G loss: 0.955448]\n",
      "epoch:31 step:29348 [D loss: 0.700167, acc.: 53.91%] [G loss: 0.881915]\n",
      "epoch:31 step:29349 [D loss: 0.645916, acc.: 55.47%] [G loss: 0.959069]\n",
      "epoch:31 step:29350 [D loss: 0.697121, acc.: 53.91%] [G loss: 0.906966]\n",
      "epoch:31 step:29351 [D loss: 0.597797, acc.: 73.44%] [G loss: 0.947471]\n",
      "epoch:31 step:29352 [D loss: 0.654767, acc.: 59.38%] [G loss: 0.935711]\n",
      "epoch:31 step:29353 [D loss: 0.649069, acc.: 62.50%] [G loss: 0.909467]\n",
      "epoch:31 step:29354 [D loss: 0.703974, acc.: 51.56%] [G loss: 0.877138]\n",
      "epoch:31 step:29355 [D loss: 0.651597, acc.: 59.38%] [G loss: 0.809637]\n",
      "epoch:31 step:29356 [D loss: 0.623352, acc.: 67.97%] [G loss: 0.861078]\n",
      "epoch:31 step:29357 [D loss: 0.647341, acc.: 59.38%] [G loss: 0.920891]\n",
      "epoch:31 step:29358 [D loss: 0.651292, acc.: 64.06%] [G loss: 0.957700]\n",
      "epoch:31 step:29359 [D loss: 0.660765, acc.: 62.50%] [G loss: 0.903069]\n",
      "epoch:31 step:29360 [D loss: 0.678316, acc.: 58.59%] [G loss: 0.886415]\n",
      "epoch:31 step:29361 [D loss: 0.625263, acc.: 61.72%] [G loss: 0.907171]\n",
      "epoch:31 step:29362 [D loss: 0.641662, acc.: 66.41%] [G loss: 0.884603]\n",
      "epoch:31 step:29363 [D loss: 0.654267, acc.: 55.47%] [G loss: 0.924400]\n",
      "epoch:31 step:29364 [D loss: 0.662283, acc.: 62.50%] [G loss: 0.902359]\n",
      "epoch:31 step:29365 [D loss: 0.640207, acc.: 64.84%] [G loss: 0.941579]\n",
      "epoch:31 step:29366 [D loss: 0.664194, acc.: 55.47%] [G loss: 0.946009]\n",
      "epoch:31 step:29367 [D loss: 0.649902, acc.: 60.16%] [G loss: 0.920603]\n",
      "epoch:31 step:29368 [D loss: 0.628102, acc.: 64.06%] [G loss: 0.889046]\n",
      "epoch:31 step:29369 [D loss: 0.644610, acc.: 60.16%] [G loss: 0.886376]\n",
      "epoch:31 step:29370 [D loss: 0.640873, acc.: 61.72%] [G loss: 0.905730]\n",
      "epoch:31 step:29371 [D loss: 0.611216, acc.: 70.31%] [G loss: 0.879564]\n",
      "epoch:31 step:29372 [D loss: 0.653703, acc.: 62.50%] [G loss: 0.896564]\n",
      "epoch:31 step:29373 [D loss: 0.699799, acc.: 52.34%] [G loss: 0.860429]\n",
      "epoch:31 step:29374 [D loss: 0.616682, acc.: 59.38%] [G loss: 0.936043]\n",
      "epoch:31 step:29375 [D loss: 0.638482, acc.: 63.28%] [G loss: 0.875310]\n",
      "epoch:31 step:29376 [D loss: 0.616530, acc.: 67.97%] [G loss: 0.886262]\n",
      "epoch:31 step:29377 [D loss: 0.634352, acc.: 63.28%] [G loss: 0.907937]\n",
      "epoch:31 step:29378 [D loss: 0.706044, acc.: 53.91%] [G loss: 0.925570]\n",
      "epoch:31 step:29379 [D loss: 0.618635, acc.: 62.50%] [G loss: 0.982019]\n",
      "epoch:31 step:29380 [D loss: 0.617827, acc.: 62.50%] [G loss: 0.919569]\n",
      "epoch:31 step:29381 [D loss: 0.612925, acc.: 65.62%] [G loss: 0.890266]\n",
      "epoch:31 step:29382 [D loss: 0.656719, acc.: 54.69%] [G loss: 0.917042]\n",
      "epoch:31 step:29383 [D loss: 0.641822, acc.: 58.59%] [G loss: 0.901286]\n",
      "epoch:31 step:29384 [D loss: 0.645462, acc.: 63.28%] [G loss: 0.894229]\n",
      "epoch:31 step:29385 [D loss: 0.654040, acc.: 58.59%] [G loss: 0.895186]\n",
      "epoch:31 step:29386 [D loss: 0.646423, acc.: 63.28%] [G loss: 0.940318]\n",
      "epoch:31 step:29387 [D loss: 0.666217, acc.: 57.81%] [G loss: 0.938572]\n",
      "epoch:31 step:29388 [D loss: 0.647651, acc.: 62.50%] [G loss: 0.894562]\n",
      "epoch:31 step:29389 [D loss: 0.616689, acc.: 69.53%] [G loss: 0.942738]\n",
      "epoch:31 step:29390 [D loss: 0.647178, acc.: 63.28%] [G loss: 0.905001]\n",
      "epoch:31 step:29391 [D loss: 0.645288, acc.: 62.50%] [G loss: 0.888057]\n",
      "epoch:31 step:29392 [D loss: 0.630739, acc.: 60.16%] [G loss: 0.858252]\n",
      "epoch:31 step:29393 [D loss: 0.679857, acc.: 57.81%] [G loss: 0.878647]\n",
      "epoch:31 step:29394 [D loss: 0.648390, acc.: 60.94%] [G loss: 0.874198]\n",
      "epoch:31 step:29395 [D loss: 0.640306, acc.: 61.72%] [G loss: 0.909393]\n",
      "epoch:31 step:29396 [D loss: 0.641909, acc.: 60.94%] [G loss: 0.876545]\n",
      "epoch:31 step:29397 [D loss: 0.640409, acc.: 61.72%] [G loss: 0.933708]\n",
      "epoch:31 step:29398 [D loss: 0.647210, acc.: 62.50%] [G loss: 0.869509]\n",
      "epoch:31 step:29399 [D loss: 0.671516, acc.: 61.72%] [G loss: 0.844426]\n",
      "epoch:31 step:29400 [D loss: 0.672463, acc.: 52.34%] [G loss: 0.856310]\n",
      "##############\n",
      "[3.02276407 2.661763   2.3943065  4.34513801 1.5074741  9.27426719\n",
      " 2.74832847 3.71619075 4.28759419 5.63721182]\n",
      "##########\n",
      "epoch:31 step:29401 [D loss: 0.695505, acc.: 53.12%] [G loss: 0.908073]\n",
      "epoch:31 step:29402 [D loss: 0.641239, acc.: 64.06%] [G loss: 0.909949]\n",
      "epoch:31 step:29403 [D loss: 0.636949, acc.: 64.06%] [G loss: 0.961518]\n",
      "epoch:31 step:29404 [D loss: 0.647241, acc.: 60.16%] [G loss: 0.919898]\n",
      "epoch:31 step:29405 [D loss: 0.670937, acc.: 56.25%] [G loss: 0.913625]\n",
      "epoch:31 step:29406 [D loss: 0.665599, acc.: 59.38%] [G loss: 0.908078]\n",
      "epoch:31 step:29407 [D loss: 0.605738, acc.: 65.62%] [G loss: 0.944013]\n",
      "epoch:31 step:29408 [D loss: 0.625935, acc.: 67.97%] [G loss: 0.893355]\n",
      "epoch:31 step:29409 [D loss: 0.626839, acc.: 64.06%] [G loss: 0.910942]\n",
      "epoch:31 step:29410 [D loss: 0.685718, acc.: 60.94%] [G loss: 0.847822]\n",
      "epoch:31 step:29411 [D loss: 0.658665, acc.: 61.72%] [G loss: 0.890775]\n",
      "epoch:31 step:29412 [D loss: 0.631612, acc.: 65.62%] [G loss: 0.985241]\n",
      "epoch:31 step:29413 [D loss: 0.652563, acc.: 57.81%] [G loss: 0.836906]\n",
      "epoch:31 step:29414 [D loss: 0.608455, acc.: 71.09%] [G loss: 0.908909]\n",
      "epoch:31 step:29415 [D loss: 0.671057, acc.: 60.16%] [G loss: 0.888165]\n",
      "epoch:31 step:29416 [D loss: 0.674371, acc.: 60.16%] [G loss: 0.864876]\n",
      "epoch:31 step:29417 [D loss: 0.638526, acc.: 65.62%] [G loss: 0.881554]\n",
      "epoch:31 step:29418 [D loss: 0.647689, acc.: 57.81%] [G loss: 0.927710]\n",
      "epoch:31 step:29419 [D loss: 0.664886, acc.: 59.38%] [G loss: 0.860778]\n",
      "epoch:31 step:29420 [D loss: 0.597867, acc.: 72.66%] [G loss: 0.925900]\n",
      "epoch:31 step:29421 [D loss: 0.718011, acc.: 46.88%] [G loss: 0.904024]\n",
      "epoch:31 step:29422 [D loss: 0.674396, acc.: 57.81%] [G loss: 0.961455]\n",
      "epoch:31 step:29423 [D loss: 0.671632, acc.: 57.81%] [G loss: 0.831986]\n",
      "epoch:31 step:29424 [D loss: 0.631660, acc.: 64.06%] [G loss: 0.883387]\n",
      "epoch:31 step:29425 [D loss: 0.608145, acc.: 63.28%] [G loss: 0.904767]\n",
      "epoch:31 step:29426 [D loss: 0.678229, acc.: 59.38%] [G loss: 0.908183]\n",
      "epoch:31 step:29427 [D loss: 0.640797, acc.: 65.62%] [G loss: 0.946135]\n",
      "epoch:31 step:29428 [D loss: 0.636155, acc.: 57.03%] [G loss: 0.946723]\n",
      "epoch:31 step:29429 [D loss: 0.631751, acc.: 62.50%] [G loss: 0.939916]\n",
      "epoch:31 step:29430 [D loss: 0.625829, acc.: 67.97%] [G loss: 0.895132]\n",
      "epoch:31 step:29431 [D loss: 0.664749, acc.: 59.38%] [G loss: 0.846718]\n",
      "epoch:31 step:29432 [D loss: 0.661697, acc.: 59.38%] [G loss: 0.848269]\n",
      "epoch:31 step:29433 [D loss: 0.642642, acc.: 64.84%] [G loss: 0.840318]\n",
      "epoch:31 step:29434 [D loss: 0.635387, acc.: 65.62%] [G loss: 0.964632]\n",
      "epoch:31 step:29435 [D loss: 0.655595, acc.: 60.16%] [G loss: 0.891290]\n",
      "epoch:31 step:29436 [D loss: 0.641345, acc.: 60.94%] [G loss: 0.895663]\n",
      "epoch:31 step:29437 [D loss: 0.678850, acc.: 59.38%] [G loss: 0.843052]\n",
      "epoch:31 step:29438 [D loss: 0.673741, acc.: 60.16%] [G loss: 0.835918]\n",
      "epoch:31 step:29439 [D loss: 0.669384, acc.: 54.69%] [G loss: 0.912819]\n",
      "epoch:31 step:29440 [D loss: 0.735033, acc.: 46.09%] [G loss: 0.931114]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:29441 [D loss: 0.646938, acc.: 62.50%] [G loss: 0.882453]\n",
      "epoch:31 step:29442 [D loss: 0.635552, acc.: 61.72%] [G loss: 0.965122]\n",
      "epoch:31 step:29443 [D loss: 0.681674, acc.: 57.81%] [G loss: 0.874453]\n",
      "epoch:31 step:29444 [D loss: 0.689366, acc.: 53.91%] [G loss: 0.970128]\n",
      "epoch:31 step:29445 [D loss: 0.693371, acc.: 53.91%] [G loss: 0.906585]\n",
      "epoch:31 step:29446 [D loss: 0.652197, acc.: 60.16%] [G loss: 0.857427]\n",
      "epoch:31 step:29447 [D loss: 0.618865, acc.: 68.75%] [G loss: 0.942840]\n",
      "epoch:31 step:29448 [D loss: 0.661688, acc.: 58.59%] [G loss: 0.913786]\n",
      "epoch:31 step:29449 [D loss: 0.616639, acc.: 62.50%] [G loss: 0.968591]\n",
      "epoch:31 step:29450 [D loss: 0.645625, acc.: 60.94%] [G loss: 0.962783]\n",
      "epoch:31 step:29451 [D loss: 0.614302, acc.: 64.84%] [G loss: 0.934070]\n",
      "epoch:31 step:29452 [D loss: 0.663502, acc.: 58.59%] [G loss: 0.933004]\n",
      "epoch:31 step:29453 [D loss: 0.608899, acc.: 73.44%] [G loss: 1.012097]\n",
      "epoch:31 step:29454 [D loss: 0.672654, acc.: 59.38%] [G loss: 0.977622]\n",
      "epoch:31 step:29455 [D loss: 0.619991, acc.: 63.28%] [G loss: 0.973331]\n",
      "epoch:31 step:29456 [D loss: 0.660880, acc.: 57.81%] [G loss: 0.908903]\n",
      "epoch:31 step:29457 [D loss: 0.672314, acc.: 60.16%] [G loss: 0.924340]\n",
      "epoch:31 step:29458 [D loss: 0.680957, acc.: 57.81%] [G loss: 0.974350]\n",
      "epoch:31 step:29459 [D loss: 0.682683, acc.: 58.59%] [G loss: 0.863278]\n",
      "epoch:31 step:29460 [D loss: 0.679559, acc.: 57.03%] [G loss: 0.908859]\n",
      "epoch:31 step:29461 [D loss: 0.617202, acc.: 64.84%] [G loss: 0.891400]\n",
      "epoch:31 step:29462 [D loss: 0.681975, acc.: 50.78%] [G loss: 0.925389]\n",
      "epoch:31 step:29463 [D loss: 0.612231, acc.: 63.28%] [G loss: 0.919291]\n",
      "epoch:31 step:29464 [D loss: 0.604377, acc.: 71.09%] [G loss: 0.928860]\n",
      "epoch:31 step:29465 [D loss: 0.654971, acc.: 58.59%] [G loss: 0.870937]\n",
      "epoch:31 step:29466 [D loss: 0.628504, acc.: 63.28%] [G loss: 0.901358]\n",
      "epoch:31 step:29467 [D loss: 0.623173, acc.: 66.41%] [G loss: 0.924698]\n",
      "epoch:31 step:29468 [D loss: 0.606829, acc.: 64.84%] [G loss: 0.959138]\n",
      "epoch:31 step:29469 [D loss: 0.697610, acc.: 55.47%] [G loss: 0.904007]\n",
      "epoch:31 step:29470 [D loss: 0.670709, acc.: 57.81%] [G loss: 0.926343]\n",
      "epoch:31 step:29471 [D loss: 0.646550, acc.: 64.06%] [G loss: 0.950298]\n",
      "epoch:31 step:29472 [D loss: 0.670152, acc.: 64.06%] [G loss: 0.905632]\n",
      "epoch:31 step:29473 [D loss: 0.657172, acc.: 62.50%] [G loss: 0.952158]\n",
      "epoch:31 step:29474 [D loss: 0.653426, acc.: 63.28%] [G loss: 0.935661]\n",
      "epoch:31 step:29475 [D loss: 0.692311, acc.: 57.03%] [G loss: 0.954766]\n",
      "epoch:31 step:29476 [D loss: 0.673220, acc.: 59.38%] [G loss: 0.875494]\n",
      "epoch:31 step:29477 [D loss: 0.694706, acc.: 54.69%] [G loss: 0.921923]\n",
      "epoch:31 step:29478 [D loss: 0.659415, acc.: 62.50%] [G loss: 0.965497]\n",
      "epoch:31 step:29479 [D loss: 0.627106, acc.: 64.84%] [G loss: 0.957879]\n",
      "epoch:31 step:29480 [D loss: 0.651409, acc.: 62.50%] [G loss: 0.903279]\n",
      "epoch:31 step:29481 [D loss: 0.655952, acc.: 57.03%] [G loss: 0.901202]\n",
      "epoch:31 step:29482 [D loss: 0.654719, acc.: 61.72%] [G loss: 0.890210]\n",
      "epoch:31 step:29483 [D loss: 0.650582, acc.: 60.16%] [G loss: 0.896309]\n",
      "epoch:31 step:29484 [D loss: 0.629951, acc.: 65.62%] [G loss: 0.900008]\n",
      "epoch:31 step:29485 [D loss: 0.672562, acc.: 57.81%] [G loss: 0.956386]\n",
      "epoch:31 step:29486 [D loss: 0.652174, acc.: 56.25%] [G loss: 0.921470]\n",
      "epoch:31 step:29487 [D loss: 0.659683, acc.: 61.72%] [G loss: 0.937109]\n",
      "epoch:31 step:29488 [D loss: 0.671946, acc.: 63.28%] [G loss: 0.821288]\n",
      "epoch:31 step:29489 [D loss: 0.659624, acc.: 60.94%] [G loss: 0.872112]\n",
      "epoch:31 step:29490 [D loss: 0.633532, acc.: 62.50%] [G loss: 0.893878]\n",
      "epoch:31 step:29491 [D loss: 0.638851, acc.: 63.28%] [G loss: 0.883598]\n",
      "epoch:31 step:29492 [D loss: 0.652779, acc.: 57.81%] [G loss: 0.870678]\n",
      "epoch:31 step:29493 [D loss: 0.687660, acc.: 54.69%] [G loss: 0.930354]\n",
      "epoch:31 step:29494 [D loss: 0.642114, acc.: 64.06%] [G loss: 0.954778]\n",
      "epoch:31 step:29495 [D loss: 0.680930, acc.: 54.69%] [G loss: 0.920426]\n",
      "epoch:31 step:29496 [D loss: 0.650110, acc.: 55.47%] [G loss: 0.901155]\n",
      "epoch:31 step:29497 [D loss: 0.632758, acc.: 64.06%] [G loss: 0.884909]\n",
      "epoch:31 step:29498 [D loss: 0.628917, acc.: 64.06%] [G loss: 0.904006]\n",
      "epoch:31 step:29499 [D loss: 0.676716, acc.: 63.28%] [G loss: 0.890128]\n",
      "epoch:31 step:29500 [D loss: 0.635101, acc.: 61.72%] [G loss: 0.892222]\n",
      "epoch:31 step:29501 [D loss: 0.647539, acc.: 62.50%] [G loss: 0.843362]\n",
      "epoch:31 step:29502 [D loss: 0.589364, acc.: 73.44%] [G loss: 0.868779]\n",
      "epoch:31 step:29503 [D loss: 0.685830, acc.: 57.81%] [G loss: 0.903862]\n",
      "epoch:31 step:29504 [D loss: 0.657459, acc.: 58.59%] [G loss: 0.822809]\n",
      "epoch:31 step:29505 [D loss: 0.665551, acc.: 61.72%] [G loss: 0.882075]\n",
      "epoch:31 step:29506 [D loss: 0.613155, acc.: 67.19%] [G loss: 0.928174]\n",
      "epoch:31 step:29507 [D loss: 0.635067, acc.: 64.84%] [G loss: 0.907193]\n",
      "epoch:31 step:29508 [D loss: 0.657117, acc.: 53.12%] [G loss: 0.965891]\n",
      "epoch:31 step:29509 [D loss: 0.674244, acc.: 50.00%] [G loss: 0.962687]\n",
      "epoch:31 step:29510 [D loss: 0.642293, acc.: 61.72%] [G loss: 0.972996]\n",
      "epoch:31 step:29511 [D loss: 0.661079, acc.: 59.38%] [G loss: 0.954681]\n",
      "epoch:31 step:29512 [D loss: 0.674939, acc.: 57.81%] [G loss: 0.945782]\n",
      "epoch:31 step:29513 [D loss: 0.662953, acc.: 62.50%] [G loss: 0.912934]\n",
      "epoch:31 step:29514 [D loss: 0.627817, acc.: 66.41%] [G loss: 0.913458]\n",
      "epoch:31 step:29515 [D loss: 0.641723, acc.: 63.28%] [G loss: 0.953618]\n",
      "epoch:31 step:29516 [D loss: 0.612866, acc.: 59.38%] [G loss: 1.019339]\n",
      "epoch:31 step:29517 [D loss: 0.654726, acc.: 61.72%] [G loss: 1.018569]\n",
      "epoch:31 step:29518 [D loss: 0.616017, acc.: 66.41%] [G loss: 0.980542]\n",
      "epoch:31 step:29519 [D loss: 0.614782, acc.: 69.53%] [G loss: 0.927085]\n",
      "epoch:31 step:29520 [D loss: 0.663237, acc.: 58.59%] [G loss: 1.005941]\n",
      "epoch:31 step:29521 [D loss: 0.622542, acc.: 66.41%] [G loss: 0.958218]\n",
      "epoch:31 step:29522 [D loss: 0.610680, acc.: 66.41%] [G loss: 0.990064]\n",
      "epoch:31 step:29523 [D loss: 0.667710, acc.: 57.03%] [G loss: 0.970741]\n",
      "epoch:31 step:29524 [D loss: 0.691371, acc.: 52.34%] [G loss: 1.006811]\n",
      "epoch:31 step:29525 [D loss: 0.651834, acc.: 57.81%] [G loss: 0.898394]\n",
      "epoch:31 step:29526 [D loss: 0.672446, acc.: 57.81%] [G loss: 0.894932]\n",
      "epoch:31 step:29527 [D loss: 0.647400, acc.: 59.38%] [G loss: 0.870607]\n",
      "epoch:31 step:29528 [D loss: 0.680997, acc.: 56.25%] [G loss: 0.924178]\n",
      "epoch:31 step:29529 [D loss: 0.682553, acc.: 57.81%] [G loss: 0.980798]\n",
      "epoch:31 step:29530 [D loss: 0.659220, acc.: 63.28%] [G loss: 0.976733]\n",
      "epoch:31 step:29531 [D loss: 0.632988, acc.: 64.84%] [G loss: 0.960840]\n",
      "epoch:31 step:29532 [D loss: 0.659585, acc.: 56.25%] [G loss: 0.933771]\n",
      "epoch:31 step:29533 [D loss: 0.631055, acc.: 62.50%] [G loss: 0.942555]\n",
      "epoch:31 step:29534 [D loss: 0.624318, acc.: 64.84%] [G loss: 0.941528]\n",
      "epoch:31 step:29535 [D loss: 0.606498, acc.: 67.97%] [G loss: 0.923129]\n",
      "epoch:31 step:29536 [D loss: 0.647441, acc.: 68.75%] [G loss: 0.935632]\n",
      "epoch:31 step:29537 [D loss: 0.625278, acc.: 65.62%] [G loss: 0.980847]\n",
      "epoch:31 step:29538 [D loss: 0.660232, acc.: 57.03%] [G loss: 0.903356]\n",
      "epoch:31 step:29539 [D loss: 0.633967, acc.: 62.50%] [G loss: 0.932898]\n",
      "epoch:31 step:29540 [D loss: 0.660482, acc.: 56.25%] [G loss: 0.946308]\n",
      "epoch:31 step:29541 [D loss: 0.641085, acc.: 63.28%] [G loss: 0.990945]\n",
      "epoch:31 step:29542 [D loss: 0.650851, acc.: 62.50%] [G loss: 0.952220]\n",
      "epoch:31 step:29543 [D loss: 0.663101, acc.: 57.81%] [G loss: 0.986244]\n",
      "epoch:31 step:29544 [D loss: 0.693217, acc.: 53.12%] [G loss: 0.945302]\n",
      "epoch:31 step:29545 [D loss: 0.665390, acc.: 58.59%] [G loss: 0.933874]\n",
      "epoch:31 step:29546 [D loss: 0.600651, acc.: 70.31%] [G loss: 0.964650]\n",
      "epoch:31 step:29547 [D loss: 0.678344, acc.: 56.25%] [G loss: 0.907557]\n",
      "epoch:31 step:29548 [D loss: 0.674602, acc.: 49.22%] [G loss: 0.931421]\n",
      "epoch:31 step:29549 [D loss: 0.584051, acc.: 66.41%] [G loss: 0.911748]\n",
      "epoch:31 step:29550 [D loss: 0.642496, acc.: 64.06%] [G loss: 0.896904]\n",
      "epoch:31 step:29551 [D loss: 0.686732, acc.: 53.12%] [G loss: 0.863840]\n",
      "epoch:31 step:29552 [D loss: 0.677180, acc.: 57.03%] [G loss: 0.883359]\n",
      "epoch:31 step:29553 [D loss: 0.647071, acc.: 67.97%] [G loss: 0.881646]\n",
      "epoch:31 step:29554 [D loss: 0.688404, acc.: 54.69%] [G loss: 0.899489]\n",
      "epoch:31 step:29555 [D loss: 0.624992, acc.: 66.41%] [G loss: 0.967278]\n",
      "epoch:31 step:29556 [D loss: 0.623078, acc.: 68.75%] [G loss: 0.912961]\n",
      "epoch:31 step:29557 [D loss: 0.601045, acc.: 70.31%] [G loss: 0.945136]\n",
      "epoch:31 step:29558 [D loss: 0.615124, acc.: 68.75%] [G loss: 0.938455]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:29559 [D loss: 0.649065, acc.: 58.59%] [G loss: 0.924197]\n",
      "epoch:31 step:29560 [D loss: 0.637346, acc.: 62.50%] [G loss: 0.867014]\n",
      "epoch:31 step:29561 [D loss: 0.650616, acc.: 60.16%] [G loss: 0.856886]\n",
      "epoch:31 step:29562 [D loss: 0.672121, acc.: 57.81%] [G loss: 0.919479]\n",
      "epoch:31 step:29563 [D loss: 0.667999, acc.: 59.38%] [G loss: 0.979096]\n",
      "epoch:31 step:29564 [D loss: 0.649442, acc.: 61.72%] [G loss: 0.960455]\n",
      "epoch:31 step:29565 [D loss: 0.660664, acc.: 64.84%] [G loss: 0.913811]\n",
      "epoch:31 step:29566 [D loss: 0.646449, acc.: 63.28%] [G loss: 0.842413]\n",
      "epoch:31 step:29567 [D loss: 0.652061, acc.: 61.72%] [G loss: 0.894489]\n",
      "epoch:31 step:29568 [D loss: 0.658062, acc.: 59.38%] [G loss: 0.882701]\n",
      "epoch:31 step:29569 [D loss: 0.618081, acc.: 67.19%] [G loss: 0.896871]\n",
      "epoch:31 step:29570 [D loss: 0.600028, acc.: 72.66%] [G loss: 0.904692]\n",
      "epoch:31 step:29571 [D loss: 0.645919, acc.: 62.50%] [G loss: 0.962685]\n",
      "epoch:31 step:29572 [D loss: 0.664717, acc.: 56.25%] [G loss: 0.888286]\n",
      "epoch:31 step:29573 [D loss: 0.661604, acc.: 58.59%] [G loss: 0.885284]\n",
      "epoch:31 step:29574 [D loss: 0.639057, acc.: 64.84%] [G loss: 0.913372]\n",
      "epoch:31 step:29575 [D loss: 0.660262, acc.: 64.06%] [G loss: 0.954394]\n",
      "epoch:31 step:29576 [D loss: 0.636744, acc.: 62.50%] [G loss: 0.869605]\n",
      "epoch:31 step:29577 [D loss: 0.612640, acc.: 69.53%] [G loss: 0.846903]\n",
      "epoch:31 step:29578 [D loss: 0.692141, acc.: 61.72%] [G loss: 0.966417]\n",
      "epoch:31 step:29579 [D loss: 0.681384, acc.: 53.91%] [G loss: 0.937941]\n",
      "epoch:31 step:29580 [D loss: 0.666774, acc.: 56.25%] [G loss: 0.977222]\n",
      "epoch:31 step:29581 [D loss: 0.685647, acc.: 57.81%] [G loss: 0.894819]\n",
      "epoch:31 step:29582 [D loss: 0.614869, acc.: 71.88%] [G loss: 0.927306]\n",
      "epoch:31 step:29583 [D loss: 0.666275, acc.: 57.81%] [G loss: 0.956937]\n",
      "epoch:31 step:29584 [D loss: 0.665998, acc.: 60.94%] [G loss: 0.836988]\n",
      "epoch:31 step:29585 [D loss: 0.664770, acc.: 62.50%] [G loss: 0.865921]\n",
      "epoch:31 step:29586 [D loss: 0.670570, acc.: 55.47%] [G loss: 0.899194]\n",
      "epoch:31 step:29587 [D loss: 0.657497, acc.: 63.28%] [G loss: 0.868565]\n",
      "epoch:31 step:29588 [D loss: 0.631844, acc.: 62.50%] [G loss: 0.892636]\n",
      "epoch:31 step:29589 [D loss: 0.638269, acc.: 63.28%] [G loss: 0.985184]\n",
      "epoch:31 step:29590 [D loss: 0.626960, acc.: 64.84%] [G loss: 0.862023]\n",
      "epoch:31 step:29591 [D loss: 0.612647, acc.: 67.19%] [G loss: 0.899613]\n",
      "epoch:31 step:29592 [D loss: 0.632743, acc.: 63.28%] [G loss: 0.872211]\n",
      "epoch:31 step:29593 [D loss: 0.643986, acc.: 69.53%] [G loss: 0.882887]\n",
      "epoch:31 step:29594 [D loss: 0.644338, acc.: 60.94%] [G loss: 0.923172]\n",
      "epoch:31 step:29595 [D loss: 0.664842, acc.: 55.47%] [G loss: 0.812217]\n",
      "epoch:31 step:29596 [D loss: 0.637963, acc.: 63.28%] [G loss: 0.902085]\n",
      "epoch:31 step:29597 [D loss: 0.635154, acc.: 59.38%] [G loss: 0.909265]\n",
      "epoch:31 step:29598 [D loss: 0.631884, acc.: 61.72%] [G loss: 0.904259]\n",
      "epoch:31 step:29599 [D loss: 0.625051, acc.: 61.72%] [G loss: 0.901798]\n",
      "epoch:31 step:29600 [D loss: 0.673272, acc.: 59.38%] [G loss: 0.887699]\n",
      "##############\n",
      "[3.00701833 2.44348292 2.20121443 3.50451867 1.24044368 8.14053749\n",
      " 2.83689453 3.23567957 4.27936102 8.14868929]\n",
      "##########\n",
      "epoch:31 step:29601 [D loss: 0.621584, acc.: 67.19%] [G loss: 0.923308]\n",
      "epoch:31 step:29602 [D loss: 0.680590, acc.: 53.12%] [G loss: 0.938138]\n",
      "epoch:31 step:29603 [D loss: 0.663074, acc.: 53.91%] [G loss: 0.898288]\n",
      "epoch:31 step:29604 [D loss: 0.615613, acc.: 68.75%] [G loss: 0.886461]\n",
      "epoch:31 step:29605 [D loss: 0.670334, acc.: 62.50%] [G loss: 0.844970]\n",
      "epoch:31 step:29606 [D loss: 0.667341, acc.: 55.47%] [G loss: 0.793146]\n",
      "epoch:31 step:29607 [D loss: 0.670431, acc.: 60.94%] [G loss: 0.891904]\n",
      "epoch:31 step:29608 [D loss: 0.650989, acc.: 66.41%] [G loss: 0.898589]\n",
      "epoch:31 step:29609 [D loss: 0.650294, acc.: 59.38%] [G loss: 0.820807]\n",
      "epoch:31 step:29610 [D loss: 0.622744, acc.: 69.53%] [G loss: 0.862849]\n",
      "epoch:31 step:29611 [D loss: 0.665019, acc.: 56.25%] [G loss: 0.916397]\n",
      "epoch:31 step:29612 [D loss: 0.605921, acc.: 72.66%] [G loss: 0.927077]\n",
      "epoch:31 step:29613 [D loss: 0.617812, acc.: 62.50%] [G loss: 0.937715]\n",
      "epoch:31 step:29614 [D loss: 0.630280, acc.: 64.06%] [G loss: 0.826946]\n",
      "epoch:31 step:29615 [D loss: 0.690976, acc.: 57.03%] [G loss: 0.928954]\n",
      "epoch:31 step:29616 [D loss: 0.601214, acc.: 69.53%] [G loss: 0.986936]\n",
      "epoch:31 step:29617 [D loss: 0.681654, acc.: 54.69%] [G loss: 0.931145]\n",
      "epoch:31 step:29618 [D loss: 0.642536, acc.: 62.50%] [G loss: 0.993747]\n",
      "epoch:31 step:29619 [D loss: 0.653666, acc.: 63.28%] [G loss: 0.930325]\n",
      "epoch:31 step:29620 [D loss: 0.645183, acc.: 59.38%] [G loss: 0.940413]\n",
      "epoch:31 step:29621 [D loss: 0.677489, acc.: 47.66%] [G loss: 0.918825]\n",
      "epoch:31 step:29622 [D loss: 0.712044, acc.: 48.44%] [G loss: 0.907152]\n",
      "epoch:31 step:29623 [D loss: 0.638877, acc.: 64.06%] [G loss: 0.936617]\n",
      "epoch:31 step:29624 [D loss: 0.595600, acc.: 66.41%] [G loss: 0.888852]\n",
      "epoch:31 step:29625 [D loss: 0.659241, acc.: 63.28%] [G loss: 0.857775]\n",
      "epoch:31 step:29626 [D loss: 0.665267, acc.: 67.19%] [G loss: 0.907789]\n",
      "epoch:31 step:29627 [D loss: 0.666614, acc.: 61.72%] [G loss: 0.900967]\n",
      "epoch:31 step:29628 [D loss: 0.642510, acc.: 60.16%] [G loss: 0.929525]\n",
      "epoch:31 step:29629 [D loss: 0.630886, acc.: 60.94%] [G loss: 0.889182]\n",
      "epoch:31 step:29630 [D loss: 0.694258, acc.: 55.47%] [G loss: 0.960499]\n",
      "epoch:31 step:29631 [D loss: 0.657071, acc.: 64.06%] [G loss: 0.967519]\n",
      "epoch:31 step:29632 [D loss: 0.634519, acc.: 63.28%] [G loss: 0.893369]\n",
      "epoch:31 step:29633 [D loss: 0.658174, acc.: 60.94%] [G loss: 0.905891]\n",
      "epoch:31 step:29634 [D loss: 0.644949, acc.: 64.84%] [G loss: 0.881634]\n",
      "epoch:31 step:29635 [D loss: 0.678621, acc.: 59.38%] [G loss: 0.926702]\n",
      "epoch:31 step:29636 [D loss: 0.651987, acc.: 61.72%] [G loss: 0.894924]\n",
      "epoch:31 step:29637 [D loss: 0.679714, acc.: 63.28%] [G loss: 0.899391]\n",
      "epoch:31 step:29638 [D loss: 0.669134, acc.: 60.94%] [G loss: 0.906844]\n",
      "epoch:31 step:29639 [D loss: 0.668425, acc.: 57.81%] [G loss: 0.932861]\n",
      "epoch:31 step:29640 [D loss: 0.708128, acc.: 49.22%] [G loss: 0.867888]\n",
      "epoch:31 step:29641 [D loss: 0.664684, acc.: 59.38%] [G loss: 0.915651]\n",
      "epoch:31 step:29642 [D loss: 0.679929, acc.: 60.94%] [G loss: 0.987204]\n",
      "epoch:31 step:29643 [D loss: 0.662781, acc.: 57.03%] [G loss: 0.919357]\n",
      "epoch:31 step:29644 [D loss: 0.651711, acc.: 57.03%] [G loss: 0.903408]\n",
      "epoch:31 step:29645 [D loss: 0.643602, acc.: 60.94%] [G loss: 0.918178]\n",
      "epoch:31 step:29646 [D loss: 0.667166, acc.: 60.16%] [G loss: 0.918894]\n",
      "epoch:31 step:29647 [D loss: 0.667378, acc.: 56.25%] [G loss: 0.868596]\n",
      "epoch:31 step:29648 [D loss: 0.678508, acc.: 54.69%] [G loss: 0.861041]\n",
      "epoch:31 step:29649 [D loss: 0.666910, acc.: 64.84%] [G loss: 0.885207]\n",
      "epoch:31 step:29650 [D loss: 0.675701, acc.: 57.03%] [G loss: 0.991359]\n",
      "epoch:31 step:29651 [D loss: 0.724661, acc.: 53.12%] [G loss: 0.908760]\n",
      "epoch:31 step:29652 [D loss: 0.667822, acc.: 59.38%] [G loss: 0.902615]\n",
      "epoch:31 step:29653 [D loss: 0.630151, acc.: 65.62%] [G loss: 0.921781]\n",
      "epoch:31 step:29654 [D loss: 0.677436, acc.: 53.12%] [G loss: 0.872491]\n",
      "epoch:31 step:29655 [D loss: 0.665219, acc.: 58.59%] [G loss: 0.884732]\n",
      "epoch:31 step:29656 [D loss: 0.656969, acc.: 67.19%] [G loss: 0.951058]\n",
      "epoch:31 step:29657 [D loss: 0.619931, acc.: 72.66%] [G loss: 0.896425]\n",
      "epoch:31 step:29658 [D loss: 0.651543, acc.: 61.72%] [G loss: 0.907824]\n",
      "epoch:31 step:29659 [D loss: 0.692515, acc.: 53.12%] [G loss: 0.850602]\n",
      "epoch:31 step:29660 [D loss: 0.659743, acc.: 58.59%] [G loss: 0.897319]\n",
      "epoch:31 step:29661 [D loss: 0.638468, acc.: 61.72%] [G loss: 0.905907]\n",
      "epoch:31 step:29662 [D loss: 0.649357, acc.: 57.81%] [G loss: 0.913719]\n",
      "epoch:31 step:29663 [D loss: 0.645746, acc.: 66.41%] [G loss: 0.891550]\n",
      "epoch:31 step:29664 [D loss: 0.639444, acc.: 66.41%] [G loss: 0.895020]\n",
      "epoch:31 step:29665 [D loss: 0.660408, acc.: 56.25%] [G loss: 0.899984]\n",
      "epoch:31 step:29666 [D loss: 0.673497, acc.: 56.25%] [G loss: 0.906722]\n",
      "epoch:31 step:29667 [D loss: 0.631569, acc.: 64.84%] [G loss: 0.857675]\n",
      "epoch:31 step:29668 [D loss: 0.680987, acc.: 57.03%] [G loss: 0.911530]\n",
      "epoch:31 step:29669 [D loss: 0.661940, acc.: 58.59%] [G loss: 0.877392]\n",
      "epoch:31 step:29670 [D loss: 0.653466, acc.: 60.16%] [G loss: 0.904861]\n",
      "epoch:31 step:29671 [D loss: 0.663821, acc.: 60.16%] [G loss: 0.909637]\n",
      "epoch:31 step:29672 [D loss: 0.652867, acc.: 64.84%] [G loss: 0.910960]\n",
      "epoch:31 step:29673 [D loss: 0.655828, acc.: 56.25%] [G loss: 0.920499]\n",
      "epoch:31 step:29674 [D loss: 0.631590, acc.: 64.06%] [G loss: 0.939974]\n",
      "epoch:31 step:29675 [D loss: 0.666993, acc.: 59.38%] [G loss: 0.870052]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:29676 [D loss: 0.625921, acc.: 64.06%] [G loss: 0.859712]\n",
      "epoch:31 step:29677 [D loss: 0.706432, acc.: 53.12%] [G loss: 0.873486]\n",
      "epoch:31 step:29678 [D loss: 0.586852, acc.: 67.97%] [G loss: 0.877877]\n",
      "epoch:31 step:29679 [D loss: 0.645408, acc.: 63.28%] [G loss: 0.911781]\n",
      "epoch:31 step:29680 [D loss: 0.573208, acc.: 76.56%] [G loss: 0.866131]\n",
      "epoch:31 step:29681 [D loss: 0.668618, acc.: 59.38%] [G loss: 0.889131]\n",
      "epoch:31 step:29682 [D loss: 0.664697, acc.: 57.81%] [G loss: 0.933521]\n",
      "epoch:31 step:29683 [D loss: 0.603354, acc.: 68.75%] [G loss: 0.905676]\n",
      "epoch:31 step:29684 [D loss: 0.636257, acc.: 63.28%] [G loss: 0.990509]\n",
      "epoch:31 step:29685 [D loss: 0.595654, acc.: 67.19%] [G loss: 0.911309]\n",
      "epoch:31 step:29686 [D loss: 0.671007, acc.: 57.03%] [G loss: 0.859868]\n",
      "epoch:31 step:29687 [D loss: 0.663594, acc.: 60.94%] [G loss: 0.846152]\n",
      "epoch:31 step:29688 [D loss: 0.658988, acc.: 60.16%] [G loss: 0.927905]\n",
      "epoch:31 step:29689 [D loss: 0.663477, acc.: 67.19%] [G loss: 0.926530]\n",
      "epoch:31 step:29690 [D loss: 0.701667, acc.: 53.12%] [G loss: 0.903821]\n",
      "epoch:31 step:29691 [D loss: 0.661193, acc.: 60.94%] [G loss: 0.927915]\n",
      "epoch:31 step:29692 [D loss: 0.650183, acc.: 60.16%] [G loss: 0.895607]\n",
      "epoch:31 step:29693 [D loss: 0.679456, acc.: 54.69%] [G loss: 0.915741]\n",
      "epoch:31 step:29694 [D loss: 0.699813, acc.: 52.34%] [G loss: 0.939291]\n",
      "epoch:31 step:29695 [D loss: 0.639146, acc.: 64.06%] [G loss: 0.870743]\n",
      "epoch:31 step:29696 [D loss: 0.667697, acc.: 57.81%] [G loss: 0.900169]\n",
      "epoch:31 step:29697 [D loss: 0.639857, acc.: 67.19%] [G loss: 0.934561]\n",
      "epoch:31 step:29698 [D loss: 0.677421, acc.: 54.69%] [G loss: 0.983035]\n",
      "epoch:31 step:29699 [D loss: 0.647681, acc.: 63.28%] [G loss: 0.964573]\n",
      "epoch:31 step:29700 [D loss: 0.647951, acc.: 58.59%] [G loss: 0.895496]\n",
      "epoch:31 step:29701 [D loss: 0.601163, acc.: 65.62%] [G loss: 0.852344]\n",
      "epoch:31 step:29702 [D loss: 0.700215, acc.: 53.12%] [G loss: 0.979870]\n",
      "epoch:31 step:29703 [D loss: 0.617884, acc.: 62.50%] [G loss: 0.924758]\n",
      "epoch:31 step:29704 [D loss: 0.663595, acc.: 52.34%] [G loss: 0.962014]\n",
      "epoch:31 step:29705 [D loss: 0.678722, acc.: 59.38%] [G loss: 0.905521]\n",
      "epoch:31 step:29706 [D loss: 0.679000, acc.: 60.16%] [G loss: 0.933282]\n",
      "epoch:31 step:29707 [D loss: 0.669795, acc.: 56.25%] [G loss: 0.890530]\n",
      "epoch:31 step:29708 [D loss: 0.637588, acc.: 66.41%] [G loss: 0.882591]\n",
      "epoch:31 step:29709 [D loss: 0.676094, acc.: 60.16%] [G loss: 0.854481]\n",
      "epoch:31 step:29710 [D loss: 0.630886, acc.: 68.75%] [G loss: 0.910538]\n",
      "epoch:31 step:29711 [D loss: 0.638216, acc.: 64.06%] [G loss: 0.861828]\n",
      "epoch:31 step:29712 [D loss: 0.671363, acc.: 58.59%] [G loss: 0.929829]\n",
      "epoch:31 step:29713 [D loss: 0.651219, acc.: 64.84%] [G loss: 0.917754]\n",
      "epoch:31 step:29714 [D loss: 0.641206, acc.: 59.38%] [G loss: 0.955333]\n",
      "epoch:31 step:29715 [D loss: 0.664220, acc.: 59.38%] [G loss: 0.932997]\n",
      "epoch:31 step:29716 [D loss: 0.628423, acc.: 61.72%] [G loss: 0.899909]\n",
      "epoch:31 step:29717 [D loss: 0.629741, acc.: 62.50%] [G loss: 0.915751]\n",
      "epoch:31 step:29718 [D loss: 0.683094, acc.: 55.47%] [G loss: 0.895448]\n",
      "epoch:31 step:29719 [D loss: 0.679406, acc.: 56.25%] [G loss: 0.925250]\n",
      "epoch:31 step:29720 [D loss: 0.625654, acc.: 66.41%] [G loss: 0.934823]\n",
      "epoch:31 step:29721 [D loss: 0.623959, acc.: 67.19%] [G loss: 0.940027]\n",
      "epoch:31 step:29722 [D loss: 0.654540, acc.: 62.50%] [G loss: 0.899703]\n",
      "epoch:31 step:29723 [D loss: 0.668026, acc.: 60.94%] [G loss: 0.898722]\n",
      "epoch:31 step:29724 [D loss: 0.663587, acc.: 54.69%] [G loss: 0.873028]\n",
      "epoch:31 step:29725 [D loss: 0.662918, acc.: 57.03%] [G loss: 0.840492]\n",
      "epoch:31 step:29726 [D loss: 0.674034, acc.: 59.38%] [G loss: 0.927150]\n",
      "epoch:31 step:29727 [D loss: 0.640975, acc.: 60.16%] [G loss: 0.927923]\n",
      "epoch:31 step:29728 [D loss: 0.635665, acc.: 64.06%] [G loss: 0.855372]\n",
      "epoch:31 step:29729 [D loss: 0.644895, acc.: 64.06%] [G loss: 0.902855]\n",
      "epoch:31 step:29730 [D loss: 0.672999, acc.: 56.25%] [G loss: 0.856577]\n",
      "epoch:31 step:29731 [D loss: 0.645473, acc.: 60.94%] [G loss: 0.967733]\n",
      "epoch:31 step:29732 [D loss: 0.683407, acc.: 53.91%] [G loss: 0.942277]\n",
      "epoch:31 step:29733 [D loss: 0.653280, acc.: 57.81%] [G loss: 0.860218]\n",
      "epoch:31 step:29734 [D loss: 0.641515, acc.: 65.62%] [G loss: 0.913312]\n",
      "epoch:31 step:29735 [D loss: 0.638514, acc.: 64.06%] [G loss: 0.950801]\n",
      "epoch:31 step:29736 [D loss: 0.657964, acc.: 60.94%] [G loss: 0.937821]\n",
      "epoch:31 step:29737 [D loss: 0.614041, acc.: 63.28%] [G loss: 0.901843]\n",
      "epoch:31 step:29738 [D loss: 0.694110, acc.: 51.56%] [G loss: 0.958962]\n",
      "epoch:31 step:29739 [D loss: 0.644851, acc.: 66.41%] [G loss: 0.921088]\n",
      "epoch:31 step:29740 [D loss: 0.666498, acc.: 60.94%] [G loss: 0.889906]\n",
      "epoch:31 step:29741 [D loss: 0.614714, acc.: 72.66%] [G loss: 1.037172]\n",
      "epoch:31 step:29742 [D loss: 0.600690, acc.: 66.41%] [G loss: 1.019192]\n",
      "epoch:31 step:29743 [D loss: 0.652566, acc.: 61.72%] [G loss: 0.938540]\n",
      "epoch:31 step:29744 [D loss: 0.678378, acc.: 56.25%] [G loss: 0.914692]\n",
      "epoch:31 step:29745 [D loss: 0.612050, acc.: 64.84%] [G loss: 0.866381]\n",
      "epoch:31 step:29746 [D loss: 0.631655, acc.: 67.19%] [G loss: 0.844431]\n",
      "epoch:31 step:29747 [D loss: 0.641945, acc.: 60.94%] [G loss: 0.870654]\n",
      "epoch:31 step:29748 [D loss: 0.651876, acc.: 63.28%] [G loss: 0.860851]\n",
      "epoch:31 step:29749 [D loss: 0.676807, acc.: 57.81%] [G loss: 0.889070]\n",
      "epoch:31 step:29750 [D loss: 0.714682, acc.: 50.00%] [G loss: 0.877282]\n",
      "epoch:31 step:29751 [D loss: 0.641467, acc.: 65.62%] [G loss: 0.867715]\n",
      "epoch:31 step:29752 [D loss: 0.628626, acc.: 63.28%] [G loss: 0.878280]\n",
      "epoch:31 step:29753 [D loss: 0.698763, acc.: 56.25%] [G loss: 0.813695]\n",
      "epoch:31 step:29754 [D loss: 0.636110, acc.: 63.28%] [G loss: 0.856677]\n",
      "epoch:31 step:29755 [D loss: 0.649855, acc.: 56.25%] [G loss: 0.990717]\n",
      "epoch:31 step:29756 [D loss: 0.710493, acc.: 50.00%] [G loss: 0.957134]\n",
      "epoch:31 step:29757 [D loss: 0.583200, acc.: 70.31%] [G loss: 0.968592]\n",
      "epoch:31 step:29758 [D loss: 0.638640, acc.: 62.50%] [G loss: 0.967755]\n",
      "epoch:31 step:29759 [D loss: 0.660291, acc.: 63.28%] [G loss: 0.917071]\n",
      "epoch:31 step:29760 [D loss: 0.659465, acc.: 58.59%] [G loss: 0.931991]\n",
      "epoch:31 step:29761 [D loss: 0.627637, acc.: 64.84%] [G loss: 0.912726]\n",
      "epoch:31 step:29762 [D loss: 0.664172, acc.: 61.72%] [G loss: 0.864437]\n",
      "epoch:31 step:29763 [D loss: 0.647110, acc.: 60.94%] [G loss: 0.853360]\n",
      "epoch:31 step:29764 [D loss: 0.635354, acc.: 60.16%] [G loss: 0.852159]\n",
      "epoch:31 step:29765 [D loss: 0.619226, acc.: 67.19%] [G loss: 0.926866]\n",
      "epoch:31 step:29766 [D loss: 0.683725, acc.: 55.47%] [G loss: 0.872942]\n",
      "epoch:31 step:29767 [D loss: 0.680276, acc.: 64.06%] [G loss: 0.956702]\n",
      "epoch:31 step:29768 [D loss: 0.652258, acc.: 64.84%] [G loss: 0.950834]\n",
      "epoch:31 step:29769 [D loss: 0.600303, acc.: 70.31%] [G loss: 0.919388]\n",
      "epoch:31 step:29770 [D loss: 0.684162, acc.: 52.34%] [G loss: 0.943457]\n",
      "epoch:31 step:29771 [D loss: 0.651328, acc.: 60.94%] [G loss: 0.856224]\n",
      "epoch:31 step:29772 [D loss: 0.625388, acc.: 67.97%] [G loss: 0.931294]\n",
      "epoch:31 step:29773 [D loss: 0.673467, acc.: 59.38%] [G loss: 0.907451]\n",
      "epoch:31 step:29774 [D loss: 0.618745, acc.: 67.19%] [G loss: 0.953474]\n",
      "epoch:31 step:29775 [D loss: 0.684424, acc.: 55.47%] [G loss: 0.906031]\n",
      "epoch:31 step:29776 [D loss: 0.598609, acc.: 69.53%] [G loss: 0.873912]\n",
      "epoch:31 step:29777 [D loss: 0.663333, acc.: 60.16%] [G loss: 0.922546]\n",
      "epoch:31 step:29778 [D loss: 0.634477, acc.: 61.72%] [G loss: 0.892590]\n",
      "epoch:31 step:29779 [D loss: 0.645054, acc.: 59.38%] [G loss: 0.863751]\n",
      "epoch:31 step:29780 [D loss: 0.649906, acc.: 58.59%] [G loss: 0.927284]\n",
      "epoch:31 step:29781 [D loss: 0.641269, acc.: 61.72%] [G loss: 0.986189]\n",
      "epoch:31 step:29782 [D loss: 0.641151, acc.: 64.84%] [G loss: 0.988973]\n",
      "epoch:31 step:29783 [D loss: 0.642478, acc.: 59.38%] [G loss: 0.948248]\n",
      "epoch:31 step:29784 [D loss: 0.675869, acc.: 58.59%] [G loss: 0.961448]\n",
      "epoch:31 step:29785 [D loss: 0.684016, acc.: 54.69%] [G loss: 0.946235]\n",
      "epoch:31 step:29786 [D loss: 0.665643, acc.: 63.28%] [G loss: 0.939919]\n",
      "epoch:31 step:29787 [D loss: 0.666043, acc.: 61.72%] [G loss: 0.906261]\n",
      "epoch:31 step:29788 [D loss: 0.660173, acc.: 61.72%] [G loss: 0.997117]\n",
      "epoch:31 step:29789 [D loss: 0.637529, acc.: 63.28%] [G loss: 0.927930]\n",
      "epoch:31 step:29790 [D loss: 0.692235, acc.: 51.56%] [G loss: 0.893443]\n",
      "epoch:31 step:29791 [D loss: 0.654303, acc.: 63.28%] [G loss: 0.912898]\n",
      "epoch:31 step:29792 [D loss: 0.648488, acc.: 61.72%] [G loss: 0.916639]\n",
      "epoch:31 step:29793 [D loss: 0.612300, acc.: 69.53%] [G loss: 0.906219]\n",
      "epoch:31 step:29794 [D loss: 0.622742, acc.: 65.62%] [G loss: 0.891828]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:29795 [D loss: 0.635112, acc.: 63.28%] [G loss: 0.856547]\n",
      "epoch:31 step:29796 [D loss: 0.619532, acc.: 64.06%] [G loss: 0.903462]\n",
      "epoch:31 step:29797 [D loss: 0.620304, acc.: 65.62%] [G loss: 0.916503]\n",
      "epoch:31 step:29798 [D loss: 0.642015, acc.: 57.81%] [G loss: 0.948416]\n",
      "epoch:31 step:29799 [D loss: 0.681577, acc.: 60.16%] [G loss: 0.953211]\n",
      "epoch:31 step:29800 [D loss: 0.636687, acc.: 66.41%] [G loss: 1.036966]\n",
      "##############\n",
      "[2.89896239 2.47252607 2.2823046  3.5426762  1.47030316 9.27426719\n",
      " 2.6675854  3.79711803 4.27730332 7.14868929]\n",
      "##########\n",
      "epoch:31 step:29801 [D loss: 0.624193, acc.: 65.62%] [G loss: 0.969219]\n",
      "epoch:31 step:29802 [D loss: 0.654256, acc.: 64.06%] [G loss: 0.886381]\n",
      "epoch:31 step:29803 [D loss: 0.622480, acc.: 66.41%] [G loss: 0.891043]\n",
      "epoch:31 step:29804 [D loss: 0.679971, acc.: 60.94%] [G loss: 0.876575]\n",
      "epoch:31 step:29805 [D loss: 0.651836, acc.: 57.81%] [G loss: 0.875007]\n",
      "epoch:31 step:29806 [D loss: 0.655399, acc.: 67.19%] [G loss: 0.868030]\n",
      "epoch:31 step:29807 [D loss: 0.692254, acc.: 53.12%] [G loss: 0.968113]\n",
      "epoch:31 step:29808 [D loss: 0.678372, acc.: 57.03%] [G loss: 0.947118]\n",
      "epoch:31 step:29809 [D loss: 0.692781, acc.: 53.12%] [G loss: 0.923008]\n",
      "epoch:31 step:29810 [D loss: 0.649374, acc.: 64.06%] [G loss: 0.926379]\n",
      "epoch:31 step:29811 [D loss: 0.618116, acc.: 66.41%] [G loss: 0.919415]\n",
      "epoch:31 step:29812 [D loss: 0.670986, acc.: 63.28%] [G loss: 0.876649]\n",
      "epoch:31 step:29813 [D loss: 0.651811, acc.: 61.72%] [G loss: 0.942686]\n",
      "epoch:31 step:29814 [D loss: 0.676668, acc.: 57.03%] [G loss: 0.902605]\n",
      "epoch:31 step:29815 [D loss: 0.684252, acc.: 57.03%] [G loss: 0.987739]\n",
      "epoch:31 step:29816 [D loss: 0.604490, acc.: 67.19%] [G loss: 1.000204]\n",
      "epoch:31 step:29817 [D loss: 0.674471, acc.: 54.69%] [G loss: 0.870694]\n",
      "epoch:31 step:29818 [D loss: 0.652566, acc.: 62.50%] [G loss: 0.911579]\n",
      "epoch:31 step:29819 [D loss: 0.625539, acc.: 65.62%] [G loss: 0.900608]\n",
      "epoch:31 step:29820 [D loss: 0.679811, acc.: 57.81%] [G loss: 0.913984]\n",
      "epoch:31 step:29821 [D loss: 0.631003, acc.: 64.84%] [G loss: 0.984978]\n",
      "epoch:31 step:29822 [D loss: 0.638841, acc.: 60.94%] [G loss: 0.966202]\n",
      "epoch:31 step:29823 [D loss: 0.654739, acc.: 60.16%] [G loss: 0.841208]\n",
      "epoch:31 step:29824 [D loss: 0.659458, acc.: 53.12%] [G loss: 0.883344]\n",
      "epoch:31 step:29825 [D loss: 0.642291, acc.: 58.59%] [G loss: 0.952529]\n",
      "epoch:31 step:29826 [D loss: 0.625747, acc.: 68.75%] [G loss: 0.919388]\n",
      "epoch:31 step:29827 [D loss: 0.658296, acc.: 54.69%] [G loss: 0.952285]\n",
      "epoch:31 step:29828 [D loss: 0.667382, acc.: 64.84%] [G loss: 1.021737]\n",
      "epoch:31 step:29829 [D loss: 0.641289, acc.: 60.94%] [G loss: 0.960213]\n",
      "epoch:31 step:29830 [D loss: 0.645254, acc.: 60.94%] [G loss: 0.957158]\n",
      "epoch:31 step:29831 [D loss: 0.654187, acc.: 59.38%] [G loss: 0.987274]\n",
      "epoch:31 step:29832 [D loss: 0.679076, acc.: 57.81%] [G loss: 0.936070]\n",
      "epoch:31 step:29833 [D loss: 0.677055, acc.: 57.81%] [G loss: 0.912248]\n",
      "epoch:31 step:29834 [D loss: 0.672443, acc.: 53.91%] [G loss: 0.924355]\n",
      "epoch:31 step:29835 [D loss: 0.611058, acc.: 67.97%] [G loss: 0.936360]\n",
      "epoch:31 step:29836 [D loss: 0.646084, acc.: 62.50%] [G loss: 0.904990]\n",
      "epoch:31 step:29837 [D loss: 0.647581, acc.: 61.72%] [G loss: 0.885785]\n",
      "epoch:31 step:29838 [D loss: 0.619321, acc.: 65.62%] [G loss: 0.934169]\n",
      "epoch:31 step:29839 [D loss: 0.620903, acc.: 67.97%] [G loss: 0.858452]\n",
      "epoch:31 step:29840 [D loss: 0.662086, acc.: 58.59%] [G loss: 0.908172]\n",
      "epoch:31 step:29841 [D loss: 0.634319, acc.: 69.53%] [G loss: 0.891500]\n",
      "epoch:31 step:29842 [D loss: 0.604551, acc.: 69.53%] [G loss: 0.959483]\n",
      "epoch:31 step:29843 [D loss: 0.638976, acc.: 60.94%] [G loss: 0.926708]\n",
      "epoch:31 step:29844 [D loss: 0.668747, acc.: 57.81%] [G loss: 0.970493]\n",
      "epoch:31 step:29845 [D loss: 0.645386, acc.: 64.84%] [G loss: 0.886138]\n",
      "epoch:31 step:29846 [D loss: 0.642312, acc.: 60.94%] [G loss: 0.930412]\n",
      "epoch:31 step:29847 [D loss: 0.651241, acc.: 63.28%] [G loss: 0.917906]\n",
      "epoch:31 step:29848 [D loss: 0.642312, acc.: 60.16%] [G loss: 0.980583]\n",
      "epoch:31 step:29849 [D loss: 0.677948, acc.: 58.59%] [G loss: 0.890073]\n",
      "epoch:31 step:29850 [D loss: 0.621895, acc.: 69.53%] [G loss: 0.921189]\n",
      "epoch:31 step:29851 [D loss: 0.637607, acc.: 65.62%] [G loss: 0.914876]\n",
      "epoch:31 step:29852 [D loss: 0.626180, acc.: 61.72%] [G loss: 0.885503]\n",
      "epoch:31 step:29853 [D loss: 0.633089, acc.: 67.97%] [G loss: 0.858777]\n",
      "epoch:31 step:29854 [D loss: 0.661395, acc.: 60.16%] [G loss: 0.844950]\n",
      "epoch:31 step:29855 [D loss: 0.640575, acc.: 61.72%] [G loss: 0.880994]\n",
      "epoch:31 step:29856 [D loss: 0.639403, acc.: 66.41%] [G loss: 0.874846]\n",
      "epoch:31 step:29857 [D loss: 0.654348, acc.: 59.38%] [G loss: 0.950065]\n",
      "epoch:31 step:29858 [D loss: 0.694542, acc.: 53.91%] [G loss: 0.957016]\n",
      "epoch:31 step:29859 [D loss: 0.659614, acc.: 56.25%] [G loss: 0.969378]\n",
      "epoch:31 step:29860 [D loss: 0.682213, acc.: 62.50%] [G loss: 1.058841]\n",
      "epoch:31 step:29861 [D loss: 0.662106, acc.: 63.28%] [G loss: 0.952243]\n",
      "epoch:31 step:29862 [D loss: 0.653654, acc.: 59.38%] [G loss: 0.990582]\n",
      "epoch:31 step:29863 [D loss: 0.673735, acc.: 57.81%] [G loss: 0.962675]\n",
      "epoch:31 step:29864 [D loss: 0.689130, acc.: 55.47%] [G loss: 0.971790]\n",
      "epoch:31 step:29865 [D loss: 0.670957, acc.: 57.81%] [G loss: 0.941785]\n",
      "epoch:31 step:29866 [D loss: 0.686714, acc.: 48.44%] [G loss: 0.879500]\n",
      "epoch:31 step:29867 [D loss: 0.680864, acc.: 62.50%] [G loss: 0.962735]\n",
      "epoch:31 step:29868 [D loss: 0.643585, acc.: 57.81%] [G loss: 0.893387]\n",
      "epoch:31 step:29869 [D loss: 0.604409, acc.: 72.66%] [G loss: 0.926710]\n",
      "epoch:31 step:29870 [D loss: 0.686123, acc.: 56.25%] [G loss: 0.909934]\n",
      "epoch:31 step:29871 [D loss: 0.646359, acc.: 60.16%] [G loss: 0.899851]\n",
      "epoch:31 step:29872 [D loss: 0.661199, acc.: 61.72%] [G loss: 0.874338]\n",
      "epoch:31 step:29873 [D loss: 0.632692, acc.: 64.06%] [G loss: 0.928807]\n",
      "epoch:31 step:29874 [D loss: 0.621922, acc.: 66.41%] [G loss: 0.974840]\n",
      "epoch:31 step:29875 [D loss: 0.680479, acc.: 56.25%] [G loss: 0.967173]\n",
      "epoch:31 step:29876 [D loss: 0.656546, acc.: 65.62%] [G loss: 0.925852]\n",
      "epoch:31 step:29877 [D loss: 0.626693, acc.: 66.41%] [G loss: 0.958493]\n",
      "epoch:31 step:29878 [D loss: 0.655441, acc.: 61.72%] [G loss: 0.850280]\n",
      "epoch:31 step:29879 [D loss: 0.699341, acc.: 50.78%] [G loss: 0.890595]\n",
      "epoch:31 step:29880 [D loss: 0.646747, acc.: 63.28%] [G loss: 0.930254]\n",
      "epoch:31 step:29881 [D loss: 0.668348, acc.: 58.59%] [G loss: 0.891668]\n",
      "epoch:31 step:29882 [D loss: 0.663217, acc.: 61.72%] [G loss: 0.937328]\n",
      "epoch:31 step:29883 [D loss: 0.663525, acc.: 55.47%] [G loss: 0.890489]\n",
      "epoch:31 step:29884 [D loss: 0.635687, acc.: 64.84%] [G loss: 0.944001]\n",
      "epoch:31 step:29885 [D loss: 0.671926, acc.: 62.50%] [G loss: 0.928150]\n",
      "epoch:31 step:29886 [D loss: 0.656167, acc.: 57.81%] [G loss: 0.840802]\n",
      "epoch:31 step:29887 [D loss: 0.657396, acc.: 61.72%] [G loss: 0.927577]\n",
      "epoch:31 step:29888 [D loss: 0.678567, acc.: 58.59%] [G loss: 0.905472]\n",
      "epoch:31 step:29889 [D loss: 0.658293, acc.: 61.72%] [G loss: 0.859969]\n",
      "epoch:31 step:29890 [D loss: 0.685302, acc.: 53.91%] [G loss: 0.837619]\n",
      "epoch:31 step:29891 [D loss: 0.669417, acc.: 59.38%] [G loss: 0.860378]\n",
      "epoch:31 step:29892 [D loss: 0.689567, acc.: 51.56%] [G loss: 0.915340]\n",
      "epoch:31 step:29893 [D loss: 0.666813, acc.: 55.47%] [G loss: 0.891830]\n",
      "epoch:31 step:29894 [D loss: 0.679254, acc.: 53.91%] [G loss: 0.858038]\n",
      "epoch:31 step:29895 [D loss: 0.681462, acc.: 49.22%] [G loss: 0.911130]\n",
      "epoch:31 step:29896 [D loss: 0.631881, acc.: 64.84%] [G loss: 0.918531]\n",
      "epoch:31 step:29897 [D loss: 0.638809, acc.: 67.19%] [G loss: 0.935777]\n",
      "epoch:31 step:29898 [D loss: 0.646250, acc.: 58.59%] [G loss: 0.887512]\n",
      "epoch:31 step:29899 [D loss: 0.629817, acc.: 65.62%] [G loss: 0.898372]\n",
      "epoch:31 step:29900 [D loss: 0.646245, acc.: 57.81%] [G loss: 0.922949]\n",
      "epoch:31 step:29901 [D loss: 0.648564, acc.: 60.94%] [G loss: 0.830399]\n",
      "epoch:31 step:29902 [D loss: 0.680035, acc.: 58.59%] [G loss: 0.877177]\n",
      "epoch:31 step:29903 [D loss: 0.609129, acc.: 68.75%] [G loss: 0.925785]\n",
      "epoch:31 step:29904 [D loss: 0.678230, acc.: 56.25%] [G loss: 0.949294]\n",
      "epoch:31 step:29905 [D loss: 0.648516, acc.: 60.94%] [G loss: 0.865048]\n",
      "epoch:31 step:29906 [D loss: 0.647680, acc.: 67.19%] [G loss: 0.928090]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:31 step:29907 [D loss: 0.638588, acc.: 60.94%] [G loss: 0.902251]\n",
      "epoch:31 step:29908 [D loss: 0.618971, acc.: 65.62%] [G loss: 0.911936]\n",
      "epoch:31 step:29909 [D loss: 0.646077, acc.: 64.06%] [G loss: 0.954409]\n",
      "epoch:31 step:29910 [D loss: 0.632915, acc.: 67.19%] [G loss: 0.862853]\n",
      "epoch:31 step:29911 [D loss: 0.653872, acc.: 58.59%] [G loss: 0.926936]\n",
      "epoch:31 step:29912 [D loss: 0.663951, acc.: 54.69%] [G loss: 0.885377]\n",
      "epoch:31 step:29913 [D loss: 0.661611, acc.: 55.47%] [G loss: 0.943721]\n",
      "epoch:31 step:29914 [D loss: 0.679653, acc.: 59.38%] [G loss: 0.834873]\n",
      "epoch:31 step:29915 [D loss: 0.637002, acc.: 64.06%] [G loss: 0.930075]\n",
      "epoch:31 step:29916 [D loss: 0.627018, acc.: 64.06%] [G loss: 0.940670]\n",
      "epoch:31 step:29917 [D loss: 0.657548, acc.: 52.34%] [G loss: 0.883695]\n",
      "epoch:31 step:29918 [D loss: 0.635842, acc.: 61.72%] [G loss: 0.927091]\n",
      "epoch:31 step:29919 [D loss: 0.690611, acc.: 57.03%] [G loss: 0.982006]\n",
      "epoch:31 step:29920 [D loss: 0.599041, acc.: 71.88%] [G loss: 0.890431]\n",
      "epoch:31 step:29921 [D loss: 0.602241, acc.: 69.53%] [G loss: 0.895564]\n",
      "epoch:31 step:29922 [D loss: 0.664768, acc.: 66.41%] [G loss: 0.915257]\n",
      "epoch:31 step:29923 [D loss: 0.655548, acc.: 62.50%] [G loss: 0.907452]\n",
      "epoch:31 step:29924 [D loss: 0.653214, acc.: 57.81%] [G loss: 0.974140]\n",
      "epoch:31 step:29925 [D loss: 0.632208, acc.: 64.84%] [G loss: 0.904735]\n",
      "epoch:31 step:29926 [D loss: 0.653528, acc.: 60.16%] [G loss: 0.969134]\n",
      "epoch:31 step:29927 [D loss: 0.643848, acc.: 66.41%] [G loss: 0.893729]\n",
      "epoch:31 step:29928 [D loss: 0.666458, acc.: 56.25%] [G loss: 0.954255]\n",
      "epoch:31 step:29929 [D loss: 0.661361, acc.: 59.38%] [G loss: 0.947589]\n",
      "epoch:31 step:29930 [D loss: 0.615422, acc.: 69.53%] [G loss: 0.945321]\n",
      "epoch:31 step:29931 [D loss: 0.668903, acc.: 53.91%] [G loss: 0.970814]\n",
      "epoch:31 step:29932 [D loss: 0.656507, acc.: 63.28%] [G loss: 0.967378]\n",
      "epoch:31 step:29933 [D loss: 0.621634, acc.: 64.06%] [G loss: 1.011964]\n",
      "epoch:31 step:29934 [D loss: 0.637989, acc.: 64.84%] [G loss: 0.980643]\n",
      "epoch:31 step:29935 [D loss: 0.652630, acc.: 61.72%] [G loss: 1.020671]\n",
      "epoch:31 step:29936 [D loss: 0.655304, acc.: 58.59%] [G loss: 0.940285]\n",
      "epoch:31 step:29937 [D loss: 0.621435, acc.: 67.97%] [G loss: 0.917621]\n",
      "epoch:31 step:29938 [D loss: 0.627189, acc.: 65.62%] [G loss: 0.883136]\n",
      "epoch:31 step:29939 [D loss: 0.628170, acc.: 62.50%] [G loss: 0.989608]\n",
      "epoch:31 step:29940 [D loss: 0.648686, acc.: 60.94%] [G loss: 0.865124]\n",
      "epoch:31 step:29941 [D loss: 0.648494, acc.: 57.81%] [G loss: 0.853593]\n",
      "epoch:31 step:29942 [D loss: 0.597629, acc.: 74.22%] [G loss: 0.980131]\n",
      "epoch:31 step:29943 [D loss: 0.636425, acc.: 67.19%] [G loss: 0.889735]\n",
      "epoch:31 step:29944 [D loss: 0.625258, acc.: 60.94%] [G loss: 0.925819]\n",
      "epoch:31 step:29945 [D loss: 0.691283, acc.: 51.56%] [G loss: 0.931609]\n",
      "epoch:31 step:29946 [D loss: 0.644315, acc.: 60.94%] [G loss: 0.942818]\n",
      "epoch:31 step:29947 [D loss: 0.646156, acc.: 63.28%] [G loss: 0.911424]\n",
      "epoch:31 step:29948 [D loss: 0.673070, acc.: 58.59%] [G loss: 0.849277]\n",
      "epoch:31 step:29949 [D loss: 0.705801, acc.: 53.91%] [G loss: 0.819821]\n",
      "epoch:31 step:29950 [D loss: 0.608540, acc.: 72.66%] [G loss: 0.867658]\n",
      "epoch:31 step:29951 [D loss: 0.631613, acc.: 63.28%] [G loss: 0.933501]\n",
      "epoch:31 step:29952 [D loss: 0.729817, acc.: 56.25%] [G loss: 0.922070]\n",
      "epoch:31 step:29953 [D loss: 0.645081, acc.: 60.94%] [G loss: 0.981280]\n",
      "epoch:31 step:29954 [D loss: 0.724569, acc.: 51.56%] [G loss: 0.937504]\n",
      "epoch:31 step:29955 [D loss: 0.659369, acc.: 60.16%] [G loss: 0.915442]\n",
      "epoch:31 step:29956 [D loss: 0.659978, acc.: 62.50%] [G loss: 0.894559]\n",
      "epoch:31 step:29957 [D loss: 0.684393, acc.: 53.91%] [G loss: 0.966679]\n",
      "epoch:31 step:29958 [D loss: 0.640718, acc.: 61.72%] [G loss: 0.965824]\n",
      "epoch:31 step:29959 [D loss: 0.658131, acc.: 57.81%] [G loss: 0.936934]\n",
      "epoch:31 step:29960 [D loss: 0.659267, acc.: 59.38%] [G loss: 0.923647]\n",
      "epoch:31 step:29961 [D loss: 0.628690, acc.: 61.72%] [G loss: 0.912419]\n",
      "epoch:31 step:29962 [D loss: 0.700488, acc.: 53.91%] [G loss: 0.917451]\n",
      "epoch:31 step:29963 [D loss: 0.622890, acc.: 67.19%] [G loss: 0.941861]\n",
      "epoch:31 step:29964 [D loss: 0.606972, acc.: 67.97%] [G loss: 0.938803]\n",
      "epoch:31 step:29965 [D loss: 0.673733, acc.: 60.16%] [G loss: 0.906316]\n",
      "epoch:31 step:29966 [D loss: 0.603560, acc.: 68.75%] [G loss: 0.898730]\n",
      "epoch:31 step:29967 [D loss: 0.630692, acc.: 65.62%] [G loss: 0.903464]\n",
      "epoch:31 step:29968 [D loss: 0.660655, acc.: 57.03%] [G loss: 0.964518]\n",
      "epoch:31 step:29969 [D loss: 0.646594, acc.: 60.94%] [G loss: 0.916442]\n",
      "epoch:31 step:29970 [D loss: 0.615664, acc.: 68.75%] [G loss: 0.872479]\n",
      "epoch:31 step:29971 [D loss: 0.622958, acc.: 64.84%] [G loss: 0.954790]\n",
      "epoch:31 step:29972 [D loss: 0.672293, acc.: 60.16%] [G loss: 0.948305]\n",
      "epoch:31 step:29973 [D loss: 0.654902, acc.: 59.38%] [G loss: 0.946725]\n",
      "epoch:31 step:29974 [D loss: 0.703304, acc.: 51.56%] [G loss: 0.948840]\n",
      "epoch:31 step:29975 [D loss: 0.588005, acc.: 68.75%] [G loss: 0.936665]\n",
      "epoch:31 step:29976 [D loss: 0.660491, acc.: 58.59%] [G loss: 0.910016]\n",
      "epoch:31 step:29977 [D loss: 0.602463, acc.: 71.09%] [G loss: 0.927255]\n",
      "epoch:31 step:29978 [D loss: 0.666567, acc.: 57.03%] [G loss: 0.977742]\n",
      "epoch:31 step:29979 [D loss: 0.584783, acc.: 71.09%] [G loss: 1.029427]\n",
      "epoch:31 step:29980 [D loss: 0.702440, acc.: 57.03%] [G loss: 0.898479]\n",
      "epoch:31 step:29981 [D loss: 0.607458, acc.: 65.62%] [G loss: 0.915579]\n",
      "epoch:31 step:29982 [D loss: 0.634365, acc.: 60.94%] [G loss: 0.873516]\n",
      "epoch:31 step:29983 [D loss: 0.627178, acc.: 63.28%] [G loss: 0.863481]\n",
      "epoch:31 step:29984 [D loss: 0.608713, acc.: 64.84%] [G loss: 0.922112]\n",
      "epoch:32 step:29985 [D loss: 0.653064, acc.: 60.16%] [G loss: 0.908144]\n",
      "epoch:32 step:29986 [D loss: 0.682175, acc.: 63.28%] [G loss: 0.892017]\n",
      "epoch:32 step:29987 [D loss: 0.616057, acc.: 66.41%] [G loss: 0.933572]\n",
      "epoch:32 step:29988 [D loss: 0.684152, acc.: 53.91%] [G loss: 0.953526]\n",
      "epoch:32 step:29989 [D loss: 0.661745, acc.: 62.50%] [G loss: 0.931529]\n",
      "epoch:32 step:29990 [D loss: 0.661238, acc.: 60.94%] [G loss: 0.983620]\n",
      "epoch:32 step:29991 [D loss: 0.690903, acc.: 54.69%] [G loss: 0.975560]\n",
      "epoch:32 step:29992 [D loss: 0.712047, acc.: 54.69%] [G loss: 0.955269]\n",
      "epoch:32 step:29993 [D loss: 0.658639, acc.: 58.59%] [G loss: 0.938845]\n",
      "epoch:32 step:29994 [D loss: 0.605919, acc.: 69.53%] [G loss: 0.931264]\n",
      "epoch:32 step:29995 [D loss: 0.592786, acc.: 68.75%] [G loss: 0.962583]\n",
      "epoch:32 step:29996 [D loss: 0.612469, acc.: 67.19%] [G loss: 1.072334]\n",
      "epoch:32 step:29997 [D loss: 0.622373, acc.: 67.97%] [G loss: 1.009746]\n",
      "epoch:32 step:29998 [D loss: 0.653114, acc.: 62.50%] [G loss: 0.936248]\n",
      "epoch:32 step:29999 [D loss: 0.646880, acc.: 60.94%] [G loss: 0.932510]\n",
      "epoch:32 step:30000 [D loss: 0.646127, acc.: 64.84%] [G loss: 0.937601]\n",
      "##############\n",
      "[3.04548385 2.12064588 1.94562714 3.68261057 1.4269725  9.27377891\n",
      " 2.65809401 3.74083036 4.38147406 6.77299561]\n",
      "##########\n",
      "epoch:32 step:30001 [D loss: 0.648869, acc.: 60.94%] [G loss: 0.892916]\n",
      "epoch:32 step:30002 [D loss: 0.640976, acc.: 62.50%] [G loss: 0.939395]\n",
      "epoch:32 step:30003 [D loss: 0.697245, acc.: 57.03%] [G loss: 0.931863]\n",
      "epoch:32 step:30004 [D loss: 0.670555, acc.: 53.12%] [G loss: 0.993290]\n",
      "epoch:32 step:30005 [D loss: 0.658211, acc.: 60.94%] [G loss: 0.912510]\n",
      "epoch:32 step:30006 [D loss: 0.655809, acc.: 64.84%] [G loss: 1.005838]\n",
      "epoch:32 step:30007 [D loss: 0.668780, acc.: 58.59%] [G loss: 0.960690]\n",
      "epoch:32 step:30008 [D loss: 0.668262, acc.: 61.72%] [G loss: 0.941757]\n",
      "epoch:32 step:30009 [D loss: 0.603877, acc.: 69.53%] [G loss: 0.917249]\n",
      "epoch:32 step:30010 [D loss: 0.661582, acc.: 61.72%] [G loss: 1.006011]\n",
      "epoch:32 step:30011 [D loss: 0.644336, acc.: 59.38%] [G loss: 0.884763]\n",
      "epoch:32 step:30012 [D loss: 0.590757, acc.: 71.09%] [G loss: 0.867168]\n",
      "epoch:32 step:30013 [D loss: 0.653793, acc.: 55.47%] [G loss: 0.897050]\n",
      "epoch:32 step:30014 [D loss: 0.670558, acc.: 61.72%] [G loss: 0.940796]\n",
      "epoch:32 step:30015 [D loss: 0.645918, acc.: 62.50%] [G loss: 0.900045]\n",
      "epoch:32 step:30016 [D loss: 0.676243, acc.: 53.12%] [G loss: 0.907326]\n",
      "epoch:32 step:30017 [D loss: 0.639731, acc.: 66.41%] [G loss: 0.921966]\n",
      "epoch:32 step:30018 [D loss: 0.680202, acc.: 60.94%] [G loss: 0.961316]\n",
      "epoch:32 step:30019 [D loss: 0.650411, acc.: 60.16%] [G loss: 0.898292]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:30020 [D loss: 0.617237, acc.: 61.72%] [G loss: 0.892815]\n",
      "epoch:32 step:30021 [D loss: 0.663833, acc.: 56.25%] [G loss: 0.912657]\n",
      "epoch:32 step:30022 [D loss: 0.683445, acc.: 56.25%] [G loss: 0.893413]\n",
      "epoch:32 step:30023 [D loss: 0.641059, acc.: 64.06%] [G loss: 0.953610]\n",
      "epoch:32 step:30024 [D loss: 0.651228, acc.: 60.94%] [G loss: 0.956931]\n",
      "epoch:32 step:30025 [D loss: 0.682232, acc.: 56.25%] [G loss: 0.959689]\n",
      "epoch:32 step:30026 [D loss: 0.638819, acc.: 64.06%] [G loss: 0.917393]\n",
      "epoch:32 step:30027 [D loss: 0.685938, acc.: 53.91%] [G loss: 0.896104]\n",
      "epoch:32 step:30028 [D loss: 0.642631, acc.: 63.28%] [G loss: 0.913831]\n",
      "epoch:32 step:30029 [D loss: 0.650208, acc.: 64.06%] [G loss: 0.875580]\n",
      "epoch:32 step:30030 [D loss: 0.631607, acc.: 66.41%] [G loss: 0.894202]\n",
      "epoch:32 step:30031 [D loss: 0.688230, acc.: 58.59%] [G loss: 0.814567]\n",
      "epoch:32 step:30032 [D loss: 0.662183, acc.: 63.28%] [G loss: 0.933952]\n",
      "epoch:32 step:30033 [D loss: 0.666682, acc.: 59.38%] [G loss: 0.951203]\n",
      "epoch:32 step:30034 [D loss: 0.693169, acc.: 52.34%] [G loss: 0.970249]\n",
      "epoch:32 step:30035 [D loss: 0.646576, acc.: 64.06%] [G loss: 0.958385]\n",
      "epoch:32 step:30036 [D loss: 0.628584, acc.: 67.19%] [G loss: 0.859828]\n",
      "epoch:32 step:30037 [D loss: 0.656368, acc.: 57.81%] [G loss: 0.944023]\n",
      "epoch:32 step:30038 [D loss: 0.633570, acc.: 62.50%] [G loss: 0.928770]\n",
      "epoch:32 step:30039 [D loss: 0.651151, acc.: 57.03%] [G loss: 0.922353]\n",
      "epoch:32 step:30040 [D loss: 0.675625, acc.: 59.38%] [G loss: 0.900549]\n",
      "epoch:32 step:30041 [D loss: 0.659658, acc.: 58.59%] [G loss: 0.928879]\n",
      "epoch:32 step:30042 [D loss: 0.639786, acc.: 64.06%] [G loss: 0.880838]\n",
      "epoch:32 step:30043 [D loss: 0.604859, acc.: 62.50%] [G loss: 0.922809]\n",
      "epoch:32 step:30044 [D loss: 0.654393, acc.: 58.59%] [G loss: 0.978184]\n",
      "epoch:32 step:30045 [D loss: 0.641924, acc.: 62.50%] [G loss: 0.958966]\n",
      "epoch:32 step:30046 [D loss: 0.637141, acc.: 58.59%] [G loss: 0.956943]\n",
      "epoch:32 step:30047 [D loss: 0.658148, acc.: 59.38%] [G loss: 0.930291]\n",
      "epoch:32 step:30048 [D loss: 0.656831, acc.: 59.38%] [G loss: 0.927993]\n",
      "epoch:32 step:30049 [D loss: 0.654168, acc.: 60.94%] [G loss: 0.927187]\n",
      "epoch:32 step:30050 [D loss: 0.624098, acc.: 64.06%] [G loss: 1.006068]\n",
      "epoch:32 step:30051 [D loss: 0.668804, acc.: 51.56%] [G loss: 0.918663]\n",
      "epoch:32 step:30052 [D loss: 0.623095, acc.: 66.41%] [G loss: 0.953183]\n",
      "epoch:32 step:30053 [D loss: 0.641524, acc.: 57.81%] [G loss: 0.948926]\n",
      "epoch:32 step:30054 [D loss: 0.635140, acc.: 67.97%] [G loss: 0.944023]\n",
      "epoch:32 step:30055 [D loss: 0.651761, acc.: 60.94%] [G loss: 0.955386]\n",
      "epoch:32 step:30056 [D loss: 0.644263, acc.: 56.25%] [G loss: 0.982206]\n",
      "epoch:32 step:30057 [D loss: 0.628856, acc.: 65.62%] [G loss: 0.980231]\n",
      "epoch:32 step:30058 [D loss: 0.648806, acc.: 61.72%] [G loss: 0.996858]\n",
      "epoch:32 step:30059 [D loss: 0.655231, acc.: 59.38%] [G loss: 0.946189]\n",
      "epoch:32 step:30060 [D loss: 0.627315, acc.: 63.28%] [G loss: 0.905280]\n",
      "epoch:32 step:30061 [D loss: 0.684909, acc.: 56.25%] [G loss: 0.946194]\n",
      "epoch:32 step:30062 [D loss: 0.628349, acc.: 63.28%] [G loss: 0.854239]\n",
      "epoch:32 step:30063 [D loss: 0.638238, acc.: 62.50%] [G loss: 1.007197]\n",
      "epoch:32 step:30064 [D loss: 0.681765, acc.: 55.47%] [G loss: 1.003522]\n",
      "epoch:32 step:30065 [D loss: 0.677642, acc.: 57.03%] [G loss: 0.946651]\n",
      "epoch:32 step:30066 [D loss: 0.669633, acc.: 63.28%] [G loss: 0.883336]\n",
      "epoch:32 step:30067 [D loss: 0.653104, acc.: 64.84%] [G loss: 0.925487]\n",
      "epoch:32 step:30068 [D loss: 0.668534, acc.: 58.59%] [G loss: 0.931155]\n",
      "epoch:32 step:30069 [D loss: 0.659688, acc.: 58.59%] [G loss: 0.981435]\n",
      "epoch:32 step:30070 [D loss: 0.624669, acc.: 62.50%] [G loss: 1.028002]\n",
      "epoch:32 step:30071 [D loss: 0.599644, acc.: 67.97%] [G loss: 1.011250]\n",
      "epoch:32 step:30072 [D loss: 0.656448, acc.: 64.06%] [G loss: 0.919493]\n",
      "epoch:32 step:30073 [D loss: 0.650590, acc.: 64.06%] [G loss: 0.904071]\n",
      "epoch:32 step:30074 [D loss: 0.654213, acc.: 60.16%] [G loss: 0.906552]\n",
      "epoch:32 step:30075 [D loss: 0.670550, acc.: 59.38%] [G loss: 0.931564]\n",
      "epoch:32 step:30076 [D loss: 0.662152, acc.: 58.59%] [G loss: 0.929626]\n",
      "epoch:32 step:30077 [D loss: 0.673146, acc.: 56.25%] [G loss: 0.874377]\n",
      "epoch:32 step:30078 [D loss: 0.657705, acc.: 52.34%] [G loss: 0.926763]\n",
      "epoch:32 step:30079 [D loss: 0.674911, acc.: 57.81%] [G loss: 0.909013]\n",
      "epoch:32 step:30080 [D loss: 0.632276, acc.: 64.84%] [G loss: 0.911390]\n",
      "epoch:32 step:30081 [D loss: 0.639865, acc.: 63.28%] [G loss: 0.894143]\n",
      "epoch:32 step:30082 [D loss: 0.623169, acc.: 65.62%] [G loss: 0.926544]\n",
      "epoch:32 step:30083 [D loss: 0.688832, acc.: 61.72%] [G loss: 0.983330]\n",
      "epoch:32 step:30084 [D loss: 0.688987, acc.: 54.69%] [G loss: 0.875351]\n",
      "epoch:32 step:30085 [D loss: 0.669649, acc.: 57.81%] [G loss: 0.906769]\n",
      "epoch:32 step:30086 [D loss: 0.664516, acc.: 59.38%] [G loss: 0.928917]\n",
      "epoch:32 step:30087 [D loss: 0.652146, acc.: 60.94%] [G loss: 0.895916]\n",
      "epoch:32 step:30088 [D loss: 0.658994, acc.: 61.72%] [G loss: 0.901562]\n",
      "epoch:32 step:30089 [D loss: 0.656507, acc.: 60.16%] [G loss: 0.897363]\n",
      "epoch:32 step:30090 [D loss: 0.627514, acc.: 64.06%] [G loss: 0.939649]\n",
      "epoch:32 step:30091 [D loss: 0.633835, acc.: 67.19%] [G loss: 0.888883]\n",
      "epoch:32 step:30092 [D loss: 0.659008, acc.: 63.28%] [G loss: 0.916494]\n",
      "epoch:32 step:30093 [D loss: 0.642931, acc.: 67.97%] [G loss: 0.900469]\n",
      "epoch:32 step:30094 [D loss: 0.679546, acc.: 56.25%] [G loss: 0.887351]\n",
      "epoch:32 step:30095 [D loss: 0.671031, acc.: 58.59%] [G loss: 0.882641]\n",
      "epoch:32 step:30096 [D loss: 0.682428, acc.: 60.94%] [G loss: 0.897167]\n",
      "epoch:32 step:30097 [D loss: 0.665802, acc.: 60.94%] [G loss: 0.902631]\n",
      "epoch:32 step:30098 [D loss: 0.639460, acc.: 61.72%] [G loss: 0.823254]\n",
      "epoch:32 step:30099 [D loss: 0.675205, acc.: 56.25%] [G loss: 0.866989]\n",
      "epoch:32 step:30100 [D loss: 0.621073, acc.: 63.28%] [G loss: 0.923235]\n",
      "epoch:32 step:30101 [D loss: 0.672150, acc.: 54.69%] [G loss: 0.869803]\n",
      "epoch:32 step:30102 [D loss: 0.660041, acc.: 59.38%] [G loss: 0.832165]\n",
      "epoch:32 step:30103 [D loss: 0.645887, acc.: 66.41%] [G loss: 0.930415]\n",
      "epoch:32 step:30104 [D loss: 0.675369, acc.: 56.25%] [G loss: 0.914598]\n",
      "epoch:32 step:30105 [D loss: 0.597247, acc.: 71.88%] [G loss: 0.929014]\n",
      "epoch:32 step:30106 [D loss: 0.650797, acc.: 60.16%] [G loss: 0.936957]\n",
      "epoch:32 step:30107 [D loss: 0.643005, acc.: 67.19%] [G loss: 0.878646]\n",
      "epoch:32 step:30108 [D loss: 0.684747, acc.: 55.47%] [G loss: 0.848102]\n",
      "epoch:32 step:30109 [D loss: 0.657474, acc.: 60.94%] [G loss: 0.885989]\n",
      "epoch:32 step:30110 [D loss: 0.634781, acc.: 64.84%] [G loss: 0.872926]\n",
      "epoch:32 step:30111 [D loss: 0.644340, acc.: 63.28%] [G loss: 0.875276]\n",
      "epoch:32 step:30112 [D loss: 0.624363, acc.: 65.62%] [G loss: 0.899826]\n",
      "epoch:32 step:30113 [D loss: 0.674529, acc.: 57.03%] [G loss: 0.865629]\n",
      "epoch:32 step:30114 [D loss: 0.652087, acc.: 67.19%] [G loss: 0.894937]\n",
      "epoch:32 step:30115 [D loss: 0.626689, acc.: 65.62%] [G loss: 0.889010]\n",
      "epoch:32 step:30116 [D loss: 0.655111, acc.: 60.16%] [G loss: 0.958477]\n",
      "epoch:32 step:30117 [D loss: 0.651119, acc.: 53.12%] [G loss: 0.887891]\n",
      "epoch:32 step:30118 [D loss: 0.663969, acc.: 56.25%] [G loss: 0.858127]\n",
      "epoch:32 step:30119 [D loss: 0.686435, acc.: 50.00%] [G loss: 0.890952]\n",
      "epoch:32 step:30120 [D loss: 0.672065, acc.: 54.69%] [G loss: 0.916859]\n",
      "epoch:32 step:30121 [D loss: 0.623708, acc.: 65.62%] [G loss: 0.923266]\n",
      "epoch:32 step:30122 [D loss: 0.616924, acc.: 66.41%] [G loss: 0.922832]\n",
      "epoch:32 step:30123 [D loss: 0.662026, acc.: 64.06%] [G loss: 0.862601]\n",
      "epoch:32 step:30124 [D loss: 0.622598, acc.: 63.28%] [G loss: 0.919478]\n",
      "epoch:32 step:30125 [D loss: 0.683870, acc.: 51.56%] [G loss: 0.918556]\n",
      "epoch:32 step:30126 [D loss: 0.604760, acc.: 67.19%] [G loss: 0.928347]\n",
      "epoch:32 step:30127 [D loss: 0.649168, acc.: 57.03%] [G loss: 0.929983]\n",
      "epoch:32 step:30128 [D loss: 0.678162, acc.: 60.94%] [G loss: 0.917810]\n",
      "epoch:32 step:30129 [D loss: 0.636866, acc.: 64.84%] [G loss: 0.926737]\n",
      "epoch:32 step:30130 [D loss: 0.650121, acc.: 60.16%] [G loss: 0.921630]\n",
      "epoch:32 step:30131 [D loss: 0.634364, acc.: 62.50%] [G loss: 0.939243]\n",
      "epoch:32 step:30132 [D loss: 0.676484, acc.: 61.72%] [G loss: 0.964665]\n",
      "epoch:32 step:30133 [D loss: 0.660916, acc.: 57.81%] [G loss: 0.954908]\n",
      "epoch:32 step:30134 [D loss: 0.609827, acc.: 66.41%] [G loss: 0.904008]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:30135 [D loss: 0.640123, acc.: 58.59%] [G loss: 0.930244]\n",
      "epoch:32 step:30136 [D loss: 0.667590, acc.: 52.34%] [G loss: 0.898708]\n",
      "epoch:32 step:30137 [D loss: 0.624743, acc.: 63.28%] [G loss: 0.897134]\n",
      "epoch:32 step:30138 [D loss: 0.663260, acc.: 57.81%] [G loss: 0.951262]\n",
      "epoch:32 step:30139 [D loss: 0.632357, acc.: 66.41%] [G loss: 0.891976]\n",
      "epoch:32 step:30140 [D loss: 0.609374, acc.: 64.84%] [G loss: 0.939890]\n",
      "epoch:32 step:30141 [D loss: 0.634324, acc.: 64.06%] [G loss: 0.970618]\n",
      "epoch:32 step:30142 [D loss: 0.657258, acc.: 60.94%] [G loss: 0.966970]\n",
      "epoch:32 step:30143 [D loss: 0.637728, acc.: 60.16%] [G loss: 0.949344]\n",
      "epoch:32 step:30144 [D loss: 0.638310, acc.: 64.84%] [G loss: 0.902869]\n",
      "epoch:32 step:30145 [D loss: 0.598469, acc.: 67.19%] [G loss: 0.967823]\n",
      "epoch:32 step:30146 [D loss: 0.625875, acc.: 64.84%] [G loss: 0.990624]\n",
      "epoch:32 step:30147 [D loss: 0.697121, acc.: 59.38%] [G loss: 0.865880]\n",
      "epoch:32 step:30148 [D loss: 0.660076, acc.: 53.91%] [G loss: 0.870033]\n",
      "epoch:32 step:30149 [D loss: 0.637319, acc.: 62.50%] [G loss: 0.878865]\n",
      "epoch:32 step:30150 [D loss: 0.665734, acc.: 53.91%] [G loss: 0.887005]\n",
      "epoch:32 step:30151 [D loss: 0.650587, acc.: 60.16%] [G loss: 1.004395]\n",
      "epoch:32 step:30152 [D loss: 0.635186, acc.: 62.50%] [G loss: 0.965628]\n",
      "epoch:32 step:30153 [D loss: 0.711686, acc.: 47.66%] [G loss: 0.921174]\n",
      "epoch:32 step:30154 [D loss: 0.620830, acc.: 65.62%] [G loss: 0.935056]\n",
      "epoch:32 step:30155 [D loss: 0.652821, acc.: 57.81%] [G loss: 0.877154]\n",
      "epoch:32 step:30156 [D loss: 0.649906, acc.: 60.94%] [G loss: 0.912758]\n",
      "epoch:32 step:30157 [D loss: 0.645085, acc.: 58.59%] [G loss: 0.895078]\n",
      "epoch:32 step:30158 [D loss: 0.628074, acc.: 64.84%] [G loss: 0.924264]\n",
      "epoch:32 step:30159 [D loss: 0.677157, acc.: 57.81%] [G loss: 0.903904]\n",
      "epoch:32 step:30160 [D loss: 0.612900, acc.: 65.62%] [G loss: 0.936947]\n",
      "epoch:32 step:30161 [D loss: 0.614093, acc.: 66.41%] [G loss: 0.857937]\n",
      "epoch:32 step:30162 [D loss: 0.626122, acc.: 60.16%] [G loss: 0.955763]\n",
      "epoch:32 step:30163 [D loss: 0.671223, acc.: 59.38%] [G loss: 0.900481]\n",
      "epoch:32 step:30164 [D loss: 0.625806, acc.: 64.84%] [G loss: 0.909405]\n",
      "epoch:32 step:30165 [D loss: 0.682307, acc.: 57.81%] [G loss: 0.968111]\n",
      "epoch:32 step:30166 [D loss: 0.676704, acc.: 57.03%] [G loss: 0.935127]\n",
      "epoch:32 step:30167 [D loss: 0.633827, acc.: 61.72%] [G loss: 0.931517]\n",
      "epoch:32 step:30168 [D loss: 0.635198, acc.: 64.84%] [G loss: 0.994342]\n",
      "epoch:32 step:30169 [D loss: 0.651172, acc.: 60.16%] [G loss: 0.860842]\n",
      "epoch:32 step:30170 [D loss: 0.659513, acc.: 59.38%] [G loss: 0.878531]\n",
      "epoch:32 step:30171 [D loss: 0.634000, acc.: 63.28%] [G loss: 0.910107]\n",
      "epoch:32 step:30172 [D loss: 0.692542, acc.: 52.34%] [G loss: 0.949912]\n",
      "epoch:32 step:30173 [D loss: 0.634035, acc.: 67.19%] [G loss: 0.927898]\n",
      "epoch:32 step:30174 [D loss: 0.677613, acc.: 53.12%] [G loss: 0.922230]\n",
      "epoch:32 step:30175 [D loss: 0.604806, acc.: 71.88%] [G loss: 0.904058]\n",
      "epoch:32 step:30176 [D loss: 0.663207, acc.: 58.59%] [G loss: 0.903791]\n",
      "epoch:32 step:30177 [D loss: 0.609107, acc.: 68.75%] [G loss: 0.944643]\n",
      "epoch:32 step:30178 [D loss: 0.639992, acc.: 60.94%] [G loss: 0.907877]\n",
      "epoch:32 step:30179 [D loss: 0.655980, acc.: 60.16%] [G loss: 0.937549]\n",
      "epoch:32 step:30180 [D loss: 0.622910, acc.: 66.41%] [G loss: 0.949318]\n",
      "epoch:32 step:30181 [D loss: 0.654349, acc.: 59.38%] [G loss: 0.884333]\n",
      "epoch:32 step:30182 [D loss: 0.603199, acc.: 66.41%] [G loss: 0.921276]\n",
      "epoch:32 step:30183 [D loss: 0.612851, acc.: 65.62%] [G loss: 0.929102]\n",
      "epoch:32 step:30184 [D loss: 0.592178, acc.: 67.97%] [G loss: 0.862028]\n",
      "epoch:32 step:30185 [D loss: 0.672480, acc.: 60.94%] [G loss: 0.941407]\n",
      "epoch:32 step:30186 [D loss: 0.636674, acc.: 67.19%] [G loss: 0.879166]\n",
      "epoch:32 step:30187 [D loss: 0.643255, acc.: 69.53%] [G loss: 0.881282]\n",
      "epoch:32 step:30188 [D loss: 0.619732, acc.: 63.28%] [G loss: 0.951097]\n",
      "epoch:32 step:30189 [D loss: 0.643426, acc.: 61.72%] [G loss: 0.904094]\n",
      "epoch:32 step:30190 [D loss: 0.654622, acc.: 57.81%] [G loss: 1.010894]\n",
      "epoch:32 step:30191 [D loss: 0.656587, acc.: 60.94%] [G loss: 0.935603]\n",
      "epoch:32 step:30192 [D loss: 0.621979, acc.: 67.97%] [G loss: 0.974044]\n",
      "epoch:32 step:30193 [D loss: 0.672575, acc.: 57.81%] [G loss: 0.928196]\n",
      "epoch:32 step:30194 [D loss: 0.641814, acc.: 60.16%] [G loss: 0.901254]\n",
      "epoch:32 step:30195 [D loss: 0.661159, acc.: 55.47%] [G loss: 0.951776]\n",
      "epoch:32 step:30196 [D loss: 0.684276, acc.: 55.47%] [G loss: 0.902941]\n",
      "epoch:32 step:30197 [D loss: 0.675164, acc.: 54.69%] [G loss: 0.924530]\n",
      "epoch:32 step:30198 [D loss: 0.643115, acc.: 67.19%] [G loss: 0.988912]\n",
      "epoch:32 step:30199 [D loss: 0.703204, acc.: 54.69%] [G loss: 0.941352]\n",
      "epoch:32 step:30200 [D loss: 0.672664, acc.: 54.69%] [G loss: 0.897177]\n",
      "##############\n",
      "[2.92025374 2.37194121 2.39961919 3.75138723 1.22068709 8.2831601\n",
      " 2.63235192 3.11451696 4.2009371  5.66855933]\n",
      "##########\n",
      "epoch:32 step:30201 [D loss: 0.615604, acc.: 68.75%] [G loss: 0.920265]\n",
      "epoch:32 step:30202 [D loss: 0.671130, acc.: 61.72%] [G loss: 0.903977]\n",
      "epoch:32 step:30203 [D loss: 0.705803, acc.: 48.44%] [G loss: 0.904825]\n",
      "epoch:32 step:30204 [D loss: 0.649290, acc.: 62.50%] [G loss: 0.903559]\n",
      "epoch:32 step:30205 [D loss: 0.631376, acc.: 66.41%] [G loss: 0.958866]\n",
      "epoch:32 step:30206 [D loss: 0.693282, acc.: 53.12%] [G loss: 0.875388]\n",
      "epoch:32 step:30207 [D loss: 0.602339, acc.: 71.09%] [G loss: 0.841370]\n",
      "epoch:32 step:30208 [D loss: 0.629833, acc.: 63.28%] [G loss: 0.910699]\n",
      "epoch:32 step:30209 [D loss: 0.631336, acc.: 62.50%] [G loss: 0.829440]\n",
      "epoch:32 step:30210 [D loss: 0.667714, acc.: 58.59%] [G loss: 0.835726]\n",
      "epoch:32 step:30211 [D loss: 0.672819, acc.: 60.16%] [G loss: 0.896747]\n",
      "epoch:32 step:30212 [D loss: 0.627718, acc.: 62.50%] [G loss: 0.926345]\n",
      "epoch:32 step:30213 [D loss: 0.633650, acc.: 69.53%] [G loss: 0.888523]\n",
      "epoch:32 step:30214 [D loss: 0.653248, acc.: 62.50%] [G loss: 0.869173]\n",
      "epoch:32 step:30215 [D loss: 0.692848, acc.: 57.03%] [G loss: 0.991761]\n",
      "epoch:32 step:30216 [D loss: 0.642803, acc.: 60.94%] [G loss: 0.994163]\n",
      "epoch:32 step:30217 [D loss: 0.683899, acc.: 55.47%] [G loss: 0.952792]\n",
      "epoch:32 step:30218 [D loss: 0.644870, acc.: 63.28%] [G loss: 0.926743]\n",
      "epoch:32 step:30219 [D loss: 0.659425, acc.: 54.69%] [G loss: 0.995219]\n",
      "epoch:32 step:30220 [D loss: 0.665712, acc.: 54.69%] [G loss: 0.916172]\n",
      "epoch:32 step:30221 [D loss: 0.667792, acc.: 62.50%] [G loss: 0.922753]\n",
      "epoch:32 step:30222 [D loss: 0.637171, acc.: 63.28%] [G loss: 0.895857]\n",
      "epoch:32 step:30223 [D loss: 0.683132, acc.: 56.25%] [G loss: 0.885755]\n",
      "epoch:32 step:30224 [D loss: 0.638615, acc.: 63.28%] [G loss: 0.856257]\n",
      "epoch:32 step:30225 [D loss: 0.612738, acc.: 69.53%] [G loss: 0.973636]\n",
      "epoch:32 step:30226 [D loss: 0.647183, acc.: 62.50%] [G loss: 0.936616]\n",
      "epoch:32 step:30227 [D loss: 0.620150, acc.: 66.41%] [G loss: 0.928673]\n",
      "epoch:32 step:30228 [D loss: 0.696502, acc.: 53.91%] [G loss: 0.934948]\n",
      "epoch:32 step:30229 [D loss: 0.640126, acc.: 64.06%] [G loss: 0.915910]\n",
      "epoch:32 step:30230 [D loss: 0.647070, acc.: 59.38%] [G loss: 0.900946]\n",
      "epoch:32 step:30231 [D loss: 0.632898, acc.: 60.16%] [G loss: 0.905518]\n",
      "epoch:32 step:30232 [D loss: 0.673589, acc.: 59.38%] [G loss: 0.939171]\n",
      "epoch:32 step:30233 [D loss: 0.684041, acc.: 56.25%] [G loss: 0.897638]\n",
      "epoch:32 step:30234 [D loss: 0.642861, acc.: 66.41%] [G loss: 0.931297]\n",
      "epoch:32 step:30235 [D loss: 0.656958, acc.: 58.59%] [G loss: 1.009228]\n",
      "epoch:32 step:30236 [D loss: 0.647807, acc.: 60.16%] [G loss: 0.872870]\n",
      "epoch:32 step:30237 [D loss: 0.624947, acc.: 65.62%] [G loss: 0.946762]\n",
      "epoch:32 step:30238 [D loss: 0.663604, acc.: 60.16%] [G loss: 0.853744]\n",
      "epoch:32 step:30239 [D loss: 0.648938, acc.: 61.72%] [G loss: 0.902945]\n",
      "epoch:32 step:30240 [D loss: 0.655111, acc.: 60.16%] [G loss: 0.953194]\n",
      "epoch:32 step:30241 [D loss: 0.645452, acc.: 63.28%] [G loss: 0.935492]\n",
      "epoch:32 step:30242 [D loss: 0.621814, acc.: 64.84%] [G loss: 0.890669]\n",
      "epoch:32 step:30243 [D loss: 0.697764, acc.: 55.47%] [G loss: 0.915654]\n",
      "epoch:32 step:30244 [D loss: 0.670103, acc.: 57.03%] [G loss: 0.927343]\n",
      "epoch:32 step:30245 [D loss: 0.659421, acc.: 59.38%] [G loss: 0.999381]\n",
      "epoch:32 step:30246 [D loss: 0.660265, acc.: 64.84%] [G loss: 0.910709]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:30247 [D loss: 0.633549, acc.: 64.84%] [G loss: 0.938124]\n",
      "epoch:32 step:30248 [D loss: 0.656801, acc.: 62.50%] [G loss: 0.933877]\n",
      "epoch:32 step:30249 [D loss: 0.655666, acc.: 57.03%] [G loss: 0.956634]\n",
      "epoch:32 step:30250 [D loss: 0.622499, acc.: 65.62%] [G loss: 0.911402]\n",
      "epoch:32 step:30251 [D loss: 0.638888, acc.: 62.50%] [G loss: 1.007402]\n",
      "epoch:32 step:30252 [D loss: 0.686202, acc.: 52.34%] [G loss: 0.991091]\n",
      "epoch:32 step:30253 [D loss: 0.630664, acc.: 60.94%] [G loss: 0.921142]\n",
      "epoch:32 step:30254 [D loss: 0.671210, acc.: 57.03%] [G loss: 0.955424]\n",
      "epoch:32 step:30255 [D loss: 0.645071, acc.: 59.38%] [G loss: 0.887757]\n",
      "epoch:32 step:30256 [D loss: 0.644008, acc.: 63.28%] [G loss: 1.002169]\n",
      "epoch:32 step:30257 [D loss: 0.667294, acc.: 57.81%] [G loss: 0.934626]\n",
      "epoch:32 step:30258 [D loss: 0.656240, acc.: 60.94%] [G loss: 0.908619]\n",
      "epoch:32 step:30259 [D loss: 0.660446, acc.: 60.16%] [G loss: 0.970185]\n",
      "epoch:32 step:30260 [D loss: 0.670972, acc.: 53.91%] [G loss: 0.921151]\n",
      "epoch:32 step:30261 [D loss: 0.626193, acc.: 64.84%] [G loss: 0.881038]\n",
      "epoch:32 step:30262 [D loss: 0.647502, acc.: 58.59%] [G loss: 0.868837]\n",
      "epoch:32 step:30263 [D loss: 0.669012, acc.: 63.28%] [G loss: 0.873914]\n",
      "epoch:32 step:30264 [D loss: 0.701531, acc.: 57.03%] [G loss: 0.871110]\n",
      "epoch:32 step:30265 [D loss: 0.623825, acc.: 65.62%] [G loss: 0.846374]\n",
      "epoch:32 step:30266 [D loss: 0.646405, acc.: 64.06%] [G loss: 0.873473]\n",
      "epoch:32 step:30267 [D loss: 0.648499, acc.: 59.38%] [G loss: 0.898742]\n",
      "epoch:32 step:30268 [D loss: 0.616325, acc.: 68.75%] [G loss: 0.884397]\n",
      "epoch:32 step:30269 [D loss: 0.657193, acc.: 59.38%] [G loss: 0.924819]\n",
      "epoch:32 step:30270 [D loss: 0.636876, acc.: 65.62%] [G loss: 0.926498]\n",
      "epoch:32 step:30271 [D loss: 0.640382, acc.: 63.28%] [G loss: 0.970844]\n",
      "epoch:32 step:30272 [D loss: 0.634568, acc.: 62.50%] [G loss: 0.924371]\n",
      "epoch:32 step:30273 [D loss: 0.718092, acc.: 50.78%] [G loss: 0.909757]\n",
      "epoch:32 step:30274 [D loss: 0.612418, acc.: 61.72%] [G loss: 0.930792]\n",
      "epoch:32 step:30275 [D loss: 0.652354, acc.: 60.16%] [G loss: 0.939217]\n",
      "epoch:32 step:30276 [D loss: 0.645398, acc.: 60.16%] [G loss: 0.871453]\n",
      "epoch:32 step:30277 [D loss: 0.674381, acc.: 57.03%] [G loss: 0.873415]\n",
      "epoch:32 step:30278 [D loss: 0.663234, acc.: 59.38%] [G loss: 0.922484]\n",
      "epoch:32 step:30279 [D loss: 0.659202, acc.: 62.50%] [G loss: 0.883844]\n",
      "epoch:32 step:30280 [D loss: 0.655043, acc.: 59.38%] [G loss: 0.861401]\n",
      "epoch:32 step:30281 [D loss: 0.620356, acc.: 65.62%] [G loss: 0.956065]\n",
      "epoch:32 step:30282 [D loss: 0.643657, acc.: 60.16%] [G loss: 0.892885]\n",
      "epoch:32 step:30283 [D loss: 0.667564, acc.: 57.81%] [G loss: 0.893883]\n",
      "epoch:32 step:30284 [D loss: 0.634698, acc.: 63.28%] [G loss: 0.887985]\n",
      "epoch:32 step:30285 [D loss: 0.663496, acc.: 60.94%] [G loss: 0.884893]\n",
      "epoch:32 step:30286 [D loss: 0.639576, acc.: 62.50%] [G loss: 0.880291]\n",
      "epoch:32 step:30287 [D loss: 0.696712, acc.: 50.78%] [G loss: 0.873628]\n",
      "epoch:32 step:30288 [D loss: 0.655762, acc.: 57.81%] [G loss: 0.981024]\n",
      "epoch:32 step:30289 [D loss: 0.661840, acc.: 60.16%] [G loss: 0.965575]\n",
      "epoch:32 step:30290 [D loss: 0.655563, acc.: 58.59%] [G loss: 0.908186]\n",
      "epoch:32 step:30291 [D loss: 0.659886, acc.: 58.59%] [G loss: 0.869788]\n",
      "epoch:32 step:30292 [D loss: 0.638970, acc.: 58.59%] [G loss: 0.893705]\n",
      "epoch:32 step:30293 [D loss: 0.647408, acc.: 55.47%] [G loss: 0.923380]\n",
      "epoch:32 step:30294 [D loss: 0.661203, acc.: 60.16%] [G loss: 0.855872]\n",
      "epoch:32 step:30295 [D loss: 0.634479, acc.: 62.50%] [G loss: 0.884176]\n",
      "epoch:32 step:30296 [D loss: 0.654511, acc.: 57.81%] [G loss: 0.986127]\n",
      "epoch:32 step:30297 [D loss: 0.661515, acc.: 64.06%] [G loss: 0.852425]\n",
      "epoch:32 step:30298 [D loss: 0.614042, acc.: 60.16%] [G loss: 0.933981]\n",
      "epoch:32 step:30299 [D loss: 0.602416, acc.: 67.19%] [G loss: 0.918270]\n",
      "epoch:32 step:30300 [D loss: 0.644037, acc.: 60.16%] [G loss: 0.952239]\n",
      "epoch:32 step:30301 [D loss: 0.645189, acc.: 60.94%] [G loss: 0.910163]\n",
      "epoch:32 step:30302 [D loss: 0.672479, acc.: 57.81%] [G loss: 0.986267]\n",
      "epoch:32 step:30303 [D loss: 0.640239, acc.: 62.50%] [G loss: 0.909131]\n",
      "epoch:32 step:30304 [D loss: 0.662929, acc.: 57.03%] [G loss: 0.887153]\n",
      "epoch:32 step:30305 [D loss: 0.657453, acc.: 62.50%] [G loss: 0.882974]\n",
      "epoch:32 step:30306 [D loss: 0.663820, acc.: 59.38%] [G loss: 0.843246]\n",
      "epoch:32 step:30307 [D loss: 0.627144, acc.: 64.06%] [G loss: 0.890436]\n",
      "epoch:32 step:30308 [D loss: 0.645772, acc.: 64.84%] [G loss: 0.869025]\n",
      "epoch:32 step:30309 [D loss: 0.650914, acc.: 60.94%] [G loss: 0.912794]\n",
      "epoch:32 step:30310 [D loss: 0.686082, acc.: 57.03%] [G loss: 0.863897]\n",
      "epoch:32 step:30311 [D loss: 0.619271, acc.: 67.97%] [G loss: 0.912781]\n",
      "epoch:32 step:30312 [D loss: 0.672361, acc.: 62.50%] [G loss: 0.919362]\n",
      "epoch:32 step:30313 [D loss: 0.643127, acc.: 63.28%] [G loss: 0.957282]\n",
      "epoch:32 step:30314 [D loss: 0.626476, acc.: 67.97%] [G loss: 0.932120]\n",
      "epoch:32 step:30315 [D loss: 0.658329, acc.: 67.19%] [G loss: 0.999684]\n",
      "epoch:32 step:30316 [D loss: 0.634781, acc.: 61.72%] [G loss: 0.984871]\n",
      "epoch:32 step:30317 [D loss: 0.654445, acc.: 62.50%] [G loss: 0.948175]\n",
      "epoch:32 step:30318 [D loss: 0.685715, acc.: 53.91%] [G loss: 0.943652]\n",
      "epoch:32 step:30319 [D loss: 0.654273, acc.: 58.59%] [G loss: 0.843499]\n",
      "epoch:32 step:30320 [D loss: 0.628268, acc.: 63.28%] [G loss: 0.964955]\n",
      "epoch:32 step:30321 [D loss: 0.620457, acc.: 64.06%] [G loss: 0.888813]\n",
      "epoch:32 step:30322 [D loss: 0.667180, acc.: 55.47%] [G loss: 0.925436]\n",
      "epoch:32 step:30323 [D loss: 0.627884, acc.: 64.06%] [G loss: 0.977891]\n",
      "epoch:32 step:30324 [D loss: 0.633717, acc.: 64.84%] [G loss: 0.972252]\n",
      "epoch:32 step:30325 [D loss: 0.669235, acc.: 57.81%] [G loss: 0.935637]\n",
      "epoch:32 step:30326 [D loss: 0.614946, acc.: 62.50%] [G loss: 0.912654]\n",
      "epoch:32 step:30327 [D loss: 0.658326, acc.: 57.03%] [G loss: 0.982541]\n",
      "epoch:32 step:30328 [D loss: 0.672163, acc.: 54.69%] [G loss: 0.941731]\n",
      "epoch:32 step:30329 [D loss: 0.622313, acc.: 62.50%] [G loss: 0.938620]\n",
      "epoch:32 step:30330 [D loss: 0.642873, acc.: 65.62%] [G loss: 0.911587]\n",
      "epoch:32 step:30331 [D loss: 0.625472, acc.: 70.31%] [G loss: 0.886036]\n",
      "epoch:32 step:30332 [D loss: 0.710638, acc.: 52.34%] [G loss: 0.901093]\n",
      "epoch:32 step:30333 [D loss: 0.650783, acc.: 61.72%] [G loss: 0.955855]\n",
      "epoch:32 step:30334 [D loss: 0.647945, acc.: 59.38%] [G loss: 0.934019]\n",
      "epoch:32 step:30335 [D loss: 0.654189, acc.: 60.94%] [G loss: 0.867136]\n",
      "epoch:32 step:30336 [D loss: 0.675186, acc.: 57.81%] [G loss: 0.970260]\n",
      "epoch:32 step:30337 [D loss: 0.629467, acc.: 64.06%] [G loss: 0.867904]\n",
      "epoch:32 step:30338 [D loss: 0.663182, acc.: 60.16%] [G loss: 0.911817]\n",
      "epoch:32 step:30339 [D loss: 0.648685, acc.: 60.16%] [G loss: 0.882862]\n",
      "epoch:32 step:30340 [D loss: 0.621973, acc.: 62.50%] [G loss: 0.897565]\n",
      "epoch:32 step:30341 [D loss: 0.636623, acc.: 60.94%] [G loss: 0.935886]\n",
      "epoch:32 step:30342 [D loss: 0.619360, acc.: 67.97%] [G loss: 0.964054]\n",
      "epoch:32 step:30343 [D loss: 0.659468, acc.: 54.69%] [G loss: 0.921457]\n",
      "epoch:32 step:30344 [D loss: 0.616291, acc.: 68.75%] [G loss: 0.944392]\n",
      "epoch:32 step:30345 [D loss: 0.628640, acc.: 67.19%] [G loss: 0.904932]\n",
      "epoch:32 step:30346 [D loss: 0.639343, acc.: 64.06%] [G loss: 0.878965]\n",
      "epoch:32 step:30347 [D loss: 0.660211, acc.: 63.28%] [G loss: 0.911265]\n",
      "epoch:32 step:30348 [D loss: 0.653509, acc.: 58.59%] [G loss: 0.864156]\n",
      "epoch:32 step:30349 [D loss: 0.632559, acc.: 64.84%] [G loss: 0.833334]\n",
      "epoch:32 step:30350 [D loss: 0.640876, acc.: 65.62%] [G loss: 0.866306]\n",
      "epoch:32 step:30351 [D loss: 0.661477, acc.: 59.38%] [G loss: 0.872466]\n",
      "epoch:32 step:30352 [D loss: 0.672760, acc.: 57.81%] [G loss: 0.921076]\n",
      "epoch:32 step:30353 [D loss: 0.628530, acc.: 67.97%] [G loss: 0.876206]\n",
      "epoch:32 step:30354 [D loss: 0.653886, acc.: 53.91%] [G loss: 0.926132]\n",
      "epoch:32 step:30355 [D loss: 0.677972, acc.: 61.72%] [G loss: 0.901470]\n",
      "epoch:32 step:30356 [D loss: 0.606480, acc.: 67.97%] [G loss: 0.947991]\n",
      "epoch:32 step:30357 [D loss: 0.603205, acc.: 67.97%] [G loss: 0.939128]\n",
      "epoch:32 step:30358 [D loss: 0.676261, acc.: 50.78%] [G loss: 0.895395]\n",
      "epoch:32 step:30359 [D loss: 0.654475, acc.: 62.50%] [G loss: 0.899451]\n",
      "epoch:32 step:30360 [D loss: 0.700530, acc.: 52.34%] [G loss: 0.873101]\n",
      "epoch:32 step:30361 [D loss: 0.639090, acc.: 63.28%] [G loss: 0.903869]\n",
      "epoch:32 step:30362 [D loss: 0.654744, acc.: 59.38%] [G loss: 0.872273]\n",
      "epoch:32 step:30363 [D loss: 0.677433, acc.: 56.25%] [G loss: 0.961909]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:30364 [D loss: 0.642898, acc.: 58.59%] [G loss: 0.884334]\n",
      "epoch:32 step:30365 [D loss: 0.688711, acc.: 52.34%] [G loss: 0.908409]\n",
      "epoch:32 step:30366 [D loss: 0.620667, acc.: 66.41%] [G loss: 0.946832]\n",
      "epoch:32 step:30367 [D loss: 0.642880, acc.: 64.84%] [G loss: 0.949032]\n",
      "epoch:32 step:30368 [D loss: 0.648432, acc.: 57.03%] [G loss: 0.914199]\n",
      "epoch:32 step:30369 [D loss: 0.673135, acc.: 57.03%] [G loss: 0.934011]\n",
      "epoch:32 step:30370 [D loss: 0.615042, acc.: 71.88%] [G loss: 0.861578]\n",
      "epoch:32 step:30371 [D loss: 0.636694, acc.: 60.16%] [G loss: 0.906863]\n",
      "epoch:32 step:30372 [D loss: 0.679567, acc.: 54.69%] [G loss: 0.896098]\n",
      "epoch:32 step:30373 [D loss: 0.630471, acc.: 67.97%] [G loss: 0.889760]\n",
      "epoch:32 step:30374 [D loss: 0.684998, acc.: 60.16%] [G loss: 0.848350]\n",
      "epoch:32 step:30375 [D loss: 0.659944, acc.: 62.50%] [G loss: 0.883042]\n",
      "epoch:32 step:30376 [D loss: 0.620058, acc.: 68.75%] [G loss: 0.983062]\n",
      "epoch:32 step:30377 [D loss: 0.667757, acc.: 60.94%] [G loss: 0.886766]\n",
      "epoch:32 step:30378 [D loss: 0.651816, acc.: 58.59%] [G loss: 0.855056]\n",
      "epoch:32 step:30379 [D loss: 0.666275, acc.: 57.03%] [G loss: 0.942080]\n",
      "epoch:32 step:30380 [D loss: 0.645800, acc.: 64.06%] [G loss: 0.891399]\n",
      "epoch:32 step:30381 [D loss: 0.649879, acc.: 59.38%] [G loss: 0.974156]\n",
      "epoch:32 step:30382 [D loss: 0.658208, acc.: 60.16%] [G loss: 0.898399]\n",
      "epoch:32 step:30383 [D loss: 0.649099, acc.: 59.38%] [G loss: 0.874088]\n",
      "epoch:32 step:30384 [D loss: 0.663726, acc.: 60.16%] [G loss: 0.888053]\n",
      "epoch:32 step:30385 [D loss: 0.613101, acc.: 70.31%] [G loss: 0.958683]\n",
      "epoch:32 step:30386 [D loss: 0.630675, acc.: 64.06%] [G loss: 0.922939]\n",
      "epoch:32 step:30387 [D loss: 0.657249, acc.: 63.28%] [G loss: 0.918189]\n",
      "epoch:32 step:30388 [D loss: 0.664601, acc.: 62.50%] [G loss: 0.954292]\n",
      "epoch:32 step:30389 [D loss: 0.642709, acc.: 65.62%] [G loss: 0.964370]\n",
      "epoch:32 step:30390 [D loss: 0.613101, acc.: 67.97%] [G loss: 0.951766]\n",
      "epoch:32 step:30391 [D loss: 0.652452, acc.: 63.28%] [G loss: 0.963768]\n",
      "epoch:32 step:30392 [D loss: 0.660684, acc.: 60.16%] [G loss: 0.942959]\n",
      "epoch:32 step:30393 [D loss: 0.672858, acc.: 60.94%] [G loss: 0.928616]\n",
      "epoch:32 step:30394 [D loss: 0.676042, acc.: 57.81%] [G loss: 0.854523]\n",
      "epoch:32 step:30395 [D loss: 0.626909, acc.: 65.62%] [G loss: 0.925916]\n",
      "epoch:32 step:30396 [D loss: 0.659644, acc.: 57.81%] [G loss: 0.937416]\n",
      "epoch:32 step:30397 [D loss: 0.677106, acc.: 53.91%] [G loss: 0.864302]\n",
      "epoch:32 step:30398 [D loss: 0.626281, acc.: 65.62%] [G loss: 0.847019]\n",
      "epoch:32 step:30399 [D loss: 0.683175, acc.: 55.47%] [G loss: 0.918660]\n",
      "epoch:32 step:30400 [D loss: 0.612165, acc.: 64.06%] [G loss: 0.910309]\n",
      "##############\n",
      "[ 3.06153622  2.57311933  2.591477    3.67226096  1.12288882 10.27426719\n",
      "  2.81522074  3.43527302  4.32251421  7.14868929]\n",
      "##########\n",
      "epoch:32 step:30401 [D loss: 0.628522, acc.: 68.75%] [G loss: 0.924847]\n",
      "epoch:32 step:30402 [D loss: 0.679615, acc.: 57.03%] [G loss: 0.878166]\n",
      "epoch:32 step:30403 [D loss: 0.640595, acc.: 58.59%] [G loss: 0.860423]\n",
      "epoch:32 step:30404 [D loss: 0.625258, acc.: 63.28%] [G loss: 0.949791]\n",
      "epoch:32 step:30405 [D loss: 0.665455, acc.: 60.94%] [G loss: 0.925168]\n",
      "epoch:32 step:30406 [D loss: 0.658985, acc.: 57.03%] [G loss: 0.923491]\n",
      "epoch:32 step:30407 [D loss: 0.614753, acc.: 64.84%] [G loss: 0.913029]\n",
      "epoch:32 step:30408 [D loss: 0.641491, acc.: 62.50%] [G loss: 1.012509]\n",
      "epoch:32 step:30409 [D loss: 0.641425, acc.: 64.06%] [G loss: 0.999828]\n",
      "epoch:32 step:30410 [D loss: 0.634228, acc.: 64.06%] [G loss: 0.926541]\n",
      "epoch:32 step:30411 [D loss: 0.661271, acc.: 60.16%] [G loss: 0.973281]\n",
      "epoch:32 step:30412 [D loss: 0.672780, acc.: 57.03%] [G loss: 0.915349]\n",
      "epoch:32 step:30413 [D loss: 0.652767, acc.: 57.03%] [G loss: 0.921891]\n",
      "epoch:32 step:30414 [D loss: 0.660471, acc.: 64.84%] [G loss: 0.949098]\n",
      "epoch:32 step:30415 [D loss: 0.688462, acc.: 51.56%] [G loss: 0.907103]\n",
      "epoch:32 step:30416 [D loss: 0.639041, acc.: 63.28%] [G loss: 0.920774]\n",
      "epoch:32 step:30417 [D loss: 0.673317, acc.: 60.94%] [G loss: 0.892732]\n",
      "epoch:32 step:30418 [D loss: 0.665414, acc.: 59.38%] [G loss: 0.860033]\n",
      "epoch:32 step:30419 [D loss: 0.630229, acc.: 65.62%] [G loss: 0.866473]\n",
      "epoch:32 step:30420 [D loss: 0.662416, acc.: 55.47%] [G loss: 0.929687]\n",
      "epoch:32 step:30421 [D loss: 0.658252, acc.: 62.50%] [G loss: 0.873145]\n",
      "epoch:32 step:30422 [D loss: 0.661416, acc.: 54.69%] [G loss: 0.897590]\n",
      "epoch:32 step:30423 [D loss: 0.651439, acc.: 57.03%] [G loss: 0.891346]\n",
      "epoch:32 step:30424 [D loss: 0.686787, acc.: 53.12%] [G loss: 0.906277]\n",
      "epoch:32 step:30425 [D loss: 0.660774, acc.: 63.28%] [G loss: 0.926136]\n",
      "epoch:32 step:30426 [D loss: 0.661813, acc.: 64.06%] [G loss: 0.871129]\n",
      "epoch:32 step:30427 [D loss: 0.653112, acc.: 64.84%] [G loss: 0.901105]\n",
      "epoch:32 step:30428 [D loss: 0.647160, acc.: 63.28%] [G loss: 0.935954]\n",
      "epoch:32 step:30429 [D loss: 0.648342, acc.: 60.16%] [G loss: 0.918357]\n",
      "epoch:32 step:30430 [D loss: 0.706170, acc.: 53.91%] [G loss: 0.976516]\n",
      "epoch:32 step:30431 [D loss: 0.648597, acc.: 60.94%] [G loss: 0.923319]\n",
      "epoch:32 step:30432 [D loss: 0.664252, acc.: 60.16%] [G loss: 0.851263]\n",
      "epoch:32 step:30433 [D loss: 0.644761, acc.: 57.03%] [G loss: 0.884788]\n",
      "epoch:32 step:30434 [D loss: 0.650725, acc.: 60.94%] [G loss: 0.927743]\n",
      "epoch:32 step:30435 [D loss: 0.605486, acc.: 66.41%] [G loss: 0.890835]\n",
      "epoch:32 step:30436 [D loss: 0.665197, acc.: 58.59%] [G loss: 0.883150]\n",
      "epoch:32 step:30437 [D loss: 0.639682, acc.: 63.28%] [G loss: 0.970387]\n",
      "epoch:32 step:30438 [D loss: 0.694731, acc.: 53.12%] [G loss: 0.897275]\n",
      "epoch:32 step:30439 [D loss: 0.626031, acc.: 62.50%] [G loss: 0.897521]\n",
      "epoch:32 step:30440 [D loss: 0.691310, acc.: 56.25%] [G loss: 0.967897]\n",
      "epoch:32 step:30441 [D loss: 0.653288, acc.: 59.38%] [G loss: 0.941357]\n",
      "epoch:32 step:30442 [D loss: 0.681980, acc.: 54.69%] [G loss: 0.935852]\n",
      "epoch:32 step:30443 [D loss: 0.569947, acc.: 73.44%] [G loss: 0.910891]\n",
      "epoch:32 step:30444 [D loss: 0.653485, acc.: 59.38%] [G loss: 0.920319]\n",
      "epoch:32 step:30445 [D loss: 0.655094, acc.: 57.03%] [G loss: 0.894074]\n",
      "epoch:32 step:30446 [D loss: 0.662022, acc.: 57.81%] [G loss: 0.924439]\n",
      "epoch:32 step:30447 [D loss: 0.655438, acc.: 61.72%] [G loss: 0.901119]\n",
      "epoch:32 step:30448 [D loss: 0.663109, acc.: 57.03%] [G loss: 0.922842]\n",
      "epoch:32 step:30449 [D loss: 0.643080, acc.: 64.84%] [G loss: 0.922291]\n",
      "epoch:32 step:30450 [D loss: 0.684788, acc.: 55.47%] [G loss: 0.944939]\n",
      "epoch:32 step:30451 [D loss: 0.629467, acc.: 68.75%] [G loss: 0.978865]\n",
      "epoch:32 step:30452 [D loss: 0.603502, acc.: 71.09%] [G loss: 0.990059]\n",
      "epoch:32 step:30453 [D loss: 0.597005, acc.: 73.44%] [G loss: 0.965805]\n",
      "epoch:32 step:30454 [D loss: 0.683790, acc.: 57.03%] [G loss: 0.938053]\n",
      "epoch:32 step:30455 [D loss: 0.610035, acc.: 67.19%] [G loss: 0.916652]\n",
      "epoch:32 step:30456 [D loss: 0.639534, acc.: 67.19%] [G loss: 0.944219]\n",
      "epoch:32 step:30457 [D loss: 0.620077, acc.: 61.72%] [G loss: 0.908154]\n",
      "epoch:32 step:30458 [D loss: 0.647619, acc.: 57.03%] [G loss: 0.904506]\n",
      "epoch:32 step:30459 [D loss: 0.637948, acc.: 65.62%] [G loss: 1.013319]\n",
      "epoch:32 step:30460 [D loss: 0.655458, acc.: 62.50%] [G loss: 0.950805]\n",
      "epoch:32 step:30461 [D loss: 0.694198, acc.: 57.03%] [G loss: 1.017383]\n",
      "epoch:32 step:30462 [D loss: 0.621876, acc.: 69.53%] [G loss: 0.927439]\n",
      "epoch:32 step:30463 [D loss: 0.682359, acc.: 53.91%] [G loss: 0.961289]\n",
      "epoch:32 step:30464 [D loss: 0.641443, acc.: 61.72%] [G loss: 0.900914]\n",
      "epoch:32 step:30465 [D loss: 0.640434, acc.: 66.41%] [G loss: 0.875278]\n",
      "epoch:32 step:30466 [D loss: 0.677772, acc.: 60.94%] [G loss: 0.893525]\n",
      "epoch:32 step:30467 [D loss: 0.651503, acc.: 64.06%] [G loss: 0.867032]\n",
      "epoch:32 step:30468 [D loss: 0.653392, acc.: 57.81%] [G loss: 0.903859]\n",
      "epoch:32 step:30469 [D loss: 0.631599, acc.: 64.84%] [G loss: 0.933206]\n",
      "epoch:32 step:30470 [D loss: 0.638411, acc.: 65.62%] [G loss: 0.912134]\n",
      "epoch:32 step:30471 [D loss: 0.699977, acc.: 53.12%] [G loss: 0.915610]\n",
      "epoch:32 step:30472 [D loss: 0.624857, acc.: 64.84%] [G loss: 0.924349]\n",
      "epoch:32 step:30473 [D loss: 0.630465, acc.: 63.28%] [G loss: 1.012733]\n",
      "epoch:32 step:30474 [D loss: 0.636585, acc.: 64.06%] [G loss: 0.991716]\n",
      "epoch:32 step:30475 [D loss: 0.674751, acc.: 61.72%] [G loss: 0.906150]\n",
      "epoch:32 step:30476 [D loss: 0.684614, acc.: 55.47%] [G loss: 0.943314]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:30477 [D loss: 0.647075, acc.: 59.38%] [G loss: 0.933081]\n",
      "epoch:32 step:30478 [D loss: 0.609763, acc.: 64.84%] [G loss: 0.885691]\n",
      "epoch:32 step:30479 [D loss: 0.658152, acc.: 60.94%] [G loss: 0.897578]\n",
      "epoch:32 step:30480 [D loss: 0.638512, acc.: 59.38%] [G loss: 0.972632]\n",
      "epoch:32 step:30481 [D loss: 0.673115, acc.: 56.25%] [G loss: 0.860484]\n",
      "epoch:32 step:30482 [D loss: 0.700974, acc.: 52.34%] [G loss: 0.854811]\n",
      "epoch:32 step:30483 [D loss: 0.631559, acc.: 65.62%] [G loss: 0.850334]\n",
      "epoch:32 step:30484 [D loss: 0.650123, acc.: 61.72%] [G loss: 0.869631]\n",
      "epoch:32 step:30485 [D loss: 0.636286, acc.: 61.72%] [G loss: 0.886944]\n",
      "epoch:32 step:30486 [D loss: 0.614916, acc.: 63.28%] [G loss: 0.893117]\n",
      "epoch:32 step:30487 [D loss: 0.661848, acc.: 60.16%] [G loss: 0.967864]\n",
      "epoch:32 step:30488 [D loss: 0.647395, acc.: 63.28%] [G loss: 0.916563]\n",
      "epoch:32 step:30489 [D loss: 0.666263, acc.: 60.94%] [G loss: 0.918313]\n",
      "epoch:32 step:30490 [D loss: 0.618182, acc.: 68.75%] [G loss: 0.904480]\n",
      "epoch:32 step:30491 [D loss: 0.677581, acc.: 56.25%] [G loss: 0.921076]\n",
      "epoch:32 step:30492 [D loss: 0.618968, acc.: 67.97%] [G loss: 0.922385]\n",
      "epoch:32 step:30493 [D loss: 0.628375, acc.: 62.50%] [G loss: 0.914201]\n",
      "epoch:32 step:30494 [D loss: 0.599109, acc.: 68.75%] [G loss: 0.918590]\n",
      "epoch:32 step:30495 [D loss: 0.604363, acc.: 69.53%] [G loss: 0.958246]\n",
      "epoch:32 step:30496 [D loss: 0.644463, acc.: 59.38%] [G loss: 0.943174]\n",
      "epoch:32 step:30497 [D loss: 0.629726, acc.: 61.72%] [G loss: 0.929917]\n",
      "epoch:32 step:30498 [D loss: 0.649305, acc.: 58.59%] [G loss: 0.950478]\n",
      "epoch:32 step:30499 [D loss: 0.654613, acc.: 61.72%] [G loss: 0.982335]\n",
      "epoch:32 step:30500 [D loss: 0.666403, acc.: 57.81%] [G loss: 0.903827]\n",
      "epoch:32 step:30501 [D loss: 0.657820, acc.: 57.81%] [G loss: 0.918230]\n",
      "epoch:32 step:30502 [D loss: 0.682617, acc.: 60.94%] [G loss: 0.866969]\n",
      "epoch:32 step:30503 [D loss: 0.637160, acc.: 65.62%] [G loss: 0.920104]\n",
      "epoch:32 step:30504 [D loss: 0.633694, acc.: 65.62%] [G loss: 0.963603]\n",
      "epoch:32 step:30505 [D loss: 0.643182, acc.: 60.94%] [G loss: 0.918745]\n",
      "epoch:32 step:30506 [D loss: 0.621712, acc.: 63.28%] [G loss: 0.943175]\n",
      "epoch:32 step:30507 [D loss: 0.658765, acc.: 62.50%] [G loss: 0.947016]\n",
      "epoch:32 step:30508 [D loss: 0.686045, acc.: 58.59%] [G loss: 0.952817]\n",
      "epoch:32 step:30509 [D loss: 0.622335, acc.: 61.72%] [G loss: 0.953336]\n",
      "epoch:32 step:30510 [D loss: 0.676953, acc.: 52.34%] [G loss: 0.936467]\n",
      "epoch:32 step:30511 [D loss: 0.661795, acc.: 60.16%] [G loss: 0.888937]\n",
      "epoch:32 step:30512 [D loss: 0.639946, acc.: 65.62%] [G loss: 0.909763]\n",
      "epoch:32 step:30513 [D loss: 0.627584, acc.: 64.06%] [G loss: 0.899135]\n",
      "epoch:32 step:30514 [D loss: 0.674909, acc.: 60.16%] [G loss: 0.939163]\n",
      "epoch:32 step:30515 [D loss: 0.615542, acc.: 67.19%] [G loss: 0.954808]\n",
      "epoch:32 step:30516 [D loss: 0.678109, acc.: 59.38%] [G loss: 0.955598]\n",
      "epoch:32 step:30517 [D loss: 0.638981, acc.: 63.28%] [G loss: 0.855980]\n",
      "epoch:32 step:30518 [D loss: 0.657443, acc.: 59.38%] [G loss: 0.871311]\n",
      "epoch:32 step:30519 [D loss: 0.611714, acc.: 67.19%] [G loss: 0.896964]\n",
      "epoch:32 step:30520 [D loss: 0.662332, acc.: 60.16%] [G loss: 0.933885]\n",
      "epoch:32 step:30521 [D loss: 0.641361, acc.: 60.94%] [G loss: 0.964380]\n",
      "epoch:32 step:30522 [D loss: 0.654610, acc.: 63.28%] [G loss: 0.935340]\n",
      "epoch:32 step:30523 [D loss: 0.695838, acc.: 57.81%] [G loss: 0.909775]\n",
      "epoch:32 step:30524 [D loss: 0.632629, acc.: 60.94%] [G loss: 0.952947]\n",
      "epoch:32 step:30525 [D loss: 0.684862, acc.: 54.69%] [G loss: 0.961401]\n",
      "epoch:32 step:30526 [D loss: 0.638501, acc.: 67.19%] [G loss: 0.975034]\n",
      "epoch:32 step:30527 [D loss: 0.597612, acc.: 71.09%] [G loss: 0.923394]\n",
      "epoch:32 step:30528 [D loss: 0.657485, acc.: 61.72%] [G loss: 0.947396]\n",
      "epoch:32 step:30529 [D loss: 0.605256, acc.: 67.97%] [G loss: 0.902291]\n",
      "epoch:32 step:30530 [D loss: 0.657586, acc.: 59.38%] [G loss: 0.893536]\n",
      "epoch:32 step:30531 [D loss: 0.646916, acc.: 60.16%] [G loss: 0.870770]\n",
      "epoch:32 step:30532 [D loss: 0.663947, acc.: 57.03%] [G loss: 0.848866]\n",
      "epoch:32 step:30533 [D loss: 0.662087, acc.: 60.94%] [G loss: 0.864770]\n",
      "epoch:32 step:30534 [D loss: 0.664973, acc.: 61.72%] [G loss: 0.942285]\n",
      "epoch:32 step:30535 [D loss: 0.660860, acc.: 66.41%] [G loss: 0.923041]\n",
      "epoch:32 step:30536 [D loss: 0.611044, acc.: 67.97%] [G loss: 0.947411]\n",
      "epoch:32 step:30537 [D loss: 0.671741, acc.: 54.69%] [G loss: 0.958657]\n",
      "epoch:32 step:30538 [D loss: 0.650107, acc.: 63.28%] [G loss: 1.055315]\n",
      "epoch:32 step:30539 [D loss: 0.655544, acc.: 62.50%] [G loss: 0.918731]\n",
      "epoch:32 step:30540 [D loss: 0.659373, acc.: 58.59%] [G loss: 0.876560]\n",
      "epoch:32 step:30541 [D loss: 0.626195, acc.: 67.19%] [G loss: 0.873711]\n",
      "epoch:32 step:30542 [D loss: 0.604629, acc.: 63.28%] [G loss: 0.898076]\n",
      "epoch:32 step:30543 [D loss: 0.682231, acc.: 53.91%] [G loss: 0.928112]\n",
      "epoch:32 step:30544 [D loss: 0.633456, acc.: 59.38%] [G loss: 0.880036]\n",
      "epoch:32 step:30545 [D loss: 0.652054, acc.: 58.59%] [G loss: 0.880889]\n",
      "epoch:32 step:30546 [D loss: 0.641557, acc.: 66.41%] [G loss: 0.929898]\n",
      "epoch:32 step:30547 [D loss: 0.651951, acc.: 61.72%] [G loss: 0.914747]\n",
      "epoch:32 step:30548 [D loss: 0.653538, acc.: 64.06%] [G loss: 0.948237]\n",
      "epoch:32 step:30549 [D loss: 0.667722, acc.: 60.16%] [G loss: 0.965955]\n",
      "epoch:32 step:30550 [D loss: 0.645420, acc.: 61.72%] [G loss: 0.936352]\n",
      "epoch:32 step:30551 [D loss: 0.632917, acc.: 63.28%] [G loss: 0.930146]\n",
      "epoch:32 step:30552 [D loss: 0.670596, acc.: 61.72%] [G loss: 0.922682]\n",
      "epoch:32 step:30553 [D loss: 0.642107, acc.: 66.41%] [G loss: 0.970477]\n",
      "epoch:32 step:30554 [D loss: 0.650351, acc.: 64.06%] [G loss: 0.998498]\n",
      "epoch:32 step:30555 [D loss: 0.594046, acc.: 67.97%] [G loss: 0.993765]\n",
      "epoch:32 step:30556 [D loss: 0.654520, acc.: 61.72%] [G loss: 0.917892]\n",
      "epoch:32 step:30557 [D loss: 0.667972, acc.: 61.72%] [G loss: 0.828347]\n",
      "epoch:32 step:30558 [D loss: 0.681584, acc.: 59.38%] [G loss: 0.909455]\n",
      "epoch:32 step:30559 [D loss: 0.651622, acc.: 61.72%] [G loss: 0.801424]\n",
      "epoch:32 step:30560 [D loss: 0.618929, acc.: 63.28%] [G loss: 0.907520]\n",
      "epoch:32 step:30561 [D loss: 0.595289, acc.: 72.66%] [G loss: 0.888626]\n",
      "epoch:32 step:30562 [D loss: 0.607633, acc.: 69.53%] [G loss: 0.916256]\n",
      "epoch:32 step:30563 [D loss: 0.643583, acc.: 62.50%] [G loss: 0.897614]\n",
      "epoch:32 step:30564 [D loss: 0.643161, acc.: 61.72%] [G loss: 0.904135]\n",
      "epoch:32 step:30565 [D loss: 0.614970, acc.: 64.06%] [G loss: 0.890305]\n",
      "epoch:32 step:30566 [D loss: 0.604703, acc.: 64.06%] [G loss: 0.930476]\n",
      "epoch:32 step:30567 [D loss: 0.695800, acc.: 53.12%] [G loss: 0.874875]\n",
      "epoch:32 step:30568 [D loss: 0.651313, acc.: 59.38%] [G loss: 0.950998]\n",
      "epoch:32 step:30569 [D loss: 0.633997, acc.: 64.06%] [G loss: 0.926958]\n",
      "epoch:32 step:30570 [D loss: 0.671248, acc.: 59.38%] [G loss: 0.942846]\n",
      "epoch:32 step:30571 [D loss: 0.655139, acc.: 64.84%] [G loss: 0.892034]\n",
      "epoch:32 step:30572 [D loss: 0.632388, acc.: 66.41%] [G loss: 0.984378]\n",
      "epoch:32 step:30573 [D loss: 0.664606, acc.: 62.50%] [G loss: 0.961440]\n",
      "epoch:32 step:30574 [D loss: 0.653253, acc.: 64.06%] [G loss: 0.948116]\n",
      "epoch:32 step:30575 [D loss: 0.674263, acc.: 64.06%] [G loss: 0.947560]\n",
      "epoch:32 step:30576 [D loss: 0.635180, acc.: 66.41%] [G loss: 0.906636]\n",
      "epoch:32 step:30577 [D loss: 0.684515, acc.: 52.34%] [G loss: 0.946169]\n",
      "epoch:32 step:30578 [D loss: 0.611099, acc.: 63.28%] [G loss: 0.914614]\n",
      "epoch:32 step:30579 [D loss: 0.667865, acc.: 61.72%] [G loss: 0.920030]\n",
      "epoch:32 step:30580 [D loss: 0.627683, acc.: 71.09%] [G loss: 0.861119]\n",
      "epoch:32 step:30581 [D loss: 0.634485, acc.: 64.84%] [G loss: 0.969287]\n",
      "epoch:32 step:30582 [D loss: 0.687872, acc.: 60.16%] [G loss: 0.953581]\n",
      "epoch:32 step:30583 [D loss: 0.604622, acc.: 67.97%] [G loss: 0.968458]\n",
      "epoch:32 step:30584 [D loss: 0.611861, acc.: 62.50%] [G loss: 0.956038]\n",
      "epoch:32 step:30585 [D loss: 0.658480, acc.: 59.38%] [G loss: 0.951915]\n",
      "epoch:32 step:30586 [D loss: 0.634304, acc.: 61.72%] [G loss: 0.884747]\n",
      "epoch:32 step:30587 [D loss: 0.647427, acc.: 63.28%] [G loss: 0.877224]\n",
      "epoch:32 step:30588 [D loss: 0.641048, acc.: 62.50%] [G loss: 0.898389]\n",
      "epoch:32 step:30589 [D loss: 0.657824, acc.: 60.94%] [G loss: 0.885108]\n",
      "epoch:32 step:30590 [D loss: 0.621515, acc.: 66.41%] [G loss: 0.951548]\n",
      "epoch:32 step:30591 [D loss: 0.648795, acc.: 65.62%] [G loss: 0.940049]\n",
      "epoch:32 step:30592 [D loss: 0.666147, acc.: 58.59%] [G loss: 0.902935]\n",
      "epoch:32 step:30593 [D loss: 0.621303, acc.: 66.41%] [G loss: 0.915418]\n",
      "epoch:32 step:30594 [D loss: 0.680293, acc.: 53.91%] [G loss: 0.870563]\n",
      "epoch:32 step:30595 [D loss: 0.649430, acc.: 59.38%] [G loss: 0.936790]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:30596 [D loss: 0.647846, acc.: 65.62%] [G loss: 0.863778]\n",
      "epoch:32 step:30597 [D loss: 0.646320, acc.: 61.72%] [G loss: 0.861647]\n",
      "epoch:32 step:30598 [D loss: 0.662303, acc.: 53.91%] [G loss: 0.878983]\n",
      "epoch:32 step:30599 [D loss: 0.659791, acc.: 57.03%] [G loss: 0.875378]\n",
      "epoch:32 step:30600 [D loss: 0.661328, acc.: 60.94%] [G loss: 0.892334]\n",
      "##############\n",
      "[3.12050167 2.71007558 2.46917073 4.15842146 1.32713253 8.12953864\n",
      " 2.74655745 3.95581632 4.35558275 6.02045919]\n",
      "##########\n",
      "epoch:32 step:30601 [D loss: 0.641714, acc.: 64.06%] [G loss: 0.918707]\n",
      "epoch:32 step:30602 [D loss: 0.655031, acc.: 62.50%] [G loss: 0.872120]\n",
      "epoch:32 step:30603 [D loss: 0.636309, acc.: 67.97%] [G loss: 0.948734]\n",
      "epoch:32 step:30604 [D loss: 0.660496, acc.: 60.94%] [G loss: 0.968503]\n",
      "epoch:32 step:30605 [D loss: 0.673640, acc.: 62.50%] [G loss: 0.920282]\n",
      "epoch:32 step:30606 [D loss: 0.675433, acc.: 55.47%] [G loss: 0.892534]\n",
      "epoch:32 step:30607 [D loss: 0.643090, acc.: 60.16%] [G loss: 0.942153]\n",
      "epoch:32 step:30608 [D loss: 0.647116, acc.: 62.50%] [G loss: 1.044574]\n",
      "epoch:32 step:30609 [D loss: 0.644010, acc.: 62.50%] [G loss: 0.916679]\n",
      "epoch:32 step:30610 [D loss: 0.645819, acc.: 57.03%] [G loss: 0.936706]\n",
      "epoch:32 step:30611 [D loss: 0.626817, acc.: 64.84%] [G loss: 0.916291]\n",
      "epoch:32 step:30612 [D loss: 0.694893, acc.: 51.56%] [G loss: 0.877582]\n",
      "epoch:32 step:30613 [D loss: 0.644675, acc.: 63.28%] [G loss: 0.913282]\n",
      "epoch:32 step:30614 [D loss: 0.672086, acc.: 56.25%] [G loss: 0.897666]\n",
      "epoch:32 step:30615 [D loss: 0.609989, acc.: 64.84%] [G loss: 0.871496]\n",
      "epoch:32 step:30616 [D loss: 0.620801, acc.: 64.84%] [G loss: 0.931267]\n",
      "epoch:32 step:30617 [D loss: 0.661600, acc.: 60.94%] [G loss: 0.901574]\n",
      "epoch:32 step:30618 [D loss: 0.620904, acc.: 63.28%] [G loss: 0.918392]\n",
      "epoch:32 step:30619 [D loss: 0.676690, acc.: 57.03%] [G loss: 0.937773]\n",
      "epoch:32 step:30620 [D loss: 0.635356, acc.: 65.62%] [G loss: 0.933447]\n",
      "epoch:32 step:30621 [D loss: 0.635293, acc.: 60.94%] [G loss: 0.879535]\n",
      "epoch:32 step:30622 [D loss: 0.620839, acc.: 66.41%] [G loss: 0.970455]\n",
      "epoch:32 step:30623 [D loss: 0.667443, acc.: 59.38%] [G loss: 0.988153]\n",
      "epoch:32 step:30624 [D loss: 0.620655, acc.: 66.41%] [G loss: 0.961677]\n",
      "epoch:32 step:30625 [D loss: 0.669363, acc.: 57.81%] [G loss: 0.931447]\n",
      "epoch:32 step:30626 [D loss: 0.639246, acc.: 65.62%] [G loss: 0.995889]\n",
      "epoch:32 step:30627 [D loss: 0.700078, acc.: 53.12%] [G loss: 0.910549]\n",
      "epoch:32 step:30628 [D loss: 0.613798, acc.: 64.06%] [G loss: 0.921137]\n",
      "epoch:32 step:30629 [D loss: 0.601302, acc.: 67.97%] [G loss: 0.951182]\n",
      "epoch:32 step:30630 [D loss: 0.677807, acc.: 53.91%] [G loss: 0.938519]\n",
      "epoch:32 step:30631 [D loss: 0.635868, acc.: 64.06%] [G loss: 0.916554]\n",
      "epoch:32 step:30632 [D loss: 0.661262, acc.: 58.59%] [G loss: 0.907230]\n",
      "epoch:32 step:30633 [D loss: 0.671649, acc.: 55.47%] [G loss: 0.923005]\n",
      "epoch:32 step:30634 [D loss: 0.626643, acc.: 61.72%] [G loss: 0.951815]\n",
      "epoch:32 step:30635 [D loss: 0.620131, acc.: 64.84%] [G loss: 0.860957]\n",
      "epoch:32 step:30636 [D loss: 0.607939, acc.: 70.31%] [G loss: 0.909069]\n",
      "epoch:32 step:30637 [D loss: 0.622151, acc.: 64.84%] [G loss: 0.830029]\n",
      "epoch:32 step:30638 [D loss: 0.632779, acc.: 64.06%] [G loss: 0.901823]\n",
      "epoch:32 step:30639 [D loss: 0.682051, acc.: 56.25%] [G loss: 0.906674]\n",
      "epoch:32 step:30640 [D loss: 0.613992, acc.: 69.53%] [G loss: 0.937989]\n",
      "epoch:32 step:30641 [D loss: 0.608857, acc.: 64.06%] [G loss: 0.902641]\n",
      "epoch:32 step:30642 [D loss: 0.753520, acc.: 52.34%] [G loss: 0.858510]\n",
      "epoch:32 step:30643 [D loss: 0.734956, acc.: 44.53%] [G loss: 0.843904]\n",
      "epoch:32 step:30644 [D loss: 0.671129, acc.: 60.16%] [G loss: 0.893243]\n",
      "epoch:32 step:30645 [D loss: 0.632081, acc.: 64.06%] [G loss: 0.940819]\n",
      "epoch:32 step:30646 [D loss: 0.667551, acc.: 59.38%] [G loss: 0.882187]\n",
      "epoch:32 step:30647 [D loss: 0.653270, acc.: 64.06%] [G loss: 0.936756]\n",
      "epoch:32 step:30648 [D loss: 0.647444, acc.: 64.84%] [G loss: 0.975616]\n",
      "epoch:32 step:30649 [D loss: 0.690956, acc.: 56.25%] [G loss: 0.937422]\n",
      "epoch:32 step:30650 [D loss: 0.620520, acc.: 68.75%] [G loss: 0.958486]\n",
      "epoch:32 step:30651 [D loss: 0.640373, acc.: 65.62%] [G loss: 0.933202]\n",
      "epoch:32 step:30652 [D loss: 0.663429, acc.: 58.59%] [G loss: 0.889278]\n",
      "epoch:32 step:30653 [D loss: 0.601567, acc.: 63.28%] [G loss: 0.925790]\n",
      "epoch:32 step:30654 [D loss: 0.670536, acc.: 53.12%] [G loss: 0.938008]\n",
      "epoch:32 step:30655 [D loss: 0.647989, acc.: 58.59%] [G loss: 0.907875]\n",
      "epoch:32 step:30656 [D loss: 0.643870, acc.: 60.16%] [G loss: 0.902305]\n",
      "epoch:32 step:30657 [D loss: 0.651526, acc.: 59.38%] [G loss: 1.013705]\n",
      "epoch:32 step:30658 [D loss: 0.644015, acc.: 62.50%] [G loss: 0.958422]\n",
      "epoch:32 step:30659 [D loss: 0.665277, acc.: 57.81%] [G loss: 0.929968]\n",
      "epoch:32 step:30660 [D loss: 0.654592, acc.: 63.28%] [G loss: 0.965872]\n",
      "epoch:32 step:30661 [D loss: 0.653384, acc.: 57.81%] [G loss: 0.907548]\n",
      "epoch:32 step:30662 [D loss: 0.655044, acc.: 59.38%] [G loss: 0.881665]\n",
      "epoch:32 step:30663 [D loss: 0.629097, acc.: 61.72%] [G loss: 0.965648]\n",
      "epoch:32 step:30664 [D loss: 0.652830, acc.: 61.72%] [G loss: 0.914477]\n",
      "epoch:32 step:30665 [D loss: 0.657161, acc.: 58.59%] [G loss: 0.934328]\n",
      "epoch:32 step:30666 [D loss: 0.674438, acc.: 55.47%] [G loss: 0.959223]\n",
      "epoch:32 step:30667 [D loss: 0.662931, acc.: 57.81%] [G loss: 0.970058]\n",
      "epoch:32 step:30668 [D loss: 0.638113, acc.: 64.84%] [G loss: 1.007130]\n",
      "epoch:32 step:30669 [D loss: 0.646048, acc.: 64.84%] [G loss: 0.948028]\n",
      "epoch:32 step:30670 [D loss: 0.659506, acc.: 58.59%] [G loss: 1.025613]\n",
      "epoch:32 step:30671 [D loss: 0.637190, acc.: 60.16%] [G loss: 0.958168]\n",
      "epoch:32 step:30672 [D loss: 0.634978, acc.: 63.28%] [G loss: 0.865597]\n",
      "epoch:32 step:30673 [D loss: 0.647399, acc.: 60.94%] [G loss: 0.887686]\n",
      "epoch:32 step:30674 [D loss: 0.633860, acc.: 63.28%] [G loss: 0.988475]\n",
      "epoch:32 step:30675 [D loss: 0.640992, acc.: 59.38%] [G loss: 0.951087]\n",
      "epoch:32 step:30676 [D loss: 0.653313, acc.: 63.28%] [G loss: 0.863982]\n",
      "epoch:32 step:30677 [D loss: 0.670148, acc.: 54.69%] [G loss: 0.956977]\n",
      "epoch:32 step:30678 [D loss: 0.604202, acc.: 71.09%] [G loss: 0.871870]\n",
      "epoch:32 step:30679 [D loss: 0.645034, acc.: 59.38%] [G loss: 0.886241]\n",
      "epoch:32 step:30680 [D loss: 0.631870, acc.: 62.50%] [G loss: 0.911193]\n",
      "epoch:32 step:30681 [D loss: 0.620765, acc.: 70.31%] [G loss: 0.938223]\n",
      "epoch:32 step:30682 [D loss: 0.646837, acc.: 60.16%] [G loss: 0.895746]\n",
      "epoch:32 step:30683 [D loss: 0.674670, acc.: 55.47%] [G loss: 0.930027]\n",
      "epoch:32 step:30684 [D loss: 0.673051, acc.: 60.94%] [G loss: 0.961361]\n",
      "epoch:32 step:30685 [D loss: 0.665160, acc.: 54.69%] [G loss: 1.029902]\n",
      "epoch:32 step:30686 [D loss: 0.612558, acc.: 71.09%] [G loss: 0.955114]\n",
      "epoch:32 step:30687 [D loss: 0.706193, acc.: 52.34%] [G loss: 0.942121]\n",
      "epoch:32 step:30688 [D loss: 0.622924, acc.: 63.28%] [G loss: 0.931123]\n",
      "epoch:32 step:30689 [D loss: 0.642101, acc.: 64.06%] [G loss: 0.908056]\n",
      "epoch:32 step:30690 [D loss: 0.661295, acc.: 64.06%] [G loss: 0.913942]\n",
      "epoch:32 step:30691 [D loss: 0.663011, acc.: 56.25%] [G loss: 0.946204]\n",
      "epoch:32 step:30692 [D loss: 0.633372, acc.: 64.84%] [G loss: 0.896911]\n",
      "epoch:32 step:30693 [D loss: 0.739185, acc.: 46.09%] [G loss: 0.935923]\n",
      "epoch:32 step:30694 [D loss: 0.602925, acc.: 67.19%] [G loss: 0.948347]\n",
      "epoch:32 step:30695 [D loss: 0.650737, acc.: 60.94%] [G loss: 0.938133]\n",
      "epoch:32 step:30696 [D loss: 0.652883, acc.: 60.94%] [G loss: 0.850114]\n",
      "epoch:32 step:30697 [D loss: 0.637830, acc.: 67.19%] [G loss: 0.939017]\n",
      "epoch:32 step:30698 [D loss: 0.645659, acc.: 57.03%] [G loss: 0.970351]\n",
      "epoch:32 step:30699 [D loss: 0.706964, acc.: 53.12%] [G loss: 0.918249]\n",
      "epoch:32 step:30700 [D loss: 0.626169, acc.: 69.53%] [G loss: 0.941310]\n",
      "epoch:32 step:30701 [D loss: 0.625142, acc.: 64.06%] [G loss: 0.907756]\n",
      "epoch:32 step:30702 [D loss: 0.599574, acc.: 69.53%] [G loss: 0.944991]\n",
      "epoch:32 step:30703 [D loss: 0.647353, acc.: 63.28%] [G loss: 0.949408]\n",
      "epoch:32 step:30704 [D loss: 0.611433, acc.: 67.19%] [G loss: 0.880509]\n",
      "epoch:32 step:30705 [D loss: 0.606743, acc.: 70.31%] [G loss: 0.886789]\n",
      "epoch:32 step:30706 [D loss: 0.616479, acc.: 70.31%] [G loss: 0.908124]\n",
      "epoch:32 step:30707 [D loss: 0.671066, acc.: 57.03%] [G loss: 0.961038]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:30708 [D loss: 0.661085, acc.: 57.03%] [G loss: 0.894881]\n",
      "epoch:32 step:30709 [D loss: 0.643559, acc.: 64.84%] [G loss: 0.957955]\n",
      "epoch:32 step:30710 [D loss: 0.660680, acc.: 62.50%] [G loss: 0.937637]\n",
      "epoch:32 step:30711 [D loss: 0.632711, acc.: 64.84%] [G loss: 0.941693]\n",
      "epoch:32 step:30712 [D loss: 0.677350, acc.: 55.47%] [G loss: 0.979455]\n",
      "epoch:32 step:30713 [D loss: 0.648634, acc.: 64.06%] [G loss: 0.935516]\n",
      "epoch:32 step:30714 [D loss: 0.630930, acc.: 66.41%] [G loss: 0.893335]\n",
      "epoch:32 step:30715 [D loss: 0.620353, acc.: 64.84%] [G loss: 0.980971]\n",
      "epoch:32 step:30716 [D loss: 0.645513, acc.: 61.72%] [G loss: 0.911032]\n",
      "epoch:32 step:30717 [D loss: 0.655060, acc.: 57.03%] [G loss: 0.893081]\n",
      "epoch:32 step:30718 [D loss: 0.607341, acc.: 64.84%] [G loss: 0.994423]\n",
      "epoch:32 step:30719 [D loss: 0.647693, acc.: 58.59%] [G loss: 0.996856]\n",
      "epoch:32 step:30720 [D loss: 0.642316, acc.: 63.28%] [G loss: 0.932878]\n",
      "epoch:32 step:30721 [D loss: 0.637989, acc.: 60.94%] [G loss: 0.937477]\n",
      "epoch:32 step:30722 [D loss: 0.678916, acc.: 57.03%] [G loss: 0.928696]\n",
      "epoch:32 step:30723 [D loss: 0.639033, acc.: 66.41%] [G loss: 0.904991]\n",
      "epoch:32 step:30724 [D loss: 0.684214, acc.: 58.59%] [G loss: 0.990776]\n",
      "epoch:32 step:30725 [D loss: 0.647532, acc.: 61.72%] [G loss: 0.918568]\n",
      "epoch:32 step:30726 [D loss: 0.652695, acc.: 61.72%] [G loss: 0.947664]\n",
      "epoch:32 step:30727 [D loss: 0.623650, acc.: 67.97%] [G loss: 0.978262]\n",
      "epoch:32 step:30728 [D loss: 0.649240, acc.: 61.72%] [G loss: 0.945583]\n",
      "epoch:32 step:30729 [D loss: 0.613162, acc.: 70.31%] [G loss: 0.927691]\n",
      "epoch:32 step:30730 [D loss: 0.653023, acc.: 59.38%] [G loss: 0.910058]\n",
      "epoch:32 step:30731 [D loss: 0.629939, acc.: 64.06%] [G loss: 0.875829]\n",
      "epoch:32 step:30732 [D loss: 0.633123, acc.: 63.28%] [G loss: 0.932395]\n",
      "epoch:32 step:30733 [D loss: 0.654205, acc.: 60.16%] [G loss: 0.897879]\n",
      "epoch:32 step:30734 [D loss: 0.623175, acc.: 64.84%] [G loss: 0.951100]\n",
      "epoch:32 step:30735 [D loss: 0.613473, acc.: 66.41%] [G loss: 0.936127]\n",
      "epoch:32 step:30736 [D loss: 0.646810, acc.: 63.28%] [G loss: 0.917901]\n",
      "epoch:32 step:30737 [D loss: 0.662607, acc.: 59.38%] [G loss: 0.942399]\n",
      "epoch:32 step:30738 [D loss: 0.653279, acc.: 64.06%] [G loss: 0.969842]\n",
      "epoch:32 step:30739 [D loss: 0.655994, acc.: 60.94%] [G loss: 0.923499]\n",
      "epoch:32 step:30740 [D loss: 0.637825, acc.: 62.50%] [G loss: 0.930063]\n",
      "epoch:32 step:30741 [D loss: 0.612780, acc.: 68.75%] [G loss: 0.859245]\n",
      "epoch:32 step:30742 [D loss: 0.669214, acc.: 58.59%] [G loss: 0.848528]\n",
      "epoch:32 step:30743 [D loss: 0.653082, acc.: 60.16%] [G loss: 0.919527]\n",
      "epoch:32 step:30744 [D loss: 0.647091, acc.: 64.84%] [G loss: 0.920638]\n",
      "epoch:32 step:30745 [D loss: 0.694669, acc.: 53.12%] [G loss: 0.924827]\n",
      "epoch:32 step:30746 [D loss: 0.670083, acc.: 56.25%] [G loss: 0.967916]\n",
      "epoch:32 step:30747 [D loss: 0.654298, acc.: 57.81%] [G loss: 0.890464]\n",
      "epoch:32 step:30748 [D loss: 0.605788, acc.: 67.97%] [G loss: 0.898274]\n",
      "epoch:32 step:30749 [D loss: 0.634912, acc.: 60.94%] [G loss: 0.942204]\n",
      "epoch:32 step:30750 [D loss: 0.620244, acc.: 62.50%] [G loss: 0.948131]\n",
      "epoch:32 step:30751 [D loss: 0.678363, acc.: 57.81%] [G loss: 0.936843]\n",
      "epoch:32 step:30752 [D loss: 0.650342, acc.: 62.50%] [G loss: 0.907237]\n",
      "epoch:32 step:30753 [D loss: 0.640918, acc.: 64.06%] [G loss: 0.957995]\n",
      "epoch:32 step:30754 [D loss: 0.641167, acc.: 67.19%] [G loss: 0.920413]\n",
      "epoch:32 step:30755 [D loss: 0.642860, acc.: 62.50%] [G loss: 0.908877]\n",
      "epoch:32 step:30756 [D loss: 0.648464, acc.: 57.81%] [G loss: 0.889833]\n",
      "epoch:32 step:30757 [D loss: 0.635231, acc.: 61.72%] [G loss: 0.922663]\n",
      "epoch:32 step:30758 [D loss: 0.623761, acc.: 71.88%] [G loss: 0.922582]\n",
      "epoch:32 step:30759 [D loss: 0.651099, acc.: 57.03%] [G loss: 0.977754]\n",
      "epoch:32 step:30760 [D loss: 0.618370, acc.: 64.84%] [G loss: 0.901956]\n",
      "epoch:32 step:30761 [D loss: 0.638862, acc.: 63.28%] [G loss: 0.899142]\n",
      "epoch:32 step:30762 [D loss: 0.635390, acc.: 64.06%] [G loss: 0.884122]\n",
      "epoch:32 step:30763 [D loss: 0.649320, acc.: 61.72%] [G loss: 0.893926]\n",
      "epoch:32 step:30764 [D loss: 0.655863, acc.: 57.03%] [G loss: 0.901431]\n",
      "epoch:32 step:30765 [D loss: 0.646207, acc.: 64.84%] [G loss: 0.921615]\n",
      "epoch:32 step:30766 [D loss: 0.674194, acc.: 55.47%] [G loss: 0.935370]\n",
      "epoch:32 step:30767 [D loss: 0.626436, acc.: 65.62%] [G loss: 0.930511]\n",
      "epoch:32 step:30768 [D loss: 0.655434, acc.: 58.59%] [G loss: 0.873038]\n",
      "epoch:32 step:30769 [D loss: 0.655805, acc.: 60.94%] [G loss: 0.878728]\n",
      "epoch:32 step:30770 [D loss: 0.675010, acc.: 58.59%] [G loss: 0.880634]\n",
      "epoch:32 step:30771 [D loss: 0.644529, acc.: 64.06%] [G loss: 0.914190]\n",
      "epoch:32 step:30772 [D loss: 0.633564, acc.: 64.06%] [G loss: 0.885359]\n",
      "epoch:32 step:30773 [D loss: 0.637704, acc.: 64.84%] [G loss: 0.942970]\n",
      "epoch:32 step:30774 [D loss: 0.666285, acc.: 57.03%] [G loss: 0.917336]\n",
      "epoch:32 step:30775 [D loss: 0.682315, acc.: 58.59%] [G loss: 0.921797]\n",
      "epoch:32 step:30776 [D loss: 0.650910, acc.: 67.19%] [G loss: 0.895436]\n",
      "epoch:32 step:30777 [D loss: 0.629586, acc.: 65.62%] [G loss: 0.907274]\n",
      "epoch:32 step:30778 [D loss: 0.637750, acc.: 64.06%] [G loss: 0.949723]\n",
      "epoch:32 step:30779 [D loss: 0.628911, acc.: 61.72%] [G loss: 0.858828]\n",
      "epoch:32 step:30780 [D loss: 0.634310, acc.: 61.72%] [G loss: 0.909743]\n",
      "epoch:32 step:30781 [D loss: 0.681160, acc.: 57.81%] [G loss: 0.905032]\n",
      "epoch:32 step:30782 [D loss: 0.620457, acc.: 68.75%] [G loss: 0.872842]\n",
      "epoch:32 step:30783 [D loss: 0.634411, acc.: 68.75%] [G loss: 0.931938]\n",
      "epoch:32 step:30784 [D loss: 0.683457, acc.: 59.38%] [G loss: 0.933638]\n",
      "epoch:32 step:30785 [D loss: 0.630704, acc.: 61.72%] [G loss: 0.903300]\n",
      "epoch:32 step:30786 [D loss: 0.668870, acc.: 58.59%] [G loss: 0.941157]\n",
      "epoch:32 step:30787 [D loss: 0.653142, acc.: 65.62%] [G loss: 0.971956]\n",
      "epoch:32 step:30788 [D loss: 0.707546, acc.: 50.78%] [G loss: 0.907402]\n",
      "epoch:32 step:30789 [D loss: 0.674298, acc.: 53.91%] [G loss: 0.876776]\n",
      "epoch:32 step:30790 [D loss: 0.642075, acc.: 60.94%] [G loss: 0.897273]\n",
      "epoch:32 step:30791 [D loss: 0.679594, acc.: 59.38%] [G loss: 0.915089]\n",
      "epoch:32 step:30792 [D loss: 0.638082, acc.: 61.72%] [G loss: 0.946854]\n",
      "epoch:32 step:30793 [D loss: 0.668929, acc.: 58.59%] [G loss: 0.883628]\n",
      "epoch:32 step:30794 [D loss: 0.660102, acc.: 57.81%] [G loss: 0.919131]\n",
      "epoch:32 step:30795 [D loss: 0.656720, acc.: 63.28%] [G loss: 0.958750]\n",
      "epoch:32 step:30796 [D loss: 0.663266, acc.: 59.38%] [G loss: 0.963302]\n",
      "epoch:32 step:30797 [D loss: 0.623566, acc.: 68.75%] [G loss: 0.896442]\n",
      "epoch:32 step:30798 [D loss: 0.651887, acc.: 60.16%] [G loss: 0.848464]\n",
      "epoch:32 step:30799 [D loss: 0.664234, acc.: 58.59%] [G loss: 0.892722]\n",
      "epoch:32 step:30800 [D loss: 0.623279, acc.: 64.06%] [G loss: 0.932419]\n",
      "##############\n",
      "[2.93870178 2.45799824 2.09302292 3.637559   0.91307618 9.27426719\n",
      " 2.91409861 3.63681595 4.21446438 7.14868929]\n",
      "##########\n",
      "epoch:32 step:30801 [D loss: 0.709937, acc.: 50.78%] [G loss: 0.965831]\n",
      "epoch:32 step:30802 [D loss: 0.691954, acc.: 57.81%] [G loss: 0.941087]\n",
      "epoch:32 step:30803 [D loss: 0.635085, acc.: 64.06%] [G loss: 0.902829]\n",
      "epoch:32 step:30804 [D loss: 0.663022, acc.: 59.38%] [G loss: 0.901020]\n",
      "epoch:32 step:30805 [D loss: 0.643591, acc.: 59.38%] [G loss: 0.916501]\n",
      "epoch:32 step:30806 [D loss: 0.656949, acc.: 60.94%] [G loss: 0.909597]\n",
      "epoch:32 step:30807 [D loss: 0.710911, acc.: 51.56%] [G loss: 0.895160]\n",
      "epoch:32 step:30808 [D loss: 0.634194, acc.: 65.62%] [G loss: 0.919130]\n",
      "epoch:32 step:30809 [D loss: 0.641056, acc.: 65.62%] [G loss: 0.883287]\n",
      "epoch:32 step:30810 [D loss: 0.629246, acc.: 67.97%] [G loss: 0.949893]\n",
      "epoch:32 step:30811 [D loss: 0.660958, acc.: 60.16%] [G loss: 0.969075]\n",
      "epoch:32 step:30812 [D loss: 0.659017, acc.: 57.81%] [G loss: 0.915916]\n",
      "epoch:32 step:30813 [D loss: 0.652391, acc.: 60.94%] [G loss: 0.856838]\n",
      "epoch:32 step:30814 [D loss: 0.650195, acc.: 60.94%] [G loss: 0.921833]\n",
      "epoch:32 step:30815 [D loss: 0.649496, acc.: 64.06%] [G loss: 0.873611]\n",
      "epoch:32 step:30816 [D loss: 0.647399, acc.: 60.16%] [G loss: 0.873469]\n",
      "epoch:32 step:30817 [D loss: 0.643840, acc.: 60.16%] [G loss: 0.934160]\n",
      "epoch:32 step:30818 [D loss: 0.689366, acc.: 47.66%] [G loss: 0.905474]\n",
      "epoch:32 step:30819 [D loss: 0.654756, acc.: 60.16%] [G loss: 0.994061]\n",
      "epoch:32 step:30820 [D loss: 0.661779, acc.: 57.03%] [G loss: 0.877216]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:32 step:30821 [D loss: 0.621385, acc.: 65.62%] [G loss: 0.934208]\n",
      "epoch:32 step:30822 [D loss: 0.647901, acc.: 64.06%] [G loss: 0.979645]\n",
      "epoch:32 step:30823 [D loss: 0.604889, acc.: 67.19%] [G loss: 1.000269]\n",
      "epoch:32 step:30824 [D loss: 0.640549, acc.: 65.62%] [G loss: 0.944761]\n",
      "epoch:32 step:30825 [D loss: 0.633287, acc.: 64.06%] [G loss: 0.900490]\n",
      "epoch:32 step:30826 [D loss: 0.674501, acc.: 58.59%] [G loss: 0.931545]\n",
      "epoch:32 step:30827 [D loss: 0.678044, acc.: 57.81%] [G loss: 0.938771]\n",
      "epoch:32 step:30828 [D loss: 0.625988, acc.: 66.41%] [G loss: 0.925098]\n",
      "epoch:32 step:30829 [D loss: 0.635147, acc.: 61.72%] [G loss: 0.974138]\n",
      "epoch:32 step:30830 [D loss: 0.680216, acc.: 57.03%] [G loss: 0.909395]\n",
      "epoch:32 step:30831 [D loss: 0.605015, acc.: 68.75%] [G loss: 0.890885]\n",
      "epoch:32 step:30832 [D loss: 0.665449, acc.: 57.81%] [G loss: 0.903631]\n",
      "epoch:32 step:30833 [D loss: 0.640423, acc.: 64.84%] [G loss: 0.873814]\n",
      "epoch:32 step:30834 [D loss: 0.624450, acc.: 63.28%] [G loss: 0.924691]\n",
      "epoch:32 step:30835 [D loss: 0.671700, acc.: 54.69%] [G loss: 0.882391]\n",
      "epoch:32 step:30836 [D loss: 0.604813, acc.: 71.88%] [G loss: 0.844350]\n",
      "epoch:32 step:30837 [D loss: 0.697010, acc.: 53.12%] [G loss: 0.858304]\n",
      "epoch:32 step:30838 [D loss: 0.660614, acc.: 61.72%] [G loss: 0.925769]\n",
      "epoch:32 step:30839 [D loss: 0.686176, acc.: 57.81%] [G loss: 0.879676]\n",
      "epoch:32 step:30840 [D loss: 0.660300, acc.: 59.38%] [G loss: 0.872095]\n",
      "epoch:32 step:30841 [D loss: 0.636122, acc.: 63.28%] [G loss: 0.941867]\n",
      "epoch:32 step:30842 [D loss: 0.647428, acc.: 58.59%] [G loss: 0.863839]\n",
      "epoch:32 step:30843 [D loss: 0.620092, acc.: 67.19%] [G loss: 0.923290]\n",
      "epoch:32 step:30844 [D loss: 0.644756, acc.: 60.16%] [G loss: 0.881389]\n",
      "epoch:32 step:30845 [D loss: 0.615657, acc.: 64.84%] [G loss: 0.882166]\n",
      "epoch:32 step:30846 [D loss: 0.638162, acc.: 61.72%] [G loss: 0.935118]\n",
      "epoch:32 step:30847 [D loss: 0.653738, acc.: 65.62%] [G loss: 0.925662]\n",
      "epoch:32 step:30848 [D loss: 0.663050, acc.: 59.38%] [G loss: 0.969229]\n",
      "epoch:32 step:30849 [D loss: 0.613302, acc.: 67.97%] [G loss: 0.943102]\n",
      "epoch:32 step:30850 [D loss: 0.645556, acc.: 62.50%] [G loss: 0.940796]\n",
      "epoch:32 step:30851 [D loss: 0.661273, acc.: 57.03%] [G loss: 0.951732]\n",
      "epoch:32 step:30852 [D loss: 0.624452, acc.: 67.19%] [G loss: 0.910611]\n",
      "epoch:32 step:30853 [D loss: 0.646333, acc.: 60.94%] [G loss: 0.886409]\n",
      "epoch:32 step:30854 [D loss: 0.691877, acc.: 53.12%] [G loss: 0.888159]\n",
      "epoch:32 step:30855 [D loss: 0.686415, acc.: 53.91%] [G loss: 0.935395]\n",
      "epoch:32 step:30856 [D loss: 0.648791, acc.: 60.94%] [G loss: 0.923097]\n",
      "epoch:32 step:30857 [D loss: 0.621449, acc.: 67.19%] [G loss: 0.970778]\n",
      "epoch:32 step:30858 [D loss: 0.644702, acc.: 60.16%] [G loss: 0.961248]\n",
      "epoch:32 step:30859 [D loss: 0.645679, acc.: 60.16%] [G loss: 0.969285]\n",
      "epoch:32 step:30860 [D loss: 0.634749, acc.: 65.62%] [G loss: 0.964971]\n",
      "epoch:32 step:30861 [D loss: 0.605702, acc.: 72.66%] [G loss: 0.977213]\n",
      "epoch:32 step:30862 [D loss: 0.613689, acc.: 67.97%] [G loss: 1.038697]\n",
      "epoch:32 step:30863 [D loss: 0.648589, acc.: 61.72%] [G loss: 0.970645]\n",
      "epoch:32 step:30864 [D loss: 0.655842, acc.: 58.59%] [G loss: 0.901280]\n",
      "epoch:32 step:30865 [D loss: 0.674379, acc.: 51.56%] [G loss: 0.879560]\n",
      "epoch:32 step:30866 [D loss: 0.611494, acc.: 69.53%] [G loss: 0.904347]\n",
      "epoch:32 step:30867 [D loss: 0.591155, acc.: 72.66%] [G loss: 0.864240]\n",
      "epoch:32 step:30868 [D loss: 0.638698, acc.: 67.97%] [G loss: 0.943947]\n",
      "epoch:32 step:30869 [D loss: 0.682794, acc.: 55.47%] [G loss: 0.930375]\n",
      "epoch:32 step:30870 [D loss: 0.655382, acc.: 60.94%] [G loss: 0.915887]\n",
      "epoch:32 step:30871 [D loss: 0.625461, acc.: 68.75%] [G loss: 0.944844]\n",
      "epoch:32 step:30872 [D loss: 0.654780, acc.: 61.72%] [G loss: 0.891343]\n",
      "epoch:32 step:30873 [D loss: 0.648332, acc.: 60.94%] [G loss: 0.914405]\n",
      "epoch:32 step:30874 [D loss: 0.624669, acc.: 62.50%] [G loss: 0.924885]\n",
      "epoch:32 step:30875 [D loss: 0.662674, acc.: 60.94%] [G loss: 0.881747]\n",
      "epoch:32 step:30876 [D loss: 0.685261, acc.: 56.25%] [G loss: 0.954136]\n",
      "epoch:32 step:30877 [D loss: 0.668355, acc.: 58.59%] [G loss: 0.883497]\n",
      "epoch:32 step:30878 [D loss: 0.638127, acc.: 62.50%] [G loss: 0.881865]\n",
      "epoch:32 step:30879 [D loss: 0.664490, acc.: 56.25%] [G loss: 0.896282]\n",
      "epoch:32 step:30880 [D loss: 0.615479, acc.: 64.06%] [G loss: 0.949428]\n",
      "epoch:32 step:30881 [D loss: 0.653528, acc.: 57.81%] [G loss: 0.920645]\n",
      "epoch:32 step:30882 [D loss: 0.644091, acc.: 60.94%] [G loss: 0.964875]\n",
      "epoch:32 step:30883 [D loss: 0.654583, acc.: 57.03%] [G loss: 0.952427]\n",
      "epoch:32 step:30884 [D loss: 0.680946, acc.: 58.59%] [G loss: 1.005997]\n",
      "epoch:32 step:30885 [D loss: 0.692335, acc.: 56.25%] [G loss: 0.920129]\n",
      "epoch:32 step:30886 [D loss: 0.704883, acc.: 48.44%] [G loss: 0.906066]\n",
      "epoch:32 step:30887 [D loss: 0.623144, acc.: 71.09%] [G loss: 0.853810]\n",
      "epoch:32 step:30888 [D loss: 0.594757, acc.: 75.00%] [G loss: 0.936093]\n",
      "epoch:32 step:30889 [D loss: 0.692660, acc.: 56.25%] [G loss: 0.870304]\n",
      "epoch:32 step:30890 [D loss: 0.578448, acc.: 69.53%] [G loss: 0.947452]\n",
      "epoch:32 step:30891 [D loss: 0.685863, acc.: 55.47%] [G loss: 0.894746]\n",
      "epoch:32 step:30892 [D loss: 0.678888, acc.: 54.69%] [G loss: 0.933407]\n",
      "epoch:32 step:30893 [D loss: 0.696298, acc.: 57.81%] [G loss: 0.982337]\n",
      "epoch:32 step:30894 [D loss: 0.678265, acc.: 54.69%] [G loss: 0.914709]\n",
      "epoch:32 step:30895 [D loss: 0.615472, acc.: 66.41%] [G loss: 0.955186]\n",
      "epoch:32 step:30896 [D loss: 0.690764, acc.: 53.91%] [G loss: 0.925942]\n",
      "epoch:32 step:30897 [D loss: 0.683652, acc.: 47.66%] [G loss: 0.943868]\n",
      "epoch:32 step:30898 [D loss: 0.633102, acc.: 62.50%] [G loss: 0.935871]\n",
      "epoch:32 step:30899 [D loss: 0.661533, acc.: 59.38%] [G loss: 0.923138]\n",
      "epoch:32 step:30900 [D loss: 0.605033, acc.: 71.88%] [G loss: 0.923102]\n",
      "epoch:32 step:30901 [D loss: 0.600822, acc.: 68.75%] [G loss: 0.962609]\n",
      "epoch:32 step:30902 [D loss: 0.666730, acc.: 52.34%] [G loss: 0.911724]\n",
      "epoch:32 step:30903 [D loss: 0.641309, acc.: 60.16%] [G loss: 0.844640]\n",
      "epoch:32 step:30904 [D loss: 0.625104, acc.: 69.53%] [G loss: 0.934644]\n",
      "epoch:32 step:30905 [D loss: 0.680751, acc.: 55.47%] [G loss: 0.892124]\n",
      "epoch:32 step:30906 [D loss: 0.640182, acc.: 63.28%] [G loss: 0.957756]\n",
      "epoch:32 step:30907 [D loss: 0.655159, acc.: 62.50%] [G loss: 0.864295]\n",
      "epoch:32 step:30908 [D loss: 0.625939, acc.: 64.84%] [G loss: 0.899826]\n",
      "epoch:32 step:30909 [D loss: 0.620392, acc.: 65.62%] [G loss: 0.883614]\n",
      "epoch:32 step:30910 [D loss: 0.663450, acc.: 58.59%] [G loss: 0.916556]\n",
      "epoch:32 step:30911 [D loss: 0.669261, acc.: 55.47%] [G loss: 0.891903]\n",
      "epoch:32 step:30912 [D loss: 0.626726, acc.: 66.41%] [G loss: 0.881348]\n",
      "epoch:32 step:30913 [D loss: 0.648149, acc.: 57.81%] [G loss: 0.892399]\n",
      "epoch:32 step:30914 [D loss: 0.601408, acc.: 71.09%] [G loss: 0.920873]\n",
      "epoch:32 step:30915 [D loss: 0.658115, acc.: 60.16%] [G loss: 0.976558]\n",
      "epoch:32 step:30916 [D loss: 0.623868, acc.: 61.72%] [G loss: 0.953295]\n",
      "epoch:32 step:30917 [D loss: 0.632427, acc.: 67.97%] [G loss: 0.926855]\n",
      "epoch:32 step:30918 [D loss: 0.589796, acc.: 68.75%] [G loss: 0.955185]\n",
      "epoch:32 step:30919 [D loss: 0.661362, acc.: 67.19%] [G loss: 0.898815]\n",
      "epoch:32 step:30920 [D loss: 0.631025, acc.: 60.16%] [G loss: 0.927612]\n",
      "epoch:32 step:30921 [D loss: 0.635704, acc.: 62.50%] [G loss: 0.994854]\n",
      "epoch:33 step:30922 [D loss: 0.675281, acc.: 59.38%] [G loss: 1.074095]\n",
      "epoch:33 step:30923 [D loss: 0.687888, acc.: 57.81%] [G loss: 0.972397]\n",
      "epoch:33 step:30924 [D loss: 0.622809, acc.: 67.97%] [G loss: 0.929203]\n",
      "epoch:33 step:30925 [D loss: 0.665310, acc.: 55.47%] [G loss: 0.945372]\n",
      "epoch:33 step:30926 [D loss: 0.650357, acc.: 64.84%] [G loss: 0.906062]\n",
      "epoch:33 step:30927 [D loss: 0.631821, acc.: 64.06%] [G loss: 0.981258]\n",
      "epoch:33 step:30928 [D loss: 0.694038, acc.: 53.91%] [G loss: 0.991239]\n",
      "epoch:33 step:30929 [D loss: 0.682054, acc.: 53.91%] [G loss: 1.000117]\n",
      "epoch:33 step:30930 [D loss: 0.669408, acc.: 60.94%] [G loss: 0.889174]\n",
      "epoch:33 step:30931 [D loss: 0.638213, acc.: 61.72%] [G loss: 0.881350]\n",
      "epoch:33 step:30932 [D loss: 0.635783, acc.: 62.50%] [G loss: 0.859768]\n",
      "epoch:33 step:30933 [D loss: 0.615981, acc.: 63.28%] [G loss: 0.962406]\n",
      "epoch:33 step:30934 [D loss: 0.660472, acc.: 56.25%] [G loss: 1.004063]\n",
      "epoch:33 step:30935 [D loss: 0.638686, acc.: 61.72%] [G loss: 1.007916]\n",
      "epoch:33 step:30936 [D loss: 0.643578, acc.: 60.94%] [G loss: 0.920223]\n",
      "epoch:33 step:30937 [D loss: 0.604662, acc.: 66.41%] [G loss: 0.946825]\n",
      "epoch:33 step:30938 [D loss: 0.667745, acc.: 59.38%] [G loss: 0.928748]\n",
      "epoch:33 step:30939 [D loss: 0.664967, acc.: 58.59%] [G loss: 0.943735]\n",
      "epoch:33 step:30940 [D loss: 0.648501, acc.: 62.50%] [G loss: 0.947855]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:30941 [D loss: 0.649320, acc.: 63.28%] [G loss: 0.925704]\n",
      "epoch:33 step:30942 [D loss: 0.655346, acc.: 58.59%] [G loss: 0.928689]\n",
      "epoch:33 step:30943 [D loss: 0.625961, acc.: 60.94%] [G loss: 0.905447]\n",
      "epoch:33 step:30944 [D loss: 0.635343, acc.: 64.06%] [G loss: 0.951632]\n",
      "epoch:33 step:30945 [D loss: 0.640885, acc.: 60.16%] [G loss: 0.921162]\n",
      "epoch:33 step:30946 [D loss: 0.644496, acc.: 61.72%] [G loss: 0.977182]\n",
      "epoch:33 step:30947 [D loss: 0.623071, acc.: 63.28%] [G loss: 0.952891]\n",
      "epoch:33 step:30948 [D loss: 0.641585, acc.: 64.06%] [G loss: 0.896540]\n",
      "epoch:33 step:30949 [D loss: 0.582394, acc.: 73.44%] [G loss: 0.904869]\n",
      "epoch:33 step:30950 [D loss: 0.670476, acc.: 57.03%] [G loss: 0.907314]\n",
      "epoch:33 step:30951 [D loss: 0.635386, acc.: 67.97%] [G loss: 0.942615]\n",
      "epoch:33 step:30952 [D loss: 0.630111, acc.: 65.62%] [G loss: 0.863042]\n",
      "epoch:33 step:30953 [D loss: 0.628566, acc.: 64.84%] [G loss: 0.941595]\n",
      "epoch:33 step:30954 [D loss: 0.626005, acc.: 67.19%] [G loss: 0.962780]\n",
      "epoch:33 step:30955 [D loss: 0.638340, acc.: 64.84%] [G loss: 0.925375]\n",
      "epoch:33 step:30956 [D loss: 0.686807, acc.: 57.81%] [G loss: 0.903420]\n",
      "epoch:33 step:30957 [D loss: 0.602371, acc.: 71.88%] [G loss: 0.898657]\n",
      "epoch:33 step:30958 [D loss: 0.614089, acc.: 67.19%] [G loss: 0.896044]\n",
      "epoch:33 step:30959 [D loss: 0.688889, acc.: 61.72%] [G loss: 0.883740]\n",
      "epoch:33 step:30960 [D loss: 0.676275, acc.: 59.38%] [G loss: 0.882445]\n",
      "epoch:33 step:30961 [D loss: 0.668699, acc.: 57.81%] [G loss: 0.959484]\n",
      "epoch:33 step:30962 [D loss: 0.622275, acc.: 67.19%] [G loss: 0.903528]\n",
      "epoch:33 step:30963 [D loss: 0.657802, acc.: 58.59%] [G loss: 0.877784]\n",
      "epoch:33 step:30964 [D loss: 0.655719, acc.: 63.28%] [G loss: 0.915106]\n",
      "epoch:33 step:30965 [D loss: 0.658514, acc.: 57.03%] [G loss: 0.948565]\n",
      "epoch:33 step:30966 [D loss: 0.651383, acc.: 63.28%] [G loss: 0.969831]\n",
      "epoch:33 step:30967 [D loss: 0.666679, acc.: 57.03%] [G loss: 0.977914]\n",
      "epoch:33 step:30968 [D loss: 0.703598, acc.: 56.25%] [G loss: 0.991080]\n",
      "epoch:33 step:30969 [D loss: 0.620736, acc.: 68.75%] [G loss: 0.973889]\n",
      "epoch:33 step:30970 [D loss: 0.636304, acc.: 66.41%] [G loss: 0.998974]\n",
      "epoch:33 step:30971 [D loss: 0.620093, acc.: 64.84%] [G loss: 1.008205]\n",
      "epoch:33 step:30972 [D loss: 0.647602, acc.: 61.72%] [G loss: 0.993872]\n",
      "epoch:33 step:30973 [D loss: 0.608908, acc.: 67.19%] [G loss: 0.984610]\n",
      "epoch:33 step:30974 [D loss: 0.633442, acc.: 66.41%] [G loss: 0.913927]\n",
      "epoch:33 step:30975 [D loss: 0.609502, acc.: 63.28%] [G loss: 0.924946]\n",
      "epoch:33 step:30976 [D loss: 0.684289, acc.: 57.03%] [G loss: 0.932048]\n",
      "epoch:33 step:30977 [D loss: 0.654802, acc.: 62.50%] [G loss: 0.908189]\n",
      "epoch:33 step:30978 [D loss: 0.677692, acc.: 57.81%] [G loss: 0.994481]\n",
      "epoch:33 step:30979 [D loss: 0.636743, acc.: 63.28%] [G loss: 0.991762]\n",
      "epoch:33 step:30980 [D loss: 0.653930, acc.: 60.94%] [G loss: 0.970208]\n",
      "epoch:33 step:30981 [D loss: 0.631262, acc.: 64.84%] [G loss: 0.917005]\n",
      "epoch:33 step:30982 [D loss: 0.681582, acc.: 57.03%] [G loss: 0.933549]\n",
      "epoch:33 step:30983 [D loss: 0.637105, acc.: 55.47%] [G loss: 0.931288]\n",
      "epoch:33 step:30984 [D loss: 0.625708, acc.: 61.72%] [G loss: 0.932940]\n",
      "epoch:33 step:30985 [D loss: 0.617068, acc.: 66.41%] [G loss: 0.949719]\n",
      "epoch:33 step:30986 [D loss: 0.633067, acc.: 61.72%] [G loss: 0.933792]\n",
      "epoch:33 step:30987 [D loss: 0.610094, acc.: 67.19%] [G loss: 0.940435]\n",
      "epoch:33 step:30988 [D loss: 0.689554, acc.: 57.81%] [G loss: 0.954216]\n",
      "epoch:33 step:30989 [D loss: 0.638370, acc.: 61.72%] [G loss: 0.914065]\n",
      "epoch:33 step:30990 [D loss: 0.594810, acc.: 67.97%] [G loss: 0.959485]\n",
      "epoch:33 step:30991 [D loss: 0.639218, acc.: 64.06%] [G loss: 0.915287]\n",
      "epoch:33 step:30992 [D loss: 0.602717, acc.: 66.41%] [G loss: 1.004019]\n",
      "epoch:33 step:30993 [D loss: 0.687493, acc.: 59.38%] [G loss: 0.936596]\n",
      "epoch:33 step:30994 [D loss: 0.600488, acc.: 69.53%] [G loss: 0.909041]\n",
      "epoch:33 step:30995 [D loss: 0.682918, acc.: 57.81%] [G loss: 0.897351]\n",
      "epoch:33 step:30996 [D loss: 0.646875, acc.: 61.72%] [G loss: 0.954298]\n",
      "epoch:33 step:30997 [D loss: 0.617693, acc.: 67.19%] [G loss: 0.946413]\n",
      "epoch:33 step:30998 [D loss: 0.636471, acc.: 64.84%] [G loss: 0.919675]\n",
      "epoch:33 step:30999 [D loss: 0.621276, acc.: 61.72%] [G loss: 0.902031]\n",
      "epoch:33 step:31000 [D loss: 0.640714, acc.: 64.06%] [G loss: 0.903765]\n",
      "##############\n",
      "[ 2.98007758  2.41451295  2.39567844  3.91873139  1.69442565 10.27426719\n",
      "  2.81228134  3.63054415  4.24001489  6.63944771]\n",
      "##########\n",
      "epoch:33 step:31001 [D loss: 0.698369, acc.: 53.91%] [G loss: 0.932891]\n",
      "epoch:33 step:31002 [D loss: 0.685857, acc.: 55.47%] [G loss: 0.903570]\n",
      "epoch:33 step:31003 [D loss: 0.629861, acc.: 67.19%] [G loss: 0.975388]\n",
      "epoch:33 step:31004 [D loss: 0.604725, acc.: 67.97%] [G loss: 1.028699]\n",
      "epoch:33 step:31005 [D loss: 0.639420, acc.: 64.84%] [G loss: 0.978933]\n",
      "epoch:33 step:31006 [D loss: 0.643135, acc.: 57.81%] [G loss: 0.930544]\n",
      "epoch:33 step:31007 [D loss: 0.656438, acc.: 61.72%] [G loss: 0.943405]\n",
      "epoch:33 step:31008 [D loss: 0.646938, acc.: 64.06%] [G loss: 0.894906]\n",
      "epoch:33 step:31009 [D loss: 0.652303, acc.: 64.06%] [G loss: 0.938027]\n",
      "epoch:33 step:31010 [D loss: 0.623637, acc.: 68.75%] [G loss: 0.877136]\n",
      "epoch:33 step:31011 [D loss: 0.621718, acc.: 59.38%] [G loss: 0.934328]\n",
      "epoch:33 step:31012 [D loss: 0.686625, acc.: 55.47%] [G loss: 0.919578]\n",
      "epoch:33 step:31013 [D loss: 0.629320, acc.: 63.28%] [G loss: 0.951173]\n",
      "epoch:33 step:31014 [D loss: 0.635886, acc.: 67.97%] [G loss: 0.959116]\n",
      "epoch:33 step:31015 [D loss: 0.615279, acc.: 66.41%] [G loss: 0.896789]\n",
      "epoch:33 step:31016 [D loss: 0.635184, acc.: 65.62%] [G loss: 0.919786]\n",
      "epoch:33 step:31017 [D loss: 0.627016, acc.: 67.19%] [G loss: 0.975356]\n",
      "epoch:33 step:31018 [D loss: 0.639337, acc.: 64.06%] [G loss: 0.873777]\n",
      "epoch:33 step:31019 [D loss: 0.665758, acc.: 61.72%] [G loss: 0.877996]\n",
      "epoch:33 step:31020 [D loss: 0.651578, acc.: 67.97%] [G loss: 0.848285]\n",
      "epoch:33 step:31021 [D loss: 0.654785, acc.: 57.03%] [G loss: 0.915586]\n",
      "epoch:33 step:31022 [D loss: 0.661925, acc.: 60.16%] [G loss: 0.943820]\n",
      "epoch:33 step:31023 [D loss: 0.674607, acc.: 57.03%] [G loss: 0.912861]\n",
      "epoch:33 step:31024 [D loss: 0.589976, acc.: 64.06%] [G loss: 0.959206]\n",
      "epoch:33 step:31025 [D loss: 0.665868, acc.: 59.38%] [G loss: 0.907981]\n",
      "epoch:33 step:31026 [D loss: 0.647299, acc.: 64.06%] [G loss: 0.955500]\n",
      "epoch:33 step:31027 [D loss: 0.627539, acc.: 67.19%] [G loss: 0.904591]\n",
      "epoch:33 step:31028 [D loss: 0.650258, acc.: 61.72%] [G loss: 0.873922]\n",
      "epoch:33 step:31029 [D loss: 0.650651, acc.: 64.06%] [G loss: 0.926327]\n",
      "epoch:33 step:31030 [D loss: 0.636250, acc.: 65.62%] [G loss: 0.967726]\n",
      "epoch:33 step:31031 [D loss: 0.620318, acc.: 69.53%] [G loss: 0.967518]\n",
      "epoch:33 step:31032 [D loss: 0.659735, acc.: 62.50%] [G loss: 0.947962]\n",
      "epoch:33 step:31033 [D loss: 0.635136, acc.: 67.19%] [G loss: 0.980969]\n",
      "epoch:33 step:31034 [D loss: 0.615967, acc.: 64.06%] [G loss: 0.950290]\n",
      "epoch:33 step:31035 [D loss: 0.648678, acc.: 66.41%] [G loss: 0.914132]\n",
      "epoch:33 step:31036 [D loss: 0.612027, acc.: 67.19%] [G loss: 0.902137]\n",
      "epoch:33 step:31037 [D loss: 0.651924, acc.: 63.28%] [G loss: 0.896161]\n",
      "epoch:33 step:31038 [D loss: 0.647862, acc.: 52.34%] [G loss: 0.893868]\n",
      "epoch:33 step:31039 [D loss: 0.668812, acc.: 57.81%] [G loss: 0.938547]\n",
      "epoch:33 step:31040 [D loss: 0.639912, acc.: 65.62%] [G loss: 0.931661]\n",
      "epoch:33 step:31041 [D loss: 0.637292, acc.: 65.62%] [G loss: 0.952929]\n",
      "epoch:33 step:31042 [D loss: 0.577668, acc.: 73.44%] [G loss: 0.906188]\n",
      "epoch:33 step:31043 [D loss: 0.680070, acc.: 57.81%] [G loss: 0.902621]\n",
      "epoch:33 step:31044 [D loss: 0.682292, acc.: 60.94%] [G loss: 0.953945]\n",
      "epoch:33 step:31045 [D loss: 0.651102, acc.: 59.38%] [G loss: 0.930248]\n",
      "epoch:33 step:31046 [D loss: 0.670743, acc.: 60.16%] [G loss: 1.007932]\n",
      "epoch:33 step:31047 [D loss: 0.643642, acc.: 62.50%] [G loss: 0.970876]\n",
      "epoch:33 step:31048 [D loss: 0.633957, acc.: 62.50%] [G loss: 0.940554]\n",
      "epoch:33 step:31049 [D loss: 0.630096, acc.: 62.50%] [G loss: 0.928833]\n",
      "epoch:33 step:31050 [D loss: 0.659872, acc.: 61.72%] [G loss: 0.957573]\n",
      "epoch:33 step:31051 [D loss: 0.586745, acc.: 75.00%] [G loss: 0.932406]\n",
      "epoch:33 step:31052 [D loss: 0.635298, acc.: 65.62%] [G loss: 0.967043]\n",
      "epoch:33 step:31053 [D loss: 0.615416, acc.: 67.19%] [G loss: 0.963791]\n",
      "epoch:33 step:31054 [D loss: 0.673901, acc.: 55.47%] [G loss: 0.919368]\n",
      "epoch:33 step:31055 [D loss: 0.638629, acc.: 65.62%] [G loss: 0.890290]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:31056 [D loss: 0.646217, acc.: 58.59%] [G loss: 0.927759]\n",
      "epoch:33 step:31057 [D loss: 0.678383, acc.: 57.81%] [G loss: 0.923806]\n",
      "epoch:33 step:31058 [D loss: 0.646136, acc.: 64.06%] [G loss: 0.891649]\n",
      "epoch:33 step:31059 [D loss: 0.685327, acc.: 57.03%] [G loss: 0.882884]\n",
      "epoch:33 step:31060 [D loss: 0.638480, acc.: 62.50%] [G loss: 0.918850]\n",
      "epoch:33 step:31061 [D loss: 0.640847, acc.: 64.84%] [G loss: 0.905126]\n",
      "epoch:33 step:31062 [D loss: 0.654467, acc.: 59.38%] [G loss: 0.847815]\n",
      "epoch:33 step:31063 [D loss: 0.604455, acc.: 65.62%] [G loss: 0.910701]\n",
      "epoch:33 step:31064 [D loss: 0.615760, acc.: 70.31%] [G loss: 0.861613]\n",
      "epoch:33 step:31065 [D loss: 0.666562, acc.: 59.38%] [G loss: 0.873173]\n",
      "epoch:33 step:31066 [D loss: 0.634813, acc.: 60.94%] [G loss: 0.861366]\n",
      "epoch:33 step:31067 [D loss: 0.688375, acc.: 55.47%] [G loss: 0.843101]\n",
      "epoch:33 step:31068 [D loss: 0.609300, acc.: 67.97%] [G loss: 0.940087]\n",
      "epoch:33 step:31069 [D loss: 0.655051, acc.: 62.50%] [G loss: 1.016190]\n",
      "epoch:33 step:31070 [D loss: 0.625361, acc.: 62.50%] [G loss: 0.976849]\n",
      "epoch:33 step:31071 [D loss: 0.661830, acc.: 63.28%] [G loss: 0.964800]\n",
      "epoch:33 step:31072 [D loss: 0.595842, acc.: 68.75%] [G loss: 0.967956]\n",
      "epoch:33 step:31073 [D loss: 0.677421, acc.: 57.03%] [G loss: 0.932764]\n",
      "epoch:33 step:31074 [D loss: 0.650165, acc.: 64.84%] [G loss: 0.945085]\n",
      "epoch:33 step:31075 [D loss: 0.642220, acc.: 57.81%] [G loss: 0.889512]\n",
      "epoch:33 step:31076 [D loss: 0.675683, acc.: 54.69%] [G loss: 0.980299]\n",
      "epoch:33 step:31077 [D loss: 0.600863, acc.: 71.88%] [G loss: 0.925595]\n",
      "epoch:33 step:31078 [D loss: 0.635088, acc.: 65.62%] [G loss: 0.902057]\n",
      "epoch:33 step:31079 [D loss: 0.626333, acc.: 64.06%] [G loss: 0.920782]\n",
      "epoch:33 step:31080 [D loss: 0.639424, acc.: 59.38%] [G loss: 0.956961]\n",
      "epoch:33 step:31081 [D loss: 0.663430, acc.: 58.59%] [G loss: 0.914908]\n",
      "epoch:33 step:31082 [D loss: 0.592107, acc.: 70.31%] [G loss: 0.949254]\n",
      "epoch:33 step:31083 [D loss: 0.665470, acc.: 60.16%] [G loss: 0.929866]\n",
      "epoch:33 step:31084 [D loss: 0.674930, acc.: 54.69%] [G loss: 0.925970]\n",
      "epoch:33 step:31085 [D loss: 0.660370, acc.: 59.38%] [G loss: 0.957029]\n",
      "epoch:33 step:31086 [D loss: 0.636868, acc.: 62.50%] [G loss: 0.891619]\n",
      "epoch:33 step:31087 [D loss: 0.623890, acc.: 67.97%] [G loss: 0.949604]\n",
      "epoch:33 step:31088 [D loss: 0.615065, acc.: 64.84%] [G loss: 0.925739]\n",
      "epoch:33 step:31089 [D loss: 0.642570, acc.: 67.19%] [G loss: 0.938270]\n",
      "epoch:33 step:31090 [D loss: 0.641631, acc.: 60.94%] [G loss: 0.942481]\n",
      "epoch:33 step:31091 [D loss: 0.615418, acc.: 64.06%] [G loss: 0.941167]\n",
      "epoch:33 step:31092 [D loss: 0.658747, acc.: 59.38%] [G loss: 0.909037]\n",
      "epoch:33 step:31093 [D loss: 0.614166, acc.: 65.62%] [G loss: 0.893542]\n",
      "epoch:33 step:31094 [D loss: 0.624726, acc.: 63.28%] [G loss: 0.822509]\n",
      "epoch:33 step:31095 [D loss: 0.624909, acc.: 63.28%] [G loss: 0.842821]\n",
      "epoch:33 step:31096 [D loss: 0.678339, acc.: 60.16%] [G loss: 0.851470]\n",
      "epoch:33 step:31097 [D loss: 0.605703, acc.: 67.97%] [G loss: 0.922752]\n",
      "epoch:33 step:31098 [D loss: 0.619668, acc.: 70.31%] [G loss: 0.914698]\n",
      "epoch:33 step:31099 [D loss: 0.611216, acc.: 65.62%] [G loss: 0.920455]\n",
      "epoch:33 step:31100 [D loss: 0.639669, acc.: 57.81%] [G loss: 0.864331]\n",
      "epoch:33 step:31101 [D loss: 0.621306, acc.: 66.41%] [G loss: 0.954042]\n",
      "epoch:33 step:31102 [D loss: 0.646235, acc.: 58.59%] [G loss: 1.015461]\n",
      "epoch:33 step:31103 [D loss: 0.623614, acc.: 65.62%] [G loss: 0.946564]\n",
      "epoch:33 step:31104 [D loss: 0.683144, acc.: 58.59%] [G loss: 0.956872]\n",
      "epoch:33 step:31105 [D loss: 0.653843, acc.: 65.62%] [G loss: 0.959677]\n",
      "epoch:33 step:31106 [D loss: 0.637888, acc.: 64.84%] [G loss: 0.993815]\n",
      "epoch:33 step:31107 [D loss: 0.645715, acc.: 64.06%] [G loss: 0.948142]\n",
      "epoch:33 step:31108 [D loss: 0.630113, acc.: 60.94%] [G loss: 0.965797]\n",
      "epoch:33 step:31109 [D loss: 0.626588, acc.: 68.75%] [G loss: 0.933877]\n",
      "epoch:33 step:31110 [D loss: 0.638477, acc.: 60.94%] [G loss: 0.982055]\n",
      "epoch:33 step:31111 [D loss: 0.665909, acc.: 60.16%] [G loss: 0.964980]\n",
      "epoch:33 step:31112 [D loss: 0.629487, acc.: 63.28%] [G loss: 0.966227]\n",
      "epoch:33 step:31113 [D loss: 0.652618, acc.: 57.81%] [G loss: 0.917197]\n",
      "epoch:33 step:31114 [D loss: 0.586964, acc.: 69.53%] [G loss: 0.970544]\n",
      "epoch:33 step:31115 [D loss: 0.666270, acc.: 63.28%] [G loss: 0.938841]\n",
      "epoch:33 step:31116 [D loss: 0.674752, acc.: 60.16%] [G loss: 0.943409]\n",
      "epoch:33 step:31117 [D loss: 0.657702, acc.: 61.72%] [G loss: 0.925007]\n",
      "epoch:33 step:31118 [D loss: 0.617357, acc.: 64.84%] [G loss: 0.879363]\n",
      "epoch:33 step:31119 [D loss: 0.650230, acc.: 66.41%] [G loss: 0.989070]\n",
      "epoch:33 step:31120 [D loss: 0.690409, acc.: 64.06%] [G loss: 0.989329]\n",
      "epoch:33 step:31121 [D loss: 0.663248, acc.: 58.59%] [G loss: 0.900762]\n",
      "epoch:33 step:31122 [D loss: 0.644598, acc.: 59.38%] [G loss: 0.948484]\n",
      "epoch:33 step:31123 [D loss: 0.650039, acc.: 61.72%] [G loss: 0.944053]\n",
      "epoch:33 step:31124 [D loss: 0.650540, acc.: 58.59%] [G loss: 0.968275]\n",
      "epoch:33 step:31125 [D loss: 0.637604, acc.: 66.41%] [G loss: 0.923388]\n",
      "epoch:33 step:31126 [D loss: 0.665299, acc.: 54.69%] [G loss: 0.935598]\n",
      "epoch:33 step:31127 [D loss: 0.650354, acc.: 65.62%] [G loss: 0.922005]\n",
      "epoch:33 step:31128 [D loss: 0.650967, acc.: 62.50%] [G loss: 0.933835]\n",
      "epoch:33 step:31129 [D loss: 0.627346, acc.: 65.62%] [G loss: 0.959232]\n",
      "epoch:33 step:31130 [D loss: 0.650565, acc.: 60.16%] [G loss: 0.939003]\n",
      "epoch:33 step:31131 [D loss: 0.650833, acc.: 64.06%] [G loss: 0.938742]\n",
      "epoch:33 step:31132 [D loss: 0.648694, acc.: 57.81%] [G loss: 0.879501]\n",
      "epoch:33 step:31133 [D loss: 0.670368, acc.: 57.03%] [G loss: 0.862213]\n",
      "epoch:33 step:31134 [D loss: 0.660742, acc.: 60.94%] [G loss: 0.857157]\n",
      "epoch:33 step:31135 [D loss: 0.653985, acc.: 64.06%] [G loss: 0.951768]\n",
      "epoch:33 step:31136 [D loss: 0.662735, acc.: 59.38%] [G loss: 0.875639]\n",
      "epoch:33 step:31137 [D loss: 0.684679, acc.: 56.25%] [G loss: 0.949211]\n",
      "epoch:33 step:31138 [D loss: 0.630530, acc.: 63.28%] [G loss: 0.931900]\n",
      "epoch:33 step:31139 [D loss: 0.657445, acc.: 57.81%] [G loss: 0.851975]\n",
      "epoch:33 step:31140 [D loss: 0.657393, acc.: 59.38%] [G loss: 0.923748]\n",
      "epoch:33 step:31141 [D loss: 0.651480, acc.: 58.59%] [G loss: 0.935713]\n",
      "epoch:33 step:31142 [D loss: 0.619976, acc.: 64.06%] [G loss: 0.927508]\n",
      "epoch:33 step:31143 [D loss: 0.695163, acc.: 57.81%] [G loss: 0.910125]\n",
      "epoch:33 step:31144 [D loss: 0.602603, acc.: 67.97%] [G loss: 0.881257]\n",
      "epoch:33 step:31145 [D loss: 0.691890, acc.: 57.81%] [G loss: 0.903917]\n",
      "epoch:33 step:31146 [D loss: 0.651518, acc.: 59.38%] [G loss: 0.903755]\n",
      "epoch:33 step:31147 [D loss: 0.654110, acc.: 64.06%] [G loss: 0.911400]\n",
      "epoch:33 step:31148 [D loss: 0.631704, acc.: 63.28%] [G loss: 0.912864]\n",
      "epoch:33 step:31149 [D loss: 0.664092, acc.: 60.94%] [G loss: 0.901061]\n",
      "epoch:33 step:31150 [D loss: 0.656022, acc.: 60.94%] [G loss: 0.897391]\n",
      "epoch:33 step:31151 [D loss: 0.642433, acc.: 60.94%] [G loss: 0.956802]\n",
      "epoch:33 step:31152 [D loss: 0.680525, acc.: 55.47%] [G loss: 0.906155]\n",
      "epoch:33 step:31153 [D loss: 0.634004, acc.: 62.50%] [G loss: 0.940282]\n",
      "epoch:33 step:31154 [D loss: 0.652804, acc.: 60.16%] [G loss: 0.992128]\n",
      "epoch:33 step:31155 [D loss: 0.707865, acc.: 53.12%] [G loss: 0.937336]\n",
      "epoch:33 step:31156 [D loss: 0.704306, acc.: 51.56%] [G loss: 0.906111]\n",
      "epoch:33 step:31157 [D loss: 0.664770, acc.: 60.16%] [G loss: 0.896768]\n",
      "epoch:33 step:31158 [D loss: 0.676745, acc.: 57.81%] [G loss: 0.902257]\n",
      "epoch:33 step:31159 [D loss: 0.690684, acc.: 53.12%] [G loss: 0.898214]\n",
      "epoch:33 step:31160 [D loss: 0.679111, acc.: 58.59%] [G loss: 0.907302]\n",
      "epoch:33 step:31161 [D loss: 0.631061, acc.: 64.84%] [G loss: 0.866765]\n",
      "epoch:33 step:31162 [D loss: 0.659565, acc.: 57.81%] [G loss: 0.925218]\n",
      "epoch:33 step:31163 [D loss: 0.668032, acc.: 58.59%] [G loss: 0.928663]\n",
      "epoch:33 step:31164 [D loss: 0.667266, acc.: 60.16%] [G loss: 0.912109]\n",
      "epoch:33 step:31165 [D loss: 0.637872, acc.: 60.94%] [G loss: 0.933933]\n",
      "epoch:33 step:31166 [D loss: 0.648661, acc.: 59.38%] [G loss: 0.930843]\n",
      "epoch:33 step:31167 [D loss: 0.658513, acc.: 50.78%] [G loss: 0.954025]\n",
      "epoch:33 step:31168 [D loss: 0.604758, acc.: 70.31%] [G loss: 0.929636]\n",
      "epoch:33 step:31169 [D loss: 0.628488, acc.: 63.28%] [G loss: 0.944179]\n",
      "epoch:33 step:31170 [D loss: 0.686393, acc.: 53.91%] [G loss: 0.884064]\n",
      "epoch:33 step:31171 [D loss: 0.636727, acc.: 60.16%] [G loss: 0.991115]\n",
      "epoch:33 step:31172 [D loss: 0.670197, acc.: 58.59%] [G loss: 0.956600]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:31173 [D loss: 0.634986, acc.: 63.28%] [G loss: 0.937260]\n",
      "epoch:33 step:31174 [D loss: 0.618201, acc.: 70.31%] [G loss: 0.966124]\n",
      "epoch:33 step:31175 [D loss: 0.680047, acc.: 57.03%] [G loss: 0.970586]\n",
      "epoch:33 step:31176 [D loss: 0.649786, acc.: 61.72%] [G loss: 0.960879]\n",
      "epoch:33 step:31177 [D loss: 0.659479, acc.: 61.72%] [G loss: 0.919958]\n",
      "epoch:33 step:31178 [D loss: 0.630449, acc.: 64.06%] [G loss: 0.938578]\n",
      "epoch:33 step:31179 [D loss: 0.650171, acc.: 60.16%] [G loss: 0.876189]\n",
      "epoch:33 step:31180 [D loss: 0.683574, acc.: 51.56%] [G loss: 0.874895]\n",
      "epoch:33 step:31181 [D loss: 0.612417, acc.: 64.06%] [G loss: 0.911995]\n",
      "epoch:33 step:31182 [D loss: 0.653174, acc.: 60.16%] [G loss: 0.875584]\n",
      "epoch:33 step:31183 [D loss: 0.670777, acc.: 60.16%] [G loss: 0.932938]\n",
      "epoch:33 step:31184 [D loss: 0.627931, acc.: 63.28%] [G loss: 0.998272]\n",
      "epoch:33 step:31185 [D loss: 0.693113, acc.: 53.91%] [G loss: 0.898054]\n",
      "epoch:33 step:31186 [D loss: 0.625608, acc.: 67.19%] [G loss: 0.891576]\n",
      "epoch:33 step:31187 [D loss: 0.624258, acc.: 66.41%] [G loss: 0.906674]\n",
      "epoch:33 step:31188 [D loss: 0.653935, acc.: 60.16%] [G loss: 0.864622]\n",
      "epoch:33 step:31189 [D loss: 0.622361, acc.: 66.41%] [G loss: 0.920697]\n",
      "epoch:33 step:31190 [D loss: 0.591468, acc.: 71.88%] [G loss: 0.978042]\n",
      "epoch:33 step:31191 [D loss: 0.626529, acc.: 64.84%] [G loss: 0.946757]\n",
      "epoch:33 step:31192 [D loss: 0.631310, acc.: 65.62%] [G loss: 0.943703]\n",
      "epoch:33 step:31193 [D loss: 0.653884, acc.: 61.72%] [G loss: 0.930003]\n",
      "epoch:33 step:31194 [D loss: 0.675148, acc.: 60.16%] [G loss: 0.920549]\n",
      "epoch:33 step:31195 [D loss: 0.713665, acc.: 57.81%] [G loss: 0.939853]\n",
      "epoch:33 step:31196 [D loss: 0.645358, acc.: 63.28%] [G loss: 0.898255]\n",
      "epoch:33 step:31197 [D loss: 0.646294, acc.: 61.72%] [G loss: 0.897823]\n",
      "epoch:33 step:31198 [D loss: 0.672216, acc.: 53.12%] [G loss: 0.896667]\n",
      "epoch:33 step:31199 [D loss: 0.665467, acc.: 57.03%] [G loss: 0.881756]\n",
      "epoch:33 step:31200 [D loss: 0.671111, acc.: 57.03%] [G loss: 0.914668]\n",
      "##############\n",
      "[3.11776404 2.35873511 2.27145132 3.57748439 0.92424306 6.22393561\n",
      " 2.0742984  3.50092975 4.27904383 6.74568765]\n",
      "##########\n",
      "epoch:33 step:31201 [D loss: 0.695747, acc.: 54.69%] [G loss: 0.853769]\n",
      "epoch:33 step:31202 [D loss: 0.615980, acc.: 67.97%] [G loss: 0.916812]\n",
      "epoch:33 step:31203 [D loss: 0.624951, acc.: 64.06%] [G loss: 0.952026]\n",
      "epoch:33 step:31204 [D loss: 0.632436, acc.: 61.72%] [G loss: 1.013160]\n",
      "epoch:33 step:31205 [D loss: 0.590177, acc.: 66.41%] [G loss: 1.002485]\n",
      "epoch:33 step:31206 [D loss: 0.596320, acc.: 69.53%] [G loss: 0.968473]\n",
      "epoch:33 step:31207 [D loss: 0.660019, acc.: 59.38%] [G loss: 0.963330]\n",
      "epoch:33 step:31208 [D loss: 0.623567, acc.: 60.94%] [G loss: 1.016090]\n",
      "epoch:33 step:31209 [D loss: 0.641155, acc.: 64.06%] [G loss: 0.926871]\n",
      "epoch:33 step:31210 [D loss: 0.692705, acc.: 58.59%] [G loss: 0.961247]\n",
      "epoch:33 step:31211 [D loss: 0.600569, acc.: 67.19%] [G loss: 0.971415]\n",
      "epoch:33 step:31212 [D loss: 0.637919, acc.: 60.94%] [G loss: 0.988418]\n",
      "epoch:33 step:31213 [D loss: 0.698140, acc.: 57.81%] [G loss: 0.934555]\n",
      "epoch:33 step:31214 [D loss: 0.629043, acc.: 59.38%] [G loss: 0.930733]\n",
      "epoch:33 step:31215 [D loss: 0.655073, acc.: 62.50%] [G loss: 0.909719]\n",
      "epoch:33 step:31216 [D loss: 0.663408, acc.: 57.81%] [G loss: 0.864640]\n",
      "epoch:33 step:31217 [D loss: 0.662344, acc.: 64.84%] [G loss: 0.921970]\n",
      "epoch:33 step:31218 [D loss: 0.602071, acc.: 65.62%] [G loss: 0.858834]\n",
      "epoch:33 step:31219 [D loss: 0.634974, acc.: 65.62%] [G loss: 0.885498]\n",
      "epoch:33 step:31220 [D loss: 0.658628, acc.: 57.03%] [G loss: 0.912838]\n",
      "epoch:33 step:31221 [D loss: 0.682114, acc.: 52.34%] [G loss: 0.943880]\n",
      "epoch:33 step:31222 [D loss: 0.666499, acc.: 57.81%] [G loss: 0.942924]\n",
      "epoch:33 step:31223 [D loss: 0.647838, acc.: 65.62%] [G loss: 0.917721]\n",
      "epoch:33 step:31224 [D loss: 0.661343, acc.: 56.25%] [G loss: 0.940913]\n",
      "epoch:33 step:31225 [D loss: 0.650400, acc.: 62.50%] [G loss: 0.876423]\n",
      "epoch:33 step:31226 [D loss: 0.658720, acc.: 58.59%] [G loss: 0.946741]\n",
      "epoch:33 step:31227 [D loss: 0.635896, acc.: 66.41%] [G loss: 0.912477]\n",
      "epoch:33 step:31228 [D loss: 0.679439, acc.: 53.91%] [G loss: 0.914198]\n",
      "epoch:33 step:31229 [D loss: 0.654173, acc.: 60.16%] [G loss: 0.886125]\n",
      "epoch:33 step:31230 [D loss: 0.693492, acc.: 56.25%] [G loss: 0.885032]\n",
      "epoch:33 step:31231 [D loss: 0.629181, acc.: 61.72%] [G loss: 0.881189]\n",
      "epoch:33 step:31232 [D loss: 0.668076, acc.: 57.03%] [G loss: 0.918128]\n",
      "epoch:33 step:31233 [D loss: 0.651382, acc.: 64.06%] [G loss: 0.924977]\n",
      "epoch:33 step:31234 [D loss: 0.667191, acc.: 54.69%] [G loss: 0.905163]\n",
      "epoch:33 step:31235 [D loss: 0.631016, acc.: 62.50%] [G loss: 0.969066]\n",
      "epoch:33 step:31236 [D loss: 0.646995, acc.: 67.19%] [G loss: 0.941012]\n",
      "epoch:33 step:31237 [D loss: 0.704639, acc.: 50.00%] [G loss: 0.910200]\n",
      "epoch:33 step:31238 [D loss: 0.624982, acc.: 60.94%] [G loss: 0.944965]\n",
      "epoch:33 step:31239 [D loss: 0.619628, acc.: 66.41%] [G loss: 0.973213]\n",
      "epoch:33 step:31240 [D loss: 0.654489, acc.: 58.59%] [G loss: 0.946695]\n",
      "epoch:33 step:31241 [D loss: 0.707399, acc.: 54.69%] [G loss: 0.916787]\n",
      "epoch:33 step:31242 [D loss: 0.619960, acc.: 66.41%] [G loss: 0.900471]\n",
      "epoch:33 step:31243 [D loss: 0.674132, acc.: 57.81%] [G loss: 0.950139]\n",
      "epoch:33 step:31244 [D loss: 0.655500, acc.: 60.94%] [G loss: 0.923766]\n",
      "epoch:33 step:31245 [D loss: 0.639640, acc.: 58.59%] [G loss: 0.929218]\n",
      "epoch:33 step:31246 [D loss: 0.648200, acc.: 64.06%] [G loss: 0.889155]\n",
      "epoch:33 step:31247 [D loss: 0.724196, acc.: 53.91%] [G loss: 0.835105]\n",
      "epoch:33 step:31248 [D loss: 0.640404, acc.: 63.28%] [G loss: 0.934695]\n",
      "epoch:33 step:31249 [D loss: 0.612644, acc.: 67.19%] [G loss: 0.967632]\n",
      "epoch:33 step:31250 [D loss: 0.665592, acc.: 57.81%] [G loss: 0.908441]\n",
      "epoch:33 step:31251 [D loss: 0.642850, acc.: 60.16%] [G loss: 0.981004]\n",
      "epoch:33 step:31252 [D loss: 0.650948, acc.: 60.16%] [G loss: 0.942213]\n",
      "epoch:33 step:31253 [D loss: 0.651878, acc.: 67.19%] [G loss: 0.948034]\n",
      "epoch:33 step:31254 [D loss: 0.649206, acc.: 60.94%] [G loss: 0.901055]\n",
      "epoch:33 step:31255 [D loss: 0.640725, acc.: 61.72%] [G loss: 1.017357]\n",
      "epoch:33 step:31256 [D loss: 0.676270, acc.: 55.47%] [G loss: 0.878615]\n",
      "epoch:33 step:31257 [D loss: 0.623717, acc.: 64.06%] [G loss: 0.868522]\n",
      "epoch:33 step:31258 [D loss: 0.673937, acc.: 55.47%] [G loss: 0.927337]\n",
      "epoch:33 step:31259 [D loss: 0.623033, acc.: 70.31%] [G loss: 0.889020]\n",
      "epoch:33 step:31260 [D loss: 0.650235, acc.: 58.59%] [G loss: 0.917163]\n",
      "epoch:33 step:31261 [D loss: 0.625255, acc.: 66.41%] [G loss: 0.939448]\n",
      "epoch:33 step:31262 [D loss: 0.654739, acc.: 61.72%] [G loss: 0.882026]\n",
      "epoch:33 step:31263 [D loss: 0.653814, acc.: 62.50%] [G loss: 0.935396]\n",
      "epoch:33 step:31264 [D loss: 0.667376, acc.: 57.81%] [G loss: 0.891102]\n",
      "epoch:33 step:31265 [D loss: 0.617118, acc.: 70.31%] [G loss: 0.914885]\n",
      "epoch:33 step:31266 [D loss: 0.652455, acc.: 59.38%] [G loss: 0.898328]\n",
      "epoch:33 step:31267 [D loss: 0.689115, acc.: 52.34%] [G loss: 0.933875]\n",
      "epoch:33 step:31268 [D loss: 0.602006, acc.: 70.31%] [G loss: 0.905693]\n",
      "epoch:33 step:31269 [D loss: 0.638715, acc.: 68.75%] [G loss: 0.877230]\n",
      "epoch:33 step:31270 [D loss: 0.632843, acc.: 59.38%] [G loss: 0.888997]\n",
      "epoch:33 step:31271 [D loss: 0.651605, acc.: 57.81%] [G loss: 0.900516]\n",
      "epoch:33 step:31272 [D loss: 0.630841, acc.: 64.06%] [G loss: 0.942382]\n",
      "epoch:33 step:31273 [D loss: 0.658697, acc.: 64.84%] [G loss: 0.861723]\n",
      "epoch:33 step:31274 [D loss: 0.663027, acc.: 57.81%] [G loss: 0.886439]\n",
      "epoch:33 step:31275 [D loss: 0.662748, acc.: 53.91%] [G loss: 0.892106]\n",
      "epoch:33 step:31276 [D loss: 0.629276, acc.: 67.19%] [G loss: 0.938660]\n",
      "epoch:33 step:31277 [D loss: 0.645908, acc.: 64.06%] [G loss: 0.968977]\n",
      "epoch:33 step:31278 [D loss: 0.737258, acc.: 50.00%] [G loss: 0.952107]\n",
      "epoch:33 step:31279 [D loss: 0.649579, acc.: 64.84%] [G loss: 0.870038]\n",
      "epoch:33 step:31280 [D loss: 0.658305, acc.: 57.81%] [G loss: 0.907366]\n",
      "epoch:33 step:31281 [D loss: 0.628540, acc.: 63.28%] [G loss: 0.919814]\n",
      "epoch:33 step:31282 [D loss: 0.598079, acc.: 62.50%] [G loss: 0.964687]\n",
      "epoch:33 step:31283 [D loss: 0.673997, acc.: 60.94%] [G loss: 0.887907]\n",
      "epoch:33 step:31284 [D loss: 0.684844, acc.: 55.47%] [G loss: 0.895426]\n",
      "epoch:33 step:31285 [D loss: 0.652868, acc.: 60.94%] [G loss: 0.887556]\n",
      "epoch:33 step:31286 [D loss: 0.636482, acc.: 60.16%] [G loss: 0.863032]\n",
      "epoch:33 step:31287 [D loss: 0.642224, acc.: 63.28%] [G loss: 0.890176]\n",
      "epoch:33 step:31288 [D loss: 0.665444, acc.: 58.59%] [G loss: 0.879762]\n",
      "epoch:33 step:31289 [D loss: 0.643097, acc.: 60.16%] [G loss: 0.893684]\n",
      "epoch:33 step:31290 [D loss: 0.636896, acc.: 62.50%] [G loss: 0.951654]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:31291 [D loss: 0.633114, acc.: 58.59%] [G loss: 0.876431]\n",
      "epoch:33 step:31292 [D loss: 0.644636, acc.: 63.28%] [G loss: 0.950314]\n",
      "epoch:33 step:31293 [D loss: 0.642391, acc.: 67.19%] [G loss: 0.954117]\n",
      "epoch:33 step:31294 [D loss: 0.651892, acc.: 56.25%] [G loss: 0.948076]\n",
      "epoch:33 step:31295 [D loss: 0.640220, acc.: 63.28%] [G loss: 1.035036]\n",
      "epoch:33 step:31296 [D loss: 0.648489, acc.: 66.41%] [G loss: 1.031528]\n",
      "epoch:33 step:31297 [D loss: 0.604903, acc.: 67.97%] [G loss: 0.982963]\n",
      "epoch:33 step:31298 [D loss: 0.649788, acc.: 67.19%] [G loss: 1.000228]\n",
      "epoch:33 step:31299 [D loss: 0.608050, acc.: 67.97%] [G loss: 0.956364]\n",
      "epoch:33 step:31300 [D loss: 0.602445, acc.: 71.88%] [G loss: 0.945877]\n",
      "epoch:33 step:31301 [D loss: 0.681278, acc.: 55.47%] [G loss: 0.889501]\n",
      "epoch:33 step:31302 [D loss: 0.643846, acc.: 63.28%] [G loss: 0.854901]\n",
      "epoch:33 step:31303 [D loss: 0.652728, acc.: 59.38%] [G loss: 0.944327]\n",
      "epoch:33 step:31304 [D loss: 0.646833, acc.: 60.94%] [G loss: 0.874714]\n",
      "epoch:33 step:31305 [D loss: 0.623389, acc.: 65.62%] [G loss: 0.935421]\n",
      "epoch:33 step:31306 [D loss: 0.663180, acc.: 66.41%] [G loss: 0.903947]\n",
      "epoch:33 step:31307 [D loss: 0.618203, acc.: 64.06%] [G loss: 0.925279]\n",
      "epoch:33 step:31308 [D loss: 0.630329, acc.: 65.62%] [G loss: 0.966175]\n",
      "epoch:33 step:31309 [D loss: 0.689911, acc.: 59.38%] [G loss: 1.006998]\n",
      "epoch:33 step:31310 [D loss: 0.652542, acc.: 60.16%] [G loss: 0.944351]\n",
      "epoch:33 step:31311 [D loss: 0.648778, acc.: 62.50%] [G loss: 0.964172]\n",
      "epoch:33 step:31312 [D loss: 0.642938, acc.: 57.03%] [G loss: 0.930906]\n",
      "epoch:33 step:31313 [D loss: 0.664592, acc.: 60.94%] [G loss: 0.940448]\n",
      "epoch:33 step:31314 [D loss: 0.675861, acc.: 60.16%] [G loss: 0.953892]\n",
      "epoch:33 step:31315 [D loss: 0.644382, acc.: 57.81%] [G loss: 0.885556]\n",
      "epoch:33 step:31316 [D loss: 0.662717, acc.: 56.25%] [G loss: 0.880893]\n",
      "epoch:33 step:31317 [D loss: 0.667087, acc.: 60.16%] [G loss: 0.879057]\n",
      "epoch:33 step:31318 [D loss: 0.663129, acc.: 60.16%] [G loss: 0.923404]\n",
      "epoch:33 step:31319 [D loss: 0.645622, acc.: 66.41%] [G loss: 0.904817]\n",
      "epoch:33 step:31320 [D loss: 0.611845, acc.: 70.31%] [G loss: 0.994616]\n",
      "epoch:33 step:31321 [D loss: 0.629608, acc.: 65.62%] [G loss: 0.910000]\n",
      "epoch:33 step:31322 [D loss: 0.596006, acc.: 64.84%] [G loss: 1.027287]\n",
      "epoch:33 step:31323 [D loss: 0.575625, acc.: 71.09%] [G loss: 0.942957]\n",
      "epoch:33 step:31324 [D loss: 0.627125, acc.: 62.50%] [G loss: 0.980747]\n",
      "epoch:33 step:31325 [D loss: 0.663389, acc.: 63.28%] [G loss: 0.933581]\n",
      "epoch:33 step:31326 [D loss: 0.605436, acc.: 69.53%] [G loss: 0.956824]\n",
      "epoch:33 step:31327 [D loss: 0.618648, acc.: 64.06%] [G loss: 0.904211]\n",
      "epoch:33 step:31328 [D loss: 0.675579, acc.: 59.38%] [G loss: 0.882100]\n",
      "epoch:33 step:31329 [D loss: 0.666860, acc.: 55.47%] [G loss: 0.892511]\n",
      "epoch:33 step:31330 [D loss: 0.646597, acc.: 64.84%] [G loss: 0.926027]\n",
      "epoch:33 step:31331 [D loss: 0.690463, acc.: 53.91%] [G loss: 0.883905]\n",
      "epoch:33 step:31332 [D loss: 0.623648, acc.: 65.62%] [G loss: 0.964047]\n",
      "epoch:33 step:31333 [D loss: 0.639725, acc.: 61.72%] [G loss: 0.903166]\n",
      "epoch:33 step:31334 [D loss: 0.670447, acc.: 60.16%] [G loss: 0.936778]\n",
      "epoch:33 step:31335 [D loss: 0.639714, acc.: 58.59%] [G loss: 0.921461]\n",
      "epoch:33 step:31336 [D loss: 0.639480, acc.: 62.50%] [G loss: 0.949359]\n",
      "epoch:33 step:31337 [D loss: 0.653569, acc.: 57.03%] [G loss: 0.903162]\n",
      "epoch:33 step:31338 [D loss: 0.618043, acc.: 67.97%] [G loss: 0.959806]\n",
      "epoch:33 step:31339 [D loss: 0.643040, acc.: 57.81%] [G loss: 0.926157]\n",
      "epoch:33 step:31340 [D loss: 0.656026, acc.: 65.62%] [G loss: 0.839271]\n",
      "epoch:33 step:31341 [D loss: 0.650427, acc.: 61.72%] [G loss: 0.888522]\n",
      "epoch:33 step:31342 [D loss: 0.632331, acc.: 65.62%] [G loss: 0.853751]\n",
      "epoch:33 step:31343 [D loss: 0.633335, acc.: 69.53%] [G loss: 0.899405]\n",
      "epoch:33 step:31344 [D loss: 0.652910, acc.: 64.84%] [G loss: 0.843443]\n",
      "epoch:33 step:31345 [D loss: 0.672019, acc.: 57.03%] [G loss: 0.905495]\n",
      "epoch:33 step:31346 [D loss: 0.640862, acc.: 63.28%] [G loss: 0.851794]\n",
      "epoch:33 step:31347 [D loss: 0.671324, acc.: 55.47%] [G loss: 0.911115]\n",
      "epoch:33 step:31348 [D loss: 0.672995, acc.: 61.72%] [G loss: 0.915998]\n",
      "epoch:33 step:31349 [D loss: 0.711689, acc.: 53.91%] [G loss: 0.914409]\n",
      "epoch:33 step:31350 [D loss: 0.627397, acc.: 67.19%] [G loss: 0.904368]\n",
      "epoch:33 step:31351 [D loss: 0.653390, acc.: 60.16%] [G loss: 0.910638]\n",
      "epoch:33 step:31352 [D loss: 0.656599, acc.: 57.81%] [G loss: 0.919500]\n",
      "epoch:33 step:31353 [D loss: 0.642405, acc.: 67.19%] [G loss: 0.911076]\n",
      "epoch:33 step:31354 [D loss: 0.650988, acc.: 63.28%] [G loss: 0.940994]\n",
      "epoch:33 step:31355 [D loss: 0.624607, acc.: 67.97%] [G loss: 0.980484]\n",
      "epoch:33 step:31356 [D loss: 0.630096, acc.: 63.28%] [G loss: 0.964897]\n",
      "epoch:33 step:31357 [D loss: 0.685410, acc.: 57.03%] [G loss: 0.985694]\n",
      "epoch:33 step:31358 [D loss: 0.681397, acc.: 56.25%] [G loss: 0.938304]\n",
      "epoch:33 step:31359 [D loss: 0.640082, acc.: 64.84%] [G loss: 0.986429]\n",
      "epoch:33 step:31360 [D loss: 0.648165, acc.: 60.16%] [G loss: 0.945659]\n",
      "epoch:33 step:31361 [D loss: 0.647710, acc.: 60.16%] [G loss: 0.897062]\n",
      "epoch:33 step:31362 [D loss: 0.658264, acc.: 60.94%] [G loss: 0.889747]\n",
      "epoch:33 step:31363 [D loss: 0.655788, acc.: 61.72%] [G loss: 0.953973]\n",
      "epoch:33 step:31364 [D loss: 0.633719, acc.: 67.19%] [G loss: 0.914814]\n",
      "epoch:33 step:31365 [D loss: 0.627502, acc.: 61.72%] [G loss: 0.885778]\n",
      "epoch:33 step:31366 [D loss: 0.679581, acc.: 56.25%] [G loss: 0.893561]\n",
      "epoch:33 step:31367 [D loss: 0.697005, acc.: 53.91%] [G loss: 0.887145]\n",
      "epoch:33 step:31368 [D loss: 0.640935, acc.: 63.28%] [G loss: 0.909750]\n",
      "epoch:33 step:31369 [D loss: 0.643595, acc.: 63.28%] [G loss: 0.917484]\n",
      "epoch:33 step:31370 [D loss: 0.635675, acc.: 57.81%] [G loss: 0.906989]\n",
      "epoch:33 step:31371 [D loss: 0.649331, acc.: 64.06%] [G loss: 0.942722]\n",
      "epoch:33 step:31372 [D loss: 0.606720, acc.: 66.41%] [G loss: 0.889718]\n",
      "epoch:33 step:31373 [D loss: 0.657617, acc.: 57.81%] [G loss: 0.936980]\n",
      "epoch:33 step:31374 [D loss: 0.666984, acc.: 55.47%] [G loss: 0.874922]\n",
      "epoch:33 step:31375 [D loss: 0.650411, acc.: 57.03%] [G loss: 0.885917]\n",
      "epoch:33 step:31376 [D loss: 0.659028, acc.: 58.59%] [G loss: 0.878808]\n",
      "epoch:33 step:31377 [D loss: 0.692332, acc.: 56.25%] [G loss: 0.870697]\n",
      "epoch:33 step:31378 [D loss: 0.661554, acc.: 56.25%] [G loss: 0.931865]\n",
      "epoch:33 step:31379 [D loss: 0.680805, acc.: 53.12%] [G loss: 0.917169]\n",
      "epoch:33 step:31380 [D loss: 0.618971, acc.: 68.75%] [G loss: 0.949982]\n",
      "epoch:33 step:31381 [D loss: 0.657498, acc.: 61.72%] [G loss: 0.919371]\n",
      "epoch:33 step:31382 [D loss: 0.644043, acc.: 62.50%] [G loss: 0.959122]\n",
      "epoch:33 step:31383 [D loss: 0.645056, acc.: 62.50%] [G loss: 1.019200]\n",
      "epoch:33 step:31384 [D loss: 0.694913, acc.: 57.03%] [G loss: 0.952922]\n",
      "epoch:33 step:31385 [D loss: 0.660677, acc.: 55.47%] [G loss: 1.002491]\n",
      "epoch:33 step:31386 [D loss: 0.638271, acc.: 65.62%] [G loss: 0.919930]\n",
      "epoch:33 step:31387 [D loss: 0.635922, acc.: 62.50%] [G loss: 0.953505]\n",
      "epoch:33 step:31388 [D loss: 0.629291, acc.: 65.62%] [G loss: 0.903167]\n",
      "epoch:33 step:31389 [D loss: 0.656973, acc.: 61.72%] [G loss: 0.908240]\n",
      "epoch:33 step:31390 [D loss: 0.635113, acc.: 59.38%] [G loss: 0.840695]\n",
      "epoch:33 step:31391 [D loss: 0.684978, acc.: 52.34%] [G loss: 0.884116]\n",
      "epoch:33 step:31392 [D loss: 0.621168, acc.: 64.06%] [G loss: 0.891461]\n",
      "epoch:33 step:31393 [D loss: 0.634045, acc.: 58.59%] [G loss: 0.990577]\n",
      "epoch:33 step:31394 [D loss: 0.670436, acc.: 59.38%] [G loss: 0.992297]\n",
      "epoch:33 step:31395 [D loss: 0.615923, acc.: 64.06%] [G loss: 0.989058]\n",
      "epoch:33 step:31396 [D loss: 0.626670, acc.: 64.06%] [G loss: 0.966284]\n",
      "epoch:33 step:31397 [D loss: 0.667866, acc.: 62.50%] [G loss: 0.941380]\n",
      "epoch:33 step:31398 [D loss: 0.669829, acc.: 60.94%] [G loss: 0.881748]\n",
      "epoch:33 step:31399 [D loss: 0.622876, acc.: 64.84%] [G loss: 0.925346]\n",
      "epoch:33 step:31400 [D loss: 0.683127, acc.: 59.38%] [G loss: 0.924781]\n",
      "##############\n",
      "[ 3.08021257  2.19381407  2.05144223  4.25180088  1.16624827 10.27426719\n",
      "  2.95009795  3.15365587  4.33773486  7.14868929]\n",
      "##########\n",
      "epoch:33 step:31401 [D loss: 0.655353, acc.: 57.03%] [G loss: 0.873591]\n",
      "epoch:33 step:31402 [D loss: 0.642148, acc.: 60.94%] [G loss: 0.932868]\n",
      "epoch:33 step:31403 [D loss: 0.661791, acc.: 62.50%] [G loss: 0.895642]\n",
      "epoch:33 step:31404 [D loss: 0.655189, acc.: 64.06%] [G loss: 0.877894]\n",
      "epoch:33 step:31405 [D loss: 0.616270, acc.: 65.62%] [G loss: 0.874007]\n",
      "epoch:33 step:31406 [D loss: 0.629540, acc.: 60.16%] [G loss: 0.880162]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:31407 [D loss: 0.656408, acc.: 59.38%] [G loss: 0.872990]\n",
      "epoch:33 step:31408 [D loss: 0.660353, acc.: 57.81%] [G loss: 0.902659]\n",
      "epoch:33 step:31409 [D loss: 0.583628, acc.: 73.44%] [G loss: 0.910429]\n",
      "epoch:33 step:31410 [D loss: 0.651360, acc.: 64.84%] [G loss: 0.939034]\n",
      "epoch:33 step:31411 [D loss: 0.651992, acc.: 57.81%] [G loss: 0.916851]\n",
      "epoch:33 step:31412 [D loss: 0.661758, acc.: 56.25%] [G loss: 0.884927]\n",
      "epoch:33 step:31413 [D loss: 0.676126, acc.: 63.28%] [G loss: 0.868253]\n",
      "epoch:33 step:31414 [D loss: 0.656037, acc.: 61.72%] [G loss: 0.878551]\n",
      "epoch:33 step:31415 [D loss: 0.612092, acc.: 64.06%] [G loss: 0.940341]\n",
      "epoch:33 step:31416 [D loss: 0.638873, acc.: 63.28%] [G loss: 0.926624]\n",
      "epoch:33 step:31417 [D loss: 0.617655, acc.: 64.84%] [G loss: 0.885509]\n",
      "epoch:33 step:31418 [D loss: 0.635938, acc.: 62.50%] [G loss: 0.901254]\n",
      "epoch:33 step:31419 [D loss: 0.666016, acc.: 60.94%] [G loss: 0.882068]\n",
      "epoch:33 step:31420 [D loss: 0.625044, acc.: 63.28%] [G loss: 1.070051]\n",
      "epoch:33 step:31421 [D loss: 0.662482, acc.: 61.72%] [G loss: 0.927433]\n",
      "epoch:33 step:31422 [D loss: 0.677666, acc.: 60.16%] [G loss: 0.916364]\n",
      "epoch:33 step:31423 [D loss: 0.652196, acc.: 60.94%] [G loss: 0.915455]\n",
      "epoch:33 step:31424 [D loss: 0.656935, acc.: 63.28%] [G loss: 0.853788]\n",
      "epoch:33 step:31425 [D loss: 0.636628, acc.: 67.19%] [G loss: 0.930940]\n",
      "epoch:33 step:31426 [D loss: 0.657601, acc.: 61.72%] [G loss: 0.899106]\n",
      "epoch:33 step:31427 [D loss: 0.704747, acc.: 54.69%] [G loss: 0.923687]\n",
      "epoch:33 step:31428 [D loss: 0.674668, acc.: 60.16%] [G loss: 0.821477]\n",
      "epoch:33 step:31429 [D loss: 0.629735, acc.: 68.75%] [G loss: 0.937129]\n",
      "epoch:33 step:31430 [D loss: 0.670318, acc.: 60.16%] [G loss: 0.961142]\n",
      "epoch:33 step:31431 [D loss: 0.608095, acc.: 67.19%] [G loss: 0.934109]\n",
      "epoch:33 step:31432 [D loss: 0.650089, acc.: 61.72%] [G loss: 0.862674]\n",
      "epoch:33 step:31433 [D loss: 0.708460, acc.: 55.47%] [G loss: 0.863019]\n",
      "epoch:33 step:31434 [D loss: 0.673805, acc.: 59.38%] [G loss: 0.903875]\n",
      "epoch:33 step:31435 [D loss: 0.640233, acc.: 64.84%] [G loss: 0.987604]\n",
      "epoch:33 step:31436 [D loss: 0.664195, acc.: 60.16%] [G loss: 0.848693]\n",
      "epoch:33 step:31437 [D loss: 0.640035, acc.: 61.72%] [G loss: 0.973750]\n",
      "epoch:33 step:31438 [D loss: 0.621350, acc.: 67.97%] [G loss: 0.924678]\n",
      "epoch:33 step:31439 [D loss: 0.666370, acc.: 62.50%] [G loss: 0.938426]\n",
      "epoch:33 step:31440 [D loss: 0.646399, acc.: 67.19%] [G loss: 0.884332]\n",
      "epoch:33 step:31441 [D loss: 0.631239, acc.: 64.84%] [G loss: 0.971902]\n",
      "epoch:33 step:31442 [D loss: 0.634348, acc.: 64.84%] [G loss: 0.879781]\n",
      "epoch:33 step:31443 [D loss: 0.626962, acc.: 70.31%] [G loss: 0.932719]\n",
      "epoch:33 step:31444 [D loss: 0.644246, acc.: 58.59%] [G loss: 0.922075]\n",
      "epoch:33 step:31445 [D loss: 0.643065, acc.: 63.28%] [G loss: 1.002562]\n",
      "epoch:33 step:31446 [D loss: 0.666430, acc.: 53.91%] [G loss: 0.893115]\n",
      "epoch:33 step:31447 [D loss: 0.641164, acc.: 62.50%] [G loss: 0.884505]\n",
      "epoch:33 step:31448 [D loss: 0.689535, acc.: 54.69%] [G loss: 0.917938]\n",
      "epoch:33 step:31449 [D loss: 0.660014, acc.: 58.59%] [G loss: 0.889041]\n",
      "epoch:33 step:31450 [D loss: 0.588199, acc.: 68.75%] [G loss: 0.963286]\n",
      "epoch:33 step:31451 [D loss: 0.652755, acc.: 60.16%] [G loss: 0.926425]\n",
      "epoch:33 step:31452 [D loss: 0.643865, acc.: 67.19%] [G loss: 0.945903]\n",
      "epoch:33 step:31453 [D loss: 0.677480, acc.: 55.47%] [G loss: 0.913796]\n",
      "epoch:33 step:31454 [D loss: 0.642635, acc.: 61.72%] [G loss: 0.912926]\n",
      "epoch:33 step:31455 [D loss: 0.629731, acc.: 62.50%] [G loss: 0.925870]\n",
      "epoch:33 step:31456 [D loss: 0.630735, acc.: 61.72%] [G loss: 0.861067]\n",
      "epoch:33 step:31457 [D loss: 0.661359, acc.: 57.81%] [G loss: 0.952018]\n",
      "epoch:33 step:31458 [D loss: 0.647692, acc.: 61.72%] [G loss: 0.913081]\n",
      "epoch:33 step:31459 [D loss: 0.668623, acc.: 60.94%] [G loss: 0.908646]\n",
      "epoch:33 step:31460 [D loss: 0.635090, acc.: 62.50%] [G loss: 0.952918]\n",
      "epoch:33 step:31461 [D loss: 0.647095, acc.: 60.16%] [G loss: 0.892968]\n",
      "epoch:33 step:31462 [D loss: 0.659085, acc.: 56.25%] [G loss: 0.926396]\n",
      "epoch:33 step:31463 [D loss: 0.638725, acc.: 64.84%] [G loss: 0.931687]\n",
      "epoch:33 step:31464 [D loss: 0.637247, acc.: 64.84%] [G loss: 0.938588]\n",
      "epoch:33 step:31465 [D loss: 0.632840, acc.: 63.28%] [G loss: 0.881051]\n",
      "epoch:33 step:31466 [D loss: 0.640103, acc.: 61.72%] [G loss: 0.931012]\n",
      "epoch:33 step:31467 [D loss: 0.653247, acc.: 61.72%] [G loss: 0.884286]\n",
      "epoch:33 step:31468 [D loss: 0.664940, acc.: 51.56%] [G loss: 0.927614]\n",
      "epoch:33 step:31469 [D loss: 0.706171, acc.: 47.66%] [G loss: 0.901984]\n",
      "epoch:33 step:31470 [D loss: 0.625132, acc.: 61.72%] [G loss: 0.900140]\n",
      "epoch:33 step:31471 [D loss: 0.666092, acc.: 54.69%] [G loss: 0.914687]\n",
      "epoch:33 step:31472 [D loss: 0.623279, acc.: 60.94%] [G loss: 0.868211]\n",
      "epoch:33 step:31473 [D loss: 0.642149, acc.: 65.62%] [G loss: 0.952297]\n",
      "epoch:33 step:31474 [D loss: 0.585110, acc.: 69.53%] [G loss: 0.953312]\n",
      "epoch:33 step:31475 [D loss: 0.668278, acc.: 60.94%] [G loss: 0.861452]\n",
      "epoch:33 step:31476 [D loss: 0.642179, acc.: 65.62%] [G loss: 0.869608]\n",
      "epoch:33 step:31477 [D loss: 0.628223, acc.: 65.62%] [G loss: 0.883445]\n",
      "epoch:33 step:31478 [D loss: 0.640414, acc.: 66.41%] [G loss: 0.900647]\n",
      "epoch:33 step:31479 [D loss: 0.633987, acc.: 67.97%] [G loss: 0.898813]\n",
      "epoch:33 step:31480 [D loss: 0.651715, acc.: 60.94%] [G loss: 0.910487]\n",
      "epoch:33 step:31481 [D loss: 0.631254, acc.: 62.50%] [G loss: 0.935486]\n",
      "epoch:33 step:31482 [D loss: 0.653242, acc.: 60.94%] [G loss: 0.909623]\n",
      "epoch:33 step:31483 [D loss: 0.642356, acc.: 64.06%] [G loss: 0.961953]\n",
      "epoch:33 step:31484 [D loss: 0.642301, acc.: 59.38%] [G loss: 0.931815]\n",
      "epoch:33 step:31485 [D loss: 0.640525, acc.: 61.72%] [G loss: 0.899123]\n",
      "epoch:33 step:31486 [D loss: 0.649630, acc.: 58.59%] [G loss: 0.843283]\n",
      "epoch:33 step:31487 [D loss: 0.595280, acc.: 67.97%] [G loss: 0.924291]\n",
      "epoch:33 step:31488 [D loss: 0.604108, acc.: 67.97%] [G loss: 0.950641]\n",
      "epoch:33 step:31489 [D loss: 0.681309, acc.: 57.03%] [G loss: 0.922976]\n",
      "epoch:33 step:31490 [D loss: 0.647196, acc.: 60.16%] [G loss: 0.951694]\n",
      "epoch:33 step:31491 [D loss: 0.651771, acc.: 61.72%] [G loss: 0.924204]\n",
      "epoch:33 step:31492 [D loss: 0.665091, acc.: 57.81%] [G loss: 0.904112]\n",
      "epoch:33 step:31493 [D loss: 0.644490, acc.: 61.72%] [G loss: 0.866132]\n",
      "epoch:33 step:31494 [D loss: 0.654476, acc.: 59.38%] [G loss: 0.877529]\n",
      "epoch:33 step:31495 [D loss: 0.685651, acc.: 57.81%] [G loss: 0.890431]\n",
      "epoch:33 step:31496 [D loss: 0.671628, acc.: 56.25%] [G loss: 0.918524]\n",
      "epoch:33 step:31497 [D loss: 0.622800, acc.: 66.41%] [G loss: 0.944494]\n",
      "epoch:33 step:31498 [D loss: 0.627959, acc.: 67.19%] [G loss: 0.944386]\n",
      "epoch:33 step:31499 [D loss: 0.667905, acc.: 55.47%] [G loss: 0.916545]\n",
      "epoch:33 step:31500 [D loss: 0.643466, acc.: 68.75%] [G loss: 0.925299]\n",
      "epoch:33 step:31501 [D loss: 0.660446, acc.: 57.03%] [G loss: 0.945342]\n",
      "epoch:33 step:31502 [D loss: 0.629668, acc.: 63.28%] [G loss: 0.888306]\n",
      "epoch:33 step:31503 [D loss: 0.603952, acc.: 65.62%] [G loss: 0.856476]\n",
      "epoch:33 step:31504 [D loss: 0.687427, acc.: 57.03%] [G loss: 0.934836]\n",
      "epoch:33 step:31505 [D loss: 0.660928, acc.: 61.72%] [G loss: 0.920864]\n",
      "epoch:33 step:31506 [D loss: 0.635990, acc.: 60.16%] [G loss: 0.845741]\n",
      "epoch:33 step:31507 [D loss: 0.704924, acc.: 52.34%] [G loss: 0.892458]\n",
      "epoch:33 step:31508 [D loss: 0.644317, acc.: 61.72%] [G loss: 1.008546]\n",
      "epoch:33 step:31509 [D loss: 0.675092, acc.: 58.59%] [G loss: 0.954609]\n",
      "epoch:33 step:31510 [D loss: 0.622202, acc.: 64.06%] [G loss: 0.925355]\n",
      "epoch:33 step:31511 [D loss: 0.685758, acc.: 53.12%] [G loss: 0.939544]\n",
      "epoch:33 step:31512 [D loss: 0.645918, acc.: 60.94%] [G loss: 0.929425]\n",
      "epoch:33 step:31513 [D loss: 0.658415, acc.: 59.38%] [G loss: 0.991731]\n",
      "epoch:33 step:31514 [D loss: 0.674189, acc.: 53.91%] [G loss: 0.925668]\n",
      "epoch:33 step:31515 [D loss: 0.621313, acc.: 64.84%] [G loss: 0.924600]\n",
      "epoch:33 step:31516 [D loss: 0.647208, acc.: 57.81%] [G loss: 0.899474]\n",
      "epoch:33 step:31517 [D loss: 0.629345, acc.: 69.53%] [G loss: 0.896755]\n",
      "epoch:33 step:31518 [D loss: 0.646137, acc.: 61.72%] [G loss: 0.863438]\n",
      "epoch:33 step:31519 [D loss: 0.666775, acc.: 61.72%] [G loss: 0.868580]\n",
      "epoch:33 step:31520 [D loss: 0.621037, acc.: 67.97%] [G loss: 0.915202]\n",
      "epoch:33 step:31521 [D loss: 0.673247, acc.: 56.25%] [G loss: 0.937827]\n",
      "epoch:33 step:31522 [D loss: 0.652957, acc.: 57.81%] [G loss: 0.910942]\n",
      "epoch:33 step:31523 [D loss: 0.644436, acc.: 59.38%] [G loss: 0.953973]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:31524 [D loss: 0.680408, acc.: 53.12%] [G loss: 0.912208]\n",
      "epoch:33 step:31525 [D loss: 0.686126, acc.: 51.56%] [G loss: 0.950216]\n",
      "epoch:33 step:31526 [D loss: 0.646625, acc.: 61.72%] [G loss: 0.938111]\n",
      "epoch:33 step:31527 [D loss: 0.642761, acc.: 69.53%] [G loss: 0.913440]\n",
      "epoch:33 step:31528 [D loss: 0.649457, acc.: 62.50%] [G loss: 0.949865]\n",
      "epoch:33 step:31529 [D loss: 0.666324, acc.: 60.94%] [G loss: 0.924286]\n",
      "epoch:33 step:31530 [D loss: 0.628010, acc.: 67.19%] [G loss: 0.914457]\n",
      "epoch:33 step:31531 [D loss: 0.654373, acc.: 60.16%] [G loss: 0.973531]\n",
      "epoch:33 step:31532 [D loss: 0.664616, acc.: 61.72%] [G loss: 0.872696]\n",
      "epoch:33 step:31533 [D loss: 0.652417, acc.: 57.81%] [G loss: 0.864673]\n",
      "epoch:33 step:31534 [D loss: 0.678504, acc.: 57.03%] [G loss: 0.939021]\n",
      "epoch:33 step:31535 [D loss: 0.634694, acc.: 60.16%] [G loss: 0.914038]\n",
      "epoch:33 step:31536 [D loss: 0.643305, acc.: 61.72%] [G loss: 0.897581]\n",
      "epoch:33 step:31537 [D loss: 0.635786, acc.: 68.75%] [G loss: 0.928872]\n",
      "epoch:33 step:31538 [D loss: 0.664783, acc.: 64.06%] [G loss: 0.934186]\n",
      "epoch:33 step:31539 [D loss: 0.614624, acc.: 62.50%] [G loss: 0.895625]\n",
      "epoch:33 step:31540 [D loss: 0.649070, acc.: 63.28%] [G loss: 0.884038]\n",
      "epoch:33 step:31541 [D loss: 0.696307, acc.: 55.47%] [G loss: 0.910013]\n",
      "epoch:33 step:31542 [D loss: 0.687967, acc.: 57.81%] [G loss: 0.932815]\n",
      "epoch:33 step:31543 [D loss: 0.628428, acc.: 66.41%] [G loss: 0.930637]\n",
      "epoch:33 step:31544 [D loss: 0.615597, acc.: 69.53%] [G loss: 0.955422]\n",
      "epoch:33 step:31545 [D loss: 0.668713, acc.: 60.94%] [G loss: 0.947259]\n",
      "epoch:33 step:31546 [D loss: 0.606343, acc.: 66.41%] [G loss: 0.952367]\n",
      "epoch:33 step:31547 [D loss: 0.734808, acc.: 51.56%] [G loss: 0.904478]\n",
      "epoch:33 step:31548 [D loss: 0.682216, acc.: 53.91%] [G loss: 0.905384]\n",
      "epoch:33 step:31549 [D loss: 0.659818, acc.: 60.16%] [G loss: 0.910056]\n",
      "epoch:33 step:31550 [D loss: 0.628412, acc.: 64.84%] [G loss: 0.853155]\n",
      "epoch:33 step:31551 [D loss: 0.669221, acc.: 54.69%] [G loss: 0.953163]\n",
      "epoch:33 step:31552 [D loss: 0.598276, acc.: 68.75%] [G loss: 0.906476]\n",
      "epoch:33 step:31553 [D loss: 0.636229, acc.: 59.38%] [G loss: 0.887847]\n",
      "epoch:33 step:31554 [D loss: 0.648022, acc.: 67.19%] [G loss: 0.944392]\n",
      "epoch:33 step:31555 [D loss: 0.636349, acc.: 63.28%] [G loss: 0.927805]\n",
      "epoch:33 step:31556 [D loss: 0.639090, acc.: 66.41%] [G loss: 0.970573]\n",
      "epoch:33 step:31557 [D loss: 0.579387, acc.: 71.09%] [G loss: 0.991869]\n",
      "epoch:33 step:31558 [D loss: 0.609103, acc.: 64.06%] [G loss: 1.022021]\n",
      "epoch:33 step:31559 [D loss: 0.635436, acc.: 64.06%] [G loss: 0.946212]\n",
      "epoch:33 step:31560 [D loss: 0.638554, acc.: 60.94%] [G loss: 1.011630]\n",
      "epoch:33 step:31561 [D loss: 0.642745, acc.: 60.16%] [G loss: 0.983301]\n",
      "epoch:33 step:31562 [D loss: 0.650981, acc.: 59.38%] [G loss: 0.998785]\n",
      "epoch:33 step:31563 [D loss: 0.632793, acc.: 64.84%] [G loss: 0.969062]\n",
      "epoch:33 step:31564 [D loss: 0.681476, acc.: 54.69%] [G loss: 0.966407]\n",
      "epoch:33 step:31565 [D loss: 0.655755, acc.: 64.84%] [G loss: 0.910574]\n",
      "epoch:33 step:31566 [D loss: 0.618830, acc.: 65.62%] [G loss: 0.905668]\n",
      "epoch:33 step:31567 [D loss: 0.676504, acc.: 57.03%] [G loss: 0.966876]\n",
      "epoch:33 step:31568 [D loss: 0.682608, acc.: 56.25%] [G loss: 0.832627]\n",
      "epoch:33 step:31569 [D loss: 0.625843, acc.: 63.28%] [G loss: 0.918639]\n",
      "epoch:33 step:31570 [D loss: 0.669411, acc.: 54.69%] [G loss: 0.919677]\n",
      "epoch:33 step:31571 [D loss: 0.649410, acc.: 62.50%] [G loss: 0.870808]\n",
      "epoch:33 step:31572 [D loss: 0.634895, acc.: 60.16%] [G loss: 0.999841]\n",
      "epoch:33 step:31573 [D loss: 0.642651, acc.: 62.50%] [G loss: 0.920464]\n",
      "epoch:33 step:31574 [D loss: 0.634634, acc.: 60.94%] [G loss: 0.862274]\n",
      "epoch:33 step:31575 [D loss: 0.604941, acc.: 65.62%] [G loss: 0.938078]\n",
      "epoch:33 step:31576 [D loss: 0.699786, acc.: 54.69%] [G loss: 0.916355]\n",
      "epoch:33 step:31577 [D loss: 0.615749, acc.: 68.75%] [G loss: 0.960065]\n",
      "epoch:33 step:31578 [D loss: 0.668326, acc.: 55.47%] [G loss: 0.889261]\n",
      "epoch:33 step:31579 [D loss: 0.683282, acc.: 53.91%] [G loss: 0.919526]\n",
      "epoch:33 step:31580 [D loss: 0.687106, acc.: 50.00%] [G loss: 0.897572]\n",
      "epoch:33 step:31581 [D loss: 0.693640, acc.: 55.47%] [G loss: 0.972818]\n",
      "epoch:33 step:31582 [D loss: 0.650910, acc.: 60.94%] [G loss: 0.993547]\n",
      "epoch:33 step:31583 [D loss: 0.669510, acc.: 56.25%] [G loss: 0.925601]\n",
      "epoch:33 step:31584 [D loss: 0.629843, acc.: 63.28%] [G loss: 0.889513]\n",
      "epoch:33 step:31585 [D loss: 0.624108, acc.: 66.41%] [G loss: 0.936961]\n",
      "epoch:33 step:31586 [D loss: 0.687366, acc.: 60.94%] [G loss: 0.909879]\n",
      "epoch:33 step:31587 [D loss: 0.645114, acc.: 58.59%] [G loss: 0.932572]\n",
      "epoch:33 step:31588 [D loss: 0.613209, acc.: 66.41%] [G loss: 0.879472]\n",
      "epoch:33 step:31589 [D loss: 0.646467, acc.: 64.84%] [G loss: 0.883750]\n",
      "epoch:33 step:31590 [D loss: 0.666258, acc.: 61.72%] [G loss: 0.863941]\n",
      "epoch:33 step:31591 [D loss: 0.646014, acc.: 58.59%] [G loss: 0.937991]\n",
      "epoch:33 step:31592 [D loss: 0.671369, acc.: 58.59%] [G loss: 0.884692]\n",
      "epoch:33 step:31593 [D loss: 0.644474, acc.: 59.38%] [G loss: 0.960185]\n",
      "epoch:33 step:31594 [D loss: 0.672225, acc.: 57.81%] [G loss: 0.961996]\n",
      "epoch:33 step:31595 [D loss: 0.621696, acc.: 61.72%] [G loss: 0.969880]\n",
      "epoch:33 step:31596 [D loss: 0.650960, acc.: 57.81%] [G loss: 0.971191]\n",
      "epoch:33 step:31597 [D loss: 0.643927, acc.: 61.72%] [G loss: 1.005146]\n",
      "epoch:33 step:31598 [D loss: 0.640810, acc.: 63.28%] [G loss: 0.941461]\n",
      "epoch:33 step:31599 [D loss: 0.649783, acc.: 66.41%] [G loss: 0.930739]\n",
      "epoch:33 step:31600 [D loss: 0.670335, acc.: 53.91%] [G loss: 0.929172]\n",
      "##############\n",
      "[3.10887214 2.55602181 2.58729215 3.83137987 1.21748417 7.90261566\n",
      " 2.48741619 3.02655201 4.07181226 7.14868929]\n",
      "##########\n",
      "epoch:33 step:31601 [D loss: 0.624105, acc.: 64.84%] [G loss: 0.854457]\n",
      "epoch:33 step:31602 [D loss: 0.626656, acc.: 63.28%] [G loss: 0.905250]\n",
      "epoch:33 step:31603 [D loss: 0.643531, acc.: 60.16%] [G loss: 0.879104]\n",
      "epoch:33 step:31604 [D loss: 0.623192, acc.: 64.06%] [G loss: 0.873234]\n",
      "epoch:33 step:31605 [D loss: 0.649584, acc.: 61.72%] [G loss: 0.886267]\n",
      "epoch:33 step:31606 [D loss: 0.671021, acc.: 64.84%] [G loss: 0.898901]\n",
      "epoch:33 step:31607 [D loss: 0.642325, acc.: 67.97%] [G loss: 0.882761]\n",
      "epoch:33 step:31608 [D loss: 0.663120, acc.: 60.16%] [G loss: 0.949470]\n",
      "epoch:33 step:31609 [D loss: 0.616764, acc.: 63.28%] [G loss: 0.941452]\n",
      "epoch:33 step:31610 [D loss: 0.650526, acc.: 61.72%] [G loss: 0.926718]\n",
      "epoch:33 step:31611 [D loss: 0.651750, acc.: 58.59%] [G loss: 0.876059]\n",
      "epoch:33 step:31612 [D loss: 0.682507, acc.: 60.94%] [G loss: 0.850220]\n",
      "epoch:33 step:31613 [D loss: 0.642372, acc.: 64.84%] [G loss: 0.945319]\n",
      "epoch:33 step:31614 [D loss: 0.647910, acc.: 60.16%] [G loss: 0.912714]\n",
      "epoch:33 step:31615 [D loss: 0.620160, acc.: 63.28%] [G loss: 0.912290]\n",
      "epoch:33 step:31616 [D loss: 0.678956, acc.: 56.25%] [G loss: 0.924909]\n",
      "epoch:33 step:31617 [D loss: 0.610681, acc.: 66.41%] [G loss: 0.935786]\n",
      "epoch:33 step:31618 [D loss: 0.671036, acc.: 57.81%] [G loss: 0.983450]\n",
      "epoch:33 step:31619 [D loss: 0.641060, acc.: 63.28%] [G loss: 0.936858]\n",
      "epoch:33 step:31620 [D loss: 0.613063, acc.: 70.31%] [G loss: 0.984162]\n",
      "epoch:33 step:31621 [D loss: 0.605576, acc.: 64.84%] [G loss: 0.928643]\n",
      "epoch:33 step:31622 [D loss: 0.644435, acc.: 61.72%] [G loss: 0.922445]\n",
      "epoch:33 step:31623 [D loss: 0.616875, acc.: 68.75%] [G loss: 0.985746]\n",
      "epoch:33 step:31624 [D loss: 0.672770, acc.: 59.38%] [G loss: 0.963420]\n",
      "epoch:33 step:31625 [D loss: 0.641498, acc.: 66.41%] [G loss: 0.919563]\n",
      "epoch:33 step:31626 [D loss: 0.652107, acc.: 58.59%] [G loss: 0.891313]\n",
      "epoch:33 step:31627 [D loss: 0.648628, acc.: 60.94%] [G loss: 0.931484]\n",
      "epoch:33 step:31628 [D loss: 0.642347, acc.: 60.94%] [G loss: 0.874795]\n",
      "epoch:33 step:31629 [D loss: 0.645137, acc.: 62.50%] [G loss: 0.877577]\n",
      "epoch:33 step:31630 [D loss: 0.698858, acc.: 52.34%] [G loss: 0.942692]\n",
      "epoch:33 step:31631 [D loss: 0.627417, acc.: 67.19%] [G loss: 0.931418]\n",
      "epoch:33 step:31632 [D loss: 0.695867, acc.: 57.03%] [G loss: 1.026183]\n",
      "epoch:33 step:31633 [D loss: 0.651603, acc.: 62.50%] [G loss: 0.976400]\n",
      "epoch:33 step:31634 [D loss: 0.628389, acc.: 64.06%] [G loss: 0.911950]\n",
      "epoch:33 step:31635 [D loss: 0.670895, acc.: 60.16%] [G loss: 0.908343]\n",
      "epoch:33 step:31636 [D loss: 0.684705, acc.: 58.59%] [G loss: 0.841666]\n",
      "epoch:33 step:31637 [D loss: 0.655080, acc.: 59.38%] [G loss: 0.871028]\n",
      "epoch:33 step:31638 [D loss: 0.613816, acc.: 67.97%] [G loss: 0.886570]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:31639 [D loss: 0.635550, acc.: 62.50%] [G loss: 0.958243]\n",
      "epoch:33 step:31640 [D loss: 0.672889, acc.: 57.03%] [G loss: 0.981551]\n",
      "epoch:33 step:31641 [D loss: 0.643369, acc.: 63.28%] [G loss: 0.920032]\n",
      "epoch:33 step:31642 [D loss: 0.625913, acc.: 67.97%] [G loss: 0.888200]\n",
      "epoch:33 step:31643 [D loss: 0.638083, acc.: 69.53%] [G loss: 0.952730]\n",
      "epoch:33 step:31644 [D loss: 0.674882, acc.: 52.34%] [G loss: 0.927414]\n",
      "epoch:33 step:31645 [D loss: 0.626205, acc.: 63.28%] [G loss: 0.965785]\n",
      "epoch:33 step:31646 [D loss: 0.612740, acc.: 68.75%] [G loss: 0.884689]\n",
      "epoch:33 step:31647 [D loss: 0.658375, acc.: 58.59%] [G loss: 0.864144]\n",
      "epoch:33 step:31648 [D loss: 0.621980, acc.: 64.06%] [G loss: 0.945097]\n",
      "epoch:33 step:31649 [D loss: 0.660099, acc.: 57.81%] [G loss: 0.948985]\n",
      "epoch:33 step:31650 [D loss: 0.637211, acc.: 73.44%] [G loss: 0.963711]\n",
      "epoch:33 step:31651 [D loss: 0.642641, acc.: 63.28%] [G loss: 1.008719]\n",
      "epoch:33 step:31652 [D loss: 0.623913, acc.: 69.53%] [G loss: 0.956787]\n",
      "epoch:33 step:31653 [D loss: 0.641629, acc.: 60.94%] [G loss: 0.906100]\n",
      "epoch:33 step:31654 [D loss: 0.664302, acc.: 61.72%] [G loss: 0.919806]\n",
      "epoch:33 step:31655 [D loss: 0.603479, acc.: 67.19%] [G loss: 0.938805]\n",
      "epoch:33 step:31656 [D loss: 0.627151, acc.: 60.94%] [G loss: 0.930068]\n",
      "epoch:33 step:31657 [D loss: 0.630554, acc.: 61.72%] [G loss: 0.919791]\n",
      "epoch:33 step:31658 [D loss: 0.654121, acc.: 60.16%] [G loss: 0.932436]\n",
      "epoch:33 step:31659 [D loss: 0.662590, acc.: 60.16%] [G loss: 0.967617]\n",
      "epoch:33 step:31660 [D loss: 0.681702, acc.: 60.16%] [G loss: 0.925374]\n",
      "epoch:33 step:31661 [D loss: 0.681851, acc.: 59.38%] [G loss: 0.944026]\n",
      "epoch:33 step:31662 [D loss: 0.624912, acc.: 63.28%] [G loss: 0.957839]\n",
      "epoch:33 step:31663 [D loss: 0.647252, acc.: 67.19%] [G loss: 0.955587]\n",
      "epoch:33 step:31664 [D loss: 0.678899, acc.: 52.34%] [G loss: 0.886914]\n",
      "epoch:33 step:31665 [D loss: 0.630870, acc.: 66.41%] [G loss: 0.847632]\n",
      "epoch:33 step:31666 [D loss: 0.658260, acc.: 56.25%] [G loss: 0.949346]\n",
      "epoch:33 step:31667 [D loss: 0.616714, acc.: 68.75%] [G loss: 0.933371]\n",
      "epoch:33 step:31668 [D loss: 0.659510, acc.: 64.84%] [G loss: 0.972370]\n",
      "epoch:33 step:31669 [D loss: 0.591764, acc.: 69.53%] [G loss: 0.965290]\n",
      "epoch:33 step:31670 [D loss: 0.643783, acc.: 60.16%] [G loss: 0.939272]\n",
      "epoch:33 step:31671 [D loss: 0.643411, acc.: 65.62%] [G loss: 0.908813]\n",
      "epoch:33 step:31672 [D loss: 0.627821, acc.: 69.53%] [G loss: 0.971351]\n",
      "epoch:33 step:31673 [D loss: 0.649840, acc.: 62.50%] [G loss: 0.940777]\n",
      "epoch:33 step:31674 [D loss: 0.667139, acc.: 57.03%] [G loss: 0.886283]\n",
      "epoch:33 step:31675 [D loss: 0.638016, acc.: 62.50%] [G loss: 0.890263]\n",
      "epoch:33 step:31676 [D loss: 0.671543, acc.: 55.47%] [G loss: 0.934845]\n",
      "epoch:33 step:31677 [D loss: 0.644378, acc.: 63.28%] [G loss: 0.938528]\n",
      "epoch:33 step:31678 [D loss: 0.652339, acc.: 61.72%] [G loss: 0.863103]\n",
      "epoch:33 step:31679 [D loss: 0.630079, acc.: 63.28%] [G loss: 0.944877]\n",
      "epoch:33 step:31680 [D loss: 0.641921, acc.: 68.75%] [G loss: 0.899793]\n",
      "epoch:33 step:31681 [D loss: 0.660114, acc.: 57.81%] [G loss: 0.863627]\n",
      "epoch:33 step:31682 [D loss: 0.636239, acc.: 60.16%] [G loss: 1.001057]\n",
      "epoch:33 step:31683 [D loss: 0.684884, acc.: 54.69%] [G loss: 0.956383]\n",
      "epoch:33 step:31684 [D loss: 0.643170, acc.: 63.28%] [G loss: 0.932327]\n",
      "epoch:33 step:31685 [D loss: 0.611003, acc.: 70.31%] [G loss: 0.914225]\n",
      "epoch:33 step:31686 [D loss: 0.648996, acc.: 60.94%] [G loss: 0.893736]\n",
      "epoch:33 step:31687 [D loss: 0.637938, acc.: 62.50%] [G loss: 0.845630]\n",
      "epoch:33 step:31688 [D loss: 0.634120, acc.: 64.06%] [G loss: 0.892573]\n",
      "epoch:33 step:31689 [D loss: 0.631047, acc.: 68.75%] [G loss: 0.870398]\n",
      "epoch:33 step:31690 [D loss: 0.619193, acc.: 71.88%] [G loss: 0.943750]\n",
      "epoch:33 step:31691 [D loss: 0.630073, acc.: 61.72%] [G loss: 0.919449]\n",
      "epoch:33 step:31692 [D loss: 0.673518, acc.: 59.38%] [G loss: 0.859477]\n",
      "epoch:33 step:31693 [D loss: 0.626346, acc.: 66.41%] [G loss: 0.899471]\n",
      "epoch:33 step:31694 [D loss: 0.681049, acc.: 58.59%] [G loss: 0.955494]\n",
      "epoch:33 step:31695 [D loss: 0.602392, acc.: 66.41%] [G loss: 0.978938]\n",
      "epoch:33 step:31696 [D loss: 0.603424, acc.: 66.41%] [G loss: 0.955713]\n",
      "epoch:33 step:31697 [D loss: 0.631211, acc.: 65.62%] [G loss: 0.948116]\n",
      "epoch:33 step:31698 [D loss: 0.688944, acc.: 60.94%] [G loss: 0.956426]\n",
      "epoch:33 step:31699 [D loss: 0.586669, acc.: 71.09%] [G loss: 0.928976]\n",
      "epoch:33 step:31700 [D loss: 0.652555, acc.: 58.59%] [G loss: 0.913887]\n",
      "epoch:33 step:31701 [D loss: 0.648955, acc.: 61.72%] [G loss: 0.923439]\n",
      "epoch:33 step:31702 [D loss: 0.655753, acc.: 59.38%] [G loss: 0.950988]\n",
      "epoch:33 step:31703 [D loss: 0.609982, acc.: 62.50%] [G loss: 0.928236]\n",
      "epoch:33 step:31704 [D loss: 0.627050, acc.: 61.72%] [G loss: 0.914024]\n",
      "epoch:33 step:31705 [D loss: 0.651959, acc.: 57.81%] [G loss: 0.874918]\n",
      "epoch:33 step:31706 [D loss: 0.634960, acc.: 63.28%] [G loss: 0.948024]\n",
      "epoch:33 step:31707 [D loss: 0.661329, acc.: 58.59%] [G loss: 0.917363]\n",
      "epoch:33 step:31708 [D loss: 0.608432, acc.: 66.41%] [G loss: 0.899321]\n",
      "epoch:33 step:31709 [D loss: 0.653814, acc.: 59.38%] [G loss: 0.898380]\n",
      "epoch:33 step:31710 [D loss: 0.655833, acc.: 58.59%] [G loss: 0.851885]\n",
      "epoch:33 step:31711 [D loss: 0.683067, acc.: 55.47%] [G loss: 0.950245]\n",
      "epoch:33 step:31712 [D loss: 0.619275, acc.: 70.31%] [G loss: 0.951104]\n",
      "epoch:33 step:31713 [D loss: 0.639220, acc.: 67.19%] [G loss: 0.928740]\n",
      "epoch:33 step:31714 [D loss: 0.638408, acc.: 60.94%] [G loss: 0.919314]\n",
      "epoch:33 step:31715 [D loss: 0.601461, acc.: 68.75%] [G loss: 0.925090]\n",
      "epoch:33 step:31716 [D loss: 0.633531, acc.: 64.06%] [G loss: 0.898648]\n",
      "epoch:33 step:31717 [D loss: 0.656311, acc.: 60.94%] [G loss: 0.949361]\n",
      "epoch:33 step:31718 [D loss: 0.679410, acc.: 53.91%] [G loss: 0.906115]\n",
      "epoch:33 step:31719 [D loss: 0.678658, acc.: 57.03%] [G loss: 0.926952]\n",
      "epoch:33 step:31720 [D loss: 0.623668, acc.: 64.84%] [G loss: 0.957683]\n",
      "epoch:33 step:31721 [D loss: 0.645712, acc.: 65.62%] [G loss: 0.895811]\n",
      "epoch:33 step:31722 [D loss: 0.638203, acc.: 62.50%] [G loss: 0.876573]\n",
      "epoch:33 step:31723 [D loss: 0.677292, acc.: 60.16%] [G loss: 0.941325]\n",
      "epoch:33 step:31724 [D loss: 0.657428, acc.: 60.94%] [G loss: 0.899336]\n",
      "epoch:33 step:31725 [D loss: 0.678278, acc.: 58.59%] [G loss: 0.885958]\n",
      "epoch:33 step:31726 [D loss: 0.653815, acc.: 56.25%] [G loss: 0.917533]\n",
      "epoch:33 step:31727 [D loss: 0.640687, acc.: 60.94%] [G loss: 0.915920]\n",
      "epoch:33 step:31728 [D loss: 0.646210, acc.: 61.72%] [G loss: 0.936736]\n",
      "epoch:33 step:31729 [D loss: 0.655759, acc.: 65.62%] [G loss: 0.931523]\n",
      "epoch:33 step:31730 [D loss: 0.624060, acc.: 65.62%] [G loss: 1.000960]\n",
      "epoch:33 step:31731 [D loss: 0.630256, acc.: 59.38%] [G loss: 0.972624]\n",
      "epoch:33 step:31732 [D loss: 0.655670, acc.: 62.50%] [G loss: 0.985419]\n",
      "epoch:33 step:31733 [D loss: 0.635381, acc.: 60.16%] [G loss: 0.911611]\n",
      "epoch:33 step:31734 [D loss: 0.631400, acc.: 65.62%] [G loss: 0.918272]\n",
      "epoch:33 step:31735 [D loss: 0.637726, acc.: 66.41%] [G loss: 0.913205]\n",
      "epoch:33 step:31736 [D loss: 0.677324, acc.: 60.94%] [G loss: 0.916052]\n",
      "epoch:33 step:31737 [D loss: 0.644624, acc.: 63.28%] [G loss: 0.924792]\n",
      "epoch:33 step:31738 [D loss: 0.678918, acc.: 60.16%] [G loss: 0.931668]\n",
      "epoch:33 step:31739 [D loss: 0.620106, acc.: 67.97%] [G loss: 0.995255]\n",
      "epoch:33 step:31740 [D loss: 0.657806, acc.: 61.72%] [G loss: 0.941285]\n",
      "epoch:33 step:31741 [D loss: 0.651657, acc.: 64.84%] [G loss: 0.936916]\n",
      "epoch:33 step:31742 [D loss: 0.620919, acc.: 65.62%] [G loss: 0.984867]\n",
      "epoch:33 step:31743 [D loss: 0.606015, acc.: 68.75%] [G loss: 1.026785]\n",
      "epoch:33 step:31744 [D loss: 0.658353, acc.: 62.50%] [G loss: 0.894841]\n",
      "epoch:33 step:31745 [D loss: 0.694870, acc.: 53.91%] [G loss: 0.919336]\n",
      "epoch:33 step:31746 [D loss: 0.655388, acc.: 64.06%] [G loss: 0.916800]\n",
      "epoch:33 step:31747 [D loss: 0.642401, acc.: 64.84%] [G loss: 0.969799]\n",
      "epoch:33 step:31748 [D loss: 0.693013, acc.: 48.44%] [G loss: 0.943141]\n",
      "epoch:33 step:31749 [D loss: 0.664626, acc.: 58.59%] [G loss: 0.953561]\n",
      "epoch:33 step:31750 [D loss: 0.652126, acc.: 62.50%] [G loss: 0.911186]\n",
      "epoch:33 step:31751 [D loss: 0.635214, acc.: 61.72%] [G loss: 0.908151]\n",
      "epoch:33 step:31752 [D loss: 0.645894, acc.: 59.38%] [G loss: 0.848824]\n",
      "epoch:33 step:31753 [D loss: 0.598766, acc.: 64.84%] [G loss: 0.908228]\n",
      "epoch:33 step:31754 [D loss: 0.662501, acc.: 62.50%] [G loss: 0.985568]\n",
      "epoch:33 step:31755 [D loss: 0.612628, acc.: 68.75%] [G loss: 0.874663]\n",
      "epoch:33 step:31756 [D loss: 0.624335, acc.: 61.72%] [G loss: 0.949567]\n",
      "epoch:33 step:31757 [D loss: 0.636823, acc.: 65.62%] [G loss: 0.943695]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:33 step:31758 [D loss: 0.646915, acc.: 60.16%] [G loss: 0.979948]\n",
      "epoch:33 step:31759 [D loss: 0.666514, acc.: 60.16%] [G loss: 0.887059]\n",
      "epoch:33 step:31760 [D loss: 0.608068, acc.: 69.53%] [G loss: 0.977112]\n",
      "epoch:33 step:31761 [D loss: 0.617827, acc.: 62.50%] [G loss: 0.947832]\n",
      "epoch:33 step:31762 [D loss: 0.640554, acc.: 61.72%] [G loss: 0.860723]\n",
      "epoch:33 step:31763 [D loss: 0.688984, acc.: 57.03%] [G loss: 0.906432]\n",
      "epoch:33 step:31764 [D loss: 0.674267, acc.: 64.84%] [G loss: 0.909686]\n",
      "epoch:33 step:31765 [D loss: 0.643282, acc.: 63.28%] [G loss: 0.952233]\n",
      "epoch:33 step:31766 [D loss: 0.666711, acc.: 58.59%] [G loss: 0.896988]\n",
      "epoch:33 step:31767 [D loss: 0.645310, acc.: 56.25%] [G loss: 0.929539]\n",
      "epoch:33 step:31768 [D loss: 0.640492, acc.: 64.06%] [G loss: 0.925234]\n",
      "epoch:33 step:31769 [D loss: 0.656417, acc.: 61.72%] [G loss: 0.972924]\n",
      "epoch:33 step:31770 [D loss: 0.640034, acc.: 60.16%] [G loss: 1.014511]\n",
      "epoch:33 step:31771 [D loss: 0.678148, acc.: 59.38%] [G loss: 0.979301]\n",
      "epoch:33 step:31772 [D loss: 0.664430, acc.: 56.25%] [G loss: 1.048737]\n",
      "epoch:33 step:31773 [D loss: 0.594623, acc.: 70.31%] [G loss: 1.010041]\n",
      "epoch:33 step:31774 [D loss: 0.637369, acc.: 67.19%] [G loss: 1.006996]\n",
      "epoch:33 step:31775 [D loss: 0.642986, acc.: 65.62%] [G loss: 0.936604]\n",
      "epoch:33 step:31776 [D loss: 0.684540, acc.: 59.38%] [G loss: 0.899046]\n",
      "epoch:33 step:31777 [D loss: 0.624312, acc.: 61.72%] [G loss: 0.941975]\n",
      "epoch:33 step:31778 [D loss: 0.674576, acc.: 62.50%] [G loss: 0.898352]\n",
      "epoch:33 step:31779 [D loss: 0.643153, acc.: 63.28%] [G loss: 0.916181]\n",
      "epoch:33 step:31780 [D loss: 0.622166, acc.: 67.97%] [G loss: 0.976637]\n",
      "epoch:33 step:31781 [D loss: 0.641860, acc.: 60.94%] [G loss: 1.006391]\n",
      "epoch:33 step:31782 [D loss: 0.594850, acc.: 73.44%] [G loss: 0.930750]\n",
      "epoch:33 step:31783 [D loss: 0.635587, acc.: 60.94%] [G loss: 0.966251]\n",
      "epoch:33 step:31784 [D loss: 0.604016, acc.: 69.53%] [G loss: 0.942089]\n",
      "epoch:33 step:31785 [D loss: 0.677876, acc.: 57.03%] [G loss: 0.909454]\n",
      "epoch:33 step:31786 [D loss: 0.687620, acc.: 60.94%] [G loss: 0.886512]\n",
      "epoch:33 step:31787 [D loss: 0.643668, acc.: 65.62%] [G loss: 1.000988]\n",
      "epoch:33 step:31788 [D loss: 0.678805, acc.: 55.47%] [G loss: 0.936768]\n",
      "epoch:33 step:31789 [D loss: 0.636222, acc.: 63.28%] [G loss: 0.900770]\n",
      "epoch:33 step:31790 [D loss: 0.619475, acc.: 62.50%] [G loss: 0.954007]\n",
      "epoch:33 step:31791 [D loss: 0.661500, acc.: 55.47%] [G loss: 0.938852]\n",
      "epoch:33 step:31792 [D loss: 0.630673, acc.: 64.06%] [G loss: 0.903974]\n",
      "epoch:33 step:31793 [D loss: 0.678390, acc.: 54.69%] [G loss: 0.885516]\n",
      "epoch:33 step:31794 [D loss: 0.652846, acc.: 58.59%] [G loss: 0.894727]\n",
      "epoch:33 step:31795 [D loss: 0.631215, acc.: 60.16%] [G loss: 0.956669]\n",
      "epoch:33 step:31796 [D loss: 0.623490, acc.: 64.06%] [G loss: 1.002129]\n",
      "epoch:33 step:31797 [D loss: 0.671462, acc.: 57.03%] [G loss: 0.960565]\n",
      "epoch:33 step:31798 [D loss: 0.626855, acc.: 64.06%] [G loss: 1.006066]\n",
      "epoch:33 step:31799 [D loss: 0.622663, acc.: 70.31%] [G loss: 1.010800]\n",
      "epoch:33 step:31800 [D loss: 0.602183, acc.: 65.62%] [G loss: 0.995009]\n",
      "##############\n",
      "[ 3.07413917  2.61391764  2.56666777  3.76907185  1.23066274 10.27426719\n",
      "  2.49846472  3.32926384  4.12569595  5.35461213]\n",
      "##########\n",
      "epoch:33 step:31801 [D loss: 0.639804, acc.: 60.16%] [G loss: 0.962910]\n",
      "epoch:33 step:31802 [D loss: 0.656817, acc.: 61.72%] [G loss: 0.933674]\n",
      "epoch:33 step:31803 [D loss: 0.617333, acc.: 67.97%] [G loss: 0.893203]\n",
      "epoch:33 step:31804 [D loss: 0.630749, acc.: 63.28%] [G loss: 0.944928]\n",
      "epoch:33 step:31805 [D loss: 0.646254, acc.: 57.81%] [G loss: 0.999231]\n",
      "epoch:33 step:31806 [D loss: 0.612247, acc.: 67.97%] [G loss: 0.919572]\n",
      "epoch:33 step:31807 [D loss: 0.647189, acc.: 61.72%] [G loss: 0.940787]\n",
      "epoch:33 step:31808 [D loss: 0.608222, acc.: 68.75%] [G loss: 0.983467]\n",
      "epoch:33 step:31809 [D loss: 0.590543, acc.: 72.66%] [G loss: 0.942140]\n",
      "epoch:33 step:31810 [D loss: 0.652390, acc.: 60.94%] [G loss: 0.925930]\n",
      "epoch:33 step:31811 [D loss: 0.627859, acc.: 63.28%] [G loss: 0.955197]\n",
      "epoch:33 step:31812 [D loss: 0.635736, acc.: 61.72%] [G loss: 0.943325]\n",
      "epoch:33 step:31813 [D loss: 0.651500, acc.: 57.81%] [G loss: 0.963427]\n",
      "epoch:33 step:31814 [D loss: 0.640196, acc.: 63.28%] [G loss: 0.920314]\n",
      "epoch:33 step:31815 [D loss: 0.634674, acc.: 68.75%] [G loss: 0.910855]\n",
      "epoch:33 step:31816 [D loss: 0.638879, acc.: 60.16%] [G loss: 0.835397]\n",
      "epoch:33 step:31817 [D loss: 0.613672, acc.: 64.84%] [G loss: 0.897502]\n",
      "epoch:33 step:31818 [D loss: 0.622305, acc.: 60.16%] [G loss: 0.824305]\n",
      "epoch:33 step:31819 [D loss: 0.644195, acc.: 64.06%] [G loss: 0.883570]\n",
      "epoch:33 step:31820 [D loss: 0.629278, acc.: 60.94%] [G loss: 0.862536]\n",
      "epoch:33 step:31821 [D loss: 0.640930, acc.: 60.16%] [G loss: 0.905624]\n",
      "epoch:33 step:31822 [D loss: 0.674893, acc.: 52.34%] [G loss: 0.937608]\n",
      "epoch:33 step:31823 [D loss: 0.629469, acc.: 64.84%] [G loss: 0.976506]\n",
      "epoch:33 step:31824 [D loss: 0.644341, acc.: 64.84%] [G loss: 0.900960]\n",
      "epoch:33 step:31825 [D loss: 0.580377, acc.: 67.97%] [G loss: 0.973865]\n",
      "epoch:33 step:31826 [D loss: 0.661343, acc.: 60.94%] [G loss: 0.936412]\n",
      "epoch:33 step:31827 [D loss: 0.621688, acc.: 63.28%] [G loss: 0.956490]\n",
      "epoch:33 step:31828 [D loss: 0.715564, acc.: 52.34%] [G loss: 0.921996]\n",
      "epoch:33 step:31829 [D loss: 0.687079, acc.: 58.59%] [G loss: 0.912531]\n",
      "epoch:33 step:31830 [D loss: 0.658084, acc.: 56.25%] [G loss: 0.886822]\n",
      "epoch:33 step:31831 [D loss: 0.640592, acc.: 57.81%] [G loss: 0.952204]\n",
      "epoch:33 step:31832 [D loss: 0.606369, acc.: 71.88%] [G loss: 0.957902]\n",
      "epoch:33 step:31833 [D loss: 0.651056, acc.: 57.03%] [G loss: 0.960923]\n",
      "epoch:33 step:31834 [D loss: 0.642734, acc.: 62.50%] [G loss: 0.897873]\n",
      "epoch:33 step:31835 [D loss: 0.664659, acc.: 60.16%] [G loss: 0.962570]\n",
      "epoch:33 step:31836 [D loss: 0.638309, acc.: 67.97%] [G loss: 0.910363]\n",
      "epoch:33 step:31837 [D loss: 0.654209, acc.: 64.06%] [G loss: 0.955985]\n",
      "epoch:33 step:31838 [D loss: 0.614215, acc.: 62.50%] [G loss: 0.907644]\n",
      "epoch:33 step:31839 [D loss: 0.687955, acc.: 59.38%] [G loss: 0.891102]\n",
      "epoch:33 step:31840 [D loss: 0.658500, acc.: 60.16%] [G loss: 0.914163]\n",
      "epoch:33 step:31841 [D loss: 0.616786, acc.: 69.53%] [G loss: 0.881338]\n",
      "epoch:33 step:31842 [D loss: 0.677524, acc.: 58.59%] [G loss: 0.904485]\n",
      "epoch:33 step:31843 [D loss: 0.645053, acc.: 57.03%] [G loss: 0.904206]\n",
      "epoch:33 step:31844 [D loss: 0.642950, acc.: 57.03%] [G loss: 0.981869]\n",
      "epoch:33 step:31845 [D loss: 0.656452, acc.: 61.72%] [G loss: 0.942340]\n",
      "epoch:33 step:31846 [D loss: 0.635628, acc.: 64.84%] [G loss: 0.980521]\n",
      "epoch:33 step:31847 [D loss: 0.644036, acc.: 61.72%] [G loss: 0.898961]\n",
      "epoch:33 step:31848 [D loss: 0.629693, acc.: 65.62%] [G loss: 0.948746]\n",
      "epoch:33 step:31849 [D loss: 0.655407, acc.: 59.38%] [G loss: 0.940361]\n",
      "epoch:33 step:31850 [D loss: 0.648264, acc.: 57.81%] [G loss: 0.884624]\n",
      "epoch:33 step:31851 [D loss: 0.591388, acc.: 68.75%] [G loss: 0.918219]\n",
      "epoch:33 step:31852 [D loss: 0.633106, acc.: 65.62%] [G loss: 0.823670]\n",
      "epoch:33 step:31853 [D loss: 0.606565, acc.: 64.84%] [G loss: 0.880989]\n",
      "epoch:33 step:31854 [D loss: 0.672955, acc.: 59.38%] [G loss: 0.896795]\n",
      "epoch:33 step:31855 [D loss: 0.660503, acc.: 58.59%] [G loss: 0.942379]\n",
      "epoch:33 step:31856 [D loss: 0.675457, acc.: 56.25%] [G loss: 0.875030]\n",
      "epoch:33 step:31857 [D loss: 0.630691, acc.: 65.62%] [G loss: 0.987146]\n",
      "epoch:33 step:31858 [D loss: 0.664468, acc.: 62.50%] [G loss: 0.918682]\n",
      "epoch:34 step:31859 [D loss: 0.646210, acc.: 64.84%] [G loss: 1.025326]\n",
      "epoch:34 step:31860 [D loss: 0.615763, acc.: 67.19%] [G loss: 0.979355]\n",
      "epoch:34 step:31861 [D loss: 0.619244, acc.: 66.41%] [G loss: 0.944928]\n",
      "epoch:34 step:31862 [D loss: 0.615560, acc.: 67.19%] [G loss: 0.949949]\n",
      "epoch:34 step:31863 [D loss: 0.700788, acc.: 55.47%] [G loss: 0.878145]\n",
      "epoch:34 step:31864 [D loss: 0.614563, acc.: 66.41%] [G loss: 0.862147]\n",
      "epoch:34 step:31865 [D loss: 0.686040, acc.: 54.69%] [G loss: 0.928951]\n",
      "epoch:34 step:31866 [D loss: 0.678231, acc.: 57.03%] [G loss: 1.008692]\n",
      "epoch:34 step:31867 [D loss: 0.644887, acc.: 60.94%] [G loss: 0.941752]\n",
      "epoch:34 step:31868 [D loss: 0.598896, acc.: 68.75%] [G loss: 0.960446]\n",
      "epoch:34 step:31869 [D loss: 0.697213, acc.: 54.69%] [G loss: 0.975291]\n",
      "epoch:34 step:31870 [D loss: 0.616835, acc.: 64.84%] [G loss: 0.954450]\n",
      "epoch:34 step:31871 [D loss: 0.624994, acc.: 60.16%] [G loss: 0.940962]\n",
      "epoch:34 step:31872 [D loss: 0.685893, acc.: 53.12%] [G loss: 0.983512]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:31873 [D loss: 0.648927, acc.: 64.84%] [G loss: 0.933629]\n",
      "epoch:34 step:31874 [D loss: 0.660254, acc.: 56.25%] [G loss: 0.990478]\n",
      "epoch:34 step:31875 [D loss: 0.653049, acc.: 59.38%] [G loss: 0.958995]\n",
      "epoch:34 step:31876 [D loss: 0.645462, acc.: 63.28%] [G loss: 0.985475]\n",
      "epoch:34 step:31877 [D loss: 0.693942, acc.: 56.25%] [G loss: 0.933631]\n",
      "epoch:34 step:31878 [D loss: 0.671271, acc.: 58.59%] [G loss: 0.878547]\n",
      "epoch:34 step:31879 [D loss: 0.619900, acc.: 65.62%] [G loss: 0.994534]\n",
      "epoch:34 step:31880 [D loss: 0.649375, acc.: 63.28%] [G loss: 0.951071]\n",
      "epoch:34 step:31881 [D loss: 0.652874, acc.: 53.91%] [G loss: 0.941995]\n",
      "epoch:34 step:31882 [D loss: 0.644354, acc.: 65.62%] [G loss: 0.927485]\n",
      "epoch:34 step:31883 [D loss: 0.633169, acc.: 69.53%] [G loss: 0.941796]\n",
      "epoch:34 step:31884 [D loss: 0.679018, acc.: 62.50%] [G loss: 0.955959]\n",
      "epoch:34 step:31885 [D loss: 0.666713, acc.: 63.28%] [G loss: 0.951107]\n",
      "epoch:34 step:31886 [D loss: 0.649340, acc.: 60.16%] [G loss: 0.987572]\n",
      "epoch:34 step:31887 [D loss: 0.664033, acc.: 60.16%] [G loss: 0.938504]\n",
      "epoch:34 step:31888 [D loss: 0.642096, acc.: 63.28%] [G loss: 0.880985]\n",
      "epoch:34 step:31889 [D loss: 0.621703, acc.: 73.44%] [G loss: 0.919910]\n",
      "epoch:34 step:31890 [D loss: 0.622812, acc.: 67.19%] [G loss: 0.933300]\n",
      "epoch:34 step:31891 [D loss: 0.685425, acc.: 57.03%] [G loss: 0.922995]\n",
      "epoch:34 step:31892 [D loss: 0.670879, acc.: 58.59%] [G loss: 1.000351]\n",
      "epoch:34 step:31893 [D loss: 0.664586, acc.: 59.38%] [G loss: 0.953908]\n",
      "epoch:34 step:31894 [D loss: 0.647016, acc.: 61.72%] [G loss: 0.904405]\n",
      "epoch:34 step:31895 [D loss: 0.647137, acc.: 62.50%] [G loss: 0.963979]\n",
      "epoch:34 step:31896 [D loss: 0.698421, acc.: 53.12%] [G loss: 0.921084]\n",
      "epoch:34 step:31897 [D loss: 0.645515, acc.: 59.38%] [G loss: 0.946440]\n",
      "epoch:34 step:31898 [D loss: 0.659421, acc.: 53.91%] [G loss: 0.912354]\n",
      "epoch:34 step:31899 [D loss: 0.622412, acc.: 68.75%] [G loss: 0.916768]\n",
      "epoch:34 step:31900 [D loss: 0.655251, acc.: 61.72%] [G loss: 0.913239]\n",
      "epoch:34 step:31901 [D loss: 0.711461, acc.: 53.91%] [G loss: 0.867383]\n",
      "epoch:34 step:31902 [D loss: 0.628067, acc.: 64.06%] [G loss: 0.928396]\n",
      "epoch:34 step:31903 [D loss: 0.689825, acc.: 54.69%] [G loss: 0.908281]\n",
      "epoch:34 step:31904 [D loss: 0.669232, acc.: 54.69%] [G loss: 0.953027]\n",
      "epoch:34 step:31905 [D loss: 0.687062, acc.: 55.47%] [G loss: 0.966489]\n",
      "epoch:34 step:31906 [D loss: 0.622536, acc.: 68.75%] [G loss: 0.885206]\n",
      "epoch:34 step:31907 [D loss: 0.610483, acc.: 66.41%] [G loss: 0.897913]\n",
      "epoch:34 step:31908 [D loss: 0.636790, acc.: 56.25%] [G loss: 0.907034]\n",
      "epoch:34 step:31909 [D loss: 0.645844, acc.: 63.28%] [G loss: 0.944332]\n",
      "epoch:34 step:31910 [D loss: 0.619859, acc.: 69.53%] [G loss: 0.945705]\n",
      "epoch:34 step:31911 [D loss: 0.691283, acc.: 51.56%] [G loss: 0.905095]\n",
      "epoch:34 step:31912 [D loss: 0.654110, acc.: 62.50%] [G loss: 0.934188]\n",
      "epoch:34 step:31913 [D loss: 0.676880, acc.: 58.59%] [G loss: 0.901227]\n",
      "epoch:34 step:31914 [D loss: 0.637617, acc.: 63.28%] [G loss: 0.985666]\n",
      "epoch:34 step:31915 [D loss: 0.622092, acc.: 71.09%] [G loss: 0.990662]\n",
      "epoch:34 step:31916 [D loss: 0.680968, acc.: 57.03%] [G loss: 0.953050]\n",
      "epoch:34 step:31917 [D loss: 0.616446, acc.: 67.97%] [G loss: 0.990107]\n",
      "epoch:34 step:31918 [D loss: 0.638497, acc.: 60.16%] [G loss: 0.970119]\n",
      "epoch:34 step:31919 [D loss: 0.626870, acc.: 63.28%] [G loss: 0.929738]\n",
      "epoch:34 step:31920 [D loss: 0.652624, acc.: 63.28%] [G loss: 0.963473]\n",
      "epoch:34 step:31921 [D loss: 0.617474, acc.: 68.75%] [G loss: 0.862844]\n",
      "epoch:34 step:31922 [D loss: 0.615833, acc.: 64.84%] [G loss: 0.936980]\n",
      "epoch:34 step:31923 [D loss: 0.618107, acc.: 63.28%] [G loss: 0.919342]\n",
      "epoch:34 step:31924 [D loss: 0.648364, acc.: 60.16%] [G loss: 0.923910]\n",
      "epoch:34 step:31925 [D loss: 0.656448, acc.: 59.38%] [G loss: 0.980555]\n",
      "epoch:34 step:31926 [D loss: 0.650583, acc.: 63.28%] [G loss: 0.970476]\n",
      "epoch:34 step:31927 [D loss: 0.614533, acc.: 64.84%] [G loss: 1.058922]\n",
      "epoch:34 step:31928 [D loss: 0.632144, acc.: 63.28%] [G loss: 0.988123]\n",
      "epoch:34 step:31929 [D loss: 0.637742, acc.: 62.50%] [G loss: 1.005564]\n",
      "epoch:34 step:31930 [D loss: 0.657567, acc.: 57.03%] [G loss: 0.956571]\n",
      "epoch:34 step:31931 [D loss: 0.583657, acc.: 71.88%] [G loss: 0.920201]\n",
      "epoch:34 step:31932 [D loss: 0.658398, acc.: 60.94%] [G loss: 1.008623]\n",
      "epoch:34 step:31933 [D loss: 0.652991, acc.: 59.38%] [G loss: 0.914375]\n",
      "epoch:34 step:31934 [D loss: 0.662519, acc.: 60.94%] [G loss: 0.984846]\n",
      "epoch:34 step:31935 [D loss: 0.622640, acc.: 69.53%] [G loss: 0.998065]\n",
      "epoch:34 step:31936 [D loss: 0.655473, acc.: 58.59%] [G loss: 0.891348]\n",
      "epoch:34 step:31937 [D loss: 0.641428, acc.: 59.38%] [G loss: 0.963178]\n",
      "epoch:34 step:31938 [D loss: 0.645116, acc.: 59.38%] [G loss: 0.937429]\n",
      "epoch:34 step:31939 [D loss: 0.670578, acc.: 59.38%] [G loss: 1.016590]\n",
      "epoch:34 step:31940 [D loss: 0.661095, acc.: 62.50%] [G loss: 0.932514]\n",
      "epoch:34 step:31941 [D loss: 0.669615, acc.: 59.38%] [G loss: 0.871498]\n",
      "epoch:34 step:31942 [D loss: 0.630228, acc.: 63.28%] [G loss: 0.868202]\n",
      "epoch:34 step:31943 [D loss: 0.656893, acc.: 56.25%] [G loss: 0.901153]\n",
      "epoch:34 step:31944 [D loss: 0.644784, acc.: 64.06%] [G loss: 0.966914]\n",
      "epoch:34 step:31945 [D loss: 0.625433, acc.: 66.41%] [G loss: 0.936556]\n",
      "epoch:34 step:31946 [D loss: 0.668872, acc.: 60.94%] [G loss: 0.931600]\n",
      "epoch:34 step:31947 [D loss: 0.657411, acc.: 60.16%] [G loss: 0.904984]\n",
      "epoch:34 step:31948 [D loss: 0.621373, acc.: 63.28%] [G loss: 0.884715]\n",
      "epoch:34 step:31949 [D loss: 0.687660, acc.: 57.03%] [G loss: 0.895828]\n",
      "epoch:34 step:31950 [D loss: 0.657864, acc.: 64.84%] [G loss: 0.868821]\n",
      "epoch:34 step:31951 [D loss: 0.679265, acc.: 51.56%] [G loss: 0.879393]\n",
      "epoch:34 step:31952 [D loss: 0.647470, acc.: 57.03%] [G loss: 0.930783]\n",
      "epoch:34 step:31953 [D loss: 0.654343, acc.: 58.59%] [G loss: 0.945747]\n",
      "epoch:34 step:31954 [D loss: 0.635546, acc.: 70.31%] [G loss: 0.916757]\n",
      "epoch:34 step:31955 [D loss: 0.638493, acc.: 64.84%] [G loss: 0.938908]\n",
      "epoch:34 step:31956 [D loss: 0.638911, acc.: 61.72%] [G loss: 0.984166]\n",
      "epoch:34 step:31957 [D loss: 0.663906, acc.: 62.50%] [G loss: 0.955005]\n",
      "epoch:34 step:31958 [D loss: 0.664889, acc.: 57.81%] [G loss: 0.977970]\n",
      "epoch:34 step:31959 [D loss: 0.656490, acc.: 64.06%] [G loss: 0.949736]\n",
      "epoch:34 step:31960 [D loss: 0.654280, acc.: 58.59%] [G loss: 0.902527]\n",
      "epoch:34 step:31961 [D loss: 0.632631, acc.: 60.16%] [G loss: 0.925996]\n",
      "epoch:34 step:31962 [D loss: 0.699561, acc.: 58.59%] [G loss: 0.876049]\n",
      "epoch:34 step:31963 [D loss: 0.653610, acc.: 57.03%] [G loss: 0.908856]\n",
      "epoch:34 step:31964 [D loss: 0.646479, acc.: 59.38%] [G loss: 0.909618]\n",
      "epoch:34 step:31965 [D loss: 0.619831, acc.: 64.84%] [G loss: 0.939147]\n",
      "epoch:34 step:31966 [D loss: 0.601265, acc.: 71.88%] [G loss: 0.966058]\n",
      "epoch:34 step:31967 [D loss: 0.611918, acc.: 68.75%] [G loss: 0.951402]\n",
      "epoch:34 step:31968 [D loss: 0.648507, acc.: 63.28%] [G loss: 0.869355]\n",
      "epoch:34 step:31969 [D loss: 0.676986, acc.: 57.03%] [G loss: 0.876543]\n",
      "epoch:34 step:31970 [D loss: 0.669214, acc.: 64.06%] [G loss: 0.923519]\n",
      "epoch:34 step:31971 [D loss: 0.680342, acc.: 53.12%] [G loss: 0.906416]\n",
      "epoch:34 step:31972 [D loss: 0.635251, acc.: 64.84%] [G loss: 0.953039]\n",
      "epoch:34 step:31973 [D loss: 0.676997, acc.: 54.69%] [G loss: 0.938289]\n",
      "epoch:34 step:31974 [D loss: 0.639310, acc.: 61.72%] [G loss: 0.929344]\n",
      "epoch:34 step:31975 [D loss: 0.648934, acc.: 63.28%] [G loss: 0.835043]\n",
      "epoch:34 step:31976 [D loss: 0.658325, acc.: 58.59%] [G loss: 0.941151]\n",
      "epoch:34 step:31977 [D loss: 0.642740, acc.: 61.72%] [G loss: 0.873066]\n",
      "epoch:34 step:31978 [D loss: 0.653180, acc.: 64.06%] [G loss: 0.933643]\n",
      "epoch:34 step:31979 [D loss: 0.660561, acc.: 57.03%] [G loss: 0.893591]\n",
      "epoch:34 step:31980 [D loss: 0.632914, acc.: 61.72%] [G loss: 0.937967]\n",
      "epoch:34 step:31981 [D loss: 0.657437, acc.: 60.94%] [G loss: 0.921079]\n",
      "epoch:34 step:31982 [D loss: 0.674172, acc.: 61.72%] [G loss: 0.886735]\n",
      "epoch:34 step:31983 [D loss: 0.657301, acc.: 60.16%] [G loss: 0.958218]\n",
      "epoch:34 step:31984 [D loss: 0.680655, acc.: 56.25%] [G loss: 0.968420]\n",
      "epoch:34 step:31985 [D loss: 0.660694, acc.: 64.84%] [G loss: 0.916475]\n",
      "epoch:34 step:31986 [D loss: 0.686062, acc.: 57.81%] [G loss: 0.906304]\n",
      "epoch:34 step:31987 [D loss: 0.631072, acc.: 60.94%] [G loss: 0.866911]\n",
      "epoch:34 step:31988 [D loss: 0.629451, acc.: 64.84%] [G loss: 0.878052]\n",
      "epoch:34 step:31989 [D loss: 0.644824, acc.: 64.06%] [G loss: 0.906519]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:31990 [D loss: 0.700997, acc.: 50.78%] [G loss: 0.890282]\n",
      "epoch:34 step:31991 [D loss: 0.624694, acc.: 64.06%] [G loss: 0.866794]\n",
      "epoch:34 step:31992 [D loss: 0.676734, acc.: 53.91%] [G loss: 0.873176]\n",
      "epoch:34 step:31993 [D loss: 0.666918, acc.: 60.94%] [G loss: 0.903095]\n",
      "epoch:34 step:31994 [D loss: 0.631751, acc.: 64.84%] [G loss: 0.932187]\n",
      "epoch:34 step:31995 [D loss: 0.640955, acc.: 67.19%] [G loss: 0.936143]\n",
      "epoch:34 step:31996 [D loss: 0.670479, acc.: 56.25%] [G loss: 0.930092]\n",
      "epoch:34 step:31997 [D loss: 0.691871, acc.: 57.81%] [G loss: 0.927059]\n",
      "epoch:34 step:31998 [D loss: 0.663022, acc.: 59.38%] [G loss: 0.898301]\n",
      "epoch:34 step:31999 [D loss: 0.686618, acc.: 52.34%] [G loss: 0.861253]\n",
      "epoch:34 step:32000 [D loss: 0.632828, acc.: 70.31%] [G loss: 0.954267]\n",
      "##############\n",
      "[2.93584501 2.81694665 2.2037217  3.71449958 1.61852256 7.5878852\n",
      " 2.76117318 3.19940964 4.11172389 7.14730822]\n",
      "##########\n",
      "epoch:34 step:32001 [D loss: 0.631595, acc.: 62.50%] [G loss: 0.844752]\n",
      "epoch:34 step:32002 [D loss: 0.649547, acc.: 57.03%] [G loss: 0.889529]\n",
      "epoch:34 step:32003 [D loss: 0.667448, acc.: 56.25%] [G loss: 0.939750]\n",
      "epoch:34 step:32004 [D loss: 0.620360, acc.: 71.88%] [G loss: 0.943404]\n",
      "epoch:34 step:32005 [D loss: 0.627075, acc.: 67.19%] [G loss: 0.919348]\n",
      "epoch:34 step:32006 [D loss: 0.644395, acc.: 64.84%] [G loss: 0.883769]\n",
      "epoch:34 step:32007 [D loss: 0.611280, acc.: 64.84%] [G loss: 0.990096]\n",
      "epoch:34 step:32008 [D loss: 0.691704, acc.: 57.81%] [G loss: 0.901943]\n",
      "epoch:34 step:32009 [D loss: 0.639568, acc.: 62.50%] [G loss: 0.986699]\n",
      "epoch:34 step:32010 [D loss: 0.637899, acc.: 60.16%] [G loss: 0.963183]\n",
      "epoch:34 step:32011 [D loss: 0.643799, acc.: 57.81%] [G loss: 0.960596]\n",
      "epoch:34 step:32012 [D loss: 0.681917, acc.: 54.69%] [G loss: 0.923066]\n",
      "epoch:34 step:32013 [D loss: 0.662069, acc.: 57.03%] [G loss: 0.873109]\n",
      "epoch:34 step:32014 [D loss: 0.608601, acc.: 64.06%] [G loss: 0.851343]\n",
      "epoch:34 step:32015 [D loss: 0.612802, acc.: 69.53%] [G loss: 0.893502]\n",
      "epoch:34 step:32016 [D loss: 0.624070, acc.: 62.50%] [G loss: 0.855778]\n",
      "epoch:34 step:32017 [D loss: 0.635177, acc.: 62.50%] [G loss: 0.948518]\n",
      "epoch:34 step:32018 [D loss: 0.648736, acc.: 57.81%] [G loss: 0.917882]\n",
      "epoch:34 step:32019 [D loss: 0.632830, acc.: 64.84%] [G loss: 0.909164]\n",
      "epoch:34 step:32020 [D loss: 0.618140, acc.: 68.75%] [G loss: 0.908888]\n",
      "epoch:34 step:32021 [D loss: 0.633273, acc.: 65.62%] [G loss: 0.850911]\n",
      "epoch:34 step:32022 [D loss: 0.731584, acc.: 51.56%] [G loss: 0.865937]\n",
      "epoch:34 step:32023 [D loss: 0.629484, acc.: 67.97%] [G loss: 0.889308]\n",
      "epoch:34 step:32024 [D loss: 0.662838, acc.: 60.94%] [G loss: 0.936477]\n",
      "epoch:34 step:32025 [D loss: 0.605915, acc.: 69.53%] [G loss: 0.945664]\n",
      "epoch:34 step:32026 [D loss: 0.634005, acc.: 69.53%] [G loss: 0.898823]\n",
      "epoch:34 step:32027 [D loss: 0.646527, acc.: 58.59%] [G loss: 0.884518]\n",
      "epoch:34 step:32028 [D loss: 0.645553, acc.: 60.94%] [G loss: 0.858043]\n",
      "epoch:34 step:32029 [D loss: 0.709553, acc.: 50.78%] [G loss: 0.944721]\n",
      "epoch:34 step:32030 [D loss: 0.635368, acc.: 64.06%] [G loss: 0.913582]\n",
      "epoch:34 step:32031 [D loss: 0.669817, acc.: 60.16%] [G loss: 0.916711]\n",
      "epoch:34 step:32032 [D loss: 0.634952, acc.: 61.72%] [G loss: 0.887803]\n",
      "epoch:34 step:32033 [D loss: 0.662134, acc.: 57.81%] [G loss: 0.995204]\n",
      "epoch:34 step:32034 [D loss: 0.607927, acc.: 74.22%] [G loss: 0.932434]\n",
      "epoch:34 step:32035 [D loss: 0.625688, acc.: 64.06%] [G loss: 1.030062]\n",
      "epoch:34 step:32036 [D loss: 0.624847, acc.: 65.62%] [G loss: 0.936676]\n",
      "epoch:34 step:32037 [D loss: 0.664401, acc.: 59.38%] [G loss: 0.984841]\n",
      "epoch:34 step:32038 [D loss: 0.638312, acc.: 64.84%] [G loss: 0.973938]\n",
      "epoch:34 step:32039 [D loss: 0.673912, acc.: 57.03%] [G loss: 0.936935]\n",
      "epoch:34 step:32040 [D loss: 0.634128, acc.: 67.19%] [G loss: 0.887937]\n",
      "epoch:34 step:32041 [D loss: 0.661083, acc.: 59.38%] [G loss: 0.890936]\n",
      "epoch:34 step:32042 [D loss: 0.672846, acc.: 61.72%] [G loss: 0.975749]\n",
      "epoch:34 step:32043 [D loss: 0.646462, acc.: 61.72%] [G loss: 0.925904]\n",
      "epoch:34 step:32044 [D loss: 0.612738, acc.: 67.19%] [G loss: 1.027497]\n",
      "epoch:34 step:32045 [D loss: 0.629322, acc.: 64.06%] [G loss: 0.989873]\n",
      "epoch:34 step:32046 [D loss: 0.674972, acc.: 57.03%] [G loss: 1.009468]\n",
      "epoch:34 step:32047 [D loss: 0.665441, acc.: 52.34%] [G loss: 0.943610]\n",
      "epoch:34 step:32048 [D loss: 0.658684, acc.: 60.94%] [G loss: 1.000857]\n",
      "epoch:34 step:32049 [D loss: 0.623504, acc.: 64.84%] [G loss: 0.962320]\n",
      "epoch:34 step:32050 [D loss: 0.634391, acc.: 63.28%] [G loss: 0.958665]\n",
      "epoch:34 step:32051 [D loss: 0.627447, acc.: 67.19%] [G loss: 0.970965]\n",
      "epoch:34 step:32052 [D loss: 0.669545, acc.: 60.94%] [G loss: 0.922309]\n",
      "epoch:34 step:32053 [D loss: 0.625193, acc.: 66.41%] [G loss: 0.960399]\n",
      "epoch:34 step:32054 [D loss: 0.673753, acc.: 58.59%] [G loss: 0.917489]\n",
      "epoch:34 step:32055 [D loss: 0.633128, acc.: 65.62%] [G loss: 0.943595]\n",
      "epoch:34 step:32056 [D loss: 0.622275, acc.: 65.62%] [G loss: 0.965639]\n",
      "epoch:34 step:32057 [D loss: 0.610021, acc.: 75.78%] [G loss: 0.900917]\n",
      "epoch:34 step:32058 [D loss: 0.640266, acc.: 63.28%] [G loss: 0.940211]\n",
      "epoch:34 step:32059 [D loss: 0.665509, acc.: 53.12%] [G loss: 0.972730]\n",
      "epoch:34 step:32060 [D loss: 0.614630, acc.: 66.41%] [G loss: 0.985157]\n",
      "epoch:34 step:32061 [D loss: 0.638184, acc.: 63.28%] [G loss: 0.958575]\n",
      "epoch:34 step:32062 [D loss: 0.663071, acc.: 57.81%] [G loss: 0.960116]\n",
      "epoch:34 step:32063 [D loss: 0.675119, acc.: 57.03%] [G loss: 0.952313]\n",
      "epoch:34 step:32064 [D loss: 0.630900, acc.: 63.28%] [G loss: 1.002448]\n",
      "epoch:34 step:32065 [D loss: 0.653937, acc.: 64.06%] [G loss: 0.961370]\n",
      "epoch:34 step:32066 [D loss: 0.643696, acc.: 58.59%] [G loss: 0.942136]\n",
      "epoch:34 step:32067 [D loss: 0.676807, acc.: 55.47%] [G loss: 0.905362]\n",
      "epoch:34 step:32068 [D loss: 0.661412, acc.: 60.94%] [G loss: 0.917981]\n",
      "epoch:34 step:32069 [D loss: 0.642272, acc.: 64.84%] [G loss: 0.939955]\n",
      "epoch:34 step:32070 [D loss: 0.609343, acc.: 67.19%] [G loss: 0.888762]\n",
      "epoch:34 step:32071 [D loss: 0.659850, acc.: 57.81%] [G loss: 0.911896]\n",
      "epoch:34 step:32072 [D loss: 0.661632, acc.: 61.72%] [G loss: 0.906153]\n",
      "epoch:34 step:32073 [D loss: 0.669761, acc.: 58.59%] [G loss: 0.948911]\n",
      "epoch:34 step:32074 [D loss: 0.692470, acc.: 54.69%] [G loss: 0.923454]\n",
      "epoch:34 step:32075 [D loss: 0.632771, acc.: 66.41%] [G loss: 0.949600]\n",
      "epoch:34 step:32076 [D loss: 0.644919, acc.: 60.94%] [G loss: 0.909733]\n",
      "epoch:34 step:32077 [D loss: 0.688868, acc.: 54.69%] [G loss: 0.938329]\n",
      "epoch:34 step:32078 [D loss: 0.669576, acc.: 57.81%] [G loss: 0.954058]\n",
      "epoch:34 step:32079 [D loss: 0.639423, acc.: 67.97%] [G loss: 0.979295]\n",
      "epoch:34 step:32080 [D loss: 0.681483, acc.: 60.16%] [G loss: 0.925200]\n",
      "epoch:34 step:32081 [D loss: 0.654399, acc.: 60.16%] [G loss: 0.946286]\n",
      "epoch:34 step:32082 [D loss: 0.638744, acc.: 64.84%] [G loss: 0.880497]\n",
      "epoch:34 step:32083 [D loss: 0.611166, acc.: 67.19%] [G loss: 0.885636]\n",
      "epoch:34 step:32084 [D loss: 0.681286, acc.: 57.03%] [G loss: 0.847284]\n",
      "epoch:34 step:32085 [D loss: 0.637966, acc.: 62.50%] [G loss: 0.835567]\n",
      "epoch:34 step:32086 [D loss: 0.628118, acc.: 67.97%] [G loss: 0.904203]\n",
      "epoch:34 step:32087 [D loss: 0.642019, acc.: 57.03%] [G loss: 0.903244]\n",
      "epoch:34 step:32088 [D loss: 0.661683, acc.: 60.94%] [G loss: 0.863753]\n",
      "epoch:34 step:32089 [D loss: 0.723534, acc.: 49.22%] [G loss: 0.969094]\n",
      "epoch:34 step:32090 [D loss: 0.619858, acc.: 67.19%] [G loss: 1.023326]\n",
      "epoch:34 step:32091 [D loss: 0.626244, acc.: 62.50%] [G loss: 0.975909]\n",
      "epoch:34 step:32092 [D loss: 0.670733, acc.: 55.47%] [G loss: 0.924282]\n",
      "epoch:34 step:32093 [D loss: 0.635690, acc.: 62.50%] [G loss: 0.905316]\n",
      "epoch:34 step:32094 [D loss: 0.627417, acc.: 61.72%] [G loss: 0.862198]\n",
      "epoch:34 step:32095 [D loss: 0.655133, acc.: 57.81%] [G loss: 0.962841]\n",
      "epoch:34 step:32096 [D loss: 0.670207, acc.: 63.28%] [G loss: 0.881476]\n",
      "epoch:34 step:32097 [D loss: 0.655194, acc.: 56.25%] [G loss: 0.871373]\n",
      "epoch:34 step:32098 [D loss: 0.658166, acc.: 59.38%] [G loss: 0.934969]\n",
      "epoch:34 step:32099 [D loss: 0.628767, acc.: 63.28%] [G loss: 0.952106]\n",
      "epoch:34 step:32100 [D loss: 0.630417, acc.: 70.31%] [G loss: 0.982832]\n",
      "epoch:34 step:32101 [D loss: 0.663232, acc.: 59.38%] [G loss: 0.924013]\n",
      "epoch:34 step:32102 [D loss: 0.685248, acc.: 54.69%] [G loss: 0.910204]\n",
      "epoch:34 step:32103 [D loss: 0.705809, acc.: 52.34%] [G loss: 0.877949]\n",
      "epoch:34 step:32104 [D loss: 0.635415, acc.: 63.28%] [G loss: 0.922566]\n",
      "epoch:34 step:32105 [D loss: 0.639992, acc.: 58.59%] [G loss: 0.953674]\n",
      "epoch:34 step:32106 [D loss: 0.619603, acc.: 64.06%] [G loss: 0.980226]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:32107 [D loss: 0.712881, acc.: 53.12%] [G loss: 0.898664]\n",
      "epoch:34 step:32108 [D loss: 0.696049, acc.: 57.81%] [G loss: 0.877822]\n",
      "epoch:34 step:32109 [D loss: 0.626213, acc.: 63.28%] [G loss: 0.952938]\n",
      "epoch:34 step:32110 [D loss: 0.621574, acc.: 67.97%] [G loss: 0.881855]\n",
      "epoch:34 step:32111 [D loss: 0.661635, acc.: 57.81%] [G loss: 0.993650]\n",
      "epoch:34 step:32112 [D loss: 0.685233, acc.: 57.03%] [G loss: 0.939881]\n",
      "epoch:34 step:32113 [D loss: 0.645769, acc.: 64.84%] [G loss: 0.955717]\n",
      "epoch:34 step:32114 [D loss: 0.659802, acc.: 61.72%] [G loss: 0.904405]\n",
      "epoch:34 step:32115 [D loss: 0.655852, acc.: 65.62%] [G loss: 0.947412]\n",
      "epoch:34 step:32116 [D loss: 0.677733, acc.: 58.59%] [G loss: 0.906492]\n",
      "epoch:34 step:32117 [D loss: 0.680486, acc.: 57.03%] [G loss: 0.865099]\n",
      "epoch:34 step:32118 [D loss: 0.642732, acc.: 61.72%] [G loss: 0.894254]\n",
      "epoch:34 step:32119 [D loss: 0.687994, acc.: 54.69%] [G loss: 0.883589]\n",
      "epoch:34 step:32120 [D loss: 0.662075, acc.: 61.72%] [G loss: 0.924012]\n",
      "epoch:34 step:32121 [D loss: 0.631576, acc.: 60.94%] [G loss: 0.959423]\n",
      "epoch:34 step:32122 [D loss: 0.665820, acc.: 54.69%] [G loss: 1.001021]\n",
      "epoch:34 step:32123 [D loss: 0.626607, acc.: 64.84%] [G loss: 0.993204]\n",
      "epoch:34 step:32124 [D loss: 0.661435, acc.: 57.81%] [G loss: 0.954321]\n",
      "epoch:34 step:32125 [D loss: 0.631589, acc.: 65.62%] [G loss: 0.979890]\n",
      "epoch:34 step:32126 [D loss: 0.671538, acc.: 57.03%] [G loss: 0.951265]\n",
      "epoch:34 step:32127 [D loss: 0.618573, acc.: 65.62%] [G loss: 0.927062]\n",
      "epoch:34 step:32128 [D loss: 0.641690, acc.: 61.72%] [G loss: 0.951348]\n",
      "epoch:34 step:32129 [D loss: 0.623108, acc.: 70.31%] [G loss: 0.878452]\n",
      "epoch:34 step:32130 [D loss: 0.661010, acc.: 57.03%] [G loss: 0.944037]\n",
      "epoch:34 step:32131 [D loss: 0.687302, acc.: 53.91%] [G loss: 0.996709]\n",
      "epoch:34 step:32132 [D loss: 0.651573, acc.: 60.94%] [G loss: 0.999363]\n",
      "epoch:34 step:32133 [D loss: 0.690975, acc.: 55.47%] [G loss: 0.996406]\n",
      "epoch:34 step:32134 [D loss: 0.704044, acc.: 50.78%] [G loss: 0.999403]\n",
      "epoch:34 step:32135 [D loss: 0.635566, acc.: 60.16%] [G loss: 0.966561]\n",
      "epoch:34 step:32136 [D loss: 0.643371, acc.: 61.72%] [G loss: 0.975199]\n",
      "epoch:34 step:32137 [D loss: 0.654483, acc.: 64.84%] [G loss: 0.938731]\n",
      "epoch:34 step:32138 [D loss: 0.676710, acc.: 55.47%] [G loss: 0.871166]\n",
      "epoch:34 step:32139 [D loss: 0.611732, acc.: 65.62%] [G loss: 0.854824]\n",
      "epoch:34 step:32140 [D loss: 0.648204, acc.: 62.50%] [G loss: 0.917576]\n",
      "epoch:34 step:32141 [D loss: 0.633404, acc.: 60.94%] [G loss: 0.943804]\n",
      "epoch:34 step:32142 [D loss: 0.598333, acc.: 70.31%] [G loss: 0.885056]\n",
      "epoch:34 step:32143 [D loss: 0.599282, acc.: 64.06%] [G loss: 0.886097]\n",
      "epoch:34 step:32144 [D loss: 0.625207, acc.: 64.84%] [G loss: 0.868309]\n",
      "epoch:34 step:32145 [D loss: 0.652681, acc.: 60.16%] [G loss: 0.857702]\n",
      "epoch:34 step:32146 [D loss: 0.608456, acc.: 65.62%] [G loss: 0.933455]\n",
      "epoch:34 step:32147 [D loss: 0.654848, acc.: 65.62%] [G loss: 0.932612]\n",
      "epoch:34 step:32148 [D loss: 0.645563, acc.: 64.06%] [G loss: 0.923674]\n",
      "epoch:34 step:32149 [D loss: 0.651126, acc.: 58.59%] [G loss: 0.981236]\n",
      "epoch:34 step:32150 [D loss: 0.620272, acc.: 68.75%] [G loss: 0.919693]\n",
      "epoch:34 step:32151 [D loss: 0.627546, acc.: 65.62%] [G loss: 0.935070]\n",
      "epoch:34 step:32152 [D loss: 0.665787, acc.: 57.81%] [G loss: 0.942234]\n",
      "epoch:34 step:32153 [D loss: 0.651479, acc.: 60.16%] [G loss: 0.959447]\n",
      "epoch:34 step:32154 [D loss: 0.655440, acc.: 63.28%] [G loss: 0.917010]\n",
      "epoch:34 step:32155 [D loss: 0.622775, acc.: 66.41%] [G loss: 0.950753]\n",
      "epoch:34 step:32156 [D loss: 0.625464, acc.: 63.28%] [G loss: 0.885175]\n",
      "epoch:34 step:32157 [D loss: 0.674549, acc.: 67.19%] [G loss: 0.946402]\n",
      "epoch:34 step:32158 [D loss: 0.603838, acc.: 65.62%] [G loss: 0.879554]\n",
      "epoch:34 step:32159 [D loss: 0.686398, acc.: 56.25%] [G loss: 0.917416]\n",
      "epoch:34 step:32160 [D loss: 0.627837, acc.: 66.41%] [G loss: 0.897571]\n",
      "epoch:34 step:32161 [D loss: 0.657940, acc.: 60.16%] [G loss: 0.964150]\n",
      "epoch:34 step:32162 [D loss: 0.596370, acc.: 68.75%] [G loss: 0.907735]\n",
      "epoch:34 step:32163 [D loss: 0.675865, acc.: 58.59%] [G loss: 0.844983]\n",
      "epoch:34 step:32164 [D loss: 0.692278, acc.: 53.91%] [G loss: 0.951921]\n",
      "epoch:34 step:32165 [D loss: 0.658241, acc.: 56.25%] [G loss: 0.986028]\n",
      "epoch:34 step:32166 [D loss: 0.661587, acc.: 59.38%] [G loss: 0.894943]\n",
      "epoch:34 step:32167 [D loss: 0.654364, acc.: 60.16%] [G loss: 0.937271]\n",
      "epoch:34 step:32168 [D loss: 0.646776, acc.: 62.50%] [G loss: 0.957596]\n",
      "epoch:34 step:32169 [D loss: 0.630479, acc.: 64.06%] [G loss: 0.981864]\n",
      "epoch:34 step:32170 [D loss: 0.612528, acc.: 68.75%] [G loss: 0.946250]\n",
      "epoch:34 step:32171 [D loss: 0.679711, acc.: 57.03%] [G loss: 0.919830]\n",
      "epoch:34 step:32172 [D loss: 0.593843, acc.: 68.75%] [G loss: 0.930560]\n",
      "epoch:34 step:32173 [D loss: 0.615334, acc.: 66.41%] [G loss: 0.868991]\n",
      "epoch:34 step:32174 [D loss: 0.659880, acc.: 63.28%] [G loss: 0.973360]\n",
      "epoch:34 step:32175 [D loss: 0.634856, acc.: 64.06%] [G loss: 0.874696]\n",
      "epoch:34 step:32176 [D loss: 0.652922, acc.: 61.72%] [G loss: 0.870007]\n",
      "epoch:34 step:32177 [D loss: 0.662453, acc.: 57.81%] [G loss: 0.917556]\n",
      "epoch:34 step:32178 [D loss: 0.623416, acc.: 64.84%] [G loss: 0.964143]\n",
      "epoch:34 step:32179 [D loss: 0.635306, acc.: 61.72%] [G loss: 0.934407]\n",
      "epoch:34 step:32180 [D loss: 0.644064, acc.: 60.16%] [G loss: 0.952871]\n",
      "epoch:34 step:32181 [D loss: 0.614291, acc.: 71.88%] [G loss: 0.923317]\n",
      "epoch:34 step:32182 [D loss: 0.604587, acc.: 67.19%] [G loss: 0.901828]\n",
      "epoch:34 step:32183 [D loss: 0.660514, acc.: 62.50%] [G loss: 0.910853]\n",
      "epoch:34 step:32184 [D loss: 0.645775, acc.: 59.38%] [G loss: 0.886969]\n",
      "epoch:34 step:32185 [D loss: 0.646397, acc.: 60.94%] [G loss: 0.883703]\n",
      "epoch:34 step:32186 [D loss: 0.617320, acc.: 60.94%] [G loss: 0.928385]\n",
      "epoch:34 step:32187 [D loss: 0.607427, acc.: 67.97%] [G loss: 0.939261]\n",
      "epoch:34 step:32188 [D loss: 0.616979, acc.: 64.84%] [G loss: 1.006648]\n",
      "epoch:34 step:32189 [D loss: 0.620594, acc.: 66.41%] [G loss: 1.053346]\n",
      "epoch:34 step:32190 [D loss: 0.646706, acc.: 60.94%] [G loss: 0.937850]\n",
      "epoch:34 step:32191 [D loss: 0.663371, acc.: 56.25%] [G loss: 0.905964]\n",
      "epoch:34 step:32192 [D loss: 0.599401, acc.: 65.62%] [G loss: 0.859480]\n",
      "epoch:34 step:32193 [D loss: 0.652954, acc.: 60.94%] [G loss: 0.892126]\n",
      "epoch:34 step:32194 [D loss: 0.615568, acc.: 66.41%] [G loss: 0.876437]\n",
      "epoch:34 step:32195 [D loss: 0.592403, acc.: 68.75%] [G loss: 0.899096]\n",
      "epoch:34 step:32196 [D loss: 0.635751, acc.: 61.72%] [G loss: 0.946135]\n",
      "epoch:34 step:32197 [D loss: 0.606848, acc.: 72.66%] [G loss: 0.986763]\n",
      "epoch:34 step:32198 [D loss: 0.618370, acc.: 65.62%] [G loss: 0.913525]\n",
      "epoch:34 step:32199 [D loss: 0.645516, acc.: 60.94%] [G loss: 0.943888]\n",
      "epoch:34 step:32200 [D loss: 0.646230, acc.: 64.84%] [G loss: 1.014166]\n",
      "##############\n",
      "[3.03254122 2.36983892 2.56112371 3.84403021 1.33505835 9.27426719\n",
      " 2.77229468 3.2165872  4.38601206 7.14730822]\n",
      "##########\n",
      "epoch:34 step:32201 [D loss: 0.681350, acc.: 62.50%] [G loss: 0.889636]\n",
      "epoch:34 step:32202 [D loss: 0.627737, acc.: 66.41%] [G loss: 0.897304]\n",
      "epoch:34 step:32203 [D loss: 0.634796, acc.: 64.84%] [G loss: 0.890616]\n",
      "epoch:34 step:32204 [D loss: 0.691776, acc.: 53.12%] [G loss: 0.907767]\n",
      "epoch:34 step:32205 [D loss: 0.626571, acc.: 62.50%] [G loss: 0.943248]\n",
      "epoch:34 step:32206 [D loss: 0.648176, acc.: 63.28%] [G loss: 0.915597]\n",
      "epoch:34 step:32207 [D loss: 0.655010, acc.: 59.38%] [G loss: 0.930180]\n",
      "epoch:34 step:32208 [D loss: 0.628509, acc.: 62.50%] [G loss: 0.944700]\n",
      "epoch:34 step:32209 [D loss: 0.676049, acc.: 55.47%] [G loss: 0.879680]\n",
      "epoch:34 step:32210 [D loss: 0.711623, acc.: 52.34%] [G loss: 0.920047]\n",
      "epoch:34 step:32211 [D loss: 0.616121, acc.: 64.06%] [G loss: 0.937247]\n",
      "epoch:34 step:32212 [D loss: 0.697224, acc.: 54.69%] [G loss: 0.873039]\n",
      "epoch:34 step:32213 [D loss: 0.660967, acc.: 60.94%] [G loss: 0.924138]\n",
      "epoch:34 step:32214 [D loss: 0.674627, acc.: 57.81%] [G loss: 0.904819]\n",
      "epoch:34 step:32215 [D loss: 0.661717, acc.: 60.16%] [G loss: 0.971332]\n",
      "epoch:34 step:32216 [D loss: 0.645716, acc.: 62.50%] [G loss: 0.944432]\n",
      "epoch:34 step:32217 [D loss: 0.632590, acc.: 64.06%] [G loss: 0.932635]\n",
      "epoch:34 step:32218 [D loss: 0.623278, acc.: 64.06%] [G loss: 0.861468]\n",
      "epoch:34 step:32219 [D loss: 0.640897, acc.: 63.28%] [G loss: 0.973934]\n",
      "epoch:34 step:32220 [D loss: 0.603570, acc.: 70.31%] [G loss: 0.943777]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:32221 [D loss: 0.655785, acc.: 64.84%] [G loss: 0.928757]\n",
      "epoch:34 step:32222 [D loss: 0.653868, acc.: 59.38%] [G loss: 0.943876]\n",
      "epoch:34 step:32223 [D loss: 0.636503, acc.: 66.41%] [G loss: 0.905884]\n",
      "epoch:34 step:32224 [D loss: 0.658342, acc.: 61.72%] [G loss: 0.927880]\n",
      "epoch:34 step:32225 [D loss: 0.630899, acc.: 60.94%] [G loss: 0.942885]\n",
      "epoch:34 step:32226 [D loss: 0.659532, acc.: 64.84%] [G loss: 0.898855]\n",
      "epoch:34 step:32227 [D loss: 0.681041, acc.: 60.16%] [G loss: 0.869774]\n",
      "epoch:34 step:32228 [D loss: 0.659641, acc.: 62.50%] [G loss: 0.929015]\n",
      "epoch:34 step:32229 [D loss: 0.628477, acc.: 64.06%] [G loss: 0.937036]\n",
      "epoch:34 step:32230 [D loss: 0.635208, acc.: 63.28%] [G loss: 0.957903]\n",
      "epoch:34 step:32231 [D loss: 0.610470, acc.: 67.97%] [G loss: 0.942182]\n",
      "epoch:34 step:32232 [D loss: 0.653497, acc.: 61.72%] [G loss: 0.905306]\n",
      "epoch:34 step:32233 [D loss: 0.662858, acc.: 57.81%] [G loss: 0.949555]\n",
      "epoch:34 step:32234 [D loss: 0.657913, acc.: 55.47%] [G loss: 0.881654]\n",
      "epoch:34 step:32235 [D loss: 0.643175, acc.: 60.94%] [G loss: 0.943159]\n",
      "epoch:34 step:32236 [D loss: 0.611120, acc.: 66.41%] [G loss: 0.941667]\n",
      "epoch:34 step:32237 [D loss: 0.694717, acc.: 55.47%] [G loss: 0.981126]\n",
      "epoch:34 step:32238 [D loss: 0.616259, acc.: 67.19%] [G loss: 0.992248]\n",
      "epoch:34 step:32239 [D loss: 0.670523, acc.: 57.81%] [G loss: 0.998842]\n",
      "epoch:34 step:32240 [D loss: 0.597498, acc.: 67.97%] [G loss: 0.999006]\n",
      "epoch:34 step:32241 [D loss: 0.660625, acc.: 60.94%] [G loss: 0.890007]\n",
      "epoch:34 step:32242 [D loss: 0.657729, acc.: 55.47%] [G loss: 0.895946]\n",
      "epoch:34 step:32243 [D loss: 0.689135, acc.: 57.03%] [G loss: 0.839407]\n",
      "epoch:34 step:32244 [D loss: 0.617033, acc.: 64.06%] [G loss: 0.879314]\n",
      "epoch:34 step:32245 [D loss: 0.633838, acc.: 68.75%] [G loss: 0.924562]\n",
      "epoch:34 step:32246 [D loss: 0.700572, acc.: 56.25%] [G loss: 0.984554]\n",
      "epoch:34 step:32247 [D loss: 0.654555, acc.: 60.94%] [G loss: 0.935736]\n",
      "epoch:34 step:32248 [D loss: 0.614098, acc.: 64.06%] [G loss: 0.912096]\n",
      "epoch:34 step:32249 [D loss: 0.617250, acc.: 69.53%] [G loss: 0.892541]\n",
      "epoch:34 step:32250 [D loss: 0.598913, acc.: 70.31%] [G loss: 0.970926]\n",
      "epoch:34 step:32251 [D loss: 0.701090, acc.: 51.56%] [G loss: 0.847051]\n",
      "epoch:34 step:32252 [D loss: 0.638981, acc.: 57.81%] [G loss: 0.917329]\n",
      "epoch:34 step:32253 [D loss: 0.634710, acc.: 60.94%] [G loss: 0.865835]\n",
      "epoch:34 step:32254 [D loss: 0.617531, acc.: 65.62%] [G loss: 0.887486]\n",
      "epoch:34 step:32255 [D loss: 0.699182, acc.: 57.03%] [G loss: 0.913858]\n",
      "epoch:34 step:32256 [D loss: 0.645254, acc.: 65.62%] [G loss: 0.819669]\n",
      "epoch:34 step:32257 [D loss: 0.610560, acc.: 66.41%] [G loss: 0.871290]\n",
      "epoch:34 step:32258 [D loss: 0.630312, acc.: 65.62%] [G loss: 0.924278]\n",
      "epoch:34 step:32259 [D loss: 0.605560, acc.: 64.84%] [G loss: 0.919521]\n",
      "epoch:34 step:32260 [D loss: 0.598700, acc.: 70.31%] [G loss: 0.956622]\n",
      "epoch:34 step:32261 [D loss: 0.601116, acc.: 71.09%] [G loss: 0.968465]\n",
      "epoch:34 step:32262 [D loss: 0.609518, acc.: 64.84%] [G loss: 0.932013]\n",
      "epoch:34 step:32263 [D loss: 0.613287, acc.: 65.62%] [G loss: 0.984963]\n",
      "epoch:34 step:32264 [D loss: 0.677474, acc.: 61.72%] [G loss: 0.958794]\n",
      "epoch:34 step:32265 [D loss: 0.629493, acc.: 62.50%] [G loss: 1.034918]\n",
      "epoch:34 step:32266 [D loss: 0.676406, acc.: 59.38%] [G loss: 0.919452]\n",
      "epoch:34 step:32267 [D loss: 0.654650, acc.: 60.94%] [G loss: 0.889261]\n",
      "epoch:34 step:32268 [D loss: 0.701840, acc.: 50.00%] [G loss: 0.940060]\n",
      "epoch:34 step:32269 [D loss: 0.619469, acc.: 63.28%] [G loss: 0.951406]\n",
      "epoch:34 step:32270 [D loss: 0.640182, acc.: 63.28%] [G loss: 0.964846]\n",
      "epoch:34 step:32271 [D loss: 0.642779, acc.: 64.06%] [G loss: 0.903818]\n",
      "epoch:34 step:32272 [D loss: 0.643682, acc.: 61.72%] [G loss: 0.914791]\n",
      "epoch:34 step:32273 [D loss: 0.615295, acc.: 64.84%] [G loss: 0.912248]\n",
      "epoch:34 step:32274 [D loss: 0.615348, acc.: 65.62%] [G loss: 0.969751]\n",
      "epoch:34 step:32275 [D loss: 0.606958, acc.: 67.19%] [G loss: 0.941478]\n",
      "epoch:34 step:32276 [D loss: 0.640381, acc.: 60.94%] [G loss: 0.955878]\n",
      "epoch:34 step:32277 [D loss: 0.641266, acc.: 63.28%] [G loss: 0.952519]\n",
      "epoch:34 step:32278 [D loss: 0.636193, acc.: 60.16%] [G loss: 1.002599]\n",
      "epoch:34 step:32279 [D loss: 0.631572, acc.: 61.72%] [G loss: 0.987576]\n",
      "epoch:34 step:32280 [D loss: 0.644224, acc.: 61.72%] [G loss: 0.930216]\n",
      "epoch:34 step:32281 [D loss: 0.673484, acc.: 62.50%] [G loss: 1.011369]\n",
      "epoch:34 step:32282 [D loss: 0.630672, acc.: 64.84%] [G loss: 1.011485]\n",
      "epoch:34 step:32283 [D loss: 0.625539, acc.: 64.06%] [G loss: 0.996154]\n",
      "epoch:34 step:32284 [D loss: 0.657310, acc.: 60.94%] [G loss: 0.979375]\n",
      "epoch:34 step:32285 [D loss: 0.649865, acc.: 63.28%] [G loss: 0.960574]\n",
      "epoch:34 step:32286 [D loss: 0.659797, acc.: 63.28%] [G loss: 0.844900]\n",
      "epoch:34 step:32287 [D loss: 0.610979, acc.: 65.62%] [G loss: 0.923746]\n",
      "epoch:34 step:32288 [D loss: 0.674529, acc.: 57.03%] [G loss: 0.975625]\n",
      "epoch:34 step:32289 [D loss: 0.652350, acc.: 55.47%] [G loss: 1.008478]\n",
      "epoch:34 step:32290 [D loss: 0.687014, acc.: 53.91%] [G loss: 0.982319]\n",
      "epoch:34 step:32291 [D loss: 0.677921, acc.: 53.91%] [G loss: 0.969964]\n",
      "epoch:34 step:32292 [D loss: 0.657843, acc.: 57.81%] [G loss: 0.960751]\n",
      "epoch:34 step:32293 [D loss: 0.655246, acc.: 60.94%] [G loss: 0.974400]\n",
      "epoch:34 step:32294 [D loss: 0.625552, acc.: 71.88%] [G loss: 0.877149]\n",
      "epoch:34 step:32295 [D loss: 0.652048, acc.: 58.59%] [G loss: 0.887714]\n",
      "epoch:34 step:32296 [D loss: 0.641313, acc.: 61.72%] [G loss: 0.901528]\n",
      "epoch:34 step:32297 [D loss: 0.725577, acc.: 48.44%] [G loss: 0.905139]\n",
      "epoch:34 step:32298 [D loss: 0.648335, acc.: 60.16%] [G loss: 0.942889]\n",
      "epoch:34 step:32299 [D loss: 0.652165, acc.: 62.50%] [G loss: 0.874287]\n",
      "epoch:34 step:32300 [D loss: 0.653346, acc.: 61.72%] [G loss: 0.939909]\n",
      "epoch:34 step:32301 [D loss: 0.628535, acc.: 64.84%] [G loss: 0.957388]\n",
      "epoch:34 step:32302 [D loss: 0.645735, acc.: 59.38%] [G loss: 0.935228]\n",
      "epoch:34 step:32303 [D loss: 0.681823, acc.: 55.47%] [G loss: 0.942941]\n",
      "epoch:34 step:32304 [D loss: 0.684793, acc.: 54.69%] [G loss: 0.966847]\n",
      "epoch:34 step:32305 [D loss: 0.629194, acc.: 69.53%] [G loss: 0.937411]\n",
      "epoch:34 step:32306 [D loss: 0.625412, acc.: 61.72%] [G loss: 0.918067]\n",
      "epoch:34 step:32307 [D loss: 0.663595, acc.: 58.59%] [G loss: 0.961863]\n",
      "epoch:34 step:32308 [D loss: 0.631027, acc.: 65.62%] [G loss: 0.938536]\n",
      "epoch:34 step:32309 [D loss: 0.591949, acc.: 68.75%] [G loss: 0.957632]\n",
      "epoch:34 step:32310 [D loss: 0.664384, acc.: 60.94%] [G loss: 0.874694]\n",
      "epoch:34 step:32311 [D loss: 0.633475, acc.: 64.06%] [G loss: 0.959711]\n",
      "epoch:34 step:32312 [D loss: 0.627921, acc.: 66.41%] [G loss: 0.903358]\n",
      "epoch:34 step:32313 [D loss: 0.652118, acc.: 57.03%] [G loss: 0.948399]\n",
      "epoch:34 step:32314 [D loss: 0.646253, acc.: 66.41%] [G loss: 0.863332]\n",
      "epoch:34 step:32315 [D loss: 0.637252, acc.: 60.94%] [G loss: 0.919128]\n",
      "epoch:34 step:32316 [D loss: 0.626140, acc.: 60.94%] [G loss: 0.934931]\n",
      "epoch:34 step:32317 [D loss: 0.603006, acc.: 69.53%] [G loss: 0.903669]\n",
      "epoch:34 step:32318 [D loss: 0.608952, acc.: 57.81%] [G loss: 0.894707]\n",
      "epoch:34 step:32319 [D loss: 0.656895, acc.: 59.38%] [G loss: 0.873821]\n",
      "epoch:34 step:32320 [D loss: 0.696232, acc.: 51.56%] [G loss: 0.950873]\n",
      "epoch:34 step:32321 [D loss: 0.651668, acc.: 61.72%] [G loss: 0.947880]\n",
      "epoch:34 step:32322 [D loss: 0.690573, acc.: 50.00%] [G loss: 0.932257]\n",
      "epoch:34 step:32323 [D loss: 0.665104, acc.: 53.12%] [G loss: 0.948318]\n",
      "epoch:34 step:32324 [D loss: 0.620481, acc.: 64.06%] [G loss: 0.897228]\n",
      "epoch:34 step:32325 [D loss: 0.621576, acc.: 66.41%] [G loss: 0.959748]\n",
      "epoch:34 step:32326 [D loss: 0.637993, acc.: 63.28%] [G loss: 0.962502]\n",
      "epoch:34 step:32327 [D loss: 0.610236, acc.: 67.97%] [G loss: 0.934480]\n",
      "epoch:34 step:32328 [D loss: 0.703482, acc.: 53.12%] [G loss: 0.924310]\n",
      "epoch:34 step:32329 [D loss: 0.619687, acc.: 62.50%] [G loss: 0.942187]\n",
      "epoch:34 step:32330 [D loss: 0.601209, acc.: 68.75%] [G loss: 0.940236]\n",
      "epoch:34 step:32331 [D loss: 0.638404, acc.: 63.28%] [G loss: 0.947125]\n",
      "epoch:34 step:32332 [D loss: 0.623375, acc.: 65.62%] [G loss: 0.919571]\n",
      "epoch:34 step:32333 [D loss: 0.615985, acc.: 65.62%] [G loss: 0.949258]\n",
      "epoch:34 step:32334 [D loss: 0.592051, acc.: 70.31%] [G loss: 0.922308]\n",
      "epoch:34 step:32335 [D loss: 0.633632, acc.: 64.84%] [G loss: 0.944911]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:32336 [D loss: 0.600383, acc.: 65.62%] [G loss: 0.894795]\n",
      "epoch:34 step:32337 [D loss: 0.646197, acc.: 57.03%] [G loss: 0.934039]\n",
      "epoch:34 step:32338 [D loss: 0.663055, acc.: 60.16%] [G loss: 0.929850]\n",
      "epoch:34 step:32339 [D loss: 0.657645, acc.: 57.03%] [G loss: 0.907368]\n",
      "epoch:34 step:32340 [D loss: 0.654791, acc.: 58.59%] [G loss: 0.954946]\n",
      "epoch:34 step:32341 [D loss: 0.651482, acc.: 60.94%] [G loss: 0.879710]\n",
      "epoch:34 step:32342 [D loss: 0.621963, acc.: 67.19%] [G loss: 0.946894]\n",
      "epoch:34 step:32343 [D loss: 0.665890, acc.: 60.94%] [G loss: 0.985642]\n",
      "epoch:34 step:32344 [D loss: 0.630081, acc.: 67.19%] [G loss: 0.898201]\n",
      "epoch:34 step:32345 [D loss: 0.633837, acc.: 66.41%] [G loss: 0.886537]\n",
      "epoch:34 step:32346 [D loss: 0.613670, acc.: 67.19%] [G loss: 0.872049]\n",
      "epoch:34 step:32347 [D loss: 0.626660, acc.: 67.19%] [G loss: 0.911869]\n",
      "epoch:34 step:32348 [D loss: 0.619113, acc.: 64.84%] [G loss: 0.860699]\n",
      "epoch:34 step:32349 [D loss: 0.687889, acc.: 55.47%] [G loss: 0.882237]\n",
      "epoch:34 step:32350 [D loss: 0.666129, acc.: 59.38%] [G loss: 0.942271]\n",
      "epoch:34 step:32351 [D loss: 0.686566, acc.: 57.81%] [G loss: 0.913622]\n",
      "epoch:34 step:32352 [D loss: 0.616366, acc.: 64.84%] [G loss: 0.986080]\n",
      "epoch:34 step:32353 [D loss: 0.667288, acc.: 60.16%] [G loss: 0.916646]\n",
      "epoch:34 step:32354 [D loss: 0.637140, acc.: 59.38%] [G loss: 0.924937]\n",
      "epoch:34 step:32355 [D loss: 0.678450, acc.: 54.69%] [G loss: 0.949432]\n",
      "epoch:34 step:32356 [D loss: 0.645772, acc.: 61.72%] [G loss: 0.946908]\n",
      "epoch:34 step:32357 [D loss: 0.665909, acc.: 64.06%] [G loss: 0.922267]\n",
      "epoch:34 step:32358 [D loss: 0.685929, acc.: 57.03%] [G loss: 0.920338]\n",
      "epoch:34 step:32359 [D loss: 0.627424, acc.: 64.06%] [G loss: 0.877898]\n",
      "epoch:34 step:32360 [D loss: 0.613879, acc.: 66.41%] [G loss: 0.877040]\n",
      "epoch:34 step:32361 [D loss: 0.652167, acc.: 62.50%] [G loss: 0.909630]\n",
      "epoch:34 step:32362 [D loss: 0.673178, acc.: 55.47%] [G loss: 0.973590]\n",
      "epoch:34 step:32363 [D loss: 0.679768, acc.: 53.91%] [G loss: 0.976861]\n",
      "epoch:34 step:32364 [D loss: 0.664160, acc.: 57.81%] [G loss: 0.984098]\n",
      "epoch:34 step:32365 [D loss: 0.669057, acc.: 59.38%] [G loss: 0.925146]\n",
      "epoch:34 step:32366 [D loss: 0.656290, acc.: 57.81%] [G loss: 0.952329]\n",
      "epoch:34 step:32367 [D loss: 0.642731, acc.: 63.28%] [G loss: 0.962713]\n",
      "epoch:34 step:32368 [D loss: 0.632416, acc.: 60.16%] [G loss: 0.885895]\n",
      "epoch:34 step:32369 [D loss: 0.595625, acc.: 71.88%] [G loss: 0.961902]\n",
      "epoch:34 step:32370 [D loss: 0.670429, acc.: 53.91%] [G loss: 0.962796]\n",
      "epoch:34 step:32371 [D loss: 0.653742, acc.: 58.59%] [G loss: 0.899560]\n",
      "epoch:34 step:32372 [D loss: 0.649408, acc.: 59.38%] [G loss: 0.959938]\n",
      "epoch:34 step:32373 [D loss: 0.622438, acc.: 67.19%] [G loss: 0.955617]\n",
      "epoch:34 step:32374 [D loss: 0.634218, acc.: 61.72%] [G loss: 0.906635]\n",
      "epoch:34 step:32375 [D loss: 0.611647, acc.: 67.19%] [G loss: 0.960942]\n",
      "epoch:34 step:32376 [D loss: 0.695863, acc.: 58.59%] [G loss: 0.993104]\n",
      "epoch:34 step:32377 [D loss: 0.606199, acc.: 64.06%] [G loss: 0.924628]\n",
      "epoch:34 step:32378 [D loss: 0.619985, acc.: 64.84%] [G loss: 0.965482]\n",
      "epoch:34 step:32379 [D loss: 0.624533, acc.: 64.84%] [G loss: 0.899349]\n",
      "epoch:34 step:32380 [D loss: 0.618301, acc.: 62.50%] [G loss: 0.906961]\n",
      "epoch:34 step:32381 [D loss: 0.638089, acc.: 61.72%] [G loss: 0.974438]\n",
      "epoch:34 step:32382 [D loss: 0.606464, acc.: 66.41%] [G loss: 0.997102]\n",
      "epoch:34 step:32383 [D loss: 0.674010, acc.: 58.59%] [G loss: 0.993102]\n",
      "epoch:34 step:32384 [D loss: 0.703883, acc.: 53.12%] [G loss: 0.915295]\n",
      "epoch:34 step:32385 [D loss: 0.612599, acc.: 63.28%] [G loss: 0.964782]\n",
      "epoch:34 step:32386 [D loss: 0.653904, acc.: 60.16%] [G loss: 0.943770]\n",
      "epoch:34 step:32387 [D loss: 0.627833, acc.: 63.28%] [G loss: 0.949171]\n",
      "epoch:34 step:32388 [D loss: 0.631529, acc.: 59.38%] [G loss: 0.917977]\n",
      "epoch:34 step:32389 [D loss: 0.646809, acc.: 61.72%] [G loss: 0.937714]\n",
      "epoch:34 step:32390 [D loss: 0.649695, acc.: 62.50%] [G loss: 0.947554]\n",
      "epoch:34 step:32391 [D loss: 0.652047, acc.: 67.19%] [G loss: 0.974313]\n",
      "epoch:34 step:32392 [D loss: 0.641639, acc.: 65.62%] [G loss: 0.953347]\n",
      "epoch:34 step:32393 [D loss: 0.601096, acc.: 69.53%] [G loss: 0.866624]\n",
      "epoch:34 step:32394 [D loss: 0.661412, acc.: 58.59%] [G loss: 0.935431]\n",
      "epoch:34 step:32395 [D loss: 0.643760, acc.: 64.84%] [G loss: 0.891036]\n",
      "epoch:34 step:32396 [D loss: 0.671517, acc.: 59.38%] [G loss: 0.879178]\n",
      "epoch:34 step:32397 [D loss: 0.647760, acc.: 60.16%] [G loss: 0.879277]\n",
      "epoch:34 step:32398 [D loss: 0.634044, acc.: 64.06%] [G loss: 0.921304]\n",
      "epoch:34 step:32399 [D loss: 0.644214, acc.: 61.72%] [G loss: 0.946804]\n",
      "epoch:34 step:32400 [D loss: 0.667035, acc.: 61.72%] [G loss: 0.922697]\n",
      "##############\n",
      "[2.90288481 2.39370119 2.2734556  4.24626753 1.22701514 7.73452599\n",
      " 2.72482861 3.42088885 4.26727797 7.14834402]\n",
      "##########\n",
      "epoch:34 step:32401 [D loss: 0.651291, acc.: 61.72%] [G loss: 0.955785]\n",
      "epoch:34 step:32402 [D loss: 0.664389, acc.: 59.38%] [G loss: 0.949353]\n",
      "epoch:34 step:32403 [D loss: 0.627810, acc.: 60.16%] [G loss: 0.962420]\n",
      "epoch:34 step:32404 [D loss: 0.640266, acc.: 60.16%] [G loss: 0.942426]\n",
      "epoch:34 step:32405 [D loss: 0.646486, acc.: 60.94%] [G loss: 0.918430]\n",
      "epoch:34 step:32406 [D loss: 0.673799, acc.: 53.91%] [G loss: 0.863839]\n",
      "epoch:34 step:32407 [D loss: 0.673590, acc.: 56.25%] [G loss: 0.923948]\n",
      "epoch:34 step:32408 [D loss: 0.599422, acc.: 70.31%] [G loss: 0.955396]\n",
      "epoch:34 step:32409 [D loss: 0.617192, acc.: 66.41%] [G loss: 0.913866]\n",
      "epoch:34 step:32410 [D loss: 0.634214, acc.: 58.59%] [G loss: 0.907170]\n",
      "epoch:34 step:32411 [D loss: 0.665751, acc.: 58.59%] [G loss: 0.883741]\n",
      "epoch:34 step:32412 [D loss: 0.626607, acc.: 64.06%] [G loss: 0.882540]\n",
      "epoch:34 step:32413 [D loss: 0.612979, acc.: 66.41%] [G loss: 0.892839]\n",
      "epoch:34 step:32414 [D loss: 0.634694, acc.: 64.84%] [G loss: 0.951976]\n",
      "epoch:34 step:32415 [D loss: 0.670623, acc.: 62.50%] [G loss: 0.922692]\n",
      "epoch:34 step:32416 [D loss: 0.656057, acc.: 59.38%] [G loss: 0.956372]\n",
      "epoch:34 step:32417 [D loss: 0.675673, acc.: 57.81%] [G loss: 0.983370]\n",
      "epoch:34 step:32418 [D loss: 0.673118, acc.: 58.59%] [G loss: 0.946752]\n",
      "epoch:34 step:32419 [D loss: 0.614771, acc.: 70.31%] [G loss: 0.961559]\n",
      "epoch:34 step:32420 [D loss: 0.655648, acc.: 63.28%] [G loss: 0.941294]\n",
      "epoch:34 step:32421 [D loss: 0.641430, acc.: 60.94%] [G loss: 0.931568]\n",
      "epoch:34 step:32422 [D loss: 0.670215, acc.: 60.16%] [G loss: 0.940212]\n",
      "epoch:34 step:32423 [D loss: 0.631187, acc.: 62.50%] [G loss: 0.922635]\n",
      "epoch:34 step:32424 [D loss: 0.638832, acc.: 59.38%] [G loss: 0.940202]\n",
      "epoch:34 step:32425 [D loss: 0.645057, acc.: 66.41%] [G loss: 0.964181]\n",
      "epoch:34 step:32426 [D loss: 0.718365, acc.: 50.78%] [G loss: 0.935110]\n",
      "epoch:34 step:32427 [D loss: 0.614301, acc.: 66.41%] [G loss: 0.972340]\n",
      "epoch:34 step:32428 [D loss: 0.634548, acc.: 61.72%] [G loss: 1.005922]\n",
      "epoch:34 step:32429 [D loss: 0.646112, acc.: 60.16%] [G loss: 0.942245]\n",
      "epoch:34 step:32430 [D loss: 0.654864, acc.: 62.50%] [G loss: 0.913667]\n",
      "epoch:34 step:32431 [D loss: 0.651352, acc.: 63.28%] [G loss: 0.979254]\n",
      "epoch:34 step:32432 [D loss: 0.621892, acc.: 60.94%] [G loss: 0.930157]\n",
      "epoch:34 step:32433 [D loss: 0.655299, acc.: 57.81%] [G loss: 0.893305]\n",
      "epoch:34 step:32434 [D loss: 0.625858, acc.: 71.09%] [G loss: 0.996938]\n",
      "epoch:34 step:32435 [D loss: 0.662684, acc.: 58.59%] [G loss: 0.946517]\n",
      "epoch:34 step:32436 [D loss: 0.634615, acc.: 62.50%] [G loss: 0.907710]\n",
      "epoch:34 step:32437 [D loss: 0.685170, acc.: 57.03%] [G loss: 0.959395]\n",
      "epoch:34 step:32438 [D loss: 0.623626, acc.: 64.06%] [G loss: 0.903545]\n",
      "epoch:34 step:32439 [D loss: 0.663639, acc.: 54.69%] [G loss: 0.955390]\n",
      "epoch:34 step:32440 [D loss: 0.641434, acc.: 60.94%] [G loss: 0.912656]\n",
      "epoch:34 step:32441 [D loss: 0.666497, acc.: 53.12%] [G loss: 0.927431]\n",
      "epoch:34 step:32442 [D loss: 0.622896, acc.: 71.09%] [G loss: 0.931281]\n",
      "epoch:34 step:32443 [D loss: 0.644474, acc.: 64.84%] [G loss: 0.897195]\n",
      "epoch:34 step:32444 [D loss: 0.672860, acc.: 60.16%] [G loss: 0.930389]\n",
      "epoch:34 step:32445 [D loss: 0.644294, acc.: 64.84%] [G loss: 1.005028]\n",
      "epoch:34 step:32446 [D loss: 0.679478, acc.: 57.81%] [G loss: 0.955520]\n",
      "epoch:34 step:32447 [D loss: 0.642571, acc.: 62.50%] [G loss: 0.900074]\n",
      "epoch:34 step:32448 [D loss: 0.620384, acc.: 63.28%] [G loss: 0.845947]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:32449 [D loss: 0.626126, acc.: 63.28%] [G loss: 0.884091]\n",
      "epoch:34 step:32450 [D loss: 0.621879, acc.: 65.62%] [G loss: 0.862916]\n",
      "epoch:34 step:32451 [D loss: 0.665117, acc.: 57.03%] [G loss: 0.869660]\n",
      "epoch:34 step:32452 [D loss: 0.622417, acc.: 64.06%] [G loss: 0.900798]\n",
      "epoch:34 step:32453 [D loss: 0.616047, acc.: 65.62%] [G loss: 0.994096]\n",
      "epoch:34 step:32454 [D loss: 0.625248, acc.: 64.06%] [G loss: 0.925200]\n",
      "epoch:34 step:32455 [D loss: 0.642764, acc.: 64.06%] [G loss: 0.929092]\n",
      "epoch:34 step:32456 [D loss: 0.644256, acc.: 60.94%] [G loss: 0.905338]\n",
      "epoch:34 step:32457 [D loss: 0.617517, acc.: 68.75%] [G loss: 0.999737]\n",
      "epoch:34 step:32458 [D loss: 0.639521, acc.: 57.81%] [G loss: 0.983461]\n",
      "epoch:34 step:32459 [D loss: 0.653780, acc.: 63.28%] [G loss: 0.884025]\n",
      "epoch:34 step:32460 [D loss: 0.605600, acc.: 75.00%] [G loss: 0.943264]\n",
      "epoch:34 step:32461 [D loss: 0.674033, acc.: 57.81%] [G loss: 0.907827]\n",
      "epoch:34 step:32462 [D loss: 0.633440, acc.: 64.06%] [G loss: 0.900565]\n",
      "epoch:34 step:32463 [D loss: 0.643323, acc.: 64.06%] [G loss: 0.911868]\n",
      "epoch:34 step:32464 [D loss: 0.650204, acc.: 64.84%] [G loss: 0.933161]\n",
      "epoch:34 step:32465 [D loss: 0.668587, acc.: 59.38%] [G loss: 0.905325]\n",
      "epoch:34 step:32466 [D loss: 0.639075, acc.: 64.06%] [G loss: 0.896414]\n",
      "epoch:34 step:32467 [D loss: 0.626111, acc.: 67.97%] [G loss: 0.872770]\n",
      "epoch:34 step:32468 [D loss: 0.654524, acc.: 62.50%] [G loss: 0.883899]\n",
      "epoch:34 step:32469 [D loss: 0.661274, acc.: 60.16%] [G loss: 0.925594]\n",
      "epoch:34 step:32470 [D loss: 0.656336, acc.: 61.72%] [G loss: 0.941788]\n",
      "epoch:34 step:32471 [D loss: 0.629449, acc.: 67.97%] [G loss: 0.851910]\n",
      "epoch:34 step:32472 [D loss: 0.650400, acc.: 60.94%] [G loss: 0.889795]\n",
      "epoch:34 step:32473 [D loss: 0.649785, acc.: 65.62%] [G loss: 0.932123]\n",
      "epoch:34 step:32474 [D loss: 0.612813, acc.: 62.50%] [G loss: 0.892332]\n",
      "epoch:34 step:32475 [D loss: 0.676192, acc.: 60.16%] [G loss: 0.977587]\n",
      "epoch:34 step:32476 [D loss: 0.614060, acc.: 67.19%] [G loss: 0.954971]\n",
      "epoch:34 step:32477 [D loss: 0.656076, acc.: 57.03%] [G loss: 0.886441]\n",
      "epoch:34 step:32478 [D loss: 0.655092, acc.: 61.72%] [G loss: 0.945028]\n",
      "epoch:34 step:32479 [D loss: 0.637943, acc.: 60.94%] [G loss: 0.946295]\n",
      "epoch:34 step:32480 [D loss: 0.665071, acc.: 62.50%] [G loss: 0.963828]\n",
      "epoch:34 step:32481 [D loss: 0.613989, acc.: 69.53%] [G loss: 0.960350]\n",
      "epoch:34 step:32482 [D loss: 0.644335, acc.: 63.28%] [G loss: 0.999446]\n",
      "epoch:34 step:32483 [D loss: 0.641572, acc.: 66.41%] [G loss: 0.943246]\n",
      "epoch:34 step:32484 [D loss: 0.627712, acc.: 61.72%] [G loss: 0.913941]\n",
      "epoch:34 step:32485 [D loss: 0.630521, acc.: 67.19%] [G loss: 1.015872]\n",
      "epoch:34 step:32486 [D loss: 0.644109, acc.: 62.50%] [G loss: 0.904628]\n",
      "epoch:34 step:32487 [D loss: 0.633969, acc.: 68.75%] [G loss: 0.915738]\n",
      "epoch:34 step:32488 [D loss: 0.649201, acc.: 61.72%] [G loss: 0.899296]\n",
      "epoch:34 step:32489 [D loss: 0.633861, acc.: 61.72%] [G loss: 0.884629]\n",
      "epoch:34 step:32490 [D loss: 0.602276, acc.: 69.53%] [G loss: 0.975098]\n",
      "epoch:34 step:32491 [D loss: 0.611290, acc.: 64.06%] [G loss: 0.948292]\n",
      "epoch:34 step:32492 [D loss: 0.610238, acc.: 66.41%] [G loss: 0.947083]\n",
      "epoch:34 step:32493 [D loss: 0.640174, acc.: 60.94%] [G loss: 0.977556]\n",
      "epoch:34 step:32494 [D loss: 0.622594, acc.: 69.53%] [G loss: 0.980240]\n",
      "epoch:34 step:32495 [D loss: 0.634506, acc.: 66.41%] [G loss: 1.041434]\n",
      "epoch:34 step:32496 [D loss: 0.677711, acc.: 54.69%] [G loss: 0.976999]\n",
      "epoch:34 step:32497 [D loss: 0.641937, acc.: 60.94%] [G loss: 0.949665]\n",
      "epoch:34 step:32498 [D loss: 0.655362, acc.: 59.38%] [G loss: 0.962440]\n",
      "epoch:34 step:32499 [D loss: 0.677865, acc.: 50.78%] [G loss: 0.947795]\n",
      "epoch:34 step:32500 [D loss: 0.629975, acc.: 68.75%] [G loss: 0.959759]\n",
      "epoch:34 step:32501 [D loss: 0.686216, acc.: 58.59%] [G loss: 0.870449]\n",
      "epoch:34 step:32502 [D loss: 0.633632, acc.: 61.72%] [G loss: 0.915950]\n",
      "epoch:34 step:32503 [D loss: 0.635931, acc.: 62.50%] [G loss: 0.855995]\n",
      "epoch:34 step:32504 [D loss: 0.643603, acc.: 60.16%] [G loss: 0.905089]\n",
      "epoch:34 step:32505 [D loss: 0.613929, acc.: 67.19%] [G loss: 0.950800]\n",
      "epoch:34 step:32506 [D loss: 0.656466, acc.: 57.81%] [G loss: 0.912706]\n",
      "epoch:34 step:32507 [D loss: 0.662093, acc.: 54.69%] [G loss: 1.000149]\n",
      "epoch:34 step:32508 [D loss: 0.648955, acc.: 60.16%] [G loss: 0.931739]\n",
      "epoch:34 step:32509 [D loss: 0.625139, acc.: 64.06%] [G loss: 0.964643]\n",
      "epoch:34 step:32510 [D loss: 0.645618, acc.: 61.72%] [G loss: 0.949264]\n",
      "epoch:34 step:32511 [D loss: 0.627510, acc.: 60.16%] [G loss: 0.900776]\n",
      "epoch:34 step:32512 [D loss: 0.635094, acc.: 61.72%] [G loss: 0.970707]\n",
      "epoch:34 step:32513 [D loss: 0.679913, acc.: 58.59%] [G loss: 0.950106]\n",
      "epoch:34 step:32514 [D loss: 0.629338, acc.: 67.19%] [G loss: 0.923555]\n",
      "epoch:34 step:32515 [D loss: 0.644272, acc.: 65.62%] [G loss: 0.933994]\n",
      "epoch:34 step:32516 [D loss: 0.634011, acc.: 64.84%] [G loss: 0.881696]\n",
      "epoch:34 step:32517 [D loss: 0.667995, acc.: 59.38%] [G loss: 0.943455]\n",
      "epoch:34 step:32518 [D loss: 0.661004, acc.: 63.28%] [G loss: 0.863047]\n",
      "epoch:34 step:32519 [D loss: 0.652840, acc.: 66.41%] [G loss: 0.883591]\n",
      "epoch:34 step:32520 [D loss: 0.671535, acc.: 56.25%] [G loss: 0.914054]\n",
      "epoch:34 step:32521 [D loss: 0.666656, acc.: 56.25%] [G loss: 0.937247]\n",
      "epoch:34 step:32522 [D loss: 0.587911, acc.: 71.09%] [G loss: 0.971104]\n",
      "epoch:34 step:32523 [D loss: 0.649850, acc.: 60.16%] [G loss: 0.911543]\n",
      "epoch:34 step:32524 [D loss: 0.648207, acc.: 63.28%] [G loss: 0.973578]\n",
      "epoch:34 step:32525 [D loss: 0.651183, acc.: 57.03%] [G loss: 0.943931]\n",
      "epoch:34 step:32526 [D loss: 0.628536, acc.: 68.75%] [G loss: 0.911270]\n",
      "epoch:34 step:32527 [D loss: 0.577485, acc.: 69.53%] [G loss: 0.938669]\n",
      "epoch:34 step:32528 [D loss: 0.657470, acc.: 59.38%] [G loss: 0.876090]\n",
      "epoch:34 step:32529 [D loss: 0.669770, acc.: 54.69%] [G loss: 0.972037]\n",
      "epoch:34 step:32530 [D loss: 0.676740, acc.: 58.59%] [G loss: 0.940151]\n",
      "epoch:34 step:32531 [D loss: 0.657304, acc.: 59.38%] [G loss: 0.934897]\n",
      "epoch:34 step:32532 [D loss: 0.640334, acc.: 66.41%] [G loss: 0.989700]\n",
      "epoch:34 step:32533 [D loss: 0.654663, acc.: 67.19%] [G loss: 0.898679]\n",
      "epoch:34 step:32534 [D loss: 0.638641, acc.: 61.72%] [G loss: 0.934180]\n",
      "epoch:34 step:32535 [D loss: 0.646491, acc.: 58.59%] [G loss: 0.991298]\n",
      "epoch:34 step:32536 [D loss: 0.630662, acc.: 61.72%] [G loss: 0.982697]\n",
      "epoch:34 step:32537 [D loss: 0.619372, acc.: 65.62%] [G loss: 0.978305]\n",
      "epoch:34 step:32538 [D loss: 0.656097, acc.: 56.25%] [G loss: 0.930662]\n",
      "epoch:34 step:32539 [D loss: 0.654264, acc.: 66.41%] [G loss: 0.960034]\n",
      "epoch:34 step:32540 [D loss: 0.608783, acc.: 66.41%] [G loss: 0.936361]\n",
      "epoch:34 step:32541 [D loss: 0.669221, acc.: 56.25%] [G loss: 0.917018]\n",
      "epoch:34 step:32542 [D loss: 0.636768, acc.: 67.97%] [G loss: 0.881052]\n",
      "epoch:34 step:32543 [D loss: 0.664999, acc.: 60.94%] [G loss: 0.966145]\n",
      "epoch:34 step:32544 [D loss: 0.655676, acc.: 60.94%] [G loss: 0.965528]\n",
      "epoch:34 step:32545 [D loss: 0.667524, acc.: 56.25%] [G loss: 0.939563]\n",
      "epoch:34 step:32546 [D loss: 0.634345, acc.: 61.72%] [G loss: 0.920929]\n",
      "epoch:34 step:32547 [D loss: 0.632542, acc.: 62.50%] [G loss: 0.928061]\n",
      "epoch:34 step:32548 [D loss: 0.670966, acc.: 58.59%] [G loss: 0.909059]\n",
      "epoch:34 step:32549 [D loss: 0.680543, acc.: 55.47%] [G loss: 0.876320]\n",
      "epoch:34 step:32550 [D loss: 0.623592, acc.: 68.75%] [G loss: 0.906389]\n",
      "epoch:34 step:32551 [D loss: 0.613604, acc.: 64.06%] [G loss: 0.956353]\n",
      "epoch:34 step:32552 [D loss: 0.683584, acc.: 60.16%] [G loss: 0.914438]\n",
      "epoch:34 step:32553 [D loss: 0.626069, acc.: 64.06%] [G loss: 0.954319]\n",
      "epoch:34 step:32554 [D loss: 0.641468, acc.: 59.38%] [G loss: 0.962199]\n",
      "epoch:34 step:32555 [D loss: 0.643145, acc.: 67.19%] [G loss: 0.943351]\n",
      "epoch:34 step:32556 [D loss: 0.635232, acc.: 62.50%] [G loss: 0.925892]\n",
      "epoch:34 step:32557 [D loss: 0.640993, acc.: 63.28%] [G loss: 0.936884]\n",
      "epoch:34 step:32558 [D loss: 0.643969, acc.: 64.06%] [G loss: 0.941767]\n",
      "epoch:34 step:32559 [D loss: 0.641225, acc.: 61.72%] [G loss: 0.893111]\n",
      "epoch:34 step:32560 [D loss: 0.622797, acc.: 64.84%] [G loss: 0.892554]\n",
      "epoch:34 step:32561 [D loss: 0.685459, acc.: 53.91%] [G loss: 0.919069]\n",
      "epoch:34 step:32562 [D loss: 0.624452, acc.: 63.28%] [G loss: 0.901349]\n",
      "epoch:34 step:32563 [D loss: 0.664044, acc.: 60.16%] [G loss: 0.893294]\n",
      "epoch:34 step:32564 [D loss: 0.661326, acc.: 58.59%] [G loss: 0.952962]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:32565 [D loss: 0.637135, acc.: 64.06%] [G loss: 0.896070]\n",
      "epoch:34 step:32566 [D loss: 0.664344, acc.: 57.03%] [G loss: 0.926500]\n",
      "epoch:34 step:32567 [D loss: 0.681219, acc.: 53.91%] [G loss: 0.920596]\n",
      "epoch:34 step:32568 [D loss: 0.633843, acc.: 60.94%] [G loss: 0.961112]\n",
      "epoch:34 step:32569 [D loss: 0.623855, acc.: 67.97%] [G loss: 0.964180]\n",
      "epoch:34 step:32570 [D loss: 0.659989, acc.: 64.06%] [G loss: 1.050589]\n",
      "epoch:34 step:32571 [D loss: 0.668865, acc.: 58.59%] [G loss: 0.920531]\n",
      "epoch:34 step:32572 [D loss: 0.626794, acc.: 64.84%] [G loss: 0.962628]\n",
      "epoch:34 step:32573 [D loss: 0.631488, acc.: 66.41%] [G loss: 0.973105]\n",
      "epoch:34 step:32574 [D loss: 0.621657, acc.: 64.84%] [G loss: 0.989851]\n",
      "epoch:34 step:32575 [D loss: 0.583454, acc.: 71.88%] [G loss: 0.922199]\n",
      "epoch:34 step:32576 [D loss: 0.607018, acc.: 69.53%] [G loss: 0.911361]\n",
      "epoch:34 step:32577 [D loss: 0.673566, acc.: 59.38%] [G loss: 0.878461]\n",
      "epoch:34 step:32578 [D loss: 0.650975, acc.: 59.38%] [G loss: 0.924479]\n",
      "epoch:34 step:32579 [D loss: 0.620905, acc.: 68.75%] [G loss: 0.957092]\n",
      "epoch:34 step:32580 [D loss: 0.601254, acc.: 69.53%] [G loss: 0.905951]\n",
      "epoch:34 step:32581 [D loss: 0.636705, acc.: 62.50%] [G loss: 0.972057]\n",
      "epoch:34 step:32582 [D loss: 0.640666, acc.: 60.94%] [G loss: 0.985210]\n",
      "epoch:34 step:32583 [D loss: 0.639306, acc.: 62.50%] [G loss: 0.920858]\n",
      "epoch:34 step:32584 [D loss: 0.651607, acc.: 63.28%] [G loss: 0.874362]\n",
      "epoch:34 step:32585 [D loss: 0.603622, acc.: 69.53%] [G loss: 0.947274]\n",
      "epoch:34 step:32586 [D loss: 0.677805, acc.: 58.59%] [G loss: 0.947173]\n",
      "epoch:34 step:32587 [D loss: 0.613470, acc.: 67.19%] [G loss: 0.939570]\n",
      "epoch:34 step:32588 [D loss: 0.642986, acc.: 62.50%] [G loss: 0.964824]\n",
      "epoch:34 step:32589 [D loss: 0.574628, acc.: 72.66%] [G loss: 1.007531]\n",
      "epoch:34 step:32590 [D loss: 0.643285, acc.: 61.72%] [G loss: 0.892984]\n",
      "epoch:34 step:32591 [D loss: 0.660907, acc.: 57.81%] [G loss: 0.900597]\n",
      "epoch:34 step:32592 [D loss: 0.625954, acc.: 68.75%] [G loss: 0.946710]\n",
      "epoch:34 step:32593 [D loss: 0.646690, acc.: 62.50%] [G loss: 0.931072]\n",
      "epoch:34 step:32594 [D loss: 0.617337, acc.: 66.41%] [G loss: 0.894396]\n",
      "epoch:34 step:32595 [D loss: 0.682666, acc.: 56.25%] [G loss: 0.910070]\n",
      "epoch:34 step:32596 [D loss: 0.692014, acc.: 51.56%] [G loss: 0.925193]\n",
      "epoch:34 step:32597 [D loss: 0.669771, acc.: 61.72%] [G loss: 0.911849]\n",
      "epoch:34 step:32598 [D loss: 0.650376, acc.: 62.50%] [G loss: 0.869490]\n",
      "epoch:34 step:32599 [D loss: 0.670042, acc.: 60.94%] [G loss: 0.895763]\n",
      "epoch:34 step:32600 [D loss: 0.691044, acc.: 55.47%] [G loss: 0.941524]\n",
      "##############\n",
      "[3.03882046 2.17967135 2.46711152 3.96841794 1.20347751 6.36959227\n",
      " 2.22622207 3.65798829 4.25331362 8.14868929]\n",
      "##########\n",
      "epoch:34 step:32601 [D loss: 0.621313, acc.: 69.53%] [G loss: 0.900980]\n",
      "epoch:34 step:32602 [D loss: 0.649084, acc.: 65.62%] [G loss: 0.898965]\n",
      "epoch:34 step:32603 [D loss: 0.634942, acc.: 62.50%] [G loss: 0.935796]\n",
      "epoch:34 step:32604 [D loss: 0.614283, acc.: 68.75%] [G loss: 0.975086]\n",
      "epoch:34 step:32605 [D loss: 0.644383, acc.: 60.16%] [G loss: 1.004470]\n",
      "epoch:34 step:32606 [D loss: 0.608725, acc.: 67.19%] [G loss: 0.952446]\n",
      "epoch:34 step:32607 [D loss: 0.644072, acc.: 63.28%] [G loss: 0.972631]\n",
      "epoch:34 step:32608 [D loss: 0.651300, acc.: 63.28%] [G loss: 0.993996]\n",
      "epoch:34 step:32609 [D loss: 0.601618, acc.: 70.31%] [G loss: 0.943218]\n",
      "epoch:34 step:32610 [D loss: 0.640445, acc.: 65.62%] [G loss: 0.939227]\n",
      "epoch:34 step:32611 [D loss: 0.593894, acc.: 66.41%] [G loss: 0.935961]\n",
      "epoch:34 step:32612 [D loss: 0.664348, acc.: 62.50%] [G loss: 0.884165]\n",
      "epoch:34 step:32613 [D loss: 0.640598, acc.: 59.38%] [G loss: 0.948679]\n",
      "epoch:34 step:32614 [D loss: 0.621714, acc.: 68.75%] [G loss: 0.896329]\n",
      "epoch:34 step:32615 [D loss: 0.618997, acc.: 67.19%] [G loss: 0.981525]\n",
      "epoch:34 step:32616 [D loss: 0.633981, acc.: 66.41%] [G loss: 0.956177]\n",
      "epoch:34 step:32617 [D loss: 0.656600, acc.: 60.16%] [G loss: 0.902457]\n",
      "epoch:34 step:32618 [D loss: 0.625811, acc.: 62.50%] [G loss: 0.876928]\n",
      "epoch:34 step:32619 [D loss: 0.652291, acc.: 59.38%] [G loss: 0.974233]\n",
      "epoch:34 step:32620 [D loss: 0.682278, acc.: 54.69%] [G loss: 0.975132]\n",
      "epoch:34 step:32621 [D loss: 0.656066, acc.: 64.84%] [G loss: 0.931079]\n",
      "epoch:34 step:32622 [D loss: 0.637039, acc.: 61.72%] [G loss: 0.929322]\n",
      "epoch:34 step:32623 [D loss: 0.671397, acc.: 55.47%] [G loss: 0.971783]\n",
      "epoch:34 step:32624 [D loss: 0.646194, acc.: 64.84%] [G loss: 0.932840]\n",
      "epoch:34 step:32625 [D loss: 0.654547, acc.: 62.50%] [G loss: 1.019681]\n",
      "epoch:34 step:32626 [D loss: 0.653619, acc.: 64.84%] [G loss: 1.025090]\n",
      "epoch:34 step:32627 [D loss: 0.621634, acc.: 72.66%] [G loss: 0.986220]\n",
      "epoch:34 step:32628 [D loss: 0.648778, acc.: 64.06%] [G loss: 0.923303]\n",
      "epoch:34 step:32629 [D loss: 0.636532, acc.: 64.84%] [G loss: 0.923070]\n",
      "epoch:34 step:32630 [D loss: 0.612128, acc.: 70.31%] [G loss: 0.909187]\n",
      "epoch:34 step:32631 [D loss: 0.679842, acc.: 56.25%] [G loss: 0.906916]\n",
      "epoch:34 step:32632 [D loss: 0.625500, acc.: 69.53%] [G loss: 0.996912]\n",
      "epoch:34 step:32633 [D loss: 0.642804, acc.: 64.84%] [G loss: 0.941753]\n",
      "epoch:34 step:32634 [D loss: 0.647349, acc.: 67.97%] [G loss: 0.942669]\n",
      "epoch:34 step:32635 [D loss: 0.657885, acc.: 62.50%] [G loss: 0.908402]\n",
      "epoch:34 step:32636 [D loss: 0.636331, acc.: 62.50%] [G loss: 0.914371]\n",
      "epoch:34 step:32637 [D loss: 0.645641, acc.: 63.28%] [G loss: 0.878603]\n",
      "epoch:34 step:32638 [D loss: 0.644757, acc.: 60.16%] [G loss: 0.986676]\n",
      "epoch:34 step:32639 [D loss: 0.647800, acc.: 65.62%] [G loss: 0.988917]\n",
      "epoch:34 step:32640 [D loss: 0.659949, acc.: 62.50%] [G loss: 0.935667]\n",
      "epoch:34 step:32641 [D loss: 0.663323, acc.: 58.59%] [G loss: 0.898010]\n",
      "epoch:34 step:32642 [D loss: 0.641463, acc.: 64.06%] [G loss: 0.956347]\n",
      "epoch:34 step:32643 [D loss: 0.639106, acc.: 60.94%] [G loss: 0.948765]\n",
      "epoch:34 step:32644 [D loss: 0.681979, acc.: 57.03%] [G loss: 0.916202]\n",
      "epoch:34 step:32645 [D loss: 0.652755, acc.: 57.03%] [G loss: 0.961122]\n",
      "epoch:34 step:32646 [D loss: 0.623351, acc.: 60.94%] [G loss: 0.943020]\n",
      "epoch:34 step:32647 [D loss: 0.609789, acc.: 69.53%] [G loss: 0.866486]\n",
      "epoch:34 step:32648 [D loss: 0.582986, acc.: 71.09%] [G loss: 0.890494]\n",
      "epoch:34 step:32649 [D loss: 0.632203, acc.: 64.84%] [G loss: 0.891502]\n",
      "epoch:34 step:32650 [D loss: 0.641022, acc.: 66.41%] [G loss: 0.970561]\n",
      "epoch:34 step:32651 [D loss: 0.581982, acc.: 73.44%] [G loss: 0.955010]\n",
      "epoch:34 step:32652 [D loss: 0.610437, acc.: 64.06%] [G loss: 0.955913]\n",
      "epoch:34 step:32653 [D loss: 0.680647, acc.: 55.47%] [G loss: 0.956123]\n",
      "epoch:34 step:32654 [D loss: 0.677119, acc.: 58.59%] [G loss: 0.885983]\n",
      "epoch:34 step:32655 [D loss: 0.641922, acc.: 62.50%] [G loss: 0.948432]\n",
      "epoch:34 step:32656 [D loss: 0.625962, acc.: 62.50%] [G loss: 0.967488]\n",
      "epoch:34 step:32657 [D loss: 0.634599, acc.: 63.28%] [G loss: 0.935630]\n",
      "epoch:34 step:32658 [D loss: 0.650008, acc.: 65.62%] [G loss: 0.982219]\n",
      "epoch:34 step:32659 [D loss: 0.661141, acc.: 56.25%] [G loss: 0.983169]\n",
      "epoch:34 step:32660 [D loss: 0.695151, acc.: 56.25%] [G loss: 0.999311]\n",
      "epoch:34 step:32661 [D loss: 0.649477, acc.: 66.41%] [G loss: 0.902803]\n",
      "epoch:34 step:32662 [D loss: 0.642261, acc.: 60.94%] [G loss: 0.938027]\n",
      "epoch:34 step:32663 [D loss: 0.637246, acc.: 62.50%] [G loss: 0.896338]\n",
      "epoch:34 step:32664 [D loss: 0.683339, acc.: 51.56%] [G loss: 0.887216]\n",
      "epoch:34 step:32665 [D loss: 0.667299, acc.: 57.03%] [G loss: 0.875439]\n",
      "epoch:34 step:32666 [D loss: 0.633971, acc.: 63.28%] [G loss: 0.957906]\n",
      "epoch:34 step:32667 [D loss: 0.644883, acc.: 60.16%] [G loss: 0.884941]\n",
      "epoch:34 step:32668 [D loss: 0.623920, acc.: 67.19%] [G loss: 0.941652]\n",
      "epoch:34 step:32669 [D loss: 0.678757, acc.: 54.69%] [G loss: 0.885706]\n",
      "epoch:34 step:32670 [D loss: 0.638139, acc.: 63.28%] [G loss: 0.967444]\n",
      "epoch:34 step:32671 [D loss: 0.654547, acc.: 59.38%] [G loss: 0.994440]\n",
      "epoch:34 step:32672 [D loss: 0.627556, acc.: 61.72%] [G loss: 0.955982]\n",
      "epoch:34 step:32673 [D loss: 0.629280, acc.: 64.84%] [G loss: 0.951108]\n",
      "epoch:34 step:32674 [D loss: 0.630482, acc.: 62.50%] [G loss: 0.876421]\n",
      "epoch:34 step:32675 [D loss: 0.709755, acc.: 55.47%] [G loss: 0.958615]\n",
      "epoch:34 step:32676 [D loss: 0.666485, acc.: 56.25%] [G loss: 0.953213]\n",
      "epoch:34 step:32677 [D loss: 0.649662, acc.: 62.50%] [G loss: 0.916835]\n",
      "epoch:34 step:32678 [D loss: 0.685193, acc.: 60.94%] [G loss: 0.954978]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:34 step:32679 [D loss: 0.629916, acc.: 63.28%] [G loss: 0.919219]\n",
      "epoch:34 step:32680 [D loss: 0.635268, acc.: 60.16%] [G loss: 0.890651]\n",
      "epoch:34 step:32681 [D loss: 0.657296, acc.: 61.72%] [G loss: 0.980982]\n",
      "epoch:34 step:32682 [D loss: 0.647220, acc.: 64.06%] [G loss: 0.971487]\n",
      "epoch:34 step:32683 [D loss: 0.641394, acc.: 66.41%] [G loss: 0.927830]\n",
      "epoch:34 step:32684 [D loss: 0.623805, acc.: 66.41%] [G loss: 0.919276]\n",
      "epoch:34 step:32685 [D loss: 0.657796, acc.: 59.38%] [G loss: 0.934412]\n",
      "epoch:34 step:32686 [D loss: 0.712622, acc.: 53.12%] [G loss: 0.880662]\n",
      "epoch:34 step:32687 [D loss: 0.660345, acc.: 62.50%] [G loss: 0.899728]\n",
      "epoch:34 step:32688 [D loss: 0.667063, acc.: 57.03%] [G loss: 0.841825]\n",
      "epoch:34 step:32689 [D loss: 0.631820, acc.: 59.38%] [G loss: 0.926214]\n",
      "epoch:34 step:32690 [D loss: 0.626168, acc.: 60.16%] [G loss: 0.904526]\n",
      "epoch:34 step:32691 [D loss: 0.641869, acc.: 60.94%] [G loss: 0.893538]\n",
      "epoch:34 step:32692 [D loss: 0.618693, acc.: 64.84%] [G loss: 0.940439]\n",
      "epoch:34 step:32693 [D loss: 0.684019, acc.: 60.16%] [G loss: 0.914336]\n",
      "epoch:34 step:32694 [D loss: 0.628644, acc.: 70.31%] [G loss: 0.905949]\n",
      "epoch:34 step:32695 [D loss: 0.634348, acc.: 59.38%] [G loss: 0.862508]\n",
      "epoch:34 step:32696 [D loss: 0.682433, acc.: 59.38%] [G loss: 0.940493]\n",
      "epoch:34 step:32697 [D loss: 0.615123, acc.: 65.62%] [G loss: 0.962686]\n",
      "epoch:34 step:32698 [D loss: 0.621837, acc.: 67.19%] [G loss: 0.918808]\n",
      "epoch:34 step:32699 [D loss: 0.659300, acc.: 63.28%] [G loss: 0.938721]\n",
      "epoch:34 step:32700 [D loss: 0.655744, acc.: 60.16%] [G loss: 0.910564]\n",
      "epoch:34 step:32701 [D loss: 0.713694, acc.: 50.00%] [G loss: 0.884604]\n",
      "epoch:34 step:32702 [D loss: 0.666702, acc.: 58.59%] [G loss: 0.900810]\n",
      "epoch:34 step:32703 [D loss: 0.659000, acc.: 62.50%] [G loss: 0.940596]\n",
      "epoch:34 step:32704 [D loss: 0.645864, acc.: 59.38%] [G loss: 0.925521]\n",
      "epoch:34 step:32705 [D loss: 0.648062, acc.: 60.16%] [G loss: 0.970182]\n",
      "epoch:34 step:32706 [D loss: 0.659158, acc.: 58.59%] [G loss: 0.881866]\n",
      "epoch:34 step:32707 [D loss: 0.629025, acc.: 65.62%] [G loss: 0.964239]\n",
      "epoch:34 step:32708 [D loss: 0.618556, acc.: 59.38%] [G loss: 0.949745]\n",
      "epoch:34 step:32709 [D loss: 0.647054, acc.: 57.81%] [G loss: 0.917451]\n",
      "epoch:34 step:32710 [D loss: 0.626405, acc.: 68.75%] [G loss: 0.946934]\n",
      "epoch:34 step:32711 [D loss: 0.642969, acc.: 60.94%] [G loss: 0.894039]\n",
      "epoch:34 step:32712 [D loss: 0.676140, acc.: 57.03%] [G loss: 0.921390]\n",
      "epoch:34 step:32713 [D loss: 0.709891, acc.: 54.69%] [G loss: 0.919147]\n",
      "epoch:34 step:32714 [D loss: 0.603856, acc.: 67.97%] [G loss: 0.916287]\n",
      "epoch:34 step:32715 [D loss: 0.668330, acc.: 57.03%] [G loss: 0.968280]\n",
      "epoch:34 step:32716 [D loss: 0.655625, acc.: 56.25%] [G loss: 0.929479]\n",
      "epoch:34 step:32717 [D loss: 0.668616, acc.: 57.03%] [G loss: 0.877697]\n",
      "epoch:34 step:32718 [D loss: 0.670705, acc.: 54.69%] [G loss: 0.980362]\n",
      "epoch:34 step:32719 [D loss: 0.586673, acc.: 67.19%] [G loss: 0.908743]\n",
      "epoch:34 step:32720 [D loss: 0.693195, acc.: 54.69%] [G loss: 0.940539]\n",
      "epoch:34 step:32721 [D loss: 0.645345, acc.: 64.06%] [G loss: 0.929727]\n",
      "epoch:34 step:32722 [D loss: 0.636664, acc.: 62.50%] [G loss: 0.955450]\n",
      "epoch:34 step:32723 [D loss: 0.691460, acc.: 53.12%] [G loss: 0.889704]\n",
      "epoch:34 step:32724 [D loss: 0.624346, acc.: 61.72%] [G loss: 0.918077]\n",
      "epoch:34 step:32725 [D loss: 0.699894, acc.: 57.81%] [G loss: 0.923290]\n",
      "epoch:34 step:32726 [D loss: 0.637384, acc.: 68.75%] [G loss: 0.909336]\n",
      "epoch:34 step:32727 [D loss: 0.688745, acc.: 51.56%] [G loss: 0.923369]\n",
      "epoch:34 step:32728 [D loss: 0.648741, acc.: 60.16%] [G loss: 0.962613]\n",
      "epoch:34 step:32729 [D loss: 0.636235, acc.: 60.16%] [G loss: 0.940555]\n",
      "epoch:34 step:32730 [D loss: 0.680346, acc.: 52.34%] [G loss: 0.910669]\n",
      "epoch:34 step:32731 [D loss: 0.620796, acc.: 63.28%] [G loss: 0.906620]\n",
      "epoch:34 step:32732 [D loss: 0.604472, acc.: 69.53%] [G loss: 0.897841]\n",
      "epoch:34 step:32733 [D loss: 0.628097, acc.: 64.06%] [G loss: 0.929600]\n",
      "epoch:34 step:32734 [D loss: 0.666163, acc.: 61.72%] [G loss: 0.940505]\n",
      "epoch:34 step:32735 [D loss: 0.629899, acc.: 63.28%] [G loss: 0.950980]\n",
      "epoch:34 step:32736 [D loss: 0.611127, acc.: 65.62%] [G loss: 1.023285]\n",
      "epoch:34 step:32737 [D loss: 0.655778, acc.: 59.38%] [G loss: 1.011384]\n",
      "epoch:34 step:32738 [D loss: 0.626865, acc.: 63.28%] [G loss: 0.945236]\n",
      "epoch:34 step:32739 [D loss: 0.684539, acc.: 53.91%] [G loss: 0.929805]\n",
      "epoch:34 step:32740 [D loss: 0.609188, acc.: 67.19%] [G loss: 0.928477]\n",
      "epoch:34 step:32741 [D loss: 0.603623, acc.: 68.75%] [G loss: 0.914282]\n",
      "epoch:34 step:32742 [D loss: 0.586518, acc.: 75.00%] [G loss: 0.961116]\n",
      "epoch:34 step:32743 [D loss: 0.651320, acc.: 64.06%] [G loss: 0.993342]\n",
      "epoch:34 step:32744 [D loss: 0.611507, acc.: 67.97%] [G loss: 0.973715]\n",
      "epoch:34 step:32745 [D loss: 0.601147, acc.: 67.19%] [G loss: 1.031741]\n",
      "epoch:34 step:32746 [D loss: 0.622609, acc.: 64.84%] [G loss: 0.998864]\n",
      "epoch:34 step:32747 [D loss: 0.610482, acc.: 67.97%] [G loss: 0.928389]\n",
      "epoch:34 step:32748 [D loss: 0.619681, acc.: 67.97%] [G loss: 0.898211]\n",
      "epoch:34 step:32749 [D loss: 0.647034, acc.: 60.94%] [G loss: 0.957560]\n",
      "epoch:34 step:32750 [D loss: 0.630518, acc.: 64.84%] [G loss: 0.911539]\n",
      "epoch:34 step:32751 [D loss: 0.668138, acc.: 57.81%] [G loss: 0.964517]\n",
      "epoch:34 step:32752 [D loss: 0.672463, acc.: 57.03%] [G loss: 0.972602]\n",
      "epoch:34 step:32753 [D loss: 0.618723, acc.: 64.84%] [G loss: 1.016066]\n",
      "epoch:34 step:32754 [D loss: 0.639256, acc.: 61.72%] [G loss: 0.978932]\n",
      "epoch:34 step:32755 [D loss: 0.641689, acc.: 63.28%] [G loss: 0.904026]\n",
      "epoch:34 step:32756 [D loss: 0.652676, acc.: 61.72%] [G loss: 0.958005]\n",
      "epoch:34 step:32757 [D loss: 0.602581, acc.: 68.75%] [G loss: 1.002341]\n",
      "epoch:34 step:32758 [D loss: 0.655969, acc.: 61.72%] [G loss: 0.973003]\n",
      "epoch:34 step:32759 [D loss: 0.656528, acc.: 60.94%] [G loss: 0.919406]\n",
      "epoch:34 step:32760 [D loss: 0.670125, acc.: 57.81%] [G loss: 0.946155]\n",
      "epoch:34 step:32761 [D loss: 0.608856, acc.: 67.97%] [G loss: 0.923399]\n",
      "epoch:34 step:32762 [D loss: 0.646039, acc.: 61.72%] [G loss: 0.969110]\n",
      "epoch:34 step:32763 [D loss: 0.666608, acc.: 64.84%] [G loss: 0.930026]\n",
      "epoch:34 step:32764 [D loss: 0.618974, acc.: 64.84%] [G loss: 0.923594]\n",
      "epoch:34 step:32765 [D loss: 0.665223, acc.: 52.34%] [G loss: 0.897932]\n",
      "epoch:34 step:32766 [D loss: 0.671254, acc.: 59.38%] [G loss: 0.960318]\n",
      "epoch:34 step:32767 [D loss: 0.643453, acc.: 60.94%] [G loss: 0.887929]\n",
      "epoch:34 step:32768 [D loss: 0.675210, acc.: 53.12%] [G loss: 0.932590]\n",
      "epoch:34 step:32769 [D loss: 0.599778, acc.: 70.31%] [G loss: 0.957074]\n",
      "epoch:34 step:32770 [D loss: 0.657752, acc.: 57.81%] [G loss: 0.917275]\n",
      "epoch:34 step:32771 [D loss: 0.669507, acc.: 60.94%] [G loss: 0.917441]\n",
      "epoch:34 step:32772 [D loss: 0.639131, acc.: 61.72%] [G loss: 0.953310]\n",
      "epoch:34 step:32773 [D loss: 0.636354, acc.: 67.19%] [G loss: 0.900301]\n",
      "epoch:34 step:32774 [D loss: 0.622861, acc.: 65.62%] [G loss: 0.895849]\n",
      "epoch:34 step:32775 [D loss: 0.631778, acc.: 67.19%] [G loss: 0.974007]\n",
      "epoch:34 step:32776 [D loss: 0.598554, acc.: 65.62%] [G loss: 0.935203]\n",
      "epoch:34 step:32777 [D loss: 0.645948, acc.: 63.28%] [G loss: 0.902015]\n",
      "epoch:34 step:32778 [D loss: 0.584909, acc.: 68.75%] [G loss: 0.866746]\n",
      "epoch:34 step:32779 [D loss: 0.639164, acc.: 59.38%] [G loss: 0.898841]\n",
      "epoch:34 step:32780 [D loss: 0.650580, acc.: 63.28%] [G loss: 0.879710]\n",
      "epoch:34 step:32781 [D loss: 0.656353, acc.: 56.25%] [G loss: 0.946244]\n",
      "epoch:34 step:32782 [D loss: 0.617874, acc.: 67.19%] [G loss: 0.979288]\n",
      "epoch:34 step:32783 [D loss: 0.618867, acc.: 67.97%] [G loss: 0.890748]\n",
      "epoch:34 step:32784 [D loss: 0.641945, acc.: 64.06%] [G loss: 0.891005]\n",
      "epoch:34 step:32785 [D loss: 0.630204, acc.: 64.84%] [G loss: 0.939923]\n",
      "epoch:34 step:32786 [D loss: 0.631244, acc.: 64.06%] [G loss: 0.834179]\n",
      "epoch:34 step:32787 [D loss: 0.683188, acc.: 60.16%] [G loss: 0.948993]\n",
      "epoch:34 step:32788 [D loss: 0.583471, acc.: 71.09%] [G loss: 1.053723]\n",
      "epoch:34 step:32789 [D loss: 0.653947, acc.: 61.72%] [G loss: 1.009808]\n",
      "epoch:34 step:32790 [D loss: 0.641511, acc.: 60.94%] [G loss: 1.038633]\n",
      "epoch:34 step:32791 [D loss: 0.665305, acc.: 63.28%] [G loss: 1.003639]\n",
      "epoch:34 step:32792 [D loss: 0.575959, acc.: 76.56%] [G loss: 0.925556]\n",
      "epoch:34 step:32793 [D loss: 0.659131, acc.: 60.16%] [G loss: 0.893101]\n",
      "epoch:34 step:32794 [D loss: 0.664659, acc.: 58.59%] [G loss: 0.865615]\n",
      "epoch:34 step:32795 [D loss: 0.639935, acc.: 64.84%] [G loss: 0.888658]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:32796 [D loss: 0.628158, acc.: 64.06%] [G loss: 1.026447]\n",
      "epoch:35 step:32797 [D loss: 0.633783, acc.: 69.53%] [G loss: 0.931344]\n",
      "epoch:35 step:32798 [D loss: 0.633672, acc.: 62.50%] [G loss: 0.896690]\n",
      "epoch:35 step:32799 [D loss: 0.655717, acc.: 63.28%] [G loss: 0.977603]\n",
      "epoch:35 step:32800 [D loss: 0.656279, acc.: 58.59%] [G loss: 0.982094]\n",
      "##############\n",
      "[3.15392823 2.40514176 2.09363034 3.64517591 1.35105963 7.0454911\n",
      " 2.44109624 3.95379282 4.04504359 7.14868929]\n",
      "##########\n",
      "epoch:35 step:32801 [D loss: 0.638920, acc.: 68.75%] [G loss: 0.974512]\n",
      "epoch:35 step:32802 [D loss: 0.673522, acc.: 55.47%] [G loss: 0.980185]\n",
      "epoch:35 step:32803 [D loss: 0.664634, acc.: 59.38%] [G loss: 0.959383]\n",
      "epoch:35 step:32804 [D loss: 0.675556, acc.: 58.59%] [G loss: 0.911240]\n",
      "epoch:35 step:32805 [D loss: 0.617914, acc.: 66.41%] [G loss: 0.980533]\n",
      "epoch:35 step:32806 [D loss: 0.587253, acc.: 67.19%] [G loss: 0.970412]\n",
      "epoch:35 step:32807 [D loss: 0.630811, acc.: 65.62%] [G loss: 0.844666]\n",
      "epoch:35 step:32808 [D loss: 0.635249, acc.: 61.72%] [G loss: 0.880607]\n",
      "epoch:35 step:32809 [D loss: 0.645976, acc.: 61.72%] [G loss: 0.909484]\n",
      "epoch:35 step:32810 [D loss: 0.629721, acc.: 64.84%] [G loss: 0.883640]\n",
      "epoch:35 step:32811 [D loss: 0.652291, acc.: 57.81%] [G loss: 0.895420]\n",
      "epoch:35 step:32812 [D loss: 0.629551, acc.: 65.62%] [G loss: 0.934722]\n",
      "epoch:35 step:32813 [D loss: 0.647683, acc.: 59.38%] [G loss: 0.941449]\n",
      "epoch:35 step:32814 [D loss: 0.635912, acc.: 62.50%] [G loss: 0.945199]\n",
      "epoch:35 step:32815 [D loss: 0.650083, acc.: 56.25%] [G loss: 0.990796]\n",
      "epoch:35 step:32816 [D loss: 0.664108, acc.: 56.25%] [G loss: 1.031682]\n",
      "epoch:35 step:32817 [D loss: 0.628492, acc.: 67.97%] [G loss: 0.973803]\n",
      "epoch:35 step:32818 [D loss: 0.675976, acc.: 57.81%] [G loss: 0.902580]\n",
      "epoch:35 step:32819 [D loss: 0.661537, acc.: 55.47%] [G loss: 0.901607]\n",
      "epoch:35 step:32820 [D loss: 0.631972, acc.: 64.06%] [G loss: 0.990429]\n",
      "epoch:35 step:32821 [D loss: 0.635566, acc.: 64.06%] [G loss: 0.962734]\n",
      "epoch:35 step:32822 [D loss: 0.669518, acc.: 59.38%] [G loss: 0.901414]\n",
      "epoch:35 step:32823 [D loss: 0.569481, acc.: 74.22%] [G loss: 0.939262]\n",
      "epoch:35 step:32824 [D loss: 0.679694, acc.: 57.03%] [G loss: 0.892624]\n",
      "epoch:35 step:32825 [D loss: 0.617460, acc.: 66.41%] [G loss: 0.948096]\n",
      "epoch:35 step:32826 [D loss: 0.618639, acc.: 67.97%] [G loss: 0.938247]\n",
      "epoch:35 step:32827 [D loss: 0.627833, acc.: 66.41%] [G loss: 0.936020]\n",
      "epoch:35 step:32828 [D loss: 0.692093, acc.: 59.38%] [G loss: 0.949942]\n",
      "epoch:35 step:32829 [D loss: 0.683949, acc.: 57.81%] [G loss: 1.012776]\n",
      "epoch:35 step:32830 [D loss: 0.645263, acc.: 63.28%] [G loss: 0.975419]\n",
      "epoch:35 step:32831 [D loss: 0.616926, acc.: 64.84%] [G loss: 0.984522]\n",
      "epoch:35 step:32832 [D loss: 0.634418, acc.: 64.84%] [G loss: 1.003408]\n",
      "epoch:35 step:32833 [D loss: 0.676037, acc.: 58.59%] [G loss: 1.024745]\n",
      "epoch:35 step:32834 [D loss: 0.630093, acc.: 64.84%] [G loss: 0.945472]\n",
      "epoch:35 step:32835 [D loss: 0.667920, acc.: 58.59%] [G loss: 0.900941]\n",
      "epoch:35 step:32836 [D loss: 0.654562, acc.: 57.81%] [G loss: 0.910599]\n",
      "epoch:35 step:32837 [D loss: 0.619070, acc.: 64.06%] [G loss: 0.926412]\n",
      "epoch:35 step:32838 [D loss: 0.659201, acc.: 57.03%] [G loss: 0.880894]\n",
      "epoch:35 step:32839 [D loss: 0.606225, acc.: 68.75%] [G loss: 0.916083]\n",
      "epoch:35 step:32840 [D loss: 0.668432, acc.: 57.81%] [G loss: 0.908609]\n",
      "epoch:35 step:32841 [D loss: 0.688732, acc.: 57.03%] [G loss: 0.877267]\n",
      "epoch:35 step:32842 [D loss: 0.672844, acc.: 57.03%] [G loss: 0.990345]\n",
      "epoch:35 step:32843 [D loss: 0.618130, acc.: 64.06%] [G loss: 0.947174]\n",
      "epoch:35 step:32844 [D loss: 0.646436, acc.: 69.53%] [G loss: 0.938841]\n",
      "epoch:35 step:32845 [D loss: 0.645589, acc.: 60.16%] [G loss: 0.992310]\n",
      "epoch:35 step:32846 [D loss: 0.640814, acc.: 64.84%] [G loss: 0.991845]\n",
      "epoch:35 step:32847 [D loss: 0.642301, acc.: 59.38%] [G loss: 0.986658]\n",
      "epoch:35 step:32848 [D loss: 0.636322, acc.: 67.97%] [G loss: 0.948305]\n",
      "epoch:35 step:32849 [D loss: 0.620225, acc.: 66.41%] [G loss: 0.989127]\n",
      "epoch:35 step:32850 [D loss: 0.629240, acc.: 65.62%] [G loss: 0.955888]\n",
      "epoch:35 step:32851 [D loss: 0.630790, acc.: 60.94%] [G loss: 0.947327]\n",
      "epoch:35 step:32852 [D loss: 0.688831, acc.: 54.69%] [G loss: 0.951194]\n",
      "epoch:35 step:32853 [D loss: 0.669330, acc.: 60.94%] [G loss: 0.966076]\n",
      "epoch:35 step:32854 [D loss: 0.581956, acc.: 74.22%] [G loss: 1.010848]\n",
      "epoch:35 step:32855 [D loss: 0.597739, acc.: 65.62%] [G loss: 0.991530]\n",
      "epoch:35 step:32856 [D loss: 0.608951, acc.: 67.97%] [G loss: 0.965345]\n",
      "epoch:35 step:32857 [D loss: 0.640358, acc.: 63.28%] [G loss: 0.956897]\n",
      "epoch:35 step:32858 [D loss: 0.622392, acc.: 64.06%] [G loss: 0.909505]\n",
      "epoch:35 step:32859 [D loss: 0.623889, acc.: 66.41%] [G loss: 0.905541]\n",
      "epoch:35 step:32860 [D loss: 0.618826, acc.: 65.62%] [G loss: 0.941478]\n",
      "epoch:35 step:32861 [D loss: 0.634800, acc.: 62.50%] [G loss: 0.866377]\n",
      "epoch:35 step:32862 [D loss: 0.665884, acc.: 59.38%] [G loss: 0.921969]\n",
      "epoch:35 step:32863 [D loss: 0.656715, acc.: 61.72%] [G loss: 0.864374]\n",
      "epoch:35 step:32864 [D loss: 0.645353, acc.: 55.47%] [G loss: 0.903815]\n",
      "epoch:35 step:32865 [D loss: 0.652011, acc.: 58.59%] [G loss: 0.967739]\n",
      "epoch:35 step:32866 [D loss: 0.645401, acc.: 63.28%] [G loss: 1.023825]\n",
      "epoch:35 step:32867 [D loss: 0.669830, acc.: 59.38%] [G loss: 0.959746]\n",
      "epoch:35 step:32868 [D loss: 0.600863, acc.: 71.09%] [G loss: 0.965483]\n",
      "epoch:35 step:32869 [D loss: 0.603930, acc.: 67.19%] [G loss: 0.941657]\n",
      "epoch:35 step:32870 [D loss: 0.650024, acc.: 59.38%] [G loss: 0.945014]\n",
      "epoch:35 step:32871 [D loss: 0.603459, acc.: 65.62%] [G loss: 0.932419]\n",
      "epoch:35 step:32872 [D loss: 0.657441, acc.: 60.94%] [G loss: 0.936800]\n",
      "epoch:35 step:32873 [D loss: 0.615330, acc.: 72.66%] [G loss: 1.003592]\n",
      "epoch:35 step:32874 [D loss: 0.670527, acc.: 64.06%] [G loss: 0.967136]\n",
      "epoch:35 step:32875 [D loss: 0.664336, acc.: 62.50%] [G loss: 0.880036]\n",
      "epoch:35 step:32876 [D loss: 0.646316, acc.: 60.94%] [G loss: 0.920396]\n",
      "epoch:35 step:32877 [D loss: 0.638283, acc.: 64.06%] [G loss: 0.878480]\n",
      "epoch:35 step:32878 [D loss: 0.679007, acc.: 60.94%] [G loss: 0.896196]\n",
      "epoch:35 step:32879 [D loss: 0.664022, acc.: 58.59%] [G loss: 0.896429]\n",
      "epoch:35 step:32880 [D loss: 0.669837, acc.: 60.16%] [G loss: 0.962972]\n",
      "epoch:35 step:32881 [D loss: 0.642704, acc.: 64.84%] [G loss: 0.873107]\n",
      "epoch:35 step:32882 [D loss: 0.639033, acc.: 61.72%] [G loss: 0.955626]\n",
      "epoch:35 step:32883 [D loss: 0.633450, acc.: 70.31%] [G loss: 0.898428]\n",
      "epoch:35 step:32884 [D loss: 0.601965, acc.: 73.44%] [G loss: 0.889773]\n",
      "epoch:35 step:32885 [D loss: 0.639547, acc.: 64.84%] [G loss: 0.975851]\n",
      "epoch:35 step:32886 [D loss: 0.682487, acc.: 60.16%] [G loss: 0.941405]\n",
      "epoch:35 step:32887 [D loss: 0.634025, acc.: 62.50%] [G loss: 0.974662]\n",
      "epoch:35 step:32888 [D loss: 0.647381, acc.: 61.72%] [G loss: 0.864370]\n",
      "epoch:35 step:32889 [D loss: 0.633145, acc.: 63.28%] [G loss: 0.940560]\n",
      "epoch:35 step:32890 [D loss: 0.680405, acc.: 59.38%] [G loss: 0.915396]\n",
      "epoch:35 step:32891 [D loss: 0.661646, acc.: 60.16%] [G loss: 0.944416]\n",
      "epoch:35 step:32892 [D loss: 0.634004, acc.: 65.62%] [G loss: 0.963745]\n",
      "epoch:35 step:32893 [D loss: 0.677549, acc.: 53.91%] [G loss: 0.990608]\n",
      "epoch:35 step:32894 [D loss: 0.690876, acc.: 57.03%] [G loss: 1.027338]\n",
      "epoch:35 step:32895 [D loss: 0.673649, acc.: 56.25%] [G loss: 0.987098]\n",
      "epoch:35 step:32896 [D loss: 0.640487, acc.: 64.84%] [G loss: 0.971995]\n",
      "epoch:35 step:32897 [D loss: 0.687425, acc.: 51.56%] [G loss: 0.979493]\n",
      "epoch:35 step:32898 [D loss: 0.622357, acc.: 57.81%] [G loss: 0.930302]\n",
      "epoch:35 step:32899 [D loss: 0.640409, acc.: 63.28%] [G loss: 0.878589]\n",
      "epoch:35 step:32900 [D loss: 0.611705, acc.: 66.41%] [G loss: 0.895986]\n",
      "epoch:35 step:32901 [D loss: 0.613825, acc.: 67.97%] [G loss: 0.897274]\n",
      "epoch:35 step:32902 [D loss: 0.616605, acc.: 66.41%] [G loss: 0.892231]\n",
      "epoch:35 step:32903 [D loss: 0.635614, acc.: 64.84%] [G loss: 0.966841]\n",
      "epoch:35 step:32904 [D loss: 0.629454, acc.: 59.38%] [G loss: 0.929489]\n",
      "epoch:35 step:32905 [D loss: 0.639153, acc.: 61.72%] [G loss: 0.965939]\n",
      "epoch:35 step:32906 [D loss: 0.680830, acc.: 52.34%] [G loss: 0.989581]\n",
      "epoch:35 step:32907 [D loss: 0.642582, acc.: 56.25%] [G loss: 1.061180]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:32908 [D loss: 0.631550, acc.: 62.50%] [G loss: 0.950924]\n",
      "epoch:35 step:32909 [D loss: 0.657570, acc.: 64.06%] [G loss: 0.928422]\n",
      "epoch:35 step:32910 [D loss: 0.673677, acc.: 64.84%] [G loss: 0.934819]\n",
      "epoch:35 step:32911 [D loss: 0.606735, acc.: 69.53%] [G loss: 0.940328]\n",
      "epoch:35 step:32912 [D loss: 0.681156, acc.: 55.47%] [G loss: 0.992524]\n",
      "epoch:35 step:32913 [D loss: 0.634925, acc.: 63.28%] [G loss: 0.886261]\n",
      "epoch:35 step:32914 [D loss: 0.653052, acc.: 63.28%] [G loss: 0.887321]\n",
      "epoch:35 step:32915 [D loss: 0.700400, acc.: 60.94%] [G loss: 0.977440]\n",
      "epoch:35 step:32916 [D loss: 0.626405, acc.: 64.84%] [G loss: 0.952915]\n",
      "epoch:35 step:32917 [D loss: 0.651710, acc.: 60.94%] [G loss: 0.965703]\n",
      "epoch:35 step:32918 [D loss: 0.652882, acc.: 64.06%] [G loss: 0.990021]\n",
      "epoch:35 step:32919 [D loss: 0.682746, acc.: 57.81%] [G loss: 0.923069]\n",
      "epoch:35 step:32920 [D loss: 0.611289, acc.: 65.62%] [G loss: 0.875222]\n",
      "epoch:35 step:32921 [D loss: 0.669654, acc.: 58.59%] [G loss: 0.973556]\n",
      "epoch:35 step:32922 [D loss: 0.630541, acc.: 70.31%] [G loss: 0.928748]\n",
      "epoch:35 step:32923 [D loss: 0.632357, acc.: 60.94%] [G loss: 0.939018]\n",
      "epoch:35 step:32924 [D loss: 0.630491, acc.: 66.41%] [G loss: 0.941905]\n",
      "epoch:35 step:32925 [D loss: 0.622528, acc.: 67.19%] [G loss: 0.913898]\n",
      "epoch:35 step:32926 [D loss: 0.627356, acc.: 64.06%] [G loss: 0.861404]\n",
      "epoch:35 step:32927 [D loss: 0.674715, acc.: 54.69%] [G loss: 0.931142]\n",
      "epoch:35 step:32928 [D loss: 0.654725, acc.: 60.16%] [G loss: 0.855036]\n",
      "epoch:35 step:32929 [D loss: 0.683341, acc.: 53.91%] [G loss: 0.943147]\n",
      "epoch:35 step:32930 [D loss: 0.677097, acc.: 63.28%] [G loss: 0.906108]\n",
      "epoch:35 step:32931 [D loss: 0.644040, acc.: 62.50%] [G loss: 0.940537]\n",
      "epoch:35 step:32932 [D loss: 0.612163, acc.: 69.53%] [G loss: 1.003855]\n",
      "epoch:35 step:32933 [D loss: 0.634153, acc.: 65.62%] [G loss: 0.998833]\n",
      "epoch:35 step:32934 [D loss: 0.638504, acc.: 64.06%] [G loss: 0.943400]\n",
      "epoch:35 step:32935 [D loss: 0.631219, acc.: 66.41%] [G loss: 0.954176]\n",
      "epoch:35 step:32936 [D loss: 0.701027, acc.: 56.25%] [G loss: 0.864990]\n",
      "epoch:35 step:32937 [D loss: 0.608309, acc.: 67.97%] [G loss: 0.932326]\n",
      "epoch:35 step:32938 [D loss: 0.621231, acc.: 62.50%] [G loss: 0.965620]\n",
      "epoch:35 step:32939 [D loss: 0.631614, acc.: 66.41%] [G loss: 0.895662]\n",
      "epoch:35 step:32940 [D loss: 0.677033, acc.: 56.25%] [G loss: 0.880212]\n",
      "epoch:35 step:32941 [D loss: 0.616103, acc.: 65.62%] [G loss: 0.924480]\n",
      "epoch:35 step:32942 [D loss: 0.636852, acc.: 60.94%] [G loss: 0.934954]\n",
      "epoch:35 step:32943 [D loss: 0.684090, acc.: 54.69%] [G loss: 0.922039]\n",
      "epoch:35 step:32944 [D loss: 0.665413, acc.: 63.28%] [G loss: 0.946984]\n",
      "epoch:35 step:32945 [D loss: 0.658533, acc.: 62.50%] [G loss: 0.986795]\n",
      "epoch:35 step:32946 [D loss: 0.625611, acc.: 64.06%] [G loss: 0.985641]\n",
      "epoch:35 step:32947 [D loss: 0.721208, acc.: 48.44%] [G loss: 0.985246]\n",
      "epoch:35 step:32948 [D loss: 0.657866, acc.: 63.28%] [G loss: 0.975516]\n",
      "epoch:35 step:32949 [D loss: 0.650272, acc.: 59.38%] [G loss: 1.000051]\n",
      "epoch:35 step:32950 [D loss: 0.648139, acc.: 57.81%] [G loss: 0.922318]\n",
      "epoch:35 step:32951 [D loss: 0.608995, acc.: 70.31%] [G loss: 0.979846]\n",
      "epoch:35 step:32952 [D loss: 0.628507, acc.: 66.41%] [G loss: 0.994951]\n",
      "epoch:35 step:32953 [D loss: 0.600837, acc.: 70.31%] [G loss: 0.984973]\n",
      "epoch:35 step:32954 [D loss: 0.600132, acc.: 67.97%] [G loss: 0.936008]\n",
      "epoch:35 step:32955 [D loss: 0.645030, acc.: 60.94%] [G loss: 0.940672]\n",
      "epoch:35 step:32956 [D loss: 0.659062, acc.: 60.94%] [G loss: 0.948209]\n",
      "epoch:35 step:32957 [D loss: 0.631437, acc.: 61.72%] [G loss: 0.943029]\n",
      "epoch:35 step:32958 [D loss: 0.642123, acc.: 64.06%] [G loss: 1.016816]\n",
      "epoch:35 step:32959 [D loss: 0.638745, acc.: 64.84%] [G loss: 0.916414]\n",
      "epoch:35 step:32960 [D loss: 0.618640, acc.: 69.53%] [G loss: 0.974461]\n",
      "epoch:35 step:32961 [D loss: 0.616454, acc.: 64.84%] [G loss: 0.943364]\n",
      "epoch:35 step:32962 [D loss: 0.631511, acc.: 63.28%] [G loss: 0.896968]\n",
      "epoch:35 step:32963 [D loss: 0.644783, acc.: 63.28%] [G loss: 0.993880]\n",
      "epoch:35 step:32964 [D loss: 0.636979, acc.: 64.06%] [G loss: 0.936094]\n",
      "epoch:35 step:32965 [D loss: 0.623435, acc.: 63.28%] [G loss: 0.958356]\n",
      "epoch:35 step:32966 [D loss: 0.672330, acc.: 54.69%] [G loss: 0.897214]\n",
      "epoch:35 step:32967 [D loss: 0.687966, acc.: 57.81%] [G loss: 0.941842]\n",
      "epoch:35 step:32968 [D loss: 0.616720, acc.: 66.41%] [G loss: 0.955631]\n",
      "epoch:35 step:32969 [D loss: 0.597922, acc.: 70.31%] [G loss: 0.946457]\n",
      "epoch:35 step:32970 [D loss: 0.636575, acc.: 62.50%] [G loss: 0.940242]\n",
      "epoch:35 step:32971 [D loss: 0.583297, acc.: 70.31%] [G loss: 0.947603]\n",
      "epoch:35 step:32972 [D loss: 0.648105, acc.: 60.16%] [G loss: 0.964745]\n",
      "epoch:35 step:32973 [D loss: 0.638676, acc.: 64.06%] [G loss: 0.974087]\n",
      "epoch:35 step:32974 [D loss: 0.618370, acc.: 68.75%] [G loss: 0.924270]\n",
      "epoch:35 step:32975 [D loss: 0.583751, acc.: 68.75%] [G loss: 0.917717]\n",
      "epoch:35 step:32976 [D loss: 0.682091, acc.: 50.78%] [G loss: 0.962991]\n",
      "epoch:35 step:32977 [D loss: 0.627521, acc.: 67.19%] [G loss: 0.931951]\n",
      "epoch:35 step:32978 [D loss: 0.658303, acc.: 59.38%] [G loss: 0.895587]\n",
      "epoch:35 step:32979 [D loss: 0.642891, acc.: 67.19%] [G loss: 0.956140]\n",
      "epoch:35 step:32980 [D loss: 0.652453, acc.: 51.56%] [G loss: 1.003227]\n",
      "epoch:35 step:32981 [D loss: 0.625522, acc.: 64.84%] [G loss: 0.967524]\n",
      "epoch:35 step:32982 [D loss: 0.651009, acc.: 62.50%] [G loss: 0.974020]\n",
      "epoch:35 step:32983 [D loss: 0.645243, acc.: 66.41%] [G loss: 0.932301]\n",
      "epoch:35 step:32984 [D loss: 0.697303, acc.: 56.25%] [G loss: 0.928520]\n",
      "epoch:35 step:32985 [D loss: 0.630980, acc.: 65.62%] [G loss: 0.968120]\n",
      "epoch:35 step:32986 [D loss: 0.617847, acc.: 67.19%] [G loss: 0.886504]\n",
      "epoch:35 step:32987 [D loss: 0.632215, acc.: 68.75%] [G loss: 0.912602]\n",
      "epoch:35 step:32988 [D loss: 0.600162, acc.: 71.88%] [G loss: 0.963454]\n",
      "epoch:35 step:32989 [D loss: 0.690571, acc.: 54.69%] [G loss: 0.923760]\n",
      "epoch:35 step:32990 [D loss: 0.619235, acc.: 66.41%] [G loss: 0.948694]\n",
      "epoch:35 step:32991 [D loss: 0.682953, acc.: 57.03%] [G loss: 0.927500]\n",
      "epoch:35 step:32992 [D loss: 0.613251, acc.: 61.72%] [G loss: 0.876997]\n",
      "epoch:35 step:32993 [D loss: 0.664134, acc.: 60.16%] [G loss: 0.969437]\n",
      "epoch:35 step:32994 [D loss: 0.619233, acc.: 64.06%] [G loss: 1.011831]\n",
      "epoch:35 step:32995 [D loss: 0.662918, acc.: 57.03%] [G loss: 0.966616]\n",
      "epoch:35 step:32996 [D loss: 0.629889, acc.: 65.62%] [G loss: 1.018451]\n",
      "epoch:35 step:32997 [D loss: 0.617484, acc.: 66.41%] [G loss: 0.957777]\n",
      "epoch:35 step:32998 [D loss: 0.638856, acc.: 58.59%] [G loss: 0.938573]\n",
      "epoch:35 step:32999 [D loss: 0.678981, acc.: 61.72%] [G loss: 0.938197]\n",
      "epoch:35 step:33000 [D loss: 0.660190, acc.: 55.47%] [G loss: 0.879452]\n",
      "##############\n",
      "[ 2.90845042  2.27861231  2.17989426  3.91960643  0.99962233 10.27426719\n",
      "  2.25876297  3.41408629  4.1138967   7.14868929]\n",
      "##########\n",
      "epoch:35 step:33001 [D loss: 0.649267, acc.: 62.50%] [G loss: 0.921424]\n",
      "epoch:35 step:33002 [D loss: 0.634478, acc.: 64.84%] [G loss: 0.914844]\n",
      "epoch:35 step:33003 [D loss: 0.630232, acc.: 64.84%] [G loss: 0.966778]\n",
      "epoch:35 step:33004 [D loss: 0.661293, acc.: 57.81%] [G loss: 0.997181]\n",
      "epoch:35 step:33005 [D loss: 0.645545, acc.: 70.31%] [G loss: 0.901599]\n",
      "epoch:35 step:33006 [D loss: 0.638099, acc.: 60.94%] [G loss: 0.905322]\n",
      "epoch:35 step:33007 [D loss: 0.643530, acc.: 60.94%] [G loss: 0.962069]\n",
      "epoch:35 step:33008 [D loss: 0.668129, acc.: 54.69%] [G loss: 0.929541]\n",
      "epoch:35 step:33009 [D loss: 0.695382, acc.: 60.16%] [G loss: 0.928285]\n",
      "epoch:35 step:33010 [D loss: 0.673772, acc.: 60.94%] [G loss: 0.950228]\n",
      "epoch:35 step:33011 [D loss: 0.707498, acc.: 50.00%] [G loss: 0.946634]\n",
      "epoch:35 step:33012 [D loss: 0.615120, acc.: 64.06%] [G loss: 0.878729]\n",
      "epoch:35 step:33013 [D loss: 0.705383, acc.: 56.25%] [G loss: 0.918730]\n",
      "epoch:35 step:33014 [D loss: 0.697948, acc.: 52.34%] [G loss: 0.932957]\n",
      "epoch:35 step:33015 [D loss: 0.648279, acc.: 61.72%] [G loss: 0.918448]\n",
      "epoch:35 step:33016 [D loss: 0.604937, acc.: 71.88%] [G loss: 0.941561]\n",
      "epoch:35 step:33017 [D loss: 0.656642, acc.: 63.28%] [G loss: 0.914104]\n",
      "epoch:35 step:33018 [D loss: 0.652118, acc.: 60.94%] [G loss: 0.956088]\n",
      "epoch:35 step:33019 [D loss: 0.634534, acc.: 61.72%] [G loss: 0.923849]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:33020 [D loss: 0.598703, acc.: 64.84%] [G loss: 0.963118]\n",
      "epoch:35 step:33021 [D loss: 0.675363, acc.: 60.94%] [G loss: 0.929753]\n",
      "epoch:35 step:33022 [D loss: 0.630599, acc.: 64.84%] [G loss: 0.929832]\n",
      "epoch:35 step:33023 [D loss: 0.640029, acc.: 64.06%] [G loss: 0.929607]\n",
      "epoch:35 step:33024 [D loss: 0.682659, acc.: 57.03%] [G loss: 0.893667]\n",
      "epoch:35 step:33025 [D loss: 0.672234, acc.: 59.38%] [G loss: 0.918167]\n",
      "epoch:35 step:33026 [D loss: 0.653349, acc.: 60.16%] [G loss: 1.005938]\n",
      "epoch:35 step:33027 [D loss: 0.666864, acc.: 58.59%] [G loss: 0.997679]\n",
      "epoch:35 step:33028 [D loss: 0.624513, acc.: 64.06%] [G loss: 0.987462]\n",
      "epoch:35 step:33029 [D loss: 0.692567, acc.: 52.34%] [G loss: 0.928596]\n",
      "epoch:35 step:33030 [D loss: 0.675566, acc.: 55.47%] [G loss: 0.912486]\n",
      "epoch:35 step:33031 [D loss: 0.629881, acc.: 62.50%] [G loss: 0.936628]\n",
      "epoch:35 step:33032 [D loss: 0.668993, acc.: 53.12%] [G loss: 0.957420]\n",
      "epoch:35 step:33033 [D loss: 0.653951, acc.: 60.94%] [G loss: 0.856639]\n",
      "epoch:35 step:33034 [D loss: 0.676347, acc.: 57.81%] [G loss: 0.871019]\n",
      "epoch:35 step:33035 [D loss: 0.635254, acc.: 65.62%] [G loss: 0.904549]\n",
      "epoch:35 step:33036 [D loss: 0.638913, acc.: 57.81%] [G loss: 0.944009]\n",
      "epoch:35 step:33037 [D loss: 0.617932, acc.: 67.19%] [G loss: 0.982561]\n",
      "epoch:35 step:33038 [D loss: 0.674810, acc.: 58.59%] [G loss: 0.911947]\n",
      "epoch:35 step:33039 [D loss: 0.694734, acc.: 53.12%] [G loss: 0.858669]\n",
      "epoch:35 step:33040 [D loss: 0.643433, acc.: 58.59%] [G loss: 0.902949]\n",
      "epoch:35 step:33041 [D loss: 0.634827, acc.: 60.94%] [G loss: 0.985818]\n",
      "epoch:35 step:33042 [D loss: 0.642181, acc.: 65.62%] [G loss: 0.909085]\n",
      "epoch:35 step:33043 [D loss: 0.620088, acc.: 63.28%] [G loss: 0.924028]\n",
      "epoch:35 step:33044 [D loss: 0.660894, acc.: 62.50%] [G loss: 0.927636]\n",
      "epoch:35 step:33045 [D loss: 0.649979, acc.: 59.38%] [G loss: 0.923843]\n",
      "epoch:35 step:33046 [D loss: 0.653796, acc.: 59.38%] [G loss: 0.930547]\n",
      "epoch:35 step:33047 [D loss: 0.672402, acc.: 62.50%] [G loss: 0.888683]\n",
      "epoch:35 step:33048 [D loss: 0.618726, acc.: 67.97%] [G loss: 0.975239]\n",
      "epoch:35 step:33049 [D loss: 0.660587, acc.: 60.16%] [G loss: 0.929868]\n",
      "epoch:35 step:33050 [D loss: 0.614552, acc.: 67.19%] [G loss: 0.900633]\n",
      "epoch:35 step:33051 [D loss: 0.653146, acc.: 62.50%] [G loss: 0.864742]\n",
      "epoch:35 step:33052 [D loss: 0.613986, acc.: 65.62%] [G loss: 0.920624]\n",
      "epoch:35 step:33053 [D loss: 0.619961, acc.: 64.84%] [G loss: 0.889476]\n",
      "epoch:35 step:33054 [D loss: 0.692357, acc.: 52.34%] [G loss: 0.947367]\n",
      "epoch:35 step:33055 [D loss: 0.659043, acc.: 57.81%] [G loss: 0.985888]\n",
      "epoch:35 step:33056 [D loss: 0.676409, acc.: 57.03%] [G loss: 0.874943]\n",
      "epoch:35 step:33057 [D loss: 0.683922, acc.: 55.47%] [G loss: 0.968135]\n",
      "epoch:35 step:33058 [D loss: 0.611487, acc.: 65.62%] [G loss: 0.916654]\n",
      "epoch:35 step:33059 [D loss: 0.609315, acc.: 63.28%] [G loss: 0.929294]\n",
      "epoch:35 step:33060 [D loss: 0.631340, acc.: 64.84%] [G loss: 0.984186]\n",
      "epoch:35 step:33061 [D loss: 0.628252, acc.: 62.50%] [G loss: 0.957182]\n",
      "epoch:35 step:33062 [D loss: 0.673820, acc.: 57.81%] [G loss: 0.985441]\n",
      "epoch:35 step:33063 [D loss: 0.647850, acc.: 60.16%] [G loss: 0.979224]\n",
      "epoch:35 step:33064 [D loss: 0.613260, acc.: 65.62%] [G loss: 0.979666]\n",
      "epoch:35 step:33065 [D loss: 0.657716, acc.: 57.81%] [G loss: 0.945846]\n",
      "epoch:35 step:33066 [D loss: 0.618059, acc.: 63.28%] [G loss: 0.919872]\n",
      "epoch:35 step:33067 [D loss: 0.627757, acc.: 59.38%] [G loss: 0.988761]\n",
      "epoch:35 step:33068 [D loss: 0.667880, acc.: 57.03%] [G loss: 0.949289]\n",
      "epoch:35 step:33069 [D loss: 0.632041, acc.: 61.72%] [G loss: 0.951817]\n",
      "epoch:35 step:33070 [D loss: 0.646346, acc.: 60.16%] [G loss: 0.874419]\n",
      "epoch:35 step:33071 [D loss: 0.677610, acc.: 60.94%] [G loss: 0.898060]\n",
      "epoch:35 step:33072 [D loss: 0.635376, acc.: 64.84%] [G loss: 0.932909]\n",
      "epoch:35 step:33073 [D loss: 0.627361, acc.: 63.28%] [G loss: 0.931197]\n",
      "epoch:35 step:33074 [D loss: 0.668231, acc.: 56.25%] [G loss: 0.938574]\n",
      "epoch:35 step:33075 [D loss: 0.672270, acc.: 64.06%] [G loss: 0.891393]\n",
      "epoch:35 step:33076 [D loss: 0.628594, acc.: 64.84%] [G loss: 0.898153]\n",
      "epoch:35 step:33077 [D loss: 0.626125, acc.: 64.84%] [G loss: 0.918746]\n",
      "epoch:35 step:33078 [D loss: 0.654068, acc.: 59.38%] [G loss: 0.887201]\n",
      "epoch:35 step:33079 [D loss: 0.631869, acc.: 63.28%] [G loss: 0.921580]\n",
      "epoch:35 step:33080 [D loss: 0.638628, acc.: 71.09%] [G loss: 0.936174]\n",
      "epoch:35 step:33081 [D loss: 0.646264, acc.: 60.94%] [G loss: 0.917802]\n",
      "epoch:35 step:33082 [D loss: 0.598029, acc.: 71.88%] [G loss: 0.900812]\n",
      "epoch:35 step:33083 [D loss: 0.616714, acc.: 66.41%] [G loss: 0.896642]\n",
      "epoch:35 step:33084 [D loss: 0.716278, acc.: 53.12%] [G loss: 0.839870]\n",
      "epoch:35 step:33085 [D loss: 0.638136, acc.: 58.59%] [G loss: 0.901160]\n",
      "epoch:35 step:33086 [D loss: 0.644386, acc.: 63.28%] [G loss: 0.902562]\n",
      "epoch:35 step:33087 [D loss: 0.648766, acc.: 63.28%] [G loss: 0.890232]\n",
      "epoch:35 step:33088 [D loss: 0.645224, acc.: 60.16%] [G loss: 0.824906]\n",
      "epoch:35 step:33089 [D loss: 0.654472, acc.: 59.38%] [G loss: 0.903214]\n",
      "epoch:35 step:33090 [D loss: 0.674428, acc.: 57.03%] [G loss: 0.876961]\n",
      "epoch:35 step:33091 [D loss: 0.656193, acc.: 59.38%] [G loss: 0.927051]\n",
      "epoch:35 step:33092 [D loss: 0.647911, acc.: 59.38%] [G loss: 0.920976]\n",
      "epoch:35 step:33093 [D loss: 0.652089, acc.: 60.94%] [G loss: 0.979970]\n",
      "epoch:35 step:33094 [D loss: 0.669959, acc.: 59.38%] [G loss: 1.015115]\n",
      "epoch:35 step:33095 [D loss: 0.623749, acc.: 66.41%] [G loss: 0.995640]\n",
      "epoch:35 step:33096 [D loss: 0.694295, acc.: 56.25%] [G loss: 0.942806]\n",
      "epoch:35 step:33097 [D loss: 0.638708, acc.: 62.50%] [G loss: 0.885660]\n",
      "epoch:35 step:33098 [D loss: 0.645416, acc.: 66.41%] [G loss: 0.922187]\n",
      "epoch:35 step:33099 [D loss: 0.668237, acc.: 57.81%] [G loss: 0.932205]\n",
      "epoch:35 step:33100 [D loss: 0.664190, acc.: 60.16%] [G loss: 0.882945]\n",
      "epoch:35 step:33101 [D loss: 0.644462, acc.: 69.53%] [G loss: 0.926889]\n",
      "epoch:35 step:33102 [D loss: 0.700200, acc.: 50.78%] [G loss: 0.871588]\n",
      "epoch:35 step:33103 [D loss: 0.661713, acc.: 58.59%] [G loss: 0.979877]\n",
      "epoch:35 step:33104 [D loss: 0.666140, acc.: 59.38%] [G loss: 0.885690]\n",
      "epoch:35 step:33105 [D loss: 0.663944, acc.: 58.59%] [G loss: 0.922137]\n",
      "epoch:35 step:33106 [D loss: 0.672835, acc.: 57.81%] [G loss: 0.984680]\n",
      "epoch:35 step:33107 [D loss: 0.643469, acc.: 58.59%] [G loss: 0.968924]\n",
      "epoch:35 step:33108 [D loss: 0.658248, acc.: 62.50%] [G loss: 0.954268]\n",
      "epoch:35 step:33109 [D loss: 0.610738, acc.: 64.06%] [G loss: 0.887083]\n",
      "epoch:35 step:33110 [D loss: 0.610326, acc.: 65.62%] [G loss: 0.908872]\n",
      "epoch:35 step:33111 [D loss: 0.641570, acc.: 60.16%] [G loss: 0.852965]\n",
      "epoch:35 step:33112 [D loss: 0.631777, acc.: 65.62%] [G loss: 0.833656]\n",
      "epoch:35 step:33113 [D loss: 0.674227, acc.: 56.25%] [G loss: 0.905890]\n",
      "epoch:35 step:33114 [D loss: 0.664729, acc.: 59.38%] [G loss: 0.928887]\n",
      "epoch:35 step:33115 [D loss: 0.643068, acc.: 55.47%] [G loss: 0.963638]\n",
      "epoch:35 step:33116 [D loss: 0.668245, acc.: 62.50%] [G loss: 0.979969]\n",
      "epoch:35 step:33117 [D loss: 0.664725, acc.: 60.94%] [G loss: 0.954497]\n",
      "epoch:35 step:33118 [D loss: 0.643954, acc.: 64.06%] [G loss: 0.919740]\n",
      "epoch:35 step:33119 [D loss: 0.644006, acc.: 60.94%] [G loss: 0.961737]\n",
      "epoch:35 step:33120 [D loss: 0.634774, acc.: 66.41%] [G loss: 0.971523]\n",
      "epoch:35 step:33121 [D loss: 0.713688, acc.: 49.22%] [G loss: 0.922768]\n",
      "epoch:35 step:33122 [D loss: 0.610219, acc.: 61.72%] [G loss: 0.917283]\n",
      "epoch:35 step:33123 [D loss: 0.654449, acc.: 60.94%] [G loss: 0.874279]\n",
      "epoch:35 step:33124 [D loss: 0.621446, acc.: 64.84%] [G loss: 0.961050]\n",
      "epoch:35 step:33125 [D loss: 0.624551, acc.: 67.19%] [G loss: 0.984505]\n",
      "epoch:35 step:33126 [D loss: 0.656692, acc.: 63.28%] [G loss: 0.945877]\n",
      "epoch:35 step:33127 [D loss: 0.635505, acc.: 63.28%] [G loss: 0.959504]\n",
      "epoch:35 step:33128 [D loss: 0.672735, acc.: 54.69%] [G loss: 0.991181]\n",
      "epoch:35 step:33129 [D loss: 0.631885, acc.: 62.50%] [G loss: 0.979568]\n",
      "epoch:35 step:33130 [D loss: 0.649546, acc.: 60.94%] [G loss: 0.901724]\n",
      "epoch:35 step:33131 [D loss: 0.595636, acc.: 72.66%] [G loss: 0.968856]\n",
      "epoch:35 step:33132 [D loss: 0.650213, acc.: 61.72%] [G loss: 0.914096]\n",
      "epoch:35 step:33133 [D loss: 0.637248, acc.: 61.72%] [G loss: 0.951997]\n",
      "epoch:35 step:33134 [D loss: 0.657204, acc.: 59.38%] [G loss: 0.937983]\n",
      "epoch:35 step:33135 [D loss: 0.698047, acc.: 55.47%] [G loss: 0.945471]\n",
      "epoch:35 step:33136 [D loss: 0.630157, acc.: 61.72%] [G loss: 0.940468]\n",
      "epoch:35 step:33137 [D loss: 0.638596, acc.: 61.72%] [G loss: 0.889304]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:33138 [D loss: 0.698975, acc.: 52.34%] [G loss: 0.881423]\n",
      "epoch:35 step:33139 [D loss: 0.654423, acc.: 59.38%] [G loss: 0.849007]\n",
      "epoch:35 step:33140 [D loss: 0.642235, acc.: 58.59%] [G loss: 0.929517]\n",
      "epoch:35 step:33141 [D loss: 0.640946, acc.: 61.72%] [G loss: 0.841749]\n",
      "epoch:35 step:33142 [D loss: 0.626956, acc.: 64.84%] [G loss: 0.954747]\n",
      "epoch:35 step:33143 [D loss: 0.639383, acc.: 61.72%] [G loss: 0.951628]\n",
      "epoch:35 step:33144 [D loss: 0.551584, acc.: 74.22%] [G loss: 0.979853]\n",
      "epoch:35 step:33145 [D loss: 0.689529, acc.: 59.38%] [G loss: 0.959677]\n",
      "epoch:35 step:33146 [D loss: 0.616506, acc.: 67.97%] [G loss: 0.900054]\n",
      "epoch:35 step:33147 [D loss: 0.672771, acc.: 61.72%] [G loss: 0.936091]\n",
      "epoch:35 step:33148 [D loss: 0.644525, acc.: 65.62%] [G loss: 0.968036]\n",
      "epoch:35 step:33149 [D loss: 0.678801, acc.: 57.03%] [G loss: 0.901480]\n",
      "epoch:35 step:33150 [D loss: 0.637208, acc.: 64.84%] [G loss: 0.922862]\n",
      "epoch:35 step:33151 [D loss: 0.578458, acc.: 70.31%] [G loss: 0.935444]\n",
      "epoch:35 step:33152 [D loss: 0.688756, acc.: 56.25%] [G loss: 0.883752]\n",
      "epoch:35 step:33153 [D loss: 0.615640, acc.: 66.41%] [G loss: 0.871161]\n",
      "epoch:35 step:33154 [D loss: 0.673933, acc.: 54.69%] [G loss: 0.879243]\n",
      "epoch:35 step:33155 [D loss: 0.604725, acc.: 64.06%] [G loss: 0.935948]\n",
      "epoch:35 step:33156 [D loss: 0.601578, acc.: 67.97%] [G loss: 0.965819]\n",
      "epoch:35 step:33157 [D loss: 0.614799, acc.: 64.06%] [G loss: 0.962080]\n",
      "epoch:35 step:33158 [D loss: 0.663274, acc.: 60.16%] [G loss: 0.935075]\n",
      "epoch:35 step:33159 [D loss: 0.651053, acc.: 63.28%] [G loss: 0.981594]\n",
      "epoch:35 step:33160 [D loss: 0.629497, acc.: 66.41%] [G loss: 0.929368]\n",
      "epoch:35 step:33161 [D loss: 0.665664, acc.: 59.38%] [G loss: 0.976606]\n",
      "epoch:35 step:33162 [D loss: 0.635103, acc.: 60.94%] [G loss: 1.026914]\n",
      "epoch:35 step:33163 [D loss: 0.673458, acc.: 53.12%] [G loss: 1.033476]\n",
      "epoch:35 step:33164 [D loss: 0.648287, acc.: 64.06%] [G loss: 0.902833]\n",
      "epoch:35 step:33165 [D loss: 0.629178, acc.: 60.16%] [G loss: 0.884812]\n",
      "epoch:35 step:33166 [D loss: 0.647887, acc.: 59.38%] [G loss: 0.855126]\n",
      "epoch:35 step:33167 [D loss: 0.647121, acc.: 60.16%] [G loss: 0.895941]\n",
      "epoch:35 step:33168 [D loss: 0.623924, acc.: 68.75%] [G loss: 0.912547]\n",
      "epoch:35 step:33169 [D loss: 0.664136, acc.: 60.94%] [G loss: 0.932749]\n",
      "epoch:35 step:33170 [D loss: 0.612398, acc.: 68.75%] [G loss: 0.912720]\n",
      "epoch:35 step:33171 [D loss: 0.651687, acc.: 64.06%] [G loss: 0.982180]\n",
      "epoch:35 step:33172 [D loss: 0.642040, acc.: 60.94%] [G loss: 0.933726]\n",
      "epoch:35 step:33173 [D loss: 0.582422, acc.: 71.09%] [G loss: 0.937251]\n",
      "epoch:35 step:33174 [D loss: 0.652337, acc.: 62.50%] [G loss: 0.930539]\n",
      "epoch:35 step:33175 [D loss: 0.618948, acc.: 67.19%] [G loss: 0.977867]\n",
      "epoch:35 step:33176 [D loss: 0.641583, acc.: 60.94%] [G loss: 0.978409]\n",
      "epoch:35 step:33177 [D loss: 0.631044, acc.: 63.28%] [G loss: 0.875574]\n",
      "epoch:35 step:33178 [D loss: 0.615100, acc.: 70.31%] [G loss: 0.950881]\n",
      "epoch:35 step:33179 [D loss: 0.634120, acc.: 61.72%] [G loss: 0.924743]\n",
      "epoch:35 step:33180 [D loss: 0.662111, acc.: 60.16%] [G loss: 0.935344]\n",
      "epoch:35 step:33181 [D loss: 0.622496, acc.: 64.06%] [G loss: 0.914827]\n",
      "epoch:35 step:33182 [D loss: 0.639996, acc.: 62.50%] [G loss: 0.897679]\n",
      "epoch:35 step:33183 [D loss: 0.659230, acc.: 63.28%] [G loss: 0.985160]\n",
      "epoch:35 step:33184 [D loss: 0.587315, acc.: 71.09%] [G loss: 0.965516]\n",
      "epoch:35 step:33185 [D loss: 0.647553, acc.: 67.19%] [G loss: 0.921964]\n",
      "epoch:35 step:33186 [D loss: 0.607398, acc.: 64.84%] [G loss: 0.958790]\n",
      "epoch:35 step:33187 [D loss: 0.617865, acc.: 68.75%] [G loss: 1.026731]\n",
      "epoch:35 step:33188 [D loss: 0.693355, acc.: 50.78%] [G loss: 0.974878]\n",
      "epoch:35 step:33189 [D loss: 0.614927, acc.: 67.97%] [G loss: 1.016395]\n",
      "epoch:35 step:33190 [D loss: 0.666641, acc.: 55.47%] [G loss: 0.917423]\n",
      "epoch:35 step:33191 [D loss: 0.605753, acc.: 68.75%] [G loss: 0.936956]\n",
      "epoch:35 step:33192 [D loss: 0.625266, acc.: 62.50%] [G loss: 0.887263]\n",
      "epoch:35 step:33193 [D loss: 0.693068, acc.: 52.34%] [G loss: 0.905498]\n",
      "epoch:35 step:33194 [D loss: 0.644632, acc.: 57.81%] [G loss: 0.925341]\n",
      "epoch:35 step:33195 [D loss: 0.610947, acc.: 63.28%] [G loss: 0.902787]\n",
      "epoch:35 step:33196 [D loss: 0.600532, acc.: 67.19%] [G loss: 0.958667]\n",
      "epoch:35 step:33197 [D loss: 0.645208, acc.: 58.59%] [G loss: 1.002470]\n",
      "epoch:35 step:33198 [D loss: 0.622963, acc.: 62.50%] [G loss: 0.955019]\n",
      "epoch:35 step:33199 [D loss: 0.652134, acc.: 57.03%] [G loss: 0.948014]\n",
      "epoch:35 step:33200 [D loss: 0.650215, acc.: 61.72%] [G loss: 0.999111]\n",
      "##############\n",
      "[2.83965435 2.04124802 2.10107048 3.88867003 1.05143041 6.33308391\n",
      " 2.76450758 3.44393727 4.24127147 7.14868929]\n",
      "##########\n",
      "epoch:35 step:33201 [D loss: 0.619944, acc.: 69.53%] [G loss: 0.984869]\n",
      "epoch:35 step:33202 [D loss: 0.636416, acc.: 62.50%] [G loss: 0.965941]\n",
      "epoch:35 step:33203 [D loss: 0.682072, acc.: 59.38%] [G loss: 1.004588]\n",
      "epoch:35 step:33204 [D loss: 0.655924, acc.: 60.94%] [G loss: 1.033246]\n",
      "epoch:35 step:33205 [D loss: 0.633192, acc.: 64.06%] [G loss: 0.949289]\n",
      "epoch:35 step:33206 [D loss: 0.631574, acc.: 60.94%] [G loss: 0.986002]\n",
      "epoch:35 step:33207 [D loss: 0.635966, acc.: 62.50%] [G loss: 0.935667]\n",
      "epoch:35 step:33208 [D loss: 0.646277, acc.: 60.16%] [G loss: 0.962724]\n",
      "epoch:35 step:33209 [D loss: 0.663624, acc.: 54.69%] [G loss: 0.977906]\n",
      "epoch:35 step:33210 [D loss: 0.605431, acc.: 70.31%] [G loss: 0.940816]\n",
      "epoch:35 step:33211 [D loss: 0.622836, acc.: 66.41%] [G loss: 0.900298]\n",
      "epoch:35 step:33212 [D loss: 0.606619, acc.: 71.09%] [G loss: 1.001870]\n",
      "epoch:35 step:33213 [D loss: 0.689293, acc.: 50.00%] [G loss: 0.945676]\n",
      "epoch:35 step:33214 [D loss: 0.646714, acc.: 62.50%] [G loss: 0.939991]\n",
      "epoch:35 step:33215 [D loss: 0.604119, acc.: 68.75%] [G loss: 0.924590]\n",
      "epoch:35 step:33216 [D loss: 0.661936, acc.: 58.59%] [G loss: 0.870493]\n",
      "epoch:35 step:33217 [D loss: 0.650203, acc.: 59.38%] [G loss: 0.887493]\n",
      "epoch:35 step:33218 [D loss: 0.663898, acc.: 57.03%] [G loss: 0.863240]\n",
      "epoch:35 step:33219 [D loss: 0.664596, acc.: 60.16%] [G loss: 0.917804]\n",
      "epoch:35 step:33220 [D loss: 0.677058, acc.: 57.03%] [G loss: 0.915710]\n",
      "epoch:35 step:33221 [D loss: 0.673200, acc.: 61.72%] [G loss: 0.952561]\n",
      "epoch:35 step:33222 [D loss: 0.631972, acc.: 67.97%] [G loss: 1.069793]\n",
      "epoch:35 step:33223 [D loss: 0.663508, acc.: 61.72%] [G loss: 0.978317]\n",
      "epoch:35 step:33224 [D loss: 0.656285, acc.: 63.28%] [G loss: 0.942579]\n",
      "epoch:35 step:33225 [D loss: 0.655545, acc.: 61.72%] [G loss: 0.920155]\n",
      "epoch:35 step:33226 [D loss: 0.632353, acc.: 65.62%] [G loss: 0.904864]\n",
      "epoch:35 step:33227 [D loss: 0.636072, acc.: 64.06%] [G loss: 0.922775]\n",
      "epoch:35 step:33228 [D loss: 0.656595, acc.: 64.06%] [G loss: 0.884089]\n",
      "epoch:35 step:33229 [D loss: 0.660596, acc.: 61.72%] [G loss: 0.905652]\n",
      "epoch:35 step:33230 [D loss: 0.648593, acc.: 63.28%] [G loss: 0.940740]\n",
      "epoch:35 step:33231 [D loss: 0.619316, acc.: 71.88%] [G loss: 0.833816]\n",
      "epoch:35 step:33232 [D loss: 0.681581, acc.: 54.69%] [G loss: 0.832119]\n",
      "epoch:35 step:33233 [D loss: 0.714816, acc.: 54.69%] [G loss: 0.931030]\n",
      "epoch:35 step:33234 [D loss: 0.658698, acc.: 59.38%] [G loss: 0.924266]\n",
      "epoch:35 step:33235 [D loss: 0.615183, acc.: 67.97%] [G loss: 0.945865]\n",
      "epoch:35 step:33236 [D loss: 0.635076, acc.: 62.50%] [G loss: 0.887823]\n",
      "epoch:35 step:33237 [D loss: 0.664855, acc.: 59.38%] [G loss: 0.870064]\n",
      "epoch:35 step:33238 [D loss: 0.622358, acc.: 64.84%] [G loss: 0.855441]\n",
      "epoch:35 step:33239 [D loss: 0.646672, acc.: 60.16%] [G loss: 0.915874]\n",
      "epoch:35 step:33240 [D loss: 0.611808, acc.: 71.09%] [G loss: 0.936524]\n",
      "epoch:35 step:33241 [D loss: 0.660991, acc.: 58.59%] [G loss: 0.921714]\n",
      "epoch:35 step:33242 [D loss: 0.622078, acc.: 64.06%] [G loss: 0.897772]\n",
      "epoch:35 step:33243 [D loss: 0.671158, acc.: 58.59%] [G loss: 0.888898]\n",
      "epoch:35 step:33244 [D loss: 0.621827, acc.: 62.50%] [G loss: 0.877945]\n",
      "epoch:35 step:33245 [D loss: 0.661453, acc.: 59.38%] [G loss: 0.987453]\n",
      "epoch:35 step:33246 [D loss: 0.624293, acc.: 62.50%] [G loss: 0.925023]\n",
      "epoch:35 step:33247 [D loss: 0.614428, acc.: 64.84%] [G loss: 0.903342]\n",
      "epoch:35 step:33248 [D loss: 0.644911, acc.: 61.72%] [G loss: 0.889883]\n",
      "epoch:35 step:33249 [D loss: 0.645210, acc.: 61.72%] [G loss: 0.928261]\n",
      "epoch:35 step:33250 [D loss: 0.613640, acc.: 67.97%] [G loss: 0.872879]\n",
      "epoch:35 step:33251 [D loss: 0.650413, acc.: 61.72%] [G loss: 0.898342]\n",
      "epoch:35 step:33252 [D loss: 0.639857, acc.: 61.72%] [G loss: 0.935520]\n",
      "epoch:35 step:33253 [D loss: 0.615076, acc.: 67.97%] [G loss: 0.925968]\n",
      "epoch:35 step:33254 [D loss: 0.608160, acc.: 58.59%] [G loss: 0.868903]\n",
      "epoch:35 step:33255 [D loss: 0.629905, acc.: 58.59%] [G loss: 0.933933]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:33256 [D loss: 0.634733, acc.: 63.28%] [G loss: 0.902819]\n",
      "epoch:35 step:33257 [D loss: 0.674263, acc.: 54.69%] [G loss: 0.998157]\n",
      "epoch:35 step:33258 [D loss: 0.644248, acc.: 66.41%] [G loss: 0.944989]\n",
      "epoch:35 step:33259 [D loss: 0.677884, acc.: 51.56%] [G loss: 0.900125]\n",
      "epoch:35 step:33260 [D loss: 0.627214, acc.: 64.84%] [G loss: 0.932616]\n",
      "epoch:35 step:33261 [D loss: 0.637542, acc.: 68.75%] [G loss: 0.957799]\n",
      "epoch:35 step:33262 [D loss: 0.608920, acc.: 65.62%] [G loss: 0.991713]\n",
      "epoch:35 step:33263 [D loss: 0.625455, acc.: 60.16%] [G loss: 0.967478]\n",
      "epoch:35 step:33264 [D loss: 0.599836, acc.: 67.19%] [G loss: 0.955184]\n",
      "epoch:35 step:33265 [D loss: 0.716190, acc.: 50.78%] [G loss: 0.872658]\n",
      "epoch:35 step:33266 [D loss: 0.647061, acc.: 62.50%] [G loss: 0.948867]\n",
      "epoch:35 step:33267 [D loss: 0.591513, acc.: 70.31%] [G loss: 0.946596]\n",
      "epoch:35 step:33268 [D loss: 0.611412, acc.: 67.19%] [G loss: 0.879760]\n",
      "epoch:35 step:33269 [D loss: 0.617231, acc.: 63.28%] [G loss: 0.876874]\n",
      "epoch:35 step:33270 [D loss: 0.645681, acc.: 60.94%] [G loss: 0.938320]\n",
      "epoch:35 step:33271 [D loss: 0.642154, acc.: 59.38%] [G loss: 0.941021]\n",
      "epoch:35 step:33272 [D loss: 0.701020, acc.: 53.91%] [G loss: 0.958582]\n",
      "epoch:35 step:33273 [D loss: 0.629143, acc.: 67.19%] [G loss: 0.935632]\n",
      "epoch:35 step:33274 [D loss: 0.674128, acc.: 55.47%] [G loss: 0.985580]\n",
      "epoch:35 step:33275 [D loss: 0.652936, acc.: 57.81%] [G loss: 0.920717]\n",
      "epoch:35 step:33276 [D loss: 0.614285, acc.: 70.31%] [G loss: 0.941928]\n",
      "epoch:35 step:33277 [D loss: 0.632949, acc.: 69.53%] [G loss: 0.854002]\n",
      "epoch:35 step:33278 [D loss: 0.674860, acc.: 60.94%] [G loss: 0.881336]\n",
      "epoch:35 step:33279 [D loss: 0.618723, acc.: 63.28%] [G loss: 0.929934]\n",
      "epoch:35 step:33280 [D loss: 0.630392, acc.: 66.41%] [G loss: 0.873931]\n",
      "epoch:35 step:33281 [D loss: 0.623107, acc.: 64.84%] [G loss: 0.891757]\n",
      "epoch:35 step:33282 [D loss: 0.620031, acc.: 64.84%] [G loss: 0.817174]\n",
      "epoch:35 step:33283 [D loss: 0.647608, acc.: 62.50%] [G loss: 0.922315]\n",
      "epoch:35 step:33284 [D loss: 0.594320, acc.: 71.09%] [G loss: 0.949503]\n",
      "epoch:35 step:33285 [D loss: 0.649210, acc.: 62.50%] [G loss: 0.996053]\n",
      "epoch:35 step:33286 [D loss: 0.659660, acc.: 58.59%] [G loss: 0.938459]\n",
      "epoch:35 step:33287 [D loss: 0.653184, acc.: 63.28%] [G loss: 0.945406]\n",
      "epoch:35 step:33288 [D loss: 0.653448, acc.: 53.91%] [G loss: 0.992872]\n",
      "epoch:35 step:33289 [D loss: 0.641653, acc.: 64.06%] [G loss: 0.948601]\n",
      "epoch:35 step:33290 [D loss: 0.632460, acc.: 62.50%] [G loss: 0.961050]\n",
      "epoch:35 step:33291 [D loss: 0.644298, acc.: 59.38%] [G loss: 0.969732]\n",
      "epoch:35 step:33292 [D loss: 0.644056, acc.: 60.94%] [G loss: 0.954910]\n",
      "epoch:35 step:33293 [D loss: 0.653313, acc.: 58.59%] [G loss: 0.924653]\n",
      "epoch:35 step:33294 [D loss: 0.620587, acc.: 66.41%] [G loss: 0.948728]\n",
      "epoch:35 step:33295 [D loss: 0.674504, acc.: 60.94%] [G loss: 0.906978]\n",
      "epoch:35 step:33296 [D loss: 0.659587, acc.: 57.03%] [G loss: 0.966483]\n",
      "epoch:35 step:33297 [D loss: 0.654737, acc.: 59.38%] [G loss: 0.938024]\n",
      "epoch:35 step:33298 [D loss: 0.677735, acc.: 55.47%] [G loss: 0.974236]\n",
      "epoch:35 step:33299 [D loss: 0.662796, acc.: 60.16%] [G loss: 0.975306]\n",
      "epoch:35 step:33300 [D loss: 0.645301, acc.: 66.41%] [G loss: 0.946574]\n",
      "epoch:35 step:33301 [D loss: 0.653120, acc.: 59.38%] [G loss: 0.911939]\n",
      "epoch:35 step:33302 [D loss: 0.676846, acc.: 56.25%] [G loss: 0.907521]\n",
      "epoch:35 step:33303 [D loss: 0.641266, acc.: 60.16%] [G loss: 0.930643]\n",
      "epoch:35 step:33304 [D loss: 0.657805, acc.: 57.03%] [G loss: 0.921150]\n",
      "epoch:35 step:33305 [D loss: 0.626943, acc.: 64.06%] [G loss: 0.869679]\n",
      "epoch:35 step:33306 [D loss: 0.616973, acc.: 64.84%] [G loss: 0.999220]\n",
      "epoch:35 step:33307 [D loss: 0.655387, acc.: 62.50%] [G loss: 0.967625]\n",
      "epoch:35 step:33308 [D loss: 0.662546, acc.: 59.38%] [G loss: 1.054950]\n",
      "epoch:35 step:33309 [D loss: 0.637750, acc.: 65.62%] [G loss: 0.996995]\n",
      "epoch:35 step:33310 [D loss: 0.649863, acc.: 64.84%] [G loss: 0.881701]\n",
      "epoch:35 step:33311 [D loss: 0.666221, acc.: 58.59%] [G loss: 0.920161]\n",
      "epoch:35 step:33312 [D loss: 0.639772, acc.: 64.84%] [G loss: 0.871118]\n",
      "epoch:35 step:33313 [D loss: 0.644082, acc.: 59.38%] [G loss: 0.869172]\n",
      "epoch:35 step:33314 [D loss: 0.625908, acc.: 67.19%] [G loss: 0.843118]\n",
      "epoch:35 step:33315 [D loss: 0.637615, acc.: 67.19%] [G loss: 0.897480]\n",
      "epoch:35 step:33316 [D loss: 0.624474, acc.: 63.28%] [G loss: 0.908251]\n",
      "epoch:35 step:33317 [D loss: 0.612602, acc.: 67.97%] [G loss: 0.966679]\n",
      "epoch:35 step:33318 [D loss: 0.655056, acc.: 63.28%] [G loss: 0.992012]\n",
      "epoch:35 step:33319 [D loss: 0.619706, acc.: 64.84%] [G loss: 0.995397]\n",
      "epoch:35 step:33320 [D loss: 0.689778, acc.: 58.59%] [G loss: 0.963483]\n",
      "epoch:35 step:33321 [D loss: 0.666766, acc.: 55.47%] [G loss: 0.960380]\n",
      "epoch:35 step:33322 [D loss: 0.620463, acc.: 68.75%] [G loss: 0.925763]\n",
      "epoch:35 step:33323 [D loss: 0.626307, acc.: 60.94%] [G loss: 0.957518]\n",
      "epoch:35 step:33324 [D loss: 0.632039, acc.: 65.62%] [G loss: 0.944154]\n",
      "epoch:35 step:33325 [D loss: 0.673513, acc.: 56.25%] [G loss: 0.930856]\n",
      "epoch:35 step:33326 [D loss: 0.641828, acc.: 64.06%] [G loss: 0.883923]\n",
      "epoch:35 step:33327 [D loss: 0.648284, acc.: 66.41%] [G loss: 0.902104]\n",
      "epoch:35 step:33328 [D loss: 0.646213, acc.: 56.25%] [G loss: 0.964179]\n",
      "epoch:35 step:33329 [D loss: 0.676443, acc.: 58.59%] [G loss: 0.945227]\n",
      "epoch:35 step:33330 [D loss: 0.598000, acc.: 67.19%] [G loss: 0.906616]\n",
      "epoch:35 step:33331 [D loss: 0.672502, acc.: 53.91%] [G loss: 0.945730]\n",
      "epoch:35 step:33332 [D loss: 0.671199, acc.: 62.50%] [G loss: 0.900533]\n",
      "epoch:35 step:33333 [D loss: 0.666030, acc.: 64.06%] [G loss: 0.911839]\n",
      "epoch:35 step:33334 [D loss: 0.645155, acc.: 60.16%] [G loss: 0.921542]\n",
      "epoch:35 step:33335 [D loss: 0.646128, acc.: 60.16%] [G loss: 0.949449]\n",
      "epoch:35 step:33336 [D loss: 0.627201, acc.: 65.62%] [G loss: 0.947214]\n",
      "epoch:35 step:33337 [D loss: 0.652217, acc.: 61.72%] [G loss: 0.894902]\n",
      "epoch:35 step:33338 [D loss: 0.603563, acc.: 65.62%] [G loss: 0.956521]\n",
      "epoch:35 step:33339 [D loss: 0.639450, acc.: 60.16%] [G loss: 0.931815]\n",
      "epoch:35 step:33340 [D loss: 0.593941, acc.: 68.75%] [G loss: 0.924845]\n",
      "epoch:35 step:33341 [D loss: 0.648516, acc.: 63.28%] [G loss: 0.922288]\n",
      "epoch:35 step:33342 [D loss: 0.676846, acc.: 59.38%] [G loss: 0.971142]\n",
      "epoch:35 step:33343 [D loss: 0.669041, acc.: 58.59%] [G loss: 0.909663]\n",
      "epoch:35 step:33344 [D loss: 0.641269, acc.: 58.59%] [G loss: 0.904529]\n",
      "epoch:35 step:33345 [D loss: 0.646898, acc.: 63.28%] [G loss: 0.995431]\n",
      "epoch:35 step:33346 [D loss: 0.645739, acc.: 64.06%] [G loss: 1.020163]\n",
      "epoch:35 step:33347 [D loss: 0.674368, acc.: 60.16%] [G loss: 0.999003]\n",
      "epoch:35 step:33348 [D loss: 0.611967, acc.: 67.97%] [G loss: 1.034450]\n",
      "epoch:35 step:33349 [D loss: 0.667391, acc.: 61.72%] [G loss: 1.013155]\n",
      "epoch:35 step:33350 [D loss: 0.681546, acc.: 60.94%] [G loss: 0.917361]\n",
      "epoch:35 step:33351 [D loss: 0.659076, acc.: 59.38%] [G loss: 0.913132]\n",
      "epoch:35 step:33352 [D loss: 0.652903, acc.: 62.50%] [G loss: 0.848858]\n",
      "epoch:35 step:33353 [D loss: 0.652453, acc.: 61.72%] [G loss: 0.884748]\n",
      "epoch:35 step:33354 [D loss: 0.662634, acc.: 64.84%] [G loss: 0.866287]\n",
      "epoch:35 step:33355 [D loss: 0.670228, acc.: 58.59%] [G loss: 0.850838]\n",
      "epoch:35 step:33356 [D loss: 0.677930, acc.: 54.69%] [G loss: 0.917199]\n",
      "epoch:35 step:33357 [D loss: 0.608799, acc.: 71.88%] [G loss: 0.912526]\n",
      "epoch:35 step:33358 [D loss: 0.669966, acc.: 51.56%] [G loss: 0.914734]\n",
      "epoch:35 step:33359 [D loss: 0.607368, acc.: 67.97%] [G loss: 0.906906]\n",
      "epoch:35 step:33360 [D loss: 0.646641, acc.: 60.16%] [G loss: 0.908785]\n",
      "epoch:35 step:33361 [D loss: 0.604588, acc.: 70.31%] [G loss: 0.888236]\n",
      "epoch:35 step:33362 [D loss: 0.612090, acc.: 66.41%] [G loss: 0.896491]\n",
      "epoch:35 step:33363 [D loss: 0.700529, acc.: 55.47%] [G loss: 0.971318]\n",
      "epoch:35 step:33364 [D loss: 0.610374, acc.: 64.06%] [G loss: 0.981581]\n",
      "epoch:35 step:33365 [D loss: 0.673731, acc.: 60.16%] [G loss: 0.994193]\n",
      "epoch:35 step:33366 [D loss: 0.642901, acc.: 63.28%] [G loss: 0.957700]\n",
      "epoch:35 step:33367 [D loss: 0.665548, acc.: 63.28%] [G loss: 0.952549]\n",
      "epoch:35 step:33368 [D loss: 0.639706, acc.: 65.62%] [G loss: 0.962648]\n",
      "epoch:35 step:33369 [D loss: 0.643609, acc.: 60.16%] [G loss: 0.966967]\n",
      "epoch:35 step:33370 [D loss: 0.637753, acc.: 60.16%] [G loss: 0.972134]\n",
      "epoch:35 step:33371 [D loss: 0.608470, acc.: 67.97%] [G loss: 0.989276]\n",
      "epoch:35 step:33372 [D loss: 0.597889, acc.: 73.44%] [G loss: 0.995002]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:33373 [D loss: 0.670591, acc.: 54.69%] [G loss: 0.985465]\n",
      "epoch:35 step:33374 [D loss: 0.656431, acc.: 58.59%] [G loss: 0.929244]\n",
      "epoch:35 step:33375 [D loss: 0.622747, acc.: 65.62%] [G loss: 0.998093]\n",
      "epoch:35 step:33376 [D loss: 0.622980, acc.: 58.59%] [G loss: 0.909659]\n",
      "epoch:35 step:33377 [D loss: 0.600883, acc.: 67.97%] [G loss: 0.928296]\n",
      "epoch:35 step:33378 [D loss: 0.675559, acc.: 53.91%] [G loss: 0.903350]\n",
      "epoch:35 step:33379 [D loss: 0.638090, acc.: 67.19%] [G loss: 0.858159]\n",
      "epoch:35 step:33380 [D loss: 0.673531, acc.: 60.94%] [G loss: 0.943988]\n",
      "epoch:35 step:33381 [D loss: 0.646738, acc.: 60.94%] [G loss: 0.986387]\n",
      "epoch:35 step:33382 [D loss: 0.654738, acc.: 62.50%] [G loss: 0.977773]\n",
      "epoch:35 step:33383 [D loss: 0.682341, acc.: 58.59%] [G loss: 0.964806]\n",
      "epoch:35 step:33384 [D loss: 0.624122, acc.: 70.31%] [G loss: 0.950308]\n",
      "epoch:35 step:33385 [D loss: 0.611931, acc.: 69.53%] [G loss: 0.956951]\n",
      "epoch:35 step:33386 [D loss: 0.645999, acc.: 65.62%] [G loss: 0.955973]\n",
      "epoch:35 step:33387 [D loss: 0.636474, acc.: 63.28%] [G loss: 0.921665]\n",
      "epoch:35 step:33388 [D loss: 0.624110, acc.: 60.94%] [G loss: 0.944876]\n",
      "epoch:35 step:33389 [D loss: 0.593515, acc.: 67.97%] [G loss: 0.945342]\n",
      "epoch:35 step:33390 [D loss: 0.683985, acc.: 54.69%] [G loss: 0.914405]\n",
      "epoch:35 step:33391 [D loss: 0.638183, acc.: 64.84%] [G loss: 0.920728]\n",
      "epoch:35 step:33392 [D loss: 0.632029, acc.: 65.62%] [G loss: 0.944184]\n",
      "epoch:35 step:33393 [D loss: 0.630625, acc.: 60.94%] [G loss: 0.965239]\n",
      "epoch:35 step:33394 [D loss: 0.618579, acc.: 67.19%] [G loss: 1.033106]\n",
      "epoch:35 step:33395 [D loss: 0.594117, acc.: 67.19%] [G loss: 1.003656]\n",
      "epoch:35 step:33396 [D loss: 0.617211, acc.: 65.62%] [G loss: 1.018920]\n",
      "epoch:35 step:33397 [D loss: 0.629261, acc.: 57.03%] [G loss: 0.950230]\n",
      "epoch:35 step:33398 [D loss: 0.656980, acc.: 60.94%] [G loss: 0.977456]\n",
      "epoch:35 step:33399 [D loss: 0.646723, acc.: 57.81%] [G loss: 0.897102]\n",
      "epoch:35 step:33400 [D loss: 0.678519, acc.: 48.44%] [G loss: 0.874283]\n",
      "##############\n",
      "[3.0790535  2.63377995 2.33774023 3.91661643 1.30599717 7.79348874\n",
      " 2.76872659 3.31981004 4.20349397 7.14868929]\n",
      "##########\n",
      "epoch:35 step:33401 [D loss: 0.634891, acc.: 63.28%] [G loss: 0.920943]\n",
      "epoch:35 step:33402 [D loss: 0.668725, acc.: 57.81%] [G loss: 0.978379]\n",
      "epoch:35 step:33403 [D loss: 0.643946, acc.: 59.38%] [G loss: 0.872669]\n",
      "epoch:35 step:33404 [D loss: 0.623414, acc.: 67.19%] [G loss: 0.890164]\n",
      "epoch:35 step:33405 [D loss: 0.637473, acc.: 64.06%] [G loss: 0.882691]\n",
      "epoch:35 step:33406 [D loss: 0.626366, acc.: 67.97%] [G loss: 0.910672]\n",
      "epoch:35 step:33407 [D loss: 0.655093, acc.: 58.59%] [G loss: 0.942841]\n",
      "epoch:35 step:33408 [D loss: 0.626324, acc.: 61.72%] [G loss: 0.988585]\n",
      "epoch:35 step:33409 [D loss: 0.620124, acc.: 64.06%] [G loss: 1.011704]\n",
      "epoch:35 step:33410 [D loss: 0.656959, acc.: 59.38%] [G loss: 1.026089]\n",
      "epoch:35 step:33411 [D loss: 0.613178, acc.: 69.53%] [G loss: 0.900610]\n",
      "epoch:35 step:33412 [D loss: 0.652157, acc.: 57.81%] [G loss: 0.934490]\n",
      "epoch:35 step:33413 [D loss: 0.611415, acc.: 64.84%] [G loss: 0.933568]\n",
      "epoch:35 step:33414 [D loss: 0.660422, acc.: 60.94%] [G loss: 0.937585]\n",
      "epoch:35 step:33415 [D loss: 0.659379, acc.: 59.38%] [G loss: 0.894227]\n",
      "epoch:35 step:33416 [D loss: 0.650395, acc.: 57.03%] [G loss: 0.906953]\n",
      "epoch:35 step:33417 [D loss: 0.605122, acc.: 69.53%] [G loss: 0.909453]\n",
      "epoch:35 step:33418 [D loss: 0.598999, acc.: 65.62%] [G loss: 0.903215]\n",
      "epoch:35 step:33419 [D loss: 0.622282, acc.: 63.28%] [G loss: 0.920935]\n",
      "epoch:35 step:33420 [D loss: 0.638281, acc.: 67.19%] [G loss: 0.960577]\n",
      "epoch:35 step:33421 [D loss: 0.695048, acc.: 58.59%] [G loss: 0.943047]\n",
      "epoch:35 step:33422 [D loss: 0.641769, acc.: 64.84%] [G loss: 0.904314]\n",
      "epoch:35 step:33423 [D loss: 0.652988, acc.: 64.84%] [G loss: 1.015928]\n",
      "epoch:35 step:33424 [D loss: 0.659134, acc.: 61.72%] [G loss: 0.951832]\n",
      "epoch:35 step:33425 [D loss: 0.632230, acc.: 64.84%] [G loss: 0.862875]\n",
      "epoch:35 step:33426 [D loss: 0.590121, acc.: 71.09%] [G loss: 0.929449]\n",
      "epoch:35 step:33427 [D loss: 0.672875, acc.: 56.25%] [G loss: 0.883955]\n",
      "epoch:35 step:33428 [D loss: 0.666060, acc.: 64.84%] [G loss: 0.879028]\n",
      "epoch:35 step:33429 [D loss: 0.656681, acc.: 60.16%] [G loss: 0.959511]\n",
      "epoch:35 step:33430 [D loss: 0.675323, acc.: 63.28%] [G loss: 0.928453]\n",
      "epoch:35 step:33431 [D loss: 0.644180, acc.: 57.81%] [G loss: 0.887309]\n",
      "epoch:35 step:33432 [D loss: 0.643809, acc.: 62.50%] [G loss: 0.944228]\n",
      "epoch:35 step:33433 [D loss: 0.609007, acc.: 66.41%] [G loss: 0.990811]\n",
      "epoch:35 step:33434 [D loss: 0.663607, acc.: 56.25%] [G loss: 0.934280]\n",
      "epoch:35 step:33435 [D loss: 0.651952, acc.: 59.38%] [G loss: 0.864924]\n",
      "epoch:35 step:33436 [D loss: 0.659313, acc.: 60.94%] [G loss: 0.965686]\n",
      "epoch:35 step:33437 [D loss: 0.643128, acc.: 65.62%] [G loss: 0.949354]\n",
      "epoch:35 step:33438 [D loss: 0.691276, acc.: 60.94%] [G loss: 0.886719]\n",
      "epoch:35 step:33439 [D loss: 0.651257, acc.: 60.16%] [G loss: 0.877289]\n",
      "epoch:35 step:33440 [D loss: 0.648543, acc.: 64.06%] [G loss: 0.969884]\n",
      "epoch:35 step:33441 [D loss: 0.675524, acc.: 58.59%] [G loss: 0.890417]\n",
      "epoch:35 step:33442 [D loss: 0.672617, acc.: 64.84%] [G loss: 0.971976]\n",
      "epoch:35 step:33443 [D loss: 0.622870, acc.: 64.06%] [G loss: 0.927921]\n",
      "epoch:35 step:33444 [D loss: 0.668757, acc.: 59.38%] [G loss: 0.980887]\n",
      "epoch:35 step:33445 [D loss: 0.621371, acc.: 70.31%] [G loss: 1.000389]\n",
      "epoch:35 step:33446 [D loss: 0.633025, acc.: 60.16%] [G loss: 0.912613]\n",
      "epoch:35 step:33447 [D loss: 0.648246, acc.: 58.59%] [G loss: 0.891731]\n",
      "epoch:35 step:33448 [D loss: 0.618019, acc.: 65.62%] [G loss: 0.901850]\n",
      "epoch:35 step:33449 [D loss: 0.661372, acc.: 62.50%] [G loss: 0.841749]\n",
      "epoch:35 step:33450 [D loss: 0.690557, acc.: 54.69%] [G loss: 0.920922]\n",
      "epoch:35 step:33451 [D loss: 0.640399, acc.: 61.72%] [G loss: 0.965692]\n",
      "epoch:35 step:33452 [D loss: 0.684097, acc.: 56.25%] [G loss: 0.955638]\n",
      "epoch:35 step:33453 [D loss: 0.683378, acc.: 57.03%] [G loss: 0.979277]\n",
      "epoch:35 step:33454 [D loss: 0.647092, acc.: 65.62%] [G loss: 0.940416]\n",
      "epoch:35 step:33455 [D loss: 0.647652, acc.: 60.16%] [G loss: 0.974592]\n",
      "epoch:35 step:33456 [D loss: 0.660244, acc.: 62.50%] [G loss: 0.914155]\n",
      "epoch:35 step:33457 [D loss: 0.660970, acc.: 60.16%] [G loss: 0.924396]\n",
      "epoch:35 step:33458 [D loss: 0.654980, acc.: 61.72%] [G loss: 0.903457]\n",
      "epoch:35 step:33459 [D loss: 0.658455, acc.: 66.41%] [G loss: 0.862270]\n",
      "epoch:35 step:33460 [D loss: 0.637362, acc.: 63.28%] [G loss: 0.927500]\n",
      "epoch:35 step:33461 [D loss: 0.623413, acc.: 67.97%] [G loss: 0.974584]\n",
      "epoch:35 step:33462 [D loss: 0.623813, acc.: 64.06%] [G loss: 0.913174]\n",
      "epoch:35 step:33463 [D loss: 0.636863, acc.: 60.94%] [G loss: 0.920011]\n",
      "epoch:35 step:33464 [D loss: 0.641367, acc.: 57.03%] [G loss: 0.961627]\n",
      "epoch:35 step:33465 [D loss: 0.631617, acc.: 67.19%] [G loss: 0.919355]\n",
      "epoch:35 step:33466 [D loss: 0.646035, acc.: 60.16%] [G loss: 0.938993]\n",
      "epoch:35 step:33467 [D loss: 0.691920, acc.: 56.25%] [G loss: 0.939205]\n",
      "epoch:35 step:33468 [D loss: 0.661080, acc.: 62.50%] [G loss: 0.932258]\n",
      "epoch:35 step:33469 [D loss: 0.634683, acc.: 65.62%] [G loss: 0.952753]\n",
      "epoch:35 step:33470 [D loss: 0.638413, acc.: 61.72%] [G loss: 0.972022]\n",
      "epoch:35 step:33471 [D loss: 0.605765, acc.: 69.53%] [G loss: 0.899870]\n",
      "epoch:35 step:33472 [D loss: 0.638935, acc.: 64.84%] [G loss: 0.936708]\n",
      "epoch:35 step:33473 [D loss: 0.690973, acc.: 53.91%] [G loss: 0.901172]\n",
      "epoch:35 step:33474 [D loss: 0.607049, acc.: 60.16%] [G loss: 0.893098]\n",
      "epoch:35 step:33475 [D loss: 0.656896, acc.: 58.59%] [G loss: 0.896625]\n",
      "epoch:35 step:33476 [D loss: 0.621298, acc.: 67.19%] [G loss: 0.862049]\n",
      "epoch:35 step:33477 [D loss: 0.657446, acc.: 62.50%] [G loss: 0.881372]\n",
      "epoch:35 step:33478 [D loss: 0.647004, acc.: 58.59%] [G loss: 0.933580]\n",
      "epoch:35 step:33479 [D loss: 0.669788, acc.: 59.38%] [G loss: 0.940125]\n",
      "epoch:35 step:33480 [D loss: 0.618530, acc.: 65.62%] [G loss: 0.977615]\n",
      "epoch:35 step:33481 [D loss: 0.645176, acc.: 66.41%] [G loss: 1.033082]\n",
      "epoch:35 step:33482 [D loss: 0.632479, acc.: 67.19%] [G loss: 0.993899]\n",
      "epoch:35 step:33483 [D loss: 0.615394, acc.: 62.50%] [G loss: 1.029201]\n",
      "epoch:35 step:33484 [D loss: 0.620468, acc.: 64.84%] [G loss: 0.930193]\n",
      "epoch:35 step:33485 [D loss: 0.623822, acc.: 65.62%] [G loss: 0.961966]\n",
      "epoch:35 step:33486 [D loss: 0.644575, acc.: 57.03%] [G loss: 0.903148]\n",
      "epoch:35 step:33487 [D loss: 0.666553, acc.: 62.50%] [G loss: 0.878979]\n",
      "epoch:35 step:33488 [D loss: 0.618943, acc.: 64.06%] [G loss: 0.998903]\n",
      "epoch:35 step:33489 [D loss: 0.640335, acc.: 64.84%] [G loss: 0.994264]\n",
      "epoch:35 step:33490 [D loss: 0.633639, acc.: 65.62%] [G loss: 0.994395]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:33491 [D loss: 0.646199, acc.: 59.38%] [G loss: 0.973738]\n",
      "epoch:35 step:33492 [D loss: 0.613341, acc.: 66.41%] [G loss: 1.019598]\n",
      "epoch:35 step:33493 [D loss: 0.662802, acc.: 58.59%] [G loss: 0.969019]\n",
      "epoch:35 step:33494 [D loss: 0.631157, acc.: 65.62%] [G loss: 0.944914]\n",
      "epoch:35 step:33495 [D loss: 0.633743, acc.: 64.84%] [G loss: 0.980325]\n",
      "epoch:35 step:33496 [D loss: 0.623721, acc.: 68.75%] [G loss: 0.910092]\n",
      "epoch:35 step:33497 [D loss: 0.624924, acc.: 61.72%] [G loss: 0.892937]\n",
      "epoch:35 step:33498 [D loss: 0.660982, acc.: 54.69%] [G loss: 0.983395]\n",
      "epoch:35 step:33499 [D loss: 0.634290, acc.: 61.72%] [G loss: 0.967384]\n",
      "epoch:35 step:33500 [D loss: 0.671778, acc.: 54.69%] [G loss: 0.967003]\n",
      "epoch:35 step:33501 [D loss: 0.661797, acc.: 60.16%] [G loss: 0.937707]\n",
      "epoch:35 step:33502 [D loss: 0.596028, acc.: 66.41%] [G loss: 0.971083]\n",
      "epoch:35 step:33503 [D loss: 0.611951, acc.: 65.62%] [G loss: 0.976585]\n",
      "epoch:35 step:33504 [D loss: 0.734651, acc.: 48.44%] [G loss: 0.931501]\n",
      "epoch:35 step:33505 [D loss: 0.659252, acc.: 60.16%] [G loss: 0.949228]\n",
      "epoch:35 step:33506 [D loss: 0.630679, acc.: 65.62%] [G loss: 0.961902]\n",
      "epoch:35 step:33507 [D loss: 0.642963, acc.: 61.72%] [G loss: 0.906491]\n",
      "epoch:35 step:33508 [D loss: 0.675831, acc.: 57.81%] [G loss: 0.921359]\n",
      "epoch:35 step:33509 [D loss: 0.623274, acc.: 62.50%] [G loss: 0.894162]\n",
      "epoch:35 step:33510 [D loss: 0.672822, acc.: 58.59%] [G loss: 0.964082]\n",
      "epoch:35 step:33511 [D loss: 0.614406, acc.: 64.06%] [G loss: 1.007396]\n",
      "epoch:35 step:33512 [D loss: 0.624395, acc.: 59.38%] [G loss: 0.947776]\n",
      "epoch:35 step:33513 [D loss: 0.644210, acc.: 62.50%] [G loss: 0.937848]\n",
      "epoch:35 step:33514 [D loss: 0.635031, acc.: 65.62%] [G loss: 0.944897]\n",
      "epoch:35 step:33515 [D loss: 0.639265, acc.: 63.28%] [G loss: 0.883321]\n",
      "epoch:35 step:33516 [D loss: 0.623664, acc.: 66.41%] [G loss: 0.967943]\n",
      "epoch:35 step:33517 [D loss: 0.648628, acc.: 60.94%] [G loss: 1.044925]\n",
      "epoch:35 step:33518 [D loss: 0.631708, acc.: 61.72%] [G loss: 1.004972]\n",
      "epoch:35 step:33519 [D loss: 0.630322, acc.: 69.53%] [G loss: 0.971790]\n",
      "epoch:35 step:33520 [D loss: 0.620822, acc.: 64.84%] [G loss: 0.972315]\n",
      "epoch:35 step:33521 [D loss: 0.664406, acc.: 63.28%] [G loss: 0.963866]\n",
      "epoch:35 step:33522 [D loss: 0.605967, acc.: 69.53%] [G loss: 0.937783]\n",
      "epoch:35 step:33523 [D loss: 0.677064, acc.: 61.72%] [G loss: 0.944234]\n",
      "epoch:35 step:33524 [D loss: 0.635966, acc.: 60.16%] [G loss: 0.937794]\n",
      "epoch:35 step:33525 [D loss: 0.656521, acc.: 59.38%] [G loss: 0.937194]\n",
      "epoch:35 step:33526 [D loss: 0.664699, acc.: 57.81%] [G loss: 1.019940]\n",
      "epoch:35 step:33527 [D loss: 0.616837, acc.: 67.19%] [G loss: 0.944515]\n",
      "epoch:35 step:33528 [D loss: 0.672362, acc.: 63.28%] [G loss: 1.017127]\n",
      "epoch:35 step:33529 [D loss: 0.616247, acc.: 64.06%] [G loss: 0.943663]\n",
      "epoch:35 step:33530 [D loss: 0.647466, acc.: 59.38%] [G loss: 0.924001]\n",
      "epoch:35 step:33531 [D loss: 0.602044, acc.: 67.97%] [G loss: 0.907020]\n",
      "epoch:35 step:33532 [D loss: 0.648770, acc.: 60.16%] [G loss: 0.904178]\n",
      "epoch:35 step:33533 [D loss: 0.663122, acc.: 59.38%] [G loss: 0.941352]\n",
      "epoch:35 step:33534 [D loss: 0.676711, acc.: 57.81%] [G loss: 0.942510]\n",
      "epoch:35 step:33535 [D loss: 0.687894, acc.: 56.25%] [G loss: 0.903468]\n",
      "epoch:35 step:33536 [D loss: 0.620626, acc.: 65.62%] [G loss: 0.918289]\n",
      "epoch:35 step:33537 [D loss: 0.634423, acc.: 67.19%] [G loss: 0.872889]\n",
      "epoch:35 step:33538 [D loss: 0.652824, acc.: 62.50%] [G loss: 0.935064]\n",
      "epoch:35 step:33539 [D loss: 0.643046, acc.: 61.72%] [G loss: 0.832474]\n",
      "epoch:35 step:33540 [D loss: 0.634960, acc.: 58.59%] [G loss: 0.978268]\n",
      "epoch:35 step:33541 [D loss: 0.662208, acc.: 64.84%] [G loss: 0.979293]\n",
      "epoch:35 step:33542 [D loss: 0.608307, acc.: 67.97%] [G loss: 0.914928]\n",
      "epoch:35 step:33543 [D loss: 0.602252, acc.: 60.16%] [G loss: 0.938543]\n",
      "epoch:35 step:33544 [D loss: 0.641222, acc.: 64.06%] [G loss: 0.953285]\n",
      "epoch:35 step:33545 [D loss: 0.635288, acc.: 64.84%] [G loss: 0.948852]\n",
      "epoch:35 step:33546 [D loss: 0.622626, acc.: 60.94%] [G loss: 0.954401]\n",
      "epoch:35 step:33547 [D loss: 0.638932, acc.: 66.41%] [G loss: 0.992828]\n",
      "epoch:35 step:33548 [D loss: 0.600709, acc.: 69.53%] [G loss: 0.934513]\n",
      "epoch:35 step:33549 [D loss: 0.651882, acc.: 57.81%] [G loss: 0.925493]\n",
      "epoch:35 step:33550 [D loss: 0.615399, acc.: 64.06%] [G loss: 0.936952]\n",
      "epoch:35 step:33551 [D loss: 0.588555, acc.: 69.53%] [G loss: 0.989232]\n",
      "epoch:35 step:33552 [D loss: 0.595143, acc.: 73.44%] [G loss: 0.985330]\n",
      "epoch:35 step:33553 [D loss: 0.633545, acc.: 67.19%] [G loss: 0.899897]\n",
      "epoch:35 step:33554 [D loss: 0.679369, acc.: 59.38%] [G loss: 0.917621]\n",
      "epoch:35 step:33555 [D loss: 0.655408, acc.: 65.62%] [G loss: 0.952374]\n",
      "epoch:35 step:33556 [D loss: 0.674674, acc.: 60.16%] [G loss: 0.910864]\n",
      "epoch:35 step:33557 [D loss: 0.684220, acc.: 57.03%] [G loss: 0.949806]\n",
      "epoch:35 step:33558 [D loss: 0.677807, acc.: 57.81%] [G loss: 0.972763]\n",
      "epoch:35 step:33559 [D loss: 0.612140, acc.: 66.41%] [G loss: 0.964834]\n",
      "epoch:35 step:33560 [D loss: 0.662864, acc.: 57.81%] [G loss: 0.978034]\n",
      "epoch:35 step:33561 [D loss: 0.614342, acc.: 66.41%] [G loss: 0.912424]\n",
      "epoch:35 step:33562 [D loss: 0.640588, acc.: 64.84%] [G loss: 0.975129]\n",
      "epoch:35 step:33563 [D loss: 0.623043, acc.: 65.62%] [G loss: 0.983605]\n",
      "epoch:35 step:33564 [D loss: 0.592884, acc.: 71.09%] [G loss: 0.973078]\n",
      "epoch:35 step:33565 [D loss: 0.606293, acc.: 61.72%] [G loss: 0.909128]\n",
      "epoch:35 step:33566 [D loss: 0.613498, acc.: 69.53%] [G loss: 0.899370]\n",
      "epoch:35 step:33567 [D loss: 0.595056, acc.: 67.19%] [G loss: 0.869920]\n",
      "epoch:35 step:33568 [D loss: 0.677774, acc.: 57.81%] [G loss: 0.887667]\n",
      "epoch:35 step:33569 [D loss: 0.627926, acc.: 64.06%] [G loss: 0.876458]\n",
      "epoch:35 step:33570 [D loss: 0.636297, acc.: 57.03%] [G loss: 0.954668]\n",
      "epoch:35 step:33571 [D loss: 0.621981, acc.: 62.50%] [G loss: 0.958618]\n",
      "epoch:35 step:33572 [D loss: 0.683183, acc.: 58.59%] [G loss: 0.866483]\n",
      "epoch:35 step:33573 [D loss: 0.648063, acc.: 60.94%] [G loss: 0.934777]\n",
      "epoch:35 step:33574 [D loss: 0.599153, acc.: 67.97%] [G loss: 1.000298]\n",
      "epoch:35 step:33575 [D loss: 0.663833, acc.: 60.16%] [G loss: 0.973462]\n",
      "epoch:35 step:33576 [D loss: 0.675905, acc.: 62.50%] [G loss: 0.942864]\n",
      "epoch:35 step:33577 [D loss: 0.629163, acc.: 64.06%] [G loss: 0.945386]\n",
      "epoch:35 step:33578 [D loss: 0.652465, acc.: 57.03%] [G loss: 0.996294]\n",
      "epoch:35 step:33579 [D loss: 0.657006, acc.: 53.91%] [G loss: 0.981737]\n",
      "epoch:35 step:33580 [D loss: 0.661706, acc.: 62.50%] [G loss: 0.953895]\n",
      "epoch:35 step:33581 [D loss: 0.643365, acc.: 59.38%] [G loss: 0.982339]\n",
      "epoch:35 step:33582 [D loss: 0.665340, acc.: 58.59%] [G loss: 0.962458]\n",
      "epoch:35 step:33583 [D loss: 0.668837, acc.: 64.84%] [G loss: 0.951569]\n",
      "epoch:35 step:33584 [D loss: 0.625371, acc.: 64.06%] [G loss: 0.860999]\n",
      "epoch:35 step:33585 [D loss: 0.688422, acc.: 51.56%] [G loss: 0.873916]\n",
      "epoch:35 step:33586 [D loss: 0.643699, acc.: 64.06%] [G loss: 0.862973]\n",
      "epoch:35 step:33587 [D loss: 0.629254, acc.: 62.50%] [G loss: 0.900799]\n",
      "epoch:35 step:33588 [D loss: 0.612673, acc.: 68.75%] [G loss: 0.957996]\n",
      "epoch:35 step:33589 [D loss: 0.665227, acc.: 59.38%] [G loss: 1.001163]\n",
      "epoch:35 step:33590 [D loss: 0.602313, acc.: 67.19%] [G loss: 0.980066]\n",
      "epoch:35 step:33591 [D loss: 0.657298, acc.: 60.16%] [G loss: 0.938866]\n",
      "epoch:35 step:33592 [D loss: 0.657084, acc.: 60.94%] [G loss: 0.920979]\n",
      "epoch:35 step:33593 [D loss: 0.616681, acc.: 62.50%] [G loss: 0.904414]\n",
      "epoch:35 step:33594 [D loss: 0.638127, acc.: 60.94%] [G loss: 0.924435]\n",
      "epoch:35 step:33595 [D loss: 0.633365, acc.: 65.62%] [G loss: 1.027154]\n",
      "epoch:35 step:33596 [D loss: 0.652269, acc.: 58.59%] [G loss: 0.965367]\n",
      "epoch:35 step:33597 [D loss: 0.667544, acc.: 59.38%] [G loss: 1.001140]\n",
      "epoch:35 step:33598 [D loss: 0.641031, acc.: 66.41%] [G loss: 0.945040]\n",
      "epoch:35 step:33599 [D loss: 0.688759, acc.: 51.56%] [G loss: 0.912475]\n",
      "epoch:35 step:33600 [D loss: 0.652263, acc.: 61.72%] [G loss: 0.927501]\n",
      "##############\n",
      "[3.00089952 2.47224999 2.53263272 3.80844446 1.4269896  9.27426719\n",
      " 2.65221816 3.1883588  4.22438746 8.14868929]\n",
      "##########\n",
      "epoch:35 step:33601 [D loss: 0.599400, acc.: 71.88%] [G loss: 0.976602]\n",
      "epoch:35 step:33602 [D loss: 0.635440, acc.: 63.28%] [G loss: 0.876449]\n",
      "epoch:35 step:33603 [D loss: 0.661238, acc.: 56.25%] [G loss: 0.859086]\n",
      "epoch:35 step:33604 [D loss: 0.637966, acc.: 60.94%] [G loss: 0.921987]\n",
      "epoch:35 step:33605 [D loss: 0.603962, acc.: 68.75%] [G loss: 0.962227]\n",
      "epoch:35 step:33606 [D loss: 0.636098, acc.: 58.59%] [G loss: 0.947240]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:33607 [D loss: 0.648783, acc.: 60.94%] [G loss: 0.973125]\n",
      "epoch:35 step:33608 [D loss: 0.628669, acc.: 71.09%] [G loss: 0.961973]\n",
      "epoch:35 step:33609 [D loss: 0.622230, acc.: 65.62%] [G loss: 0.933929]\n",
      "epoch:35 step:33610 [D loss: 0.658384, acc.: 58.59%] [G loss: 0.915633]\n",
      "epoch:35 step:33611 [D loss: 0.640900, acc.: 61.72%] [G loss: 0.937649]\n",
      "epoch:35 step:33612 [D loss: 0.673001, acc.: 55.47%] [G loss: 0.942177]\n",
      "epoch:35 step:33613 [D loss: 0.671209, acc.: 54.69%] [G loss: 1.008270]\n",
      "epoch:35 step:33614 [D loss: 0.669841, acc.: 58.59%] [G loss: 0.933474]\n",
      "epoch:35 step:33615 [D loss: 0.670315, acc.: 61.72%] [G loss: 0.950551]\n",
      "epoch:35 step:33616 [D loss: 0.642363, acc.: 66.41%] [G loss: 0.947414]\n",
      "epoch:35 step:33617 [D loss: 0.614685, acc.: 63.28%] [G loss: 0.971543]\n",
      "epoch:35 step:33618 [D loss: 0.686060, acc.: 50.00%] [G loss: 1.006264]\n",
      "epoch:35 step:33619 [D loss: 0.617838, acc.: 65.62%] [G loss: 0.892761]\n",
      "epoch:35 step:33620 [D loss: 0.643397, acc.: 59.38%] [G loss: 0.914786]\n",
      "epoch:35 step:33621 [D loss: 0.628724, acc.: 67.97%] [G loss: 0.931284]\n",
      "epoch:35 step:33622 [D loss: 0.617863, acc.: 69.53%] [G loss: 0.946801]\n",
      "epoch:35 step:33623 [D loss: 0.677346, acc.: 56.25%] [G loss: 0.906831]\n",
      "epoch:35 step:33624 [D loss: 0.667505, acc.: 62.50%] [G loss: 0.868927]\n",
      "epoch:35 step:33625 [D loss: 0.629183, acc.: 60.16%] [G loss: 0.919301]\n",
      "epoch:35 step:33626 [D loss: 0.647984, acc.: 62.50%] [G loss: 0.991204]\n",
      "epoch:35 step:33627 [D loss: 0.640680, acc.: 60.94%] [G loss: 0.940372]\n",
      "epoch:35 step:33628 [D loss: 0.637659, acc.: 61.72%] [G loss: 0.917146]\n",
      "epoch:35 step:33629 [D loss: 0.650782, acc.: 60.16%] [G loss: 0.869617]\n",
      "epoch:35 step:33630 [D loss: 0.672217, acc.: 57.03%] [G loss: 0.887850]\n",
      "epoch:35 step:33631 [D loss: 0.621105, acc.: 66.41%] [G loss: 0.882448]\n",
      "epoch:35 step:33632 [D loss: 0.644330, acc.: 60.16%] [G loss: 0.930624]\n",
      "epoch:35 step:33633 [D loss: 0.717877, acc.: 50.78%] [G loss: 0.864906]\n",
      "epoch:35 step:33634 [D loss: 0.655242, acc.: 57.81%] [G loss: 0.847903]\n",
      "epoch:35 step:33635 [D loss: 0.615952, acc.: 65.62%] [G loss: 0.927852]\n",
      "epoch:35 step:33636 [D loss: 0.652466, acc.: 62.50%] [G loss: 0.915987]\n",
      "epoch:35 step:33637 [D loss: 0.664368, acc.: 60.94%] [G loss: 0.913708]\n",
      "epoch:35 step:33638 [D loss: 0.690913, acc.: 57.03%] [G loss: 0.925174]\n",
      "epoch:35 step:33639 [D loss: 0.616386, acc.: 64.84%] [G loss: 0.903133]\n",
      "epoch:35 step:33640 [D loss: 0.637940, acc.: 64.06%] [G loss: 0.932265]\n",
      "epoch:35 step:33641 [D loss: 0.623744, acc.: 61.72%] [G loss: 0.900940]\n",
      "epoch:35 step:33642 [D loss: 0.638255, acc.: 61.72%] [G loss: 0.952449]\n",
      "epoch:35 step:33643 [D loss: 0.631898, acc.: 60.16%] [G loss: 0.889330]\n",
      "epoch:35 step:33644 [D loss: 0.651204, acc.: 58.59%] [G loss: 0.973903]\n",
      "epoch:35 step:33645 [D loss: 0.610466, acc.: 67.19%] [G loss: 0.913500]\n",
      "epoch:35 step:33646 [D loss: 0.671097, acc.: 60.94%] [G loss: 1.003794]\n",
      "epoch:35 step:33647 [D loss: 0.648070, acc.: 64.84%] [G loss: 0.962988]\n",
      "epoch:35 step:33648 [D loss: 0.642198, acc.: 56.25%] [G loss: 0.966189]\n",
      "epoch:35 step:33649 [D loss: 0.652753, acc.: 64.06%] [G loss: 0.952373]\n",
      "epoch:35 step:33650 [D loss: 0.696887, acc.: 57.81%] [G loss: 0.844589]\n",
      "epoch:35 step:33651 [D loss: 0.615229, acc.: 68.75%] [G loss: 0.900489]\n",
      "epoch:35 step:33652 [D loss: 0.682302, acc.: 57.03%] [G loss: 0.871503]\n",
      "epoch:35 step:33653 [D loss: 0.655936, acc.: 55.47%] [G loss: 0.910842]\n",
      "epoch:35 step:33654 [D loss: 0.641995, acc.: 61.72%] [G loss: 0.915777]\n",
      "epoch:35 step:33655 [D loss: 0.667187, acc.: 54.69%] [G loss: 0.886431]\n",
      "epoch:35 step:33656 [D loss: 0.622542, acc.: 67.19%] [G loss: 0.953673]\n",
      "epoch:35 step:33657 [D loss: 0.590745, acc.: 64.84%] [G loss: 0.968237]\n",
      "epoch:35 step:33658 [D loss: 0.610045, acc.: 66.41%] [G loss: 0.970243]\n",
      "epoch:35 step:33659 [D loss: 0.706582, acc.: 50.00%] [G loss: 0.885446]\n",
      "epoch:35 step:33660 [D loss: 0.694000, acc.: 49.22%] [G loss: 0.988976]\n",
      "epoch:35 step:33661 [D loss: 0.622346, acc.: 64.06%] [G loss: 0.950957]\n",
      "epoch:35 step:33662 [D loss: 0.659492, acc.: 61.72%] [G loss: 0.918010]\n",
      "epoch:35 step:33663 [D loss: 0.624522, acc.: 66.41%] [G loss: 0.872032]\n",
      "epoch:35 step:33664 [D loss: 0.652168, acc.: 58.59%] [G loss: 0.831308]\n",
      "epoch:35 step:33665 [D loss: 0.660006, acc.: 53.12%] [G loss: 0.945172]\n",
      "epoch:35 step:33666 [D loss: 0.622375, acc.: 67.19%] [G loss: 0.982801]\n",
      "epoch:35 step:33667 [D loss: 0.662589, acc.: 56.25%] [G loss: 0.847574]\n",
      "epoch:35 step:33668 [D loss: 0.618759, acc.: 66.41%] [G loss: 0.934885]\n",
      "epoch:35 step:33669 [D loss: 0.679563, acc.: 58.59%] [G loss: 0.902690]\n",
      "epoch:35 step:33670 [D loss: 0.658005, acc.: 64.84%] [G loss: 0.917161]\n",
      "epoch:35 step:33671 [D loss: 0.664600, acc.: 56.25%] [G loss: 0.943747]\n",
      "epoch:35 step:33672 [D loss: 0.627613, acc.: 64.84%] [G loss: 0.902648]\n",
      "epoch:35 step:33673 [D loss: 0.640223, acc.: 56.25%] [G loss: 0.941290]\n",
      "epoch:35 step:33674 [D loss: 0.655319, acc.: 62.50%] [G loss: 0.930608]\n",
      "epoch:35 step:33675 [D loss: 0.636198, acc.: 60.94%] [G loss: 0.928191]\n",
      "epoch:35 step:33676 [D loss: 0.651178, acc.: 64.06%] [G loss: 0.913928]\n",
      "epoch:35 step:33677 [D loss: 0.594826, acc.: 67.19%] [G loss: 0.896510]\n",
      "epoch:35 step:33678 [D loss: 0.629328, acc.: 60.16%] [G loss: 0.934581]\n",
      "epoch:35 step:33679 [D loss: 0.617050, acc.: 71.09%] [G loss: 0.939342]\n",
      "epoch:35 step:33680 [D loss: 0.663153, acc.: 64.06%] [G loss: 0.997764]\n",
      "epoch:35 step:33681 [D loss: 0.641968, acc.: 58.59%] [G loss: 0.893295]\n",
      "epoch:35 step:33682 [D loss: 0.657043, acc.: 60.16%] [G loss: 0.905081]\n",
      "epoch:35 step:33683 [D loss: 0.654183, acc.: 64.06%] [G loss: 0.926637]\n",
      "epoch:35 step:33684 [D loss: 0.647884, acc.: 67.97%] [G loss: 0.898327]\n",
      "epoch:35 step:33685 [D loss: 0.634899, acc.: 61.72%] [G loss: 0.977039]\n",
      "epoch:35 step:33686 [D loss: 0.629354, acc.: 65.62%] [G loss: 0.928702]\n",
      "epoch:35 step:33687 [D loss: 0.638057, acc.: 66.41%] [G loss: 0.839328]\n",
      "epoch:35 step:33688 [D loss: 0.672918, acc.: 57.81%] [G loss: 0.861990]\n",
      "epoch:35 step:33689 [D loss: 0.671009, acc.: 64.06%] [G loss: 0.877243]\n",
      "epoch:35 step:33690 [D loss: 0.639298, acc.: 63.28%] [G loss: 0.891499]\n",
      "epoch:35 step:33691 [D loss: 0.622100, acc.: 65.62%] [G loss: 0.927602]\n",
      "epoch:35 step:33692 [D loss: 0.642365, acc.: 63.28%] [G loss: 0.936576]\n",
      "epoch:35 step:33693 [D loss: 0.642293, acc.: 62.50%] [G loss: 0.949127]\n",
      "epoch:35 step:33694 [D loss: 0.686490, acc.: 53.91%] [G loss: 0.925547]\n",
      "epoch:35 step:33695 [D loss: 0.645649, acc.: 60.16%] [G loss: 0.936166]\n",
      "epoch:35 step:33696 [D loss: 0.688533, acc.: 57.03%] [G loss: 0.950314]\n",
      "epoch:35 step:33697 [D loss: 0.678552, acc.: 58.59%] [G loss: 0.872467]\n",
      "epoch:35 step:33698 [D loss: 0.621767, acc.: 67.19%] [G loss: 0.951278]\n",
      "epoch:35 step:33699 [D loss: 0.627606, acc.: 60.94%] [G loss: 0.905905]\n",
      "epoch:35 step:33700 [D loss: 0.697284, acc.: 53.12%] [G loss: 0.927978]\n",
      "epoch:35 step:33701 [D loss: 0.613263, acc.: 64.06%] [G loss: 0.915305]\n",
      "epoch:35 step:33702 [D loss: 0.683560, acc.: 58.59%] [G loss: 0.882939]\n",
      "epoch:35 step:33703 [D loss: 0.672140, acc.: 60.16%] [G loss: 0.863463]\n",
      "epoch:35 step:33704 [D loss: 0.659399, acc.: 60.94%] [G loss: 0.853144]\n",
      "epoch:35 step:33705 [D loss: 0.693588, acc.: 57.81%] [G loss: 0.908064]\n",
      "epoch:35 step:33706 [D loss: 0.651722, acc.: 57.03%] [G loss: 0.981570]\n",
      "epoch:35 step:33707 [D loss: 0.646776, acc.: 61.72%] [G loss: 0.941748]\n",
      "epoch:35 step:33708 [D loss: 0.641698, acc.: 60.94%] [G loss: 0.901119]\n",
      "epoch:35 step:33709 [D loss: 0.611822, acc.: 62.50%] [G loss: 0.891648]\n",
      "epoch:35 step:33710 [D loss: 0.698664, acc.: 50.78%] [G loss: 0.872489]\n",
      "epoch:35 step:33711 [D loss: 0.632515, acc.: 62.50%] [G loss: 0.868203]\n",
      "epoch:35 step:33712 [D loss: 0.639686, acc.: 62.50%] [G loss: 0.921223]\n",
      "epoch:35 step:33713 [D loss: 0.695181, acc.: 53.12%] [G loss: 0.891520]\n",
      "epoch:35 step:33714 [D loss: 0.649685, acc.: 58.59%] [G loss: 0.930129]\n",
      "epoch:35 step:33715 [D loss: 0.614250, acc.: 66.41%] [G loss: 0.949471]\n",
      "epoch:35 step:33716 [D loss: 0.665294, acc.: 57.81%] [G loss: 0.959336]\n",
      "epoch:35 step:33717 [D loss: 0.635200, acc.: 62.50%] [G loss: 0.906075]\n",
      "epoch:35 step:33718 [D loss: 0.631902, acc.: 64.84%] [G loss: 0.954325]\n",
      "epoch:35 step:33719 [D loss: 0.621648, acc.: 62.50%] [G loss: 0.904674]\n",
      "epoch:35 step:33720 [D loss: 0.649361, acc.: 62.50%] [G loss: 0.889396]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:35 step:33721 [D loss: 0.649568, acc.: 62.50%] [G loss: 0.985293]\n",
      "epoch:35 step:33722 [D loss: 0.678412, acc.: 53.12%] [G loss: 0.915076]\n",
      "epoch:35 step:33723 [D loss: 0.671227, acc.: 58.59%] [G loss: 0.892501]\n",
      "epoch:35 step:33724 [D loss: 0.642656, acc.: 59.38%] [G loss: 0.915767]\n",
      "epoch:35 step:33725 [D loss: 0.616930, acc.: 65.62%] [G loss: 0.938772]\n",
      "epoch:35 step:33726 [D loss: 0.663395, acc.: 64.06%] [G loss: 0.982585]\n",
      "epoch:35 step:33727 [D loss: 0.577553, acc.: 75.00%] [G loss: 0.898625]\n",
      "epoch:35 step:33728 [D loss: 0.669254, acc.: 63.28%] [G loss: 0.923881]\n",
      "epoch:35 step:33729 [D loss: 0.619004, acc.: 67.97%] [G loss: 0.936897]\n",
      "epoch:35 step:33730 [D loss: 0.619249, acc.: 60.94%] [G loss: 0.911019]\n",
      "epoch:35 step:33731 [D loss: 0.662609, acc.: 59.38%] [G loss: 0.969202]\n",
      "epoch:35 step:33732 [D loss: 0.639163, acc.: 60.16%] [G loss: 0.914573]\n",
      "epoch:36 step:33733 [D loss: 0.638623, acc.: 58.59%] [G loss: 0.909045]\n",
      "epoch:36 step:33734 [D loss: 0.638766, acc.: 63.28%] [G loss: 0.931825]\n",
      "epoch:36 step:33735 [D loss: 0.633993, acc.: 61.72%] [G loss: 0.950831]\n",
      "epoch:36 step:33736 [D loss: 0.643374, acc.: 64.06%] [G loss: 0.941731]\n",
      "epoch:36 step:33737 [D loss: 0.665714, acc.: 61.72%] [G loss: 0.948593]\n",
      "epoch:36 step:33738 [D loss: 0.664555, acc.: 60.16%] [G loss: 0.932249]\n",
      "epoch:36 step:33739 [D loss: 0.666884, acc.: 57.03%] [G loss: 0.935504]\n",
      "epoch:36 step:33740 [D loss: 0.648239, acc.: 60.16%] [G loss: 0.955407]\n",
      "epoch:36 step:33741 [D loss: 0.658865, acc.: 63.28%] [G loss: 0.934825]\n",
      "epoch:36 step:33742 [D loss: 0.636907, acc.: 64.06%] [G loss: 0.917742]\n",
      "epoch:36 step:33743 [D loss: 0.623208, acc.: 67.97%] [G loss: 0.850021]\n",
      "epoch:36 step:33744 [D loss: 0.642654, acc.: 62.50%] [G loss: 0.930851]\n",
      "epoch:36 step:33745 [D loss: 0.620766, acc.: 67.19%] [G loss: 0.922333]\n",
      "epoch:36 step:33746 [D loss: 0.671570, acc.: 57.81%] [G loss: 0.912096]\n",
      "epoch:36 step:33747 [D loss: 0.594942, acc.: 66.41%] [G loss: 0.894401]\n",
      "epoch:36 step:33748 [D loss: 0.636862, acc.: 63.28%] [G loss: 0.970488]\n",
      "epoch:36 step:33749 [D loss: 0.627564, acc.: 63.28%] [G loss: 0.961890]\n",
      "epoch:36 step:33750 [D loss: 0.657179, acc.: 57.81%] [G loss: 0.920594]\n",
      "epoch:36 step:33751 [D loss: 0.688631, acc.: 53.91%] [G loss: 0.923742]\n",
      "epoch:36 step:33752 [D loss: 0.678292, acc.: 60.16%] [G loss: 0.973725]\n",
      "epoch:36 step:33753 [D loss: 0.613882, acc.: 68.75%] [G loss: 0.975059]\n",
      "epoch:36 step:33754 [D loss: 0.632252, acc.: 61.72%] [G loss: 1.031672]\n",
      "epoch:36 step:33755 [D loss: 0.658777, acc.: 58.59%] [G loss: 1.011882]\n",
      "epoch:36 step:33756 [D loss: 0.673290, acc.: 56.25%] [G loss: 0.944148]\n",
      "epoch:36 step:33757 [D loss: 0.638284, acc.: 60.94%] [G loss: 0.886215]\n",
      "epoch:36 step:33758 [D loss: 0.656108, acc.: 64.84%] [G loss: 0.928989]\n",
      "epoch:36 step:33759 [D loss: 0.640875, acc.: 64.84%] [G loss: 0.928616]\n",
      "epoch:36 step:33760 [D loss: 0.669504, acc.: 56.25%] [G loss: 0.930226]\n",
      "epoch:36 step:33761 [D loss: 0.630668, acc.: 67.97%] [G loss: 0.943003]\n",
      "epoch:36 step:33762 [D loss: 0.644273, acc.: 64.06%] [G loss: 0.916615]\n",
      "epoch:36 step:33763 [D loss: 0.668484, acc.: 57.03%] [G loss: 0.900538]\n",
      "epoch:36 step:33764 [D loss: 0.612186, acc.: 67.19%] [G loss: 0.978102]\n",
      "epoch:36 step:33765 [D loss: 0.643901, acc.: 56.25%] [G loss: 0.937043]\n",
      "epoch:36 step:33766 [D loss: 0.688774, acc.: 53.12%] [G loss: 0.928314]\n",
      "epoch:36 step:33767 [D loss: 0.656702, acc.: 60.94%] [G loss: 0.984039]\n",
      "epoch:36 step:33768 [D loss: 0.632387, acc.: 65.62%] [G loss: 0.937145]\n",
      "epoch:36 step:33769 [D loss: 0.619438, acc.: 62.50%] [G loss: 0.912291]\n",
      "epoch:36 step:33770 [D loss: 0.672234, acc.: 58.59%] [G loss: 0.908238]\n",
      "epoch:36 step:33771 [D loss: 0.613350, acc.: 68.75%] [G loss: 0.903322]\n",
      "epoch:36 step:33772 [D loss: 0.706104, acc.: 53.12%] [G loss: 0.847026]\n",
      "epoch:36 step:33773 [D loss: 0.653771, acc.: 58.59%] [G loss: 0.894648]\n",
      "epoch:36 step:33774 [D loss: 0.601004, acc.: 67.97%] [G loss: 0.991591]\n",
      "epoch:36 step:33775 [D loss: 0.655208, acc.: 53.12%] [G loss: 0.916488]\n",
      "epoch:36 step:33776 [D loss: 0.641476, acc.: 60.16%] [G loss: 0.966422]\n",
      "epoch:36 step:33777 [D loss: 0.660312, acc.: 60.94%] [G loss: 0.951678]\n",
      "epoch:36 step:33778 [D loss: 0.651971, acc.: 61.72%] [G loss: 0.925455]\n",
      "epoch:36 step:33779 [D loss: 0.661758, acc.: 61.72%] [G loss: 0.891049]\n",
      "epoch:36 step:33780 [D loss: 0.637181, acc.: 66.41%] [G loss: 0.925846]\n",
      "epoch:36 step:33781 [D loss: 0.636006, acc.: 61.72%] [G loss: 0.888027]\n",
      "epoch:36 step:33782 [D loss: 0.629530, acc.: 63.28%] [G loss: 0.933472]\n",
      "epoch:36 step:33783 [D loss: 0.622923, acc.: 66.41%] [G loss: 0.946057]\n",
      "epoch:36 step:33784 [D loss: 0.628828, acc.: 65.62%] [G loss: 0.912729]\n",
      "epoch:36 step:33785 [D loss: 0.656300, acc.: 64.84%] [G loss: 0.887569]\n",
      "epoch:36 step:33786 [D loss: 0.634114, acc.: 62.50%] [G loss: 0.893517]\n",
      "epoch:36 step:33787 [D loss: 0.635475, acc.: 62.50%] [G loss: 0.884029]\n",
      "epoch:36 step:33788 [D loss: 0.702137, acc.: 51.56%] [G loss: 0.930026]\n",
      "epoch:36 step:33789 [D loss: 0.646892, acc.: 63.28%] [G loss: 0.941004]\n",
      "epoch:36 step:33790 [D loss: 0.617639, acc.: 64.84%] [G loss: 0.965859]\n",
      "epoch:36 step:33791 [D loss: 0.636285, acc.: 62.50%] [G loss: 0.986754]\n",
      "epoch:36 step:33792 [D loss: 0.635185, acc.: 64.84%] [G loss: 0.963563]\n",
      "epoch:36 step:33793 [D loss: 0.623548, acc.: 66.41%] [G loss: 0.941423]\n",
      "epoch:36 step:33794 [D loss: 0.617800, acc.: 68.75%] [G loss: 0.935638]\n",
      "epoch:36 step:33795 [D loss: 0.634883, acc.: 67.19%] [G loss: 0.950194]\n",
      "epoch:36 step:33796 [D loss: 0.617898, acc.: 63.28%] [G loss: 0.950820]\n",
      "epoch:36 step:33797 [D loss: 0.659904, acc.: 58.59%] [G loss: 0.971452]\n",
      "epoch:36 step:33798 [D loss: 0.609965, acc.: 65.62%] [G loss: 0.969202]\n",
      "epoch:36 step:33799 [D loss: 0.665468, acc.: 58.59%] [G loss: 0.979933]\n",
      "epoch:36 step:33800 [D loss: 0.647569, acc.: 61.72%] [G loss: 1.007471]\n",
      "##############\n",
      "[3.2074219  2.43738278 1.96395385 3.6098555  1.46560881 7.90880287\n",
      " 2.47999026 2.98152225 4.24115182 8.14868929]\n",
      "##########\n",
      "epoch:36 step:33801 [D loss: 0.589041, acc.: 70.31%] [G loss: 0.931521]\n",
      "epoch:36 step:33802 [D loss: 0.635166, acc.: 64.84%] [G loss: 0.984289]\n",
      "epoch:36 step:33803 [D loss: 0.627744, acc.: 62.50%] [G loss: 1.003525]\n",
      "epoch:36 step:33804 [D loss: 0.642382, acc.: 61.72%] [G loss: 0.959625]\n",
      "epoch:36 step:33805 [D loss: 0.627732, acc.: 60.16%] [G loss: 0.992085]\n",
      "epoch:36 step:33806 [D loss: 0.591304, acc.: 64.06%] [G loss: 0.964830]\n",
      "epoch:36 step:33807 [D loss: 0.653217, acc.: 57.03%] [G loss: 0.908619]\n",
      "epoch:36 step:33808 [D loss: 0.597236, acc.: 66.41%] [G loss: 0.924821]\n",
      "epoch:36 step:33809 [D loss: 0.657624, acc.: 60.16%] [G loss: 0.964440]\n",
      "epoch:36 step:33810 [D loss: 0.620387, acc.: 66.41%] [G loss: 0.938604]\n",
      "epoch:36 step:33811 [D loss: 0.613249, acc.: 68.75%] [G loss: 0.887959]\n",
      "epoch:36 step:33812 [D loss: 0.677658, acc.: 57.81%] [G loss: 0.862649]\n",
      "epoch:36 step:33813 [D loss: 0.655162, acc.: 59.38%] [G loss: 0.865848]\n",
      "epoch:36 step:33814 [D loss: 0.657759, acc.: 60.94%] [G loss: 0.926261]\n",
      "epoch:36 step:33815 [D loss: 0.650332, acc.: 60.16%] [G loss: 0.939155]\n",
      "epoch:36 step:33816 [D loss: 0.675484, acc.: 57.03%] [G loss: 0.901535]\n",
      "epoch:36 step:33817 [D loss: 0.667143, acc.: 53.12%] [G loss: 0.963274]\n",
      "epoch:36 step:33818 [D loss: 0.643445, acc.: 63.28%] [G loss: 0.964718]\n",
      "epoch:36 step:33819 [D loss: 0.644383, acc.: 59.38%] [G loss: 0.951160]\n",
      "epoch:36 step:33820 [D loss: 0.664821, acc.: 59.38%] [G loss: 0.989076]\n",
      "epoch:36 step:33821 [D loss: 0.610346, acc.: 68.75%] [G loss: 0.935960]\n",
      "epoch:36 step:33822 [D loss: 0.659100, acc.: 57.81%] [G loss: 1.007913]\n",
      "epoch:36 step:33823 [D loss: 0.691822, acc.: 60.16%] [G loss: 0.984541]\n",
      "epoch:36 step:33824 [D loss: 0.653107, acc.: 60.16%] [G loss: 0.880796]\n",
      "epoch:36 step:33825 [D loss: 0.681313, acc.: 57.81%] [G loss: 0.937564]\n",
      "epoch:36 step:33826 [D loss: 0.620571, acc.: 69.53%] [G loss: 0.942990]\n",
      "epoch:36 step:33827 [D loss: 0.703757, acc.: 51.56%] [G loss: 0.964088]\n",
      "epoch:36 step:33828 [D loss: 0.626719, acc.: 61.72%] [G loss: 0.902992]\n",
      "epoch:36 step:33829 [D loss: 0.665276, acc.: 61.72%] [G loss: 0.926350]\n",
      "epoch:36 step:33830 [D loss: 0.638174, acc.: 61.72%] [G loss: 0.920729]\n",
      "epoch:36 step:33831 [D loss: 0.653219, acc.: 61.72%] [G loss: 0.964675]\n",
      "epoch:36 step:33832 [D loss: 0.678057, acc.: 55.47%] [G loss: 0.960151]\n",
      "epoch:36 step:33833 [D loss: 0.623695, acc.: 67.19%] [G loss: 0.923679]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:33834 [D loss: 0.643771, acc.: 64.06%] [G loss: 0.920723]\n",
      "epoch:36 step:33835 [D loss: 0.607536, acc.: 64.84%] [G loss: 0.913594]\n",
      "epoch:36 step:33836 [D loss: 0.646650, acc.: 57.03%] [G loss: 0.974008]\n",
      "epoch:36 step:33837 [D loss: 0.649553, acc.: 58.59%] [G loss: 0.892903]\n",
      "epoch:36 step:33838 [D loss: 0.607449, acc.: 67.19%] [G loss: 0.909949]\n",
      "epoch:36 step:33839 [D loss: 0.585994, acc.: 71.09%] [G loss: 0.973749]\n",
      "epoch:36 step:33840 [D loss: 0.652386, acc.: 61.72%] [G loss: 0.920423]\n",
      "epoch:36 step:33841 [D loss: 0.618572, acc.: 66.41%] [G loss: 0.945048]\n",
      "epoch:36 step:33842 [D loss: 0.605994, acc.: 68.75%] [G loss: 0.908563]\n",
      "epoch:36 step:33843 [D loss: 0.684502, acc.: 57.81%] [G loss: 0.827618]\n",
      "epoch:36 step:33844 [D loss: 0.712321, acc.: 60.16%] [G loss: 0.895225]\n",
      "epoch:36 step:33845 [D loss: 0.641275, acc.: 61.72%] [G loss: 0.936756]\n",
      "epoch:36 step:33846 [D loss: 0.665541, acc.: 55.47%] [G loss: 0.973331]\n",
      "epoch:36 step:33847 [D loss: 0.654884, acc.: 62.50%] [G loss: 0.973429]\n",
      "epoch:36 step:33848 [D loss: 0.623147, acc.: 68.75%] [G loss: 0.912968]\n",
      "epoch:36 step:33849 [D loss: 0.644081, acc.: 61.72%] [G loss: 0.965095]\n",
      "epoch:36 step:33850 [D loss: 0.637033, acc.: 58.59%] [G loss: 0.995565]\n",
      "epoch:36 step:33851 [D loss: 0.643552, acc.: 63.28%] [G loss: 0.926511]\n",
      "epoch:36 step:33852 [D loss: 0.687487, acc.: 50.00%] [G loss: 0.929208]\n",
      "epoch:36 step:33853 [D loss: 0.654322, acc.: 61.72%] [G loss: 0.962100]\n",
      "epoch:36 step:33854 [D loss: 0.657167, acc.: 62.50%] [G loss: 0.998339]\n",
      "epoch:36 step:33855 [D loss: 0.675913, acc.: 57.03%] [G loss: 0.901987]\n",
      "epoch:36 step:33856 [D loss: 0.637601, acc.: 61.72%] [G loss: 0.914467]\n",
      "epoch:36 step:33857 [D loss: 0.655462, acc.: 59.38%] [G loss: 0.910141]\n",
      "epoch:36 step:33858 [D loss: 0.654799, acc.: 59.38%] [G loss: 0.940544]\n",
      "epoch:36 step:33859 [D loss: 0.630639, acc.: 64.84%] [G loss: 0.961655]\n",
      "epoch:36 step:33860 [D loss: 0.615288, acc.: 66.41%] [G loss: 0.908086]\n",
      "epoch:36 step:33861 [D loss: 0.634189, acc.: 63.28%] [G loss: 0.932290]\n",
      "epoch:36 step:33862 [D loss: 0.594489, acc.: 70.31%] [G loss: 0.869712]\n",
      "epoch:36 step:33863 [D loss: 0.626343, acc.: 66.41%] [G loss: 1.000094]\n",
      "epoch:36 step:33864 [D loss: 0.663473, acc.: 60.16%] [G loss: 0.972630]\n",
      "epoch:36 step:33865 [D loss: 0.623621, acc.: 67.97%] [G loss: 0.946678]\n",
      "epoch:36 step:33866 [D loss: 0.682248, acc.: 60.94%] [G loss: 0.950646]\n",
      "epoch:36 step:33867 [D loss: 0.651397, acc.: 64.06%] [G loss: 0.929606]\n",
      "epoch:36 step:33868 [D loss: 0.665282, acc.: 56.25%] [G loss: 0.927889]\n",
      "epoch:36 step:33869 [D loss: 0.654497, acc.: 63.28%] [G loss: 0.923095]\n",
      "epoch:36 step:33870 [D loss: 0.626099, acc.: 64.84%] [G loss: 0.931255]\n",
      "epoch:36 step:33871 [D loss: 0.699667, acc.: 50.00%] [G loss: 0.894433]\n",
      "epoch:36 step:33872 [D loss: 0.634469, acc.: 60.94%] [G loss: 0.908508]\n",
      "epoch:36 step:33873 [D loss: 0.657761, acc.: 61.72%] [G loss: 0.901127]\n",
      "epoch:36 step:33874 [D loss: 0.629945, acc.: 63.28%] [G loss: 0.966486]\n",
      "epoch:36 step:33875 [D loss: 0.629785, acc.: 64.84%] [G loss: 0.901915]\n",
      "epoch:36 step:33876 [D loss: 0.637185, acc.: 61.72%] [G loss: 0.960948]\n",
      "epoch:36 step:33877 [D loss: 0.656675, acc.: 57.81%] [G loss: 0.916908]\n",
      "epoch:36 step:33878 [D loss: 0.610737, acc.: 71.09%] [G loss: 0.909241]\n",
      "epoch:36 step:33879 [D loss: 0.652550, acc.: 57.03%] [G loss: 0.880720]\n",
      "epoch:36 step:33880 [D loss: 0.611409, acc.: 66.41%] [G loss: 0.916962]\n",
      "epoch:36 step:33881 [D loss: 0.674997, acc.: 57.03%] [G loss: 0.882994]\n",
      "epoch:36 step:33882 [D loss: 0.642588, acc.: 62.50%] [G loss: 0.925060]\n",
      "epoch:36 step:33883 [D loss: 0.635978, acc.: 59.38%] [G loss: 0.918214]\n",
      "epoch:36 step:33884 [D loss: 0.686569, acc.: 51.56%] [G loss: 0.925267]\n",
      "epoch:36 step:33885 [D loss: 0.623422, acc.: 64.84%] [G loss: 0.920158]\n",
      "epoch:36 step:33886 [D loss: 0.638927, acc.: 59.38%] [G loss: 0.979555]\n",
      "epoch:36 step:33887 [D loss: 0.683761, acc.: 58.59%] [G loss: 0.974255]\n",
      "epoch:36 step:33888 [D loss: 0.573717, acc.: 68.75%] [G loss: 0.974664]\n",
      "epoch:36 step:33889 [D loss: 0.660221, acc.: 60.16%] [G loss: 0.940010]\n",
      "epoch:36 step:33890 [D loss: 0.631983, acc.: 58.59%] [G loss: 0.921259]\n",
      "epoch:36 step:33891 [D loss: 0.612525, acc.: 70.31%] [G loss: 0.914003]\n",
      "epoch:36 step:33892 [D loss: 0.611070, acc.: 66.41%] [G loss: 0.853786]\n",
      "epoch:36 step:33893 [D loss: 0.618437, acc.: 63.28%] [G loss: 0.916241]\n",
      "epoch:36 step:33894 [D loss: 0.668872, acc.: 57.81%] [G loss: 0.840944]\n",
      "epoch:36 step:33895 [D loss: 0.627812, acc.: 64.84%] [G loss: 0.949048]\n",
      "epoch:36 step:33896 [D loss: 0.637416, acc.: 67.19%] [G loss: 0.913875]\n",
      "epoch:36 step:33897 [D loss: 0.644014, acc.: 63.28%] [G loss: 0.892719]\n",
      "epoch:36 step:33898 [D loss: 0.628753, acc.: 67.19%] [G loss: 0.923064]\n",
      "epoch:36 step:33899 [D loss: 0.640589, acc.: 59.38%] [G loss: 0.973941]\n",
      "epoch:36 step:33900 [D loss: 0.629065, acc.: 61.72%] [G loss: 0.948475]\n",
      "epoch:36 step:33901 [D loss: 0.653646, acc.: 57.81%] [G loss: 1.031599]\n",
      "epoch:36 step:33902 [D loss: 0.615561, acc.: 61.72%] [G loss: 0.968789]\n",
      "epoch:36 step:33903 [D loss: 0.704168, acc.: 52.34%] [G loss: 0.917367]\n",
      "epoch:36 step:33904 [D loss: 0.658825, acc.: 57.03%] [G loss: 0.951683]\n",
      "epoch:36 step:33905 [D loss: 0.637124, acc.: 61.72%] [G loss: 0.922955]\n",
      "epoch:36 step:33906 [D loss: 0.601070, acc.: 67.19%] [G loss: 0.913196]\n",
      "epoch:36 step:33907 [D loss: 0.657635, acc.: 57.03%] [G loss: 0.840074]\n",
      "epoch:36 step:33908 [D loss: 0.621173, acc.: 64.84%] [G loss: 0.877547]\n",
      "epoch:36 step:33909 [D loss: 0.622865, acc.: 60.16%] [G loss: 0.885920]\n",
      "epoch:36 step:33910 [D loss: 0.655845, acc.: 54.69%] [G loss: 0.903588]\n",
      "epoch:36 step:33911 [D loss: 0.620555, acc.: 64.06%] [G loss: 0.973490]\n",
      "epoch:36 step:33912 [D loss: 0.606876, acc.: 70.31%] [G loss: 0.986162]\n",
      "epoch:36 step:33913 [D loss: 0.658132, acc.: 57.81%] [G loss: 0.978199]\n",
      "epoch:36 step:33914 [D loss: 0.638107, acc.: 64.84%] [G loss: 0.950236]\n",
      "epoch:36 step:33915 [D loss: 0.687219, acc.: 50.78%] [G loss: 0.951682]\n",
      "epoch:36 step:33916 [D loss: 0.641192, acc.: 67.19%] [G loss: 0.955571]\n",
      "epoch:36 step:33917 [D loss: 0.652525, acc.: 59.38%] [G loss: 0.921474]\n",
      "epoch:36 step:33918 [D loss: 0.641579, acc.: 61.72%] [G loss: 0.888922]\n",
      "epoch:36 step:33919 [D loss: 0.614032, acc.: 69.53%] [G loss: 0.918067]\n",
      "epoch:36 step:33920 [D loss: 0.692133, acc.: 54.69%] [G loss: 0.890856]\n",
      "epoch:36 step:33921 [D loss: 0.658458, acc.: 62.50%] [G loss: 0.935459]\n",
      "epoch:36 step:33922 [D loss: 0.675659, acc.: 64.06%] [G loss: 0.940108]\n",
      "epoch:36 step:33923 [D loss: 0.671456, acc.: 57.03%] [G loss: 0.919852]\n",
      "epoch:36 step:33924 [D loss: 0.614751, acc.: 67.97%] [G loss: 0.929171]\n",
      "epoch:36 step:33925 [D loss: 0.614418, acc.: 67.19%] [G loss: 0.951717]\n",
      "epoch:36 step:33926 [D loss: 0.680396, acc.: 57.03%] [G loss: 0.923500]\n",
      "epoch:36 step:33927 [D loss: 0.633541, acc.: 65.62%] [G loss: 0.890101]\n",
      "epoch:36 step:33928 [D loss: 0.655083, acc.: 58.59%] [G loss: 0.963202]\n",
      "epoch:36 step:33929 [D loss: 0.634624, acc.: 61.72%] [G loss: 0.899908]\n",
      "epoch:36 step:33930 [D loss: 0.573585, acc.: 74.22%] [G loss: 0.981715]\n",
      "epoch:36 step:33931 [D loss: 0.633801, acc.: 69.53%] [G loss: 0.881046]\n",
      "epoch:36 step:33932 [D loss: 0.612395, acc.: 67.19%] [G loss: 0.951142]\n",
      "epoch:36 step:33933 [D loss: 0.657139, acc.: 64.06%] [G loss: 0.901383]\n",
      "epoch:36 step:33934 [D loss: 0.615942, acc.: 60.94%] [G loss: 0.918674]\n",
      "epoch:36 step:33935 [D loss: 0.632726, acc.: 64.06%] [G loss: 0.930838]\n",
      "epoch:36 step:33936 [D loss: 0.641578, acc.: 62.50%] [G loss: 1.010902]\n",
      "epoch:36 step:33937 [D loss: 0.668558, acc.: 62.50%] [G loss: 0.960524]\n",
      "epoch:36 step:33938 [D loss: 0.616537, acc.: 64.06%] [G loss: 0.993833]\n",
      "epoch:36 step:33939 [D loss: 0.658527, acc.: 61.72%] [G loss: 0.934511]\n",
      "epoch:36 step:33940 [D loss: 0.601730, acc.: 74.22%] [G loss: 1.027328]\n",
      "epoch:36 step:33941 [D loss: 0.626747, acc.: 69.53%] [G loss: 0.938605]\n",
      "epoch:36 step:33942 [D loss: 0.650624, acc.: 62.50%] [G loss: 0.973443]\n",
      "epoch:36 step:33943 [D loss: 0.654261, acc.: 60.16%] [G loss: 1.012603]\n",
      "epoch:36 step:33944 [D loss: 0.648463, acc.: 63.28%] [G loss: 0.997916]\n",
      "epoch:36 step:33945 [D loss: 0.680663, acc.: 52.34%] [G loss: 0.914857]\n",
      "epoch:36 step:33946 [D loss: 0.661270, acc.: 63.28%] [G loss: 0.953115]\n",
      "epoch:36 step:33947 [D loss: 0.682217, acc.: 60.16%] [G loss: 0.900720]\n",
      "epoch:36 step:33948 [D loss: 0.684923, acc.: 56.25%] [G loss: 0.920424]\n",
      "epoch:36 step:33949 [D loss: 0.623874, acc.: 61.72%] [G loss: 0.898117]\n",
      "epoch:36 step:33950 [D loss: 0.675988, acc.: 53.91%] [G loss: 0.942467]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:33951 [D loss: 0.661546, acc.: 57.03%] [G loss: 0.927148]\n",
      "epoch:36 step:33952 [D loss: 0.639885, acc.: 63.28%] [G loss: 0.906982]\n",
      "epoch:36 step:33953 [D loss: 0.607611, acc.: 67.19%] [G loss: 0.877527]\n",
      "epoch:36 step:33954 [D loss: 0.674469, acc.: 57.03%] [G loss: 0.886360]\n",
      "epoch:36 step:33955 [D loss: 0.655498, acc.: 66.41%] [G loss: 0.880412]\n",
      "epoch:36 step:33956 [D loss: 0.670658, acc.: 57.81%] [G loss: 0.940259]\n",
      "epoch:36 step:33957 [D loss: 0.630872, acc.: 64.84%] [G loss: 0.910850]\n",
      "epoch:36 step:33958 [D loss: 0.634535, acc.: 62.50%] [G loss: 0.981490]\n",
      "epoch:36 step:33959 [D loss: 0.631140, acc.: 64.06%] [G loss: 0.917581]\n",
      "epoch:36 step:33960 [D loss: 0.658460, acc.: 60.94%] [G loss: 0.948943]\n",
      "epoch:36 step:33961 [D loss: 0.625838, acc.: 64.06%] [G loss: 0.968230]\n",
      "epoch:36 step:33962 [D loss: 0.628095, acc.: 63.28%] [G loss: 0.883757]\n",
      "epoch:36 step:33963 [D loss: 0.648966, acc.: 59.38%] [G loss: 0.964884]\n",
      "epoch:36 step:33964 [D loss: 0.645670, acc.: 62.50%] [G loss: 1.034346]\n",
      "epoch:36 step:33965 [D loss: 0.651758, acc.: 57.81%] [G loss: 0.992876]\n",
      "epoch:36 step:33966 [D loss: 0.675249, acc.: 58.59%] [G loss: 0.982257]\n",
      "epoch:36 step:33967 [D loss: 0.648353, acc.: 60.94%] [G loss: 0.893606]\n",
      "epoch:36 step:33968 [D loss: 0.670129, acc.: 55.47%] [G loss: 0.932750]\n",
      "epoch:36 step:33969 [D loss: 0.667583, acc.: 59.38%] [G loss: 0.925011]\n",
      "epoch:36 step:33970 [D loss: 0.642089, acc.: 60.16%] [G loss: 0.911458]\n",
      "epoch:36 step:33971 [D loss: 0.632663, acc.: 59.38%] [G loss: 0.921003]\n",
      "epoch:36 step:33972 [D loss: 0.620521, acc.: 65.62%] [G loss: 0.920399]\n",
      "epoch:36 step:33973 [D loss: 0.638744, acc.: 60.16%] [G loss: 0.906635]\n",
      "epoch:36 step:33974 [D loss: 0.660194, acc.: 57.81%] [G loss: 0.944375]\n",
      "epoch:36 step:33975 [D loss: 0.638356, acc.: 64.06%] [G loss: 0.954470]\n",
      "epoch:36 step:33976 [D loss: 0.668778, acc.: 62.50%] [G loss: 0.937648]\n",
      "epoch:36 step:33977 [D loss: 0.676849, acc.: 57.81%] [G loss: 0.920919]\n",
      "epoch:36 step:33978 [D loss: 0.662599, acc.: 61.72%] [G loss: 0.890101]\n",
      "epoch:36 step:33979 [D loss: 0.642124, acc.: 61.72%] [G loss: 0.878022]\n",
      "epoch:36 step:33980 [D loss: 0.638294, acc.: 62.50%] [G loss: 0.957122]\n",
      "epoch:36 step:33981 [D loss: 0.628276, acc.: 68.75%] [G loss: 0.946746]\n",
      "epoch:36 step:33982 [D loss: 0.650058, acc.: 63.28%] [G loss: 0.921968]\n",
      "epoch:36 step:33983 [D loss: 0.643853, acc.: 59.38%] [G loss: 0.917686]\n",
      "epoch:36 step:33984 [D loss: 0.666509, acc.: 58.59%] [G loss: 0.933108]\n",
      "epoch:36 step:33985 [D loss: 0.619279, acc.: 64.06%] [G loss: 0.969262]\n",
      "epoch:36 step:33986 [D loss: 0.627054, acc.: 65.62%] [G loss: 0.971183]\n",
      "epoch:36 step:33987 [D loss: 0.636014, acc.: 64.84%] [G loss: 0.937911]\n",
      "epoch:36 step:33988 [D loss: 0.636099, acc.: 65.62%] [G loss: 0.923902]\n",
      "epoch:36 step:33989 [D loss: 0.618785, acc.: 63.28%] [G loss: 0.902656]\n",
      "epoch:36 step:33990 [D loss: 0.630870, acc.: 61.72%] [G loss: 0.982467]\n",
      "epoch:36 step:33991 [D loss: 0.680344, acc.: 53.12%] [G loss: 1.034379]\n",
      "epoch:36 step:33992 [D loss: 0.624534, acc.: 66.41%] [G loss: 0.951915]\n",
      "epoch:36 step:33993 [D loss: 0.696024, acc.: 54.69%] [G loss: 0.975327]\n",
      "epoch:36 step:33994 [D loss: 0.690813, acc.: 54.69%] [G loss: 0.935092]\n",
      "epoch:36 step:33995 [D loss: 0.633853, acc.: 60.16%] [G loss: 0.993176]\n",
      "epoch:36 step:33996 [D loss: 0.688557, acc.: 57.81%] [G loss: 0.952298]\n",
      "epoch:36 step:33997 [D loss: 0.640756, acc.: 58.59%] [G loss: 0.948902]\n",
      "epoch:36 step:33998 [D loss: 0.611226, acc.: 72.66%] [G loss: 0.970207]\n",
      "epoch:36 step:33999 [D loss: 0.631178, acc.: 64.06%] [G loss: 0.899938]\n",
      "epoch:36 step:34000 [D loss: 0.619942, acc.: 65.62%] [G loss: 0.928350]\n",
      "##############\n",
      "[ 2.93580153  2.06382373  2.01033752  3.88787252  1.05882938 10.27426719\n",
      "  2.55244027  3.44250295  3.93948209  8.14868929]\n",
      "##########\n",
      "epoch:36 step:34001 [D loss: 0.620704, acc.: 62.50%] [G loss: 0.953520]\n",
      "epoch:36 step:34002 [D loss: 0.649934, acc.: 58.59%] [G loss: 0.941336]\n",
      "epoch:36 step:34003 [D loss: 0.623927, acc.: 61.72%] [G loss: 0.961434]\n",
      "epoch:36 step:34004 [D loss: 0.671969, acc.: 57.03%] [G loss: 0.976096]\n",
      "epoch:36 step:34005 [D loss: 0.648198, acc.: 63.28%] [G loss: 0.991398]\n",
      "epoch:36 step:34006 [D loss: 0.645616, acc.: 56.25%] [G loss: 0.985401]\n",
      "epoch:36 step:34007 [D loss: 0.650118, acc.: 57.03%] [G loss: 0.877731]\n",
      "epoch:36 step:34008 [D loss: 0.626803, acc.: 64.06%] [G loss: 0.940603]\n",
      "epoch:36 step:34009 [D loss: 0.629838, acc.: 60.94%] [G loss: 0.949995]\n",
      "epoch:36 step:34010 [D loss: 0.643100, acc.: 65.62%] [G loss: 0.945723]\n",
      "epoch:36 step:34011 [D loss: 0.675004, acc.: 63.28%] [G loss: 0.914596]\n",
      "epoch:36 step:34012 [D loss: 0.684315, acc.: 60.16%] [G loss: 0.895457]\n",
      "epoch:36 step:34013 [D loss: 0.581622, acc.: 72.66%] [G loss: 0.915413]\n",
      "epoch:36 step:34014 [D loss: 0.631576, acc.: 67.19%] [G loss: 0.880492]\n",
      "epoch:36 step:34015 [D loss: 0.650683, acc.: 60.16%] [G loss: 0.959071]\n",
      "epoch:36 step:34016 [D loss: 0.637156, acc.: 65.62%] [G loss: 0.910651]\n",
      "epoch:36 step:34017 [D loss: 0.638200, acc.: 68.75%] [G loss: 0.946215]\n",
      "epoch:36 step:34018 [D loss: 0.629497, acc.: 65.62%] [G loss: 0.981566]\n",
      "epoch:36 step:34019 [D loss: 0.618533, acc.: 71.88%] [G loss: 0.943966]\n",
      "epoch:36 step:34020 [D loss: 0.649244, acc.: 59.38%] [G loss: 0.974985]\n",
      "epoch:36 step:34021 [D loss: 0.680913, acc.: 56.25%] [G loss: 0.944273]\n",
      "epoch:36 step:34022 [D loss: 0.559549, acc.: 72.66%] [G loss: 1.048041]\n",
      "epoch:36 step:34023 [D loss: 0.630732, acc.: 64.06%] [G loss: 0.969392]\n",
      "epoch:36 step:34024 [D loss: 0.666749, acc.: 61.72%] [G loss: 0.931229]\n",
      "epoch:36 step:34025 [D loss: 0.644439, acc.: 62.50%] [G loss: 0.917190]\n",
      "epoch:36 step:34026 [D loss: 0.666054, acc.: 58.59%] [G loss: 0.898038]\n",
      "epoch:36 step:34027 [D loss: 0.686538, acc.: 55.47%] [G loss: 0.877669]\n",
      "epoch:36 step:34028 [D loss: 0.596724, acc.: 67.19%] [G loss: 0.909114]\n",
      "epoch:36 step:34029 [D loss: 0.618035, acc.: 66.41%] [G loss: 0.948235]\n",
      "epoch:36 step:34030 [D loss: 0.618215, acc.: 68.75%] [G loss: 0.942543]\n",
      "epoch:36 step:34031 [D loss: 0.705687, acc.: 53.91%] [G loss: 0.892665]\n",
      "epoch:36 step:34032 [D loss: 0.630171, acc.: 63.28%] [G loss: 0.919721]\n",
      "epoch:36 step:34033 [D loss: 0.701944, acc.: 52.34%] [G loss: 0.974047]\n",
      "epoch:36 step:34034 [D loss: 0.644354, acc.: 60.16%] [G loss: 1.018709]\n",
      "epoch:36 step:34035 [D loss: 0.644976, acc.: 66.41%] [G loss: 0.952314]\n",
      "epoch:36 step:34036 [D loss: 0.613499, acc.: 68.75%] [G loss: 1.012479]\n",
      "epoch:36 step:34037 [D loss: 0.681593, acc.: 53.91%] [G loss: 0.930430]\n",
      "epoch:36 step:34038 [D loss: 0.655918, acc.: 63.28%] [G loss: 0.948512]\n",
      "epoch:36 step:34039 [D loss: 0.694936, acc.: 53.12%] [G loss: 0.949081]\n",
      "epoch:36 step:34040 [D loss: 0.608924, acc.: 67.97%] [G loss: 0.925039]\n",
      "epoch:36 step:34041 [D loss: 0.640402, acc.: 62.50%] [G loss: 0.933147]\n",
      "epoch:36 step:34042 [D loss: 0.596008, acc.: 71.88%] [G loss: 0.955991]\n",
      "epoch:36 step:34043 [D loss: 0.622249, acc.: 61.72%] [G loss: 1.000154]\n",
      "epoch:36 step:34044 [D loss: 0.633922, acc.: 60.94%] [G loss: 0.951063]\n",
      "epoch:36 step:34045 [D loss: 0.664084, acc.: 62.50%] [G loss: 0.939605]\n",
      "epoch:36 step:34046 [D loss: 0.645074, acc.: 61.72%] [G loss: 0.928121]\n",
      "epoch:36 step:34047 [D loss: 0.634242, acc.: 65.62%] [G loss: 0.894091]\n",
      "epoch:36 step:34048 [D loss: 0.649025, acc.: 62.50%] [G loss: 0.916277]\n",
      "epoch:36 step:34049 [D loss: 0.634969, acc.: 64.06%] [G loss: 0.934172]\n",
      "epoch:36 step:34050 [D loss: 0.626817, acc.: 60.16%] [G loss: 0.899907]\n",
      "epoch:36 step:34051 [D loss: 0.688692, acc.: 57.03%] [G loss: 0.975762]\n",
      "epoch:36 step:34052 [D loss: 0.669220, acc.: 56.25%] [G loss: 0.937541]\n",
      "epoch:36 step:34053 [D loss: 0.648020, acc.: 58.59%] [G loss: 0.959335]\n",
      "epoch:36 step:34054 [D loss: 0.657546, acc.: 58.59%] [G loss: 0.942733]\n",
      "epoch:36 step:34055 [D loss: 0.694384, acc.: 53.12%] [G loss: 0.954651]\n",
      "epoch:36 step:34056 [D loss: 0.631585, acc.: 62.50%] [G loss: 0.897204]\n",
      "epoch:36 step:34057 [D loss: 0.678935, acc.: 58.59%] [G loss: 0.981023]\n",
      "epoch:36 step:34058 [D loss: 0.680854, acc.: 57.81%] [G loss: 0.901285]\n",
      "epoch:36 step:34059 [D loss: 0.580669, acc.: 67.97%] [G loss: 0.919580]\n",
      "epoch:36 step:34060 [D loss: 0.635870, acc.: 67.19%] [G loss: 0.896643]\n",
      "epoch:36 step:34061 [D loss: 0.628058, acc.: 65.62%] [G loss: 0.848109]\n",
      "epoch:36 step:34062 [D loss: 0.658251, acc.: 60.16%] [G loss: 0.887012]\n",
      "epoch:36 step:34063 [D loss: 0.680739, acc.: 53.12%] [G loss: 0.909077]\n",
      "epoch:36 step:34064 [D loss: 0.597318, acc.: 69.53%] [G loss: 0.929202]\n",
      "epoch:36 step:34065 [D loss: 0.640406, acc.: 63.28%] [G loss: 0.915507]\n",
      "epoch:36 step:34066 [D loss: 0.659121, acc.: 55.47%] [G loss: 0.870225]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:34067 [D loss: 0.662856, acc.: 60.16%] [G loss: 0.908117]\n",
      "epoch:36 step:34068 [D loss: 0.606117, acc.: 65.62%] [G loss: 0.917759]\n",
      "epoch:36 step:34069 [D loss: 0.628175, acc.: 60.94%] [G loss: 0.907079]\n",
      "epoch:36 step:34070 [D loss: 0.635423, acc.: 62.50%] [G loss: 0.969229]\n",
      "epoch:36 step:34071 [D loss: 0.603105, acc.: 63.28%] [G loss: 0.983988]\n",
      "epoch:36 step:34072 [D loss: 0.653591, acc.: 57.81%] [G loss: 0.947781]\n",
      "epoch:36 step:34073 [D loss: 0.634995, acc.: 61.72%] [G loss: 0.973516]\n",
      "epoch:36 step:34074 [D loss: 0.614811, acc.: 64.06%] [G loss: 0.957942]\n",
      "epoch:36 step:34075 [D loss: 0.671629, acc.: 57.81%] [G loss: 0.974397]\n",
      "epoch:36 step:34076 [D loss: 0.625285, acc.: 63.28%] [G loss: 0.975435]\n",
      "epoch:36 step:34077 [D loss: 0.628923, acc.: 61.72%] [G loss: 0.895194]\n",
      "epoch:36 step:34078 [D loss: 0.688158, acc.: 57.03%] [G loss: 0.937688]\n",
      "epoch:36 step:34079 [D loss: 0.581273, acc.: 68.75%] [G loss: 0.923392]\n",
      "epoch:36 step:34080 [D loss: 0.624288, acc.: 67.19%] [G loss: 0.903932]\n",
      "epoch:36 step:34081 [D loss: 0.608934, acc.: 67.19%] [G loss: 0.909924]\n",
      "epoch:36 step:34082 [D loss: 0.686442, acc.: 50.78%] [G loss: 0.950889]\n",
      "epoch:36 step:34083 [D loss: 0.616913, acc.: 65.62%] [G loss: 0.956185]\n",
      "epoch:36 step:34084 [D loss: 0.649497, acc.: 66.41%] [G loss: 0.893041]\n",
      "epoch:36 step:34085 [D loss: 0.642357, acc.: 60.16%] [G loss: 0.971848]\n",
      "epoch:36 step:34086 [D loss: 0.699792, acc.: 52.34%] [G loss: 0.915204]\n",
      "epoch:36 step:34087 [D loss: 0.643943, acc.: 67.19%] [G loss: 0.894803]\n",
      "epoch:36 step:34088 [D loss: 0.641854, acc.: 65.62%] [G loss: 0.973918]\n",
      "epoch:36 step:34089 [D loss: 0.655332, acc.: 57.03%] [G loss: 0.905472]\n",
      "epoch:36 step:34090 [D loss: 0.649238, acc.: 64.06%] [G loss: 0.981801]\n",
      "epoch:36 step:34091 [D loss: 0.641533, acc.: 64.06%] [G loss: 0.885608]\n",
      "epoch:36 step:34092 [D loss: 0.617111, acc.: 66.41%] [G loss: 0.953990]\n",
      "epoch:36 step:34093 [D loss: 0.595846, acc.: 71.09%] [G loss: 0.945042]\n",
      "epoch:36 step:34094 [D loss: 0.625913, acc.: 64.06%] [G loss: 0.987477]\n",
      "epoch:36 step:34095 [D loss: 0.643975, acc.: 62.50%] [G loss: 0.959113]\n",
      "epoch:36 step:34096 [D loss: 0.609417, acc.: 67.97%] [G loss: 0.974656]\n",
      "epoch:36 step:34097 [D loss: 0.664282, acc.: 57.03%] [G loss: 0.986973]\n",
      "epoch:36 step:34098 [D loss: 0.657236, acc.: 62.50%] [G loss: 0.979527]\n",
      "epoch:36 step:34099 [D loss: 0.668889, acc.: 54.69%] [G loss: 0.927201]\n",
      "epoch:36 step:34100 [D loss: 0.670323, acc.: 54.69%] [G loss: 0.936287]\n",
      "epoch:36 step:34101 [D loss: 0.669600, acc.: 60.94%] [G loss: 0.925899]\n",
      "epoch:36 step:34102 [D loss: 0.610740, acc.: 67.97%] [G loss: 0.918546]\n",
      "epoch:36 step:34103 [D loss: 0.623672, acc.: 59.38%] [G loss: 0.902866]\n",
      "epoch:36 step:34104 [D loss: 0.635093, acc.: 65.62%] [G loss: 0.923350]\n",
      "epoch:36 step:34105 [D loss: 0.619424, acc.: 63.28%] [G loss: 0.935489]\n",
      "epoch:36 step:34106 [D loss: 0.635261, acc.: 65.62%] [G loss: 0.922300]\n",
      "epoch:36 step:34107 [D loss: 0.617530, acc.: 67.97%] [G loss: 0.957187]\n",
      "epoch:36 step:34108 [D loss: 0.663914, acc.: 61.72%] [G loss: 0.836775]\n",
      "epoch:36 step:34109 [D loss: 0.656122, acc.: 55.47%] [G loss: 0.906264]\n",
      "epoch:36 step:34110 [D loss: 0.597695, acc.: 66.41%] [G loss: 0.935497]\n",
      "epoch:36 step:34111 [D loss: 0.631751, acc.: 65.62%] [G loss: 0.975637]\n",
      "epoch:36 step:34112 [D loss: 0.645754, acc.: 61.72%] [G loss: 0.916458]\n",
      "epoch:36 step:34113 [D loss: 0.673577, acc.: 54.69%] [G loss: 0.890968]\n",
      "epoch:36 step:34114 [D loss: 0.636058, acc.: 64.06%] [G loss: 0.885152]\n",
      "epoch:36 step:34115 [D loss: 0.648960, acc.: 57.81%] [G loss: 0.920112]\n",
      "epoch:36 step:34116 [D loss: 0.657995, acc.: 60.16%] [G loss: 0.952950]\n",
      "epoch:36 step:34117 [D loss: 0.695318, acc.: 57.03%] [G loss: 0.980847]\n",
      "epoch:36 step:34118 [D loss: 0.592483, acc.: 71.09%] [G loss: 0.956608]\n",
      "epoch:36 step:34119 [D loss: 0.647097, acc.: 62.50%] [G loss: 0.964784]\n",
      "epoch:36 step:34120 [D loss: 0.693887, acc.: 53.12%] [G loss: 0.875573]\n",
      "epoch:36 step:34121 [D loss: 0.628973, acc.: 65.62%] [G loss: 0.924063]\n",
      "epoch:36 step:34122 [D loss: 0.684949, acc.: 58.59%] [G loss: 0.931134]\n",
      "epoch:36 step:34123 [D loss: 0.629044, acc.: 66.41%] [G loss: 0.925112]\n",
      "epoch:36 step:34124 [D loss: 0.631744, acc.: 65.62%] [G loss: 0.939217]\n",
      "epoch:36 step:34125 [D loss: 0.687323, acc.: 53.12%] [G loss: 0.976091]\n",
      "epoch:36 step:34126 [D loss: 0.648678, acc.: 60.94%] [G loss: 0.924507]\n",
      "epoch:36 step:34127 [D loss: 0.647045, acc.: 63.28%] [G loss: 0.879790]\n",
      "epoch:36 step:34128 [D loss: 0.655114, acc.: 57.81%] [G loss: 0.881303]\n",
      "epoch:36 step:34129 [D loss: 0.648033, acc.: 63.28%] [G loss: 0.876259]\n",
      "epoch:36 step:34130 [D loss: 0.653829, acc.: 60.16%] [G loss: 0.895362]\n",
      "epoch:36 step:34131 [D loss: 0.601508, acc.: 65.62%] [G loss: 1.001022]\n",
      "epoch:36 step:34132 [D loss: 0.603842, acc.: 65.62%] [G loss: 0.968690]\n",
      "epoch:36 step:34133 [D loss: 0.640663, acc.: 60.94%] [G loss: 0.994759]\n",
      "epoch:36 step:34134 [D loss: 0.592212, acc.: 71.88%] [G loss: 1.054077]\n",
      "epoch:36 step:34135 [D loss: 0.630896, acc.: 64.84%] [G loss: 0.941445]\n",
      "epoch:36 step:34136 [D loss: 0.609066, acc.: 65.62%] [G loss: 0.881725]\n",
      "epoch:36 step:34137 [D loss: 0.644354, acc.: 58.59%] [G loss: 0.900317]\n",
      "epoch:36 step:34138 [D loss: 0.613481, acc.: 64.06%] [G loss: 0.956804]\n",
      "epoch:36 step:34139 [D loss: 0.604531, acc.: 67.97%] [G loss: 0.917814]\n",
      "epoch:36 step:34140 [D loss: 0.650036, acc.: 67.19%] [G loss: 0.886404]\n",
      "epoch:36 step:34141 [D loss: 0.676264, acc.: 59.38%] [G loss: 0.955188]\n",
      "epoch:36 step:34142 [D loss: 0.680871, acc.: 57.81%] [G loss: 0.902616]\n",
      "epoch:36 step:34143 [D loss: 0.649508, acc.: 62.50%] [G loss: 0.947088]\n",
      "epoch:36 step:34144 [D loss: 0.623960, acc.: 70.31%] [G loss: 0.967497]\n",
      "epoch:36 step:34145 [D loss: 0.669964, acc.: 57.81%] [G loss: 0.971021]\n",
      "epoch:36 step:34146 [D loss: 0.640049, acc.: 66.41%] [G loss: 0.965095]\n",
      "epoch:36 step:34147 [D loss: 0.595411, acc.: 70.31%] [G loss: 0.969168]\n",
      "epoch:36 step:34148 [D loss: 0.664631, acc.: 58.59%] [G loss: 0.919830]\n",
      "epoch:36 step:34149 [D loss: 0.603634, acc.: 67.97%] [G loss: 0.870843]\n",
      "epoch:36 step:34150 [D loss: 0.647553, acc.: 60.16%] [G loss: 0.942565]\n",
      "epoch:36 step:34151 [D loss: 0.676511, acc.: 55.47%] [G loss: 0.893451]\n",
      "epoch:36 step:34152 [D loss: 0.650101, acc.: 63.28%] [G loss: 0.958288]\n",
      "epoch:36 step:34153 [D loss: 0.608728, acc.: 68.75%] [G loss: 0.944083]\n",
      "epoch:36 step:34154 [D loss: 0.623710, acc.: 68.75%] [G loss: 1.000530]\n",
      "epoch:36 step:34155 [D loss: 0.599723, acc.: 70.31%] [G loss: 0.928741]\n",
      "epoch:36 step:34156 [D loss: 0.611618, acc.: 64.06%] [G loss: 0.972841]\n",
      "epoch:36 step:34157 [D loss: 0.679541, acc.: 55.47%] [G loss: 0.914235]\n",
      "epoch:36 step:34158 [D loss: 0.654162, acc.: 67.97%] [G loss: 0.903834]\n",
      "epoch:36 step:34159 [D loss: 0.616387, acc.: 67.19%] [G loss: 0.927166]\n",
      "epoch:36 step:34160 [D loss: 0.642911, acc.: 62.50%] [G loss: 0.861578]\n",
      "epoch:36 step:34161 [D loss: 0.638694, acc.: 65.62%] [G loss: 0.947012]\n",
      "epoch:36 step:34162 [D loss: 0.689382, acc.: 53.12%] [G loss: 0.887837]\n",
      "epoch:36 step:34163 [D loss: 0.694008, acc.: 53.12%] [G loss: 0.959105]\n",
      "epoch:36 step:34164 [D loss: 0.637875, acc.: 65.62%] [G loss: 0.913297]\n",
      "epoch:36 step:34165 [D loss: 0.673897, acc.: 59.38%] [G loss: 0.915832]\n",
      "epoch:36 step:34166 [D loss: 0.678774, acc.: 58.59%] [G loss: 1.071161]\n",
      "epoch:36 step:34167 [D loss: 0.645625, acc.: 63.28%] [G loss: 0.967165]\n",
      "epoch:36 step:34168 [D loss: 0.652861, acc.: 67.19%] [G loss: 0.964246]\n",
      "epoch:36 step:34169 [D loss: 0.626498, acc.: 67.19%] [G loss: 0.922652]\n",
      "epoch:36 step:34170 [D loss: 0.642983, acc.: 60.16%] [G loss: 0.965904]\n",
      "epoch:36 step:34171 [D loss: 0.621034, acc.: 67.19%] [G loss: 0.887158]\n",
      "epoch:36 step:34172 [D loss: 0.623143, acc.: 67.19%] [G loss: 0.855505]\n",
      "epoch:36 step:34173 [D loss: 0.686131, acc.: 55.47%] [G loss: 0.922889]\n",
      "epoch:36 step:34174 [D loss: 0.673664, acc.: 59.38%] [G loss: 0.919068]\n",
      "epoch:36 step:34175 [D loss: 0.635985, acc.: 62.50%] [G loss: 0.966438]\n",
      "epoch:36 step:34176 [D loss: 0.635949, acc.: 59.38%] [G loss: 0.974345]\n",
      "epoch:36 step:34177 [D loss: 0.632414, acc.: 67.97%] [G loss: 0.953460]\n",
      "epoch:36 step:34178 [D loss: 0.657659, acc.: 61.72%] [G loss: 0.917439]\n",
      "epoch:36 step:34179 [D loss: 0.619982, acc.: 66.41%] [G loss: 0.914348]\n",
      "epoch:36 step:34180 [D loss: 0.678187, acc.: 57.03%] [G loss: 0.922069]\n",
      "epoch:36 step:34181 [D loss: 0.691305, acc.: 56.25%] [G loss: 0.940639]\n",
      "epoch:36 step:34182 [D loss: 0.635349, acc.: 67.97%] [G loss: 0.947686]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:34183 [D loss: 0.618959, acc.: 63.28%] [G loss: 0.956139]\n",
      "epoch:36 step:34184 [D loss: 0.630079, acc.: 64.84%] [G loss: 0.947113]\n",
      "epoch:36 step:34185 [D loss: 0.614065, acc.: 66.41%] [G loss: 0.967545]\n",
      "epoch:36 step:34186 [D loss: 0.658290, acc.: 53.91%] [G loss: 0.952280]\n",
      "epoch:36 step:34187 [D loss: 0.644406, acc.: 64.84%] [G loss: 0.957691]\n",
      "epoch:36 step:34188 [D loss: 0.642630, acc.: 60.94%] [G loss: 0.914380]\n",
      "epoch:36 step:34189 [D loss: 0.665123, acc.: 59.38%] [G loss: 0.921729]\n",
      "epoch:36 step:34190 [D loss: 0.658589, acc.: 55.47%] [G loss: 0.922098]\n",
      "epoch:36 step:34191 [D loss: 0.620967, acc.: 67.97%] [G loss: 0.876893]\n",
      "epoch:36 step:34192 [D loss: 0.598059, acc.: 66.41%] [G loss: 0.961684]\n",
      "epoch:36 step:34193 [D loss: 0.647147, acc.: 56.25%] [G loss: 0.987897]\n",
      "epoch:36 step:34194 [D loss: 0.645432, acc.: 59.38%] [G loss: 0.984621]\n",
      "epoch:36 step:34195 [D loss: 0.634397, acc.: 63.28%] [G loss: 0.907066]\n",
      "epoch:36 step:34196 [D loss: 0.652364, acc.: 65.62%] [G loss: 0.889369]\n",
      "epoch:36 step:34197 [D loss: 0.658728, acc.: 64.06%] [G loss: 0.915140]\n",
      "epoch:36 step:34198 [D loss: 0.625490, acc.: 66.41%] [G loss: 0.911559]\n",
      "epoch:36 step:34199 [D loss: 0.601592, acc.: 67.19%] [G loss: 0.933109]\n",
      "epoch:36 step:34200 [D loss: 0.634830, acc.: 63.28%] [G loss: 0.955945]\n",
      "##############\n",
      "[ 3.02246408  2.44290857  2.22362385  3.81972958  1.23221696 10.27426719\n",
      "  2.73558248  3.61254718  4.38222501  8.14868929]\n",
      "##########\n",
      "epoch:36 step:34201 [D loss: 0.653051, acc.: 60.94%] [G loss: 0.933762]\n",
      "epoch:36 step:34202 [D loss: 0.690125, acc.: 57.81%] [G loss: 0.928593]\n",
      "epoch:36 step:34203 [D loss: 0.587951, acc.: 73.44%] [G loss: 0.938561]\n",
      "epoch:36 step:34204 [D loss: 0.626600, acc.: 64.84%] [G loss: 1.003625]\n",
      "epoch:36 step:34205 [D loss: 0.591500, acc.: 70.31%] [G loss: 0.933793]\n",
      "epoch:36 step:34206 [D loss: 0.631629, acc.: 66.41%] [G loss: 0.935867]\n",
      "epoch:36 step:34207 [D loss: 0.649356, acc.: 64.84%] [G loss: 0.871583]\n",
      "epoch:36 step:34208 [D loss: 0.645067, acc.: 58.59%] [G loss: 0.966103]\n",
      "epoch:36 step:34209 [D loss: 0.650629, acc.: 60.16%] [G loss: 0.988921]\n",
      "epoch:36 step:34210 [D loss: 0.653884, acc.: 63.28%] [G loss: 0.925945]\n",
      "epoch:36 step:34211 [D loss: 0.678396, acc.: 53.12%] [G loss: 0.934606]\n",
      "epoch:36 step:34212 [D loss: 0.672824, acc.: 59.38%] [G loss: 0.911225]\n",
      "epoch:36 step:34213 [D loss: 0.660494, acc.: 57.03%] [G loss: 0.911020]\n",
      "epoch:36 step:34214 [D loss: 0.635248, acc.: 63.28%] [G loss: 0.917135]\n",
      "epoch:36 step:34215 [D loss: 0.632037, acc.: 68.75%] [G loss: 0.956125]\n",
      "epoch:36 step:34216 [D loss: 0.645122, acc.: 64.06%] [G loss: 0.927481]\n",
      "epoch:36 step:34217 [D loss: 0.572873, acc.: 75.00%] [G loss: 0.914661]\n",
      "epoch:36 step:34218 [D loss: 0.650149, acc.: 56.25%] [G loss: 0.923927]\n",
      "epoch:36 step:34219 [D loss: 0.641708, acc.: 66.41%] [G loss: 0.865589]\n",
      "epoch:36 step:34220 [D loss: 0.577443, acc.: 73.44%] [G loss: 0.978957]\n",
      "epoch:36 step:34221 [D loss: 0.645014, acc.: 60.94%] [G loss: 0.934875]\n",
      "epoch:36 step:34222 [D loss: 0.676409, acc.: 60.16%] [G loss: 0.971072]\n",
      "epoch:36 step:34223 [D loss: 0.679824, acc.: 54.69%] [G loss: 0.892825]\n",
      "epoch:36 step:34224 [D loss: 0.662975, acc.: 63.28%] [G loss: 0.921261]\n",
      "epoch:36 step:34225 [D loss: 0.629629, acc.: 65.62%] [G loss: 0.958789]\n",
      "epoch:36 step:34226 [D loss: 0.643243, acc.: 60.16%] [G loss: 0.956986]\n",
      "epoch:36 step:34227 [D loss: 0.644991, acc.: 58.59%] [G loss: 0.889826]\n",
      "epoch:36 step:34228 [D loss: 0.635444, acc.: 61.72%] [G loss: 0.920147]\n",
      "epoch:36 step:34229 [D loss: 0.678790, acc.: 60.16%] [G loss: 0.926918]\n",
      "epoch:36 step:34230 [D loss: 0.652363, acc.: 62.50%] [G loss: 0.911611]\n",
      "epoch:36 step:34231 [D loss: 0.633552, acc.: 66.41%] [G loss: 0.948736]\n",
      "epoch:36 step:34232 [D loss: 0.654921, acc.: 60.94%] [G loss: 0.887829]\n",
      "epoch:36 step:34233 [D loss: 0.667628, acc.: 58.59%] [G loss: 0.885549]\n",
      "epoch:36 step:34234 [D loss: 0.664386, acc.: 62.50%] [G loss: 0.910176]\n",
      "epoch:36 step:34235 [D loss: 0.613192, acc.: 68.75%] [G loss: 0.935461]\n",
      "epoch:36 step:34236 [D loss: 0.656144, acc.: 64.06%] [G loss: 0.932218]\n",
      "epoch:36 step:34237 [D loss: 0.657606, acc.: 60.94%] [G loss: 0.919018]\n",
      "epoch:36 step:34238 [D loss: 0.656339, acc.: 62.50%] [G loss: 0.929136]\n",
      "epoch:36 step:34239 [D loss: 0.641568, acc.: 66.41%] [G loss: 0.940520]\n",
      "epoch:36 step:34240 [D loss: 0.617455, acc.: 67.19%] [G loss: 0.923636]\n",
      "epoch:36 step:34241 [D loss: 0.642789, acc.: 62.50%] [G loss: 0.981756]\n",
      "epoch:36 step:34242 [D loss: 0.621489, acc.: 58.59%] [G loss: 0.982314]\n",
      "epoch:36 step:34243 [D loss: 0.611815, acc.: 65.62%] [G loss: 0.887952]\n",
      "epoch:36 step:34244 [D loss: 0.656064, acc.: 60.16%] [G loss: 0.953654]\n",
      "epoch:36 step:34245 [D loss: 0.645659, acc.: 61.72%] [G loss: 0.911483]\n",
      "epoch:36 step:34246 [D loss: 0.650455, acc.: 60.94%] [G loss: 0.974889]\n",
      "epoch:36 step:34247 [D loss: 0.619822, acc.: 69.53%] [G loss: 0.993265]\n",
      "epoch:36 step:34248 [D loss: 0.659502, acc.: 64.84%] [G loss: 0.879071]\n",
      "epoch:36 step:34249 [D loss: 0.613541, acc.: 70.31%] [G loss: 0.900173]\n",
      "epoch:36 step:34250 [D loss: 0.667759, acc.: 66.41%] [G loss: 0.870601]\n",
      "epoch:36 step:34251 [D loss: 0.607372, acc.: 70.31%] [G loss: 0.976161]\n",
      "epoch:36 step:34252 [D loss: 0.618784, acc.: 67.97%] [G loss: 0.954723]\n",
      "epoch:36 step:34253 [D loss: 0.712150, acc.: 51.56%] [G loss: 0.942536]\n",
      "epoch:36 step:34254 [D loss: 0.614258, acc.: 60.16%] [G loss: 0.956359]\n",
      "epoch:36 step:34255 [D loss: 0.652691, acc.: 60.94%] [G loss: 1.002303]\n",
      "epoch:36 step:34256 [D loss: 0.650173, acc.: 63.28%] [G loss: 0.911205]\n",
      "epoch:36 step:34257 [D loss: 0.684676, acc.: 59.38%] [G loss: 0.926816]\n",
      "epoch:36 step:34258 [D loss: 0.641033, acc.: 63.28%] [G loss: 0.913254]\n",
      "epoch:36 step:34259 [D loss: 0.665530, acc.: 62.50%] [G loss: 0.868292]\n",
      "epoch:36 step:34260 [D loss: 0.661628, acc.: 64.06%] [G loss: 0.898851]\n",
      "epoch:36 step:34261 [D loss: 0.632291, acc.: 63.28%] [G loss: 0.924017]\n",
      "epoch:36 step:34262 [D loss: 0.633285, acc.: 62.50%] [G loss: 0.929332]\n",
      "epoch:36 step:34263 [D loss: 0.651946, acc.: 63.28%] [G loss: 0.909315]\n",
      "epoch:36 step:34264 [D loss: 0.662822, acc.: 57.81%] [G loss: 0.885216]\n",
      "epoch:36 step:34265 [D loss: 0.639260, acc.: 64.06%] [G loss: 0.992832]\n",
      "epoch:36 step:34266 [D loss: 0.706536, acc.: 50.78%] [G loss: 0.947457]\n",
      "epoch:36 step:34267 [D loss: 0.621160, acc.: 64.06%] [G loss: 0.932535]\n",
      "epoch:36 step:34268 [D loss: 0.673831, acc.: 57.81%] [G loss: 0.955281]\n",
      "epoch:36 step:34269 [D loss: 0.616709, acc.: 71.88%] [G loss: 0.904500]\n",
      "epoch:36 step:34270 [D loss: 0.683812, acc.: 55.47%] [G loss: 0.907515]\n",
      "epoch:36 step:34271 [D loss: 0.655818, acc.: 62.50%] [G loss: 0.928755]\n",
      "epoch:36 step:34272 [D loss: 0.670250, acc.: 61.72%] [G loss: 0.855661]\n",
      "epoch:36 step:34273 [D loss: 0.670502, acc.: 62.50%] [G loss: 0.936744]\n",
      "epoch:36 step:34274 [D loss: 0.622137, acc.: 67.97%] [G loss: 0.894155]\n",
      "epoch:36 step:34275 [D loss: 0.633377, acc.: 59.38%] [G loss: 0.947595]\n",
      "epoch:36 step:34276 [D loss: 0.661710, acc.: 59.38%] [G loss: 0.909433]\n",
      "epoch:36 step:34277 [D loss: 0.613229, acc.: 64.06%] [G loss: 0.892171]\n",
      "epoch:36 step:34278 [D loss: 0.658410, acc.: 53.91%] [G loss: 0.966142]\n",
      "epoch:36 step:34279 [D loss: 0.656316, acc.: 61.72%] [G loss: 0.922691]\n",
      "epoch:36 step:34280 [D loss: 0.652662, acc.: 56.25%] [G loss: 0.950602]\n",
      "epoch:36 step:34281 [D loss: 0.617732, acc.: 66.41%] [G loss: 0.893842]\n",
      "epoch:36 step:34282 [D loss: 0.665413, acc.: 58.59%] [G loss: 0.931662]\n",
      "epoch:36 step:34283 [D loss: 0.639996, acc.: 62.50%] [G loss: 0.931688]\n",
      "epoch:36 step:34284 [D loss: 0.631769, acc.: 62.50%] [G loss: 1.009560]\n",
      "epoch:36 step:34285 [D loss: 0.638046, acc.: 62.50%] [G loss: 1.023373]\n",
      "epoch:36 step:34286 [D loss: 0.667395, acc.: 59.38%] [G loss: 0.889736]\n",
      "epoch:36 step:34287 [D loss: 0.655064, acc.: 65.62%] [G loss: 0.864468]\n",
      "epoch:36 step:34288 [D loss: 0.649569, acc.: 61.72%] [G loss: 0.885460]\n",
      "epoch:36 step:34289 [D loss: 0.638820, acc.: 61.72%] [G loss: 0.900220]\n",
      "epoch:36 step:34290 [D loss: 0.613637, acc.: 65.62%] [G loss: 0.946714]\n",
      "epoch:36 step:34291 [D loss: 0.706793, acc.: 51.56%] [G loss: 0.948706]\n",
      "epoch:36 step:34292 [D loss: 0.650875, acc.: 57.03%] [G loss: 0.912326]\n",
      "epoch:36 step:34293 [D loss: 0.681492, acc.: 58.59%] [G loss: 0.927553]\n",
      "epoch:36 step:34294 [D loss: 0.624862, acc.: 62.50%] [G loss: 0.999347]\n",
      "epoch:36 step:34295 [D loss: 0.714831, acc.: 53.91%] [G loss: 0.922495]\n",
      "epoch:36 step:34296 [D loss: 0.655874, acc.: 57.81%] [G loss: 0.918768]\n",
      "epoch:36 step:34297 [D loss: 0.627519, acc.: 67.97%] [G loss: 0.912001]\n",
      "epoch:36 step:34298 [D loss: 0.615954, acc.: 64.84%] [G loss: 0.903816]\n",
      "epoch:36 step:34299 [D loss: 0.602014, acc.: 72.66%] [G loss: 0.959784]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:34300 [D loss: 0.674785, acc.: 58.59%] [G loss: 1.014636]\n",
      "epoch:36 step:34301 [D loss: 0.606054, acc.: 63.28%] [G loss: 1.017384]\n",
      "epoch:36 step:34302 [D loss: 0.618609, acc.: 70.31%] [G loss: 0.952544]\n",
      "epoch:36 step:34303 [D loss: 0.626738, acc.: 59.38%] [G loss: 0.854608]\n",
      "epoch:36 step:34304 [D loss: 0.706373, acc.: 53.91%] [G loss: 0.896926]\n",
      "epoch:36 step:34305 [D loss: 0.634968, acc.: 63.28%] [G loss: 0.881572]\n",
      "epoch:36 step:34306 [D loss: 0.667670, acc.: 56.25%] [G loss: 0.905100]\n",
      "epoch:36 step:34307 [D loss: 0.629658, acc.: 63.28%] [G loss: 0.937704]\n",
      "epoch:36 step:34308 [D loss: 0.622825, acc.: 67.19%] [G loss: 0.923024]\n",
      "epoch:36 step:34309 [D loss: 0.608884, acc.: 70.31%] [G loss: 0.904833]\n",
      "epoch:36 step:34310 [D loss: 0.628869, acc.: 62.50%] [G loss: 0.911117]\n",
      "epoch:36 step:34311 [D loss: 0.632678, acc.: 60.94%] [G loss: 0.864960]\n",
      "epoch:36 step:34312 [D loss: 0.660331, acc.: 50.78%] [G loss: 0.880067]\n",
      "epoch:36 step:34313 [D loss: 0.631315, acc.: 62.50%] [G loss: 0.950110]\n",
      "epoch:36 step:34314 [D loss: 0.611204, acc.: 64.84%] [G loss: 0.939219]\n",
      "epoch:36 step:34315 [D loss: 0.641251, acc.: 62.50%] [G loss: 0.950285]\n",
      "epoch:36 step:34316 [D loss: 0.675046, acc.: 57.81%] [G loss: 0.928219]\n",
      "epoch:36 step:34317 [D loss: 0.632429, acc.: 69.53%] [G loss: 0.970736]\n",
      "epoch:36 step:34318 [D loss: 0.642581, acc.: 61.72%] [G loss: 0.899392]\n",
      "epoch:36 step:34319 [D loss: 0.683308, acc.: 51.56%] [G loss: 0.968031]\n",
      "epoch:36 step:34320 [D loss: 0.687066, acc.: 55.47%] [G loss: 0.935032]\n",
      "epoch:36 step:34321 [D loss: 0.625068, acc.: 64.84%] [G loss: 0.969272]\n",
      "epoch:36 step:34322 [D loss: 0.664556, acc.: 59.38%] [G loss: 0.935753]\n",
      "epoch:36 step:34323 [D loss: 0.677401, acc.: 57.03%] [G loss: 0.968665]\n",
      "epoch:36 step:34324 [D loss: 0.608882, acc.: 67.19%] [G loss: 0.904100]\n",
      "epoch:36 step:34325 [D loss: 0.671183, acc.: 58.59%] [G loss: 0.924708]\n",
      "epoch:36 step:34326 [D loss: 0.595602, acc.: 70.31%] [G loss: 1.033206]\n",
      "epoch:36 step:34327 [D loss: 0.643500, acc.: 61.72%] [G loss: 1.008984]\n",
      "epoch:36 step:34328 [D loss: 0.681508, acc.: 56.25%] [G loss: 0.934710]\n",
      "epoch:36 step:34329 [D loss: 0.636403, acc.: 60.94%] [G loss: 0.979533]\n",
      "epoch:36 step:34330 [D loss: 0.628411, acc.: 60.94%] [G loss: 0.979084]\n",
      "epoch:36 step:34331 [D loss: 0.633246, acc.: 60.94%] [G loss: 1.042392]\n",
      "epoch:36 step:34332 [D loss: 0.643094, acc.: 62.50%] [G loss: 1.029959]\n",
      "epoch:36 step:34333 [D loss: 0.661920, acc.: 53.91%] [G loss: 0.991317]\n",
      "epoch:36 step:34334 [D loss: 0.625048, acc.: 62.50%] [G loss: 0.878317]\n",
      "epoch:36 step:34335 [D loss: 0.673685, acc.: 54.69%] [G loss: 0.929966]\n",
      "epoch:36 step:34336 [D loss: 0.669548, acc.: 52.34%] [G loss: 0.921107]\n",
      "epoch:36 step:34337 [D loss: 0.681025, acc.: 50.00%] [G loss: 0.940209]\n",
      "epoch:36 step:34338 [D loss: 0.631578, acc.: 62.50%] [G loss: 0.932155]\n",
      "epoch:36 step:34339 [D loss: 0.644296, acc.: 58.59%] [G loss: 0.923152]\n",
      "epoch:36 step:34340 [D loss: 0.657185, acc.: 59.38%] [G loss: 0.969448]\n",
      "epoch:36 step:34341 [D loss: 0.606085, acc.: 67.97%] [G loss: 0.894844]\n",
      "epoch:36 step:34342 [D loss: 0.683468, acc.: 57.03%] [G loss: 0.912896]\n",
      "epoch:36 step:34343 [D loss: 0.652137, acc.: 60.94%] [G loss: 0.909511]\n",
      "epoch:36 step:34344 [D loss: 0.648978, acc.: 63.28%] [G loss: 0.882677]\n",
      "epoch:36 step:34345 [D loss: 0.670791, acc.: 60.16%] [G loss: 0.958900]\n",
      "epoch:36 step:34346 [D loss: 0.657658, acc.: 54.69%] [G loss: 0.915785]\n",
      "epoch:36 step:34347 [D loss: 0.651123, acc.: 60.94%] [G loss: 0.931180]\n",
      "epoch:36 step:34348 [D loss: 0.663904, acc.: 64.84%] [G loss: 0.880040]\n",
      "epoch:36 step:34349 [D loss: 0.638619, acc.: 63.28%] [G loss: 0.942167]\n",
      "epoch:36 step:34350 [D loss: 0.638129, acc.: 64.06%] [G loss: 0.862828]\n",
      "epoch:36 step:34351 [D loss: 0.628900, acc.: 64.84%] [G loss: 0.897568]\n",
      "epoch:36 step:34352 [D loss: 0.652732, acc.: 59.38%] [G loss: 0.812984]\n",
      "epoch:36 step:34353 [D loss: 0.660260, acc.: 57.03%] [G loss: 0.918793]\n",
      "epoch:36 step:34354 [D loss: 0.687791, acc.: 53.91%] [G loss: 0.903268]\n",
      "epoch:36 step:34355 [D loss: 0.614470, acc.: 71.09%] [G loss: 0.946915]\n",
      "epoch:36 step:34356 [D loss: 0.666295, acc.: 57.81%] [G loss: 0.992443]\n",
      "epoch:36 step:34357 [D loss: 0.605367, acc.: 67.19%] [G loss: 0.950703]\n",
      "epoch:36 step:34358 [D loss: 0.620323, acc.: 64.06%] [G loss: 0.969959]\n",
      "epoch:36 step:34359 [D loss: 0.650795, acc.: 64.06%] [G loss: 0.910550]\n",
      "epoch:36 step:34360 [D loss: 0.652973, acc.: 56.25%] [G loss: 0.830785]\n",
      "epoch:36 step:34361 [D loss: 0.669046, acc.: 57.81%] [G loss: 0.874606]\n",
      "epoch:36 step:34362 [D loss: 0.681911, acc.: 60.16%] [G loss: 0.898561]\n",
      "epoch:36 step:34363 [D loss: 0.614952, acc.: 64.06%] [G loss: 0.913010]\n",
      "epoch:36 step:34364 [D loss: 0.603808, acc.: 64.84%] [G loss: 0.956801]\n",
      "epoch:36 step:34365 [D loss: 0.585227, acc.: 70.31%] [G loss: 0.931194]\n",
      "epoch:36 step:34366 [D loss: 0.638904, acc.: 62.50%] [G loss: 0.901809]\n",
      "epoch:36 step:34367 [D loss: 0.655357, acc.: 57.03%] [G loss: 0.956750]\n",
      "epoch:36 step:34368 [D loss: 0.619278, acc.: 64.84%] [G loss: 0.986843]\n",
      "epoch:36 step:34369 [D loss: 0.641402, acc.: 61.72%] [G loss: 1.029685]\n",
      "epoch:36 step:34370 [D loss: 0.598368, acc.: 63.28%] [G loss: 1.037647]\n",
      "epoch:36 step:34371 [D loss: 0.644140, acc.: 62.50%] [G loss: 0.903648]\n",
      "epoch:36 step:34372 [D loss: 0.640262, acc.: 60.94%] [G loss: 0.887982]\n",
      "epoch:36 step:34373 [D loss: 0.688407, acc.: 54.69%] [G loss: 0.916725]\n",
      "epoch:36 step:34374 [D loss: 0.687202, acc.: 56.25%] [G loss: 0.932588]\n",
      "epoch:36 step:34375 [D loss: 0.687836, acc.: 56.25%] [G loss: 0.923510]\n",
      "epoch:36 step:34376 [D loss: 0.653020, acc.: 60.94%] [G loss: 0.912955]\n",
      "epoch:36 step:34377 [D loss: 0.598441, acc.: 65.62%] [G loss: 0.936175]\n",
      "epoch:36 step:34378 [D loss: 0.644318, acc.: 60.16%] [G loss: 0.967627]\n",
      "epoch:36 step:34379 [D loss: 0.665623, acc.: 57.81%] [G loss: 0.923687]\n",
      "epoch:36 step:34380 [D loss: 0.630558, acc.: 64.06%] [G loss: 0.924499]\n",
      "epoch:36 step:34381 [D loss: 0.631151, acc.: 64.84%] [G loss: 0.899542]\n",
      "epoch:36 step:34382 [D loss: 0.649907, acc.: 60.94%] [G loss: 0.848239]\n",
      "epoch:36 step:34383 [D loss: 0.641959, acc.: 63.28%] [G loss: 0.948617]\n",
      "epoch:36 step:34384 [D loss: 0.646533, acc.: 60.94%] [G loss: 0.961992]\n",
      "epoch:36 step:34385 [D loss: 0.652586, acc.: 66.41%] [G loss: 0.907563]\n",
      "epoch:36 step:34386 [D loss: 0.647049, acc.: 63.28%] [G loss: 0.918154]\n",
      "epoch:36 step:34387 [D loss: 0.673922, acc.: 57.03%] [G loss: 0.858919]\n",
      "epoch:36 step:34388 [D loss: 0.636666, acc.: 58.59%] [G loss: 0.977168]\n",
      "epoch:36 step:34389 [D loss: 0.693494, acc.: 53.12%] [G loss: 0.974836]\n",
      "epoch:36 step:34390 [D loss: 0.696072, acc.: 59.38%] [G loss: 0.896793]\n",
      "epoch:36 step:34391 [D loss: 0.643102, acc.: 64.06%] [G loss: 0.956273]\n",
      "epoch:36 step:34392 [D loss: 0.662831, acc.: 55.47%] [G loss: 0.902904]\n",
      "epoch:36 step:34393 [D loss: 0.655402, acc.: 62.50%] [G loss: 0.977079]\n",
      "epoch:36 step:34394 [D loss: 0.679047, acc.: 57.81%] [G loss: 0.939789]\n",
      "epoch:36 step:34395 [D loss: 0.656788, acc.: 63.28%] [G loss: 0.945096]\n",
      "epoch:36 step:34396 [D loss: 0.611516, acc.: 67.97%] [G loss: 0.971919]\n",
      "epoch:36 step:34397 [D loss: 0.681564, acc.: 59.38%] [G loss: 0.849831]\n",
      "epoch:36 step:34398 [D loss: 0.633613, acc.: 61.72%] [G loss: 0.951911]\n",
      "epoch:36 step:34399 [D loss: 0.638612, acc.: 59.38%] [G loss: 0.923313]\n",
      "epoch:36 step:34400 [D loss: 0.665074, acc.: 64.06%] [G loss: 0.992597]\n",
      "##############\n",
      "[2.84990231 2.27389914 2.19526954 3.76284711 1.36883106 9.27426719\n",
      " 2.84892504 3.64856625 4.14785385 7.14868929]\n",
      "##########\n",
      "epoch:36 step:34401 [D loss: 0.623684, acc.: 66.41%] [G loss: 0.938093]\n",
      "epoch:36 step:34402 [D loss: 0.660003, acc.: 60.16%] [G loss: 0.938034]\n",
      "epoch:36 step:34403 [D loss: 0.628153, acc.: 64.06%] [G loss: 0.948004]\n",
      "epoch:36 step:34404 [D loss: 0.652718, acc.: 59.38%] [G loss: 0.890994]\n",
      "epoch:36 step:34405 [D loss: 0.652517, acc.: 59.38%] [G loss: 0.918591]\n",
      "epoch:36 step:34406 [D loss: 0.657531, acc.: 59.38%] [G loss: 0.964184]\n",
      "epoch:36 step:34407 [D loss: 0.636436, acc.: 60.94%] [G loss: 0.932911]\n",
      "epoch:36 step:34408 [D loss: 0.653890, acc.: 63.28%] [G loss: 0.907211]\n",
      "epoch:36 step:34409 [D loss: 0.650610, acc.: 57.81%] [G loss: 0.888491]\n",
      "epoch:36 step:34410 [D loss: 0.663329, acc.: 57.03%] [G loss: 0.865082]\n",
      "epoch:36 step:34411 [D loss: 0.633659, acc.: 58.59%] [G loss: 0.929408]\n",
      "epoch:36 step:34412 [D loss: 0.649820, acc.: 64.06%] [G loss: 0.915296]\n",
      "epoch:36 step:34413 [D loss: 0.638138, acc.: 66.41%] [G loss: 0.884743]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:34414 [D loss: 0.621583, acc.: 65.62%] [G loss: 0.914045]\n",
      "epoch:36 step:34415 [D loss: 0.681237, acc.: 54.69%] [G loss: 0.954356]\n",
      "epoch:36 step:34416 [D loss: 0.665901, acc.: 60.16%] [G loss: 0.946027]\n",
      "epoch:36 step:34417 [D loss: 0.647307, acc.: 62.50%] [G loss: 0.922860]\n",
      "epoch:36 step:34418 [D loss: 0.657287, acc.: 55.47%] [G loss: 0.996554]\n",
      "epoch:36 step:34419 [D loss: 0.646348, acc.: 59.38%] [G loss: 0.971979]\n",
      "epoch:36 step:34420 [D loss: 0.604301, acc.: 63.28%] [G loss: 0.920564]\n",
      "epoch:36 step:34421 [D loss: 0.645261, acc.: 60.94%] [G loss: 0.973292]\n",
      "epoch:36 step:34422 [D loss: 0.656082, acc.: 64.06%] [G loss: 0.988313]\n",
      "epoch:36 step:34423 [D loss: 0.679180, acc.: 54.69%] [G loss: 0.890219]\n",
      "epoch:36 step:34424 [D loss: 0.663516, acc.: 61.72%] [G loss: 0.865278]\n",
      "epoch:36 step:34425 [D loss: 0.668496, acc.: 57.03%] [G loss: 0.916831]\n",
      "epoch:36 step:34426 [D loss: 0.628638, acc.: 67.97%] [G loss: 0.979558]\n",
      "epoch:36 step:34427 [D loss: 0.592061, acc.: 68.75%] [G loss: 0.907053]\n",
      "epoch:36 step:34428 [D loss: 0.627294, acc.: 61.72%] [G loss: 0.871309]\n",
      "epoch:36 step:34429 [D loss: 0.646559, acc.: 61.72%] [G loss: 0.950548]\n",
      "epoch:36 step:34430 [D loss: 0.638487, acc.: 60.94%] [G loss: 1.005088]\n",
      "epoch:36 step:34431 [D loss: 0.655433, acc.: 60.16%] [G loss: 0.999207]\n",
      "epoch:36 step:34432 [D loss: 0.646486, acc.: 59.38%] [G loss: 0.870138]\n",
      "epoch:36 step:34433 [D loss: 0.635285, acc.: 64.84%] [G loss: 1.026554]\n",
      "epoch:36 step:34434 [D loss: 0.582292, acc.: 69.53%] [G loss: 0.968346]\n",
      "epoch:36 step:34435 [D loss: 0.698132, acc.: 57.81%] [G loss: 0.901265]\n",
      "epoch:36 step:34436 [D loss: 0.585327, acc.: 73.44%] [G loss: 0.970163]\n",
      "epoch:36 step:34437 [D loss: 0.633327, acc.: 64.84%] [G loss: 0.936539]\n",
      "epoch:36 step:34438 [D loss: 0.685963, acc.: 53.91%] [G loss: 0.916114]\n",
      "epoch:36 step:34439 [D loss: 0.660271, acc.: 59.38%] [G loss: 0.985364]\n",
      "epoch:36 step:34440 [D loss: 0.649865, acc.: 61.72%] [G loss: 0.971297]\n",
      "epoch:36 step:34441 [D loss: 0.724246, acc.: 48.44%] [G loss: 0.973503]\n",
      "epoch:36 step:34442 [D loss: 0.608184, acc.: 65.62%] [G loss: 0.967759]\n",
      "epoch:36 step:34443 [D loss: 0.627532, acc.: 64.06%] [G loss: 0.992689]\n",
      "epoch:36 step:34444 [D loss: 0.679172, acc.: 62.50%] [G loss: 0.958418]\n",
      "epoch:36 step:34445 [D loss: 0.621552, acc.: 64.06%] [G loss: 0.940343]\n",
      "epoch:36 step:34446 [D loss: 0.678142, acc.: 60.94%] [G loss: 0.932247]\n",
      "epoch:36 step:34447 [D loss: 0.672241, acc.: 57.81%] [G loss: 0.917935]\n",
      "epoch:36 step:34448 [D loss: 0.646959, acc.: 59.38%] [G loss: 0.903748]\n",
      "epoch:36 step:34449 [D loss: 0.628527, acc.: 62.50%] [G loss: 0.953993]\n",
      "epoch:36 step:34450 [D loss: 0.603752, acc.: 65.62%] [G loss: 0.930904]\n",
      "epoch:36 step:34451 [D loss: 0.640293, acc.: 65.62%] [G loss: 0.944719]\n",
      "epoch:36 step:34452 [D loss: 0.634983, acc.: 60.16%] [G loss: 0.935341]\n",
      "epoch:36 step:34453 [D loss: 0.636738, acc.: 63.28%] [G loss: 0.855730]\n",
      "epoch:36 step:34454 [D loss: 0.618066, acc.: 69.53%] [G loss: 0.920275]\n",
      "epoch:36 step:34455 [D loss: 0.678922, acc.: 54.69%] [G loss: 0.965689]\n",
      "epoch:36 step:34456 [D loss: 0.622402, acc.: 68.75%] [G loss: 0.938401]\n",
      "epoch:36 step:34457 [D loss: 0.607252, acc.: 64.84%] [G loss: 0.941178]\n",
      "epoch:36 step:34458 [D loss: 0.658756, acc.: 60.16%] [G loss: 0.901047]\n",
      "epoch:36 step:34459 [D loss: 0.622807, acc.: 67.97%] [G loss: 1.047920]\n",
      "epoch:36 step:34460 [D loss: 0.658121, acc.: 59.38%] [G loss: 0.916923]\n",
      "epoch:36 step:34461 [D loss: 0.633946, acc.: 66.41%] [G loss: 0.916392]\n",
      "epoch:36 step:34462 [D loss: 0.660460, acc.: 60.16%] [G loss: 0.986861]\n",
      "epoch:36 step:34463 [D loss: 0.599523, acc.: 69.53%] [G loss: 0.931479]\n",
      "epoch:36 step:34464 [D loss: 0.618852, acc.: 67.19%] [G loss: 0.882339]\n",
      "epoch:36 step:34465 [D loss: 0.644059, acc.: 60.94%] [G loss: 0.949530]\n",
      "epoch:36 step:34466 [D loss: 0.600089, acc.: 63.28%] [G loss: 0.916986]\n",
      "epoch:36 step:34467 [D loss: 0.619429, acc.: 64.84%] [G loss: 0.895181]\n",
      "epoch:36 step:34468 [D loss: 0.636198, acc.: 64.84%] [G loss: 0.905114]\n",
      "epoch:36 step:34469 [D loss: 0.629773, acc.: 64.06%] [G loss: 0.928232]\n",
      "epoch:36 step:34470 [D loss: 0.671135, acc.: 54.69%] [G loss: 0.912947]\n",
      "epoch:36 step:34471 [D loss: 0.678893, acc.: 57.03%] [G loss: 1.002400]\n",
      "epoch:36 step:34472 [D loss: 0.631830, acc.: 64.84%] [G loss: 0.997282]\n",
      "epoch:36 step:34473 [D loss: 0.638506, acc.: 62.50%] [G loss: 0.896809]\n",
      "epoch:36 step:34474 [D loss: 0.639077, acc.: 65.62%] [G loss: 0.879032]\n",
      "epoch:36 step:34475 [D loss: 0.661512, acc.: 59.38%] [G loss: 0.833207]\n",
      "epoch:36 step:34476 [D loss: 0.625719, acc.: 63.28%] [G loss: 0.996178]\n",
      "epoch:36 step:34477 [D loss: 0.613001, acc.: 66.41%] [G loss: 1.016014]\n",
      "epoch:36 step:34478 [D loss: 0.610784, acc.: 67.97%] [G loss: 1.016277]\n",
      "epoch:36 step:34479 [D loss: 0.611143, acc.: 64.06%] [G loss: 0.960382]\n",
      "epoch:36 step:34480 [D loss: 0.603719, acc.: 66.41%] [G loss: 0.958691]\n",
      "epoch:36 step:34481 [D loss: 0.663378, acc.: 58.59%] [G loss: 0.869880]\n",
      "epoch:36 step:34482 [D loss: 0.624886, acc.: 66.41%] [G loss: 0.971498]\n",
      "epoch:36 step:34483 [D loss: 0.631555, acc.: 63.28%] [G loss: 0.973345]\n",
      "epoch:36 step:34484 [D loss: 0.611924, acc.: 67.97%] [G loss: 0.971571]\n",
      "epoch:36 step:34485 [D loss: 0.604856, acc.: 70.31%] [G loss: 0.919474]\n",
      "epoch:36 step:34486 [D loss: 0.637643, acc.: 61.72%] [G loss: 0.916500]\n",
      "epoch:36 step:34487 [D loss: 0.635257, acc.: 60.16%] [G loss: 0.805289]\n",
      "epoch:36 step:34488 [D loss: 0.648575, acc.: 57.03%] [G loss: 0.877981]\n",
      "epoch:36 step:34489 [D loss: 0.587484, acc.: 70.31%] [G loss: 0.950763]\n",
      "epoch:36 step:34490 [D loss: 0.642418, acc.: 62.50%] [G loss: 0.935118]\n",
      "epoch:36 step:34491 [D loss: 0.636980, acc.: 59.38%] [G loss: 0.968058]\n",
      "epoch:36 step:34492 [D loss: 0.661202, acc.: 58.59%] [G loss: 0.934288]\n",
      "epoch:36 step:34493 [D loss: 0.664511, acc.: 52.34%] [G loss: 0.933480]\n",
      "epoch:36 step:34494 [D loss: 0.663034, acc.: 60.94%] [G loss: 0.903929]\n",
      "epoch:36 step:34495 [D loss: 0.678948, acc.: 60.94%] [G loss: 0.948206]\n",
      "epoch:36 step:34496 [D loss: 0.614745, acc.: 69.53%] [G loss: 0.950391]\n",
      "epoch:36 step:34497 [D loss: 0.629283, acc.: 64.06%] [G loss: 0.935348]\n",
      "epoch:36 step:34498 [D loss: 0.621699, acc.: 69.53%] [G loss: 0.927154]\n",
      "epoch:36 step:34499 [D loss: 0.640517, acc.: 67.97%] [G loss: 0.926835]\n",
      "epoch:36 step:34500 [D loss: 0.650737, acc.: 63.28%] [G loss: 1.051756]\n",
      "epoch:36 step:34501 [D loss: 0.598128, acc.: 71.09%] [G loss: 0.986933]\n",
      "epoch:36 step:34502 [D loss: 0.631316, acc.: 65.62%] [G loss: 0.982258]\n",
      "epoch:36 step:34503 [D loss: 0.641303, acc.: 60.16%] [G loss: 0.992840]\n",
      "epoch:36 step:34504 [D loss: 0.641262, acc.: 61.72%] [G loss: 0.922352]\n",
      "epoch:36 step:34505 [D loss: 0.652531, acc.: 63.28%] [G loss: 0.940387]\n",
      "epoch:36 step:34506 [D loss: 0.642574, acc.: 64.84%] [G loss: 0.975167]\n",
      "epoch:36 step:34507 [D loss: 0.606707, acc.: 67.97%] [G loss: 0.964458]\n",
      "epoch:36 step:34508 [D loss: 0.659912, acc.: 55.47%] [G loss: 0.922737]\n",
      "epoch:36 step:34509 [D loss: 0.629738, acc.: 64.06%] [G loss: 0.975150]\n",
      "epoch:36 step:34510 [D loss: 0.592242, acc.: 68.75%] [G loss: 0.998561]\n",
      "epoch:36 step:34511 [D loss: 0.656533, acc.: 63.28%] [G loss: 0.922143]\n",
      "epoch:36 step:34512 [D loss: 0.651878, acc.: 60.16%] [G loss: 1.011711]\n",
      "epoch:36 step:34513 [D loss: 0.673485, acc.: 65.62%] [G loss: 0.939876]\n",
      "epoch:36 step:34514 [D loss: 0.615268, acc.: 67.19%] [G loss: 0.957194]\n",
      "epoch:36 step:34515 [D loss: 0.633895, acc.: 61.72%] [G loss: 0.958315]\n",
      "epoch:36 step:34516 [D loss: 0.634980, acc.: 64.84%] [G loss: 0.908139]\n",
      "epoch:36 step:34517 [D loss: 0.631458, acc.: 64.84%] [G loss: 0.988153]\n",
      "epoch:36 step:34518 [D loss: 0.690113, acc.: 53.12%] [G loss: 0.945238]\n",
      "epoch:36 step:34519 [D loss: 0.636384, acc.: 59.38%] [G loss: 0.977077]\n",
      "epoch:36 step:34520 [D loss: 0.592999, acc.: 71.88%] [G loss: 1.036163]\n",
      "epoch:36 step:34521 [D loss: 0.621984, acc.: 64.06%] [G loss: 0.987650]\n",
      "epoch:36 step:34522 [D loss: 0.604863, acc.: 68.75%] [G loss: 0.949544]\n",
      "epoch:36 step:34523 [D loss: 0.622095, acc.: 65.62%] [G loss: 0.896459]\n",
      "epoch:36 step:34524 [D loss: 0.594260, acc.: 71.88%] [G loss: 0.965563]\n",
      "epoch:36 step:34525 [D loss: 0.577012, acc.: 71.88%] [G loss: 0.912060]\n",
      "epoch:36 step:34526 [D loss: 0.612912, acc.: 64.84%] [G loss: 0.924060]\n",
      "epoch:36 step:34527 [D loss: 0.591993, acc.: 66.41%] [G loss: 0.946062]\n",
      "epoch:36 step:34528 [D loss: 0.640885, acc.: 65.62%] [G loss: 0.903347]\n",
      "epoch:36 step:34529 [D loss: 0.680853, acc.: 60.16%] [G loss: 0.980545]\n",
      "epoch:36 step:34530 [D loss: 0.618805, acc.: 69.53%] [G loss: 0.939860]\n",
      "epoch:36 step:34531 [D loss: 0.661362, acc.: 56.25%] [G loss: 0.927965]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:34532 [D loss: 0.638717, acc.: 62.50%] [G loss: 0.978975]\n",
      "epoch:36 step:34533 [D loss: 0.636226, acc.: 64.84%] [G loss: 0.969803]\n",
      "epoch:36 step:34534 [D loss: 0.628925, acc.: 67.19%] [G loss: 0.909677]\n",
      "epoch:36 step:34535 [D loss: 0.631410, acc.: 66.41%] [G loss: 0.997613]\n",
      "epoch:36 step:34536 [D loss: 0.662434, acc.: 55.47%] [G loss: 0.944288]\n",
      "epoch:36 step:34537 [D loss: 0.693657, acc.: 53.12%] [G loss: 0.935134]\n",
      "epoch:36 step:34538 [D loss: 0.655195, acc.: 57.81%] [G loss: 0.860327]\n",
      "epoch:36 step:34539 [D loss: 0.614149, acc.: 70.31%] [G loss: 0.884237]\n",
      "epoch:36 step:34540 [D loss: 0.603706, acc.: 65.62%] [G loss: 1.012685]\n",
      "epoch:36 step:34541 [D loss: 0.613268, acc.: 64.06%] [G loss: 0.895389]\n",
      "epoch:36 step:34542 [D loss: 0.633203, acc.: 65.62%] [G loss: 0.964599]\n",
      "epoch:36 step:34543 [D loss: 0.675240, acc.: 50.78%] [G loss: 0.956502]\n",
      "epoch:36 step:34544 [D loss: 0.672990, acc.: 54.69%] [G loss: 0.945297]\n",
      "epoch:36 step:34545 [D loss: 0.648336, acc.: 58.59%] [G loss: 0.908590]\n",
      "epoch:36 step:34546 [D loss: 0.625035, acc.: 66.41%] [G loss: 0.909947]\n",
      "epoch:36 step:34547 [D loss: 0.642134, acc.: 68.75%] [G loss: 0.974694]\n",
      "epoch:36 step:34548 [D loss: 0.611637, acc.: 64.84%] [G loss: 0.975280]\n",
      "epoch:36 step:34549 [D loss: 0.702166, acc.: 55.47%] [G loss: 0.897244]\n",
      "epoch:36 step:34550 [D loss: 0.664427, acc.: 56.25%] [G loss: 0.882585]\n",
      "epoch:36 step:34551 [D loss: 0.631745, acc.: 67.19%] [G loss: 0.934133]\n",
      "epoch:36 step:34552 [D loss: 0.639199, acc.: 67.19%] [G loss: 0.918049]\n",
      "epoch:36 step:34553 [D loss: 0.597720, acc.: 71.09%] [G loss: 0.888705]\n",
      "epoch:36 step:34554 [D loss: 0.630351, acc.: 66.41%] [G loss: 0.960216]\n",
      "epoch:36 step:34555 [D loss: 0.670096, acc.: 57.03%] [G loss: 0.915769]\n",
      "epoch:36 step:34556 [D loss: 0.608803, acc.: 63.28%] [G loss: 0.946644]\n",
      "epoch:36 step:34557 [D loss: 0.660259, acc.: 60.16%] [G loss: 0.938959]\n",
      "epoch:36 step:34558 [D loss: 0.636786, acc.: 56.25%] [G loss: 1.007558]\n",
      "epoch:36 step:34559 [D loss: 0.655928, acc.: 60.94%] [G loss: 0.890748]\n",
      "epoch:36 step:34560 [D loss: 0.669750, acc.: 58.59%] [G loss: 0.952350]\n",
      "epoch:36 step:34561 [D loss: 0.649399, acc.: 58.59%] [G loss: 0.874233]\n",
      "epoch:36 step:34562 [D loss: 0.637873, acc.: 62.50%] [G loss: 0.902204]\n",
      "epoch:36 step:34563 [D loss: 0.658180, acc.: 63.28%] [G loss: 0.927284]\n",
      "epoch:36 step:34564 [D loss: 0.653028, acc.: 56.25%] [G loss: 0.952838]\n",
      "epoch:36 step:34565 [D loss: 0.663078, acc.: 61.72%] [G loss: 0.914397]\n",
      "epoch:36 step:34566 [D loss: 0.653205, acc.: 57.81%] [G loss: 0.901962]\n",
      "epoch:36 step:34567 [D loss: 0.692928, acc.: 62.50%] [G loss: 0.936389]\n",
      "epoch:36 step:34568 [D loss: 0.651148, acc.: 61.72%] [G loss: 0.930133]\n",
      "epoch:36 step:34569 [D loss: 0.600976, acc.: 65.62%] [G loss: 0.996138]\n",
      "epoch:36 step:34570 [D loss: 0.660184, acc.: 63.28%] [G loss: 0.911143]\n",
      "epoch:36 step:34571 [D loss: 0.678711, acc.: 60.16%] [G loss: 0.936086]\n",
      "epoch:36 step:34572 [D loss: 0.644663, acc.: 65.62%] [G loss: 0.919139]\n",
      "epoch:36 step:34573 [D loss: 0.662633, acc.: 59.38%] [G loss: 0.941495]\n",
      "epoch:36 step:34574 [D loss: 0.676354, acc.: 53.12%] [G loss: 0.939147]\n",
      "epoch:36 step:34575 [D loss: 0.678875, acc.: 60.16%] [G loss: 0.956738]\n",
      "epoch:36 step:34576 [D loss: 0.597224, acc.: 71.09%] [G loss: 0.958815]\n",
      "epoch:36 step:34577 [D loss: 0.643505, acc.: 59.38%] [G loss: 0.916497]\n",
      "epoch:36 step:34578 [D loss: 0.665627, acc.: 56.25%] [G loss: 0.890126]\n",
      "epoch:36 step:34579 [D loss: 0.630786, acc.: 61.72%] [G loss: 0.919063]\n",
      "epoch:36 step:34580 [D loss: 0.619214, acc.: 68.75%] [G loss: 0.933417]\n",
      "epoch:36 step:34581 [D loss: 0.621870, acc.: 65.62%] [G loss: 0.942573]\n",
      "epoch:36 step:34582 [D loss: 0.625718, acc.: 64.84%] [G loss: 0.996195]\n",
      "epoch:36 step:34583 [D loss: 0.647521, acc.: 63.28%] [G loss: 1.015790]\n",
      "epoch:36 step:34584 [D loss: 0.611683, acc.: 71.09%] [G loss: 0.986114]\n",
      "epoch:36 step:34585 [D loss: 0.670604, acc.: 57.81%] [G loss: 1.028998]\n",
      "epoch:36 step:34586 [D loss: 0.643489, acc.: 62.50%] [G loss: 0.956590]\n",
      "epoch:36 step:34587 [D loss: 0.678694, acc.: 57.03%] [G loss: 0.983953]\n",
      "epoch:36 step:34588 [D loss: 0.622097, acc.: 63.28%] [G loss: 0.913082]\n",
      "epoch:36 step:34589 [D loss: 0.663858, acc.: 57.03%] [G loss: 0.957204]\n",
      "epoch:36 step:34590 [D loss: 0.647223, acc.: 59.38%] [G loss: 0.929885]\n",
      "epoch:36 step:34591 [D loss: 0.675154, acc.: 53.91%] [G loss: 0.889969]\n",
      "epoch:36 step:34592 [D loss: 0.652691, acc.: 60.16%] [G loss: 0.926696]\n",
      "epoch:36 step:34593 [D loss: 0.626085, acc.: 59.38%] [G loss: 0.904608]\n",
      "epoch:36 step:34594 [D loss: 0.645599, acc.: 62.50%] [G loss: 0.853268]\n",
      "epoch:36 step:34595 [D loss: 0.654191, acc.: 61.72%] [G loss: 0.907740]\n",
      "epoch:36 step:34596 [D loss: 0.620212, acc.: 66.41%] [G loss: 0.993664]\n",
      "epoch:36 step:34597 [D loss: 0.648328, acc.: 53.91%] [G loss: 1.076233]\n",
      "epoch:36 step:34598 [D loss: 0.612550, acc.: 68.75%] [G loss: 0.966005]\n",
      "epoch:36 step:34599 [D loss: 0.664310, acc.: 58.59%] [G loss: 0.911548]\n",
      "epoch:36 step:34600 [D loss: 0.670448, acc.: 60.94%] [G loss: 0.941145]\n",
      "##############\n",
      "[3.14978531 2.29822867 2.37861793 3.81824058 0.92307405 6.89942971\n",
      " 2.75787214 3.75890328 4.22762917 8.14868929]\n",
      "##########\n",
      "epoch:36 step:34601 [D loss: 0.612822, acc.: 71.09%] [G loss: 0.975583]\n",
      "epoch:36 step:34602 [D loss: 0.666551, acc.: 59.38%] [G loss: 0.923614]\n",
      "epoch:36 step:34603 [D loss: 0.714473, acc.: 54.69%] [G loss: 0.874317]\n",
      "epoch:36 step:34604 [D loss: 0.667994, acc.: 56.25%] [G loss: 0.885480]\n",
      "epoch:36 step:34605 [D loss: 0.629991, acc.: 67.19%] [G loss: 0.959263]\n",
      "epoch:36 step:34606 [D loss: 0.619072, acc.: 64.06%] [G loss: 0.964037]\n",
      "epoch:36 step:34607 [D loss: 0.614837, acc.: 63.28%] [G loss: 0.984111]\n",
      "epoch:36 step:34608 [D loss: 0.658868, acc.: 63.28%] [G loss: 0.953329]\n",
      "epoch:36 step:34609 [D loss: 0.617144, acc.: 68.75%] [G loss: 0.928337]\n",
      "epoch:36 step:34610 [D loss: 0.663259, acc.: 50.78%] [G loss: 0.985741]\n",
      "epoch:36 step:34611 [D loss: 0.653780, acc.: 62.50%] [G loss: 0.992198]\n",
      "epoch:36 step:34612 [D loss: 0.635495, acc.: 61.72%] [G loss: 0.884777]\n",
      "epoch:36 step:34613 [D loss: 0.649672, acc.: 61.72%] [G loss: 0.958924]\n",
      "epoch:36 step:34614 [D loss: 0.628851, acc.: 61.72%] [G loss: 0.949853]\n",
      "epoch:36 step:34615 [D loss: 0.625209, acc.: 67.19%] [G loss: 0.967533]\n",
      "epoch:36 step:34616 [D loss: 0.610443, acc.: 69.53%] [G loss: 0.979804]\n",
      "epoch:36 step:34617 [D loss: 0.672579, acc.: 54.69%] [G loss: 0.937897]\n",
      "epoch:36 step:34618 [D loss: 0.609365, acc.: 68.75%] [G loss: 0.916264]\n",
      "epoch:36 step:34619 [D loss: 0.653292, acc.: 63.28%] [G loss: 0.908193]\n",
      "epoch:36 step:34620 [D loss: 0.644746, acc.: 63.28%] [G loss: 0.930439]\n",
      "epoch:36 step:34621 [D loss: 0.637152, acc.: 57.81%] [G loss: 0.991126]\n",
      "epoch:36 step:34622 [D loss: 0.633287, acc.: 66.41%] [G loss: 0.975564]\n",
      "epoch:36 step:34623 [D loss: 0.660870, acc.: 54.69%] [G loss: 0.998598]\n",
      "epoch:36 step:34624 [D loss: 0.638541, acc.: 64.06%] [G loss: 0.937968]\n",
      "epoch:36 step:34625 [D loss: 0.669245, acc.: 53.91%] [G loss: 0.956160]\n",
      "epoch:36 step:34626 [D loss: 0.622671, acc.: 65.62%] [G loss: 0.894227]\n",
      "epoch:36 step:34627 [D loss: 0.630868, acc.: 66.41%] [G loss: 0.973171]\n",
      "epoch:36 step:34628 [D loss: 0.592651, acc.: 67.19%] [G loss: 0.901355]\n",
      "epoch:36 step:34629 [D loss: 0.621290, acc.: 67.19%] [G loss: 0.907045]\n",
      "epoch:36 step:34630 [D loss: 0.660418, acc.: 57.81%] [G loss: 0.980601]\n",
      "epoch:36 step:34631 [D loss: 0.631751, acc.: 65.62%] [G loss: 0.938115]\n",
      "epoch:36 step:34632 [D loss: 0.629987, acc.: 64.84%] [G loss: 0.944157]\n",
      "epoch:36 step:34633 [D loss: 0.703363, acc.: 60.94%] [G loss: 0.914835]\n",
      "epoch:36 step:34634 [D loss: 0.662342, acc.: 64.84%] [G loss: 0.870638]\n",
      "epoch:36 step:34635 [D loss: 0.611393, acc.: 67.19%] [G loss: 0.897486]\n",
      "epoch:36 step:34636 [D loss: 0.619505, acc.: 67.19%] [G loss: 0.848787]\n",
      "epoch:36 step:34637 [D loss: 0.694801, acc.: 53.91%] [G loss: 0.898050]\n",
      "epoch:36 step:34638 [D loss: 0.577453, acc.: 73.44%] [G loss: 0.937051]\n",
      "epoch:36 step:34639 [D loss: 0.658520, acc.: 56.25%] [G loss: 0.965348]\n",
      "epoch:36 step:34640 [D loss: 0.655798, acc.: 61.72%] [G loss: 0.985286]\n",
      "epoch:36 step:34641 [D loss: 0.632715, acc.: 68.75%] [G loss: 0.964684]\n",
      "epoch:36 step:34642 [D loss: 0.680339, acc.: 55.47%] [G loss: 0.914620]\n",
      "epoch:36 step:34643 [D loss: 0.627933, acc.: 62.50%] [G loss: 0.994800]\n",
      "epoch:36 step:34644 [D loss: 0.642978, acc.: 64.84%] [G loss: 0.937480]\n",
      "epoch:36 step:34645 [D loss: 0.644025, acc.: 60.94%] [G loss: 0.965452]\n",
      "epoch:36 step:34646 [D loss: 0.635747, acc.: 62.50%] [G loss: 0.927830]\n",
      "epoch:36 step:34647 [D loss: 0.641793, acc.: 64.06%] [G loss: 0.940607]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:36 step:34648 [D loss: 0.640690, acc.: 62.50%] [G loss: 0.947162]\n",
      "epoch:36 step:34649 [D loss: 0.562601, acc.: 75.00%] [G loss: 1.009698]\n",
      "epoch:36 step:34650 [D loss: 0.700077, acc.: 54.69%] [G loss: 1.057149]\n",
      "epoch:36 step:34651 [D loss: 0.643656, acc.: 64.06%] [G loss: 0.949762]\n",
      "epoch:36 step:34652 [D loss: 0.608548, acc.: 69.53%] [G loss: 0.942564]\n",
      "epoch:36 step:34653 [D loss: 0.707383, acc.: 53.91%] [G loss: 0.901451]\n",
      "epoch:36 step:34654 [D loss: 0.641801, acc.: 64.84%] [G loss: 0.938202]\n",
      "epoch:36 step:34655 [D loss: 0.645440, acc.: 61.72%] [G loss: 0.895970]\n",
      "epoch:36 step:34656 [D loss: 0.675620, acc.: 58.59%] [G loss: 0.894096]\n",
      "epoch:36 step:34657 [D loss: 0.666923, acc.: 58.59%] [G loss: 0.950122]\n",
      "epoch:36 step:34658 [D loss: 0.645060, acc.: 63.28%] [G loss: 0.953907]\n",
      "epoch:36 step:34659 [D loss: 0.666508, acc.: 60.16%] [G loss: 0.998412]\n",
      "epoch:36 step:34660 [D loss: 0.585260, acc.: 66.41%] [G loss: 0.934301]\n",
      "epoch:36 step:34661 [D loss: 0.667826, acc.: 53.12%] [G loss: 0.962911]\n",
      "epoch:36 step:34662 [D loss: 0.582964, acc.: 69.53%] [G loss: 0.942772]\n",
      "epoch:36 step:34663 [D loss: 0.666305, acc.: 57.03%] [G loss: 0.924425]\n",
      "epoch:36 step:34664 [D loss: 0.613952, acc.: 67.19%] [G loss: 0.900740]\n",
      "epoch:36 step:34665 [D loss: 0.644458, acc.: 62.50%] [G loss: 0.857328]\n",
      "epoch:36 step:34666 [D loss: 0.636593, acc.: 60.94%] [G loss: 0.869052]\n",
      "epoch:36 step:34667 [D loss: 0.655378, acc.: 58.59%] [G loss: 0.855444]\n",
      "epoch:36 step:34668 [D loss: 0.649387, acc.: 64.06%] [G loss: 0.954964]\n",
      "epoch:36 step:34669 [D loss: 0.598066, acc.: 67.97%] [G loss: 1.054045]\n",
      "epoch:37 step:34670 [D loss: 0.681394, acc.: 55.47%] [G loss: 1.013496]\n",
      "epoch:37 step:34671 [D loss: 0.617592, acc.: 69.53%] [G loss: 0.956338]\n",
      "epoch:37 step:34672 [D loss: 0.618609, acc.: 65.62%] [G loss: 0.979398]\n",
      "epoch:37 step:34673 [D loss: 0.641468, acc.: 64.06%] [G loss: 1.004547]\n",
      "epoch:37 step:34674 [D loss: 0.654195, acc.: 59.38%] [G loss: 1.027004]\n",
      "epoch:37 step:34675 [D loss: 0.613777, acc.: 67.19%] [G loss: 0.940895]\n",
      "epoch:37 step:34676 [D loss: 0.665942, acc.: 61.72%] [G loss: 0.981837]\n",
      "epoch:37 step:34677 [D loss: 0.695252, acc.: 53.91%] [G loss: 0.907633]\n",
      "epoch:37 step:34678 [D loss: 0.637484, acc.: 65.62%] [G loss: 0.893934]\n",
      "epoch:37 step:34679 [D loss: 0.667120, acc.: 60.16%] [G loss: 0.954560]\n",
      "epoch:37 step:34680 [D loss: 0.632602, acc.: 63.28%] [G loss: 0.940556]\n",
      "epoch:37 step:34681 [D loss: 0.618021, acc.: 66.41%] [G loss: 0.951998]\n",
      "epoch:37 step:34682 [D loss: 0.617838, acc.: 63.28%] [G loss: 1.005144]\n",
      "epoch:37 step:34683 [D loss: 0.690583, acc.: 55.47%] [G loss: 0.967902]\n",
      "epoch:37 step:34684 [D loss: 0.601605, acc.: 63.28%] [G loss: 0.904880]\n",
      "epoch:37 step:34685 [D loss: 0.638501, acc.: 65.62%] [G loss: 0.944332]\n",
      "epoch:37 step:34686 [D loss: 0.642230, acc.: 63.28%] [G loss: 0.952825]\n",
      "epoch:37 step:34687 [D loss: 0.658444, acc.: 63.28%] [G loss: 0.976560]\n",
      "epoch:37 step:34688 [D loss: 0.616288, acc.: 65.62%] [G loss: 0.896834]\n",
      "epoch:37 step:34689 [D loss: 0.653546, acc.: 57.03%] [G loss: 0.874375]\n",
      "epoch:37 step:34690 [D loss: 0.622334, acc.: 65.62%] [G loss: 0.931232]\n",
      "epoch:37 step:34691 [D loss: 0.677203, acc.: 57.03%] [G loss: 0.909162]\n",
      "epoch:37 step:34692 [D loss: 0.656747, acc.: 63.28%] [G loss: 0.923979]\n",
      "epoch:37 step:34693 [D loss: 0.655444, acc.: 60.94%] [G loss: 0.824099]\n",
      "epoch:37 step:34694 [D loss: 0.630279, acc.: 68.75%] [G loss: 0.922324]\n",
      "epoch:37 step:34695 [D loss: 0.637608, acc.: 59.38%] [G loss: 0.902183]\n",
      "epoch:37 step:34696 [D loss: 0.645321, acc.: 61.72%] [G loss: 0.937041]\n",
      "epoch:37 step:34697 [D loss: 0.589511, acc.: 75.78%] [G loss: 0.956680]\n",
      "epoch:37 step:34698 [D loss: 0.658975, acc.: 59.38%] [G loss: 0.904774]\n",
      "epoch:37 step:34699 [D loss: 0.636785, acc.: 64.84%] [G loss: 0.867754]\n",
      "epoch:37 step:34700 [D loss: 0.619647, acc.: 67.19%] [G loss: 0.937138]\n",
      "epoch:37 step:34701 [D loss: 0.614164, acc.: 65.62%] [G loss: 0.935498]\n",
      "epoch:37 step:34702 [D loss: 0.656845, acc.: 64.84%] [G loss: 1.004900]\n",
      "epoch:37 step:34703 [D loss: 0.671939, acc.: 60.94%] [G loss: 0.965058]\n",
      "epoch:37 step:34704 [D loss: 0.665224, acc.: 57.81%] [G loss: 0.911071]\n",
      "epoch:37 step:34705 [D loss: 0.613666, acc.: 71.09%] [G loss: 0.894843]\n",
      "epoch:37 step:34706 [D loss: 0.636954, acc.: 63.28%] [G loss: 0.972142]\n",
      "epoch:37 step:34707 [D loss: 0.666877, acc.: 58.59%] [G loss: 0.903351]\n",
      "epoch:37 step:34708 [D loss: 0.660246, acc.: 57.81%] [G loss: 0.916540]\n",
      "epoch:37 step:34709 [D loss: 0.640296, acc.: 61.72%] [G loss: 0.919509]\n",
      "epoch:37 step:34710 [D loss: 0.641051, acc.: 61.72%] [G loss: 0.895955]\n",
      "epoch:37 step:34711 [D loss: 0.621315, acc.: 62.50%] [G loss: 0.939306]\n",
      "epoch:37 step:34712 [D loss: 0.659343, acc.: 59.38%] [G loss: 0.938898]\n",
      "epoch:37 step:34713 [D loss: 0.611542, acc.: 64.84%] [G loss: 1.007099]\n",
      "epoch:37 step:34714 [D loss: 0.652463, acc.: 58.59%] [G loss: 0.938990]\n",
      "epoch:37 step:34715 [D loss: 0.651185, acc.: 60.94%] [G loss: 0.920801]\n",
      "epoch:37 step:34716 [D loss: 0.656693, acc.: 51.56%] [G loss: 1.050510]\n",
      "epoch:37 step:34717 [D loss: 0.625088, acc.: 65.62%] [G loss: 0.911513]\n",
      "epoch:37 step:34718 [D loss: 0.680828, acc.: 55.47%] [G loss: 0.919730]\n",
      "epoch:37 step:34719 [D loss: 0.636729, acc.: 59.38%] [G loss: 0.969325]\n",
      "epoch:37 step:34720 [D loss: 0.632793, acc.: 66.41%] [G loss: 0.926546]\n",
      "epoch:37 step:34721 [D loss: 0.603930, acc.: 65.62%] [G loss: 0.893146]\n",
      "epoch:37 step:34722 [D loss: 0.635702, acc.: 60.16%] [G loss: 0.935455]\n",
      "epoch:37 step:34723 [D loss: 0.668061, acc.: 57.03%] [G loss: 0.929674]\n",
      "epoch:37 step:34724 [D loss: 0.658098, acc.: 60.94%] [G loss: 0.876556]\n",
      "epoch:37 step:34725 [D loss: 0.655867, acc.: 59.38%] [G loss: 0.945009]\n",
      "epoch:37 step:34726 [D loss: 0.632113, acc.: 65.62%] [G loss: 0.982584]\n",
      "epoch:37 step:34727 [D loss: 0.664747, acc.: 58.59%] [G loss: 0.972143]\n",
      "epoch:37 step:34728 [D loss: 0.590663, acc.: 70.31%] [G loss: 0.971713]\n",
      "epoch:37 step:34729 [D loss: 0.620409, acc.: 67.97%] [G loss: 0.919106]\n",
      "epoch:37 step:34730 [D loss: 0.658252, acc.: 56.25%] [G loss: 0.953994]\n",
      "epoch:37 step:34731 [D loss: 0.597526, acc.: 62.50%] [G loss: 0.928047]\n",
      "epoch:37 step:34732 [D loss: 0.615497, acc.: 67.97%] [G loss: 0.908748]\n",
      "epoch:37 step:34733 [D loss: 0.610746, acc.: 64.06%] [G loss: 0.958933]\n",
      "epoch:37 step:34734 [D loss: 0.637708, acc.: 64.06%] [G loss: 0.872836]\n",
      "epoch:37 step:34735 [D loss: 0.673351, acc.: 60.16%] [G loss: 0.907830]\n",
      "epoch:37 step:34736 [D loss: 0.661273, acc.: 57.03%] [G loss: 0.976615]\n",
      "epoch:37 step:34737 [D loss: 0.649760, acc.: 64.06%] [G loss: 0.821667]\n",
      "epoch:37 step:34738 [D loss: 0.617356, acc.: 63.28%] [G loss: 0.935363]\n",
      "epoch:37 step:34739 [D loss: 0.635690, acc.: 66.41%] [G loss: 1.037484]\n",
      "epoch:37 step:34740 [D loss: 0.627003, acc.: 65.62%] [G loss: 1.013246]\n",
      "epoch:37 step:34741 [D loss: 0.677575, acc.: 58.59%] [G loss: 0.938265]\n",
      "epoch:37 step:34742 [D loss: 0.600003, acc.: 67.97%] [G loss: 0.985848]\n",
      "epoch:37 step:34743 [D loss: 0.653789, acc.: 61.72%] [G loss: 0.933630]\n",
      "epoch:37 step:34744 [D loss: 0.641150, acc.: 67.97%] [G loss: 0.897527]\n",
      "epoch:37 step:34745 [D loss: 0.559806, acc.: 74.22%] [G loss: 0.964854]\n",
      "epoch:37 step:34746 [D loss: 0.616760, acc.: 63.28%] [G loss: 0.927500]\n",
      "epoch:37 step:34747 [D loss: 0.649280, acc.: 61.72%] [G loss: 0.938972]\n",
      "epoch:37 step:34748 [D loss: 0.671658, acc.: 57.81%] [G loss: 0.971369]\n",
      "epoch:37 step:34749 [D loss: 0.650948, acc.: 64.06%] [G loss: 0.995516]\n",
      "epoch:37 step:34750 [D loss: 0.639172, acc.: 64.06%] [G loss: 0.913348]\n",
      "epoch:37 step:34751 [D loss: 0.633398, acc.: 62.50%] [G loss: 0.887581]\n",
      "epoch:37 step:34752 [D loss: 0.649379, acc.: 57.81%] [G loss: 1.028227]\n",
      "epoch:37 step:34753 [D loss: 0.634199, acc.: 67.19%] [G loss: 0.985193]\n",
      "epoch:37 step:34754 [D loss: 0.634420, acc.: 62.50%] [G loss: 0.970726]\n",
      "epoch:37 step:34755 [D loss: 0.631666, acc.: 68.75%] [G loss: 0.875727]\n",
      "epoch:37 step:34756 [D loss: 0.661805, acc.: 61.72%] [G loss: 0.949223]\n",
      "epoch:37 step:34757 [D loss: 0.640379, acc.: 63.28%] [G loss: 1.009562]\n",
      "epoch:37 step:34758 [D loss: 0.603293, acc.: 68.75%] [G loss: 0.977007]\n",
      "epoch:37 step:34759 [D loss: 0.669820, acc.: 60.16%] [G loss: 0.916868]\n",
      "epoch:37 step:34760 [D loss: 0.646529, acc.: 60.94%] [G loss: 0.949481]\n",
      "epoch:37 step:34761 [D loss: 0.625112, acc.: 65.62%] [G loss: 0.889008]\n",
      "epoch:37 step:34762 [D loss: 0.670261, acc.: 60.16%] [G loss: 0.900688]\n",
      "epoch:37 step:34763 [D loss: 0.608817, acc.: 69.53%] [G loss: 0.921253]\n",
      "epoch:37 step:34764 [D loss: 0.631325, acc.: 62.50%] [G loss: 0.893510]\n",
      "epoch:37 step:34765 [D loss: 0.604207, acc.: 70.31%] [G loss: 0.946984]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:34766 [D loss: 0.623060, acc.: 66.41%] [G loss: 0.902187]\n",
      "epoch:37 step:34767 [D loss: 0.641870, acc.: 60.94%] [G loss: 1.009735]\n",
      "epoch:37 step:34768 [D loss: 0.710428, acc.: 53.91%] [G loss: 0.945008]\n",
      "epoch:37 step:34769 [D loss: 0.657047, acc.: 62.50%] [G loss: 0.966727]\n",
      "epoch:37 step:34770 [D loss: 0.668791, acc.: 63.28%] [G loss: 0.997290]\n",
      "epoch:37 step:34771 [D loss: 0.679219, acc.: 55.47%] [G loss: 0.978965]\n",
      "epoch:37 step:34772 [D loss: 0.621172, acc.: 64.06%] [G loss: 0.994140]\n",
      "epoch:37 step:34773 [D loss: 0.635418, acc.: 62.50%] [G loss: 0.945889]\n",
      "epoch:37 step:34774 [D loss: 0.683456, acc.: 55.47%] [G loss: 0.899709]\n",
      "epoch:37 step:34775 [D loss: 0.622552, acc.: 64.06%] [G loss: 0.937603]\n",
      "epoch:37 step:34776 [D loss: 0.626050, acc.: 62.50%] [G loss: 0.968313]\n",
      "epoch:37 step:34777 [D loss: 0.637100, acc.: 65.62%] [G loss: 1.013211]\n",
      "epoch:37 step:34778 [D loss: 0.608325, acc.: 66.41%] [G loss: 0.888052]\n",
      "epoch:37 step:34779 [D loss: 0.663281, acc.: 60.94%] [G loss: 0.979651]\n",
      "epoch:37 step:34780 [D loss: 0.653442, acc.: 58.59%] [G loss: 0.967219]\n",
      "epoch:37 step:34781 [D loss: 0.685473, acc.: 58.59%] [G loss: 0.880141]\n",
      "epoch:37 step:34782 [D loss: 0.607650, acc.: 71.88%] [G loss: 0.936237]\n",
      "epoch:37 step:34783 [D loss: 0.631126, acc.: 63.28%] [G loss: 0.930112]\n",
      "epoch:37 step:34784 [D loss: 0.612260, acc.: 64.84%] [G loss: 0.985455]\n",
      "epoch:37 step:34785 [D loss: 0.626991, acc.: 65.62%] [G loss: 1.021813]\n",
      "epoch:37 step:34786 [D loss: 0.687515, acc.: 55.47%] [G loss: 0.980640]\n",
      "epoch:37 step:34787 [D loss: 0.644628, acc.: 58.59%] [G loss: 0.971574]\n",
      "epoch:37 step:34788 [D loss: 0.676257, acc.: 60.94%] [G loss: 0.952735]\n",
      "epoch:37 step:34789 [D loss: 0.680459, acc.: 54.69%] [G loss: 0.908883]\n",
      "epoch:37 step:34790 [D loss: 0.612964, acc.: 67.97%] [G loss: 0.930263]\n",
      "epoch:37 step:34791 [D loss: 0.646429, acc.: 60.16%] [G loss: 0.888453]\n",
      "epoch:37 step:34792 [D loss: 0.644244, acc.: 63.28%] [G loss: 0.943718]\n",
      "epoch:37 step:34793 [D loss: 0.632204, acc.: 63.28%] [G loss: 1.015913]\n",
      "epoch:37 step:34794 [D loss: 0.606617, acc.: 68.75%] [G loss: 0.985181]\n",
      "epoch:37 step:34795 [D loss: 0.658873, acc.: 53.12%] [G loss: 0.962169]\n",
      "epoch:37 step:34796 [D loss: 0.665187, acc.: 59.38%] [G loss: 0.960551]\n",
      "epoch:37 step:34797 [D loss: 0.661259, acc.: 61.72%] [G loss: 0.867811]\n",
      "epoch:37 step:34798 [D loss: 0.653970, acc.: 57.81%] [G loss: 0.891760]\n",
      "epoch:37 step:34799 [D loss: 0.577212, acc.: 72.66%] [G loss: 0.927698]\n",
      "epoch:37 step:34800 [D loss: 0.602642, acc.: 69.53%] [G loss: 0.996966]\n",
      "##############\n",
      "[2.98513542 2.32420145 2.11952046 4.2594511  1.34459462 7.33880485\n",
      " 2.16167738 3.61198399 4.16686718 7.14771273]\n",
      "##########\n",
      "epoch:37 step:34801 [D loss: 0.679437, acc.: 55.47%] [G loss: 0.934030]\n",
      "epoch:37 step:34802 [D loss: 0.633388, acc.: 60.16%] [G loss: 0.916664]\n",
      "epoch:37 step:34803 [D loss: 0.691334, acc.: 54.69%] [G loss: 0.897359]\n",
      "epoch:37 step:34804 [D loss: 0.656507, acc.: 60.16%] [G loss: 0.884759]\n",
      "epoch:37 step:34805 [D loss: 0.645467, acc.: 64.84%] [G loss: 0.866814]\n",
      "epoch:37 step:34806 [D loss: 0.609175, acc.: 63.28%] [G loss: 0.931094]\n",
      "epoch:37 step:34807 [D loss: 0.622273, acc.: 67.19%] [G loss: 0.924827]\n",
      "epoch:37 step:34808 [D loss: 0.658617, acc.: 61.72%] [G loss: 0.943852]\n",
      "epoch:37 step:34809 [D loss: 0.626128, acc.: 60.94%] [G loss: 0.937322]\n",
      "epoch:37 step:34810 [D loss: 0.681182, acc.: 56.25%] [G loss: 0.870757]\n",
      "epoch:37 step:34811 [D loss: 0.637901, acc.: 57.81%] [G loss: 0.983518]\n",
      "epoch:37 step:34812 [D loss: 0.603335, acc.: 71.09%] [G loss: 0.957405]\n",
      "epoch:37 step:34813 [D loss: 0.633099, acc.: 66.41%] [G loss: 0.943154]\n",
      "epoch:37 step:34814 [D loss: 0.663637, acc.: 56.25%] [G loss: 0.963385]\n",
      "epoch:37 step:34815 [D loss: 0.602848, acc.: 71.09%] [G loss: 1.048540]\n",
      "epoch:37 step:34816 [D loss: 0.672130, acc.: 53.12%] [G loss: 0.922828]\n",
      "epoch:37 step:34817 [D loss: 0.642121, acc.: 58.59%] [G loss: 0.984377]\n",
      "epoch:37 step:34818 [D loss: 0.641900, acc.: 65.62%] [G loss: 0.932968]\n",
      "epoch:37 step:34819 [D loss: 0.653616, acc.: 57.03%] [G loss: 0.887466]\n",
      "epoch:37 step:34820 [D loss: 0.633214, acc.: 60.94%] [G loss: 0.972114]\n",
      "epoch:37 step:34821 [D loss: 0.633750, acc.: 61.72%] [G loss: 0.898689]\n",
      "epoch:37 step:34822 [D loss: 0.604990, acc.: 67.97%] [G loss: 0.958531]\n",
      "epoch:37 step:34823 [D loss: 0.659846, acc.: 55.47%] [G loss: 0.953472]\n",
      "epoch:37 step:34824 [D loss: 0.651394, acc.: 62.50%] [G loss: 0.902260]\n",
      "epoch:37 step:34825 [D loss: 0.598593, acc.: 69.53%] [G loss: 0.910651]\n",
      "epoch:37 step:34826 [D loss: 0.655138, acc.: 64.06%] [G loss: 0.918121]\n",
      "epoch:37 step:34827 [D loss: 0.648072, acc.: 61.72%] [G loss: 0.973212]\n",
      "epoch:37 step:34828 [D loss: 0.627841, acc.: 63.28%] [G loss: 0.945104]\n",
      "epoch:37 step:34829 [D loss: 0.666993, acc.: 58.59%] [G loss: 0.955200]\n",
      "epoch:37 step:34830 [D loss: 0.626953, acc.: 64.06%] [G loss: 0.962554]\n",
      "epoch:37 step:34831 [D loss: 0.625704, acc.: 63.28%] [G loss: 0.987333]\n",
      "epoch:37 step:34832 [D loss: 0.659885, acc.: 64.06%] [G loss: 0.955206]\n",
      "epoch:37 step:34833 [D loss: 0.656368, acc.: 60.94%] [G loss: 1.011500]\n",
      "epoch:37 step:34834 [D loss: 0.655957, acc.: 60.94%] [G loss: 0.965174]\n",
      "epoch:37 step:34835 [D loss: 0.662660, acc.: 58.59%] [G loss: 0.926241]\n",
      "epoch:37 step:34836 [D loss: 0.662994, acc.: 58.59%] [G loss: 1.003955]\n",
      "epoch:37 step:34837 [D loss: 0.650378, acc.: 66.41%] [G loss: 0.973257]\n",
      "epoch:37 step:34838 [D loss: 0.634337, acc.: 60.94%] [G loss: 0.988430]\n",
      "epoch:37 step:34839 [D loss: 0.594678, acc.: 67.97%] [G loss: 0.955477]\n",
      "epoch:37 step:34840 [D loss: 0.700557, acc.: 53.12%] [G loss: 0.926831]\n",
      "epoch:37 step:34841 [D loss: 0.678294, acc.: 55.47%] [G loss: 0.881406]\n",
      "epoch:37 step:34842 [D loss: 0.601575, acc.: 65.62%] [G loss: 0.888423]\n",
      "epoch:37 step:34843 [D loss: 0.611488, acc.: 63.28%] [G loss: 0.924430]\n",
      "epoch:37 step:34844 [D loss: 0.680773, acc.: 58.59%] [G loss: 0.894819]\n",
      "epoch:37 step:34845 [D loss: 0.576166, acc.: 72.66%] [G loss: 0.882455]\n",
      "epoch:37 step:34846 [D loss: 0.620569, acc.: 69.53%] [G loss: 0.988183]\n",
      "epoch:37 step:34847 [D loss: 0.660088, acc.: 53.91%] [G loss: 0.936818]\n",
      "epoch:37 step:34848 [D loss: 0.630306, acc.: 64.84%] [G loss: 0.927312]\n",
      "epoch:37 step:34849 [D loss: 0.580400, acc.: 71.88%] [G loss: 0.922761]\n",
      "epoch:37 step:34850 [D loss: 0.687996, acc.: 52.34%] [G loss: 0.976157]\n",
      "epoch:37 step:34851 [D loss: 0.640409, acc.: 64.84%] [G loss: 0.889901]\n",
      "epoch:37 step:34852 [D loss: 0.652716, acc.: 57.81%] [G loss: 0.950809]\n",
      "epoch:37 step:34853 [D loss: 0.671286, acc.: 59.38%] [G loss: 0.917897]\n",
      "epoch:37 step:34854 [D loss: 0.653124, acc.: 58.59%] [G loss: 0.964972]\n",
      "epoch:37 step:34855 [D loss: 0.628691, acc.: 62.50%] [G loss: 0.978348]\n",
      "epoch:37 step:34856 [D loss: 0.666170, acc.: 58.59%] [G loss: 0.937646]\n",
      "epoch:37 step:34857 [D loss: 0.670026, acc.: 56.25%] [G loss: 0.931207]\n",
      "epoch:37 step:34858 [D loss: 0.653740, acc.: 67.19%] [G loss: 0.921106]\n",
      "epoch:37 step:34859 [D loss: 0.693496, acc.: 55.47%] [G loss: 0.939336]\n",
      "epoch:37 step:34860 [D loss: 0.680784, acc.: 56.25%] [G loss: 0.957081]\n",
      "epoch:37 step:34861 [D loss: 0.679479, acc.: 57.81%] [G loss: 0.935754]\n",
      "epoch:37 step:34862 [D loss: 0.590568, acc.: 73.44%] [G loss: 0.994303]\n",
      "epoch:37 step:34863 [D loss: 0.679751, acc.: 61.72%] [G loss: 1.008238]\n",
      "epoch:37 step:34864 [D loss: 0.613080, acc.: 67.19%] [G loss: 0.966104]\n",
      "epoch:37 step:34865 [D loss: 0.640699, acc.: 60.94%] [G loss: 0.912835]\n",
      "epoch:37 step:34866 [D loss: 0.637163, acc.: 61.72%] [G loss: 0.912393]\n",
      "epoch:37 step:34867 [D loss: 0.612201, acc.: 63.28%] [G loss: 0.944635]\n",
      "epoch:37 step:34868 [D loss: 0.656016, acc.: 58.59%] [G loss: 0.937388]\n",
      "epoch:37 step:34869 [D loss: 0.650872, acc.: 61.72%] [G loss: 0.939803]\n",
      "epoch:37 step:34870 [D loss: 0.622310, acc.: 64.84%] [G loss: 0.970874]\n",
      "epoch:37 step:34871 [D loss: 0.642173, acc.: 58.59%] [G loss: 0.961398]\n",
      "epoch:37 step:34872 [D loss: 0.628009, acc.: 59.38%] [G loss: 0.966177]\n",
      "epoch:37 step:34873 [D loss: 0.628086, acc.: 64.84%] [G loss: 0.956444]\n",
      "epoch:37 step:34874 [D loss: 0.663149, acc.: 63.28%] [G loss: 0.980742]\n",
      "epoch:37 step:34875 [D loss: 0.622211, acc.: 64.06%] [G loss: 0.975896]\n",
      "epoch:37 step:34876 [D loss: 0.644511, acc.: 62.50%] [G loss: 0.895710]\n",
      "epoch:37 step:34877 [D loss: 0.608012, acc.: 72.66%] [G loss: 1.037194]\n",
      "epoch:37 step:34878 [D loss: 0.668796, acc.: 60.16%] [G loss: 0.988413]\n",
      "epoch:37 step:34879 [D loss: 0.643302, acc.: 60.94%] [G loss: 0.940642]\n",
      "epoch:37 step:34880 [D loss: 0.643544, acc.: 60.16%] [G loss: 0.963109]\n",
      "epoch:37 step:34881 [D loss: 0.609391, acc.: 71.09%] [G loss: 0.949916]\n",
      "epoch:37 step:34882 [D loss: 0.694021, acc.: 60.16%] [G loss: 0.947301]\n",
      "epoch:37 step:34883 [D loss: 0.675008, acc.: 54.69%] [G loss: 0.956275]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:34884 [D loss: 0.636285, acc.: 64.06%] [G loss: 0.945699]\n",
      "epoch:37 step:34885 [D loss: 0.627696, acc.: 62.50%] [G loss: 0.949363]\n",
      "epoch:37 step:34886 [D loss: 0.612243, acc.: 67.97%] [G loss: 0.935686]\n",
      "epoch:37 step:34887 [D loss: 0.665489, acc.: 57.81%] [G loss: 0.968431]\n",
      "epoch:37 step:34888 [D loss: 0.691949, acc.: 57.03%] [G loss: 1.001657]\n",
      "epoch:37 step:34889 [D loss: 0.636077, acc.: 64.84%] [G loss: 0.958596]\n",
      "epoch:37 step:34890 [D loss: 0.597204, acc.: 65.62%] [G loss: 0.924992]\n",
      "epoch:37 step:34891 [D loss: 0.673230, acc.: 58.59%] [G loss: 0.880674]\n",
      "epoch:37 step:34892 [D loss: 0.644939, acc.: 60.94%] [G loss: 0.976504]\n",
      "epoch:37 step:34893 [D loss: 0.664664, acc.: 64.84%] [G loss: 0.918478]\n",
      "epoch:37 step:34894 [D loss: 0.631951, acc.: 58.59%] [G loss: 0.920885]\n",
      "epoch:37 step:34895 [D loss: 0.617475, acc.: 68.75%] [G loss: 0.915472]\n",
      "epoch:37 step:34896 [D loss: 0.686955, acc.: 56.25%] [G loss: 0.896643]\n",
      "epoch:37 step:34897 [D loss: 0.635907, acc.: 60.94%] [G loss: 0.922293]\n",
      "epoch:37 step:34898 [D loss: 0.622261, acc.: 67.19%] [G loss: 0.942072]\n",
      "epoch:37 step:34899 [D loss: 0.656296, acc.: 63.28%] [G loss: 0.900490]\n",
      "epoch:37 step:34900 [D loss: 0.660115, acc.: 54.69%] [G loss: 0.951415]\n",
      "epoch:37 step:34901 [D loss: 0.655610, acc.: 57.81%] [G loss: 0.942131]\n",
      "epoch:37 step:34902 [D loss: 0.598030, acc.: 68.75%] [G loss: 0.907934]\n",
      "epoch:37 step:34903 [D loss: 0.683196, acc.: 55.47%] [G loss: 0.986987]\n",
      "epoch:37 step:34904 [D loss: 0.669203, acc.: 57.81%] [G loss: 1.010772]\n",
      "epoch:37 step:34905 [D loss: 0.629461, acc.: 64.84%] [G loss: 1.013652]\n",
      "epoch:37 step:34906 [D loss: 0.674607, acc.: 62.50%] [G loss: 0.948907]\n",
      "epoch:37 step:34907 [D loss: 0.629712, acc.: 64.06%] [G loss: 0.891120]\n",
      "epoch:37 step:34908 [D loss: 0.699638, acc.: 50.78%] [G loss: 0.927677]\n",
      "epoch:37 step:34909 [D loss: 0.619699, acc.: 67.19%] [G loss: 0.914488]\n",
      "epoch:37 step:34910 [D loss: 0.639061, acc.: 59.38%] [G loss: 0.958596]\n",
      "epoch:37 step:34911 [D loss: 0.648865, acc.: 61.72%] [G loss: 0.909008]\n",
      "epoch:37 step:34912 [D loss: 0.678093, acc.: 58.59%] [G loss: 0.948517]\n",
      "epoch:37 step:34913 [D loss: 0.666996, acc.: 57.81%] [G loss: 0.905368]\n",
      "epoch:37 step:34914 [D loss: 0.683981, acc.: 59.38%] [G loss: 0.892647]\n",
      "epoch:37 step:34915 [D loss: 0.652292, acc.: 61.72%] [G loss: 0.928707]\n",
      "epoch:37 step:34916 [D loss: 0.628216, acc.: 68.75%] [G loss: 0.983154]\n",
      "epoch:37 step:34917 [D loss: 0.662006, acc.: 59.38%] [G loss: 0.996809]\n",
      "epoch:37 step:34918 [D loss: 0.649927, acc.: 65.62%] [G loss: 0.939949]\n",
      "epoch:37 step:34919 [D loss: 0.684952, acc.: 60.16%] [G loss: 0.961877]\n",
      "epoch:37 step:34920 [D loss: 0.633873, acc.: 61.72%] [G loss: 0.964473]\n",
      "epoch:37 step:34921 [D loss: 0.630138, acc.: 69.53%] [G loss: 0.928062]\n",
      "epoch:37 step:34922 [D loss: 0.621181, acc.: 58.59%] [G loss: 0.976957]\n",
      "epoch:37 step:34923 [D loss: 0.655200, acc.: 59.38%] [G loss: 0.979126]\n",
      "epoch:37 step:34924 [D loss: 0.636662, acc.: 63.28%] [G loss: 0.873584]\n",
      "epoch:37 step:34925 [D loss: 0.627732, acc.: 67.19%] [G loss: 0.927163]\n",
      "epoch:37 step:34926 [D loss: 0.638476, acc.: 61.72%] [G loss: 0.930221]\n",
      "epoch:37 step:34927 [D loss: 0.610469, acc.: 68.75%] [G loss: 0.894724]\n",
      "epoch:37 step:34928 [D loss: 0.670645, acc.: 56.25%] [G loss: 0.923865]\n",
      "epoch:37 step:34929 [D loss: 0.637678, acc.: 64.84%] [G loss: 1.039270]\n",
      "epoch:37 step:34930 [D loss: 0.667383, acc.: 59.38%] [G loss: 0.879037]\n",
      "epoch:37 step:34931 [D loss: 0.689335, acc.: 58.59%] [G loss: 0.897353]\n",
      "epoch:37 step:34932 [D loss: 0.706982, acc.: 53.12%] [G loss: 0.960276]\n",
      "epoch:37 step:34933 [D loss: 0.654535, acc.: 61.72%] [G loss: 0.892616]\n",
      "epoch:37 step:34934 [D loss: 0.621333, acc.: 67.97%] [G loss: 0.938342]\n",
      "epoch:37 step:34935 [D loss: 0.641553, acc.: 60.16%] [G loss: 0.965101]\n",
      "epoch:37 step:34936 [D loss: 0.616138, acc.: 67.19%] [G loss: 0.936412]\n",
      "epoch:37 step:34937 [D loss: 0.651967, acc.: 59.38%] [G loss: 0.976551]\n",
      "epoch:37 step:34938 [D loss: 0.624914, acc.: 60.94%] [G loss: 0.944715]\n",
      "epoch:37 step:34939 [D loss: 0.660208, acc.: 60.16%] [G loss: 0.964089]\n",
      "epoch:37 step:34940 [D loss: 0.603580, acc.: 64.06%] [G loss: 0.981759]\n",
      "epoch:37 step:34941 [D loss: 0.652688, acc.: 62.50%] [G loss: 0.985165]\n",
      "epoch:37 step:34942 [D loss: 0.687415, acc.: 54.69%] [G loss: 0.918319]\n",
      "epoch:37 step:34943 [D loss: 0.654133, acc.: 55.47%] [G loss: 0.904139]\n",
      "epoch:37 step:34944 [D loss: 0.621119, acc.: 67.19%] [G loss: 0.909560]\n",
      "epoch:37 step:34945 [D loss: 0.658947, acc.: 62.50%] [G loss: 0.940954]\n",
      "epoch:37 step:34946 [D loss: 0.649260, acc.: 57.03%] [G loss: 0.945269]\n",
      "epoch:37 step:34947 [D loss: 0.673249, acc.: 59.38%] [G loss: 0.866887]\n",
      "epoch:37 step:34948 [D loss: 0.670714, acc.: 61.72%] [G loss: 0.926323]\n",
      "epoch:37 step:34949 [D loss: 0.658551, acc.: 60.16%] [G loss: 0.899147]\n",
      "epoch:37 step:34950 [D loss: 0.638998, acc.: 66.41%] [G loss: 0.938675]\n",
      "epoch:37 step:34951 [D loss: 0.633190, acc.: 65.62%] [G loss: 0.892895]\n",
      "epoch:37 step:34952 [D loss: 0.652393, acc.: 60.16%] [G loss: 0.932873]\n",
      "epoch:37 step:34953 [D loss: 0.588591, acc.: 70.31%] [G loss: 0.955366]\n",
      "epoch:37 step:34954 [D loss: 0.640589, acc.: 60.94%] [G loss: 1.066427]\n",
      "epoch:37 step:34955 [D loss: 0.631212, acc.: 63.28%] [G loss: 0.979031]\n",
      "epoch:37 step:34956 [D loss: 0.647037, acc.: 61.72%] [G loss: 0.916454]\n",
      "epoch:37 step:34957 [D loss: 0.664570, acc.: 58.59%] [G loss: 0.955647]\n",
      "epoch:37 step:34958 [D loss: 0.700234, acc.: 52.34%] [G loss: 0.843330]\n",
      "epoch:37 step:34959 [D loss: 0.593635, acc.: 66.41%] [G loss: 0.930231]\n",
      "epoch:37 step:34960 [D loss: 0.618974, acc.: 64.06%] [G loss: 0.942319]\n",
      "epoch:37 step:34961 [D loss: 0.675410, acc.: 60.16%] [G loss: 0.954202]\n",
      "epoch:37 step:34962 [D loss: 0.636491, acc.: 57.03%] [G loss: 1.021972]\n",
      "epoch:37 step:34963 [D loss: 0.627552, acc.: 67.19%] [G loss: 0.961872]\n",
      "epoch:37 step:34964 [D loss: 0.662269, acc.: 62.50%] [G loss: 0.912193]\n",
      "epoch:37 step:34965 [D loss: 0.611849, acc.: 64.84%] [G loss: 0.904853]\n",
      "epoch:37 step:34966 [D loss: 0.594751, acc.: 68.75%] [G loss: 0.940673]\n",
      "epoch:37 step:34967 [D loss: 0.704937, acc.: 56.25%] [G loss: 0.952762]\n",
      "epoch:37 step:34968 [D loss: 0.634161, acc.: 62.50%] [G loss: 0.918063]\n",
      "epoch:37 step:34969 [D loss: 0.594645, acc.: 69.53%] [G loss: 0.975380]\n",
      "epoch:37 step:34970 [D loss: 0.669815, acc.: 57.03%] [G loss: 0.878557]\n",
      "epoch:37 step:34971 [D loss: 0.630364, acc.: 66.41%] [G loss: 0.931707]\n",
      "epoch:37 step:34972 [D loss: 0.675203, acc.: 60.16%] [G loss: 0.932761]\n",
      "epoch:37 step:34973 [D loss: 0.650935, acc.: 61.72%] [G loss: 0.916381]\n",
      "epoch:37 step:34974 [D loss: 0.656217, acc.: 58.59%] [G loss: 0.877028]\n",
      "epoch:37 step:34975 [D loss: 0.643874, acc.: 60.16%] [G loss: 0.911032]\n",
      "epoch:37 step:34976 [D loss: 0.696750, acc.: 52.34%] [G loss: 0.901990]\n",
      "epoch:37 step:34977 [D loss: 0.665566, acc.: 60.94%] [G loss: 0.937240]\n",
      "epoch:37 step:34978 [D loss: 0.668750, acc.: 60.94%] [G loss: 0.927967]\n",
      "epoch:37 step:34979 [D loss: 0.632495, acc.: 64.84%] [G loss: 0.994740]\n",
      "epoch:37 step:34980 [D loss: 0.621443, acc.: 65.62%] [G loss: 1.013790]\n",
      "epoch:37 step:34981 [D loss: 0.637868, acc.: 57.81%] [G loss: 0.927443]\n",
      "epoch:37 step:34982 [D loss: 0.677114, acc.: 56.25%] [G loss: 0.911524]\n",
      "epoch:37 step:34983 [D loss: 0.601829, acc.: 70.31%] [G loss: 0.974352]\n",
      "epoch:37 step:34984 [D loss: 0.617038, acc.: 64.06%] [G loss: 0.936976]\n",
      "epoch:37 step:34985 [D loss: 0.629500, acc.: 61.72%] [G loss: 0.954513]\n",
      "epoch:37 step:34986 [D loss: 0.631107, acc.: 64.84%] [G loss: 0.949546]\n",
      "epoch:37 step:34987 [D loss: 0.655115, acc.: 55.47%] [G loss: 0.927351]\n",
      "epoch:37 step:34988 [D loss: 0.668367, acc.: 59.38%] [G loss: 0.850599]\n",
      "epoch:37 step:34989 [D loss: 0.646951, acc.: 54.69%] [G loss: 0.954960]\n",
      "epoch:37 step:34990 [D loss: 0.651378, acc.: 60.16%] [G loss: 0.940879]\n",
      "epoch:37 step:34991 [D loss: 0.651140, acc.: 60.94%] [G loss: 0.919295]\n",
      "epoch:37 step:34992 [D loss: 0.636943, acc.: 57.81%] [G loss: 0.942552]\n",
      "epoch:37 step:34993 [D loss: 0.661823, acc.: 57.81%] [G loss: 0.911821]\n",
      "epoch:37 step:34994 [D loss: 0.665627, acc.: 64.06%] [G loss: 0.939536]\n",
      "epoch:37 step:34995 [D loss: 0.674608, acc.: 59.38%] [G loss: 0.888552]\n",
      "epoch:37 step:34996 [D loss: 0.588332, acc.: 73.44%] [G loss: 0.997884]\n",
      "epoch:37 step:34997 [D loss: 0.615575, acc.: 61.72%] [G loss: 0.958693]\n",
      "epoch:37 step:34998 [D loss: 0.614098, acc.: 67.97%] [G loss: 0.950211]\n",
      "epoch:37 step:34999 [D loss: 0.621377, acc.: 66.41%] [G loss: 0.984578]\n",
      "epoch:37 step:35000 [D loss: 0.668805, acc.: 55.47%] [G loss: 0.990832]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[3.11695348 2.39374677 2.33792985 4.25093924 1.22724515 8.2288177\n",
      " 3.02602246 3.52313906 4.40910408 8.14868929]\n",
      "##########\n",
      "epoch:37 step:35001 [D loss: 0.642506, acc.: 61.72%] [G loss: 0.909966]\n",
      "epoch:37 step:35002 [D loss: 0.678808, acc.: 58.59%] [G loss: 0.935812]\n",
      "epoch:37 step:35003 [D loss: 0.609135, acc.: 67.19%] [G loss: 1.009825]\n",
      "epoch:37 step:35004 [D loss: 0.642647, acc.: 60.94%] [G loss: 0.939370]\n",
      "epoch:37 step:35005 [D loss: 0.617491, acc.: 62.50%] [G loss: 0.953697]\n",
      "epoch:37 step:35006 [D loss: 0.644974, acc.: 60.16%] [G loss: 0.939340]\n",
      "epoch:37 step:35007 [D loss: 0.647625, acc.: 57.81%] [G loss: 0.935371]\n",
      "epoch:37 step:35008 [D loss: 0.640081, acc.: 62.50%] [G loss: 0.879577]\n",
      "epoch:37 step:35009 [D loss: 0.675180, acc.: 54.69%] [G loss: 0.931347]\n",
      "epoch:37 step:35010 [D loss: 0.689137, acc.: 49.22%] [G loss: 0.930966]\n",
      "epoch:37 step:35011 [D loss: 0.633806, acc.: 60.94%] [G loss: 0.969401]\n",
      "epoch:37 step:35012 [D loss: 0.646708, acc.: 60.16%] [G loss: 0.963611]\n",
      "epoch:37 step:35013 [D loss: 0.636067, acc.: 65.62%] [G loss: 0.941351]\n",
      "epoch:37 step:35014 [D loss: 0.614052, acc.: 65.62%] [G loss: 1.016850]\n",
      "epoch:37 step:35015 [D loss: 0.652088, acc.: 62.50%] [G loss: 1.011836]\n",
      "epoch:37 step:35016 [D loss: 0.641718, acc.: 63.28%] [G loss: 0.932809]\n",
      "epoch:37 step:35017 [D loss: 0.641852, acc.: 64.06%] [G loss: 0.916066]\n",
      "epoch:37 step:35018 [D loss: 0.663006, acc.: 56.25%] [G loss: 0.930685]\n",
      "epoch:37 step:35019 [D loss: 0.655057, acc.: 61.72%] [G loss: 0.946722]\n",
      "epoch:37 step:35020 [D loss: 0.607549, acc.: 66.41%] [G loss: 0.930920]\n",
      "epoch:37 step:35021 [D loss: 0.659517, acc.: 56.25%] [G loss: 0.917355]\n",
      "epoch:37 step:35022 [D loss: 0.623587, acc.: 62.50%] [G loss: 0.916205]\n",
      "epoch:37 step:35023 [D loss: 0.676140, acc.: 57.81%] [G loss: 0.838745]\n",
      "epoch:37 step:35024 [D loss: 0.644139, acc.: 65.62%] [G loss: 0.898228]\n",
      "epoch:37 step:35025 [D loss: 0.621616, acc.: 63.28%] [G loss: 0.952167]\n",
      "epoch:37 step:35026 [D loss: 0.653700, acc.: 65.62%] [G loss: 0.880817]\n",
      "epoch:37 step:35027 [D loss: 0.620659, acc.: 62.50%] [G loss: 0.898555]\n",
      "epoch:37 step:35028 [D loss: 0.658114, acc.: 62.50%] [G loss: 0.918847]\n",
      "epoch:37 step:35029 [D loss: 0.620900, acc.: 67.19%] [G loss: 0.990408]\n",
      "epoch:37 step:35030 [D loss: 0.655792, acc.: 63.28%] [G loss: 1.039237]\n",
      "epoch:37 step:35031 [D loss: 0.624614, acc.: 63.28%] [G loss: 1.017717]\n",
      "epoch:37 step:35032 [D loss: 0.647587, acc.: 62.50%] [G loss: 1.015874]\n",
      "epoch:37 step:35033 [D loss: 0.638007, acc.: 57.81%] [G loss: 0.982030]\n",
      "epoch:37 step:35034 [D loss: 0.664266, acc.: 55.47%] [G loss: 0.967360]\n",
      "epoch:37 step:35035 [D loss: 0.693666, acc.: 51.56%] [G loss: 0.931803]\n",
      "epoch:37 step:35036 [D loss: 0.649970, acc.: 64.06%] [G loss: 0.942665]\n",
      "epoch:37 step:35037 [D loss: 0.693708, acc.: 56.25%] [G loss: 0.937512]\n",
      "epoch:37 step:35038 [D loss: 0.661633, acc.: 62.50%] [G loss: 0.922600]\n",
      "epoch:37 step:35039 [D loss: 0.619789, acc.: 66.41%] [G loss: 0.864817]\n",
      "epoch:37 step:35040 [D loss: 0.629181, acc.: 66.41%] [G loss: 0.881003]\n",
      "epoch:37 step:35041 [D loss: 0.681951, acc.: 55.47%] [G loss: 0.902158]\n",
      "epoch:37 step:35042 [D loss: 0.632381, acc.: 67.19%] [G loss: 0.975017]\n",
      "epoch:37 step:35043 [D loss: 0.665650, acc.: 56.25%] [G loss: 0.950369]\n",
      "epoch:37 step:35044 [D loss: 0.631169, acc.: 62.50%] [G loss: 0.911886]\n",
      "epoch:37 step:35045 [D loss: 0.654511, acc.: 61.72%] [G loss: 0.892828]\n",
      "epoch:37 step:35046 [D loss: 0.656784, acc.: 62.50%] [G loss: 0.931809]\n",
      "epoch:37 step:35047 [D loss: 0.609627, acc.: 67.97%] [G loss: 0.959685]\n",
      "epoch:37 step:35048 [D loss: 0.646294, acc.: 62.50%] [G loss: 0.969567]\n",
      "epoch:37 step:35049 [D loss: 0.662902, acc.: 61.72%] [G loss: 0.927955]\n",
      "epoch:37 step:35050 [D loss: 0.661935, acc.: 60.94%] [G loss: 0.983585]\n",
      "epoch:37 step:35051 [D loss: 0.633702, acc.: 64.84%] [G loss: 0.930088]\n",
      "epoch:37 step:35052 [D loss: 0.667257, acc.: 54.69%] [G loss: 0.859676]\n",
      "epoch:37 step:35053 [D loss: 0.652406, acc.: 60.94%] [G loss: 0.917669]\n",
      "epoch:37 step:35054 [D loss: 0.645416, acc.: 56.25%] [G loss: 0.945503]\n",
      "epoch:37 step:35055 [D loss: 0.620057, acc.: 67.19%] [G loss: 0.963317]\n",
      "epoch:37 step:35056 [D loss: 0.635655, acc.: 67.19%] [G loss: 0.908766]\n",
      "epoch:37 step:35057 [D loss: 0.675532, acc.: 60.16%] [G loss: 0.953866]\n",
      "epoch:37 step:35058 [D loss: 0.569970, acc.: 74.22%] [G loss: 0.899334]\n",
      "epoch:37 step:35059 [D loss: 0.674070, acc.: 57.81%] [G loss: 0.920934]\n",
      "epoch:37 step:35060 [D loss: 0.663148, acc.: 57.81%] [G loss: 0.925311]\n",
      "epoch:37 step:35061 [D loss: 0.633245, acc.: 65.62%] [G loss: 0.935633]\n",
      "epoch:37 step:35062 [D loss: 0.695840, acc.: 53.91%] [G loss: 0.931328]\n",
      "epoch:37 step:35063 [D loss: 0.628765, acc.: 59.38%] [G loss: 0.944017]\n",
      "epoch:37 step:35064 [D loss: 0.663605, acc.: 61.72%] [G loss: 0.911015]\n",
      "epoch:37 step:35065 [D loss: 0.629429, acc.: 64.06%] [G loss: 0.875857]\n",
      "epoch:37 step:35066 [D loss: 0.688784, acc.: 54.69%] [G loss: 0.937497]\n",
      "epoch:37 step:35067 [D loss: 0.700314, acc.: 50.78%] [G loss: 1.017995]\n",
      "epoch:37 step:35068 [D loss: 0.620656, acc.: 66.41%] [G loss: 0.949041]\n",
      "epoch:37 step:35069 [D loss: 0.622527, acc.: 64.84%] [G loss: 0.889258]\n",
      "epoch:37 step:35070 [D loss: 0.594439, acc.: 73.44%] [G loss: 1.035199]\n",
      "epoch:37 step:35071 [D loss: 0.627575, acc.: 64.84%] [G loss: 0.995756]\n",
      "epoch:37 step:35072 [D loss: 0.627117, acc.: 64.06%] [G loss: 0.975603]\n",
      "epoch:37 step:35073 [D loss: 0.625439, acc.: 67.19%] [G loss: 0.960602]\n",
      "epoch:37 step:35074 [D loss: 0.606740, acc.: 67.97%] [G loss: 1.029603]\n",
      "epoch:37 step:35075 [D loss: 0.629116, acc.: 65.62%] [G loss: 0.987356]\n",
      "epoch:37 step:35076 [D loss: 0.635538, acc.: 60.94%] [G loss: 0.904882]\n",
      "epoch:37 step:35077 [D loss: 0.691134, acc.: 54.69%] [G loss: 0.908603]\n",
      "epoch:37 step:35078 [D loss: 0.664803, acc.: 55.47%] [G loss: 0.948977]\n",
      "epoch:37 step:35079 [D loss: 0.666891, acc.: 58.59%] [G loss: 0.915648]\n",
      "epoch:37 step:35080 [D loss: 0.627723, acc.: 61.72%] [G loss: 0.942043]\n",
      "epoch:37 step:35081 [D loss: 0.661061, acc.: 61.72%] [G loss: 0.939421]\n",
      "epoch:37 step:35082 [D loss: 0.645007, acc.: 65.62%] [G loss: 0.943225]\n",
      "epoch:37 step:35083 [D loss: 0.638291, acc.: 58.59%] [G loss: 0.995166]\n",
      "epoch:37 step:35084 [D loss: 0.612385, acc.: 71.09%] [G loss: 1.001717]\n",
      "epoch:37 step:35085 [D loss: 0.612774, acc.: 71.09%] [G loss: 1.014723]\n",
      "epoch:37 step:35086 [D loss: 0.590882, acc.: 75.00%] [G loss: 0.980644]\n",
      "epoch:37 step:35087 [D loss: 0.654398, acc.: 58.59%] [G loss: 0.943398]\n",
      "epoch:37 step:35088 [D loss: 0.625480, acc.: 64.06%] [G loss: 0.913164]\n",
      "epoch:37 step:35089 [D loss: 0.634398, acc.: 64.84%] [G loss: 0.967102]\n",
      "epoch:37 step:35090 [D loss: 0.604731, acc.: 71.88%] [G loss: 0.973247]\n",
      "epoch:37 step:35091 [D loss: 0.648191, acc.: 62.50%] [G loss: 0.889895]\n",
      "epoch:37 step:35092 [D loss: 0.637078, acc.: 64.06%] [G loss: 0.918790]\n",
      "epoch:37 step:35093 [D loss: 0.664259, acc.: 57.81%] [G loss: 0.929316]\n",
      "epoch:37 step:35094 [D loss: 0.643751, acc.: 65.62%] [G loss: 0.987901]\n",
      "epoch:37 step:35095 [D loss: 0.664016, acc.: 61.72%] [G loss: 0.973300]\n",
      "epoch:37 step:35096 [D loss: 0.653632, acc.: 57.81%] [G loss: 0.921222]\n",
      "epoch:37 step:35097 [D loss: 0.685473, acc.: 60.94%] [G loss: 0.946540]\n",
      "epoch:37 step:35098 [D loss: 0.647259, acc.: 64.84%] [G loss: 1.029178]\n",
      "epoch:37 step:35099 [D loss: 0.635518, acc.: 64.06%] [G loss: 1.003012]\n",
      "epoch:37 step:35100 [D loss: 0.653509, acc.: 61.72%] [G loss: 0.986105]\n",
      "epoch:37 step:35101 [D loss: 0.637989, acc.: 64.84%] [G loss: 0.951362]\n",
      "epoch:37 step:35102 [D loss: 0.680202, acc.: 56.25%] [G loss: 0.922509]\n",
      "epoch:37 step:35103 [D loss: 0.621322, acc.: 69.53%] [G loss: 0.916241]\n",
      "epoch:37 step:35104 [D loss: 0.604885, acc.: 65.62%] [G loss: 0.884086]\n",
      "epoch:37 step:35105 [D loss: 0.649910, acc.: 65.62%] [G loss: 0.932602]\n",
      "epoch:37 step:35106 [D loss: 0.652645, acc.: 64.06%] [G loss: 0.926543]\n",
      "epoch:37 step:35107 [D loss: 0.662549, acc.: 60.16%] [G loss: 0.958705]\n",
      "epoch:37 step:35108 [D loss: 0.636776, acc.: 63.28%] [G loss: 0.943880]\n",
      "epoch:37 step:35109 [D loss: 0.639240, acc.: 57.81%] [G loss: 0.886028]\n",
      "epoch:37 step:35110 [D loss: 0.666360, acc.: 60.94%] [G loss: 0.919354]\n",
      "epoch:37 step:35111 [D loss: 0.675644, acc.: 60.16%] [G loss: 0.906094]\n",
      "epoch:37 step:35112 [D loss: 0.622566, acc.: 66.41%] [G loss: 0.907041]\n",
      "epoch:37 step:35113 [D loss: 0.609928, acc.: 64.84%] [G loss: 0.907936]\n",
      "epoch:37 step:35114 [D loss: 0.626553, acc.: 64.06%] [G loss: 0.967828]\n",
      "epoch:37 step:35115 [D loss: 0.678966, acc.: 57.03%] [G loss: 0.932094]\n",
      "epoch:37 step:35116 [D loss: 0.601092, acc.: 68.75%] [G loss: 0.916268]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:35117 [D loss: 0.661778, acc.: 59.38%] [G loss: 0.931481]\n",
      "epoch:37 step:35118 [D loss: 0.594711, acc.: 67.97%] [G loss: 0.915413]\n",
      "epoch:37 step:35119 [D loss: 0.653683, acc.: 57.03%] [G loss: 0.847507]\n",
      "epoch:37 step:35120 [D loss: 0.578014, acc.: 71.88%] [G loss: 0.943205]\n",
      "epoch:37 step:35121 [D loss: 0.623960, acc.: 64.06%] [G loss: 0.852632]\n",
      "epoch:37 step:35122 [D loss: 0.649726, acc.: 54.69%] [G loss: 0.889857]\n",
      "epoch:37 step:35123 [D loss: 0.635316, acc.: 60.94%] [G loss: 0.927441]\n",
      "epoch:37 step:35124 [D loss: 0.628468, acc.: 64.84%] [G loss: 0.908255]\n",
      "epoch:37 step:35125 [D loss: 0.661359, acc.: 62.50%] [G loss: 0.970320]\n",
      "epoch:37 step:35126 [D loss: 0.676428, acc.: 61.72%] [G loss: 0.965494]\n",
      "epoch:37 step:35127 [D loss: 0.657949, acc.: 60.16%] [G loss: 0.923771]\n",
      "epoch:37 step:35128 [D loss: 0.594821, acc.: 71.09%] [G loss: 0.909922]\n",
      "epoch:37 step:35129 [D loss: 0.586374, acc.: 64.06%] [G loss: 1.011091]\n",
      "epoch:37 step:35130 [D loss: 0.636590, acc.: 69.53%] [G loss: 0.972669]\n",
      "epoch:37 step:35131 [D loss: 0.645691, acc.: 60.16%] [G loss: 0.963964]\n",
      "epoch:37 step:35132 [D loss: 0.649549, acc.: 63.28%] [G loss: 0.959603]\n",
      "epoch:37 step:35133 [D loss: 0.639012, acc.: 58.59%] [G loss: 0.950356]\n",
      "epoch:37 step:35134 [D loss: 0.642715, acc.: 61.72%] [G loss: 0.879980]\n",
      "epoch:37 step:35135 [D loss: 0.667142, acc.: 60.16%] [G loss: 0.882871]\n",
      "epoch:37 step:35136 [D loss: 0.652365, acc.: 67.19%] [G loss: 0.919243]\n",
      "epoch:37 step:35137 [D loss: 0.615996, acc.: 64.84%] [G loss: 0.872252]\n",
      "epoch:37 step:35138 [D loss: 0.662869, acc.: 57.03%] [G loss: 0.927453]\n",
      "epoch:37 step:35139 [D loss: 0.659788, acc.: 62.50%] [G loss: 0.914249]\n",
      "epoch:37 step:35140 [D loss: 0.643261, acc.: 56.25%] [G loss: 0.965193]\n",
      "epoch:37 step:35141 [D loss: 0.616221, acc.: 67.19%] [G loss: 0.950656]\n",
      "epoch:37 step:35142 [D loss: 0.678406, acc.: 54.69%] [G loss: 0.984748]\n",
      "epoch:37 step:35143 [D loss: 0.598739, acc.: 64.84%] [G loss: 0.924458]\n",
      "epoch:37 step:35144 [D loss: 0.633062, acc.: 64.06%] [G loss: 0.936795]\n",
      "epoch:37 step:35145 [D loss: 0.644967, acc.: 57.81%] [G loss: 0.951573]\n",
      "epoch:37 step:35146 [D loss: 0.680880, acc.: 59.38%] [G loss: 0.944787]\n",
      "epoch:37 step:35147 [D loss: 0.640579, acc.: 60.94%] [G loss: 0.946160]\n",
      "epoch:37 step:35148 [D loss: 0.678726, acc.: 63.28%] [G loss: 0.916022]\n",
      "epoch:37 step:35149 [D loss: 0.649436, acc.: 62.50%] [G loss: 0.978535]\n",
      "epoch:37 step:35150 [D loss: 0.652917, acc.: 64.84%] [G loss: 0.944191]\n",
      "epoch:37 step:35151 [D loss: 0.653083, acc.: 60.94%] [G loss: 0.902355]\n",
      "epoch:37 step:35152 [D loss: 0.646696, acc.: 62.50%] [G loss: 0.903829]\n",
      "epoch:37 step:35153 [D loss: 0.643894, acc.: 58.59%] [G loss: 0.901677]\n",
      "epoch:37 step:35154 [D loss: 0.603052, acc.: 69.53%] [G loss: 0.947857]\n",
      "epoch:37 step:35155 [D loss: 0.634519, acc.: 64.06%] [G loss: 0.924218]\n",
      "epoch:37 step:35156 [D loss: 0.655953, acc.: 60.16%] [G loss: 0.940281]\n",
      "epoch:37 step:35157 [D loss: 0.580541, acc.: 71.09%] [G loss: 0.946972]\n",
      "epoch:37 step:35158 [D loss: 0.606642, acc.: 67.97%] [G loss: 0.916098]\n",
      "epoch:37 step:35159 [D loss: 0.605665, acc.: 64.84%] [G loss: 0.968243]\n",
      "epoch:37 step:35160 [D loss: 0.661096, acc.: 61.72%] [G loss: 0.925463]\n",
      "epoch:37 step:35161 [D loss: 0.696956, acc.: 53.12%] [G loss: 0.954995]\n",
      "epoch:37 step:35162 [D loss: 0.656206, acc.: 57.81%] [G loss: 0.886270]\n",
      "epoch:37 step:35163 [D loss: 0.621344, acc.: 64.84%] [G loss: 0.969144]\n",
      "epoch:37 step:35164 [D loss: 0.645260, acc.: 60.94%] [G loss: 1.013367]\n",
      "epoch:37 step:35165 [D loss: 0.655917, acc.: 60.94%] [G loss: 1.029505]\n",
      "epoch:37 step:35166 [D loss: 0.614080, acc.: 68.75%] [G loss: 0.962360]\n",
      "epoch:37 step:35167 [D loss: 0.645345, acc.: 65.62%] [G loss: 0.951661]\n",
      "epoch:37 step:35168 [D loss: 0.655666, acc.: 56.25%] [G loss: 0.918724]\n",
      "epoch:37 step:35169 [D loss: 0.654525, acc.: 64.06%] [G loss: 0.969362]\n",
      "epoch:37 step:35170 [D loss: 0.632809, acc.: 60.94%] [G loss: 0.933987]\n",
      "epoch:37 step:35171 [D loss: 0.641885, acc.: 63.28%] [G loss: 0.897034]\n",
      "epoch:37 step:35172 [D loss: 0.650890, acc.: 60.94%] [G loss: 0.907877]\n",
      "epoch:37 step:35173 [D loss: 0.617388, acc.: 64.84%] [G loss: 1.007202]\n",
      "epoch:37 step:35174 [D loss: 0.595032, acc.: 72.66%] [G loss: 1.010054]\n",
      "epoch:37 step:35175 [D loss: 0.622204, acc.: 61.72%] [G loss: 0.915895]\n",
      "epoch:37 step:35176 [D loss: 0.631858, acc.: 62.50%] [G loss: 0.936224]\n",
      "epoch:37 step:35177 [D loss: 0.621849, acc.: 62.50%] [G loss: 0.960204]\n",
      "epoch:37 step:35178 [D loss: 0.670987, acc.: 60.16%] [G loss: 0.969560]\n",
      "epoch:37 step:35179 [D loss: 0.593635, acc.: 67.19%] [G loss: 0.950426]\n",
      "epoch:37 step:35180 [D loss: 0.605199, acc.: 65.62%] [G loss: 0.915506]\n",
      "epoch:37 step:35181 [D loss: 0.646475, acc.: 58.59%] [G loss: 0.944775]\n",
      "epoch:37 step:35182 [D loss: 0.653913, acc.: 53.91%] [G loss: 0.921406]\n",
      "epoch:37 step:35183 [D loss: 0.624669, acc.: 63.28%] [G loss: 0.834651]\n",
      "epoch:37 step:35184 [D loss: 0.614574, acc.: 66.41%] [G loss: 0.893088]\n",
      "epoch:37 step:35185 [D loss: 0.638821, acc.: 60.16%] [G loss: 0.932693]\n",
      "epoch:37 step:35186 [D loss: 0.637515, acc.: 62.50%] [G loss: 0.980777]\n",
      "epoch:37 step:35187 [D loss: 0.661083, acc.: 61.72%] [G loss: 0.956117]\n",
      "epoch:37 step:35188 [D loss: 0.620221, acc.: 64.84%] [G loss: 0.915567]\n",
      "epoch:37 step:35189 [D loss: 0.626521, acc.: 60.94%] [G loss: 0.950015]\n",
      "epoch:37 step:35190 [D loss: 0.623498, acc.: 64.84%] [G loss: 0.939405]\n",
      "epoch:37 step:35191 [D loss: 0.655742, acc.: 61.72%] [G loss: 0.912480]\n",
      "epoch:37 step:35192 [D loss: 0.620940, acc.: 64.84%] [G loss: 0.952982]\n",
      "epoch:37 step:35193 [D loss: 0.646304, acc.: 63.28%] [G loss: 1.038024]\n",
      "epoch:37 step:35194 [D loss: 0.653376, acc.: 62.50%] [G loss: 0.993121]\n",
      "epoch:37 step:35195 [D loss: 0.686458, acc.: 59.38%] [G loss: 0.895301]\n",
      "epoch:37 step:35196 [D loss: 0.649982, acc.: 59.38%] [G loss: 0.864906]\n",
      "epoch:37 step:35197 [D loss: 0.692059, acc.: 50.78%] [G loss: 0.927604]\n",
      "epoch:37 step:35198 [D loss: 0.638990, acc.: 61.72%] [G loss: 0.926437]\n",
      "epoch:37 step:35199 [D loss: 0.600418, acc.: 66.41%] [G loss: 0.909214]\n",
      "epoch:37 step:35200 [D loss: 0.662319, acc.: 60.94%] [G loss: 0.971473]\n",
      "##############\n",
      "[3.12204244 2.37128409 2.23004793 3.82222103 1.40830934 7.84089624\n",
      " 2.71260546 3.74000758 4.30140907 8.14868929]\n",
      "##########\n",
      "epoch:37 step:35201 [D loss: 0.655005, acc.: 62.50%] [G loss: 0.992566]\n",
      "epoch:37 step:35202 [D loss: 0.649766, acc.: 61.72%] [G loss: 0.954972]\n",
      "epoch:37 step:35203 [D loss: 0.647314, acc.: 67.19%] [G loss: 0.947027]\n",
      "epoch:37 step:35204 [D loss: 0.657331, acc.: 60.94%] [G loss: 0.866143]\n",
      "epoch:37 step:35205 [D loss: 0.675333, acc.: 57.81%] [G loss: 0.878197]\n",
      "epoch:37 step:35206 [D loss: 0.643135, acc.: 65.62%] [G loss: 0.870202]\n",
      "epoch:37 step:35207 [D loss: 0.648165, acc.: 61.72%] [G loss: 0.877578]\n",
      "epoch:37 step:35208 [D loss: 0.664721, acc.: 60.16%] [G loss: 0.881307]\n",
      "epoch:37 step:35209 [D loss: 0.613361, acc.: 71.88%] [G loss: 0.918771]\n",
      "epoch:37 step:35210 [D loss: 0.694960, acc.: 53.12%] [G loss: 1.013345]\n",
      "epoch:37 step:35211 [D loss: 0.674677, acc.: 60.94%] [G loss: 0.994971]\n",
      "epoch:37 step:35212 [D loss: 0.616290, acc.: 63.28%] [G loss: 0.935800]\n",
      "epoch:37 step:35213 [D loss: 0.648803, acc.: 67.19%] [G loss: 0.986259]\n",
      "epoch:37 step:35214 [D loss: 0.651426, acc.: 61.72%] [G loss: 0.968122]\n",
      "epoch:37 step:35215 [D loss: 0.650475, acc.: 60.94%] [G loss: 0.958763]\n",
      "epoch:37 step:35216 [D loss: 0.663457, acc.: 51.56%] [G loss: 0.980175]\n",
      "epoch:37 step:35217 [D loss: 0.679025, acc.: 51.56%] [G loss: 0.922907]\n",
      "epoch:37 step:35218 [D loss: 0.644824, acc.: 61.72%] [G loss: 0.918087]\n",
      "epoch:37 step:35219 [D loss: 0.640856, acc.: 66.41%] [G loss: 0.963838]\n",
      "epoch:37 step:35220 [D loss: 0.673231, acc.: 56.25%] [G loss: 0.907283]\n",
      "epoch:37 step:35221 [D loss: 0.601152, acc.: 64.06%] [G loss: 0.936505]\n",
      "epoch:37 step:35222 [D loss: 0.639715, acc.: 63.28%] [G loss: 0.923571]\n",
      "epoch:37 step:35223 [D loss: 0.698361, acc.: 57.03%] [G loss: 0.956035]\n",
      "epoch:37 step:35224 [D loss: 0.676728, acc.: 60.16%] [G loss: 0.876535]\n",
      "epoch:37 step:35225 [D loss: 0.649686, acc.: 65.62%] [G loss: 0.916398]\n",
      "epoch:37 step:35226 [D loss: 0.663531, acc.: 57.81%] [G loss: 0.900143]\n",
      "epoch:37 step:35227 [D loss: 0.622620, acc.: 64.84%] [G loss: 0.907792]\n",
      "epoch:37 step:35228 [D loss: 0.653488, acc.: 53.12%] [G loss: 0.874397]\n",
      "epoch:37 step:35229 [D loss: 0.624947, acc.: 67.97%] [G loss: 0.951475]\n",
      "epoch:37 step:35230 [D loss: 0.640109, acc.: 64.84%] [G loss: 0.987004]\n",
      "epoch:37 step:35231 [D loss: 0.665528, acc.: 63.28%] [G loss: 0.982739]\n",
      "epoch:37 step:35232 [D loss: 0.627951, acc.: 65.62%] [G loss: 1.058872]\n",
      "epoch:37 step:35233 [D loss: 0.609903, acc.: 67.97%] [G loss: 0.958967]\n",
      "epoch:37 step:35234 [D loss: 0.593052, acc.: 67.97%] [G loss: 1.007304]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:35235 [D loss: 0.644649, acc.: 60.94%] [G loss: 0.918845]\n",
      "epoch:37 step:35236 [D loss: 0.630082, acc.: 67.19%] [G loss: 0.939904]\n",
      "epoch:37 step:35237 [D loss: 0.639203, acc.: 60.16%] [G loss: 1.026027]\n",
      "epoch:37 step:35238 [D loss: 0.614684, acc.: 64.06%] [G loss: 0.962743]\n",
      "epoch:37 step:35239 [D loss: 0.646343, acc.: 64.06%] [G loss: 0.945848]\n",
      "epoch:37 step:35240 [D loss: 0.614969, acc.: 64.06%] [G loss: 0.955027]\n",
      "epoch:37 step:35241 [D loss: 0.639071, acc.: 62.50%] [G loss: 0.879645]\n",
      "epoch:37 step:35242 [D loss: 0.644678, acc.: 63.28%] [G loss: 0.856575]\n",
      "epoch:37 step:35243 [D loss: 0.641011, acc.: 62.50%] [G loss: 0.925984]\n",
      "epoch:37 step:35244 [D loss: 0.644424, acc.: 60.94%] [G loss: 0.905452]\n",
      "epoch:37 step:35245 [D loss: 0.580740, acc.: 71.09%] [G loss: 0.940176]\n",
      "epoch:37 step:35246 [D loss: 0.644575, acc.: 65.62%] [G loss: 0.892964]\n",
      "epoch:37 step:35247 [D loss: 0.667924, acc.: 57.81%] [G loss: 0.884682]\n",
      "epoch:37 step:35248 [D loss: 0.639152, acc.: 61.72%] [G loss: 0.913265]\n",
      "epoch:37 step:35249 [D loss: 0.652244, acc.: 58.59%] [G loss: 0.901840]\n",
      "epoch:37 step:35250 [D loss: 0.606960, acc.: 70.31%] [G loss: 0.929025]\n",
      "epoch:37 step:35251 [D loss: 0.599795, acc.: 67.97%] [G loss: 0.907985]\n",
      "epoch:37 step:35252 [D loss: 0.705910, acc.: 61.72%] [G loss: 0.926215]\n",
      "epoch:37 step:35253 [D loss: 0.637071, acc.: 62.50%] [G loss: 0.926037]\n",
      "epoch:37 step:35254 [D loss: 0.605779, acc.: 66.41%] [G loss: 0.928095]\n",
      "epoch:37 step:35255 [D loss: 0.680776, acc.: 55.47%] [G loss: 0.906804]\n",
      "epoch:37 step:35256 [D loss: 0.617368, acc.: 64.06%] [G loss: 0.969872]\n",
      "epoch:37 step:35257 [D loss: 0.704669, acc.: 60.16%] [G loss: 0.967438]\n",
      "epoch:37 step:35258 [D loss: 0.646190, acc.: 64.06%] [G loss: 0.939496]\n",
      "epoch:37 step:35259 [D loss: 0.610687, acc.: 68.75%] [G loss: 0.927110]\n",
      "epoch:37 step:35260 [D loss: 0.657949, acc.: 59.38%] [G loss: 0.931177]\n",
      "epoch:37 step:35261 [D loss: 0.660645, acc.: 61.72%] [G loss: 0.883021]\n",
      "epoch:37 step:35262 [D loss: 0.644617, acc.: 62.50%] [G loss: 0.897234]\n",
      "epoch:37 step:35263 [D loss: 0.597146, acc.: 70.31%] [G loss: 0.904894]\n",
      "epoch:37 step:35264 [D loss: 0.671015, acc.: 57.81%] [G loss: 0.882615]\n",
      "epoch:37 step:35265 [D loss: 0.620698, acc.: 71.88%] [G loss: 0.892361]\n",
      "epoch:37 step:35266 [D loss: 0.624135, acc.: 65.62%] [G loss: 0.941017]\n",
      "epoch:37 step:35267 [D loss: 0.661024, acc.: 58.59%] [G loss: 0.880682]\n",
      "epoch:37 step:35268 [D loss: 0.623975, acc.: 65.62%] [G loss: 0.965478]\n",
      "epoch:37 step:35269 [D loss: 0.642282, acc.: 64.84%] [G loss: 0.979093]\n",
      "epoch:37 step:35270 [D loss: 0.687791, acc.: 53.12%] [G loss: 1.083362]\n",
      "epoch:37 step:35271 [D loss: 0.632502, acc.: 64.84%] [G loss: 0.934137]\n",
      "epoch:37 step:35272 [D loss: 0.683633, acc.: 56.25%] [G loss: 0.947459]\n",
      "epoch:37 step:35273 [D loss: 0.686353, acc.: 53.91%] [G loss: 0.916751]\n",
      "epoch:37 step:35274 [D loss: 0.675266, acc.: 50.00%] [G loss: 0.873195]\n",
      "epoch:37 step:35275 [D loss: 0.641636, acc.: 60.94%] [G loss: 0.896989]\n",
      "epoch:37 step:35276 [D loss: 0.668263, acc.: 57.81%] [G loss: 0.898167]\n",
      "epoch:37 step:35277 [D loss: 0.670950, acc.: 53.12%] [G loss: 0.914403]\n",
      "epoch:37 step:35278 [D loss: 0.613415, acc.: 63.28%] [G loss: 0.923127]\n",
      "epoch:37 step:35279 [D loss: 0.637743, acc.: 61.72%] [G loss: 0.913952]\n",
      "epoch:37 step:35280 [D loss: 0.667824, acc.: 60.16%] [G loss: 0.933469]\n",
      "epoch:37 step:35281 [D loss: 0.659498, acc.: 60.94%] [G loss: 0.942846]\n",
      "epoch:37 step:35282 [D loss: 0.641324, acc.: 63.28%] [G loss: 0.908409]\n",
      "epoch:37 step:35283 [D loss: 0.658618, acc.: 57.81%] [G loss: 0.863860]\n",
      "epoch:37 step:35284 [D loss: 0.644771, acc.: 59.38%] [G loss: 0.867199]\n",
      "epoch:37 step:35285 [D loss: 0.656151, acc.: 63.28%] [G loss: 0.830620]\n",
      "epoch:37 step:35286 [D loss: 0.643667, acc.: 61.72%] [G loss: 0.893898]\n",
      "epoch:37 step:35287 [D loss: 0.618675, acc.: 66.41%] [G loss: 0.909940]\n",
      "epoch:37 step:35288 [D loss: 0.676154, acc.: 53.91%] [G loss: 0.958190]\n",
      "epoch:37 step:35289 [D loss: 0.633191, acc.: 64.84%] [G loss: 0.947042]\n",
      "epoch:37 step:35290 [D loss: 0.645298, acc.: 61.72%] [G loss: 0.880464]\n",
      "epoch:37 step:35291 [D loss: 0.672029, acc.: 62.50%] [G loss: 0.974068]\n",
      "epoch:37 step:35292 [D loss: 0.631271, acc.: 62.50%] [G loss: 0.962097]\n",
      "epoch:37 step:35293 [D loss: 0.659639, acc.: 57.81%] [G loss: 0.935055]\n",
      "epoch:37 step:35294 [D loss: 0.689327, acc.: 52.34%] [G loss: 0.926367]\n",
      "epoch:37 step:35295 [D loss: 0.608838, acc.: 66.41%] [G loss: 0.933391]\n",
      "epoch:37 step:35296 [D loss: 0.594742, acc.: 70.31%] [G loss: 0.935083]\n",
      "epoch:37 step:35297 [D loss: 0.648282, acc.: 63.28%] [G loss: 0.949656]\n",
      "epoch:37 step:35298 [D loss: 0.660004, acc.: 59.38%] [G loss: 0.890960]\n",
      "epoch:37 step:35299 [D loss: 0.665579, acc.: 62.50%] [G loss: 0.858973]\n",
      "epoch:37 step:35300 [D loss: 0.603936, acc.: 67.19%] [G loss: 0.953195]\n",
      "epoch:37 step:35301 [D loss: 0.637338, acc.: 60.16%] [G loss: 0.927183]\n",
      "epoch:37 step:35302 [D loss: 0.638217, acc.: 64.84%] [G loss: 0.963766]\n",
      "epoch:37 step:35303 [D loss: 0.632106, acc.: 64.06%] [G loss: 0.930246]\n",
      "epoch:37 step:35304 [D loss: 0.668578, acc.: 63.28%] [G loss: 0.935086]\n",
      "epoch:37 step:35305 [D loss: 0.584234, acc.: 73.44%] [G loss: 1.015999]\n",
      "epoch:37 step:35306 [D loss: 0.603222, acc.: 67.97%] [G loss: 1.090292]\n",
      "epoch:37 step:35307 [D loss: 0.641643, acc.: 61.72%] [G loss: 0.988889]\n",
      "epoch:37 step:35308 [D loss: 0.648044, acc.: 57.81%] [G loss: 0.970188]\n",
      "epoch:37 step:35309 [D loss: 0.628207, acc.: 64.84%] [G loss: 0.952159]\n",
      "epoch:37 step:35310 [D loss: 0.631666, acc.: 63.28%] [G loss: 1.010628]\n",
      "epoch:37 step:35311 [D loss: 0.630303, acc.: 64.84%] [G loss: 0.944507]\n",
      "epoch:37 step:35312 [D loss: 0.685371, acc.: 60.16%] [G loss: 0.904192]\n",
      "epoch:37 step:35313 [D loss: 0.636421, acc.: 66.41%] [G loss: 0.864496]\n",
      "epoch:37 step:35314 [D loss: 0.609147, acc.: 67.97%] [G loss: 0.956747]\n",
      "epoch:37 step:35315 [D loss: 0.647165, acc.: 59.38%] [G loss: 0.951085]\n",
      "epoch:37 step:35316 [D loss: 0.658567, acc.: 59.38%] [G loss: 0.955436]\n",
      "epoch:37 step:35317 [D loss: 0.646701, acc.: 58.59%] [G loss: 0.979267]\n",
      "epoch:37 step:35318 [D loss: 0.669163, acc.: 59.38%] [G loss: 0.975691]\n",
      "epoch:37 step:35319 [D loss: 0.682222, acc.: 56.25%] [G loss: 0.953857]\n",
      "epoch:37 step:35320 [D loss: 0.632071, acc.: 62.50%] [G loss: 0.953114]\n",
      "epoch:37 step:35321 [D loss: 0.659812, acc.: 58.59%] [G loss: 0.963847]\n",
      "epoch:37 step:35322 [D loss: 0.589102, acc.: 66.41%] [G loss: 1.032628]\n",
      "epoch:37 step:35323 [D loss: 0.589875, acc.: 69.53%] [G loss: 0.995725]\n",
      "epoch:37 step:35324 [D loss: 0.663280, acc.: 58.59%] [G loss: 0.905689]\n",
      "epoch:37 step:35325 [D loss: 0.633990, acc.: 65.62%] [G loss: 0.938368]\n",
      "epoch:37 step:35326 [D loss: 0.640963, acc.: 61.72%] [G loss: 0.959435]\n",
      "epoch:37 step:35327 [D loss: 0.708308, acc.: 55.47%] [G loss: 0.959668]\n",
      "epoch:37 step:35328 [D loss: 0.630933, acc.: 65.62%] [G loss: 0.968788]\n",
      "epoch:37 step:35329 [D loss: 0.667228, acc.: 61.72%] [G loss: 0.947035]\n",
      "epoch:37 step:35330 [D loss: 0.658224, acc.: 61.72%] [G loss: 0.918380]\n",
      "epoch:37 step:35331 [D loss: 0.669368, acc.: 57.81%] [G loss: 0.925568]\n",
      "epoch:37 step:35332 [D loss: 0.641983, acc.: 65.62%] [G loss: 0.942889]\n",
      "epoch:37 step:35333 [D loss: 0.665477, acc.: 60.16%] [G loss: 0.936037]\n",
      "epoch:37 step:35334 [D loss: 0.701293, acc.: 59.38%] [G loss: 0.974298]\n",
      "epoch:37 step:35335 [D loss: 0.609616, acc.: 67.19%] [G loss: 0.990568]\n",
      "epoch:37 step:35336 [D loss: 0.633470, acc.: 67.19%] [G loss: 1.034556]\n",
      "epoch:37 step:35337 [D loss: 0.656900, acc.: 63.28%] [G loss: 1.006049]\n",
      "epoch:37 step:35338 [D loss: 0.654277, acc.: 63.28%] [G loss: 0.968067]\n",
      "epoch:37 step:35339 [D loss: 0.632230, acc.: 64.06%] [G loss: 0.945721]\n",
      "epoch:37 step:35340 [D loss: 0.645873, acc.: 62.50%] [G loss: 0.968582]\n",
      "epoch:37 step:35341 [D loss: 0.591496, acc.: 75.00%] [G loss: 0.980784]\n",
      "epoch:37 step:35342 [D loss: 0.623327, acc.: 67.19%] [G loss: 0.973704]\n",
      "epoch:37 step:35343 [D loss: 0.628561, acc.: 67.19%] [G loss: 0.897994]\n",
      "epoch:37 step:35344 [D loss: 0.628765, acc.: 65.62%] [G loss: 0.980957]\n",
      "epoch:37 step:35345 [D loss: 0.639854, acc.: 60.94%] [G loss: 0.894547]\n",
      "epoch:37 step:35346 [D loss: 0.634374, acc.: 64.06%] [G loss: 0.897576]\n",
      "epoch:37 step:35347 [D loss: 0.624402, acc.: 64.06%] [G loss: 0.926288]\n",
      "epoch:37 step:35348 [D loss: 0.610737, acc.: 66.41%] [G loss: 0.928937]\n",
      "epoch:37 step:35349 [D loss: 0.614053, acc.: 64.84%] [G loss: 0.912535]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:35350 [D loss: 0.661092, acc.: 64.06%] [G loss: 0.952361]\n",
      "epoch:37 step:35351 [D loss: 0.662606, acc.: 54.69%] [G loss: 0.910350]\n",
      "epoch:37 step:35352 [D loss: 0.650072, acc.: 61.72%] [G loss: 0.972072]\n",
      "epoch:37 step:35353 [D loss: 0.662056, acc.: 56.25%] [G loss: 0.961223]\n",
      "epoch:37 step:35354 [D loss: 0.635068, acc.: 62.50%] [G loss: 0.934636]\n",
      "epoch:37 step:35355 [D loss: 0.657487, acc.: 60.94%] [G loss: 0.993847]\n",
      "epoch:37 step:35356 [D loss: 0.656384, acc.: 64.06%] [G loss: 0.951783]\n",
      "epoch:37 step:35357 [D loss: 0.640696, acc.: 61.72%] [G loss: 0.991272]\n",
      "epoch:37 step:35358 [D loss: 0.669062, acc.: 58.59%] [G loss: 1.039673]\n",
      "epoch:37 step:35359 [D loss: 0.604404, acc.: 69.53%] [G loss: 0.962650]\n",
      "epoch:37 step:35360 [D loss: 0.648439, acc.: 60.94%] [G loss: 0.920866]\n",
      "epoch:37 step:35361 [D loss: 0.629620, acc.: 64.84%] [G loss: 0.959931]\n",
      "epoch:37 step:35362 [D loss: 0.637032, acc.: 66.41%] [G loss: 0.961839]\n",
      "epoch:37 step:35363 [D loss: 0.659312, acc.: 62.50%] [G loss: 0.982555]\n",
      "epoch:37 step:35364 [D loss: 0.658985, acc.: 60.16%] [G loss: 0.967570]\n",
      "epoch:37 step:35365 [D loss: 0.590999, acc.: 68.75%] [G loss: 0.967063]\n",
      "epoch:37 step:35366 [D loss: 0.577246, acc.: 70.31%] [G loss: 0.931447]\n",
      "epoch:37 step:35367 [D loss: 0.648234, acc.: 57.81%] [G loss: 0.945584]\n",
      "epoch:37 step:35368 [D loss: 0.598698, acc.: 69.53%] [G loss: 0.936480]\n",
      "epoch:37 step:35369 [D loss: 0.617167, acc.: 63.28%] [G loss: 0.956988]\n",
      "epoch:37 step:35370 [D loss: 0.622196, acc.: 62.50%] [G loss: 0.927307]\n",
      "epoch:37 step:35371 [D loss: 0.650281, acc.: 53.12%] [G loss: 0.970404]\n",
      "epoch:37 step:35372 [D loss: 0.667764, acc.: 58.59%] [G loss: 0.882026]\n",
      "epoch:37 step:35373 [D loss: 0.644707, acc.: 58.59%] [G loss: 0.947961]\n",
      "epoch:37 step:35374 [D loss: 0.640801, acc.: 58.59%] [G loss: 0.939642]\n",
      "epoch:37 step:35375 [D loss: 0.665895, acc.: 60.16%] [G loss: 0.935544]\n",
      "epoch:37 step:35376 [D loss: 0.614830, acc.: 64.06%] [G loss: 0.945205]\n",
      "epoch:37 step:35377 [D loss: 0.625095, acc.: 62.50%] [G loss: 0.929411]\n",
      "epoch:37 step:35378 [D loss: 0.678652, acc.: 56.25%] [G loss: 0.951764]\n",
      "epoch:37 step:35379 [D loss: 0.596201, acc.: 71.88%] [G loss: 1.031080]\n",
      "epoch:37 step:35380 [D loss: 0.674741, acc.: 58.59%] [G loss: 0.954636]\n",
      "epoch:37 step:35381 [D loss: 0.616039, acc.: 64.84%] [G loss: 1.013637]\n",
      "epoch:37 step:35382 [D loss: 0.646034, acc.: 62.50%] [G loss: 0.949847]\n",
      "epoch:37 step:35383 [D loss: 0.652730, acc.: 56.25%] [G loss: 0.995113]\n",
      "epoch:37 step:35384 [D loss: 0.662368, acc.: 63.28%] [G loss: 0.965698]\n",
      "epoch:37 step:35385 [D loss: 0.619242, acc.: 65.62%] [G loss: 0.922761]\n",
      "epoch:37 step:35386 [D loss: 0.629599, acc.: 61.72%] [G loss: 0.918272]\n",
      "epoch:37 step:35387 [D loss: 0.597394, acc.: 69.53%] [G loss: 1.010284]\n",
      "epoch:37 step:35388 [D loss: 0.658715, acc.: 65.62%] [G loss: 0.928730]\n",
      "epoch:37 step:35389 [D loss: 0.598991, acc.: 67.97%] [G loss: 0.906590]\n",
      "epoch:37 step:35390 [D loss: 0.624269, acc.: 63.28%] [G loss: 0.959698]\n",
      "epoch:37 step:35391 [D loss: 0.618469, acc.: 66.41%] [G loss: 0.918003]\n",
      "epoch:37 step:35392 [D loss: 0.663122, acc.: 55.47%] [G loss: 0.972200]\n",
      "epoch:37 step:35393 [D loss: 0.636588, acc.: 63.28%] [G loss: 0.913289]\n",
      "epoch:37 step:35394 [D loss: 0.615538, acc.: 64.06%] [G loss: 0.949834]\n",
      "epoch:37 step:35395 [D loss: 0.622969, acc.: 64.06%] [G loss: 0.926301]\n",
      "epoch:37 step:35396 [D loss: 0.639018, acc.: 67.19%] [G loss: 0.941633]\n",
      "epoch:37 step:35397 [D loss: 0.667172, acc.: 60.94%] [G loss: 0.922682]\n",
      "epoch:37 step:35398 [D loss: 0.618688, acc.: 67.19%] [G loss: 0.926017]\n",
      "epoch:37 step:35399 [D loss: 0.641803, acc.: 63.28%] [G loss: 0.912797]\n",
      "epoch:37 step:35400 [D loss: 0.613386, acc.: 62.50%] [G loss: 0.903795]\n",
      "##############\n",
      "[2.6618041  2.58632317 2.21855848 3.72799376 1.2186996  6.65027793\n",
      " 2.88975291 3.34461097 4.20163225 7.14868929]\n",
      "##########\n",
      "epoch:37 step:35401 [D loss: 0.654109, acc.: 60.16%] [G loss: 0.904524]\n",
      "epoch:37 step:35402 [D loss: 0.655960, acc.: 61.72%] [G loss: 0.924949]\n",
      "epoch:37 step:35403 [D loss: 0.629474, acc.: 67.19%] [G loss: 0.974678]\n",
      "epoch:37 step:35404 [D loss: 0.641289, acc.: 58.59%] [G loss: 1.009880]\n",
      "epoch:37 step:35405 [D loss: 0.632451, acc.: 64.84%] [G loss: 0.922881]\n",
      "epoch:37 step:35406 [D loss: 0.649188, acc.: 60.94%] [G loss: 0.932532]\n",
      "epoch:37 step:35407 [D loss: 0.626171, acc.: 64.84%] [G loss: 0.918789]\n",
      "epoch:37 step:35408 [D loss: 0.661480, acc.: 61.72%] [G loss: 0.890945]\n",
      "epoch:37 step:35409 [D loss: 0.659584, acc.: 57.03%] [G loss: 0.997784]\n",
      "epoch:37 step:35410 [D loss: 0.672947, acc.: 51.56%] [G loss: 0.966052]\n",
      "epoch:37 step:35411 [D loss: 0.680242, acc.: 57.03%] [G loss: 0.935909]\n",
      "epoch:37 step:35412 [D loss: 0.675805, acc.: 52.34%] [G loss: 0.950494]\n",
      "epoch:37 step:35413 [D loss: 0.613337, acc.: 72.66%] [G loss: 1.061692]\n",
      "epoch:37 step:35414 [D loss: 0.617373, acc.: 64.84%] [G loss: 0.976957]\n",
      "epoch:37 step:35415 [D loss: 0.599466, acc.: 71.88%] [G loss: 0.990645]\n",
      "epoch:37 step:35416 [D loss: 0.601635, acc.: 72.66%] [G loss: 0.950561]\n",
      "epoch:37 step:35417 [D loss: 0.652076, acc.: 62.50%] [G loss: 0.921613]\n",
      "epoch:37 step:35418 [D loss: 0.626992, acc.: 67.19%] [G loss: 0.959254]\n",
      "epoch:37 step:35419 [D loss: 0.639192, acc.: 62.50%] [G loss: 0.978446]\n",
      "epoch:37 step:35420 [D loss: 0.625974, acc.: 60.16%] [G loss: 0.891144]\n",
      "epoch:37 step:35421 [D loss: 0.646528, acc.: 60.16%] [G loss: 0.870862]\n",
      "epoch:37 step:35422 [D loss: 0.642985, acc.: 61.72%] [G loss: 0.942148]\n",
      "epoch:37 step:35423 [D loss: 0.724370, acc.: 50.78%] [G loss: 0.951024]\n",
      "epoch:37 step:35424 [D loss: 0.625670, acc.: 67.19%] [G loss: 0.975626]\n",
      "epoch:37 step:35425 [D loss: 0.642921, acc.: 64.06%] [G loss: 0.931976]\n",
      "epoch:37 step:35426 [D loss: 0.619008, acc.: 71.09%] [G loss: 0.996852]\n",
      "epoch:37 step:35427 [D loss: 0.614182, acc.: 70.31%] [G loss: 0.953614]\n",
      "epoch:37 step:35428 [D loss: 0.623648, acc.: 71.09%] [G loss: 0.943815]\n",
      "epoch:37 step:35429 [D loss: 0.627977, acc.: 68.75%] [G loss: 0.964860]\n",
      "epoch:37 step:35430 [D loss: 0.642502, acc.: 58.59%] [G loss: 0.942811]\n",
      "epoch:37 step:35431 [D loss: 0.609113, acc.: 63.28%] [G loss: 0.901067]\n",
      "epoch:37 step:35432 [D loss: 0.667589, acc.: 60.94%] [G loss: 0.931421]\n",
      "epoch:37 step:35433 [D loss: 0.634791, acc.: 62.50%] [G loss: 0.925470]\n",
      "epoch:37 step:35434 [D loss: 0.627280, acc.: 62.50%] [G loss: 0.922190]\n",
      "epoch:37 step:35435 [D loss: 0.637608, acc.: 64.06%] [G loss: 0.998214]\n",
      "epoch:37 step:35436 [D loss: 0.610557, acc.: 63.28%] [G loss: 0.904787]\n",
      "epoch:37 step:35437 [D loss: 0.678924, acc.: 56.25%] [G loss: 0.891086]\n",
      "epoch:37 step:35438 [D loss: 0.638536, acc.: 66.41%] [G loss: 0.999224]\n",
      "epoch:37 step:35439 [D loss: 0.655916, acc.: 57.03%] [G loss: 0.948342]\n",
      "epoch:37 step:35440 [D loss: 0.657370, acc.: 58.59%] [G loss: 0.917411]\n",
      "epoch:37 step:35441 [D loss: 0.633661, acc.: 62.50%] [G loss: 1.019479]\n",
      "epoch:37 step:35442 [D loss: 0.641059, acc.: 61.72%] [G loss: 0.992252]\n",
      "epoch:37 step:35443 [D loss: 0.642781, acc.: 66.41%] [G loss: 0.977654]\n",
      "epoch:37 step:35444 [D loss: 0.611764, acc.: 64.84%] [G loss: 0.996074]\n",
      "epoch:37 step:35445 [D loss: 0.628773, acc.: 64.84%] [G loss: 0.989987]\n",
      "epoch:37 step:35446 [D loss: 0.686616, acc.: 57.03%] [G loss: 1.003814]\n",
      "epoch:37 step:35447 [D loss: 0.609284, acc.: 64.84%] [G loss: 1.077694]\n",
      "epoch:37 step:35448 [D loss: 0.634472, acc.: 61.72%] [G loss: 1.001023]\n",
      "epoch:37 step:35449 [D loss: 0.630939, acc.: 64.06%] [G loss: 0.928017]\n",
      "epoch:37 step:35450 [D loss: 0.708038, acc.: 55.47%] [G loss: 0.962719]\n",
      "epoch:37 step:35451 [D loss: 0.636968, acc.: 64.84%] [G loss: 0.879400]\n",
      "epoch:37 step:35452 [D loss: 0.657332, acc.: 58.59%] [G loss: 1.009296]\n",
      "epoch:37 step:35453 [D loss: 0.647241, acc.: 60.16%] [G loss: 1.012334]\n",
      "epoch:37 step:35454 [D loss: 0.634064, acc.: 68.75%] [G loss: 0.943553]\n",
      "epoch:37 step:35455 [D loss: 0.621883, acc.: 67.19%] [G loss: 1.075395]\n",
      "epoch:37 step:35456 [D loss: 0.599549, acc.: 66.41%] [G loss: 0.983499]\n",
      "epoch:37 step:35457 [D loss: 0.637981, acc.: 60.16%] [G loss: 0.946307]\n",
      "epoch:37 step:35458 [D loss: 0.609635, acc.: 67.19%] [G loss: 0.925248]\n",
      "epoch:37 step:35459 [D loss: 0.627060, acc.: 62.50%] [G loss: 0.940837]\n",
      "epoch:37 step:35460 [D loss: 0.593167, acc.: 67.97%] [G loss: 0.890075]\n",
      "epoch:37 step:35461 [D loss: 0.615713, acc.: 66.41%] [G loss: 0.981012]\n",
      "epoch:37 step:35462 [D loss: 0.651792, acc.: 63.28%] [G loss: 0.994621]\n",
      "epoch:37 step:35463 [D loss: 0.619636, acc.: 66.41%] [G loss: 0.924507]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:35464 [D loss: 0.630811, acc.: 62.50%] [G loss: 0.995219]\n",
      "epoch:37 step:35465 [D loss: 0.664398, acc.: 57.03%] [G loss: 0.965977]\n",
      "epoch:37 step:35466 [D loss: 0.666737, acc.: 64.84%] [G loss: 0.961595]\n",
      "epoch:37 step:35467 [D loss: 0.629267, acc.: 61.72%] [G loss: 0.931242]\n",
      "epoch:37 step:35468 [D loss: 0.647312, acc.: 60.16%] [G loss: 0.889735]\n",
      "epoch:37 step:35469 [D loss: 0.636333, acc.: 62.50%] [G loss: 0.972456]\n",
      "epoch:37 step:35470 [D loss: 0.615511, acc.: 71.09%] [G loss: 1.013233]\n",
      "epoch:37 step:35471 [D loss: 0.671425, acc.: 55.47%] [G loss: 0.916435]\n",
      "epoch:37 step:35472 [D loss: 0.629703, acc.: 68.75%] [G loss: 0.917608]\n",
      "epoch:37 step:35473 [D loss: 0.661405, acc.: 61.72%] [G loss: 0.908023]\n",
      "epoch:37 step:35474 [D loss: 0.665952, acc.: 62.50%] [G loss: 0.922382]\n",
      "epoch:37 step:35475 [D loss: 0.648700, acc.: 63.28%] [G loss: 0.860105]\n",
      "epoch:37 step:35476 [D loss: 0.651085, acc.: 61.72%] [G loss: 0.965555]\n",
      "epoch:37 step:35477 [D loss: 0.649665, acc.: 55.47%] [G loss: 0.917318]\n",
      "epoch:37 step:35478 [D loss: 0.655934, acc.: 60.16%] [G loss: 0.934128]\n",
      "epoch:37 step:35479 [D loss: 0.655011, acc.: 60.16%] [G loss: 1.009444]\n",
      "epoch:37 step:35480 [D loss: 0.667742, acc.: 58.59%] [G loss: 0.945087]\n",
      "epoch:37 step:35481 [D loss: 0.668865, acc.: 59.38%] [G loss: 0.970633]\n",
      "epoch:37 step:35482 [D loss: 0.659626, acc.: 60.94%] [G loss: 0.943359]\n",
      "epoch:37 step:35483 [D loss: 0.634979, acc.: 67.19%] [G loss: 0.993152]\n",
      "epoch:37 step:35484 [D loss: 0.630463, acc.: 64.84%] [G loss: 0.967470]\n",
      "epoch:37 step:35485 [D loss: 0.585233, acc.: 71.09%] [G loss: 1.011299]\n",
      "epoch:37 step:35486 [D loss: 0.679696, acc.: 57.81%] [G loss: 0.970060]\n",
      "epoch:37 step:35487 [D loss: 0.670376, acc.: 63.28%] [G loss: 0.926206]\n",
      "epoch:37 step:35488 [D loss: 0.673603, acc.: 57.81%] [G loss: 0.952576]\n",
      "epoch:37 step:35489 [D loss: 0.648552, acc.: 64.06%] [G loss: 0.956403]\n",
      "epoch:37 step:35490 [D loss: 0.624206, acc.: 65.62%] [G loss: 0.955697]\n",
      "epoch:37 step:35491 [D loss: 0.617814, acc.: 63.28%] [G loss: 0.954174]\n",
      "epoch:37 step:35492 [D loss: 0.686872, acc.: 55.47%] [G loss: 0.938277]\n",
      "epoch:37 step:35493 [D loss: 0.596330, acc.: 71.88%] [G loss: 0.904663]\n",
      "epoch:37 step:35494 [D loss: 0.662914, acc.: 57.03%] [G loss: 0.948117]\n",
      "epoch:37 step:35495 [D loss: 0.636438, acc.: 66.41%] [G loss: 0.863481]\n",
      "epoch:37 step:35496 [D loss: 0.641175, acc.: 60.94%] [G loss: 0.978048]\n",
      "epoch:37 step:35497 [D loss: 0.678094, acc.: 55.47%] [G loss: 0.920085]\n",
      "epoch:37 step:35498 [D loss: 0.641866, acc.: 67.19%] [G loss: 0.924226]\n",
      "epoch:37 step:35499 [D loss: 0.637666, acc.: 66.41%] [G loss: 0.907637]\n",
      "epoch:37 step:35500 [D loss: 0.640618, acc.: 61.72%] [G loss: 0.887430]\n",
      "epoch:37 step:35501 [D loss: 0.623297, acc.: 65.62%] [G loss: 0.925042]\n",
      "epoch:37 step:35502 [D loss: 0.707593, acc.: 59.38%] [G loss: 0.921621]\n",
      "epoch:37 step:35503 [D loss: 0.636237, acc.: 64.06%] [G loss: 0.942421]\n",
      "epoch:37 step:35504 [D loss: 0.633533, acc.: 64.06%] [G loss: 0.917991]\n",
      "epoch:37 step:35505 [D loss: 0.621339, acc.: 67.19%] [G loss: 0.974122]\n",
      "epoch:37 step:35506 [D loss: 0.628665, acc.: 63.28%] [G loss: 0.892547]\n",
      "epoch:37 step:35507 [D loss: 0.737134, acc.: 52.34%] [G loss: 0.971561]\n",
      "epoch:37 step:35508 [D loss: 0.586321, acc.: 73.44%] [G loss: 0.935698]\n",
      "epoch:37 step:35509 [D loss: 0.647233, acc.: 65.62%] [G loss: 0.903970]\n",
      "epoch:37 step:35510 [D loss: 0.668320, acc.: 60.16%] [G loss: 0.942122]\n",
      "epoch:37 step:35511 [D loss: 0.670186, acc.: 55.47%] [G loss: 0.960305]\n",
      "epoch:37 step:35512 [D loss: 0.682118, acc.: 58.59%] [G loss: 0.940281]\n",
      "epoch:37 step:35513 [D loss: 0.626050, acc.: 64.06%] [G loss: 0.903649]\n",
      "epoch:37 step:35514 [D loss: 0.661683, acc.: 57.03%] [G loss: 0.899214]\n",
      "epoch:37 step:35515 [D loss: 0.622770, acc.: 65.62%] [G loss: 0.910583]\n",
      "epoch:37 step:35516 [D loss: 0.663957, acc.: 60.94%] [G loss: 0.913513]\n",
      "epoch:37 step:35517 [D loss: 0.668251, acc.: 58.59%] [G loss: 0.895929]\n",
      "epoch:37 step:35518 [D loss: 0.669710, acc.: 57.03%] [G loss: 0.914287]\n",
      "epoch:37 step:35519 [D loss: 0.624077, acc.: 66.41%] [G loss: 0.937646]\n",
      "epoch:37 step:35520 [D loss: 0.653533, acc.: 64.84%] [G loss: 0.975171]\n",
      "epoch:37 step:35521 [D loss: 0.631377, acc.: 68.75%] [G loss: 0.993511]\n",
      "epoch:37 step:35522 [D loss: 0.650470, acc.: 62.50%] [G loss: 0.892713]\n",
      "epoch:37 step:35523 [D loss: 0.603167, acc.: 71.09%] [G loss: 0.955418]\n",
      "epoch:37 step:35524 [D loss: 0.684838, acc.: 55.47%] [G loss: 0.937860]\n",
      "epoch:37 step:35525 [D loss: 0.632071, acc.: 68.75%] [G loss: 0.947443]\n",
      "epoch:37 step:35526 [D loss: 0.636038, acc.: 63.28%] [G loss: 0.900618]\n",
      "epoch:37 step:35527 [D loss: 0.676342, acc.: 56.25%] [G loss: 0.918159]\n",
      "epoch:37 step:35528 [D loss: 0.646539, acc.: 66.41%] [G loss: 0.902605]\n",
      "epoch:37 step:35529 [D loss: 0.628329, acc.: 66.41%] [G loss: 0.966304]\n",
      "epoch:37 step:35530 [D loss: 0.581421, acc.: 70.31%] [G loss: 0.960338]\n",
      "epoch:37 step:35531 [D loss: 0.624559, acc.: 64.84%] [G loss: 0.937723]\n",
      "epoch:37 step:35532 [D loss: 0.620268, acc.: 71.09%] [G loss: 0.960913]\n",
      "epoch:37 step:35533 [D loss: 0.671951, acc.: 58.59%] [G loss: 0.849654]\n",
      "epoch:37 step:35534 [D loss: 0.656822, acc.: 58.59%] [G loss: 0.932603]\n",
      "epoch:37 step:35535 [D loss: 0.631867, acc.: 62.50%] [G loss: 0.885195]\n",
      "epoch:37 step:35536 [D loss: 0.662057, acc.: 61.72%] [G loss: 0.900431]\n",
      "epoch:37 step:35537 [D loss: 0.621737, acc.: 64.06%] [G loss: 0.879703]\n",
      "epoch:37 step:35538 [D loss: 0.639164, acc.: 58.59%] [G loss: 0.890187]\n",
      "epoch:37 step:35539 [D loss: 0.672402, acc.: 54.69%] [G loss: 0.953279]\n",
      "epoch:37 step:35540 [D loss: 0.633301, acc.: 65.62%] [G loss: 1.003325]\n",
      "epoch:37 step:35541 [D loss: 0.661625, acc.: 53.12%] [G loss: 0.964752]\n",
      "epoch:37 step:35542 [D loss: 0.625017, acc.: 65.62%] [G loss: 0.974507]\n",
      "epoch:37 step:35543 [D loss: 0.649831, acc.: 64.06%] [G loss: 0.925113]\n",
      "epoch:37 step:35544 [D loss: 0.623513, acc.: 64.06%] [G loss: 0.925259]\n",
      "epoch:37 step:35545 [D loss: 0.676234, acc.: 62.50%] [G loss: 0.957530]\n",
      "epoch:37 step:35546 [D loss: 0.624687, acc.: 63.28%] [G loss: 0.998121]\n",
      "epoch:37 step:35547 [D loss: 0.651355, acc.: 59.38%] [G loss: 1.017647]\n",
      "epoch:37 step:35548 [D loss: 0.622907, acc.: 67.97%] [G loss: 0.888072]\n",
      "epoch:37 step:35549 [D loss: 0.654207, acc.: 59.38%] [G loss: 0.944814]\n",
      "epoch:37 step:35550 [D loss: 0.669911, acc.: 55.47%] [G loss: 0.924053]\n",
      "epoch:37 step:35551 [D loss: 0.653066, acc.: 64.84%] [G loss: 0.901365]\n",
      "epoch:37 step:35552 [D loss: 0.646421, acc.: 56.25%] [G loss: 0.998094]\n",
      "epoch:37 step:35553 [D loss: 0.616544, acc.: 65.62%] [G loss: 0.949646]\n",
      "epoch:37 step:35554 [D loss: 0.678800, acc.: 51.56%] [G loss: 0.934573]\n",
      "epoch:37 step:35555 [D loss: 0.639876, acc.: 64.84%] [G loss: 0.875612]\n",
      "epoch:37 step:35556 [D loss: 0.620552, acc.: 62.50%] [G loss: 0.924752]\n",
      "epoch:37 step:35557 [D loss: 0.647505, acc.: 62.50%] [G loss: 0.896111]\n",
      "epoch:37 step:35558 [D loss: 0.673943, acc.: 60.94%] [G loss: 0.896645]\n",
      "epoch:37 step:35559 [D loss: 0.627704, acc.: 67.97%] [G loss: 0.973559]\n",
      "epoch:37 step:35560 [D loss: 0.651070, acc.: 56.25%] [G loss: 0.985231]\n",
      "epoch:37 step:35561 [D loss: 0.660015, acc.: 63.28%] [G loss: 0.969212]\n",
      "epoch:37 step:35562 [D loss: 0.652439, acc.: 61.72%] [G loss: 0.912163]\n",
      "epoch:37 step:35563 [D loss: 0.652446, acc.: 64.06%] [G loss: 0.905461]\n",
      "epoch:37 step:35564 [D loss: 0.643649, acc.: 64.84%] [G loss: 0.981719]\n",
      "epoch:37 step:35565 [D loss: 0.627504, acc.: 65.62%] [G loss: 0.932047]\n",
      "epoch:37 step:35566 [D loss: 0.631246, acc.: 64.84%] [G loss: 0.970421]\n",
      "epoch:37 step:35567 [D loss: 0.636317, acc.: 60.94%] [G loss: 0.965958]\n",
      "epoch:37 step:35568 [D loss: 0.616471, acc.: 70.31%] [G loss: 0.941569]\n",
      "epoch:37 step:35569 [D loss: 0.663144, acc.: 57.81%] [G loss: 0.936855]\n",
      "epoch:37 step:35570 [D loss: 0.684037, acc.: 58.59%] [G loss: 0.933523]\n",
      "epoch:37 step:35571 [D loss: 0.635219, acc.: 62.50%] [G loss: 0.972938]\n",
      "epoch:37 step:35572 [D loss: 0.638951, acc.: 64.06%] [G loss: 0.944955]\n",
      "epoch:37 step:35573 [D loss: 0.635452, acc.: 61.72%] [G loss: 0.953263]\n",
      "epoch:37 step:35574 [D loss: 0.676372, acc.: 57.03%] [G loss: 0.983440]\n",
      "epoch:37 step:35575 [D loss: 0.640444, acc.: 60.16%] [G loss: 0.937199]\n",
      "epoch:37 step:35576 [D loss: 0.700434, acc.: 50.00%] [G loss: 0.960746]\n",
      "epoch:37 step:35577 [D loss: 0.655188, acc.: 64.06%] [G loss: 0.970046]\n",
      "epoch:37 step:35578 [D loss: 0.654401, acc.: 55.47%] [G loss: 0.926123]\n",
      "epoch:37 step:35579 [D loss: 0.649995, acc.: 62.50%] [G loss: 0.865227]\n",
      "epoch:37 step:35580 [D loss: 0.644889, acc.: 62.50%] [G loss: 0.975018]\n",
      "epoch:37 step:35581 [D loss: 0.645200, acc.: 57.03%] [G loss: 0.898315]\n",
      "epoch:37 step:35582 [D loss: 0.636366, acc.: 66.41%] [G loss: 0.924041]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:37 step:35583 [D loss: 0.657673, acc.: 57.81%] [G loss: 0.887643]\n",
      "epoch:37 step:35584 [D loss: 0.645788, acc.: 64.06%] [G loss: 0.966761]\n",
      "epoch:37 step:35585 [D loss: 0.658439, acc.: 63.28%] [G loss: 0.831892]\n",
      "epoch:37 step:35586 [D loss: 0.632710, acc.: 60.94%] [G loss: 0.903017]\n",
      "epoch:37 step:35587 [D loss: 0.653650, acc.: 59.38%] [G loss: 0.954307]\n",
      "epoch:37 step:35588 [D loss: 0.628026, acc.: 67.97%] [G loss: 0.931063]\n",
      "epoch:37 step:35589 [D loss: 0.615334, acc.: 64.84%] [G loss: 0.956017]\n",
      "epoch:37 step:35590 [D loss: 0.684708, acc.: 57.03%] [G loss: 0.952115]\n",
      "epoch:37 step:35591 [D loss: 0.615418, acc.: 67.97%] [G loss: 0.967835]\n",
      "epoch:37 step:35592 [D loss: 0.667869, acc.: 58.59%] [G loss: 0.967166]\n",
      "epoch:37 step:35593 [D loss: 0.648140, acc.: 66.41%] [G loss: 0.926654]\n",
      "epoch:37 step:35594 [D loss: 0.629200, acc.: 62.50%] [G loss: 0.924068]\n",
      "epoch:37 step:35595 [D loss: 0.619007, acc.: 64.06%] [G loss: 0.875213]\n",
      "epoch:37 step:35596 [D loss: 0.663551, acc.: 58.59%] [G loss: 0.933759]\n",
      "epoch:37 step:35597 [D loss: 0.641406, acc.: 60.94%] [G loss: 0.871133]\n",
      "epoch:37 step:35598 [D loss: 0.619737, acc.: 67.19%] [G loss: 0.876379]\n",
      "epoch:37 step:35599 [D loss: 0.655036, acc.: 60.94%] [G loss: 0.875052]\n",
      "epoch:37 step:35600 [D loss: 0.622556, acc.: 58.59%] [G loss: 0.932925]\n",
      "##############\n",
      "[ 2.96156656  2.24758446  2.40353492  3.81394872  1.2135556  10.27426719\n",
      "  2.58253524  3.08279354  4.20250858  8.14868929]\n",
      "##########\n",
      "epoch:37 step:35601 [D loss: 0.635352, acc.: 62.50%] [G loss: 0.935467]\n",
      "epoch:37 step:35602 [D loss: 0.705578, acc.: 55.47%] [G loss: 0.951243]\n",
      "epoch:37 step:35603 [D loss: 0.619534, acc.: 64.84%] [G loss: 0.962784]\n",
      "epoch:37 step:35604 [D loss: 0.670709, acc.: 53.91%] [G loss: 0.913915]\n",
      "epoch:37 step:35605 [D loss: 0.680712, acc.: 54.69%] [G loss: 0.992822]\n",
      "epoch:37 step:35606 [D loss: 0.632356, acc.: 60.94%] [G loss: 0.958815]\n",
      "epoch:38 step:35607 [D loss: 0.679780, acc.: 55.47%] [G loss: 0.962199]\n",
      "epoch:38 step:35608 [D loss: 0.648202, acc.: 57.03%] [G loss: 0.898146]\n",
      "epoch:38 step:35609 [D loss: 0.619642, acc.: 61.72%] [G loss: 1.034568]\n",
      "epoch:38 step:35610 [D loss: 0.648782, acc.: 62.50%] [G loss: 0.992482]\n",
      "epoch:38 step:35611 [D loss: 0.698886, acc.: 53.91%] [G loss: 0.918689]\n",
      "epoch:38 step:35612 [D loss: 0.621200, acc.: 68.75%] [G loss: 0.936871]\n",
      "epoch:38 step:35613 [D loss: 0.650035, acc.: 61.72%] [G loss: 0.932374]\n",
      "epoch:38 step:35614 [D loss: 0.691411, acc.: 58.59%] [G loss: 0.935767]\n",
      "epoch:38 step:35615 [D loss: 0.654904, acc.: 55.47%] [G loss: 0.989139]\n",
      "epoch:38 step:35616 [D loss: 0.612669, acc.: 67.97%] [G loss: 0.957709]\n",
      "epoch:38 step:35617 [D loss: 0.595894, acc.: 71.09%] [G loss: 0.949361]\n",
      "epoch:38 step:35618 [D loss: 0.693909, acc.: 52.34%] [G loss: 0.927449]\n",
      "epoch:38 step:35619 [D loss: 0.619812, acc.: 64.06%] [G loss: 0.931948]\n",
      "epoch:38 step:35620 [D loss: 0.655161, acc.: 64.06%] [G loss: 0.941371]\n",
      "epoch:38 step:35621 [D loss: 0.592538, acc.: 65.62%] [G loss: 0.902356]\n",
      "epoch:38 step:35622 [D loss: 0.621003, acc.: 65.62%] [G loss: 0.979671]\n",
      "epoch:38 step:35623 [D loss: 0.656657, acc.: 60.16%] [G loss: 0.960038]\n",
      "epoch:38 step:35624 [D loss: 0.626565, acc.: 60.94%] [G loss: 0.989070]\n",
      "epoch:38 step:35625 [D loss: 0.641366, acc.: 62.50%] [G loss: 0.947459]\n",
      "epoch:38 step:35626 [D loss: 0.636522, acc.: 66.41%] [G loss: 0.910215]\n",
      "epoch:38 step:35627 [D loss: 0.638558, acc.: 63.28%] [G loss: 0.869407]\n",
      "epoch:38 step:35628 [D loss: 0.649022, acc.: 57.03%] [G loss: 0.884640]\n",
      "epoch:38 step:35629 [D loss: 0.667222, acc.: 56.25%] [G loss: 0.966246]\n",
      "epoch:38 step:35630 [D loss: 0.645354, acc.: 61.72%] [G loss: 0.969430]\n",
      "epoch:38 step:35631 [D loss: 0.609366, acc.: 65.62%] [G loss: 0.985145]\n",
      "epoch:38 step:35632 [D loss: 0.640478, acc.: 64.06%] [G loss: 0.992451]\n",
      "epoch:38 step:35633 [D loss: 0.648816, acc.: 64.84%] [G loss: 0.950536]\n",
      "epoch:38 step:35634 [D loss: 0.639676, acc.: 65.62%] [G loss: 0.960181]\n",
      "epoch:38 step:35635 [D loss: 0.637180, acc.: 64.06%] [G loss: 0.938269]\n",
      "epoch:38 step:35636 [D loss: 0.642121, acc.: 63.28%] [G loss: 0.965586]\n",
      "epoch:38 step:35637 [D loss: 0.661610, acc.: 62.50%] [G loss: 0.965070]\n",
      "epoch:38 step:35638 [D loss: 0.640038, acc.: 69.53%] [G loss: 0.949753]\n",
      "epoch:38 step:35639 [D loss: 0.644846, acc.: 66.41%] [G loss: 0.948503]\n",
      "epoch:38 step:35640 [D loss: 0.647188, acc.: 62.50%] [G loss: 0.971460]\n",
      "epoch:38 step:35641 [D loss: 0.666219, acc.: 56.25%] [G loss: 0.896001]\n",
      "epoch:38 step:35642 [D loss: 0.605053, acc.: 67.97%] [G loss: 0.875430]\n",
      "epoch:38 step:35643 [D loss: 0.633491, acc.: 64.84%] [G loss: 0.934219]\n",
      "epoch:38 step:35644 [D loss: 0.678291, acc.: 54.69%] [G loss: 0.936871]\n",
      "epoch:38 step:35645 [D loss: 0.648628, acc.: 62.50%] [G loss: 0.989493]\n",
      "epoch:38 step:35646 [D loss: 0.642316, acc.: 59.38%] [G loss: 0.970871]\n",
      "epoch:38 step:35647 [D loss: 0.640163, acc.: 60.16%] [G loss: 0.924329]\n",
      "epoch:38 step:35648 [D loss: 0.624310, acc.: 67.19%] [G loss: 0.961048]\n",
      "epoch:38 step:35649 [D loss: 0.635332, acc.: 60.94%] [G loss: 0.952274]\n",
      "epoch:38 step:35650 [D loss: 0.598327, acc.: 71.88%] [G loss: 0.859083]\n",
      "epoch:38 step:35651 [D loss: 0.680649, acc.: 57.81%] [G loss: 0.928962]\n",
      "epoch:38 step:35652 [D loss: 0.632109, acc.: 62.50%] [G loss: 0.928324]\n",
      "epoch:38 step:35653 [D loss: 0.686638, acc.: 57.81%] [G loss: 1.020044]\n",
      "epoch:38 step:35654 [D loss: 0.631761, acc.: 64.84%] [G loss: 0.950702]\n",
      "epoch:38 step:35655 [D loss: 0.575525, acc.: 68.75%] [G loss: 0.937425]\n",
      "epoch:38 step:35656 [D loss: 0.638512, acc.: 58.59%] [G loss: 0.974790]\n",
      "epoch:38 step:35657 [D loss: 0.619227, acc.: 63.28%] [G loss: 0.963610]\n",
      "epoch:38 step:35658 [D loss: 0.612002, acc.: 64.06%] [G loss: 0.969098]\n",
      "epoch:38 step:35659 [D loss: 0.611213, acc.: 67.19%] [G loss: 0.916135]\n",
      "epoch:38 step:35660 [D loss: 0.598873, acc.: 64.84%] [G loss: 0.947921]\n",
      "epoch:38 step:35661 [D loss: 0.628403, acc.: 64.06%] [G loss: 0.936809]\n",
      "epoch:38 step:35662 [D loss: 0.662892, acc.: 60.94%] [G loss: 0.970333]\n",
      "epoch:38 step:35663 [D loss: 0.626685, acc.: 61.72%] [G loss: 0.931446]\n",
      "epoch:38 step:35664 [D loss: 0.628891, acc.: 65.62%] [G loss: 0.980145]\n",
      "epoch:38 step:35665 [D loss: 0.611024, acc.: 67.97%] [G loss: 1.023984]\n",
      "epoch:38 step:35666 [D loss: 0.612391, acc.: 69.53%] [G loss: 1.046997]\n",
      "epoch:38 step:35667 [D loss: 0.614406, acc.: 67.97%] [G loss: 0.982059]\n",
      "epoch:38 step:35668 [D loss: 0.642463, acc.: 65.62%] [G loss: 1.046302]\n",
      "epoch:38 step:35669 [D loss: 0.622699, acc.: 63.28%] [G loss: 0.957271]\n",
      "epoch:38 step:35670 [D loss: 0.615766, acc.: 66.41%] [G loss: 0.959151]\n",
      "epoch:38 step:35671 [D loss: 0.647804, acc.: 67.19%] [G loss: 0.988438]\n",
      "epoch:38 step:35672 [D loss: 0.648819, acc.: 64.06%] [G loss: 1.038707]\n",
      "epoch:38 step:35673 [D loss: 0.652010, acc.: 63.28%] [G loss: 1.021094]\n",
      "epoch:38 step:35674 [D loss: 0.613313, acc.: 69.53%] [G loss: 1.019923]\n",
      "epoch:38 step:35675 [D loss: 0.606906, acc.: 69.53%] [G loss: 0.969895]\n",
      "epoch:38 step:35676 [D loss: 0.628111, acc.: 66.41%] [G loss: 0.951168]\n",
      "epoch:38 step:35677 [D loss: 0.610545, acc.: 66.41%] [G loss: 1.018902]\n",
      "epoch:38 step:35678 [D loss: 0.638741, acc.: 63.28%] [G loss: 0.879612]\n",
      "epoch:38 step:35679 [D loss: 0.616817, acc.: 66.41%] [G loss: 0.935204]\n",
      "epoch:38 step:35680 [D loss: 0.638048, acc.: 64.06%] [G loss: 0.913008]\n",
      "epoch:38 step:35681 [D loss: 0.695659, acc.: 58.59%] [G loss: 0.998617]\n",
      "epoch:38 step:35682 [D loss: 0.627401, acc.: 66.41%] [G loss: 0.957420]\n",
      "epoch:38 step:35683 [D loss: 0.616817, acc.: 66.41%] [G loss: 0.992213]\n",
      "epoch:38 step:35684 [D loss: 0.650248, acc.: 63.28%] [G loss: 0.912066]\n",
      "epoch:38 step:35685 [D loss: 0.645443, acc.: 65.62%] [G loss: 0.916546]\n",
      "epoch:38 step:35686 [D loss: 0.657440, acc.: 63.28%] [G loss: 0.998843]\n",
      "epoch:38 step:35687 [D loss: 0.679287, acc.: 63.28%] [G loss: 0.962370]\n",
      "epoch:38 step:35688 [D loss: 0.643409, acc.: 62.50%] [G loss: 0.918705]\n",
      "epoch:38 step:35689 [D loss: 0.666852, acc.: 64.06%] [G loss: 0.934737]\n",
      "epoch:38 step:35690 [D loss: 0.660296, acc.: 59.38%] [G loss: 1.014067]\n",
      "epoch:38 step:35691 [D loss: 0.594667, acc.: 67.97%] [G loss: 0.961161]\n",
      "epoch:38 step:35692 [D loss: 0.655587, acc.: 64.06%] [G loss: 0.991192]\n",
      "epoch:38 step:35693 [D loss: 0.624086, acc.: 64.06%] [G loss: 0.941711]\n",
      "epoch:38 step:35694 [D loss: 0.631980, acc.: 64.06%] [G loss: 0.985189]\n",
      "epoch:38 step:35695 [D loss: 0.584442, acc.: 71.88%] [G loss: 0.984954]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:35696 [D loss: 0.673374, acc.: 57.81%] [G loss: 0.948884]\n",
      "epoch:38 step:35697 [D loss: 0.637511, acc.: 60.94%] [G loss: 0.984196]\n",
      "epoch:38 step:35698 [D loss: 0.656034, acc.: 62.50%] [G loss: 0.985106]\n",
      "epoch:38 step:35699 [D loss: 0.651956, acc.: 58.59%] [G loss: 0.884942]\n",
      "epoch:38 step:35700 [D loss: 0.619496, acc.: 66.41%] [G loss: 0.847654]\n",
      "epoch:38 step:35701 [D loss: 0.687961, acc.: 60.94%] [G loss: 0.905314]\n",
      "epoch:38 step:35702 [D loss: 0.639974, acc.: 60.16%] [G loss: 0.912826]\n",
      "epoch:38 step:35703 [D loss: 0.626482, acc.: 64.84%] [G loss: 0.903679]\n",
      "epoch:38 step:35704 [D loss: 0.643414, acc.: 64.84%] [G loss: 0.934212]\n",
      "epoch:38 step:35705 [D loss: 0.670944, acc.: 59.38%] [G loss: 0.995587]\n",
      "epoch:38 step:35706 [D loss: 0.693025, acc.: 57.03%] [G loss: 0.939976]\n",
      "epoch:38 step:35707 [D loss: 0.622632, acc.: 66.41%] [G loss: 0.986447]\n",
      "epoch:38 step:35708 [D loss: 0.683562, acc.: 59.38%] [G loss: 0.976296]\n",
      "epoch:38 step:35709 [D loss: 0.589923, acc.: 69.53%] [G loss: 0.950847]\n",
      "epoch:38 step:35710 [D loss: 0.631541, acc.: 64.06%] [G loss: 1.012999]\n",
      "epoch:38 step:35711 [D loss: 0.610157, acc.: 62.50%] [G loss: 0.975439]\n",
      "epoch:38 step:35712 [D loss: 0.586156, acc.: 69.53%] [G loss: 0.942866]\n",
      "epoch:38 step:35713 [D loss: 0.610645, acc.: 60.94%] [G loss: 1.015476]\n",
      "epoch:38 step:35714 [D loss: 0.596091, acc.: 68.75%] [G loss: 1.040972]\n",
      "epoch:38 step:35715 [D loss: 0.651440, acc.: 54.69%] [G loss: 0.920275]\n",
      "epoch:38 step:35716 [D loss: 0.624589, acc.: 66.41%] [G loss: 0.934353]\n",
      "epoch:38 step:35717 [D loss: 0.666411, acc.: 56.25%] [G loss: 0.951026]\n",
      "epoch:38 step:35718 [D loss: 0.680473, acc.: 55.47%] [G loss: 0.960266]\n",
      "epoch:38 step:35719 [D loss: 0.612432, acc.: 60.94%] [G loss: 0.956796]\n",
      "epoch:38 step:35720 [D loss: 0.634337, acc.: 67.19%] [G loss: 1.023837]\n",
      "epoch:38 step:35721 [D loss: 0.634854, acc.: 64.06%] [G loss: 0.994388]\n",
      "epoch:38 step:35722 [D loss: 0.652964, acc.: 60.94%] [G loss: 0.923443]\n",
      "epoch:38 step:35723 [D loss: 0.658242, acc.: 64.84%] [G loss: 1.012215]\n",
      "epoch:38 step:35724 [D loss: 0.667576, acc.: 60.94%] [G loss: 1.020351]\n",
      "epoch:38 step:35725 [D loss: 0.662973, acc.: 55.47%] [G loss: 0.938882]\n",
      "epoch:38 step:35726 [D loss: 0.615253, acc.: 65.62%] [G loss: 0.997850]\n",
      "epoch:38 step:35727 [D loss: 0.626712, acc.: 65.62%] [G loss: 0.967978]\n",
      "epoch:38 step:35728 [D loss: 0.627739, acc.: 67.97%] [G loss: 0.893428]\n",
      "epoch:38 step:35729 [D loss: 0.645542, acc.: 66.41%] [G loss: 0.962230]\n",
      "epoch:38 step:35730 [D loss: 0.627117, acc.: 65.62%] [G loss: 0.949854]\n",
      "epoch:38 step:35731 [D loss: 0.617940, acc.: 64.06%] [G loss: 0.923843]\n",
      "epoch:38 step:35732 [D loss: 0.620460, acc.: 63.28%] [G loss: 0.899095]\n",
      "epoch:38 step:35733 [D loss: 0.647791, acc.: 60.94%] [G loss: 0.904643]\n",
      "epoch:38 step:35734 [D loss: 0.602547, acc.: 67.97%] [G loss: 0.975449]\n",
      "epoch:38 step:35735 [D loss: 0.665668, acc.: 60.16%] [G loss: 0.956322]\n",
      "epoch:38 step:35736 [D loss: 0.610978, acc.: 60.94%] [G loss: 0.986668]\n",
      "epoch:38 step:35737 [D loss: 0.646722, acc.: 61.72%] [G loss: 0.956746]\n",
      "epoch:38 step:35738 [D loss: 0.655877, acc.: 57.81%] [G loss: 0.913517]\n",
      "epoch:38 step:35739 [D loss: 0.627729, acc.: 64.84%] [G loss: 1.027420]\n",
      "epoch:38 step:35740 [D loss: 0.668017, acc.: 61.72%] [G loss: 0.861103]\n",
      "epoch:38 step:35741 [D loss: 0.612022, acc.: 66.41%] [G loss: 0.843376]\n",
      "epoch:38 step:35742 [D loss: 0.673617, acc.: 53.12%] [G loss: 0.892412]\n",
      "epoch:38 step:35743 [D loss: 0.593215, acc.: 74.22%] [G loss: 0.869396]\n",
      "epoch:38 step:35744 [D loss: 0.624635, acc.: 65.62%] [G loss: 0.989912]\n",
      "epoch:38 step:35745 [D loss: 0.683692, acc.: 56.25%] [G loss: 0.939319]\n",
      "epoch:38 step:35746 [D loss: 0.619400, acc.: 60.94%] [G loss: 0.917132]\n",
      "epoch:38 step:35747 [D loss: 0.670213, acc.: 56.25%] [G loss: 0.924060]\n",
      "epoch:38 step:35748 [D loss: 0.622205, acc.: 60.16%] [G loss: 0.898763]\n",
      "epoch:38 step:35749 [D loss: 0.648485, acc.: 57.03%] [G loss: 0.937297]\n",
      "epoch:38 step:35750 [D loss: 0.637964, acc.: 64.06%] [G loss: 0.868088]\n",
      "epoch:38 step:35751 [D loss: 0.642768, acc.: 61.72%] [G loss: 0.905388]\n",
      "epoch:38 step:35752 [D loss: 0.606416, acc.: 69.53%] [G loss: 0.981325]\n",
      "epoch:38 step:35753 [D loss: 0.654073, acc.: 61.72%] [G loss: 0.932570]\n",
      "epoch:38 step:35754 [D loss: 0.624645, acc.: 68.75%] [G loss: 0.881235]\n",
      "epoch:38 step:35755 [D loss: 0.630709, acc.: 63.28%] [G loss: 0.960189]\n",
      "epoch:38 step:35756 [D loss: 0.631732, acc.: 64.06%] [G loss: 0.976662]\n",
      "epoch:38 step:35757 [D loss: 0.647061, acc.: 60.94%] [G loss: 0.982527]\n",
      "epoch:38 step:35758 [D loss: 0.650765, acc.: 62.50%] [G loss: 0.940520]\n",
      "epoch:38 step:35759 [D loss: 0.634948, acc.: 64.06%] [G loss: 0.948750]\n",
      "epoch:38 step:35760 [D loss: 0.617512, acc.: 65.62%] [G loss: 0.919462]\n",
      "epoch:38 step:35761 [D loss: 0.657205, acc.: 59.38%] [G loss: 0.981122]\n",
      "epoch:38 step:35762 [D loss: 0.605039, acc.: 71.88%] [G loss: 0.960687]\n",
      "epoch:38 step:35763 [D loss: 0.670806, acc.: 64.06%] [G loss: 1.023871]\n",
      "epoch:38 step:35764 [D loss: 0.610566, acc.: 65.62%] [G loss: 0.974463]\n",
      "epoch:38 step:35765 [D loss: 0.636751, acc.: 60.94%] [G loss: 0.952948]\n",
      "epoch:38 step:35766 [D loss: 0.664304, acc.: 57.81%] [G loss: 0.928089]\n",
      "epoch:38 step:35767 [D loss: 0.632606, acc.: 62.50%] [G loss: 0.992288]\n",
      "epoch:38 step:35768 [D loss: 0.634968, acc.: 62.50%] [G loss: 1.005094]\n",
      "epoch:38 step:35769 [D loss: 0.580286, acc.: 73.44%] [G loss: 1.028225]\n",
      "epoch:38 step:35770 [D loss: 0.649683, acc.: 57.81%] [G loss: 0.983539]\n",
      "epoch:38 step:35771 [D loss: 0.597532, acc.: 69.53%] [G loss: 0.959357]\n",
      "epoch:38 step:35772 [D loss: 0.666647, acc.: 57.81%] [G loss: 0.954187]\n",
      "epoch:38 step:35773 [D loss: 0.645711, acc.: 64.06%] [G loss: 0.899666]\n",
      "epoch:38 step:35774 [D loss: 0.646926, acc.: 57.03%] [G loss: 0.887921]\n",
      "epoch:38 step:35775 [D loss: 0.651282, acc.: 60.94%] [G loss: 0.973864]\n",
      "epoch:38 step:35776 [D loss: 0.644292, acc.: 60.16%] [G loss: 0.923024]\n",
      "epoch:38 step:35777 [D loss: 0.690977, acc.: 57.03%] [G loss: 0.993819]\n",
      "epoch:38 step:35778 [D loss: 0.646778, acc.: 62.50%] [G loss: 1.014849]\n",
      "epoch:38 step:35779 [D loss: 0.651286, acc.: 67.97%] [G loss: 0.983956]\n",
      "epoch:38 step:35780 [D loss: 0.597521, acc.: 67.19%] [G loss: 0.936034]\n",
      "epoch:38 step:35781 [D loss: 0.622952, acc.: 65.62%] [G loss: 0.910734]\n",
      "epoch:38 step:35782 [D loss: 0.634407, acc.: 68.75%] [G loss: 0.908251]\n",
      "epoch:38 step:35783 [D loss: 0.609238, acc.: 65.62%] [G loss: 0.905583]\n",
      "epoch:38 step:35784 [D loss: 0.659718, acc.: 59.38%] [G loss: 1.034394]\n",
      "epoch:38 step:35785 [D loss: 0.630070, acc.: 64.06%] [G loss: 1.033804]\n",
      "epoch:38 step:35786 [D loss: 0.601939, acc.: 69.53%] [G loss: 0.942035]\n",
      "epoch:38 step:35787 [D loss: 0.662069, acc.: 58.59%] [G loss: 0.949588]\n",
      "epoch:38 step:35788 [D loss: 0.607457, acc.: 67.97%] [G loss: 0.886953]\n",
      "epoch:38 step:35789 [D loss: 0.657600, acc.: 65.62%] [G loss: 0.868638]\n",
      "epoch:38 step:35790 [D loss: 0.672261, acc.: 58.59%] [G loss: 0.977193]\n",
      "epoch:38 step:35791 [D loss: 0.653545, acc.: 60.94%] [G loss: 0.954466]\n",
      "epoch:38 step:35792 [D loss: 0.641289, acc.: 60.94%] [G loss: 0.986235]\n",
      "epoch:38 step:35793 [D loss: 0.633445, acc.: 64.06%] [G loss: 0.905814]\n",
      "epoch:38 step:35794 [D loss: 0.689209, acc.: 58.59%] [G loss: 0.871160]\n",
      "epoch:38 step:35795 [D loss: 0.637747, acc.: 69.53%] [G loss: 0.983810]\n",
      "epoch:38 step:35796 [D loss: 0.685655, acc.: 56.25%] [G loss: 0.951034]\n",
      "epoch:38 step:35797 [D loss: 0.656366, acc.: 62.50%] [G loss: 0.968903]\n",
      "epoch:38 step:35798 [D loss: 0.611118, acc.: 72.66%] [G loss: 0.957430]\n",
      "epoch:38 step:35799 [D loss: 0.593469, acc.: 68.75%] [G loss: 1.025514]\n",
      "epoch:38 step:35800 [D loss: 0.671415, acc.: 60.16%] [G loss: 0.942191]\n",
      "##############\n",
      "[ 2.93073357  2.55678173  2.19302711  4.15114816  0.92980641 10.27426719\n",
      "  2.61111765  3.21311319  4.2756432   7.14868929]\n",
      "##########\n",
      "epoch:38 step:35801 [D loss: 0.651796, acc.: 63.28%] [G loss: 0.921667]\n",
      "epoch:38 step:35802 [D loss: 0.647340, acc.: 61.72%] [G loss: 0.931303]\n",
      "epoch:38 step:35803 [D loss: 0.624959, acc.: 63.28%] [G loss: 0.974603]\n",
      "epoch:38 step:35804 [D loss: 0.600239, acc.: 68.75%] [G loss: 0.961969]\n",
      "epoch:38 step:35805 [D loss: 0.631968, acc.: 63.28%] [G loss: 0.993046]\n",
      "epoch:38 step:35806 [D loss: 0.649149, acc.: 57.81%] [G loss: 0.910723]\n",
      "epoch:38 step:35807 [D loss: 0.631302, acc.: 64.06%] [G loss: 0.939374]\n",
      "epoch:38 step:35808 [D loss: 0.611538, acc.: 62.50%] [G loss: 1.053973]\n",
      "epoch:38 step:35809 [D loss: 0.645445, acc.: 64.06%] [G loss: 0.976103]\n",
      "epoch:38 step:35810 [D loss: 0.644136, acc.: 63.28%] [G loss: 0.993578]\n",
      "epoch:38 step:35811 [D loss: 0.602689, acc.: 64.06%] [G loss: 1.041519]\n",
      "epoch:38 step:35812 [D loss: 0.602849, acc.: 67.19%] [G loss: 0.898020]\n",
      "epoch:38 step:35813 [D loss: 0.605979, acc.: 66.41%] [G loss: 0.985840]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:35814 [D loss: 0.636546, acc.: 66.41%] [G loss: 0.989262]\n",
      "epoch:38 step:35815 [D loss: 0.646105, acc.: 64.06%] [G loss: 0.975791]\n",
      "epoch:38 step:35816 [D loss: 0.642963, acc.: 65.62%] [G loss: 0.926103]\n",
      "epoch:38 step:35817 [D loss: 0.650239, acc.: 58.59%] [G loss: 0.928708]\n",
      "epoch:38 step:35818 [D loss: 0.655695, acc.: 60.94%] [G loss: 0.997701]\n",
      "epoch:38 step:35819 [D loss: 0.625826, acc.: 65.62%] [G loss: 0.979937]\n",
      "epoch:38 step:35820 [D loss: 0.652211, acc.: 63.28%] [G loss: 0.986231]\n",
      "epoch:38 step:35821 [D loss: 0.633511, acc.: 61.72%] [G loss: 0.932624]\n",
      "epoch:38 step:35822 [D loss: 0.661368, acc.: 61.72%] [G loss: 0.881351]\n",
      "epoch:38 step:35823 [D loss: 0.624196, acc.: 63.28%] [G loss: 0.898811]\n",
      "epoch:38 step:35824 [D loss: 0.686710, acc.: 59.38%] [G loss: 0.919226]\n",
      "epoch:38 step:35825 [D loss: 0.673610, acc.: 58.59%] [G loss: 0.954199]\n",
      "epoch:38 step:35826 [D loss: 0.647391, acc.: 63.28%] [G loss: 0.928761]\n",
      "epoch:38 step:35827 [D loss: 0.640966, acc.: 60.16%] [G loss: 0.923053]\n",
      "epoch:38 step:35828 [D loss: 0.636504, acc.: 60.94%] [G loss: 1.013099]\n",
      "epoch:38 step:35829 [D loss: 0.654251, acc.: 64.84%] [G loss: 0.914061]\n",
      "epoch:38 step:35830 [D loss: 0.655004, acc.: 56.25%] [G loss: 0.916832]\n",
      "epoch:38 step:35831 [D loss: 0.653223, acc.: 57.81%] [G loss: 0.893975]\n",
      "epoch:38 step:35832 [D loss: 0.685018, acc.: 53.91%] [G loss: 0.921279]\n",
      "epoch:38 step:35833 [D loss: 0.657395, acc.: 61.72%] [G loss: 0.902994]\n",
      "epoch:38 step:35834 [D loss: 0.658621, acc.: 60.94%] [G loss: 0.952510]\n",
      "epoch:38 step:35835 [D loss: 0.672200, acc.: 57.81%] [G loss: 1.005428]\n",
      "epoch:38 step:35836 [D loss: 0.639385, acc.: 65.62%] [G loss: 0.999052]\n",
      "epoch:38 step:35837 [D loss: 0.636313, acc.: 63.28%] [G loss: 0.994290]\n",
      "epoch:38 step:35838 [D loss: 0.651665, acc.: 64.84%] [G loss: 0.952154]\n",
      "epoch:38 step:35839 [D loss: 0.627676, acc.: 66.41%] [G loss: 0.988971]\n",
      "epoch:38 step:35840 [D loss: 0.723883, acc.: 51.56%] [G loss: 0.996839]\n",
      "epoch:38 step:35841 [D loss: 0.648116, acc.: 61.72%] [G loss: 0.955741]\n",
      "epoch:38 step:35842 [D loss: 0.644525, acc.: 65.62%] [G loss: 0.938330]\n",
      "epoch:38 step:35843 [D loss: 0.656840, acc.: 60.16%] [G loss: 0.935788]\n",
      "epoch:38 step:35844 [D loss: 0.658178, acc.: 61.72%] [G loss: 0.908551]\n",
      "epoch:38 step:35845 [D loss: 0.661219, acc.: 57.81%] [G loss: 0.882617]\n",
      "epoch:38 step:35846 [D loss: 0.663678, acc.: 62.50%] [G loss: 0.970097]\n",
      "epoch:38 step:35847 [D loss: 0.634006, acc.: 64.84%] [G loss: 0.990998]\n",
      "epoch:38 step:35848 [D loss: 0.625094, acc.: 71.09%] [G loss: 0.969279]\n",
      "epoch:38 step:35849 [D loss: 0.640697, acc.: 63.28%] [G loss: 0.943615]\n",
      "epoch:38 step:35850 [D loss: 0.654846, acc.: 58.59%] [G loss: 0.896593]\n",
      "epoch:38 step:35851 [D loss: 0.639455, acc.: 57.81%] [G loss: 0.924664]\n",
      "epoch:38 step:35852 [D loss: 0.675582, acc.: 51.56%] [G loss: 0.881191]\n",
      "epoch:38 step:35853 [D loss: 0.643234, acc.: 64.84%] [G loss: 0.982396]\n",
      "epoch:38 step:35854 [D loss: 0.655810, acc.: 60.16%] [G loss: 0.979807]\n",
      "epoch:38 step:35855 [D loss: 0.648430, acc.: 58.59%] [G loss: 0.978490]\n",
      "epoch:38 step:35856 [D loss: 0.667948, acc.: 60.16%] [G loss: 0.923119]\n",
      "epoch:38 step:35857 [D loss: 0.634159, acc.: 61.72%] [G loss: 0.961442]\n",
      "epoch:38 step:35858 [D loss: 0.585084, acc.: 75.78%] [G loss: 0.891579]\n",
      "epoch:38 step:35859 [D loss: 0.616924, acc.: 67.97%] [G loss: 0.977600]\n",
      "epoch:38 step:35860 [D loss: 0.688821, acc.: 53.12%] [G loss: 0.968579]\n",
      "epoch:38 step:35861 [D loss: 0.636507, acc.: 64.84%] [G loss: 0.922867]\n",
      "epoch:38 step:35862 [D loss: 0.618815, acc.: 60.16%] [G loss: 0.955766]\n",
      "epoch:38 step:35863 [D loss: 0.665905, acc.: 59.38%] [G loss: 0.894541]\n",
      "epoch:38 step:35864 [D loss: 0.622467, acc.: 65.62%] [G loss: 0.950311]\n",
      "epoch:38 step:35865 [D loss: 0.646147, acc.: 61.72%] [G loss: 0.954600]\n",
      "epoch:38 step:35866 [D loss: 0.621415, acc.: 64.84%] [G loss: 0.911959]\n",
      "epoch:38 step:35867 [D loss: 0.653659, acc.: 62.50%] [G loss: 0.893150]\n",
      "epoch:38 step:35868 [D loss: 0.612351, acc.: 64.84%] [G loss: 0.930647]\n",
      "epoch:38 step:35869 [D loss: 0.612795, acc.: 70.31%] [G loss: 0.972505]\n",
      "epoch:38 step:35870 [D loss: 0.626980, acc.: 66.41%] [G loss: 0.923821]\n",
      "epoch:38 step:35871 [D loss: 0.602718, acc.: 67.19%] [G loss: 0.927459]\n",
      "epoch:38 step:35872 [D loss: 0.605353, acc.: 71.88%] [G loss: 0.996455]\n",
      "epoch:38 step:35873 [D loss: 0.637995, acc.: 57.81%] [G loss: 0.918680]\n",
      "epoch:38 step:35874 [D loss: 0.643128, acc.: 58.59%] [G loss: 0.980332]\n",
      "epoch:38 step:35875 [D loss: 0.605098, acc.: 68.75%] [G loss: 0.930921]\n",
      "epoch:38 step:35876 [D loss: 0.673574, acc.: 57.81%] [G loss: 0.962645]\n",
      "epoch:38 step:35877 [D loss: 0.618232, acc.: 63.28%] [G loss: 0.987788]\n",
      "epoch:38 step:35878 [D loss: 0.638532, acc.: 60.94%] [G loss: 0.953637]\n",
      "epoch:38 step:35879 [D loss: 0.611292, acc.: 67.19%] [G loss: 0.951678]\n",
      "epoch:38 step:35880 [D loss: 0.628102, acc.: 65.62%] [G loss: 0.917966]\n",
      "epoch:38 step:35881 [D loss: 0.651921, acc.: 54.69%] [G loss: 0.964715]\n",
      "epoch:38 step:35882 [D loss: 0.674024, acc.: 58.59%] [G loss: 0.894797]\n",
      "epoch:38 step:35883 [D loss: 0.576827, acc.: 69.53%] [G loss: 0.953525]\n",
      "epoch:38 step:35884 [D loss: 0.649169, acc.: 59.38%] [G loss: 0.986693]\n",
      "epoch:38 step:35885 [D loss: 0.661507, acc.: 63.28%] [G loss: 0.827705]\n",
      "epoch:38 step:35886 [D loss: 0.655820, acc.: 60.16%] [G loss: 0.907672]\n",
      "epoch:38 step:35887 [D loss: 0.652921, acc.: 64.84%] [G loss: 0.885417]\n",
      "epoch:38 step:35888 [D loss: 0.637868, acc.: 64.84%] [G loss: 0.877936]\n",
      "epoch:38 step:35889 [D loss: 0.629614, acc.: 66.41%] [G loss: 0.963751]\n",
      "epoch:38 step:35890 [D loss: 0.612466, acc.: 67.19%] [G loss: 0.947328]\n",
      "epoch:38 step:35891 [D loss: 0.639783, acc.: 63.28%] [G loss: 0.978784]\n",
      "epoch:38 step:35892 [D loss: 0.632226, acc.: 64.06%] [G loss: 1.025177]\n",
      "epoch:38 step:35893 [D loss: 0.628565, acc.: 62.50%] [G loss: 0.977570]\n",
      "epoch:38 step:35894 [D loss: 0.703892, acc.: 51.56%] [G loss: 0.962115]\n",
      "epoch:38 step:35895 [D loss: 0.619723, acc.: 67.19%] [G loss: 0.947674]\n",
      "epoch:38 step:35896 [D loss: 0.630774, acc.: 61.72%] [G loss: 0.906201]\n",
      "epoch:38 step:35897 [D loss: 0.692436, acc.: 61.72%] [G loss: 0.948029]\n",
      "epoch:38 step:35898 [D loss: 0.603352, acc.: 70.31%] [G loss: 0.931424]\n",
      "epoch:38 step:35899 [D loss: 0.656121, acc.: 58.59%] [G loss: 0.970255]\n",
      "epoch:38 step:35900 [D loss: 0.687658, acc.: 56.25%] [G loss: 0.937921]\n",
      "epoch:38 step:35901 [D loss: 0.663322, acc.: 60.16%] [G loss: 0.999609]\n",
      "epoch:38 step:35902 [D loss: 0.673601, acc.: 57.81%] [G loss: 0.997481]\n",
      "epoch:38 step:35903 [D loss: 0.586074, acc.: 67.19%] [G loss: 0.977814]\n",
      "epoch:38 step:35904 [D loss: 0.627821, acc.: 66.41%] [G loss: 0.967039]\n",
      "epoch:38 step:35905 [D loss: 0.645120, acc.: 57.81%] [G loss: 0.937025]\n",
      "epoch:38 step:35906 [D loss: 0.644205, acc.: 62.50%] [G loss: 0.971231]\n",
      "epoch:38 step:35907 [D loss: 0.639544, acc.: 60.16%] [G loss: 0.959961]\n",
      "epoch:38 step:35908 [D loss: 0.620431, acc.: 62.50%] [G loss: 0.967208]\n",
      "epoch:38 step:35909 [D loss: 0.660373, acc.: 61.72%] [G loss: 0.912634]\n",
      "epoch:38 step:35910 [D loss: 0.623347, acc.: 66.41%] [G loss: 0.902148]\n",
      "epoch:38 step:35911 [D loss: 0.690837, acc.: 53.91%] [G loss: 0.901429]\n",
      "epoch:38 step:35912 [D loss: 0.636804, acc.: 60.94%] [G loss: 0.838183]\n",
      "epoch:38 step:35913 [D loss: 0.634786, acc.: 68.75%] [G loss: 0.942958]\n",
      "epoch:38 step:35914 [D loss: 0.658261, acc.: 56.25%] [G loss: 0.868834]\n",
      "epoch:38 step:35915 [D loss: 0.668570, acc.: 56.25%] [G loss: 0.956632]\n",
      "epoch:38 step:35916 [D loss: 0.582949, acc.: 74.22%] [G loss: 0.919936]\n",
      "epoch:38 step:35917 [D loss: 0.646047, acc.: 60.16%] [G loss: 0.919191]\n",
      "epoch:38 step:35918 [D loss: 0.657935, acc.: 61.72%] [G loss: 0.940485]\n",
      "epoch:38 step:35919 [D loss: 0.621306, acc.: 64.06%] [G loss: 0.923976]\n",
      "epoch:38 step:35920 [D loss: 0.620877, acc.: 60.16%] [G loss: 0.962702]\n",
      "epoch:38 step:35921 [D loss: 0.598549, acc.: 64.06%] [G loss: 1.015949]\n",
      "epoch:38 step:35922 [D loss: 0.648244, acc.: 63.28%] [G loss: 1.001812]\n",
      "epoch:38 step:35923 [D loss: 0.658886, acc.: 59.38%] [G loss: 0.925209]\n",
      "epoch:38 step:35924 [D loss: 0.661949, acc.: 60.16%] [G loss: 1.019476]\n",
      "epoch:38 step:35925 [D loss: 0.647589, acc.: 64.06%] [G loss: 0.965387]\n",
      "epoch:38 step:35926 [D loss: 0.636075, acc.: 58.59%] [G loss: 0.968954]\n",
      "epoch:38 step:35927 [D loss: 0.669542, acc.: 62.50%] [G loss: 0.925506]\n",
      "epoch:38 step:35928 [D loss: 0.663561, acc.: 57.81%] [G loss: 0.954202]\n",
      "epoch:38 step:35929 [D loss: 0.629368, acc.: 64.84%] [G loss: 0.962521]\n",
      "epoch:38 step:35930 [D loss: 0.645670, acc.: 56.25%] [G loss: 0.988951]\n",
      "epoch:38 step:35931 [D loss: 0.673142, acc.: 59.38%] [G loss: 0.926018]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:35932 [D loss: 0.651155, acc.: 61.72%] [G loss: 0.968266]\n",
      "epoch:38 step:35933 [D loss: 0.588071, acc.: 71.09%] [G loss: 0.904598]\n",
      "epoch:38 step:35934 [D loss: 0.620136, acc.: 63.28%] [G loss: 0.873215]\n",
      "epoch:38 step:35935 [D loss: 0.625872, acc.: 63.28%] [G loss: 0.961405]\n",
      "epoch:38 step:35936 [D loss: 0.595602, acc.: 67.97%] [G loss: 1.053847]\n",
      "epoch:38 step:35937 [D loss: 0.664389, acc.: 61.72%] [G loss: 1.019930]\n",
      "epoch:38 step:35938 [D loss: 0.632935, acc.: 68.75%] [G loss: 0.973158]\n",
      "epoch:38 step:35939 [D loss: 0.659580, acc.: 57.03%] [G loss: 0.930549]\n",
      "epoch:38 step:35940 [D loss: 0.683704, acc.: 53.91%] [G loss: 0.960257]\n",
      "epoch:38 step:35941 [D loss: 0.663635, acc.: 60.16%] [G loss: 0.894622]\n",
      "epoch:38 step:35942 [D loss: 0.650371, acc.: 62.50%] [G loss: 0.948216]\n",
      "epoch:38 step:35943 [D loss: 0.619025, acc.: 64.06%] [G loss: 0.923312]\n",
      "epoch:38 step:35944 [D loss: 0.647891, acc.: 61.72%] [G loss: 1.018649]\n",
      "epoch:38 step:35945 [D loss: 0.603754, acc.: 67.97%] [G loss: 1.016951]\n",
      "epoch:38 step:35946 [D loss: 0.650401, acc.: 64.06%] [G loss: 0.920474]\n",
      "epoch:38 step:35947 [D loss: 0.673795, acc.: 56.25%] [G loss: 0.934335]\n",
      "epoch:38 step:35948 [D loss: 0.656371, acc.: 59.38%] [G loss: 0.992181]\n",
      "epoch:38 step:35949 [D loss: 0.651895, acc.: 60.16%] [G loss: 0.985282]\n",
      "epoch:38 step:35950 [D loss: 0.613798, acc.: 65.62%] [G loss: 0.985866]\n",
      "epoch:38 step:35951 [D loss: 0.627023, acc.: 64.84%] [G loss: 0.984127]\n",
      "epoch:38 step:35952 [D loss: 0.695779, acc.: 53.91%] [G loss: 0.972523]\n",
      "epoch:38 step:35953 [D loss: 0.622744, acc.: 65.62%] [G loss: 0.941970]\n",
      "epoch:38 step:35954 [D loss: 0.672190, acc.: 58.59%] [G loss: 0.888520]\n",
      "epoch:38 step:35955 [D loss: 0.631607, acc.: 63.28%] [G loss: 0.934156]\n",
      "epoch:38 step:35956 [D loss: 0.633470, acc.: 57.03%] [G loss: 1.036062]\n",
      "epoch:38 step:35957 [D loss: 0.691729, acc.: 51.56%] [G loss: 0.991077]\n",
      "epoch:38 step:35958 [D loss: 0.654814, acc.: 60.16%] [G loss: 1.032812]\n",
      "epoch:38 step:35959 [D loss: 0.634295, acc.: 59.38%] [G loss: 1.010062]\n",
      "epoch:38 step:35960 [D loss: 0.682294, acc.: 58.59%] [G loss: 0.968923]\n",
      "epoch:38 step:35961 [D loss: 0.652556, acc.: 61.72%] [G loss: 0.917876]\n",
      "epoch:38 step:35962 [D loss: 0.614866, acc.: 62.50%] [G loss: 0.904497]\n",
      "epoch:38 step:35963 [D loss: 0.673891, acc.: 58.59%] [G loss: 0.919106]\n",
      "epoch:38 step:35964 [D loss: 0.635637, acc.: 66.41%] [G loss: 0.896527]\n",
      "epoch:38 step:35965 [D loss: 0.642246, acc.: 68.75%] [G loss: 1.001814]\n",
      "epoch:38 step:35966 [D loss: 0.606863, acc.: 67.19%] [G loss: 0.979961]\n",
      "epoch:38 step:35967 [D loss: 0.630299, acc.: 62.50%] [G loss: 0.958539]\n",
      "epoch:38 step:35968 [D loss: 0.624487, acc.: 67.97%] [G loss: 0.981931]\n",
      "epoch:38 step:35969 [D loss: 0.651659, acc.: 60.16%] [G loss: 0.967097]\n",
      "epoch:38 step:35970 [D loss: 0.660842, acc.: 51.56%] [G loss: 0.970248]\n",
      "epoch:38 step:35971 [D loss: 0.616165, acc.: 64.84%] [G loss: 1.024758]\n",
      "epoch:38 step:35972 [D loss: 0.633038, acc.: 63.28%] [G loss: 1.003206]\n",
      "epoch:38 step:35973 [D loss: 0.655147, acc.: 61.72%] [G loss: 0.988617]\n",
      "epoch:38 step:35974 [D loss: 0.675448, acc.: 56.25%] [G loss: 0.952376]\n",
      "epoch:38 step:35975 [D loss: 0.642663, acc.: 60.16%] [G loss: 0.884609]\n",
      "epoch:38 step:35976 [D loss: 0.634427, acc.: 59.38%] [G loss: 0.911334]\n",
      "epoch:38 step:35977 [D loss: 0.643474, acc.: 60.94%] [G loss: 0.908941]\n",
      "epoch:38 step:35978 [D loss: 0.644033, acc.: 60.16%] [G loss: 0.935760]\n",
      "epoch:38 step:35979 [D loss: 0.673696, acc.: 56.25%] [G loss: 0.907521]\n",
      "epoch:38 step:35980 [D loss: 0.616810, acc.: 64.84%] [G loss: 0.829787]\n",
      "epoch:38 step:35981 [D loss: 0.663628, acc.: 57.81%] [G loss: 0.920240]\n",
      "epoch:38 step:35982 [D loss: 0.683945, acc.: 57.81%] [G loss: 0.950804]\n",
      "epoch:38 step:35983 [D loss: 0.651672, acc.: 62.50%] [G loss: 0.958688]\n",
      "epoch:38 step:35984 [D loss: 0.602581, acc.: 64.84%] [G loss: 0.957668]\n",
      "epoch:38 step:35985 [D loss: 0.643865, acc.: 60.94%] [G loss: 0.946356]\n",
      "epoch:38 step:35986 [D loss: 0.675046, acc.: 60.94%] [G loss: 0.934694]\n",
      "epoch:38 step:35987 [D loss: 0.662807, acc.: 58.59%] [G loss: 0.996532]\n",
      "epoch:38 step:35988 [D loss: 0.595743, acc.: 68.75%] [G loss: 0.934900]\n",
      "epoch:38 step:35989 [D loss: 0.617097, acc.: 64.06%] [G loss: 0.949704]\n",
      "epoch:38 step:35990 [D loss: 0.661139, acc.: 61.72%] [G loss: 0.934253]\n",
      "epoch:38 step:35991 [D loss: 0.642271, acc.: 66.41%] [G loss: 0.848966]\n",
      "epoch:38 step:35992 [D loss: 0.593692, acc.: 70.31%] [G loss: 0.884280]\n",
      "epoch:38 step:35993 [D loss: 0.664045, acc.: 60.16%] [G loss: 0.895902]\n",
      "epoch:38 step:35994 [D loss: 0.720913, acc.: 49.22%] [G loss: 0.900809]\n",
      "epoch:38 step:35995 [D loss: 0.654157, acc.: 60.94%] [G loss: 0.909835]\n",
      "epoch:38 step:35996 [D loss: 0.641571, acc.: 64.84%] [G loss: 0.892699]\n",
      "epoch:38 step:35997 [D loss: 0.629391, acc.: 62.50%] [G loss: 0.951953]\n",
      "epoch:38 step:35998 [D loss: 0.637141, acc.: 62.50%] [G loss: 0.980546]\n",
      "epoch:38 step:35999 [D loss: 0.687583, acc.: 50.78%] [G loss: 0.863220]\n",
      "epoch:38 step:36000 [D loss: 0.598984, acc.: 68.75%] [G loss: 0.952836]\n",
      "##############\n",
      "[3.20062032 2.33068143 2.66450195 4.31921117 1.24136172 7.71661247\n",
      " 2.42637503 3.15184677 4.18750474 7.14868929]\n",
      "##########\n",
      "epoch:38 step:36001 [D loss: 0.646878, acc.: 66.41%] [G loss: 0.907864]\n",
      "epoch:38 step:36002 [D loss: 0.635251, acc.: 64.06%] [G loss: 0.903143]\n",
      "epoch:38 step:36003 [D loss: 0.658978, acc.: 57.81%] [G loss: 0.915719]\n",
      "epoch:38 step:36004 [D loss: 0.649078, acc.: 65.62%] [G loss: 0.917762]\n",
      "epoch:38 step:36005 [D loss: 0.612535, acc.: 68.75%] [G loss: 1.014260]\n",
      "epoch:38 step:36006 [D loss: 0.620830, acc.: 63.28%] [G loss: 0.965390]\n",
      "epoch:38 step:36007 [D loss: 0.587033, acc.: 68.75%] [G loss: 0.942316]\n",
      "epoch:38 step:36008 [D loss: 0.611283, acc.: 64.84%] [G loss: 0.960708]\n",
      "epoch:38 step:36009 [D loss: 0.603279, acc.: 63.28%] [G loss: 0.947191]\n",
      "epoch:38 step:36010 [D loss: 0.647580, acc.: 62.50%] [G loss: 0.989956]\n",
      "epoch:38 step:36011 [D loss: 0.584145, acc.: 75.78%] [G loss: 1.069120]\n",
      "epoch:38 step:36012 [D loss: 0.602015, acc.: 66.41%] [G loss: 0.974313]\n",
      "epoch:38 step:36013 [D loss: 0.666921, acc.: 60.94%] [G loss: 0.953491]\n",
      "epoch:38 step:36014 [D loss: 0.630629, acc.: 55.47%] [G loss: 0.972582]\n",
      "epoch:38 step:36015 [D loss: 0.628444, acc.: 60.94%] [G loss: 0.963158]\n",
      "epoch:38 step:36016 [D loss: 0.677278, acc.: 54.69%] [G loss: 0.903398]\n",
      "epoch:38 step:36017 [D loss: 0.627577, acc.: 61.72%] [G loss: 1.008422]\n",
      "epoch:38 step:36018 [D loss: 0.644646, acc.: 62.50%] [G loss: 0.932732]\n",
      "epoch:38 step:36019 [D loss: 0.609923, acc.: 64.84%] [G loss: 0.890348]\n",
      "epoch:38 step:36020 [D loss: 0.618008, acc.: 64.06%] [G loss: 0.957065]\n",
      "epoch:38 step:36021 [D loss: 0.608089, acc.: 64.06%] [G loss: 1.019181]\n",
      "epoch:38 step:36022 [D loss: 0.594496, acc.: 72.66%] [G loss: 0.997073]\n",
      "epoch:38 step:36023 [D loss: 0.566427, acc.: 75.78%] [G loss: 0.925509]\n",
      "epoch:38 step:36024 [D loss: 0.649238, acc.: 60.94%] [G loss: 0.895735]\n",
      "epoch:38 step:36025 [D loss: 0.635139, acc.: 61.72%] [G loss: 0.904559]\n",
      "epoch:38 step:36026 [D loss: 0.632236, acc.: 64.06%] [G loss: 0.996639]\n",
      "epoch:38 step:36027 [D loss: 0.627134, acc.: 63.28%] [G loss: 0.903838]\n",
      "epoch:38 step:36028 [D loss: 0.653307, acc.: 59.38%] [G loss: 0.916292]\n",
      "epoch:38 step:36029 [D loss: 0.597519, acc.: 70.31%] [G loss: 0.921633]\n",
      "epoch:38 step:36030 [D loss: 0.664749, acc.: 62.50%] [G loss: 0.884086]\n",
      "epoch:38 step:36031 [D loss: 0.677897, acc.: 53.91%] [G loss: 0.925132]\n",
      "epoch:38 step:36032 [D loss: 0.647634, acc.: 64.06%] [G loss: 0.898488]\n",
      "epoch:38 step:36033 [D loss: 0.670625, acc.: 57.81%] [G loss: 0.946726]\n",
      "epoch:38 step:36034 [D loss: 0.654924, acc.: 59.38%] [G loss: 1.045744]\n",
      "epoch:38 step:36035 [D loss: 0.643836, acc.: 57.81%] [G loss: 1.106479]\n",
      "epoch:38 step:36036 [D loss: 0.632379, acc.: 64.84%] [G loss: 1.072881]\n",
      "epoch:38 step:36037 [D loss: 0.643044, acc.: 57.03%] [G loss: 1.036961]\n",
      "epoch:38 step:36038 [D loss: 0.622175, acc.: 67.97%] [G loss: 0.990702]\n",
      "epoch:38 step:36039 [D loss: 0.647376, acc.: 57.81%] [G loss: 0.973096]\n",
      "epoch:38 step:36040 [D loss: 0.563909, acc.: 75.00%] [G loss: 0.951143]\n",
      "epoch:38 step:36041 [D loss: 0.617501, acc.: 65.62%] [G loss: 0.962442]\n",
      "epoch:38 step:36042 [D loss: 0.629557, acc.: 61.72%] [G loss: 1.028859]\n",
      "epoch:38 step:36043 [D loss: 0.646108, acc.: 59.38%] [G loss: 0.966372]\n",
      "epoch:38 step:36044 [D loss: 0.673204, acc.: 59.38%] [G loss: 0.940565]\n",
      "epoch:38 step:36045 [D loss: 0.648994, acc.: 57.81%] [G loss: 0.947267]\n",
      "epoch:38 step:36046 [D loss: 0.653167, acc.: 57.03%] [G loss: 0.873268]\n",
      "epoch:38 step:36047 [D loss: 0.677852, acc.: 57.03%] [G loss: 0.954945]\n",
      "epoch:38 step:36048 [D loss: 0.683903, acc.: 54.69%] [G loss: 0.989818]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:36049 [D loss: 0.618507, acc.: 62.50%] [G loss: 1.019254]\n",
      "epoch:38 step:36050 [D loss: 0.633096, acc.: 59.38%] [G loss: 0.953590]\n",
      "epoch:38 step:36051 [D loss: 0.695387, acc.: 52.34%] [G loss: 0.949889]\n",
      "epoch:38 step:36052 [D loss: 0.655002, acc.: 61.72%] [G loss: 0.972266]\n",
      "epoch:38 step:36053 [D loss: 0.618442, acc.: 67.19%] [G loss: 0.956033]\n",
      "epoch:38 step:36054 [D loss: 0.634710, acc.: 60.16%] [G loss: 0.950509]\n",
      "epoch:38 step:36055 [D loss: 0.644053, acc.: 61.72%] [G loss: 0.911361]\n",
      "epoch:38 step:36056 [D loss: 0.631962, acc.: 64.06%] [G loss: 1.018205]\n",
      "epoch:38 step:36057 [D loss: 0.604221, acc.: 66.41%] [G loss: 0.990225]\n",
      "epoch:38 step:36058 [D loss: 0.696278, acc.: 57.03%] [G loss: 0.869180]\n",
      "epoch:38 step:36059 [D loss: 0.624571, acc.: 67.19%] [G loss: 0.991349]\n",
      "epoch:38 step:36060 [D loss: 0.649148, acc.: 58.59%] [G loss: 0.964759]\n",
      "epoch:38 step:36061 [D loss: 0.628031, acc.: 67.19%] [G loss: 0.986284]\n",
      "epoch:38 step:36062 [D loss: 0.643249, acc.: 68.75%] [G loss: 0.995463]\n",
      "epoch:38 step:36063 [D loss: 0.621181, acc.: 63.28%] [G loss: 0.894848]\n",
      "epoch:38 step:36064 [D loss: 0.611245, acc.: 65.62%] [G loss: 0.907135]\n",
      "epoch:38 step:36065 [D loss: 0.561689, acc.: 73.44%] [G loss: 0.928025]\n",
      "epoch:38 step:36066 [D loss: 0.636866, acc.: 62.50%] [G loss: 0.990172]\n",
      "epoch:38 step:36067 [D loss: 0.673718, acc.: 59.38%] [G loss: 0.912737]\n",
      "epoch:38 step:36068 [D loss: 0.668572, acc.: 56.25%] [G loss: 0.933374]\n",
      "epoch:38 step:36069 [D loss: 0.665538, acc.: 59.38%] [G loss: 0.939846]\n",
      "epoch:38 step:36070 [D loss: 0.694787, acc.: 56.25%] [G loss: 0.948283]\n",
      "epoch:38 step:36071 [D loss: 0.621181, acc.: 65.62%] [G loss: 0.912514]\n",
      "epoch:38 step:36072 [D loss: 0.641467, acc.: 63.28%] [G loss: 0.927426]\n",
      "epoch:38 step:36073 [D loss: 0.637585, acc.: 64.06%] [G loss: 0.963387]\n",
      "epoch:38 step:36074 [D loss: 0.634520, acc.: 64.84%] [G loss: 0.959873]\n",
      "epoch:38 step:36075 [D loss: 0.604943, acc.: 67.97%] [G loss: 0.970119]\n",
      "epoch:38 step:36076 [D loss: 0.649231, acc.: 63.28%] [G loss: 0.926711]\n",
      "epoch:38 step:36077 [D loss: 0.624038, acc.: 62.50%] [G loss: 0.946347]\n",
      "epoch:38 step:36078 [D loss: 0.594624, acc.: 64.84%] [G loss: 0.948287]\n",
      "epoch:38 step:36079 [D loss: 0.669195, acc.: 55.47%] [G loss: 0.992209]\n",
      "epoch:38 step:36080 [D loss: 0.617207, acc.: 64.06%] [G loss: 1.017550]\n",
      "epoch:38 step:36081 [D loss: 0.605199, acc.: 63.28%] [G loss: 0.972764]\n",
      "epoch:38 step:36082 [D loss: 0.638190, acc.: 61.72%] [G loss: 0.964097]\n",
      "epoch:38 step:36083 [D loss: 0.684819, acc.: 54.69%] [G loss: 1.034011]\n",
      "epoch:38 step:36084 [D loss: 0.672243, acc.: 58.59%] [G loss: 1.022852]\n",
      "epoch:38 step:36085 [D loss: 0.648687, acc.: 60.94%] [G loss: 0.993492]\n",
      "epoch:38 step:36086 [D loss: 0.667634, acc.: 55.47%] [G loss: 0.977543]\n",
      "epoch:38 step:36087 [D loss: 0.640904, acc.: 61.72%] [G loss: 0.913793]\n",
      "epoch:38 step:36088 [D loss: 0.668962, acc.: 63.28%] [G loss: 0.982284]\n",
      "epoch:38 step:36089 [D loss: 0.621895, acc.: 63.28%] [G loss: 0.936917]\n",
      "epoch:38 step:36090 [D loss: 0.597837, acc.: 65.62%] [G loss: 0.930010]\n",
      "epoch:38 step:36091 [D loss: 0.625661, acc.: 67.19%] [G loss: 0.970871]\n",
      "epoch:38 step:36092 [D loss: 0.636633, acc.: 64.84%] [G loss: 1.006990]\n",
      "epoch:38 step:36093 [D loss: 0.622944, acc.: 64.06%] [G loss: 0.990456]\n",
      "epoch:38 step:36094 [D loss: 0.591178, acc.: 73.44%] [G loss: 1.041234]\n",
      "epoch:38 step:36095 [D loss: 0.620399, acc.: 63.28%] [G loss: 0.985418]\n",
      "epoch:38 step:36096 [D loss: 0.659864, acc.: 60.16%] [G loss: 0.893469]\n",
      "epoch:38 step:36097 [D loss: 0.635502, acc.: 60.16%] [G loss: 0.923927]\n",
      "epoch:38 step:36098 [D loss: 0.622290, acc.: 62.50%] [G loss: 0.930925]\n",
      "epoch:38 step:36099 [D loss: 0.656186, acc.: 60.94%] [G loss: 0.893660]\n",
      "epoch:38 step:36100 [D loss: 0.618089, acc.: 66.41%] [G loss: 0.924155]\n",
      "epoch:38 step:36101 [D loss: 0.634363, acc.: 61.72%] [G loss: 0.894426]\n",
      "epoch:38 step:36102 [D loss: 0.591749, acc.: 71.88%] [G loss: 0.955079]\n",
      "epoch:38 step:36103 [D loss: 0.623977, acc.: 64.84%] [G loss: 0.890196]\n",
      "epoch:38 step:36104 [D loss: 0.652654, acc.: 59.38%] [G loss: 0.905257]\n",
      "epoch:38 step:36105 [D loss: 0.659168, acc.: 55.47%] [G loss: 0.998098]\n",
      "epoch:38 step:36106 [D loss: 0.630985, acc.: 61.72%] [G loss: 0.950116]\n",
      "epoch:38 step:36107 [D loss: 0.638487, acc.: 60.16%] [G loss: 0.948953]\n",
      "epoch:38 step:36108 [D loss: 0.670046, acc.: 57.03%] [G loss: 0.931507]\n",
      "epoch:38 step:36109 [D loss: 0.598377, acc.: 64.84%] [G loss: 0.912064]\n",
      "epoch:38 step:36110 [D loss: 0.614305, acc.: 67.19%] [G loss: 1.028494]\n",
      "epoch:38 step:36111 [D loss: 0.621561, acc.: 66.41%] [G loss: 0.997087]\n",
      "epoch:38 step:36112 [D loss: 0.630213, acc.: 64.84%] [G loss: 0.932400]\n",
      "epoch:38 step:36113 [D loss: 0.602816, acc.: 67.97%] [G loss: 0.919594]\n",
      "epoch:38 step:36114 [D loss: 0.621195, acc.: 60.16%] [G loss: 0.936503]\n",
      "epoch:38 step:36115 [D loss: 0.628245, acc.: 61.72%] [G loss: 0.960901]\n",
      "epoch:38 step:36116 [D loss: 0.589596, acc.: 71.09%] [G loss: 0.965140]\n",
      "epoch:38 step:36117 [D loss: 0.606207, acc.: 71.88%] [G loss: 0.973667]\n",
      "epoch:38 step:36118 [D loss: 0.651419, acc.: 58.59%] [G loss: 0.973091]\n",
      "epoch:38 step:36119 [D loss: 0.609642, acc.: 64.06%] [G loss: 0.973175]\n",
      "epoch:38 step:36120 [D loss: 0.630250, acc.: 63.28%] [G loss: 0.935994]\n",
      "epoch:38 step:36121 [D loss: 0.645968, acc.: 60.94%] [G loss: 0.965517]\n",
      "epoch:38 step:36122 [D loss: 0.636903, acc.: 61.72%] [G loss: 0.955956]\n",
      "epoch:38 step:36123 [D loss: 0.585057, acc.: 71.09%] [G loss: 0.985258]\n",
      "epoch:38 step:36124 [D loss: 0.669610, acc.: 60.16%] [G loss: 0.976576]\n",
      "epoch:38 step:36125 [D loss: 0.625463, acc.: 58.59%] [G loss: 0.966791]\n",
      "epoch:38 step:36126 [D loss: 0.661137, acc.: 58.59%] [G loss: 0.975244]\n",
      "epoch:38 step:36127 [D loss: 0.638763, acc.: 63.28%] [G loss: 1.031833]\n",
      "epoch:38 step:36128 [D loss: 0.621881, acc.: 62.50%] [G loss: 1.009519]\n",
      "epoch:38 step:36129 [D loss: 0.667006, acc.: 58.59%] [G loss: 1.087778]\n",
      "epoch:38 step:36130 [D loss: 0.624806, acc.: 64.84%] [G loss: 1.010046]\n",
      "epoch:38 step:36131 [D loss: 0.632387, acc.: 65.62%] [G loss: 0.962551]\n",
      "epoch:38 step:36132 [D loss: 0.674503, acc.: 60.94%] [G loss: 0.955016]\n",
      "epoch:38 step:36133 [D loss: 0.632911, acc.: 61.72%] [G loss: 0.968897]\n",
      "epoch:38 step:36134 [D loss: 0.614739, acc.: 74.22%] [G loss: 0.921239]\n",
      "epoch:38 step:36135 [D loss: 0.636104, acc.: 64.84%] [G loss: 0.927779]\n",
      "epoch:38 step:36136 [D loss: 0.615803, acc.: 66.41%] [G loss: 0.943666]\n",
      "epoch:38 step:36137 [D loss: 0.623836, acc.: 60.16%] [G loss: 0.891826]\n",
      "epoch:38 step:36138 [D loss: 0.691909, acc.: 50.00%] [G loss: 0.940405]\n",
      "epoch:38 step:36139 [D loss: 0.655243, acc.: 59.38%] [G loss: 0.958337]\n",
      "epoch:38 step:36140 [D loss: 0.641812, acc.: 64.06%] [G loss: 1.032233]\n",
      "epoch:38 step:36141 [D loss: 0.627280, acc.: 65.62%] [G loss: 1.008225]\n",
      "epoch:38 step:36142 [D loss: 0.665235, acc.: 57.81%] [G loss: 0.998953]\n",
      "epoch:38 step:36143 [D loss: 0.630376, acc.: 65.62%] [G loss: 0.954274]\n",
      "epoch:38 step:36144 [D loss: 0.670360, acc.: 63.28%] [G loss: 0.949867]\n",
      "epoch:38 step:36145 [D loss: 0.681351, acc.: 60.94%] [G loss: 0.936364]\n",
      "epoch:38 step:36146 [D loss: 0.637975, acc.: 63.28%] [G loss: 0.815140]\n",
      "epoch:38 step:36147 [D loss: 0.642162, acc.: 64.84%] [G loss: 0.910607]\n",
      "epoch:38 step:36148 [D loss: 0.643447, acc.: 65.62%] [G loss: 0.937291]\n",
      "epoch:38 step:36149 [D loss: 0.677982, acc.: 59.38%] [G loss: 0.923147]\n",
      "epoch:38 step:36150 [D loss: 0.646067, acc.: 67.97%] [G loss: 0.985565]\n",
      "epoch:38 step:36151 [D loss: 0.602426, acc.: 67.97%] [G loss: 0.983355]\n",
      "epoch:38 step:36152 [D loss: 0.626999, acc.: 60.94%] [G loss: 0.949625]\n",
      "epoch:38 step:36153 [D loss: 0.653643, acc.: 61.72%] [G loss: 0.906608]\n",
      "epoch:38 step:36154 [D loss: 0.669749, acc.: 57.03%] [G loss: 0.978811]\n",
      "epoch:38 step:36155 [D loss: 0.668261, acc.: 55.47%] [G loss: 1.032766]\n",
      "epoch:38 step:36156 [D loss: 0.631755, acc.: 65.62%] [G loss: 0.994048]\n",
      "epoch:38 step:36157 [D loss: 0.671570, acc.: 58.59%] [G loss: 0.947651]\n",
      "epoch:38 step:36158 [D loss: 0.609030, acc.: 70.31%] [G loss: 0.985907]\n",
      "epoch:38 step:36159 [D loss: 0.613209, acc.: 66.41%] [G loss: 0.991676]\n",
      "epoch:38 step:36160 [D loss: 0.653848, acc.: 59.38%] [G loss: 0.984013]\n",
      "epoch:38 step:36161 [D loss: 0.631644, acc.: 63.28%] [G loss: 0.978156]\n",
      "epoch:38 step:36162 [D loss: 0.630707, acc.: 59.38%] [G loss: 0.959599]\n",
      "epoch:38 step:36163 [D loss: 0.637388, acc.: 62.50%] [G loss: 0.977801]\n",
      "epoch:38 step:36164 [D loss: 0.621122, acc.: 59.38%] [G loss: 0.943320]\n",
      "epoch:38 step:36165 [D loss: 0.684124, acc.: 50.00%] [G loss: 1.029902]\n",
      "epoch:38 step:36166 [D loss: 0.636149, acc.: 60.94%] [G loss: 0.950102]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:36167 [D loss: 0.670604, acc.: 57.81%] [G loss: 0.870812]\n",
      "epoch:38 step:36168 [D loss: 0.665995, acc.: 61.72%] [G loss: 0.922915]\n",
      "epoch:38 step:36169 [D loss: 0.687217, acc.: 55.47%] [G loss: 0.893788]\n",
      "epoch:38 step:36170 [D loss: 0.653840, acc.: 60.16%] [G loss: 0.903127]\n",
      "epoch:38 step:36171 [D loss: 0.685475, acc.: 55.47%] [G loss: 0.961143]\n",
      "epoch:38 step:36172 [D loss: 0.616820, acc.: 65.62%] [G loss: 0.983718]\n",
      "epoch:38 step:36173 [D loss: 0.633204, acc.: 65.62%] [G loss: 0.940877]\n",
      "epoch:38 step:36174 [D loss: 0.676124, acc.: 57.81%] [G loss: 0.941318]\n",
      "epoch:38 step:36175 [D loss: 0.601462, acc.: 68.75%] [G loss: 0.996870]\n",
      "epoch:38 step:36176 [D loss: 0.701352, acc.: 56.25%] [G loss: 0.989277]\n",
      "epoch:38 step:36177 [D loss: 0.621050, acc.: 63.28%] [G loss: 0.977560]\n",
      "epoch:38 step:36178 [D loss: 0.655582, acc.: 61.72%] [G loss: 0.879499]\n",
      "epoch:38 step:36179 [D loss: 0.613692, acc.: 69.53%] [G loss: 0.900749]\n",
      "epoch:38 step:36180 [D loss: 0.688756, acc.: 52.34%] [G loss: 0.918931]\n",
      "epoch:38 step:36181 [D loss: 0.629617, acc.: 63.28%] [G loss: 0.934040]\n",
      "epoch:38 step:36182 [D loss: 0.597077, acc.: 68.75%] [G loss: 0.931750]\n",
      "epoch:38 step:36183 [D loss: 0.635654, acc.: 64.06%] [G loss: 1.027782]\n",
      "epoch:38 step:36184 [D loss: 0.648485, acc.: 62.50%] [G loss: 0.903717]\n",
      "epoch:38 step:36185 [D loss: 0.650286, acc.: 71.88%] [G loss: 0.995436]\n",
      "epoch:38 step:36186 [D loss: 0.637339, acc.: 64.84%] [G loss: 0.950071]\n",
      "epoch:38 step:36187 [D loss: 0.625713, acc.: 64.06%] [G loss: 0.943361]\n",
      "epoch:38 step:36188 [D loss: 0.652656, acc.: 61.72%] [G loss: 0.950438]\n",
      "epoch:38 step:36189 [D loss: 0.648126, acc.: 62.50%] [G loss: 0.890028]\n",
      "epoch:38 step:36190 [D loss: 0.619454, acc.: 59.38%] [G loss: 0.983857]\n",
      "epoch:38 step:36191 [D loss: 0.660548, acc.: 60.94%] [G loss: 0.946450]\n",
      "epoch:38 step:36192 [D loss: 0.641111, acc.: 64.06%] [G loss: 1.025385]\n",
      "epoch:38 step:36193 [D loss: 0.644168, acc.: 69.53%] [G loss: 1.018581]\n",
      "epoch:38 step:36194 [D loss: 0.631295, acc.: 64.06%] [G loss: 0.918406]\n",
      "epoch:38 step:36195 [D loss: 0.649656, acc.: 62.50%] [G loss: 0.937485]\n",
      "epoch:38 step:36196 [D loss: 0.634568, acc.: 60.16%] [G loss: 0.999397]\n",
      "epoch:38 step:36197 [D loss: 0.660726, acc.: 58.59%] [G loss: 0.916448]\n",
      "epoch:38 step:36198 [D loss: 0.632784, acc.: 64.84%] [G loss: 0.941432]\n",
      "epoch:38 step:36199 [D loss: 0.677091, acc.: 53.91%] [G loss: 0.951820]\n",
      "epoch:38 step:36200 [D loss: 0.570001, acc.: 67.97%] [G loss: 0.979991]\n",
      "##############\n",
      "[2.74594794 2.56420535 2.27387114 3.77034896 1.33613278 9.27426719\n",
      " 2.78858974 3.28300582 4.19938913 8.14868929]\n",
      "##########\n",
      "epoch:38 step:36201 [D loss: 0.652444, acc.: 62.50%] [G loss: 0.985225]\n",
      "epoch:38 step:36202 [D loss: 0.627041, acc.: 67.19%] [G loss: 0.907695]\n",
      "epoch:38 step:36203 [D loss: 0.664719, acc.: 62.50%] [G loss: 0.892083]\n",
      "epoch:38 step:36204 [D loss: 0.623343, acc.: 61.72%] [G loss: 0.948191]\n",
      "epoch:38 step:36205 [D loss: 0.617335, acc.: 61.72%] [G loss: 0.967183]\n",
      "epoch:38 step:36206 [D loss: 0.628418, acc.: 64.84%] [G loss: 0.990107]\n",
      "epoch:38 step:36207 [D loss: 0.616659, acc.: 63.28%] [G loss: 0.998560]\n",
      "epoch:38 step:36208 [D loss: 0.612834, acc.: 69.53%] [G loss: 0.948288]\n",
      "epoch:38 step:36209 [D loss: 0.653149, acc.: 64.84%] [G loss: 0.935614]\n",
      "epoch:38 step:36210 [D loss: 0.664179, acc.: 60.16%] [G loss: 0.913488]\n",
      "epoch:38 step:36211 [D loss: 0.634910, acc.: 60.94%] [G loss: 0.845364]\n",
      "epoch:38 step:36212 [D loss: 0.646198, acc.: 58.59%] [G loss: 0.916506]\n",
      "epoch:38 step:36213 [D loss: 0.631587, acc.: 62.50%] [G loss: 0.865712]\n",
      "epoch:38 step:36214 [D loss: 0.657562, acc.: 57.03%] [G loss: 0.897439]\n",
      "epoch:38 step:36215 [D loss: 0.636888, acc.: 63.28%] [G loss: 0.969770]\n",
      "epoch:38 step:36216 [D loss: 0.675042, acc.: 60.94%] [G loss: 0.988919]\n",
      "epoch:38 step:36217 [D loss: 0.663518, acc.: 60.16%] [G loss: 0.875345]\n",
      "epoch:38 step:36218 [D loss: 0.621977, acc.: 65.62%] [G loss: 0.887796]\n",
      "epoch:38 step:36219 [D loss: 0.624761, acc.: 66.41%] [G loss: 0.908386]\n",
      "epoch:38 step:36220 [D loss: 0.685372, acc.: 53.12%] [G loss: 0.970527]\n",
      "epoch:38 step:36221 [D loss: 0.611318, acc.: 71.88%] [G loss: 0.961382]\n",
      "epoch:38 step:36222 [D loss: 0.619535, acc.: 66.41%] [G loss: 0.938302]\n",
      "epoch:38 step:36223 [D loss: 0.673470, acc.: 57.81%] [G loss: 0.941175]\n",
      "epoch:38 step:36224 [D loss: 0.632391, acc.: 59.38%] [G loss: 0.939090]\n",
      "epoch:38 step:36225 [D loss: 0.664563, acc.: 56.25%] [G loss: 0.923730]\n",
      "epoch:38 step:36226 [D loss: 0.704324, acc.: 52.34%] [G loss: 0.967635]\n",
      "epoch:38 step:36227 [D loss: 0.678538, acc.: 52.34%] [G loss: 1.038919]\n",
      "epoch:38 step:36228 [D loss: 0.670235, acc.: 65.62%] [G loss: 0.953550]\n",
      "epoch:38 step:36229 [D loss: 0.608106, acc.: 67.19%] [G loss: 0.994977]\n",
      "epoch:38 step:36230 [D loss: 0.644982, acc.: 61.72%] [G loss: 0.970608]\n",
      "epoch:38 step:36231 [D loss: 0.605201, acc.: 69.53%] [G loss: 0.945330]\n",
      "epoch:38 step:36232 [D loss: 0.651627, acc.: 58.59%] [G loss: 0.901238]\n",
      "epoch:38 step:36233 [D loss: 0.625308, acc.: 64.84%] [G loss: 1.008976]\n",
      "epoch:38 step:36234 [D loss: 0.684703, acc.: 54.69%] [G loss: 0.931910]\n",
      "epoch:38 step:36235 [D loss: 0.652323, acc.: 60.16%] [G loss: 0.976185]\n",
      "epoch:38 step:36236 [D loss: 0.641861, acc.: 61.72%] [G loss: 0.941921]\n",
      "epoch:38 step:36237 [D loss: 0.609167, acc.: 66.41%] [G loss: 1.000228]\n",
      "epoch:38 step:36238 [D loss: 0.641332, acc.: 66.41%] [G loss: 0.963386]\n",
      "epoch:38 step:36239 [D loss: 0.614879, acc.: 67.19%] [G loss: 0.938531]\n",
      "epoch:38 step:36240 [D loss: 0.631779, acc.: 60.94%] [G loss: 0.959689]\n",
      "epoch:38 step:36241 [D loss: 0.637414, acc.: 61.72%] [G loss: 0.937380]\n",
      "epoch:38 step:36242 [D loss: 0.594699, acc.: 64.84%] [G loss: 1.016266]\n",
      "epoch:38 step:36243 [D loss: 0.627094, acc.: 66.41%] [G loss: 0.980370]\n",
      "epoch:38 step:36244 [D loss: 0.638275, acc.: 57.81%] [G loss: 0.952274]\n",
      "epoch:38 step:36245 [D loss: 0.675649, acc.: 59.38%] [G loss: 0.952916]\n",
      "epoch:38 step:36246 [D loss: 0.649260, acc.: 60.94%] [G loss: 0.952746]\n",
      "epoch:38 step:36247 [D loss: 0.652078, acc.: 60.94%] [G loss: 0.973522]\n",
      "epoch:38 step:36248 [D loss: 0.638954, acc.: 65.62%] [G loss: 0.944116]\n",
      "epoch:38 step:36249 [D loss: 0.671295, acc.: 59.38%] [G loss: 0.923977]\n",
      "epoch:38 step:36250 [D loss: 0.651169, acc.: 59.38%] [G loss: 0.974642]\n",
      "epoch:38 step:36251 [D loss: 0.603474, acc.: 66.41%] [G loss: 0.890750]\n",
      "epoch:38 step:36252 [D loss: 0.609461, acc.: 71.09%] [G loss: 0.992253]\n",
      "epoch:38 step:36253 [D loss: 0.638548, acc.: 58.59%] [G loss: 0.896236]\n",
      "epoch:38 step:36254 [D loss: 0.618537, acc.: 62.50%] [G loss: 0.929744]\n",
      "epoch:38 step:36255 [D loss: 0.640191, acc.: 64.84%] [G loss: 0.870203]\n",
      "epoch:38 step:36256 [D loss: 0.664780, acc.: 60.94%] [G loss: 0.891623]\n",
      "epoch:38 step:36257 [D loss: 0.630187, acc.: 67.19%] [G loss: 0.950522]\n",
      "epoch:38 step:36258 [D loss: 0.624703, acc.: 61.72%] [G loss: 0.915502]\n",
      "epoch:38 step:36259 [D loss: 0.616248, acc.: 64.06%] [G loss: 0.890277]\n",
      "epoch:38 step:36260 [D loss: 0.634491, acc.: 62.50%] [G loss: 0.971097]\n",
      "epoch:38 step:36261 [D loss: 0.679121, acc.: 52.34%] [G loss: 0.887121]\n",
      "epoch:38 step:36262 [D loss: 0.620476, acc.: 67.19%] [G loss: 0.991473]\n",
      "epoch:38 step:36263 [D loss: 0.647155, acc.: 66.41%] [G loss: 1.094923]\n",
      "epoch:38 step:36264 [D loss: 0.655664, acc.: 65.62%] [G loss: 1.084043]\n",
      "epoch:38 step:36265 [D loss: 0.653074, acc.: 60.16%] [G loss: 1.017925]\n",
      "epoch:38 step:36266 [D loss: 0.658566, acc.: 60.94%] [G loss: 0.999304]\n",
      "epoch:38 step:36267 [D loss: 0.608139, acc.: 71.88%] [G loss: 0.963267]\n",
      "epoch:38 step:36268 [D loss: 0.667798, acc.: 62.50%] [G loss: 0.927390]\n",
      "epoch:38 step:36269 [D loss: 0.670294, acc.: 56.25%] [G loss: 0.979728]\n",
      "epoch:38 step:36270 [D loss: 0.617263, acc.: 67.97%] [G loss: 0.946326]\n",
      "epoch:38 step:36271 [D loss: 0.680052, acc.: 57.03%] [G loss: 0.998074]\n",
      "epoch:38 step:36272 [D loss: 0.638943, acc.: 60.94%] [G loss: 0.906145]\n",
      "epoch:38 step:36273 [D loss: 0.648283, acc.: 60.16%] [G loss: 0.937694]\n",
      "epoch:38 step:36274 [D loss: 0.646966, acc.: 60.16%] [G loss: 0.947054]\n",
      "epoch:38 step:36275 [D loss: 0.602002, acc.: 67.19%] [G loss: 0.929101]\n",
      "epoch:38 step:36276 [D loss: 0.617042, acc.: 60.94%] [G loss: 0.933768]\n",
      "epoch:38 step:36277 [D loss: 0.646737, acc.: 64.84%] [G loss: 0.940920]\n",
      "epoch:38 step:36278 [D loss: 0.647560, acc.: 59.38%] [G loss: 0.936340]\n",
      "epoch:38 step:36279 [D loss: 0.662254, acc.: 60.16%] [G loss: 0.889586]\n",
      "epoch:38 step:36280 [D loss: 0.642147, acc.: 65.62%] [G loss: 0.899613]\n",
      "epoch:38 step:36281 [D loss: 0.648448, acc.: 59.38%] [G loss: 0.985079]\n",
      "epoch:38 step:36282 [D loss: 0.641598, acc.: 63.28%] [G loss: 0.978795]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:36283 [D loss: 0.641053, acc.: 63.28%] [G loss: 0.995267]\n",
      "epoch:38 step:36284 [D loss: 0.629646, acc.: 63.28%] [G loss: 0.914716]\n",
      "epoch:38 step:36285 [D loss: 0.644752, acc.: 59.38%] [G loss: 0.959064]\n",
      "epoch:38 step:36286 [D loss: 0.647719, acc.: 60.94%] [G loss: 0.894363]\n",
      "epoch:38 step:36287 [D loss: 0.650529, acc.: 67.97%] [G loss: 0.914059]\n",
      "epoch:38 step:36288 [D loss: 0.636343, acc.: 59.38%] [G loss: 0.962342]\n",
      "epoch:38 step:36289 [D loss: 0.668862, acc.: 56.25%] [G loss: 1.001469]\n",
      "epoch:38 step:36290 [D loss: 0.638787, acc.: 60.94%] [G loss: 1.011807]\n",
      "epoch:38 step:36291 [D loss: 0.650247, acc.: 63.28%] [G loss: 0.998268]\n",
      "epoch:38 step:36292 [D loss: 0.623974, acc.: 65.62%] [G loss: 0.942923]\n",
      "epoch:38 step:36293 [D loss: 0.646028, acc.: 64.84%] [G loss: 0.909014]\n",
      "epoch:38 step:36294 [D loss: 0.580705, acc.: 70.31%] [G loss: 1.040023]\n",
      "epoch:38 step:36295 [D loss: 0.644699, acc.: 62.50%] [G loss: 0.987350]\n",
      "epoch:38 step:36296 [D loss: 0.680542, acc.: 52.34%] [G loss: 0.975000]\n",
      "epoch:38 step:36297 [D loss: 0.712695, acc.: 52.34%] [G loss: 0.954021]\n",
      "epoch:38 step:36298 [D loss: 0.645133, acc.: 61.72%] [G loss: 1.003516]\n",
      "epoch:38 step:36299 [D loss: 0.644252, acc.: 61.72%] [G loss: 0.902786]\n",
      "epoch:38 step:36300 [D loss: 0.655488, acc.: 64.06%] [G loss: 0.944167]\n",
      "epoch:38 step:36301 [D loss: 0.670368, acc.: 59.38%] [G loss: 0.932584]\n",
      "epoch:38 step:36302 [D loss: 0.630325, acc.: 64.84%] [G loss: 0.904938]\n",
      "epoch:38 step:36303 [D loss: 0.644104, acc.: 64.84%] [G loss: 0.919258]\n",
      "epoch:38 step:36304 [D loss: 0.636769, acc.: 60.94%] [G loss: 0.937244]\n",
      "epoch:38 step:36305 [D loss: 0.631338, acc.: 63.28%] [G loss: 0.956502]\n",
      "epoch:38 step:36306 [D loss: 0.654473, acc.: 61.72%] [G loss: 0.975599]\n",
      "epoch:38 step:36307 [D loss: 0.653388, acc.: 63.28%] [G loss: 0.938072]\n",
      "epoch:38 step:36308 [D loss: 0.652610, acc.: 57.81%] [G loss: 0.930649]\n",
      "epoch:38 step:36309 [D loss: 0.625375, acc.: 64.06%] [G loss: 0.961656]\n",
      "epoch:38 step:36310 [D loss: 0.629145, acc.: 66.41%] [G loss: 0.850931]\n",
      "epoch:38 step:36311 [D loss: 0.682937, acc.: 53.12%] [G loss: 0.948779]\n",
      "epoch:38 step:36312 [D loss: 0.643469, acc.: 61.72%] [G loss: 0.969815]\n",
      "epoch:38 step:36313 [D loss: 0.617107, acc.: 64.06%] [G loss: 0.952125]\n",
      "epoch:38 step:36314 [D loss: 0.674318, acc.: 56.25%] [G loss: 0.998502]\n",
      "epoch:38 step:36315 [D loss: 0.672965, acc.: 57.03%] [G loss: 0.966840]\n",
      "epoch:38 step:36316 [D loss: 0.596525, acc.: 70.31%] [G loss: 0.986124]\n",
      "epoch:38 step:36317 [D loss: 0.648989, acc.: 60.94%] [G loss: 1.032156]\n",
      "epoch:38 step:36318 [D loss: 0.657359, acc.: 63.28%] [G loss: 1.001165]\n",
      "epoch:38 step:36319 [D loss: 0.626380, acc.: 68.75%] [G loss: 0.972233]\n",
      "epoch:38 step:36320 [D loss: 0.643156, acc.: 56.25%] [G loss: 0.943944]\n",
      "epoch:38 step:36321 [D loss: 0.632084, acc.: 65.62%] [G loss: 0.909842]\n",
      "epoch:38 step:36322 [D loss: 0.620295, acc.: 62.50%] [G loss: 0.922069]\n",
      "epoch:38 step:36323 [D loss: 0.627813, acc.: 65.62%] [G loss: 0.929940]\n",
      "epoch:38 step:36324 [D loss: 0.621887, acc.: 66.41%] [G loss: 0.917874]\n",
      "epoch:38 step:36325 [D loss: 0.638258, acc.: 64.06%] [G loss: 0.914886]\n",
      "epoch:38 step:36326 [D loss: 0.629832, acc.: 64.06%] [G loss: 0.905178]\n",
      "epoch:38 step:36327 [D loss: 0.600416, acc.: 67.97%] [G loss: 0.945298]\n",
      "epoch:38 step:36328 [D loss: 0.613336, acc.: 67.19%] [G loss: 0.935498]\n",
      "epoch:38 step:36329 [D loss: 0.629668, acc.: 62.50%] [G loss: 0.916514]\n",
      "epoch:38 step:36330 [D loss: 0.688931, acc.: 60.94%] [G loss: 0.985549]\n",
      "epoch:38 step:36331 [D loss: 0.580284, acc.: 72.66%] [G loss: 1.000267]\n",
      "epoch:38 step:36332 [D loss: 0.606253, acc.: 70.31%] [G loss: 0.988247]\n",
      "epoch:38 step:36333 [D loss: 0.633107, acc.: 64.84%] [G loss: 0.974272]\n",
      "epoch:38 step:36334 [D loss: 0.716711, acc.: 52.34%] [G loss: 0.922035]\n",
      "epoch:38 step:36335 [D loss: 0.652493, acc.: 61.72%] [G loss: 1.019852]\n",
      "epoch:38 step:36336 [D loss: 0.634961, acc.: 62.50%] [G loss: 1.016095]\n",
      "epoch:38 step:36337 [D loss: 0.648183, acc.: 60.94%] [G loss: 1.046946]\n",
      "epoch:38 step:36338 [D loss: 0.668491, acc.: 58.59%] [G loss: 1.035045]\n",
      "epoch:38 step:36339 [D loss: 0.599983, acc.: 70.31%] [G loss: 0.955763]\n",
      "epoch:38 step:36340 [D loss: 0.640836, acc.: 58.59%] [G loss: 0.966732]\n",
      "epoch:38 step:36341 [D loss: 0.645847, acc.: 64.84%] [G loss: 1.028253]\n",
      "epoch:38 step:36342 [D loss: 0.652816, acc.: 60.94%] [G loss: 0.982738]\n",
      "epoch:38 step:36343 [D loss: 0.652160, acc.: 57.03%] [G loss: 0.925466]\n",
      "epoch:38 step:36344 [D loss: 0.653530, acc.: 63.28%] [G loss: 0.976858]\n",
      "epoch:38 step:36345 [D loss: 0.646139, acc.: 67.19%] [G loss: 1.071171]\n",
      "epoch:38 step:36346 [D loss: 0.628615, acc.: 64.06%] [G loss: 0.927611]\n",
      "epoch:38 step:36347 [D loss: 0.627575, acc.: 62.50%] [G loss: 0.919667]\n",
      "epoch:38 step:36348 [D loss: 0.605201, acc.: 70.31%] [G loss: 0.963935]\n",
      "epoch:38 step:36349 [D loss: 0.632813, acc.: 65.62%] [G loss: 0.990387]\n",
      "epoch:38 step:36350 [D loss: 0.618021, acc.: 63.28%] [G loss: 0.982891]\n",
      "epoch:38 step:36351 [D loss: 0.665633, acc.: 60.16%] [G loss: 1.077049]\n",
      "epoch:38 step:36352 [D loss: 0.604338, acc.: 70.31%] [G loss: 1.028422]\n",
      "epoch:38 step:36353 [D loss: 0.601320, acc.: 71.88%] [G loss: 1.014322]\n",
      "epoch:38 step:36354 [D loss: 0.599850, acc.: 67.97%] [G loss: 1.017258]\n",
      "epoch:38 step:36355 [D loss: 0.630998, acc.: 65.62%] [G loss: 0.998531]\n",
      "epoch:38 step:36356 [D loss: 0.629576, acc.: 65.62%] [G loss: 1.022390]\n",
      "epoch:38 step:36357 [D loss: 0.608706, acc.: 63.28%] [G loss: 1.004296]\n",
      "epoch:38 step:36358 [D loss: 0.640025, acc.: 60.16%] [G loss: 0.952085]\n",
      "epoch:38 step:36359 [D loss: 0.594868, acc.: 69.53%] [G loss: 0.989700]\n",
      "epoch:38 step:36360 [D loss: 0.691153, acc.: 53.91%] [G loss: 1.013938]\n",
      "epoch:38 step:36361 [D loss: 0.639489, acc.: 62.50%] [G loss: 0.922174]\n",
      "epoch:38 step:36362 [D loss: 0.653103, acc.: 59.38%] [G loss: 0.956602]\n",
      "epoch:38 step:36363 [D loss: 0.598511, acc.: 72.66%] [G loss: 0.968780]\n",
      "epoch:38 step:36364 [D loss: 0.606096, acc.: 68.75%] [G loss: 0.941663]\n",
      "epoch:38 step:36365 [D loss: 0.671422, acc.: 61.72%] [G loss: 0.971079]\n",
      "epoch:38 step:36366 [D loss: 0.631656, acc.: 64.06%] [G loss: 0.987307]\n",
      "epoch:38 step:36367 [D loss: 0.654718, acc.: 58.59%] [G loss: 0.988965]\n",
      "epoch:38 step:36368 [D loss: 0.635570, acc.: 58.59%] [G loss: 0.990543]\n",
      "epoch:38 step:36369 [D loss: 0.652414, acc.: 61.72%] [G loss: 1.065488]\n",
      "epoch:38 step:36370 [D loss: 0.622289, acc.: 64.84%] [G loss: 1.018215]\n",
      "epoch:38 step:36371 [D loss: 0.663447, acc.: 60.94%] [G loss: 0.993242]\n",
      "epoch:38 step:36372 [D loss: 0.642621, acc.: 59.38%] [G loss: 0.973712]\n",
      "epoch:38 step:36373 [D loss: 0.640093, acc.: 62.50%] [G loss: 0.944025]\n",
      "epoch:38 step:36374 [D loss: 0.653806, acc.: 65.62%] [G loss: 0.928121]\n",
      "epoch:38 step:36375 [D loss: 0.622599, acc.: 67.97%] [G loss: 1.016750]\n",
      "epoch:38 step:36376 [D loss: 0.629923, acc.: 62.50%] [G loss: 1.028059]\n",
      "epoch:38 step:36377 [D loss: 0.660228, acc.: 57.81%] [G loss: 1.013664]\n",
      "epoch:38 step:36378 [D loss: 0.620729, acc.: 64.06%] [G loss: 1.048966]\n",
      "epoch:38 step:36379 [D loss: 0.665671, acc.: 56.25%] [G loss: 1.026210]\n",
      "epoch:38 step:36380 [D loss: 0.591608, acc.: 72.66%] [G loss: 0.894105]\n",
      "epoch:38 step:36381 [D loss: 0.684401, acc.: 58.59%] [G loss: 1.011590]\n",
      "epoch:38 step:36382 [D loss: 0.605848, acc.: 64.06%] [G loss: 0.937691]\n",
      "epoch:38 step:36383 [D loss: 0.622828, acc.: 67.97%] [G loss: 1.024571]\n",
      "epoch:38 step:36384 [D loss: 0.600622, acc.: 68.75%] [G loss: 0.936484]\n",
      "epoch:38 step:36385 [D loss: 0.622849, acc.: 65.62%] [G loss: 0.934474]\n",
      "epoch:38 step:36386 [D loss: 0.667303, acc.: 56.25%] [G loss: 0.947809]\n",
      "epoch:38 step:36387 [D loss: 0.663800, acc.: 64.84%] [G loss: 0.999821]\n",
      "epoch:38 step:36388 [D loss: 0.639957, acc.: 58.59%] [G loss: 1.042710]\n",
      "epoch:38 step:36389 [D loss: 0.674179, acc.: 56.25%] [G loss: 0.977587]\n",
      "epoch:38 step:36390 [D loss: 0.644148, acc.: 60.94%] [G loss: 0.920589]\n",
      "epoch:38 step:36391 [D loss: 0.651984, acc.: 61.72%] [G loss: 0.951141]\n",
      "epoch:38 step:36392 [D loss: 0.623995, acc.: 68.75%] [G loss: 0.918375]\n",
      "epoch:38 step:36393 [D loss: 0.651291, acc.: 61.72%] [G loss: 0.958887]\n",
      "epoch:38 step:36394 [D loss: 0.638116, acc.: 61.72%] [G loss: 0.975148]\n",
      "epoch:38 step:36395 [D loss: 0.631525, acc.: 61.72%] [G loss: 0.999919]\n",
      "epoch:38 step:36396 [D loss: 0.637308, acc.: 60.16%] [G loss: 0.957713]\n",
      "epoch:38 step:36397 [D loss: 0.635456, acc.: 60.94%] [G loss: 0.968467]\n",
      "epoch:38 step:36398 [D loss: 0.632107, acc.: 70.31%] [G loss: 0.930875]\n",
      "epoch:38 step:36399 [D loss: 0.571970, acc.: 69.53%] [G loss: 1.028602]\n",
      "epoch:38 step:36400 [D loss: 0.633351, acc.: 62.50%] [G loss: 0.977027]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "[3.10387745 2.38527877 2.4579864  3.95705986 1.16002338 7.88557481\n",
      " 2.89047987 3.41301505 4.18203258 6.12597563]\n",
      "##########\n",
      "epoch:38 step:36401 [D loss: 0.668288, acc.: 62.50%] [G loss: 0.987295]\n",
      "epoch:38 step:36402 [D loss: 0.654020, acc.: 55.47%] [G loss: 0.937149]\n",
      "epoch:38 step:36403 [D loss: 0.634976, acc.: 61.72%] [G loss: 0.972849]\n",
      "epoch:38 step:36404 [D loss: 0.658494, acc.: 60.16%] [G loss: 0.922347]\n",
      "epoch:38 step:36405 [D loss: 0.624309, acc.: 69.53%] [G loss: 0.959947]\n",
      "epoch:38 step:36406 [D loss: 0.640894, acc.: 60.94%] [G loss: 0.971384]\n",
      "epoch:38 step:36407 [D loss: 0.594374, acc.: 70.31%] [G loss: 1.013813]\n",
      "epoch:38 step:36408 [D loss: 0.700669, acc.: 56.25%] [G loss: 0.960267]\n",
      "epoch:38 step:36409 [D loss: 0.675785, acc.: 59.38%] [G loss: 1.017975]\n",
      "epoch:38 step:36410 [D loss: 0.662287, acc.: 57.03%] [G loss: 0.926395]\n",
      "epoch:38 step:36411 [D loss: 0.659564, acc.: 56.25%] [G loss: 0.895142]\n",
      "epoch:38 step:36412 [D loss: 0.630959, acc.: 63.28%] [G loss: 0.888726]\n",
      "epoch:38 step:36413 [D loss: 0.632194, acc.: 62.50%] [G loss: 0.953411]\n",
      "epoch:38 step:36414 [D loss: 0.602307, acc.: 67.97%] [G loss: 0.970110]\n",
      "epoch:38 step:36415 [D loss: 0.662308, acc.: 57.81%] [G loss: 0.883105]\n",
      "epoch:38 step:36416 [D loss: 0.629125, acc.: 61.72%] [G loss: 0.926300]\n",
      "epoch:38 step:36417 [D loss: 0.633358, acc.: 68.75%] [G loss: 0.951836]\n",
      "epoch:38 step:36418 [D loss: 0.651273, acc.: 60.16%] [G loss: 0.877009]\n",
      "epoch:38 step:36419 [D loss: 0.646790, acc.: 63.28%] [G loss: 0.875793]\n",
      "epoch:38 step:36420 [D loss: 0.635420, acc.: 64.06%] [G loss: 0.934435]\n",
      "epoch:38 step:36421 [D loss: 0.655124, acc.: 62.50%] [G loss: 0.976198]\n",
      "epoch:38 step:36422 [D loss: 0.617631, acc.: 63.28%] [G loss: 0.886941]\n",
      "epoch:38 step:36423 [D loss: 0.695060, acc.: 52.34%] [G loss: 0.888421]\n",
      "epoch:38 step:36424 [D loss: 0.655452, acc.: 57.81%] [G loss: 0.882825]\n",
      "epoch:38 step:36425 [D loss: 0.615164, acc.: 66.41%] [G loss: 0.884279]\n",
      "epoch:38 step:36426 [D loss: 0.637833, acc.: 69.53%] [G loss: 0.930934]\n",
      "epoch:38 step:36427 [D loss: 0.611332, acc.: 66.41%] [G loss: 0.924979]\n",
      "epoch:38 step:36428 [D loss: 0.595729, acc.: 71.09%] [G loss: 0.919711]\n",
      "epoch:38 step:36429 [D loss: 0.661754, acc.: 59.38%] [G loss: 0.935729]\n",
      "epoch:38 step:36430 [D loss: 0.600750, acc.: 64.84%] [G loss: 0.946409]\n",
      "epoch:38 step:36431 [D loss: 0.634400, acc.: 64.06%] [G loss: 0.946250]\n",
      "epoch:38 step:36432 [D loss: 0.629122, acc.: 67.19%] [G loss: 0.905382]\n",
      "epoch:38 step:36433 [D loss: 0.625360, acc.: 66.41%] [G loss: 0.987293]\n",
      "epoch:38 step:36434 [D loss: 0.662787, acc.: 53.91%] [G loss: 0.868763]\n",
      "epoch:38 step:36435 [D loss: 0.678452, acc.: 58.59%] [G loss: 0.875629]\n",
      "epoch:38 step:36436 [D loss: 0.680487, acc.: 59.38%] [G loss: 0.982346]\n",
      "epoch:38 step:36437 [D loss: 0.647937, acc.: 63.28%] [G loss: 0.874062]\n",
      "epoch:38 step:36438 [D loss: 0.645194, acc.: 60.16%] [G loss: 0.971305]\n",
      "epoch:38 step:36439 [D loss: 0.677267, acc.: 53.91%] [G loss: 0.981419]\n",
      "epoch:38 step:36440 [D loss: 0.657752, acc.: 53.91%] [G loss: 0.952068]\n",
      "epoch:38 step:36441 [D loss: 0.662847, acc.: 57.81%] [G loss: 0.970594]\n",
      "epoch:38 step:36442 [D loss: 0.644490, acc.: 60.94%] [G loss: 0.901102]\n",
      "epoch:38 step:36443 [D loss: 0.641196, acc.: 60.16%] [G loss: 0.949526]\n",
      "epoch:38 step:36444 [D loss: 0.633394, acc.: 60.94%] [G loss: 0.936050]\n",
      "epoch:38 step:36445 [D loss: 0.693860, acc.: 61.72%] [G loss: 0.974062]\n",
      "epoch:38 step:36446 [D loss: 0.651768, acc.: 57.81%] [G loss: 0.959885]\n",
      "epoch:38 step:36447 [D loss: 0.631627, acc.: 64.06%] [G loss: 0.937610]\n",
      "epoch:38 step:36448 [D loss: 0.664183, acc.: 54.69%] [G loss: 0.900936]\n",
      "epoch:38 step:36449 [D loss: 0.695879, acc.: 56.25%] [G loss: 0.969229]\n",
      "epoch:38 step:36450 [D loss: 0.639544, acc.: 58.59%] [G loss: 0.882727]\n",
      "epoch:38 step:36451 [D loss: 0.666398, acc.: 57.81%] [G loss: 0.937212]\n",
      "epoch:38 step:36452 [D loss: 0.626762, acc.: 66.41%] [G loss: 0.935936]\n",
      "epoch:38 step:36453 [D loss: 0.653291, acc.: 56.25%] [G loss: 0.929125]\n",
      "epoch:38 step:36454 [D loss: 0.642560, acc.: 62.50%] [G loss: 0.938147]\n",
      "epoch:38 step:36455 [D loss: 0.605910, acc.: 71.88%] [G loss: 0.959913]\n",
      "epoch:38 step:36456 [D loss: 0.670259, acc.: 57.03%] [G loss: 0.915325]\n",
      "epoch:38 step:36457 [D loss: 0.653544, acc.: 62.50%] [G loss: 0.928768]\n",
      "epoch:38 step:36458 [D loss: 0.637909, acc.: 66.41%] [G loss: 0.890238]\n",
      "epoch:38 step:36459 [D loss: 0.713875, acc.: 50.00%] [G loss: 0.914825]\n",
      "epoch:38 step:36460 [D loss: 0.655512, acc.: 60.94%] [G loss: 0.962134]\n",
      "epoch:38 step:36461 [D loss: 0.693047, acc.: 57.03%] [G loss: 0.928348]\n",
      "epoch:38 step:36462 [D loss: 0.647367, acc.: 62.50%] [G loss: 0.968124]\n",
      "epoch:38 step:36463 [D loss: 0.686263, acc.: 58.59%] [G loss: 0.977373]\n",
      "epoch:38 step:36464 [D loss: 0.657497, acc.: 53.91%] [G loss: 0.955934]\n",
      "epoch:38 step:36465 [D loss: 0.624463, acc.: 70.31%] [G loss: 0.931700]\n",
      "epoch:38 step:36466 [D loss: 0.635879, acc.: 63.28%] [G loss: 0.909609]\n",
      "epoch:38 step:36467 [D loss: 0.631602, acc.: 65.62%] [G loss: 0.962662]\n",
      "epoch:38 step:36468 [D loss: 0.649410, acc.: 56.25%] [G loss: 0.915240]\n",
      "epoch:38 step:36469 [D loss: 0.605344, acc.: 67.97%] [G loss: 0.982143]\n",
      "epoch:38 step:36470 [D loss: 0.639833, acc.: 64.84%] [G loss: 0.931544]\n",
      "epoch:38 step:36471 [D loss: 0.633716, acc.: 64.06%] [G loss: 0.923397]\n",
      "epoch:38 step:36472 [D loss: 0.626207, acc.: 61.72%] [G loss: 0.937627]\n",
      "epoch:38 step:36473 [D loss: 0.684711, acc.: 57.03%] [G loss: 0.929018]\n",
      "epoch:38 step:36474 [D loss: 0.618182, acc.: 65.62%] [G loss: 0.903108]\n",
      "epoch:38 step:36475 [D loss: 0.623500, acc.: 64.84%] [G loss: 0.911712]\n",
      "epoch:38 step:36476 [D loss: 0.670214, acc.: 58.59%] [G loss: 0.874913]\n",
      "epoch:38 step:36477 [D loss: 0.637909, acc.: 64.06%] [G loss: 0.934961]\n",
      "epoch:38 step:36478 [D loss: 0.700421, acc.: 51.56%] [G loss: 0.893040]\n",
      "epoch:38 step:36479 [D loss: 0.617637, acc.: 60.16%] [G loss: 0.957086]\n",
      "epoch:38 step:36480 [D loss: 0.605712, acc.: 64.06%] [G loss: 0.955496]\n",
      "epoch:38 step:36481 [D loss: 0.612177, acc.: 64.84%] [G loss: 0.965558]\n",
      "epoch:38 step:36482 [D loss: 0.680378, acc.: 57.03%] [G loss: 0.977507]\n",
      "epoch:38 step:36483 [D loss: 0.616602, acc.: 63.28%] [G loss: 0.912596]\n",
      "epoch:38 step:36484 [D loss: 0.641824, acc.: 64.84%] [G loss: 1.000019]\n",
      "epoch:38 step:36485 [D loss: 0.670912, acc.: 55.47%] [G loss: 0.967106]\n",
      "epoch:38 step:36486 [D loss: 0.631201, acc.: 66.41%] [G loss: 0.933659]\n",
      "epoch:38 step:36487 [D loss: 0.689645, acc.: 57.03%] [G loss: 0.936484]\n",
      "epoch:38 step:36488 [D loss: 0.597888, acc.: 69.53%] [G loss: 0.897674]\n",
      "epoch:38 step:36489 [D loss: 0.648652, acc.: 63.28%] [G loss: 0.924520]\n",
      "epoch:38 step:36490 [D loss: 0.614776, acc.: 64.06%] [G loss: 0.991306]\n",
      "epoch:38 step:36491 [D loss: 0.638858, acc.: 62.50%] [G loss: 0.992259]\n",
      "epoch:38 step:36492 [D loss: 0.627168, acc.: 62.50%] [G loss: 0.987225]\n",
      "epoch:38 step:36493 [D loss: 0.632669, acc.: 62.50%] [G loss: 0.938058]\n",
      "epoch:38 step:36494 [D loss: 0.633334, acc.: 58.59%] [G loss: 0.963513]\n",
      "epoch:38 step:36495 [D loss: 0.659988, acc.: 57.81%] [G loss: 0.955314]\n",
      "epoch:38 step:36496 [D loss: 0.591301, acc.: 68.75%] [G loss: 1.067070]\n",
      "epoch:38 step:36497 [D loss: 0.667087, acc.: 56.25%] [G loss: 1.015264]\n",
      "epoch:38 step:36498 [D loss: 0.630359, acc.: 69.53%] [G loss: 0.964558]\n",
      "epoch:38 step:36499 [D loss: 0.644354, acc.: 61.72%] [G loss: 1.033481]\n",
      "epoch:38 step:36500 [D loss: 0.618560, acc.: 67.19%] [G loss: 1.005454]\n",
      "epoch:38 step:36501 [D loss: 0.621570, acc.: 64.84%] [G loss: 1.017205]\n",
      "epoch:38 step:36502 [D loss: 0.634147, acc.: 59.38%] [G loss: 0.941656]\n",
      "epoch:38 step:36503 [D loss: 0.651313, acc.: 60.16%] [G loss: 0.900849]\n",
      "epoch:38 step:36504 [D loss: 0.681177, acc.: 63.28%] [G loss: 0.870638]\n",
      "epoch:38 step:36505 [D loss: 0.678803, acc.: 56.25%] [G loss: 0.882596]\n",
      "epoch:38 step:36506 [D loss: 0.658937, acc.: 58.59%] [G loss: 0.906970]\n",
      "epoch:38 step:36507 [D loss: 0.653960, acc.: 61.72%] [G loss: 0.880958]\n",
      "epoch:38 step:36508 [D loss: 0.634110, acc.: 64.06%] [G loss: 0.967510]\n",
      "epoch:38 step:36509 [D loss: 0.637857, acc.: 63.28%] [G loss: 0.956898]\n",
      "epoch:38 step:36510 [D loss: 0.632490, acc.: 67.97%] [G loss: 0.983737]\n",
      "epoch:38 step:36511 [D loss: 0.641472, acc.: 63.28%] [G loss: 0.945993]\n",
      "epoch:38 step:36512 [D loss: 0.621371, acc.: 60.94%] [G loss: 0.897746]\n",
      "epoch:38 step:36513 [D loss: 0.687090, acc.: 53.91%] [G loss: 0.991673]\n",
      "epoch:38 step:36514 [D loss: 0.654582, acc.: 61.72%] [G loss: 0.953768]\n",
      "epoch:38 step:36515 [D loss: 0.639011, acc.: 60.16%] [G loss: 0.936921]\n",
      "epoch:38 step:36516 [D loss: 0.702778, acc.: 54.69%] [G loss: 0.937556]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:38 step:36517 [D loss: 0.632473, acc.: 63.28%] [G loss: 0.935514]\n",
      "epoch:38 step:36518 [D loss: 0.644546, acc.: 64.84%] [G loss: 0.915771]\n",
      "epoch:38 step:36519 [D loss: 0.592405, acc.: 67.97%] [G loss: 0.906226]\n",
      "epoch:38 step:36520 [D loss: 0.624777, acc.: 61.72%] [G loss: 0.953043]\n",
      "epoch:38 step:36521 [D loss: 0.631839, acc.: 64.84%] [G loss: 0.902691]\n",
      "epoch:38 step:36522 [D loss: 0.666784, acc.: 59.38%] [G loss: 0.916833]\n",
      "epoch:38 step:36523 [D loss: 0.634138, acc.: 59.38%] [G loss: 0.945520]\n",
      "epoch:38 step:36524 [D loss: 0.640900, acc.: 65.62%] [G loss: 0.921380]\n",
      "epoch:38 step:36525 [D loss: 0.586169, acc.: 69.53%] [G loss: 0.925145]\n",
      "epoch:38 step:36526 [D loss: 0.607228, acc.: 66.41%] [G loss: 0.853687]\n",
      "epoch:38 step:36527 [D loss: 0.681823, acc.: 58.59%] [G loss: 0.855031]\n",
      "epoch:38 step:36528 [D loss: 0.648994, acc.: 59.38%] [G loss: 0.847460]\n",
      "epoch:38 step:36529 [D loss: 0.660235, acc.: 60.94%] [G loss: 0.848714]\n",
      "epoch:38 step:36530 [D loss: 0.592163, acc.: 70.31%] [G loss: 0.888276]\n",
      "epoch:38 step:36531 [D loss: 0.659332, acc.: 60.16%] [G loss: 0.946675]\n",
      "epoch:38 step:36532 [D loss: 0.602729, acc.: 70.31%] [G loss: 0.920640]\n",
      "epoch:38 step:36533 [D loss: 0.666720, acc.: 58.59%] [G loss: 0.939231]\n",
      "epoch:38 step:36534 [D loss: 0.647187, acc.: 57.81%] [G loss: 0.936647]\n",
      "epoch:38 step:36535 [D loss: 0.632431, acc.: 60.94%] [G loss: 0.904922]\n",
      "epoch:38 step:36536 [D loss: 0.622997, acc.: 64.06%] [G loss: 0.954563]\n",
      "epoch:38 step:36537 [D loss: 0.653826, acc.: 63.28%] [G loss: 0.957728]\n",
      "epoch:38 step:36538 [D loss: 0.624605, acc.: 60.16%] [G loss: 0.949149]\n",
      "epoch:38 step:36539 [D loss: 0.694949, acc.: 57.81%] [G loss: 0.943199]\n",
      "epoch:38 step:36540 [D loss: 0.616050, acc.: 65.62%] [G loss: 0.950164]\n",
      "epoch:38 step:36541 [D loss: 0.657770, acc.: 56.25%] [G loss: 0.917061]\n",
      "epoch:38 step:36542 [D loss: 0.639497, acc.: 58.59%] [G loss: 0.930231]\n",
      "epoch:38 step:36543 [D loss: 0.640820, acc.: 65.62%] [G loss: 0.960027]\n",
      "epoch:39 step:36544 [D loss: 0.669264, acc.: 60.94%] [G loss: 0.959644]\n",
      "epoch:39 step:36545 [D loss: 0.654590, acc.: 60.94%] [G loss: 0.932803]\n",
      "epoch:39 step:36546 [D loss: 0.627814, acc.: 60.94%] [G loss: 0.961067]\n",
      "epoch:39 step:36547 [D loss: 0.641619, acc.: 65.62%] [G loss: 0.920569]\n",
      "epoch:39 step:36548 [D loss: 0.675688, acc.: 55.47%] [G loss: 0.974714]\n",
      "epoch:39 step:36549 [D loss: 0.648976, acc.: 64.06%] [G loss: 0.912564]\n",
      "epoch:39 step:36550 [D loss: 0.649489, acc.: 64.06%] [G loss: 0.946323]\n",
      "epoch:39 step:36551 [D loss: 0.651366, acc.: 62.50%] [G loss: 0.973673]\n",
      "epoch:39 step:36552 [D loss: 0.644490, acc.: 62.50%] [G loss: 0.989226]\n",
      "epoch:39 step:36553 [D loss: 0.624028, acc.: 64.84%] [G loss: 0.939679]\n",
      "epoch:39 step:36554 [D loss: 0.597082, acc.: 75.78%] [G loss: 0.906306]\n",
      "epoch:39 step:36555 [D loss: 0.595147, acc.: 66.41%] [G loss: 0.898428]\n",
      "epoch:39 step:36556 [D loss: 0.698055, acc.: 56.25%] [G loss: 0.891927]\n",
      "epoch:39 step:36557 [D loss: 0.667363, acc.: 60.16%] [G loss: 0.863940]\n",
      "epoch:39 step:36558 [D loss: 0.624033, acc.: 64.84%] [G loss: 0.865256]\n",
      "epoch:39 step:36559 [D loss: 0.575918, acc.: 68.75%] [G loss: 0.886049]\n",
      "epoch:39 step:36560 [D loss: 0.623922, acc.: 67.97%] [G loss: 0.893550]\n",
      "epoch:39 step:36561 [D loss: 0.687223, acc.: 55.47%] [G loss: 0.855317]\n",
      "epoch:39 step:36562 [D loss: 0.645799, acc.: 65.62%] [G loss: 0.927332]\n",
      "epoch:39 step:36563 [D loss: 0.623681, acc.: 60.16%] [G loss: 0.944156]\n",
      "epoch:39 step:36564 [D loss: 0.598959, acc.: 67.97%] [G loss: 0.983402]\n",
      "epoch:39 step:36565 [D loss: 0.578385, acc.: 70.31%] [G loss: 0.907104]\n",
      "epoch:39 step:36566 [D loss: 0.705361, acc.: 52.34%] [G loss: 0.963096]\n",
      "epoch:39 step:36567 [D loss: 0.604503, acc.: 68.75%] [G loss: 0.984419]\n",
      "epoch:39 step:36568 [D loss: 0.618438, acc.: 60.16%] [G loss: 0.937900]\n",
      "epoch:39 step:36569 [D loss: 0.697764, acc.: 58.59%] [G loss: 0.916905]\n",
      "epoch:39 step:36570 [D loss: 0.654728, acc.: 60.94%] [G loss: 0.925988]\n",
      "epoch:39 step:36571 [D loss: 0.599727, acc.: 67.97%] [G loss: 0.928673]\n",
      "epoch:39 step:36572 [D loss: 0.652129, acc.: 64.06%] [G loss: 0.941107]\n",
      "epoch:39 step:36573 [D loss: 0.637820, acc.: 60.94%] [G loss: 0.930125]\n",
      "epoch:39 step:36574 [D loss: 0.632604, acc.: 67.19%] [G loss: 0.978312]\n",
      "epoch:39 step:36575 [D loss: 0.607748, acc.: 64.06%] [G loss: 0.903243]\n",
      "epoch:39 step:36576 [D loss: 0.666698, acc.: 57.81%] [G loss: 0.953238]\n",
      "epoch:39 step:36577 [D loss: 0.657867, acc.: 59.38%] [G loss: 0.957166]\n",
      "epoch:39 step:36578 [D loss: 0.653887, acc.: 60.94%] [G loss: 0.904655]\n",
      "epoch:39 step:36579 [D loss: 0.658651, acc.: 60.94%] [G loss: 0.893592]\n",
      "epoch:39 step:36580 [D loss: 0.649679, acc.: 56.25%] [G loss: 0.945481]\n",
      "epoch:39 step:36581 [D loss: 0.659081, acc.: 57.03%] [G loss: 0.929639]\n",
      "epoch:39 step:36582 [D loss: 0.634428, acc.: 65.62%] [G loss: 0.975252]\n",
      "epoch:39 step:36583 [D loss: 0.669237, acc.: 57.81%] [G loss: 0.930106]\n",
      "epoch:39 step:36584 [D loss: 0.667503, acc.: 61.72%] [G loss: 0.893052]\n",
      "epoch:39 step:36585 [D loss: 0.580740, acc.: 71.88%] [G loss: 0.960596]\n",
      "epoch:39 step:36586 [D loss: 0.624860, acc.: 61.72%] [G loss: 0.936220]\n",
      "epoch:39 step:36587 [D loss: 0.615791, acc.: 58.59%] [G loss: 0.949837]\n",
      "epoch:39 step:36588 [D loss: 0.683024, acc.: 58.59%] [G loss: 0.895820]\n",
      "epoch:39 step:36589 [D loss: 0.630224, acc.: 64.84%] [G loss: 0.927375]\n",
      "epoch:39 step:36590 [D loss: 0.641253, acc.: 62.50%] [G loss: 0.947725]\n",
      "epoch:39 step:36591 [D loss: 0.633333, acc.: 55.47%] [G loss: 0.944834]\n",
      "epoch:39 step:36592 [D loss: 0.602370, acc.: 67.19%] [G loss: 0.946563]\n",
      "epoch:39 step:36593 [D loss: 0.657491, acc.: 60.94%] [G loss: 0.926600]\n",
      "epoch:39 step:36594 [D loss: 0.636778, acc.: 64.84%] [G loss: 0.964863]\n",
      "epoch:39 step:36595 [D loss: 0.565115, acc.: 75.78%] [G loss: 0.966099]\n",
      "epoch:39 step:36596 [D loss: 0.691343, acc.: 60.94%] [G loss: 0.935598]\n",
      "epoch:39 step:36597 [D loss: 0.666102, acc.: 58.59%] [G loss: 1.002374]\n",
      "epoch:39 step:36598 [D loss: 0.627920, acc.: 63.28%] [G loss: 0.947031]\n",
      "epoch:39 step:36599 [D loss: 0.637360, acc.: 63.28%] [G loss: 0.978119]\n",
      "epoch:39 step:36600 [D loss: 0.644112, acc.: 64.06%] [G loss: 0.990037]\n",
      "##############\n",
      "[3.08089633 2.39438003 2.24643092 4.23844885 1.33489425 8.31902146\n",
      " 2.51649611 3.41645511 4.30602585 8.14868929]\n",
      "##########\n",
      "epoch:39 step:36601 [D loss: 0.626789, acc.: 62.50%] [G loss: 1.033303]\n",
      "epoch:39 step:36602 [D loss: 0.624998, acc.: 69.53%] [G loss: 0.912847]\n",
      "epoch:39 step:36603 [D loss: 0.592617, acc.: 68.75%] [G loss: 0.980290]\n",
      "epoch:39 step:36604 [D loss: 0.649566, acc.: 60.94%] [G loss: 0.914921]\n",
      "epoch:39 step:36605 [D loss: 0.650376, acc.: 59.38%] [G loss: 0.953001]\n",
      "epoch:39 step:36606 [D loss: 0.653688, acc.: 60.94%] [G loss: 0.928418]\n",
      "epoch:39 step:36607 [D loss: 0.637184, acc.: 59.38%] [G loss: 0.968854]\n",
      "epoch:39 step:36608 [D loss: 0.619434, acc.: 65.62%] [G loss: 0.934196]\n",
      "epoch:39 step:36609 [D loss: 0.625612, acc.: 60.94%] [G loss: 0.864701]\n",
      "epoch:39 step:36610 [D loss: 0.660652, acc.: 58.59%] [G loss: 0.988266]\n",
      "epoch:39 step:36611 [D loss: 0.664914, acc.: 51.56%] [G loss: 0.940514]\n",
      "epoch:39 step:36612 [D loss: 0.599632, acc.: 69.53%] [G loss: 0.963380]\n",
      "epoch:39 step:36613 [D loss: 0.695751, acc.: 57.03%] [G loss: 0.995944]\n",
      "epoch:39 step:36614 [D loss: 0.637888, acc.: 69.53%] [G loss: 0.955428]\n",
      "epoch:39 step:36615 [D loss: 0.695404, acc.: 53.12%] [G loss: 0.958538]\n",
      "epoch:39 step:36616 [D loss: 0.594583, acc.: 67.97%] [G loss: 0.888365]\n",
      "epoch:39 step:36617 [D loss: 0.615037, acc.: 64.84%] [G loss: 0.905639]\n",
      "epoch:39 step:36618 [D loss: 0.633221, acc.: 67.19%] [G loss: 0.929620]\n",
      "epoch:39 step:36619 [D loss: 0.610201, acc.: 64.06%] [G loss: 0.924257]\n",
      "epoch:39 step:36620 [D loss: 0.628830, acc.: 62.50%] [G loss: 0.904397]\n",
      "epoch:39 step:36621 [D loss: 0.611135, acc.: 66.41%] [G loss: 0.958851]\n",
      "epoch:39 step:36622 [D loss: 0.673560, acc.: 60.16%] [G loss: 0.999285]\n",
      "epoch:39 step:36623 [D loss: 0.645450, acc.: 64.06%] [G loss: 0.967829]\n",
      "epoch:39 step:36624 [D loss: 0.669032, acc.: 57.03%] [G loss: 0.913005]\n",
      "epoch:39 step:36625 [D loss: 0.623457, acc.: 64.84%] [G loss: 1.000366]\n",
      "epoch:39 step:36626 [D loss: 0.670035, acc.: 63.28%] [G loss: 0.923760]\n",
      "epoch:39 step:36627 [D loss: 0.646062, acc.: 64.06%] [G loss: 0.991250]\n",
      "epoch:39 step:36628 [D loss: 0.625560, acc.: 60.94%] [G loss: 0.980651]\n",
      "epoch:39 step:36629 [D loss: 0.615260, acc.: 65.62%] [G loss: 1.026549]\n",
      "epoch:39 step:36630 [D loss: 0.643178, acc.: 66.41%] [G loss: 1.031341]\n",
      "epoch:39 step:36631 [D loss: 0.663700, acc.: 62.50%] [G loss: 0.957302]\n",
      "epoch:39 step:36632 [D loss: 0.642174, acc.: 67.19%] [G loss: 0.933243]\n",
      "epoch:39 step:36633 [D loss: 0.615628, acc.: 64.06%] [G loss: 0.921793]\n",
      "epoch:39 step:36634 [D loss: 0.669546, acc.: 58.59%] [G loss: 1.000399]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:36635 [D loss: 0.641375, acc.: 65.62%] [G loss: 0.942401]\n",
      "epoch:39 step:36636 [D loss: 0.638796, acc.: 59.38%] [G loss: 1.005181]\n",
      "epoch:39 step:36637 [D loss: 0.653218, acc.: 60.16%] [G loss: 1.030624]\n",
      "epoch:39 step:36638 [D loss: 0.686689, acc.: 57.03%] [G loss: 0.928505]\n",
      "epoch:39 step:36639 [D loss: 0.613512, acc.: 68.75%] [G loss: 0.969000]\n",
      "epoch:39 step:36640 [D loss: 0.603526, acc.: 62.50%] [G loss: 0.956560]\n",
      "epoch:39 step:36641 [D loss: 0.687355, acc.: 57.81%] [G loss: 0.942286]\n",
      "epoch:39 step:36642 [D loss: 0.658725, acc.: 61.72%] [G loss: 0.895860]\n",
      "epoch:39 step:36643 [D loss: 0.664939, acc.: 59.38%] [G loss: 0.935647]\n",
      "epoch:39 step:36644 [D loss: 0.631512, acc.: 63.28%] [G loss: 0.981334]\n",
      "epoch:39 step:36645 [D loss: 0.641548, acc.: 61.72%] [G loss: 0.958852]\n",
      "epoch:39 step:36646 [D loss: 0.608603, acc.: 66.41%] [G loss: 1.013499]\n",
      "epoch:39 step:36647 [D loss: 0.626451, acc.: 62.50%] [G loss: 0.965393]\n",
      "epoch:39 step:36648 [D loss: 0.636698, acc.: 55.47%] [G loss: 0.956655]\n",
      "epoch:39 step:36649 [D loss: 0.615963, acc.: 63.28%] [G loss: 0.918712]\n",
      "epoch:39 step:36650 [D loss: 0.610334, acc.: 68.75%] [G loss: 0.946944]\n",
      "epoch:39 step:36651 [D loss: 0.697152, acc.: 60.94%] [G loss: 0.961945]\n",
      "epoch:39 step:36652 [D loss: 0.656917, acc.: 67.19%] [G loss: 0.950578]\n",
      "epoch:39 step:36653 [D loss: 0.604671, acc.: 64.06%] [G loss: 0.914199]\n",
      "epoch:39 step:36654 [D loss: 0.666852, acc.: 59.38%] [G loss: 0.979310]\n",
      "epoch:39 step:36655 [D loss: 0.621836, acc.: 65.62%] [G loss: 0.910781]\n",
      "epoch:39 step:36656 [D loss: 0.635975, acc.: 66.41%] [G loss: 1.004599]\n",
      "epoch:39 step:36657 [D loss: 0.649417, acc.: 56.25%] [G loss: 0.970046]\n",
      "epoch:39 step:36658 [D loss: 0.649275, acc.: 67.19%] [G loss: 0.977847]\n",
      "epoch:39 step:36659 [D loss: 0.611773, acc.: 68.75%] [G loss: 0.971683]\n",
      "epoch:39 step:36660 [D loss: 0.630070, acc.: 67.19%] [G loss: 0.969233]\n",
      "epoch:39 step:36661 [D loss: 0.631345, acc.: 61.72%] [G loss: 0.999544]\n",
      "epoch:39 step:36662 [D loss: 0.607961, acc.: 69.53%] [G loss: 0.974182]\n",
      "epoch:39 step:36663 [D loss: 0.685241, acc.: 54.69%] [G loss: 0.944203]\n",
      "epoch:39 step:36664 [D loss: 0.619725, acc.: 69.53%] [G loss: 0.965003]\n",
      "epoch:39 step:36665 [D loss: 0.645312, acc.: 66.41%] [G loss: 0.999560]\n",
      "epoch:39 step:36666 [D loss: 0.651865, acc.: 67.97%] [G loss: 0.978953]\n",
      "epoch:39 step:36667 [D loss: 0.641313, acc.: 64.06%] [G loss: 0.897785]\n",
      "epoch:39 step:36668 [D loss: 0.624747, acc.: 64.84%] [G loss: 0.960898]\n",
      "epoch:39 step:36669 [D loss: 0.652392, acc.: 62.50%] [G loss: 0.919993]\n",
      "epoch:39 step:36670 [D loss: 0.633180, acc.: 63.28%] [G loss: 0.968724]\n",
      "epoch:39 step:36671 [D loss: 0.613248, acc.: 67.19%] [G loss: 0.973840]\n",
      "epoch:39 step:36672 [D loss: 0.667495, acc.: 60.94%] [G loss: 0.950004]\n",
      "epoch:39 step:36673 [D loss: 0.626739, acc.: 65.62%] [G loss: 0.891352]\n",
      "epoch:39 step:36674 [D loss: 0.611801, acc.: 65.62%] [G loss: 0.971897]\n",
      "epoch:39 step:36675 [D loss: 0.667235, acc.: 56.25%] [G loss: 0.896469]\n",
      "epoch:39 step:36676 [D loss: 0.618007, acc.: 69.53%] [G loss: 0.918337]\n",
      "epoch:39 step:36677 [D loss: 0.640329, acc.: 57.81%] [G loss: 0.911762]\n",
      "epoch:39 step:36678 [D loss: 0.636962, acc.: 60.16%] [G loss: 0.965891]\n",
      "epoch:39 step:36679 [D loss: 0.643126, acc.: 63.28%] [G loss: 0.937266]\n",
      "epoch:39 step:36680 [D loss: 0.612904, acc.: 70.31%] [G loss: 0.936983]\n",
      "epoch:39 step:36681 [D loss: 0.636816, acc.: 62.50%] [G loss: 0.918168]\n",
      "epoch:39 step:36682 [D loss: 0.642598, acc.: 61.72%] [G loss: 0.957303]\n",
      "epoch:39 step:36683 [D loss: 0.622496, acc.: 64.84%] [G loss: 0.939824]\n",
      "epoch:39 step:36684 [D loss: 0.665989, acc.: 57.81%] [G loss: 0.976317]\n",
      "epoch:39 step:36685 [D loss: 0.641735, acc.: 57.81%] [G loss: 0.947332]\n",
      "epoch:39 step:36686 [D loss: 0.657699, acc.: 56.25%] [G loss: 0.912568]\n",
      "epoch:39 step:36687 [D loss: 0.640905, acc.: 63.28%] [G loss: 0.947020]\n",
      "epoch:39 step:36688 [D loss: 0.645032, acc.: 60.16%] [G loss: 0.962016]\n",
      "epoch:39 step:36689 [D loss: 0.606665, acc.: 66.41%] [G loss: 1.039945]\n",
      "epoch:39 step:36690 [D loss: 0.644899, acc.: 60.94%] [G loss: 0.964067]\n",
      "epoch:39 step:36691 [D loss: 0.639636, acc.: 60.16%] [G loss: 0.982780]\n",
      "epoch:39 step:36692 [D loss: 0.661098, acc.: 52.34%] [G loss: 1.003503]\n",
      "epoch:39 step:36693 [D loss: 0.670222, acc.: 58.59%] [G loss: 0.995989]\n",
      "epoch:39 step:36694 [D loss: 0.664514, acc.: 58.59%] [G loss: 0.967398]\n",
      "epoch:39 step:36695 [D loss: 0.614187, acc.: 64.84%] [G loss: 1.019627]\n",
      "epoch:39 step:36696 [D loss: 0.595352, acc.: 69.53%] [G loss: 0.956748]\n",
      "epoch:39 step:36697 [D loss: 0.642933, acc.: 58.59%] [G loss: 0.974946]\n",
      "epoch:39 step:36698 [D loss: 0.640171, acc.: 64.84%] [G loss: 0.965072]\n",
      "epoch:39 step:36699 [D loss: 0.599255, acc.: 68.75%] [G loss: 0.938947]\n",
      "epoch:39 step:36700 [D loss: 0.630692, acc.: 61.72%] [G loss: 0.936834]\n",
      "epoch:39 step:36701 [D loss: 0.658026, acc.: 56.25%] [G loss: 0.945151]\n",
      "epoch:39 step:36702 [D loss: 0.631873, acc.: 66.41%] [G loss: 0.984573]\n",
      "epoch:39 step:36703 [D loss: 0.644040, acc.: 63.28%] [G loss: 0.956576]\n",
      "epoch:39 step:36704 [D loss: 0.608649, acc.: 69.53%] [G loss: 0.963038]\n",
      "epoch:39 step:36705 [D loss: 0.636281, acc.: 63.28%] [G loss: 1.001044]\n",
      "epoch:39 step:36706 [D loss: 0.670968, acc.: 61.72%] [G loss: 0.989802]\n",
      "epoch:39 step:36707 [D loss: 0.690715, acc.: 48.44%] [G loss: 0.954044]\n",
      "epoch:39 step:36708 [D loss: 0.638009, acc.: 64.84%] [G loss: 0.949219]\n",
      "epoch:39 step:36709 [D loss: 0.619069, acc.: 68.75%] [G loss: 0.987754]\n",
      "epoch:39 step:36710 [D loss: 0.671950, acc.: 56.25%] [G loss: 0.960773]\n",
      "epoch:39 step:36711 [D loss: 0.632176, acc.: 64.84%] [G loss: 0.980151]\n",
      "epoch:39 step:36712 [D loss: 0.643687, acc.: 61.72%] [G loss: 1.085185]\n",
      "epoch:39 step:36713 [D loss: 0.616178, acc.: 64.06%] [G loss: 0.983831]\n",
      "epoch:39 step:36714 [D loss: 0.677071, acc.: 62.50%] [G loss: 1.033244]\n",
      "epoch:39 step:36715 [D loss: 0.633886, acc.: 67.19%] [G loss: 0.973390]\n",
      "epoch:39 step:36716 [D loss: 0.622598, acc.: 64.84%] [G loss: 0.907230]\n",
      "epoch:39 step:36717 [D loss: 0.628537, acc.: 65.62%] [G loss: 0.922934]\n",
      "epoch:39 step:36718 [D loss: 0.611600, acc.: 67.97%] [G loss: 0.870805]\n",
      "epoch:39 step:36719 [D loss: 0.597509, acc.: 67.97%] [G loss: 0.950855]\n",
      "epoch:39 step:36720 [D loss: 0.625841, acc.: 66.41%] [G loss: 0.941194]\n",
      "epoch:39 step:36721 [D loss: 0.656478, acc.: 57.81%] [G loss: 0.974555]\n",
      "epoch:39 step:36722 [D loss: 0.676825, acc.: 55.47%] [G loss: 0.973693]\n",
      "epoch:39 step:36723 [D loss: 0.623260, acc.: 60.94%] [G loss: 0.968252]\n",
      "epoch:39 step:36724 [D loss: 0.666199, acc.: 60.94%] [G loss: 0.945375]\n",
      "epoch:39 step:36725 [D loss: 0.581882, acc.: 71.09%] [G loss: 1.017883]\n",
      "epoch:39 step:36726 [D loss: 0.612385, acc.: 67.19%] [G loss: 0.978615]\n",
      "epoch:39 step:36727 [D loss: 0.631829, acc.: 64.06%] [G loss: 0.992695]\n",
      "epoch:39 step:36728 [D loss: 0.617028, acc.: 66.41%] [G loss: 0.902037]\n",
      "epoch:39 step:36729 [D loss: 0.713026, acc.: 57.03%] [G loss: 0.942401]\n",
      "epoch:39 step:36730 [D loss: 0.642733, acc.: 61.72%] [G loss: 0.933853]\n",
      "epoch:39 step:36731 [D loss: 0.658798, acc.: 60.16%] [G loss: 0.918573]\n",
      "epoch:39 step:36732 [D loss: 0.591379, acc.: 71.09%] [G loss: 1.008471]\n",
      "epoch:39 step:36733 [D loss: 0.654829, acc.: 62.50%] [G loss: 0.967834]\n",
      "epoch:39 step:36734 [D loss: 0.616480, acc.: 70.31%] [G loss: 0.992939]\n",
      "epoch:39 step:36735 [D loss: 0.656929, acc.: 60.16%] [G loss: 0.972020]\n",
      "epoch:39 step:36736 [D loss: 0.590641, acc.: 67.97%] [G loss: 1.022848]\n",
      "epoch:39 step:36737 [D loss: 0.626738, acc.: 64.06%] [G loss: 0.969804]\n",
      "epoch:39 step:36738 [D loss: 0.630041, acc.: 63.28%] [G loss: 0.970316]\n",
      "epoch:39 step:36739 [D loss: 0.605065, acc.: 64.06%] [G loss: 0.944790]\n",
      "epoch:39 step:36740 [D loss: 0.647319, acc.: 60.94%] [G loss: 0.995591]\n",
      "epoch:39 step:36741 [D loss: 0.611852, acc.: 66.41%] [G loss: 0.977791]\n",
      "epoch:39 step:36742 [D loss: 0.611908, acc.: 62.50%] [G loss: 1.023412]\n",
      "epoch:39 step:36743 [D loss: 0.650397, acc.: 64.84%] [G loss: 0.912858]\n",
      "epoch:39 step:36744 [D loss: 0.647414, acc.: 63.28%] [G loss: 1.006362]\n",
      "epoch:39 step:36745 [D loss: 0.615508, acc.: 65.62%] [G loss: 0.962884]\n",
      "epoch:39 step:36746 [D loss: 0.605698, acc.: 64.06%] [G loss: 1.038369]\n",
      "epoch:39 step:36747 [D loss: 0.605968, acc.: 64.84%] [G loss: 0.943438]\n",
      "epoch:39 step:36748 [D loss: 0.630778, acc.: 65.62%] [G loss: 0.967083]\n",
      "epoch:39 step:36749 [D loss: 0.643413, acc.: 63.28%] [G loss: 0.932126]\n",
      "epoch:39 step:36750 [D loss: 0.603071, acc.: 67.19%] [G loss: 0.946726]\n",
      "epoch:39 step:36751 [D loss: 0.620121, acc.: 67.19%] [G loss: 0.961629]\n",
      "epoch:39 step:36752 [D loss: 0.654823, acc.: 64.06%] [G loss: 1.055068]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:36753 [D loss: 0.603611, acc.: 67.97%] [G loss: 1.028244]\n",
      "epoch:39 step:36754 [D loss: 0.637808, acc.: 64.06%] [G loss: 0.960856]\n",
      "epoch:39 step:36755 [D loss: 0.621894, acc.: 67.19%] [G loss: 1.015734]\n",
      "epoch:39 step:36756 [D loss: 0.708290, acc.: 53.91%] [G loss: 0.971527]\n",
      "epoch:39 step:36757 [D loss: 0.604406, acc.: 68.75%] [G loss: 1.019502]\n",
      "epoch:39 step:36758 [D loss: 0.643262, acc.: 64.06%] [G loss: 1.030916]\n",
      "epoch:39 step:36759 [D loss: 0.653519, acc.: 60.94%] [G loss: 1.042623]\n",
      "epoch:39 step:36760 [D loss: 0.586129, acc.: 69.53%] [G loss: 0.992875]\n",
      "epoch:39 step:36761 [D loss: 0.657208, acc.: 62.50%] [G loss: 0.945412]\n",
      "epoch:39 step:36762 [D loss: 0.696016, acc.: 53.91%] [G loss: 0.950432]\n",
      "epoch:39 step:36763 [D loss: 0.661586, acc.: 60.16%] [G loss: 0.943341]\n",
      "epoch:39 step:36764 [D loss: 0.611709, acc.: 62.50%] [G loss: 0.935979]\n",
      "epoch:39 step:36765 [D loss: 0.712177, acc.: 53.12%] [G loss: 0.937005]\n",
      "epoch:39 step:36766 [D loss: 0.629482, acc.: 65.62%] [G loss: 0.899184]\n",
      "epoch:39 step:36767 [D loss: 0.694573, acc.: 57.03%] [G loss: 0.985017]\n",
      "epoch:39 step:36768 [D loss: 0.596568, acc.: 72.66%] [G loss: 0.921996]\n",
      "epoch:39 step:36769 [D loss: 0.652913, acc.: 57.03%] [G loss: 0.981464]\n",
      "epoch:39 step:36770 [D loss: 0.675669, acc.: 59.38%] [G loss: 0.891101]\n",
      "epoch:39 step:36771 [D loss: 0.654142, acc.: 59.38%] [G loss: 0.958390]\n",
      "epoch:39 step:36772 [D loss: 0.636955, acc.: 63.28%] [G loss: 0.975463]\n",
      "epoch:39 step:36773 [D loss: 0.619367, acc.: 65.62%] [G loss: 1.010631]\n",
      "epoch:39 step:36774 [D loss: 0.687782, acc.: 57.03%] [G loss: 0.967628]\n",
      "epoch:39 step:36775 [D loss: 0.672482, acc.: 60.94%] [G loss: 0.922490]\n",
      "epoch:39 step:36776 [D loss: 0.625619, acc.: 65.62%] [G loss: 0.969736]\n",
      "epoch:39 step:36777 [D loss: 0.667523, acc.: 59.38%] [G loss: 1.011495]\n",
      "epoch:39 step:36778 [D loss: 0.693620, acc.: 59.38%] [G loss: 0.921022]\n",
      "epoch:39 step:36779 [D loss: 0.651436, acc.: 61.72%] [G loss: 0.962184]\n",
      "epoch:39 step:36780 [D loss: 0.723831, acc.: 53.91%] [G loss: 0.948847]\n",
      "epoch:39 step:36781 [D loss: 0.674374, acc.: 57.03%] [G loss: 0.964211]\n",
      "epoch:39 step:36782 [D loss: 0.633806, acc.: 61.72%] [G loss: 0.947612]\n",
      "epoch:39 step:36783 [D loss: 0.607772, acc.: 67.19%] [G loss: 1.018184]\n",
      "epoch:39 step:36784 [D loss: 0.595758, acc.: 67.97%] [G loss: 0.962902]\n",
      "epoch:39 step:36785 [D loss: 0.671006, acc.: 60.94%] [G loss: 0.962254]\n",
      "epoch:39 step:36786 [D loss: 0.696913, acc.: 60.16%] [G loss: 0.990671]\n",
      "epoch:39 step:36787 [D loss: 0.650499, acc.: 60.16%] [G loss: 0.931944]\n",
      "epoch:39 step:36788 [D loss: 0.644803, acc.: 60.94%] [G loss: 1.038422]\n",
      "epoch:39 step:36789 [D loss: 0.633782, acc.: 57.81%] [G loss: 0.984834]\n",
      "epoch:39 step:36790 [D loss: 0.703480, acc.: 61.72%] [G loss: 1.043750]\n",
      "epoch:39 step:36791 [D loss: 0.595929, acc.: 64.06%] [G loss: 0.982920]\n",
      "epoch:39 step:36792 [D loss: 0.689738, acc.: 54.69%] [G loss: 1.012654]\n",
      "epoch:39 step:36793 [D loss: 0.617053, acc.: 65.62%] [G loss: 1.049833]\n",
      "epoch:39 step:36794 [D loss: 0.648246, acc.: 60.16%] [G loss: 0.943902]\n",
      "epoch:39 step:36795 [D loss: 0.608843, acc.: 64.84%] [G loss: 1.033589]\n",
      "epoch:39 step:36796 [D loss: 0.695278, acc.: 59.38%] [G loss: 0.958714]\n",
      "epoch:39 step:36797 [D loss: 0.636096, acc.: 60.94%] [G loss: 0.967031]\n",
      "epoch:39 step:36798 [D loss: 0.642056, acc.: 65.62%] [G loss: 0.980932]\n",
      "epoch:39 step:36799 [D loss: 0.666862, acc.: 56.25%] [G loss: 0.966358]\n",
      "epoch:39 step:36800 [D loss: 0.633144, acc.: 64.06%] [G loss: 0.948826]\n",
      "##############\n",
      "[3.07640266 2.44749859 2.4721911  4.19852069 1.32754605 8.21329104\n",
      " 2.77889248 3.66519069 4.29339147 7.14868929]\n",
      "##########\n",
      "epoch:39 step:36801 [D loss: 0.657070, acc.: 62.50%] [G loss: 0.936281]\n",
      "epoch:39 step:36802 [D loss: 0.622433, acc.: 63.28%] [G loss: 0.885287]\n",
      "epoch:39 step:36803 [D loss: 0.640947, acc.: 57.03%] [G loss: 0.893355]\n",
      "epoch:39 step:36804 [D loss: 0.668123, acc.: 56.25%] [G loss: 0.870720]\n",
      "epoch:39 step:36805 [D loss: 0.701977, acc.: 50.78%] [G loss: 0.961918]\n",
      "epoch:39 step:36806 [D loss: 0.646528, acc.: 60.94%] [G loss: 1.051575]\n",
      "epoch:39 step:36807 [D loss: 0.655781, acc.: 57.81%] [G loss: 0.956914]\n",
      "epoch:39 step:36808 [D loss: 0.622372, acc.: 64.84%] [G loss: 0.976403]\n",
      "epoch:39 step:36809 [D loss: 0.649612, acc.: 60.16%] [G loss: 0.998281]\n",
      "epoch:39 step:36810 [D loss: 0.607871, acc.: 63.28%] [G loss: 0.980226]\n",
      "epoch:39 step:36811 [D loss: 0.628678, acc.: 60.94%] [G loss: 0.928810]\n",
      "epoch:39 step:36812 [D loss: 0.578532, acc.: 71.09%] [G loss: 0.925982]\n",
      "epoch:39 step:36813 [D loss: 0.674590, acc.: 59.38%] [G loss: 0.963455]\n",
      "epoch:39 step:36814 [D loss: 0.605398, acc.: 65.62%] [G loss: 0.985998]\n",
      "epoch:39 step:36815 [D loss: 0.631143, acc.: 67.97%] [G loss: 0.961655]\n",
      "epoch:39 step:36816 [D loss: 0.628835, acc.: 64.06%] [G loss: 0.964577]\n",
      "epoch:39 step:36817 [D loss: 0.625973, acc.: 71.09%] [G loss: 0.904934]\n",
      "epoch:39 step:36818 [D loss: 0.623955, acc.: 63.28%] [G loss: 0.952370]\n",
      "epoch:39 step:36819 [D loss: 0.701417, acc.: 57.03%] [G loss: 0.915248]\n",
      "epoch:39 step:36820 [D loss: 0.653228, acc.: 64.06%] [G loss: 0.963037]\n",
      "epoch:39 step:36821 [D loss: 0.655236, acc.: 64.84%] [G loss: 0.955654]\n",
      "epoch:39 step:36822 [D loss: 0.671085, acc.: 56.25%] [G loss: 0.976170]\n",
      "epoch:39 step:36823 [D loss: 0.684689, acc.: 54.69%] [G loss: 0.891381]\n",
      "epoch:39 step:36824 [D loss: 0.613151, acc.: 68.75%] [G loss: 0.898501]\n",
      "epoch:39 step:36825 [D loss: 0.597518, acc.: 67.97%] [G loss: 0.939901]\n",
      "epoch:39 step:36826 [D loss: 0.619428, acc.: 61.72%] [G loss: 0.988579]\n",
      "epoch:39 step:36827 [D loss: 0.635466, acc.: 65.62%] [G loss: 1.002461]\n",
      "epoch:39 step:36828 [D loss: 0.630752, acc.: 63.28%] [G loss: 0.949299]\n",
      "epoch:39 step:36829 [D loss: 0.619514, acc.: 64.84%] [G loss: 0.925225]\n",
      "epoch:39 step:36830 [D loss: 0.584901, acc.: 68.75%] [G loss: 0.924432]\n",
      "epoch:39 step:36831 [D loss: 0.627286, acc.: 64.84%] [G loss: 0.894169]\n",
      "epoch:39 step:36832 [D loss: 0.644577, acc.: 61.72%] [G loss: 0.942017]\n",
      "epoch:39 step:36833 [D loss: 0.605892, acc.: 65.62%] [G loss: 0.940784]\n",
      "epoch:39 step:36834 [D loss: 0.645172, acc.: 64.06%] [G loss: 0.901980]\n",
      "epoch:39 step:36835 [D loss: 0.682377, acc.: 60.94%] [G loss: 0.953588]\n",
      "epoch:39 step:36836 [D loss: 0.655886, acc.: 61.72%] [G loss: 0.876000]\n",
      "epoch:39 step:36837 [D loss: 0.696859, acc.: 53.91%] [G loss: 1.016215]\n",
      "epoch:39 step:36838 [D loss: 0.660049, acc.: 60.16%] [G loss: 1.063473]\n",
      "epoch:39 step:36839 [D loss: 0.658670, acc.: 59.38%] [G loss: 1.000663]\n",
      "epoch:39 step:36840 [D loss: 0.639841, acc.: 63.28%] [G loss: 1.009254]\n",
      "epoch:39 step:36841 [D loss: 0.612830, acc.: 64.06%] [G loss: 1.020696]\n",
      "epoch:39 step:36842 [D loss: 0.665186, acc.: 60.16%] [G loss: 0.983942]\n",
      "epoch:39 step:36843 [D loss: 0.622308, acc.: 64.84%] [G loss: 0.968763]\n",
      "epoch:39 step:36844 [D loss: 0.664140, acc.: 57.81%] [G loss: 0.944092]\n",
      "epoch:39 step:36845 [D loss: 0.645331, acc.: 61.72%] [G loss: 0.961385]\n",
      "epoch:39 step:36846 [D loss: 0.628271, acc.: 60.16%] [G loss: 0.969891]\n",
      "epoch:39 step:36847 [D loss: 0.600372, acc.: 63.28%] [G loss: 0.894831]\n",
      "epoch:39 step:36848 [D loss: 0.673282, acc.: 58.59%] [G loss: 0.970557]\n",
      "epoch:39 step:36849 [D loss: 0.611124, acc.: 67.19%] [G loss: 0.934053]\n",
      "epoch:39 step:36850 [D loss: 0.681312, acc.: 53.91%] [G loss: 0.933604]\n",
      "epoch:39 step:36851 [D loss: 0.644127, acc.: 64.06%] [G loss: 0.921106]\n",
      "epoch:39 step:36852 [D loss: 0.643149, acc.: 61.72%] [G loss: 0.933392]\n",
      "epoch:39 step:36853 [D loss: 0.649124, acc.: 60.94%] [G loss: 0.933688]\n",
      "epoch:39 step:36854 [D loss: 0.631168, acc.: 62.50%] [G loss: 0.954084]\n",
      "epoch:39 step:36855 [D loss: 0.652082, acc.: 60.94%] [G loss: 1.064560]\n",
      "epoch:39 step:36856 [D loss: 0.630328, acc.: 64.06%] [G loss: 0.938855]\n",
      "epoch:39 step:36857 [D loss: 0.604020, acc.: 64.06%] [G loss: 0.957495]\n",
      "epoch:39 step:36858 [D loss: 0.572946, acc.: 73.44%] [G loss: 0.919488]\n",
      "epoch:39 step:36859 [D loss: 0.677039, acc.: 59.38%] [G loss: 1.003717]\n",
      "epoch:39 step:36860 [D loss: 0.611192, acc.: 63.28%] [G loss: 0.997906]\n",
      "epoch:39 step:36861 [D loss: 0.652223, acc.: 57.81%] [G loss: 1.026310]\n",
      "epoch:39 step:36862 [D loss: 0.628237, acc.: 71.88%] [G loss: 0.973049]\n",
      "epoch:39 step:36863 [D loss: 0.673525, acc.: 60.94%] [G loss: 0.995149]\n",
      "epoch:39 step:36864 [D loss: 0.635894, acc.: 59.38%] [G loss: 0.947907]\n",
      "epoch:39 step:36865 [D loss: 0.644919, acc.: 64.84%] [G loss: 0.927470]\n",
      "epoch:39 step:36866 [D loss: 0.602013, acc.: 71.88%] [G loss: 0.964109]\n",
      "epoch:39 step:36867 [D loss: 0.642382, acc.: 55.47%] [G loss: 0.917837]\n",
      "epoch:39 step:36868 [D loss: 0.640617, acc.: 64.06%] [G loss: 0.941956]\n",
      "epoch:39 step:36869 [D loss: 0.679465, acc.: 59.38%] [G loss: 0.959550]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:36870 [D loss: 0.609269, acc.: 67.97%] [G loss: 0.954657]\n",
      "epoch:39 step:36871 [D loss: 0.595838, acc.: 67.19%] [G loss: 0.997290]\n",
      "epoch:39 step:36872 [D loss: 0.588540, acc.: 71.09%] [G loss: 0.971540]\n",
      "epoch:39 step:36873 [D loss: 0.599697, acc.: 70.31%] [G loss: 0.931008]\n",
      "epoch:39 step:36874 [D loss: 0.657779, acc.: 59.38%] [G loss: 0.943661]\n",
      "epoch:39 step:36875 [D loss: 0.618002, acc.: 68.75%] [G loss: 0.966311]\n",
      "epoch:39 step:36876 [D loss: 0.619771, acc.: 68.75%] [G loss: 0.970388]\n",
      "epoch:39 step:36877 [D loss: 0.672065, acc.: 53.91%] [G loss: 0.846999]\n",
      "epoch:39 step:36878 [D loss: 0.648869, acc.: 61.72%] [G loss: 0.886282]\n",
      "epoch:39 step:36879 [D loss: 0.605202, acc.: 61.72%] [G loss: 0.901292]\n",
      "epoch:39 step:36880 [D loss: 0.643706, acc.: 63.28%] [G loss: 0.925861]\n",
      "epoch:39 step:36881 [D loss: 0.609664, acc.: 64.06%] [G loss: 0.962312]\n",
      "epoch:39 step:36882 [D loss: 0.619669, acc.: 68.75%] [G loss: 0.928378]\n",
      "epoch:39 step:36883 [D loss: 0.643712, acc.: 66.41%] [G loss: 0.955401]\n",
      "epoch:39 step:36884 [D loss: 0.670905, acc.: 53.12%] [G loss: 1.013665]\n",
      "epoch:39 step:36885 [D loss: 0.656586, acc.: 60.16%] [G loss: 0.940273]\n",
      "epoch:39 step:36886 [D loss: 0.673063, acc.: 57.81%] [G loss: 1.010919]\n",
      "epoch:39 step:36887 [D loss: 0.653499, acc.: 64.06%] [G loss: 0.981730]\n",
      "epoch:39 step:36888 [D loss: 0.627714, acc.: 65.62%] [G loss: 0.937872]\n",
      "epoch:39 step:36889 [D loss: 0.663239, acc.: 62.50%] [G loss: 0.943374]\n",
      "epoch:39 step:36890 [D loss: 0.612641, acc.: 63.28%] [G loss: 0.891609]\n",
      "epoch:39 step:36891 [D loss: 0.676973, acc.: 57.81%] [G loss: 0.945981]\n",
      "epoch:39 step:36892 [D loss: 0.653586, acc.: 64.84%] [G loss: 0.889500]\n",
      "epoch:39 step:36893 [D loss: 0.624671, acc.: 67.19%] [G loss: 0.919998]\n",
      "epoch:39 step:36894 [D loss: 0.632785, acc.: 63.28%] [G loss: 0.967284]\n",
      "epoch:39 step:36895 [D loss: 0.665040, acc.: 64.84%] [G loss: 0.898783]\n",
      "epoch:39 step:36896 [D loss: 0.645138, acc.: 60.94%] [G loss: 0.869215]\n",
      "epoch:39 step:36897 [D loss: 0.670005, acc.: 56.25%] [G loss: 0.909012]\n",
      "epoch:39 step:36898 [D loss: 0.605753, acc.: 65.62%] [G loss: 0.875711]\n",
      "epoch:39 step:36899 [D loss: 0.609679, acc.: 64.84%] [G loss: 0.903880]\n",
      "epoch:39 step:36900 [D loss: 0.616568, acc.: 69.53%] [G loss: 0.913788]\n",
      "epoch:39 step:36901 [D loss: 0.624299, acc.: 65.62%] [G loss: 0.952402]\n",
      "epoch:39 step:36902 [D loss: 0.633948, acc.: 59.38%] [G loss: 0.943268]\n",
      "epoch:39 step:36903 [D loss: 0.618487, acc.: 65.62%] [G loss: 0.970803]\n",
      "epoch:39 step:36904 [D loss: 0.629413, acc.: 63.28%] [G loss: 1.033134]\n",
      "epoch:39 step:36905 [D loss: 0.644020, acc.: 64.06%] [G loss: 0.957002]\n",
      "epoch:39 step:36906 [D loss: 0.665337, acc.: 60.16%] [G loss: 0.999934]\n",
      "epoch:39 step:36907 [D loss: 0.667866, acc.: 60.94%] [G loss: 0.942721]\n",
      "epoch:39 step:36908 [D loss: 0.661143, acc.: 58.59%] [G loss: 0.970059]\n",
      "epoch:39 step:36909 [D loss: 0.624527, acc.: 64.84%] [G loss: 0.880153]\n",
      "epoch:39 step:36910 [D loss: 0.701236, acc.: 54.69%] [G loss: 0.971994]\n",
      "epoch:39 step:36911 [D loss: 0.666254, acc.: 58.59%] [G loss: 0.986396]\n",
      "epoch:39 step:36912 [D loss: 0.674703, acc.: 58.59%] [G loss: 1.044650]\n",
      "epoch:39 step:36913 [D loss: 0.613586, acc.: 68.75%] [G loss: 0.937664]\n",
      "epoch:39 step:36914 [D loss: 0.610441, acc.: 67.97%] [G loss: 0.949807]\n",
      "epoch:39 step:36915 [D loss: 0.658324, acc.: 57.03%] [G loss: 0.931378]\n",
      "epoch:39 step:36916 [D loss: 0.624347, acc.: 63.28%] [G loss: 0.927298]\n",
      "epoch:39 step:36917 [D loss: 0.639454, acc.: 61.72%] [G loss: 0.918096]\n",
      "epoch:39 step:36918 [D loss: 0.647297, acc.: 64.84%] [G loss: 0.893453]\n",
      "epoch:39 step:36919 [D loss: 0.651424, acc.: 59.38%] [G loss: 0.984132]\n",
      "epoch:39 step:36920 [D loss: 0.632834, acc.: 59.38%] [G loss: 0.870696]\n",
      "epoch:39 step:36921 [D loss: 0.643618, acc.: 67.19%] [G loss: 0.957411]\n",
      "epoch:39 step:36922 [D loss: 0.646867, acc.: 61.72%] [G loss: 0.914949]\n",
      "epoch:39 step:36923 [D loss: 0.701519, acc.: 58.59%] [G loss: 0.971586]\n",
      "epoch:39 step:36924 [D loss: 0.688213, acc.: 53.91%] [G loss: 1.043362]\n",
      "epoch:39 step:36925 [D loss: 0.614210, acc.: 66.41%] [G loss: 0.993351]\n",
      "epoch:39 step:36926 [D loss: 0.667245, acc.: 60.94%] [G loss: 0.993450]\n",
      "epoch:39 step:36927 [D loss: 0.632597, acc.: 64.06%] [G loss: 0.985614]\n",
      "epoch:39 step:36928 [D loss: 0.731069, acc.: 57.03%] [G loss: 0.941229]\n",
      "epoch:39 step:36929 [D loss: 0.620685, acc.: 61.72%] [G loss: 0.951532]\n",
      "epoch:39 step:36930 [D loss: 0.662248, acc.: 58.59%] [G loss: 0.981664]\n",
      "epoch:39 step:36931 [D loss: 0.656625, acc.: 60.16%] [G loss: 0.950596]\n",
      "epoch:39 step:36932 [D loss: 0.565085, acc.: 72.66%] [G loss: 1.014453]\n",
      "epoch:39 step:36933 [D loss: 0.624037, acc.: 68.75%] [G loss: 0.885231]\n",
      "epoch:39 step:36934 [D loss: 0.633387, acc.: 60.94%] [G loss: 0.975612]\n",
      "epoch:39 step:36935 [D loss: 0.660419, acc.: 60.94%] [G loss: 0.916455]\n",
      "epoch:39 step:36936 [D loss: 0.731675, acc.: 50.78%] [G loss: 0.939850]\n",
      "epoch:39 step:36937 [D loss: 0.594149, acc.: 68.75%] [G loss: 1.044068]\n",
      "epoch:39 step:36938 [D loss: 0.666177, acc.: 59.38%] [G loss: 0.983885]\n",
      "epoch:39 step:36939 [D loss: 0.610401, acc.: 60.94%] [G loss: 1.035058]\n",
      "epoch:39 step:36940 [D loss: 0.662687, acc.: 62.50%] [G loss: 1.021420]\n",
      "epoch:39 step:36941 [D loss: 0.653107, acc.: 60.16%] [G loss: 0.982846]\n",
      "epoch:39 step:36942 [D loss: 0.638860, acc.: 64.06%] [G loss: 0.967242]\n",
      "epoch:39 step:36943 [D loss: 0.626524, acc.: 65.62%] [G loss: 0.979343]\n",
      "epoch:39 step:36944 [D loss: 0.628748, acc.: 65.62%] [G loss: 0.974664]\n",
      "epoch:39 step:36945 [D loss: 0.553602, acc.: 74.22%] [G loss: 1.048817]\n",
      "epoch:39 step:36946 [D loss: 0.606833, acc.: 73.44%] [G loss: 1.034254]\n",
      "epoch:39 step:36947 [D loss: 0.591276, acc.: 64.06%] [G loss: 0.992676]\n",
      "epoch:39 step:36948 [D loss: 0.621884, acc.: 64.06%] [G loss: 0.870768]\n",
      "epoch:39 step:36949 [D loss: 0.585753, acc.: 65.62%] [G loss: 0.969521]\n",
      "epoch:39 step:36950 [D loss: 0.652553, acc.: 59.38%] [G loss: 0.938349]\n",
      "epoch:39 step:36951 [D loss: 0.651759, acc.: 62.50%] [G loss: 0.895135]\n",
      "epoch:39 step:36952 [D loss: 0.641594, acc.: 60.16%] [G loss: 0.966877]\n",
      "epoch:39 step:36953 [D loss: 0.653964, acc.: 60.94%] [G loss: 0.964213]\n",
      "epoch:39 step:36954 [D loss: 0.623994, acc.: 64.06%] [G loss: 0.996700]\n",
      "epoch:39 step:36955 [D loss: 0.640901, acc.: 59.38%] [G loss: 0.976934]\n",
      "epoch:39 step:36956 [D loss: 0.658012, acc.: 60.16%] [G loss: 1.022517]\n",
      "epoch:39 step:36957 [D loss: 0.605703, acc.: 64.06%] [G loss: 0.954533]\n",
      "epoch:39 step:36958 [D loss: 0.621989, acc.: 60.16%] [G loss: 0.937218]\n",
      "epoch:39 step:36959 [D loss: 0.671177, acc.: 60.16%] [G loss: 0.999931]\n",
      "epoch:39 step:36960 [D loss: 0.604882, acc.: 70.31%] [G loss: 1.063874]\n",
      "epoch:39 step:36961 [D loss: 0.688703, acc.: 50.00%] [G loss: 0.919690]\n",
      "epoch:39 step:36962 [D loss: 0.600809, acc.: 67.19%] [G loss: 0.940315]\n",
      "epoch:39 step:36963 [D loss: 0.660400, acc.: 55.47%] [G loss: 0.987127]\n",
      "epoch:39 step:36964 [D loss: 0.626309, acc.: 64.84%] [G loss: 0.959783]\n",
      "epoch:39 step:36965 [D loss: 0.671389, acc.: 56.25%] [G loss: 0.989905]\n",
      "epoch:39 step:36966 [D loss: 0.650834, acc.: 56.25%] [G loss: 0.926241]\n",
      "epoch:39 step:36967 [D loss: 0.618930, acc.: 63.28%] [G loss: 1.004340]\n",
      "epoch:39 step:36968 [D loss: 0.715747, acc.: 55.47%] [G loss: 0.927890]\n",
      "epoch:39 step:36969 [D loss: 0.678799, acc.: 57.81%] [G loss: 0.901545]\n",
      "epoch:39 step:36970 [D loss: 0.651904, acc.: 60.16%] [G loss: 0.973716]\n",
      "epoch:39 step:36971 [D loss: 0.681274, acc.: 60.16%] [G loss: 0.961168]\n",
      "epoch:39 step:36972 [D loss: 0.653223, acc.: 60.94%] [G loss: 0.950659]\n",
      "epoch:39 step:36973 [D loss: 0.670719, acc.: 60.94%] [G loss: 0.973997]\n",
      "epoch:39 step:36974 [D loss: 0.654619, acc.: 62.50%] [G loss: 1.032474]\n",
      "epoch:39 step:36975 [D loss: 0.628040, acc.: 64.06%] [G loss: 0.997371]\n",
      "epoch:39 step:36976 [D loss: 0.663674, acc.: 64.06%] [G loss: 0.998250]\n",
      "epoch:39 step:36977 [D loss: 0.599028, acc.: 69.53%] [G loss: 1.010900]\n",
      "epoch:39 step:36978 [D loss: 0.660989, acc.: 63.28%] [G loss: 0.935053]\n",
      "epoch:39 step:36979 [D loss: 0.672547, acc.: 60.16%] [G loss: 0.965649]\n",
      "epoch:39 step:36980 [D loss: 0.657466, acc.: 62.50%] [G loss: 1.005671]\n",
      "epoch:39 step:36981 [D loss: 0.656697, acc.: 63.28%] [G loss: 0.948113]\n",
      "epoch:39 step:36982 [D loss: 0.667359, acc.: 57.81%] [G loss: 0.947230]\n",
      "epoch:39 step:36983 [D loss: 0.580807, acc.: 71.09%] [G loss: 0.967319]\n",
      "epoch:39 step:36984 [D loss: 0.626706, acc.: 60.94%] [G loss: 0.938678]\n",
      "epoch:39 step:36985 [D loss: 0.670907, acc.: 57.81%] [G loss: 0.883285]\n",
      "epoch:39 step:36986 [D loss: 0.611257, acc.: 66.41%] [G loss: 0.939599]\n",
      "epoch:39 step:36987 [D loss: 0.648771, acc.: 57.03%] [G loss: 0.945090]\n",
      "epoch:39 step:36988 [D loss: 0.630752, acc.: 64.84%] [G loss: 0.958268]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:36989 [D loss: 0.687172, acc.: 54.69%] [G loss: 0.957981]\n",
      "epoch:39 step:36990 [D loss: 0.652323, acc.: 53.91%] [G loss: 0.977690]\n",
      "epoch:39 step:36991 [D loss: 0.671863, acc.: 55.47%] [G loss: 0.898180]\n",
      "epoch:39 step:36992 [D loss: 0.602434, acc.: 68.75%] [G loss: 0.912628]\n",
      "epoch:39 step:36993 [D loss: 0.644387, acc.: 64.06%] [G loss: 0.930438]\n",
      "epoch:39 step:36994 [D loss: 0.615314, acc.: 63.28%] [G loss: 0.906877]\n",
      "epoch:39 step:36995 [D loss: 0.641815, acc.: 60.16%] [G loss: 0.925136]\n",
      "epoch:39 step:36996 [D loss: 0.643398, acc.: 60.16%] [G loss: 0.992052]\n",
      "epoch:39 step:36997 [D loss: 0.638198, acc.: 58.59%] [G loss: 0.998317]\n",
      "epoch:39 step:36998 [D loss: 0.623098, acc.: 64.06%] [G loss: 0.900005]\n",
      "epoch:39 step:36999 [D loss: 0.623783, acc.: 68.75%] [G loss: 0.929037]\n",
      "epoch:39 step:37000 [D loss: 0.623221, acc.: 65.62%] [G loss: 0.955602]\n",
      "##############\n",
      "[2.94256995 2.82900112 2.0777407  3.99122382 1.42259229 6.75493073\n",
      " 2.46208209 4.19991288 4.29768082 8.14868929]\n",
      "##########\n",
      "epoch:39 step:37001 [D loss: 0.657338, acc.: 64.06%] [G loss: 0.989197]\n",
      "epoch:39 step:37002 [D loss: 0.552176, acc.: 73.44%] [G loss: 0.967350]\n",
      "epoch:39 step:37003 [D loss: 0.583880, acc.: 70.31%] [G loss: 1.052937]\n",
      "epoch:39 step:37004 [D loss: 0.618134, acc.: 64.06%] [G loss: 0.966347]\n",
      "epoch:39 step:37005 [D loss: 0.671536, acc.: 56.25%] [G loss: 0.968210]\n",
      "epoch:39 step:37006 [D loss: 0.617324, acc.: 62.50%] [G loss: 0.977689]\n",
      "epoch:39 step:37007 [D loss: 0.643631, acc.: 63.28%] [G loss: 0.969509]\n",
      "epoch:39 step:37008 [D loss: 0.650932, acc.: 60.94%] [G loss: 0.978303]\n",
      "epoch:39 step:37009 [D loss: 0.645387, acc.: 61.72%] [G loss: 0.938779]\n",
      "epoch:39 step:37010 [D loss: 0.591827, acc.: 69.53%] [G loss: 0.935744]\n",
      "epoch:39 step:37011 [D loss: 0.596981, acc.: 70.31%] [G loss: 0.958910]\n",
      "epoch:39 step:37012 [D loss: 0.615747, acc.: 65.62%] [G loss: 0.972516]\n",
      "epoch:39 step:37013 [D loss: 0.681063, acc.: 53.12%] [G loss: 0.939576]\n",
      "epoch:39 step:37014 [D loss: 0.608139, acc.: 64.84%] [G loss: 0.965326]\n",
      "epoch:39 step:37015 [D loss: 0.623266, acc.: 64.84%] [G loss: 1.078343]\n",
      "epoch:39 step:37016 [D loss: 0.605751, acc.: 66.41%] [G loss: 0.982556]\n",
      "epoch:39 step:37017 [D loss: 0.643402, acc.: 63.28%] [G loss: 0.990063]\n",
      "epoch:39 step:37018 [D loss: 0.583757, acc.: 69.53%] [G loss: 0.939136]\n",
      "epoch:39 step:37019 [D loss: 0.640050, acc.: 64.06%] [G loss: 1.039557]\n",
      "epoch:39 step:37020 [D loss: 0.655247, acc.: 66.41%] [G loss: 0.911951]\n",
      "epoch:39 step:37021 [D loss: 0.647167, acc.: 61.72%] [G loss: 0.919074]\n",
      "epoch:39 step:37022 [D loss: 0.641943, acc.: 62.50%] [G loss: 0.929967]\n",
      "epoch:39 step:37023 [D loss: 0.657612, acc.: 60.94%] [G loss: 0.928264]\n",
      "epoch:39 step:37024 [D loss: 0.644706, acc.: 60.94%] [G loss: 0.921502]\n",
      "epoch:39 step:37025 [D loss: 0.630417, acc.: 64.84%] [G loss: 0.927924]\n",
      "epoch:39 step:37026 [D loss: 0.631029, acc.: 67.19%] [G loss: 0.960701]\n",
      "epoch:39 step:37027 [D loss: 0.647568, acc.: 63.28%] [G loss: 0.882622]\n",
      "epoch:39 step:37028 [D loss: 0.617775, acc.: 67.97%] [G loss: 0.931105]\n",
      "epoch:39 step:37029 [D loss: 0.631414, acc.: 64.06%] [G loss: 0.870963]\n",
      "epoch:39 step:37030 [D loss: 0.644203, acc.: 62.50%] [G loss: 0.888909]\n",
      "epoch:39 step:37031 [D loss: 0.568569, acc.: 73.44%] [G loss: 0.970971]\n",
      "epoch:39 step:37032 [D loss: 0.621781, acc.: 64.06%] [G loss: 0.964514]\n",
      "epoch:39 step:37033 [D loss: 0.665885, acc.: 57.81%] [G loss: 0.973633]\n",
      "epoch:39 step:37034 [D loss: 0.659215, acc.: 58.59%] [G loss: 0.998366]\n",
      "epoch:39 step:37035 [D loss: 0.638438, acc.: 67.19%] [G loss: 0.943991]\n",
      "epoch:39 step:37036 [D loss: 0.662007, acc.: 60.94%] [G loss: 0.960275]\n",
      "epoch:39 step:37037 [D loss: 0.610532, acc.: 67.19%] [G loss: 0.945959]\n",
      "epoch:39 step:37038 [D loss: 0.617175, acc.: 60.16%] [G loss: 0.963102]\n",
      "epoch:39 step:37039 [D loss: 0.645096, acc.: 60.16%] [G loss: 1.027757]\n",
      "epoch:39 step:37040 [D loss: 0.630594, acc.: 64.84%] [G loss: 0.931895]\n",
      "epoch:39 step:37041 [D loss: 0.651351, acc.: 58.59%] [G loss: 0.932005]\n",
      "epoch:39 step:37042 [D loss: 0.615383, acc.: 64.84%] [G loss: 1.000158]\n",
      "epoch:39 step:37043 [D loss: 0.665185, acc.: 60.94%] [G loss: 0.916826]\n",
      "epoch:39 step:37044 [D loss: 0.616956, acc.: 62.50%] [G loss: 0.941884]\n",
      "epoch:39 step:37045 [D loss: 0.623440, acc.: 60.94%] [G loss: 0.985089]\n",
      "epoch:39 step:37046 [D loss: 0.611080, acc.: 64.06%] [G loss: 0.981010]\n",
      "epoch:39 step:37047 [D loss: 0.602152, acc.: 73.44%] [G loss: 0.987504]\n",
      "epoch:39 step:37048 [D loss: 0.612092, acc.: 71.88%] [G loss: 0.975959]\n",
      "epoch:39 step:37049 [D loss: 0.639399, acc.: 58.59%] [G loss: 0.984281]\n",
      "epoch:39 step:37050 [D loss: 0.628636, acc.: 61.72%] [G loss: 0.964891]\n",
      "epoch:39 step:37051 [D loss: 0.583133, acc.: 70.31%] [G loss: 0.929845]\n",
      "epoch:39 step:37052 [D loss: 0.596236, acc.: 70.31%] [G loss: 0.936540]\n",
      "epoch:39 step:37053 [D loss: 0.608240, acc.: 69.53%] [G loss: 1.007853]\n",
      "epoch:39 step:37054 [D loss: 0.636090, acc.: 61.72%] [G loss: 0.921555]\n",
      "epoch:39 step:37055 [D loss: 0.661146, acc.: 59.38%] [G loss: 0.890826]\n",
      "epoch:39 step:37056 [D loss: 0.599098, acc.: 69.53%] [G loss: 0.881429]\n",
      "epoch:39 step:37057 [D loss: 0.650688, acc.: 60.94%] [G loss: 0.990084]\n",
      "epoch:39 step:37058 [D loss: 0.625915, acc.: 67.97%] [G loss: 0.918199]\n",
      "epoch:39 step:37059 [D loss: 0.657666, acc.: 60.16%] [G loss: 0.940732]\n",
      "epoch:39 step:37060 [D loss: 0.636983, acc.: 61.72%] [G loss: 0.898237]\n",
      "epoch:39 step:37061 [D loss: 0.662308, acc.: 59.38%] [G loss: 0.986040]\n",
      "epoch:39 step:37062 [D loss: 0.649043, acc.: 58.59%] [G loss: 0.885886]\n",
      "epoch:39 step:37063 [D loss: 0.602655, acc.: 68.75%] [G loss: 0.978042]\n",
      "epoch:39 step:37064 [D loss: 0.659238, acc.: 60.94%] [G loss: 0.943281]\n",
      "epoch:39 step:37065 [D loss: 0.579730, acc.: 74.22%] [G loss: 1.039913]\n",
      "epoch:39 step:37066 [D loss: 0.638119, acc.: 66.41%] [G loss: 1.018494]\n",
      "epoch:39 step:37067 [D loss: 0.625381, acc.: 67.19%] [G loss: 0.962686]\n",
      "epoch:39 step:37068 [D loss: 0.669091, acc.: 57.03%] [G loss: 0.933347]\n",
      "epoch:39 step:37069 [D loss: 0.645990, acc.: 65.62%] [G loss: 0.920972]\n",
      "epoch:39 step:37070 [D loss: 0.650495, acc.: 64.84%] [G loss: 0.945377]\n",
      "epoch:39 step:37071 [D loss: 0.679757, acc.: 58.59%] [G loss: 0.930652]\n",
      "epoch:39 step:37072 [D loss: 0.673149, acc.: 53.91%] [G loss: 0.906586]\n",
      "epoch:39 step:37073 [D loss: 0.645172, acc.: 63.28%] [G loss: 0.968068]\n",
      "epoch:39 step:37074 [D loss: 0.613724, acc.: 65.62%] [G loss: 1.032959]\n",
      "epoch:39 step:37075 [D loss: 0.645658, acc.: 62.50%] [G loss: 0.993617]\n",
      "epoch:39 step:37076 [D loss: 0.609670, acc.: 65.62%] [G loss: 1.015060]\n",
      "epoch:39 step:37077 [D loss: 0.651607, acc.: 60.94%] [G loss: 0.922495]\n",
      "epoch:39 step:37078 [D loss: 0.634223, acc.: 60.94%] [G loss: 0.913407]\n",
      "epoch:39 step:37079 [D loss: 0.635930, acc.: 64.06%] [G loss: 0.947336]\n",
      "epoch:39 step:37080 [D loss: 0.618868, acc.: 64.06%] [G loss: 0.989778]\n",
      "epoch:39 step:37081 [D loss: 0.662124, acc.: 60.16%] [G loss: 0.924363]\n",
      "epoch:39 step:37082 [D loss: 0.668363, acc.: 55.47%] [G loss: 0.901521]\n",
      "epoch:39 step:37083 [D loss: 0.630726, acc.: 61.72%] [G loss: 0.891419]\n",
      "epoch:39 step:37084 [D loss: 0.641876, acc.: 66.41%] [G loss: 0.914386]\n",
      "epoch:39 step:37085 [D loss: 0.664706, acc.: 56.25%] [G loss: 1.011890]\n",
      "epoch:39 step:37086 [D loss: 0.596995, acc.: 67.19%] [G loss: 0.960175]\n",
      "epoch:39 step:37087 [D loss: 0.661262, acc.: 61.72%] [G loss: 1.008132]\n",
      "epoch:39 step:37088 [D loss: 0.618825, acc.: 62.50%] [G loss: 0.959617]\n",
      "epoch:39 step:37089 [D loss: 0.644513, acc.: 65.62%] [G loss: 0.910500]\n",
      "epoch:39 step:37090 [D loss: 0.653023, acc.: 60.16%] [G loss: 0.899478]\n",
      "epoch:39 step:37091 [D loss: 0.668062, acc.: 54.69%] [G loss: 0.995619]\n",
      "epoch:39 step:37092 [D loss: 0.647865, acc.: 61.72%] [G loss: 0.922269]\n",
      "epoch:39 step:37093 [D loss: 0.603458, acc.: 70.31%] [G loss: 0.993843]\n",
      "epoch:39 step:37094 [D loss: 0.611028, acc.: 66.41%] [G loss: 1.018127]\n",
      "epoch:39 step:37095 [D loss: 0.642430, acc.: 57.03%] [G loss: 0.985613]\n",
      "epoch:39 step:37096 [D loss: 0.602108, acc.: 69.53%] [G loss: 0.979315]\n",
      "epoch:39 step:37097 [D loss: 0.675542, acc.: 60.94%] [G loss: 0.919410]\n",
      "epoch:39 step:37098 [D loss: 0.674130, acc.: 58.59%] [G loss: 0.903392]\n",
      "epoch:39 step:37099 [D loss: 0.645908, acc.: 58.59%] [G loss: 0.944426]\n",
      "epoch:39 step:37100 [D loss: 0.633501, acc.: 60.94%] [G loss: 0.900538]\n",
      "epoch:39 step:37101 [D loss: 0.647372, acc.: 57.03%] [G loss: 0.926769]\n",
      "epoch:39 step:37102 [D loss: 0.669842, acc.: 59.38%] [G loss: 0.859804]\n",
      "epoch:39 step:37103 [D loss: 0.643131, acc.: 60.94%] [G loss: 0.916488]\n",
      "epoch:39 step:37104 [D loss: 0.669478, acc.: 59.38%] [G loss: 0.817147]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:37105 [D loss: 0.666068, acc.: 60.94%] [G loss: 0.926908]\n",
      "epoch:39 step:37106 [D loss: 0.621938, acc.: 61.72%] [G loss: 0.961439]\n",
      "epoch:39 step:37107 [D loss: 0.637202, acc.: 67.97%] [G loss: 0.974353]\n",
      "epoch:39 step:37108 [D loss: 0.644861, acc.: 64.06%] [G loss: 0.953635]\n",
      "epoch:39 step:37109 [D loss: 0.644310, acc.: 65.62%] [G loss: 0.962527]\n",
      "epoch:39 step:37110 [D loss: 0.615283, acc.: 63.28%] [G loss: 0.941461]\n",
      "epoch:39 step:37111 [D loss: 0.681165, acc.: 53.91%] [G loss: 0.958469]\n",
      "epoch:39 step:37112 [D loss: 0.613415, acc.: 69.53%] [G loss: 1.043622]\n",
      "epoch:39 step:37113 [D loss: 0.644629, acc.: 61.72%] [G loss: 0.953986]\n",
      "epoch:39 step:37114 [D loss: 0.626933, acc.: 67.97%] [G loss: 0.898528]\n",
      "epoch:39 step:37115 [D loss: 0.595458, acc.: 68.75%] [G loss: 0.920897]\n",
      "epoch:39 step:37116 [D loss: 0.610568, acc.: 64.84%] [G loss: 0.941599]\n",
      "epoch:39 step:37117 [D loss: 0.658299, acc.: 59.38%] [G loss: 0.969821]\n",
      "epoch:39 step:37118 [D loss: 0.665670, acc.: 63.28%] [G loss: 0.857627]\n",
      "epoch:39 step:37119 [D loss: 0.621526, acc.: 60.94%] [G loss: 0.877140]\n",
      "epoch:39 step:37120 [D loss: 0.627384, acc.: 64.84%] [G loss: 0.971290]\n",
      "epoch:39 step:37121 [D loss: 0.672752, acc.: 58.59%] [G loss: 0.910834]\n",
      "epoch:39 step:37122 [D loss: 0.667548, acc.: 59.38%] [G loss: 0.935231]\n",
      "epoch:39 step:37123 [D loss: 0.639290, acc.: 62.50%] [G loss: 0.907145]\n",
      "epoch:39 step:37124 [D loss: 0.632362, acc.: 66.41%] [G loss: 0.968050]\n",
      "epoch:39 step:37125 [D loss: 0.629251, acc.: 66.41%] [G loss: 0.928491]\n",
      "epoch:39 step:37126 [D loss: 0.686907, acc.: 58.59%] [G loss: 0.989063]\n",
      "epoch:39 step:37127 [D loss: 0.627148, acc.: 64.06%] [G loss: 0.965167]\n",
      "epoch:39 step:37128 [D loss: 0.648668, acc.: 70.31%] [G loss: 0.990824]\n",
      "epoch:39 step:37129 [D loss: 0.623844, acc.: 65.62%] [G loss: 0.983204]\n",
      "epoch:39 step:37130 [D loss: 0.623828, acc.: 67.97%] [G loss: 0.983320]\n",
      "epoch:39 step:37131 [D loss: 0.680038, acc.: 60.16%] [G loss: 0.975712]\n",
      "epoch:39 step:37132 [D loss: 0.677462, acc.: 55.47%] [G loss: 0.944593]\n",
      "epoch:39 step:37133 [D loss: 0.624119, acc.: 66.41%] [G loss: 0.949838]\n",
      "epoch:39 step:37134 [D loss: 0.642496, acc.: 63.28%] [G loss: 0.935093]\n",
      "epoch:39 step:37135 [D loss: 0.628381, acc.: 65.62%] [G loss: 0.957641]\n",
      "epoch:39 step:37136 [D loss: 0.613710, acc.: 66.41%] [G loss: 0.940135]\n",
      "epoch:39 step:37137 [D loss: 0.573848, acc.: 68.75%] [G loss: 0.896923]\n",
      "epoch:39 step:37138 [D loss: 0.645685, acc.: 68.75%] [G loss: 0.988805]\n",
      "epoch:39 step:37139 [D loss: 0.658499, acc.: 60.16%] [G loss: 0.943239]\n",
      "epoch:39 step:37140 [D loss: 0.609674, acc.: 64.06%] [G loss: 0.942819]\n",
      "epoch:39 step:37141 [D loss: 0.654975, acc.: 63.28%] [G loss: 0.894568]\n",
      "epoch:39 step:37142 [D loss: 0.605905, acc.: 69.53%] [G loss: 1.009030]\n",
      "epoch:39 step:37143 [D loss: 0.639390, acc.: 64.84%] [G loss: 0.994497]\n",
      "epoch:39 step:37144 [D loss: 0.644654, acc.: 59.38%] [G loss: 1.020975]\n",
      "epoch:39 step:37145 [D loss: 0.576902, acc.: 71.88%] [G loss: 0.920941]\n",
      "epoch:39 step:37146 [D loss: 0.713333, acc.: 51.56%] [G loss: 1.010428]\n",
      "epoch:39 step:37147 [D loss: 0.644619, acc.: 62.50%] [G loss: 0.943679]\n",
      "epoch:39 step:37148 [D loss: 0.648611, acc.: 56.25%] [G loss: 0.991122]\n",
      "epoch:39 step:37149 [D loss: 0.656325, acc.: 58.59%] [G loss: 0.986648]\n",
      "epoch:39 step:37150 [D loss: 0.618343, acc.: 63.28%] [G loss: 0.942317]\n",
      "epoch:39 step:37151 [D loss: 0.642329, acc.: 61.72%] [G loss: 0.943165]\n",
      "epoch:39 step:37152 [D loss: 0.606784, acc.: 69.53%] [G loss: 0.967275]\n",
      "epoch:39 step:37153 [D loss: 0.666748, acc.: 57.81%] [G loss: 0.912540]\n",
      "epoch:39 step:37154 [D loss: 0.648513, acc.: 65.62%] [G loss: 0.955954]\n",
      "epoch:39 step:37155 [D loss: 0.624474, acc.: 68.75%] [G loss: 0.917160]\n",
      "epoch:39 step:37156 [D loss: 0.634457, acc.: 61.72%] [G loss: 0.979469]\n",
      "epoch:39 step:37157 [D loss: 0.654478, acc.: 66.41%] [G loss: 0.969763]\n",
      "epoch:39 step:37158 [D loss: 0.615144, acc.: 64.84%] [G loss: 0.976846]\n",
      "epoch:39 step:37159 [D loss: 0.648389, acc.: 60.94%] [G loss: 0.936490]\n",
      "epoch:39 step:37160 [D loss: 0.650284, acc.: 60.94%] [G loss: 0.987432]\n",
      "epoch:39 step:37161 [D loss: 0.655731, acc.: 60.16%] [G loss: 0.944087]\n",
      "epoch:39 step:37162 [D loss: 0.629980, acc.: 58.59%] [G loss: 0.991402]\n",
      "epoch:39 step:37163 [D loss: 0.669129, acc.: 58.59%] [G loss: 0.985280]\n",
      "epoch:39 step:37164 [D loss: 0.689812, acc.: 59.38%] [G loss: 0.955189]\n",
      "epoch:39 step:37165 [D loss: 0.624932, acc.: 64.84%] [G loss: 0.933356]\n",
      "epoch:39 step:37166 [D loss: 0.627329, acc.: 67.97%] [G loss: 0.986836]\n",
      "epoch:39 step:37167 [D loss: 0.640504, acc.: 62.50%] [G loss: 0.927666]\n",
      "epoch:39 step:37168 [D loss: 0.622198, acc.: 64.84%] [G loss: 0.893353]\n",
      "epoch:39 step:37169 [D loss: 0.633138, acc.: 68.75%] [G loss: 0.976544]\n",
      "epoch:39 step:37170 [D loss: 0.621422, acc.: 68.75%] [G loss: 0.925904]\n",
      "epoch:39 step:37171 [D loss: 0.657827, acc.: 57.03%] [G loss: 0.976730]\n",
      "epoch:39 step:37172 [D loss: 0.633998, acc.: 66.41%] [G loss: 0.882349]\n",
      "epoch:39 step:37173 [D loss: 0.677989, acc.: 57.03%] [G loss: 0.953742]\n",
      "epoch:39 step:37174 [D loss: 0.621073, acc.: 62.50%] [G loss: 0.957342]\n",
      "epoch:39 step:37175 [D loss: 0.635184, acc.: 62.50%] [G loss: 1.014363]\n",
      "epoch:39 step:37176 [D loss: 0.600022, acc.: 67.19%] [G loss: 1.025348]\n",
      "epoch:39 step:37177 [D loss: 0.632524, acc.: 61.72%] [G loss: 1.018740]\n",
      "epoch:39 step:37178 [D loss: 0.614173, acc.: 67.97%] [G loss: 1.006038]\n",
      "epoch:39 step:37179 [D loss: 0.607239, acc.: 65.62%] [G loss: 0.981507]\n",
      "epoch:39 step:37180 [D loss: 0.631851, acc.: 67.19%] [G loss: 1.030045]\n",
      "epoch:39 step:37181 [D loss: 0.616652, acc.: 64.84%] [G loss: 1.015380]\n",
      "epoch:39 step:37182 [D loss: 0.687153, acc.: 55.47%] [G loss: 0.919538]\n",
      "epoch:39 step:37183 [D loss: 0.642414, acc.: 61.72%] [G loss: 0.923885]\n",
      "epoch:39 step:37184 [D loss: 0.627715, acc.: 63.28%] [G loss: 0.995238]\n",
      "epoch:39 step:37185 [D loss: 0.629196, acc.: 67.97%] [G loss: 1.031113]\n",
      "epoch:39 step:37186 [D loss: 0.698923, acc.: 55.47%] [G loss: 0.972055]\n",
      "epoch:39 step:37187 [D loss: 0.612866, acc.: 67.19%] [G loss: 0.925560]\n",
      "epoch:39 step:37188 [D loss: 0.614260, acc.: 62.50%] [G loss: 0.901734]\n",
      "epoch:39 step:37189 [D loss: 0.661534, acc.: 64.06%] [G loss: 0.989037]\n",
      "epoch:39 step:37190 [D loss: 0.662588, acc.: 60.94%] [G loss: 0.986495]\n",
      "epoch:39 step:37191 [D loss: 0.633033, acc.: 60.94%] [G loss: 0.974175]\n",
      "epoch:39 step:37192 [D loss: 0.664477, acc.: 57.81%] [G loss: 0.975566]\n",
      "epoch:39 step:37193 [D loss: 0.651740, acc.: 64.84%] [G loss: 1.006308]\n",
      "epoch:39 step:37194 [D loss: 0.646577, acc.: 54.69%] [G loss: 0.964455]\n",
      "epoch:39 step:37195 [D loss: 0.658730, acc.: 64.06%] [G loss: 1.025812]\n",
      "epoch:39 step:37196 [D loss: 0.580323, acc.: 72.66%] [G loss: 0.942386]\n",
      "epoch:39 step:37197 [D loss: 0.657587, acc.: 59.38%] [G loss: 1.007703]\n",
      "epoch:39 step:37198 [D loss: 0.675428, acc.: 59.38%] [G loss: 0.942758]\n",
      "epoch:39 step:37199 [D loss: 0.644208, acc.: 59.38%] [G loss: 0.953158]\n",
      "epoch:39 step:37200 [D loss: 0.654882, acc.: 62.50%] [G loss: 0.957956]\n",
      "##############\n",
      "[2.99315316 2.66511694 2.19166786 4.20721983 0.9885525  7.53267224\n",
      " 2.75269172 3.44515224 4.21327625 8.14868929]\n",
      "##########\n",
      "epoch:39 step:37201 [D loss: 0.684168, acc.: 59.38%] [G loss: 0.930879]\n",
      "epoch:39 step:37202 [D loss: 0.676266, acc.: 53.91%] [G loss: 1.050772]\n",
      "epoch:39 step:37203 [D loss: 0.630486, acc.: 65.62%] [G loss: 1.041718]\n",
      "epoch:39 step:37204 [D loss: 0.652419, acc.: 64.06%] [G loss: 1.007453]\n",
      "epoch:39 step:37205 [D loss: 0.639187, acc.: 61.72%] [G loss: 0.918896]\n",
      "epoch:39 step:37206 [D loss: 0.660433, acc.: 57.81%] [G loss: 1.003423]\n",
      "epoch:39 step:37207 [D loss: 0.624539, acc.: 63.28%] [G loss: 0.945573]\n",
      "epoch:39 step:37208 [D loss: 0.647055, acc.: 57.81%] [G loss: 0.958148]\n",
      "epoch:39 step:37209 [D loss: 0.628635, acc.: 64.06%] [G loss: 0.924508]\n",
      "epoch:39 step:37210 [D loss: 0.652296, acc.: 62.50%] [G loss: 1.025139]\n",
      "epoch:39 step:37211 [D loss: 0.619095, acc.: 67.97%] [G loss: 0.981836]\n",
      "epoch:39 step:37212 [D loss: 0.615969, acc.: 63.28%] [G loss: 1.031959]\n",
      "epoch:39 step:37213 [D loss: 0.637988, acc.: 62.50%] [G loss: 0.962207]\n",
      "epoch:39 step:37214 [D loss: 0.613466, acc.: 68.75%] [G loss: 0.943168]\n",
      "epoch:39 step:37215 [D loss: 0.636934, acc.: 62.50%] [G loss: 1.064510]\n",
      "epoch:39 step:37216 [D loss: 0.634460, acc.: 64.06%] [G loss: 1.057863]\n",
      "epoch:39 step:37217 [D loss: 0.627557, acc.: 62.50%] [G loss: 0.968471]\n",
      "epoch:39 step:37218 [D loss: 0.627131, acc.: 67.97%] [G loss: 1.022412]\n",
      "epoch:39 step:37219 [D loss: 0.609372, acc.: 66.41%] [G loss: 0.958307]\n",
      "epoch:39 step:37220 [D loss: 0.623585, acc.: 68.75%] [G loss: 0.852023]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:37221 [D loss: 0.660492, acc.: 61.72%] [G loss: 1.001187]\n",
      "epoch:39 step:37222 [D loss: 0.612609, acc.: 68.75%] [G loss: 0.956879]\n",
      "epoch:39 step:37223 [D loss: 0.682508, acc.: 55.47%] [G loss: 0.916668]\n",
      "epoch:39 step:37224 [D loss: 0.655320, acc.: 62.50%] [G loss: 0.964812]\n",
      "epoch:39 step:37225 [D loss: 0.638346, acc.: 64.84%] [G loss: 0.960669]\n",
      "epoch:39 step:37226 [D loss: 0.638457, acc.: 65.62%] [G loss: 0.968227]\n",
      "epoch:39 step:37227 [D loss: 0.610890, acc.: 64.06%] [G loss: 0.983025]\n",
      "epoch:39 step:37228 [D loss: 0.582459, acc.: 72.66%] [G loss: 0.990994]\n",
      "epoch:39 step:37229 [D loss: 0.679898, acc.: 57.81%] [G loss: 0.974003]\n",
      "epoch:39 step:37230 [D loss: 0.586259, acc.: 70.31%] [G loss: 0.869319]\n",
      "epoch:39 step:37231 [D loss: 0.637616, acc.: 64.06%] [G loss: 0.953828]\n",
      "epoch:39 step:37232 [D loss: 0.633906, acc.: 61.72%] [G loss: 0.975811]\n",
      "epoch:39 step:37233 [D loss: 0.653064, acc.: 59.38%] [G loss: 0.973956]\n",
      "epoch:39 step:37234 [D loss: 0.660903, acc.: 57.03%] [G loss: 0.915025]\n",
      "epoch:39 step:37235 [D loss: 0.644358, acc.: 61.72%] [G loss: 0.996252]\n",
      "epoch:39 step:37236 [D loss: 0.596608, acc.: 71.88%] [G loss: 0.993429]\n",
      "epoch:39 step:37237 [D loss: 0.636620, acc.: 64.06%] [G loss: 0.921416]\n",
      "epoch:39 step:37238 [D loss: 0.655641, acc.: 65.62%] [G loss: 0.932081]\n",
      "epoch:39 step:37239 [D loss: 0.659488, acc.: 59.38%] [G loss: 1.041814]\n",
      "epoch:39 step:37240 [D loss: 0.617131, acc.: 62.50%] [G loss: 0.975418]\n",
      "epoch:39 step:37241 [D loss: 0.649300, acc.: 57.03%] [G loss: 0.981361]\n",
      "epoch:39 step:37242 [D loss: 0.662273, acc.: 56.25%] [G loss: 0.987842]\n",
      "epoch:39 step:37243 [D loss: 0.624738, acc.: 63.28%] [G loss: 0.944148]\n",
      "epoch:39 step:37244 [D loss: 0.614770, acc.: 60.16%] [G loss: 0.952920]\n",
      "epoch:39 step:37245 [D loss: 0.668531, acc.: 55.47%] [G loss: 0.919154]\n",
      "epoch:39 step:37246 [D loss: 0.654024, acc.: 55.47%] [G loss: 1.003217]\n",
      "epoch:39 step:37247 [D loss: 0.638502, acc.: 61.72%] [G loss: 0.988674]\n",
      "epoch:39 step:37248 [D loss: 0.637480, acc.: 63.28%] [G loss: 0.974710]\n",
      "epoch:39 step:37249 [D loss: 0.663456, acc.: 58.59%] [G loss: 1.006921]\n",
      "epoch:39 step:37250 [D loss: 0.612148, acc.: 68.75%] [G loss: 0.955844]\n",
      "epoch:39 step:37251 [D loss: 0.635488, acc.: 61.72%] [G loss: 0.917396]\n",
      "epoch:39 step:37252 [D loss: 0.674624, acc.: 58.59%] [G loss: 0.849157]\n",
      "epoch:39 step:37253 [D loss: 0.648432, acc.: 67.97%] [G loss: 0.867660]\n",
      "epoch:39 step:37254 [D loss: 0.651061, acc.: 57.81%] [G loss: 0.929237]\n",
      "epoch:39 step:37255 [D loss: 0.640172, acc.: 59.38%] [G loss: 0.956033]\n",
      "epoch:39 step:37256 [D loss: 0.644667, acc.: 60.94%] [G loss: 0.960192]\n",
      "epoch:39 step:37257 [D loss: 0.645199, acc.: 57.03%] [G loss: 0.986300]\n",
      "epoch:39 step:37258 [D loss: 0.687620, acc.: 58.59%] [G loss: 0.989811]\n",
      "epoch:39 step:37259 [D loss: 0.619342, acc.: 62.50%] [G loss: 0.943412]\n",
      "epoch:39 step:37260 [D loss: 0.592617, acc.: 67.97%] [G loss: 0.961989]\n",
      "epoch:39 step:37261 [D loss: 0.586247, acc.: 71.09%] [G loss: 0.932562]\n",
      "epoch:39 step:37262 [D loss: 0.668803, acc.: 57.03%] [G loss: 1.005282]\n",
      "epoch:39 step:37263 [D loss: 0.592625, acc.: 67.19%] [G loss: 1.044068]\n",
      "epoch:39 step:37264 [D loss: 0.570949, acc.: 74.22%] [G loss: 1.026483]\n",
      "epoch:39 step:37265 [D loss: 0.576091, acc.: 69.53%] [G loss: 1.027966]\n",
      "epoch:39 step:37266 [D loss: 0.626877, acc.: 60.16%] [G loss: 0.975297]\n",
      "epoch:39 step:37267 [D loss: 0.648757, acc.: 60.16%] [G loss: 0.979660]\n",
      "epoch:39 step:37268 [D loss: 0.579781, acc.: 71.09%] [G loss: 0.978585]\n",
      "epoch:39 step:37269 [D loss: 0.625746, acc.: 67.19%] [G loss: 0.949398]\n",
      "epoch:39 step:37270 [D loss: 0.643374, acc.: 60.94%] [G loss: 0.926754]\n",
      "epoch:39 step:37271 [D loss: 0.644320, acc.: 61.72%] [G loss: 0.965886]\n",
      "epoch:39 step:37272 [D loss: 0.631499, acc.: 62.50%] [G loss: 1.003528]\n",
      "epoch:39 step:37273 [D loss: 0.651865, acc.: 59.38%] [G loss: 0.960875]\n",
      "epoch:39 step:37274 [D loss: 0.636636, acc.: 62.50%] [G loss: 0.945179]\n",
      "epoch:39 step:37275 [D loss: 0.659044, acc.: 58.59%] [G loss: 0.890904]\n",
      "epoch:39 step:37276 [D loss: 0.651608, acc.: 57.81%] [G loss: 0.899977]\n",
      "epoch:39 step:37277 [D loss: 0.623098, acc.: 61.72%] [G loss: 0.894205]\n",
      "epoch:39 step:37278 [D loss: 0.632937, acc.: 58.59%] [G loss: 1.035167]\n",
      "epoch:39 step:37279 [D loss: 0.628271, acc.: 67.97%] [G loss: 0.948698]\n",
      "epoch:39 step:37280 [D loss: 0.601554, acc.: 66.41%] [G loss: 1.027367]\n",
      "epoch:39 step:37281 [D loss: 0.623510, acc.: 62.50%] [G loss: 0.968863]\n",
      "epoch:39 step:37282 [D loss: 0.683055, acc.: 55.47%] [G loss: 0.975018]\n",
      "epoch:39 step:37283 [D loss: 0.690876, acc.: 56.25%] [G loss: 0.987921]\n",
      "epoch:39 step:37284 [D loss: 0.645611, acc.: 61.72%] [G loss: 0.953802]\n",
      "epoch:39 step:37285 [D loss: 0.647405, acc.: 60.94%] [G loss: 0.911576]\n",
      "epoch:39 step:37286 [D loss: 0.691277, acc.: 50.00%] [G loss: 0.930963]\n",
      "epoch:39 step:37287 [D loss: 0.617300, acc.: 65.62%] [G loss: 0.892773]\n",
      "epoch:39 step:37288 [D loss: 0.654446, acc.: 61.72%] [G loss: 0.982311]\n",
      "epoch:39 step:37289 [D loss: 0.628753, acc.: 62.50%] [G loss: 0.967452]\n",
      "epoch:39 step:37290 [D loss: 0.629075, acc.: 66.41%] [G loss: 0.999718]\n",
      "epoch:39 step:37291 [D loss: 0.614363, acc.: 64.06%] [G loss: 0.983324]\n",
      "epoch:39 step:37292 [D loss: 0.611133, acc.: 67.19%] [G loss: 0.988843]\n",
      "epoch:39 step:37293 [D loss: 0.599562, acc.: 67.97%] [G loss: 0.930056]\n",
      "epoch:39 step:37294 [D loss: 0.587502, acc.: 67.97%] [G loss: 0.958216]\n",
      "epoch:39 step:37295 [D loss: 0.611572, acc.: 68.75%] [G loss: 0.971703]\n",
      "epoch:39 step:37296 [D loss: 0.626714, acc.: 64.06%] [G loss: 0.934913]\n",
      "epoch:39 step:37297 [D loss: 0.645404, acc.: 65.62%] [G loss: 0.940639]\n",
      "epoch:39 step:37298 [D loss: 0.633313, acc.: 65.62%] [G loss: 0.942039]\n",
      "epoch:39 step:37299 [D loss: 0.615131, acc.: 64.84%] [G loss: 0.939822]\n",
      "epoch:39 step:37300 [D loss: 0.597499, acc.: 68.75%] [G loss: 0.945673]\n",
      "epoch:39 step:37301 [D loss: 0.621314, acc.: 63.28%] [G loss: 1.003050]\n",
      "epoch:39 step:37302 [D loss: 0.672716, acc.: 56.25%] [G loss: 1.009929]\n",
      "epoch:39 step:37303 [D loss: 0.653494, acc.: 61.72%] [G loss: 0.977153]\n",
      "epoch:39 step:37304 [D loss: 0.643372, acc.: 60.94%] [G loss: 0.963350]\n",
      "epoch:39 step:37305 [D loss: 0.656383, acc.: 62.50%] [G loss: 0.933535]\n",
      "epoch:39 step:37306 [D loss: 0.644029, acc.: 64.84%] [G loss: 0.936774]\n",
      "epoch:39 step:37307 [D loss: 0.571914, acc.: 74.22%] [G loss: 0.901706]\n",
      "epoch:39 step:37308 [D loss: 0.640851, acc.: 60.94%] [G loss: 0.895964]\n",
      "epoch:39 step:37309 [D loss: 0.685220, acc.: 52.34%] [G loss: 0.961550]\n",
      "epoch:39 step:37310 [D loss: 0.600470, acc.: 70.31%] [G loss: 0.884442]\n",
      "epoch:39 step:37311 [D loss: 0.631272, acc.: 60.94%] [G loss: 0.937892]\n",
      "epoch:39 step:37312 [D loss: 0.585670, acc.: 70.31%] [G loss: 0.976693]\n",
      "epoch:39 step:37313 [D loss: 0.641541, acc.: 62.50%] [G loss: 0.976598]\n",
      "epoch:39 step:37314 [D loss: 0.694341, acc.: 52.34%] [G loss: 0.979731]\n",
      "epoch:39 step:37315 [D loss: 0.599040, acc.: 71.09%] [G loss: 1.028685]\n",
      "epoch:39 step:37316 [D loss: 0.648161, acc.: 62.50%] [G loss: 0.991094]\n",
      "epoch:39 step:37317 [D loss: 0.633786, acc.: 66.41%] [G loss: 1.013939]\n",
      "epoch:39 step:37318 [D loss: 0.635707, acc.: 64.84%] [G loss: 1.073631]\n",
      "epoch:39 step:37319 [D loss: 0.619717, acc.: 67.19%] [G loss: 1.009067]\n",
      "epoch:39 step:37320 [D loss: 0.633839, acc.: 64.84%] [G loss: 1.029405]\n",
      "epoch:39 step:37321 [D loss: 0.589389, acc.: 67.19%] [G loss: 0.995199]\n",
      "epoch:39 step:37322 [D loss: 0.701140, acc.: 54.69%] [G loss: 0.961524]\n",
      "epoch:39 step:37323 [D loss: 0.651498, acc.: 60.94%] [G loss: 1.095121]\n",
      "epoch:39 step:37324 [D loss: 0.698053, acc.: 55.47%] [G loss: 0.943710]\n",
      "epoch:39 step:37325 [D loss: 0.649440, acc.: 64.84%] [G loss: 0.955554]\n",
      "epoch:39 step:37326 [D loss: 0.632763, acc.: 61.72%] [G loss: 0.944122]\n",
      "epoch:39 step:37327 [D loss: 0.700034, acc.: 48.44%] [G loss: 0.933396]\n",
      "epoch:39 step:37328 [D loss: 0.604183, acc.: 66.41%] [G loss: 0.992069]\n",
      "epoch:39 step:37329 [D loss: 0.663609, acc.: 63.28%] [G loss: 1.000617]\n",
      "epoch:39 step:37330 [D loss: 0.663495, acc.: 51.56%] [G loss: 0.998123]\n",
      "epoch:39 step:37331 [D loss: 0.640016, acc.: 60.94%] [G loss: 0.901446]\n",
      "epoch:39 step:37332 [D loss: 0.600629, acc.: 65.62%] [G loss: 0.926543]\n",
      "epoch:39 step:37333 [D loss: 0.683566, acc.: 57.81%] [G loss: 0.982859]\n",
      "epoch:39 step:37334 [D loss: 0.578546, acc.: 66.41%] [G loss: 0.949059]\n",
      "epoch:39 step:37335 [D loss: 0.587793, acc.: 75.00%] [G loss: 0.955043]\n",
      "epoch:39 step:37336 [D loss: 0.613712, acc.: 62.50%] [G loss: 0.962913]\n",
      "epoch:39 step:37337 [D loss: 0.614698, acc.: 64.06%] [G loss: 0.982136]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:37338 [D loss: 0.616716, acc.: 64.06%] [G loss: 1.016601]\n",
      "epoch:39 step:37339 [D loss: 0.666609, acc.: 63.28%] [G loss: 1.000219]\n",
      "epoch:39 step:37340 [D loss: 0.636404, acc.: 65.62%] [G loss: 0.967287]\n",
      "epoch:39 step:37341 [D loss: 0.657200, acc.: 55.47%] [G loss: 0.926739]\n",
      "epoch:39 step:37342 [D loss: 0.643556, acc.: 63.28%] [G loss: 0.981456]\n",
      "epoch:39 step:37343 [D loss: 0.614539, acc.: 65.62%] [G loss: 0.967320]\n",
      "epoch:39 step:37344 [D loss: 0.635620, acc.: 63.28%] [G loss: 0.955403]\n",
      "epoch:39 step:37345 [D loss: 0.700367, acc.: 53.91%] [G loss: 0.941830]\n",
      "epoch:39 step:37346 [D loss: 0.642681, acc.: 61.72%] [G loss: 0.999905]\n",
      "epoch:39 step:37347 [D loss: 0.651425, acc.: 60.16%] [G loss: 0.929522]\n",
      "epoch:39 step:37348 [D loss: 0.641344, acc.: 61.72%] [G loss: 0.904368]\n",
      "epoch:39 step:37349 [D loss: 0.627622, acc.: 62.50%] [G loss: 0.926546]\n",
      "epoch:39 step:37350 [D loss: 0.661879, acc.: 53.91%] [G loss: 0.981220]\n",
      "epoch:39 step:37351 [D loss: 0.628412, acc.: 66.41%] [G loss: 1.003377]\n",
      "epoch:39 step:37352 [D loss: 0.653934, acc.: 55.47%] [G loss: 0.936166]\n",
      "epoch:39 step:37353 [D loss: 0.643731, acc.: 60.94%] [G loss: 0.956543]\n",
      "epoch:39 step:37354 [D loss: 0.638452, acc.: 62.50%] [G loss: 1.009649]\n",
      "epoch:39 step:37355 [D loss: 0.662183, acc.: 60.16%] [G loss: 0.876970]\n",
      "epoch:39 step:37356 [D loss: 0.640671, acc.: 63.28%] [G loss: 0.919195]\n",
      "epoch:39 step:37357 [D loss: 0.607450, acc.: 72.66%] [G loss: 1.026065]\n",
      "epoch:39 step:37358 [D loss: 0.592583, acc.: 64.84%] [G loss: 0.980156]\n",
      "epoch:39 step:37359 [D loss: 0.616322, acc.: 64.84%] [G loss: 1.009607]\n",
      "epoch:39 step:37360 [D loss: 0.708646, acc.: 53.12%] [G loss: 1.007670]\n",
      "epoch:39 step:37361 [D loss: 0.681954, acc.: 57.81%] [G loss: 0.934248]\n",
      "epoch:39 step:37362 [D loss: 0.662255, acc.: 64.84%] [G loss: 0.980146]\n",
      "epoch:39 step:37363 [D loss: 0.652839, acc.: 58.59%] [G loss: 0.961839]\n",
      "epoch:39 step:37364 [D loss: 0.624889, acc.: 65.62%] [G loss: 0.938359]\n",
      "epoch:39 step:37365 [D loss: 0.595193, acc.: 67.97%] [G loss: 0.951514]\n",
      "epoch:39 step:37366 [D loss: 0.658562, acc.: 60.94%] [G loss: 0.941181]\n",
      "epoch:39 step:37367 [D loss: 0.646035, acc.: 62.50%] [G loss: 0.939149]\n",
      "epoch:39 step:37368 [D loss: 0.645740, acc.: 54.69%] [G loss: 0.987416]\n",
      "epoch:39 step:37369 [D loss: 0.624094, acc.: 62.50%] [G loss: 0.984132]\n",
      "epoch:39 step:37370 [D loss: 0.634694, acc.: 60.94%] [G loss: 0.930020]\n",
      "epoch:39 step:37371 [D loss: 0.634858, acc.: 61.72%] [G loss: 0.960260]\n",
      "epoch:39 step:37372 [D loss: 0.642361, acc.: 63.28%] [G loss: 0.908120]\n",
      "epoch:39 step:37373 [D loss: 0.620349, acc.: 70.31%] [G loss: 0.966292]\n",
      "epoch:39 step:37374 [D loss: 0.629884, acc.: 59.38%] [G loss: 0.947759]\n",
      "epoch:39 step:37375 [D loss: 0.592361, acc.: 66.41%] [G loss: 1.033810]\n",
      "epoch:39 step:37376 [D loss: 0.649457, acc.: 64.06%] [G loss: 0.992608]\n",
      "epoch:39 step:37377 [D loss: 0.622285, acc.: 63.28%] [G loss: 0.945211]\n",
      "epoch:39 step:37378 [D loss: 0.670302, acc.: 59.38%] [G loss: 1.002797]\n",
      "epoch:39 step:37379 [D loss: 0.633793, acc.: 60.94%] [G loss: 0.940034]\n",
      "epoch:39 step:37380 [D loss: 0.619199, acc.: 59.38%] [G loss: 0.969253]\n",
      "epoch:39 step:37381 [D loss: 0.652264, acc.: 64.06%] [G loss: 0.984375]\n",
      "epoch:39 step:37382 [D loss: 0.608342, acc.: 67.19%] [G loss: 0.935171]\n",
      "epoch:39 step:37383 [D loss: 0.627421, acc.: 63.28%] [G loss: 0.897949]\n",
      "epoch:39 step:37384 [D loss: 0.622738, acc.: 63.28%] [G loss: 0.969944]\n",
      "epoch:39 step:37385 [D loss: 0.667295, acc.: 52.34%] [G loss: 0.903374]\n",
      "epoch:39 step:37386 [D loss: 0.696009, acc.: 54.69%] [G loss: 0.907609]\n",
      "epoch:39 step:37387 [D loss: 0.622094, acc.: 61.72%] [G loss: 0.995835]\n",
      "epoch:39 step:37388 [D loss: 0.668450, acc.: 60.16%] [G loss: 0.962515]\n",
      "epoch:39 step:37389 [D loss: 0.665503, acc.: 62.50%] [G loss: 0.971630]\n",
      "epoch:39 step:37390 [D loss: 0.626180, acc.: 61.72%] [G loss: 0.968640]\n",
      "epoch:39 step:37391 [D loss: 0.630697, acc.: 67.97%] [G loss: 0.975872]\n",
      "epoch:39 step:37392 [D loss: 0.612677, acc.: 67.19%] [G loss: 1.030378]\n",
      "epoch:39 step:37393 [D loss: 0.629077, acc.: 65.62%] [G loss: 1.003323]\n",
      "epoch:39 step:37394 [D loss: 0.647516, acc.: 63.28%] [G loss: 0.974442]\n",
      "epoch:39 step:37395 [D loss: 0.639455, acc.: 66.41%] [G loss: 0.990611]\n",
      "epoch:39 step:37396 [D loss: 0.693298, acc.: 56.25%] [G loss: 0.885770]\n",
      "epoch:39 step:37397 [D loss: 0.636244, acc.: 63.28%] [G loss: 0.909757]\n",
      "epoch:39 step:37398 [D loss: 0.681829, acc.: 60.16%] [G loss: 0.963555]\n",
      "epoch:39 step:37399 [D loss: 0.598739, acc.: 68.75%] [G loss: 0.903833]\n",
      "epoch:39 step:37400 [D loss: 0.693466, acc.: 55.47%] [G loss: 0.939563]\n",
      "##############\n",
      "[2.98482859 2.23949552 2.28768339 3.78381394 1.40502843 8.5094935\n",
      " 2.80290084 3.68265976 4.29870546 8.14868929]\n",
      "##########\n",
      "epoch:39 step:37401 [D loss: 0.638293, acc.: 62.50%] [G loss: 0.895256]\n",
      "epoch:39 step:37402 [D loss: 0.691183, acc.: 54.69%] [G loss: 0.945088]\n",
      "epoch:39 step:37403 [D loss: 0.651768, acc.: 58.59%] [G loss: 0.963592]\n",
      "epoch:39 step:37404 [D loss: 0.619175, acc.: 66.41%] [G loss: 0.948339]\n",
      "epoch:39 step:37405 [D loss: 0.619198, acc.: 64.06%] [G loss: 0.944299]\n",
      "epoch:39 step:37406 [D loss: 0.610796, acc.: 63.28%] [G loss: 0.948807]\n",
      "epoch:39 step:37407 [D loss: 0.649717, acc.: 58.59%] [G loss: 0.899467]\n",
      "epoch:39 step:37408 [D loss: 0.635303, acc.: 65.62%] [G loss: 0.943162]\n",
      "epoch:39 step:37409 [D loss: 0.641842, acc.: 61.72%] [G loss: 0.957651]\n",
      "epoch:39 step:37410 [D loss: 0.644595, acc.: 57.81%] [G loss: 0.915147]\n",
      "epoch:39 step:37411 [D loss: 0.629751, acc.: 64.06%] [G loss: 0.939174]\n",
      "epoch:39 step:37412 [D loss: 0.614011, acc.: 61.72%] [G loss: 0.974880]\n",
      "epoch:39 step:37413 [D loss: 0.670777, acc.: 57.81%] [G loss: 0.955519]\n",
      "epoch:39 step:37414 [D loss: 0.586937, acc.: 71.88%] [G loss: 1.018055]\n",
      "epoch:39 step:37415 [D loss: 0.652526, acc.: 55.47%] [G loss: 0.965710]\n",
      "epoch:39 step:37416 [D loss: 0.616845, acc.: 67.97%] [G loss: 0.858462]\n",
      "epoch:39 step:37417 [D loss: 0.614604, acc.: 64.84%] [G loss: 0.904416]\n",
      "epoch:39 step:37418 [D loss: 0.641969, acc.: 63.28%] [G loss: 0.962181]\n",
      "epoch:39 step:37419 [D loss: 0.682334, acc.: 62.50%] [G loss: 0.879873]\n",
      "epoch:39 step:37420 [D loss: 0.599433, acc.: 67.19%] [G loss: 0.974685]\n",
      "epoch:39 step:37421 [D loss: 0.690474, acc.: 61.72%] [G loss: 0.972304]\n",
      "epoch:39 step:37422 [D loss: 0.679875, acc.: 57.03%] [G loss: 0.988427]\n",
      "epoch:39 step:37423 [D loss: 0.658769, acc.: 59.38%] [G loss: 0.967272]\n",
      "epoch:39 step:37424 [D loss: 0.673288, acc.: 53.91%] [G loss: 0.923635]\n",
      "epoch:39 step:37425 [D loss: 0.615471, acc.: 63.28%] [G loss: 0.922698]\n",
      "epoch:39 step:37426 [D loss: 0.644877, acc.: 60.16%] [G loss: 0.954749]\n",
      "epoch:39 step:37427 [D loss: 0.609590, acc.: 70.31%] [G loss: 1.018394]\n",
      "epoch:39 step:37428 [D loss: 0.646261, acc.: 60.16%] [G loss: 1.045418]\n",
      "epoch:39 step:37429 [D loss: 0.613775, acc.: 66.41%] [G loss: 0.933251]\n",
      "epoch:39 step:37430 [D loss: 0.655343, acc.: 64.06%] [G loss: 0.906438]\n",
      "epoch:39 step:37431 [D loss: 0.656835, acc.: 65.62%] [G loss: 0.989449]\n",
      "epoch:39 step:37432 [D loss: 0.620332, acc.: 64.84%] [G loss: 0.933875]\n",
      "epoch:39 step:37433 [D loss: 0.623016, acc.: 67.19%] [G loss: 0.972102]\n",
      "epoch:39 step:37434 [D loss: 0.648340, acc.: 58.59%] [G loss: 0.976614]\n",
      "epoch:39 step:37435 [D loss: 0.712237, acc.: 58.59%] [G loss: 0.962527]\n",
      "epoch:39 step:37436 [D loss: 0.624876, acc.: 64.06%] [G loss: 0.992365]\n",
      "epoch:39 step:37437 [D loss: 0.629701, acc.: 60.16%] [G loss: 1.000395]\n",
      "epoch:39 step:37438 [D loss: 0.598588, acc.: 69.53%] [G loss: 0.930517]\n",
      "epoch:39 step:37439 [D loss: 0.622459, acc.: 64.06%] [G loss: 0.939508]\n",
      "epoch:39 step:37440 [D loss: 0.661251, acc.: 56.25%] [G loss: 0.940859]\n",
      "epoch:39 step:37441 [D loss: 0.626646, acc.: 63.28%] [G loss: 0.985447]\n",
      "epoch:39 step:37442 [D loss: 0.629595, acc.: 60.94%] [G loss: 0.984223]\n",
      "epoch:39 step:37443 [D loss: 0.640967, acc.: 64.84%] [G loss: 0.968811]\n",
      "epoch:39 step:37444 [D loss: 0.657093, acc.: 57.81%] [G loss: 0.936961]\n",
      "epoch:39 step:37445 [D loss: 0.642557, acc.: 64.84%] [G loss: 0.987639]\n",
      "epoch:39 step:37446 [D loss: 0.632381, acc.: 61.72%] [G loss: 0.970844]\n",
      "epoch:39 step:37447 [D loss: 0.624444, acc.: 68.75%] [G loss: 1.025660]\n",
      "epoch:39 step:37448 [D loss: 0.654386, acc.: 60.16%] [G loss: 0.989507]\n",
      "epoch:39 step:37449 [D loss: 0.594217, acc.: 64.84%] [G loss: 0.918512]\n",
      "epoch:39 step:37450 [D loss: 0.648520, acc.: 62.50%] [G loss: 0.916031]\n",
      "epoch:39 step:37451 [D loss: 0.691248, acc.: 57.81%] [G loss: 0.920643]\n",
      "epoch:39 step:37452 [D loss: 0.667175, acc.: 61.72%] [G loss: 0.957379]\n",
      "epoch:39 step:37453 [D loss: 0.696461, acc.: 55.47%] [G loss: 0.991565]\n",
      "epoch:39 step:37454 [D loss: 0.598351, acc.: 67.97%] [G loss: 0.963711]\n",
      "epoch:39 step:37455 [D loss: 0.647444, acc.: 61.72%] [G loss: 0.960540]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:39 step:37456 [D loss: 0.625457, acc.: 62.50%] [G loss: 0.893860]\n",
      "epoch:39 step:37457 [D loss: 0.627559, acc.: 63.28%] [G loss: 0.981777]\n",
      "epoch:39 step:37458 [D loss: 0.643228, acc.: 59.38%] [G loss: 1.024500]\n",
      "epoch:39 step:37459 [D loss: 0.672864, acc.: 57.03%] [G loss: 0.926458]\n",
      "epoch:39 step:37460 [D loss: 0.632415, acc.: 62.50%] [G loss: 0.903006]\n",
      "epoch:39 step:37461 [D loss: 0.693866, acc.: 58.59%] [G loss: 0.865650]\n",
      "epoch:39 step:37462 [D loss: 0.648706, acc.: 60.94%] [G loss: 0.983708]\n",
      "epoch:39 step:37463 [D loss: 0.587675, acc.: 67.97%] [G loss: 1.000249]\n",
      "epoch:39 step:37464 [D loss: 0.646008, acc.: 61.72%] [G loss: 0.939110]\n",
      "epoch:39 step:37465 [D loss: 0.667738, acc.: 59.38%] [G loss: 0.925648]\n",
      "epoch:39 step:37466 [D loss: 0.679799, acc.: 54.69%] [G loss: 0.968219]\n",
      "epoch:39 step:37467 [D loss: 0.640472, acc.: 57.81%] [G loss: 0.940898]\n",
      "epoch:39 step:37468 [D loss: 0.668066, acc.: 58.59%] [G loss: 0.913846]\n",
      "epoch:39 step:37469 [D loss: 0.609338, acc.: 64.84%] [G loss: 0.975380]\n",
      "epoch:39 step:37470 [D loss: 0.649973, acc.: 61.72%] [G loss: 1.002167]\n",
      "epoch:39 step:37471 [D loss: 0.598276, acc.: 66.41%] [G loss: 0.907539]\n",
      "epoch:39 step:37472 [D loss: 0.657859, acc.: 60.94%] [G loss: 0.916171]\n",
      "epoch:39 step:37473 [D loss: 0.619799, acc.: 62.50%] [G loss: 0.958679]\n",
      "epoch:39 step:37474 [D loss: 0.689237, acc.: 52.34%] [G loss: 0.985716]\n",
      "epoch:39 step:37475 [D loss: 0.610861, acc.: 64.06%] [G loss: 0.995735]\n",
      "epoch:39 step:37476 [D loss: 0.693247, acc.: 60.16%] [G loss: 0.929867]\n",
      "epoch:39 step:37477 [D loss: 0.620052, acc.: 64.84%] [G loss: 0.937796]\n",
      "epoch:39 step:37478 [D loss: 0.632483, acc.: 63.28%] [G loss: 0.945540]\n",
      "epoch:39 step:37479 [D loss: 0.650760, acc.: 65.62%] [G loss: 0.925864]\n",
      "epoch:39 step:37480 [D loss: 0.626858, acc.: 65.62%] [G loss: 1.008236]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if not os.path.isdir('saved_models_{}'.format('gan')):\n",
    "    os.mkdir('saved_models_{}'.format('gan'))\n",
    "f = open('saved_models_{}/log_collapse1.txt'.format('gan'), mode='w')\n",
    "import cv2\n",
    "import torch.utils.data as Data\n",
    "\n",
    "from keras.datasets import mnist,fashion_mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import Adam #optimizer of keras\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "class GAN():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 28\n",
    "        self.img_cols = 28\n",
    "        self.channels = 1\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels) #shape of image\n",
    "        self.latent_dim = 100\n",
    "        self.x = []\n",
    "        self.y = np.zeros((31, 1), dtype=np.int)\n",
    "        self.y = list(self.y)\n",
    "        for i in range(31):\n",
    "            self.y[i] = []\n",
    "\n",
    "        optimizer = Adam(0.0002, 0.5) #optimizer of gan\n",
    "\n",
    "        # Build and compile the discriminator,only to keras\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy',\n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build the generator\n",
    "        self.generator = self.build_generator()\n",
    "\n",
    "        # The generator takes noise as input and generates imgs\n",
    "        z = Input(shape=(self.latent_dim,))  #Input():用来实例化一个keras张量\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The discriminator takes generated images as input and determines validity\n",
    "        validity = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator)\n",
    "        # Trains the generator to fool the discriminator\n",
    "        self.combined = Model(z, validity)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "        model.add(Dense(256, input_dim=self.latent_dim))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=(self.latent_dim,))\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Flatten(input_shape=self.img_shape))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=self.img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self, epochs, batch_size=128, sample_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        (X_train, _), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "        X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "        X_train = np.expand_dims(X_train, axis=3)\n",
    "        X_test = (X_test.astype(np.float32) - 127.5) / 127.5\n",
    "        X_test = np.expand_dims(X_test, axis=3)\n",
    "        # y_train = y_train.reshape(-1, 1)\n",
    "\n",
    "        # Adversarial ground truths\n",
    "        valid = np.ones((batch_size, 1))\n",
    "        fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        nb_batches = int(X_train.shape[0] / batch_size)\n",
    "        global_step = 0\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            for index in range(nb_batches):\n",
    "                global_step += 1\n",
    "                imgs = X_train[index * batch_size:(index + 1) * batch_size]\n",
    "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "                # Generate a batch of new images\n",
    "                gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "                # Train the discriminator\n",
    "                d_loss_real = self.discriminator.train_on_batch(imgs, valid)\n",
    "                d_loss_fake = self.discriminator.train_on_batch(gen_imgs, fake)\n",
    "                d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "                # ---------------------\n",
    "                #  Train Generator\n",
    "                # ---------------------\n",
    "\n",
    "                noise = np.random.normal(0, 1, (batch_size, self.latent_dim))\n",
    "\n",
    "                # Train the generator (to have the discriminator label samples as valid)\n",
    "                g_loss = self.combined.train_on_batch(noise, valid)\n",
    "\n",
    "                # Plot the progress\n",
    "                print(\"epoch:%d step:%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (\n",
    "                epoch, global_step, d_loss[0], 100 * d_loss[1], g_loss))\n",
    "\n",
    "                # If at save interval => save generated image samples\n",
    "                sampleSize = 5000\n",
    "                # If at save interval => save generated image samples\n",
    "                if global_step % sample_interval == 0:\n",
    "                    s = self.sample_images(global_step, X_test,y_test, sampleSize)\n",
    "    def sample_images(self, epoch,x_test,y_test,sample_num):\n",
    "        r, c = sample_num//10, 10\n",
    "        noise = np.random.normal(0, 1, (r * c, 100))\n",
    "#         sampled_labels = np.array([num for _ in range(r) for num in range(c)])\n",
    "        gen_imgs = self.generator.predict([noise])\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = 0.5 * gen_imgs + 0.5\n",
    "        labels = np.squeeze(y_test[:sample_num])\n",
    "        labels = np.squeeze(labels)\n",
    "        dis_real = cal_distance_image_real(x_test[:sample_num], labels)\n",
    "        dis_fake = cal_distance_image_fake(gen_imgs)\n",
    "        dis_cha = dis_real - dis_fake\n",
    "        print('##############')\n",
    "        # print(dis_real)\n",
    "        # print(dis_fake)\n",
    "        print(dis_cha)\n",
    "        print('##########')\n",
    "        f.writelines('\\n')\n",
    "        f.writelines('epoch:' + str(epoch))\n",
    "        f.writelines('\\n')\n",
    "        f.writelines('紧度')\n",
    "        f.writelines('\\n')\n",
    "        f.writelines(' %.8f ' % (i) for i in dis_cha)\n",
    "        f.writelines('\\n')\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    gan = GAN()\n",
    "    gan.train(epochs=40, batch_size=64, sample_interval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pppppppp [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
